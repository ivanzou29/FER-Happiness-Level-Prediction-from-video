Epoch: 1| Step: 0
Training loss: 4.905614532331228
Validation loss: 5.754037624525386

Epoch: 5| Step: 1
Training loss: 5.155036552292209
Validation loss: 5.735222072715214

Epoch: 5| Step: 2
Training loss: 5.192368210877297
Validation loss: 5.716668228660554

Epoch: 5| Step: 3
Training loss: 5.620735756168744
Validation loss: 5.695368787789306

Epoch: 5| Step: 4
Training loss: 6.5094286685220055
Validation loss: 5.671420375722393

Epoch: 5| Step: 5
Training loss: 6.36179764923673
Validation loss: 5.6457714211671215

Epoch: 5| Step: 6
Training loss: 5.469184204302842
Validation loss: 5.615815037619883

Epoch: 5| Step: 7
Training loss: 5.639576146046409
Validation loss: 5.581284978196335

Epoch: 5| Step: 8
Training loss: 5.938995815385461
Validation loss: 5.544323054695198

Epoch: 5| Step: 9
Training loss: 4.891338844730523
Validation loss: 5.503090099465755

Epoch: 5| Step: 10
Training loss: 6.4368350972613815
Validation loss: 5.460420783150909

Epoch: 2| Step: 0
Training loss: 6.628100839127493
Validation loss: 5.413530731520042

Epoch: 5| Step: 1
Training loss: 3.66024861580527
Validation loss: 5.364717626837122

Epoch: 5| Step: 2
Training loss: 5.538944044043673
Validation loss: 5.315222088265738

Epoch: 5| Step: 3
Training loss: 5.1136471680806395
Validation loss: 5.266371778132701

Epoch: 5| Step: 4
Training loss: 5.457600590490501
Validation loss: 5.215636057938347

Epoch: 5| Step: 5
Training loss: 5.318995017158195
Validation loss: 5.164080574309697

Epoch: 5| Step: 6
Training loss: 4.823228643336167
Validation loss: 5.110586893134827

Epoch: 5| Step: 7
Training loss: 5.4795949596882805
Validation loss: 5.05520636196863

Epoch: 5| Step: 8
Training loss: 5.3148322876158
Validation loss: 4.999402672968396

Epoch: 5| Step: 9
Training loss: 5.1557015792037175
Validation loss: 4.93812195949565

Epoch: 5| Step: 10
Training loss: 4.3095122229047265
Validation loss: 4.869519182046004

Epoch: 3| Step: 0
Training loss: 5.749906787946076
Validation loss: 4.8000453818647255

Epoch: 5| Step: 1
Training loss: 4.824295253378721
Validation loss: 4.732209403887975

Epoch: 5| Step: 2
Training loss: 4.372012398928191
Validation loss: 4.6696920491154685

Epoch: 5| Step: 3
Training loss: 4.670509368432968
Validation loss: 4.614623353638712

Epoch: 5| Step: 4
Training loss: 5.47899257059389
Validation loss: 4.559618365921917

Epoch: 5| Step: 5
Training loss: 4.5458995913330975
Validation loss: 4.50614264755468

Epoch: 5| Step: 6
Training loss: 4.9983670429154285
Validation loss: 4.471990704342543

Epoch: 5| Step: 7
Training loss: 2.9990487179921943
Validation loss: 4.432029132835969

Epoch: 5| Step: 8
Training loss: 4.681579513055454
Validation loss: 4.398392990820542

Epoch: 5| Step: 9
Training loss: 3.1735495671028047
Validation loss: 4.364275875545263

Epoch: 5| Step: 10
Training loss: 4.985528029289872
Validation loss: 4.330957820972729

Epoch: 4| Step: 0
Training loss: 4.779244993588447
Validation loss: 4.301296474526382

Epoch: 5| Step: 1
Training loss: 4.851515715983165
Validation loss: 4.269854779491731

Epoch: 5| Step: 2
Training loss: 3.4788419986996395
Validation loss: 4.227981742465165

Epoch: 5| Step: 3
Training loss: 4.54297483776731
Validation loss: 4.2001331319965045

Epoch: 5| Step: 4
Training loss: 4.899609585214358
Validation loss: 4.161471155238689

Epoch: 5| Step: 5
Training loss: 3.0473820191124967
Validation loss: 4.116527558576523

Epoch: 5| Step: 6
Training loss: 4.889750149512571
Validation loss: 4.092947923831265

Epoch: 5| Step: 7
Training loss: 3.67102898124326
Validation loss: 4.075506241818245

Epoch: 5| Step: 8
Training loss: 3.363426710432412
Validation loss: 4.055957298273437

Epoch: 5| Step: 9
Training loss: 4.330775582008797
Validation loss: 4.035540757802488

Epoch: 5| Step: 10
Training loss: 4.739545862517859
Validation loss: 4.0095188528921675

Epoch: 5| Step: 0
Training loss: 3.5432957810582835
Validation loss: 3.977806580875905

Epoch: 5| Step: 1
Training loss: 4.451545515526786
Validation loss: 3.94242332064365

Epoch: 5| Step: 2
Training loss: 4.073994031434516
Validation loss: 3.916343884246351

Epoch: 5| Step: 3
Training loss: 4.076104493034344
Validation loss: 3.8904357223637036

Epoch: 5| Step: 4
Training loss: 4.408849287696959
Validation loss: 3.8768590172052817

Epoch: 5| Step: 5
Training loss: 4.021815415587909
Validation loss: 3.8511544378165525

Epoch: 5| Step: 6
Training loss: 3.7899254514262104
Validation loss: 3.8394791588116033

Epoch: 5| Step: 7
Training loss: 3.376861059148417
Validation loss: 3.8120162498269723

Epoch: 5| Step: 8
Training loss: 4.166810351119579
Validation loss: 3.798895637782634

Epoch: 5| Step: 9
Training loss: 4.4631891397018935
Validation loss: 3.77952463096988

Epoch: 5| Step: 10
Training loss: 3.745389647439238
Validation loss: 3.755862547588601

Epoch: 6| Step: 0
Training loss: 4.193925169968919
Validation loss: 3.7462495240667324

Epoch: 5| Step: 1
Training loss: 3.6340614714979007
Validation loss: 3.7289221752152537

Epoch: 5| Step: 2
Training loss: 4.267247600544241
Validation loss: 3.704768181683907

Epoch: 5| Step: 3
Training loss: 3.7002665758758444
Validation loss: 3.683038717601702

Epoch: 5| Step: 4
Training loss: 3.4655382563447437
Validation loss: 3.660505103354969

Epoch: 5| Step: 5
Training loss: 3.8391244239765707
Validation loss: 3.6438561746228366

Epoch: 5| Step: 6
Training loss: 3.6893267228711015
Validation loss: 3.6266526460293624

Epoch: 5| Step: 7
Training loss: 3.920089375975656
Validation loss: 3.6169324811691874

Epoch: 5| Step: 8
Training loss: 4.513184201262063
Validation loss: 3.6018926951240324

Epoch: 5| Step: 9
Training loss: 3.5744324667150233
Validation loss: 3.58663122934161

Epoch: 5| Step: 10
Training loss: 3.28063726607835
Validation loss: 3.5883654917557046

Epoch: 7| Step: 0
Training loss: 3.8108819748703318
Validation loss: 3.575466671863948

Epoch: 5| Step: 1
Training loss: 2.366807762381606
Validation loss: 3.5510032906844646

Epoch: 5| Step: 2
Training loss: 4.187233532070979
Validation loss: 3.543724690245818

Epoch: 5| Step: 3
Training loss: 3.9161313008943823
Validation loss: 3.5261312721676688

Epoch: 5| Step: 4
Training loss: 4.373828404092605
Validation loss: 3.5218514469581077

Epoch: 5| Step: 5
Training loss: 3.818800426094029
Validation loss: 3.5089715014540492

Epoch: 5| Step: 6
Training loss: 3.2434600171252965
Validation loss: 3.497938210997698

Epoch: 5| Step: 7
Training loss: 4.2603931130999415
Validation loss: 3.4846688563322648

Epoch: 5| Step: 8
Training loss: 3.689034223629918
Validation loss: 3.4842956819413105

Epoch: 5| Step: 9
Training loss: 3.3094730582402048
Validation loss: 3.471410354752671

Epoch: 5| Step: 10
Training loss: 3.492587004815493
Validation loss: 3.45872830120822

Epoch: 8| Step: 0
Training loss: 2.9896189369624735
Validation loss: 3.4517135723795427

Epoch: 5| Step: 1
Training loss: 3.5283943715414647
Validation loss: 3.441000998232484

Epoch: 5| Step: 2
Training loss: 3.2314969586383593
Validation loss: 3.4411239181369004

Epoch: 5| Step: 3
Training loss: 2.9713773645715196
Validation loss: 3.448364663426908

Epoch: 5| Step: 4
Training loss: 4.098396052661061
Validation loss: 3.442500342058231

Epoch: 5| Step: 5
Training loss: 4.376428207521611
Validation loss: 3.416040004903852

Epoch: 5| Step: 6
Training loss: 3.680856053463096
Validation loss: 3.417348516534074

Epoch: 5| Step: 7
Training loss: 3.661869914045967
Validation loss: 3.403836478561285

Epoch: 5| Step: 8
Training loss: 4.0427295558771785
Validation loss: 3.3979945207977154

Epoch: 5| Step: 9
Training loss: 3.8469328069488293
Validation loss: 3.403649609395401

Epoch: 5| Step: 10
Training loss: 3.3247110112166847
Validation loss: 3.3823773670890778

Epoch: 9| Step: 0
Training loss: 3.969673229577163
Validation loss: 3.3731394994449553

Epoch: 5| Step: 1
Training loss: 3.735943325266331
Validation loss: 3.3729702281916887

Epoch: 5| Step: 2
Training loss: 4.0738929040359775
Validation loss: 3.3622721681979084

Epoch: 5| Step: 3
Training loss: 3.5673366974931384
Validation loss: 3.3544001914862247

Epoch: 5| Step: 4
Training loss: 2.507173545938359
Validation loss: 3.342212414334761

Epoch: 5| Step: 5
Training loss: 3.1968116134967195
Validation loss: 3.335833204809617

Epoch: 5| Step: 6
Training loss: 3.6165491451266374
Validation loss: 3.3313548466615335

Epoch: 5| Step: 7
Training loss: 3.9171615179757593
Validation loss: 3.3340787889763916

Epoch: 5| Step: 8
Training loss: 3.676742509098298
Validation loss: 3.32665552896913

Epoch: 5| Step: 9
Training loss: 3.6025075603461367
Validation loss: 3.322148745093484

Epoch: 5| Step: 10
Training loss: 3.165632597753176
Validation loss: 3.3065657882576156

Epoch: 10| Step: 0
Training loss: 3.2560507861682586
Validation loss: 3.302387314521733

Epoch: 5| Step: 1
Training loss: 3.9165530627934504
Validation loss: 3.294629441336963

Epoch: 5| Step: 2
Training loss: 3.5557540467276856
Validation loss: 3.2931481969869885

Epoch: 5| Step: 3
Training loss: 3.321619113314401
Validation loss: 3.2869641218530177

Epoch: 5| Step: 4
Training loss: 3.9700541118325963
Validation loss: 3.2898816094302994

Epoch: 5| Step: 5
Training loss: 3.8740895339946944
Validation loss: 3.2911750693244715

Epoch: 5| Step: 6
Training loss: 3.7065376620404806
Validation loss: 3.2817886996340664

Epoch: 5| Step: 7
Training loss: 3.057389023295941
Validation loss: 3.277359899906201

Epoch: 5| Step: 8
Training loss: 3.6114142135831377
Validation loss: 3.27352818451495

Epoch: 5| Step: 9
Training loss: 2.879053658136761
Validation loss: 3.2649803618525324

Epoch: 5| Step: 10
Training loss: 3.524504032820528
Validation loss: 3.2620269993249864

Epoch: 11| Step: 0
Training loss: 4.351744615452533
Validation loss: 3.2570562631142974

Epoch: 5| Step: 1
Training loss: 3.579293272704997
Validation loss: 3.248980129435155

Epoch: 5| Step: 2
Training loss: 2.596861478217184
Validation loss: 3.2451192746777475

Epoch: 5| Step: 3
Training loss: 3.496276782481856
Validation loss: 3.2462433811279334

Epoch: 5| Step: 4
Training loss: 3.2153288798508664
Validation loss: 3.2401555841893686

Epoch: 5| Step: 5
Training loss: 2.923137534822019
Validation loss: 3.232270423050777

Epoch: 5| Step: 6
Training loss: 4.036617992894131
Validation loss: 3.2352573942215086

Epoch: 5| Step: 7
Training loss: 3.447112774364513
Validation loss: 3.232134324623325

Epoch: 5| Step: 8
Training loss: 3.533577885951635
Validation loss: 3.2278962943387874

Epoch: 5| Step: 9
Training loss: 3.815924685344777
Validation loss: 3.223667714878052

Epoch: 5| Step: 10
Training loss: 3.0017707684934956
Validation loss: 3.218936336932771

Epoch: 12| Step: 0
Training loss: 3.1316928146865046
Validation loss: 3.217130250874681

Epoch: 5| Step: 1
Training loss: 3.484284130331352
Validation loss: 3.217539771535272

Epoch: 5| Step: 2
Training loss: 2.873173340711689
Validation loss: 3.214773922324375

Epoch: 5| Step: 3
Training loss: 3.3861856535989943
Validation loss: 3.2267967607264083

Epoch: 5| Step: 4
Training loss: 3.3991304239253575
Validation loss: 3.2100231486669633

Epoch: 5| Step: 5
Training loss: 3.683834775965965
Validation loss: 3.2067483860643313

Epoch: 5| Step: 6
Training loss: 3.676326828782551
Validation loss: 3.2090447580895045

Epoch: 5| Step: 7
Training loss: 4.019946433702069
Validation loss: 3.2080159557048944

Epoch: 5| Step: 8
Training loss: 3.4475169492751663
Validation loss: 3.2060378721473137

Epoch: 5| Step: 9
Training loss: 3.951863566340905
Validation loss: 3.204409838887883

Epoch: 5| Step: 10
Training loss: 2.807708813042961
Validation loss: 3.199979376534177

Epoch: 13| Step: 0
Training loss: 3.2175592979296215
Validation loss: 3.1973165515709088

Epoch: 5| Step: 1
Training loss: 3.211363975251477
Validation loss: 3.1933410557704396

Epoch: 5| Step: 2
Training loss: 4.063655982242666
Validation loss: 3.192457098509965

Epoch: 5| Step: 3
Training loss: 3.5525763981420906
Validation loss: 3.189451975584528

Epoch: 5| Step: 4
Training loss: 3.6551539416581673
Validation loss: 3.1886540333910993

Epoch: 5| Step: 5
Training loss: 3.6932165803140284
Validation loss: 3.184187460937776

Epoch: 5| Step: 6
Training loss: 3.103636386987341
Validation loss: 3.1829450580430847

Epoch: 5| Step: 7
Training loss: 3.7293922029344277
Validation loss: 3.1793484837263506

Epoch: 5| Step: 8
Training loss: 3.5407325559947416
Validation loss: 3.1773398847330605

Epoch: 5| Step: 9
Training loss: 2.7909516419964437
Validation loss: 3.176681902031475

Epoch: 5| Step: 10
Training loss: 3.1976541086241457
Validation loss: 3.1753087750236624

Epoch: 14| Step: 0
Training loss: 3.970571265257098
Validation loss: 3.1784101064318526

Epoch: 5| Step: 1
Training loss: 3.623370363338116
Validation loss: 3.175145390348245

Epoch: 5| Step: 2
Training loss: 3.2081371263891305
Validation loss: 3.1725886453532186

Epoch: 5| Step: 3
Training loss: 3.306980645080717
Validation loss: 3.1651679757926607

Epoch: 5| Step: 4
Training loss: 3.645783269629297
Validation loss: 3.1668011831610365

Epoch: 5| Step: 5
Training loss: 3.8018395890093895
Validation loss: 3.1646918084843985

Epoch: 5| Step: 6
Training loss: 3.4382552270959805
Validation loss: 3.162095632969589

Epoch: 5| Step: 7
Training loss: 3.408864828762849
Validation loss: 3.158319867326956

Epoch: 5| Step: 8
Training loss: 2.8381359311993575
Validation loss: 3.159095372632574

Epoch: 5| Step: 9
Training loss: 2.7557599693878667
Validation loss: 3.161038160678707

Epoch: 5| Step: 10
Training loss: 3.606110256403075
Validation loss: 3.1565426845402005

Epoch: 15| Step: 0
Training loss: 3.2744466823792733
Validation loss: 3.153162915562746

Epoch: 5| Step: 1
Training loss: 3.552792087818072
Validation loss: 3.1507664898557666

Epoch: 5| Step: 2
Training loss: 3.838891905804737
Validation loss: 3.148804052758883

Epoch: 5| Step: 3
Training loss: 3.6352073077205627
Validation loss: 3.15055796647188

Epoch: 5| Step: 4
Training loss: 3.488644981430114
Validation loss: 3.1758838833696235

Epoch: 5| Step: 5
Training loss: 3.718403647826764
Validation loss: 3.159146479558747

Epoch: 5| Step: 6
Training loss: 3.2064641156005145
Validation loss: 3.1438634537477705

Epoch: 5| Step: 7
Training loss: 3.4282548905891805
Validation loss: 3.1538842528751516

Epoch: 5| Step: 8
Training loss: 3.319067436597461
Validation loss: 3.1626820200076886

Epoch: 5| Step: 9
Training loss: 3.1975110984532087
Validation loss: 3.161950142146657

Epoch: 5| Step: 10
Training loss: 2.8051098688813174
Validation loss: 3.1595423585968185

Epoch: 16| Step: 0
Training loss: 3.6623700428062067
Validation loss: 3.15992522190279

Epoch: 5| Step: 1
Training loss: 3.574380572882155
Validation loss: 3.1591754450308884

Epoch: 5| Step: 2
Training loss: 3.4288605755405954
Validation loss: 3.152386209448205

Epoch: 5| Step: 3
Training loss: 3.343053299524905
Validation loss: 3.1485370610168113

Epoch: 5| Step: 4
Training loss: 3.599631894683355
Validation loss: 3.1494026818673575

Epoch: 5| Step: 5
Training loss: 2.8758813916765935
Validation loss: 3.1422693434094935

Epoch: 5| Step: 6
Training loss: 3.504793018754329
Validation loss: 3.139276386280453

Epoch: 5| Step: 7
Training loss: 3.399204912904927
Validation loss: 3.1365258113807144

Epoch: 5| Step: 8
Training loss: 2.734506571192823
Validation loss: 3.1367731424865126

Epoch: 5| Step: 9
Training loss: 3.9312779751557043
Validation loss: 3.1395395274745033

Epoch: 5| Step: 10
Training loss: 3.3807032398684638
Validation loss: 3.1333942766640304

Epoch: 17| Step: 0
Training loss: 3.4203774994537564
Validation loss: 3.1347878063645

Epoch: 5| Step: 1
Training loss: 2.837063988615782
Validation loss: 3.1363396305975573

Epoch: 5| Step: 2
Training loss: 3.1555418220931575
Validation loss: 3.1367440976437497

Epoch: 5| Step: 3
Training loss: 3.309065423737745
Validation loss: 3.134447736201543

Epoch: 5| Step: 4
Training loss: 3.8107832498524443
Validation loss: 3.12874830823713

Epoch: 5| Step: 5
Training loss: 2.6928329783255616
Validation loss: 3.1246431388955926

Epoch: 5| Step: 6
Training loss: 3.685081335280381
Validation loss: 3.1225759148847914

Epoch: 5| Step: 7
Training loss: 3.4248712390169085
Validation loss: 3.1198722115007813

Epoch: 5| Step: 8
Training loss: 3.6804273635004576
Validation loss: 3.1201894999755337

Epoch: 5| Step: 9
Training loss: 3.4977555571656382
Validation loss: 3.1177846405648455

Epoch: 5| Step: 10
Training loss: 3.7444263999899112
Validation loss: 3.116194979136019

Epoch: 18| Step: 0
Training loss: 3.2997481856937596
Validation loss: 3.114748508212259

Epoch: 5| Step: 1
Training loss: 3.6940879809152065
Validation loss: 3.1104126586672844

Epoch: 5| Step: 2
Training loss: 2.970035635994482
Validation loss: 3.109159553967742

Epoch: 5| Step: 3
Training loss: 3.5523474064697615
Validation loss: 3.109753733272845

Epoch: 5| Step: 4
Training loss: 4.111286835451812
Validation loss: 3.108275823323118

Epoch: 5| Step: 5
Training loss: 3.2847936477763224
Validation loss: 3.104888599721

Epoch: 5| Step: 6
Training loss: 3.003238995757282
Validation loss: 3.1078292179461773

Epoch: 5| Step: 7
Training loss: 3.1244648284422025
Validation loss: 3.108194951040205

Epoch: 5| Step: 8
Training loss: 3.0923301444130926
Validation loss: 3.104641193382057

Epoch: 5| Step: 9
Training loss: 3.4153254287730515
Validation loss: 3.101798534620418

Epoch: 5| Step: 10
Training loss: 3.5225395868593457
Validation loss: 3.0982324439625244

Epoch: 19| Step: 0
Training loss: 3.682294889643804
Validation loss: 3.092816734647476

Epoch: 5| Step: 1
Training loss: 3.649666491386857
Validation loss: 3.0933119951779173

Epoch: 5| Step: 2
Training loss: 3.3046773996040977
Validation loss: 3.0954091162370547

Epoch: 5| Step: 3
Training loss: 3.237163576298602
Validation loss: 3.091970185956778

Epoch: 5| Step: 4
Training loss: 2.958611291712999
Validation loss: 3.0966136585636197

Epoch: 5| Step: 5
Training loss: 2.9537110731067715
Validation loss: 3.0989158610226046

Epoch: 5| Step: 6
Training loss: 3.3154286807343833
Validation loss: 3.1792702982801644

Epoch: 5| Step: 7
Training loss: 3.5894346118183473
Validation loss: 3.1595967557519926

Epoch: 5| Step: 8
Training loss: 3.677979933633667
Validation loss: 3.090885576888392

Epoch: 5| Step: 9
Training loss: 3.4270525218811474
Validation loss: 3.0833132315537206

Epoch: 5| Step: 10
Training loss: 3.3158097915855502
Validation loss: 3.105251542771979

Epoch: 20| Step: 0
Training loss: 2.539204942669111
Validation loss: 3.0807153373481855

Epoch: 5| Step: 1
Training loss: 3.6340677697303163
Validation loss: 3.0844681892638706

Epoch: 5| Step: 2
Training loss: 3.705485947384257
Validation loss: 3.083447739979342

Epoch: 5| Step: 3
Training loss: 3.0037325844833314
Validation loss: 3.0830284079843566

Epoch: 5| Step: 4
Training loss: 3.517208573470159
Validation loss: 3.0908222268399346

Epoch: 5| Step: 5
Training loss: 3.9382185507401126
Validation loss: 3.0941052490265872

Epoch: 5| Step: 6
Training loss: 2.7190984743783555
Validation loss: 3.093790136304601

Epoch: 5| Step: 7
Training loss: 3.9405331509418717
Validation loss: 3.0913338140852686

Epoch: 5| Step: 8
Training loss: 3.269078814742323
Validation loss: 3.079456501724648

Epoch: 5| Step: 9
Training loss: 2.844974799019433
Validation loss: 3.0773982740366277

Epoch: 5| Step: 10
Training loss: 3.5903488650602404
Validation loss: 3.0829070449806975

Epoch: 21| Step: 0
Training loss: 3.3829387967185793
Validation loss: 3.089804481750596

Epoch: 5| Step: 1
Training loss: 3.5225328184809563
Validation loss: 3.0911246411661892

Epoch: 5| Step: 2
Training loss: 3.4264390024733986
Validation loss: 3.068908226652905

Epoch: 5| Step: 3
Training loss: 4.063762996656322
Validation loss: 3.0689433282445737

Epoch: 5| Step: 4
Training loss: 3.23624222525749
Validation loss: 3.072688656803991

Epoch: 5| Step: 5
Training loss: 3.2348505674868084
Validation loss: 3.068969686753212

Epoch: 5| Step: 6
Training loss: 2.9342116760366896
Validation loss: 3.069724987298573

Epoch: 5| Step: 7
Training loss: 2.4995754835189192
Validation loss: 3.0715101496146917

Epoch: 5| Step: 8
Training loss: 3.6790546755884503
Validation loss: 3.0575311317556326

Epoch: 5| Step: 9
Training loss: 3.515158117870081
Validation loss: 3.0503652056097432

Epoch: 5| Step: 10
Training loss: 3.097719516565066
Validation loss: 3.04952401781429

Epoch: 22| Step: 0
Training loss: 3.761872127016602
Validation loss: 3.047968001323039

Epoch: 5| Step: 1
Training loss: 2.9144067637630764
Validation loss: 3.0448562804546713

Epoch: 5| Step: 2
Training loss: 3.3195824392694266
Validation loss: 3.0422167343143225

Epoch: 5| Step: 3
Training loss: 3.1744143088487413
Validation loss: 3.0516523192452016

Epoch: 5| Step: 4
Training loss: 3.174847342358028
Validation loss: 3.0854525468414056

Epoch: 5| Step: 5
Training loss: 3.319960631631203
Validation loss: 3.053011556980093

Epoch: 5| Step: 6
Training loss: 3.1870950179788315
Validation loss: 3.026614580201798

Epoch: 5| Step: 7
Training loss: 3.4890715418287175
Validation loss: 3.031832899555225

Epoch: 5| Step: 8
Training loss: 3.8885647017972422
Validation loss: 3.037046524788729

Epoch: 5| Step: 9
Training loss: 3.3380027649481163
Validation loss: 3.029822166027569

Epoch: 5| Step: 10
Training loss: 2.843018825558577
Validation loss: 3.0230449559367853

Epoch: 23| Step: 0
Training loss: 2.997521966467156
Validation loss: 3.0201721712563705

Epoch: 5| Step: 1
Training loss: 3.3119784250432036
Validation loss: 3.030285607324687

Epoch: 5| Step: 2
Training loss: 2.9578851351356175
Validation loss: 3.0283196589592314

Epoch: 5| Step: 3
Training loss: 2.976281340528976
Validation loss: 3.0435460957103793

Epoch: 5| Step: 4
Training loss: 4.126656864218298
Validation loss: 3.0622326883024797

Epoch: 5| Step: 5
Training loss: 3.1642430383485567
Validation loss: 3.0166309278654686

Epoch: 5| Step: 6
Training loss: 3.6452715776994045
Validation loss: 3.027894558372488

Epoch: 5| Step: 7
Training loss: 3.6713808417067106
Validation loss: 3.06548109152168

Epoch: 5| Step: 8
Training loss: 3.2389070023614894
Validation loss: 3.0987102626755156

Epoch: 5| Step: 9
Training loss: 3.175015102560814
Validation loss: 3.0364273692512262

Epoch: 5| Step: 10
Training loss: 3.19440624564363
Validation loss: 3.0048784153190358

Epoch: 24| Step: 0
Training loss: 3.5952901442461465
Validation loss: 3.0404365837564344

Epoch: 5| Step: 1
Training loss: 3.141687469683375
Validation loss: 3.085885205545534

Epoch: 5| Step: 2
Training loss: 3.496236412504741
Validation loss: 3.055722082441003

Epoch: 5| Step: 3
Training loss: 3.1069496702323542
Validation loss: 3.00950691132442

Epoch: 5| Step: 4
Training loss: 2.7667279818837494
Validation loss: 2.9945174986904837

Epoch: 5| Step: 5
Training loss: 3.911512812181292
Validation loss: 2.993792370131085

Epoch: 5| Step: 6
Training loss: 3.590043520012806
Validation loss: 2.9927346312929206

Epoch: 5| Step: 7
Training loss: 2.8350949888109667
Validation loss: 2.9960082177591727

Epoch: 5| Step: 8
Training loss: 2.867234897481618
Validation loss: 2.9958304489673866

Epoch: 5| Step: 9
Training loss: 2.9563353512078545
Validation loss: 2.9998317076537377

Epoch: 5| Step: 10
Training loss: 3.9035965108607846
Validation loss: 2.997034489734227

Epoch: 25| Step: 0
Training loss: 3.151257333652387
Validation loss: 2.994188588301951

Epoch: 5| Step: 1
Training loss: 3.4146990499076826
Validation loss: 2.9945613081598434

Epoch: 5| Step: 2
Training loss: 2.877123007384561
Validation loss: 2.99118747459392

Epoch: 5| Step: 3
Training loss: 3.6526416677459754
Validation loss: 2.985578165066397

Epoch: 5| Step: 4
Training loss: 3.3902075725910805
Validation loss: 2.9806878015550065

Epoch: 5| Step: 5
Training loss: 3.0601241569014572
Validation loss: 2.9782408648251777

Epoch: 5| Step: 6
Training loss: 3.3544923296488327
Validation loss: 2.974496982763503

Epoch: 5| Step: 7
Training loss: 3.4968982303723886
Validation loss: 2.9731025364567705

Epoch: 5| Step: 8
Training loss: 3.0751015002858924
Validation loss: 2.9958531010753275

Epoch: 5| Step: 9
Training loss: 3.208585820026876
Validation loss: 3.001069003211225

Epoch: 5| Step: 10
Training loss: 3.386948803190649
Validation loss: 2.9720724032488315

Epoch: 26| Step: 0
Training loss: 3.479626623271228
Validation loss: 2.9603896931272136

Epoch: 5| Step: 1
Training loss: 3.218392509681582
Validation loss: 2.9639634435389723

Epoch: 5| Step: 2
Training loss: 3.089032053278839
Validation loss: 2.959757613809292

Epoch: 5| Step: 3
Training loss: 3.489645218181828
Validation loss: 2.960938556300924

Epoch: 5| Step: 4
Training loss: 2.7606195531216606
Validation loss: 2.962156644748871

Epoch: 5| Step: 5
Training loss: 2.767310539452545
Validation loss: 2.9617443244688504

Epoch: 5| Step: 6
Training loss: 3.0290327319759744
Validation loss: 2.957491606906555

Epoch: 5| Step: 7
Training loss: 3.2543496588827865
Validation loss: 2.958261117800464

Epoch: 5| Step: 8
Training loss: 3.7058489474759746
Validation loss: 2.957418367584831

Epoch: 5| Step: 9
Training loss: 3.596180765481966
Validation loss: 2.9538145756067635

Epoch: 5| Step: 10
Training loss: 3.3572912096446776
Validation loss: 2.9503360549926976

Epoch: 27| Step: 0
Training loss: 3.1478322396274376
Validation loss: 2.946927033683366

Epoch: 5| Step: 1
Training loss: 2.9527069280272
Validation loss: 2.947746177713936

Epoch: 5| Step: 2
Training loss: 3.20554078346814
Validation loss: 2.9616967792496576

Epoch: 5| Step: 3
Training loss: 3.233466716518965
Validation loss: 2.946311950186823

Epoch: 5| Step: 4
Training loss: 3.0185406282530076
Validation loss: 2.951434812693173

Epoch: 5| Step: 5
Training loss: 2.754579632183961
Validation loss: 2.947468227424773

Epoch: 5| Step: 6
Training loss: 3.2381665401595825
Validation loss: 2.9579740101270167

Epoch: 5| Step: 7
Training loss: 3.6936463678735896
Validation loss: 2.9417203661309004

Epoch: 5| Step: 8
Training loss: 3.7831005265676207
Validation loss: 2.942013598182939

Epoch: 5| Step: 9
Training loss: 3.600940973435282
Validation loss: 2.944167777408628

Epoch: 5| Step: 10
Training loss: 2.865549726755973
Validation loss: 2.9438980408439344

Epoch: 28| Step: 0
Training loss: 3.07518290774332
Validation loss: 2.9416093518534874

Epoch: 5| Step: 1
Training loss: 3.4080748263369482
Validation loss: 2.941794273394955

Epoch: 5| Step: 2
Training loss: 3.251468766716078
Validation loss: 2.940505458061938

Epoch: 5| Step: 3
Training loss: 3.118661020725854
Validation loss: 2.938617569636969

Epoch: 5| Step: 4
Training loss: 3.6258108613330404
Validation loss: 2.9378583607016884

Epoch: 5| Step: 5
Training loss: 3.1316826131298625
Validation loss: 2.938866712118969

Epoch: 5| Step: 6
Training loss: 2.9580203862393706
Validation loss: 2.934235178654947

Epoch: 5| Step: 7
Training loss: 2.514740118929424
Validation loss: 2.9330839512085545

Epoch: 5| Step: 8
Training loss: 3.125759490227466
Validation loss: 2.9370471820898536

Epoch: 5| Step: 9
Training loss: 3.8739679254199584
Validation loss: 2.939879656819004

Epoch: 5| Step: 10
Training loss: 3.377650597615199
Validation loss: 2.936940689966279

Epoch: 29| Step: 0
Training loss: 3.1613364450167762
Validation loss: 2.9491276535245956

Epoch: 5| Step: 1
Training loss: 3.0517429687138997
Validation loss: 2.9645811152108132

Epoch: 5| Step: 2
Training loss: 2.598407837405388
Validation loss: 2.9793521563193783

Epoch: 5| Step: 3
Training loss: 2.910144944137015
Validation loss: 2.956125249647595

Epoch: 5| Step: 4
Training loss: 2.754197125595883
Validation loss: 2.930939119262744

Epoch: 5| Step: 5
Training loss: 3.263056863198719
Validation loss: 2.9273515990806898

Epoch: 5| Step: 6
Training loss: 2.9495689335767183
Validation loss: 2.928174914748854

Epoch: 5| Step: 7
Training loss: 3.2742295501902228
Validation loss: 2.9284616155832075

Epoch: 5| Step: 8
Training loss: 3.7737582052671694
Validation loss: 2.9261217186869612

Epoch: 5| Step: 9
Training loss: 3.840278484458621
Validation loss: 2.941600512990376

Epoch: 5| Step: 10
Training loss: 3.7450281881129737
Validation loss: 2.9355766974906974

Epoch: 30| Step: 0
Training loss: 3.5545348417597737
Validation loss: 2.933355510698684

Epoch: 5| Step: 1
Training loss: 3.1467482055455287
Validation loss: 2.928520254284212

Epoch: 5| Step: 2
Training loss: 3.138790676714751
Validation loss: 2.930272738504971

Epoch: 5| Step: 3
Training loss: 3.400283207037544
Validation loss: 2.9260198887188946

Epoch: 5| Step: 4
Training loss: 3.1780698818352193
Validation loss: 2.92199520951557

Epoch: 5| Step: 5
Training loss: 3.3264969976524292
Validation loss: 2.9219748318897514

Epoch: 5| Step: 6
Training loss: 3.0423735402515666
Validation loss: 2.9190184034993094

Epoch: 5| Step: 7
Training loss: 2.708591996581041
Validation loss: 2.9185105728546255

Epoch: 5| Step: 8
Training loss: 3.350006951851535
Validation loss: 2.9198858704670556

Epoch: 5| Step: 9
Training loss: 2.9756904185587
Validation loss: 2.9282585035599378

Epoch: 5| Step: 10
Training loss: 3.613894452823699
Validation loss: 2.9273953102767574

Epoch: 31| Step: 0
Training loss: 3.3280828768791166
Validation loss: 2.9254955921896215

Epoch: 5| Step: 1
Training loss: 3.304543061402821
Validation loss: 2.9376804285049345

Epoch: 5| Step: 2
Training loss: 3.3222818435909973
Validation loss: 2.9472271831737284

Epoch: 5| Step: 3
Training loss: 2.9873769950283817
Validation loss: 2.9210173847670737

Epoch: 5| Step: 4
Training loss: 2.862697984270347
Validation loss: 2.915463462789495

Epoch: 5| Step: 5
Training loss: 3.3462656130620627
Validation loss: 2.9143076807297073

Epoch: 5| Step: 6
Training loss: 3.2650233540422655
Validation loss: 2.916011705707684

Epoch: 5| Step: 7
Training loss: 3.045905482267823
Validation loss: 2.9148257591354687

Epoch: 5| Step: 8
Training loss: 2.758080834148142
Validation loss: 2.916460958747696

Epoch: 5| Step: 9
Training loss: 3.219766252693643
Validation loss: 2.9152504446211105

Epoch: 5| Step: 10
Training loss: 3.9268384430449745
Validation loss: 2.913959301973622

Epoch: 32| Step: 0
Training loss: 3.0887405991883985
Validation loss: 2.9137224733982596

Epoch: 5| Step: 1
Training loss: 3.318054149257113
Validation loss: 2.913155270855845

Epoch: 5| Step: 2
Training loss: 3.2399993498530737
Validation loss: 2.911733861088553

Epoch: 5| Step: 3
Training loss: 3.3702044855670303
Validation loss: 2.916694907888169

Epoch: 5| Step: 4
Training loss: 3.6227307287099406
Validation loss: 2.9171647597274197

Epoch: 5| Step: 5
Training loss: 3.8496875338891523
Validation loss: 2.910329611636489

Epoch: 5| Step: 6
Training loss: 2.642206203906577
Validation loss: 2.9111387611721886

Epoch: 5| Step: 7
Training loss: 2.894325980090757
Validation loss: 2.9069691250279845

Epoch: 5| Step: 8
Training loss: 2.4292829857573484
Validation loss: 2.906318197995

Epoch: 5| Step: 9
Training loss: 2.9926897628390354
Validation loss: 2.900531544484571

Epoch: 5| Step: 10
Training loss: 3.672534769723312
Validation loss: 2.901585998622012

Epoch: 33| Step: 0
Training loss: 3.0577201131470875
Validation loss: 2.902781616547012

Epoch: 5| Step: 1
Training loss: 3.2085118099623644
Validation loss: 2.9092882382429357

Epoch: 5| Step: 2
Training loss: 3.2658519027219675
Validation loss: 2.903215722439115

Epoch: 5| Step: 3
Training loss: 3.033703784189801
Validation loss: 2.912417385467009

Epoch: 5| Step: 4
Training loss: 2.7729484879186614
Validation loss: 2.9215040486357147

Epoch: 5| Step: 5
Training loss: 2.493526947830499
Validation loss: 2.913602684547897

Epoch: 5| Step: 6
Training loss: 3.829095086946195
Validation loss: 2.9234890395492155

Epoch: 5| Step: 7
Training loss: 3.4869017057050837
Validation loss: 2.9012231469377037

Epoch: 5| Step: 8
Training loss: 3.4592334694240985
Validation loss: 2.892386438842312

Epoch: 5| Step: 9
Training loss: 3.2814142095257557
Validation loss: 2.893230039753466

Epoch: 5| Step: 10
Training loss: 3.1229389260287443
Validation loss: 2.897798323171967

Epoch: 34| Step: 0
Training loss: 2.503271537234752
Validation loss: 2.902422214257245

Epoch: 5| Step: 1
Training loss: 2.307255959216561
Validation loss: 2.9103608790567863

Epoch: 5| Step: 2
Training loss: 3.069255928552726
Validation loss: 2.90324718480004

Epoch: 5| Step: 3
Training loss: 3.281844167046904
Validation loss: 2.901884720916406

Epoch: 5| Step: 4
Training loss: 3.734632028329421
Validation loss: 2.8929312966634906

Epoch: 5| Step: 5
Training loss: 2.8795077602615087
Validation loss: 2.8937747378503307

Epoch: 5| Step: 6
Training loss: 3.6097779152310796
Validation loss: 2.888379058077849

Epoch: 5| Step: 7
Training loss: 2.821811182730458
Validation loss: 2.8867241939325887

Epoch: 5| Step: 8
Training loss: 3.6786633663883963
Validation loss: 2.900629208487444

Epoch: 5| Step: 9
Training loss: 3.4603855218161352
Validation loss: 2.9170336871825207

Epoch: 5| Step: 10
Training loss: 3.5613665199699662
Validation loss: 2.9000289179343515

Epoch: 35| Step: 0
Training loss: 3.0587251715359773
Validation loss: 2.8855848348147948

Epoch: 5| Step: 1
Training loss: 3.517296830134183
Validation loss: 2.885375642793975

Epoch: 5| Step: 2
Training loss: 3.240508819233754
Validation loss: 2.893335589753011

Epoch: 5| Step: 3
Training loss: 3.1994297950077906
Validation loss: 2.8959021097938034

Epoch: 5| Step: 4
Training loss: 3.0535874203013824
Validation loss: 2.9035677194078375

Epoch: 5| Step: 5
Training loss: 3.0298104554871412
Validation loss: 2.9006770122714256

Epoch: 5| Step: 6
Training loss: 3.179550580350212
Validation loss: 2.902820918091078

Epoch: 5| Step: 7
Training loss: 3.502424354144761
Validation loss: 2.896138796066838

Epoch: 5| Step: 8
Training loss: 2.9359509868220695
Validation loss: 2.8921834348159825

Epoch: 5| Step: 9
Training loss: 3.4345099189227435
Validation loss: 2.884991090038906

Epoch: 5| Step: 10
Training loss: 3.029518340701695
Validation loss: 2.8810541754578285

Epoch: 36| Step: 0
Training loss: 3.9959066427359056
Validation loss: 2.881672440316233

Epoch: 5| Step: 1
Training loss: 3.0894114581346734
Validation loss: 2.8774719543478713

Epoch: 5| Step: 2
Training loss: 3.4024701626020852
Validation loss: 2.8772003872008987

Epoch: 5| Step: 3
Training loss: 3.323707478492638
Validation loss: 2.8789792666796754

Epoch: 5| Step: 4
Training loss: 3.201082350553771
Validation loss: 2.8830681446355797

Epoch: 5| Step: 5
Training loss: 2.9406283339056887
Validation loss: 2.8858038680726747

Epoch: 5| Step: 6
Training loss: 2.8301751730254727
Validation loss: 2.8820519777937914

Epoch: 5| Step: 7
Training loss: 2.714979780343146
Validation loss: 2.8840361270757824

Epoch: 5| Step: 8
Training loss: 3.1327700338553375
Validation loss: 2.8816155919908706

Epoch: 5| Step: 9
Training loss: 2.9005193508366114
Validation loss: 2.882587893542614

Epoch: 5| Step: 10
Training loss: 3.295189015085721
Validation loss: 2.869528528557862

Epoch: 37| Step: 0
Training loss: 2.579125967202786
Validation loss: 2.8797206181272474

Epoch: 5| Step: 1
Training loss: 4.030574298385366
Validation loss: 2.8754140957821086

Epoch: 5| Step: 2
Training loss: 3.522923197289987
Validation loss: 2.874227274612168

Epoch: 5| Step: 3
Training loss: 2.6678114658982417
Validation loss: 2.8703345349640683

Epoch: 5| Step: 4
Training loss: 2.968770237903881
Validation loss: 2.8670746513199825

Epoch: 5| Step: 5
Training loss: 2.9655072621970686
Validation loss: 2.8694052088274895

Epoch: 5| Step: 6
Training loss: 3.9668275276926837
Validation loss: 2.8608135637215737

Epoch: 5| Step: 7
Training loss: 2.7835619457568175
Validation loss: 2.8637985655057774

Epoch: 5| Step: 8
Training loss: 3.2796403115463924
Validation loss: 2.8627001604148132

Epoch: 5| Step: 9
Training loss: 2.835690826533119
Validation loss: 2.862661779431563

Epoch: 5| Step: 10
Training loss: 2.9067356155103896
Validation loss: 2.8620725804559446

Epoch: 38| Step: 0
Training loss: 2.9063814195021687
Validation loss: 2.8622108946484595

Epoch: 5| Step: 1
Training loss: 3.5857098409487294
Validation loss: 2.8597216768899463

Epoch: 5| Step: 2
Training loss: 3.228189940044028
Validation loss: 2.859244456775115

Epoch: 5| Step: 3
Training loss: 2.952321099555048
Validation loss: 2.8622131356525626

Epoch: 5| Step: 4
Training loss: 2.963349741177642
Validation loss: 2.864636651192693

Epoch: 5| Step: 5
Training loss: 3.3845827611271297
Validation loss: 2.8731901313618846

Epoch: 5| Step: 6
Training loss: 2.708625269096608
Validation loss: 2.8726011668501927

Epoch: 5| Step: 7
Training loss: 2.652308333192755
Validation loss: 2.87739557703565

Epoch: 5| Step: 8
Training loss: 3.255205533852963
Validation loss: 2.864520451516494

Epoch: 5| Step: 9
Training loss: 3.84444365406457
Validation loss: 2.856070812445312

Epoch: 5| Step: 10
Training loss: 3.2017552866495556
Validation loss: 2.855410629409753

Epoch: 39| Step: 0
Training loss: 2.7673818751542276
Validation loss: 2.870883697623308

Epoch: 5| Step: 1
Training loss: 3.3147877404567287
Validation loss: 2.9019236026111

Epoch: 5| Step: 2
Training loss: 3.890562983865047
Validation loss: 2.890678268691212

Epoch: 5| Step: 3
Training loss: 3.0511143071539983
Validation loss: 2.858810827296472

Epoch: 5| Step: 4
Training loss: 3.0059087103549555
Validation loss: 2.855684585598705

Epoch: 5| Step: 5
Training loss: 2.7563908616659196
Validation loss: 2.8548624388103305

Epoch: 5| Step: 6
Training loss: 3.3513886377726476
Validation loss: 2.8510160368980606

Epoch: 5| Step: 7
Training loss: 2.896538701129946
Validation loss: 2.850795365872581

Epoch: 5| Step: 8
Training loss: 2.887961650456397
Validation loss: 2.853288370914243

Epoch: 5| Step: 9
Training loss: 3.785639713303477
Validation loss: 2.854868216478261

Epoch: 5| Step: 10
Training loss: 2.9612339646375045
Validation loss: 2.87499897900207

Epoch: 40| Step: 0
Training loss: 2.6079773043423136
Validation loss: 2.8655857618074436

Epoch: 5| Step: 1
Training loss: 3.0841502748383784
Validation loss: 2.8635039329463625

Epoch: 5| Step: 2
Training loss: 2.8064602745475526
Validation loss: 2.872828080062896

Epoch: 5| Step: 3
Training loss: 3.713644802949408
Validation loss: 2.894417857171725

Epoch: 5| Step: 4
Training loss: 2.5022230754603907
Validation loss: 2.8841474801156854

Epoch: 5| Step: 5
Training loss: 3.1153161112905705
Validation loss: 2.8602773918034403

Epoch: 5| Step: 6
Training loss: 3.537241351373787
Validation loss: 2.8464600690899347

Epoch: 5| Step: 7
Training loss: 3.1945793971059886
Validation loss: 2.844524566989252

Epoch: 5| Step: 8
Training loss: 3.649758469415586
Validation loss: 2.840791810017224

Epoch: 5| Step: 9
Training loss: 3.080621162299167
Validation loss: 2.840705952501134

Epoch: 5| Step: 10
Training loss: 3.1918348867309585
Validation loss: 2.842677651071723

Epoch: 41| Step: 0
Training loss: 3.171220834107003
Validation loss: 2.8419655194493156

Epoch: 5| Step: 1
Training loss: 3.0104442625969883
Validation loss: 2.841953323490031

Epoch: 5| Step: 2
Training loss: 3.30874680274316
Validation loss: 2.839545476251503

Epoch: 5| Step: 3
Training loss: 3.4741279221318173
Validation loss: 2.8409041668354216

Epoch: 5| Step: 4
Training loss: 3.238282722500419
Validation loss: 2.836432599267245

Epoch: 5| Step: 5
Training loss: 3.2597068200769903
Validation loss: 2.840142873405187

Epoch: 5| Step: 6
Training loss: 2.539494686024261
Validation loss: 2.836390975981423

Epoch: 5| Step: 7
Training loss: 3.790513726194865
Validation loss: 2.8432699936750763

Epoch: 5| Step: 8
Training loss: 3.0606643469199355
Validation loss: 2.8516709317617464

Epoch: 5| Step: 9
Training loss: 2.2995618817554053
Validation loss: 2.860446873601339

Epoch: 5| Step: 10
Training loss: 3.3156685699562765
Validation loss: 2.8715726907075814

Epoch: 42| Step: 0
Training loss: 3.187942474171692
Validation loss: 2.8732432454901593

Epoch: 5| Step: 1
Training loss: 3.34968482285656
Validation loss: 2.8951700173420503

Epoch: 5| Step: 2
Training loss: 3.241185780399131
Validation loss: 2.8592821932459476

Epoch: 5| Step: 3
Training loss: 3.168545483491918
Validation loss: 2.8401706765389965

Epoch: 5| Step: 4
Training loss: 3.1382089307874206
Validation loss: 2.829822363379418

Epoch: 5| Step: 5
Training loss: 3.2308207715642774
Validation loss: 2.829094594061317

Epoch: 5| Step: 6
Training loss: 3.0676343268819304
Validation loss: 2.8344837949900903

Epoch: 5| Step: 7
Training loss: 3.257706674736921
Validation loss: 2.8386634284994248

Epoch: 5| Step: 8
Training loss: 3.7686838729396333
Validation loss: 2.8319674088153284

Epoch: 5| Step: 9
Training loss: 2.6775318962355774
Validation loss: 2.8308958599273133

Epoch: 5| Step: 10
Training loss: 2.409933763124054
Validation loss: 2.828270323246766

Epoch: 43| Step: 0
Training loss: 2.917668379474098
Validation loss: 2.833186472127385

Epoch: 5| Step: 1
Training loss: 2.8398667535283075
Validation loss: 2.834955144581137

Epoch: 5| Step: 2
Training loss: 3.7132319695308422
Validation loss: 2.8405642130644817

Epoch: 5| Step: 3
Training loss: 3.4932792714961325
Validation loss: 2.8363036746416004

Epoch: 5| Step: 4
Training loss: 3.4723589569295745
Validation loss: 2.8290440619463975

Epoch: 5| Step: 5
Training loss: 2.1591364020706476
Validation loss: 2.827627066220582

Epoch: 5| Step: 6
Training loss: 3.4058129266423576
Validation loss: 2.827652533631761

Epoch: 5| Step: 7
Training loss: 3.43746754024092
Validation loss: 2.8295330901741886

Epoch: 5| Step: 8
Training loss: 2.895181394965334
Validation loss: 2.826627262327047

Epoch: 5| Step: 9
Training loss: 2.9696772683244435
Validation loss: 2.8323510072848292

Epoch: 5| Step: 10
Training loss: 2.967098378976899
Validation loss: 2.8315531058912375

Epoch: 44| Step: 0
Training loss: 3.0458574209726303
Validation loss: 2.833730681230697

Epoch: 5| Step: 1
Training loss: 3.3564265597199436
Validation loss: 2.821458166775306

Epoch: 5| Step: 2
Training loss: 2.6637326928538214
Validation loss: 2.8227727255676274

Epoch: 5| Step: 3
Training loss: 3.095932162022169
Validation loss: 2.820549290576727

Epoch: 5| Step: 4
Training loss: 3.62734422850087
Validation loss: 2.8201801967917546

Epoch: 5| Step: 5
Training loss: 3.4621937970991565
Validation loss: 2.8210219515045907

Epoch: 5| Step: 6
Training loss: 3.0535630598089
Validation loss: 2.8185398618014736

Epoch: 5| Step: 7
Training loss: 3.041167719081119
Validation loss: 2.816981836186695

Epoch: 5| Step: 8
Training loss: 2.893089439847653
Validation loss: 2.819773021826841

Epoch: 5| Step: 9
Training loss: 3.105292779507266
Validation loss: 2.818296045521304

Epoch: 5| Step: 10
Training loss: 3.0154263920188127
Validation loss: 2.8214405394419377

Epoch: 45| Step: 0
Training loss: 3.725968735453657
Validation loss: 2.826913150993521

Epoch: 5| Step: 1
Training loss: 3.3611174566736213
Validation loss: 2.834449353435447

Epoch: 5| Step: 2
Training loss: 3.7444233436882923
Validation loss: 2.8335506897519736

Epoch: 5| Step: 3
Training loss: 3.089500205597297
Validation loss: 2.8238865523049417

Epoch: 5| Step: 4
Training loss: 2.9505256637080293
Validation loss: 2.8179317749173696

Epoch: 5| Step: 5
Training loss: 2.5451334984620937
Validation loss: 2.813213277994839

Epoch: 5| Step: 6
Training loss: 3.4434984063324414
Validation loss: 2.812402221730139

Epoch: 5| Step: 7
Training loss: 3.4593837169340973
Validation loss: 2.8106788335704636

Epoch: 5| Step: 8
Training loss: 2.704183382316694
Validation loss: 2.815752201376277

Epoch: 5| Step: 9
Training loss: 2.581103090257462
Validation loss: 2.8132072771730305

Epoch: 5| Step: 10
Training loss: 2.3902453950171894
Validation loss: 2.8110179610505406

Epoch: 46| Step: 0
Training loss: 3.025796448078198
Validation loss: 2.8118932965183503

Epoch: 5| Step: 1
Training loss: 2.788415229979476
Validation loss: 2.8137185049303115

Epoch: 5| Step: 2
Training loss: 2.9122772066094957
Validation loss: 2.81348613555387

Epoch: 5| Step: 3
Training loss: 2.755698282466137
Validation loss: 2.811351987555575

Epoch: 5| Step: 4
Training loss: 2.667290664224144
Validation loss: 2.8169235699452893

Epoch: 5| Step: 5
Training loss: 2.6459139613884948
Validation loss: 2.8154660007241135

Epoch: 5| Step: 6
Training loss: 3.1132405085751724
Validation loss: 2.817258774448275

Epoch: 5| Step: 7
Training loss: 3.5484208422815335
Validation loss: 2.824109567406132

Epoch: 5| Step: 8
Training loss: 3.776106433532201
Validation loss: 2.824939633340738

Epoch: 5| Step: 9
Training loss: 3.0488960019069746
Validation loss: 2.8139669040711115

Epoch: 5| Step: 10
Training loss: 3.811302247056826
Validation loss: 2.815447594676524

Epoch: 47| Step: 0
Training loss: 3.1616788197553447
Validation loss: 2.8137424436460745

Epoch: 5| Step: 1
Training loss: 2.7469315315826277
Validation loss: 2.8093201284155414

Epoch: 5| Step: 2
Training loss: 2.909159526774302
Validation loss: 2.8025609365827195

Epoch: 5| Step: 3
Training loss: 2.8882041898172015
Validation loss: 2.803993830571383

Epoch: 5| Step: 4
Training loss: 2.9664654424195365
Validation loss: 2.8003560173892503

Epoch: 5| Step: 5
Training loss: 3.142538066867128
Validation loss: 2.7991681139855418

Epoch: 5| Step: 6
Training loss: 2.7571559048731458
Validation loss: 2.799078448215123

Epoch: 5| Step: 7
Training loss: 3.3703879880696985
Validation loss: 2.7961896463517744

Epoch: 5| Step: 8
Training loss: 3.142246871379746
Validation loss: 2.7963977740454307

Epoch: 5| Step: 9
Training loss: 3.8780493274717007
Validation loss: 2.7940893617843687

Epoch: 5| Step: 10
Training loss: 3.1834113133118187
Validation loss: 2.8063272497674894

Epoch: 48| Step: 0
Training loss: 3.0527573363159988
Validation loss: 2.7936693002081285

Epoch: 5| Step: 1
Training loss: 2.6455785573608894
Validation loss: 2.792701054480064

Epoch: 5| Step: 2
Training loss: 3.39458252195348
Validation loss: 2.79431996794836

Epoch: 5| Step: 3
Training loss: 3.1265904766091213
Validation loss: 2.7931315735944753

Epoch: 5| Step: 4
Training loss: 2.626188463291727
Validation loss: 2.7899121823138837

Epoch: 5| Step: 5
Training loss: 3.341368923732437
Validation loss: 2.791864015022498

Epoch: 5| Step: 6
Training loss: 3.2777458735348306
Validation loss: 2.790839853536302

Epoch: 5| Step: 7
Training loss: 3.3836051593694734
Validation loss: 2.7965379352484034

Epoch: 5| Step: 8
Training loss: 2.40113554555164
Validation loss: 2.7904119630486903

Epoch: 5| Step: 9
Training loss: 3.0749676772488987
Validation loss: 2.794725572131388

Epoch: 5| Step: 10
Training loss: 3.7685686058307373
Validation loss: 2.807822177788636

Epoch: 49| Step: 0
Training loss: 2.845271615201266
Validation loss: 2.808728528514555

Epoch: 5| Step: 1
Training loss: 2.872125266443401
Validation loss: 2.7926364922779108

Epoch: 5| Step: 2
Training loss: 3.2395525048721976
Validation loss: 2.7887614700043923

Epoch: 5| Step: 3
Training loss: 2.9090393790644624
Validation loss: 2.7895974158464054

Epoch: 5| Step: 4
Training loss: 3.0730248038882633
Validation loss: 2.788418699754578

Epoch: 5| Step: 5
Training loss: 3.179134836366695
Validation loss: 2.788811467122657

Epoch: 5| Step: 6
Training loss: 2.8470686108676397
Validation loss: 2.793694184303572

Epoch: 5| Step: 7
Training loss: 3.3570381020664013
Validation loss: 2.7914458493462737

Epoch: 5| Step: 8
Training loss: 2.5671220358954843
Validation loss: 2.792696865739213

Epoch: 5| Step: 9
Training loss: 3.6946800287483006
Validation loss: 2.800376990717875

Epoch: 5| Step: 10
Training loss: 3.5436733769066904
Validation loss: 2.784635549140306

Epoch: 50| Step: 0
Training loss: 3.1412695987088504
Validation loss: 2.78034599888942

Epoch: 5| Step: 1
Training loss: 3.239690568300084
Validation loss: 2.7798839807945073

Epoch: 5| Step: 2
Training loss: 2.907794009011012
Validation loss: 2.7870079252191284

Epoch: 5| Step: 3
Training loss: 2.5685879101626807
Validation loss: 2.781333626198158

Epoch: 5| Step: 4
Training loss: 3.0014527300293414
Validation loss: 2.783295964130231

Epoch: 5| Step: 5
Training loss: 3.50332565345491
Validation loss: 2.7859566657954344

Epoch: 5| Step: 6
Training loss: 3.0018749735679524
Validation loss: 2.7844442101034286

Epoch: 5| Step: 7
Training loss: 2.591811041372833
Validation loss: 2.7831958537356676

Epoch: 5| Step: 8
Training loss: 3.7843227039506977
Validation loss: 2.784906048836541

Epoch: 5| Step: 9
Training loss: 3.0618550146898604
Validation loss: 2.781088917127716

Epoch: 5| Step: 10
Training loss: 3.1274165156235303
Validation loss: 2.78156342998058

Epoch: 51| Step: 0
Training loss: 3.3275426793961826
Validation loss: 2.775954659207097

Epoch: 5| Step: 1
Training loss: 3.3070709074739457
Validation loss: 2.7749621787353576

Epoch: 5| Step: 2
Training loss: 3.3057357532384914
Validation loss: 2.7759623096093433

Epoch: 5| Step: 3
Training loss: 2.7955327569321318
Validation loss: 2.7826414279013787

Epoch: 5| Step: 4
Training loss: 2.186016778823942
Validation loss: 2.7799485920171843

Epoch: 5| Step: 5
Training loss: 2.8008765892071628
Validation loss: 2.770856549257261

Epoch: 5| Step: 6
Training loss: 3.399571442241766
Validation loss: 2.7676221355825046

Epoch: 5| Step: 7
Training loss: 2.8499625956439893
Validation loss: 2.7695027765926987

Epoch: 5| Step: 8
Training loss: 3.209241878790764
Validation loss: 2.769579106140186

Epoch: 5| Step: 9
Training loss: 3.136310555583106
Validation loss: 2.768371278020317

Epoch: 5| Step: 10
Training loss: 3.478765651107051
Validation loss: 2.768846735232802

Epoch: 52| Step: 0
Training loss: 3.877455763819675
Validation loss: 2.7695590714574845

Epoch: 5| Step: 1
Training loss: 2.993278762586157
Validation loss: 2.766173355470692

Epoch: 5| Step: 2
Training loss: 2.4777270927244
Validation loss: 2.7671489554910074

Epoch: 5| Step: 3
Training loss: 3.082952286827749
Validation loss: 2.7718070317319334

Epoch: 5| Step: 4
Training loss: 3.1142365295505905
Validation loss: 2.763578305192652

Epoch: 5| Step: 5
Training loss: 2.6241241083684677
Validation loss: 2.7654025395808377

Epoch: 5| Step: 6
Training loss: 3.4159673269705997
Validation loss: 2.761420467277994

Epoch: 5| Step: 7
Training loss: 3.0984684575660504
Validation loss: 2.762478468267276

Epoch: 5| Step: 8
Training loss: 3.192303796293835
Validation loss: 2.764211105185891

Epoch: 5| Step: 9
Training loss: 2.876683281430223
Validation loss: 2.7616824754723948

Epoch: 5| Step: 10
Training loss: 2.9512557315084083
Validation loss: 2.7660676242662667

Epoch: 53| Step: 0
Training loss: 2.9498062458096097
Validation loss: 2.7704182583085553

Epoch: 5| Step: 1
Training loss: 2.9093730922409997
Validation loss: 2.776641013277545

Epoch: 5| Step: 2
Training loss: 2.7092099360571185
Validation loss: 2.76229587205927

Epoch: 5| Step: 3
Training loss: 3.2492479774754677
Validation loss: 2.756835268886458

Epoch: 5| Step: 4
Training loss: 2.838005047858859
Validation loss: 2.7538254029476525

Epoch: 5| Step: 5
Training loss: 3.406664481887067
Validation loss: 2.751960105255131

Epoch: 5| Step: 6
Training loss: 3.4452697336046825
Validation loss: 2.7542567248643337

Epoch: 5| Step: 7
Training loss: 2.9842645914315913
Validation loss: 2.7591661298035026

Epoch: 5| Step: 8
Training loss: 3.2987054019412505
Validation loss: 2.7596254508450118

Epoch: 5| Step: 9
Training loss: 2.956902726679792
Validation loss: 2.749156615621815

Epoch: 5| Step: 10
Training loss: 3.0713493013766597
Validation loss: 2.7545247781081756

Epoch: 54| Step: 0
Training loss: 3.078264262345819
Validation loss: 2.7556571980185285

Epoch: 5| Step: 1
Training loss: 3.434927098862436
Validation loss: 2.7545196378384076

Epoch: 5| Step: 2
Training loss: 3.24405096344715
Validation loss: 2.7567931514860207

Epoch: 5| Step: 3
Training loss: 2.895548159236184
Validation loss: 2.756965615703952

Epoch: 5| Step: 4
Training loss: 3.5042325721618144
Validation loss: 2.7543874077792143

Epoch: 5| Step: 5
Training loss: 2.520045690727792
Validation loss: 2.750193136971084

Epoch: 5| Step: 6
Training loss: 3.1573265430349498
Validation loss: 2.7498423222581745

Epoch: 5| Step: 7
Training loss: 3.375206552472098
Validation loss: 2.748615202421854

Epoch: 5| Step: 8
Training loss: 2.9643753747298414
Validation loss: 2.7470797586091074

Epoch: 5| Step: 9
Training loss: 2.4322886388679517
Validation loss: 2.7517008495097657

Epoch: 5| Step: 10
Training loss: 3.0417420016500496
Validation loss: 2.7580399088171714

Epoch: 55| Step: 0
Training loss: 3.386899386717815
Validation loss: 2.7575665635921545

Epoch: 5| Step: 1
Training loss: 2.7176521101477964
Validation loss: 2.756531096142395

Epoch: 5| Step: 2
Training loss: 3.2423369223851055
Validation loss: 2.756068872560981

Epoch: 5| Step: 3
Training loss: 2.5207248906121453
Validation loss: 2.749794000496523

Epoch: 5| Step: 4
Training loss: 3.0775562671069836
Validation loss: 2.7454428076253157

Epoch: 5| Step: 5
Training loss: 2.9788053778120243
Validation loss: 2.7454368753121354

Epoch: 5| Step: 6
Training loss: 2.639126233810088
Validation loss: 2.7436155112602942

Epoch: 5| Step: 7
Training loss: 3.3007721488872312
Validation loss: 2.7460391418547547

Epoch: 5| Step: 8
Training loss: 3.1183266147831348
Validation loss: 2.7429072699847

Epoch: 5| Step: 9
Training loss: 3.6068193379616806
Validation loss: 2.743026909229266

Epoch: 5| Step: 10
Training loss: 2.9473170736687386
Validation loss: 2.7417335757424977

Epoch: 56| Step: 0
Training loss: 2.8050995845422704
Validation loss: 2.745341611046421

Epoch: 5| Step: 1
Training loss: 2.8573923376698747
Validation loss: 2.741955561084821

Epoch: 5| Step: 2
Training loss: 3.2649792484482734
Validation loss: 2.7454109253765893

Epoch: 5| Step: 3
Training loss: 3.3450667025953327
Validation loss: 2.740112611650985

Epoch: 5| Step: 4
Training loss: 3.017687156707407
Validation loss: 2.7387087201889897

Epoch: 5| Step: 5
Training loss: 2.9486102758585995
Validation loss: 2.737503338920987

Epoch: 5| Step: 6
Training loss: 2.692572751988283
Validation loss: 2.7383356187119965

Epoch: 5| Step: 7
Training loss: 3.3047336728452867
Validation loss: 2.7401319316571286

Epoch: 5| Step: 8
Training loss: 3.459991394649675
Validation loss: 2.7388652117809564

Epoch: 5| Step: 9
Training loss: 2.9276791618897344
Validation loss: 2.754355431745263

Epoch: 5| Step: 10
Training loss: 2.973036392107225
Validation loss: 2.7620071506772863

Epoch: 57| Step: 0
Training loss: 2.8115102085916632
Validation loss: 2.7582044987793375

Epoch: 5| Step: 1
Training loss: 3.336934925490824
Validation loss: 2.7373368168204575

Epoch: 5| Step: 2
Training loss: 3.1046588345391246
Validation loss: 2.7346014057423904

Epoch: 5| Step: 3
Training loss: 3.449564206891685
Validation loss: 2.7318731935733074

Epoch: 5| Step: 4
Training loss: 3.1621633599275296
Validation loss: 2.735768687793314

Epoch: 5| Step: 5
Training loss: 2.7053805956797405
Validation loss: 2.7327188284149715

Epoch: 5| Step: 6
Training loss: 2.7263919809792125
Validation loss: 2.7350369038167104

Epoch: 5| Step: 7
Training loss: 3.4050388807858107
Validation loss: 2.7342581100207752

Epoch: 5| Step: 8
Training loss: 3.2975364853096383
Validation loss: 2.731479319336047

Epoch: 5| Step: 9
Training loss: 2.75363214089068
Validation loss: 2.7279360327043274

Epoch: 5| Step: 10
Training loss: 2.801710753978058
Validation loss: 2.730931254916724

Epoch: 58| Step: 0
Training loss: 3.4023335190629043
Validation loss: 2.730755798348048

Epoch: 5| Step: 1
Training loss: 2.901039785570577
Validation loss: 2.7313864544164597

Epoch: 5| Step: 2
Training loss: 2.9913736934887756
Validation loss: 2.7410181955085404

Epoch: 5| Step: 3
Training loss: 2.3691090253843776
Validation loss: 2.7614551141090176

Epoch: 5| Step: 4
Training loss: 3.1617875574541183
Validation loss: 2.765420835595066

Epoch: 5| Step: 5
Training loss: 2.5753915803810035
Validation loss: 2.7563171060076885

Epoch: 5| Step: 6
Training loss: 3.04441366303871
Validation loss: 2.753005243622331

Epoch: 5| Step: 7
Training loss: 3.008323566565329
Validation loss: 2.741008757503994

Epoch: 5| Step: 8
Training loss: 2.8354511947454153
Validation loss: 2.7268230204348853

Epoch: 5| Step: 9
Training loss: 3.4087024224615177
Validation loss: 2.7235110750252733

Epoch: 5| Step: 10
Training loss: 3.8008665602578997
Validation loss: 2.7331310230610657

Epoch: 59| Step: 0
Training loss: 2.9038642196754028
Validation loss: 2.7391804676880067

Epoch: 5| Step: 1
Training loss: 2.890959519283982
Validation loss: 2.729110005784771

Epoch: 5| Step: 2
Training loss: 2.7967305918659746
Validation loss: 2.7220059969510193

Epoch: 5| Step: 3
Training loss: 3.0976890379431983
Validation loss: 2.721716128770212

Epoch: 5| Step: 4
Training loss: 3.4475143213230512
Validation loss: 2.7331249317684425

Epoch: 5| Step: 5
Training loss: 3.6023642088309735
Validation loss: 2.771796540586472

Epoch: 5| Step: 6
Training loss: 2.233354989226758
Validation loss: 2.791587111861345

Epoch: 5| Step: 7
Training loss: 3.3998032905670854
Validation loss: 2.835312867219692

Epoch: 5| Step: 8
Training loss: 2.4871396211055474
Validation loss: 2.8754488258943285

Epoch: 5| Step: 9
Training loss: 3.651251481685057
Validation loss: 2.8079862746457858

Epoch: 5| Step: 10
Training loss: 3.107624270347343
Validation loss: 2.761341648759977

Epoch: 60| Step: 0
Training loss: 3.4018132423571497
Validation loss: 2.715722812330861

Epoch: 5| Step: 1
Training loss: 2.694210014981735
Validation loss: 2.7254426283409208

Epoch: 5| Step: 2
Training loss: 3.5620135594259295
Validation loss: 2.748174952973716

Epoch: 5| Step: 3
Training loss: 2.717132437939442
Validation loss: 2.7658553359236193

Epoch: 5| Step: 4
Training loss: 3.418911281875053
Validation loss: 2.7925072458861573

Epoch: 5| Step: 5
Training loss: 2.9498322713982104
Validation loss: 2.7601177206164778

Epoch: 5| Step: 6
Training loss: 2.602842273905976
Validation loss: 2.7332569833347162

Epoch: 5| Step: 7
Training loss: 3.4701433562202766
Validation loss: 2.7254971929607845

Epoch: 5| Step: 8
Training loss: 2.7824412162994325
Validation loss: 2.726556987329654

Epoch: 5| Step: 9
Training loss: 2.902322391724071
Validation loss: 2.7336368812676834

Epoch: 5| Step: 10
Training loss: 3.101435814871804
Validation loss: 2.753966000782276

Epoch: 61| Step: 0
Training loss: 2.9727605132216297
Validation loss: 2.755079454854037

Epoch: 5| Step: 1
Training loss: 3.254152872509768
Validation loss: 2.7299033846341487

Epoch: 5| Step: 2
Training loss: 3.5726182699947926
Validation loss: 2.7383298722860934

Epoch: 5| Step: 3
Training loss: 2.9654763894987943
Validation loss: 2.7279938356497513

Epoch: 5| Step: 4
Training loss: 3.202300472669725
Validation loss: 2.7361449248623457

Epoch: 5| Step: 5
Training loss: 2.7078362130933433
Validation loss: 2.751802420579293

Epoch: 5| Step: 6
Training loss: 3.2436825901443362
Validation loss: 2.7253736565113327

Epoch: 5| Step: 7
Training loss: 3.0223192616229753
Validation loss: 2.7118704108134084

Epoch: 5| Step: 8
Training loss: 2.4763009206975255
Validation loss: 2.7126345853277574

Epoch: 5| Step: 9
Training loss: 2.902209683141774
Validation loss: 2.7156789046770173

Epoch: 5| Step: 10
Training loss: 3.220254638981267
Validation loss: 2.720387788806839

Epoch: 62| Step: 0
Training loss: 3.8540668508990255
Validation loss: 2.722329683242777

Epoch: 5| Step: 1
Training loss: 3.1877071836867676
Validation loss: 2.7331492865396974

Epoch: 5| Step: 2
Training loss: 3.1183556683907883
Validation loss: 2.7228095336519327

Epoch: 5| Step: 3
Training loss: 3.0534093968385814
Validation loss: 2.71784762130185

Epoch: 5| Step: 4
Training loss: 3.310012026992568
Validation loss: 2.714355198157925

Epoch: 5| Step: 5
Training loss: 2.7352630045241457
Validation loss: 2.7095455227243024

Epoch: 5| Step: 6
Training loss: 2.493385433614856
Validation loss: 2.723362744716862

Epoch: 5| Step: 7
Training loss: 3.308876214698764
Validation loss: 2.765040146760746

Epoch: 5| Step: 8
Training loss: 2.7654051612506225
Validation loss: 2.7233702755156024

Epoch: 5| Step: 9
Training loss: 2.752189977997121
Validation loss: 2.7050231646065526

Epoch: 5| Step: 10
Training loss: 3.012072115699719
Validation loss: 2.7027766363460093

Epoch: 63| Step: 0
Training loss: 3.535504504168963
Validation loss: 2.702488474505847

Epoch: 5| Step: 1
Training loss: 3.236811360648598
Validation loss: 2.7062775537603407

Epoch: 5| Step: 2
Training loss: 2.7626360242677257
Validation loss: 2.706592645679664

Epoch: 5| Step: 3
Training loss: 2.8033096201646313
Validation loss: 2.7053197092773056

Epoch: 5| Step: 4
Training loss: 2.1382563496520692
Validation loss: 2.70598584488535

Epoch: 5| Step: 5
Training loss: 3.2805830504747187
Validation loss: 2.7056691563406656

Epoch: 5| Step: 6
Training loss: 2.8388876794496047
Validation loss: 2.70396794108582

Epoch: 5| Step: 7
Training loss: 2.9594761606588103
Validation loss: 2.7038909416849686

Epoch: 5| Step: 8
Training loss: 3.2959418399920017
Validation loss: 2.7011092384863398

Epoch: 5| Step: 9
Training loss: 2.9163635823040743
Validation loss: 2.702674936847163

Epoch: 5| Step: 10
Training loss: 3.579551179339082
Validation loss: 2.699143097752278

Epoch: 64| Step: 0
Training loss: 2.6769953514118607
Validation loss: 2.7021914350760152

Epoch: 5| Step: 1
Training loss: 2.8171790302168334
Validation loss: 2.7009307725490688

Epoch: 5| Step: 2
Training loss: 3.48835110140554
Validation loss: 2.7044450869081875

Epoch: 5| Step: 3
Training loss: 3.3473689379971057
Validation loss: 2.703317823473145

Epoch: 5| Step: 4
Training loss: 2.8737511617650706
Validation loss: 2.7026380709364726

Epoch: 5| Step: 5
Training loss: 2.9957010939428668
Validation loss: 2.7028928343211307

Epoch: 5| Step: 6
Training loss: 3.0592306942752616
Validation loss: 2.701616042344546

Epoch: 5| Step: 7
Training loss: 2.9155786573973104
Validation loss: 2.7025431639211193

Epoch: 5| Step: 8
Training loss: 3.0591332750222153
Validation loss: 2.705038560016965

Epoch: 5| Step: 9
Training loss: 3.0290377694838937
Validation loss: 2.7028057007729127

Epoch: 5| Step: 10
Training loss: 3.060476452005676
Validation loss: 2.7176517752659044

Epoch: 65| Step: 0
Training loss: 3.1983710016997966
Validation loss: 2.7177882319746733

Epoch: 5| Step: 1
Training loss: 2.999780964802596
Validation loss: 2.7129556543004596

Epoch: 5| Step: 2
Training loss: 2.9009367252091165
Validation loss: 2.6955546951087426

Epoch: 5| Step: 3
Training loss: 2.9334149464900148
Validation loss: 2.70223103557888

Epoch: 5| Step: 4
Training loss: 3.042429649774687
Validation loss: 2.704910865352174

Epoch: 5| Step: 5
Training loss: 3.3967993986670977
Validation loss: 2.711274842415987

Epoch: 5| Step: 6
Training loss: 1.7895024187701054
Validation loss: 2.716144828445009

Epoch: 5| Step: 7
Training loss: 3.2473935165743706
Validation loss: 2.720763416507244

Epoch: 5| Step: 8
Training loss: 3.093909981954942
Validation loss: 2.71892928533156

Epoch: 5| Step: 9
Training loss: 3.0372469070548185
Validation loss: 2.720474705064458

Epoch: 5| Step: 10
Training loss: 3.5867478861588173
Validation loss: 2.7242678324077025

Epoch: 66| Step: 0
Training loss: 2.82159175021526
Validation loss: 2.722686520241058

Epoch: 5| Step: 1
Training loss: 3.1462403764604074
Validation loss: 2.723930350429536

Epoch: 5| Step: 2
Training loss: 2.7700412641130305
Validation loss: 2.7275790939036013

Epoch: 5| Step: 3
Training loss: 3.101627839214551
Validation loss: 2.740451613542947

Epoch: 5| Step: 4
Training loss: 3.4632158551624013
Validation loss: 2.7514694441958625

Epoch: 5| Step: 5
Training loss: 3.0865267806628576
Validation loss: 2.728241456868545

Epoch: 5| Step: 6
Training loss: 3.5169883966544657
Validation loss: 2.716498993632017

Epoch: 5| Step: 7
Training loss: 3.174845239667188
Validation loss: 2.7082880443891355

Epoch: 5| Step: 8
Training loss: 2.771866732373213
Validation loss: 2.7089930085146356

Epoch: 5| Step: 9
Training loss: 2.951652199960844
Validation loss: 2.7014304729903493

Epoch: 5| Step: 10
Training loss: 2.46162622895944
Validation loss: 2.6984301080214217

Epoch: 67| Step: 0
Training loss: 3.3515418703382434
Validation loss: 2.696707637342333

Epoch: 5| Step: 1
Training loss: 3.299821594502041
Validation loss: 2.6982528202170917

Epoch: 5| Step: 2
Training loss: 3.372293022483691
Validation loss: 2.6972229652072435

Epoch: 5| Step: 3
Training loss: 2.591485563208178
Validation loss: 2.7009519821289216

Epoch: 5| Step: 4
Training loss: 2.7214799526414657
Validation loss: 2.6955211195448046

Epoch: 5| Step: 5
Training loss: 2.6823921456390076
Validation loss: 2.698664585110696

Epoch: 5| Step: 6
Training loss: 3.3241576425604085
Validation loss: 2.6997961615683113

Epoch: 5| Step: 7
Training loss: 2.82371193544789
Validation loss: 2.7001256672711773

Epoch: 5| Step: 8
Training loss: 3.563578124623195
Validation loss: 2.707861956017097

Epoch: 5| Step: 9
Training loss: 2.84286854256277
Validation loss: 2.7026665762547726

Epoch: 5| Step: 10
Training loss: 2.584155987427694
Validation loss: 2.694524104761196

Epoch: 68| Step: 0
Training loss: 3.1864284135291503
Validation loss: 2.699385122968335

Epoch: 5| Step: 1
Training loss: 3.4069668076860267
Validation loss: 2.69994844617585

Epoch: 5| Step: 2
Training loss: 3.0950930984126788
Validation loss: 2.698651217150642

Epoch: 5| Step: 3
Training loss: 3.023372836739876
Validation loss: 2.6952686127306724

Epoch: 5| Step: 4
Training loss: 3.411507425124871
Validation loss: 2.6905917283813787

Epoch: 5| Step: 5
Training loss: 3.182382402307523
Validation loss: 2.6921008716423622

Epoch: 5| Step: 6
Training loss: 2.5507719965674904
Validation loss: 2.690867417475961

Epoch: 5| Step: 7
Training loss: 3.182347789879276
Validation loss: 2.6942218330459107

Epoch: 5| Step: 8
Training loss: 2.3624288235392537
Validation loss: 2.688444413773706

Epoch: 5| Step: 9
Training loss: 2.892037866020024
Validation loss: 2.693856398706697

Epoch: 5| Step: 10
Training loss: 2.790899190215854
Validation loss: 2.691975630244169

Epoch: 69| Step: 0
Training loss: 3.49613030270696
Validation loss: 2.6892157408077764

Epoch: 5| Step: 1
Training loss: 2.543406927794686
Validation loss: 2.689529421556819

Epoch: 5| Step: 2
Training loss: 2.96377660873741
Validation loss: 2.691651732020039

Epoch: 5| Step: 3
Training loss: 3.093166720189314
Validation loss: 2.6941104062425563

Epoch: 5| Step: 4
Training loss: 3.1167126439693034
Validation loss: 2.689222952544309

Epoch: 5| Step: 5
Training loss: 2.9157425279224745
Validation loss: 2.6887584829436664

Epoch: 5| Step: 6
Training loss: 2.605017764567247
Validation loss: 2.688601061047117

Epoch: 5| Step: 7
Training loss: 3.0955863665875856
Validation loss: 2.684123914698012

Epoch: 5| Step: 8
Training loss: 3.0959149116730944
Validation loss: 2.6839485034880313

Epoch: 5| Step: 9
Training loss: 3.1020352173902217
Validation loss: 2.691745018232196

Epoch: 5| Step: 10
Training loss: 3.2228823310849455
Validation loss: 2.7002391045045617

Epoch: 70| Step: 0
Training loss: 3.3340511661715544
Validation loss: 2.7010628438585367

Epoch: 5| Step: 1
Training loss: 2.616064941160136
Validation loss: 2.6974353963628035

Epoch: 5| Step: 2
Training loss: 1.8651530782348733
Validation loss: 2.6858667675130365

Epoch: 5| Step: 3
Training loss: 3.0425609858974516
Validation loss: 2.6897103543801415

Epoch: 5| Step: 4
Training loss: 3.3392043544570904
Validation loss: 2.6915158837750437

Epoch: 5| Step: 5
Training loss: 3.0243366491444696
Validation loss: 2.687067192084785

Epoch: 5| Step: 6
Training loss: 3.017616997625834
Validation loss: 2.6905488789219674

Epoch: 5| Step: 7
Training loss: 3.0339584048895754
Validation loss: 2.692478474703214

Epoch: 5| Step: 8
Training loss: 3.1806786044628423
Validation loss: 2.694475612989397

Epoch: 5| Step: 9
Training loss: 3.194364001233342
Validation loss: 2.6796113939209807

Epoch: 5| Step: 10
Training loss: 3.2801872348843806
Validation loss: 2.676356617303256

Epoch: 71| Step: 0
Training loss: 2.873430736008981
Validation loss: 2.6779536249964226

Epoch: 5| Step: 1
Training loss: 3.3314845362222365
Validation loss: 2.674653821865191

Epoch: 5| Step: 2
Training loss: 2.8523633694502943
Validation loss: 2.675482692339369

Epoch: 5| Step: 3
Training loss: 3.0934172171970076
Validation loss: 2.6750237501897747

Epoch: 5| Step: 4
Training loss: 3.237720178606554
Validation loss: 2.6755807792957156

Epoch: 5| Step: 5
Training loss: 3.207265866208764
Validation loss: 2.6744667565203546

Epoch: 5| Step: 6
Training loss: 2.524183889258707
Validation loss: 2.6785812627374512

Epoch: 5| Step: 7
Training loss: 2.986924285960974
Validation loss: 2.683385105992809

Epoch: 5| Step: 8
Training loss: 2.2589057994450767
Validation loss: 2.6809199759532873

Epoch: 5| Step: 9
Training loss: 3.320126947940312
Validation loss: 2.705561980746581

Epoch: 5| Step: 10
Training loss: 3.285509233414443
Validation loss: 2.6884298144595085

Epoch: 72| Step: 0
Training loss: 3.076725210650211
Validation loss: 2.6732859498260724

Epoch: 5| Step: 1
Training loss: 2.874956213576212
Validation loss: 2.674798602355546

Epoch: 5| Step: 2
Training loss: 2.847069615768763
Validation loss: 2.673401809942921

Epoch: 5| Step: 3
Training loss: 3.6337277807836497
Validation loss: 2.677185368515634

Epoch: 5| Step: 4
Training loss: 2.5151961061682906
Validation loss: 2.68001645526386

Epoch: 5| Step: 5
Training loss: 2.7620684498088464
Validation loss: 2.6808015996048864

Epoch: 5| Step: 6
Training loss: 3.0520921691836067
Validation loss: 2.678125812362253

Epoch: 5| Step: 7
Training loss: 3.0992839909257577
Validation loss: 2.675165745933887

Epoch: 5| Step: 8
Training loss: 3.1667426920013173
Validation loss: 2.6710435731929745

Epoch: 5| Step: 9
Training loss: 3.107976244203564
Validation loss: 2.6751568997508532

Epoch: 5| Step: 10
Training loss: 3.0110571860739572
Validation loss: 2.67055308511904

Epoch: 73| Step: 0
Training loss: 2.822036005202741
Validation loss: 2.6700733488506017

Epoch: 5| Step: 1
Training loss: 2.870168523858256
Validation loss: 2.67367339668726

Epoch: 5| Step: 2
Training loss: 2.9009922829242303
Validation loss: 2.67273012485951

Epoch: 5| Step: 3
Training loss: 3.1338344058343157
Validation loss: 2.6803746806833613

Epoch: 5| Step: 4
Training loss: 2.8979824151031472
Validation loss: 2.672729246246594

Epoch: 5| Step: 5
Training loss: 3.4060107505839237
Validation loss: 2.6698514803934272

Epoch: 5| Step: 6
Training loss: 3.015287548416202
Validation loss: 2.6675625367844584

Epoch: 5| Step: 7
Training loss: 3.315962367462019
Validation loss: 2.672262326212072

Epoch: 5| Step: 8
Training loss: 2.918570378594556
Validation loss: 2.6700959965051605

Epoch: 5| Step: 9
Training loss: 2.8113148205426293
Validation loss: 2.6696608231739662

Epoch: 5| Step: 10
Training loss: 2.904536408613671
Validation loss: 2.6654445551774897

Epoch: 74| Step: 0
Training loss: 2.758485101479475
Validation loss: 2.6716256108330336

Epoch: 5| Step: 1
Training loss: 3.206480771212768
Validation loss: 2.6793464341466184

Epoch: 5| Step: 2
Training loss: 1.9412752103427426
Validation loss: 2.671186445615516

Epoch: 5| Step: 3
Training loss: 3.751238046364582
Validation loss: 2.6861948076286377

Epoch: 5| Step: 4
Training loss: 3.0296445704817763
Validation loss: 2.674970078514215

Epoch: 5| Step: 5
Training loss: 3.3095544638525807
Validation loss: 2.684699314110101

Epoch: 5| Step: 6
Training loss: 2.82297312174483
Validation loss: 2.677559174248498

Epoch: 5| Step: 7
Training loss: 2.3951029009604086
Validation loss: 2.659240371282649

Epoch: 5| Step: 8
Training loss: 3.1174710940662895
Validation loss: 2.665229239469251

Epoch: 5| Step: 9
Training loss: 3.176801041532647
Validation loss: 2.658523714196556

Epoch: 5| Step: 10
Training loss: 3.1859917157598865
Validation loss: 2.659791928058706

Epoch: 75| Step: 0
Training loss: 2.2691283401837046
Validation loss: 2.6581940844537915

Epoch: 5| Step: 1
Training loss: 3.0334684768027276
Validation loss: 2.6601129748519834

Epoch: 5| Step: 2
Training loss: 3.240518089598278
Validation loss: 2.6666526819703305

Epoch: 5| Step: 3
Training loss: 2.8098314977333243
Validation loss: 2.6771896470154877

Epoch: 5| Step: 4
Training loss: 3.050816573599119
Validation loss: 2.664745483477978

Epoch: 5| Step: 5
Training loss: 3.222375402061579
Validation loss: 2.6699620645410667

Epoch: 5| Step: 6
Training loss: 3.2324693751230495
Validation loss: 2.6687323762729105

Epoch: 5| Step: 7
Training loss: 2.805228518528965
Validation loss: 2.659117415433313

Epoch: 5| Step: 8
Training loss: 2.8369628061647214
Validation loss: 2.6561753225717117

Epoch: 5| Step: 9
Training loss: 3.0123474019130017
Validation loss: 2.655332191759595

Epoch: 5| Step: 10
Training loss: 3.401986349716475
Validation loss: 2.656461164174883

Epoch: 76| Step: 0
Training loss: 3.326021917953346
Validation loss: 2.661506167086444

Epoch: 5| Step: 1
Training loss: 2.705219141179997
Validation loss: 2.658514274068403

Epoch: 5| Step: 2
Training loss: 2.469335752120732
Validation loss: 2.6537119486155234

Epoch: 5| Step: 3
Training loss: 3.090602468132683
Validation loss: 2.6530109246439926

Epoch: 5| Step: 4
Training loss: 2.8335593264339636
Validation loss: 2.655010744536629

Epoch: 5| Step: 5
Training loss: 3.1107671486978847
Validation loss: 2.653750356886188

Epoch: 5| Step: 6
Training loss: 3.3912994135945125
Validation loss: 2.6540514239640234

Epoch: 5| Step: 7
Training loss: 2.9187035305726825
Validation loss: 2.6574724833428394

Epoch: 5| Step: 8
Training loss: 2.6935351717578486
Validation loss: 2.6529206095015776

Epoch: 5| Step: 9
Training loss: 3.0187203921175167
Validation loss: 2.6511259405052936

Epoch: 5| Step: 10
Training loss: 3.345312733763785
Validation loss: 2.659470314255546

Epoch: 77| Step: 0
Training loss: 2.648359179393651
Validation loss: 2.6660677037859517

Epoch: 5| Step: 1
Training loss: 3.1186113284668853
Validation loss: 2.6572573378581215

Epoch: 5| Step: 2
Training loss: 3.002327016505378
Validation loss: 2.6673859297914833

Epoch: 5| Step: 3
Training loss: 3.0840304505939025
Validation loss: 2.658523952863236

Epoch: 5| Step: 4
Training loss: 2.4999052983467003
Validation loss: 2.6555049529362837

Epoch: 5| Step: 5
Training loss: 2.8884916113886328
Validation loss: 2.6522862392525504

Epoch: 5| Step: 6
Training loss: 3.156826457645622
Validation loss: 2.6543496347507567

Epoch: 5| Step: 7
Training loss: 3.006072256817525
Validation loss: 2.65157887395149

Epoch: 5| Step: 8
Training loss: 3.087607248273699
Validation loss: 2.6478641281504665

Epoch: 5| Step: 9
Training loss: 3.152537664903894
Validation loss: 2.651880903900694

Epoch: 5| Step: 10
Training loss: 3.1816987745990595
Validation loss: 2.6469266565726475

Epoch: 78| Step: 0
Training loss: 3.1001334561569904
Validation loss: 2.64567032372353

Epoch: 5| Step: 1
Training loss: 3.285552482885923
Validation loss: 2.644711187124856

Epoch: 5| Step: 2
Training loss: 2.9812324315479137
Validation loss: 2.643520296314653

Epoch: 5| Step: 3
Training loss: 3.002932863311329
Validation loss: 2.645434330032465

Epoch: 5| Step: 4
Training loss: 2.840416935685723
Validation loss: 2.649376200978484

Epoch: 5| Step: 5
Training loss: 2.8794493040115428
Validation loss: 2.6477087297566015

Epoch: 5| Step: 6
Training loss: 2.7611028046443584
Validation loss: 2.65205969083699

Epoch: 5| Step: 7
Training loss: 3.154515006728188
Validation loss: 2.6444209828893874

Epoch: 5| Step: 8
Training loss: 3.2844125674755165
Validation loss: 2.65441827320542

Epoch: 5| Step: 9
Training loss: 2.7378560605441
Validation loss: 2.658278779298054

Epoch: 5| Step: 10
Training loss: 2.7254811413367412
Validation loss: 2.650009114394299

Epoch: 79| Step: 0
Training loss: 3.0283003151044836
Validation loss: 2.649516689776873

Epoch: 5| Step: 1
Training loss: 2.741900045864406
Validation loss: 2.6441421613957115

Epoch: 5| Step: 2
Training loss: 3.2197021261299716
Validation loss: 2.641715376851818

Epoch: 5| Step: 3
Training loss: 2.8757227113668136
Validation loss: 2.6341466022727302

Epoch: 5| Step: 4
Training loss: 3.541441263244147
Validation loss: 2.639358180713159

Epoch: 5| Step: 5
Training loss: 2.7243531465539985
Validation loss: 2.6400953930288287

Epoch: 5| Step: 6
Training loss: 3.3933606340650364
Validation loss: 2.6404068127288585

Epoch: 5| Step: 7
Training loss: 2.787474963156988
Validation loss: 2.641012564411874

Epoch: 5| Step: 8
Training loss: 3.304748246015641
Validation loss: 2.638090479054241

Epoch: 5| Step: 9
Training loss: 2.6063139543988254
Validation loss: 2.638758026128095

Epoch: 5| Step: 10
Training loss: 2.3767855106331974
Validation loss: 2.6392514507775533

Epoch: 80| Step: 0
Training loss: 3.478710274066876
Validation loss: 2.654087011661322

Epoch: 5| Step: 1
Training loss: 3.1322489776256477
Validation loss: 2.6476794913880295

Epoch: 5| Step: 2
Training loss: 2.5999578619256627
Validation loss: 2.6430020759990325

Epoch: 5| Step: 3
Training loss: 3.2484912304565374
Validation loss: 2.63533949448183

Epoch: 5| Step: 4
Training loss: 2.970298443579888
Validation loss: 2.626131706908438

Epoch: 5| Step: 5
Training loss: 2.623950748551267
Validation loss: 2.624953650921372

Epoch: 5| Step: 6
Training loss: 3.0713261685457227
Validation loss: 2.6250133758219762

Epoch: 5| Step: 7
Training loss: 3.341419298968412
Validation loss: 2.62291910654443

Epoch: 5| Step: 8
Training loss: 2.642476081992529
Validation loss: 2.6263127626174314

Epoch: 5| Step: 9
Training loss: 2.708515415428761
Validation loss: 2.6287067082044504

Epoch: 5| Step: 10
Training loss: 2.7475893552097737
Validation loss: 2.6328652482110173

Epoch: 81| Step: 0
Training loss: 2.52661962025843
Validation loss: 2.650479800863359

Epoch: 5| Step: 1
Training loss: 3.1931949678148417
Validation loss: 2.6864431983420802

Epoch: 5| Step: 2
Training loss: 3.2238974290722573
Validation loss: 2.7598522291042715

Epoch: 5| Step: 3
Training loss: 3.20363765428781
Validation loss: 2.6746583900454675

Epoch: 5| Step: 4
Training loss: 2.617387359731331
Validation loss: 2.6671420072343466

Epoch: 5| Step: 5
Training loss: 3.2345075349789263
Validation loss: 2.6303867721013456

Epoch: 5| Step: 6
Training loss: 2.406002378727347
Validation loss: 2.6269829356142096

Epoch: 5| Step: 7
Training loss: 3.4970660855444295
Validation loss: 2.629552894067852

Epoch: 5| Step: 8
Training loss: 2.8262643331023387
Validation loss: 2.6358337574887205

Epoch: 5| Step: 9
Training loss: 2.7480647473543733
Validation loss: 2.6422292020016678

Epoch: 5| Step: 10
Training loss: 3.2529072596138424
Validation loss: 2.6542009396982817

Epoch: 82| Step: 0
Training loss: 2.002554573334607
Validation loss: 2.654007876368101

Epoch: 5| Step: 1
Training loss: 2.601558284355162
Validation loss: 2.6503307377990692

Epoch: 5| Step: 2
Training loss: 3.0295701238786417
Validation loss: 2.6438736004778938

Epoch: 5| Step: 3
Training loss: 3.3285598112660217
Validation loss: 2.6373155114986746

Epoch: 5| Step: 4
Training loss: 2.9883784259628587
Validation loss: 2.64327147711782

Epoch: 5| Step: 5
Training loss: 3.155760472170669
Validation loss: 2.650742732014081

Epoch: 5| Step: 6
Training loss: 3.5568686699697807
Validation loss: 2.6654409397461856

Epoch: 5| Step: 7
Training loss: 2.971217685855946
Validation loss: 2.663617557491012

Epoch: 5| Step: 8
Training loss: 2.842370002343926
Validation loss: 2.666916878431373

Epoch: 5| Step: 9
Training loss: 3.035880101908516
Validation loss: 2.6558975169230608

Epoch: 5| Step: 10
Training loss: 3.223695085877985
Validation loss: 2.6529750857617556

Epoch: 83| Step: 0
Training loss: 2.9303778483510357
Validation loss: 2.6350855977886627

Epoch: 5| Step: 1
Training loss: 3.0048247323359987
Validation loss: 2.6272852960770723

Epoch: 5| Step: 2
Training loss: 3.1776128275578746
Validation loss: 2.629878995134463

Epoch: 5| Step: 3
Training loss: 2.7030489695887177
Validation loss: 2.6301652470855554

Epoch: 5| Step: 4
Training loss: 3.2119336590121255
Validation loss: 2.6332460883026063

Epoch: 5| Step: 5
Training loss: 2.8793448084380073
Validation loss: 2.6476541015675155

Epoch: 5| Step: 6
Training loss: 2.8785279231145893
Validation loss: 2.6353939187872872

Epoch: 5| Step: 7
Training loss: 3.1592885112149425
Validation loss: 2.643189731952146

Epoch: 5| Step: 8
Training loss: 2.9915283114461064
Validation loss: 2.6280711481532455

Epoch: 5| Step: 9
Training loss: 2.4243411398064842
Validation loss: 2.6326188302598656

Epoch: 5| Step: 10
Training loss: 3.209188388647598
Validation loss: 2.632549436454224

Epoch: 84| Step: 0
Training loss: 3.1293815413723416
Validation loss: 2.621337326691809

Epoch: 5| Step: 1
Training loss: 3.1333838343777862
Validation loss: 2.618096102960541

Epoch: 5| Step: 2
Training loss: 2.1863568179871926
Validation loss: 2.6185902391647726

Epoch: 5| Step: 3
Training loss: 3.3149534532319946
Validation loss: 2.619113574471368

Epoch: 5| Step: 4
Training loss: 2.6102328232440355
Validation loss: 2.620675014969648

Epoch: 5| Step: 5
Training loss: 2.709586034737553
Validation loss: 2.6183577449514877

Epoch: 5| Step: 6
Training loss: 3.05633079250398
Validation loss: 2.6256960831228464

Epoch: 5| Step: 7
Training loss: 3.09009050428074
Validation loss: 2.6319229104604545

Epoch: 5| Step: 8
Training loss: 3.1311455379886
Validation loss: 2.6800418092028253

Epoch: 5| Step: 9
Training loss: 3.286773972787505
Validation loss: 2.617556838996609

Epoch: 5| Step: 10
Training loss: 2.7068380972249932
Validation loss: 2.6153337442497397

Epoch: 85| Step: 0
Training loss: 2.943245645716693
Validation loss: 2.615859878322192

Epoch: 5| Step: 1
Training loss: 3.451718695626188
Validation loss: 2.61621352641021

Epoch: 5| Step: 2
Training loss: 2.5425799141386873
Validation loss: 2.617872330448956

Epoch: 5| Step: 3
Training loss: 3.366749037940407
Validation loss: 2.6167050093968967

Epoch: 5| Step: 4
Training loss: 2.8675679882074614
Validation loss: 2.609586578293666

Epoch: 5| Step: 5
Training loss: 2.64129160756649
Validation loss: 2.6175576675706447

Epoch: 5| Step: 6
Training loss: 2.4390249128457415
Validation loss: 2.6204059938785997

Epoch: 5| Step: 7
Training loss: 2.7043966488448854
Validation loss: 2.6141044558265314

Epoch: 5| Step: 8
Training loss: 3.1716885817294007
Validation loss: 2.6268705299629476

Epoch: 5| Step: 9
Training loss: 3.0128029382112977
Validation loss: 2.6371775116756404

Epoch: 5| Step: 10
Training loss: 3.251130420989325
Validation loss: 2.646888961897546

Epoch: 86| Step: 0
Training loss: 3.2715490898449966
Validation loss: 2.7013808610395125

Epoch: 5| Step: 1
Training loss: 3.166300568415889
Validation loss: 2.6837641674774564

Epoch: 5| Step: 2
Training loss: 3.3217589335651265
Validation loss: 2.6095777038277825

Epoch: 5| Step: 3
Training loss: 2.9329171651334067
Validation loss: 2.6071623008045854

Epoch: 5| Step: 4
Training loss: 2.6624618599179177
Validation loss: 2.605109838836208

Epoch: 5| Step: 5
Training loss: 3.1837899551310787
Validation loss: 2.6094023479767277

Epoch: 5| Step: 6
Training loss: 3.1749931755893686
Validation loss: 2.611281575467217

Epoch: 5| Step: 7
Training loss: 3.063079156413858
Validation loss: 2.613434531379977

Epoch: 5| Step: 8
Training loss: 2.911165899468128
Validation loss: 2.610823678811842

Epoch: 5| Step: 9
Training loss: 2.352109927716081
Validation loss: 2.6078386770719697

Epoch: 5| Step: 10
Training loss: 2.2838696631874016
Validation loss: 2.6088114584261928

Epoch: 87| Step: 0
Training loss: 2.6366480386930387
Validation loss: 2.6094219500001103

Epoch: 5| Step: 1
Training loss: 3.1661713530678193
Validation loss: 2.6041390533624007

Epoch: 5| Step: 2
Training loss: 3.013033370923614
Validation loss: 2.6150303754126814

Epoch: 5| Step: 3
Training loss: 3.395939051068823
Validation loss: 2.6116273338149085

Epoch: 5| Step: 4
Training loss: 3.227093595156393
Validation loss: 2.6218697468817953

Epoch: 5| Step: 5
Training loss: 2.246735960328527
Validation loss: 2.6319594373117328

Epoch: 5| Step: 6
Training loss: 2.4678485045282845
Validation loss: 2.6245514456662895

Epoch: 5| Step: 7
Training loss: 2.5825617673712276
Validation loss: 2.6115448131242935

Epoch: 5| Step: 8
Training loss: 2.9367596931170903
Validation loss: 2.608097767177657

Epoch: 5| Step: 9
Training loss: 3.482132399546811
Validation loss: 2.610721597554636

Epoch: 5| Step: 10
Training loss: 3.0563794691750443
Validation loss: 2.607384354491668

Epoch: 88| Step: 0
Training loss: 3.226892191227676
Validation loss: 2.600590292731904

Epoch: 5| Step: 1
Training loss: 2.8217447717637962
Validation loss: 2.604734584450866

Epoch: 5| Step: 2
Training loss: 2.563384112916276
Validation loss: 2.6100921676914535

Epoch: 5| Step: 3
Training loss: 2.5137015624764474
Validation loss: 2.6132558752147115

Epoch: 5| Step: 4
Training loss: 3.4756642756432075
Validation loss: 2.616149569190904

Epoch: 5| Step: 5
Training loss: 3.061508796815073
Validation loss: 2.604432844443348

Epoch: 5| Step: 6
Training loss: 3.557416802919273
Validation loss: 2.6031734690767583

Epoch: 5| Step: 7
Training loss: 2.4534057650896335
Validation loss: 2.6021873489653506

Epoch: 5| Step: 8
Training loss: 3.0819769444776033
Validation loss: 2.597690478609872

Epoch: 5| Step: 9
Training loss: 2.894095322373704
Validation loss: 2.599517451075499

Epoch: 5| Step: 10
Training loss: 2.5136566991577634
Validation loss: 2.602892002996552

Epoch: 89| Step: 0
Training loss: 2.6679983290991633
Validation loss: 2.59870638226069

Epoch: 5| Step: 1
Training loss: 3.3584993862499672
Validation loss: 2.6082910903921945

Epoch: 5| Step: 2
Training loss: 2.1413973786185263
Validation loss: 2.6098785346839866

Epoch: 5| Step: 3
Training loss: 2.6274347367243682
Validation loss: 2.6048072771899693

Epoch: 5| Step: 4
Training loss: 3.3111562342488434
Validation loss: 2.606780608197592

Epoch: 5| Step: 5
Training loss: 2.8864405682523127
Validation loss: 2.6073807912885694

Epoch: 5| Step: 6
Training loss: 2.8939366521433487
Validation loss: 2.598185702793893

Epoch: 5| Step: 7
Training loss: 2.935622893851038
Validation loss: 2.6024323336874278

Epoch: 5| Step: 8
Training loss: 3.299110847676068
Validation loss: 2.61021892381769

Epoch: 5| Step: 9
Training loss: 3.088793705160568
Validation loss: 2.6132253144874538

Epoch: 5| Step: 10
Training loss: 2.938343819700308
Validation loss: 2.6167338904304733

Epoch: 90| Step: 0
Training loss: 3.0935380651149167
Validation loss: 2.613479848774319

Epoch: 5| Step: 1
Training loss: 2.678050172132103
Validation loss: 2.6095715098089705

Epoch: 5| Step: 2
Training loss: 2.4497413381934745
Validation loss: 2.6138031619222413

Epoch: 5| Step: 3
Training loss: 2.663618033911509
Validation loss: 2.62742042482435

Epoch: 5| Step: 4
Training loss: 2.7727144400218644
Validation loss: 2.6295031037148644

Epoch: 5| Step: 5
Training loss: 2.7082515899842283
Validation loss: 2.6195128056831307

Epoch: 5| Step: 6
Training loss: 2.9761345823579837
Validation loss: 2.605204850181254

Epoch: 5| Step: 7
Training loss: 2.632953040110245
Validation loss: 2.5944522540059607

Epoch: 5| Step: 8
Training loss: 2.9765341449498353
Validation loss: 2.5934463779904893

Epoch: 5| Step: 9
Training loss: 3.4670515971562565
Validation loss: 2.594014822048525

Epoch: 5| Step: 10
Training loss: 3.7959896358352525
Validation loss: 2.5962927845364905

Epoch: 91| Step: 0
Training loss: 3.142980347113438
Validation loss: 2.593927436904267

Epoch: 5| Step: 1
Training loss: 2.743405411268964
Validation loss: 2.5959369045478646

Epoch: 5| Step: 2
Training loss: 2.7315933465650657
Validation loss: 2.5924624288870777

Epoch: 5| Step: 3
Training loss: 2.5428493020501652
Validation loss: 2.592007022356947

Epoch: 5| Step: 4
Training loss: 2.854764963820529
Validation loss: 2.594326967722369

Epoch: 5| Step: 5
Training loss: 3.148126402220907
Validation loss: 2.5898429808612944

Epoch: 5| Step: 6
Training loss: 2.668732607782586
Validation loss: 2.5932283812251367

Epoch: 5| Step: 7
Training loss: 3.6339306494940202
Validation loss: 2.5983067286137826

Epoch: 5| Step: 8
Training loss: 3.322055493795584
Validation loss: 2.60867785402694

Epoch: 5| Step: 9
Training loss: 2.475844510811923
Validation loss: 2.6232125563766298

Epoch: 5| Step: 10
Training loss: 2.8777784107785243
Validation loss: 2.6469178961606947

Epoch: 92| Step: 0
Training loss: 2.776807344253398
Validation loss: 2.688785674711931

Epoch: 5| Step: 1
Training loss: 3.003730838252561
Validation loss: 2.686342712794187

Epoch: 5| Step: 2
Training loss: 3.075151585510013
Validation loss: 2.663754758260597

Epoch: 5| Step: 3
Training loss: 2.8608226342635006
Validation loss: 2.595417401513947

Epoch: 5| Step: 4
Training loss: 3.131669214019903
Validation loss: 2.5862303938698146

Epoch: 5| Step: 5
Training loss: 3.38698062082293
Validation loss: 2.5891716653182235

Epoch: 5| Step: 6
Training loss: 2.7181334399322328
Validation loss: 2.597432556315838

Epoch: 5| Step: 7
Training loss: 2.9056448357672853
Validation loss: 2.60891877233109

Epoch: 5| Step: 8
Training loss: 3.0128197148140425
Validation loss: 2.6081017117698497

Epoch: 5| Step: 9
Training loss: 2.765512151624887
Validation loss: 2.6035634142384674

Epoch: 5| Step: 10
Training loss: 2.912775404847073
Validation loss: 2.5973335997742915

Epoch: 93| Step: 0
Training loss: 2.2572142128418005
Validation loss: 2.594577296113356

Epoch: 5| Step: 1
Training loss: 3.1985583992057864
Validation loss: 2.5931481519202246

Epoch: 5| Step: 2
Training loss: 2.926448241781941
Validation loss: 2.591684876621881

Epoch: 5| Step: 3
Training loss: 3.3065242487734836
Validation loss: 2.590645607764003

Epoch: 5| Step: 4
Training loss: 3.3709569662374954
Validation loss: 2.5923679701021154

Epoch: 5| Step: 5
Training loss: 3.0300919985259935
Validation loss: 2.5855959567677855

Epoch: 5| Step: 6
Training loss: 2.322518478500719
Validation loss: 2.58673264107372

Epoch: 5| Step: 7
Training loss: 3.0300567480633718
Validation loss: 2.6117489995659198

Epoch: 5| Step: 8
Training loss: 2.8512248636264075
Validation loss: 2.5931667102466234

Epoch: 5| Step: 9
Training loss: 2.835932960191356
Validation loss: 2.598348594157171

Epoch: 5| Step: 10
Training loss: 3.0995098403304313
Validation loss: 2.599309255214252

Epoch: 94| Step: 0
Training loss: 2.6208768888492084
Validation loss: 2.634615083173836

Epoch: 5| Step: 1
Training loss: 3.1683492373235054
Validation loss: 2.6489839006224125

Epoch: 5| Step: 2
Training loss: 2.281726212635936
Validation loss: 2.6388233550878746

Epoch: 5| Step: 3
Training loss: 3.3879831455176284
Validation loss: 2.6170415625475982

Epoch: 5| Step: 4
Training loss: 2.6179836599482633
Validation loss: 2.586998783975492

Epoch: 5| Step: 5
Training loss: 3.2652818417376235
Validation loss: 2.5851656250617

Epoch: 5| Step: 6
Training loss: 2.895875688055581
Validation loss: 2.576400857492647

Epoch: 5| Step: 7
Training loss: 3.0367565673797308
Validation loss: 2.579767774115026

Epoch: 5| Step: 8
Training loss: 2.9506512327185597
Validation loss: 2.5834507678991163

Epoch: 5| Step: 9
Training loss: 3.118442521772155
Validation loss: 2.5855164415126803

Epoch: 5| Step: 10
Training loss: 2.8827977787458643
Validation loss: 2.589303960391875

Epoch: 95| Step: 0
Training loss: 3.1784025027972147
Validation loss: 2.5827903272800166

Epoch: 5| Step: 1
Training loss: 2.8729731837507257
Validation loss: 2.5822130672624906

Epoch: 5| Step: 2
Training loss: 2.676633468016668
Validation loss: 2.5859030464230943

Epoch: 5| Step: 3
Training loss: 2.7806077708565624
Validation loss: 2.5833529518909435

Epoch: 5| Step: 4
Training loss: 2.7647823623348513
Validation loss: 2.585646149420625

Epoch: 5| Step: 5
Training loss: 2.7333813414970902
Validation loss: 2.6010435045464573

Epoch: 5| Step: 6
Training loss: 3.221371962370426
Validation loss: 2.62076261167282

Epoch: 5| Step: 7
Training loss: 3.003018291375762
Validation loss: 2.638914296478195

Epoch: 5| Step: 8
Training loss: 2.582938769162308
Validation loss: 2.689308888453662

Epoch: 5| Step: 9
Training loss: 3.054882618948191
Validation loss: 2.656367924369036

Epoch: 5| Step: 10
Training loss: 3.5441313899981632
Validation loss: 2.615614259606425

Epoch: 96| Step: 0
Training loss: 3.0383552571682935
Validation loss: 2.5830432376339427

Epoch: 5| Step: 1
Training loss: 3.3375214651039022
Validation loss: 2.5764541835139867

Epoch: 5| Step: 2
Training loss: 2.927614175213519
Validation loss: 2.5655916733396027

Epoch: 5| Step: 3
Training loss: 3.457746494247582
Validation loss: 2.5711341669397254

Epoch: 5| Step: 4
Training loss: 2.352363526037243
Validation loss: 2.56888332705073

Epoch: 5| Step: 5
Training loss: 2.5427412877701028
Validation loss: 2.5649590607314687

Epoch: 5| Step: 6
Training loss: 2.480035602867769
Validation loss: 2.571350680925595

Epoch: 5| Step: 7
Training loss: 3.153524751908708
Validation loss: 2.5687902247560377

Epoch: 5| Step: 8
Training loss: 2.9974833104780148
Validation loss: 2.568076396244193

Epoch: 5| Step: 9
Training loss: 2.651391466567013
Validation loss: 2.566534066926823

Epoch: 5| Step: 10
Training loss: 3.1099057152000738
Validation loss: 2.5666642287165113

Epoch: 97| Step: 0
Training loss: 3.1189854534919266
Validation loss: 2.564530067460144

Epoch: 5| Step: 1
Training loss: 3.214061099484685
Validation loss: 2.575239212261933

Epoch: 5| Step: 2
Training loss: 2.7935660623850778
Validation loss: 2.577866207096961

Epoch: 5| Step: 3
Training loss: 2.6695866294075605
Validation loss: 2.5846746861045333

Epoch: 5| Step: 4
Training loss: 2.9303750820744887
Validation loss: 2.577484140702706

Epoch: 5| Step: 5
Training loss: 2.901013650992885
Validation loss: 2.6027576731731714

Epoch: 5| Step: 6
Training loss: 3.1279841098820826
Validation loss: 2.6180919971702297

Epoch: 5| Step: 7
Training loss: 3.139257332512173
Validation loss: 2.589372766188101

Epoch: 5| Step: 8
Training loss: 2.8988629052075705
Validation loss: 2.5705061741480995

Epoch: 5| Step: 9
Training loss: 2.2917547960386195
Validation loss: 2.5681584319885973

Epoch: 5| Step: 10
Training loss: 3.0738854039709427
Validation loss: 2.573060517468197

Epoch: 98| Step: 0
Training loss: 2.7030369738760722
Validation loss: 2.580905739433172

Epoch: 5| Step: 1
Training loss: 3.067893436635276
Validation loss: 2.56899132990792

Epoch: 5| Step: 2
Training loss: 2.670709902509409
Validation loss: 2.5640247069805273

Epoch: 5| Step: 3
Training loss: 2.8778740159401583
Validation loss: 2.565228870775904

Epoch: 5| Step: 4
Training loss: 3.000352997674897
Validation loss: 2.570519615616039

Epoch: 5| Step: 5
Training loss: 3.2130718330832915
Validation loss: 2.5980882471566096

Epoch: 5| Step: 6
Training loss: 3.046257386822798
Validation loss: 2.636689376150912

Epoch: 5| Step: 7
Training loss: 2.4369845701221475
Validation loss: 2.6592284787354625

Epoch: 5| Step: 8
Training loss: 3.061114250715353
Validation loss: 2.7022856505140083

Epoch: 5| Step: 9
Training loss: 2.8491458215106236
Validation loss: 2.606149584169408

Epoch: 5| Step: 10
Training loss: 3.4181926544965826
Validation loss: 2.564214575504372

Epoch: 99| Step: 0
Training loss: 2.995989025528776
Validation loss: 2.565712726355178

Epoch: 5| Step: 1
Training loss: 2.888610137630497
Validation loss: 2.568648026446341

Epoch: 5| Step: 2
Training loss: 3.067993997033325
Validation loss: 2.573198622293733

Epoch: 5| Step: 3
Training loss: 2.8874652810920027
Validation loss: 2.575524610161639

Epoch: 5| Step: 4
Training loss: 2.383270119671262
Validation loss: 2.58305065200843

Epoch: 5| Step: 5
Training loss: 3.4199266155913746
Validation loss: 2.592910266940624

Epoch: 5| Step: 6
Training loss: 2.682736633330047
Validation loss: 2.573370147062174

Epoch: 5| Step: 7
Training loss: 3.145317709056712
Validation loss: 2.566615409829358

Epoch: 5| Step: 8
Training loss: 3.00068466003262
Validation loss: 2.555478005847319

Epoch: 5| Step: 9
Training loss: 2.8887095110377845
Validation loss: 2.557789434419352

Epoch: 5| Step: 10
Training loss: 2.8056680564440333
Validation loss: 2.61068194840014

Epoch: 100| Step: 0
Training loss: 2.6087548895343606
Validation loss: 2.733372913507217

Epoch: 5| Step: 1
Training loss: 3.333425822564314
Validation loss: 2.8993739322541665

Epoch: 5| Step: 2
Training loss: 2.9309154327697433
Validation loss: 2.655939858829321

Epoch: 5| Step: 3
Training loss: 2.6400619899812208
Validation loss: 2.5897175082160704

Epoch: 5| Step: 4
Training loss: 2.831771102006254
Validation loss: 2.577085390419312

Epoch: 5| Step: 5
Training loss: 3.0418412319587516
Validation loss: 2.5815066138644993

Epoch: 5| Step: 6
Training loss: 3.1612479041934654
Validation loss: 2.590022044442564

Epoch: 5| Step: 7
Training loss: 3.011228845632062
Validation loss: 2.6121828837342314

Epoch: 5| Step: 8
Training loss: 2.443949944397183
Validation loss: 2.605688165645767

Epoch: 5| Step: 9
Training loss: 3.5252096451987844
Validation loss: 2.612424186340121

Epoch: 5| Step: 10
Training loss: 2.846411832113049
Validation loss: 2.597369910301549

Epoch: 101| Step: 0
Training loss: 2.8666343051355336
Validation loss: 2.605858193300284

Epoch: 5| Step: 1
Training loss: 2.3027532186861523
Validation loss: 2.601732600201991

Epoch: 5| Step: 2
Training loss: 3.1862654445628555
Validation loss: 2.608782885712332

Epoch: 5| Step: 3
Training loss: 2.9698843946980653
Validation loss: 2.634963747679465

Epoch: 5| Step: 4
Training loss: 2.845543096961035
Validation loss: 2.6090425030558477

Epoch: 5| Step: 5
Training loss: 2.7711875708210982
Validation loss: 2.60679162380742

Epoch: 5| Step: 6
Training loss: 3.027437152036965
Validation loss: 2.599774021664856

Epoch: 5| Step: 7
Training loss: 3.2060661397050256
Validation loss: 2.624655756178936

Epoch: 5| Step: 8
Training loss: 3.382338563347036
Validation loss: 2.6387856612410174

Epoch: 5| Step: 9
Training loss: 2.932293437372264
Validation loss: 2.617325846615772

Epoch: 5| Step: 10
Training loss: 2.602636167278491
Validation loss: 2.5731466863995514

Epoch: 102| Step: 0
Training loss: 3.260187175502585
Validation loss: 2.5598321588643196

Epoch: 5| Step: 1
Training loss: 2.557623433167011
Validation loss: 2.5618652009668637

Epoch: 5| Step: 2
Training loss: 3.105484565358706
Validation loss: 2.5569949640334526

Epoch: 5| Step: 3
Training loss: 3.2328110014080926
Validation loss: 2.560075977480444

Epoch: 5| Step: 4
Training loss: 2.7391537134854396
Validation loss: 2.5592875930336945

Epoch: 5| Step: 5
Training loss: 2.2740054125826257
Validation loss: 2.5552389375069477

Epoch: 5| Step: 6
Training loss: 2.863141357002092
Validation loss: 2.5519178382465926

Epoch: 5| Step: 7
Training loss: 3.1168656338370653
Validation loss: 2.5491810730093873

Epoch: 5| Step: 8
Training loss: 2.8922335711189073
Validation loss: 2.550346444113251

Epoch: 5| Step: 9
Training loss: 2.937232634368766
Validation loss: 2.569769336041382

Epoch: 5| Step: 10
Training loss: 3.1751436576482805
Validation loss: 2.5847904050469426

Epoch: 103| Step: 0
Training loss: 3.0178179895564976
Validation loss: 2.5977151123108535

Epoch: 5| Step: 1
Training loss: 2.4254945349064556
Validation loss: 2.6082404803582393

Epoch: 5| Step: 2
Training loss: 2.7401757318987796
Validation loss: 2.660464698995889

Epoch: 5| Step: 3
Training loss: 3.163978104584332
Validation loss: 2.726118317736357

Epoch: 5| Step: 4
Training loss: 3.246776155613917
Validation loss: 2.644204226715657

Epoch: 5| Step: 5
Training loss: 2.896853278777199
Validation loss: 2.561994748411014

Epoch: 5| Step: 6
Training loss: 2.9525640045644743
Validation loss: 2.5497575365933303

Epoch: 5| Step: 7
Training loss: 2.8578153431890243
Validation loss: 2.5493217878136014

Epoch: 5| Step: 8
Training loss: 3.4283847985108316
Validation loss: 2.5531310880047733

Epoch: 5| Step: 9
Training loss: 2.861947491892557
Validation loss: 2.5609157045659656

Epoch: 5| Step: 10
Training loss: 2.680562846734426
Validation loss: 2.559891934969222

Epoch: 104| Step: 0
Training loss: 2.8849993425761884
Validation loss: 2.561077201136281

Epoch: 5| Step: 1
Training loss: 3.0099655570153865
Validation loss: 2.5523928312505846

Epoch: 5| Step: 2
Training loss: 3.451545733941709
Validation loss: 2.554741970652011

Epoch: 5| Step: 3
Training loss: 2.990458095760173
Validation loss: 2.546372007195496

Epoch: 5| Step: 4
Training loss: 2.7234008296351497
Validation loss: 2.546975436867184

Epoch: 5| Step: 5
Training loss: 3.1615465498572153
Validation loss: 2.570718986893519

Epoch: 5| Step: 6
Training loss: 2.7067298446134576
Validation loss: 2.59657628600683

Epoch: 5| Step: 7
Training loss: 3.3214930690708573
Validation loss: 2.608747186085986

Epoch: 5| Step: 8
Training loss: 2.328880955386946
Validation loss: 2.5918911587560536

Epoch: 5| Step: 9
Training loss: 2.5252347516002738
Validation loss: 2.570936781299928

Epoch: 5| Step: 10
Training loss: 2.904011181938565
Validation loss: 2.5671008895248475

Epoch: 105| Step: 0
Training loss: 2.9733183395395435
Validation loss: 2.545723111122789

Epoch: 5| Step: 1
Training loss: 2.6408472814058173
Validation loss: 2.5477415354993433

Epoch: 5| Step: 2
Training loss: 2.444119878616551
Validation loss: 2.548680886036822

Epoch: 5| Step: 3
Training loss: 3.387665612933737
Validation loss: 2.546893099301487

Epoch: 5| Step: 4
Training loss: 3.0250391303439867
Validation loss: 2.544424203883019

Epoch: 5| Step: 5
Training loss: 2.915468423938329
Validation loss: 2.540809931431594

Epoch: 5| Step: 6
Training loss: 2.770472357237003
Validation loss: 2.539199046461821

Epoch: 5| Step: 7
Training loss: 3.101270070931657
Validation loss: 2.5409675744873894

Epoch: 5| Step: 8
Training loss: 3.0176451246607296
Validation loss: 2.5421523126627723

Epoch: 5| Step: 9
Training loss: 2.800006328303134
Validation loss: 2.543335446628185

Epoch: 5| Step: 10
Training loss: 2.769348482845685
Validation loss: 2.5395221434885635

Epoch: 106| Step: 0
Training loss: 3.006002937046426
Validation loss: 2.5405289184466793

Epoch: 5| Step: 1
Training loss: 2.5870711961820825
Validation loss: 2.5434647626075053

Epoch: 5| Step: 2
Training loss: 2.62765777099696
Validation loss: 2.5523696594812537

Epoch: 5| Step: 3
Training loss: 3.2069881310857395
Validation loss: 2.5757620096840257

Epoch: 5| Step: 4
Training loss: 2.9043238009427697
Validation loss: 2.6181715580734264

Epoch: 5| Step: 5
Training loss: 2.7793080268684385
Validation loss: 2.6874837185671034

Epoch: 5| Step: 6
Training loss: 2.8534711746837353
Validation loss: 2.7049307154304687

Epoch: 5| Step: 7
Training loss: 2.913394473006819
Validation loss: 2.6864595662408144

Epoch: 5| Step: 8
Training loss: 3.0632614434751635
Validation loss: 2.605219086331527

Epoch: 5| Step: 9
Training loss: 3.12906321537852
Validation loss: 2.5780386991403628

Epoch: 5| Step: 10
Training loss: 2.8698963808500833
Validation loss: 2.5399078531937356

Epoch: 107| Step: 0
Training loss: 2.8136114679345257
Validation loss: 2.536136329232067

Epoch: 5| Step: 1
Training loss: 3.240341212354858
Validation loss: 2.534751892328248

Epoch: 5| Step: 2
Training loss: 3.045524728346772
Validation loss: 2.5365640402991554

Epoch: 5| Step: 3
Training loss: 2.334353723390738
Validation loss: 2.5357375478454327

Epoch: 5| Step: 4
Training loss: 2.985707090581645
Validation loss: 2.5342677520106993

Epoch: 5| Step: 5
Training loss: 2.9110610681783324
Validation loss: 2.533477483716568

Epoch: 5| Step: 6
Training loss: 3.381312647889621
Validation loss: 2.534181577215613

Epoch: 5| Step: 7
Training loss: 2.5409340871033357
Validation loss: 2.532230261827769

Epoch: 5| Step: 8
Training loss: 2.5873329108648324
Validation loss: 2.530215183631896

Epoch: 5| Step: 9
Training loss: 3.3182679826658297
Validation loss: 2.531341444738983

Epoch: 5| Step: 10
Training loss: 2.6520639083722277
Validation loss: 2.534577520464354

Epoch: 108| Step: 0
Training loss: 2.982214819934803
Validation loss: 2.532102084158199

Epoch: 5| Step: 1
Training loss: 2.6424932247713797
Validation loss: 2.533908279151915

Epoch: 5| Step: 2
Training loss: 2.2385626544444843
Validation loss: 2.5351354750876

Epoch: 5| Step: 3
Training loss: 3.0857016944123767
Validation loss: 2.5373321690268664

Epoch: 5| Step: 4
Training loss: 3.4182139978978503
Validation loss: 2.540423974206037

Epoch: 5| Step: 5
Training loss: 2.7905935151138475
Validation loss: 2.5542325497853944

Epoch: 5| Step: 6
Training loss: 3.102307285468227
Validation loss: 2.5565555312395882

Epoch: 5| Step: 7
Training loss: 2.7389493336777178
Validation loss: 2.582129626396401

Epoch: 5| Step: 8
Training loss: 2.874886220256194
Validation loss: 2.6450482470495364

Epoch: 5| Step: 9
Training loss: 3.153291883485196
Validation loss: 2.6763601653052516

Epoch: 5| Step: 10
Training loss: 2.7908383654183324
Validation loss: 2.6257584516720054

Epoch: 109| Step: 0
Training loss: 2.6126260206865632
Validation loss: 2.5857899887125284

Epoch: 5| Step: 1
Training loss: 2.808655718251091
Validation loss: 2.5569754273143865

Epoch: 5| Step: 2
Training loss: 2.8972392522941868
Validation loss: 2.532382816426272

Epoch: 5| Step: 3
Training loss: 3.2517350773838833
Validation loss: 2.528296082559724

Epoch: 5| Step: 4
Training loss: 2.7193417836823515
Validation loss: 2.533362850406924

Epoch: 5| Step: 5
Training loss: 3.1661291837476737
Validation loss: 2.5313854862375016

Epoch: 5| Step: 6
Training loss: 3.337774195462452
Validation loss: 2.5274893990102205

Epoch: 5| Step: 7
Training loss: 2.3440505788703643
Validation loss: 2.5312232802669756

Epoch: 5| Step: 8
Training loss: 2.9511804384906366
Validation loss: 2.5331314297767267

Epoch: 5| Step: 9
Training loss: 2.8853713673548627
Validation loss: 2.5318106573885952

Epoch: 5| Step: 10
Training loss: 2.7370806577517173
Validation loss: 2.540264112493411

Epoch: 110| Step: 0
Training loss: 3.2775442359901215
Validation loss: 2.5339789103388357

Epoch: 5| Step: 1
Training loss: 2.65114686728481
Validation loss: 2.5320811110560357

Epoch: 5| Step: 2
Training loss: 2.854230745436213
Validation loss: 2.5400775510471147

Epoch: 5| Step: 3
Training loss: 3.102960305198835
Validation loss: 2.548146775675604

Epoch: 5| Step: 4
Training loss: 2.77754822312321
Validation loss: 2.5445493579527865

Epoch: 5| Step: 5
Training loss: 2.818097457294299
Validation loss: 2.543664286094716

Epoch: 5| Step: 6
Training loss: 2.704576312181238
Validation loss: 2.5373976895712915

Epoch: 5| Step: 7
Training loss: 2.8281407645613372
Validation loss: 2.5331029780220766

Epoch: 5| Step: 8
Training loss: 3.335237023024879
Validation loss: 2.5373123869438268

Epoch: 5| Step: 9
Training loss: 2.669590112463108
Validation loss: 2.535495524195828

Epoch: 5| Step: 10
Training loss: 2.671501624359431
Validation loss: 2.546958796641754

Epoch: 111| Step: 0
Training loss: 2.4515106331837595
Validation loss: 2.5524649165064335

Epoch: 5| Step: 1
Training loss: 2.6939485056372905
Validation loss: 2.5721487236320146

Epoch: 5| Step: 2
Training loss: 2.8458505774255265
Validation loss: 2.573982704107548

Epoch: 5| Step: 3
Training loss: 3.015224449950873
Validation loss: 2.5669033785053728

Epoch: 5| Step: 4
Training loss: 2.5494292387134
Validation loss: 2.5582480190677317

Epoch: 5| Step: 5
Training loss: 3.0805267413662327
Validation loss: 2.5493575664001074

Epoch: 5| Step: 6
Training loss: 3.145083929740169
Validation loss: 2.556770626672869

Epoch: 5| Step: 7
Training loss: 3.1232995556687992
Validation loss: 2.540154041449084

Epoch: 5| Step: 8
Training loss: 2.8846771908521
Validation loss: 2.5412360044521844

Epoch: 5| Step: 9
Training loss: 2.9345904611413127
Validation loss: 2.5346197134444948

Epoch: 5| Step: 10
Training loss: 2.964320683232013
Validation loss: 2.5484277041289167

Epoch: 112| Step: 0
Training loss: 2.6229913383279793
Validation loss: 2.5507546368686946

Epoch: 5| Step: 1
Training loss: 2.9269523365035472
Validation loss: 2.5560493794276384

Epoch: 5| Step: 2
Training loss: 2.650552271029791
Validation loss: 2.5529373615107027

Epoch: 5| Step: 3
Training loss: 3.1821936026706372
Validation loss: 2.5689266650574094

Epoch: 5| Step: 4
Training loss: 2.555762575121771
Validation loss: 2.5430624493311083

Epoch: 5| Step: 5
Training loss: 2.9560658177751313
Validation loss: 2.529712754590147

Epoch: 5| Step: 6
Training loss: 2.435340805329769
Validation loss: 2.5314213836392003

Epoch: 5| Step: 7
Training loss: 2.6344844591743377
Validation loss: 2.5261446371214618

Epoch: 5| Step: 8
Training loss: 3.2345504344594045
Validation loss: 2.52963065575847

Epoch: 5| Step: 9
Training loss: 3.375443606009959
Validation loss: 2.530431155434489

Epoch: 5| Step: 10
Training loss: 2.973674504531208
Validation loss: 2.5302488756969135

Epoch: 113| Step: 0
Training loss: 2.7155761609004148
Validation loss: 2.5270574007794453

Epoch: 5| Step: 1
Training loss: 2.8958001077698987
Validation loss: 2.5257020536593613

Epoch: 5| Step: 2
Training loss: 2.4286196407373057
Validation loss: 2.5353505130797194

Epoch: 5| Step: 3
Training loss: 2.443467294092017
Validation loss: 2.5381545828465595

Epoch: 5| Step: 4
Training loss: 3.589038181513172
Validation loss: 2.5495150590169384

Epoch: 5| Step: 5
Training loss: 2.147202903438032
Validation loss: 2.5507786519667826

Epoch: 5| Step: 6
Training loss: 2.8548067215200974
Validation loss: 2.5867781041616165

Epoch: 5| Step: 7
Training loss: 3.397018381863535
Validation loss: 2.614926273093501

Epoch: 5| Step: 8
Training loss: 3.4089842854789723
Validation loss: 2.6895422162361124

Epoch: 5| Step: 9
Training loss: 2.8766299064235348
Validation loss: 2.588938181922775

Epoch: 5| Step: 10
Training loss: 2.6594451536435257
Validation loss: 2.535188042041446

Epoch: 114| Step: 0
Training loss: 3.440201547396103
Validation loss: 2.5225031237902673

Epoch: 5| Step: 1
Training loss: 2.707455380284312
Validation loss: 2.530272337178472

Epoch: 5| Step: 2
Training loss: 2.7855027506233894
Validation loss: 2.5376331975532334

Epoch: 5| Step: 3
Training loss: 2.8809659673076937
Validation loss: 2.5449984268102064

Epoch: 5| Step: 4
Training loss: 2.6051361008892595
Validation loss: 2.572404741189593

Epoch: 5| Step: 5
Training loss: 3.2077815749753698
Validation loss: 2.5894366348213755

Epoch: 5| Step: 6
Training loss: 3.3666956425039927
Validation loss: 2.616064934300412

Epoch: 5| Step: 7
Training loss: 3.2935579073807126
Validation loss: 2.6120136809855503

Epoch: 5| Step: 8
Training loss: 2.0657056691725497
Validation loss: 2.6284228596631496

Epoch: 5| Step: 9
Training loss: 2.956074851011096
Validation loss: 2.6019454339675834

Epoch: 5| Step: 10
Training loss: 2.861667402027045
Validation loss: 2.569676121188374

Epoch: 115| Step: 0
Training loss: 3.029437752355699
Validation loss: 2.538770306026359

Epoch: 5| Step: 1
Training loss: 2.6239335754930715
Validation loss: 2.531968025428901

Epoch: 5| Step: 2
Training loss: 2.999524078765943
Validation loss: 2.5280523172118623

Epoch: 5| Step: 3
Training loss: 2.699932616770522
Validation loss: 2.5483416711560096

Epoch: 5| Step: 4
Training loss: 2.790433829702252
Validation loss: 2.5852338969244224

Epoch: 5| Step: 5
Training loss: 2.5840023671602914
Validation loss: 2.634604556581175

Epoch: 5| Step: 6
Training loss: 2.9890979722864968
Validation loss: 2.7741894070312276

Epoch: 5| Step: 7
Training loss: 3.286406325680923
Validation loss: 2.6928100725395274

Epoch: 5| Step: 8
Training loss: 2.888980542057647
Validation loss: 2.6564761659681295

Epoch: 5| Step: 9
Training loss: 3.243637018312527
Validation loss: 2.5510136039727693

Epoch: 5| Step: 10
Training loss: 2.9019919756010073
Validation loss: 2.5193735660789014

Epoch: 116| Step: 0
Training loss: 2.7884756801256745
Validation loss: 2.5217815189866513

Epoch: 5| Step: 1
Training loss: 3.1795762251145163
Validation loss: 2.521042698059628

Epoch: 5| Step: 2
Training loss: 2.5609160389213352
Validation loss: 2.5260858567210867

Epoch: 5| Step: 3
Training loss: 2.766127546093514
Validation loss: 2.526436640352568

Epoch: 5| Step: 4
Training loss: 2.902461710569709
Validation loss: 2.52736693008666

Epoch: 5| Step: 5
Training loss: 3.0138119005565085
Validation loss: 2.5212828375151344

Epoch: 5| Step: 6
Training loss: 3.266602000420374
Validation loss: 2.5340699298329126

Epoch: 5| Step: 7
Training loss: 2.48631517956788
Validation loss: 2.545379923582155

Epoch: 5| Step: 8
Training loss: 3.1505568118171277
Validation loss: 2.5751107502389585

Epoch: 5| Step: 9
Training loss: 2.8469538823242386
Validation loss: 2.627970146578397

Epoch: 5| Step: 10
Training loss: 2.8728166665609574
Validation loss: 2.5921030915622754

Epoch: 117| Step: 0
Training loss: 2.6755267613925553
Validation loss: 2.613112033019191

Epoch: 5| Step: 1
Training loss: 3.0230455563437975
Validation loss: 2.5990734225698064

Epoch: 5| Step: 2
Training loss: 3.4374227341724732
Validation loss: 2.5616437110072745

Epoch: 5| Step: 3
Training loss: 2.8385356004749305
Validation loss: 2.5508095457772746

Epoch: 5| Step: 4
Training loss: 2.636533377453668
Validation loss: 2.547899263841525

Epoch: 5| Step: 5
Training loss: 2.216197950480257
Validation loss: 2.5475527920083767

Epoch: 5| Step: 6
Training loss: 2.716514633074702
Validation loss: 2.5578308947122217

Epoch: 5| Step: 7
Training loss: 3.067453387838201
Validation loss: 2.582717526051518

Epoch: 5| Step: 8
Training loss: 3.0780484727360444
Validation loss: 2.590329267523108

Epoch: 5| Step: 9
Training loss: 3.070463298171382
Validation loss: 2.5628788345635147

Epoch: 5| Step: 10
Training loss: 2.8791104662241063
Validation loss: 2.55113618882503

Epoch: 118| Step: 0
Training loss: 3.4144405618315807
Validation loss: 2.5401823274328748

Epoch: 5| Step: 1
Training loss: 2.9436867676765215
Validation loss: 2.541030658632902

Epoch: 5| Step: 2
Training loss: 3.258144590434896
Validation loss: 2.5371340906646576

Epoch: 5| Step: 3
Training loss: 2.618720217879109
Validation loss: 2.5386135565802768

Epoch: 5| Step: 4
Training loss: 2.814509119222007
Validation loss: 2.538227174477734

Epoch: 5| Step: 5
Training loss: 2.7836042576885154
Validation loss: 2.551117170992866

Epoch: 5| Step: 6
Training loss: 2.396734471783402
Validation loss: 2.6031384153854678

Epoch: 5| Step: 7
Training loss: 3.1113958644736717
Validation loss: 2.607976446183525

Epoch: 5| Step: 8
Training loss: 3.077609875946422
Validation loss: 2.6263124141365575

Epoch: 5| Step: 9
Training loss: 2.4926954367644494
Validation loss: 2.6007101031097424

Epoch: 5| Step: 10
Training loss: 2.540665809894792
Validation loss: 2.549552758462463

Epoch: 119| Step: 0
Training loss: 2.3882076033697768
Validation loss: 2.5309757431985163

Epoch: 5| Step: 1
Training loss: 2.2377971771486993
Validation loss: 2.5235122257639526

Epoch: 5| Step: 2
Training loss: 3.031358697259801
Validation loss: 2.5215150573540774

Epoch: 5| Step: 3
Training loss: 2.5495033042214486
Validation loss: 2.5251290448284975

Epoch: 5| Step: 4
Training loss: 3.5486590902059016
Validation loss: 2.5194651895282467

Epoch: 5| Step: 5
Training loss: 3.0346319465003027
Validation loss: 2.5205834784502597

Epoch: 5| Step: 6
Training loss: 3.067282076605179
Validation loss: 2.521029749877487

Epoch: 5| Step: 7
Training loss: 2.9511500622229128
Validation loss: 2.518008990417062

Epoch: 5| Step: 8
Training loss: 2.904198527514818
Validation loss: 2.51889641253617

Epoch: 5| Step: 9
Training loss: 2.934986581333036
Validation loss: 2.5151322537689564

Epoch: 5| Step: 10
Training loss: 2.8755835894509194
Validation loss: 2.5169631220961235

Epoch: 120| Step: 0
Training loss: 2.85226373280755
Validation loss: 2.518699508328236

Epoch: 5| Step: 1
Training loss: 2.680543634874612
Validation loss: 2.518797164398461

Epoch: 5| Step: 2
Training loss: 3.1500347619939086
Validation loss: 2.5256691089077568

Epoch: 5| Step: 3
Training loss: 2.9195942672612585
Validation loss: 2.5354463084043433

Epoch: 5| Step: 4
Training loss: 2.881493905225984
Validation loss: 2.5438770592315976

Epoch: 5| Step: 5
Training loss: 2.642714717517961
Validation loss: 2.5696279840639193

Epoch: 5| Step: 6
Training loss: 2.8753975303141
Validation loss: 2.6060859633078444

Epoch: 5| Step: 7
Training loss: 2.7394572955439345
Validation loss: 2.703353582909522

Epoch: 5| Step: 8
Training loss: 3.41122772757478
Validation loss: 2.700655501790653

Epoch: 5| Step: 9
Training loss: 2.8422542453035917
Validation loss: 2.5522668438936065

Epoch: 5| Step: 10
Training loss: 2.794839299312999
Validation loss: 2.5139117706607514

Epoch: 121| Step: 0
Training loss: 3.023178050025463
Validation loss: 2.5092473939749818

Epoch: 5| Step: 1
Training loss: 2.5576813213847136
Validation loss: 2.525346676909352

Epoch: 5| Step: 2
Training loss: 2.7432594051882977
Validation loss: 2.5504483917528873

Epoch: 5| Step: 3
Training loss: 3.210473242840246
Validation loss: 2.579242199482184

Epoch: 5| Step: 4
Training loss: 3.084687648646046
Validation loss: 2.6043660799195996

Epoch: 5| Step: 5
Training loss: 3.262469797981164
Validation loss: 2.6052959781077836

Epoch: 5| Step: 6
Training loss: 2.7992003593298502
Validation loss: 2.5612134957969572

Epoch: 5| Step: 7
Training loss: 2.9351441696604774
Validation loss: 2.5584336638497236

Epoch: 5| Step: 8
Training loss: 2.742030560385076
Validation loss: 2.5385339633299746

Epoch: 5| Step: 9
Training loss: 3.014935824848367
Validation loss: 2.524023140144807

Epoch: 5| Step: 10
Training loss: 3.037230108382012
Validation loss: 2.5191069800049855

Epoch: 122| Step: 0
Training loss: 2.449564591468177
Validation loss: 2.511530473385461

Epoch: 5| Step: 1
Training loss: 3.0040038729158876
Validation loss: 2.5154570824945157

Epoch: 5| Step: 2
Training loss: 2.950411402577276
Validation loss: 2.5252867998057527

Epoch: 5| Step: 3
Training loss: 3.282014594232166
Validation loss: 2.561504219556714

Epoch: 5| Step: 4
Training loss: 2.508747342521199
Validation loss: 2.602555057752219

Epoch: 5| Step: 5
Training loss: 3.0559525858011996
Validation loss: 2.6108837033749124

Epoch: 5| Step: 6
Training loss: 2.956381319448059
Validation loss: 2.5983064957624373

Epoch: 5| Step: 7
Training loss: 2.7027929024851987
Validation loss: 2.574481529748301

Epoch: 5| Step: 8
Training loss: 2.656868447506797
Validation loss: 2.53451137170514

Epoch: 5| Step: 9
Training loss: 3.18081307698983
Validation loss: 2.5407306239256298

Epoch: 5| Step: 10
Training loss: 2.861309960213246
Validation loss: 2.525451728954532

Epoch: 123| Step: 0
Training loss: 3.0125213622289455
Validation loss: 2.5170670380406674

Epoch: 5| Step: 1
Training loss: 2.5294432608760875
Validation loss: 2.5198415654318054

Epoch: 5| Step: 2
Training loss: 2.6003087777403486
Validation loss: 2.5225838061924684

Epoch: 5| Step: 3
Training loss: 3.5572757897457885
Validation loss: 2.560834949458287

Epoch: 5| Step: 4
Training loss: 2.3417245887117986
Validation loss: 2.589910758229407

Epoch: 5| Step: 5
Training loss: 3.049775449897878
Validation loss: 2.580160868134264

Epoch: 5| Step: 6
Training loss: 2.43761297110877
Validation loss: 2.5924329758444498

Epoch: 5| Step: 7
Training loss: 2.704483132048644
Validation loss: 2.577576918031919

Epoch: 5| Step: 8
Training loss: 3.0132889470345043
Validation loss: 2.5332549285278705

Epoch: 5| Step: 9
Training loss: 3.117070016583081
Validation loss: 2.52373275215653

Epoch: 5| Step: 10
Training loss: 2.9821503821050435
Validation loss: 2.510855568509217

Epoch: 124| Step: 0
Training loss: 2.795119261952448
Validation loss: 2.5058511690346488

Epoch: 5| Step: 1
Training loss: 2.5185175786089338
Validation loss: 2.501459569324308

Epoch: 5| Step: 2
Training loss: 2.5217636745608165
Validation loss: 2.508506340806225

Epoch: 5| Step: 3
Training loss: 3.3306995158880244
Validation loss: 2.502442688356117

Epoch: 5| Step: 4
Training loss: 2.9014460740075
Validation loss: 2.5078885316048924

Epoch: 5| Step: 5
Training loss: 3.1360940465546387
Validation loss: 2.507742975018973

Epoch: 5| Step: 6
Training loss: 2.37794843662398
Validation loss: 2.520319546035487

Epoch: 5| Step: 7
Training loss: 3.366987253417044
Validation loss: 2.5473592370690437

Epoch: 5| Step: 8
Training loss: 2.454711303984031
Validation loss: 2.6514584992302503

Epoch: 5| Step: 9
Training loss: 3.0838088794370866
Validation loss: 2.657574589133951

Epoch: 5| Step: 10
Training loss: 2.655182118895646
Validation loss: 2.616937825797117

Epoch: 125| Step: 0
Training loss: 3.18083841175703
Validation loss: 2.6135395788777704

Epoch: 5| Step: 1
Training loss: 2.6657557322384964
Validation loss: 2.6616075681526943

Epoch: 5| Step: 2
Training loss: 3.3669317374043715
Validation loss: 2.6616874502929884

Epoch: 5| Step: 3
Training loss: 2.9117525574175156
Validation loss: 2.680721455995979

Epoch: 5| Step: 4
Training loss: 2.869990254827562
Validation loss: 2.63518631010365

Epoch: 5| Step: 5
Training loss: 2.134164123394618
Validation loss: 2.5784279365343354

Epoch: 5| Step: 6
Training loss: 3.2053955962321914
Validation loss: 2.5193895103432014

Epoch: 5| Step: 7
Training loss: 2.415873912704254
Validation loss: 2.501910023509615

Epoch: 5| Step: 8
Training loss: 2.3975862365424345
Validation loss: 2.5114621563198067

Epoch: 5| Step: 9
Training loss: 2.998406781888557
Validation loss: 2.5144352648219517

Epoch: 5| Step: 10
Training loss: 2.9156699157722326
Validation loss: 2.5210520240043253

Epoch: 126| Step: 0
Training loss: 2.8131098615861543
Validation loss: 2.5167264907067746

Epoch: 5| Step: 1
Training loss: 2.9365893636596994
Validation loss: 2.519262766478163

Epoch: 5| Step: 2
Training loss: 2.872492650539734
Validation loss: 2.522222308298808

Epoch: 5| Step: 3
Training loss: 2.6939492136494807
Validation loss: 2.522269052067709

Epoch: 5| Step: 4
Training loss: 2.888014320707875
Validation loss: 2.5201120757517144

Epoch: 5| Step: 5
Training loss: 3.0601613983274603
Validation loss: 2.5308778733110766

Epoch: 5| Step: 6
Training loss: 3.288920129879645
Validation loss: 2.523894166797115

Epoch: 5| Step: 7
Training loss: 2.858752907374963
Validation loss: 2.517952790467342

Epoch: 5| Step: 8
Training loss: 2.575709280455447
Validation loss: 2.5068941895774666

Epoch: 5| Step: 9
Training loss: 2.851360157097556
Validation loss: 2.516345891561552

Epoch: 5| Step: 10
Training loss: 3.1136633663613984
Validation loss: 2.5174697026155113

Epoch: 127| Step: 0
Training loss: 3.237951393031219
Validation loss: 2.5323273151120604

Epoch: 5| Step: 1
Training loss: 3.1257527779843928
Validation loss: 2.5831491756659872

Epoch: 5| Step: 2
Training loss: 2.8170018935246275
Validation loss: 2.6728968987766453

Epoch: 5| Step: 3
Training loss: 2.179127720423409
Validation loss: 2.6592125216609004

Epoch: 5| Step: 4
Training loss: 3.0674878976547406
Validation loss: 2.6483732068029067

Epoch: 5| Step: 5
Training loss: 2.528728877916055
Validation loss: 2.6064514942764636

Epoch: 5| Step: 6
Training loss: 3.679074116828404
Validation loss: 2.607164935082394

Epoch: 5| Step: 7
Training loss: 2.772082188377295
Validation loss: 2.5903072644899843

Epoch: 5| Step: 8
Training loss: 2.4559014031752007
Validation loss: 2.565748257890193

Epoch: 5| Step: 9
Training loss: 2.596912799656503
Validation loss: 2.5548204930087866

Epoch: 5| Step: 10
Training loss: 2.844808695819124
Validation loss: 2.5452702208265316

Epoch: 128| Step: 0
Training loss: 2.6637827259274935
Validation loss: 2.5195067157522235

Epoch: 5| Step: 1
Training loss: 2.7604875855362767
Validation loss: 2.5191909116287046

Epoch: 5| Step: 2
Training loss: 2.3895837847557626
Validation loss: 2.5152631155535223

Epoch: 5| Step: 3
Training loss: 3.2098894845352057
Validation loss: 2.517832089558285

Epoch: 5| Step: 4
Training loss: 2.8935904473300784
Validation loss: 2.5206905108591826

Epoch: 5| Step: 5
Training loss: 2.828477026174626
Validation loss: 2.515304674459505

Epoch: 5| Step: 6
Training loss: 3.165174350124652
Validation loss: 2.5090170319919616

Epoch: 5| Step: 7
Training loss: 2.7359568352835746
Validation loss: 2.511349886299029

Epoch: 5| Step: 8
Training loss: 3.286517320557985
Validation loss: 2.507392931772855

Epoch: 5| Step: 9
Training loss: 2.5792016757772696
Validation loss: 2.5014480662926353

Epoch: 5| Step: 10
Training loss: 2.9463578451015757
Validation loss: 2.5113087361259407

Epoch: 129| Step: 0
Training loss: 2.722375491319091
Validation loss: 2.536037219001032

Epoch: 5| Step: 1
Training loss: 2.4542102721333743
Validation loss: 2.57047912095496

Epoch: 5| Step: 2
Training loss: 2.98996438888726
Validation loss: 2.59885101290771

Epoch: 5| Step: 3
Training loss: 3.339155802228704
Validation loss: 2.6377258404711426

Epoch: 5| Step: 4
Training loss: 2.8026917563996188
Validation loss: 2.600544398788807

Epoch: 5| Step: 5
Training loss: 2.3658464617855928
Validation loss: 2.575779270015832

Epoch: 5| Step: 6
Training loss: 3.0413613536312676
Validation loss: 2.553779262230335

Epoch: 5| Step: 7
Training loss: 3.2257059729216913
Validation loss: 2.5225329248198856

Epoch: 5| Step: 8
Training loss: 2.6524156608440213
Validation loss: 2.5182951306145642

Epoch: 5| Step: 9
Training loss: 2.7753251649893818
Validation loss: 2.504853409422251

Epoch: 5| Step: 10
Training loss: 2.8669811039366113
Validation loss: 2.5044422848989436

Epoch: 130| Step: 0
Training loss: 2.772211023926866
Validation loss: 2.506153146920551

Epoch: 5| Step: 1
Training loss: 3.0100042111186736
Validation loss: 2.507899707628174

Epoch: 5| Step: 2
Training loss: 2.624203515697072
Validation loss: 2.4984674976180585

Epoch: 5| Step: 3
Training loss: 3.5642404153142055
Validation loss: 2.502738386562445

Epoch: 5| Step: 4
Training loss: 1.9501712283737567
Validation loss: 2.521303619298284

Epoch: 5| Step: 5
Training loss: 2.971403040750045
Validation loss: 2.509100305961605

Epoch: 5| Step: 6
Training loss: 2.9567322674354446
Validation loss: 2.5505079937661703

Epoch: 5| Step: 7
Training loss: 2.94521455070676
Validation loss: 2.5951722662872756

Epoch: 5| Step: 8
Training loss: 2.71212584204704
Validation loss: 2.5814592276603996

Epoch: 5| Step: 9
Training loss: 2.857362800034414
Validation loss: 2.5558881058038456

Epoch: 5| Step: 10
Training loss: 2.542990501299064
Validation loss: 2.5778263042064635

Epoch: 131| Step: 0
Training loss: 2.6636520472274023
Validation loss: 2.5288298834231977

Epoch: 5| Step: 1
Training loss: 3.2775977744409865
Validation loss: 2.4956924799189593

Epoch: 5| Step: 2
Training loss: 2.868706989173674
Validation loss: 2.5112794368693243

Epoch: 5| Step: 3
Training loss: 2.8722715284623304
Validation loss: 2.5067106861427786

Epoch: 5| Step: 4
Training loss: 2.8636346159209936
Validation loss: 2.503283491713217

Epoch: 5| Step: 5
Training loss: 3.008208172026996
Validation loss: 2.5029871650114255

Epoch: 5| Step: 6
Training loss: 2.823130713273999
Validation loss: 2.4986859498253655

Epoch: 5| Step: 7
Training loss: 2.979691110257711
Validation loss: 2.50046939339984

Epoch: 5| Step: 8
Training loss: 2.7285230523174233
Validation loss: 2.498013113961833

Epoch: 5| Step: 9
Training loss: 2.6113323248727447
Validation loss: 2.4880755449535306

Epoch: 5| Step: 10
Training loss: 2.67893210571307
Validation loss: 2.4985036135054957

Epoch: 132| Step: 0
Training loss: 2.609501270277069
Validation loss: 2.5271996253840094

Epoch: 5| Step: 1
Training loss: 2.8332319989502253
Validation loss: 2.535777101043846

Epoch: 5| Step: 2
Training loss: 2.8645294924213403
Validation loss: 2.6154654981850025

Epoch: 5| Step: 3
Training loss: 2.7797655580313223
Validation loss: 2.666475989718243

Epoch: 5| Step: 4
Training loss: 3.0450073778285454
Validation loss: 2.7287814286358816

Epoch: 5| Step: 5
Training loss: 2.865640082366423
Validation loss: 2.67504879398368

Epoch: 5| Step: 6
Training loss: 2.2780334579850803
Validation loss: 2.5864833524220443

Epoch: 5| Step: 7
Training loss: 2.686091830361813
Validation loss: 2.5383054401332776

Epoch: 5| Step: 8
Training loss: 3.6091864730677865
Validation loss: 2.500268281877491

Epoch: 5| Step: 9
Training loss: 2.943849235530448
Validation loss: 2.4918534455556105

Epoch: 5| Step: 10
Training loss: 2.64141978204257
Validation loss: 2.5022124457813866

Epoch: 133| Step: 0
Training loss: 2.763838454978602
Validation loss: 2.507021791892033

Epoch: 5| Step: 1
Training loss: 3.4371160119338695
Validation loss: 2.5020783891026457

Epoch: 5| Step: 2
Training loss: 3.1256192928842585
Validation loss: 2.5057587838270194

Epoch: 5| Step: 3
Training loss: 2.4890884694997446
Validation loss: 2.4970032953836085

Epoch: 5| Step: 4
Training loss: 2.411846637702403
Validation loss: 2.4944190566303774

Epoch: 5| Step: 5
Training loss: 2.9106806954561124
Validation loss: 2.4849016814508103

Epoch: 5| Step: 6
Training loss: 2.983382454437547
Validation loss: 2.4837014509422626

Epoch: 5| Step: 7
Training loss: 3.0343539676271276
Validation loss: 2.5025951103669843

Epoch: 5| Step: 8
Training loss: 2.419199394646826
Validation loss: 2.5190188943330116

Epoch: 5| Step: 9
Training loss: 2.894019530825562
Validation loss: 2.549873972494311

Epoch: 5| Step: 10
Training loss: 2.748304711496061
Validation loss: 2.5806024117800064

Epoch: 134| Step: 0
Training loss: 2.8659477359987
Validation loss: 2.627460985412838

Epoch: 5| Step: 1
Training loss: 2.6504909240590293
Validation loss: 2.6726729750918135

Epoch: 5| Step: 2
Training loss: 3.01173458268374
Validation loss: 2.7373322783169227

Epoch: 5| Step: 3
Training loss: 3.185614832487116
Validation loss: 2.7830812426888563

Epoch: 5| Step: 4
Training loss: 2.705931601173746
Validation loss: 2.861728212951778

Epoch: 5| Step: 5
Training loss: 2.8463635853119746
Validation loss: 2.8279607626898655

Epoch: 5| Step: 6
Training loss: 3.524504032820528
Validation loss: 2.705257902283105

Epoch: 5| Step: 7
Training loss: 2.441099394778506
Validation loss: 2.5373311758343835

Epoch: 5| Step: 8
Training loss: 2.6540779657877844
Validation loss: 2.4849646909323866

Epoch: 5| Step: 9
Training loss: 2.6027279554457077
Validation loss: 2.4807295343307065

Epoch: 5| Step: 10
Training loss: 3.0285909729195852
Validation loss: 2.5092060831425

Epoch: 135| Step: 0
Training loss: 3.20280819698584
Validation loss: 2.530220315537963

Epoch: 5| Step: 1
Training loss: 2.497950858507051
Validation loss: 2.5337982577954716

Epoch: 5| Step: 2
Training loss: 2.781031224936582
Validation loss: 2.5266633006662302

Epoch: 5| Step: 3
Training loss: 2.2698594084235237
Validation loss: 2.5155734673018335

Epoch: 5| Step: 4
Training loss: 2.7093664008579386
Validation loss: 2.502313039156944

Epoch: 5| Step: 5
Training loss: 2.8351676463457576
Validation loss: 2.4886430476781043

Epoch: 5| Step: 6
Training loss: 3.0617298014081933
Validation loss: 2.4836543209049577

Epoch: 5| Step: 7
Training loss: 3.422169572527037
Validation loss: 2.481456008409422

Epoch: 5| Step: 8
Training loss: 2.6173014601763325
Validation loss: 2.491038474148448

Epoch: 5| Step: 9
Training loss: 3.3331694721636302
Validation loss: 2.5009024857425506

Epoch: 5| Step: 10
Training loss: 2.8625683905414983
Validation loss: 2.544030406830038

Epoch: 136| Step: 0
Training loss: 3.4068058505307355
Validation loss: 2.6197890375830704

Epoch: 5| Step: 1
Training loss: 2.569540354224569
Validation loss: 2.6047777127616323

Epoch: 5| Step: 2
Training loss: 2.7247321425914235
Validation loss: 2.5844565828116006

Epoch: 5| Step: 3
Training loss: 2.34456905040884
Validation loss: 2.5810581946744033

Epoch: 5| Step: 4
Training loss: 3.238237958188456
Validation loss: 2.557378760211599

Epoch: 5| Step: 5
Training loss: 2.5836194300406254
Validation loss: 2.542563074745047

Epoch: 5| Step: 6
Training loss: 2.786674609956265
Validation loss: 2.5108539379353694

Epoch: 5| Step: 7
Training loss: 3.14816093649999
Validation loss: 2.498967840562546

Epoch: 5| Step: 8
Training loss: 2.42642247667401
Validation loss: 2.495373801687115

Epoch: 5| Step: 9
Training loss: 2.6826619803095104
Validation loss: 2.4853421603578862

Epoch: 5| Step: 10
Training loss: 3.22676170787134
Validation loss: 2.488231337307765

Epoch: 137| Step: 0
Training loss: 2.763252663242054
Validation loss: 2.4897613983449407

Epoch: 5| Step: 1
Training loss: 3.018963008971149
Validation loss: 2.480212066601136

Epoch: 5| Step: 2
Training loss: 2.8524999462398486
Validation loss: 2.487572991585467

Epoch: 5| Step: 3
Training loss: 2.739514996700105
Validation loss: 2.491118149306417

Epoch: 5| Step: 4
Training loss: 2.6995333586212786
Validation loss: 2.5236929421295615

Epoch: 5| Step: 5
Training loss: 2.682821504181208
Validation loss: 2.5588459320522623

Epoch: 5| Step: 6
Training loss: 2.6430200854262447
Validation loss: 2.6110355192000467

Epoch: 5| Step: 7
Training loss: 3.139087813234019
Validation loss: 2.588622347069437

Epoch: 5| Step: 8
Training loss: 3.0105367634366975
Validation loss: 2.564417454056955

Epoch: 5| Step: 9
Training loss: 3.0561705596522355
Validation loss: 2.52912179658724

Epoch: 5| Step: 10
Training loss: 2.3220883134119648
Validation loss: 2.5206750965684934

Epoch: 138| Step: 0
Training loss: 3.207142613065336
Validation loss: 2.496244347525088

Epoch: 5| Step: 1
Training loss: 2.798687565981594
Validation loss: 2.4892007852468927

Epoch: 5| Step: 2
Training loss: 2.566868291919935
Validation loss: 2.485582395336343

Epoch: 5| Step: 3
Training loss: 2.739869618898763
Validation loss: 2.493655954831246

Epoch: 5| Step: 4
Training loss: 3.05959088476566
Validation loss: 2.5049894790439935

Epoch: 5| Step: 5
Training loss: 2.721322344482878
Validation loss: 2.523287432237895

Epoch: 5| Step: 6
Training loss: 2.5026427605729786
Validation loss: 2.538073867152819

Epoch: 5| Step: 7
Training loss: 3.2112132601420007
Validation loss: 2.5481983548856983

Epoch: 5| Step: 8
Training loss: 2.5935099846886907
Validation loss: 2.5473287049813145

Epoch: 5| Step: 9
Training loss: 2.7549361230884037
Validation loss: 2.5291980197820982

Epoch: 5| Step: 10
Training loss: 2.7066983104916873
Validation loss: 2.495331935496224

Epoch: 139| Step: 0
Training loss: 2.623215568384133
Validation loss: 2.476617568911798

Epoch: 5| Step: 1
Training loss: 2.7295858240870774
Validation loss: 2.4749496403046787

Epoch: 5| Step: 2
Training loss: 2.913778746343243
Validation loss: 2.481899977633963

Epoch: 5| Step: 3
Training loss: 3.2692955597546165
Validation loss: 2.481893447412131

Epoch: 5| Step: 4
Training loss: 2.726722515843107
Validation loss: 2.480828944441166

Epoch: 5| Step: 5
Training loss: 2.6176528744655028
Validation loss: 2.4801621879135536

Epoch: 5| Step: 6
Training loss: 2.73756066172376
Validation loss: 2.4876968713179695

Epoch: 5| Step: 7
Training loss: 2.892895770613976
Validation loss: 2.499417464774506

Epoch: 5| Step: 8
Training loss: 2.520952353281809
Validation loss: 2.5168722672455535

Epoch: 5| Step: 9
Training loss: 2.9115937030328474
Validation loss: 2.538681309106796

Epoch: 5| Step: 10
Training loss: 2.789857467921022
Validation loss: 2.559681902744518

Epoch: 140| Step: 0
Training loss: 3.019574677030455
Validation loss: 2.6074577874443565

Epoch: 5| Step: 1
Training loss: 2.7450371089018173
Validation loss: 2.5836082590731317

Epoch: 5| Step: 2
Training loss: 2.896662330433973
Validation loss: 2.583923179882743

Epoch: 5| Step: 3
Training loss: 3.0488187409769103
Validation loss: 2.5552665618901975

Epoch: 5| Step: 4
Training loss: 2.7578756092836634
Validation loss: 2.516883240404867

Epoch: 5| Step: 5
Training loss: 2.8337954163077503
Validation loss: 2.485033688479771

Epoch: 5| Step: 6
Training loss: 3.0444734939371116
Validation loss: 2.473457221599704

Epoch: 5| Step: 7
Training loss: 2.6478591332436765
Validation loss: 2.4721399348247384

Epoch: 5| Step: 8
Training loss: 2.3644576746507524
Validation loss: 2.4796652440334035

Epoch: 5| Step: 9
Training loss: 2.7675638245594723
Validation loss: 2.470670114069948

Epoch: 5| Step: 10
Training loss: 2.8862674344850894
Validation loss: 2.475088785351709

Epoch: 141| Step: 0
Training loss: 2.2128506528067358
Validation loss: 2.4847134822441515

Epoch: 5| Step: 1
Training loss: 2.4388996898360786
Validation loss: 2.486493475184716

Epoch: 5| Step: 2
Training loss: 2.8744458203467476
Validation loss: 2.5070048874972

Epoch: 5| Step: 3
Training loss: 2.9412389456901544
Validation loss: 2.511916791317902

Epoch: 5| Step: 4
Training loss: 2.2919683662415165
Validation loss: 2.535327716414062

Epoch: 5| Step: 5
Training loss: 2.8917455202577327
Validation loss: 2.5542697249417876

Epoch: 5| Step: 6
Training loss: 2.8403083179907704
Validation loss: 2.5619487194466695

Epoch: 5| Step: 7
Training loss: 3.1178546851199487
Validation loss: 2.5514282145812204

Epoch: 5| Step: 8
Training loss: 3.0984007432597416
Validation loss: 2.5337282337151246

Epoch: 5| Step: 9
Training loss: 2.811314142088246
Validation loss: 2.5043149718871556

Epoch: 5| Step: 10
Training loss: 3.130196789780001
Validation loss: 2.488727934582183

Epoch: 142| Step: 0
Training loss: 2.514649290806894
Validation loss: 2.4846578106713846

Epoch: 5| Step: 1
Training loss: 2.9254036062499904
Validation loss: 2.484400576682147

Epoch: 5| Step: 2
Training loss: 3.3548866273283457
Validation loss: 2.4859317198386237

Epoch: 5| Step: 3
Training loss: 2.21316405422653
Validation loss: 2.4878764363571695

Epoch: 5| Step: 4
Training loss: 2.734241068148527
Validation loss: 2.4971738746164753

Epoch: 5| Step: 5
Training loss: 2.879025998982959
Validation loss: 2.510288882374368

Epoch: 5| Step: 6
Training loss: 2.8423810745094493
Validation loss: 2.5294568541660998

Epoch: 5| Step: 7
Training loss: 2.6158610612271223
Validation loss: 2.577395531654903

Epoch: 5| Step: 8
Training loss: 2.8037185057641234
Validation loss: 2.5687278652592296

Epoch: 5| Step: 9
Training loss: 2.9059100208568753
Validation loss: 2.55385123607666

Epoch: 5| Step: 10
Training loss: 2.915503424330892
Validation loss: 2.551345650943117

Epoch: 143| Step: 0
Training loss: 3.0318807358649167
Validation loss: 2.506001162799097

Epoch: 5| Step: 1
Training loss: 2.9746941737851422
Validation loss: 2.4829856840501545

Epoch: 5| Step: 2
Training loss: 2.5197397071892333
Validation loss: 2.4721748269465467

Epoch: 5| Step: 3
Training loss: 2.7612126384398894
Validation loss: 2.4743145782156475

Epoch: 5| Step: 4
Training loss: 3.0168893960182923
Validation loss: 2.4655017722329315

Epoch: 5| Step: 5
Training loss: 2.6736999882269283
Validation loss: 2.463661394555296

Epoch: 5| Step: 6
Training loss: 2.094194051996374
Validation loss: 2.4669706454406084

Epoch: 5| Step: 7
Training loss: 3.0098052322385818
Validation loss: 2.4698022126836587

Epoch: 5| Step: 8
Training loss: 2.5803461852432634
Validation loss: 2.4756788180334524

Epoch: 5| Step: 9
Training loss: 3.116096630767453
Validation loss: 2.4918156643253635

Epoch: 5| Step: 10
Training loss: 2.7494091786425687
Validation loss: 2.5018314749128834

Epoch: 144| Step: 0
Training loss: 2.7540694384550792
Validation loss: 2.5088496695296616

Epoch: 5| Step: 1
Training loss: 1.9941286690079882
Validation loss: 2.5324801068172063

Epoch: 5| Step: 2
Training loss: 2.3751702498600626
Validation loss: 2.515714471186814

Epoch: 5| Step: 3
Training loss: 3.4172161559833856
Validation loss: 2.5196066288420824

Epoch: 5| Step: 4
Training loss: 2.950756273474517
Validation loss: 2.525618334354414

Epoch: 5| Step: 5
Training loss: 2.7080163525660956
Validation loss: 2.5470490191400126

Epoch: 5| Step: 6
Training loss: 2.8273997351612907
Validation loss: 2.5576246991380995

Epoch: 5| Step: 7
Training loss: 2.947751601128074
Validation loss: 2.5541642823476076

Epoch: 5| Step: 8
Training loss: 3.038758407323796
Validation loss: 2.5417540605980244

Epoch: 5| Step: 9
Training loss: 2.728541926350731
Validation loss: 2.521445486221704

Epoch: 5| Step: 10
Training loss: 2.567778384560154
Validation loss: 2.504164873028717

Epoch: 145| Step: 0
Training loss: 2.8980197656877524
Validation loss: 2.4963938751389563

Epoch: 5| Step: 1
Training loss: 3.2415822394849463
Validation loss: 2.4825176731950207

Epoch: 5| Step: 2
Training loss: 2.014675656096429
Validation loss: 2.476465196070524

Epoch: 5| Step: 3
Training loss: 2.4895592107096287
Validation loss: 2.484076048229265

Epoch: 5| Step: 4
Training loss: 2.5794279562909983
Validation loss: 2.4928510391216503

Epoch: 5| Step: 5
Training loss: 3.3258821335470623
Validation loss: 2.5025882530715893

Epoch: 5| Step: 6
Training loss: 2.4897427900209745
Validation loss: 2.516197681049255

Epoch: 5| Step: 7
Training loss: 3.036578342341064
Validation loss: 2.522988727041398

Epoch: 5| Step: 8
Training loss: 2.6097062865695526
Validation loss: 2.5264251333349184

Epoch: 5| Step: 9
Training loss: 2.8023582711227744
Validation loss: 2.5421242734862948

Epoch: 5| Step: 10
Training loss: 2.7257107603930595
Validation loss: 2.511792957871658

Epoch: 146| Step: 0
Training loss: 2.5469392171615577
Validation loss: 2.4983185722974914

Epoch: 5| Step: 1
Training loss: 2.711770405190814
Validation loss: 2.4835723882743945

Epoch: 5| Step: 2
Training loss: 2.90648297432297
Validation loss: 2.4766319810944304

Epoch: 5| Step: 3
Training loss: 2.8464830281555584
Validation loss: 2.466543519766025

Epoch: 5| Step: 4
Training loss: 2.9807060017280795
Validation loss: 2.471164534570843

Epoch: 5| Step: 5
Training loss: 2.62109138500033
Validation loss: 2.472072650447765

Epoch: 5| Step: 6
Training loss: 2.5833933320820215
Validation loss: 2.4897740787383515

Epoch: 5| Step: 7
Training loss: 2.61145685716021
Validation loss: 2.5176054263956202

Epoch: 5| Step: 8
Training loss: 2.701078224351557
Validation loss: 2.54398361648652

Epoch: 5| Step: 9
Training loss: 2.740942169592562
Validation loss: 2.5897213738922216

Epoch: 5| Step: 10
Training loss: 3.273184463808701
Validation loss: 2.522991141323781

Epoch: 147| Step: 0
Training loss: 2.901650511557714
Validation loss: 2.4811761375958477

Epoch: 5| Step: 1
Training loss: 2.758346635569356
Validation loss: 2.4726484315073987

Epoch: 5| Step: 2
Training loss: 2.484450237166571
Validation loss: 2.4888764820153435

Epoch: 5| Step: 3
Training loss: 2.7638235313402584
Validation loss: 2.486578574654795

Epoch: 5| Step: 4
Training loss: 2.6372520077081454
Validation loss: 2.4778285342584625

Epoch: 5| Step: 5
Training loss: 2.5898720119769685
Validation loss: 2.478832974876703

Epoch: 5| Step: 6
Training loss: 2.7288504458579945
Validation loss: 2.4814827805241926

Epoch: 5| Step: 7
Training loss: 3.3199584772202058
Validation loss: 2.50773658569816

Epoch: 5| Step: 8
Training loss: 2.5948140363266257
Validation loss: 2.5095980764861547

Epoch: 5| Step: 9
Training loss: 2.593334210631836
Validation loss: 2.5847407026051346

Epoch: 5| Step: 10
Training loss: 3.1776300845766707
Validation loss: 2.596839946149269

Epoch: 148| Step: 0
Training loss: 2.2151329753218327
Validation loss: 2.6288647833304126

Epoch: 5| Step: 1
Training loss: 3.002950647792703
Validation loss: 2.686145040261582

Epoch: 5| Step: 2
Training loss: 2.929785480132415
Validation loss: 2.702283111809204

Epoch: 5| Step: 3
Training loss: 2.8026237014026374
Validation loss: 2.625012837704286

Epoch: 5| Step: 4
Training loss: 2.433377913062322
Validation loss: 2.5540153705787967

Epoch: 5| Step: 5
Training loss: 2.7076354570397756
Validation loss: 2.514394079498466

Epoch: 5| Step: 6
Training loss: 3.145537524599659
Validation loss: 2.4799368215234847

Epoch: 5| Step: 7
Training loss: 2.2703027251125705
Validation loss: 2.4772702475788564

Epoch: 5| Step: 8
Training loss: 2.5076659923314066
Validation loss: 2.4715858839344005

Epoch: 5| Step: 9
Training loss: 2.9205619595248837
Validation loss: 2.4762387322689112

Epoch: 5| Step: 10
Training loss: 3.548563282331792
Validation loss: 2.4793376565483087

Epoch: 149| Step: 0
Training loss: 3.4526347507087625
Validation loss: 2.46588303918207

Epoch: 5| Step: 1
Training loss: 2.799783824341303
Validation loss: 2.466926498358372

Epoch: 5| Step: 2
Training loss: 2.326325405893166
Validation loss: 2.483620623308941

Epoch: 5| Step: 3
Training loss: 2.558969438067
Validation loss: 2.5211284616897576

Epoch: 5| Step: 4
Training loss: 2.685124434104225
Validation loss: 2.54483427689428

Epoch: 5| Step: 5
Training loss: 2.8611034734761867
Validation loss: 2.577194527736597

Epoch: 5| Step: 6
Training loss: 2.8686639378090173
Validation loss: 2.574374318372391

Epoch: 5| Step: 7
Training loss: 2.704053862520559
Validation loss: 2.5612673882534525

Epoch: 5| Step: 8
Training loss: 2.4643182693131793
Validation loss: 2.545439904119504

Epoch: 5| Step: 9
Training loss: 2.859960610712011
Validation loss: 2.5153603312315878

Epoch: 5| Step: 10
Training loss: 2.8969087502037127
Validation loss: 2.4937656993928465

Epoch: 150| Step: 0
Training loss: 2.996663145148811
Validation loss: 2.480820857190991

Epoch: 5| Step: 1
Training loss: 2.4667538648949887
Validation loss: 2.4599487443511925

Epoch: 5| Step: 2
Training loss: 2.7233701889115354
Validation loss: 2.4538762180947713

Epoch: 5| Step: 3
Training loss: 3.372689197795545
Validation loss: 2.464384438533661

Epoch: 5| Step: 4
Training loss: 2.671642806465594
Validation loss: 2.464388703142513

Epoch: 5| Step: 5
Training loss: 2.847283316683014
Validation loss: 2.4707078788322807

Epoch: 5| Step: 6
Training loss: 2.2953908887426566
Validation loss: 2.4958666441484145

Epoch: 5| Step: 7
Training loss: 2.904705991065404
Validation loss: 2.54270537878084

Epoch: 5| Step: 8
Training loss: 2.6377895865175596
Validation loss: 2.569626349880013

Epoch: 5| Step: 9
Training loss: 3.044402385879041
Validation loss: 2.5927019973391574

Epoch: 5| Step: 10
Training loss: 2.2946382387887683
Validation loss: 2.5633286587676674

Epoch: 151| Step: 0
Training loss: 2.924553933324421
Validation loss: 2.556312013165688

Epoch: 5| Step: 1
Training loss: 2.9161099765483307
Validation loss: 2.523708976940373

Epoch: 5| Step: 2
Training loss: 2.583174690379663
Validation loss: 2.487683867054425

Epoch: 5| Step: 3
Training loss: 2.2108207105651774
Validation loss: 2.494244729137789

Epoch: 5| Step: 4
Training loss: 2.594472945240791
Validation loss: 2.485130741505177

Epoch: 5| Step: 5
Training loss: 2.822157069035731
Validation loss: 2.495918766558873

Epoch: 5| Step: 6
Training loss: 2.8022518367279754
Validation loss: 2.4844134258059727

Epoch: 5| Step: 7
Training loss: 2.6275561466624313
Validation loss: 2.48585682349115

Epoch: 5| Step: 8
Training loss: 3.200524889097859
Validation loss: 2.4901244073724023

Epoch: 5| Step: 9
Training loss: 2.641823490995275
Validation loss: 2.4947613537387348

Epoch: 5| Step: 10
Training loss: 2.7327624988725496
Validation loss: 2.503272574664127

Epoch: 152| Step: 0
Training loss: 3.161320004063306
Validation loss: 2.5243566442941403

Epoch: 5| Step: 1
Training loss: 2.8428408668145253
Validation loss: 2.580615570683185

Epoch: 5| Step: 2
Training loss: 2.7980590530337124
Validation loss: 2.6080345133083056

Epoch: 5| Step: 3
Training loss: 2.9361963828929385
Validation loss: 2.6387999610474875

Epoch: 5| Step: 4
Training loss: 2.687486249311888
Validation loss: 2.595276384564827

Epoch: 5| Step: 5
Training loss: 2.615587525458194
Validation loss: 2.5434701157310426

Epoch: 5| Step: 6
Training loss: 2.3599039457461384
Validation loss: 2.500098617208352

Epoch: 5| Step: 7
Training loss: 2.760168781786537
Validation loss: 2.4800654593692983

Epoch: 5| Step: 8
Training loss: 2.5549325621302983
Validation loss: 2.469810681664687

Epoch: 5| Step: 9
Training loss: 2.730965630503961
Validation loss: 2.468817415429378

Epoch: 5| Step: 10
Training loss: 2.616716120388245
Validation loss: 2.46377907995887

Epoch: 153| Step: 0
Training loss: 2.7350396792586285
Validation loss: 2.476904317590886

Epoch: 5| Step: 1
Training loss: 3.074432016655535
Validation loss: 2.465171584016737

Epoch: 5| Step: 2
Training loss: 2.9532976049611457
Validation loss: 2.4625228210744314

Epoch: 5| Step: 3
Training loss: 2.8400240792341678
Validation loss: 2.4813398314000237

Epoch: 5| Step: 4
Training loss: 2.8843738493911912
Validation loss: 2.4877171458381158

Epoch: 5| Step: 5
Training loss: 3.0120635670189126
Validation loss: 2.4968843909130687

Epoch: 5| Step: 6
Training loss: 2.5357257221048455
Validation loss: 2.5081289947365026

Epoch: 5| Step: 7
Training loss: 2.493893030792549
Validation loss: 2.5156034971732293

Epoch: 5| Step: 8
Training loss: 2.6013456603631018
Validation loss: 2.561495602361071

Epoch: 5| Step: 9
Training loss: 2.4216657978886804
Validation loss: 2.569216192724589

Epoch: 5| Step: 10
Training loss: 2.4098860776258717
Validation loss: 2.595112066016799

Epoch: 154| Step: 0
Training loss: 2.805994011092915
Validation loss: 2.554693708675362

Epoch: 5| Step: 1
Training loss: 2.772405469983844
Validation loss: 2.530594703828629

Epoch: 5| Step: 2
Training loss: 3.352530670822224
Validation loss: 2.4973991606426047

Epoch: 5| Step: 3
Training loss: 2.4541330392430236
Validation loss: 2.483933251442636

Epoch: 5| Step: 4
Training loss: 2.5138921040982174
Validation loss: 2.484699788620112

Epoch: 5| Step: 5
Training loss: 2.5625382397287306
Validation loss: 2.4897364945438976

Epoch: 5| Step: 6
Training loss: 3.1698427501870006
Validation loss: 2.4779923359174036

Epoch: 5| Step: 7
Training loss: 2.4990811566763953
Validation loss: 2.479400208757398

Epoch: 5| Step: 8
Training loss: 2.3111713819816284
Validation loss: 2.4801365850949306

Epoch: 5| Step: 9
Training loss: 2.3577198007813784
Validation loss: 2.4935235684034245

Epoch: 5| Step: 10
Training loss: 3.0121767559190356
Validation loss: 2.526123543518073

Epoch: 155| Step: 0
Training loss: 3.003047507851253
Validation loss: 2.5364243521385754

Epoch: 5| Step: 1
Training loss: 2.398156662195847
Validation loss: 2.5479550779460087

Epoch: 5| Step: 2
Training loss: 2.238707709836862
Validation loss: 2.5769718717432486

Epoch: 5| Step: 3
Training loss: 2.7040938035957662
Validation loss: 2.603420768645419

Epoch: 5| Step: 4
Training loss: 2.7265563789889207
Validation loss: 2.622249818961635

Epoch: 5| Step: 5
Training loss: 2.848488349900101
Validation loss: 2.6001025570519904

Epoch: 5| Step: 6
Training loss: 2.5429483111097784
Validation loss: 2.550825807114126

Epoch: 5| Step: 7
Training loss: 3.162471569069183
Validation loss: 2.484271432693054

Epoch: 5| Step: 8
Training loss: 2.509672336848435
Validation loss: 2.4800564982183997

Epoch: 5| Step: 9
Training loss: 3.1357020420390316
Validation loss: 2.494029855662619

Epoch: 5| Step: 10
Training loss: 2.7688531516258776
Validation loss: 2.489525872108583

Epoch: 156| Step: 0
Training loss: 3.1322725739239163
Validation loss: 2.47284767145927

Epoch: 5| Step: 1
Training loss: 2.633394624101435
Validation loss: 2.476737304555396

Epoch: 5| Step: 2
Training loss: 2.53680667143287
Validation loss: 2.484446926911242

Epoch: 5| Step: 3
Training loss: 2.858224439261275
Validation loss: 2.4898140017346937

Epoch: 5| Step: 4
Training loss: 2.168746011603918
Validation loss: 2.511147755964616

Epoch: 5| Step: 5
Training loss: 3.027389427578788
Validation loss: 2.575439394768577

Epoch: 5| Step: 6
Training loss: 2.9369386177129866
Validation loss: 2.6421632848487357

Epoch: 5| Step: 7
Training loss: 3.195835061468646
Validation loss: 2.6208190397449305

Epoch: 5| Step: 8
Training loss: 2.1280762340543107
Validation loss: 2.6004123669946066

Epoch: 5| Step: 9
Training loss: 2.926752761872102
Validation loss: 2.5460856341984006

Epoch: 5| Step: 10
Training loss: 2.4311831859831896
Validation loss: 2.50481381005747

Epoch: 157| Step: 0
Training loss: 2.969643548710263
Validation loss: 2.488994521722121

Epoch: 5| Step: 1
Training loss: 2.80184631101517
Validation loss: 2.4869680052106657

Epoch: 5| Step: 2
Training loss: 2.842347522360032
Validation loss: 2.480167111223927

Epoch: 5| Step: 3
Training loss: 2.957263771096657
Validation loss: 2.4824572969592267

Epoch: 5| Step: 4
Training loss: 2.6337170051785557
Validation loss: 2.4806084091406437

Epoch: 5| Step: 5
Training loss: 2.839383472360293
Validation loss: 2.484757125524268

Epoch: 5| Step: 6
Training loss: 2.696965603505484
Validation loss: 2.4923940660335493

Epoch: 5| Step: 7
Training loss: 2.7525146431321192
Validation loss: 2.5036632811647372

Epoch: 5| Step: 8
Training loss: 3.05490899807363
Validation loss: 2.5311463412145407

Epoch: 5| Step: 9
Training loss: 2.265603953296639
Validation loss: 2.5496160102674104

Epoch: 5| Step: 10
Training loss: 1.5748251984490742
Validation loss: 2.597269121378732

Epoch: 158| Step: 0
Training loss: 2.112942088440666
Validation loss: 2.596403131710229

Epoch: 5| Step: 1
Training loss: 2.6405498787391566
Validation loss: 2.6034339126554973

Epoch: 5| Step: 2
Training loss: 2.706294676519848
Validation loss: 2.5999429432246073

Epoch: 5| Step: 3
Training loss: 2.5571633570245913
Validation loss: 2.595745603386863

Epoch: 5| Step: 4
Training loss: 2.851515510903516
Validation loss: 2.5983258045933635

Epoch: 5| Step: 5
Training loss: 2.983972492336679
Validation loss: 2.591166383106609

Epoch: 5| Step: 6
Training loss: 2.6253187803436924
Validation loss: 2.5639185096908803

Epoch: 5| Step: 7
Training loss: 2.952049907386507
Validation loss: 2.5320166638732897

Epoch: 5| Step: 8
Training loss: 2.504291475034636
Validation loss: 2.5166026402753827

Epoch: 5| Step: 9
Training loss: 3.054719812558878
Validation loss: 2.5066212924469355

Epoch: 5| Step: 10
Training loss: 2.535513125371163
Validation loss: 2.508777124037235

Epoch: 159| Step: 0
Training loss: 2.579818908930384
Validation loss: 2.499265769074064

Epoch: 5| Step: 1
Training loss: 2.0805862880599277
Validation loss: 2.4870955774299506

Epoch: 5| Step: 2
Training loss: 2.883845115915189
Validation loss: 2.490811930433331

Epoch: 5| Step: 3
Training loss: 2.7499512754805475
Validation loss: 2.496426524351306

Epoch: 5| Step: 4
Training loss: 2.5387208679421036
Validation loss: 2.5062720172315855

Epoch: 5| Step: 5
Training loss: 2.878266179270164
Validation loss: 2.508265222926057

Epoch: 5| Step: 6
Training loss: 3.0064275550355037
Validation loss: 2.520582058603083

Epoch: 5| Step: 7
Training loss: 2.285258285983181
Validation loss: 2.5564389744633145

Epoch: 5| Step: 8
Training loss: 2.8501752431431258
Validation loss: 2.5930586940202853

Epoch: 5| Step: 9
Training loss: 2.840825012350014
Validation loss: 2.6197846438109225

Epoch: 5| Step: 10
Training loss: 2.7409946205451003
Validation loss: 2.618372348224675

Epoch: 160| Step: 0
Training loss: 2.9357119048754994
Validation loss: 2.5838547245611103

Epoch: 5| Step: 1
Training loss: 2.552818618003116
Validation loss: 2.5699849814446227

Epoch: 5| Step: 2
Training loss: 2.5345982200448347
Validation loss: 2.5366676227207776

Epoch: 5| Step: 3
Training loss: 3.183348551475805
Validation loss: 2.4998815395633085

Epoch: 5| Step: 4
Training loss: 2.4546655567725453
Validation loss: 2.494725717012018

Epoch: 5| Step: 5
Training loss: 2.721297375148791
Validation loss: 2.4914090819529187

Epoch: 5| Step: 6
Training loss: 2.6554544491676
Validation loss: 2.4874522068484195

Epoch: 5| Step: 7
Training loss: 2.8148140606358654
Validation loss: 2.4894351126491454

Epoch: 5| Step: 8
Training loss: 2.5810565349501524
Validation loss: 2.503541858560936

Epoch: 5| Step: 9
Training loss: 2.455838688781028
Validation loss: 2.5101672599125164

Epoch: 5| Step: 10
Training loss: 2.530519733345229
Validation loss: 2.523325066344515

Epoch: 161| Step: 0
Training loss: 2.802493626691937
Validation loss: 2.5435275630785297

Epoch: 5| Step: 1
Training loss: 2.475773153054072
Validation loss: 2.5694297443853684

Epoch: 5| Step: 2
Training loss: 2.7102507235263307
Validation loss: 2.5955730712347216

Epoch: 5| Step: 3
Training loss: 2.704557270901412
Validation loss: 2.6163239289937454

Epoch: 5| Step: 4
Training loss: 2.842984442315083
Validation loss: 2.621473552213031

Epoch: 5| Step: 5
Training loss: 2.918103726902441
Validation loss: 2.6149001181890137

Epoch: 5| Step: 6
Training loss: 2.4232161223423376
Validation loss: 2.5886984265744593

Epoch: 5| Step: 7
Training loss: 2.441725565055661
Validation loss: 2.540278118165689

Epoch: 5| Step: 8
Training loss: 2.6786540627221793
Validation loss: 2.5165091797464396

Epoch: 5| Step: 9
Training loss: 2.8674936572855314
Validation loss: 2.493231667114636

Epoch: 5| Step: 10
Training loss: 2.320093626237803
Validation loss: 2.4998504778540256

Epoch: 162| Step: 0
Training loss: 2.7054243065942423
Validation loss: 2.4814668814519685

Epoch: 5| Step: 1
Training loss: 2.502842431662835
Validation loss: 2.471991653109437

Epoch: 5| Step: 2
Training loss: 2.4669925856708868
Validation loss: 2.484984298599999

Epoch: 5| Step: 3
Training loss: 2.8561419777508106
Validation loss: 2.503384246864984

Epoch: 5| Step: 4
Training loss: 2.596489803606387
Validation loss: 2.531137319852377

Epoch: 5| Step: 5
Training loss: 3.014711389851294
Validation loss: 2.5549152472573486

Epoch: 5| Step: 6
Training loss: 2.946087884403966
Validation loss: 2.5806495176811777

Epoch: 5| Step: 7
Training loss: 2.4948110135044352
Validation loss: 2.6319787953633424

Epoch: 5| Step: 8
Training loss: 2.623845436864831
Validation loss: 2.720777148831086

Epoch: 5| Step: 9
Training loss: 2.4289440722632665
Validation loss: 2.7430048141954346

Epoch: 5| Step: 10
Training loss: 2.9993789347873006
Validation loss: 2.6735212100960677

Epoch: 163| Step: 0
Training loss: 2.5178777429110952
Validation loss: 2.592494786897138

Epoch: 5| Step: 1
Training loss: 3.031791402701886
Validation loss: 2.5213229697871897

Epoch: 5| Step: 2
Training loss: 2.618112155921959
Validation loss: 2.4794023821742734

Epoch: 5| Step: 3
Training loss: 2.83811224159409
Validation loss: 2.462555015727706

Epoch: 5| Step: 4
Training loss: 2.7124230439832298
Validation loss: 2.4606716540442677

Epoch: 5| Step: 5
Training loss: 2.973636661019677
Validation loss: 2.4567424697652798

Epoch: 5| Step: 6
Training loss: 2.4667792844409435
Validation loss: 2.4582905446690066

Epoch: 5| Step: 7
Training loss: 3.0063442857830913
Validation loss: 2.4668867297675057

Epoch: 5| Step: 8
Training loss: 2.3720996614590297
Validation loss: 2.4918415092878723

Epoch: 5| Step: 9
Training loss: 2.435520248451085
Validation loss: 2.5146749785731357

Epoch: 5| Step: 10
Training loss: 2.3762714596521324
Validation loss: 2.538587593993748

Epoch: 164| Step: 0
Training loss: 2.6004405308696916
Validation loss: 2.5632496219311

Epoch: 5| Step: 1
Training loss: 2.5122923010765654
Validation loss: 2.6044265240052806

Epoch: 5| Step: 2
Training loss: 2.9734838388894462
Validation loss: 2.647874709498741

Epoch: 5| Step: 3
Training loss: 2.1600884811504657
Validation loss: 2.722894701421226

Epoch: 5| Step: 4
Training loss: 2.1972242834652462
Validation loss: 2.6532378633585947

Epoch: 5| Step: 5
Training loss: 3.0302142703899833
Validation loss: 2.5828711274515963

Epoch: 5| Step: 6
Training loss: 2.4680647079974523
Validation loss: 2.5346145479650355

Epoch: 5| Step: 7
Training loss: 2.82624096578363
Validation loss: 2.5112434761354105

Epoch: 5| Step: 8
Training loss: 2.5669715758036524
Validation loss: 2.5015504889666706

Epoch: 5| Step: 9
Training loss: 2.7477871054260383
Validation loss: 2.4828120422063416

Epoch: 5| Step: 10
Training loss: 3.110336998346985
Validation loss: 2.484646366050199

Epoch: 165| Step: 0
Training loss: 3.0534863854519045
Validation loss: 2.49045094400263

Epoch: 5| Step: 1
Training loss: 2.3868198404583585
Validation loss: 2.502779745252352

Epoch: 5| Step: 2
Training loss: 2.249840942694736
Validation loss: 2.516698401526132

Epoch: 5| Step: 3
Training loss: 2.4379647618814717
Validation loss: 2.533103841305215

Epoch: 5| Step: 4
Training loss: 3.060604988330295
Validation loss: 2.573550118717818

Epoch: 5| Step: 5
Training loss: 2.7109321352331195
Validation loss: 2.638455132343911

Epoch: 5| Step: 6
Training loss: 2.9851886379119255
Validation loss: 2.6673032214930275

Epoch: 5| Step: 7
Training loss: 2.302844328839588
Validation loss: 2.6645304095412374

Epoch: 5| Step: 8
Training loss: 2.659014262063239
Validation loss: 2.6580499619976448

Epoch: 5| Step: 9
Training loss: 2.8329904760220153
Validation loss: 2.627352083158377

Epoch: 5| Step: 10
Training loss: 2.1859650812597207
Validation loss: 2.6151479929983545

Epoch: 166| Step: 0
Training loss: 3.196964797383676
Validation loss: 2.588508987212221

Epoch: 5| Step: 1
Training loss: 1.4487712817073055
Validation loss: 2.6106392092818176

Epoch: 5| Step: 2
Training loss: 2.5872770683338913
Validation loss: 2.6085731267039374

Epoch: 5| Step: 3
Training loss: 2.770761493717191
Validation loss: 2.59419786678743

Epoch: 5| Step: 4
Training loss: 3.1010635704947282
Validation loss: 2.5979888325618665

Epoch: 5| Step: 5
Training loss: 2.151510918690828
Validation loss: 2.5996914254910104

Epoch: 5| Step: 6
Training loss: 2.744134108783411
Validation loss: 2.604661769604398

Epoch: 5| Step: 7
Training loss: 2.3302553402066315
Validation loss: 2.607801436344365

Epoch: 5| Step: 8
Training loss: 2.7119724375919274
Validation loss: 2.5822623338744943

Epoch: 5| Step: 9
Training loss: 2.677265908117334
Validation loss: 2.5709477201445337

Epoch: 5| Step: 10
Training loss: 2.8950328315098637
Validation loss: 2.5623637917787243

Epoch: 167| Step: 0
Training loss: 2.6454415719662485
Validation loss: 2.577737983400105

Epoch: 5| Step: 1
Training loss: 2.2522006399237933
Validation loss: 2.5915281433710406

Epoch: 5| Step: 2
Training loss: 2.5946574634429296
Validation loss: 2.6240566197264883

Epoch: 5| Step: 3
Training loss: 2.6462181492304544
Validation loss: 2.659061253439804

Epoch: 5| Step: 4
Training loss: 2.6020079451900746
Validation loss: 2.6554869837720605

Epoch: 5| Step: 5
Training loss: 2.551768276982944
Validation loss: 2.6666875698695716

Epoch: 5| Step: 6
Training loss: 2.332814351903202
Validation loss: 2.6545523230419206

Epoch: 5| Step: 7
Training loss: 2.725815810129054
Validation loss: 2.600356683095176

Epoch: 5| Step: 8
Training loss: 2.5710497323519057
Validation loss: 2.517494361603022

Epoch: 5| Step: 9
Training loss: 3.314985674198548
Validation loss: 2.5057899595219775

Epoch: 5| Step: 10
Training loss: 2.8718509843255924
Validation loss: 2.501339557633445

Epoch: 168| Step: 0
Training loss: 2.290139215227334
Validation loss: 2.512867957533016

Epoch: 5| Step: 1
Training loss: 2.534967965068462
Validation loss: 2.5242014118879226

Epoch: 5| Step: 2
Training loss: 2.385255555510561
Validation loss: 2.558522357459716

Epoch: 5| Step: 3
Training loss: 2.4688672387979995
Validation loss: 2.6302536398340988

Epoch: 5| Step: 4
Training loss: 2.541588005558009
Validation loss: 2.6902138643053717

Epoch: 5| Step: 5
Training loss: 2.9506919566554703
Validation loss: 2.735503697111856

Epoch: 5| Step: 6
Training loss: 3.2249011179824043
Validation loss: 2.732857888312691

Epoch: 5| Step: 7
Training loss: 2.1299932941814763
Validation loss: 2.691233934970905

Epoch: 5| Step: 8
Training loss: 2.9613384689957516
Validation loss: 2.647098730561116

Epoch: 5| Step: 9
Training loss: 2.855693176885047
Validation loss: 2.567592185326222

Epoch: 5| Step: 10
Training loss: 2.5099916111475364
Validation loss: 2.5364196957003737

Epoch: 169| Step: 0
Training loss: 2.3794620159120963
Validation loss: 2.5088655979066607

Epoch: 5| Step: 1
Training loss: 2.4896265342720314
Validation loss: 2.494277172141252

Epoch: 5| Step: 2
Training loss: 2.143016287025724
Validation loss: 2.4842726803186994

Epoch: 5| Step: 3
Training loss: 2.7655240487677455
Validation loss: 2.4733054159042904

Epoch: 5| Step: 4
Training loss: 2.962282544617496
Validation loss: 2.48135049057024

Epoch: 5| Step: 5
Training loss: 2.41241349376484
Validation loss: 2.4994857484777055

Epoch: 5| Step: 6
Training loss: 2.7295400543656125
Validation loss: 2.4954887860102

Epoch: 5| Step: 7
Training loss: 3.049253660095525
Validation loss: 2.5292771223073514

Epoch: 5| Step: 8
Training loss: 2.542144876320897
Validation loss: 2.596715616215051

Epoch: 5| Step: 9
Training loss: 2.599385585080035
Validation loss: 2.636223590013141

Epoch: 5| Step: 10
Training loss: 2.8709240091193107
Validation loss: 2.6840623990094272

Epoch: 170| Step: 0
Training loss: 2.0117569114250617
Validation loss: 2.718807160923821

Epoch: 5| Step: 1
Training loss: 2.2474637041566354
Validation loss: 2.7447219325762124

Epoch: 5| Step: 2
Training loss: 2.79331069667023
Validation loss: 2.793931136923809

Epoch: 5| Step: 3
Training loss: 3.1273665050676493
Validation loss: 2.8120774565828692

Epoch: 5| Step: 4
Training loss: 2.8512330583456222
Validation loss: 2.787045790755464

Epoch: 5| Step: 5
Training loss: 2.881441612243862
Validation loss: 2.7279103166346808

Epoch: 5| Step: 6
Training loss: 2.2525137528519354
Validation loss: 2.639170852634448

Epoch: 5| Step: 7
Training loss: 3.027990889753497
Validation loss: 2.55816740522912

Epoch: 5| Step: 8
Training loss: 2.501068554444676
Validation loss: 2.5074913533068757

Epoch: 5| Step: 9
Training loss: 2.817494514141818
Validation loss: 2.498380094148042

Epoch: 5| Step: 10
Training loss: 2.5659913260357152
Validation loss: 2.4950609887498767

Epoch: 171| Step: 0
Training loss: 2.5528967877931836
Validation loss: 2.4900184121085176

Epoch: 5| Step: 1
Training loss: 2.6396725533894223
Validation loss: 2.494743859652122

Epoch: 5| Step: 2
Training loss: 2.4676941170906255
Validation loss: 2.4987081235425475

Epoch: 5| Step: 3
Training loss: 2.679879673776039
Validation loss: 2.533953560916708

Epoch: 5| Step: 4
Training loss: 2.4376923900874337
Validation loss: 2.534352958851111

Epoch: 5| Step: 5
Training loss: 3.0121086847826177
Validation loss: 2.5347648493029875

Epoch: 5| Step: 6
Training loss: 2.513735043458912
Validation loss: 2.5994404278188012

Epoch: 5| Step: 7
Training loss: 2.154380762121841
Validation loss: 2.6587979791855196

Epoch: 5| Step: 8
Training loss: 3.0063430169004524
Validation loss: 2.699662981340584

Epoch: 5| Step: 9
Training loss: 2.8133158877887965
Validation loss: 2.602050623119214

Epoch: 5| Step: 10
Training loss: 2.676655736436138
Validation loss: 2.580113299229417

Epoch: 172| Step: 0
Training loss: 2.6784081254860923
Validation loss: 2.547457267776947

Epoch: 5| Step: 1
Training loss: 3.4020066734845047
Validation loss: 2.5244285481050563

Epoch: 5| Step: 2
Training loss: 2.4760282403509417
Validation loss: 2.5230322345755782

Epoch: 5| Step: 3
Training loss: 2.7526461268137776
Validation loss: 2.538679886253658

Epoch: 5| Step: 4
Training loss: 2.564473392496548
Validation loss: 2.5506843511177433

Epoch: 5| Step: 5
Training loss: 2.300737934320081
Validation loss: 2.5764353436100698

Epoch: 5| Step: 6
Training loss: 2.965024196275145
Validation loss: 2.5531261919288206

Epoch: 5| Step: 7
Training loss: 2.76319787371785
Validation loss: 2.54398610557066

Epoch: 5| Step: 8
Training loss: 2.2749030249750803
Validation loss: 2.5319048784997

Epoch: 5| Step: 9
Training loss: 2.3524420731291085
Validation loss: 2.53169664731255

Epoch: 5| Step: 10
Training loss: 2.192913441492263
Validation loss: 2.5536499204377012

Epoch: 173| Step: 0
Training loss: 3.151573569222086
Validation loss: 2.5451250947814437

Epoch: 5| Step: 1
Training loss: 2.296528381351678
Validation loss: 2.567253553921694

Epoch: 5| Step: 2
Training loss: 2.318604428227978
Validation loss: 2.602277366882111

Epoch: 5| Step: 3
Training loss: 2.639271496480612
Validation loss: 2.583578617771244

Epoch: 5| Step: 4
Training loss: 2.036492492961651
Validation loss: 2.573086502855381

Epoch: 5| Step: 5
Training loss: 2.8939369816855525
Validation loss: 2.5632349276477746

Epoch: 5| Step: 6
Training loss: 2.6131515128600173
Validation loss: 2.598251668556302

Epoch: 5| Step: 7
Training loss: 2.4640428115358097
Validation loss: 2.6076025324107164

Epoch: 5| Step: 8
Training loss: 2.2911257249892505
Validation loss: 2.5729235919329274

Epoch: 5| Step: 9
Training loss: 2.8570240132274356
Validation loss: 2.5761891047221166

Epoch: 5| Step: 10
Training loss: 2.7543325107829766
Validation loss: 2.5356066396770216

Epoch: 174| Step: 0
Training loss: 2.5002484198169426
Validation loss: 2.547363651098255

Epoch: 5| Step: 1
Training loss: 2.4026208237068465
Validation loss: 2.564027014633768

Epoch: 5| Step: 2
Training loss: 2.701654817185331
Validation loss: 2.583897429480752

Epoch: 5| Step: 3
Training loss: 3.1834367771883687
Validation loss: 2.6129342574476273

Epoch: 5| Step: 4
Training loss: 2.5981951391219695
Validation loss: 2.6079750837452815

Epoch: 5| Step: 5
Training loss: 2.309947693137604
Validation loss: 2.6623802157728353

Epoch: 5| Step: 6
Training loss: 2.7281055183195706
Validation loss: 2.644895263432156

Epoch: 5| Step: 7
Training loss: 2.2284877016422704
Validation loss: 2.6024589803453524

Epoch: 5| Step: 8
Training loss: 2.261847984825134
Validation loss: 2.5625560583290152

Epoch: 5| Step: 9
Training loss: 2.7699200743288905
Validation loss: 2.5434879005992754

Epoch: 5| Step: 10
Training loss: 2.5554817668194927
Validation loss: 2.5288651176134405

Epoch: 175| Step: 0
Training loss: 2.4909976043934674
Validation loss: 2.50875382532435

Epoch: 5| Step: 1
Training loss: 2.6422967979523495
Validation loss: 2.496715551847059

Epoch: 5| Step: 2
Training loss: 2.672690551502013
Validation loss: 2.4901201693368944

Epoch: 5| Step: 3
Training loss: 2.5954610856691533
Validation loss: 2.500826616936712

Epoch: 5| Step: 4
Training loss: 2.4822085549264683
Validation loss: 2.5153556775866113

Epoch: 5| Step: 5
Training loss: 2.13570947888048
Validation loss: 2.53545497975519

Epoch: 5| Step: 6
Training loss: 2.390093376538201
Validation loss: 2.571475084767651

Epoch: 5| Step: 7
Training loss: 2.34964448390488
Validation loss: 2.6160312675364095

Epoch: 5| Step: 8
Training loss: 2.950119022619194
Validation loss: 2.619583048836424

Epoch: 5| Step: 9
Training loss: 2.8445745257925807
Validation loss: 2.6724831043167745

Epoch: 5| Step: 10
Training loss: 2.520396759649124
Validation loss: 2.6541533744923353

Epoch: 176| Step: 0
Training loss: 2.859401848672191
Validation loss: 2.650262425872562

Epoch: 5| Step: 1
Training loss: 2.722683396060421
Validation loss: 2.6699162828293685

Epoch: 5| Step: 2
Training loss: 2.7447679338870845
Validation loss: 2.6555256926741793

Epoch: 5| Step: 3
Training loss: 2.7370733407633208
Validation loss: 2.6009192089742723

Epoch: 5| Step: 4
Training loss: 2.604791235731644
Validation loss: 2.5560778967122255

Epoch: 5| Step: 5
Training loss: 2.397279838978606
Validation loss: 2.520136939802764

Epoch: 5| Step: 6
Training loss: 1.8901393045828023
Validation loss: 2.498240255575907

Epoch: 5| Step: 7
Training loss: 2.4087915250864125
Validation loss: 2.4849574517580804

Epoch: 5| Step: 8
Training loss: 2.444676325617797
Validation loss: 2.4974073995121158

Epoch: 5| Step: 9
Training loss: 2.244193107183859
Validation loss: 2.490711874047679

Epoch: 5| Step: 10
Training loss: 2.7531097342406734
Validation loss: 2.5073237790918332

Epoch: 177| Step: 0
Training loss: 2.1517052785224418
Validation loss: 2.5012381215473605

Epoch: 5| Step: 1
Training loss: 2.970052975268845
Validation loss: 2.504861524497407

Epoch: 5| Step: 2
Training loss: 2.401125318238154
Validation loss: 2.539141824270418

Epoch: 5| Step: 3
Training loss: 2.4785664149642375
Validation loss: 2.587241467323379

Epoch: 5| Step: 4
Training loss: 2.201796543738665
Validation loss: 2.6242827760429166

Epoch: 5| Step: 5
Training loss: 2.1134890526442223
Validation loss: 2.6823190628948095

Epoch: 5| Step: 6
Training loss: 2.9875495363861067
Validation loss: 2.748261070659857

Epoch: 5| Step: 7
Training loss: 2.3632197096197083
Validation loss: 2.8078757806637133

Epoch: 5| Step: 8
Training loss: 2.971360193503328
Validation loss: 2.8879936908859465

Epoch: 5| Step: 9
Training loss: 2.324834969518922
Validation loss: 2.8023988282573367

Epoch: 5| Step: 10
Training loss: 2.8068179059300515
Validation loss: 2.718566482869736

Epoch: 178| Step: 0
Training loss: 2.045156325168974
Validation loss: 2.662429903548027

Epoch: 5| Step: 1
Training loss: 2.2200733590248554
Validation loss: 2.5956324440062555

Epoch: 5| Step: 2
Training loss: 2.4893374993375064
Validation loss: 2.5431019586656665

Epoch: 5| Step: 3
Training loss: 3.186870737231932
Validation loss: 2.531259883859799

Epoch: 5| Step: 4
Training loss: 2.4917452907171382
Validation loss: 2.5171328212791697

Epoch: 5| Step: 5
Training loss: 2.2450615410132997
Validation loss: 2.512360701181154

Epoch: 5| Step: 6
Training loss: 2.4341076450664616
Validation loss: 2.5120598996682086

Epoch: 5| Step: 7
Training loss: 2.5056280681984306
Validation loss: 2.5193121834334646

Epoch: 5| Step: 8
Training loss: 2.9449195498502725
Validation loss: 2.5328935477695755

Epoch: 5| Step: 9
Training loss: 2.70788041264623
Validation loss: 2.536009269913244

Epoch: 5| Step: 10
Training loss: 2.2849287914307483
Validation loss: 2.585453961896236

Epoch: 179| Step: 0
Training loss: 2.8932273903654444
Validation loss: 2.6083423844990663

Epoch: 5| Step: 1
Training loss: 2.822533491153879
Validation loss: 2.6683531604810686

Epoch: 5| Step: 2
Training loss: 2.4766929423639934
Validation loss: 2.679386832512996

Epoch: 5| Step: 3
Training loss: 2.480014356910003
Validation loss: 2.6938788854330786

Epoch: 5| Step: 4
Training loss: 2.706963608462268
Validation loss: 2.65130774490783

Epoch: 5| Step: 5
Training loss: 1.8912439515394674
Validation loss: 2.5690349704522526

Epoch: 5| Step: 6
Training loss: 2.598430225685567
Validation loss: 2.528023983731474

Epoch: 5| Step: 7
Training loss: 2.590117979418766
Validation loss: 2.5239797664986017

Epoch: 5| Step: 8
Training loss: 2.5712004174332437
Validation loss: 2.497213809690412

Epoch: 5| Step: 9
Training loss: 2.458453180872376
Validation loss: 2.4864370371852718

Epoch: 5| Step: 10
Training loss: 2.0008074799307467
Validation loss: 2.4841598073919395

Epoch: 180| Step: 0
Training loss: 2.119692850894914
Validation loss: 2.4932697716000147

Epoch: 5| Step: 1
Training loss: 1.8418615983126603
Validation loss: 2.533307575994591

Epoch: 5| Step: 2
Training loss: 3.015489802517076
Validation loss: 2.57390060399574

Epoch: 5| Step: 3
Training loss: 2.7123391872850866
Validation loss: 2.6748541770660474

Epoch: 5| Step: 4
Training loss: 2.5897942217525602
Validation loss: 2.629289990935418

Epoch: 5| Step: 5
Training loss: 2.290993666807868
Validation loss: 2.6190330662713914

Epoch: 5| Step: 6
Training loss: 2.3735649391099707
Validation loss: 2.6211881213305426

Epoch: 5| Step: 7
Training loss: 2.4499321830861343
Validation loss: 2.6460519386567376

Epoch: 5| Step: 8
Training loss: 2.968488501024198
Validation loss: 2.6624271294458772

Epoch: 5| Step: 9
Training loss: 1.7837338446438225
Validation loss: 2.6800406651479665

Epoch: 5| Step: 10
Training loss: 3.3160267894753304
Validation loss: 2.647118954113278

Epoch: 181| Step: 0
Training loss: 2.2060360985825938
Validation loss: 2.619103030601571

Epoch: 5| Step: 1
Training loss: 2.8266375091536404
Validation loss: 2.5760474720710973

Epoch: 5| Step: 2
Training loss: 2.6739802404342687
Validation loss: 2.5654955077220123

Epoch: 5| Step: 3
Training loss: 2.4597612748964037
Validation loss: 2.5559748065234595

Epoch: 5| Step: 4
Training loss: 2.581602952670456
Validation loss: 2.5585623359646044

Epoch: 5| Step: 5
Training loss: 2.330819433300627
Validation loss: 2.5847719403125904

Epoch: 5| Step: 6
Training loss: 2.2794702982037442
Validation loss: 2.6086542997133786

Epoch: 5| Step: 7
Training loss: 2.6670004119243385
Validation loss: 2.6727557656498413

Epoch: 5| Step: 8
Training loss: 1.7816609360353228
Validation loss: 2.6814220923686936

Epoch: 5| Step: 9
Training loss: 3.194208154831047
Validation loss: 2.7167350677262947

Epoch: 5| Step: 10
Training loss: 2.209084425059349
Validation loss: 2.6756941332436925

Epoch: 182| Step: 0
Training loss: 2.72422388556007
Validation loss: 2.6576678358016355

Epoch: 5| Step: 1
Training loss: 2.704302845383098
Validation loss: 2.634533905299821

Epoch: 5| Step: 2
Training loss: 2.2715092507572217
Validation loss: 2.5988961111088256

Epoch: 5| Step: 3
Training loss: 2.323697789894849
Validation loss: 2.576879646665757

Epoch: 5| Step: 4
Training loss: 2.5630349321965293
Validation loss: 2.59332880128038

Epoch: 5| Step: 5
Training loss: 2.3283958533523563
Validation loss: 2.600634083207407

Epoch: 5| Step: 6
Training loss: 2.328632376255191
Validation loss: 2.6037572090079415

Epoch: 5| Step: 7
Training loss: 2.482755120912548
Validation loss: 2.613136789172217

Epoch: 5| Step: 8
Training loss: 2.5966150477334375
Validation loss: 2.575037001142752

Epoch: 5| Step: 9
Training loss: 2.058903187725392
Validation loss: 2.5467207385233235

Epoch: 5| Step: 10
Training loss: 2.4741089035525867
Validation loss: 2.560178596114447

Epoch: 183| Step: 0
Training loss: 2.6386236247092034
Validation loss: 2.565972670074129

Epoch: 5| Step: 1
Training loss: 3.1032290653477457
Validation loss: 2.560700670484754

Epoch: 5| Step: 2
Training loss: 2.3194078936206424
Validation loss: 2.614263831649309

Epoch: 5| Step: 3
Training loss: 2.1445906167073105
Validation loss: 2.5904944337491638

Epoch: 5| Step: 4
Training loss: 2.1259031059671307
Validation loss: 2.6277018421103806

Epoch: 5| Step: 5
Training loss: 2.442688920866416
Validation loss: 2.6481669661039136

Epoch: 5| Step: 6
Training loss: 2.199077486478006
Validation loss: 2.6767968085551987

Epoch: 5| Step: 7
Training loss: 2.631385212593254
Validation loss: 2.7353811552281564

Epoch: 5| Step: 8
Training loss: 2.3119484527213774
Validation loss: 2.67687585530326

Epoch: 5| Step: 9
Training loss: 2.223641390107523
Validation loss: 2.599574412300019

Epoch: 5| Step: 10
Training loss: 2.4605234918060117
Validation loss: 2.5603299390265475

Epoch: 184| Step: 0
Training loss: 2.6289232091937653
Validation loss: 2.5480806511866385

Epoch: 5| Step: 1
Training loss: 2.300631610557222
Validation loss: 2.5355863163563117

Epoch: 5| Step: 2
Training loss: 2.4880743734215427
Validation loss: 2.53942498761417

Epoch: 5| Step: 3
Training loss: 2.1723778231805646
Validation loss: 2.538994724325148

Epoch: 5| Step: 4
Training loss: 2.4360061371574075
Validation loss: 2.5324481835982366

Epoch: 5| Step: 5
Training loss: 2.1162294141440747
Validation loss: 2.5243530359998414

Epoch: 5| Step: 6
Training loss: 2.718312019936625
Validation loss: 2.547645695329548

Epoch: 5| Step: 7
Training loss: 2.3498037865070796
Validation loss: 2.6042039779123147

Epoch: 5| Step: 8
Training loss: 2.240963591845438
Validation loss: 2.6595173476994405

Epoch: 5| Step: 9
Training loss: 2.5894602035584535
Validation loss: 2.7049905225779463

Epoch: 5| Step: 10
Training loss: 2.764050310193187
Validation loss: 2.621329776601248

Epoch: 185| Step: 0
Training loss: 2.7336539053369244
Validation loss: 2.5645697763759636

Epoch: 5| Step: 1
Training loss: 2.4297271430899734
Validation loss: 2.5483852428070235

Epoch: 5| Step: 2
Training loss: 2.162286132644681
Validation loss: 2.5294686889446294

Epoch: 5| Step: 3
Training loss: 1.9292878266002826
Validation loss: 2.5241135801742254

Epoch: 5| Step: 4
Training loss: 2.261014680527104
Validation loss: 2.562226161536402

Epoch: 5| Step: 5
Training loss: 2.0556985086558752
Validation loss: 2.5665670255165276

Epoch: 5| Step: 6
Training loss: 2.851527718109792
Validation loss: 2.6020426022796523

Epoch: 5| Step: 7
Training loss: 2.2757899118213443
Validation loss: 2.67478080497772

Epoch: 5| Step: 8
Training loss: 2.6790914067148672
Validation loss: 2.7228903874054504

Epoch: 5| Step: 9
Training loss: 2.740911029082875
Validation loss: 2.668743815324474

Epoch: 5| Step: 10
Training loss: 2.0211090476596603
Validation loss: 2.647854062324111

Epoch: 186| Step: 0
Training loss: 2.247787871632226
Validation loss: 2.5744843981171943

Epoch: 5| Step: 1
Training loss: 2.1450799403377614
Validation loss: 2.522317410003517

Epoch: 5| Step: 2
Training loss: 2.572932429915312
Validation loss: 2.5340839323083704

Epoch: 5| Step: 3
Training loss: 2.6006454363558342
Validation loss: 2.5198809561076616

Epoch: 5| Step: 4
Training loss: 2.45758254229832
Validation loss: 2.530235695995676

Epoch: 5| Step: 5
Training loss: 2.5823577351265583
Validation loss: 2.5736419491123907

Epoch: 5| Step: 6
Training loss: 1.5891668204814409
Validation loss: 2.630601899096793

Epoch: 5| Step: 7
Training loss: 2.3844219838084233
Validation loss: 2.6784496836967886

Epoch: 5| Step: 8
Training loss: 2.806251451113863
Validation loss: 2.742986278006123

Epoch: 5| Step: 9
Training loss: 2.3858694010611052
Validation loss: 2.7754118368676384

Epoch: 5| Step: 10
Training loss: 2.6066384042084145
Validation loss: 2.8980703707069093

Epoch: 187| Step: 0
Training loss: 2.263413922256726
Validation loss: 2.753116253423914

Epoch: 5| Step: 1
Training loss: 2.550344245712128
Validation loss: 2.6556731783064227

Epoch: 5| Step: 2
Training loss: 2.57505911972177
Validation loss: 2.598013933136207

Epoch: 5| Step: 3
Training loss: 2.1211166802110006
Validation loss: 2.5225278900834676

Epoch: 5| Step: 4
Training loss: 2.4217562738665936
Validation loss: 2.4771617297602857

Epoch: 5| Step: 5
Training loss: 2.4667066978952246
Validation loss: 2.4768435447264863

Epoch: 5| Step: 6
Training loss: 2.033691230398402
Validation loss: 2.4980597534786746

Epoch: 5| Step: 7
Training loss: 2.456729063728013
Validation loss: 2.49512320739856

Epoch: 5| Step: 8
Training loss: 2.4954066995075705
Validation loss: 2.5179216187520375

Epoch: 5| Step: 9
Training loss: 2.3906271940732373
Validation loss: 2.6004006421438866

Epoch: 5| Step: 10
Training loss: 2.502671721489743
Validation loss: 2.6888313954309

Epoch: 188| Step: 0
Training loss: 2.676769035285211
Validation loss: 2.7207177094370296

Epoch: 5| Step: 1
Training loss: 2.4266444342855875
Validation loss: 2.712819521515484

Epoch: 5| Step: 2
Training loss: 2.0026108866075756
Validation loss: 2.627481555255975

Epoch: 5| Step: 3
Training loss: 2.178292870859608
Validation loss: 2.585596706348181

Epoch: 5| Step: 4
Training loss: 2.3504820714744357
Validation loss: 2.551275415136531

Epoch: 5| Step: 5
Training loss: 2.3126081492935535
Validation loss: 2.5501773617321835

Epoch: 5| Step: 6
Training loss: 1.764844873975959
Validation loss: 2.5561500976883598

Epoch: 5| Step: 7
Training loss: 2.9045099771557785
Validation loss: 2.5771472776111826

Epoch: 5| Step: 8
Training loss: 2.3691768533400674
Validation loss: 2.6143357014572706

Epoch: 5| Step: 9
Training loss: 2.4278347396666695
Validation loss: 2.6456980765564033

Epoch: 5| Step: 10
Training loss: 2.4825117693696024
Validation loss: 2.715663820225238

Epoch: 189| Step: 0
Training loss: 2.333486029760287
Validation loss: 2.6760469191434475

Epoch: 5| Step: 1
Training loss: 2.514922997753877
Validation loss: 2.639761462014314

Epoch: 5| Step: 2
Training loss: 1.7326845746163742
Validation loss: 2.651640651120967

Epoch: 5| Step: 3
Training loss: 2.342311773890478
Validation loss: 2.624146344655651

Epoch: 5| Step: 4
Training loss: 2.8283961044955817
Validation loss: 2.6755141181558666

Epoch: 5| Step: 5
Training loss: 2.4647656895387424
Validation loss: 2.7032606650507858

Epoch: 5| Step: 6
Training loss: 2.2596535749688775
Validation loss: 2.7087513874712013

Epoch: 5| Step: 7
Training loss: 2.5151262440479076
Validation loss: 2.7165523968803407

Epoch: 5| Step: 8
Training loss: 1.7109546399237792
Validation loss: 2.71262931275434

Epoch: 5| Step: 9
Training loss: 2.4004623365127213
Validation loss: 2.718686880195342

Epoch: 5| Step: 10
Training loss: 2.3422081516976467
Validation loss: 2.653950579420809

Epoch: 190| Step: 0
Training loss: 2.184058943382748
Validation loss: 2.5577885694450067

Epoch: 5| Step: 1
Training loss: 2.559979478485586
Validation loss: 2.528965239805413

Epoch: 5| Step: 2
Training loss: 2.7261842831505394
Validation loss: 2.5078063214427564

Epoch: 5| Step: 3
Training loss: 2.231173482485787
Validation loss: 2.524544737645666

Epoch: 5| Step: 4
Training loss: 2.5538491089532425
Validation loss: 2.542792891938967

Epoch: 5| Step: 5
Training loss: 2.4358379859979937
Validation loss: 2.6085823441350278

Epoch: 5| Step: 6
Training loss: 1.9273158027716375
Validation loss: 2.707534408739285

Epoch: 5| Step: 7
Training loss: 2.3622379742995623
Validation loss: 2.8201227925072128

Epoch: 5| Step: 8
Training loss: 2.571946757950565
Validation loss: 2.885777055383851

Epoch: 5| Step: 9
Training loss: 2.5346159983866086
Validation loss: 2.886677896199805

Epoch: 5| Step: 10
Training loss: 1.6748435502506382
Validation loss: 2.6802020801488

Epoch: 191| Step: 0
Training loss: 2.8031918248745407
Validation loss: 2.560374179777511

Epoch: 5| Step: 1
Training loss: 2.0044537069713315
Validation loss: 2.5054219118007794

Epoch: 5| Step: 2
Training loss: 2.0864323518392034
Validation loss: 2.506281668180349

Epoch: 5| Step: 3
Training loss: 1.915581548051747
Validation loss: 2.5293094423271434

Epoch: 5| Step: 4
Training loss: 2.1819968620018986
Validation loss: 2.5339016927563596

Epoch: 5| Step: 5
Training loss: 2.4834955926237403
Validation loss: 2.526180873866689

Epoch: 5| Step: 6
Training loss: 2.1371522007010126
Validation loss: 2.5380092468911046

Epoch: 5| Step: 7
Training loss: 2.5284164958529805
Validation loss: 2.6154145633440518

Epoch: 5| Step: 8
Training loss: 2.374450419233048
Validation loss: 2.5868292698683124

Epoch: 5| Step: 9
Training loss: 2.292923207131296
Validation loss: 2.590279184421124

Epoch: 5| Step: 10
Training loss: 2.7467182691905583
Validation loss: 2.5736208563131657

Epoch: 192| Step: 0
Training loss: 2.0068038603732026
Validation loss: 2.582260864546932

Epoch: 5| Step: 1
Training loss: 2.2602612373132622
Validation loss: 2.5469224689971344

Epoch: 5| Step: 2
Training loss: 1.889837621242872
Validation loss: 2.5450337061104666

Epoch: 5| Step: 3
Training loss: 2.7327843971617756
Validation loss: 2.5589391066207843

Epoch: 5| Step: 4
Training loss: 2.658253889979531
Validation loss: 2.5574858736060198

Epoch: 5| Step: 5
Training loss: 2.32040846911961
Validation loss: 2.6090885098661554

Epoch: 5| Step: 6
Training loss: 2.1354752571317754
Validation loss: 2.638535053758595

Epoch: 5| Step: 7
Training loss: 2.615564007885432
Validation loss: 2.7052434458268997

Epoch: 5| Step: 8
Training loss: 2.691629918165483
Validation loss: 2.6919701581686057

Epoch: 5| Step: 9
Training loss: 1.8599757017578915
Validation loss: 2.6917379989729455

Epoch: 5| Step: 10
Training loss: 1.8544679532669779
Validation loss: 2.692174979153591

Epoch: 193| Step: 0
Training loss: 2.149098575495043
Validation loss: 2.6464833723987433

Epoch: 5| Step: 1
Training loss: 1.6341862352526586
Validation loss: 2.6278798254188724

Epoch: 5| Step: 2
Training loss: 2.1375510984860493
Validation loss: 2.618628972650617

Epoch: 5| Step: 3
Training loss: 1.9947064201393563
Validation loss: 2.6119685619347823

Epoch: 5| Step: 4
Training loss: 2.6227227278424063
Validation loss: 2.6525927030259595

Epoch: 5| Step: 5
Training loss: 2.2942312167179093
Validation loss: 2.665486592501984

Epoch: 5| Step: 6
Training loss: 2.7124174184577723
Validation loss: 2.6587825160985354

Epoch: 5| Step: 7
Training loss: 2.3760553324193663
Validation loss: 2.6491081522894446

Epoch: 5| Step: 8
Training loss: 2.139686211548979
Validation loss: 2.632027245388477

Epoch: 5| Step: 9
Training loss: 2.4976968646811675
Validation loss: 2.631632514671797

Epoch: 5| Step: 10
Training loss: 1.9535973549908503
Validation loss: 2.668355081034863

Epoch: 194| Step: 0
Training loss: 2.299962362727834
Validation loss: 2.6706419169916957

Epoch: 5| Step: 1
Training loss: 2.3893576859413885
Validation loss: 2.7218595795054314

Epoch: 5| Step: 2
Training loss: 2.304189440687692
Validation loss: 2.6689179022625207

Epoch: 5| Step: 3
Training loss: 2.1519960098300515
Validation loss: 2.6574077064253525

Epoch: 5| Step: 4
Training loss: 2.2459903593731148
Validation loss: 2.6226694520907508

Epoch: 5| Step: 5
Training loss: 1.884649876019916
Validation loss: 2.57909349911636

Epoch: 5| Step: 6
Training loss: 2.1805338429897354
Validation loss: 2.590292575243376

Epoch: 5| Step: 7
Training loss: 2.076900264690786
Validation loss: 2.6059111270506303

Epoch: 5| Step: 8
Training loss: 2.4229593126168925
Validation loss: 2.5975731966464357

Epoch: 5| Step: 9
Training loss: 2.463907441828319
Validation loss: 2.6182294725271826

Epoch: 5| Step: 10
Training loss: 1.9163743362848606
Validation loss: 2.6196470543430275

Epoch: 195| Step: 0
Training loss: 1.8801683402277054
Validation loss: 2.6370068163124785

Epoch: 5| Step: 1
Training loss: 1.948985664941281
Validation loss: 2.6571315492079046

Epoch: 5| Step: 2
Training loss: 2.057169412449085
Validation loss: 2.67870487845608

Epoch: 5| Step: 3
Training loss: 2.4949989843270903
Validation loss: 2.6293211615335474

Epoch: 5| Step: 4
Training loss: 2.3151516532247296
Validation loss: 2.6093571307188372

Epoch: 5| Step: 5
Training loss: 2.2472936460411366
Validation loss: 2.6031682978154085

Epoch: 5| Step: 6
Training loss: 2.3387041835487006
Validation loss: 2.563742042744706

Epoch: 5| Step: 7
Training loss: 2.049118792313468
Validation loss: 2.5751755743863782

Epoch: 5| Step: 8
Training loss: 2.190474096044483
Validation loss: 2.5930663392787037

Epoch: 5| Step: 9
Training loss: 2.1428351582807217
Validation loss: 2.5914909378262454

Epoch: 5| Step: 10
Training loss: 2.57474485818446
Validation loss: 2.617977387893097

Epoch: 196| Step: 0
Training loss: 2.040130803084711
Validation loss: 2.6776402157866914

Epoch: 5| Step: 1
Training loss: 2.1023479823109223
Validation loss: 2.7076771517860703

Epoch: 5| Step: 2
Training loss: 2.445571836911987
Validation loss: 2.7267292899126088

Epoch: 5| Step: 3
Training loss: 2.3793786492806968
Validation loss: 2.6999786253811906

Epoch: 5| Step: 4
Training loss: 2.5098828477609993
Validation loss: 2.6046293009340404

Epoch: 5| Step: 5
Training loss: 2.0838196250482737
Validation loss: 2.561069620545092

Epoch: 5| Step: 6
Training loss: 2.558931610863156
Validation loss: 2.5471600020073355

Epoch: 5| Step: 7
Training loss: 1.9828194957035585
Validation loss: 2.537523210404105

Epoch: 5| Step: 8
Training loss: 2.170618036568168
Validation loss: 2.599125000182498

Epoch: 5| Step: 9
Training loss: 1.7382668483866195
Validation loss: 2.628334198562328

Epoch: 5| Step: 10
Training loss: 1.8393213133733175
Validation loss: 2.682792377102018

Epoch: 197| Step: 0
Training loss: 1.9342772229554224
Validation loss: 2.7094647409949735

Epoch: 5| Step: 1
Training loss: 2.0179198456678202
Validation loss: 2.7496390530000694

Epoch: 5| Step: 2
Training loss: 2.6594587803698113
Validation loss: 2.7048346282862936

Epoch: 5| Step: 3
Training loss: 2.2232926836925544
Validation loss: 2.675643206673976

Epoch: 5| Step: 4
Training loss: 1.5871836459718986
Validation loss: 2.6128387039669483

Epoch: 5| Step: 5
Training loss: 2.3461411549151556
Validation loss: 2.579353641854417

Epoch: 5| Step: 6
Training loss: 2.4189598997844377
Validation loss: 2.5688094311042686

Epoch: 5| Step: 7
Training loss: 1.8317273504023894
Validation loss: 2.566280513559023

Epoch: 5| Step: 8
Training loss: 2.5045180503178
Validation loss: 2.530313512788773

Epoch: 5| Step: 9
Training loss: 1.9504817318700123
Validation loss: 2.6109167580268435

Epoch: 5| Step: 10
Training loss: 2.186182006511462
Validation loss: 2.6404015852560394

Epoch: 198| Step: 0
Training loss: 2.055131407385799
Validation loss: 2.676718449056521

Epoch: 5| Step: 1
Training loss: 2.147514339128257
Validation loss: 2.7133575972850132

Epoch: 5| Step: 2
Training loss: 2.112235157633974
Validation loss: 2.736966380494986

Epoch: 5| Step: 3
Training loss: 2.6210809243992745
Validation loss: 2.7291500817792005

Epoch: 5| Step: 4
Training loss: 2.013657548559306
Validation loss: 2.6652019256789665

Epoch: 5| Step: 5
Training loss: 2.1881566833102544
Validation loss: 2.616896756288833

Epoch: 5| Step: 6
Training loss: 1.5837988503742055
Validation loss: 2.597730886599308

Epoch: 5| Step: 7
Training loss: 2.1349340374157255
Validation loss: 2.629338100500893

Epoch: 5| Step: 8
Training loss: 2.3087732338885125
Validation loss: 2.6656643053306266

Epoch: 5| Step: 9
Training loss: 2.283750130789617
Validation loss: 2.6315556461952

Epoch: 5| Step: 10
Training loss: 2.1281629472169716
Validation loss: 2.5982259022903493

Epoch: 199| Step: 0
Training loss: 1.7814451411920211
Validation loss: 2.5851438086451455

Epoch: 5| Step: 1
Training loss: 2.1616136487440967
Validation loss: 2.574377557807185

Epoch: 5| Step: 2
Training loss: 2.059213273640069
Validation loss: 2.571000445321016

Epoch: 5| Step: 3
Training loss: 2.0502662811395695
Validation loss: 2.5742925105873615

Epoch: 5| Step: 4
Training loss: 1.8448253663695413
Validation loss: 2.610204190462814

Epoch: 5| Step: 5
Training loss: 2.3195949690878526
Validation loss: 2.7032911894601894

Epoch: 5| Step: 6
Training loss: 2.6224990920364366
Validation loss: 2.7059586355304437

Epoch: 5| Step: 7
Training loss: 2.338645666538517
Validation loss: 2.686265050713939

Epoch: 5| Step: 8
Training loss: 2.744320640225407
Validation loss: 2.6740275210319115

Epoch: 5| Step: 9
Training loss: 1.4762354089854062
Validation loss: 2.6016943522258713

Epoch: 5| Step: 10
Training loss: 2.1032417707065734
Validation loss: 2.5633589952799123

Epoch: 200| Step: 0
Training loss: 2.284440305013819
Validation loss: 2.553905166445412

Epoch: 5| Step: 1
Training loss: 1.8999879259428565
Validation loss: 2.5586810804347313

Epoch: 5| Step: 2
Training loss: 2.1456202675922498
Validation loss: 2.563768684552431

Epoch: 5| Step: 3
Training loss: 2.0637015108619363
Validation loss: 2.5676682619343034

Epoch: 5| Step: 4
Training loss: 2.3637069444855427
Validation loss: 2.5763261801029818

Epoch: 5| Step: 5
Training loss: 1.89500273510577
Validation loss: 2.632323287207189

Epoch: 5| Step: 6
Training loss: 2.4429554654971892
Validation loss: 2.71901667532551

Epoch: 5| Step: 7
Training loss: 2.042172453634438
Validation loss: 2.6937792206719133

Epoch: 5| Step: 8
Training loss: 2.237971046349098
Validation loss: 2.6397880057284233

Epoch: 5| Step: 9
Training loss: 2.3222710663111714
Validation loss: 2.560088776244757

Epoch: 5| Step: 10
Training loss: 1.7595258712449215
Validation loss: 2.5632460343814065

Epoch: 201| Step: 0
Training loss: 1.8896616853944526
Validation loss: 2.551323945755149

Epoch: 5| Step: 1
Training loss: 2.295021295220137
Validation loss: 2.5470544935640724

Epoch: 5| Step: 2
Training loss: 2.123798928508278
Validation loss: 2.5991753921914937

Epoch: 5| Step: 3
Training loss: 1.9276316575779597
Validation loss: 2.69663587994057

Epoch: 5| Step: 4
Training loss: 1.7408884448355846
Validation loss: 2.7555634314177175

Epoch: 5| Step: 5
Training loss: 2.6066636486800236
Validation loss: 2.8258545910313213

Epoch: 5| Step: 6
Training loss: 2.053296913137741
Validation loss: 2.707773218536916

Epoch: 5| Step: 7
Training loss: 2.0258603705429157
Validation loss: 2.599200749585919

Epoch: 5| Step: 8
Training loss: 2.1290053598274645
Validation loss: 2.546867132536479

Epoch: 5| Step: 9
Training loss: 1.6401873776924545
Validation loss: 2.5262446144477972

Epoch: 5| Step: 10
Training loss: 2.9210915560636317
Validation loss: 2.4908038272219617

Epoch: 202| Step: 0
Training loss: 2.127190190494697
Validation loss: 2.5088530640767854

Epoch: 5| Step: 1
Training loss: 1.7782862585118049
Validation loss: 2.4984206030300813

Epoch: 5| Step: 2
Training loss: 2.000830001266906
Validation loss: 2.5268767413987234

Epoch: 5| Step: 3
Training loss: 2.141995735962058
Validation loss: 2.540848352303801

Epoch: 5| Step: 4
Training loss: 2.135618160014688
Validation loss: 2.6173021438656043

Epoch: 5| Step: 5
Training loss: 2.1667205241429803
Validation loss: 2.747983321690283

Epoch: 5| Step: 6
Training loss: 2.332940874700302
Validation loss: 2.8049561098306284

Epoch: 5| Step: 7
Training loss: 2.5259073647784263
Validation loss: 2.785210703294595

Epoch: 5| Step: 8
Training loss: 1.653886151811081
Validation loss: 2.6413146262427345

Epoch: 5| Step: 9
Training loss: 1.6700809871429387
Validation loss: 2.567850905484701

Epoch: 5| Step: 10
Training loss: 2.625883044715885
Validation loss: 2.4974983691549

Epoch: 203| Step: 0
Training loss: 1.9140842358659027
Validation loss: 2.471964624714165

Epoch: 5| Step: 1
Training loss: 2.349260286827254
Validation loss: 2.437831578447438

Epoch: 5| Step: 2
Training loss: 2.183614167747509
Validation loss: 2.4451849915104726

Epoch: 5| Step: 3
Training loss: 1.6690816628263663
Validation loss: 2.4785606201574635

Epoch: 5| Step: 4
Training loss: 1.8815869660078524
Validation loss: 2.5352702025845706

Epoch: 5| Step: 5
Training loss: 1.8238055069485626
Validation loss: 2.5965890144501436

Epoch: 5| Step: 6
Training loss: 2.298984519026952
Validation loss: 2.7049366654971805

Epoch: 5| Step: 7
Training loss: 2.378364388526665
Validation loss: 2.7490612620406747

Epoch: 5| Step: 8
Training loss: 2.3934782865012334
Validation loss: 2.717977334565031

Epoch: 5| Step: 9
Training loss: 2.2140700723091884
Validation loss: 2.6559444949114166

Epoch: 5| Step: 10
Training loss: 2.2184388923130163
Validation loss: 2.5820412859858863

Epoch: 204| Step: 0
Training loss: 1.6028742186945957
Validation loss: 2.5018191446004323

Epoch: 5| Step: 1
Training loss: 1.8645009141604165
Validation loss: 2.5031992689282867

Epoch: 5| Step: 2
Training loss: 2.1402736848889274
Validation loss: 2.48747561541708

Epoch: 5| Step: 3
Training loss: 2.004317629938461
Validation loss: 2.516320875944555

Epoch: 5| Step: 4
Training loss: 2.323597236688658
Validation loss: 2.5066405772994247

Epoch: 5| Step: 5
Training loss: 2.511947123110715
Validation loss: 2.5090317168406178

Epoch: 5| Step: 6
Training loss: 2.078993078208362
Validation loss: 2.5070489873688033

Epoch: 5| Step: 7
Training loss: 2.390030531428858
Validation loss: 2.498395523114423

Epoch: 5| Step: 8
Training loss: 1.8863692502902372
Validation loss: 2.539832032162894

Epoch: 5| Step: 9
Training loss: 2.287692131770445
Validation loss: 2.585165258142423

Epoch: 5| Step: 10
Training loss: 1.9123038795990785
Validation loss: 2.627069895538052

Epoch: 205| Step: 0
Training loss: 1.7121866621728008
Validation loss: 2.6775450306957236

Epoch: 5| Step: 1
Training loss: 2.592244090266761
Validation loss: 2.671008356349919

Epoch: 5| Step: 2
Training loss: 1.8751663134247398
Validation loss: 2.624448220173798

Epoch: 5| Step: 3
Training loss: 1.9177221073593242
Validation loss: 2.570587556411206

Epoch: 5| Step: 4
Training loss: 2.074538154219924
Validation loss: 2.548957937761143

Epoch: 5| Step: 5
Training loss: 2.0118968699588806
Validation loss: 2.5378921221978876

Epoch: 5| Step: 6
Training loss: 2.032955685967099
Validation loss: 2.581177502313517

Epoch: 5| Step: 7
Training loss: 2.1874415798560665
Validation loss: 2.628834433315864

Epoch: 5| Step: 8
Training loss: 2.085575029404981
Validation loss: 2.6119961281283386

Epoch: 5| Step: 9
Training loss: 2.048723623630808
Validation loss: 2.624355776206865

Epoch: 5| Step: 10
Training loss: 2.204948049785345
Validation loss: 2.595709854823791

Epoch: 206| Step: 0
Training loss: 2.3550427812387706
Validation loss: 2.5957793959730475

Epoch: 5| Step: 1
Training loss: 1.8571141707122647
Validation loss: 2.615682247364231

Epoch: 5| Step: 2
Training loss: 1.6469497837408962
Validation loss: 2.668287251694262

Epoch: 5| Step: 3
Training loss: 2.2720962185835054
Validation loss: 2.6978818664954334

Epoch: 5| Step: 4
Training loss: 2.3858587085876963
Validation loss: 2.745494437724763

Epoch: 5| Step: 5
Training loss: 2.4199350770801096
Validation loss: 2.678040680696054

Epoch: 5| Step: 6
Training loss: 2.2221314358710047
Validation loss: 2.62906640377452

Epoch: 5| Step: 7
Training loss: 1.9709575326293731
Validation loss: 2.5799391701813468

Epoch: 5| Step: 8
Training loss: 2.0396475117151733
Validation loss: 2.5410833255870515

Epoch: 5| Step: 9
Training loss: 2.1325750533175207
Validation loss: 2.5678487699909356

Epoch: 5| Step: 10
Training loss: 1.585486512352035
Validation loss: 2.589641293326757

Epoch: 207| Step: 0
Training loss: 1.5204661026111215
Validation loss: 2.5723409235633032

Epoch: 5| Step: 1
Training loss: 2.373495930698941
Validation loss: 2.6290320044370876

Epoch: 5| Step: 2
Training loss: 2.3469231043125705
Validation loss: 2.6035768480034243

Epoch: 5| Step: 3
Training loss: 1.7745173187528582
Validation loss: 2.6173974619190674

Epoch: 5| Step: 4
Training loss: 2.2259690949590127
Validation loss: 2.6322290268103057

Epoch: 5| Step: 5
Training loss: 2.2441277698649977
Validation loss: 2.628340660487277

Epoch: 5| Step: 6
Training loss: 2.010489019432715
Validation loss: 2.608514066167552

Epoch: 5| Step: 7
Training loss: 2.537940425892065
Validation loss: 2.595411747589082

Epoch: 5| Step: 8
Training loss: 1.8246783508709044
Validation loss: 2.5785436435153053

Epoch: 5| Step: 9
Training loss: 1.8383758585424606
Validation loss: 2.5996323051793313

Epoch: 5| Step: 10
Training loss: 1.3974173037196758
Validation loss: 2.6230561529880316

Epoch: 208| Step: 0
Training loss: 1.8176776333232116
Validation loss: 2.6560599995653025

Epoch: 5| Step: 1
Training loss: 2.674577294579724
Validation loss: 2.6986580165601453

Epoch: 5| Step: 2
Training loss: 2.4582621246197167
Validation loss: 2.674960800411169

Epoch: 5| Step: 3
Training loss: 2.067633742004773
Validation loss: 2.6022892458265394

Epoch: 5| Step: 4
Training loss: 1.8970437919014214
Validation loss: 2.5529623893806166

Epoch: 5| Step: 5
Training loss: 1.937166062156576
Validation loss: 2.560017765878231

Epoch: 5| Step: 6
Training loss: 1.8452651054116527
Validation loss: 2.572189986359177

Epoch: 5| Step: 7
Training loss: 1.8297337683374553
Validation loss: 2.5841896647064635

Epoch: 5| Step: 8
Training loss: 2.018990951661405
Validation loss: 2.5788236117111993

Epoch: 5| Step: 9
Training loss: 2.0871169509764473
Validation loss: 2.624453587851003

Epoch: 5| Step: 10
Training loss: 1.5851509135510378
Validation loss: 2.648154170943876

Epoch: 209| Step: 0
Training loss: 2.1483645894943693
Validation loss: 2.656849281417614

Epoch: 5| Step: 1
Training loss: 2.322381737760304
Validation loss: 2.660183589095459

Epoch: 5| Step: 2
Training loss: 2.188992236559726
Validation loss: 2.6793515837235695

Epoch: 5| Step: 3
Training loss: 2.05900115120454
Validation loss: 2.677225194305151

Epoch: 5| Step: 4
Training loss: 1.7804980112829032
Validation loss: 2.6645708093256903

Epoch: 5| Step: 5
Training loss: 1.7082335125051988
Validation loss: 2.661493537194323

Epoch: 5| Step: 6
Training loss: 1.9370848918582224
Validation loss: 2.666098777101998

Epoch: 5| Step: 7
Training loss: 2.2591230027685927
Validation loss: 2.6121431164155196

Epoch: 5| Step: 8
Training loss: 1.650349741773579
Validation loss: 2.6114119425009092

Epoch: 5| Step: 9
Training loss: 1.787786970244655
Validation loss: 2.588328627430672

Epoch: 5| Step: 10
Training loss: 2.0498179471194526
Validation loss: 2.5677599352711593

Epoch: 210| Step: 0
Training loss: 1.6363195692737058
Validation loss: 2.5662579856578764

Epoch: 5| Step: 1
Training loss: 2.03540634990825
Validation loss: 2.5611491380581235

Epoch: 5| Step: 2
Training loss: 1.8301200088381848
Validation loss: 2.57893786749353

Epoch: 5| Step: 3
Training loss: 1.7833029310659376
Validation loss: 2.569289953244738

Epoch: 5| Step: 4
Training loss: 2.0668877831990304
Validation loss: 2.5758931433058154

Epoch: 5| Step: 5
Training loss: 2.1351140497910723
Validation loss: 2.5801492420271366

Epoch: 5| Step: 6
Training loss: 1.6240062609490786
Validation loss: 2.5896213257617116

Epoch: 5| Step: 7
Training loss: 2.657390215123125
Validation loss: 2.607758494198206

Epoch: 5| Step: 8
Training loss: 1.9506427708103233
Validation loss: 2.6572480509714023

Epoch: 5| Step: 9
Training loss: 1.8211013329019519
Validation loss: 2.6817171552990557

Epoch: 5| Step: 10
Training loss: 2.019125449399769
Validation loss: 2.702111136517749

Epoch: 211| Step: 0
Training loss: 2.2381163531373125
Validation loss: 2.7023498563737185

Epoch: 5| Step: 1
Training loss: 1.6526258872554698
Validation loss: 2.647687730294702

Epoch: 5| Step: 2
Training loss: 1.7268713075126854
Validation loss: 2.6049581431627065

Epoch: 5| Step: 3
Training loss: 1.7772518595322087
Validation loss: 2.5709068872045155

Epoch: 5| Step: 4
Training loss: 2.3332659393750332
Validation loss: 2.5415543871494974

Epoch: 5| Step: 5
Training loss: 1.7423608120642275
Validation loss: 2.539630558151207

Epoch: 5| Step: 6
Training loss: 1.7208788778760538
Validation loss: 2.510717965587926

Epoch: 5| Step: 7
Training loss: 2.241513247244647
Validation loss: 2.5128524891361055

Epoch: 5| Step: 8
Training loss: 1.6181018842723538
Validation loss: 2.4935670143060715

Epoch: 5| Step: 9
Training loss: 2.3268525403312093
Validation loss: 2.5197182608427022

Epoch: 5| Step: 10
Training loss: 2.0185079140081603
Validation loss: 2.527445853583574

Epoch: 212| Step: 0
Training loss: 1.722091686094074
Validation loss: 2.6006800682290856

Epoch: 5| Step: 1
Training loss: 2.0624825447962247
Validation loss: 2.655151129273718

Epoch: 5| Step: 2
Training loss: 2.245742053817387
Validation loss: 2.6635571996183223

Epoch: 5| Step: 3
Training loss: 2.1980178833807567
Validation loss: 2.638269048071155

Epoch: 5| Step: 4
Training loss: 1.6088040274178408
Validation loss: 2.5879071020869877

Epoch: 5| Step: 5
Training loss: 2.065805272071678
Validation loss: 2.5822430200926294

Epoch: 5| Step: 6
Training loss: 1.747194357189736
Validation loss: 2.572927395158606

Epoch: 5| Step: 7
Training loss: 1.7656532892982255
Validation loss: 2.623394523505612

Epoch: 5| Step: 8
Training loss: 2.297377758406165
Validation loss: 2.678135354230754

Epoch: 5| Step: 9
Training loss: 2.0682560910237013
Validation loss: 2.7240696312187604

Epoch: 5| Step: 10
Training loss: 1.6536053830303241
Validation loss: 2.7661384637488227

Epoch: 213| Step: 0
Training loss: 2.02399569437828
Validation loss: 2.721641520096465

Epoch: 5| Step: 1
Training loss: 1.6340679106309979
Validation loss: 2.7414504579516517

Epoch: 5| Step: 2
Training loss: 2.2095096142454587
Validation loss: 2.6768022168342274

Epoch: 5| Step: 3
Training loss: 1.8034815206064816
Validation loss: 2.6784363478876028

Epoch: 5| Step: 4
Training loss: 1.3865059702786304
Validation loss: 2.6693930846080702

Epoch: 5| Step: 5
Training loss: 2.1878356676056057
Validation loss: 2.60866185209384

Epoch: 5| Step: 6
Training loss: 1.7396485855138453
Validation loss: 2.623044028948848

Epoch: 5| Step: 7
Training loss: 1.7393521214254257
Validation loss: 2.5812944724975826

Epoch: 5| Step: 8
Training loss: 2.2743520044399674
Validation loss: 2.6010531448783256

Epoch: 5| Step: 9
Training loss: 2.270468224621277
Validation loss: 2.5865997328004227

Epoch: 5| Step: 10
Training loss: 1.652266696729551
Validation loss: 2.53215897744238

Epoch: 214| Step: 0
Training loss: 2.1990574291409843
Validation loss: 2.579937063573397

Epoch: 5| Step: 1
Training loss: 1.9608387713256257
Validation loss: 2.580840859055814

Epoch: 5| Step: 2
Training loss: 1.8264894913048155
Validation loss: 2.592974493843845

Epoch: 5| Step: 3
Training loss: 1.723132286125555
Validation loss: 2.5766751336431386

Epoch: 5| Step: 4
Training loss: 1.710586093715204
Validation loss: 2.5859201696692713

Epoch: 5| Step: 5
Training loss: 1.9572937688432184
Validation loss: 2.5635393657501413

Epoch: 5| Step: 6
Training loss: 1.8985878841663344
Validation loss: 2.5890273989923007

Epoch: 5| Step: 7
Training loss: 1.869377671280983
Validation loss: 2.5970677598254097

Epoch: 5| Step: 8
Training loss: 1.568361579256896
Validation loss: 2.6026942025965054

Epoch: 5| Step: 9
Training loss: 2.095118516651485
Validation loss: 2.6810989424913165

Epoch: 5| Step: 10
Training loss: 2.261594251721056
Validation loss: 2.721496525239155

Epoch: 215| Step: 0
Training loss: 1.7323656556857128
Validation loss: 2.7278951926832584

Epoch: 5| Step: 1
Training loss: 1.6199402899393391
Validation loss: 2.600163951126637

Epoch: 5| Step: 2
Training loss: 2.1692270287483044
Validation loss: 2.5630324115997567

Epoch: 5| Step: 3
Training loss: 1.9040476474530155
Validation loss: 2.540620664917196

Epoch: 5| Step: 4
Training loss: 2.2343722256729937
Validation loss: 2.533387525715007

Epoch: 5| Step: 5
Training loss: 2.030243492180858
Validation loss: 2.5419893354142147

Epoch: 5| Step: 6
Training loss: 2.123170626208738
Validation loss: 2.5674418855897017

Epoch: 5| Step: 7
Training loss: 2.0659744590369615
Validation loss: 2.601526184922391

Epoch: 5| Step: 8
Training loss: 2.0088398601987514
Validation loss: 2.653312014753173

Epoch: 5| Step: 9
Training loss: 1.4558078241906558
Validation loss: 2.724660223747603

Epoch: 5| Step: 10
Training loss: 1.5957658771703358
Validation loss: 2.7405988823723613

Epoch: 216| Step: 0
Training loss: 1.4949795630343516
Validation loss: 2.7149291459389

Epoch: 5| Step: 1
Training loss: 1.5223345554202956
Validation loss: 2.6655525455322984

Epoch: 5| Step: 2
Training loss: 1.7655627484445486
Validation loss: 2.6352880371044143

Epoch: 5| Step: 3
Training loss: 1.6122294176763265
Validation loss: 2.615914839224846

Epoch: 5| Step: 4
Training loss: 1.5781715310667996
Validation loss: 2.659446352829088

Epoch: 5| Step: 5
Training loss: 2.389606233823529
Validation loss: 2.636265922137367

Epoch: 5| Step: 6
Training loss: 2.001989567122585
Validation loss: 2.5748114239952966

Epoch: 5| Step: 7
Training loss: 2.188655330194416
Validation loss: 2.486678688071174

Epoch: 5| Step: 8
Training loss: 2.4651136054116147
Validation loss: 2.48604621897233

Epoch: 5| Step: 9
Training loss: 1.7318431485405514
Validation loss: 2.4604547884343493

Epoch: 5| Step: 10
Training loss: 1.9548375060706147
Validation loss: 2.4954494058244703

Epoch: 217| Step: 0
Training loss: 1.8212638628241584
Validation loss: 2.5223439232321363

Epoch: 5| Step: 1
Training loss: 1.8122154538649113
Validation loss: 2.647720336128782

Epoch: 5| Step: 2
Training loss: 1.9258180193070031
Validation loss: 2.802125855365025

Epoch: 5| Step: 3
Training loss: 2.130514506851293
Validation loss: 2.8096141479927255

Epoch: 5| Step: 4
Training loss: 2.1285189495036203
Validation loss: 2.6390889901670027

Epoch: 5| Step: 5
Training loss: 2.2402869486938037
Validation loss: 2.531543051850445

Epoch: 5| Step: 6
Training loss: 1.300827804511322
Validation loss: 2.4684638234851066

Epoch: 5| Step: 7
Training loss: 1.9522413772664189
Validation loss: 2.423069325266803

Epoch: 5| Step: 8
Training loss: 1.947648449823618
Validation loss: 2.4574642049375557

Epoch: 5| Step: 9
Training loss: 1.6862595555492133
Validation loss: 2.5017581500069395

Epoch: 5| Step: 10
Training loss: 2.0291643439037443
Validation loss: 2.5691580106022838

Epoch: 218| Step: 0
Training loss: 1.9646994687567254
Validation loss: 2.6402733263955516

Epoch: 5| Step: 1
Training loss: 1.8103542780981832
Validation loss: 2.6304461387623577

Epoch: 5| Step: 2
Training loss: 2.0920517140227455
Validation loss: 2.6387713050084223

Epoch: 5| Step: 3
Training loss: 1.6777158298733117
Validation loss: 2.6088075679722427

Epoch: 5| Step: 4
Training loss: 1.528244806441536
Validation loss: 2.5518323931064164

Epoch: 5| Step: 5
Training loss: 1.8485808367709822
Validation loss: 2.539624973844646

Epoch: 5| Step: 6
Training loss: 1.9230867613027247
Validation loss: 2.5171311519956263

Epoch: 5| Step: 7
Training loss: 1.7983961218242304
Validation loss: 2.5598930395842143

Epoch: 5| Step: 8
Training loss: 2.059980645505481
Validation loss: 2.6155990440321726

Epoch: 5| Step: 9
Training loss: 1.948850975430247
Validation loss: 2.6235481315737412

Epoch: 5| Step: 10
Training loss: 1.8263235753334752
Validation loss: 2.6530844755532375

Epoch: 219| Step: 0
Training loss: 1.7301009155343336
Validation loss: 2.687672494330617

Epoch: 5| Step: 1
Training loss: 2.1233706117807993
Validation loss: 2.6361570364440414

Epoch: 5| Step: 2
Training loss: 1.3719988061048913
Validation loss: 2.5950043905866225

Epoch: 5| Step: 3
Training loss: 1.7741728615044192
Validation loss: 2.580404730076838

Epoch: 5| Step: 4
Training loss: 1.7904863979629344
Validation loss: 2.5617950744420135

Epoch: 5| Step: 5
Training loss: 2.1538869099376554
Validation loss: 2.5612207696732168

Epoch: 5| Step: 6
Training loss: 1.7722759055667012
Validation loss: 2.585965434888468

Epoch: 5| Step: 7
Training loss: 1.8604597886211607
Validation loss: 2.6264108439915863

Epoch: 5| Step: 8
Training loss: 1.9060775803931531
Validation loss: 2.649631484836719

Epoch: 5| Step: 9
Training loss: 1.6435430099063386
Validation loss: 2.688844026580411

Epoch: 5| Step: 10
Training loss: 1.880355815087402
Validation loss: 2.692519477734711

Epoch: 220| Step: 0
Training loss: 1.1776810819040713
Validation loss: 2.7583217857671074

Epoch: 5| Step: 1
Training loss: 2.176884643638469
Validation loss: 2.8130123268842113

Epoch: 5| Step: 2
Training loss: 1.620073185668662
Validation loss: 2.7648352530175933

Epoch: 5| Step: 3
Training loss: 2.188402371253303
Validation loss: 2.703106059460253

Epoch: 5| Step: 4
Training loss: 1.878491012783245
Validation loss: 2.605176030275372

Epoch: 5| Step: 5
Training loss: 1.8123493789702518
Validation loss: 2.5066465337279036

Epoch: 5| Step: 6
Training loss: 1.895808090489052
Validation loss: 2.500218140919145

Epoch: 5| Step: 7
Training loss: 2.0221221065308352
Validation loss: 2.502894279745469

Epoch: 5| Step: 8
Training loss: 1.8387851787964784
Validation loss: 2.546476362003324

Epoch: 5| Step: 9
Training loss: 1.7036202786740071
Validation loss: 2.598303201308329

Epoch: 5| Step: 10
Training loss: 1.5768603554860954
Validation loss: 2.6812031546838258

Epoch: 221| Step: 0
Training loss: 1.8332262513648547
Validation loss: 2.7172492504129275

Epoch: 5| Step: 1
Training loss: 1.7185400401099358
Validation loss: 2.6669327634541413

Epoch: 5| Step: 2
Training loss: 1.5868239908332338
Validation loss: 2.5950019247526184

Epoch: 5| Step: 3
Training loss: 1.8613615563383452
Validation loss: 2.5436771583654507

Epoch: 5| Step: 4
Training loss: 1.9587707707339044
Validation loss: 2.5074319904443247

Epoch: 5| Step: 5
Training loss: 2.1477479140118687
Validation loss: 2.4805197521492794

Epoch: 5| Step: 6
Training loss: 2.2366887630540413
Validation loss: 2.5290151716898848

Epoch: 5| Step: 7
Training loss: 1.5418807044385667
Validation loss: 2.6033487816601815

Epoch: 5| Step: 8
Training loss: 1.6198126821187036
Validation loss: 2.694201288421365

Epoch: 5| Step: 9
Training loss: 1.8862051254809549
Validation loss: 2.7196225171365116

Epoch: 5| Step: 10
Training loss: 1.7480196647018031
Validation loss: 2.7301796770352356

Epoch: 222| Step: 0
Training loss: 1.643481211569695
Validation loss: 2.6691483590726097

Epoch: 5| Step: 1
Training loss: 1.784458215914251
Validation loss: 2.5863575284591405

Epoch: 5| Step: 2
Training loss: 1.9282682195609104
Validation loss: 2.541688730523016

Epoch: 5| Step: 3
Training loss: 2.1652557718842877
Validation loss: 2.526096437700041

Epoch: 5| Step: 4
Training loss: 1.4872788785822926
Validation loss: 2.501201557261971

Epoch: 5| Step: 5
Training loss: 1.6977284879100953
Validation loss: 2.5407955392202206

Epoch: 5| Step: 6
Training loss: 1.5461016176244284
Validation loss: 2.623320691338489

Epoch: 5| Step: 7
Training loss: 2.027811867356257
Validation loss: 2.669345624922861

Epoch: 5| Step: 8
Training loss: 2.058458240544113
Validation loss: 2.6955286320695677

Epoch: 5| Step: 9
Training loss: 1.4544020752790225
Validation loss: 2.7213643410577806

Epoch: 5| Step: 10
Training loss: 1.7133267933662566
Validation loss: 2.7467848570756637

Epoch: 223| Step: 0
Training loss: 1.5887814283526376
Validation loss: 2.7008433958281897

Epoch: 5| Step: 1
Training loss: 1.704462069003482
Validation loss: 2.6648243547402375

Epoch: 5| Step: 2
Training loss: 1.564300110533599
Validation loss: 2.655269092790286

Epoch: 5| Step: 3
Training loss: 1.5241830419818638
Validation loss: 2.5973100965604496

Epoch: 5| Step: 4
Training loss: 1.7771937044966744
Validation loss: 2.5646076233796977

Epoch: 5| Step: 5
Training loss: 1.512581591336424
Validation loss: 2.5821922738173892

Epoch: 5| Step: 6
Training loss: 1.9132604670301212
Validation loss: 2.63065548294813

Epoch: 5| Step: 7
Training loss: 2.1056826452764454
Validation loss: 2.6877864657308383

Epoch: 5| Step: 8
Training loss: 1.4621987024323668
Validation loss: 2.6645911571537884

Epoch: 5| Step: 9
Training loss: 2.2445921016295487
Validation loss: 2.666787772223039

Epoch: 5| Step: 10
Training loss: 1.8735519539659409
Validation loss: 2.638466975693146

Epoch: 224| Step: 0
Training loss: 1.716803679816221
Validation loss: 2.613061075849639

Epoch: 5| Step: 1
Training loss: 1.5355194671599248
Validation loss: 2.610404818591874

Epoch: 5| Step: 2
Training loss: 1.8393106194343014
Validation loss: 2.559134100810055

Epoch: 5| Step: 3
Training loss: 1.9360511654051213
Validation loss: 2.5344712272510783

Epoch: 5| Step: 4
Training loss: 1.3719463686094873
Validation loss: 2.511897710268908

Epoch: 5| Step: 5
Training loss: 1.597876647819452
Validation loss: 2.5319431884591626

Epoch: 5| Step: 6
Training loss: 1.7718050665400917
Validation loss: 2.5405622033000053

Epoch: 5| Step: 7
Training loss: 1.9649961499669066
Validation loss: 2.611496074392718

Epoch: 5| Step: 8
Training loss: 1.9074416266392675
Validation loss: 2.6460671622314673

Epoch: 5| Step: 9
Training loss: 1.7286366565809785
Validation loss: 2.7217471893684584

Epoch: 5| Step: 10
Training loss: 1.9713934453950666
Validation loss: 2.7962543465507848

Epoch: 225| Step: 0
Training loss: 2.1884859315534615
Validation loss: 2.7506878534212804

Epoch: 5| Step: 1
Training loss: 1.5040500324429213
Validation loss: 2.687230340126056

Epoch: 5| Step: 2
Training loss: 1.550264748143735
Validation loss: 2.6044142650087907

Epoch: 5| Step: 3
Training loss: 1.4523637479869411
Validation loss: 2.6111262021108304

Epoch: 5| Step: 4
Training loss: 1.5478525637072866
Validation loss: 2.5813219819136277

Epoch: 5| Step: 5
Training loss: 2.0150204720415577
Validation loss: 2.6059122151099743

Epoch: 5| Step: 6
Training loss: 1.8764494062230908
Validation loss: 2.6180507783213414

Epoch: 5| Step: 7
Training loss: 1.80733978764418
Validation loss: 2.7573002295284392

Epoch: 5| Step: 8
Training loss: 1.8352314342104807
Validation loss: 2.8310070999306323

Epoch: 5| Step: 9
Training loss: 1.506436446430987
Validation loss: 2.8424880418901033

Epoch: 5| Step: 10
Training loss: 1.9314073319528915
Validation loss: 2.8431860305827885

Epoch: 226| Step: 0
Training loss: 1.2367251754468513
Validation loss: 2.7384865671409946

Epoch: 5| Step: 1
Training loss: 1.9535767299872073
Validation loss: 2.6262483260581484

Epoch: 5| Step: 2
Training loss: 1.75692197494647
Validation loss: 2.56373357006585

Epoch: 5| Step: 3
Training loss: 1.732140553715878
Validation loss: 2.5294963788870835

Epoch: 5| Step: 4
Training loss: 1.750304740530317
Validation loss: 2.5512025084486614

Epoch: 5| Step: 5
Training loss: 1.613173659018269
Validation loss: 2.547857143868726

Epoch: 5| Step: 6
Training loss: 1.6329265353887805
Validation loss: 2.6363842746025687

Epoch: 5| Step: 7
Training loss: 1.5753104918076835
Validation loss: 2.654011168325878

Epoch: 5| Step: 8
Training loss: 1.6793301224328925
Validation loss: 2.700685753781611

Epoch: 5| Step: 9
Training loss: 1.9137972901006093
Validation loss: 2.730976748804953

Epoch: 5| Step: 10
Training loss: 2.2460535195106335
Validation loss: 2.688249705228503

Epoch: 227| Step: 0
Training loss: 1.5073795784193407
Validation loss: 2.687854902715477

Epoch: 5| Step: 1
Training loss: 1.776590174960172
Validation loss: 2.6435899927192144

Epoch: 5| Step: 2
Training loss: 1.6937652418288345
Validation loss: 2.622398000986063

Epoch: 5| Step: 3
Training loss: 1.627740895949636
Validation loss: 2.6426178534080793

Epoch: 5| Step: 4
Training loss: 2.0861301976039224
Validation loss: 2.6272557660170213

Epoch: 5| Step: 5
Training loss: 1.8718146287356434
Validation loss: 2.659651156922363

Epoch: 5| Step: 6
Training loss: 1.8278557994903397
Validation loss: 2.6539891098125077

Epoch: 5| Step: 7
Training loss: 1.4949455137753698
Validation loss: 2.666057021558777

Epoch: 5| Step: 8
Training loss: 1.341816153797319
Validation loss: 2.664083867896593

Epoch: 5| Step: 9
Training loss: 1.5468770807425636
Validation loss: 2.661129902174533

Epoch: 5| Step: 10
Training loss: 1.7529728026121791
Validation loss: 2.7040116359645765

Epoch: 228| Step: 0
Training loss: 1.525357410884994
Validation loss: 2.692701633941935

Epoch: 5| Step: 1
Training loss: 1.4450638015811823
Validation loss: 2.6561784110897

Epoch: 5| Step: 2
Training loss: 1.6760574504456027
Validation loss: 2.6084427150890206

Epoch: 5| Step: 3
Training loss: 1.7482401991342662
Validation loss: 2.5564813491501224

Epoch: 5| Step: 4
Training loss: 1.6608476702423343
Validation loss: 2.5603037420618264

Epoch: 5| Step: 5
Training loss: 1.865180369289335
Validation loss: 2.5865477498154013

Epoch: 5| Step: 6
Training loss: 1.3247360974338391
Validation loss: 2.5944427413184155

Epoch: 5| Step: 7
Training loss: 1.359496714086795
Validation loss: 2.5784201156340356

Epoch: 5| Step: 8
Training loss: 1.8987327314725433
Validation loss: 2.626277224163126

Epoch: 5| Step: 9
Training loss: 1.696620032613283
Validation loss: 2.680399364595409

Epoch: 5| Step: 10
Training loss: 2.146265103748567
Validation loss: 2.7372825874858666

Epoch: 229| Step: 0
Training loss: 2.0566858357299225
Validation loss: 2.731628081713478

Epoch: 5| Step: 1
Training loss: 1.7443878237869013
Validation loss: 2.678013801991965

Epoch: 5| Step: 2
Training loss: 1.7571215140367904
Validation loss: 2.6015287115821017

Epoch: 5| Step: 3
Training loss: 1.674316904641403
Validation loss: 2.561169830084351

Epoch: 5| Step: 4
Training loss: 1.607381604641556
Validation loss: 2.5067145376695104

Epoch: 5| Step: 5
Training loss: 1.5500551921493333
Validation loss: 2.48448371507454

Epoch: 5| Step: 6
Training loss: 1.6127128431031026
Validation loss: 2.568301450962919

Epoch: 5| Step: 7
Training loss: 1.6999972960506702
Validation loss: 2.6618698884280776

Epoch: 5| Step: 8
Training loss: 1.5645873813432865
Validation loss: 2.737523391877667

Epoch: 5| Step: 9
Training loss: 1.4317906653662509
Validation loss: 2.81246993255039

Epoch: 5| Step: 10
Training loss: 1.8814854674131591
Validation loss: 2.8254728189653866

Epoch: 230| Step: 0
Training loss: 1.4762529321135909
Validation loss: 2.755203738044855

Epoch: 5| Step: 1
Training loss: 2.2429671045375037
Validation loss: 2.6636587863167067

Epoch: 5| Step: 2
Training loss: 1.848045775825014
Validation loss: 2.5802921805870547

Epoch: 5| Step: 3
Training loss: 1.0824404607173204
Validation loss: 2.532490900995516

Epoch: 5| Step: 4
Training loss: 1.7287832624058557
Validation loss: 2.49208323379882

Epoch: 5| Step: 5
Training loss: 1.752181056408628
Validation loss: 2.5004286490863232

Epoch: 5| Step: 6
Training loss: 1.7546101200641118
Validation loss: 2.5147868478406026

Epoch: 5| Step: 7
Training loss: 1.6901879272708664
Validation loss: 2.5987262376003724

Epoch: 5| Step: 8
Training loss: 1.695818917715426
Validation loss: 2.6612435893942656

Epoch: 5| Step: 9
Training loss: 1.230931319225838
Validation loss: 2.7376320337765447

Epoch: 5| Step: 10
Training loss: 1.7378868084122019
Validation loss: 2.738781800571671

Epoch: 231| Step: 0
Training loss: 1.5792834118824262
Validation loss: 2.6833886810058947

Epoch: 5| Step: 1
Training loss: 1.7996312770417402
Validation loss: 2.6270321999209245

Epoch: 5| Step: 2
Training loss: 1.409734520234751
Validation loss: 2.577815879867387

Epoch: 5| Step: 3
Training loss: 1.4665493000638683
Validation loss: 2.5421796597389

Epoch: 5| Step: 4
Training loss: 1.5958060671449923
Validation loss: 2.5511368118638966

Epoch: 5| Step: 5
Training loss: 1.9928320945146107
Validation loss: 2.554217440291829

Epoch: 5| Step: 6
Training loss: 1.7576600411315124
Validation loss: 2.5749178679673204

Epoch: 5| Step: 7
Training loss: 1.5780936511863524
Validation loss: 2.5924516678457663

Epoch: 5| Step: 8
Training loss: 1.5467365087300275
Validation loss: 2.6387326806521427

Epoch: 5| Step: 9
Training loss: 1.4116715508293562
Validation loss: 2.6989667695979613

Epoch: 5| Step: 10
Training loss: 1.7691581282167792
Validation loss: 2.7245407537495336

Epoch: 232| Step: 0
Training loss: 1.6908898391168374
Validation loss: 2.776988235744719

Epoch: 5| Step: 1
Training loss: 1.259044872775022
Validation loss: 2.7819044636598393

Epoch: 5| Step: 2
Training loss: 1.6340527364468693
Validation loss: 2.7468858427587155

Epoch: 5| Step: 3
Training loss: 1.4977621233097198
Validation loss: 2.7290029964358498

Epoch: 5| Step: 4
Training loss: 1.4780055669233196
Validation loss: 2.65743849126212

Epoch: 5| Step: 5
Training loss: 1.77082699793262
Validation loss: 2.607067671532679

Epoch: 5| Step: 6
Training loss: 1.6109524745596677
Validation loss: 2.6264660067494394

Epoch: 5| Step: 7
Training loss: 1.8187690707645585
Validation loss: 2.6294343730523617

Epoch: 5| Step: 8
Training loss: 1.631859606257883
Validation loss: 2.6410862300873554

Epoch: 5| Step: 9
Training loss: 1.855180384664401
Validation loss: 2.608056991953089

Epoch: 5| Step: 10
Training loss: 1.395606345134447
Validation loss: 2.6129744311733987

Epoch: 233| Step: 0
Training loss: 1.3468405646150605
Validation loss: 2.6181441048803324

Epoch: 5| Step: 1
Training loss: 1.4846026597365212
Validation loss: 2.60907468982866

Epoch: 5| Step: 2
Training loss: 1.832089225974145
Validation loss: 2.5844928292458347

Epoch: 5| Step: 3
Training loss: 1.3314309207675095
Validation loss: 2.5709682954167525

Epoch: 5| Step: 4
Training loss: 1.4307732133596949
Validation loss: 2.5997567135565958

Epoch: 5| Step: 5
Training loss: 1.5063055542637378
Validation loss: 2.6063043551657814

Epoch: 5| Step: 6
Training loss: 1.7145349315734846
Validation loss: 2.626773094763079

Epoch: 5| Step: 7
Training loss: 1.7553513994027325
Validation loss: 2.6202971232328474

Epoch: 5| Step: 8
Training loss: 1.8137223955784016
Validation loss: 2.6219787028021186

Epoch: 5| Step: 9
Training loss: 1.8238802806188776
Validation loss: 2.6324766381852887

Epoch: 5| Step: 10
Training loss: 1.486402071142242
Validation loss: 2.61710750853693

Epoch: 234| Step: 0
Training loss: 1.412887633143583
Validation loss: 2.5927599072202296

Epoch: 5| Step: 1
Training loss: 1.4300788385493133
Validation loss: 2.606822983767347

Epoch: 5| Step: 2
Training loss: 1.73838507524378
Validation loss: 2.624509822767507

Epoch: 5| Step: 3
Training loss: 1.5274928183628709
Validation loss: 2.6311709310586617

Epoch: 5| Step: 4
Training loss: 1.7328350344294232
Validation loss: 2.612990899705876

Epoch: 5| Step: 5
Training loss: 1.626265253322415
Validation loss: 2.618661596679934

Epoch: 5| Step: 6
Training loss: 2.000007271753443
Validation loss: 2.576585171465699

Epoch: 5| Step: 7
Training loss: 1.1549673440783732
Validation loss: 2.566609690459569

Epoch: 5| Step: 8
Training loss: 1.0462827572998425
Validation loss: 2.5843179085518897

Epoch: 5| Step: 9
Training loss: 1.6576723433202467
Validation loss: 2.6023188060163336

Epoch: 5| Step: 10
Training loss: 1.9066516265520477
Validation loss: 2.643007330337515

Epoch: 235| Step: 0
Training loss: 1.1143607811654492
Validation loss: 2.6721882219456656

Epoch: 5| Step: 1
Training loss: 1.7926786433200854
Validation loss: 2.6575248790706194

Epoch: 5| Step: 2
Training loss: 1.678900813914463
Validation loss: 2.675141704678981

Epoch: 5| Step: 3
Training loss: 1.2427538174632162
Validation loss: 2.6455317208988545

Epoch: 5| Step: 4
Training loss: 1.6877316916321305
Validation loss: 2.639907410294733

Epoch: 5| Step: 5
Training loss: 1.7266840827215753
Validation loss: 2.6381590954692595

Epoch: 5| Step: 6
Training loss: 1.0927934005591093
Validation loss: 2.597241457114696

Epoch: 5| Step: 7
Training loss: 1.8704769256645106
Validation loss: 2.542629610924104

Epoch: 5| Step: 8
Training loss: 1.8627516275720548
Validation loss: 2.597261019640263

Epoch: 5| Step: 9
Training loss: 1.676306297727981
Validation loss: 2.6433774575042945

Epoch: 5| Step: 10
Training loss: 1.3561509584046356
Validation loss: 2.655250507007367

Epoch: 236| Step: 0
Training loss: 1.5835686642617561
Validation loss: 2.657447865271039

Epoch: 5| Step: 1
Training loss: 1.4781810628892686
Validation loss: 2.6270263007830907

Epoch: 5| Step: 2
Training loss: 1.1655862551224998
Validation loss: 2.5831982110523746

Epoch: 5| Step: 3
Training loss: 1.5246411385967076
Validation loss: 2.5712894294053394

Epoch: 5| Step: 4
Training loss: 1.5685523497552543
Validation loss: 2.5960136495794783

Epoch: 5| Step: 5
Training loss: 1.5255458230207266
Validation loss: 2.6101861039062

Epoch: 5| Step: 6
Training loss: 1.4802583328525363
Validation loss: 2.61389381354728

Epoch: 5| Step: 7
Training loss: 1.8390871342878379
Validation loss: 2.625080089841541

Epoch: 5| Step: 8
Training loss: 1.8820000632850564
Validation loss: 2.6285116104288115

Epoch: 5| Step: 9
Training loss: 1.7991225408620626
Validation loss: 2.6583274829157335

Epoch: 5| Step: 10
Training loss: 1.2149761655220073
Validation loss: 2.6609692802205616

Epoch: 237| Step: 0
Training loss: 1.5627859998262883
Validation loss: 2.667379355337752

Epoch: 5| Step: 1
Training loss: 1.6873559537090008
Validation loss: 2.6626289525170543

Epoch: 5| Step: 2
Training loss: 2.011111269588476
Validation loss: 2.6370652669089574

Epoch: 5| Step: 3
Training loss: 1.5463559599630772
Validation loss: 2.6071623391535534

Epoch: 5| Step: 4
Training loss: 1.7120218542254952
Validation loss: 2.5959248671643285

Epoch: 5| Step: 5
Training loss: 1.4148173978006005
Validation loss: 2.5731537003819143

Epoch: 5| Step: 6
Training loss: 1.5664518354446602
Validation loss: 2.6011802675606783

Epoch: 5| Step: 7
Training loss: 1.2143194901152627
Validation loss: 2.638951980715979

Epoch: 5| Step: 8
Training loss: 1.3628882686105892
Validation loss: 2.6560196257261635

Epoch: 5| Step: 9
Training loss: 1.422244767955719
Validation loss: 2.6974756606778274

Epoch: 5| Step: 10
Training loss: 1.3717635819847454
Validation loss: 2.699523385266587

Epoch: 238| Step: 0
Training loss: 1.2832886828461936
Validation loss: 2.670967662331345

Epoch: 5| Step: 1
Training loss: 1.375182529818605
Validation loss: 2.672070674355237

Epoch: 5| Step: 2
Training loss: 0.8245372428047345
Validation loss: 2.651777505769446

Epoch: 5| Step: 3
Training loss: 1.8017832849867765
Validation loss: 2.6277704537002906

Epoch: 5| Step: 4
Training loss: 1.3579404869382086
Validation loss: 2.684739943224812

Epoch: 5| Step: 5
Training loss: 0.7754293283176613
Validation loss: 2.6687469488552367

Epoch: 5| Step: 6
Training loss: 1.708959263208361
Validation loss: 2.6720387580666736

Epoch: 5| Step: 7
Training loss: 1.6486172691058094
Validation loss: 2.6882476463043483

Epoch: 5| Step: 8
Training loss: 2.137969771846836
Validation loss: 2.6579221438761302

Epoch: 5| Step: 9
Training loss: 1.6471455650368774
Validation loss: 2.6128673795028536

Epoch: 5| Step: 10
Training loss: 1.7013344407830375
Validation loss: 2.588842614186776

Epoch: 239| Step: 0
Training loss: 1.8745694619834452
Validation loss: 2.5639989537093966

Epoch: 5| Step: 1
Training loss: 1.6724950763532984
Validation loss: 2.5939720227798753

Epoch: 5| Step: 2
Training loss: 1.796220145936418
Validation loss: 2.5895788983822086

Epoch: 5| Step: 3
Training loss: 1.0304439168602881
Validation loss: 2.60834321403447

Epoch: 5| Step: 4
Training loss: 0.8860836022955795
Validation loss: 2.678567910355671

Epoch: 5| Step: 5
Training loss: 1.384672089122709
Validation loss: 2.6979268135174244

Epoch: 5| Step: 6
Training loss: 1.7979448533602156
Validation loss: 2.687246832974711

Epoch: 5| Step: 7
Training loss: 1.47644276612859
Validation loss: 2.6813629623020856

Epoch: 5| Step: 8
Training loss: 1.5181227091068779
Validation loss: 2.6701301615707114

Epoch: 5| Step: 9
Training loss: 1.554983676321819
Validation loss: 2.6592908233958763

Epoch: 5| Step: 10
Training loss: 1.3123404542136954
Validation loss: 2.625418578379164

Epoch: 240| Step: 0
Training loss: 1.571653941329836
Validation loss: 2.5856702048234808

Epoch: 5| Step: 1
Training loss: 1.4029562629902785
Validation loss: 2.590144093578078

Epoch: 5| Step: 2
Training loss: 1.5172206698247963
Validation loss: 2.5978570735114714

Epoch: 5| Step: 3
Training loss: 1.7573465365481624
Validation loss: 2.6017597752759545

Epoch: 5| Step: 4
Training loss: 1.4015342479907567
Validation loss: 2.61871382766432

Epoch: 5| Step: 5
Training loss: 1.3885845688041725
Validation loss: 2.6460946221880945

Epoch: 5| Step: 6
Training loss: 1.720729935921055
Validation loss: 2.696124709232656

Epoch: 5| Step: 7
Training loss: 1.5381772356336039
Validation loss: 2.6883441975648195

Epoch: 5| Step: 8
Training loss: 1.550541626219852
Validation loss: 2.689229377789648

Epoch: 5| Step: 9
Training loss: 1.59569266606502
Validation loss: 2.7042540075588093

Epoch: 5| Step: 10
Training loss: 0.8738303541309367
Validation loss: 2.665823636569559

Epoch: 241| Step: 0
Training loss: 1.4644283265104947
Validation loss: 2.610848178780144

Epoch: 5| Step: 1
Training loss: 1.3910734332273258
Validation loss: 2.5561625520477045

Epoch: 5| Step: 2
Training loss: 1.4220350405993887
Validation loss: 2.5567718188674187

Epoch: 5| Step: 3
Training loss: 1.7317205512603557
Validation loss: 2.55202681525111

Epoch: 5| Step: 4
Training loss: 1.916878384492944
Validation loss: 2.577702976661621

Epoch: 5| Step: 5
Training loss: 1.3670323747095487
Validation loss: 2.574711047410407

Epoch: 5| Step: 6
Training loss: 1.4433810964144898
Validation loss: 2.643293260401117

Epoch: 5| Step: 7
Training loss: 1.617662590380682
Validation loss: 2.6329667338402847

Epoch: 5| Step: 8
Training loss: 1.028311270214874
Validation loss: 2.6882034930163496

Epoch: 5| Step: 9
Training loss: 1.1701900321331193
Validation loss: 2.690498527957979

Epoch: 5| Step: 10
Training loss: 1.7698117469634846
Validation loss: 2.6450013498273015

Epoch: 242| Step: 0
Training loss: 1.4651714314482467
Validation loss: 2.668556150277108

Epoch: 5| Step: 1
Training loss: 1.6115999859438488
Validation loss: 2.6528824559333724

Epoch: 5| Step: 2
Training loss: 1.8918987428695766
Validation loss: 2.639132184584487

Epoch: 5| Step: 3
Training loss: 1.2349302757133347
Validation loss: 2.635647208980317

Epoch: 5| Step: 4
Training loss: 1.439580738306352
Validation loss: 2.652678760594155

Epoch: 5| Step: 5
Training loss: 1.5977639159693482
Validation loss: 2.6370873522721094

Epoch: 5| Step: 6
Training loss: 1.662650713865221
Validation loss: 2.6451305075724374

Epoch: 5| Step: 7
Training loss: 1.3216319967792032
Validation loss: 2.6229590437740056

Epoch: 5| Step: 8
Training loss: 1.5397104361397285
Validation loss: 2.6438190220115905

Epoch: 5| Step: 9
Training loss: 1.0129914397982305
Validation loss: 2.60380863279818

Epoch: 5| Step: 10
Training loss: 1.3854080668399995
Validation loss: 2.60767478734826

Epoch: 243| Step: 0
Training loss: 1.3210456663435228
Validation loss: 2.5709199790641906

Epoch: 5| Step: 1
Training loss: 1.640795453617413
Validation loss: 2.6206012314016

Epoch: 5| Step: 2
Training loss: 2.011731312536625
Validation loss: 2.6261364790780237

Epoch: 5| Step: 3
Training loss: 1.044766765740195
Validation loss: 2.606600272476014

Epoch: 5| Step: 4
Training loss: 1.623823326751616
Validation loss: 2.644681655829194

Epoch: 5| Step: 5
Training loss: 1.722430363591479
Validation loss: 2.6560244373385733

Epoch: 5| Step: 6
Training loss: 1.2851554151723636
Validation loss: 2.6348494986586544

Epoch: 5| Step: 7
Training loss: 1.2144877902752507
Validation loss: 2.6842361304447255

Epoch: 5| Step: 8
Training loss: 1.4679399244920497
Validation loss: 2.6564132336256367

Epoch: 5| Step: 9
Training loss: 1.2321949793767353
Validation loss: 2.6122695355278

Epoch: 5| Step: 10
Training loss: 1.3413963553008728
Validation loss: 2.601580024711209

Epoch: 244| Step: 0
Training loss: 0.993166283048925
Validation loss: 2.6546342446338844

Epoch: 5| Step: 1
Training loss: 1.1177600380539143
Validation loss: 2.6766925253748113

Epoch: 5| Step: 2
Training loss: 1.6933293851420914
Validation loss: 2.6675730044374677

Epoch: 5| Step: 3
Training loss: 1.0832621599928334
Validation loss: 2.675145889657249

Epoch: 5| Step: 4
Training loss: 1.5379003794319335
Validation loss: 2.6717343137727005

Epoch: 5| Step: 5
Training loss: 0.9703086803809526
Validation loss: 2.649565258380491

Epoch: 5| Step: 6
Training loss: 1.6362411785543636
Validation loss: 2.656611356820939

Epoch: 5| Step: 7
Training loss: 1.4633217190402517
Validation loss: 2.6114696181151187

Epoch: 5| Step: 8
Training loss: 1.2377321006360569
Validation loss: 2.605207408698823

Epoch: 5| Step: 9
Training loss: 1.9222214549338121
Validation loss: 2.6204096861205515

Epoch: 5| Step: 10
Training loss: 1.9398236031317615
Validation loss: 2.5872950831760964

Epoch: 245| Step: 0
Training loss: 1.4746986210576107
Validation loss: 2.5846805797418915

Epoch: 5| Step: 1
Training loss: 1.643072936001141
Validation loss: 2.5342685299235086

Epoch: 5| Step: 2
Training loss: 1.5202191911312863
Validation loss: 2.5625451026706907

Epoch: 5| Step: 3
Training loss: 1.4153007017971724
Validation loss: 2.5928059211551417

Epoch: 5| Step: 4
Training loss: 1.6677031473066846
Validation loss: 2.591953145927282

Epoch: 5| Step: 5
Training loss: 1.5774892905184617
Validation loss: 2.600704059491509

Epoch: 5| Step: 6
Training loss: 1.0807472074297428
Validation loss: 2.6347823645281645

Epoch: 5| Step: 7
Training loss: 1.2246550775058171
Validation loss: 2.631269719902925

Epoch: 5| Step: 8
Training loss: 1.2641271510996586
Validation loss: 2.650336232972613

Epoch: 5| Step: 9
Training loss: 1.643751235787395
Validation loss: 2.635673245542929

Epoch: 5| Step: 10
Training loss: 1.011130614901876
Validation loss: 2.618356631711699

Epoch: 246| Step: 0
Training loss: 1.3992961612929828
Validation loss: 2.6055275410960035

Epoch: 5| Step: 1
Training loss: 1.8209886072966115
Validation loss: 2.579914091498261

Epoch: 5| Step: 2
Training loss: 1.1945379402966259
Validation loss: 2.5691143681565083

Epoch: 5| Step: 3
Training loss: 1.364862787106295
Validation loss: 2.594346525544045

Epoch: 5| Step: 4
Training loss: 1.81545693806454
Validation loss: 2.5848821634078574

Epoch: 5| Step: 5
Training loss: 1.1115998537631109
Validation loss: 2.6123901811988652

Epoch: 5| Step: 6
Training loss: 1.331556487285841
Validation loss: 2.6399215758391277

Epoch: 5| Step: 7
Training loss: 1.3027337802044885
Validation loss: 2.67399808820071

Epoch: 5| Step: 8
Training loss: 1.0985334699008915
Validation loss: 2.706948000020768

Epoch: 5| Step: 9
Training loss: 1.416752485406034
Validation loss: 2.691348346133937

Epoch: 5| Step: 10
Training loss: 1.6341274387618923
Validation loss: 2.6905000372714336

Epoch: 247| Step: 0
Training loss: 1.517455656984314
Validation loss: 2.691713407610933

Epoch: 5| Step: 1
Training loss: 1.4865894062910339
Validation loss: 2.6573394760927633

Epoch: 5| Step: 2
Training loss: 1.4699471647148488
Validation loss: 2.647452520680885

Epoch: 5| Step: 3
Training loss: 1.2602064204294767
Validation loss: 2.5744197168917844

Epoch: 5| Step: 4
Training loss: 1.1795725987542316
Validation loss: 2.570137930373147

Epoch: 5| Step: 5
Training loss: 1.7725636350026104
Validation loss: 2.550311910802347

Epoch: 5| Step: 6
Training loss: 1.2178058390524529
Validation loss: 2.6111021465716937

Epoch: 5| Step: 7
Training loss: 1.4091542242317865
Validation loss: 2.617032862260802

Epoch: 5| Step: 8
Training loss: 1.0705688058298972
Validation loss: 2.6299512745868765

Epoch: 5| Step: 9
Training loss: 1.5983996911671963
Validation loss: 2.667227790488269

Epoch: 5| Step: 10
Training loss: 1.503807322233252
Validation loss: 2.6771266648536516

Epoch: 248| Step: 0
Training loss: 1.3429598592183163
Validation loss: 2.6680988425446017

Epoch: 5| Step: 1
Training loss: 1.0507602618649168
Validation loss: 2.6384490780195713

Epoch: 5| Step: 2
Training loss: 1.4817084202642181
Validation loss: 2.652018403973786

Epoch: 5| Step: 3
Training loss: 1.4301999533848362
Validation loss: 2.644269078885968

Epoch: 5| Step: 4
Training loss: 1.8942716125648902
Validation loss: 2.6225359622700375

Epoch: 5| Step: 5
Training loss: 1.4124915738825001
Validation loss: 2.6891042238312517

Epoch: 5| Step: 6
Training loss: 1.2046756907080927
Validation loss: 2.6677391344883215

Epoch: 5| Step: 7
Training loss: 1.4354354296132972
Validation loss: 2.64742157518065

Epoch: 5| Step: 8
Training loss: 1.33811371885388
Validation loss: 2.6186015350221434

Epoch: 5| Step: 9
Training loss: 1.5173448066601685
Validation loss: 2.6101508536673146

Epoch: 5| Step: 10
Training loss: 1.183816416729155
Validation loss: 2.6279850739616633

Epoch: 249| Step: 0
Training loss: 1.29411467973221
Validation loss: 2.622364993293433

Epoch: 5| Step: 1
Training loss: 1.655412714227195
Validation loss: 2.651943930747818

Epoch: 5| Step: 2
Training loss: 1.7573653945275047
Validation loss: 2.654588982755015

Epoch: 5| Step: 3
Training loss: 1.7043799580081214
Validation loss: 2.6688756903688713

Epoch: 5| Step: 4
Training loss: 1.1468626889599693
Validation loss: 2.6299920632311116

Epoch: 5| Step: 5
Training loss: 0.9747426891693578
Validation loss: 2.6516065533410798

Epoch: 5| Step: 6
Training loss: 1.220810444501192
Validation loss: 2.6585692345360292

Epoch: 5| Step: 7
Training loss: 1.7741172260916929
Validation loss: 2.700659217215496

Epoch: 5| Step: 8
Training loss: 1.5136495084032997
Validation loss: 2.641171922940551

Epoch: 5| Step: 9
Training loss: 0.661063456877003
Validation loss: 2.659202568686012

Epoch: 5| Step: 10
Training loss: 1.0286482155043948
Validation loss: 2.680242237972313

Epoch: 250| Step: 0
Training loss: 1.1904906710243557
Validation loss: 2.665978950285194

Epoch: 5| Step: 1
Training loss: 1.5438427731209146
Validation loss: 2.6564961154714997

Epoch: 5| Step: 2
Training loss: 1.913555841145964
Validation loss: 2.659634289563793

Epoch: 5| Step: 3
Training loss: 1.0646478597317157
Validation loss: 2.6783531251187784

Epoch: 5| Step: 4
Training loss: 1.531882953226275
Validation loss: 2.6397826915684806

Epoch: 5| Step: 5
Training loss: 1.2336155450404283
Validation loss: 2.6518115240111215

Epoch: 5| Step: 6
Training loss: 1.4762703742834713
Validation loss: 2.606433398400041

Epoch: 5| Step: 7
Training loss: 1.0454874664898093
Validation loss: 2.610101699464096

Epoch: 5| Step: 8
Training loss: 1.3140268073751342
Validation loss: 2.6099999460303547

Epoch: 5| Step: 9
Training loss: 1.5518851783102174
Validation loss: 2.623670315452907

Epoch: 5| Step: 10
Training loss: 1.1423871785558344
Validation loss: 2.663397536436137

Epoch: 251| Step: 0
Training loss: 1.243092621026315
Validation loss: 2.5915448050694785

Epoch: 5| Step: 1
Training loss: 1.3512284852890284
Validation loss: 2.605733368847319

Epoch: 5| Step: 2
Training loss: 1.3636980266789784
Validation loss: 2.5578079626408323

Epoch: 5| Step: 3
Training loss: 1.1036221883178248
Validation loss: 2.5457385404131125

Epoch: 5| Step: 4
Training loss: 1.5147017980506337
Validation loss: 2.582954262487499

Epoch: 5| Step: 5
Training loss: 1.119453426406035
Validation loss: 2.5986030604255603

Epoch: 5| Step: 6
Training loss: 1.4964081356709462
Validation loss: 2.6494783507589563

Epoch: 5| Step: 7
Training loss: 1.5042398454330683
Validation loss: 2.6707459785561456

Epoch: 5| Step: 8
Training loss: 1.1860383725898134
Validation loss: 2.671834815245525

Epoch: 5| Step: 9
Training loss: 1.5178269583641968
Validation loss: 2.7038060599454097

Epoch: 5| Step: 10
Training loss: 1.7402912306140874
Validation loss: 2.627497208406469

Epoch: 252| Step: 0
Training loss: 1.027255732605963
Validation loss: 2.5966967594277994

Epoch: 5| Step: 1
Training loss: 1.3316203627495327
Validation loss: 2.5682455150467316

Epoch: 5| Step: 2
Training loss: 1.1885319291745933
Validation loss: 2.541523527098589

Epoch: 5| Step: 3
Training loss: 1.5287394281054536
Validation loss: 2.562036035585397

Epoch: 5| Step: 4
Training loss: 1.2251015971345791
Validation loss: 2.581833091855232

Epoch: 5| Step: 5
Training loss: 1.38072387375807
Validation loss: 2.5912000504006163

Epoch: 5| Step: 6
Training loss: 1.3826285633234028
Validation loss: 2.631139448173676

Epoch: 5| Step: 7
Training loss: 1.9007885350700406
Validation loss: 2.6769873951940664

Epoch: 5| Step: 8
Training loss: 1.1011738734178114
Validation loss: 2.714708709132114

Epoch: 5| Step: 9
Training loss: 1.5390630421903788
Validation loss: 2.7283741272181525

Epoch: 5| Step: 10
Training loss: 1.3517008363345682
Validation loss: 2.6586525404620014

Epoch: 253| Step: 0
Training loss: 0.9753829240781394
Validation loss: 2.5426654241914735

Epoch: 5| Step: 1
Training loss: 1.2477270441865214
Validation loss: 2.532363596004501

Epoch: 5| Step: 2
Training loss: 1.7076016308990933
Validation loss: 2.493007045156621

Epoch: 5| Step: 3
Training loss: 1.0582255606457347
Validation loss: 2.5087014995096726

Epoch: 5| Step: 4
Training loss: 1.808846968850591
Validation loss: 2.4926073485313984

Epoch: 5| Step: 5
Training loss: 1.4534588502059298
Validation loss: 2.5465340697227474

Epoch: 5| Step: 6
Training loss: 1.3263730779951524
Validation loss: 2.6545812471727674

Epoch: 5| Step: 7
Training loss: 1.213689519473397
Validation loss: 2.6812569320179493

Epoch: 5| Step: 8
Training loss: 1.120889412470882
Validation loss: 2.7279097894170055

Epoch: 5| Step: 9
Training loss: 1.1629221918641588
Validation loss: 2.7083182584533922

Epoch: 5| Step: 10
Training loss: 1.8750411347009641
Validation loss: 2.6216235207022005

Epoch: 254| Step: 0
Training loss: 1.056575977653555
Validation loss: 2.5577375259189292

Epoch: 5| Step: 1
Training loss: 1.5195159519082508
Validation loss: 2.4995438354409107

Epoch: 5| Step: 2
Training loss: 1.6102995947970868
Validation loss: 2.467851308291211

Epoch: 5| Step: 3
Training loss: 1.076030410358138
Validation loss: 2.534275241814096

Epoch: 5| Step: 4
Training loss: 1.3413848022097097
Validation loss: 2.5264626451061463

Epoch: 5| Step: 5
Training loss: 1.735857767905876
Validation loss: 2.5800590641430854

Epoch: 5| Step: 6
Training loss: 2.064248239966214
Validation loss: 2.617129902396424

Epoch: 5| Step: 7
Training loss: 1.2750872825217519
Validation loss: 2.6463975541356644

Epoch: 5| Step: 8
Training loss: 0.946421925888996
Validation loss: 2.6861761266021733

Epoch: 5| Step: 9
Training loss: 0.9195647305702852
Validation loss: 2.652757396282178

Epoch: 5| Step: 10
Training loss: 1.0146528433005586
Validation loss: 2.6040326185284024

Epoch: 255| Step: 0
Training loss: 1.588624678980691
Validation loss: 2.5842948097532563

Epoch: 5| Step: 1
Training loss: 1.5417140833118204
Validation loss: 2.5474920148878413

Epoch: 5| Step: 2
Training loss: 0.9510982414429087
Validation loss: 2.584244249596597

Epoch: 5| Step: 3
Training loss: 1.6624563283131932
Validation loss: 2.595799990707016

Epoch: 5| Step: 4
Training loss: 1.5317892565284612
Validation loss: 2.5930378847247866

Epoch: 5| Step: 5
Training loss: 1.2456523149235414
Validation loss: 2.5786282512755943

Epoch: 5| Step: 6
Training loss: 1.2667252738260457
Validation loss: 2.5937389517354967

Epoch: 5| Step: 7
Training loss: 1.1910657052045366
Validation loss: 2.62200421414055

Epoch: 5| Step: 8
Training loss: 1.0954909501705241
Validation loss: 2.5962807033812605

Epoch: 5| Step: 9
Training loss: 1.4233319709259111
Validation loss: 2.641517235516892

Epoch: 5| Step: 10
Training loss: 1.0002313584676479
Validation loss: 2.6421591495081977

Epoch: 256| Step: 0
Training loss: 1.3124677563294342
Validation loss: 2.637596443573532

Epoch: 5| Step: 1
Training loss: 1.3764410703621672
Validation loss: 2.59296315852057

Epoch: 5| Step: 2
Training loss: 1.1636888557211877
Validation loss: 2.6337708400527093

Epoch: 5| Step: 3
Training loss: 1.558427538888695
Validation loss: 2.5853391363443525

Epoch: 5| Step: 4
Training loss: 1.1578736117936455
Validation loss: 2.6160263059271935

Epoch: 5| Step: 5
Training loss: 1.3727024129227607
Validation loss: 2.586810830588912

Epoch: 5| Step: 6
Training loss: 1.1179868599353202
Validation loss: 2.5764328281630178

Epoch: 5| Step: 7
Training loss: 0.8943291315010123
Validation loss: 2.610240182484955

Epoch: 5| Step: 8
Training loss: 1.2155370175410427
Validation loss: 2.6174387263163057

Epoch: 5| Step: 9
Training loss: 1.3373732854409819
Validation loss: 2.6691626633346974

Epoch: 5| Step: 10
Training loss: 1.9550433084320278
Validation loss: 2.6505622980767907

Epoch: 257| Step: 0
Training loss: 1.4712063965538575
Validation loss: 2.695607057241044

Epoch: 5| Step: 1
Training loss: 1.1460710914623888
Validation loss: 2.6107862454877435

Epoch: 5| Step: 2
Training loss: 1.6073433357416975
Validation loss: 2.6142907999746243

Epoch: 5| Step: 3
Training loss: 1.6598677081512347
Validation loss: 2.6044773469409965

Epoch: 5| Step: 4
Training loss: 1.3791865423255112
Validation loss: 2.5806252634847744

Epoch: 5| Step: 5
Training loss: 1.454014413654609
Validation loss: 2.5658590004545285

Epoch: 5| Step: 6
Training loss: 1.2309909257531102
Validation loss: 2.5889350607203414

Epoch: 5| Step: 7
Training loss: 1.3660642532886802
Validation loss: 2.6094706655778834

Epoch: 5| Step: 8
Training loss: 1.1277466728721186
Validation loss: 2.6791731798465404

Epoch: 5| Step: 9
Training loss: 0.8142058365287725
Validation loss: 2.692939807538509

Epoch: 5| Step: 10
Training loss: 1.0022800202301934
Validation loss: 2.7047333625550554

Epoch: 258| Step: 0
Training loss: 1.1950660900371073
Validation loss: 2.6490676134659066

Epoch: 5| Step: 1
Training loss: 0.8897241419919906
Validation loss: 2.6240272282125137

Epoch: 5| Step: 2
Training loss: 0.7957475577726528
Validation loss: 2.6021294429815236

Epoch: 5| Step: 3
Training loss: 1.1854359105072814
Validation loss: 2.584424119696243

Epoch: 5| Step: 4
Training loss: 1.405293923786024
Validation loss: 2.557574286341848

Epoch: 5| Step: 5
Training loss: 1.215603949357195
Validation loss: 2.573317741416092

Epoch: 5| Step: 6
Training loss: 1.209291779565122
Validation loss: 2.5735237415403263

Epoch: 5| Step: 7
Training loss: 1.8280607032880516
Validation loss: 2.5750719385943186

Epoch: 5| Step: 8
Training loss: 1.4679954700971765
Validation loss: 2.61839791232379

Epoch: 5| Step: 9
Training loss: 1.2711075137846253
Validation loss: 2.6148755708898377

Epoch: 5| Step: 10
Training loss: 1.6878224523964596
Validation loss: 2.645698936045585

Epoch: 259| Step: 0
Training loss: 1.223137514014302
Validation loss: 2.6905679745570836

Epoch: 5| Step: 1
Training loss: 1.5237265288224955
Validation loss: 2.6650437433561094

Epoch: 5| Step: 2
Training loss: 0.9555125428438985
Validation loss: 2.647470135739622

Epoch: 5| Step: 3
Training loss: 1.2882824936508552
Validation loss: 2.5694430493062126

Epoch: 5| Step: 4
Training loss: 1.261243417682995
Validation loss: 2.6015253906599005

Epoch: 5| Step: 5
Training loss: 1.2750726510834889
Validation loss: 2.584695915335932

Epoch: 5| Step: 6
Training loss: 1.3050106813278664
Validation loss: 2.6009856647618204

Epoch: 5| Step: 7
Training loss: 1.435329789336407
Validation loss: 2.6338298286979023

Epoch: 5| Step: 8
Training loss: 1.3875744825424567
Validation loss: 2.6623722524700595

Epoch: 5| Step: 9
Training loss: 1.4424872751187077
Validation loss: 2.7224188314306232

Epoch: 5| Step: 10
Training loss: 1.2474584490749898
Validation loss: 2.7289313564261968

Epoch: 260| Step: 0
Training loss: 1.3610693358586734
Validation loss: 2.7097518279416035

Epoch: 5| Step: 1
Training loss: 0.7704170279934416
Validation loss: 2.730488316632805

Epoch: 5| Step: 2
Training loss: 1.3470097414668416
Validation loss: 2.678611162987705

Epoch: 5| Step: 3
Training loss: 1.1706277440533348
Validation loss: 2.65604163648928

Epoch: 5| Step: 4
Training loss: 1.226555988270185
Validation loss: 2.6679311133580152

Epoch: 5| Step: 5
Training loss: 1.2076741207151427
Validation loss: 2.6274000759939966

Epoch: 5| Step: 6
Training loss: 1.4583443050880054
Validation loss: 2.666139439664617

Epoch: 5| Step: 7
Training loss: 1.6732220793337684
Validation loss: 2.6785561945453202

Epoch: 5| Step: 8
Training loss: 1.0484511054757992
Validation loss: 2.658275799304358

Epoch: 5| Step: 9
Training loss: 1.4480431407698175
Validation loss: 2.649305233842716

Epoch: 5| Step: 10
Training loss: 1.356785599035748
Validation loss: 2.636808538940008

Epoch: 261| Step: 0
Training loss: 1.0770751153471314
Validation loss: 2.6270548204788637

Epoch: 5| Step: 1
Training loss: 1.6154311958520873
Validation loss: 2.619215245463352

Epoch: 5| Step: 2
Training loss: 1.4035485492839723
Validation loss: 2.624071605520288

Epoch: 5| Step: 3
Training loss: 1.4196662935171527
Validation loss: 2.632223361378661

Epoch: 5| Step: 4
Training loss: 1.002322539701999
Validation loss: 2.6951196060245968

Epoch: 5| Step: 5
Training loss: 1.290973749217434
Validation loss: 2.679579737747777

Epoch: 5| Step: 6
Training loss: 1.1925944422465535
Validation loss: 2.734298077745073

Epoch: 5| Step: 7
Training loss: 1.6299028526797492
Validation loss: 2.6466991631489987

Epoch: 5| Step: 8
Training loss: 1.1655088821949848
Validation loss: 2.593284123283311

Epoch: 5| Step: 9
Training loss: 0.8389499965380127
Validation loss: 2.571488051109903

Epoch: 5| Step: 10
Training loss: 1.3419647778068795
Validation loss: 2.536542358711423

Epoch: 262| Step: 0
Training loss: 1.2499484051546712
Validation loss: 2.544838185564529

Epoch: 5| Step: 1
Training loss: 1.324246701646024
Validation loss: 2.5979682522190264

Epoch: 5| Step: 2
Training loss: 1.0368445681566405
Validation loss: 2.6158895566278257

Epoch: 5| Step: 3
Training loss: 1.5011870138023895
Validation loss: 2.663434110979248

Epoch: 5| Step: 4
Training loss: 1.1767643971872308
Validation loss: 2.7266007865655

Epoch: 5| Step: 5
Training loss: 1.6561968812881587
Validation loss: 2.739103955551812

Epoch: 5| Step: 6
Training loss: 1.2144510302889069
Validation loss: 2.7481796041700957

Epoch: 5| Step: 7
Training loss: 1.4749945333347203
Validation loss: 2.6754104605257765

Epoch: 5| Step: 8
Training loss: 0.9595126000551591
Validation loss: 2.649138996799214

Epoch: 5| Step: 9
Training loss: 1.3073112921995758
Validation loss: 2.614791079085249

Epoch: 5| Step: 10
Training loss: 1.074976982934854
Validation loss: 2.596554098952745

Epoch: 263| Step: 0
Training loss: 1.3807392850505342
Validation loss: 2.6206924715464894

Epoch: 5| Step: 1
Training loss: 1.0687535202236091
Validation loss: 2.6674673178896584

Epoch: 5| Step: 2
Training loss: 1.0065131868009294
Validation loss: 2.643156292355955

Epoch: 5| Step: 3
Training loss: 0.909502801730395
Validation loss: 2.672597895162398

Epoch: 5| Step: 4
Training loss: 1.954521107471598
Validation loss: 2.6683362904846666

Epoch: 5| Step: 5
Training loss: 1.017647592585922
Validation loss: 2.6907464137202974

Epoch: 5| Step: 6
Training loss: 1.1571101005314455
Validation loss: 2.6612533603747703

Epoch: 5| Step: 7
Training loss: 1.237504300196719
Validation loss: 2.635937492180516

Epoch: 5| Step: 8
Training loss: 1.1577449104462454
Validation loss: 2.6027305873167412

Epoch: 5| Step: 9
Training loss: 1.306042498666743
Validation loss: 2.527739370806218

Epoch: 5| Step: 10
Training loss: 1.5915411059134268
Validation loss: 2.5289506230599685

Epoch: 264| Step: 0
Training loss: 0.9015961229213054
Validation loss: 2.523195485290279

Epoch: 5| Step: 1
Training loss: 1.139834404345576
Validation loss: 2.526533899955787

Epoch: 5| Step: 2
Training loss: 0.7624671975881446
Validation loss: 2.614121959222303

Epoch: 5| Step: 3
Training loss: 1.1477780687094417
Validation loss: 2.707292774938841

Epoch: 5| Step: 4
Training loss: 1.3071046014007413
Validation loss: 2.745230277520497

Epoch: 5| Step: 5
Training loss: 1.9159575131748772
Validation loss: 2.7295457178608116

Epoch: 5| Step: 6
Training loss: 1.187044256996957
Validation loss: 2.7024077370106907

Epoch: 5| Step: 7
Training loss: 1.2850976252301107
Validation loss: 2.61575303441785

Epoch: 5| Step: 8
Training loss: 1.712353682010145
Validation loss: 2.537905859131127

Epoch: 5| Step: 9
Training loss: 1.4454858624384819
Validation loss: 2.518108200390104

Epoch: 5| Step: 10
Training loss: 0.6981203413067648
Validation loss: 2.4957643004851144

Epoch: 265| Step: 0
Training loss: 0.9470903686740995
Validation loss: 2.497090804536955

Epoch: 5| Step: 1
Training loss: 1.2499484528403544
Validation loss: 2.521700689935926

Epoch: 5| Step: 2
Training loss: 0.9128975903462009
Validation loss: 2.609355770966459

Epoch: 5| Step: 3
Training loss: 1.3255711404163673
Validation loss: 2.717373700568634

Epoch: 5| Step: 4
Training loss: 0.9559884442923853
Validation loss: 2.7941904700476963

Epoch: 5| Step: 5
Training loss: 0.9956383954599984
Validation loss: 2.823086357548645

Epoch: 5| Step: 6
Training loss: 1.779897008659472
Validation loss: 2.732268018747139

Epoch: 5| Step: 7
Training loss: 1.442713942901319
Validation loss: 2.653321500926916

Epoch: 5| Step: 8
Training loss: 1.676943289396711
Validation loss: 2.5590398173386806

Epoch: 5| Step: 9
Training loss: 1.0591178244297375
Validation loss: 2.5207960010253427

Epoch: 5| Step: 10
Training loss: 1.5484737264974282
Validation loss: 2.532923574722738

Epoch: 266| Step: 0
Training loss: 1.1608300098956736
Validation loss: 2.523403869382453

Epoch: 5| Step: 1
Training loss: 1.3553488730593488
Validation loss: 2.573094558162527

Epoch: 5| Step: 2
Training loss: 1.196324786217245
Validation loss: 2.6030221096590527

Epoch: 5| Step: 3
Training loss: 1.2236809869463634
Validation loss: 2.6752579012776914

Epoch: 5| Step: 4
Training loss: 1.1132700066249683
Validation loss: 2.687848552395191

Epoch: 5| Step: 5
Training loss: 1.4160841510897328
Validation loss: 2.7680069992042258

Epoch: 5| Step: 6
Training loss: 1.4937797160365092
Validation loss: 2.71986450616073

Epoch: 5| Step: 7
Training loss: 1.4212871635899262
Validation loss: 2.7104068142227105

Epoch: 5| Step: 8
Training loss: 0.96539504019714
Validation loss: 2.674856437983953

Epoch: 5| Step: 9
Training loss: 1.2278190056872913
Validation loss: 2.664817186646013

Epoch: 5| Step: 10
Training loss: 1.3021502464903252
Validation loss: 2.686301010431529

Epoch: 267| Step: 0
Training loss: 0.8372961749958184
Validation loss: 2.584275357398893

Epoch: 5| Step: 1
Training loss: 1.1620709581196051
Validation loss: 2.6423397070798313

Epoch: 5| Step: 2
Training loss: 1.1236319170768747
Validation loss: 2.6608659760819466

Epoch: 5| Step: 3
Training loss: 1.379353048325351
Validation loss: 2.6625482763481245

Epoch: 5| Step: 4
Training loss: 1.2413762640527457
Validation loss: 2.6409953071853325

Epoch: 5| Step: 5
Training loss: 1.4117419343869617
Validation loss: 2.666221028310587

Epoch: 5| Step: 6
Training loss: 1.6485114058428871
Validation loss: 2.6296458094902113

Epoch: 5| Step: 7
Training loss: 1.2136643747442353
Validation loss: 2.665582015835645

Epoch: 5| Step: 8
Training loss: 1.3930015401783773
Validation loss: 2.6245745261809894

Epoch: 5| Step: 9
Training loss: 0.9584055161588846
Validation loss: 2.5841025068444248

Epoch: 5| Step: 10
Training loss: 1.1269065278731734
Validation loss: 2.60115811287806

Epoch: 268| Step: 0
Training loss: 1.031264969688195
Validation loss: 2.608665749644286

Epoch: 5| Step: 1
Training loss: 0.870862716349448
Validation loss: 2.6369775176142114

Epoch: 5| Step: 2
Training loss: 1.2672329801589377
Validation loss: 2.5883931978014942

Epoch: 5| Step: 3
Training loss: 1.2885518305178998
Validation loss: 2.602096704289581

Epoch: 5| Step: 4
Training loss: 1.8168984679395004
Validation loss: 2.632111881279612

Epoch: 5| Step: 5
Training loss: 1.2894824182140832
Validation loss: 2.6142306869306786

Epoch: 5| Step: 6
Training loss: 1.120023741811065
Validation loss: 2.6036446016466424

Epoch: 5| Step: 7
Training loss: 1.5395905803807528
Validation loss: 2.61987712186355

Epoch: 5| Step: 8
Training loss: 0.8812733964993165
Validation loss: 2.64238009977972

Epoch: 5| Step: 9
Training loss: 1.1178602847112171
Validation loss: 2.6568862558378963

Epoch: 5| Step: 10
Training loss: 1.206208674063888
Validation loss: 2.6715236016084054

Epoch: 269| Step: 0
Training loss: 1.0054235606794402
Validation loss: 2.649220225505036

Epoch: 5| Step: 1
Training loss: 1.1732965112908533
Validation loss: 2.661242657859498

Epoch: 5| Step: 2
Training loss: 1.3873641110797252
Validation loss: 2.617156283823476

Epoch: 5| Step: 3
Training loss: 1.0710161777845244
Validation loss: 2.5803105492120197

Epoch: 5| Step: 4
Training loss: 1.299813125090007
Validation loss: 2.611905606944411

Epoch: 5| Step: 5
Training loss: 1.640287673422199
Validation loss: 2.5802382652151574

Epoch: 5| Step: 6
Training loss: 0.863862476340343
Validation loss: 2.5799984824133295

Epoch: 5| Step: 7
Training loss: 1.3227654868823302
Validation loss: 2.600253456412822

Epoch: 5| Step: 8
Training loss: 1.1378982035590455
Validation loss: 2.638363150491995

Epoch: 5| Step: 9
Training loss: 1.1793019251985377
Validation loss: 2.6231486114817155

Epoch: 5| Step: 10
Training loss: 1.2674287728605904
Validation loss: 2.6983440550174653

Epoch: 270| Step: 0
Training loss: 0.8298935269808564
Validation loss: 2.658408308391129

Epoch: 5| Step: 1
Training loss: 1.6080905269837433
Validation loss: 2.6812094337337036

Epoch: 5| Step: 2
Training loss: 1.0148781010758559
Validation loss: 2.6540805419088875

Epoch: 5| Step: 3
Training loss: 1.1531589534071702
Validation loss: 2.61506159833993

Epoch: 5| Step: 4
Training loss: 1.4702973838296667
Validation loss: 2.601951739741706

Epoch: 5| Step: 5
Training loss: 0.8041828758371844
Validation loss: 2.584262657588107

Epoch: 5| Step: 6
Training loss: 1.2298486994131357
Validation loss: 2.5797330304422195

Epoch: 5| Step: 7
Training loss: 1.5875084523854555
Validation loss: 2.6048608700420357

Epoch: 5| Step: 8
Training loss: 0.8315087768908082
Validation loss: 2.603862096552332

Epoch: 5| Step: 9
Training loss: 1.111625323253616
Validation loss: 2.5947501049236306

Epoch: 5| Step: 10
Training loss: 1.396037850651063
Validation loss: 2.6220806410736484

Epoch: 271| Step: 0
Training loss: 1.3581530461090434
Validation loss: 2.613023136934253

Epoch: 5| Step: 1
Training loss: 1.2763285671190634
Validation loss: 2.6426807829853183

Epoch: 5| Step: 2
Training loss: 0.9292392130757533
Validation loss: 2.6486691319082354

Epoch: 5| Step: 3
Training loss: 1.4043804881281927
Validation loss: 2.7429109076150517

Epoch: 5| Step: 4
Training loss: 1.1831421446930839
Validation loss: 2.7517412356013025

Epoch: 5| Step: 5
Training loss: 1.2489388253048836
Validation loss: 2.7393673486038352

Epoch: 5| Step: 6
Training loss: 0.9519227058644079
Validation loss: 2.7211742048211036

Epoch: 5| Step: 7
Training loss: 1.039692909770131
Validation loss: 2.6926164813525246

Epoch: 5| Step: 8
Training loss: 0.5328096607837373
Validation loss: 2.644190656141307

Epoch: 5| Step: 9
Training loss: 1.6526719797645795
Validation loss: 2.763376505551969

Epoch: 5| Step: 10
Training loss: 1.3010975679350958
Validation loss: 2.7025766010224936

Epoch: 272| Step: 0
Training loss: 1.254064294474896
Validation loss: 2.6661573706884405

Epoch: 5| Step: 1
Training loss: 1.0562250867986658
Validation loss: 2.6585543380906125

Epoch: 5| Step: 2
Training loss: 0.8750256807100925
Validation loss: 2.6741889912580943

Epoch: 5| Step: 3
Training loss: 1.365227476874785
Validation loss: 2.7118446841979678

Epoch: 5| Step: 4
Training loss: 1.4637669382003018
Validation loss: 2.704151602346841

Epoch: 5| Step: 5
Training loss: 0.6503323365631886
Validation loss: 2.7427366081065183

Epoch: 5| Step: 6
Training loss: 0.9842826254962496
Validation loss: 2.689213940968862

Epoch: 5| Step: 7
Training loss: 1.3911359469815716
Validation loss: 2.7003036201077624

Epoch: 5| Step: 8
Training loss: 1.0327920077739352
Validation loss: 2.657576384354913

Epoch: 5| Step: 9
Training loss: 1.4506086486131518
Validation loss: 2.581270281965191

Epoch: 5| Step: 10
Training loss: 1.3168933544500212
Validation loss: 2.5769407006471523

Epoch: 273| Step: 0
Training loss: 1.1722532551973053
Validation loss: 2.5855818465703524

Epoch: 5| Step: 1
Training loss: 0.7983182291727087
Validation loss: 2.6088156141989596

Epoch: 5| Step: 2
Training loss: 0.9393361865443189
Validation loss: 2.6348176423171434

Epoch: 5| Step: 3
Training loss: 1.165519161379427
Validation loss: 2.6628175571036348

Epoch: 5| Step: 4
Training loss: 1.2171009351238282
Validation loss: 2.703120283608415

Epoch: 5| Step: 5
Training loss: 0.9067407134500565
Validation loss: 2.708102121888282

Epoch: 5| Step: 6
Training loss: 1.2491201642172924
Validation loss: 2.643766263501925

Epoch: 5| Step: 7
Training loss: 1.101021383502301
Validation loss: 2.634362315345646

Epoch: 5| Step: 8
Training loss: 1.5491515082974938
Validation loss: 2.629724541202914

Epoch: 5| Step: 9
Training loss: 1.3578361043864708
Validation loss: 2.5991797448552987

Epoch: 5| Step: 10
Training loss: 1.4157622011909503
Validation loss: 2.5957288906294824

Epoch: 274| Step: 0
Training loss: 1.5363490782433256
Validation loss: 2.569650621095491

Epoch: 5| Step: 1
Training loss: 1.2766236775002109
Validation loss: 2.603072556225648

Epoch: 5| Step: 2
Training loss: 0.9608520842015895
Validation loss: 2.674395396422445

Epoch: 5| Step: 3
Training loss: 1.2199927620594881
Validation loss: 2.7677463918573975

Epoch: 5| Step: 4
Training loss: 1.2251505895424752
Validation loss: 2.75603787134164

Epoch: 5| Step: 5
Training loss: 0.9432172332519938
Validation loss: 2.7793135769586597

Epoch: 5| Step: 6
Training loss: 1.167410777846634
Validation loss: 2.748104713913949

Epoch: 5| Step: 7
Training loss: 1.071962518705766
Validation loss: 2.703894525614716

Epoch: 5| Step: 8
Training loss: 0.9374330178809888
Validation loss: 2.6965456179188103

Epoch: 5| Step: 9
Training loss: 1.3303395377116156
Validation loss: 2.603771204957166

Epoch: 5| Step: 10
Training loss: 1.42528109204113
Validation loss: 2.560239594763687

Epoch: 275| Step: 0
Training loss: 0.6141107865390542
Validation loss: 2.56816083674966

Epoch: 5| Step: 1
Training loss: 1.4937714962230557
Validation loss: 2.5782970223162582

Epoch: 5| Step: 2
Training loss: 1.2260553562866063
Validation loss: 2.6004595596495896

Epoch: 5| Step: 3
Training loss: 1.1943621379133793
Validation loss: 2.7196718830469417

Epoch: 5| Step: 4
Training loss: 1.0342708615897807
Validation loss: 2.7454925123051477

Epoch: 5| Step: 5
Training loss: 1.2651396397652983
Validation loss: 2.733964391018332

Epoch: 5| Step: 6
Training loss: 1.2525377262547936
Validation loss: 2.7206966459344097

Epoch: 5| Step: 7
Training loss: 0.9087956946217276
Validation loss: 2.660007194296821

Epoch: 5| Step: 8
Training loss: 1.7434397759895355
Validation loss: 2.6140849487383466

Epoch: 5| Step: 9
Training loss: 1.1501872428550075
Validation loss: 2.571630209266144

Epoch: 5| Step: 10
Training loss: 0.6741090935107747
Validation loss: 2.5477486828153633

Epoch: 276| Step: 0
Training loss: 1.0818859787796573
Validation loss: 2.538183935483402

Epoch: 5| Step: 1
Training loss: 1.5380960906162906
Validation loss: 2.506810061002529

Epoch: 5| Step: 2
Training loss: 1.2034138419481348
Validation loss: 2.5437726683376454

Epoch: 5| Step: 3
Training loss: 1.131276424373325
Validation loss: 2.581858721351591

Epoch: 5| Step: 4
Training loss: 1.3286855524462355
Validation loss: 2.5840605647648793

Epoch: 5| Step: 5
Training loss: 1.1015249475882523
Validation loss: 2.6473462836368595

Epoch: 5| Step: 6
Training loss: 1.3518056485415473
Validation loss: 2.692159615406303

Epoch: 5| Step: 7
Training loss: 1.196540899432948
Validation loss: 2.734664820533989

Epoch: 5| Step: 8
Training loss: 1.0439676937205609
Validation loss: 2.696720839066491

Epoch: 5| Step: 9
Training loss: 1.0362208811645626
Validation loss: 2.7092337431274016

Epoch: 5| Step: 10
Training loss: 0.8501151848332853
Validation loss: 2.6661977977430813

Epoch: 277| Step: 0
Training loss: 1.1130693735984338
Validation loss: 2.636008202124515

Epoch: 5| Step: 1
Training loss: 1.5971987939120695
Validation loss: 2.6114228119350194

Epoch: 5| Step: 2
Training loss: 1.0474559253897775
Validation loss: 2.5827760111774003

Epoch: 5| Step: 3
Training loss: 0.8566542471704083
Validation loss: 2.5613339019645536

Epoch: 5| Step: 4
Training loss: 1.1165648639353922
Validation loss: 2.568612578439532

Epoch: 5| Step: 5
Training loss: 1.1123293906559133
Validation loss: 2.547406312608374

Epoch: 5| Step: 6
Training loss: 0.8632824237522069
Validation loss: 2.5616374000836704

Epoch: 5| Step: 7
Training loss: 1.176485224766003
Validation loss: 2.598925885475471

Epoch: 5| Step: 8
Training loss: 1.1339899192409086
Validation loss: 2.664765270539569

Epoch: 5| Step: 9
Training loss: 1.2964898881970286
Validation loss: 2.7071453931564435

Epoch: 5| Step: 10
Training loss: 1.3698619297509935
Validation loss: 2.7030148564042102

Epoch: 278| Step: 0
Training loss: 1.0361932131090168
Validation loss: 2.75126984811884

Epoch: 5| Step: 1
Training loss: 1.5226450888869099
Validation loss: 2.724098103317112

Epoch: 5| Step: 2
Training loss: 0.9323962843746872
Validation loss: 2.7203362052317046

Epoch: 5| Step: 3
Training loss: 0.8867367645988081
Validation loss: 2.666323783644386

Epoch: 5| Step: 4
Training loss: 1.1507228507602427
Validation loss: 2.6563820040655153

Epoch: 5| Step: 5
Training loss: 1.1301015050416434
Validation loss: 2.6125669212619447

Epoch: 5| Step: 6
Training loss: 1.2790820691261122
Validation loss: 2.5957666956575074

Epoch: 5| Step: 7
Training loss: 1.0838839647681022
Validation loss: 2.5997093464181757

Epoch: 5| Step: 8
Training loss: 1.1319881201953075
Validation loss: 2.631830825479555

Epoch: 5| Step: 9
Training loss: 1.3129698956707123
Validation loss: 2.6656587859751664

Epoch: 5| Step: 10
Training loss: 1.0094407996116128
Validation loss: 2.6808931299421417

Epoch: 279| Step: 0
Training loss: 1.0894268701562284
Validation loss: 2.6921217522604723

Epoch: 5| Step: 1
Training loss: 1.2967741593830924
Validation loss: 2.7157027220618666

Epoch: 5| Step: 2
Training loss: 0.7929000448895895
Validation loss: 2.637786224748807

Epoch: 5| Step: 3
Training loss: 0.9798144706934501
Validation loss: 2.6277668283854694

Epoch: 5| Step: 4
Training loss: 0.8363213415463199
Validation loss: 2.5944338214746936

Epoch: 5| Step: 5
Training loss: 1.046830589149529
Validation loss: 2.599564852282079

Epoch: 5| Step: 6
Training loss: 1.1119899287659671
Validation loss: 2.6485874245997154

Epoch: 5| Step: 7
Training loss: 1.2519147512949464
Validation loss: 2.6549924475885316

Epoch: 5| Step: 8
Training loss: 1.4449816350858835
Validation loss: 2.6585156732866126

Epoch: 5| Step: 9
Training loss: 1.2167158513165055
Validation loss: 2.6988619210622984

Epoch: 5| Step: 10
Training loss: 1.396395337660914
Validation loss: 2.7097662593997605

Epoch: 280| Step: 0
Training loss: 1.000979897098104
Validation loss: 2.691691854745067

Epoch: 5| Step: 1
Training loss: 1.2442640306242374
Validation loss: 2.6739881404057466

Epoch: 5| Step: 2
Training loss: 1.066212004133265
Validation loss: 2.6347563211079175

Epoch: 5| Step: 3
Training loss: 1.3248035411219563
Validation loss: 2.610566794815139

Epoch: 5| Step: 4
Training loss: 0.9626316859834526
Validation loss: 2.591106822911119

Epoch: 5| Step: 5
Training loss: 1.0040537210051594
Validation loss: 2.601760828613511

Epoch: 5| Step: 6
Training loss: 1.0854125366327614
Validation loss: 2.6349564321933547

Epoch: 5| Step: 7
Training loss: 0.9641483287226855
Validation loss: 2.704817971608366

Epoch: 5| Step: 8
Training loss: 1.4225303062066608
Validation loss: 2.68662897844119

Epoch: 5| Step: 9
Training loss: 1.2532628865853128
Validation loss: 2.703086309792114

Epoch: 5| Step: 10
Training loss: 0.9608532938465085
Validation loss: 2.6730726103460682

Epoch: 281| Step: 0
Training loss: 1.0090168698491302
Validation loss: 2.6612610707830413

Epoch: 5| Step: 1
Training loss: 1.1257719464417306
Validation loss: 2.7140772003720857

Epoch: 5| Step: 2
Training loss: 0.8675481372856566
Validation loss: 2.7362943142760625

Epoch: 5| Step: 3
Training loss: 1.270581371573482
Validation loss: 2.678999135393084

Epoch: 5| Step: 4
Training loss: 1.0311124883348852
Validation loss: 2.625875623875096

Epoch: 5| Step: 5
Training loss: 1.596897383381837
Validation loss: 2.636925436933157

Epoch: 5| Step: 6
Training loss: 1.1718932595419895
Validation loss: 2.6514084685499224

Epoch: 5| Step: 7
Training loss: 1.200148926871383
Validation loss: 2.616330344152999

Epoch: 5| Step: 8
Training loss: 1.070913438484951
Validation loss: 2.627534258280088

Epoch: 5| Step: 9
Training loss: 0.9657884058296102
Validation loss: 2.6200343735393963

Epoch: 5| Step: 10
Training loss: 0.6642309087494288
Validation loss: 2.6408139082549837

Epoch: 282| Step: 0
Training loss: 1.0437583648894668
Validation loss: 2.637032535162298

Epoch: 5| Step: 1
Training loss: 1.1148122867242483
Validation loss: 2.6335419317808983

Epoch: 5| Step: 2
Training loss: 1.087466528804936
Validation loss: 2.636472565807685

Epoch: 5| Step: 3
Training loss: 1.019434781827069
Validation loss: 2.637664156304978

Epoch: 5| Step: 4
Training loss: 0.7788887197957178
Validation loss: 2.6690403758922634

Epoch: 5| Step: 5
Training loss: 1.3179361299775476
Validation loss: 2.6953556361112074

Epoch: 5| Step: 6
Training loss: 1.2908194850296182
Validation loss: 2.69302324685504

Epoch: 5| Step: 7
Training loss: 0.99678595931511
Validation loss: 2.645360823234258

Epoch: 5| Step: 8
Training loss: 1.1020648433141393
Validation loss: 2.65190158400988

Epoch: 5| Step: 9
Training loss: 1.2189791537310368
Validation loss: 2.6363479534623875

Epoch: 5| Step: 10
Training loss: 1.2226760911398038
Validation loss: 2.5870539106064525

Epoch: 283| Step: 0
Training loss: 1.0113900729611935
Validation loss: 2.589428565999204

Epoch: 5| Step: 1
Training loss: 1.3476371432069452
Validation loss: 2.5999748600690147

Epoch: 5| Step: 2
Training loss: 0.915009554099143
Validation loss: 2.5890089189267926

Epoch: 5| Step: 3
Training loss: 1.0980587693000734
Validation loss: 2.6635680429809554

Epoch: 5| Step: 4
Training loss: 0.9467063589964616
Validation loss: 2.6585940987238086

Epoch: 5| Step: 5
Training loss: 1.2924897381284772
Validation loss: 2.6801192862163767

Epoch: 5| Step: 6
Training loss: 1.2027221599775038
Validation loss: 2.6785542095234423

Epoch: 5| Step: 7
Training loss: 1.122351814463035
Validation loss: 2.6608896674828486

Epoch: 5| Step: 8
Training loss: 1.149022375116371
Validation loss: 2.6539048740854883

Epoch: 5| Step: 9
Training loss: 0.88932316986274
Validation loss: 2.6475966496882326

Epoch: 5| Step: 10
Training loss: 0.9972769199064921
Validation loss: 2.63294201029638

Epoch: 284| Step: 0
Training loss: 1.4537196429585335
Validation loss: 2.67007892533009

Epoch: 5| Step: 1
Training loss: 0.461491187571517
Validation loss: 2.6184055188434385

Epoch: 5| Step: 2
Training loss: 1.2385676200249987
Validation loss: 2.6585222576061103

Epoch: 5| Step: 3
Training loss: 1.153394420545857
Validation loss: 2.6831120897069742

Epoch: 5| Step: 4
Training loss: 1.0078076502956836
Validation loss: 2.659939270629311

Epoch: 5| Step: 5
Training loss: 1.3027005627317672
Validation loss: 2.673730564383242

Epoch: 5| Step: 6
Training loss: 0.9201917313251295
Validation loss: 2.679884082858314

Epoch: 5| Step: 7
Training loss: 1.046456039631754
Validation loss: 2.647028051509541

Epoch: 5| Step: 8
Training loss: 0.8673202825390757
Validation loss: 2.615724029844176

Epoch: 5| Step: 9
Training loss: 1.2083890617059903
Validation loss: 2.610793209411033

Epoch: 5| Step: 10
Training loss: 0.9672388164852798
Validation loss: 2.570185245022205

Epoch: 285| Step: 0
Training loss: 1.3260132999587448
Validation loss: 2.64149908288152

Epoch: 5| Step: 1
Training loss: 0.5721415622840083
Validation loss: 2.652789957199338

Epoch: 5| Step: 2
Training loss: 0.7036277457133014
Validation loss: 2.71544314755631

Epoch: 5| Step: 3
Training loss: 1.0276003905025703
Validation loss: 2.7121965317486154

Epoch: 5| Step: 4
Training loss: 1.2294244603659197
Validation loss: 2.7039144836551294

Epoch: 5| Step: 5
Training loss: 1.1081224274323063
Validation loss: 2.73635363454369

Epoch: 5| Step: 6
Training loss: 0.8972914310475975
Validation loss: 2.711605763092306

Epoch: 5| Step: 7
Training loss: 1.3852523142146957
Validation loss: 2.6840039021137954

Epoch: 5| Step: 8
Training loss: 0.882488022309628
Validation loss: 2.6412619341818706

Epoch: 5| Step: 9
Training loss: 1.399522413809572
Validation loss: 2.575728481990017

Epoch: 5| Step: 10
Training loss: 1.002322837034612
Validation loss: 2.6055379322948435

Epoch: 286| Step: 0
Training loss: 0.9825802745493788
Validation loss: 2.534975101879162

Epoch: 5| Step: 1
Training loss: 1.0718560887217135
Validation loss: 2.6258871109879918

Epoch: 5| Step: 2
Training loss: 1.1950548679731952
Validation loss: 2.6416159421704424

Epoch: 5| Step: 3
Training loss: 1.3077511024419404
Validation loss: 2.6809599203006798

Epoch: 5| Step: 4
Training loss: 0.9698356574734809
Validation loss: 2.6983427667097253

Epoch: 5| Step: 5
Training loss: 0.79872134364725
Validation loss: 2.697032384135154

Epoch: 5| Step: 6
Training loss: 1.314187191593473
Validation loss: 2.6820213582294032

Epoch: 5| Step: 7
Training loss: 0.9755864262698976
Validation loss: 2.666001610604708

Epoch: 5| Step: 8
Training loss: 1.027671268603373
Validation loss: 2.6487217211372176

Epoch: 5| Step: 9
Training loss: 1.131777902584875
Validation loss: 2.6658461722316713

Epoch: 5| Step: 10
Training loss: 1.0711927483660055
Validation loss: 2.6244455485414706

Epoch: 287| Step: 0
Training loss: 0.6757734441582011
Validation loss: 2.582974704403316

Epoch: 5| Step: 1
Training loss: 1.4460834818124608
Validation loss: 2.6300695183883853

Epoch: 5| Step: 2
Training loss: 0.9819703173492406
Validation loss: 2.6060768757513264

Epoch: 5| Step: 3
Training loss: 0.7276259812016008
Validation loss: 2.613904808988091

Epoch: 5| Step: 4
Training loss: 0.7893328817190133
Validation loss: 2.648491687095091

Epoch: 5| Step: 5
Training loss: 1.1455704069475017
Validation loss: 2.654935434536361

Epoch: 5| Step: 6
Training loss: 1.3153498454738797
Validation loss: 2.672315629684857

Epoch: 5| Step: 7
Training loss: 1.1383099512423456
Validation loss: 2.687054626046294

Epoch: 5| Step: 8
Training loss: 1.4803396687058894
Validation loss: 2.6997560733491404

Epoch: 5| Step: 9
Training loss: 0.7648510037351941
Validation loss: 2.719482935996867

Epoch: 5| Step: 10
Training loss: 0.9269810237938078
Validation loss: 2.7502016961196647

Epoch: 288| Step: 0
Training loss: 0.984028164751265
Validation loss: 2.7399478537119366

Epoch: 5| Step: 1
Training loss: 0.820009302691283
Validation loss: 2.7529568069630193

Epoch: 5| Step: 2
Training loss: 0.8456378585615959
Validation loss: 2.726901356917455

Epoch: 5| Step: 3
Training loss: 1.254757601061119
Validation loss: 2.712608967083697

Epoch: 5| Step: 4
Training loss: 1.090135815497112
Validation loss: 2.657398411381667

Epoch: 5| Step: 5
Training loss: 1.1908539539382192
Validation loss: 2.590425854193701

Epoch: 5| Step: 6
Training loss: 1.2313293838083084
Validation loss: 2.592692164781908

Epoch: 5| Step: 7
Training loss: 0.8934190324046837
Validation loss: 2.6383165488674645

Epoch: 5| Step: 8
Training loss: 1.5410482695667003
Validation loss: 2.638134941450856

Epoch: 5| Step: 9
Training loss: 1.1861670692807285
Validation loss: 2.689650680224837

Epoch: 5| Step: 10
Training loss: 0.5918244207537044
Validation loss: 2.729156199791125

Epoch: 289| Step: 0
Training loss: 0.9338604215010725
Validation loss: 2.7209552726700847

Epoch: 5| Step: 1
Training loss: 0.9470303587412893
Validation loss: 2.7023842397826114

Epoch: 5| Step: 2
Training loss: 1.1347884735591014
Validation loss: 2.662008932019877

Epoch: 5| Step: 3
Training loss: 1.0998291012915278
Validation loss: 2.640566967518655

Epoch: 5| Step: 4
Training loss: 0.87065154342554
Validation loss: 2.616014707896199

Epoch: 5| Step: 5
Training loss: 1.0975375942838559
Validation loss: 2.600978336503447

Epoch: 5| Step: 6
Training loss: 1.349814370426536
Validation loss: 2.6074853674056913

Epoch: 5| Step: 7
Training loss: 1.440465852962303
Validation loss: 2.609793883065508

Epoch: 5| Step: 8
Training loss: 0.9707520010173804
Validation loss: 2.671664742731178

Epoch: 5| Step: 9
Training loss: 0.9557733482244991
Validation loss: 2.6997218881691896

Epoch: 5| Step: 10
Training loss: 0.8933540160598451
Validation loss: 2.688771666966777

Epoch: 290| Step: 0
Training loss: 0.935294481607988
Validation loss: 2.6561995654110597

Epoch: 5| Step: 1
Training loss: 0.7852672289707407
Validation loss: 2.6801997950449508

Epoch: 5| Step: 2
Training loss: 0.882572580330069
Validation loss: 2.6565923789841213

Epoch: 5| Step: 3
Training loss: 0.9538638893613125
Validation loss: 2.6662056015440467

Epoch: 5| Step: 4
Training loss: 1.106523906613263
Validation loss: 2.625049022210953

Epoch: 5| Step: 5
Training loss: 0.9305944426715981
Validation loss: 2.601726780665223

Epoch: 5| Step: 6
Training loss: 1.539387315274165
Validation loss: 2.6027680153473467

Epoch: 5| Step: 7
Training loss: 0.9376841682100795
Validation loss: 2.566340336758809

Epoch: 5| Step: 8
Training loss: 1.4292306639167562
Validation loss: 2.558393980943245

Epoch: 5| Step: 9
Training loss: 0.9748078107927136
Validation loss: 2.580999561362842

Epoch: 5| Step: 10
Training loss: 0.897027842028971
Validation loss: 2.6019029730484537

Epoch: 291| Step: 0
Training loss: 0.8823758961459136
Validation loss: 2.60513539235756

Epoch: 5| Step: 1
Training loss: 0.37664982349088283
Validation loss: 2.630963482192237

Epoch: 5| Step: 2
Training loss: 1.014475245008766
Validation loss: 2.686386646637134

Epoch: 5| Step: 3
Training loss: 0.9259060803688468
Validation loss: 2.7210874512853294

Epoch: 5| Step: 4
Training loss: 1.1241867516836928
Validation loss: 2.7201983693689655

Epoch: 5| Step: 5
Training loss: 1.467589467715308
Validation loss: 2.705559315302318

Epoch: 5| Step: 6
Training loss: 0.9408256038036279
Validation loss: 2.6409625843474767

Epoch: 5| Step: 7
Training loss: 1.182039858628496
Validation loss: 2.588756495335351

Epoch: 5| Step: 8
Training loss: 1.0467419326249043
Validation loss: 2.5998994951014525

Epoch: 5| Step: 9
Training loss: 1.2659928058190857
Validation loss: 2.638201717210231

Epoch: 5| Step: 10
Training loss: 1.0460455156164439
Validation loss: 2.667246073667983

Epoch: 292| Step: 0
Training loss: 1.1148030370537458
Validation loss: 2.7011964713645757

Epoch: 5| Step: 1
Training loss: 0.8590772633205048
Validation loss: 2.7350029393407316

Epoch: 5| Step: 2
Training loss: 1.0961729188307405
Validation loss: 2.723882793452859

Epoch: 5| Step: 3
Training loss: 0.8101261379785466
Validation loss: 2.666103381095245

Epoch: 5| Step: 4
Training loss: 0.8289116056594625
Validation loss: 2.6400525959958805

Epoch: 5| Step: 5
Training loss: 0.720465313306135
Validation loss: 2.6045041075269446

Epoch: 5| Step: 6
Training loss: 0.8718962116464103
Validation loss: 2.5941173047778627

Epoch: 5| Step: 7
Training loss: 1.6123866078332818
Validation loss: 2.558301668357619

Epoch: 5| Step: 8
Training loss: 1.466282984369895
Validation loss: 2.547277616405919

Epoch: 5| Step: 9
Training loss: 0.8449956388191676
Validation loss: 2.5540782197775873

Epoch: 5| Step: 10
Training loss: 1.011823317378343
Validation loss: 2.583438395475233

Epoch: 293| Step: 0
Training loss: 1.0374331211457535
Validation loss: 2.610649822195985

Epoch: 5| Step: 1
Training loss: 0.9059280283953542
Validation loss: 2.6468046048117664

Epoch: 5| Step: 2
Training loss: 0.9819853705930536
Validation loss: 2.7019064368355883

Epoch: 5| Step: 3
Training loss: 1.468104443818281
Validation loss: 2.739278422565044

Epoch: 5| Step: 4
Training loss: 0.5974057239710344
Validation loss: 2.7104038404659527

Epoch: 5| Step: 5
Training loss: 1.0658479563585082
Validation loss: 2.646580735316959

Epoch: 5| Step: 6
Training loss: 1.0824261987738153
Validation loss: 2.6358861904206763

Epoch: 5| Step: 7
Training loss: 1.1740429470616076
Validation loss: 2.5956303832220633

Epoch: 5| Step: 8
Training loss: 0.8891922318079339
Validation loss: 2.590810545035891

Epoch: 5| Step: 9
Training loss: 1.2147034689813134
Validation loss: 2.595148228824602

Epoch: 5| Step: 10
Training loss: 0.6936221202488768
Validation loss: 2.6296668935592353

Epoch: 294| Step: 0
Training loss: 1.228130674470406
Validation loss: 2.632462472507054

Epoch: 5| Step: 1
Training loss: 0.9002440161512768
Validation loss: 2.643183111378268

Epoch: 5| Step: 2
Training loss: 0.7488671329946579
Validation loss: 2.687890891236507

Epoch: 5| Step: 3
Training loss: 1.3685980359726877
Validation loss: 2.669324242482468

Epoch: 5| Step: 4
Training loss: 1.0485490537782776
Validation loss: 2.6438579453797857

Epoch: 5| Step: 5
Training loss: 0.8255010095055252
Validation loss: 2.6694648468476676

Epoch: 5| Step: 6
Training loss: 0.979413380214691
Validation loss: 2.6213476014303776

Epoch: 5| Step: 7
Training loss: 1.1176213842430969
Validation loss: 2.633417505422437

Epoch: 5| Step: 8
Training loss: 0.9423480882324996
Validation loss: 2.677464805886387

Epoch: 5| Step: 9
Training loss: 1.0754982835870344
Validation loss: 2.651317567009164

Epoch: 5| Step: 10
Training loss: 1.050063444673104
Validation loss: 2.65794072833888

Epoch: 295| Step: 0
Training loss: 0.8912566772467617
Validation loss: 2.656806232234987

Epoch: 5| Step: 1
Training loss: 1.2297887951865134
Validation loss: 2.6612101839876234

Epoch: 5| Step: 2
Training loss: 0.9435266066146898
Validation loss: 2.648293301558382

Epoch: 5| Step: 3
Training loss: 0.9193774513611311
Validation loss: 2.6870635761705364

Epoch: 5| Step: 4
Training loss: 0.8733433981550867
Validation loss: 2.623477410224194

Epoch: 5| Step: 5
Training loss: 1.0308012708541385
Validation loss: 2.6506826525657345

Epoch: 5| Step: 6
Training loss: 0.9084513335327828
Validation loss: 2.6546933462071847

Epoch: 5| Step: 7
Training loss: 1.0407790725792896
Validation loss: 2.6510240176394846

Epoch: 5| Step: 8
Training loss: 1.532495731515836
Validation loss: 2.6642083015752704

Epoch: 5| Step: 9
Training loss: 0.5880765145774862
Validation loss: 2.655026030681196

Epoch: 5| Step: 10
Training loss: 1.0413676341309963
Validation loss: 2.6161152204967273

Epoch: 296| Step: 0
Training loss: 0.9394598185405874
Validation loss: 2.640636114223425

Epoch: 5| Step: 1
Training loss: 1.1994184893048243
Validation loss: 2.6217285764615434

Epoch: 5| Step: 2
Training loss: 0.9964977866137203
Validation loss: 2.6143125962502594

Epoch: 5| Step: 3
Training loss: 0.7660839495809065
Validation loss: 2.626369061682267

Epoch: 5| Step: 4
Training loss: 1.215730202640949
Validation loss: 2.689050662540725

Epoch: 5| Step: 5
Training loss: 0.8389814696442363
Validation loss: 2.693568302857313

Epoch: 5| Step: 6
Training loss: 1.1912736662588295
Validation loss: 2.7135540744621505

Epoch: 5| Step: 7
Training loss: 0.6698832153198092
Validation loss: 2.6749194927672684

Epoch: 5| Step: 8
Training loss: 0.9191920144905382
Validation loss: 2.7475151738651364

Epoch: 5| Step: 9
Training loss: 1.303446745088615
Validation loss: 2.6900911524537188

Epoch: 5| Step: 10
Training loss: 0.8196427653965926
Validation loss: 2.6560121153464227

Epoch: 297| Step: 0
Training loss: 0.6974234095262012
Validation loss: 2.6126631911730094

Epoch: 5| Step: 1
Training loss: 0.6902104397883705
Validation loss: 2.6154768477250876

Epoch: 5| Step: 2
Training loss: 1.0167482473650482
Validation loss: 2.6596651705613663

Epoch: 5| Step: 3
Training loss: 0.7952522509823948
Validation loss: 2.653969034242248

Epoch: 5| Step: 4
Training loss: 1.1883639154516117
Validation loss: 2.7102721415763433

Epoch: 5| Step: 5
Training loss: 0.8110384633859801
Validation loss: 2.6828171037487567

Epoch: 5| Step: 6
Training loss: 1.5139254449908432
Validation loss: 2.687802407682721

Epoch: 5| Step: 7
Training loss: 1.2173854329059417
Validation loss: 2.67088487105799

Epoch: 5| Step: 8
Training loss: 0.6377994983848759
Validation loss: 2.657668472451029

Epoch: 5| Step: 9
Training loss: 1.1809600635724011
Validation loss: 2.690611150526163

Epoch: 5| Step: 10
Training loss: 0.8397487497936503
Validation loss: 2.649225726852844

Epoch: 298| Step: 0
Training loss: 0.8251865002765421
Validation loss: 2.6716535172160523

Epoch: 5| Step: 1
Training loss: 1.384845166417073
Validation loss: 2.6374605395260704

Epoch: 5| Step: 2
Training loss: 0.8574368208362463
Validation loss: 2.631362378875873

Epoch: 5| Step: 3
Training loss: 0.955600151202995
Validation loss: 2.6185866760351537

Epoch: 5| Step: 4
Training loss: 1.301513557383987
Validation loss: 2.619750242962432

Epoch: 5| Step: 5
Training loss: 0.8804887554397334
Validation loss: 2.599594741274322

Epoch: 5| Step: 6
Training loss: 1.0090817878890457
Validation loss: 2.6158986620365883

Epoch: 5| Step: 7
Training loss: 0.9278947229849728
Validation loss: 2.6553455779520743

Epoch: 5| Step: 8
Training loss: 1.1228759104752504
Validation loss: 2.6756807305245998

Epoch: 5| Step: 9
Training loss: 0.7121025013971182
Validation loss: 2.6679796004161416

Epoch: 5| Step: 10
Training loss: 0.7159943622734773
Validation loss: 2.701166205637177

Epoch: 299| Step: 0
Training loss: 1.1714505253372796
Validation loss: 2.729920832977212

Epoch: 5| Step: 1
Training loss: 0.6075115812241668
Validation loss: 2.699758800548186

Epoch: 5| Step: 2
Training loss: 1.0805692194347418
Validation loss: 2.666098646328473

Epoch: 5| Step: 3
Training loss: 0.9191704209828303
Validation loss: 2.6382739037171232

Epoch: 5| Step: 4
Training loss: 1.1313794773254713
Validation loss: 2.6162027258753437

Epoch: 5| Step: 5
Training loss: 1.4745438112752836
Validation loss: 2.631424892732705

Epoch: 5| Step: 6
Training loss: 1.1027250715857162
Validation loss: 2.597785491898689

Epoch: 5| Step: 7
Training loss: 0.9661558858480445
Validation loss: 2.6157287489653007

Epoch: 5| Step: 8
Training loss: 0.4358550892803978
Validation loss: 2.6321901282194733

Epoch: 5| Step: 9
Training loss: 0.8228860720649118
Validation loss: 2.6643048531863993

Epoch: 5| Step: 10
Training loss: 0.6768831959841987
Validation loss: 2.6709811429295454

Epoch: 300| Step: 0
Training loss: 1.0800944045980116
Validation loss: 2.681456526144916

Epoch: 5| Step: 1
Training loss: 1.0271308591317372
Validation loss: 2.6825556229244625

Epoch: 5| Step: 2
Training loss: 1.0573935373523298
Validation loss: 2.683043461039562

Epoch: 5| Step: 3
Training loss: 1.2060707492762714
Validation loss: 2.6821863921776474

Epoch: 5| Step: 4
Training loss: 0.825875736486246
Validation loss: 2.6782907245317693

Epoch: 5| Step: 5
Training loss: 0.65076300697356
Validation loss: 2.666439143467642

Epoch: 5| Step: 6
Training loss: 0.874780252655805
Validation loss: 2.674581251354777

Epoch: 5| Step: 7
Training loss: 0.8828065585046191
Validation loss: 2.6692012065667474

Epoch: 5| Step: 8
Training loss: 0.8192925788400818
Validation loss: 2.6722840285885154

Epoch: 5| Step: 9
Training loss: 1.0160352611880845
Validation loss: 2.67117278562165

Epoch: 5| Step: 10
Training loss: 1.272513633684969
Validation loss: 2.6480517077211703

Epoch: 301| Step: 0
Training loss: 1.0901202326266728
Validation loss: 2.636123695330387

Epoch: 5| Step: 1
Training loss: 0.7469753229924249
Validation loss: 2.6342892083148675

Epoch: 5| Step: 2
Training loss: 0.9000420216181052
Validation loss: 2.6626763297313416

Epoch: 5| Step: 3
Training loss: 0.8095153127285816
Validation loss: 2.651716832956871

Epoch: 5| Step: 4
Training loss: 1.319196150099421
Validation loss: 2.65560088167527

Epoch: 5| Step: 5
Training loss: 1.3562741923481814
Validation loss: 2.652811441020187

Epoch: 5| Step: 6
Training loss: 0.9222862167030782
Validation loss: 2.6599191031073475

Epoch: 5| Step: 7
Training loss: 0.9290371070365896
Validation loss: 2.689731794928992

Epoch: 5| Step: 8
Training loss: 0.665257847853986
Validation loss: 2.701223722994238

Epoch: 5| Step: 9
Training loss: 0.9770955576399709
Validation loss: 2.7099364566334665

Epoch: 5| Step: 10
Training loss: 0.729120080458775
Validation loss: 2.6927244321153405

Epoch: 302| Step: 0
Training loss: 0.9492047469750626
Validation loss: 2.7070597933429674

Epoch: 5| Step: 1
Training loss: 1.0995370085569383
Validation loss: 2.722890748946974

Epoch: 5| Step: 2
Training loss: 1.0024433684109206
Validation loss: 2.701066316697044

Epoch: 5| Step: 3
Training loss: 0.9817974920051574
Validation loss: 2.726922702006031

Epoch: 5| Step: 4
Training loss: 0.9935236067172698
Validation loss: 2.645796329768248

Epoch: 5| Step: 5
Training loss: 0.683243667333116
Validation loss: 2.6417600528706644

Epoch: 5| Step: 6
Training loss: 0.8518127633615756
Validation loss: 2.6197470116824193

Epoch: 5| Step: 7
Training loss: 0.9799154475774632
Validation loss: 2.6090665736544976

Epoch: 5| Step: 8
Training loss: 1.0733728025615372
Validation loss: 2.601958207085416

Epoch: 5| Step: 9
Training loss: 1.141419747838728
Validation loss: 2.6253518680786163

Epoch: 5| Step: 10
Training loss: 0.9423279425108463
Validation loss: 2.604004413759461

Epoch: 303| Step: 0
Training loss: 1.042162637256727
Validation loss: 2.6743801217744188

Epoch: 5| Step: 1
Training loss: 1.1746863656775541
Validation loss: 2.647214001383121

Epoch: 5| Step: 2
Training loss: 0.9464642152989038
Validation loss: 2.698655414119649

Epoch: 5| Step: 3
Training loss: 0.7658232607367615
Validation loss: 2.6845121924273156

Epoch: 5| Step: 4
Training loss: 0.8165258292640513
Validation loss: 2.6523631100601444

Epoch: 5| Step: 5
Training loss: 1.2412653925345616
Validation loss: 2.6256041800792715

Epoch: 5| Step: 6
Training loss: 0.8445790068244745
Validation loss: 2.6448941206523253

Epoch: 5| Step: 7
Training loss: 0.804185581149546
Validation loss: 2.6660429612247647

Epoch: 5| Step: 8
Training loss: 1.2286565605795974
Validation loss: 2.672773807671569

Epoch: 5| Step: 9
Training loss: 0.5137604611670575
Validation loss: 2.695876743631355

Epoch: 5| Step: 10
Training loss: 0.9689187856502126
Validation loss: 2.7307062666738116

Epoch: 304| Step: 0
Training loss: 0.8275057078507517
Validation loss: 2.675462823083715

Epoch: 5| Step: 1
Training loss: 1.176138636620779
Validation loss: 2.661669235842627

Epoch: 5| Step: 2
Training loss: 1.5551286387821428
Validation loss: 2.665910141162376

Epoch: 5| Step: 3
Training loss: 0.8975708471828758
Validation loss: 2.629685694279982

Epoch: 5| Step: 4
Training loss: 0.8224446153980135
Validation loss: 2.5865394509554718

Epoch: 5| Step: 5
Training loss: 0.9737690454366248
Validation loss: 2.6093391443994043

Epoch: 5| Step: 6
Training loss: 0.808201939105809
Validation loss: 2.6317956104218134

Epoch: 5| Step: 7
Training loss: 0.8526544831439211
Validation loss: 2.5963354843293125

Epoch: 5| Step: 8
Training loss: 0.8689524929155522
Validation loss: 2.619414088237663

Epoch: 5| Step: 9
Training loss: 0.6004347199905442
Validation loss: 2.6823221107967

Epoch: 5| Step: 10
Training loss: 0.9103039797624138
Validation loss: 2.688677688808338

Epoch: 305| Step: 0
Training loss: 0.9194926821804867
Validation loss: 2.719670720785568

Epoch: 5| Step: 1
Training loss: 0.7839138772892615
Validation loss: 2.735046435540454

Epoch: 5| Step: 2
Training loss: 0.9827670937436546
Validation loss: 2.7299926198091593

Epoch: 5| Step: 3
Training loss: 1.176426099188473
Validation loss: 2.6696562205143133

Epoch: 5| Step: 4
Training loss: 0.9873957228832396
Validation loss: 2.6663201270997154

Epoch: 5| Step: 5
Training loss: 0.9218393092601161
Validation loss: 2.64554031874117

Epoch: 5| Step: 6
Training loss: 0.899383378722162
Validation loss: 2.6149668323839457

Epoch: 5| Step: 7
Training loss: 1.0363429914285998
Validation loss: 2.602326225072777

Epoch: 5| Step: 8
Training loss: 0.8565477507865171
Validation loss: 2.6046994385816418

Epoch: 5| Step: 9
Training loss: 1.0686671286237086
Validation loss: 2.607423399956702

Epoch: 5| Step: 10
Training loss: 0.7648282089446886
Validation loss: 2.5906337417313936

Epoch: 306| Step: 0
Training loss: 0.9264323845990854
Validation loss: 2.6217011614936885

Epoch: 5| Step: 1
Training loss: 0.9511586840457091
Validation loss: 2.6378449185357886

Epoch: 5| Step: 2
Training loss: 0.890401176302425
Validation loss: 2.6327822870250728

Epoch: 5| Step: 3
Training loss: 0.8622629710698638
Validation loss: 2.601316100941118

Epoch: 5| Step: 4
Training loss: 1.0799076987490102
Validation loss: 2.655372917821651

Epoch: 5| Step: 5
Training loss: 0.8204616229434823
Validation loss: 2.667596628583816

Epoch: 5| Step: 6
Training loss: 0.7491227025748393
Validation loss: 2.6101915952003627

Epoch: 5| Step: 7
Training loss: 0.8994572035790538
Validation loss: 2.5883245264203336

Epoch: 5| Step: 8
Training loss: 1.204744264920293
Validation loss: 2.607882104008904

Epoch: 5| Step: 9
Training loss: 1.107585323052306
Validation loss: 2.619997608025912

Epoch: 5| Step: 10
Training loss: 0.7551985422135483
Validation loss: 2.633660516653576

Epoch: 307| Step: 0
Training loss: 0.8866972731623521
Validation loss: 2.596145918903297

Epoch: 5| Step: 1
Training loss: 0.7512715607276915
Validation loss: 2.652766123880309

Epoch: 5| Step: 2
Training loss: 0.7222043248143479
Validation loss: 2.6184974934186314

Epoch: 5| Step: 3
Training loss: 1.1610908211958735
Validation loss: 2.633923036104247

Epoch: 5| Step: 4
Training loss: 1.0252989519102558
Validation loss: 2.6761005491044707

Epoch: 5| Step: 5
Training loss: 0.6244661673963138
Validation loss: 2.667956443775896

Epoch: 5| Step: 6
Training loss: 0.8065085683983546
Validation loss: 2.684260620307057

Epoch: 5| Step: 7
Training loss: 0.8935561883632375
Validation loss: 2.6761434363973224

Epoch: 5| Step: 8
Training loss: 1.1216545164594236
Validation loss: 2.6688866610107884

Epoch: 5| Step: 9
Training loss: 1.183802721567533
Validation loss: 2.662457253479195

Epoch: 5| Step: 10
Training loss: 0.8666090883483187
Validation loss: 2.6329020833080263

Epoch: 308| Step: 0
Training loss: 0.5989078804549255
Validation loss: 2.639405876079056

Epoch: 5| Step: 1
Training loss: 0.9191034000638898
Validation loss: 2.6908005405315585

Epoch: 5| Step: 2
Training loss: 0.9977924896154855
Validation loss: 2.6847671819002596

Epoch: 5| Step: 3
Training loss: 0.7486910125856377
Validation loss: 2.667562115847865

Epoch: 5| Step: 4
Training loss: 1.0197513971115757
Validation loss: 2.677023933459977

Epoch: 5| Step: 5
Training loss: 0.9516773173398173
Validation loss: 2.6547401784410503

Epoch: 5| Step: 6
Training loss: 1.2949501368227658
Validation loss: 2.6585880516898834

Epoch: 5| Step: 7
Training loss: 0.5284382517497414
Validation loss: 2.6497395517281164

Epoch: 5| Step: 8
Training loss: 0.6753878909442339
Validation loss: 2.63275661331901

Epoch: 5| Step: 9
Training loss: 1.0908630417366914
Validation loss: 2.6001953643999633

Epoch: 5| Step: 10
Training loss: 1.1110183471792263
Validation loss: 2.6159137386656854

Epoch: 309| Step: 0
Training loss: 0.6816118119497957
Validation loss: 2.6032726723845045

Epoch: 5| Step: 1
Training loss: 0.5795312480664246
Validation loss: 2.6467536066735207

Epoch: 5| Step: 2
Training loss: 1.3596568637518518
Validation loss: 2.6390442145301516

Epoch: 5| Step: 3
Training loss: 0.7833056299572922
Validation loss: 2.6337843319371563

Epoch: 5| Step: 4
Training loss: 0.8152841403834936
Validation loss: 2.6460761250422724

Epoch: 5| Step: 5
Training loss: 0.7706557447328872
Validation loss: 2.6282395258826985

Epoch: 5| Step: 6
Training loss: 0.7292372578556183
Validation loss: 2.6475553314749134

Epoch: 5| Step: 7
Training loss: 1.2307025505650113
Validation loss: 2.639426968142345

Epoch: 5| Step: 8
Training loss: 0.7460493304226419
Validation loss: 2.6295012181560455

Epoch: 5| Step: 9
Training loss: 1.1595476911309868
Validation loss: 2.6225781653773343

Epoch: 5| Step: 10
Training loss: 0.9806705890218773
Validation loss: 2.6703150748984115

Epoch: 310| Step: 0
Training loss: 0.4721862410724856
Validation loss: 2.6494192218742

Epoch: 5| Step: 1
Training loss: 0.7924819353974991
Validation loss: 2.6877801801081675

Epoch: 5| Step: 2
Training loss: 0.6071788878328283
Validation loss: 2.696175733868703

Epoch: 5| Step: 3
Training loss: 1.2219846300666304
Validation loss: 2.716543516544428

Epoch: 5| Step: 4
Training loss: 0.975867978129014
Validation loss: 2.685436710190041

Epoch: 5| Step: 5
Training loss: 1.2087597861776493
Validation loss: 2.6467989555659037

Epoch: 5| Step: 6
Training loss: 0.7580873443233503
Validation loss: 2.621097579182286

Epoch: 5| Step: 7
Training loss: 1.1460506002030224
Validation loss: 2.610810799813623

Epoch: 5| Step: 8
Training loss: 1.0225159084696067
Validation loss: 2.5836236144277223

Epoch: 5| Step: 9
Training loss: 0.7015793447872374
Validation loss: 2.5971968780112196

Epoch: 5| Step: 10
Training loss: 0.9164433568546051
Validation loss: 2.673299650807033

Epoch: 311| Step: 0
Training loss: 0.9410271098765018
Validation loss: 2.677915143597017

Epoch: 5| Step: 1
Training loss: 1.0071947437088622
Validation loss: 2.70798339349929

Epoch: 5| Step: 2
Training loss: 0.8172284234560317
Validation loss: 2.712004709634047

Epoch: 5| Step: 3
Training loss: 1.1602632620936495
Validation loss: 2.6748174155570417

Epoch: 5| Step: 4
Training loss: 0.8460362507310883
Validation loss: 2.6964981122794414

Epoch: 5| Step: 5
Training loss: 0.6010695828368262
Validation loss: 2.684326559024579

Epoch: 5| Step: 6
Training loss: 0.6842844498184927
Validation loss: 2.6723914058464433

Epoch: 5| Step: 7
Training loss: 1.0861529678535278
Validation loss: 2.674426153467773

Epoch: 5| Step: 8
Training loss: 0.8911128130349797
Validation loss: 2.694183631584915

Epoch: 5| Step: 9
Training loss: 1.0604173219350252
Validation loss: 2.6438107322618114

Epoch: 5| Step: 10
Training loss: 0.6689861424369411
Validation loss: 2.6393512338796117

Epoch: 312| Step: 0
Training loss: 0.5690026330015409
Validation loss: 2.6411045952250145

Epoch: 5| Step: 1
Training loss: 0.71603590150417
Validation loss: 2.621136799369801

Epoch: 5| Step: 2
Training loss: 0.8050796886356723
Validation loss: 2.619422068607774

Epoch: 5| Step: 3
Training loss: 0.8099823238068891
Validation loss: 2.6616202263993562

Epoch: 5| Step: 4
Training loss: 0.9380895668164491
Validation loss: 2.6635596655102765

Epoch: 5| Step: 5
Training loss: 1.2591940359342741
Validation loss: 2.692609603372043

Epoch: 5| Step: 6
Training loss: 0.8433344842189229
Validation loss: 2.7321147224614792

Epoch: 5| Step: 7
Training loss: 0.7823473281123317
Validation loss: 2.719152064161573

Epoch: 5| Step: 8
Training loss: 1.0150517533173058
Validation loss: 2.736190097829807

Epoch: 5| Step: 9
Training loss: 0.9394307917043936
Validation loss: 2.714352659407928

Epoch: 5| Step: 10
Training loss: 1.0434361814094706
Validation loss: 2.6913923716268027

Epoch: 313| Step: 0
Training loss: 0.9119179502311578
Validation loss: 2.671438962009547

Epoch: 5| Step: 1
Training loss: 0.9882170765664194
Validation loss: 2.6627063922148784

Epoch: 5| Step: 2
Training loss: 0.8826724253566988
Validation loss: 2.6598604954688634

Epoch: 5| Step: 3
Training loss: 0.7693654380346696
Validation loss: 2.6066001839593116

Epoch: 5| Step: 4
Training loss: 0.8276672897769254
Validation loss: 2.5955659321484816

Epoch: 5| Step: 5
Training loss: 0.7732720631616206
Validation loss: 2.627452750405357

Epoch: 5| Step: 6
Training loss: 1.1356962658822685
Validation loss: 2.633930571509472

Epoch: 5| Step: 7
Training loss: 0.8055338066460959
Validation loss: 2.6251483148727703

Epoch: 5| Step: 8
Training loss: 0.5686310842930251
Validation loss: 2.637861857192365

Epoch: 5| Step: 9
Training loss: 1.0112063019580273
Validation loss: 2.69628336147717

Epoch: 5| Step: 10
Training loss: 1.1518780300620055
Validation loss: 2.7283394380288266

Epoch: 314| Step: 0
Training loss: 1.1376270977739047
Validation loss: 2.6985373246133952

Epoch: 5| Step: 1
Training loss: 0.7715231970181713
Validation loss: 2.70633283680304

Epoch: 5| Step: 2
Training loss: 0.6282337929562634
Validation loss: 2.6912874347116857

Epoch: 5| Step: 3
Training loss: 1.0125456858559196
Validation loss: 2.667737143820085

Epoch: 5| Step: 4
Training loss: 0.41135233910158575
Validation loss: 2.6908782670185696

Epoch: 5| Step: 5
Training loss: 1.1131301509645897
Validation loss: 2.6990911262065937

Epoch: 5| Step: 6
Training loss: 0.9373636146522403
Validation loss: 2.7243819535080283

Epoch: 5| Step: 7
Training loss: 0.81198866966874
Validation loss: 2.714003561504475

Epoch: 5| Step: 8
Training loss: 0.74660031363018
Validation loss: 2.6869329124645165

Epoch: 5| Step: 9
Training loss: 1.0240154236213102
Validation loss: 2.7401899788018724

Epoch: 5| Step: 10
Training loss: 0.8945688631237474
Validation loss: 2.7316941074038494

Epoch: 315| Step: 0
Training loss: 0.5717240983911449
Validation loss: 2.7278428347634436

Epoch: 5| Step: 1
Training loss: 1.2582292517928275
Validation loss: 2.6974516909090966

Epoch: 5| Step: 2
Training loss: 0.7741460925825484
Validation loss: 2.6736040510973926

Epoch: 5| Step: 3
Training loss: 0.9938645494765868
Validation loss: 2.666686854619345

Epoch: 5| Step: 4
Training loss: 0.9292435748227343
Validation loss: 2.649283434673907

Epoch: 5| Step: 5
Training loss: 0.6662643281494568
Validation loss: 2.6287759576935366

Epoch: 5| Step: 6
Training loss: 1.0418286324785901
Validation loss: 2.6412721547068827

Epoch: 5| Step: 7
Training loss: 0.7482762794225988
Validation loss: 2.67945487361223

Epoch: 5| Step: 8
Training loss: 0.582408142951353
Validation loss: 2.695308030552641

Epoch: 5| Step: 9
Training loss: 0.6999389945422244
Validation loss: 2.7268636367774426

Epoch: 5| Step: 10
Training loss: 1.1840539421603884
Validation loss: 2.7216972205893284

Epoch: 316| Step: 0
Training loss: 0.8991735345921688
Validation loss: 2.72227776824901

Epoch: 5| Step: 1
Training loss: 0.9807522428488387
Validation loss: 2.7444043585657516

Epoch: 5| Step: 2
Training loss: 1.040913990205333
Validation loss: 2.687377049275286

Epoch: 5| Step: 3
Training loss: 1.0853776105906234
Validation loss: 2.62805900140182

Epoch: 5| Step: 4
Training loss: 1.0338468511340215
Validation loss: 2.646755023732229

Epoch: 5| Step: 5
Training loss: 0.6524770223656882
Validation loss: 2.6392945415173283

Epoch: 5| Step: 6
Training loss: 0.9405411667075863
Validation loss: 2.638661253832549

Epoch: 5| Step: 7
Training loss: 0.6698106945967808
Validation loss: 2.668977803679153

Epoch: 5| Step: 8
Training loss: 0.784200285644596
Validation loss: 2.6644986793096326

Epoch: 5| Step: 9
Training loss: 0.4192849585323713
Validation loss: 2.659925595283078

Epoch: 5| Step: 10
Training loss: 1.0115413436586391
Validation loss: 2.705581545576671

Epoch: 317| Step: 0
Training loss: 0.6195656554011784
Validation loss: 2.677310163265705

Epoch: 5| Step: 1
Training loss: 0.8120961652876815
Validation loss: 2.709855648716282

Epoch: 5| Step: 2
Training loss: 0.8741918987551598
Validation loss: 2.7265972926566184

Epoch: 5| Step: 3
Training loss: 0.743446527003756
Validation loss: 2.6704723315432997

Epoch: 5| Step: 4
Training loss: 1.1726764735664261
Validation loss: 2.6817496886662395

Epoch: 5| Step: 5
Training loss: 1.1815442763211832
Validation loss: 2.689979611727535

Epoch: 5| Step: 6
Training loss: 0.7739800756043763
Validation loss: 2.6568879299461092

Epoch: 5| Step: 7
Training loss: 0.7325822985118224
Validation loss: 2.6317903380827365

Epoch: 5| Step: 8
Training loss: 0.6332815104120953
Validation loss: 2.6260184857763162

Epoch: 5| Step: 9
Training loss: 1.104439137986746
Validation loss: 2.6525902279054017

Epoch: 5| Step: 10
Training loss: 0.7969744751120342
Validation loss: 2.6533543670005284

Epoch: 318| Step: 0
Training loss: 0.9165839605878698
Validation loss: 2.68085629058838

Epoch: 5| Step: 1
Training loss: 1.0570464139472346
Validation loss: 2.6866724486296305

Epoch: 5| Step: 2
Training loss: 1.0574029510010967
Validation loss: 2.604617855897008

Epoch: 5| Step: 3
Training loss: 0.5925058581066659
Validation loss: 2.649456361911537

Epoch: 5| Step: 4
Training loss: 1.4438785347137764
Validation loss: 2.673532509754845

Epoch: 5| Step: 5
Training loss: 0.3434149019132272
Validation loss: 2.6184715758720487

Epoch: 5| Step: 6
Training loss: 0.5765709739413826
Validation loss: 2.6463709149375783

Epoch: 5| Step: 7
Training loss: 0.991764819606395
Validation loss: 2.652407418259108

Epoch: 5| Step: 8
Training loss: 0.8954587234470897
Validation loss: 2.6679946537099855

Epoch: 5| Step: 9
Training loss: 0.6531904288195152
Validation loss: 2.6753451898705207

Epoch: 5| Step: 10
Training loss: 0.53046696119049
Validation loss: 2.694205248728462

Epoch: 319| Step: 0
Training loss: 0.8477109197047589
Validation loss: 2.660205615036155

Epoch: 5| Step: 1
Training loss: 0.8800243132657084
Validation loss: 2.685226075582398

Epoch: 5| Step: 2
Training loss: 0.7070755496820842
Validation loss: 2.6475532631749723

Epoch: 5| Step: 3
Training loss: 0.8053767391306247
Validation loss: 2.6747825867335733

Epoch: 5| Step: 4
Training loss: 0.6624997093991776
Validation loss: 2.6708011902920163

Epoch: 5| Step: 5
Training loss: 1.2355078798086785
Validation loss: 2.725686179263213

Epoch: 5| Step: 6
Training loss: 0.5558833542649149
Validation loss: 2.756469728742293

Epoch: 5| Step: 7
Training loss: 0.8477265992395532
Validation loss: 2.7119775739008403

Epoch: 5| Step: 8
Training loss: 0.8706526730117771
Validation loss: 2.7182133528882395

Epoch: 5| Step: 9
Training loss: 0.9971998169848706
Validation loss: 2.665511216157782

Epoch: 5| Step: 10
Training loss: 1.0282748104508834
Validation loss: 2.7022617452312887

Epoch: 320| Step: 0
Training loss: 0.8495968170991821
Validation loss: 2.695535519721044

Epoch: 5| Step: 1
Training loss: 0.7752287573218253
Validation loss: 2.6848309077002384

Epoch: 5| Step: 2
Training loss: 0.5722734105749057
Validation loss: 2.664976278977253

Epoch: 5| Step: 3
Training loss: 1.0976723774984314
Validation loss: 2.7024484774509037

Epoch: 5| Step: 4
Training loss: 0.5105727664187566
Validation loss: 2.676910429919912

Epoch: 5| Step: 5
Training loss: 0.9324633726131586
Validation loss: 2.710406886580301

Epoch: 5| Step: 6
Training loss: 1.1942186025030217
Validation loss: 2.6969830520169586

Epoch: 5| Step: 7
Training loss: 1.006218292494968
Validation loss: 2.7519846622351323

Epoch: 5| Step: 8
Training loss: 0.9301504697384586
Validation loss: 2.7141672345128347

Epoch: 5| Step: 9
Training loss: 0.4388699540380821
Validation loss: 2.68128748319026

Epoch: 5| Step: 10
Training loss: 0.81252622562045
Validation loss: 2.645846953941157

Epoch: 321| Step: 0
Training loss: 0.8839728232862449
Validation loss: 2.674079377632612

Epoch: 5| Step: 1
Training loss: 0.6694964067079211
Validation loss: 2.6757064422049748

Epoch: 5| Step: 2
Training loss: 0.8969246774133963
Validation loss: 2.6176317680603662

Epoch: 5| Step: 3
Training loss: 0.9307875976550973
Validation loss: 2.6731440076740807

Epoch: 5| Step: 4
Training loss: 1.003526727207374
Validation loss: 2.6824293411688975

Epoch: 5| Step: 5
Training loss: 0.6852770760804963
Validation loss: 2.670842787197781

Epoch: 5| Step: 6
Training loss: 0.9669940477698887
Validation loss: 2.6784995012055353

Epoch: 5| Step: 7
Training loss: 0.7650582298232561
Validation loss: 2.680294705083319

Epoch: 5| Step: 8
Training loss: 0.5267213044264466
Validation loss: 2.692275950711125

Epoch: 5| Step: 9
Training loss: 1.1697848180817805
Validation loss: 2.659508845650538

Epoch: 5| Step: 10
Training loss: 0.6597401588633983
Validation loss: 2.6396632493109524

Epoch: 322| Step: 0
Training loss: 0.8348886202006612
Validation loss: 2.6528907260330565

Epoch: 5| Step: 1
Training loss: 0.9202278098239692
Validation loss: 2.638954348166949

Epoch: 5| Step: 2
Training loss: 0.8988696178688393
Validation loss: 2.6592545524200912

Epoch: 5| Step: 3
Training loss: 0.8584258646917705
Validation loss: 2.6391441803179494

Epoch: 5| Step: 4
Training loss: 0.5659395333921827
Validation loss: 2.6849872912541564

Epoch: 5| Step: 5
Training loss: 0.7528861858303946
Validation loss: 2.689128934387049

Epoch: 5| Step: 6
Training loss: 0.9466375097185898
Validation loss: 2.7074806742237443

Epoch: 5| Step: 7
Training loss: 0.9202354204576899
Validation loss: 2.722506616961158

Epoch: 5| Step: 8
Training loss: 0.6716011065732985
Validation loss: 2.6618402816785522

Epoch: 5| Step: 9
Training loss: 0.6242208869907051
Validation loss: 2.6721309910316595

Epoch: 5| Step: 10
Training loss: 1.199648950806528
Validation loss: 2.6496711016835577

Epoch: 323| Step: 0
Training loss: 0.6589732433163547
Validation loss: 2.6244497586811257

Epoch: 5| Step: 1
Training loss: 0.9980914858050639
Validation loss: 2.6271227092832907

Epoch: 5| Step: 2
Training loss: 1.1393638327381406
Validation loss: 2.5983867611476232

Epoch: 5| Step: 3
Training loss: 0.8133752949891319
Validation loss: 2.6371949382431756

Epoch: 5| Step: 4
Training loss: 0.7469016688864619
Validation loss: 2.700305792310685

Epoch: 5| Step: 5
Training loss: 0.5490167368368339
Validation loss: 2.7580403633501764

Epoch: 5| Step: 6
Training loss: 0.7940763058113425
Validation loss: 2.7832963786165865

Epoch: 5| Step: 7
Training loss: 0.8082041147188199
Validation loss: 2.813273718360296

Epoch: 5| Step: 8
Training loss: 0.8272415703199615
Validation loss: 2.7639659393954616

Epoch: 5| Step: 9
Training loss: 0.7218285847063399
Validation loss: 2.7850582739137755

Epoch: 5| Step: 10
Training loss: 1.073498238034839
Validation loss: 2.6865427907681414

Epoch: 324| Step: 0
Training loss: 0.7145270808315373
Validation loss: 2.678582112153795

Epoch: 5| Step: 1
Training loss: 0.6434956409185179
Validation loss: 2.6386565397770956

Epoch: 5| Step: 2
Training loss: 0.9755401753335843
Validation loss: 2.5744787938163056

Epoch: 5| Step: 3
Training loss: 0.9406467714039654
Validation loss: 2.5727538957871934

Epoch: 5| Step: 4
Training loss: 1.0744484395773968
Validation loss: 2.58650242590134

Epoch: 5| Step: 5
Training loss: 1.0011269061065295
Validation loss: 2.616939375087446

Epoch: 5| Step: 6
Training loss: 0.6750633748644562
Validation loss: 2.679859578830128

Epoch: 5| Step: 7
Training loss: 0.7736601075690553
Validation loss: 2.6632911942395308

Epoch: 5| Step: 8
Training loss: 0.8734639172320863
Validation loss: 2.666979206776789

Epoch: 5| Step: 9
Training loss: 0.6324336012565442
Validation loss: 2.6837677333884447

Epoch: 5| Step: 10
Training loss: 0.7187861972484508
Validation loss: 2.6899323994640785

Epoch: 325| Step: 0
Training loss: 0.9308642785459029
Validation loss: 2.650132223906461

Epoch: 5| Step: 1
Training loss: 0.39849997012019794
Validation loss: 2.661441192626341

Epoch: 5| Step: 2
Training loss: 0.7265840752792493
Validation loss: 2.6421339084601483

Epoch: 5| Step: 3
Training loss: 0.945745794443717
Validation loss: 2.63696321959127

Epoch: 5| Step: 4
Training loss: 1.0343056116715534
Validation loss: 2.624750796441448

Epoch: 5| Step: 5
Training loss: 0.857542824523845
Validation loss: 2.639527022386765

Epoch: 5| Step: 6
Training loss: 0.9076326609031949
Validation loss: 2.65423087119688

Epoch: 5| Step: 7
Training loss: 0.5670042892778222
Validation loss: 2.6569187680850805

Epoch: 5| Step: 8
Training loss: 0.5590630807121932
Validation loss: 2.680349993674622

Epoch: 5| Step: 9
Training loss: 0.861615502820234
Validation loss: 2.647644100301066

Epoch: 5| Step: 10
Training loss: 0.9234087841132521
Validation loss: 2.715629267933776

Epoch: 326| Step: 0
Training loss: 0.8624613393881719
Validation loss: 2.7289028624188676

Epoch: 5| Step: 1
Training loss: 0.6635554228893276
Validation loss: 2.7220500648392973

Epoch: 5| Step: 2
Training loss: 0.896560100606724
Validation loss: 2.688666614895024

Epoch: 5| Step: 3
Training loss: 0.8173674624151366
Validation loss: 2.7102502751671618

Epoch: 5| Step: 4
Training loss: 0.9317541473128512
Validation loss: 2.6700549986175592

Epoch: 5| Step: 5
Training loss: 0.8978536616183213
Validation loss: 2.6612584168406865

Epoch: 5| Step: 6
Training loss: 0.7171829805252522
Validation loss: 2.6577508738523186

Epoch: 5| Step: 7
Training loss: 0.6008892750941999
Validation loss: 2.667524917476473

Epoch: 5| Step: 8
Training loss: 0.8022924910146289
Validation loss: 2.6779861054825744

Epoch: 5| Step: 9
Training loss: 0.9659489776413198
Validation loss: 2.6878450357725012

Epoch: 5| Step: 10
Training loss: 0.65818666613005
Validation loss: 2.6840562775453454

Epoch: 327| Step: 0
Training loss: 0.7880540200805167
Validation loss: 2.679368528842815

Epoch: 5| Step: 1
Training loss: 0.808120552221864
Validation loss: 2.7086118272539648

Epoch: 5| Step: 2
Training loss: 0.495987798234998
Validation loss: 2.699564661154523

Epoch: 5| Step: 3
Training loss: 1.3127412120239441
Validation loss: 2.7147714020496765

Epoch: 5| Step: 4
Training loss: 0.7700636904868055
Validation loss: 2.6427512057974285

Epoch: 5| Step: 5
Training loss: 0.35221593318933475
Validation loss: 2.60209412300896

Epoch: 5| Step: 6
Training loss: 0.9770638361587226
Validation loss: 2.591086498580216

Epoch: 5| Step: 7
Training loss: 0.7700767713521117
Validation loss: 2.6073519295573004

Epoch: 5| Step: 8
Training loss: 0.9508387552140758
Validation loss: 2.616291490407518

Epoch: 5| Step: 9
Training loss: 0.7533918612314737
Validation loss: 2.664399181542571

Epoch: 5| Step: 10
Training loss: 0.4400924101694487
Validation loss: 2.736550322116183

Epoch: 328| Step: 0
Training loss: 0.763821287246474
Validation loss: 2.726847912847331

Epoch: 5| Step: 1
Training loss: 0.7602922041599067
Validation loss: 2.7872732086311314

Epoch: 5| Step: 2
Training loss: 0.6356446737809988
Validation loss: 2.7921997195647723

Epoch: 5| Step: 3
Training loss: 0.8609448745882473
Validation loss: 2.741688213593486

Epoch: 5| Step: 4
Training loss: 0.8685320491598371
Validation loss: 2.656806084600198

Epoch: 5| Step: 5
Training loss: 0.7190931993518611
Validation loss: 2.613171433559698

Epoch: 5| Step: 6
Training loss: 0.9629417854630177
Validation loss: 2.6091005808450562

Epoch: 5| Step: 7
Training loss: 0.7832490522279676
Validation loss: 2.5910017019944074

Epoch: 5| Step: 8
Training loss: 0.8314410341496397
Validation loss: 2.589509070927639

Epoch: 5| Step: 9
Training loss: 0.9397732512430771
Validation loss: 2.5980197491485075

Epoch: 5| Step: 10
Training loss: 0.6721389828547557
Validation loss: 2.66126583245955

Epoch: 329| Step: 0
Training loss: 0.7925546250636083
Validation loss: 2.701578192165711

Epoch: 5| Step: 1
Training loss: 0.48266394715548494
Validation loss: 2.6960206202407395

Epoch: 5| Step: 2
Training loss: 0.940749323033422
Validation loss: 2.699025534898054

Epoch: 5| Step: 3
Training loss: 0.893096105750182
Validation loss: 2.6902655108676328

Epoch: 5| Step: 4
Training loss: 0.6207018161421385
Validation loss: 2.6939324782470373

Epoch: 5| Step: 5
Training loss: 1.0529016138975065
Validation loss: 2.667054058464568

Epoch: 5| Step: 6
Training loss: 0.652060738579349
Validation loss: 2.629218130129849

Epoch: 5| Step: 7
Training loss: 0.7238208356594225
Validation loss: 2.632775207938979

Epoch: 5| Step: 8
Training loss: 1.0211305899129082
Validation loss: 2.5876962071651874

Epoch: 5| Step: 9
Training loss: 0.5873093123106405
Validation loss: 2.6426304318765585

Epoch: 5| Step: 10
Training loss: 0.9357795187156561
Validation loss: 2.6411305391616864

Epoch: 330| Step: 0
Training loss: 0.8520702283328707
Validation loss: 2.667312614656734

Epoch: 5| Step: 1
Training loss: 0.663306063490065
Validation loss: 2.695352685696243

Epoch: 5| Step: 2
Training loss: 0.7985152025728309
Validation loss: 2.728423648612056

Epoch: 5| Step: 3
Training loss: 0.8755494163941266
Validation loss: 2.7598881468415932

Epoch: 5| Step: 4
Training loss: 0.981297359417051
Validation loss: 2.7200251526079797

Epoch: 5| Step: 5
Training loss: 0.7822933859029504
Validation loss: 2.710863805160887

Epoch: 5| Step: 6
Training loss: 0.2755400610682349
Validation loss: 2.703066204322396

Epoch: 5| Step: 7
Training loss: 0.8966606149741048
Validation loss: 2.664003389760264

Epoch: 5| Step: 8
Training loss: 0.600605637141985
Validation loss: 2.664196282054352

Epoch: 5| Step: 9
Training loss: 0.9162720278685038
Validation loss: 2.6602816547122554

Epoch: 5| Step: 10
Training loss: 0.7034619689508836
Validation loss: 2.706203213127915

Epoch: 331| Step: 0
Training loss: 0.6634335849554808
Validation loss: 2.6996458084471424

Epoch: 5| Step: 1
Training loss: 0.3592900092756079
Validation loss: 2.6816063369891423

Epoch: 5| Step: 2
Training loss: 0.8837584769504718
Validation loss: 2.6905416059467124

Epoch: 5| Step: 3
Training loss: 1.0067085311302326
Validation loss: 2.671500015067263

Epoch: 5| Step: 4
Training loss: 0.5091193768860176
Validation loss: 2.7233918690241774

Epoch: 5| Step: 5
Training loss: 0.8212876835833028
Validation loss: 2.7407553081318703

Epoch: 5| Step: 6
Training loss: 0.7504439629379464
Validation loss: 2.6691975741333973

Epoch: 5| Step: 7
Training loss: 0.8408110614759485
Validation loss: 2.616744194021366

Epoch: 5| Step: 8
Training loss: 0.7257523891266419
Validation loss: 2.6562228129646575

Epoch: 5| Step: 9
Training loss: 0.9525739609045311
Validation loss: 2.6699978338376202

Epoch: 5| Step: 10
Training loss: 0.8120083054719114
Validation loss: 2.64391807421991

Epoch: 332| Step: 0
Training loss: 0.714902823253419
Validation loss: 2.6638623542146598

Epoch: 5| Step: 1
Training loss: 1.0240718244419704
Validation loss: 2.626334734389608

Epoch: 5| Step: 2
Training loss: 0.815265022144109
Validation loss: 2.6439140637984777

Epoch: 5| Step: 3
Training loss: 0.8464376242155248
Validation loss: 2.6638254410155406

Epoch: 5| Step: 4
Training loss: 0.7321340987382768
Validation loss: 2.680584277244737

Epoch: 5| Step: 5
Training loss: 0.5098851381712198
Validation loss: 2.7117310148993967

Epoch: 5| Step: 6
Training loss: 0.46928130874486085
Validation loss: 2.706669729239037

Epoch: 5| Step: 7
Training loss: 0.7641322706698167
Validation loss: 2.7298309981749074

Epoch: 5| Step: 8
Training loss: 0.7262225842841064
Validation loss: 2.687265512281937

Epoch: 5| Step: 9
Training loss: 0.9136896269510167
Validation loss: 2.7022802012134672

Epoch: 5| Step: 10
Training loss: 0.8314226458817756
Validation loss: 2.6780557521043726

Epoch: 333| Step: 0
Training loss: 1.0654897699102162
Validation loss: 2.7045576344197326

Epoch: 5| Step: 1
Training loss: 1.0525001166155608
Validation loss: 2.6584400238014445

Epoch: 5| Step: 2
Training loss: 0.749707920103253
Validation loss: 2.6597287257310183

Epoch: 5| Step: 3
Training loss: 0.8633729014356666
Validation loss: 2.6943390079647855

Epoch: 5| Step: 4
Training loss: 0.523453470242685
Validation loss: 2.6916706874427136

Epoch: 5| Step: 5
Training loss: 0.6246892633456159
Validation loss: 2.720218731785501

Epoch: 5| Step: 6
Training loss: 0.6752097739871564
Validation loss: 2.734741184542861

Epoch: 5| Step: 7
Training loss: 0.7458653924399002
Validation loss: 2.7356073914819548

Epoch: 5| Step: 8
Training loss: 0.6933969192011181
Validation loss: 2.697685913779274

Epoch: 5| Step: 9
Training loss: 0.6435630230515751
Validation loss: 2.695427834669378

Epoch: 5| Step: 10
Training loss: 0.6424429847044503
Validation loss: 2.659327839063187

Epoch: 334| Step: 0
Training loss: 0.7191112688445492
Validation loss: 2.6417529750370803

Epoch: 5| Step: 1
Training loss: 1.0522590087664498
Validation loss: 2.6344884304293252

Epoch: 5| Step: 2
Training loss: 0.5462994135018164
Validation loss: 2.628561056750431

Epoch: 5| Step: 3
Training loss: 0.6952324724755413
Validation loss: 2.6665585352396164

Epoch: 5| Step: 4
Training loss: 0.661367940858909
Validation loss: 2.645172647726436

Epoch: 5| Step: 5
Training loss: 0.7388512565555124
Validation loss: 2.6557619402892656

Epoch: 5| Step: 6
Training loss: 0.982828530088369
Validation loss: 2.704081167835063

Epoch: 5| Step: 7
Training loss: 0.9190934454031628
Validation loss: 2.7466785988661497

Epoch: 5| Step: 8
Training loss: 0.5626974818814482
Validation loss: 2.7220435037461557

Epoch: 5| Step: 9
Training loss: 0.7249642297536495
Validation loss: 2.7089766244027524

Epoch: 5| Step: 10
Training loss: 0.5838037421996202
Validation loss: 2.744412430403302

Epoch: 335| Step: 0
Training loss: 0.8774531580711701
Validation loss: 2.711302474025799

Epoch: 5| Step: 1
Training loss: 0.9744467437151069
Validation loss: 2.7015378608866567

Epoch: 5| Step: 2
Training loss: 0.6472800622134567
Validation loss: 2.707927132586207

Epoch: 5| Step: 3
Training loss: 0.8898047300496403
Validation loss: 2.6932981521118378

Epoch: 5| Step: 4
Training loss: 0.7572529486859788
Validation loss: 2.703967538615985

Epoch: 5| Step: 5
Training loss: 0.6287446614108948
Validation loss: 2.6684944491189233

Epoch: 5| Step: 6
Training loss: 0.8793670124702482
Validation loss: 2.6655664180242757

Epoch: 5| Step: 7
Training loss: 0.9229597401667577
Validation loss: 2.67089497630732

Epoch: 5| Step: 8
Training loss: 0.5235823815095418
Validation loss: 2.655930164825971

Epoch: 5| Step: 9
Training loss: 0.43212385444058915
Validation loss: 2.697343897972306

Epoch: 5| Step: 10
Training loss: 0.5253730685906279
Validation loss: 2.6739033870665985

Epoch: 336| Step: 0
Training loss: 0.4943179539876271
Validation loss: 2.6840883613502275

Epoch: 5| Step: 1
Training loss: 0.4830917155951352
Validation loss: 2.6678711567294315

Epoch: 5| Step: 2
Training loss: 0.7759048332746225
Validation loss: 2.6795460462060525

Epoch: 5| Step: 3
Training loss: 0.6855520916601733
Validation loss: 2.689237095690164

Epoch: 5| Step: 4
Training loss: 0.6300595057858791
Validation loss: 2.661511225961749

Epoch: 5| Step: 5
Training loss: 0.8398187323104289
Validation loss: 2.633104346810027

Epoch: 5| Step: 6
Training loss: 0.7327690013997481
Validation loss: 2.654413934822407

Epoch: 5| Step: 7
Training loss: 1.0745387485026734
Validation loss: 2.681408579170548

Epoch: 5| Step: 8
Training loss: 0.5268704586353724
Validation loss: 2.6511371238447805

Epoch: 5| Step: 9
Training loss: 0.9970026992753659
Validation loss: 2.646606381472278

Epoch: 5| Step: 10
Training loss: 0.5733299123260914
Validation loss: 2.661096650444529

Epoch: 337| Step: 0
Training loss: 0.6078800301191716
Validation loss: 2.6986437636671847

Epoch: 5| Step: 1
Training loss: 0.8341951126319465
Validation loss: 2.746345978599608

Epoch: 5| Step: 2
Training loss: 0.9134667566281669
Validation loss: 2.7437939632138764

Epoch: 5| Step: 3
Training loss: 0.5429411407696423
Validation loss: 2.7384788288947357

Epoch: 5| Step: 4
Training loss: 0.8588144381471905
Validation loss: 2.7097483264991378

Epoch: 5| Step: 5
Training loss: 0.6575655920070022
Validation loss: 2.676386644899464

Epoch: 5| Step: 6
Training loss: 0.8743763472224253
Validation loss: 2.6681821910673524

Epoch: 5| Step: 7
Training loss: 0.5533099732676853
Validation loss: 2.6837469664038966

Epoch: 5| Step: 8
Training loss: 0.969596339276378
Validation loss: 2.6859406270634953

Epoch: 5| Step: 9
Training loss: 0.6237714852816283
Validation loss: 2.691478953598544

Epoch: 5| Step: 10
Training loss: 0.6162929329221986
Validation loss: 2.6858545986560785

Epoch: 338| Step: 0
Training loss: 0.2236542504042532
Validation loss: 2.703602287003156

Epoch: 5| Step: 1
Training loss: 0.740286631488479
Validation loss: 2.6724303341931863

Epoch: 5| Step: 2
Training loss: 0.42004694295986994
Validation loss: 2.6649691334171517

Epoch: 5| Step: 3
Training loss: 1.015203300373313
Validation loss: 2.6383305966336486

Epoch: 5| Step: 4
Training loss: 0.7070480471138475
Validation loss: 2.652981221445984

Epoch: 5| Step: 5
Training loss: 0.8014619492787306
Validation loss: 2.6551611930231633

Epoch: 5| Step: 6
Training loss: 0.7274285763815027
Validation loss: 2.6027066442841797

Epoch: 5| Step: 7
Training loss: 0.8877875990364814
Validation loss: 2.6760292843060407

Epoch: 5| Step: 8
Training loss: 0.542774302841216
Validation loss: 2.672067394092931

Epoch: 5| Step: 9
Training loss: 0.8890144442424351
Validation loss: 2.6785398616190537

Epoch: 5| Step: 10
Training loss: 0.8446362750362348
Validation loss: 2.6855113290352843

Epoch: 339| Step: 0
Training loss: 0.7150557990409104
Validation loss: 2.6667081697628547

Epoch: 5| Step: 1
Training loss: 0.6153460931011223
Validation loss: 2.641465751934562

Epoch: 5| Step: 2
Training loss: 0.5877778208032908
Validation loss: 2.6208658238639706

Epoch: 5| Step: 3
Training loss: 0.6895233205014758
Validation loss: 2.6527904800185094

Epoch: 5| Step: 4
Training loss: 0.9349601036372469
Validation loss: 2.642166675008112

Epoch: 5| Step: 5
Training loss: 0.8964209108182742
Validation loss: 2.6418383604803264

Epoch: 5| Step: 6
Training loss: 0.709246290184433
Validation loss: 2.6512744260732815

Epoch: 5| Step: 7
Training loss: 0.447199137714191
Validation loss: 2.686601597853906

Epoch: 5| Step: 8
Training loss: 0.6803697691447742
Validation loss: 2.705702585130844

Epoch: 5| Step: 9
Training loss: 0.9509135684719889
Validation loss: 2.7357848430458604

Epoch: 5| Step: 10
Training loss: 0.7259529181759046
Validation loss: 2.7459549150590017

Epoch: 340| Step: 0
Training loss: 0.6723922468385751
Validation loss: 2.7435111496205105

Epoch: 5| Step: 1
Training loss: 0.6855222909546014
Validation loss: 2.7800002318689288

Epoch: 5| Step: 2
Training loss: 0.5995845230369968
Validation loss: 2.703359769733352

Epoch: 5| Step: 3
Training loss: 0.9324064166382149
Validation loss: 2.681288350393682

Epoch: 5| Step: 4
Training loss: 0.6183372845442076
Validation loss: 2.7248309527523373

Epoch: 5| Step: 5
Training loss: 0.843786309485304
Validation loss: 2.709614683626006

Epoch: 5| Step: 6
Training loss: 0.6191635849603467
Validation loss: 2.6723089299344487

Epoch: 5| Step: 7
Training loss: 0.9154064373289249
Validation loss: 2.6859012473915644

Epoch: 5| Step: 8
Training loss: 0.6201458060802104
Validation loss: 2.70665256859776

Epoch: 5| Step: 9
Training loss: 0.8116365392943596
Validation loss: 2.7230662603902154

Epoch: 5| Step: 10
Training loss: 0.6765066013634373
Validation loss: 2.716028884992168

Epoch: 341| Step: 0
Training loss: 0.7465380399328848
Validation loss: 2.7612209935252072

Epoch: 5| Step: 1
Training loss: 0.6258348134866101
Validation loss: 2.7433046441678877

Epoch: 5| Step: 2
Training loss: 0.7878730420187082
Validation loss: 2.725159517977746

Epoch: 5| Step: 3
Training loss: 0.8218574870169154
Validation loss: 2.7190641165867904

Epoch: 5| Step: 4
Training loss: 0.8888474175759385
Validation loss: 2.683578821464844

Epoch: 5| Step: 5
Training loss: 0.7759785381131643
Validation loss: 2.712761972652215

Epoch: 5| Step: 6
Training loss: 0.8091940747565028
Validation loss: 2.676913198589779

Epoch: 5| Step: 7
Training loss: 0.6094389417308709
Validation loss: 2.669419816744374

Epoch: 5| Step: 8
Training loss: 0.51913376711068
Validation loss: 2.620452556445108

Epoch: 5| Step: 9
Training loss: 0.7026419781878384
Validation loss: 2.6977061211169873

Epoch: 5| Step: 10
Training loss: 0.5249490690504112
Validation loss: 2.699243521822674

Epoch: 342| Step: 0
Training loss: 0.6272867806340523
Validation loss: 2.7450402375266387

Epoch: 5| Step: 1
Training loss: 1.3093589708899402
Validation loss: 2.7526660368598845

Epoch: 5| Step: 2
Training loss: 0.9298872532745517
Validation loss: 2.7537295183910153

Epoch: 5| Step: 3
Training loss: 0.5387061226450999
Validation loss: 2.679120101323739

Epoch: 5| Step: 4
Training loss: 0.40714790078495317
Validation loss: 2.6538093564251963

Epoch: 5| Step: 5
Training loss: 0.5278231102174539
Validation loss: 2.650029979372934

Epoch: 5| Step: 6
Training loss: 0.35341042064945133
Validation loss: 2.6145537974116753

Epoch: 5| Step: 7
Training loss: 0.6383377974638786
Validation loss: 2.650939662550509

Epoch: 5| Step: 8
Training loss: 0.7015459343328656
Validation loss: 2.664528399638371

Epoch: 5| Step: 9
Training loss: 0.924732918457031
Validation loss: 2.6860516139652937

Epoch: 5| Step: 10
Training loss: 0.5770064952342618
Validation loss: 2.701743338112618

Epoch: 343| Step: 0
Training loss: 0.5890959489872509
Validation loss: 2.743985737584661

Epoch: 5| Step: 1
Training loss: 0.752227970773108
Validation loss: 2.742143100832159

Epoch: 5| Step: 2
Training loss: 0.7505871540727764
Validation loss: 2.74229234204555

Epoch: 5| Step: 3
Training loss: 0.7504632631697374
Validation loss: 2.694988679389693

Epoch: 5| Step: 4
Training loss: 0.5882729842579216
Validation loss: 2.645986699032596

Epoch: 5| Step: 5
Training loss: 0.8832856657254214
Validation loss: 2.6218221710513636

Epoch: 5| Step: 6
Training loss: 0.8693901475345036
Validation loss: 2.6006214415952607

Epoch: 5| Step: 7
Training loss: 0.6253092477571861
Validation loss: 2.5966078335150025

Epoch: 5| Step: 8
Training loss: 0.5086159439049445
Validation loss: 2.6037043939291893

Epoch: 5| Step: 9
Training loss: 0.8468748789431777
Validation loss: 2.6424785384518765

Epoch: 5| Step: 10
Training loss: 0.8095529736179458
Validation loss: 2.6469600160915374

Epoch: 344| Step: 0
Training loss: 0.5013662388030625
Validation loss: 2.67368072130066

Epoch: 5| Step: 1
Training loss: 0.6981048448909521
Validation loss: 2.682629427425437

Epoch: 5| Step: 2
Training loss: 0.7262516792527447
Validation loss: 2.6988511843560166

Epoch: 5| Step: 3
Training loss: 0.792367453516782
Validation loss: 2.665191708425721

Epoch: 5| Step: 4
Training loss: 0.503781650722655
Validation loss: 2.673928554486748

Epoch: 5| Step: 5
Training loss: 0.46791068275658654
Validation loss: 2.6305265793128463

Epoch: 5| Step: 6
Training loss: 0.7098915874291721
Validation loss: 2.621515979743467

Epoch: 5| Step: 7
Training loss: 0.6203828738095497
Validation loss: 2.6231505783259963

Epoch: 5| Step: 8
Training loss: 0.9508915983686808
Validation loss: 2.675000831347798

Epoch: 5| Step: 9
Training loss: 0.871735956186651
Validation loss: 2.6859795174782906

Epoch: 5| Step: 10
Training loss: 0.8053873222624528
Validation loss: 2.669657373820763

Epoch: 345| Step: 0
Training loss: 0.7947540480950701
Validation loss: 2.7142852588828665

Epoch: 5| Step: 1
Training loss: 0.5754464965958942
Validation loss: 2.7461126582396296

Epoch: 5| Step: 2
Training loss: 0.6979832095596965
Validation loss: 2.7198211423126333

Epoch: 5| Step: 3
Training loss: 0.5061971354256931
Validation loss: 2.713056976456403

Epoch: 5| Step: 4
Training loss: 0.9268969159097917
Validation loss: 2.6567695264035907

Epoch: 5| Step: 5
Training loss: 0.47265569828726356
Validation loss: 2.6616219928855434

Epoch: 5| Step: 6
Training loss: 0.7171072638680377
Validation loss: 2.6454558590524684

Epoch: 5| Step: 7
Training loss: 0.7338411541649893
Validation loss: 2.6256728220739265

Epoch: 5| Step: 8
Training loss: 0.6823279951096725
Validation loss: 2.627607503737015

Epoch: 5| Step: 9
Training loss: 0.4846996019575445
Validation loss: 2.646891275759174

Epoch: 5| Step: 10
Training loss: 0.9764038872655886
Validation loss: 2.657000538560091

Epoch: 346| Step: 0
Training loss: 0.7119729183865129
Validation loss: 2.6642760307688484

Epoch: 5| Step: 1
Training loss: 0.5018788442310073
Validation loss: 2.724812434058527

Epoch: 5| Step: 2
Training loss: 0.6064630035915973
Validation loss: 2.705286461493653

Epoch: 5| Step: 3
Training loss: 0.5215201204886036
Validation loss: 2.7449860240244948

Epoch: 5| Step: 4
Training loss: 0.6611385373384663
Validation loss: 2.7257499552444124

Epoch: 5| Step: 5
Training loss: 0.6888228391081314
Validation loss: 2.759396980714751

Epoch: 5| Step: 6
Training loss: 0.660338856197711
Validation loss: 2.7299947195577867

Epoch: 5| Step: 7
Training loss: 0.6547146274891508
Validation loss: 2.6947967440077556

Epoch: 5| Step: 8
Training loss: 0.8924247559850983
Validation loss: 2.6603149098834065

Epoch: 5| Step: 9
Training loss: 0.7391834700379327
Validation loss: 2.6554513038128986

Epoch: 5| Step: 10
Training loss: 1.0036923072928332
Validation loss: 2.6478716664819704

Epoch: 347| Step: 0
Training loss: 0.5440182046316063
Validation loss: 2.659903140537825

Epoch: 5| Step: 1
Training loss: 0.5694650336810351
Validation loss: 2.6267431031636392

Epoch: 5| Step: 2
Training loss: 0.5320722163668814
Validation loss: 2.6565758010099314

Epoch: 5| Step: 3
Training loss: 0.7544319020122788
Validation loss: 2.6750072289393043

Epoch: 5| Step: 4
Training loss: 0.8318033398745772
Validation loss: 2.663709005565666

Epoch: 5| Step: 5
Training loss: 0.8012671136441857
Validation loss: 2.6944330755287877

Epoch: 5| Step: 6
Training loss: 0.845032035852382
Validation loss: 2.702528379902451

Epoch: 5| Step: 7
Training loss: 0.5433241415221421
Validation loss: 2.6523876259954386

Epoch: 5| Step: 8
Training loss: 1.000361019770412
Validation loss: 2.578001428192641

Epoch: 5| Step: 9
Training loss: 0.8529312263057341
Validation loss: 2.5973348108571983

Epoch: 5| Step: 10
Training loss: 0.36404621431655954
Validation loss: 2.6086748606125387

Epoch: 348| Step: 0
Training loss: 1.0128056641712566
Validation loss: 2.6233781930865243

Epoch: 5| Step: 1
Training loss: 0.8317553282080629
Validation loss: 2.63100125302764

Epoch: 5| Step: 2
Training loss: 0.8681936183914597
Validation loss: 2.6242654439692656

Epoch: 5| Step: 3
Training loss: 0.39153422397406895
Validation loss: 2.6456115138099454

Epoch: 5| Step: 4
Training loss: 0.6861731556738527
Validation loss: 2.672422259821499

Epoch: 5| Step: 5
Training loss: 0.3742801392917694
Validation loss: 2.673908333801655

Epoch: 5| Step: 6
Training loss: 0.5941121853875653
Validation loss: 2.7079827213441057

Epoch: 5| Step: 7
Training loss: 0.8110485684401427
Validation loss: 2.722826613177584

Epoch: 5| Step: 8
Training loss: 0.603250093285387
Validation loss: 2.7043030406681607

Epoch: 5| Step: 9
Training loss: 0.6008015811491096
Validation loss: 2.719636673282375

Epoch: 5| Step: 10
Training loss: 0.6533444889082853
Validation loss: 2.6736359956845157

Epoch: 349| Step: 0
Training loss: 0.5174768888684793
Validation loss: 2.674314200954583

Epoch: 5| Step: 1
Training loss: 0.8384253300747915
Validation loss: 2.6482898437350655

Epoch: 5| Step: 2
Training loss: 0.5607913079134388
Validation loss: 2.650009339800408

Epoch: 5| Step: 3
Training loss: 0.5867862657490175
Validation loss: 2.6249611944952593

Epoch: 5| Step: 4
Training loss: 0.6844197106235833
Validation loss: 2.624041662179575

Epoch: 5| Step: 5
Training loss: 0.7882355615326108
Validation loss: 2.6750827788765665

Epoch: 5| Step: 6
Training loss: 0.8873509241543935
Validation loss: 2.675622145716951

Epoch: 5| Step: 7
Training loss: 0.48110567690767364
Validation loss: 2.7066662986349384

Epoch: 5| Step: 8
Training loss: 0.7079361241319606
Validation loss: 2.7164694528459945

Epoch: 5| Step: 9
Training loss: 0.9059674052592013
Validation loss: 2.7317778626558398

Epoch: 5| Step: 10
Training loss: 0.5134764905300504
Validation loss: 2.734016653273692

Epoch: 350| Step: 0
Training loss: 0.9648764600884818
Validation loss: 2.7548959652954945

Epoch: 5| Step: 1
Training loss: 0.6154327557147414
Validation loss: 2.7835678944432463

Epoch: 5| Step: 2
Training loss: 0.7008979921265649
Validation loss: 2.763569466504423

Epoch: 5| Step: 3
Training loss: 0.4195777725197221
Validation loss: 2.6874518975629367

Epoch: 5| Step: 4
Training loss: 0.6040764089010232
Validation loss: 2.6895136213831323

Epoch: 5| Step: 5
Training loss: 0.45548825753838684
Validation loss: 2.6786634524506034

Epoch: 5| Step: 6
Training loss: 0.9753942291718709
Validation loss: 2.6374979888996997

Epoch: 5| Step: 7
Training loss: 0.6317646864937694
Validation loss: 2.661191011597549

Epoch: 5| Step: 8
Training loss: 0.8582681984554065
Validation loss: 2.6251135028573294

Epoch: 5| Step: 9
Training loss: 0.5486363520496192
Validation loss: 2.6524440844206767

Epoch: 5| Step: 10
Training loss: 0.34094039419258704
Validation loss: 2.6483118064510025

Epoch: 351| Step: 0
Training loss: 0.7062855576535361
Validation loss: 2.637088722029055

Epoch: 5| Step: 1
Training loss: 0.6042481455176687
Validation loss: 2.659195433641085

Epoch: 5| Step: 2
Training loss: 0.5881421131072542
Validation loss: 2.6747591353194786

Epoch: 5| Step: 3
Training loss: 0.36505132565787324
Validation loss: 2.7105974834842015

Epoch: 5| Step: 4
Training loss: 0.5601405621703396
Validation loss: 2.6949791800694545

Epoch: 5| Step: 5
Training loss: 0.6293029244982811
Validation loss: 2.6949260390025893

Epoch: 5| Step: 6
Training loss: 0.941631116167869
Validation loss: 2.6803260113540213

Epoch: 5| Step: 7
Training loss: 0.8585718042764098
Validation loss: 2.6595411455802456

Epoch: 5| Step: 8
Training loss: 0.7285595182639402
Validation loss: 2.6101598150715843

Epoch: 5| Step: 9
Training loss: 0.7663739492159988
Validation loss: 2.6589422462152985

Epoch: 5| Step: 10
Training loss: 0.34946818137870944
Validation loss: 2.648452771812792

Epoch: 352| Step: 0
Training loss: 0.7990085985535068
Validation loss: 2.6569728063324853

Epoch: 5| Step: 1
Training loss: 0.5130389996199087
Validation loss: 2.649820822975328

Epoch: 5| Step: 2
Training loss: 0.6947662693931365
Validation loss: 2.6378567102002983

Epoch: 5| Step: 3
Training loss: 0.406719779776443
Validation loss: 2.6697134012514026

Epoch: 5| Step: 4
Training loss: 0.6070469131314578
Validation loss: 2.6850826961118224

Epoch: 5| Step: 5
Training loss: 0.5824898059100307
Validation loss: 2.6887195964923842

Epoch: 5| Step: 6
Training loss: 0.7225641965229967
Validation loss: 2.7195649491506386

Epoch: 5| Step: 7
Training loss: 0.9238027686093078
Validation loss: 2.709350002445205

Epoch: 5| Step: 8
Training loss: 0.7589702610778781
Validation loss: 2.70315230236815

Epoch: 5| Step: 9
Training loss: 0.47096955606045965
Validation loss: 2.675700215393388

Epoch: 5| Step: 10
Training loss: 0.7379870358313106
Validation loss: 2.651060240696775

Epoch: 353| Step: 0
Training loss: 0.38708680873346807
Validation loss: 2.64326790506897

Epoch: 5| Step: 1
Training loss: 0.4666268905082234
Validation loss: 2.6742406299917976

Epoch: 5| Step: 2
Training loss: 0.7623820229235164
Validation loss: 2.667404294541812

Epoch: 5| Step: 3
Training loss: 0.7678351129812498
Validation loss: 2.693587975741928

Epoch: 5| Step: 4
Training loss: 0.6430565117123304
Validation loss: 2.701860479080654

Epoch: 5| Step: 5
Training loss: 0.6212972151776917
Validation loss: 2.708348618898886

Epoch: 5| Step: 6
Training loss: 0.5958264332707445
Validation loss: 2.702029014858195

Epoch: 5| Step: 7
Training loss: 0.7204103779853851
Validation loss: 2.6637830512207215

Epoch: 5| Step: 8
Training loss: 0.97694786097814
Validation loss: 2.679650769400075

Epoch: 5| Step: 9
Training loss: 0.639999968633055
Validation loss: 2.6749155230749393

Epoch: 5| Step: 10
Training loss: 0.6411446812792627
Validation loss: 2.6929234590356024

Epoch: 354| Step: 0
Training loss: 0.5664713065834203
Validation loss: 2.684025140863703

Epoch: 5| Step: 1
Training loss: 0.6131989004645969
Validation loss: 2.6930168344692946

Epoch: 5| Step: 2
Training loss: 0.45771103212964154
Validation loss: 2.666151039362318

Epoch: 5| Step: 3
Training loss: 0.6615228221024342
Validation loss: 2.6559826199367156

Epoch: 5| Step: 4
Training loss: 0.5105753638937103
Validation loss: 2.6826130944518867

Epoch: 5| Step: 5
Training loss: 0.7875610267365638
Validation loss: 2.683944206152059

Epoch: 5| Step: 6
Training loss: 0.7882012303004697
Validation loss: 2.7366638944925397

Epoch: 5| Step: 7
Training loss: 0.5227532255473659
Validation loss: 2.733591595770826

Epoch: 5| Step: 8
Training loss: 0.6622900477202881
Validation loss: 2.7004172435331997

Epoch: 5| Step: 9
Training loss: 1.0108030439106828
Validation loss: 2.7090071364548436

Epoch: 5| Step: 10
Training loss: 0.556516452792868
Validation loss: 2.7071205335979243

Epoch: 355| Step: 0
Training loss: 0.6548278248515512
Validation loss: 2.7018887202876605

Epoch: 5| Step: 1
Training loss: 0.46194769190498514
Validation loss: 2.65761704998109

Epoch: 5| Step: 2
Training loss: 0.6604556471294496
Validation loss: 2.6584718921616584

Epoch: 5| Step: 3
Training loss: 0.4692030624526295
Validation loss: 2.6496747067040083

Epoch: 5| Step: 4
Training loss: 0.815994195213895
Validation loss: 2.679799708276073

Epoch: 5| Step: 5
Training loss: 0.6102229112459894
Validation loss: 2.713651598703942

Epoch: 5| Step: 6
Training loss: 0.7976286820776705
Validation loss: 2.699469356431946

Epoch: 5| Step: 7
Training loss: 0.5048138333390737
Validation loss: 2.703127524636554

Epoch: 5| Step: 8
Training loss: 0.49500381706673424
Validation loss: 2.726529798033325

Epoch: 5| Step: 9
Training loss: 0.7704342418981469
Validation loss: 2.7465967494191967

Epoch: 5| Step: 10
Training loss: 0.860595287566389
Validation loss: 2.7306084624489717

Epoch: 356| Step: 0
Training loss: 0.6464357386615491
Validation loss: 2.6934706634528545

Epoch: 5| Step: 1
Training loss: 0.4987875573159976
Validation loss: 2.6968096854548462

Epoch: 5| Step: 2
Training loss: 0.8877186116433218
Validation loss: 2.6875775434062925

Epoch: 5| Step: 3
Training loss: 0.7568206194896425
Validation loss: 2.705604771522175

Epoch: 5| Step: 4
Training loss: 0.537453003980138
Validation loss: 2.6681745967417148

Epoch: 5| Step: 5
Training loss: 0.28286193815982413
Validation loss: 2.6543347803009945

Epoch: 5| Step: 6
Training loss: 0.7279718327994327
Validation loss: 2.668000797612608

Epoch: 5| Step: 7
Training loss: 0.7957818255973875
Validation loss: 2.6942627286667893

Epoch: 5| Step: 8
Training loss: 0.7766491264059854
Validation loss: 2.6864545591172684

Epoch: 5| Step: 9
Training loss: 0.5043297104668618
Validation loss: 2.657504364270321

Epoch: 5| Step: 10
Training loss: 0.44839880374269064
Validation loss: 2.677440836022505

Epoch: 357| Step: 0
Training loss: 0.7624308851843047
Validation loss: 2.6342879772404086

Epoch: 5| Step: 1
Training loss: 0.4945142185598939
Validation loss: 2.6828534116395626

Epoch: 5| Step: 2
Training loss: 0.5427549201851258
Validation loss: 2.633935443913206

Epoch: 5| Step: 3
Training loss: 0.587098306943687
Validation loss: 2.7237836637104578

Epoch: 5| Step: 4
Training loss: 0.5433333017002089
Validation loss: 2.715614188870502

Epoch: 5| Step: 5
Training loss: 0.6863985124339033
Validation loss: 2.6881388930050782

Epoch: 5| Step: 6
Training loss: 0.6711607840723635
Validation loss: 2.735198991090449

Epoch: 5| Step: 7
Training loss: 1.0902650627210115
Validation loss: 2.740370215189815

Epoch: 5| Step: 8
Training loss: 0.43643013385848006
Validation loss: 2.7619768630597377

Epoch: 5| Step: 9
Training loss: 0.5052332888335384
Validation loss: 2.6873756374193882

Epoch: 5| Step: 10
Training loss: 0.5325757482318129
Validation loss: 2.6783169802019646

Epoch: 358| Step: 0
Training loss: 0.8178931025490224
Validation loss: 2.6687270404976666

Epoch: 5| Step: 1
Training loss: 0.8711194090207404
Validation loss: 2.6485779195344947

Epoch: 5| Step: 2
Training loss: 0.5130709770469828
Validation loss: 2.6547915658625203

Epoch: 5| Step: 3
Training loss: 0.7211938856698239
Validation loss: 2.687658721632471

Epoch: 5| Step: 4
Training loss: 0.6107664117501367
Validation loss: 2.679968569575382

Epoch: 5| Step: 5
Training loss: 0.608730464363349
Validation loss: 2.6577942530519705

Epoch: 5| Step: 6
Training loss: 0.48750955254414513
Validation loss: 2.6628352649955245

Epoch: 5| Step: 7
Training loss: 0.5271606692647272
Validation loss: 2.64724965291367

Epoch: 5| Step: 8
Training loss: 0.5288239227637413
Validation loss: 2.654205584613007

Epoch: 5| Step: 9
Training loss: 0.6575580458166139
Validation loss: 2.635123606265545

Epoch: 5| Step: 10
Training loss: 0.6447936015390218
Validation loss: 2.6736757707885257

Epoch: 359| Step: 0
Training loss: 0.830620586191223
Validation loss: 2.670021157123467

Epoch: 5| Step: 1
Training loss: 0.7329095463048136
Validation loss: 2.6786042212897536

Epoch: 5| Step: 2
Training loss: 0.6863472116820124
Validation loss: 2.7032693718496064

Epoch: 5| Step: 3
Training loss: 0.5544173428987986
Validation loss: 2.7336638601434724

Epoch: 5| Step: 4
Training loss: 0.8489484298846109
Validation loss: 2.763014952060004

Epoch: 5| Step: 5
Training loss: 0.5904996648136644
Validation loss: 2.7255727693018876

Epoch: 5| Step: 6
Training loss: 0.3564580627669276
Validation loss: 2.7016198613048585

Epoch: 5| Step: 7
Training loss: 0.47917484884601524
Validation loss: 2.6684474831149765

Epoch: 5| Step: 8
Training loss: 0.33508081765492687
Validation loss: 2.6400782676957797

Epoch: 5| Step: 9
Training loss: 0.7792946951699424
Validation loss: 2.658590439744392

Epoch: 5| Step: 10
Training loss: 0.6812933881749287
Validation loss: 2.666169348675941

Epoch: 360| Step: 0
Training loss: 0.69373139622806
Validation loss: 2.6744394316291022

Epoch: 5| Step: 1
Training loss: 0.8360588128310237
Validation loss: 2.692780565106377

Epoch: 5| Step: 2
Training loss: 0.7113547724970141
Validation loss: 2.7288916182377707

Epoch: 5| Step: 3
Training loss: 0.48725710466430083
Validation loss: 2.711810412231072

Epoch: 5| Step: 4
Training loss: 0.5917939793481267
Validation loss: 2.730644735742298

Epoch: 5| Step: 5
Training loss: 0.783222987810201
Validation loss: 2.7103340319129785

Epoch: 5| Step: 6
Training loss: 0.5215416351771022
Validation loss: 2.7091839466618923

Epoch: 5| Step: 7
Training loss: 0.6371969755702014
Validation loss: 2.6805581021217546

Epoch: 5| Step: 8
Training loss: 0.563885466038547
Validation loss: 2.611131940808192

Epoch: 5| Step: 9
Training loss: 0.6536464361869393
Validation loss: 2.6315100536114913

Epoch: 5| Step: 10
Training loss: 0.5057411497551378
Validation loss: 2.6424280777393543

Epoch: 361| Step: 0
Training loss: 1.0642674835432138
Validation loss: 2.695943232197515

Epoch: 5| Step: 1
Training loss: 0.5590255775434688
Validation loss: 2.705781656252943

Epoch: 5| Step: 2
Training loss: 0.4971616320111617
Validation loss: 2.7452257838177516

Epoch: 5| Step: 3
Training loss: 0.7345388108030496
Validation loss: 2.7888282637764217

Epoch: 5| Step: 4
Training loss: 0.711011568340184
Validation loss: 2.7306959640478023

Epoch: 5| Step: 5
Training loss: 0.5498722231431251
Validation loss: 2.74433350267474

Epoch: 5| Step: 6
Training loss: 0.4656047522219589
Validation loss: 2.7661171640862445

Epoch: 5| Step: 7
Training loss: 0.5104365117892689
Validation loss: 2.7231623905243207

Epoch: 5| Step: 8
Training loss: 0.31993115217197715
Validation loss: 2.7084047110896003

Epoch: 5| Step: 9
Training loss: 0.6142001223499123
Validation loss: 2.672807257027446

Epoch: 5| Step: 10
Training loss: 0.6587173762196528
Validation loss: 2.6818729203198055

Epoch: 362| Step: 0
Training loss: 0.6388549542283556
Validation loss: 2.687251821450007

Epoch: 5| Step: 1
Training loss: 0.5359194805352357
Validation loss: 2.674022827140219

Epoch: 5| Step: 2
Training loss: 0.5454377497810918
Validation loss: 2.645891238518732

Epoch: 5| Step: 3
Training loss: 0.3325873486434105
Validation loss: 2.677849376334949

Epoch: 5| Step: 4
Training loss: 0.6446067765807331
Validation loss: 2.67169686451458

Epoch: 5| Step: 5
Training loss: 0.6751821431141063
Validation loss: 2.690059771608885

Epoch: 5| Step: 6
Training loss: 0.4952314497040916
Validation loss: 2.660107310982743

Epoch: 5| Step: 7
Training loss: 0.8013548866571878
Validation loss: 2.672957720958491

Epoch: 5| Step: 8
Training loss: 0.7029410863462471
Validation loss: 2.656924260246749

Epoch: 5| Step: 9
Training loss: 0.8147090079947715
Validation loss: 2.6728719479980376

Epoch: 5| Step: 10
Training loss: 0.5986180513687206
Validation loss: 2.6400742339625887

Epoch: 363| Step: 0
Training loss: 0.652455463095268
Validation loss: 2.630138191027821

Epoch: 5| Step: 1
Training loss: 0.6748719464801938
Validation loss: 2.6920543055760775

Epoch: 5| Step: 2
Training loss: 0.8820476763592014
Validation loss: 2.672014235820701

Epoch: 5| Step: 3
Training loss: 0.38891741410535013
Validation loss: 2.7320899052475762

Epoch: 5| Step: 4
Training loss: 0.2982250810774796
Validation loss: 2.739073273350853

Epoch: 5| Step: 5
Training loss: 0.5756255323591888
Validation loss: 2.7175809359697376

Epoch: 5| Step: 6
Training loss: 0.965035176303113
Validation loss: 2.6811917190686865

Epoch: 5| Step: 7
Training loss: 0.4948257702234164
Validation loss: 2.5968285743890713

Epoch: 5| Step: 8
Training loss: 0.510518946098986
Validation loss: 2.609169291507412

Epoch: 5| Step: 9
Training loss: 0.7639436750320805
Validation loss: 2.5907595301924964

Epoch: 5| Step: 10
Training loss: 0.5294374511524187
Validation loss: 2.5628417182655037

Epoch: 364| Step: 0
Training loss: 0.43492194533240447
Validation loss: 2.6088966226848185

Epoch: 5| Step: 1
Training loss: 0.43359249561575136
Validation loss: 2.648259044513844

Epoch: 5| Step: 2
Training loss: 0.8317935227890592
Validation loss: 2.671829484226744

Epoch: 5| Step: 3
Training loss: 0.4312511603021907
Validation loss: 2.700616962262475

Epoch: 5| Step: 4
Training loss: 0.4545266899386322
Validation loss: 2.753957095869884

Epoch: 5| Step: 5
Training loss: 1.09834240953538
Validation loss: 2.7438054658682782

Epoch: 5| Step: 6
Training loss: 0.8818492529318973
Validation loss: 2.6990927228472525

Epoch: 5| Step: 7
Training loss: 0.7084229403271356
Validation loss: 2.679252604289286

Epoch: 5| Step: 8
Training loss: 0.5455790013328297
Validation loss: 2.6312115507507743

Epoch: 5| Step: 9
Training loss: 0.5214857465747412
Validation loss: 2.653470298399393

Epoch: 5| Step: 10
Training loss: 0.42542060837459206
Validation loss: 2.677895308664171

Epoch: 365| Step: 0
Training loss: 0.6591155522546739
Validation loss: 2.6486251705999244

Epoch: 5| Step: 1
Training loss: 0.5080128201271236
Validation loss: 2.732365053313737

Epoch: 5| Step: 2
Training loss: 0.6568748814213408
Validation loss: 2.7043380220625606

Epoch: 5| Step: 3
Training loss: 0.5125355789581366
Validation loss: 2.712790249683548

Epoch: 5| Step: 4
Training loss: 0.7238265999429512
Validation loss: 2.6979056300424795

Epoch: 5| Step: 5
Training loss: 0.6692071778024778
Validation loss: 2.679170691963787

Epoch: 5| Step: 6
Training loss: 0.7347924689459867
Validation loss: 2.688021489777852

Epoch: 5| Step: 7
Training loss: 0.47101886337516
Validation loss: 2.6934217824589237

Epoch: 5| Step: 8
Training loss: 0.678985891291091
Validation loss: 2.6398770255428556

Epoch: 5| Step: 9
Training loss: 0.6392671569831223
Validation loss: 2.674910092771642

Epoch: 5| Step: 10
Training loss: 0.6689035444376459
Validation loss: 2.6774852749883125

Epoch: 366| Step: 0
Training loss: 0.6106268910248914
Validation loss: 2.659291106821179

Epoch: 5| Step: 1
Training loss: 0.5880610830375279
Validation loss: 2.647872986123462

Epoch: 5| Step: 2
Training loss: 0.7522639833432999
Validation loss: 2.6260552460706528

Epoch: 5| Step: 3
Training loss: 0.6633388390943574
Validation loss: 2.6663739805826774

Epoch: 5| Step: 4
Training loss: 0.6101358993985383
Validation loss: 2.6665945732333762

Epoch: 5| Step: 5
Training loss: 0.5381993833609217
Validation loss: 2.650932369875803

Epoch: 5| Step: 6
Training loss: 0.4900715774203341
Validation loss: 2.6902438153727233

Epoch: 5| Step: 7
Training loss: 0.6318694021805235
Validation loss: 2.7145132278376574

Epoch: 5| Step: 8
Training loss: 0.4754786438904469
Validation loss: 2.7268407705335544

Epoch: 5| Step: 9
Training loss: 0.5601829384121473
Validation loss: 2.7124455932253855

Epoch: 5| Step: 10
Training loss: 0.7984039374238167
Validation loss: 2.700130585429824

Epoch: 367| Step: 0
Training loss: 0.5767692443355447
Validation loss: 2.691475673177675

Epoch: 5| Step: 1
Training loss: 0.6207890512901351
Validation loss: 2.7110247381494075

Epoch: 5| Step: 2
Training loss: 0.5641094600329906
Validation loss: 2.683601235730656

Epoch: 5| Step: 3
Training loss: 0.6321687838715631
Validation loss: 2.705032109299016

Epoch: 5| Step: 4
Training loss: 0.5580196498193439
Validation loss: 2.6535004545539604

Epoch: 5| Step: 5
Training loss: 0.5532786786230535
Validation loss: 2.6644717234095148

Epoch: 5| Step: 6
Training loss: 0.7368221497612046
Validation loss: 2.7177686371076875

Epoch: 5| Step: 7
Training loss: 0.5384419504469907
Validation loss: 2.6649707254896193

Epoch: 5| Step: 8
Training loss: 0.5333276959459071
Validation loss: 2.653437037636795

Epoch: 5| Step: 9
Training loss: 0.8431341254756357
Validation loss: 2.649404382356706

Epoch: 5| Step: 10
Training loss: 0.5150936452204408
Validation loss: 2.6822551990438948

Epoch: 368| Step: 0
Training loss: 0.6378192868729056
Validation loss: 2.661367683864815

Epoch: 5| Step: 1
Training loss: 0.602252985032009
Validation loss: 2.6953574356535013

Epoch: 5| Step: 2
Training loss: 0.5597880207913634
Validation loss: 2.72433051990035

Epoch: 5| Step: 3
Training loss: 0.3604644350505467
Validation loss: 2.6981072045973447

Epoch: 5| Step: 4
Training loss: 0.6335079233762464
Validation loss: 2.722019100465982

Epoch: 5| Step: 5
Training loss: 0.5924537714295113
Validation loss: 2.7541403063637264

Epoch: 5| Step: 6
Training loss: 0.6568538975252349
Validation loss: 2.763875349569575

Epoch: 5| Step: 7
Training loss: 0.5372874571610803
Validation loss: 2.770539031188526

Epoch: 5| Step: 8
Training loss: 0.7430055627216741
Validation loss: 2.742742286413612

Epoch: 5| Step: 9
Training loss: 0.5743795675733264
Validation loss: 2.718626558667199

Epoch: 5| Step: 10
Training loss: 0.7444228790925306
Validation loss: 2.6959244989039557

Epoch: 369| Step: 0
Training loss: 0.2712867072094483
Validation loss: 2.725116713463772

Epoch: 5| Step: 1
Training loss: 0.4105817857992776
Validation loss: 2.7357739841778037

Epoch: 5| Step: 2
Training loss: 0.7644182933109578
Validation loss: 2.7042911614331495

Epoch: 5| Step: 3
Training loss: 0.6199538368682308
Validation loss: 2.7417211695549635

Epoch: 5| Step: 4
Training loss: 0.8820550758245611
Validation loss: 2.7309662172104385

Epoch: 5| Step: 5
Training loss: 0.4690082156736703
Validation loss: 2.7240115765408466

Epoch: 5| Step: 6
Training loss: 0.388506868694469
Validation loss: 2.7299428005454853

Epoch: 5| Step: 7
Training loss: 0.7321567716838032
Validation loss: 2.7334948101362335

Epoch: 5| Step: 8
Training loss: 0.47919092600682245
Validation loss: 2.730795928109

Epoch: 5| Step: 9
Training loss: 0.7449441411371807
Validation loss: 2.737092519248955

Epoch: 5| Step: 10
Training loss: 0.5426009599729202
Validation loss: 2.739526960888654

Epoch: 370| Step: 0
Training loss: 0.4113694187459148
Validation loss: 2.7238620556028574

Epoch: 5| Step: 1
Training loss: 0.47763291511276845
Validation loss: 2.6880309965190605

Epoch: 5| Step: 2
Training loss: 0.3228537308469536
Validation loss: 2.694158704761081

Epoch: 5| Step: 3
Training loss: 0.6320173660469741
Validation loss: 2.651661114605825

Epoch: 5| Step: 4
Training loss: 0.6357609853001678
Validation loss: 2.66962789953048

Epoch: 5| Step: 5
Training loss: 0.5277262677883646
Validation loss: 2.68477875936369

Epoch: 5| Step: 6
Training loss: 0.8499762784228339
Validation loss: 2.6735833619433014

Epoch: 5| Step: 7
Training loss: 0.6780542943280214
Validation loss: 2.6702036691305597

Epoch: 5| Step: 8
Training loss: 0.6945298107977632
Validation loss: 2.667063791817225

Epoch: 5| Step: 9
Training loss: 0.6442733017286435
Validation loss: 2.667869928178608

Epoch: 5| Step: 10
Training loss: 0.47349033375654953
Validation loss: 2.6964360374770853

Epoch: 371| Step: 0
Training loss: 0.4663263926679172
Validation loss: 2.694317432808882

Epoch: 5| Step: 1
Training loss: 0.6595655654045074
Validation loss: 2.739015210027872

Epoch: 5| Step: 2
Training loss: 0.6737901538709778
Validation loss: 2.712487593028387

Epoch: 5| Step: 3
Training loss: 0.8804983003763478
Validation loss: 2.7278869103272205

Epoch: 5| Step: 4
Training loss: 0.34750064839501577
Validation loss: 2.7005708847860643

Epoch: 5| Step: 5
Training loss: 0.5791762048178327
Validation loss: 2.6951261135225515

Epoch: 5| Step: 6
Training loss: 0.42735508863620253
Validation loss: 2.666309396847646

Epoch: 5| Step: 7
Training loss: 0.604488588485727
Validation loss: 2.6615923621881454

Epoch: 5| Step: 8
Training loss: 0.5881715527878585
Validation loss: 2.640568280616615

Epoch: 5| Step: 9
Training loss: 0.5219775949927867
Validation loss: 2.687404136731808

Epoch: 5| Step: 10
Training loss: 0.6564421372477296
Validation loss: 2.6899895418415705

Epoch: 372| Step: 0
Training loss: 0.8285987506552266
Validation loss: 2.669167449813928

Epoch: 5| Step: 1
Training loss: 0.5053747794344012
Validation loss: 2.6296324226223438

Epoch: 5| Step: 2
Training loss: 0.6339985129612713
Validation loss: 2.6126609814273474

Epoch: 5| Step: 3
Training loss: 0.34767968388133924
Validation loss: 2.6343204428657128

Epoch: 5| Step: 4
Training loss: 0.7542918508827574
Validation loss: 2.639852622610129

Epoch: 5| Step: 5
Training loss: 0.32402155520931175
Validation loss: 2.6862820161640357

Epoch: 5| Step: 6
Training loss: 0.39328232041744865
Validation loss: 2.696069853486432

Epoch: 5| Step: 7
Training loss: 0.48507519841981667
Validation loss: 2.71246483242555

Epoch: 5| Step: 8
Training loss: 0.5705255084507609
Validation loss: 2.7400758162523453

Epoch: 5| Step: 9
Training loss: 0.5362646222288442
Validation loss: 2.7066371534792335

Epoch: 5| Step: 10
Training loss: 0.8880586289820743
Validation loss: 2.7348567415226213

Epoch: 373| Step: 0
Training loss: 0.32286263854775454
Validation loss: 2.720609507787402

Epoch: 5| Step: 1
Training loss: 0.5008438261692186
Validation loss: 2.644135926666436

Epoch: 5| Step: 2
Training loss: 0.5231148593699069
Validation loss: 2.640626303846068

Epoch: 5| Step: 3
Training loss: 0.5782457689492494
Validation loss: 2.628580927232741

Epoch: 5| Step: 4
Training loss: 0.793391335922161
Validation loss: 2.6304042402467265

Epoch: 5| Step: 5
Training loss: 0.4323305166167946
Validation loss: 2.6757586868732446

Epoch: 5| Step: 6
Training loss: 0.46013822601199733
Validation loss: 2.6883195761116827

Epoch: 5| Step: 7
Training loss: 0.7426922336739867
Validation loss: 2.719426988409372

Epoch: 5| Step: 8
Training loss: 0.6422925505836716
Validation loss: 2.777236360644926

Epoch: 5| Step: 9
Training loss: 0.7940606177801999
Validation loss: 2.764032080234539

Epoch: 5| Step: 10
Training loss: 0.6301284902347704
Validation loss: 2.7827939684778586

Epoch: 374| Step: 0
Training loss: 0.7738251918561901
Validation loss: 2.774014747649806

Epoch: 5| Step: 1
Training loss: 0.7950868552524134
Validation loss: 2.71459356562663

Epoch: 5| Step: 2
Training loss: 0.7216166260955506
Validation loss: 2.753298967717515

Epoch: 5| Step: 3
Training loss: 0.39881366849248956
Validation loss: 2.705760343831288

Epoch: 5| Step: 4
Training loss: 0.4816057816004331
Validation loss: 2.6850911186160635

Epoch: 5| Step: 5
Training loss: 0.42855453245031333
Validation loss: 2.6837069517734156

Epoch: 5| Step: 6
Training loss: 0.620962093002561
Validation loss: 2.721106417404831

Epoch: 5| Step: 7
Training loss: 0.5234808548010581
Validation loss: 2.720058147665744

Epoch: 5| Step: 8
Training loss: 0.5188118966644459
Validation loss: 2.7483920153418295

Epoch: 5| Step: 9
Training loss: 0.4456152639622896
Validation loss: 2.769458673706071

Epoch: 5| Step: 10
Training loss: 0.5690611868292768
Validation loss: 2.77080063511845

Epoch: 375| Step: 0
Training loss: 0.8096036271440916
Validation loss: 2.782530604658913

Epoch: 5| Step: 1
Training loss: 0.561966271969908
Validation loss: 2.770089430267374

Epoch: 5| Step: 2
Training loss: 0.46016374397328336
Validation loss: 2.7597912987636235

Epoch: 5| Step: 3
Training loss: 0.6346507980951749
Validation loss: 2.7161827465187884

Epoch: 5| Step: 4
Training loss: 0.5915643468103534
Validation loss: 2.6760595186692715

Epoch: 5| Step: 5
Training loss: 0.5799909327061344
Validation loss: 2.6822957982765123

Epoch: 5| Step: 6
Training loss: 0.702817446944423
Validation loss: 2.6651912611434514

Epoch: 5| Step: 7
Training loss: 0.5826462690133275
Validation loss: 2.688118707209781

Epoch: 5| Step: 8
Training loss: 0.35429873061193623
Validation loss: 2.695887487428991

Epoch: 5| Step: 9
Training loss: 0.5880472981996357
Validation loss: 2.7241644479676568

Epoch: 5| Step: 10
Training loss: 0.2090084828527253
Validation loss: 2.7411350880801164

Epoch: 376| Step: 0
Training loss: 0.5736415063590822
Validation loss: 2.760835335284207

Epoch: 5| Step: 1
Training loss: 0.4657820519943013
Validation loss: 2.758049305272587

Epoch: 5| Step: 2
Training loss: 0.32892970909852653
Validation loss: 2.7113220257985846

Epoch: 5| Step: 3
Training loss: 0.7922189484322477
Validation loss: 2.692654706951302

Epoch: 5| Step: 4
Training loss: 0.47849922930596606
Validation loss: 2.657999460289834

Epoch: 5| Step: 5
Training loss: 0.5193310688962689
Validation loss: 2.653445708894783

Epoch: 5| Step: 6
Training loss: 0.6031959946508259
Validation loss: 2.6430759267710426

Epoch: 5| Step: 7
Training loss: 0.5749001644372498
Validation loss: 2.689612778899868

Epoch: 5| Step: 8
Training loss: 0.5986614376025953
Validation loss: 2.6687545598038134

Epoch: 5| Step: 9
Training loss: 0.59901893696122
Validation loss: 2.697376057056405

Epoch: 5| Step: 10
Training loss: 0.6881036709036007
Validation loss: 2.7238848301470497

Epoch: 377| Step: 0
Training loss: 0.42965484841873014
Validation loss: 2.7358759703774047

Epoch: 5| Step: 1
Training loss: 0.6329904470913097
Validation loss: 2.7488172211861728

Epoch: 5| Step: 2
Training loss: 0.5752315024112885
Validation loss: 2.7770990650708804

Epoch: 5| Step: 3
Training loss: 0.5878954155305363
Validation loss: 2.6897315328206246

Epoch: 5| Step: 4
Training loss: 0.3908538529446122
Validation loss: 2.724269956330538

Epoch: 5| Step: 5
Training loss: 0.4154315125246407
Validation loss: 2.695662525354495

Epoch: 5| Step: 6
Training loss: 0.5575768344260769
Validation loss: 2.697990896958787

Epoch: 5| Step: 7
Training loss: 0.623451412495044
Validation loss: 2.67307746702835

Epoch: 5| Step: 8
Training loss: 0.7085328148462128
Validation loss: 2.6595532275887495

Epoch: 5| Step: 9
Training loss: 0.5678425172420088
Validation loss: 2.6250167178135833

Epoch: 5| Step: 10
Training loss: 0.6960689630173265
Validation loss: 2.645293499406071

Epoch: 378| Step: 0
Training loss: 0.5245879327250739
Validation loss: 2.6612104797318814

Epoch: 5| Step: 1
Training loss: 0.15861046120492744
Validation loss: 2.679645743813517

Epoch: 5| Step: 2
Training loss: 0.6099574411116719
Validation loss: 2.6720410060159083

Epoch: 5| Step: 3
Training loss: 0.4531994791316602
Validation loss: 2.7327067370881957

Epoch: 5| Step: 4
Training loss: 0.7517077553451913
Validation loss: 2.7296033965559374

Epoch: 5| Step: 5
Training loss: 0.4893517622905339
Validation loss: 2.717844234048206

Epoch: 5| Step: 6
Training loss: 0.5465919852223651
Validation loss: 2.736906991079185

Epoch: 5| Step: 7
Training loss: 0.16817380343058722
Validation loss: 2.7343068441636693

Epoch: 5| Step: 8
Training loss: 0.33773542158258957
Validation loss: 2.7147233994322884

Epoch: 5| Step: 9
Training loss: 0.9699989389630049
Validation loss: 2.742410637681429

Epoch: 5| Step: 10
Training loss: 0.65738926498943
Validation loss: 2.703515564633652

Epoch: 379| Step: 0
Training loss: 0.41969509654722037
Validation loss: 2.688174035153625

Epoch: 5| Step: 1
Training loss: 0.5125465395195762
Validation loss: 2.708148315458368

Epoch: 5| Step: 2
Training loss: 0.5841336266900825
Validation loss: 2.7350964678749863

Epoch: 5| Step: 3
Training loss: 0.4301072411378397
Validation loss: 2.7364700265481523

Epoch: 5| Step: 4
Training loss: 0.42839177444826393
Validation loss: 2.7346293585116643

Epoch: 5| Step: 5
Training loss: 0.748548573512435
Validation loss: 2.7518987002015267

Epoch: 5| Step: 6
Training loss: 0.4695285213092849
Validation loss: 2.7270929706873575

Epoch: 5| Step: 7
Training loss: 0.6341395650612522
Validation loss: 2.7515138056094437

Epoch: 5| Step: 8
Training loss: 0.691558303923704
Validation loss: 2.7390077727868993

Epoch: 5| Step: 9
Training loss: 0.7200236852379367
Validation loss: 2.744124351712752

Epoch: 5| Step: 10
Training loss: 0.40946891959459863
Validation loss: 2.690559191401195

Epoch: 380| Step: 0
Training loss: 0.3792109100323554
Validation loss: 2.7236437677775287

Epoch: 5| Step: 1
Training loss: 0.7043714918575575
Validation loss: 2.750676002085802

Epoch: 5| Step: 2
Training loss: 0.4420602392923308
Validation loss: 2.6998637372197654

Epoch: 5| Step: 3
Training loss: 0.7173530021973179
Validation loss: 2.6975436313627594

Epoch: 5| Step: 4
Training loss: 0.5935082445367411
Validation loss: 2.7017857604789794

Epoch: 5| Step: 5
Training loss: 0.48653646395781514
Validation loss: 2.676144436508261

Epoch: 5| Step: 6
Training loss: 0.545544531788629
Validation loss: 2.6673620260169195

Epoch: 5| Step: 7
Training loss: 0.3757785027734656
Validation loss: 2.6989136899481148

Epoch: 5| Step: 8
Training loss: 0.8298245390455212
Validation loss: 2.6968815551551906

Epoch: 5| Step: 9
Training loss: 0.1915425379808463
Validation loss: 2.662447093095374

Epoch: 5| Step: 10
Training loss: 0.43001666898910135
Validation loss: 2.708905204302574

Epoch: 381| Step: 0
Training loss: 0.3681406878834843
Validation loss: 2.712607720518926

Epoch: 5| Step: 1
Training loss: 0.6999340341344059
Validation loss: 2.6963639714510625

Epoch: 5| Step: 2
Training loss: 0.7960759064506203
Validation loss: 2.7068609221877757

Epoch: 5| Step: 3
Training loss: 0.5508598379788626
Validation loss: 2.723060266148309

Epoch: 5| Step: 4
Training loss: 0.2977201203032128
Validation loss: 2.668128394258907

Epoch: 5| Step: 5
Training loss: 0.3698816883852837
Validation loss: 2.7176133192302445

Epoch: 5| Step: 6
Training loss: 0.7337974549890626
Validation loss: 2.678606729797321

Epoch: 5| Step: 7
Training loss: 0.5385088911234572
Validation loss: 2.6925656025424325

Epoch: 5| Step: 8
Training loss: 0.49260286939093473
Validation loss: 2.675568835775979

Epoch: 5| Step: 9
Training loss: 0.48602870931521136
Validation loss: 2.717599116225719

Epoch: 5| Step: 10
Training loss: 0.441770116668578
Validation loss: 2.7085207083151683

Epoch: 382| Step: 0
Training loss: 0.3724077351764508
Validation loss: 2.7079107713736863

Epoch: 5| Step: 1
Training loss: 0.6649830888447874
Validation loss: 2.7252997368343017

Epoch: 5| Step: 2
Training loss: 0.3736622911899496
Validation loss: 2.7139470522675087

Epoch: 5| Step: 3
Training loss: 0.6062537242342418
Validation loss: 2.703845992355247

Epoch: 5| Step: 4
Training loss: 0.6356632400457678
Validation loss: 2.7034040254048444

Epoch: 5| Step: 5
Training loss: 0.6933715174511711
Validation loss: 2.6451278800902793

Epoch: 5| Step: 6
Training loss: 0.5714906776899411
Validation loss: 2.6862287011343824

Epoch: 5| Step: 7
Training loss: 0.406290382432256
Validation loss: 2.7042612427072465

Epoch: 5| Step: 8
Training loss: 0.4824546463063331
Validation loss: 2.686406029519775

Epoch: 5| Step: 9
Training loss: 0.5765680018216758
Validation loss: 2.715148146662136

Epoch: 5| Step: 10
Training loss: 0.5067083238534189
Validation loss: 2.7055965649557723

Epoch: 383| Step: 0
Training loss: 0.4466246463839361
Validation loss: 2.726331388917571

Epoch: 5| Step: 1
Training loss: 0.3769239107976849
Validation loss: 2.6836001724830485

Epoch: 5| Step: 2
Training loss: 0.5621582158483887
Validation loss: 2.721291185770782

Epoch: 5| Step: 3
Training loss: 0.5197402419017831
Validation loss: 2.7034537358324857

Epoch: 5| Step: 4
Training loss: 0.6828183381204221
Validation loss: 2.6825472330755655

Epoch: 5| Step: 5
Training loss: 0.5677203226719156
Validation loss: 2.6845565821390753

Epoch: 5| Step: 6
Training loss: 0.5484773594209505
Validation loss: 2.6816225661541524

Epoch: 5| Step: 7
Training loss: 0.3330528251229183
Validation loss: 2.6525900143162096

Epoch: 5| Step: 8
Training loss: 0.6621229907410973
Validation loss: 2.693367779236689

Epoch: 5| Step: 9
Training loss: 0.582754159824968
Validation loss: 2.713127265353954

Epoch: 5| Step: 10
Training loss: 0.7032354480039276
Validation loss: 2.746168163449357

Epoch: 384| Step: 0
Training loss: 0.7664694508227282
Validation loss: 2.763253836860652

Epoch: 5| Step: 1
Training loss: 0.478732390839355
Validation loss: 2.741218524009952

Epoch: 5| Step: 2
Training loss: 0.4735575508019155
Validation loss: 2.7398680801729127

Epoch: 5| Step: 3
Training loss: 0.439485201194812
Validation loss: 2.68093206680247

Epoch: 5| Step: 4
Training loss: 0.5432037284164116
Validation loss: 2.6430928571223506

Epoch: 5| Step: 5
Training loss: 0.5403929063352593
Validation loss: 2.607106353975891

Epoch: 5| Step: 6
Training loss: 0.6166890461400585
Validation loss: 2.58332075327001

Epoch: 5| Step: 7
Training loss: 0.5679984765754338
Validation loss: 2.5924008192941503

Epoch: 5| Step: 8
Training loss: 0.8181483832063758
Validation loss: 2.6730497059446967

Epoch: 5| Step: 9
Training loss: 0.5729415599154408
Validation loss: 2.6910917496419615

Epoch: 5| Step: 10
Training loss: 0.3495744122972277
Validation loss: 2.778204409606819

Epoch: 385| Step: 0
Training loss: 0.47230284854163984
Validation loss: 2.8151395955873464

Epoch: 5| Step: 1
Training loss: 0.4138993715641387
Validation loss: 2.782815448190351

Epoch: 5| Step: 2
Training loss: 0.43683764864233293
Validation loss: 2.8052245440645147

Epoch: 5| Step: 3
Training loss: 0.4968803657385967
Validation loss: 2.7740257165138216

Epoch: 5| Step: 4
Training loss: 0.4535805286947083
Validation loss: 2.7627866467005324

Epoch: 5| Step: 5
Training loss: 0.47065576338814086
Validation loss: 2.691526440671784

Epoch: 5| Step: 6
Training loss: 0.604485309912978
Validation loss: 2.6433600959415644

Epoch: 5| Step: 7
Training loss: 0.720031921950638
Validation loss: 2.650718408319056

Epoch: 5| Step: 8
Training loss: 0.6731785836316821
Validation loss: 2.6189548305129935

Epoch: 5| Step: 9
Training loss: 0.9234249210953224
Validation loss: 2.6732167533810975

Epoch: 5| Step: 10
Training loss: 0.34137229706955835
Validation loss: 2.6513310459903554

Epoch: 386| Step: 0
Training loss: 0.2858406762833326
Validation loss: 2.710717160391862

Epoch: 5| Step: 1
Training loss: 0.5019655040594934
Validation loss: 2.756166742521274

Epoch: 5| Step: 2
Training loss: 0.5238569770849358
Validation loss: 2.736818862338291

Epoch: 5| Step: 3
Training loss: 0.47862268923931167
Validation loss: 2.7605405157859835

Epoch: 5| Step: 4
Training loss: 0.7680761842293208
Validation loss: 2.7679534656894935

Epoch: 5| Step: 5
Training loss: 0.4943006203709853
Validation loss: 2.7521620321889446

Epoch: 5| Step: 6
Training loss: 0.6611803677245705
Validation loss: 2.693839288722147

Epoch: 5| Step: 7
Training loss: 0.5346892052182374
Validation loss: 2.652897735980514

Epoch: 5| Step: 8
Training loss: 0.5151012534999981
Validation loss: 2.659589073738648

Epoch: 5| Step: 9
Training loss: 0.7537290532885005
Validation loss: 2.5822738353049384

Epoch: 5| Step: 10
Training loss: 0.6301536983000389
Validation loss: 2.603560941740714

Epoch: 387| Step: 0
Training loss: 0.5401621673056831
Validation loss: 2.5886070550389015

Epoch: 5| Step: 1
Training loss: 0.6489749657309419
Validation loss: 2.603086786310094

Epoch: 5| Step: 2
Training loss: 0.5305751272517285
Validation loss: 2.6227541172448037

Epoch: 5| Step: 3
Training loss: 0.7090404477815571
Validation loss: 2.686230655671652

Epoch: 5| Step: 4
Training loss: 0.5584379926016524
Validation loss: 2.689070490505332

Epoch: 5| Step: 5
Training loss: 0.724885502357136
Validation loss: 2.7112174839191074

Epoch: 5| Step: 6
Training loss: 0.5575764335530771
Validation loss: 2.7143217710927723

Epoch: 5| Step: 7
Training loss: 0.5958347112688612
Validation loss: 2.7400097441247393

Epoch: 5| Step: 8
Training loss: 0.3734691287257359
Validation loss: 2.726622426887401

Epoch: 5| Step: 9
Training loss: 0.4478051874877436
Validation loss: 2.7264523037132213

Epoch: 5| Step: 10
Training loss: 0.36425151257014354
Validation loss: 2.697331023396338

Epoch: 388| Step: 0
Training loss: 0.4513903662665554
Validation loss: 2.6885330321029506

Epoch: 5| Step: 1
Training loss: 0.6724415320112356
Validation loss: 2.6936190351938216

Epoch: 5| Step: 2
Training loss: 0.6457359614852943
Validation loss: 2.688662253587559

Epoch: 5| Step: 3
Training loss: 0.5100671453779756
Validation loss: 2.6513858063057922

Epoch: 5| Step: 4
Training loss: 0.5345732025748511
Validation loss: 2.674758797463494

Epoch: 5| Step: 5
Training loss: 0.5636470807729733
Validation loss: 2.6498343492364

Epoch: 5| Step: 6
Training loss: 0.5706013248625442
Validation loss: 2.687340054590013

Epoch: 5| Step: 7
Training loss: 0.4972920550853724
Validation loss: 2.660040880808622

Epoch: 5| Step: 8
Training loss: 0.5278508891390219
Validation loss: 2.6733128712712633

Epoch: 5| Step: 9
Training loss: 0.5215194061742937
Validation loss: 2.6848428004690916

Epoch: 5| Step: 10
Training loss: 0.42540742054579755
Validation loss: 2.7055036142125024

Epoch: 389| Step: 0
Training loss: 0.40988039095079765
Validation loss: 2.690330230385476

Epoch: 5| Step: 1
Training loss: 0.7272699664887133
Validation loss: 2.7364839062987594

Epoch: 5| Step: 2
Training loss: 0.6064526347088404
Validation loss: 2.731870599783048

Epoch: 5| Step: 3
Training loss: 0.6049259090375292
Validation loss: 2.732438059422471

Epoch: 5| Step: 4
Training loss: 0.6560859020878489
Validation loss: 2.6830412232640812

Epoch: 5| Step: 5
Training loss: 0.4769552207357116
Validation loss: 2.668415192997359

Epoch: 5| Step: 6
Training loss: 0.41991106950918616
Validation loss: 2.636291585006394

Epoch: 5| Step: 7
Training loss: 0.4555087855493614
Validation loss: 2.67142022961799

Epoch: 5| Step: 8
Training loss: 0.4165175906367246
Validation loss: 2.6247985365047772

Epoch: 5| Step: 9
Training loss: 0.6377590083372414
Validation loss: 2.6657963682983192

Epoch: 5| Step: 10
Training loss: 0.40765223222231567
Validation loss: 2.689686790071454

Epoch: 390| Step: 0
Training loss: 0.32370947860401916
Validation loss: 2.6980234906454466

Epoch: 5| Step: 1
Training loss: 0.3868673019999099
Validation loss: 2.7413408489082176

Epoch: 5| Step: 2
Training loss: 0.5283190432831191
Validation loss: 2.7274001318372765

Epoch: 5| Step: 3
Training loss: 0.5324623075765228
Validation loss: 2.7322122860450433

Epoch: 5| Step: 4
Training loss: 0.4048282246058574
Validation loss: 2.705132319486978

Epoch: 5| Step: 5
Training loss: 0.5326530217872701
Validation loss: 2.6994171584908115

Epoch: 5| Step: 6
Training loss: 0.6082560462933366
Validation loss: 2.647977331570012

Epoch: 5| Step: 7
Training loss: 0.7713552632518309
Validation loss: 2.6762536657239804

Epoch: 5| Step: 8
Training loss: 0.6869628932279636
Validation loss: 2.6467366115958932

Epoch: 5| Step: 9
Training loss: 0.4932643372974664
Validation loss: 2.6632408294600705

Epoch: 5| Step: 10
Training loss: 0.4388730607702947
Validation loss: 2.6491871862116123

Epoch: 391| Step: 0
Training loss: 0.4312742240294214
Validation loss: 2.660920929403891

Epoch: 5| Step: 1
Training loss: 0.4850388715101101
Validation loss: 2.6923731973408027

Epoch: 5| Step: 2
Training loss: 0.6075248508315517
Validation loss: 2.6836484652802683

Epoch: 5| Step: 3
Training loss: 0.44240627268716837
Validation loss: 2.716704386737326

Epoch: 5| Step: 4
Training loss: 0.4717120362872063
Validation loss: 2.713689588931249

Epoch: 5| Step: 5
Training loss: 0.4630696236300215
Validation loss: 2.7683046787304098

Epoch: 5| Step: 6
Training loss: 0.596737373423027
Validation loss: 2.681629444590719

Epoch: 5| Step: 7
Training loss: 0.6386027634117342
Validation loss: 2.695090590929657

Epoch: 5| Step: 8
Training loss: 0.5560688227366607
Validation loss: 2.671518727706989

Epoch: 5| Step: 9
Training loss: 0.4253307198763819
Validation loss: 2.6119409287077593

Epoch: 5| Step: 10
Training loss: 0.7180117256992237
Validation loss: 2.579767636977714

Epoch: 392| Step: 0
Training loss: 0.629220114157756
Validation loss: 2.6227243973657477

Epoch: 5| Step: 1
Training loss: 0.6254979057673364
Validation loss: 2.599719751011387

Epoch: 5| Step: 2
Training loss: 0.39442925976164056
Validation loss: 2.6477042753245366

Epoch: 5| Step: 3
Training loss: 0.5372094910687895
Validation loss: 2.704971201310077

Epoch: 5| Step: 4
Training loss: 0.4881652694287963
Validation loss: 2.7188663610994133

Epoch: 5| Step: 5
Training loss: 0.6103589110885743
Validation loss: 2.7539434480071248

Epoch: 5| Step: 6
Training loss: 0.4708873815516249
Validation loss: 2.7166450705601903

Epoch: 5| Step: 7
Training loss: 0.5518138215661305
Validation loss: 2.696197523305747

Epoch: 5| Step: 8
Training loss: 0.9015452497342662
Validation loss: 2.7132684584551066

Epoch: 5| Step: 9
Training loss: 0.3775696135748913
Validation loss: 2.751902590517593

Epoch: 5| Step: 10
Training loss: 0.31007633909372895
Validation loss: 2.7465741099982846

Epoch: 393| Step: 0
Training loss: 0.5240237810074757
Validation loss: 2.718261814476441

Epoch: 5| Step: 1
Training loss: 0.4922647869646028
Validation loss: 2.747562387108159

Epoch: 5| Step: 2
Training loss: 0.4946670743444893
Validation loss: 2.747204545548829

Epoch: 5| Step: 3
Training loss: 0.6631314651073431
Validation loss: 2.7324976369739886

Epoch: 5| Step: 4
Training loss: 0.35226241481906273
Validation loss: 2.7665501910155794

Epoch: 5| Step: 5
Training loss: 0.312167133434481
Validation loss: 2.7677680402189613

Epoch: 5| Step: 6
Training loss: 0.5044013260183368
Validation loss: 2.755735535358579

Epoch: 5| Step: 7
Training loss: 0.659628617745737
Validation loss: 2.751390901533526

Epoch: 5| Step: 8
Training loss: 0.45755491659307296
Validation loss: 2.71147156411505

Epoch: 5| Step: 9
Training loss: 0.5172091338366759
Validation loss: 2.7639394881818506

Epoch: 5| Step: 10
Training loss: 0.6745442883095385
Validation loss: 2.7248724088426335

Epoch: 394| Step: 0
Training loss: 0.44594879868541576
Validation loss: 2.7281489186939916

Epoch: 5| Step: 1
Training loss: 0.6302416348656888
Validation loss: 2.7030306212862554

Epoch: 5| Step: 2
Training loss: 0.5221691992684386
Validation loss: 2.6959982721431466

Epoch: 5| Step: 3
Training loss: 0.5192037711908778
Validation loss: 2.708287847498235

Epoch: 5| Step: 4
Training loss: 0.496791709060793
Validation loss: 2.6935509312095562

Epoch: 5| Step: 5
Training loss: 0.46624403901163114
Validation loss: 2.653398896325238

Epoch: 5| Step: 6
Training loss: 0.2765018148707589
Validation loss: 2.7098899614875953

Epoch: 5| Step: 7
Training loss: 0.41349944932940164
Validation loss: 2.713179174019093

Epoch: 5| Step: 8
Training loss: 0.47892978417474735
Validation loss: 2.70471667302691

Epoch: 5| Step: 9
Training loss: 0.6576214945702806
Validation loss: 2.7424239727539566

Epoch: 5| Step: 10
Training loss: 0.5284735268843938
Validation loss: 2.757958668902133

Epoch: 395| Step: 0
Training loss: 0.39244863167916794
Validation loss: 2.7569476490149016

Epoch: 5| Step: 1
Training loss: 0.5207948734070678
Validation loss: 2.781384403879804

Epoch: 5| Step: 2
Training loss: 0.550026884288897
Validation loss: 2.7519708983920297

Epoch: 5| Step: 3
Training loss: 0.469583691859454
Validation loss: 2.740729437341021

Epoch: 5| Step: 4
Training loss: 0.5273788723022477
Validation loss: 2.682296639826213

Epoch: 5| Step: 5
Training loss: 0.46388487129635364
Validation loss: 2.6936944980621824

Epoch: 5| Step: 6
Training loss: 0.7134297879537851
Validation loss: 2.6845962909376233

Epoch: 5| Step: 7
Training loss: 0.49549389414773587
Validation loss: 2.667487549438138

Epoch: 5| Step: 8
Training loss: 0.5710745645162786
Validation loss: 2.6720279557951225

Epoch: 5| Step: 9
Training loss: 0.3425579861122735
Validation loss: 2.7010102448527826

Epoch: 5| Step: 10
Training loss: 0.3729812005038059
Validation loss: 2.7170516930721296

Epoch: 396| Step: 0
Training loss: 0.39069629018656243
Validation loss: 2.705289639880032

Epoch: 5| Step: 1
Training loss: 0.6314321698875015
Validation loss: 2.6723518620085676

Epoch: 5| Step: 2
Training loss: 0.49117509472257226
Validation loss: 2.7218452573771486

Epoch: 5| Step: 3
Training loss: 0.7208074892148241
Validation loss: 2.6802190629336478

Epoch: 5| Step: 4
Training loss: 0.47654294145816123
Validation loss: 2.683576948107892

Epoch: 5| Step: 5
Training loss: 0.44829648754859264
Validation loss: 2.688628539030952

Epoch: 5| Step: 6
Training loss: 0.3730389259649862
Validation loss: 2.6430601714079986

Epoch: 5| Step: 7
Training loss: 0.47358863860530676
Validation loss: 2.6403108523888608

Epoch: 5| Step: 8
Training loss: 0.4882198142502986
Validation loss: 2.658717262944393

Epoch: 5| Step: 9
Training loss: 0.5113728934230415
Validation loss: 2.6542865225650494

Epoch: 5| Step: 10
Training loss: 0.34068385236988685
Validation loss: 2.701065478622459

Epoch: 397| Step: 0
Training loss: 0.4813647405897606
Validation loss: 2.7021939207383143

Epoch: 5| Step: 1
Training loss: 0.49017260644853344
Validation loss: 2.722167971104411

Epoch: 5| Step: 2
Training loss: 0.6892119896418162
Validation loss: 2.6846328345074904

Epoch: 5| Step: 3
Training loss: 0.2886197978782131
Validation loss: 2.716353138186913

Epoch: 5| Step: 4
Training loss: 0.49629380104898363
Validation loss: 2.6855620980674964

Epoch: 5| Step: 5
Training loss: 0.345845478727412
Validation loss: 2.6568219721793103

Epoch: 5| Step: 6
Training loss: 0.6411619262369679
Validation loss: 2.694243094012488

Epoch: 5| Step: 7
Training loss: 0.581717822791136
Validation loss: 2.6705820029835876

Epoch: 5| Step: 8
Training loss: 0.40689413649739875
Validation loss: 2.696092500515585

Epoch: 5| Step: 9
Training loss: 0.47653201271469897
Validation loss: 2.6585579590299675

Epoch: 5| Step: 10
Training loss: 0.48268707028796737
Validation loss: 2.7255380030719847

Epoch: 398| Step: 0
Training loss: 0.513648203025132
Validation loss: 2.7344564793132875

Epoch: 5| Step: 1
Training loss: 0.4887980358489355
Validation loss: 2.747770470625826

Epoch: 5| Step: 2
Training loss: 0.5147797563575534
Validation loss: 2.73437340802265

Epoch: 5| Step: 3
Training loss: 0.5737787494229927
Validation loss: 2.7376355454414063

Epoch: 5| Step: 4
Training loss: 0.33742965830583116
Validation loss: 2.724920109426986

Epoch: 5| Step: 5
Training loss: 0.5455287439009373
Validation loss: 2.7646799722552005

Epoch: 5| Step: 6
Training loss: 0.5851762531360483
Validation loss: 2.70874881412976

Epoch: 5| Step: 7
Training loss: 0.40014681952824965
Validation loss: 2.6911406672421085

Epoch: 5| Step: 8
Training loss: 0.2754308116621016
Validation loss: 2.723436224654525

Epoch: 5| Step: 9
Training loss: 0.6444233659561869
Validation loss: 2.6793374400642884

Epoch: 5| Step: 10
Training loss: 0.5072408833499957
Validation loss: 2.6860245329123065

Epoch: 399| Step: 0
Training loss: 0.3409915919973304
Validation loss: 2.7005315902985725

Epoch: 5| Step: 1
Training loss: 0.7332522555166021
Validation loss: 2.705329597298759

Epoch: 5| Step: 2
Training loss: 0.46123012047600426
Validation loss: 2.7057018489268514

Epoch: 5| Step: 3
Training loss: 0.5524507205873158
Validation loss: 2.714932375358633

Epoch: 5| Step: 4
Training loss: 0.3261389116088617
Validation loss: 2.6784028936943924

Epoch: 5| Step: 5
Training loss: 0.6111081248509048
Validation loss: 2.6898137821258463

Epoch: 5| Step: 6
Training loss: 0.4209783526889852
Validation loss: 2.703923160853166

Epoch: 5| Step: 7
Training loss: 0.4023887646131844
Validation loss: 2.6496890725553603

Epoch: 5| Step: 8
Training loss: 0.3937265101495458
Validation loss: 2.6700136755663393

Epoch: 5| Step: 9
Training loss: 0.7282703385582253
Validation loss: 2.679230153643106

Epoch: 5| Step: 10
Training loss: 0.444747164403615
Validation loss: 2.684054702524477

Epoch: 400| Step: 0
Training loss: 0.4752320808080595
Validation loss: 2.7003185482712575

Epoch: 5| Step: 1
Training loss: 0.4361534513517784
Validation loss: 2.7195290201522675

Epoch: 5| Step: 2
Training loss: 0.3770673904772043
Validation loss: 2.766466266205455

Epoch: 5| Step: 3
Training loss: 0.44062007671338216
Validation loss: 2.745390728331858

Epoch: 5| Step: 4
Training loss: 0.3388518514103582
Validation loss: 2.770155145877421

Epoch: 5| Step: 5
Training loss: 0.6572713624102335
Validation loss: 2.737451610548626

Epoch: 5| Step: 6
Training loss: 0.4922462004519281
Validation loss: 2.7030016560189423

Epoch: 5| Step: 7
Training loss: 0.4410287035750513
Validation loss: 2.73181002225601

Epoch: 5| Step: 8
Training loss: 0.40204657533200155
Validation loss: 2.705605581659871

Epoch: 5| Step: 9
Training loss: 0.6809638743656454
Validation loss: 2.7017415940635288

Epoch: 5| Step: 10
Training loss: 0.49749388568801417
Validation loss: 2.671559794294555

Epoch: 401| Step: 0
Training loss: 0.24831823839296846
Validation loss: 2.6435018267358363

Epoch: 5| Step: 1
Training loss: 0.5534798545289887
Validation loss: 2.646021365291915

Epoch: 5| Step: 2
Training loss: 0.6370174900690001
Validation loss: 2.6911423295675236

Epoch: 5| Step: 3
Training loss: 0.5859168494082341
Validation loss: 2.6899268045770084

Epoch: 5| Step: 4
Training loss: 0.4388162703064841
Validation loss: 2.725911168511509

Epoch: 5| Step: 5
Training loss: 0.3655639833905129
Validation loss: 2.729509687311656

Epoch: 5| Step: 6
Training loss: 0.5689027423954814
Validation loss: 2.736129721812193

Epoch: 5| Step: 7
Training loss: 0.28494920137748314
Validation loss: 2.737701374745437

Epoch: 5| Step: 8
Training loss: 0.6268832444079565
Validation loss: 2.7818852512946326

Epoch: 5| Step: 9
Training loss: 0.3335680458118166
Validation loss: 2.7473631344783485

Epoch: 5| Step: 10
Training loss: 0.46053446913973306
Validation loss: 2.7243547782629918

Epoch: 402| Step: 0
Training loss: 0.4757084933369748
Validation loss: 2.781915214343141

Epoch: 5| Step: 1
Training loss: 0.4545320172924648
Validation loss: 2.740171467543405

Epoch: 5| Step: 2
Training loss: 0.5402644757913561
Validation loss: 2.7230025910192883

Epoch: 5| Step: 3
Training loss: 0.5375701592366197
Validation loss: 2.70375499915331

Epoch: 5| Step: 4
Training loss: 0.3964289922509482
Validation loss: 2.7187664506259184

Epoch: 5| Step: 5
Training loss: 0.5946585580315028
Validation loss: 2.717710864772913

Epoch: 5| Step: 6
Training loss: 0.4253587288716551
Validation loss: 2.72069912034377

Epoch: 5| Step: 7
Training loss: 0.31269893274826577
Validation loss: 2.729316529461059

Epoch: 5| Step: 8
Training loss: 0.3057796515655454
Validation loss: 2.7085129270492274

Epoch: 5| Step: 9
Training loss: 0.46180144665100353
Validation loss: 2.734407158119031

Epoch: 5| Step: 10
Training loss: 0.5539324282121642
Validation loss: 2.7241244214389826

Epoch: 403| Step: 0
Training loss: 0.49556129897654405
Validation loss: 2.700473564073555

Epoch: 5| Step: 1
Training loss: 0.4216940279735641
Validation loss: 2.6971825920909485

Epoch: 5| Step: 2
Training loss: 0.39179099583422144
Validation loss: 2.728338676455323

Epoch: 5| Step: 3
Training loss: 0.49680478661553235
Validation loss: 2.774113771751506

Epoch: 5| Step: 4
Training loss: 0.2998342219911722
Validation loss: 2.7473479074251035

Epoch: 5| Step: 5
Training loss: 0.23792693106933957
Validation loss: 2.7323052223531126

Epoch: 5| Step: 6
Training loss: 0.4507945741373453
Validation loss: 2.72563269349517

Epoch: 5| Step: 7
Training loss: 0.5127421039845634
Validation loss: 2.7393472520581965

Epoch: 5| Step: 8
Training loss: 0.49811661175948685
Validation loss: 2.744875964025148

Epoch: 5| Step: 9
Training loss: 0.5783506932341929
Validation loss: 2.729795648975566

Epoch: 5| Step: 10
Training loss: 0.5548919515854102
Validation loss: 2.7148906239532145

Epoch: 404| Step: 0
Training loss: 0.2908172315199917
Validation loss: 2.7221809532944397

Epoch: 5| Step: 1
Training loss: 0.49882109061279656
Validation loss: 2.7383555756989755

Epoch: 5| Step: 2
Training loss: 0.30063345609735653
Validation loss: 2.7294821320078735

Epoch: 5| Step: 3
Training loss: 0.5296441096985645
Validation loss: 2.7309660069348514

Epoch: 5| Step: 4
Training loss: 0.34591249279068664
Validation loss: 2.7290083660728475

Epoch: 5| Step: 5
Training loss: 0.19518918913160144
Validation loss: 2.7838976716104815

Epoch: 5| Step: 6
Training loss: 0.6188240565669635
Validation loss: 2.755538740727289

Epoch: 5| Step: 7
Training loss: 0.45091198788893694
Validation loss: 2.759946883833204

Epoch: 5| Step: 8
Training loss: 0.3562343443391958
Validation loss: 2.712481750257523

Epoch: 5| Step: 9
Training loss: 0.5806431442891402
Validation loss: 2.7126590692514574

Epoch: 5| Step: 10
Training loss: 0.5105240832074032
Validation loss: 2.7004991474472084

Epoch: 405| Step: 0
Training loss: 0.7480300622549674
Validation loss: 2.7090751187435202

Epoch: 5| Step: 1
Training loss: 0.42037618147575967
Validation loss: 2.70341432962345

Epoch: 5| Step: 2
Training loss: 0.4280065254233156
Validation loss: 2.7000730633012657

Epoch: 5| Step: 3
Training loss: 0.31928796437007984
Validation loss: 2.6846349955167534

Epoch: 5| Step: 4
Training loss: 0.18043445740246328
Validation loss: 2.676672666057662

Epoch: 5| Step: 5
Training loss: 0.5878341749089901
Validation loss: 2.672969586949222

Epoch: 5| Step: 6
Training loss: 0.4501474317794547
Validation loss: 2.695694050675526

Epoch: 5| Step: 7
Training loss: 0.2606499326567176
Validation loss: 2.6797251422914217

Epoch: 5| Step: 8
Training loss: 0.5937154659467736
Validation loss: 2.6883236633323793

Epoch: 5| Step: 9
Training loss: 0.38025578329038506
Validation loss: 2.7129718754736722

Epoch: 5| Step: 10
Training loss: 0.1490811085132063
Validation loss: 2.6999758110497245

Epoch: 406| Step: 0
Training loss: 0.4665456758341477
Validation loss: 2.7496720288119367

Epoch: 5| Step: 1
Training loss: 0.40665664861148443
Validation loss: 2.7582903804718053

Epoch: 5| Step: 2
Training loss: 0.5919418912669712
Validation loss: 2.7373301542272523

Epoch: 5| Step: 3
Training loss: 0.2842789964749076
Validation loss: 2.7428143012828006

Epoch: 5| Step: 4
Training loss: 0.45808351456391805
Validation loss: 2.7067932309321767

Epoch: 5| Step: 5
Training loss: 0.5402744601059846
Validation loss: 2.7226457615484954

Epoch: 5| Step: 6
Training loss: 0.5373040418714599
Validation loss: 2.744964835274938

Epoch: 5| Step: 7
Training loss: 0.49925302796742155
Validation loss: 2.683140058161163

Epoch: 5| Step: 8
Training loss: 0.4325487758717486
Validation loss: 2.714909328360063

Epoch: 5| Step: 9
Training loss: 0.34298297531066857
Validation loss: 2.7014233621708206

Epoch: 5| Step: 10
Training loss: 0.24717720644481045
Validation loss: 2.7057398271270223

Epoch: 407| Step: 0
Training loss: 0.4490043294258219
Validation loss: 2.710366020313671

Epoch: 5| Step: 1
Training loss: 0.4994010914657331
Validation loss: 2.687808610272528

Epoch: 5| Step: 2
Training loss: 0.2373179993212037
Validation loss: 2.737639665789101

Epoch: 5| Step: 3
Training loss: 0.4672511775020827
Validation loss: 2.7222453406516327

Epoch: 5| Step: 4
Training loss: 0.3016294681725589
Validation loss: 2.7212915060737948

Epoch: 5| Step: 5
Training loss: 0.49295597029623595
Validation loss: 2.7344481549533928

Epoch: 5| Step: 6
Training loss: 0.31277999255525685
Validation loss: 2.765912016453423

Epoch: 5| Step: 7
Training loss: 0.5817988911154923
Validation loss: 2.7655648003119904

Epoch: 5| Step: 8
Training loss: 0.4604603188593609
Validation loss: 2.736334529577987

Epoch: 5| Step: 9
Training loss: 0.44063434793823597
Validation loss: 2.700580811554144

Epoch: 5| Step: 10
Training loss: 0.6336291894749759
Validation loss: 2.665885761603002

Epoch: 408| Step: 0
Training loss: 0.6436127099608321
Validation loss: 2.7324023869516796

Epoch: 5| Step: 1
Training loss: 0.5570913798660067
Validation loss: 2.655613389960575

Epoch: 5| Step: 2
Training loss: 0.325389746656755
Validation loss: 2.6861750796438977

Epoch: 5| Step: 3
Training loss: 0.5008133888346236
Validation loss: 2.667336570774791

Epoch: 5| Step: 4
Training loss: 0.19305036880499432
Validation loss: 2.6691435980116816

Epoch: 5| Step: 5
Training loss: 0.36823719219147116
Validation loss: 2.6691298680133526

Epoch: 5| Step: 6
Training loss: 0.5069038477918859
Validation loss: 2.7023033635109375

Epoch: 5| Step: 7
Training loss: 0.5748059391030137
Validation loss: 2.7057887887801457

Epoch: 5| Step: 8
Training loss: 0.3219255560457251
Validation loss: 2.7472963681470435

Epoch: 5| Step: 9
Training loss: 0.45152825156354237
Validation loss: 2.732338626445467

Epoch: 5| Step: 10
Training loss: 0.22902447541021373
Validation loss: 2.749325590322424

Epoch: 409| Step: 0
Training loss: 0.37755631329968264
Validation loss: 2.707383987284493

Epoch: 5| Step: 1
Training loss: 0.4165722342610814
Validation loss: 2.7140114177094583

Epoch: 5| Step: 2
Training loss: 0.5048133610487463
Validation loss: 2.7330523004528984

Epoch: 5| Step: 3
Training loss: 0.38912925453935937
Validation loss: 2.752947863399286

Epoch: 5| Step: 4
Training loss: 0.5476832547787807
Validation loss: 2.6940546977737823

Epoch: 5| Step: 5
Training loss: 0.3408295813231942
Validation loss: 2.6977510159503506

Epoch: 5| Step: 6
Training loss: 0.6002385320970081
Validation loss: 2.6979029522828073

Epoch: 5| Step: 7
Training loss: 0.4337979772236553
Validation loss: 2.8115242791219908

Epoch: 5| Step: 8
Training loss: 0.28997948545210983
Validation loss: 2.7367473280982217

Epoch: 5| Step: 9
Training loss: 0.3948427424778404
Validation loss: 2.706583526178929

Epoch: 5| Step: 10
Training loss: 0.5410048280595697
Validation loss: 2.7485266791221767

Epoch: 410| Step: 0
Training loss: 0.4899816127412033
Validation loss: 2.732176657073019

Epoch: 5| Step: 1
Training loss: 0.3375105842943981
Validation loss: 2.751479169629564

Epoch: 5| Step: 2
Training loss: 0.3911604263522786
Validation loss: 2.7000544498107892

Epoch: 5| Step: 3
Training loss: 0.4049659757686165
Validation loss: 2.6902816468202073

Epoch: 5| Step: 4
Training loss: 0.5291238762482899
Validation loss: 2.7265048378381844

Epoch: 5| Step: 5
Training loss: 0.35519769835376136
Validation loss: 2.730217552304865

Epoch: 5| Step: 6
Training loss: 0.49724171199671263
Validation loss: 2.726171746017319

Epoch: 5| Step: 7
Training loss: 0.3415111328267977
Validation loss: 2.7437787745160085

Epoch: 5| Step: 8
Training loss: 0.45012045215130236
Validation loss: 2.718585168586982

Epoch: 5| Step: 9
Training loss: 0.501696242567442
Validation loss: 2.779195085613191

Epoch: 5| Step: 10
Training loss: 0.4084568603993906
Validation loss: 2.7554432851571833

Epoch: 411| Step: 0
Training loss: 0.454723334457046
Validation loss: 2.7707219511250565

Epoch: 5| Step: 1
Training loss: 0.281648909278964
Validation loss: 2.7948713561110883

Epoch: 5| Step: 2
Training loss: 0.3482390244747338
Validation loss: 2.746739969417332

Epoch: 5| Step: 3
Training loss: 0.4142260318491609
Validation loss: 2.730039454337352

Epoch: 5| Step: 4
Training loss: 0.4658014065726579
Validation loss: 2.7053548935824585

Epoch: 5| Step: 5
Training loss: 0.5155554059775637
Validation loss: 2.713746049209958

Epoch: 5| Step: 6
Training loss: 0.34931505057413365
Validation loss: 2.6942383706364508

Epoch: 5| Step: 7
Training loss: 0.5784076051493668
Validation loss: 2.7189069784406525

Epoch: 5| Step: 8
Training loss: 0.5450304531635981
Validation loss: 2.70936559184478

Epoch: 5| Step: 9
Training loss: 0.3548711007452562
Validation loss: 2.6980581928634484

Epoch: 5| Step: 10
Training loss: 0.3748574979549948
Validation loss: 2.7378905018129864

Epoch: 412| Step: 0
Training loss: 0.6795709663550669
Validation loss: 2.7333871208359097

Epoch: 5| Step: 1
Training loss: 0.4688760429041224
Validation loss: 2.707547966712263

Epoch: 5| Step: 2
Training loss: 0.3472803848614194
Validation loss: 2.7284916939611836

Epoch: 5| Step: 3
Training loss: 0.401583685112017
Validation loss: 2.7023512272028025

Epoch: 5| Step: 4
Training loss: 0.5342722364518673
Validation loss: 2.690858629581142

Epoch: 5| Step: 5
Training loss: 0.36453214240588305
Validation loss: 2.7414015674488827

Epoch: 5| Step: 6
Training loss: 0.18873335584934903
Validation loss: 2.729164302636721

Epoch: 5| Step: 7
Training loss: 0.3697034188758672
Validation loss: 2.744485316872344

Epoch: 5| Step: 8
Training loss: 0.47446957636778
Validation loss: 2.7210609516330537

Epoch: 5| Step: 9
Training loss: 0.48487640393833986
Validation loss: 2.7386962291568473

Epoch: 5| Step: 10
Training loss: 0.3194620309298701
Validation loss: 2.7300909334535257

Epoch: 413| Step: 0
Training loss: 0.516606927566216
Validation loss: 2.7633084601369617

Epoch: 5| Step: 1
Training loss: 0.30618410082657155
Validation loss: 2.711642924013603

Epoch: 5| Step: 2
Training loss: 0.5533041561526995
Validation loss: 2.7085893871217186

Epoch: 5| Step: 3
Training loss: 0.3154127984500535
Validation loss: 2.7059463988107533

Epoch: 5| Step: 4
Training loss: 0.47717218015969487
Validation loss: 2.7378962276249146

Epoch: 5| Step: 5
Training loss: 0.37966681373036265
Validation loss: 2.708794018079767

Epoch: 5| Step: 6
Training loss: 0.46732724756549204
Validation loss: 2.6909689211067085

Epoch: 5| Step: 7
Training loss: 0.3177303934516124
Validation loss: 2.697344397899234

Epoch: 5| Step: 8
Training loss: 0.399307908405983
Validation loss: 2.6930198140981805

Epoch: 5| Step: 9
Training loss: 0.4263662466684499
Validation loss: 2.701947444809043

Epoch: 5| Step: 10
Training loss: 0.5473976362678413
Validation loss: 2.685408962314472

Epoch: 414| Step: 0
Training loss: 0.4109612149840153
Validation loss: 2.713419549635742

Epoch: 5| Step: 1
Training loss: 0.49669973653214566
Validation loss: 2.7230843880196636

Epoch: 5| Step: 2
Training loss: 0.5721714606294923
Validation loss: 2.73201617104438

Epoch: 5| Step: 3
Training loss: 0.39421867981440234
Validation loss: 2.743499039279362

Epoch: 5| Step: 4
Training loss: 0.47301455386536406
Validation loss: 2.7571378403983218

Epoch: 5| Step: 5
Training loss: 0.501401427362584
Validation loss: 2.7446196473915054

Epoch: 5| Step: 6
Training loss: 0.20509273840291337
Validation loss: 2.7273356819391275

Epoch: 5| Step: 7
Training loss: 0.3244521094053022
Validation loss: 2.7666995153010308

Epoch: 5| Step: 8
Training loss: 0.4685055413177985
Validation loss: 2.750476544165424

Epoch: 5| Step: 9
Training loss: 0.3867540054434436
Validation loss: 2.747897459323434

Epoch: 5| Step: 10
Training loss: 0.3695005246831036
Validation loss: 2.7372498403258114

Epoch: 415| Step: 0
Training loss: 0.44283465284931733
Validation loss: 2.7567506419331376

Epoch: 5| Step: 1
Training loss: 0.4363487798844431
Validation loss: 2.7644660810658923

Epoch: 5| Step: 2
Training loss: 0.2998806735985223
Validation loss: 2.7378492222405044

Epoch: 5| Step: 3
Training loss: 0.3754721490497378
Validation loss: 2.754241191760547

Epoch: 5| Step: 4
Training loss: 0.3374666740600195
Validation loss: 2.7507348929149247

Epoch: 5| Step: 5
Training loss: 0.5930025767050048
Validation loss: 2.7545418117563063

Epoch: 5| Step: 6
Training loss: 0.39359837897691863
Validation loss: 2.7638528869293677

Epoch: 5| Step: 7
Training loss: 0.390942673256338
Validation loss: 2.734944639625547

Epoch: 5| Step: 8
Training loss: 0.24134085704675395
Validation loss: 2.7381182694019026

Epoch: 5| Step: 9
Training loss: 0.3150618212071488
Validation loss: 2.734623680233033

Epoch: 5| Step: 10
Training loss: 0.6279873028036514
Validation loss: 2.6648893207876823

Epoch: 416| Step: 0
Training loss: 0.5587811722476705
Validation loss: 2.7338730246128113

Epoch: 5| Step: 1
Training loss: 0.1705677265853039
Validation loss: 2.718820865411445

Epoch: 5| Step: 2
Training loss: 0.46578717063869846
Validation loss: 2.7124781994118186

Epoch: 5| Step: 3
Training loss: 0.3629933518780894
Validation loss: 2.6988606676730167

Epoch: 5| Step: 4
Training loss: 0.36514305564276717
Validation loss: 2.7206787417347376

Epoch: 5| Step: 5
Training loss: 0.38466908362005037
Validation loss: 2.7188980558216245

Epoch: 5| Step: 6
Training loss: 0.39681175884490644
Validation loss: 2.7287576897051387

Epoch: 5| Step: 7
Training loss: 0.4764586788966309
Validation loss: 2.7213990711138756

Epoch: 5| Step: 8
Training loss: 0.25502182834359355
Validation loss: 2.7396216768628747

Epoch: 5| Step: 9
Training loss: 0.23189178089897072
Validation loss: 2.730171248551917

Epoch: 5| Step: 10
Training loss: 0.6634261728937841
Validation loss: 2.7333945414815335

Epoch: 417| Step: 0
Training loss: 0.5317145728508521
Validation loss: 2.7714352271270295

Epoch: 5| Step: 1
Training loss: 0.5529740962847688
Validation loss: 2.7786568303544175

Epoch: 5| Step: 2
Training loss: 0.2637875621046308
Validation loss: 2.7749306975445514

Epoch: 5| Step: 3
Training loss: 0.5249162539036233
Validation loss: 2.759983261982636

Epoch: 5| Step: 4
Training loss: 0.5342636181939233
Validation loss: 2.7784280594859165

Epoch: 5| Step: 5
Training loss: 0.1698439847072464
Validation loss: 2.75077551406529

Epoch: 5| Step: 6
Training loss: 0.2819293083602534
Validation loss: 2.7521613070156175

Epoch: 5| Step: 7
Training loss: 0.23132457883745586
Validation loss: 2.7230068587250673

Epoch: 5| Step: 8
Training loss: 0.5209266451852904
Validation loss: 2.776498758578784

Epoch: 5| Step: 9
Training loss: 0.3680582881122294
Validation loss: 2.789352639508046

Epoch: 5| Step: 10
Training loss: 0.30227833515813757
Validation loss: 2.7706411700461815

Epoch: 418| Step: 0
Training loss: 0.5319377150357546
Validation loss: 2.7761703547883183

Epoch: 5| Step: 1
Training loss: 0.3329665754185469
Validation loss: 2.7801486917336993

Epoch: 5| Step: 2
Training loss: 0.21430492456930703
Validation loss: 2.776013179999903

Epoch: 5| Step: 3
Training loss: 0.4804345560699501
Validation loss: 2.736630228435102

Epoch: 5| Step: 4
Training loss: 0.4943624458455133
Validation loss: 2.7565520197475015

Epoch: 5| Step: 5
Training loss: 0.4398197255594739
Validation loss: 2.72761980989372

Epoch: 5| Step: 6
Training loss: 0.27319925010405094
Validation loss: 2.7371826917348714

Epoch: 5| Step: 7
Training loss: 0.5708718104748449
Validation loss: 2.7547755870497515

Epoch: 5| Step: 8
Training loss: 0.3891387703833568
Validation loss: 2.734035321538605

Epoch: 5| Step: 9
Training loss: 0.15618854148482397
Validation loss: 2.6868158916357263

Epoch: 5| Step: 10
Training loss: 0.36282668849068805
Validation loss: 2.712564605469758

Epoch: 419| Step: 0
Training loss: 0.4097101055749505
Validation loss: 2.723037759615102

Epoch: 5| Step: 1
Training loss: 0.3960952164361357
Validation loss: 2.7246024836900267

Epoch: 5| Step: 2
Training loss: 0.39809107212202377
Validation loss: 2.7290846577408945

Epoch: 5| Step: 3
Training loss: 0.3285511519264854
Validation loss: 2.745594398950216

Epoch: 5| Step: 4
Training loss: 0.22672169945689255
Validation loss: 2.727358272381748

Epoch: 5| Step: 5
Training loss: 0.39837313113389156
Validation loss: 2.713319051097804

Epoch: 5| Step: 6
Training loss: 0.39293117684843276
Validation loss: 2.735519075142962

Epoch: 5| Step: 7
Training loss: 0.35724082905775123
Validation loss: 2.7403050997247598

Epoch: 5| Step: 8
Training loss: 0.45910871728823305
Validation loss: 2.745561039417778

Epoch: 5| Step: 9
Training loss: 0.5407046033433652
Validation loss: 2.739241357654155

Epoch: 5| Step: 10
Training loss: 0.44526737386036963
Validation loss: 2.738610452868482

Epoch: 420| Step: 0
Training loss: 0.4792338528039648
Validation loss: 2.7197978600917687

Epoch: 5| Step: 1
Training loss: 0.6737682592362987
Validation loss: 2.7430409973957257

Epoch: 5| Step: 2
Training loss: 0.308478780648878
Validation loss: 2.7341203918520662

Epoch: 5| Step: 3
Training loss: 0.36559773286397196
Validation loss: 2.6827359796951034

Epoch: 5| Step: 4
Training loss: 0.23275279681290334
Validation loss: 2.7056654738519597

Epoch: 5| Step: 5
Training loss: 0.5280530609703148
Validation loss: 2.7267350748888277

Epoch: 5| Step: 6
Training loss: 0.27631284631061576
Validation loss: 2.7260071028680968

Epoch: 5| Step: 7
Training loss: 0.36517023349507444
Validation loss: 2.7076075702368168

Epoch: 5| Step: 8
Training loss: 0.3932207266636533
Validation loss: 2.7406378558845588

Epoch: 5| Step: 9
Training loss: 0.2645535175664972
Validation loss: 2.738493792355301

Epoch: 5| Step: 10
Training loss: 0.3813869441427289
Validation loss: 2.7292237074269745

Epoch: 421| Step: 0
Training loss: 0.345680677902862
Validation loss: 2.7214716177915044

Epoch: 5| Step: 1
Training loss: 0.20596699407943467
Validation loss: 2.748421304893097

Epoch: 5| Step: 2
Training loss: 0.33834168200496384
Validation loss: 2.7416829763222155

Epoch: 5| Step: 3
Training loss: 0.38934765825362216
Validation loss: 2.717918796513728

Epoch: 5| Step: 4
Training loss: 0.5134847321845266
Validation loss: 2.695166662264628

Epoch: 5| Step: 5
Training loss: 0.6443180772075779
Validation loss: 2.7132075411898087

Epoch: 5| Step: 6
Training loss: 0.29988679786569084
Validation loss: 2.715784916867575

Epoch: 5| Step: 7
Training loss: 0.47677369987899004
Validation loss: 2.7244891321244555

Epoch: 5| Step: 8
Training loss: 0.30820667762787796
Validation loss: 2.723597677943396

Epoch: 5| Step: 9
Training loss: 0.301405308822341
Validation loss: 2.760555795207678

Epoch: 5| Step: 10
Training loss: 0.41200215178687005
Validation loss: 2.7522662846951262

Epoch: 422| Step: 0
Training loss: 0.523415493858411
Validation loss: 2.7808225237985478

Epoch: 5| Step: 1
Training loss: 0.22748116341883823
Validation loss: 2.7397910637113605

Epoch: 5| Step: 2
Training loss: 0.5362817109342005
Validation loss: 2.774055972388004

Epoch: 5| Step: 3
Training loss: 0.14731215872540956
Validation loss: 2.7323077688173165

Epoch: 5| Step: 4
Training loss: 0.35570164271933313
Validation loss: 2.7491737925671784

Epoch: 5| Step: 5
Training loss: 0.5708044621436197
Validation loss: 2.713697085640617

Epoch: 5| Step: 6
Training loss: 0.11790631691617101
Validation loss: 2.7036356408376117

Epoch: 5| Step: 7
Training loss: 0.2763616069324627
Validation loss: 2.684912646386919

Epoch: 5| Step: 8
Training loss: 0.2792083760081091
Validation loss: 2.6840699942283375

Epoch: 5| Step: 9
Training loss: 0.4006897901910795
Validation loss: 2.6914984798305146

Epoch: 5| Step: 10
Training loss: 0.6174315199544539
Validation loss: 2.697959131465781

Epoch: 423| Step: 0
Training loss: 0.2860471447496251
Validation loss: 2.68326347436949

Epoch: 5| Step: 1
Training loss: 0.30685005811109856
Validation loss: 2.71213060705495

Epoch: 5| Step: 2
Training loss: 0.3740459465245753
Validation loss: 2.724835626860924

Epoch: 5| Step: 3
Training loss: 0.4342500513798184
Validation loss: 2.713174684397223

Epoch: 5| Step: 4
Training loss: 0.30747408490186307
Validation loss: 2.7261867290696737

Epoch: 5| Step: 5
Training loss: 0.2859150184590141
Validation loss: 2.7441996990523996

Epoch: 5| Step: 6
Training loss: 0.5145515770579316
Validation loss: 2.7148741734493056

Epoch: 5| Step: 7
Training loss: 0.5113716112825079
Validation loss: 2.764495368627141

Epoch: 5| Step: 8
Training loss: 0.36622334777148924
Validation loss: 2.7288459890651624

Epoch: 5| Step: 9
Training loss: 0.4859869652744602
Validation loss: 2.7110466143876955

Epoch: 5| Step: 10
Training loss: 0.339834246009264
Validation loss: 2.710302458852236

Epoch: 424| Step: 0
Training loss: 0.23370415524857993
Validation loss: 2.723668041669188

Epoch: 5| Step: 1
Training loss: 0.3370327173907612
Validation loss: 2.7552827684333336

Epoch: 5| Step: 2
Training loss: 0.3220049873389342
Validation loss: 2.7553380261109632

Epoch: 5| Step: 3
Training loss: 0.43383656825184475
Validation loss: 2.778332066215075

Epoch: 5| Step: 4
Training loss: 0.4414541674236317
Validation loss: 2.7534346372827394

Epoch: 5| Step: 5
Training loss: 0.5548081871158157
Validation loss: 2.710231660628948

Epoch: 5| Step: 6
Training loss: 0.49530004852721365
Validation loss: 2.7355065568942494

Epoch: 5| Step: 7
Training loss: 0.2601890841089244
Validation loss: 2.7223096850504804

Epoch: 5| Step: 8
Training loss: 0.4919827201753159
Validation loss: 2.7355931909985456

Epoch: 5| Step: 9
Training loss: 0.2754203563900872
Validation loss: 2.73125328179595

Epoch: 5| Step: 10
Training loss: 0.45166942690021133
Validation loss: 2.7237735984383966

Epoch: 425| Step: 0
Training loss: 0.29208863620642367
Validation loss: 2.741088566587918

Epoch: 5| Step: 1
Training loss: 0.4731980678318978
Validation loss: 2.7233674138145343

Epoch: 5| Step: 2
Training loss: 0.2879419387158952
Validation loss: 2.7270674840359597

Epoch: 5| Step: 3
Training loss: 0.4539977252331852
Validation loss: 2.6890689689492304

Epoch: 5| Step: 4
Training loss: 0.5628931473007712
Validation loss: 2.715964818443496

Epoch: 5| Step: 5
Training loss: 0.22238347427159808
Validation loss: 2.7430050469133973

Epoch: 5| Step: 6
Training loss: 0.4230198690401403
Validation loss: 2.7634812385568495

Epoch: 5| Step: 7
Training loss: 0.31494173744834814
Validation loss: 2.7497876738824703

Epoch: 5| Step: 8
Training loss: 0.2994117273885368
Validation loss: 2.7226287063116636

Epoch: 5| Step: 9
Training loss: 0.48931613353705966
Validation loss: 2.753049716243968

Epoch: 5| Step: 10
Training loss: 0.417526010628184
Validation loss: 2.750899588179455

Epoch: 426| Step: 0
Training loss: 0.42804974639425214
Validation loss: 2.7114636854233707

Epoch: 5| Step: 1
Training loss: 0.48107251944657453
Validation loss: 2.703105649749049

Epoch: 5| Step: 2
Training loss: 0.39190165753020123
Validation loss: 2.7013864070551485

Epoch: 5| Step: 3
Training loss: 0.4121855534297163
Validation loss: 2.6908238549977423

Epoch: 5| Step: 4
Training loss: 0.4118260498944036
Validation loss: 2.6802369141110045

Epoch: 5| Step: 5
Training loss: 0.18260641627241628
Validation loss: 2.689514159940291

Epoch: 5| Step: 6
Training loss: 0.36771610439110985
Validation loss: 2.7235374670633035

Epoch: 5| Step: 7
Training loss: 0.4062865314197582
Validation loss: 2.727774585262565

Epoch: 5| Step: 8
Training loss: 0.32360527874548334
Validation loss: 2.7285903651592127

Epoch: 5| Step: 9
Training loss: 0.44016455813452593
Validation loss: 2.7392112965612117

Epoch: 5| Step: 10
Training loss: 0.4607147389733925
Validation loss: 2.750388165595653

Epoch: 427| Step: 0
Training loss: 0.388932548023093
Validation loss: 2.7478335834829375

Epoch: 5| Step: 1
Training loss: 0.30073494988326716
Validation loss: 2.7353029032050844

Epoch: 5| Step: 2
Training loss: 0.42214891583530395
Validation loss: 2.721722042141653

Epoch: 5| Step: 3
Training loss: 0.5159598332636692
Validation loss: 2.739010168879828

Epoch: 5| Step: 4
Training loss: 0.455906225050849
Validation loss: 2.7350863233208984

Epoch: 5| Step: 5
Training loss: 0.35120986631134826
Validation loss: 2.700316904886149

Epoch: 5| Step: 6
Training loss: 0.18432526240850758
Validation loss: 2.703272530795606

Epoch: 5| Step: 7
Training loss: 0.392866398884985
Validation loss: 2.707212996061361

Epoch: 5| Step: 8
Training loss: 0.41211695008750954
Validation loss: 2.717393498288304

Epoch: 5| Step: 9
Training loss: 0.4687468528641911
Validation loss: 2.708592590026826

Epoch: 5| Step: 10
Training loss: 0.3422723569123059
Validation loss: 2.7221651731212138

Epoch: 428| Step: 0
Training loss: 0.38887720099929557
Validation loss: 2.7673611390398904

Epoch: 5| Step: 1
Training loss: 0.4504806210279867
Validation loss: 2.724500228866259

Epoch: 5| Step: 2
Training loss: 0.2253625349791145
Validation loss: 2.7229917856818093

Epoch: 5| Step: 3
Training loss: 0.35275990762321363
Validation loss: 2.7265111921504843

Epoch: 5| Step: 4
Training loss: 0.5091774422815921
Validation loss: 2.677701454405718

Epoch: 5| Step: 5
Training loss: 0.5946682304752355
Validation loss: 2.7079521276929315

Epoch: 5| Step: 6
Training loss: 0.33149197485431625
Validation loss: 2.7034250482071096

Epoch: 5| Step: 7
Training loss: 0.4907709505979478
Validation loss: 2.6503915448726403

Epoch: 5| Step: 8
Training loss: 0.28601933855919354
Validation loss: 2.6907682318790944

Epoch: 5| Step: 9
Training loss: 0.3523105081241719
Validation loss: 2.715170965971865

Epoch: 5| Step: 10
Training loss: 0.24022697034139526
Validation loss: 2.7155482499082684

Epoch: 429| Step: 0
Training loss: 0.42233041624415646
Validation loss: 2.727450862760089

Epoch: 5| Step: 1
Training loss: 0.1968120894508041
Validation loss: 2.7087404154985735

Epoch: 5| Step: 2
Training loss: 0.3553225667327616
Validation loss: 2.707632079734376

Epoch: 5| Step: 3
Training loss: 0.3752546240707836
Validation loss: 2.7144231154502108

Epoch: 5| Step: 4
Training loss: 0.4117882548663741
Validation loss: 2.710370439864762

Epoch: 5| Step: 5
Training loss: 0.20593727527137268
Validation loss: 2.7039143670361288

Epoch: 5| Step: 6
Training loss: 0.5222346876592191
Validation loss: 2.719371331918021

Epoch: 5| Step: 7
Training loss: 0.3976623624620394
Validation loss: 2.7070006029787566

Epoch: 5| Step: 8
Training loss: 0.45753220059207694
Validation loss: 2.7042203319161944

Epoch: 5| Step: 9
Training loss: 0.3405073198842464
Validation loss: 2.723598907712301

Epoch: 5| Step: 10
Training loss: 0.42363006604976483
Validation loss: 2.7014801998051854

Epoch: 430| Step: 0
Training loss: 0.37004753000821317
Validation loss: 2.7254019334417885

Epoch: 5| Step: 1
Training loss: 0.2549886374185977
Validation loss: 2.6931100238957497

Epoch: 5| Step: 2
Training loss: 0.2385306225986693
Validation loss: 2.7138997888869048

Epoch: 5| Step: 3
Training loss: 0.43176010687572286
Validation loss: 2.691076315883138

Epoch: 5| Step: 4
Training loss: 0.1714074103317003
Validation loss: 2.718167590676736

Epoch: 5| Step: 5
Training loss: 0.3702335225160069
Validation loss: 2.7433517700762176

Epoch: 5| Step: 6
Training loss: 0.3533904133131644
Validation loss: 2.7191534802600996

Epoch: 5| Step: 7
Training loss: 0.3468403833316796
Validation loss: 2.752545793934431

Epoch: 5| Step: 8
Training loss: 0.5955336032486048
Validation loss: 2.7445146831446334

Epoch: 5| Step: 9
Training loss: 0.5760586902202302
Validation loss: 2.7453300653359194

Epoch: 5| Step: 10
Training loss: 0.33302097909801076
Validation loss: 2.7675202021088556

Epoch: 431| Step: 0
Training loss: 0.43262287075882166
Validation loss: 2.7557573041216408

Epoch: 5| Step: 1
Training loss: 0.38784798563524725
Validation loss: 2.7315801050284216

Epoch: 5| Step: 2
Training loss: 0.3307265959912615
Validation loss: 2.727529107897373

Epoch: 5| Step: 3
Training loss: 0.1806147121350735
Validation loss: 2.698092988701717

Epoch: 5| Step: 4
Training loss: 0.1967786784162292
Validation loss: 2.7257041352196016

Epoch: 5| Step: 5
Training loss: 0.3355431348883093
Validation loss: 2.702494137774609

Epoch: 5| Step: 6
Training loss: 0.49064972748371277
Validation loss: 2.705027295773022

Epoch: 5| Step: 7
Training loss: 0.3679809317222608
Validation loss: 2.7105288281299327

Epoch: 5| Step: 8
Training loss: 0.40571505832586563
Validation loss: 2.7094709772584418

Epoch: 5| Step: 9
Training loss: 0.3606635089986944
Validation loss: 2.731183960156737

Epoch: 5| Step: 10
Training loss: 0.5362448097635841
Validation loss: 2.7270233999286284

Epoch: 432| Step: 0
Training loss: 0.333443789757965
Validation loss: 2.7171387679382115

Epoch: 5| Step: 1
Training loss: 0.24677837599556182
Validation loss: 2.7308456130543086

Epoch: 5| Step: 2
Training loss: 0.399245490057643
Validation loss: 2.7631244584128227

Epoch: 5| Step: 3
Training loss: 0.30033740203375714
Validation loss: 2.7464521199301837

Epoch: 5| Step: 4
Training loss: 0.4258169806650744
Validation loss: 2.753215369925597

Epoch: 5| Step: 5
Training loss: 0.5177492542583818
Validation loss: 2.7426572311528163

Epoch: 5| Step: 6
Training loss: 0.39701238717252646
Validation loss: 2.754542965353572

Epoch: 5| Step: 7
Training loss: 0.4155922468086386
Validation loss: 2.763063833114672

Epoch: 5| Step: 8
Training loss: 0.36293043610123316
Validation loss: 2.75737402025241

Epoch: 5| Step: 9
Training loss: 0.37952863564342704
Validation loss: 2.736184588628482

Epoch: 5| Step: 10
Training loss: 0.2918378236934595
Validation loss: 2.752034546856103

Epoch: 433| Step: 0
Training loss: 0.41857741058800135
Validation loss: 2.73761098054891

Epoch: 5| Step: 1
Training loss: 0.5537089998726018
Validation loss: 2.7001913381920866

Epoch: 5| Step: 2
Training loss: 0.20712785446281237
Validation loss: 2.711365958622612

Epoch: 5| Step: 3
Training loss: 0.37370836817074576
Validation loss: 2.7177027126858433

Epoch: 5| Step: 4
Training loss: 0.41805621150096633
Validation loss: 2.7280200095272398

Epoch: 5| Step: 5
Training loss: 0.32749187605005436
Validation loss: 2.7358952668901124

Epoch: 5| Step: 6
Training loss: 0.21027519306128192
Validation loss: 2.720446543717051

Epoch: 5| Step: 7
Training loss: 0.2839115752632406
Validation loss: 2.726973110423714

Epoch: 5| Step: 8
Training loss: 0.31256903839442796
Validation loss: 2.731974856199851

Epoch: 5| Step: 9
Training loss: 0.40100998774002833
Validation loss: 2.736991715490502

Epoch: 5| Step: 10
Training loss: 0.4662267962708184
Validation loss: 2.7416392211994065

Epoch: 434| Step: 0
Training loss: 0.35425370446491217
Validation loss: 2.7330448413573847

Epoch: 5| Step: 1
Training loss: 0.3032051363934563
Validation loss: 2.7092338169357126

Epoch: 5| Step: 2
Training loss: 0.4315996452659761
Validation loss: 2.712722083600303

Epoch: 5| Step: 3
Training loss: 0.3832773383680029
Validation loss: 2.6951919602424126

Epoch: 5| Step: 4
Training loss: 0.5509188595115879
Validation loss: 2.708395278701851

Epoch: 5| Step: 5
Training loss: 0.2443443211520631
Validation loss: 2.7099057450273

Epoch: 5| Step: 6
Training loss: 0.3627964599769979
Validation loss: 2.7129994245980424

Epoch: 5| Step: 7
Training loss: 0.37323424741562594
Validation loss: 2.7071352811743163

Epoch: 5| Step: 8
Training loss: 0.2800543058048369
Validation loss: 2.7114539105380837

Epoch: 5| Step: 9
Training loss: 0.4590176671716996
Validation loss: 2.753115039167843

Epoch: 5| Step: 10
Training loss: 0.30428179604382516
Validation loss: 2.735162497945218

Epoch: 435| Step: 0
Training loss: 0.21328200665014843
Validation loss: 2.725913763740234

Epoch: 5| Step: 1
Training loss: 0.3040900976118301
Validation loss: 2.726532399725138

Epoch: 5| Step: 2
Training loss: 0.44818171340468804
Validation loss: 2.721045468337817

Epoch: 5| Step: 3
Training loss: 0.4153899381386884
Validation loss: 2.704096454367605

Epoch: 5| Step: 4
Training loss: 0.43378207266791174
Validation loss: 2.676488413223963

Epoch: 5| Step: 5
Training loss: 0.22708367550383754
Validation loss: 2.6700183649842186

Epoch: 5| Step: 6
Training loss: 0.35007560798882625
Validation loss: 2.7054867891953687

Epoch: 5| Step: 7
Training loss: 0.42013693337033564
Validation loss: 2.7289925088918325

Epoch: 5| Step: 8
Training loss: 0.4849873794063917
Validation loss: 2.7421519618382377

Epoch: 5| Step: 9
Training loss: 0.5111385288290582
Validation loss: 2.717981439439446

Epoch: 5| Step: 10
Training loss: 0.29923987849366795
Validation loss: 2.7326983987204763

Epoch: 436| Step: 0
Training loss: 0.4488252159934065
Validation loss: 2.760915050840944

Epoch: 5| Step: 1
Training loss: 0.4797320106059692
Validation loss: 2.7420394058608637

Epoch: 5| Step: 2
Training loss: 0.41682387803473003
Validation loss: 2.7436764158604077

Epoch: 5| Step: 3
Training loss: 0.2813560497828688
Validation loss: 2.7028785454274797

Epoch: 5| Step: 4
Training loss: 0.43130034415463275
Validation loss: 2.6685141488185162

Epoch: 5| Step: 5
Training loss: 0.39180453550659794
Validation loss: 2.625233406905545

Epoch: 5| Step: 6
Training loss: 0.42137382903116005
Validation loss: 2.689464366300527

Epoch: 5| Step: 7
Training loss: 0.23813024019497944
Validation loss: 2.706196046878876

Epoch: 5| Step: 8
Training loss: 0.5082965011489767
Validation loss: 2.7268705336547434

Epoch: 5| Step: 9
Training loss: 0.3709520973090745
Validation loss: 2.733859012045348

Epoch: 5| Step: 10
Training loss: 0.3896257972354216
Validation loss: 2.7695499278778217

Epoch: 437| Step: 0
Training loss: 0.2647062850735599
Validation loss: 2.7589537229918975

Epoch: 5| Step: 1
Training loss: 0.4281402125753539
Validation loss: 2.7311010286910196

Epoch: 5| Step: 2
Training loss: 0.43456681496573585
Validation loss: 2.699574468168645

Epoch: 5| Step: 3
Training loss: 0.30479661503805805
Validation loss: 2.712330382001795

Epoch: 5| Step: 4
Training loss: 0.2239973936099596
Validation loss: 2.7023874035579136

Epoch: 5| Step: 5
Training loss: 0.3363012739532847
Validation loss: 2.663198070341203

Epoch: 5| Step: 6
Training loss: 0.4806432949696509
Validation loss: 2.7072714313270922

Epoch: 5| Step: 7
Training loss: 0.4318992047351794
Validation loss: 2.6893990511427655

Epoch: 5| Step: 8
Training loss: 0.4923040312614568
Validation loss: 2.745612009953127

Epoch: 5| Step: 9
Training loss: 0.40273919162774446
Validation loss: 2.718673130712493

Epoch: 5| Step: 10
Training loss: 0.2984724858133773
Validation loss: 2.72956712539082

Epoch: 438| Step: 0
Training loss: 0.3675450755067448
Validation loss: 2.741396357684753

Epoch: 5| Step: 1
Training loss: 0.3786173436790878
Validation loss: 2.7544705102243414

Epoch: 5| Step: 2
Training loss: 0.49314324363350936
Validation loss: 2.766159328584301

Epoch: 5| Step: 3
Training loss: 0.43801117734059714
Validation loss: 2.799455840730704

Epoch: 5| Step: 4
Training loss: 0.3399052838270297
Validation loss: 2.7681681918067405

Epoch: 5| Step: 5
Training loss: 0.5132285696369051
Validation loss: 2.716891246358043

Epoch: 5| Step: 6
Training loss: 0.37936344289379986
Validation loss: 2.7499919967684066

Epoch: 5| Step: 7
Training loss: 0.30729223375214226
Validation loss: 2.7304169822476574

Epoch: 5| Step: 8
Training loss: 0.25593941288420685
Validation loss: 2.7013899240810675

Epoch: 5| Step: 9
Training loss: 0.20471407957984575
Validation loss: 2.6643114924785674

Epoch: 5| Step: 10
Training loss: 0.4391461635444606
Validation loss: 2.6904493395026567

Epoch: 439| Step: 0
Training loss: 0.33422346647696727
Validation loss: 2.6773421292244564

Epoch: 5| Step: 1
Training loss: 0.3497746572378449
Validation loss: 2.6599089214625464

Epoch: 5| Step: 2
Training loss: 0.3063629739985472
Validation loss: 2.664703959754131

Epoch: 5| Step: 3
Training loss: 0.43073455510426467
Validation loss: 2.707802410163858

Epoch: 5| Step: 4
Training loss: 0.5306344954558792
Validation loss: 2.7177450010181916

Epoch: 5| Step: 5
Training loss: 0.4179381421727295
Validation loss: 2.708678639235792

Epoch: 5| Step: 6
Training loss: 0.2692599520646014
Validation loss: 2.7309991983603488

Epoch: 5| Step: 7
Training loss: 0.333364849041162
Validation loss: 2.7330473740002468

Epoch: 5| Step: 8
Training loss: 0.4381133616448472
Validation loss: 2.6732089259329586

Epoch: 5| Step: 9
Training loss: 0.42654179533290437
Validation loss: 2.661433065409389

Epoch: 5| Step: 10
Training loss: 0.3372215084500085
Validation loss: 2.73117199602851

Epoch: 440| Step: 0
Training loss: 0.4445118147317218
Validation loss: 2.687925323690558

Epoch: 5| Step: 1
Training loss: 0.35696980805379236
Validation loss: 2.6959456494485523

Epoch: 5| Step: 2
Training loss: 0.4172455065115577
Validation loss: 2.716060014404711

Epoch: 5| Step: 3
Training loss: 0.4028294788626525
Validation loss: 2.726908856320826

Epoch: 5| Step: 4
Training loss: 0.4375321172097102
Validation loss: 2.7378665375449183

Epoch: 5| Step: 5
Training loss: 0.3304244712943694
Validation loss: 2.710442620116629

Epoch: 5| Step: 6
Training loss: 0.43868899562508457
Validation loss: 2.746175839419804

Epoch: 5| Step: 7
Training loss: 0.2204069242971456
Validation loss: 2.747689922257214

Epoch: 5| Step: 8
Training loss: 0.4538480810032168
Validation loss: 2.7341695991401846

Epoch: 5| Step: 9
Training loss: 0.2024015785857317
Validation loss: 2.7035609210392373

Epoch: 5| Step: 10
Training loss: 0.4865052387106434
Validation loss: 2.712484501521787

Epoch: 441| Step: 0
Training loss: 0.2481153874132741
Validation loss: 2.694136512975863

Epoch: 5| Step: 1
Training loss: 0.3366450797826674
Validation loss: 2.672204551481726

Epoch: 5| Step: 2
Training loss: 0.4652514072634708
Validation loss: 2.7026930504267344

Epoch: 5| Step: 3
Training loss: 0.518546871262891
Validation loss: 2.667728084651208

Epoch: 5| Step: 4
Training loss: 0.26080500099723897
Validation loss: 2.7365633157055607

Epoch: 5| Step: 5
Training loss: 0.36339934285697034
Validation loss: 2.7298861174261924

Epoch: 5| Step: 6
Training loss: 0.2080480151659113
Validation loss: 2.7377632466490076

Epoch: 5| Step: 7
Training loss: 0.492453442735361
Validation loss: 2.7370432015334627

Epoch: 5| Step: 8
Training loss: 0.4229749715324233
Validation loss: 2.708304910692076

Epoch: 5| Step: 9
Training loss: 0.44193140371350415
Validation loss: 2.72191107110658

Epoch: 5| Step: 10
Training loss: 0.30701445613679157
Validation loss: 2.7539612811636767

Epoch: 442| Step: 0
Training loss: 0.3032379883653937
Validation loss: 2.707540349296735

Epoch: 5| Step: 1
Training loss: 0.3338689214130945
Validation loss: 2.694703669993963

Epoch: 5| Step: 2
Training loss: 0.46008355840790216
Validation loss: 2.7433445838223354

Epoch: 5| Step: 3
Training loss: 0.2917147054734105
Validation loss: 2.707379759341789

Epoch: 5| Step: 4
Training loss: 0.4801354221204983
Validation loss: 2.696873490299828

Epoch: 5| Step: 5
Training loss: 0.33634920176038047
Validation loss: 2.6989274194599675

Epoch: 5| Step: 6
Training loss: 0.3991385444651102
Validation loss: 2.6904902457758966

Epoch: 5| Step: 7
Training loss: 0.23620816804004519
Validation loss: 2.7117533779836576

Epoch: 5| Step: 8
Training loss: 0.3973328292551993
Validation loss: 2.7314157118574056

Epoch: 5| Step: 9
Training loss: 0.39002332125529204
Validation loss: 2.7346997552503636

Epoch: 5| Step: 10
Training loss: 0.35497060392123825
Validation loss: 2.6927820731407426

Epoch: 443| Step: 0
Training loss: 0.34950169444730783
Validation loss: 2.754004649220573

Epoch: 5| Step: 1
Training loss: 0.4958443803384734
Validation loss: 2.710472023234619

Epoch: 5| Step: 2
Training loss: 0.37232804070364944
Validation loss: 2.7296343467425657

Epoch: 5| Step: 3
Training loss: 0.4738607900104483
Validation loss: 2.6655674836564196

Epoch: 5| Step: 4
Training loss: 0.35780795148598754
Validation loss: 2.6887877294102696

Epoch: 5| Step: 5
Training loss: 0.3196319001847516
Validation loss: 2.6703928273968547

Epoch: 5| Step: 6
Training loss: 0.35362389524091076
Validation loss: 2.6820563645122526

Epoch: 5| Step: 7
Training loss: 0.47103434895136514
Validation loss: 2.6901135167466457

Epoch: 5| Step: 8
Training loss: 0.23390723279849737
Validation loss: 2.697343719291176

Epoch: 5| Step: 9
Training loss: 0.3761280497753452
Validation loss: 2.756560215046388

Epoch: 5| Step: 10
Training loss: 0.29288243611738
Validation loss: 2.731032583694905

Epoch: 444| Step: 0
Training loss: 0.33716451209461473
Validation loss: 2.765150076340239

Epoch: 5| Step: 1
Training loss: 0.25381462204493915
Validation loss: 2.674325310333431

Epoch: 5| Step: 2
Training loss: 0.31128240845564914
Validation loss: 2.7391162584731394

Epoch: 5| Step: 3
Training loss: 0.3618501346326965
Validation loss: 2.7383886939403377

Epoch: 5| Step: 4
Training loss: 0.40365294993700174
Validation loss: 2.7065232683150073

Epoch: 5| Step: 5
Training loss: 0.39530979426969554
Validation loss: 2.7087662747571173

Epoch: 5| Step: 6
Training loss: 0.5141384775893343
Validation loss: 2.712507001106879

Epoch: 5| Step: 7
Training loss: 0.26690924360005375
Validation loss: 2.6872507758648254

Epoch: 5| Step: 8
Training loss: 0.5615433399156357
Validation loss: 2.7024374495317987

Epoch: 5| Step: 9
Training loss: 0.2320303544435012
Validation loss: 2.710993534842524

Epoch: 5| Step: 10
Training loss: 0.26978843968104976
Validation loss: 2.710331010782499

Epoch: 445| Step: 0
Training loss: 0.3150947847887515
Validation loss: 2.7126307908526717

Epoch: 5| Step: 1
Training loss: 0.34238944865975035
Validation loss: 2.7142741685489598

Epoch: 5| Step: 2
Training loss: 0.21596610206942446
Validation loss: 2.680718203054912

Epoch: 5| Step: 3
Training loss: 0.1800758270646644
Validation loss: 2.7364922670919096

Epoch: 5| Step: 4
Training loss: 0.3809577228038215
Validation loss: 2.695243179454726

Epoch: 5| Step: 5
Training loss: 0.2410352198148847
Validation loss: 2.738275152375788

Epoch: 5| Step: 6
Training loss: 0.43861026891810456
Validation loss: 2.698152184446205

Epoch: 5| Step: 7
Training loss: 0.43608761052204525
Validation loss: 2.730564414854524

Epoch: 5| Step: 8
Training loss: 0.5579216922346586
Validation loss: 2.686872839813776

Epoch: 5| Step: 9
Training loss: 0.24861914034498042
Validation loss: 2.67281246812

Epoch: 5| Step: 10
Training loss: 0.5111452047954287
Validation loss: 2.7012950500858017

Epoch: 446| Step: 0
Training loss: 0.28561650326150523
Validation loss: 2.70060798965663

Epoch: 5| Step: 1
Training loss: 0.25218614256445043
Validation loss: 2.6863570285665266

Epoch: 5| Step: 2
Training loss: 0.4804779610099839
Validation loss: 2.707538890670471

Epoch: 5| Step: 3
Training loss: 0.3845439795317298
Validation loss: 2.7356807543178365

Epoch: 5| Step: 4
Training loss: 0.4491690898480751
Validation loss: 2.7394118807284324

Epoch: 5| Step: 5
Training loss: 0.41374739767103275
Validation loss: 2.7191924839622503

Epoch: 5| Step: 6
Training loss: 0.3753511850714634
Validation loss: 2.749732598348822

Epoch: 5| Step: 7
Training loss: 0.35489033180378887
Validation loss: 2.732411172001115

Epoch: 5| Step: 8
Training loss: 0.15832417178209177
Validation loss: 2.7435881840618275

Epoch: 5| Step: 9
Training loss: 0.41573352830867794
Validation loss: 2.723134378416151

Epoch: 5| Step: 10
Training loss: 0.23865121511643125
Validation loss: 2.735022861593405

Epoch: 447| Step: 0
Training loss: 0.2894487378074946
Validation loss: 2.722220955190503

Epoch: 5| Step: 1
Training loss: 0.2499879372189922
Validation loss: 2.6849690563167794

Epoch: 5| Step: 2
Training loss: 0.3407702696166802
Validation loss: 2.7054812098919743

Epoch: 5| Step: 3
Training loss: 0.38751587450674596
Validation loss: 2.6979556536774543

Epoch: 5| Step: 4
Training loss: 0.33255374413147526
Validation loss: 2.702171985163942

Epoch: 5| Step: 5
Training loss: 0.20899018609354655
Validation loss: 2.732011104782778

Epoch: 5| Step: 6
Training loss: 0.3939617503438448
Validation loss: 2.6937737027721855

Epoch: 5| Step: 7
Training loss: 0.5004306964776255
Validation loss: 2.767930977331187

Epoch: 5| Step: 8
Training loss: 0.40735282129884204
Validation loss: 2.7083444454700327

Epoch: 5| Step: 9
Training loss: 0.3814605272328268
Validation loss: 2.7387493062893804

Epoch: 5| Step: 10
Training loss: 0.42537624450420836
Validation loss: 2.759064545492454

Epoch: 448| Step: 0
Training loss: 0.2728044811962347
Validation loss: 2.696566850581199

Epoch: 5| Step: 1
Training loss: 0.2560091672192884
Validation loss: 2.724100915313587

Epoch: 5| Step: 2
Training loss: 0.359019601316007
Validation loss: 2.74006998178604

Epoch: 5| Step: 3
Training loss: 0.2658056037863942
Validation loss: 2.7269673851791927

Epoch: 5| Step: 4
Training loss: 0.32072982119404353
Validation loss: 2.727984408970222

Epoch: 5| Step: 5
Training loss: 0.5788283837547347
Validation loss: 2.7587119725511813

Epoch: 5| Step: 6
Training loss: 0.43616064301462454
Validation loss: 2.716228131607054

Epoch: 5| Step: 7
Training loss: 0.33893249278209736
Validation loss: 2.786621284646213

Epoch: 5| Step: 8
Training loss: 0.3062162682387636
Validation loss: 2.745077646264108

Epoch: 5| Step: 9
Training loss: 0.2653523476312602
Validation loss: 2.7487535560483174

Epoch: 5| Step: 10
Training loss: 0.4533698144105538
Validation loss: 2.7171636981208556

Epoch: 449| Step: 0
Training loss: 0.30802479940825406
Validation loss: 2.722044525606961

Epoch: 5| Step: 1
Training loss: 0.3551665268437829
Validation loss: 2.711294852975488

Epoch: 5| Step: 2
Training loss: 0.4676168414589351
Validation loss: 2.6956615039541756

Epoch: 5| Step: 3
Training loss: 0.5124804527927921
Validation loss: 2.7389122783534665

Epoch: 5| Step: 4
Training loss: 0.39040013516797006
Validation loss: 2.722574132225681

Epoch: 5| Step: 5
Training loss: 0.32398114057682875
Validation loss: 2.7115459959629264

Epoch: 5| Step: 6
Training loss: 0.31397148825346577
Validation loss: 2.7178240236300377

Epoch: 5| Step: 7
Training loss: 0.16647313412542838
Validation loss: 2.7733693797509673

Epoch: 5| Step: 8
Training loss: 0.2548534771052813
Validation loss: 2.7508645912607776

Epoch: 5| Step: 9
Training loss: 0.19014524098847346
Validation loss: 2.7598430970237495

Epoch: 5| Step: 10
Training loss: 0.31592657675947705
Validation loss: 2.755194706866345

Epoch: 450| Step: 0
Training loss: 0.2954681843914103
Validation loss: 2.7723041571827944

Epoch: 5| Step: 1
Training loss: 0.3892525595517737
Validation loss: 2.763771492301104

Epoch: 5| Step: 2
Training loss: 0.44514740008216547
Validation loss: 2.731683157195769

Epoch: 5| Step: 3
Training loss: 0.3730163162257638
Validation loss: 2.7374456300129637

Epoch: 5| Step: 4
Training loss: 0.2944883229267373
Validation loss: 2.7057527469650253

Epoch: 5| Step: 5
Training loss: 0.40201314287147016
Validation loss: 2.7201424192964283

Epoch: 5| Step: 6
Training loss: 0.30414221950596115
Validation loss: 2.7229210194056597

Epoch: 5| Step: 7
Training loss: 0.28469194209865606
Validation loss: 2.6828230780149056

Epoch: 5| Step: 8
Training loss: 0.2988002365163393
Validation loss: 2.7139485938820824

Epoch: 5| Step: 9
Training loss: 0.5116084030799685
Validation loss: 2.7319375870991705

Epoch: 5| Step: 10
Training loss: 0.3281431420170074
Validation loss: 2.7130921889304322

Testing loss: 2.807120361008415
