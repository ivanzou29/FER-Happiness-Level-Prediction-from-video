Epoch: 1| Step: 0
Training loss: 5.834596043114564
Validation loss: 5.820552875856916

Epoch: 5| Step: 1
Training loss: 6.370337482896498
Validation loss: 5.79785430307394

Epoch: 5| Step: 2
Training loss: 6.408938257894661
Validation loss: 5.775057154227339

Epoch: 5| Step: 3
Training loss: 5.804425281131482
Validation loss: 5.753393758024142

Epoch: 5| Step: 4
Training loss: 4.774598924659267
Validation loss: 5.729282781444148

Epoch: 5| Step: 5
Training loss: 6.088460808035667
Validation loss: 5.703223022211922

Epoch: 5| Step: 6
Training loss: 6.097958407592057
Validation loss: 5.673556507139516

Epoch: 5| Step: 7
Training loss: 5.538224645178181
Validation loss: 5.641619418340155

Epoch: 5| Step: 8
Training loss: 4.9885682073516255
Validation loss: 5.605214562115432

Epoch: 5| Step: 9
Training loss: 6.3602189387418475
Validation loss: 5.563455254223429

Epoch: 5| Step: 10
Training loss: 4.108091901039072
Validation loss: 5.518438135499042

Epoch: 2| Step: 0
Training loss: 5.501000400073729
Validation loss: 5.471058940378861

Epoch: 5| Step: 1
Training loss: 5.528112523834141
Validation loss: 5.419539813028656

Epoch: 5| Step: 2
Training loss: 6.15696812812619
Validation loss: 5.3652357721587665

Epoch: 5| Step: 3
Training loss: 5.22717646483794
Validation loss: 5.307945973934435

Epoch: 5| Step: 4
Training loss: 5.743537920501464
Validation loss: 5.249495003940965

Epoch: 5| Step: 5
Training loss: 3.938888668233067
Validation loss: 5.190926104517348

Epoch: 5| Step: 6
Training loss: 4.763941733336276
Validation loss: 5.132709574001842

Epoch: 5| Step: 7
Training loss: 5.860941522363489
Validation loss: 5.073909572988044

Epoch: 5| Step: 8
Training loss: 4.716732174763293
Validation loss: 5.018449621444863

Epoch: 5| Step: 9
Training loss: 4.569994688803093
Validation loss: 4.966442688701477

Epoch: 5| Step: 10
Training loss: 5.409451281066449
Validation loss: 4.918410081617404

Epoch: 3| Step: 0
Training loss: 4.854515074094864
Validation loss: 4.87391626992601

Epoch: 5| Step: 1
Training loss: 5.123705816848526
Validation loss: 4.835170533879014

Epoch: 5| Step: 2
Training loss: 4.2592034264067085
Validation loss: 4.802498985927965

Epoch: 5| Step: 3
Training loss: 6.208122949641166
Validation loss: 4.773780170945482

Epoch: 5| Step: 4
Training loss: 4.946641017370911
Validation loss: 4.745660735251096

Epoch: 5| Step: 5
Training loss: 5.008091673307503
Validation loss: 4.716541903964854

Epoch: 5| Step: 6
Training loss: 4.066622007364497
Validation loss: 4.687097078459748

Epoch: 5| Step: 7
Training loss: 4.4943358483782205
Validation loss: 4.657816629199876

Epoch: 5| Step: 8
Training loss: 3.9234329108147197
Validation loss: 4.641452488341644

Epoch: 5| Step: 9
Training loss: 4.484371597341915
Validation loss: 4.616349864387658

Epoch: 5| Step: 10
Training loss: 5.333285252036482
Validation loss: 4.593394753707641

Epoch: 4| Step: 0
Training loss: 5.511125236582001
Validation loss: 4.578245202894077

Epoch: 5| Step: 1
Training loss: 4.944383868490518
Validation loss: 4.563346041526985

Epoch: 5| Step: 2
Training loss: 3.9807364810828325
Validation loss: 4.545985989252745

Epoch: 5| Step: 3
Training loss: 4.453779848369713
Validation loss: 4.528109362287403

Epoch: 5| Step: 4
Training loss: 4.212644779422739
Validation loss: 4.51085600548314

Epoch: 5| Step: 5
Training loss: 4.7766332339713795
Validation loss: 4.499403840001879

Epoch: 5| Step: 6
Training loss: 4.931197381071253
Validation loss: 4.485024151575786

Epoch: 5| Step: 7
Training loss: 4.548534182350157
Validation loss: 4.470622866849548

Epoch: 5| Step: 8
Training loss: 4.761348619228393
Validation loss: 4.460078775924269

Epoch: 5| Step: 9
Training loss: 4.084603378110257
Validation loss: 4.446713353125797

Epoch: 5| Step: 10
Training loss: 4.3033112750878075
Validation loss: 4.432418838576992

Epoch: 5| Step: 0
Training loss: 4.775043523300501
Validation loss: 4.42072491669397

Epoch: 5| Step: 1
Training loss: 5.1153029837418735
Validation loss: 4.408052986560715

Epoch: 5| Step: 2
Training loss: 4.833944128620339
Validation loss: 4.392230235024486

Epoch: 5| Step: 3
Training loss: 4.4061876657824905
Validation loss: 4.380493968676238

Epoch: 5| Step: 4
Training loss: 4.95044932011927
Validation loss: 4.369676363479788

Epoch: 5| Step: 5
Training loss: 4.395911241657553
Validation loss: 4.356323519714395

Epoch: 5| Step: 6
Training loss: 5.1006810126298365
Validation loss: 4.342545537184486

Epoch: 5| Step: 7
Training loss: 4.089544101293065
Validation loss: 4.328184144062551

Epoch: 5| Step: 8
Training loss: 2.998755355772934
Validation loss: 4.3176655126407395

Epoch: 5| Step: 9
Training loss: 4.036358811987166
Validation loss: 4.311972613349414

Epoch: 5| Step: 10
Training loss: 4.119735363729458
Validation loss: 4.295384488493861

Epoch: 6| Step: 0
Training loss: 4.70926222738959
Validation loss: 4.282147368500934

Epoch: 5| Step: 1
Training loss: 4.794995464684785
Validation loss: 4.271691056067155

Epoch: 5| Step: 2
Training loss: 4.327731448572889
Validation loss: 4.258522688406262

Epoch: 5| Step: 3
Training loss: 4.539395712409075
Validation loss: 4.244566615354603

Epoch: 5| Step: 4
Training loss: 4.554066427558049
Validation loss: 4.231843889109109

Epoch: 5| Step: 5
Training loss: 4.06225397392049
Validation loss: 4.21989030759503

Epoch: 5| Step: 6
Training loss: 3.5008366810880176
Validation loss: 4.208404468937057

Epoch: 5| Step: 7
Training loss: 4.486302828686301
Validation loss: 4.198399986503939

Epoch: 5| Step: 8
Training loss: 4.189142389044383
Validation loss: 4.186282178404288

Epoch: 5| Step: 9
Training loss: 4.833406097039785
Validation loss: 4.173244473841703

Epoch: 5| Step: 10
Training loss: 3.5763040098387293
Validation loss: 4.163720602157945

Epoch: 7| Step: 0
Training loss: 4.630772879833302
Validation loss: 4.153436187392085

Epoch: 5| Step: 1
Training loss: 4.268779105538243
Validation loss: 4.140423278166969

Epoch: 5| Step: 2
Training loss: 4.43411168505563
Validation loss: 4.131357402031246

Epoch: 5| Step: 3
Training loss: 4.1947239297772505
Validation loss: 4.121082629723537

Epoch: 5| Step: 4
Training loss: 3.6232038849486154
Validation loss: 4.107888723926788

Epoch: 5| Step: 5
Training loss: 4.851245028172073
Validation loss: 4.0990415514819984

Epoch: 5| Step: 6
Training loss: 3.41570837646801
Validation loss: 4.087826250807999

Epoch: 5| Step: 7
Training loss: 4.132818038157915
Validation loss: 4.077146090882075

Epoch: 5| Step: 8
Training loss: 4.476975134028333
Validation loss: 4.067099469791683

Epoch: 5| Step: 9
Training loss: 4.804561259774484
Validation loss: 4.056335474711427

Epoch: 5| Step: 10
Training loss: 3.4423147987518594
Validation loss: 4.0476039049970565

Epoch: 8| Step: 0
Training loss: 3.436521494919883
Validation loss: 4.041142016806181

Epoch: 5| Step: 1
Training loss: 3.888339554876677
Validation loss: 4.026223429128823

Epoch: 5| Step: 2
Training loss: 4.38664352882413
Validation loss: 4.0134885229464174

Epoch: 5| Step: 3
Training loss: 4.961556271388573
Validation loss: 4.005216565565

Epoch: 5| Step: 4
Training loss: 4.671340758738644
Validation loss: 3.9950576789706007

Epoch: 5| Step: 5
Training loss: 4.682651300872872
Validation loss: 3.985054491249805

Epoch: 5| Step: 6
Training loss: 3.7801124816386524
Validation loss: 3.9727219844891555

Epoch: 5| Step: 7
Training loss: 3.38964421726185
Validation loss: 3.9592371601188328

Epoch: 5| Step: 8
Training loss: 3.2673192352050955
Validation loss: 3.947981834712522

Epoch: 5| Step: 9
Training loss: 4.862514646846413
Validation loss: 3.937466680018216

Epoch: 5| Step: 10
Training loss: 3.6571289049461435
Validation loss: 3.9251509840730865

Epoch: 9| Step: 0
Training loss: 3.9354161394616023
Validation loss: 3.920861894206388

Epoch: 5| Step: 1
Training loss: 4.55200053240835
Validation loss: 3.9017616209037653

Epoch: 5| Step: 2
Training loss: 4.613228741895293
Validation loss: 3.8936867956702117

Epoch: 5| Step: 3
Training loss: 4.3072754545571685
Validation loss: 3.8829737530107247

Epoch: 5| Step: 4
Training loss: 4.432813937133513
Validation loss: 3.8705230424980956

Epoch: 5| Step: 5
Training loss: 4.626938284853787
Validation loss: 3.860975297984773

Epoch: 5| Step: 6
Training loss: 3.4593777898623856
Validation loss: 3.8477641602154766

Epoch: 5| Step: 7
Training loss: 3.3772177297468122
Validation loss: 3.8402979092547267

Epoch: 5| Step: 8
Training loss: 3.4717394344806083
Validation loss: 3.827684029417011

Epoch: 5| Step: 9
Training loss: 3.661997003484278
Validation loss: 3.82657037324487

Epoch: 5| Step: 10
Training loss: 3.5538974428937777
Validation loss: 3.8096692883255217

Epoch: 10| Step: 0
Training loss: 4.5718770275515626
Validation loss: 3.809745383832281

Epoch: 5| Step: 1
Training loss: 4.954967072008893
Validation loss: 3.8007430135475975

Epoch: 5| Step: 2
Training loss: 3.846214062879584
Validation loss: 3.7822762485448966

Epoch: 5| Step: 3
Training loss: 3.483619779158895
Validation loss: 3.7715490778350964

Epoch: 5| Step: 4
Training loss: 3.838826569638526
Validation loss: 3.766834113762012

Epoch: 5| Step: 5
Training loss: 3.688743252413559
Validation loss: 3.762220461660527

Epoch: 5| Step: 6
Training loss: 4.068650739311618
Validation loss: 3.753670861205403

Epoch: 5| Step: 7
Training loss: 2.5891896798500853
Validation loss: 3.732357640940725

Epoch: 5| Step: 8
Training loss: 4.175513577424208
Validation loss: 3.7204019736577054

Epoch: 5| Step: 9
Training loss: 3.392101195022482
Validation loss: 3.708473196476565

Epoch: 5| Step: 10
Training loss: 4.242761393976313
Validation loss: 3.6994883618393244

Epoch: 11| Step: 0
Training loss: 3.741011974487882
Validation loss: 3.690745206841797

Epoch: 5| Step: 1
Training loss: 3.6737580361137225
Validation loss: 3.6768940551496314

Epoch: 5| Step: 2
Training loss: 2.5846530455685532
Validation loss: 3.668553771940571

Epoch: 5| Step: 3
Training loss: 3.800789906569343
Validation loss: 3.6613035711804334

Epoch: 5| Step: 4
Training loss: 3.702811569920736
Validation loss: 3.6525215846592127

Epoch: 5| Step: 5
Training loss: 4.251284012651423
Validation loss: 3.639521249515058

Epoch: 5| Step: 6
Training loss: 3.65390030438533
Validation loss: 3.628549964149019

Epoch: 5| Step: 7
Training loss: 3.744237668685642
Validation loss: 3.623972035907231

Epoch: 5| Step: 8
Training loss: 3.85530017302587
Validation loss: 3.613968575647817

Epoch: 5| Step: 9
Training loss: 4.523653805951945
Validation loss: 3.6077890770926184

Epoch: 5| Step: 10
Training loss: 4.416294849987529
Validation loss: 3.6015090908170597

Epoch: 12| Step: 0
Training loss: 3.4583175076654955
Validation loss: 3.5926040470205356

Epoch: 5| Step: 1
Training loss: 3.8016182114187407
Validation loss: 3.5813309773855573

Epoch: 5| Step: 2
Training loss: 3.297288769253345
Validation loss: 3.5729705070792663

Epoch: 5| Step: 3
Training loss: 3.224607452632301
Validation loss: 3.5654785522481447

Epoch: 5| Step: 4
Training loss: 3.1608279425604144
Validation loss: 3.5582738757590455

Epoch: 5| Step: 5
Training loss: 3.7009866069230815
Validation loss: 3.5517413454332325

Epoch: 5| Step: 6
Training loss: 4.166381877067517
Validation loss: 3.542985712249503

Epoch: 5| Step: 7
Training loss: 3.9568345829706084
Validation loss: 3.5375586401320307

Epoch: 5| Step: 8
Training loss: 4.414486376909983
Validation loss: 3.528254293956689

Epoch: 5| Step: 9
Training loss: 4.120502910474581
Validation loss: 3.5188285526130967

Epoch: 5| Step: 10
Training loss: 3.7895815778871187
Validation loss: 3.5125166491077153

Epoch: 13| Step: 0
Training loss: 3.6717624078897964
Validation loss: 3.507076965111124

Epoch: 5| Step: 1
Training loss: 4.173211844344632
Validation loss: 3.497549858449473

Epoch: 5| Step: 2
Training loss: 4.091854442837877
Validation loss: 3.4880514682078227

Epoch: 5| Step: 3
Training loss: 3.897481980884684
Validation loss: 3.481905607675205

Epoch: 5| Step: 4
Training loss: 3.8952645823335077
Validation loss: 3.4728604238960474

Epoch: 5| Step: 5
Training loss: 4.077762982315353
Validation loss: 3.467428710892197

Epoch: 5| Step: 6
Training loss: 3.3998773440507883
Validation loss: 3.4557136510382347

Epoch: 5| Step: 7
Training loss: 3.600438933634557
Validation loss: 3.4454318828044204

Epoch: 5| Step: 8
Training loss: 2.864921152251518
Validation loss: 3.453935585845885

Epoch: 5| Step: 9
Training loss: 2.6145448010608177
Validation loss: 3.449216658486687

Epoch: 5| Step: 10
Training loss: 4.004484523789489
Validation loss: 3.4363673487312854

Epoch: 14| Step: 0
Training loss: 3.226239869472438
Validation loss: 3.414163363232008

Epoch: 5| Step: 1
Training loss: 3.991179038401704
Validation loss: 3.4166096448204346

Epoch: 5| Step: 2
Training loss: 4.045284709930738
Validation loss: 3.402418577014375

Epoch: 5| Step: 3
Training loss: 4.165448786448982
Validation loss: 3.4003966096540297

Epoch: 5| Step: 4
Training loss: 3.206442701114777
Validation loss: 3.3889227372096355

Epoch: 5| Step: 5
Training loss: 2.801956674958324
Validation loss: 3.3773425680062066

Epoch: 5| Step: 6
Training loss: 3.624728883273049
Validation loss: 3.3721208935507296

Epoch: 5| Step: 7
Training loss: 3.0512943398060313
Validation loss: 3.36306948435379

Epoch: 5| Step: 8
Training loss: 4.003966272415957
Validation loss: 3.3515305863108367

Epoch: 5| Step: 9
Training loss: 3.4893016796413363
Validation loss: 3.3463105548851173

Epoch: 5| Step: 10
Training loss: 3.84458839763174
Validation loss: 3.333876862870906

Epoch: 15| Step: 0
Training loss: 4.072674027782271
Validation loss: 3.3282074899525584

Epoch: 5| Step: 1
Training loss: 2.9418565625791544
Validation loss: 3.3183003908597413

Epoch: 5| Step: 2
Training loss: 3.080918956251565
Validation loss: 3.310359211210666

Epoch: 5| Step: 3
Training loss: 3.7273240181043423
Validation loss: 3.301342955540168

Epoch: 5| Step: 4
Training loss: 3.471166095756735
Validation loss: 3.2968669223108105

Epoch: 5| Step: 5
Training loss: 3.4753020669845536
Validation loss: 3.2864216353806173

Epoch: 5| Step: 6
Training loss: 4.0704626835446955
Validation loss: 3.2812227559557856

Epoch: 5| Step: 7
Training loss: 3.771347699289089
Validation loss: 3.2714804568364437

Epoch: 5| Step: 8
Training loss: 2.9155178168937677
Validation loss: 3.2644936784892926

Epoch: 5| Step: 9
Training loss: 3.735376327532284
Validation loss: 3.257641990246033

Epoch: 5| Step: 10
Training loss: 3.303488222937523
Validation loss: 3.2490098989587994

Epoch: 16| Step: 0
Training loss: 3.769499498935256
Validation loss: 3.24590645576005

Epoch: 5| Step: 1
Training loss: 3.8223463390095036
Validation loss: 3.2439952022892853

Epoch: 5| Step: 2
Training loss: 3.953215948573967
Validation loss: 3.2324256580948894

Epoch: 5| Step: 3
Training loss: 3.4491539124975517
Validation loss: 3.227151923507701

Epoch: 5| Step: 4
Training loss: 2.8018992385990114
Validation loss: 3.223320091389946

Epoch: 5| Step: 5
Training loss: 3.496566859791569
Validation loss: 3.2215845076397662

Epoch: 5| Step: 6
Training loss: 3.212373955179795
Validation loss: 3.213239589022067

Epoch: 5| Step: 7
Training loss: 3.155083771332542
Validation loss: 3.2132546058703135

Epoch: 5| Step: 8
Training loss: 3.549499347468003
Validation loss: 3.205254540713609

Epoch: 5| Step: 9
Training loss: 3.274297997169405
Validation loss: 3.2024086572136827

Epoch: 5| Step: 10
Training loss: 3.632489589983417
Validation loss: 3.2003835219789383

Epoch: 17| Step: 0
Training loss: 3.4532097853526467
Validation loss: 3.191725050610341

Epoch: 5| Step: 1
Training loss: 3.887242819567778
Validation loss: 3.1885091546184117

Epoch: 5| Step: 2
Training loss: 2.6632683876467786
Validation loss: 3.185762506502773

Epoch: 5| Step: 3
Training loss: 3.680302983540782
Validation loss: 3.1942055496217137

Epoch: 5| Step: 4
Training loss: 3.4910967529404155
Validation loss: 3.1820266237583774

Epoch: 5| Step: 5
Training loss: 3.645724674603821
Validation loss: 3.1837252263286326

Epoch: 5| Step: 6
Training loss: 3.2160637766554223
Validation loss: 3.1738965627960445

Epoch: 5| Step: 7
Training loss: 3.4730997392395824
Validation loss: 3.170157262795324

Epoch: 5| Step: 8
Training loss: 3.2625054604203285
Validation loss: 3.1677523831261474

Epoch: 5| Step: 9
Training loss: 3.1837614986480123
Validation loss: 3.16877523264424

Epoch: 5| Step: 10
Training loss: 3.8049004277799208
Validation loss: 3.166492841663631

Epoch: 18| Step: 0
Training loss: 3.419633523145015
Validation loss: 3.161989960840965

Epoch: 5| Step: 1
Training loss: 3.2979543645603493
Validation loss: 3.1584928039565323

Epoch: 5| Step: 2
Training loss: 2.662695928537301
Validation loss: 3.1574823001837724

Epoch: 5| Step: 3
Training loss: 3.210080665929581
Validation loss: 3.1539436278921626

Epoch: 5| Step: 4
Training loss: 3.473351116195913
Validation loss: 3.151239912684658

Epoch: 5| Step: 5
Training loss: 4.11111285808171
Validation loss: 3.1519980709133946

Epoch: 5| Step: 6
Training loss: 2.985356194539668
Validation loss: 3.148796155365164

Epoch: 5| Step: 7
Training loss: 3.484655394626464
Validation loss: 3.1469903456372945

Epoch: 5| Step: 8
Training loss: 4.140650335270368
Validation loss: 3.144861918995265

Epoch: 5| Step: 9
Training loss: 3.3584587799445913
Validation loss: 3.1406469930516363

Epoch: 5| Step: 10
Training loss: 3.1779851081840134
Validation loss: 3.1383230954349925

Epoch: 19| Step: 0
Training loss: 3.5926720370815692
Validation loss: 3.1358791249154003

Epoch: 5| Step: 1
Training loss: 3.319845727760242
Validation loss: 3.1316351797936486

Epoch: 5| Step: 2
Training loss: 2.619904613651296
Validation loss: 3.130676282601304

Epoch: 5| Step: 3
Training loss: 3.071184883716026
Validation loss: 3.128442821088572

Epoch: 5| Step: 4
Training loss: 3.1328245243593273
Validation loss: 3.12501528336264

Epoch: 5| Step: 5
Training loss: 4.117737821973106
Validation loss: 3.122482301207408

Epoch: 5| Step: 6
Training loss: 3.06200000028903
Validation loss: 3.1184091611786133

Epoch: 5| Step: 7
Training loss: 3.613408992674348
Validation loss: 3.1155348772316867

Epoch: 5| Step: 8
Training loss: 4.166683553025678
Validation loss: 3.1114798190992166

Epoch: 5| Step: 9
Training loss: 3.481334779758316
Validation loss: 3.106256841011278

Epoch: 5| Step: 10
Training loss: 2.73095908285112
Validation loss: 3.1169230096814124

Epoch: 20| Step: 0
Training loss: 3.3490203962414022
Validation loss: 3.169932280223719

Epoch: 5| Step: 1
Training loss: 3.8127675197109503
Validation loss: 3.0980418525871163

Epoch: 5| Step: 2
Training loss: 3.919068080520033
Validation loss: 3.100867094715891

Epoch: 5| Step: 3
Training loss: 2.071520183209857
Validation loss: 3.1122999692779216

Epoch: 5| Step: 4
Training loss: 3.9860187804855847
Validation loss: 3.103291616896859

Epoch: 5| Step: 5
Training loss: 3.13826575794152
Validation loss: 3.094650752286085

Epoch: 5| Step: 6
Training loss: 3.3938854380185024
Validation loss: 3.0919611559049818

Epoch: 5| Step: 7
Training loss: 3.3395636190085187
Validation loss: 3.0890943138648765

Epoch: 5| Step: 8
Training loss: 3.324389012926306
Validation loss: 3.085496814145442

Epoch: 5| Step: 9
Training loss: 3.014487412690106
Validation loss: 3.084574447672916

Epoch: 5| Step: 10
Training loss: 3.432459100200371
Validation loss: 3.085065586772168

Epoch: 21| Step: 0
Training loss: 3.375596876700003
Validation loss: 3.083980210306962

Epoch: 5| Step: 1
Training loss: 2.521302255780223
Validation loss: 3.08494232276722

Epoch: 5| Step: 2
Training loss: 2.772311903658788
Validation loss: 3.082109782780374

Epoch: 5| Step: 3
Training loss: 3.1800151534289265
Validation loss: 3.0790513924912646

Epoch: 5| Step: 4
Training loss: 3.1405427077410533
Validation loss: 3.075027975786675

Epoch: 5| Step: 5
Training loss: 4.11833947875304
Validation loss: 3.071464797654521

Epoch: 5| Step: 6
Training loss: 2.885031737577778
Validation loss: 3.06998566421636

Epoch: 5| Step: 7
Training loss: 3.314742139220474
Validation loss: 3.0708356387250944

Epoch: 5| Step: 8
Training loss: 3.591593086804807
Validation loss: 3.0688968206375726

Epoch: 5| Step: 9
Training loss: 4.24974283674516
Validation loss: 3.0712797212281764

Epoch: 5| Step: 10
Training loss: 3.387291601323249
Validation loss: 3.0688337985895804

Epoch: 22| Step: 0
Training loss: 3.3474971417392783
Validation loss: 3.0674399371618155

Epoch: 5| Step: 1
Training loss: 3.342689702564663
Validation loss: 3.065988716190721

Epoch: 5| Step: 2
Training loss: 3.5925762084013453
Validation loss: 3.0675268197689247

Epoch: 5| Step: 3
Training loss: 3.1519794844526126
Validation loss: 3.0624843401965767

Epoch: 5| Step: 4
Training loss: 2.9979205872220898
Validation loss: 3.0605785778858565

Epoch: 5| Step: 5
Training loss: 4.213578735238804
Validation loss: 3.058873423216903

Epoch: 5| Step: 6
Training loss: 3.0195252491248588
Validation loss: 3.0584986708376003

Epoch: 5| Step: 7
Training loss: 3.1542850836660414
Validation loss: 3.0605390396927232

Epoch: 5| Step: 8
Training loss: 3.665231871926767
Validation loss: 3.0597040984598314

Epoch: 5| Step: 9
Training loss: 3.073274304973977
Validation loss: 3.063182974813874

Epoch: 5| Step: 10
Training loss: 3.000186119663997
Validation loss: 3.059736066464149

Epoch: 23| Step: 0
Training loss: 3.177936793693272
Validation loss: 3.0718316255355846

Epoch: 5| Step: 1
Training loss: 3.2670664549141324
Validation loss: 3.0580742930967375

Epoch: 5| Step: 2
Training loss: 3.3097571767381555
Validation loss: 3.0496887979582157

Epoch: 5| Step: 3
Training loss: 3.432592877536606
Validation loss: 3.059146192365062

Epoch: 5| Step: 4
Training loss: 3.2051847952713084
Validation loss: 3.050447174037193

Epoch: 5| Step: 5
Training loss: 3.843622221024603
Validation loss: 3.048726311010459

Epoch: 5| Step: 6
Training loss: 3.7784749085957543
Validation loss: 3.0494412814010117

Epoch: 5| Step: 7
Training loss: 3.6113896547793707
Validation loss: 3.0453355289265476

Epoch: 5| Step: 8
Training loss: 3.1289441967209717
Validation loss: 3.0435913363970135

Epoch: 5| Step: 9
Training loss: 2.6958250581200622
Validation loss: 3.0455308665496577

Epoch: 5| Step: 10
Training loss: 3.0453922674263163
Validation loss: 3.0451101639425278

Epoch: 24| Step: 0
Training loss: 3.1431410091566656
Validation loss: 3.0543907996431976

Epoch: 5| Step: 1
Training loss: 3.1977646053249975
Validation loss: 3.054007989314042

Epoch: 5| Step: 2
Training loss: 3.457351514561292
Validation loss: 3.0447620437064176

Epoch: 5| Step: 3
Training loss: 2.5470492063516197
Validation loss: 3.0407160139952114

Epoch: 5| Step: 4
Training loss: 2.8951413725230295
Validation loss: 3.041316408518595

Epoch: 5| Step: 5
Training loss: 3.2279302547535353
Validation loss: 3.0411519637621036

Epoch: 5| Step: 6
Training loss: 3.5682501982391717
Validation loss: 3.0398563392434075

Epoch: 5| Step: 7
Training loss: 3.399834707393531
Validation loss: 3.039007244435004

Epoch: 5| Step: 8
Training loss: 3.6345023214091654
Validation loss: 3.0382383436243607

Epoch: 5| Step: 9
Training loss: 3.9128408752733557
Validation loss: 3.0442356555418946

Epoch: 5| Step: 10
Training loss: 3.4269800296198234
Validation loss: 3.0571729358831004

Epoch: 25| Step: 0
Training loss: 3.2264099823971097
Validation loss: 3.0574032778735805

Epoch: 5| Step: 1
Training loss: 2.929056084301376
Validation loss: 3.0423029923575267

Epoch: 5| Step: 2
Training loss: 3.2185363698637524
Validation loss: 3.035664903785952

Epoch: 5| Step: 3
Training loss: 2.7491302848907004
Validation loss: 3.0310879592032176

Epoch: 5| Step: 4
Training loss: 3.691519663849682
Validation loss: 3.029194578887453

Epoch: 5| Step: 5
Training loss: 3.193914653318574
Validation loss: 3.0311096001584317

Epoch: 5| Step: 6
Training loss: 3.459768403521522
Validation loss: 3.0314144051456444

Epoch: 5| Step: 7
Training loss: 3.5080006300470012
Validation loss: 3.0384640183322698

Epoch: 5| Step: 8
Training loss: 3.8671072286886834
Validation loss: 3.037096117450557

Epoch: 5| Step: 9
Training loss: 3.5606791879214383
Validation loss: 3.0208975157462916

Epoch: 5| Step: 10
Training loss: 2.8211861311376527
Validation loss: 3.0263220739183216

Epoch: 26| Step: 0
Training loss: 2.966408056781531
Validation loss: 3.0191056082687755

Epoch: 5| Step: 1
Training loss: 3.130674474519073
Validation loss: 3.021646681367913

Epoch: 5| Step: 2
Training loss: 3.6924067034650916
Validation loss: 3.0091282822262646

Epoch: 5| Step: 3
Training loss: 3.9080935591057226
Validation loss: 3.005663926678386

Epoch: 5| Step: 4
Training loss: 2.993346784033287
Validation loss: 3.0078572724185926

Epoch: 5| Step: 5
Training loss: 3.1806402255304977
Validation loss: 3.0083455527929526

Epoch: 5| Step: 6
Training loss: 3.0913710261746594
Validation loss: 3.0058608709530685

Epoch: 5| Step: 7
Training loss: 2.9127213815532746
Validation loss: 3.0007657523103597

Epoch: 5| Step: 8
Training loss: 3.342063407145773
Validation loss: 2.996610817274566

Epoch: 5| Step: 9
Training loss: 3.5015211886786615
Validation loss: 2.9958066876454295

Epoch: 5| Step: 10
Training loss: 3.3319770119871244
Validation loss: 3.0014776501181792

Epoch: 27| Step: 0
Training loss: 3.6607846562337434
Validation loss: 3.001023150541447

Epoch: 5| Step: 1
Training loss: 3.499035974981027
Validation loss: 2.9918322467276397

Epoch: 5| Step: 2
Training loss: 2.8127170055170856
Validation loss: 3.0046371142009636

Epoch: 5| Step: 3
Training loss: 3.041958485718207
Validation loss: 3.0107793858072514

Epoch: 5| Step: 4
Training loss: 3.367109612008826
Validation loss: 3.0093059827782853

Epoch: 5| Step: 5
Training loss: 2.8975078397682643
Validation loss: 3.007647651125715

Epoch: 5| Step: 6
Training loss: 3.638317768682813
Validation loss: 3.0143022560133246

Epoch: 5| Step: 7
Training loss: 3.415579801297039
Validation loss: 3.0109382197754813

Epoch: 5| Step: 8
Training loss: 3.448635445130529
Validation loss: 2.9947580948598036

Epoch: 5| Step: 9
Training loss: 3.5534853736551737
Validation loss: 3.0013544450130003

Epoch: 5| Step: 10
Training loss: 2.6286802378933083
Validation loss: 2.992581908926635

Epoch: 28| Step: 0
Training loss: 3.6166440749158637
Validation loss: 2.9855018124471435

Epoch: 5| Step: 1
Training loss: 3.1890364291196867
Validation loss: 2.982758670024791

Epoch: 5| Step: 2
Training loss: 3.432852360142814
Validation loss: 2.9884038994503928

Epoch: 5| Step: 3
Training loss: 3.502986451266803
Validation loss: 2.9990365795529366

Epoch: 5| Step: 4
Training loss: 3.3611825737480228
Validation loss: 3.004433463096918

Epoch: 5| Step: 5
Training loss: 3.37112345411667
Validation loss: 2.9819406929145797

Epoch: 5| Step: 6
Training loss: 3.104302029997214
Validation loss: 2.9781496885284997

Epoch: 5| Step: 7
Training loss: 2.4873169568062132
Validation loss: 2.983185443270601

Epoch: 5| Step: 8
Training loss: 3.4071989924812485
Validation loss: 2.984009474511025

Epoch: 5| Step: 9
Training loss: 2.871496968922185
Validation loss: 2.981187448455699

Epoch: 5| Step: 10
Training loss: 3.600542764014282
Validation loss: 2.984282861709063

Epoch: 29| Step: 0
Training loss: 2.9353564943671557
Validation loss: 2.9710422019318594

Epoch: 5| Step: 1
Training loss: 3.2091041398641402
Validation loss: 2.969235410874973

Epoch: 5| Step: 2
Training loss: 2.6934991458645747
Validation loss: 2.971151381335844

Epoch: 5| Step: 3
Training loss: 3.4364808392411677
Validation loss: 2.9974219138421136

Epoch: 5| Step: 4
Training loss: 3.417165921338904
Validation loss: 2.9719799465188608

Epoch: 5| Step: 5
Training loss: 3.3892940598660313
Validation loss: 2.967994846916098

Epoch: 5| Step: 6
Training loss: 4.105150959988789
Validation loss: 2.966396470973774

Epoch: 5| Step: 7
Training loss: 3.3934931424275248
Validation loss: 2.965331480971853

Epoch: 5| Step: 8
Training loss: 3.1783174379615065
Validation loss: 2.968228440380843

Epoch: 5| Step: 9
Training loss: 3.04019512654545
Validation loss: 2.9673373165882913

Epoch: 5| Step: 10
Training loss: 2.8425805338620926
Validation loss: 2.970502937543987

Epoch: 30| Step: 0
Training loss: 3.1337674557139206
Validation loss: 3.000835944853125

Epoch: 5| Step: 1
Training loss: 3.801705886011935
Validation loss: 2.962216944490252

Epoch: 5| Step: 2
Training loss: 2.9363415645582585
Validation loss: 2.970271055820296

Epoch: 5| Step: 3
Training loss: 3.18620408585916
Validation loss: 2.999337579544654

Epoch: 5| Step: 4
Training loss: 3.1329887511790795
Validation loss: 2.9727984351510175

Epoch: 5| Step: 5
Training loss: 3.0211362138816495
Validation loss: 2.9745909608459202

Epoch: 5| Step: 6
Training loss: 3.305896871417904
Validation loss: 2.987363557964558

Epoch: 5| Step: 7
Training loss: 3.2807861000196326
Validation loss: 2.985407771652654

Epoch: 5| Step: 8
Training loss: 3.3938484866076193
Validation loss: 2.9739812350775514

Epoch: 5| Step: 9
Training loss: 2.847916956140875
Validation loss: 2.9583537424421404

Epoch: 5| Step: 10
Training loss: 3.796936160250405
Validation loss: 2.9555183995042147

Epoch: 31| Step: 0
Training loss: 3.2073859925795505
Validation loss: 2.9584006758678

Epoch: 5| Step: 1
Training loss: 3.1114835251328024
Validation loss: 2.958226205589553

Epoch: 5| Step: 2
Training loss: 3.1266809138913554
Validation loss: 2.9573323643274643

Epoch: 5| Step: 3
Training loss: 2.7201402989836363
Validation loss: 2.9591332000893225

Epoch: 5| Step: 4
Training loss: 3.8730605409412835
Validation loss: 2.954506619415699

Epoch: 5| Step: 5
Training loss: 3.529258098716493
Validation loss: 2.95099613813692

Epoch: 5| Step: 6
Training loss: 3.217549813217677
Validation loss: 2.9519307498130867

Epoch: 5| Step: 7
Training loss: 3.3806083140822727
Validation loss: 2.9493742723265908

Epoch: 5| Step: 8
Training loss: 3.425106943507442
Validation loss: 2.947360367860917

Epoch: 5| Step: 9
Training loss: 2.6318766121914865
Validation loss: 2.9493497447130785

Epoch: 5| Step: 10
Training loss: 3.332110673465419
Validation loss: 2.9483819502538338

Epoch: 32| Step: 0
Training loss: 3.383370227957069
Validation loss: 2.9486572791660612

Epoch: 5| Step: 1
Training loss: 3.5962985083020333
Validation loss: 2.956514284260602

Epoch: 5| Step: 2
Training loss: 3.0258758727115866
Validation loss: 2.9494869847710032

Epoch: 5| Step: 3
Training loss: 3.0679378887787636
Validation loss: 2.9470357990197327

Epoch: 5| Step: 4
Training loss: 3.260505715678575
Validation loss: 2.9435672349785733

Epoch: 5| Step: 5
Training loss: 3.5545699886139643
Validation loss: 2.941497766012132

Epoch: 5| Step: 6
Training loss: 2.96671876182964
Validation loss: 2.9427040569779996

Epoch: 5| Step: 7
Training loss: 3.2953023187761312
Validation loss: 2.9383918762735997

Epoch: 5| Step: 8
Training loss: 3.2454112008981295
Validation loss: 2.9389957441571513

Epoch: 5| Step: 9
Training loss: 3.5101930148969096
Validation loss: 2.9387849394357892

Epoch: 5| Step: 10
Training loss: 2.4743992355713034
Validation loss: 2.9379576896156774

Epoch: 33| Step: 0
Training loss: 2.8205496141505844
Validation loss: 2.937819902241224

Epoch: 5| Step: 1
Training loss: 3.6202572017787977
Validation loss: 2.937290045383384

Epoch: 5| Step: 2
Training loss: 2.900969599725284
Validation loss: 2.937767867505826

Epoch: 5| Step: 3
Training loss: 2.6300427274532976
Validation loss: 2.943323561358671

Epoch: 5| Step: 4
Training loss: 3.747198202591749
Validation loss: 2.9495264071207887

Epoch: 5| Step: 5
Training loss: 3.7454452828497296
Validation loss: 2.9350033817242775

Epoch: 5| Step: 6
Training loss: 2.739638923883594
Validation loss: 2.9331732997374016

Epoch: 5| Step: 7
Training loss: 3.7694019670997143
Validation loss: 2.9320852905405497

Epoch: 5| Step: 8
Training loss: 3.612362900610625
Validation loss: 2.934235341163102

Epoch: 5| Step: 9
Training loss: 2.166597279635799
Validation loss: 2.9353196380894877

Epoch: 5| Step: 10
Training loss: 3.374457139048645
Validation loss: 2.933501893898258

Epoch: 34| Step: 0
Training loss: 3.282386365029049
Validation loss: 2.930607486565337

Epoch: 5| Step: 1
Training loss: 3.36281051620086
Validation loss: 2.92894440970899

Epoch: 5| Step: 2
Training loss: 2.637888737817239
Validation loss: 2.9266113503879243

Epoch: 5| Step: 3
Training loss: 3.01983822622962
Validation loss: 2.9259802302679834

Epoch: 5| Step: 4
Training loss: 3.0804050734050814
Validation loss: 2.9273730821296304

Epoch: 5| Step: 5
Training loss: 3.124986877413854
Validation loss: 2.930469181252575

Epoch: 5| Step: 6
Training loss: 3.2842598325970274
Validation loss: 2.9798110186498152

Epoch: 5| Step: 7
Training loss: 3.6036495359603635
Validation loss: 3.0591225398592754

Epoch: 5| Step: 8
Training loss: 3.266176314108556
Validation loss: 2.926791660066131

Epoch: 5| Step: 9
Training loss: 3.109867229510074
Validation loss: 2.9210742192885175

Epoch: 5| Step: 10
Training loss: 3.668384857462938
Validation loss: 2.9268840920069494

Epoch: 35| Step: 0
Training loss: 3.9537988623639877
Validation loss: 2.986774452620512

Epoch: 5| Step: 1
Training loss: 3.176994214084773
Validation loss: 2.9894810111999375

Epoch: 5| Step: 2
Training loss: 3.5511263605150307
Validation loss: 2.930042661953847

Epoch: 5| Step: 3
Training loss: 2.6623966680542566
Validation loss: 2.9216550373860315

Epoch: 5| Step: 4
Training loss: 3.343769536897145
Validation loss: 2.9203120015832273

Epoch: 5| Step: 5
Training loss: 3.326500007898883
Validation loss: 2.925535369376408

Epoch: 5| Step: 6
Training loss: 2.5485499204611473
Validation loss: 2.9452572752085224

Epoch: 5| Step: 7
Training loss: 3.320500626563823
Validation loss: 3.0058183443162374

Epoch: 5| Step: 8
Training loss: 3.6135416132968268
Validation loss: 2.9692917040824294

Epoch: 5| Step: 9
Training loss: 3.050717166320378
Validation loss: 2.9281787302103397

Epoch: 5| Step: 10
Training loss: 2.792213433843828
Validation loss: 2.9158654836793083

Epoch: 36| Step: 0
Training loss: 3.320065190697827
Validation loss: 2.913776083965354

Epoch: 5| Step: 1
Training loss: 3.0864791974124124
Validation loss: 2.914270640941738

Epoch: 5| Step: 2
Training loss: 3.6399830264439825
Validation loss: 2.928047915178249

Epoch: 5| Step: 3
Training loss: 3.0801868020419856
Validation loss: 2.908745303001493

Epoch: 5| Step: 4
Training loss: 3.1822635797154972
Validation loss: 2.912374732006378

Epoch: 5| Step: 5
Training loss: 3.0462620827830875
Validation loss: 2.924351747399145

Epoch: 5| Step: 6
Training loss: 2.995330991971479
Validation loss: 2.9735378264556562

Epoch: 5| Step: 7
Training loss: 3.0056017392837573
Validation loss: 3.0278087077637466

Epoch: 5| Step: 8
Training loss: 3.5046045804599495
Validation loss: 2.9909339253095184

Epoch: 5| Step: 9
Training loss: 2.7627729807481205
Validation loss: 2.9118110923951543

Epoch: 5| Step: 10
Training loss: 3.8415682423548
Validation loss: 2.9085608178459275

Epoch: 37| Step: 0
Training loss: 3.668029849647529
Validation loss: 2.9209473155953916

Epoch: 5| Step: 1
Training loss: 3.1933441441723938
Validation loss: 2.910016788571951

Epoch: 5| Step: 2
Training loss: 3.569311623549199
Validation loss: 2.9022271290729433

Epoch: 5| Step: 3
Training loss: 3.3802907940524816
Validation loss: 2.9048319168718795

Epoch: 5| Step: 4
Training loss: 3.786607588074319
Validation loss: 2.9142262252995383

Epoch: 5| Step: 5
Training loss: 2.913243237403688
Validation loss: 2.9417943065102357

Epoch: 5| Step: 6
Training loss: 3.262180099296196
Validation loss: 2.913752066145014

Epoch: 5| Step: 7
Training loss: 2.4661308591576696
Validation loss: 2.911292994418472

Epoch: 5| Step: 8
Training loss: 2.6419409006859493
Validation loss: 2.9134517994068347

Epoch: 5| Step: 9
Training loss: 2.9869102374734386
Validation loss: 2.907698740470772

Epoch: 5| Step: 10
Training loss: 3.12716508250637
Validation loss: 2.907747232985099

Epoch: 38| Step: 0
Training loss: 3.678320110270198
Validation loss: 2.909917527867381

Epoch: 5| Step: 1
Training loss: 2.9670406841578285
Validation loss: 2.905633040319748

Epoch: 5| Step: 2
Training loss: 2.8789347384530073
Validation loss: 2.897442647090697

Epoch: 5| Step: 3
Training loss: 2.837401461465725
Validation loss: 2.897489416938038

Epoch: 5| Step: 4
Training loss: 3.375481606488862
Validation loss: 2.8944843898402834

Epoch: 5| Step: 5
Training loss: 2.9808510951308476
Validation loss: 2.8952842316335143

Epoch: 5| Step: 6
Training loss: 2.7908381091312684
Validation loss: 2.8970847257037247

Epoch: 5| Step: 7
Training loss: 3.6039607406323855
Validation loss: 2.8984108041826864

Epoch: 5| Step: 8
Training loss: 3.153351614363453
Validation loss: 2.8976908672588055

Epoch: 5| Step: 9
Training loss: 3.391280150513245
Validation loss: 2.8992598180610303

Epoch: 5| Step: 10
Training loss: 3.3701548235728094
Validation loss: 2.898852585583359

Epoch: 39| Step: 0
Training loss: 3.553792652219009
Validation loss: 2.897565730860889

Epoch: 5| Step: 1
Training loss: 3.3944246299513576
Validation loss: 2.8914920658305308

Epoch: 5| Step: 2
Training loss: 3.415407522525222
Validation loss: 2.8880610310866928

Epoch: 5| Step: 3
Training loss: 3.3251855612008265
Validation loss: 2.885666095713283

Epoch: 5| Step: 4
Training loss: 2.9405835788254033
Validation loss: 2.885297587488869

Epoch: 5| Step: 5
Training loss: 2.90684142299002
Validation loss: 2.886298553995368

Epoch: 5| Step: 6
Training loss: 3.2731910193972626
Validation loss: 2.88598060331655

Epoch: 5| Step: 7
Training loss: 2.7482195205518227
Validation loss: 2.881796653118602

Epoch: 5| Step: 8
Training loss: 3.3801095220213466
Validation loss: 2.881565326995098

Epoch: 5| Step: 9
Training loss: 2.8175769335745438
Validation loss: 2.8803197216153853

Epoch: 5| Step: 10
Training loss: 3.2281998366242237
Validation loss: 2.880850355086572

Epoch: 40| Step: 0
Training loss: 4.152838662224644
Validation loss: 2.8772693040335082

Epoch: 5| Step: 1
Training loss: 2.9354882351823592
Validation loss: 2.876020643591198

Epoch: 5| Step: 2
Training loss: 3.285858405844177
Validation loss: 2.8756082559238902

Epoch: 5| Step: 3
Training loss: 2.8536904116343984
Validation loss: 2.874472992021335

Epoch: 5| Step: 4
Training loss: 3.43654855218693
Validation loss: 2.873253754347784

Epoch: 5| Step: 5
Training loss: 2.6595570341715695
Validation loss: 2.8706577773917346

Epoch: 5| Step: 6
Training loss: 3.2250044711769514
Validation loss: 2.868736624480434

Epoch: 5| Step: 7
Training loss: 2.9069603492806775
Validation loss: 2.867704259242282

Epoch: 5| Step: 8
Training loss: 3.178319838411367
Validation loss: 2.866674908008257

Epoch: 5| Step: 9
Training loss: 3.111518619354753
Validation loss: 2.864354323614091

Epoch: 5| Step: 10
Training loss: 2.8794353935676313
Validation loss: 2.863234573201145

Epoch: 41| Step: 0
Training loss: 2.961908427861027
Validation loss: 2.862323832084979

Epoch: 5| Step: 1
Training loss: 2.9800538740472664
Validation loss: 2.861183386777614

Epoch: 5| Step: 2
Training loss: 3.4006850954847825
Validation loss: 2.863660452434691

Epoch: 5| Step: 3
Training loss: 3.6512043363908164
Validation loss: 2.863827046693614

Epoch: 5| Step: 4
Training loss: 3.4028855252669445
Validation loss: 2.8685258266291274

Epoch: 5| Step: 5
Training loss: 3.025216301364903
Validation loss: 2.865422717009285

Epoch: 5| Step: 6
Training loss: 3.284987001901398
Validation loss: 2.86389312095599

Epoch: 5| Step: 7
Training loss: 3.060638484788805
Validation loss: 2.8577310718407363

Epoch: 5| Step: 8
Training loss: 3.612790032066062
Validation loss: 2.856854733978533

Epoch: 5| Step: 9
Training loss: 2.680937806207364
Validation loss: 2.8578654248849227

Epoch: 5| Step: 10
Training loss: 2.4069483350558594
Validation loss: 2.856207682279759

Epoch: 42| Step: 0
Training loss: 3.051634372503499
Validation loss: 2.856579639861787

Epoch: 5| Step: 1
Training loss: 3.460374911288134
Validation loss: 2.8560274952042124

Epoch: 5| Step: 2
Training loss: 3.5427750741664723
Validation loss: 2.855547261554904

Epoch: 5| Step: 3
Training loss: 2.50558429733486
Validation loss: 2.8530941618725825

Epoch: 5| Step: 4
Training loss: 4.037081027658097
Validation loss: 2.852541392886125

Epoch: 5| Step: 5
Training loss: 2.78036356311928
Validation loss: 2.8505649729516858

Epoch: 5| Step: 6
Training loss: 3.026093019103364
Validation loss: 2.850062046480242

Epoch: 5| Step: 7
Training loss: 2.3132667301421845
Validation loss: 2.8516555678794706

Epoch: 5| Step: 8
Training loss: 3.248770261072413
Validation loss: 2.854490630181296

Epoch: 5| Step: 9
Training loss: 3.3639231566589403
Validation loss: 2.8589373309135335

Epoch: 5| Step: 10
Training loss: 3.0114098376857066
Validation loss: 2.8714339069781847

Epoch: 43| Step: 0
Training loss: 2.503830264362346
Validation loss: 2.8537224793042424

Epoch: 5| Step: 1
Training loss: 3.0151205480968195
Validation loss: 2.8485314919922526

Epoch: 5| Step: 2
Training loss: 3.4745743799618403
Validation loss: 2.8474557930015534

Epoch: 5| Step: 3
Training loss: 2.7946295222108337
Validation loss: 2.845854173554934

Epoch: 5| Step: 4
Training loss: 3.6264532399020792
Validation loss: 2.846483130827882

Epoch: 5| Step: 5
Training loss: 3.4140422480002166
Validation loss: 2.8472695102027865

Epoch: 5| Step: 6
Training loss: 3.3186279331898225
Validation loss: 2.845555155008444

Epoch: 5| Step: 7
Training loss: 3.0871576528673144
Validation loss: 2.8464423804319865

Epoch: 5| Step: 8
Training loss: 2.6769562529052022
Validation loss: 2.8442589035036514

Epoch: 5| Step: 9
Training loss: 3.520754856536686
Validation loss: 2.8459881702769567

Epoch: 5| Step: 10
Training loss: 2.9910336652702165
Validation loss: 2.844854363766461

Epoch: 44| Step: 0
Training loss: 3.3170207142957944
Validation loss: 2.8443915828743713

Epoch: 5| Step: 1
Training loss: 3.2901406593748663
Validation loss: 2.8453021217015415

Epoch: 5| Step: 2
Training loss: 2.934287729478845
Validation loss: 2.845385006043642

Epoch: 5| Step: 3
Training loss: 3.2152800883831145
Validation loss: 2.8428569691008265

Epoch: 5| Step: 4
Training loss: 3.535351961735517
Validation loss: 2.8400278659856166

Epoch: 5| Step: 5
Training loss: 2.9358018877299985
Validation loss: 2.8403497286271406

Epoch: 5| Step: 6
Training loss: 3.4733940859684247
Validation loss: 2.8386187158073315

Epoch: 5| Step: 7
Training loss: 2.7911005347585376
Validation loss: 2.8382673012225714

Epoch: 5| Step: 8
Training loss: 3.266336755896042
Validation loss: 2.8369838287578415

Epoch: 5| Step: 9
Training loss: 2.6581414164402393
Validation loss: 2.837528514804615

Epoch: 5| Step: 10
Training loss: 3.0959301597544395
Validation loss: 2.8354362569815748

Epoch: 45| Step: 0
Training loss: 2.392797741833855
Validation loss: 2.8331220416547533

Epoch: 5| Step: 1
Training loss: 2.997725260131337
Validation loss: 2.8348799929105133

Epoch: 5| Step: 2
Training loss: 3.136538755732334
Validation loss: 2.83451951861635

Epoch: 5| Step: 3
Training loss: 3.420499202813495
Validation loss: 2.8335579041789036

Epoch: 5| Step: 4
Training loss: 4.205416483716407
Validation loss: 2.8312978406025855

Epoch: 5| Step: 5
Training loss: 3.1053158128614586
Validation loss: 2.832866418200704

Epoch: 5| Step: 6
Training loss: 3.4477729575334886
Validation loss: 2.8320866785222782

Epoch: 5| Step: 7
Training loss: 3.137592122826616
Validation loss: 2.8328243379915854

Epoch: 5| Step: 8
Training loss: 2.6527280009483407
Validation loss: 2.8366666985355815

Epoch: 5| Step: 9
Training loss: 2.177207383510861
Validation loss: 2.831196922031628

Epoch: 5| Step: 10
Training loss: 3.3929526781671653
Validation loss: 2.8334936721524873

Epoch: 46| Step: 0
Training loss: 3.1302487354347606
Validation loss: 2.831817521576008

Epoch: 5| Step: 1
Training loss: 2.998723871292955
Validation loss: 2.831388669945241

Epoch: 5| Step: 2
Training loss: 2.969489557605322
Validation loss: 2.8279361139417007

Epoch: 5| Step: 3
Training loss: 2.7554788630932396
Validation loss: 2.825976003828486

Epoch: 5| Step: 4
Training loss: 2.810476719747458
Validation loss: 2.8248057013559307

Epoch: 5| Step: 5
Training loss: 3.3960650000310704
Validation loss: 2.825020979359537

Epoch: 5| Step: 6
Training loss: 3.451126417844023
Validation loss: 2.831067272703146

Epoch: 5| Step: 7
Training loss: 3.1813029466581026
Validation loss: 2.824223847832034

Epoch: 5| Step: 8
Training loss: 3.2347201103340777
Validation loss: 2.822523284833211

Epoch: 5| Step: 9
Training loss: 3.5920119353438045
Validation loss: 2.819916726334992

Epoch: 5| Step: 10
Training loss: 2.871359967196426
Validation loss: 2.819394541698079

Epoch: 47| Step: 0
Training loss: 2.6626951226745237
Validation loss: 2.821381131791597

Epoch: 5| Step: 1
Training loss: 3.082946100061399
Validation loss: 2.82197308255247

Epoch: 5| Step: 2
Training loss: 3.5072360850183277
Validation loss: 2.8259665365865665

Epoch: 5| Step: 3
Training loss: 2.6765044856868547
Validation loss: 2.83709750475554

Epoch: 5| Step: 4
Training loss: 2.9646446352152145
Validation loss: 2.8491061655704004

Epoch: 5| Step: 5
Training loss: 3.5832795575268945
Validation loss: 2.8311766723273033

Epoch: 5| Step: 6
Training loss: 3.2467990664432014
Validation loss: 2.819130943253172

Epoch: 5| Step: 7
Training loss: 2.9815443105595594
Validation loss: 2.817211069411102

Epoch: 5| Step: 8
Training loss: 3.0821630645529026
Validation loss: 2.821868839751637

Epoch: 5| Step: 9
Training loss: 2.9296774088367874
Validation loss: 2.8264818954178335

Epoch: 5| Step: 10
Training loss: 3.737972171008354
Validation loss: 2.827868150636815

Epoch: 48| Step: 0
Training loss: 2.800877440435467
Validation loss: 2.822309245144932

Epoch: 5| Step: 1
Training loss: 3.8279031494628337
Validation loss: 2.8197848755030384

Epoch: 5| Step: 2
Training loss: 2.9935868380050787
Validation loss: 2.818647156403051

Epoch: 5| Step: 3
Training loss: 3.491074352660399
Validation loss: 2.8176123056229754

Epoch: 5| Step: 4
Training loss: 3.683232310939354
Validation loss: 2.8179855994234737

Epoch: 5| Step: 5
Training loss: 2.325587483497901
Validation loss: 2.816876108598855

Epoch: 5| Step: 6
Training loss: 3.5251371424625377
Validation loss: 2.8165794529682624

Epoch: 5| Step: 7
Training loss: 2.551319573746655
Validation loss: 2.812827034079294

Epoch: 5| Step: 8
Training loss: 2.824108242970066
Validation loss: 2.812032434207687

Epoch: 5| Step: 9
Training loss: 3.0239563331680612
Validation loss: 2.8117762975579073

Epoch: 5| Step: 10
Training loss: 3.0428253649325736
Validation loss: 2.811579399798722

Epoch: 49| Step: 0
Training loss: 3.339557907632778
Validation loss: 2.809925935017522

Epoch: 5| Step: 1
Training loss: 3.497765372667796
Validation loss: 2.809315541943455

Epoch: 5| Step: 2
Training loss: 2.673647198013796
Validation loss: 2.8102688077905613

Epoch: 5| Step: 3
Training loss: 3.738657518860876
Validation loss: 2.8283585568840333

Epoch: 5| Step: 4
Training loss: 2.4973465189011175
Validation loss: 2.821229938807936

Epoch: 5| Step: 5
Training loss: 3.323663434310513
Validation loss: 2.8152620378042155

Epoch: 5| Step: 6
Training loss: 2.9893702698035503
Validation loss: 2.8112680013345615

Epoch: 5| Step: 7
Training loss: 2.8167570321599724
Validation loss: 2.805867620310588

Epoch: 5| Step: 8
Training loss: 2.9526392623009756
Validation loss: 2.8034395619105483

Epoch: 5| Step: 9
Training loss: 2.9805372237792946
Validation loss: 2.8035501680953923

Epoch: 5| Step: 10
Training loss: 3.302048082293891
Validation loss: 2.8008955312640014

Epoch: 50| Step: 0
Training loss: 3.0593684787700224
Validation loss: 2.8007488004287753

Epoch: 5| Step: 1
Training loss: 2.9764199210233504
Validation loss: 2.798558847299378

Epoch: 5| Step: 2
Training loss: 3.0981958984733975
Validation loss: 2.7984383272722537

Epoch: 5| Step: 3
Training loss: 3.313964088342057
Validation loss: 2.803503617455073

Epoch: 5| Step: 4
Training loss: 3.0266188018083744
Validation loss: 2.8060444631216472

Epoch: 5| Step: 5
Training loss: 2.952256493794428
Validation loss: 2.8003037170415017

Epoch: 5| Step: 6
Training loss: 3.4633522995352064
Validation loss: 2.7944804101536875

Epoch: 5| Step: 7
Training loss: 3.453164355023545
Validation loss: 2.794355252739459

Epoch: 5| Step: 8
Training loss: 2.4861319225536547
Validation loss: 2.794597056249951

Epoch: 5| Step: 9
Training loss: 3.117980397278421
Validation loss: 2.791975762476039

Epoch: 5| Step: 10
Training loss: 3.15736777275651
Validation loss: 2.793891507507325

Epoch: 51| Step: 0
Training loss: 2.7415776022809593
Validation loss: 2.7908600633857965

Epoch: 5| Step: 1
Training loss: 3.4010353419355592
Validation loss: 2.7916286721825245

Epoch: 5| Step: 2
Training loss: 2.7274517369043094
Validation loss: 2.793325895041639

Epoch: 5| Step: 3
Training loss: 3.043191101020694
Validation loss: 2.7939443875892023

Epoch: 5| Step: 4
Training loss: 3.4335879172838686
Validation loss: 2.7930189196309203

Epoch: 5| Step: 5
Training loss: 2.5561723506111735
Validation loss: 2.791063520586505

Epoch: 5| Step: 6
Training loss: 2.879598671448151
Validation loss: 2.7915418710549753

Epoch: 5| Step: 7
Training loss: 3.5787909941568814
Validation loss: 2.787203354246366

Epoch: 5| Step: 8
Training loss: 3.8414654649410767
Validation loss: 2.7881644725936043

Epoch: 5| Step: 9
Training loss: 2.9709673180312115
Validation loss: 2.7898071633279744

Epoch: 5| Step: 10
Training loss: 2.6060986079240425
Validation loss: 2.788825922436324

Epoch: 52| Step: 0
Training loss: 3.151469018293945
Validation loss: 2.798237277092084

Epoch: 5| Step: 1
Training loss: 3.4369066593302664
Validation loss: 2.7874092075124706

Epoch: 5| Step: 2
Training loss: 2.886043072036081
Validation loss: 2.7868252720861024

Epoch: 5| Step: 3
Training loss: 2.953834569546102
Validation loss: 2.786056377011876

Epoch: 5| Step: 4
Training loss: 2.9906256760424066
Validation loss: 2.784257191030804

Epoch: 5| Step: 5
Training loss: 3.3037107931661955
Validation loss: 2.789618583098137

Epoch: 5| Step: 6
Training loss: 3.1308199284496454
Validation loss: 2.7885136755864606

Epoch: 5| Step: 7
Training loss: 2.8855040682742668
Validation loss: 2.7845910727749112

Epoch: 5| Step: 8
Training loss: 2.8665903909279318
Validation loss: 2.7855648469430943

Epoch: 5| Step: 9
Training loss: 3.11200667918452
Validation loss: 2.7830559670864967

Epoch: 5| Step: 10
Training loss: 3.432640802728156
Validation loss: 2.784328325498969

Epoch: 53| Step: 0
Training loss: 3.352568219861192
Validation loss: 2.782277543182694

Epoch: 5| Step: 1
Training loss: 2.757141723321982
Validation loss: 2.780277509411994

Epoch: 5| Step: 2
Training loss: 2.9690333181010518
Validation loss: 2.7811115742481407

Epoch: 5| Step: 3
Training loss: 3.351266274332658
Validation loss: 2.780741830553537

Epoch: 5| Step: 4
Training loss: 3.0402721361023026
Validation loss: 2.7786556549379986

Epoch: 5| Step: 5
Training loss: 3.5034733295386413
Validation loss: 2.779456930925053

Epoch: 5| Step: 6
Training loss: 2.7423402575251696
Validation loss: 2.779676556650556

Epoch: 5| Step: 7
Training loss: 3.116451166899842
Validation loss: 2.7815296115040105

Epoch: 5| Step: 8
Training loss: 2.797439092087259
Validation loss: 2.7803780328484695

Epoch: 5| Step: 9
Training loss: 3.4242122106121964
Validation loss: 2.7813372006675787

Epoch: 5| Step: 10
Training loss: 2.87388539476926
Validation loss: 2.7852802054291677

Epoch: 54| Step: 0
Training loss: 2.679027331473037
Validation loss: 2.77780984528466

Epoch: 5| Step: 1
Training loss: 2.9052921480489937
Validation loss: 2.777996895122498

Epoch: 5| Step: 2
Training loss: 3.125691146715126
Validation loss: 2.776799622320462

Epoch: 5| Step: 3
Training loss: 3.052800759285007
Validation loss: 2.77801724731352

Epoch: 5| Step: 4
Training loss: 2.9069692070441895
Validation loss: 2.781544499131377

Epoch: 5| Step: 5
Training loss: 2.713689632860109
Validation loss: 2.784747002999685

Epoch: 5| Step: 6
Training loss: 3.081899739252985
Validation loss: 2.774580101949307

Epoch: 5| Step: 7
Training loss: 3.274559975685709
Validation loss: 2.772428621576671

Epoch: 5| Step: 8
Training loss: 3.2686818978270322
Validation loss: 2.7710534716960167

Epoch: 5| Step: 9
Training loss: 3.8017433885466807
Validation loss: 2.7716948864245077

Epoch: 5| Step: 10
Training loss: 3.0288447639732294
Validation loss: 2.7687878537158093

Epoch: 55| Step: 0
Training loss: 2.75065076237363
Validation loss: 2.7676824507674693

Epoch: 5| Step: 1
Training loss: 2.6918448878318535
Validation loss: 2.768500581656713

Epoch: 5| Step: 2
Training loss: 3.4681362949502956
Validation loss: 2.7681777414196915

Epoch: 5| Step: 3
Training loss: 3.2576608599675403
Validation loss: 2.767638982098413

Epoch: 5| Step: 4
Training loss: 2.8476472077402737
Validation loss: 2.767871340919426

Epoch: 5| Step: 5
Training loss: 3.129637672000996
Validation loss: 2.7665326363865548

Epoch: 5| Step: 6
Training loss: 3.3130558915010715
Validation loss: 2.764029224459582

Epoch: 5| Step: 7
Training loss: 3.2670308422621286
Validation loss: 2.7646013380053325

Epoch: 5| Step: 8
Training loss: 2.658932486989362
Validation loss: 2.76597685209781

Epoch: 5| Step: 9
Training loss: 3.052674081198402
Validation loss: 2.774017527529464

Epoch: 5| Step: 10
Training loss: 3.4747803652944933
Validation loss: 2.7841072849589072

Epoch: 56| Step: 0
Training loss: 2.9153907346496717
Validation loss: 2.77542755445771

Epoch: 5| Step: 1
Training loss: 2.95939962664854
Validation loss: 2.7680960108925516

Epoch: 5| Step: 2
Training loss: 3.2514002791142795
Validation loss: 2.7666118259334467

Epoch: 5| Step: 3
Training loss: 2.6729866972084557
Validation loss: 2.7621083418248586

Epoch: 5| Step: 4
Training loss: 3.4288775415233457
Validation loss: 2.7620279566886055

Epoch: 5| Step: 5
Training loss: 3.2611722385527013
Validation loss: 2.764236877702822

Epoch: 5| Step: 6
Training loss: 3.472581276872768
Validation loss: 2.7658817669614657

Epoch: 5| Step: 7
Training loss: 2.842049226338566
Validation loss: 2.766355856990846

Epoch: 5| Step: 8
Training loss: 2.8760193386037844
Validation loss: 2.7696935298737353

Epoch: 5| Step: 9
Training loss: 3.3453783010098688
Validation loss: 2.7696129844551916

Epoch: 5| Step: 10
Training loss: 2.726363822453418
Validation loss: 2.7714883127492187

Epoch: 57| Step: 0
Training loss: 2.663713807138051
Validation loss: 2.7664772612918815

Epoch: 5| Step: 1
Training loss: 2.37419375738789
Validation loss: 2.7572904437367867

Epoch: 5| Step: 2
Training loss: 3.3951607878733365
Validation loss: 2.7605590102554327

Epoch: 5| Step: 3
Training loss: 2.7154925771719625
Validation loss: 2.7657894908055143

Epoch: 5| Step: 4
Training loss: 2.551531414115934
Validation loss: 2.764155396071086

Epoch: 5| Step: 5
Training loss: 3.544654184538157
Validation loss: 2.7607209882815305

Epoch: 5| Step: 6
Training loss: 3.442834494967949
Validation loss: 2.7571015939348005

Epoch: 5| Step: 7
Training loss: 2.948266771282897
Validation loss: 2.7523839132127086

Epoch: 5| Step: 8
Training loss: 3.1170830195229233
Validation loss: 2.753011611265267

Epoch: 5| Step: 9
Training loss: 3.27411449778851
Validation loss: 2.753410219861363

Epoch: 5| Step: 10
Training loss: 3.609838943058848
Validation loss: 2.75067531613088

Epoch: 58| Step: 0
Training loss: 2.6809017888954605
Validation loss: 2.7502649241169648

Epoch: 5| Step: 1
Training loss: 2.794938509269813
Validation loss: 2.750789001504062

Epoch: 5| Step: 2
Training loss: 2.950150864186434
Validation loss: 2.7507182597479587

Epoch: 5| Step: 3
Training loss: 2.9444721348578087
Validation loss: 2.7483372084692164

Epoch: 5| Step: 4
Training loss: 3.5420204584272916
Validation loss: 2.751097979199519

Epoch: 5| Step: 5
Training loss: 3.547048421644842
Validation loss: 2.748102044954727

Epoch: 5| Step: 6
Training loss: 3.365272490761001
Validation loss: 2.750784307189488

Epoch: 5| Step: 7
Training loss: 2.7383935663150476
Validation loss: 2.7528658576483473

Epoch: 5| Step: 8
Training loss: 3.0200441228409645
Validation loss: 2.7532999649425367

Epoch: 5| Step: 9
Training loss: 3.2297474656722933
Validation loss: 2.7734851593308703

Epoch: 5| Step: 10
Training loss: 2.7770911851692284
Validation loss: 2.746365204348339

Epoch: 59| Step: 0
Training loss: 2.416279290382397
Validation loss: 2.7480735752731444

Epoch: 5| Step: 1
Training loss: 3.9454519719314014
Validation loss: 2.7546106702895625

Epoch: 5| Step: 2
Training loss: 2.9340381107988556
Validation loss: 2.769163636359136

Epoch: 5| Step: 3
Training loss: 3.1564654286203098
Validation loss: 2.800968637523743

Epoch: 5| Step: 4
Training loss: 3.5100278252262194
Validation loss: 2.769200751618992

Epoch: 5| Step: 5
Training loss: 3.08947458485245
Validation loss: 2.7489463003087686

Epoch: 5| Step: 6
Training loss: 3.4160644806933727
Validation loss: 2.7460547530950308

Epoch: 5| Step: 7
Training loss: 2.7440685113411587
Validation loss: 2.744799614388673

Epoch: 5| Step: 8
Training loss: 2.864129787722262
Validation loss: 2.7470043129489405

Epoch: 5| Step: 9
Training loss: 2.929484856272912
Validation loss: 2.7476693416973554

Epoch: 5| Step: 10
Training loss: 2.584428421815271
Validation loss: 2.756607237567328

Epoch: 60| Step: 0
Training loss: 3.0327220370653096
Validation loss: 2.7656305061731854

Epoch: 5| Step: 1
Training loss: 2.904977006936137
Validation loss: 2.7565582489952907

Epoch: 5| Step: 2
Training loss: 3.331959981927603
Validation loss: 2.7569938615219582

Epoch: 5| Step: 3
Training loss: 3.0444385666183322
Validation loss: 2.752213675030216

Epoch: 5| Step: 4
Training loss: 3.464486741313539
Validation loss: 2.750089209518213

Epoch: 5| Step: 5
Training loss: 2.5113573541095824
Validation loss: 2.739823239665963

Epoch: 5| Step: 6
Training loss: 2.9241669992957835
Validation loss: 2.7404033376165913

Epoch: 5| Step: 7
Training loss: 2.991041955212972
Validation loss: 2.7401905869225653

Epoch: 5| Step: 8
Training loss: 3.07760910125886
Validation loss: 2.7379696068476336

Epoch: 5| Step: 9
Training loss: 2.770632074451601
Validation loss: 2.737267527493519

Epoch: 5| Step: 10
Training loss: 3.58459673647156
Validation loss: 2.732773946644232

Epoch: 61| Step: 0
Training loss: 3.499724377270003
Validation loss: 2.733103096239428

Epoch: 5| Step: 1
Training loss: 3.45681510292679
Validation loss: 2.7398370233636338

Epoch: 5| Step: 2
Training loss: 2.7952087383085638
Validation loss: 2.7378882461300686

Epoch: 5| Step: 3
Training loss: 2.5759638195458754
Validation loss: 2.7469031253655154

Epoch: 5| Step: 4
Training loss: 3.0817143769299196
Validation loss: 2.769840569343605

Epoch: 5| Step: 5
Training loss: 2.7333993969663823
Validation loss: 2.7877301571802784

Epoch: 5| Step: 6
Training loss: 3.49124521945581
Validation loss: 2.820998309024878

Epoch: 5| Step: 7
Training loss: 2.589253307947777
Validation loss: 2.7635011428987415

Epoch: 5| Step: 8
Training loss: 3.1459043549526826
Validation loss: 2.734212395071285

Epoch: 5| Step: 9
Training loss: 3.3228257664093035
Validation loss: 2.7279485297770862

Epoch: 5| Step: 10
Training loss: 2.6542665144395907
Validation loss: 2.731349602472224

Epoch: 62| Step: 0
Training loss: 2.6089565832488644
Validation loss: 2.735160523074338

Epoch: 5| Step: 1
Training loss: 3.212216458999576
Validation loss: 2.7372443163990208

Epoch: 5| Step: 2
Training loss: 3.2752652766991965
Validation loss: 2.743224479950263

Epoch: 5| Step: 3
Training loss: 2.567075970038617
Validation loss: 2.7454143467855117

Epoch: 5| Step: 4
Training loss: 2.929103782995341
Validation loss: 2.7477214076590126

Epoch: 5| Step: 5
Training loss: 2.6364927746047804
Validation loss: 2.739764434307252

Epoch: 5| Step: 6
Training loss: 2.956782422500233
Validation loss: 2.7374159912368827

Epoch: 5| Step: 7
Training loss: 3.1422051397480066
Validation loss: 2.73270600886285

Epoch: 5| Step: 8
Training loss: 3.6569725692008146
Validation loss: 2.7299194806876566

Epoch: 5| Step: 9
Training loss: 3.2985275971844175
Validation loss: 2.7265004373883155

Epoch: 5| Step: 10
Training loss: 3.352447890773481
Validation loss: 2.7226133599911257

Epoch: 63| Step: 0
Training loss: 2.6389860224554216
Validation loss: 2.7220644061386894

Epoch: 5| Step: 1
Training loss: 2.7659992891477607
Validation loss: 2.7218576072268186

Epoch: 5| Step: 2
Training loss: 3.059585897562444
Validation loss: 2.725997951450673

Epoch: 5| Step: 3
Training loss: 2.752973596088066
Validation loss: 2.730141189942155

Epoch: 5| Step: 4
Training loss: 3.1145298845857203
Validation loss: 2.7446435872561756

Epoch: 5| Step: 5
Training loss: 3.369229222114082
Validation loss: 2.756254946033835

Epoch: 5| Step: 6
Training loss: 3.1597359923643733
Validation loss: 2.7702837267950575

Epoch: 5| Step: 7
Training loss: 3.5634281221015636
Validation loss: 2.776422850106993

Epoch: 5| Step: 8
Training loss: 3.357810432358891
Validation loss: 2.743968515082687

Epoch: 5| Step: 9
Training loss: 3.271030460580863
Validation loss: 2.716911360863989

Epoch: 5| Step: 10
Training loss: 2.3190058358839925
Validation loss: 2.7160608988221653

Epoch: 64| Step: 0
Training loss: 3.0307841778736275
Validation loss: 2.72107222534608

Epoch: 5| Step: 1
Training loss: 3.1575921859029843
Validation loss: 2.720732043154374

Epoch: 5| Step: 2
Training loss: 2.9537226965211776
Validation loss: 2.7229041485458243

Epoch: 5| Step: 3
Training loss: 2.833049554264186
Validation loss: 2.7240985503381645

Epoch: 5| Step: 4
Training loss: 2.3389246796169787
Validation loss: 2.722531802139722

Epoch: 5| Step: 5
Training loss: 3.112039469157288
Validation loss: 2.719509048499259

Epoch: 5| Step: 6
Training loss: 2.8831899339006943
Validation loss: 2.721018457624831

Epoch: 5| Step: 7
Training loss: 2.9756649396203434
Validation loss: 2.7184325681048476

Epoch: 5| Step: 8
Training loss: 2.8900875107342596
Validation loss: 2.718785211346645

Epoch: 5| Step: 9
Training loss: 3.8208360683773877
Validation loss: 2.715041430230173

Epoch: 5| Step: 10
Training loss: 3.5084377487724816
Validation loss: 2.717059308354027

Epoch: 65| Step: 0
Training loss: 2.7946145923739945
Validation loss: 2.7153293909745417

Epoch: 5| Step: 1
Training loss: 3.0989682664899014
Validation loss: 2.7153139014326952

Epoch: 5| Step: 2
Training loss: 2.5756681816037705
Validation loss: 2.716469753899009

Epoch: 5| Step: 3
Training loss: 3.195573940633919
Validation loss: 2.7137569395399335

Epoch: 5| Step: 4
Training loss: 3.647895070173094
Validation loss: 2.7120772859406195

Epoch: 5| Step: 5
Training loss: 2.738517892491769
Validation loss: 2.713283432448762

Epoch: 5| Step: 6
Training loss: 3.1170632856282094
Validation loss: 2.71344979430845

Epoch: 5| Step: 7
Training loss: 3.5033566863651515
Validation loss: 2.714271909296367

Epoch: 5| Step: 8
Training loss: 2.9972855685468054
Validation loss: 2.714579057836889

Epoch: 5| Step: 9
Training loss: 2.9630988694740377
Validation loss: 2.7108899571852105

Epoch: 5| Step: 10
Training loss: 2.6812490467701178
Validation loss: 2.710430142588104

Epoch: 66| Step: 0
Training loss: 3.184801642500706
Validation loss: 2.7109555961986267

Epoch: 5| Step: 1
Training loss: 3.2696435469252907
Validation loss: 2.71264288306549

Epoch: 5| Step: 2
Training loss: 3.132195086058483
Validation loss: 2.7155445416378323

Epoch: 5| Step: 3
Training loss: 2.928933171117775
Validation loss: 2.713662692526915

Epoch: 5| Step: 4
Training loss: 3.1870263439630144
Validation loss: 2.714350632561918

Epoch: 5| Step: 5
Training loss: 2.914928808635233
Validation loss: 2.716891273722251

Epoch: 5| Step: 6
Training loss: 2.1243404037922176
Validation loss: 2.7114920223221493

Epoch: 5| Step: 7
Training loss: 3.171089262957992
Validation loss: 2.716336957968908

Epoch: 5| Step: 8
Training loss: 3.4559930136751276
Validation loss: 2.7109344852160406

Epoch: 5| Step: 9
Training loss: 3.025172797698111
Validation loss: 2.7062813898248943

Epoch: 5| Step: 10
Training loss: 2.821474971700117
Validation loss: 2.709667024779269

Epoch: 67| Step: 0
Training loss: 3.3019901747854856
Validation loss: 2.7088410109138854

Epoch: 5| Step: 1
Training loss: 3.0137418094810093
Validation loss: 2.715041521821091

Epoch: 5| Step: 2
Training loss: 3.0637729101363327
Validation loss: 2.7011387764207844

Epoch: 5| Step: 3
Training loss: 2.6421585595764063
Validation loss: 2.7032357413166417

Epoch: 5| Step: 4
Training loss: 2.4842968814492004
Validation loss: 2.7036445806383695

Epoch: 5| Step: 5
Training loss: 2.5096320565746697
Validation loss: 2.700025936854399

Epoch: 5| Step: 6
Training loss: 2.790192959993592
Validation loss: 2.6985620276411124

Epoch: 5| Step: 7
Training loss: 3.3966152172540873
Validation loss: 2.6985036655072734

Epoch: 5| Step: 8
Training loss: 3.652180550748902
Validation loss: 2.6991390706058804

Epoch: 5| Step: 9
Training loss: 3.3746128566656424
Validation loss: 2.7069940882756813

Epoch: 5| Step: 10
Training loss: 2.919060968664707
Validation loss: 2.708240472102426

Epoch: 68| Step: 0
Training loss: 2.825179615893571
Validation loss: 2.71852528425221

Epoch: 5| Step: 1
Training loss: 3.046199625919107
Validation loss: 2.734771572249604

Epoch: 5| Step: 2
Training loss: 2.705247607929585
Validation loss: 2.760474024753499

Epoch: 5| Step: 3
Training loss: 2.6147462305234557
Validation loss: 2.7483214712063875

Epoch: 5| Step: 4
Training loss: 2.571737804438437
Validation loss: 2.7100712547474797

Epoch: 5| Step: 5
Training loss: 3.438249263601641
Validation loss: 2.6974442445655087

Epoch: 5| Step: 6
Training loss: 2.1521459028140986
Validation loss: 2.700919167979984

Epoch: 5| Step: 7
Training loss: 3.5835844144165243
Validation loss: 2.7084625087125187

Epoch: 5| Step: 8
Training loss: 3.587960264872604
Validation loss: 2.7177939935348343

Epoch: 5| Step: 9
Training loss: 3.291043878541555
Validation loss: 2.7039362552914983

Epoch: 5| Step: 10
Training loss: 3.3379976223068044
Validation loss: 2.7006129819301083

Epoch: 69| Step: 0
Training loss: 3.093151458485244
Validation loss: 2.6962191775491307

Epoch: 5| Step: 1
Training loss: 2.914665752897035
Validation loss: 2.6943278307710767

Epoch: 5| Step: 2
Training loss: 3.3475249185695892
Validation loss: 2.692229292449381

Epoch: 5| Step: 3
Training loss: 2.5312309735371925
Validation loss: 2.6909269674736382

Epoch: 5| Step: 4
Training loss: 2.554969422069701
Validation loss: 2.6891336610176455

Epoch: 5| Step: 5
Training loss: 3.171330447501644
Validation loss: 2.691000684326754

Epoch: 5| Step: 6
Training loss: 3.217882650602995
Validation loss: 2.6971392128794833

Epoch: 5| Step: 7
Training loss: 3.0680625378577364
Validation loss: 2.688165090633959

Epoch: 5| Step: 8
Training loss: 3.0096399873903077
Validation loss: 2.6895783580405705

Epoch: 5| Step: 9
Training loss: 3.396989465660671
Validation loss: 2.6894175953944846

Epoch: 5| Step: 10
Training loss: 2.9712881381259653
Validation loss: 2.6880979490426014

Epoch: 70| Step: 0
Training loss: 2.623410424824922
Validation loss: 2.686076815496444

Epoch: 5| Step: 1
Training loss: 3.128909145549144
Validation loss: 2.6857500133185184

Epoch: 5| Step: 2
Training loss: 3.0642029056545006
Validation loss: 2.6849554177477404

Epoch: 5| Step: 3
Training loss: 2.7286428477855953
Validation loss: 2.686658687026516

Epoch: 5| Step: 4
Training loss: 3.481160686997762
Validation loss: 2.6919732703772343

Epoch: 5| Step: 5
Training loss: 3.042420246016178
Validation loss: 2.696041296487726

Epoch: 5| Step: 6
Training loss: 2.989390687129712
Validation loss: 2.6928742015853673

Epoch: 5| Step: 7
Training loss: 3.368240651990543
Validation loss: 2.685294354421799

Epoch: 5| Step: 8
Training loss: 2.716020024654183
Validation loss: 2.6815189544020743

Epoch: 5| Step: 9
Training loss: 2.9069455862815117
Validation loss: 2.6827270084438473

Epoch: 5| Step: 10
Training loss: 3.112399676441097
Validation loss: 2.6864008762880753

Epoch: 71| Step: 0
Training loss: 2.802431947560766
Validation loss: 2.6842118638479975

Epoch: 5| Step: 1
Training loss: 2.566502585265037
Validation loss: 2.6845315353657253

Epoch: 5| Step: 2
Training loss: 2.9714141135335623
Validation loss: 2.6795095260672417

Epoch: 5| Step: 3
Training loss: 3.584700759678273
Validation loss: 2.679192994314882

Epoch: 5| Step: 4
Training loss: 2.4575048332904155
Validation loss: 2.6780069554323056

Epoch: 5| Step: 5
Training loss: 2.9863177462111175
Validation loss: 2.6795047279244573

Epoch: 5| Step: 6
Training loss: 3.2627802235190932
Validation loss: 2.6769751170219602

Epoch: 5| Step: 7
Training loss: 3.0569594731862453
Validation loss: 2.6764534385215444

Epoch: 5| Step: 8
Training loss: 2.8950973966089726
Validation loss: 2.678773734074979

Epoch: 5| Step: 9
Training loss: 3.2566236343846544
Validation loss: 2.691590326467914

Epoch: 5| Step: 10
Training loss: 3.1800544395825203
Validation loss: 2.699801821938537

Epoch: 72| Step: 0
Training loss: 2.7524796490518915
Validation loss: 2.7627409133984484

Epoch: 5| Step: 1
Training loss: 3.228027306820545
Validation loss: 2.7059330706142686

Epoch: 5| Step: 2
Training loss: 3.300611358423689
Validation loss: 2.689023997806796

Epoch: 5| Step: 3
Training loss: 2.8692468217135962
Validation loss: 2.6825762605604893

Epoch: 5| Step: 4
Training loss: 3.279048071869242
Validation loss: 2.680438891091636

Epoch: 5| Step: 5
Training loss: 2.804074956368213
Validation loss: 2.6779627050977273

Epoch: 5| Step: 6
Training loss: 3.3421189082215332
Validation loss: 2.6778397606885274

Epoch: 5| Step: 7
Training loss: 2.8527199264384033
Validation loss: 2.678414205301442

Epoch: 5| Step: 8
Training loss: 2.789885583808007
Validation loss: 2.679685703328288

Epoch: 5| Step: 9
Training loss: 3.1348693640350356
Validation loss: 2.6833667760940867

Epoch: 5| Step: 10
Training loss: 2.679244202183534
Validation loss: 2.678387764895652

Epoch: 73| Step: 0
Training loss: 3.183968626078628
Validation loss: 2.676799611820724

Epoch: 5| Step: 1
Training loss: 2.686496014803471
Validation loss: 2.680305852801297

Epoch: 5| Step: 2
Training loss: 3.021753280697201
Validation loss: 2.6746409176243304

Epoch: 5| Step: 3
Training loss: 3.0665550633177716
Validation loss: 2.6773656226465916

Epoch: 5| Step: 4
Training loss: 3.087000873700245
Validation loss: 2.675328514889021

Epoch: 5| Step: 5
Training loss: 2.92907382895744
Validation loss: 2.67251223343911

Epoch: 5| Step: 6
Training loss: 2.9783065372308326
Validation loss: 2.669786331657757

Epoch: 5| Step: 7
Training loss: 3.09312740958662
Validation loss: 2.673923343651774

Epoch: 5| Step: 8
Training loss: 3.0941263605710523
Validation loss: 2.672050026576789

Epoch: 5| Step: 9
Training loss: 3.127720983368671
Validation loss: 2.6730833460573002

Epoch: 5| Step: 10
Training loss: 2.815870003831676
Validation loss: 2.677204479989117

Epoch: 74| Step: 0
Training loss: 2.8809116785506244
Validation loss: 2.6812497772584627

Epoch: 5| Step: 1
Training loss: 3.010958683273952
Validation loss: 2.692612832902165

Epoch: 5| Step: 2
Training loss: 2.4291445011896498
Validation loss: 2.711507192382984

Epoch: 5| Step: 3
Training loss: 3.4258269042710467
Validation loss: 2.7281402471316656

Epoch: 5| Step: 4
Training loss: 2.8478809576765456
Validation loss: 2.685244364147828

Epoch: 5| Step: 5
Training loss: 3.4135090883524315
Validation loss: 2.676888740151107

Epoch: 5| Step: 6
Training loss: 3.043237794237879
Validation loss: 2.6699551858121833

Epoch: 5| Step: 7
Training loss: 2.866263841079053
Validation loss: 2.6728449952557725

Epoch: 5| Step: 8
Training loss: 3.067292336893936
Validation loss: 2.670851111108516

Epoch: 5| Step: 9
Training loss: 3.5084407388249668
Validation loss: 2.6716190309793992

Epoch: 5| Step: 10
Training loss: 2.4345508242614007
Validation loss: 2.674387481357949

Epoch: 75| Step: 0
Training loss: 2.9861034560783106
Validation loss: 2.6727184937660082

Epoch: 5| Step: 1
Training loss: 2.8034529240062405
Validation loss: 2.670958486463393

Epoch: 5| Step: 2
Training loss: 3.1072452478184487
Validation loss: 2.6708801591652698

Epoch: 5| Step: 3
Training loss: 2.8120381293933603
Validation loss: 2.670511685296795

Epoch: 5| Step: 4
Training loss: 3.3150679513172254
Validation loss: 2.6684691252491275

Epoch: 5| Step: 5
Training loss: 2.8894565179486973
Validation loss: 2.665661570178382

Epoch: 5| Step: 6
Training loss: 2.8203415803123337
Validation loss: 2.6640208251318622

Epoch: 5| Step: 7
Training loss: 3.4409531328578735
Validation loss: 2.6652727066404442

Epoch: 5| Step: 8
Training loss: 2.3834721887149097
Validation loss: 2.6679669627327467

Epoch: 5| Step: 9
Training loss: 3.27463351230219
Validation loss: 2.6738738282283707

Epoch: 5| Step: 10
Training loss: 3.1435258667908403
Validation loss: 2.6843259248775984

Epoch: 76| Step: 0
Training loss: 2.796771852093691
Validation loss: 2.699961862784685

Epoch: 5| Step: 1
Training loss: 2.972455573106895
Validation loss: 2.7301858528358727

Epoch: 5| Step: 2
Training loss: 3.324294200359227
Validation loss: 2.7693433386161557

Epoch: 5| Step: 3
Training loss: 3.1703631927663825
Validation loss: 2.7608337799218794

Epoch: 5| Step: 4
Training loss: 3.4338659324002765
Validation loss: 2.714259849842693

Epoch: 5| Step: 5
Training loss: 3.0073015051428538
Validation loss: 2.6700578704104703

Epoch: 5| Step: 6
Training loss: 2.651134456866764
Validation loss: 2.661701534597975

Epoch: 5| Step: 7
Training loss: 3.060722302227456
Validation loss: 2.6730607889296865

Epoch: 5| Step: 8
Training loss: 2.6680924259859355
Validation loss: 2.722965638790756

Epoch: 5| Step: 9
Training loss: 3.195839537639804
Validation loss: 2.757306325989348

Epoch: 5| Step: 10
Training loss: 3.0757165771692505
Validation loss: 2.6710172181921763

Epoch: 77| Step: 0
Training loss: 3.143916592440418
Validation loss: 2.658488329092842

Epoch: 5| Step: 1
Training loss: 2.625219880840462
Validation loss: 2.663924738629675

Epoch: 5| Step: 2
Training loss: 2.7447338834081454
Validation loss: 2.69232799001649

Epoch: 5| Step: 3
Training loss: 3.4321523511723244
Validation loss: 2.685589499753374

Epoch: 5| Step: 4
Training loss: 2.5536157068763816
Validation loss: 2.685030128261237

Epoch: 5| Step: 5
Training loss: 2.7786868854172724
Validation loss: 2.6945544217842077

Epoch: 5| Step: 6
Training loss: 3.4019141643175357
Validation loss: 2.687335132102525

Epoch: 5| Step: 7
Training loss: 3.4124669726663397
Validation loss: 2.6830095464059984

Epoch: 5| Step: 8
Training loss: 3.045391954273106
Validation loss: 2.657787505844587

Epoch: 5| Step: 9
Training loss: 3.0245819685693305
Validation loss: 2.655456840522872

Epoch: 5| Step: 10
Training loss: 2.621765869197359
Validation loss: 2.653623289059831

Epoch: 78| Step: 0
Training loss: 2.4809268077923132
Validation loss: 2.6518657804053656

Epoch: 5| Step: 1
Training loss: 3.0872873951226194
Validation loss: 2.6490976378033686

Epoch: 5| Step: 2
Training loss: 2.722847667735361
Validation loss: 2.657340314451347

Epoch: 5| Step: 3
Training loss: 3.3098947608559843
Validation loss: 2.6834782124166514

Epoch: 5| Step: 4
Training loss: 2.676664821898069
Validation loss: 2.69593805345334

Epoch: 5| Step: 5
Training loss: 2.875352091583521
Validation loss: 2.71042380354274

Epoch: 5| Step: 6
Training loss: 2.9666059280635633
Validation loss: 2.6833414717239825

Epoch: 5| Step: 7
Training loss: 2.9957130319548666
Validation loss: 2.647857526041581

Epoch: 5| Step: 8
Training loss: 2.9891721506939635
Validation loss: 2.6545114250385122

Epoch: 5| Step: 9
Training loss: 3.7348240538472224
Validation loss: 2.655914496334413

Epoch: 5| Step: 10
Training loss: 3.015100146855631
Validation loss: 2.658861221957033

Epoch: 79| Step: 0
Training loss: 2.442431620613873
Validation loss: 2.6576011256753653

Epoch: 5| Step: 1
Training loss: 3.2620595057314796
Validation loss: 2.65786417413972

Epoch: 5| Step: 2
Training loss: 3.0399441653695636
Validation loss: 2.6633731521658106

Epoch: 5| Step: 3
Training loss: 2.953895105130556
Validation loss: 2.664708099552492

Epoch: 5| Step: 4
Training loss: 3.11088211109892
Validation loss: 2.6639232262887504

Epoch: 5| Step: 5
Training loss: 3.130367856819123
Validation loss: 2.6621640050909923

Epoch: 5| Step: 6
Training loss: 2.520010590606718
Validation loss: 2.6555255150408414

Epoch: 5| Step: 7
Training loss: 3.147306101722076
Validation loss: 2.6564377797375376

Epoch: 5| Step: 8
Training loss: 3.26385099420576
Validation loss: 2.654507257748848

Epoch: 5| Step: 9
Training loss: 3.006537784117582
Validation loss: 2.6525434562942416

Epoch: 5| Step: 10
Training loss: 3.1483310274432417
Validation loss: 2.652097766343536

Epoch: 80| Step: 0
Training loss: 2.732622467814613
Validation loss: 2.6508792016962266

Epoch: 5| Step: 1
Training loss: 2.8222714539569997
Validation loss: 2.649041085313656

Epoch: 5| Step: 2
Training loss: 2.8913466094121745
Validation loss: 2.645560274639757

Epoch: 5| Step: 3
Training loss: 2.9787578346703283
Validation loss: 2.6462562080345475

Epoch: 5| Step: 4
Training loss: 3.140408332904415
Validation loss: 2.6462471692997847

Epoch: 5| Step: 5
Training loss: 2.6364583204719807
Validation loss: 2.656685374493058

Epoch: 5| Step: 6
Training loss: 3.713270237202268
Validation loss: 2.666864987338476

Epoch: 5| Step: 7
Training loss: 3.0381215656561666
Validation loss: 2.6700970305655214

Epoch: 5| Step: 8
Training loss: 2.817419200642396
Validation loss: 2.6610732161836834

Epoch: 5| Step: 9
Training loss: 3.1598242737402296
Validation loss: 2.6544680269592247

Epoch: 5| Step: 10
Training loss: 2.823407532829001
Validation loss: 2.650528349884375

Epoch: 81| Step: 0
Training loss: 3.1121545377767466
Validation loss: 2.6468362510200247

Epoch: 5| Step: 1
Training loss: 2.611649943502896
Validation loss: 2.6424331450039333

Epoch: 5| Step: 2
Training loss: 3.533046299293869
Validation loss: 2.644713907108785

Epoch: 5| Step: 3
Training loss: 3.480393808159572
Validation loss: 2.6449309297399024

Epoch: 5| Step: 4
Training loss: 2.4961355859536867
Validation loss: 2.6398666583177617

Epoch: 5| Step: 5
Training loss: 2.8293324627468963
Validation loss: 2.6406651548626248

Epoch: 5| Step: 6
Training loss: 2.3857933535497757
Validation loss: 2.6400519463589003

Epoch: 5| Step: 7
Training loss: 3.6241993513202817
Validation loss: 2.6503143218554492

Epoch: 5| Step: 8
Training loss: 2.414678896136659
Validation loss: 2.6496366099235056

Epoch: 5| Step: 9
Training loss: 3.101300360606302
Validation loss: 2.660526850878462

Epoch: 5| Step: 10
Training loss: 2.9088384115030936
Validation loss: 2.6651333013833356

Epoch: 82| Step: 0
Training loss: 2.6216712008576692
Validation loss: 2.645304932240737

Epoch: 5| Step: 1
Training loss: 2.638721027947077
Validation loss: 2.634326688174373

Epoch: 5| Step: 2
Training loss: 3.4918835398861643
Validation loss: 2.6326129387715036

Epoch: 5| Step: 3
Training loss: 3.2928662267180773
Validation loss: 2.63522539989399

Epoch: 5| Step: 4
Training loss: 2.917069507208852
Validation loss: 2.638130825061647

Epoch: 5| Step: 5
Training loss: 3.235655158088233
Validation loss: 2.636594685530172

Epoch: 5| Step: 6
Training loss: 2.995229743208292
Validation loss: 2.6394578917910767

Epoch: 5| Step: 7
Training loss: 2.6038843739412134
Validation loss: 2.638522288647858

Epoch: 5| Step: 8
Training loss: 2.8167356174163083
Validation loss: 2.6368685339431712

Epoch: 5| Step: 9
Training loss: 3.0208176886493234
Validation loss: 2.638311617507583

Epoch: 5| Step: 10
Training loss: 3.0873918027877347
Validation loss: 2.638951938943128

Epoch: 83| Step: 0
Training loss: 3.0793657464766557
Validation loss: 2.634108926174543

Epoch: 5| Step: 1
Training loss: 3.334610614835814
Validation loss: 2.6379293191795457

Epoch: 5| Step: 2
Training loss: 2.341926882891691
Validation loss: 2.6490635189037834

Epoch: 5| Step: 3
Training loss: 2.646178595976507
Validation loss: 2.6627815373111585

Epoch: 5| Step: 4
Training loss: 2.886068681297537
Validation loss: 2.687861956913693

Epoch: 5| Step: 5
Training loss: 2.7683490333670777
Validation loss: 2.7289736304595023

Epoch: 5| Step: 6
Training loss: 3.051700624464166
Validation loss: 2.7319497759039546

Epoch: 5| Step: 7
Training loss: 2.8445344618454644
Validation loss: 2.77366901351733

Epoch: 5| Step: 8
Training loss: 2.440295255025846
Validation loss: 2.699839477674317

Epoch: 5| Step: 9
Training loss: 3.6156843782262325
Validation loss: 2.6371228685079275

Epoch: 5| Step: 10
Training loss: 3.7181502427581066
Validation loss: 2.631386415798108

Epoch: 84| Step: 0
Training loss: 3.1112165508870757
Validation loss: 2.6377413550763698

Epoch: 5| Step: 1
Training loss: 3.4301020691034507
Validation loss: 2.6568724817951224

Epoch: 5| Step: 2
Training loss: 3.399335089349477
Validation loss: 2.688956154034185

Epoch: 5| Step: 3
Training loss: 2.817529970024902
Validation loss: 2.6712951760231163

Epoch: 5| Step: 4
Training loss: 3.1421817697921397
Validation loss: 2.644597900120748

Epoch: 5| Step: 5
Training loss: 3.0193589569720527
Validation loss: 2.634348006291364

Epoch: 5| Step: 6
Training loss: 3.509783558489242
Validation loss: 2.634658489112017

Epoch: 5| Step: 7
Training loss: 2.627489635036942
Validation loss: 2.627456443477662

Epoch: 5| Step: 8
Training loss: 2.5649988039843055
Validation loss: 2.6352620599693415

Epoch: 5| Step: 9
Training loss: 2.725577365010256
Validation loss: 2.641118286487944

Epoch: 5| Step: 10
Training loss: 2.1964107494982525
Validation loss: 2.683611038032193

Epoch: 85| Step: 0
Training loss: 2.6831885952347174
Validation loss: 2.7570116349634746

Epoch: 5| Step: 1
Training loss: 2.744182328419766
Validation loss: 2.751820318849658

Epoch: 5| Step: 2
Training loss: 3.2711269627523345
Validation loss: 2.6850333573599814

Epoch: 5| Step: 3
Training loss: 3.026763899861595
Validation loss: 2.6476612483492574

Epoch: 5| Step: 4
Training loss: 3.0645612669633753
Validation loss: 2.628211594547311

Epoch: 5| Step: 5
Training loss: 2.6831917052082197
Validation loss: 2.622396188526101

Epoch: 5| Step: 6
Training loss: 3.102580559212574
Validation loss: 2.628312780947147

Epoch: 5| Step: 7
Training loss: 3.3676084888090725
Validation loss: 2.633118565504702

Epoch: 5| Step: 8
Training loss: 2.7823474733237026
Validation loss: 2.6297587443087376

Epoch: 5| Step: 9
Training loss: 2.7301164871906787
Validation loss: 2.629116036631434

Epoch: 5| Step: 10
Training loss: 3.2949826563377242
Validation loss: 2.6289557522842073

Epoch: 86| Step: 0
Training loss: 3.1809983609245367
Validation loss: 2.624181622796637

Epoch: 5| Step: 1
Training loss: 3.0804400573059807
Validation loss: 2.6287830143918014

Epoch: 5| Step: 2
Training loss: 2.8011505862379136
Validation loss: 2.623109729721646

Epoch: 5| Step: 3
Training loss: 2.933244422807807
Validation loss: 2.6244369621800345

Epoch: 5| Step: 4
Training loss: 3.0879296934297162
Validation loss: 2.626183456444146

Epoch: 5| Step: 5
Training loss: 2.5646626720246966
Validation loss: 2.6254241286247857

Epoch: 5| Step: 6
Training loss: 2.9962898200185633
Validation loss: 2.620692849143336

Epoch: 5| Step: 7
Training loss: 2.6813442791633637
Validation loss: 2.621447404933592

Epoch: 5| Step: 8
Training loss: 2.9545400952910787
Validation loss: 2.61827408811766

Epoch: 5| Step: 9
Training loss: 3.252862549967633
Validation loss: 2.615708904097014

Epoch: 5| Step: 10
Training loss: 3.0230438212689705
Validation loss: 2.621815902312033

Epoch: 87| Step: 0
Training loss: 2.7776697667633057
Validation loss: 2.619831348546701

Epoch: 5| Step: 1
Training loss: 2.9046749646191827
Validation loss: 2.6168080867436916

Epoch: 5| Step: 2
Training loss: 2.76126677660424
Validation loss: 2.6202718799846445

Epoch: 5| Step: 3
Training loss: 2.814702676143669
Validation loss: 2.6204045444716524

Epoch: 5| Step: 4
Training loss: 2.88793126968642
Validation loss: 2.618869158575469

Epoch: 5| Step: 5
Training loss: 3.0131011046605685
Validation loss: 2.6202338360980915

Epoch: 5| Step: 6
Training loss: 3.1307245845419507
Validation loss: 2.6166792141976876

Epoch: 5| Step: 7
Training loss: 2.8605677717342357
Validation loss: 2.6174339289840076

Epoch: 5| Step: 8
Training loss: 2.625573958364122
Validation loss: 2.6155310805759284

Epoch: 5| Step: 9
Training loss: 3.329081653055383
Validation loss: 2.619341695167733

Epoch: 5| Step: 10
Training loss: 3.383958864561728
Validation loss: 2.620908436321166

Epoch: 88| Step: 0
Training loss: 3.137148018961027
Validation loss: 2.624990883189756

Epoch: 5| Step: 1
Training loss: 2.967275795569508
Validation loss: 2.6243565156933726

Epoch: 5| Step: 2
Training loss: 2.8270670561203577
Validation loss: 2.6470393674127264

Epoch: 5| Step: 3
Training loss: 3.4371119887104364
Validation loss: 2.6299956016483472

Epoch: 5| Step: 4
Training loss: 3.270764992034383
Validation loss: 2.6142361128515765

Epoch: 5| Step: 5
Training loss: 2.5362922462641153
Validation loss: 2.6136150958951636

Epoch: 5| Step: 6
Training loss: 3.622573961512507
Validation loss: 2.6199586090507543

Epoch: 5| Step: 7
Training loss: 2.4688195327431095
Validation loss: 2.623855415505972

Epoch: 5| Step: 8
Training loss: 2.8535911555284432
Validation loss: 2.6249353778813034

Epoch: 5| Step: 9
Training loss: 2.9088979163959494
Validation loss: 2.6385568197914373

Epoch: 5| Step: 10
Training loss: 2.352855440990009
Validation loss: 2.648091666710098

Epoch: 89| Step: 0
Training loss: 3.446798475562524
Validation loss: 2.668726509753394

Epoch: 5| Step: 1
Training loss: 2.878150374873297
Validation loss: 2.6242827057066975

Epoch: 5| Step: 2
Training loss: 3.0022368039557383
Validation loss: 2.620758002371221

Epoch: 5| Step: 3
Training loss: 3.4683480244633507
Validation loss: 2.6218444092612425

Epoch: 5| Step: 4
Training loss: 3.117711838145548
Validation loss: 2.618270948033707

Epoch: 5| Step: 5
Training loss: 2.8550849792339736
Validation loss: 2.6182105924796235

Epoch: 5| Step: 6
Training loss: 2.829760673836465
Validation loss: 2.615995845673875

Epoch: 5| Step: 7
Training loss: 2.5841858800399122
Validation loss: 2.6269215944935778

Epoch: 5| Step: 8
Training loss: 2.7094225429424688
Validation loss: 2.63490604828645

Epoch: 5| Step: 9
Training loss: 2.672298821637742
Validation loss: 2.6505549008724487

Epoch: 5| Step: 10
Training loss: 3.131265843516944
Validation loss: 2.6659509686357103

Epoch: 90| Step: 0
Training loss: 2.4343685674031468
Validation loss: 2.707037890568367

Epoch: 5| Step: 1
Training loss: 3.1710465575487223
Validation loss: 2.7383738623764895

Epoch: 5| Step: 2
Training loss: 3.441739606353789
Validation loss: 2.640373577709613

Epoch: 5| Step: 3
Training loss: 1.843615381531167
Validation loss: 2.6101475731806367

Epoch: 5| Step: 4
Training loss: 3.2836967428511468
Validation loss: 2.6151916975365737

Epoch: 5| Step: 5
Training loss: 2.7809946178670883
Validation loss: 2.615567114953721

Epoch: 5| Step: 6
Training loss: 3.0834547654717506
Validation loss: 2.6191310502645715

Epoch: 5| Step: 7
Training loss: 2.8402326021174495
Validation loss: 2.622856513113754

Epoch: 5| Step: 8
Training loss: 3.182594264118504
Validation loss: 2.6259028693193995

Epoch: 5| Step: 9
Training loss: 3.2613541267940294
Validation loss: 2.626193228036819

Epoch: 5| Step: 10
Training loss: 3.4075412927421973
Validation loss: 2.6325692361756134

Epoch: 91| Step: 0
Training loss: 3.0550293401879434
Validation loss: 2.640152355616237

Epoch: 5| Step: 1
Training loss: 2.791965373745412
Validation loss: 2.628951246086825

Epoch: 5| Step: 2
Training loss: 3.381180508334899
Validation loss: 2.624817093250143

Epoch: 5| Step: 3
Training loss: 3.2670439781215785
Validation loss: 2.6217907450679045

Epoch: 5| Step: 4
Training loss: 2.865452379125525
Validation loss: 2.6175916555299112

Epoch: 5| Step: 5
Training loss: 2.702935625620103
Validation loss: 2.6198140927077427

Epoch: 5| Step: 6
Training loss: 2.9677848451676936
Validation loss: 2.6170732145376374

Epoch: 5| Step: 7
Training loss: 2.85053408119157
Validation loss: 2.61608545165562

Epoch: 5| Step: 8
Training loss: 2.725413870223671
Validation loss: 2.61402115029543

Epoch: 5| Step: 9
Training loss: 2.558797534078078
Validation loss: 2.6123433552025874

Epoch: 5| Step: 10
Training loss: 3.6857604756845843
Validation loss: 2.6099378472349146

Epoch: 92| Step: 0
Training loss: 2.4221909839859515
Validation loss: 2.6079117541564947

Epoch: 5| Step: 1
Training loss: 3.4693035337041596
Validation loss: 2.601338262162274

Epoch: 5| Step: 2
Training loss: 3.2022258706137863
Validation loss: 2.603576061751481

Epoch: 5| Step: 3
Training loss: 2.9634530445830807
Validation loss: 2.6050499892585854

Epoch: 5| Step: 4
Training loss: 3.0151072635833516
Validation loss: 2.6152397655093402

Epoch: 5| Step: 5
Training loss: 3.1043407382844683
Validation loss: 2.633399381649109

Epoch: 5| Step: 6
Training loss: 2.7970893820323086
Validation loss: 2.6742596148798303

Epoch: 5| Step: 7
Training loss: 3.0773580922211163
Validation loss: 2.6701245573547414

Epoch: 5| Step: 8
Training loss: 3.2610105191049126
Validation loss: 2.6139208592474774

Epoch: 5| Step: 9
Training loss: 2.362431851166041
Validation loss: 2.6010114155164668

Epoch: 5| Step: 10
Training loss: 2.561260854196332
Validation loss: 2.6036274738575784

Epoch: 93| Step: 0
Training loss: 2.8261987016587007
Validation loss: 2.6016587149642727

Epoch: 5| Step: 1
Training loss: 2.5165209389066905
Validation loss: 2.604712162761903

Epoch: 5| Step: 2
Training loss: 2.5415051726852034
Validation loss: 2.607927585223339

Epoch: 5| Step: 3
Training loss: 3.1483332992992596
Validation loss: 2.6055477321186706

Epoch: 5| Step: 4
Training loss: 2.799192949197965
Validation loss: 2.605140258588751

Epoch: 5| Step: 5
Training loss: 3.570510825360443
Validation loss: 2.60300842681217

Epoch: 5| Step: 6
Training loss: 3.3164052435308395
Validation loss: 2.6035376020733456

Epoch: 5| Step: 7
Training loss: 2.62787842744855
Validation loss: 2.6032517792915293

Epoch: 5| Step: 8
Training loss: 2.9026736332545906
Validation loss: 2.6025864884615175

Epoch: 5| Step: 9
Training loss: 3.3612126491822054
Validation loss: 2.600743034717153

Epoch: 5| Step: 10
Training loss: 2.8440442614216277
Validation loss: 2.5994582508680386

Epoch: 94| Step: 0
Training loss: 2.7194657534564417
Validation loss: 2.6030788321860383

Epoch: 5| Step: 1
Training loss: 2.4390463203514248
Validation loss: 2.6024184970194666

Epoch: 5| Step: 2
Training loss: 3.175306746916228
Validation loss: 2.6022602419159693

Epoch: 5| Step: 3
Training loss: 3.589659245080036
Validation loss: 2.606707873124023

Epoch: 5| Step: 4
Training loss: 2.470742688974234
Validation loss: 2.600870479105001

Epoch: 5| Step: 5
Training loss: 3.0571978076432336
Validation loss: 2.5996117181241107

Epoch: 5| Step: 6
Training loss: 2.6107461947126893
Validation loss: 2.6021561883053828

Epoch: 5| Step: 7
Training loss: 2.9089175871672035
Validation loss: 2.6069804466038495

Epoch: 5| Step: 8
Training loss: 3.0070744389212214
Validation loss: 2.607694272587679

Epoch: 5| Step: 9
Training loss: 3.1040977282624342
Validation loss: 2.6281856089210778

Epoch: 5| Step: 10
Training loss: 3.226293224708777
Validation loss: 2.63800826527915

Epoch: 95| Step: 0
Training loss: 3.3319335064521405
Validation loss: 2.6334446436341366

Epoch: 5| Step: 1
Training loss: 3.0289111995582787
Validation loss: 2.623930210627401

Epoch: 5| Step: 2
Training loss: 2.875320748391026
Validation loss: 2.6083282794082407

Epoch: 5| Step: 3
Training loss: 3.1050965284002996
Validation loss: 2.6059861932258332

Epoch: 5| Step: 4
Training loss: 2.2779900237443553
Validation loss: 2.6167140644518194

Epoch: 5| Step: 5
Training loss: 3.4519984276106026
Validation loss: 2.6311234883350605

Epoch: 5| Step: 6
Training loss: 3.4460065146997367
Validation loss: 2.6329384602599486

Epoch: 5| Step: 7
Training loss: 2.062340470126521
Validation loss: 2.631566929263536

Epoch: 5| Step: 8
Training loss: 2.8932667800468144
Validation loss: 2.6167937186832395

Epoch: 5| Step: 9
Training loss: 3.0210200460325107
Validation loss: 2.598175882602205

Epoch: 5| Step: 10
Training loss: 2.4600733617372867
Validation loss: 2.5955996006498734

Epoch: 96| Step: 0
Training loss: 3.0276978119566924
Validation loss: 2.5909092490534125

Epoch: 5| Step: 1
Training loss: 3.3535814584303205
Validation loss: 2.586578025610761

Epoch: 5| Step: 2
Training loss: 3.0780129969014487
Validation loss: 2.5900638766228905

Epoch: 5| Step: 3
Training loss: 2.631259086393855
Validation loss: 2.5863620761571156

Epoch: 5| Step: 4
Training loss: 2.7636794666415168
Validation loss: 2.5838905989436407

Epoch: 5| Step: 5
Training loss: 2.9103335332955247
Validation loss: 2.586157572507771

Epoch: 5| Step: 6
Training loss: 2.437390153806185
Validation loss: 2.5935285048408137

Epoch: 5| Step: 7
Training loss: 2.604506101739173
Validation loss: 2.616829406503641

Epoch: 5| Step: 8
Training loss: 3.2252769587860923
Validation loss: 2.637386813405896

Epoch: 5| Step: 9
Training loss: 3.283621666603759
Validation loss: 2.648255683450676

Epoch: 5| Step: 10
Training loss: 2.932213591941605
Validation loss: 2.678711019805667

Epoch: 97| Step: 0
Training loss: 3.193442844618213
Validation loss: 2.655645497861673

Epoch: 5| Step: 1
Training loss: 2.4556373317425373
Validation loss: 2.6343273927474167

Epoch: 5| Step: 2
Training loss: 2.6145179000711547
Validation loss: 2.6287891143831215

Epoch: 5| Step: 3
Training loss: 3.318559682098163
Validation loss: 2.6051632065103836

Epoch: 5| Step: 4
Training loss: 3.0779205099429294
Validation loss: 2.6057468573425595

Epoch: 5| Step: 5
Training loss: 2.928855513374652
Validation loss: 2.5961234141500436

Epoch: 5| Step: 6
Training loss: 3.287294469870417
Validation loss: 2.5967096788100026

Epoch: 5| Step: 7
Training loss: 2.8861521163473505
Validation loss: 2.593432024825006

Epoch: 5| Step: 8
Training loss: 2.7203261092983273
Validation loss: 2.5825416130424603

Epoch: 5| Step: 9
Training loss: 2.7152274978895248
Validation loss: 2.581026743165294

Epoch: 5| Step: 10
Training loss: 2.9736201444208814
Validation loss: 2.577550408006782

Epoch: 98| Step: 0
Training loss: 2.6885961027274203
Validation loss: 2.5784782021053907

Epoch: 5| Step: 1
Training loss: 3.1181501465297834
Validation loss: 2.5793885834530643

Epoch: 5| Step: 2
Training loss: 2.99718693133124
Validation loss: 2.5764306440604403

Epoch: 5| Step: 3
Training loss: 3.008161727646187
Validation loss: 2.5807650624769876

Epoch: 5| Step: 4
Training loss: 2.781970670105307
Validation loss: 2.581480356715764

Epoch: 5| Step: 5
Training loss: 2.744508809541674
Validation loss: 2.5847619823734935

Epoch: 5| Step: 6
Training loss: 2.7628037885483896
Validation loss: 2.581326872180948

Epoch: 5| Step: 7
Training loss: 2.698294849965636
Validation loss: 2.5872833761687155

Epoch: 5| Step: 8
Training loss: 3.3613532340814793
Validation loss: 2.5845193737005707

Epoch: 5| Step: 9
Training loss: 3.425011299281729
Validation loss: 2.588012909371224

Epoch: 5| Step: 10
Training loss: 2.4209539815632946
Validation loss: 2.5869929431861354

Epoch: 99| Step: 0
Training loss: 2.8496978934268227
Validation loss: 2.5941081486104207

Epoch: 5| Step: 1
Training loss: 3.3982059794521255
Validation loss: 2.6059882207351532

Epoch: 5| Step: 2
Training loss: 3.1353396451663347
Validation loss: 2.5800686790479266

Epoch: 5| Step: 3
Training loss: 2.1616928402334032
Validation loss: 2.5769038346414437

Epoch: 5| Step: 4
Training loss: 3.3589782480555965
Validation loss: 2.5762706164439346

Epoch: 5| Step: 5
Training loss: 2.975546355527267
Validation loss: 2.572157580223882

Epoch: 5| Step: 6
Training loss: 2.7527976110954087
Validation loss: 2.574728239114882

Epoch: 5| Step: 7
Training loss: 2.994798124002323
Validation loss: 2.5729588709446953

Epoch: 5| Step: 8
Training loss: 3.022495014448448
Validation loss: 2.5751160783944504

Epoch: 5| Step: 9
Training loss: 2.7023058405321048
Validation loss: 2.57536262494037

Epoch: 5| Step: 10
Training loss: 2.6395671463620336
Validation loss: 2.574682947598101

Epoch: 100| Step: 0
Training loss: 2.880683588386855
Validation loss: 2.5748625507063387

Epoch: 5| Step: 1
Training loss: 2.867370599622346
Validation loss: 2.5759842403038444

Epoch: 5| Step: 2
Training loss: 2.9607743593228664
Validation loss: 2.577891995866078

Epoch: 5| Step: 3
Training loss: 2.7357910849076195
Validation loss: 2.5828959362348396

Epoch: 5| Step: 4
Training loss: 3.0168786481981837
Validation loss: 2.5812576448370597

Epoch: 5| Step: 5
Training loss: 2.2290380803274323
Validation loss: 2.582764510990624

Epoch: 5| Step: 6
Training loss: 3.0950299322255463
Validation loss: 2.590713116746528

Epoch: 5| Step: 7
Training loss: 3.2447839107186014
Validation loss: 2.5878735464921347

Epoch: 5| Step: 8
Training loss: 3.472540494107352
Validation loss: 2.6024471002055054

Epoch: 5| Step: 9
Training loss: 2.8800008651944027
Validation loss: 2.5971071390599803

Epoch: 5| Step: 10
Training loss: 2.5503173219298416
Validation loss: 2.5917795601094467

Epoch: 101| Step: 0
Training loss: 2.6214971331446644
Validation loss: 2.604962296225544

Epoch: 5| Step: 1
Training loss: 2.9792650824521396
Validation loss: 2.604909351067488

Epoch: 5| Step: 2
Training loss: 2.61434590957511
Validation loss: 2.5851983738849413

Epoch: 5| Step: 3
Training loss: 3.118929192358461
Validation loss: 2.5892144587853814

Epoch: 5| Step: 4
Training loss: 2.7619261926765395
Validation loss: 2.585797168669055

Epoch: 5| Step: 5
Training loss: 2.6790589243185194
Validation loss: 2.5958504284985944

Epoch: 5| Step: 6
Training loss: 3.4929545198106746
Validation loss: 2.5916283157302438

Epoch: 5| Step: 7
Training loss: 2.564571659692701
Validation loss: 2.5809952733939547

Epoch: 5| Step: 8
Training loss: 2.44208994333149
Validation loss: 2.5784768966605727

Epoch: 5| Step: 9
Training loss: 3.479615660303968
Validation loss: 2.5779590363095366

Epoch: 5| Step: 10
Training loss: 3.170216845728063
Validation loss: 2.574722973881318

Epoch: 102| Step: 0
Training loss: 2.9638860108030776
Validation loss: 2.573616442492315

Epoch: 5| Step: 1
Training loss: 3.037772014981118
Validation loss: 2.5726670779382714

Epoch: 5| Step: 2
Training loss: 3.3050470539846684
Validation loss: 2.580041154778207

Epoch: 5| Step: 3
Training loss: 2.5374018006514496
Validation loss: 2.5780978432894064

Epoch: 5| Step: 4
Training loss: 3.212598681882398
Validation loss: 2.5978658434457778

Epoch: 5| Step: 5
Training loss: 3.2523110315902466
Validation loss: 2.599948859441481

Epoch: 5| Step: 6
Training loss: 2.9640956331853494
Validation loss: 2.5797281003842656

Epoch: 5| Step: 7
Training loss: 2.227350249560295
Validation loss: 2.5741709716979924

Epoch: 5| Step: 8
Training loss: 2.626705523879616
Validation loss: 2.5654969087079733

Epoch: 5| Step: 9
Training loss: 3.2225692459846407
Validation loss: 2.56715775813613

Epoch: 5| Step: 10
Training loss: 2.483955011915615
Validation loss: 2.5702862481858313

Epoch: 103| Step: 0
Training loss: 3.254043557886639
Validation loss: 2.576005002253616

Epoch: 5| Step: 1
Training loss: 3.2454446999847617
Validation loss: 2.579276117840637

Epoch: 5| Step: 2
Training loss: 2.891495032443259
Validation loss: 2.5713663647092755

Epoch: 5| Step: 3
Training loss: 2.53699641750806
Validation loss: 2.5731278073341377

Epoch: 5| Step: 4
Training loss: 2.6808259286285137
Validation loss: 2.570478725011106

Epoch: 5| Step: 5
Training loss: 2.4740284371063894
Validation loss: 2.5673479461577213

Epoch: 5| Step: 6
Training loss: 2.4705758405021885
Validation loss: 2.567483128105425

Epoch: 5| Step: 7
Training loss: 2.9307994309164616
Validation loss: 2.5686858373140216

Epoch: 5| Step: 8
Training loss: 3.2830119897145327
Validation loss: 2.576398833565708

Epoch: 5| Step: 9
Training loss: 3.215713105324671
Validation loss: 2.5788699747104564

Epoch: 5| Step: 10
Training loss: 2.909690215410947
Validation loss: 2.5772909655588063

Epoch: 104| Step: 0
Training loss: 3.1001151524967963
Validation loss: 2.5845504811671858

Epoch: 5| Step: 1
Training loss: 3.2005299546577626
Validation loss: 2.5710425301566264

Epoch: 5| Step: 2
Training loss: 3.1269930778014468
Validation loss: 2.5886699042020007

Epoch: 5| Step: 3
Training loss: 2.4480575412769268
Validation loss: 2.612876424800099

Epoch: 5| Step: 4
Training loss: 2.6484437115351662
Validation loss: 2.612757662920751

Epoch: 5| Step: 5
Training loss: 3.48588522440563
Validation loss: 2.5825967866696256

Epoch: 5| Step: 6
Training loss: 2.635937926920442
Validation loss: 2.5580682295762847

Epoch: 5| Step: 7
Training loss: 2.7245536333623743
Validation loss: 2.565486559180937

Epoch: 5| Step: 8
Training loss: 2.722253931167935
Validation loss: 2.5678979258319248

Epoch: 5| Step: 9
Training loss: 3.18383308868362
Validation loss: 2.5903919007187537

Epoch: 5| Step: 10
Training loss: 2.6892997570536044
Validation loss: 2.618305945020902

Epoch: 105| Step: 0
Training loss: 2.9349142828256807
Validation loss: 2.612469308316361

Epoch: 5| Step: 1
Training loss: 2.9850284200622115
Validation loss: 2.6024627197214327

Epoch: 5| Step: 2
Training loss: 3.026207258953938
Validation loss: 2.635886841084343

Epoch: 5| Step: 3
Training loss: 2.7017647733138843
Validation loss: 2.574157260979082

Epoch: 5| Step: 4
Training loss: 2.780624233527838
Validation loss: 2.567846813202195

Epoch: 5| Step: 5
Training loss: 2.7835327381574895
Validation loss: 2.563726619308399

Epoch: 5| Step: 6
Training loss: 3.325718542488606
Validation loss: 2.5646483097102326

Epoch: 5| Step: 7
Training loss: 2.3849773641027947
Validation loss: 2.5870892104759773

Epoch: 5| Step: 8
Training loss: 3.256276452365265
Validation loss: 2.604090537322315

Epoch: 5| Step: 9
Training loss: 3.0337391494538073
Validation loss: 2.6009513809512166

Epoch: 5| Step: 10
Training loss: 2.8040249607809082
Validation loss: 2.6027205079848477

Epoch: 106| Step: 0
Training loss: 3.176730944158971
Validation loss: 2.602394339317247

Epoch: 5| Step: 1
Training loss: 3.0818311967214314
Validation loss: 2.599947845797279

Epoch: 5| Step: 2
Training loss: 2.6954554423146946
Validation loss: 2.604694521330724

Epoch: 5| Step: 3
Training loss: 2.7153722893498946
Validation loss: 2.609009883537349

Epoch: 5| Step: 4
Training loss: 3.1966393287876644
Validation loss: 2.590214995597573

Epoch: 5| Step: 5
Training loss: 2.4728215118672074
Validation loss: 2.5664914306933047

Epoch: 5| Step: 6
Training loss: 3.05093629567604
Validation loss: 2.557007228296507

Epoch: 5| Step: 7
Training loss: 2.9460919307600952
Validation loss: 2.560610751289105

Epoch: 5| Step: 8
Training loss: 2.705365790209873
Validation loss: 2.5599726577357416

Epoch: 5| Step: 9
Training loss: 2.7418499600284667
Validation loss: 2.562389316364402

Epoch: 5| Step: 10
Training loss: 3.2092283577554404
Validation loss: 2.556497239977992

Epoch: 107| Step: 0
Training loss: 2.4592638894639265
Validation loss: 2.5573379592276035

Epoch: 5| Step: 1
Training loss: 2.695226872507602
Validation loss: 2.5585304425888307

Epoch: 5| Step: 2
Training loss: 2.9027081308319396
Validation loss: 2.562982443257794

Epoch: 5| Step: 3
Training loss: 2.722027961996554
Validation loss: 2.5622107549896347

Epoch: 5| Step: 4
Training loss: 3.116245519433624
Validation loss: 2.570901549328361

Epoch: 5| Step: 5
Training loss: 3.0583628522260837
Validation loss: 2.5919720530497834

Epoch: 5| Step: 6
Training loss: 3.281772826185632
Validation loss: 2.612435261565589

Epoch: 5| Step: 7
Training loss: 2.8067532638214154
Validation loss: 2.6217960859178238

Epoch: 5| Step: 8
Training loss: 2.92719783536378
Validation loss: 2.611488832565562

Epoch: 5| Step: 9
Training loss: 3.1055519716639832
Validation loss: 2.5944436187756295

Epoch: 5| Step: 10
Training loss: 2.762875240611549
Validation loss: 2.573088155764618

Epoch: 108| Step: 0
Training loss: 2.734203660228903
Validation loss: 2.5602495539566545

Epoch: 5| Step: 1
Training loss: 2.8061943575433883
Validation loss: 2.556005219283665

Epoch: 5| Step: 2
Training loss: 2.6956410083432507
Validation loss: 2.5539014683993515

Epoch: 5| Step: 3
Training loss: 2.648231340784631
Validation loss: 2.5566896243241923

Epoch: 5| Step: 4
Training loss: 2.612706051234285
Validation loss: 2.5589391567126483

Epoch: 5| Step: 5
Training loss: 3.202548686959527
Validation loss: 2.560072066038729

Epoch: 5| Step: 6
Training loss: 3.0487963756054266
Validation loss: 2.5563029828349784

Epoch: 5| Step: 7
Training loss: 3.387445321292808
Validation loss: 2.5589814940057214

Epoch: 5| Step: 8
Training loss: 2.732307131732353
Validation loss: 2.554997674474466

Epoch: 5| Step: 9
Training loss: 3.347781024330181
Validation loss: 2.5601999929202286

Epoch: 5| Step: 10
Training loss: 2.806275324717822
Validation loss: 2.5827802435826364

Epoch: 109| Step: 0
Training loss: 2.243720935856438
Validation loss: 2.592502432829644

Epoch: 5| Step: 1
Training loss: 3.224270133294674
Validation loss: 2.596285318616302

Epoch: 5| Step: 2
Training loss: 2.744850886729707
Validation loss: 2.5942737294227585

Epoch: 5| Step: 3
Training loss: 3.2079413698884216
Validation loss: 2.5880773182335397

Epoch: 5| Step: 4
Training loss: 2.699998491781308
Validation loss: 2.5806450254814566

Epoch: 5| Step: 5
Training loss: 3.416528714504131
Validation loss: 2.5744808451432064

Epoch: 5| Step: 6
Training loss: 2.8731049636165413
Validation loss: 2.5741395356311334

Epoch: 5| Step: 7
Training loss: 3.0888204121794276
Validation loss: 2.565650679754186

Epoch: 5| Step: 8
Training loss: 2.7930803183299857
Validation loss: 2.5595710446623583

Epoch: 5| Step: 9
Training loss: 2.5132640872425047
Validation loss: 2.5548322403984765

Epoch: 5| Step: 10
Training loss: 3.0077089762521303
Validation loss: 2.55771306698243

Epoch: 110| Step: 0
Training loss: 2.8821582413592184
Validation loss: 2.5568223332139053

Epoch: 5| Step: 1
Training loss: 2.457355714367294
Validation loss: 2.565375464766236

Epoch: 5| Step: 2
Training loss: 2.5153221753692985
Validation loss: 2.5614777163331937

Epoch: 5| Step: 3
Training loss: 2.8115748261303106
Validation loss: 2.5795805659532802

Epoch: 5| Step: 4
Training loss: 3.3546522432703525
Validation loss: 2.5659570232596196

Epoch: 5| Step: 5
Training loss: 2.900043053143006
Validation loss: 2.5607682465899217

Epoch: 5| Step: 6
Training loss: 3.109933927514908
Validation loss: 2.5631489140928014

Epoch: 5| Step: 7
Training loss: 3.287205985378406
Validation loss: 2.569559148903389

Epoch: 5| Step: 8
Training loss: 3.007552019210041
Validation loss: 2.5717421038552746

Epoch: 5| Step: 9
Training loss: 2.6550241671107053
Validation loss: 2.561625467731931

Epoch: 5| Step: 10
Training loss: 2.8055159426453553
Validation loss: 2.555938162688738

Epoch: 111| Step: 0
Training loss: 2.3690631347462174
Validation loss: 2.5506285374355637

Epoch: 5| Step: 1
Training loss: 2.5026175147635756
Validation loss: 2.546145647447739

Epoch: 5| Step: 2
Training loss: 3.0375654362666906
Validation loss: 2.5451855386161464

Epoch: 5| Step: 3
Training loss: 2.6999067431698385
Validation loss: 2.539332734549902

Epoch: 5| Step: 4
Training loss: 3.0259313426476617
Validation loss: 2.5422965132905544

Epoch: 5| Step: 5
Training loss: 2.4052021668097505
Validation loss: 2.544371444871315

Epoch: 5| Step: 6
Training loss: 3.1777954470833105
Validation loss: 2.5438733838951193

Epoch: 5| Step: 7
Training loss: 3.216421229300042
Validation loss: 2.541914368180188

Epoch: 5| Step: 8
Training loss: 3.213255405298903
Validation loss: 2.5481497717814006

Epoch: 5| Step: 9
Training loss: 2.7816482430273264
Validation loss: 2.5569470493775377

Epoch: 5| Step: 10
Training loss: 3.295057473730616
Validation loss: 2.5602955303601354

Epoch: 112| Step: 0
Training loss: 2.777266575080404
Validation loss: 2.569173603995321

Epoch: 5| Step: 1
Training loss: 2.6138769363236345
Validation loss: 2.5676465749141255

Epoch: 5| Step: 2
Training loss: 2.915518798202285
Validation loss: 2.577038723235899

Epoch: 5| Step: 3
Training loss: 2.742889401410779
Validation loss: 2.557767949292106

Epoch: 5| Step: 4
Training loss: 2.871987298507019
Validation loss: 2.5424497969025617

Epoch: 5| Step: 5
Training loss: 2.713108391806512
Validation loss: 2.541488997975491

Epoch: 5| Step: 6
Training loss: 3.1610216386942005
Validation loss: 2.541709295029999

Epoch: 5| Step: 7
Training loss: 3.122118116960805
Validation loss: 2.544176271452438

Epoch: 5| Step: 8
Training loss: 3.0247750884375395
Validation loss: 2.5347567520865075

Epoch: 5| Step: 9
Training loss: 2.98786426701629
Validation loss: 2.545825332519737

Epoch: 5| Step: 10
Training loss: 2.8376916761819397
Validation loss: 2.5480836493823964

Epoch: 113| Step: 0
Training loss: 2.902847923960384
Validation loss: 2.554104259774895

Epoch: 5| Step: 1
Training loss: 2.8149495795496042
Validation loss: 2.540207218071054

Epoch: 5| Step: 2
Training loss: 2.806183227560279
Validation loss: 2.5359944966417833

Epoch: 5| Step: 3
Training loss: 2.946684580988679
Validation loss: 2.540345277308862

Epoch: 5| Step: 4
Training loss: 3.1185773843763682
Validation loss: 2.5411929205636596

Epoch: 5| Step: 5
Training loss: 2.5394065271739983
Validation loss: 2.545334736316792

Epoch: 5| Step: 6
Training loss: 2.587240300068838
Validation loss: 2.545388161749059

Epoch: 5| Step: 7
Training loss: 2.8635180532833195
Validation loss: 2.551877504494566

Epoch: 5| Step: 8
Training loss: 3.105238727231867
Validation loss: 2.572097379516259

Epoch: 5| Step: 9
Training loss: 3.136655205906015
Validation loss: 2.5837472596603384

Epoch: 5| Step: 10
Training loss: 2.748036377106592
Validation loss: 2.5810404561299833

Epoch: 114| Step: 0
Training loss: 2.921362684081831
Validation loss: 2.5934547763347764

Epoch: 5| Step: 1
Training loss: 3.2393468707138653
Validation loss: 2.6000066207315538

Epoch: 5| Step: 2
Training loss: 3.215956132779399
Validation loss: 2.545829296060188

Epoch: 5| Step: 3
Training loss: 2.770923603470867
Validation loss: 2.5450636260954207

Epoch: 5| Step: 4
Training loss: 2.7723849166224244
Validation loss: 2.5423239636875685

Epoch: 5| Step: 5
Training loss: 3.3090406384017466
Validation loss: 2.5388123273381167

Epoch: 5| Step: 6
Training loss: 2.735471843347965
Validation loss: 2.535710778341977

Epoch: 5| Step: 7
Training loss: 2.588625614230106
Validation loss: 2.540648363484247

Epoch: 5| Step: 8
Training loss: 3.134369194656731
Validation loss: 2.5367692545119787

Epoch: 5| Step: 9
Training loss: 2.5480454452629937
Validation loss: 2.5357238972335785

Epoch: 5| Step: 10
Training loss: 2.4851749499809745
Validation loss: 2.533070440230877

Epoch: 115| Step: 0
Training loss: 2.6529317437229754
Validation loss: 2.5340644516379807

Epoch: 5| Step: 1
Training loss: 2.6153745834451625
Validation loss: 2.5428768664515085

Epoch: 5| Step: 2
Training loss: 2.641053114276424
Validation loss: 2.554618252227159

Epoch: 5| Step: 3
Training loss: 2.8657610512555065
Validation loss: 2.574010305610812

Epoch: 5| Step: 4
Training loss: 2.7866122384513012
Validation loss: 2.6017268220503937

Epoch: 5| Step: 5
Training loss: 3.005276966247847
Validation loss: 2.5918391444103164

Epoch: 5| Step: 6
Training loss: 2.977500947812792
Validation loss: 2.5689910205535695

Epoch: 5| Step: 7
Training loss: 3.5924254256905526
Validation loss: 2.5476864643695603

Epoch: 5| Step: 8
Training loss: 2.4232903067517766
Validation loss: 2.544184708496557

Epoch: 5| Step: 9
Training loss: 2.9479504011580637
Validation loss: 2.5350786010736766

Epoch: 5| Step: 10
Training loss: 3.14522644319408
Validation loss: 2.52897060638733

Epoch: 116| Step: 0
Training loss: 2.899546778549381
Validation loss: 2.5345383683108436

Epoch: 5| Step: 1
Training loss: 2.178159663664778
Validation loss: 2.532438153540413

Epoch: 5| Step: 2
Training loss: 3.2697255066619912
Validation loss: 2.527936873022674

Epoch: 5| Step: 3
Training loss: 2.615231184213186
Validation loss: 2.527337062304639

Epoch: 5| Step: 4
Training loss: 2.7811118959578263
Validation loss: 2.527195575818034

Epoch: 5| Step: 5
Training loss: 3.388606301148685
Validation loss: 2.5335658944100987

Epoch: 5| Step: 6
Training loss: 2.3824216428282186
Validation loss: 2.540218162083404

Epoch: 5| Step: 7
Training loss: 3.04756884377432
Validation loss: 2.547631273307815

Epoch: 5| Step: 8
Training loss: 2.733615268340213
Validation loss: 2.5592074146375845

Epoch: 5| Step: 9
Training loss: 3.359097065628422
Validation loss: 2.551077638570948

Epoch: 5| Step: 10
Training loss: 2.734533773989652
Validation loss: 2.5593614433673073

Epoch: 117| Step: 0
Training loss: 2.9243240292650894
Validation loss: 2.5455850615645867

Epoch: 5| Step: 1
Training loss: 2.5739327302217965
Validation loss: 2.5372911497527326

Epoch: 5| Step: 2
Training loss: 2.8390966217056386
Validation loss: 2.5346695035954054

Epoch: 5| Step: 3
Training loss: 2.9146525013269096
Validation loss: 2.5235471603535538

Epoch: 5| Step: 4
Training loss: 3.4437033426824595
Validation loss: 2.5224053418658334

Epoch: 5| Step: 5
Training loss: 2.6278491225805496
Validation loss: 2.523576159718515

Epoch: 5| Step: 6
Training loss: 2.8117116035016587
Validation loss: 2.5189986366556467

Epoch: 5| Step: 7
Training loss: 2.640352223770546
Validation loss: 2.518435206948576

Epoch: 5| Step: 8
Training loss: 2.8290518406378844
Validation loss: 2.5239553506564145

Epoch: 5| Step: 9
Training loss: 2.8302193152970787
Validation loss: 2.5270085197799954

Epoch: 5| Step: 10
Training loss: 3.178201013966968
Validation loss: 2.527437779577943

Epoch: 118| Step: 0
Training loss: 3.2930834332787797
Validation loss: 2.5315132353653222

Epoch: 5| Step: 1
Training loss: 2.361124766690527
Validation loss: 2.536542000424219

Epoch: 5| Step: 2
Training loss: 3.0507739038904034
Validation loss: 2.5604448318250657

Epoch: 5| Step: 3
Training loss: 2.8062517059932697
Validation loss: 2.5508732488212402

Epoch: 5| Step: 4
Training loss: 2.9234552852837874
Validation loss: 2.5395617144632046

Epoch: 5| Step: 5
Training loss: 2.658441155936621
Validation loss: 2.536099284526133

Epoch: 5| Step: 6
Training loss: 2.879893740442135
Validation loss: 2.5305908531900996

Epoch: 5| Step: 7
Training loss: 3.187542335378707
Validation loss: 2.520383100203145

Epoch: 5| Step: 8
Training loss: 2.741214068621297
Validation loss: 2.5155304442774753

Epoch: 5| Step: 9
Training loss: 2.506997805021928
Validation loss: 2.526064601769125

Epoch: 5| Step: 10
Training loss: 3.0565991286120964
Validation loss: 2.520713901631337

Epoch: 119| Step: 0
Training loss: 3.0781482366469066
Validation loss: 2.521964607924389

Epoch: 5| Step: 1
Training loss: 2.760427645295582
Validation loss: 2.533569781507714

Epoch: 5| Step: 2
Training loss: 2.4666911364535875
Validation loss: 2.5610308548748177

Epoch: 5| Step: 3
Training loss: 2.699864002617427
Validation loss: 2.5697534300173586

Epoch: 5| Step: 4
Training loss: 2.9134026565276727
Validation loss: 2.5688576574170816

Epoch: 5| Step: 5
Training loss: 2.871343360482445
Validation loss: 2.5448225609214585

Epoch: 5| Step: 6
Training loss: 3.4324374286146835
Validation loss: 2.5232425950827517

Epoch: 5| Step: 7
Training loss: 2.6305938337477826
Validation loss: 2.517949054891161

Epoch: 5| Step: 8
Training loss: 2.832556019537972
Validation loss: 2.5168737299287933

Epoch: 5| Step: 9
Training loss: 2.740241335522165
Validation loss: 2.5165374014349857

Epoch: 5| Step: 10
Training loss: 3.292086626778726
Validation loss: 2.516205110529083

Epoch: 120| Step: 0
Training loss: 2.276043005156542
Validation loss: 2.517476870702072

Epoch: 5| Step: 1
Training loss: 2.8762378515644307
Validation loss: 2.515912250965967

Epoch: 5| Step: 2
Training loss: 2.488969692648026
Validation loss: 2.514519671496348

Epoch: 5| Step: 3
Training loss: 2.998013792569916
Validation loss: 2.518688847418209

Epoch: 5| Step: 4
Training loss: 2.6086319647837737
Validation loss: 2.518702187289558

Epoch: 5| Step: 5
Training loss: 2.877971109092819
Validation loss: 2.5252594839968467

Epoch: 5| Step: 6
Training loss: 3.0466962713003842
Validation loss: 2.526495357797833

Epoch: 5| Step: 7
Training loss: 2.414028031680253
Validation loss: 2.5531055140377075

Epoch: 5| Step: 8
Training loss: 3.4632687262737414
Validation loss: 2.555042330637631

Epoch: 5| Step: 9
Training loss: 3.2573979614858524
Validation loss: 2.551962372502225

Epoch: 5| Step: 10
Training loss: 3.099461379481201
Validation loss: 2.55335937168109

Epoch: 121| Step: 0
Training loss: 2.4853764081211454
Validation loss: 2.5755081354785014

Epoch: 5| Step: 1
Training loss: 2.49021110972588
Validation loss: 2.568660047937366

Epoch: 5| Step: 2
Training loss: 2.3717580050235543
Validation loss: 2.5693730507816803

Epoch: 5| Step: 3
Training loss: 3.0142673737233348
Validation loss: 2.5761726740938538

Epoch: 5| Step: 4
Training loss: 3.420167958780968
Validation loss: 2.593838853891849

Epoch: 5| Step: 5
Training loss: 2.2709040732841608
Validation loss: 2.579998540045594

Epoch: 5| Step: 6
Training loss: 2.814516573739398
Validation loss: 2.55930257542991

Epoch: 5| Step: 7
Training loss: 3.4044316189089696
Validation loss: 2.542576725945181

Epoch: 5| Step: 8
Training loss: 2.691738069451352
Validation loss: 2.5291449198322

Epoch: 5| Step: 9
Training loss: 3.123403828197536
Validation loss: 2.5167206936145146

Epoch: 5| Step: 10
Training loss: 3.0990007328156906
Validation loss: 2.5159148544345227

Epoch: 122| Step: 0
Training loss: 2.59257655428916
Validation loss: 2.51058797992571

Epoch: 5| Step: 1
Training loss: 3.200862327258316
Validation loss: 2.515138164605078

Epoch: 5| Step: 2
Training loss: 2.829279374212407
Validation loss: 2.5186830202356925

Epoch: 5| Step: 3
Training loss: 3.0107607177401703
Validation loss: 2.5155469825879417

Epoch: 5| Step: 4
Training loss: 3.212703321383035
Validation loss: 2.515090047814058

Epoch: 5| Step: 5
Training loss: 2.5943747078369976
Validation loss: 2.514804090363202

Epoch: 5| Step: 6
Training loss: 2.4980044029508566
Validation loss: 2.5131555710600906

Epoch: 5| Step: 7
Training loss: 2.8190429873563456
Validation loss: 2.5133636507717068

Epoch: 5| Step: 8
Training loss: 2.887389645800304
Validation loss: 2.516600761808349

Epoch: 5| Step: 9
Training loss: 2.8203993173693904
Validation loss: 2.517470863523087

Epoch: 5| Step: 10
Training loss: 3.1032458140662222
Validation loss: 2.545440644374888

Epoch: 123| Step: 0
Training loss: 3.202648592620255
Validation loss: 2.5727151631817264

Epoch: 5| Step: 1
Training loss: 2.8676870466985642
Validation loss: 2.5801914478943293

Epoch: 5| Step: 2
Training loss: 3.274627542064228
Validation loss: 2.591077108095809

Epoch: 5| Step: 3
Training loss: 2.204099615431683
Validation loss: 2.5891742822550863

Epoch: 5| Step: 4
Training loss: 2.739091043274606
Validation loss: 2.5779705221333846

Epoch: 5| Step: 5
Training loss: 2.4874871871848288
Validation loss: 2.600903557518435

Epoch: 5| Step: 6
Training loss: 3.021966936355974
Validation loss: 2.6278224348575976

Epoch: 5| Step: 7
Training loss: 3.129078911483306
Validation loss: 2.595030469403941

Epoch: 5| Step: 8
Training loss: 3.0359110439873556
Validation loss: 2.551213080720815

Epoch: 5| Step: 9
Training loss: 2.9806596087420036
Validation loss: 2.524375819047087

Epoch: 5| Step: 10
Training loss: 2.2346046169713008
Validation loss: 2.5112792102405237

Epoch: 124| Step: 0
Training loss: 3.038367498404182
Validation loss: 2.5042194649654785

Epoch: 5| Step: 1
Training loss: 2.8688876648826493
Validation loss: 2.502364424895297

Epoch: 5| Step: 2
Training loss: 2.9933109415430317
Validation loss: 2.5075879266533416

Epoch: 5| Step: 3
Training loss: 2.461785064549813
Validation loss: 2.5095270553487175

Epoch: 5| Step: 4
Training loss: 3.342067116757986
Validation loss: 2.5062323922047223

Epoch: 5| Step: 5
Training loss: 2.7050945185085387
Validation loss: 2.511067942468089

Epoch: 5| Step: 6
Training loss: 2.6877176063621477
Validation loss: 2.5068742552516365

Epoch: 5| Step: 7
Training loss: 2.6955306255148317
Validation loss: 2.514718779804535

Epoch: 5| Step: 8
Training loss: 3.246987193485025
Validation loss: 2.53049869546039

Epoch: 5| Step: 9
Training loss: 2.0075194148624824
Validation loss: 2.539650520028798

Epoch: 5| Step: 10
Training loss: 3.2323622775850307
Validation loss: 2.5711172064591716

Epoch: 125| Step: 0
Training loss: 2.8053769935043658
Validation loss: 2.61046789226899

Epoch: 5| Step: 1
Training loss: 2.981333036086057
Validation loss: 2.633901653228224

Epoch: 5| Step: 2
Training loss: 2.7864662716951516
Validation loss: 2.6451651055798453

Epoch: 5| Step: 3
Training loss: 2.814092397239763
Validation loss: 2.6386235800164064

Epoch: 5| Step: 4
Training loss: 2.9502290927704413
Validation loss: 2.636661241664584

Epoch: 5| Step: 5
Training loss: 3.0226534041102684
Validation loss: 2.5930798976189697

Epoch: 5| Step: 6
Training loss: 2.776215443471222
Validation loss: 2.5338899636688588

Epoch: 5| Step: 7
Training loss: 2.4920541374853227
Validation loss: 2.507916675502457

Epoch: 5| Step: 8
Training loss: 2.619526378832986
Validation loss: 2.5044841687177035

Epoch: 5| Step: 9
Training loss: 3.014184162854443
Validation loss: 2.5101048646903226

Epoch: 5| Step: 10
Training loss: 3.2900170325212277
Validation loss: 2.513282244984993

Epoch: 126| Step: 0
Training loss: 2.4356842124658167
Validation loss: 2.518960456520929

Epoch: 5| Step: 1
Training loss: 2.9571926622165297
Validation loss: 2.517554975962468

Epoch: 5| Step: 2
Training loss: 2.6552239624217946
Validation loss: 2.519521358795223

Epoch: 5| Step: 3
Training loss: 2.9311983408981526
Validation loss: 2.5130539207739253

Epoch: 5| Step: 4
Training loss: 3.2601156532507862
Validation loss: 2.5124534160597496

Epoch: 5| Step: 5
Training loss: 3.1388282001071035
Validation loss: 2.5105181805283663

Epoch: 5| Step: 6
Training loss: 2.850964627231474
Validation loss: 2.5046040665785885

Epoch: 5| Step: 7
Training loss: 2.8026460746652306
Validation loss: 2.51120947293293

Epoch: 5| Step: 8
Training loss: 3.151041246314323
Validation loss: 2.5190748130223173

Epoch: 5| Step: 9
Training loss: 2.8341551505122813
Validation loss: 2.5284025431058037

Epoch: 5| Step: 10
Training loss: 2.4679545799106997
Validation loss: 2.5553402665853966

Epoch: 127| Step: 0
Training loss: 3.018837596183158
Validation loss: 2.5755305516126517

Epoch: 5| Step: 1
Training loss: 2.721919700351863
Validation loss: 2.6013054553672106

Epoch: 5| Step: 2
Training loss: 2.695033846839017
Validation loss: 2.5952094447393934

Epoch: 5| Step: 3
Training loss: 2.7250445930961926
Validation loss: 2.5767714809671984

Epoch: 5| Step: 4
Training loss: 3.2564300604475487
Validation loss: 2.540267208724483

Epoch: 5| Step: 5
Training loss: 2.6410508574240374
Validation loss: 2.5177455701212703

Epoch: 5| Step: 6
Training loss: 2.8301856189687244
Validation loss: 2.5034555375050553

Epoch: 5| Step: 7
Training loss: 2.9338458444341975
Validation loss: 2.5032947405252535

Epoch: 5| Step: 8
Training loss: 3.1013795428759967
Validation loss: 2.503044733381793

Epoch: 5| Step: 9
Training loss: 2.2722716603060427
Validation loss: 2.5141909499092883

Epoch: 5| Step: 10
Training loss: 3.226792297308313
Validation loss: 2.513358534427117

Epoch: 128| Step: 0
Training loss: 2.784659192858892
Validation loss: 2.5107630019022094

Epoch: 5| Step: 1
Training loss: 2.7663897302969764
Validation loss: 2.5157448514528737

Epoch: 5| Step: 2
Training loss: 3.404408648390974
Validation loss: 2.507677473996888

Epoch: 5| Step: 3
Training loss: 2.9016367075463747
Validation loss: 2.5103725384708517

Epoch: 5| Step: 4
Training loss: 3.4680513245371705
Validation loss: 2.508335369145939

Epoch: 5| Step: 5
Training loss: 2.513082036407946
Validation loss: 2.5130006235389586

Epoch: 5| Step: 6
Training loss: 2.441345311739481
Validation loss: 2.5182134617604643

Epoch: 5| Step: 7
Training loss: 2.4630698033739775
Validation loss: 2.506063224406618

Epoch: 5| Step: 8
Training loss: 3.1463060002880727
Validation loss: 2.5104285680582117

Epoch: 5| Step: 9
Training loss: 2.4629833618419856
Validation loss: 2.518971403282196

Epoch: 5| Step: 10
Training loss: 2.6482062224733984
Validation loss: 2.5195647440721665

Epoch: 129| Step: 0
Training loss: 2.3919010122861866
Validation loss: 2.526347024262068

Epoch: 5| Step: 1
Training loss: 2.844840710409379
Validation loss: 2.5387737645760255

Epoch: 5| Step: 2
Training loss: 2.657729510985731
Validation loss: 2.5670170722863275

Epoch: 5| Step: 3
Training loss: 3.02406734244229
Validation loss: 2.5829591724924317

Epoch: 5| Step: 4
Training loss: 2.8411172270390956
Validation loss: 2.57219682554242

Epoch: 5| Step: 5
Training loss: 3.118595579678039
Validation loss: 2.556913560720965

Epoch: 5| Step: 6
Training loss: 3.281863927174132
Validation loss: 2.552859058397099

Epoch: 5| Step: 7
Training loss: 3.0194145466309754
Validation loss: 2.5341935669629967

Epoch: 5| Step: 8
Training loss: 2.8933277588305706
Validation loss: 2.5165409027645227

Epoch: 5| Step: 9
Training loss: 2.4475090715592844
Validation loss: 2.5049864343862858

Epoch: 5| Step: 10
Training loss: 2.6426978468295332
Validation loss: 2.51049789510388

Epoch: 130| Step: 0
Training loss: 3.0744523343795835
Validation loss: 2.5102855362359215

Epoch: 5| Step: 1
Training loss: 3.465842325673259
Validation loss: 2.512372231799624

Epoch: 5| Step: 2
Training loss: 2.2245281362059623
Validation loss: 2.514306887592564

Epoch: 5| Step: 3
Training loss: 2.8282307136125557
Validation loss: 2.520804452251845

Epoch: 5| Step: 4
Training loss: 2.863519718497265
Validation loss: 2.518126836312173

Epoch: 5| Step: 5
Training loss: 2.7428646284097753
Validation loss: 2.542644366817637

Epoch: 5| Step: 6
Training loss: 2.452444577460942
Validation loss: 2.5503479559527036

Epoch: 5| Step: 7
Training loss: 2.7432374166945572
Validation loss: 2.5687981907423714

Epoch: 5| Step: 8
Training loss: 2.969497265379148
Validation loss: 2.5481978880737794

Epoch: 5| Step: 9
Training loss: 2.839242401889457
Validation loss: 2.5513280434386805

Epoch: 5| Step: 10
Training loss: 2.763619078007169
Validation loss: 2.5474670766783496

Epoch: 131| Step: 0
Training loss: 1.7329870633117361
Validation loss: 2.514690968940028

Epoch: 5| Step: 1
Training loss: 2.830401773947531
Validation loss: 2.507101581837448

Epoch: 5| Step: 2
Training loss: 2.992821847790119
Validation loss: 2.515624523067257

Epoch: 5| Step: 3
Training loss: 2.425765720876723
Validation loss: 2.515494996812688

Epoch: 5| Step: 4
Training loss: 2.9481508051939973
Validation loss: 2.5142699892694043

Epoch: 5| Step: 5
Training loss: 3.094863228926558
Validation loss: 2.508431523678697

Epoch: 5| Step: 6
Training loss: 2.8047405439795976
Validation loss: 2.5060274333162167

Epoch: 5| Step: 7
Training loss: 2.910988339253026
Validation loss: 2.508856997126996

Epoch: 5| Step: 8
Training loss: 2.827062839404727
Validation loss: 2.5146678585708697

Epoch: 5| Step: 9
Training loss: 3.0975835919126893
Validation loss: 2.508099872984975

Epoch: 5| Step: 10
Training loss: 3.1371273472978527
Validation loss: 2.5136645053450453

Epoch: 132| Step: 0
Training loss: 2.396559884297118
Validation loss: 2.512135928244278

Epoch: 5| Step: 1
Training loss: 2.978718935171792
Validation loss: 2.52195122330126

Epoch: 5| Step: 2
Training loss: 2.538312407983635
Validation loss: 2.5076117167003313

Epoch: 5| Step: 3
Training loss: 2.7536434832806362
Validation loss: 2.527461499939029

Epoch: 5| Step: 4
Training loss: 3.299538643694065
Validation loss: 2.5337216944065326

Epoch: 5| Step: 5
Training loss: 3.1944157990723876
Validation loss: 2.550583097395908

Epoch: 5| Step: 6
Training loss: 2.8157890585332845
Validation loss: 2.527069583599737

Epoch: 5| Step: 7
Training loss: 2.790247561228554
Validation loss: 2.507511315443175

Epoch: 5| Step: 8
Training loss: 2.0673130403835063
Validation loss: 2.519569537988017

Epoch: 5| Step: 9
Training loss: 3.177585816383784
Validation loss: 2.5220382007354756

Epoch: 5| Step: 10
Training loss: 2.8606089446550924
Validation loss: 2.516609807775542

Epoch: 133| Step: 0
Training loss: 2.704600730663343
Validation loss: 2.501657424667785

Epoch: 5| Step: 1
Training loss: 3.270311269381711
Validation loss: 2.5010254566731827

Epoch: 5| Step: 2
Training loss: 3.0636943123222116
Validation loss: 2.4984649806296835

Epoch: 5| Step: 3
Training loss: 2.9660524661156096
Validation loss: 2.506186055148721

Epoch: 5| Step: 4
Training loss: 2.486630357710746
Validation loss: 2.507676864696043

Epoch: 5| Step: 5
Training loss: 2.6232887321309573
Validation loss: 2.5141849471152526

Epoch: 5| Step: 6
Training loss: 2.992135229226859
Validation loss: 2.5415022958438303

Epoch: 5| Step: 7
Training loss: 3.3167146465211252
Validation loss: 2.5720995583280337

Epoch: 5| Step: 8
Training loss: 2.449215829655855
Validation loss: 2.5715211396110265

Epoch: 5| Step: 9
Training loss: 2.4348603652302003
Validation loss: 2.5640635908602594

Epoch: 5| Step: 10
Training loss: 2.7990856278471123
Validation loss: 2.549139792846787

Epoch: 134| Step: 0
Training loss: 2.616380618389305
Validation loss: 2.54806128658027

Epoch: 5| Step: 1
Training loss: 3.084147955703633
Validation loss: 2.5417381819883604

Epoch: 5| Step: 2
Training loss: 2.8850085983280462
Validation loss: 2.5307034452246078

Epoch: 5| Step: 3
Training loss: 2.696103983229321
Validation loss: 2.5260308655657076

Epoch: 5| Step: 4
Training loss: 2.769403322867486
Validation loss: 2.530461745516857

Epoch: 5| Step: 5
Training loss: 2.931278213983353
Validation loss: 2.540042570795926

Epoch: 5| Step: 6
Training loss: 2.9571766987635284
Validation loss: 2.5143051277257364

Epoch: 5| Step: 7
Training loss: 2.5567553256236666
Validation loss: 2.503430433018734

Epoch: 5| Step: 8
Training loss: 3.011415063016504
Validation loss: 2.4884346671773785

Epoch: 5| Step: 9
Training loss: 2.9051486974271383
Validation loss: 2.4898095093612973

Epoch: 5| Step: 10
Training loss: 2.666706730621103
Validation loss: 2.48336962345572

Epoch: 135| Step: 0
Training loss: 3.101855516405192
Validation loss: 2.483266147393728

Epoch: 5| Step: 1
Training loss: 2.5396291247258933
Validation loss: 2.488075007099863

Epoch: 5| Step: 2
Training loss: 2.395326267708007
Validation loss: 2.4850648853558437

Epoch: 5| Step: 3
Training loss: 2.5705110884825926
Validation loss: 2.4908593439323967

Epoch: 5| Step: 4
Training loss: 2.940272868981276
Validation loss: 2.5049877300293124

Epoch: 5| Step: 5
Training loss: 2.998126239533811
Validation loss: 2.5238892211149038

Epoch: 5| Step: 6
Training loss: 2.867030833275114
Validation loss: 2.5454389745195813

Epoch: 5| Step: 7
Training loss: 3.1630993542765005
Validation loss: 2.5491111546995135

Epoch: 5| Step: 8
Training loss: 2.7877913284310294
Validation loss: 2.5754204916973458

Epoch: 5| Step: 9
Training loss: 2.9171649688847694
Validation loss: 2.582700617815488

Epoch: 5| Step: 10
Training loss: 2.7882081334047366
Validation loss: 2.553695034855281

Epoch: 136| Step: 0
Training loss: 3.34533397199073
Validation loss: 2.51302607924326

Epoch: 5| Step: 1
Training loss: 2.88881036659859
Validation loss: 2.510226701069297

Epoch: 5| Step: 2
Training loss: 2.9236059926265834
Validation loss: 2.498238100599962

Epoch: 5| Step: 3
Training loss: 3.140119976983146
Validation loss: 2.5011988011332424

Epoch: 5| Step: 4
Training loss: 3.009312798004779
Validation loss: 2.5059177725426074

Epoch: 5| Step: 5
Training loss: 2.551239860398639
Validation loss: 2.5105195703266823

Epoch: 5| Step: 6
Training loss: 2.704651770749663
Validation loss: 2.5100923952645617

Epoch: 5| Step: 7
Training loss: 2.3872833832741525
Validation loss: 2.531344036389762

Epoch: 5| Step: 8
Training loss: 2.3345366395194027
Validation loss: 2.5466718675113285

Epoch: 5| Step: 9
Training loss: 2.753781146731791
Validation loss: 2.5513411573885043

Epoch: 5| Step: 10
Training loss: 2.7554132761507293
Validation loss: 2.5709032395406717

Epoch: 137| Step: 0
Training loss: 3.021667119857437
Validation loss: 2.558237401712145

Epoch: 5| Step: 1
Training loss: 3.184460705622969
Validation loss: 2.540665347753131

Epoch: 5| Step: 2
Training loss: 2.5798008875936347
Validation loss: 2.5244342482856585

Epoch: 5| Step: 3
Training loss: 2.9726366801877186
Validation loss: 2.5297679200707996

Epoch: 5| Step: 4
Training loss: 2.4569092736950426
Validation loss: 2.5152274553753946

Epoch: 5| Step: 5
Training loss: 2.9754373821938254
Validation loss: 2.5338187532939433

Epoch: 5| Step: 6
Training loss: 2.6205415556214273
Validation loss: 2.5273442723962076

Epoch: 5| Step: 7
Training loss: 3.2583806482442377
Validation loss: 2.528119202841974

Epoch: 5| Step: 8
Training loss: 2.9257520768426235
Validation loss: 2.5174387896901815

Epoch: 5| Step: 9
Training loss: 2.5299734970634584
Validation loss: 2.5129439381974623

Epoch: 5| Step: 10
Training loss: 2.226496538222505
Validation loss: 2.5150329406749554

Epoch: 138| Step: 0
Training loss: 2.952657188217144
Validation loss: 2.5297568558583694

Epoch: 5| Step: 1
Training loss: 2.715510224791066
Validation loss: 2.5515537113387254

Epoch: 5| Step: 2
Training loss: 2.8384301026611296
Validation loss: 2.596736798838508

Epoch: 5| Step: 3
Training loss: 2.8053287208770623
Validation loss: 2.657840369924599

Epoch: 5| Step: 4
Training loss: 3.3097540071937015
Validation loss: 2.633804562334037

Epoch: 5| Step: 5
Training loss: 2.943592814077778
Validation loss: 2.604219356537068

Epoch: 5| Step: 6
Training loss: 2.3215217906973473
Validation loss: 2.5618402845900876

Epoch: 5| Step: 7
Training loss: 2.8148465857701943
Validation loss: 2.527342047900539

Epoch: 5| Step: 8
Training loss: 3.2283649720975487
Validation loss: 2.5054103000793324

Epoch: 5| Step: 9
Training loss: 2.2596362710789726
Validation loss: 2.489314977477498

Epoch: 5| Step: 10
Training loss: 2.9727959618839725
Validation loss: 2.4935490162917127

Epoch: 139| Step: 0
Training loss: 2.7181945759597674
Validation loss: 2.494501520432298

Epoch: 5| Step: 1
Training loss: 2.8381609646808243
Validation loss: 2.4952195474310104

Epoch: 5| Step: 2
Training loss: 3.1665263061201743
Validation loss: 2.499581197299419

Epoch: 5| Step: 3
Training loss: 2.7557991610625914
Validation loss: 2.5167149830937783

Epoch: 5| Step: 4
Training loss: 2.175822451079832
Validation loss: 2.548936373163875

Epoch: 5| Step: 5
Training loss: 2.623021151941306
Validation loss: 2.6107299962989163

Epoch: 5| Step: 6
Training loss: 2.8953905567531395
Validation loss: 2.6235907092591426

Epoch: 5| Step: 7
Training loss: 2.973400929998364
Validation loss: 2.6432346061255747

Epoch: 5| Step: 8
Training loss: 2.650883268309521
Validation loss: 2.636519676966993

Epoch: 5| Step: 9
Training loss: 3.0426059648653294
Validation loss: 2.6522113400250196

Epoch: 5| Step: 10
Training loss: 3.284437248300674
Validation loss: 2.6161076915931107

Epoch: 140| Step: 0
Training loss: 2.5613555213262407
Validation loss: 2.568329916054057

Epoch: 5| Step: 1
Training loss: 2.5063238270985133
Validation loss: 2.517459941805638

Epoch: 5| Step: 2
Training loss: 2.860000625290169
Validation loss: 2.4995720179113508

Epoch: 5| Step: 3
Training loss: 2.7696926570286085
Validation loss: 2.495090779505764

Epoch: 5| Step: 4
Training loss: 2.914160187339252
Validation loss: 2.4998683792249676

Epoch: 5| Step: 5
Training loss: 2.9539737188245847
Validation loss: 2.501205443921048

Epoch: 5| Step: 6
Training loss: 2.7993408074306068
Validation loss: 2.490384920231696

Epoch: 5| Step: 7
Training loss: 2.940934466335202
Validation loss: 2.492037916482539

Epoch: 5| Step: 8
Training loss: 2.9898460529718234
Validation loss: 2.4928089248786325

Epoch: 5| Step: 9
Training loss: 2.581784789172273
Validation loss: 2.4991992324274044

Epoch: 5| Step: 10
Training loss: 3.145754747903905
Validation loss: 2.5136611948066006

Epoch: 141| Step: 0
Training loss: 2.8872756936940545
Validation loss: 2.5484558922453955

Epoch: 5| Step: 1
Training loss: 2.611862732766493
Validation loss: 2.5673710396579272

Epoch: 5| Step: 2
Training loss: 3.135401086779104
Validation loss: 2.572324500246896

Epoch: 5| Step: 3
Training loss: 2.3422189416486403
Validation loss: 2.5700548884896737

Epoch: 5| Step: 4
Training loss: 2.6508383882201167
Validation loss: 2.5855070635189015

Epoch: 5| Step: 5
Training loss: 3.040728663905268
Validation loss: 2.5772347875679356

Epoch: 5| Step: 6
Training loss: 2.91504887718197
Validation loss: 2.581081968046174

Epoch: 5| Step: 7
Training loss: 2.916394484399402
Validation loss: 2.558688852959481

Epoch: 5| Step: 8
Training loss: 3.203511135738685
Validation loss: 2.5404674626743735

Epoch: 5| Step: 9
Training loss: 2.244240276358524
Validation loss: 2.5081222588730325

Epoch: 5| Step: 10
Training loss: 2.821630534485057
Validation loss: 2.499015387587316

Epoch: 142| Step: 0
Training loss: 2.9010560579245452
Validation loss: 2.495364384911806

Epoch: 5| Step: 1
Training loss: 3.1846227188266885
Validation loss: 2.4972467263879183

Epoch: 5| Step: 2
Training loss: 2.4387288052856513
Validation loss: 2.488923519346385

Epoch: 5| Step: 3
Training loss: 2.5023012060573726
Validation loss: 2.487865169354608

Epoch: 5| Step: 4
Training loss: 2.8845227965143283
Validation loss: 2.4913303957310147

Epoch: 5| Step: 5
Training loss: 2.6338419274218072
Validation loss: 2.4895096439002704

Epoch: 5| Step: 6
Training loss: 2.844072260779626
Validation loss: 2.4916937580035823

Epoch: 5| Step: 7
Training loss: 3.4083108529715123
Validation loss: 2.505536444203768

Epoch: 5| Step: 8
Training loss: 2.6349858671963893
Validation loss: 2.507450059551634

Epoch: 5| Step: 9
Training loss: 2.5947525660568944
Validation loss: 2.5271909135341404

Epoch: 5| Step: 10
Training loss: 2.455330895618006
Validation loss: 2.5563709304140985

Epoch: 143| Step: 0
Training loss: 3.1434295430297445
Validation loss: 2.5579566115301007

Epoch: 5| Step: 1
Training loss: 2.7377175092290575
Validation loss: 2.536566163725426

Epoch: 5| Step: 2
Training loss: 2.552601186930509
Validation loss: 2.5266991809436194

Epoch: 5| Step: 3
Training loss: 2.585774304175875
Validation loss: 2.5158288295161944

Epoch: 5| Step: 4
Training loss: 2.8099873657214043
Validation loss: 2.507129235569345

Epoch: 5| Step: 5
Training loss: 3.0281497792902234
Validation loss: 2.504293175398069

Epoch: 5| Step: 6
Training loss: 2.600630676366015
Validation loss: 2.4928260396925968

Epoch: 5| Step: 7
Training loss: 2.8502647477708547
Validation loss: 2.498178773382158

Epoch: 5| Step: 8
Training loss: 2.9937743120261513
Validation loss: 2.506432144526114

Epoch: 5| Step: 9
Training loss: 2.8876206740227253
Validation loss: 2.521902522882197

Epoch: 5| Step: 10
Training loss: 2.5913479264521264
Validation loss: 2.5369520257550193

Epoch: 144| Step: 0
Training loss: 2.5583606875900817
Validation loss: 2.571903316332103

Epoch: 5| Step: 1
Training loss: 2.725531702926911
Validation loss: 2.5924981114763552

Epoch: 5| Step: 2
Training loss: 3.3624528846134214
Validation loss: 2.615351197268618

Epoch: 5| Step: 3
Training loss: 3.0879119351138486
Validation loss: 2.618760378712736

Epoch: 5| Step: 4
Training loss: 2.6202169165468536
Validation loss: 2.615603117470802

Epoch: 5| Step: 5
Training loss: 2.7203957848943503
Validation loss: 2.579502070810275

Epoch: 5| Step: 6
Training loss: 2.9103581096098594
Validation loss: 2.556361677157979

Epoch: 5| Step: 7
Training loss: 2.610512856560484
Validation loss: 2.532915301582172

Epoch: 5| Step: 8
Training loss: 2.524686049781909
Validation loss: 2.5049915299642764

Epoch: 5| Step: 9
Training loss: 3.0357981117279356
Validation loss: 2.499447030265386

Epoch: 5| Step: 10
Training loss: 2.4134461440104817
Validation loss: 2.4978782407480358

Epoch: 145| Step: 0
Training loss: 2.627752949510221
Validation loss: 2.4962376381311158

Epoch: 5| Step: 1
Training loss: 2.341451000540765
Validation loss: 2.5031982217391433

Epoch: 5| Step: 2
Training loss: 2.4447719963809162
Validation loss: 2.5082117963389186

Epoch: 5| Step: 3
Training loss: 2.556825915238216
Validation loss: 2.5230923470603903

Epoch: 5| Step: 4
Training loss: 2.0345508458423023
Validation loss: 2.555062679806825

Epoch: 5| Step: 5
Training loss: 3.145685626134894
Validation loss: 2.5934088094990506

Epoch: 5| Step: 6
Training loss: 2.9662818687710715
Validation loss: 2.5723910649070865

Epoch: 5| Step: 7
Training loss: 3.1816986247303247
Validation loss: 2.5463309039957176

Epoch: 5| Step: 8
Training loss: 3.186697017280408
Validation loss: 2.4970698073835385

Epoch: 5| Step: 9
Training loss: 2.793005200128191
Validation loss: 2.4987972124603077

Epoch: 5| Step: 10
Training loss: 3.215227588530075
Validation loss: 2.4922665757597833

Epoch: 146| Step: 0
Training loss: 2.902986067782829
Validation loss: 2.4948149943814815

Epoch: 5| Step: 1
Training loss: 2.6303955212951733
Validation loss: 2.4913286649107853

Epoch: 5| Step: 2
Training loss: 2.5431364739534894
Validation loss: 2.4988367779031946

Epoch: 5| Step: 3
Training loss: 3.044229934108728
Validation loss: 2.503712215536067

Epoch: 5| Step: 4
Training loss: 2.749010254741926
Validation loss: 2.518072136613132

Epoch: 5| Step: 5
Training loss: 2.960239136804713
Validation loss: 2.5467165488683916

Epoch: 5| Step: 6
Training loss: 2.6772273478877047
Validation loss: 2.523375963746985

Epoch: 5| Step: 7
Training loss: 2.6697038004736
Validation loss: 2.5313014495291877

Epoch: 5| Step: 8
Training loss: 2.600495540639277
Validation loss: 2.515872980551231

Epoch: 5| Step: 9
Training loss: 3.0321410137891744
Validation loss: 2.5219928529360693

Epoch: 5| Step: 10
Training loss: 2.7956379120509562
Validation loss: 2.533891397305601

Epoch: 147| Step: 0
Training loss: 2.417040226006195
Validation loss: 2.5432400401909314

Epoch: 5| Step: 1
Training loss: 3.330473881358937
Validation loss: 2.578568683828158

Epoch: 5| Step: 2
Training loss: 2.553575746302046
Validation loss: 2.558200778261467

Epoch: 5| Step: 3
Training loss: 2.590902120863743
Validation loss: 2.538035033577811

Epoch: 5| Step: 4
Training loss: 2.517032111289301
Validation loss: 2.5373469577482988

Epoch: 5| Step: 5
Training loss: 2.9477043659520428
Validation loss: 2.532082759346676

Epoch: 5| Step: 6
Training loss: 2.5826571307612674
Validation loss: 2.527617640198736

Epoch: 5| Step: 7
Training loss: 2.3580991819713946
Validation loss: 2.53840545053598

Epoch: 5| Step: 8
Training loss: 2.835203301677116
Validation loss: 2.5457148166384433

Epoch: 5| Step: 9
Training loss: 3.278600876762288
Validation loss: 2.5363716308938673

Epoch: 5| Step: 10
Training loss: 2.8134207172141106
Validation loss: 2.5387535544617497

Epoch: 148| Step: 0
Training loss: 2.1736934376794586
Validation loss: 2.533650888084277

Epoch: 5| Step: 1
Training loss: 2.709574067965528
Validation loss: 2.5415911465753527

Epoch: 5| Step: 2
Training loss: 3.0333642566767485
Validation loss: 2.5514631497639986

Epoch: 5| Step: 3
Training loss: 2.275201486740753
Validation loss: 2.558960670075891

Epoch: 5| Step: 4
Training loss: 2.841718346208802
Validation loss: 2.546079922077235

Epoch: 5| Step: 5
Training loss: 3.0058222539740025
Validation loss: 2.544581944415107

Epoch: 5| Step: 6
Training loss: 2.622485273263491
Validation loss: 2.5560732489972553

Epoch: 5| Step: 7
Training loss: 3.000341395980071
Validation loss: 2.564682918873013

Epoch: 5| Step: 8
Training loss: 2.86279875682992
Validation loss: 2.567308233279386

Epoch: 5| Step: 9
Training loss: 2.9452972816458627
Validation loss: 2.544654647878373

Epoch: 5| Step: 10
Training loss: 2.662711687582598
Validation loss: 2.5565491706530175

Epoch: 149| Step: 0
Training loss: 3.2153441548390456
Validation loss: 2.5281331632371735

Epoch: 5| Step: 1
Training loss: 2.235257274660646
Validation loss: 2.5269714416994886

Epoch: 5| Step: 2
Training loss: 2.705044280022929
Validation loss: 2.5375170486227443

Epoch: 5| Step: 3
Training loss: 3.12730139866402
Validation loss: 2.535631960440306

Epoch: 5| Step: 4
Training loss: 3.013801141761433
Validation loss: 2.566706785171621

Epoch: 5| Step: 5
Training loss: 2.7629821563707826
Validation loss: 2.5735737691903124

Epoch: 5| Step: 6
Training loss: 3.026440137320604
Validation loss: 2.5784094471162247

Epoch: 5| Step: 7
Training loss: 2.629656521665146
Validation loss: 2.564058381714384

Epoch: 5| Step: 8
Training loss: 2.9315091992526194
Validation loss: 2.580844220500682

Epoch: 5| Step: 9
Training loss: 1.9914407564737646
Validation loss: 2.5748608541322513

Epoch: 5| Step: 10
Training loss: 2.0942559840743096
Validation loss: 2.58838008933337

Epoch: 150| Step: 0
Training loss: 2.6375075679146183
Validation loss: 2.5960597510076338

Epoch: 5| Step: 1
Training loss: 2.481485281678301
Validation loss: 2.58300929728269

Epoch: 5| Step: 2
Training loss: 2.785179705206723
Validation loss: 2.556801826090791

Epoch: 5| Step: 3
Training loss: 2.6269541233443734
Validation loss: 2.5336050049275105

Epoch: 5| Step: 4
Training loss: 2.8658474069397486
Validation loss: 2.5392682149770036

Epoch: 5| Step: 5
Training loss: 2.703286755964514
Validation loss: 2.519624547557716

Epoch: 5| Step: 6
Training loss: 2.7099579462258268
Validation loss: 2.5217913830277072

Epoch: 5| Step: 7
Training loss: 3.1124776571306816
Validation loss: 2.5152214856325834

Epoch: 5| Step: 8
Training loss: 3.062551381205614
Validation loss: 2.528421708468443

Epoch: 5| Step: 9
Training loss: 2.435576437959614
Validation loss: 2.5317699111625696

Epoch: 5| Step: 10
Training loss: 2.6514806677487415
Validation loss: 2.537689530921015

Epoch: 151| Step: 0
Training loss: 2.85170145610707
Validation loss: 2.5390892947465673

Epoch: 5| Step: 1
Training loss: 2.3189946294922223
Validation loss: 2.5648742249569936

Epoch: 5| Step: 2
Training loss: 2.6757695775577983
Validation loss: 2.5884385881450647

Epoch: 5| Step: 3
Training loss: 3.130728696879037
Validation loss: 2.5783895317686847

Epoch: 5| Step: 4
Training loss: 2.640133061379125
Validation loss: 2.55701296964579

Epoch: 5| Step: 5
Training loss: 2.6097019013628837
Validation loss: 2.559429374857549

Epoch: 5| Step: 6
Training loss: 2.2877651873853453
Validation loss: 2.554496853105142

Epoch: 5| Step: 7
Training loss: 2.4238364859658876
Validation loss: 2.5477027607340803

Epoch: 5| Step: 8
Training loss: 2.6773149758744306
Validation loss: 2.562726062614452

Epoch: 5| Step: 9
Training loss: 3.3789425180947337
Validation loss: 2.573875038683427

Epoch: 5| Step: 10
Training loss: 2.7308563262961725
Validation loss: 2.571083683007382

Epoch: 152| Step: 0
Training loss: 2.6551166584944705
Validation loss: 2.560109728187526

Epoch: 5| Step: 1
Training loss: 2.314209486615919
Validation loss: 2.5593763532112477

Epoch: 5| Step: 2
Training loss: 2.674788821432042
Validation loss: 2.5560986257791587

Epoch: 5| Step: 3
Training loss: 2.845517793274331
Validation loss: 2.5550301507580744

Epoch: 5| Step: 4
Training loss: 2.509228553156591
Validation loss: 2.5587223228896097

Epoch: 5| Step: 5
Training loss: 3.0503087184567184
Validation loss: 2.5897151878176783

Epoch: 5| Step: 6
Training loss: 3.0267958803645154
Validation loss: 2.6203217371469005

Epoch: 5| Step: 7
Training loss: 3.0604456024844815
Validation loss: 2.5988577730514577

Epoch: 5| Step: 8
Training loss: 2.3501012577399423
Validation loss: 2.5795776600198352

Epoch: 5| Step: 9
Training loss: 2.3885082772127295
Validation loss: 2.5651898216703417

Epoch: 5| Step: 10
Training loss: 2.9005214879989683
Validation loss: 2.5351490924632474

Epoch: 153| Step: 0
Training loss: 3.0327223515267923
Validation loss: 2.5309030752625867

Epoch: 5| Step: 1
Training loss: 2.688538106871392
Validation loss: 2.5339192119237017

Epoch: 5| Step: 2
Training loss: 2.797583974987513
Validation loss: 2.529609731080394

Epoch: 5| Step: 3
Training loss: 2.3290503794166497
Validation loss: 2.530384899820542

Epoch: 5| Step: 4
Training loss: 3.0134957658261037
Validation loss: 2.5285824435855226

Epoch: 5| Step: 5
Training loss: 3.0584277111601135
Validation loss: 2.545319263787156

Epoch: 5| Step: 6
Training loss: 2.5415123022345707
Validation loss: 2.5720800585946932

Epoch: 5| Step: 7
Training loss: 2.67813652685972
Validation loss: 2.5732558124345988

Epoch: 5| Step: 8
Training loss: 2.55165400624223
Validation loss: 2.5476930342471182

Epoch: 5| Step: 9
Training loss: 2.1189101977255644
Validation loss: 2.574741704840998

Epoch: 5| Step: 10
Training loss: 2.753459228596142
Validation loss: 2.5968336407962407

Epoch: 154| Step: 0
Training loss: 2.463751742954112
Validation loss: 2.5845413664930827

Epoch: 5| Step: 1
Training loss: 2.683172067886484
Validation loss: 2.5928659050460037

Epoch: 5| Step: 2
Training loss: 2.2547782387983184
Validation loss: 2.6065930495031973

Epoch: 5| Step: 3
Training loss: 2.7954931841517983
Validation loss: 2.58887450944071

Epoch: 5| Step: 4
Training loss: 2.4963811431346166
Validation loss: 2.55871082280104

Epoch: 5| Step: 5
Training loss: 3.0871307770041376
Validation loss: 2.544829766805195

Epoch: 5| Step: 6
Training loss: 2.6237257634934035
Validation loss: 2.535543962521835

Epoch: 5| Step: 7
Training loss: 2.777913438875131
Validation loss: 2.531749462871502

Epoch: 5| Step: 8
Training loss: 2.1458260495948007
Validation loss: 2.542524594078602

Epoch: 5| Step: 9
Training loss: 2.963281674816243
Validation loss: 2.5307166832704424

Epoch: 5| Step: 10
Training loss: 3.0742966134318266
Validation loss: 2.5406048760943225

Epoch: 155| Step: 0
Training loss: 2.773525526772063
Validation loss: 2.5365415178228985

Epoch: 5| Step: 1
Training loss: 2.882492750676511
Validation loss: 2.568537630698172

Epoch: 5| Step: 2
Training loss: 2.211622799187011
Validation loss: 2.5979653263946796

Epoch: 5| Step: 3
Training loss: 2.6439457164853426
Validation loss: 2.601625918122551

Epoch: 5| Step: 4
Training loss: 2.663020402796503
Validation loss: 2.5798624577386247

Epoch: 5| Step: 5
Training loss: 2.8383109929326875
Validation loss: 2.5898937326374147

Epoch: 5| Step: 6
Training loss: 2.6556012427240776
Validation loss: 2.5656236138325763

Epoch: 5| Step: 7
Training loss: 2.3936763064841053
Validation loss: 2.5461406604099723

Epoch: 5| Step: 8
Training loss: 3.1118145291286705
Validation loss: 2.5428156065555307

Epoch: 5| Step: 9
Training loss: 2.4386824649627905
Validation loss: 2.551746432727952

Epoch: 5| Step: 10
Training loss: 2.8565145891706085
Validation loss: 2.560302298182033

Epoch: 156| Step: 0
Training loss: 2.409233918370172
Validation loss: 2.589556272208226

Epoch: 5| Step: 1
Training loss: 2.3513307172030475
Validation loss: 2.577390162457046

Epoch: 5| Step: 2
Training loss: 2.367750547821236
Validation loss: 2.5742422130790854

Epoch: 5| Step: 3
Training loss: 2.433146183010875
Validation loss: 2.563787910520037

Epoch: 5| Step: 4
Training loss: 2.8214982094888312
Validation loss: 2.5531604080334533

Epoch: 5| Step: 5
Training loss: 3.4063981050262986
Validation loss: 2.5578121381373222

Epoch: 5| Step: 6
Training loss: 2.693639086499955
Validation loss: 2.5706247513510054

Epoch: 5| Step: 7
Training loss: 2.857579235403436
Validation loss: 2.573416313436179

Epoch: 5| Step: 8
Training loss: 2.527734363681473
Validation loss: 2.5808945005976414

Epoch: 5| Step: 9
Training loss: 2.755057625834255
Validation loss: 2.5835092443644463

Epoch: 5| Step: 10
Training loss: 2.478309087662489
Validation loss: 2.5822266269924405

Epoch: 157| Step: 0
Training loss: 2.5456309644449866
Validation loss: 2.5669939895834295

Epoch: 5| Step: 1
Training loss: 2.831275660249077
Validation loss: 2.5498908530869433

Epoch: 5| Step: 2
Training loss: 3.2174940899703515
Validation loss: 2.535141135519785

Epoch: 5| Step: 3
Training loss: 2.4668492593284883
Validation loss: 2.538222869801713

Epoch: 5| Step: 4
Training loss: 2.4361294536801386
Validation loss: 2.541599392483915

Epoch: 5| Step: 5
Training loss: 2.7615134501463787
Validation loss: 2.5582688728488296

Epoch: 5| Step: 6
Training loss: 2.7903118167124017
Validation loss: 2.5689427308805786

Epoch: 5| Step: 7
Training loss: 2.6906792222074425
Validation loss: 2.567256806336029

Epoch: 5| Step: 8
Training loss: 2.612862455056793
Validation loss: 2.561530611414583

Epoch: 5| Step: 9
Training loss: 2.660443933198348
Validation loss: 2.5779787237758494

Epoch: 5| Step: 10
Training loss: 1.9820533447477595
Validation loss: 2.5780787707746073

Epoch: 158| Step: 0
Training loss: 2.4990268720668074
Validation loss: 2.5875309192929796

Epoch: 5| Step: 1
Training loss: 3.0073528780828145
Validation loss: 2.5750915759558866

Epoch: 5| Step: 2
Training loss: 2.533077098620358
Validation loss: 2.56523984095615

Epoch: 5| Step: 3
Training loss: 2.949359572124286
Validation loss: 2.5575705013826955

Epoch: 5| Step: 4
Training loss: 2.2703944024095626
Validation loss: 2.5598347106539205

Epoch: 5| Step: 5
Training loss: 2.6733111710077657
Validation loss: 2.594275765097551

Epoch: 5| Step: 6
Training loss: 2.681175864023929
Validation loss: 2.596697530485503

Epoch: 5| Step: 7
Training loss: 2.8784356528427297
Validation loss: 2.6150448335497374

Epoch: 5| Step: 8
Training loss: 2.6762172817063656
Validation loss: 2.599075177316368

Epoch: 5| Step: 9
Training loss: 2.667960171106266
Validation loss: 2.562343183431724

Epoch: 5| Step: 10
Training loss: 2.1569285776253815
Validation loss: 2.5696645823279245

Epoch: 159| Step: 0
Training loss: 2.5504983041111164
Validation loss: 2.5741130414958966

Epoch: 5| Step: 1
Training loss: 2.742608975355258
Validation loss: 2.549622130742711

Epoch: 5| Step: 2
Training loss: 2.8076210937472825
Validation loss: 2.552902983752065

Epoch: 5| Step: 3
Training loss: 2.6108934929527416
Validation loss: 2.529691055324641

Epoch: 5| Step: 4
Training loss: 3.0708258978565177
Validation loss: 2.552374180353157

Epoch: 5| Step: 5
Training loss: 3.2775659133486874
Validation loss: 2.564396250394271

Epoch: 5| Step: 6
Training loss: 2.5844266690274975
Validation loss: 2.5697697839705125

Epoch: 5| Step: 7
Training loss: 1.7275723227172013
Validation loss: 2.5800032251469354

Epoch: 5| Step: 8
Training loss: 2.4584936208248487
Validation loss: 2.589803501070609

Epoch: 5| Step: 9
Training loss: 2.3656381503385937
Validation loss: 2.61943609732308

Epoch: 5| Step: 10
Training loss: 2.459254000836657
Validation loss: 2.6257830134155986

Epoch: 160| Step: 0
Training loss: 2.827781445622225
Validation loss: 2.611053978863599

Epoch: 5| Step: 1
Training loss: 2.4706527523891704
Validation loss: 2.5879371187843927

Epoch: 5| Step: 2
Training loss: 2.2568407970658413
Validation loss: 2.6018917485495323

Epoch: 5| Step: 3
Training loss: 2.5019006180148513
Validation loss: 2.573797650957748

Epoch: 5| Step: 4
Training loss: 2.9517744901992784
Validation loss: 2.591102837110861

Epoch: 5| Step: 5
Training loss: 2.689004698624767
Validation loss: 2.5845726105773634

Epoch: 5| Step: 6
Training loss: 2.6580141380112017
Validation loss: 2.569301939802766

Epoch: 5| Step: 7
Training loss: 2.746542664648436
Validation loss: 2.5787485422058074

Epoch: 5| Step: 8
Training loss: 2.610854043773919
Validation loss: 2.5718885578565747

Epoch: 5| Step: 9
Training loss: 2.4341331116913323
Validation loss: 2.5892993307328966

Epoch: 5| Step: 10
Training loss: 2.7437465832804127
Validation loss: 2.6155459358485045

Epoch: 161| Step: 0
Training loss: 3.1581839500132953
Validation loss: 2.601314634491754

Epoch: 5| Step: 1
Training loss: 2.45485019156836
Validation loss: 2.5827220206021533

Epoch: 5| Step: 2
Training loss: 2.014256922391445
Validation loss: 2.5891101492126474

Epoch: 5| Step: 3
Training loss: 2.406695535210144
Validation loss: 2.5970211225018796

Epoch: 5| Step: 4
Training loss: 2.6248478618312356
Validation loss: 2.591372960764293

Epoch: 5| Step: 5
Training loss: 2.36289160172374
Validation loss: 2.588984760866952

Epoch: 5| Step: 6
Training loss: 2.8528339216614977
Validation loss: 2.6300633463113976

Epoch: 5| Step: 7
Training loss: 2.8825567695473207
Validation loss: 2.583104832719083

Epoch: 5| Step: 8
Training loss: 2.4980758891981965
Validation loss: 2.5270345171268507

Epoch: 5| Step: 9
Training loss: 2.8694941002372505
Validation loss: 2.520659546915694

Epoch: 5| Step: 10
Training loss: 2.6182072261338467
Validation loss: 2.526524380146155

Epoch: 162| Step: 0
Training loss: 2.993260920639208
Validation loss: 2.528863908207692

Epoch: 5| Step: 1
Training loss: 3.0816063727062404
Validation loss: 2.532331249161072

Epoch: 5| Step: 2
Training loss: 1.9253226269946495
Validation loss: 2.545952232233017

Epoch: 5| Step: 3
Training loss: 2.6434904724145656
Validation loss: 2.5689384916446185

Epoch: 5| Step: 4
Training loss: 2.443909458899478
Validation loss: 2.5922858470315453

Epoch: 5| Step: 5
Training loss: 2.569673313796178
Validation loss: 2.6293507707732267

Epoch: 5| Step: 6
Training loss: 2.556195481891846
Validation loss: 2.7093279795628087

Epoch: 5| Step: 7
Training loss: 2.6906093087442153
Validation loss: 2.6765416464223617

Epoch: 5| Step: 8
Training loss: 3.1316218598878818
Validation loss: 2.6523868194170883

Epoch: 5| Step: 9
Training loss: 2.5486595595002353
Validation loss: 2.5871763955471927

Epoch: 5| Step: 10
Training loss: 1.9775367717965129
Validation loss: 2.537767029751247

Epoch: 163| Step: 0
Training loss: 2.6480952128899675
Validation loss: 2.526805733120961

Epoch: 5| Step: 1
Training loss: 2.7258113493149967
Validation loss: 2.5424510492540886

Epoch: 5| Step: 2
Training loss: 2.907743828898879
Validation loss: 2.5362563905116033

Epoch: 5| Step: 3
Training loss: 3.1726506229173195
Validation loss: 2.518554085920132

Epoch: 5| Step: 4
Training loss: 2.248315604526231
Validation loss: 2.51681371236304

Epoch: 5| Step: 5
Training loss: 2.6596666689372856
Validation loss: 2.557389687879919

Epoch: 5| Step: 6
Training loss: 2.9113131482952026
Validation loss: 2.6072091618395694

Epoch: 5| Step: 7
Training loss: 2.2155489328774958
Validation loss: 2.6559671983729456

Epoch: 5| Step: 8
Training loss: 3.2325497697036067
Validation loss: 2.7046837325173056

Epoch: 5| Step: 9
Training loss: 2.4467447492247505
Validation loss: 2.6128667711836595

Epoch: 5| Step: 10
Training loss: 1.8655244451928745
Validation loss: 2.5358360005302356

Epoch: 164| Step: 0
Training loss: 2.6291381370902878
Validation loss: 2.5301870131830597

Epoch: 5| Step: 1
Training loss: 2.763332559089261
Validation loss: 2.510170116494583

Epoch: 5| Step: 2
Training loss: 2.4412678671718697
Validation loss: 2.526556306170679

Epoch: 5| Step: 3
Training loss: 2.2266514810550655
Validation loss: 2.5217172314946192

Epoch: 5| Step: 4
Training loss: 2.8071828808110024
Validation loss: 2.522595716915609

Epoch: 5| Step: 5
Training loss: 2.861114973129415
Validation loss: 2.552247736048954

Epoch: 5| Step: 6
Training loss: 2.3707625080741304
Validation loss: 2.556003297559379

Epoch: 5| Step: 7
Training loss: 2.743681150367661
Validation loss: 2.575534199690625

Epoch: 5| Step: 8
Training loss: 2.6970381810049675
Validation loss: 2.5925221774659444

Epoch: 5| Step: 9
Training loss: 2.8729303622916356
Validation loss: 2.6654158114494146

Epoch: 5| Step: 10
Training loss: 2.704577546333638
Validation loss: 2.731647595932741

Epoch: 165| Step: 0
Training loss: 2.63561437013512
Validation loss: 2.662510948229895

Epoch: 5| Step: 1
Training loss: 2.5944033799426154
Validation loss: 2.6168456337791826

Epoch: 5| Step: 2
Training loss: 2.6530471341014956
Validation loss: 2.5815594332229495

Epoch: 5| Step: 3
Training loss: 2.7931121575945252
Validation loss: 2.575381399028991

Epoch: 5| Step: 4
Training loss: 2.8803167523930786
Validation loss: 2.552056739640109

Epoch: 5| Step: 5
Training loss: 2.1123954340770736
Validation loss: 2.544589360537531

Epoch: 5| Step: 6
Training loss: 2.6532183231974216
Validation loss: 2.5384563894468464

Epoch: 5| Step: 7
Training loss: 2.4330935630070694
Validation loss: 2.5239326349149653

Epoch: 5| Step: 8
Training loss: 3.008476679408034
Validation loss: 2.5322498699970324

Epoch: 5| Step: 9
Training loss: 2.7525724170385164
Validation loss: 2.536422336741801

Epoch: 5| Step: 10
Training loss: 2.232740431223799
Validation loss: 2.543770873930536

Epoch: 166| Step: 0
Training loss: 2.5175341830920805
Validation loss: 2.580114756862984

Epoch: 5| Step: 1
Training loss: 2.6527084976212616
Validation loss: 2.5999763213578957

Epoch: 5| Step: 2
Training loss: 2.498067490386006
Validation loss: 2.582308766180372

Epoch: 5| Step: 3
Training loss: 3.2096473348008105
Validation loss: 2.595494663671977

Epoch: 5| Step: 4
Training loss: 2.5357383212633238
Validation loss: 2.6427726072863633

Epoch: 5| Step: 5
Training loss: 2.4074162220861446
Validation loss: 2.6221058062911626

Epoch: 5| Step: 6
Training loss: 2.4093399025504327
Validation loss: 2.5984940142565125

Epoch: 5| Step: 7
Training loss: 2.854088069826709
Validation loss: 2.587782839300617

Epoch: 5| Step: 8
Training loss: 1.8778677943559348
Validation loss: 2.5672204723298737

Epoch: 5| Step: 9
Training loss: 2.5683979916298414
Validation loss: 2.5690273384998155

Epoch: 5| Step: 10
Training loss: 2.907755964038063
Validation loss: 2.5713771960453258

Epoch: 167| Step: 0
Training loss: 2.666266282144112
Validation loss: 2.572494409081259

Epoch: 5| Step: 1
Training loss: 2.703028153465164
Validation loss: 2.57921686652595

Epoch: 5| Step: 2
Training loss: 2.385863205428146
Validation loss: 2.610342032130797

Epoch: 5| Step: 3
Training loss: 2.438220577835738
Validation loss: 2.638613897206912

Epoch: 5| Step: 4
Training loss: 2.684628127645678
Validation loss: 2.683775273082309

Epoch: 5| Step: 5
Training loss: 2.7915470799885287
Validation loss: 2.6897475671338396

Epoch: 5| Step: 6
Training loss: 2.5170763461234853
Validation loss: 2.643915438745389

Epoch: 5| Step: 7
Training loss: 2.440044346703435
Validation loss: 2.62932226525592

Epoch: 5| Step: 8
Training loss: 2.698293789657675
Validation loss: 2.6128437206876383

Epoch: 5| Step: 9
Training loss: 2.831098984486579
Validation loss: 2.5709504633242455

Epoch: 5| Step: 10
Training loss: 2.156738668160623
Validation loss: 2.5781116981200483

Epoch: 168| Step: 0
Training loss: 2.1719168240478903
Validation loss: 2.5530883765550096

Epoch: 5| Step: 1
Training loss: 2.6291144686765344
Validation loss: 2.568354691616146

Epoch: 5| Step: 2
Training loss: 2.609387883137405
Validation loss: 2.571177602609132

Epoch: 5| Step: 3
Training loss: 2.2609655414099876
Validation loss: 2.571167195683816

Epoch: 5| Step: 4
Training loss: 2.8344176031609893
Validation loss: 2.588799251102689

Epoch: 5| Step: 5
Training loss: 2.911594685663928
Validation loss: 2.5718723379889465

Epoch: 5| Step: 6
Training loss: 2.2170062667833816
Validation loss: 2.606255853858406

Epoch: 5| Step: 7
Training loss: 2.808499351899363
Validation loss: 2.6328560281585673

Epoch: 5| Step: 8
Training loss: 2.160932018744743
Validation loss: 2.6111245389171414

Epoch: 5| Step: 9
Training loss: 2.952628119109045
Validation loss: 2.6421775023368745

Epoch: 5| Step: 10
Training loss: 2.323150235280972
Validation loss: 2.5990288492426115

Epoch: 169| Step: 0
Training loss: 2.4630318585285713
Validation loss: 2.56116160514406

Epoch: 5| Step: 1
Training loss: 2.909059376708278
Validation loss: 2.5412675499461774

Epoch: 5| Step: 2
Training loss: 2.3681334566321235
Validation loss: 2.530354680636955

Epoch: 5| Step: 3
Training loss: 2.2045442595474163
Validation loss: 2.536189912546692

Epoch: 5| Step: 4
Training loss: 2.394717434837021
Validation loss: 2.5521820508001576

Epoch: 5| Step: 5
Training loss: 3.182604152656262
Validation loss: 2.5602651915938037

Epoch: 5| Step: 6
Training loss: 2.512091388024064
Validation loss: 2.586428102121489

Epoch: 5| Step: 7
Training loss: 2.808303584574204
Validation loss: 2.622390125476715

Epoch: 5| Step: 8
Training loss: 3.152812029577351
Validation loss: 2.6527752689343336

Epoch: 5| Step: 9
Training loss: 1.8912800056210253
Validation loss: 2.6208297459360175

Epoch: 5| Step: 10
Training loss: 2.0213411879391074
Validation loss: 2.592900063416132

Epoch: 170| Step: 0
Training loss: 3.0103105748543753
Validation loss: 2.5654289280298883

Epoch: 5| Step: 1
Training loss: 2.5450789782967096
Validation loss: 2.5410251974624023

Epoch: 5| Step: 2
Training loss: 2.6019749586526237
Validation loss: 2.4946501757237503

Epoch: 5| Step: 3
Training loss: 2.5920926969459535
Validation loss: 2.471548641364308

Epoch: 5| Step: 4
Training loss: 2.7433368415238424
Validation loss: 2.4738850313390213

Epoch: 5| Step: 5
Training loss: 2.6481678693235122
Validation loss: 2.474103094678833

Epoch: 5| Step: 6
Training loss: 2.481678488989092
Validation loss: 2.4908077012869287

Epoch: 5| Step: 7
Training loss: 1.9903724929457423
Validation loss: 2.502731670505957

Epoch: 5| Step: 8
Training loss: 2.5949751017410563
Validation loss: 2.5385027014806196

Epoch: 5| Step: 9
Training loss: 2.1975409983693504
Validation loss: 2.6040298865708817

Epoch: 5| Step: 10
Training loss: 2.7001267050223863
Validation loss: 2.6735133307996315

Epoch: 171| Step: 0
Training loss: 2.5997130088870697
Validation loss: 2.6978258111380553

Epoch: 5| Step: 1
Training loss: 2.8887573807282454
Validation loss: 2.6904642623127826

Epoch: 5| Step: 2
Training loss: 2.7929054093014276
Validation loss: 2.670044522932213

Epoch: 5| Step: 3
Training loss: 2.384659848378435
Validation loss: 2.630682932262385

Epoch: 5| Step: 4
Training loss: 2.818081382740487
Validation loss: 2.569391988366447

Epoch: 5| Step: 5
Training loss: 2.4608919654145516
Validation loss: 2.5391253629085475

Epoch: 5| Step: 6
Training loss: 1.886852567677745
Validation loss: 2.5211087995625077

Epoch: 5| Step: 7
Training loss: 2.9042704413621374
Validation loss: 2.5290913413332627

Epoch: 5| Step: 8
Training loss: 2.253455687235113
Validation loss: 2.5357726931316207

Epoch: 5| Step: 9
Training loss: 2.2529864095319447
Validation loss: 2.555102919132027

Epoch: 5| Step: 10
Training loss: 2.5602055954331973
Validation loss: 2.555172385535482

Epoch: 172| Step: 0
Training loss: 2.426036974808341
Validation loss: 2.5555422014422855

Epoch: 5| Step: 1
Training loss: 2.4480041704703317
Validation loss: 2.558275008698331

Epoch: 5| Step: 2
Training loss: 2.2575681349567653
Validation loss: 2.555632220227437

Epoch: 5| Step: 3
Training loss: 2.0791941022368765
Validation loss: 2.523076371327528

Epoch: 5| Step: 4
Training loss: 2.4536818340081306
Validation loss: 2.531839115565322

Epoch: 5| Step: 5
Training loss: 2.5144175599412613
Validation loss: 2.560145995882556

Epoch: 5| Step: 6
Training loss: 2.1573044783136432
Validation loss: 2.589514597159201

Epoch: 5| Step: 7
Training loss: 2.3954863144928136
Validation loss: 2.605176417993639

Epoch: 5| Step: 8
Training loss: 3.016474154601431
Validation loss: 2.5851542862403005

Epoch: 5| Step: 9
Training loss: 3.0129949139420114
Validation loss: 2.587420217520432

Epoch: 5| Step: 10
Training loss: 2.578150153759868
Validation loss: 2.587810547221073

Epoch: 173| Step: 0
Training loss: 2.6030618282131224
Validation loss: 2.6065141049608536

Epoch: 5| Step: 1
Training loss: 2.3702803446751854
Validation loss: 2.6476604069258816

Epoch: 5| Step: 2
Training loss: 2.2131890468600086
Validation loss: 2.6550193044408195

Epoch: 5| Step: 3
Training loss: 2.2406059828287717
Validation loss: 2.6371036512642645

Epoch: 5| Step: 4
Training loss: 2.5507346086195675
Validation loss: 2.6437322212536256

Epoch: 5| Step: 5
Training loss: 2.638352539256065
Validation loss: 2.6347871750308847

Epoch: 5| Step: 6
Training loss: 2.331072484025593
Validation loss: 2.603561274558151

Epoch: 5| Step: 7
Training loss: 2.4829192304867367
Validation loss: 2.5996331315771672

Epoch: 5| Step: 8
Training loss: 2.860293881716128
Validation loss: 2.56338761926473

Epoch: 5| Step: 9
Training loss: 2.2999937720836408
Validation loss: 2.5530879026041258

Epoch: 5| Step: 10
Training loss: 2.4964750234529904
Validation loss: 2.5601934891833635

Epoch: 174| Step: 0
Training loss: 2.5458332575804787
Validation loss: 2.5642574175550497

Epoch: 5| Step: 1
Training loss: 2.44751813092788
Validation loss: 2.5701874773224884

Epoch: 5| Step: 2
Training loss: 2.164402022736957
Validation loss: 2.5828057113193075

Epoch: 5| Step: 3
Training loss: 2.5036172447109233
Validation loss: 2.5979632304564273

Epoch: 5| Step: 4
Training loss: 2.30498189823879
Validation loss: 2.630966114075933

Epoch: 5| Step: 5
Training loss: 2.107819386238404
Validation loss: 2.63569687937576

Epoch: 5| Step: 6
Training loss: 2.3759359222210192
Validation loss: 2.6413555208780335

Epoch: 5| Step: 7
Training loss: 2.8864871540005095
Validation loss: 2.660112519969618

Epoch: 5| Step: 8
Training loss: 2.501630918673932
Validation loss: 2.6901398542929864

Epoch: 5| Step: 9
Training loss: 2.341146014379396
Validation loss: 2.6962595180260736

Epoch: 5| Step: 10
Training loss: 2.5717293680705278
Validation loss: 2.6527470537851205

Epoch: 175| Step: 0
Training loss: 2.624301363299623
Validation loss: 2.640784931382013

Epoch: 5| Step: 1
Training loss: 2.4460559238955897
Validation loss: 2.6141165497362127

Epoch: 5| Step: 2
Training loss: 2.6361501122945903
Validation loss: 2.6046959071381672

Epoch: 5| Step: 3
Training loss: 2.504843216670476
Validation loss: 2.589849474483344

Epoch: 5| Step: 4
Training loss: 2.6899745106109867
Validation loss: 2.608960254354293

Epoch: 5| Step: 5
Training loss: 2.2221690953050044
Validation loss: 2.599817002508488

Epoch: 5| Step: 6
Training loss: 1.9628786001264134
Validation loss: 2.5863376961204434

Epoch: 5| Step: 7
Training loss: 2.2445270945918505
Validation loss: 2.589342152782455

Epoch: 5| Step: 8
Training loss: 2.7092744414819956
Validation loss: 2.6257294346005255

Epoch: 5| Step: 9
Training loss: 2.1344353506735296
Validation loss: 2.6594148431813025

Epoch: 5| Step: 10
Training loss: 2.2647679253393167
Validation loss: 2.6524578853258935

Epoch: 176| Step: 0
Training loss: 2.0982368560782936
Validation loss: 2.6333267509603524

Epoch: 5| Step: 1
Training loss: 2.320166175415668
Validation loss: 2.614329205896407

Epoch: 5| Step: 2
Training loss: 2.1624453455021553
Validation loss: 2.6398835354460233

Epoch: 5| Step: 3
Training loss: 2.511452383390066
Validation loss: 2.641766268461265

Epoch: 5| Step: 4
Training loss: 2.5147747237706835
Validation loss: 2.649034914857554

Epoch: 5| Step: 5
Training loss: 2.1248014020679626
Validation loss: 2.677196580890278

Epoch: 5| Step: 6
Training loss: 2.330798770710569
Validation loss: 2.660121683135836

Epoch: 5| Step: 7
Training loss: 2.641576290891131
Validation loss: 2.6949857780386752

Epoch: 5| Step: 8
Training loss: 2.382534523680772
Validation loss: 2.718602192611103

Epoch: 5| Step: 9
Training loss: 2.2803190239019284
Validation loss: 2.720027146007913

Epoch: 5| Step: 10
Training loss: 2.774230156039545
Validation loss: 2.666626356638011

Epoch: 177| Step: 0
Training loss: 2.3608899841980295
Validation loss: 2.625334427835886

Epoch: 5| Step: 1
Training loss: 2.5595905255127582
Validation loss: 2.6028038639598465

Epoch: 5| Step: 2
Training loss: 2.336333480494614
Validation loss: 2.585739444902897

Epoch: 5| Step: 3
Training loss: 2.1350840115601253
Validation loss: 2.604782482224717

Epoch: 5| Step: 4
Training loss: 2.825837363987662
Validation loss: 2.645801692893284

Epoch: 5| Step: 5
Training loss: 2.3877762919230467
Validation loss: 2.6867606196913223

Epoch: 5| Step: 6
Training loss: 2.3347883683223873
Validation loss: 2.7426695256128455

Epoch: 5| Step: 7
Training loss: 2.4501018970085915
Validation loss: 2.7132039657823217

Epoch: 5| Step: 8
Training loss: 2.53511129612734
Validation loss: 2.656471213310856

Epoch: 5| Step: 9
Training loss: 1.9638696762516863
Validation loss: 2.5701590647231023

Epoch: 5| Step: 10
Training loss: 2.155937503892661
Validation loss: 2.517745077298563

Epoch: 178| Step: 0
Training loss: 2.06486075571471
Validation loss: 2.498198480522857

Epoch: 5| Step: 1
Training loss: 2.717826160134722
Validation loss: 2.494521263817878

Epoch: 5| Step: 2
Training loss: 1.989484441672879
Validation loss: 2.4997844151890547

Epoch: 5| Step: 3
Training loss: 2.4488435546077354
Validation loss: 2.5175128747786997

Epoch: 5| Step: 4
Training loss: 2.3524275801210877
Validation loss: 2.5458843308331223

Epoch: 5| Step: 5
Training loss: 2.592165727391704
Validation loss: 2.5802077943100836

Epoch: 5| Step: 6
Training loss: 2.5056254990601703
Validation loss: 2.6261667841293126

Epoch: 5| Step: 7
Training loss: 1.9993639172899431
Validation loss: 2.614087321057535

Epoch: 5| Step: 8
Training loss: 2.5432705326584544
Validation loss: 2.655454686662003

Epoch: 5| Step: 9
Training loss: 2.6190688018850454
Validation loss: 2.683048211767659

Epoch: 5| Step: 10
Training loss: 2.4916739099029424
Validation loss: 2.6924341822726103

Epoch: 179| Step: 0
Training loss: 2.34606188874105
Validation loss: 2.6464051596119

Epoch: 5| Step: 1
Training loss: 2.379045253757795
Validation loss: 2.617435584250739

Epoch: 5| Step: 2
Training loss: 2.1900150554609783
Validation loss: 2.58904645224435

Epoch: 5| Step: 3
Training loss: 2.260208706291544
Validation loss: 2.566731518470943

Epoch: 5| Step: 4
Training loss: 2.216737290980625
Validation loss: 2.5688943734368714

Epoch: 5| Step: 5
Training loss: 2.1459698186140326
Validation loss: 2.5664006460393383

Epoch: 5| Step: 6
Training loss: 2.37196778931386
Validation loss: 2.5608833709942402

Epoch: 5| Step: 7
Training loss: 2.622934618810939
Validation loss: 2.56147324155396

Epoch: 5| Step: 8
Training loss: 2.2309554816591524
Validation loss: 2.596884020011075

Epoch: 5| Step: 9
Training loss: 2.761164975253896
Validation loss: 2.6331660414075975

Epoch: 5| Step: 10
Training loss: 2.3453087264709818
Validation loss: 2.680057088410412

Epoch: 180| Step: 0
Training loss: 2.6314922157852343
Validation loss: 2.7111541906371723

Epoch: 5| Step: 1
Training loss: 2.7721750744225213
Validation loss: 2.707529465208398

Epoch: 5| Step: 2
Training loss: 2.608037914410082
Validation loss: 2.6462815037336163

Epoch: 5| Step: 3
Training loss: 1.8210511898531776
Validation loss: 2.5796882054243664

Epoch: 5| Step: 4
Training loss: 2.279116115904451
Validation loss: 2.5852591768695987

Epoch: 5| Step: 5
Training loss: 2.5465963948459103
Validation loss: 2.5736594786659

Epoch: 5| Step: 6
Training loss: 2.245777618717386
Validation loss: 2.5956997610692105

Epoch: 5| Step: 7
Training loss: 2.0883054401496546
Validation loss: 2.592839566171469

Epoch: 5| Step: 8
Training loss: 2.6791092941129233
Validation loss: 2.6179925387241627

Epoch: 5| Step: 9
Training loss: 2.222282928061482
Validation loss: 2.651961029725231

Epoch: 5| Step: 10
Training loss: 1.823457873703761
Validation loss: 2.68798437043828

Epoch: 181| Step: 0
Training loss: 1.9600608051366069
Validation loss: 2.711928265973558

Epoch: 5| Step: 1
Training loss: 2.206978208191437
Validation loss: 2.719138840292462

Epoch: 5| Step: 2
Training loss: 1.8488820306498432
Validation loss: 2.710436753074857

Epoch: 5| Step: 3
Training loss: 2.598281486814487
Validation loss: 2.70627770295915

Epoch: 5| Step: 4
Training loss: 2.5513467672968035
Validation loss: 2.659544244648615

Epoch: 5| Step: 5
Training loss: 2.638825655620181
Validation loss: 2.6386345258427504

Epoch: 5| Step: 6
Training loss: 2.6059464641526198
Validation loss: 2.6158691729808217

Epoch: 5| Step: 7
Training loss: 2.3687253684018845
Validation loss: 2.581635659300661

Epoch: 5| Step: 8
Training loss: 2.4824030505531343
Validation loss: 2.5493399079570302

Epoch: 5| Step: 9
Training loss: 1.627808930804506
Validation loss: 2.5444308355840723

Epoch: 5| Step: 10
Training loss: 2.0572737165867103
Validation loss: 2.55027291878087

Epoch: 182| Step: 0
Training loss: 2.484510406067003
Validation loss: 2.5878291438255054

Epoch: 5| Step: 1
Training loss: 2.6115599296130836
Validation loss: 2.633737183529793

Epoch: 5| Step: 2
Training loss: 2.176655947944612
Validation loss: 2.655381299880803

Epoch: 5| Step: 3
Training loss: 2.322755907822477
Validation loss: 2.7046786216929974

Epoch: 5| Step: 4
Training loss: 2.3670195970066503
Validation loss: 2.748904889257486

Epoch: 5| Step: 5
Training loss: 2.455024809702269
Validation loss: 2.7893281780635775

Epoch: 5| Step: 6
Training loss: 2.0513375826496043
Validation loss: 2.792383122848935

Epoch: 5| Step: 7
Training loss: 2.5021623796421926
Validation loss: 2.78713200065544

Epoch: 5| Step: 8
Training loss: 2.182849627583876
Validation loss: 2.7190431034450735

Epoch: 5| Step: 9
Training loss: 2.0367452381959117
Validation loss: 2.6419095577881224

Epoch: 5| Step: 10
Training loss: 1.7672184868076573
Validation loss: 2.577311159952443

Epoch: 183| Step: 0
Training loss: 2.2228875065052547
Validation loss: 2.5425755996911743

Epoch: 5| Step: 1
Training loss: 2.5793909837076416
Validation loss: 2.5287223317619167

Epoch: 5| Step: 2
Training loss: 2.17968771876399
Validation loss: 2.523681387047522

Epoch: 5| Step: 3
Training loss: 2.0982386741264336
Validation loss: 2.520060352002188

Epoch: 5| Step: 4
Training loss: 1.363335725849045
Validation loss: 2.5338109272444624

Epoch: 5| Step: 5
Training loss: 2.2347081076133657
Validation loss: 2.5301389941199313

Epoch: 5| Step: 6
Training loss: 2.4938282124962785
Validation loss: 2.52732717324717

Epoch: 5| Step: 7
Training loss: 2.2010785060194116
Validation loss: 2.573638374056958

Epoch: 5| Step: 8
Training loss: 2.6698082855775023
Validation loss: 2.5946499473669795

Epoch: 5| Step: 9
Training loss: 2.4892394228675374
Validation loss: 2.601790670701284

Epoch: 5| Step: 10
Training loss: 1.9822141040482282
Validation loss: 2.6058432877192907

Epoch: 184| Step: 0
Training loss: 2.454758992844646
Validation loss: 2.619575751073959

Epoch: 5| Step: 1
Training loss: 2.482275405512502
Validation loss: 2.6306128334719867

Epoch: 5| Step: 2
Training loss: 2.350384692906861
Validation loss: 2.6490318673669533

Epoch: 5| Step: 3
Training loss: 1.7570263948623657
Validation loss: 2.646193290824863

Epoch: 5| Step: 4
Training loss: 1.9592552111937132
Validation loss: 2.649829496392219

Epoch: 5| Step: 5
Training loss: 2.201249535044459
Validation loss: 2.6260666425848287

Epoch: 5| Step: 6
Training loss: 2.187076309589143
Validation loss: 2.6242605975719755

Epoch: 5| Step: 7
Training loss: 2.0637052078053446
Validation loss: 2.6162665661687425

Epoch: 5| Step: 8
Training loss: 1.972980434860149
Validation loss: 2.6227620121877995

Epoch: 5| Step: 9
Training loss: 2.0975716856208657
Validation loss: 2.627433732708291

Epoch: 5| Step: 10
Training loss: 2.425606787361825
Validation loss: 2.631756016236563

Epoch: 185| Step: 0
Training loss: 2.4272099954410606
Validation loss: 2.639765084452609

Epoch: 5| Step: 1
Training loss: 1.7849205078461712
Validation loss: 2.6500304592035957

Epoch: 5| Step: 2
Training loss: 2.132541401719462
Validation loss: 2.6459565047188294

Epoch: 5| Step: 3
Training loss: 1.834877844650212
Validation loss: 2.6841284132747014

Epoch: 5| Step: 4
Training loss: 2.1524723519954296
Validation loss: 2.673659719675101

Epoch: 5| Step: 5
Training loss: 2.5226290798525697
Validation loss: 2.6981406049824344

Epoch: 5| Step: 6
Training loss: 2.4134384385645147
Validation loss: 2.671315879540125

Epoch: 5| Step: 7
Training loss: 2.350187996182672
Validation loss: 2.687771437440722

Epoch: 5| Step: 8
Training loss: 2.178717393921126
Validation loss: 2.6685811577391725

Epoch: 5| Step: 9
Training loss: 2.1267659198635536
Validation loss: 2.623492099330339

Epoch: 5| Step: 10
Training loss: 1.6508576042834104
Validation loss: 2.600659423421756

Epoch: 186| Step: 0
Training loss: 2.3244886225608408
Validation loss: 2.5561689998476873

Epoch: 5| Step: 1
Training loss: 2.234927555932705
Validation loss: 2.5504186786801335

Epoch: 5| Step: 2
Training loss: 2.4731679088696437
Validation loss: 2.545165147745567

Epoch: 5| Step: 3
Training loss: 2.126539458094652
Validation loss: 2.5643879518267836

Epoch: 5| Step: 4
Training loss: 2.164355757360926
Validation loss: 2.5684195934522593

Epoch: 5| Step: 5
Training loss: 1.899412116905334
Validation loss: 2.5803228392672413

Epoch: 5| Step: 6
Training loss: 2.093338541623741
Validation loss: 2.6187809640338835

Epoch: 5| Step: 7
Training loss: 1.9105887518212326
Validation loss: 2.6355821971828965

Epoch: 5| Step: 8
Training loss: 2.5486287824645797
Validation loss: 2.6553423629549173

Epoch: 5| Step: 9
Training loss: 1.8669527297285524
Validation loss: 2.6679110629428298

Epoch: 5| Step: 10
Training loss: 1.9088299287000532
Validation loss: 2.6619298617693543

Epoch: 187| Step: 0
Training loss: 2.2543421279206974
Validation loss: 2.638247873871548

Epoch: 5| Step: 1
Training loss: 2.3367385766486897
Validation loss: 2.6378065576016057

Epoch: 5| Step: 2
Training loss: 2.00099360103623
Validation loss: 2.612417530976483

Epoch: 5| Step: 3
Training loss: 2.5109312445533565
Validation loss: 2.595906726547098

Epoch: 5| Step: 4
Training loss: 2.402520993525054
Validation loss: 2.5916504766995674

Epoch: 5| Step: 5
Training loss: 1.599921302052076
Validation loss: 2.562141482416675

Epoch: 5| Step: 6
Training loss: 1.9227170262657063
Validation loss: 2.584271357590199

Epoch: 5| Step: 7
Training loss: 1.9703340364348547
Validation loss: 2.5998362537753166

Epoch: 5| Step: 8
Training loss: 2.2884676944918647
Validation loss: 2.6649745897485655

Epoch: 5| Step: 9
Training loss: 2.2990051564361633
Validation loss: 2.671632320213548

Epoch: 5| Step: 10
Training loss: 1.4527821290141665
Validation loss: 2.6928096498374052

Epoch: 188| Step: 0
Training loss: 2.102661526130451
Validation loss: 2.7062830760053953

Epoch: 5| Step: 1
Training loss: 2.0496922099098174
Validation loss: 2.705684445271436

Epoch: 5| Step: 2
Training loss: 2.2491637901277395
Validation loss: 2.6774041109865614

Epoch: 5| Step: 3
Training loss: 2.1322829039641626
Validation loss: 2.6587791056643657

Epoch: 5| Step: 4
Training loss: 1.8465189427577327
Validation loss: 2.5978799984342604

Epoch: 5| Step: 5
Training loss: 2.411094050290893
Validation loss: 2.582008530877952

Epoch: 5| Step: 6
Training loss: 2.0930071979222142
Validation loss: 2.553983922312458

Epoch: 5| Step: 7
Training loss: 2.3726562178445008
Validation loss: 2.561810471480081

Epoch: 5| Step: 8
Training loss: 2.2827648202249806
Validation loss: 2.563233463415635

Epoch: 5| Step: 9
Training loss: 1.8078949404212032
Validation loss: 2.6164021395590242

Epoch: 5| Step: 10
Training loss: 1.4718578005553193
Validation loss: 2.6433991075328223

Epoch: 189| Step: 0
Training loss: 2.0664442091341617
Validation loss: 2.709777381428222

Epoch: 5| Step: 1
Training loss: 2.348526220619124
Validation loss: 2.757305911315143

Epoch: 5| Step: 2
Training loss: 1.64421234300716
Validation loss: 2.7699694573256477

Epoch: 5| Step: 3
Training loss: 2.1516885469812888
Validation loss: 2.784902992614381

Epoch: 5| Step: 4
Training loss: 1.826100132802849
Validation loss: 2.787721426334416

Epoch: 5| Step: 5
Training loss: 1.7607986517308718
Validation loss: 2.7393064015424256

Epoch: 5| Step: 6
Training loss: 2.146389182481723
Validation loss: 2.735093870580281

Epoch: 5| Step: 7
Training loss: 2.2041928564389424
Validation loss: 2.6761080672911293

Epoch: 5| Step: 8
Training loss: 2.042109992753491
Validation loss: 2.6625341281593693

Epoch: 5| Step: 9
Training loss: 2.2921804603515366
Validation loss: 2.626937442258045

Epoch: 5| Step: 10
Training loss: 2.176889572160495
Validation loss: 2.627952255458377

Epoch: 190| Step: 0
Training loss: 2.3697690075360445
Validation loss: 2.6431376572864713

Epoch: 5| Step: 1
Training loss: 1.8886743997203912
Validation loss: 2.6459691244801857

Epoch: 5| Step: 2
Training loss: 2.032310795722484
Validation loss: 2.67647491917701

Epoch: 5| Step: 3
Training loss: 2.007736857729736
Validation loss: 2.6838424922470883

Epoch: 5| Step: 4
Training loss: 2.205519004516775
Validation loss: 2.67644289448917

Epoch: 5| Step: 5
Training loss: 1.4789301544369433
Validation loss: 2.6497881742961784

Epoch: 5| Step: 6
Training loss: 1.659365261358215
Validation loss: 2.6528136791699155

Epoch: 5| Step: 7
Training loss: 2.1234797481238523
Validation loss: 2.663864627348851

Epoch: 5| Step: 8
Training loss: 2.1226957955606176
Validation loss: 2.6550665132891336

Epoch: 5| Step: 9
Training loss: 2.2153255201062843
Validation loss: 2.6698335357708323

Epoch: 5| Step: 10
Training loss: 2.0938026079998777
Validation loss: 2.6569516900086287

Epoch: 191| Step: 0
Training loss: 2.3463255908395917
Validation loss: 2.679579399064502

Epoch: 5| Step: 1
Training loss: 1.392995678122033
Validation loss: 2.7183255335859364

Epoch: 5| Step: 2
Training loss: 1.6342976218117513
Validation loss: 2.737040807465175

Epoch: 5| Step: 3
Training loss: 2.266020957284226
Validation loss: 2.734752289368971

Epoch: 5| Step: 4
Training loss: 2.0315082092494845
Validation loss: 2.7608745988391292

Epoch: 5| Step: 5
Training loss: 2.0824748241281195
Validation loss: 2.7565431306293107

Epoch: 5| Step: 6
Training loss: 2.347454144859754
Validation loss: 2.7645074407764754

Epoch: 5| Step: 7
Training loss: 2.2332536778075434
Validation loss: 2.7426079190929538

Epoch: 5| Step: 8
Training loss: 1.620333058770324
Validation loss: 2.708282036370455

Epoch: 5| Step: 9
Training loss: 2.0337465642842614
Validation loss: 2.689895949811882

Epoch: 5| Step: 10
Training loss: 2.0250657059170325
Validation loss: 2.647226284916814

Epoch: 192| Step: 0
Training loss: 1.7582434232001098
Validation loss: 2.623155869007629

Epoch: 5| Step: 1
Training loss: 2.230017514523549
Validation loss: 2.606089671903207

Epoch: 5| Step: 2
Training loss: 2.08689612602698
Validation loss: 2.5948743689826395

Epoch: 5| Step: 3
Training loss: 1.8866012884186771
Validation loss: 2.579130291081324

Epoch: 5| Step: 4
Training loss: 2.022021884682812
Validation loss: 2.587933588242097

Epoch: 5| Step: 5
Training loss: 2.2486878913754578
Validation loss: 2.6063102805495926

Epoch: 5| Step: 6
Training loss: 2.2769070397970133
Validation loss: 2.617926185621693

Epoch: 5| Step: 7
Training loss: 1.9108114854462248
Validation loss: 2.618157397247708

Epoch: 5| Step: 8
Training loss: 1.631830604676916
Validation loss: 2.634307260763586

Epoch: 5| Step: 9
Training loss: 1.8550856666628524
Validation loss: 2.702521142012041

Epoch: 5| Step: 10
Training loss: 1.9732938132753424
Validation loss: 2.7331015401030965

Epoch: 193| Step: 0
Training loss: 1.8554745965162824
Validation loss: 2.7804495883465754

Epoch: 5| Step: 1
Training loss: 2.1889616306544286
Validation loss: 2.7926047256210773

Epoch: 5| Step: 2
Training loss: 1.9212853992702954
Validation loss: 2.7970830606578265

Epoch: 5| Step: 3
Training loss: 2.0415596706873522
Validation loss: 2.7765779778115394

Epoch: 5| Step: 4
Training loss: 1.8624804553344139
Validation loss: 2.767681077098317

Epoch: 5| Step: 5
Training loss: 2.156343983246753
Validation loss: 2.7144005703578844

Epoch: 5| Step: 6
Training loss: 2.09720395005149
Validation loss: 2.678512112165321

Epoch: 5| Step: 7
Training loss: 1.6430260663231455
Validation loss: 2.657976291932951

Epoch: 5| Step: 8
Training loss: 1.8345370531392438
Validation loss: 2.6370646077866406

Epoch: 5| Step: 9
Training loss: 1.767250190789896
Validation loss: 2.6075473845064536

Epoch: 5| Step: 10
Training loss: 2.339718925190644
Validation loss: 2.632280269340543

Epoch: 194| Step: 0
Training loss: 2.208207132824065
Validation loss: 2.6262792335672285

Epoch: 5| Step: 1
Training loss: 1.818032076478167
Validation loss: 2.6851564574088873

Epoch: 5| Step: 2
Training loss: 1.8629775849497348
Validation loss: 2.6904476891363487

Epoch: 5| Step: 3
Training loss: 2.2410076373275265
Validation loss: 2.7085426786050397

Epoch: 5| Step: 4
Training loss: 2.3876609628152927
Validation loss: 2.724946562141554

Epoch: 5| Step: 5
Training loss: 2.191701070227825
Validation loss: 2.7014345688442702

Epoch: 5| Step: 6
Training loss: 1.2306706338600146
Validation loss: 2.6360674042572976

Epoch: 5| Step: 7
Training loss: 2.3449337830782095
Validation loss: 2.618603234585303

Epoch: 5| Step: 8
Training loss: 2.1714369517358247
Validation loss: 2.6107472876306588

Epoch: 5| Step: 9
Training loss: 1.4282421873664548
Validation loss: 2.616853899227325

Epoch: 5| Step: 10
Training loss: 1.740328836499649
Validation loss: 2.627154661859464

Epoch: 195| Step: 0
Training loss: 2.398059728239703
Validation loss: 2.6251084578258537

Epoch: 5| Step: 1
Training loss: 1.4394609924681114
Validation loss: 2.654824668669617

Epoch: 5| Step: 2
Training loss: 1.9355232245023284
Validation loss: 2.679086908292486

Epoch: 5| Step: 3
Training loss: 2.1020228225674047
Validation loss: 2.691217147437409

Epoch: 5| Step: 4
Training loss: 2.26085080901311
Validation loss: 2.7357241385342066

Epoch: 5| Step: 5
Training loss: 1.893484239217007
Validation loss: 2.732116578488758

Epoch: 5| Step: 6
Training loss: 2.3004413347165924
Validation loss: 2.715927372123104

Epoch: 5| Step: 7
Training loss: 1.4068591176191036
Validation loss: 2.6397033100308835

Epoch: 5| Step: 8
Training loss: 1.8261182154967388
Validation loss: 2.6096904294544916

Epoch: 5| Step: 9
Training loss: 1.5854732792388202
Validation loss: 2.591967480577215

Epoch: 5| Step: 10
Training loss: 2.2938875245488304
Validation loss: 2.573851638493383

Epoch: 196| Step: 0
Training loss: 2.0709582203510175
Validation loss: 2.592182021538368

Epoch: 5| Step: 1
Training loss: 2.308228336337924
Validation loss: 2.609827529114565

Epoch: 5| Step: 2
Training loss: 1.6980349571664528
Validation loss: 2.6242206645197172

Epoch: 5| Step: 3
Training loss: 1.849854466152463
Validation loss: 2.651068636391604

Epoch: 5| Step: 4
Training loss: 1.8713382569155301
Validation loss: 2.709382093773003

Epoch: 5| Step: 5
Training loss: 2.0983946795152875
Validation loss: 2.70460088422012

Epoch: 5| Step: 6
Training loss: 1.6642278311537806
Validation loss: 2.729731442058657

Epoch: 5| Step: 7
Training loss: 1.7859140870169103
Validation loss: 2.7458621727836876

Epoch: 5| Step: 8
Training loss: 2.057215422815005
Validation loss: 2.7340581698060915

Epoch: 5| Step: 9
Training loss: 1.8486524803538078
Validation loss: 2.7092428754712374

Epoch: 5| Step: 10
Training loss: 1.936358392389241
Validation loss: 2.701862570329191

Epoch: 197| Step: 0
Training loss: 1.5199913759990786
Validation loss: 2.6981772359001583

Epoch: 5| Step: 1
Training loss: 1.8693664478143361
Validation loss: 2.702667633898647

Epoch: 5| Step: 2
Training loss: 1.377535216751907
Validation loss: 2.6871608893164614

Epoch: 5| Step: 3
Training loss: 1.843474480684354
Validation loss: 2.6996602511958936

Epoch: 5| Step: 4
Training loss: 1.7013852394047564
Validation loss: 2.7065365954995015

Epoch: 5| Step: 5
Training loss: 1.713861831700143
Validation loss: 2.704980660327834

Epoch: 5| Step: 6
Training loss: 2.2693872192692606
Validation loss: 2.735047923082504

Epoch: 5| Step: 7
Training loss: 1.9344291962902662
Validation loss: 2.7609357216226655

Epoch: 5| Step: 8
Training loss: 1.977781500378271
Validation loss: 2.7930807836820506

Epoch: 5| Step: 9
Training loss: 2.571447614569011
Validation loss: 2.7731653519333572

Epoch: 5| Step: 10
Training loss: 2.0617747332108305
Validation loss: 2.6909276648484557

Epoch: 198| Step: 0
Training loss: 1.4371362308814222
Validation loss: 2.6398955996278004

Epoch: 5| Step: 1
Training loss: 2.111721288049367
Validation loss: 2.656665755470529

Epoch: 5| Step: 2
Training loss: 2.0382178884873197
Validation loss: 2.6219826871318315

Epoch: 5| Step: 3
Training loss: 1.8549918435218173
Validation loss: 2.641842453625458

Epoch: 5| Step: 4
Training loss: 1.6260676178051638
Validation loss: 2.6289245627259925

Epoch: 5| Step: 5
Training loss: 1.8758025676972874
Validation loss: 2.595934358619731

Epoch: 5| Step: 6
Training loss: 1.8943913044317535
Validation loss: 2.603217831596991

Epoch: 5| Step: 7
Training loss: 2.240922418111922
Validation loss: 2.59469068034499

Epoch: 5| Step: 8
Training loss: 2.3933802665245674
Validation loss: 2.6119638006860297

Epoch: 5| Step: 9
Training loss: 1.4593966104675888
Validation loss: 2.6740210717223154

Epoch: 5| Step: 10
Training loss: 1.8753628061873608
Validation loss: 2.692497042496465

Epoch: 199| Step: 0
Training loss: 1.9624889665038354
Validation loss: 2.6834789719137873

Epoch: 5| Step: 1
Training loss: 2.1058557611178648
Validation loss: 2.6956520117600715

Epoch: 5| Step: 2
Training loss: 1.7450708725754605
Validation loss: 2.701713244093533

Epoch: 5| Step: 3
Training loss: 1.984712947393407
Validation loss: 2.6532992221816056

Epoch: 5| Step: 4
Training loss: 1.9584919547372743
Validation loss: 2.646789492991534

Epoch: 5| Step: 5
Training loss: 1.5561453726653947
Validation loss: 2.637084416381866

Epoch: 5| Step: 6
Training loss: 1.8072820071384588
Validation loss: 2.6189746821096835

Epoch: 5| Step: 7
Training loss: 1.8603750152311072
Validation loss: 2.65241023376971

Epoch: 5| Step: 8
Training loss: 2.1454590282701935
Validation loss: 2.6649879578095126

Epoch: 5| Step: 9
Training loss: 1.8853923170790043
Validation loss: 2.662907575571561

Epoch: 5| Step: 10
Training loss: 1.48497198046314
Validation loss: 2.670144874381881

Epoch: 200| Step: 0
Training loss: 1.8317995880649611
Validation loss: 2.712400666571935

Epoch: 5| Step: 1
Training loss: 1.9334478766392718
Validation loss: 2.7426144389356386

Epoch: 5| Step: 2
Training loss: 1.336872063946097
Validation loss: 2.722623712034489

Epoch: 5| Step: 3
Training loss: 2.0908196283131764
Validation loss: 2.7414537748920718

Epoch: 5| Step: 4
Training loss: 1.9461478772134198
Validation loss: 2.73211692191935

Epoch: 5| Step: 5
Training loss: 1.6765506285347553
Validation loss: 2.7247040506509954

Epoch: 5| Step: 6
Training loss: 2.065103794657484
Validation loss: 2.696773192815747

Epoch: 5| Step: 7
Training loss: 1.6011529910669413
Validation loss: 2.681017519743813

Epoch: 5| Step: 8
Training loss: 1.9887205586630865
Validation loss: 2.648601592600774

Epoch: 5| Step: 9
Training loss: 1.5941599150436745
Validation loss: 2.6556410939085526

Epoch: 5| Step: 10
Training loss: 2.0968354677660894
Validation loss: 2.6811045237679254

Epoch: 201| Step: 0
Training loss: 1.8788914035519861
Validation loss: 2.6785929066567955

Epoch: 5| Step: 1
Training loss: 1.3495555817280065
Validation loss: 2.7029397789464387

Epoch: 5| Step: 2
Training loss: 2.327455872507674
Validation loss: 2.7045092784708546

Epoch: 5| Step: 3
Training loss: 1.9002501072150222
Validation loss: 2.685308592724952

Epoch: 5| Step: 4
Training loss: 1.9544832923391693
Validation loss: 2.702539812504534

Epoch: 5| Step: 5
Training loss: 1.2437922829959818
Validation loss: 2.7017162796050935

Epoch: 5| Step: 6
Training loss: 1.4851740242558171
Validation loss: 2.6868491208558454

Epoch: 5| Step: 7
Training loss: 1.8022863755107863
Validation loss: 2.7115551148465404

Epoch: 5| Step: 8
Training loss: 2.1128645678264184
Validation loss: 2.706425819690603

Epoch: 5| Step: 9
Training loss: 2.0287815060052394
Validation loss: 2.6992433936047155

Epoch: 5| Step: 10
Training loss: 1.6237950626078808
Validation loss: 2.6857228538154154

Epoch: 202| Step: 0
Training loss: 1.4462792539811307
Validation loss: 2.6773100924074935

Epoch: 5| Step: 1
Training loss: 1.669444518989368
Validation loss: 2.677419020329917

Epoch: 5| Step: 2
Training loss: 1.8255026503966585
Validation loss: 2.725413224942709

Epoch: 5| Step: 3
Training loss: 1.8788954006841456
Validation loss: 2.7230906147454497

Epoch: 5| Step: 4
Training loss: 2.160181635178035
Validation loss: 2.7362119480750047

Epoch: 5| Step: 5
Training loss: 1.9202355936664948
Validation loss: 2.700734554562719

Epoch: 5| Step: 6
Training loss: 1.9799121322786497
Validation loss: 2.6941378542035843

Epoch: 5| Step: 7
Training loss: 1.827506718864562
Validation loss: 2.6828360384572987

Epoch: 5| Step: 8
Training loss: 1.5884032225601834
Validation loss: 2.677713639730521

Epoch: 5| Step: 9
Training loss: 2.2192594990906764
Validation loss: 2.6535076232687

Epoch: 5| Step: 10
Training loss: 1.0711523506055067
Validation loss: 2.656313211749346

Epoch: 203| Step: 0
Training loss: 1.8340292895650003
Validation loss: 2.6431833965307807

Epoch: 5| Step: 1
Training loss: 1.627828044498575
Validation loss: 2.653333692417171

Epoch: 5| Step: 2
Training loss: 1.686410198816734
Validation loss: 2.6438624368364305

Epoch: 5| Step: 3
Training loss: 1.3615809989759922
Validation loss: 2.6707866586745728

Epoch: 5| Step: 4
Training loss: 1.802293320550962
Validation loss: 2.669149287848283

Epoch: 5| Step: 5
Training loss: 1.8505476733758488
Validation loss: 2.6777857127224043

Epoch: 5| Step: 6
Training loss: 2.2529472545506053
Validation loss: 2.7079068027091595

Epoch: 5| Step: 7
Training loss: 1.6527969063614496
Validation loss: 2.6765973190334784

Epoch: 5| Step: 8
Training loss: 2.2068352806386757
Validation loss: 2.689456808239741

Epoch: 5| Step: 9
Training loss: 1.6122193617166956
Validation loss: 2.6549583687158345

Epoch: 5| Step: 10
Training loss: 1.5852304019194812
Validation loss: 2.6477278332352805

Epoch: 204| Step: 0
Training loss: 1.656591488164127
Validation loss: 2.658321910716216

Epoch: 5| Step: 1
Training loss: 2.053573016053528
Validation loss: 2.6679561641538405

Epoch: 5| Step: 2
Training loss: 1.4155274279654597
Validation loss: 2.6759445180140338

Epoch: 5| Step: 3
Training loss: 1.7441767126025838
Validation loss: 2.684240411077132

Epoch: 5| Step: 4
Training loss: 1.7828886291671928
Validation loss: 2.717714993160839

Epoch: 5| Step: 5
Training loss: 1.9894424974482363
Validation loss: 2.765964211713329

Epoch: 5| Step: 6
Training loss: 1.6638532336827951
Validation loss: 2.8230749581644976

Epoch: 5| Step: 7
Training loss: 1.9898113366412469
Validation loss: 2.784510431657817

Epoch: 5| Step: 8
Training loss: 1.7914023611007384
Validation loss: 2.768088262805965

Epoch: 5| Step: 9
Training loss: 1.7695524033383132
Validation loss: 2.7344201562671633

Epoch: 5| Step: 10
Training loss: 1.7400317347033238
Validation loss: 2.679435355291559

Epoch: 205| Step: 0
Training loss: 1.9320791766881773
Validation loss: 2.6464934013002988

Epoch: 5| Step: 1
Training loss: 1.5935399534150008
Validation loss: 2.654110702720793

Epoch: 5| Step: 2
Training loss: 1.849448175868023
Validation loss: 2.6254030641891233

Epoch: 5| Step: 3
Training loss: 1.8958465100623458
Validation loss: 2.606147904028082

Epoch: 5| Step: 4
Training loss: 1.3357172555795733
Validation loss: 2.6498112062367407

Epoch: 5| Step: 5
Training loss: 1.7578812649310132
Validation loss: 2.652323238620853

Epoch: 5| Step: 6
Training loss: 2.0618407611946967
Validation loss: 2.6879485667664036

Epoch: 5| Step: 7
Training loss: 1.5376050990709829
Validation loss: 2.66366021459337

Epoch: 5| Step: 8
Training loss: 1.9357628571907186
Validation loss: 2.660427597966122

Epoch: 5| Step: 9
Training loss: 1.6545647738640712
Validation loss: 2.6646508441177907

Epoch: 5| Step: 10
Training loss: 1.9990610064175507
Validation loss: 2.6716879636656614

Epoch: 206| Step: 0
Training loss: 2.1508216529872914
Validation loss: 2.7041625104592533

Epoch: 5| Step: 1
Training loss: 1.6659498660133643
Validation loss: 2.7197239495846603

Epoch: 5| Step: 2
Training loss: 1.9789925816586296
Validation loss: 2.7262051124185747

Epoch: 5| Step: 3
Training loss: 1.0717221187188783
Validation loss: 2.7348436526469557

Epoch: 5| Step: 4
Training loss: 1.8549440947177351
Validation loss: 2.7505161280226065

Epoch: 5| Step: 5
Training loss: 1.5128040607093283
Validation loss: 2.7196588935931256

Epoch: 5| Step: 6
Training loss: 1.8605813352607967
Validation loss: 2.702760369160398

Epoch: 5| Step: 7
Training loss: 1.602287537747965
Validation loss: 2.687139862343012

Epoch: 5| Step: 8
Training loss: 1.748640008811668
Validation loss: 2.7063969267560557

Epoch: 5| Step: 9
Training loss: 1.804354418117577
Validation loss: 2.708945759960719

Epoch: 5| Step: 10
Training loss: 1.9528359161062085
Validation loss: 2.6857219069076006

Epoch: 207| Step: 0
Training loss: 1.3735755998533803
Validation loss: 2.705070267964982

Epoch: 5| Step: 1
Training loss: 1.9346550389029598
Validation loss: 2.6482383301517145

Epoch: 5| Step: 2
Training loss: 2.224350107840984
Validation loss: 2.6650580302092823

Epoch: 5| Step: 3
Training loss: 1.9433204838680727
Validation loss: 2.665658909076441

Epoch: 5| Step: 4
Training loss: 1.9753951293097376
Validation loss: 2.6505289834125603

Epoch: 5| Step: 5
Training loss: 1.7533255042540725
Validation loss: 2.6388850189580717

Epoch: 5| Step: 6
Training loss: 1.803018103328296
Validation loss: 2.6608133349417296

Epoch: 5| Step: 7
Training loss: 1.4963431287447577
Validation loss: 2.66934365418049

Epoch: 5| Step: 8
Training loss: 1.2548339834249995
Validation loss: 2.6745630020230156

Epoch: 5| Step: 9
Training loss: 1.481296197355933
Validation loss: 2.687337083927131

Epoch: 5| Step: 10
Training loss: 1.5500033563146862
Validation loss: 2.687600519542623

Epoch: 208| Step: 0
Training loss: 1.9140517253961726
Validation loss: 2.7172971584067276

Epoch: 5| Step: 1
Training loss: 1.759056295525253
Validation loss: 2.727437871816021

Epoch: 5| Step: 2
Training loss: 1.6498920116343772
Validation loss: 2.730505834471372

Epoch: 5| Step: 3
Training loss: 1.7860905645931253
Validation loss: 2.710017523233454

Epoch: 5| Step: 4
Training loss: 1.5304187932022626
Validation loss: 2.7187597217793824

Epoch: 5| Step: 5
Training loss: 1.8727339084327552
Validation loss: 2.7158809332868077

Epoch: 5| Step: 6
Training loss: 1.7055674546634696
Validation loss: 2.727729085899747

Epoch: 5| Step: 7
Training loss: 1.54373204147457
Validation loss: 2.7080739615711837

Epoch: 5| Step: 8
Training loss: 1.7952426295881503
Validation loss: 2.692268042507383

Epoch: 5| Step: 9
Training loss: 1.5756761038276819
Validation loss: 2.6939115126931217

Epoch: 5| Step: 10
Training loss: 1.6507667609471217
Validation loss: 2.6830604239285325

Epoch: 209| Step: 0
Training loss: 1.8455022470465214
Validation loss: 2.699084207736098

Epoch: 5| Step: 1
Training loss: 1.6158266838111348
Validation loss: 2.703734895811534

Epoch: 5| Step: 2
Training loss: 1.7809178226667055
Validation loss: 2.708648716916773

Epoch: 5| Step: 3
Training loss: 1.869722568719293
Validation loss: 2.7146821576010574

Epoch: 5| Step: 4
Training loss: 1.843758922490659
Validation loss: 2.706573497344764

Epoch: 5| Step: 5
Training loss: 1.5000241595547876
Validation loss: 2.738225466484013

Epoch: 5| Step: 6
Training loss: 1.7005382807616938
Validation loss: 2.715871238960376

Epoch: 5| Step: 7
Training loss: 1.5572949497694368
Validation loss: 2.726752084697422

Epoch: 5| Step: 8
Training loss: 1.4716780674551468
Validation loss: 2.7446486619575907

Epoch: 5| Step: 9
Training loss: 1.9050829707622399
Validation loss: 2.728618430242406

Epoch: 5| Step: 10
Training loss: 1.5806381308303192
Validation loss: 2.690259151943538

Epoch: 210| Step: 0
Training loss: 1.4992931607909872
Validation loss: 2.6669185895004

Epoch: 5| Step: 1
Training loss: 1.9404941926322286
Validation loss: 2.6574918340155578

Epoch: 5| Step: 2
Training loss: 1.4332773966557069
Validation loss: 2.633112966245647

Epoch: 5| Step: 3
Training loss: 1.884269372310814
Validation loss: 2.6642718623944788

Epoch: 5| Step: 4
Training loss: 1.5745732592162602
Validation loss: 2.650385386266029

Epoch: 5| Step: 5
Training loss: 1.6195948277759
Validation loss: 2.693612293018053

Epoch: 5| Step: 6
Training loss: 1.4998493118890388
Validation loss: 2.676885994440626

Epoch: 5| Step: 7
Training loss: 1.2836759906596258
Validation loss: 2.7277273876005665

Epoch: 5| Step: 8
Training loss: 2.004764603568872
Validation loss: 2.7509068236597334

Epoch: 5| Step: 9
Training loss: 1.8629499416782445
Validation loss: 2.729661962495577

Epoch: 5| Step: 10
Training loss: 1.7640541312979638
Validation loss: 2.703222217669278

Epoch: 211| Step: 0
Training loss: 1.961037561059821
Validation loss: 2.672388829149762

Epoch: 5| Step: 1
Training loss: 1.390048818485681
Validation loss: 2.660920281007939

Epoch: 5| Step: 2
Training loss: 1.8399351060867868
Validation loss: 2.6671565942731275

Epoch: 5| Step: 3
Training loss: 1.7149573355836916
Validation loss: 2.6607704934552343

Epoch: 5| Step: 4
Training loss: 1.4451216288133706
Validation loss: 2.680873602967402

Epoch: 5| Step: 5
Training loss: 1.6709174150094859
Validation loss: 2.669724490404478

Epoch: 5| Step: 6
Training loss: 1.2249830244795483
Validation loss: 2.683001061469793

Epoch: 5| Step: 7
Training loss: 1.9686280470118498
Validation loss: 2.690685906943478

Epoch: 5| Step: 8
Training loss: 1.4691663922882834
Validation loss: 2.7185716826325645

Epoch: 5| Step: 9
Training loss: 1.2248642943594028
Validation loss: 2.722400576008858

Epoch: 5| Step: 10
Training loss: 2.1388169052209305
Validation loss: 2.7273399616641107

Epoch: 212| Step: 0
Training loss: 1.3903831528802968
Validation loss: 2.7110686408030378

Epoch: 5| Step: 1
Training loss: 1.819684947799997
Validation loss: 2.718402660729674

Epoch: 5| Step: 2
Training loss: 1.7711738558213777
Validation loss: 2.702842916289902

Epoch: 5| Step: 3
Training loss: 1.5395174080340541
Validation loss: 2.698662039199588

Epoch: 5| Step: 4
Training loss: 1.567932146725693
Validation loss: 2.694818748177806

Epoch: 5| Step: 5
Training loss: 1.751724279250518
Validation loss: 2.6952171352803354

Epoch: 5| Step: 6
Training loss: 1.485518326385967
Validation loss: 2.693508689903587

Epoch: 5| Step: 7
Training loss: 1.7727754676376355
Validation loss: 2.710971810426166

Epoch: 5| Step: 8
Training loss: 1.7448860788185598
Validation loss: 2.6843793407301324

Epoch: 5| Step: 9
Training loss: 1.6121064496874582
Validation loss: 2.7236471817037065

Epoch: 5| Step: 10
Training loss: 1.6617546734067679
Validation loss: 2.704016088181554

Epoch: 213| Step: 0
Training loss: 1.204150122338569
Validation loss: 2.71670028936991

Epoch: 5| Step: 1
Training loss: 1.557315617848145
Validation loss: 2.7261779685125633

Epoch: 5| Step: 2
Training loss: 1.6079600512063832
Validation loss: 2.702957562584891

Epoch: 5| Step: 3
Training loss: 1.769630951419994
Validation loss: 2.7080193412515268

Epoch: 5| Step: 4
Training loss: 1.4184055969052551
Validation loss: 2.6756252376571057

Epoch: 5| Step: 5
Training loss: 1.6999130058469198
Validation loss: 2.679050601029814

Epoch: 5| Step: 6
Training loss: 1.2806772021651787
Validation loss: 2.668590171742508

Epoch: 5| Step: 7
Training loss: 1.9267443247041214
Validation loss: 2.638052509436235

Epoch: 5| Step: 8
Training loss: 1.7963487600892387
Validation loss: 2.654736181471153

Epoch: 5| Step: 9
Training loss: 1.7823579253814095
Validation loss: 2.665229812751891

Epoch: 5| Step: 10
Training loss: 1.8038904320711857
Validation loss: 2.669191507420827

Epoch: 214| Step: 0
Training loss: 1.6675326561196526
Validation loss: 2.6481325215510614

Epoch: 5| Step: 1
Training loss: 1.183753327039738
Validation loss: 2.6894029184314725

Epoch: 5| Step: 2
Training loss: 1.286430492434486
Validation loss: 2.701565260904032

Epoch: 5| Step: 3
Training loss: 1.6822623456007892
Validation loss: 2.7440031842034163

Epoch: 5| Step: 4
Training loss: 1.8852284233862766
Validation loss: 2.7396446245189465

Epoch: 5| Step: 5
Training loss: 1.2258839279165548
Validation loss: 2.7386960644066423

Epoch: 5| Step: 6
Training loss: 1.7771195154952653
Validation loss: 2.709026878918913

Epoch: 5| Step: 7
Training loss: 1.7212008255504674
Validation loss: 2.7049436542972756

Epoch: 5| Step: 8
Training loss: 1.758152229540306
Validation loss: 2.660397797857772

Epoch: 5| Step: 9
Training loss: 1.8858724081947418
Validation loss: 2.683816207528438

Epoch: 5| Step: 10
Training loss: 1.465762244592253
Validation loss: 2.6724919353685626

Epoch: 215| Step: 0
Training loss: 1.6350405882250851
Validation loss: 2.6462466408283243

Epoch: 5| Step: 1
Training loss: 1.4990725033958905
Validation loss: 2.680484375442611

Epoch: 5| Step: 2
Training loss: 1.787974597374961
Validation loss: 2.6578329486065955

Epoch: 5| Step: 3
Training loss: 1.3560606793580714
Validation loss: 2.6746971809236517

Epoch: 5| Step: 4
Training loss: 1.775884343522574
Validation loss: 2.71152861090835

Epoch: 5| Step: 5
Training loss: 1.2481440594344475
Validation loss: 2.7269945785734686

Epoch: 5| Step: 6
Training loss: 1.9574869504764012
Validation loss: 2.738095691894624

Epoch: 5| Step: 7
Training loss: 1.5607471552390124
Validation loss: 2.700835859169427

Epoch: 5| Step: 8
Training loss: 1.6492184782186092
Validation loss: 2.6892039884480328

Epoch: 5| Step: 9
Training loss: 1.5724157415719489
Validation loss: 2.6660748704411525

Epoch: 5| Step: 10
Training loss: 1.6466154179854247
Validation loss: 2.675418270034259

Epoch: 216| Step: 0
Training loss: 1.5835883119298741
Validation loss: 2.658745509231013

Epoch: 5| Step: 1
Training loss: 1.5899757124287406
Validation loss: 2.6660603746038176

Epoch: 5| Step: 2
Training loss: 1.5936579958220978
Validation loss: 2.6960344500658864

Epoch: 5| Step: 3
Training loss: 1.7207595867891405
Validation loss: 2.6856011132872135

Epoch: 5| Step: 4
Training loss: 1.6401617940318591
Validation loss: 2.682164787129436

Epoch: 5| Step: 5
Training loss: 1.1541659156622435
Validation loss: 2.704572303551778

Epoch: 5| Step: 6
Training loss: 1.5200225114410233
Validation loss: 2.7080939191031765

Epoch: 5| Step: 7
Training loss: 1.955640957634039
Validation loss: 2.6930295411832055

Epoch: 5| Step: 8
Training loss: 1.3803446240580926
Validation loss: 2.696721219326905

Epoch: 5| Step: 9
Training loss: 1.7182574173184295
Validation loss: 2.686228126129861

Epoch: 5| Step: 10
Training loss: 1.6031462491357935
Validation loss: 2.6800905439558096

Epoch: 217| Step: 0
Training loss: 1.370172653108756
Validation loss: 2.677110279155606

Epoch: 5| Step: 1
Training loss: 1.4135219320532773
Validation loss: 2.671254817475316

Epoch: 5| Step: 2
Training loss: 1.6866761775119299
Validation loss: 2.66756022980124

Epoch: 5| Step: 3
Training loss: 2.14826404218103
Validation loss: 2.683560501487102

Epoch: 5| Step: 4
Training loss: 1.845658559109779
Validation loss: 2.7044563502593078

Epoch: 5| Step: 5
Training loss: 1.13845027383428
Validation loss: 2.702821906981359

Epoch: 5| Step: 6
Training loss: 1.3860787647595318
Validation loss: 2.713882543603076

Epoch: 5| Step: 7
Training loss: 1.5532442227508954
Validation loss: 2.7141718967602997

Epoch: 5| Step: 8
Training loss: 1.506490097854032
Validation loss: 2.713600648537333

Epoch: 5| Step: 9
Training loss: 1.4106221367262284
Validation loss: 2.679206125894472

Epoch: 5| Step: 10
Training loss: 1.7359305614260663
Validation loss: 2.671861334890929

Epoch: 218| Step: 0
Training loss: 1.6034863338048675
Validation loss: 2.6619257263180045

Epoch: 5| Step: 1
Training loss: 1.937029012223502
Validation loss: 2.6427688172701065

Epoch: 5| Step: 2
Training loss: 1.67881262417442
Validation loss: 2.658136611553219

Epoch: 5| Step: 3
Training loss: 1.5802965991574474
Validation loss: 2.699351274041782

Epoch: 5| Step: 4
Training loss: 1.3958467321559378
Validation loss: 2.6854426203951296

Epoch: 5| Step: 5
Training loss: 1.3397458766411825
Validation loss: 2.6841050587983566

Epoch: 5| Step: 6
Training loss: 1.507384797940423
Validation loss: 2.746265151691312

Epoch: 5| Step: 7
Training loss: 1.6203498328385846
Validation loss: 2.745148905995629

Epoch: 5| Step: 8
Training loss: 1.4186893030030219
Validation loss: 2.7305121719616605

Epoch: 5| Step: 9
Training loss: 1.4418120187828627
Validation loss: 2.711592445695227

Epoch: 5| Step: 10
Training loss: 1.675615066789142
Validation loss: 2.668100795950308

Epoch: 219| Step: 0
Training loss: 1.7344991278691544
Validation loss: 2.627766022542475

Epoch: 5| Step: 1
Training loss: 1.6353978765424668
Validation loss: 2.6560978034546046

Epoch: 5| Step: 2
Training loss: 1.8413616811078877
Validation loss: 2.6374808933577065

Epoch: 5| Step: 3
Training loss: 1.5000708881158111
Validation loss: 2.6695321790650053

Epoch: 5| Step: 4
Training loss: 1.0194341386752843
Validation loss: 2.696775499049559

Epoch: 5| Step: 5
Training loss: 1.3364063354906055
Validation loss: 2.7076511561997325

Epoch: 5| Step: 6
Training loss: 1.6552768223370629
Validation loss: 2.74265484338712

Epoch: 5| Step: 7
Training loss: 2.1168392781841248
Validation loss: 2.7528308661702217

Epoch: 5| Step: 8
Training loss: 1.3978350742972534
Validation loss: 2.7223458683363364

Epoch: 5| Step: 9
Training loss: 1.7168339539777882
Validation loss: 2.694861835113987

Epoch: 5| Step: 10
Training loss: 1.1228006374922663
Validation loss: 2.66722533183221

Epoch: 220| Step: 0
Training loss: 1.5810195513679965
Validation loss: 2.616035608814258

Epoch: 5| Step: 1
Training loss: 1.6677772001033502
Validation loss: 2.6458067604793087

Epoch: 5| Step: 2
Training loss: 1.2772451006858285
Validation loss: 2.637248703093427

Epoch: 5| Step: 3
Training loss: 1.8906712802235244
Validation loss: 2.6661223777719365

Epoch: 5| Step: 4
Training loss: 1.4838877631155833
Validation loss: 2.713834661293948

Epoch: 5| Step: 5
Training loss: 1.6457748966063623
Validation loss: 2.706183032529905

Epoch: 5| Step: 6
Training loss: 1.5296430914475228
Validation loss: 2.736465210238097

Epoch: 5| Step: 7
Training loss: 1.4806193172012454
Validation loss: 2.7547778475172024

Epoch: 5| Step: 8
Training loss: 1.6562574854267758
Validation loss: 2.774752611823104

Epoch: 5| Step: 9
Training loss: 1.7182520752029398
Validation loss: 2.770392221266925

Epoch: 5| Step: 10
Training loss: 1.280251090337002
Validation loss: 2.6741812519768144

Epoch: 221| Step: 0
Training loss: 1.2010344139777844
Validation loss: 2.641585104925951

Epoch: 5| Step: 1
Training loss: 1.4263313799817452
Validation loss: 2.6140290578837737

Epoch: 5| Step: 2
Training loss: 1.7476696438504202
Validation loss: 2.5975193330239787

Epoch: 5| Step: 3
Training loss: 1.631582426494911
Validation loss: 2.62674866720215

Epoch: 5| Step: 4
Training loss: 1.9529869946360758
Validation loss: 2.6452239903517993

Epoch: 5| Step: 5
Training loss: 1.4143111711057788
Validation loss: 2.650772437567909

Epoch: 5| Step: 6
Training loss: 1.7451072824940994
Validation loss: 2.6419822048174106

Epoch: 5| Step: 7
Training loss: 1.6151117834136908
Validation loss: 2.658401760434858

Epoch: 5| Step: 8
Training loss: 1.4554946610442263
Validation loss: 2.7153230954673995

Epoch: 5| Step: 9
Training loss: 1.4966920298839421
Validation loss: 2.6930587736324463

Epoch: 5| Step: 10
Training loss: 1.726761129009547
Validation loss: 2.697226253845708

Epoch: 222| Step: 0
Training loss: 1.5546447901394358
Validation loss: 2.6848754181821795

Epoch: 5| Step: 1
Training loss: 1.4076445552387977
Validation loss: 2.6819622958602976

Epoch: 5| Step: 2
Training loss: 1.3571919857182024
Validation loss: 2.6273194226279304

Epoch: 5| Step: 3
Training loss: 1.7128359221506644
Validation loss: 2.6430921771945486

Epoch: 5| Step: 4
Training loss: 1.4055263352696945
Validation loss: 2.652730802105661

Epoch: 5| Step: 5
Training loss: 1.5161530666076124
Validation loss: 2.6073680024563304

Epoch: 5| Step: 6
Training loss: 1.2345534087069259
Validation loss: 2.6481847361426687

Epoch: 5| Step: 7
Training loss: 1.3231742137609293
Validation loss: 2.681623755422278

Epoch: 5| Step: 8
Training loss: 1.7046054390265182
Validation loss: 2.6622726557317526

Epoch: 5| Step: 9
Training loss: 2.0683167248760177
Validation loss: 2.7355847248401215

Epoch: 5| Step: 10
Training loss: 1.6056806512664088
Validation loss: 2.713503977482521

Epoch: 223| Step: 0
Training loss: 1.2074703664677768
Validation loss: 2.7194023514221892

Epoch: 5| Step: 1
Training loss: 1.7603964569316175
Validation loss: 2.718592303356869

Epoch: 5| Step: 2
Training loss: 1.3202294317895948
Validation loss: 2.7075940854684735

Epoch: 5| Step: 3
Training loss: 1.5709452706412848
Validation loss: 2.701553291816543

Epoch: 5| Step: 4
Training loss: 1.7395205077135427
Validation loss: 2.6575495707080843

Epoch: 5| Step: 5
Training loss: 1.7970998872094324
Validation loss: 2.6900806728351627

Epoch: 5| Step: 6
Training loss: 1.331207512907345
Validation loss: 2.6650022598722147

Epoch: 5| Step: 7
Training loss: 1.1970707048616842
Validation loss: 2.70091635035727

Epoch: 5| Step: 8
Training loss: 1.7036931901221903
Validation loss: 2.7242130267211886

Epoch: 5| Step: 9
Training loss: 1.4901134196899373
Validation loss: 2.7398375707427696

Epoch: 5| Step: 10
Training loss: 1.5004389438530836
Validation loss: 2.730944409480626

Epoch: 224| Step: 0
Training loss: 1.5408000916188849
Validation loss: 2.717415582693751

Epoch: 5| Step: 1
Training loss: 1.1448124875277288
Validation loss: 2.7015769291237994

Epoch: 5| Step: 2
Training loss: 1.445093251687585
Validation loss: 2.665144451917556

Epoch: 5| Step: 3
Training loss: 1.304359714654287
Validation loss: 2.6502728264312987

Epoch: 5| Step: 4
Training loss: 1.3349614286386944
Validation loss: 2.6357423231839303

Epoch: 5| Step: 5
Training loss: 1.5663884416362222
Validation loss: 2.6185025521664063

Epoch: 5| Step: 6
Training loss: 2.001936332818294
Validation loss: 2.592038611630668

Epoch: 5| Step: 7
Training loss: 1.7900042990947223
Validation loss: 2.6120790114401604

Epoch: 5| Step: 8
Training loss: 1.3035044074326054
Validation loss: 2.631248909791194

Epoch: 5| Step: 9
Training loss: 1.7296731812143749
Validation loss: 2.6450869708449867

Epoch: 5| Step: 10
Training loss: 1.1206000965795793
Validation loss: 2.6267089661971936

Epoch: 225| Step: 0
Training loss: 1.2666172800140345
Validation loss: 2.6451818636149933

Epoch: 5| Step: 1
Training loss: 1.145145290601819
Validation loss: 2.6379407742122267

Epoch: 5| Step: 2
Training loss: 1.397094166606826
Validation loss: 2.6678684459411355

Epoch: 5| Step: 3
Training loss: 1.190402999966825
Validation loss: 2.6896136195899127

Epoch: 5| Step: 4
Training loss: 1.3273882000212307
Validation loss: 2.7207742467127076

Epoch: 5| Step: 5
Training loss: 1.7129297371621364
Validation loss: 2.697509579708262

Epoch: 5| Step: 6
Training loss: 1.6651216100551285
Validation loss: 2.745249796839696

Epoch: 5| Step: 7
Training loss: 1.3635471379826258
Validation loss: 2.7368096763507093

Epoch: 5| Step: 8
Training loss: 1.693094798255587
Validation loss: 2.7072884919311537

Epoch: 5| Step: 9
Training loss: 1.9933144168317665
Validation loss: 2.7479213286496216

Epoch: 5| Step: 10
Training loss: 1.4672685822171243
Validation loss: 2.6998261354723545

Epoch: 226| Step: 0
Training loss: 1.1243416661340984
Validation loss: 2.7202263353739546

Epoch: 5| Step: 1
Training loss: 1.5847281369050528
Validation loss: 2.716947478280915

Epoch: 5| Step: 2
Training loss: 1.7083385358901781
Validation loss: 2.717864156623139

Epoch: 5| Step: 3
Training loss: 1.4228049789689066
Validation loss: 2.667168574501505

Epoch: 5| Step: 4
Training loss: 1.398865021722619
Validation loss: 2.662823855438704

Epoch: 5| Step: 5
Training loss: 1.6058094563446996
Validation loss: 2.7030099871217326

Epoch: 5| Step: 6
Training loss: 1.6843688313613636
Validation loss: 2.6665828673080716

Epoch: 5| Step: 7
Training loss: 1.7581003589171285
Validation loss: 2.706425523203791

Epoch: 5| Step: 8
Training loss: 1.2070710505864766
Validation loss: 2.6905539946712462

Epoch: 5| Step: 9
Training loss: 1.0433997931554968
Validation loss: 2.6810990170741538

Epoch: 5| Step: 10
Training loss: 1.5482008675260766
Validation loss: 2.705193193996584

Epoch: 227| Step: 0
Training loss: 1.5472073438801488
Validation loss: 2.709050001512656

Epoch: 5| Step: 1
Training loss: 1.4132660366776792
Validation loss: 2.7221735821303747

Epoch: 5| Step: 2
Training loss: 1.2860532372491433
Validation loss: 2.727575183933507

Epoch: 5| Step: 3
Training loss: 1.2569662054764639
Validation loss: 2.7448773350974887

Epoch: 5| Step: 4
Training loss: 1.5931960246378198
Validation loss: 2.7778547763065413

Epoch: 5| Step: 5
Training loss: 1.2925458141449042
Validation loss: 2.748230371289466

Epoch: 5| Step: 6
Training loss: 1.5993228045492396
Validation loss: 2.7571557598222443

Epoch: 5| Step: 7
Training loss: 1.462964126105367
Validation loss: 2.7431080530481573

Epoch: 5| Step: 8
Training loss: 1.6093852959460935
Validation loss: 2.739326965384505

Epoch: 5| Step: 9
Training loss: 1.255388091368056
Validation loss: 2.7277976692355574

Epoch: 5| Step: 10
Training loss: 1.8627195011315123
Validation loss: 2.71701735846276

Epoch: 228| Step: 0
Training loss: 1.112956163559329
Validation loss: 2.7061156918895555

Epoch: 5| Step: 1
Training loss: 1.735306086075833
Validation loss: 2.697702500456716

Epoch: 5| Step: 2
Training loss: 1.5837426994896127
Validation loss: 2.677380473795662

Epoch: 5| Step: 3
Training loss: 1.8111398789527031
Validation loss: 2.6868594790218014

Epoch: 5| Step: 4
Training loss: 1.0925645125696637
Validation loss: 2.690184157815554

Epoch: 5| Step: 5
Training loss: 1.6473475464136056
Validation loss: 2.7115905472564674

Epoch: 5| Step: 6
Training loss: 1.3376614339501014
Validation loss: 2.6821761851426262

Epoch: 5| Step: 7
Training loss: 1.249982166163065
Validation loss: 2.703262552269118

Epoch: 5| Step: 8
Training loss: 1.716500422690184
Validation loss: 2.715300983657483

Epoch: 5| Step: 9
Training loss: 1.2617828541819243
Validation loss: 2.6865346109017874

Epoch: 5| Step: 10
Training loss: 1.2787340629680828
Validation loss: 2.6841297790831176

Epoch: 229| Step: 0
Training loss: 1.075156617399468
Validation loss: 2.691589384481681

Epoch: 5| Step: 1
Training loss: 1.3708734579890693
Validation loss: 2.6717456785610896

Epoch: 5| Step: 2
Training loss: 1.3375613956085903
Validation loss: 2.6751953767444556

Epoch: 5| Step: 3
Training loss: 1.2996702748079219
Validation loss: 2.6922126987143984

Epoch: 5| Step: 4
Training loss: 1.564744329317602
Validation loss: 2.7212241059527105

Epoch: 5| Step: 5
Training loss: 1.5487107452516387
Validation loss: 2.6896421142518476

Epoch: 5| Step: 6
Training loss: 1.4963273545795346
Validation loss: 2.74478892194504

Epoch: 5| Step: 7
Training loss: 1.7242640044716757
Validation loss: 2.7140069818894084

Epoch: 5| Step: 8
Training loss: 1.7893778427266662
Validation loss: 2.689600488782072

Epoch: 5| Step: 9
Training loss: 1.444404770640479
Validation loss: 2.676066375959264

Epoch: 5| Step: 10
Training loss: 1.424104891278562
Validation loss: 2.6792308674584744

Epoch: 230| Step: 0
Training loss: 1.6316384653155223
Validation loss: 2.638870143517964

Epoch: 5| Step: 1
Training loss: 1.2675174645719858
Validation loss: 2.661424127585328

Epoch: 5| Step: 2
Training loss: 0.9838199564430256
Validation loss: 2.6426955195954154

Epoch: 5| Step: 3
Training loss: 1.5668308510207634
Validation loss: 2.674812098150216

Epoch: 5| Step: 4
Training loss: 1.3728611957571883
Validation loss: 2.6710648305350215

Epoch: 5| Step: 5
Training loss: 1.6212491983545538
Validation loss: 2.656150448771617

Epoch: 5| Step: 6
Training loss: 1.4094626710271478
Validation loss: 2.6889618238755335

Epoch: 5| Step: 7
Training loss: 1.754360828240494
Validation loss: 2.665428440068806

Epoch: 5| Step: 8
Training loss: 1.1709575367728369
Validation loss: 2.696245931814105

Epoch: 5| Step: 9
Training loss: 1.6991652907808255
Validation loss: 2.7290292545742223

Epoch: 5| Step: 10
Training loss: 1.1439482991233474
Validation loss: 2.7325766739017268

Epoch: 231| Step: 0
Training loss: 1.2916955124290026
Validation loss: 2.753839377222092

Epoch: 5| Step: 1
Training loss: 1.2954142513275124
Validation loss: 2.7435490585673765

Epoch: 5| Step: 2
Training loss: 1.2506829303552938
Validation loss: 2.763865847701187

Epoch: 5| Step: 3
Training loss: 1.5047384758511317
Validation loss: 2.745477547770876

Epoch: 5| Step: 4
Training loss: 1.6994720620947843
Validation loss: 2.722536074350033

Epoch: 5| Step: 5
Training loss: 1.6575572774665361
Validation loss: 2.716621908806499

Epoch: 5| Step: 6
Training loss: 1.1079381314642374
Validation loss: 2.698619636126971

Epoch: 5| Step: 7
Training loss: 1.4700430190350624
Validation loss: 2.702123555688207

Epoch: 5| Step: 8
Training loss: 1.5581095237284668
Validation loss: 2.6948058577324967

Epoch: 5| Step: 9
Training loss: 1.4769707978085909
Validation loss: 2.702742072965087

Epoch: 5| Step: 10
Training loss: 1.1636054658716153
Validation loss: 2.669401904754056

Epoch: 232| Step: 0
Training loss: 1.1188050943799417
Validation loss: 2.7060747129767555

Epoch: 5| Step: 1
Training loss: 1.7591495430439876
Validation loss: 2.692168404767938

Epoch: 5| Step: 2
Training loss: 1.300547352516507
Validation loss: 2.722731506914872

Epoch: 5| Step: 3
Training loss: 1.334555686492027
Validation loss: 2.6909598963244923

Epoch: 5| Step: 4
Training loss: 1.2691358214546051
Validation loss: 2.680488957596456

Epoch: 5| Step: 5
Training loss: 1.1224485179930253
Validation loss: 2.6657242596629396

Epoch: 5| Step: 6
Training loss: 1.359867313728312
Validation loss: 2.687925116724228

Epoch: 5| Step: 7
Training loss: 1.671714917656392
Validation loss: 2.683487398018535

Epoch: 5| Step: 8
Training loss: 1.681469703698576
Validation loss: 2.68566470809278

Epoch: 5| Step: 9
Training loss: 1.5031482718523983
Validation loss: 2.6986653797574585

Epoch: 5| Step: 10
Training loss: 1.4787324975623293
Validation loss: 2.6988273797394347

Epoch: 233| Step: 0
Training loss: 1.6080086101899287
Validation loss: 2.696807850758043

Epoch: 5| Step: 1
Training loss: 1.5392383145831612
Validation loss: 2.6867358701782527

Epoch: 5| Step: 2
Training loss: 1.3864308232941704
Validation loss: 2.6914692085270513

Epoch: 5| Step: 3
Training loss: 1.4047111992963714
Validation loss: 2.6589575598938926

Epoch: 5| Step: 4
Training loss: 1.3270290565270473
Validation loss: 2.6684913244183823

Epoch: 5| Step: 5
Training loss: 1.6313655593104348
Validation loss: 2.6515536843826597

Epoch: 5| Step: 6
Training loss: 1.6359779301905875
Validation loss: 2.670927008005695

Epoch: 5| Step: 7
Training loss: 1.3423332463846935
Validation loss: 2.6631520327691245

Epoch: 5| Step: 8
Training loss: 1.2006122060607418
Validation loss: 2.6615247005162495

Epoch: 5| Step: 9
Training loss: 1.2185896743567346
Validation loss: 2.7151357360798385

Epoch: 5| Step: 10
Training loss: 1.0379825228320432
Validation loss: 2.6921217227399428

Epoch: 234| Step: 0
Training loss: 1.6113378166138466
Validation loss: 2.7044290250343006

Epoch: 5| Step: 1
Training loss: 1.3753666388931753
Validation loss: 2.7425397706196204

Epoch: 5| Step: 2
Training loss: 1.3455812263367537
Validation loss: 2.704044213015678

Epoch: 5| Step: 3
Training loss: 1.072427317061601
Validation loss: 2.7434383372577225

Epoch: 5| Step: 4
Training loss: 1.1422850143199024
Validation loss: 2.725924082559629

Epoch: 5| Step: 5
Training loss: 1.3714613027867406
Validation loss: 2.7423712107323066

Epoch: 5| Step: 6
Training loss: 1.3329698047179903
Validation loss: 2.7254908720278217

Epoch: 5| Step: 7
Training loss: 1.622401213496693
Validation loss: 2.7369480694266484

Epoch: 5| Step: 8
Training loss: 1.3393265418232867
Validation loss: 2.6913592508904993

Epoch: 5| Step: 9
Training loss: 1.4524322827520133
Validation loss: 2.704441599449697

Epoch: 5| Step: 10
Training loss: 1.538220635222962
Validation loss: 2.719541317361171

Epoch: 235| Step: 0
Training loss: 1.3665451720748814
Validation loss: 2.685058124475517

Epoch: 5| Step: 1
Training loss: 1.4307098902109783
Validation loss: 2.6692083340742987

Epoch: 5| Step: 2
Training loss: 1.2829483220522093
Validation loss: 2.6847944288932233

Epoch: 5| Step: 3
Training loss: 1.1728940983030163
Validation loss: 2.7020060096059315

Epoch: 5| Step: 4
Training loss: 0.8915744873481819
Validation loss: 2.69463880339969

Epoch: 5| Step: 5
Training loss: 1.7440290084272445
Validation loss: 2.699789965628566

Epoch: 5| Step: 6
Training loss: 1.288764826766083
Validation loss: 2.6504779515066486

Epoch: 5| Step: 7
Training loss: 1.3769869320013188
Validation loss: 2.683779749317752

Epoch: 5| Step: 8
Training loss: 1.7262903059356591
Validation loss: 2.6494816870486617

Epoch: 5| Step: 9
Training loss: 1.4027010746665183
Validation loss: 2.6707365312346996

Epoch: 5| Step: 10
Training loss: 1.4140085452413733
Validation loss: 2.655180180123824

Epoch: 236| Step: 0
Training loss: 1.2840956743847052
Validation loss: 2.667072335145489

Epoch: 5| Step: 1
Training loss: 1.2408604761147712
Validation loss: 2.6879345274766746

Epoch: 5| Step: 2
Training loss: 1.5184878809912865
Validation loss: 2.7003730984055414

Epoch: 5| Step: 3
Training loss: 1.3376889710311526
Validation loss: 2.7027561766687045

Epoch: 5| Step: 4
Training loss: 1.5073777594910804
Validation loss: 2.6832086346751036

Epoch: 5| Step: 5
Training loss: 1.4390404781350599
Validation loss: 2.655059597899989

Epoch: 5| Step: 6
Training loss: 1.4389607843989654
Validation loss: 2.657512386534981

Epoch: 5| Step: 7
Training loss: 1.1447588593372793
Validation loss: 2.684859837926448

Epoch: 5| Step: 8
Training loss: 1.3835426601151113
Validation loss: 2.6787253792347787

Epoch: 5| Step: 9
Training loss: 1.4075086682799733
Validation loss: 2.702126346910258

Epoch: 5| Step: 10
Training loss: 1.502720273543955
Validation loss: 2.719246752577139

Epoch: 237| Step: 0
Training loss: 1.5057817134795108
Validation loss: 2.731479452610701

Epoch: 5| Step: 1
Training loss: 1.2977018822553374
Validation loss: 2.7289807098869305

Epoch: 5| Step: 2
Training loss: 1.1498107484917277
Validation loss: 2.738155862588918

Epoch: 5| Step: 3
Training loss: 1.2702358227400175
Validation loss: 2.7057862931557364

Epoch: 5| Step: 4
Training loss: 1.5560589592655842
Validation loss: 2.699954512143452

Epoch: 5| Step: 5
Training loss: 1.2413100496424179
Validation loss: 2.6954343411854107

Epoch: 5| Step: 6
Training loss: 1.7459188284079545
Validation loss: 2.6648839797226853

Epoch: 5| Step: 7
Training loss: 0.988543931632199
Validation loss: 2.7039522527767934

Epoch: 5| Step: 8
Training loss: 1.2661066433945503
Validation loss: 2.6959767758789055

Epoch: 5| Step: 9
Training loss: 1.3374937485165534
Validation loss: 2.6909475161375047

Epoch: 5| Step: 10
Training loss: 1.5322968155052386
Validation loss: 2.7027871193807433

Epoch: 238| Step: 0
Training loss: 1.2822714664821457
Validation loss: 2.6582596378434675

Epoch: 5| Step: 1
Training loss: 1.0450275688550295
Validation loss: 2.6928605449807828

Epoch: 5| Step: 2
Training loss: 1.5726596883403638
Validation loss: 2.6934936825949114

Epoch: 5| Step: 3
Training loss: 1.3953508378215982
Validation loss: 2.700601023810674

Epoch: 5| Step: 4
Training loss: 1.8513152524793015
Validation loss: 2.6754268460939987

Epoch: 5| Step: 5
Training loss: 1.462160954749091
Validation loss: 2.664716367585094

Epoch: 5| Step: 6
Training loss: 1.5328390478854628
Validation loss: 2.6346526119151155

Epoch: 5| Step: 7
Training loss: 1.1915210105781988
Validation loss: 2.6454008315910507

Epoch: 5| Step: 8
Training loss: 1.258820597724898
Validation loss: 2.6458561161278964

Epoch: 5| Step: 9
Training loss: 1.2613149179740053
Validation loss: 2.6528626763943186

Epoch: 5| Step: 10
Training loss: 0.8847475702662545
Validation loss: 2.714207437633142

Epoch: 239| Step: 0
Training loss: 1.4310191472210059
Validation loss: 2.7188149561021833

Epoch: 5| Step: 1
Training loss: 1.3043194097381319
Validation loss: 2.7251571812022193

Epoch: 5| Step: 2
Training loss: 1.2748198232311836
Validation loss: 2.6947982280819436

Epoch: 5| Step: 3
Training loss: 1.4157593383373304
Validation loss: 2.6927254346364506

Epoch: 5| Step: 4
Training loss: 1.3281257180604678
Validation loss: 2.672921607625243

Epoch: 5| Step: 5
Training loss: 1.524922434600879
Validation loss: 2.6642153596867337

Epoch: 5| Step: 6
Training loss: 1.230602923147275
Validation loss: 2.6834845702130887

Epoch: 5| Step: 7
Training loss: 1.3843258265594809
Validation loss: 2.65857847727173

Epoch: 5| Step: 8
Training loss: 1.2100915722835885
Validation loss: 2.690945232536961

Epoch: 5| Step: 9
Training loss: 1.3090991510326853
Validation loss: 2.688579372145054

Epoch: 5| Step: 10
Training loss: 1.5040451976447475
Validation loss: 2.699722196787334

Epoch: 240| Step: 0
Training loss: 0.8257325359256655
Validation loss: 2.720540695183293

Epoch: 5| Step: 1
Training loss: 1.3347234731018436
Validation loss: 2.7263765721538844

Epoch: 5| Step: 2
Training loss: 0.8935245696448366
Validation loss: 2.7070584087989036

Epoch: 5| Step: 3
Training loss: 1.5319739206997696
Validation loss: 2.723906892981619

Epoch: 5| Step: 4
Training loss: 1.4408187702796917
Validation loss: 2.7499248861680115

Epoch: 5| Step: 5
Training loss: 1.452759235248348
Validation loss: 2.7043017239156906

Epoch: 5| Step: 6
Training loss: 1.080405435755083
Validation loss: 2.69467667018447

Epoch: 5| Step: 7
Training loss: 1.3704662136741153
Validation loss: 2.684035161300283

Epoch: 5| Step: 8
Training loss: 1.5493672648394896
Validation loss: 2.7057865158102476

Epoch: 5| Step: 9
Training loss: 1.4598101994193826
Validation loss: 2.6894631566690705

Epoch: 5| Step: 10
Training loss: 1.5372934001032785
Validation loss: 2.6894992432969227

Epoch: 241| Step: 0
Training loss: 1.6309125880165916
Validation loss: 2.6811388707859516

Epoch: 5| Step: 1
Training loss: 1.2220209683306562
Validation loss: 2.7268878679048356

Epoch: 5| Step: 2
Training loss: 1.2554470114971252
Validation loss: 2.7173271421033114

Epoch: 5| Step: 3
Training loss: 1.295129037341756
Validation loss: 2.7519515823174436

Epoch: 5| Step: 4
Training loss: 1.5879092432410953
Validation loss: 2.753244358155496

Epoch: 5| Step: 5
Training loss: 1.2393545799862367
Validation loss: 2.7562299620375943

Epoch: 5| Step: 6
Training loss: 1.155480515405311
Validation loss: 2.7199322048261134

Epoch: 5| Step: 7
Training loss: 1.5184458800950358
Validation loss: 2.725922366207489

Epoch: 5| Step: 8
Training loss: 1.2914137233695584
Validation loss: 2.6778124290493883

Epoch: 5| Step: 9
Training loss: 1.1689277207812414
Validation loss: 2.7029644208730765

Epoch: 5| Step: 10
Training loss: 1.1067256723801677
Validation loss: 2.675006157483955

Epoch: 242| Step: 0
Training loss: 1.0637748026841987
Validation loss: 2.686164172929409

Epoch: 5| Step: 1
Training loss: 1.3502135408137537
Validation loss: 2.7326040919875254

Epoch: 5| Step: 2
Training loss: 1.035514395314888
Validation loss: 2.7147117674143866

Epoch: 5| Step: 3
Training loss: 1.2941260100097016
Validation loss: 2.7480814646826306

Epoch: 5| Step: 4
Training loss: 1.3774078267685594
Validation loss: 2.7966900918653623

Epoch: 5| Step: 5
Training loss: 1.6602909527153538
Validation loss: 2.763557365210891

Epoch: 5| Step: 6
Training loss: 1.3162880683168616
Validation loss: 2.736184012410356

Epoch: 5| Step: 7
Training loss: 1.277445564528627
Validation loss: 2.7279660968167776

Epoch: 5| Step: 8
Training loss: 1.2787972209784482
Validation loss: 2.723102013740282

Epoch: 5| Step: 9
Training loss: 1.3553553377136238
Validation loss: 2.703667453422119

Epoch: 5| Step: 10
Training loss: 1.4291731112291302
Validation loss: 2.735306262278182

Epoch: 243| Step: 0
Training loss: 1.0555261738909751
Validation loss: 2.7062333474486087

Epoch: 5| Step: 1
Training loss: 1.2662203765898612
Validation loss: 2.6967312543798436

Epoch: 5| Step: 2
Training loss: 1.3714045419603038
Validation loss: 2.731580168847733

Epoch: 5| Step: 3
Training loss: 1.1290539707565912
Validation loss: 2.7309685114662376

Epoch: 5| Step: 4
Training loss: 1.4655760702005733
Validation loss: 2.742570046679466

Epoch: 5| Step: 5
Training loss: 1.3543472707574098
Validation loss: 2.735440934842716

Epoch: 5| Step: 6
Training loss: 1.4439724044910418
Validation loss: 2.7553729317856814

Epoch: 5| Step: 7
Training loss: 1.4601945262808953
Validation loss: 2.7460802805771873

Epoch: 5| Step: 8
Training loss: 1.0947764893171503
Validation loss: 2.753537996226685

Epoch: 5| Step: 9
Training loss: 1.3126801866642681
Validation loss: 2.7291005397495316

Epoch: 5| Step: 10
Training loss: 1.4145559219303812
Validation loss: 2.724661646392377

Epoch: 244| Step: 0
Training loss: 1.2444536662658858
Validation loss: 2.703772774111179

Epoch: 5| Step: 1
Training loss: 1.20675275731725
Validation loss: 2.735890614487394

Epoch: 5| Step: 2
Training loss: 1.8002798578143417
Validation loss: 2.739341951352126

Epoch: 5| Step: 3
Training loss: 0.9546477551467388
Validation loss: 2.7026916532116005

Epoch: 5| Step: 4
Training loss: 1.2083807749588038
Validation loss: 2.716588270169239

Epoch: 5| Step: 5
Training loss: 1.1960320395129997
Validation loss: 2.7225017109750116

Epoch: 5| Step: 6
Training loss: 1.2503095720328838
Validation loss: 2.7107874763862805

Epoch: 5| Step: 7
Training loss: 1.2558028948528608
Validation loss: 2.7165459626504793

Epoch: 5| Step: 8
Training loss: 1.426225817623291
Validation loss: 2.723905010654783

Epoch: 5| Step: 9
Training loss: 1.1577793008469293
Validation loss: 2.7211777904826953

Epoch: 5| Step: 10
Training loss: 1.399629862425387
Validation loss: 2.7446442140051928

Epoch: 245| Step: 0
Training loss: 1.2011780777437664
Validation loss: 2.708128169944559

Epoch: 5| Step: 1
Training loss: 1.1183710831146874
Validation loss: 2.6860406933874357

Epoch: 5| Step: 2
Training loss: 1.6251858825006582
Validation loss: 2.690019787030467

Epoch: 5| Step: 3
Training loss: 1.3741941691635096
Validation loss: 2.675913841651682

Epoch: 5| Step: 4
Training loss: 1.267990868000035
Validation loss: 2.6867488871261473

Epoch: 5| Step: 5
Training loss: 1.121024790912545
Validation loss: 2.676554177530168

Epoch: 5| Step: 6
Training loss: 1.104520627034248
Validation loss: 2.6560553019116315

Epoch: 5| Step: 7
Training loss: 1.4324553332596648
Validation loss: 2.7085904301485613

Epoch: 5| Step: 8
Training loss: 1.306877217448254
Validation loss: 2.743746966367026

Epoch: 5| Step: 9
Training loss: 1.3813955515125889
Validation loss: 2.692451666815202

Epoch: 5| Step: 10
Training loss: 1.3072597707477012
Validation loss: 2.7090333215440596

Epoch: 246| Step: 0
Training loss: 0.9130181108874077
Validation loss: 2.7054334792771453

Epoch: 5| Step: 1
Training loss: 1.7384802543653222
Validation loss: 2.6887273539953043

Epoch: 5| Step: 2
Training loss: 1.1201357586359626
Validation loss: 2.7082032351487606

Epoch: 5| Step: 3
Training loss: 1.4236812646632924
Validation loss: 2.7069485104857534

Epoch: 5| Step: 4
Training loss: 1.3513606808314595
Validation loss: 2.694878475322759

Epoch: 5| Step: 5
Training loss: 1.3835403337296541
Validation loss: 2.712429922760096

Epoch: 5| Step: 6
Training loss: 1.27433483125953
Validation loss: 2.7064693659567887

Epoch: 5| Step: 7
Training loss: 1.1659069425964301
Validation loss: 2.7297416018173633

Epoch: 5| Step: 8
Training loss: 1.2622185535015673
Validation loss: 2.7450811577431504

Epoch: 5| Step: 9
Training loss: 1.3825613537327475
Validation loss: 2.724489523564603

Epoch: 5| Step: 10
Training loss: 0.9535457745403084
Validation loss: 2.7450550923754156

Epoch: 247| Step: 0
Training loss: 1.0747419158390148
Validation loss: 2.734701119237832

Epoch: 5| Step: 1
Training loss: 1.099933800005774
Validation loss: 2.684553131871113

Epoch: 5| Step: 2
Training loss: 1.1054475061107514
Validation loss: 2.7296332572839233

Epoch: 5| Step: 3
Training loss: 1.1353796973319752
Validation loss: 2.689537064247487

Epoch: 5| Step: 4
Training loss: 1.0540346173495574
Validation loss: 2.6836668410187707

Epoch: 5| Step: 5
Training loss: 1.5925696995212648
Validation loss: 2.72064851605752

Epoch: 5| Step: 6
Training loss: 1.1216013221260854
Validation loss: 2.7536639921916826

Epoch: 5| Step: 7
Training loss: 1.388370787095114
Validation loss: 2.735179493773162

Epoch: 5| Step: 8
Training loss: 1.3537565735210901
Validation loss: 2.7332959611750374

Epoch: 5| Step: 9
Training loss: 1.3746203418585816
Validation loss: 2.706262915659381

Epoch: 5| Step: 10
Training loss: 1.6249352222149205
Validation loss: 2.715659163371174

Epoch: 248| Step: 0
Training loss: 1.450235097833885
Validation loss: 2.732102582247907

Epoch: 5| Step: 1
Training loss: 1.0219736477427406
Validation loss: 2.70098778617569

Epoch: 5| Step: 2
Training loss: 1.1163204536545488
Validation loss: 2.672628224937578

Epoch: 5| Step: 3
Training loss: 1.1887952867740523
Validation loss: 2.6773273530293626

Epoch: 5| Step: 4
Training loss: 0.9678183351758991
Validation loss: 2.679946919862816

Epoch: 5| Step: 5
Training loss: 1.3551090433789181
Validation loss: 2.6929558855798077

Epoch: 5| Step: 6
Training loss: 1.0663663416510871
Validation loss: 2.6875527928311778

Epoch: 5| Step: 7
Training loss: 1.0168991312963156
Validation loss: 2.6860723707671466

Epoch: 5| Step: 8
Training loss: 1.3640694075122213
Validation loss: 2.693560592608239

Epoch: 5| Step: 9
Training loss: 1.7562545993513925
Validation loss: 2.6912030223181707

Epoch: 5| Step: 10
Training loss: 1.4117253837999573
Validation loss: 2.720344003567738

Epoch: 249| Step: 0
Training loss: 1.445694001856262
Validation loss: 2.698368055812173

Epoch: 5| Step: 1
Training loss: 1.4664658987019317
Validation loss: 2.714281324095764

Epoch: 5| Step: 2
Training loss: 0.9991234275321561
Validation loss: 2.682661944951085

Epoch: 5| Step: 3
Training loss: 1.5855485410979944
Validation loss: 2.6647767290257924

Epoch: 5| Step: 4
Training loss: 1.080183800051179
Validation loss: 2.6901915975719395

Epoch: 5| Step: 5
Training loss: 0.8207160320474461
Validation loss: 2.624492472168582

Epoch: 5| Step: 6
Training loss: 1.1015301422344732
Validation loss: 2.6479339077267534

Epoch: 5| Step: 7
Training loss: 1.3563055264405441
Validation loss: 2.6594562557290606

Epoch: 5| Step: 8
Training loss: 1.1490496606345482
Validation loss: 2.6675951995316853

Epoch: 5| Step: 9
Training loss: 1.007352443046332
Validation loss: 2.67003275195934

Epoch: 5| Step: 10
Training loss: 1.5816716291686748
Validation loss: 2.694264137865212

Epoch: 250| Step: 0
Training loss: 1.4794382016243657
Validation loss: 2.70552897567188

Epoch: 5| Step: 1
Training loss: 1.7434650748944496
Validation loss: 2.6936906949897783

Epoch: 5| Step: 2
Training loss: 1.1282620819580935
Validation loss: 2.657286618448865

Epoch: 5| Step: 3
Training loss: 1.104804820261114
Validation loss: 2.627328030793516

Epoch: 5| Step: 4
Training loss: 1.040884671733107
Validation loss: 2.61501546917399

Epoch: 5| Step: 5
Training loss: 0.8223330363641745
Validation loss: 2.618669802552035

Epoch: 5| Step: 6
Training loss: 1.2940496899233989
Validation loss: 2.630096808113621

Epoch: 5| Step: 7
Training loss: 1.212463500269882
Validation loss: 2.654240544362262

Epoch: 5| Step: 8
Training loss: 1.1966673708269886
Validation loss: 2.6871655697991423

Epoch: 5| Step: 9
Training loss: 1.3095845129962738
Validation loss: 2.706853058488927

Epoch: 5| Step: 10
Training loss: 1.2087088472763534
Validation loss: 2.7471847984227735

Epoch: 251| Step: 0
Training loss: 1.0124799302549194
Validation loss: 2.6917285224677157

Epoch: 5| Step: 1
Training loss: 1.2486471962066736
Validation loss: 2.724409809758379

Epoch: 5| Step: 2
Training loss: 1.4831038000984473
Validation loss: 2.7076015711233414

Epoch: 5| Step: 3
Training loss: 1.0830276803893624
Validation loss: 2.731168439445217

Epoch: 5| Step: 4
Training loss: 0.6826601028595595
Validation loss: 2.7253372956593944

Epoch: 5| Step: 5
Training loss: 1.0841365123213624
Validation loss: 2.7383570230593586

Epoch: 5| Step: 6
Training loss: 1.5015039851351408
Validation loss: 2.7656411032083033

Epoch: 5| Step: 7
Training loss: 1.3154098860419188
Validation loss: 2.715379505258895

Epoch: 5| Step: 8
Training loss: 1.1609240216670327
Validation loss: 2.7349752856562315

Epoch: 5| Step: 9
Training loss: 1.3350322400175554
Validation loss: 2.7107216512467738

Epoch: 5| Step: 10
Training loss: 1.4193153397700826
Validation loss: 2.6915951630715096

Epoch: 252| Step: 0
Training loss: 0.9511252515203189
Validation loss: 2.6622793429431453

Epoch: 5| Step: 1
Training loss: 1.2605792116805685
Validation loss: 2.6230712236623637

Epoch: 5| Step: 2
Training loss: 1.6107991407975168
Validation loss: 2.610276850700964

Epoch: 5| Step: 3
Training loss: 1.2406434833677547
Validation loss: 2.599955166113844

Epoch: 5| Step: 4
Training loss: 1.194700346131026
Validation loss: 2.583181270234997

Epoch: 5| Step: 5
Training loss: 1.2119714076317436
Validation loss: 2.58357370497441

Epoch: 5| Step: 6
Training loss: 1.4332076963911662
Validation loss: 2.598234251638334

Epoch: 5| Step: 7
Training loss: 1.386619628802311
Validation loss: 2.5995305162025577

Epoch: 5| Step: 8
Training loss: 0.9173682663438198
Validation loss: 2.6231938162762587

Epoch: 5| Step: 9
Training loss: 1.1051417969220132
Validation loss: 2.6631919721533883

Epoch: 5| Step: 10
Training loss: 1.2619498309941029
Validation loss: 2.6714877884455532

Epoch: 253| Step: 0
Training loss: 1.230361594726557
Validation loss: 2.679793461319328

Epoch: 5| Step: 1
Training loss: 1.2349960117044028
Validation loss: 2.686977412932756

Epoch: 5| Step: 2
Training loss: 1.3158984011184298
Validation loss: 2.6738410053586974

Epoch: 5| Step: 3
Training loss: 1.2879419253507403
Validation loss: 2.6639616937582398

Epoch: 5| Step: 4
Training loss: 1.3817781793499981
Validation loss: 2.6767775706233805

Epoch: 5| Step: 5
Training loss: 1.019180646807236
Validation loss: 2.661897274931985

Epoch: 5| Step: 6
Training loss: 1.2950674121940815
Validation loss: 2.6585536187236447

Epoch: 5| Step: 7
Training loss: 1.3674631331389082
Validation loss: 2.6451795637648563

Epoch: 5| Step: 8
Training loss: 0.8667914027229984
Validation loss: 2.68547062758329

Epoch: 5| Step: 9
Training loss: 1.3136289373453707
Validation loss: 2.7158779447571493

Epoch: 5| Step: 10
Training loss: 0.9637508302776555
Validation loss: 2.732326103477178

Epoch: 254| Step: 0
Training loss: 1.2671892366032866
Validation loss: 2.714289596020371

Epoch: 5| Step: 1
Training loss: 1.4040620100749401
Validation loss: 2.6961975413716237

Epoch: 5| Step: 2
Training loss: 1.0287929510186555
Validation loss: 2.705141079018576

Epoch: 5| Step: 3
Training loss: 1.3162503928449285
Validation loss: 2.7231493810046943

Epoch: 5| Step: 4
Training loss: 0.9749896085625539
Validation loss: 2.7203090461150703

Epoch: 5| Step: 5
Training loss: 0.9949617423557179
Validation loss: 2.7316991179446575

Epoch: 5| Step: 6
Training loss: 0.9102341123355784
Validation loss: 2.7041883509250786

Epoch: 5| Step: 7
Training loss: 1.27725466729635
Validation loss: 2.7206851544123967

Epoch: 5| Step: 8
Training loss: 1.3136587023748114
Validation loss: 2.6996782606037297

Epoch: 5| Step: 9
Training loss: 1.2923986094124627
Validation loss: 2.7224520460777764

Epoch: 5| Step: 10
Training loss: 1.5913491210271542
Validation loss: 2.7300212855581463

Epoch: 255| Step: 0
Training loss: 1.3520812433791896
Validation loss: 2.7755039704570152

Epoch: 5| Step: 1
Training loss: 1.3665651485296195
Validation loss: 2.758584398668801

Epoch: 5| Step: 2
Training loss: 0.9248771921032096
Validation loss: 2.752690925611989

Epoch: 5| Step: 3
Training loss: 1.0012962761137205
Validation loss: 2.7427494359229776

Epoch: 5| Step: 4
Training loss: 1.0221117474514512
Validation loss: 2.758370734189453

Epoch: 5| Step: 5
Training loss: 1.0379482404045546
Validation loss: 2.7387839207273514

Epoch: 5| Step: 6
Training loss: 1.0260110195378678
Validation loss: 2.691931571434863

Epoch: 5| Step: 7
Training loss: 1.1802744131732843
Validation loss: 2.6807296602946042

Epoch: 5| Step: 8
Training loss: 1.622527001366376
Validation loss: 2.661118784913889

Epoch: 5| Step: 9
Training loss: 0.8473717699969887
Validation loss: 2.659750112058572

Epoch: 5| Step: 10
Training loss: 1.663296662093931
Validation loss: 2.628660477147573

Epoch: 256| Step: 0
Training loss: 0.8897145620450292
Validation loss: 2.6751907155675476

Epoch: 5| Step: 1
Training loss: 1.5190337084859176
Validation loss: 2.7202176366709856

Epoch: 5| Step: 2
Training loss: 0.9800697213789872
Validation loss: 2.6848776095512155

Epoch: 5| Step: 3
Training loss: 1.0245728928720628
Validation loss: 2.7257461310601303

Epoch: 5| Step: 4
Training loss: 0.993731731270864
Validation loss: 2.687927081473077

Epoch: 5| Step: 5
Training loss: 1.3822053341423286
Validation loss: 2.669863147982252

Epoch: 5| Step: 6
Training loss: 1.2532816249160577
Validation loss: 2.6679900318408523

Epoch: 5| Step: 7
Training loss: 1.2690455989656275
Validation loss: 2.6711953730886924

Epoch: 5| Step: 8
Training loss: 1.2978455921549565
Validation loss: 2.6615948770971274

Epoch: 5| Step: 9
Training loss: 1.3261175804653365
Validation loss: 2.6812671444646394

Epoch: 5| Step: 10
Training loss: 1.238329432178854
Validation loss: 2.66835413084609

Epoch: 257| Step: 0
Training loss: 1.2772475740115141
Validation loss: 2.6898902952824275

Epoch: 5| Step: 1
Training loss: 0.8996039406549761
Validation loss: 2.735962225005452

Epoch: 5| Step: 2
Training loss: 0.9561139440048141
Validation loss: 2.7169972447415365

Epoch: 5| Step: 3
Training loss: 1.5074628513497315
Validation loss: 2.7515617188968746

Epoch: 5| Step: 4
Training loss: 1.1232297002170875
Validation loss: 2.698404506931474

Epoch: 5| Step: 5
Training loss: 1.316067887013257
Validation loss: 2.712991297096822

Epoch: 5| Step: 6
Training loss: 1.2516285301439873
Validation loss: 2.6443795365296516

Epoch: 5| Step: 7
Training loss: 1.1543856875467544
Validation loss: 2.6233206972019905

Epoch: 5| Step: 8
Training loss: 1.0256799489515598
Validation loss: 2.6490546174916374

Epoch: 5| Step: 9
Training loss: 1.2909252233205455
Validation loss: 2.658707226154805

Epoch: 5| Step: 10
Training loss: 1.3786304835709307
Validation loss: 2.632710887678527

Epoch: 258| Step: 0
Training loss: 0.8236802497936602
Validation loss: 2.670416501478507

Epoch: 5| Step: 1
Training loss: 1.0051819529390709
Validation loss: 2.693167028410863

Epoch: 5| Step: 2
Training loss: 1.3118320763750386
Validation loss: 2.713131043071371

Epoch: 5| Step: 3
Training loss: 1.3767345065534728
Validation loss: 2.719062875809927

Epoch: 5| Step: 4
Training loss: 1.2322282593709835
Validation loss: 2.6875153732146284

Epoch: 5| Step: 5
Training loss: 1.2926735901243045
Validation loss: 2.700892283933332

Epoch: 5| Step: 6
Training loss: 0.9833514932528878
Validation loss: 2.6951817648891576

Epoch: 5| Step: 7
Training loss: 1.2530130788237728
Validation loss: 2.7028111765207226

Epoch: 5| Step: 8
Training loss: 1.4723089400529077
Validation loss: 2.6319532355751383

Epoch: 5| Step: 9
Training loss: 0.9454897249410896
Validation loss: 2.6550205896310457

Epoch: 5| Step: 10
Training loss: 1.2898394006370444
Validation loss: 2.660079055062886

Epoch: 259| Step: 0
Training loss: 1.3389695321107338
Validation loss: 2.643783582155398

Epoch: 5| Step: 1
Training loss: 1.463310232450817
Validation loss: 2.6314382885051297

Epoch: 5| Step: 2
Training loss: 1.141913117773187
Validation loss: 2.6568570258349946

Epoch: 5| Step: 3
Training loss: 1.2266833008972093
Validation loss: 2.6624800410223806

Epoch: 5| Step: 4
Training loss: 1.2128873324387928
Validation loss: 2.698622478472235

Epoch: 5| Step: 5
Training loss: 1.1882294873682815
Validation loss: 2.655645962197383

Epoch: 5| Step: 6
Training loss: 0.9871434533803723
Validation loss: 2.6248494030343634

Epoch: 5| Step: 7
Training loss: 1.0661438000685561
Validation loss: 2.6120916780806698

Epoch: 5| Step: 8
Training loss: 1.0938782208081086
Validation loss: 2.6163057064065494

Epoch: 5| Step: 9
Training loss: 0.9809110639254042
Validation loss: 2.5906034979955916

Epoch: 5| Step: 10
Training loss: 1.2939080920354296
Validation loss: 2.6366744358193093

Epoch: 260| Step: 0
Training loss: 1.181103797220875
Validation loss: 2.6299341319380423

Epoch: 5| Step: 1
Training loss: 1.181361646270597
Validation loss: 2.6921754495681713

Epoch: 5| Step: 2
Training loss: 1.2301696898323278
Validation loss: 2.710530133345058

Epoch: 5| Step: 3
Training loss: 1.1976374535724845
Validation loss: 2.7279624354990544

Epoch: 5| Step: 4
Training loss: 1.121141386183072
Validation loss: 2.665449048731456

Epoch: 5| Step: 5
Training loss: 0.964041959769426
Validation loss: 2.6938163358198177

Epoch: 5| Step: 6
Training loss: 1.2623722049505792
Validation loss: 2.7028876238395214

Epoch: 5| Step: 7
Training loss: 1.436230970078999
Validation loss: 2.7085624528493484

Epoch: 5| Step: 8
Training loss: 0.9840122038755139
Validation loss: 2.6671779820765296

Epoch: 5| Step: 9
Training loss: 1.0090675523524535
Validation loss: 2.6583604867233555

Epoch: 5| Step: 10
Training loss: 1.1488274152403983
Validation loss: 2.6802222021784035

Epoch: 261| Step: 0
Training loss: 1.036315844276498
Validation loss: 2.7241971830339193

Epoch: 5| Step: 1
Training loss: 1.2424553636327593
Validation loss: 2.665349674209706

Epoch: 5| Step: 2
Training loss: 1.1132302791237356
Validation loss: 2.678777778439387

Epoch: 5| Step: 3
Training loss: 0.9661053274597096
Validation loss: 2.70866402120917

Epoch: 5| Step: 4
Training loss: 0.7254892441407748
Validation loss: 2.7224981383568885

Epoch: 5| Step: 5
Training loss: 0.8813590854738506
Validation loss: 2.7071628953760074

Epoch: 5| Step: 6
Training loss: 1.2332492958683932
Validation loss: 2.717342097505218

Epoch: 5| Step: 7
Training loss: 0.9289489505280001
Validation loss: 2.7362990507819083

Epoch: 5| Step: 8
Training loss: 1.433503691211814
Validation loss: 2.710724978834479

Epoch: 5| Step: 9
Training loss: 1.238339636355789
Validation loss: 2.707067557951447

Epoch: 5| Step: 10
Training loss: 1.5784946424207853
Validation loss: 2.6921144597275246

Epoch: 262| Step: 0
Training loss: 1.1474681578064057
Validation loss: 2.6937132706569837

Epoch: 5| Step: 1
Training loss: 1.1569367508608903
Validation loss: 2.6846584380105343

Epoch: 5| Step: 2
Training loss: 1.0858385329123248
Validation loss: 2.6862155070162443

Epoch: 5| Step: 3
Training loss: 1.1047327401961764
Validation loss: 2.6803546267503524

Epoch: 5| Step: 4
Training loss: 1.1736031569011331
Validation loss: 2.6675108975557498

Epoch: 5| Step: 5
Training loss: 0.7908306517788358
Validation loss: 2.6587744610258914

Epoch: 5| Step: 6
Training loss: 1.2190513238343215
Validation loss: 2.6949754473011662

Epoch: 5| Step: 7
Training loss: 1.2918063929056915
Validation loss: 2.6977163064549106

Epoch: 5| Step: 8
Training loss: 1.4452403282497814
Validation loss: 2.6404630171171086

Epoch: 5| Step: 9
Training loss: 1.0149249084770295
Validation loss: 2.7224913660009693

Epoch: 5| Step: 10
Training loss: 0.9638277952112173
Validation loss: 2.6656883589695326

Epoch: 263| Step: 0
Training loss: 1.0347373258667487
Validation loss: 2.6840461196473986

Epoch: 5| Step: 1
Training loss: 0.9687917454246605
Validation loss: 2.6763795020250343

Epoch: 5| Step: 2
Training loss: 1.1499644398374347
Validation loss: 2.668673208081486

Epoch: 5| Step: 3
Training loss: 1.1219039275708838
Validation loss: 2.698549169326827

Epoch: 5| Step: 4
Training loss: 1.08216157534614
Validation loss: 2.6487802229353137

Epoch: 5| Step: 5
Training loss: 1.4245009435166527
Validation loss: 2.6493984933597856

Epoch: 5| Step: 6
Training loss: 1.0637281276188995
Validation loss: 2.6506727971624047

Epoch: 5| Step: 7
Training loss: 1.0768737165960367
Validation loss: 2.641767758065895

Epoch: 5| Step: 8
Training loss: 1.0570362640735602
Validation loss: 2.7001459731320385

Epoch: 5| Step: 9
Training loss: 1.3522869660142955
Validation loss: 2.648377950995103

Epoch: 5| Step: 10
Training loss: 0.8913424095408804
Validation loss: 2.66901021954213

Epoch: 264| Step: 0
Training loss: 1.208868313889705
Validation loss: 2.6793701075751755

Epoch: 5| Step: 1
Training loss: 1.0254979831260962
Validation loss: 2.6594021729914505

Epoch: 5| Step: 2
Training loss: 0.785237777804303
Validation loss: 2.6729492367236394

Epoch: 5| Step: 3
Training loss: 1.1748570456692973
Validation loss: 2.652370299246697

Epoch: 5| Step: 4
Training loss: 1.1046148985836528
Validation loss: 2.6312903915008587

Epoch: 5| Step: 5
Training loss: 0.8972792747698218
Validation loss: 2.612039221929142

Epoch: 5| Step: 6
Training loss: 1.249761892528842
Validation loss: 2.647488941726242

Epoch: 5| Step: 7
Training loss: 1.3126909480386315
Validation loss: 2.6470648715998175

Epoch: 5| Step: 8
Training loss: 1.0348672715373197
Validation loss: 2.651860376374038

Epoch: 5| Step: 9
Training loss: 1.3352230012924964
Validation loss: 2.677936593381253

Epoch: 5| Step: 10
Training loss: 0.9786510259637048
Validation loss: 2.6727509409950034

Epoch: 265| Step: 0
Training loss: 1.4197496732162957
Validation loss: 2.6699925116332253

Epoch: 5| Step: 1
Training loss: 1.1892380292866158
Validation loss: 2.68112511711512

Epoch: 5| Step: 2
Training loss: 1.0348172190423182
Validation loss: 2.6907213883601506

Epoch: 5| Step: 3
Training loss: 0.9656286406216925
Validation loss: 2.6924944022042547

Epoch: 5| Step: 4
Training loss: 1.0250360947743304
Validation loss: 2.6802891709008265

Epoch: 5| Step: 5
Training loss: 0.8284548336533839
Validation loss: 2.7124992851482075

Epoch: 5| Step: 6
Training loss: 1.0165737708962368
Validation loss: 2.6536040748964713

Epoch: 5| Step: 7
Training loss: 0.9202141105246535
Validation loss: 2.6831901631204267

Epoch: 5| Step: 8
Training loss: 1.1286106448577193
Validation loss: 2.654183766289411

Epoch: 5| Step: 9
Training loss: 1.352671746862193
Validation loss: 2.6579219432542747

Epoch: 5| Step: 10
Training loss: 1.113594359152445
Validation loss: 2.6330431463505732

Epoch: 266| Step: 0
Training loss: 0.963075569760789
Validation loss: 2.668646094772654

Epoch: 5| Step: 1
Training loss: 0.8749287099406929
Validation loss: 2.6630009353788417

Epoch: 5| Step: 2
Training loss: 0.8715332359524687
Validation loss: 2.6507275420619583

Epoch: 5| Step: 3
Training loss: 1.1830479335925026
Validation loss: 2.663181372728523

Epoch: 5| Step: 4
Training loss: 1.062665085028744
Validation loss: 2.6977004273651897

Epoch: 5| Step: 5
Training loss: 1.1115071398891399
Validation loss: 2.6794153010257595

Epoch: 5| Step: 6
Training loss: 1.1472461775422815
Validation loss: 2.681039658519227

Epoch: 5| Step: 7
Training loss: 1.2235376270776792
Validation loss: 2.6865973496106452

Epoch: 5| Step: 8
Training loss: 0.9894942728756807
Validation loss: 2.6507462243561046

Epoch: 5| Step: 9
Training loss: 1.391048324102072
Validation loss: 2.643733797993659

Epoch: 5| Step: 10
Training loss: 1.1899172123393185
Validation loss: 2.6706533286656335

Epoch: 267| Step: 0
Training loss: 1.0097433120948067
Validation loss: 2.631641803305443

Epoch: 5| Step: 1
Training loss: 1.1259376009629516
Validation loss: 2.674566111482535

Epoch: 5| Step: 2
Training loss: 0.9416513717444494
Validation loss: 2.6652480961711387

Epoch: 5| Step: 3
Training loss: 1.2877230071473433
Validation loss: 2.6767571890105533

Epoch: 5| Step: 4
Training loss: 0.9987613636272727
Validation loss: 2.6746628844141256

Epoch: 5| Step: 5
Training loss: 1.1423784652108095
Validation loss: 2.6597884524130833

Epoch: 5| Step: 6
Training loss: 1.0530886363647884
Validation loss: 2.6829483310028714

Epoch: 5| Step: 7
Training loss: 1.1519001769751813
Validation loss: 2.6422949351064497

Epoch: 5| Step: 8
Training loss: 0.9010528313858324
Validation loss: 2.652227770325233

Epoch: 5| Step: 9
Training loss: 1.1461735422640875
Validation loss: 2.643737193896736

Epoch: 5| Step: 10
Training loss: 1.1358275180554902
Validation loss: 2.6695957696577883

Epoch: 268| Step: 0
Training loss: 1.1806464939372159
Validation loss: 2.6439279228039836

Epoch: 5| Step: 1
Training loss: 0.9429790922923577
Validation loss: 2.647873758979958

Epoch: 5| Step: 2
Training loss: 0.9942481501799236
Validation loss: 2.6918774997460506

Epoch: 5| Step: 3
Training loss: 1.0383228164515794
Validation loss: 2.6544272628687557

Epoch: 5| Step: 4
Training loss: 0.9137202869390485
Validation loss: 2.679494477187438

Epoch: 5| Step: 5
Training loss: 1.1084300032502763
Validation loss: 2.647601617978157

Epoch: 5| Step: 6
Training loss: 1.0795856477473862
Validation loss: 2.6661093081959804

Epoch: 5| Step: 7
Training loss: 1.1605264606047787
Validation loss: 2.658205199962076

Epoch: 5| Step: 8
Training loss: 0.98766177819963
Validation loss: 2.664829537190124

Epoch: 5| Step: 9
Training loss: 1.0970375788258482
Validation loss: 2.670304786484114

Epoch: 5| Step: 10
Training loss: 1.3017163280793753
Validation loss: 2.6661387684988997

Epoch: 269| Step: 0
Training loss: 0.7846062095279683
Validation loss: 2.6670951793786997

Epoch: 5| Step: 1
Training loss: 1.0459196941591375
Validation loss: 2.67286732593041

Epoch: 5| Step: 2
Training loss: 1.059676963958515
Validation loss: 2.6875325618544617

Epoch: 5| Step: 3
Training loss: 1.0011266679562951
Validation loss: 2.699374813816076

Epoch: 5| Step: 4
Training loss: 1.0081951982023236
Validation loss: 2.655210970511028

Epoch: 5| Step: 5
Training loss: 1.1528737546551524
Validation loss: 2.6792744997794173

Epoch: 5| Step: 6
Training loss: 1.268129202514724
Validation loss: 2.683483956884622

Epoch: 5| Step: 7
Training loss: 0.7319275675723407
Validation loss: 2.697427793157916

Epoch: 5| Step: 8
Training loss: 0.9295458325069225
Validation loss: 2.683054445413407

Epoch: 5| Step: 9
Training loss: 1.3711477415751683
Validation loss: 2.685971267175731

Epoch: 5| Step: 10
Training loss: 1.219550627823906
Validation loss: 2.6683082965660243

Epoch: 270| Step: 0
Training loss: 1.0741883984526077
Validation loss: 2.655664934247934

Epoch: 5| Step: 1
Training loss: 1.1414084683187182
Validation loss: 2.6331509744754187

Epoch: 5| Step: 2
Training loss: 0.8575542234843347
Validation loss: 2.6298588632161697

Epoch: 5| Step: 3
Training loss: 1.2065325944578777
Validation loss: 2.6494091837276827

Epoch: 5| Step: 4
Training loss: 1.0314129787318624
Validation loss: 2.647484938650636

Epoch: 5| Step: 5
Training loss: 0.8483819623722998
Validation loss: 2.6159903396138815

Epoch: 5| Step: 6
Training loss: 1.1284178631071455
Validation loss: 2.6386093822423553

Epoch: 5| Step: 7
Training loss: 1.0729534673706498
Validation loss: 2.637784558927143

Epoch: 5| Step: 8
Training loss: 1.2179919599728115
Validation loss: 2.6450230432640196

Epoch: 5| Step: 9
Training loss: 0.6547408007135368
Validation loss: 2.696822218396931

Epoch: 5| Step: 10
Training loss: 1.3609562151001997
Validation loss: 2.65711264551845

Epoch: 271| Step: 0
Training loss: 1.2317775486876634
Validation loss: 2.668351173633568

Epoch: 5| Step: 1
Training loss: 0.7187854509318361
Validation loss: 2.668005145611467

Epoch: 5| Step: 2
Training loss: 1.20178440262349
Validation loss: 2.634998286540265

Epoch: 5| Step: 3
Training loss: 0.7569966988409671
Validation loss: 2.635134050036615

Epoch: 5| Step: 4
Training loss: 1.2140243072590116
Validation loss: 2.608997936439628

Epoch: 5| Step: 5
Training loss: 1.1107905852746127
Validation loss: 2.6439442678625005

Epoch: 5| Step: 6
Training loss: 1.3984911178454102
Validation loss: 2.63233961959322

Epoch: 5| Step: 7
Training loss: 0.9010273963518496
Validation loss: 2.608470330337329

Epoch: 5| Step: 8
Training loss: 1.0049529797196726
Validation loss: 2.6411898128401514

Epoch: 5| Step: 9
Training loss: 0.927352312622132
Validation loss: 2.6578025763525344

Epoch: 5| Step: 10
Training loss: 0.9801106805970425
Validation loss: 2.638982384375979

Epoch: 272| Step: 0
Training loss: 1.0353600067559992
Validation loss: 2.665085630207256

Epoch: 5| Step: 1
Training loss: 0.9745325581889067
Validation loss: 2.7147315132487555

Epoch: 5| Step: 2
Training loss: 0.8274230140992994
Validation loss: 2.699739071973752

Epoch: 5| Step: 3
Training loss: 0.9770800935465139
Validation loss: 2.6584888748994326

Epoch: 5| Step: 4
Training loss: 1.062190122856455
Validation loss: 2.6788252107411363

Epoch: 5| Step: 5
Training loss: 1.423950357514792
Validation loss: 2.6677921314598243

Epoch: 5| Step: 6
Training loss: 1.2865964478189753
Validation loss: 2.6741450209521562

Epoch: 5| Step: 7
Training loss: 1.0013341348757459
Validation loss: 2.6923232056722846

Epoch: 5| Step: 8
Training loss: 1.0489801335776403
Validation loss: 2.7175698609721213

Epoch: 5| Step: 9
Training loss: 1.0715239414276343
Validation loss: 2.722709116302787

Epoch: 5| Step: 10
Training loss: 0.8602162838253782
Validation loss: 2.708276973040125

Epoch: 273| Step: 0
Training loss: 1.1496067452797607
Validation loss: 2.7067046146934275

Epoch: 5| Step: 1
Training loss: 0.768756069376487
Validation loss: 2.686953099535267

Epoch: 5| Step: 2
Training loss: 1.2224681087928986
Validation loss: 2.635325601983921

Epoch: 5| Step: 3
Training loss: 0.9997043172477691
Validation loss: 2.6200855845134408

Epoch: 5| Step: 4
Training loss: 0.9150610140484937
Validation loss: 2.642988704887494

Epoch: 5| Step: 5
Training loss: 1.2281695971751434
Validation loss: 2.5982506295829952

Epoch: 5| Step: 6
Training loss: 0.9613462369685957
Validation loss: 2.643943969217264

Epoch: 5| Step: 7
Training loss: 1.1176371169829111
Validation loss: 2.606214986370058

Epoch: 5| Step: 8
Training loss: 0.8877811201566063
Validation loss: 2.673817905234002

Epoch: 5| Step: 9
Training loss: 1.4578285796984654
Validation loss: 2.6629677224151136

Epoch: 5| Step: 10
Training loss: 0.6632767235699198
Validation loss: 2.667493709885823

Epoch: 274| Step: 0
Training loss: 0.9817893872249089
Validation loss: 2.7153501260134854

Epoch: 5| Step: 1
Training loss: 0.7771031376323846
Validation loss: 2.6969296700146064

Epoch: 5| Step: 2
Training loss: 1.2131564575393234
Validation loss: 2.704317322035158

Epoch: 5| Step: 3
Training loss: 1.2998647582792158
Validation loss: 2.6941927359651316

Epoch: 5| Step: 4
Training loss: 1.013659820778972
Validation loss: 2.6889959389641622

Epoch: 5| Step: 5
Training loss: 1.026278563646735
Validation loss: 2.7311566076007434

Epoch: 5| Step: 6
Training loss: 1.1121236571777304
Validation loss: 2.70118144745034

Epoch: 5| Step: 7
Training loss: 0.9874753417787366
Validation loss: 2.691710015090142

Epoch: 5| Step: 8
Training loss: 0.9159953881734832
Validation loss: 2.6663513195818807

Epoch: 5| Step: 9
Training loss: 0.9671917657958388
Validation loss: 2.6769827151112393

Epoch: 5| Step: 10
Training loss: 1.3684315280474744
Validation loss: 2.6595839316833114

Epoch: 275| Step: 0
Training loss: 0.7728174594915916
Validation loss: 2.6765024071914256

Epoch: 5| Step: 1
Training loss: 1.1061661208944933
Validation loss: 2.6400239147108056

Epoch: 5| Step: 2
Training loss: 1.4747106656281783
Validation loss: 2.656526736200842

Epoch: 5| Step: 3
Training loss: 1.015938402384953
Validation loss: 2.6586481347400834

Epoch: 5| Step: 4
Training loss: 1.1605211705122105
Validation loss: 2.6429826978075286

Epoch: 5| Step: 5
Training loss: 0.5687099044416263
Validation loss: 2.6870097385434892

Epoch: 5| Step: 6
Training loss: 1.1974908265337854
Validation loss: 2.6936007197351497

Epoch: 5| Step: 7
Training loss: 1.040527515599323
Validation loss: 2.6954784093166166

Epoch: 5| Step: 8
Training loss: 0.8878615489114282
Validation loss: 2.713870346390507

Epoch: 5| Step: 9
Training loss: 0.6821590954838622
Validation loss: 2.7288144183417664

Epoch: 5| Step: 10
Training loss: 1.2953408140394158
Validation loss: 2.705589912322019

Epoch: 276| Step: 0
Training loss: 1.0828196273503086
Validation loss: 2.700552449398438

Epoch: 5| Step: 1
Training loss: 1.1952929027671237
Validation loss: 2.714466093314106

Epoch: 5| Step: 2
Training loss: 0.9505105039827861
Validation loss: 2.6640715639352748

Epoch: 5| Step: 3
Training loss: 0.7798790919909925
Validation loss: 2.6959551073265478

Epoch: 5| Step: 4
Training loss: 1.2223544494792593
Validation loss: 2.6490453812045796

Epoch: 5| Step: 5
Training loss: 1.0703733106727014
Validation loss: 2.680446536747756

Epoch: 5| Step: 6
Training loss: 1.144758703134997
Validation loss: 2.679693494637156

Epoch: 5| Step: 7
Training loss: 1.2210295462005423
Validation loss: 2.7010259806221564

Epoch: 5| Step: 8
Training loss: 0.6873351896585002
Validation loss: 2.690152135752339

Epoch: 5| Step: 9
Training loss: 0.9057275318367177
Validation loss: 2.7214545582579017

Epoch: 5| Step: 10
Training loss: 0.8810794665319919
Validation loss: 2.725679598235904

Epoch: 277| Step: 0
Training loss: 0.9679398994980123
Validation loss: 2.7067820199254777

Epoch: 5| Step: 1
Training loss: 1.0130899335474617
Validation loss: 2.7706405093905717

Epoch: 5| Step: 2
Training loss: 0.7863297304685665
Validation loss: 2.695541813889232

Epoch: 5| Step: 3
Training loss: 1.0591181058178678
Validation loss: 2.689345056271986

Epoch: 5| Step: 4
Training loss: 1.1227542927298304
Validation loss: 2.7041191479399047

Epoch: 5| Step: 5
Training loss: 1.004664390855864
Validation loss: 2.647799796825519

Epoch: 5| Step: 6
Training loss: 1.4723360639418284
Validation loss: 2.703063296466716

Epoch: 5| Step: 7
Training loss: 1.2770784435002285
Validation loss: 2.6706768348515983

Epoch: 5| Step: 8
Training loss: 0.7880949376761092
Validation loss: 2.6485980340319224

Epoch: 5| Step: 9
Training loss: 0.8730565012970766
Validation loss: 2.6709718888829297

Epoch: 5| Step: 10
Training loss: 0.812823744611387
Validation loss: 2.6537182859508537

Epoch: 278| Step: 0
Training loss: 0.8482037371502962
Validation loss: 2.685328877928159

Epoch: 5| Step: 1
Training loss: 0.8409043113938205
Validation loss: 2.7013558411929277

Epoch: 5| Step: 2
Training loss: 0.6910938915137832
Validation loss: 2.695962065207364

Epoch: 5| Step: 3
Training loss: 1.2302405251671271
Validation loss: 2.7008803242029433

Epoch: 5| Step: 4
Training loss: 1.0575270680419573
Validation loss: 2.6876556344742633

Epoch: 5| Step: 5
Training loss: 0.9803755210535585
Validation loss: 2.6985808870245678

Epoch: 5| Step: 6
Training loss: 0.8434130030972297
Validation loss: 2.665648372356151

Epoch: 5| Step: 7
Training loss: 1.1731045185754232
Validation loss: 2.6876790510983297

Epoch: 5| Step: 8
Training loss: 1.2454678389517568
Validation loss: 2.6868742805579244

Epoch: 5| Step: 9
Training loss: 1.134920355905496
Validation loss: 2.6437887854867927

Epoch: 5| Step: 10
Training loss: 1.1574587818329216
Validation loss: 2.6405882027325402

Epoch: 279| Step: 0
Training loss: 1.1156265985386613
Validation loss: 2.646265807660201

Epoch: 5| Step: 1
Training loss: 0.9929162000291384
Validation loss: 2.6073694841824757

Epoch: 5| Step: 2
Training loss: 1.3235197219618593
Validation loss: 2.6054141443588477

Epoch: 5| Step: 3
Training loss: 0.903264884279177
Validation loss: 2.574807864502931

Epoch: 5| Step: 4
Training loss: 1.055611438833505
Validation loss: 2.6047257333151137

Epoch: 5| Step: 5
Training loss: 0.8097694437366617
Validation loss: 2.6070207440359985

Epoch: 5| Step: 6
Training loss: 1.1250039736359674
Validation loss: 2.58357764136478

Epoch: 5| Step: 7
Training loss: 0.8230215118512269
Validation loss: 2.590635815396503

Epoch: 5| Step: 8
Training loss: 1.1247288059154879
Validation loss: 2.576026838843357

Epoch: 5| Step: 9
Training loss: 0.8515991063080591
Validation loss: 2.6021117791143076

Epoch: 5| Step: 10
Training loss: 1.0898949942624618
Validation loss: 2.586367950089963

Epoch: 280| Step: 0
Training loss: 0.6912989991189495
Validation loss: 2.638323975526638

Epoch: 5| Step: 1
Training loss: 0.9359956433508628
Validation loss: 2.647742771226888

Epoch: 5| Step: 2
Training loss: 0.9822034346489188
Validation loss: 2.65555929991561

Epoch: 5| Step: 3
Training loss: 1.2230581774656912
Validation loss: 2.66112768643305

Epoch: 5| Step: 4
Training loss: 1.041507740612814
Validation loss: 2.669100878707595

Epoch: 5| Step: 5
Training loss: 1.2303002620569927
Validation loss: 2.654840770892284

Epoch: 5| Step: 6
Training loss: 0.8729490016207674
Validation loss: 2.68792005701245

Epoch: 5| Step: 7
Training loss: 0.9155131509316558
Validation loss: 2.6371180729593755

Epoch: 5| Step: 8
Training loss: 0.9876599978952338
Validation loss: 2.6205550256147245

Epoch: 5| Step: 9
Training loss: 0.8896917841345567
Validation loss: 2.616720288344945

Epoch: 5| Step: 10
Training loss: 1.3358444270678556
Validation loss: 2.6304363878415082

Epoch: 281| Step: 0
Training loss: 0.9848699385078048
Validation loss: 2.5996211251150108

Epoch: 5| Step: 1
Training loss: 0.9938849399526819
Validation loss: 2.6268321473483436

Epoch: 5| Step: 2
Training loss: 1.0262096803204492
Validation loss: 2.5989298055180776

Epoch: 5| Step: 3
Training loss: 1.1705991793675417
Validation loss: 2.637523777803082

Epoch: 5| Step: 4
Training loss: 0.9873269038054353
Validation loss: 2.6456794671421258

Epoch: 5| Step: 5
Training loss: 1.069399088906506
Validation loss: 2.670043021738796

Epoch: 5| Step: 6
Training loss: 0.60113502771236
Validation loss: 2.6785147332199033

Epoch: 5| Step: 7
Training loss: 0.903137287465493
Validation loss: 2.702045488062075

Epoch: 5| Step: 8
Training loss: 1.1185137472625208
Validation loss: 2.688742791702778

Epoch: 5| Step: 9
Training loss: 1.2430282722382047
Validation loss: 2.6749995524026833

Epoch: 5| Step: 10
Training loss: 0.8406782750261735
Validation loss: 2.671569092845379

Epoch: 282| Step: 0
Training loss: 0.9377066702334635
Validation loss: 2.677571552189515

Epoch: 5| Step: 1
Training loss: 1.1026400983551021
Validation loss: 2.641334675699581

Epoch: 5| Step: 2
Training loss: 1.045876667497814
Validation loss: 2.6647373194383377

Epoch: 5| Step: 3
Training loss: 1.1061814777251933
Validation loss: 2.6579943850856798

Epoch: 5| Step: 4
Training loss: 0.7209905862630169
Validation loss: 2.644427325040291

Epoch: 5| Step: 5
Training loss: 1.0429194863789677
Validation loss: 2.667467005539719

Epoch: 5| Step: 6
Training loss: 0.882870900070736
Validation loss: 2.6902495901822365

Epoch: 5| Step: 7
Training loss: 1.1949170025529439
Validation loss: 2.67565212598386

Epoch: 5| Step: 8
Training loss: 1.2443348300337933
Validation loss: 2.6536408728174066

Epoch: 5| Step: 9
Training loss: 0.7480860767102437
Validation loss: 2.6910176561224755

Epoch: 5| Step: 10
Training loss: 0.785174279456689
Validation loss: 2.698676115778022

Epoch: 283| Step: 0
Training loss: 0.9033059608762805
Validation loss: 2.678628467864666

Epoch: 5| Step: 1
Training loss: 1.1139787597001067
Validation loss: 2.6720246879530607

Epoch: 5| Step: 2
Training loss: 1.086510267080151
Validation loss: 2.674532375954061

Epoch: 5| Step: 3
Training loss: 0.8492711588840491
Validation loss: 2.6425675011002685

Epoch: 5| Step: 4
Training loss: 0.8331682915969003
Validation loss: 2.645200962082544

Epoch: 5| Step: 5
Training loss: 0.9168907816334156
Validation loss: 2.676131246317769

Epoch: 5| Step: 6
Training loss: 0.7969787380536616
Validation loss: 2.6723482933357188

Epoch: 5| Step: 7
Training loss: 0.9791466663563511
Validation loss: 2.6785625970443867

Epoch: 5| Step: 8
Training loss: 1.1486109388526338
Validation loss: 2.66394110727139

Epoch: 5| Step: 9
Training loss: 1.1535351817136095
Validation loss: 2.6662346627133156

Epoch: 5| Step: 10
Training loss: 0.969219432426531
Validation loss: 2.6695750268721246

Epoch: 284| Step: 0
Training loss: 0.8770703277771378
Validation loss: 2.6229455959003114

Epoch: 5| Step: 1
Training loss: 0.8059833425712655
Validation loss: 2.6092012133958744

Epoch: 5| Step: 2
Training loss: 1.0934461989142603
Validation loss: 2.657550012523856

Epoch: 5| Step: 3
Training loss: 1.088523256185738
Validation loss: 2.66778918323394

Epoch: 5| Step: 4
Training loss: 0.9830144835362659
Validation loss: 2.6618862282926647

Epoch: 5| Step: 5
Training loss: 0.6144431703298295
Validation loss: 2.635802056991124

Epoch: 5| Step: 6
Training loss: 0.7095345708369886
Validation loss: 2.682024903516917

Epoch: 5| Step: 7
Training loss: 1.168464427881546
Validation loss: 2.675303428675316

Epoch: 5| Step: 8
Training loss: 0.7667173261767224
Validation loss: 2.698934717331052

Epoch: 5| Step: 9
Training loss: 1.3574438738241006
Validation loss: 2.7072044903928396

Epoch: 5| Step: 10
Training loss: 1.0969980241519517
Validation loss: 2.7078434519248513

Epoch: 285| Step: 0
Training loss: 0.5553339294265915
Validation loss: 2.710542861997007

Epoch: 5| Step: 1
Training loss: 1.222491999796958
Validation loss: 2.7029463916282257

Epoch: 5| Step: 2
Training loss: 0.7589004022515518
Validation loss: 2.670182210032607

Epoch: 5| Step: 3
Training loss: 0.9030505958188078
Validation loss: 2.6701681925429455

Epoch: 5| Step: 4
Training loss: 0.9788102488773514
Validation loss: 2.6586385566812316

Epoch: 5| Step: 5
Training loss: 0.8575432415616552
Validation loss: 2.669956563671775

Epoch: 5| Step: 6
Training loss: 0.9029260053153174
Validation loss: 2.6306560520709126

Epoch: 5| Step: 7
Training loss: 0.8401026836712482
Validation loss: 2.6530271214605774

Epoch: 5| Step: 8
Training loss: 0.9885520413292819
Validation loss: 2.637472196828136

Epoch: 5| Step: 9
Training loss: 1.378987037086003
Validation loss: 2.624886851159872

Epoch: 5| Step: 10
Training loss: 1.1605274878044234
Validation loss: 2.6094540662688677

Epoch: 286| Step: 0
Training loss: 1.1382353323718875
Validation loss: 2.647279328907098

Epoch: 5| Step: 1
Training loss: 1.0963152639172498
Validation loss: 2.594553102949518

Epoch: 5| Step: 2
Training loss: 0.935088616827895
Validation loss: 2.6440975009021206

Epoch: 5| Step: 3
Training loss: 0.6630397774945856
Validation loss: 2.684681638706333

Epoch: 5| Step: 4
Training loss: 0.9902601370385301
Validation loss: 2.6273437424281507

Epoch: 5| Step: 5
Training loss: 0.987737966185624
Validation loss: 2.665726271549265

Epoch: 5| Step: 6
Training loss: 0.681994043233313
Validation loss: 2.6546345121390678

Epoch: 5| Step: 7
Training loss: 1.1708512475667128
Validation loss: 2.6658711551090373

Epoch: 5| Step: 8
Training loss: 0.8695497385751664
Validation loss: 2.6832546290867403

Epoch: 5| Step: 9
Training loss: 0.8243713237689159
Validation loss: 2.660208851139398

Epoch: 5| Step: 10
Training loss: 1.2176667314291483
Validation loss: 2.681119718512307

Epoch: 287| Step: 0
Training loss: 0.5813910272210321
Validation loss: 2.6525570952804576

Epoch: 5| Step: 1
Training loss: 0.8990701852628439
Validation loss: 2.656628544451916

Epoch: 5| Step: 2
Training loss: 1.0846955586856382
Validation loss: 2.6982369219569993

Epoch: 5| Step: 3
Training loss: 1.1134483881184345
Validation loss: 2.644430157772298

Epoch: 5| Step: 4
Training loss: 1.1003156599212316
Validation loss: 2.6799315395834125

Epoch: 5| Step: 5
Training loss: 0.9973933101187215
Validation loss: 2.6429584093940894

Epoch: 5| Step: 6
Training loss: 0.9130852194390559
Validation loss: 2.6422191375095565

Epoch: 5| Step: 7
Training loss: 1.0872953419654616
Validation loss: 2.6187149128516456

Epoch: 5| Step: 8
Training loss: 0.7017777569360242
Validation loss: 2.5872423858671163

Epoch: 5| Step: 9
Training loss: 0.9206573073551118
Validation loss: 2.612946167905947

Epoch: 5| Step: 10
Training loss: 1.0288221505914457
Validation loss: 2.6618386723239915

Epoch: 288| Step: 0
Training loss: 0.9364263744791961
Validation loss: 2.640919386862602

Epoch: 5| Step: 1
Training loss: 0.9377451258313785
Validation loss: 2.632329134544161

Epoch: 5| Step: 2
Training loss: 0.8547575968951201
Validation loss: 2.6986416889237983

Epoch: 5| Step: 3
Training loss: 0.8099086592824946
Validation loss: 2.6710822495664317

Epoch: 5| Step: 4
Training loss: 0.810834571612655
Validation loss: 2.6606640934733825

Epoch: 5| Step: 5
Training loss: 0.7259060755417486
Validation loss: 2.681030199181449

Epoch: 5| Step: 6
Training loss: 1.2052921741879399
Validation loss: 2.648365080381714

Epoch: 5| Step: 7
Training loss: 0.9890921662086452
Validation loss: 2.6172103133942164

Epoch: 5| Step: 8
Training loss: 1.0030961386073018
Validation loss: 2.5898272585074253

Epoch: 5| Step: 9
Training loss: 1.210996466400762
Validation loss: 2.591591850567

Epoch: 5| Step: 10
Training loss: 1.2319875396154132
Validation loss: 2.60658744391566

Epoch: 289| Step: 0
Training loss: 1.0457389702850222
Validation loss: 2.600368352935051

Epoch: 5| Step: 1
Training loss: 1.2205938427645582
Validation loss: 2.617534106975422

Epoch: 5| Step: 2
Training loss: 0.8640377475718137
Validation loss: 2.66209744904495

Epoch: 5| Step: 3
Training loss: 0.680366746722401
Validation loss: 2.689808749794126

Epoch: 5| Step: 4
Training loss: 0.5422364105677983
Validation loss: 2.652901205192214

Epoch: 5| Step: 5
Training loss: 0.7687055156211635
Validation loss: 2.678361245741103

Epoch: 5| Step: 6
Training loss: 0.8647203145419864
Validation loss: 2.6562013741083343

Epoch: 5| Step: 7
Training loss: 1.1576183058422924
Validation loss: 2.640759361689911

Epoch: 5| Step: 8
Training loss: 0.7054918929620355
Validation loss: 2.654778279720438

Epoch: 5| Step: 9
Training loss: 1.1449472237796743
Validation loss: 2.5976884317945115

Epoch: 5| Step: 10
Training loss: 1.2532576550216241
Validation loss: 2.6126639957868627

Epoch: 290| Step: 0
Training loss: 0.9161348245005195
Validation loss: 2.621501568053366

Epoch: 5| Step: 1
Training loss: 0.5688287952881772
Validation loss: 2.627410185542887

Epoch: 5| Step: 2
Training loss: 1.0295555759600734
Validation loss: 2.6587813216757

Epoch: 5| Step: 3
Training loss: 0.9779040467908492
Validation loss: 2.677612580518622

Epoch: 5| Step: 4
Training loss: 1.0137975831629682
Validation loss: 2.7147414973081907

Epoch: 5| Step: 5
Training loss: 0.7702582551067461
Validation loss: 2.6943665806198265

Epoch: 5| Step: 6
Training loss: 0.838265821842878
Validation loss: 2.7000306444088773

Epoch: 5| Step: 7
Training loss: 1.1825424410117407
Validation loss: 2.6662034457895825

Epoch: 5| Step: 8
Training loss: 0.9189832884251784
Validation loss: 2.6399271023910216

Epoch: 5| Step: 9
Training loss: 1.0364386334615772
Validation loss: 2.6842640298833054

Epoch: 5| Step: 10
Training loss: 1.075941888565921
Validation loss: 2.6409595789902744

Epoch: 291| Step: 0
Training loss: 0.7375096320476965
Validation loss: 2.632884494443094

Epoch: 5| Step: 1
Training loss: 1.1948800395464623
Validation loss: 2.6079323941446053

Epoch: 5| Step: 2
Training loss: 1.015347545578997
Validation loss: 2.637486754532244

Epoch: 5| Step: 3
Training loss: 1.038379530779578
Validation loss: 2.6342471062149473

Epoch: 5| Step: 4
Training loss: 0.881666874864502
Validation loss: 2.656144881174152

Epoch: 5| Step: 5
Training loss: 1.1713974043059414
Validation loss: 2.651385309316102

Epoch: 5| Step: 6
Training loss: 0.7800381989784472
Validation loss: 2.6816695819955316

Epoch: 5| Step: 7
Training loss: 0.7512496630244205
Validation loss: 2.6942940848225936

Epoch: 5| Step: 8
Training loss: 0.5608321205124157
Validation loss: 2.674903658049228

Epoch: 5| Step: 9
Training loss: 0.838131245384302
Validation loss: 2.728168127966995

Epoch: 5| Step: 10
Training loss: 1.1777037558046854
Validation loss: 2.6834184130453806

Epoch: 292| Step: 0
Training loss: 1.091904636585695
Validation loss: 2.698190073183702

Epoch: 5| Step: 1
Training loss: 0.9844225614653203
Validation loss: 2.70843483961036

Epoch: 5| Step: 2
Training loss: 0.7503213988526736
Validation loss: 2.6771500610549364

Epoch: 5| Step: 3
Training loss: 0.80844675100819
Validation loss: 2.696774795581911

Epoch: 5| Step: 4
Training loss: 1.0504181528793366
Validation loss: 2.677475943364566

Epoch: 5| Step: 5
Training loss: 0.8799356832083834
Validation loss: 2.6459968489882995

Epoch: 5| Step: 6
Training loss: 0.5813265893580339
Validation loss: 2.7083110530747723

Epoch: 5| Step: 7
Training loss: 0.9721994208129526
Validation loss: 2.6881511182791007

Epoch: 5| Step: 8
Training loss: 0.7510911236553012
Validation loss: 2.6734066075317244

Epoch: 5| Step: 9
Training loss: 0.8206803723122268
Validation loss: 2.670193742723034

Epoch: 5| Step: 10
Training loss: 1.3623837027656347
Validation loss: 2.665329989114161

Epoch: 293| Step: 0
Training loss: 0.28217225393718404
Validation loss: 2.644850110167895

Epoch: 5| Step: 1
Training loss: 0.8981435875505569
Validation loss: 2.6337182501473926

Epoch: 5| Step: 2
Training loss: 0.9343995642861892
Validation loss: 2.6698562257887626

Epoch: 5| Step: 3
Training loss: 0.9119691924822922
Validation loss: 2.6149190662561703

Epoch: 5| Step: 4
Training loss: 0.9439641305384409
Validation loss: 2.668045874245887

Epoch: 5| Step: 5
Training loss: 0.9031841773474303
Validation loss: 2.675588194503486

Epoch: 5| Step: 6
Training loss: 0.9787567207134914
Validation loss: 2.644842336408606

Epoch: 5| Step: 7
Training loss: 1.3061802256807955
Validation loss: 2.6588886394501503

Epoch: 5| Step: 8
Training loss: 0.5416195249828812
Validation loss: 2.6246263860257684

Epoch: 5| Step: 9
Training loss: 0.8203473401618302
Validation loss: 2.655560784679364

Epoch: 5| Step: 10
Training loss: 1.215551041655341
Validation loss: 2.656056180248988

Epoch: 294| Step: 0
Training loss: 0.7541239923097064
Validation loss: 2.6641805452623375

Epoch: 5| Step: 1
Training loss: 0.7595584067061183
Validation loss: 2.6665218045383186

Epoch: 5| Step: 2
Training loss: 0.8428611311922085
Validation loss: 2.6575787699422033

Epoch: 5| Step: 3
Training loss: 1.1427897461109033
Validation loss: 2.6904462026623643

Epoch: 5| Step: 4
Training loss: 1.0589770084295147
Validation loss: 2.6663640629932743

Epoch: 5| Step: 5
Training loss: 1.1627416093023641
Validation loss: 2.7259297742577315

Epoch: 5| Step: 6
Training loss: 0.9868034199610942
Validation loss: 2.685628656807064

Epoch: 5| Step: 7
Training loss: 0.7456641433302512
Validation loss: 2.647123922331309

Epoch: 5| Step: 8
Training loss: 0.6713546911750049
Validation loss: 2.6659792820417385

Epoch: 5| Step: 9
Training loss: 0.8520003426824247
Validation loss: 2.689698020864071

Epoch: 5| Step: 10
Training loss: 0.8806231873536254
Validation loss: 2.67317201808412

Epoch: 295| Step: 0
Training loss: 1.2773141186744934
Validation loss: 2.6689356916693425

Epoch: 5| Step: 1
Training loss: 0.7978286272952352
Validation loss: 2.6511651182491014

Epoch: 5| Step: 2
Training loss: 1.0224110355241298
Validation loss: 2.703944354071738

Epoch: 5| Step: 3
Training loss: 0.566657543342674
Validation loss: 2.720192308490656

Epoch: 5| Step: 4
Training loss: 0.8062683059033627
Validation loss: 2.71303875678637

Epoch: 5| Step: 5
Training loss: 0.8285642934242988
Validation loss: 2.7138222409263077

Epoch: 5| Step: 6
Training loss: 1.0291029224397625
Validation loss: 2.6910152287287827

Epoch: 5| Step: 7
Training loss: 0.8507282475266891
Validation loss: 2.6806724056439295

Epoch: 5| Step: 8
Training loss: 0.9114384603604518
Validation loss: 2.6823638348777425

Epoch: 5| Step: 9
Training loss: 0.8037330744905673
Validation loss: 2.6889379259900545

Epoch: 5| Step: 10
Training loss: 0.7525510318219063
Validation loss: 2.694584749407274

Epoch: 296| Step: 0
Training loss: 0.7849695923255257
Validation loss: 2.6557342395325727

Epoch: 5| Step: 1
Training loss: 1.134046474416088
Validation loss: 2.712219007256471

Epoch: 5| Step: 2
Training loss: 0.6983549653855152
Validation loss: 2.6799463152907435

Epoch: 5| Step: 3
Training loss: 0.7245638028438072
Validation loss: 2.671418204746077

Epoch: 5| Step: 4
Training loss: 0.781767788007897
Validation loss: 2.6890207000904485

Epoch: 5| Step: 5
Training loss: 0.9343868063496563
Validation loss: 2.67359219415524

Epoch: 5| Step: 6
Training loss: 0.9406600464029844
Validation loss: 2.657596005336775

Epoch: 5| Step: 7
Training loss: 0.6645107103048667
Validation loss: 2.6415681173566736

Epoch: 5| Step: 8
Training loss: 0.9397983035850598
Validation loss: 2.6484454258272527

Epoch: 5| Step: 9
Training loss: 1.0114311486993393
Validation loss: 2.621053620028746

Epoch: 5| Step: 10
Training loss: 1.0946992297337712
Validation loss: 2.6562484924582366

Epoch: 297| Step: 0
Training loss: 0.8774826048623927
Validation loss: 2.671905081799765

Epoch: 5| Step: 1
Training loss: 0.8088928627702833
Validation loss: 2.6874100655047664

Epoch: 5| Step: 2
Training loss: 0.8143323264428731
Validation loss: 2.6835008529817364

Epoch: 5| Step: 3
Training loss: 0.675286437118177
Validation loss: 2.6683058744542376

Epoch: 5| Step: 4
Training loss: 1.0208372907496965
Validation loss: 2.6697640818005346

Epoch: 5| Step: 5
Training loss: 1.0429723503822161
Validation loss: 2.654476521974692

Epoch: 5| Step: 6
Training loss: 0.8534031494893367
Validation loss: 2.631579739803115

Epoch: 5| Step: 7
Training loss: 1.0071831445839474
Validation loss: 2.6660481422674276

Epoch: 5| Step: 8
Training loss: 0.9276689365798734
Validation loss: 2.6793378381009108

Epoch: 5| Step: 9
Training loss: 0.9136302610708541
Validation loss: 2.662600370960227

Epoch: 5| Step: 10
Training loss: 0.7431047493603316
Validation loss: 2.700644043175609

Epoch: 298| Step: 0
Training loss: 1.0619647416873006
Validation loss: 2.671500023703896

Epoch: 5| Step: 1
Training loss: 0.6531724976421048
Validation loss: 2.6868844888282752

Epoch: 5| Step: 2
Training loss: 0.7501855461758118
Validation loss: 2.651024151090708

Epoch: 5| Step: 3
Training loss: 0.8544212093847022
Validation loss: 2.6491377968187253

Epoch: 5| Step: 4
Training loss: 1.0455083894434063
Validation loss: 2.6453247963948363

Epoch: 5| Step: 5
Training loss: 1.1119304291930947
Validation loss: 2.606826084535664

Epoch: 5| Step: 6
Training loss: 0.4976409604345335
Validation loss: 2.5895935441581437

Epoch: 5| Step: 7
Training loss: 0.7148718489664012
Validation loss: 2.6055865965189016

Epoch: 5| Step: 8
Training loss: 0.8675179753928444
Validation loss: 2.6279001861430986

Epoch: 5| Step: 9
Training loss: 1.1316582949295468
Validation loss: 2.6549405049663037

Epoch: 5| Step: 10
Training loss: 0.8965246985182579
Validation loss: 2.628538762229381

Epoch: 299| Step: 0
Training loss: 0.7763471876723276
Validation loss: 2.6425377394501495

Epoch: 5| Step: 1
Training loss: 0.9887895746907531
Validation loss: 2.6865753907043692

Epoch: 5| Step: 2
Training loss: 0.5500727215287373
Validation loss: 2.68240556499985

Epoch: 5| Step: 3
Training loss: 0.9715544500106413
Validation loss: 2.7152311258663957

Epoch: 5| Step: 4
Training loss: 1.0540389150677663
Validation loss: 2.6777556673065055

Epoch: 5| Step: 5
Training loss: 0.5788229518169564
Validation loss: 2.6922439349595715

Epoch: 5| Step: 6
Training loss: 0.9536264695028588
Validation loss: 2.7077762680839683

Epoch: 5| Step: 7
Training loss: 0.8753829186307551
Validation loss: 2.6719164429833766

Epoch: 5| Step: 8
Training loss: 0.7845160688015219
Validation loss: 2.7086135943272147

Epoch: 5| Step: 9
Training loss: 0.9759127171741363
Validation loss: 2.637364549749821

Epoch: 5| Step: 10
Training loss: 1.0293652043111015
Validation loss: 2.675452726463379

Epoch: 300| Step: 0
Training loss: 0.8758025235698343
Validation loss: 2.6940658361339764

Epoch: 5| Step: 1
Training loss: 0.9097745692663926
Validation loss: 2.691037838272927

Epoch: 5| Step: 2
Training loss: 0.5493353403854896
Validation loss: 2.712072099248599

Epoch: 5| Step: 3
Training loss: 1.0311742812593265
Validation loss: 2.6657149234134074

Epoch: 5| Step: 4
Training loss: 0.6434186406681073
Validation loss: 2.6822172252353957

Epoch: 5| Step: 5
Training loss: 0.765191325154364
Validation loss: 2.67657493327561

Epoch: 5| Step: 6
Training loss: 0.9473884424246708
Validation loss: 2.64301697086235

Epoch: 5| Step: 7
Training loss: 0.9186211073893266
Validation loss: 2.65660250385932

Epoch: 5| Step: 8
Training loss: 0.7815300248883218
Validation loss: 2.6593229572701627

Epoch: 5| Step: 9
Training loss: 0.8347118340718767
Validation loss: 2.674846390829693

Epoch: 5| Step: 10
Training loss: 1.2344113598067832
Validation loss: 2.6330230454407126

Testing loss: 2.4795808579689953
