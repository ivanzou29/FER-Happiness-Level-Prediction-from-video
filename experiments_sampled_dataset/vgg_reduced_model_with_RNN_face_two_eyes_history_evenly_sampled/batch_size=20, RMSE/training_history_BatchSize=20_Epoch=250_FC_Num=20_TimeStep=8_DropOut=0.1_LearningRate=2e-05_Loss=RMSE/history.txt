Epoch: 1| Step: 0
Training loss: 5.518981431059263
Validation loss: 5.807469296002374

Epoch: 5| Step: 1
Training loss: 5.177891668796197
Validation loss: 5.787893537435107

Epoch: 5| Step: 2
Training loss: 6.420751023141442
Validation loss: 5.768915786790008

Epoch: 5| Step: 3
Training loss: 5.332593548647611
Validation loss: 5.747596447027068

Epoch: 5| Step: 4
Training loss: 5.6356344786157395
Validation loss: 5.7226286901493335

Epoch: 5| Step: 5
Training loss: 5.118279866111446
Validation loss: 5.694317092625292

Epoch: 5| Step: 6
Training loss: 5.44786574544747
Validation loss: 5.660989252889325

Epoch: 5| Step: 7
Training loss: 6.602377792666052
Validation loss: 5.6245093492841125

Epoch: 5| Step: 8
Training loss: 5.558795166655629
Validation loss: 5.583646804367729

Epoch: 5| Step: 9
Training loss: 5.892914425790306
Validation loss: 5.537836236777241

Epoch: 5| Step: 10
Training loss: 5.939966271815248
Validation loss: 5.487265681261128

Epoch: 2| Step: 0
Training loss: 5.799337599187986
Validation loss: 5.434142674910988

Epoch: 5| Step: 1
Training loss: 5.145647279822503
Validation loss: 5.377372775057642

Epoch: 5| Step: 2
Training loss: 5.738954300747171
Validation loss: 5.317864528536039

Epoch: 5| Step: 3
Training loss: 4.93592249139555
Validation loss: 5.256524956838957

Epoch: 5| Step: 4
Training loss: 5.935193708130118
Validation loss: 5.194596468650299

Epoch: 5| Step: 5
Training loss: 5.343508352426444
Validation loss: 5.1313224569233595

Epoch: 5| Step: 6
Training loss: 4.240131364622777
Validation loss: 5.06793155875585

Epoch: 5| Step: 7
Training loss: 5.385527835291288
Validation loss: 5.007414994470669

Epoch: 5| Step: 8
Training loss: 5.128139743632637
Validation loss: 4.947021818302371

Epoch: 5| Step: 9
Training loss: 4.545276898467269
Validation loss: 4.887469844967947

Epoch: 5| Step: 10
Training loss: 4.692821279754931
Validation loss: 4.832989381653036

Epoch: 3| Step: 0
Training loss: 4.544638172011272
Validation loss: 4.780955137784795

Epoch: 5| Step: 1
Training loss: 4.097148620174266
Validation loss: 4.7321650241051465

Epoch: 5| Step: 2
Training loss: 4.8431917914868885
Validation loss: 4.690082244057473

Epoch: 5| Step: 3
Training loss: 4.631353808023392
Validation loss: 4.648253547087457

Epoch: 5| Step: 4
Training loss: 4.720101876533335
Validation loss: 4.6078355802341875

Epoch: 5| Step: 5
Training loss: 4.857987675003744
Validation loss: 4.5691843911461945

Epoch: 5| Step: 6
Training loss: 5.08577604960476
Validation loss: 4.529691656348094

Epoch: 5| Step: 7
Training loss: 4.431004888429832
Validation loss: 4.48993630862384

Epoch: 5| Step: 8
Training loss: 4.79781469031603
Validation loss: 4.453030891337965

Epoch: 5| Step: 9
Training loss: 4.499443231683405
Validation loss: 4.412686943884505

Epoch: 5| Step: 10
Training loss: 4.796493465397262
Validation loss: 4.37023796937111

Epoch: 4| Step: 0
Training loss: 3.9171196425365045
Validation loss: 4.328078663641146

Epoch: 5| Step: 1
Training loss: 3.516911928082319
Validation loss: 4.286445828281022

Epoch: 5| Step: 2
Training loss: 4.075304013010798
Validation loss: 4.273774734397326

Epoch: 5| Step: 3
Training loss: 5.042099905184092
Validation loss: 4.265748883533576

Epoch: 5| Step: 4
Training loss: 4.846666602371265
Validation loss: 4.247488188025433

Epoch: 5| Step: 5
Training loss: 4.3412468373479065
Validation loss: 4.223334297586493

Epoch: 5| Step: 6
Training loss: 4.309561792741691
Validation loss: 4.200935711860463

Epoch: 5| Step: 7
Training loss: 4.612647185006103
Validation loss: 4.190693469734375

Epoch: 5| Step: 8
Training loss: 4.106867384113269
Validation loss: 4.176243673894252

Epoch: 5| Step: 9
Training loss: 4.678459299255998
Validation loss: 4.15439661043981

Epoch: 5| Step: 10
Training loss: 4.256915356673402
Validation loss: 4.127005626783871

Epoch: 5| Step: 0
Training loss: 3.032864799225455
Validation loss: 4.105428353186373

Epoch: 5| Step: 1
Training loss: 3.3375224652052173
Validation loss: 4.08857576779133

Epoch: 5| Step: 2
Training loss: 4.878267220397874
Validation loss: 4.067851149545676

Epoch: 5| Step: 3
Training loss: 3.4464829029061517
Validation loss: 4.052987984862672

Epoch: 5| Step: 4
Training loss: 4.715027610398617
Validation loss: 4.0320760776101014

Epoch: 5| Step: 5
Training loss: 3.8785553895477682
Validation loss: 4.015476359878728

Epoch: 5| Step: 6
Training loss: 4.658495879820512
Validation loss: 3.9985117886921837

Epoch: 5| Step: 7
Training loss: 4.342882248081696
Validation loss: 3.977543102407865

Epoch: 5| Step: 8
Training loss: 4.34038891188014
Validation loss: 3.9595013905504057

Epoch: 5| Step: 9
Training loss: 4.376833940046746
Validation loss: 3.938140471977015

Epoch: 5| Step: 10
Training loss: 4.31509387748503
Validation loss: 3.9236591972250086

Epoch: 6| Step: 0
Training loss: 4.598304411154356
Validation loss: 3.9059899041327366

Epoch: 5| Step: 1
Training loss: 3.8140993359516524
Validation loss: 3.8863256751942346

Epoch: 5| Step: 2
Training loss: 4.218582941209092
Validation loss: 3.8637544865165365

Epoch: 5| Step: 3
Training loss: 3.943722606630298
Validation loss: 3.84703799591565

Epoch: 5| Step: 4
Training loss: 3.4912788181775003
Validation loss: 3.8234047432986107

Epoch: 5| Step: 5
Training loss: 4.0386204726695505
Validation loss: 3.8052790507176018

Epoch: 5| Step: 6
Training loss: 3.5255924241066166
Validation loss: 3.791481310129308

Epoch: 5| Step: 7
Training loss: 3.9594621487655774
Validation loss: 3.7773643739368494

Epoch: 5| Step: 8
Training loss: 4.298204029194858
Validation loss: 3.7650636610215003

Epoch: 5| Step: 9
Training loss: 3.6844565553188744
Validation loss: 3.7552917852591765

Epoch: 5| Step: 10
Training loss: 4.202929637580452
Validation loss: 3.7396504166515765

Epoch: 7| Step: 0
Training loss: 3.630324301196844
Validation loss: 3.7285271638950723

Epoch: 5| Step: 1
Training loss: 3.366474120296265
Validation loss: 3.7201365072089

Epoch: 5| Step: 2
Training loss: 3.741733850047307
Validation loss: 3.710738013647706

Epoch: 5| Step: 3
Training loss: 4.879011606586128
Validation loss: 3.7005074816234576

Epoch: 5| Step: 4
Training loss: 3.6008803244940153
Validation loss: 3.681895754637441

Epoch: 5| Step: 5
Training loss: 3.4614298795314467
Validation loss: 3.6730725878764843

Epoch: 5| Step: 6
Training loss: 3.6212420222306787
Validation loss: 3.6625913241334986

Epoch: 5| Step: 7
Training loss: 4.245913616665505
Validation loss: 3.6504383988123443

Epoch: 5| Step: 8
Training loss: 4.600169983086605
Validation loss: 3.6385168811031914

Epoch: 5| Step: 9
Training loss: 4.143746980461758
Validation loss: 3.63005654262538

Epoch: 5| Step: 10
Training loss: 2.4714434453168574
Validation loss: 3.616156169402439

Epoch: 8| Step: 0
Training loss: 3.159597000789414
Validation loss: 3.6048449598164

Epoch: 5| Step: 1
Training loss: 3.5099070525293143
Validation loss: 3.6014791172070075

Epoch: 5| Step: 2
Training loss: 3.772687564987683
Validation loss: 3.589462499085906

Epoch: 5| Step: 3
Training loss: 3.048369838133809
Validation loss: 3.576588040992974

Epoch: 5| Step: 4
Training loss: 3.977988716182365
Validation loss: 3.5638497571014094

Epoch: 5| Step: 5
Training loss: 3.904123200317433
Validation loss: 3.559454764340729

Epoch: 5| Step: 6
Training loss: 3.724194812157571
Validation loss: 3.543893355638783

Epoch: 5| Step: 7
Training loss: 4.153755988530845
Validation loss: 3.5355050697571366

Epoch: 5| Step: 8
Training loss: 4.2994623335984965
Validation loss: 3.5231882690266576

Epoch: 5| Step: 9
Training loss: 4.033194139669168
Validation loss: 3.512293807436884

Epoch: 5| Step: 10
Training loss: 3.536964990711672
Validation loss: 3.5053339100719136

Epoch: 9| Step: 0
Training loss: 3.044664882265418
Validation loss: 3.4999236129300555

Epoch: 5| Step: 1
Training loss: 3.817617140336101
Validation loss: 3.4922258099178896

Epoch: 5| Step: 2
Training loss: 4.04589431250544
Validation loss: 3.482553110315083

Epoch: 5| Step: 3
Training loss: 3.5204190945392124
Validation loss: 3.4786926535127027

Epoch: 5| Step: 4
Training loss: 3.37365611129098
Validation loss: 3.470948245285049

Epoch: 5| Step: 5
Training loss: 4.4249425162337035
Validation loss: 3.4620301529622917

Epoch: 5| Step: 6
Training loss: 4.463975610044292
Validation loss: 3.4538825392063757

Epoch: 5| Step: 7
Training loss: 3.3649428955946328
Validation loss: 3.4458203135308665

Epoch: 5| Step: 8
Training loss: 2.528181311660401
Validation loss: 3.437982539132929

Epoch: 5| Step: 9
Training loss: 3.6921200016808124
Validation loss: 3.4390424144839096

Epoch: 5| Step: 10
Training loss: 3.7685136913907726
Validation loss: 3.4366634092940815

Epoch: 10| Step: 0
Training loss: 3.330812613739578
Validation loss: 3.4244431482737934

Epoch: 5| Step: 1
Training loss: 3.655798468463025
Validation loss: 3.4422414318251247

Epoch: 5| Step: 2
Training loss: 3.512715267223346
Validation loss: 3.422982189266425

Epoch: 5| Step: 3
Training loss: 3.3672706257412663
Validation loss: 3.4098779091867755

Epoch: 5| Step: 4
Training loss: 2.907220657850067
Validation loss: 3.4167810856598733

Epoch: 5| Step: 5
Training loss: 3.7980191739900544
Validation loss: 3.424117495239705

Epoch: 5| Step: 6
Training loss: 4.69344634230703
Validation loss: 3.412091153550489

Epoch: 5| Step: 7
Training loss: 3.0921463326079413
Validation loss: 3.3958181751687224

Epoch: 5| Step: 8
Training loss: 3.532227237480928
Validation loss: 3.3886570000240015

Epoch: 5| Step: 9
Training loss: 4.15125955977426
Validation loss: 3.388348531171469

Epoch: 5| Step: 10
Training loss: 3.640145855590897
Validation loss: 3.382584145114785

Epoch: 11| Step: 0
Training loss: 3.9308859360904522
Validation loss: 3.3732942427922517

Epoch: 5| Step: 1
Training loss: 3.013516019695989
Validation loss: 3.3639649971280305

Epoch: 5| Step: 2
Training loss: 3.063079934776207
Validation loss: 3.3591985047077664

Epoch: 5| Step: 3
Training loss: 4.319384401046508
Validation loss: 3.3553121026600032

Epoch: 5| Step: 4
Training loss: 3.4759820003416615
Validation loss: 3.3513795256904433

Epoch: 5| Step: 5
Training loss: 3.4637079108168285
Validation loss: 3.3457957279375994

Epoch: 5| Step: 6
Training loss: 3.267269760694386
Validation loss: 3.350511360780893

Epoch: 5| Step: 7
Training loss: 3.1579449323379136
Validation loss: 3.3537748690499694

Epoch: 5| Step: 8
Training loss: 4.192833990579474
Validation loss: 3.3524507507767383

Epoch: 5| Step: 9
Training loss: 3.6182099250635824
Validation loss: 3.3360415721479937

Epoch: 5| Step: 10
Training loss: 3.7156137015489357
Validation loss: 3.3330269400976467

Epoch: 12| Step: 0
Training loss: 3.5087996625222577
Validation loss: 3.332544313897792

Epoch: 5| Step: 1
Training loss: 2.885660393034957
Validation loss: 3.3301274577772433

Epoch: 5| Step: 2
Training loss: 3.161338556692677
Validation loss: 3.32580646483741

Epoch: 5| Step: 3
Training loss: 3.707167467161099
Validation loss: 3.3246575806437026

Epoch: 5| Step: 4
Training loss: 4.270744409643359
Validation loss: 3.3183974621218977

Epoch: 5| Step: 5
Training loss: 3.3796194040578267
Validation loss: 3.3176393472601124

Epoch: 5| Step: 6
Training loss: 3.218643779298221
Validation loss: 3.3098906139747233

Epoch: 5| Step: 7
Training loss: 4.311526865974005
Validation loss: 3.307458303276434

Epoch: 5| Step: 8
Training loss: 3.2699026901745025
Validation loss: 3.303638746530935

Epoch: 5| Step: 9
Training loss: 3.4584955077848756
Validation loss: 3.3021628912176815

Epoch: 5| Step: 10
Training loss: 3.709231978553989
Validation loss: 3.300278768576287

Epoch: 13| Step: 0
Training loss: 4.112455308665552
Validation loss: 3.296017072735443

Epoch: 5| Step: 1
Training loss: 3.677163718464292
Validation loss: 3.292106685198144

Epoch: 5| Step: 2
Training loss: 3.903008787136952
Validation loss: 3.287943281824488

Epoch: 5| Step: 3
Training loss: 3.3930079089633853
Validation loss: 3.2859718682065426

Epoch: 5| Step: 4
Training loss: 3.572957267567618
Validation loss: 3.283278406022198

Epoch: 5| Step: 5
Training loss: 4.102777675271956
Validation loss: 3.2807895272842003

Epoch: 5| Step: 6
Training loss: 3.270464655675991
Validation loss: 3.27831398456433

Epoch: 5| Step: 7
Training loss: 2.8073372822430818
Validation loss: 3.2751487178707044

Epoch: 5| Step: 8
Training loss: 2.78277631732908
Validation loss: 3.2742288439464886

Epoch: 5| Step: 9
Training loss: 2.626603862702273
Validation loss: 3.270457389132061

Epoch: 5| Step: 10
Training loss: 4.2367047309115975
Validation loss: 3.26987580553274

Epoch: 14| Step: 0
Training loss: 2.902410288236694
Validation loss: 3.269166124256254

Epoch: 5| Step: 1
Training loss: 3.3224867938305223
Validation loss: 3.264830824649706

Epoch: 5| Step: 2
Training loss: 4.212203307980714
Validation loss: 3.2678248657857063

Epoch: 5| Step: 3
Training loss: 3.5980652484501294
Validation loss: 3.3006732217919033

Epoch: 5| Step: 4
Training loss: 3.7033070708636084
Validation loss: 3.2645753151900725

Epoch: 5| Step: 5
Training loss: 3.518202315914417
Validation loss: 3.2595271365135385

Epoch: 5| Step: 6
Training loss: 3.6438476968168767
Validation loss: 3.2602548148560246

Epoch: 5| Step: 7
Training loss: 3.1624751877847976
Validation loss: 3.2595876576588565

Epoch: 5| Step: 8
Training loss: 2.853278492938283
Validation loss: 3.2558251011803794

Epoch: 5| Step: 9
Training loss: 3.7075375049466373
Validation loss: 3.2553626890277076

Epoch: 5| Step: 10
Training loss: 3.849486993076257
Validation loss: 3.2535250488635823

Epoch: 15| Step: 0
Training loss: 4.011502892500885
Validation loss: 3.253544557853752

Epoch: 5| Step: 1
Training loss: 3.3477112310428145
Validation loss: 3.2522993008030086

Epoch: 5| Step: 2
Training loss: 3.390188865914379
Validation loss: 3.250048394864381

Epoch: 5| Step: 3
Training loss: 3.2967903885673264
Validation loss: 3.24878963684829

Epoch: 5| Step: 4
Training loss: 3.7148345080721
Validation loss: 3.2459942337572367

Epoch: 5| Step: 5
Training loss: 3.5480969714532113
Validation loss: 3.244951487215112

Epoch: 5| Step: 6
Training loss: 3.868347117410273
Validation loss: 3.2457889081897746

Epoch: 5| Step: 7
Training loss: 2.9744051426728655
Validation loss: 3.245834334494413

Epoch: 5| Step: 8
Training loss: 3.3991768569837184
Validation loss: 3.246712722030531

Epoch: 5| Step: 9
Training loss: 3.9371996568240366
Validation loss: 3.240054348192667

Epoch: 5| Step: 10
Training loss: 2.678420142488157
Validation loss: 3.239929002459724

Epoch: 16| Step: 0
Training loss: 3.498725931698795
Validation loss: 3.2411844389347064

Epoch: 5| Step: 1
Training loss: 3.444793454471505
Validation loss: 3.2565468460484976

Epoch: 5| Step: 2
Training loss: 3.443000554058419
Validation loss: 3.2368493808692986

Epoch: 5| Step: 3
Training loss: 3.603341083383004
Validation loss: 3.2350833199059315

Epoch: 5| Step: 4
Training loss: 3.3520625526127072
Validation loss: 3.2375095993332352

Epoch: 5| Step: 5
Training loss: 3.524114370354191
Validation loss: 3.237944400307798

Epoch: 5| Step: 6
Training loss: 3.4140988136298156
Validation loss: 3.237462008452062

Epoch: 5| Step: 7
Training loss: 4.216208815815988
Validation loss: 3.2417048142795166

Epoch: 5| Step: 8
Training loss: 3.193116270371826
Validation loss: 3.2513484713086696

Epoch: 5| Step: 9
Training loss: 3.026582723145281
Validation loss: 3.233719786179187

Epoch: 5| Step: 10
Training loss: 3.6304255693731418
Validation loss: 3.240598187987489

Epoch: 17| Step: 0
Training loss: 3.2192444653005405
Validation loss: 3.234379600381733

Epoch: 5| Step: 1
Training loss: 2.9583168208418087
Validation loss: 3.2306623305012567

Epoch: 5| Step: 2
Training loss: 3.8314087777273125
Validation loss: 3.2283830679694763

Epoch: 5| Step: 3
Training loss: 3.6225480304321827
Validation loss: 3.227346935786922

Epoch: 5| Step: 4
Training loss: 3.3350869016749223
Validation loss: 3.225921904948676

Epoch: 5| Step: 5
Training loss: 3.944836155301674
Validation loss: 3.2246936734332117

Epoch: 5| Step: 6
Training loss: 3.6324898525235447
Validation loss: 3.222392887156887

Epoch: 5| Step: 7
Training loss: 3.1166441020726725
Validation loss: 3.2215577242940743

Epoch: 5| Step: 8
Training loss: 3.5510057770733905
Validation loss: 3.2205687164587924

Epoch: 5| Step: 9
Training loss: 3.429117976631345
Validation loss: 3.2189579693497157

Epoch: 5| Step: 10
Training loss: 3.5549839441121964
Validation loss: 3.218795057635087

Epoch: 18| Step: 0
Training loss: 3.682228846825725
Validation loss: 3.2160352932610614

Epoch: 5| Step: 1
Training loss: 4.0044623756313005
Validation loss: 3.215504014024398

Epoch: 5| Step: 2
Training loss: 4.5968414077205635
Validation loss: 3.2143404024116955

Epoch: 5| Step: 3
Training loss: 3.500717498260108
Validation loss: 3.212478688187195

Epoch: 5| Step: 4
Training loss: 2.9972386367280808
Validation loss: 3.2117981124269903

Epoch: 5| Step: 5
Training loss: 3.5376019358691333
Validation loss: 3.209949611002156

Epoch: 5| Step: 6
Training loss: 3.3578440881719316
Validation loss: 3.2079525132787805

Epoch: 5| Step: 7
Training loss: 3.378811414854111
Validation loss: 3.2066204664348956

Epoch: 5| Step: 8
Training loss: 3.2311616867068245
Validation loss: 3.20610933978569

Epoch: 5| Step: 9
Training loss: 2.6734074887988495
Validation loss: 3.2048397817574346

Epoch: 5| Step: 10
Training loss: 2.6470083696256816
Validation loss: 3.2037126091696795

Epoch: 19| Step: 0
Training loss: 3.1175910095782173
Validation loss: 3.2031097787915086

Epoch: 5| Step: 1
Training loss: 3.4486604716124076
Validation loss: 3.2010503461540094

Epoch: 5| Step: 2
Training loss: 3.0814584410076384
Validation loss: 3.201177773213724

Epoch: 5| Step: 3
Training loss: 3.3206832858225446
Validation loss: 3.198251413649686

Epoch: 5| Step: 4
Training loss: 3.786266435730437
Validation loss: 3.196785054845941

Epoch: 5| Step: 5
Training loss: 3.3878077743746444
Validation loss: 3.1959252334496155

Epoch: 5| Step: 6
Training loss: 3.8037629619757376
Validation loss: 3.1893241788991555

Epoch: 5| Step: 7
Training loss: 3.0683223884825215
Validation loss: 3.1877106643799347

Epoch: 5| Step: 8
Training loss: 3.701554363687831
Validation loss: 3.1845854436072396

Epoch: 5| Step: 9
Training loss: 3.5438614869788014
Validation loss: 3.185702997046153

Epoch: 5| Step: 10
Training loss: 3.6833283701959605
Validation loss: 3.177322438947589

Epoch: 20| Step: 0
Training loss: 3.119523246481641
Validation loss: 3.174168297849954

Epoch: 5| Step: 1
Training loss: 3.4667044441903525
Validation loss: 3.174931456924359

Epoch: 5| Step: 2
Training loss: 3.5869386559444796
Validation loss: 3.1755818133081632

Epoch: 5| Step: 3
Training loss: 3.582269126123829
Validation loss: 3.1739487964291073

Epoch: 5| Step: 4
Training loss: 3.4574061303625516
Validation loss: 3.1724443533379523

Epoch: 5| Step: 5
Training loss: 4.119003561316106
Validation loss: 3.169609594023031

Epoch: 5| Step: 6
Training loss: 3.4949219514047996
Validation loss: 3.1679970375965745

Epoch: 5| Step: 7
Training loss: 2.6296952354602974
Validation loss: 3.169100441975106

Epoch: 5| Step: 8
Training loss: 3.9687413493385053
Validation loss: 3.166492232832966

Epoch: 5| Step: 9
Training loss: 3.2579146627603834
Validation loss: 3.163889083454877

Epoch: 5| Step: 10
Training loss: 2.716598185356751
Validation loss: 3.163768533966367

Epoch: 21| Step: 0
Training loss: 3.238165803883041
Validation loss: 3.165744289870074

Epoch: 5| Step: 1
Training loss: 3.7776022726941574
Validation loss: 3.162877350122922

Epoch: 5| Step: 2
Training loss: 3.827055240556376
Validation loss: 3.1629872161881405

Epoch: 5| Step: 3
Training loss: 3.8933164793024226
Validation loss: 3.162912812698252

Epoch: 5| Step: 4
Training loss: 2.5853818544251674
Validation loss: 3.16684797563479

Epoch: 5| Step: 5
Training loss: 3.2871203997512684
Validation loss: 3.1649862914041305

Epoch: 5| Step: 6
Training loss: 3.4599566652086944
Validation loss: 3.161572535269383

Epoch: 5| Step: 7
Training loss: 3.7769248753823828
Validation loss: 3.1550373211682996

Epoch: 5| Step: 8
Training loss: 3.26010322079745
Validation loss: 3.1533767169293934

Epoch: 5| Step: 9
Training loss: 3.2765063192329027
Validation loss: 3.1521284300744914

Epoch: 5| Step: 10
Training loss: 3.067508727716467
Validation loss: 3.1515988038991933

Epoch: 22| Step: 0
Training loss: 3.782886749887655
Validation loss: 3.1525696332228765

Epoch: 5| Step: 1
Training loss: 3.32208707173774
Validation loss: 3.1557762832606215

Epoch: 5| Step: 2
Training loss: 3.690791584489918
Validation loss: 3.1575293720300963

Epoch: 5| Step: 3
Training loss: 3.722105291690336
Validation loss: 3.155277399218101

Epoch: 5| Step: 4
Training loss: 3.340567669853817
Validation loss: 3.149433165525127

Epoch: 5| Step: 5
Training loss: 2.6295627720810266
Validation loss: 3.1515110453758823

Epoch: 5| Step: 6
Training loss: 2.9174882730674905
Validation loss: 3.14518569498241

Epoch: 5| Step: 7
Training loss: 3.012854375612512
Validation loss: 3.1506690741769656

Epoch: 5| Step: 8
Training loss: 3.6191962248663603
Validation loss: 3.1517741029455553

Epoch: 5| Step: 9
Training loss: 4.14352419138701
Validation loss: 3.1494148976696192

Epoch: 5| Step: 10
Training loss: 3.029311199142069
Validation loss: 3.1456174857227337

Epoch: 23| Step: 0
Training loss: 3.270441035821716
Validation loss: 3.1442142197079157

Epoch: 5| Step: 1
Training loss: 3.034219761814935
Validation loss: 3.140992903584286

Epoch: 5| Step: 2
Training loss: 3.361940052249146
Validation loss: 3.1411937332740356

Epoch: 5| Step: 3
Training loss: 3.4293590901101183
Validation loss: 3.1403402714600976

Epoch: 5| Step: 4
Training loss: 4.250036800449589
Validation loss: 3.1397101524295548

Epoch: 5| Step: 5
Training loss: 3.118019394545708
Validation loss: 3.1370174557048593

Epoch: 5| Step: 6
Training loss: 3.2987581632974967
Validation loss: 3.1344795635005114

Epoch: 5| Step: 7
Training loss: 3.494095044507764
Validation loss: 3.1371990405144095

Epoch: 5| Step: 8
Training loss: 3.613824652973152
Validation loss: 3.1338771782281856

Epoch: 5| Step: 9
Training loss: 3.5324958696496442
Validation loss: 3.135222593370884

Epoch: 5| Step: 10
Training loss: 2.759083830353159
Validation loss: 3.135881270084413

Epoch: 24| Step: 0
Training loss: 4.055973150506773
Validation loss: 3.1399958206868983

Epoch: 5| Step: 1
Training loss: 3.152615106524692
Validation loss: 3.1449995124970807

Epoch: 5| Step: 2
Training loss: 3.3319662787664757
Validation loss: 3.1484473362220946

Epoch: 5| Step: 3
Training loss: 3.4705407271551754
Validation loss: 3.1454787276882192

Epoch: 5| Step: 4
Training loss: 2.777511827665154
Validation loss: 3.1335664887780688

Epoch: 5| Step: 5
Training loss: 3.49040487307397
Validation loss: 3.1303636096986684

Epoch: 5| Step: 6
Training loss: 2.993867009370958
Validation loss: 3.130226121416864

Epoch: 5| Step: 7
Training loss: 2.7339678651976413
Validation loss: 3.1293118269198317

Epoch: 5| Step: 8
Training loss: 3.7875111343673358
Validation loss: 3.127324615857154

Epoch: 5| Step: 9
Training loss: 3.0404379117673987
Validation loss: 3.126817193764557

Epoch: 5| Step: 10
Training loss: 4.301663924025073
Validation loss: 3.123751282954745

Epoch: 25| Step: 0
Training loss: 3.561595868942319
Validation loss: 3.123334313565171

Epoch: 5| Step: 1
Training loss: 3.2320276855567123
Validation loss: 3.123440323334745

Epoch: 5| Step: 2
Training loss: 3.6854291370469108
Validation loss: 3.123203598851425

Epoch: 5| Step: 3
Training loss: 3.413647519518119
Validation loss: 3.124286509453316

Epoch: 5| Step: 4
Training loss: 2.5518296615231675
Validation loss: 3.121802308869028

Epoch: 5| Step: 5
Training loss: 4.0867361305726275
Validation loss: 3.1210457162840304

Epoch: 5| Step: 6
Training loss: 3.6926458628777183
Validation loss: 3.119039971113929

Epoch: 5| Step: 7
Training loss: 2.8736034816245075
Validation loss: 3.1172575398799527

Epoch: 5| Step: 8
Training loss: 3.0739801840208614
Validation loss: 3.115883986152721

Epoch: 5| Step: 9
Training loss: 3.641525615576379
Validation loss: 3.1158604656777036

Epoch: 5| Step: 10
Training loss: 3.083090093829949
Validation loss: 3.114364523874861

Epoch: 26| Step: 0
Training loss: 4.017287566972516
Validation loss: 3.112734727360081

Epoch: 5| Step: 1
Training loss: 3.323232860927627
Validation loss: 3.1120963738175607

Epoch: 5| Step: 2
Training loss: 2.866256354782839
Validation loss: 3.11284071432192

Epoch: 5| Step: 3
Training loss: 3.1542215911101104
Validation loss: 3.11283803277851

Epoch: 5| Step: 4
Training loss: 3.4082621659463475
Validation loss: 3.113291707834925

Epoch: 5| Step: 5
Training loss: 3.358720582606771
Validation loss: 3.111442847506041

Epoch: 5| Step: 6
Training loss: 3.3593311395665104
Validation loss: 3.109851696937807

Epoch: 5| Step: 7
Training loss: 2.920819749859521
Validation loss: 3.1092187161270344

Epoch: 5| Step: 8
Training loss: 4.07616696176932
Validation loss: 3.106747443834494

Epoch: 5| Step: 9
Training loss: 3.1140267545693674
Validation loss: 3.1054490281563143

Epoch: 5| Step: 10
Training loss: 3.3403388476236
Validation loss: 3.1047391350531974

Epoch: 27| Step: 0
Training loss: 3.3702630603119283
Validation loss: 3.104836347025311

Epoch: 5| Step: 1
Training loss: 3.3105785627170783
Validation loss: 3.113220877138

Epoch: 5| Step: 2
Training loss: 3.512992856890124
Validation loss: 3.114801458829082

Epoch: 5| Step: 3
Training loss: 2.7969961299985395
Validation loss: 3.105062919562967

Epoch: 5| Step: 4
Training loss: 3.0350968638615905
Validation loss: 3.1041146820686145

Epoch: 5| Step: 5
Training loss: 3.662494901581949
Validation loss: 3.101711752419054

Epoch: 5| Step: 6
Training loss: 3.686809281136749
Validation loss: 3.100607129768138

Epoch: 5| Step: 7
Training loss: 3.953609994682236
Validation loss: 3.0994060493168956

Epoch: 5| Step: 8
Training loss: 2.566235866145378
Validation loss: 3.099203220672853

Epoch: 5| Step: 9
Training loss: 3.6882285998529087
Validation loss: 3.107234494064818

Epoch: 5| Step: 10
Training loss: 3.210389621892182
Validation loss: 3.0968241668863987

Epoch: 28| Step: 0
Training loss: 3.561083060114599
Validation loss: 3.095223488694896

Epoch: 5| Step: 1
Training loss: 3.601484517144824
Validation loss: 3.0970489225631437

Epoch: 5| Step: 2
Training loss: 2.5219470839851867
Validation loss: 3.0981396354836304

Epoch: 5| Step: 3
Training loss: 3.5202966465362344
Validation loss: 3.1109836107146016

Epoch: 5| Step: 4
Training loss: 3.153900934176611
Validation loss: 3.1137043928927244

Epoch: 5| Step: 5
Training loss: 3.9081737206461935
Validation loss: 3.1240529239306984

Epoch: 5| Step: 6
Training loss: 2.8153917493324925
Validation loss: 3.0962045949898203

Epoch: 5| Step: 7
Training loss: 3.541316983780788
Validation loss: 3.089706898056155

Epoch: 5| Step: 8
Training loss: 3.665899991308663
Validation loss: 3.090753611776893

Epoch: 5| Step: 9
Training loss: 3.5116452897888744
Validation loss: 3.096902258316051

Epoch: 5| Step: 10
Training loss: 2.833552426861717
Validation loss: 3.095091811246752

Epoch: 29| Step: 0
Training loss: 3.0478925521915285
Validation loss: 3.091111233779169

Epoch: 5| Step: 1
Training loss: 3.5636677752120725
Validation loss: 3.082398841434982

Epoch: 5| Step: 2
Training loss: 2.320709502810627
Validation loss: 3.0785938782618985

Epoch: 5| Step: 3
Training loss: 3.2782619858622066
Validation loss: 3.076693124200625

Epoch: 5| Step: 4
Training loss: 3.2848917778687277
Validation loss: 3.0754322420840707

Epoch: 5| Step: 5
Training loss: 3.685091945789926
Validation loss: 3.0754907743458673

Epoch: 5| Step: 6
Training loss: 3.9598388352013827
Validation loss: 3.076061367609405

Epoch: 5| Step: 7
Training loss: 3.712939041841406
Validation loss: 3.0838248424561967

Epoch: 5| Step: 8
Training loss: 2.9553559772092375
Validation loss: 3.0882650581895574

Epoch: 5| Step: 9
Training loss: 3.735893292007953
Validation loss: 3.112815942900276

Epoch: 5| Step: 10
Training loss: 2.851069995728697
Validation loss: 3.0694386940268434

Epoch: 30| Step: 0
Training loss: 3.368776871214867
Validation loss: 3.0708406126671526

Epoch: 5| Step: 1
Training loss: 3.1571087565981584
Validation loss: 3.091179588784536

Epoch: 5| Step: 2
Training loss: 3.210689785723075
Validation loss: 3.1474745674926696

Epoch: 5| Step: 3
Training loss: 3.6975753984894815
Validation loss: 3.104523729819317

Epoch: 5| Step: 4
Training loss: 3.0219009792785156
Validation loss: 3.083033639987133

Epoch: 5| Step: 5
Training loss: 2.549354329363234
Validation loss: 3.0671416770358095

Epoch: 5| Step: 6
Training loss: 2.7320330372456265
Validation loss: 3.0705931563759283

Epoch: 5| Step: 7
Training loss: 3.4490044636331123
Validation loss: 3.073507006075752

Epoch: 5| Step: 8
Training loss: 3.5022628825899247
Validation loss: 3.0974870379065482

Epoch: 5| Step: 9
Training loss: 4.443718649623502
Validation loss: 3.2875382398913158

Epoch: 5| Step: 10
Training loss: 3.771525338818189
Validation loss: 3.1188385829058505

Epoch: 31| Step: 0
Training loss: 3.813795276174291
Validation loss: 3.0712048372743426

Epoch: 5| Step: 1
Training loss: 3.2879121993377805
Validation loss: 3.0678313666744392

Epoch: 5| Step: 2
Training loss: 2.9390410581188884
Validation loss: 3.074602762744652

Epoch: 5| Step: 3
Training loss: 2.6230161527310107
Validation loss: 3.132151546685073

Epoch: 5| Step: 4
Training loss: 3.230889105057567
Validation loss: 3.173642206771557

Epoch: 5| Step: 5
Training loss: 3.798340565595204
Validation loss: 3.121138260901163

Epoch: 5| Step: 6
Training loss: 3.3653130148512553
Validation loss: 3.0734430734388356

Epoch: 5| Step: 7
Training loss: 3.7295315668744498
Validation loss: 3.067783608768213

Epoch: 5| Step: 8
Training loss: 3.3709596538726343
Validation loss: 3.06247734612262

Epoch: 5| Step: 9
Training loss: 3.543306143277461
Validation loss: 3.074523569597581

Epoch: 5| Step: 10
Training loss: 3.035073454720547
Validation loss: 3.11827233215195

Epoch: 32| Step: 0
Training loss: 3.9975122822089157
Validation loss: 3.146757274719344

Epoch: 5| Step: 1
Training loss: 2.776054845114245
Validation loss: 3.0781571098348963

Epoch: 5| Step: 2
Training loss: 3.1957811977174035
Validation loss: 3.053799579078819

Epoch: 5| Step: 3
Training loss: 3.1591875362151343
Validation loss: 3.049658548805517

Epoch: 5| Step: 4
Training loss: 3.8285694097908083
Validation loss: 3.049370508612131

Epoch: 5| Step: 5
Training loss: 3.2011394021957305
Validation loss: 3.0472638879331346

Epoch: 5| Step: 6
Training loss: 3.0312232576744016
Validation loss: 3.049518756902475

Epoch: 5| Step: 7
Training loss: 3.876353611943717
Validation loss: 3.0524184667961736

Epoch: 5| Step: 8
Training loss: 2.2731765649761217
Validation loss: 3.047792280734413

Epoch: 5| Step: 9
Training loss: 3.2997591682177814
Validation loss: 3.0424278659277486

Epoch: 5| Step: 10
Training loss: 3.697754647730762
Validation loss: 3.043153242495557

Epoch: 33| Step: 0
Training loss: 2.9279820882635015
Validation loss: 3.0408098854611416

Epoch: 5| Step: 1
Training loss: 4.2391809870875035
Validation loss: 3.041255364034622

Epoch: 5| Step: 2
Training loss: 3.0798073445792222
Validation loss: 3.0395115831271404

Epoch: 5| Step: 3
Training loss: 2.5063152656714
Validation loss: 3.038659283886557

Epoch: 5| Step: 4
Training loss: 3.412807766516639
Validation loss: 3.037756456407414

Epoch: 5| Step: 5
Training loss: 3.131567196189162
Validation loss: 3.035855933731719

Epoch: 5| Step: 6
Training loss: 3.3639325121665467
Validation loss: 3.0359248809276065

Epoch: 5| Step: 7
Training loss: 3.539711326423959
Validation loss: 3.0351088107823676

Epoch: 5| Step: 8
Training loss: 3.6807126441557014
Validation loss: 3.035274370126241

Epoch: 5| Step: 9
Training loss: 3.119714157508753
Validation loss: 3.0362985895716488

Epoch: 5| Step: 10
Training loss: 3.13039207659722
Validation loss: 3.037355194731878

Epoch: 34| Step: 0
Training loss: 3.4171168023057956
Validation loss: 3.0332740104695395

Epoch: 5| Step: 1
Training loss: 2.844807857736006
Validation loss: 3.032911675088977

Epoch: 5| Step: 2
Training loss: 3.246112111908431
Validation loss: 3.0338158513652598

Epoch: 5| Step: 3
Training loss: 3.200451288587683
Validation loss: 3.032865150864751

Epoch: 5| Step: 4
Training loss: 3.177419542544047
Validation loss: 3.027173475120556

Epoch: 5| Step: 5
Training loss: 3.3935062103102247
Validation loss: 3.0282369764488015

Epoch: 5| Step: 6
Training loss: 2.7427555376205057
Validation loss: 3.0273528635534213

Epoch: 5| Step: 7
Training loss: 3.757230781052695
Validation loss: 3.025895648904227

Epoch: 5| Step: 8
Training loss: 3.3559822870816904
Validation loss: 3.026347446578783

Epoch: 5| Step: 9
Training loss: 3.5155333104362856
Validation loss: 3.026859183112719

Epoch: 5| Step: 10
Training loss: 3.6164103058227552
Validation loss: 3.02490182634396

Epoch: 35| Step: 0
Training loss: 2.9470355510968496
Validation loss: 3.0238469967825474

Epoch: 5| Step: 1
Training loss: 2.7180308125190074
Validation loss: 3.024393137371909

Epoch: 5| Step: 2
Training loss: 2.999204212182303
Validation loss: 3.0300895314130676

Epoch: 5| Step: 3
Training loss: 3.0246778206247193
Validation loss: 3.0227647377180777

Epoch: 5| Step: 4
Training loss: 3.8262444061368015
Validation loss: 3.0200041486176072

Epoch: 5| Step: 5
Training loss: 3.5149804096571344
Validation loss: 3.019661024921924

Epoch: 5| Step: 6
Training loss: 3.67182058740435
Validation loss: 3.019870702839769

Epoch: 5| Step: 7
Training loss: 3.2879538219207105
Validation loss: 3.0193595037717027

Epoch: 5| Step: 8
Training loss: 4.1707179147233555
Validation loss: 3.0178656139287305

Epoch: 5| Step: 9
Training loss: 2.9533810782035594
Validation loss: 3.017119632186062

Epoch: 5| Step: 10
Training loss: 2.7739346770479827
Validation loss: 3.0171334805329235

Epoch: 36| Step: 0
Training loss: 3.0740192741231573
Validation loss: 3.0156558489668153

Epoch: 5| Step: 1
Training loss: 3.6730307200887022
Validation loss: 3.0149146264582707

Epoch: 5| Step: 2
Training loss: 2.9918325826245047
Validation loss: 3.015020798880273

Epoch: 5| Step: 3
Training loss: 3.6601804815933483
Validation loss: 3.014602968260695

Epoch: 5| Step: 4
Training loss: 3.212771298126043
Validation loss: 3.013408994556056

Epoch: 5| Step: 5
Training loss: 3.6655522878318214
Validation loss: 3.011522460370051

Epoch: 5| Step: 6
Training loss: 3.3257522363093877
Validation loss: 3.0118002704078646

Epoch: 5| Step: 7
Training loss: 3.1171963722657257
Validation loss: 3.01024175295374

Epoch: 5| Step: 8
Training loss: 3.3866224440243027
Validation loss: 3.009372263608674

Epoch: 5| Step: 9
Training loss: 2.9737979736563407
Validation loss: 3.00889477200933

Epoch: 5| Step: 10
Training loss: 2.968160149050276
Validation loss: 3.0078937648986734

Epoch: 37| Step: 0
Training loss: 3.6634582151370547
Validation loss: 3.0062064349256894

Epoch: 5| Step: 1
Training loss: 3.002546024779705
Validation loss: 3.0044909953461727

Epoch: 5| Step: 2
Training loss: 3.539134852193988
Validation loss: 3.0040954080526103

Epoch: 5| Step: 3
Training loss: 3.9656169870234006
Validation loss: 3.0033196298230775

Epoch: 5| Step: 4
Training loss: 3.3343639370020606
Validation loss: 3.0016662762494244

Epoch: 5| Step: 5
Training loss: 3.0436907439368017
Validation loss: 3.001506768846614

Epoch: 5| Step: 6
Training loss: 2.8271329204021485
Validation loss: 2.9999698189615294

Epoch: 5| Step: 7
Training loss: 3.684851131460123
Validation loss: 3.0040780357071197

Epoch: 5| Step: 8
Training loss: 2.7804943301124707
Validation loss: 3.000803345959846

Epoch: 5| Step: 9
Training loss: 2.980535303975141
Validation loss: 2.9984529340569384

Epoch: 5| Step: 10
Training loss: 2.9994829050102503
Validation loss: 2.99725514634285

Epoch: 38| Step: 0
Training loss: 2.7293560069169973
Validation loss: 2.9966278162771225

Epoch: 5| Step: 1
Training loss: 3.1625403239578116
Validation loss: 2.997637432850211

Epoch: 5| Step: 2
Training loss: 3.4450168612528453
Validation loss: 2.9945322254829607

Epoch: 5| Step: 3
Training loss: 3.4157051656377564
Validation loss: 2.994087835197209

Epoch: 5| Step: 4
Training loss: 2.714647464380132
Validation loss: 2.993614623046541

Epoch: 5| Step: 5
Training loss: 3.279102312851707
Validation loss: 2.993107039710342

Epoch: 5| Step: 6
Training loss: 3.3461484774100407
Validation loss: 2.992543110310396

Epoch: 5| Step: 7
Training loss: 3.3739512191529433
Validation loss: 2.991132308270777

Epoch: 5| Step: 8
Training loss: 3.4133860181924773
Validation loss: 2.9897816612851287

Epoch: 5| Step: 9
Training loss: 3.796406155748072
Validation loss: 2.989516722954774

Epoch: 5| Step: 10
Training loss: 3.1762321123972868
Validation loss: 2.9898033482747275

Epoch: 39| Step: 0
Training loss: 3.4710770782819016
Validation loss: 2.986857084704436

Epoch: 5| Step: 1
Training loss: 2.823971390608982
Validation loss: 2.987282482907143

Epoch: 5| Step: 2
Training loss: 3.2449515820198798
Validation loss: 2.9849069339576997

Epoch: 5| Step: 3
Training loss: 3.683413552723971
Validation loss: 2.9848014270471768

Epoch: 5| Step: 4
Training loss: 3.30537454303608
Validation loss: 2.983069631480795

Epoch: 5| Step: 5
Training loss: 3.611427945314598
Validation loss: 2.983106171092147

Epoch: 5| Step: 6
Training loss: 3.449829185790626
Validation loss: 2.983566324945154

Epoch: 5| Step: 7
Training loss: 2.10804650186283
Validation loss: 2.9814981971712666

Epoch: 5| Step: 8
Training loss: 3.8262640964830377
Validation loss: 2.980791199869675

Epoch: 5| Step: 9
Training loss: 3.0906151195711473
Validation loss: 2.9818971811964743

Epoch: 5| Step: 10
Training loss: 2.9071199489185
Validation loss: 2.9795316723121203

Epoch: 40| Step: 0
Training loss: 3.6363540941893486
Validation loss: 2.9798642841968794

Epoch: 5| Step: 1
Training loss: 2.639180888924693
Validation loss: 2.9789549519074665

Epoch: 5| Step: 2
Training loss: 2.8387608621407114
Validation loss: 2.9782255229214143

Epoch: 5| Step: 3
Training loss: 3.0812568029982423
Validation loss: 2.9769308499475673

Epoch: 5| Step: 4
Training loss: 3.452276203213811
Validation loss: 2.976702130169398

Epoch: 5| Step: 5
Training loss: 2.8508856819325032
Validation loss: 2.976125249941917

Epoch: 5| Step: 6
Training loss: 3.7221348848740408
Validation loss: 2.9760433897715024

Epoch: 5| Step: 7
Training loss: 3.759961186066625
Validation loss: 2.975338839224447

Epoch: 5| Step: 8
Training loss: 3.3201375758150244
Validation loss: 2.9734483208318045

Epoch: 5| Step: 9
Training loss: 2.9164271846728034
Validation loss: 2.9733578520186557

Epoch: 5| Step: 10
Training loss: 3.4656748844612006
Validation loss: 2.9722872357571517

Epoch: 41| Step: 0
Training loss: 3.2409480287974706
Validation loss: 2.9708657359864565

Epoch: 5| Step: 1
Training loss: 2.9152611933791728
Validation loss: 2.970446439445817

Epoch: 5| Step: 2
Training loss: 3.4562964051702894
Validation loss: 2.969661919300231

Epoch: 5| Step: 3
Training loss: 3.646128542619445
Validation loss: 2.9680579578663653

Epoch: 5| Step: 4
Training loss: 3.0725636080062104
Validation loss: 2.96782264927414

Epoch: 5| Step: 5
Training loss: 3.32902607786049
Validation loss: 2.96765750629598

Epoch: 5| Step: 6
Training loss: 3.323275475975651
Validation loss: 2.966802698235636

Epoch: 5| Step: 7
Training loss: 3.1039530191995417
Validation loss: 2.9661881157534236

Epoch: 5| Step: 8
Training loss: 3.444916925189918
Validation loss: 2.965111690071389

Epoch: 5| Step: 9
Training loss: 3.385306128629092
Validation loss: 2.9634676852560684

Epoch: 5| Step: 10
Training loss: 2.680753623703102
Validation loss: 2.964151690159725

Epoch: 42| Step: 0
Training loss: 2.7961127238710364
Validation loss: 2.962349240629555

Epoch: 5| Step: 1
Training loss: 2.718996409507477
Validation loss: 2.9620431230916773

Epoch: 5| Step: 2
Training loss: 2.9469650044455493
Validation loss: 2.961385081560123

Epoch: 5| Step: 3
Training loss: 3.0725054104713125
Validation loss: 2.961720828943982

Epoch: 5| Step: 4
Training loss: 3.337429740251945
Validation loss: 2.9575796875962252

Epoch: 5| Step: 5
Training loss: 3.0650426468985925
Validation loss: 2.964538082023353

Epoch: 5| Step: 6
Training loss: 3.631241916246986
Validation loss: 2.9624921021936657

Epoch: 5| Step: 7
Training loss: 3.519557398149607
Validation loss: 2.973480935108446

Epoch: 5| Step: 8
Training loss: 3.4520571339145802
Validation loss: 2.9596582265515856

Epoch: 5| Step: 9
Training loss: 3.4230550882340416
Validation loss: 2.9556865357123665

Epoch: 5| Step: 10
Training loss: 3.751671736341113
Validation loss: 2.9551642337673742

Epoch: 43| Step: 0
Training loss: 2.925067483498461
Validation loss: 2.954303739513068

Epoch: 5| Step: 1
Training loss: 3.2937313477424164
Validation loss: 2.9545694058938525

Epoch: 5| Step: 2
Training loss: 3.4410968342652795
Validation loss: 2.955396327507018

Epoch: 5| Step: 3
Training loss: 3.1739131599185417
Validation loss: 2.9544658213728554

Epoch: 5| Step: 4
Training loss: 3.1012857539473395
Validation loss: 2.954967617761619

Epoch: 5| Step: 5
Training loss: 3.384536691397728
Validation loss: 2.9558839200281835

Epoch: 5| Step: 6
Training loss: 2.268319573044178
Validation loss: 2.9551802965771694

Epoch: 5| Step: 7
Training loss: 3.4919250526207057
Validation loss: 2.9542054652565244

Epoch: 5| Step: 8
Training loss: 3.6410459348761215
Validation loss: 2.9530807121112823

Epoch: 5| Step: 9
Training loss: 3.0897790875522944
Validation loss: 2.9513024338267138

Epoch: 5| Step: 10
Training loss: 3.720129446423139
Validation loss: 2.9516517344210733

Epoch: 44| Step: 0
Training loss: 2.5331780896387217
Validation loss: 2.949167335375568

Epoch: 5| Step: 1
Training loss: 3.240344449795471
Validation loss: 2.9481081600180823

Epoch: 5| Step: 2
Training loss: 2.999955971712644
Validation loss: 2.9468768378954193

Epoch: 5| Step: 3
Training loss: 2.694391153951245
Validation loss: 2.945744516482721

Epoch: 5| Step: 4
Training loss: 3.360377814077567
Validation loss: 2.9455118467369283

Epoch: 5| Step: 5
Training loss: 3.712014646303945
Validation loss: 2.9437535401428323

Epoch: 5| Step: 6
Training loss: 3.502346478405208
Validation loss: 2.943331464819982

Epoch: 5| Step: 7
Training loss: 3.9778624922210475
Validation loss: 2.9421974587350506

Epoch: 5| Step: 8
Training loss: 3.556136487815211
Validation loss: 2.9399729050453747

Epoch: 5| Step: 9
Training loss: 2.6140302602509347
Validation loss: 2.939833263122255

Epoch: 5| Step: 10
Training loss: 3.072590456097408
Validation loss: 2.937573241972596

Epoch: 45| Step: 0
Training loss: 3.344912318062664
Validation loss: 2.9382962535542028

Epoch: 5| Step: 1
Training loss: 3.4706367653774923
Validation loss: 2.935793434817293

Epoch: 5| Step: 2
Training loss: 3.752591064486727
Validation loss: 2.934247071432276

Epoch: 5| Step: 3
Training loss: 2.9194649125081487
Validation loss: 2.9345251400433403

Epoch: 5| Step: 4
Training loss: 3.1216433999545004
Validation loss: 2.934562655385979

Epoch: 5| Step: 5
Training loss: 3.3142000550207746
Validation loss: 2.933826732274394

Epoch: 5| Step: 6
Training loss: 3.3296682871886745
Validation loss: 2.930820984036857

Epoch: 5| Step: 7
Training loss: 3.3620400436803335
Validation loss: 2.931502173412976

Epoch: 5| Step: 8
Training loss: 3.346029912574346
Validation loss: 2.9294465311687024

Epoch: 5| Step: 9
Training loss: 2.552953569126737
Validation loss: 2.928321851076021

Epoch: 5| Step: 10
Training loss: 2.726249611289142
Validation loss: 2.9278330588138326

Epoch: 46| Step: 0
Training loss: 3.3112247819469443
Validation loss: 2.9246439912486033

Epoch: 5| Step: 1
Training loss: 3.3943208161722995
Validation loss: 2.926041852035858

Epoch: 5| Step: 2
Training loss: 3.3892497424700787
Validation loss: 2.923095502614165

Epoch: 5| Step: 3
Training loss: 2.9523424191458036
Validation loss: 2.922621738555845

Epoch: 5| Step: 4
Training loss: 2.810956234575301
Validation loss: 2.9202246526773536

Epoch: 5| Step: 5
Training loss: 3.024098090029104
Validation loss: 2.92133474978962

Epoch: 5| Step: 6
Training loss: 3.785459335050284
Validation loss: 2.918809346884665

Epoch: 5| Step: 7
Training loss: 3.493308892152426
Validation loss: 2.9192466124866963

Epoch: 5| Step: 8
Training loss: 2.700049353960861
Validation loss: 2.9164847661500777

Epoch: 5| Step: 9
Training loss: 3.4153809958483046
Validation loss: 2.916111314584339

Epoch: 5| Step: 10
Training loss: 2.864656833514917
Validation loss: 2.915404616870629

Epoch: 47| Step: 0
Training loss: 3.274074883874045
Validation loss: 2.913854678518545

Epoch: 5| Step: 1
Training loss: 3.287113146629595
Validation loss: 2.9139204981761018

Epoch: 5| Step: 2
Training loss: 4.0076328408349084
Validation loss: 2.913508638965724

Epoch: 5| Step: 3
Training loss: 3.1306580248534175
Validation loss: 2.9135390609961913

Epoch: 5| Step: 4
Training loss: 3.2352025544372496
Validation loss: 2.912753311570955

Epoch: 5| Step: 5
Training loss: 2.388622068196238
Validation loss: 2.912083679580165

Epoch: 5| Step: 6
Training loss: 2.9037111739717063
Validation loss: 2.9125726019612377

Epoch: 5| Step: 7
Training loss: 3.0091080686839007
Validation loss: 2.9114884785826507

Epoch: 5| Step: 8
Training loss: 2.7406507571324736
Validation loss: 2.910332561690016

Epoch: 5| Step: 9
Training loss: 3.791187815069744
Validation loss: 2.9092871711195967

Epoch: 5| Step: 10
Training loss: 3.225944108794572
Validation loss: 2.9077207143338972

Epoch: 48| Step: 0
Training loss: 3.001808892720849
Validation loss: 2.9059333412639603

Epoch: 5| Step: 1
Training loss: 3.5912571761381242
Validation loss: 2.907616683732913

Epoch: 5| Step: 2
Training loss: 3.5776188254999006
Validation loss: 2.907224594284688

Epoch: 5| Step: 3
Training loss: 3.30206541102667
Validation loss: 2.9123278068444196

Epoch: 5| Step: 4
Training loss: 3.2401481373206114
Validation loss: 2.9154615370665637

Epoch: 5| Step: 5
Training loss: 2.8261889158630167
Validation loss: 2.9064152626827515

Epoch: 5| Step: 6
Training loss: 3.0844965793876957
Validation loss: 2.9022574591267225

Epoch: 5| Step: 7
Training loss: 2.704242012451541
Validation loss: 2.9029664398314496

Epoch: 5| Step: 8
Training loss: 3.4823480706302137
Validation loss: 2.8999455338293645

Epoch: 5| Step: 9
Training loss: 3.398798079380329
Validation loss: 2.900504683213758

Epoch: 5| Step: 10
Training loss: 2.806223244316485
Validation loss: 2.8992649528364285

Epoch: 49| Step: 0
Training loss: 3.1598716579401325
Validation loss: 2.9003044634079633

Epoch: 5| Step: 1
Training loss: 3.8237632347693458
Validation loss: 2.9019189663771243

Epoch: 5| Step: 2
Training loss: 2.8615270968575164
Validation loss: 2.8972165397116103

Epoch: 5| Step: 3
Training loss: 3.5034684297868566
Validation loss: 2.8964661456910012

Epoch: 5| Step: 4
Training loss: 3.145354396580826
Validation loss: 2.8949444541906453

Epoch: 5| Step: 5
Training loss: 2.558473913283779
Validation loss: 2.8958859005472104

Epoch: 5| Step: 6
Training loss: 2.9456921239206624
Validation loss: 2.8929558267432927

Epoch: 5| Step: 7
Training loss: 2.993946006904724
Validation loss: 2.892901635379897

Epoch: 5| Step: 8
Training loss: 3.7863966540210803
Validation loss: 2.8943427826631094

Epoch: 5| Step: 9
Training loss: 3.15689473129568
Validation loss: 2.8941144045940015

Epoch: 5| Step: 10
Training loss: 2.9847317627173022
Validation loss: 2.8923636987886954

Epoch: 50| Step: 0
Training loss: 2.4935413856536996
Validation loss: 2.890803974157317

Epoch: 5| Step: 1
Training loss: 3.4508203609185566
Validation loss: 2.890939460285587

Epoch: 5| Step: 2
Training loss: 3.3764248418748477
Validation loss: 2.8903982164973887

Epoch: 5| Step: 3
Training loss: 2.6434655796304436
Validation loss: 2.889727206548812

Epoch: 5| Step: 4
Training loss: 3.1196430831111783
Validation loss: 2.891357706824195

Epoch: 5| Step: 5
Training loss: 3.281372503991086
Validation loss: 2.890224304186552

Epoch: 5| Step: 6
Training loss: 3.435526610851977
Validation loss: 2.892307362850691

Epoch: 5| Step: 7
Training loss: 3.109666666891293
Validation loss: 2.8913569194732593

Epoch: 5| Step: 8
Training loss: 3.2211204614672075
Validation loss: 2.8898008449333634

Epoch: 5| Step: 9
Training loss: 3.302056602265538
Validation loss: 2.890680681405734

Epoch: 5| Step: 10
Training loss: 3.553262613629341
Validation loss: 2.8900804675802467

Epoch: 51| Step: 0
Training loss: 2.6171834006206236
Validation loss: 2.8884575493266094

Epoch: 5| Step: 1
Training loss: 2.8938363047967934
Validation loss: 2.8872458064925652

Epoch: 5| Step: 2
Training loss: 3.590436651935597
Validation loss: 2.8877921926248455

Epoch: 5| Step: 3
Training loss: 3.479403245995236
Validation loss: 2.8876947549735643

Epoch: 5| Step: 4
Training loss: 3.075592393336004
Validation loss: 2.8860539304617503

Epoch: 5| Step: 5
Training loss: 2.841462777020984
Validation loss: 2.8855747031393095

Epoch: 5| Step: 6
Training loss: 3.6046497410787883
Validation loss: 2.8845745519414776

Epoch: 5| Step: 7
Training loss: 3.278244240394943
Validation loss: 2.8832538252587643

Epoch: 5| Step: 8
Training loss: 3.501042210855908
Validation loss: 2.8818700511384416

Epoch: 5| Step: 9
Training loss: 2.7136978914730547
Validation loss: 2.8806616743774947

Epoch: 5| Step: 10
Training loss: 3.306902204195091
Validation loss: 2.880153899746634

Epoch: 52| Step: 0
Training loss: 2.3481720978087903
Validation loss: 2.8772344444241975

Epoch: 5| Step: 1
Training loss: 4.012138069918562
Validation loss: 2.8779469786378273

Epoch: 5| Step: 2
Training loss: 3.1836247542106086
Validation loss: 2.8760806491966338

Epoch: 5| Step: 3
Training loss: 3.1067076317156013
Validation loss: 2.875811994967563

Epoch: 5| Step: 4
Training loss: 3.753912728231598
Validation loss: 2.8761856840707876

Epoch: 5| Step: 5
Training loss: 3.2998533852114704
Validation loss: 2.8747298642976133

Epoch: 5| Step: 6
Training loss: 2.890931479213038
Validation loss: 2.877184864714462

Epoch: 5| Step: 7
Training loss: 3.077658061129493
Validation loss: 2.878757760327577

Epoch: 5| Step: 8
Training loss: 2.908916931476971
Validation loss: 2.8847423983015092

Epoch: 5| Step: 9
Training loss: 2.845513939050649
Validation loss: 2.8786358717130667

Epoch: 5| Step: 10
Training loss: 3.2345690093156754
Validation loss: 2.8819198438004046

Epoch: 53| Step: 0
Training loss: 2.5152929809586424
Validation loss: 2.881117452161354

Epoch: 5| Step: 1
Training loss: 3.1286721588461552
Validation loss: 2.8859625563879128

Epoch: 5| Step: 2
Training loss: 3.720607518046579
Validation loss: 2.880506664310856

Epoch: 5| Step: 3
Training loss: 3.7487127001904716
Validation loss: 2.8788517621097918

Epoch: 5| Step: 4
Training loss: 2.697823060128931
Validation loss: 2.876164431036431

Epoch: 5| Step: 5
Training loss: 3.5457771383480297
Validation loss: 2.8736855148918443

Epoch: 5| Step: 6
Training loss: 3.5301298542291226
Validation loss: 2.8730675122085976

Epoch: 5| Step: 7
Training loss: 2.8517584746442113
Validation loss: 2.873437703989394

Epoch: 5| Step: 8
Training loss: 3.1235209207238723
Validation loss: 2.873727099358666

Epoch: 5| Step: 9
Training loss: 2.8143257149335663
Validation loss: 2.8739844370329473

Epoch: 5| Step: 10
Training loss: 2.982079706755238
Validation loss: 2.8624758977896736

Epoch: 54| Step: 0
Training loss: 3.42460321508728
Validation loss: 2.86388164499044

Epoch: 5| Step: 1
Training loss: 3.105192659209033
Validation loss: 2.8632545666365616

Epoch: 5| Step: 2
Training loss: 3.201907936178474
Validation loss: 2.864963373087058

Epoch: 5| Step: 3
Training loss: 3.3597887361048944
Validation loss: 2.8651070076782954

Epoch: 5| Step: 4
Training loss: 3.0859201937805865
Validation loss: 2.8726949524406273

Epoch: 5| Step: 5
Training loss: 3.6285193886903184
Validation loss: 2.86654598058831

Epoch: 5| Step: 6
Training loss: 2.5173975226447296
Validation loss: 2.866986934083146

Epoch: 5| Step: 7
Training loss: 3.150475535753197
Validation loss: 2.863895831497146

Epoch: 5| Step: 8
Training loss: 3.2249178262340132
Validation loss: 2.8624830652876905

Epoch: 5| Step: 9
Training loss: 2.5554927758323918
Validation loss: 2.858228272309079

Epoch: 5| Step: 10
Training loss: 3.487938944220968
Validation loss: 2.858601365559925

Epoch: 55| Step: 0
Training loss: 2.786413735481424
Validation loss: 2.854959501002186

Epoch: 5| Step: 1
Training loss: 3.6306062951823455
Validation loss: 2.853496416827182

Epoch: 5| Step: 2
Training loss: 3.3326760279760603
Validation loss: 2.8515991586173812

Epoch: 5| Step: 3
Training loss: 3.203673971630682
Validation loss: 2.850847496197554

Epoch: 5| Step: 4
Training loss: 2.876644825003384
Validation loss: 2.8503071128542765

Epoch: 5| Step: 5
Training loss: 3.1743644378600555
Validation loss: 2.848991337311104

Epoch: 5| Step: 6
Training loss: 3.2456788900813236
Validation loss: 2.846805624335311

Epoch: 5| Step: 7
Training loss: 3.308535092316883
Validation loss: 2.8466485977761744

Epoch: 5| Step: 8
Training loss: 2.9503645332240303
Validation loss: 2.8471777990440423

Epoch: 5| Step: 9
Training loss: 2.9406930329806937
Validation loss: 2.8497247019287926

Epoch: 5| Step: 10
Training loss: 3.2036961488220213
Validation loss: 2.856101397479447

Epoch: 56| Step: 0
Training loss: 3.6263702696639566
Validation loss: 2.8638440675951533

Epoch: 5| Step: 1
Training loss: 2.8824667787912075
Validation loss: 2.8495912713592584

Epoch: 5| Step: 2
Training loss: 3.180367361957866
Validation loss: 2.8423872581634413

Epoch: 5| Step: 3
Training loss: 2.338990936509635
Validation loss: 2.842252509002295

Epoch: 5| Step: 4
Training loss: 3.289662068644575
Validation loss: 2.8419806127785328

Epoch: 5| Step: 5
Training loss: 3.015719081221469
Validation loss: 2.841809697698942

Epoch: 5| Step: 6
Training loss: 2.976298483205744
Validation loss: 2.841384742451939

Epoch: 5| Step: 7
Training loss: 3.6983146489138274
Validation loss: 2.841110213177412

Epoch: 5| Step: 8
Training loss: 3.276619832379085
Validation loss: 2.8403845065966347

Epoch: 5| Step: 9
Training loss: 3.11520483307897
Validation loss: 2.8379269254393225

Epoch: 5| Step: 10
Training loss: 3.1178910840521223
Validation loss: 2.8361095137986667

Epoch: 57| Step: 0
Training loss: 2.9132363628715456
Validation loss: 2.8365492626873947

Epoch: 5| Step: 1
Training loss: 3.0290421772964504
Validation loss: 2.836256752721817

Epoch: 5| Step: 2
Training loss: 3.3574235792971243
Validation loss: 2.8342927548544607

Epoch: 5| Step: 3
Training loss: 3.3135485159259432
Validation loss: 2.836943914253463

Epoch: 5| Step: 4
Training loss: 3.643636481216393
Validation loss: 2.8326942020367354

Epoch: 5| Step: 5
Training loss: 2.488403317318379
Validation loss: 2.8342378344020944

Epoch: 5| Step: 6
Training loss: 3.0019769512514127
Validation loss: 2.8316053577902247

Epoch: 5| Step: 7
Training loss: 3.1258197472186477
Validation loss: 2.8304652175056386

Epoch: 5| Step: 8
Training loss: 3.3103891520780153
Validation loss: 2.8332510612916084

Epoch: 5| Step: 9
Training loss: 3.1873770297396438
Validation loss: 2.831021795284896

Epoch: 5| Step: 10
Training loss: 3.1000776219648163
Validation loss: 2.8298822234360808

Epoch: 58| Step: 0
Training loss: 2.4783219787125477
Validation loss: 2.8298369154071987

Epoch: 5| Step: 1
Training loss: 2.2915219579148607
Validation loss: 2.8300447331731884

Epoch: 5| Step: 2
Training loss: 3.2741695486826132
Validation loss: 2.832537367945632

Epoch: 5| Step: 3
Training loss: 3.4107665469517516
Validation loss: 2.831004501884037

Epoch: 5| Step: 4
Training loss: 3.0865929016241265
Validation loss: 2.829284606997516

Epoch: 5| Step: 5
Training loss: 3.539677783288936
Validation loss: 2.828559080278452

Epoch: 5| Step: 6
Training loss: 3.2839851242360423
Validation loss: 2.8270340884910494

Epoch: 5| Step: 7
Training loss: 3.0480968666303596
Validation loss: 2.8256667444487844

Epoch: 5| Step: 8
Training loss: 3.4684588335884645
Validation loss: 2.8251915176641913

Epoch: 5| Step: 9
Training loss: 3.334604322990325
Validation loss: 2.825709761387035

Epoch: 5| Step: 10
Training loss: 3.0400451797340478
Validation loss: 2.8216866479389604

Epoch: 59| Step: 0
Training loss: 3.175636203733342
Validation loss: 2.8251070699058567

Epoch: 5| Step: 1
Training loss: 3.2357628834616854
Validation loss: 2.822344816760066

Epoch: 5| Step: 2
Training loss: 3.1566092409457993
Validation loss: 2.820738035992102

Epoch: 5| Step: 3
Training loss: 3.0013963310796297
Validation loss: 2.822563797450728

Epoch: 5| Step: 4
Training loss: 3.132492848210798
Validation loss: 2.8216084789328186

Epoch: 5| Step: 5
Training loss: 3.3151111028358473
Validation loss: 2.821805274690754

Epoch: 5| Step: 6
Training loss: 3.2013257439473204
Validation loss: 2.8213001846852253

Epoch: 5| Step: 7
Training loss: 2.6565147716729713
Validation loss: 2.819276871965002

Epoch: 5| Step: 8
Training loss: 3.251453074823366
Validation loss: 2.819575134080764

Epoch: 5| Step: 9
Training loss: 3.4467627831294836
Validation loss: 2.81636080072941

Epoch: 5| Step: 10
Training loss: 2.8152486297682677
Validation loss: 2.8166493570089925

Epoch: 60| Step: 0
Training loss: 3.2552919585612643
Validation loss: 2.817519050421131

Epoch: 5| Step: 1
Training loss: 2.777059419781308
Validation loss: 2.814691866708718

Epoch: 5| Step: 2
Training loss: 3.544258530609656
Validation loss: 2.8243922926008707

Epoch: 5| Step: 3
Training loss: 3.2104542315193756
Validation loss: 2.8393101407881676

Epoch: 5| Step: 4
Training loss: 2.9809545918422655
Validation loss: 2.8395041134740806

Epoch: 5| Step: 5
Training loss: 2.725075040011531
Validation loss: 2.8347182170790073

Epoch: 5| Step: 6
Training loss: 2.5763476169384525
Validation loss: 2.8409447611473966

Epoch: 5| Step: 7
Training loss: 3.3974651480284344
Validation loss: 2.8391902499084773

Epoch: 5| Step: 8
Training loss: 3.4645912052569
Validation loss: 2.8145841070874105

Epoch: 5| Step: 9
Training loss: 2.7516844532339966
Validation loss: 2.810117177492548

Epoch: 5| Step: 10
Training loss: 3.64398365874662
Validation loss: 2.8119171286041236

Epoch: 61| Step: 0
Training loss: 2.9823836628302693
Validation loss: 2.816501833985792

Epoch: 5| Step: 1
Training loss: 3.499848362498844
Validation loss: 2.8218894524141103

Epoch: 5| Step: 2
Training loss: 2.8779528836654267
Validation loss: 2.8314008534630104

Epoch: 5| Step: 3
Training loss: 2.8341588519365413
Validation loss: 2.8291169963072487

Epoch: 5| Step: 4
Training loss: 2.5969606314265143
Validation loss: 2.830077012609748

Epoch: 5| Step: 5
Training loss: 3.232544016763345
Validation loss: 2.826269245829521

Epoch: 5| Step: 6
Training loss: 3.726042833222308
Validation loss: 2.8251116879101335

Epoch: 5| Step: 7
Training loss: 2.855428504921163
Validation loss: 2.8219932120664453

Epoch: 5| Step: 8
Training loss: 3.626681233919096
Validation loss: 2.813960452067796

Epoch: 5| Step: 9
Training loss: 3.3303256930061034
Validation loss: 2.813102537305332

Epoch: 5| Step: 10
Training loss: 2.668499962128926
Validation loss: 2.8104856289258278

Epoch: 62| Step: 0
Training loss: 3.516781222630529
Validation loss: 2.8103921317714526

Epoch: 5| Step: 1
Training loss: 2.3681766470348617
Validation loss: 2.8080938538068287

Epoch: 5| Step: 2
Training loss: 2.7126815418720875
Validation loss: 2.8068857925616766

Epoch: 5| Step: 3
Training loss: 3.1987450403828723
Validation loss: 2.8073320843439555

Epoch: 5| Step: 4
Training loss: 3.2266708245001032
Validation loss: 2.8033441297125137

Epoch: 5| Step: 5
Training loss: 3.2749968026414944
Validation loss: 2.805718215547636

Epoch: 5| Step: 6
Training loss: 3.0145405613189884
Validation loss: 2.8001382718173264

Epoch: 5| Step: 7
Training loss: 2.9933295796915265
Validation loss: 2.80165489011538

Epoch: 5| Step: 8
Training loss: 3.1881209124008145
Validation loss: 2.8012473057765335

Epoch: 5| Step: 9
Training loss: 3.721895570481961
Validation loss: 2.7995385100973325

Epoch: 5| Step: 10
Training loss: 2.8887321254386853
Validation loss: 2.8036061126091703

Epoch: 63| Step: 0
Training loss: 2.951150546953044
Validation loss: 2.8009459167862096

Epoch: 5| Step: 1
Training loss: 3.824023981170795
Validation loss: 2.8164905617796894

Epoch: 5| Step: 2
Training loss: 2.916856014826661
Validation loss: 2.814842925891662

Epoch: 5| Step: 3
Training loss: 3.6115265745822187
Validation loss: 2.821129557907724

Epoch: 5| Step: 4
Training loss: 2.244050000039982
Validation loss: 2.8037104528816905

Epoch: 5| Step: 5
Training loss: 3.6259785350873304
Validation loss: 2.800451782104927

Epoch: 5| Step: 6
Training loss: 3.215304113453685
Validation loss: 2.805038546721284

Epoch: 5| Step: 7
Training loss: 3.132770338274194
Validation loss: 2.7907875438761995

Epoch: 5| Step: 8
Training loss: 3.2963678774480982
Validation loss: 2.79321622101381

Epoch: 5| Step: 9
Training loss: 2.9649006834331013
Validation loss: 2.792660429946451

Epoch: 5| Step: 10
Training loss: 1.791031665792569
Validation loss: 2.7911071250262887

Epoch: 64| Step: 0
Training loss: 3.089153535820305
Validation loss: 2.791037842393672

Epoch: 5| Step: 1
Training loss: 3.0967636072967433
Validation loss: 2.7904725610316614

Epoch: 5| Step: 2
Training loss: 2.91283351969596
Validation loss: 2.7897305234194354

Epoch: 5| Step: 3
Training loss: 2.820997667432684
Validation loss: 2.78774475880135

Epoch: 5| Step: 4
Training loss: 3.712604477565034
Validation loss: 2.7895345582802604

Epoch: 5| Step: 5
Training loss: 3.2999454320384074
Validation loss: 2.786183784275985

Epoch: 5| Step: 6
Training loss: 3.046938851494413
Validation loss: 2.786952614763783

Epoch: 5| Step: 7
Training loss: 3.0569260924005692
Validation loss: 2.7904633766526543

Epoch: 5| Step: 8
Training loss: 2.70445280593935
Validation loss: 2.793628646623919

Epoch: 5| Step: 9
Training loss: 3.2845172419357525
Validation loss: 2.792801165628322

Epoch: 5| Step: 10
Training loss: 3.120378662997214
Validation loss: 2.790130850903901

Epoch: 65| Step: 0
Training loss: 3.2757049209577795
Validation loss: 2.7939353384953822

Epoch: 5| Step: 1
Training loss: 2.838019161372055
Validation loss: 2.7894586948282227

Epoch: 5| Step: 2
Training loss: 3.1486225689054725
Validation loss: 2.7841592072468786

Epoch: 5| Step: 3
Training loss: 3.228697876075677
Validation loss: 2.785117323235973

Epoch: 5| Step: 4
Training loss: 2.62401044449821
Validation loss: 2.787401389867361

Epoch: 5| Step: 5
Training loss: 3.206543228988207
Validation loss: 2.7866022142799363

Epoch: 5| Step: 6
Training loss: 3.2517315580018558
Validation loss: 2.786386607667943

Epoch: 5| Step: 7
Training loss: 3.4790268982244643
Validation loss: 2.7860636426509457

Epoch: 5| Step: 8
Training loss: 3.068453237942123
Validation loss: 2.7875564593389526

Epoch: 5| Step: 9
Training loss: 2.6606788962068877
Validation loss: 2.791959159220227

Epoch: 5| Step: 10
Training loss: 3.448581105237964
Validation loss: 2.797958139542479

Epoch: 66| Step: 0
Training loss: 3.3893138969888548
Validation loss: 2.7936972254025187

Epoch: 5| Step: 1
Training loss: 2.6045547094518073
Validation loss: 2.786765410774813

Epoch: 5| Step: 2
Training loss: 2.9384754265846094
Validation loss: 2.7855552377544686

Epoch: 5| Step: 3
Training loss: 3.5257695974457066
Validation loss: 2.781692527748055

Epoch: 5| Step: 4
Training loss: 3.553858129981025
Validation loss: 2.7785971953349096

Epoch: 5| Step: 5
Training loss: 2.8624201334510175
Validation loss: 2.778219290138298

Epoch: 5| Step: 6
Training loss: 3.3559773140778204
Validation loss: 2.777522809485529

Epoch: 5| Step: 7
Training loss: 2.787028193210423
Validation loss: 2.7775291319964754

Epoch: 5| Step: 8
Training loss: 3.3308796116681787
Validation loss: 2.7759433581095774

Epoch: 5| Step: 9
Training loss: 3.0208418396577885
Validation loss: 2.774084044191423

Epoch: 5| Step: 10
Training loss: 2.5570381385903906
Validation loss: 2.7768492827264906

Epoch: 67| Step: 0
Training loss: 2.955781740681704
Validation loss: 2.777393489288587

Epoch: 5| Step: 1
Training loss: 2.635534040126642
Validation loss: 2.7860590731035595

Epoch: 5| Step: 2
Training loss: 3.6618703046964907
Validation loss: 2.789906593579564

Epoch: 5| Step: 3
Training loss: 3.6064081590372314
Validation loss: 2.779110849885748

Epoch: 5| Step: 4
Training loss: 3.537654099629511
Validation loss: 2.773395875985002

Epoch: 5| Step: 5
Training loss: 2.8651483336923516
Validation loss: 2.7800178254872803

Epoch: 5| Step: 6
Training loss: 2.757502811323239
Validation loss: 2.7720338834443035

Epoch: 5| Step: 7
Training loss: 2.553127921019883
Validation loss: 2.7660271275940467

Epoch: 5| Step: 8
Training loss: 3.3210846126612865
Validation loss: 2.7679862992629096

Epoch: 5| Step: 9
Training loss: 3.185820192999602
Validation loss: 2.7664149478107083

Epoch: 5| Step: 10
Training loss: 2.6921371552668996
Validation loss: 2.7645932184728492

Epoch: 68| Step: 0
Training loss: 2.966825001666788
Validation loss: 2.7606911062909827

Epoch: 5| Step: 1
Training loss: 2.8214524942387555
Validation loss: 2.766690523964172

Epoch: 5| Step: 2
Training loss: 3.4332869634614176
Validation loss: 2.764415555537612

Epoch: 5| Step: 3
Training loss: 2.995607179922596
Validation loss: 2.7622551066281216

Epoch: 5| Step: 4
Training loss: 3.0217826316310625
Validation loss: 2.76075127667658

Epoch: 5| Step: 5
Training loss: 3.189086070667502
Validation loss: 2.758384714248131

Epoch: 5| Step: 6
Training loss: 3.3892898391866213
Validation loss: 2.7626572821001782

Epoch: 5| Step: 7
Training loss: 3.2271219650592946
Validation loss: 2.7577110814993193

Epoch: 5| Step: 8
Training loss: 2.6642283278954153
Validation loss: 2.755167209322912

Epoch: 5| Step: 9
Training loss: 3.3624402632955364
Validation loss: 2.758612115855148

Epoch: 5| Step: 10
Training loss: 2.732279208687292
Validation loss: 2.7511681940222137

Epoch: 69| Step: 0
Training loss: 3.3554030957088274
Validation loss: 2.750122733188026

Epoch: 5| Step: 1
Training loss: 3.2734562911994205
Validation loss: 2.7484309436388044

Epoch: 5| Step: 2
Training loss: 3.0474458599836107
Validation loss: 2.748265831783394

Epoch: 5| Step: 3
Training loss: 3.2513045113762877
Validation loss: 2.750559081581388

Epoch: 5| Step: 4
Training loss: 2.8271927956904364
Validation loss: 2.7522611970267667

Epoch: 5| Step: 5
Training loss: 2.94470516186178
Validation loss: 2.746209882288529

Epoch: 5| Step: 6
Training loss: 3.0062405528596203
Validation loss: 2.7447403010628113

Epoch: 5| Step: 7
Training loss: 3.250247212324494
Validation loss: 2.7467534440052015

Epoch: 5| Step: 8
Training loss: 3.211928759895303
Validation loss: 2.7452570434753563

Epoch: 5| Step: 9
Training loss: 2.4458543463545706
Validation loss: 2.7509193915803682

Epoch: 5| Step: 10
Training loss: 3.186131800797133
Validation loss: 2.7472846785474294

Epoch: 70| Step: 0
Training loss: 3.3458276871332306
Validation loss: 2.7464850065934714

Epoch: 5| Step: 1
Training loss: 2.5310588811614014
Validation loss: 2.7476737278383028

Epoch: 5| Step: 2
Training loss: 2.987036671482663
Validation loss: 2.7456833323793948

Epoch: 5| Step: 3
Training loss: 3.442303716954787
Validation loss: 2.750259210073462

Epoch: 5| Step: 4
Training loss: 2.8468657810635585
Validation loss: 2.747501616236523

Epoch: 5| Step: 5
Training loss: 3.008093565652378
Validation loss: 2.743694408252633

Epoch: 5| Step: 6
Training loss: 2.7083201677051294
Validation loss: 2.743658412137539

Epoch: 5| Step: 7
Training loss: 3.1359020039175056
Validation loss: 2.7456002991763295

Epoch: 5| Step: 8
Training loss: 2.7914369877709144
Validation loss: 2.7495862364278882

Epoch: 5| Step: 9
Training loss: 3.1867854495501957
Validation loss: 2.7485996532922834

Epoch: 5| Step: 10
Training loss: 3.74687840554637
Validation loss: 2.74362393394967

Epoch: 71| Step: 0
Training loss: 2.920707591819842
Validation loss: 2.7381056286798047

Epoch: 5| Step: 1
Training loss: 3.2616171449837057
Validation loss: 2.743129915477651

Epoch: 5| Step: 2
Training loss: 2.9821508617962653
Validation loss: 2.744391861696476

Epoch: 5| Step: 3
Training loss: 3.617777238726543
Validation loss: 2.7415995002920135

Epoch: 5| Step: 4
Training loss: 2.9022448434316472
Validation loss: 2.742848822361145

Epoch: 5| Step: 5
Training loss: 3.597898791956645
Validation loss: 2.7423183327096736

Epoch: 5| Step: 6
Training loss: 2.73734997900008
Validation loss: 2.739611695980822

Epoch: 5| Step: 7
Training loss: 2.4505550261870983
Validation loss: 2.7407372739958347

Epoch: 5| Step: 8
Training loss: 2.584326850414899
Validation loss: 2.738363130799406

Epoch: 5| Step: 9
Training loss: 3.397752855111228
Validation loss: 2.737437384981209

Epoch: 5| Step: 10
Training loss: 3.118173084909042
Validation loss: 2.736754758367618

Epoch: 72| Step: 0
Training loss: 2.9812562634544233
Validation loss: 2.7354124514743305

Epoch: 5| Step: 1
Training loss: 3.088213812595742
Validation loss: 2.7354199495680027

Epoch: 5| Step: 2
Training loss: 3.2269106623976596
Validation loss: 2.736058504526031

Epoch: 5| Step: 3
Training loss: 2.632666337571647
Validation loss: 2.7362394918214332

Epoch: 5| Step: 4
Training loss: 3.2226602450259327
Validation loss: 2.7335752568704943

Epoch: 5| Step: 5
Training loss: 3.108441696800773
Validation loss: 2.7298832334434135

Epoch: 5| Step: 6
Training loss: 3.1634000861866407
Validation loss: 2.7283990778293936

Epoch: 5| Step: 7
Training loss: 3.3505351308174336
Validation loss: 2.729229449542828

Epoch: 5| Step: 8
Training loss: 3.0753734702977984
Validation loss: 2.731079416346797

Epoch: 5| Step: 9
Training loss: 2.949383176552573
Validation loss: 2.729405559337899

Epoch: 5| Step: 10
Training loss: 2.8129238233181884
Validation loss: 2.728447266422342

Epoch: 73| Step: 0
Training loss: 2.745198132255549
Validation loss: 2.7284441516567894

Epoch: 5| Step: 1
Training loss: 2.744504813466826
Validation loss: 2.7258774444204796

Epoch: 5| Step: 2
Training loss: 3.379374459522191
Validation loss: 2.728789205655586

Epoch: 5| Step: 3
Training loss: 3.7924510158526243
Validation loss: 2.7289622033831717

Epoch: 5| Step: 4
Training loss: 2.9889647655790537
Validation loss: 2.724198907060428

Epoch: 5| Step: 5
Training loss: 2.776032858733804
Validation loss: 2.721573580417043

Epoch: 5| Step: 6
Training loss: 2.7263932052563455
Validation loss: 2.724176271597126

Epoch: 5| Step: 7
Training loss: 2.408501698593735
Validation loss: 2.725591782278405

Epoch: 5| Step: 8
Training loss: 3.576820635531596
Validation loss: 2.728680926653279

Epoch: 5| Step: 9
Training loss: 3.314970139128772
Validation loss: 2.728735989747958

Epoch: 5| Step: 10
Training loss: 2.9743392531139996
Validation loss: 2.738410589834599

Epoch: 74| Step: 0
Training loss: 3.1638543708071163
Validation loss: 2.7395526474553162

Epoch: 5| Step: 1
Training loss: 3.1235111504592803
Validation loss: 2.727070869234255

Epoch: 5| Step: 2
Training loss: 3.02260812823141
Validation loss: 2.718824494722352

Epoch: 5| Step: 3
Training loss: 2.6931756878817095
Validation loss: 2.7201411368360713

Epoch: 5| Step: 4
Training loss: 3.2235550060664746
Validation loss: 2.718137504014988

Epoch: 5| Step: 5
Training loss: 2.8524118491083286
Validation loss: 2.7237226296035844

Epoch: 5| Step: 6
Training loss: 2.932789210947007
Validation loss: 2.7438679134803388

Epoch: 5| Step: 7
Training loss: 3.141231649081831
Validation loss: 2.7530105273329384

Epoch: 5| Step: 8
Training loss: 3.106833334478227
Validation loss: 2.7692503501829813

Epoch: 5| Step: 9
Training loss: 3.3165941668179126
Validation loss: 2.7762847294066293

Epoch: 5| Step: 10
Training loss: 3.057287334241944
Validation loss: 2.7313350147354063

Epoch: 75| Step: 0
Training loss: 2.801183270021752
Validation loss: 2.7189589361091344

Epoch: 5| Step: 1
Training loss: 3.589632279203866
Validation loss: 2.714689873021505

Epoch: 5| Step: 2
Training loss: 2.6934976410870504
Validation loss: 2.7152269748184197

Epoch: 5| Step: 3
Training loss: 2.8725804638196237
Validation loss: 2.7215267904815397

Epoch: 5| Step: 4
Training loss: 3.1863327881214345
Validation loss: 2.722883413599016

Epoch: 5| Step: 5
Training loss: 2.98503289286064
Validation loss: 2.7261341690663006

Epoch: 5| Step: 6
Training loss: 3.4006712138774926
Validation loss: 2.725716483574373

Epoch: 5| Step: 7
Training loss: 3.0946199369253913
Validation loss: 2.7225407928888297

Epoch: 5| Step: 8
Training loss: 2.8919771898037534
Validation loss: 2.7185451801466924

Epoch: 5| Step: 9
Training loss: 3.06361913668469
Validation loss: 2.719698850576288

Epoch: 5| Step: 10
Training loss: 2.9070927208232247
Validation loss: 2.7168315681383297

Epoch: 76| Step: 0
Training loss: 3.3774393943922916
Validation loss: 2.72041121911442

Epoch: 5| Step: 1
Training loss: 2.720194378106351
Validation loss: 2.717066647159578

Epoch: 5| Step: 2
Training loss: 3.5687872301821977
Validation loss: 2.7106009526189188

Epoch: 5| Step: 3
Training loss: 2.7026589934577787
Validation loss: 2.7080054382034775

Epoch: 5| Step: 4
Training loss: 3.5313369605235585
Validation loss: 2.7038277765138354

Epoch: 5| Step: 5
Training loss: 2.9382182115782514
Validation loss: 2.7134243018609006

Epoch: 5| Step: 6
Training loss: 3.3795361587705344
Validation loss: 2.741573712275219

Epoch: 5| Step: 7
Training loss: 2.5701694622647553
Validation loss: 2.751454281097195

Epoch: 5| Step: 8
Training loss: 2.3919417800133407
Validation loss: 2.776076843325745

Epoch: 5| Step: 9
Training loss: 2.9662553444937596
Validation loss: 2.794486015427754

Epoch: 5| Step: 10
Training loss: 3.2857243140879113
Validation loss: 2.76541781346081

Epoch: 77| Step: 0
Training loss: 3.2845271139734495
Validation loss: 2.739595052362708

Epoch: 5| Step: 1
Training loss: 2.7483837406524163
Validation loss: 2.7121778577852202

Epoch: 5| Step: 2
Training loss: 2.750070224212128
Validation loss: 2.7048219391181734

Epoch: 5| Step: 3
Training loss: 3.363245238356132
Validation loss: 2.7041386862354067

Epoch: 5| Step: 4
Training loss: 3.0502832375009854
Validation loss: 2.708371825847851

Epoch: 5| Step: 5
Training loss: 2.7357706050631934
Validation loss: 2.7114512069206542

Epoch: 5| Step: 6
Training loss: 3.2872634280411592
Validation loss: 2.7123196863229713

Epoch: 5| Step: 7
Training loss: 3.1649866332243444
Validation loss: 2.715177978471133

Epoch: 5| Step: 8
Training loss: 3.3754190255466745
Validation loss: 2.7195274270256964

Epoch: 5| Step: 9
Training loss: 2.3402808390923413
Validation loss: 2.715636967446971

Epoch: 5| Step: 10
Training loss: 3.4014559265179294
Validation loss: 2.706782769095321

Epoch: 78| Step: 0
Training loss: 3.371558094423085
Validation loss: 2.703635522310144

Epoch: 5| Step: 1
Training loss: 3.0091302536485274
Validation loss: 2.703560162442388

Epoch: 5| Step: 2
Training loss: 3.150758857751527
Validation loss: 2.69773304119142

Epoch: 5| Step: 3
Training loss: 2.880264438039019
Validation loss: 2.6978728600868123

Epoch: 5| Step: 4
Training loss: 3.4331233512836956
Validation loss: 2.700423196899385

Epoch: 5| Step: 5
Training loss: 2.8366232639254143
Validation loss: 2.70052568558624

Epoch: 5| Step: 6
Training loss: 3.6924808290432005
Validation loss: 2.704414283555116

Epoch: 5| Step: 7
Training loss: 2.462696137338519
Validation loss: 2.701449202266078

Epoch: 5| Step: 8
Training loss: 3.006899370575621
Validation loss: 2.7087961106003564

Epoch: 5| Step: 9
Training loss: 2.697568441376538
Validation loss: 2.712629646366118

Epoch: 5| Step: 10
Training loss: 2.614334692410605
Validation loss: 2.717167836303356

Epoch: 79| Step: 0
Training loss: 2.829647939775146
Validation loss: 2.711178332391219

Epoch: 5| Step: 1
Training loss: 3.2446341601373
Validation loss: 2.7057631692006527

Epoch: 5| Step: 2
Training loss: 3.514584671379035
Validation loss: 2.6975201877523345

Epoch: 5| Step: 3
Training loss: 2.697549173863223
Validation loss: 2.691302273811815

Epoch: 5| Step: 4
Training loss: 2.6777669625000122
Validation loss: 2.6925374349311415

Epoch: 5| Step: 5
Training loss: 3.051539992226501
Validation loss: 2.6970438585699004

Epoch: 5| Step: 6
Training loss: 3.157175211749894
Validation loss: 2.700862868596631

Epoch: 5| Step: 7
Training loss: 3.1514022915034294
Validation loss: 2.6979701026232936

Epoch: 5| Step: 8
Training loss: 2.9243157132476427
Validation loss: 2.6992145026191823

Epoch: 5| Step: 9
Training loss: 3.292786580722553
Validation loss: 2.7014314485557485

Epoch: 5| Step: 10
Training loss: 2.856487379497931
Validation loss: 2.7006977352571595

Epoch: 80| Step: 0
Training loss: 3.102053817154287
Validation loss: 2.7048917752473733

Epoch: 5| Step: 1
Training loss: 3.024071757499619
Validation loss: 2.6993170989310866

Epoch: 5| Step: 2
Training loss: 2.9939157459989794
Validation loss: 2.6972971135258996

Epoch: 5| Step: 3
Training loss: 2.534822462587784
Validation loss: 2.701352688546752

Epoch: 5| Step: 4
Training loss: 2.771293735735453
Validation loss: 2.6997187725483487

Epoch: 5| Step: 5
Training loss: 2.9852137160990893
Validation loss: 2.700664706808049

Epoch: 5| Step: 6
Training loss: 2.6643312380205906
Validation loss: 2.6969947334072137

Epoch: 5| Step: 7
Training loss: 3.37444004075996
Validation loss: 2.6965621279480456

Epoch: 5| Step: 8
Training loss: 3.3911720221356836
Validation loss: 2.695144816933032

Epoch: 5| Step: 9
Training loss: 3.242531190603059
Validation loss: 2.69080114171215

Epoch: 5| Step: 10
Training loss: 3.2579265181168116
Validation loss: 2.6926574461032393

Epoch: 81| Step: 0
Training loss: 2.8280769470516223
Validation loss: 2.6918957697880783

Epoch: 5| Step: 1
Training loss: 2.830650592872717
Validation loss: 2.6956281655776513

Epoch: 5| Step: 2
Training loss: 2.9424435836841565
Validation loss: 2.7006505912328063

Epoch: 5| Step: 3
Training loss: 3.090069363503779
Validation loss: 2.733904692581913

Epoch: 5| Step: 4
Training loss: 3.149075502635856
Validation loss: 2.71308509591912

Epoch: 5| Step: 5
Training loss: 3.3775639155373565
Validation loss: 2.7083456476150887

Epoch: 5| Step: 6
Training loss: 2.5972110682319944
Validation loss: 2.7020787667110735

Epoch: 5| Step: 7
Training loss: 2.723806830448365
Validation loss: 2.701535059567012

Epoch: 5| Step: 8
Training loss: 2.643674274920229
Validation loss: 2.692090846945479

Epoch: 5| Step: 9
Training loss: 3.6282085819786136
Validation loss: 2.69305273449413

Epoch: 5| Step: 10
Training loss: 3.454506438094299
Validation loss: 2.687155457046071

Epoch: 82| Step: 0
Training loss: 2.6764004401623227
Validation loss: 2.6808750067722897

Epoch: 5| Step: 1
Training loss: 3.0581687349380413
Validation loss: 2.6785024089290648

Epoch: 5| Step: 2
Training loss: 2.5692582678717972
Validation loss: 2.678342650781371

Epoch: 5| Step: 3
Training loss: 3.6712217358549015
Validation loss: 2.676805110120151

Epoch: 5| Step: 4
Training loss: 3.34289539860225
Validation loss: 2.679994060758947

Epoch: 5| Step: 5
Training loss: 3.2364238938945684
Validation loss: 2.677636950964239

Epoch: 5| Step: 6
Training loss: 3.170302428732001
Validation loss: 2.6782820829811027

Epoch: 5| Step: 7
Training loss: 3.0211505767157556
Validation loss: 2.676118866504706

Epoch: 5| Step: 8
Training loss: 2.618523737708216
Validation loss: 2.6752506509369587

Epoch: 5| Step: 9
Training loss: 3.169645079951591
Validation loss: 2.676570808000211

Epoch: 5| Step: 10
Training loss: 2.4136982368280417
Validation loss: 2.6846049665949723

Epoch: 83| Step: 0
Training loss: 2.5640270986211084
Validation loss: 2.6758014100646683

Epoch: 5| Step: 1
Training loss: 3.102917891522159
Validation loss: 2.673057516595874

Epoch: 5| Step: 2
Training loss: 3.3639975747497743
Validation loss: 2.673406008193198

Epoch: 5| Step: 3
Training loss: 3.253587356822706
Validation loss: 2.6793293874645343

Epoch: 5| Step: 4
Training loss: 3.1168042858019898
Validation loss: 2.686840198641643

Epoch: 5| Step: 5
Training loss: 3.3053019788772438
Validation loss: 2.6933770067813856

Epoch: 5| Step: 6
Training loss: 3.2636081728148776
Validation loss: 2.686029707863602

Epoch: 5| Step: 7
Training loss: 2.987312508928548
Validation loss: 2.680662846028427

Epoch: 5| Step: 8
Training loss: 2.322181437051574
Validation loss: 2.6812522536507166

Epoch: 5| Step: 9
Training loss: 2.9148800600479827
Validation loss: 2.676840238250145

Epoch: 5| Step: 10
Training loss: 2.99353347664282
Validation loss: 2.677076430128494

Epoch: 84| Step: 0
Training loss: 3.704518116490029
Validation loss: 2.665773108064602

Epoch: 5| Step: 1
Training loss: 3.2052628988671885
Validation loss: 2.667533005710902

Epoch: 5| Step: 2
Training loss: 2.9390399224216703
Validation loss: 2.673298682237157

Epoch: 5| Step: 3
Training loss: 2.654628303500988
Validation loss: 2.67507938826511

Epoch: 5| Step: 4
Training loss: 3.334964940974903
Validation loss: 2.683455527714422

Epoch: 5| Step: 5
Training loss: 3.1045781999920252
Validation loss: 2.673575261807961

Epoch: 5| Step: 6
Training loss: 2.705107210188854
Validation loss: 2.6823119281720764

Epoch: 5| Step: 7
Training loss: 2.53621760694067
Validation loss: 2.6716045834562583

Epoch: 5| Step: 8
Training loss: 3.04958860405657
Validation loss: 2.6724649164405743

Epoch: 5| Step: 9
Training loss: 2.7976213876469034
Validation loss: 2.6693608184141246

Epoch: 5| Step: 10
Training loss: 3.1436945400313543
Validation loss: 2.6729247074848517

Epoch: 85| Step: 0
Training loss: 3.2384806204647845
Validation loss: 2.6785373932472587

Epoch: 5| Step: 1
Training loss: 2.787535519223936
Validation loss: 2.684644084532692

Epoch: 5| Step: 2
Training loss: 3.5065180167781467
Validation loss: 2.6934653733530443

Epoch: 5| Step: 3
Training loss: 2.9608898309982075
Validation loss: 2.676878411399979

Epoch: 5| Step: 4
Training loss: 2.9577427843263964
Validation loss: 2.673768437716201

Epoch: 5| Step: 5
Training loss: 2.885220811350324
Validation loss: 2.6806318162532334

Epoch: 5| Step: 6
Training loss: 3.052753431342473
Validation loss: 2.684325959259065

Epoch: 5| Step: 7
Training loss: 2.800704720913352
Validation loss: 2.695787829407359

Epoch: 5| Step: 8
Training loss: 3.240771027882651
Validation loss: 2.6915701465552337

Epoch: 5| Step: 9
Training loss: 3.2398392227689463
Validation loss: 2.6793434249596677

Epoch: 5| Step: 10
Training loss: 2.320829699894123
Validation loss: 2.668150939279552

Epoch: 86| Step: 0
Training loss: 3.120029158089177
Validation loss: 2.667516321778402

Epoch: 5| Step: 1
Training loss: 3.0321400702237593
Validation loss: 2.663277311821534

Epoch: 5| Step: 2
Training loss: 2.749908272340483
Validation loss: 2.6616063160020578

Epoch: 5| Step: 3
Training loss: 2.661669598957788
Validation loss: 2.6610820783565816

Epoch: 5| Step: 4
Training loss: 3.6277831344474074
Validation loss: 2.6648081189936272

Epoch: 5| Step: 5
Training loss: 2.9144592833188687
Validation loss: 2.6644301319158976

Epoch: 5| Step: 6
Training loss: 2.7522903788034703
Validation loss: 2.67050694874605

Epoch: 5| Step: 7
Training loss: 2.549150445077376
Validation loss: 2.6843494703489017

Epoch: 5| Step: 8
Training loss: 3.3711228883264166
Validation loss: 2.674402406559922

Epoch: 5| Step: 9
Training loss: 3.2870509141878803
Validation loss: 2.6674710958794146

Epoch: 5| Step: 10
Training loss: 2.828847887584935
Validation loss: 2.6579515299917658

Epoch: 87| Step: 0
Training loss: 2.9833106894317485
Validation loss: 2.6551968633635177

Epoch: 5| Step: 1
Training loss: 2.9839042571920547
Validation loss: 2.6542310885175078

Epoch: 5| Step: 2
Training loss: 2.789739275546176
Validation loss: 2.6523319096539355

Epoch: 5| Step: 3
Training loss: 3.2762541022305967
Validation loss: 2.657346816786276

Epoch: 5| Step: 4
Training loss: 3.076547751093472
Validation loss: 2.657720005819802

Epoch: 5| Step: 5
Training loss: 2.7882620039361425
Validation loss: 2.661347071532635

Epoch: 5| Step: 6
Training loss: 3.021147893554131
Validation loss: 2.6604690699106293

Epoch: 5| Step: 7
Training loss: 3.0084044035092274
Validation loss: 2.658039018965369

Epoch: 5| Step: 8
Training loss: 2.9065339964882053
Validation loss: 2.6578183036444183

Epoch: 5| Step: 9
Training loss: 3.3311739284854656
Validation loss: 2.6569424039833374

Epoch: 5| Step: 10
Training loss: 2.8183038802575227
Validation loss: 2.6544435529342323

Epoch: 88| Step: 0
Training loss: 2.7522360640678984
Validation loss: 2.6584924139606483

Epoch: 5| Step: 1
Training loss: 3.2484850653853616
Validation loss: 2.6612596441087324

Epoch: 5| Step: 2
Training loss: 3.2879092987897143
Validation loss: 2.6610901023596125

Epoch: 5| Step: 3
Training loss: 2.7998394307008962
Validation loss: 2.6780792521893817

Epoch: 5| Step: 4
Training loss: 3.499879834973328
Validation loss: 2.6907288723639846

Epoch: 5| Step: 5
Training loss: 2.7483522507120774
Validation loss: 2.6980446171341232

Epoch: 5| Step: 6
Training loss: 3.0230728442078134
Validation loss: 2.6952015739063273

Epoch: 5| Step: 7
Training loss: 2.856084879770575
Validation loss: 2.6763967389544927

Epoch: 5| Step: 8
Training loss: 3.2878247466891244
Validation loss: 2.663566008289787

Epoch: 5| Step: 9
Training loss: 2.4800861694378513
Validation loss: 2.6511096223182906

Epoch: 5| Step: 10
Training loss: 2.8872717300615975
Validation loss: 2.6549158692101082

Epoch: 89| Step: 0
Training loss: 2.6511261832224577
Validation loss: 2.652015659097905

Epoch: 5| Step: 1
Training loss: 2.9468462363140895
Validation loss: 2.65560066543211

Epoch: 5| Step: 2
Training loss: 3.0790984652497904
Validation loss: 2.655715936950478

Epoch: 5| Step: 3
Training loss: 2.8053951805111965
Validation loss: 2.658419031960672

Epoch: 5| Step: 4
Training loss: 3.1746550905811537
Validation loss: 2.6543990459633795

Epoch: 5| Step: 5
Training loss: 3.442416195538486
Validation loss: 2.655539207253998

Epoch: 5| Step: 6
Training loss: 2.9940170391976495
Validation loss: 2.647779926065559

Epoch: 5| Step: 7
Training loss: 3.18725734609849
Validation loss: 2.649626176873444

Epoch: 5| Step: 8
Training loss: 2.3355085814801626
Validation loss: 2.6453150964418475

Epoch: 5| Step: 9
Training loss: 3.474093471264485
Validation loss: 2.643491411174784

Epoch: 5| Step: 10
Training loss: 2.6968946153407
Validation loss: 2.6540589244371593

Epoch: 90| Step: 0
Training loss: 3.1813723437573325
Validation loss: 2.6923628537221145

Epoch: 5| Step: 1
Training loss: 3.141332745872058
Validation loss: 2.7152730443445137

Epoch: 5| Step: 2
Training loss: 2.72448878961428
Validation loss: 2.782295378092522

Epoch: 5| Step: 3
Training loss: 3.0609723387561623
Validation loss: 2.8000110371470277

Epoch: 5| Step: 4
Training loss: 3.1190479816587704
Validation loss: 2.7845798813010556

Epoch: 5| Step: 5
Training loss: 3.084083637671857
Validation loss: 2.793037965460306

Epoch: 5| Step: 6
Training loss: 2.8880021026159857
Validation loss: 2.7346054191015163

Epoch: 5| Step: 7
Training loss: 3.0537788620223902
Validation loss: 2.674348554658921

Epoch: 5| Step: 8
Training loss: 2.546072336102752
Validation loss: 2.649895874906319

Epoch: 5| Step: 9
Training loss: 2.759381158806742
Validation loss: 2.6519635276670215

Epoch: 5| Step: 10
Training loss: 3.718165888712978
Validation loss: 2.6606904720162197

Epoch: 91| Step: 0
Training loss: 2.393124837887814
Validation loss: 2.6601270048508234

Epoch: 5| Step: 1
Training loss: 3.0521323207703843
Validation loss: 2.6661468840157245

Epoch: 5| Step: 2
Training loss: 3.5130216326570083
Validation loss: 2.660950029983738

Epoch: 5| Step: 3
Training loss: 3.0138399048871256
Validation loss: 2.6550837572674677

Epoch: 5| Step: 4
Training loss: 2.8295358753077013
Validation loss: 2.650221393954657

Epoch: 5| Step: 5
Training loss: 2.802680867711151
Validation loss: 2.6482899366665458

Epoch: 5| Step: 6
Training loss: 3.0914310279838446
Validation loss: 2.644546464879396

Epoch: 5| Step: 7
Training loss: 2.3043752685083203
Validation loss: 2.6445621944231172

Epoch: 5| Step: 8
Training loss: 3.44431904766202
Validation loss: 2.6446672259417525

Epoch: 5| Step: 9
Training loss: 3.034745864911856
Validation loss: 2.642905936347206

Epoch: 5| Step: 10
Training loss: 3.3577263623563627
Validation loss: 2.639445517712916

Epoch: 92| Step: 0
Training loss: 2.7145343412095033
Validation loss: 2.643467562876669

Epoch: 5| Step: 1
Training loss: 3.302941693116153
Validation loss: 2.641511693851978

Epoch: 5| Step: 2
Training loss: 2.96273644385014
Validation loss: 2.6365808083970506

Epoch: 5| Step: 3
Training loss: 2.5814805821470355
Validation loss: 2.63831046118738

Epoch: 5| Step: 4
Training loss: 3.0852153464265153
Validation loss: 2.6348242829381134

Epoch: 5| Step: 5
Training loss: 2.912634778485665
Validation loss: 2.635759914862454

Epoch: 5| Step: 6
Training loss: 3.4184012003212003
Validation loss: 2.6354372934155745

Epoch: 5| Step: 7
Training loss: 2.4901899505841385
Validation loss: 2.6378718333483526

Epoch: 5| Step: 8
Training loss: 2.9418196064758795
Validation loss: 2.636093781912495

Epoch: 5| Step: 9
Training loss: 2.777343921688198
Validation loss: 2.6410861689347285

Epoch: 5| Step: 10
Training loss: 3.6060401736458445
Validation loss: 2.649943550392453

Epoch: 93| Step: 0
Training loss: 2.8724425177470883
Validation loss: 2.6606541603815996

Epoch: 5| Step: 1
Training loss: 2.9701371014222757
Validation loss: 2.669874143372967

Epoch: 5| Step: 2
Training loss: 2.6725934942037126
Validation loss: 2.6749995533610536

Epoch: 5| Step: 3
Training loss: 3.1572199171558584
Validation loss: 2.6632413945073155

Epoch: 5| Step: 4
Training loss: 3.003510487532591
Validation loss: 2.640611304237735

Epoch: 5| Step: 5
Training loss: 3.158171418266165
Validation loss: 2.629175434910817

Epoch: 5| Step: 6
Training loss: 3.117650353814182
Validation loss: 2.6339478808629333

Epoch: 5| Step: 7
Training loss: 2.8797947251491003
Validation loss: 2.6298263400748727

Epoch: 5| Step: 8
Training loss: 2.8531875787329573
Validation loss: 2.63088246838665

Epoch: 5| Step: 9
Training loss: 3.325880413087001
Validation loss: 2.6367540436892667

Epoch: 5| Step: 10
Training loss: 2.6925272385716807
Validation loss: 2.6339719438287874

Epoch: 94| Step: 0
Training loss: 2.9982682634056785
Validation loss: 2.6334794243719797

Epoch: 5| Step: 1
Training loss: 2.877596801932506
Validation loss: 2.6381985026992503

Epoch: 5| Step: 2
Training loss: 3.0208388405234463
Validation loss: 2.6398830372620115

Epoch: 5| Step: 3
Training loss: 3.0730468377597875
Validation loss: 2.6357747553334985

Epoch: 5| Step: 4
Training loss: 2.4537923111768
Validation loss: 2.6331761346607814

Epoch: 5| Step: 5
Training loss: 3.2901777610178877
Validation loss: 2.6327288379937666

Epoch: 5| Step: 6
Training loss: 2.914726283994418
Validation loss: 2.634746043197724

Epoch: 5| Step: 7
Training loss: 3.0889338758411204
Validation loss: 2.6456331567001006

Epoch: 5| Step: 8
Training loss: 3.223702777518163
Validation loss: 2.654912525264933

Epoch: 5| Step: 9
Training loss: 3.2597430978662896
Validation loss: 2.655403295660729

Epoch: 5| Step: 10
Training loss: 2.4776943761058825
Validation loss: 2.6551734706879

Epoch: 95| Step: 0
Training loss: 2.612518609815689
Validation loss: 2.6440818049530885

Epoch: 5| Step: 1
Training loss: 2.951441855360483
Validation loss: 2.6366962687431434

Epoch: 5| Step: 2
Training loss: 2.663912682222039
Validation loss: 2.6352293992174087

Epoch: 5| Step: 3
Training loss: 3.3186775041553696
Validation loss: 2.632333688523785

Epoch: 5| Step: 4
Training loss: 2.8088203094741226
Validation loss: 2.6267633633903245

Epoch: 5| Step: 5
Training loss: 3.0200337020307186
Validation loss: 2.621535961566913

Epoch: 5| Step: 6
Training loss: 3.151554807805824
Validation loss: 2.6209381719014466

Epoch: 5| Step: 7
Training loss: 3.068442981535198
Validation loss: 2.6152521315839863

Epoch: 5| Step: 8
Training loss: 3.078529137740376
Validation loss: 2.614424751968995

Epoch: 5| Step: 9
Training loss: 2.93387103643341
Validation loss: 2.6181473440137175

Epoch: 5| Step: 10
Training loss: 3.07383312632631
Validation loss: 2.614145066114266

Epoch: 96| Step: 0
Training loss: 2.654141385743027
Validation loss: 2.6193073163960525

Epoch: 5| Step: 1
Training loss: 3.2686493662994156
Validation loss: 2.6172792049155555

Epoch: 5| Step: 2
Training loss: 3.195570657836192
Validation loss: 2.6165311462655256

Epoch: 5| Step: 3
Training loss: 2.931150350930628
Validation loss: 2.616365361218982

Epoch: 5| Step: 4
Training loss: 3.035609777238426
Validation loss: 2.6163288905284796

Epoch: 5| Step: 5
Training loss: 3.1786960865148473
Validation loss: 2.6148540567642096

Epoch: 5| Step: 6
Training loss: 2.9073590859323213
Validation loss: 2.6149239123196995

Epoch: 5| Step: 7
Training loss: 2.6626402338913002
Validation loss: 2.6202947379465913

Epoch: 5| Step: 8
Training loss: 2.993517229113769
Validation loss: 2.6114281474833483

Epoch: 5| Step: 9
Training loss: 3.206647025171771
Validation loss: 2.6121319211976117

Epoch: 5| Step: 10
Training loss: 2.473239438193163
Validation loss: 2.6130020676969297

Epoch: 97| Step: 0
Training loss: 2.801816187795929
Validation loss: 2.6120133315784493

Epoch: 5| Step: 1
Training loss: 2.846937468227577
Validation loss: 2.608851574279212

Epoch: 5| Step: 2
Training loss: 3.2008810976081867
Validation loss: 2.6068171529754514

Epoch: 5| Step: 3
Training loss: 2.9568293513884805
Validation loss: 2.6095967308185264

Epoch: 5| Step: 4
Training loss: 3.303674998187979
Validation loss: 2.6090601828865183

Epoch: 5| Step: 5
Training loss: 2.96446191392079
Validation loss: 2.618108982351141

Epoch: 5| Step: 6
Training loss: 2.7475516951525045
Validation loss: 2.623073185189289

Epoch: 5| Step: 7
Training loss: 2.6225474571683347
Validation loss: 2.631683933447391

Epoch: 5| Step: 8
Training loss: 3.1875092749367204
Validation loss: 2.6367322958321404

Epoch: 5| Step: 9
Training loss: 3.1339150483985065
Validation loss: 2.6208017219358504

Epoch: 5| Step: 10
Training loss: 2.7894002245139204
Validation loss: 2.607601414579302

Epoch: 98| Step: 0
Training loss: 2.250905172742665
Validation loss: 2.6019882666229397

Epoch: 5| Step: 1
Training loss: 2.421232470526233
Validation loss: 2.607428758437073

Epoch: 5| Step: 2
Training loss: 3.66735574720734
Validation loss: 2.609090886728362

Epoch: 5| Step: 3
Training loss: 2.930350999085986
Validation loss: 2.608481042002933

Epoch: 5| Step: 4
Training loss: 2.4868103183062877
Validation loss: 2.6098618996598093

Epoch: 5| Step: 5
Training loss: 2.5351406384944015
Validation loss: 2.6063423535212906

Epoch: 5| Step: 6
Training loss: 3.3185665791143393
Validation loss: 2.6047393884406764

Epoch: 5| Step: 7
Training loss: 2.8720349488323524
Validation loss: 2.606593796979526

Epoch: 5| Step: 8
Training loss: 2.961892328833467
Validation loss: 2.6058558744850537

Epoch: 5| Step: 9
Training loss: 3.724097118147961
Validation loss: 2.6083285270907948

Epoch: 5| Step: 10
Training loss: 3.062344294112534
Validation loss: 2.6044761096497417

Epoch: 99| Step: 0
Training loss: 2.843668506837994
Validation loss: 2.6126453728376022

Epoch: 5| Step: 1
Training loss: 2.3996226212714826
Validation loss: 2.6164916223787906

Epoch: 5| Step: 2
Training loss: 3.65703619956839
Validation loss: 2.6241717968205833

Epoch: 5| Step: 3
Training loss: 3.0080415712791364
Validation loss: 2.6362015402025385

Epoch: 5| Step: 4
Training loss: 3.184551895214683
Validation loss: 2.66166387001573

Epoch: 5| Step: 5
Training loss: 2.9135867796701125
Validation loss: 2.6575486716417025

Epoch: 5| Step: 6
Training loss: 2.4186775019226694
Validation loss: 2.6419021577047963

Epoch: 5| Step: 7
Training loss: 3.1500153859080626
Validation loss: 2.6290198904038857

Epoch: 5| Step: 8
Training loss: 3.2186234828935474
Validation loss: 2.61516199072497

Epoch: 5| Step: 9
Training loss: 2.6928166872478725
Validation loss: 2.598729913292761

Epoch: 5| Step: 10
Training loss: 2.8221698256340346
Validation loss: 2.5968745715147348

Epoch: 100| Step: 0
Training loss: 2.934902584922266
Validation loss: 2.599882001463097

Epoch: 5| Step: 1
Training loss: 2.9325918221305622
Validation loss: 2.597051814683373

Epoch: 5| Step: 2
Training loss: 3.4717641570683755
Validation loss: 2.596117167787386

Epoch: 5| Step: 3
Training loss: 2.8176259271461013
Validation loss: 2.5941369234748874

Epoch: 5| Step: 4
Training loss: 2.933684935593897
Validation loss: 2.5937421689617666

Epoch: 5| Step: 5
Training loss: 3.0598626750475137
Validation loss: 2.5946745516402783

Epoch: 5| Step: 6
Training loss: 2.777213435596535
Validation loss: 2.5935090298138976

Epoch: 5| Step: 7
Training loss: 2.729169326276187
Validation loss: 2.5925011947676073

Epoch: 5| Step: 8
Training loss: 2.704790429195789
Validation loss: 2.5943503052697645

Epoch: 5| Step: 9
Training loss: 3.059557532689556
Validation loss: 2.5916760966529004

Epoch: 5| Step: 10
Training loss: 3.0380352412095313
Validation loss: 2.59473359323777

Epoch: 101| Step: 0
Training loss: 2.9524742095621908
Validation loss: 2.5936352817722548

Epoch: 5| Step: 1
Training loss: 2.6013816793567828
Validation loss: 2.605703860183892

Epoch: 5| Step: 2
Training loss: 2.473592716438753
Validation loss: 2.5987049912862084

Epoch: 5| Step: 3
Training loss: 2.5171180227720678
Validation loss: 2.6046179700720327

Epoch: 5| Step: 4
Training loss: 3.0016532157442657
Validation loss: 2.617371703907856

Epoch: 5| Step: 5
Training loss: 3.5733354654827685
Validation loss: 2.5968506919677097

Epoch: 5| Step: 6
Training loss: 3.1004410645288356
Validation loss: 2.591491287032592

Epoch: 5| Step: 7
Training loss: 3.428198558536318
Validation loss: 2.5898369772160574

Epoch: 5| Step: 8
Training loss: 2.916005486523735
Validation loss: 2.594341858439827

Epoch: 5| Step: 9
Training loss: 3.0610954021951575
Validation loss: 2.599361238430784

Epoch: 5| Step: 10
Training loss: 2.732169607977175
Validation loss: 2.5994206854340276

Epoch: 102| Step: 0
Training loss: 2.9707828990049103
Validation loss: 2.597719468408342

Epoch: 5| Step: 1
Training loss: 3.1196160285601517
Validation loss: 2.595479711414795

Epoch: 5| Step: 2
Training loss: 2.8696366745391066
Validation loss: 2.5987013224641275

Epoch: 5| Step: 3
Training loss: 3.175741310384616
Validation loss: 2.596904447047088

Epoch: 5| Step: 4
Training loss: 3.0418101934423336
Validation loss: 2.599919285124809

Epoch: 5| Step: 5
Training loss: 3.4440301078517104
Validation loss: 2.606399449850717

Epoch: 5| Step: 6
Training loss: 2.381684983941397
Validation loss: 2.613075496809818

Epoch: 5| Step: 7
Training loss: 3.1092371311005778
Validation loss: 2.611729143108211

Epoch: 5| Step: 8
Training loss: 2.764181158905481
Validation loss: 2.602040865298119

Epoch: 5| Step: 9
Training loss: 2.8619076711502203
Validation loss: 2.5964247562642364

Epoch: 5| Step: 10
Training loss: 2.6124500726190902
Validation loss: 2.5919762239527255

Epoch: 103| Step: 0
Training loss: 2.5669427830524083
Validation loss: 2.587585135484992

Epoch: 5| Step: 1
Training loss: 2.9185762602825647
Validation loss: 2.586987932820862

Epoch: 5| Step: 2
Training loss: 3.0446810134651026
Validation loss: 2.586361287149932

Epoch: 5| Step: 3
Training loss: 2.9653239508395792
Validation loss: 2.5931888877272415

Epoch: 5| Step: 4
Training loss: 3.0204610836387014
Validation loss: 2.5852327624794755

Epoch: 5| Step: 5
Training loss: 2.796562475719616
Validation loss: 2.5857796946307126

Epoch: 5| Step: 6
Training loss: 3.280424032249469
Validation loss: 2.5814014426440908

Epoch: 5| Step: 7
Training loss: 3.1887615923519412
Validation loss: 2.587174891356128

Epoch: 5| Step: 8
Training loss: 2.897281220728299
Validation loss: 2.584049638273365

Epoch: 5| Step: 9
Training loss: 2.7340821899584062
Validation loss: 2.586257395797611

Epoch: 5| Step: 10
Training loss: 2.9098473711395307
Validation loss: 2.591653191041753

Epoch: 104| Step: 0
Training loss: 2.8680059527730415
Validation loss: 2.614357019806

Epoch: 5| Step: 1
Training loss: 3.235542860515664
Validation loss: 2.6519038509623027

Epoch: 5| Step: 2
Training loss: 2.310274445055091
Validation loss: 2.6082300193282055

Epoch: 5| Step: 3
Training loss: 2.709617535252422
Validation loss: 2.5941286320932293

Epoch: 5| Step: 4
Training loss: 2.9438540948495895
Validation loss: 2.587993683081533

Epoch: 5| Step: 5
Training loss: 2.998993227827332
Validation loss: 2.5831275280564387

Epoch: 5| Step: 6
Training loss: 3.232717633042346
Validation loss: 2.5822267481143233

Epoch: 5| Step: 7
Training loss: 3.201739351108476
Validation loss: 2.581238440733267

Epoch: 5| Step: 8
Training loss: 3.0483064858943894
Validation loss: 2.582128442931285

Epoch: 5| Step: 9
Training loss: 3.491558248677265
Validation loss: 2.585292764414198

Epoch: 5| Step: 10
Training loss: 2.11779900197409
Validation loss: 2.5848597668806765

Epoch: 105| Step: 0
Training loss: 3.2570059164319694
Validation loss: 2.5846089029950186

Epoch: 5| Step: 1
Training loss: 2.80499537911264
Validation loss: 2.5932346385004093

Epoch: 5| Step: 2
Training loss: 2.7841241965489045
Validation loss: 2.5959401427515307

Epoch: 5| Step: 3
Training loss: 2.648186415751735
Validation loss: 2.6133418660548293

Epoch: 5| Step: 4
Training loss: 2.762346296220244
Validation loss: 2.615693181381611

Epoch: 5| Step: 5
Training loss: 2.6006703722973925
Validation loss: 2.623523277252356

Epoch: 5| Step: 6
Training loss: 3.3044312289818216
Validation loss: 2.6447112326841253

Epoch: 5| Step: 7
Training loss: 3.155247897461243
Validation loss: 2.621781125252559

Epoch: 5| Step: 8
Training loss: 3.094882642157144
Validation loss: 2.6048738217613687

Epoch: 5| Step: 9
Training loss: 2.7705496353580137
Validation loss: 2.590168378401425

Epoch: 5| Step: 10
Training loss: 3.236096499896229
Validation loss: 2.5805598460535975

Epoch: 106| Step: 0
Training loss: 2.648741938104823
Validation loss: 2.575516064760333

Epoch: 5| Step: 1
Training loss: 3.177402584524515
Validation loss: 2.5741454354627122

Epoch: 5| Step: 2
Training loss: 2.5715250326410892
Validation loss: 2.5775067962639318

Epoch: 5| Step: 3
Training loss: 3.0586601630122057
Validation loss: 2.576234149840219

Epoch: 5| Step: 4
Training loss: 3.4796055195285
Validation loss: 2.5784837480014446

Epoch: 5| Step: 5
Training loss: 2.6205430113114536
Validation loss: 2.574851927187036

Epoch: 5| Step: 6
Training loss: 2.790551565470665
Validation loss: 2.5703413657145844

Epoch: 5| Step: 7
Training loss: 2.7311173570490985
Validation loss: 2.570959722905249

Epoch: 5| Step: 8
Training loss: 3.006992614767471
Validation loss: 2.5681897615863245

Epoch: 5| Step: 9
Training loss: 2.986012913077475
Validation loss: 2.569203292747766

Epoch: 5| Step: 10
Training loss: 3.19554275391935
Validation loss: 2.573502443557835

Epoch: 107| Step: 0
Training loss: 2.8839360557165468
Validation loss: 2.5722451149210808

Epoch: 5| Step: 1
Training loss: 2.5703521076153755
Validation loss: 2.575752982351057

Epoch: 5| Step: 2
Training loss: 2.5883733335189256
Validation loss: 2.5753150141936274

Epoch: 5| Step: 3
Training loss: 2.7502954497717433
Validation loss: 2.5765842799669696

Epoch: 5| Step: 4
Training loss: 2.98270357471607
Validation loss: 2.576746313748961

Epoch: 5| Step: 5
Training loss: 3.305557028363182
Validation loss: 2.576930500544585

Epoch: 5| Step: 6
Training loss: 3.119544034798417
Validation loss: 2.5740074591229907

Epoch: 5| Step: 7
Training loss: 3.050101112815914
Validation loss: 2.5914657730818247

Epoch: 5| Step: 8
Training loss: 2.5963235060636083
Validation loss: 2.5947262502857953

Epoch: 5| Step: 9
Training loss: 2.8994630711166236
Validation loss: 2.6211260890535213

Epoch: 5| Step: 10
Training loss: 3.581809067153424
Validation loss: 2.6315129158358177

Epoch: 108| Step: 0
Training loss: 3.3266217055814895
Validation loss: 2.5893671193610013

Epoch: 5| Step: 1
Training loss: 3.1723694063667396
Validation loss: 2.5657221906880565

Epoch: 5| Step: 2
Training loss: 2.901430461223132
Validation loss: 2.5613945718366953

Epoch: 5| Step: 3
Training loss: 2.9378541773475413
Validation loss: 2.5634897503100995

Epoch: 5| Step: 4
Training loss: 2.8658909997650257
Validation loss: 2.5655028883712627

Epoch: 5| Step: 5
Training loss: 3.1015787964976465
Validation loss: 2.5666873843019196

Epoch: 5| Step: 6
Training loss: 2.9444290576588763
Validation loss: 2.5624573886869038

Epoch: 5| Step: 7
Training loss: 2.5607645624594513
Validation loss: 2.5603132894711753

Epoch: 5| Step: 8
Training loss: 3.0821974096725833
Validation loss: 2.5646434736065684

Epoch: 5| Step: 9
Training loss: 2.327316143669929
Validation loss: 2.566746915860663

Epoch: 5| Step: 10
Training loss: 2.9912366028424717
Validation loss: 2.5821771134794784

Epoch: 109| Step: 0
Training loss: 3.3927330109109963
Validation loss: 2.6006438748942338

Epoch: 5| Step: 1
Training loss: 2.6361925292318804
Validation loss: 2.6109288352816202

Epoch: 5| Step: 2
Training loss: 1.8433285247620448
Validation loss: 2.6068837898199377

Epoch: 5| Step: 3
Training loss: 2.8704811740212053
Validation loss: 2.611404342116473

Epoch: 5| Step: 4
Training loss: 2.929059828595549
Validation loss: 2.602050112765585

Epoch: 5| Step: 5
Training loss: 3.053398777567161
Validation loss: 2.592401515978309

Epoch: 5| Step: 6
Training loss: 2.907624606662883
Validation loss: 2.587962026603625

Epoch: 5| Step: 7
Training loss: 3.3720065369638816
Validation loss: 2.5860930504055575

Epoch: 5| Step: 8
Training loss: 3.506452606929624
Validation loss: 2.570994858354233

Epoch: 5| Step: 9
Training loss: 2.7264151547030906
Validation loss: 2.5655191555030536

Epoch: 5| Step: 10
Training loss: 2.6703761843726164
Validation loss: 2.567330244694901

Epoch: 110| Step: 0
Training loss: 2.978077100146419
Validation loss: 2.5644994419024765

Epoch: 5| Step: 1
Training loss: 3.0754894456330355
Validation loss: 2.5723935514187146

Epoch: 5| Step: 2
Training loss: 2.728686885060142
Validation loss: 2.577462641705849

Epoch: 5| Step: 3
Training loss: 3.377501937899538
Validation loss: 2.575854498710174

Epoch: 5| Step: 4
Training loss: 2.2997047483593334
Validation loss: 2.574014592268128

Epoch: 5| Step: 5
Training loss: 2.6880646046016015
Validation loss: 2.5724185001161697

Epoch: 5| Step: 6
Training loss: 2.879273596920385
Validation loss: 2.567910524878455

Epoch: 5| Step: 7
Training loss: 2.973044571846188
Validation loss: 2.570006009319844

Epoch: 5| Step: 8
Training loss: 2.8429260737105873
Validation loss: 2.5673456624591875

Epoch: 5| Step: 9
Training loss: 3.2820430705459893
Validation loss: 2.5678353759418515

Epoch: 5| Step: 10
Training loss: 3.0406541750410923
Validation loss: 2.564394108024824

Epoch: 111| Step: 0
Training loss: 3.3950193556850414
Validation loss: 2.565836193588277

Epoch: 5| Step: 1
Training loss: 3.1505315362453468
Validation loss: 2.5664801362279883

Epoch: 5| Step: 2
Training loss: 3.1508812897698446
Validation loss: 2.5652148624161377

Epoch: 5| Step: 3
Training loss: 2.878034068772151
Validation loss: 2.560612241049372

Epoch: 5| Step: 4
Training loss: 3.033603973332149
Validation loss: 2.5617354278086104

Epoch: 5| Step: 5
Training loss: 2.985467361335673
Validation loss: 2.5623608072905366

Epoch: 5| Step: 6
Training loss: 2.5079841911511256
Validation loss: 2.5653910311850985

Epoch: 5| Step: 7
Training loss: 3.0917226911405837
Validation loss: 2.57025740479303

Epoch: 5| Step: 8
Training loss: 2.3596404475766217
Validation loss: 2.5930788091184054

Epoch: 5| Step: 9
Training loss: 2.641953444533472
Validation loss: 2.622782953171944

Epoch: 5| Step: 10
Training loss: 2.84616790934556
Validation loss: 2.603043219295567

Epoch: 112| Step: 0
Training loss: 3.6234472171839034
Validation loss: 2.590900131022731

Epoch: 5| Step: 1
Training loss: 3.183026334595508
Validation loss: 2.5735614937236937

Epoch: 5| Step: 2
Training loss: 3.110776192560731
Validation loss: 2.561586631910604

Epoch: 5| Step: 3
Training loss: 2.9931412812652627
Validation loss: 2.5587167071096553

Epoch: 5| Step: 4
Training loss: 2.6835415986392306
Validation loss: 2.555851835865845

Epoch: 5| Step: 5
Training loss: 2.7769874741268676
Validation loss: 2.553431969801779

Epoch: 5| Step: 6
Training loss: 2.777494659830723
Validation loss: 2.5513238412530796

Epoch: 5| Step: 7
Training loss: 2.24820531689426
Validation loss: 2.555860874310326

Epoch: 5| Step: 8
Training loss: 2.879418336622067
Validation loss: 2.5565903081161623

Epoch: 5| Step: 9
Training loss: 2.9804231532697476
Validation loss: 2.55273549375919

Epoch: 5| Step: 10
Training loss: 2.641982773440942
Validation loss: 2.555945526302181

Epoch: 113| Step: 0
Training loss: 3.0756554936132017
Validation loss: 2.5592224916654667

Epoch: 5| Step: 1
Training loss: 3.044012358401021
Validation loss: 2.555609010619162

Epoch: 5| Step: 2
Training loss: 3.164585098624391
Validation loss: 2.559767551070583

Epoch: 5| Step: 3
Training loss: 2.9436644134714447
Validation loss: 2.5588879843565797

Epoch: 5| Step: 4
Training loss: 2.2138382178229743
Validation loss: 2.565111931555421

Epoch: 5| Step: 5
Training loss: 3.292459867170549
Validation loss: 2.5775898954521352

Epoch: 5| Step: 6
Training loss: 2.9013400697676675
Validation loss: 2.5844088811898196

Epoch: 5| Step: 7
Training loss: 2.51448810547727
Validation loss: 2.5745219002154167

Epoch: 5| Step: 8
Training loss: 3.1539975428792397
Validation loss: 2.5718671222311387

Epoch: 5| Step: 9
Training loss: 2.5165680249147724
Validation loss: 2.569425309396444

Epoch: 5| Step: 10
Training loss: 3.170224065473161
Validation loss: 2.5678969993702787

Epoch: 114| Step: 0
Training loss: 2.4864585344825625
Validation loss: 2.5861458811683415

Epoch: 5| Step: 1
Training loss: 2.695996272387319
Validation loss: 2.6026247745479743

Epoch: 5| Step: 2
Training loss: 3.39317486071319
Validation loss: 2.6098940380185045

Epoch: 5| Step: 3
Training loss: 2.525506933709903
Validation loss: 2.6087746359659536

Epoch: 5| Step: 4
Training loss: 3.441580691121947
Validation loss: 2.6103893025774667

Epoch: 5| Step: 5
Training loss: 3.0194273384246832
Validation loss: 2.601393157355896

Epoch: 5| Step: 6
Training loss: 3.566911341988534
Validation loss: 2.589656312952459

Epoch: 5| Step: 7
Training loss: 2.522436835232557
Validation loss: 2.582900532706983

Epoch: 5| Step: 8
Training loss: 2.55528742194422
Validation loss: 2.5729708214794362

Epoch: 5| Step: 9
Training loss: 2.5944681667066565
Validation loss: 2.560707196460391

Epoch: 5| Step: 10
Training loss: 3.102498026316197
Validation loss: 2.555116393972

Epoch: 115| Step: 0
Training loss: 2.792741160690119
Validation loss: 2.5518604310973223

Epoch: 5| Step: 1
Training loss: 3.0391368709770585
Validation loss: 2.5547837593644145

Epoch: 5| Step: 2
Training loss: 3.6625296633824345
Validation loss: 2.560868011428602

Epoch: 5| Step: 3
Training loss: 3.055288582515362
Validation loss: 2.564508308916738

Epoch: 5| Step: 4
Training loss: 3.085927765263522
Validation loss: 2.5582019126683444

Epoch: 5| Step: 5
Training loss: 2.968013631948747
Validation loss: 2.5565323560859308

Epoch: 5| Step: 6
Training loss: 1.8545280561549005
Validation loss: 2.5543723660725774

Epoch: 5| Step: 7
Training loss: 2.809477305008168
Validation loss: 2.5560810299533707

Epoch: 5| Step: 8
Training loss: 2.9905644489404675
Validation loss: 2.552028529014237

Epoch: 5| Step: 9
Training loss: 2.627827892224364
Validation loss: 2.558414841550941

Epoch: 5| Step: 10
Training loss: 2.8914295623342494
Validation loss: 2.561910227754489

Epoch: 116| Step: 0
Training loss: 2.9971648170584135
Validation loss: 2.5686624981388877

Epoch: 5| Step: 1
Training loss: 2.7195358017705553
Validation loss: 2.5705671895202467

Epoch: 5| Step: 2
Training loss: 2.5381464318011946
Validation loss: 2.559479763134556

Epoch: 5| Step: 3
Training loss: 3.2769395399386125
Validation loss: 2.5536720626320033

Epoch: 5| Step: 4
Training loss: 2.9024500461587235
Validation loss: 2.5498368378133875

Epoch: 5| Step: 5
Training loss: 2.744739703290343
Validation loss: 2.5412236433943964

Epoch: 5| Step: 6
Training loss: 2.7366471795500704
Validation loss: 2.5470365906741437

Epoch: 5| Step: 7
Training loss: 2.555803434356476
Validation loss: 2.543582426926423

Epoch: 5| Step: 8
Training loss: 2.9257809240445414
Validation loss: 2.548288657238239

Epoch: 5| Step: 9
Training loss: 3.195771200744021
Validation loss: 2.556273969629202

Epoch: 5| Step: 10
Training loss: 3.3617072947185287
Validation loss: 2.601832507774281

Epoch: 117| Step: 0
Training loss: 3.0502082003213515
Validation loss: 2.6847076848198705

Epoch: 5| Step: 1
Training loss: 3.165989117331968
Validation loss: 2.7551938312889437

Epoch: 5| Step: 2
Training loss: 3.073475535806599
Validation loss: 2.812049001905647

Epoch: 5| Step: 3
Training loss: 2.97447455758791
Validation loss: 2.7787106314179773

Epoch: 5| Step: 4
Training loss: 2.7788626893977866
Validation loss: 2.708214788627026

Epoch: 5| Step: 5
Training loss: 2.735570068783983
Validation loss: 2.6496582315463804

Epoch: 5| Step: 6
Training loss: 2.8044145286567854
Validation loss: 2.599224584857414

Epoch: 5| Step: 7
Training loss: 3.380206577827613
Validation loss: 2.5864931857853146

Epoch: 5| Step: 8
Training loss: 2.940299303299063
Validation loss: 2.544476163835724

Epoch: 5| Step: 9
Training loss: 3.2749606938223765
Validation loss: 2.55575374196228

Epoch: 5| Step: 10
Training loss: 2.633447406406585
Validation loss: 2.576274128140873

Epoch: 118| Step: 0
Training loss: 2.75615679178912
Validation loss: 2.6099431759963885

Epoch: 5| Step: 1
Training loss: 3.3034180712360857
Validation loss: 2.6943018072452114

Epoch: 5| Step: 2
Training loss: 3.0994647640730597
Validation loss: 2.670290741316124

Epoch: 5| Step: 3
Training loss: 3.025985550920943
Validation loss: 2.590761961472595

Epoch: 5| Step: 4
Training loss: 3.2501362992096103
Validation loss: 2.5744136961993136

Epoch: 5| Step: 5
Training loss: 2.713009001618865
Validation loss: 2.5870827976237

Epoch: 5| Step: 6
Training loss: 2.5418374259578442
Validation loss: 2.616866887595994

Epoch: 5| Step: 7
Training loss: 2.9773220584973084
Validation loss: 2.6229901146568304

Epoch: 5| Step: 8
Training loss: 3.4011390909648003
Validation loss: 2.6076170553272804

Epoch: 5| Step: 9
Training loss: 2.7589373577399514
Validation loss: 2.579890366986736

Epoch: 5| Step: 10
Training loss: 2.5074347571027067
Validation loss: 2.552925676699649

Epoch: 119| Step: 0
Training loss: 2.920382031571751
Validation loss: 2.5497287163586906

Epoch: 5| Step: 1
Training loss: 2.9289183560678556
Validation loss: 2.54967840383775

Epoch: 5| Step: 2
Training loss: 2.660117710635384
Validation loss: 2.5549793175208046

Epoch: 5| Step: 3
Training loss: 3.187962367612267
Validation loss: 2.554759716438072

Epoch: 5| Step: 4
Training loss: 2.950035780350245
Validation loss: 2.558996304880111

Epoch: 5| Step: 5
Training loss: 2.7170769816511915
Validation loss: 2.5533066376533653

Epoch: 5| Step: 6
Training loss: 2.6810617732067437
Validation loss: 2.552591840666959

Epoch: 5| Step: 7
Training loss: 2.795395614386303
Validation loss: 2.542405595153551

Epoch: 5| Step: 8
Training loss: 2.684908127163042
Validation loss: 2.5423060123594254

Epoch: 5| Step: 9
Training loss: 3.523561192136649
Validation loss: 2.542759203762509

Epoch: 5| Step: 10
Training loss: 3.014994975476483
Validation loss: 2.5470311021203087

Epoch: 120| Step: 0
Training loss: 3.1357995155437743
Validation loss: 2.5591227227837696

Epoch: 5| Step: 1
Training loss: 2.63887552849137
Validation loss: 2.582169335208691

Epoch: 5| Step: 2
Training loss: 2.7025409574695693
Validation loss: 2.601637037345692

Epoch: 5| Step: 3
Training loss: 3.096349221565954
Validation loss: 2.6419266964800596

Epoch: 5| Step: 4
Training loss: 2.9719677001101554
Validation loss: 2.660017391949529

Epoch: 5| Step: 5
Training loss: 3.4000638731398363
Validation loss: 2.6471580391135148

Epoch: 5| Step: 6
Training loss: 2.7114318045218306
Validation loss: 2.6228629015435834

Epoch: 5| Step: 7
Training loss: 3.4307584372249007
Validation loss: 2.5896767574018447

Epoch: 5| Step: 8
Training loss: 2.128911065612386
Validation loss: 2.5468825755310833

Epoch: 5| Step: 9
Training loss: 2.71187704993085
Validation loss: 2.534906023544079

Epoch: 5| Step: 10
Training loss: 2.876599903267572
Validation loss: 2.534831600289432

Epoch: 121| Step: 0
Training loss: 2.7426400965861077
Validation loss: 2.5411747826808155

Epoch: 5| Step: 1
Training loss: 3.104664670863161
Validation loss: 2.5480579452728307

Epoch: 5| Step: 2
Training loss: 3.1442088465351477
Validation loss: 2.5567769516145584

Epoch: 5| Step: 3
Training loss: 3.016738290797054
Validation loss: 2.5534319527338125

Epoch: 5| Step: 4
Training loss: 3.3933474251005484
Validation loss: 2.5488808918395334

Epoch: 5| Step: 5
Training loss: 2.898447206383259
Validation loss: 2.541498265536914

Epoch: 5| Step: 6
Training loss: 2.819784690943191
Validation loss: 2.536811205891637

Epoch: 5| Step: 7
Training loss: 2.929353984922603
Validation loss: 2.5324892175399936

Epoch: 5| Step: 8
Training loss: 2.347061564297533
Validation loss: 2.5347100909426907

Epoch: 5| Step: 9
Training loss: 2.993749624104964
Validation loss: 2.5407612585089905

Epoch: 5| Step: 10
Training loss: 2.603488426896335
Validation loss: 2.554569693872783

Epoch: 122| Step: 0
Training loss: 2.3366581752403324
Validation loss: 2.572550005471063

Epoch: 5| Step: 1
Training loss: 3.077694470654894
Validation loss: 2.599507576249527

Epoch: 5| Step: 2
Training loss: 3.3240083119073867
Validation loss: 2.592764787779448

Epoch: 5| Step: 3
Training loss: 2.3375478443818363
Validation loss: 2.5742040944300393

Epoch: 5| Step: 4
Training loss: 2.702372187045466
Validation loss: 2.552289950805086

Epoch: 5| Step: 5
Training loss: 2.370662140880909
Validation loss: 2.542646975178841

Epoch: 5| Step: 6
Training loss: 3.1116933183255724
Validation loss: 2.5376738142771122

Epoch: 5| Step: 7
Training loss: 3.1715367329439976
Validation loss: 2.5368702582155147

Epoch: 5| Step: 8
Training loss: 3.3163825260028217
Validation loss: 2.5367175555967836

Epoch: 5| Step: 9
Training loss: 2.6294108979150566
Validation loss: 2.534276699510968

Epoch: 5| Step: 10
Training loss: 3.280854119533831
Validation loss: 2.535574426213047

Epoch: 123| Step: 0
Training loss: 2.896709904086465
Validation loss: 2.5315118854478778

Epoch: 5| Step: 1
Training loss: 3.119848200944404
Validation loss: 2.5372417687315463

Epoch: 5| Step: 2
Training loss: 2.6457097682984934
Validation loss: 2.539191067377313

Epoch: 5| Step: 3
Training loss: 2.699472948131333
Validation loss: 2.53104399087492

Epoch: 5| Step: 4
Training loss: 2.890130737937827
Validation loss: 2.5306053520647875

Epoch: 5| Step: 5
Training loss: 2.637351812023436
Validation loss: 2.5251445669584607

Epoch: 5| Step: 6
Training loss: 3.223170383940876
Validation loss: 2.529256678189092

Epoch: 5| Step: 7
Training loss: 2.7661996880121906
Validation loss: 2.5327721620532238

Epoch: 5| Step: 8
Training loss: 3.1448821257075323
Validation loss: 2.5267626730638026

Epoch: 5| Step: 9
Training loss: 2.939776086649497
Validation loss: 2.550094792781517

Epoch: 5| Step: 10
Training loss: 2.826006691408436
Validation loss: 2.583086626880532

Epoch: 124| Step: 0
Training loss: 2.909005120486319
Validation loss: 2.6093069314137773

Epoch: 5| Step: 1
Training loss: 2.9858132935885195
Validation loss: 2.632814573063982

Epoch: 5| Step: 2
Training loss: 2.6711350693565343
Validation loss: 2.6021009496039342

Epoch: 5| Step: 3
Training loss: 2.8978114518774896
Validation loss: 2.561928819235966

Epoch: 5| Step: 4
Training loss: 2.829119091354913
Validation loss: 2.543871365329941

Epoch: 5| Step: 5
Training loss: 3.1354039763302586
Validation loss: 2.5354418149827938

Epoch: 5| Step: 6
Training loss: 2.9298754822503463
Validation loss: 2.537838793524443

Epoch: 5| Step: 7
Training loss: 3.043924164537942
Validation loss: 2.5362611897717517

Epoch: 5| Step: 8
Training loss: 2.4789847192327947
Validation loss: 2.53558341257817

Epoch: 5| Step: 9
Training loss: 2.6936015572770287
Validation loss: 2.522872791010549

Epoch: 5| Step: 10
Training loss: 3.296551439941321
Validation loss: 2.5285464430193016

Epoch: 125| Step: 0
Training loss: 2.784787275316053
Validation loss: 2.5399179516599206

Epoch: 5| Step: 1
Training loss: 3.257221854478069
Validation loss: 2.5538411254487468

Epoch: 5| Step: 2
Training loss: 2.8580979794364283
Validation loss: 2.5754014760033974

Epoch: 5| Step: 3
Training loss: 2.820697705282539
Validation loss: 2.5918445548925484

Epoch: 5| Step: 4
Training loss: 3.0149717265712335
Validation loss: 2.6035169090278476

Epoch: 5| Step: 5
Training loss: 2.4351876857418646
Validation loss: 2.59009573803188

Epoch: 5| Step: 6
Training loss: 3.1785940778730537
Validation loss: 2.6046813787608416

Epoch: 5| Step: 7
Training loss: 2.98133559513973
Validation loss: 2.5734345089883033

Epoch: 5| Step: 8
Training loss: 2.871917730932951
Validation loss: 2.53579742687942

Epoch: 5| Step: 9
Training loss: 2.783071714277065
Validation loss: 2.5212031603089056

Epoch: 5| Step: 10
Training loss: 2.9206199194359668
Validation loss: 2.5199829246159298

Epoch: 126| Step: 0
Training loss: 3.15135614176287
Validation loss: 2.5235750849214025

Epoch: 5| Step: 1
Training loss: 2.5525951157799702
Validation loss: 2.5286271627369734

Epoch: 5| Step: 2
Training loss: 3.0034474591733162
Validation loss: 2.5343085642920915

Epoch: 5| Step: 3
Training loss: 2.444434255039287
Validation loss: 2.536711826928521

Epoch: 5| Step: 4
Training loss: 3.0935450013955155
Validation loss: 2.5327944847407005

Epoch: 5| Step: 5
Training loss: 3.144795396029087
Validation loss: 2.532631504555359

Epoch: 5| Step: 6
Training loss: 2.8561478210469757
Validation loss: 2.524705622109215

Epoch: 5| Step: 7
Training loss: 2.6020710765915442
Validation loss: 2.539147473247274

Epoch: 5| Step: 8
Training loss: 2.7701059883029537
Validation loss: 2.5388703284098995

Epoch: 5| Step: 9
Training loss: 2.7133684938981655
Validation loss: 2.5434778747667743

Epoch: 5| Step: 10
Training loss: 3.414021856210088
Validation loss: 2.5442846187867536

Epoch: 127| Step: 0
Training loss: 3.089504527147776
Validation loss: 2.542832169042836

Epoch: 5| Step: 1
Training loss: 2.9374418861646823
Validation loss: 2.535586934116483

Epoch: 5| Step: 2
Training loss: 2.8707421327526497
Validation loss: 2.527348485035856

Epoch: 5| Step: 3
Training loss: 2.8461722652925814
Validation loss: 2.52852544650785

Epoch: 5| Step: 4
Training loss: 2.8987569710013137
Validation loss: 2.521544681972741

Epoch: 5| Step: 5
Training loss: 2.592204817150141
Validation loss: 2.518343810193541

Epoch: 5| Step: 6
Training loss: 2.8574328888415557
Validation loss: 2.5282910491600084

Epoch: 5| Step: 7
Training loss: 3.2859907507833004
Validation loss: 2.523832804710114

Epoch: 5| Step: 8
Training loss: 2.5128327030792463
Validation loss: 2.5282008802511866

Epoch: 5| Step: 9
Training loss: 2.79118800448472
Validation loss: 2.5349868320136757

Epoch: 5| Step: 10
Training loss: 2.8902203250836873
Validation loss: 2.540821938331875

Epoch: 128| Step: 0
Training loss: 3.366675388841063
Validation loss: 2.546678830590577

Epoch: 5| Step: 1
Training loss: 2.8219592076576583
Validation loss: 2.5463643526230326

Epoch: 5| Step: 2
Training loss: 2.9585561713165847
Validation loss: 2.5657205200439965

Epoch: 5| Step: 3
Training loss: 3.1066792366144633
Validation loss: 2.5773980859488823

Epoch: 5| Step: 4
Training loss: 2.866905427201188
Validation loss: 2.5291630993873486

Epoch: 5| Step: 5
Training loss: 2.7254235804608666
Validation loss: 2.5172078900259223

Epoch: 5| Step: 6
Training loss: 2.7258999519600318
Validation loss: 2.51790791838822

Epoch: 5| Step: 7
Training loss: 2.6590310292293124
Validation loss: 2.5230417086282992

Epoch: 5| Step: 8
Training loss: 2.565508774089065
Validation loss: 2.529451048749657

Epoch: 5| Step: 9
Training loss: 3.003160719009094
Validation loss: 2.527644524827112

Epoch: 5| Step: 10
Training loss: 2.878390924716572
Validation loss: 2.5325861455027723

Epoch: 129| Step: 0
Training loss: 3.023985347348999
Validation loss: 2.5470641681379975

Epoch: 5| Step: 1
Training loss: 2.9259810538627
Validation loss: 2.5573513631459166

Epoch: 5| Step: 2
Training loss: 3.3197681653990645
Validation loss: 2.6638970274804135

Epoch: 5| Step: 3
Training loss: 2.9745071002813264
Validation loss: 2.70392164575875

Epoch: 5| Step: 4
Training loss: 2.917963847573693
Validation loss: 2.6447751670749593

Epoch: 5| Step: 5
Training loss: 3.034388539591478
Validation loss: 2.584559269471991

Epoch: 5| Step: 6
Training loss: 2.607130718762831
Validation loss: 2.5340918252959836

Epoch: 5| Step: 7
Training loss: 2.7234477530465346
Validation loss: 2.530199739216842

Epoch: 5| Step: 8
Training loss: 2.596380531434803
Validation loss: 2.556939275067267

Epoch: 5| Step: 9
Training loss: 3.262034947950121
Validation loss: 2.6236876455952944

Epoch: 5| Step: 10
Training loss: 2.9124954551039175
Validation loss: 2.656314087106086

Epoch: 130| Step: 0
Training loss: 3.119952435986777
Validation loss: 2.632505536088339

Epoch: 5| Step: 1
Training loss: 2.6021396122861304
Validation loss: 2.558788105248266

Epoch: 5| Step: 2
Training loss: 2.586897657377673
Validation loss: 2.539510431274391

Epoch: 5| Step: 3
Training loss: 2.7468440413222246
Validation loss: 2.533474525914101

Epoch: 5| Step: 4
Training loss: 2.5810884956284674
Validation loss: 2.53718636259292

Epoch: 5| Step: 5
Training loss: 3.102650948663211
Validation loss: 2.5197973954192094

Epoch: 5| Step: 6
Training loss: 2.891839839209573
Validation loss: 2.5151904349951595

Epoch: 5| Step: 7
Training loss: 3.0464668196137987
Validation loss: 2.5127380580950422

Epoch: 5| Step: 8
Training loss: 2.594296776923209
Validation loss: 2.5091385319170425

Epoch: 5| Step: 9
Training loss: 3.596526425172674
Validation loss: 2.5102035690040077

Epoch: 5| Step: 10
Training loss: 2.7218362238297527
Validation loss: 2.5226161255853934

Epoch: 131| Step: 0
Training loss: 3.06349041552295
Validation loss: 2.512669968736981

Epoch: 5| Step: 1
Training loss: 2.6989219491308005
Validation loss: 2.513579608951854

Epoch: 5| Step: 2
Training loss: 2.423050429067753
Validation loss: 2.521621674055881

Epoch: 5| Step: 3
Training loss: 2.8631563458645175
Validation loss: 2.528031578230579

Epoch: 5| Step: 4
Training loss: 2.386158579318549
Validation loss: 2.56253744238574

Epoch: 5| Step: 5
Training loss: 3.5825228254997974
Validation loss: 2.5753759340512494

Epoch: 5| Step: 6
Training loss: 3.256670927931914
Validation loss: 2.5975326480306196

Epoch: 5| Step: 7
Training loss: 3.0456955411943065
Validation loss: 2.5755100764925043

Epoch: 5| Step: 8
Training loss: 2.8723495539617114
Validation loss: 2.561417750038865

Epoch: 5| Step: 9
Training loss: 2.9402741663766516
Validation loss: 2.5729813212447925

Epoch: 5| Step: 10
Training loss: 2.342845589662437
Validation loss: 2.568697403525819

Epoch: 132| Step: 0
Training loss: 2.7928057002778397
Validation loss: 2.568364969696074

Epoch: 5| Step: 1
Training loss: 2.8932718891293763
Validation loss: 2.5601862794788457

Epoch: 5| Step: 2
Training loss: 2.799024895767536
Validation loss: 2.572852511330762

Epoch: 5| Step: 3
Training loss: 3.0114424562689943
Validation loss: 2.566195302887563

Epoch: 5| Step: 4
Training loss: 2.4382900033761294
Validation loss: 2.5654585042281157

Epoch: 5| Step: 5
Training loss: 3.1560288153470304
Validation loss: 2.551955442926263

Epoch: 5| Step: 6
Training loss: 2.804491126536292
Validation loss: 2.5487928871563823

Epoch: 5| Step: 7
Training loss: 2.635408655287637
Validation loss: 2.5354543660073356

Epoch: 5| Step: 8
Training loss: 2.8124543928051327
Validation loss: 2.5330380194231616

Epoch: 5| Step: 9
Training loss: 3.0888512870579525
Validation loss: 2.5077515152153227

Epoch: 5| Step: 10
Training loss: 3.248486239685535
Validation loss: 2.518678802263203

Epoch: 133| Step: 0
Training loss: 2.0574763991716147
Validation loss: 2.5302191351498284

Epoch: 5| Step: 1
Training loss: 2.7918289953454725
Validation loss: 2.5444218855039606

Epoch: 5| Step: 2
Training loss: 2.717992479747617
Validation loss: 2.557856471547041

Epoch: 5| Step: 3
Training loss: 3.0852046820750565
Validation loss: 2.554058931760453

Epoch: 5| Step: 4
Training loss: 3.2182656821896587
Validation loss: 2.5362050900177375

Epoch: 5| Step: 5
Training loss: 2.835242992933673
Validation loss: 2.5284733990653248

Epoch: 5| Step: 6
Training loss: 2.7004690186775706
Validation loss: 2.514704208703362

Epoch: 5| Step: 7
Training loss: 3.315298949235609
Validation loss: 2.5077967990336076

Epoch: 5| Step: 8
Training loss: 3.0789064296518123
Validation loss: 2.513797388349355

Epoch: 5| Step: 9
Training loss: 2.4463894456075628
Validation loss: 2.5145909390365637

Epoch: 5| Step: 10
Training loss: 3.106422901522429
Validation loss: 2.5181104103906375

Epoch: 134| Step: 0
Training loss: 2.6347405592939923
Validation loss: 2.514168305015259

Epoch: 5| Step: 1
Training loss: 2.493887390329265
Validation loss: 2.526903541586795

Epoch: 5| Step: 2
Training loss: 2.912932721519688
Validation loss: 2.518442486806107

Epoch: 5| Step: 3
Training loss: 3.1703254409909456
Validation loss: 2.5351729252227

Epoch: 5| Step: 4
Training loss: 2.9559809685328027
Validation loss: 2.537506110135848

Epoch: 5| Step: 5
Training loss: 2.9874271144515236
Validation loss: 2.5395784082043362

Epoch: 5| Step: 6
Training loss: 2.3542715291212293
Validation loss: 2.523342057489338

Epoch: 5| Step: 7
Training loss: 3.1266325691603387
Validation loss: 2.5180809889473523

Epoch: 5| Step: 8
Training loss: 2.7818758828224524
Validation loss: 2.510157913953981

Epoch: 5| Step: 9
Training loss: 2.9049814388450366
Validation loss: 2.5018346433004846

Epoch: 5| Step: 10
Training loss: 3.254855563567308
Validation loss: 2.4940624972756607

Epoch: 135| Step: 0
Training loss: 3.2652986354279805
Validation loss: 2.5041423944328853

Epoch: 5| Step: 1
Training loss: 2.992380638960848
Validation loss: 2.504184880109456

Epoch: 5| Step: 2
Training loss: 2.798945507668025
Validation loss: 2.5001364045206076

Epoch: 5| Step: 3
Training loss: 2.802649732634142
Validation loss: 2.494945267492441

Epoch: 5| Step: 4
Training loss: 3.2819718792981614
Validation loss: 2.4970148024641516

Epoch: 5| Step: 5
Training loss: 2.7317398016191072
Validation loss: 2.499988768152417

Epoch: 5| Step: 6
Training loss: 2.6766471853849727
Validation loss: 2.506737923857317

Epoch: 5| Step: 7
Training loss: 2.6142980310982242
Validation loss: 2.5457497249914653

Epoch: 5| Step: 8
Training loss: 3.1317803639928226
Validation loss: 2.559965910072514

Epoch: 5| Step: 9
Training loss: 2.471427720760385
Validation loss: 2.6209473135682937

Epoch: 5| Step: 10
Training loss: 2.5849958013208996
Validation loss: 2.6609166469046746

Epoch: 136| Step: 0
Training loss: 2.7695331438970077
Validation loss: 2.677851551434568

Epoch: 5| Step: 1
Training loss: 2.867076071255218
Validation loss: 2.6996542325228208

Epoch: 5| Step: 2
Training loss: 2.6910442668062236
Validation loss: 2.701690252283782

Epoch: 5| Step: 3
Training loss: 3.1762843560496656
Validation loss: 2.6488605538530603

Epoch: 5| Step: 4
Training loss: 2.254625651885288
Validation loss: 2.584363415110777

Epoch: 5| Step: 5
Training loss: 2.910608776162811
Validation loss: 2.529542898037748

Epoch: 5| Step: 6
Training loss: 3.0609857357755823
Validation loss: 2.4878434925451027

Epoch: 5| Step: 7
Training loss: 2.8675304072662735
Validation loss: 2.4964511930008633

Epoch: 5| Step: 8
Training loss: 3.280842201686659
Validation loss: 2.5023143884340944

Epoch: 5| Step: 9
Training loss: 2.763018225483768
Validation loss: 2.509767555570285

Epoch: 5| Step: 10
Training loss: 2.786680941142098
Validation loss: 2.5164175566571676

Epoch: 137| Step: 0
Training loss: 3.1213661428283634
Validation loss: 2.5436889572178383

Epoch: 5| Step: 1
Training loss: 2.7258399508784765
Validation loss: 2.5803422995607406

Epoch: 5| Step: 2
Training loss: 2.7575575410817286
Validation loss: 2.6172584990567165

Epoch: 5| Step: 3
Training loss: 2.5001012781609493
Validation loss: 2.5924369225161996

Epoch: 5| Step: 4
Training loss: 3.0422329484378796
Validation loss: 2.5581928313864646

Epoch: 5| Step: 5
Training loss: 3.1905583687605175
Validation loss: 2.543101902213397

Epoch: 5| Step: 6
Training loss: 2.844981000464743
Validation loss: 2.5445736658570453

Epoch: 5| Step: 7
Training loss: 2.7381856469023163
Validation loss: 2.5405269194243263

Epoch: 5| Step: 8
Training loss: 3.0924996055164873
Validation loss: 2.5389325266245106

Epoch: 5| Step: 9
Training loss: 2.936379888722015
Validation loss: 2.5425230291885317

Epoch: 5| Step: 10
Training loss: 2.7321142823820255
Validation loss: 2.5642863124404394

Epoch: 138| Step: 0
Training loss: 2.312460203086084
Validation loss: 2.5808389796645175

Epoch: 5| Step: 1
Training loss: 2.9793110170049992
Validation loss: 2.6279449584998664

Epoch: 5| Step: 2
Training loss: 2.280548405865164
Validation loss: 2.6453972275300313

Epoch: 5| Step: 3
Training loss: 2.982762725079066
Validation loss: 2.6977111083072205

Epoch: 5| Step: 4
Training loss: 2.7222322109151604
Validation loss: 2.6524765457675605

Epoch: 5| Step: 5
Training loss: 3.3204575450855898
Validation loss: 2.5404652769160094

Epoch: 5| Step: 6
Training loss: 2.871334724953217
Validation loss: 2.4945292172410607

Epoch: 5| Step: 7
Training loss: 2.909824101483577
Validation loss: 2.504301671055748

Epoch: 5| Step: 8
Training loss: 2.657834466824364
Validation loss: 2.5201280509479465

Epoch: 5| Step: 9
Training loss: 3.322825622905791
Validation loss: 2.549225988952862

Epoch: 5| Step: 10
Training loss: 3.3750175193049348
Validation loss: 2.7030411621385286

Epoch: 139| Step: 0
Training loss: 2.999169552621374
Validation loss: 2.648407063557497

Epoch: 5| Step: 1
Training loss: 3.087089690462201
Validation loss: 2.5345606713968833

Epoch: 5| Step: 2
Training loss: 2.5865405897830436
Validation loss: 2.5527798259549144

Epoch: 5| Step: 3
Training loss: 2.3533020682414847
Validation loss: 2.541646940846372

Epoch: 5| Step: 4
Training loss: 2.7983203754802854
Validation loss: 2.5283306275945137

Epoch: 5| Step: 5
Training loss: 3.255914734551105
Validation loss: 2.52881343907863

Epoch: 5| Step: 6
Training loss: 2.852143528936747
Validation loss: 2.5215609815664477

Epoch: 5| Step: 7
Training loss: 3.478673401241819
Validation loss: 2.522439263255509

Epoch: 5| Step: 8
Training loss: 3.036474385990658
Validation loss: 2.522570899457999

Epoch: 5| Step: 9
Training loss: 2.817287185606331
Validation loss: 2.511616274496667

Epoch: 5| Step: 10
Training loss: 2.4574480779679155
Validation loss: 2.5246728938433254

Epoch: 140| Step: 0
Training loss: 3.226483581907909
Validation loss: 2.5304245589752656

Epoch: 5| Step: 1
Training loss: 3.028908838128811
Validation loss: 2.5189974158976667

Epoch: 5| Step: 2
Training loss: 2.4311586691365545
Validation loss: 2.5231042513186175

Epoch: 5| Step: 3
Training loss: 2.841768685427195
Validation loss: 2.5492280435042165

Epoch: 5| Step: 4
Training loss: 3.0633051845293595
Validation loss: 2.594093804047829

Epoch: 5| Step: 5
Training loss: 3.0869855815129346
Validation loss: 2.6220825280578124

Epoch: 5| Step: 6
Training loss: 2.48175044550065
Validation loss: 2.6245563169230546

Epoch: 5| Step: 7
Training loss: 2.7981225326898707
Validation loss: 2.615797057167532

Epoch: 5| Step: 8
Training loss: 3.2996389364907874
Validation loss: 2.5927789636952454

Epoch: 5| Step: 9
Training loss: 2.464275119197965
Validation loss: 2.568538670711357

Epoch: 5| Step: 10
Training loss: 2.647152028904978
Validation loss: 2.5504044241227337

Epoch: 141| Step: 0
Training loss: 2.6443139667360405
Validation loss: 2.5427818395360626

Epoch: 5| Step: 1
Training loss: 3.050279016708627
Validation loss: 2.536232093865038

Epoch: 5| Step: 2
Training loss: 3.413353608513259
Validation loss: 2.5227014576872198

Epoch: 5| Step: 3
Training loss: 2.7782281468126744
Validation loss: 2.5081001469197015

Epoch: 5| Step: 4
Training loss: 2.5825130226715345
Validation loss: 2.4908928633226606

Epoch: 5| Step: 5
Training loss: 2.0591015415655884
Validation loss: 2.5034959386611173

Epoch: 5| Step: 6
Training loss: 3.035376188540233
Validation loss: 2.4913651435964206

Epoch: 5| Step: 7
Training loss: 2.775338910001561
Validation loss: 2.500261170065984

Epoch: 5| Step: 8
Training loss: 2.96436089766685
Validation loss: 2.4937386808288333

Epoch: 5| Step: 9
Training loss: 2.6033923612863656
Validation loss: 2.489915724073266

Epoch: 5| Step: 10
Training loss: 3.4191632957234237
Validation loss: 2.496683988680982

Epoch: 142| Step: 0
Training loss: 3.1996941777958874
Validation loss: 2.5033912637825977

Epoch: 5| Step: 1
Training loss: 2.5745723406269985
Validation loss: 2.5042231626698004

Epoch: 5| Step: 2
Training loss: 2.6905899027840303
Validation loss: 2.498639431780653

Epoch: 5| Step: 3
Training loss: 2.7915003617887897
Validation loss: 2.497037190195709

Epoch: 5| Step: 4
Training loss: 2.81049139565856
Validation loss: 2.4993739133745185

Epoch: 5| Step: 5
Training loss: 3.3248885630813523
Validation loss: 2.4947486031266384

Epoch: 5| Step: 6
Training loss: 2.6891070152202277
Validation loss: 2.4881839530659176

Epoch: 5| Step: 7
Training loss: 2.358304418739301
Validation loss: 2.4984740142769537

Epoch: 5| Step: 8
Training loss: 3.006547458707406
Validation loss: 2.494917595853278

Epoch: 5| Step: 9
Training loss: 2.70982025606126
Validation loss: 2.498347460204228

Epoch: 5| Step: 10
Training loss: 2.9432900363017183
Validation loss: 2.5102931701024023

Epoch: 143| Step: 0
Training loss: 2.8911835002054698
Validation loss: 2.5063108120811446

Epoch: 5| Step: 1
Training loss: 2.9301825753571666
Validation loss: 2.498403177662615

Epoch: 5| Step: 2
Training loss: 3.0750966933019748
Validation loss: 2.4894205439102333

Epoch: 5| Step: 3
Training loss: 2.6955283258245064
Validation loss: 2.486285365120365

Epoch: 5| Step: 4
Training loss: 2.9221685741449304
Validation loss: 2.483318033589006

Epoch: 5| Step: 5
Training loss: 2.890984920054651
Validation loss: 2.479000318293725

Epoch: 5| Step: 6
Training loss: 2.8065538917259127
Validation loss: 2.4793936430002717

Epoch: 5| Step: 7
Training loss: 2.469712178530424
Validation loss: 2.484369197587672

Epoch: 5| Step: 8
Training loss: 2.9614769436661517
Validation loss: 2.487693017141235

Epoch: 5| Step: 9
Training loss: 3.1880477733789814
Validation loss: 2.495418466675869

Epoch: 5| Step: 10
Training loss: 2.0568425585664016
Validation loss: 2.5191086652797696

Epoch: 144| Step: 0
Training loss: 2.7574187692002448
Validation loss: 2.5481521964312623

Epoch: 5| Step: 1
Training loss: 2.482033159629272
Validation loss: 2.5810990030942613

Epoch: 5| Step: 2
Training loss: 2.989478735251433
Validation loss: 2.596428694893582

Epoch: 5| Step: 3
Training loss: 3.2516010448952026
Validation loss: 2.6011058245557948

Epoch: 5| Step: 4
Training loss: 2.4928813673943364
Validation loss: 2.557190941571131

Epoch: 5| Step: 5
Training loss: 3.031482019098365
Validation loss: 2.5280117142421346

Epoch: 5| Step: 6
Training loss: 3.0938766915939113
Validation loss: 2.4997132413742738

Epoch: 5| Step: 7
Training loss: 2.3007465353453354
Validation loss: 2.4894754622661424

Epoch: 5| Step: 8
Training loss: 2.84638921652687
Validation loss: 2.48286497455498

Epoch: 5| Step: 9
Training loss: 2.8477004561898
Validation loss: 2.4846697587501314

Epoch: 5| Step: 10
Training loss: 3.1963497800622362
Validation loss: 2.4754211802011605

Epoch: 145| Step: 0
Training loss: 2.8894858925325333
Validation loss: 2.4800059796283387

Epoch: 5| Step: 1
Training loss: 3.337406880083329
Validation loss: 2.480697463161419

Epoch: 5| Step: 2
Training loss: 2.9227143576320613
Validation loss: 2.4793886876515887

Epoch: 5| Step: 3
Training loss: 3.240710112613682
Validation loss: 2.480533692085739

Epoch: 5| Step: 4
Training loss: 2.00912290329528
Validation loss: 2.4825021612948595

Epoch: 5| Step: 5
Training loss: 2.7317525440594173
Validation loss: 2.4886751078772655

Epoch: 5| Step: 6
Training loss: 2.5821967136846995
Validation loss: 2.487836813564237

Epoch: 5| Step: 7
Training loss: 3.0138753450229014
Validation loss: 2.4930141632653244

Epoch: 5| Step: 8
Training loss: 2.5864695206296635
Validation loss: 2.5022611257551794

Epoch: 5| Step: 9
Training loss: 2.8039057500184583
Validation loss: 2.513472975468197

Epoch: 5| Step: 10
Training loss: 2.671874464603839
Validation loss: 2.5168619235247025

Epoch: 146| Step: 0
Training loss: 2.8453753511042925
Validation loss: 2.531078612859041

Epoch: 5| Step: 1
Training loss: 3.1667250744971107
Validation loss: 2.5246275319338283

Epoch: 5| Step: 2
Training loss: 3.043743852613065
Validation loss: 2.50618579123403

Epoch: 5| Step: 3
Training loss: 3.3682041270902876
Validation loss: 2.496384213178223

Epoch: 5| Step: 4
Training loss: 2.648290129305751
Validation loss: 2.4757888230886684

Epoch: 5| Step: 5
Training loss: 2.6862324231523727
Validation loss: 2.4793336828746013

Epoch: 5| Step: 6
Training loss: 2.9202318109965266
Validation loss: 2.4840167986888804

Epoch: 5| Step: 7
Training loss: 2.754518697827871
Validation loss: 2.48925353024893

Epoch: 5| Step: 8
Training loss: 2.380501448754437
Validation loss: 2.4945251906888575

Epoch: 5| Step: 9
Training loss: 2.6335964224368116
Validation loss: 2.4909112675074256

Epoch: 5| Step: 10
Training loss: 2.7024273275225683
Validation loss: 2.4780440387277607

Epoch: 147| Step: 0
Training loss: 2.6688984135046554
Validation loss: 2.4834857055118174

Epoch: 5| Step: 1
Training loss: 3.112467852200476
Validation loss: 2.491690460972466

Epoch: 5| Step: 2
Training loss: 2.8043632638684426
Validation loss: 2.496496569863503

Epoch: 5| Step: 3
Training loss: 3.145649851991319
Validation loss: 2.514641639580017

Epoch: 5| Step: 4
Training loss: 2.589251558426199
Validation loss: 2.537080150386261

Epoch: 5| Step: 5
Training loss: 2.6627448170895947
Validation loss: 2.567568115314311

Epoch: 5| Step: 6
Training loss: 2.956643889238025
Validation loss: 2.5982473054576287

Epoch: 5| Step: 7
Training loss: 3.3437143484336245
Validation loss: 2.589784560297969

Epoch: 5| Step: 8
Training loss: 2.493580109203802
Validation loss: 2.552107283526093

Epoch: 5| Step: 9
Training loss: 2.4871790194807186
Validation loss: 2.5548360635315017

Epoch: 5| Step: 10
Training loss: 2.4407154296064695
Validation loss: 2.52870522165503

Epoch: 148| Step: 0
Training loss: 2.9452360836406486
Validation loss: 2.5239367811319973

Epoch: 5| Step: 1
Training loss: 2.5701740076848987
Validation loss: 2.501355755212578

Epoch: 5| Step: 2
Training loss: 2.835950951242204
Validation loss: 2.510135229612439

Epoch: 5| Step: 3
Training loss: 2.946496214647514
Validation loss: 2.5006355380228875

Epoch: 5| Step: 4
Training loss: 2.66003937541529
Validation loss: 2.5006027489759597

Epoch: 5| Step: 5
Training loss: 2.634747979491737
Validation loss: 2.4996885228701364

Epoch: 5| Step: 6
Training loss: 3.1928077337941265
Validation loss: 2.503114111305425

Epoch: 5| Step: 7
Training loss: 3.1435654572761305
Validation loss: 2.4885091655503344

Epoch: 5| Step: 8
Training loss: 2.240448067674257
Validation loss: 2.483079934541657

Epoch: 5| Step: 9
Training loss: 2.8064494854342974
Validation loss: 2.47142258709996

Epoch: 5| Step: 10
Training loss: 2.576475413315625
Validation loss: 2.482998204940549

Epoch: 149| Step: 0
Training loss: 2.4484028651277594
Validation loss: 2.4730451558896163

Epoch: 5| Step: 1
Training loss: 2.6238201759698425
Validation loss: 2.4913545529989047

Epoch: 5| Step: 2
Training loss: 2.9738194599674266
Validation loss: 2.4859485798425753

Epoch: 5| Step: 3
Training loss: 3.1777702381100905
Validation loss: 2.4982966496093897

Epoch: 5| Step: 4
Training loss: 2.155411598744811
Validation loss: 2.500740635282563

Epoch: 5| Step: 5
Training loss: 2.7357862046181807
Validation loss: 2.5167567961108857

Epoch: 5| Step: 6
Training loss: 3.003870057283591
Validation loss: 2.524282760063188

Epoch: 5| Step: 7
Training loss: 2.898152216523763
Validation loss: 2.520414390996718

Epoch: 5| Step: 8
Training loss: 2.801395279786635
Validation loss: 2.5064988297619615

Epoch: 5| Step: 9
Training loss: 2.7721949413114975
Validation loss: 2.4951188057537284

Epoch: 5| Step: 10
Training loss: 2.972623526634935
Validation loss: 2.4883110848349745

Epoch: 150| Step: 0
Training loss: 2.7915627094859308
Validation loss: 2.47915969010741

Epoch: 5| Step: 1
Training loss: 2.777285804626934
Validation loss: 2.475184107131518

Epoch: 5| Step: 2
Training loss: 2.898780658489061
Validation loss: 2.4778242674325153

Epoch: 5| Step: 3
Training loss: 2.3732554402945536
Validation loss: 2.468527694959115

Epoch: 5| Step: 4
Training loss: 3.1709050541777284
Validation loss: 2.4660998297455614

Epoch: 5| Step: 5
Training loss: 2.6206316249189605
Validation loss: 2.461182989926093

Epoch: 5| Step: 6
Training loss: 3.1053350071927786
Validation loss: 2.475242348029154

Epoch: 5| Step: 7
Training loss: 2.5113682717422146
Validation loss: 2.4686558452246277

Epoch: 5| Step: 8
Training loss: 2.4944135237289866
Validation loss: 2.4837673014401385

Epoch: 5| Step: 9
Training loss: 3.2412491876885823
Validation loss: 2.495093277293547

Epoch: 5| Step: 10
Training loss: 2.4060742202561722
Validation loss: 2.5008350454369697

Epoch: 151| Step: 0
Training loss: 2.7608333824918425
Validation loss: 2.4927680162743115

Epoch: 5| Step: 1
Training loss: 3.620495727275239
Validation loss: 2.5126692463747715

Epoch: 5| Step: 2
Training loss: 2.2163215564551244
Validation loss: 2.531121630890659

Epoch: 5| Step: 3
Training loss: 2.464749632185616
Validation loss: 2.531083411808293

Epoch: 5| Step: 4
Training loss: 2.511135003821135
Validation loss: 2.527989545043569

Epoch: 5| Step: 5
Training loss: 3.0564707358438463
Validation loss: 2.518956605399108

Epoch: 5| Step: 6
Training loss: 3.0549419326383265
Validation loss: 2.504245866782247

Epoch: 5| Step: 7
Training loss: 2.333620485166048
Validation loss: 2.4982202183326185

Epoch: 5| Step: 8
Training loss: 2.573309174738855
Validation loss: 2.487826353758822

Epoch: 5| Step: 9
Training loss: 2.558560017370668
Validation loss: 2.472235802720728

Epoch: 5| Step: 10
Training loss: 2.968000618566978
Validation loss: 2.473295632134092

Epoch: 152| Step: 0
Training loss: 2.588536918118968
Validation loss: 2.468453684031293

Epoch: 5| Step: 1
Training loss: 2.970017493867569
Validation loss: 2.479420126159613

Epoch: 5| Step: 2
Training loss: 2.910956724536458
Validation loss: 2.487033278556232

Epoch: 5| Step: 3
Training loss: 2.8000836428002014
Validation loss: 2.4874765594642745

Epoch: 5| Step: 4
Training loss: 2.809215323012564
Validation loss: 2.482275925000026

Epoch: 5| Step: 5
Training loss: 3.179392658032379
Validation loss: 2.478117425981463

Epoch: 5| Step: 6
Training loss: 2.781255743470852
Validation loss: 2.4616896831950443

Epoch: 5| Step: 7
Training loss: 2.1470261255459504
Validation loss: 2.466123044926273

Epoch: 5| Step: 8
Training loss: 3.0333444497320468
Validation loss: 2.4868310268413474

Epoch: 5| Step: 9
Training loss: 2.6870680173521304
Validation loss: 2.4886411130820645

Epoch: 5| Step: 10
Training loss: 2.6838633750275385
Validation loss: 2.509201350651732

Epoch: 153| Step: 0
Training loss: 2.158130875841014
Validation loss: 2.543289461996767

Epoch: 5| Step: 1
Training loss: 2.368554655288818
Validation loss: 2.5512820611838283

Epoch: 5| Step: 2
Training loss: 2.7845672369805734
Validation loss: 2.5775293402295243

Epoch: 5| Step: 3
Training loss: 3.1114916474115146
Validation loss: 2.557699670973604

Epoch: 5| Step: 4
Training loss: 2.974931244897138
Validation loss: 2.528617004985172

Epoch: 5| Step: 5
Training loss: 3.0251002901965203
Validation loss: 2.5075385536623727

Epoch: 5| Step: 6
Training loss: 2.5041894142611416
Validation loss: 2.485165388307756

Epoch: 5| Step: 7
Training loss: 2.512525271767823
Validation loss: 2.4749629207156687

Epoch: 5| Step: 8
Training loss: 3.1596797022677556
Validation loss: 2.469261873387757

Epoch: 5| Step: 9
Training loss: 2.6754196479549845
Validation loss: 2.462028849746924

Epoch: 5| Step: 10
Training loss: 3.122537481909182
Validation loss: 2.4669904262612463

Epoch: 154| Step: 0
Training loss: 2.704686061389349
Validation loss: 2.457350252938343

Epoch: 5| Step: 1
Training loss: 3.137811567786779
Validation loss: 2.4584891379573532

Epoch: 5| Step: 2
Training loss: 2.362853158056866
Validation loss: 2.4688477128840973

Epoch: 5| Step: 3
Training loss: 2.6222601624705693
Validation loss: 2.470609205494686

Epoch: 5| Step: 4
Training loss: 2.610851121588813
Validation loss: 2.49323754966898

Epoch: 5| Step: 5
Training loss: 2.8061766005264683
Validation loss: 2.503300433527303

Epoch: 5| Step: 6
Training loss: 2.82425471239422
Validation loss: 2.5077434882085146

Epoch: 5| Step: 7
Training loss: 2.4679828852302745
Validation loss: 2.501794631352996

Epoch: 5| Step: 8
Training loss: 3.165351058991744
Validation loss: 2.514186500073195

Epoch: 5| Step: 9
Training loss: 3.2007882875826494
Validation loss: 2.5114483268066405

Epoch: 5| Step: 10
Training loss: 2.250772237710014
Validation loss: 2.501998318057989

Epoch: 155| Step: 0
Training loss: 2.8994847793666394
Validation loss: 2.522402395472397

Epoch: 5| Step: 1
Training loss: 2.83362091699308
Validation loss: 2.5242940584956353

Epoch: 5| Step: 2
Training loss: 2.7980829113284353
Validation loss: 2.5183462844091262

Epoch: 5| Step: 3
Training loss: 2.7995018584048847
Validation loss: 2.498704502833801

Epoch: 5| Step: 4
Training loss: 2.9664059670874896
Validation loss: 2.4867611307207085

Epoch: 5| Step: 5
Training loss: 2.2722935895689282
Validation loss: 2.4773456275615056

Epoch: 5| Step: 6
Training loss: 2.5855276468717245
Validation loss: 2.465745737886733

Epoch: 5| Step: 7
Training loss: 3.37747977250012
Validation loss: 2.465667565617261

Epoch: 5| Step: 8
Training loss: 2.8644024786067064
Validation loss: 2.4631275719672154

Epoch: 5| Step: 9
Training loss: 2.6783723412050695
Validation loss: 2.4780886188106193

Epoch: 5| Step: 10
Training loss: 2.3765033180346884
Validation loss: 2.492721678843272

Epoch: 156| Step: 0
Training loss: 2.5716539957752516
Validation loss: 2.4999355000204737

Epoch: 5| Step: 1
Training loss: 2.760810843100819
Validation loss: 2.524419555543838

Epoch: 5| Step: 2
Training loss: 2.2955963312441776
Validation loss: 2.53668957307461

Epoch: 5| Step: 3
Training loss: 2.518544747672078
Validation loss: 2.5551943670508614

Epoch: 5| Step: 4
Training loss: 2.6543717868498953
Validation loss: 2.543760583150125

Epoch: 5| Step: 5
Training loss: 3.209765440787767
Validation loss: 2.5416390007150023

Epoch: 5| Step: 6
Training loss: 2.90169504547995
Validation loss: 2.545232343124467

Epoch: 5| Step: 7
Training loss: 2.5847960197203204
Validation loss: 2.5443292141027327

Epoch: 5| Step: 8
Training loss: 2.9986914323920795
Validation loss: 2.5275015523621813

Epoch: 5| Step: 9
Training loss: 3.2314851538795057
Validation loss: 2.513737681817661

Epoch: 5| Step: 10
Training loss: 2.7620502364709196
Validation loss: 2.5050400617804898

Epoch: 157| Step: 0
Training loss: 3.3445872747001144
Validation loss: 2.4992410994841623

Epoch: 5| Step: 1
Training loss: 2.7213038584365044
Validation loss: 2.494978090816801

Epoch: 5| Step: 2
Training loss: 2.8354829786526676
Validation loss: 2.4801895786779173

Epoch: 5| Step: 3
Training loss: 2.2258438824577764
Validation loss: 2.4777795605044775

Epoch: 5| Step: 4
Training loss: 2.774539868121805
Validation loss: 2.4732165354764937

Epoch: 5| Step: 5
Training loss: 2.9343288430188204
Validation loss: 2.4776062791341045

Epoch: 5| Step: 6
Training loss: 2.502161617361959
Validation loss: 2.470367869336818

Epoch: 5| Step: 7
Training loss: 2.570847197690538
Validation loss: 2.471429081712825

Epoch: 5| Step: 8
Training loss: 2.4222241549916776
Validation loss: 2.4915710081721176

Epoch: 5| Step: 9
Training loss: 3.0849042104134705
Validation loss: 2.5125048056201282

Epoch: 5| Step: 10
Training loss: 2.9980295385797615
Validation loss: 2.540944392357803

Epoch: 158| Step: 0
Training loss: 3.0407161185401383
Validation loss: 2.613779517462233

Epoch: 5| Step: 1
Training loss: 2.8229182244515902
Validation loss: 2.6541390772360964

Epoch: 5| Step: 2
Training loss: 2.8859541813523713
Validation loss: 2.6756758522190363

Epoch: 5| Step: 3
Training loss: 2.8079254246560197
Validation loss: 2.6463955469295275

Epoch: 5| Step: 4
Training loss: 2.710369479340146
Validation loss: 2.5778105960778186

Epoch: 5| Step: 5
Training loss: 2.552874373761229
Validation loss: 2.4971429588869887

Epoch: 5| Step: 6
Training loss: 2.615598008029084
Validation loss: 2.47133759748563

Epoch: 5| Step: 7
Training loss: 2.2772003181005673
Validation loss: 2.4588369149539577

Epoch: 5| Step: 8
Training loss: 3.141444464666686
Validation loss: 2.4590349574430306

Epoch: 5| Step: 9
Training loss: 2.6679768820508842
Validation loss: 2.460581122222592

Epoch: 5| Step: 10
Training loss: 3.3654840324724686
Validation loss: 2.4672814670887133

Epoch: 159| Step: 0
Training loss: 2.42403556679923
Validation loss: 2.4734448845799575

Epoch: 5| Step: 1
Training loss: 2.959693989787389
Validation loss: 2.4718024761392097

Epoch: 5| Step: 2
Training loss: 2.81971408909671
Validation loss: 2.480076635695307

Epoch: 5| Step: 3
Training loss: 2.676133626860261
Validation loss: 2.4701841142004057

Epoch: 5| Step: 4
Training loss: 3.2298400340903863
Validation loss: 2.4636973552309445

Epoch: 5| Step: 5
Training loss: 2.922890879235649
Validation loss: 2.4580192622526025

Epoch: 5| Step: 6
Training loss: 3.4115938038414932
Validation loss: 2.460645808837685

Epoch: 5| Step: 7
Training loss: 2.4183224125130702
Validation loss: 2.487271348570453

Epoch: 5| Step: 8
Training loss: 2.689793960593554
Validation loss: 2.4932682012439153

Epoch: 5| Step: 9
Training loss: 2.2691429449441576
Validation loss: 2.5064340357282187

Epoch: 5| Step: 10
Training loss: 2.816811626323226
Validation loss: 2.502717288773243

Epoch: 160| Step: 0
Training loss: 2.9364864142785807
Validation loss: 2.522895651442626

Epoch: 5| Step: 1
Training loss: 3.0260927039529837
Validation loss: 2.57514359009814

Epoch: 5| Step: 2
Training loss: 2.835480792469399
Validation loss: 2.5421534844846643

Epoch: 5| Step: 3
Training loss: 2.4107605904466505
Validation loss: 2.5303687168426805

Epoch: 5| Step: 4
Training loss: 2.6620336061415624
Validation loss: 2.522675269347775

Epoch: 5| Step: 5
Training loss: 2.442925015879372
Validation loss: 2.4956005199104654

Epoch: 5| Step: 6
Training loss: 2.6903293708611704
Validation loss: 2.487632975716444

Epoch: 5| Step: 7
Training loss: 2.557018278364688
Validation loss: 2.4802754939324365

Epoch: 5| Step: 8
Training loss: 3.454506852194378
Validation loss: 2.4638018872712055

Epoch: 5| Step: 9
Training loss: 2.5437384640293836
Validation loss: 2.462680250747665

Epoch: 5| Step: 10
Training loss: 2.751973917593558
Validation loss: 2.4660210376721676

Epoch: 161| Step: 0
Training loss: 3.097779395408457
Validation loss: 2.46289511026513

Epoch: 5| Step: 1
Training loss: 2.9531321046128163
Validation loss: 2.4577607745921575

Epoch: 5| Step: 2
Training loss: 2.5442142747093386
Validation loss: 2.4591632093708964

Epoch: 5| Step: 3
Training loss: 2.5759611354466876
Validation loss: 2.4571134103334034

Epoch: 5| Step: 4
Training loss: 2.490496596947677
Validation loss: 2.461038604393943

Epoch: 5| Step: 5
Training loss: 2.9837263910376746
Validation loss: 2.4634978476857072

Epoch: 5| Step: 6
Training loss: 3.0015175477950615
Validation loss: 2.4767683021365867

Epoch: 5| Step: 7
Training loss: 2.9884799068465373
Validation loss: 2.477924693157831

Epoch: 5| Step: 8
Training loss: 2.567989331410431
Validation loss: 2.478652719521734

Epoch: 5| Step: 9
Training loss: 2.4129479066590402
Validation loss: 2.485269185528781

Epoch: 5| Step: 10
Training loss: 2.340976447292053
Validation loss: 2.5038626630264837

Epoch: 162| Step: 0
Training loss: 2.321354076741261
Validation loss: 2.524773483853904

Epoch: 5| Step: 1
Training loss: 2.7625625810395964
Validation loss: 2.5466822643067597

Epoch: 5| Step: 2
Training loss: 3.312610552400478
Validation loss: 2.5559059637446206

Epoch: 5| Step: 3
Training loss: 3.016370928127011
Validation loss: 2.5471050753169187

Epoch: 5| Step: 4
Training loss: 2.702045467663353
Validation loss: 2.5139458331705735

Epoch: 5| Step: 5
Training loss: 2.6861176595133562
Validation loss: 2.491372671825111

Epoch: 5| Step: 6
Training loss: 2.864596908999555
Validation loss: 2.4710603969862874

Epoch: 5| Step: 7
Training loss: 2.3715953516296446
Validation loss: 2.468927051264543

Epoch: 5| Step: 8
Training loss: 2.8368762435624615
Validation loss: 2.463636577080206

Epoch: 5| Step: 9
Training loss: 2.742180544417817
Validation loss: 2.4593735290131837

Epoch: 5| Step: 10
Training loss: 2.7204733461947312
Validation loss: 2.4566900327197443

Epoch: 163| Step: 0
Training loss: 2.793515537331413
Validation loss: 2.462374016446939

Epoch: 5| Step: 1
Training loss: 2.8190629468197983
Validation loss: 2.45913750781263

Epoch: 5| Step: 2
Training loss: 2.5557113602269745
Validation loss: 2.459681513712471

Epoch: 5| Step: 3
Training loss: 2.3567354708946335
Validation loss: 2.4773623328249075

Epoch: 5| Step: 4
Training loss: 3.1109435759197166
Validation loss: 2.4798949666032035

Epoch: 5| Step: 5
Training loss: 2.802784903997917
Validation loss: 2.501754732511384

Epoch: 5| Step: 6
Training loss: 2.6633452851174906
Validation loss: 2.502793239572317

Epoch: 5| Step: 7
Training loss: 3.3893345781209456
Validation loss: 2.4869507067962786

Epoch: 5| Step: 8
Training loss: 2.484905833987312
Validation loss: 2.487604243699149

Epoch: 5| Step: 9
Training loss: 1.7616918862064557
Validation loss: 2.4678809299194486

Epoch: 5| Step: 10
Training loss: 3.094806529270171
Validation loss: 2.4628647645652397

Epoch: 164| Step: 0
Training loss: 2.3426029704616136
Validation loss: 2.4677212431644198

Epoch: 5| Step: 1
Training loss: 3.0672470980901076
Validation loss: 2.46565163474756

Epoch: 5| Step: 2
Training loss: 2.5993736613059903
Validation loss: 2.4688627051944443

Epoch: 5| Step: 3
Training loss: 2.4897282344090046
Validation loss: 2.480883390603572

Epoch: 5| Step: 4
Training loss: 2.4676539245335576
Validation loss: 2.492436353914407

Epoch: 5| Step: 5
Training loss: 3.195016712031587
Validation loss: 2.472764175020038

Epoch: 5| Step: 6
Training loss: 2.427037600194185
Validation loss: 2.4713554740636137

Epoch: 5| Step: 7
Training loss: 2.835510726216921
Validation loss: 2.4796707276505683

Epoch: 5| Step: 8
Training loss: 2.3734204912612142
Validation loss: 2.4740999736728893

Epoch: 5| Step: 9
Training loss: 3.050390943892847
Validation loss: 2.4757197428914735

Epoch: 5| Step: 10
Training loss: 3.006316846076592
Validation loss: 2.477304095199372

Epoch: 165| Step: 0
Training loss: 3.0622575625001494
Validation loss: 2.4709566254037605

Epoch: 5| Step: 1
Training loss: 2.620013905699424
Validation loss: 2.4660947317740525

Epoch: 5| Step: 2
Training loss: 3.411221297476381
Validation loss: 2.4787691403762224

Epoch: 5| Step: 3
Training loss: 3.197976939143855
Validation loss: 2.481687650887753

Epoch: 5| Step: 4
Training loss: 2.739785645028966
Validation loss: 2.481531085102193

Epoch: 5| Step: 5
Training loss: 2.453993916759708
Validation loss: 2.4816992496438575

Epoch: 5| Step: 6
Training loss: 2.500323465402152
Validation loss: 2.4794788207164147

Epoch: 5| Step: 7
Training loss: 1.7673291784506506
Validation loss: 2.4773416838072997

Epoch: 5| Step: 8
Training loss: 3.094865385958192
Validation loss: 2.478700803102056

Epoch: 5| Step: 9
Training loss: 2.09866962072188
Validation loss: 2.482116198636078

Epoch: 5| Step: 10
Training loss: 2.5415026398141656
Validation loss: 2.4800793491408877

Epoch: 166| Step: 0
Training loss: 2.8191366941200773
Validation loss: 2.47137553928694

Epoch: 5| Step: 1
Training loss: 2.5939239995112575
Validation loss: 2.484858629813154

Epoch: 5| Step: 2
Training loss: 2.468627154034154
Validation loss: 2.4879429017720223

Epoch: 5| Step: 3
Training loss: 3.15275712830386
Validation loss: 2.4836157858094348

Epoch: 5| Step: 4
Training loss: 2.979027235774184
Validation loss: 2.4779501388131666

Epoch: 5| Step: 5
Training loss: 2.651661668585337
Validation loss: 2.4815533397897385

Epoch: 5| Step: 6
Training loss: 2.794043956883214
Validation loss: 2.4768729542758745

Epoch: 5| Step: 7
Training loss: 2.3722835867352696
Validation loss: 2.4780486289863624

Epoch: 5| Step: 8
Training loss: 2.367037626753078
Validation loss: 2.471303057657811

Epoch: 5| Step: 9
Training loss: 2.859755527211205
Validation loss: 2.483842217444522

Epoch: 5| Step: 10
Training loss: 2.725888931452228
Validation loss: 2.4807846202822192

Epoch: 167| Step: 0
Training loss: 2.6660209012940004
Validation loss: 2.483087243200995

Epoch: 5| Step: 1
Training loss: 2.647711460216634
Validation loss: 2.4773615266947933

Epoch: 5| Step: 2
Training loss: 2.900307435149555
Validation loss: 2.4949690023831974

Epoch: 5| Step: 3
Training loss: 2.7395298787016045
Validation loss: 2.4961543468927023

Epoch: 5| Step: 4
Training loss: 2.6397159975630955
Validation loss: 2.5015759361591705

Epoch: 5| Step: 5
Training loss: 2.8255804427695934
Validation loss: 2.4955626341256414

Epoch: 5| Step: 6
Training loss: 2.6898521952810897
Validation loss: 2.5039453671550627

Epoch: 5| Step: 7
Training loss: 2.979021153308642
Validation loss: 2.4806141335383534

Epoch: 5| Step: 8
Training loss: 2.852709228705667
Validation loss: 2.4667740184728664

Epoch: 5| Step: 9
Training loss: 2.5380641441686516
Validation loss: 2.4632397548861267

Epoch: 5| Step: 10
Training loss: 2.118605135576118
Validation loss: 2.4702963295098894

Epoch: 168| Step: 0
Training loss: 2.8251450155391464
Validation loss: 2.4552955521699

Epoch: 5| Step: 1
Training loss: 2.560042249360733
Validation loss: 2.454838872195386

Epoch: 5| Step: 2
Training loss: 3.2495391225483297
Validation loss: 2.4550691593143608

Epoch: 5| Step: 3
Training loss: 3.327047684075817
Validation loss: 2.4547710300546544

Epoch: 5| Step: 4
Training loss: 2.5845927173280767
Validation loss: 2.4535078747026944

Epoch: 5| Step: 5
Training loss: 2.3544973518128245
Validation loss: 2.4553535610983093

Epoch: 5| Step: 6
Training loss: 2.465327437591655
Validation loss: 2.467246699031296

Epoch: 5| Step: 7
Training loss: 2.4416783051544315
Validation loss: 2.4720804230576645

Epoch: 5| Step: 8
Training loss: 2.9226918430195354
Validation loss: 2.504511646628149

Epoch: 5| Step: 9
Training loss: 2.782684556267771
Validation loss: 2.5293849767393426

Epoch: 5| Step: 10
Training loss: 2.110668209809546
Validation loss: 2.5561597097552244

Epoch: 169| Step: 0
Training loss: 2.5155561923455703
Validation loss: 2.562393931112718

Epoch: 5| Step: 1
Training loss: 3.15390562105208
Validation loss: 2.562662785259476

Epoch: 5| Step: 2
Training loss: 2.8344371179000585
Validation loss: 2.483480311868183

Epoch: 5| Step: 3
Training loss: 2.8699375860890903
Validation loss: 2.465712492153266

Epoch: 5| Step: 4
Training loss: 3.095475303377625
Validation loss: 2.462061135201409

Epoch: 5| Step: 5
Training loss: 2.071981196609072
Validation loss: 2.476772198155344

Epoch: 5| Step: 6
Training loss: 3.0229526495725363
Validation loss: 2.4792361547449118

Epoch: 5| Step: 7
Training loss: 2.784903794412748
Validation loss: 2.4792514502847216

Epoch: 5| Step: 8
Training loss: 2.1605566388373214
Validation loss: 2.478397995442968

Epoch: 5| Step: 9
Training loss: 2.679367001777174
Validation loss: 2.4844629116476833

Epoch: 5| Step: 10
Training loss: 3.108335695103898
Validation loss: 2.472158356250618

Epoch: 170| Step: 0
Training loss: 2.399111972868673
Validation loss: 2.485438134804056

Epoch: 5| Step: 1
Training loss: 2.6330300985456683
Validation loss: 2.4808409874300694

Epoch: 5| Step: 2
Training loss: 2.6138229378913507
Validation loss: 2.484995460024947

Epoch: 5| Step: 3
Training loss: 2.603527804530073
Validation loss: 2.5082276960597407

Epoch: 5| Step: 4
Training loss: 3.21760657287374
Validation loss: 2.5599937167798763

Epoch: 5| Step: 5
Training loss: 2.4434939316154547
Validation loss: 2.6017968359476398

Epoch: 5| Step: 6
Training loss: 2.6991685788119466
Validation loss: 2.600680842048835

Epoch: 5| Step: 7
Training loss: 2.438137753513661
Validation loss: 2.5799792644654453

Epoch: 5| Step: 8
Training loss: 2.5407496085113612
Validation loss: 2.6313996539379425

Epoch: 5| Step: 9
Training loss: 3.3730171878217314
Validation loss: 2.63352767643352

Epoch: 5| Step: 10
Training loss: 3.164729144663415
Validation loss: 2.568133093516306

Epoch: 171| Step: 0
Training loss: 2.5860289589189036
Validation loss: 2.521803130772734

Epoch: 5| Step: 1
Training loss: 2.6639469602706076
Validation loss: 2.4844386925287916

Epoch: 5| Step: 2
Training loss: 2.6996947999050334
Validation loss: 2.472497465782543

Epoch: 5| Step: 3
Training loss: 2.8228433934986104
Validation loss: 2.4683682754210445

Epoch: 5| Step: 4
Training loss: 2.716014143231384
Validation loss: 2.4669174427154434

Epoch: 5| Step: 5
Training loss: 3.099788129395871
Validation loss: 2.465751610116317

Epoch: 5| Step: 6
Training loss: 2.8681579111804143
Validation loss: 2.460871017763852

Epoch: 5| Step: 7
Training loss: 2.387252722911698
Validation loss: 2.4769485911265945

Epoch: 5| Step: 8
Training loss: 2.7653378267493873
Validation loss: 2.4723493548277244

Epoch: 5| Step: 9
Training loss: 2.429884825908709
Validation loss: 2.4851689936684145

Epoch: 5| Step: 10
Training loss: 2.7244641118310358
Validation loss: 2.4721031651901657

Epoch: 172| Step: 0
Training loss: 2.580560262306428
Validation loss: 2.480066771132701

Epoch: 5| Step: 1
Training loss: 2.968109704285676
Validation loss: 2.4845445445707095

Epoch: 5| Step: 2
Training loss: 2.7430602855614765
Validation loss: 2.4826645290447544

Epoch: 5| Step: 3
Training loss: 2.3867985638698057
Validation loss: 2.4906448824392005

Epoch: 5| Step: 4
Training loss: 2.60937353807968
Validation loss: 2.492135424022777

Epoch: 5| Step: 5
Training loss: 2.6841459414149695
Validation loss: 2.483966097463658

Epoch: 5| Step: 6
Training loss: 2.6169766013732354
Validation loss: 2.470651191782675

Epoch: 5| Step: 7
Training loss: 2.548362063771325
Validation loss: 2.4696804965480497

Epoch: 5| Step: 8
Training loss: 3.0527521817498897
Validation loss: 2.4683733967390364

Epoch: 5| Step: 9
Training loss: 2.9850033403183027
Validation loss: 2.4657113131150834

Epoch: 5| Step: 10
Training loss: 2.557256404429005
Validation loss: 2.4682660690987728

Epoch: 173| Step: 0
Training loss: 2.5418686604098335
Validation loss: 2.4699607923628424

Epoch: 5| Step: 1
Training loss: 2.727285469632292
Validation loss: 2.470675235804731

Epoch: 5| Step: 2
Training loss: 2.371165744247824
Validation loss: 2.488565853244499

Epoch: 5| Step: 3
Training loss: 2.844479813041273
Validation loss: 2.496636024513891

Epoch: 5| Step: 4
Training loss: 2.746464624226736
Validation loss: 2.4990646258312306

Epoch: 5| Step: 5
Training loss: 2.453831370515908
Validation loss: 2.52506052712439

Epoch: 5| Step: 6
Training loss: 2.889762131032621
Validation loss: 2.530077920279849

Epoch: 5| Step: 7
Training loss: 2.9244848009543807
Validation loss: 2.551697466075859

Epoch: 5| Step: 8
Training loss: 2.5076780669405214
Validation loss: 2.5174413640845383

Epoch: 5| Step: 9
Training loss: 3.162818494598283
Validation loss: 2.4915182453491136

Epoch: 5| Step: 10
Training loss: 2.530729169597627
Validation loss: 2.4789920761609263

Epoch: 174| Step: 0
Training loss: 2.246141303844426
Validation loss: 2.468128654199257

Epoch: 5| Step: 1
Training loss: 2.797166691918873
Validation loss: 2.46501813028944

Epoch: 5| Step: 2
Training loss: 1.8778024710712595
Validation loss: 2.4635108474593226

Epoch: 5| Step: 3
Training loss: 2.6834923781970303
Validation loss: 2.469214188454481

Epoch: 5| Step: 4
Training loss: 3.264158951067934
Validation loss: 2.4656957672255806

Epoch: 5| Step: 5
Training loss: 2.8659196175951274
Validation loss: 2.4655814969389875

Epoch: 5| Step: 6
Training loss: 3.024468928607114
Validation loss: 2.475434229207579

Epoch: 5| Step: 7
Training loss: 2.475338221087546
Validation loss: 2.493528293636964

Epoch: 5| Step: 8
Training loss: 2.8012054845633956
Validation loss: 2.509341811510775

Epoch: 5| Step: 9
Training loss: 2.3616393888303007
Validation loss: 2.5323409303781492

Epoch: 5| Step: 10
Training loss: 3.026019115440568
Validation loss: 2.566094757109712

Epoch: 175| Step: 0
Training loss: 2.8367397550258535
Validation loss: 2.588474580738062

Epoch: 5| Step: 1
Training loss: 3.1743342445011975
Validation loss: 2.5786723262247215

Epoch: 5| Step: 2
Training loss: 2.538996111662127
Validation loss: 2.5940478771958144

Epoch: 5| Step: 3
Training loss: 2.9869715394796
Validation loss: 2.6178428224954584

Epoch: 5| Step: 4
Training loss: 2.3502361828231795
Validation loss: 2.5840878993931704

Epoch: 5| Step: 5
Training loss: 2.679069781492077
Validation loss: 2.566518312659337

Epoch: 5| Step: 6
Training loss: 2.6194141538110753
Validation loss: 2.55125941240051

Epoch: 5| Step: 7
Training loss: 2.835338014235386
Validation loss: 2.5190566980512368

Epoch: 5| Step: 8
Training loss: 2.1622217385196874
Validation loss: 2.511111325764203

Epoch: 5| Step: 9
Training loss: 3.120749061848974
Validation loss: 2.498666101862852

Epoch: 5| Step: 10
Training loss: 2.3617190407397275
Validation loss: 2.5015718697088327

Epoch: 176| Step: 0
Training loss: 2.749005397920384
Validation loss: 2.5059127248847095

Epoch: 5| Step: 1
Training loss: 2.8239969717825413
Validation loss: 2.507573641270861

Epoch: 5| Step: 2
Training loss: 2.8510325318202803
Validation loss: 2.530406893276942

Epoch: 5| Step: 3
Training loss: 2.7326973264317003
Validation loss: 2.5425769770080024

Epoch: 5| Step: 4
Training loss: 2.8248564658371205
Validation loss: 2.547430593251211

Epoch: 5| Step: 5
Training loss: 2.679729316763282
Validation loss: 2.5493225983405554

Epoch: 5| Step: 6
Training loss: 2.5595008232292735
Validation loss: 2.555566204153486

Epoch: 5| Step: 7
Training loss: 2.6564458438257685
Validation loss: 2.572019956743555

Epoch: 5| Step: 8
Training loss: 1.9468925218115138
Validation loss: 2.5627550187809685

Epoch: 5| Step: 9
Training loss: 3.13709360355502
Validation loss: 2.5659838428863515

Epoch: 5| Step: 10
Training loss: 2.555873210717366
Validation loss: 2.5506948099539173

Epoch: 177| Step: 0
Training loss: 2.7602033328746374
Validation loss: 2.5335131025513906

Epoch: 5| Step: 1
Training loss: 2.7113044776209536
Validation loss: 2.5104388739512045

Epoch: 5| Step: 2
Training loss: 2.6172443440655226
Validation loss: 2.4995054576215794

Epoch: 5| Step: 3
Training loss: 2.5971025608215363
Validation loss: 2.5070900310684094

Epoch: 5| Step: 4
Training loss: 2.6212647520131354
Validation loss: 2.5069432592704946

Epoch: 5| Step: 5
Training loss: 2.823877253271932
Validation loss: 2.5141964775246857

Epoch: 5| Step: 6
Training loss: 2.2278192553803717
Validation loss: 2.5171382008663143

Epoch: 5| Step: 7
Training loss: 2.8508865182289065
Validation loss: 2.530054505632635

Epoch: 5| Step: 8
Training loss: 2.821708270414214
Validation loss: 2.5124474963564936

Epoch: 5| Step: 9
Training loss: 3.0087572075662785
Validation loss: 2.515935612796627

Epoch: 5| Step: 10
Training loss: 2.2864176081084167
Validation loss: 2.521020545879101

Epoch: 178| Step: 0
Training loss: 2.387982672189181
Validation loss: 2.5113501420148694

Epoch: 5| Step: 1
Training loss: 2.5187072826009866
Validation loss: 2.507082271899411

Epoch: 5| Step: 2
Training loss: 2.357170439224373
Validation loss: 2.499254511360022

Epoch: 5| Step: 3
Training loss: 2.0084381909782487
Validation loss: 2.493936982177711

Epoch: 5| Step: 4
Training loss: 3.2250526719634327
Validation loss: 2.504254302201284

Epoch: 5| Step: 5
Training loss: 3.327231703674471
Validation loss: 2.5077152191799734

Epoch: 5| Step: 6
Training loss: 2.470562330011317
Validation loss: 2.520792783246457

Epoch: 5| Step: 7
Training loss: 3.0900738385708237
Validation loss: 2.5465280525646175

Epoch: 5| Step: 8
Training loss: 2.4972661329102115
Validation loss: 2.543311689349757

Epoch: 5| Step: 9
Training loss: 2.83458448348797
Validation loss: 2.5379331287284335

Epoch: 5| Step: 10
Training loss: 2.4141925665620803
Validation loss: 2.556900210655207

Epoch: 179| Step: 0
Training loss: 2.169112829809649
Validation loss: 2.5594216982357643

Epoch: 5| Step: 1
Training loss: 2.7985757952266397
Validation loss: 2.542453746546949

Epoch: 5| Step: 2
Training loss: 2.355188356225111
Validation loss: 2.515716499096923

Epoch: 5| Step: 3
Training loss: 2.40794243681659
Validation loss: 2.5013703056819256

Epoch: 5| Step: 4
Training loss: 3.203028830968682
Validation loss: 2.5137606212461154

Epoch: 5| Step: 5
Training loss: 3.068479655802086
Validation loss: 2.514839407908013

Epoch: 5| Step: 6
Training loss: 2.7761214902660583
Validation loss: 2.503751509277016

Epoch: 5| Step: 7
Training loss: 2.6130620981422465
Validation loss: 2.5030865924485868

Epoch: 5| Step: 8
Training loss: 2.643728565462846
Validation loss: 2.4978325728709416

Epoch: 5| Step: 9
Training loss: 2.607680815794093
Validation loss: 2.4984170927241047

Epoch: 5| Step: 10
Training loss: 2.608234453205966
Validation loss: 2.50015944926089

Epoch: 180| Step: 0
Training loss: 2.8034492670853415
Validation loss: 2.5125270165558313

Epoch: 5| Step: 1
Training loss: 2.5404340120907682
Validation loss: 2.5057249762980662

Epoch: 5| Step: 2
Training loss: 2.8614739390640747
Validation loss: 2.5169841559845767

Epoch: 5| Step: 3
Training loss: 2.424169720748004
Validation loss: 2.518674109455152

Epoch: 5| Step: 4
Training loss: 2.5236699141954815
Validation loss: 2.523020547422921

Epoch: 5| Step: 5
Training loss: 3.197232515959451
Validation loss: 2.516560005146238

Epoch: 5| Step: 6
Training loss: 2.5704668456697704
Validation loss: 2.5342884915498436

Epoch: 5| Step: 7
Training loss: 2.832474035967269
Validation loss: 2.5211554389038144

Epoch: 5| Step: 8
Training loss: 2.272427363981686
Validation loss: 2.5134424142359473

Epoch: 5| Step: 9
Training loss: 2.6353097725601584
Validation loss: 2.5173286305388816

Epoch: 5| Step: 10
Training loss: 2.5909208931722545
Validation loss: 2.503508005734195

Epoch: 181| Step: 0
Training loss: 2.297197695530329
Validation loss: 2.4909555411490523

Epoch: 5| Step: 1
Training loss: 2.584296313636659
Validation loss: 2.4896839502691415

Epoch: 5| Step: 2
Training loss: 2.863427464185424
Validation loss: 2.495703998179459

Epoch: 5| Step: 3
Training loss: 2.9705769589209554
Validation loss: 2.494545890674421

Epoch: 5| Step: 4
Training loss: 2.402781773773967
Validation loss: 2.4901453513878047

Epoch: 5| Step: 5
Training loss: 3.1407297600881425
Validation loss: 2.5076050029613266

Epoch: 5| Step: 6
Training loss: 2.7836579603679446
Validation loss: 2.5327662427730844

Epoch: 5| Step: 7
Training loss: 2.3247423624015178
Validation loss: 2.5622535114806864

Epoch: 5| Step: 8
Training loss: 3.3056365109173105
Validation loss: 2.598083649432062

Epoch: 5| Step: 9
Training loss: 2.250790774938628
Validation loss: 2.6220236564453185

Epoch: 5| Step: 10
Training loss: 2.6022789687399466
Validation loss: 2.677065888071052

Epoch: 182| Step: 0
Training loss: 3.155787065756264
Validation loss: 2.650437243085757

Epoch: 5| Step: 1
Training loss: 3.1289729993465345
Validation loss: 2.5800815957440175

Epoch: 5| Step: 2
Training loss: 2.7198776011415755
Validation loss: 2.530296264504436

Epoch: 5| Step: 3
Training loss: 2.31716335332923
Validation loss: 2.5108515895804415

Epoch: 5| Step: 4
Training loss: 2.4337535334220046
Validation loss: 2.4953867833409205

Epoch: 5| Step: 5
Training loss: 2.7168885797617994
Validation loss: 2.4913424476397257

Epoch: 5| Step: 6
Training loss: 2.670237613920327
Validation loss: 2.482466828787898

Epoch: 5| Step: 7
Training loss: 2.0249988320429697
Validation loss: 2.478225619025032

Epoch: 5| Step: 8
Training loss: 2.6150286980361677
Validation loss: 2.4825316783304534

Epoch: 5| Step: 9
Training loss: 2.7498515695915584
Validation loss: 2.4936486668671676

Epoch: 5| Step: 10
Training loss: 3.069591486090534
Validation loss: 2.5092829394025253

Epoch: 183| Step: 0
Training loss: 2.175552767086266
Validation loss: 2.512219646821641

Epoch: 5| Step: 1
Training loss: 2.311571914428831
Validation loss: 2.5232479921240505

Epoch: 5| Step: 2
Training loss: 2.464531203100482
Validation loss: 2.5409986188585454

Epoch: 5| Step: 3
Training loss: 2.9889290300751825
Validation loss: 2.5183382713215328

Epoch: 5| Step: 4
Training loss: 2.42746831981286
Validation loss: 2.5124489937575403

Epoch: 5| Step: 5
Training loss: 2.6130184845473132
Validation loss: 2.515080595792925

Epoch: 5| Step: 6
Training loss: 2.848351748164965
Validation loss: 2.51057538321511

Epoch: 5| Step: 7
Training loss: 2.6248593065613903
Validation loss: 2.508999303182131

Epoch: 5| Step: 8
Training loss: 2.624627223112405
Validation loss: 2.5243525729028735

Epoch: 5| Step: 9
Training loss: 3.1041949652762293
Validation loss: 2.524785072522595

Epoch: 5| Step: 10
Training loss: 3.0006433432903705
Validation loss: 2.563649058736498

Epoch: 184| Step: 0
Training loss: 3.1222729800598343
Validation loss: 2.597179599614978

Epoch: 5| Step: 1
Training loss: 2.8387531353401125
Validation loss: 2.578527412319442

Epoch: 5| Step: 2
Training loss: 2.194708364312289
Validation loss: 2.5338980140800547

Epoch: 5| Step: 3
Training loss: 2.285444922839054
Validation loss: 2.5155529974185318

Epoch: 5| Step: 4
Training loss: 2.7804768377038003
Validation loss: 2.5082602372286376

Epoch: 5| Step: 5
Training loss: 2.697856907323852
Validation loss: 2.4943548219058544

Epoch: 5| Step: 6
Training loss: 2.5225962839947114
Validation loss: 2.4968118561076915

Epoch: 5| Step: 7
Training loss: 2.493563185652179
Validation loss: 2.5003401791461544

Epoch: 5| Step: 8
Training loss: 3.1650301736896935
Validation loss: 2.50170750808583

Epoch: 5| Step: 9
Training loss: 2.361472100979305
Validation loss: 2.5113936704942894

Epoch: 5| Step: 10
Training loss: 2.599501151132888
Validation loss: 2.5311030430420454

Epoch: 185| Step: 0
Training loss: 1.980746578916065
Validation loss: 2.5531366226880228

Epoch: 5| Step: 1
Training loss: 2.502375142034253
Validation loss: 2.5769330214748902

Epoch: 5| Step: 2
Training loss: 2.7491902979998857
Validation loss: 2.5923965674894642

Epoch: 5| Step: 3
Training loss: 2.8353222056024814
Validation loss: 2.5997948164866593

Epoch: 5| Step: 4
Training loss: 2.9972768186024363
Validation loss: 2.5870469457061898

Epoch: 5| Step: 5
Training loss: 3.074312589151108
Validation loss: 2.560201588060558

Epoch: 5| Step: 6
Training loss: 2.541371677561061
Validation loss: 2.5445661247593563

Epoch: 5| Step: 7
Training loss: 2.4507776194075257
Validation loss: 2.538466674462358

Epoch: 5| Step: 8
Training loss: 2.572329579038386
Validation loss: 2.5260137077960345

Epoch: 5| Step: 9
Training loss: 2.5239439653865885
Validation loss: 2.5207401439093466

Epoch: 5| Step: 10
Training loss: 2.7549709994248794
Validation loss: 2.5246834604354143

Epoch: 186| Step: 0
Training loss: 2.593312973524388
Validation loss: 2.5396365305797306

Epoch: 5| Step: 1
Training loss: 3.1880806786680114
Validation loss: 2.554178232876996

Epoch: 5| Step: 2
Training loss: 2.528699932573856
Validation loss: 2.5683766900707146

Epoch: 5| Step: 3
Training loss: 2.8881467350907792
Validation loss: 2.5459119952936264

Epoch: 5| Step: 4
Training loss: 2.3912334789736356
Validation loss: 2.5342405805500046

Epoch: 5| Step: 5
Training loss: 2.568451459851116
Validation loss: 2.5266293943859943

Epoch: 5| Step: 6
Training loss: 2.6996353644940285
Validation loss: 2.5146795376476194

Epoch: 5| Step: 7
Training loss: 2.5259777782003376
Validation loss: 2.5427578285608115

Epoch: 5| Step: 8
Training loss: 2.3030294370041213
Validation loss: 2.562777584477036

Epoch: 5| Step: 9
Training loss: 2.4542055119374617
Validation loss: 2.5780128332791894

Epoch: 5| Step: 10
Training loss: 2.817184108027544
Validation loss: 2.5937160035549467

Epoch: 187| Step: 0
Training loss: 2.9397958752101876
Validation loss: 2.6131656419499056

Epoch: 5| Step: 1
Training loss: 2.54775527064471
Validation loss: 2.593368181931429

Epoch: 5| Step: 2
Training loss: 2.6155142374411433
Validation loss: 2.5865552706032404

Epoch: 5| Step: 3
Training loss: 3.1731603864883517
Validation loss: 2.573280996854346

Epoch: 5| Step: 4
Training loss: 2.122119859098589
Validation loss: 2.5694651442025354

Epoch: 5| Step: 5
Training loss: 2.544750427419947
Validation loss: 2.5495493215735543

Epoch: 5| Step: 6
Training loss: 1.9835809034883336
Validation loss: 2.552696018536688

Epoch: 5| Step: 7
Training loss: 2.6704887675706384
Validation loss: 2.53166686504053

Epoch: 5| Step: 8
Training loss: 2.411655448179201
Validation loss: 2.535347414888891

Epoch: 5| Step: 9
Training loss: 2.6064902252066666
Validation loss: 2.5331046975036764

Epoch: 5| Step: 10
Training loss: 2.948977024706794
Validation loss: 2.532719792948553

Epoch: 188| Step: 0
Training loss: 2.295003323022768
Validation loss: 2.5340246971910347

Epoch: 5| Step: 1
Training loss: 3.0596714581410036
Validation loss: 2.5423263822971665

Epoch: 5| Step: 2
Training loss: 2.2529423865864464
Validation loss: 2.5685003236895323

Epoch: 5| Step: 3
Training loss: 2.558414272390686
Validation loss: 2.600515143749953

Epoch: 5| Step: 4
Training loss: 2.730044265080795
Validation loss: 2.601005845702872

Epoch: 5| Step: 5
Training loss: 2.9669154873631425
Validation loss: 2.6100239203807534

Epoch: 5| Step: 6
Training loss: 2.451771259354555
Validation loss: 2.6063701061054165

Epoch: 5| Step: 7
Training loss: 2.644603914195106
Validation loss: 2.590208877014693

Epoch: 5| Step: 8
Training loss: 2.3560116270390443
Validation loss: 2.5903390130493493

Epoch: 5| Step: 9
Training loss: 2.8910746456657814
Validation loss: 2.573672856350298

Epoch: 5| Step: 10
Training loss: 2.3845950603802204
Validation loss: 2.550313423667497

Epoch: 189| Step: 0
Training loss: 2.6336944642297264
Validation loss: 2.5474108271931275

Epoch: 5| Step: 1
Training loss: 2.6811586128790985
Validation loss: 2.551682725361277

Epoch: 5| Step: 2
Training loss: 2.587748190360938
Validation loss: 2.5337095708904998

Epoch: 5| Step: 3
Training loss: 2.831760156744767
Validation loss: 2.534630623930146

Epoch: 5| Step: 4
Training loss: 2.4880497463932154
Validation loss: 2.5428153182132456

Epoch: 5| Step: 5
Training loss: 2.703136995322012
Validation loss: 2.574517649254915

Epoch: 5| Step: 6
Training loss: 2.3914235096669705
Validation loss: 2.6064170325299285

Epoch: 5| Step: 7
Training loss: 2.6349512123933367
Validation loss: 2.623195723471545

Epoch: 5| Step: 8
Training loss: 2.6804330750606606
Validation loss: 2.6197647846517462

Epoch: 5| Step: 9
Training loss: 2.953203149800931
Validation loss: 2.6399493667713316

Epoch: 5| Step: 10
Training loss: 1.9502030144674527
Validation loss: 2.5987689605445636

Epoch: 190| Step: 0
Training loss: 2.7505348725777163
Validation loss: 2.585255046695003

Epoch: 5| Step: 1
Training loss: 2.6093964718603377
Validation loss: 2.556239396048285

Epoch: 5| Step: 2
Training loss: 2.5673497525448474
Validation loss: 2.5559393081299664

Epoch: 5| Step: 3
Training loss: 2.0624913302152654
Validation loss: 2.5467073682453076

Epoch: 5| Step: 4
Training loss: 2.879016227122584
Validation loss: 2.5535518995685247

Epoch: 5| Step: 5
Training loss: 2.613590148094999
Validation loss: 2.556077283904369

Epoch: 5| Step: 6
Training loss: 2.780922173885316
Validation loss: 2.55356373511783

Epoch: 5| Step: 7
Training loss: 3.0273702115779
Validation loss: 2.559626125507429

Epoch: 5| Step: 8
Training loss: 2.2815770999037435
Validation loss: 2.597627856580287

Epoch: 5| Step: 9
Training loss: 2.2283225080312286
Validation loss: 2.6256893657155094

Epoch: 5| Step: 10
Training loss: 2.6619503116455654
Validation loss: 2.6325535401466627

Epoch: 191| Step: 0
Training loss: 2.790019493581837
Validation loss: 2.636404195273523

Epoch: 5| Step: 1
Training loss: 2.77060866819422
Validation loss: 2.631757528067104

Epoch: 5| Step: 2
Training loss: 2.68448718439412
Validation loss: 2.6473576906598066

Epoch: 5| Step: 3
Training loss: 1.9137409173611637
Validation loss: 2.628012275099995

Epoch: 5| Step: 4
Training loss: 2.6289613896520523
Validation loss: 2.6087487004408816

Epoch: 5| Step: 5
Training loss: 2.001981945295599
Validation loss: 2.562066332369336

Epoch: 5| Step: 6
Training loss: 2.973037675205021
Validation loss: 2.5478683075756883

Epoch: 5| Step: 7
Training loss: 2.677279444140148
Validation loss: 2.528671523215945

Epoch: 5| Step: 8
Training loss: 2.939946555865051
Validation loss: 2.525049452945672

Epoch: 5| Step: 9
Training loss: 2.6289253857668617
Validation loss: 2.5407085384634462

Epoch: 5| Step: 10
Training loss: 2.407350957105397
Validation loss: 2.5384290517457435

Epoch: 192| Step: 0
Training loss: 2.7883104010180677
Validation loss: 2.5468677727250535

Epoch: 5| Step: 1
Training loss: 2.7859092004935797
Validation loss: 2.5624801175766536

Epoch: 5| Step: 2
Training loss: 2.4466600696395093
Validation loss: 2.584998430419123

Epoch: 5| Step: 3
Training loss: 2.4195002572646205
Validation loss: 2.5981154026250493

Epoch: 5| Step: 4
Training loss: 3.0303821697882767
Validation loss: 2.631128927649908

Epoch: 5| Step: 5
Training loss: 2.367182363372366
Validation loss: 2.648031545507956

Epoch: 5| Step: 6
Training loss: 2.4969550662995315
Validation loss: 2.6509113843453465

Epoch: 5| Step: 7
Training loss: 2.504892045091416
Validation loss: 2.651559118527747

Epoch: 5| Step: 8
Training loss: 2.161794968706527
Validation loss: 2.62445040338869

Epoch: 5| Step: 9
Training loss: 2.733458708779732
Validation loss: 2.6311673825299895

Epoch: 5| Step: 10
Training loss: 2.614331409328962
Validation loss: 2.6132334452140373

Epoch: 193| Step: 0
Training loss: 2.7699249805523944
Validation loss: 2.59937430828802

Epoch: 5| Step: 1
Training loss: 2.3636006289228377
Validation loss: 2.569630542088411

Epoch: 5| Step: 2
Training loss: 2.4511460990614355
Validation loss: 2.5855518749110207

Epoch: 5| Step: 3
Training loss: 2.781845714763763
Validation loss: 2.582833904400524

Epoch: 5| Step: 4
Training loss: 2.620449208632595
Validation loss: 2.59654298560804

Epoch: 5| Step: 5
Training loss: 2.5593596964507843
Validation loss: 2.6286990768787386

Epoch: 5| Step: 6
Training loss: 2.7423292161453046
Validation loss: 2.6280955682993827

Epoch: 5| Step: 7
Training loss: 2.5344055663122353
Validation loss: 2.635466614100372

Epoch: 5| Step: 8
Training loss: 2.7510182489575405
Validation loss: 2.649195740739864

Epoch: 5| Step: 9
Training loss: 2.5285583124751945
Validation loss: 2.663521968491147

Epoch: 5| Step: 10
Training loss: 2.237258437772179
Validation loss: 2.6615009589006995

Epoch: 194| Step: 0
Training loss: 2.5013467975666184
Validation loss: 2.648576415369316

Epoch: 5| Step: 1
Training loss: 2.4702354501172783
Validation loss: 2.654802358118257

Epoch: 5| Step: 2
Training loss: 2.860341726841659
Validation loss: 2.626527724531457

Epoch: 5| Step: 3
Training loss: 2.600500858188657
Validation loss: 2.626917414665143

Epoch: 5| Step: 4
Training loss: 2.7006655402606894
Validation loss: 2.6245636418618163

Epoch: 5| Step: 5
Training loss: 2.244212654890051
Validation loss: 2.6006065119141266

Epoch: 5| Step: 6
Training loss: 2.378411703585081
Validation loss: 2.598574076538252

Epoch: 5| Step: 7
Training loss: 2.327017706409821
Validation loss: 2.5862027542697303

Epoch: 5| Step: 8
Training loss: 2.5443171663207544
Validation loss: 2.582334627729161

Epoch: 5| Step: 9
Training loss: 2.173412739155382
Validation loss: 2.567504376669124

Epoch: 5| Step: 10
Training loss: 3.250865820949156
Validation loss: 2.5552060184114023

Epoch: 195| Step: 0
Training loss: 2.5287686654352854
Validation loss: 2.549448574829143

Epoch: 5| Step: 1
Training loss: 2.204817209949789
Validation loss: 2.5648161877267888

Epoch: 5| Step: 2
Training loss: 2.703645248182764
Validation loss: 2.5939718923233515

Epoch: 5| Step: 3
Training loss: 2.6406392655749094
Validation loss: 2.5842039075028334

Epoch: 5| Step: 4
Training loss: 2.4604459725835652
Validation loss: 2.635315076283776

Epoch: 5| Step: 5
Training loss: 2.4361762340293676
Validation loss: 2.6373947364770687

Epoch: 5| Step: 6
Training loss: 2.7380622634718668
Validation loss: 2.637714268360912

Epoch: 5| Step: 7
Training loss: 2.6110257164087924
Validation loss: 2.618077758556808

Epoch: 5| Step: 8
Training loss: 2.4730741078479057
Validation loss: 2.6080067400990856

Epoch: 5| Step: 9
Training loss: 2.4083157874219485
Validation loss: 2.598049234571457

Epoch: 5| Step: 10
Training loss: 3.015471933858234
Validation loss: 2.6082199632144003

Epoch: 196| Step: 0
Training loss: 2.4735590776552385
Validation loss: 2.5742161706416713

Epoch: 5| Step: 1
Training loss: 1.855587604129188
Validation loss: 2.5531906926588865

Epoch: 5| Step: 2
Training loss: 2.6342789276090004
Validation loss: 2.5295345560717424

Epoch: 5| Step: 3
Training loss: 3.1390560653263595
Validation loss: 2.5372646052872834

Epoch: 5| Step: 4
Training loss: 1.9042008439328095
Validation loss: 2.5268906427128592

Epoch: 5| Step: 5
Training loss: 2.643896480317036
Validation loss: 2.5265264876577316

Epoch: 5| Step: 6
Training loss: 2.959732172679917
Validation loss: 2.5611178874965104

Epoch: 5| Step: 7
Training loss: 2.4693293796999254
Validation loss: 2.583384789884904

Epoch: 5| Step: 8
Training loss: 2.8054992011257265
Validation loss: 2.623365949358738

Epoch: 5| Step: 9
Training loss: 2.401947236872001
Validation loss: 2.611469052664479

Epoch: 5| Step: 10
Training loss: 2.9828245919063936
Validation loss: 2.614665947686547

Epoch: 197| Step: 0
Training loss: 1.9885765710734442
Validation loss: 2.6085872285052907

Epoch: 5| Step: 1
Training loss: 2.9898755576477973
Validation loss: 2.6149175466511507

Epoch: 5| Step: 2
Training loss: 2.901864793978475
Validation loss: 2.6130257584358563

Epoch: 5| Step: 3
Training loss: 2.470108044998697
Validation loss: 2.591128134495693

Epoch: 5| Step: 4
Training loss: 2.3649219712980742
Validation loss: 2.5780500165538833

Epoch: 5| Step: 5
Training loss: 2.306514726864257
Validation loss: 2.5728733045306704

Epoch: 5| Step: 6
Training loss: 2.829639514029642
Validation loss: 2.584416404234034

Epoch: 5| Step: 7
Training loss: 2.535183052661908
Validation loss: 2.583860729207947

Epoch: 5| Step: 8
Training loss: 2.5798487593804516
Validation loss: 2.584795120143548

Epoch: 5| Step: 9
Training loss: 2.484146875428253
Validation loss: 2.590942298306207

Epoch: 5| Step: 10
Training loss: 2.4614682548625413
Validation loss: 2.5997175470279594

Epoch: 198| Step: 0
Training loss: 2.8335002588205
Validation loss: 2.6103573490592127

Epoch: 5| Step: 1
Training loss: 2.601925569693924
Validation loss: 2.6192701790248716

Epoch: 5| Step: 2
Training loss: 2.571717872315861
Validation loss: 2.5903741835341094

Epoch: 5| Step: 3
Training loss: 2.6632502148118857
Validation loss: 2.62417074173248

Epoch: 5| Step: 4
Training loss: 1.8883897162311152
Validation loss: 2.6219630567940846

Epoch: 5| Step: 5
Training loss: 2.831432452859757
Validation loss: 2.5971647009838157

Epoch: 5| Step: 6
Training loss: 2.9137777644487066
Validation loss: 2.6144623675518797

Epoch: 5| Step: 7
Training loss: 1.978703722433729
Validation loss: 2.6020358858789474

Epoch: 5| Step: 8
Training loss: 1.8150778229898357
Validation loss: 2.594627136679258

Epoch: 5| Step: 9
Training loss: 2.707750101135438
Validation loss: 2.5954838697668645

Epoch: 5| Step: 10
Training loss: 2.8952151583238646
Validation loss: 2.5977542981747943

Epoch: 199| Step: 0
Training loss: 2.498303887073049
Validation loss: 2.5943980380379403

Epoch: 5| Step: 1
Training loss: 1.913290872545761
Validation loss: 2.6073945534453657

Epoch: 5| Step: 2
Training loss: 2.4919944377488075
Validation loss: 2.6313471160177446

Epoch: 5| Step: 3
Training loss: 2.303433869353453
Validation loss: 2.6341030341259604

Epoch: 5| Step: 4
Training loss: 3.125666890511049
Validation loss: 2.63026515071244

Epoch: 5| Step: 5
Training loss: 2.354177649368279
Validation loss: 2.631243550130447

Epoch: 5| Step: 6
Training loss: 2.795302476433171
Validation loss: 2.6287215026731072

Epoch: 5| Step: 7
Training loss: 2.521553777305426
Validation loss: 2.6335559349270237

Epoch: 5| Step: 8
Training loss: 2.322117780722767
Validation loss: 2.6406275397323276

Epoch: 5| Step: 9
Training loss: 2.881401564444973
Validation loss: 2.6186853615276413

Epoch: 5| Step: 10
Training loss: 2.2913186473729112
Validation loss: 2.6131282505136904

Epoch: 200| Step: 0
Training loss: 2.5953727150212376
Validation loss: 2.595791935739168

Epoch: 5| Step: 1
Training loss: 2.837714193048811
Validation loss: 2.593192516895264

Epoch: 5| Step: 2
Training loss: 2.894007997155097
Validation loss: 2.578984969006322

Epoch: 5| Step: 3
Training loss: 3.1100759051710125
Validation loss: 2.6022973250146038

Epoch: 5| Step: 4
Training loss: 2.1485701086560574
Validation loss: 2.602265364738802

Epoch: 5| Step: 5
Training loss: 2.17523482359509
Validation loss: 2.6127631404700273

Epoch: 5| Step: 6
Training loss: 2.2876433572509427
Validation loss: 2.649085014558515

Epoch: 5| Step: 7
Training loss: 2.261552821053391
Validation loss: 2.6549305205263636

Epoch: 5| Step: 8
Training loss: 2.3706983459696023
Validation loss: 2.64750253219055

Epoch: 5| Step: 9
Training loss: 2.515024148965403
Validation loss: 2.650699256758069

Epoch: 5| Step: 10
Training loss: 2.1995821122444736
Validation loss: 2.640487500333034

Epoch: 201| Step: 0
Training loss: 2.2550187827806134
Validation loss: 2.6308455728555162

Epoch: 5| Step: 1
Training loss: 2.563622391685421
Validation loss: 2.637880984360941

Epoch: 5| Step: 2
Training loss: 2.502796706865341
Validation loss: 2.6301112419117407

Epoch: 5| Step: 3
Training loss: 2.744428105076153
Validation loss: 2.6249570867465533

Epoch: 5| Step: 4
Training loss: 2.42451323510206
Validation loss: 2.606654735741451

Epoch: 5| Step: 5
Training loss: 2.860883304534725
Validation loss: 2.570128769573923

Epoch: 5| Step: 6
Training loss: 2.8550428915726864
Validation loss: 2.5791383081293504

Epoch: 5| Step: 7
Training loss: 2.3329829793113777
Validation loss: 2.592012395893753

Epoch: 5| Step: 8
Training loss: 1.9860025774890044
Validation loss: 2.5966805444557943

Epoch: 5| Step: 9
Training loss: 2.7959723694326994
Validation loss: 2.642806426174667

Epoch: 5| Step: 10
Training loss: 2.44535734970352
Validation loss: 2.6598043539847804

Epoch: 202| Step: 0
Training loss: 2.0973715136052467
Validation loss: 2.719178434397289

Epoch: 5| Step: 1
Training loss: 2.328891704709694
Validation loss: 2.72408057532853

Epoch: 5| Step: 2
Training loss: 2.777337740906386
Validation loss: 2.734493612831268

Epoch: 5| Step: 3
Training loss: 3.260744965978526
Validation loss: 2.6932699578946395

Epoch: 5| Step: 4
Training loss: 2.462685584806111
Validation loss: 2.6620300448231067

Epoch: 5| Step: 5
Training loss: 2.6217858755174857
Validation loss: 2.6080577468736026

Epoch: 5| Step: 6
Training loss: 2.638278437718278
Validation loss: 2.5818824550819217

Epoch: 5| Step: 7
Training loss: 2.381110111643208
Validation loss: 2.5462360608593695

Epoch: 5| Step: 8
Training loss: 2.2925629914759713
Validation loss: 2.550908613700709

Epoch: 5| Step: 9
Training loss: 2.610522628870224
Validation loss: 2.57039351986587

Epoch: 5| Step: 10
Training loss: 2.8151268453799045
Validation loss: 2.5768347570890158

Epoch: 203| Step: 0
Training loss: 2.5586374526623072
Validation loss: 2.607963566886784

Epoch: 5| Step: 1
Training loss: 2.7295497499241135
Validation loss: 2.626380421694699

Epoch: 5| Step: 2
Training loss: 3.0753733152476315
Validation loss: 2.6655647955311954

Epoch: 5| Step: 3
Training loss: 2.4614310602223446
Validation loss: 2.6931748054679594

Epoch: 5| Step: 4
Training loss: 2.246121454482672
Validation loss: 2.697094546442648

Epoch: 5| Step: 5
Training loss: 2.4672968003726568
Validation loss: 2.7115221137025

Epoch: 5| Step: 6
Training loss: 2.3390329322143795
Validation loss: 2.7128349534792293

Epoch: 5| Step: 7
Training loss: 1.9505735287510833
Validation loss: 2.6912017363075442

Epoch: 5| Step: 8
Training loss: 3.035861253787151
Validation loss: 2.685545189164305

Epoch: 5| Step: 9
Training loss: 2.4669987708414554
Validation loss: 2.625761121968494

Epoch: 5| Step: 10
Training loss: 2.7444212420465606
Validation loss: 2.596994718169732

Epoch: 204| Step: 0
Training loss: 2.3025540062020373
Validation loss: 2.578887611875985

Epoch: 5| Step: 1
Training loss: 2.5380186781680667
Validation loss: 2.5753078468225836

Epoch: 5| Step: 2
Training loss: 2.7557572008599656
Validation loss: 2.5843946524186787

Epoch: 5| Step: 3
Training loss: 2.258840359947669
Validation loss: 2.5784043365524467

Epoch: 5| Step: 4
Training loss: 2.777775855593546
Validation loss: 2.6012639232180743

Epoch: 5| Step: 5
Training loss: 1.399799642531154
Validation loss: 2.630095384029165

Epoch: 5| Step: 6
Training loss: 2.677053508270804
Validation loss: 2.67376797556889

Epoch: 5| Step: 7
Training loss: 2.6522846018694834
Validation loss: 2.663602425561713

Epoch: 5| Step: 8
Training loss: 2.776163400315306
Validation loss: 2.6654281515252385

Epoch: 5| Step: 9
Training loss: 2.2824683920268876
Validation loss: 2.6400217472879217

Epoch: 5| Step: 10
Training loss: 3.3898712586119517
Validation loss: 2.6332569508503645

Epoch: 205| Step: 0
Training loss: 2.201800550230285
Validation loss: 2.616242835203675

Epoch: 5| Step: 1
Training loss: 2.171415650895765
Validation loss: 2.5735138028358193

Epoch: 5| Step: 2
Training loss: 2.7984176728756545
Validation loss: 2.537723354586547

Epoch: 5| Step: 3
Training loss: 2.2199094724669486
Validation loss: 2.5447598387501396

Epoch: 5| Step: 4
Training loss: 2.2645805319096404
Validation loss: 2.535566222386114

Epoch: 5| Step: 5
Training loss: 2.6771197681446237
Validation loss: 2.5481084376858583

Epoch: 5| Step: 6
Training loss: 3.145980898867639
Validation loss: 2.5510815567688936

Epoch: 5| Step: 7
Training loss: 2.301431716134711
Validation loss: 2.5988226818644877

Epoch: 5| Step: 8
Training loss: 2.3884382032258364
Validation loss: 2.617203302875991

Epoch: 5| Step: 9
Training loss: 2.696331329180216
Validation loss: 2.606449328443323

Epoch: 5| Step: 10
Training loss: 2.716368147083886
Validation loss: 2.610100463365708

Epoch: 206| Step: 0
Training loss: 2.727821649594388
Validation loss: 2.6210096816563913

Epoch: 5| Step: 1
Training loss: 1.696074143291571
Validation loss: 2.631430782009782

Epoch: 5| Step: 2
Training loss: 2.6808019161389414
Validation loss: 2.6365569160653926

Epoch: 5| Step: 3
Training loss: 2.7325470836383654
Validation loss: 2.6600021046116584

Epoch: 5| Step: 4
Training loss: 3.0173723761774176
Validation loss: 2.6616527453536145

Epoch: 5| Step: 5
Training loss: 1.9713938686819243
Validation loss: 2.667775994976312

Epoch: 5| Step: 6
Training loss: 2.73415665980954
Validation loss: 2.6528892165823383

Epoch: 5| Step: 7
Training loss: 2.479756699133153
Validation loss: 2.655292437314805

Epoch: 5| Step: 8
Training loss: 2.218563663018863
Validation loss: 2.6476743160363174

Epoch: 5| Step: 9
Training loss: 2.148393887163868
Validation loss: 2.640269274511804

Epoch: 5| Step: 10
Training loss: 2.677594671632624
Validation loss: 2.651971394621574

Epoch: 207| Step: 0
Training loss: 2.7187487722810624
Validation loss: 2.627255643067923

Epoch: 5| Step: 1
Training loss: 1.9854576581610759
Validation loss: 2.631556852244703

Epoch: 5| Step: 2
Training loss: 2.247690605083996
Validation loss: 2.6154427332841004

Epoch: 5| Step: 3
Training loss: 3.062503581142278
Validation loss: 2.6178800765743837

Epoch: 5| Step: 4
Training loss: 2.294251585124427
Validation loss: 2.6094334221063735

Epoch: 5| Step: 5
Training loss: 2.6856773760905877
Validation loss: 2.6132205849593038

Epoch: 5| Step: 6
Training loss: 2.4231959524484195
Validation loss: 2.625572524991633

Epoch: 5| Step: 7
Training loss: 2.374610668193944
Validation loss: 2.652102675935822

Epoch: 5| Step: 8
Training loss: 2.27950000266418
Validation loss: 2.66677287217758

Epoch: 5| Step: 9
Training loss: 2.6204603086397804
Validation loss: 2.670979473815381

Epoch: 5| Step: 10
Training loss: 2.4787664865165766
Validation loss: 2.6587374145127245

Epoch: 208| Step: 0
Training loss: 2.1055091754946216
Validation loss: 2.6672049464296825

Epoch: 5| Step: 1
Training loss: 1.8135039738815852
Validation loss: 2.6769669969831233

Epoch: 5| Step: 2
Training loss: 2.9915898376063734
Validation loss: 2.66404169007333

Epoch: 5| Step: 3
Training loss: 2.3604723670988825
Validation loss: 2.6384559096594624

Epoch: 5| Step: 4
Training loss: 2.3063553287262026
Validation loss: 2.6466921580938454

Epoch: 5| Step: 5
Training loss: 2.6364838219993976
Validation loss: 2.649110570663726

Epoch: 5| Step: 6
Training loss: 2.7243458828963956
Validation loss: 2.6289034161432574

Epoch: 5| Step: 7
Training loss: 2.549130242810675
Validation loss: 2.631967652374271

Epoch: 5| Step: 8
Training loss: 2.7593159238338756
Validation loss: 2.622050910627844

Epoch: 5| Step: 9
Training loss: 2.499529412801823
Validation loss: 2.6104612417384283

Epoch: 5| Step: 10
Training loss: 2.0872264979843322
Validation loss: 2.6243100702611777

Epoch: 209| Step: 0
Training loss: 2.791119071052456
Validation loss: 2.6277080860762334

Epoch: 5| Step: 1
Training loss: 2.4177991471717526
Validation loss: 2.6198645251562604

Epoch: 5| Step: 2
Training loss: 2.6045591948635645
Validation loss: 2.636887334844784

Epoch: 5| Step: 3
Training loss: 2.558378487187463
Validation loss: 2.643044477058355

Epoch: 5| Step: 4
Training loss: 2.741833960193614
Validation loss: 2.6422985831784374

Epoch: 5| Step: 5
Training loss: 1.8655905178851477
Validation loss: 2.6412928111116245

Epoch: 5| Step: 6
Training loss: 2.15804525635138
Validation loss: 2.6459655851397534

Epoch: 5| Step: 7
Training loss: 2.78302288341812
Validation loss: 2.6423702095290524

Epoch: 5| Step: 8
Training loss: 2.357668935602708
Validation loss: 2.6228222522542635

Epoch: 5| Step: 9
Training loss: 2.236661794498934
Validation loss: 2.635156781026372

Epoch: 5| Step: 10
Training loss: 2.283644060121642
Validation loss: 2.6269708238426244

Epoch: 210| Step: 0
Training loss: 2.803414398530206
Validation loss: 2.625639260930284

Epoch: 5| Step: 1
Training loss: 2.72667328792536
Validation loss: 2.636641306406377

Epoch: 5| Step: 2
Training loss: 2.215035566470656
Validation loss: 2.6145697976025795

Epoch: 5| Step: 3
Training loss: 2.9286007098817555
Validation loss: 2.6298736239085043

Epoch: 5| Step: 4
Training loss: 2.2624643312456203
Validation loss: 2.651812026721436

Epoch: 5| Step: 5
Training loss: 2.197118267628259
Validation loss: 2.6487295657803207

Epoch: 5| Step: 6
Training loss: 2.5300199557636893
Validation loss: 2.6550004755119403

Epoch: 5| Step: 7
Training loss: 2.3757782714985645
Validation loss: 2.659520116161199

Epoch: 5| Step: 8
Training loss: 2.218735600814302
Validation loss: 2.641648394888074

Epoch: 5| Step: 9
Training loss: 2.0777829684681692
Validation loss: 2.6116257259114377

Epoch: 5| Step: 10
Training loss: 2.3368967185550495
Validation loss: 2.615298358521406

Epoch: 211| Step: 0
Training loss: 2.9193982729742642
Validation loss: 2.5916298470125296

Epoch: 5| Step: 1
Training loss: 2.4124129996153
Validation loss: 2.59223712299365

Epoch: 5| Step: 2
Training loss: 2.7547813810642934
Validation loss: 2.585898991631313

Epoch: 5| Step: 3
Training loss: 2.4484518453619617
Validation loss: 2.5773225621253966

Epoch: 5| Step: 4
Training loss: 2.320903972415926
Validation loss: 2.5923762967824833

Epoch: 5| Step: 5
Training loss: 1.9628261878221576
Validation loss: 2.6261956919171836

Epoch: 5| Step: 6
Training loss: 2.3551396635072925
Validation loss: 2.647036588803185

Epoch: 5| Step: 7
Training loss: 2.471153827314425
Validation loss: 2.6580639450170396

Epoch: 5| Step: 8
Training loss: 2.362076684073591
Validation loss: 2.6664939627045783

Epoch: 5| Step: 9
Training loss: 2.1740720325878944
Validation loss: 2.669124755383826

Epoch: 5| Step: 10
Training loss: 2.47883987410027
Validation loss: 2.643110902788462

Epoch: 212| Step: 0
Training loss: 2.4323221622709066
Validation loss: 2.6429173280998683

Epoch: 5| Step: 1
Training loss: 2.0585356094286165
Validation loss: 2.6335952825416444

Epoch: 5| Step: 2
Training loss: 2.527958743519274
Validation loss: 2.6315834339030197

Epoch: 5| Step: 3
Training loss: 2.4231030703800154
Validation loss: 2.6354582543046354

Epoch: 5| Step: 4
Training loss: 2.5390754582001067
Validation loss: 2.6381681133273855

Epoch: 5| Step: 5
Training loss: 2.383635431986114
Validation loss: 2.621275018234063

Epoch: 5| Step: 6
Training loss: 2.533834480190873
Validation loss: 2.6246890993875773

Epoch: 5| Step: 7
Training loss: 2.5939847541190466
Validation loss: 2.605789026394973

Epoch: 5| Step: 8
Training loss: 2.252005001638492
Validation loss: 2.619130928891704

Epoch: 5| Step: 9
Training loss: 2.8056430729559896
Validation loss: 2.602285028403564

Epoch: 5| Step: 10
Training loss: 1.8642616491742867
Validation loss: 2.622189763234235

Epoch: 213| Step: 0
Training loss: 2.7452184549201863
Validation loss: 2.6125558603324888

Epoch: 5| Step: 1
Training loss: 2.345314622607405
Validation loss: 2.613719104292292

Epoch: 5| Step: 2
Training loss: 3.0483405867695916
Validation loss: 2.618432926216441

Epoch: 5| Step: 3
Training loss: 2.8232816246759134
Validation loss: 2.646461649278244

Epoch: 5| Step: 4
Training loss: 2.218692725073636
Validation loss: 2.675903702662966

Epoch: 5| Step: 5
Training loss: 1.8248926915013373
Validation loss: 2.669353942937861

Epoch: 5| Step: 6
Training loss: 2.4009354596152295
Validation loss: 2.6509882070180257

Epoch: 5| Step: 7
Training loss: 2.1966177430249827
Validation loss: 2.6391755900557277

Epoch: 5| Step: 8
Training loss: 1.937727084234378
Validation loss: 2.6223728141324667

Epoch: 5| Step: 9
Training loss: 2.1620181787240034
Validation loss: 2.6204111467755102

Epoch: 5| Step: 10
Training loss: 2.639891934639505
Validation loss: 2.612371654922929

Epoch: 214| Step: 0
Training loss: 2.5311490262460654
Validation loss: 2.587776022486555

Epoch: 5| Step: 1
Training loss: 2.0547787026009874
Validation loss: 2.591649729859291

Epoch: 5| Step: 2
Training loss: 2.3883425718751283
Validation loss: 2.5967709842823323

Epoch: 5| Step: 3
Training loss: 2.1612590161693124
Validation loss: 2.6107487556554236

Epoch: 5| Step: 4
Training loss: 2.130003032413527
Validation loss: 2.607882179702635

Epoch: 5| Step: 5
Training loss: 2.6621688421916327
Validation loss: 2.651006693099326

Epoch: 5| Step: 6
Training loss: 2.571838667880619
Validation loss: 2.698772283500448

Epoch: 5| Step: 7
Training loss: 2.81431258391402
Validation loss: 2.7176358820068347

Epoch: 5| Step: 8
Training loss: 2.0471568605135886
Validation loss: 2.6860491649040634

Epoch: 5| Step: 9
Training loss: 2.8310193167849063
Validation loss: 2.656505535267648

Epoch: 5| Step: 10
Training loss: 2.671584621065222
Validation loss: 2.59844749132604

Epoch: 215| Step: 0
Training loss: 2.11004187320905
Validation loss: 2.562618331918215

Epoch: 5| Step: 1
Training loss: 2.593230505704997
Validation loss: 2.5481158888188267

Epoch: 5| Step: 2
Training loss: 2.5668853823459035
Validation loss: 2.548938089004842

Epoch: 5| Step: 3
Training loss: 2.4031312225618398
Validation loss: 2.5701759537247275

Epoch: 5| Step: 4
Training loss: 2.0860767103740314
Validation loss: 2.560155747156508

Epoch: 5| Step: 5
Training loss: 2.478313416753942
Validation loss: 2.604685527343759

Epoch: 5| Step: 6
Training loss: 2.3389688171095586
Validation loss: 2.626216192112657

Epoch: 5| Step: 7
Training loss: 2.58815815244554
Validation loss: 2.6515344774596405

Epoch: 5| Step: 8
Training loss: 2.468010030982655
Validation loss: 2.6770497476347854

Epoch: 5| Step: 9
Training loss: 2.8080678137010855
Validation loss: 2.711428983168321

Epoch: 5| Step: 10
Training loss: 2.4391067295597364
Validation loss: 2.6936888971891673

Epoch: 216| Step: 0
Training loss: 2.959621328154481
Validation loss: 2.6780587924137573

Epoch: 5| Step: 1
Training loss: 2.3262025204937165
Validation loss: 2.6125718855158926

Epoch: 5| Step: 2
Training loss: 1.9002745103794803
Validation loss: 2.577026557786056

Epoch: 5| Step: 3
Training loss: 2.1213461934692286
Validation loss: 2.5639842927166314

Epoch: 5| Step: 4
Training loss: 2.4072196294905233
Validation loss: 2.558652623224181

Epoch: 5| Step: 5
Training loss: 3.103299593743774
Validation loss: 2.5364576393078146

Epoch: 5| Step: 6
Training loss: 2.4633433374383293
Validation loss: 2.5585877366548355

Epoch: 5| Step: 7
Training loss: 2.1437012780883755
Validation loss: 2.5506558278062044

Epoch: 5| Step: 8
Training loss: 2.448693810870304
Validation loss: 2.557869443782573

Epoch: 5| Step: 9
Training loss: 2.0230067910397675
Validation loss: 2.5996687581467346

Epoch: 5| Step: 10
Training loss: 2.921128121454642
Validation loss: 2.671961176274767

Epoch: 217| Step: 0
Training loss: 2.1206048503877466
Validation loss: 2.753546721874198

Epoch: 5| Step: 1
Training loss: 3.3902184027251505
Validation loss: 2.8962016414041116

Epoch: 5| Step: 2
Training loss: 3.3071473257852064
Validation loss: 2.7784371923023015

Epoch: 5| Step: 3
Training loss: 2.172631221271806
Validation loss: 2.660272954661469

Epoch: 5| Step: 4
Training loss: 2.5035643917005834
Validation loss: 2.5650421846350215

Epoch: 5| Step: 5
Training loss: 2.3957437802591985
Validation loss: 2.528851766471831

Epoch: 5| Step: 6
Training loss: 2.4187909578704763
Validation loss: 2.4856850334267286

Epoch: 5| Step: 7
Training loss: 2.6505544298416095
Validation loss: 2.4877084379344376

Epoch: 5| Step: 8
Training loss: 1.8982185896886328
Validation loss: 2.5204117525070657

Epoch: 5| Step: 9
Training loss: 2.702980787366299
Validation loss: 2.5107119269212346

Epoch: 5| Step: 10
Training loss: 2.5826828865811535
Validation loss: 2.5285285855019586

Epoch: 218| Step: 0
Training loss: 2.7389087692615632
Validation loss: 2.5613365443407705

Epoch: 5| Step: 1
Training loss: 2.72173653917233
Validation loss: 2.6074996692678223

Epoch: 5| Step: 2
Training loss: 2.437292432505852
Validation loss: 2.670424014547491

Epoch: 5| Step: 3
Training loss: 2.550731711030722
Validation loss: 2.674442720484893

Epoch: 5| Step: 4
Training loss: 2.2141172371332347
Validation loss: 2.696162103495526

Epoch: 5| Step: 5
Training loss: 2.899510269907291
Validation loss: 2.687384138116222

Epoch: 5| Step: 6
Training loss: 2.6414247464218095
Validation loss: 2.6803768929480816

Epoch: 5| Step: 7
Training loss: 2.643512478883575
Validation loss: 2.669567456675528

Epoch: 5| Step: 8
Training loss: 2.364622331429311
Validation loss: 2.662984203798456

Epoch: 5| Step: 9
Training loss: 2.2185309933313038
Validation loss: 2.6474887209471936

Epoch: 5| Step: 10
Training loss: 1.9206877351911975
Validation loss: 2.6722986201765324

Epoch: 219| Step: 0
Training loss: 2.748001586280598
Validation loss: 2.6539844635529564

Epoch: 5| Step: 1
Training loss: 2.1869905150966154
Validation loss: 2.6465502097138005

Epoch: 5| Step: 2
Training loss: 2.7321291174307163
Validation loss: 2.64891573300721

Epoch: 5| Step: 3
Training loss: 2.3465575632106144
Validation loss: 2.6128953453531536

Epoch: 5| Step: 4
Training loss: 2.3134079259156723
Validation loss: 2.6072782389580214

Epoch: 5| Step: 5
Training loss: 2.1554046300550382
Validation loss: 2.574777740546024

Epoch: 5| Step: 6
Training loss: 2.727855211968663
Validation loss: 2.5647453817169343

Epoch: 5| Step: 7
Training loss: 2.4137450568110514
Validation loss: 2.535660874169915

Epoch: 5| Step: 8
Training loss: 2.1106122944556454
Validation loss: 2.5338338154623234

Epoch: 5| Step: 9
Training loss: 2.473829042502889
Validation loss: 2.5647314116989524

Epoch: 5| Step: 10
Training loss: 2.2589717647616756
Validation loss: 2.6000196572713135

Epoch: 220| Step: 0
Training loss: 1.5861810205971256
Validation loss: 2.6012190030604567

Epoch: 5| Step: 1
Training loss: 1.9882079824801782
Validation loss: 2.651578097582455

Epoch: 5| Step: 2
Training loss: 2.353181503448339
Validation loss: 2.6831966228763213

Epoch: 5| Step: 3
Training loss: 2.6743155593132446
Validation loss: 2.7046527233522912

Epoch: 5| Step: 4
Training loss: 2.7491444210444835
Validation loss: 2.703147645772829

Epoch: 5| Step: 5
Training loss: 2.4322037500561318
Validation loss: 2.6773632470296103

Epoch: 5| Step: 6
Training loss: 2.246948504140945
Validation loss: 2.683184017691125

Epoch: 5| Step: 7
Training loss: 2.4574936763647144
Validation loss: 2.6515077303391155

Epoch: 5| Step: 8
Training loss: 2.5434734822160676
Validation loss: 2.649002674571339

Epoch: 5| Step: 9
Training loss: 2.6141768262343694
Validation loss: 2.6376106866502282

Epoch: 5| Step: 10
Training loss: 2.6891263432213686
Validation loss: 2.59834000246181

Epoch: 221| Step: 0
Training loss: 1.9308555866924324
Validation loss: 2.59748318447483

Epoch: 5| Step: 1
Training loss: 2.2870466189484753
Validation loss: 2.6129828270915643

Epoch: 5| Step: 2
Training loss: 2.3633121204724468
Validation loss: 2.5946856838560928

Epoch: 5| Step: 3
Training loss: 2.1326474974807117
Validation loss: 2.615738649781162

Epoch: 5| Step: 4
Training loss: 2.189129794473037
Validation loss: 2.6200495036694003

Epoch: 5| Step: 5
Training loss: 2.6286866775119955
Validation loss: 2.6388507242974533

Epoch: 5| Step: 6
Training loss: 2.415352091110019
Validation loss: 2.6536582777340616

Epoch: 5| Step: 7
Training loss: 2.333707836160492
Validation loss: 2.6598958772574774

Epoch: 5| Step: 8
Training loss: 2.7552082852590134
Validation loss: 2.67179512307994

Epoch: 5| Step: 9
Training loss: 2.471079343113976
Validation loss: 2.6732255062477495

Epoch: 5| Step: 10
Training loss: 2.5799147433602942
Validation loss: 2.670730146930577

Epoch: 222| Step: 0
Training loss: 2.498027595642472
Validation loss: 2.6966772665719017

Epoch: 5| Step: 1
Training loss: 1.927207124875217
Validation loss: 2.689170519489968

Epoch: 5| Step: 2
Training loss: 2.7482878817225016
Validation loss: 2.7072822402239316

Epoch: 5| Step: 3
Training loss: 2.390722534583577
Validation loss: 2.7260137489352574

Epoch: 5| Step: 4
Training loss: 2.313570651085083
Validation loss: 2.711416498832906

Epoch: 5| Step: 5
Training loss: 2.428130604701895
Validation loss: 2.6459261143424886

Epoch: 5| Step: 6
Training loss: 2.392925078478927
Validation loss: 2.611904512548082

Epoch: 5| Step: 7
Training loss: 2.1082374048335164
Validation loss: 2.577381563560927

Epoch: 5| Step: 8
Training loss: 2.3854017854140306
Validation loss: 2.549780422426758

Epoch: 5| Step: 9
Training loss: 2.182096401270406
Validation loss: 2.5301406923113245

Epoch: 5| Step: 10
Training loss: 2.6668683710903176
Validation loss: 2.5219584365922096

Epoch: 223| Step: 0
Training loss: 2.7930349915658645
Validation loss: 2.5205974490528926

Epoch: 5| Step: 1
Training loss: 2.467807928039791
Validation loss: 2.520364558269166

Epoch: 5| Step: 2
Training loss: 2.8917811375660865
Validation loss: 2.53701110764226

Epoch: 5| Step: 3
Training loss: 2.1496426618058666
Validation loss: 2.5407350070921138

Epoch: 5| Step: 4
Training loss: 2.453134330197225
Validation loss: 2.559780205657585

Epoch: 5| Step: 5
Training loss: 2.4955603278818277
Validation loss: 2.5898639692580967

Epoch: 5| Step: 6
Training loss: 1.5019293139570633
Validation loss: 2.6004506003077132

Epoch: 5| Step: 7
Training loss: 2.4996585612786464
Validation loss: 2.6182470433235245

Epoch: 5| Step: 8
Training loss: 2.112794492159868
Validation loss: 2.6190895639077727

Epoch: 5| Step: 9
Training loss: 1.873605018488306
Validation loss: 2.6183686863991564

Epoch: 5| Step: 10
Training loss: 2.570561081017184
Validation loss: 2.600609300700295

Epoch: 224| Step: 0
Training loss: 2.333487153659768
Validation loss: 2.58417827497629

Epoch: 5| Step: 1
Training loss: 2.3506446644032257
Validation loss: 2.571647763249141

Epoch: 5| Step: 2
Training loss: 2.2702200758538935
Validation loss: 2.562442417733356

Epoch: 5| Step: 3
Training loss: 2.4733444148155583
Validation loss: 2.5938115108316215

Epoch: 5| Step: 4
Training loss: 1.8743290018439454
Validation loss: 2.6068904937304875

Epoch: 5| Step: 5
Training loss: 2.610934585213532
Validation loss: 2.6176884506787585

Epoch: 5| Step: 6
Training loss: 2.38503604389841
Validation loss: 2.643441458582192

Epoch: 5| Step: 7
Training loss: 2.356276441673638
Validation loss: 2.6658129649044553

Epoch: 5| Step: 8
Training loss: 2.8152291513952683
Validation loss: 2.6504920489500448

Epoch: 5| Step: 9
Training loss: 1.8723490094169344
Validation loss: 2.6546188413116187

Epoch: 5| Step: 10
Training loss: 2.242625549272113
Validation loss: 2.632834610326306

Epoch: 225| Step: 0
Training loss: 2.8547713110302286
Validation loss: 2.6243122306342967

Epoch: 5| Step: 1
Training loss: 1.8994499615020133
Validation loss: 2.584878239913706

Epoch: 5| Step: 2
Training loss: 2.180689864939153
Validation loss: 2.588684205535706

Epoch: 5| Step: 3
Training loss: 2.6083497186050644
Validation loss: 2.582118387427275

Epoch: 5| Step: 4
Training loss: 1.5994261845175786
Validation loss: 2.588616599075032

Epoch: 5| Step: 5
Training loss: 2.16642219435791
Validation loss: 2.601277432917825

Epoch: 5| Step: 6
Training loss: 2.3445361027068343
Validation loss: 2.6127562647088407

Epoch: 5| Step: 7
Training loss: 2.6343764009845305
Validation loss: 2.629574295732881

Epoch: 5| Step: 8
Training loss: 2.6560756850546956
Validation loss: 2.64750948571713

Epoch: 5| Step: 9
Training loss: 1.7062856062642775
Validation loss: 2.6473800063324635

Epoch: 5| Step: 10
Training loss: 2.7388829156614025
Validation loss: 2.6465660043575197

Epoch: 226| Step: 0
Training loss: 2.227462426071
Validation loss: 2.6207128245259095

Epoch: 5| Step: 1
Training loss: 2.3553480936655595
Validation loss: 2.5848103633156057

Epoch: 5| Step: 2
Training loss: 2.3702249207784787
Validation loss: 2.560541311279754

Epoch: 5| Step: 3
Training loss: 2.2320820173419063
Validation loss: 2.5510203522018147

Epoch: 5| Step: 4
Training loss: 2.2674567874378444
Validation loss: 2.526666992919747

Epoch: 5| Step: 5
Training loss: 2.8413696387394225
Validation loss: 2.5412526246485303

Epoch: 5| Step: 6
Training loss: 1.77677046364663
Validation loss: 2.534474919256497

Epoch: 5| Step: 7
Training loss: 2.2587257307107267
Validation loss: 2.5475775180547076

Epoch: 5| Step: 8
Training loss: 2.6528170673152642
Validation loss: 2.5753644336694994

Epoch: 5| Step: 9
Training loss: 2.2825428682711757
Validation loss: 2.6268238474209

Epoch: 5| Step: 10
Training loss: 2.0483087075814415
Validation loss: 2.6721185039407316

Epoch: 227| Step: 0
Training loss: 2.583344049328964
Validation loss: 2.702026999641219

Epoch: 5| Step: 1
Training loss: 2.2345392126815486
Validation loss: 2.712862479424181

Epoch: 5| Step: 2
Training loss: 2.5299078126177323
Validation loss: 2.6922169647595564

Epoch: 5| Step: 3
Training loss: 2.044133804167031
Validation loss: 2.6789520621586136

Epoch: 5| Step: 4
Training loss: 2.5993078043994173
Validation loss: 2.62659649367559

Epoch: 5| Step: 5
Training loss: 1.9438098174577967
Validation loss: 2.6024506238645815

Epoch: 5| Step: 6
Training loss: 1.8050307570819508
Validation loss: 2.588848582507992

Epoch: 5| Step: 7
Training loss: 2.6762875711368594
Validation loss: 2.5847846882039307

Epoch: 5| Step: 8
Training loss: 1.9537492898755482
Validation loss: 2.563660247675318

Epoch: 5| Step: 9
Training loss: 2.5428567091113314
Validation loss: 2.5405033013758334

Epoch: 5| Step: 10
Training loss: 2.4490232739477773
Validation loss: 2.5322750117242543

Epoch: 228| Step: 0
Training loss: 2.3173556513104856
Validation loss: 2.5587397332320156

Epoch: 5| Step: 1
Training loss: 1.999998748302068
Validation loss: 2.589772894241494

Epoch: 5| Step: 2
Training loss: 2.1312811527604274
Validation loss: 2.5969266607234216

Epoch: 5| Step: 3
Training loss: 2.141531647855593
Validation loss: 2.6158679008964265

Epoch: 5| Step: 4
Training loss: 2.449737055934574
Validation loss: 2.646937182588153

Epoch: 5| Step: 5
Training loss: 2.356202069915673
Validation loss: 2.6431468725110934

Epoch: 5| Step: 6
Training loss: 2.4202268837746
Validation loss: 2.6589309636135767

Epoch: 5| Step: 7
Training loss: 2.6258161275193608
Validation loss: 2.6383460756170543

Epoch: 5| Step: 8
Training loss: 2.3937612667764796
Validation loss: 2.6109751976746334

Epoch: 5| Step: 9
Training loss: 2.345241834781829
Validation loss: 2.58135668235099

Epoch: 5| Step: 10
Training loss: 1.9399506237196071
Validation loss: 2.58486034410297

Epoch: 229| Step: 0
Training loss: 1.8993930374197845
Validation loss: 2.5782152952489006

Epoch: 5| Step: 1
Training loss: 2.328285774977672
Validation loss: 2.6011890060867224

Epoch: 5| Step: 2
Training loss: 2.1945266131484145
Validation loss: 2.61532415655751

Epoch: 5| Step: 3
Training loss: 2.3798619748010608
Validation loss: 2.6083277122937334

Epoch: 5| Step: 4
Training loss: 2.2905790233291405
Validation loss: 2.6313026792210987

Epoch: 5| Step: 5
Training loss: 2.2732716922662655
Validation loss: 2.604910515325351

Epoch: 5| Step: 6
Training loss: 2.9046472211141197
Validation loss: 2.5781293832313463

Epoch: 5| Step: 7
Training loss: 2.2318591913086947
Validation loss: 2.592424769991547

Epoch: 5| Step: 8
Training loss: 2.388756314623125
Validation loss: 2.6096968442202377

Epoch: 5| Step: 9
Training loss: 1.84160301507012
Validation loss: 2.640631677471431

Epoch: 5| Step: 10
Training loss: 2.236388146540328
Validation loss: 2.611543462364234

Epoch: 230| Step: 0
Training loss: 1.8784454478551211
Validation loss: 2.6013027816479037

Epoch: 5| Step: 1
Training loss: 2.505193085072217
Validation loss: 2.5658451159314604

Epoch: 5| Step: 2
Training loss: 2.0504602380826027
Validation loss: 2.6005929484537087

Epoch: 5| Step: 3
Training loss: 1.8849385394693654
Validation loss: 2.6415130603441614

Epoch: 5| Step: 4
Training loss: 2.432328827687773
Validation loss: 2.6144625205194387

Epoch: 5| Step: 5
Training loss: 2.2120644221452834
Validation loss: 2.5938988040128006

Epoch: 5| Step: 6
Training loss: 1.6260116069327817
Validation loss: 2.5941209761300423

Epoch: 5| Step: 7
Training loss: 2.428182153998758
Validation loss: 2.580186023408959

Epoch: 5| Step: 8
Training loss: 2.1986412794375925
Validation loss: 2.5498962349462584

Epoch: 5| Step: 9
Training loss: 2.6929153175907414
Validation loss: 2.566115187470731

Epoch: 5| Step: 10
Training loss: 2.6009344769136806
Validation loss: 2.5469365749468893

Epoch: 231| Step: 0
Training loss: 2.2976890730240123
Validation loss: 2.5414948565913105

Epoch: 5| Step: 1
Training loss: 2.2078993988753655
Validation loss: 2.546751221528367

Epoch: 5| Step: 2
Training loss: 2.061324969721742
Validation loss: 2.5699394547072485

Epoch: 5| Step: 3
Training loss: 2.2713099221621444
Validation loss: 2.5841999661141597

Epoch: 5| Step: 4
Training loss: 2.369792046739038
Validation loss: 2.609348882787998

Epoch: 5| Step: 5
Training loss: 2.197108284297168
Validation loss: 2.627080919754629

Epoch: 5| Step: 6
Training loss: 1.7395653257370687
Validation loss: 2.6565704953415277

Epoch: 5| Step: 7
Training loss: 2.6625046635976433
Validation loss: 2.6550318038790923

Epoch: 5| Step: 8
Training loss: 2.4647757495139078
Validation loss: 2.6738779471181893

Epoch: 5| Step: 9
Training loss: 1.8009699724649995
Validation loss: 2.625617562587294

Epoch: 5| Step: 10
Training loss: 2.3481697625327467
Validation loss: 2.601753173431229

Epoch: 232| Step: 0
Training loss: 2.2321715260435715
Validation loss: 2.5757274468705096

Epoch: 5| Step: 1
Training loss: 2.248298001286282
Validation loss: 2.552658524192785

Epoch: 5| Step: 2
Training loss: 2.0681285927523145
Validation loss: 2.564198195119231

Epoch: 5| Step: 3
Training loss: 3.006060201319987
Validation loss: 2.5814522461757243

Epoch: 5| Step: 4
Training loss: 2.251886848208904
Validation loss: 2.5557318374808182

Epoch: 5| Step: 5
Training loss: 1.885506629553859
Validation loss: 2.558631813651051

Epoch: 5| Step: 6
Training loss: 2.123193983159455
Validation loss: 2.549376156907869

Epoch: 5| Step: 7
Training loss: 1.7838227280865206
Validation loss: 2.5945271122149447

Epoch: 5| Step: 8
Training loss: 1.8842157223825278
Validation loss: 2.582770014430949

Epoch: 5| Step: 9
Training loss: 2.1292708618389
Validation loss: 2.59342679756429

Epoch: 5| Step: 10
Training loss: 2.5014575524031204
Validation loss: 2.5759092243983854

Epoch: 233| Step: 0
Training loss: 2.183672362739651
Validation loss: 2.5788668820803986

Epoch: 5| Step: 1
Training loss: 2.043298873341127
Validation loss: 2.5735601011124865

Epoch: 5| Step: 2
Training loss: 2.0619654107138823
Validation loss: 2.594580998433045

Epoch: 5| Step: 3
Training loss: 2.1918194223215375
Validation loss: 2.602971679842803

Epoch: 5| Step: 4
Training loss: 1.9267261964627627
Validation loss: 2.638433556887742

Epoch: 5| Step: 5
Training loss: 2.4020301179927244
Validation loss: 2.634228743875293

Epoch: 5| Step: 6
Training loss: 2.5362446804000243
Validation loss: 2.6154681966335325

Epoch: 5| Step: 7
Training loss: 2.2431893585997495
Validation loss: 2.5975784964917628

Epoch: 5| Step: 8
Training loss: 2.1647139577458874
Validation loss: 2.5907962653348777

Epoch: 5| Step: 9
Training loss: 2.556027122425294
Validation loss: 2.583444978628265

Epoch: 5| Step: 10
Training loss: 1.8816250424079382
Validation loss: 2.5935406561475935

Epoch: 234| Step: 0
Training loss: 2.3420456856719114
Validation loss: 2.5650700012766783

Epoch: 5| Step: 1
Training loss: 1.8560680826870495
Validation loss: 2.5880376411295876

Epoch: 5| Step: 2
Training loss: 2.1045769269482335
Validation loss: 2.610511544548271

Epoch: 5| Step: 3
Training loss: 2.275372812094975
Validation loss: 2.6157764909969834

Epoch: 5| Step: 4
Training loss: 2.559758184903301
Validation loss: 2.6641668377998817

Epoch: 5| Step: 5
Training loss: 2.517328574017832
Validation loss: 2.6744346694431034

Epoch: 5| Step: 6
Training loss: 2.212701208588446
Validation loss: 2.655039477317376

Epoch: 5| Step: 7
Training loss: 1.9582463373651322
Validation loss: 2.5859654418280367

Epoch: 5| Step: 8
Training loss: 2.1996916945046645
Validation loss: 2.5530516722126864

Epoch: 5| Step: 9
Training loss: 2.4701608417050136
Validation loss: 2.5216629370384394

Epoch: 5| Step: 10
Training loss: 1.4743615756974082
Validation loss: 2.5172593291775067

Epoch: 235| Step: 0
Training loss: 2.2282422606013763
Validation loss: 2.537846725847284

Epoch: 5| Step: 1
Training loss: 1.6661406958658713
Validation loss: 2.5510645694932528

Epoch: 5| Step: 2
Training loss: 1.9527296352767731
Validation loss: 2.5930465750580662

Epoch: 5| Step: 3
Training loss: 2.0256361633200326
Validation loss: 2.61776053299387

Epoch: 5| Step: 4
Training loss: 2.4618294204633644
Validation loss: 2.6619066958396047

Epoch: 5| Step: 5
Training loss: 2.403977745562481
Validation loss: 2.654683177353734

Epoch: 5| Step: 6
Training loss: 1.9264628536940982
Validation loss: 2.641840004337858

Epoch: 5| Step: 7
Training loss: 2.028041594543366
Validation loss: 2.6368175555835194

Epoch: 5| Step: 8
Training loss: 2.502691441395879
Validation loss: 2.63547500597012

Epoch: 5| Step: 9
Training loss: 2.637436064175726
Validation loss: 2.608162349417388

Epoch: 5| Step: 10
Training loss: 1.9272611862453761
Validation loss: 2.622126694831923

Epoch: 236| Step: 0
Training loss: 2.693386108177245
Validation loss: 2.588480403328114

Epoch: 5| Step: 1
Training loss: 2.67919543672562
Validation loss: 2.595971533070291

Epoch: 5| Step: 2
Training loss: 1.6366478078394011
Validation loss: 2.610062365514653

Epoch: 5| Step: 3
Training loss: 1.2286983287420834
Validation loss: 2.5869801150064546

Epoch: 5| Step: 4
Training loss: 1.8001746357867157
Validation loss: 2.5917535029841465

Epoch: 5| Step: 5
Training loss: 2.393287721622546
Validation loss: 2.5823272981656453

Epoch: 5| Step: 6
Training loss: 2.010867870343544
Validation loss: 2.6133160283396997

Epoch: 5| Step: 7
Training loss: 2.35159311876609
Validation loss: 2.6233153995233907

Epoch: 5| Step: 8
Training loss: 2.45340508483922
Validation loss: 2.61187528267197

Epoch: 5| Step: 9
Training loss: 1.8321313891666722
Validation loss: 2.604922538742347

Epoch: 5| Step: 10
Training loss: 2.205000383545719
Validation loss: 2.585408063026452

Epoch: 237| Step: 0
Training loss: 2.050105217815361
Validation loss: 2.5774887895947534

Epoch: 5| Step: 1
Training loss: 1.7431522999428073
Validation loss: 2.6017792013532284

Epoch: 5| Step: 2
Training loss: 2.3437599690543194
Validation loss: 2.59296585468089

Epoch: 5| Step: 3
Training loss: 2.401789109627243
Validation loss: 2.6064099841284625

Epoch: 5| Step: 4
Training loss: 2.2044754759059693
Validation loss: 2.6494790087282563

Epoch: 5| Step: 5
Training loss: 1.7989283232476543
Validation loss: 2.6888063980127908

Epoch: 5| Step: 6
Training loss: 2.0628380931832107
Validation loss: 2.6969004491042714

Epoch: 5| Step: 7
Training loss: 2.1098792709595737
Validation loss: 2.706904164072959

Epoch: 5| Step: 8
Training loss: 2.5056494775814904
Validation loss: 2.656505544918073

Epoch: 5| Step: 9
Training loss: 2.2372719717776612
Validation loss: 2.6448085697246553

Epoch: 5| Step: 10
Training loss: 2.4178291243511287
Validation loss: 2.594464941487576

Epoch: 238| Step: 0
Training loss: 2.6444797708073375
Validation loss: 2.5747162230555123

Epoch: 5| Step: 1
Training loss: 1.5190412422643675
Validation loss: 2.5595414775562513

Epoch: 5| Step: 2
Training loss: 1.954169276492634
Validation loss: 2.5595571585816197

Epoch: 5| Step: 3
Training loss: 2.0180645750468043
Validation loss: 2.5463133373251674

Epoch: 5| Step: 4
Training loss: 2.9084106945107213
Validation loss: 2.5783915093904546

Epoch: 5| Step: 5
Training loss: 2.311646381262583
Validation loss: 2.5837067178093602

Epoch: 5| Step: 6
Training loss: 2.258393843099409
Validation loss: 2.5808303257055383

Epoch: 5| Step: 7
Training loss: 1.9551524511151146
Validation loss: 2.576172412373229

Epoch: 5| Step: 8
Training loss: 1.8707447084818238
Validation loss: 2.571231799699687

Epoch: 5| Step: 9
Training loss: 1.8868002548146434
Validation loss: 2.581174017151781

Epoch: 5| Step: 10
Training loss: 2.0505766266962873
Validation loss: 2.590499129062079

Epoch: 239| Step: 0
Training loss: 1.941442477772837
Validation loss: 2.61133892802507

Epoch: 5| Step: 1
Training loss: 2.168313268832069
Validation loss: 2.6203621953132643

Epoch: 5| Step: 2
Training loss: 2.464896949641318
Validation loss: 2.6081452006753256

Epoch: 5| Step: 3
Training loss: 2.2197522330991983
Validation loss: 2.597306234282596

Epoch: 5| Step: 4
Training loss: 2.1935713301278548
Validation loss: 2.5750178661337926

Epoch: 5| Step: 5
Training loss: 2.0659115637272194
Validation loss: 2.549314207463434

Epoch: 5| Step: 6
Training loss: 2.0862740805889235
Validation loss: 2.5475540327944923

Epoch: 5| Step: 7
Training loss: 2.0813667424999056
Validation loss: 2.5524913636615154

Epoch: 5| Step: 8
Training loss: 1.9170184918239561
Validation loss: 2.5858559598856763

Epoch: 5| Step: 9
Training loss: 2.356653424845844
Validation loss: 2.573508902702671

Epoch: 5| Step: 10
Training loss: 1.9473968124965326
Validation loss: 2.591981704372497

Epoch: 240| Step: 0
Training loss: 2.176128147489121
Validation loss: 2.6465662460398764

Epoch: 5| Step: 1
Training loss: 2.2032753101774967
Validation loss: 2.690911684249545

Epoch: 5| Step: 2
Training loss: 2.3253002054970913
Validation loss: 2.6736041834215483

Epoch: 5| Step: 3
Training loss: 2.1038540397027394
Validation loss: 2.6354131562803262

Epoch: 5| Step: 4
Training loss: 1.909786133900859
Validation loss: 2.5795325510455953

Epoch: 5| Step: 5
Training loss: 2.165389112255995
Validation loss: 2.5460970201404507

Epoch: 5| Step: 6
Training loss: 2.2094931046187742
Validation loss: 2.5300440232824504

Epoch: 5| Step: 7
Training loss: 1.718794735413022
Validation loss: 2.5204546505071943

Epoch: 5| Step: 8
Training loss: 2.235427075231755
Validation loss: 2.507720567599319

Epoch: 5| Step: 9
Training loss: 2.3388720805011447
Validation loss: 2.5334954186720138

Epoch: 5| Step: 10
Training loss: 2.380832437264293
Validation loss: 2.5849941788357125

Epoch: 241| Step: 0
Training loss: 2.278574380390119
Validation loss: 2.629481046296898

Epoch: 5| Step: 1
Training loss: 1.8363045183557958
Validation loss: 2.6432737485620663

Epoch: 5| Step: 2
Training loss: 2.139363829271249
Validation loss: 2.6808703506890845

Epoch: 5| Step: 3
Training loss: 2.2291943438466597
Validation loss: 2.649638023505261

Epoch: 5| Step: 4
Training loss: 1.8218590711155744
Validation loss: 2.61153455282762

Epoch: 5| Step: 5
Training loss: 1.587982062490706
Validation loss: 2.613857369670976

Epoch: 5| Step: 6
Training loss: 2.3475886127293895
Validation loss: 2.595093221286753

Epoch: 5| Step: 7
Training loss: 2.5796506124686087
Validation loss: 2.5591326492580113

Epoch: 5| Step: 8
Training loss: 2.32273383910753
Validation loss: 2.554438779314557

Epoch: 5| Step: 9
Training loss: 2.543998826062633
Validation loss: 2.5593287315565227

Epoch: 5| Step: 10
Training loss: 1.4923921614494993
Validation loss: 2.555112290323867

Epoch: 242| Step: 0
Training loss: 1.0580499244549664
Validation loss: 2.568435801187709

Epoch: 5| Step: 1
Training loss: 2.080539075613291
Validation loss: 2.570997335247662

Epoch: 5| Step: 2
Training loss: 2.075738439954793
Validation loss: 2.601020399538566

Epoch: 5| Step: 3
Training loss: 2.224562218277628
Validation loss: 2.6155103138298643

Epoch: 5| Step: 4
Training loss: 2.024288985146573
Validation loss: 2.631889778706828

Epoch: 5| Step: 5
Training loss: 1.768303518927814
Validation loss: 2.635562670569522

Epoch: 5| Step: 6
Training loss: 2.1213493403932357
Validation loss: 2.6586001033155657

Epoch: 5| Step: 7
Training loss: 1.8467780641267235
Validation loss: 2.6615589862024382

Epoch: 5| Step: 8
Training loss: 2.259076144343068
Validation loss: 2.6595056983432293

Epoch: 5| Step: 9
Training loss: 2.415043307561726
Validation loss: 2.635593682843521

Epoch: 5| Step: 10
Training loss: 2.926838132604496
Validation loss: 2.6049517393630284

Epoch: 243| Step: 0
Training loss: 1.7923656770822995
Validation loss: 2.5943333285761647

Epoch: 5| Step: 1
Training loss: 2.029031099129067
Validation loss: 2.571586573635019

Epoch: 5| Step: 2
Training loss: 2.013215628440098
Validation loss: 2.5810703252298364

Epoch: 5| Step: 3
Training loss: 1.6498474310649534
Validation loss: 2.556296046973773

Epoch: 5| Step: 4
Training loss: 2.3753707997831417
Validation loss: 2.5691667437921515

Epoch: 5| Step: 5
Training loss: 1.900735853149318
Validation loss: 2.596074657461261

Epoch: 5| Step: 6
Training loss: 2.0462400893132733
Validation loss: 2.6243557048957373

Epoch: 5| Step: 7
Training loss: 2.317381680790126
Validation loss: 2.6420178299126693

Epoch: 5| Step: 8
Training loss: 2.601577621278549
Validation loss: 2.6485727401307275

Epoch: 5| Step: 9
Training loss: 2.152051625444399
Validation loss: 2.667797253369927

Epoch: 5| Step: 10
Training loss: 1.8313047355309415
Validation loss: 2.6627376039231163

Epoch: 244| Step: 0
Training loss: 2.362056294913001
Validation loss: 2.688133050717821

Epoch: 5| Step: 1
Training loss: 2.480097416994829
Validation loss: 2.684526101594586

Epoch: 5| Step: 2
Training loss: 1.8901156535412316
Validation loss: 2.66628918039699

Epoch: 5| Step: 3
Training loss: 1.6914227420980754
Validation loss: 2.6734444154522747

Epoch: 5| Step: 4
Training loss: 2.5318322159677193
Validation loss: 2.6530000622901624

Epoch: 5| Step: 5
Training loss: 2.4291146636508985
Validation loss: 2.663782468965063

Epoch: 5| Step: 6
Training loss: 1.6371251150333468
Validation loss: 2.669300396403133

Epoch: 5| Step: 7
Training loss: 1.7916596065056851
Validation loss: 2.6516571739035473

Epoch: 5| Step: 8
Training loss: 1.917274675820054
Validation loss: 2.604622282144074

Epoch: 5| Step: 9
Training loss: 1.9616861927850802
Validation loss: 2.5671280656999738

Epoch: 5| Step: 10
Training loss: 1.855859847762253
Validation loss: 2.5196064599409707

Epoch: 245| Step: 0
Training loss: 1.7231226698368824
Validation loss: 2.542425939588999

Epoch: 5| Step: 1
Training loss: 2.1872735042479836
Validation loss: 2.5499693579363862

Epoch: 5| Step: 2
Training loss: 1.7384719572573046
Validation loss: 2.564343026529136

Epoch: 5| Step: 3
Training loss: 1.6932999579577237
Validation loss: 2.58866204393114

Epoch: 5| Step: 4
Training loss: 2.469019428471835
Validation loss: 2.605298462735086

Epoch: 5| Step: 5
Training loss: 2.098657464991605
Validation loss: 2.7015342871158947

Epoch: 5| Step: 6
Training loss: 2.257338635833665
Validation loss: 2.7288245101151754

Epoch: 5| Step: 7
Training loss: 1.9697847825818846
Validation loss: 2.7708877223824353

Epoch: 5| Step: 8
Training loss: 2.589960294146678
Validation loss: 2.763855804105453

Epoch: 5| Step: 9
Training loss: 2.37101300524713
Validation loss: 2.756811170793062

Epoch: 5| Step: 10
Training loss: 1.8976404848225206
Validation loss: 2.745885569646522

Epoch: 246| Step: 0
Training loss: 1.7351230692020378
Validation loss: 2.700559203675814

Epoch: 5| Step: 1
Training loss: 1.9155274682162846
Validation loss: 2.6642405791717727

Epoch: 5| Step: 2
Training loss: 2.363595887984661
Validation loss: 2.645294993808391

Epoch: 5| Step: 3
Training loss: 1.7435698905000832
Validation loss: 2.607739911914589

Epoch: 5| Step: 4
Training loss: 1.513743855395395
Validation loss: 2.5959574733434794

Epoch: 5| Step: 5
Training loss: 2.5845854298764888
Validation loss: 2.5810493666375223

Epoch: 5| Step: 6
Training loss: 2.1641169241661604
Validation loss: 2.6060403746976433

Epoch: 5| Step: 7
Training loss: 2.2390216448318205
Validation loss: 2.6101245880502453

Epoch: 5| Step: 8
Training loss: 2.021969531530579
Validation loss: 2.6145987551693985

Epoch: 5| Step: 9
Training loss: 2.387994453398175
Validation loss: 2.617617780602761

Epoch: 5| Step: 10
Training loss: 2.218524652776986
Validation loss: 2.621827678064408

Epoch: 247| Step: 0
Training loss: 1.9118940253556613
Validation loss: 2.610242920710499

Epoch: 5| Step: 1
Training loss: 2.415526702183688
Validation loss: 2.594953429541032

Epoch: 5| Step: 2
Training loss: 2.030895730449139
Validation loss: 2.586820771721637

Epoch: 5| Step: 3
Training loss: 2.242242686160746
Validation loss: 2.593836022245458

Epoch: 5| Step: 4
Training loss: 2.0228311815935838
Validation loss: 2.6041673984321467

Epoch: 5| Step: 5
Training loss: 2.5035049664429256
Validation loss: 2.611459923957435

Epoch: 5| Step: 6
Training loss: 1.7403887028449583
Validation loss: 2.6125490296552716

Epoch: 5| Step: 7
Training loss: 1.6743717267900449
Validation loss: 2.621915043636267

Epoch: 5| Step: 8
Training loss: 2.0731708875516506
Validation loss: 2.6403054285913994

Epoch: 5| Step: 9
Training loss: 1.5188852226435081
Validation loss: 2.638566152061477

Epoch: 5| Step: 10
Training loss: 2.345792566987538
Validation loss: 2.6577986929848114

Epoch: 248| Step: 0
Training loss: 2.2457535195780105
Validation loss: 2.6774432642329122

Epoch: 5| Step: 1
Training loss: 2.0206129471725887
Validation loss: 2.667417878685975

Epoch: 5| Step: 2
Training loss: 1.9718038700290585
Validation loss: 2.6744847409891332

Epoch: 5| Step: 3
Training loss: 1.9127828874992798
Validation loss: 2.6812992186182947

Epoch: 5| Step: 4
Training loss: 1.762892575202673
Validation loss: 2.685044283944434

Epoch: 5| Step: 5
Training loss: 1.7748445818919514
Validation loss: 2.707187913637416

Epoch: 5| Step: 6
Training loss: 1.935819943409511
Validation loss: 2.680455622750564

Epoch: 5| Step: 7
Training loss: 1.760715173396658
Validation loss: 2.6700384437417637

Epoch: 5| Step: 8
Training loss: 2.0320651252853286
Validation loss: 2.6703725669779907

Epoch: 5| Step: 9
Training loss: 2.668698748558758
Validation loss: 2.6430148655469936

Epoch: 5| Step: 10
Training loss: 2.314837949283991
Validation loss: 2.6503640863917735

Epoch: 249| Step: 0
Training loss: 2.1126875122637276
Validation loss: 2.6473904908424815

Epoch: 5| Step: 1
Training loss: 1.9198824470018434
Validation loss: 2.6399815243739195

Epoch: 5| Step: 2
Training loss: 2.2195922972069244
Validation loss: 2.6252410541648414

Epoch: 5| Step: 3
Training loss: 1.5653418065924338
Validation loss: 2.6150861889879633

Epoch: 5| Step: 4
Training loss: 1.861898809090593
Validation loss: 2.6187180132445316

Epoch: 5| Step: 5
Training loss: 2.066735975067257
Validation loss: 2.6039602123172947

Epoch: 5| Step: 6
Training loss: 1.9019939876545606
Validation loss: 2.6325474849095856

Epoch: 5| Step: 7
Training loss: 2.348123361131565
Validation loss: 2.6496135929136484

Epoch: 5| Step: 8
Training loss: 2.18550345724579
Validation loss: 2.705632989754356

Epoch: 5| Step: 9
Training loss: 2.207663440464494
Validation loss: 2.735166647325188

Epoch: 5| Step: 10
Training loss: 2.13718801084251
Validation loss: 2.6554869586713328

Epoch: 250| Step: 0
Training loss: 1.7737151613369375
Validation loss: 2.6136793701558365

Epoch: 5| Step: 1
Training loss: 2.4104315354776915
Validation loss: 2.5856334870790545

Epoch: 5| Step: 2
Training loss: 2.1997665888337155
Validation loss: 2.5614078594438334

Epoch: 5| Step: 3
Training loss: 2.5891992563931114
Validation loss: 2.5523632472821767

Epoch: 5| Step: 4
Training loss: 1.799053298160675
Validation loss: 2.578209059691344

Epoch: 5| Step: 5
Training loss: 1.8627054856382441
Validation loss: 2.6006903979644482

Epoch: 5| Step: 6
Training loss: 2.1563408873932812
Validation loss: 2.6344165090132945

Epoch: 5| Step: 7
Training loss: 1.9156898898262589
Validation loss: 2.678800143874858

Epoch: 5| Step: 8
Training loss: 1.428986758075329
Validation loss: 2.721982843141107

Epoch: 5| Step: 9
Training loss: 2.3253158928992894
Validation loss: 2.7320216942816464

Epoch: 5| Step: 10
Training loss: 1.7530864337344227
Validation loss: 2.7658011031218406

Testing loss: 2.708527973712499
