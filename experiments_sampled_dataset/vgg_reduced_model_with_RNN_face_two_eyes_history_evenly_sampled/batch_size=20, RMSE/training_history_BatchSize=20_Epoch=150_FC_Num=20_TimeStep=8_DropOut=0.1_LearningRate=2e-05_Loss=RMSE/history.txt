Epoch: 1| Step: 0
Training loss: 6.530504686092655
Validation loss: 5.777601152727834

Epoch: 5| Step: 1
Training loss: 5.045947671734596
Validation loss: 5.760332092199534

Epoch: 5| Step: 2
Training loss: 5.621177561375701
Validation loss: 5.74616091179167

Epoch: 5| Step: 3
Training loss: 6.200823686090931
Validation loss: 5.732355643462067

Epoch: 5| Step: 4
Training loss: 6.032599579818777
Validation loss: 5.717015526595958

Epoch: 5| Step: 5
Training loss: 4.959561855591527
Validation loss: 5.698954659896309

Epoch: 5| Step: 6
Training loss: 5.195179964827336
Validation loss: 5.6782189998857415

Epoch: 5| Step: 7
Training loss: 6.1180701465507275
Validation loss: 5.654759085172853

Epoch: 5| Step: 8
Training loss: 5.563913572911263
Validation loss: 5.627737635622811

Epoch: 5| Step: 9
Training loss: 5.918884971876269
Validation loss: 5.5977130654553395

Epoch: 5| Step: 10
Training loss: 5.55903002916087
Validation loss: 5.563433172639694

Epoch: 2| Step: 0
Training loss: 5.590743125149487
Validation loss: 5.526074531272423

Epoch: 5| Step: 1
Training loss: 4.897623825026757
Validation loss: 5.485539845086064

Epoch: 5| Step: 2
Training loss: 5.5821532335560615
Validation loss: 5.443061610447388

Epoch: 5| Step: 3
Training loss: 5.312591372433428
Validation loss: 5.398319521912864

Epoch: 5| Step: 4
Training loss: 4.8253276338173805
Validation loss: 5.352328003643572

Epoch: 5| Step: 5
Training loss: 5.830922127978458
Validation loss: 5.306598077203915

Epoch: 5| Step: 6
Training loss: 5.79813373400125
Validation loss: 5.2580709381235415

Epoch: 5| Step: 7
Training loss: 4.554305988122369
Validation loss: 5.2062151664566505

Epoch: 5| Step: 8
Training loss: 5.221786620638056
Validation loss: 5.152932991889249

Epoch: 5| Step: 9
Training loss: 5.465678894928854
Validation loss: 5.09573341948966

Epoch: 5| Step: 10
Training loss: 5.624144934196195
Validation loss: 5.035654962419252

Epoch: 3| Step: 0
Training loss: 5.420669993413197
Validation loss: 4.9741764796677215

Epoch: 5| Step: 1
Training loss: 5.266963075594213
Validation loss: 4.914439374533927

Epoch: 5| Step: 2
Training loss: 4.440439674327619
Validation loss: 4.854107452852486

Epoch: 5| Step: 3
Training loss: 5.018731506997665
Validation loss: 4.80097290052753

Epoch: 5| Step: 4
Training loss: 4.331345664725223
Validation loss: 4.756088087937258

Epoch: 5| Step: 5
Training loss: 4.670394816076807
Validation loss: 4.7137893802934006

Epoch: 5| Step: 6
Training loss: 5.210513439395778
Validation loss: 4.675610547362748

Epoch: 5| Step: 7
Training loss: 5.498883740983309
Validation loss: 4.635986602060977

Epoch: 5| Step: 8
Training loss: 4.796954722782648
Validation loss: 4.603248168633216

Epoch: 5| Step: 9
Training loss: 3.2994926871866
Validation loss: 4.565927925624379

Epoch: 5| Step: 10
Training loss: 4.682211168365956
Validation loss: 4.533826580454795

Epoch: 4| Step: 0
Training loss: 4.671908069098055
Validation loss: 4.4974984470465005

Epoch: 5| Step: 1
Training loss: 4.11555949675296
Validation loss: 4.46516668451484

Epoch: 5| Step: 2
Training loss: 4.286298462245284
Validation loss: 4.439169925823629

Epoch: 5| Step: 3
Training loss: 4.528992610185002
Validation loss: 4.41293651242869

Epoch: 5| Step: 4
Training loss: 4.019848216972875
Validation loss: 4.390538882434012

Epoch: 5| Step: 5
Training loss: 5.204398517722717
Validation loss: 4.364943762163953

Epoch: 5| Step: 6
Training loss: 4.860365199429583
Validation loss: 4.338206208122083

Epoch: 5| Step: 7
Training loss: 4.502204990582023
Validation loss: 4.31216610327334

Epoch: 5| Step: 8
Training loss: 4.696793765281161
Validation loss: 4.2857929411495475

Epoch: 5| Step: 9
Training loss: 3.382199273679758
Validation loss: 4.2476146393140075

Epoch: 5| Step: 10
Training loss: 4.813995921495752
Validation loss: 4.227009397883136

Epoch: 5| Step: 0
Training loss: 4.376443243393713
Validation loss: 4.1971688799084035

Epoch: 5| Step: 1
Training loss: 4.504618923314947
Validation loss: 4.171672409784094

Epoch: 5| Step: 2
Training loss: 3.1151154402746926
Validation loss: 4.16495164748876

Epoch: 5| Step: 3
Training loss: 3.9934221064444535
Validation loss: 4.1403534248929805

Epoch: 5| Step: 4
Training loss: 4.324685613418301
Validation loss: 4.141910199201991

Epoch: 5| Step: 5
Training loss: 4.05580220858658
Validation loss: 4.113601628932628

Epoch: 5| Step: 6
Training loss: 4.607460374335759
Validation loss: 4.090821612236832

Epoch: 5| Step: 7
Training loss: 4.158012303336447
Validation loss: 4.076971362142487

Epoch: 5| Step: 8
Training loss: 3.7724646030835802
Validation loss: 4.048417248262463

Epoch: 5| Step: 9
Training loss: 5.267224349099818
Validation loss: 4.039679908068714

Epoch: 5| Step: 10
Training loss: 4.218275707569191
Validation loss: 4.028757759473582

Epoch: 6| Step: 0
Training loss: 3.810408221625301
Validation loss: 4.01423432159053

Epoch: 5| Step: 1
Training loss: 4.313758998033529
Validation loss: 3.993545082097942

Epoch: 5| Step: 2
Training loss: 3.8362762239466615
Validation loss: 3.9712665186556313

Epoch: 5| Step: 3
Training loss: 3.9173845214961744
Validation loss: 3.963380350949195

Epoch: 5| Step: 4
Training loss: 4.11438564678717
Validation loss: 3.9526143368187374

Epoch: 5| Step: 5
Training loss: 3.876368127306595
Validation loss: 3.9377799064032457

Epoch: 5| Step: 6
Training loss: 3.6618313696560856
Validation loss: 3.9202476177399146

Epoch: 5| Step: 7
Training loss: 4.676293774450641
Validation loss: 3.911617159764503

Epoch: 5| Step: 8
Training loss: 4.782440635683614
Validation loss: 3.9012500933928114

Epoch: 5| Step: 9
Training loss: 4.075444652426313
Validation loss: 3.8858920468025655

Epoch: 5| Step: 10
Training loss: 3.7422839572397186
Validation loss: 3.875250528727024

Epoch: 7| Step: 0
Training loss: 4.8034106535096495
Validation loss: 3.8600185735014327

Epoch: 5| Step: 1
Training loss: 3.720796294560184
Validation loss: 3.844370087232436

Epoch: 5| Step: 2
Training loss: 4.033810297820018
Validation loss: 3.834871694119083

Epoch: 5| Step: 3
Training loss: 3.323017768557509
Validation loss: 3.8224480342764524

Epoch: 5| Step: 4
Training loss: 3.898628306640663
Validation loss: 3.8113859940581114

Epoch: 5| Step: 5
Training loss: 4.399375368343987
Validation loss: 3.8002887643638563

Epoch: 5| Step: 6
Training loss: 3.974478364702011
Validation loss: 3.796381582195921

Epoch: 5| Step: 7
Training loss: 4.109920799067711
Validation loss: 3.785810242327274

Epoch: 5| Step: 8
Training loss: 3.8780115791844376
Validation loss: 3.7739444888797697

Epoch: 5| Step: 9
Training loss: 4.0715426235429675
Validation loss: 3.7621036091115614

Epoch: 5| Step: 10
Training loss: 3.2443541858985014
Validation loss: 3.7553515255990457

Epoch: 8| Step: 0
Training loss: 4.618406183353569
Validation loss: 3.7478673086594196

Epoch: 5| Step: 1
Training loss: 3.9693599442484926
Validation loss: 3.7392131809494504

Epoch: 5| Step: 2
Training loss: 4.841632404742368
Validation loss: 3.728212396825975

Epoch: 5| Step: 3
Training loss: 3.6349403630418884
Validation loss: 3.7176615307027054

Epoch: 5| Step: 4
Training loss: 3.589878418332666
Validation loss: 3.7102050542001614

Epoch: 5| Step: 5
Training loss: 3.487265717762169
Validation loss: 3.703416942897082

Epoch: 5| Step: 6
Training loss: 2.7089887755123776
Validation loss: 3.6930230702522904

Epoch: 5| Step: 7
Training loss: 3.361409977077563
Validation loss: 3.6904663979892023

Epoch: 5| Step: 8
Training loss: 4.113666107054877
Validation loss: 3.684891243228846

Epoch: 5| Step: 9
Training loss: 3.8840833460845112
Validation loss: 3.6746349552713973

Epoch: 5| Step: 10
Training loss: 4.228547425183542
Validation loss: 3.6701795515516524

Epoch: 9| Step: 0
Training loss: 4.077303398065679
Validation loss: 3.6642328283042485

Epoch: 5| Step: 1
Training loss: 3.9042100386244334
Validation loss: 3.6615184643106797

Epoch: 5| Step: 2
Training loss: 3.6799256719463513
Validation loss: 3.6529767916064793

Epoch: 5| Step: 3
Training loss: 4.129676249009219
Validation loss: 3.6478111117776977

Epoch: 5| Step: 4
Training loss: 3.9092159150441628
Validation loss: 3.63221682030028

Epoch: 5| Step: 5
Training loss: 4.605217354912396
Validation loss: 3.619349642123209

Epoch: 5| Step: 6
Training loss: 3.3479721650273397
Validation loss: 3.6167118994198524

Epoch: 5| Step: 7
Training loss: 3.7832651364626084
Validation loss: 3.6215876203016477

Epoch: 5| Step: 8
Training loss: 3.7559547194005165
Validation loss: 3.6036326301823856

Epoch: 5| Step: 9
Training loss: 3.4518013052573813
Validation loss: 3.6066956665029877

Epoch: 5| Step: 10
Training loss: 3.208889570362351
Validation loss: 3.612361474143009

Epoch: 10| Step: 0
Training loss: 4.2347934417613295
Validation loss: 3.617370908411496

Epoch: 5| Step: 1
Training loss: 3.3062875900583464
Validation loss: 3.604602784252481

Epoch: 5| Step: 2
Training loss: 3.807309228497387
Validation loss: 3.5941017866833893

Epoch: 5| Step: 3
Training loss: 3.20153694794243
Validation loss: 3.5815031973232894

Epoch: 5| Step: 4
Training loss: 3.3824075011513934
Validation loss: 3.5771170285132845

Epoch: 5| Step: 5
Training loss: 4.460540058983649
Validation loss: 3.563682132621338

Epoch: 5| Step: 6
Training loss: 4.023858679790676
Validation loss: 3.5573801434333845

Epoch: 5| Step: 7
Training loss: 3.9288037863049587
Validation loss: 3.547904705676584

Epoch: 5| Step: 8
Training loss: 3.5564907321002046
Validation loss: 3.5426595643654006

Epoch: 5| Step: 9
Training loss: 3.8341321251141087
Validation loss: 3.536741280039814

Epoch: 5| Step: 10
Training loss: 3.5513445551099214
Validation loss: 3.525045620318993

Epoch: 11| Step: 0
Training loss: 4.043699926334579
Validation loss: 3.5221376361703074

Epoch: 5| Step: 1
Training loss: 3.5407083149709044
Validation loss: 3.519969628670069

Epoch: 5| Step: 2
Training loss: 3.4899583909142096
Validation loss: 3.5149731993246824

Epoch: 5| Step: 3
Training loss: 3.6033287764904793
Validation loss: 3.50982371859617

Epoch: 5| Step: 4
Training loss: 3.5028763259979385
Validation loss: 3.504008384228749

Epoch: 5| Step: 5
Training loss: 3.321477851560688
Validation loss: 3.4971142634449577

Epoch: 5| Step: 6
Training loss: 3.607236550718141
Validation loss: 3.4918028799602037

Epoch: 5| Step: 7
Training loss: 4.148893571916945
Validation loss: 3.48562253785796

Epoch: 5| Step: 8
Training loss: 3.7259650241277025
Validation loss: 3.4798612740621295

Epoch: 5| Step: 9
Training loss: 4.3606672661815935
Validation loss: 3.472322531259586

Epoch: 5| Step: 10
Training loss: 3.238436742346481
Validation loss: 3.467078226872224

Epoch: 12| Step: 0
Training loss: 4.317889839777878
Validation loss: 3.4619191928668553

Epoch: 5| Step: 1
Training loss: 4.016083093779024
Validation loss: 3.4576828902503958

Epoch: 5| Step: 2
Training loss: 3.647261305405362
Validation loss: 3.4497513370388635

Epoch: 5| Step: 3
Training loss: 3.719904103427438
Validation loss: 3.4472517495089745

Epoch: 5| Step: 4
Training loss: 2.5573613817044514
Validation loss: 3.444926824267161

Epoch: 5| Step: 5
Training loss: 4.427707020826951
Validation loss: 3.443389160030408

Epoch: 5| Step: 6
Training loss: 3.2420367470128917
Validation loss: 3.4385972465354464

Epoch: 5| Step: 7
Training loss: 3.4051698144364146
Validation loss: 3.4327576292484476

Epoch: 5| Step: 8
Training loss: 3.933335054257119
Validation loss: 3.4233976752147957

Epoch: 5| Step: 9
Training loss: 3.709078867403159
Validation loss: 3.416396385225097

Epoch: 5| Step: 10
Training loss: 2.7271011825999305
Validation loss: 3.412650381190936

Epoch: 13| Step: 0
Training loss: 3.594867565702721
Validation loss: 3.4049618616510506

Epoch: 5| Step: 1
Training loss: 3.8512752650248445
Validation loss: 3.3969066701980335

Epoch: 5| Step: 2
Training loss: 3.9354523678168776
Validation loss: 3.386481276000675

Epoch: 5| Step: 3
Training loss: 2.7184021825937688
Validation loss: 3.379280930230211

Epoch: 5| Step: 4
Training loss: 4.6953728238767365
Validation loss: 3.3742997640584287

Epoch: 5| Step: 5
Training loss: 3.359300479505947
Validation loss: 3.3691107040391612

Epoch: 5| Step: 6
Training loss: 2.8115042725228183
Validation loss: 3.364238553084552

Epoch: 5| Step: 7
Training loss: 3.415034035866332
Validation loss: 3.3609798672108706

Epoch: 5| Step: 8
Training loss: 3.8462791495819424
Validation loss: 3.360663966621697

Epoch: 5| Step: 9
Training loss: 4.0049331762332505
Validation loss: 3.354185596663087

Epoch: 5| Step: 10
Training loss: 2.821888406749151
Validation loss: 3.3535307032461965

Epoch: 14| Step: 0
Training loss: 3.087737434925615
Validation loss: 3.3443711656188286

Epoch: 5| Step: 1
Training loss: 3.3609479193745395
Validation loss: 3.34062190498933

Epoch: 5| Step: 2
Training loss: 3.7501102431305036
Validation loss: 3.3360211293040827

Epoch: 5| Step: 3
Training loss: 3.6550632735384125
Validation loss: 3.32916259921441

Epoch: 5| Step: 4
Training loss: 3.3181362065829987
Validation loss: 3.324471711251073

Epoch: 5| Step: 5
Training loss: 3.2060366910951656
Validation loss: 3.3189745065633396

Epoch: 5| Step: 6
Training loss: 2.443863607043974
Validation loss: 3.3176442911852497

Epoch: 5| Step: 7
Training loss: 3.9122216317596705
Validation loss: 3.311900532910359

Epoch: 5| Step: 8
Training loss: 3.942873965991601
Validation loss: 3.310301822371488

Epoch: 5| Step: 9
Training loss: 4.346598397949441
Validation loss: 3.3071504373637532

Epoch: 5| Step: 10
Training loss: 3.8289846272552253
Validation loss: 3.3032395096692198

Epoch: 15| Step: 0
Training loss: 3.3297381722556456
Validation loss: 3.2997188397378783

Epoch: 5| Step: 1
Training loss: 3.6153083682409646
Validation loss: 3.2955290638300925

Epoch: 5| Step: 2
Training loss: 3.813183957644376
Validation loss: 3.292844603371153

Epoch: 5| Step: 3
Training loss: 3.5494368791568407
Validation loss: 3.2890893127706295

Epoch: 5| Step: 4
Training loss: 3.443584674944582
Validation loss: 3.28982871506551

Epoch: 5| Step: 5
Training loss: 3.231292435092563
Validation loss: 3.288874608053842

Epoch: 5| Step: 6
Training loss: 3.856310040518147
Validation loss: 3.3133307522147817

Epoch: 5| Step: 7
Training loss: 3.8157021254634267
Validation loss: 3.281388457502751

Epoch: 5| Step: 8
Training loss: 3.0223375631120275
Validation loss: 3.2832513615222276

Epoch: 5| Step: 9
Training loss: 3.739321317853262
Validation loss: 3.285216952937746

Epoch: 5| Step: 10
Training loss: 3.3434818909013333
Validation loss: 3.2808430455954363

Epoch: 16| Step: 0
Training loss: 3.426528066313393
Validation loss: 3.2808926561105034

Epoch: 5| Step: 1
Training loss: 3.510917393924336
Validation loss: 3.2812466044684294

Epoch: 5| Step: 2
Training loss: 4.0829046893743
Validation loss: 3.278248655656351

Epoch: 5| Step: 3
Training loss: 3.7398154240721464
Validation loss: 3.2758827420685934

Epoch: 5| Step: 4
Training loss: 3.8059947061346526
Validation loss: 3.2723590784558656

Epoch: 5| Step: 5
Training loss: 3.120247698757123
Validation loss: 3.2699956961114838

Epoch: 5| Step: 6
Training loss: 3.2168081407286033
Validation loss: 3.269266288615225

Epoch: 5| Step: 7
Training loss: 3.5473307178155262
Validation loss: 3.265717675594167

Epoch: 5| Step: 8
Training loss: 3.2591924512001373
Validation loss: 3.261928758252046

Epoch: 5| Step: 9
Training loss: 2.7680157172137205
Validation loss: 3.2620329706194373

Epoch: 5| Step: 10
Training loss: 4.1277336541531975
Validation loss: 3.262076034661485

Epoch: 17| Step: 0
Training loss: 3.085760261178002
Validation loss: 3.25992175505523

Epoch: 5| Step: 1
Training loss: 3.997831949141822
Validation loss: 3.2575371935452964

Epoch: 5| Step: 2
Training loss: 4.275758214268525
Validation loss: 3.254787582014924

Epoch: 5| Step: 3
Training loss: 3.282068350331845
Validation loss: 3.2511809800905827

Epoch: 5| Step: 4
Training loss: 3.243245662224357
Validation loss: 3.2498419970148427

Epoch: 5| Step: 5
Training loss: 3.5355859653367405
Validation loss: 3.248762008538173

Epoch: 5| Step: 6
Training loss: 4.156824516800843
Validation loss: 3.246862334108135

Epoch: 5| Step: 7
Training loss: 2.7139267504821167
Validation loss: 3.2460401247351767

Epoch: 5| Step: 8
Training loss: 2.9349896681959535
Validation loss: 3.2436038198653168

Epoch: 5| Step: 9
Training loss: 3.762726994254111
Validation loss: 3.242205020576992

Epoch: 5| Step: 10
Training loss: 3.093516485475816
Validation loss: 3.2428502729473445

Epoch: 18| Step: 0
Training loss: 3.793122371937295
Validation loss: 3.240094670009359

Epoch: 5| Step: 1
Training loss: 2.8672927712388447
Validation loss: 3.2389077812112927

Epoch: 5| Step: 2
Training loss: 3.819060137902264
Validation loss: 3.2372431193995577

Epoch: 5| Step: 3
Training loss: 3.981703277606929
Validation loss: 3.2354631409136236

Epoch: 5| Step: 4
Training loss: 3.2820023900220354
Validation loss: 3.2341718918561084

Epoch: 5| Step: 5
Training loss: 3.8553468014370105
Validation loss: 3.2325406652386985

Epoch: 5| Step: 6
Training loss: 2.918004374050447
Validation loss: 3.231245152511923

Epoch: 5| Step: 7
Training loss: 4.031987558951181
Validation loss: 3.2301088390974693

Epoch: 5| Step: 8
Training loss: 2.9831144057205026
Validation loss: 3.228271987351831

Epoch: 5| Step: 9
Training loss: 2.7410393291881996
Validation loss: 3.2267700754641804

Epoch: 5| Step: 10
Training loss: 3.7917868347129358
Validation loss: 3.2251792770760934

Epoch: 19| Step: 0
Training loss: 4.441249284344268
Validation loss: 3.2241133899878744

Epoch: 5| Step: 1
Training loss: 3.5086889042986464
Validation loss: 3.2225932787637372

Epoch: 5| Step: 2
Training loss: 2.9942556061785766
Validation loss: 3.221549791981975

Epoch: 5| Step: 3
Training loss: 3.239815674000832
Validation loss: 3.2210726602747695

Epoch: 5| Step: 4
Training loss: 3.761738778097644
Validation loss: 3.21889899554436

Epoch: 5| Step: 5
Training loss: 3.608898577272578
Validation loss: 3.2183497899202855

Epoch: 5| Step: 6
Training loss: 3.012304662172567
Validation loss: 3.216318406929493

Epoch: 5| Step: 7
Training loss: 3.840862523207538
Validation loss: 3.2145146940270815

Epoch: 5| Step: 8
Training loss: 2.923553474282998
Validation loss: 3.2138698708976

Epoch: 5| Step: 9
Training loss: 3.353175630924902
Validation loss: 3.2128286385200555

Epoch: 5| Step: 10
Training loss: 3.2438801586813777
Validation loss: 3.2114571853223786

Epoch: 20| Step: 0
Training loss: 3.634167227870026
Validation loss: 3.2106443564304303

Epoch: 5| Step: 1
Training loss: 3.554758595185325
Validation loss: 3.208629690886371

Epoch: 5| Step: 2
Training loss: 3.036433870316248
Validation loss: 3.208086163818006

Epoch: 5| Step: 3
Training loss: 3.2824544966507925
Validation loss: 3.207156565750125

Epoch: 5| Step: 4
Training loss: 3.5858702144252446
Validation loss: 3.205454887253051

Epoch: 5| Step: 5
Training loss: 3.060587538867145
Validation loss: 3.204303373236313

Epoch: 5| Step: 6
Training loss: 3.3615380708693894
Validation loss: 3.203657285421592

Epoch: 5| Step: 7
Training loss: 3.2163061845885355
Validation loss: 3.201938165766847

Epoch: 5| Step: 8
Training loss: 3.6198719189573216
Validation loss: 3.200933413090315

Epoch: 5| Step: 9
Training loss: 3.3004511380322805
Validation loss: 3.200773720045594

Epoch: 5| Step: 10
Training loss: 4.424955878603525
Validation loss: 3.1990600355850765

Epoch: 21| Step: 0
Training loss: 3.4561192575735578
Validation loss: 3.1974859182388666

Epoch: 5| Step: 1
Training loss: 3.882686375002918
Validation loss: 3.196265775177763

Epoch: 5| Step: 2
Training loss: 2.9971816811949075
Validation loss: 3.195152062263105

Epoch: 5| Step: 3
Training loss: 3.7637369954959192
Validation loss: 3.1935963482319774

Epoch: 5| Step: 4
Training loss: 3.367097149763039
Validation loss: 3.1908705390230785

Epoch: 5| Step: 5
Training loss: 3.8302576469433194
Validation loss: 3.189452002913292

Epoch: 5| Step: 6
Training loss: 3.7037746970118994
Validation loss: 3.187039891621287

Epoch: 5| Step: 7
Training loss: 3.3934619479234467
Validation loss: 3.1851607233423875

Epoch: 5| Step: 8
Training loss: 2.2503478523087006
Validation loss: 3.1829658195541812

Epoch: 5| Step: 9
Training loss: 3.7158232640017843
Validation loss: 3.181317785473946

Epoch: 5| Step: 10
Training loss: 3.28063188816306
Validation loss: 3.1811271239047305

Epoch: 22| Step: 0
Training loss: 3.9371934801715263
Validation loss: 3.17909236806033

Epoch: 5| Step: 1
Training loss: 3.5552261782776826
Validation loss: 3.177484559549387

Epoch: 5| Step: 2
Training loss: 3.0458092023638956
Validation loss: 3.1757953889038606

Epoch: 5| Step: 3
Training loss: 3.5743374830859445
Validation loss: 3.1732861802411088

Epoch: 5| Step: 4
Training loss: 3.30450741973889
Validation loss: 3.1715138846741127

Epoch: 5| Step: 5
Training loss: 3.5285387011191207
Validation loss: 3.170026150522427

Epoch: 5| Step: 6
Training loss: 3.080629211162863
Validation loss: 3.1681155407504566

Epoch: 5| Step: 7
Training loss: 3.78992180273063
Validation loss: 3.167381166075523

Epoch: 5| Step: 8
Training loss: 3.2530142670912796
Validation loss: 3.1645380653010817

Epoch: 5| Step: 9
Training loss: 3.4685843488300425
Validation loss: 3.163719021064954

Epoch: 5| Step: 10
Training loss: 3.106440093519665
Validation loss: 3.161664777460207

Epoch: 23| Step: 0
Training loss: 3.2093157234400804
Validation loss: 3.160179824504896

Epoch: 5| Step: 1
Training loss: 3.748467322895184
Validation loss: 3.159294851967853

Epoch: 5| Step: 2
Training loss: 3.339206639250446
Validation loss: 3.1578495322525155

Epoch: 5| Step: 3
Training loss: 3.4325723181189076
Validation loss: 3.15625712660833

Epoch: 5| Step: 4
Training loss: 4.037108902545933
Validation loss: 3.1562878169756154

Epoch: 5| Step: 5
Training loss: 3.2951929221743823
Validation loss: 3.1539785796698476

Epoch: 5| Step: 6
Training loss: 3.9018449283133347
Validation loss: 3.1533418080731277

Epoch: 5| Step: 7
Training loss: 3.489765598983985
Validation loss: 3.1516037593797113

Epoch: 5| Step: 8
Training loss: 2.798192742068555
Validation loss: 3.1507704198126794

Epoch: 5| Step: 9
Training loss: 2.6465098700051946
Validation loss: 3.149555504190318

Epoch: 5| Step: 10
Training loss: 3.5300981111373337
Validation loss: 3.14794882255198

Epoch: 24| Step: 0
Training loss: 3.1747108147552936
Validation loss: 3.147781655928211

Epoch: 5| Step: 1
Training loss: 3.4710945247878526
Validation loss: 3.1467236260955707

Epoch: 5| Step: 2
Training loss: 3.6173083818641167
Validation loss: 3.1456159967392283

Epoch: 5| Step: 3
Training loss: 3.5577929000750195
Validation loss: 3.1445024675914266

Epoch: 5| Step: 4
Training loss: 3.185539091230527
Validation loss: 3.1437763665184972

Epoch: 5| Step: 5
Training loss: 3.175342186938345
Validation loss: 3.142635277765201

Epoch: 5| Step: 6
Training loss: 4.09609708405715
Validation loss: 3.141465291536782

Epoch: 5| Step: 7
Training loss: 3.603843909716144
Validation loss: 3.140943233256184

Epoch: 5| Step: 8
Training loss: 3.1701345695548815
Validation loss: 3.139558912686972

Epoch: 5| Step: 9
Training loss: 3.0542984736694883
Validation loss: 3.137960829697466

Epoch: 5| Step: 10
Training loss: 3.3105733774750385
Validation loss: 3.137551870302561

Epoch: 25| Step: 0
Training loss: 3.200720801235393
Validation loss: 3.1361225856906776

Epoch: 5| Step: 1
Training loss: 3.2991030427740236
Validation loss: 3.1348505958753856

Epoch: 5| Step: 2
Training loss: 3.263429040281426
Validation loss: 3.134253052161189

Epoch: 5| Step: 3
Training loss: 3.5890538588782297
Validation loss: 3.1332680039106937

Epoch: 5| Step: 4
Training loss: 2.919588877594303
Validation loss: 3.131710684930718

Epoch: 5| Step: 5
Training loss: 3.5236201947334505
Validation loss: 3.131325108705981

Epoch: 5| Step: 6
Training loss: 3.606197262912228
Validation loss: 3.129886709704873

Epoch: 5| Step: 7
Training loss: 2.941946033327718
Validation loss: 3.1297484337765415

Epoch: 5| Step: 8
Training loss: 3.9290519792007372
Validation loss: 3.1284525456313803

Epoch: 5| Step: 9
Training loss: 3.6040806107730434
Validation loss: 3.1270475296013047

Epoch: 5| Step: 10
Training loss: 3.4726845361439387
Validation loss: 3.1264449694061316

Epoch: 26| Step: 0
Training loss: 3.0878421362219184
Validation loss: 3.1247567900491213

Epoch: 5| Step: 1
Training loss: 3.6260976773722913
Validation loss: 3.124897665993921

Epoch: 5| Step: 2
Training loss: 3.938077369623485
Validation loss: 3.12564279323682

Epoch: 5| Step: 3
Training loss: 2.982658971369296
Validation loss: 3.122751400743394

Epoch: 5| Step: 4
Training loss: 3.595972054208491
Validation loss: 3.1215217446063477

Epoch: 5| Step: 5
Training loss: 3.460323373975043
Validation loss: 3.120686288456468

Epoch: 5| Step: 6
Training loss: 3.0470449546950595
Validation loss: 3.119814286745834

Epoch: 5| Step: 7
Training loss: 3.8702331263781318
Validation loss: 3.118308598779645

Epoch: 5| Step: 8
Training loss: 3.0780464588349834
Validation loss: 3.117389164278403

Epoch: 5| Step: 9
Training loss: 3.1589914634325997
Validation loss: 3.117562707847819

Epoch: 5| Step: 10
Training loss: 3.3603959772112018
Validation loss: 3.116841244794204

Epoch: 27| Step: 0
Training loss: 3.226437619358057
Validation loss: 3.1152492306175352

Epoch: 5| Step: 1
Training loss: 2.9341742986225725
Validation loss: 3.114280853635404

Epoch: 5| Step: 2
Training loss: 3.7358998014748943
Validation loss: 3.1135249561846745

Epoch: 5| Step: 3
Training loss: 3.5827080972185676
Validation loss: 3.1126817926494814

Epoch: 5| Step: 4
Training loss: 3.1355530127264117
Validation loss: 3.1115524006917674

Epoch: 5| Step: 5
Training loss: 3.422206357476038
Validation loss: 3.1106711258774946

Epoch: 5| Step: 6
Training loss: 3.545786551956236
Validation loss: 3.108884605668387

Epoch: 5| Step: 7
Training loss: 3.0463769750229854
Validation loss: 3.108971939680591

Epoch: 5| Step: 8
Training loss: 3.5842656246083413
Validation loss: 3.107771137193493

Epoch: 5| Step: 9
Training loss: 3.80643606247914
Validation loss: 3.1065445506833833

Epoch: 5| Step: 10
Training loss: 3.0867047478762077
Validation loss: 3.106533027029482

Epoch: 28| Step: 0
Training loss: 2.980310038369278
Validation loss: 3.1057006551222455

Epoch: 5| Step: 1
Training loss: 3.7318830914681973
Validation loss: 3.1044103198253112

Epoch: 5| Step: 2
Training loss: 3.362430336383017
Validation loss: 3.1029815465195933

Epoch: 5| Step: 3
Training loss: 3.3201424588811888
Validation loss: 3.101441702723755

Epoch: 5| Step: 4
Training loss: 3.1320445196756035
Validation loss: 3.1016426922253895

Epoch: 5| Step: 5
Training loss: 4.140467226873257
Validation loss: 3.100164800531285

Epoch: 5| Step: 6
Training loss: 2.8732043754097156
Validation loss: 3.0990660747530407

Epoch: 5| Step: 7
Training loss: 3.5489880153682596
Validation loss: 3.0979374289815964

Epoch: 5| Step: 8
Training loss: 3.7340432502517933
Validation loss: 3.0969871538353346

Epoch: 5| Step: 9
Training loss: 3.064081211995866
Validation loss: 3.0963663701412623

Epoch: 5| Step: 10
Training loss: 3.023113696676767
Validation loss: 3.095325007323346

Epoch: 29| Step: 0
Training loss: 3.2619161032173576
Validation loss: 3.094681425683176

Epoch: 5| Step: 1
Training loss: 3.206038773328992
Validation loss: 3.0944549297714965

Epoch: 5| Step: 2
Training loss: 3.9882548272493366
Validation loss: 3.092411572521824

Epoch: 5| Step: 3
Training loss: 3.5900942577005974
Validation loss: 3.091265057783198

Epoch: 5| Step: 4
Training loss: 3.5368675178735853
Validation loss: 3.090134446302587

Epoch: 5| Step: 5
Training loss: 3.6006914852223773
Validation loss: 3.0895400112630993

Epoch: 5| Step: 6
Training loss: 2.937416887122085
Validation loss: 3.0884695074587465

Epoch: 5| Step: 7
Training loss: 3.2087341322467515
Validation loss: 3.0876441872742966

Epoch: 5| Step: 8
Training loss: 2.7368447621328764
Validation loss: 3.0864758417721716

Epoch: 5| Step: 9
Training loss: 3.3526613794865248
Validation loss: 3.0850618822425577

Epoch: 5| Step: 10
Training loss: 3.5294984507667437
Validation loss: 3.0848262640231825

Epoch: 30| Step: 0
Training loss: 3.5777601031017547
Validation loss: 3.0844647649441392

Epoch: 5| Step: 1
Training loss: 3.372449971160936
Validation loss: 3.083191352597335

Epoch: 5| Step: 2
Training loss: 2.7958502570453514
Validation loss: 3.0820275384959706

Epoch: 5| Step: 3
Training loss: 4.003477968710115
Validation loss: 3.0811308189279236

Epoch: 5| Step: 4
Training loss: 2.766345603728424
Validation loss: 3.0792488697838665

Epoch: 5| Step: 5
Training loss: 2.7854168998663003
Validation loss: 3.079603646350495

Epoch: 5| Step: 6
Training loss: 3.899487921523782
Validation loss: 3.0787884597021855

Epoch: 5| Step: 7
Training loss: 3.2528176931148653
Validation loss: 3.078215008965599

Epoch: 5| Step: 8
Training loss: 3.80788893217909
Validation loss: 3.0777227400094835

Epoch: 5| Step: 9
Training loss: 3.3216189697587577
Validation loss: 3.075518668847093

Epoch: 5| Step: 10
Training loss: 3.0912289606929404
Validation loss: 3.074211860177125

Epoch: 31| Step: 0
Training loss: 3.6103556568224686
Validation loss: 3.0765123437831052

Epoch: 5| Step: 1
Training loss: 3.316805362836566
Validation loss: 3.078163774286848

Epoch: 5| Step: 2
Training loss: 3.426802340566353
Validation loss: 3.0750639529230384

Epoch: 5| Step: 3
Training loss: 3.3858580942177254
Validation loss: 3.0733750646760587

Epoch: 5| Step: 4
Training loss: 2.535100292652133
Validation loss: 3.0715991138325234

Epoch: 5| Step: 5
Training loss: 4.014080062120982
Validation loss: 3.0702427352005075

Epoch: 5| Step: 6
Training loss: 3.0095720173169127
Validation loss: 3.0685912265600552

Epoch: 5| Step: 7
Training loss: 3.482901633736331
Validation loss: 3.0685033247415094

Epoch: 5| Step: 8
Training loss: 3.7806993824469264
Validation loss: 3.068755029652043

Epoch: 5| Step: 9
Training loss: 2.9678483095606505
Validation loss: 3.070075101821976

Epoch: 5| Step: 10
Training loss: 3.123026415368411
Validation loss: 3.06815702485583

Epoch: 32| Step: 0
Training loss: 2.536204258114751
Validation loss: 3.066652529359772

Epoch: 5| Step: 1
Training loss: 3.4597212675864
Validation loss: 3.0660706883494235

Epoch: 5| Step: 2
Training loss: 3.424206779680124
Validation loss: 3.0818580272970983

Epoch: 5| Step: 3
Training loss: 2.7255577706467373
Validation loss: 3.0615967269592805

Epoch: 5| Step: 4
Training loss: 3.5410612748281274
Validation loss: 3.0604101135907054

Epoch: 5| Step: 5
Training loss: 3.8187844432519933
Validation loss: 3.067070507751483

Epoch: 5| Step: 6
Training loss: 3.269932876037969
Validation loss: 3.067522229906886

Epoch: 5| Step: 7
Training loss: 3.3914515459102224
Validation loss: 3.06466143311648

Epoch: 5| Step: 8
Training loss: 3.0370902204982797
Validation loss: 3.060490131810865

Epoch: 5| Step: 9
Training loss: 3.5480015515879924
Validation loss: 3.0584557612842045

Epoch: 5| Step: 10
Training loss: 3.9634108787075095
Validation loss: 3.0578531835958986

Epoch: 33| Step: 0
Training loss: 3.0900506916023827
Validation loss: 3.057674441786039

Epoch: 5| Step: 1
Training loss: 3.066802136566465
Validation loss: 3.062878462891524

Epoch: 5| Step: 2
Training loss: 3.3275912577713607
Validation loss: 3.0562636091708266

Epoch: 5| Step: 3
Training loss: 3.1252557268412926
Validation loss: 3.0631766209068267

Epoch: 5| Step: 4
Training loss: 3.856160667040062
Validation loss: 3.109406392200832

Epoch: 5| Step: 5
Training loss: 3.6096952221992327
Validation loss: 3.057558030514766

Epoch: 5| Step: 6
Training loss: 3.0671586395320594
Validation loss: 3.0549508799430645

Epoch: 5| Step: 7
Training loss: 3.149250086574276
Validation loss: 3.058253208530356

Epoch: 5| Step: 8
Training loss: 3.020598426542521
Validation loss: 3.0591434067690764

Epoch: 5| Step: 9
Training loss: 3.9821491082562117
Validation loss: 3.0604079305990046

Epoch: 5| Step: 10
Training loss: 3.4544792454137903
Validation loss: 3.0559871969685535

Epoch: 34| Step: 0
Training loss: 3.2312038927459503
Validation loss: 3.0610792971959238

Epoch: 5| Step: 1
Training loss: 3.0050397502789936
Validation loss: 3.0545972845341343

Epoch: 5| Step: 2
Training loss: 3.495690417333241
Validation loss: 3.0491171959409598

Epoch: 5| Step: 3
Training loss: 3.3153282902848824
Validation loss: 3.044662135625033

Epoch: 5| Step: 4
Training loss: 2.6975991100244197
Validation loss: 3.0482390971103497

Epoch: 5| Step: 5
Training loss: 3.385385288190919
Validation loss: 3.059764238650906

Epoch: 5| Step: 6
Training loss: 3.176055258253389
Validation loss: 3.061859946285612

Epoch: 5| Step: 7
Training loss: 3.687857529716253
Validation loss: 3.061808213534532

Epoch: 5| Step: 8
Training loss: 3.4807227456247043
Validation loss: 3.0457289928789053

Epoch: 5| Step: 9
Training loss: 3.6622929641481474
Validation loss: 3.0396730702913515

Epoch: 5| Step: 10
Training loss: 3.5161837663592888
Validation loss: 3.0387039696439273

Epoch: 35| Step: 0
Training loss: 3.2579085155215473
Validation loss: 3.0385698715901572

Epoch: 5| Step: 1
Training loss: 3.9513959759807142
Validation loss: 3.037645525416938

Epoch: 5| Step: 2
Training loss: 3.399145013232576
Validation loss: 3.0371899589919087

Epoch: 5| Step: 3
Training loss: 3.352501228667965
Validation loss: 3.035418039249054

Epoch: 5| Step: 4
Training loss: 3.04107489555679
Validation loss: 3.0337214896896367

Epoch: 5| Step: 5
Training loss: 3.20693044004544
Validation loss: 3.0322099253992487

Epoch: 5| Step: 6
Training loss: 3.2681118927643724
Validation loss: 3.0327905432506093

Epoch: 5| Step: 7
Training loss: 2.9718550656329
Validation loss: 3.03128050896722

Epoch: 5| Step: 8
Training loss: 3.685723992374012
Validation loss: 3.0293095133550265

Epoch: 5| Step: 9
Training loss: 3.3469009526632956
Validation loss: 3.0275117188324563

Epoch: 5| Step: 10
Training loss: 2.9415886203113137
Validation loss: 3.0259199779681074

Epoch: 36| Step: 0
Training loss: 3.403739634094256
Validation loss: 3.0242443042173854

Epoch: 5| Step: 1
Training loss: 3.838777628892045
Validation loss: 3.0231028641354087

Epoch: 5| Step: 2
Training loss: 3.518226305407253
Validation loss: 3.0242253886635195

Epoch: 5| Step: 3
Training loss: 3.5146388048197394
Validation loss: 3.0226470599981545

Epoch: 5| Step: 4
Training loss: 3.642552859957622
Validation loss: 3.0218532403465215

Epoch: 5| Step: 5
Training loss: 3.076220547730017
Validation loss: 3.0217882649144676

Epoch: 5| Step: 6
Training loss: 3.2887861629572663
Validation loss: 3.019744996655022

Epoch: 5| Step: 7
Training loss: 2.9176700137826024
Validation loss: 3.023673362484958

Epoch: 5| Step: 8
Training loss: 2.411715752612427
Validation loss: 3.0311673077712173

Epoch: 5| Step: 9
Training loss: 3.892737982989791
Validation loss: 3.0825986449725864

Epoch: 5| Step: 10
Training loss: 2.5963044973282083
Validation loss: 3.0798949337636734

Epoch: 37| Step: 0
Training loss: 3.5906544497405215
Validation loss: 3.0800098282580373

Epoch: 5| Step: 1
Training loss: 3.4000195558770954
Validation loss: 3.0797298036060186

Epoch: 5| Step: 2
Training loss: 3.4079612143283993
Validation loss: 3.089796559672577

Epoch: 5| Step: 3
Training loss: 3.0815828526599147
Validation loss: 3.089291740863379

Epoch: 5| Step: 4
Training loss: 3.3778873384704418
Validation loss: 3.084803998487977

Epoch: 5| Step: 5
Training loss: 3.1771857239947208
Validation loss: 3.0791078735539577

Epoch: 5| Step: 6
Training loss: 3.3698541477234163
Validation loss: 3.0770356556827605

Epoch: 5| Step: 7
Training loss: 3.090626536678476
Validation loss: 3.076757275101248

Epoch: 5| Step: 8
Training loss: 3.2151420148983085
Validation loss: 3.0723929872342435

Epoch: 5| Step: 9
Training loss: 3.8296927842314243
Validation loss: 3.0714548050426447

Epoch: 5| Step: 10
Training loss: 3.359477338784581
Validation loss: 3.0713726844400404

Epoch: 38| Step: 0
Training loss: 3.8743627701068015
Validation loss: 3.0685902064809683

Epoch: 5| Step: 1
Training loss: 2.859970280953033
Validation loss: 3.0682913187280216

Epoch: 5| Step: 2
Training loss: 3.14841841699009
Validation loss: 3.0720949676505622

Epoch: 5| Step: 3
Training loss: 3.6895717684569744
Validation loss: 3.082368169735894

Epoch: 5| Step: 4
Training loss: 3.397671176845157
Validation loss: 3.084957529516474

Epoch: 5| Step: 5
Training loss: 4.087634928398245
Validation loss: 3.1121353673827645

Epoch: 5| Step: 6
Training loss: 3.584606181158402
Validation loss: 3.1388009368449556

Epoch: 5| Step: 7
Training loss: 2.942863599793947
Validation loss: 3.082158137162967

Epoch: 5| Step: 8
Training loss: 2.926549100259633
Validation loss: 3.0467170129565684

Epoch: 5| Step: 9
Training loss: 3.3729241663044585
Validation loss: 3.050217785146371

Epoch: 5| Step: 10
Training loss: 2.719381237193841
Validation loss: 3.0473412682050216

Epoch: 39| Step: 0
Training loss: 3.433430569083535
Validation loss: 3.0462492580815943

Epoch: 5| Step: 1
Training loss: 3.2148860219445163
Validation loss: 3.045878073231854

Epoch: 5| Step: 2
Training loss: 3.7822519031151485
Validation loss: 3.0489353059847084

Epoch: 5| Step: 3
Training loss: 4.0718534338754
Validation loss: 3.051497421686794

Epoch: 5| Step: 4
Training loss: 3.384673912535986
Validation loss: 3.050350086946052

Epoch: 5| Step: 5
Training loss: 2.8432231037675977
Validation loss: 3.0579086267893265

Epoch: 5| Step: 6
Training loss: 2.8568107071316144
Validation loss: 3.0572770244439713

Epoch: 5| Step: 7
Training loss: 3.2545785198014094
Validation loss: 3.04958860405657

Epoch: 5| Step: 8
Training loss: 2.7821592066368557
Validation loss: 3.031701632262446

Epoch: 5| Step: 9
Training loss: 3.5300606944455963
Validation loss: 3.0336237371736936

Epoch: 5| Step: 10
Training loss: 3.28024698095166
Validation loss: 3.035779594131825

Epoch: 40| Step: 0
Training loss: 3.897304209647877
Validation loss: 3.0364726180636574

Epoch: 5| Step: 1
Training loss: 3.5613670555364347
Validation loss: 3.035289887367722

Epoch: 5| Step: 2
Training loss: 3.08221829503121
Validation loss: 3.0343969121658256

Epoch: 5| Step: 3
Training loss: 3.6094349777720955
Validation loss: 3.0322769754523073

Epoch: 5| Step: 4
Training loss: 3.780699886943135
Validation loss: 3.0275325910754294

Epoch: 5| Step: 5
Training loss: 3.1630897062631917
Validation loss: 3.0281605751522154

Epoch: 5| Step: 6
Training loss: 2.026700485578925
Validation loss: 3.0218634071598145

Epoch: 5| Step: 7
Training loss: 3.3931459117560503
Validation loss: 3.027735758741965

Epoch: 5| Step: 8
Training loss: 3.221453077955921
Validation loss: 3.027596304339232

Epoch: 5| Step: 9
Training loss: 3.6475478727507866
Validation loss: 3.0507716938356677

Epoch: 5| Step: 10
Training loss: 2.6082658980389724
Validation loss: 3.0478239850736033

Epoch: 41| Step: 0
Training loss: 3.358843526272752
Validation loss: 3.0404673066145884

Epoch: 5| Step: 1
Training loss: 3.351890565692723
Validation loss: 3.034868221278813

Epoch: 5| Step: 2
Training loss: 3.217621837049047
Validation loss: 3.026181907144082

Epoch: 5| Step: 3
Training loss: 3.0223432428619588
Validation loss: 3.0255018892342047

Epoch: 5| Step: 4
Training loss: 3.2597167672529404
Validation loss: 3.026587127756958

Epoch: 5| Step: 5
Training loss: 3.378006337893352
Validation loss: 3.0261704553012163

Epoch: 5| Step: 6
Training loss: 3.211786830721506
Validation loss: 3.022504975538828

Epoch: 5| Step: 7
Training loss: 3.0012366607000978
Validation loss: 3.018958455668769

Epoch: 5| Step: 8
Training loss: 3.5925739520165774
Validation loss: 3.0207138637614306

Epoch: 5| Step: 9
Training loss: 3.7439298456009746
Validation loss: 3.0116244697521353

Epoch: 5| Step: 10
Training loss: 3.144504257939277
Validation loss: 3.011289276281138

Epoch: 42| Step: 0
Training loss: 3.0830791128019888
Validation loss: 3.013879531735688

Epoch: 5| Step: 1
Training loss: 2.359569617322553
Validation loss: 3.0222965457719084

Epoch: 5| Step: 2
Training loss: 3.3333882009441025
Validation loss: 3.0176723747058296

Epoch: 5| Step: 3
Training loss: 3.3219690835284643
Validation loss: 3.0177671005950018

Epoch: 5| Step: 4
Training loss: 2.810825782069824
Validation loss: 3.011304436962602

Epoch: 5| Step: 5
Training loss: 3.339711968571544
Validation loss: 3.007408202068265

Epoch: 5| Step: 6
Training loss: 3.7226867354306576
Validation loss: 3.0145310705611275

Epoch: 5| Step: 7
Training loss: 3.6913591008480298
Validation loss: 3.0154635546467

Epoch: 5| Step: 8
Training loss: 3.6169582483794334
Validation loss: 3.024634399057114

Epoch: 5| Step: 9
Training loss: 3.024021614683701
Validation loss: 3.0218828193663576

Epoch: 5| Step: 10
Training loss: 3.8256275983557613
Validation loss: 3.0145505333859615

Epoch: 43| Step: 0
Training loss: 4.2398232182050775
Validation loss: 3.0076535879047115

Epoch: 5| Step: 1
Training loss: 3.3497793438108245
Validation loss: 3.0064054081124167

Epoch: 5| Step: 2
Training loss: 2.5857932059145146
Validation loss: 3.0052155087460823

Epoch: 5| Step: 3
Training loss: 3.172801817236614
Validation loss: 3.005494333797943

Epoch: 5| Step: 4
Training loss: 3.3888154013192797
Validation loss: 3.003651476710927

Epoch: 5| Step: 5
Training loss: 3.628535158300045
Validation loss: 3.0013900633253745

Epoch: 5| Step: 6
Training loss: 2.54453717922964
Validation loss: 3.0035693698238473

Epoch: 5| Step: 7
Training loss: 3.09724306138521
Validation loss: 3.014245942696034

Epoch: 5| Step: 8
Training loss: 3.2334603753317177
Validation loss: 2.9984075719093273

Epoch: 5| Step: 9
Training loss: 3.4813818969943138
Validation loss: 2.9957491965668175

Epoch: 5| Step: 10
Training loss: 3.1077571474634023
Validation loss: 2.998614598056788

Epoch: 44| Step: 0
Training loss: 2.4361360108125103
Validation loss: 2.998731909151053

Epoch: 5| Step: 1
Training loss: 3.096388183270008
Validation loss: 2.995728204714365

Epoch: 5| Step: 2
Training loss: 3.035499032988227
Validation loss: 2.997296747568575

Epoch: 5| Step: 3
Training loss: 3.292767899837416
Validation loss: 2.9995050714223663

Epoch: 5| Step: 4
Training loss: 3.6805374880813093
Validation loss: 3.0178429291158237

Epoch: 5| Step: 5
Training loss: 2.9953399067929776
Validation loss: 3.0012654511964634

Epoch: 5| Step: 6
Training loss: 2.692706188641302
Validation loss: 3.002545660197578

Epoch: 5| Step: 7
Training loss: 3.9769584293777855
Validation loss: 2.986652568870481

Epoch: 5| Step: 8
Training loss: 3.37987392438697
Validation loss: 2.979590657637152

Epoch: 5| Step: 9
Training loss: 3.5588365423829726
Validation loss: 2.9854718369113065

Epoch: 5| Step: 10
Training loss: 3.6442746708902294
Validation loss: 2.970836502460331

Epoch: 45| Step: 0
Training loss: 2.7217098216622064
Validation loss: 2.934009568466013

Epoch: 5| Step: 1
Training loss: 2.384629954135014
Validation loss: 2.931146215727713

Epoch: 5| Step: 2
Training loss: 3.4959418066667793
Validation loss: 2.9392539246879736

Epoch: 5| Step: 3
Training loss: 2.7577903681831493
Validation loss: 2.953843963708659

Epoch: 5| Step: 4
Training loss: 3.3928763654350758
Validation loss: 2.9856440659101047

Epoch: 5| Step: 5
Training loss: 3.256081979117898
Validation loss: 2.935256307093859

Epoch: 5| Step: 6
Training loss: 3.769813202902477
Validation loss: 2.9305553920009486

Epoch: 5| Step: 7
Training loss: 3.6156415169090517
Validation loss: 2.933142654825447

Epoch: 5| Step: 8
Training loss: 3.569323379765871
Validation loss: 2.946605631879633

Epoch: 5| Step: 9
Training loss: 2.915588306715365
Validation loss: 2.9573089767856957

Epoch: 5| Step: 10
Training loss: 3.518164772707487
Validation loss: 2.951062317807986

Epoch: 46| Step: 0
Training loss: 2.9836784468638347
Validation loss: 2.9296983786760387

Epoch: 5| Step: 1
Training loss: 2.9482423492360836
Validation loss: 2.9360647175099928

Epoch: 5| Step: 2
Training loss: 3.3814734083678704
Validation loss: 2.9405477017349595

Epoch: 5| Step: 3
Training loss: 3.596155572260792
Validation loss: 2.9395677074257387

Epoch: 5| Step: 4
Training loss: 3.0547927096851444
Validation loss: 2.925347258964188

Epoch: 5| Step: 5
Training loss: 4.417521460005529
Validation loss: 2.9238422626441785

Epoch: 5| Step: 6
Training loss: 3.653880859704386
Validation loss: 2.9223836504651026

Epoch: 5| Step: 7
Training loss: 2.3166660208209486
Validation loss: 2.924276920633685

Epoch: 5| Step: 8
Training loss: 3.1841748415227955
Validation loss: 2.9346345397430107

Epoch: 5| Step: 9
Training loss: 2.8619939764933773
Validation loss: 2.9337157338828317

Epoch: 5| Step: 10
Training loss: 2.482490928763943
Validation loss: 2.952878998315868

Epoch: 47| Step: 0
Training loss: 3.247945282724189
Validation loss: 3.0106842391045707

Epoch: 5| Step: 1
Training loss: 3.7506709452266906
Validation loss: 2.926332129426595

Epoch: 5| Step: 2
Training loss: 3.272956758217577
Validation loss: 2.9086816710336874

Epoch: 5| Step: 3
Training loss: 3.279718532115575
Validation loss: 2.9103287254747077

Epoch: 5| Step: 4
Training loss: 2.8021864937059084
Validation loss: 2.909580493700342

Epoch: 5| Step: 5
Training loss: 2.659106076693014
Validation loss: 2.9256184526338194

Epoch: 5| Step: 6
Training loss: 2.714336188642963
Validation loss: 2.9412008138417693

Epoch: 5| Step: 7
Training loss: 3.4949324570488476
Validation loss: 2.9560396805549836

Epoch: 5| Step: 8
Training loss: 3.357379977423642
Validation loss: 2.9357875884961793

Epoch: 5| Step: 9
Training loss: 3.6392779170639598
Validation loss: 2.916755553325289

Epoch: 5| Step: 10
Training loss: 3.3639057213253363
Validation loss: 2.905329882917155

Epoch: 48| Step: 0
Training loss: 2.737486197380211
Validation loss: 2.9036899776111413

Epoch: 5| Step: 1
Training loss: 3.5089238706534376
Validation loss: 2.9032646721798634

Epoch: 5| Step: 2
Training loss: 3.7027466657176804
Validation loss: 2.900758049233714

Epoch: 5| Step: 3
Training loss: 3.266952755785231
Validation loss: 2.90034534094025

Epoch: 5| Step: 4
Training loss: 3.371007323676669
Validation loss: 2.921504769946487

Epoch: 5| Step: 5
Training loss: 3.1695337533882153
Validation loss: 2.956591085455294

Epoch: 5| Step: 6
Training loss: 2.8387294508855025
Validation loss: 2.9315366518118773

Epoch: 5| Step: 7
Training loss: 3.697723440933608
Validation loss: 2.9136701376513967

Epoch: 5| Step: 8
Training loss: 2.8382222873769907
Validation loss: 2.8979681884571593

Epoch: 5| Step: 9
Training loss: 2.468046353657583
Validation loss: 2.892620558110104

Epoch: 5| Step: 10
Training loss: 3.4671460816641577
Validation loss: 2.8940869691014757

Epoch: 49| Step: 0
Training loss: 3.291524586246877
Validation loss: 2.893970001269775

Epoch: 5| Step: 1
Training loss: 2.7233226513351565
Validation loss: 2.89218769132099

Epoch: 5| Step: 2
Training loss: 3.644935642715599
Validation loss: 2.8934605077326836

Epoch: 5| Step: 3
Training loss: 3.566930057628092
Validation loss: 2.8953844008546112

Epoch: 5| Step: 4
Training loss: 3.173616278987566
Validation loss: 2.893880066001386

Epoch: 5| Step: 5
Training loss: 3.148041731047649
Validation loss: 2.8912361986598136

Epoch: 5| Step: 6
Training loss: 2.779032905787367
Validation loss: 2.8920933713035124

Epoch: 5| Step: 7
Training loss: 3.587179795705639
Validation loss: 2.8909370517775703

Epoch: 5| Step: 8
Training loss: 2.9921428786653315
Validation loss: 2.8907405866745655

Epoch: 5| Step: 9
Training loss: 2.6612566269934956
Validation loss: 2.8882126328885636

Epoch: 5| Step: 10
Training loss: 3.485397120525659
Validation loss: 2.8871702018569185

Epoch: 50| Step: 0
Training loss: 3.6832540604243977
Validation loss: 2.8859507577786587

Epoch: 5| Step: 1
Training loss: 3.385078217632459
Validation loss: 2.8850073009606234

Epoch: 5| Step: 2
Training loss: 3.05018021723389
Validation loss: 2.8866382292193395

Epoch: 5| Step: 3
Training loss: 3.446210886802832
Validation loss: 2.884974218782841

Epoch: 5| Step: 4
Training loss: 2.831742307458362
Validation loss: 2.8816210135368183

Epoch: 5| Step: 5
Training loss: 2.5862608185989417
Validation loss: 2.881391916305006

Epoch: 5| Step: 6
Training loss: 3.5535181155179796
Validation loss: 2.8825429817127692

Epoch: 5| Step: 7
Training loss: 3.466081022043078
Validation loss: 2.8800291460979643

Epoch: 5| Step: 8
Training loss: 2.980002190505893
Validation loss: 2.878502430231958

Epoch: 5| Step: 9
Training loss: 2.5774022794416087
Validation loss: 2.877925793839621

Epoch: 5| Step: 10
Training loss: 3.2830827226863266
Validation loss: 2.877285696564436

Epoch: 51| Step: 0
Training loss: 2.592029874399887
Validation loss: 2.876592354750085

Epoch: 5| Step: 1
Training loss: 2.901375897990543
Validation loss: 2.877018771273226

Epoch: 5| Step: 2
Training loss: 3.406946793427668
Validation loss: 2.876455219603272

Epoch: 5| Step: 3
Training loss: 3.2094880705381597
Validation loss: 2.8781597274711226

Epoch: 5| Step: 4
Training loss: 3.713592029602754
Validation loss: 2.8740868681022462

Epoch: 5| Step: 5
Training loss: 3.1591728953269334
Validation loss: 2.873139596722244

Epoch: 5| Step: 6
Training loss: 2.7724095978372194
Validation loss: 2.872912261939763

Epoch: 5| Step: 7
Training loss: 3.2309816407674115
Validation loss: 2.8795649600197164

Epoch: 5| Step: 8
Training loss: 3.1824681076525474
Validation loss: 2.8818590274992935

Epoch: 5| Step: 9
Training loss: 3.5300574525474984
Validation loss: 2.88347136855683

Epoch: 5| Step: 10
Training loss: 3.1025329147916745
Validation loss: 2.8709319931268906

Epoch: 52| Step: 0
Training loss: 3.0606020281605177
Validation loss: 2.8697313395764117

Epoch: 5| Step: 1
Training loss: 3.2623556463233965
Validation loss: 2.8670886181586805

Epoch: 5| Step: 2
Training loss: 3.0650207110602885
Validation loss: 2.8675862912598897

Epoch: 5| Step: 3
Training loss: 3.222328936976511
Validation loss: 2.868263554373855

Epoch: 5| Step: 4
Training loss: 2.7874948065328757
Validation loss: 2.865914669071047

Epoch: 5| Step: 5
Training loss: 3.3573812556625175
Validation loss: 2.8652265782225053

Epoch: 5| Step: 6
Training loss: 3.617851048158981
Validation loss: 2.8693616988758515

Epoch: 5| Step: 7
Training loss: 2.8510517655847543
Validation loss: 2.8659229953246617

Epoch: 5| Step: 8
Training loss: 3.5192442850027352
Validation loss: 2.8682574086304253

Epoch: 5| Step: 9
Training loss: 2.9162324491349616
Validation loss: 2.8640169331369743

Epoch: 5| Step: 10
Training loss: 3.1458954120767566
Validation loss: 2.8658450006022065

Epoch: 53| Step: 0
Training loss: 3.5259274229909647
Validation loss: 2.8651334134111215

Epoch: 5| Step: 1
Training loss: 3.135580233915298
Validation loss: 2.8660368303539348

Epoch: 5| Step: 2
Training loss: 2.8734529728185065
Validation loss: 2.8698422047258143

Epoch: 5| Step: 3
Training loss: 3.3119814484855294
Validation loss: 2.870222154785813

Epoch: 5| Step: 4
Training loss: 3.5614866187344862
Validation loss: 2.8613775888303215

Epoch: 5| Step: 5
Training loss: 3.397505007439096
Validation loss: 2.863243319115195

Epoch: 5| Step: 6
Training loss: 2.395692229607694
Validation loss: 2.8595453977342915

Epoch: 5| Step: 7
Training loss: 3.2824398245020503
Validation loss: 2.8589420619570074

Epoch: 5| Step: 8
Training loss: 2.9226389819432734
Validation loss: 2.858084272738208

Epoch: 5| Step: 9
Training loss: 2.8829932841031876
Validation loss: 2.857374485210467

Epoch: 5| Step: 10
Training loss: 3.4135585386767073
Validation loss: 2.858011481095041

Epoch: 54| Step: 0
Training loss: 3.2773489878161364
Validation loss: 2.856866880681499

Epoch: 5| Step: 1
Training loss: 2.2964975475096363
Validation loss: 2.855488442283379

Epoch: 5| Step: 2
Training loss: 2.5996598167885163
Validation loss: 2.8578210897693412

Epoch: 5| Step: 3
Training loss: 2.8522607235930524
Validation loss: 2.8571113346634522

Epoch: 5| Step: 4
Training loss: 2.8075247946754245
Validation loss: 2.8523378391056156

Epoch: 5| Step: 5
Training loss: 3.3525778915152378
Validation loss: 2.855501020350819

Epoch: 5| Step: 6
Training loss: 3.160756887498258
Validation loss: 2.854555911103133

Epoch: 5| Step: 7
Training loss: 3.527961482540596
Validation loss: 2.853027215703979

Epoch: 5| Step: 8
Training loss: 3.872535783418904
Validation loss: 2.852791650716682

Epoch: 5| Step: 9
Training loss: 3.007839450467734
Validation loss: 2.8587921945495247

Epoch: 5| Step: 10
Training loss: 3.7577740514616336
Validation loss: 2.870701174823499

Epoch: 55| Step: 0
Training loss: 3.163025335171228
Validation loss: 2.8974394689079563

Epoch: 5| Step: 1
Training loss: 2.941293093669213
Validation loss: 2.8604689550232196

Epoch: 5| Step: 2
Training loss: 2.7032364838824163
Validation loss: 2.8477836740286793

Epoch: 5| Step: 3
Training loss: 3.5021268649386474
Validation loss: 2.854267310504379

Epoch: 5| Step: 4
Training loss: 2.9472834218109134
Validation loss: 2.85265459361585

Epoch: 5| Step: 5
Training loss: 2.599775645773249
Validation loss: 2.8543246693833604

Epoch: 5| Step: 6
Training loss: 2.9200172434258493
Validation loss: 2.848171495688825

Epoch: 5| Step: 7
Training loss: 3.5335881417242834
Validation loss: 2.8433794413254088

Epoch: 5| Step: 8
Training loss: 3.1918726828861583
Validation loss: 2.8430969911097734

Epoch: 5| Step: 9
Training loss: 3.576556132499656
Validation loss: 2.840147308999031

Epoch: 5| Step: 10
Training loss: 3.5456986009855322
Validation loss: 2.8399657833863774

Epoch: 56| Step: 0
Training loss: 3.4192386033959554
Validation loss: 2.8422446518874285

Epoch: 5| Step: 1
Training loss: 2.932512960445971
Validation loss: 2.843499060008169

Epoch: 5| Step: 2
Training loss: 3.6375934601932394
Validation loss: 2.844147125393146

Epoch: 5| Step: 3
Training loss: 2.3287801140861677
Validation loss: 2.8448033018938337

Epoch: 5| Step: 4
Training loss: 3.2041256713890296
Validation loss: 2.842354259879881

Epoch: 5| Step: 5
Training loss: 3.34339774584755
Validation loss: 2.8434593956403007

Epoch: 5| Step: 6
Training loss: 3.277532742567353
Validation loss: 2.839437576407637

Epoch: 5| Step: 7
Training loss: 3.1007148103138897
Validation loss: 2.838475989742581

Epoch: 5| Step: 8
Training loss: 2.869725239856685
Validation loss: 2.83575320974885

Epoch: 5| Step: 9
Training loss: 3.2247105194994345
Validation loss: 2.836407304688854

Epoch: 5| Step: 10
Training loss: 3.1933898364372832
Validation loss: 2.83688653650842

Epoch: 57| Step: 0
Training loss: 3.3214261689301927
Validation loss: 2.8470526800759317

Epoch: 5| Step: 1
Training loss: 3.515178601216403
Validation loss: 2.8468848196530985

Epoch: 5| Step: 2
Training loss: 2.9170832381902088
Validation loss: 2.8642860367209986

Epoch: 5| Step: 3
Training loss: 2.891249635583415
Validation loss: 2.867877299730927

Epoch: 5| Step: 4
Training loss: 3.08800798322209
Validation loss: 2.8734453910529205

Epoch: 5| Step: 5
Training loss: 2.8133319895712487
Validation loss: 2.8714177881680567

Epoch: 5| Step: 6
Training loss: 3.4623107252478804
Validation loss: 2.855612161015006

Epoch: 5| Step: 7
Training loss: 2.7325112230745763
Validation loss: 2.8300565103094866

Epoch: 5| Step: 8
Training loss: 3.1361510640758525
Validation loss: 2.827191813648004

Epoch: 5| Step: 9
Training loss: 3.5132937691745205
Validation loss: 2.82933567303545

Epoch: 5| Step: 10
Training loss: 3.085040848274535
Validation loss: 2.8301812538155464

Epoch: 58| Step: 0
Training loss: 3.275003209003303
Validation loss: 2.830492473543169

Epoch: 5| Step: 1
Training loss: 2.655729803870908
Validation loss: 2.8341162129005406

Epoch: 5| Step: 2
Training loss: 2.9910000269974963
Validation loss: 2.8332375510841596

Epoch: 5| Step: 3
Training loss: 3.4089950559607654
Validation loss: 2.8299056286311837

Epoch: 5| Step: 4
Training loss: 3.0897631918030384
Validation loss: 2.8295459014032383

Epoch: 5| Step: 5
Training loss: 3.2942566802232203
Validation loss: 2.8283863652776513

Epoch: 5| Step: 6
Training loss: 2.779392093359692
Validation loss: 2.826023425742055

Epoch: 5| Step: 7
Training loss: 3.5074470856441655
Validation loss: 2.8236880313168955

Epoch: 5| Step: 8
Training loss: 3.35753890139269
Validation loss: 2.8239058238927712

Epoch: 5| Step: 9
Training loss: 2.9847632350345426
Validation loss: 2.821667132238547

Epoch: 5| Step: 10
Training loss: 3.1605677012642683
Validation loss: 2.8183197625190797

Epoch: 59| Step: 0
Training loss: 3.456450919024808
Validation loss: 2.8218406300764936

Epoch: 5| Step: 1
Training loss: 3.7029739542227214
Validation loss: 2.821152214233978

Epoch: 5| Step: 2
Training loss: 3.1116625168508256
Validation loss: 2.820274438442981

Epoch: 5| Step: 3
Training loss: 3.1202473931165278
Validation loss: 2.8346836454282585

Epoch: 5| Step: 4
Training loss: 2.799094997335329
Validation loss: 2.8513883039934895

Epoch: 5| Step: 5
Training loss: 3.7898577612604325
Validation loss: 2.8674250857439727

Epoch: 5| Step: 6
Training loss: 2.8221112799761463
Validation loss: 2.8217547065251822

Epoch: 5| Step: 7
Training loss: 2.5260662169426893
Validation loss: 2.8164082998877285

Epoch: 5| Step: 8
Training loss: 3.4175055489707833
Validation loss: 2.815043211293306

Epoch: 5| Step: 9
Training loss: 2.7334982201999742
Validation loss: 2.8184436137998037

Epoch: 5| Step: 10
Training loss: 2.6396795081180997
Validation loss: 2.8178846162213587

Epoch: 60| Step: 0
Training loss: 3.0430585385200635
Validation loss: 2.8227998515384494

Epoch: 5| Step: 1
Training loss: 2.4075120861031345
Validation loss: 2.827856513063632

Epoch: 5| Step: 2
Training loss: 3.2268181577172323
Validation loss: 2.823943723935378

Epoch: 5| Step: 3
Training loss: 3.1072661182778285
Validation loss: 2.8182963593477997

Epoch: 5| Step: 4
Training loss: 3.4807969954291607
Validation loss: 2.8142347666771212

Epoch: 5| Step: 5
Training loss: 3.0317571156832623
Validation loss: 2.8131027569337888

Epoch: 5| Step: 6
Training loss: 3.32463341893513
Validation loss: 2.812874847189273

Epoch: 5| Step: 7
Training loss: 3.1939573515527093
Validation loss: 2.8106159585758363

Epoch: 5| Step: 8
Training loss: 3.38536796339166
Validation loss: 2.8118648345071846

Epoch: 5| Step: 9
Training loss: 3.4248660875858357
Validation loss: 2.8123041428856075

Epoch: 5| Step: 10
Training loss: 2.642468412818617
Validation loss: 2.8219592394538022

Epoch: 61| Step: 0
Training loss: 3.4844127704300947
Validation loss: 2.837360206576704

Epoch: 5| Step: 1
Training loss: 3.508177060764301
Validation loss: 2.843242698728765

Epoch: 5| Step: 2
Training loss: 3.4595514626367154
Validation loss: 2.8219641078934745

Epoch: 5| Step: 3
Training loss: 3.412452859518006
Validation loss: 2.804215714337562

Epoch: 5| Step: 4
Training loss: 2.8242703297232765
Validation loss: 2.8077504762146344

Epoch: 5| Step: 5
Training loss: 2.677408567233394
Validation loss: 2.811150704587255

Epoch: 5| Step: 6
Training loss: 3.437848298894018
Validation loss: 2.818393486514141

Epoch: 5| Step: 7
Training loss: 2.8796168864591625
Validation loss: 2.8270351395073625

Epoch: 5| Step: 8
Training loss: 3.0122193391733676
Validation loss: 2.8171203298785574

Epoch: 5| Step: 9
Training loss: 2.9902448996589768
Validation loss: 2.8083034658999657

Epoch: 5| Step: 10
Training loss: 2.6921544246224816
Validation loss: 2.8054103179837533

Epoch: 62| Step: 0
Training loss: 2.80955775327398
Validation loss: 2.803047519012268

Epoch: 5| Step: 1
Training loss: 3.0541663932713434
Validation loss: 2.801706097402422

Epoch: 5| Step: 2
Training loss: 3.2896516322139835
Validation loss: 2.7990533097412302

Epoch: 5| Step: 3
Training loss: 3.002763905484832
Validation loss: 2.8056026148036524

Epoch: 5| Step: 4
Training loss: 3.1676416569250714
Validation loss: 2.831895651394609

Epoch: 5| Step: 5
Training loss: 2.9019638778152514
Validation loss: 2.884406827355676

Epoch: 5| Step: 6
Training loss: 3.364603772804999
Validation loss: 2.9285793907817914

Epoch: 5| Step: 7
Training loss: 3.377396756845339
Validation loss: 2.8320413849408475

Epoch: 5| Step: 8
Training loss: 2.8088112270742545
Validation loss: 2.7983809368782917

Epoch: 5| Step: 9
Training loss: 3.5597788808494824
Validation loss: 2.7968589336323135

Epoch: 5| Step: 10
Training loss: 2.945413521974408
Validation loss: 2.801159770353801

Epoch: 63| Step: 0
Training loss: 3.3037728561205397
Validation loss: 2.802596170674506

Epoch: 5| Step: 1
Training loss: 2.8810493846237044
Validation loss: 2.807791067766078

Epoch: 5| Step: 2
Training loss: 3.636685183787093
Validation loss: 2.832659240051609

Epoch: 5| Step: 3
Training loss: 3.1262604269641625
Validation loss: 2.8134981287056045

Epoch: 5| Step: 4
Training loss: 2.9813936530797176
Validation loss: 2.8034417913694853

Epoch: 5| Step: 5
Training loss: 2.653069420761431
Validation loss: 2.798627236563575

Epoch: 5| Step: 6
Training loss: 2.9849079714698963
Validation loss: 2.795940419700537

Epoch: 5| Step: 7
Training loss: 2.6873749105041025
Validation loss: 2.7906895716614053

Epoch: 5| Step: 8
Training loss: 2.6136712437590313
Validation loss: 2.791188215734311

Epoch: 5| Step: 9
Training loss: 3.7593680035279475
Validation loss: 2.7915704622131465

Epoch: 5| Step: 10
Training loss: 3.6116098858275416
Validation loss: 2.7910893730598074

Epoch: 64| Step: 0
Training loss: 3.3620254351886554
Validation loss: 2.786374886089069

Epoch: 5| Step: 1
Training loss: 3.147658031517087
Validation loss: 2.7869737699076675

Epoch: 5| Step: 2
Training loss: 3.3073464376565087
Validation loss: 2.788258628668519

Epoch: 5| Step: 3
Training loss: 2.7399487173195887
Validation loss: 2.7949849691277953

Epoch: 5| Step: 4
Training loss: 3.1882640446500354
Validation loss: 2.825214719439306

Epoch: 5| Step: 5
Training loss: 3.248611006660418
Validation loss: 2.834486256894015

Epoch: 5| Step: 6
Training loss: 2.956643727961527
Validation loss: 2.790006161792961

Epoch: 5| Step: 7
Training loss: 3.1885000417875946
Validation loss: 2.7862953528619765

Epoch: 5| Step: 8
Training loss: 2.7342750749040774
Validation loss: 2.7828206541121774

Epoch: 5| Step: 9
Training loss: 3.1382619593670555
Validation loss: 2.7852426279177864

Epoch: 5| Step: 10
Training loss: 3.0507346722396678
Validation loss: 2.7846986710322894

Epoch: 65| Step: 0
Training loss: 2.7972786894419817
Validation loss: 2.7835238587581386

Epoch: 5| Step: 1
Training loss: 3.5439075038025205
Validation loss: 2.7861609024842413

Epoch: 5| Step: 2
Training loss: 3.0684027325767826
Validation loss: 2.7847069565719904

Epoch: 5| Step: 3
Training loss: 3.4160186959498775
Validation loss: 2.784381410219795

Epoch: 5| Step: 4
Training loss: 2.9437985361556533
Validation loss: 2.784456751864532

Epoch: 5| Step: 5
Training loss: 3.2487034779146207
Validation loss: 2.7817123156044614

Epoch: 5| Step: 6
Training loss: 2.905956786756572
Validation loss: 2.7835174439478094

Epoch: 5| Step: 7
Training loss: 3.270218680066228
Validation loss: 2.783552852779607

Epoch: 5| Step: 8
Training loss: 3.0566097367648593
Validation loss: 2.781526880606989

Epoch: 5| Step: 9
Training loss: 3.4182790037760595
Validation loss: 2.7809213700170963

Epoch: 5| Step: 10
Training loss: 2.128733216699462
Validation loss: 2.778976808372982

Epoch: 66| Step: 0
Training loss: 2.7583666020564293
Validation loss: 2.778835373471402

Epoch: 5| Step: 1
Training loss: 3.2937834649313213
Validation loss: 2.7759171974207217

Epoch: 5| Step: 2
Training loss: 3.2267788498137686
Validation loss: 2.7732530166528027

Epoch: 5| Step: 3
Training loss: 2.8471345986216487
Validation loss: 2.77722194377932

Epoch: 5| Step: 4
Training loss: 2.5782084133641523
Validation loss: 2.7792684647442063

Epoch: 5| Step: 5
Training loss: 3.011113720791457
Validation loss: 2.784769379035596

Epoch: 5| Step: 6
Training loss: 3.6858923042117047
Validation loss: 2.7875261311147996

Epoch: 5| Step: 7
Training loss: 3.2183811013383963
Validation loss: 2.7846102885668613

Epoch: 5| Step: 8
Training loss: 3.2325224800242776
Validation loss: 2.783482870950959

Epoch: 5| Step: 9
Training loss: 2.876497459194335
Validation loss: 2.784819652193748

Epoch: 5| Step: 10
Training loss: 3.1889642082591045
Validation loss: 2.7896795061711006

Epoch: 67| Step: 0
Training loss: 2.567684232793421
Validation loss: 2.779797620813043

Epoch: 5| Step: 1
Training loss: 2.6995807852077767
Validation loss: 2.7829232366990038

Epoch: 5| Step: 2
Training loss: 3.0582477865979003
Validation loss: 2.781084733942532

Epoch: 5| Step: 3
Training loss: 3.294935478539642
Validation loss: 2.766225366007064

Epoch: 5| Step: 4
Training loss: 2.8944113187873315
Validation loss: 2.766891342520984

Epoch: 5| Step: 5
Training loss: 2.821197117422674
Validation loss: 2.7628032382961223

Epoch: 5| Step: 6
Training loss: 3.0984736899735807
Validation loss: 2.766982368201641

Epoch: 5| Step: 7
Training loss: 3.6578546898847706
Validation loss: 2.7684964563090007

Epoch: 5| Step: 8
Training loss: 3.4843290180542206
Validation loss: 2.7743023007204153

Epoch: 5| Step: 9
Training loss: 3.5423883637772158
Validation loss: 2.7696799141989197

Epoch: 5| Step: 10
Training loss: 2.6905963714529775
Validation loss: 2.770082680327985

Epoch: 68| Step: 0
Training loss: 2.9362975561091718
Validation loss: 2.7721888313543324

Epoch: 5| Step: 1
Training loss: 3.0630895864529055
Validation loss: 2.766977524395938

Epoch: 5| Step: 2
Training loss: 2.9146493929251935
Validation loss: 2.7620472106486735

Epoch: 5| Step: 3
Training loss: 3.3817372364134117
Validation loss: 2.7620741811890737

Epoch: 5| Step: 4
Training loss: 2.8551397590701653
Validation loss: 2.760473370951578

Epoch: 5| Step: 5
Training loss: 2.667163375450404
Validation loss: 2.7596489706951415

Epoch: 5| Step: 6
Training loss: 3.411298318075507
Validation loss: 2.760056980046315

Epoch: 5| Step: 7
Training loss: 3.975378793386024
Validation loss: 2.7583846045790192

Epoch: 5| Step: 8
Training loss: 3.22464826573118
Validation loss: 2.7538287822504173

Epoch: 5| Step: 9
Training loss: 2.8382224553825575
Validation loss: 2.7563579090350294

Epoch: 5| Step: 10
Training loss: 2.3372504075560347
Validation loss: 2.748950750626044

Epoch: 69| Step: 0
Training loss: 3.0436327776572343
Validation loss: 2.747332437904846

Epoch: 5| Step: 1
Training loss: 2.5623379167608653
Validation loss: 2.7456976067262193

Epoch: 5| Step: 2
Training loss: 3.617929205434328
Validation loss: 2.74313073789711

Epoch: 5| Step: 3
Training loss: 2.829432064262087
Validation loss: 2.739147702972724

Epoch: 5| Step: 4
Training loss: 3.2044960623205228
Validation loss: 2.739685785336856

Epoch: 5| Step: 5
Training loss: 3.20379706054606
Validation loss: 2.7404481344866016

Epoch: 5| Step: 6
Training loss: 3.1414851438932123
Validation loss: 2.7412379063626786

Epoch: 5| Step: 7
Training loss: 2.5087420205605673
Validation loss: 2.7409374743139985

Epoch: 5| Step: 8
Training loss: 2.957108329060639
Validation loss: 2.7395100528594196

Epoch: 5| Step: 9
Training loss: 3.488841388835296
Validation loss: 2.7347580733100085

Epoch: 5| Step: 10
Training loss: 2.9854424449999413
Validation loss: 2.7393904490611956

Epoch: 70| Step: 0
Training loss: 3.304776526440097
Validation loss: 2.739512003071348

Epoch: 5| Step: 1
Training loss: 2.4378168927121204
Validation loss: 2.740561440562952

Epoch: 5| Step: 2
Training loss: 2.71709102132484
Validation loss: 2.737430962380203

Epoch: 5| Step: 3
Training loss: 2.668404271336269
Validation loss: 2.7334387770027315

Epoch: 5| Step: 4
Training loss: 2.932957322412028
Validation loss: 2.73083945564365

Epoch: 5| Step: 5
Training loss: 3.10223181586739
Validation loss: 2.730912309154291

Epoch: 5| Step: 6
Training loss: 3.406235861092717
Validation loss: 2.729491139311069

Epoch: 5| Step: 7
Training loss: 3.0624750875899993
Validation loss: 2.7318742577398

Epoch: 5| Step: 8
Training loss: 3.332317165616254
Validation loss: 2.736347868965406

Epoch: 5| Step: 9
Training loss: 3.0000859884018616
Validation loss: 2.733824137385413

Epoch: 5| Step: 10
Training loss: 3.628133143268814
Validation loss: 2.7453518923281495

Epoch: 71| Step: 0
Training loss: 3.271537138100633
Validation loss: 2.7471737662488676

Epoch: 5| Step: 1
Training loss: 3.1452531258464673
Validation loss: 2.7451472754400443

Epoch: 5| Step: 2
Training loss: 2.3860927328937285
Validation loss: 2.738694459963786

Epoch: 5| Step: 3
Training loss: 3.0914813113794493
Validation loss: 2.7270180057011655

Epoch: 5| Step: 4
Training loss: 3.2632484366803993
Validation loss: 2.7254134591627843

Epoch: 5| Step: 5
Training loss: 3.001400779485992
Validation loss: 2.7296745643675733

Epoch: 5| Step: 6
Training loss: 3.1606902059233555
Validation loss: 2.7289157402326576

Epoch: 5| Step: 7
Training loss: 3.4493532597374577
Validation loss: 2.730398840392679

Epoch: 5| Step: 8
Training loss: 2.8983593542047124
Validation loss: 2.729433961685643

Epoch: 5| Step: 9
Training loss: 2.3787219347277913
Validation loss: 2.7308266056771284

Epoch: 5| Step: 10
Training loss: 3.4479073853766384
Validation loss: 2.730202781988762

Epoch: 72| Step: 0
Training loss: 3.3983311428220784
Validation loss: 2.733037421638306

Epoch: 5| Step: 1
Training loss: 3.470500332602455
Validation loss: 2.730585780599048

Epoch: 5| Step: 2
Training loss: 3.303850938320923
Validation loss: 2.7323064533633703

Epoch: 5| Step: 3
Training loss: 2.7506052564914825
Validation loss: 2.7286835648142143

Epoch: 5| Step: 4
Training loss: 3.1630386014519174
Validation loss: 2.7272493011211805

Epoch: 5| Step: 5
Training loss: 3.404941692553266
Validation loss: 2.726807489003768

Epoch: 5| Step: 6
Training loss: 2.8727929309720817
Validation loss: 2.725054273603935

Epoch: 5| Step: 7
Training loss: 2.7509504756428638
Validation loss: 2.725615962634958

Epoch: 5| Step: 8
Training loss: 2.176623416001645
Validation loss: 2.723548052798549

Epoch: 5| Step: 9
Training loss: 3.079665984335516
Validation loss: 2.722621816579611

Epoch: 5| Step: 10
Training loss: 3.1378808630068806
Validation loss: 2.7238217662732005

Epoch: 73| Step: 0
Training loss: 3.325102960813726
Validation loss: 2.7211982369540277

Epoch: 5| Step: 1
Training loss: 3.0965410993704463
Validation loss: 2.720950453394445

Epoch: 5| Step: 2
Training loss: 3.3745844549863393
Validation loss: 2.71800502914213

Epoch: 5| Step: 3
Training loss: 3.2038519801929564
Validation loss: 2.7149071923928183

Epoch: 5| Step: 4
Training loss: 2.680175736771839
Validation loss: 2.7159003492100524

Epoch: 5| Step: 5
Training loss: 2.8761831419865387
Validation loss: 2.7179861140085504

Epoch: 5| Step: 6
Training loss: 3.5228609344988855
Validation loss: 2.7363565904049993

Epoch: 5| Step: 7
Training loss: 2.666479898905959
Validation loss: 2.729564812112095

Epoch: 5| Step: 8
Training loss: 3.166351620579124
Validation loss: 2.7185272268855387

Epoch: 5| Step: 9
Training loss: 2.516078742197564
Validation loss: 2.7143897978346865

Epoch: 5| Step: 10
Training loss: 2.9385739250445377
Validation loss: 2.7152744284764783

Epoch: 74| Step: 0
Training loss: 3.3975007969600592
Validation loss: 2.7169171620270403

Epoch: 5| Step: 1
Training loss: 2.78750626772873
Validation loss: 2.715507927859812

Epoch: 5| Step: 2
Training loss: 3.5117043568079622
Validation loss: 2.7137412690894878

Epoch: 5| Step: 3
Training loss: 2.516078363165552
Validation loss: 2.724469966543831

Epoch: 5| Step: 4
Training loss: 3.319029652223135
Validation loss: 2.751762015821378

Epoch: 5| Step: 5
Training loss: 2.830746273678088
Validation loss: 2.7393685184177747

Epoch: 5| Step: 6
Training loss: 3.4085444850539646
Validation loss: 2.733866228859457

Epoch: 5| Step: 7
Training loss: 3.18104737841266
Validation loss: 2.710849424939046

Epoch: 5| Step: 8
Training loss: 3.2406437519233555
Validation loss: 2.7036395010373435

Epoch: 5| Step: 9
Training loss: 2.334605778287771
Validation loss: 2.705041812143453

Epoch: 5| Step: 10
Training loss: 2.655213007742617
Validation loss: 2.702969882072548

Epoch: 75| Step: 0
Training loss: 3.218056909696883
Validation loss: 2.7079079330975016

Epoch: 5| Step: 1
Training loss: 2.707271945045405
Validation loss: 2.7075780915106824

Epoch: 5| Step: 2
Training loss: 3.6590517183054256
Validation loss: 2.7067719084800994

Epoch: 5| Step: 3
Training loss: 2.9404770395348674
Validation loss: 2.707495066656702

Epoch: 5| Step: 4
Training loss: 3.0528474617169654
Validation loss: 2.7054775669455653

Epoch: 5| Step: 5
Training loss: 2.928528416547027
Validation loss: 2.705798896319704

Epoch: 5| Step: 6
Training loss: 3.255118813873257
Validation loss: 2.7052634668846602

Epoch: 5| Step: 7
Training loss: 3.334893449628269
Validation loss: 2.7087018594468764

Epoch: 5| Step: 8
Training loss: 2.1975223374343544
Validation loss: 2.7076894365452655

Epoch: 5| Step: 9
Training loss: 2.957077529928049
Validation loss: 2.7071150798247703

Epoch: 5| Step: 10
Training loss: 3.0840023105479095
Validation loss: 2.7062575274162923

Epoch: 76| Step: 0
Training loss: 3.199483001191685
Validation loss: 2.703747776872886

Epoch: 5| Step: 1
Training loss: 3.062393809443229
Validation loss: 2.699048125782398

Epoch: 5| Step: 2
Training loss: 3.2318540322135014
Validation loss: 2.6990031014992684

Epoch: 5| Step: 3
Training loss: 2.90577579033992
Validation loss: 2.704892469021787

Epoch: 5| Step: 4
Training loss: 2.786409713938908
Validation loss: 2.6992331067055426

Epoch: 5| Step: 5
Training loss: 2.849788249665601
Validation loss: 2.7003218995965423

Epoch: 5| Step: 6
Training loss: 3.170571045088428
Validation loss: 2.694701713991484

Epoch: 5| Step: 7
Training loss: 3.1977055549315416
Validation loss: 2.695448091272945

Epoch: 5| Step: 8
Training loss: 3.012822721931076
Validation loss: 2.6943815649885363

Epoch: 5| Step: 9
Training loss: 2.955242225543162
Validation loss: 2.6964539990147984

Epoch: 5| Step: 10
Training loss: 2.9536332596267005
Validation loss: 2.69457989295753

Epoch: 77| Step: 0
Training loss: 2.917700084895703
Validation loss: 2.6911816496943977

Epoch: 5| Step: 1
Training loss: 2.8043710854224373
Validation loss: 2.6916436905449994

Epoch: 5| Step: 2
Training loss: 2.6723837563308668
Validation loss: 2.690735682741745

Epoch: 5| Step: 3
Training loss: 2.884374841295364
Validation loss: 2.692036266115592

Epoch: 5| Step: 4
Training loss: 3.2522443211403487
Validation loss: 2.6893467645104097

Epoch: 5| Step: 5
Training loss: 3.224669559316841
Validation loss: 2.6919851753991275

Epoch: 5| Step: 6
Training loss: 3.2192413547616336
Validation loss: 2.692534908934025

Epoch: 5| Step: 7
Training loss: 2.925715243278713
Validation loss: 2.6928553803004913

Epoch: 5| Step: 8
Training loss: 3.329642223120132
Validation loss: 2.700854134106795

Epoch: 5| Step: 9
Training loss: 2.9390042288569047
Validation loss: 2.714657834995924

Epoch: 5| Step: 10
Training loss: 3.1121819636240793
Validation loss: 2.70227614933263

Epoch: 78| Step: 0
Training loss: 3.0846068012053
Validation loss: 2.701785628586191

Epoch: 5| Step: 1
Training loss: 3.0180172301369996
Validation loss: 2.689383552381739

Epoch: 5| Step: 2
Training loss: 2.608333174082921
Validation loss: 2.6862229033653167

Epoch: 5| Step: 3
Training loss: 3.206264985107145
Validation loss: 2.6856276325452324

Epoch: 5| Step: 4
Training loss: 3.1115840559953405
Validation loss: 2.6869800920395033

Epoch: 5| Step: 5
Training loss: 2.8888494863838905
Validation loss: 2.6894577728969353

Epoch: 5| Step: 6
Training loss: 2.56990451531462
Validation loss: 2.685193860252127

Epoch: 5| Step: 7
Training loss: 3.147310798418361
Validation loss: 2.68444500435697

Epoch: 5| Step: 8
Training loss: 3.1988744305897137
Validation loss: 2.684958349988641

Epoch: 5| Step: 9
Training loss: 2.9786315295071693
Validation loss: 2.691864386647891

Epoch: 5| Step: 10
Training loss: 3.464883935258792
Validation loss: 2.7098810214773694

Epoch: 79| Step: 0
Training loss: 3.1731355915114468
Validation loss: 2.734758515776307

Epoch: 5| Step: 1
Training loss: 2.4756202228888164
Validation loss: 2.7137623516246863

Epoch: 5| Step: 2
Training loss: 2.919745990469847
Validation loss: 2.695122024965558

Epoch: 5| Step: 3
Training loss: 3.1869234049761173
Validation loss: 2.685739158331987

Epoch: 5| Step: 4
Training loss: 2.9725404333343586
Validation loss: 2.687674123508609

Epoch: 5| Step: 5
Training loss: 3.232987700665787
Validation loss: 2.6855081902455704

Epoch: 5| Step: 6
Training loss: 3.4762895455523553
Validation loss: 2.6814260619891686

Epoch: 5| Step: 7
Training loss: 2.8607102908587403
Validation loss: 2.680040301652173

Epoch: 5| Step: 8
Training loss: 2.7229327768804112
Validation loss: 2.682143695181391

Epoch: 5| Step: 9
Training loss: 3.0021943967677855
Validation loss: 2.6827978201181724

Epoch: 5| Step: 10
Training loss: 3.1293428380740846
Validation loss: 2.6830573138028604

Epoch: 80| Step: 0
Training loss: 3.4911591724746254
Validation loss: 2.6783721880588813

Epoch: 5| Step: 1
Training loss: 2.4848444273239583
Validation loss: 2.679108545816741

Epoch: 5| Step: 2
Training loss: 2.8533214422079185
Validation loss: 2.676721029247406

Epoch: 5| Step: 3
Training loss: 3.188359163468482
Validation loss: 2.6807503999686637

Epoch: 5| Step: 4
Training loss: 2.5639090966938785
Validation loss: 2.6801680893866915

Epoch: 5| Step: 5
Training loss: 2.8989699869381984
Validation loss: 2.681248019879097

Epoch: 5| Step: 6
Training loss: 3.362794918471284
Validation loss: 2.678492764999136

Epoch: 5| Step: 7
Training loss: 2.8356282719775487
Validation loss: 2.674053584636012

Epoch: 5| Step: 8
Training loss: 3.2799943247024936
Validation loss: 2.6736896011329865

Epoch: 5| Step: 9
Training loss: 3.0370975997058705
Validation loss: 2.6701427400499704

Epoch: 5| Step: 10
Training loss: 3.1507317677004925
Validation loss: 2.6747625320876303

Epoch: 81| Step: 0
Training loss: 3.2723063333089204
Validation loss: 2.6733921102142926

Epoch: 5| Step: 1
Training loss: 3.0133272420208335
Validation loss: 2.6712856538677405

Epoch: 5| Step: 2
Training loss: 3.066406094496413
Validation loss: 2.676185400501211

Epoch: 5| Step: 3
Training loss: 2.3917949531344354
Validation loss: 2.671187486931652

Epoch: 5| Step: 4
Training loss: 3.2361616277139924
Validation loss: 2.673485883970873

Epoch: 5| Step: 5
Training loss: 2.9477071159659185
Validation loss: 2.6734042293556604

Epoch: 5| Step: 6
Training loss: 3.4924351819849444
Validation loss: 2.668400155526281

Epoch: 5| Step: 7
Training loss: 2.444065543873868
Validation loss: 2.675196535329314

Epoch: 5| Step: 8
Training loss: 3.048697997303073
Validation loss: 2.6789242652984444

Epoch: 5| Step: 9
Training loss: 3.1372419517146954
Validation loss: 2.6861623615019408

Epoch: 5| Step: 10
Training loss: 2.812342151874737
Validation loss: 2.686874985663554

Epoch: 82| Step: 0
Training loss: 3.2225853744573634
Validation loss: 2.6897752102064425

Epoch: 5| Step: 1
Training loss: 3.2671083430694496
Validation loss: 2.6743533773901933

Epoch: 5| Step: 2
Training loss: 3.412924849784044
Validation loss: 2.6728655639988115

Epoch: 5| Step: 3
Training loss: 3.3947616165359045
Validation loss: 2.6722989626605798

Epoch: 5| Step: 4
Training loss: 2.9217305683199095
Validation loss: 2.6654803240226994

Epoch: 5| Step: 5
Training loss: 2.901173742131148
Validation loss: 2.6686468162223287

Epoch: 5| Step: 6
Training loss: 2.713087037723168
Validation loss: 2.665837365324519

Epoch: 5| Step: 7
Training loss: 2.6038205539852313
Validation loss: 2.6636091022160926

Epoch: 5| Step: 8
Training loss: 2.6742259608045313
Validation loss: 2.665731793650105

Epoch: 5| Step: 9
Training loss: 2.961740510700113
Validation loss: 2.66876879701284

Epoch: 5| Step: 10
Training loss: 2.881286217054356
Validation loss: 2.6772301746417217

Epoch: 83| Step: 0
Training loss: 3.3479043697249242
Validation loss: 2.6938077112413183

Epoch: 5| Step: 1
Training loss: 3.060239151977728
Validation loss: 2.6664992116128707

Epoch: 5| Step: 2
Training loss: 2.6983508689770823
Validation loss: 2.672724540482983

Epoch: 5| Step: 3
Training loss: 2.8504656628767266
Validation loss: 2.6705565659541293

Epoch: 5| Step: 4
Training loss: 3.9083121997991195
Validation loss: 2.6651109289923816

Epoch: 5| Step: 5
Training loss: 3.036377178872132
Validation loss: 2.6609473795848877

Epoch: 5| Step: 6
Training loss: 2.6772316224901846
Validation loss: 2.661823718089396

Epoch: 5| Step: 7
Training loss: 2.766874645259844
Validation loss: 2.660192367980469

Epoch: 5| Step: 8
Training loss: 3.123617400445784
Validation loss: 2.670671525999385

Epoch: 5| Step: 9
Training loss: 2.641572951410445
Validation loss: 2.6748190190195706

Epoch: 5| Step: 10
Training loss: 2.7458290200399773
Validation loss: 2.6738403936533235

Epoch: 84| Step: 0
Training loss: 2.8971849393005216
Validation loss: 2.6722060269968417

Epoch: 5| Step: 1
Training loss: 3.1868206122920064
Validation loss: 2.665740517238205

Epoch: 5| Step: 2
Training loss: 3.420461423654418
Validation loss: 2.6656112011364055

Epoch: 5| Step: 3
Training loss: 3.1563524286249347
Validation loss: 2.6641209170462004

Epoch: 5| Step: 4
Training loss: 2.7994006809794945
Validation loss: 2.6608636184917973

Epoch: 5| Step: 5
Training loss: 2.723658110568465
Validation loss: 2.6588644423411836

Epoch: 5| Step: 6
Training loss: 2.4996256548039453
Validation loss: 2.6639650128716728

Epoch: 5| Step: 7
Training loss: 3.1493265491717226
Validation loss: 2.670680794045697

Epoch: 5| Step: 8
Training loss: 2.9622809349219974
Validation loss: 2.6800699933566143

Epoch: 5| Step: 9
Training loss: 3.0702457178050415
Validation loss: 2.686891856620202

Epoch: 5| Step: 10
Training loss: 3.165081547655306
Validation loss: 2.707466220167199

Epoch: 85| Step: 0
Training loss: 2.991861430197743
Validation loss: 2.7288915134897715

Epoch: 5| Step: 1
Training loss: 2.9219784641816924
Validation loss: 2.7123787256414715

Epoch: 5| Step: 2
Training loss: 3.108606904973422
Validation loss: 2.7127589504455485

Epoch: 5| Step: 3
Training loss: 3.344174224467276
Validation loss: 2.7087503577563465

Epoch: 5| Step: 4
Training loss: 2.4810936328420174
Validation loss: 2.6672334517322662

Epoch: 5| Step: 5
Training loss: 3.463897472643896
Validation loss: 2.661207571418027

Epoch: 5| Step: 6
Training loss: 2.7905109822218286
Validation loss: 2.6530848620679484

Epoch: 5| Step: 7
Training loss: 3.1865108675625504
Validation loss: 2.6553105255837424

Epoch: 5| Step: 8
Training loss: 2.626133446991735
Validation loss: 2.6578666250579857

Epoch: 5| Step: 9
Training loss: 2.853562414058563
Validation loss: 2.656972058556006

Epoch: 5| Step: 10
Training loss: 3.1396865581375493
Validation loss: 2.658014964583059

Epoch: 86| Step: 0
Training loss: 3.1441627428677568
Validation loss: 2.657291915934127

Epoch: 5| Step: 1
Training loss: 3.135304361319703
Validation loss: 2.6604851389349284

Epoch: 5| Step: 2
Training loss: 3.027782383797629
Validation loss: 2.658259145032131

Epoch: 5| Step: 3
Training loss: 3.243000121712719
Validation loss: 2.65867563639231

Epoch: 5| Step: 4
Training loss: 2.957238617130424
Validation loss: 2.661695522555411

Epoch: 5| Step: 5
Training loss: 2.981747414220714
Validation loss: 2.664924687757026

Epoch: 5| Step: 6
Training loss: 2.5897662351121298
Validation loss: 2.6643713127171273

Epoch: 5| Step: 7
Training loss: 2.7503204159037034
Validation loss: 2.6716703979317926

Epoch: 5| Step: 8
Training loss: 3.304378125294058
Validation loss: 2.6989977301078047

Epoch: 5| Step: 9
Training loss: 2.5670473642114553
Validation loss: 2.6712359177607308

Epoch: 5| Step: 10
Training loss: 3.2323520987087493
Validation loss: 2.656467218945506

Epoch: 87| Step: 0
Training loss: 3.079691996346128
Validation loss: 2.655978702055275

Epoch: 5| Step: 1
Training loss: 2.287985903303029
Validation loss: 2.6539258794144853

Epoch: 5| Step: 2
Training loss: 3.236251655186259
Validation loss: 2.662828028968028

Epoch: 5| Step: 3
Training loss: 3.306847842416259
Validation loss: 2.679942074672988

Epoch: 5| Step: 4
Training loss: 3.4549878649353585
Validation loss: 2.687683814617241

Epoch: 5| Step: 5
Training loss: 2.9869188581440773
Validation loss: 2.661827720789649

Epoch: 5| Step: 6
Training loss: 2.6619619551189095
Validation loss: 2.653428006455244

Epoch: 5| Step: 7
Training loss: 2.7952789355800887
Validation loss: 2.653453917337517

Epoch: 5| Step: 8
Training loss: 3.0286939403401147
Validation loss: 2.6475933119914417

Epoch: 5| Step: 9
Training loss: 3.1766360775841447
Validation loss: 2.6506055734363847

Epoch: 5| Step: 10
Training loss: 2.6587908093073946
Validation loss: 2.6439038607585954

Epoch: 88| Step: 0
Training loss: 2.448535781377672
Validation loss: 2.646180180946936

Epoch: 5| Step: 1
Training loss: 3.297102644595558
Validation loss: 2.6413590033083474

Epoch: 5| Step: 2
Training loss: 3.4934654543063868
Validation loss: 2.6455168246893375

Epoch: 5| Step: 3
Training loss: 2.825190417868643
Validation loss: 2.6494977549790466

Epoch: 5| Step: 4
Training loss: 3.2465587884211806
Validation loss: 2.652368095518553

Epoch: 5| Step: 5
Training loss: 2.8969666895506774
Validation loss: 2.6587405434448717

Epoch: 5| Step: 6
Training loss: 2.677830266591971
Validation loss: 2.6618108152150985

Epoch: 5| Step: 7
Training loss: 2.8956377434486136
Validation loss: 2.6622023915713355

Epoch: 5| Step: 8
Training loss: 3.336105163791962
Validation loss: 2.659762582517596

Epoch: 5| Step: 9
Training loss: 2.9944048203217797
Validation loss: 2.6531983480819563

Epoch: 5| Step: 10
Training loss: 2.4108224006912167
Validation loss: 2.6545416630440344

Epoch: 89| Step: 0
Training loss: 2.3695241141282573
Validation loss: 2.6456406665042005

Epoch: 5| Step: 1
Training loss: 2.9800413932741674
Validation loss: 2.6455356639420957

Epoch: 5| Step: 2
Training loss: 3.596099350962399
Validation loss: 2.6426137556432714

Epoch: 5| Step: 3
Training loss: 2.9573758326412833
Validation loss: 2.643370432493332

Epoch: 5| Step: 4
Training loss: 3.2969532455632695
Validation loss: 2.637282721617021

Epoch: 5| Step: 5
Training loss: 3.096380637365606
Validation loss: 2.64137736946116

Epoch: 5| Step: 6
Training loss: 2.9927775545719904
Validation loss: 2.6386884440135807

Epoch: 5| Step: 7
Training loss: 2.895281530997943
Validation loss: 2.6353594891997165

Epoch: 5| Step: 8
Training loss: 2.729931081244269
Validation loss: 2.6420659599983596

Epoch: 5| Step: 9
Training loss: 2.5694300287432275
Validation loss: 2.640447478696314

Epoch: 5| Step: 10
Training loss: 3.1193124512393804
Validation loss: 2.6437462470310824

Epoch: 90| Step: 0
Training loss: 2.460627751308896
Validation loss: 2.635536282248755

Epoch: 5| Step: 1
Training loss: 2.9535675524569047
Validation loss: 2.6293065742193376

Epoch: 5| Step: 2
Training loss: 2.466969874364693
Validation loss: 2.6346423734954247

Epoch: 5| Step: 3
Training loss: 2.6822012185460693
Validation loss: 2.6315877173768234

Epoch: 5| Step: 4
Training loss: 2.816351901943984
Validation loss: 2.635506377727338

Epoch: 5| Step: 5
Training loss: 3.334277702706703
Validation loss: 2.6322552413254723

Epoch: 5| Step: 6
Training loss: 2.9039870445130616
Validation loss: 2.6274113086068676

Epoch: 5| Step: 7
Training loss: 3.4416847419418066
Validation loss: 2.628156035327104

Epoch: 5| Step: 8
Training loss: 2.9729067963772913
Validation loss: 2.6371650005219176

Epoch: 5| Step: 9
Training loss: 3.111536702685772
Validation loss: 2.651821698075925

Epoch: 5| Step: 10
Training loss: 3.478253928208681
Validation loss: 2.6548678677914808

Epoch: 91| Step: 0
Training loss: 2.9358140693124204
Validation loss: 2.6869642272616217

Epoch: 5| Step: 1
Training loss: 3.1012677645991324
Validation loss: 2.715269099658959

Epoch: 5| Step: 2
Training loss: 2.2861574245791774
Validation loss: 2.810405997182295

Epoch: 5| Step: 3
Training loss: 3.181812373069316
Validation loss: 2.8526337628978995

Epoch: 5| Step: 4
Training loss: 3.2348513045179232
Validation loss: 2.845648677918023

Epoch: 5| Step: 5
Training loss: 3.6568346126753464
Validation loss: 2.7351768000169274

Epoch: 5| Step: 6
Training loss: 2.6831965923021546
Validation loss: 2.6249047001788193

Epoch: 5| Step: 7
Training loss: 2.885823318709349
Validation loss: 2.6617547090881435

Epoch: 5| Step: 8
Training loss: 3.5108953917371553
Validation loss: 2.7631434644324915

Epoch: 5| Step: 9
Training loss: 3.425985297604094
Validation loss: 2.777321349214415

Epoch: 5| Step: 10
Training loss: 2.7409882708148587
Validation loss: 2.750282189218371

Epoch: 92| Step: 0
Training loss: 2.734124831608483
Validation loss: 2.7183976143640374

Epoch: 5| Step: 1
Training loss: 2.952619559817121
Validation loss: 2.7361504172784037

Epoch: 5| Step: 2
Training loss: 3.108666880884176
Validation loss: 2.7259456821711443

Epoch: 5| Step: 3
Training loss: 3.522880696286571
Validation loss: 2.695671094070051

Epoch: 5| Step: 4
Training loss: 2.6240583274801774
Validation loss: 2.680234150787518

Epoch: 5| Step: 5
Training loss: 3.59071527140183
Validation loss: 2.6809047628641407

Epoch: 5| Step: 6
Training loss: 2.8051471811667588
Validation loss: 2.646396884744212

Epoch: 5| Step: 7
Training loss: 2.970240008228617
Validation loss: 2.648017571472552

Epoch: 5| Step: 8
Training loss: 3.008745955245402
Validation loss: 2.660496744495139

Epoch: 5| Step: 9
Training loss: 2.837942040247424
Validation loss: 2.744969127206543

Epoch: 5| Step: 10
Training loss: 3.076897390881944
Validation loss: 2.802036470886765

Epoch: 93| Step: 0
Training loss: 2.741446196514272
Validation loss: 2.742986781764449

Epoch: 5| Step: 1
Training loss: 3.561391289834848
Validation loss: 2.7265450593133345

Epoch: 5| Step: 2
Training loss: 3.0738272314619364
Validation loss: 2.6630916527936397

Epoch: 5| Step: 3
Training loss: 2.319051997422233
Validation loss: 2.6409345390675822

Epoch: 5| Step: 4
Training loss: 2.625884679035851
Validation loss: 2.679843424129247

Epoch: 5| Step: 5
Training loss: 3.0027694634592903
Validation loss: 2.7342893713040906

Epoch: 5| Step: 6
Training loss: 3.316733048763535
Validation loss: 2.740616475898585

Epoch: 5| Step: 7
Training loss: 3.4805132759234514
Validation loss: 2.7138924490747436

Epoch: 5| Step: 8
Training loss: 2.8406924064536616
Validation loss: 2.6879726489370492

Epoch: 5| Step: 9
Training loss: 3.4863787308126875
Validation loss: 2.68271100001812

Epoch: 5| Step: 10
Training loss: 2.524954230771852
Validation loss: 2.670642149295773

Epoch: 94| Step: 0
Training loss: 3.2044314813667674
Validation loss: 2.6608640269995987

Epoch: 5| Step: 1
Training loss: 2.8900381781356352
Validation loss: 2.6620231234477316

Epoch: 5| Step: 2
Training loss: 3.2529389224670022
Validation loss: 2.6593559371554023

Epoch: 5| Step: 3
Training loss: 2.89843700645422
Validation loss: 2.6618521384791984

Epoch: 5| Step: 4
Training loss: 3.0987299132378916
Validation loss: 2.6669924653006283

Epoch: 5| Step: 5
Training loss: 3.028470367483168
Validation loss: 2.668915787121058

Epoch: 5| Step: 6
Training loss: 2.9829291391322847
Validation loss: 2.6732639324030063

Epoch: 5| Step: 7
Training loss: 3.146076841382347
Validation loss: 2.683915662458674

Epoch: 5| Step: 8
Training loss: 2.9836249082925606
Validation loss: 2.778607250230647

Epoch: 5| Step: 9
Training loss: 2.9442627348901778
Validation loss: 2.8474673423697503

Epoch: 5| Step: 10
Training loss: 2.7058320354822367
Validation loss: 2.805375325762183

Epoch: 95| Step: 0
Training loss: 3.2284695436820248
Validation loss: 2.716083894518775

Epoch: 5| Step: 1
Training loss: 3.171221134834805
Validation loss: 2.632027378828873

Epoch: 5| Step: 2
Training loss: 2.728279076209376
Validation loss: 2.6217996627753446

Epoch: 5| Step: 3
Training loss: 2.7916031066339393
Validation loss: 2.6459245960740807

Epoch: 5| Step: 4
Training loss: 2.606512909945611
Validation loss: 2.6611316294882443

Epoch: 5| Step: 5
Training loss: 3.0667424303177357
Validation loss: 2.6778539103434253

Epoch: 5| Step: 6
Training loss: 3.3975845845116397
Validation loss: 2.6723078202229598

Epoch: 5| Step: 7
Training loss: 2.824913435428345
Validation loss: 2.6742799992308517

Epoch: 5| Step: 8
Training loss: 3.246219196489244
Validation loss: 2.671612399291941

Epoch: 5| Step: 9
Training loss: 3.2062753955214562
Validation loss: 2.6685391518707324

Epoch: 5| Step: 10
Training loss: 2.7026295290526545
Validation loss: 2.6584880687257013

Epoch: 96| Step: 0
Training loss: 3.239634784318535
Validation loss: 2.6381667072043378

Epoch: 5| Step: 1
Training loss: 2.0749866623047666
Validation loss: 2.6356497360010636

Epoch: 5| Step: 2
Training loss: 2.793760558242816
Validation loss: 2.648677473237072

Epoch: 5| Step: 3
Training loss: 3.1183593383009205
Validation loss: 2.6541665860081722

Epoch: 5| Step: 4
Training loss: 3.1835503136415646
Validation loss: 2.6441462422485738

Epoch: 5| Step: 5
Training loss: 3.385819928531336
Validation loss: 2.624637381435377

Epoch: 5| Step: 6
Training loss: 2.6995197575470193
Validation loss: 2.620437338636345

Epoch: 5| Step: 7
Training loss: 2.8710361189475253
Validation loss: 2.6085843578332524

Epoch: 5| Step: 8
Training loss: 3.146606518714751
Validation loss: 2.6067845360973743

Epoch: 5| Step: 9
Training loss: 3.1029798214422586
Validation loss: 2.604501520757772

Epoch: 5| Step: 10
Training loss: 2.878924966282869
Validation loss: 2.6054414699534747

Epoch: 97| Step: 0
Training loss: 2.832401309335247
Validation loss: 2.606080567636466

Epoch: 5| Step: 1
Training loss: 3.5353591102016693
Validation loss: 2.6124593695960616

Epoch: 5| Step: 2
Training loss: 2.597857979420313
Validation loss: 2.6152853996125085

Epoch: 5| Step: 3
Training loss: 2.996603950916347
Validation loss: 2.618233176650815

Epoch: 5| Step: 4
Training loss: 3.042552679604168
Validation loss: 2.6121970416172093

Epoch: 5| Step: 5
Training loss: 2.768506289535083
Validation loss: 2.609314486817746

Epoch: 5| Step: 6
Training loss: 3.5209416179069177
Validation loss: 2.605465577756065

Epoch: 5| Step: 7
Training loss: 2.98036027663436
Validation loss: 2.6036134003332347

Epoch: 5| Step: 8
Training loss: 2.849752776817149
Validation loss: 2.6027903779423234

Epoch: 5| Step: 9
Training loss: 2.6913408733782327
Validation loss: 2.60216785303067

Epoch: 5| Step: 10
Training loss: 2.6570763592815196
Validation loss: 2.6021515598382403

Epoch: 98| Step: 0
Training loss: 2.9049738881813765
Validation loss: 2.6011945124321043

Epoch: 5| Step: 1
Training loss: 3.4408974244300308
Validation loss: 2.6039051034479703

Epoch: 5| Step: 2
Training loss: 3.2442332236746987
Validation loss: 2.601847592997573

Epoch: 5| Step: 3
Training loss: 2.7968197609332077
Validation loss: 2.6045709256010916

Epoch: 5| Step: 4
Training loss: 2.932774740554243
Validation loss: 2.609752864200384

Epoch: 5| Step: 5
Training loss: 3.1767963884358568
Validation loss: 2.636098505413418

Epoch: 5| Step: 6
Training loss: 2.413457109410404
Validation loss: 2.6437712225053343

Epoch: 5| Step: 7
Training loss: 2.6336572576632453
Validation loss: 2.6857486521521947

Epoch: 5| Step: 8
Training loss: 2.884416666277552
Validation loss: 2.6973853469224496

Epoch: 5| Step: 9
Training loss: 3.6627969406626724
Validation loss: 2.6706396611452643

Epoch: 5| Step: 10
Training loss: 2.090806400657243
Validation loss: 2.6386383460867373

Epoch: 99| Step: 0
Training loss: 2.7605181597399255
Validation loss: 2.5994909379754274

Epoch: 5| Step: 1
Training loss: 2.9428263322696115
Validation loss: 2.5949463381468605

Epoch: 5| Step: 2
Training loss: 3.1082625196093243
Validation loss: 2.5959535952274475

Epoch: 5| Step: 3
Training loss: 2.393674414016531
Validation loss: 2.592384919615277

Epoch: 5| Step: 4
Training loss: 3.0985661790129084
Validation loss: 2.6023586032780077

Epoch: 5| Step: 5
Training loss: 3.33140910557727
Validation loss: 2.6007693083364365

Epoch: 5| Step: 6
Training loss: 3.218354728650002
Validation loss: 2.5976392692524715

Epoch: 5| Step: 7
Training loss: 3.3836282711166143
Validation loss: 2.5958141757251116

Epoch: 5| Step: 8
Training loss: 2.438275825081327
Validation loss: 2.594443174118295

Epoch: 5| Step: 9
Training loss: 2.691446378765835
Validation loss: 2.5890013240697907

Epoch: 5| Step: 10
Training loss: 3.065952612493889
Validation loss: 2.5976223752427363

Epoch: 100| Step: 0
Training loss: 2.700956323591828
Validation loss: 2.604039304182446

Epoch: 5| Step: 1
Training loss: 2.6440321030045664
Validation loss: 2.615034579142899

Epoch: 5| Step: 2
Training loss: 3.057348316887352
Validation loss: 2.6175823777608875

Epoch: 5| Step: 3
Training loss: 3.3335481256581705
Validation loss: 2.6050803368871356

Epoch: 5| Step: 4
Training loss: 3.0934147508638112
Validation loss: 2.603978377559664

Epoch: 5| Step: 5
Training loss: 3.0850427030454957
Validation loss: 2.5949751965818493

Epoch: 5| Step: 6
Training loss: 2.9576462140221125
Validation loss: 2.596172457276751

Epoch: 5| Step: 7
Training loss: 2.4775889101829076
Validation loss: 2.593398805641126

Epoch: 5| Step: 8
Training loss: 2.9920928382341856
Validation loss: 2.5999056234182594

Epoch: 5| Step: 9
Training loss: 3.063865668526907
Validation loss: 2.6070286772829454

Epoch: 5| Step: 10
Training loss: 2.988200826123655
Validation loss: 2.6066698840307936

Epoch: 101| Step: 0
Training loss: 2.6943329288788025
Validation loss: 2.6068968239291572

Epoch: 5| Step: 1
Training loss: 2.864850580869447
Validation loss: 2.6276448345038377

Epoch: 5| Step: 2
Training loss: 2.6795332171898756
Validation loss: 2.628902430241245

Epoch: 5| Step: 3
Training loss: 3.325750659159435
Validation loss: 2.6524245432444453

Epoch: 5| Step: 4
Training loss: 3.0883078441058656
Validation loss: 2.6262843324781473

Epoch: 5| Step: 5
Training loss: 3.017122045327528
Validation loss: 2.607644540698791

Epoch: 5| Step: 6
Training loss: 2.588349200230994
Validation loss: 2.5939387531889206

Epoch: 5| Step: 7
Training loss: 3.160876065994622
Validation loss: 2.587541638380577

Epoch: 5| Step: 8
Training loss: 2.724967774366862
Validation loss: 2.5869172158709017

Epoch: 5| Step: 9
Training loss: 3.2190400520670015
Validation loss: 2.5862312374365097

Epoch: 5| Step: 10
Training loss: 2.983340578407853
Validation loss: 2.5873705834312744

Epoch: 102| Step: 0
Training loss: 3.090705375281972
Validation loss: 2.5936725761559574

Epoch: 5| Step: 1
Training loss: 2.7311741868589863
Validation loss: 2.5944034624525254

Epoch: 5| Step: 2
Training loss: 3.1406290993734904
Validation loss: 2.5925835730584104

Epoch: 5| Step: 3
Training loss: 2.7335174087631544
Validation loss: 2.5892755288481895

Epoch: 5| Step: 4
Training loss: 3.204637570413016
Validation loss: 2.5879789361263428

Epoch: 5| Step: 5
Training loss: 2.6213014068437914
Validation loss: 2.5876187661527013

Epoch: 5| Step: 6
Training loss: 3.2119240092294294
Validation loss: 2.588015273890883

Epoch: 5| Step: 7
Training loss: 3.2273811243977897
Validation loss: 2.5834727320802493

Epoch: 5| Step: 8
Training loss: 2.4554180920455044
Validation loss: 2.587800404823173

Epoch: 5| Step: 9
Training loss: 2.769368972651234
Validation loss: 2.584564419444397

Epoch: 5| Step: 10
Training loss: 3.1986147504851976
Validation loss: 2.586189723914321

Epoch: 103| Step: 0
Training loss: 3.046681872384866
Validation loss: 2.598772805851305

Epoch: 5| Step: 1
Training loss: 2.6258732387747283
Validation loss: 2.6085839195174216

Epoch: 5| Step: 2
Training loss: 2.78865326088238
Validation loss: 2.630740291604671

Epoch: 5| Step: 3
Training loss: 2.6812613178005416
Validation loss: 2.672093419251345

Epoch: 5| Step: 4
Training loss: 3.117070016583081
Validation loss: 2.672542292718229

Epoch: 5| Step: 5
Training loss: 2.889573354412763
Validation loss: 2.677278589043958

Epoch: 5| Step: 6
Training loss: 3.224066038700109
Validation loss: 2.641204380143254

Epoch: 5| Step: 7
Training loss: 2.949029898754843
Validation loss: 2.6280200645004976

Epoch: 5| Step: 8
Training loss: 2.4606558502332976
Validation loss: 2.6010331890265324

Epoch: 5| Step: 9
Training loss: 3.4416658994167357
Validation loss: 2.5898882072148415

Epoch: 5| Step: 10
Training loss: 3.0097312454943514
Validation loss: 2.5844632918277424

Epoch: 104| Step: 0
Training loss: 3.3735550507016696
Validation loss: 2.576062287329282

Epoch: 5| Step: 1
Training loss: 2.750607076741223
Validation loss: 2.5831034164714173

Epoch: 5| Step: 2
Training loss: 2.9280372956615763
Validation loss: 2.5745944990447924

Epoch: 5| Step: 3
Training loss: 2.8342628263338234
Validation loss: 2.5783452044054758

Epoch: 5| Step: 4
Training loss: 3.1244017982134897
Validation loss: 2.5799838527194177

Epoch: 5| Step: 5
Training loss: 3.2702612568959215
Validation loss: 2.581126191795299

Epoch: 5| Step: 6
Training loss: 2.6452893476379953
Validation loss: 2.5777853335862226

Epoch: 5| Step: 7
Training loss: 2.8685326188446902
Validation loss: 2.5794482482494714

Epoch: 5| Step: 8
Training loss: 2.942484097109645
Validation loss: 2.579531078175441

Epoch: 5| Step: 9
Training loss: 2.8096314954941
Validation loss: 2.585637010847081

Epoch: 5| Step: 10
Training loss: 2.7872194670738613
Validation loss: 2.594136976840071

Epoch: 105| Step: 0
Training loss: 2.530327240207361
Validation loss: 2.602375999488742

Epoch: 5| Step: 1
Training loss: 2.80192510637915
Validation loss: 2.589677299892299

Epoch: 5| Step: 2
Training loss: 3.0476538029601974
Validation loss: 2.5863006369540114

Epoch: 5| Step: 3
Training loss: 2.7794874800132296
Validation loss: 2.588549358278665

Epoch: 5| Step: 4
Training loss: 3.091662540758641
Validation loss: 2.5837830209353645

Epoch: 5| Step: 5
Training loss: 2.747202924611974
Validation loss: 2.585398214628572

Epoch: 5| Step: 6
Training loss: 2.7387499877428256
Validation loss: 2.5744082849331

Epoch: 5| Step: 7
Training loss: 2.818921451471582
Validation loss: 2.5747303798554038

Epoch: 5| Step: 8
Training loss: 3.226205136365197
Validation loss: 2.5758540468628546

Epoch: 5| Step: 9
Training loss: 3.1866775648444126
Validation loss: 2.577638070867816

Epoch: 5| Step: 10
Training loss: 3.1979930425380965
Validation loss: 2.5811215146916657

Epoch: 106| Step: 0
Training loss: 3.228664203231957
Validation loss: 2.5769559733673972

Epoch: 5| Step: 1
Training loss: 2.4675129555591093
Validation loss: 2.5767357367979487

Epoch: 5| Step: 2
Training loss: 2.6389403076070206
Validation loss: 2.5727855171840566

Epoch: 5| Step: 3
Training loss: 3.26230229622772
Validation loss: 2.580543340929024

Epoch: 5| Step: 4
Training loss: 3.0673326004227532
Validation loss: 2.570885111831039

Epoch: 5| Step: 5
Training loss: 2.7061963576006662
Validation loss: 2.5795042682138343

Epoch: 5| Step: 6
Training loss: 3.1161494235545626
Validation loss: 2.57570590434666

Epoch: 5| Step: 7
Training loss: 3.2786317097322053
Validation loss: 2.5751956678981474

Epoch: 5| Step: 8
Training loss: 2.77690436513186
Validation loss: 2.5703057764890933

Epoch: 5| Step: 9
Training loss: 2.758911691826529
Validation loss: 2.5730327632983263

Epoch: 5| Step: 10
Training loss: 2.766603372225185
Validation loss: 2.5748898659926454

Epoch: 107| Step: 0
Training loss: 3.007507308735453
Validation loss: 2.5760598969105044

Epoch: 5| Step: 1
Training loss: 2.753864520683399
Validation loss: 2.575205525448509

Epoch: 5| Step: 2
Training loss: 2.8837806295910395
Validation loss: 2.575546157188012

Epoch: 5| Step: 3
Training loss: 2.467656726439773
Validation loss: 2.577645357074892

Epoch: 5| Step: 4
Training loss: 2.7980922841742757
Validation loss: 2.5752106373828645

Epoch: 5| Step: 5
Training loss: 3.1828588468298076
Validation loss: 2.575507460602521

Epoch: 5| Step: 6
Training loss: 3.0953029241514862
Validation loss: 2.578113983220253

Epoch: 5| Step: 7
Training loss: 3.1320084374753834
Validation loss: 2.577521048139101

Epoch: 5| Step: 8
Training loss: 2.6090575613307965
Validation loss: 2.5758730557324405

Epoch: 5| Step: 9
Training loss: 3.243396800074634
Validation loss: 2.576688115605168

Epoch: 5| Step: 10
Training loss: 2.936155620306961
Validation loss: 2.5739470935180933

Epoch: 108| Step: 0
Training loss: 2.842747270469573
Validation loss: 2.5670574253218694

Epoch: 5| Step: 1
Training loss: 2.699528501102624
Validation loss: 2.5647851892536653

Epoch: 5| Step: 2
Training loss: 3.076332461086222
Validation loss: 2.5661687182413178

Epoch: 5| Step: 3
Training loss: 2.863589989643102
Validation loss: 2.565369530774932

Epoch: 5| Step: 4
Training loss: 2.8836273447713703
Validation loss: 2.566119093697273

Epoch: 5| Step: 5
Training loss: 3.708505962225596
Validation loss: 2.565147609831075

Epoch: 5| Step: 6
Training loss: 2.3982896790321226
Validation loss: 2.5711609694557596

Epoch: 5| Step: 7
Training loss: 2.380065134583682
Validation loss: 2.577029688437603

Epoch: 5| Step: 8
Training loss: 2.840847672232035
Validation loss: 2.573067091304759

Epoch: 5| Step: 9
Training loss: 3.002525061662374
Validation loss: 2.5762454751811017

Epoch: 5| Step: 10
Training loss: 3.399582663335468
Validation loss: 2.586574026885017

Epoch: 109| Step: 0
Training loss: 3.382369014574967
Validation loss: 2.573428773891672

Epoch: 5| Step: 1
Training loss: 2.8111908302848
Validation loss: 2.561883559615305

Epoch: 5| Step: 2
Training loss: 3.1354882283878673
Validation loss: 2.5603894031291032

Epoch: 5| Step: 3
Training loss: 3.3633033671964414
Validation loss: 2.5640142485260267

Epoch: 5| Step: 4
Training loss: 3.2913608811387025
Validation loss: 2.568343396361126

Epoch: 5| Step: 5
Training loss: 2.696480141528212
Validation loss: 2.567670487436945

Epoch: 5| Step: 6
Training loss: 2.7918681930756195
Validation loss: 2.570107797564695

Epoch: 5| Step: 7
Training loss: 3.095808481054212
Validation loss: 2.5717069158129915

Epoch: 5| Step: 8
Training loss: 2.37182806921003
Validation loss: 2.56539749376445

Epoch: 5| Step: 9
Training loss: 2.4874943757113415
Validation loss: 2.560925261706575

Epoch: 5| Step: 10
Training loss: 2.6999297909968427
Validation loss: 2.560079945995462

Epoch: 110| Step: 0
Training loss: 3.179144285697368
Validation loss: 2.561848741515128

Epoch: 5| Step: 1
Training loss: 2.9491007193889778
Validation loss: 2.5650146345486937

Epoch: 5| Step: 2
Training loss: 3.1897174377621087
Validation loss: 2.5695017737197725

Epoch: 5| Step: 3
Training loss: 2.5965246962723176
Validation loss: 2.5919476080805524

Epoch: 5| Step: 4
Training loss: 2.858688522231597
Validation loss: 2.608707903943503

Epoch: 5| Step: 5
Training loss: 3.10917685946107
Validation loss: 2.6001578175029483

Epoch: 5| Step: 6
Training loss: 2.3708843911767783
Validation loss: 2.6142027069263056

Epoch: 5| Step: 7
Training loss: 3.193772222213922
Validation loss: 2.6042265457324296

Epoch: 5| Step: 8
Training loss: 2.7771892263184546
Validation loss: 2.6291413997321866

Epoch: 5| Step: 9
Training loss: 2.570004801318957
Validation loss: 2.5842693795079175

Epoch: 5| Step: 10
Training loss: 3.2104205158531554
Validation loss: 2.568680819184704

Epoch: 111| Step: 0
Training loss: 3.214105310372856
Validation loss: 2.5601013606492438

Epoch: 5| Step: 1
Training loss: 2.997336317720432
Validation loss: 2.5544632590645744

Epoch: 5| Step: 2
Training loss: 2.5710844138853113
Validation loss: 2.5572056615619227

Epoch: 5| Step: 3
Training loss: 2.9908425119478315
Validation loss: 2.560427053601301

Epoch: 5| Step: 4
Training loss: 3.0710338104384256
Validation loss: 2.561134838120717

Epoch: 5| Step: 5
Training loss: 3.2222106995504443
Validation loss: 2.5537648718354427

Epoch: 5| Step: 6
Training loss: 2.489829738877957
Validation loss: 2.55454517098605

Epoch: 5| Step: 7
Training loss: 3.189686044292953
Validation loss: 2.558628896950765

Epoch: 5| Step: 8
Training loss: 2.819153608366511
Validation loss: 2.558670617171411

Epoch: 5| Step: 9
Training loss: 2.5596145573663027
Validation loss: 2.5583570871723107

Epoch: 5| Step: 10
Training loss: 2.872249614536586
Validation loss: 2.5592327192711832

Epoch: 112| Step: 0
Training loss: 3.2289696089802042
Validation loss: 2.5738503575948926

Epoch: 5| Step: 1
Training loss: 3.3906932068042455
Validation loss: 2.5763809962726163

Epoch: 5| Step: 2
Training loss: 2.6766253622659892
Validation loss: 2.5903686660641414

Epoch: 5| Step: 3
Training loss: 2.964664579463516
Validation loss: 2.603679037072656

Epoch: 5| Step: 4
Training loss: 2.4561128340221843
Validation loss: 2.6343302742934958

Epoch: 5| Step: 5
Training loss: 2.4504922722595572
Validation loss: 2.666845250943533

Epoch: 5| Step: 6
Training loss: 3.0727980941051483
Validation loss: 2.755415361179694

Epoch: 5| Step: 7
Training loss: 3.1244190438987918
Validation loss: 2.738943625979261

Epoch: 5| Step: 8
Training loss: 2.813221732889553
Validation loss: 2.629377327933939

Epoch: 5| Step: 9
Training loss: 2.7461404592955865
Validation loss: 2.5713617855049717

Epoch: 5| Step: 10
Training loss: 3.078710355143319
Validation loss: 2.5571169293001867

Epoch: 113| Step: 0
Training loss: 3.191074984480871
Validation loss: 2.557502337579691

Epoch: 5| Step: 1
Training loss: 3.1830088072189646
Validation loss: 2.5696584936276943

Epoch: 5| Step: 2
Training loss: 2.8834072419618506
Validation loss: 2.5733360462545285

Epoch: 5| Step: 3
Training loss: 3.098344877842953
Validation loss: 2.5961961663067217

Epoch: 5| Step: 4
Training loss: 2.425164038232302
Validation loss: 2.60609816132047

Epoch: 5| Step: 5
Training loss: 3.407145531200035
Validation loss: 2.6454101852645557

Epoch: 5| Step: 6
Training loss: 2.887641150257194
Validation loss: 2.6034160124432217

Epoch: 5| Step: 7
Training loss: 3.2240582000268923
Validation loss: 2.5793831319348888

Epoch: 5| Step: 8
Training loss: 2.945410607927525
Validation loss: 2.569576160573191

Epoch: 5| Step: 9
Training loss: 2.612806063159231
Validation loss: 2.5661395508382427

Epoch: 5| Step: 10
Training loss: 2.668541418139034
Validation loss: 2.558520360471976

Epoch: 114| Step: 0
Training loss: 2.6914615265550017
Validation loss: 2.560068254730582

Epoch: 5| Step: 1
Training loss: 3.9033671002402888
Validation loss: 2.5775865198173884

Epoch: 5| Step: 2
Training loss: 2.717305643804728
Validation loss: 2.616147865093948

Epoch: 5| Step: 3
Training loss: 2.8134187681173457
Validation loss: 2.6761695454928693

Epoch: 5| Step: 4
Training loss: 3.1679500856802223
Validation loss: 2.6777745267490065

Epoch: 5| Step: 5
Training loss: 2.6083176349334045
Validation loss: 2.573315124293742

Epoch: 5| Step: 6
Training loss: 2.3522382506674004
Validation loss: 2.5654388291041776

Epoch: 5| Step: 7
Training loss: 3.178635481775313
Validation loss: 2.548878791244841

Epoch: 5| Step: 8
Training loss: 2.5735438479491455
Validation loss: 2.5504191953447752

Epoch: 5| Step: 9
Training loss: 3.0117546900721157
Validation loss: 2.548695515362368

Epoch: 5| Step: 10
Training loss: 2.997882572604941
Validation loss: 2.5470966167449176

Epoch: 115| Step: 0
Training loss: 2.6573538786512905
Validation loss: 2.548127816019131

Epoch: 5| Step: 1
Training loss: 2.6314600518622964
Validation loss: 2.555978748307198

Epoch: 5| Step: 2
Training loss: 2.602862059283627
Validation loss: 2.57082737433864

Epoch: 5| Step: 3
Training loss: 2.115091222144029
Validation loss: 2.5829814574652223

Epoch: 5| Step: 4
Training loss: 3.4746388803465487
Validation loss: 2.6185027000027046

Epoch: 5| Step: 5
Training loss: 3.1958144710005683
Validation loss: 2.6205091447866122

Epoch: 5| Step: 6
Training loss: 2.868352253253194
Validation loss: 2.6011553207379814

Epoch: 5| Step: 7
Training loss: 3.3121262825373385
Validation loss: 2.6307361772877766

Epoch: 5| Step: 8
Training loss: 3.158848665279285
Validation loss: 2.5738031810418676

Epoch: 5| Step: 9
Training loss: 3.1387589258016164
Validation loss: 2.5569580721339156

Epoch: 5| Step: 10
Training loss: 2.76704275570101
Validation loss: 2.5496718169554704

Epoch: 116| Step: 0
Training loss: 3.3237419100200647
Validation loss: 2.5521149379505266

Epoch: 5| Step: 1
Training loss: 2.921626932149973
Validation loss: 2.546351806041364

Epoch: 5| Step: 2
Training loss: 3.0607394393393474
Validation loss: 2.548020135171195

Epoch: 5| Step: 3
Training loss: 3.323599303789992
Validation loss: 2.547223173332534

Epoch: 5| Step: 4
Training loss: 2.504899564393302
Validation loss: 2.549328594824147

Epoch: 5| Step: 5
Training loss: 2.5601180566447987
Validation loss: 2.5477995576827626

Epoch: 5| Step: 6
Training loss: 3.0387893200946636
Validation loss: 2.556007598368305

Epoch: 5| Step: 7
Training loss: 3.2535055767906726
Validation loss: 2.5580075780248013

Epoch: 5| Step: 8
Training loss: 2.6745864762442606
Validation loss: 2.56531102756142

Epoch: 5| Step: 9
Training loss: 2.4038752938485066
Validation loss: 2.561374451129529

Epoch: 5| Step: 10
Training loss: 2.642603838133632
Validation loss: 2.5682460460927974

Epoch: 117| Step: 0
Training loss: 2.8256519105571036
Validation loss: 2.5568733679387514

Epoch: 5| Step: 1
Training loss: 2.913416077452111
Validation loss: 2.563134861358889

Epoch: 5| Step: 2
Training loss: 2.9478412164708625
Validation loss: 2.560344297528969

Epoch: 5| Step: 3
Training loss: 3.082231444999222
Validation loss: 2.5543908116922314

Epoch: 5| Step: 4
Training loss: 2.837415746034537
Validation loss: 2.5668486445808996

Epoch: 5| Step: 5
Training loss: 2.5765200156277026
Validation loss: 2.5581666846907094

Epoch: 5| Step: 6
Training loss: 2.95843238843825
Validation loss: 2.5611700653110487

Epoch: 5| Step: 7
Training loss: 3.2369187529192773
Validation loss: 2.561800257167811

Epoch: 5| Step: 8
Training loss: 2.7233637105429644
Validation loss: 2.547923394898463

Epoch: 5| Step: 9
Training loss: 2.8011593530194423
Validation loss: 2.551941837877722

Epoch: 5| Step: 10
Training loss: 2.958581475251801
Validation loss: 2.5452392809321993

Epoch: 118| Step: 0
Training loss: 3.001326267809737
Validation loss: 2.552986712075739

Epoch: 5| Step: 1
Training loss: 3.0748673449179518
Validation loss: 2.545904770319749

Epoch: 5| Step: 2
Training loss: 2.9877919712803735
Validation loss: 2.5449077860892446

Epoch: 5| Step: 3
Training loss: 2.6115114522876763
Validation loss: 2.5454019116077062

Epoch: 5| Step: 4
Training loss: 2.899814823420943
Validation loss: 2.548844351705251

Epoch: 5| Step: 5
Training loss: 2.789852938587501
Validation loss: 2.547343867411977

Epoch: 5| Step: 6
Training loss: 2.6430770955555833
Validation loss: 2.5417040834407865

Epoch: 5| Step: 7
Training loss: 2.993243875108412
Validation loss: 2.5403285381483625

Epoch: 5| Step: 8
Training loss: 2.4556250012427623
Validation loss: 2.533893580640733

Epoch: 5| Step: 9
Training loss: 3.3002375950678045
Validation loss: 2.5353611736989343

Epoch: 5| Step: 10
Training loss: 3.081939347786166
Validation loss: 2.5323624115536383

Epoch: 119| Step: 0
Training loss: 3.206415040525692
Validation loss: 2.5326561080345895

Epoch: 5| Step: 1
Training loss: 3.764847291278618
Validation loss: 2.531644108621072

Epoch: 5| Step: 2
Training loss: 2.5731422129832007
Validation loss: 2.533925791191632

Epoch: 5| Step: 3
Training loss: 2.691263624157685
Validation loss: 2.5305182795627035

Epoch: 5| Step: 4
Training loss: 2.033768486403165
Validation loss: 2.5357189139634664

Epoch: 5| Step: 5
Training loss: 3.1627476350231043
Validation loss: 2.5327347776396363

Epoch: 5| Step: 6
Training loss: 2.9825806341278867
Validation loss: 2.5360072885570766

Epoch: 5| Step: 7
Training loss: 2.5369603301943804
Validation loss: 2.5376209957401157

Epoch: 5| Step: 8
Training loss: 2.884615863897822
Validation loss: 2.5525871805786453

Epoch: 5| Step: 9
Training loss: 2.967549292035295
Validation loss: 2.5859299238809195

Epoch: 5| Step: 10
Training loss: 2.8510056043320255
Validation loss: 2.611440297963674

Epoch: 120| Step: 0
Training loss: 2.514874458895781
Validation loss: 2.5587299094330738

Epoch: 5| Step: 1
Training loss: 2.5270837476142445
Validation loss: 2.5534450157186916

Epoch: 5| Step: 2
Training loss: 2.9142971404570224
Validation loss: 2.5411304649297204

Epoch: 5| Step: 3
Training loss: 2.7328116171013708
Validation loss: 2.5361658285490787

Epoch: 5| Step: 4
Training loss: 3.0770810288455284
Validation loss: 2.533313078089611

Epoch: 5| Step: 5
Training loss: 2.8018232506136864
Validation loss: 2.535746426466434

Epoch: 5| Step: 6
Training loss: 2.8352441702082216
Validation loss: 2.5313277056034287

Epoch: 5| Step: 7
Training loss: 3.239451087795543
Validation loss: 2.5293219072214423

Epoch: 5| Step: 8
Training loss: 2.8642648045857375
Validation loss: 2.5407928653918255

Epoch: 5| Step: 9
Training loss: 3.2305012231968235
Validation loss: 2.553891608924647

Epoch: 5| Step: 10
Training loss: 3.001936764197853
Validation loss: 2.536256161060648

Epoch: 121| Step: 0
Training loss: 3.3214426787467946
Validation loss: 2.528735260830891

Epoch: 5| Step: 1
Training loss: 2.5036942843076715
Validation loss: 2.52998987914968

Epoch: 5| Step: 2
Training loss: 2.8635045650146713
Validation loss: 2.526906014015627

Epoch: 5| Step: 3
Training loss: 2.979108867662567
Validation loss: 2.5294405780879554

Epoch: 5| Step: 4
Training loss: 2.333577983382773
Validation loss: 2.528044307002056

Epoch: 5| Step: 5
Training loss: 2.7690860621839644
Validation loss: 2.532178877741994

Epoch: 5| Step: 6
Training loss: 2.825239195023005
Validation loss: 2.5363936783136762

Epoch: 5| Step: 7
Training loss: 3.150566649559706
Validation loss: 2.5452092149476275

Epoch: 5| Step: 8
Training loss: 3.113774087109044
Validation loss: 2.547956865884835

Epoch: 5| Step: 9
Training loss: 2.7081691007459012
Validation loss: 2.5486777497334647

Epoch: 5| Step: 10
Training loss: 3.0569496461703767
Validation loss: 2.554561292131094

Epoch: 122| Step: 0
Training loss: 2.831134017353956
Validation loss: 2.556183582306249

Epoch: 5| Step: 1
Training loss: 2.892546803615872
Validation loss: 2.5689280971042394

Epoch: 5| Step: 2
Training loss: 3.533069108284407
Validation loss: 2.5492042385641387

Epoch: 5| Step: 3
Training loss: 2.8005015979797023
Validation loss: 2.5451370088011225

Epoch: 5| Step: 4
Training loss: 2.632568348054374
Validation loss: 2.5206266491523968

Epoch: 5| Step: 5
Training loss: 3.2574188946034304
Validation loss: 2.523823192434101

Epoch: 5| Step: 6
Training loss: 2.8390511058522043
Validation loss: 2.531121292093092

Epoch: 5| Step: 7
Training loss: 2.3793711341163166
Validation loss: 2.5287551150805183

Epoch: 5| Step: 8
Training loss: 2.8881535042415076
Validation loss: 2.532653367915656

Epoch: 5| Step: 9
Training loss: 2.629908740414799
Validation loss: 2.536338512404267

Epoch: 5| Step: 10
Training loss: 3.261044296614197
Validation loss: 2.530995355009418

Epoch: 123| Step: 0
Training loss: 2.885739874153049
Validation loss: 2.5233691532722724

Epoch: 5| Step: 1
Training loss: 3.2475866013418844
Validation loss: 2.5225578422471444

Epoch: 5| Step: 2
Training loss: 2.4540597871867167
Validation loss: 2.52709574871897

Epoch: 5| Step: 3
Training loss: 2.76354143353828
Validation loss: 2.53355832155982

Epoch: 5| Step: 4
Training loss: 2.6447791655281203
Validation loss: 2.5397166732257044

Epoch: 5| Step: 5
Training loss: 3.282719019884764
Validation loss: 2.537097271713843

Epoch: 5| Step: 6
Training loss: 3.042173230216597
Validation loss: 2.546888528437254

Epoch: 5| Step: 7
Training loss: 2.9492971649860955
Validation loss: 2.5430795429838224

Epoch: 5| Step: 8
Training loss: 3.049863943598614
Validation loss: 2.5427949597537793

Epoch: 5| Step: 9
Training loss: 2.952073328777008
Validation loss: 2.544106908880863

Epoch: 5| Step: 10
Training loss: 2.289867689150069
Validation loss: 2.531852922804562

Epoch: 124| Step: 0
Training loss: 2.746848381182573
Validation loss: 2.544828299034921

Epoch: 5| Step: 1
Training loss: 2.998995612812554
Validation loss: 2.5320070998781063

Epoch: 5| Step: 2
Training loss: 3.1550878519198986
Validation loss: 2.5342671248246456

Epoch: 5| Step: 3
Training loss: 2.504260914362433
Validation loss: 2.5440146714157845

Epoch: 5| Step: 4
Training loss: 2.8498100016655954
Validation loss: 2.539049970849916

Epoch: 5| Step: 5
Training loss: 2.66683270016996
Validation loss: 2.553903684316574

Epoch: 5| Step: 6
Training loss: 2.737830371169183
Validation loss: 2.5403434527285675

Epoch: 5| Step: 7
Training loss: 3.5619889277565084
Validation loss: 2.548091988976137

Epoch: 5| Step: 8
Training loss: 2.9085338191872476
Validation loss: 2.5362116795288374

Epoch: 5| Step: 9
Training loss: 3.0695357177266893
Validation loss: 2.5377079134368024

Epoch: 5| Step: 10
Training loss: 2.1386195903640317
Validation loss: 2.541894734715893

Epoch: 125| Step: 0
Training loss: 3.058763677132306
Validation loss: 2.531946450793343

Epoch: 5| Step: 1
Training loss: 2.3627098716885784
Validation loss: 2.527277521458591

Epoch: 5| Step: 2
Training loss: 2.9847140294380656
Validation loss: 2.523839321899783

Epoch: 5| Step: 3
Training loss: 2.8118181885701166
Validation loss: 2.5205305123201627

Epoch: 5| Step: 4
Training loss: 2.5493299202231112
Validation loss: 2.530720698837844

Epoch: 5| Step: 5
Training loss: 2.575810266064625
Validation loss: 2.5227298235085227

Epoch: 5| Step: 6
Training loss: 2.964017287951669
Validation loss: 2.52311890599707

Epoch: 5| Step: 7
Training loss: 2.716784062413623
Validation loss: 2.523537522608108

Epoch: 5| Step: 8
Training loss: 2.946866786455862
Validation loss: 2.532135318803736

Epoch: 5| Step: 9
Training loss: 3.344643161597059
Validation loss: 2.5376151534370743

Epoch: 5| Step: 10
Training loss: 3.2311305483315476
Validation loss: 2.5534881609445477

Epoch: 126| Step: 0
Training loss: 3.0121971769599916
Validation loss: 2.55221481804899

Epoch: 5| Step: 1
Training loss: 3.3396407216250275
Validation loss: 2.5461623020492175

Epoch: 5| Step: 2
Training loss: 3.082640458346476
Validation loss: 2.5425566640298634

Epoch: 5| Step: 3
Training loss: 2.8297401157924034
Validation loss: 2.5275797941252973

Epoch: 5| Step: 4
Training loss: 2.8801427538248285
Validation loss: 2.5260026687505865

Epoch: 5| Step: 5
Training loss: 3.02103977594136
Validation loss: 2.519589766146953

Epoch: 5| Step: 6
Training loss: 2.420932512555168
Validation loss: 2.5156225511328416

Epoch: 5| Step: 7
Training loss: 2.4345823579162005
Validation loss: 2.5193747250916223

Epoch: 5| Step: 8
Training loss: 2.4454516288982298
Validation loss: 2.5164983078481047

Epoch: 5| Step: 9
Training loss: 3.2122728675671386
Validation loss: 2.5159471392587083

Epoch: 5| Step: 10
Training loss: 2.9557036590595853
Validation loss: 2.51507741045482

Epoch: 127| Step: 0
Training loss: 2.588645416165993
Validation loss: 2.517494560686576

Epoch: 5| Step: 1
Training loss: 2.767793398004422
Validation loss: 2.5211618054028824

Epoch: 5| Step: 2
Training loss: 3.1012520814924778
Validation loss: 2.5285709432913834

Epoch: 5| Step: 3
Training loss: 3.0278423858499974
Validation loss: 2.527524425700606

Epoch: 5| Step: 4
Training loss: 2.660385950957217
Validation loss: 2.5329245929224133

Epoch: 5| Step: 5
Training loss: 2.8903519785021596
Validation loss: 2.5359831239744306

Epoch: 5| Step: 6
Training loss: 2.8272602592846785
Validation loss: 2.541758171692383

Epoch: 5| Step: 7
Training loss: 2.937658752047529
Validation loss: 2.5546218087413584

Epoch: 5| Step: 8
Training loss: 2.7690783131643744
Validation loss: 2.544755603555118

Epoch: 5| Step: 9
Training loss: 2.886965192668876
Validation loss: 2.5392698979766557

Epoch: 5| Step: 10
Training loss: 3.1225458808502937
Validation loss: 2.547806907085167

Epoch: 128| Step: 0
Training loss: 2.8757870467587936
Validation loss: 2.557869407701348

Epoch: 5| Step: 1
Training loss: 2.729571411948408
Validation loss: 2.560982611809558

Epoch: 5| Step: 2
Training loss: 2.9325762125633967
Validation loss: 2.560284052357644

Epoch: 5| Step: 3
Training loss: 3.1983732380116154
Validation loss: 2.5635894492393376

Epoch: 5| Step: 4
Training loss: 2.6633199512716823
Validation loss: 2.571271006305697

Epoch: 5| Step: 5
Training loss: 3.111840272408185
Validation loss: 2.554634046765225

Epoch: 5| Step: 6
Training loss: 2.6532178738966663
Validation loss: 2.5437303298689957

Epoch: 5| Step: 7
Training loss: 2.6970591317590866
Validation loss: 2.537896473901529

Epoch: 5| Step: 8
Training loss: 2.913960391140005
Validation loss: 2.5206103465680183

Epoch: 5| Step: 9
Training loss: 2.4835323608145585
Validation loss: 2.523338928298815

Epoch: 5| Step: 10
Training loss: 3.200537255009403
Validation loss: 2.514720875801508

Epoch: 129| Step: 0
Training loss: 2.795487043497746
Validation loss: 2.513936880104544

Epoch: 5| Step: 1
Training loss: 2.7145301253480536
Validation loss: 2.5158912906532533

Epoch: 5| Step: 2
Training loss: 2.6363930282030625
Validation loss: 2.5140387832735476

Epoch: 5| Step: 3
Training loss: 3.2324381018286057
Validation loss: 2.5144018716712826

Epoch: 5| Step: 4
Training loss: 2.5311809577473983
Validation loss: 2.513000825528891

Epoch: 5| Step: 5
Training loss: 3.2975448723343543
Validation loss: 2.5134871763241775

Epoch: 5| Step: 6
Training loss: 3.148552904309431
Validation loss: 2.5194564824776733

Epoch: 5| Step: 7
Training loss: 2.8243999924285204
Validation loss: 2.5228053120501706

Epoch: 5| Step: 8
Training loss: 2.3741041802908547
Validation loss: 2.5341046450255753

Epoch: 5| Step: 9
Training loss: 2.8747181961605257
Validation loss: 2.5419151336674024

Epoch: 5| Step: 10
Training loss: 3.0788929557368085
Validation loss: 2.5779208135059273

Epoch: 130| Step: 0
Training loss: 3.034737380101699
Validation loss: 2.583190736066862

Epoch: 5| Step: 1
Training loss: 3.0473522888386304
Validation loss: 2.601291075593461

Epoch: 5| Step: 2
Training loss: 2.6557668807548884
Validation loss: 2.571734225739135

Epoch: 5| Step: 3
Training loss: 3.3056320391728056
Validation loss: 2.5464973101714383

Epoch: 5| Step: 4
Training loss: 2.491795619659897
Validation loss: 2.53189188461317

Epoch: 5| Step: 5
Training loss: 2.905534225427716
Validation loss: 2.5190840414305335

Epoch: 5| Step: 6
Training loss: 2.7725111582938253
Validation loss: 2.5084856088559038

Epoch: 5| Step: 7
Training loss: 2.7992939637896606
Validation loss: 2.5188279741405686

Epoch: 5| Step: 8
Training loss: 2.754842482700633
Validation loss: 2.5183014605705902

Epoch: 5| Step: 9
Training loss: 2.83111869052782
Validation loss: 2.513705160563756

Epoch: 5| Step: 10
Training loss: 3.043241084672471
Validation loss: 2.514022662311127

Epoch: 131| Step: 0
Training loss: 3.0216264056388416
Validation loss: 2.5103408886458904

Epoch: 5| Step: 1
Training loss: 3.182350936479218
Validation loss: 2.5143063864486885

Epoch: 5| Step: 2
Training loss: 2.6776436443246947
Validation loss: 2.517228408576489

Epoch: 5| Step: 3
Training loss: 2.636798139719168
Validation loss: 2.5241076598864436

Epoch: 5| Step: 4
Training loss: 2.75946341315703
Validation loss: 2.5425100603266686

Epoch: 5| Step: 5
Training loss: 2.7412914757606726
Validation loss: 2.5537991647105285

Epoch: 5| Step: 6
Training loss: 3.106349220456572
Validation loss: 2.5992766240132306

Epoch: 5| Step: 7
Training loss: 2.704293500123156
Validation loss: 2.631164788846752

Epoch: 5| Step: 8
Training loss: 3.2053621248812956
Validation loss: 2.5947426651930674

Epoch: 5| Step: 9
Training loss: 2.973046015327198
Validation loss: 2.5545352818817166

Epoch: 5| Step: 10
Training loss: 2.478128605920542
Validation loss: 2.5154212110405934

Epoch: 132| Step: 0
Training loss: 3.1155291665967497
Validation loss: 2.524355888715913

Epoch: 5| Step: 1
Training loss: 2.79232469081858
Validation loss: 2.5082139570551614

Epoch: 5| Step: 2
Training loss: 2.871307987861495
Validation loss: 2.5004758115426995

Epoch: 5| Step: 3
Training loss: 3.120192224498719
Validation loss: 2.499484469470337

Epoch: 5| Step: 4
Training loss: 2.828972958060314
Validation loss: 2.505355660415962

Epoch: 5| Step: 5
Training loss: 2.5866606931355247
Validation loss: 2.510229628051858

Epoch: 5| Step: 6
Training loss: 2.4562353352116197
Validation loss: 2.505607635751619

Epoch: 5| Step: 7
Training loss: 3.133245500050455
Validation loss: 2.511972576223534

Epoch: 5| Step: 8
Training loss: 3.0840592088371586
Validation loss: 2.5139190886019134

Epoch: 5| Step: 9
Training loss: 2.680284172336269
Validation loss: 2.5395776107190473

Epoch: 5| Step: 10
Training loss: 2.852848964679167
Validation loss: 2.563781291891718

Epoch: 133| Step: 0
Training loss: 2.720153884601808
Validation loss: 2.560948242444464

Epoch: 5| Step: 1
Training loss: 2.8596851618409875
Validation loss: 2.547902298473099

Epoch: 5| Step: 2
Training loss: 2.924371315973566
Validation loss: 2.5327977115643487

Epoch: 5| Step: 3
Training loss: 3.0101949396723633
Validation loss: 2.5222084432568908

Epoch: 5| Step: 4
Training loss: 3.31837288245853
Validation loss: 2.5110642921073802

Epoch: 5| Step: 5
Training loss: 2.742465448014072
Validation loss: 2.5166661446754235

Epoch: 5| Step: 6
Training loss: 2.911327561573305
Validation loss: 2.5143155309067198

Epoch: 5| Step: 7
Training loss: 2.994395743473176
Validation loss: 2.5120138078819805

Epoch: 5| Step: 8
Training loss: 2.720025125275299
Validation loss: 2.5115810453438945

Epoch: 5| Step: 9
Training loss: 2.1210575557311313
Validation loss: 2.504594876939333

Epoch: 5| Step: 10
Training loss: 3.014619491630957
Validation loss: 2.509995777329378

Epoch: 134| Step: 0
Training loss: 3.2427326525397016
Validation loss: 2.507383855109742

Epoch: 5| Step: 1
Training loss: 2.3342726270092338
Validation loss: 2.5134751673602036

Epoch: 5| Step: 2
Training loss: 2.6542477410198972
Validation loss: 2.506819627043899

Epoch: 5| Step: 3
Training loss: 2.7112690395814054
Validation loss: 2.5052578180802656

Epoch: 5| Step: 4
Training loss: 2.9491147862987823
Validation loss: 2.5100456075557593

Epoch: 5| Step: 5
Training loss: 2.913855824031901
Validation loss: 2.508157110382813

Epoch: 5| Step: 6
Training loss: 2.895569896836514
Validation loss: 2.512882629059326

Epoch: 5| Step: 7
Training loss: 2.556103888255509
Validation loss: 2.5216778578115213

Epoch: 5| Step: 8
Training loss: 2.8791732353728055
Validation loss: 2.5187692672671247

Epoch: 5| Step: 9
Training loss: 2.827119511537039
Validation loss: 2.5232485864887737

Epoch: 5| Step: 10
Training loss: 3.266440111854723
Validation loss: 2.5246251801435537

Epoch: 135| Step: 0
Training loss: 3.216696371096166
Validation loss: 2.514433091099576

Epoch: 5| Step: 1
Training loss: 2.7246599527675617
Validation loss: 2.50196841691556

Epoch: 5| Step: 2
Training loss: 2.9486802980109474
Validation loss: 2.5034876000174875

Epoch: 5| Step: 3
Training loss: 2.555240209675851
Validation loss: 2.5048238268901106

Epoch: 5| Step: 4
Training loss: 3.0352663783611913
Validation loss: 2.5059098082054363

Epoch: 5| Step: 5
Training loss: 3.2145039227002314
Validation loss: 2.5111390027189873

Epoch: 5| Step: 6
Training loss: 2.9138926438641866
Validation loss: 2.506345756288407

Epoch: 5| Step: 7
Training loss: 2.7030720788262523
Validation loss: 2.5119297823920403

Epoch: 5| Step: 8
Training loss: 2.3083060096564987
Validation loss: 2.516623607906321

Epoch: 5| Step: 9
Training loss: 2.558916051235227
Validation loss: 2.5429278327376137

Epoch: 5| Step: 10
Training loss: 3.1654754874497937
Validation loss: 2.537356332886152

Epoch: 136| Step: 0
Training loss: 2.2649655138636655
Validation loss: 2.512800665945884

Epoch: 5| Step: 1
Training loss: 2.2950295021305096
Validation loss: 2.5120691528260792

Epoch: 5| Step: 2
Training loss: 3.1514084951875154
Validation loss: 2.5014718470919832

Epoch: 5| Step: 3
Training loss: 2.9131275139507062
Validation loss: 2.4975199642194585

Epoch: 5| Step: 4
Training loss: 2.8083542680573212
Validation loss: 2.49292979663663

Epoch: 5| Step: 5
Training loss: 3.039334870908359
Validation loss: 2.499630552086072

Epoch: 5| Step: 6
Training loss: 2.1826755183061204
Validation loss: 2.500281550847734

Epoch: 5| Step: 7
Training loss: 3.2007951404213335
Validation loss: 2.510736221387627

Epoch: 5| Step: 8
Training loss: 3.0628524888822746
Validation loss: 2.5119155727314935

Epoch: 5| Step: 9
Training loss: 3.307289199627935
Validation loss: 2.5143213447601616

Epoch: 5| Step: 10
Training loss: 2.7101882646769533
Validation loss: 2.5143312329703726

Epoch: 137| Step: 0
Training loss: 3.1158286744543973
Validation loss: 2.5173026536361776

Epoch: 5| Step: 1
Training loss: 2.641958588396172
Validation loss: 2.509986852560699

Epoch: 5| Step: 2
Training loss: 2.6522860401375445
Validation loss: 2.4996154530421775

Epoch: 5| Step: 3
Training loss: 3.062425262162021
Validation loss: 2.5070045889006103

Epoch: 5| Step: 4
Training loss: 2.846418365471159
Validation loss: 2.499795355675877

Epoch: 5| Step: 5
Training loss: 2.9808419770103107
Validation loss: 2.4984503978489268

Epoch: 5| Step: 6
Training loss: 3.218459773636166
Validation loss: 2.5030411885923596

Epoch: 5| Step: 7
Training loss: 3.152861334038464
Validation loss: 2.4997010329128617

Epoch: 5| Step: 8
Training loss: 2.5625586154095417
Validation loss: 2.5068947162350312

Epoch: 5| Step: 9
Training loss: 2.7336308801947005
Validation loss: 2.520233791497974

Epoch: 5| Step: 10
Training loss: 2.0356513828703053
Validation loss: 2.520408833280524

Epoch: 138| Step: 0
Training loss: 3.291662932446128
Validation loss: 2.5523757040489046

Epoch: 5| Step: 1
Training loss: 3.319203198195411
Validation loss: 2.5380129054670935

Epoch: 5| Step: 2
Training loss: 3.169111429101387
Validation loss: 2.5544296515353255

Epoch: 5| Step: 3
Training loss: 3.073354054158407
Validation loss: 2.5119175200200448

Epoch: 5| Step: 4
Training loss: 3.001230305484339
Validation loss: 2.5080583245088506

Epoch: 5| Step: 5
Training loss: 1.8392817778948645
Validation loss: 2.5060087125319828

Epoch: 5| Step: 6
Training loss: 2.2796811496575575
Validation loss: 2.5107665480424197

Epoch: 5| Step: 7
Training loss: 3.011403345595419
Validation loss: 2.519221821371431

Epoch: 5| Step: 8
Training loss: 1.9884390477964764
Validation loss: 2.5303213689056245

Epoch: 5| Step: 9
Training loss: 3.1356999130987204
Validation loss: 2.525396697597123

Epoch: 5| Step: 10
Training loss: 2.7876382391483405
Validation loss: 2.5362931069455428

Epoch: 139| Step: 0
Training loss: 2.7008585165423593
Validation loss: 2.507980932401854

Epoch: 5| Step: 1
Training loss: 2.2417196922223157
Validation loss: 2.507124872897436

Epoch: 5| Step: 2
Training loss: 3.0095934066663736
Validation loss: 2.503143437517767

Epoch: 5| Step: 3
Training loss: 3.258577325633656
Validation loss: 2.4954912186791427

Epoch: 5| Step: 4
Training loss: 2.876352738290845
Validation loss: 2.494787315131764

Epoch: 5| Step: 5
Training loss: 2.9309998688191827
Validation loss: 2.4900849562489014

Epoch: 5| Step: 6
Training loss: 3.068939290161866
Validation loss: 2.494038114913546

Epoch: 5| Step: 7
Training loss: 3.352778572040988
Validation loss: 2.4956171153056146

Epoch: 5| Step: 8
Training loss: 2.4106962072108327
Validation loss: 2.4979289100130235

Epoch: 5| Step: 9
Training loss: 2.6392661667104886
Validation loss: 2.4980670234424176

Epoch: 5| Step: 10
Training loss: 2.4359174628470526
Validation loss: 2.5011234548386727

Epoch: 140| Step: 0
Training loss: 2.7795907546775243
Validation loss: 2.5089873503930047

Epoch: 5| Step: 1
Training loss: 2.893591106493305
Validation loss: 2.5434497080840797

Epoch: 5| Step: 2
Training loss: 3.19433459401722
Validation loss: 2.5498800310212357

Epoch: 5| Step: 3
Training loss: 2.985899371148744
Validation loss: 2.592562776759688

Epoch: 5| Step: 4
Training loss: 2.9695667950179607
Validation loss: 2.6374273431977575

Epoch: 5| Step: 5
Training loss: 2.380018854146696
Validation loss: 2.6049614351052393

Epoch: 5| Step: 6
Training loss: 3.024424310555369
Validation loss: 2.5424984727912725

Epoch: 5| Step: 7
Training loss: 2.889653883010668
Validation loss: 2.500355044144029

Epoch: 5| Step: 8
Training loss: 2.491347981701909
Validation loss: 2.491944617948177

Epoch: 5| Step: 9
Training loss: 2.9793750361063855
Validation loss: 2.5074943356243526

Epoch: 5| Step: 10
Training loss: 2.7459861766859004
Validation loss: 2.5165279680934565

Epoch: 141| Step: 0
Training loss: 2.768391663933726
Validation loss: 2.5180784701840033

Epoch: 5| Step: 1
Training loss: 2.932191150268247
Validation loss: 2.5195801824530544

Epoch: 5| Step: 2
Training loss: 3.2460533534358382
Validation loss: 2.5209078986634177

Epoch: 5| Step: 3
Training loss: 2.662773737916836
Validation loss: 2.5176219500572077

Epoch: 5| Step: 4
Training loss: 3.0931573165219737
Validation loss: 2.5089713788520114

Epoch: 5| Step: 5
Training loss: 2.753158316264523
Validation loss: 2.5150627476544276

Epoch: 5| Step: 6
Training loss: 3.007856413285364
Validation loss: 2.5177248032626123

Epoch: 5| Step: 7
Training loss: 3.0012360251791272
Validation loss: 2.506760862911219

Epoch: 5| Step: 8
Training loss: 2.7083768596575
Validation loss: 2.5055299489831993

Epoch: 5| Step: 9
Training loss: 2.4355509864264615
Validation loss: 2.508318420456856

Epoch: 5| Step: 10
Training loss: 2.9713678964246957
Validation loss: 2.539127609389944

Epoch: 142| Step: 0
Training loss: 2.8885863667406793
Validation loss: 2.5641447401877078

Epoch: 5| Step: 1
Training loss: 2.148457364077204
Validation loss: 2.572201232829244

Epoch: 5| Step: 2
Training loss: 3.0675800773782465
Validation loss: 2.544388226956215

Epoch: 5| Step: 3
Training loss: 2.488273009761179
Validation loss: 2.556680776318593

Epoch: 5| Step: 4
Training loss: 2.6865407429411277
Validation loss: 2.5352457872772263

Epoch: 5| Step: 5
Training loss: 2.848533212766423
Validation loss: 2.5285588295511046

Epoch: 5| Step: 6
Training loss: 3.084123681988649
Validation loss: 2.532955799126973

Epoch: 5| Step: 7
Training loss: 3.0321914941108203
Validation loss: 2.514659223604073

Epoch: 5| Step: 8
Training loss: 3.1596673273667446
Validation loss: 2.5244879246089567

Epoch: 5| Step: 9
Training loss: 2.7216478009883116
Validation loss: 2.517107498770482

Epoch: 5| Step: 10
Training loss: 2.8800702375218354
Validation loss: 2.515654060115922

Epoch: 143| Step: 0
Training loss: 2.653404686589788
Validation loss: 2.5071544287902334

Epoch: 5| Step: 1
Training loss: 2.7101616092649787
Validation loss: 2.5104128660931413

Epoch: 5| Step: 2
Training loss: 3.004480671620328
Validation loss: 2.5161619464934346

Epoch: 5| Step: 3
Training loss: 2.3565085474122727
Validation loss: 2.5165641905059233

Epoch: 5| Step: 4
Training loss: 2.751299464376021
Validation loss: 2.5317232253477324

Epoch: 5| Step: 5
Training loss: 2.915724702134146
Validation loss: 2.5256479291144087

Epoch: 5| Step: 6
Training loss: 2.8770063282695144
Validation loss: 2.554920045584033

Epoch: 5| Step: 7
Training loss: 2.9462350063403715
Validation loss: 2.5685323168430436

Epoch: 5| Step: 8
Training loss: 3.0402095561832265
Validation loss: 2.5265550834836144

Epoch: 5| Step: 9
Training loss: 3.0483857933050764
Validation loss: 2.505351998150885

Epoch: 5| Step: 10
Training loss: 2.902310562457462
Validation loss: 2.4903068574076106

Epoch: 144| Step: 0
Training loss: 2.502486899357821
Validation loss: 2.476064687678955

Epoch: 5| Step: 1
Training loss: 3.170371465007729
Validation loss: 2.483717031733584

Epoch: 5| Step: 2
Training loss: 3.019262620196255
Validation loss: 2.4815651519868784

Epoch: 5| Step: 3
Training loss: 2.977155491190473
Validation loss: 2.4806426912543444

Epoch: 5| Step: 4
Training loss: 2.9113085622372052
Validation loss: 2.4897778184896304

Epoch: 5| Step: 5
Training loss: 2.7478183415434434
Validation loss: 2.4953335248442157

Epoch: 5| Step: 6
Training loss: 2.75900510769102
Validation loss: 2.488629232486719

Epoch: 5| Step: 7
Training loss: 3.16566076531499
Validation loss: 2.491917302896679

Epoch: 5| Step: 8
Training loss: 2.526096702579149
Validation loss: 2.5248438811755434

Epoch: 5| Step: 9
Training loss: 2.421497635513528
Validation loss: 2.556881892426754

Epoch: 5| Step: 10
Training loss: 2.9208501150508024
Validation loss: 2.595298877894741

Epoch: 145| Step: 0
Training loss: 2.5768726428250366
Validation loss: 2.557324444967355

Epoch: 5| Step: 1
Training loss: 2.4277149300935883
Validation loss: 2.559752501289574

Epoch: 5| Step: 2
Training loss: 2.7296022450977855
Validation loss: 2.5746739184731493

Epoch: 5| Step: 3
Training loss: 2.9297626943475183
Validation loss: 2.524366056505037

Epoch: 5| Step: 4
Training loss: 3.4667868342724315
Validation loss: 2.5145188456729195

Epoch: 5| Step: 5
Training loss: 3.0448858566062444
Validation loss: 2.4897774508986883

Epoch: 5| Step: 6
Training loss: 2.3514731760898044
Validation loss: 2.480177650362304

Epoch: 5| Step: 7
Training loss: 2.743082796972885
Validation loss: 2.475459952118945

Epoch: 5| Step: 8
Training loss: 2.8414819077495235
Validation loss: 2.4837327734460786

Epoch: 5| Step: 9
Training loss: 2.802955709085016
Validation loss: 2.4868134620189863

Epoch: 5| Step: 10
Training loss: 3.3269258586486883
Validation loss: 2.488904950079219

Epoch: 146| Step: 0
Training loss: 2.569275806380173
Validation loss: 2.4821637792710627

Epoch: 5| Step: 1
Training loss: 2.7767941216765144
Validation loss: 2.4787581681064554

Epoch: 5| Step: 2
Training loss: 2.8297588202484545
Validation loss: 2.4874794967267264

Epoch: 5| Step: 3
Training loss: 2.503319348661504
Validation loss: 2.4771430702540487

Epoch: 5| Step: 4
Training loss: 3.1840560858210094
Validation loss: 2.479581267910629

Epoch: 5| Step: 5
Training loss: 2.68707467195528
Validation loss: 2.4949932364200476

Epoch: 5| Step: 6
Training loss: 2.723133280708448
Validation loss: 2.5039274488586485

Epoch: 5| Step: 7
Training loss: 3.149858102175838
Validation loss: 2.5151004324588926

Epoch: 5| Step: 8
Training loss: 2.834344926399079
Validation loss: 2.5443387307723464

Epoch: 5| Step: 9
Training loss: 2.9373738687909907
Validation loss: 2.53787628306499

Epoch: 5| Step: 10
Training loss: 2.8348026579674186
Validation loss: 2.5142987061386495

Epoch: 147| Step: 0
Training loss: 2.6490311308975967
Validation loss: 2.5217315495996613

Epoch: 5| Step: 1
Training loss: 2.739196798423652
Validation loss: 2.4995286938215484

Epoch: 5| Step: 2
Training loss: 2.897296526711805
Validation loss: 2.502694630206166

Epoch: 5| Step: 3
Training loss: 2.7187834112810965
Validation loss: 2.483406269634601

Epoch: 5| Step: 4
Training loss: 2.9481116635876337
Validation loss: 2.485578512611422

Epoch: 5| Step: 5
Training loss: 3.246458912128667
Validation loss: 2.4807417276476724

Epoch: 5| Step: 6
Training loss: 2.753010142741726
Validation loss: 2.4782625409175534

Epoch: 5| Step: 7
Training loss: 2.6416458774875786
Validation loss: 2.4728917097241934

Epoch: 5| Step: 8
Training loss: 2.465880259172307
Validation loss: 2.4787978005348514

Epoch: 5| Step: 9
Training loss: 2.8624847678233167
Validation loss: 2.483416769219023

Epoch: 5| Step: 10
Training loss: 3.0473430567472004
Validation loss: 2.4878007793210317

Epoch: 148| Step: 0
Training loss: 2.12911263961577
Validation loss: 2.4995086863944884

Epoch: 5| Step: 1
Training loss: 2.662471441554539
Validation loss: 2.5144049895532294

Epoch: 5| Step: 2
Training loss: 2.7285528487640724
Validation loss: 2.5094934508003393

Epoch: 5| Step: 3
Training loss: 2.6060631115547164
Validation loss: 2.506535581673636

Epoch: 5| Step: 4
Training loss: 3.303796959325695
Validation loss: 2.5017102298371947

Epoch: 5| Step: 5
Training loss: 3.322477034581986
Validation loss: 2.501697000212228

Epoch: 5| Step: 6
Training loss: 2.5638902196011637
Validation loss: 2.495574333272176

Epoch: 5| Step: 7
Training loss: 2.627363049597613
Validation loss: 2.491495565192471

Epoch: 5| Step: 8
Training loss: 2.787938936169568
Validation loss: 2.4864689438504723

Epoch: 5| Step: 9
Training loss: 3.0739063458046862
Validation loss: 2.496583265022183

Epoch: 5| Step: 10
Training loss: 2.8870669349809934
Validation loss: 2.499144614943628

Epoch: 149| Step: 0
Training loss: 2.549242475599733
Validation loss: 2.519192902140451

Epoch: 5| Step: 1
Training loss: 2.7329587920146357
Validation loss: 2.5483598395144194

Epoch: 5| Step: 2
Training loss: 3.107373384088969
Validation loss: 2.567139068708498

Epoch: 5| Step: 3
Training loss: 3.1551176249345843
Validation loss: 2.582233454485101

Epoch: 5| Step: 4
Training loss: 3.047573068320182
Validation loss: 2.5694493849585904

Epoch: 5| Step: 5
Training loss: 3.039234617404742
Validation loss: 2.5318747331478666

Epoch: 5| Step: 6
Training loss: 2.509463518417543
Validation loss: 2.494290848130898

Epoch: 5| Step: 7
Training loss: 2.488150456941986
Validation loss: 2.4833516000556375

Epoch: 5| Step: 8
Training loss: 2.8179284160827267
Validation loss: 2.4732626008698135

Epoch: 5| Step: 9
Training loss: 2.8251305845343913
Validation loss: 2.480214745788544

Epoch: 5| Step: 10
Training loss: 2.7003793167413845
Validation loss: 2.4845466897552635

Epoch: 150| Step: 0
Training loss: 2.94765373288514
Validation loss: 2.4789977070814686

Epoch: 5| Step: 1
Training loss: 2.7261954773737833
Validation loss: 2.4792158935931963

Epoch: 5| Step: 2
Training loss: 2.0487452691182413
Validation loss: 2.474526152459519

Epoch: 5| Step: 3
Training loss: 2.962860851603456
Validation loss: 2.4758305941758714

Epoch: 5| Step: 4
Training loss: 2.699860558617838
Validation loss: 2.493907284547232

Epoch: 5| Step: 5
Training loss: 2.9932940555988967
Validation loss: 2.4946626930485127

Epoch: 5| Step: 6
Training loss: 2.7041682176237747
Validation loss: 2.4963205620169533

Epoch: 5| Step: 7
Training loss: 2.7955207316421853
Validation loss: 2.502068338737474

Epoch: 5| Step: 8
Training loss: 3.099680139590767
Validation loss: 2.5077068541852854

Epoch: 5| Step: 9
Training loss: 2.731687609359715
Validation loss: 2.5211970745606553

Epoch: 5| Step: 10
Training loss: 3.040647431748577
Validation loss: 2.552279933432952

Testing loss: 2.7401843553942826
