Epoch: 1| Step: 0
Training loss: 5.533491467127464
Validation loss: 5.8227244521206325

Epoch: 5| Step: 1
Training loss: 6.103739683387439
Validation loss: 5.808945746647896

Epoch: 5| Step: 2
Training loss: 4.747402083043518
Validation loss: 5.796793498928017

Epoch: 5| Step: 3
Training loss: 6.4957983668937755
Validation loss: 5.784315670756868

Epoch: 5| Step: 4
Training loss: 6.45283356163175
Validation loss: 5.7703319097900065

Epoch: 5| Step: 5
Training loss: 6.440044307674789
Validation loss: 5.753979276613577

Epoch: 5| Step: 6
Training loss: 5.257047373633135
Validation loss: 5.73578802466151

Epoch: 5| Step: 7
Training loss: 5.799544138916289
Validation loss: 5.7152898963070715

Epoch: 5| Step: 8
Training loss: 4.952615705714629
Validation loss: 5.692345845654858

Epoch: 5| Step: 9
Training loss: 5.771474130172803
Validation loss: 5.665982121205518

Epoch: 5| Step: 10
Training loss: 5.730373888849301
Validation loss: 5.637549493512977

Epoch: 2| Step: 0
Training loss: 6.766972713721547
Validation loss: 5.605559230670319

Epoch: 5| Step: 1
Training loss: 5.792275632316924
Validation loss: 5.57049065511696

Epoch: 5| Step: 2
Training loss: 5.576137840581336
Validation loss: 5.533020681618518

Epoch: 5| Step: 3
Training loss: 4.777643376808478
Validation loss: 5.493012681792559

Epoch: 5| Step: 4
Training loss: 5.739587062642939
Validation loss: 5.451613677293529

Epoch: 5| Step: 5
Training loss: 4.980896121369628
Validation loss: 5.410100584779233

Epoch: 5| Step: 6
Training loss: 4.604649905338344
Validation loss: 5.367489168034763

Epoch: 5| Step: 7
Training loss: 4.8742685013714535
Validation loss: 5.326095732068866

Epoch: 5| Step: 8
Training loss: 5.406000561555021
Validation loss: 5.284957771541968

Epoch: 5| Step: 9
Training loss: 5.962435432900209
Validation loss: 5.240868760356805

Epoch: 5| Step: 10
Training loss: 5.169258862024341
Validation loss: 5.195426758687789

Epoch: 3| Step: 0
Training loss: 6.137238711760115
Validation loss: 5.143833583729385

Epoch: 5| Step: 1
Training loss: 4.22646276670108
Validation loss: 5.090909160543563

Epoch: 5| Step: 2
Training loss: 5.1858574898143015
Validation loss: 5.038012252123204

Epoch: 5| Step: 3
Training loss: 5.340426655273112
Validation loss: 4.983973975052451

Epoch: 5| Step: 4
Training loss: 4.860657157894578
Validation loss: 4.927275607875854

Epoch: 5| Step: 5
Training loss: 4.177574579108513
Validation loss: 4.845540514222581

Epoch: 5| Step: 6
Training loss: 4.161854571916612
Validation loss: 4.776914452419942

Epoch: 5| Step: 7
Training loss: 5.17252366530258
Validation loss: 4.735465761615964

Epoch: 5| Step: 8
Training loss: 5.872269340782434
Validation loss: 4.697655236168998

Epoch: 5| Step: 9
Training loss: 4.460304228666007
Validation loss: 4.641885791060979

Epoch: 5| Step: 10
Training loss: 4.1721950222527875
Validation loss: 4.59320211753334

Epoch: 4| Step: 0
Training loss: 5.352959087270351
Validation loss: 4.555869125993034

Epoch: 5| Step: 1
Training loss: 4.191517738644218
Validation loss: 4.52383298535508

Epoch: 5| Step: 2
Training loss: 3.245722964119774
Validation loss: 4.495939731423275

Epoch: 5| Step: 3
Training loss: 4.153485748490662
Validation loss: 4.476788877220122

Epoch: 5| Step: 4
Training loss: 4.787443251310817
Validation loss: 4.458269171511373

Epoch: 5| Step: 5
Training loss: 5.217312369233253
Validation loss: 4.436659446045944

Epoch: 5| Step: 6
Training loss: 4.411406401501565
Validation loss: 4.42042596899503

Epoch: 5| Step: 7
Training loss: 4.108246739050723
Validation loss: 4.406259932805356

Epoch: 5| Step: 8
Training loss: 5.375598075771775
Validation loss: 4.389693685935786

Epoch: 5| Step: 9
Training loss: 5.195029619589583
Validation loss: 4.371601719819136

Epoch: 5| Step: 10
Training loss: 3.1963262092536664
Validation loss: 4.347030381879942

Epoch: 5| Step: 0
Training loss: 4.139346058378742
Validation loss: 4.325443296934092

Epoch: 5| Step: 1
Training loss: 4.678352483953227
Validation loss: 4.291980605685118

Epoch: 5| Step: 2
Training loss: 4.569262783429424
Validation loss: 4.264925667150667

Epoch: 5| Step: 3
Training loss: 4.170992525754793
Validation loss: 4.268947935289096

Epoch: 5| Step: 4
Training loss: 4.3689921954559585
Validation loss: 4.255008106544256

Epoch: 5| Step: 5
Training loss: 4.884370649827617
Validation loss: 4.231454956482639

Epoch: 5| Step: 6
Training loss: 3.7241274637438146
Validation loss: 4.206379738639108

Epoch: 5| Step: 7
Training loss: 4.325166538097162
Validation loss: 4.197985118341567

Epoch: 5| Step: 8
Training loss: 3.960627617084926
Validation loss: 4.189481978495522

Epoch: 5| Step: 9
Training loss: 4.214049709075763
Validation loss: 4.183472867968241

Epoch: 5| Step: 10
Training loss: 4.902629707172906
Validation loss: 4.158279968099476

Epoch: 6| Step: 0
Training loss: 4.093692691780409
Validation loss: 4.154302404264157

Epoch: 5| Step: 1
Training loss: 4.429146654592803
Validation loss: 4.150961026782718

Epoch: 5| Step: 2
Training loss: 4.393121952843297
Validation loss: 4.147997644859722

Epoch: 5| Step: 3
Training loss: 4.44945838289595
Validation loss: 4.135069247951786

Epoch: 5| Step: 4
Training loss: 4.2782354949436
Validation loss: 4.113331945595948

Epoch: 5| Step: 5
Training loss: 3.8038181196789176
Validation loss: 4.100039724882351

Epoch: 5| Step: 6
Training loss: 4.754639417773128
Validation loss: 4.0838111579454

Epoch: 5| Step: 7
Training loss: 3.7156325665036762
Validation loss: 4.069610020505737

Epoch: 5| Step: 8
Training loss: 4.456084970893426
Validation loss: 4.063906199224614

Epoch: 5| Step: 9
Training loss: 4.073502182236623
Validation loss: 4.043940396884176

Epoch: 5| Step: 10
Training loss: 4.086971349098206
Validation loss: 4.036129490546371

Epoch: 7| Step: 0
Training loss: 3.4372790178881267
Validation loss: 4.018829035305139

Epoch: 5| Step: 1
Training loss: 3.780115509084865
Validation loss: 4.011251177006053

Epoch: 5| Step: 2
Training loss: 4.613849084906863
Validation loss: 4.003561144626883

Epoch: 5| Step: 3
Training loss: 3.8504225957223728
Validation loss: 3.9903148870498173

Epoch: 5| Step: 4
Training loss: 4.298294332346317
Validation loss: 3.9861753812840486

Epoch: 5| Step: 5
Training loss: 4.741618742921309
Validation loss: 3.976504775540425

Epoch: 5| Step: 6
Training loss: 3.629530344864469
Validation loss: 3.9637445962729947

Epoch: 5| Step: 7
Training loss: 3.968395667891613
Validation loss: 3.946702555794932

Epoch: 5| Step: 8
Training loss: 3.8345851650950067
Validation loss: 3.9390813813272767

Epoch: 5| Step: 9
Training loss: 4.2435150036475235
Validation loss: 3.9251881418673413

Epoch: 5| Step: 10
Training loss: 4.828932018794495
Validation loss: 3.918193974042957

Epoch: 8| Step: 0
Training loss: 3.5936457079805884
Validation loss: 3.9109450688250638

Epoch: 5| Step: 1
Training loss: 4.646169926833679
Validation loss: 3.9073018052189368

Epoch: 5| Step: 2
Training loss: 4.171356969095674
Validation loss: 3.8987547062946755

Epoch: 5| Step: 3
Training loss: 4.176333670121957
Validation loss: 3.8857190524370435

Epoch: 5| Step: 4
Training loss: 3.5328659816171037
Validation loss: 3.873892104080633

Epoch: 5| Step: 5
Training loss: 4.087222653933494
Validation loss: 3.8773546451460166

Epoch: 5| Step: 6
Training loss: 4.099463516119532
Validation loss: 3.8596923293794134

Epoch: 5| Step: 7
Training loss: 4.239344534682247
Validation loss: 3.8564688359013455

Epoch: 5| Step: 8
Training loss: 4.165775025650215
Validation loss: 3.8518441947207593

Epoch: 5| Step: 9
Training loss: 3.5052614174952015
Validation loss: 3.8460094748379183

Epoch: 5| Step: 10
Training loss: 4.095006618843738
Validation loss: 3.8378365715416334

Epoch: 9| Step: 0
Training loss: 4.057616834950346
Validation loss: 3.8299370969322677

Epoch: 5| Step: 1
Training loss: 3.948087475519694
Validation loss: 3.820478971751312

Epoch: 5| Step: 2
Training loss: 4.066570179737883
Validation loss: 3.8110899540940673

Epoch: 5| Step: 3
Training loss: 3.3502223040709307
Validation loss: 3.803955355367398

Epoch: 5| Step: 4
Training loss: 4.248415932244583
Validation loss: 3.7958104680258775

Epoch: 5| Step: 5
Training loss: 4.4305091916604455
Validation loss: 3.7855378445846397

Epoch: 5| Step: 6
Training loss: 3.5291741945681103
Validation loss: 3.7824756002555846

Epoch: 5| Step: 7
Training loss: 3.78326639684765
Validation loss: 3.7766216158879975

Epoch: 5| Step: 8
Training loss: 3.805499920279793
Validation loss: 3.7690412937978914

Epoch: 5| Step: 9
Training loss: 3.813438049981586
Validation loss: 3.7677752183843816

Epoch: 5| Step: 10
Training loss: 4.546584287178664
Validation loss: 3.765116535440097

Epoch: 10| Step: 0
Training loss: 4.4881801079226245
Validation loss: 3.7550170999026227

Epoch: 5| Step: 1
Training loss: 3.3347896414646345
Validation loss: 3.750741723925796

Epoch: 5| Step: 2
Training loss: 3.798775154274005
Validation loss: 3.7474622035238982

Epoch: 5| Step: 3
Training loss: 4.478933189280466
Validation loss: 3.7354475909409612

Epoch: 5| Step: 4
Training loss: 3.476703632361814
Validation loss: 3.7335428031557933

Epoch: 5| Step: 5
Training loss: 3.6900322188544754
Validation loss: 3.733115345348712

Epoch: 5| Step: 6
Training loss: 3.0185399963752007
Validation loss: 3.747292182914889

Epoch: 5| Step: 7
Training loss: 3.8672433560123394
Validation loss: 3.730880199717238

Epoch: 5| Step: 8
Training loss: 3.9133008874547834
Validation loss: 3.723347844530817

Epoch: 5| Step: 9
Training loss: 4.293492765092468
Validation loss: 3.7240810524084527

Epoch: 5| Step: 10
Training loss: 4.523175431271229
Validation loss: 3.720723908555568

Epoch: 11| Step: 0
Training loss: 3.845065380279702
Validation loss: 3.7187678384150535

Epoch: 5| Step: 1
Training loss: 3.9699697947854453
Validation loss: 3.7169624500251706

Epoch: 5| Step: 2
Training loss: 4.135524617026506
Validation loss: 3.705759642841796

Epoch: 5| Step: 3
Training loss: 4.203040593657596
Validation loss: 3.695450304875973

Epoch: 5| Step: 4
Training loss: 3.041252229927271
Validation loss: 3.7088608670139562

Epoch: 5| Step: 5
Training loss: 3.1035543430954893
Validation loss: 3.687371278312944

Epoch: 5| Step: 6
Training loss: 3.7586056195493702
Validation loss: 3.681847769300238

Epoch: 5| Step: 7
Training loss: 3.626679524674716
Validation loss: 3.6764597668039114

Epoch: 5| Step: 8
Training loss: 3.801688075314026
Validation loss: 3.67052769253773

Epoch: 5| Step: 9
Training loss: 4.5510327183740324
Validation loss: 3.667702494063322

Epoch: 5| Step: 10
Training loss: 4.4318581834957405
Validation loss: 3.662484799584903

Epoch: 12| Step: 0
Training loss: 3.9115162255497875
Validation loss: 3.6622277604632614

Epoch: 5| Step: 1
Training loss: 3.5613539341347757
Validation loss: 3.657923820568441

Epoch: 5| Step: 2
Training loss: 3.615875995071036
Validation loss: 3.65670739569718

Epoch: 5| Step: 3
Training loss: 3.387864918777864
Validation loss: 3.651305078824615

Epoch: 5| Step: 4
Training loss: 4.381513705731802
Validation loss: 3.6427338792926665

Epoch: 5| Step: 5
Training loss: 3.6613658099288866
Validation loss: 3.6418195272883436

Epoch: 5| Step: 6
Training loss: 4.550228180246521
Validation loss: 3.637385413896591

Epoch: 5| Step: 7
Training loss: 3.894887037487742
Validation loss: 3.63221656621009

Epoch: 5| Step: 8
Training loss: 3.182790530863521
Validation loss: 3.630005912923973

Epoch: 5| Step: 9
Training loss: 3.581739440812941
Validation loss: 3.6238769585120822

Epoch: 5| Step: 10
Training loss: 4.2962062245886585
Validation loss: 3.622321164840204

Epoch: 13| Step: 0
Training loss: 3.4829585870059994
Validation loss: 3.618480388148776

Epoch: 5| Step: 1
Training loss: 3.6295436139269563
Validation loss: 3.6126945071096617

Epoch: 5| Step: 2
Training loss: 3.5973031432984843
Validation loss: 3.6086035038301048

Epoch: 5| Step: 3
Training loss: 4.594559786259898
Validation loss: 3.6064820930985846

Epoch: 5| Step: 4
Training loss: 3.738267984237173
Validation loss: 3.599774681295798

Epoch: 5| Step: 5
Training loss: 3.5629786119699722
Validation loss: 3.596292638646283

Epoch: 5| Step: 6
Training loss: 3.584491779051378
Validation loss: 3.5969182840502687

Epoch: 5| Step: 7
Training loss: 3.571382525010953
Validation loss: 3.593318770307566

Epoch: 5| Step: 8
Training loss: 3.930590425358377
Validation loss: 3.5851542336141193

Epoch: 5| Step: 9
Training loss: 4.029967347952279
Validation loss: 3.5835593529801537

Epoch: 5| Step: 10
Training loss: 3.9454646619404166
Validation loss: 3.5809767563167907

Epoch: 14| Step: 0
Training loss: 3.6444655695615684
Validation loss: 3.575887089564025

Epoch: 5| Step: 1
Training loss: 3.450407451950082
Validation loss: 3.5710878772226824

Epoch: 5| Step: 2
Training loss: 4.575443250519091
Validation loss: 3.5678149782317807

Epoch: 5| Step: 3
Training loss: 4.438241386268125
Validation loss: 3.56630392161066

Epoch: 5| Step: 4
Training loss: 2.99270920152095
Validation loss: 3.564437489033499

Epoch: 5| Step: 5
Training loss: 4.160058363358361
Validation loss: 3.561869007151884

Epoch: 5| Step: 6
Training loss: 3.8542436471760415
Validation loss: 3.559947003097635

Epoch: 5| Step: 7
Training loss: 4.071313072421106
Validation loss: 3.557655803129943

Epoch: 5| Step: 8
Training loss: 3.34470959735661
Validation loss: 3.5526071624781954

Epoch: 5| Step: 9
Training loss: 2.8395325963802143
Validation loss: 3.55101645610847

Epoch: 5| Step: 10
Training loss: 3.702412210746352
Validation loss: 3.551999352946468

Epoch: 15| Step: 0
Training loss: 4.230842045510858
Validation loss: 3.5434642570564696

Epoch: 5| Step: 1
Training loss: 3.24629322820825
Validation loss: 3.5390735642255846

Epoch: 5| Step: 2
Training loss: 3.810338517616965
Validation loss: 3.5363429603433985

Epoch: 5| Step: 3
Training loss: 3.3866783412471806
Validation loss: 3.5317292624634398

Epoch: 5| Step: 4
Training loss: 3.3735778072662987
Validation loss: 3.529831613319958

Epoch: 5| Step: 5
Training loss: 3.3375014630146604
Validation loss: 3.5269540247501263

Epoch: 5| Step: 6
Training loss: 4.091165440166589
Validation loss: 3.5229733414690676

Epoch: 5| Step: 7
Training loss: 4.1764476162358495
Validation loss: 3.51742424685013

Epoch: 5| Step: 8
Training loss: 3.4983312170692598
Validation loss: 3.512905742934352

Epoch: 5| Step: 9
Training loss: 4.064844716614699
Validation loss: 3.5157260587653565

Epoch: 5| Step: 10
Training loss: 3.7051742613631373
Validation loss: 3.5062128013240446

Epoch: 16| Step: 0
Training loss: 3.652760201441288
Validation loss: 3.5097483371231215

Epoch: 5| Step: 1
Training loss: 3.585980450408291
Validation loss: 3.5019112875075273

Epoch: 5| Step: 2
Training loss: 3.4449529135798396
Validation loss: 3.4897611934839134

Epoch: 5| Step: 3
Training loss: 3.587360972192792
Validation loss: 3.484685169513441

Epoch: 5| Step: 4
Training loss: 3.493814725054523
Validation loss: 3.4789016742578154

Epoch: 5| Step: 5
Training loss: 3.9010900979119114
Validation loss: 3.4963218212639506

Epoch: 5| Step: 6
Training loss: 4.557993923757335
Validation loss: 3.465958652912517

Epoch: 5| Step: 7
Training loss: 3.0136107996687103
Validation loss: 3.4670753845254416

Epoch: 5| Step: 8
Training loss: 3.070287340366858
Validation loss: 3.471473335038801

Epoch: 5| Step: 9
Training loss: 4.12082483941962
Validation loss: 3.4745657045613663

Epoch: 5| Step: 10
Training loss: 4.018652817187358
Validation loss: 3.468810258611899

Epoch: 17| Step: 0
Training loss: 3.3301356872774286
Validation loss: 3.549101465690915

Epoch: 5| Step: 1
Training loss: 4.12124555407612
Validation loss: 3.5537994519554816

Epoch: 5| Step: 2
Training loss: 3.1812452394940745
Validation loss: 3.5500068767318664

Epoch: 5| Step: 3
Training loss: 3.158850174807264
Validation loss: 3.5475662379691233

Epoch: 5| Step: 4
Training loss: 3.9269191933621816
Validation loss: 3.542737575720193

Epoch: 5| Step: 5
Training loss: 3.3766294713684624
Validation loss: 3.5373614625970036

Epoch: 5| Step: 6
Training loss: 4.238528983615223
Validation loss: 3.534573890455531

Epoch: 5| Step: 7
Training loss: 3.822582108967362
Validation loss: 3.5318195429298695

Epoch: 5| Step: 8
Training loss: 4.517028379326244
Validation loss: 3.5274286076079133

Epoch: 5| Step: 9
Training loss: 3.675858694430249
Validation loss: 3.5241283986014107

Epoch: 5| Step: 10
Training loss: 3.5770182001356328
Validation loss: 3.52008659529654

Epoch: 18| Step: 0
Training loss: 3.5604046465181796
Validation loss: 3.5167866009935684

Epoch: 5| Step: 1
Training loss: 2.820169291994765
Validation loss: 3.5155487482513474

Epoch: 5| Step: 2
Training loss: 4.38317564957468
Validation loss: 3.513514498563242

Epoch: 5| Step: 3
Training loss: 4.0758810483367185
Validation loss: 3.5113705066784973

Epoch: 5| Step: 4
Training loss: 4.279902113748804
Validation loss: 3.5080875822654294

Epoch: 5| Step: 5
Training loss: 3.4667023809745183
Validation loss: 3.504458835022827

Epoch: 5| Step: 6
Training loss: 3.929610568254779
Validation loss: 3.5019200401133523

Epoch: 5| Step: 7
Training loss: 4.140412638274783
Validation loss: 3.497037908642414

Epoch: 5| Step: 8
Training loss: 3.281535108986157
Validation loss: 3.4951636568457785

Epoch: 5| Step: 9
Training loss: 3.1671236277360975
Validation loss: 3.492833871653574

Epoch: 5| Step: 10
Training loss: 3.413266715527177
Validation loss: 3.491006914495441

Epoch: 19| Step: 0
Training loss: 4.189931818150156
Validation loss: 3.4892999280814627

Epoch: 5| Step: 1
Training loss: 3.2114367317383055
Validation loss: 3.4875974222466923

Epoch: 5| Step: 2
Training loss: 3.246349779078428
Validation loss: 3.484203700633562

Epoch: 5| Step: 3
Training loss: 4.8868549672511525
Validation loss: 3.481356821490421

Epoch: 5| Step: 4
Training loss: 2.835152341325409
Validation loss: 3.477175549512558

Epoch: 5| Step: 5
Training loss: 3.8531947517114546
Validation loss: 3.4632530258053604

Epoch: 5| Step: 6
Training loss: 3.866545282848296
Validation loss: 3.438979803410507

Epoch: 5| Step: 7
Training loss: 3.0262691830291395
Validation loss: 3.43105932591634

Epoch: 5| Step: 8
Training loss: 3.3447287009573454
Validation loss: 3.417426561799382

Epoch: 5| Step: 9
Training loss: 4.304201849873345
Validation loss: 3.4105761743469545

Epoch: 5| Step: 10
Training loss: 3.0096860920908024
Validation loss: 3.4080919996008086

Epoch: 20| Step: 0
Training loss: 3.8523173801476553
Validation loss: 3.4067397964498323

Epoch: 5| Step: 1
Training loss: 3.594273006694855
Validation loss: 3.4058049567804205

Epoch: 5| Step: 2
Training loss: 3.637979618713766
Validation loss: 3.4037225623935354

Epoch: 5| Step: 3
Training loss: 3.817055528867955
Validation loss: 3.40351223210499

Epoch: 5| Step: 4
Training loss: 2.819073772232393
Validation loss: 3.399421700440748

Epoch: 5| Step: 5
Training loss: 3.925106222088173
Validation loss: 3.395943563939433

Epoch: 5| Step: 6
Training loss: 3.6098290360141
Validation loss: 3.395322282723426

Epoch: 5| Step: 7
Training loss: 3.620423947373542
Validation loss: 3.3939264861091014

Epoch: 5| Step: 8
Training loss: 3.5740358399663217
Validation loss: 3.3911978038027044

Epoch: 5| Step: 9
Training loss: 3.89902040943597
Validation loss: 3.3896756314390277

Epoch: 5| Step: 10
Training loss: 3.385234996127138
Validation loss: 3.3882834186532027

Epoch: 21| Step: 0
Training loss: 3.488946900287028
Validation loss: 3.385829731594688

Epoch: 5| Step: 1
Training loss: 2.974772237826513
Validation loss: 3.3838043376855604

Epoch: 5| Step: 2
Training loss: 2.6082461536532313
Validation loss: 3.3813198407272473

Epoch: 5| Step: 3
Training loss: 3.706563777410385
Validation loss: 3.3798559599813354

Epoch: 5| Step: 4
Training loss: 3.7526819175626724
Validation loss: 3.377290008806509

Epoch: 5| Step: 5
Training loss: 3.864911390228926
Validation loss: 3.3735849702405525

Epoch: 5| Step: 6
Training loss: 2.790026842623966
Validation loss: 3.369220560037213

Epoch: 5| Step: 7
Training loss: 4.120321684195301
Validation loss: 3.3683531956356147

Epoch: 5| Step: 8
Training loss: 3.9108998204243877
Validation loss: 3.3664810988671956

Epoch: 5| Step: 9
Training loss: 3.726418162495635
Validation loss: 3.3658752389206006

Epoch: 5| Step: 10
Training loss: 4.421931074346312
Validation loss: 3.3634029811977135

Epoch: 22| Step: 0
Training loss: 3.856782482609573
Validation loss: 3.3612431331577755

Epoch: 5| Step: 1
Training loss: 3.34822453379198
Validation loss: 3.3622126582043594

Epoch: 5| Step: 2
Training loss: 3.2029852115552915
Validation loss: 3.3591574779465647

Epoch: 5| Step: 3
Training loss: 3.6854053302343988
Validation loss: 3.357506572633361

Epoch: 5| Step: 4
Training loss: 3.734703145313984
Validation loss: 3.3637561218696463

Epoch: 5| Step: 5
Training loss: 3.82139113475354
Validation loss: 3.3551868168094794

Epoch: 5| Step: 6
Training loss: 3.4071738014061275
Validation loss: 3.3541568829080317

Epoch: 5| Step: 7
Training loss: 2.8446380570037384
Validation loss: 3.352669177463665

Epoch: 5| Step: 8
Training loss: 3.8917514135593767
Validation loss: 3.350525860324304

Epoch: 5| Step: 9
Training loss: 3.2951505227794127
Validation loss: 3.351259270198618

Epoch: 5| Step: 10
Training loss: 4.301852807371952
Validation loss: 3.350468994209297

Epoch: 23| Step: 0
Training loss: 3.2164966880939025
Validation loss: 3.3511661542157687

Epoch: 5| Step: 1
Training loss: 2.892063422197497
Validation loss: 3.371377063078817

Epoch: 5| Step: 2
Training loss: 3.3138983312193213
Validation loss: 3.347919268024193

Epoch: 5| Step: 3
Training loss: 3.5865793090117974
Validation loss: 3.3547827317227203

Epoch: 5| Step: 4
Training loss: 4.080466347390041
Validation loss: 3.3677772492972116

Epoch: 5| Step: 5
Training loss: 3.6105236521148103
Validation loss: 3.369442647314831

Epoch: 5| Step: 6
Training loss: 3.3868817880847217
Validation loss: 3.3523873973094664

Epoch: 5| Step: 7
Training loss: 4.771218141364974
Validation loss: 3.3440294031133164

Epoch: 5| Step: 8
Training loss: 4.010781539898554
Validation loss: 3.3407466611838093

Epoch: 5| Step: 9
Training loss: 3.0325525375809197
Validation loss: 3.33878457085119

Epoch: 5| Step: 10
Training loss: 3.0471313368733015
Validation loss: 3.3383520328225584

Epoch: 24| Step: 0
Training loss: 3.69327726227468
Validation loss: 3.339839852160545

Epoch: 5| Step: 1
Training loss: 3.033988266411097
Validation loss: 3.3400672425718825

Epoch: 5| Step: 2
Training loss: 2.7445772631377165
Validation loss: 3.344878274608487

Epoch: 5| Step: 3
Training loss: 3.551401619177048
Validation loss: 3.3540225881149706

Epoch: 5| Step: 4
Training loss: 4.091668218442749
Validation loss: 3.3566619334269134

Epoch: 5| Step: 5
Training loss: 3.9614282789284774
Validation loss: 3.342460074536996

Epoch: 5| Step: 6
Training loss: 3.252945079097105
Validation loss: 3.3359818263129015

Epoch: 5| Step: 7
Training loss: 4.10342266226208
Validation loss: 3.329985700097003

Epoch: 5| Step: 8
Training loss: 3.5275680115846075
Validation loss: 3.3298551168238153

Epoch: 5| Step: 9
Training loss: 3.621751316121138
Validation loss: 3.3285501668683346

Epoch: 5| Step: 10
Training loss: 3.492194463735716
Validation loss: 3.3267546836891144

Epoch: 25| Step: 0
Training loss: 3.416042007161203
Validation loss: 3.326394374825562

Epoch: 5| Step: 1
Training loss: 4.334897028174146
Validation loss: 3.325638668808799

Epoch: 5| Step: 2
Training loss: 3.4844937838847754
Validation loss: 3.325751832386402

Epoch: 5| Step: 3
Training loss: 3.035541131987715
Validation loss: 3.324180923920926

Epoch: 5| Step: 4
Training loss: 3.5469048452592076
Validation loss: 3.3229857288525544

Epoch: 5| Step: 5
Training loss: 3.8811307830438198
Validation loss: 3.3210308674603364

Epoch: 5| Step: 6
Training loss: 2.716977561136364
Validation loss: 3.3193986366399484

Epoch: 5| Step: 7
Training loss: 2.8368863286617683
Validation loss: 3.318209998187457

Epoch: 5| Step: 8
Training loss: 3.6871010516032627
Validation loss: 3.316932410666158

Epoch: 5| Step: 9
Training loss: 4.424572879845848
Validation loss: 3.315934075746001

Epoch: 5| Step: 10
Training loss: 3.381117891843963
Validation loss: 3.315944027431405

Epoch: 26| Step: 0
Training loss: 4.606717859987556
Validation loss: 3.313958326658604

Epoch: 5| Step: 1
Training loss: 4.027407922242737
Validation loss: 3.3141330223584275

Epoch: 5| Step: 2
Training loss: 3.826389339667769
Validation loss: 3.3139574896355506

Epoch: 5| Step: 3
Training loss: 3.1934870423161135
Validation loss: 3.3198035860777075

Epoch: 5| Step: 4
Training loss: 3.003503184566267
Validation loss: 3.3111293957692145

Epoch: 5| Step: 5
Training loss: 3.0618649816962367
Validation loss: 3.311266236139988

Epoch: 5| Step: 6
Training loss: 2.8470252322977125
Validation loss: 3.3079384623887242

Epoch: 5| Step: 7
Training loss: 3.7961555709876573
Validation loss: 3.3118713255975094

Epoch: 5| Step: 8
Training loss: 3.19114327251883
Validation loss: 3.307701250713562

Epoch: 5| Step: 9
Training loss: 3.44209301750047
Validation loss: 3.3043178178096184

Epoch: 5| Step: 10
Training loss: 3.7110942606692525
Validation loss: 3.3043118608612776

Epoch: 27| Step: 0
Training loss: 3.8319183861835553
Validation loss: 3.302262720807319

Epoch: 5| Step: 1
Training loss: 3.9961220301189564
Validation loss: 3.3012632904031847

Epoch: 5| Step: 2
Training loss: 2.4510232462409003
Validation loss: 3.300211709497609

Epoch: 5| Step: 3
Training loss: 3.2279983539978896
Validation loss: 3.298037360392384

Epoch: 5| Step: 4
Training loss: 3.4478795874562045
Validation loss: 3.297650584489506

Epoch: 5| Step: 5
Training loss: 3.8165694234084473
Validation loss: 3.2950572745559343

Epoch: 5| Step: 6
Training loss: 2.9763622466881854
Validation loss: 3.2938265699557303

Epoch: 5| Step: 7
Training loss: 3.0235598832627377
Validation loss: 3.290691509068824

Epoch: 5| Step: 8
Training loss: 3.8218030147682134
Validation loss: 3.290752912315489

Epoch: 5| Step: 9
Training loss: 3.777766112390596
Validation loss: 3.289726229521312

Epoch: 5| Step: 10
Training loss: 4.285806500487293
Validation loss: 3.2874902315905854

Epoch: 28| Step: 0
Training loss: 3.2896213373876324
Validation loss: 3.286643561070859

Epoch: 5| Step: 1
Training loss: 4.004555254184099
Validation loss: 3.286019815212603

Epoch: 5| Step: 2
Training loss: 3.7083834241134315
Validation loss: 3.285004370687062

Epoch: 5| Step: 3
Training loss: 3.6513605273324523
Validation loss: 3.2834132207339484

Epoch: 5| Step: 4
Training loss: 3.346519535396956
Validation loss: 3.2822286338904694

Epoch: 5| Step: 5
Training loss: 3.1396813944129507
Validation loss: 3.282699940430811

Epoch: 5| Step: 6
Training loss: 3.4758928318337943
Validation loss: 3.279090735763247

Epoch: 5| Step: 7
Training loss: 3.9451906695298407
Validation loss: 3.2789186413700637

Epoch: 5| Step: 8
Training loss: 3.100495661825545
Validation loss: 3.278093676109149

Epoch: 5| Step: 9
Training loss: 3.6114782505386587
Validation loss: 3.277172300767656

Epoch: 5| Step: 10
Training loss: 3.3844238390441053
Validation loss: 3.276335508493769

Epoch: 29| Step: 0
Training loss: 3.817868939291901
Validation loss: 3.276549042825342

Epoch: 5| Step: 1
Training loss: 2.9836050907867406
Validation loss: 3.2737770046456345

Epoch: 5| Step: 2
Training loss: 3.570715549682327
Validation loss: 3.2733918631095826

Epoch: 5| Step: 3
Training loss: 3.7138900415086984
Validation loss: 3.274038528414935

Epoch: 5| Step: 4
Training loss: 4.0237889997400105
Validation loss: 3.2727318536520857

Epoch: 5| Step: 5
Training loss: 2.9850774607360258
Validation loss: 3.273257859021583

Epoch: 5| Step: 6
Training loss: 3.608374254612808
Validation loss: 3.2767464854993116

Epoch: 5| Step: 7
Training loss: 4.115711041523607
Validation loss: 3.285536440354135

Epoch: 5| Step: 8
Training loss: 2.8651445058758873
Validation loss: 3.2711979746571864

Epoch: 5| Step: 9
Training loss: 2.9406361173283804
Validation loss: 3.2685875572304512

Epoch: 5| Step: 10
Training loss: 3.8211322053242815
Validation loss: 3.267553489439248

Epoch: 30| Step: 0
Training loss: 3.316898089311079
Validation loss: 3.2676250795505934

Epoch: 5| Step: 1
Training loss: 3.2462199309391924
Validation loss: 3.265908053696027

Epoch: 5| Step: 2
Training loss: 4.104742535823702
Validation loss: 3.2676200787755607

Epoch: 5| Step: 3
Training loss: 3.7763067042851675
Validation loss: 3.2660198786422656

Epoch: 5| Step: 4
Training loss: 4.099272984501623
Validation loss: 3.2643173479967866

Epoch: 5| Step: 5
Training loss: 3.539084866013073
Validation loss: 3.2624231401347235

Epoch: 5| Step: 6
Training loss: 3.2930185624198063
Validation loss: 3.260520356009133

Epoch: 5| Step: 7
Training loss: 3.071582948727429
Validation loss: 3.259757452207859

Epoch: 5| Step: 8
Training loss: 3.2526888361657025
Validation loss: 3.2595943365447337

Epoch: 5| Step: 9
Training loss: 3.539685866001143
Validation loss: 3.2586194928459125

Epoch: 5| Step: 10
Training loss: 3.160046399898539
Validation loss: 3.2581812333983153

Epoch: 31| Step: 0
Training loss: 3.6231720360372304
Validation loss: 3.2585256539659886

Epoch: 5| Step: 1
Training loss: 2.542526370711651
Validation loss: 3.2584091170996388

Epoch: 5| Step: 2
Training loss: 3.25845045251596
Validation loss: 3.2623585695910977

Epoch: 5| Step: 3
Training loss: 3.6538094746528573
Validation loss: 3.2775652359822884

Epoch: 5| Step: 4
Training loss: 4.632118932261164
Validation loss: 3.2605746960640425

Epoch: 5| Step: 5
Training loss: 3.7218566227866776
Validation loss: 3.2547305870019088

Epoch: 5| Step: 6
Training loss: 3.443083926828543
Validation loss: 3.253498923227877

Epoch: 5| Step: 7
Training loss: 2.736487221296108
Validation loss: 3.2538195190287045

Epoch: 5| Step: 8
Training loss: 3.62804837141838
Validation loss: 3.2756016929782428

Epoch: 5| Step: 9
Training loss: 3.5227699747042434
Validation loss: 3.2629348956612283

Epoch: 5| Step: 10
Training loss: 3.5252279059140634
Validation loss: 3.460521126566508

Epoch: 32| Step: 0
Training loss: 3.814963873495934
Validation loss: 3.5130371530250266

Epoch: 5| Step: 1
Training loss: 2.8942375085539216
Validation loss: 3.336045951643295

Epoch: 5| Step: 2
Training loss: 3.6665898372808314
Validation loss: 3.2642568666351632

Epoch: 5| Step: 3
Training loss: 4.159366901713684
Validation loss: 3.270166250037251

Epoch: 5| Step: 4
Training loss: 3.9881572648073256
Validation loss: 3.3987117345043782

Epoch: 5| Step: 5
Training loss: 3.936496425073222
Validation loss: 3.429525489221898

Epoch: 5| Step: 6
Training loss: 3.205435463874062
Validation loss: 3.4487512332721213

Epoch: 5| Step: 7
Training loss: 3.499639901301524
Validation loss: 3.4392349503696664

Epoch: 5| Step: 8
Training loss: 3.813678871874343
Validation loss: 3.4329096172664397

Epoch: 5| Step: 9
Training loss: 3.246014278462725
Validation loss: 3.4322543768288916

Epoch: 5| Step: 10
Training loss: 3.2836389473621033
Validation loss: 3.3801954167944017

Epoch: 33| Step: 0
Training loss: 2.9941173734216227
Validation loss: 3.3611513478527186

Epoch: 5| Step: 1
Training loss: 4.08346547023261
Validation loss: 3.28418604784738

Epoch: 5| Step: 2
Training loss: 3.588152697797969
Validation loss: 3.2508083439426683

Epoch: 5| Step: 3
Training loss: 3.671207708232715
Validation loss: 3.2536917945968993

Epoch: 5| Step: 4
Training loss: 3.2274671122369765
Validation loss: 3.251859238807261

Epoch: 5| Step: 5
Training loss: 2.943533848563519
Validation loss: 3.261426242865132

Epoch: 5| Step: 6
Training loss: 3.832329259205732
Validation loss: 3.2714870283776953

Epoch: 5| Step: 7
Training loss: 3.4319849335488706
Validation loss: 3.2650575265953403

Epoch: 5| Step: 8
Training loss: 3.2942158610264274
Validation loss: 3.250350090840746

Epoch: 5| Step: 9
Training loss: 3.479618538086217
Validation loss: 3.2460607062007765

Epoch: 5| Step: 10
Training loss: 3.9479918191780583
Validation loss: 3.245056331695498

Epoch: 34| Step: 0
Training loss: 3.483020194061644
Validation loss: 3.2452264165089324

Epoch: 5| Step: 1
Training loss: 2.526207504858811
Validation loss: 3.2445613452972455

Epoch: 5| Step: 2
Training loss: 4.157205572202999
Validation loss: 3.240572735002284

Epoch: 5| Step: 3
Training loss: 3.267920750304915
Validation loss: 3.237018640040392

Epoch: 5| Step: 4
Training loss: 3.110028528898332
Validation loss: 3.250778461554302

Epoch: 5| Step: 5
Training loss: 3.5329456140611706
Validation loss: 3.230842956025713

Epoch: 5| Step: 6
Training loss: 4.149330287347115
Validation loss: 3.2262601656394296

Epoch: 5| Step: 7
Training loss: 3.4651719618452836
Validation loss: 3.2295868286989573

Epoch: 5| Step: 8
Training loss: 3.514100553816231
Validation loss: 3.2330911743784565

Epoch: 5| Step: 9
Training loss: 2.843166417197366
Validation loss: 3.235480490307639

Epoch: 5| Step: 10
Training loss: 3.980075326331335
Validation loss: 3.2417047652479942

Epoch: 35| Step: 0
Training loss: 3.090519769649474
Validation loss: 3.2359150648130335

Epoch: 5| Step: 1
Training loss: 3.0328767481763754
Validation loss: 3.2286782336261854

Epoch: 5| Step: 2
Training loss: 3.052548803740695
Validation loss: 3.219092625128601

Epoch: 5| Step: 3
Training loss: 4.009952561247705
Validation loss: 3.2188649032095777

Epoch: 5| Step: 4
Training loss: 3.8083900436308085
Validation loss: 3.216199060565643

Epoch: 5| Step: 5
Training loss: 3.8617006777233023
Validation loss: 3.2142991330201514

Epoch: 5| Step: 6
Training loss: 4.0624293394545985
Validation loss: 3.212564050268869

Epoch: 5| Step: 7
Training loss: 3.141186564329057
Validation loss: 3.2121042869651193

Epoch: 5| Step: 8
Training loss: 3.2025399022590686
Validation loss: 3.2134419140524426

Epoch: 5| Step: 9
Training loss: 2.5674683392289603
Validation loss: 3.211487679456872

Epoch: 5| Step: 10
Training loss: 4.025573282109492
Validation loss: 3.2112176605901666

Epoch: 36| Step: 0
Training loss: 3.7085627938475905
Validation loss: 3.209834240094677

Epoch: 5| Step: 1
Training loss: 2.9118927351195967
Validation loss: 3.2086440278056236

Epoch: 5| Step: 2
Training loss: 3.936862106726052
Validation loss: 3.208738184554159

Epoch: 5| Step: 3
Training loss: 3.1844879579584413
Validation loss: 3.206084225501706

Epoch: 5| Step: 4
Training loss: 3.6804013217943137
Validation loss: 3.205209527882669

Epoch: 5| Step: 5
Training loss: 3.18612042660078
Validation loss: 3.204097934789394

Epoch: 5| Step: 6
Training loss: 2.8325078734164726
Validation loss: 3.2057621210459564

Epoch: 5| Step: 7
Training loss: 3.2968421681292504
Validation loss: 3.209029555373266

Epoch: 5| Step: 8
Training loss: 3.9749422800923684
Validation loss: 3.2115771884468547

Epoch: 5| Step: 9
Training loss: 3.2403830045214117
Validation loss: 3.2032579684026956

Epoch: 5| Step: 10
Training loss: 3.929584479071753
Validation loss: 3.1992558186640654

Epoch: 37| Step: 0
Training loss: 4.175197007333765
Validation loss: 3.197730027113114

Epoch: 5| Step: 1
Training loss: 2.7961000189293896
Validation loss: 3.19772150576441

Epoch: 5| Step: 2
Training loss: 2.868267967931912
Validation loss: 3.197546702870519

Epoch: 5| Step: 3
Training loss: 3.854192427815441
Validation loss: 3.1967369106140944

Epoch: 5| Step: 4
Training loss: 3.342280269867228
Validation loss: 3.198195478406197

Epoch: 5| Step: 5
Training loss: 3.6093055090882196
Validation loss: 3.196160151558625

Epoch: 5| Step: 6
Training loss: 3.4012714364842385
Validation loss: 3.1957725323920965

Epoch: 5| Step: 7
Training loss: 3.6512107356492867
Validation loss: 3.1966269790746242

Epoch: 5| Step: 8
Training loss: 3.1650452394551727
Validation loss: 3.194895846155753

Epoch: 5| Step: 9
Training loss: 2.9810134569930953
Validation loss: 3.194609567643709

Epoch: 5| Step: 10
Training loss: 3.882145354217115
Validation loss: 3.1945836712025737

Epoch: 38| Step: 0
Training loss: 3.14454550414083
Validation loss: 3.1920207147229642

Epoch: 5| Step: 1
Training loss: 3.002958428470184
Validation loss: 3.190475318652405

Epoch: 5| Step: 2
Training loss: 3.844617296080367
Validation loss: 3.192617218789641

Epoch: 5| Step: 3
Training loss: 3.1148305601324386
Validation loss: 3.1927237063744083

Epoch: 5| Step: 4
Training loss: 3.2489870400162952
Validation loss: 3.1896436119839167

Epoch: 5| Step: 5
Training loss: 3.366121835970827
Validation loss: 3.1918448012572354

Epoch: 5| Step: 6
Training loss: 3.6039304416984903
Validation loss: 3.1921883562312625

Epoch: 5| Step: 7
Training loss: 3.0560866173756973
Validation loss: 3.192906686879437

Epoch: 5| Step: 8
Training loss: 4.049227586722221
Validation loss: 3.189005189726453

Epoch: 5| Step: 9
Training loss: 3.589444575152716
Validation loss: 3.187725933383197

Epoch: 5| Step: 10
Training loss: 3.6682271815575405
Validation loss: 3.189152992926382

Epoch: 39| Step: 0
Training loss: 3.3693793789950646
Validation loss: 3.1892244024520644

Epoch: 5| Step: 1
Training loss: 4.087827868829687
Validation loss: 3.18254657702739

Epoch: 5| Step: 2
Training loss: 2.997770911820698
Validation loss: 3.182198191482116

Epoch: 5| Step: 3
Training loss: 3.753311094169613
Validation loss: 3.1823766360123473

Epoch: 5| Step: 4
Training loss: 3.274408819989093
Validation loss: 3.184415758724997

Epoch: 5| Step: 5
Training loss: 3.6444185981635173
Validation loss: 3.18192407653289

Epoch: 5| Step: 6
Training loss: 2.7075415896728807
Validation loss: 3.1835975379702384

Epoch: 5| Step: 7
Training loss: 3.3925553553316203
Validation loss: 3.1807167911053873

Epoch: 5| Step: 8
Training loss: 3.4962170456610804
Validation loss: 3.182771698931354

Epoch: 5| Step: 9
Training loss: 3.5594364847527844
Validation loss: 3.1825623186796133

Epoch: 5| Step: 10
Training loss: 3.300267792442161
Validation loss: 3.176103851587048

Epoch: 40| Step: 0
Training loss: 3.136335337615477
Validation loss: 3.1813050595859274

Epoch: 5| Step: 1
Training loss: 3.6020680898090482
Validation loss: 3.1983090792876996

Epoch: 5| Step: 2
Training loss: 3.6410891519437345
Validation loss: 3.200717637452563

Epoch: 5| Step: 3
Training loss: 3.0031521449613794
Validation loss: 3.1912630385700256

Epoch: 5| Step: 4
Training loss: 3.1107219289892547
Validation loss: 3.181811006572822

Epoch: 5| Step: 5
Training loss: 3.382100724185002
Validation loss: 3.175959452900013

Epoch: 5| Step: 6
Training loss: 3.3149520147886853
Validation loss: 3.173142930650897

Epoch: 5| Step: 7
Training loss: 3.626026534381616
Validation loss: 3.1734006316212504

Epoch: 5| Step: 8
Training loss: 3.276910146189726
Validation loss: 3.1685321723040087

Epoch: 5| Step: 9
Training loss: 3.8668043775261216
Validation loss: 3.166052258918574

Epoch: 5| Step: 10
Training loss: 3.7082874995338777
Validation loss: 3.1657855184754773

Epoch: 41| Step: 0
Training loss: 3.78618986427708
Validation loss: 3.1656444666752814

Epoch: 5| Step: 1
Training loss: 3.445411870998216
Validation loss: 3.1644277516011337

Epoch: 5| Step: 2
Training loss: 3.430967192121354
Validation loss: 3.161335642190315

Epoch: 5| Step: 3
Training loss: 3.1677659954094404
Validation loss: 3.1610758173746794

Epoch: 5| Step: 4
Training loss: 3.4637073601500767
Validation loss: 3.161115763865234

Epoch: 5| Step: 5
Training loss: 3.0163867363919774
Validation loss: 3.1599967759431236

Epoch: 5| Step: 6
Training loss: 3.695342436784128
Validation loss: 3.1595042000263165

Epoch: 5| Step: 7
Training loss: 3.6809541178576834
Validation loss: 3.158323148258116

Epoch: 5| Step: 8
Training loss: 3.306631684220783
Validation loss: 3.158234629294216

Epoch: 5| Step: 9
Training loss: 3.1172466989503254
Validation loss: 3.157522780909651

Epoch: 5| Step: 10
Training loss: 3.419087149612526
Validation loss: 3.155057658536175

Epoch: 42| Step: 0
Training loss: 3.1023467871546138
Validation loss: 3.1541895704483207

Epoch: 5| Step: 1
Training loss: 3.413249671948872
Validation loss: 3.1552327979149895

Epoch: 5| Step: 2
Training loss: 3.9638661048363266
Validation loss: 3.1545955740924994

Epoch: 5| Step: 3
Training loss: 3.1574642753845357
Validation loss: 3.155042952167854

Epoch: 5| Step: 4
Training loss: 2.596190717495089
Validation loss: 3.152433025592682

Epoch: 5| Step: 5
Training loss: 2.993091576151244
Validation loss: 3.151041105564074

Epoch: 5| Step: 6
Training loss: 4.166431318630049
Validation loss: 3.1519925808753393

Epoch: 5| Step: 7
Training loss: 3.2121324380860585
Validation loss: 3.1529291975596667

Epoch: 5| Step: 8
Training loss: 4.0274948254581036
Validation loss: 3.149566342983258

Epoch: 5| Step: 9
Training loss: 3.239389558906966
Validation loss: 3.149774989803002

Epoch: 5| Step: 10
Training loss: 3.2827345623222475
Validation loss: 3.1505048462192176

Epoch: 43| Step: 0
Training loss: 3.8292082830304626
Validation loss: 3.1493103581091195

Epoch: 5| Step: 1
Training loss: 2.7130394957241015
Validation loss: 3.147268255021697

Epoch: 5| Step: 2
Training loss: 3.665154723353185
Validation loss: 3.1462834250896465

Epoch: 5| Step: 3
Training loss: 2.552776496849066
Validation loss: 3.146059853761474

Epoch: 5| Step: 4
Training loss: 3.2956773652709805
Validation loss: 3.1460345852493

Epoch: 5| Step: 5
Training loss: 3.7220704457351603
Validation loss: 3.145181035867767

Epoch: 5| Step: 6
Training loss: 3.9416716744281555
Validation loss: 3.1443911558482416

Epoch: 5| Step: 7
Training loss: 3.1663526747449118
Validation loss: 3.1430746341038596

Epoch: 5| Step: 8
Training loss: 2.9312051733042113
Validation loss: 3.1426457178625893

Epoch: 5| Step: 9
Training loss: 3.0353493254729225
Validation loss: 3.1422051756464224

Epoch: 5| Step: 10
Training loss: 4.268132740705841
Validation loss: 3.140933536774746

Epoch: 44| Step: 0
Training loss: 2.403643000894836
Validation loss: 3.139193629107421

Epoch: 5| Step: 1
Training loss: 4.172116619071174
Validation loss: 3.1409222976338036

Epoch: 5| Step: 2
Training loss: 2.9156162732025415
Validation loss: 3.140908760006577

Epoch: 5| Step: 3
Training loss: 2.496943130804969
Validation loss: 3.1377514201644328

Epoch: 5| Step: 4
Training loss: 3.4844157810989334
Validation loss: 3.1371547460478446

Epoch: 5| Step: 5
Training loss: 4.2388410488599355
Validation loss: 3.1366940036891133

Epoch: 5| Step: 6
Training loss: 4.041834693378569
Validation loss: 3.1350646002051943

Epoch: 5| Step: 7
Training loss: 3.1775511517072874
Validation loss: 3.1354971960408236

Epoch: 5| Step: 8
Training loss: 3.2812081470545076
Validation loss: 3.1343164396560836

Epoch: 5| Step: 9
Training loss: 3.064833861137421
Validation loss: 3.1341621495552774

Epoch: 5| Step: 10
Training loss: 3.49701836149802
Validation loss: 3.1323741873912314

Epoch: 45| Step: 0
Training loss: 3.0155721867339405
Validation loss: 3.1335440459666573

Epoch: 5| Step: 1
Training loss: 3.842516817590944
Validation loss: 3.1303479282252153

Epoch: 5| Step: 2
Training loss: 2.550277216185435
Validation loss: 3.1320237750396225

Epoch: 5| Step: 3
Training loss: 3.3795358765796326
Validation loss: 3.128551670817296

Epoch: 5| Step: 4
Training loss: 3.5911688781987356
Validation loss: 3.131635825690165

Epoch: 5| Step: 5
Training loss: 3.6259244858063466
Validation loss: 3.126597706079536

Epoch: 5| Step: 6
Training loss: 3.2521048845501195
Validation loss: 3.1267774682873606

Epoch: 5| Step: 7
Training loss: 3.3103096395916114
Validation loss: 3.1266006636226127

Epoch: 5| Step: 8
Training loss: 3.7112528134955602
Validation loss: 3.1252386793643336

Epoch: 5| Step: 9
Training loss: 3.4659793545327653
Validation loss: 3.1250216313095422

Epoch: 5| Step: 10
Training loss: 3.3043834645621235
Validation loss: 3.12440811294497

Epoch: 46| Step: 0
Training loss: 3.978233960405746
Validation loss: 3.123083788026101

Epoch: 5| Step: 1
Training loss: 2.914659699718156
Validation loss: 3.121444197647199

Epoch: 5| Step: 2
Training loss: 2.905226332338714
Validation loss: 3.119735807390253

Epoch: 5| Step: 3
Training loss: 4.306014117907437
Validation loss: 3.1197876856340905

Epoch: 5| Step: 4
Training loss: 2.3750905471406134
Validation loss: 3.120354952108942

Epoch: 5| Step: 5
Training loss: 3.4896258147581336
Validation loss: 3.121422023302573

Epoch: 5| Step: 6
Training loss: 3.7183396569823337
Validation loss: 3.125751053991971

Epoch: 5| Step: 7
Training loss: 2.550716942623528
Validation loss: 3.1307099153608404

Epoch: 5| Step: 8
Training loss: 3.2476955460076775
Validation loss: 3.1240583449001114

Epoch: 5| Step: 9
Training loss: 3.0115857521704044
Validation loss: 3.11867013540861

Epoch: 5| Step: 10
Training loss: 4.156154315965676
Validation loss: 3.1164436432505696

Epoch: 47| Step: 0
Training loss: 3.2815818982068192
Validation loss: 3.114100583275725

Epoch: 5| Step: 1
Training loss: 3.1594942245853193
Validation loss: 3.1148170868833622

Epoch: 5| Step: 2
Training loss: 3.6738296825156187
Validation loss: 3.1137274570600577

Epoch: 5| Step: 3
Training loss: 3.268222779448855
Validation loss: 3.112673928796592

Epoch: 5| Step: 4
Training loss: 2.408906535361212
Validation loss: 3.112929920443587

Epoch: 5| Step: 5
Training loss: 3.712616165347386
Validation loss: 3.1114596508826438

Epoch: 5| Step: 6
Training loss: 3.0926174055801607
Validation loss: 3.1108560022331546

Epoch: 5| Step: 7
Training loss: 3.550513195499492
Validation loss: 3.110326687182141

Epoch: 5| Step: 8
Training loss: 3.265011816543764
Validation loss: 3.1096841179555117

Epoch: 5| Step: 9
Training loss: 3.6595436324463084
Validation loss: 3.108945379383748

Epoch: 5| Step: 10
Training loss: 3.849368571235651
Validation loss: 3.1075631762818223

Epoch: 48| Step: 0
Training loss: 3.3148855580272123
Validation loss: 3.107147626891524

Epoch: 5| Step: 1
Training loss: 3.8870173507314956
Validation loss: 3.1063825356065697

Epoch: 5| Step: 2
Training loss: 4.251235782248443
Validation loss: 3.1052605837103195

Epoch: 5| Step: 3
Training loss: 3.4524233005851612
Validation loss: 3.1035431883156694

Epoch: 5| Step: 4
Training loss: 2.681839237512535
Validation loss: 3.10469703963715

Epoch: 5| Step: 5
Training loss: 3.3182176870685285
Validation loss: 3.104009946566994

Epoch: 5| Step: 6
Training loss: 2.864814295850087
Validation loss: 3.103861290318881

Epoch: 5| Step: 7
Training loss: 3.3843733994470475
Validation loss: 3.1025149657273134

Epoch: 5| Step: 8
Training loss: 3.3389073180079545
Validation loss: 3.1021445251493023

Epoch: 5| Step: 9
Training loss: 3.3024391119034413
Validation loss: 3.101027033569114

Epoch: 5| Step: 10
Training loss: 2.8602310316765376
Validation loss: 3.0998089938245323

Epoch: 49| Step: 0
Training loss: 3.5519538177117025
Validation loss: 3.0993305851687856

Epoch: 5| Step: 1
Training loss: 2.808053974176281
Validation loss: 3.100838948311334

Epoch: 5| Step: 2
Training loss: 4.054730777105267
Validation loss: 3.0976784711564544

Epoch: 5| Step: 3
Training loss: 3.6159168755336513
Validation loss: 3.09788156762286

Epoch: 5| Step: 4
Training loss: 3.62937676178929
Validation loss: 3.095891304076755

Epoch: 5| Step: 5
Training loss: 3.3449962824642583
Validation loss: 3.096088823450653

Epoch: 5| Step: 6
Training loss: 2.783125941226919
Validation loss: 3.0946398586711377

Epoch: 5| Step: 7
Training loss: 2.9966542342638474
Validation loss: 3.0951610946351686

Epoch: 5| Step: 8
Training loss: 3.264417215067388
Validation loss: 3.09439936096218

Epoch: 5| Step: 9
Training loss: 3.1544073788209506
Validation loss: 3.093242425051722

Epoch: 5| Step: 10
Training loss: 3.5209084376764848
Validation loss: 3.093343133524553

Epoch: 50| Step: 0
Training loss: 2.768999013617475
Validation loss: 3.092282285683616

Epoch: 5| Step: 1
Training loss: 2.604400003787864
Validation loss: 3.0916127329685636

Epoch: 5| Step: 2
Training loss: 3.5118386457129476
Validation loss: 3.0905660845897995

Epoch: 5| Step: 3
Training loss: 3.3390628370214355
Validation loss: 3.0915139873530575

Epoch: 5| Step: 4
Training loss: 3.6026747303930584
Validation loss: 3.08870374219066

Epoch: 5| Step: 5
Training loss: 3.4406160969493405
Validation loss: 3.0920212465853765

Epoch: 5| Step: 6
Training loss: 3.6025607697062196
Validation loss: 3.0904990498886504

Epoch: 5| Step: 7
Training loss: 3.1151835565996095
Validation loss: 3.0875663822924824

Epoch: 5| Step: 8
Training loss: 3.3306694512560493
Validation loss: 3.087294210924459

Epoch: 5| Step: 9
Training loss: 3.90153035191501
Validation loss: 3.0838462371948405

Epoch: 5| Step: 10
Training loss: 3.448288097524311
Validation loss: 3.0857804594506706

Epoch: 51| Step: 0
Training loss: 3.7269002893291314
Validation loss: 3.0845511879596073

Epoch: 5| Step: 1
Training loss: 3.0443398908620156
Validation loss: 3.084147775326413

Epoch: 5| Step: 2
Training loss: 3.0642800899203753
Validation loss: 3.0832449183360415

Epoch: 5| Step: 3
Training loss: 3.12273110993581
Validation loss: 3.081098941440765

Epoch: 5| Step: 4
Training loss: 3.3805071792199057
Validation loss: 3.082211086229871

Epoch: 5| Step: 5
Training loss: 2.985041199468512
Validation loss: 3.081243011547223

Epoch: 5| Step: 6
Training loss: 3.1883413662953006
Validation loss: 3.0790533899155053

Epoch: 5| Step: 7
Training loss: 3.2734836766302275
Validation loss: 3.0791492747462663

Epoch: 5| Step: 8
Training loss: 3.4766135222730687
Validation loss: 3.0780717132921516

Epoch: 5| Step: 9
Training loss: 3.6830324168004718
Validation loss: 3.078069422892503

Epoch: 5| Step: 10
Training loss: 3.7872550507454568
Validation loss: 3.0750039985764803

Epoch: 52| Step: 0
Training loss: 3.3308349465321814
Validation loss: 3.0760829955278037

Epoch: 5| Step: 1
Training loss: 4.016134623091091
Validation loss: 3.0740247341215627

Epoch: 5| Step: 2
Training loss: 3.1696605750956865
Validation loss: 3.0720457463769484

Epoch: 5| Step: 3
Training loss: 3.5486240191804477
Validation loss: 3.0749137222027474

Epoch: 5| Step: 4
Training loss: 3.0221654300714165
Validation loss: 3.0741089029356106

Epoch: 5| Step: 5
Training loss: 3.254410172329724
Validation loss: 3.075487530918491

Epoch: 5| Step: 6
Training loss: 2.9826162858214373
Validation loss: 3.0758155532265095

Epoch: 5| Step: 7
Training loss: 2.8528718633426817
Validation loss: 3.0731497187991765

Epoch: 5| Step: 8
Training loss: 3.641553637556728
Validation loss: 3.071708766051464

Epoch: 5| Step: 9
Training loss: 3.2043179407279476
Validation loss: 3.0673714726893

Epoch: 5| Step: 10
Training loss: 3.5368382620163166
Validation loss: 3.0680518573350173

Epoch: 53| Step: 0
Training loss: 3.7630070493593064
Validation loss: 3.068672165120517

Epoch: 5| Step: 1
Training loss: 4.027913213330939
Validation loss: 3.070621088689532

Epoch: 5| Step: 2
Training loss: 3.1252418424485975
Validation loss: 3.0680943519248505

Epoch: 5| Step: 3
Training loss: 3.801984198684405
Validation loss: 3.065984682578172

Epoch: 5| Step: 4
Training loss: 3.1893528059946514
Validation loss: 3.064844912555065

Epoch: 5| Step: 5
Training loss: 2.5346797736342563
Validation loss: 3.0650903136884504

Epoch: 5| Step: 6
Training loss: 2.931482848331792
Validation loss: 3.0640272125052714

Epoch: 5| Step: 7
Training loss: 3.2740632326315158
Validation loss: 3.0635981295515275

Epoch: 5| Step: 8
Training loss: 3.4206100285664394
Validation loss: 3.0618014958990867

Epoch: 5| Step: 9
Training loss: 2.876281121129949
Validation loss: 3.059677720457322

Epoch: 5| Step: 10
Training loss: 3.426511784503065
Validation loss: 3.060074925711455

Epoch: 54| Step: 0
Training loss: 3.609542776724891
Validation loss: 3.059525133804228

Epoch: 5| Step: 1
Training loss: 2.6294010144563758
Validation loss: 3.0588437174699408

Epoch: 5| Step: 2
Training loss: 3.4611677175035833
Validation loss: 3.0565067267567336

Epoch: 5| Step: 3
Training loss: 3.494044277511092
Validation loss: 3.0571614978243398

Epoch: 5| Step: 4
Training loss: 3.2638232357555474
Validation loss: 3.055804232685667

Epoch: 5| Step: 5
Training loss: 2.8806018158171502
Validation loss: 3.0555092718273973

Epoch: 5| Step: 6
Training loss: 3.579322314773039
Validation loss: 3.055195951385132

Epoch: 5| Step: 7
Training loss: 3.5137850545452975
Validation loss: 3.055044595972813

Epoch: 5| Step: 8
Training loss: 3.045765836274835
Validation loss: 3.0537821436175263

Epoch: 5| Step: 9
Training loss: 3.1417802043066048
Validation loss: 3.0515197168544597

Epoch: 5| Step: 10
Training loss: 3.8109978389929053
Validation loss: 3.0527283151051927

Epoch: 55| Step: 0
Training loss: 3.2130510562624
Validation loss: 3.0532396352000486

Epoch: 5| Step: 1
Training loss: 3.1892889649846485
Validation loss: 3.0570177578612037

Epoch: 5| Step: 2
Training loss: 3.6616497107350363
Validation loss: 3.060517613534617

Epoch: 5| Step: 3
Training loss: 2.993996971949369
Validation loss: 3.05829024808576

Epoch: 5| Step: 4
Training loss: 3.459361662662368
Validation loss: 3.052800804632412

Epoch: 5| Step: 5
Training loss: 3.035700882954222
Validation loss: 3.04735072996822

Epoch: 5| Step: 6
Training loss: 2.811894160822466
Validation loss: 3.0454374520665337

Epoch: 5| Step: 7
Training loss: 3.4742407428996662
Validation loss: 3.043198152055791

Epoch: 5| Step: 8
Training loss: 3.583849063990329
Validation loss: 3.0429835826685987

Epoch: 5| Step: 9
Training loss: 3.763411128341262
Validation loss: 3.0435841721398322

Epoch: 5| Step: 10
Training loss: 3.1365887720676797
Validation loss: 3.040180903436094

Epoch: 56| Step: 0
Training loss: 3.0605407987435695
Validation loss: 3.0410526030570093

Epoch: 5| Step: 1
Training loss: 4.225083633588267
Validation loss: 3.040712818628374

Epoch: 5| Step: 2
Training loss: 3.488254320610989
Validation loss: 3.0416493861344875

Epoch: 5| Step: 3
Training loss: 2.9455990436915016
Validation loss: 3.039140484710306

Epoch: 5| Step: 4
Training loss: 3.1126754343619214
Validation loss: 3.0397583800377252

Epoch: 5| Step: 5
Training loss: 3.4572999321790006
Validation loss: 3.0385965112929285

Epoch: 5| Step: 6
Training loss: 3.1407192842365723
Validation loss: 3.0370181612814418

Epoch: 5| Step: 7
Training loss: 2.8187353738544885
Validation loss: 3.036693055595074

Epoch: 5| Step: 8
Training loss: 2.894127121279993
Validation loss: 3.0349816240034566

Epoch: 5| Step: 9
Training loss: 3.216161335072501
Validation loss: 3.0345030061426774

Epoch: 5| Step: 10
Training loss: 3.868471984241179
Validation loss: 3.0347924785691927

Epoch: 57| Step: 0
Training loss: 3.090081091251926
Validation loss: 3.033917407769597

Epoch: 5| Step: 1
Training loss: 3.7371557887358975
Validation loss: 3.0397417757263385

Epoch: 5| Step: 2
Training loss: 3.676547449991442
Validation loss: 3.044753142239561

Epoch: 5| Step: 3
Training loss: 2.8313748565831425
Validation loss: 3.0396151370369155

Epoch: 5| Step: 4
Training loss: 3.301151918444145
Validation loss: 3.0410649177359925

Epoch: 5| Step: 5
Training loss: 3.7915003533969993
Validation loss: 3.0428962823682895

Epoch: 5| Step: 6
Training loss: 2.805571945276847
Validation loss: 3.02790871896776

Epoch: 5| Step: 7
Training loss: 3.3520288387505603
Validation loss: 3.0279517269777774

Epoch: 5| Step: 8
Training loss: 3.3011332848978765
Validation loss: 3.027723369527875

Epoch: 5| Step: 9
Training loss: 3.069148884194452
Validation loss: 3.030454317429421

Epoch: 5| Step: 10
Training loss: 3.2328862251441146
Validation loss: 3.042979111645184

Epoch: 58| Step: 0
Training loss: 3.2562278351422935
Validation loss: 3.0382246750100608

Epoch: 5| Step: 1
Training loss: 2.9528036598689305
Validation loss: 3.028276005164149

Epoch: 5| Step: 2
Training loss: 3.5919758273460416
Validation loss: 3.027395001314025

Epoch: 5| Step: 3
Training loss: 3.3935021353844594
Validation loss: 3.025762072792061

Epoch: 5| Step: 4
Training loss: 3.366854126750286
Validation loss: 3.026594989972869

Epoch: 5| Step: 5
Training loss: 3.4593028046363674
Validation loss: 3.033714921968554

Epoch: 5| Step: 6
Training loss: 3.596009845902624
Validation loss: 3.0479188404144613

Epoch: 5| Step: 7
Training loss: 3.287311296160029
Validation loss: 3.021678095837699

Epoch: 5| Step: 8
Training loss: 2.8887289891454846
Validation loss: 3.0223152749101594

Epoch: 5| Step: 9
Training loss: 3.0257137118680815
Validation loss: 3.0216437848435183

Epoch: 5| Step: 10
Training loss: 3.4275848269104157
Validation loss: 3.0227703216770747

Epoch: 59| Step: 0
Training loss: 3.7871008130705177
Validation loss: 3.024203071989425

Epoch: 5| Step: 1
Training loss: 3.0982399158509133
Validation loss: 3.030275339329145

Epoch: 5| Step: 2
Training loss: 3.5347923133627526
Validation loss: 3.0329070903206725

Epoch: 5| Step: 3
Training loss: 2.7221575900166495
Validation loss: 3.034730373610753

Epoch: 5| Step: 4
Training loss: 3.0844611777157995
Validation loss: 3.0233046072760077

Epoch: 5| Step: 5
Training loss: 3.5058841290038347
Validation loss: 3.025717562774143

Epoch: 5| Step: 6
Training loss: 3.0068595664770656
Validation loss: 3.0238571416319453

Epoch: 5| Step: 7
Training loss: 3.8371342736342866
Validation loss: 3.0269394488228283

Epoch: 5| Step: 8
Training loss: 3.440830212812856
Validation loss: 3.0253641884766203

Epoch: 5| Step: 9
Training loss: 2.7691547692091425
Validation loss: 3.019381705536883

Epoch: 5| Step: 10
Training loss: 3.2983519513679513
Validation loss: 3.0202453437073786

Epoch: 60| Step: 0
Training loss: 3.32118583413344
Validation loss: 3.0185520139210427

Epoch: 5| Step: 1
Training loss: 3.713939215668542
Validation loss: 3.018926276651597

Epoch: 5| Step: 2
Training loss: 3.0935876977135828
Validation loss: 3.0191065762872005

Epoch: 5| Step: 3
Training loss: 2.956112596734149
Validation loss: 3.015842583553631

Epoch: 5| Step: 4
Training loss: 3.0240927289339057
Validation loss: 3.0161086280224265

Epoch: 5| Step: 5
Training loss: 3.495191677223821
Validation loss: 3.014832963220449

Epoch: 5| Step: 6
Training loss: 3.4069684871988635
Validation loss: 3.0125085836608294

Epoch: 5| Step: 7
Training loss: 2.870561739878384
Validation loss: 3.011698395515695

Epoch: 5| Step: 8
Training loss: 3.4597522781423007
Validation loss: 3.007798438271727

Epoch: 5| Step: 9
Training loss: 3.012326348709238
Validation loss: 3.0095620679380826

Epoch: 5| Step: 10
Training loss: 3.7231370709453944
Validation loss: 3.009069701258812

Epoch: 61| Step: 0
Training loss: 3.6007659097362534
Validation loss: 3.0062666680651198

Epoch: 5| Step: 1
Training loss: 3.1940036322107845
Validation loss: 3.0058347155477465

Epoch: 5| Step: 2
Training loss: 3.7960638741846333
Validation loss: 3.0043944403738756

Epoch: 5| Step: 3
Training loss: 3.1028146210155216
Validation loss: 3.003785043479349

Epoch: 5| Step: 4
Training loss: 3.265863583259106
Validation loss: 3.0034515119019525

Epoch: 5| Step: 5
Training loss: 3.251883327892109
Validation loss: 3.0050753095546168

Epoch: 5| Step: 6
Training loss: 2.398740867291231
Validation loss: 3.001539546295883

Epoch: 5| Step: 7
Training loss: 3.3615799166207005
Validation loss: 3.0010363248413827

Epoch: 5| Step: 8
Training loss: 3.414306352579202
Validation loss: 3.0000568900644757

Epoch: 5| Step: 9
Training loss: 3.512776352406507
Validation loss: 2.9978324569489887

Epoch: 5| Step: 10
Training loss: 2.896099453414434
Validation loss: 2.9983481470603595

Epoch: 62| Step: 0
Training loss: 3.1652763393105534
Validation loss: 2.997343485178656

Epoch: 5| Step: 1
Training loss: 3.1017374522641856
Validation loss: 2.997581645450248

Epoch: 5| Step: 2
Training loss: 3.087167847099038
Validation loss: 2.9960333363002163

Epoch: 5| Step: 3
Training loss: 3.3927522657433364
Validation loss: 2.994498986079859

Epoch: 5| Step: 4
Training loss: 3.157508674664032
Validation loss: 2.993871950203071

Epoch: 5| Step: 5
Training loss: 3.9249218052163775
Validation loss: 2.9956051687919123

Epoch: 5| Step: 6
Training loss: 3.241534725795798
Validation loss: 2.993863873608116

Epoch: 5| Step: 7
Training loss: 3.3668871256594204
Validation loss: 2.995169906093134

Epoch: 5| Step: 8
Training loss: 2.7655139620629714
Validation loss: 2.994273202467757

Epoch: 5| Step: 9
Training loss: 2.799141333252347
Validation loss: 2.9913279158874557

Epoch: 5| Step: 10
Training loss: 3.8591791636089527
Validation loss: 2.9910884425783557

Epoch: 63| Step: 0
Training loss: 3.5302158968339707
Validation loss: 2.9895681614015777

Epoch: 5| Step: 1
Training loss: 3.3493085631600628
Validation loss: 2.9893695134130325

Epoch: 5| Step: 2
Training loss: 3.482915050696214
Validation loss: 2.988569537020862

Epoch: 5| Step: 3
Training loss: 3.3555263030297806
Validation loss: 2.986280916242536

Epoch: 5| Step: 4
Training loss: 3.175810528722276
Validation loss: 2.986286936705499

Epoch: 5| Step: 5
Training loss: 2.841628068976913
Validation loss: 2.985977262444899

Epoch: 5| Step: 6
Training loss: 3.7294664883982986
Validation loss: 2.984624469872357

Epoch: 5| Step: 7
Training loss: 3.2006588257646755
Validation loss: 2.9856258881111866

Epoch: 5| Step: 8
Training loss: 3.2911012542179763
Validation loss: 2.985246143440592

Epoch: 5| Step: 9
Training loss: 2.649017360528125
Validation loss: 2.9825898363247996

Epoch: 5| Step: 10
Training loss: 3.1181467822199695
Validation loss: 2.9839636286089517

Epoch: 64| Step: 0
Training loss: 3.206539511297531
Validation loss: 2.982011630329332

Epoch: 5| Step: 1
Training loss: 3.625387236860016
Validation loss: 2.9816326153206556

Epoch: 5| Step: 2
Training loss: 3.339533919748003
Validation loss: 2.979591821758503

Epoch: 5| Step: 3
Training loss: 1.7468130520395235
Validation loss: 2.982106453065737

Epoch: 5| Step: 4
Training loss: 3.1089227242030186
Validation loss: 2.9847604744990615

Epoch: 5| Step: 5
Training loss: 3.003757349101334
Validation loss: 2.983751534785332

Epoch: 5| Step: 6
Training loss: 3.8225599047979673
Validation loss: 2.986126701375969

Epoch: 5| Step: 7
Training loss: 3.1183608674288674
Validation loss: 2.9861536672742157

Epoch: 5| Step: 8
Training loss: 3.9300084371694606
Validation loss: 2.984503307482484

Epoch: 5| Step: 9
Training loss: 3.347667645108961
Validation loss: 2.9814520804901603

Epoch: 5| Step: 10
Training loss: 3.037990665444052
Validation loss: 2.9809928808103914

Epoch: 65| Step: 0
Training loss: 3.9123600895152455
Validation loss: 2.9735902491265187

Epoch: 5| Step: 1
Training loss: 2.557415640027912
Validation loss: 2.971300305369444

Epoch: 5| Step: 2
Training loss: 3.5035151132546454
Validation loss: 2.9711852106744683

Epoch: 5| Step: 3
Training loss: 2.8749723018472997
Validation loss: 2.970612628678058

Epoch: 5| Step: 4
Training loss: 3.4932987911273488
Validation loss: 2.970362590469219

Epoch: 5| Step: 5
Training loss: 2.9575327116704195
Validation loss: 2.969118397884156

Epoch: 5| Step: 6
Training loss: 3.616700504220863
Validation loss: 2.9687738751162205

Epoch: 5| Step: 7
Training loss: 3.044684772178965
Validation loss: 2.967551598624727

Epoch: 5| Step: 8
Training loss: 3.6867826378248685
Validation loss: 2.9668687854128533

Epoch: 5| Step: 9
Training loss: 2.8444016936023417
Validation loss: 2.965843025259475

Epoch: 5| Step: 10
Training loss: 2.880211460509623
Validation loss: 2.9653850991105943

Epoch: 66| Step: 0
Training loss: 2.4928081062606227
Validation loss: 2.964912394408915

Epoch: 5| Step: 1
Training loss: 3.2652873909666003
Validation loss: 2.966124669425293

Epoch: 5| Step: 2
Training loss: 2.719248758803773
Validation loss: 2.9652581793788

Epoch: 5| Step: 3
Training loss: 2.9091980451124386
Validation loss: 2.9648932698012

Epoch: 5| Step: 4
Training loss: 3.826113799249778
Validation loss: 2.9675071493804723

Epoch: 5| Step: 5
Training loss: 2.6983353180747445
Validation loss: 2.9653430899603554

Epoch: 5| Step: 6
Training loss: 3.7885638665943917
Validation loss: 2.9632830668191863

Epoch: 5| Step: 7
Training loss: 4.0173286356813565
Validation loss: 2.962227994492057

Epoch: 5| Step: 8
Training loss: 3.483916111309526
Validation loss: 2.9600701843927353

Epoch: 5| Step: 9
Training loss: 2.868294068384888
Validation loss: 2.9600124114784347

Epoch: 5| Step: 10
Training loss: 3.156923127865787
Validation loss: 2.95908287520921

Epoch: 67| Step: 0
Training loss: 3.934028912048685
Validation loss: 2.957989958876949

Epoch: 5| Step: 1
Training loss: 3.4694062033273827
Validation loss: 2.956138722902882

Epoch: 5| Step: 2
Training loss: 3.1558455406364523
Validation loss: 2.95745721004964

Epoch: 5| Step: 3
Training loss: 3.0710338104384256
Validation loss: 2.955967576949724

Epoch: 5| Step: 4
Training loss: 2.6578740260265006
Validation loss: 2.954558922484308

Epoch: 5| Step: 5
Training loss: 2.9088526731172495
Validation loss: 2.9569144537258527

Epoch: 5| Step: 6
Training loss: 3.2506633961791227
Validation loss: 2.9542726056854427

Epoch: 5| Step: 7
Training loss: 3.3235531060934527
Validation loss: 2.9515990020128284

Epoch: 5| Step: 8
Training loss: 2.827791647470065
Validation loss: 2.9522078266612284

Epoch: 5| Step: 9
Training loss: 3.3837739842286707
Validation loss: 2.950269108256335

Epoch: 5| Step: 10
Training loss: 3.435932981341532
Validation loss: 2.9492436142348497

Epoch: 68| Step: 0
Training loss: 2.6557780126964996
Validation loss: 2.9494923945540483

Epoch: 5| Step: 1
Training loss: 3.1776221313535644
Validation loss: 2.9495607860809145

Epoch: 5| Step: 2
Training loss: 3.5431341534313128
Validation loss: 2.9491174167739134

Epoch: 5| Step: 3
Training loss: 2.8961527988947506
Validation loss: 2.9457400258027966

Epoch: 5| Step: 4
Training loss: 3.456394218760846
Validation loss: 2.946866977845892

Epoch: 5| Step: 5
Training loss: 3.7127298303227976
Validation loss: 2.9467746724717796

Epoch: 5| Step: 6
Training loss: 3.3362402320738833
Validation loss: 2.9446975511251643

Epoch: 5| Step: 7
Training loss: 2.983459332183362
Validation loss: 2.9441229855735784

Epoch: 5| Step: 8
Training loss: 3.1889624139311867
Validation loss: 2.9440329958115297

Epoch: 5| Step: 9
Training loss: 3.482358614207379
Validation loss: 2.9425907379765364

Epoch: 5| Step: 10
Training loss: 2.8848509159277027
Validation loss: 2.9412896168417726

Epoch: 69| Step: 0
Training loss: 3.282456094603626
Validation loss: 2.94238656074613

Epoch: 5| Step: 1
Training loss: 3.0371762578045547
Validation loss: 2.943587520607255

Epoch: 5| Step: 2
Training loss: 3.521577399067712
Validation loss: 2.9467282168119704

Epoch: 5| Step: 3
Training loss: 3.123392683569251
Validation loss: 2.944877296635512

Epoch: 5| Step: 4
Training loss: 2.7831225145946945
Validation loss: 2.9548595408813068

Epoch: 5| Step: 5
Training loss: 3.6724484259695536
Validation loss: 2.956444428575952

Epoch: 5| Step: 6
Training loss: 3.0654740198192063
Validation loss: 2.9443680453499956

Epoch: 5| Step: 7
Training loss: 3.6735310168189352
Validation loss: 2.9389640425480907

Epoch: 5| Step: 8
Training loss: 2.2926765528661064
Validation loss: 2.9386603289838216

Epoch: 5| Step: 9
Training loss: 3.311503278377891
Validation loss: 2.936540071956137

Epoch: 5| Step: 10
Training loss: 3.573095126278211
Validation loss: 2.9385353887069927

Epoch: 70| Step: 0
Training loss: 3.154744913033159
Validation loss: 2.93729489897073

Epoch: 5| Step: 1
Training loss: 3.0638781191038174
Validation loss: 2.9369409605636947

Epoch: 5| Step: 2
Training loss: 3.3733434497043264
Validation loss: 2.9349266026102296

Epoch: 5| Step: 3
Training loss: 2.628921032618867
Validation loss: 2.934228540276495

Epoch: 5| Step: 4
Training loss: 3.0595199722059583
Validation loss: 2.932679450439297

Epoch: 5| Step: 5
Training loss: 3.6045304190179857
Validation loss: 2.9339370449116022

Epoch: 5| Step: 6
Training loss: 4.031851317040921
Validation loss: 2.9367781777482107

Epoch: 5| Step: 7
Training loss: 3.2743049874186685
Validation loss: 2.937127050612569

Epoch: 5| Step: 8
Training loss: 3.2044435345928695
Validation loss: 2.936127603231633

Epoch: 5| Step: 9
Training loss: 2.6613822274172865
Validation loss: 2.9315997396032505

Epoch: 5| Step: 10
Training loss: 3.1502503129111155
Validation loss: 2.9296556609143

Epoch: 71| Step: 0
Training loss: 2.7418810029199996
Validation loss: 2.9278374263545004

Epoch: 5| Step: 1
Training loss: 3.1002266647165704
Validation loss: 2.927910655241495

Epoch: 5| Step: 2
Training loss: 2.9069639580024034
Validation loss: 2.928007849043689

Epoch: 5| Step: 3
Training loss: 3.5979514068239857
Validation loss: 2.9258321038641246

Epoch: 5| Step: 4
Training loss: 2.6490616414612234
Validation loss: 2.9274316436772705

Epoch: 5| Step: 5
Training loss: 3.1106776283660746
Validation loss: 2.9312350705783285

Epoch: 5| Step: 6
Training loss: 2.6248254263820923
Validation loss: 2.932166916075747

Epoch: 5| Step: 7
Training loss: 4.059688593004144
Validation loss: 2.929751992667722

Epoch: 5| Step: 8
Training loss: 3.7198618020259673
Validation loss: 2.9306372123580346

Epoch: 5| Step: 9
Training loss: 3.406765959972929
Validation loss: 2.9268607659770587

Epoch: 5| Step: 10
Training loss: 3.0709008970725695
Validation loss: 2.9216691434275863

Epoch: 72| Step: 0
Training loss: 3.011406670814144
Validation loss: 2.9215359827006897

Epoch: 5| Step: 1
Training loss: 3.368276185525038
Validation loss: 2.922158146448448

Epoch: 5| Step: 2
Training loss: 2.854797534878599
Validation loss: 2.919850548577379

Epoch: 5| Step: 3
Training loss: 3.097413947116213
Validation loss: 2.919568472636014

Epoch: 5| Step: 4
Training loss: 3.520465959572648
Validation loss: 2.918677715778309

Epoch: 5| Step: 5
Training loss: 3.587587728989467
Validation loss: 2.920664650393763

Epoch: 5| Step: 6
Training loss: 3.2951017555651916
Validation loss: 2.9201737582252614

Epoch: 5| Step: 7
Training loss: 2.6708021184929147
Validation loss: 2.9177082475537883

Epoch: 5| Step: 8
Training loss: 3.5092202401282235
Validation loss: 2.9208819377765556

Epoch: 5| Step: 9
Training loss: 2.9434528500522914
Validation loss: 2.918299188809863

Epoch: 5| Step: 10
Training loss: 3.272231870060248
Validation loss: 2.918070817874848

Epoch: 73| Step: 0
Training loss: 3.7823673835697122
Validation loss: 2.9158537656246732

Epoch: 5| Step: 1
Training loss: 2.972725545348704
Validation loss: 2.9157655129524267

Epoch: 5| Step: 2
Training loss: 3.1593983876676694
Validation loss: 2.915049589536633

Epoch: 5| Step: 3
Training loss: 3.0508320470823027
Validation loss: 2.917667251273499

Epoch: 5| Step: 4
Training loss: 2.060267887844646
Validation loss: 2.9177539755897626

Epoch: 5| Step: 5
Training loss: 3.5826374235768648
Validation loss: 2.9221222414097823

Epoch: 5| Step: 6
Training loss: 2.7608862327560995
Validation loss: 2.919667026791371

Epoch: 5| Step: 7
Training loss: 3.523607880052859
Validation loss: 2.928564048707197

Epoch: 5| Step: 8
Training loss: 3.526995906809072
Validation loss: 2.941785586721038

Epoch: 5| Step: 9
Training loss: 3.381345082636656
Validation loss: 2.915913795539609

Epoch: 5| Step: 10
Training loss: 3.0416280317247906
Validation loss: 2.910285844083183

Epoch: 74| Step: 0
Training loss: 2.947222103255119
Validation loss: 2.907787789002314

Epoch: 5| Step: 1
Training loss: 3.0521991868321163
Validation loss: 2.906727199783061

Epoch: 5| Step: 2
Training loss: 2.9794518572122963
Validation loss: 2.9082831395138844

Epoch: 5| Step: 3
Training loss: 3.3624216857639238
Validation loss: 2.9086968103805035

Epoch: 5| Step: 4
Training loss: 3.18446879150508
Validation loss: 2.9089381990315695

Epoch: 5| Step: 5
Training loss: 3.1946119365918357
Validation loss: 2.9071803602340625

Epoch: 5| Step: 6
Training loss: 2.8954001086629817
Validation loss: 2.9076126755297595

Epoch: 5| Step: 7
Training loss: 2.970532012967286
Validation loss: 2.9029871389886304

Epoch: 5| Step: 8
Training loss: 3.749974314283777
Validation loss: 2.9041632761208453

Epoch: 5| Step: 9
Training loss: 2.9352470036666727
Validation loss: 2.9018126189598177

Epoch: 5| Step: 10
Training loss: 3.861312935644442
Validation loss: 2.900007691123871

Epoch: 75| Step: 0
Training loss: 3.848491194703193
Validation loss: 2.9043022083055003

Epoch: 5| Step: 1
Training loss: 2.9104875414407525
Validation loss: 2.9034889240966715

Epoch: 5| Step: 2
Training loss: 2.7103572521299815
Validation loss: 2.90026246623929

Epoch: 5| Step: 3
Training loss: 3.377895949482788
Validation loss: 2.9010310077933528

Epoch: 5| Step: 4
Training loss: 3.12186030020704
Validation loss: 2.896721919066991

Epoch: 5| Step: 5
Training loss: 2.967978447488846
Validation loss: 2.9046821559635823

Epoch: 5| Step: 6
Training loss: 3.6285559215149936
Validation loss: 2.913993586765374

Epoch: 5| Step: 7
Training loss: 2.6564419845314515
Validation loss: 2.9159751113253027

Epoch: 5| Step: 8
Training loss: 3.309050869580385
Validation loss: 2.9080008478005035

Epoch: 5| Step: 9
Training loss: 3.0288077672218967
Validation loss: 2.9126661866319514

Epoch: 5| Step: 10
Training loss: 3.3266311659922234
Validation loss: 2.9065270125922784

Epoch: 76| Step: 0
Training loss: 3.6877341761828513
Validation loss: 2.8942821831118324

Epoch: 5| Step: 1
Training loss: 2.7907899267451444
Validation loss: 2.8964685876603444

Epoch: 5| Step: 2
Training loss: 2.7094380302093417
Validation loss: 2.891706230425092

Epoch: 5| Step: 3
Training loss: 3.196270115997543
Validation loss: 2.891255860136863

Epoch: 5| Step: 4
Training loss: 3.2622891412755215
Validation loss: 2.8881419835387048

Epoch: 5| Step: 5
Training loss: 3.430810835619931
Validation loss: 2.8907614123953054

Epoch: 5| Step: 6
Training loss: 3.486463664863521
Validation loss: 2.8903388815493765

Epoch: 5| Step: 7
Training loss: 3.511931925276787
Validation loss: 2.8883697234816657

Epoch: 5| Step: 8
Training loss: 2.7861091085950562
Validation loss: 2.8907829944343297

Epoch: 5| Step: 9
Training loss: 3.119257113216942
Validation loss: 2.889569128657685

Epoch: 5| Step: 10
Training loss: 2.7836877661926955
Validation loss: 2.8968377146927806

Epoch: 77| Step: 0
Training loss: 2.8686110784930956
Validation loss: 2.9054904385785685

Epoch: 5| Step: 1
Training loss: 3.3529237770361346
Validation loss: 2.935227832504707

Epoch: 5| Step: 2
Training loss: 3.537874203357742
Validation loss: 2.9162799567123425

Epoch: 5| Step: 3
Training loss: 3.149709137097492
Validation loss: 2.9222691636232736

Epoch: 5| Step: 4
Training loss: 3.5494899437065084
Validation loss: 2.888375783827664

Epoch: 5| Step: 5
Training loss: 3.1507122445584037
Validation loss: 2.885364797808685

Epoch: 5| Step: 6
Training loss: 2.882182065265209
Validation loss: 2.8966593124711855

Epoch: 5| Step: 7
Training loss: 3.0355392469703735
Validation loss: 2.8897214959159747

Epoch: 5| Step: 8
Training loss: 2.8794254574951226
Validation loss: 2.8901029940811336

Epoch: 5| Step: 9
Training loss: 3.2071118362096533
Validation loss: 2.8942201632734443

Epoch: 5| Step: 10
Training loss: 3.4489736329506164
Validation loss: 2.8940332356364444

Epoch: 78| Step: 0
Training loss: 3.1599285482223496
Validation loss: 2.8862395211464897

Epoch: 5| Step: 1
Training loss: 3.126671458513808
Validation loss: 2.884131985241061

Epoch: 5| Step: 2
Training loss: 3.084708671725177
Validation loss: 2.8833731287279214

Epoch: 5| Step: 3
Training loss: 3.208904727404749
Validation loss: 2.8809051860422654

Epoch: 5| Step: 4
Training loss: 3.1442032352696567
Validation loss: 2.8849280982403043

Epoch: 5| Step: 5
Training loss: 3.927694433342103
Validation loss: 2.886851999955514

Epoch: 5| Step: 6
Training loss: 3.0276560763788045
Validation loss: 2.891053081765462

Epoch: 5| Step: 7
Training loss: 3.256437089052023
Validation loss: 2.8819905700695556

Epoch: 5| Step: 8
Training loss: 2.910883337756818
Validation loss: 2.8780930614900555

Epoch: 5| Step: 9
Training loss: 2.731066898868904
Validation loss: 2.8800660788254464

Epoch: 5| Step: 10
Training loss: 3.2490871321153634
Validation loss: 2.877966567890084

Epoch: 79| Step: 0
Training loss: 3.6249886874318364
Validation loss: 2.88019845897005

Epoch: 5| Step: 1
Training loss: 3.230684543030648
Validation loss: 2.8779495075838506

Epoch: 5| Step: 2
Training loss: 2.639183779742213
Validation loss: 2.8790031783336762

Epoch: 5| Step: 3
Training loss: 2.711253650710311
Validation loss: 2.878309323932234

Epoch: 5| Step: 4
Training loss: 3.5727653508448136
Validation loss: 2.876866436119456

Epoch: 5| Step: 5
Training loss: 3.355161641713974
Validation loss: 2.874260395751785

Epoch: 5| Step: 6
Training loss: 2.2926906956490067
Validation loss: 2.8738413121481665

Epoch: 5| Step: 7
Training loss: 3.4107917114919415
Validation loss: 2.877955182783621

Epoch: 5| Step: 8
Training loss: 3.1810043569880952
Validation loss: 2.8740425530838882

Epoch: 5| Step: 9
Training loss: 3.4935427090698656
Validation loss: 2.880522034508121

Epoch: 5| Step: 10
Training loss: 3.0491432550043585
Validation loss: 2.872633875692298

Epoch: 80| Step: 0
Training loss: 3.434623902233326
Validation loss: 2.8720793903362725

Epoch: 5| Step: 1
Training loss: 2.988758642422678
Validation loss: 2.8713310723451047

Epoch: 5| Step: 2
Training loss: 3.0352413995255065
Validation loss: 2.873121599408912

Epoch: 5| Step: 3
Training loss: 3.315557400430479
Validation loss: 2.8729940891857746

Epoch: 5| Step: 4
Training loss: 2.8383052809160225
Validation loss: 2.873531488149689

Epoch: 5| Step: 5
Training loss: 3.2110714478409927
Validation loss: 2.874525591483097

Epoch: 5| Step: 6
Training loss: 3.5250493526385696
Validation loss: 2.879650732599376

Epoch: 5| Step: 7
Training loss: 3.0528519913462713
Validation loss: 2.8685420385486027

Epoch: 5| Step: 8
Training loss: 3.0833216142861293
Validation loss: 2.866391310830395

Epoch: 5| Step: 9
Training loss: 3.196931834382229
Validation loss: 2.8672358237856583

Epoch: 5| Step: 10
Training loss: 3.0921182664211204
Validation loss: 2.8746224343161217

Epoch: 81| Step: 0
Training loss: 3.2192280238465623
Validation loss: 2.8800297540662454

Epoch: 5| Step: 1
Training loss: 3.7664366041383417
Validation loss: 2.872535658802034

Epoch: 5| Step: 2
Training loss: 3.296407512768161
Validation loss: 2.8623792051169987

Epoch: 5| Step: 3
Training loss: 3.329116315464891
Validation loss: 2.8607523757934987

Epoch: 5| Step: 4
Training loss: 2.385226768253373
Validation loss: 2.8602816285674493

Epoch: 5| Step: 5
Training loss: 3.2901823986938483
Validation loss: 2.859210977882508

Epoch: 5| Step: 6
Training loss: 3.59449441912063
Validation loss: 2.859449671068357

Epoch: 5| Step: 7
Training loss: 2.9789432006112944
Validation loss: 2.8591018905855474

Epoch: 5| Step: 8
Training loss: 2.460229971766268
Validation loss: 2.8548352223708653

Epoch: 5| Step: 9
Training loss: 3.1006905125081268
Validation loss: 2.8531955845178505

Epoch: 5| Step: 10
Training loss: 3.074385021710643
Validation loss: 2.852565711290912

Epoch: 82| Step: 0
Training loss: 3.2869276063361106
Validation loss: 2.8515919026291647

Epoch: 5| Step: 1
Training loss: 3.3379966223478514
Validation loss: 2.8556037607073463

Epoch: 5| Step: 2
Training loss: 2.7007550561333735
Validation loss: 2.8567351414744646

Epoch: 5| Step: 3
Training loss: 3.478397596564072
Validation loss: 2.860012471792638

Epoch: 5| Step: 4
Training loss: 2.8054279848141737
Validation loss: 2.860961878975506

Epoch: 5| Step: 5
Training loss: 3.1877599871950704
Validation loss: 2.871537706590964

Epoch: 5| Step: 6
Training loss: 3.2357705464159126
Validation loss: 2.8674188559500573

Epoch: 5| Step: 7
Training loss: 3.356839806928517
Validation loss: 2.8680687173515573

Epoch: 5| Step: 8
Training loss: 3.3039645222567167
Validation loss: 2.8577964438015497

Epoch: 5| Step: 9
Training loss: 2.893149433473698
Validation loss: 2.847611920686223

Epoch: 5| Step: 10
Training loss: 3.0213139294200166
Validation loss: 2.8469784114430645

Epoch: 83| Step: 0
Training loss: 2.424468786515832
Validation loss: 2.846789708281589

Epoch: 5| Step: 1
Training loss: 3.4719582232673494
Validation loss: 2.848076193701908

Epoch: 5| Step: 2
Training loss: 2.6022139183326023
Validation loss: 2.8490734448650374

Epoch: 5| Step: 3
Training loss: 3.807433717567763
Validation loss: 2.8535583020785396

Epoch: 5| Step: 4
Training loss: 3.2144744030503976
Validation loss: 2.860833290903759

Epoch: 5| Step: 5
Training loss: 2.5123066310582933
Validation loss: 2.855210081126274

Epoch: 5| Step: 6
Training loss: 3.105938262954712
Validation loss: 2.858044971347477

Epoch: 5| Step: 7
Training loss: 3.6780643325249076
Validation loss: 2.849182705574584

Epoch: 5| Step: 8
Training loss: 3.4235329987696264
Validation loss: 2.8460748637883273

Epoch: 5| Step: 9
Training loss: 3.01069673249623
Validation loss: 2.8434139225756283

Epoch: 5| Step: 10
Training loss: 3.0222465278857356
Validation loss: 2.8459056250931987

Epoch: 84| Step: 0
Training loss: 3.0306587822483326
Validation loss: 2.8505466163669424

Epoch: 5| Step: 1
Training loss: 2.9094314389434577
Validation loss: 2.8564381522891833

Epoch: 5| Step: 2
Training loss: 3.6912148077837665
Validation loss: 2.8740796028801685

Epoch: 5| Step: 3
Training loss: 3.3622659708143394
Validation loss: 2.8755346588441872

Epoch: 5| Step: 4
Training loss: 3.5739736671011335
Validation loss: 2.8568392552926234

Epoch: 5| Step: 5
Training loss: 2.7330288434424057
Validation loss: 2.8554894729508042

Epoch: 5| Step: 6
Training loss: 3.2907516237768
Validation loss: 2.848269020360203

Epoch: 5| Step: 7
Training loss: 2.3091618957066427
Validation loss: 2.8498343154912456

Epoch: 5| Step: 8
Training loss: 3.8071639443546865
Validation loss: 2.8471132998104016

Epoch: 5| Step: 9
Training loss: 3.1093256194060985
Validation loss: 2.8459487306697024

Epoch: 5| Step: 10
Training loss: 2.4930451929224744
Validation loss: 2.844382468046637

Epoch: 85| Step: 0
Training loss: 3.286826780596223
Validation loss: 2.850962165169678

Epoch: 5| Step: 1
Training loss: 2.6962931300336033
Validation loss: 2.8479083287934333

Epoch: 5| Step: 2
Training loss: 2.7233050543423056
Validation loss: 2.857733709282749

Epoch: 5| Step: 3
Training loss: 3.1353887681364103
Validation loss: 2.867529637511617

Epoch: 5| Step: 4
Training loss: 2.9890608026287326
Validation loss: 2.852285773319459

Epoch: 5| Step: 5
Training loss: 3.2638387220779386
Validation loss: 2.847736017619674

Epoch: 5| Step: 6
Training loss: 3.346960362646743
Validation loss: 2.8421223600533545

Epoch: 5| Step: 7
Training loss: 2.6041790059115217
Validation loss: 2.838364548400755

Epoch: 5| Step: 8
Training loss: 3.67820810436397
Validation loss: 2.8409139948902333

Epoch: 5| Step: 9
Training loss: 3.537047901177564
Validation loss: 2.8368007279828826

Epoch: 5| Step: 10
Training loss: 3.1487587133077293
Validation loss: 2.839327775462535

Epoch: 86| Step: 0
Training loss: 2.4839259287591022
Validation loss: 2.838103459787489

Epoch: 5| Step: 1
Training loss: 2.816530010662829
Validation loss: 2.835086579253839

Epoch: 5| Step: 2
Training loss: 2.802475761152218
Validation loss: 2.83894271132383

Epoch: 5| Step: 3
Training loss: 2.6728287271814093
Validation loss: 2.8362490118681927

Epoch: 5| Step: 4
Training loss: 3.274413625624412
Validation loss: 2.852013301011273

Epoch: 5| Step: 5
Training loss: 2.885114376240439
Validation loss: 2.856147627168216

Epoch: 5| Step: 6
Training loss: 3.5485209540460247
Validation loss: 2.8534951823966868

Epoch: 5| Step: 7
Training loss: 3.479887805752507
Validation loss: 2.833038103573494

Epoch: 5| Step: 8
Training loss: 3.5749054796221427
Validation loss: 2.8302218859843675

Epoch: 5| Step: 9
Training loss: 3.2989466517709056
Validation loss: 2.8314828726339774

Epoch: 5| Step: 10
Training loss: 3.487400810991462
Validation loss: 2.8297050566082285

Epoch: 87| Step: 0
Training loss: 3.467367085588947
Validation loss: 2.833529922160624

Epoch: 5| Step: 1
Training loss: 3.0903495827856178
Validation loss: 2.8332044299467207

Epoch: 5| Step: 2
Training loss: 3.25740879402503
Validation loss: 2.8338103324147177

Epoch: 5| Step: 3
Training loss: 3.1558159255870684
Validation loss: 2.8326828431268662

Epoch: 5| Step: 4
Training loss: 3.43528162727652
Validation loss: 2.832756870254034

Epoch: 5| Step: 5
Training loss: 2.7258474729523625
Validation loss: 2.831089931904331

Epoch: 5| Step: 6
Training loss: 3.3328059415041835
Validation loss: 2.83019999430626

Epoch: 5| Step: 7
Training loss: 3.175322815110863
Validation loss: 2.830243106293741

Epoch: 5| Step: 8
Training loss: 3.002257451433421
Validation loss: 2.8299906470350282

Epoch: 5| Step: 9
Training loss: 2.678444977454907
Validation loss: 2.8280220155758418

Epoch: 5| Step: 10
Training loss: 3.1133379195163884
Validation loss: 2.8258096792943213

Epoch: 88| Step: 0
Training loss: 3.18641644180427
Validation loss: 2.8258589746616685

Epoch: 5| Step: 1
Training loss: 2.8981811739125782
Validation loss: 2.823527206790986

Epoch: 5| Step: 2
Training loss: 3.7345572072033537
Validation loss: 2.8228835346239363

Epoch: 5| Step: 3
Training loss: 3.2458393167057804
Validation loss: 2.8226545754285888

Epoch: 5| Step: 4
Training loss: 3.444507876875154
Validation loss: 2.8209923729283566

Epoch: 5| Step: 5
Training loss: 3.502164171606993
Validation loss: 2.8194406840315507

Epoch: 5| Step: 6
Training loss: 2.8071831356058397
Validation loss: 2.8163859840669647

Epoch: 5| Step: 7
Training loss: 3.0792534787987713
Validation loss: 2.814158855790824

Epoch: 5| Step: 8
Training loss: 2.6743554987756935
Validation loss: 2.817045593354976

Epoch: 5| Step: 9
Training loss: 2.9459564557350326
Validation loss: 2.8155636598483924

Epoch: 5| Step: 10
Training loss: 2.5936191020245665
Validation loss: 2.8287084078903817

Epoch: 89| Step: 0
Training loss: 3.132516594893817
Validation loss: 2.8427405726594555

Epoch: 5| Step: 1
Training loss: 3.112523923728338
Validation loss: 2.841789564213428

Epoch: 5| Step: 2
Training loss: 3.600387944405398
Validation loss: 2.8417181711927593

Epoch: 5| Step: 3
Training loss: 2.6965065785134494
Validation loss: 2.810986333720166

Epoch: 5| Step: 4
Training loss: 2.9300278122659273
Validation loss: 2.8140863718735267

Epoch: 5| Step: 5
Training loss: 2.4387544191790673
Validation loss: 2.8194879767301306

Epoch: 5| Step: 6
Training loss: 3.488460591694378
Validation loss: 2.821604967291393

Epoch: 5| Step: 7
Training loss: 3.5467384076809965
Validation loss: 2.8232342674904856

Epoch: 5| Step: 8
Training loss: 3.1780182677044637
Validation loss: 2.822547689295281

Epoch: 5| Step: 9
Training loss: 2.9909663883464592
Validation loss: 2.824024188575011

Epoch: 5| Step: 10
Training loss: 3.097289709506797
Validation loss: 2.8240299893917684

Epoch: 90| Step: 0
Training loss: 3.270116464249905
Validation loss: 2.824009191275147

Epoch: 5| Step: 1
Training loss: 3.4401459654069426
Validation loss: 2.8254976869991033

Epoch: 5| Step: 2
Training loss: 3.001245399099793
Validation loss: 2.823755840115404

Epoch: 5| Step: 3
Training loss: 3.0193240549870493
Validation loss: 2.8222741209029234

Epoch: 5| Step: 4
Training loss: 3.1126815620382424
Validation loss: 2.8213041864803596

Epoch: 5| Step: 5
Training loss: 3.2095729035124636
Validation loss: 2.8188191139401533

Epoch: 5| Step: 6
Training loss: 2.4850731594438193
Validation loss: 2.8167432216758153

Epoch: 5| Step: 7
Training loss: 3.277225460423012
Validation loss: 2.8201421352672216

Epoch: 5| Step: 8
Training loss: 2.751197727509248
Validation loss: 2.814425950463097

Epoch: 5| Step: 9
Training loss: 3.5946046559317604
Validation loss: 2.81511063729768

Epoch: 5| Step: 10
Training loss: 3.208410006180823
Validation loss: 2.81343597734674

Epoch: 91| Step: 0
Training loss: 3.262766193623584
Validation loss: 2.810508400245097

Epoch: 5| Step: 1
Training loss: 3.020438981898423
Validation loss: 2.8094553684858927

Epoch: 5| Step: 2
Training loss: 2.788573321016862
Validation loss: 2.8074685296592747

Epoch: 5| Step: 3
Training loss: 3.418783106111843
Validation loss: 2.8071690981110167

Epoch: 5| Step: 4
Training loss: 2.272135253439882
Validation loss: 2.8063391410533165

Epoch: 5| Step: 5
Training loss: 3.1073885759431272
Validation loss: 2.8060751466696576

Epoch: 5| Step: 6
Training loss: 2.7931905164906983
Validation loss: 2.819417426556761

Epoch: 5| Step: 7
Training loss: 2.798595474700115
Validation loss: 2.8398635524362827

Epoch: 5| Step: 8
Training loss: 3.1907886668642527
Validation loss: 2.8230121967062556

Epoch: 5| Step: 9
Training loss: 3.3235340242487896
Validation loss: 2.8183030070034323

Epoch: 5| Step: 10
Training loss: 4.178675220583803
Validation loss: 2.8067004907973656

Epoch: 92| Step: 0
Training loss: 2.6906972097881923
Validation loss: 2.799643397549419

Epoch: 5| Step: 1
Training loss: 2.9476602036130886
Validation loss: 2.802713073555765

Epoch: 5| Step: 2
Training loss: 3.23918406161332
Validation loss: 2.8058913144476216

Epoch: 5| Step: 3
Training loss: 2.5899577166077283
Validation loss: 2.8064318442175873

Epoch: 5| Step: 4
Training loss: 3.353731036280115
Validation loss: 2.8097415207959036

Epoch: 5| Step: 5
Training loss: 3.1806514694062953
Validation loss: 2.809395159882045

Epoch: 5| Step: 6
Training loss: 3.289963116424572
Validation loss: 2.810372320534816

Epoch: 5| Step: 7
Training loss: 3.1563120920853254
Validation loss: 2.811882212797404

Epoch: 5| Step: 8
Training loss: 3.5758915889786045
Validation loss: 2.811495228884164

Epoch: 5| Step: 9
Training loss: 2.7456341680403624
Validation loss: 2.8132936795707995

Epoch: 5| Step: 10
Training loss: 3.477239855669289
Validation loss: 2.810559013867423

Epoch: 93| Step: 0
Training loss: 3.5987535226108367
Validation loss: 2.808351216357114

Epoch: 5| Step: 1
Training loss: 2.650824537297605
Validation loss: 2.8044741604230214

Epoch: 5| Step: 2
Training loss: 2.4057543355535427
Validation loss: 2.8037629100415344

Epoch: 5| Step: 3
Training loss: 3.73302598153573
Validation loss: 2.802097991296304

Epoch: 5| Step: 4
Training loss: 2.608902208816662
Validation loss: 2.8010942490132473

Epoch: 5| Step: 5
Training loss: 3.01024879770704
Validation loss: 2.801013836818715

Epoch: 5| Step: 6
Training loss: 3.238288023496384
Validation loss: 2.7994509972511774

Epoch: 5| Step: 7
Training loss: 3.3509818332126176
Validation loss: 2.796268043694371

Epoch: 5| Step: 8
Training loss: 2.8512864070643382
Validation loss: 2.794700526597541

Epoch: 5| Step: 9
Training loss: 3.205425199491277
Validation loss: 2.7958483580518174

Epoch: 5| Step: 10
Training loss: 3.3365257870114804
Validation loss: 2.7945352587908694

Epoch: 94| Step: 0
Training loss: 2.8460313637802037
Validation loss: 2.8007346208430843

Epoch: 5| Step: 1
Training loss: 2.911640541412181
Validation loss: 2.8007715053740374

Epoch: 5| Step: 2
Training loss: 2.891157936249991
Validation loss: 2.800413819539468

Epoch: 5| Step: 3
Training loss: 3.54197657108151
Validation loss: 2.799589480463309

Epoch: 5| Step: 4
Training loss: 3.299732434378395
Validation loss: 2.791219103926317

Epoch: 5| Step: 5
Training loss: 2.345445756983136
Validation loss: 2.79527887688362

Epoch: 5| Step: 6
Training loss: 3.201652672290418
Validation loss: 2.792227215997491

Epoch: 5| Step: 7
Training loss: 2.885875036599415
Validation loss: 2.7847993644461817

Epoch: 5| Step: 8
Training loss: 3.6136855770400156
Validation loss: 2.7891746152162225

Epoch: 5| Step: 9
Training loss: 3.0281260015054943
Validation loss: 2.793731482043122

Epoch: 5| Step: 10
Training loss: 3.3593484566992795
Validation loss: 2.789038794337983

Epoch: 95| Step: 0
Training loss: 2.895852306130003
Validation loss: 2.794132984146841

Epoch: 5| Step: 1
Training loss: 2.995140272113109
Validation loss: 2.7887901411466265

Epoch: 5| Step: 2
Training loss: 3.424582886182774
Validation loss: 2.80082118192581

Epoch: 5| Step: 3
Training loss: 3.1458450889788803
Validation loss: 2.788589151967442

Epoch: 5| Step: 4
Training loss: 3.2302235668273815
Validation loss: 2.7815912564360463

Epoch: 5| Step: 5
Training loss: 3.096702630936371
Validation loss: 2.7836348828295954

Epoch: 5| Step: 6
Training loss: 3.0401508961420776
Validation loss: 2.7823769826801072

Epoch: 5| Step: 7
Training loss: 3.0599209572051467
Validation loss: 2.7830350815409237

Epoch: 5| Step: 8
Training loss: 3.287344658376134
Validation loss: 2.7816555432209715

Epoch: 5| Step: 9
Training loss: 3.221610862642006
Validation loss: 2.785705117444161

Epoch: 5| Step: 10
Training loss: 2.4541351765380974
Validation loss: 2.77708923549939

Epoch: 96| Step: 0
Training loss: 3.1663076464935704
Validation loss: 2.7786183384374024

Epoch: 5| Step: 1
Training loss: 3.1172369090206233
Validation loss: 2.7783907906773764

Epoch: 5| Step: 2
Training loss: 3.421024722012486
Validation loss: 2.777491490230762

Epoch: 5| Step: 3
Training loss: 2.9960152865683236
Validation loss: 2.777650157772399

Epoch: 5| Step: 4
Training loss: 3.2072104103142083
Validation loss: 2.7792955937775097

Epoch: 5| Step: 5
Training loss: 2.667347691914987
Validation loss: 2.7821652348033346

Epoch: 5| Step: 6
Training loss: 3.0432454719130586
Validation loss: 2.7826254193896918

Epoch: 5| Step: 7
Training loss: 3.5640793361374867
Validation loss: 2.777437992301868

Epoch: 5| Step: 8
Training loss: 2.8358702428319402
Validation loss: 2.7750451971613974

Epoch: 5| Step: 9
Training loss: 3.3019417974101066
Validation loss: 2.7736069383270654

Epoch: 5| Step: 10
Training loss: 2.359884952230183
Validation loss: 2.7700903395436174

Epoch: 97| Step: 0
Training loss: 3.412097636106023
Validation loss: 2.7753299969970544

Epoch: 5| Step: 1
Training loss: 2.9897921463794512
Validation loss: 2.7762758840772914

Epoch: 5| Step: 2
Training loss: 2.707168201323584
Validation loss: 2.780165310195001

Epoch: 5| Step: 3
Training loss: 2.9582039889862397
Validation loss: 2.784098018807856

Epoch: 5| Step: 4
Training loss: 3.0677865001691558
Validation loss: 2.778349872934094

Epoch: 5| Step: 5
Training loss: 2.419386243308729
Validation loss: 2.770377007200448

Epoch: 5| Step: 6
Training loss: 2.7365446365817148
Validation loss: 2.767812486816363

Epoch: 5| Step: 7
Training loss: 3.6054852816945617
Validation loss: 2.7684535236217944

Epoch: 5| Step: 8
Training loss: 3.1040898938680668
Validation loss: 2.76718285058786

Epoch: 5| Step: 9
Training loss: 3.3975346209942425
Validation loss: 2.767837581146707

Epoch: 5| Step: 10
Training loss: 3.366896472931123
Validation loss: 2.7685923266901047

Epoch: 98| Step: 0
Training loss: 3.199079834247447
Validation loss: 2.7658582055701935

Epoch: 5| Step: 1
Training loss: 3.137804273464063
Validation loss: 2.767576183449513

Epoch: 5| Step: 2
Training loss: 3.115673950178093
Validation loss: 2.769909603802468

Epoch: 5| Step: 3
Training loss: 3.003638127815775
Validation loss: 2.7718793356672715

Epoch: 5| Step: 4
Training loss: 3.0645506863353806
Validation loss: 2.7675267457055477

Epoch: 5| Step: 5
Training loss: 2.9151808814434146
Validation loss: 2.768478965877626

Epoch: 5| Step: 6
Training loss: 3.5519187792178126
Validation loss: 2.7662057852484914

Epoch: 5| Step: 7
Training loss: 2.5814500116994
Validation loss: 2.768472651404717

Epoch: 5| Step: 8
Training loss: 3.403748880162722
Validation loss: 2.765865352793923

Epoch: 5| Step: 9
Training loss: 2.8259399571988637
Validation loss: 2.762707819369693

Epoch: 5| Step: 10
Training loss: 3.0078226460867836
Validation loss: 2.762769179972835

Epoch: 99| Step: 0
Training loss: 2.8525449131765575
Validation loss: 2.763338691411533

Epoch: 5| Step: 1
Training loss: 2.9880947079745788
Validation loss: 2.759831180035876

Epoch: 5| Step: 2
Training loss: 3.462780739320409
Validation loss: 2.760898571395859

Epoch: 5| Step: 3
Training loss: 2.476078214738074
Validation loss: 2.7573875776862478

Epoch: 5| Step: 4
Training loss: 2.948575668453366
Validation loss: 2.7609557083845853

Epoch: 5| Step: 5
Training loss: 2.836473146405289
Validation loss: 2.761922195812107

Epoch: 5| Step: 6
Training loss: 3.4487854630353487
Validation loss: 2.7607685189146167

Epoch: 5| Step: 7
Training loss: 3.190889837349695
Validation loss: 2.759568070785091

Epoch: 5| Step: 8
Training loss: 2.959931456829022
Validation loss: 2.7591831547748344

Epoch: 5| Step: 9
Training loss: 3.6400241601582324
Validation loss: 2.7603527121275717

Epoch: 5| Step: 10
Training loss: 2.7675024868920377
Validation loss: 2.7603462091061295

Epoch: 100| Step: 0
Training loss: 2.6511809506702897
Validation loss: 2.7575145013019005

Epoch: 5| Step: 1
Training loss: 2.9552467434233236
Validation loss: 2.7554640942118476

Epoch: 5| Step: 2
Training loss: 3.071125107408359
Validation loss: 2.75273515185889

Epoch: 5| Step: 3
Training loss: 2.2545809207081566
Validation loss: 2.753861182385229

Epoch: 5| Step: 4
Training loss: 3.1911130884897
Validation loss: 2.7548483217082067

Epoch: 5| Step: 5
Training loss: 3.0625773828811664
Validation loss: 2.755085221244681

Epoch: 5| Step: 6
Training loss: 3.7016693988660005
Validation loss: 2.7549306662636703

Epoch: 5| Step: 7
Training loss: 3.258693804561829
Validation loss: 2.755389297739029

Epoch: 5| Step: 8
Training loss: 2.7944216063897396
Validation loss: 2.7566483659798076

Epoch: 5| Step: 9
Training loss: 3.6294293144711713
Validation loss: 2.7591313873307217

Epoch: 5| Step: 10
Training loss: 2.8315786276234785
Validation loss: 2.754348944348587

Epoch: 101| Step: 0
Training loss: 3.434662080937438
Validation loss: 2.756975135774627

Epoch: 5| Step: 1
Training loss: 3.656563769839831
Validation loss: 2.768396212637083

Epoch: 5| Step: 2
Training loss: 2.9777940019795017
Validation loss: 2.7603075640139982

Epoch: 5| Step: 3
Training loss: 3.4988398672803127
Validation loss: 2.7614754238941206

Epoch: 5| Step: 4
Training loss: 2.9790494846870796
Validation loss: 2.762927356843005

Epoch: 5| Step: 5
Training loss: 2.808906803006913
Validation loss: 2.771912849218635

Epoch: 5| Step: 6
Training loss: 2.868642827444322
Validation loss: 2.760803618719515

Epoch: 5| Step: 7
Training loss: 2.1979827388818056
Validation loss: 2.751713041142822

Epoch: 5| Step: 8
Training loss: 2.867477859637751
Validation loss: 2.7476530678496607

Epoch: 5| Step: 9
Training loss: 2.7947589392255905
Validation loss: 2.7486626513933334

Epoch: 5| Step: 10
Training loss: 3.3738072018263305
Validation loss: 2.7452560041072673

Epoch: 102| Step: 0
Training loss: 3.022554648183772
Validation loss: 2.7477887941260524

Epoch: 5| Step: 1
Training loss: 2.9473817877000292
Validation loss: 2.7464284123893123

Epoch: 5| Step: 2
Training loss: 2.7705445581311428
Validation loss: 2.742938313060477

Epoch: 5| Step: 3
Training loss: 3.202168987239642
Validation loss: 2.741886280952651

Epoch: 5| Step: 4
Training loss: 2.8225550308471656
Validation loss: 2.7498806590066804

Epoch: 5| Step: 5
Training loss: 3.1946349230013382
Validation loss: 2.7721409296373127

Epoch: 5| Step: 6
Training loss: 3.203438050394045
Validation loss: 2.742352659042333

Epoch: 5| Step: 7
Training loss: 2.820158048083159
Validation loss: 2.7445157676300647

Epoch: 5| Step: 8
Training loss: 3.466184612528225
Validation loss: 2.7506638934650773

Epoch: 5| Step: 9
Training loss: 2.4979568715766653
Validation loss: 2.7547043604361514

Epoch: 5| Step: 10
Training loss: 3.780428458257467
Validation loss: 2.7599491781490024

Epoch: 103| Step: 0
Training loss: 3.272410083581664
Validation loss: 2.773748977180999

Epoch: 5| Step: 1
Training loss: 2.92738532593449
Validation loss: 2.756526431137046

Epoch: 5| Step: 2
Training loss: 3.5409788623212313
Validation loss: 2.7534099107433345

Epoch: 5| Step: 3
Training loss: 3.4888828010937925
Validation loss: 2.7507588392050404

Epoch: 5| Step: 4
Training loss: 2.9972060226585597
Validation loss: 2.748386633205341

Epoch: 5| Step: 5
Training loss: 2.811405392732894
Validation loss: 2.746995449863332

Epoch: 5| Step: 6
Training loss: 2.791974083974186
Validation loss: 2.7444495319662336

Epoch: 5| Step: 7
Training loss: 2.655024975301799
Validation loss: 2.74392098960983

Epoch: 5| Step: 8
Training loss: 3.0066277090228617
Validation loss: 2.744978297562997

Epoch: 5| Step: 9
Training loss: 3.328523423967289
Validation loss: 2.7458923412552183

Epoch: 5| Step: 10
Training loss: 2.8560266119414357
Validation loss: 2.7563593153196195

Epoch: 104| Step: 0
Training loss: 3.099293376003955
Validation loss: 2.755816660338868

Epoch: 5| Step: 1
Training loss: 2.6165251391905473
Validation loss: 2.747159032973752

Epoch: 5| Step: 2
Training loss: 3.3095708888130213
Validation loss: 2.7508829327099726

Epoch: 5| Step: 3
Training loss: 2.954408558428361
Validation loss: 2.7475954116362895

Epoch: 5| Step: 4
Training loss: 3.5273615941201473
Validation loss: 2.743504828141233

Epoch: 5| Step: 5
Training loss: 3.009482021944187
Validation loss: 2.7538240549491393

Epoch: 5| Step: 6
Training loss: 3.3084964670338532
Validation loss: 2.756870501530506

Epoch: 5| Step: 7
Training loss: 2.106457196919708
Validation loss: 2.7763727462392205

Epoch: 5| Step: 8
Training loss: 3.564999289278492
Validation loss: 2.74160018477737

Epoch: 5| Step: 9
Training loss: 2.9469874954191337
Validation loss: 2.7359251816974632

Epoch: 5| Step: 10
Training loss: 2.898530449623571
Validation loss: 2.7358958750283726

Epoch: 105| Step: 0
Training loss: 3.2128235412829436
Validation loss: 2.731581172124652

Epoch: 5| Step: 1
Training loss: 3.4596021844686526
Validation loss: 2.735550432600784

Epoch: 5| Step: 2
Training loss: 3.3587996588990845
Validation loss: 2.7369438927736662

Epoch: 5| Step: 3
Training loss: 2.713249869347758
Validation loss: 2.7341847333911793

Epoch: 5| Step: 4
Training loss: 2.9421350151319747
Validation loss: 2.7298602103052505

Epoch: 5| Step: 5
Training loss: 2.982349926993164
Validation loss: 2.732596845571339

Epoch: 5| Step: 6
Training loss: 2.794331678218079
Validation loss: 2.7316109079965396

Epoch: 5| Step: 7
Training loss: 2.8401348904019876
Validation loss: 2.7320765854196085

Epoch: 5| Step: 8
Training loss: 2.885577439512554
Validation loss: 2.7350434304593385

Epoch: 5| Step: 9
Training loss: 3.0030670382714635
Validation loss: 2.735955334180424

Epoch: 5| Step: 10
Training loss: 3.4381955916871245
Validation loss: 2.7402488124504707

Epoch: 106| Step: 0
Training loss: 3.1636821000112576
Validation loss: 2.752819763495638

Epoch: 5| Step: 1
Training loss: 3.5180740981113865
Validation loss: 2.7867296214273005

Epoch: 5| Step: 2
Training loss: 2.981573417602804
Validation loss: 2.8002650658443873

Epoch: 5| Step: 3
Training loss: 3.0285837304310155
Validation loss: 2.7530580728224963

Epoch: 5| Step: 4
Training loss: 2.5500405888038564
Validation loss: 2.7307268699315936

Epoch: 5| Step: 5
Training loss: 2.429542757978937
Validation loss: 2.7242532726227084

Epoch: 5| Step: 6
Training loss: 3.0946578418135258
Validation loss: 2.722594921316853

Epoch: 5| Step: 7
Training loss: 3.0314258642404144
Validation loss: 2.7267172545278267

Epoch: 5| Step: 8
Training loss: 2.9763564791932016
Validation loss: 2.7291637420795185

Epoch: 5| Step: 9
Training loss: 3.1246902312289606
Validation loss: 2.7327380135386794

Epoch: 5| Step: 10
Training loss: 3.604264377452864
Validation loss: 2.7358192279276095

Epoch: 107| Step: 0
Training loss: 3.1425286592012758
Validation loss: 2.732295513115574

Epoch: 5| Step: 1
Training loss: 2.8158849903105074
Validation loss: 2.73321395296181

Epoch: 5| Step: 2
Training loss: 3.2053301408194304
Validation loss: 2.7324948702085354

Epoch: 5| Step: 3
Training loss: 3.3673538910364065
Validation loss: 2.7300295774028123

Epoch: 5| Step: 4
Training loss: 2.8205611946163627
Validation loss: 2.7266241540815694

Epoch: 5| Step: 5
Training loss: 3.3001360200534906
Validation loss: 2.7253444941203284

Epoch: 5| Step: 6
Training loss: 3.0247561711176583
Validation loss: 2.7239769993182126

Epoch: 5| Step: 7
Training loss: 3.3216228457589483
Validation loss: 2.723463919258481

Epoch: 5| Step: 8
Training loss: 2.617260103499715
Validation loss: 2.720395646364808

Epoch: 5| Step: 9
Training loss: 3.169091718257076
Validation loss: 2.7199030943708613

Epoch: 5| Step: 10
Training loss: 2.7098852748446425
Validation loss: 2.716920501370161

Epoch: 108| Step: 0
Training loss: 3.3420330167060617
Validation loss: 2.721442168663081

Epoch: 5| Step: 1
Training loss: 2.8747735970956225
Validation loss: 2.7331259335403213

Epoch: 5| Step: 2
Training loss: 3.032199357013623
Validation loss: 2.7776503885106476

Epoch: 5| Step: 3
Training loss: 2.293746374475592
Validation loss: 2.9038064197198517

Epoch: 5| Step: 4
Training loss: 3.2577270203863717
Validation loss: 2.9159924168751106

Epoch: 5| Step: 5
Training loss: 3.222844750642383
Validation loss: 2.838927622613148

Epoch: 5| Step: 6
Training loss: 3.1947123889686817
Validation loss: 2.725379418967388

Epoch: 5| Step: 7
Training loss: 2.856247823034079
Validation loss: 2.713648537809777

Epoch: 5| Step: 8
Training loss: 2.9568085479526074
Validation loss: 2.7178837130715134

Epoch: 5| Step: 9
Training loss: 3.3250364201207474
Validation loss: 2.7201291703184864

Epoch: 5| Step: 10
Training loss: 3.3527177006914535
Validation loss: 2.7267890015965888

Epoch: 109| Step: 0
Training loss: 3.269341649035052
Validation loss: 2.7909958580945955

Epoch: 5| Step: 1
Training loss: 3.4866926072166495
Validation loss: 2.727895402255767

Epoch: 5| Step: 2
Training loss: 2.8955209870062846
Validation loss: 2.737241973081847

Epoch: 5| Step: 3
Training loss: 3.1826724726231514
Validation loss: 2.856852971553688

Epoch: 5| Step: 4
Training loss: 3.3782856806847796
Validation loss: 2.9015564779403262

Epoch: 5| Step: 5
Training loss: 2.619606471610015
Validation loss: 2.7666237906246973

Epoch: 5| Step: 6
Training loss: 3.360350852995057
Validation loss: 2.735386504846951

Epoch: 5| Step: 7
Training loss: 2.8492823851758944
Validation loss: 2.749512618980616

Epoch: 5| Step: 8
Training loss: 3.1105859593292027
Validation loss: 2.7846504063528488

Epoch: 5| Step: 9
Training loss: 3.072174517134876
Validation loss: 2.8086402149068794

Epoch: 5| Step: 10
Training loss: 2.7711311314150326
Validation loss: 2.8391142965340386

Epoch: 110| Step: 0
Training loss: 2.959210136034855
Validation loss: 2.8729073147521627

Epoch: 5| Step: 1
Training loss: 2.5779947883784113
Validation loss: 2.8548888988890617

Epoch: 5| Step: 2
Training loss: 2.9772765737345916
Validation loss: 2.817248691885279

Epoch: 5| Step: 3
Training loss: 3.652835392628533
Validation loss: 2.7847244619950833

Epoch: 5| Step: 4
Training loss: 3.119303279259336
Validation loss: 2.7611913676285202

Epoch: 5| Step: 5
Training loss: 3.2160728209492455
Validation loss: 2.7536509498862975

Epoch: 5| Step: 6
Training loss: 2.9754934719080106
Validation loss: 2.7377378190657415

Epoch: 5| Step: 7
Training loss: 3.00953098102828
Validation loss: 2.7158748976995195

Epoch: 5| Step: 8
Training loss: 2.9697601206074196
Validation loss: 2.7095872032169668

Epoch: 5| Step: 9
Training loss: 3.2125810189921853
Validation loss: 2.707065314465811

Epoch: 5| Step: 10
Training loss: 3.2807260730803716
Validation loss: 2.7070482302001477

Epoch: 111| Step: 0
Training loss: 2.974415723341926
Validation loss: 2.707366632318819

Epoch: 5| Step: 1
Training loss: 2.636959172343255
Validation loss: 2.7134558041119323

Epoch: 5| Step: 2
Training loss: 3.356431958258275
Validation loss: 2.7092554133504096

Epoch: 5| Step: 3
Training loss: 2.688728761327506
Validation loss: 2.706833975451862

Epoch: 5| Step: 4
Training loss: 3.109007693885174
Validation loss: 2.7120168003846046

Epoch: 5| Step: 5
Training loss: 2.5639676798897617
Validation loss: 2.712214167731444

Epoch: 5| Step: 6
Training loss: 2.5743322969670253
Validation loss: 2.7162254275506488

Epoch: 5| Step: 7
Training loss: 3.3804263537864605
Validation loss: 2.719599781368384

Epoch: 5| Step: 8
Training loss: 3.818703778825354
Validation loss: 2.709861786637914

Epoch: 5| Step: 9
Training loss: 3.207547145149155
Validation loss: 2.709399069648298

Epoch: 5| Step: 10
Training loss: 2.8705026030987977
Validation loss: 2.705872807739521

Epoch: 112| Step: 0
Training loss: 3.160185371707984
Validation loss: 2.7017667811354467

Epoch: 5| Step: 1
Training loss: 3.2320887644636356
Validation loss: 2.6982790260611496

Epoch: 5| Step: 2
Training loss: 2.9065253014558343
Validation loss: 2.6995323709740098

Epoch: 5| Step: 3
Training loss: 3.056240613802049
Validation loss: 2.7012214623171613

Epoch: 5| Step: 4
Training loss: 3.131008323129601
Validation loss: 2.697688207829086

Epoch: 5| Step: 5
Training loss: 2.6515067441402427
Validation loss: 2.6991447124083447

Epoch: 5| Step: 6
Training loss: 3.531930233414309
Validation loss: 2.702315947817462

Epoch: 5| Step: 7
Training loss: 2.5078865586988757
Validation loss: 2.699393986623456

Epoch: 5| Step: 8
Training loss: 2.581665382491651
Validation loss: 2.7058246320975963

Epoch: 5| Step: 9
Training loss: 3.1032246092514586
Validation loss: 2.71422766270203

Epoch: 5| Step: 10
Training loss: 3.3681688759388626
Validation loss: 2.7167976733076244

Epoch: 113| Step: 0
Training loss: 3.0369088747624353
Validation loss: 2.7050537041932685

Epoch: 5| Step: 1
Training loss: 2.9028730564410705
Validation loss: 2.699371399583319

Epoch: 5| Step: 2
Training loss: 3.3299743099195407
Validation loss: 2.6949803120751255

Epoch: 5| Step: 3
Training loss: 3.070000008946521
Validation loss: 2.6947637897395706

Epoch: 5| Step: 4
Training loss: 2.5674289657141514
Validation loss: 2.69390363213021

Epoch: 5| Step: 5
Training loss: 2.8934500421404037
Validation loss: 2.6959854700667583

Epoch: 5| Step: 6
Training loss: 3.4867726104084182
Validation loss: 2.6900172615282734

Epoch: 5| Step: 7
Training loss: 2.455004901143016
Validation loss: 2.6912971413861304

Epoch: 5| Step: 8
Training loss: 3.1423320021899825
Validation loss: 2.6934808210245125

Epoch: 5| Step: 9
Training loss: 3.449478226057306
Validation loss: 2.6914522310061266

Epoch: 5| Step: 10
Training loss: 2.70714750494416
Validation loss: 2.691350699880991

Epoch: 114| Step: 0
Training loss: 3.3046303602107985
Validation loss: 2.6906311061003256

Epoch: 5| Step: 1
Training loss: 2.915805162626427
Validation loss: 2.6898620748759874

Epoch: 5| Step: 2
Training loss: 3.3441974661351686
Validation loss: 2.6916073326439625

Epoch: 5| Step: 3
Training loss: 3.0694951724026738
Validation loss: 2.691780212350676

Epoch: 5| Step: 4
Training loss: 2.9736405095343734
Validation loss: 2.6929129128515004

Epoch: 5| Step: 5
Training loss: 2.882216808108452
Validation loss: 2.6955008758541004

Epoch: 5| Step: 6
Training loss: 2.6274382756584442
Validation loss: 2.6963227245311803

Epoch: 5| Step: 7
Training loss: 2.734518951986472
Validation loss: 2.704239198764996

Epoch: 5| Step: 8
Training loss: 3.4521409785987314
Validation loss: 2.7137149206498266

Epoch: 5| Step: 9
Training loss: 2.447775286115611
Validation loss: 2.7222324680107373

Epoch: 5| Step: 10
Training loss: 3.349234957663577
Validation loss: 2.7267696491032094

Epoch: 115| Step: 0
Training loss: 2.9607727488074067
Validation loss: 2.7173390549197127

Epoch: 5| Step: 1
Training loss: 2.99889512379159
Validation loss: 2.703673902180877

Epoch: 5| Step: 2
Training loss: 2.4451923767420314
Validation loss: 2.6915761756855052

Epoch: 5| Step: 3
Training loss: 2.9906448092546984
Validation loss: 2.6874380560048983

Epoch: 5| Step: 4
Training loss: 3.374348047653665
Validation loss: 2.685017503994637

Epoch: 5| Step: 5
Training loss: 3.135804077412054
Validation loss: 2.683714869920315

Epoch: 5| Step: 6
Training loss: 3.343015358339861
Validation loss: 2.6823208931655667

Epoch: 5| Step: 7
Training loss: 3.017641964332804
Validation loss: 2.6812152184400073

Epoch: 5| Step: 8
Training loss: 2.742504655804503
Validation loss: 2.6838770067283684

Epoch: 5| Step: 9
Training loss: 2.75698018684781
Validation loss: 2.6797481919725374

Epoch: 5| Step: 10
Training loss: 3.2537799274886923
Validation loss: 2.6829975595147633

Epoch: 116| Step: 0
Training loss: 3.30795768379536
Validation loss: 2.6819663956369046

Epoch: 5| Step: 1
Training loss: 2.8628642154515958
Validation loss: 2.6810536378150727

Epoch: 5| Step: 2
Training loss: 2.139935458983687
Validation loss: 2.6763353828344667

Epoch: 5| Step: 3
Training loss: 3.0429682798960647
Validation loss: 2.6770996275841195

Epoch: 5| Step: 4
Training loss: 3.142015898811817
Validation loss: 2.6823271323245903

Epoch: 5| Step: 5
Training loss: 3.272430192102288
Validation loss: 2.6791473622093

Epoch: 5| Step: 6
Training loss: 3.019871069574903
Validation loss: 2.6785259108379766

Epoch: 5| Step: 7
Training loss: 3.1545822723055013
Validation loss: 2.676334618436427

Epoch: 5| Step: 8
Training loss: 2.769254813232537
Validation loss: 2.68079697399572

Epoch: 5| Step: 9
Training loss: 3.305748591053684
Validation loss: 2.6776730131488087

Epoch: 5| Step: 10
Training loss: 2.889113242248923
Validation loss: 2.6828119149559413

Epoch: 117| Step: 0
Training loss: 2.4718127989146788
Validation loss: 2.682375146984693

Epoch: 5| Step: 1
Training loss: 2.439437976115143
Validation loss: 2.6819977148939658

Epoch: 5| Step: 2
Training loss: 2.8707678785092106
Validation loss: 2.689481199090311

Epoch: 5| Step: 3
Training loss: 3.093192310352404
Validation loss: 2.7020453262954636

Epoch: 5| Step: 4
Training loss: 3.238534804703265
Validation loss: 2.684148077028422

Epoch: 5| Step: 5
Training loss: 3.6442471932191487
Validation loss: 2.6794082973059665

Epoch: 5| Step: 6
Training loss: 2.7390907821457273
Validation loss: 2.679116717735595

Epoch: 5| Step: 7
Training loss: 3.1581178180636322
Validation loss: 2.6768777936848096

Epoch: 5| Step: 8
Training loss: 3.3945997997249937
Validation loss: 2.6798123475565743

Epoch: 5| Step: 9
Training loss: 3.3975514627114127
Validation loss: 2.6803634098692535

Epoch: 5| Step: 10
Training loss: 2.314460644931085
Validation loss: 2.679979087300775

Epoch: 118| Step: 0
Training loss: 3.033832826116378
Validation loss: 2.6787161782604683

Epoch: 5| Step: 1
Training loss: 2.8209915822960645
Validation loss: 2.6749204626670577

Epoch: 5| Step: 2
Training loss: 2.9974646981572977
Validation loss: 2.675506054048876

Epoch: 5| Step: 3
Training loss: 2.769189208179358
Validation loss: 2.673190301846346

Epoch: 5| Step: 4
Training loss: 3.349204489924739
Validation loss: 2.673015047822915

Epoch: 5| Step: 5
Training loss: 3.3598443701441525
Validation loss: 2.6751398024139674

Epoch: 5| Step: 6
Training loss: 2.569095497378815
Validation loss: 2.677872880145725

Epoch: 5| Step: 7
Training loss: 3.1438029897178956
Validation loss: 2.6842466839772605

Epoch: 5| Step: 8
Training loss: 3.0991102849213785
Validation loss: 2.704189506568422

Epoch: 5| Step: 9
Training loss: 2.9476140993664997
Validation loss: 2.708679664245641

Epoch: 5| Step: 10
Training loss: 2.965485394068992
Validation loss: 2.7063508207535323

Epoch: 119| Step: 0
Training loss: 2.7513193953487423
Validation loss: 2.6927343601996796

Epoch: 5| Step: 1
Training loss: 2.2745385928231023
Validation loss: 2.685506068123804

Epoch: 5| Step: 2
Training loss: 3.382857606512207
Validation loss: 2.668622761390329

Epoch: 5| Step: 3
Training loss: 2.7263925056694798
Validation loss: 2.6730857954890372

Epoch: 5| Step: 4
Training loss: 2.9110474725938964
Validation loss: 2.6689994780130393

Epoch: 5| Step: 5
Training loss: 3.4876515673444497
Validation loss: 2.6642797074389817

Epoch: 5| Step: 6
Training loss: 3.1599431856094022
Validation loss: 2.665464996362582

Epoch: 5| Step: 7
Training loss: 3.5143860392810096
Validation loss: 2.665863757109049

Epoch: 5| Step: 8
Training loss: 2.8506446510847003
Validation loss: 2.6632017013313245

Epoch: 5| Step: 9
Training loss: 3.0731262825200383
Validation loss: 2.6624993630038305

Epoch: 5| Step: 10
Training loss: 2.5059172221499213
Validation loss: 2.669713143899537

Epoch: 120| Step: 0
Training loss: 2.6861400268253663
Validation loss: 2.6853450063119824

Epoch: 5| Step: 1
Training loss: 2.742179674968803
Validation loss: 2.6967342641279264

Epoch: 5| Step: 2
Training loss: 2.8174099767158833
Validation loss: 2.7053091716172686

Epoch: 5| Step: 3
Training loss: 3.013483107088298
Validation loss: 2.7368431781491482

Epoch: 5| Step: 4
Training loss: 3.2434528133840526
Validation loss: 2.7555512391435455

Epoch: 5| Step: 5
Training loss: 3.374748361884554
Validation loss: 2.730848206879341

Epoch: 5| Step: 6
Training loss: 2.895424976418381
Validation loss: 2.67529624266167

Epoch: 5| Step: 7
Training loss: 3.3751737761794103
Validation loss: 2.6622661312428453

Epoch: 5| Step: 8
Training loss: 3.183124006755441
Validation loss: 2.662695341229925

Epoch: 5| Step: 9
Training loss: 2.8471843396486345
Validation loss: 2.666596176833465

Epoch: 5| Step: 10
Training loss: 2.9088382475760874
Validation loss: 2.6725780226852853

Epoch: 121| Step: 0
Training loss: 3.4038563288437524
Validation loss: 2.6729749367942874

Epoch: 5| Step: 1
Training loss: 2.964851791511657
Validation loss: 2.675089410585816

Epoch: 5| Step: 2
Training loss: 2.6361414298522745
Validation loss: 2.678039956033342

Epoch: 5| Step: 3
Training loss: 2.881768096880243
Validation loss: 2.6802226287787176

Epoch: 5| Step: 4
Training loss: 3.318408662588277
Validation loss: 2.679255856617647

Epoch: 5| Step: 5
Training loss: 3.13664578059584
Validation loss: 2.683262245700504

Epoch: 5| Step: 6
Training loss: 2.8926767027218454
Validation loss: 2.6800192264644123

Epoch: 5| Step: 7
Training loss: 3.0115404682356983
Validation loss: 2.6779614184726985

Epoch: 5| Step: 8
Training loss: 3.150842547890434
Validation loss: 2.6745429994084597

Epoch: 5| Step: 9
Training loss: 2.5653096124830523
Validation loss: 2.6759251340811843

Epoch: 5| Step: 10
Training loss: 3.226064722120217
Validation loss: 2.6752224025940934

Epoch: 122| Step: 0
Training loss: 2.8362387925351507
Validation loss: 2.6728469672531054

Epoch: 5| Step: 1
Training loss: 3.3615915482285446
Validation loss: 2.6624674629311986

Epoch: 5| Step: 2
Training loss: 2.872974511537705
Validation loss: 2.6625394180925617

Epoch: 5| Step: 3
Training loss: 2.839202598595955
Validation loss: 2.656903125203999

Epoch: 5| Step: 4
Training loss: 2.900735196283018
Validation loss: 2.662130773018623

Epoch: 5| Step: 5
Training loss: 2.815577031784359
Validation loss: 2.685083933972884

Epoch: 5| Step: 6
Training loss: 2.664095254735865
Validation loss: 2.6927819103416186

Epoch: 5| Step: 7
Training loss: 3.053348647860749
Validation loss: 2.7018695272296447

Epoch: 5| Step: 8
Training loss: 2.940805725965436
Validation loss: 2.696775268996646

Epoch: 5| Step: 9
Training loss: 2.964081959115092
Validation loss: 2.6984349133646286

Epoch: 5| Step: 10
Training loss: 3.889718926873525
Validation loss: 2.7081427293318967

Epoch: 123| Step: 0
Training loss: 2.7870635234052514
Validation loss: 2.6682433426643737

Epoch: 5| Step: 1
Training loss: 3.584360611212401
Validation loss: 2.656528328507715

Epoch: 5| Step: 2
Training loss: 2.7327078832511726
Validation loss: 2.654887243242241

Epoch: 5| Step: 3
Training loss: 2.6953912253561727
Validation loss: 2.6577101890524695

Epoch: 5| Step: 4
Training loss: 2.8843211126614916
Validation loss: 2.6586309987362777

Epoch: 5| Step: 5
Training loss: 3.5063030164113753
Validation loss: 2.663951262919345

Epoch: 5| Step: 6
Training loss: 2.8615642567348307
Validation loss: 2.6635439403568713

Epoch: 5| Step: 7
Training loss: 2.7083510667269244
Validation loss: 2.6565765836385498

Epoch: 5| Step: 8
Training loss: 3.3193699834143215
Validation loss: 2.6620186241107175

Epoch: 5| Step: 9
Training loss: 2.7373000712088706
Validation loss: 2.660996528591069

Epoch: 5| Step: 10
Training loss: 3.106082879527233
Validation loss: 2.659632500551432

Epoch: 124| Step: 0
Training loss: 2.867057610253958
Validation loss: 2.6569844281992383

Epoch: 5| Step: 1
Training loss: 2.8322351421754743
Validation loss: 2.654415261835239

Epoch: 5| Step: 2
Training loss: 2.4037372300338955
Validation loss: 2.65546012006473

Epoch: 5| Step: 3
Training loss: 3.9916714747220086
Validation loss: 2.6528537278149087

Epoch: 5| Step: 4
Training loss: 3.020909556161652
Validation loss: 2.6519107919815514

Epoch: 5| Step: 5
Training loss: 3.1058045403657557
Validation loss: 2.650773278970576

Epoch: 5| Step: 6
Training loss: 2.3788262715542756
Validation loss: 2.651523111126612

Epoch: 5| Step: 7
Training loss: 3.211163515178855
Validation loss: 2.6532434129004563

Epoch: 5| Step: 8
Training loss: 3.048163821215854
Validation loss: 2.6601299721697145

Epoch: 5| Step: 9
Training loss: 2.778288389535407
Validation loss: 2.661966422770637

Epoch: 5| Step: 10
Training loss: 3.026983030424765
Validation loss: 2.6763311863056973

Epoch: 125| Step: 0
Training loss: 3.3747182657835433
Validation loss: 2.689721651793109

Epoch: 5| Step: 1
Training loss: 2.973943243751169
Validation loss: 2.6829444840318066

Epoch: 5| Step: 2
Training loss: 2.6563500778194498
Validation loss: 2.6837532125164807

Epoch: 5| Step: 3
Training loss: 2.822512035766565
Validation loss: 2.7094042822737965

Epoch: 5| Step: 4
Training loss: 3.538779813748014
Validation loss: 2.7213053374755654

Epoch: 5| Step: 5
Training loss: 2.4937100438332527
Validation loss: 2.708785297806952

Epoch: 5| Step: 6
Training loss: 2.6144896309363013
Validation loss: 2.700497174757385

Epoch: 5| Step: 7
Training loss: 2.7702549686901987
Validation loss: 2.6810474913133158

Epoch: 5| Step: 8
Training loss: 2.965026930225162
Validation loss: 2.668149566252503

Epoch: 5| Step: 9
Training loss: 2.9856567825756266
Validation loss: 2.6618601360834035

Epoch: 5| Step: 10
Training loss: 3.501738797558042
Validation loss: 2.6557444053268227

Epoch: 126| Step: 0
Training loss: 2.745144285151742
Validation loss: 2.6417759765925632

Epoch: 5| Step: 1
Training loss: 2.993212651267532
Validation loss: 2.64294249570633

Epoch: 5| Step: 2
Training loss: 3.461596424073959
Validation loss: 2.638643365249347

Epoch: 5| Step: 3
Training loss: 2.7013267754019807
Validation loss: 2.6407897042537622

Epoch: 5| Step: 4
Training loss: 3.140585372447057
Validation loss: 2.6418804134113523

Epoch: 5| Step: 5
Training loss: 2.8125522184822547
Validation loss: 2.63958665452101

Epoch: 5| Step: 6
Training loss: 3.9413013576617986
Validation loss: 2.640534878696689

Epoch: 5| Step: 7
Training loss: 2.19245067058124
Validation loss: 2.6459817887498644

Epoch: 5| Step: 8
Training loss: 2.455474602998463
Validation loss: 2.6409289563798404

Epoch: 5| Step: 9
Training loss: 2.470258903525207
Validation loss: 2.646514043107013

Epoch: 5| Step: 10
Training loss: 3.4352423449986857
Validation loss: 2.646391924848578

Epoch: 127| Step: 0
Training loss: 2.9024214599392217
Validation loss: 2.6436132619426904

Epoch: 5| Step: 1
Training loss: 2.5057747901680525
Validation loss: 2.644501915426665

Epoch: 5| Step: 2
Training loss: 2.3892416348607766
Validation loss: 2.6433413071331016

Epoch: 5| Step: 3
Training loss: 3.0722009029955544
Validation loss: 2.651350759602144

Epoch: 5| Step: 4
Training loss: 2.794690776363629
Validation loss: 2.6491613047246116

Epoch: 5| Step: 5
Training loss: 2.98949500472919
Validation loss: 2.651424628261216

Epoch: 5| Step: 6
Training loss: 2.544706017802649
Validation loss: 2.6461626948728414

Epoch: 5| Step: 7
Training loss: 3.581920226861101
Validation loss: 2.64565506685731

Epoch: 5| Step: 8
Training loss: 3.3620464260111427
Validation loss: 2.641272369211305

Epoch: 5| Step: 9
Training loss: 3.358068593636144
Validation loss: 2.6444708898351488

Epoch: 5| Step: 10
Training loss: 2.9489980450840703
Validation loss: 2.642005654129276

Epoch: 128| Step: 0
Training loss: 3.3129449221669853
Validation loss: 2.6394664147193367

Epoch: 5| Step: 1
Training loss: 2.2726408621226755
Validation loss: 2.6414745576034218

Epoch: 5| Step: 2
Training loss: 3.2942336652063715
Validation loss: 2.6443577146904023

Epoch: 5| Step: 3
Training loss: 3.1163480388400346
Validation loss: 2.646258018684134

Epoch: 5| Step: 4
Training loss: 2.874333179930268
Validation loss: 2.6425526881054973

Epoch: 5| Step: 5
Training loss: 3.3063927257285224
Validation loss: 2.64726449288879

Epoch: 5| Step: 6
Training loss: 2.6809454542656326
Validation loss: 2.6348391578683534

Epoch: 5| Step: 7
Training loss: 2.8481424803508175
Validation loss: 2.6344944208727177

Epoch: 5| Step: 8
Training loss: 2.748837832322191
Validation loss: 2.6307094155555153

Epoch: 5| Step: 9
Training loss: 3.1774564596895196
Validation loss: 2.6335413642552274

Epoch: 5| Step: 10
Training loss: 2.844154412993636
Validation loss: 2.6291104044706755

Epoch: 129| Step: 0
Training loss: 2.691247500760858
Validation loss: 2.634497219522239

Epoch: 5| Step: 1
Training loss: 3.1403028028719757
Validation loss: 2.640010801386745

Epoch: 5| Step: 2
Training loss: 2.8198769357220517
Validation loss: 2.6407037713406565

Epoch: 5| Step: 3
Training loss: 3.279505529348717
Validation loss: 2.648622550456195

Epoch: 5| Step: 4
Training loss: 3.328194057840604
Validation loss: 2.6454853729842136

Epoch: 5| Step: 5
Training loss: 2.897226743937404
Validation loss: 2.637723386389101

Epoch: 5| Step: 6
Training loss: 3.299420427232584
Validation loss: 2.6381428719927893

Epoch: 5| Step: 7
Training loss: 2.8676612732824096
Validation loss: 2.6349916872205252

Epoch: 5| Step: 8
Training loss: 2.573457967263355
Validation loss: 2.634691525720559

Epoch: 5| Step: 9
Training loss: 2.7072998618197213
Validation loss: 2.6344185730299903

Epoch: 5| Step: 10
Training loss: 2.8359517919427235
Validation loss: 2.6349126886846155

Epoch: 130| Step: 0
Training loss: 2.684261055816197
Validation loss: 2.6386431223555187

Epoch: 5| Step: 1
Training loss: 2.7462293610385453
Validation loss: 2.6679441922666074

Epoch: 5| Step: 2
Training loss: 3.41338057003516
Validation loss: 2.671736340324121

Epoch: 5| Step: 3
Training loss: 2.901357490885429
Validation loss: 2.669248247188611

Epoch: 5| Step: 4
Training loss: 2.971270485094425
Validation loss: 2.6733319413832546

Epoch: 5| Step: 5
Training loss: 3.2725454494272337
Validation loss: 2.663935437105988

Epoch: 5| Step: 6
Training loss: 3.012284875050338
Validation loss: 2.6468282535427727

Epoch: 5| Step: 7
Training loss: 2.8616759001002117
Validation loss: 2.647617981993255

Epoch: 5| Step: 8
Training loss: 2.596669220374259
Validation loss: 2.6306939179498605

Epoch: 5| Step: 9
Training loss: 2.909054131437954
Validation loss: 2.6290126188367418

Epoch: 5| Step: 10
Training loss: 3.1905598632858996
Validation loss: 2.626881409115338

Epoch: 131| Step: 0
Training loss: 3.2168843315942284
Validation loss: 2.630270597162976

Epoch: 5| Step: 1
Training loss: 2.4426045887164887
Validation loss: 2.633476244009553

Epoch: 5| Step: 2
Training loss: 3.2659844743648114
Validation loss: 2.6373656092801507

Epoch: 5| Step: 3
Training loss: 3.28067607401653
Validation loss: 2.6394221194740686

Epoch: 5| Step: 4
Training loss: 2.951994179882732
Validation loss: 2.6442910788752148

Epoch: 5| Step: 5
Training loss: 3.112267610384734
Validation loss: 2.6467258813749845

Epoch: 5| Step: 6
Training loss: 2.621395724734115
Validation loss: 2.6453389629722315

Epoch: 5| Step: 7
Training loss: 2.6231055917083217
Validation loss: 2.647123637603276

Epoch: 5| Step: 8
Training loss: 3.1157220058204342
Validation loss: 2.64703111777155

Epoch: 5| Step: 9
Training loss: 2.989110893818909
Validation loss: 2.6454658424267525

Epoch: 5| Step: 10
Training loss: 3.278738023079431
Validation loss: 2.6441319519643116

Epoch: 132| Step: 0
Training loss: 3.340137562460149
Validation loss: 2.6447051917120565

Epoch: 5| Step: 1
Training loss: 3.0937916145993785
Validation loss: 2.647106969338422

Epoch: 5| Step: 2
Training loss: 2.868805556081401
Validation loss: 2.6452535844023704

Epoch: 5| Step: 3
Training loss: 2.7119729650719697
Validation loss: 2.6440585204613494

Epoch: 5| Step: 4
Training loss: 3.1499071501111406
Validation loss: 2.647586590591301

Epoch: 5| Step: 5
Training loss: 3.4229393266209125
Validation loss: 2.6463222935199266

Epoch: 5| Step: 6
Training loss: 3.1620004975658125
Validation loss: 2.6470328571908706

Epoch: 5| Step: 7
Training loss: 2.9232344295367927
Validation loss: 2.6446074912251087

Epoch: 5| Step: 8
Training loss: 2.417630617228588
Validation loss: 2.6468670367717637

Epoch: 5| Step: 9
Training loss: 2.9208679095592074
Validation loss: 2.644814311913641

Epoch: 5| Step: 10
Training loss: 2.7843703007685163
Validation loss: 2.64664920910647

Epoch: 133| Step: 0
Training loss: 3.3306077463279733
Validation loss: 2.64631682973037

Epoch: 5| Step: 1
Training loss: 3.2958815103731993
Validation loss: 2.641399648792877

Epoch: 5| Step: 2
Training loss: 2.6896025838441253
Validation loss: 2.641486015701934

Epoch: 5| Step: 3
Training loss: 2.8200308957673275
Validation loss: 2.6424354753796715

Epoch: 5| Step: 4
Training loss: 2.8330847313217853
Validation loss: 2.6392032402237193

Epoch: 5| Step: 5
Training loss: 2.2705551700370297
Validation loss: 2.650975881925154

Epoch: 5| Step: 6
Training loss: 3.3911327913518137
Validation loss: 2.644390919025812

Epoch: 5| Step: 7
Training loss: 2.89923150633604
Validation loss: 2.6414177147616607

Epoch: 5| Step: 8
Training loss: 2.768338612462047
Validation loss: 2.644473068152996

Epoch: 5| Step: 9
Training loss: 2.9533235997828244
Validation loss: 2.649924082683416

Epoch: 5| Step: 10
Training loss: 3.3975225510455824
Validation loss: 2.6503886962649528

Epoch: 134| Step: 0
Training loss: 3.3342114881270795
Validation loss: 2.627298608060669

Epoch: 5| Step: 1
Training loss: 2.848572216102151
Validation loss: 2.6282637810828344

Epoch: 5| Step: 2
Training loss: 2.9226548077361283
Validation loss: 2.628273890723448

Epoch: 5| Step: 3
Training loss: 2.577325870466931
Validation loss: 2.6315066068579833

Epoch: 5| Step: 4
Training loss: 3.151121751172184
Validation loss: 2.6238634419679046

Epoch: 5| Step: 5
Training loss: 2.7519124923532847
Validation loss: 2.6352806680408842

Epoch: 5| Step: 6
Training loss: 2.6044224321015945
Validation loss: 2.63866597468055

Epoch: 5| Step: 7
Training loss: 3.096133152308888
Validation loss: 2.635352132009447

Epoch: 5| Step: 8
Training loss: 2.849903868007615
Validation loss: 2.640455022667343

Epoch: 5| Step: 9
Training loss: 3.4145465568779283
Validation loss: 2.6205352515351246

Epoch: 5| Step: 10
Training loss: 2.7654050750359205
Validation loss: 2.6193826441291983

Epoch: 135| Step: 0
Training loss: 3.093340143355185
Validation loss: 2.618588502390562

Epoch: 5| Step: 1
Training loss: 3.3872548595283525
Validation loss: 2.6161299685791164

Epoch: 5| Step: 2
Training loss: 2.745048747368113
Validation loss: 2.6166591982254515

Epoch: 5| Step: 3
Training loss: 3.002801223115988
Validation loss: 2.618549333616412

Epoch: 5| Step: 4
Training loss: 2.7055714732316973
Validation loss: 2.6348636836116235

Epoch: 5| Step: 5
Training loss: 3.393043885792385
Validation loss: 2.647764792701472

Epoch: 5| Step: 6
Training loss: 2.4861433345569917
Validation loss: 2.6484246858192484

Epoch: 5| Step: 7
Training loss: 2.7157915176242278
Validation loss: 2.6427111544173583

Epoch: 5| Step: 8
Training loss: 3.083526055438856
Validation loss: 2.6164801675023366

Epoch: 5| Step: 9
Training loss: 3.0330305081074194
Validation loss: 2.6087341661353673

Epoch: 5| Step: 10
Training loss: 2.630308958841836
Validation loss: 2.610910157734406

Epoch: 136| Step: 0
Training loss: 2.6967144402263368
Validation loss: 2.6162312851676974

Epoch: 5| Step: 1
Training loss: 2.09982352650604
Validation loss: 2.618272112224923

Epoch: 5| Step: 2
Training loss: 3.7968585481012527
Validation loss: 2.616137954067569

Epoch: 5| Step: 3
Training loss: 2.5461364798692734
Validation loss: 2.6155850437438164

Epoch: 5| Step: 4
Training loss: 3.5950370805761898
Validation loss: 2.6155180483275022

Epoch: 5| Step: 5
Training loss: 2.298011757989057
Validation loss: 2.610195278319111

Epoch: 5| Step: 6
Training loss: 3.015002092452454
Validation loss: 2.6063525526180062

Epoch: 5| Step: 7
Training loss: 3.40774615265609
Validation loss: 2.605847408873537

Epoch: 5| Step: 8
Training loss: 2.7293816013487837
Validation loss: 2.6012244955446193

Epoch: 5| Step: 9
Training loss: 3.1100714588848466
Validation loss: 2.606495984930156

Epoch: 5| Step: 10
Training loss: 2.8938972715798035
Validation loss: 2.6105024704337776

Epoch: 137| Step: 0
Training loss: 2.824825321974867
Validation loss: 2.618468019923916

Epoch: 5| Step: 1
Training loss: 2.754385918581974
Validation loss: 2.6316516812710633

Epoch: 5| Step: 2
Training loss: 3.229521717528281
Validation loss: 2.644948589700666

Epoch: 5| Step: 3
Training loss: 2.976497459201635
Validation loss: 2.6734582594595833

Epoch: 5| Step: 4
Training loss: 2.7668886907569257
Validation loss: 2.670816258398665

Epoch: 5| Step: 5
Training loss: 2.926749829245452
Validation loss: 2.642400259515847

Epoch: 5| Step: 6
Training loss: 2.978577740131002
Validation loss: 2.616501077439614

Epoch: 5| Step: 7
Training loss: 2.369999993078819
Validation loss: 2.6028355644934646

Epoch: 5| Step: 8
Training loss: 3.4734535288987867
Validation loss: 2.5995479126013348

Epoch: 5| Step: 9
Training loss: 2.9484907653881334
Validation loss: 2.6008917028012153

Epoch: 5| Step: 10
Training loss: 3.1816634053819213
Validation loss: 2.608164916828901

Epoch: 138| Step: 0
Training loss: 2.7670715342195766
Validation loss: 2.609921740066345

Epoch: 5| Step: 1
Training loss: 3.2335852796835787
Validation loss: 2.605144890602595

Epoch: 5| Step: 2
Training loss: 3.048754616046084
Validation loss: 2.6021619320068856

Epoch: 5| Step: 3
Training loss: 2.8885627607328996
Validation loss: 2.6020353439946087

Epoch: 5| Step: 4
Training loss: 3.2262639607271923
Validation loss: 2.599998714866352

Epoch: 5| Step: 5
Training loss: 2.7247022168601736
Validation loss: 2.6056208872293394

Epoch: 5| Step: 6
Training loss: 3.1764568440757053
Validation loss: 2.612725245798431

Epoch: 5| Step: 7
Training loss: 3.3886742671551353
Validation loss: 2.627236502945655

Epoch: 5| Step: 8
Training loss: 2.198265180632747
Validation loss: 2.6287968283406857

Epoch: 5| Step: 9
Training loss: 2.5566612341904733
Validation loss: 2.656878184402229

Epoch: 5| Step: 10
Training loss: 2.8870662743281943
Validation loss: 2.6752627674086544

Epoch: 139| Step: 0
Training loss: 2.6760478311549116
Validation loss: 2.6748774474650125

Epoch: 5| Step: 1
Training loss: 3.2697508816799896
Validation loss: 2.648849082166411

Epoch: 5| Step: 2
Training loss: 2.721120217715089
Validation loss: 2.6332277004846376

Epoch: 5| Step: 3
Training loss: 3.3638518554961805
Validation loss: 2.6229189227932594

Epoch: 5| Step: 4
Training loss: 2.957693290424098
Validation loss: 2.6136923664530705

Epoch: 5| Step: 5
Training loss: 2.3527803530848477
Validation loss: 2.609385984025669

Epoch: 5| Step: 6
Training loss: 3.0533497410406953
Validation loss: 2.605882322334282

Epoch: 5| Step: 7
Training loss: 2.6903617171824696
Validation loss: 2.606591151797528

Epoch: 5| Step: 8
Training loss: 3.1974830623413726
Validation loss: 2.6064785999882902

Epoch: 5| Step: 9
Training loss: 3.06704592501918
Validation loss: 2.6089501455363884

Epoch: 5| Step: 10
Training loss: 2.8598825806742734
Validation loss: 2.619768733205536

Epoch: 140| Step: 0
Training loss: 2.473244932947817
Validation loss: 2.623939861644613

Epoch: 5| Step: 1
Training loss: 3.2080088529773807
Validation loss: 2.630609717861867

Epoch: 5| Step: 2
Training loss: 2.715514439130902
Validation loss: 2.640836583560007

Epoch: 5| Step: 3
Training loss: 2.830522732663441
Validation loss: 2.6492594478815072

Epoch: 5| Step: 4
Training loss: 3.3579927661447497
Validation loss: 2.6337298344617377

Epoch: 5| Step: 5
Training loss: 2.878659283048847
Validation loss: 2.634824879376951

Epoch: 5| Step: 6
Training loss: 2.854681613625824
Validation loss: 2.6280945450262636

Epoch: 5| Step: 7
Training loss: 3.045662976330944
Validation loss: 2.6250739284951448

Epoch: 5| Step: 8
Training loss: 2.8345944085204553
Validation loss: 2.620320390911295

Epoch: 5| Step: 9
Training loss: 3.1085769932811282
Validation loss: 2.6292848047376096

Epoch: 5| Step: 10
Training loss: 2.737242671768952
Validation loss: 2.6118760129320937

Epoch: 141| Step: 0
Training loss: 2.9704331294753246
Validation loss: 2.6070917279144283

Epoch: 5| Step: 1
Training loss: 2.9012776158443057
Validation loss: 2.6120791282334226

Epoch: 5| Step: 2
Training loss: 2.928512134018194
Validation loss: 2.6043907262744286

Epoch: 5| Step: 3
Training loss: 2.1999876802272906
Validation loss: 2.6032793176449536

Epoch: 5| Step: 4
Training loss: 2.9114852840334033
Validation loss: 2.6025497897122776

Epoch: 5| Step: 5
Training loss: 3.1432723848563286
Validation loss: 2.600859695681944

Epoch: 5| Step: 6
Training loss: 3.395246880253136
Validation loss: 2.603536078287002

Epoch: 5| Step: 7
Training loss: 2.755450050024484
Validation loss: 2.6066220484770426

Epoch: 5| Step: 8
Training loss: 3.3495726469378533
Validation loss: 2.612674834500056

Epoch: 5| Step: 9
Training loss: 3.0036028843990694
Validation loss: 2.626562130313539

Epoch: 5| Step: 10
Training loss: 2.3627733425674093
Validation loss: 2.6420170924584654

Epoch: 142| Step: 0
Training loss: 3.208084509642522
Validation loss: 2.6528732291079242

Epoch: 5| Step: 1
Training loss: 2.945975555339224
Validation loss: 2.6625847710873702

Epoch: 5| Step: 2
Training loss: 2.1638144891517697
Validation loss: 2.6541948469177963

Epoch: 5| Step: 3
Training loss: 3.051278399843589
Validation loss: 2.6336290985728565

Epoch: 5| Step: 4
Training loss: 2.6863819724318136
Validation loss: 2.6242644436251434

Epoch: 5| Step: 5
Training loss: 3.1517819042175064
Validation loss: 2.6071763305894433

Epoch: 5| Step: 6
Training loss: 2.7106098779595604
Validation loss: 2.607569792630904

Epoch: 5| Step: 7
Training loss: 3.2289604531350578
Validation loss: 2.602172263741295

Epoch: 5| Step: 8
Training loss: 2.749843766369449
Validation loss: 2.5983973012711226

Epoch: 5| Step: 9
Training loss: 3.2885785324419556
Validation loss: 2.602541798977636

Epoch: 5| Step: 10
Training loss: 2.73982132336064
Validation loss: 2.60306193950183

Epoch: 143| Step: 0
Training loss: 2.960497015646339
Validation loss: 2.600288585473888

Epoch: 5| Step: 1
Training loss: 2.948319658068362
Validation loss: 2.6133357363832754

Epoch: 5| Step: 2
Training loss: 2.324728517166646
Validation loss: 2.6106246904114734

Epoch: 5| Step: 3
Training loss: 3.0368857936192346
Validation loss: 2.6331457369791083

Epoch: 5| Step: 4
Training loss: 2.8436980190347065
Validation loss: 2.624539805211212

Epoch: 5| Step: 5
Training loss: 2.883395169721443
Validation loss: 2.626941933367704

Epoch: 5| Step: 6
Training loss: 3.248771288494887
Validation loss: 2.6342884794020756

Epoch: 5| Step: 7
Training loss: 2.7029600589241345
Validation loss: 2.631198163567243

Epoch: 5| Step: 8
Training loss: 2.7467824145652835
Validation loss: 2.630447333625335

Epoch: 5| Step: 9
Training loss: 2.842758676640654
Validation loss: 2.6228598637181197

Epoch: 5| Step: 10
Training loss: 3.530920097672138
Validation loss: 2.6046404181625733

Epoch: 144| Step: 0
Training loss: 2.549926427640012
Validation loss: 2.5964878071867012

Epoch: 5| Step: 1
Training loss: 2.882822589804921
Validation loss: 2.600632377815717

Epoch: 5| Step: 2
Training loss: 3.049431926167013
Validation loss: 2.598788646718874

Epoch: 5| Step: 3
Training loss: 3.3319621285785557
Validation loss: 2.6084988819047514

Epoch: 5| Step: 4
Training loss: 2.764901880244424
Validation loss: 2.6052559797101495

Epoch: 5| Step: 5
Training loss: 3.0262217552886996
Validation loss: 2.6026620356640264

Epoch: 5| Step: 6
Training loss: 2.8480216002555987
Validation loss: 2.5989800434873223

Epoch: 5| Step: 7
Training loss: 3.2186205199040567
Validation loss: 2.599543068445752

Epoch: 5| Step: 8
Training loss: 2.5928915050801296
Validation loss: 2.6045429432065954

Epoch: 5| Step: 9
Training loss: 2.9846766454231477
Validation loss: 2.613828030206144

Epoch: 5| Step: 10
Training loss: 2.9292825240930638
Validation loss: 2.62900142231975

Epoch: 145| Step: 0
Training loss: 2.349398710552864
Validation loss: 2.6518986732207934

Epoch: 5| Step: 1
Training loss: 3.245879128312204
Validation loss: 2.687925499182733

Epoch: 5| Step: 2
Training loss: 3.0125528607934347
Validation loss: 2.690984453607275

Epoch: 5| Step: 3
Training loss: 3.044359313009715
Validation loss: 2.7025726169361217

Epoch: 5| Step: 4
Training loss: 2.88655157986019
Validation loss: 2.6778829111582003

Epoch: 5| Step: 5
Training loss: 2.5077144805671443
Validation loss: 2.6380607541141123

Epoch: 5| Step: 6
Training loss: 3.182808209258583
Validation loss: 2.6075332033439946

Epoch: 5| Step: 7
Training loss: 2.726603597861377
Validation loss: 2.595293499308928

Epoch: 5| Step: 8
Training loss: 2.832657864406188
Validation loss: 2.588424725203046

Epoch: 5| Step: 9
Training loss: 3.1112346359737972
Validation loss: 2.5882405055345505

Epoch: 5| Step: 10
Training loss: 3.1921515837603347
Validation loss: 2.5923381490933304

Epoch: 146| Step: 0
Training loss: 3.0155494166572296
Validation loss: 2.5952049441558716

Epoch: 5| Step: 1
Training loss: 3.0954643662856687
Validation loss: 2.5909020862320125

Epoch: 5| Step: 2
Training loss: 3.1860180570063177
Validation loss: 2.5926451234294117

Epoch: 5| Step: 3
Training loss: 3.0175607427695157
Validation loss: 2.5925532848269452

Epoch: 5| Step: 4
Training loss: 3.3341820272218814
Validation loss: 2.5852384882480997

Epoch: 5| Step: 5
Training loss: 3.1812713202640803
Validation loss: 2.578946680888891

Epoch: 5| Step: 6
Training loss: 2.5003167905366612
Validation loss: 2.5823100111146045

Epoch: 5| Step: 7
Training loss: 2.6702199349562195
Validation loss: 2.5866263106405185

Epoch: 5| Step: 8
Training loss: 2.7301667009536867
Validation loss: 2.5978277753807952

Epoch: 5| Step: 9
Training loss: 2.8864491585886607
Validation loss: 2.5948947683686012

Epoch: 5| Step: 10
Training loss: 2.4734822561392162
Validation loss: 2.6015750670746174

Epoch: 147| Step: 0
Training loss: 3.3179036816027474
Validation loss: 2.615343829864127

Epoch: 5| Step: 1
Training loss: 2.9282812380150807
Validation loss: 2.599833387245771

Epoch: 5| Step: 2
Training loss: 3.080809066824101
Validation loss: 2.6165857932600787

Epoch: 5| Step: 3
Training loss: 2.747303854802299
Validation loss: 2.623786840283336

Epoch: 5| Step: 4
Training loss: 2.411598207002531
Validation loss: 2.6510592117823344

Epoch: 5| Step: 5
Training loss: 3.0158934794873407
Validation loss: 2.6520413416289923

Epoch: 5| Step: 6
Training loss: 3.177431548166873
Validation loss: 2.636096868673167

Epoch: 5| Step: 7
Training loss: 2.7681447420258167
Validation loss: 2.6161443883015463

Epoch: 5| Step: 8
Training loss: 3.3464232124696314
Validation loss: 2.5886307115471094

Epoch: 5| Step: 9
Training loss: 2.6299295006937706
Validation loss: 2.5827900781410045

Epoch: 5| Step: 10
Training loss: 2.3991394009972575
Validation loss: 2.5796894595734874

Epoch: 148| Step: 0
Training loss: 3.036446276335991
Validation loss: 2.5758679804441726

Epoch: 5| Step: 1
Training loss: 2.7878985714461764
Validation loss: 2.5798133539797896

Epoch: 5| Step: 2
Training loss: 2.724788405576399
Validation loss: 2.581560208801853

Epoch: 5| Step: 3
Training loss: 3.1262053644592713
Validation loss: 2.585035678830485

Epoch: 5| Step: 4
Training loss: 3.0354438949826434
Validation loss: 2.579552912743307

Epoch: 5| Step: 5
Training loss: 2.668756282182576
Validation loss: 2.579172644827832

Epoch: 5| Step: 6
Training loss: 2.810618640229959
Validation loss: 2.5776330194435317

Epoch: 5| Step: 7
Training loss: 3.071535754947498
Validation loss: 2.578307109627047

Epoch: 5| Step: 8
Training loss: 2.5820123207217915
Validation loss: 2.5811636291767037

Epoch: 5| Step: 9
Training loss: 3.1895577763373013
Validation loss: 2.5850043877811744

Epoch: 5| Step: 10
Training loss: 3.069801812251714
Validation loss: 2.59102610146908

Epoch: 149| Step: 0
Training loss: 2.8589325442660543
Validation loss: 2.5966950376284657

Epoch: 5| Step: 1
Training loss: 2.5578049237250347
Validation loss: 2.6293367374314056

Epoch: 5| Step: 2
Training loss: 2.9461610416647037
Validation loss: 2.6351104364506934

Epoch: 5| Step: 3
Training loss: 2.816984543178025
Validation loss: 2.6774340741726124

Epoch: 5| Step: 4
Training loss: 3.2240386772107557
Validation loss: 2.6950184622907343

Epoch: 5| Step: 5
Training loss: 3.3087394529145007
Validation loss: 2.6432351308347486

Epoch: 5| Step: 6
Training loss: 3.177561656194645
Validation loss: 2.6061294469944274

Epoch: 5| Step: 7
Training loss: 2.6770406835896683
Validation loss: 2.5800363803176802

Epoch: 5| Step: 8
Training loss: 3.359738494369661
Validation loss: 2.5759579816016873

Epoch: 5| Step: 9
Training loss: 2.5423809256938243
Validation loss: 2.576938220512791

Epoch: 5| Step: 10
Training loss: 2.626800464604643
Validation loss: 2.577271220616452

Epoch: 150| Step: 0
Training loss: 3.3531292718893893
Validation loss: 2.5830042732351455

Epoch: 5| Step: 1
Training loss: 2.2151476131878143
Validation loss: 2.579525043573153

Epoch: 5| Step: 2
Training loss: 3.09959152976117
Validation loss: 2.5767738876392094

Epoch: 5| Step: 3
Training loss: 3.229809030609479
Validation loss: 2.576802099955347

Epoch: 5| Step: 4
Training loss: 2.877815526504408
Validation loss: 2.5741616629175694

Epoch: 5| Step: 5
Training loss: 3.0151309858877684
Validation loss: 2.575695804858017

Epoch: 5| Step: 6
Training loss: 2.817657658279347
Validation loss: 2.5838275268683417

Epoch: 5| Step: 7
Training loss: 2.5517574387676727
Validation loss: 2.584329398850111

Epoch: 5| Step: 8
Training loss: 2.757056632483134
Validation loss: 2.5905167914576186

Epoch: 5| Step: 9
Training loss: 3.1378583726207236
Validation loss: 2.590335428378478

Epoch: 5| Step: 10
Training loss: 2.847630965090506
Validation loss: 2.6022243138968415

Epoch: 151| Step: 0
Training loss: 2.977175671956469
Validation loss: 2.615127117336489

Epoch: 5| Step: 1
Training loss: 2.7146055707120724
Validation loss: 2.628664052466737

Epoch: 5| Step: 2
Training loss: 3.0831655680061636
Validation loss: 2.641321111735044

Epoch: 5| Step: 3
Training loss: 2.6631897870061327
Validation loss: 2.6500584101571394

Epoch: 5| Step: 4
Training loss: 3.4013838700513226
Validation loss: 2.6337336277514787

Epoch: 5| Step: 5
Training loss: 2.806061814419196
Validation loss: 2.6092588523975513

Epoch: 5| Step: 6
Training loss: 3.250061034583139
Validation loss: 2.5904523482438484

Epoch: 5| Step: 7
Training loss: 2.5523029362661673
Validation loss: 2.5834936303280784

Epoch: 5| Step: 8
Training loss: 3.0910094482020773
Validation loss: 2.5798026311026

Epoch: 5| Step: 9
Training loss: 2.8929214840416235
Validation loss: 2.5752083377602912

Epoch: 5| Step: 10
Training loss: 2.2778601347241403
Validation loss: 2.5732082005652996

Epoch: 152| Step: 0
Training loss: 3.0261650301047216
Validation loss: 2.5726510622785317

Epoch: 5| Step: 1
Training loss: 2.471089473869008
Validation loss: 2.5716076601910602

Epoch: 5| Step: 2
Training loss: 2.8860181234402678
Validation loss: 2.570554343196807

Epoch: 5| Step: 3
Training loss: 2.3595825508229096
Validation loss: 2.571318421740823

Epoch: 5| Step: 4
Training loss: 3.080940159816737
Validation loss: 2.5753749555303314

Epoch: 5| Step: 5
Training loss: 2.94560470952865
Validation loss: 2.579760095408101

Epoch: 5| Step: 6
Training loss: 2.8712417253002194
Validation loss: 2.5800061007913504

Epoch: 5| Step: 7
Training loss: 3.582065594590668
Validation loss: 2.5941303101366144

Epoch: 5| Step: 8
Training loss: 2.703242834091743
Validation loss: 2.5794246685354296

Epoch: 5| Step: 9
Training loss: 2.422129956023158
Validation loss: 2.5733017806144645

Epoch: 5| Step: 10
Training loss: 3.3837567920990086
Validation loss: 2.5726132937453707

Epoch: 153| Step: 0
Training loss: 2.883342745844595
Validation loss: 2.5726443289353678

Epoch: 5| Step: 1
Training loss: 2.7426061935520667
Validation loss: 2.5723088571871795

Epoch: 5| Step: 2
Training loss: 2.664263138808729
Validation loss: 2.5688694693525203

Epoch: 5| Step: 3
Training loss: 3.005699148487057
Validation loss: 2.5739513454208853

Epoch: 5| Step: 4
Training loss: 2.45970059751567
Validation loss: 2.572567405940501

Epoch: 5| Step: 5
Training loss: 2.8277270632503204
Validation loss: 2.5799757831502466

Epoch: 5| Step: 6
Training loss: 2.9655087093469144
Validation loss: 2.585497788611919

Epoch: 5| Step: 7
Training loss: 3.104269619115592
Validation loss: 2.5851401488400585

Epoch: 5| Step: 8
Training loss: 2.7410529851847687
Validation loss: 2.583734526494887

Epoch: 5| Step: 9
Training loss: 3.2372376678111707
Validation loss: 2.5799924469169753

Epoch: 5| Step: 10
Training loss: 3.21642463906762
Validation loss: 2.5888724536747576

Epoch: 154| Step: 0
Training loss: 2.8376027832236996
Validation loss: 2.588310219632632

Epoch: 5| Step: 1
Training loss: 3.22461292398351
Validation loss: 2.5915435289590953

Epoch: 5| Step: 2
Training loss: 2.4768566835329247
Validation loss: 2.6038448372783707

Epoch: 5| Step: 3
Training loss: 3.244723511659238
Validation loss: 2.604526494587827

Epoch: 5| Step: 4
Training loss: 2.939690929438011
Validation loss: 2.5964762117296507

Epoch: 5| Step: 5
Training loss: 3.0692458301878474
Validation loss: 2.5932419881474535

Epoch: 5| Step: 6
Training loss: 3.317765998439002
Validation loss: 2.61390759143242

Epoch: 5| Step: 7
Training loss: 2.9729902002177573
Validation loss: 2.613418355514693

Epoch: 5| Step: 8
Training loss: 2.578180670859635
Validation loss: 2.598923956031091

Epoch: 5| Step: 9
Training loss: 2.241574193566854
Validation loss: 2.5865668471026697

Epoch: 5| Step: 10
Training loss: 2.70562848713686
Validation loss: 2.580865950586519

Epoch: 155| Step: 0
Training loss: 3.1523340690681585
Validation loss: 2.5693409782965717

Epoch: 5| Step: 1
Training loss: 3.368044007446487
Validation loss: 2.572213592527519

Epoch: 5| Step: 2
Training loss: 2.5365337279679325
Validation loss: 2.5727452644554245

Epoch: 5| Step: 3
Training loss: 3.052214184626139
Validation loss: 2.5707726691119426

Epoch: 5| Step: 4
Training loss: 2.854543136679675
Validation loss: 2.5792294778706113

Epoch: 5| Step: 5
Training loss: 2.528348979293838
Validation loss: 2.5727416612494802

Epoch: 5| Step: 6
Training loss: 2.9332866888961555
Validation loss: 2.5879960921952665

Epoch: 5| Step: 7
Training loss: 2.7098816676187796
Validation loss: 2.6110502351000346

Epoch: 5| Step: 8
Training loss: 3.0507287327425967
Validation loss: 2.621085289590186

Epoch: 5| Step: 9
Training loss: 2.6551198013489676
Validation loss: 2.6315503875011657

Epoch: 5| Step: 10
Training loss: 2.8827402162664573
Validation loss: 2.629725900171911

Epoch: 156| Step: 0
Training loss: 2.9115064113152633
Validation loss: 2.6254548607981545

Epoch: 5| Step: 1
Training loss: 2.9145181826294104
Validation loss: 2.618022520894987

Epoch: 5| Step: 2
Training loss: 2.723115594938268
Validation loss: 2.604394575093032

Epoch: 5| Step: 3
Training loss: 3.4839637411006734
Validation loss: 2.5992864612514364

Epoch: 5| Step: 4
Training loss: 2.622674365942701
Validation loss: 2.595602363209646

Epoch: 5| Step: 5
Training loss: 2.873325191790146
Validation loss: 2.5888056879260186

Epoch: 5| Step: 6
Training loss: 2.789188756141993
Validation loss: 2.5818196988614375

Epoch: 5| Step: 7
Training loss: 2.7047361302315034
Validation loss: 2.577545164451841

Epoch: 5| Step: 8
Training loss: 3.371996213980978
Validation loss: 2.5751937515350063

Epoch: 5| Step: 9
Training loss: 2.459309066412142
Validation loss: 2.5741070604214547

Epoch: 5| Step: 10
Training loss: 2.5840400118903997
Validation loss: 2.5688847481441743

Epoch: 157| Step: 0
Training loss: 3.1036881626343304
Validation loss: 2.5616932421105902

Epoch: 5| Step: 1
Training loss: 3.1888039109814246
Validation loss: 2.560082363351835

Epoch: 5| Step: 2
Training loss: 2.240898160364391
Validation loss: 2.563637757748721

Epoch: 5| Step: 3
Training loss: 2.7270523986538397
Validation loss: 2.5614519874969117

Epoch: 5| Step: 4
Training loss: 3.021655599998524
Validation loss: 2.5580763231559556

Epoch: 5| Step: 5
Training loss: 2.704933752070165
Validation loss: 2.563496344689736

Epoch: 5| Step: 6
Training loss: 2.7697298438747664
Validation loss: 2.5608968975066837

Epoch: 5| Step: 7
Training loss: 2.7780006372273913
Validation loss: 2.5633425104158927

Epoch: 5| Step: 8
Training loss: 3.315260115094637
Validation loss: 2.569924346283855

Epoch: 5| Step: 9
Training loss: 2.7936857143575526
Validation loss: 2.57966861199807

Epoch: 5| Step: 10
Training loss: 2.9395100635577562
Validation loss: 2.583554535947636

Epoch: 158| Step: 0
Training loss: 2.2997714094925152
Validation loss: 2.589936587422539

Epoch: 5| Step: 1
Training loss: 3.1050817860322484
Validation loss: 2.578930686333422

Epoch: 5| Step: 2
Training loss: 2.6166942530188235
Validation loss: 2.591281853701131

Epoch: 5| Step: 3
Training loss: 3.529154062680223
Validation loss: 2.5916462785641445

Epoch: 5| Step: 4
Training loss: 2.8234742424521118
Validation loss: 2.5824680999789154

Epoch: 5| Step: 5
Training loss: 3.227303703833487
Validation loss: 2.5704918948489026

Epoch: 5| Step: 6
Training loss: 2.904505544527488
Validation loss: 2.583495762813093

Epoch: 5| Step: 7
Training loss: 2.390691818600004
Validation loss: 2.5772256002687315

Epoch: 5| Step: 8
Training loss: 2.494287162425152
Validation loss: 2.5650325358918575

Epoch: 5| Step: 9
Training loss: 3.2579146627603834
Validation loss: 2.5759737278981922

Epoch: 5| Step: 10
Training loss: 2.6492568467510607
Validation loss: 2.5631438336133017

Epoch: 159| Step: 0
Training loss: 2.88573111646565
Validation loss: 2.5657075905011446

Epoch: 5| Step: 1
Training loss: 2.7570820562405736
Validation loss: 2.558648927029923

Epoch: 5| Step: 2
Training loss: 3.048793716774129
Validation loss: 2.5522622952089766

Epoch: 5| Step: 3
Training loss: 2.60684739545695
Validation loss: 2.5581983501079537

Epoch: 5| Step: 4
Training loss: 2.962888371888563
Validation loss: 2.5540627680960317

Epoch: 5| Step: 5
Training loss: 2.619890599187108
Validation loss: 2.556414824508627

Epoch: 5| Step: 6
Training loss: 3.5643320559490412
Validation loss: 2.5562370663212963

Epoch: 5| Step: 7
Training loss: 2.615159253728782
Validation loss: 2.5611701053496336

Epoch: 5| Step: 8
Training loss: 2.816316600542014
Validation loss: 2.561852286990838

Epoch: 5| Step: 9
Training loss: 3.074906733889524
Validation loss: 2.576490049995811

Epoch: 5| Step: 10
Training loss: 2.350434397054808
Validation loss: 2.5704617332774484

Epoch: 160| Step: 0
Training loss: 2.670296632240788
Validation loss: 2.585833053777089

Epoch: 5| Step: 1
Training loss: 2.884188687970567
Validation loss: 2.576810840069611

Epoch: 5| Step: 2
Training loss: 3.2447564300207703
Validation loss: 2.567200893594621

Epoch: 5| Step: 3
Training loss: 2.7030024859056745
Validation loss: 2.5628521404922373

Epoch: 5| Step: 4
Training loss: 2.889107960765738
Validation loss: 2.5551892913231504

Epoch: 5| Step: 5
Training loss: 2.530093364425262
Validation loss: 2.5508160945456706

Epoch: 5| Step: 6
Training loss: 2.8504086184786495
Validation loss: 2.5611581988479224

Epoch: 5| Step: 7
Training loss: 3.2974378638671045
Validation loss: 2.5897262235505054

Epoch: 5| Step: 8
Training loss: 2.965706158282197
Validation loss: 2.5928706104010666

Epoch: 5| Step: 9
Training loss: 3.0240317063864373
Validation loss: 2.570264512438309

Epoch: 5| Step: 10
Training loss: 2.3153564750458764
Validation loss: 2.568655341148578

Epoch: 161| Step: 0
Training loss: 3.217630432378031
Validation loss: 2.5886303352155196

Epoch: 5| Step: 1
Training loss: 2.8990324905748626
Validation loss: 2.6001894733925575

Epoch: 5| Step: 2
Training loss: 2.519451193313878
Validation loss: 2.625575809639694

Epoch: 5| Step: 3
Training loss: 3.3053677627547144
Validation loss: 2.6609638465058416

Epoch: 5| Step: 4
Training loss: 2.709350209194225
Validation loss: 2.670085703886237

Epoch: 5| Step: 5
Training loss: 2.3341602722029537
Validation loss: 2.6763235173981874

Epoch: 5| Step: 6
Training loss: 3.4479401617411742
Validation loss: 2.6978103769428095

Epoch: 5| Step: 7
Training loss: 2.7449463445425897
Validation loss: 2.6524434165551742

Epoch: 5| Step: 8
Training loss: 2.928475497997312
Validation loss: 2.6365718969288126

Epoch: 5| Step: 9
Training loss: 2.994171361398418
Validation loss: 2.609715778001943

Epoch: 5| Step: 10
Training loss: 2.7853211170852026
Validation loss: 2.606621062015639

Epoch: 162| Step: 0
Training loss: 2.4245089082843347
Validation loss: 2.6014996055749093

Epoch: 5| Step: 1
Training loss: 3.0629865298820316
Validation loss: 2.5928615991294435

Epoch: 5| Step: 2
Training loss: 3.0364187945784646
Validation loss: 2.5853910127407684

Epoch: 5| Step: 3
Training loss: 2.5872528326690087
Validation loss: 2.575212156526347

Epoch: 5| Step: 4
Training loss: 3.05087909224106
Validation loss: 2.5761050895814863

Epoch: 5| Step: 5
Training loss: 3.138669899997434
Validation loss: 2.571530317382584

Epoch: 5| Step: 6
Training loss: 2.9733763936549855
Validation loss: 2.5769967830802987

Epoch: 5| Step: 7
Training loss: 2.638570132718833
Validation loss: 2.5816710655283868

Epoch: 5| Step: 8
Training loss: 2.956231153883754
Validation loss: 2.582391432878337

Epoch: 5| Step: 9
Training loss: 3.062875997077603
Validation loss: 2.597717498592621

Epoch: 5| Step: 10
Training loss: 2.8203373535413743
Validation loss: 2.60206707359562

Epoch: 163| Step: 0
Training loss: 3.3559450604166865
Validation loss: 2.641802267166448

Epoch: 5| Step: 1
Training loss: 3.1095419987444397
Validation loss: 2.6479199844891683

Epoch: 5| Step: 2
Training loss: 2.858080294635029
Validation loss: 2.631506949779959

Epoch: 5| Step: 3
Training loss: 2.5807576926945504
Validation loss: 2.6335766284911113

Epoch: 5| Step: 4
Training loss: 2.854984435458271
Validation loss: 2.6140165330295098

Epoch: 5| Step: 5
Training loss: 2.5558290876517673
Validation loss: 2.6195381492189997

Epoch: 5| Step: 6
Training loss: 2.561985057170807
Validation loss: 2.5936783010845046

Epoch: 5| Step: 7
Training loss: 3.184451571546259
Validation loss: 2.5797767794491975

Epoch: 5| Step: 8
Training loss: 2.180914311414855
Validation loss: 2.585205565401158

Epoch: 5| Step: 9
Training loss: 3.0231510785681315
Validation loss: 2.5704451533382024

Epoch: 5| Step: 10
Training loss: 3.4639920431843
Validation loss: 2.567888445557741

Epoch: 164| Step: 0
Training loss: 3.269541021444105
Validation loss: 2.567252018085675

Epoch: 5| Step: 1
Training loss: 2.78900385776279
Validation loss: 2.5681581375075324

Epoch: 5| Step: 2
Training loss: 2.9377501360942158
Validation loss: 2.5663814865947647

Epoch: 5| Step: 3
Training loss: 3.09084484217162
Validation loss: 2.5601515143992097

Epoch: 5| Step: 4
Training loss: 2.8312079554924345
Validation loss: 2.554840172138818

Epoch: 5| Step: 5
Training loss: 2.5063592140203266
Validation loss: 2.5573577097078157

Epoch: 5| Step: 6
Training loss: 3.0636085528029082
Validation loss: 2.545823588398864

Epoch: 5| Step: 7
Training loss: 3.4081624113345437
Validation loss: 2.549632209334676

Epoch: 5| Step: 8
Training loss: 2.744299789645661
Validation loss: 2.5461668993887367

Epoch: 5| Step: 9
Training loss: 2.364385072796083
Validation loss: 2.544047116594707

Epoch: 5| Step: 10
Training loss: 2.391108445296442
Validation loss: 2.5513685165022633

Epoch: 165| Step: 0
Training loss: 3.2563250688623766
Validation loss: 2.5533590614368626

Epoch: 5| Step: 1
Training loss: 2.5286773983484356
Validation loss: 2.5682070129161603

Epoch: 5| Step: 2
Training loss: 2.888394706794549
Validation loss: 2.5801436291651103

Epoch: 5| Step: 3
Training loss: 3.0791413618879626
Validation loss: 2.6102842982095305

Epoch: 5| Step: 4
Training loss: 2.766984422276594
Validation loss: 2.6073764031540008

Epoch: 5| Step: 5
Training loss: 3.14441524315325
Validation loss: 2.5920500667147466

Epoch: 5| Step: 6
Training loss: 3.3336488256560335
Validation loss: 2.5898919617714493

Epoch: 5| Step: 7
Training loss: 2.8171914708368178
Validation loss: 2.572306104493154

Epoch: 5| Step: 8
Training loss: 2.544985017263981
Validation loss: 2.5467198214706586

Epoch: 5| Step: 9
Training loss: 2.635648202086142
Validation loss: 2.5392769187082247

Epoch: 5| Step: 10
Training loss: 2.296523398132526
Validation loss: 2.5398779067914234

Epoch: 166| Step: 0
Training loss: 3.1426532326228958
Validation loss: 2.5504353707148324

Epoch: 5| Step: 1
Training loss: 2.845932175654454
Validation loss: 2.5424864607002675

Epoch: 5| Step: 2
Training loss: 2.612661792910541
Validation loss: 2.5402099470139947

Epoch: 5| Step: 3
Training loss: 2.5688046377640887
Validation loss: 2.5353635792331994

Epoch: 5| Step: 4
Training loss: 2.6927610843491583
Validation loss: 2.5424604680874725

Epoch: 5| Step: 5
Training loss: 2.972193437557729
Validation loss: 2.547524243697653

Epoch: 5| Step: 6
Training loss: 2.7650895974402996
Validation loss: 2.5499537395999874

Epoch: 5| Step: 7
Training loss: 2.8621174319291707
Validation loss: 2.552305217353259

Epoch: 5| Step: 8
Training loss: 3.1691537092012347
Validation loss: 2.576474117801246

Epoch: 5| Step: 9
Training loss: 2.8110374886677185
Validation loss: 2.5772273276147857

Epoch: 5| Step: 10
Training loss: 2.9003893097640114
Validation loss: 2.579091794391369

Epoch: 167| Step: 0
Training loss: 3.011242463960319
Validation loss: 2.5801438666364187

Epoch: 5| Step: 1
Training loss: 2.810301027023225
Validation loss: 2.559525387778855

Epoch: 5| Step: 2
Training loss: 3.0928867561435425
Validation loss: 2.554731070794293

Epoch: 5| Step: 3
Training loss: 3.0203505733199902
Validation loss: 2.557308980820797

Epoch: 5| Step: 4
Training loss: 3.1425307835153813
Validation loss: 2.546779682875393

Epoch: 5| Step: 5
Training loss: 2.360993998247247
Validation loss: 2.544244303077816

Epoch: 5| Step: 6
Training loss: 2.8733625309899673
Validation loss: 2.5332590301391877

Epoch: 5| Step: 7
Training loss: 2.816181655372812
Validation loss: 2.5343759908712524

Epoch: 5| Step: 8
Training loss: 2.813015615035464
Validation loss: 2.5303723054140344

Epoch: 5| Step: 9
Training loss: 2.546668763967053
Validation loss: 2.5373429233669684

Epoch: 5| Step: 10
Training loss: 2.77937562339026
Validation loss: 2.5344837375643876

Epoch: 168| Step: 0
Training loss: 3.121282884503225
Validation loss: 2.531865300248072

Epoch: 5| Step: 1
Training loss: 3.3791729595785815
Validation loss: 2.5344227208809342

Epoch: 5| Step: 2
Training loss: 2.7375625777386188
Validation loss: 2.5427790362256864

Epoch: 5| Step: 3
Training loss: 2.3798885227991096
Validation loss: 2.5522743928741325

Epoch: 5| Step: 4
Training loss: 2.7784894466038406
Validation loss: 2.5851653434263677

Epoch: 5| Step: 5
Training loss: 2.646500410756307
Validation loss: 2.6218589911587595

Epoch: 5| Step: 6
Training loss: 2.895758447204826
Validation loss: 2.6674453663274114

Epoch: 5| Step: 7
Training loss: 3.1569259977177033
Validation loss: 2.681608520513527

Epoch: 5| Step: 8
Training loss: 2.534785779971929
Validation loss: 2.586632854955649

Epoch: 5| Step: 9
Training loss: 3.066652557782875
Validation loss: 2.545923307497257

Epoch: 5| Step: 10
Training loss: 2.8235550518718293
Validation loss: 2.533045699085095

Epoch: 169| Step: 0
Training loss: 3.0138294626247775
Validation loss: 2.535718674353762

Epoch: 5| Step: 1
Training loss: 2.8853417856206622
Validation loss: 2.5313670947742826

Epoch: 5| Step: 2
Training loss: 2.496721979639648
Validation loss: 2.5365440844523244

Epoch: 5| Step: 3
Training loss: 3.017270128648716
Validation loss: 2.5424662327068566

Epoch: 5| Step: 4
Training loss: 2.8318142090862377
Validation loss: 2.5406378209104235

Epoch: 5| Step: 5
Training loss: 2.0899116291181294
Validation loss: 2.544552737114977

Epoch: 5| Step: 6
Training loss: 3.003612250933046
Validation loss: 2.538262683231361

Epoch: 5| Step: 7
Training loss: 2.788001449026336
Validation loss: 2.5294499136108066

Epoch: 5| Step: 8
Training loss: 3.4353156345394424
Validation loss: 2.5257926670190693

Epoch: 5| Step: 9
Training loss: 2.663716850343007
Validation loss: 2.525947839186649

Epoch: 5| Step: 10
Training loss: 3.2348125364534024
Validation loss: 2.531015929926896

Epoch: 170| Step: 0
Training loss: 3.2056353896447383
Validation loss: 2.5445187357280328

Epoch: 5| Step: 1
Training loss: 2.467183159117114
Validation loss: 2.5627182108013113

Epoch: 5| Step: 2
Training loss: 2.716532712883019
Validation loss: 2.591775272170951

Epoch: 5| Step: 3
Training loss: 2.786205035429138
Validation loss: 2.6308809277944416

Epoch: 5| Step: 4
Training loss: 3.2976050269209347
Validation loss: 2.6675674429012703

Epoch: 5| Step: 5
Training loss: 3.2956942934462976
Validation loss: 2.6345091478080374

Epoch: 5| Step: 6
Training loss: 2.7905889015383325
Validation loss: 2.611769301506569

Epoch: 5| Step: 7
Training loss: 2.6093788375369424
Validation loss: 2.560567519830726

Epoch: 5| Step: 8
Training loss: 2.4620913752279634
Validation loss: 2.5380280114311042

Epoch: 5| Step: 9
Training loss: 3.091817695513835
Validation loss: 2.5321165804542916

Epoch: 5| Step: 10
Training loss: 2.514045171873549
Validation loss: 2.52972924781265

Epoch: 171| Step: 0
Training loss: 3.02571560300672
Validation loss: 2.52927951741064

Epoch: 5| Step: 1
Training loss: 2.809522790808566
Validation loss: 2.531463480355519

Epoch: 5| Step: 2
Training loss: 2.805745044977496
Validation loss: 2.5305201213581245

Epoch: 5| Step: 3
Training loss: 2.6403980044700224
Validation loss: 2.5275616731671047

Epoch: 5| Step: 4
Training loss: 3.0619539046452617
Validation loss: 2.532921802487536

Epoch: 5| Step: 5
Training loss: 3.2762287775812844
Validation loss: 2.5416439633000154

Epoch: 5| Step: 6
Training loss: 2.8388446797783358
Validation loss: 2.5534671235463784

Epoch: 5| Step: 7
Training loss: 2.652917993600221
Validation loss: 2.551139479875387

Epoch: 5| Step: 8
Training loss: 2.945009251371143
Validation loss: 2.550773236792716

Epoch: 5| Step: 9
Training loss: 2.9540997869312844
Validation loss: 2.5642119130990406

Epoch: 5| Step: 10
Training loss: 1.973481321112585
Validation loss: 2.559672639924286

Epoch: 172| Step: 0
Training loss: 3.2507464211965034
Validation loss: 2.553115279148223

Epoch: 5| Step: 1
Training loss: 2.7432481936858437
Validation loss: 2.554866497874613

Epoch: 5| Step: 2
Training loss: 3.0114909084638217
Validation loss: 2.546631793950747

Epoch: 5| Step: 3
Training loss: 1.9830238969087235
Validation loss: 2.5510926998336956

Epoch: 5| Step: 4
Training loss: 2.9707312146826976
Validation loss: 2.553537333203895

Epoch: 5| Step: 5
Training loss: 2.715375362462771
Validation loss: 2.5588856921060255

Epoch: 5| Step: 6
Training loss: 3.1405914456676904
Validation loss: 2.5510307091661306

Epoch: 5| Step: 7
Training loss: 2.553345493988215
Validation loss: 2.5511854295292333

Epoch: 5| Step: 8
Training loss: 3.028952445562734
Validation loss: 2.539780387012717

Epoch: 5| Step: 9
Training loss: 2.58951553865681
Validation loss: 2.536261712352816

Epoch: 5| Step: 10
Training loss: 2.9079755357135646
Validation loss: 2.532957170035341

Epoch: 173| Step: 0
Training loss: 2.097990155061473
Validation loss: 2.5365527267833854

Epoch: 5| Step: 1
Training loss: 3.173052188803565
Validation loss: 2.5332217450033605

Epoch: 5| Step: 2
Training loss: 3.4122900650229027
Validation loss: 2.5310408504424537

Epoch: 5| Step: 3
Training loss: 3.0838421238567073
Validation loss: 2.5336881173256764

Epoch: 5| Step: 4
Training loss: 2.2786385207285935
Validation loss: 2.5334265641035025

Epoch: 5| Step: 5
Training loss: 2.96067192879564
Validation loss: 2.533015098712258

Epoch: 5| Step: 6
Training loss: 2.8566711649493928
Validation loss: 2.536009641922801

Epoch: 5| Step: 7
Training loss: 2.4672446188134085
Validation loss: 2.539756800379321

Epoch: 5| Step: 8
Training loss: 2.801928765289299
Validation loss: 2.549812606225066

Epoch: 5| Step: 9
Training loss: 3.1116634363022477
Validation loss: 2.5536526641286184

Epoch: 5| Step: 10
Training loss: 2.597955075622204
Validation loss: 2.550055311867045

Epoch: 174| Step: 0
Training loss: 2.8042070832724257
Validation loss: 2.5667322585785164

Epoch: 5| Step: 1
Training loss: 3.098910564834483
Validation loss: 2.571006983542471

Epoch: 5| Step: 2
Training loss: 2.9541138300365115
Validation loss: 2.5662462506119184

Epoch: 5| Step: 3
Training loss: 2.8750849172241852
Validation loss: 2.5530776724733513

Epoch: 5| Step: 4
Training loss: 2.6311631285763504
Validation loss: 2.5537144440795663

Epoch: 5| Step: 5
Training loss: 2.784118116454625
Validation loss: 2.5533663225475283

Epoch: 5| Step: 6
Training loss: 2.6860498463655964
Validation loss: 2.563319847680279

Epoch: 5| Step: 7
Training loss: 2.5698810435569674
Validation loss: 2.540631123810513

Epoch: 5| Step: 8
Training loss: 2.6934561265991146
Validation loss: 2.5423500423994136

Epoch: 5| Step: 9
Training loss: 3.0420434448430385
Validation loss: 2.5393738278586593

Epoch: 5| Step: 10
Training loss: 2.878659945631051
Validation loss: 2.5349347048586672

Epoch: 175| Step: 0
Training loss: 2.5172735463548124
Validation loss: 2.5390418994153046

Epoch: 5| Step: 1
Training loss: 2.7394403243843506
Validation loss: 2.5311525367356453

Epoch: 5| Step: 2
Training loss: 3.295641627726431
Validation loss: 2.5309586250284304

Epoch: 5| Step: 3
Training loss: 2.906786305155632
Validation loss: 2.5320718044710593

Epoch: 5| Step: 4
Training loss: 1.9008331881262046
Validation loss: 2.534255606828645

Epoch: 5| Step: 5
Training loss: 3.1519704075310053
Validation loss: 2.5307591877889526

Epoch: 5| Step: 6
Training loss: 3.3420531343520006
Validation loss: 2.5383358565432097

Epoch: 5| Step: 7
Training loss: 2.7784467135405224
Validation loss: 2.555398210537273

Epoch: 5| Step: 8
Training loss: 2.5623982106903145
Validation loss: 2.575456138155056

Epoch: 5| Step: 9
Training loss: 2.573286011990431
Validation loss: 2.5896489090758803

Epoch: 5| Step: 10
Training loss: 3.128066427652339
Validation loss: 2.6029959503725753

Epoch: 176| Step: 0
Training loss: 2.765186598346581
Validation loss: 2.614461704692352

Epoch: 5| Step: 1
Training loss: 2.8432522851707875
Validation loss: 2.599401303864175

Epoch: 5| Step: 2
Training loss: 3.032827222612465
Validation loss: 2.592979112986227

Epoch: 5| Step: 3
Training loss: 3.1847323201278157
Validation loss: 2.554787298087567

Epoch: 5| Step: 4
Training loss: 2.968923945099414
Validation loss: 2.536671926498808

Epoch: 5| Step: 5
Training loss: 2.895001536683513
Validation loss: 2.529829056116468

Epoch: 5| Step: 6
Training loss: 2.575787403491569
Validation loss: 2.5310353165665695

Epoch: 5| Step: 7
Training loss: 2.9746888839505266
Validation loss: 2.5356881234254645

Epoch: 5| Step: 8
Training loss: 2.7194757479445273
Validation loss: 2.5364752479567536

Epoch: 5| Step: 9
Training loss: 2.947402981236409
Validation loss: 2.536333709247364

Epoch: 5| Step: 10
Training loss: 2.429940851378636
Validation loss: 2.5305646299934126

Epoch: 177| Step: 0
Training loss: 2.713441071991775
Validation loss: 2.5289570844848726

Epoch: 5| Step: 1
Training loss: 2.6241664471287502
Validation loss: 2.524490637032491

Epoch: 5| Step: 2
Training loss: 3.0188671334171158
Validation loss: 2.533889075360012

Epoch: 5| Step: 3
Training loss: 3.133991885137611
Validation loss: 2.549964355253403

Epoch: 5| Step: 4
Training loss: 2.697732739948074
Validation loss: 2.5683102978635857

Epoch: 5| Step: 5
Training loss: 2.9416479490151137
Validation loss: 2.5999836475104185

Epoch: 5| Step: 6
Training loss: 2.862840563908572
Validation loss: 2.661587179214266

Epoch: 5| Step: 7
Training loss: 3.011369618169428
Validation loss: 2.622870056253746

Epoch: 5| Step: 8
Training loss: 2.817838899662847
Validation loss: 2.6004710604496726

Epoch: 5| Step: 9
Training loss: 2.5348009233725577
Validation loss: 2.551698945969777

Epoch: 5| Step: 10
Training loss: 3.213363584821873
Validation loss: 2.525116099325533

Epoch: 178| Step: 0
Training loss: 2.9556376752543287
Validation loss: 2.524607777233614

Epoch: 5| Step: 1
Training loss: 2.515254876055748
Validation loss: 2.536651554106577

Epoch: 5| Step: 2
Training loss: 2.8077508460033314
Validation loss: 2.548530522201076

Epoch: 5| Step: 3
Training loss: 3.294259285686694
Validation loss: 2.5900331263788017

Epoch: 5| Step: 4
Training loss: 2.503185722005081
Validation loss: 2.5836867971545585

Epoch: 5| Step: 5
Training loss: 2.893098340079558
Validation loss: 2.59077755149487

Epoch: 5| Step: 6
Training loss: 2.557041215512967
Validation loss: 2.6036311042296374

Epoch: 5| Step: 7
Training loss: 3.0740552613969174
Validation loss: 2.583621874985676

Epoch: 5| Step: 8
Training loss: 3.476800597534971
Validation loss: 2.556840446825183

Epoch: 5| Step: 9
Training loss: 3.1983303005514894
Validation loss: 2.550601198527538

Epoch: 5| Step: 10
Training loss: 2.69512505363258
Validation loss: 2.5140207237913197

Epoch: 179| Step: 0
Training loss: 3.08532152426308
Validation loss: 2.5248263558975386

Epoch: 5| Step: 1
Training loss: 3.5032205750684624
Validation loss: 2.5383409912206303

Epoch: 5| Step: 2
Training loss: 2.378284993347626
Validation loss: 2.563624503699581

Epoch: 5| Step: 3
Training loss: 2.63409537463775
Validation loss: 2.5701400928915445

Epoch: 5| Step: 4
Training loss: 2.5840702749032247
Validation loss: 2.5981187180386103

Epoch: 5| Step: 5
Training loss: 2.7661253912880324
Validation loss: 2.5965405182731924

Epoch: 5| Step: 6
Training loss: 2.619887960091308
Validation loss: 2.5969177652063933

Epoch: 5| Step: 7
Training loss: 3.086310641750174
Validation loss: 2.620072976577622

Epoch: 5| Step: 8
Training loss: 3.025380853054748
Validation loss: 2.579509306035191

Epoch: 5| Step: 9
Training loss: 2.896944962431362
Validation loss: 2.5606340477165515

Epoch: 5| Step: 10
Training loss: 2.390560473400253
Validation loss: 2.5369733112579618

Epoch: 180| Step: 0
Training loss: 3.165067536656474
Validation loss: 2.522170159245263

Epoch: 5| Step: 1
Training loss: 3.058274136697106
Validation loss: 2.5090541587853408

Epoch: 5| Step: 2
Training loss: 3.230907700963238
Validation loss: 2.503493242403726

Epoch: 5| Step: 3
Training loss: 3.0545593390933625
Validation loss: 2.507516230040522

Epoch: 5| Step: 4
Training loss: 2.491028327783885
Validation loss: 2.506504178986967

Epoch: 5| Step: 5
Training loss: 3.168377832230328
Validation loss: 2.506514000870766

Epoch: 5| Step: 6
Training loss: 2.6009209102352244
Validation loss: 2.50353331834049

Epoch: 5| Step: 7
Training loss: 3.0716383694445613
Validation loss: 2.5083136556295926

Epoch: 5| Step: 8
Training loss: 2.2916461828067725
Validation loss: 2.527103464699227

Epoch: 5| Step: 9
Training loss: 2.183629016898512
Validation loss: 2.5515304435312447

Epoch: 5| Step: 10
Training loss: 2.6053364275455486
Validation loss: 2.5664650429009996

Epoch: 181| Step: 0
Training loss: 2.6865459789244257
Validation loss: 2.5865875122147224

Epoch: 5| Step: 1
Training loss: 2.43087445180399
Validation loss: 2.6044787171148744

Epoch: 5| Step: 2
Training loss: 2.797229339487853
Validation loss: 2.5951987276873503

Epoch: 5| Step: 3
Training loss: 2.9023642866555557
Validation loss: 2.5931812092174384

Epoch: 5| Step: 4
Training loss: 3.1034709142173487
Validation loss: 2.5935690814624546

Epoch: 5| Step: 5
Training loss: 3.0017890364128554
Validation loss: 2.619256991160115

Epoch: 5| Step: 6
Training loss: 2.8173753655664147
Validation loss: 2.6254386672051697

Epoch: 5| Step: 7
Training loss: 3.4523170872435838
Validation loss: 2.5871428740752695

Epoch: 5| Step: 8
Training loss: 3.0597676135314456
Validation loss: 2.5545775055008018

Epoch: 5| Step: 9
Training loss: 1.9171159950110026
Validation loss: 2.5430671233448696

Epoch: 5| Step: 10
Training loss: 2.925087045531806
Validation loss: 2.5327829418284735

Epoch: 182| Step: 0
Training loss: 2.8653463746110317
Validation loss: 2.5178868250173614

Epoch: 5| Step: 1
Training loss: 3.0368477957088595
Validation loss: 2.51066806089159

Epoch: 5| Step: 2
Training loss: 3.0824127541328434
Validation loss: 2.5059019113636665

Epoch: 5| Step: 3
Training loss: 2.907867145793537
Validation loss: 2.5010770426054827

Epoch: 5| Step: 4
Training loss: 2.513533297189015
Validation loss: 2.507088024812201

Epoch: 5| Step: 5
Training loss: 2.6704802860517276
Validation loss: 2.5041149298747065

Epoch: 5| Step: 6
Training loss: 2.548067714635767
Validation loss: 2.504769576670207

Epoch: 5| Step: 7
Training loss: 2.6698611516960837
Validation loss: 2.505753445287982

Epoch: 5| Step: 8
Training loss: 2.9557509277259695
Validation loss: 2.510770532211251

Epoch: 5| Step: 9
Training loss: 2.688053695062936
Validation loss: 2.5118325380449513

Epoch: 5| Step: 10
Training loss: 3.15788332535539
Validation loss: 2.515384486017914

Epoch: 183| Step: 0
Training loss: 2.7860409052598727
Validation loss: 2.5178744745666317

Epoch: 5| Step: 1
Training loss: 2.4805624636271126
Validation loss: 2.534297075820206

Epoch: 5| Step: 2
Training loss: 2.283268910448227
Validation loss: 2.536105211189799

Epoch: 5| Step: 3
Training loss: 2.7689003380459996
Validation loss: 2.532239465577923

Epoch: 5| Step: 4
Training loss: 2.488769866542184
Validation loss: 2.5457767524659647

Epoch: 5| Step: 5
Training loss: 3.3597988127466487
Validation loss: 2.51903659536932

Epoch: 5| Step: 6
Training loss: 2.749427562435778
Validation loss: 2.5048747967694904

Epoch: 5| Step: 7
Training loss: 3.430342835400536
Validation loss: 2.5002538490624207

Epoch: 5| Step: 8
Training loss: 3.08040909812187
Validation loss: 2.507228132692312

Epoch: 5| Step: 9
Training loss: 2.843399529292131
Validation loss: 2.50334220741558

Epoch: 5| Step: 10
Training loss: 2.4752028911928776
Validation loss: 2.5060043238688863

Epoch: 184| Step: 0
Training loss: 3.1495528978604086
Validation loss: 2.50399075768765

Epoch: 5| Step: 1
Training loss: 2.882830860110487
Validation loss: 2.502590151532193

Epoch: 5| Step: 2
Training loss: 2.768839202201696
Validation loss: 2.503830280744547

Epoch: 5| Step: 3
Training loss: 2.6382733770495315
Validation loss: 2.4982206985879993

Epoch: 5| Step: 4
Training loss: 2.9475482580167203
Validation loss: 2.503928827981269

Epoch: 5| Step: 5
Training loss: 2.6246756398663926
Validation loss: 2.5067220555953726

Epoch: 5| Step: 6
Training loss: 2.4702312033858598
Validation loss: 2.5147256417414297

Epoch: 5| Step: 7
Training loss: 2.8107309499853534
Validation loss: 2.5175636895894447

Epoch: 5| Step: 8
Training loss: 3.0856247369195504
Validation loss: 2.541665387031425

Epoch: 5| Step: 9
Training loss: 2.4619152246129743
Validation loss: 2.5540382102292027

Epoch: 5| Step: 10
Training loss: 3.067271660822396
Validation loss: 2.5572481518643713

Epoch: 185| Step: 0
Training loss: 2.7299214743754265
Validation loss: 2.5606797979633242

Epoch: 5| Step: 1
Training loss: 2.97231488266616
Validation loss: 2.551965303853862

Epoch: 5| Step: 2
Training loss: 2.8109664974869224
Validation loss: 2.537172681379626

Epoch: 5| Step: 3
Training loss: 3.50121245500617
Validation loss: 2.517340878264

Epoch: 5| Step: 4
Training loss: 2.8430106071625842
Validation loss: 2.54156411090303

Epoch: 5| Step: 5
Training loss: 3.064758402277585
Validation loss: 2.535618677282728

Epoch: 5| Step: 6
Training loss: 2.6791043105712378
Validation loss: 2.5336690444147143

Epoch: 5| Step: 7
Training loss: 2.2466220930905574
Validation loss: 2.5188209666392587

Epoch: 5| Step: 8
Training loss: 2.396595996598226
Validation loss: 2.5133150277371863

Epoch: 5| Step: 9
Training loss: 2.6233048187929375
Validation loss: 2.5120722491106244

Epoch: 5| Step: 10
Training loss: 2.7746553567854133
Validation loss: 2.5097364303061056

Epoch: 186| Step: 0
Training loss: 2.565531170670726
Validation loss: 2.5085217542451503

Epoch: 5| Step: 1
Training loss: 2.848175294560523
Validation loss: 2.503003994117967

Epoch: 5| Step: 2
Training loss: 2.3280526988432433
Validation loss: 2.5143308302238614

Epoch: 5| Step: 3
Training loss: 2.925995720819146
Validation loss: 2.513440677223201

Epoch: 5| Step: 4
Training loss: 2.6483411743291256
Validation loss: 2.51716585636627

Epoch: 5| Step: 5
Training loss: 3.1878537748394766
Validation loss: 2.5125744600404354

Epoch: 5| Step: 6
Training loss: 2.7472254888628482
Validation loss: 2.5229192061997576

Epoch: 5| Step: 7
Training loss: 3.355881546794482
Validation loss: 2.520998732136535

Epoch: 5| Step: 8
Training loss: 3.021614096581035
Validation loss: 2.5378296479623317

Epoch: 5| Step: 9
Training loss: 2.3053885735195596
Validation loss: 2.543954454719348

Epoch: 5| Step: 10
Training loss: 2.625844002325412
Validation loss: 2.5428055760559056

Epoch: 187| Step: 0
Training loss: 2.7737054399896843
Validation loss: 2.541829991720483

Epoch: 5| Step: 1
Training loss: 2.6665995311233384
Validation loss: 2.5253888464632737

Epoch: 5| Step: 2
Training loss: 2.7534241599310825
Validation loss: 2.5209341450236127

Epoch: 5| Step: 3
Training loss: 2.779567938512151
Validation loss: 2.5124122018196955

Epoch: 5| Step: 4
Training loss: 2.7120172730292453
Validation loss: 2.5149324432317472

Epoch: 5| Step: 5
Training loss: 2.25336025242649
Validation loss: 2.512569202304107

Epoch: 5| Step: 6
Training loss: 2.7480855693682145
Validation loss: 2.5110372457860812

Epoch: 5| Step: 7
Training loss: 2.9991350516514648
Validation loss: 2.5065237511209686

Epoch: 5| Step: 8
Training loss: 2.7626795196890863
Validation loss: 2.504497062204804

Epoch: 5| Step: 9
Training loss: 3.145255399925691
Validation loss: 2.510546927037716

Epoch: 5| Step: 10
Training loss: 3.180234819775284
Validation loss: 2.5056667369409196

Epoch: 188| Step: 0
Training loss: 2.5838583340976795
Validation loss: 2.505969464925749

Epoch: 5| Step: 1
Training loss: 3.0473710658874493
Validation loss: 2.5096952756401536

Epoch: 5| Step: 2
Training loss: 2.4442644402185785
Validation loss: 2.5203775617440924

Epoch: 5| Step: 3
Training loss: 2.644424233461752
Validation loss: 2.5155517184274636

Epoch: 5| Step: 4
Training loss: 2.654264268822217
Validation loss: 2.5117462737967697

Epoch: 5| Step: 5
Training loss: 3.1249711607555994
Validation loss: 2.5271116544063776

Epoch: 5| Step: 6
Training loss: 2.63260004561709
Validation loss: 2.5283999464120703

Epoch: 5| Step: 7
Training loss: 3.4684934778986665
Validation loss: 2.5270673304570352

Epoch: 5| Step: 8
Training loss: 2.811510632596101
Validation loss: 2.527857278272866

Epoch: 5| Step: 9
Training loss: 2.609413466484107
Validation loss: 2.527591219816606

Epoch: 5| Step: 10
Training loss: 2.49074242289929
Validation loss: 2.5227918759968277

Epoch: 189| Step: 0
Training loss: 2.9274390786182036
Validation loss: 2.51513773650567

Epoch: 5| Step: 1
Training loss: 2.6110072712733086
Validation loss: 2.5097078604243492

Epoch: 5| Step: 2
Training loss: 3.1313680234431382
Validation loss: 2.512812741387468

Epoch: 5| Step: 3
Training loss: 2.604956809654159
Validation loss: 2.5163776594269978

Epoch: 5| Step: 4
Training loss: 2.5873999018818683
Validation loss: 2.502465149437421

Epoch: 5| Step: 5
Training loss: 3.269523957858505
Validation loss: 2.5022756258808516

Epoch: 5| Step: 6
Training loss: 2.175857076915908
Validation loss: 2.505444365614947

Epoch: 5| Step: 7
Training loss: 2.6610728741816376
Validation loss: 2.506610751989141

Epoch: 5| Step: 8
Training loss: 2.976940060997201
Validation loss: 2.4990098089528643

Epoch: 5| Step: 9
Training loss: 2.532502606193806
Validation loss: 2.5035196262787855

Epoch: 5| Step: 10
Training loss: 3.1243886731148667
Validation loss: 2.5003938200665266

Epoch: 190| Step: 0
Training loss: 2.655599896031082
Validation loss: 2.5035943894920254

Epoch: 5| Step: 1
Training loss: 2.445253706642698
Validation loss: 2.504383927677995

Epoch: 5| Step: 2
Training loss: 3.000795576780919
Validation loss: 2.5064190932493227

Epoch: 5| Step: 3
Training loss: 2.8298494761305153
Validation loss: 2.5126804368439974

Epoch: 5| Step: 4
Training loss: 2.6215296011968228
Validation loss: 2.5034149616072288

Epoch: 5| Step: 5
Training loss: 2.8595942845709903
Validation loss: 2.5138740629383958

Epoch: 5| Step: 6
Training loss: 2.5389855945384334
Validation loss: 2.505383087838163

Epoch: 5| Step: 7
Training loss: 3.479710899928688
Validation loss: 2.5074862096443664

Epoch: 5| Step: 8
Training loss: 2.4647377341998626
Validation loss: 2.5057019653504042

Epoch: 5| Step: 9
Training loss: 2.9406473059624076
Validation loss: 2.491264926258191

Epoch: 5| Step: 10
Training loss: 2.6137236946201576
Validation loss: 2.5015957149186114

Epoch: 191| Step: 0
Training loss: 2.95675420030157
Validation loss: 2.503925662243582

Epoch: 5| Step: 1
Training loss: 2.30913092080896
Validation loss: 2.4979624289578823

Epoch: 5| Step: 2
Training loss: 3.1251965270234656
Validation loss: 2.5046676889102963

Epoch: 5| Step: 3
Training loss: 3.1262547834833363
Validation loss: 2.5069712470953625

Epoch: 5| Step: 4
Training loss: 2.9018715311293004
Validation loss: 2.515793806091338

Epoch: 5| Step: 5
Training loss: 2.406124260329512
Validation loss: 2.515825593156153

Epoch: 5| Step: 6
Training loss: 2.665775229546349
Validation loss: 2.5315933855500092

Epoch: 5| Step: 7
Training loss: 2.634855660497184
Validation loss: 2.5454446065000442

Epoch: 5| Step: 8
Training loss: 3.2429323374947012
Validation loss: 2.548390458840639

Epoch: 5| Step: 9
Training loss: 2.742926603953393
Validation loss: 2.5310694950329684

Epoch: 5| Step: 10
Training loss: 2.401857007346656
Validation loss: 2.508668410187868

Epoch: 192| Step: 0
Training loss: 2.694208510601247
Validation loss: 2.4972321642110784

Epoch: 5| Step: 1
Training loss: 2.5559405598900216
Validation loss: 2.4883513074123416

Epoch: 5| Step: 2
Training loss: 3.0266690591418968
Validation loss: 2.4888336989645334

Epoch: 5| Step: 3
Training loss: 2.495076194471231
Validation loss: 2.490974387414652

Epoch: 5| Step: 4
Training loss: 3.062345228371467
Validation loss: 2.489154066252375

Epoch: 5| Step: 5
Training loss: 2.54803824042425
Validation loss: 2.492254646613884

Epoch: 5| Step: 6
Training loss: 2.4419078586262732
Validation loss: 2.492690047621735

Epoch: 5| Step: 7
Training loss: 2.697541396112437
Validation loss: 2.4913542525265733

Epoch: 5| Step: 8
Training loss: 3.2272842006503826
Validation loss: 2.4970724469239194

Epoch: 5| Step: 9
Training loss: 2.6356539914673998
Validation loss: 2.495418255044032

Epoch: 5| Step: 10
Training loss: 3.2280064785406624
Validation loss: 2.5271034677426014

Epoch: 193| Step: 0
Training loss: 2.721459277494348
Validation loss: 2.562997704630592

Epoch: 5| Step: 1
Training loss: 2.859026444666735
Validation loss: 2.558015393185049

Epoch: 5| Step: 2
Training loss: 3.131742299377762
Validation loss: 2.5662256844323346

Epoch: 5| Step: 3
Training loss: 3.1169737931423533
Validation loss: 2.554094871835918

Epoch: 5| Step: 4
Training loss: 2.3395295863603267
Validation loss: 2.5272025641556555

Epoch: 5| Step: 5
Training loss: 2.6025328330131825
Validation loss: 2.511922616846769

Epoch: 5| Step: 6
Training loss: 2.7139204252717195
Validation loss: 2.512385270518418

Epoch: 5| Step: 7
Training loss: 3.104411395024523
Validation loss: 2.499848086345864

Epoch: 5| Step: 8
Training loss: 3.0227116149580247
Validation loss: 2.4954822404958215

Epoch: 5| Step: 9
Training loss: 2.3098125822654207
Validation loss: 2.4936105879622437

Epoch: 5| Step: 10
Training loss: 2.6857422691701953
Validation loss: 2.492523396002329

Epoch: 194| Step: 0
Training loss: 2.8198665361408026
Validation loss: 2.488190307078286

Epoch: 5| Step: 1
Training loss: 3.3063892645251096
Validation loss: 2.4946944266851014

Epoch: 5| Step: 2
Training loss: 2.5731164543226765
Validation loss: 2.4862504173690123

Epoch: 5| Step: 3
Training loss: 3.0763712112994286
Validation loss: 2.4920590691924076

Epoch: 5| Step: 4
Training loss: 2.9034673022936355
Validation loss: 2.4880338959828405

Epoch: 5| Step: 5
Training loss: 2.893656362909467
Validation loss: 2.482141897745614

Epoch: 5| Step: 6
Training loss: 2.6355923881801795
Validation loss: 2.4933330371831945

Epoch: 5| Step: 7
Training loss: 2.447498453546957
Validation loss: 2.489096522678227

Epoch: 5| Step: 8
Training loss: 3.267350758396404
Validation loss: 2.496408115641487

Epoch: 5| Step: 9
Training loss: 2.0832792910878015
Validation loss: 2.5141840875327355

Epoch: 5| Step: 10
Training loss: 2.3734173771982707
Validation loss: 2.52275668197774

Epoch: 195| Step: 0
Training loss: 2.7622935602028322
Validation loss: 2.5256045519047645

Epoch: 5| Step: 1
Training loss: 2.8002640633725027
Validation loss: 2.515915534087123

Epoch: 5| Step: 2
Training loss: 2.879650997897131
Validation loss: 2.521550163983581

Epoch: 5| Step: 3
Training loss: 2.910762278289048
Validation loss: 2.504914289755376

Epoch: 5| Step: 4
Training loss: 2.658437209855195
Validation loss: 2.493545138260868

Epoch: 5| Step: 5
Training loss: 2.752567566502301
Validation loss: 2.492215622673712

Epoch: 5| Step: 6
Training loss: 3.0665035936977367
Validation loss: 2.481147537973731

Epoch: 5| Step: 7
Training loss: 2.6160564654669582
Validation loss: 2.4864372949477307

Epoch: 5| Step: 8
Training loss: 2.774223452676597
Validation loss: 2.4795383865112006

Epoch: 5| Step: 9
Training loss: 2.9892554197454486
Validation loss: 2.4765709531093814

Epoch: 5| Step: 10
Training loss: 2.2643346861141675
Validation loss: 2.474170696856638

Epoch: 196| Step: 0
Training loss: 2.762578719730669
Validation loss: 2.483177498569828

Epoch: 5| Step: 1
Training loss: 2.789846785518861
Validation loss: 2.490557126212635

Epoch: 5| Step: 2
Training loss: 2.6981929701390275
Validation loss: 2.49701625932576

Epoch: 5| Step: 3
Training loss: 2.3850205493737486
Validation loss: 2.5037794401162987

Epoch: 5| Step: 4
Training loss: 2.7867688062496474
Validation loss: 2.5083731172046466

Epoch: 5| Step: 5
Training loss: 3.4761792603900927
Validation loss: 2.497724902742617

Epoch: 5| Step: 6
Training loss: 2.526579704532777
Validation loss: 2.496709628200547

Epoch: 5| Step: 7
Training loss: 2.8948149136688195
Validation loss: 2.4882346713769947

Epoch: 5| Step: 8
Training loss: 3.018882770659271
Validation loss: 2.494815592437319

Epoch: 5| Step: 9
Training loss: 2.233304707737513
Validation loss: 2.4755575772384826

Epoch: 5| Step: 10
Training loss: 2.7753039459931705
Validation loss: 2.4833837270183055

Epoch: 197| Step: 0
Training loss: 2.289359532376128
Validation loss: 2.492427766384176

Epoch: 5| Step: 1
Training loss: 2.5668680132707427
Validation loss: 2.4872531390554653

Epoch: 5| Step: 2
Training loss: 2.636161236632016
Validation loss: 2.499346151268802

Epoch: 5| Step: 3
Training loss: 2.4343720931891544
Validation loss: 2.5096664591068376

Epoch: 5| Step: 4
Training loss: 3.219983799579691
Validation loss: 2.5080323762941017

Epoch: 5| Step: 5
Training loss: 2.9704999082982977
Validation loss: 2.5059032668927506

Epoch: 5| Step: 6
Training loss: 3.1712578234126836
Validation loss: 2.5170281563836943

Epoch: 5| Step: 7
Training loss: 2.502683534399036
Validation loss: 2.4964764570108136

Epoch: 5| Step: 8
Training loss: 2.722240969102453
Validation loss: 2.4901837663938857

Epoch: 5| Step: 9
Training loss: 2.593219013325758
Validation loss: 2.492290024486165

Epoch: 5| Step: 10
Training loss: 3.183249837635839
Validation loss: 2.489381362260874

Epoch: 198| Step: 0
Training loss: 2.5914011051562773
Validation loss: 2.4783207518830346

Epoch: 5| Step: 1
Training loss: 2.6863703460503943
Validation loss: 2.485206416899979

Epoch: 5| Step: 2
Training loss: 3.003067990971639
Validation loss: 2.4844317510676484

Epoch: 5| Step: 3
Training loss: 2.781102980253281
Validation loss: 2.4912641050747264

Epoch: 5| Step: 4
Training loss: 2.746242817594558
Validation loss: 2.48053848133705

Epoch: 5| Step: 5
Training loss: 2.523473308297357
Validation loss: 2.480626457639157

Epoch: 5| Step: 6
Training loss: 2.4196259915775067
Validation loss: 2.4774528319391314

Epoch: 5| Step: 7
Training loss: 2.582949845757885
Validation loss: 2.4814829055303025

Epoch: 5| Step: 8
Training loss: 3.5590150083400665
Validation loss: 2.491488682492724

Epoch: 5| Step: 9
Training loss: 2.385320825331113
Validation loss: 2.4951706787062564

Epoch: 5| Step: 10
Training loss: 2.995590466101898
Validation loss: 2.5327608923311513

Epoch: 199| Step: 0
Training loss: 2.784743697119841
Validation loss: 2.555159054465463

Epoch: 5| Step: 1
Training loss: 2.8550251878472435
Validation loss: 2.5514007325175463

Epoch: 5| Step: 2
Training loss: 2.9799343444964967
Validation loss: 2.5299055569360944

Epoch: 5| Step: 3
Training loss: 2.647008549767591
Validation loss: 2.507945742137624

Epoch: 5| Step: 4
Training loss: 2.8074145646993314
Validation loss: 2.490824611654052

Epoch: 5| Step: 5
Training loss: 2.8031961625506208
Validation loss: 2.4824666052085873

Epoch: 5| Step: 6
Training loss: 2.715042831476459
Validation loss: 2.475675821206709

Epoch: 5| Step: 7
Training loss: 2.6173811655841397
Validation loss: 2.4798857174471514

Epoch: 5| Step: 8
Training loss: 2.96614201081889
Validation loss: 2.472174477478157

Epoch: 5| Step: 9
Training loss: 2.3256009135425244
Validation loss: 2.477787910135494

Epoch: 5| Step: 10
Training loss: 3.2092142423281156
Validation loss: 2.4698638002699727

Epoch: 200| Step: 0
Training loss: 2.4975637008898173
Validation loss: 2.4779931149436614

Epoch: 5| Step: 1
Training loss: 2.789565268114514
Validation loss: 2.4782685190014404

Epoch: 5| Step: 2
Training loss: 3.117311709422266
Validation loss: 2.4795147623946114

Epoch: 5| Step: 3
Training loss: 2.8202954236303497
Validation loss: 2.483964310424229

Epoch: 5| Step: 4
Training loss: 2.8763951772484675
Validation loss: 2.485008861096537

Epoch: 5| Step: 5
Training loss: 2.326691153961271
Validation loss: 2.4865661171568867

Epoch: 5| Step: 6
Training loss: 3.3388317694267995
Validation loss: 2.495232264814117

Epoch: 5| Step: 7
Training loss: 2.3082693423916427
Validation loss: 2.502249969627299

Epoch: 5| Step: 8
Training loss: 3.036026799120124
Validation loss: 2.5134056174603208

Epoch: 5| Step: 9
Training loss: 2.717744224684671
Validation loss: 2.5156833502044758

Epoch: 5| Step: 10
Training loss: 2.132467947715667
Validation loss: 2.5167076040142584

Epoch: 201| Step: 0
Training loss: 2.5631056279248234
Validation loss: 2.5138105889666407

Epoch: 5| Step: 1
Training loss: 2.6699845614326265
Validation loss: 2.51162340825318

Epoch: 5| Step: 2
Training loss: 2.9500647133663556
Validation loss: 2.4982699253009795

Epoch: 5| Step: 3
Training loss: 2.8582604742820017
Validation loss: 2.483436211037052

Epoch: 5| Step: 4
Training loss: 2.8999943831816903
Validation loss: 2.4845697067776444

Epoch: 5| Step: 5
Training loss: 2.4628012729442603
Validation loss: 2.4983362511983755

Epoch: 5| Step: 6
Training loss: 2.6605400895236753
Validation loss: 2.496312019684844

Epoch: 5| Step: 7
Training loss: 2.8193190243474335
Validation loss: 2.499972506341188

Epoch: 5| Step: 8
Training loss: 3.1150231364509957
Validation loss: 2.496332863005994

Epoch: 5| Step: 9
Training loss: 2.4253547526953905
Validation loss: 2.487483533653356

Epoch: 5| Step: 10
Training loss: 2.780992303118159
Validation loss: 2.4865555947856914

Epoch: 202| Step: 0
Training loss: 2.4308039317305297
Validation loss: 2.485297527806096

Epoch: 5| Step: 1
Training loss: 3.14817350809525
Validation loss: 2.476045355193396

Epoch: 5| Step: 2
Training loss: 2.567538912885908
Validation loss: 2.4782160646768037

Epoch: 5| Step: 3
Training loss: 2.8462965745093176
Validation loss: 2.4857939521306642

Epoch: 5| Step: 4
Training loss: 2.687289651135117
Validation loss: 2.482723970908441

Epoch: 5| Step: 5
Training loss: 2.9134532301765663
Validation loss: 2.4728080395641525

Epoch: 5| Step: 6
Training loss: 2.3052789478774267
Validation loss: 2.509759656566177

Epoch: 5| Step: 7
Training loss: 3.194994026859055
Validation loss: 2.5174209908584446

Epoch: 5| Step: 8
Training loss: 2.799903551211657
Validation loss: 2.540827316194023

Epoch: 5| Step: 9
Training loss: 2.7275025242025444
Validation loss: 2.5553396646363793

Epoch: 5| Step: 10
Training loss: 2.80149774683995
Validation loss: 2.5446447384714483

Epoch: 203| Step: 0
Training loss: 2.226464734524401
Validation loss: 2.528341058238564

Epoch: 5| Step: 1
Training loss: 3.027819393078063
Validation loss: 2.495298498338643

Epoch: 5| Step: 2
Training loss: 2.5516036432690226
Validation loss: 2.47768536188764

Epoch: 5| Step: 3
Training loss: 2.4264322043254167
Validation loss: 2.4741070011116677

Epoch: 5| Step: 4
Training loss: 3.185897274614637
Validation loss: 2.4752608530438462

Epoch: 5| Step: 5
Training loss: 2.4357784745412654
Validation loss: 2.471071108797388

Epoch: 5| Step: 6
Training loss: 2.947990838904879
Validation loss: 2.48265979655831

Epoch: 5| Step: 7
Training loss: 3.374154726778139
Validation loss: 2.4808056912007257

Epoch: 5| Step: 8
Training loss: 2.8412123875408755
Validation loss: 2.494492282270623

Epoch: 5| Step: 9
Training loss: 2.6011289859689675
Validation loss: 2.5182582571337093

Epoch: 5| Step: 10
Training loss: 2.400545566856561
Validation loss: 2.5255764528522833

Epoch: 204| Step: 0
Training loss: 2.615481056618789
Validation loss: 2.536906608539828

Epoch: 5| Step: 1
Training loss: 2.9841962031784943
Validation loss: 2.52837868607194

Epoch: 5| Step: 2
Training loss: 3.0422881201359626
Validation loss: 2.5536368976537815

Epoch: 5| Step: 3
Training loss: 2.382517411767794
Validation loss: 2.543837905086104

Epoch: 5| Step: 4
Training loss: 3.0513465347865694
Validation loss: 2.5350288412060973

Epoch: 5| Step: 5
Training loss: 2.577328275626572
Validation loss: 2.5243586576449655

Epoch: 5| Step: 6
Training loss: 2.8401046696031744
Validation loss: 2.5129422702120503

Epoch: 5| Step: 7
Training loss: 2.400670903528499
Validation loss: 2.495868106815983

Epoch: 5| Step: 8
Training loss: 2.7238102441701657
Validation loss: 2.502920891174408

Epoch: 5| Step: 9
Training loss: 2.59614232052584
Validation loss: 2.485325757325513

Epoch: 5| Step: 10
Training loss: 2.990510874197967
Validation loss: 2.4796507967531953

Epoch: 205| Step: 0
Training loss: 2.791176472988234
Validation loss: 2.478273865024445

Epoch: 5| Step: 1
Training loss: 2.3859540397905143
Validation loss: 2.4872151085992162

Epoch: 5| Step: 2
Training loss: 2.5010905748124213
Validation loss: 2.477872734376933

Epoch: 5| Step: 3
Training loss: 2.6976936768587754
Validation loss: 2.4860907885856527

Epoch: 5| Step: 4
Training loss: 3.0825597119020105
Validation loss: 2.484405668047063

Epoch: 5| Step: 5
Training loss: 1.9551489757157718
Validation loss: 2.4856292866639746

Epoch: 5| Step: 6
Training loss: 2.625501312342708
Validation loss: 2.4933068313569873

Epoch: 5| Step: 7
Training loss: 3.006738565125214
Validation loss: 2.4989292733396304

Epoch: 5| Step: 8
Training loss: 3.114216930734724
Validation loss: 2.511235390871392

Epoch: 5| Step: 9
Training loss: 2.92703265127015
Validation loss: 2.511174639284141

Epoch: 5| Step: 10
Training loss: 3.0478213674509576
Validation loss: 2.5156358756725354

Epoch: 206| Step: 0
Training loss: 2.0748994504167184
Validation loss: 2.5078049546751418

Epoch: 5| Step: 1
Training loss: 2.6389776203786526
Validation loss: 2.4969185060310073

Epoch: 5| Step: 2
Training loss: 2.6032795323255806
Validation loss: 2.5061567624942045

Epoch: 5| Step: 3
Training loss: 2.9540407083091553
Validation loss: 2.495374194137595

Epoch: 5| Step: 4
Training loss: 3.098624810401738
Validation loss: 2.485850022120709

Epoch: 5| Step: 5
Training loss: 2.8635416992305913
Validation loss: 2.476938223514573

Epoch: 5| Step: 6
Training loss: 2.9564735763558634
Validation loss: 2.475769789777259

Epoch: 5| Step: 7
Training loss: 2.16058544013476
Validation loss: 2.4823852648929132

Epoch: 5| Step: 8
Training loss: 2.9389466315087187
Validation loss: 2.4791709036070047

Epoch: 5| Step: 9
Training loss: 2.7568292783250694
Validation loss: 2.4791459596023695

Epoch: 5| Step: 10
Training loss: 3.2454386760516996
Validation loss: 2.490112758805877

Epoch: 207| Step: 0
Training loss: 2.499432213203074
Validation loss: 2.490158910571025

Epoch: 5| Step: 1
Training loss: 2.2112396357300432
Validation loss: 2.5116388617641197

Epoch: 5| Step: 2
Training loss: 3.435836944565844
Validation loss: 2.5292410728401657

Epoch: 5| Step: 3
Training loss: 3.077138365036276
Validation loss: 2.5701400420205145

Epoch: 5| Step: 4
Training loss: 2.859037118762182
Validation loss: 2.577358026609236

Epoch: 5| Step: 5
Training loss: 2.3269144277539207
Validation loss: 2.556069166944551

Epoch: 5| Step: 6
Training loss: 3.024777453094206
Validation loss: 2.5496403834874273

Epoch: 5| Step: 7
Training loss: 2.868328314478856
Validation loss: 2.532448379987749

Epoch: 5| Step: 8
Training loss: 2.1811314110640656
Validation loss: 2.484136166336741

Epoch: 5| Step: 9
Training loss: 2.953960966437328
Validation loss: 2.4828783995159704

Epoch: 5| Step: 10
Training loss: 2.71244211794364
Validation loss: 2.5019662077703075

Epoch: 208| Step: 0
Training loss: 3.0291750383501888
Validation loss: 2.5359403794744724

Epoch: 5| Step: 1
Training loss: 2.6268681735799357
Validation loss: 2.6340335373235386

Epoch: 5| Step: 2
Training loss: 3.0846030911380478
Validation loss: 2.6206073641333356

Epoch: 5| Step: 3
Training loss: 2.88854196087386
Validation loss: 2.486617798405744

Epoch: 5| Step: 4
Training loss: 2.6136622129828138
Validation loss: 2.483242784831263

Epoch: 5| Step: 5
Training loss: 2.4935636637201855
Validation loss: 2.496035460524367

Epoch: 5| Step: 6
Training loss: 3.073908517542243
Validation loss: 2.5130120726699463

Epoch: 5| Step: 7
Training loss: 2.3400481426144673
Validation loss: 2.5292809060221724

Epoch: 5| Step: 8
Training loss: 3.0461725452267094
Validation loss: 2.552234512750096

Epoch: 5| Step: 9
Training loss: 3.007477818484172
Validation loss: 2.611659803829559

Epoch: 5| Step: 10
Training loss: 2.7073419566007364
Validation loss: 2.6416562411267317

Epoch: 209| Step: 0
Training loss: 2.907853207310946
Validation loss: 2.5572554881470255

Epoch: 5| Step: 1
Training loss: 2.7581297608210633
Validation loss: 2.516478658443425

Epoch: 5| Step: 2
Training loss: 3.294551663497197
Validation loss: 2.494818314514397

Epoch: 5| Step: 3
Training loss: 2.2921917978362165
Validation loss: 2.4867355144000163

Epoch: 5| Step: 4
Training loss: 2.983811250336844
Validation loss: 2.4788720522969534

Epoch: 5| Step: 5
Training loss: 2.752882920186294
Validation loss: 2.4873076301188606

Epoch: 5| Step: 6
Training loss: 2.5232690335660153
Validation loss: 2.4872715114216866

Epoch: 5| Step: 7
Training loss: 2.1943838524266375
Validation loss: 2.496129112488075

Epoch: 5| Step: 8
Training loss: 3.0299961603725767
Validation loss: 2.5256976515094287

Epoch: 5| Step: 9
Training loss: 2.489870435262307
Validation loss: 2.5328766814271964

Epoch: 5| Step: 10
Training loss: 3.2791732755705087
Validation loss: 2.527781701252999

Epoch: 210| Step: 0
Training loss: 2.8584993616343293
Validation loss: 2.495984175588192

Epoch: 5| Step: 1
Training loss: 2.6696212811425153
Validation loss: 2.4931973164629007

Epoch: 5| Step: 2
Training loss: 2.982783667223713
Validation loss: 2.491918647514898

Epoch: 5| Step: 3
Training loss: 3.039772088140714
Validation loss: 2.50043937759804

Epoch: 5| Step: 4
Training loss: 2.46712546678268
Validation loss: 2.4998707112341783

Epoch: 5| Step: 5
Training loss: 2.8651694698042283
Validation loss: 2.4949049888691928

Epoch: 5| Step: 6
Training loss: 2.739082164878781
Validation loss: 2.4996099844622788

Epoch: 5| Step: 7
Training loss: 2.720901339636669
Validation loss: 2.5077828726367946

Epoch: 5| Step: 8
Training loss: 2.6869699709555546
Validation loss: 2.521569694567025

Epoch: 5| Step: 9
Training loss: 2.103950816750867
Validation loss: 2.55153178285764

Epoch: 5| Step: 10
Training loss: 3.227438745367995
Validation loss: 2.5669374768816344

Epoch: 211| Step: 0
Training loss: 2.5620734627380997
Validation loss: 2.559696167231826

Epoch: 5| Step: 1
Training loss: 3.1656466062510744
Validation loss: 2.542518440384841

Epoch: 5| Step: 2
Training loss: 3.1061055999902862
Validation loss: 2.5364170768923247

Epoch: 5| Step: 3
Training loss: 2.913421805876643
Validation loss: 2.5228223016146276

Epoch: 5| Step: 4
Training loss: 3.2763817413052316
Validation loss: 2.511098272263139

Epoch: 5| Step: 5
Training loss: 1.897923341049144
Validation loss: 2.516732554668978

Epoch: 5| Step: 6
Training loss: 2.3018029734114434
Validation loss: 2.5079337802383868

Epoch: 5| Step: 7
Training loss: 2.442465688099369
Validation loss: 2.498869966635066

Epoch: 5| Step: 8
Training loss: 2.741495854893803
Validation loss: 2.509877385209211

Epoch: 5| Step: 9
Training loss: 2.7647623559461993
Validation loss: 2.498598390858023

Epoch: 5| Step: 10
Training loss: 2.7641424310921487
Validation loss: 2.484738489008858

Epoch: 212| Step: 0
Training loss: 2.4504290302416383
Validation loss: 2.4792775285902446

Epoch: 5| Step: 1
Training loss: 2.2503031420476707
Validation loss: 2.4730792557025962

Epoch: 5| Step: 2
Training loss: 2.9894631037090087
Validation loss: 2.4699399631426537

Epoch: 5| Step: 3
Training loss: 2.9719614427511853
Validation loss: 2.4758732638460117

Epoch: 5| Step: 4
Training loss: 2.563303751615652
Validation loss: 2.4713033398207824

Epoch: 5| Step: 5
Training loss: 2.736548905651953
Validation loss: 2.464383939201004

Epoch: 5| Step: 6
Training loss: 3.063621782649422
Validation loss: 2.4615333180934855

Epoch: 5| Step: 7
Training loss: 2.5279570458903566
Validation loss: 2.4656059252025817

Epoch: 5| Step: 8
Training loss: 2.6337640780238774
Validation loss: 2.4966184860599783

Epoch: 5| Step: 9
Training loss: 2.979839133458634
Validation loss: 2.5131966695722676

Epoch: 5| Step: 10
Training loss: 2.716760367745369
Validation loss: 2.5544429512859135

Epoch: 213| Step: 0
Training loss: 3.037372030694337
Validation loss: 2.603354344491631

Epoch: 5| Step: 1
Training loss: 2.7098674146305957
Validation loss: 2.622986847295686

Epoch: 5| Step: 2
Training loss: 2.6025313672494113
Validation loss: 2.6397522437119214

Epoch: 5| Step: 3
Training loss: 2.704732075394975
Validation loss: 2.654755214101407

Epoch: 5| Step: 4
Training loss: 3.3852890851360695
Validation loss: 2.6359366761919607

Epoch: 5| Step: 5
Training loss: 3.180864196046635
Validation loss: 2.5859681551979157

Epoch: 5| Step: 6
Training loss: 2.265427574237634
Validation loss: 2.5394608157897487

Epoch: 5| Step: 7
Training loss: 2.5753989864232727
Validation loss: 2.5122515454392502

Epoch: 5| Step: 8
Training loss: 2.737507448229825
Validation loss: 2.5051518885152504

Epoch: 5| Step: 9
Training loss: 2.909294584578605
Validation loss: 2.492608603298135

Epoch: 5| Step: 10
Training loss: 2.629033214569673
Validation loss: 2.5047326442946494

Epoch: 214| Step: 0
Training loss: 2.6573481365460814
Validation loss: 2.4994552275114623

Epoch: 5| Step: 1
Training loss: 2.71952554449564
Validation loss: 2.500817665596407

Epoch: 5| Step: 2
Training loss: 2.6756475039281797
Validation loss: 2.5189870417208358

Epoch: 5| Step: 3
Training loss: 2.497745832806111
Validation loss: 2.5086182562447212

Epoch: 5| Step: 4
Training loss: 3.552908047483367
Validation loss: 2.520577355607869

Epoch: 5| Step: 5
Training loss: 2.6948777000123183
Validation loss: 2.5057977738467843

Epoch: 5| Step: 6
Training loss: 2.7534989725432757
Validation loss: 2.5009381748891752

Epoch: 5| Step: 7
Training loss: 2.525826377477311
Validation loss: 2.487719781905195

Epoch: 5| Step: 8
Training loss: 2.4886025980317097
Validation loss: 2.4957497214410087

Epoch: 5| Step: 9
Training loss: 2.7843325387990188
Validation loss: 2.491663704392727

Epoch: 5| Step: 10
Training loss: 3.108968890329261
Validation loss: 2.547458767242108

Epoch: 215| Step: 0
Training loss: 3.3110470734305704
Validation loss: 2.5588009898542277

Epoch: 5| Step: 1
Training loss: 2.615319521987209
Validation loss: 2.538228145099357

Epoch: 5| Step: 2
Training loss: 2.7315388821343576
Validation loss: 2.5101672272308293

Epoch: 5| Step: 3
Training loss: 2.385502631847023
Validation loss: 2.474109419573891

Epoch: 5| Step: 4
Training loss: 2.5337534639761103
Validation loss: 2.4636139597081863

Epoch: 5| Step: 5
Training loss: 3.2596016414621816
Validation loss: 2.4863282301716936

Epoch: 5| Step: 6
Training loss: 3.413061767841818
Validation loss: 2.4931707061302073

Epoch: 5| Step: 7
Training loss: 2.9854119381775095
Validation loss: 2.512649302769998

Epoch: 5| Step: 8
Training loss: 2.6016403965557426
Validation loss: 2.524317503216366

Epoch: 5| Step: 9
Training loss: 2.585392551683645
Validation loss: 2.5184095305607026

Epoch: 5| Step: 10
Training loss: 2.344594981145006
Validation loss: 2.5165486979677474

Epoch: 216| Step: 0
Training loss: 2.7696738051728307
Validation loss: 2.5205914574476327

Epoch: 5| Step: 1
Training loss: 3.286676334137333
Validation loss: 2.5073251057345556

Epoch: 5| Step: 2
Training loss: 2.7262327328169667
Validation loss: 2.5223072878245176

Epoch: 5| Step: 3
Training loss: 2.2137908316604786
Validation loss: 2.515989623271406

Epoch: 5| Step: 4
Training loss: 2.6971052758840655
Validation loss: 2.512633341242282

Epoch: 5| Step: 5
Training loss: 2.881071728137524
Validation loss: 2.512234422139418

Epoch: 5| Step: 6
Training loss: 2.600418343266629
Validation loss: 2.5033504492555525

Epoch: 5| Step: 7
Training loss: 3.0285519262544485
Validation loss: 2.5211176168293714

Epoch: 5| Step: 8
Training loss: 3.176246374399157
Validation loss: 2.5122842681691933

Epoch: 5| Step: 9
Training loss: 1.698355128616674
Validation loss: 2.516321109250921

Epoch: 5| Step: 10
Training loss: 3.145725644186284
Validation loss: 2.530101683270452

Epoch: 217| Step: 0
Training loss: 3.2288304964044983
Validation loss: 2.543992599347939

Epoch: 5| Step: 1
Training loss: 2.5242303600652316
Validation loss: 2.5704032821325016

Epoch: 5| Step: 2
Training loss: 2.994161965330832
Validation loss: 2.587022975445147

Epoch: 5| Step: 3
Training loss: 3.0109285933516747
Validation loss: 2.584416588738799

Epoch: 5| Step: 4
Training loss: 2.412138039113593
Validation loss: 2.5467367964545566

Epoch: 5| Step: 5
Training loss: 2.227905617890988
Validation loss: 2.5092833186947523

Epoch: 5| Step: 6
Training loss: 2.8690837857074127
Validation loss: 2.5032119944176805

Epoch: 5| Step: 7
Training loss: 2.752265950299051
Validation loss: 2.49115961601728

Epoch: 5| Step: 8
Training loss: 2.782203939338524
Validation loss: 2.498087433413886

Epoch: 5| Step: 9
Training loss: 2.988216942986578
Validation loss: 2.4732172196068807

Epoch: 5| Step: 10
Training loss: 2.5926393635885625
Validation loss: 2.4627490814915562

Epoch: 218| Step: 0
Training loss: 2.331721453001453
Validation loss: 2.4603356524758073

Epoch: 5| Step: 1
Training loss: 2.817098122531449
Validation loss: 2.462451330261676

Epoch: 5| Step: 2
Training loss: 2.3364679761243443
Validation loss: 2.4809341579280657

Epoch: 5| Step: 3
Training loss: 2.9270148942397056
Validation loss: 2.485827950282112

Epoch: 5| Step: 4
Training loss: 3.0076790123585058
Validation loss: 2.489434837690347

Epoch: 5| Step: 5
Training loss: 2.5153000900184215
Validation loss: 2.481735878134938

Epoch: 5| Step: 6
Training loss: 3.1209648019748664
Validation loss: 2.471370481243623

Epoch: 5| Step: 7
Training loss: 2.6114645261098937
Validation loss: 2.491369376941597

Epoch: 5| Step: 8
Training loss: 3.2956433639723697
Validation loss: 2.5147726828679393

Epoch: 5| Step: 9
Training loss: 2.925368235305393
Validation loss: 2.5395261148476638

Epoch: 5| Step: 10
Training loss: 2.6719995659239637
Validation loss: 2.565803917027449

Epoch: 219| Step: 0
Training loss: 3.285750000919498
Validation loss: 2.545840546197792

Epoch: 5| Step: 1
Training loss: 1.6995525163851006
Validation loss: 2.5090290551415437

Epoch: 5| Step: 2
Training loss: 2.722791890031649
Validation loss: 2.4860367864584854

Epoch: 5| Step: 3
Training loss: 2.853468500958424
Validation loss: 2.476540281207041

Epoch: 5| Step: 4
Training loss: 2.5740532365997897
Validation loss: 2.4743971038648254

Epoch: 5| Step: 5
Training loss: 2.659171080251402
Validation loss: 2.4717244197091945

Epoch: 5| Step: 6
Training loss: 2.6458135789349027
Validation loss: 2.4798120579094802

Epoch: 5| Step: 7
Training loss: 2.6914653356347698
Validation loss: 2.485017234924214

Epoch: 5| Step: 8
Training loss: 2.610833131814708
Validation loss: 2.4914316723463457

Epoch: 5| Step: 9
Training loss: 3.2186803717628267
Validation loss: 2.502014569776372

Epoch: 5| Step: 10
Training loss: 3.2381138223360537
Validation loss: 2.4972876822475065

Epoch: 220| Step: 0
Training loss: 2.8361078216437345
Validation loss: 2.4909171169467994

Epoch: 5| Step: 1
Training loss: 1.9434745716092978
Validation loss: 2.5028147633435123

Epoch: 5| Step: 2
Training loss: 2.62158871566537
Validation loss: 2.5025655062617815

Epoch: 5| Step: 3
Training loss: 2.315482613205218
Validation loss: 2.5086404831964164

Epoch: 5| Step: 4
Training loss: 3.050706537677513
Validation loss: 2.50274201628821

Epoch: 5| Step: 5
Training loss: 3.123656937951994
Validation loss: 2.4941683330113493

Epoch: 5| Step: 6
Training loss: 3.0719455714768467
Validation loss: 2.473763119174362

Epoch: 5| Step: 7
Training loss: 3.1928314799237203
Validation loss: 2.460751870702468

Epoch: 5| Step: 8
Training loss: 2.556768380653032
Validation loss: 2.4582210624284953

Epoch: 5| Step: 9
Training loss: 2.686931283791217
Validation loss: 2.469412402084516

Epoch: 5| Step: 10
Training loss: 2.957394858496251
Validation loss: 2.4720332607250577

Epoch: 221| Step: 0
Training loss: 3.0579785036338176
Validation loss: 2.4676907781246977

Epoch: 5| Step: 1
Training loss: 2.697053297388214
Validation loss: 2.472001416113796

Epoch: 5| Step: 2
Training loss: 2.7225805898741315
Validation loss: 2.4650876778192052

Epoch: 5| Step: 3
Training loss: 3.0544319533753397
Validation loss: 2.4640846163169905

Epoch: 5| Step: 4
Training loss: 3.0023895919281944
Validation loss: 2.4729253378888156

Epoch: 5| Step: 5
Training loss: 2.753497587143004
Validation loss: 2.475164942809083

Epoch: 5| Step: 6
Training loss: 3.0205687483749926
Validation loss: 2.495780567117662

Epoch: 5| Step: 7
Training loss: 2.1301720452113035
Validation loss: 2.508540127713228

Epoch: 5| Step: 8
Training loss: 2.3690246905887538
Validation loss: 2.5447800827640843

Epoch: 5| Step: 9
Training loss: 3.049373756278649
Validation loss: 2.5508290965548888

Epoch: 5| Step: 10
Training loss: 2.4036444887520503
Validation loss: 2.548552104315342

Epoch: 222| Step: 0
Training loss: 2.8784823681435636
Validation loss: 2.5561147591915017

Epoch: 5| Step: 1
Training loss: 2.5592454851890807
Validation loss: 2.5505595081388623

Epoch: 5| Step: 2
Training loss: 2.855139091029713
Validation loss: 2.5392877173106654

Epoch: 5| Step: 3
Training loss: 3.2543731024824325
Validation loss: 2.542820822923957

Epoch: 5| Step: 4
Training loss: 2.8952172994016174
Validation loss: 2.534142662750138

Epoch: 5| Step: 5
Training loss: 2.7335753225188943
Validation loss: 2.526669183512234

Epoch: 5| Step: 6
Training loss: 2.3631901494902405
Validation loss: 2.524454755830566

Epoch: 5| Step: 7
Training loss: 2.38039498185129
Validation loss: 2.519735390260583

Epoch: 5| Step: 8
Training loss: 2.5880912731767127
Validation loss: 2.5069960522953894

Epoch: 5| Step: 9
Training loss: 2.5326366629447064
Validation loss: 2.5062993272234535

Epoch: 5| Step: 10
Training loss: 3.1947101500942514
Validation loss: 2.503325707268726

Epoch: 223| Step: 0
Training loss: 2.960185979722541
Validation loss: 2.498658556620339

Epoch: 5| Step: 1
Training loss: 2.9962473286603686
Validation loss: 2.5031279837917126

Epoch: 5| Step: 2
Training loss: 3.348643777094545
Validation loss: 2.5005146142993016

Epoch: 5| Step: 3
Training loss: 3.0407121981029204
Validation loss: 2.4971933484344957

Epoch: 5| Step: 4
Training loss: 2.468072822504198
Validation loss: 2.494970627925703

Epoch: 5| Step: 5
Training loss: 2.9737208461414744
Validation loss: 2.4990070955448824

Epoch: 5| Step: 6
Training loss: 2.3882455390753545
Validation loss: 2.4967322887165304

Epoch: 5| Step: 7
Training loss: 2.0831282196798315
Validation loss: 2.4910069172650275

Epoch: 5| Step: 8
Training loss: 2.642568561454886
Validation loss: 2.493375382139849

Epoch: 5| Step: 9
Training loss: 2.672956459738306
Validation loss: 2.492889419632208

Epoch: 5| Step: 10
Training loss: 2.326217894335148
Validation loss: 2.4851463102407094

Epoch: 224| Step: 0
Training loss: 3.0274072258970337
Validation loss: 2.493467218069611

Epoch: 5| Step: 1
Training loss: 2.9698887297468968
Validation loss: 2.4810056674227243

Epoch: 5| Step: 2
Training loss: 2.78883288210307
Validation loss: 2.4787124334171295

Epoch: 5| Step: 3
Training loss: 2.633229027464946
Validation loss: 2.4705595334757513

Epoch: 5| Step: 4
Training loss: 2.343593439595171
Validation loss: 2.4843604851725205

Epoch: 5| Step: 5
Training loss: 3.2914737371248486
Validation loss: 2.4868611378240315

Epoch: 5| Step: 6
Training loss: 2.3335966801760666
Validation loss: 2.4861910670365206

Epoch: 5| Step: 7
Training loss: 2.7083264179630513
Validation loss: 2.4761985262132327

Epoch: 5| Step: 8
Training loss: 2.427079054756377
Validation loss: 2.4720535812647397

Epoch: 5| Step: 9
Training loss: 2.5346921898675365
Validation loss: 2.4691869334265224

Epoch: 5| Step: 10
Training loss: 2.7757630819750916
Validation loss: 2.4735521968679532

Epoch: 225| Step: 0
Training loss: 2.6293127870737036
Validation loss: 2.469967520200798

Epoch: 5| Step: 1
Training loss: 3.355556571264162
Validation loss: 2.465015488665582

Epoch: 5| Step: 2
Training loss: 2.4875174747025763
Validation loss: 2.4708498353698793

Epoch: 5| Step: 3
Training loss: 2.7267226907186726
Validation loss: 2.4757056971496962

Epoch: 5| Step: 4
Training loss: 2.704258675521049
Validation loss: 2.4652467989059588

Epoch: 5| Step: 5
Training loss: 2.9986763259214224
Validation loss: 2.470528831561566

Epoch: 5| Step: 6
Training loss: 2.3370450561384963
Validation loss: 2.4649056065652357

Epoch: 5| Step: 7
Training loss: 2.739675648418772
Validation loss: 2.460102490323418

Epoch: 5| Step: 8
Training loss: 2.3086144047828134
Validation loss: 2.4744844329105424

Epoch: 5| Step: 9
Training loss: 2.778450060129442
Validation loss: 2.4713751191668374

Epoch: 5| Step: 10
Training loss: 2.658187428917886
Validation loss: 2.462261504638059

Epoch: 226| Step: 0
Training loss: 3.2218716492806596
Validation loss: 2.4803327429312443

Epoch: 5| Step: 1
Training loss: 2.1119643531088514
Validation loss: 2.465271003787401

Epoch: 5| Step: 2
Training loss: 2.8452595487440577
Validation loss: 2.460543309870059

Epoch: 5| Step: 3
Training loss: 2.9782298466898682
Validation loss: 2.4583708119094787

Epoch: 5| Step: 4
Training loss: 2.3017847434253964
Validation loss: 2.4534023262181

Epoch: 5| Step: 5
Training loss: 2.4163609892352285
Validation loss: 2.4491755557661916

Epoch: 5| Step: 6
Training loss: 3.0622589639281332
Validation loss: 2.455607952875491

Epoch: 5| Step: 7
Training loss: 2.772794665130176
Validation loss: 2.458568607276851

Epoch: 5| Step: 8
Training loss: 2.8516703546062843
Validation loss: 2.4534254525624934

Epoch: 5| Step: 9
Training loss: 2.435211378788524
Validation loss: 2.4683671952796122

Epoch: 5| Step: 10
Training loss: 2.5228001406719023
Validation loss: 2.470431987335887

Epoch: 227| Step: 0
Training loss: 2.507972308144408
Validation loss: 2.4826015969766217

Epoch: 5| Step: 1
Training loss: 2.8830648999221444
Validation loss: 2.495760404325321

Epoch: 5| Step: 2
Training loss: 3.023374098475254
Validation loss: 2.500570000507982

Epoch: 5| Step: 3
Training loss: 2.976539111108076
Validation loss: 2.4925871898972396

Epoch: 5| Step: 4
Training loss: 2.8638092844773877
Validation loss: 2.4842652874310405

Epoch: 5| Step: 5
Training loss: 2.6452666349090754
Validation loss: 2.4663909138197537

Epoch: 5| Step: 6
Training loss: 2.7778101876805295
Validation loss: 2.4540105814532436

Epoch: 5| Step: 7
Training loss: 2.5868112061941626
Validation loss: 2.446115589858228

Epoch: 5| Step: 8
Training loss: 2.135366063952806
Validation loss: 2.445024843715273

Epoch: 5| Step: 9
Training loss: 2.4358042173399697
Validation loss: 2.440102430328936

Epoch: 5| Step: 10
Training loss: 2.700092709680381
Validation loss: 2.444063480638178

Epoch: 228| Step: 0
Training loss: 2.8340249246000635
Validation loss: 2.449560475305196

Epoch: 5| Step: 1
Training loss: 2.7048423471535865
Validation loss: 2.444541505836203

Epoch: 5| Step: 2
Training loss: 2.460613507938461
Validation loss: 2.4574793345030685

Epoch: 5| Step: 3
Training loss: 3.17637803217112
Validation loss: 2.468167885516105

Epoch: 5| Step: 4
Training loss: 2.5079991161277952
Validation loss: 2.478645234368551

Epoch: 5| Step: 5
Training loss: 2.9881229533236557
Validation loss: 2.4670599535221363

Epoch: 5| Step: 6
Training loss: 2.59634940179804
Validation loss: 2.4825719976436056

Epoch: 5| Step: 7
Training loss: 2.67822679573233
Validation loss: 2.4608406606470603

Epoch: 5| Step: 8
Training loss: 2.383535106716482
Validation loss: 2.455201926639756

Epoch: 5| Step: 9
Training loss: 2.8254899874408363
Validation loss: 2.450514704213958

Epoch: 5| Step: 10
Training loss: 2.4064150666926865
Validation loss: 2.457980935930945

Epoch: 229| Step: 0
Training loss: 2.582774460749544
Validation loss: 2.4493930202049286

Epoch: 5| Step: 1
Training loss: 2.5182308182551516
Validation loss: 2.4463260556058333

Epoch: 5| Step: 2
Training loss: 2.482648141365031
Validation loss: 2.451857098681113

Epoch: 5| Step: 3
Training loss: 2.3207122766596506
Validation loss: 2.4579322676187183

Epoch: 5| Step: 4
Training loss: 2.970523986832568
Validation loss: 2.4601846543789874

Epoch: 5| Step: 5
Training loss: 2.6518805974487236
Validation loss: 2.457650501893424

Epoch: 5| Step: 6
Training loss: 2.5745862313574412
Validation loss: 2.4506204722655776

Epoch: 5| Step: 7
Training loss: 2.662416189961084
Validation loss: 2.4682379082833985

Epoch: 5| Step: 8
Training loss: 2.6536056819994096
Validation loss: 2.47178790096647

Epoch: 5| Step: 9
Training loss: 3.363852422509401
Validation loss: 2.4664219515231034

Epoch: 5| Step: 10
Training loss: 2.6168484140762565
Validation loss: 2.4739806647768954

Epoch: 230| Step: 0
Training loss: 2.837712512691781
Validation loss: 2.473773286609713

Epoch: 5| Step: 1
Training loss: 2.3741809034830053
Validation loss: 2.4795259453385508

Epoch: 5| Step: 2
Training loss: 2.6597039598635352
Validation loss: 2.456691113821177

Epoch: 5| Step: 3
Training loss: 2.9108661374627056
Validation loss: 2.4631948654710545

Epoch: 5| Step: 4
Training loss: 2.753847811464402
Validation loss: 2.4578824228503358

Epoch: 5| Step: 5
Training loss: 2.7028537680317677
Validation loss: 2.44326975670974

Epoch: 5| Step: 6
Training loss: 2.7481858598582276
Validation loss: 2.454449919403469

Epoch: 5| Step: 7
Training loss: 2.845184635010495
Validation loss: 2.452735820367997

Epoch: 5| Step: 8
Training loss: 2.6524988053271508
Validation loss: 2.440491552019789

Epoch: 5| Step: 9
Training loss: 2.530841558964534
Validation loss: 2.4485576962389617

Epoch: 5| Step: 10
Training loss: 2.429859412879153
Validation loss: 2.445222218344206

Epoch: 231| Step: 0
Training loss: 2.7864290515157317
Validation loss: 2.4529795663974308

Epoch: 5| Step: 1
Training loss: 2.306931053437649
Validation loss: 2.4671178801522835

Epoch: 5| Step: 2
Training loss: 3.1840312259331385
Validation loss: 2.4804598161444296

Epoch: 5| Step: 3
Training loss: 2.6889362489542106
Validation loss: 2.487062849017689

Epoch: 5| Step: 4
Training loss: 2.5316835197036793
Validation loss: 2.489961147966452

Epoch: 5| Step: 5
Training loss: 3.068847462025153
Validation loss: 2.4720033035820412

Epoch: 5| Step: 6
Training loss: 2.0801123961011863
Validation loss: 2.4692527650542027

Epoch: 5| Step: 7
Training loss: 3.1100314420233013
Validation loss: 2.464493692686852

Epoch: 5| Step: 8
Training loss: 2.6060065725248047
Validation loss: 2.4770821728443138

Epoch: 5| Step: 9
Training loss: 2.333534254778596
Validation loss: 2.447140147970803

Epoch: 5| Step: 10
Training loss: 2.612155278291567
Validation loss: 2.450141877349649

Epoch: 232| Step: 0
Training loss: 2.736873422619177
Validation loss: 2.4557595862737482

Epoch: 5| Step: 1
Training loss: 2.5615941749430275
Validation loss: 2.453145787543089

Epoch: 5| Step: 2
Training loss: 2.586421033938795
Validation loss: 2.4535478423833577

Epoch: 5| Step: 3
Training loss: 2.2527664978689863
Validation loss: 2.4685445751717627

Epoch: 5| Step: 4
Training loss: 2.997305613777616
Validation loss: 2.485078801344005

Epoch: 5| Step: 5
Training loss: 2.435389852471367
Validation loss: 2.4901271917161085

Epoch: 5| Step: 6
Training loss: 2.315903092750162
Validation loss: 2.500308926271352

Epoch: 5| Step: 7
Training loss: 3.0848600027508972
Validation loss: 2.50307187579408

Epoch: 5| Step: 8
Training loss: 2.047768783533485
Validation loss: 2.502869491253699

Epoch: 5| Step: 9
Training loss: 3.0974462757885703
Validation loss: 2.4771653457348646

Epoch: 5| Step: 10
Training loss: 3.2690241157153337
Validation loss: 2.477882324191107

Epoch: 233| Step: 0
Training loss: 3.177341654964194
Validation loss: 2.4606849896354515

Epoch: 5| Step: 1
Training loss: 2.3398618872549344
Validation loss: 2.470108268139832

Epoch: 5| Step: 2
Training loss: 2.6198365426944124
Validation loss: 2.4623291758000128

Epoch: 5| Step: 3
Training loss: 2.6756335141127345
Validation loss: 2.4595604641290323

Epoch: 5| Step: 4
Training loss: 2.722033830425462
Validation loss: 2.4637325490156394

Epoch: 5| Step: 5
Training loss: 3.0226705993012013
Validation loss: 2.460449706898875

Epoch: 5| Step: 6
Training loss: 2.6899553659699715
Validation loss: 2.4586813297841257

Epoch: 5| Step: 7
Training loss: 2.3171468904811907
Validation loss: 2.4635129703745307

Epoch: 5| Step: 8
Training loss: 2.25511287871897
Validation loss: 2.467285212878401

Epoch: 5| Step: 9
Training loss: 2.785444119036873
Validation loss: 2.477184985124529

Epoch: 5| Step: 10
Training loss: 2.8224627891229828
Validation loss: 2.487864544896965

Epoch: 234| Step: 0
Training loss: 2.887511520032485
Validation loss: 2.4915032144435854

Epoch: 5| Step: 1
Training loss: 2.230895741439654
Validation loss: 2.4930408842707195

Epoch: 5| Step: 2
Training loss: 3.0355499287198318
Validation loss: 2.475279112459877

Epoch: 5| Step: 3
Training loss: 2.8444546675332787
Validation loss: 2.4577833926306285

Epoch: 5| Step: 4
Training loss: 2.1239920076697603
Validation loss: 2.456546424618715

Epoch: 5| Step: 5
Training loss: 2.9853383052432987
Validation loss: 2.4641301647323934

Epoch: 5| Step: 6
Training loss: 3.052244179993101
Validation loss: 2.4624443476415894

Epoch: 5| Step: 7
Training loss: 2.5166887202359747
Validation loss: 2.453917468952875

Epoch: 5| Step: 8
Training loss: 2.6527145194011457
Validation loss: 2.4525698774450424

Epoch: 5| Step: 9
Training loss: 2.651553321332449
Validation loss: 2.450869811459523

Epoch: 5| Step: 10
Training loss: 2.276653833069196
Validation loss: 2.459610864830549

Epoch: 235| Step: 0
Training loss: 2.9907710853859517
Validation loss: 2.4424948576847663

Epoch: 5| Step: 1
Training loss: 2.5296847366402737
Validation loss: 2.4469271539554422

Epoch: 5| Step: 2
Training loss: 2.4340295784061268
Validation loss: 2.452962729570519

Epoch: 5| Step: 3
Training loss: 3.3065480435023558
Validation loss: 2.4432203924283615

Epoch: 5| Step: 4
Training loss: 2.5655244795962706
Validation loss: 2.443770826523889

Epoch: 5| Step: 5
Training loss: 3.1755286910452196
Validation loss: 2.4461550484561108

Epoch: 5| Step: 6
Training loss: 2.0639174243613816
Validation loss: 2.4470857420025798

Epoch: 5| Step: 7
Training loss: 2.832229249544015
Validation loss: 2.443068169646188

Epoch: 5| Step: 8
Training loss: 2.4013950862869513
Validation loss: 2.443300936508379

Epoch: 5| Step: 9
Training loss: 2.703753800656226
Validation loss: 2.467282465620168

Epoch: 5| Step: 10
Training loss: 2.14370194539742
Validation loss: 2.48508207774606

Epoch: 236| Step: 0
Training loss: 2.7310414948302
Validation loss: 2.4740067338769522

Epoch: 5| Step: 1
Training loss: 2.4531143091053864
Validation loss: 2.461576751641608

Epoch: 5| Step: 2
Training loss: 2.3369142665456453
Validation loss: 2.468584578239291

Epoch: 5| Step: 3
Training loss: 2.6239329394517203
Validation loss: 2.467881242598952

Epoch: 5| Step: 4
Training loss: 2.904532468535824
Validation loss: 2.450091728651339

Epoch: 5| Step: 5
Training loss: 2.381941439148169
Validation loss: 2.4416388844557866

Epoch: 5| Step: 6
Training loss: 2.6247473095568417
Validation loss: 2.4426268149789734

Epoch: 5| Step: 7
Training loss: 2.703200499081121
Validation loss: 2.450064762105849

Epoch: 5| Step: 8
Training loss: 3.0661233759354043
Validation loss: 2.463333238310309

Epoch: 5| Step: 9
Training loss: 2.5917917235724994
Validation loss: 2.458210862996958

Epoch: 5| Step: 10
Training loss: 3.023887265682476
Validation loss: 2.4652281604861357

Epoch: 237| Step: 0
Training loss: 2.747991782302452
Validation loss: 2.463987402799286

Epoch: 5| Step: 1
Training loss: 2.7089859591852794
Validation loss: 2.4460218026533713

Epoch: 5| Step: 2
Training loss: 2.4064614339306596
Validation loss: 2.448745648612649

Epoch: 5| Step: 3
Training loss: 2.7595792735816445
Validation loss: 2.4491786247947127

Epoch: 5| Step: 4
Training loss: 2.2896801632742405
Validation loss: 2.4655232649049568

Epoch: 5| Step: 5
Training loss: 2.166916930588209
Validation loss: 2.4615614608371716

Epoch: 5| Step: 6
Training loss: 3.1885628517707447
Validation loss: 2.478011508375598

Epoch: 5| Step: 7
Training loss: 2.8157851636171545
Validation loss: 2.4599684044711196

Epoch: 5| Step: 8
Training loss: 2.5969136259325607
Validation loss: 2.475207439076903

Epoch: 5| Step: 9
Training loss: 2.917235745816145
Validation loss: 2.4682384400732476

Epoch: 5| Step: 10
Training loss: 2.6279394857676865
Validation loss: 2.4512952736163016

Epoch: 238| Step: 0
Training loss: 2.6634306843630253
Validation loss: 2.4647629571541954

Epoch: 5| Step: 1
Training loss: 3.1822739188057843
Validation loss: 2.4461909882394597

Epoch: 5| Step: 2
Training loss: 2.780252513532083
Validation loss: 2.4528212507189022

Epoch: 5| Step: 3
Training loss: 2.5719566767946054
Validation loss: 2.4573756842110415

Epoch: 5| Step: 4
Training loss: 2.6000148992845147
Validation loss: 2.449872085809893

Epoch: 5| Step: 5
Training loss: 2.5079777268024546
Validation loss: 2.4520184657614643

Epoch: 5| Step: 6
Training loss: 2.3004632027296235
Validation loss: 2.4548242349437612

Epoch: 5| Step: 7
Training loss: 2.9160947693127675
Validation loss: 2.4589825015175886

Epoch: 5| Step: 8
Training loss: 2.4147688440301853
Validation loss: 2.4742405207284013

Epoch: 5| Step: 9
Training loss: 2.6059575344440447
Validation loss: 2.4893293789683777

Epoch: 5| Step: 10
Training loss: 2.6852844331993246
Validation loss: 2.496414273116379

Epoch: 239| Step: 0
Training loss: 2.752419794284387
Validation loss: 2.526931619795111

Epoch: 5| Step: 1
Training loss: 2.748791949484186
Validation loss: 2.5372553161996265

Epoch: 5| Step: 2
Training loss: 2.6665401627416303
Validation loss: 2.50656234877055

Epoch: 5| Step: 3
Training loss: 3.151694607932749
Validation loss: 2.497021236673171

Epoch: 5| Step: 4
Training loss: 2.56870449053693
Validation loss: 2.477379007965892

Epoch: 5| Step: 5
Training loss: 2.5358691043526678
Validation loss: 2.4639236149598975

Epoch: 5| Step: 6
Training loss: 2.536409935042351
Validation loss: 2.461687859676651

Epoch: 5| Step: 7
Training loss: 2.19226579587494
Validation loss: 2.4558026939329256

Epoch: 5| Step: 8
Training loss: 2.550734889031217
Validation loss: 2.46214472076141

Epoch: 5| Step: 9
Training loss: 2.8488785327472534
Validation loss: 2.4527735524035146

Epoch: 5| Step: 10
Training loss: 3.1378293476273598
Validation loss: 2.4428840306570407

Epoch: 240| Step: 0
Training loss: 2.651921414219287
Validation loss: 2.4590338961377722

Epoch: 5| Step: 1
Training loss: 2.481684061129933
Validation loss: 2.463970468996584

Epoch: 5| Step: 2
Training loss: 2.8023207515456643
Validation loss: 2.4756948624892217

Epoch: 5| Step: 3
Training loss: 2.755207592988711
Validation loss: 2.4960416784893447

Epoch: 5| Step: 4
Training loss: 2.9088349690340283
Validation loss: 2.4880275044769555

Epoch: 5| Step: 5
Training loss: 3.2390311078152707
Validation loss: 2.4802983635093567

Epoch: 5| Step: 6
Training loss: 2.549675647826337
Validation loss: 2.458345873762306

Epoch: 5| Step: 7
Training loss: 1.7516943358762516
Validation loss: 2.4554747522977465

Epoch: 5| Step: 8
Training loss: 2.8061517065288775
Validation loss: 2.449896012510894

Epoch: 5| Step: 9
Training loss: 2.074030348560326
Validation loss: 2.4521055050156995

Epoch: 5| Step: 10
Training loss: 3.132094760021541
Validation loss: 2.453034588885302

Epoch: 241| Step: 0
Training loss: 2.7650085451845983
Validation loss: 2.4556321264438594

Epoch: 5| Step: 1
Training loss: 2.1998588213271213
Validation loss: 2.4749066051098922

Epoch: 5| Step: 2
Training loss: 2.5737993422563497
Validation loss: 2.497483001624531

Epoch: 5| Step: 3
Training loss: 2.4335183121207957
Validation loss: 2.5444090159932733

Epoch: 5| Step: 4
Training loss: 2.7674597564776158
Validation loss: 2.5517013582050714

Epoch: 5| Step: 5
Training loss: 2.6167274184575136
Validation loss: 2.51299468829219

Epoch: 5| Step: 6
Training loss: 3.1586623839895065
Validation loss: 2.4766084265572545

Epoch: 5| Step: 7
Training loss: 2.843551796514002
Validation loss: 2.459171688928861

Epoch: 5| Step: 8
Training loss: 2.6210641873507496
Validation loss: 2.4542985247230447

Epoch: 5| Step: 9
Training loss: 2.7447302351174905
Validation loss: 2.4490671114983678

Epoch: 5| Step: 10
Training loss: 2.647915679027054
Validation loss: 2.4484416670109095

Epoch: 242| Step: 0
Training loss: 3.0064028124127677
Validation loss: 2.454002198976107

Epoch: 5| Step: 1
Training loss: 3.0363123200492423
Validation loss: 2.4510290172471834

Epoch: 5| Step: 2
Training loss: 2.8438086870446724
Validation loss: 2.4591531253933

Epoch: 5| Step: 3
Training loss: 2.1286553751264408
Validation loss: 2.4614765218240726

Epoch: 5| Step: 4
Training loss: 2.7462225025104354
Validation loss: 2.465961828387497

Epoch: 5| Step: 5
Training loss: 2.5327594165545997
Validation loss: 2.4535071338770775

Epoch: 5| Step: 6
Training loss: 2.74392488656515
Validation loss: 2.465259707304383

Epoch: 5| Step: 7
Training loss: 2.473342390515109
Validation loss: 2.474359308378132

Epoch: 5| Step: 8
Training loss: 2.649817003373476
Validation loss: 2.4790144580895865

Epoch: 5| Step: 9
Training loss: 2.5748415296364313
Validation loss: 2.4841486164123627

Epoch: 5| Step: 10
Training loss: 2.6507922481777535
Validation loss: 2.487059907140002

Epoch: 243| Step: 0
Training loss: 2.742933296880636
Validation loss: 2.4516712931902087

Epoch: 5| Step: 1
Training loss: 2.30965330849817
Validation loss: 2.4464962083049566

Epoch: 5| Step: 2
Training loss: 2.6025789125408276
Validation loss: 2.441138324302296

Epoch: 5| Step: 3
Training loss: 2.9795838888604624
Validation loss: 2.432537248714075

Epoch: 5| Step: 4
Training loss: 2.974425823036373
Validation loss: 2.4360423203329646

Epoch: 5| Step: 5
Training loss: 2.511832084887136
Validation loss: 2.434424217990615

Epoch: 5| Step: 6
Training loss: 2.5621131046650127
Validation loss: 2.439043004707185

Epoch: 5| Step: 7
Training loss: 2.815600741638615
Validation loss: 2.4503958942250375

Epoch: 5| Step: 8
Training loss: 2.328258433774511
Validation loss: 2.4524231086781243

Epoch: 5| Step: 9
Training loss: 2.8725753179358686
Validation loss: 2.462167283950955

Epoch: 5| Step: 10
Training loss: 2.718382010274527
Validation loss: 2.4588423021825987

Epoch: 244| Step: 0
Training loss: 2.5368983039246107
Validation loss: 2.4555447831016024

Epoch: 5| Step: 1
Training loss: 2.6490325709321
Validation loss: 2.4634759169163005

Epoch: 5| Step: 2
Training loss: 3.1821252724224496
Validation loss: 2.4592383401135747

Epoch: 5| Step: 3
Training loss: 2.876001598203849
Validation loss: 2.4646413177278466

Epoch: 5| Step: 4
Training loss: 2.6980686414963713
Validation loss: 2.4822035798935316

Epoch: 5| Step: 5
Training loss: 2.9388158570004723
Validation loss: 2.4775356260833625

Epoch: 5| Step: 6
Training loss: 2.747833265340852
Validation loss: 2.519870816002605

Epoch: 5| Step: 7
Training loss: 2.544386414343227
Validation loss: 2.5287220397850017

Epoch: 5| Step: 8
Training loss: 2.2017699057981996
Validation loss: 2.5277342110436276

Epoch: 5| Step: 9
Training loss: 2.2891944612866975
Validation loss: 2.531810895343009

Epoch: 5| Step: 10
Training loss: 2.6432571384597283
Validation loss: 2.5228988462164765

Epoch: 245| Step: 0
Training loss: 2.6718864217592126
Validation loss: 2.470553864644594

Epoch: 5| Step: 1
Training loss: 2.736936143608965
Validation loss: 2.449993717670234

Epoch: 5| Step: 2
Training loss: 3.100597933047662
Validation loss: 2.459614219976558

Epoch: 5| Step: 3
Training loss: 2.327857699826622
Validation loss: 2.4493840117300354

Epoch: 5| Step: 4
Training loss: 3.2772711471863563
Validation loss: 2.45982473763704

Epoch: 5| Step: 5
Training loss: 1.956208686270489
Validation loss: 2.448606608463309

Epoch: 5| Step: 6
Training loss: 2.4946185365835807
Validation loss: 2.4615453148860142

Epoch: 5| Step: 7
Training loss: 2.9233999913560322
Validation loss: 2.445960120456163

Epoch: 5| Step: 8
Training loss: 2.662355564121891
Validation loss: 2.454722138312784

Epoch: 5| Step: 9
Training loss: 2.7405534097679562
Validation loss: 2.4546974252372067

Epoch: 5| Step: 10
Training loss: 2.532196433126771
Validation loss: 2.446401053481362

Epoch: 246| Step: 0
Training loss: 2.6557568260578437
Validation loss: 2.473715873369738

Epoch: 5| Step: 1
Training loss: 2.3638157768114842
Validation loss: 2.4858057802729245

Epoch: 5| Step: 2
Training loss: 2.809749360225064
Validation loss: 2.5324520658313916

Epoch: 5| Step: 3
Training loss: 2.0961062709279408
Validation loss: 2.55942328484633

Epoch: 5| Step: 4
Training loss: 3.099549531509185
Validation loss: 2.5809510106497444

Epoch: 5| Step: 5
Training loss: 2.725379140533618
Validation loss: 2.5405440134869512

Epoch: 5| Step: 6
Training loss: 2.3712395461379385
Validation loss: 2.501401305473373

Epoch: 5| Step: 7
Training loss: 3.0040241907824496
Validation loss: 2.480069169311439

Epoch: 5| Step: 8
Training loss: 2.7867947289215653
Validation loss: 2.4653445029762424

Epoch: 5| Step: 9
Training loss: 2.8834413085594837
Validation loss: 2.443694017462103

Epoch: 5| Step: 10
Training loss: 2.576994214461097
Validation loss: 2.4305426161773704

Epoch: 247| Step: 0
Training loss: 2.5965625267382317
Validation loss: 2.43588682105902

Epoch: 5| Step: 1
Training loss: 3.067913486807707
Validation loss: 2.4420123208158353

Epoch: 5| Step: 2
Training loss: 2.475146445363359
Validation loss: 2.44048099801761

Epoch: 5| Step: 3
Training loss: 2.678975091218221
Validation loss: 2.447014373257806

Epoch: 5| Step: 4
Training loss: 2.9309943374376055
Validation loss: 2.442248466540638

Epoch: 5| Step: 5
Training loss: 2.6077362213955646
Validation loss: 2.4365913658003784

Epoch: 5| Step: 6
Training loss: 2.6102328232440355
Validation loss: 2.434778457417494

Epoch: 5| Step: 7
Training loss: 2.237689780599451
Validation loss: 2.4416168948946186

Epoch: 5| Step: 8
Training loss: 2.800251121840224
Validation loss: 2.476171283871231

Epoch: 5| Step: 9
Training loss: 2.6838650628748484
Validation loss: 2.516469945134356

Epoch: 5| Step: 10
Training loss: 2.591981491723326
Validation loss: 2.5118572880942427

Epoch: 248| Step: 0
Training loss: 2.8956700194342235
Validation loss: 2.536523695872956

Epoch: 5| Step: 1
Training loss: 2.6655775667467005
Validation loss: 2.505324293080283

Epoch: 5| Step: 2
Training loss: 3.0086348561282352
Validation loss: 2.470335772353487

Epoch: 5| Step: 3
Training loss: 3.051850623588699
Validation loss: 2.457882246578566

Epoch: 5| Step: 4
Training loss: 2.7656905171882906
Validation loss: 2.4393403442083823

Epoch: 5| Step: 5
Training loss: 2.6645108290395156
Validation loss: 2.4393506351529033

Epoch: 5| Step: 6
Training loss: 2.4612683270625966
Validation loss: 2.4361276015580247

Epoch: 5| Step: 7
Training loss: 2.887087084818736
Validation loss: 2.4376056207575747

Epoch: 5| Step: 8
Training loss: 2.550352004943846
Validation loss: 2.449160732890464

Epoch: 5| Step: 9
Training loss: 2.1434221022492617
Validation loss: 2.448756209918179

Epoch: 5| Step: 10
Training loss: 2.343054909948795
Validation loss: 2.460765193357259

Epoch: 249| Step: 0
Training loss: 3.0485939849936323
Validation loss: 2.4693753795297657

Epoch: 5| Step: 1
Training loss: 2.3733747844433757
Validation loss: 2.516502176484853

Epoch: 5| Step: 2
Training loss: 3.2891796390215458
Validation loss: 2.5522668112487747

Epoch: 5| Step: 3
Training loss: 2.86712330426686
Validation loss: 2.568915132061617

Epoch: 5| Step: 4
Training loss: 2.6687576222366727
Validation loss: 2.5853456164886097

Epoch: 5| Step: 5
Training loss: 3.0879928504386713
Validation loss: 2.547141240830488

Epoch: 5| Step: 6
Training loss: 1.6397936940106936
Validation loss: 2.5021810667055617

Epoch: 5| Step: 7
Training loss: 2.3263934563992072
Validation loss: 2.4818318598196876

Epoch: 5| Step: 8
Training loss: 2.802558792409556
Validation loss: 2.455465239931533

Epoch: 5| Step: 9
Training loss: 2.365488682879668
Validation loss: 2.4534533372186793

Epoch: 5| Step: 10
Training loss: 2.879772371727298
Validation loss: 2.4416209121018317

Epoch: 250| Step: 0
Training loss: 2.5911892118928392
Validation loss: 2.445711469925685

Epoch: 5| Step: 1
Training loss: 2.8466947630389834
Validation loss: 2.4422677348511788

Epoch: 5| Step: 2
Training loss: 2.569325822950207
Validation loss: 2.437236718030469

Epoch: 5| Step: 3
Training loss: 2.8301660749144526
Validation loss: 2.4367300226254813

Epoch: 5| Step: 4
Training loss: 2.8008675661712354
Validation loss: 2.44517480480297

Epoch: 5| Step: 5
Training loss: 2.6164114185736684
Validation loss: 2.445002781851111

Epoch: 5| Step: 6
Training loss: 2.388946741965946
Validation loss: 2.4516212991682433

Epoch: 5| Step: 7
Training loss: 3.024565572518774
Validation loss: 2.4735386632497662

Epoch: 5| Step: 8
Training loss: 2.67945286916379
Validation loss: 2.4921229881299802

Epoch: 5| Step: 9
Training loss: 2.510123545733108
Validation loss: 2.4914398506891655

Epoch: 5| Step: 10
Training loss: 2.1314033072810443
Validation loss: 2.504339940570299

Epoch: 251| Step: 0
Training loss: 2.5226541253934807
Validation loss: 2.4983477526525566

Epoch: 5| Step: 1
Training loss: 2.4409935198005948
Validation loss: 2.507194816355148

Epoch: 5| Step: 2
Training loss: 2.75410268096544
Validation loss: 2.5140130471974134

Epoch: 5| Step: 3
Training loss: 1.689817038795405
Validation loss: 2.5169803293394364

Epoch: 5| Step: 4
Training loss: 2.934855142947094
Validation loss: 2.5089907427102895

Epoch: 5| Step: 5
Training loss: 2.169348475305895
Validation loss: 2.49654290705774

Epoch: 5| Step: 6
Training loss: 3.065416154348512
Validation loss: 2.4864037928214016

Epoch: 5| Step: 7
Training loss: 2.798168543889415
Validation loss: 2.468950200403906

Epoch: 5| Step: 8
Training loss: 2.5247140968037085
Validation loss: 2.454935253853319

Epoch: 5| Step: 9
Training loss: 3.1051108100026026
Validation loss: 2.466596906205442

Epoch: 5| Step: 10
Training loss: 2.872722055004636
Validation loss: 2.4614734582345745

Epoch: 252| Step: 0
Training loss: 2.5854961099235734
Validation loss: 2.4497535633107597

Epoch: 5| Step: 1
Training loss: 2.4393652601582736
Validation loss: 2.438750444554535

Epoch: 5| Step: 2
Training loss: 2.235521142609198
Validation loss: 2.462685449476902

Epoch: 5| Step: 3
Training loss: 2.2360656317698995
Validation loss: 2.4737497131433384

Epoch: 5| Step: 4
Training loss: 3.5041396319555673
Validation loss: 2.4787378678831056

Epoch: 5| Step: 5
Training loss: 3.0382399046388104
Validation loss: 2.48098682344723

Epoch: 5| Step: 6
Training loss: 2.0719580678268477
Validation loss: 2.5207119814787324

Epoch: 5| Step: 7
Training loss: 2.78311497598895
Validation loss: 2.540088803950767

Epoch: 5| Step: 8
Training loss: 2.2912726554853533
Validation loss: 2.5340912334745145

Epoch: 5| Step: 9
Training loss: 3.0223501847640457
Validation loss: 2.498152571182251

Epoch: 5| Step: 10
Training loss: 2.6154323784967675
Validation loss: 2.47595641366853

Epoch: 253| Step: 0
Training loss: 2.114612096832031
Validation loss: 2.447789828318356

Epoch: 5| Step: 1
Training loss: 2.522057406837721
Validation loss: 2.444830591603122

Epoch: 5| Step: 2
Training loss: 2.7987644909734435
Validation loss: 2.4316448210480592

Epoch: 5| Step: 3
Training loss: 2.953562063339708
Validation loss: 2.4384658641546744

Epoch: 5| Step: 4
Training loss: 2.4293831883069954
Validation loss: 2.4286204556571085

Epoch: 5| Step: 5
Training loss: 2.6691742570975387
Validation loss: 2.438508386015084

Epoch: 5| Step: 6
Training loss: 2.9751658930325973
Validation loss: 2.4437483116840437

Epoch: 5| Step: 7
Training loss: 2.684045478748176
Validation loss: 2.4494540523515393

Epoch: 5| Step: 8
Training loss: 2.6582088652583136
Validation loss: 2.4538244584393336

Epoch: 5| Step: 9
Training loss: 2.496562501833576
Validation loss: 2.4748447835658376

Epoch: 5| Step: 10
Training loss: 3.1273149689630078
Validation loss: 2.5099736686031027

Epoch: 254| Step: 0
Training loss: 1.776196656684491
Validation loss: 2.4814871722639955

Epoch: 5| Step: 1
Training loss: 2.770413751790447
Validation loss: 2.4766294833200253

Epoch: 5| Step: 2
Training loss: 2.32610084559771
Validation loss: 2.476390662506962

Epoch: 5| Step: 3
Training loss: 2.914685875536463
Validation loss: 2.460302568087088

Epoch: 5| Step: 4
Training loss: 2.824408940286267
Validation loss: 2.476243927379967

Epoch: 5| Step: 5
Training loss: 2.8904550863279472
Validation loss: 2.4741342734364324

Epoch: 5| Step: 6
Training loss: 2.6651075891817317
Validation loss: 2.4738303731177513

Epoch: 5| Step: 7
Training loss: 2.862333341186329
Validation loss: 2.4708647812929927

Epoch: 5| Step: 8
Training loss: 2.5004411308194894
Validation loss: 2.4631061291662535

Epoch: 5| Step: 9
Training loss: 2.7615340844212235
Validation loss: 2.4644976944489776

Epoch: 5| Step: 10
Training loss: 2.3196795592492676
Validation loss: 2.486373887670691

Epoch: 255| Step: 0
Training loss: 2.0580543231152357
Validation loss: 2.47423563846797

Epoch: 5| Step: 1
Training loss: 2.8504412393152507
Validation loss: 2.4978517757320287

Epoch: 5| Step: 2
Training loss: 2.9111447697150443
Validation loss: 2.4956958071023165

Epoch: 5| Step: 3
Training loss: 2.7168666411052524
Validation loss: 2.5082583208293916

Epoch: 5| Step: 4
Training loss: 2.422979189283903
Validation loss: 2.508087577577952

Epoch: 5| Step: 5
Training loss: 2.576846273790891
Validation loss: 2.5029082681678347

Epoch: 5| Step: 6
Training loss: 3.035936802634779
Validation loss: 2.488454457667129

Epoch: 5| Step: 7
Training loss: 2.4244854056622587
Validation loss: 2.4942189697194648

Epoch: 5| Step: 8
Training loss: 2.545371331365735
Validation loss: 2.4663582656280005

Epoch: 5| Step: 9
Training loss: 2.4006073421672047
Validation loss: 2.453231672302479

Epoch: 5| Step: 10
Training loss: 2.725122721997134
Validation loss: 2.448504515375345

Epoch: 256| Step: 0
Training loss: 2.560915294129674
Validation loss: 2.4475642117895373

Epoch: 5| Step: 1
Training loss: 2.428933471252306
Validation loss: 2.4278241053014207

Epoch: 5| Step: 2
Training loss: 2.930370688571076
Validation loss: 2.4350100774034913

Epoch: 5| Step: 3
Training loss: 2.7970586961486754
Validation loss: 2.432100525177485

Epoch: 5| Step: 4
Training loss: 1.490915205434411
Validation loss: 2.439255586245526

Epoch: 5| Step: 5
Training loss: 2.6506908811707888
Validation loss: 2.4386788108496975

Epoch: 5| Step: 6
Training loss: 3.3717142287737163
Validation loss: 2.481061812042412

Epoch: 5| Step: 7
Training loss: 2.793055649052416
Validation loss: 2.5013117578991797

Epoch: 5| Step: 8
Training loss: 2.501908908664714
Validation loss: 2.5129343505818027

Epoch: 5| Step: 9
Training loss: 2.023853863035407
Validation loss: 2.5154531770895656

Epoch: 5| Step: 10
Training loss: 2.8638166106664036
Validation loss: 2.5402652084869795

Epoch: 257| Step: 0
Training loss: 2.4314847229766525
Validation loss: 2.487744590993093

Epoch: 5| Step: 1
Training loss: 2.222012230435145
Validation loss: 2.456730147942822

Epoch: 5| Step: 2
Training loss: 2.3747231171481182
Validation loss: 2.4256195367966766

Epoch: 5| Step: 3
Training loss: 2.6725376489769
Validation loss: 2.4293689791356003

Epoch: 5| Step: 4
Training loss: 2.783822316676554
Validation loss: 2.4241735289230664

Epoch: 5| Step: 5
Training loss: 2.685168829925343
Validation loss: 2.4155740715008864

Epoch: 5| Step: 6
Training loss: 2.7657518950408178
Validation loss: 2.417296578572635

Epoch: 5| Step: 7
Training loss: 2.3502394290455455
Validation loss: 2.4168780891714405

Epoch: 5| Step: 8
Training loss: 2.690286832641145
Validation loss: 2.4157915171493327

Epoch: 5| Step: 9
Training loss: 2.59737207679652
Validation loss: 2.414338406170089

Epoch: 5| Step: 10
Training loss: 3.046040895193771
Validation loss: 2.4164701480191773

Epoch: 258| Step: 0
Training loss: 2.576573592902942
Validation loss: 2.4235724855194722

Epoch: 5| Step: 1
Training loss: 1.7162221873253183
Validation loss: 2.447994534823385

Epoch: 5| Step: 2
Training loss: 2.6904751477840314
Validation loss: 2.465691531390382

Epoch: 5| Step: 3
Training loss: 3.399421637092969
Validation loss: 2.4729739340188472

Epoch: 5| Step: 4
Training loss: 2.6239054986637704
Validation loss: 2.481959842709001

Epoch: 5| Step: 5
Training loss: 2.5699409749715354
Validation loss: 2.4953848334260376

Epoch: 5| Step: 6
Training loss: 2.4722020604410404
Validation loss: 2.531528386189833

Epoch: 5| Step: 7
Training loss: 2.5378369939115504
Validation loss: 2.5222604045001944

Epoch: 5| Step: 8
Training loss: 2.240779421285361
Validation loss: 2.5411071067254665

Epoch: 5| Step: 9
Training loss: 2.953781942936624
Validation loss: 2.5295650982153925

Epoch: 5| Step: 10
Training loss: 2.756038797811363
Validation loss: 2.510044297160528

Epoch: 259| Step: 0
Training loss: 3.0624033075755244
Validation loss: 2.4788817023650904

Epoch: 5| Step: 1
Training loss: 2.6914532882942757
Validation loss: 2.467707012687304

Epoch: 5| Step: 2
Training loss: 1.9673934986222306
Validation loss: 2.479811955562842

Epoch: 5| Step: 3
Training loss: 3.0434104589053566
Validation loss: 2.498958145979605

Epoch: 5| Step: 4
Training loss: 2.4319352427255936
Validation loss: 2.4987374122056045

Epoch: 5| Step: 5
Training loss: 2.7398635276165453
Validation loss: 2.499598228821101

Epoch: 5| Step: 6
Training loss: 2.537860010475317
Validation loss: 2.4658998657636473

Epoch: 5| Step: 7
Training loss: 2.601289293761393
Validation loss: 2.4515268117607

Epoch: 5| Step: 8
Training loss: 2.6455699058615965
Validation loss: 2.423547800711035

Epoch: 5| Step: 9
Training loss: 2.2922477563428303
Validation loss: 2.4212821920336034

Epoch: 5| Step: 10
Training loss: 2.189201238403026
Validation loss: 2.419866578456402

Epoch: 260| Step: 0
Training loss: 2.728205756776082
Validation loss: 2.4203767342464033

Epoch: 5| Step: 1
Training loss: 3.0975394112679036
Validation loss: 2.4285798539509904

Epoch: 5| Step: 2
Training loss: 2.5450374784876426
Validation loss: 2.448465295672292

Epoch: 5| Step: 3
Training loss: 2.5974136583445717
Validation loss: 2.4479014322666037

Epoch: 5| Step: 4
Training loss: 2.300113185917116
Validation loss: 2.459724739200512

Epoch: 5| Step: 5
Training loss: 2.9227223519092775
Validation loss: 2.4797165997422153

Epoch: 5| Step: 6
Training loss: 2.438634950552892
Validation loss: 2.478809080310462

Epoch: 5| Step: 7
Training loss: 2.2531768835181163
Validation loss: 2.4717794211281383

Epoch: 5| Step: 8
Training loss: 2.597348302499742
Validation loss: 2.4689663612694663

Epoch: 5| Step: 9
Training loss: 2.138717581203951
Validation loss: 2.4612491106325147

Epoch: 5| Step: 10
Training loss: 2.5208924867189295
Validation loss: 2.466461676677327

Epoch: 261| Step: 0
Training loss: 2.5691808742939153
Validation loss: 2.4895697986469827

Epoch: 5| Step: 1
Training loss: 2.206668033925965
Validation loss: 2.523012195068864

Epoch: 5| Step: 2
Training loss: 2.8190344453393985
Validation loss: 2.5336910364296195

Epoch: 5| Step: 3
Training loss: 2.1690644665604606
Validation loss: 2.5415403582494887

Epoch: 5| Step: 4
Training loss: 2.6868190346226877
Validation loss: 2.5380703137124776

Epoch: 5| Step: 5
Training loss: 2.672471275496384
Validation loss: 2.510182447659232

Epoch: 5| Step: 6
Training loss: 2.4971405842918184
Validation loss: 2.501640503495078

Epoch: 5| Step: 7
Training loss: 2.367799686046302
Validation loss: 2.495007058500925

Epoch: 5| Step: 8
Training loss: 2.7668997202997483
Validation loss: 2.474207542488313

Epoch: 5| Step: 9
Training loss: 3.2643958886106517
Validation loss: 2.4706407489755446

Epoch: 5| Step: 10
Training loss: 2.155423323791044
Validation loss: 2.46791973615564

Epoch: 262| Step: 0
Training loss: 2.702789109369535
Validation loss: 2.4548165601684295

Epoch: 5| Step: 1
Training loss: 2.5872605733623155
Validation loss: 2.455616375806827

Epoch: 5| Step: 2
Training loss: 2.405518457754616
Validation loss: 2.463074877422309

Epoch: 5| Step: 3
Training loss: 2.5534234609044035
Validation loss: 2.4853522391640395

Epoch: 5| Step: 4
Training loss: 2.4257382989542435
Validation loss: 2.4921380080966102

Epoch: 5| Step: 5
Training loss: 2.597159660886905
Validation loss: 2.505226095451844

Epoch: 5| Step: 6
Training loss: 2.819929017600734
Validation loss: 2.515975086022812

Epoch: 5| Step: 7
Training loss: 2.226146351255791
Validation loss: 2.4762182788720293

Epoch: 5| Step: 8
Training loss: 2.5754300915682364
Validation loss: 2.4543343275011575

Epoch: 5| Step: 9
Training loss: 2.655880891174427
Validation loss: 2.4509674275928215

Epoch: 5| Step: 10
Training loss: 2.506479354599874
Validation loss: 2.4404091640413816

Epoch: 263| Step: 0
Training loss: 3.073692267000989
Validation loss: 2.4452983068579592

Epoch: 5| Step: 1
Training loss: 2.4914477933695864
Validation loss: 2.4382771908694867

Epoch: 5| Step: 2
Training loss: 2.544396159515817
Validation loss: 2.43028073665023

Epoch: 5| Step: 3
Training loss: 2.0079982092799984
Validation loss: 2.416885463313558

Epoch: 5| Step: 4
Training loss: 2.7977938714329165
Validation loss: 2.4274887298467345

Epoch: 5| Step: 5
Training loss: 2.8549714079325392
Validation loss: 2.43812591387761

Epoch: 5| Step: 6
Training loss: 2.8633468641228617
Validation loss: 2.4532779342605857

Epoch: 5| Step: 7
Training loss: 2.223004412744066
Validation loss: 2.467343423070056

Epoch: 5| Step: 8
Training loss: 2.139643757482901
Validation loss: 2.497384342722049

Epoch: 5| Step: 9
Training loss: 2.7886948116078996
Validation loss: 2.4874260751102626

Epoch: 5| Step: 10
Training loss: 2.4564249961578857
Validation loss: 2.5161774673939177

Epoch: 264| Step: 0
Training loss: 2.724128664330648
Validation loss: 2.5005044028361407

Epoch: 5| Step: 1
Training loss: 2.666826620867776
Validation loss: 2.4639911494348814

Epoch: 5| Step: 2
Training loss: 2.623581730216021
Validation loss: 2.4756565208928287

Epoch: 5| Step: 3
Training loss: 2.643807744687412
Validation loss: 2.4524975777628364

Epoch: 5| Step: 4
Training loss: 2.230821892195176
Validation loss: 2.4520227931755416

Epoch: 5| Step: 5
Training loss: 2.1851185505915143
Validation loss: 2.4315431122860307

Epoch: 5| Step: 6
Training loss: 2.6903945948255803
Validation loss: 2.441796264210553

Epoch: 5| Step: 7
Training loss: 2.6110843382019686
Validation loss: 2.4299770510179104

Epoch: 5| Step: 8
Training loss: 2.1953183645801335
Validation loss: 2.428638950674079

Epoch: 5| Step: 9
Training loss: 2.5146230277842427
Validation loss: 2.4232047430092414

Epoch: 5| Step: 10
Training loss: 2.703972126958172
Validation loss: 2.4239282844073786

Epoch: 265| Step: 0
Training loss: 2.5537256885926736
Validation loss: 2.43332490193312

Epoch: 5| Step: 1
Training loss: 2.5911409055321126
Validation loss: 2.421157849290912

Epoch: 5| Step: 2
Training loss: 2.1632283389921305
Validation loss: 2.4352317534031176

Epoch: 5| Step: 3
Training loss: 2.8549672324309423
Validation loss: 2.440627759365981

Epoch: 5| Step: 4
Training loss: 2.8705540986776503
Validation loss: 2.445344879304002

Epoch: 5| Step: 5
Training loss: 2.6402050338945644
Validation loss: 2.438990513501031

Epoch: 5| Step: 6
Training loss: 2.6400553071846615
Validation loss: 2.4359561647215004

Epoch: 5| Step: 7
Training loss: 2.220628507328458
Validation loss: 2.4440125149120675

Epoch: 5| Step: 8
Training loss: 2.0545028777632677
Validation loss: 2.4471637211052557

Epoch: 5| Step: 9
Training loss: 2.622123049981752
Validation loss: 2.463124171648112

Epoch: 5| Step: 10
Training loss: 2.181388054881062
Validation loss: 2.4744732251103096

Epoch: 266| Step: 0
Training loss: 2.4389540419086377
Validation loss: 2.5019096556518394

Epoch: 5| Step: 1
Training loss: 2.713880892372736
Validation loss: 2.5100731757432944

Epoch: 5| Step: 2
Training loss: 2.431397452700411
Validation loss: 2.509752145696461

Epoch: 5| Step: 3
Training loss: 2.650957467191597
Validation loss: 2.5158589001561937

Epoch: 5| Step: 4
Training loss: 2.126673544311563
Validation loss: 2.5123887755936716

Epoch: 5| Step: 5
Training loss: 2.7868330563906936
Validation loss: 2.475633374401027

Epoch: 5| Step: 6
Training loss: 2.6174467499279706
Validation loss: 2.4453188773467196

Epoch: 5| Step: 7
Training loss: 2.5108838629320003
Validation loss: 2.418028191936773

Epoch: 5| Step: 8
Training loss: 2.087307026789416
Validation loss: 2.4059613068912347

Epoch: 5| Step: 9
Training loss: 2.4953983872549292
Validation loss: 2.402510126533528

Epoch: 5| Step: 10
Training loss: 2.7773301865988254
Validation loss: 2.4045566672953864

Epoch: 267| Step: 0
Training loss: 2.8037500541506732
Validation loss: 2.408141244332243

Epoch: 5| Step: 1
Training loss: 3.07633122107134
Validation loss: 2.41666083145993

Epoch: 5| Step: 2
Training loss: 2.14073882531258
Validation loss: 2.4397997980460224

Epoch: 5| Step: 3
Training loss: 2.6280171448193324
Validation loss: 2.4453713328299687

Epoch: 5| Step: 4
Training loss: 2.7962876028057235
Validation loss: 2.468629401322004

Epoch: 5| Step: 5
Training loss: 2.213202081699106
Validation loss: 2.5242153411386306

Epoch: 5| Step: 6
Training loss: 2.24010729907403
Validation loss: 2.53784738447393

Epoch: 5| Step: 7
Training loss: 2.8090476145526573
Validation loss: 2.5524095987621016

Epoch: 5| Step: 8
Training loss: 2.403951959482247
Validation loss: 2.524723736150249

Epoch: 5| Step: 9
Training loss: 2.2717802424130102
Validation loss: 2.5365001198892996

Epoch: 5| Step: 10
Training loss: 2.1942666165480142
Validation loss: 2.56855071467214

Epoch: 268| Step: 0
Training loss: 2.2114226007891404
Validation loss: 2.5827541720943783

Epoch: 5| Step: 1
Training loss: 2.5240678029573176
Validation loss: 2.5700024850679384

Epoch: 5| Step: 2
Training loss: 2.491149781963248
Validation loss: 2.5557499678486573

Epoch: 5| Step: 3
Training loss: 2.4315782653901508
Validation loss: 2.5113067853028155

Epoch: 5| Step: 4
Training loss: 2.494151044448919
Validation loss: 2.455519629893737

Epoch: 5| Step: 5
Training loss: 2.4732672974372893
Validation loss: 2.4505631390431684

Epoch: 5| Step: 6
Training loss: 2.6752277776409925
Validation loss: 2.416483499447621

Epoch: 5| Step: 7
Training loss: 2.567436116137891
Validation loss: 2.4135156326589

Epoch: 5| Step: 8
Training loss: 2.6795965685305254
Validation loss: 2.413729376965525

Epoch: 5| Step: 9
Training loss: 2.087219073186295
Validation loss: 2.4027314272217435

Epoch: 5| Step: 10
Training loss: 2.5585667266583423
Validation loss: 2.395001740519327

Epoch: 269| Step: 0
Training loss: 2.353153033045223
Validation loss: 2.3948113118550487

Epoch: 5| Step: 1
Training loss: 2.4606778446847253
Validation loss: 2.396247677777923

Epoch: 5| Step: 2
Training loss: 2.9721353603358462
Validation loss: 2.3885162036892083

Epoch: 5| Step: 3
Training loss: 2.229575597979789
Validation loss: 2.3973911401636694

Epoch: 5| Step: 4
Training loss: 2.8454787480712445
Validation loss: 2.4098758193653285

Epoch: 5| Step: 5
Training loss: 2.0028926672971386
Validation loss: 2.451504748802524

Epoch: 5| Step: 6
Training loss: 2.1734109839899975
Validation loss: 2.4937057825922397

Epoch: 5| Step: 7
Training loss: 2.6071093196914044
Validation loss: 2.49520017328047

Epoch: 5| Step: 8
Training loss: 2.819627757969474
Validation loss: 2.5273723264355072

Epoch: 5| Step: 9
Training loss: 2.6783440338978144
Validation loss: 2.540546495345573

Epoch: 5| Step: 10
Training loss: 1.983882272176902
Validation loss: 2.513771550877493

Epoch: 270| Step: 0
Training loss: 2.87342409812204
Validation loss: 2.5125213944568

Epoch: 5| Step: 1
Training loss: 2.6039422408992117
Validation loss: 2.4792573758333805

Epoch: 5| Step: 2
Training loss: 1.9776413577901617
Validation loss: 2.467438946402783

Epoch: 5| Step: 3
Training loss: 2.0779047110686406
Validation loss: 2.441327661705561

Epoch: 5| Step: 4
Training loss: 2.7452837643451984
Validation loss: 2.432341181426807

Epoch: 5| Step: 5
Training loss: 2.3584703138309635
Validation loss: 2.4209927288606536

Epoch: 5| Step: 6
Training loss: 2.4171216032271934
Validation loss: 2.4191814940232037

Epoch: 5| Step: 7
Training loss: 2.4389505227463686
Validation loss: 2.414037370682056

Epoch: 5| Step: 8
Training loss: 2.462855775179687
Validation loss: 2.414281092686045

Epoch: 5| Step: 9
Training loss: 2.3446570103699296
Validation loss: 2.41416486451466

Epoch: 5| Step: 10
Training loss: 2.67646083694388
Validation loss: 2.409892604039775

Epoch: 271| Step: 0
Training loss: 2.7310294474715104
Validation loss: 2.425119274924387

Epoch: 5| Step: 1
Training loss: 2.828129215131959
Validation loss: 2.429051347373811

Epoch: 5| Step: 2
Training loss: 2.952640877252839
Validation loss: 2.423692019649845

Epoch: 5| Step: 3
Training loss: 2.312298740186308
Validation loss: 2.456099443858229

Epoch: 5| Step: 4
Training loss: 2.1551450026511887
Validation loss: 2.4782647820541697

Epoch: 5| Step: 5
Training loss: 1.8406602865829527
Validation loss: 2.4965224023084374

Epoch: 5| Step: 6
Training loss: 2.1220757053831614
Validation loss: 2.5060142162524626

Epoch: 5| Step: 7
Training loss: 2.33491243561739
Validation loss: 2.492120529027443

Epoch: 5| Step: 8
Training loss: 2.3588428023397197
Validation loss: 2.4831346348798125

Epoch: 5| Step: 9
Training loss: 2.400535833624065
Validation loss: 2.4905665004329984

Epoch: 5| Step: 10
Training loss: 2.626690365721523
Validation loss: 2.511465302349887

Epoch: 272| Step: 0
Training loss: 2.327396765364723
Validation loss: 2.497003866221474

Epoch: 5| Step: 1
Training loss: 2.3627121925933547
Validation loss: 2.523541595314348

Epoch: 5| Step: 2
Training loss: 2.8788696452366747
Validation loss: 2.5153807802606956

Epoch: 5| Step: 3
Training loss: 2.4411544792055286
Validation loss: 2.523291232046286

Epoch: 5| Step: 4
Training loss: 2.7283620934513397
Validation loss: 2.524061595124543

Epoch: 5| Step: 5
Training loss: 2.1719879560119093
Validation loss: 2.521873719782983

Epoch: 5| Step: 6
Training loss: 2.7688373939378605
Validation loss: 2.4769423128114694

Epoch: 5| Step: 7
Training loss: 2.5915943057966078
Validation loss: 2.465968530749442

Epoch: 5| Step: 8
Training loss: 1.6297618347946046
Validation loss: 2.436334363354231

Epoch: 5| Step: 9
Training loss: 2.5502250497280143
Validation loss: 2.4641778075988383

Epoch: 5| Step: 10
Training loss: 2.5138330178231416
Validation loss: 2.4702614513288017

Epoch: 273| Step: 0
Training loss: 2.8999143061637636
Validation loss: 2.4891695439089063

Epoch: 5| Step: 1
Training loss: 2.059492403657726
Validation loss: 2.453593166372739

Epoch: 5| Step: 2
Training loss: 2.3138029191175393
Validation loss: 2.4242640107142086

Epoch: 5| Step: 3
Training loss: 2.192990741680622
Validation loss: 2.4030599363441754

Epoch: 5| Step: 4
Training loss: 2.4220169518001167
Validation loss: 2.389723056762494

Epoch: 5| Step: 5
Training loss: 2.5133071551827335
Validation loss: 2.3819323596161266

Epoch: 5| Step: 6
Training loss: 2.916539180330906
Validation loss: 2.376713770751239

Epoch: 5| Step: 7
Training loss: 2.7823821774443322
Validation loss: 2.374586968595176

Epoch: 5| Step: 8
Training loss: 2.4023306497356227
Validation loss: 2.3813357641069453

Epoch: 5| Step: 9
Training loss: 2.1874617437014687
Validation loss: 2.379795069731599

Epoch: 5| Step: 10
Training loss: 2.023844320868956
Validation loss: 2.4027226743232624

Epoch: 274| Step: 0
Training loss: 2.5775289135411033
Validation loss: 2.4336778824415224

Epoch: 5| Step: 1
Training loss: 2.463609776486191
Validation loss: 2.4623411624681992

Epoch: 5| Step: 2
Training loss: 1.9633398652197445
Validation loss: 2.502695716019214

Epoch: 5| Step: 3
Training loss: 2.028987034778336
Validation loss: 2.4761599346187655

Epoch: 5| Step: 4
Training loss: 2.9307468787761346
Validation loss: 2.4719432295312975

Epoch: 5| Step: 5
Training loss: 2.4530557027371396
Validation loss: 2.4583478321991747

Epoch: 5| Step: 6
Training loss: 1.8551077079864098
Validation loss: 2.462756115295839

Epoch: 5| Step: 7
Training loss: 2.4308056972093532
Validation loss: 2.4564449871352734

Epoch: 5| Step: 8
Training loss: 2.84123370171373
Validation loss: 2.466028510204108

Epoch: 5| Step: 9
Training loss: 2.4840066504765677
Validation loss: 2.4650730338244555

Epoch: 5| Step: 10
Training loss: 2.466340253041825
Validation loss: 2.4709399038087705

Epoch: 275| Step: 0
Training loss: 2.476581561379228
Validation loss: 2.481861411683967

Epoch: 5| Step: 1
Training loss: 2.8624098051428843
Validation loss: 2.49042234434805

Epoch: 5| Step: 2
Training loss: 2.0806996164781815
Validation loss: 2.501662818062575

Epoch: 5| Step: 3
Training loss: 2.0883672043635504
Validation loss: 2.5041644860509082

Epoch: 5| Step: 4
Training loss: 2.173650221901033
Validation loss: 2.5124862504408507

Epoch: 5| Step: 5
Training loss: 2.784707138853587
Validation loss: 2.5207157719480664

Epoch: 5| Step: 6
Training loss: 2.0776899068727976
Validation loss: 2.513231671046541

Epoch: 5| Step: 7
Training loss: 2.684072571172728
Validation loss: 2.490255582149315

Epoch: 5| Step: 8
Training loss: 2.5069560552335806
Validation loss: 2.4378605248085448

Epoch: 5| Step: 9
Training loss: 1.937557096562939
Validation loss: 2.3984880553289827

Epoch: 5| Step: 10
Training loss: 2.8133558030911017
Validation loss: 2.365273324065131

Epoch: 276| Step: 0
Training loss: 2.85533365120516
Validation loss: 2.3639388986797045

Epoch: 5| Step: 1
Training loss: 2.0775485278910306
Validation loss: 2.3637016386907215

Epoch: 5| Step: 2
Training loss: 2.2261354271066565
Validation loss: 2.375546372566946

Epoch: 5| Step: 3
Training loss: 2.1739574301376137
Validation loss: 2.404837291788061

Epoch: 5| Step: 4
Training loss: 2.376439912883534
Validation loss: 2.434660320507736

Epoch: 5| Step: 5
Training loss: 2.4456478778598667
Validation loss: 2.454408928175216

Epoch: 5| Step: 6
Training loss: 2.2846701080449217
Validation loss: 2.47686772529304

Epoch: 5| Step: 7
Training loss: 2.1227838516492334
Validation loss: 2.4971734146921096

Epoch: 5| Step: 8
Training loss: 2.8740826677446623
Validation loss: 2.514054033288654

Epoch: 5| Step: 9
Training loss: 2.0866659085614634
Validation loss: 2.528172703582213

Epoch: 5| Step: 10
Training loss: 3.1311901581731867
Validation loss: 2.5304696538551537

Epoch: 277| Step: 0
Training loss: 2.303608890875172
Validation loss: 2.5213708517205693

Epoch: 5| Step: 1
Training loss: 2.5612303216717223
Validation loss: 2.5074091996474723

Epoch: 5| Step: 2
Training loss: 2.850235470865501
Validation loss: 2.4783172006943515

Epoch: 5| Step: 3
Training loss: 2.4605036277379915
Validation loss: 2.4439037135654136

Epoch: 5| Step: 4
Training loss: 1.7812933665567998
Validation loss: 2.404369534116937

Epoch: 5| Step: 5
Training loss: 1.9983868053409946
Validation loss: 2.40881500735571

Epoch: 5| Step: 6
Training loss: 2.492814801231681
Validation loss: 2.3905921905365863

Epoch: 5| Step: 7
Training loss: 2.291812845827576
Validation loss: 2.406860376426837

Epoch: 5| Step: 8
Training loss: 2.6598498914426214
Validation loss: 2.3993613726519305

Epoch: 5| Step: 9
Training loss: 1.7371948276069473
Validation loss: 2.4086992987703693

Epoch: 5| Step: 10
Training loss: 3.0579022518625085
Validation loss: 2.4200389919497476

Epoch: 278| Step: 0
Training loss: 2.2271434360693205
Validation loss: 2.447304465864762

Epoch: 5| Step: 1
Training loss: 2.6980836637404275
Validation loss: 2.4663460531733796

Epoch: 5| Step: 2
Training loss: 2.669371742884266
Validation loss: 2.503446552554868

Epoch: 5| Step: 3
Training loss: 2.3398666762819325
Validation loss: 2.5165616513783573

Epoch: 5| Step: 4
Training loss: 2.2332212230195254
Validation loss: 2.537985670060532

Epoch: 5| Step: 5
Training loss: 2.1297968410262538
Validation loss: 2.52534250762801

Epoch: 5| Step: 6
Training loss: 2.541592602093634
Validation loss: 2.524225256605809

Epoch: 5| Step: 7
Training loss: 2.4783655576614083
Validation loss: 2.4993220240601484

Epoch: 5| Step: 8
Training loss: 2.2172119827478
Validation loss: 2.4879113746634993

Epoch: 5| Step: 9
Training loss: 2.0288280426451957
Validation loss: 2.4901393956395577

Epoch: 5| Step: 10
Training loss: 2.255210036584741
Validation loss: 2.485140394091433

Epoch: 279| Step: 0
Training loss: 2.311321267431626
Validation loss: 2.4774647040434794

Epoch: 5| Step: 1
Training loss: 2.225466381442146
Validation loss: 2.4656581424817983

Epoch: 5| Step: 2
Training loss: 2.4871704880120276
Validation loss: 2.4567452736808475

Epoch: 5| Step: 3
Training loss: 2.6403428327597185
Validation loss: 2.4507793997872476

Epoch: 5| Step: 4
Training loss: 2.3618994338020167
Validation loss: 2.439885035146

Epoch: 5| Step: 5
Training loss: 2.2504848381706415
Validation loss: 2.4391279965579566

Epoch: 5| Step: 6
Training loss: 2.0523903192726385
Validation loss: 2.4337898017013577

Epoch: 5| Step: 7
Training loss: 1.7568616541813937
Validation loss: 2.4305501186780774

Epoch: 5| Step: 8
Training loss: 2.5474590731731466
Validation loss: 2.436207086848139

Epoch: 5| Step: 9
Training loss: 2.6070441154548916
Validation loss: 2.4513511747385595

Epoch: 5| Step: 10
Training loss: 2.4203555355100055
Validation loss: 2.4649444133609095

Epoch: 280| Step: 0
Training loss: 2.411895866056653
Validation loss: 2.477701255736835

Epoch: 5| Step: 1
Training loss: 2.0220747081112274
Validation loss: 2.484528985478292

Epoch: 5| Step: 2
Training loss: 2.053090566407349
Validation loss: 2.4930227220391563

Epoch: 5| Step: 3
Training loss: 2.506318309737724
Validation loss: 2.538716267216807

Epoch: 5| Step: 4
Training loss: 2.1313828368194727
Validation loss: 2.5361504052091233

Epoch: 5| Step: 5
Training loss: 2.255742691787504
Validation loss: 2.546248393556475

Epoch: 5| Step: 6
Training loss: 2.3158077605451775
Validation loss: 2.568032809290354

Epoch: 5| Step: 7
Training loss: 2.6536977736032243
Validation loss: 2.527784758007544

Epoch: 5| Step: 8
Training loss: 2.713094946662522
Validation loss: 2.486247769432742

Epoch: 5| Step: 9
Training loss: 2.4177237095330866
Validation loss: 2.4244426600610516

Epoch: 5| Step: 10
Training loss: 2.461148595081974
Validation loss: 2.4330104550946396

Epoch: 281| Step: 0
Training loss: 1.9200859737022404
Validation loss: 2.407621524698717

Epoch: 5| Step: 1
Training loss: 2.5151939259686302
Validation loss: 2.419433463948551

Epoch: 5| Step: 2
Training loss: 1.9026869947893112
Validation loss: 2.4208010427607323

Epoch: 5| Step: 3
Training loss: 2.5632283175931816
Validation loss: 2.44173100158654

Epoch: 5| Step: 4
Training loss: 2.615240756561949
Validation loss: 2.431339184313955

Epoch: 5| Step: 5
Training loss: 2.67220960161591
Validation loss: 2.421707843009569

Epoch: 5| Step: 6
Training loss: 2.667671779117486
Validation loss: 2.4458279221606536

Epoch: 5| Step: 7
Training loss: 1.8383921345390604
Validation loss: 2.4757764065644245

Epoch: 5| Step: 8
Training loss: 2.4895406317673263
Validation loss: 2.4910878644019334

Epoch: 5| Step: 9
Training loss: 2.5552457147085916
Validation loss: 2.511955374478869

Epoch: 5| Step: 10
Training loss: 2.15325852908814
Validation loss: 2.5230847824014253

Epoch: 282| Step: 0
Training loss: 2.1828216661767326
Validation loss: 2.510223089825817

Epoch: 5| Step: 1
Training loss: 1.9472530751029578
Validation loss: 2.4704400110488676

Epoch: 5| Step: 2
Training loss: 1.6607011686120545
Validation loss: 2.4608224347376275

Epoch: 5| Step: 3
Training loss: 2.022218314831956
Validation loss: 2.4557285072427475

Epoch: 5| Step: 4
Training loss: 2.3581260760820744
Validation loss: 2.4380949402345125

Epoch: 5| Step: 5
Training loss: 2.756486525302158
Validation loss: 2.4454597293317644

Epoch: 5| Step: 6
Training loss: 2.6556639978602807
Validation loss: 2.445621013263514

Epoch: 5| Step: 7
Training loss: 2.610539159516505
Validation loss: 2.4244387455096987

Epoch: 5| Step: 8
Training loss: 2.490131259354064
Validation loss: 2.4345052057779473

Epoch: 5| Step: 9
Training loss: 2.4134463415856957
Validation loss: 2.4221850103836697

Epoch: 5| Step: 10
Training loss: 2.3183290371922447
Validation loss: 2.4270676660716415

Epoch: 283| Step: 0
Training loss: 2.3698502976986116
Validation loss: 2.430886368942759

Epoch: 5| Step: 1
Training loss: 2.5026566694761465
Validation loss: 2.4407446621234565

Epoch: 5| Step: 2
Training loss: 2.5138424072277212
Validation loss: 2.452576629731675

Epoch: 5| Step: 3
Training loss: 2.6104677390673547
Validation loss: 2.468271065992247

Epoch: 5| Step: 4
Training loss: 2.011021169064497
Validation loss: 2.5033930036719987

Epoch: 5| Step: 5
Training loss: 2.270802652227571
Validation loss: 2.5534570736448052

Epoch: 5| Step: 6
Training loss: 2.4385542912559046
Validation loss: 2.567801822623676

Epoch: 5| Step: 7
Training loss: 2.2817824278009167
Validation loss: 2.565897774109763

Epoch: 5| Step: 8
Training loss: 2.2651555068167517
Validation loss: 2.5513095595982986

Epoch: 5| Step: 9
Training loss: 2.0336086957032786
Validation loss: 2.528660586004554

Epoch: 5| Step: 10
Training loss: 2.2469755614462237
Validation loss: 2.5027445504861734

Epoch: 284| Step: 0
Training loss: 2.5770037438066056
Validation loss: 2.506655723004724

Epoch: 5| Step: 1
Training loss: 2.4192942004654503
Validation loss: 2.5221566669530433

Epoch: 5| Step: 2
Training loss: 2.2195479341690225
Validation loss: 2.530309571549955

Epoch: 5| Step: 3
Training loss: 2.035900602203959
Validation loss: 2.5248127640773186

Epoch: 5| Step: 4
Training loss: 2.5720667085079922
Validation loss: 2.5026833725506727

Epoch: 5| Step: 5
Training loss: 2.1864025087637384
Validation loss: 2.484737585191569

Epoch: 5| Step: 6
Training loss: 2.2044666074186465
Validation loss: 2.4812001359369398

Epoch: 5| Step: 7
Training loss: 2.146432058514228
Validation loss: 2.498768988420426

Epoch: 5| Step: 8
Training loss: 2.3717372969911152
Validation loss: 2.4937948569493407

Epoch: 5| Step: 9
Training loss: 2.1996889848212287
Validation loss: 2.5135340713195764

Epoch: 5| Step: 10
Training loss: 2.1427754091388134
Validation loss: 2.5235010823124044

Epoch: 285| Step: 0
Training loss: 1.646158677148209
Validation loss: 2.5187210804001614

Epoch: 5| Step: 1
Training loss: 2.735857142254677
Validation loss: 2.5255048060606127

Epoch: 5| Step: 2
Training loss: 2.233598694290501
Validation loss: 2.5438244380250055

Epoch: 5| Step: 3
Training loss: 2.421914180315637
Validation loss: 2.53450992324668

Epoch: 5| Step: 4
Training loss: 2.710716128586513
Validation loss: 2.516790580741323

Epoch: 5| Step: 5
Training loss: 2.17749416241044
Validation loss: 2.4766536225013893

Epoch: 5| Step: 6
Training loss: 2.4684142838142233
Validation loss: 2.43706809635546

Epoch: 5| Step: 7
Training loss: 1.8577511532651205
Validation loss: 2.443868873075224

Epoch: 5| Step: 8
Training loss: 2.0810788608330304
Validation loss: 2.4464833465609797

Epoch: 5| Step: 9
Training loss: 2.261007088286919
Validation loss: 2.457836243386781

Epoch: 5| Step: 10
Training loss: 2.083313166202845
Validation loss: 2.4581485975740454

Epoch: 286| Step: 0
Training loss: 1.9511795731126294
Validation loss: 2.478081369894632

Epoch: 5| Step: 1
Training loss: 2.259809515023214
Validation loss: 2.48881153512884

Epoch: 5| Step: 2
Training loss: 2.578678048665287
Validation loss: 2.5011953101008246

Epoch: 5| Step: 3
Training loss: 2.10260358357951
Validation loss: 2.5015105462623684

Epoch: 5| Step: 4
Training loss: 2.528567270039979
Validation loss: 2.535634207994642

Epoch: 5| Step: 5
Training loss: 2.164464038820673
Validation loss: 2.5241197899104626

Epoch: 5| Step: 6
Training loss: 2.0372966267006913
Validation loss: 2.5461224480235236

Epoch: 5| Step: 7
Training loss: 2.659671509615896
Validation loss: 2.5380792104349283

Epoch: 5| Step: 8
Training loss: 2.373369661206735
Validation loss: 2.5256356724433857

Epoch: 5| Step: 9
Training loss: 1.9802906926937722
Validation loss: 2.501600868643252

Epoch: 5| Step: 10
Training loss: 1.5778612728517538
Validation loss: 2.4969327230071454

Epoch: 287| Step: 0
Training loss: 2.058207003259833
Validation loss: 2.497692413172459

Epoch: 5| Step: 1
Training loss: 2.1427825301668237
Validation loss: 2.5053387099879423

Epoch: 5| Step: 2
Training loss: 2.155905765200908
Validation loss: 2.52340729616407

Epoch: 5| Step: 3
Training loss: 2.4152455810405367
Validation loss: 2.504179703037987

Epoch: 5| Step: 4
Training loss: 2.134930798840708
Validation loss: 2.4934585698305467

Epoch: 5| Step: 5
Training loss: 2.2170663812633626
Validation loss: 2.4961271806128855

Epoch: 5| Step: 6
Training loss: 1.976781358023646
Validation loss: 2.508531609108098

Epoch: 5| Step: 7
Training loss: 2.4732493673023206
Validation loss: 2.497831315596694

Epoch: 5| Step: 8
Training loss: 2.2225481218206715
Validation loss: 2.508828901586264

Epoch: 5| Step: 9
Training loss: 2.3293289041628085
Validation loss: 2.515492897384178

Epoch: 5| Step: 10
Training loss: 2.16574086681608
Validation loss: 2.5322644768100675

Epoch: 288| Step: 0
Training loss: 2.072150339556501
Validation loss: 2.546526667317567

Epoch: 5| Step: 1
Training loss: 1.9573156336734214
Validation loss: 2.5641562698946228

Epoch: 5| Step: 2
Training loss: 2.6437190060794036
Validation loss: 2.568988450416225

Epoch: 5| Step: 3
Training loss: 2.390778081642636
Validation loss: 2.5976209195380764

Epoch: 5| Step: 4
Training loss: 2.4033045390393086
Validation loss: 2.575508790944163

Epoch: 5| Step: 5
Training loss: 1.8205492905269776
Validation loss: 2.5728419751684806

Epoch: 5| Step: 6
Training loss: 1.9137158761199504
Validation loss: 2.551623406988898

Epoch: 5| Step: 7
Training loss: 2.4805245941363854
Validation loss: 2.5441207301551656

Epoch: 5| Step: 8
Training loss: 2.0320804952237013
Validation loss: 2.5396281945131878

Epoch: 5| Step: 9
Training loss: 2.2196675941834654
Validation loss: 2.534654405935659

Epoch: 5| Step: 10
Training loss: 2.2858559083490215
Validation loss: 2.54092953679655

Epoch: 289| Step: 0
Training loss: 2.163165405742547
Validation loss: 2.502707938553968

Epoch: 5| Step: 1
Training loss: 2.19144171755779
Validation loss: 2.491632233624347

Epoch: 5| Step: 2
Training loss: 2.2055120860486217
Validation loss: 2.4782542632285325

Epoch: 5| Step: 3
Training loss: 2.2430365147945452
Validation loss: 2.4488448757675143

Epoch: 5| Step: 4
Training loss: 1.9703857650264323
Validation loss: 2.4499331117774052

Epoch: 5| Step: 5
Training loss: 2.5477306590229065
Validation loss: 2.439546681860861

Epoch: 5| Step: 6
Training loss: 2.023881429041326
Validation loss: 2.4466077371398565

Epoch: 5| Step: 7
Training loss: 2.7582498263100823
Validation loss: 2.454497087975843

Epoch: 5| Step: 8
Training loss: 1.5413783895040591
Validation loss: 2.450999810638329

Epoch: 5| Step: 9
Training loss: 2.4481903788893993
Validation loss: 2.4796722846482546

Epoch: 5| Step: 10
Training loss: 2.1432347782350467
Validation loss: 2.513724766887507

Epoch: 290| Step: 0
Training loss: 1.9245337107305767
Validation loss: 2.515180143475243

Epoch: 5| Step: 1
Training loss: 2.0837499456285493
Validation loss: 2.557846333653573

Epoch: 5| Step: 2
Training loss: 2.4949962131265098
Validation loss: 2.576926035686438

Epoch: 5| Step: 3
Training loss: 2.0633276232556703
Validation loss: 2.6071395115846645

Epoch: 5| Step: 4
Training loss: 2.3337611646339194
Validation loss: 2.6357766004170258

Epoch: 5| Step: 5
Training loss: 1.8668893232840145
Validation loss: 2.6100941537053792

Epoch: 5| Step: 6
Training loss: 2.1555362570555285
Validation loss: 2.577509860687317

Epoch: 5| Step: 7
Training loss: 2.3241612018545124
Validation loss: 2.5501806198404693

Epoch: 5| Step: 8
Training loss: 2.32965150494467
Validation loss: 2.5059647744043843

Epoch: 5| Step: 9
Training loss: 1.6850941780553441
Validation loss: 2.5013975769506596

Epoch: 5| Step: 10
Training loss: 2.594006721017288
Validation loss: 2.483274291719228

Epoch: 291| Step: 0
Training loss: 2.3246816478706354
Validation loss: 2.4360551898460505

Epoch: 5| Step: 1
Training loss: 2.2863981084053644
Validation loss: 2.436864080530618

Epoch: 5| Step: 2
Training loss: 1.8635718161068657
Validation loss: 2.4383981678566284

Epoch: 5| Step: 3
Training loss: 1.6309057172027268
Validation loss: 2.441867102000953

Epoch: 5| Step: 4
Training loss: 2.7145310914835474
Validation loss: 2.451532103160147

Epoch: 5| Step: 5
Training loss: 1.449401021430181
Validation loss: 2.4506527490086185

Epoch: 5| Step: 6
Training loss: 2.571878715503183
Validation loss: 2.4576582387513084

Epoch: 5| Step: 7
Training loss: 2.1139401239019584
Validation loss: 2.462739047589763

Epoch: 5| Step: 8
Training loss: 1.9289954794063962
Validation loss: 2.4561843569386848

Epoch: 5| Step: 9
Training loss: 2.4566734550758405
Validation loss: 2.4508314999036154

Epoch: 5| Step: 10
Training loss: 2.2198421315603265
Validation loss: 2.4635140411972425

Epoch: 292| Step: 0
Training loss: 2.2271144249806265
Validation loss: 2.4947492392201305

Epoch: 5| Step: 1
Training loss: 2.0904540124600803
Validation loss: 2.5272965026203438

Epoch: 5| Step: 2
Training loss: 2.6191119506085565
Validation loss: 2.5479100480364

Epoch: 5| Step: 3
Training loss: 1.963353465915601
Validation loss: 2.5546350001143563

Epoch: 5| Step: 4
Training loss: 2.258150174454344
Validation loss: 2.5632785491799615

Epoch: 5| Step: 5
Training loss: 1.838065354962927
Validation loss: 2.5597460134415986

Epoch: 5| Step: 6
Training loss: 2.417856241545194
Validation loss: 2.5585260157608607

Epoch: 5| Step: 7
Training loss: 1.9517021184232026
Validation loss: 2.566551107637333

Epoch: 5| Step: 8
Training loss: 2.2228065265611185
Validation loss: 2.567309591336162

Epoch: 5| Step: 9
Training loss: 1.3273046316003532
Validation loss: 2.5846512383802036

Epoch: 5| Step: 10
Training loss: 2.7851308257024616
Validation loss: 2.5851657906711947

Epoch: 293| Step: 0
Training loss: 1.7703269533676733
Validation loss: 2.569667816725817

Epoch: 5| Step: 1
Training loss: 2.431726023694936
Validation loss: 2.5656939734438375

Epoch: 5| Step: 2
Training loss: 2.450022977604454
Validation loss: 2.585847234481149

Epoch: 5| Step: 3
Training loss: 1.9149913791631772
Validation loss: 2.5373758044487844

Epoch: 5| Step: 4
Training loss: 1.994971450658751
Validation loss: 2.538126554049211

Epoch: 5| Step: 5
Training loss: 2.239731882772526
Validation loss: 2.5083029889044317

Epoch: 5| Step: 6
Training loss: 2.1858389951531043
Validation loss: 2.49346391927091

Epoch: 5| Step: 7
Training loss: 2.5768347083399092
Validation loss: 2.5121591445656177

Epoch: 5| Step: 8
Training loss: 1.7454899164114548
Validation loss: 2.5290953959730276

Epoch: 5| Step: 9
Training loss: 1.840341164638884
Validation loss: 2.555019680570536

Epoch: 5| Step: 10
Training loss: 2.2157803931576576
Validation loss: 2.564009572203267

Epoch: 294| Step: 0
Training loss: 2.0941514726303407
Validation loss: 2.574175733135627

Epoch: 5| Step: 1
Training loss: 2.667039209410175
Validation loss: 2.5393184046366306

Epoch: 5| Step: 2
Training loss: 2.3902504820825676
Validation loss: 2.539920153029378

Epoch: 5| Step: 3
Training loss: 1.9507669481174088
Validation loss: 2.5139959950408453

Epoch: 5| Step: 4
Training loss: 1.9610931213149339
Validation loss: 2.523217251592878

Epoch: 5| Step: 5
Training loss: 2.4513592044328623
Validation loss: 2.5301050006683234

Epoch: 5| Step: 6
Training loss: 1.824276059412455
Validation loss: 2.5164104690921607

Epoch: 5| Step: 7
Training loss: 1.885745790814948
Validation loss: 2.533701484466985

Epoch: 5| Step: 8
Training loss: 1.891993508132217
Validation loss: 2.536964361142066

Epoch: 5| Step: 9
Training loss: 2.300547770908948
Validation loss: 2.5335123446444663

Epoch: 5| Step: 10
Training loss: 1.7972352703327688
Validation loss: 2.5481932692469296

Epoch: 295| Step: 0
Training loss: 2.300784565999308
Validation loss: 2.551463720474855

Epoch: 5| Step: 1
Training loss: 1.631730592752811
Validation loss: 2.528677935676524

Epoch: 5| Step: 2
Training loss: 2.4192437429454605
Validation loss: 2.5361126258177453

Epoch: 5| Step: 3
Training loss: 1.5211282296135076
Validation loss: 2.5554477568560987

Epoch: 5| Step: 4
Training loss: 2.1419633454535587
Validation loss: 2.5584601555196755

Epoch: 5| Step: 5
Training loss: 2.29704024570334
Validation loss: 2.581082132924445

Epoch: 5| Step: 6
Training loss: 2.505302623050306
Validation loss: 2.580041104102398

Epoch: 5| Step: 7
Training loss: 1.7594345407930274
Validation loss: 2.5750826771883135

Epoch: 5| Step: 8
Training loss: 2.1776693428490628
Validation loss: 2.5678845739698235

Epoch: 5| Step: 9
Training loss: 2.162797799305037
Validation loss: 2.5794017843286547

Epoch: 5| Step: 10
Training loss: 1.7484763188011576
Validation loss: 2.5622394688440946

Epoch: 296| Step: 0
Training loss: 1.917284250965953
Validation loss: 2.550108576073041

Epoch: 5| Step: 1
Training loss: 1.931379927428124
Validation loss: 2.5547959474428654

Epoch: 5| Step: 2
Training loss: 2.0788530494164603
Validation loss: 2.540858728533629

Epoch: 5| Step: 3
Training loss: 2.1159095426308836
Validation loss: 2.531896454199975

Epoch: 5| Step: 4
Training loss: 2.0512764469094624
Validation loss: 2.5328221686891

Epoch: 5| Step: 5
Training loss: 1.6350783546874466
Validation loss: 2.5275580014917742

Epoch: 5| Step: 6
Training loss: 2.545620006441182
Validation loss: 2.5601521262318423

Epoch: 5| Step: 7
Training loss: 2.366611624691048
Validation loss: 2.5816012069017056

Epoch: 5| Step: 8
Training loss: 2.3200710183816513
Validation loss: 2.5815898305776814

Epoch: 5| Step: 9
Training loss: 1.6832024989256422
Validation loss: 2.5951716301118695

Epoch: 5| Step: 10
Training loss: 1.925038718787858
Validation loss: 2.603160072622887

Epoch: 297| Step: 0
Training loss: 2.189466627829683
Validation loss: 2.586412717821957

Epoch: 5| Step: 1
Training loss: 1.8472588980849314
Validation loss: 2.5924279394039473

Epoch: 5| Step: 2
Training loss: 1.4860703273576197
Validation loss: 2.561289796899944

Epoch: 5| Step: 3
Training loss: 2.1947375864959073
Validation loss: 2.5612454798785302

Epoch: 5| Step: 4
Training loss: 2.147105632981789
Validation loss: 2.5648698560555276

Epoch: 5| Step: 5
Training loss: 2.0854806006733586
Validation loss: 2.5672613868708143

Epoch: 5| Step: 6
Training loss: 2.387351793412578
Validation loss: 2.544710344757154

Epoch: 5| Step: 7
Training loss: 2.0132914201318965
Validation loss: 2.5524253537345474

Epoch: 5| Step: 8
Training loss: 2.1269425881425184
Validation loss: 2.547401494090452

Epoch: 5| Step: 9
Training loss: 2.3574922641210563
Validation loss: 2.577765760504538

Epoch: 5| Step: 10
Training loss: 1.6130063466977755
Validation loss: 2.5982001446491605

Epoch: 298| Step: 0
Training loss: 2.650309573391069
Validation loss: 2.608074097533288

Epoch: 5| Step: 1
Training loss: 1.7710960492496517
Validation loss: 2.589827587645384

Epoch: 5| Step: 2
Training loss: 2.035649157560256
Validation loss: 2.565417376062049

Epoch: 5| Step: 3
Training loss: 1.7457645114392246
Validation loss: 2.542021676346486

Epoch: 5| Step: 4
Training loss: 2.5085414884594814
Validation loss: 2.52483368688031

Epoch: 5| Step: 5
Training loss: 1.971167518181828
Validation loss: 2.5182674172730315

Epoch: 5| Step: 6
Training loss: 1.7831134084170337
Validation loss: 2.5053897614850147

Epoch: 5| Step: 7
Training loss: 1.8667754672336219
Validation loss: 2.480159215110032

Epoch: 5| Step: 8
Training loss: 1.6113128846343656
Validation loss: 2.4903987977422903

Epoch: 5| Step: 9
Training loss: 2.116369110378609
Validation loss: 2.4831347154086587

Epoch: 5| Step: 10
Training loss: 2.39280651014559
Validation loss: 2.5047877765447937

Epoch: 299| Step: 0
Training loss: 1.7380796851403515
Validation loss: 2.481373081619417

Epoch: 5| Step: 1
Training loss: 2.424993562198234
Validation loss: 2.4825114926113057

Epoch: 5| Step: 2
Training loss: 1.7622827950688085
Validation loss: 2.483922262764818

Epoch: 5| Step: 3
Training loss: 1.947057347460659
Validation loss: 2.509592204699852

Epoch: 5| Step: 4
Training loss: 2.4319612222767275
Validation loss: 2.5042832475523964

Epoch: 5| Step: 5
Training loss: 1.6999138473671127
Validation loss: 2.538215511839053

Epoch: 5| Step: 6
Training loss: 2.3651673412195247
Validation loss: 2.569137153405547

Epoch: 5| Step: 7
Training loss: 1.7552933337479522
Validation loss: 2.6065755742323593

Epoch: 5| Step: 8
Training loss: 2.0428871736596173
Validation loss: 2.651374400659013

Epoch: 5| Step: 9
Training loss: 1.9964436263626426
Validation loss: 2.65415638615965

Epoch: 5| Step: 10
Training loss: 1.9800135824912857
Validation loss: 2.668017923402241

Epoch: 300| Step: 0
Training loss: 2.0417530534594617
Validation loss: 2.688438209790044

Epoch: 5| Step: 1
Training loss: 2.2158595855447025
Validation loss: 2.6694561330295032

Epoch: 5| Step: 2
Training loss: 2.0432783370009275
Validation loss: 2.6568132463254215

Epoch: 5| Step: 3
Training loss: 2.089481614725032
Validation loss: 2.6338897192712354

Epoch: 5| Step: 4
Training loss: 2.241526223738313
Validation loss: 2.623210027147671

Epoch: 5| Step: 5
Training loss: 2.2129038770772103
Validation loss: 2.57030818821777

Epoch: 5| Step: 6
Training loss: 1.7848791662825163
Validation loss: 2.583190510784833

Epoch: 5| Step: 7
Training loss: 2.1057997179788943
Validation loss: 2.559279488259037

Epoch: 5| Step: 8
Training loss: 1.8111809501886253
Validation loss: 2.5199820634505037

Epoch: 5| Step: 9
Training loss: 1.6933229083894235
Validation loss: 2.4907012209739143

Epoch: 5| Step: 10
Training loss: 1.7899713331729457
Validation loss: 2.4932686618886617

Epoch: 301| Step: 0
Training loss: 1.6789802659211517
Validation loss: 2.4697785805542165

Epoch: 5| Step: 1
Training loss: 2.081390683113272
Validation loss: 2.4913120090489476

Epoch: 5| Step: 2
Training loss: 1.7429547865448067
Validation loss: 2.510553507308504

Epoch: 5| Step: 3
Training loss: 2.289504285239787
Validation loss: 2.512684768954279

Epoch: 5| Step: 4
Training loss: 2.0824033823303116
Validation loss: 2.514380509283919

Epoch: 5| Step: 5
Training loss: 2.317647514545399
Validation loss: 2.4840385801029297

Epoch: 5| Step: 6
Training loss: 1.8490754497848898
Validation loss: 2.461759969374849

Epoch: 5| Step: 7
Training loss: 2.1947005426952746
Validation loss: 2.4369357170837485

Epoch: 5| Step: 8
Training loss: 2.0528040619117944
Validation loss: 2.438372902431115

Epoch: 5| Step: 9
Training loss: 1.6458559477334878
Validation loss: 2.454262638901886

Epoch: 5| Step: 10
Training loss: 2.386617355565401
Validation loss: 2.474850298581416

Epoch: 302| Step: 0
Training loss: 1.6031688542902183
Validation loss: 2.5048521700005884

Epoch: 5| Step: 1
Training loss: 1.8565018839396343
Validation loss: 2.517823919559214

Epoch: 5| Step: 2
Training loss: 1.588231949761138
Validation loss: 2.584767385849589

Epoch: 5| Step: 3
Training loss: 2.072108457827084
Validation loss: 2.6083376638085665

Epoch: 5| Step: 4
Training loss: 2.112000816099414
Validation loss: 2.6766035983524374

Epoch: 5| Step: 5
Training loss: 2.1582531677244057
Validation loss: 2.6919585806828263

Epoch: 5| Step: 6
Training loss: 2.34592519911131
Validation loss: 2.682877279634241

Epoch: 5| Step: 7
Training loss: 2.3119192682974465
Validation loss: 2.6259848138518658

Epoch: 5| Step: 8
Training loss: 2.1375369330890694
Validation loss: 2.5632681466896177

Epoch: 5| Step: 9
Training loss: 2.0305600681883904
Validation loss: 2.52130733871964

Epoch: 5| Step: 10
Training loss: 1.6451728638375205
Validation loss: 2.4892432911281217

Epoch: 303| Step: 0
Training loss: 2.2074782197424296
Validation loss: 2.4857709062224753

Epoch: 5| Step: 1
Training loss: 1.9850988194348798
Validation loss: 2.4822920972222744

Epoch: 5| Step: 2
Training loss: 1.608894128160101
Validation loss: 2.477496873197098

Epoch: 5| Step: 3
Training loss: 1.8689282335491062
Validation loss: 2.5237039994046837

Epoch: 5| Step: 4
Training loss: 2.059402683286168
Validation loss: 2.5230886526240033

Epoch: 5| Step: 5
Training loss: 1.7237197465019047
Validation loss: 2.558872670921758

Epoch: 5| Step: 6
Training loss: 2.2812252304613647
Validation loss: 2.5943718234151167

Epoch: 5| Step: 7
Training loss: 1.7616214429283081
Validation loss: 2.6001807714382026

Epoch: 5| Step: 8
Training loss: 1.936399947406821
Validation loss: 2.581130954307704

Epoch: 5| Step: 9
Training loss: 2.377248903927985
Validation loss: 2.568091053840861

Epoch: 5| Step: 10
Training loss: 1.7891305302508012
Validation loss: 2.563219863219499

Epoch: 304| Step: 0
Training loss: 2.025188145315339
Validation loss: 2.569337666657975

Epoch: 5| Step: 1
Training loss: 1.7790484291590989
Validation loss: 2.5551883572436767

Epoch: 5| Step: 2
Training loss: 2.2911933641358933
Validation loss: 2.5647412145093167

Epoch: 5| Step: 3
Training loss: 1.5699483724476033
Validation loss: 2.515304624517884

Epoch: 5| Step: 4
Training loss: 2.4126829878434304
Validation loss: 2.497085562451725

Epoch: 5| Step: 5
Training loss: 2.081584374313291
Validation loss: 2.478186282101164

Epoch: 5| Step: 6
Training loss: 1.5156891012892346
Validation loss: 2.454407073657163

Epoch: 5| Step: 7
Training loss: 2.281238608135886
Validation loss: 2.4495558389882417

Epoch: 5| Step: 8
Training loss: 2.077843439058576
Validation loss: 2.454626698701556

Epoch: 5| Step: 9
Training loss: 1.6468463468140093
Validation loss: 2.459270185807187

Epoch: 5| Step: 10
Training loss: 1.7879435275758273
Validation loss: 2.4786840479056997

Epoch: 305| Step: 0
Training loss: 1.8077217784858004
Validation loss: 2.4942601947336867

Epoch: 5| Step: 1
Training loss: 1.9944577912946926
Validation loss: 2.5158271114741972

Epoch: 5| Step: 2
Training loss: 2.213964863133932
Validation loss: 2.5275639948397197

Epoch: 5| Step: 3
Training loss: 1.7634331931386593
Validation loss: 2.5321783452065048

Epoch: 5| Step: 4
Training loss: 1.815627064268741
Validation loss: 2.5654679205337527

Epoch: 5| Step: 5
Training loss: 1.91424098836953
Validation loss: 2.5660549409157585

Epoch: 5| Step: 6
Training loss: 1.5192387551875024
Validation loss: 2.583193217145174

Epoch: 5| Step: 7
Training loss: 2.078265651446166
Validation loss: 2.595868769495188

Epoch: 5| Step: 8
Training loss: 1.7352877440387822
Validation loss: 2.5942830688088683

Epoch: 5| Step: 9
Training loss: 1.8934064849413657
Validation loss: 2.602155790777717

Epoch: 5| Step: 10
Training loss: 2.357448271166688
Validation loss: 2.644275500900688

Epoch: 306| Step: 0
Training loss: 1.629945053274412
Validation loss: 2.6425830120183393

Epoch: 5| Step: 1
Training loss: 2.4339022372006327
Validation loss: 2.6495953931859226

Epoch: 5| Step: 2
Training loss: 2.060793315017117
Validation loss: 2.6555136792275316

Epoch: 5| Step: 3
Training loss: 1.6186315014448107
Validation loss: 2.6396006052040515

Epoch: 5| Step: 4
Training loss: 1.9142781038885388
Validation loss: 2.614864248152293

Epoch: 5| Step: 5
Training loss: 1.9574080235880522
Validation loss: 2.5857465000769637

Epoch: 5| Step: 6
Training loss: 1.9359174848973546
Validation loss: 2.5544129043089954

Epoch: 5| Step: 7
Training loss: 2.0668689808211393
Validation loss: 2.525442726840014

Epoch: 5| Step: 8
Training loss: 1.8860647517321456
Validation loss: 2.505936273032378

Epoch: 5| Step: 9
Training loss: 1.637535528714826
Validation loss: 2.5075525928541555

Epoch: 5| Step: 10
Training loss: 1.6240445042182552
Validation loss: 2.495897251110306

Epoch: 307| Step: 0
Training loss: 2.2980076079877607
Validation loss: 2.482482362595376

Epoch: 5| Step: 1
Training loss: 1.9859952544571495
Validation loss: 2.489894050701062

Epoch: 5| Step: 2
Training loss: 2.2609905328969986
Validation loss: 2.488347466612356

Epoch: 5| Step: 3
Training loss: 1.876936230697576
Validation loss: 2.486477334412656

Epoch: 5| Step: 4
Training loss: 1.4424864487036277
Validation loss: 2.485258693770345

Epoch: 5| Step: 5
Training loss: 2.0121749805026012
Validation loss: 2.5146186245900157

Epoch: 5| Step: 6
Training loss: 1.5586969250634553
Validation loss: 2.5187579562658664

Epoch: 5| Step: 7
Training loss: 1.924347256556183
Validation loss: 2.5409988266941363

Epoch: 5| Step: 8
Training loss: 1.554504843865348
Validation loss: 2.5520664324189304

Epoch: 5| Step: 9
Training loss: 1.85721475467264
Validation loss: 2.579116830873294

Epoch: 5| Step: 10
Training loss: 1.8529678355275117
Validation loss: 2.588450046285506

Epoch: 308| Step: 0
Training loss: 2.105827683125584
Validation loss: 2.5948820652053057

Epoch: 5| Step: 1
Training loss: 1.7716802553939877
Validation loss: 2.5998173860955376

Epoch: 5| Step: 2
Training loss: 1.861671183975372
Validation loss: 2.6042611683752157

Epoch: 5| Step: 3
Training loss: 1.2834182628585915
Validation loss: 2.6062866369681186

Epoch: 5| Step: 4
Training loss: 1.581202311041697
Validation loss: 2.5994242556036347

Epoch: 5| Step: 5
Training loss: 2.1068138115031267
Validation loss: 2.5993823363748105

Epoch: 5| Step: 6
Training loss: 2.1022210773243564
Validation loss: 2.5975915930836537

Epoch: 5| Step: 7
Training loss: 1.9779348923870925
Validation loss: 2.56416402632281

Epoch: 5| Step: 8
Training loss: 1.8100033369086261
Validation loss: 2.5103817774239534

Epoch: 5| Step: 9
Training loss: 2.323125399347558
Validation loss: 2.5024007437318887

Epoch: 5| Step: 10
Training loss: 0.9895303544703482
Validation loss: 2.5288690144709443

Epoch: 309| Step: 0
Training loss: 1.6160848793126381
Validation loss: 2.539597852635238

Epoch: 5| Step: 1
Training loss: 2.1218213261373515
Validation loss: 2.59026847369292

Epoch: 5| Step: 2
Training loss: 1.9494036814202351
Validation loss: 2.539326456010424

Epoch: 5| Step: 3
Training loss: 1.657502114940462
Validation loss: 2.559965896052417

Epoch: 5| Step: 4
Training loss: 1.7423821584296006
Validation loss: 2.5614635663559424

Epoch: 5| Step: 5
Training loss: 1.917105859387695
Validation loss: 2.5673016382059526

Epoch: 5| Step: 6
Training loss: 1.7330363838439893
Validation loss: 2.585950188611381

Epoch: 5| Step: 7
Training loss: 2.0522015403614633
Validation loss: 2.591738138425758

Epoch: 5| Step: 8
Training loss: 1.7386175966071595
Validation loss: 2.6058356514167307

Epoch: 5| Step: 9
Training loss: 1.8031537032198066
Validation loss: 2.5666367549722113

Epoch: 5| Step: 10
Training loss: 2.030005440540258
Validation loss: 2.55115644253478

Epoch: 310| Step: 0
Training loss: 2.021713406032213
Validation loss: 2.520027664120295

Epoch: 5| Step: 1
Training loss: 1.570612105450599
Validation loss: 2.500669551732301

Epoch: 5| Step: 2
Training loss: 1.6019163159576404
Validation loss: 2.4745350186407196

Epoch: 5| Step: 3
Training loss: 2.430886711691461
Validation loss: 2.47205276614411

Epoch: 5| Step: 4
Training loss: 1.4863372682147324
Validation loss: 2.456231580920538

Epoch: 5| Step: 5
Training loss: 1.9563060033417414
Validation loss: 2.4764429846862352

Epoch: 5| Step: 6
Training loss: 1.9395038947675778
Validation loss: 2.4712568136161708

Epoch: 5| Step: 7
Training loss: 1.664775999884447
Validation loss: 2.5166647460474896

Epoch: 5| Step: 8
Training loss: 2.0211845433589155
Validation loss: 2.553499485767856

Epoch: 5| Step: 9
Training loss: 1.905037541257351
Validation loss: 2.5857376161661176

Epoch: 5| Step: 10
Training loss: 1.6672014173303975
Validation loss: 2.6371057938655467

Epoch: 311| Step: 0
Training loss: 1.5254417342490085
Validation loss: 2.6227880036540645

Epoch: 5| Step: 1
Training loss: 1.888315981891548
Validation loss: 2.600662884442527

Epoch: 5| Step: 2
Training loss: 1.8380736564928826
Validation loss: 2.5961222824885852

Epoch: 5| Step: 3
Training loss: 1.8483976848373989
Validation loss: 2.5817379571975803

Epoch: 5| Step: 4
Training loss: 1.7178103566065284
Validation loss: 2.5385377180990543

Epoch: 5| Step: 5
Training loss: 1.6274428712395896
Validation loss: 2.527680096036129

Epoch: 5| Step: 6
Training loss: 2.0803102175754646
Validation loss: 2.5217618141707487

Epoch: 5| Step: 7
Training loss: 1.7939414583433693
Validation loss: 2.5099140825426933

Epoch: 5| Step: 8
Training loss: 2.103238710047352
Validation loss: 2.502797506851617

Epoch: 5| Step: 9
Training loss: 1.7391702157633087
Validation loss: 2.524088027060556

Epoch: 5| Step: 10
Training loss: 1.934721585039574
Validation loss: 2.540368832240229

Epoch: 312| Step: 0
Training loss: 1.3436526773384279
Validation loss: 2.5707051101703504

Epoch: 5| Step: 1
Training loss: 2.198534789708277
Validation loss: 2.568984206765069

Epoch: 5| Step: 2
Training loss: 1.8719221921139932
Validation loss: 2.6070395359831235

Epoch: 5| Step: 3
Training loss: 1.878982764448748
Validation loss: 2.6118525198511553

Epoch: 5| Step: 4
Training loss: 1.894850745249145
Validation loss: 2.6294413670476593

Epoch: 5| Step: 5
Training loss: 1.7488743704142449
Validation loss: 2.619973163282553

Epoch: 5| Step: 6
Training loss: 1.6963575807216333
Validation loss: 2.5874064838729502

Epoch: 5| Step: 7
Training loss: 1.7630745350384578
Validation loss: 2.592388674017083

Epoch: 5| Step: 8
Training loss: 1.6173652882911278
Validation loss: 2.5644036861918384

Epoch: 5| Step: 9
Training loss: 1.8849383497401624
Validation loss: 2.576576329098028

Epoch: 5| Step: 10
Training loss: 1.600469895742033
Validation loss: 2.5813094920255564

Epoch: 313| Step: 0
Training loss: 2.0306154873978266
Validation loss: 2.5995520111917205

Epoch: 5| Step: 1
Training loss: 1.3643932015938818
Validation loss: 2.574619806785555

Epoch: 5| Step: 2
Training loss: 1.2322731956114426
Validation loss: 2.5999899462102425

Epoch: 5| Step: 3
Training loss: 1.850704203427437
Validation loss: 2.6125943535779386

Epoch: 5| Step: 4
Training loss: 1.527074843830209
Validation loss: 2.626224121063705

Epoch: 5| Step: 5
Training loss: 1.7516390753961593
Validation loss: 2.596523069143141

Epoch: 5| Step: 6
Training loss: 1.9819900117462719
Validation loss: 2.602264915507049

Epoch: 5| Step: 7
Training loss: 2.0211480934437
Validation loss: 2.575733209694015

Epoch: 5| Step: 8
Training loss: 1.8274379645593293
Validation loss: 2.5733074880993088

Epoch: 5| Step: 9
Training loss: 1.8860495823990036
Validation loss: 2.575929362944025

Epoch: 5| Step: 10
Training loss: 1.8057106717635718
Validation loss: 2.5517875069659133

Epoch: 314| Step: 0
Training loss: 1.354247936842264
Validation loss: 2.5285999438446076

Epoch: 5| Step: 1
Training loss: 1.2795282285735923
Validation loss: 2.5057356974797607

Epoch: 5| Step: 2
Training loss: 1.0563933529156124
Validation loss: 2.526283808880354

Epoch: 5| Step: 3
Training loss: 2.0556278760176037
Validation loss: 2.531105548844332

Epoch: 5| Step: 4
Training loss: 2.1163346378099885
Validation loss: 2.5535448468039665

Epoch: 5| Step: 5
Training loss: 2.0651988087566635
Validation loss: 2.560128292188548

Epoch: 5| Step: 6
Training loss: 1.8890885344195079
Validation loss: 2.5671380885458746

Epoch: 5| Step: 7
Training loss: 1.6984010329275274
Validation loss: 2.572839426315478

Epoch: 5| Step: 8
Training loss: 1.7978564691761534
Validation loss: 2.5893204215545556

Epoch: 5| Step: 9
Training loss: 1.9032117050288797
Validation loss: 2.582854116994736

Epoch: 5| Step: 10
Training loss: 1.8389733071684726
Validation loss: 2.5898567530619987

Epoch: 315| Step: 0
Training loss: 2.2227542902504225
Validation loss: 2.594400393773803

Epoch: 5| Step: 1
Training loss: 1.774027520393126
Validation loss: 2.634601426230245

Epoch: 5| Step: 2
Training loss: 2.2890027139296802
Validation loss: 2.6180530809498284

Epoch: 5| Step: 3
Training loss: 1.745751878693963
Validation loss: 2.624932744834152

Epoch: 5| Step: 4
Training loss: 1.5489808977745763
Validation loss: 2.598436814267508

Epoch: 5| Step: 5
Training loss: 1.5840070278368243
Validation loss: 2.5748301607832866

Epoch: 5| Step: 6
Training loss: 1.5341868360948985
Validation loss: 2.567184145798432

Epoch: 5| Step: 7
Training loss: 1.784760145319648
Validation loss: 2.5706985966111104

Epoch: 5| Step: 8
Training loss: 1.5389783032618642
Validation loss: 2.552045994063341

Epoch: 5| Step: 9
Training loss: 1.4165191386579732
Validation loss: 2.555177127193802

Epoch: 5| Step: 10
Training loss: 1.4772815870806302
Validation loss: 2.5675680643923227

Epoch: 316| Step: 0
Training loss: 1.471156563332006
Validation loss: 2.573093923502879

Epoch: 5| Step: 1
Training loss: 1.9889510849451384
Validation loss: 2.5986142507891676

Epoch: 5| Step: 2
Training loss: 1.6950445007289023
Validation loss: 2.606224899228171

Epoch: 5| Step: 3
Training loss: 1.3785141773816207
Validation loss: 2.6042486024497777

Epoch: 5| Step: 4
Training loss: 1.9978595843495772
Validation loss: 2.614320772626039

Epoch: 5| Step: 5
Training loss: 1.5483210576655198
Validation loss: 2.6058782853494167

Epoch: 5| Step: 6
Training loss: 1.9829745419590281
Validation loss: 2.597050567931621

Epoch: 5| Step: 7
Training loss: 1.5748684964457864
Validation loss: 2.6143630426492943

Epoch: 5| Step: 8
Training loss: 2.033989335638876
Validation loss: 2.6290536502217186

Epoch: 5| Step: 9
Training loss: 1.6850450814213012
Validation loss: 2.6180188370371216

Epoch: 5| Step: 10
Training loss: 1.3444576174552183
Validation loss: 2.6069413654944706

Epoch: 317| Step: 0
Training loss: 1.8827586819250133
Validation loss: 2.6206352268438717

Epoch: 5| Step: 1
Training loss: 1.8647278102828468
Validation loss: 2.6115090570134707

Epoch: 5| Step: 2
Training loss: 1.927895953702853
Validation loss: 2.6024161229290743

Epoch: 5| Step: 3
Training loss: 1.3397393366664603
Validation loss: 2.6073555508106483

Epoch: 5| Step: 4
Training loss: 1.596511393319134
Validation loss: 2.611545148850886

Epoch: 5| Step: 5
Training loss: 1.5128761611905024
Validation loss: 2.6140446278092093

Epoch: 5| Step: 6
Training loss: 1.6680770231388902
Validation loss: 2.627649129764188

Epoch: 5| Step: 7
Training loss: 2.0514517133191505
Validation loss: 2.6261065270663266

Epoch: 5| Step: 8
Training loss: 1.4303206412425593
Validation loss: 2.627868257265233

Epoch: 5| Step: 9
Training loss: 1.5511942969195234
Validation loss: 2.61918270957009

Epoch: 5| Step: 10
Training loss: 1.9672791572530461
Validation loss: 2.5925395912263216

Epoch: 318| Step: 0
Training loss: 1.3140811025275725
Validation loss: 2.560251287248798

Epoch: 5| Step: 1
Training loss: 1.946311663445199
Validation loss: 2.5472236121426204

Epoch: 5| Step: 2
Training loss: 1.9704924849875307
Validation loss: 2.528448866416587

Epoch: 5| Step: 3
Training loss: 1.5832094679450566
Validation loss: 2.5304028141438764

Epoch: 5| Step: 4
Training loss: 1.65391404587499
Validation loss: 2.500355843886202

Epoch: 5| Step: 5
Training loss: 1.5939203807038773
Validation loss: 2.5331745111142876

Epoch: 5| Step: 6
Training loss: 1.4029959009672117
Validation loss: 2.534298526423474

Epoch: 5| Step: 7
Training loss: 2.1057716392393444
Validation loss: 2.554479807250722

Epoch: 5| Step: 8
Training loss: 1.9626496276184946
Validation loss: 2.5663111458328

Epoch: 5| Step: 9
Training loss: 1.4947010859071985
Validation loss: 2.588743550126237

Epoch: 5| Step: 10
Training loss: 1.5783547715715334
Validation loss: 2.6313445059490745

Epoch: 319| Step: 0
Training loss: 1.8246349701242819
Validation loss: 2.6314353346213912

Epoch: 5| Step: 1
Training loss: 1.2521471655765846
Validation loss: 2.6281357326739325

Epoch: 5| Step: 2
Training loss: 1.9344479918381965
Validation loss: 2.631991379871198

Epoch: 5| Step: 3
Training loss: 1.8504656025354786
Validation loss: 2.651644537706352

Epoch: 5| Step: 4
Training loss: 1.8268386357982243
Validation loss: 2.6477025523224484

Epoch: 5| Step: 5
Training loss: 1.5185416561438452
Validation loss: 2.659537815162156

Epoch: 5| Step: 6
Training loss: 1.8137427048960386
Validation loss: 2.656549190534689

Epoch: 5| Step: 7
Training loss: 1.9135765237251683
Validation loss: 2.611180303436912

Epoch: 5| Step: 8
Training loss: 1.2298581015915429
Validation loss: 2.6070966829272297

Epoch: 5| Step: 9
Training loss: 1.5831235529143373
Validation loss: 2.6008660868861617

Epoch: 5| Step: 10
Training loss: 1.7472346118244464
Validation loss: 2.576592652680047

Epoch: 320| Step: 0
Training loss: 1.3574799230225476
Validation loss: 2.563405477965075

Epoch: 5| Step: 1
Training loss: 1.8911997654427384
Validation loss: 2.5425741608681864

Epoch: 5| Step: 2
Training loss: 1.5177733935163582
Validation loss: 2.547193128752071

Epoch: 5| Step: 3
Training loss: 1.6661880600699837
Validation loss: 2.565547855312484

Epoch: 5| Step: 4
Training loss: 1.96011426446618
Validation loss: 2.5580054804148893

Epoch: 5| Step: 5
Training loss: 1.8618723663075833
Validation loss: 2.54482216703012

Epoch: 5| Step: 6
Training loss: 1.5251452142335535
Validation loss: 2.56464400789751

Epoch: 5| Step: 7
Training loss: 1.7253097200846303
Validation loss: 2.552813164978205

Epoch: 5| Step: 8
Training loss: 1.1799348483445562
Validation loss: 2.5554098348846477

Epoch: 5| Step: 9
Training loss: 2.0446566142799147
Validation loss: 2.5568125917869327

Epoch: 5| Step: 10
Training loss: 1.3661578851833105
Validation loss: 2.5696848576056595

Epoch: 321| Step: 0
Training loss: 2.087925909759438
Validation loss: 2.6098073486098174

Epoch: 5| Step: 1
Training loss: 1.7904090311717507
Validation loss: 2.6235618929589233

Epoch: 5| Step: 2
Training loss: 1.3691527274953244
Validation loss: 2.6482443921058456

Epoch: 5| Step: 3
Training loss: 1.4373206980461883
Validation loss: 2.6283983069824814

Epoch: 5| Step: 4
Training loss: 1.8059833052529968
Validation loss: 2.614464342401605

Epoch: 5| Step: 5
Training loss: 1.2997178321668759
Validation loss: 2.6166387216196463

Epoch: 5| Step: 6
Training loss: 1.9077814547975376
Validation loss: 2.638529935285013

Epoch: 5| Step: 7
Training loss: 1.9276301733607655
Validation loss: 2.6290192692449197

Epoch: 5| Step: 8
Training loss: 1.3481604476038898
Validation loss: 2.6091149126649498

Epoch: 5| Step: 9
Training loss: 1.388982467147982
Validation loss: 2.597977191504771

Epoch: 5| Step: 10
Training loss: 1.6507347696154309
Validation loss: 2.6083325715863124

Epoch: 322| Step: 0
Training loss: 1.3207450925471216
Validation loss: 2.6075643233438104

Epoch: 5| Step: 1
Training loss: 1.4178485241408714
Validation loss: 2.6206252408323887

Epoch: 5| Step: 2
Training loss: 1.5784005406111474
Validation loss: 2.6139495611613217

Epoch: 5| Step: 3
Training loss: 1.5856181607758617
Validation loss: 2.620590626016838

Epoch: 5| Step: 4
Training loss: 2.0198173984293843
Validation loss: 2.588276473148597

Epoch: 5| Step: 5
Training loss: 1.2765624196905814
Validation loss: 2.58166547980743

Epoch: 5| Step: 6
Training loss: 1.913937124700422
Validation loss: 2.592607019248874

Epoch: 5| Step: 7
Training loss: 1.7042844832654236
Validation loss: 2.6078079742158597

Epoch: 5| Step: 8
Training loss: 1.4206280952550798
Validation loss: 2.620088990519452

Epoch: 5| Step: 9
Training loss: 2.0064768820371226
Validation loss: 2.673762358842699

Epoch: 5| Step: 10
Training loss: 1.32514547593053
Validation loss: 2.6450129981258246

Epoch: 323| Step: 0
Training loss: 1.3931714862993094
Validation loss: 2.6892544170339785

Epoch: 5| Step: 1
Training loss: 0.7773028799076535
Validation loss: 2.658317164018526

Epoch: 5| Step: 2
Training loss: 1.4535872841824176
Validation loss: 2.6694213831134492

Epoch: 5| Step: 3
Training loss: 1.4611491493685507
Validation loss: 2.6295623674848874

Epoch: 5| Step: 4
Training loss: 1.8799931481419145
Validation loss: 2.607842389073113

Epoch: 5| Step: 5
Training loss: 2.1387898173101054
Validation loss: 2.5771717973109163

Epoch: 5| Step: 6
Training loss: 1.7863683279365457
Validation loss: 2.5559354645808376

Epoch: 5| Step: 7
Training loss: 1.5903787298610765
Validation loss: 2.5560537272985333

Epoch: 5| Step: 8
Training loss: 1.4639678370793976
Validation loss: 2.570168776012343

Epoch: 5| Step: 9
Training loss: 1.8121053331761348
Validation loss: 2.5697752838155914

Epoch: 5| Step: 10
Training loss: 2.041880914255106
Validation loss: 2.56643783473233

Epoch: 324| Step: 0
Training loss: 1.0938887916787912
Validation loss: 2.6017668924399446

Epoch: 5| Step: 1
Training loss: 1.249138344377257
Validation loss: 2.6548467733510193

Epoch: 5| Step: 2
Training loss: 1.6633432472611385
Validation loss: 2.7038447825207403

Epoch: 5| Step: 3
Training loss: 1.6559707118222489
Validation loss: 2.737215505259366

Epoch: 5| Step: 4
Training loss: 1.9579117977354832
Validation loss: 2.730446528932717

Epoch: 5| Step: 5
Training loss: 1.9106726075275502
Validation loss: 2.7449173602079098

Epoch: 5| Step: 6
Training loss: 1.905988956775676
Validation loss: 2.699239392251585

Epoch: 5| Step: 7
Training loss: 1.6639615596906967
Validation loss: 2.641618091787125

Epoch: 5| Step: 8
Training loss: 1.3194867774240158
Validation loss: 2.5927572148008293

Epoch: 5| Step: 9
Training loss: 1.4312357206340256
Validation loss: 2.5621560148737035

Epoch: 5| Step: 10
Training loss: 1.655210852776113
Validation loss: 2.531580388039346

Epoch: 325| Step: 0
Training loss: 2.0298882247895227
Validation loss: 2.503057441733278

Epoch: 5| Step: 1
Training loss: 1.7642865804799184
Validation loss: 2.502604652568555

Epoch: 5| Step: 2
Training loss: 1.4443244649909897
Validation loss: 2.481559521726757

Epoch: 5| Step: 3
Training loss: 1.9340497336595759
Validation loss: 2.5304649854462964

Epoch: 5| Step: 4
Training loss: 1.3608708537236465
Validation loss: 2.59001867214334

Epoch: 5| Step: 5
Training loss: 1.838962740854136
Validation loss: 2.6352261363303078

Epoch: 5| Step: 6
Training loss: 1.517732079747132
Validation loss: 2.634480640691709

Epoch: 5| Step: 7
Training loss: 1.9024540362025257
Validation loss: 2.6562073725272475

Epoch: 5| Step: 8
Training loss: 1.3515553115918169
Validation loss: 2.6776145432601384

Epoch: 5| Step: 9
Training loss: 1.7394945346607162
Validation loss: 2.6943912138940482

Epoch: 5| Step: 10
Training loss: 0.8212629715520695
Validation loss: 2.6435906250008836

Epoch: 326| Step: 0
Training loss: 1.495307656083986
Validation loss: 2.6408032976442355

Epoch: 5| Step: 1
Training loss: 1.8739752194243011
Validation loss: 2.661549554431919

Epoch: 5| Step: 2
Training loss: 1.4947623361862274
Validation loss: 2.62521647367901

Epoch: 5| Step: 3
Training loss: 1.8690041997504159
Validation loss: 2.638053444300816

Epoch: 5| Step: 4
Training loss: 1.8819394441970645
Validation loss: 2.612571476325916

Epoch: 5| Step: 5
Training loss: 1.4327126271624187
Validation loss: 2.5759114786096147

Epoch: 5| Step: 6
Training loss: 1.3002492372304846
Validation loss: 2.579958777451697

Epoch: 5| Step: 7
Training loss: 1.7123456760120326
Validation loss: 2.5965119102479757

Epoch: 5| Step: 8
Training loss: 1.7061404909197424
Validation loss: 2.582275800024101

Epoch: 5| Step: 9
Training loss: 1.2982453609202225
Validation loss: 2.5991483074711423

Epoch: 5| Step: 10
Training loss: 1.413696115143125
Validation loss: 2.571873879040256

Epoch: 327| Step: 0
Training loss: 1.3030461934729016
Validation loss: 2.571993635639598

Epoch: 5| Step: 1
Training loss: 1.870347927589746
Validation loss: 2.5796452946728134

Epoch: 5| Step: 2
Training loss: 1.8629347121080622
Validation loss: 2.6192290902976065

Epoch: 5| Step: 3
Training loss: 1.6640651505856605
Validation loss: 2.6455786901177705

Epoch: 5| Step: 4
Training loss: 1.5316041809276024
Validation loss: 2.6571136653350678

Epoch: 5| Step: 5
Training loss: 1.7906604277349893
Validation loss: 2.6670565884091455

Epoch: 5| Step: 6
Training loss: 1.4450116643467854
Validation loss: 2.6455327742511137

Epoch: 5| Step: 7
Training loss: 1.2569825176610474
Validation loss: 2.6505138783183932

Epoch: 5| Step: 8
Training loss: 1.267042425955237
Validation loss: 2.6818762191779744

Epoch: 5| Step: 9
Training loss: 1.2071797301190248
Validation loss: 2.6691190779811937

Epoch: 5| Step: 10
Training loss: 1.6554798278870002
Validation loss: 2.678183237279411

Epoch: 328| Step: 0
Training loss: 1.9294859746189452
Validation loss: 2.694189123904923

Epoch: 5| Step: 1
Training loss: 1.52691113523305
Validation loss: 2.672963441999234

Epoch: 5| Step: 2
Training loss: 1.5362587578246842
Validation loss: 2.63893474790157

Epoch: 5| Step: 3
Training loss: 1.5218816392820318
Validation loss: 2.6316528161631605

Epoch: 5| Step: 4
Training loss: 1.2816376448587627
Validation loss: 2.6041099282923557

Epoch: 5| Step: 5
Training loss: 1.789576693941826
Validation loss: 2.582791883653859

Epoch: 5| Step: 6
Training loss: 1.484686567835755
Validation loss: 2.581718740778627

Epoch: 5| Step: 7
Training loss: 1.4157207734507984
Validation loss: 2.6039377618086545

Epoch: 5| Step: 8
Training loss: 1.7119364848520884
Validation loss: 2.597594196603247

Epoch: 5| Step: 9
Training loss: 1.5639684262027733
Validation loss: 2.6022834304900604

Epoch: 5| Step: 10
Training loss: 1.1804806903712384
Validation loss: 2.624195511767639

Epoch: 329| Step: 0
Training loss: 1.4116269629088252
Validation loss: 2.631502195630401

Epoch: 5| Step: 1
Training loss: 0.9553309692953408
Validation loss: 2.6440298293030224

Epoch: 5| Step: 2
Training loss: 1.5668526106255407
Validation loss: 2.631860026350284

Epoch: 5| Step: 3
Training loss: 1.3726290288146425
Validation loss: 2.616846684963025

Epoch: 5| Step: 4
Training loss: 1.3678143181547997
Validation loss: 2.6075353033878925

Epoch: 5| Step: 5
Training loss: 1.6562302786174772
Validation loss: 2.6275011502186105

Epoch: 5| Step: 6
Training loss: 1.6017339102965638
Validation loss: 2.6170536619863554

Epoch: 5| Step: 7
Training loss: 1.703754973484765
Validation loss: 2.6197970197467124

Epoch: 5| Step: 8
Training loss: 1.5464716684118598
Validation loss: 2.6223376289716795

Epoch: 5| Step: 9
Training loss: 1.6074527260101374
Validation loss: 2.6387186583436777

Epoch: 5| Step: 10
Training loss: 1.440689859978213
Validation loss: 2.6140440658577315

Epoch: 330| Step: 0
Training loss: 1.8150147717507932
Validation loss: 2.6226755897611698

Epoch: 5| Step: 1
Training loss: 1.6123158519781158
Validation loss: 2.6040392293614976

Epoch: 5| Step: 2
Training loss: 1.0239984270992717
Validation loss: 2.5781743168891658

Epoch: 5| Step: 3
Training loss: 1.7850561468659716
Validation loss: 2.5944295863415245

Epoch: 5| Step: 4
Training loss: 1.0583472158367542
Validation loss: 2.562430731744817

Epoch: 5| Step: 5
Training loss: 1.342174227097134
Validation loss: 2.548058814556488

Epoch: 5| Step: 6
Training loss: 1.184691370276245
Validation loss: 2.5471801343511755

Epoch: 5| Step: 7
Training loss: 1.5824577604324408
Validation loss: 2.543402954431569

Epoch: 5| Step: 8
Training loss: 1.9707002214423606
Validation loss: 2.5214029934783624

Epoch: 5| Step: 9
Training loss: 1.5974841783005722
Validation loss: 2.539277531027364

Epoch: 5| Step: 10
Training loss: 1.0740781934855257
Validation loss: 2.5741481264347454

Epoch: 331| Step: 0
Training loss: 1.4799396304112764
Validation loss: 2.58286092893288

Epoch: 5| Step: 1
Training loss: 1.3538429998293564
Validation loss: 2.5832843961126093

Epoch: 5| Step: 2
Training loss: 1.5416210614581483
Validation loss: 2.63727120345707

Epoch: 5| Step: 3
Training loss: 1.272382521536928
Validation loss: 2.6614427261243296

Epoch: 5| Step: 4
Training loss: 1.5580125073872317
Validation loss: 2.6442370616523307

Epoch: 5| Step: 5
Training loss: 1.0854120973184558
Validation loss: 2.599172232979549

Epoch: 5| Step: 6
Training loss: 1.3426127833581365
Validation loss: 2.5288653680100315

Epoch: 5| Step: 7
Training loss: 1.595488553696198
Validation loss: 2.5322663051867473

Epoch: 5| Step: 8
Training loss: 1.940305217250649
Validation loss: 2.520970527849932

Epoch: 5| Step: 9
Training loss: 1.0888556372880958
Validation loss: 2.4791035660072307

Epoch: 5| Step: 10
Training loss: 1.9018883757382583
Validation loss: 2.4850303862230794

Epoch: 332| Step: 0
Training loss: 1.4275579382634525
Validation loss: 2.4745501940545243

Epoch: 5| Step: 1
Training loss: 1.48508645123926
Validation loss: 2.4955842880588146

Epoch: 5| Step: 2
Training loss: 1.5408377695853597
Validation loss: 2.5255833634494853

Epoch: 5| Step: 3
Training loss: 1.3897474713399425
Validation loss: 2.560319702786988

Epoch: 5| Step: 4
Training loss: 1.1732006458734607
Validation loss: 2.578185587966879

Epoch: 5| Step: 5
Training loss: 1.6546936640205878
Validation loss: 2.639421338557913

Epoch: 5| Step: 6
Training loss: 1.1951612987753293
Validation loss: 2.6348159142934695

Epoch: 5| Step: 7
Training loss: 1.977705553369575
Validation loss: 2.6217925980370236

Epoch: 5| Step: 8
Training loss: 1.4815668950139393
Validation loss: 2.5912344038669546

Epoch: 5| Step: 9
Training loss: 1.3440165588005977
Validation loss: 2.6116382200217667

Epoch: 5| Step: 10
Training loss: 1.3546577247946527
Validation loss: 2.580098541015787

Epoch: 333| Step: 0
Training loss: 1.4704406422993193
Validation loss: 2.5510241921019894

Epoch: 5| Step: 1
Training loss: 1.1488584408721059
Validation loss: 2.510298388692082

Epoch: 5| Step: 2
Training loss: 1.4210126168954653
Validation loss: 2.5028291639777636

Epoch: 5| Step: 3
Training loss: 1.4752924063553903
Validation loss: 2.5064351761766077

Epoch: 5| Step: 4
Training loss: 1.58972092512538
Validation loss: 2.511250215877265

Epoch: 5| Step: 5
Training loss: 1.5163805150202267
Validation loss: 2.5190282450713064

Epoch: 5| Step: 6
Training loss: 1.6989717852139643
Validation loss: 2.5249605440338305

Epoch: 5| Step: 7
Training loss: 1.267680723860829
Validation loss: 2.5266134714574666

Epoch: 5| Step: 8
Training loss: 1.2141968209722853
Validation loss: 2.53273737292568

Epoch: 5| Step: 9
Training loss: 1.7940159484213922
Validation loss: 2.5441925358880813

Epoch: 5| Step: 10
Training loss: 1.3440079995808496
Validation loss: 2.5844657776360584

Epoch: 334| Step: 0
Training loss: 1.3155661146165119
Validation loss: 2.573841785718139

Epoch: 5| Step: 1
Training loss: 1.13006774918678
Validation loss: 2.6000335826274683

Epoch: 5| Step: 2
Training loss: 1.535624037273821
Validation loss: 2.610059151707414

Epoch: 5| Step: 3
Training loss: 1.6359539566742562
Validation loss: 2.5980554067228208

Epoch: 5| Step: 4
Training loss: 1.3736337462950492
Validation loss: 2.604681659270215

Epoch: 5| Step: 5
Training loss: 1.5204490106344273
Validation loss: 2.5994391200802967

Epoch: 5| Step: 6
Training loss: 1.2452507874862182
Validation loss: 2.608478384483979

Epoch: 5| Step: 7
Training loss: 1.5679248478649244
Validation loss: 2.5913510605772427

Epoch: 5| Step: 8
Training loss: 1.3385781853390881
Validation loss: 2.569357774893738

Epoch: 5| Step: 9
Training loss: 1.4268832194041026
Validation loss: 2.5636744615271767

Epoch: 5| Step: 10
Training loss: 1.6121138442994067
Validation loss: 2.555592794765259

Epoch: 335| Step: 0
Training loss: 1.1246871513245327
Validation loss: 2.5580801514623324

Epoch: 5| Step: 1
Training loss: 1.5235933664255106
Validation loss: 2.559556041802523

Epoch: 5| Step: 2
Training loss: 1.5343656955289267
Validation loss: 2.5508862696341392

Epoch: 5| Step: 3
Training loss: 1.341304505477024
Validation loss: 2.57946903698021

Epoch: 5| Step: 4
Training loss: 1.2888622243953018
Validation loss: 2.5953657996090898

Epoch: 5| Step: 5
Training loss: 1.535674728314985
Validation loss: 2.5922045234228452

Epoch: 5| Step: 6
Training loss: 1.2508255140012297
Validation loss: 2.610553146602513

Epoch: 5| Step: 7
Training loss: 1.642698811963277
Validation loss: 2.619363744010489

Epoch: 5| Step: 8
Training loss: 1.526345163138847
Validation loss: 2.626566101834235

Epoch: 5| Step: 9
Training loss: 1.6682021538338536
Validation loss: 2.619950864178163

Epoch: 5| Step: 10
Training loss: 1.0572625831149263
Validation loss: 2.628649881846949

Epoch: 336| Step: 0
Training loss: 1.7900865447577607
Validation loss: 2.6281259034353397

Epoch: 5| Step: 1
Training loss: 1.3421493578144128
Validation loss: 2.6501331283909857

Epoch: 5| Step: 2
Training loss: 1.3226643219018221
Validation loss: 2.6815467597388785

Epoch: 5| Step: 3
Training loss: 1.1869859084567937
Validation loss: 2.666523587967121

Epoch: 5| Step: 4
Training loss: 1.3878632027139155
Validation loss: 2.6490919803829156

Epoch: 5| Step: 5
Training loss: 1.1124604528877404
Validation loss: 2.643406994156711

Epoch: 5| Step: 6
Training loss: 1.639454233143277
Validation loss: 2.6020514743652

Epoch: 5| Step: 7
Training loss: 1.461898243015193
Validation loss: 2.591617941961371

Epoch: 5| Step: 8
Training loss: 1.165481419451599
Validation loss: 2.573887967537078

Epoch: 5| Step: 9
Training loss: 1.3602351832397015
Validation loss: 2.558614248271768

Epoch: 5| Step: 10
Training loss: 1.4206251582939842
Validation loss: 2.541553570110421

Epoch: 337| Step: 0
Training loss: 1.5600754810069957
Validation loss: 2.5231800700460925

Epoch: 5| Step: 1
Training loss: 1.3020101704705647
Validation loss: 2.522879852291605

Epoch: 5| Step: 2
Training loss: 1.5597196637649062
Validation loss: 2.4997357762078067

Epoch: 5| Step: 3
Training loss: 1.1945663317262294
Validation loss: 2.506616134214662

Epoch: 5| Step: 4
Training loss: 1.273080834365659
Validation loss: 2.533768418271118

Epoch: 5| Step: 5
Training loss: 1.324498959942327
Validation loss: 2.5725257646002784

Epoch: 5| Step: 6
Training loss: 1.3358178336104347
Validation loss: 2.5814451872101443

Epoch: 5| Step: 7
Training loss: 1.1772378915685335
Validation loss: 2.5622665074795665

Epoch: 5| Step: 8
Training loss: 1.0719691354770744
Validation loss: 2.57925647854424

Epoch: 5| Step: 9
Training loss: 1.5599331179978015
Validation loss: 2.5796208670566196

Epoch: 5| Step: 10
Training loss: 1.561250873989963
Validation loss: 2.564447482781968

Epoch: 338| Step: 0
Training loss: 1.4781000115054634
Validation loss: 2.576337931925048

Epoch: 5| Step: 1
Training loss: 0.9978437123612388
Validation loss: 2.5951815135336127

Epoch: 5| Step: 2
Training loss: 1.2745102184749522
Validation loss: 2.584757890085806

Epoch: 5| Step: 3
Training loss: 1.3760565253280213
Validation loss: 2.579273927200278

Epoch: 5| Step: 4
Training loss: 1.669069378182831
Validation loss: 2.570511482426808

Epoch: 5| Step: 5
Training loss: 1.346575096002406
Validation loss: 2.540684895868356

Epoch: 5| Step: 6
Training loss: 1.5527842771560565
Validation loss: 2.544394789229122

Epoch: 5| Step: 7
Training loss: 1.1944723230750665
Validation loss: 2.5771993596856717

Epoch: 5| Step: 8
Training loss: 1.1224426236176166
Validation loss: 2.5836647762504974

Epoch: 5| Step: 9
Training loss: 1.001855083227153
Validation loss: 2.5560367911212043

Epoch: 5| Step: 10
Training loss: 1.244356576810958
Validation loss: 2.5688026577517102

Epoch: 339| Step: 0
Training loss: 1.12786500423297
Validation loss: 2.5873532220752273

Epoch: 5| Step: 1
Training loss: 1.587113418968282
Validation loss: 2.5691462429012977

Epoch: 5| Step: 2
Training loss: 1.51625040266593
Validation loss: 2.562575042290106

Epoch: 5| Step: 3
Training loss: 0.9890764678402687
Validation loss: 2.5540843707132854

Epoch: 5| Step: 4
Training loss: 1.1777085638301905
Validation loss: 2.572915930662979

Epoch: 5| Step: 5
Training loss: 0.960709211322918
Validation loss: 2.5625747011482853

Epoch: 5| Step: 6
Training loss: 1.2081399412065028
Validation loss: 2.575621334463227

Epoch: 5| Step: 7
Training loss: 1.7287569211654417
Validation loss: 2.591228633964853

Epoch: 5| Step: 8
Training loss: 1.1198558818532034
Validation loss: 2.5773766757545555

Epoch: 5| Step: 9
Training loss: 1.330826334631346
Validation loss: 2.585262909639366

Epoch: 5| Step: 10
Training loss: 1.17555599653019
Validation loss: 2.6052705954131152

Epoch: 340| Step: 0
Training loss: 0.9691516597293335
Validation loss: 2.598076892207788

Epoch: 5| Step: 1
Training loss: 1.412616137565976
Validation loss: 2.5925340625431246

Epoch: 5| Step: 2
Training loss: 1.1153766922074866
Validation loss: 2.599636573748143

Epoch: 5| Step: 3
Training loss: 1.093309695310075
Validation loss: 2.58812680207483

Epoch: 5| Step: 4
Training loss: 0.7991278349624582
Validation loss: 2.563007266510767

Epoch: 5| Step: 5
Training loss: 1.4604097933024756
Validation loss: 2.575131026439994

Epoch: 5| Step: 6
Training loss: 1.5322695860405275
Validation loss: 2.579136588027103

Epoch: 5| Step: 7
Training loss: 1.2399717999143467
Validation loss: 2.5805539723116917

Epoch: 5| Step: 8
Training loss: 1.0602303554241432
Validation loss: 2.606669025441581

Epoch: 5| Step: 9
Training loss: 1.4950669552408267
Validation loss: 2.6213114157073685

Epoch: 5| Step: 10
Training loss: 1.6435052928879952
Validation loss: 2.571206990043202

Epoch: 341| Step: 0
Training loss: 1.2574402157505655
Validation loss: 2.573916001327705

Epoch: 5| Step: 1
Training loss: 1.2035352824783947
Validation loss: 2.5760754972888047

Epoch: 5| Step: 2
Training loss: 1.427896931339987
Validation loss: 2.5947085686251086

Epoch: 5| Step: 3
Training loss: 1.462580119489703
Validation loss: 2.578071865654169

Epoch: 5| Step: 4
Training loss: 1.3960292261174012
Validation loss: 2.604731515640609

Epoch: 5| Step: 5
Training loss: 1.26160489445537
Validation loss: 2.556137494833907

Epoch: 5| Step: 6
Training loss: 1.2619595607861975
Validation loss: 2.5467278715912833

Epoch: 5| Step: 7
Training loss: 1.437446095658402
Validation loss: 2.5281060759236915

Epoch: 5| Step: 8
Training loss: 0.95596920952233
Validation loss: 2.5232703635093006

Epoch: 5| Step: 9
Training loss: 1.2816625256630647
Validation loss: 2.511412121458315

Epoch: 5| Step: 10
Training loss: 0.5177835308804967
Validation loss: 2.5069435231054444

Epoch: 342| Step: 0
Training loss: 1.3007787755994202
Validation loss: 2.5281289813123924

Epoch: 5| Step: 1
Training loss: 1.3859254529014398
Validation loss: 2.498753113668602

Epoch: 5| Step: 2
Training loss: 1.147108177990345
Validation loss: 2.50360516280467

Epoch: 5| Step: 3
Training loss: 0.5624445252084157
Validation loss: 2.4981836078237425

Epoch: 5| Step: 4
Training loss: 1.3043895084175585
Validation loss: 2.536779553441862

Epoch: 5| Step: 5
Training loss: 1.4390909264622074
Validation loss: 2.5204945594860098

Epoch: 5| Step: 6
Training loss: 0.80688454401472
Validation loss: 2.555803431347277

Epoch: 5| Step: 7
Training loss: 1.0604441893377776
Validation loss: 2.575042654007369

Epoch: 5| Step: 8
Training loss: 1.382512334799624
Validation loss: 2.585384520811219

Epoch: 5| Step: 9
Training loss: 1.218956514125821
Validation loss: 2.6034526615631233

Epoch: 5| Step: 10
Training loss: 1.6949614411866056
Validation loss: 2.5930569490434925

Epoch: 343| Step: 0
Training loss: 0.8690244104075827
Validation loss: 2.5611703535888446

Epoch: 5| Step: 1
Training loss: 0.9446799944428985
Validation loss: 2.5395900514610323

Epoch: 5| Step: 2
Training loss: 1.0907793848458651
Validation loss: 2.5251781906368995

Epoch: 5| Step: 3
Training loss: 1.3754384035513207
Validation loss: 2.509669448033117

Epoch: 5| Step: 4
Training loss: 1.3044842773051457
Validation loss: 2.5107957338215905

Epoch: 5| Step: 5
Training loss: 1.1144169418820313
Validation loss: 2.5189789772407187

Epoch: 5| Step: 6
Training loss: 1.0690810086929279
Validation loss: 2.5156447304652714

Epoch: 5| Step: 7
Training loss: 1.4278455030868797
Validation loss: 2.518170280229125

Epoch: 5| Step: 8
Training loss: 1.3346339329657022
Validation loss: 2.52067003778034

Epoch: 5| Step: 9
Training loss: 1.460232977894776
Validation loss: 2.5505418670635396

Epoch: 5| Step: 10
Training loss: 1.3181299080538005
Validation loss: 2.524330193843759

Epoch: 344| Step: 0
Training loss: 0.9807443117554855
Validation loss: 2.5318795893157238

Epoch: 5| Step: 1
Training loss: 1.1962364963737953
Validation loss: 2.52663538689272

Epoch: 5| Step: 2
Training loss: 1.3704766517718416
Validation loss: 2.5445648744562974

Epoch: 5| Step: 3
Training loss: 1.1296063004854278
Validation loss: 2.534025782225445

Epoch: 5| Step: 4
Training loss: 1.2008778281950363
Validation loss: 2.5789300232878687

Epoch: 5| Step: 5
Training loss: 1.2815336983306254
Validation loss: 2.5717056418211834

Epoch: 5| Step: 6
Training loss: 1.2891794787417357
Validation loss: 2.517226526502677

Epoch: 5| Step: 7
Training loss: 1.0258636836611548
Validation loss: 2.5078510691257097

Epoch: 5| Step: 8
Training loss: 0.8851713214611338
Validation loss: 2.490411714741487

Epoch: 5| Step: 9
Training loss: 1.291139212967474
Validation loss: 2.465709821121513

Epoch: 5| Step: 10
Training loss: 1.5987429478946868
Validation loss: 2.461330104749182

Epoch: 345| Step: 0
Training loss: 1.3549929616541194
Validation loss: 2.4687503302228526

Epoch: 5| Step: 1
Training loss: 0.9554907720590292
Validation loss: 2.4596500767062737

Epoch: 5| Step: 2
Training loss: 1.184980731759172
Validation loss: 2.5074378340608354

Epoch: 5| Step: 3
Training loss: 1.2424377093445198
Validation loss: 2.5013959781321806

Epoch: 5| Step: 4
Training loss: 1.3120066305841978
Validation loss: 2.5279637126774137

Epoch: 5| Step: 5
Training loss: 1.388121891696684
Validation loss: 2.579962160912982

Epoch: 5| Step: 6
Training loss: 0.9026210738570678
Validation loss: 2.590202767325066

Epoch: 5| Step: 7
Training loss: 1.1803118335741185
Validation loss: 2.63098049828233

Epoch: 5| Step: 8
Training loss: 1.1015080648188473
Validation loss: 2.6129300591686007

Epoch: 5| Step: 9
Training loss: 1.3085939777431006
Validation loss: 2.618942653226361

Epoch: 5| Step: 10
Training loss: 1.2467597927323153
Validation loss: 2.6040619305293893

Epoch: 346| Step: 0
Training loss: 1.183999876338076
Validation loss: 2.5746937570161474

Epoch: 5| Step: 1
Training loss: 1.2790680891856663
Validation loss: 2.553967011557306

Epoch: 5| Step: 2
Training loss: 1.007600155719898
Validation loss: 2.5444009121882885

Epoch: 5| Step: 3
Training loss: 1.2797678306248068
Validation loss: 2.5212235599146045

Epoch: 5| Step: 4
Training loss: 1.4041050977631893
Validation loss: 2.538793173768363

Epoch: 5| Step: 5
Training loss: 1.1153000580106227
Validation loss: 2.5216311656081523

Epoch: 5| Step: 6
Training loss: 1.2731756397451621
Validation loss: 2.5004799951172068

Epoch: 5| Step: 7
Training loss: 1.0631039529788102
Validation loss: 2.517739326335538

Epoch: 5| Step: 8
Training loss: 1.1651644515344466
Validation loss: 2.4901141651406333

Epoch: 5| Step: 9
Training loss: 1.2526675371515872
Validation loss: 2.503906993319693

Epoch: 5| Step: 10
Training loss: 0.8596977668129737
Validation loss: 2.5262820116914693

Epoch: 347| Step: 0
Training loss: 0.8117696707562313
Validation loss: 2.5555921758221833

Epoch: 5| Step: 1
Training loss: 1.3472311040360485
Validation loss: 2.5660375881989297

Epoch: 5| Step: 2
Training loss: 1.1927504663924242
Validation loss: 2.5939524245785837

Epoch: 5| Step: 3
Training loss: 1.034845442265828
Validation loss: 2.589117824943537

Epoch: 5| Step: 4
Training loss: 1.1528722553272204
Validation loss: 2.575135035468155

Epoch: 5| Step: 5
Training loss: 0.7481344784269247
Validation loss: 2.5731604702515884

Epoch: 5| Step: 6
Training loss: 1.488821737513232
Validation loss: 2.582927170446888

Epoch: 5| Step: 7
Training loss: 0.9637414604827912
Validation loss: 2.5614660764863415

Epoch: 5| Step: 8
Training loss: 1.215684900058341
Validation loss: 2.5551700417925294

Epoch: 5| Step: 9
Training loss: 1.2758067738770749
Validation loss: 2.5144649203452665

Epoch: 5| Step: 10
Training loss: 1.377697768994552
Validation loss: 2.520258473284241

Epoch: 348| Step: 0
Training loss: 1.1386349182936526
Validation loss: 2.497240859437213

Epoch: 5| Step: 1
Training loss: 0.9517978120442424
Validation loss: 2.4832458401466107

Epoch: 5| Step: 2
Training loss: 1.2806679403721362
Validation loss: 2.4856739751407164

Epoch: 5| Step: 3
Training loss: 1.0761288947576513
Validation loss: 2.4926644428638856

Epoch: 5| Step: 4
Training loss: 1.3190176217678513
Validation loss: 2.486193257717761

Epoch: 5| Step: 5
Training loss: 1.3686615327437472
Validation loss: 2.5115046120819997

Epoch: 5| Step: 6
Training loss: 0.8595887698545394
Validation loss: 2.4900623454013795

Epoch: 5| Step: 7
Training loss: 1.170260525250873
Validation loss: 2.5137768224164065

Epoch: 5| Step: 8
Training loss: 1.027933973752464
Validation loss: 2.500086265019054

Epoch: 5| Step: 9
Training loss: 1.3994905140791407
Validation loss: 2.504131841493319

Epoch: 5| Step: 10
Training loss: 0.9506365701245939
Validation loss: 2.5110879384485716

Epoch: 349| Step: 0
Training loss: 1.001133336141447
Validation loss: 2.533291686945732

Epoch: 5| Step: 1
Training loss: 0.9681235102721463
Validation loss: 2.5241701172581807

Epoch: 5| Step: 2
Training loss: 0.8166078382505013
Validation loss: 2.5084268357171275

Epoch: 5| Step: 3
Training loss: 1.2263783116146716
Validation loss: 2.525909205876197

Epoch: 5| Step: 4
Training loss: 0.9889537046356452
Validation loss: 2.5166972035907325

Epoch: 5| Step: 5
Training loss: 1.265534715611125
Validation loss: 2.5237500473300627

Epoch: 5| Step: 6
Training loss: 1.25542863782933
Validation loss: 2.546409350466991

Epoch: 5| Step: 7
Training loss: 1.3860041536734076
Validation loss: 2.556596379806869

Epoch: 5| Step: 8
Training loss: 1.171721791742764
Validation loss: 2.55786355552033

Epoch: 5| Step: 9
Training loss: 1.1388165494900107
Validation loss: 2.526677277222613

Epoch: 5| Step: 10
Training loss: 0.9389527191633015
Validation loss: 2.537373707969222

Epoch: 350| Step: 0
Training loss: 0.8126783175296963
Validation loss: 2.522947799726134

Epoch: 5| Step: 1
Training loss: 1.4138347379077962
Validation loss: 2.5021212084928512

Epoch: 5| Step: 2
Training loss: 0.9610632217165369
Validation loss: 2.5047029006653725

Epoch: 5| Step: 3
Training loss: 0.9846242861491511
Validation loss: 2.492616520655976

Epoch: 5| Step: 4
Training loss: 1.374632266028275
Validation loss: 2.518422713110616

Epoch: 5| Step: 5
Training loss: 1.1691934040263299
Validation loss: 2.552815494817161

Epoch: 5| Step: 6
Training loss: 1.1744974928594067
Validation loss: 2.582501519328246

Epoch: 5| Step: 7
Training loss: 0.855106573211063
Validation loss: 2.5520974663415723

Epoch: 5| Step: 8
Training loss: 1.0797938823045485
Validation loss: 2.564670610847465

Epoch: 5| Step: 9
Training loss: 1.2098489113734163
Validation loss: 2.5528784197495633

Epoch: 5| Step: 10
Training loss: 1.1461302748192719
Validation loss: 2.5477797829155686

Epoch: 351| Step: 0
Training loss: 1.0864990758281907
Validation loss: 2.574018742470675

Epoch: 5| Step: 1
Training loss: 1.0920745551086293
Validation loss: 2.5838518760200326

Epoch: 5| Step: 2
Training loss: 0.8613828611390235
Validation loss: 2.587960899298182

Epoch: 5| Step: 3
Training loss: 1.2698292074477344
Validation loss: 2.61322307971044

Epoch: 5| Step: 4
Training loss: 1.1150350041732395
Validation loss: 2.595849246350923

Epoch: 5| Step: 5
Training loss: 1.3454058004495524
Validation loss: 2.5586439423192613

Epoch: 5| Step: 6
Training loss: 0.8055242983647622
Validation loss: 2.5903349048300535

Epoch: 5| Step: 7
Training loss: 1.2458223627345275
Validation loss: 2.583396198991057

Epoch: 5| Step: 8
Training loss: 1.2576549739407001
Validation loss: 2.56059746955745

Epoch: 5| Step: 9
Training loss: 0.8408031927087165
Validation loss: 2.5231256993662505

Epoch: 5| Step: 10
Training loss: 1.0191911736757413
Validation loss: 2.521930544950655

Epoch: 352| Step: 0
Training loss: 0.8891529835008948
Validation loss: 2.503204301062867

Epoch: 5| Step: 1
Training loss: 1.2333182144956698
Validation loss: 2.495696539513494

Epoch: 5| Step: 2
Training loss: 1.225482635399926
Validation loss: 2.5006043185705638

Epoch: 5| Step: 3
Training loss: 1.0517327634189226
Validation loss: 2.486691555321029

Epoch: 5| Step: 4
Training loss: 1.2020552697478704
Validation loss: 2.4556205909156215

Epoch: 5| Step: 5
Training loss: 0.8388158140782844
Validation loss: 2.4918895364197016

Epoch: 5| Step: 6
Training loss: 1.2276477264889116
Validation loss: 2.5150399760591173

Epoch: 5| Step: 7
Training loss: 1.1608040282381333
Validation loss: 2.5344415635624813

Epoch: 5| Step: 8
Training loss: 1.052591629117239
Validation loss: 2.504824597059757

Epoch: 5| Step: 9
Training loss: 1.1915121562976356
Validation loss: 2.5312665100450484

Epoch: 5| Step: 10
Training loss: 0.6263509692955237
Validation loss: 2.551323016289479

Epoch: 353| Step: 0
Training loss: 1.0296029318088264
Validation loss: 2.5488218074901496

Epoch: 5| Step: 1
Training loss: 0.9735310309038855
Validation loss: 2.566191499674643

Epoch: 5| Step: 2
Training loss: 0.9660426116394681
Validation loss: 2.576511891927192

Epoch: 5| Step: 3
Training loss: 0.8339774066714334
Validation loss: 2.5380365729526

Epoch: 5| Step: 4
Training loss: 1.0386116369023408
Validation loss: 2.510433103187362

Epoch: 5| Step: 5
Training loss: 1.090565486912832
Validation loss: 2.5040080008371253

Epoch: 5| Step: 6
Training loss: 1.4273033065369527
Validation loss: 2.4828303421157862

Epoch: 5| Step: 7
Training loss: 0.9914102588809991
Validation loss: 2.441916375006815

Epoch: 5| Step: 8
Training loss: 0.9436712914291435
Validation loss: 2.449743577690505

Epoch: 5| Step: 9
Training loss: 0.9894092440146145
Validation loss: 2.42706759635777

Epoch: 5| Step: 10
Training loss: 1.355263554324958
Validation loss: 2.4364320473219565

Epoch: 354| Step: 0
Training loss: 1.1615132317448262
Validation loss: 2.4210416727648

Epoch: 5| Step: 1
Training loss: 1.4654848043902753
Validation loss: 2.467642081068359

Epoch: 5| Step: 2
Training loss: 0.6409733685705593
Validation loss: 2.4601562416218044

Epoch: 5| Step: 3
Training loss: 0.9961914014633981
Validation loss: 2.4634356836348275

Epoch: 5| Step: 4
Training loss: 1.2554949147050416
Validation loss: 2.505621995778584

Epoch: 5| Step: 5
Training loss: 1.0300485953191103
Validation loss: 2.4723064371700647

Epoch: 5| Step: 6
Training loss: 0.7938233078873426
Validation loss: 2.508320601522343

Epoch: 5| Step: 7
Training loss: 1.0537096364717697
Validation loss: 2.5241977109497644

Epoch: 5| Step: 8
Training loss: 1.2071796807439032
Validation loss: 2.541237821329927

Epoch: 5| Step: 9
Training loss: 0.9637170305562369
Validation loss: 2.563346454871558

Epoch: 5| Step: 10
Training loss: 0.860145466223256
Validation loss: 2.6039866966490055

Epoch: 355| Step: 0
Training loss: 1.0239110535384246
Validation loss: 2.56999573381275

Epoch: 5| Step: 1
Training loss: 0.9711933088020266
Validation loss: 2.5798831576731014

Epoch: 5| Step: 2
Training loss: 0.9377418841806847
Validation loss: 2.603366199811827

Epoch: 5| Step: 3
Training loss: 1.2880617360696727
Validation loss: 2.5810239948026767

Epoch: 5| Step: 4
Training loss: 1.1948412795382382
Validation loss: 2.563538534717179

Epoch: 5| Step: 5
Training loss: 1.3527381061939816
Validation loss: 2.5484381068386583

Epoch: 5| Step: 6
Training loss: 0.7161079442954084
Validation loss: 2.5202901369033714

Epoch: 5| Step: 7
Training loss: 0.8922778402844572
Validation loss: 2.477388618317932

Epoch: 5| Step: 8
Training loss: 1.1815022032818487
Validation loss: 2.4597907469416502

Epoch: 5| Step: 9
Training loss: 0.8290013049360434
Validation loss: 2.4522845446589767

Epoch: 5| Step: 10
Training loss: 1.062757965635941
Validation loss: 2.421030557467683

Epoch: 356| Step: 0
Training loss: 0.775775727312881
Validation loss: 2.4220901282565435

Epoch: 5| Step: 1
Training loss: 1.419540417000748
Validation loss: 2.443556651244905

Epoch: 5| Step: 2
Training loss: 1.2114192373582577
Validation loss: 2.4372400135169605

Epoch: 5| Step: 3
Training loss: 0.9365813841012175
Validation loss: 2.4949275583980115

Epoch: 5| Step: 4
Training loss: 1.3415430264733488
Validation loss: 2.5398493963659345

Epoch: 5| Step: 5
Training loss: 0.9008933296186171
Validation loss: 2.5640376250126673

Epoch: 5| Step: 6
Training loss: 0.9277880201389839
Validation loss: 2.609505617506362

Epoch: 5| Step: 7
Training loss: 0.9221566949842188
Validation loss: 2.598369636192321

Epoch: 5| Step: 8
Training loss: 1.3013266030226136
Validation loss: 2.635299480270739

Epoch: 5| Step: 9
Training loss: 1.275131409548852
Validation loss: 2.602348107767368

Epoch: 5| Step: 10
Training loss: 0.6009689474382721
Validation loss: 2.5864652090203557

Epoch: 357| Step: 0
Training loss: 1.0364049325857267
Validation loss: 2.5594954245056343

Epoch: 5| Step: 1
Training loss: 0.8752133926672755
Validation loss: 2.516304190662802

Epoch: 5| Step: 2
Training loss: 0.786315745044474
Validation loss: 2.5090176746857864

Epoch: 5| Step: 3
Training loss: 1.0733034985899605
Validation loss: 2.500615230865317

Epoch: 5| Step: 4
Training loss: 1.010565199536548
Validation loss: 2.4804732644580456

Epoch: 5| Step: 5
Training loss: 1.0301845711081663
Validation loss: 2.4747081260694417

Epoch: 5| Step: 6
Training loss: 1.2747647442411072
Validation loss: 2.464507951080227

Epoch: 5| Step: 7
Training loss: 1.3016265780095813
Validation loss: 2.4989336713503505

Epoch: 5| Step: 8
Training loss: 1.1198051037832362
Validation loss: 2.493784333210996

Epoch: 5| Step: 9
Training loss: 1.1183831279336065
Validation loss: 2.5285471436097295

Epoch: 5| Step: 10
Training loss: 0.8483379101832748
Validation loss: 2.5947761986466578

Epoch: 358| Step: 0
Training loss: 1.1251064356151854
Validation loss: 2.5908424328846036

Epoch: 5| Step: 1
Training loss: 1.1544435152995098
Validation loss: 2.6179416883027677

Epoch: 5| Step: 2
Training loss: 0.8230743418103899
Validation loss: 2.6292037158053136

Epoch: 5| Step: 3
Training loss: 1.1580580930945612
Validation loss: 2.6310690760550473

Epoch: 5| Step: 4
Training loss: 0.9401311826478542
Validation loss: 2.627929644576405

Epoch: 5| Step: 5
Training loss: 1.131236960404416
Validation loss: 2.6028791714259434

Epoch: 5| Step: 6
Training loss: 0.8007852693782511
Validation loss: 2.615285315310773

Epoch: 5| Step: 7
Training loss: 1.20184555390579
Validation loss: 2.5630560621017477

Epoch: 5| Step: 8
Training loss: 0.9971306284745266
Validation loss: 2.5231268546232934

Epoch: 5| Step: 9
Training loss: 1.0024577574736524
Validation loss: 2.500963757469644

Epoch: 5| Step: 10
Training loss: 0.9089028237042007
Validation loss: 2.479749710449496

Epoch: 359| Step: 0
Training loss: 0.9281977730937006
Validation loss: 2.472986731590759

Epoch: 5| Step: 1
Training loss: 1.0644738431541658
Validation loss: 2.4416152779301004

Epoch: 5| Step: 2
Training loss: 1.1858198929322343
Validation loss: 2.4355459697694832

Epoch: 5| Step: 3
Training loss: 1.2199325692975054
Validation loss: 2.418566465896139

Epoch: 5| Step: 4
Training loss: 1.1181739773373196
Validation loss: 2.4424502933956145

Epoch: 5| Step: 5
Training loss: 1.1671877900599434
Validation loss: 2.4647934188580747

Epoch: 5| Step: 6
Training loss: 0.7365037622608189
Validation loss: 2.4869284571124193

Epoch: 5| Step: 7
Training loss: 1.0842129303143377
Validation loss: 2.5135757475460454

Epoch: 5| Step: 8
Training loss: 0.9059486545851083
Validation loss: 2.5547690364573787

Epoch: 5| Step: 9
Training loss: 1.2438437019208017
Validation loss: 2.5480615823778265

Epoch: 5| Step: 10
Training loss: 1.0063288805828245
Validation loss: 2.5803241467587577

Epoch: 360| Step: 0
Training loss: 0.7946425938491017
Validation loss: 2.561211662060202

Epoch: 5| Step: 1
Training loss: 1.3253280809274082
Validation loss: 2.540807256609358

Epoch: 5| Step: 2
Training loss: 1.2118120050607835
Validation loss: 2.5413358047019767

Epoch: 5| Step: 3
Training loss: 0.6816583975412405
Validation loss: 2.510748566108997

Epoch: 5| Step: 4
Training loss: 0.8924761824541966
Validation loss: 2.486043186176057

Epoch: 5| Step: 5
Training loss: 1.197808645049634
Validation loss: 2.507305104284394

Epoch: 5| Step: 6
Training loss: 0.7742679645744014
Validation loss: 2.5162469106233156

Epoch: 5| Step: 7
Training loss: 0.9655578688708553
Validation loss: 2.502642761597352

Epoch: 5| Step: 8
Training loss: 1.265093420974285
Validation loss: 2.5302188144691806

Epoch: 5| Step: 9
Training loss: 1.0303788985382598
Validation loss: 2.542824465503449

Epoch: 5| Step: 10
Training loss: 0.8572887065244597
Validation loss: 2.529896727737007

Epoch: 361| Step: 0
Training loss: 1.0935729837224122
Validation loss: 2.55896033746869

Epoch: 5| Step: 1
Training loss: 0.9404751617116746
Validation loss: 2.5486788129387237

Epoch: 5| Step: 2
Training loss: 1.0567656776198424
Validation loss: 2.570209368325349

Epoch: 5| Step: 3
Training loss: 0.8245606639792176
Validation loss: 2.520858137726861

Epoch: 5| Step: 4
Training loss: 1.0774859317294825
Validation loss: 2.5238334080790668

Epoch: 5| Step: 5
Training loss: 0.7335211070923715
Validation loss: 2.4974216947998285

Epoch: 5| Step: 6
Training loss: 1.3232435388311827
Validation loss: 2.528908308124395

Epoch: 5| Step: 7
Training loss: 0.7735248092539185
Validation loss: 2.5233788449984496

Epoch: 5| Step: 8
Training loss: 1.2056717608348355
Validation loss: 2.4994065569945088

Epoch: 5| Step: 9
Training loss: 1.209757026442264
Validation loss: 2.5029225330619345

Epoch: 5| Step: 10
Training loss: 1.0362147263803387
Validation loss: 2.559664914955963

Epoch: 362| Step: 0
Training loss: 0.8740933012078638
Validation loss: 2.5335189108025364

Epoch: 5| Step: 1
Training loss: 1.238749947879917
Validation loss: 2.551421515660805

Epoch: 5| Step: 2
Training loss: 0.9420842938177135
Validation loss: 2.548136924116868

Epoch: 5| Step: 3
Training loss: 1.0969328210268052
Validation loss: 2.5657102863261976

Epoch: 5| Step: 4
Training loss: 1.1468497998537919
Validation loss: 2.5237487338924627

Epoch: 5| Step: 5
Training loss: 0.7836618578322617
Validation loss: 2.5205482464759887

Epoch: 5| Step: 6
Training loss: 1.0949556517656303
Validation loss: 2.509357012426532

Epoch: 5| Step: 7
Training loss: 0.9384344530135519
Validation loss: 2.4999569022657937

Epoch: 5| Step: 8
Training loss: 1.1083700436891817
Validation loss: 2.4514239085024103

Epoch: 5| Step: 9
Training loss: 0.6506552859393044
Validation loss: 2.4905818097652235

Epoch: 5| Step: 10
Training loss: 1.0417957925236632
Validation loss: 2.4820578318941298

Epoch: 363| Step: 0
Training loss: 0.7966325054332902
Validation loss: 2.4662089289036566

Epoch: 5| Step: 1
Training loss: 1.034047926162847
Validation loss: 2.4868852086168176

Epoch: 5| Step: 2
Training loss: 0.9660655945449884
Validation loss: 2.5132058675413678

Epoch: 5| Step: 3
Training loss: 0.980428079316302
Validation loss: 2.5214687784849614

Epoch: 5| Step: 4
Training loss: 0.8929612821064794
Validation loss: 2.5406250260740855

Epoch: 5| Step: 5
Training loss: 1.1510817001538498
Validation loss: 2.526478290447599

Epoch: 5| Step: 6
Training loss: 0.8797763840539401
Validation loss: 2.553553371360067

Epoch: 5| Step: 7
Training loss: 0.8622925564181547
Validation loss: 2.5474432170410553

Epoch: 5| Step: 8
Training loss: 1.0384821597657483
Validation loss: 2.545806177334577

Epoch: 5| Step: 9
Training loss: 1.156220049083552
Validation loss: 2.511996864621066

Epoch: 5| Step: 10
Training loss: 1.0930675012069584
Validation loss: 2.5369081324307365

Epoch: 364| Step: 0
Training loss: 0.6023528121880063
Validation loss: 2.5431473408445466

Epoch: 5| Step: 1
Training loss: 0.9239358980249713
Validation loss: 2.51283164817218

Epoch: 5| Step: 2
Training loss: 0.9190102370836589
Validation loss: 2.534876122220176

Epoch: 5| Step: 3
Training loss: 1.1989702097649502
Validation loss: 2.537667259879999

Epoch: 5| Step: 4
Training loss: 1.1936242641519013
Validation loss: 2.53687998880708

Epoch: 5| Step: 5
Training loss: 1.1100026893583144
Validation loss: 2.5285986085936054

Epoch: 5| Step: 6
Training loss: 1.0008691348602807
Validation loss: 2.5334478954173245

Epoch: 5| Step: 7
Training loss: 0.7354210241979328
Validation loss: 2.4818432192884763

Epoch: 5| Step: 8
Training loss: 0.8652821133707199
Validation loss: 2.4903611725341745

Epoch: 5| Step: 9
Training loss: 1.0559258431962213
Validation loss: 2.5011459882413103

Epoch: 5| Step: 10
Training loss: 0.7639349754957787
Validation loss: 2.4976117878636432

Epoch: 365| Step: 0
Training loss: 1.0275963882381332
Validation loss: 2.514551075015143

Epoch: 5| Step: 1
Training loss: 0.990351291954826
Validation loss: 2.5512111513673172

Epoch: 5| Step: 2
Training loss: 0.9137657205400896
Validation loss: 2.5454686903274215

Epoch: 5| Step: 3
Training loss: 1.0931634692690904
Validation loss: 2.5695922846907684

Epoch: 5| Step: 4
Training loss: 0.9926818156961966
Validation loss: 2.5516981793989006

Epoch: 5| Step: 5
Training loss: 0.6862596897837788
Validation loss: 2.5579488202436638

Epoch: 5| Step: 6
Training loss: 1.0700613130846175
Validation loss: 2.57231999550194

Epoch: 5| Step: 7
Training loss: 0.5800020572609426
Validation loss: 2.5177954200652892

Epoch: 5| Step: 8
Training loss: 0.865173682157257
Validation loss: 2.5139698016751675

Epoch: 5| Step: 9
Training loss: 1.1464747569835865
Validation loss: 2.5301829319223645

Epoch: 5| Step: 10
Training loss: 0.8567899143370695
Validation loss: 2.501087412657304

Epoch: 366| Step: 0
Training loss: 0.7019854954731765
Validation loss: 2.494430210782498

Epoch: 5| Step: 1
Training loss: 1.1975160122240875
Validation loss: 2.4789417582248956

Epoch: 5| Step: 2
Training loss: 0.8669631599092322
Validation loss: 2.4713911780772904

Epoch: 5| Step: 3
Training loss: 1.0833620776740172
Validation loss: 2.4806195148115346

Epoch: 5| Step: 4
Training loss: 1.021482741170419
Validation loss: 2.5033401059878257

Epoch: 5| Step: 5
Training loss: 0.8547466139077805
Validation loss: 2.4927878093844065

Epoch: 5| Step: 6
Training loss: 0.9225688844512464
Validation loss: 2.475794303901385

Epoch: 5| Step: 7
Training loss: 0.9641372008726914
Validation loss: 2.4765650190627384

Epoch: 5| Step: 8
Training loss: 0.7443183025992703
Validation loss: 2.493072004086211

Epoch: 5| Step: 9
Training loss: 0.9529756522816062
Validation loss: 2.52264842017426

Epoch: 5| Step: 10
Training loss: 0.7546443192348743
Validation loss: 2.5092238891612118

Epoch: 367| Step: 0
Training loss: 1.1480449083330222
Validation loss: 2.496562275922562

Epoch: 5| Step: 1
Training loss: 0.8034325971717164
Validation loss: 2.518214722092982

Epoch: 5| Step: 2
Training loss: 0.9934004330747216
Validation loss: 2.54778964541437

Epoch: 5| Step: 3
Training loss: 0.9092199724329787
Validation loss: 2.5430884131092872

Epoch: 5| Step: 4
Training loss: 0.9061295659511572
Validation loss: 2.566488987908543

Epoch: 5| Step: 5
Training loss: 0.6234479468290189
Validation loss: 2.56457126083752

Epoch: 5| Step: 6
Training loss: 0.9354524823633728
Validation loss: 2.542750750898084

Epoch: 5| Step: 7
Training loss: 0.9777005088022146
Validation loss: 2.5365983170937967

Epoch: 5| Step: 8
Training loss: 1.014920856227779
Validation loss: 2.5528157498942283

Epoch: 5| Step: 9
Training loss: 0.774892690366482
Validation loss: 2.5334117899383672

Epoch: 5| Step: 10
Training loss: 0.6881260189149331
Validation loss: 2.5422883311554334

Epoch: 368| Step: 0
Training loss: 1.1894137371287918
Validation loss: 2.530096309968337

Epoch: 5| Step: 1
Training loss: 0.7764110624763395
Validation loss: 2.512471382730344

Epoch: 5| Step: 2
Training loss: 0.7098057720311868
Validation loss: 2.55229726116174

Epoch: 5| Step: 3
Training loss: 0.7534620330246613
Validation loss: 2.5329141406683107

Epoch: 5| Step: 4
Training loss: 0.9406282367840709
Validation loss: 2.5380250750932842

Epoch: 5| Step: 5
Training loss: 1.1501209610058711
Validation loss: 2.5649603670593195

Epoch: 5| Step: 6
Training loss: 0.9698903539961201
Validation loss: 2.543637898340781

Epoch: 5| Step: 7
Training loss: 0.832675630584074
Validation loss: 2.5271457642055384

Epoch: 5| Step: 8
Training loss: 1.0133383612026998
Validation loss: 2.534434857169978

Epoch: 5| Step: 9
Training loss: 0.48883028824620045
Validation loss: 2.5324954441940117

Epoch: 5| Step: 10
Training loss: 0.833581831756595
Validation loss: 2.5158973209643225

Epoch: 369| Step: 0
Training loss: 1.2296008243090188
Validation loss: 2.5060629584330405

Epoch: 5| Step: 1
Training loss: 0.8101808755749922
Validation loss: 2.5262318563121555

Epoch: 5| Step: 2
Training loss: 0.8698069215148724
Validation loss: 2.514911764765393

Epoch: 5| Step: 3
Training loss: 0.8225182441960603
Validation loss: 2.505150050582672

Epoch: 5| Step: 4
Training loss: 0.8660848669883177
Validation loss: 2.506286699240493

Epoch: 5| Step: 5
Training loss: 0.8855459380681248
Validation loss: 2.4958844919210574

Epoch: 5| Step: 6
Training loss: 1.094116912334251
Validation loss: 2.505563264948067

Epoch: 5| Step: 7
Training loss: 0.8909375161097701
Validation loss: 2.500938051880583

Epoch: 5| Step: 8
Training loss: 0.4809828543145001
Validation loss: 2.5234762453130726

Epoch: 5| Step: 9
Training loss: 0.8471355333082883
Validation loss: 2.5028208702304644

Epoch: 5| Step: 10
Training loss: 0.7969652760550411
Validation loss: 2.5293412146112764

Epoch: 370| Step: 0
Training loss: 0.9171368989519613
Validation loss: 2.529466173412712

Epoch: 5| Step: 1
Training loss: 0.808899568232085
Validation loss: 2.5264074860951817

Epoch: 5| Step: 2
Training loss: 0.6447464323636615
Validation loss: 2.510540530046268

Epoch: 5| Step: 3
Training loss: 0.7988995657689147
Validation loss: 2.531285998069332

Epoch: 5| Step: 4
Training loss: 1.0836264629417944
Validation loss: 2.5078643010425696

Epoch: 5| Step: 5
Training loss: 0.9420090640820523
Validation loss: 2.527084382669904

Epoch: 5| Step: 6
Training loss: 1.088392706843864
Validation loss: 2.499263218013831

Epoch: 5| Step: 7
Training loss: 1.1218200882673048
Validation loss: 2.518438709202455

Epoch: 5| Step: 8
Training loss: 0.7079750632242635
Validation loss: 2.4955380912675453

Epoch: 5| Step: 9
Training loss: 0.7788899059360059
Validation loss: 2.514871433341183

Epoch: 5| Step: 10
Training loss: 0.6031143187530746
Validation loss: 2.502426493714582

Epoch: 371| Step: 0
Training loss: 1.151730183332572
Validation loss: 2.517764901117698

Epoch: 5| Step: 1
Training loss: 0.8323945519390482
Validation loss: 2.4697407548710943

Epoch: 5| Step: 2
Training loss: 0.6676027287859428
Validation loss: 2.51307145367982

Epoch: 5| Step: 3
Training loss: 1.0681723478033947
Validation loss: 2.491632789230335

Epoch: 5| Step: 4
Training loss: 0.7885081544017827
Validation loss: 2.465362399093863

Epoch: 5| Step: 5
Training loss: 0.7138061079830108
Validation loss: 2.463177977738731

Epoch: 5| Step: 6
Training loss: 0.9160451009924714
Validation loss: 2.4891178291267155

Epoch: 5| Step: 7
Training loss: 0.5881014474415395
Validation loss: 2.481274571525307

Epoch: 5| Step: 8
Training loss: 0.9995426681937375
Validation loss: 2.493217080458723

Epoch: 5| Step: 9
Training loss: 1.045436269050038
Validation loss: 2.503989723627293

Epoch: 5| Step: 10
Training loss: 0.5243503808936187
Validation loss: 2.5047739511206997

Epoch: 372| Step: 0
Training loss: 0.5790058333476954
Validation loss: 2.5001047604668907

Epoch: 5| Step: 1
Training loss: 0.9467826634572861
Validation loss: 2.5185129816937586

Epoch: 5| Step: 2
Training loss: 0.8091587911969677
Validation loss: 2.456003213835317

Epoch: 5| Step: 3
Training loss: 0.978497107172585
Validation loss: 2.4966178699528

Epoch: 5| Step: 4
Training loss: 1.100712820488692
Validation loss: 2.525266505102638

Epoch: 5| Step: 5
Training loss: 0.605294233212934
Validation loss: 2.4935704687255917

Epoch: 5| Step: 6
Training loss: 0.8312252600293852
Validation loss: 2.4751497110907694

Epoch: 5| Step: 7
Training loss: 0.5486582971821378
Validation loss: 2.503672218747325

Epoch: 5| Step: 8
Training loss: 1.2302707088892586
Validation loss: 2.489438397735063

Epoch: 5| Step: 9
Training loss: 0.8550440112715808
Validation loss: 2.512516613622037

Epoch: 5| Step: 10
Training loss: 0.7258322542827074
Validation loss: 2.518711830305318

Epoch: 373| Step: 0
Training loss: 0.6281900296306905
Validation loss: 2.520755311685168

Epoch: 5| Step: 1
Training loss: 0.6908738408638879
Validation loss: 2.5327372049002213

Epoch: 5| Step: 2
Training loss: 0.909079409927554
Validation loss: 2.5284396742163575

Epoch: 5| Step: 3
Training loss: 0.6300177377898257
Validation loss: 2.5325241690054554

Epoch: 5| Step: 4
Training loss: 0.86298589702854
Validation loss: 2.5342638877328674

Epoch: 5| Step: 5
Training loss: 0.8862703508803329
Validation loss: 2.544887369320006

Epoch: 5| Step: 6
Training loss: 1.2174721890510152
Validation loss: 2.504264538298434

Epoch: 5| Step: 7
Training loss: 0.8370425327118112
Validation loss: 2.4985281846928635

Epoch: 5| Step: 8
Training loss: 0.7087993538036587
Validation loss: 2.4571804366068966

Epoch: 5| Step: 9
Training loss: 1.0137072136218799
Validation loss: 2.467158445129407

Epoch: 5| Step: 10
Training loss: 0.973043219254348
Validation loss: 2.45832564691837

Epoch: 374| Step: 0
Training loss: 0.7972386596246355
Validation loss: 2.47481477188699

Epoch: 5| Step: 1
Training loss: 0.8895703479316405
Validation loss: 2.4720801440945035

Epoch: 5| Step: 2
Training loss: 1.0267398930626426
Validation loss: 2.4992763497403967

Epoch: 5| Step: 3
Training loss: 0.791979017042348
Validation loss: 2.5094727637820773

Epoch: 5| Step: 4
Training loss: 1.0385966009356558
Validation loss: 2.496948826994781

Epoch: 5| Step: 5
Training loss: 0.7532279169825525
Validation loss: 2.487569488644776

Epoch: 5| Step: 6
Training loss: 0.7692044721289895
Validation loss: 2.5024885773853676

Epoch: 5| Step: 7
Training loss: 0.6180846779518816
Validation loss: 2.517327332591211

Epoch: 5| Step: 8
Training loss: 1.0426989717218882
Validation loss: 2.514116484475035

Epoch: 5| Step: 9
Training loss: 0.871066790107957
Validation loss: 2.525178247489867

Epoch: 5| Step: 10
Training loss: 0.6803407051502246
Validation loss: 2.523359404614925

Epoch: 375| Step: 0
Training loss: 0.6894801407402901
Validation loss: 2.5203188909658603

Epoch: 5| Step: 1
Training loss: 1.1444532348291105
Validation loss: 2.5009667055436013

Epoch: 5| Step: 2
Training loss: 0.7006287450290468
Validation loss: 2.4789042486912316

Epoch: 5| Step: 3
Training loss: 0.8685848902500778
Validation loss: 2.5125881127069656

Epoch: 5| Step: 4
Training loss: 1.1484328289326244
Validation loss: 2.475208283194745

Epoch: 5| Step: 5
Training loss: 0.8802085214347564
Validation loss: 2.488704654195225

Epoch: 5| Step: 6
Training loss: 0.7015546003886708
Validation loss: 2.4641808725077876

Epoch: 5| Step: 7
Training loss: 0.856767235065236
Validation loss: 2.4662880346124383

Epoch: 5| Step: 8
Training loss: 0.8169677847460487
Validation loss: 2.508707138344397

Epoch: 5| Step: 9
Training loss: 0.8532067619520763
Validation loss: 2.4937980797518002

Epoch: 5| Step: 10
Training loss: 0.44990684220532795
Validation loss: 2.4829744067284163

Epoch: 376| Step: 0
Training loss: 0.956957444439639
Validation loss: 2.5187533964309625

Epoch: 5| Step: 1
Training loss: 0.896816848571005
Validation loss: 2.5335407493029316

Epoch: 5| Step: 2
Training loss: 0.8386700257492821
Validation loss: 2.5272539368216105

Epoch: 5| Step: 3
Training loss: 0.6898066665169111
Validation loss: 2.5044073806697384

Epoch: 5| Step: 4
Training loss: 0.8422870315309741
Validation loss: 2.5344220927217016

Epoch: 5| Step: 5
Training loss: 0.8924999244540314
Validation loss: 2.5276905932606484

Epoch: 5| Step: 6
Training loss: 0.6509513614330592
Validation loss: 2.5234803165943376

Epoch: 5| Step: 7
Training loss: 0.7104618871024733
Validation loss: 2.543406763497958

Epoch: 5| Step: 8
Training loss: 0.8071497310437356
Validation loss: 2.5568724665592124

Epoch: 5| Step: 9
Training loss: 1.0725062366117533
Validation loss: 2.5643733990277044

Epoch: 5| Step: 10
Training loss: 0.8164861174581176
Validation loss: 2.5690212532788155

Epoch: 377| Step: 0
Training loss: 0.8770144298849595
Validation loss: 2.5490980966595744

Epoch: 5| Step: 1
Training loss: 0.9001954502230585
Validation loss: 2.5418649730922676

Epoch: 5| Step: 2
Training loss: 1.0652124898555742
Validation loss: 2.497410559141132

Epoch: 5| Step: 3
Training loss: 0.9888529876527288
Validation loss: 2.504127179266623

Epoch: 5| Step: 4
Training loss: 0.7540740384777439
Validation loss: 2.5217773173793776

Epoch: 5| Step: 5
Training loss: 0.8064707283861662
Validation loss: 2.5065435153846445

Epoch: 5| Step: 6
Training loss: 0.44499459547339903
Validation loss: 2.533410276087539

Epoch: 5| Step: 7
Training loss: 0.7313251473050685
Validation loss: 2.5189581218299146

Epoch: 5| Step: 8
Training loss: 0.8785677109505644
Validation loss: 2.5025940091443863

Epoch: 5| Step: 9
Training loss: 0.9459646828371723
Validation loss: 2.514012681110588

Epoch: 5| Step: 10
Training loss: 0.5987828674931637
Validation loss: 2.499997710667864

Epoch: 378| Step: 0
Training loss: 0.8032033993346064
Validation loss: 2.5310172730186324

Epoch: 5| Step: 1
Training loss: 0.9309951817626507
Validation loss: 2.5345429978609895

Epoch: 5| Step: 2
Training loss: 0.966325062924176
Validation loss: 2.536677404115798

Epoch: 5| Step: 3
Training loss: 0.5634283246791745
Validation loss: 2.544782797232833

Epoch: 5| Step: 4
Training loss: 0.7115145845828438
Validation loss: 2.509449471527785

Epoch: 5| Step: 5
Training loss: 0.8389634597832623
Validation loss: 2.5192743224923566

Epoch: 5| Step: 6
Training loss: 0.973336468347526
Validation loss: 2.4899373596764005

Epoch: 5| Step: 7
Training loss: 1.147984317971492
Validation loss: 2.4552326040722314

Epoch: 5| Step: 8
Training loss: 0.7210465933443966
Validation loss: 2.469521208525084

Epoch: 5| Step: 9
Training loss: 0.7223903682385586
Validation loss: 2.434601597393896

Epoch: 5| Step: 10
Training loss: 0.46105994198526357
Validation loss: 2.4800130761304953

Epoch: 379| Step: 0
Training loss: 0.4823569744485707
Validation loss: 2.4382297274422813

Epoch: 5| Step: 1
Training loss: 0.9920553284566533
Validation loss: 2.45299094399284

Epoch: 5| Step: 2
Training loss: 0.8966808893240966
Validation loss: 2.4723688396069523

Epoch: 5| Step: 3
Training loss: 0.8782741732160395
Validation loss: 2.480797062376384

Epoch: 5| Step: 4
Training loss: 0.7589195266954019
Validation loss: 2.49740695400205

Epoch: 5| Step: 5
Training loss: 0.6761359678504782
Validation loss: 2.518670078244117

Epoch: 5| Step: 6
Training loss: 0.8050846490128295
Validation loss: 2.523949309126105

Epoch: 5| Step: 7
Training loss: 0.8330200838390351
Validation loss: 2.5145201170330727

Epoch: 5| Step: 8
Training loss: 0.946138478236911
Validation loss: 2.4928174524763866

Epoch: 5| Step: 9
Training loss: 0.9785360002966143
Validation loss: 2.500652388081556

Epoch: 5| Step: 10
Training loss: 0.5996188681779808
Validation loss: 2.48230692467901

Epoch: 380| Step: 0
Training loss: 0.6248409545713806
Validation loss: 2.4817624933148092

Epoch: 5| Step: 1
Training loss: 0.9807472289467044
Validation loss: 2.477426945525326

Epoch: 5| Step: 2
Training loss: 0.5375004679655655
Validation loss: 2.4550737497160835

Epoch: 5| Step: 3
Training loss: 0.8665502457796047
Validation loss: 2.433042383295708

Epoch: 5| Step: 4
Training loss: 1.0536556140988138
Validation loss: 2.483335132258242

Epoch: 5| Step: 5
Training loss: 0.9507556921251634
Validation loss: 2.4848653647731185

Epoch: 5| Step: 6
Training loss: 0.8652966823489151
Validation loss: 2.503446544874534

Epoch: 5| Step: 7
Training loss: 0.6730212037896752
Validation loss: 2.4955262671348173

Epoch: 5| Step: 8
Training loss: 0.8719085509158204
Validation loss: 2.4985467481072616

Epoch: 5| Step: 9
Training loss: 0.5106980722313674
Validation loss: 2.4873781519531577

Epoch: 5| Step: 10
Training loss: 0.734243421738757
Validation loss: 2.5151357570546042

Epoch: 381| Step: 0
Training loss: 0.9499868417129762
Validation loss: 2.5192320648338975

Epoch: 5| Step: 1
Training loss: 0.7461633300291975
Validation loss: 2.5142377104398017

Epoch: 5| Step: 2
Training loss: 0.9590445381140679
Validation loss: 2.519056018228438

Epoch: 5| Step: 3
Training loss: 0.6630707010083277
Validation loss: 2.5056491082264203

Epoch: 5| Step: 4
Training loss: 0.8311372350628959
Validation loss: 2.531292050953104

Epoch: 5| Step: 5
Training loss: 1.0740427878787684
Validation loss: 2.5132243541639556

Epoch: 5| Step: 6
Training loss: 0.48558700346597644
Validation loss: 2.512223017426337

Epoch: 5| Step: 7
Training loss: 0.7111134573364627
Validation loss: 2.5105089002095307

Epoch: 5| Step: 8
Training loss: 0.6440340378426219
Validation loss: 2.490384191405473

Epoch: 5| Step: 9
Training loss: 0.8502122866379659
Validation loss: 2.45260985492362

Epoch: 5| Step: 10
Training loss: 0.768023723136556
Validation loss: 2.4776836049804034

Epoch: 382| Step: 0
Training loss: 0.914081638494469
Validation loss: 2.470291728997237

Epoch: 5| Step: 1
Training loss: 0.8040151286931801
Validation loss: 2.439249384327733

Epoch: 5| Step: 2
Training loss: 0.8871118287657679
Validation loss: 2.4629231406451226

Epoch: 5| Step: 3
Training loss: 0.7238960147811732
Validation loss: 2.4452187784479142

Epoch: 5| Step: 4
Training loss: 0.8272383279608156
Validation loss: 2.455165095463703

Epoch: 5| Step: 5
Training loss: 0.5413014452230152
Validation loss: 2.4670913865124273

Epoch: 5| Step: 6
Training loss: 0.8867075579100768
Validation loss: 2.488035247851722

Epoch: 5| Step: 7
Training loss: 0.8046387592850133
Validation loss: 2.4780927455209807

Epoch: 5| Step: 8
Training loss: 0.23046431294712125
Validation loss: 2.484886045154208

Epoch: 5| Step: 9
Training loss: 0.6845916875312849
Validation loss: 2.4716775145527854

Epoch: 5| Step: 10
Training loss: 1.085061028341927
Validation loss: 2.471991151165107

Epoch: 383| Step: 0
Training loss: 1.0476352151896813
Validation loss: 2.510798226706782

Epoch: 5| Step: 1
Training loss: 0.7233134400214865
Validation loss: 2.4947315528832887

Epoch: 5| Step: 2
Training loss: 0.806005121347329
Validation loss: 2.482111527074967

Epoch: 5| Step: 3
Training loss: 0.7146380185777557
Validation loss: 2.5021394470979494

Epoch: 5| Step: 4
Training loss: 0.6932606371570086
Validation loss: 2.4849827975449403

Epoch: 5| Step: 5
Training loss: 0.801260232726173
Validation loss: 2.471201006949531

Epoch: 5| Step: 6
Training loss: 0.5330833887495058
Validation loss: 2.4709606000989353

Epoch: 5| Step: 7
Training loss: 0.6455083203566223
Validation loss: 2.4622571504479795

Epoch: 5| Step: 8
Training loss: 0.8796087212801112
Validation loss: 2.454232365087677

Epoch: 5| Step: 9
Training loss: 0.8487896351836697
Validation loss: 2.4359149349009726

Epoch: 5| Step: 10
Training loss: 0.8772105155727667
Validation loss: 2.4416006118030213

Epoch: 384| Step: 0
Training loss: 0.8104784097825765
Validation loss: 2.446394339427643

Epoch: 5| Step: 1
Training loss: 0.8192716989352986
Validation loss: 2.4486232066946965

Epoch: 5| Step: 2
Training loss: 0.7824421370078112
Validation loss: 2.441503994599119

Epoch: 5| Step: 3
Training loss: 0.7256478325589008
Validation loss: 2.480663249753969

Epoch: 5| Step: 4
Training loss: 0.6521269158087871
Validation loss: 2.485121530404419

Epoch: 5| Step: 5
Training loss: 0.6502538084632136
Validation loss: 2.4935589272445156

Epoch: 5| Step: 6
Training loss: 0.9234628096208686
Validation loss: 2.4908150706393632

Epoch: 5| Step: 7
Training loss: 0.9275694690507059
Validation loss: 2.4891361527119376

Epoch: 5| Step: 8
Training loss: 0.6717737476437288
Validation loss: 2.5055100498472553

Epoch: 5| Step: 9
Training loss: 0.9221859100545261
Validation loss: 2.5164015874495282

Epoch: 5| Step: 10
Training loss: 0.6720059954668144
Validation loss: 2.5210338439223188

Epoch: 385| Step: 0
Training loss: 0.418263589844581
Validation loss: 2.5191583895376257

Epoch: 5| Step: 1
Training loss: 0.9545599032728694
Validation loss: 2.5232443964684896

Epoch: 5| Step: 2
Training loss: 0.8379573839886693
Validation loss: 2.525778722107287

Epoch: 5| Step: 3
Training loss: 0.5664884836418534
Validation loss: 2.5364451468160043

Epoch: 5| Step: 4
Training loss: 0.7427818729183447
Validation loss: 2.5319899851370216

Epoch: 5| Step: 5
Training loss: 0.7722277572678938
Validation loss: 2.5219433177302535

Epoch: 5| Step: 6
Training loss: 0.78990336267712
Validation loss: 2.523023209602953

Epoch: 5| Step: 7
Training loss: 0.8183889087819455
Validation loss: 2.501012240339146

Epoch: 5| Step: 8
Training loss: 0.9433151455890577
Validation loss: 2.50601903915892

Epoch: 5| Step: 9
Training loss: 0.6977702646760485
Validation loss: 2.50546270690834

Epoch: 5| Step: 10
Training loss: 0.8072599753445441
Validation loss: 2.5274521748222423

Epoch: 386| Step: 0
Training loss: 0.7340942008301413
Validation loss: 2.5210909117337814

Epoch: 5| Step: 1
Training loss: 1.1167724478613017
Validation loss: 2.506247182361728

Epoch: 5| Step: 2
Training loss: 0.5791641638951004
Validation loss: 2.510600614354785

Epoch: 5| Step: 3
Training loss: 1.001236984987476
Validation loss: 2.4904701286352817

Epoch: 5| Step: 4
Training loss: 0.6932669994444913
Validation loss: 2.4899623778121405

Epoch: 5| Step: 5
Training loss: 0.6482799292620125
Validation loss: 2.495046039808945

Epoch: 5| Step: 6
Training loss: 0.563741373812364
Validation loss: 2.4869660950823844

Epoch: 5| Step: 7
Training loss: 0.6326794190049468
Validation loss: 2.5057320715789944

Epoch: 5| Step: 8
Training loss: 0.6027054271063131
Validation loss: 2.522019153061479

Epoch: 5| Step: 9
Training loss: 0.8150474520483922
Validation loss: 2.480840923360779

Epoch: 5| Step: 10
Training loss: 0.8732175041571818
Validation loss: 2.517475046859281

Epoch: 387| Step: 0
Training loss: 0.6394619735450441
Validation loss: 2.5280953106843724

Epoch: 5| Step: 1
Training loss: 0.6398045473117816
Validation loss: 2.5042981444246277

Epoch: 5| Step: 2
Training loss: 0.5425256801275584
Validation loss: 2.5076177285843024

Epoch: 5| Step: 3
Training loss: 0.36477056418657744
Validation loss: 2.5006065268685536

Epoch: 5| Step: 4
Training loss: 0.5828416034703343
Validation loss: 2.516651921010745

Epoch: 5| Step: 5
Training loss: 0.8764136679327433
Validation loss: 2.494007082191216

Epoch: 5| Step: 6
Training loss: 1.10338355430294
Validation loss: 2.470179483381524

Epoch: 5| Step: 7
Training loss: 0.7635975677163745
Validation loss: 2.506958113748515

Epoch: 5| Step: 8
Training loss: 0.8895228074244548
Validation loss: 2.4921654719450537

Epoch: 5| Step: 9
Training loss: 0.8794807082614553
Validation loss: 2.5056738702427293

Epoch: 5| Step: 10
Training loss: 0.7448312753313333
Validation loss: 2.50250409037918

Epoch: 388| Step: 0
Training loss: 0.5613601314416308
Validation loss: 2.5137645588560282

Epoch: 5| Step: 1
Training loss: 0.8789759629470653
Validation loss: 2.4989833846449745

Epoch: 5| Step: 2
Training loss: 0.8218833415257205
Validation loss: 2.5161234227431635

Epoch: 5| Step: 3
Training loss: 0.7546796241491458
Validation loss: 2.510005549802333

Epoch: 5| Step: 4
Training loss: 0.9060161880895351
Validation loss: 2.4954021062491516

Epoch: 5| Step: 5
Training loss: 0.6894147824440304
Validation loss: 2.484168588622337

Epoch: 5| Step: 6
Training loss: 0.7195604979030722
Validation loss: 2.479944037104724

Epoch: 5| Step: 7
Training loss: 0.7765693833105558
Validation loss: 2.500465666563319

Epoch: 5| Step: 8
Training loss: 0.426159069872402
Validation loss: 2.489363979177732

Epoch: 5| Step: 9
Training loss: 0.739274824745426
Validation loss: 2.4653545455114667

Epoch: 5| Step: 10
Training loss: 0.7937065788467398
Validation loss: 2.446992841641677

Epoch: 389| Step: 0
Training loss: 0.8126118289576643
Validation loss: 2.461348769041347

Epoch: 5| Step: 1
Training loss: 0.666625987739053
Validation loss: 2.4623443514764087

Epoch: 5| Step: 2
Training loss: 0.912088528707342
Validation loss: 2.4520001920499825

Epoch: 5| Step: 3
Training loss: 0.3437060631502739
Validation loss: 2.458241472636249

Epoch: 5| Step: 4
Training loss: 0.7351988371656186
Validation loss: 2.50638833247121

Epoch: 5| Step: 5
Training loss: 0.48297117212305857
Validation loss: 2.4544532701149584

Epoch: 5| Step: 6
Training loss: 0.753503642523352
Validation loss: 2.4590614690750554

Epoch: 5| Step: 7
Training loss: 0.8094978622210375
Validation loss: 2.4821747540445234

Epoch: 5| Step: 8
Training loss: 0.923165404223917
Validation loss: 2.498619229470733

Epoch: 5| Step: 9
Training loss: 0.8159393727789855
Validation loss: 2.4839367450620573

Epoch: 5| Step: 10
Training loss: 0.6308444467201416
Validation loss: 2.496622962074065

Epoch: 390| Step: 0
Training loss: 0.8958177602138829
Validation loss: 2.4827521770282623

Epoch: 5| Step: 1
Training loss: 0.5045989841750327
Validation loss: 2.4885007179668643

Epoch: 5| Step: 2
Training loss: 0.6893055787672454
Validation loss: 2.4893787897431743

Epoch: 5| Step: 3
Training loss: 0.8566722330018919
Validation loss: 2.4987641879422258

Epoch: 5| Step: 4
Training loss: 0.8827787409716404
Validation loss: 2.47720030264339

Epoch: 5| Step: 5
Training loss: 0.6028342984353249
Validation loss: 2.480955428558837

Epoch: 5| Step: 6
Training loss: 0.9456997228070418
Validation loss: 2.487890105283453

Epoch: 5| Step: 7
Training loss: 0.5971983607895028
Validation loss: 2.450320924981976

Epoch: 5| Step: 8
Training loss: 0.7383254910892867
Validation loss: 2.4731495436831894

Epoch: 5| Step: 9
Training loss: 0.5392638673480421
Validation loss: 2.4966323889914563

Epoch: 5| Step: 10
Training loss: 0.6808946347585916
Validation loss: 2.461463561819804

Epoch: 391| Step: 0
Training loss: 0.8082319177999543
Validation loss: 2.450380662858434

Epoch: 5| Step: 1
Training loss: 0.9018422834736775
Validation loss: 2.4621077758252627

Epoch: 5| Step: 2
Training loss: 0.6137306607728686
Validation loss: 2.4613719957035545

Epoch: 5| Step: 3
Training loss: 0.7992783748874632
Validation loss: 2.4623571605657157

Epoch: 5| Step: 4
Training loss: 0.6781151880705869
Validation loss: 2.457675777764324

Epoch: 5| Step: 5
Training loss: 0.23512595193792907
Validation loss: 2.4391196911624133

Epoch: 5| Step: 6
Training loss: 0.7434423980615679
Validation loss: 2.4346774892325995

Epoch: 5| Step: 7
Training loss: 0.8080690681119183
Validation loss: 2.4671232378682117

Epoch: 5| Step: 8
Training loss: 0.8992889350392799
Validation loss: 2.4620810949934073

Epoch: 5| Step: 9
Training loss: 0.6122996742250161
Validation loss: 2.4502027684261787

Epoch: 5| Step: 10
Training loss: 0.6758939615972378
Validation loss: 2.455694429574283

Epoch: 392| Step: 0
Training loss: 0.5332507437098557
Validation loss: 2.499676322492711

Epoch: 5| Step: 1
Training loss: 0.5346064562664216
Validation loss: 2.5007512461015056

Epoch: 5| Step: 2
Training loss: 0.550004614463869
Validation loss: 2.503313203050739

Epoch: 5| Step: 3
Training loss: 0.754232622567877
Validation loss: 2.4991044342640003

Epoch: 5| Step: 4
Training loss: 0.5940283574582691
Validation loss: 2.5226138826926516

Epoch: 5| Step: 5
Training loss: 0.7028247192053335
Validation loss: 2.501820972683502

Epoch: 5| Step: 6
Training loss: 0.8916471872846119
Validation loss: 2.5202474792180696

Epoch: 5| Step: 7
Training loss: 0.5627145887712395
Validation loss: 2.4919378023302396

Epoch: 5| Step: 8
Training loss: 0.8463904426821129
Validation loss: 2.498878567933407

Epoch: 5| Step: 9
Training loss: 1.0630132333177604
Validation loss: 2.474683944602029

Epoch: 5| Step: 10
Training loss: 0.7921068741137843
Validation loss: 2.4520516336949854

Epoch: 393| Step: 0
Training loss: 0.5521867283382323
Validation loss: 2.4646953746576696

Epoch: 5| Step: 1
Training loss: 0.6246373316440912
Validation loss: 2.4673028933445775

Epoch: 5| Step: 2
Training loss: 0.7226981898329337
Validation loss: 2.4995987200935503

Epoch: 5| Step: 3
Training loss: 0.9383005856467936
Validation loss: 2.4863467382582662

Epoch: 5| Step: 4
Training loss: 0.8445597048331892
Validation loss: 2.499765205637641

Epoch: 5| Step: 5
Training loss: 0.5980558866872115
Validation loss: 2.497780741856835

Epoch: 5| Step: 6
Training loss: 0.4591131476085744
Validation loss: 2.4531669777703136

Epoch: 5| Step: 7
Training loss: 1.0084378571889439
Validation loss: 2.425670688170321

Epoch: 5| Step: 8
Training loss: 0.8776272092486329
Validation loss: 2.4489854317900597

Epoch: 5| Step: 9
Training loss: 0.5513314279114356
Validation loss: 2.4369648266231776

Epoch: 5| Step: 10
Training loss: 0.7315763755893605
Validation loss: 2.407978845793111

Epoch: 394| Step: 0
Training loss: 0.799131601603208
Validation loss: 2.452232328530884

Epoch: 5| Step: 1
Training loss: 0.6529684216748846
Validation loss: 2.451772540771313

Epoch: 5| Step: 2
Training loss: 0.6205689234144207
Validation loss: 2.4610402210971323

Epoch: 5| Step: 3
Training loss: 0.6724986132001227
Validation loss: 2.4583519253063364

Epoch: 5| Step: 4
Training loss: 0.9316589545600079
Validation loss: 2.4459097995479038

Epoch: 5| Step: 5
Training loss: 0.7294005473025805
Validation loss: 2.48184228342805

Epoch: 5| Step: 6
Training loss: 0.6725901191272062
Validation loss: 2.470470895666718

Epoch: 5| Step: 7
Training loss: 0.7681429582922257
Validation loss: 2.477589703822258

Epoch: 5| Step: 8
Training loss: 0.6769493239395662
Validation loss: 2.518378665818713

Epoch: 5| Step: 9
Training loss: 0.8731767186635195
Validation loss: 2.5263202120816084

Epoch: 5| Step: 10
Training loss: 0.7720441501622849
Validation loss: 2.546379580950963

Epoch: 395| Step: 0
Training loss: 0.4122005741397185
Validation loss: 2.5037428151592693

Epoch: 5| Step: 1
Training loss: 0.5579665337323324
Validation loss: 2.5197890822340994

Epoch: 5| Step: 2
Training loss: 1.024307754571713
Validation loss: 2.5099204622347995

Epoch: 5| Step: 3
Training loss: 0.5005806293421927
Validation loss: 2.496010473474887

Epoch: 5| Step: 4
Training loss: 0.8951769168576807
Validation loss: 2.47714224956372

Epoch: 5| Step: 5
Training loss: 0.8148319452003062
Validation loss: 2.4841624709697467

Epoch: 5| Step: 6
Training loss: 0.6712270761905238
Validation loss: 2.44075720644319

Epoch: 5| Step: 7
Training loss: 0.8968531031045601
Validation loss: 2.4610135312957415

Epoch: 5| Step: 8
Training loss: 0.7455514664694958
Validation loss: 2.4409820258949604

Epoch: 5| Step: 9
Training loss: 0.6809422541570992
Validation loss: 2.453349647453797

Epoch: 5| Step: 10
Training loss: 0.48141883328492663
Validation loss: 2.4116685934623394

Epoch: 396| Step: 0
Training loss: 0.4906941116153843
Validation loss: 2.428594910113538

Epoch: 5| Step: 1
Training loss: 0.46769978176305155
Validation loss: 2.460704785562188

Epoch: 5| Step: 2
Training loss: 0.8057884166577097
Validation loss: 2.468961103081179

Epoch: 5| Step: 3
Training loss: 0.8924688359971825
Validation loss: 2.4858690102216348

Epoch: 5| Step: 4
Training loss: 0.7177063372122399
Validation loss: 2.4994525320236023

Epoch: 5| Step: 5
Training loss: 0.8761903975999592
Validation loss: 2.5012909501739578

Epoch: 5| Step: 6
Training loss: 0.6310516631261431
Validation loss: 2.4879115838425854

Epoch: 5| Step: 7
Training loss: 0.8252262989975476
Validation loss: 2.514513016983059

Epoch: 5| Step: 8
Training loss: 0.5846297101688908
Validation loss: 2.5056103911233447

Epoch: 5| Step: 9
Training loss: 0.6891905416952718
Validation loss: 2.5005164792196464

Epoch: 5| Step: 10
Training loss: 0.9414904861435456
Validation loss: 2.5159574979489374

Epoch: 397| Step: 0
Training loss: 0.5618841986067651
Validation loss: 2.5344778323967025

Epoch: 5| Step: 1
Training loss: 0.7162524658347087
Validation loss: 2.5089386093375348

Epoch: 5| Step: 2
Training loss: 0.5131521169952403
Validation loss: 2.5065565772641007

Epoch: 5| Step: 3
Training loss: 0.9087176106490829
Validation loss: 2.495151737759692

Epoch: 5| Step: 4
Training loss: 0.6395605827741946
Validation loss: 2.4896703220828527

Epoch: 5| Step: 5
Training loss: 1.1138761838081104
Validation loss: 2.483709233608774

Epoch: 5| Step: 6
Training loss: 0.4155095205283556
Validation loss: 2.5020900173114544

Epoch: 5| Step: 7
Training loss: 0.9399470500033487
Validation loss: 2.493493072131199

Epoch: 5| Step: 8
Training loss: 0.5733322254805987
Validation loss: 2.5080105288042938

Epoch: 5| Step: 9
Training loss: 0.6397069074391682
Validation loss: 2.505586349814601

Epoch: 5| Step: 10
Training loss: 0.4892207757937736
Validation loss: 2.537804711781117

Epoch: 398| Step: 0
Training loss: 0.899922809999399
Validation loss: 2.5117246137529614

Epoch: 5| Step: 1
Training loss: 0.7904485482995399
Validation loss: 2.4953407226156594

Epoch: 5| Step: 2
Training loss: 0.7829733723245361
Validation loss: 2.499431650099638

Epoch: 5| Step: 3
Training loss: 0.4332748133624569
Validation loss: 2.4697348230979013

Epoch: 5| Step: 4
Training loss: 0.5415849685190339
Validation loss: 2.4939020028755294

Epoch: 5| Step: 5
Training loss: 0.7370765990069484
Validation loss: 2.513832590521284

Epoch: 5| Step: 6
Training loss: 0.9122164416320392
Validation loss: 2.4993089151398378

Epoch: 5| Step: 7
Training loss: 0.6386582026053501
Validation loss: 2.480004973298239

Epoch: 5| Step: 8
Training loss: 0.7015770721621352
Validation loss: 2.4871893825422635

Epoch: 5| Step: 9
Training loss: 0.6137620778264749
Validation loss: 2.460157835979445

Epoch: 5| Step: 10
Training loss: 0.5555067862191446
Validation loss: 2.486298605604425

Epoch: 399| Step: 0
Training loss: 0.5581574503402656
Validation loss: 2.5227314992496046

Epoch: 5| Step: 1
Training loss: 0.8721150454062002
Validation loss: 2.5143853237896976

Epoch: 5| Step: 2
Training loss: 0.601884928905632
Validation loss: 2.477524758035142

Epoch: 5| Step: 3
Training loss: 0.6041926564732225
Validation loss: 2.493172589911313

Epoch: 5| Step: 4
Training loss: 0.647778394383729
Validation loss: 2.4877042993508325

Epoch: 5| Step: 5
Training loss: 0.8105734211814457
Validation loss: 2.47549042303572

Epoch: 5| Step: 6
Training loss: 0.3412180986619175
Validation loss: 2.4669653435094316

Epoch: 5| Step: 7
Training loss: 0.5986485191388072
Validation loss: 2.4878244885999927

Epoch: 5| Step: 8
Training loss: 0.8094671572501796
Validation loss: 2.4698037509907422

Epoch: 5| Step: 9
Training loss: 0.9101501268172683
Validation loss: 2.470810632110809

Epoch: 5| Step: 10
Training loss: 0.615834890689696
Validation loss: 2.50237418926494

Epoch: 400| Step: 0
Training loss: 0.7439405517746277
Validation loss: 2.4668629855305175

Epoch: 5| Step: 1
Training loss: 0.7818195174525387
Validation loss: 2.4351895185766366

Epoch: 5| Step: 2
Training loss: 0.5474498996717455
Validation loss: 2.4090170684426226

Epoch: 5| Step: 3
Training loss: 0.6726455926881616
Validation loss: 2.443904301264301

Epoch: 5| Step: 4
Training loss: 0.36760002662847463
Validation loss: 2.437307455884195

Epoch: 5| Step: 5
Training loss: 0.7124130112265714
Validation loss: 2.4330845589835826

Epoch: 5| Step: 6
Training loss: 0.7224373150727991
Validation loss: 2.424767615572982

Epoch: 5| Step: 7
Training loss: 0.7147920099930443
Validation loss: 2.4648232218079285

Epoch: 5| Step: 8
Training loss: 0.7874885194940692
Validation loss: 2.4580829092014027

Epoch: 5| Step: 9
Training loss: 0.7309665309821279
Validation loss: 2.4721105716343015

Epoch: 5| Step: 10
Training loss: 0.6414824539246863
Validation loss: 2.466052490142205

Epoch: 401| Step: 0
Training loss: 0.6076086315311654
Validation loss: 2.4740296722817128

Epoch: 5| Step: 1
Training loss: 0.6635996158952274
Validation loss: 2.512134059703768

Epoch: 5| Step: 2
Training loss: 0.6551779209795139
Validation loss: 2.545588799890677

Epoch: 5| Step: 3
Training loss: 0.6498636396133829
Validation loss: 2.5132365152946003

Epoch: 5| Step: 4
Training loss: 0.8445318626098105
Validation loss: 2.5133881307452266

Epoch: 5| Step: 5
Training loss: 0.5717954298851493
Validation loss: 2.5111509605800357

Epoch: 5| Step: 6
Training loss: 0.4866772972321961
Validation loss: 2.5061487641365536

Epoch: 5| Step: 7
Training loss: 0.6049439647828476
Validation loss: 2.507884663480961

Epoch: 5| Step: 8
Training loss: 1.0644684116770742
Validation loss: 2.479160296076132

Epoch: 5| Step: 9
Training loss: 0.7089175358311768
Validation loss: 2.4543158840591723

Epoch: 5| Step: 10
Training loss: 0.3958003528139933
Validation loss: 2.4680324340797912

Epoch: 402| Step: 0
Training loss: 0.6353207552289541
Validation loss: 2.4477812140243156

Epoch: 5| Step: 1
Training loss: 0.717845430461605
Validation loss: 2.4643578255224527

Epoch: 5| Step: 2
Training loss: 0.6601084404060028
Validation loss: 2.4577987809972393

Epoch: 5| Step: 3
Training loss: 0.5989549277388462
Validation loss: 2.4753333648127023

Epoch: 5| Step: 4
Training loss: 0.5294935135664705
Validation loss: 2.4705023444074112

Epoch: 5| Step: 5
Training loss: 0.898863252022173
Validation loss: 2.4944272637191434

Epoch: 5| Step: 6
Training loss: 0.5539406328600138
Validation loss: 2.4972320974825437

Epoch: 5| Step: 7
Training loss: 0.777452317520545
Validation loss: 2.4502389512135796

Epoch: 5| Step: 8
Training loss: 0.8041139058279227
Validation loss: 2.4976348292105066

Epoch: 5| Step: 9
Training loss: 0.6109331457660956
Validation loss: 2.488448054878845

Epoch: 5| Step: 10
Training loss: 0.716333306945237
Validation loss: 2.5045666609126687

Epoch: 403| Step: 0
Training loss: 0.4975609147576431
Validation loss: 2.511614073837399

Epoch: 5| Step: 1
Training loss: 0.6515159608608754
Validation loss: 2.52813438110485

Epoch: 5| Step: 2
Training loss: 0.5737084437261752
Validation loss: 2.514411486827499

Epoch: 5| Step: 3
Training loss: 0.7595065736793782
Validation loss: 2.486941804988025

Epoch: 5| Step: 4
Training loss: 0.6522913700477936
Validation loss: 2.517387856772897

Epoch: 5| Step: 5
Training loss: 0.7145542329770267
Validation loss: 2.5143881776188217

Epoch: 5| Step: 6
Training loss: 0.7091093347312937
Validation loss: 2.5233102172866366

Epoch: 5| Step: 7
Training loss: 0.8800057548638218
Validation loss: 2.510971217091767

Epoch: 5| Step: 8
Training loss: 0.43348422686272464
Validation loss: 2.5294526977406337

Epoch: 5| Step: 9
Training loss: 0.8307302628433186
Validation loss: 2.5659354386715947

Epoch: 5| Step: 10
Training loss: 0.6916446598029655
Validation loss: 2.540562873331684

Epoch: 404| Step: 0
Training loss: 0.7420917650015431
Validation loss: 2.5191905340825875

Epoch: 5| Step: 1
Training loss: 0.6847049509990694
Validation loss: 2.5252458467932795

Epoch: 5| Step: 2
Training loss: 0.6798405310577169
Validation loss: 2.513583617219437

Epoch: 5| Step: 3
Training loss: 0.5746728049095735
Validation loss: 2.5405737350856286

Epoch: 5| Step: 4
Training loss: 0.8501610729527328
Validation loss: 2.533241710324229

Epoch: 5| Step: 5
Training loss: 0.5940402726816619
Validation loss: 2.5358920953071062

Epoch: 5| Step: 6
Training loss: 0.49667744577901746
Validation loss: 2.5473018610381533

Epoch: 5| Step: 7
Training loss: 0.7368105009030665
Validation loss: 2.4755317859568704

Epoch: 5| Step: 8
Training loss: 0.6278492355422226
Validation loss: 2.5204803859054454

Epoch: 5| Step: 9
Training loss: 0.7274763861163279
Validation loss: 2.5090830119814345

Epoch: 5| Step: 10
Training loss: 0.5856896957276516
Validation loss: 2.5003876518857537

Epoch: 405| Step: 0
Training loss: 0.7534233088127953
Validation loss: 2.485852831362249

Epoch: 5| Step: 1
Training loss: 0.7079013086650945
Validation loss: 2.4658039636272004

Epoch: 5| Step: 2
Training loss: 0.4016023860967848
Validation loss: 2.47308688676067

Epoch: 5| Step: 3
Training loss: 0.7118729525864039
Validation loss: 2.46139506070794

Epoch: 5| Step: 4
Training loss: 0.7600209804826267
Validation loss: 2.4385008543822297

Epoch: 5| Step: 5
Training loss: 0.6918580039537648
Validation loss: 2.4317761452585747

Epoch: 5| Step: 6
Training loss: 0.7448257536301504
Validation loss: 2.4416535619025446

Epoch: 5| Step: 7
Training loss: 0.664412417502001
Validation loss: 2.4672175165936077

Epoch: 5| Step: 8
Training loss: 0.5904383157446047
Validation loss: 2.4776915255388063

Epoch: 5| Step: 9
Training loss: 0.5636504382672277
Validation loss: 2.470513387068801

Epoch: 5| Step: 10
Training loss: 0.6138329423849141
Validation loss: 2.4576782624650977

Epoch: 406| Step: 0
Training loss: 0.7262873384919645
Validation loss: 2.497297282198483

Epoch: 5| Step: 1
Training loss: 0.7043878658375436
Validation loss: 2.514017291353318

Epoch: 5| Step: 2
Training loss: 0.5182131919762916
Validation loss: 2.4907310998999797

Epoch: 5| Step: 3
Training loss: 0.683539164952385
Validation loss: 2.494021183162729

Epoch: 5| Step: 4
Training loss: 0.6039035871084311
Validation loss: 2.4444135176923116

Epoch: 5| Step: 5
Training loss: 0.40545571146381176
Validation loss: 2.4653549203834624

Epoch: 5| Step: 6
Training loss: 0.6932015682681483
Validation loss: 2.4827663718671173

Epoch: 5| Step: 7
Training loss: 0.4608280569203308
Validation loss: 2.4552171641203464

Epoch: 5| Step: 8
Training loss: 0.6911366039274108
Validation loss: 2.496736439032078

Epoch: 5| Step: 9
Training loss: 0.7513498239318109
Validation loss: 2.4537308039421677

Epoch: 5| Step: 10
Training loss: 0.8454165424618192
Validation loss: 2.4430108333810163

Epoch: 407| Step: 0
Training loss: 0.8145835278080726
Validation loss: 2.4531261589612403

Epoch: 5| Step: 1
Training loss: 0.5736233225665127
Validation loss: 2.446221733611774

Epoch: 5| Step: 2
Training loss: 0.6871501075594655
Validation loss: 2.4469210385346933

Epoch: 5| Step: 3
Training loss: 0.5438946575363908
Validation loss: 2.438834788040183

Epoch: 5| Step: 4
Training loss: 0.5585382607382381
Validation loss: 2.4525277559169183

Epoch: 5| Step: 5
Training loss: 0.6872704512840899
Validation loss: 2.4814645409288523

Epoch: 5| Step: 6
Training loss: 0.8621558539406142
Validation loss: 2.5118905385085335

Epoch: 5| Step: 7
Training loss: 0.5926394114678145
Validation loss: 2.495563184747457

Epoch: 5| Step: 8
Training loss: 0.6053888821992145
Validation loss: 2.502691258036603

Epoch: 5| Step: 9
Training loss: 0.5751122510227006
Validation loss: 2.501874213992243

Epoch: 5| Step: 10
Training loss: 0.4562167710784526
Validation loss: 2.508551664140511

Epoch: 408| Step: 0
Training loss: 0.6462967707017803
Validation loss: 2.4719599738962974

Epoch: 5| Step: 1
Training loss: 0.7233239465828117
Validation loss: 2.4952551421731304

Epoch: 5| Step: 2
Training loss: 0.6594193764528907
Validation loss: 2.449311221576942

Epoch: 5| Step: 3
Training loss: 0.5450736213969333
Validation loss: 2.4830520640794322

Epoch: 5| Step: 4
Training loss: 0.5942159882049215
Validation loss: 2.4772478783503065

Epoch: 5| Step: 5
Training loss: 0.7855231723026354
Validation loss: 2.4649497903615254

Epoch: 5| Step: 6
Training loss: 0.9031932844594851
Validation loss: 2.480774635559859

Epoch: 5| Step: 7
Training loss: 0.5535960137054217
Validation loss: 2.468888544338763

Epoch: 5| Step: 8
Training loss: 0.31851082692241156
Validation loss: 2.497576564410254

Epoch: 5| Step: 9
Training loss: 0.44429129910781046
Validation loss: 2.479879422791099

Epoch: 5| Step: 10
Training loss: 0.669467760990703
Validation loss: 2.4607782419463375

Epoch: 409| Step: 0
Training loss: 0.6523049622842434
Validation loss: 2.488565932567425

Epoch: 5| Step: 1
Training loss: 0.8299897629324855
Validation loss: 2.4993832986320212

Epoch: 5| Step: 2
Training loss: 0.6050421165356228
Validation loss: 2.4596267384143062

Epoch: 5| Step: 3
Training loss: 0.5018388194989234
Validation loss: 2.4930011137266215

Epoch: 5| Step: 4
Training loss: 0.4707756777996058
Validation loss: 2.4645496330286853

Epoch: 5| Step: 5
Training loss: 0.6694491306007251
Validation loss: 2.445350059848018

Epoch: 5| Step: 6
Training loss: 0.709648010888756
Validation loss: 2.4487649861944165

Epoch: 5| Step: 7
Training loss: 0.5200768094463766
Validation loss: 2.463403303800643

Epoch: 5| Step: 8
Training loss: 0.5363923992143308
Validation loss: 2.4628162802023934

Epoch: 5| Step: 9
Training loss: 0.5962192488283924
Validation loss: 2.486268044427414

Epoch: 5| Step: 10
Training loss: 0.8531733684312596
Validation loss: 2.486720827782911

Epoch: 410| Step: 0
Training loss: 0.6215652499514468
Validation loss: 2.462699878131176

Epoch: 5| Step: 1
Training loss: 0.6330197548262052
Validation loss: 2.4327290965442785

Epoch: 5| Step: 2
Training loss: 0.5617399378827359
Validation loss: 2.471644201321455

Epoch: 5| Step: 3
Training loss: 0.7217058685467961
Validation loss: 2.416075803096936

Epoch: 5| Step: 4
Training loss: 0.5046363391277874
Validation loss: 2.4149317297014523

Epoch: 5| Step: 5
Training loss: 0.3695988309005726
Validation loss: 2.4600474091603646

Epoch: 5| Step: 6
Training loss: 0.5766710608191832
Validation loss: 2.4408065123579683

Epoch: 5| Step: 7
Training loss: 0.523443051209122
Validation loss: 2.4950992083736048

Epoch: 5| Step: 8
Training loss: 0.7692687850508199
Validation loss: 2.477041726913585

Epoch: 5| Step: 9
Training loss: 0.9667146589982742
Validation loss: 2.5139661631762484

Epoch: 5| Step: 10
Training loss: 0.6664508057845215
Validation loss: 2.5124319656785588

Epoch: 411| Step: 0
Training loss: 0.7010772343682422
Validation loss: 2.4986598396414954

Epoch: 5| Step: 1
Training loss: 0.5093567476337345
Validation loss: 2.520159509194678

Epoch: 5| Step: 2
Training loss: 0.5308538811338323
Validation loss: 2.507966239356161

Epoch: 5| Step: 3
Training loss: 0.4740972542392175
Validation loss: 2.4803497939637382

Epoch: 5| Step: 4
Training loss: 0.7206889412163945
Validation loss: 2.5249423017298875

Epoch: 5| Step: 5
Training loss: 0.6183694796480614
Validation loss: 2.5113929855347306

Epoch: 5| Step: 6
Training loss: 0.6815344610310442
Validation loss: 2.5023954195428715

Epoch: 5| Step: 7
Training loss: 0.6768459466350546
Validation loss: 2.454036004503907

Epoch: 5| Step: 8
Training loss: 0.6109550239410747
Validation loss: 2.4397107141557868

Epoch: 5| Step: 9
Training loss: 0.9166532790044483
Validation loss: 2.432403831340114

Epoch: 5| Step: 10
Training loss: 0.31652257688278934
Validation loss: 2.4528472985659087

Epoch: 412| Step: 0
Training loss: 0.7628865216013476
Validation loss: 2.4796803456624734

Epoch: 5| Step: 1
Training loss: 0.7302760721767715
Validation loss: 2.4447308827295364

Epoch: 5| Step: 2
Training loss: 0.6894058124853307
Validation loss: 2.456847461541064

Epoch: 5| Step: 3
Training loss: 0.45398997915022665
Validation loss: 2.4511947332039603

Epoch: 5| Step: 4
Training loss: 0.5791092561722143
Validation loss: 2.454218852371021

Epoch: 5| Step: 5
Training loss: 0.43161095219456425
Validation loss: 2.4309597740654985

Epoch: 5| Step: 6
Training loss: 0.6799659597067071
Validation loss: 2.4503867884769495

Epoch: 5| Step: 7
Training loss: 0.3081685529109224
Validation loss: 2.4307914304374316

Epoch: 5| Step: 8
Training loss: 0.7218784992744216
Validation loss: 2.4398902693115216

Epoch: 5| Step: 9
Training loss: 0.6866068456997442
Validation loss: 2.4623129578377343

Epoch: 5| Step: 10
Training loss: 0.7094397645533915
Validation loss: 2.4793555488581247

Epoch: 413| Step: 0
Training loss: 0.6349590300311629
Validation loss: 2.4662329419106217

Epoch: 5| Step: 1
Training loss: 0.6706213233043499
Validation loss: 2.4601779487644544

Epoch: 5| Step: 2
Training loss: 0.7700654707359745
Validation loss: 2.4834731736596027

Epoch: 5| Step: 3
Training loss: 0.4925405356383396
Validation loss: 2.4477353173924863

Epoch: 5| Step: 4
Training loss: 0.5897103720930961
Validation loss: 2.452674839572576

Epoch: 5| Step: 5
Training loss: 0.777251961814488
Validation loss: 2.482243416025545

Epoch: 5| Step: 6
Training loss: 0.32415488200026354
Validation loss: 2.484283249509329

Epoch: 5| Step: 7
Training loss: 0.7292217279262645
Validation loss: 2.493193117069173

Epoch: 5| Step: 8
Training loss: 0.7251766893875907
Validation loss: 2.4782898823354786

Epoch: 5| Step: 9
Training loss: 0.4277747496618845
Validation loss: 2.500844934690704

Epoch: 5| Step: 10
Training loss: 0.5930341621677594
Validation loss: 2.4624945477315516

Epoch: 414| Step: 0
Training loss: 0.5516358637445581
Validation loss: 2.460407214140368

Epoch: 5| Step: 1
Training loss: 0.3950413154470664
Validation loss: 2.4559326673904613

Epoch: 5| Step: 2
Training loss: 0.42141246164487095
Validation loss: 2.4916681635854157

Epoch: 5| Step: 3
Training loss: 0.42824753587885694
Validation loss: 2.4582655577357357

Epoch: 5| Step: 4
Training loss: 0.5705455147242402
Validation loss: 2.478878683555615

Epoch: 5| Step: 5
Training loss: 0.6415616840296042
Validation loss: 2.477600074916499

Epoch: 5| Step: 6
Training loss: 0.93291879939633
Validation loss: 2.489754533504121

Epoch: 5| Step: 7
Training loss: 0.6693382056102944
Validation loss: 2.469903232375616

Epoch: 5| Step: 8
Training loss: 0.6889821894548631
Validation loss: 2.5015082373034767

Epoch: 5| Step: 9
Training loss: 0.6768025965549495
Validation loss: 2.4978056952887235

Epoch: 5| Step: 10
Training loss: 0.6984854534507696
Validation loss: 2.4876245869910325

Epoch: 415| Step: 0
Training loss: 0.6777213587321762
Validation loss: 2.4861718205118626

Epoch: 5| Step: 1
Training loss: 0.4425444318263972
Validation loss: 2.503824267445783

Epoch: 5| Step: 2
Training loss: 0.5263920426029601
Validation loss: 2.4876481505808985

Epoch: 5| Step: 3
Training loss: 0.7248367816436322
Validation loss: 2.4813817172224724

Epoch: 5| Step: 4
Training loss: 0.4620360360592699
Validation loss: 2.4697874300435

Epoch: 5| Step: 5
Training loss: 0.46796669680952185
Validation loss: 2.465200630524171

Epoch: 5| Step: 6
Training loss: 0.5603554162750208
Validation loss: 2.4589563664454874

Epoch: 5| Step: 7
Training loss: 0.8542095305379823
Validation loss: 2.4480578303080307

Epoch: 5| Step: 8
Training loss: 0.5197068111389536
Validation loss: 2.4327804050861115

Epoch: 5| Step: 9
Training loss: 0.7617211757523474
Validation loss: 2.4281163464957904

Epoch: 5| Step: 10
Training loss: 0.568584541734737
Validation loss: 2.45703409532155

Epoch: 416| Step: 0
Training loss: 0.23086694488765658
Validation loss: 2.4292742984502005

Epoch: 5| Step: 1
Training loss: 0.7956115954664101
Validation loss: 2.440593772317508

Epoch: 5| Step: 2
Training loss: 0.7061394393938294
Validation loss: 2.433275344327354

Epoch: 5| Step: 3
Training loss: 0.4692318823593437
Validation loss: 2.4317662355178604

Epoch: 5| Step: 4
Training loss: 0.500780390650924
Validation loss: 2.457106735984816

Epoch: 5| Step: 5
Training loss: 0.7256951025351948
Validation loss: 2.4616925439604693

Epoch: 5| Step: 6
Training loss: 0.7833068094091731
Validation loss: 2.467441408804247

Epoch: 5| Step: 7
Training loss: 0.5487813420566898
Validation loss: 2.462510583872621

Epoch: 5| Step: 8
Training loss: 0.5958767497199241
Validation loss: 2.45914120814885

Epoch: 5| Step: 9
Training loss: 0.3030054539978055
Validation loss: 2.47608467539695

Epoch: 5| Step: 10
Training loss: 0.633258874075751
Validation loss: 2.4541745584260295

Epoch: 417| Step: 0
Training loss: 0.5161868992959141
Validation loss: 2.4745873375798833

Epoch: 5| Step: 1
Training loss: 0.40183453603852215
Validation loss: 2.4604209064705067

Epoch: 5| Step: 2
Training loss: 0.6028075277025533
Validation loss: 2.506849028535435

Epoch: 5| Step: 3
Training loss: 0.7352224695135356
Validation loss: 2.4384387766617137

Epoch: 5| Step: 4
Training loss: 0.5400306190534276
Validation loss: 2.47087172766661

Epoch: 5| Step: 5
Training loss: 0.7579302352213609
Validation loss: 2.464565545536793

Epoch: 5| Step: 6
Training loss: 0.18781469678625454
Validation loss: 2.460854476619468

Epoch: 5| Step: 7
Training loss: 0.6598111892966133
Validation loss: 2.41559700919617

Epoch: 5| Step: 8
Training loss: 0.6512352668281814
Validation loss: 2.424254961735317

Epoch: 5| Step: 9
Training loss: 0.6776884211810398
Validation loss: 2.4756307233931643

Epoch: 5| Step: 10
Training loss: 0.6553864473998019
Validation loss: 2.492274057034274

Epoch: 418| Step: 0
Training loss: 0.6064834705578469
Validation loss: 2.509026230978671

Epoch: 5| Step: 1
Training loss: 0.5681541308246048
Validation loss: 2.4860295318441192

Epoch: 5| Step: 2
Training loss: 0.610659931866532
Validation loss: 2.482547297443382

Epoch: 5| Step: 3
Training loss: 0.6907123165254705
Validation loss: 2.459656602403924

Epoch: 5| Step: 4
Training loss: 0.4488185592707696
Validation loss: 2.479846919616667

Epoch: 5| Step: 5
Training loss: 0.8458772968899747
Validation loss: 2.513454330539411

Epoch: 5| Step: 6
Training loss: 0.4199131277193499
Validation loss: 2.4670546486654397

Epoch: 5| Step: 7
Training loss: 0.3660193590688203
Validation loss: 2.477458359257756

Epoch: 5| Step: 8
Training loss: 0.7339702870801987
Validation loss: 2.485730133438531

Epoch: 5| Step: 9
Training loss: 0.43468326429419146
Validation loss: 2.468381201769241

Epoch: 5| Step: 10
Training loss: 0.637301733937786
Validation loss: 2.423074040829447

Epoch: 419| Step: 0
Training loss: 0.6484580898462979
Validation loss: 2.4443608077726133

Epoch: 5| Step: 1
Training loss: 0.72337915502462
Validation loss: 2.414312661726627

Epoch: 5| Step: 2
Training loss: 0.5461356751334394
Validation loss: 2.4247542452653903

Epoch: 5| Step: 3
Training loss: 0.6350044153465494
Validation loss: 2.4150585892975474

Epoch: 5| Step: 4
Training loss: 0.4218207960275265
Validation loss: 2.417842335737627

Epoch: 5| Step: 5
Training loss: 0.5722870285666479
Validation loss: 2.4468933067904164

Epoch: 5| Step: 6
Training loss: 0.6283156660700857
Validation loss: 2.4428158397138255

Epoch: 5| Step: 7
Training loss: 0.5601378487047813
Validation loss: 2.446064087308124

Epoch: 5| Step: 8
Training loss: 0.5209196082820209
Validation loss: 2.491480738913692

Epoch: 5| Step: 9
Training loss: 0.7879383275083752
Validation loss: 2.4967326429619416

Epoch: 5| Step: 10
Training loss: 0.6184182992646415
Validation loss: 2.514767389969588

Epoch: 420| Step: 0
Training loss: 0.5497125036767239
Validation loss: 2.488604762124011

Epoch: 5| Step: 1
Training loss: 0.9868480860378331
Validation loss: 2.501523191694503

Epoch: 5| Step: 2
Training loss: 0.44150047646860785
Validation loss: 2.4589273368814877

Epoch: 5| Step: 3
Training loss: 0.5876669727616027
Validation loss: 2.4416075017857777

Epoch: 5| Step: 4
Training loss: 0.43447597208299
Validation loss: 2.4483420591265124

Epoch: 5| Step: 5
Training loss: 0.6534717880294426
Validation loss: 2.4396408551219912

Epoch: 5| Step: 6
Training loss: 0.7564515940678462
Validation loss: 2.4511956185360706

Epoch: 5| Step: 7
Training loss: 0.48386915003719694
Validation loss: 2.49781891011474

Epoch: 5| Step: 8
Training loss: 0.5153468277545358
Validation loss: 2.4680181280105122

Epoch: 5| Step: 9
Training loss: 0.48086560924712485
Validation loss: 2.475834902749902

Epoch: 5| Step: 10
Training loss: 0.5208300653990903
Validation loss: 2.4845465803808193

Epoch: 421| Step: 0
Training loss: 0.7560917302495094
Validation loss: 2.489126898756945

Epoch: 5| Step: 1
Training loss: 0.5416847525536076
Validation loss: 2.481385613229757

Epoch: 5| Step: 2
Training loss: 0.6286731311609672
Validation loss: 2.4821121581442043

Epoch: 5| Step: 3
Training loss: 0.6128365915281185
Validation loss: 2.4642307115953677

Epoch: 5| Step: 4
Training loss: 0.4903274538958154
Validation loss: 2.4683163798033334

Epoch: 5| Step: 5
Training loss: 0.6643018627730953
Validation loss: 2.47847892254184

Epoch: 5| Step: 6
Training loss: 0.8067632032460054
Validation loss: 2.5027793263065345

Epoch: 5| Step: 7
Training loss: 0.45882469808609816
Validation loss: 2.478008346771726

Epoch: 5| Step: 8
Training loss: 0.5192338479458862
Validation loss: 2.4773805084540226

Epoch: 5| Step: 9
Training loss: 0.3165501043824461
Validation loss: 2.4623440443406364

Epoch: 5| Step: 10
Training loss: 0.3305441709447049
Validation loss: 2.474976002177113

Epoch: 422| Step: 0
Training loss: 0.3908226657474403
Validation loss: 2.4593170711662706

Epoch: 5| Step: 1
Training loss: 0.6572625885792074
Validation loss: 2.488006239180874

Epoch: 5| Step: 2
Training loss: 0.6312897339203519
Validation loss: 2.4571692020450957

Epoch: 5| Step: 3
Training loss: 0.6228297701372943
Validation loss: 2.4552079671379614

Epoch: 5| Step: 4
Training loss: 0.5647410677996735
Validation loss: 2.467593026700231

Epoch: 5| Step: 5
Training loss: 0.5167553966482182
Validation loss: 2.4556659742596425

Epoch: 5| Step: 6
Training loss: 0.6213090151689171
Validation loss: 2.4786925765216523

Epoch: 5| Step: 7
Training loss: 0.47450558190735553
Validation loss: 2.419158727019274

Epoch: 5| Step: 8
Training loss: 0.6658623482641025
Validation loss: 2.5024371778050756

Epoch: 5| Step: 9
Training loss: 0.6174458795838611
Validation loss: 2.472166060148938

Epoch: 5| Step: 10
Training loss: 0.5883413215757695
Validation loss: 2.477901176774014

Epoch: 423| Step: 0
Training loss: 0.5890174534823401
Validation loss: 2.487959930531052

Epoch: 5| Step: 1
Training loss: 0.6006176947904633
Validation loss: 2.448752592822732

Epoch: 5| Step: 2
Training loss: 0.7387825207724953
Validation loss: 2.464921711264594

Epoch: 5| Step: 3
Training loss: 0.4254675943538957
Validation loss: 2.4811709822592127

Epoch: 5| Step: 4
Training loss: 0.6466848978646679
Validation loss: 2.4647493804760483

Epoch: 5| Step: 5
Training loss: 0.45565356762863524
Validation loss: 2.462901413979712

Epoch: 5| Step: 6
Training loss: 0.38230408753148926
Validation loss: 2.447934288916237

Epoch: 5| Step: 7
Training loss: 0.6255887596312056
Validation loss: 2.4592036584967834

Epoch: 5| Step: 8
Training loss: 0.5970800277323859
Validation loss: 2.4422783351913484

Epoch: 5| Step: 9
Training loss: 0.5408310833675016
Validation loss: 2.4498628446934765

Epoch: 5| Step: 10
Training loss: 0.5555886752137521
Validation loss: 2.447521414665761

Epoch: 424| Step: 0
Training loss: 0.5447992986821606
Validation loss: 2.463204522316862

Epoch: 5| Step: 1
Training loss: 0.5759921035920729
Validation loss: 2.4455338831664166

Epoch: 5| Step: 2
Training loss: 0.33985403198823816
Validation loss: 2.423260068114141

Epoch: 5| Step: 3
Training loss: 0.5306022004260532
Validation loss: 2.450435587819028

Epoch: 5| Step: 4
Training loss: 0.5425616597587759
Validation loss: 2.4331294049173446

Epoch: 5| Step: 5
Training loss: 0.5252281136162948
Validation loss: 2.4499958313702863

Epoch: 5| Step: 6
Training loss: 0.6786545983951499
Validation loss: 2.4446575964319894

Epoch: 5| Step: 7
Training loss: 0.6333217926186913
Validation loss: 2.4555122000300282

Epoch: 5| Step: 8
Training loss: 0.6752859737229788
Validation loss: 2.4842404647519807

Epoch: 5| Step: 9
Training loss: 0.35761655914734786
Validation loss: 2.4950402046732556

Epoch: 5| Step: 10
Training loss: 0.6872777362817444
Validation loss: 2.481779232892631

Epoch: 425| Step: 0
Training loss: 0.5528707167623165
Validation loss: 2.4750263137305226

Epoch: 5| Step: 1
Training loss: 0.6962432204212652
Validation loss: 2.4874286826279186

Epoch: 5| Step: 2
Training loss: 0.6823641372126299
Validation loss: 2.4477240269112026

Epoch: 5| Step: 3
Training loss: 0.4073744397880867
Validation loss: 2.4662759247184156

Epoch: 5| Step: 4
Training loss: 0.610030213256599
Validation loss: 2.4680943478387567

Epoch: 5| Step: 5
Training loss: 0.5854656608506154
Validation loss: 2.490538401341151

Epoch: 5| Step: 6
Training loss: 0.6291562643728045
Validation loss: 2.4867247607862386

Epoch: 5| Step: 7
Training loss: 0.4967628532382495
Validation loss: 2.490335851632941

Epoch: 5| Step: 8
Training loss: 0.472311729786906
Validation loss: 2.5044805420286385

Epoch: 5| Step: 9
Training loss: 0.555575291627427
Validation loss: 2.478921332301361

Epoch: 5| Step: 10
Training loss: 0.3583340288125911
Validation loss: 2.488292418272125

Epoch: 426| Step: 0
Training loss: 0.5932247699801246
Validation loss: 2.464852142410704

Epoch: 5| Step: 1
Training loss: 0.45387263936863215
Validation loss: 2.4903412221932073

Epoch: 5| Step: 2
Training loss: 0.38430239294053076
Validation loss: 2.4708669954192803

Epoch: 5| Step: 3
Training loss: 0.39305744042448215
Validation loss: 2.4873714114290197

Epoch: 5| Step: 4
Training loss: 0.5855803609260211
Validation loss: 2.486167161727161

Epoch: 5| Step: 5
Training loss: 0.6617926681289376
Validation loss: 2.47432432894609

Epoch: 5| Step: 6
Training loss: 0.5027845747396344
Validation loss: 2.4727295607734248

Epoch: 5| Step: 7
Training loss: 0.7037439588961643
Validation loss: 2.4668177068569217

Epoch: 5| Step: 8
Training loss: 0.48734529436899615
Validation loss: 2.5015607627727396

Epoch: 5| Step: 9
Training loss: 0.7437977238578465
Validation loss: 2.49148905394703

Epoch: 5| Step: 10
Training loss: 0.3430868492909168
Validation loss: 2.4663841757057643

Epoch: 427| Step: 0
Training loss: 0.49938127859892795
Validation loss: 2.4429120996530647

Epoch: 5| Step: 1
Training loss: 0.5413233849109679
Validation loss: 2.477042156422204

Epoch: 5| Step: 2
Training loss: 0.6522873951217608
Validation loss: 2.465589556192399

Epoch: 5| Step: 3
Training loss: 0.5220240397270786
Validation loss: 2.448565971715326

Epoch: 5| Step: 4
Training loss: 0.3972695754613415
Validation loss: 2.44602193576026

Epoch: 5| Step: 5
Training loss: 0.7332806651391283
Validation loss: 2.455136366700165

Epoch: 5| Step: 6
Training loss: 0.5194933310990296
Validation loss: 2.4564864714165506

Epoch: 5| Step: 7
Training loss: 0.6005747724286123
Validation loss: 2.449917999964661

Epoch: 5| Step: 8
Training loss: 0.6070995886395211
Validation loss: 2.4355639443215193

Epoch: 5| Step: 9
Training loss: 0.45907220203074867
Validation loss: 2.461402855578598

Epoch: 5| Step: 10
Training loss: 0.2813987073888284
Validation loss: 2.431599549735127

Epoch: 428| Step: 0
Training loss: 0.5287023210334229
Validation loss: 2.4703674122049804

Epoch: 5| Step: 1
Training loss: 0.47702070002755226
Validation loss: 2.4789664312668096

Epoch: 5| Step: 2
Training loss: 0.4274672453584926
Validation loss: 2.489499868204726

Epoch: 5| Step: 3
Training loss: 0.5639706830139396
Validation loss: 2.487752341946736

Epoch: 5| Step: 4
Training loss: 0.5628123475815368
Validation loss: 2.480224411305174

Epoch: 5| Step: 5
Training loss: 0.46383348844491107
Validation loss: 2.454825131498819

Epoch: 5| Step: 6
Training loss: 0.7055522138494752
Validation loss: 2.477945584582526

Epoch: 5| Step: 7
Training loss: 0.3701644706215799
Validation loss: 2.466892310378271

Epoch: 5| Step: 8
Training loss: 0.6920262590246867
Validation loss: 2.4407961981425217

Epoch: 5| Step: 9
Training loss: 0.5589064943026723
Validation loss: 2.4411209363694826

Epoch: 5| Step: 10
Training loss: 0.44225336332427756
Validation loss: 2.4715177691769257

Epoch: 429| Step: 0
Training loss: 0.49923289581936453
Validation loss: 2.465235800768226

Epoch: 5| Step: 1
Training loss: 0.5881796598421648
Validation loss: 2.465917571757114

Epoch: 5| Step: 2
Training loss: 0.775495469238111
Validation loss: 2.461760884752355

Epoch: 5| Step: 3
Training loss: 0.5678983043865665
Validation loss: 2.477178546998505

Epoch: 5| Step: 4
Training loss: 0.5093584151581202
Validation loss: 2.467714303505586

Epoch: 5| Step: 5
Training loss: 0.709305703563769
Validation loss: 2.4650905752003722

Epoch: 5| Step: 6
Training loss: 0.42430913675312343
Validation loss: 2.4920252548095796

Epoch: 5| Step: 7
Training loss: 0.38624146418105504
Validation loss: 2.4955606011384446

Epoch: 5| Step: 8
Training loss: 0.608899713666651
Validation loss: 2.4984218374334954

Epoch: 5| Step: 9
Training loss: 0.277574590869311
Validation loss: 2.461437474963084

Epoch: 5| Step: 10
Training loss: 0.31815488367674377
Validation loss: 2.4561065982135943

Epoch: 430| Step: 0
Training loss: 0.6074272965069674
Validation loss: 2.4927561697460914

Epoch: 5| Step: 1
Training loss: 0.35728989963076
Validation loss: 2.4796520115520746

Epoch: 5| Step: 2
Training loss: 0.6152364579422825
Validation loss: 2.476353171787918

Epoch: 5| Step: 3
Training loss: 0.3381491978178503
Validation loss: 2.4810138331182117

Epoch: 5| Step: 4
Training loss: 0.7839101515808399
Validation loss: 2.466511417709319

Epoch: 5| Step: 5
Training loss: 0.3047506071417928
Validation loss: 2.440937724910444

Epoch: 5| Step: 6
Training loss: 0.5503341537539171
Validation loss: 2.4684860090422274

Epoch: 5| Step: 7
Training loss: 0.7748006502762224
Validation loss: 2.459042469969904

Epoch: 5| Step: 8
Training loss: 0.3195993462823537
Validation loss: 2.468923585728118

Epoch: 5| Step: 9
Training loss: 0.4195674021113586
Validation loss: 2.4878461552704216

Epoch: 5| Step: 10
Training loss: 0.4776933104987589
Validation loss: 2.4831297742364327

Epoch: 431| Step: 0
Training loss: 0.4497568639260101
Validation loss: 2.4826686373065474

Epoch: 5| Step: 1
Training loss: 0.5149725340491146
Validation loss: 2.4681640418717508

Epoch: 5| Step: 2
Training loss: 0.4161435499196275
Validation loss: 2.446298273626064

Epoch: 5| Step: 3
Training loss: 0.44599507538253425
Validation loss: 2.5022124437322875

Epoch: 5| Step: 4
Training loss: 0.358716257316143
Validation loss: 2.4762757013861867

Epoch: 5| Step: 5
Training loss: 0.699570040126856
Validation loss: 2.4956778727200293

Epoch: 5| Step: 6
Training loss: 0.5479248868183016
Validation loss: 2.474796204490494

Epoch: 5| Step: 7
Training loss: 0.5665033980618653
Validation loss: 2.448395169700373

Epoch: 5| Step: 8
Training loss: 0.3204079229991486
Validation loss: 2.43687826809128

Epoch: 5| Step: 9
Training loss: 0.6204201506403071
Validation loss: 2.446671081074709

Epoch: 5| Step: 10
Training loss: 0.6213829758630448
Validation loss: 2.46832032655291

Epoch: 432| Step: 0
Training loss: 0.4426367832781841
Validation loss: 2.4545573467017516

Epoch: 5| Step: 1
Training loss: 0.40653570838985953
Validation loss: 2.456517464674681

Epoch: 5| Step: 2
Training loss: 0.6869633487464266
Validation loss: 2.4652482714214314

Epoch: 5| Step: 3
Training loss: 0.649380882390744
Validation loss: 2.5072666857564436

Epoch: 5| Step: 4
Training loss: 0.36311317985980807
Validation loss: 2.4331964323084905

Epoch: 5| Step: 5
Training loss: 0.3173511430638933
Validation loss: 2.466737293567051

Epoch: 5| Step: 6
Training loss: 0.28171950464470236
Validation loss: 2.4669861147105494

Epoch: 5| Step: 7
Training loss: 0.6402873102895801
Validation loss: 2.459315732698974

Epoch: 5| Step: 8
Training loss: 0.5098498044719809
Validation loss: 2.495238028609158

Epoch: 5| Step: 9
Training loss: 0.4527907947737712
Validation loss: 2.502760939740065

Epoch: 5| Step: 10
Training loss: 0.7491995990998539
Validation loss: 2.486693464629252

Epoch: 433| Step: 0
Training loss: 0.5383035043398625
Validation loss: 2.475715138995214

Epoch: 5| Step: 1
Training loss: 0.49617440776992383
Validation loss: 2.482946956341359

Epoch: 5| Step: 2
Training loss: 0.5831712145548528
Validation loss: 2.4578589008877323

Epoch: 5| Step: 3
Training loss: 0.301745034845426
Validation loss: 2.461836404827597

Epoch: 5| Step: 4
Training loss: 0.5063272323094336
Validation loss: 2.422756634522755

Epoch: 5| Step: 5
Training loss: 0.32313057392927885
Validation loss: 2.484377885206563

Epoch: 5| Step: 6
Training loss: 0.7378179317469925
Validation loss: 2.458138223674259

Epoch: 5| Step: 7
Training loss: 0.5914688712141246
Validation loss: 2.441934406076922

Epoch: 5| Step: 8
Training loss: 0.4526246366565239
Validation loss: 2.4058205496069327

Epoch: 5| Step: 9
Training loss: 0.4815025991902456
Validation loss: 2.4326807102564

Epoch: 5| Step: 10
Training loss: 0.5003891860738727
Validation loss: 2.4532036095637815

Epoch: 434| Step: 0
Training loss: 0.31342075124396795
Validation loss: 2.4592738228762716

Epoch: 5| Step: 1
Training loss: 0.38123756607291737
Validation loss: 2.4740806154730457

Epoch: 5| Step: 2
Training loss: 0.7616964092401879
Validation loss: 2.4899742154962774

Epoch: 5| Step: 3
Training loss: 0.5209149169603636
Validation loss: 2.507379778141102

Epoch: 5| Step: 4
Training loss: 0.4870529900827469
Validation loss: 2.473509872194775

Epoch: 5| Step: 5
Training loss: 0.5689085833620301
Validation loss: 2.5303013405213757

Epoch: 5| Step: 6
Training loss: 0.4172058630055862
Validation loss: 2.4913656910298916

Epoch: 5| Step: 7
Training loss: 0.6003180674066882
Validation loss: 2.4850413442101296

Epoch: 5| Step: 8
Training loss: 0.5153494589965149
Validation loss: 2.4671328486836304

Epoch: 5| Step: 9
Training loss: 0.40974081889835373
Validation loss: 2.4816955132140057

Epoch: 5| Step: 10
Training loss: 0.6105240234862674
Validation loss: 2.448973450411857

Epoch: 435| Step: 0
Training loss: 0.5532670436738488
Validation loss: 2.4473545920656834

Epoch: 5| Step: 1
Training loss: 0.6442158707714667
Validation loss: 2.4490064125385254

Epoch: 5| Step: 2
Training loss: 0.6289699830169048
Validation loss: 2.4146893070471607

Epoch: 5| Step: 3
Training loss: 0.6784814021078325
Validation loss: 2.464333237684642

Epoch: 5| Step: 4
Training loss: 0.5435865167419999
Validation loss: 2.4653752465752454

Epoch: 5| Step: 5
Training loss: 0.5524468095126428
Validation loss: 2.467890775149567

Epoch: 5| Step: 6
Training loss: 0.15000215121554525
Validation loss: 2.5143330040346448

Epoch: 5| Step: 7
Training loss: 0.4249424678064934
Validation loss: 2.5157727958784943

Epoch: 5| Step: 8
Training loss: 0.40975278356047695
Validation loss: 2.5224392043081396

Epoch: 5| Step: 9
Training loss: 0.3899111901548377
Validation loss: 2.486586384400892

Epoch: 5| Step: 10
Training loss: 0.48939209273633927
Validation loss: 2.4804669619912225

Epoch: 436| Step: 0
Training loss: 0.514513609740456
Validation loss: 2.4405490598675583

Epoch: 5| Step: 1
Training loss: 0.7156054081796139
Validation loss: 2.4610323042414866

Epoch: 5| Step: 2
Training loss: 0.560104195318871
Validation loss: 2.4358491189751565

Epoch: 5| Step: 3
Training loss: 0.5257593442256092
Validation loss: 2.429942168045519

Epoch: 5| Step: 4
Training loss: 0.40251548583290137
Validation loss: 2.429796651991894

Epoch: 5| Step: 5
Training loss: 0.32826206205668645
Validation loss: 2.449042645975176

Epoch: 5| Step: 6
Training loss: 0.4822925749564904
Validation loss: 2.4596174302393465

Epoch: 5| Step: 7
Training loss: 0.5056608834282762
Validation loss: 2.481706949750006

Epoch: 5| Step: 8
Training loss: 0.5061721423996686
Validation loss: 2.4563147229818605

Epoch: 5| Step: 9
Training loss: 0.5778892139367563
Validation loss: 2.4754162117221035

Epoch: 5| Step: 10
Training loss: 0.5879013719558605
Validation loss: 2.487940136107551

Epoch: 437| Step: 0
Training loss: 0.3956309562463743
Validation loss: 2.433048291255097

Epoch: 5| Step: 1
Training loss: 0.5876502626089202
Validation loss: 2.4487493782620775

Epoch: 5| Step: 2
Training loss: 0.5115195898702957
Validation loss: 2.467674019855032

Epoch: 5| Step: 3
Training loss: 0.6297813629542491
Validation loss: 2.488909525457333

Epoch: 5| Step: 4
Training loss: 0.5275267671962154
Validation loss: 2.408503867866551

Epoch: 5| Step: 5
Training loss: 0.2834205713442427
Validation loss: 2.4779274870714847

Epoch: 5| Step: 6
Training loss: 0.3028935290953292
Validation loss: 2.4388567874438802

Epoch: 5| Step: 7
Training loss: 0.5029233469146731
Validation loss: 2.462247118185646

Epoch: 5| Step: 8
Training loss: 0.7196598099662704
Validation loss: 2.4775054390123463

Epoch: 5| Step: 9
Training loss: 0.46140666296372373
Validation loss: 2.4804827935755718

Epoch: 5| Step: 10
Training loss: 0.3314089384783768
Validation loss: 2.4439482912131574

Epoch: 438| Step: 0
Training loss: 0.5935584311384492
Validation loss: 2.471061907536021

Epoch: 5| Step: 1
Training loss: 0.16961287761499727
Validation loss: 2.4677686629515834

Epoch: 5| Step: 2
Training loss: 0.6397694946350914
Validation loss: 2.4495310994316983

Epoch: 5| Step: 3
Training loss: 0.41034871989613286
Validation loss: 2.421722265449549

Epoch: 5| Step: 4
Training loss: 0.31440257027393803
Validation loss: 2.427228380798576

Epoch: 5| Step: 5
Training loss: 0.6572151806598261
Validation loss: 2.4108175803466674

Epoch: 5| Step: 6
Training loss: 0.3404701642186072
Validation loss: 2.417930683703958

Epoch: 5| Step: 7
Training loss: 0.6039594481257133
Validation loss: 2.424312254092489

Epoch: 5| Step: 8
Training loss: 0.5935523808526436
Validation loss: 2.42330416437031

Epoch: 5| Step: 9
Training loss: 0.5170745126902787
Validation loss: 2.382378115599809

Epoch: 5| Step: 10
Training loss: 0.37161866256873743
Validation loss: 2.396960820237159

Epoch: 439| Step: 0
Training loss: 0.40898178522406753
Validation loss: 2.406738321194735

Epoch: 5| Step: 1
Training loss: 0.3200333122892472
Validation loss: 2.438232372851886

Epoch: 5| Step: 2
Training loss: 0.4951392475457993
Validation loss: 2.4401363927025774

Epoch: 5| Step: 3
Training loss: 0.4896600710472458
Validation loss: 2.4575778668711226

Epoch: 5| Step: 4
Training loss: 0.3255770622009427
Validation loss: 2.4836530069075287

Epoch: 5| Step: 5
Training loss: 0.5390259827117575
Validation loss: 2.451026306680179

Epoch: 5| Step: 6
Training loss: 0.6952201910572838
Validation loss: 2.4816448089845378

Epoch: 5| Step: 7
Training loss: 0.43650758104306425
Validation loss: 2.5050623593694294

Epoch: 5| Step: 8
Training loss: 0.6245410664741078
Validation loss: 2.462010510283166

Epoch: 5| Step: 9
Training loss: 0.6241774391378762
Validation loss: 2.482943908918232

Epoch: 5| Step: 10
Training loss: 0.2594627392833136
Validation loss: 2.4462402302197113

Epoch: 440| Step: 0
Training loss: 0.3894107256032816
Validation loss: 2.456006116714415

Epoch: 5| Step: 1
Training loss: 0.2780484126220787
Validation loss: 2.468903361954638

Epoch: 5| Step: 2
Training loss: 0.4058738213942896
Validation loss: 2.4575543581626214

Epoch: 5| Step: 3
Training loss: 0.570404384997247
Validation loss: 2.462240564474064

Epoch: 5| Step: 4
Training loss: 0.5734620850409445
Validation loss: 2.4447890521511675

Epoch: 5| Step: 5
Training loss: 0.507272580027287
Validation loss: 2.4712996955590487

Epoch: 5| Step: 6
Training loss: 0.3702911531758081
Validation loss: 2.4407673884803125

Epoch: 5| Step: 7
Training loss: 0.6004333054034787
Validation loss: 2.4584941599362997

Epoch: 5| Step: 8
Training loss: 0.433606568567997
Validation loss: 2.462956586927726

Epoch: 5| Step: 9
Training loss: 0.5697413942474656
Validation loss: 2.466907678296632

Epoch: 5| Step: 10
Training loss: 0.5711196256899432
Validation loss: 2.4813902525802276

Epoch: 441| Step: 0
Training loss: 0.43364802871369523
Validation loss: 2.4527303371546423

Epoch: 5| Step: 1
Training loss: 0.690428824201635
Validation loss: 2.481436995838095

Epoch: 5| Step: 2
Training loss: 0.34544405955503177
Validation loss: 2.490916390849283

Epoch: 5| Step: 3
Training loss: 0.2891538192224692
Validation loss: 2.458421974259543

Epoch: 5| Step: 4
Training loss: 0.49089845763135337
Validation loss: 2.486865888087159

Epoch: 5| Step: 5
Training loss: 0.33155842943056785
Validation loss: 2.4560188356893575

Epoch: 5| Step: 6
Training loss: 0.6602314787667888
Validation loss: 2.511523620071558

Epoch: 5| Step: 7
Training loss: 0.37083614844778845
Validation loss: 2.4726665241107257

Epoch: 5| Step: 8
Training loss: 0.47478357893463535
Validation loss: 2.4766663389523567

Epoch: 5| Step: 9
Training loss: 0.5246932211967844
Validation loss: 2.449231465493705

Epoch: 5| Step: 10
Training loss: 0.559374523695418
Validation loss: 2.4959422117875762

Epoch: 442| Step: 0
Training loss: 0.6614137218980607
Validation loss: 2.4807604096895726

Epoch: 5| Step: 1
Training loss: 0.46010073989215033
Validation loss: 2.487066584084083

Epoch: 5| Step: 2
Training loss: 0.5602797293667123
Validation loss: 2.4793247387249497

Epoch: 5| Step: 3
Training loss: 0.27707536902251223
Validation loss: 2.445386952363628

Epoch: 5| Step: 4
Training loss: 0.3880972520304867
Validation loss: 2.477055453558223

Epoch: 5| Step: 5
Training loss: 0.48774152299249407
Validation loss: 2.4666208530753932

Epoch: 5| Step: 6
Training loss: 0.6014207945541893
Validation loss: 2.446754332689948

Epoch: 5| Step: 7
Training loss: 0.3821319837321971
Validation loss: 2.4299120807631023

Epoch: 5| Step: 8
Training loss: 0.41558249406798037
Validation loss: 2.44397808716613

Epoch: 5| Step: 9
Training loss: 0.46379067844060196
Validation loss: 2.423933004644809

Epoch: 5| Step: 10
Training loss: 0.4555244549144182
Validation loss: 2.429026204254867

Epoch: 443| Step: 0
Training loss: 0.3817790542730492
Validation loss: 2.4469081863577045

Epoch: 5| Step: 1
Training loss: 0.41082393251822535
Validation loss: 2.4505844321549293

Epoch: 5| Step: 2
Training loss: 0.6192923759989036
Validation loss: 2.4534456393464987

Epoch: 5| Step: 3
Training loss: 0.2771882171793608
Validation loss: 2.45961516012538

Epoch: 5| Step: 4
Training loss: 0.4725763868217015
Validation loss: 2.5016854265387134

Epoch: 5| Step: 5
Training loss: 0.5477476514437742
Validation loss: 2.4724655716772275

Epoch: 5| Step: 6
Training loss: 0.684377058017371
Validation loss: 2.475537132712013

Epoch: 5| Step: 7
Training loss: 0.44804121843673483
Validation loss: 2.457590552676005

Epoch: 5| Step: 8
Training loss: 0.48469363776230745
Validation loss: 2.45326846928333

Epoch: 5| Step: 9
Training loss: 0.3817390260374426
Validation loss: 2.477357964817645

Epoch: 5| Step: 10
Training loss: 0.30218478121712994
Validation loss: 2.447806713294058

Epoch: 444| Step: 0
Training loss: 0.339110009868523
Validation loss: 2.4496184991686536

Epoch: 5| Step: 1
Training loss: 0.5066903847969535
Validation loss: 2.4344226583803503

Epoch: 5| Step: 2
Training loss: 0.5143681437891768
Validation loss: 2.4401398134982686

Epoch: 5| Step: 3
Training loss: 0.43582828479903823
Validation loss: 2.435431220656247

Epoch: 5| Step: 4
Training loss: 0.4681031850766356
Validation loss: 2.4359833663807504

Epoch: 5| Step: 5
Training loss: 0.34173810181070974
Validation loss: 2.4335366503457414

Epoch: 5| Step: 6
Training loss: 0.6838822981971938
Validation loss: 2.420767904146516

Epoch: 5| Step: 7
Training loss: 0.6334783794760205
Validation loss: 2.4303120999698646

Epoch: 5| Step: 8
Training loss: 0.11636408563854689
Validation loss: 2.390921954760268

Epoch: 5| Step: 9
Training loss: 0.3984902664848152
Validation loss: 2.4005346161662686

Epoch: 5| Step: 10
Training loss: 0.47872572976786404
Validation loss: 2.4179328455777265

Epoch: 445| Step: 0
Training loss: 0.4280123743481027
Validation loss: 2.3963870567407586

Epoch: 5| Step: 1
Training loss: 0.7094031744247922
Validation loss: 2.4059997362394077

Epoch: 5| Step: 2
Training loss: 0.4961011540618819
Validation loss: 2.416876923435465

Epoch: 5| Step: 3
Training loss: 0.18046077941863825
Validation loss: 2.459450292969021

Epoch: 5| Step: 4
Training loss: 0.3374226587475884
Validation loss: 2.4663896576683144

Epoch: 5| Step: 5
Training loss: 0.5104100038781259
Validation loss: 2.4642725912132075

Epoch: 5| Step: 6
Training loss: 0.4169127413180932
Validation loss: 2.512279699135534

Epoch: 5| Step: 7
Training loss: 0.5253897741374673
Validation loss: 2.484136977492441

Epoch: 5| Step: 8
Training loss: 0.44837816623434423
Validation loss: 2.498074650518848

Epoch: 5| Step: 9
Training loss: 0.37515200077495964
Validation loss: 2.4880232314426642

Epoch: 5| Step: 10
Training loss: 0.5175326921207856
Validation loss: 2.481989052193251

Epoch: 446| Step: 0
Training loss: 0.4293561004243931
Validation loss: 2.486224662769494

Epoch: 5| Step: 1
Training loss: 0.3573445721188568
Validation loss: 2.4703071795458396

Epoch: 5| Step: 2
Training loss: 0.5080565526358195
Validation loss: 2.440465223129021

Epoch: 5| Step: 3
Training loss: 0.4878766634358327
Validation loss: 2.4200751657079107

Epoch: 5| Step: 4
Training loss: 0.5590115298667019
Validation loss: 2.432943391495103

Epoch: 5| Step: 5
Training loss: 0.26513892466152594
Validation loss: 2.400417689282967

Epoch: 5| Step: 6
Training loss: 0.6555745190658699
Validation loss: 2.404515129367328

Epoch: 5| Step: 7
Training loss: 0.42634480479226744
Validation loss: 2.4365447512458136

Epoch: 5| Step: 8
Training loss: 0.5160637924734394
Validation loss: 2.421172554541556

Epoch: 5| Step: 9
Training loss: 0.4590154596719231
Validation loss: 2.417090584218876

Epoch: 5| Step: 10
Training loss: 0.36766921565664296
Validation loss: 2.4708718438716484

Epoch: 447| Step: 0
Training loss: 0.38136822868469955
Validation loss: 2.49585930409162

Epoch: 5| Step: 1
Training loss: 0.5103123973559004
Validation loss: 2.5049513381706023

Epoch: 5| Step: 2
Training loss: 0.46584943764282
Validation loss: 2.513997403311476

Epoch: 5| Step: 3
Training loss: 0.5782347136858911
Validation loss: 2.504665564029523

Epoch: 5| Step: 4
Training loss: 0.6188376855852138
Validation loss: 2.5155252548862634

Epoch: 5| Step: 5
Training loss: 0.3395165808818401
Validation loss: 2.500015987837337

Epoch: 5| Step: 6
Training loss: 0.43860204723461355
Validation loss: 2.525185875928239

Epoch: 5| Step: 7
Training loss: 0.4813812244154511
Validation loss: 2.4944278623818152

Epoch: 5| Step: 8
Training loss: 0.3891654786017592
Validation loss: 2.4852520362103636

Epoch: 5| Step: 9
Training loss: 0.2647007542098628
Validation loss: 2.4783453019992714

Epoch: 5| Step: 10
Training loss: 0.4492703615476963
Validation loss: 2.498122396185983

Epoch: 448| Step: 0
Training loss: 0.24856621149144295
Validation loss: 2.462269553934741

Epoch: 5| Step: 1
Training loss: 0.5028229831719405
Validation loss: 2.459928065883234

Epoch: 5| Step: 2
Training loss: 0.5024635895780146
Validation loss: 2.466703318748937

Epoch: 5| Step: 3
Training loss: 0.5998929623654738
Validation loss: 2.4713240911592105

Epoch: 5| Step: 4
Training loss: 0.4350887848967292
Validation loss: 2.448425534012692

Epoch: 5| Step: 5
Training loss: 0.6225970327440793
Validation loss: 2.4696172953793707

Epoch: 5| Step: 6
Training loss: 0.23221219646398905
Validation loss: 2.4677212265425057

Epoch: 5| Step: 7
Training loss: 0.41232643015900344
Validation loss: 2.4687659869410443

Epoch: 5| Step: 8
Training loss: 0.49270021890271887
Validation loss: 2.4670107052047845

Epoch: 5| Step: 9
Training loss: 0.4262730094706587
Validation loss: 2.471286563516388

Epoch: 5| Step: 10
Training loss: 0.2435458606139135
Validation loss: 2.446988767250219

Epoch: 449| Step: 0
Training loss: 0.20363009449725297
Validation loss: 2.4526595089490018

Epoch: 5| Step: 1
Training loss: 0.525163622744516
Validation loss: 2.509006049974103

Epoch: 5| Step: 2
Training loss: 0.6207582779346602
Validation loss: 2.4538807710283885

Epoch: 5| Step: 3
Training loss: 0.497045565065937
Validation loss: 2.479494306037596

Epoch: 5| Step: 4
Training loss: 0.4433444016402676
Validation loss: 2.4617609180766715

Epoch: 5| Step: 5
Training loss: 0.4270739748169782
Validation loss: 2.485750007340728

Epoch: 5| Step: 6
Training loss: 0.1851749607885182
Validation loss: 2.4346655474785566

Epoch: 5| Step: 7
Training loss: 0.4773436538521378
Validation loss: 2.468084941239751

Epoch: 5| Step: 8
Training loss: 0.5255991298645836
Validation loss: 2.4813885985114967

Epoch: 5| Step: 9
Training loss: 0.5199884396423434
Validation loss: 2.484855551204052

Epoch: 5| Step: 10
Training loss: 0.3783215602997943
Validation loss: 2.4598411814861194

Epoch: 450| Step: 0
Training loss: 0.5368031686639572
Validation loss: 2.439128043855117

Epoch: 5| Step: 1
Training loss: 0.4071804724941007
Validation loss: 2.4542940979107795

Epoch: 5| Step: 2
Training loss: 0.5042610693526539
Validation loss: 2.471895227629123

Epoch: 5| Step: 3
Training loss: 0.4874920685440809
Validation loss: 2.439573316480936

Epoch: 5| Step: 4
Training loss: 0.38173342448199715
Validation loss: 2.4208688552021225

Epoch: 5| Step: 5
Training loss: 0.5671757436747696
Validation loss: 2.494150442122289

Epoch: 5| Step: 6
Training loss: 0.36578030507496473
Validation loss: 2.465626329386053

Epoch: 5| Step: 7
Training loss: 0.4180445023100248
Validation loss: 2.4589213618198777

Epoch: 5| Step: 8
Training loss: 0.31889737779909494
Validation loss: 2.462424956634151

Epoch: 5| Step: 9
Training loss: 0.5464132812152329
Validation loss: 2.467406063756829

Epoch: 5| Step: 10
Training loss: 0.34508473103897397
Validation loss: 2.466467215634504

Epoch: 451| Step: 0
Training loss: 0.47586630951922426
Validation loss: 2.4500661077196475

Epoch: 5| Step: 1
Training loss: 0.6107690466722715
Validation loss: 2.4419804337821827

Epoch: 5| Step: 2
Training loss: 0.3985016154145221
Validation loss: 2.485508173851386

Epoch: 5| Step: 3
Training loss: 0.26441298987415773
Validation loss: 2.4969464183335512

Epoch: 5| Step: 4
Training loss: 0.45339571331090184
Validation loss: 2.485823621901657

Epoch: 5| Step: 5
Training loss: 0.4249694680017745
Validation loss: 2.470999861153203

Epoch: 5| Step: 6
Training loss: 0.4216749812080414
Validation loss: 2.4751926322709896

Epoch: 5| Step: 7
Training loss: 0.46745104421208655
Validation loss: 2.4721386292253396

Epoch: 5| Step: 8
Training loss: 0.3466258477325473
Validation loss: 2.4128809638353905

Epoch: 5| Step: 9
Training loss: 0.28869641810085644
Validation loss: 2.430215068256952

Epoch: 5| Step: 10
Training loss: 0.6001713011507174
Validation loss: 2.407153987491468

Epoch: 452| Step: 0
Training loss: 0.3909982423986752
Validation loss: 2.3812968398402523

Epoch: 5| Step: 1
Training loss: 0.36759060180763614
Validation loss: 2.4115056909630153

Epoch: 5| Step: 2
Training loss: 0.6088729404092756
Validation loss: 2.4156688572276472

Epoch: 5| Step: 3
Training loss: 0.24037443900576
Validation loss: 2.412809430166492

Epoch: 5| Step: 4
Training loss: 0.48423095837910035
Validation loss: 2.451516318860902

Epoch: 5| Step: 5
Training loss: 0.6722453006241077
Validation loss: 2.4348260281326333

Epoch: 5| Step: 6
Training loss: 0.5732611631927704
Validation loss: 2.407961449444562

Epoch: 5| Step: 7
Training loss: 0.3569307131461865
Validation loss: 2.453086050641524

Epoch: 5| Step: 8
Training loss: 0.3267207068189038
Validation loss: 2.44534834837739

Epoch: 5| Step: 9
Training loss: 0.3265342526790192
Validation loss: 2.4828910469151233

Epoch: 5| Step: 10
Training loss: 0.3299803391473566
Validation loss: 2.443660976858305

Epoch: 453| Step: 0
Training loss: 0.2157465864924831
Validation loss: 2.4443933129517466

Epoch: 5| Step: 1
Training loss: 0.4276834570830055
Validation loss: 2.469743927577604

Epoch: 5| Step: 2
Training loss: 0.2807149698894078
Validation loss: 2.4332116400709234

Epoch: 5| Step: 3
Training loss: 0.4853853639925088
Validation loss: 2.413822933036245

Epoch: 5| Step: 4
Training loss: 0.2735138105448315
Validation loss: 2.4391630193284217

Epoch: 5| Step: 5
Training loss: 0.4501230508729811
Validation loss: 2.4273224399974036

Epoch: 5| Step: 6
Training loss: 0.46885112625296793
Validation loss: 2.4218008632738375

Epoch: 5| Step: 7
Training loss: 0.4897089418294794
Validation loss: 2.4252813872231287

Epoch: 5| Step: 8
Training loss: 0.580128523053332
Validation loss: 2.426563973339178

Epoch: 5| Step: 9
Training loss: 0.6625864566314679
Validation loss: 2.4289767278146956

Epoch: 5| Step: 10
Training loss: 0.3131144443415501
Validation loss: 2.4157048144017

Epoch: 454| Step: 0
Training loss: 0.13184916112066572
Validation loss: 2.402770407561445

Epoch: 5| Step: 1
Training loss: 0.3808981460008395
Validation loss: 2.423377555848998

Epoch: 5| Step: 2
Training loss: 0.47319047860258756
Validation loss: 2.437638591468548

Epoch: 5| Step: 3
Training loss: 0.5764071485264746
Validation loss: 2.4395313512302965

Epoch: 5| Step: 4
Training loss: 0.43426497801873637
Validation loss: 2.462837990443501

Epoch: 5| Step: 5
Training loss: 0.31400445952179573
Validation loss: 2.456739031390314

Epoch: 5| Step: 6
Training loss: 0.5371406684775822
Validation loss: 2.4378477358089072

Epoch: 5| Step: 7
Training loss: 0.4106027987907369
Validation loss: 2.4733638015803923

Epoch: 5| Step: 8
Training loss: 0.5401871876440411
Validation loss: 2.449779598777103

Epoch: 5| Step: 9
Training loss: 0.44074763897735675
Validation loss: 2.4426834119517298

Epoch: 5| Step: 10
Training loss: 0.25735524115416236
Validation loss: 2.4998693370513534

Epoch: 455| Step: 0
Training loss: 0.3406635459473443
Validation loss: 2.4928216021109075

Epoch: 5| Step: 1
Training loss: 0.4219719987196281
Validation loss: 2.4937421607112933

Epoch: 5| Step: 2
Training loss: 0.4393237622909985
Validation loss: 2.5005087898744693

Epoch: 5| Step: 3
Training loss: 0.30542482513956043
Validation loss: 2.482044652450469

Epoch: 5| Step: 4
Training loss: 0.5996240868767232
Validation loss: 2.4812794905621227

Epoch: 5| Step: 5
Training loss: 0.5506875249239005
Validation loss: 2.447637662432769

Epoch: 5| Step: 6
Training loss: 0.45071581294489976
Validation loss: 2.495355305590377

Epoch: 5| Step: 7
Training loss: 0.2680753001143001
Validation loss: 2.4907877694466105

Epoch: 5| Step: 8
Training loss: 0.36815647350149394
Validation loss: 2.467720188711528

Epoch: 5| Step: 9
Training loss: 0.40321250749391635
Validation loss: 2.49914244818135

Epoch: 5| Step: 10
Training loss: 0.45659934935015867
Validation loss: 2.4248593893368198

Epoch: 456| Step: 0
Training loss: 0.5117087326816507
Validation loss: 2.458844693954024

Epoch: 5| Step: 1
Training loss: 0.38848828527715545
Validation loss: 2.442258877493486

Epoch: 5| Step: 2
Training loss: 0.6101897002171401
Validation loss: 2.443693895243798

Epoch: 5| Step: 3
Training loss: 0.3670039631333346
Validation loss: 2.441538224129536

Epoch: 5| Step: 4
Training loss: 0.18504042523659206
Validation loss: 2.4335793431364428

Epoch: 5| Step: 5
Training loss: 0.2603595512063083
Validation loss: 2.4660384860197473

Epoch: 5| Step: 6
Training loss: 0.46837127008676027
Validation loss: 2.4743385607370016

Epoch: 5| Step: 7
Training loss: 0.4580319689010888
Validation loss: 2.4513345839974665

Epoch: 5| Step: 8
Training loss: 0.43548569869725506
Validation loss: 2.4876196336105876

Epoch: 5| Step: 9
Training loss: 0.518105982671881
Validation loss: 2.478755871825265

Epoch: 5| Step: 10
Training loss: 0.40311986639021746
Validation loss: 2.4789316316374945

Epoch: 457| Step: 0
Training loss: 0.3493451873124581
Validation loss: 2.4604091881287418

Epoch: 5| Step: 1
Training loss: 0.37232385842372356
Validation loss: 2.5176198890604127

Epoch: 5| Step: 2
Training loss: 0.5225804272494171
Validation loss: 2.5029337056528833

Epoch: 5| Step: 3
Training loss: 0.4195256337619271
Validation loss: 2.4631693277528486

Epoch: 5| Step: 4
Training loss: 0.4481118039591702
Validation loss: 2.4560724738621986

Epoch: 5| Step: 5
Training loss: 0.4977220560638156
Validation loss: 2.4473927160770184

Epoch: 5| Step: 6
Training loss: 0.3525074445330664
Validation loss: 2.4412643712974917

Epoch: 5| Step: 7
Training loss: 0.3508235583034684
Validation loss: 2.472490481464884

Epoch: 5| Step: 8
Training loss: 0.34488663455574853
Validation loss: 2.4552573378646194

Epoch: 5| Step: 9
Training loss: 0.31528386858426366
Validation loss: 2.4240519361530146

Epoch: 5| Step: 10
Training loss: 0.5893476812801055
Validation loss: 2.4696643709781534

Epoch: 458| Step: 0
Training loss: 0.4536598928953933
Validation loss: 2.447360625744622

Epoch: 5| Step: 1
Training loss: 0.40530544292509185
Validation loss: 2.478686074049353

Epoch: 5| Step: 2
Training loss: 0.17905164249650038
Validation loss: 2.491493342645371

Epoch: 5| Step: 3
Training loss: 0.37740354360393563
Validation loss: 2.4491301390328784

Epoch: 5| Step: 4
Training loss: 0.43265104484251193
Validation loss: 2.443354379621233

Epoch: 5| Step: 5
Training loss: 0.5459895458862482
Validation loss: 2.4286184690257113

Epoch: 5| Step: 6
Training loss: 0.4777258291283326
Validation loss: 2.4218563294790925

Epoch: 5| Step: 7
Training loss: 0.41462025773490707
Validation loss: 2.4603276083140115

Epoch: 5| Step: 8
Training loss: 0.36942226020435687
Validation loss: 2.420819027777432

Epoch: 5| Step: 9
Training loss: 0.42877619079469864
Validation loss: 2.4199957218198453

Epoch: 5| Step: 10
Training loss: 0.4728208050499549
Validation loss: 2.399304307239087

Epoch: 459| Step: 0
Training loss: 0.2637434968101432
Validation loss: 2.4313668288106616

Epoch: 5| Step: 1
Training loss: 0.45269728896245887
Validation loss: 2.42509112789987

Epoch: 5| Step: 2
Training loss: 0.3965469837084107
Validation loss: 2.444474865036425

Epoch: 5| Step: 3
Training loss: 0.44868052207748405
Validation loss: 2.4248625721337693

Epoch: 5| Step: 4
Training loss: 0.5349674309416171
Validation loss: 2.4278237885188996

Epoch: 5| Step: 5
Training loss: 0.34236956982590794
Validation loss: 2.4082536983413414

Epoch: 5| Step: 6
Training loss: 0.39757178258231474
Validation loss: 2.4334663975764066

Epoch: 5| Step: 7
Training loss: 0.3478240347609284
Validation loss: 2.4112985230614843

Epoch: 5| Step: 8
Training loss: 0.4252462087649484
Validation loss: 2.4231523144432785

Epoch: 5| Step: 9
Training loss: 0.5038081228834844
Validation loss: 2.4391440176302104

Epoch: 5| Step: 10
Training loss: 0.3958959864506175
Validation loss: 2.4272091768790776

Epoch: 460| Step: 0
Training loss: 0.44269350438433297
Validation loss: 2.464258419886028

Epoch: 5| Step: 1
Training loss: 0.3740657852143317
Validation loss: 2.440901162680572

Epoch: 5| Step: 2
Training loss: 0.2533209583800706
Validation loss: 2.4403624343700216

Epoch: 5| Step: 3
Training loss: 0.43936102007877376
Validation loss: 2.4815538800899954

Epoch: 5| Step: 4
Training loss: 0.555438111395149
Validation loss: 2.4514560272146246

Epoch: 5| Step: 5
Training loss: 0.3331839132192824
Validation loss: 2.460902605852738

Epoch: 5| Step: 6
Training loss: 0.3428954208987741
Validation loss: 2.478921965216915

Epoch: 5| Step: 7
Training loss: 0.45398717280365875
Validation loss: 2.484716289933323

Epoch: 5| Step: 8
Training loss: 0.3563977980625428
Validation loss: 2.4587580277676877

Epoch: 5| Step: 9
Training loss: 0.35623122801595997
Validation loss: 2.468690941320836

Epoch: 5| Step: 10
Training loss: 0.47949183011478697
Validation loss: 2.4539138239448692

Epoch: 461| Step: 0
Training loss: 0.5191159416857886
Validation loss: 2.452931365316019

Epoch: 5| Step: 1
Training loss: 0.23813768658421694
Validation loss: 2.4327561409142593

Epoch: 5| Step: 2
Training loss: 0.44622892479590415
Validation loss: 2.4446659186679884

Epoch: 5| Step: 3
Training loss: 0.48688104902434626
Validation loss: 2.4529468395131615

Epoch: 5| Step: 4
Training loss: 0.46830626783980467
Validation loss: 2.434480398045493

Epoch: 5| Step: 5
Training loss: 0.4534672234045335
Validation loss: 2.475588288241047

Epoch: 5| Step: 6
Training loss: 0.38693620367114917
Validation loss: 2.481899638831355

Epoch: 5| Step: 7
Training loss: 0.32420441009797746
Validation loss: 2.469405386201705

Epoch: 5| Step: 8
Training loss: 0.241748018829153
Validation loss: 2.4582180568335383

Epoch: 5| Step: 9
Training loss: 0.27027905428150334
Validation loss: 2.500303049075443

Epoch: 5| Step: 10
Training loss: 0.371255979714578
Validation loss: 2.435742922635343

Epoch: 462| Step: 0
Training loss: 0.28139106868395636
Validation loss: 2.480357382498548

Epoch: 5| Step: 1
Training loss: 0.4227267074383082
Validation loss: 2.4605322761219055

Epoch: 5| Step: 2
Training loss: 0.4777580336469688
Validation loss: 2.4739363723237835

Epoch: 5| Step: 3
Training loss: 0.34985022533330984
Validation loss: 2.4629236059244635

Epoch: 5| Step: 4
Training loss: 0.21284251588164824
Validation loss: 2.4611094529146107

Epoch: 5| Step: 5
Training loss: 0.2872685750104885
Validation loss: 2.4258820209626597

Epoch: 5| Step: 6
Training loss: 0.4891087196374223
Validation loss: 2.446934520308849

Epoch: 5| Step: 7
Training loss: 0.35938335491917417
Validation loss: 2.442873617121266

Epoch: 5| Step: 8
Training loss: 0.44440290344664957
Validation loss: 2.46230115739925

Epoch: 5| Step: 9
Training loss: 0.48538639242972215
Validation loss: 2.4866530538903517

Epoch: 5| Step: 10
Training loss: 0.49864959150653515
Validation loss: 2.4724650573865934

Epoch: 463| Step: 0
Training loss: 0.30658271874530973
Validation loss: 2.4839160609057496

Epoch: 5| Step: 1
Training loss: 0.543965310186289
Validation loss: 2.465996654064945

Epoch: 5| Step: 2
Training loss: 0.4047267489749953
Validation loss: 2.481095662184273

Epoch: 5| Step: 3
Training loss: 0.3858131440004492
Validation loss: 2.4777827782714352

Epoch: 5| Step: 4
Training loss: 0.43736898640403954
Validation loss: 2.447322786161187

Epoch: 5| Step: 5
Training loss: 0.43509301457243277
Validation loss: 2.4619668100053738

Epoch: 5| Step: 6
Training loss: 0.3073699563183896
Validation loss: 2.4471636833917745

Epoch: 5| Step: 7
Training loss: 0.3820948783762382
Validation loss: 2.456223397026207

Epoch: 5| Step: 8
Training loss: 0.4605442729743789
Validation loss: 2.4606591539455978

Epoch: 5| Step: 9
Training loss: 0.35691413878558714
Validation loss: 2.4430461121489415

Epoch: 5| Step: 10
Training loss: 0.36037068716849835
Validation loss: 2.4486089065819754

Epoch: 464| Step: 0
Training loss: 0.13743831106833912
Validation loss: 2.43314917690431

Epoch: 5| Step: 1
Training loss: 0.5807270568900565
Validation loss: 2.462823438727034

Epoch: 5| Step: 2
Training loss: 0.39220051610860174
Validation loss: 2.4934957843425924

Epoch: 5| Step: 3
Training loss: 0.363735714563079
Validation loss: 2.455108427020835

Epoch: 5| Step: 4
Training loss: 0.4532363031425024
Validation loss: 2.454036002414581

Epoch: 5| Step: 5
Training loss: 0.3797046469125018
Validation loss: 2.4771369507747245

Epoch: 5| Step: 6
Training loss: 0.33963332841817445
Validation loss: 2.460212051860781

Epoch: 5| Step: 7
Training loss: 0.3847925786680695
Validation loss: 2.444681093881996

Epoch: 5| Step: 8
Training loss: 0.2651177499635035
Validation loss: 2.4546393955807257

Epoch: 5| Step: 9
Training loss: 0.4273624632258214
Validation loss: 2.434492865126269

Epoch: 5| Step: 10
Training loss: 0.41373029013648194
Validation loss: 2.432342204841841

Epoch: 465| Step: 0
Training loss: 0.4040386462564716
Validation loss: 2.4392495672009797

Epoch: 5| Step: 1
Training loss: 0.13922394746011615
Validation loss: 2.4243166891230725

Epoch: 5| Step: 2
Training loss: 0.43094629222041847
Validation loss: 2.469818830916601

Epoch: 5| Step: 3
Training loss: 0.44048747087514967
Validation loss: 2.4663762552150303

Epoch: 5| Step: 4
Training loss: 0.4437556575360768
Validation loss: 2.4463252968859956

Epoch: 5| Step: 5
Training loss: 0.24343040158471804
Validation loss: 2.482447566814247

Epoch: 5| Step: 6
Training loss: 0.31969569295488265
Validation loss: 2.4439515220539922

Epoch: 5| Step: 7
Training loss: 0.46657953030675553
Validation loss: 2.492083602078365

Epoch: 5| Step: 8
Training loss: 0.31113432257046963
Validation loss: 2.474408658572591

Epoch: 5| Step: 9
Training loss: 0.1449753857862053
Validation loss: 2.4627258449155423

Epoch: 5| Step: 10
Training loss: 0.6386195403422135
Validation loss: 2.474945286684349

Epoch: 466| Step: 0
Training loss: 0.35918854976837183
Validation loss: 2.4651252309326916

Epoch: 5| Step: 1
Training loss: 0.43142902141464573
Validation loss: 2.4646542001728755

Epoch: 5| Step: 2
Training loss: 0.39130980546429056
Validation loss: 2.448811086515762

Epoch: 5| Step: 3
Training loss: 0.4726465082346898
Validation loss: 2.466316518096141

Epoch: 5| Step: 4
Training loss: 0.4674007388422084
Validation loss: 2.4932345225355994

Epoch: 5| Step: 5
Training loss: 0.3935059358677433
Validation loss: 2.4881860868701615

Epoch: 5| Step: 6
Training loss: 0.2553907864565148
Validation loss: 2.4675855796846147

Epoch: 5| Step: 7
Training loss: 0.37581902708637266
Validation loss: 2.493879362901074

Epoch: 5| Step: 8
Training loss: 0.20745923232115981
Validation loss: 2.4716631585322792

Epoch: 5| Step: 9
Training loss: 0.43075207699691737
Validation loss: 2.4667986084832556

Epoch: 5| Step: 10
Training loss: 0.29915043023518595
Validation loss: 2.4587840294040437

Epoch: 467| Step: 0
Training loss: 0.4477230548109851
Validation loss: 2.442201506482452

Epoch: 5| Step: 1
Training loss: 0.30864023510381994
Validation loss: 2.4632271460502517

Epoch: 5| Step: 2
Training loss: 0.517047797520728
Validation loss: 2.457312789399367

Epoch: 5| Step: 3
Training loss: 0.43632403775642736
Validation loss: 2.430650613882118

Epoch: 5| Step: 4
Training loss: 0.3476771337687394
Validation loss: 2.4277769327610033

Epoch: 5| Step: 5
Training loss: 0.46433472210960985
Validation loss: 2.44301052381463

Epoch: 5| Step: 6
Training loss: 0.42219328353274865
Validation loss: 2.452505074774333

Epoch: 5| Step: 7
Training loss: 0.3073947526147283
Validation loss: 2.4825791921412654

Epoch: 5| Step: 8
Training loss: 0.21166233634336395
Validation loss: 2.486716256625225

Epoch: 5| Step: 9
Training loss: 0.32320213645984897
Validation loss: 2.493932038250921

Epoch: 5| Step: 10
Training loss: 0.30372463820976997
Validation loss: 2.51771425226836

Epoch: 468| Step: 0
Training loss: 0.41402381140422734
Validation loss: 2.501089015773072

Epoch: 5| Step: 1
Training loss: 0.4187311011647288
Validation loss: 2.490744369243682

Epoch: 5| Step: 2
Training loss: 0.23690342828166885
Validation loss: 2.499358943559437

Epoch: 5| Step: 3
Training loss: 0.3482965937127248
Validation loss: 2.501328796085899

Epoch: 5| Step: 4
Training loss: 0.25648740319873403
Validation loss: 2.436197305624009

Epoch: 5| Step: 5
Training loss: 0.5797702216174472
Validation loss: 2.4733773340823846

Epoch: 5| Step: 6
Training loss: 0.32628494861100527
Validation loss: 2.4462383003413475

Epoch: 5| Step: 7
Training loss: 0.38663838254656374
Validation loss: 2.472009785261472

Epoch: 5| Step: 8
Training loss: 0.42258510167037694
Validation loss: 2.4494977095039374

Epoch: 5| Step: 9
Training loss: 0.35265144606847765
Validation loss: 2.4266408624086178

Epoch: 5| Step: 10
Training loss: 0.40420844543794177
Validation loss: 2.431619831261022

Epoch: 469| Step: 0
Training loss: 0.4222068893983663
Validation loss: 2.4658827600376263

Epoch: 5| Step: 1
Training loss: 0.3440976010987811
Validation loss: 2.4475430505650806

Epoch: 5| Step: 2
Training loss: 0.3889647295868113
Validation loss: 2.4912172508615593

Epoch: 5| Step: 3
Training loss: 0.3184770004061708
Validation loss: 2.4624900534082106

Epoch: 5| Step: 4
Training loss: 0.36496741182042913
Validation loss: 2.4816011362788606

Epoch: 5| Step: 5
Training loss: 0.12433581923593931
Validation loss: 2.4719064943067166

Epoch: 5| Step: 6
Training loss: 0.4064620638268325
Validation loss: 2.491661184646953

Epoch: 5| Step: 7
Training loss: 0.3458937857351155
Validation loss: 2.503545465105713

Epoch: 5| Step: 8
Training loss: 0.35937033525839523
Validation loss: 2.4675466705326112

Epoch: 5| Step: 9
Training loss: 0.4938735692605256
Validation loss: 2.4834404656403235

Epoch: 5| Step: 10
Training loss: 0.4531263811813877
Validation loss: 2.4785194293185713

Epoch: 470| Step: 0
Training loss: 0.19771943910483794
Validation loss: 2.4394923950114706

Epoch: 5| Step: 1
Training loss: 0.4814913342746816
Validation loss: 2.4341351359500836

Epoch: 5| Step: 2
Training loss: 0.4429156061281203
Validation loss: 2.458877713507467

Epoch: 5| Step: 3
Training loss: 0.3532798571012927
Validation loss: 2.444187462591607

Epoch: 5| Step: 4
Training loss: 0.526793355170525
Validation loss: 2.433244416142339

Epoch: 5| Step: 5
Training loss: 0.26039089870123755
Validation loss: 2.4399628965991886

Epoch: 5| Step: 6
Training loss: 0.34732972573657067
Validation loss: 2.46196616960714

Epoch: 5| Step: 7
Training loss: 0.21831725947862388
Validation loss: 2.4443649914241066

Epoch: 5| Step: 8
Training loss: 0.2749753214860166
Validation loss: 2.4644927065484756

Epoch: 5| Step: 9
Training loss: 0.40077018425074173
Validation loss: 2.4303536031083093

Epoch: 5| Step: 10
Training loss: 0.3741295766005655
Validation loss: 2.475235649028516

Epoch: 471| Step: 0
Training loss: 0.4584153076760354
Validation loss: 2.4810457640619523

Epoch: 5| Step: 1
Training loss: 0.3051323211241687
Validation loss: 2.4558564808831367

Epoch: 5| Step: 2
Training loss: 0.3501995688507927
Validation loss: 2.4978864493003097

Epoch: 5| Step: 3
Training loss: 0.5246835367894856
Validation loss: 2.4922161503758478

Epoch: 5| Step: 4
Training loss: 0.20207063587516072
Validation loss: 2.4583944316909885

Epoch: 5| Step: 5
Training loss: 0.31293423999926734
Validation loss: 2.4518335905375284

Epoch: 5| Step: 6
Training loss: 0.30082163601524586
Validation loss: 2.458500066170837

Epoch: 5| Step: 7
Training loss: 0.47256881914074844
Validation loss: 2.4736138672749686

Epoch: 5| Step: 8
Training loss: 0.5055177042867097
Validation loss: 2.4380382304352044

Epoch: 5| Step: 9
Training loss: 0.2853160828264114
Validation loss: 2.4595713901882466

Epoch: 5| Step: 10
Training loss: 0.17240726352861846
Validation loss: 2.4191575539044883

Epoch: 472| Step: 0
Training loss: 0.2355959561203305
Validation loss: 2.4461350624676226

Epoch: 5| Step: 1
Training loss: 0.4101424805282642
Validation loss: 2.444637281500029

Epoch: 5| Step: 2
Training loss: 0.4587820053369797
Validation loss: 2.4169436007203093

Epoch: 5| Step: 3
Training loss: 0.17893303166791957
Validation loss: 2.442719507763611

Epoch: 5| Step: 4
Training loss: 0.5192787302450448
Validation loss: 2.42933316775052

Epoch: 5| Step: 5
Training loss: 0.32156520212148454
Validation loss: 2.4503782973507544

Epoch: 5| Step: 6
Training loss: 0.4499188648036406
Validation loss: 2.4251899983524297

Epoch: 5| Step: 7
Training loss: 0.23985917169153403
Validation loss: 2.4287400870344418

Epoch: 5| Step: 8
Training loss: 0.3621132439959101
Validation loss: 2.4359620877147647

Epoch: 5| Step: 9
Training loss: 0.18267637711346923
Validation loss: 2.4302077393088255

Epoch: 5| Step: 10
Training loss: 0.5478093748117753
Validation loss: 2.4764942493494972

Epoch: 473| Step: 0
Training loss: 0.27432726101501065
Validation loss: 2.457319228453174

Epoch: 5| Step: 1
Training loss: 0.4406023723121981
Validation loss: 2.445209547004657

Epoch: 5| Step: 2
Training loss: 0.3553725311510201
Validation loss: 2.4517089454086833

Epoch: 5| Step: 3
Training loss: 0.2521584731157755
Validation loss: 2.447315006153837

Epoch: 5| Step: 4
Training loss: 0.5280397696256167
Validation loss: 2.4387757565263497

Epoch: 5| Step: 5
Training loss: 0.31841144253001796
Validation loss: 2.4366716965864064

Epoch: 5| Step: 6
Training loss: 0.25833705077778063
Validation loss: 2.446367662749804

Epoch: 5| Step: 7
Training loss: 0.31369736877820864
Validation loss: 2.4485058199657024

Epoch: 5| Step: 8
Training loss: 0.37468153623491
Validation loss: 2.4483226229181683

Epoch: 5| Step: 9
Training loss: 0.44949756759986836
Validation loss: 2.4857228232678494

Epoch: 5| Step: 10
Training loss: 0.40800743340401135
Validation loss: 2.4479139362460485

Epoch: 474| Step: 0
Training loss: 0.35087567101507167
Validation loss: 2.4906437357898543

Epoch: 5| Step: 1
Training loss: 0.20638855557252928
Validation loss: 2.470183796623234

Epoch: 5| Step: 2
Training loss: 0.5082909311005245
Validation loss: 2.495491421059011

Epoch: 5| Step: 3
Training loss: 0.15689989474709704
Validation loss: 2.4849674485601474

Epoch: 5| Step: 4
Training loss: 0.4187089657961735
Validation loss: 2.4399411955851176

Epoch: 5| Step: 5
Training loss: 0.537221140937129
Validation loss: 2.4434635915277636

Epoch: 5| Step: 6
Training loss: 0.20429137862563387
Validation loss: 2.4355214821037574

Epoch: 5| Step: 7
Training loss: 0.2097463709059203
Validation loss: 2.411036418316549

Epoch: 5| Step: 8
Training loss: 0.401304328247102
Validation loss: 2.4128687569581317

Epoch: 5| Step: 9
Training loss: 0.31956575156112627
Validation loss: 2.4642136031256117

Epoch: 5| Step: 10
Training loss: 0.41458916907620175
Validation loss: 2.459461783954801

Epoch: 475| Step: 0
Training loss: 0.25013589145943277
Validation loss: 2.4393792944479

Epoch: 5| Step: 1
Training loss: 0.48843378354816797
Validation loss: 2.4637719034001604

Epoch: 5| Step: 2
Training loss: 0.3985957784986152
Validation loss: 2.470977734738478

Epoch: 5| Step: 3
Training loss: 0.2980788067552289
Validation loss: 2.4809132214022336

Epoch: 5| Step: 4
Training loss: 0.4625719478422162
Validation loss: 2.4591528303688315

Epoch: 5| Step: 5
Training loss: 0.2668652470613424
Validation loss: 2.4718242635441516

Epoch: 5| Step: 6
Training loss: 0.19383364609985287
Validation loss: 2.4601007698373056

Epoch: 5| Step: 7
Training loss: 0.49985426030462654
Validation loss: 2.4818585855290736

Epoch: 5| Step: 8
Training loss: 0.34619729234778696
Validation loss: 2.4789636028456377

Epoch: 5| Step: 9
Training loss: 0.35241589283416597
Validation loss: 2.4159611091740616

Epoch: 5| Step: 10
Training loss: 0.3105760716562668
Validation loss: 2.4407115889459625

Epoch: 476| Step: 0
Training loss: 0.3981155890246277
Validation loss: 2.4415629801002745

Epoch: 5| Step: 1
Training loss: 0.24987750479657864
Validation loss: 2.4191358631003492

Epoch: 5| Step: 2
Training loss: 0.5129754164161183
Validation loss: 2.44635434604662

Epoch: 5| Step: 3
Training loss: 0.4091576909455271
Validation loss: 2.447710746389752

Epoch: 5| Step: 4
Training loss: 0.3001818195355962
Validation loss: 2.4543174268499977

Epoch: 5| Step: 5
Training loss: 0.39333604366505553
Validation loss: 2.4288690251025575

Epoch: 5| Step: 6
Training loss: 0.45841441376537073
Validation loss: 2.433709043973747

Epoch: 5| Step: 7
Training loss: 0.3463354523940117
Validation loss: 2.4568902840332227

Epoch: 5| Step: 8
Training loss: 0.22210868631390995
Validation loss: 2.481829728299495

Epoch: 5| Step: 9
Training loss: 0.3309870175317959
Validation loss: 2.453501076652746

Epoch: 5| Step: 10
Training loss: 0.26104672824085795
Validation loss: 2.4653086396390007

Epoch: 477| Step: 0
Training loss: 0.2742970987752003
Validation loss: 2.4341716534152313

Epoch: 5| Step: 1
Training loss: 0.4021270872268841
Validation loss: 2.462293806303438

Epoch: 5| Step: 2
Training loss: 0.48931852409444404
Validation loss: 2.4737907569662165

Epoch: 5| Step: 3
Training loss: 0.42281099966252433
Validation loss: 2.44652218098347

Epoch: 5| Step: 4
Training loss: 0.4181454543454939
Validation loss: 2.423696374369392

Epoch: 5| Step: 5
Training loss: 0.44573469392874265
Validation loss: 2.471913748885307

Epoch: 5| Step: 6
Training loss: 0.31197262610116094
Validation loss: 2.481528201751179

Epoch: 5| Step: 7
Training loss: 0.18014581942904728
Validation loss: 2.49619992325781

Epoch: 5| Step: 8
Training loss: 0.2858912910061295
Validation loss: 2.482488106423785

Epoch: 5| Step: 9
Training loss: 0.2069184157749145
Validation loss: 2.476389118974499

Epoch: 5| Step: 10
Training loss: 0.23253432526802262
Validation loss: 2.481501093335622

Epoch: 478| Step: 0
Training loss: 0.24050243278113637
Validation loss: 2.476207711493529

Epoch: 5| Step: 1
Training loss: 0.45324307580446743
Validation loss: 2.4902095320361397

Epoch: 5| Step: 2
Training loss: 0.5004598469914433
Validation loss: 2.4835995917558042

Epoch: 5| Step: 3
Training loss: 0.2678173276851148
Validation loss: 2.48273247222291

Epoch: 5| Step: 4
Training loss: 0.35388977315580306
Validation loss: 2.4713830371220973

Epoch: 5| Step: 5
Training loss: 0.410170491289218
Validation loss: 2.4578422972286362

Epoch: 5| Step: 6
Training loss: 0.3213953694535792
Validation loss: 2.4447689034696554

Epoch: 5| Step: 7
Training loss: 0.24529074797197187
Validation loss: 2.463269531881542

Epoch: 5| Step: 8
Training loss: 0.4306384920240635
Validation loss: 2.433627593573934

Epoch: 5| Step: 9
Training loss: 0.38512413633844644
Validation loss: 2.4291780817022604

Epoch: 5| Step: 10
Training loss: 0.20667814336014975
Validation loss: 2.4761941996362387

Epoch: 479| Step: 0
Training loss: 0.21243961051146187
Validation loss: 2.4910474060848338

Epoch: 5| Step: 1
Training loss: 0.19273982349204793
Validation loss: 2.5010114151808285

Epoch: 5| Step: 2
Training loss: 0.2905336395350868
Validation loss: 2.4898518195161596

Epoch: 5| Step: 3
Training loss: 0.29260411777317125
Validation loss: 2.487599527824147

Epoch: 5| Step: 4
Training loss: 0.28493786640649904
Validation loss: 2.491937192267227

Epoch: 5| Step: 5
Training loss: 0.5298183167095415
Validation loss: 2.4803638299442317

Epoch: 5| Step: 6
Training loss: 0.3466720042921996
Validation loss: 2.4696836231390065

Epoch: 5| Step: 7
Training loss: 0.43520589918506186
Validation loss: 2.466815516116664

Epoch: 5| Step: 8
Training loss: 0.5147614038398257
Validation loss: 2.4760198475120103

Epoch: 5| Step: 9
Training loss: 0.1465140566953983
Validation loss: 2.443875040716321

Epoch: 5| Step: 10
Training loss: 0.33653825449413177
Validation loss: 2.4342333842001795

Epoch: 480| Step: 0
Training loss: 0.3901362986078972
Validation loss: 2.4579176936382745

Epoch: 5| Step: 1
Training loss: 0.37116074208348915
Validation loss: 2.456303788176776

Epoch: 5| Step: 2
Training loss: 0.37980137126086483
Validation loss: 2.43732666333259

Epoch: 5| Step: 3
Training loss: 0.27007811809227505
Validation loss: 2.4304560293358115

Epoch: 5| Step: 4
Training loss: 0.26481962122198005
Validation loss: 2.450327662802653

Epoch: 5| Step: 5
Training loss: 0.24663329394189998
Validation loss: 2.438491014022846

Epoch: 5| Step: 6
Training loss: 0.2239088495427051
Validation loss: 2.448216359773424

Epoch: 5| Step: 7
Training loss: 0.39950362789192134
Validation loss: 2.4537451792062033

Epoch: 5| Step: 8
Training loss: 0.5081229214784121
Validation loss: 2.4775054245256096

Epoch: 5| Step: 9
Training loss: 0.2326419093321839
Validation loss: 2.4511490646939724

Epoch: 5| Step: 10
Training loss: 0.33432154896702965
Validation loss: 2.4572961523168653

Epoch: 481| Step: 0
Training loss: 0.3228525423656994
Validation loss: 2.459506425674958

Epoch: 5| Step: 1
Training loss: 0.3831492713782406
Validation loss: 2.4628696641621004

Epoch: 5| Step: 2
Training loss: 0.3637169716774587
Validation loss: 2.48387519471563

Epoch: 5| Step: 3
Training loss: 0.3793445883224002
Validation loss: 2.4484894748432136

Epoch: 5| Step: 4
Training loss: 0.18211210239811335
Validation loss: 2.45075434150359

Epoch: 5| Step: 5
Training loss: 0.3635561938329936
Validation loss: 2.4680440196239357

Epoch: 5| Step: 6
Training loss: 0.395957690915661
Validation loss: 2.467784850253889

Epoch: 5| Step: 7
Training loss: 0.2360424253696213
Validation loss: 2.478855335489436

Epoch: 5| Step: 8
Training loss: 0.3693063555671303
Validation loss: 2.4914213639741343

Epoch: 5| Step: 9
Training loss: 0.32783964782903163
Validation loss: 2.4494365612231674

Epoch: 5| Step: 10
Training loss: 0.41138595435372094
Validation loss: 2.4811101909450874

Epoch: 482| Step: 0
Training loss: 0.4806064315403653
Validation loss: 2.4421340628020523

Epoch: 5| Step: 1
Training loss: 0.2371594412294004
Validation loss: 2.4141769894427045

Epoch: 5| Step: 2
Training loss: 0.32003846890964727
Validation loss: 2.4508475040938906

Epoch: 5| Step: 3
Training loss: 0.13242615577507738
Validation loss: 2.4398145306879604

Epoch: 5| Step: 4
Training loss: 0.5299809388565782
Validation loss: 2.401712601246111

Epoch: 5| Step: 5
Training loss: 0.19513779455962615
Validation loss: 2.417543566869947

Epoch: 5| Step: 6
Training loss: 0.44426619433015463
Validation loss: 2.445288881760962

Epoch: 5| Step: 7
Training loss: 0.29164209716490713
Validation loss: 2.437948241982798

Epoch: 5| Step: 8
Training loss: 0.33831531097693235
Validation loss: 2.4342319661179435

Epoch: 5| Step: 9
Training loss: 0.26944431340295244
Validation loss: 2.4606939546543694

Epoch: 5| Step: 10
Training loss: 0.3016638501485429
Validation loss: 2.4631773803276156

Epoch: 483| Step: 0
Training loss: 0.1858318950578886
Validation loss: 2.4551768790358954

Epoch: 5| Step: 1
Training loss: 0.56995887766956
Validation loss: 2.5017256769498024

Epoch: 5| Step: 2
Training loss: 0.3962396890821013
Validation loss: 2.469626237315636

Epoch: 5| Step: 3
Training loss: 0.14293714288584372
Validation loss: 2.4751315625821366

Epoch: 5| Step: 4
Training loss: 0.32165263281648543
Validation loss: 2.5005498773597177

Epoch: 5| Step: 5
Training loss: 0.1299604169710752
Validation loss: 2.46028048275179

Epoch: 5| Step: 6
Training loss: 0.26334222036668664
Validation loss: 2.4631670161584087

Epoch: 5| Step: 7
Training loss: 0.30617047367227884
Validation loss: 2.4682698383215804

Epoch: 5| Step: 8
Training loss: 0.3580624827396431
Validation loss: 2.444754143533597

Epoch: 5| Step: 9
Training loss: 0.343147551867248
Validation loss: 2.459236837938196

Epoch: 5| Step: 10
Training loss: 0.39225569812192873
Validation loss: 2.443981437549106

Epoch: 484| Step: 0
Training loss: 0.1286380535416856
Validation loss: 2.4702903124153694

Epoch: 5| Step: 1
Training loss: 0.5413717206592719
Validation loss: 2.454470444528504

Epoch: 5| Step: 2
Training loss: 0.34391953882438936
Validation loss: 2.4459545350598884

Epoch: 5| Step: 3
Training loss: 0.4411389714787891
Validation loss: 2.468429345225639

Epoch: 5| Step: 4
Training loss: 0.1722407783702931
Validation loss: 2.466392006780126

Epoch: 5| Step: 5
Training loss: 0.2509635595374625
Validation loss: 2.452456253891061

Epoch: 5| Step: 6
Training loss: 0.24705286680606847
Validation loss: 2.44707265392497

Epoch: 5| Step: 7
Training loss: 0.16720244906785872
Validation loss: 2.467860464388488

Epoch: 5| Step: 8
Training loss: 0.40865614726424176
Validation loss: 2.4607535235365265

Epoch: 5| Step: 9
Training loss: 0.43408906842975836
Validation loss: 2.4531567599381225

Epoch: 5| Step: 10
Training loss: 0.2423057882556699
Validation loss: 2.464863384597592

Epoch: 485| Step: 0
Training loss: 0.3545305215585151
Validation loss: 2.4797606648922206

Epoch: 5| Step: 1
Training loss: 0.303518669869211
Validation loss: 2.466234428390241

Epoch: 5| Step: 2
Training loss: 0.4037577955774797
Validation loss: 2.4436479312858226

Epoch: 5| Step: 3
Training loss: 0.27072058066804083
Validation loss: 2.46362638862238

Epoch: 5| Step: 4
Training loss: 0.26038790861922406
Validation loss: 2.472790853588608

Epoch: 5| Step: 5
Training loss: 0.4790548439434348
Validation loss: 2.4712798081481995

Epoch: 5| Step: 6
Training loss: 0.19954116760794754
Validation loss: 2.4670474826744035

Epoch: 5| Step: 7
Training loss: 0.3287235772099109
Validation loss: 2.4372834476756444

Epoch: 5| Step: 8
Training loss: 0.10019014783937012
Validation loss: 2.474197339017998

Epoch: 5| Step: 9
Training loss: 0.5127451263932649
Validation loss: 2.463804162892273

Epoch: 5| Step: 10
Training loss: 0.2203684776290837
Validation loss: 2.4729068034752766

Epoch: 486| Step: 0
Training loss: 0.309163015160671
Validation loss: 2.4488707010527295

Epoch: 5| Step: 1
Training loss: 0.18665882010728596
Validation loss: 2.433664278772797

Epoch: 5| Step: 2
Training loss: 0.15037200242707047
Validation loss: 2.407014618510555

Epoch: 5| Step: 3
Training loss: 0.3798559027312228
Validation loss: 2.4504606702859886

Epoch: 5| Step: 4
Training loss: 0.23905433254377034
Validation loss: 2.41910566605518

Epoch: 5| Step: 5
Training loss: 0.23767161944749712
Validation loss: 2.4555174123691437

Epoch: 5| Step: 6
Training loss: 0.3779565372835793
Validation loss: 2.459142028070462

Epoch: 5| Step: 7
Training loss: 0.3231584607624085
Validation loss: 2.4499097667264818

Epoch: 5| Step: 8
Training loss: 0.36740832080534896
Validation loss: 2.4545651027092887

Epoch: 5| Step: 9
Training loss: 0.29265272261596154
Validation loss: 2.479351174539451

Epoch: 5| Step: 10
Training loss: 0.5491417365524889
Validation loss: 2.457180993743004

Epoch: 487| Step: 0
Training loss: 0.23792628129103244
Validation loss: 2.438268521939353

Epoch: 5| Step: 1
Training loss: 0.3332725770039121
Validation loss: 2.446654528801532

Epoch: 5| Step: 2
Training loss: 0.18029799619551368
Validation loss: 2.4488450396038397

Epoch: 5| Step: 3
Training loss: 0.5137343568114154
Validation loss: 2.461588145218358

Epoch: 5| Step: 4
Training loss: 0.20044220377699257
Validation loss: 2.4532782728359654

Epoch: 5| Step: 5
Training loss: 0.3326394289278245
Validation loss: 2.439392830514164

Epoch: 5| Step: 6
Training loss: 0.26707726262394743
Validation loss: 2.440716638575612

Epoch: 5| Step: 7
Training loss: 0.48291321108385077
Validation loss: 2.439502647482654

Epoch: 5| Step: 8
Training loss: 0.2742184114589938
Validation loss: 2.436749543935191

Epoch: 5| Step: 9
Training loss: 0.37390846098753466
Validation loss: 2.4253076262020725

Epoch: 5| Step: 10
Training loss: 0.18295947548988953
Validation loss: 2.4321351300141787

Epoch: 488| Step: 0
Training loss: 0.35620579445279543
Validation loss: 2.4353146491873505

Epoch: 5| Step: 1
Training loss: 0.3808401054006979
Validation loss: 2.4450721909639497

Epoch: 5| Step: 2
Training loss: 0.2850189270251529
Validation loss: 2.4740673769551966

Epoch: 5| Step: 3
Training loss: 0.3449125355614983
Validation loss: 2.4742699145923286

Epoch: 5| Step: 4
Training loss: 0.4671929566437877
Validation loss: 2.496480172345237

Epoch: 5| Step: 5
Training loss: 0.27143491664977315
Validation loss: 2.4581293387650445

Epoch: 5| Step: 6
Training loss: 0.3219097947322763
Validation loss: 2.467985042732786

Epoch: 5| Step: 7
Training loss: 0.42975943570100156
Validation loss: 2.4590950841207566

Epoch: 5| Step: 8
Training loss: 0.17171749570976816
Validation loss: 2.4602009092963124

Epoch: 5| Step: 9
Training loss: 0.19455738964409383
Validation loss: 2.4498491571871495

Epoch: 5| Step: 10
Training loss: 0.28651513345720636
Validation loss: 2.4188576322070245

Epoch: 489| Step: 0
Training loss: 0.1933557240305223
Validation loss: 2.4605779236359675

Epoch: 5| Step: 1
Training loss: 0.33704235564403656
Validation loss: 2.4326731168466478

Epoch: 5| Step: 2
Training loss: 0.255310401487656
Validation loss: 2.4448403728910746

Epoch: 5| Step: 3
Training loss: 0.1713417461545251
Validation loss: 2.4662654529904424

Epoch: 5| Step: 4
Training loss: 0.41180361573418395
Validation loss: 2.4736250831144444

Epoch: 5| Step: 5
Training loss: 0.3785299418510332
Validation loss: 2.4887839086000785

Epoch: 5| Step: 6
Training loss: 0.3452243938500945
Validation loss: 2.4422001570602445

Epoch: 5| Step: 7
Training loss: 0.3482702063191083
Validation loss: 2.465515687381716

Epoch: 5| Step: 8
Training loss: 0.3857929051532444
Validation loss: 2.446868461210712

Epoch: 5| Step: 9
Training loss: 0.2711963497888527
Validation loss: 2.451888543071701

Epoch: 5| Step: 10
Training loss: 0.3207281834689602
Validation loss: 2.451175820070027

Epoch: 490| Step: 0
Training loss: 0.36515954214888263
Validation loss: 2.4602875236136383

Epoch: 5| Step: 1
Training loss: 0.4492204417321236
Validation loss: 2.4605542695941485

Epoch: 5| Step: 2
Training loss: 0.37406034760584905
Validation loss: 2.4554873821490544

Epoch: 5| Step: 3
Training loss: 0.21909585927313294
Validation loss: 2.4569681992496197

Epoch: 5| Step: 4
Training loss: 0.1653616647137374
Validation loss: 2.4620760928258716

Epoch: 5| Step: 5
Training loss: 0.26390359374675054
Validation loss: 2.450876830193832

Epoch: 5| Step: 6
Training loss: 0.25501965178236824
Validation loss: 2.4412607588537045

Epoch: 5| Step: 7
Training loss: 0.304464882439347
Validation loss: 2.4462877509636143

Epoch: 5| Step: 8
Training loss: 0.27391377251017474
Validation loss: 2.4700060746558847

Epoch: 5| Step: 9
Training loss: 0.3213606989344486
Validation loss: 2.4634161819227627

Epoch: 5| Step: 10
Training loss: 0.5311444121503424
Validation loss: 2.4687188903169357

Epoch: 491| Step: 0
Training loss: 0.3903861650842348
Validation loss: 2.4947035233124435

Epoch: 5| Step: 1
Training loss: 0.17494370883500834
Validation loss: 2.4992843536795566

Epoch: 5| Step: 2
Training loss: 0.3395211233989164
Validation loss: 2.531895672520743

Epoch: 5| Step: 3
Training loss: 0.20088818370590472
Validation loss: 2.4676950687054764

Epoch: 5| Step: 4
Training loss: 0.30114741145621804
Validation loss: 2.46487659038342

Epoch: 5| Step: 5
Training loss: 0.41948613469440377
Validation loss: 2.474630133838186

Epoch: 5| Step: 6
Training loss: 0.3334713950443261
Validation loss: 2.427471684533766

Epoch: 5| Step: 7
Training loss: 0.21610098492253615
Validation loss: 2.411633666778431

Epoch: 5| Step: 8
Training loss: 0.1944444248127549
Validation loss: 2.4101810113339557

Epoch: 5| Step: 9
Training loss: 0.4449693629348148
Validation loss: 2.4138558951091564

Epoch: 5| Step: 10
Training loss: 0.39559822461970884
Validation loss: 2.424826534550906

Epoch: 492| Step: 0
Training loss: 0.3565140331336594
Validation loss: 2.3645684152920134

Epoch: 5| Step: 1
Training loss: 0.2780144466387395
Validation loss: 2.401336553227304

Epoch: 5| Step: 2
Training loss: 0.4609142717877311
Validation loss: 2.4246896608758757

Epoch: 5| Step: 3
Training loss: 0.2819169930518104
Validation loss: 2.4352850546266933

Epoch: 5| Step: 4
Training loss: 0.3260945896709984
Validation loss: 2.472831661402948

Epoch: 5| Step: 5
Training loss: 0.3101986426105167
Validation loss: 2.448219605924717

Epoch: 5| Step: 6
Training loss: 0.3774066430352216
Validation loss: 2.457259690557376

Epoch: 5| Step: 7
Training loss: 0.35926597434135443
Validation loss: 2.486488378815562

Epoch: 5| Step: 8
Training loss: 0.3446413426521253
Validation loss: 2.4816333546003873

Epoch: 5| Step: 9
Training loss: 0.18356285443984488
Validation loss: 2.499185671515289

Epoch: 5| Step: 10
Training loss: 0.36418316769187564
Validation loss: 2.4805183031685902

Epoch: 493| Step: 0
Training loss: 0.4326730179766247
Validation loss: 2.4589910244435798

Epoch: 5| Step: 1
Training loss: 0.3215605218009046
Validation loss: 2.495056838729823

Epoch: 5| Step: 2
Training loss: 0.36992700768588693
Validation loss: 2.5165769650546896

Epoch: 5| Step: 3
Training loss: 0.4289588645807021
Validation loss: 2.438804881945836

Epoch: 5| Step: 4
Training loss: 0.22240907769591806
Validation loss: 2.48634581955928

Epoch: 5| Step: 5
Training loss: 0.1941514217513766
Validation loss: 2.461280092872559

Epoch: 5| Step: 6
Training loss: 0.2633145772515646
Validation loss: 2.4505091469836855

Epoch: 5| Step: 7
Training loss: 0.3527579433809353
Validation loss: 2.4468817740682014

Epoch: 5| Step: 8
Training loss: 0.27851145020254503
Validation loss: 2.4706083971611066

Epoch: 5| Step: 9
Training loss: 0.21166751072620196
Validation loss: 2.4415349570198526

Epoch: 5| Step: 10
Training loss: 0.33976529849193093
Validation loss: 2.446898260369971

Epoch: 494| Step: 0
Training loss: 0.2408683908305087
Validation loss: 2.4631449752410517

Epoch: 5| Step: 1
Training loss: 0.16252399184940158
Validation loss: 2.4282685051973147

Epoch: 5| Step: 2
Training loss: 0.40976520243751113
Validation loss: 2.4496519921032545

Epoch: 5| Step: 3
Training loss: 0.33488278825822765
Validation loss: 2.4597785550336546

Epoch: 5| Step: 4
Training loss: 0.3054951697824601
Validation loss: 2.426221688689446

Epoch: 5| Step: 5
Training loss: 0.27313347672373817
Validation loss: 2.4450932377939787

Epoch: 5| Step: 6
Training loss: 0.3561357800267074
Validation loss: 2.4685147911872773

Epoch: 5| Step: 7
Training loss: 0.4791703707786801
Validation loss: 2.462835277259352

Epoch: 5| Step: 8
Training loss: 0.31002180226629183
Validation loss: 2.453361444970394

Epoch: 5| Step: 9
Training loss: 0.3248202019138553
Validation loss: 2.432328901466795

Epoch: 5| Step: 10
Training loss: 0.21833189107209844
Validation loss: 2.4140586949901315

Epoch: 495| Step: 0
Training loss: 0.2584006363478891
Validation loss: 2.3951917178850612

Epoch: 5| Step: 1
Training loss: 0.43782196799802
Validation loss: 2.40297028256488

Epoch: 5| Step: 2
Training loss: 0.4958548684078416
Validation loss: 2.417449103859936

Epoch: 5| Step: 3
Training loss: 0.26029272308876145
Validation loss: 2.4205019866662507

Epoch: 5| Step: 4
Training loss: 0.16222611785247218
Validation loss: 2.4356728429661763

Epoch: 5| Step: 5
Training loss: 0.37854322759963943
Validation loss: 2.4466216518220074

Epoch: 5| Step: 6
Training loss: 0.2702700813174393
Validation loss: 2.482995763129245

Epoch: 5| Step: 7
Training loss: 0.23215796610112832
Validation loss: 2.478123061475704

Epoch: 5| Step: 8
Training loss: 0.3229018895039308
Validation loss: 2.465099929787175

Epoch: 5| Step: 9
Training loss: 0.3354137462978504
Validation loss: 2.459953336068855

Epoch: 5| Step: 10
Training loss: 0.3451694205047783
Validation loss: 2.4265536820480107

Epoch: 496| Step: 0
Training loss: 0.33300242042091444
Validation loss: 2.3930097086983713

Epoch: 5| Step: 1
Training loss: 0.3281563562215559
Validation loss: 2.415914192066317

Epoch: 5| Step: 2
Training loss: 0.4934495458406969
Validation loss: 2.3785772503764058

Epoch: 5| Step: 3
Training loss: 0.3127090231887626
Validation loss: 2.3645561503646313

Epoch: 5| Step: 4
Training loss: 0.3365348672281883
Validation loss: 2.4088412564814967

Epoch: 5| Step: 5
Training loss: 0.29511234625348975
Validation loss: 2.436845786808495

Epoch: 5| Step: 6
Training loss: 0.2561131012816369
Validation loss: 2.4441257912662984

Epoch: 5| Step: 7
Training loss: 0.42046999976157756
Validation loss: 2.486000596704656

Epoch: 5| Step: 8
Training loss: 0.30719221520904016
Validation loss: 2.4619472814288854

Epoch: 5| Step: 9
Training loss: 0.2997536134239574
Validation loss: 2.5089194898005514

Epoch: 5| Step: 10
Training loss: 0.21308575882803665
Validation loss: 2.513140931219976

Epoch: 497| Step: 0
Training loss: 0.3504776216184281
Validation loss: 2.4640012162138567

Epoch: 5| Step: 1
Training loss: 0.3914628389609137
Validation loss: 2.48576433666597

Epoch: 5| Step: 2
Training loss: 0.4339731120545961
Validation loss: 2.4647933834945506

Epoch: 5| Step: 3
Training loss: 0.21208934302955493
Validation loss: 2.4983321974323776

Epoch: 5| Step: 4
Training loss: 0.2013801866511053
Validation loss: 2.4974409110852336

Epoch: 5| Step: 5
Training loss: 0.3211913148549902
Validation loss: 2.440379561928476

Epoch: 5| Step: 6
Training loss: 0.33630927162627144
Validation loss: 2.454394301938174

Epoch: 5| Step: 7
Training loss: 0.3964699239869054
Validation loss: 2.456859563648063

Epoch: 5| Step: 8
Training loss: 0.3131846914102644
Validation loss: 2.4735510557685276

Epoch: 5| Step: 9
Training loss: 0.3107771109971366
Validation loss: 2.4536317498251723

Epoch: 5| Step: 10
Training loss: 0.36073665149945433
Validation loss: 2.4672614132496995

Epoch: 498| Step: 0
Training loss: 0.3543223454952426
Validation loss: 2.4220760594116664

Epoch: 5| Step: 1
Training loss: 0.30746463444333316
Validation loss: 2.4681883549897217

Epoch: 5| Step: 2
Training loss: 0.30056167613690177
Validation loss: 2.481342239713204

Epoch: 5| Step: 3
Training loss: 0.27480025623384546
Validation loss: 2.4809456248403556

Epoch: 5| Step: 4
Training loss: 0.2818652549505482
Validation loss: 2.5117268214600594

Epoch: 5| Step: 5
Training loss: 0.4064444663365734
Validation loss: 2.5202674130481597

Epoch: 5| Step: 6
Training loss: 0.3827160694348954
Validation loss: 2.5455733953737294

Epoch: 5| Step: 7
Training loss: 0.16799271767413795
Validation loss: 2.527768701891416

Epoch: 5| Step: 8
Training loss: 0.3900268743804596
Validation loss: 2.499251125316931

Epoch: 5| Step: 9
Training loss: 0.2313211647282621
Validation loss: 2.4566982382781557

Epoch: 5| Step: 10
Training loss: 0.38837379258443594
Validation loss: 2.455242498454406

Epoch: 499| Step: 0
Training loss: 0.36198406993737686
Validation loss: 2.4729242276006502

Epoch: 5| Step: 1
Training loss: 0.2696586805219282
Validation loss: 2.411492477285478

Epoch: 5| Step: 2
Training loss: 0.39157595277222335
Validation loss: 2.4384656181426436

Epoch: 5| Step: 3
Training loss: 0.39486314014183793
Validation loss: 2.4378811433340375

Epoch: 5| Step: 4
Training loss: 0.32092178361960955
Validation loss: 2.4306211576578898

Epoch: 5| Step: 5
Training loss: 0.2741826123283917
Validation loss: 2.427444630398164

Epoch: 5| Step: 6
Training loss: 0.2331513569431793
Validation loss: 2.4462407411158464

Epoch: 5| Step: 7
Training loss: 0.45825470083690245
Validation loss: 2.425310508741089

Epoch: 5| Step: 8
Training loss: 0.24640663631943516
Validation loss: 2.4658958059779836

Epoch: 5| Step: 9
Training loss: 0.1281068972266434
Validation loss: 2.467641775630873

Epoch: 5| Step: 10
Training loss: 0.07539921832646271
Validation loss: 2.4265197229074533

Epoch: 500| Step: 0
Training loss: 0.24039650695071227
Validation loss: 2.4677267844887627

Epoch: 5| Step: 1
Training loss: 0.36642152961804797
Validation loss: 2.457766088034953

Epoch: 5| Step: 2
Training loss: 0.38308427855625565
Validation loss: 2.4619786963911254

Epoch: 5| Step: 3
Training loss: 0.36649567787697573
Validation loss: 2.4663180513011187

Epoch: 5| Step: 4
Training loss: 0.1670254400953939
Validation loss: 2.4812038152522042

Epoch: 5| Step: 5
Training loss: 0.30971564602867335
Validation loss: 2.4425234937317275

Epoch: 5| Step: 6
Training loss: 0.2603746602829481
Validation loss: 2.481044060165587

Epoch: 5| Step: 7
Training loss: 0.20557571172606107
Validation loss: 2.4759555946556966

Epoch: 5| Step: 8
Training loss: 0.2687316866113146
Validation loss: 2.478298183697555

Epoch: 5| Step: 9
Training loss: 0.2800487987109782
Validation loss: 2.5066346341524377

Epoch: 5| Step: 10
Training loss: 0.4882420943773069
Validation loss: 2.5144678245520717

Epoch: 501| Step: 0
Training loss: 0.3107106718509334
Validation loss: 2.4664307205481113

Epoch: 5| Step: 1
Training loss: 0.3791225248709409
Validation loss: 2.505849727028611

Epoch: 5| Step: 2
Training loss: 0.28608507923464277
Validation loss: 2.4608275436314866

Epoch: 5| Step: 3
Training loss: 0.19566692619033035
Validation loss: 2.47201583031966

Epoch: 5| Step: 4
Training loss: 0.3350349211106064
Validation loss: 2.4478243899227636

Epoch: 5| Step: 5
Training loss: 0.2972372003868297
Validation loss: 2.479361659759601

Epoch: 5| Step: 6
Training loss: 0.24635139481246604
Validation loss: 2.4996430429324747

Epoch: 5| Step: 7
Training loss: 0.18598984494418339
Validation loss: 2.469874090667488

Epoch: 5| Step: 8
Training loss: 0.20696198006359753
Validation loss: 2.4832846493961633

Epoch: 5| Step: 9
Training loss: 0.5226678741485327
Validation loss: 2.5009995374835805

Epoch: 5| Step: 10
Training loss: 0.3038747780986181
Validation loss: 2.4780246006418882

Epoch: 502| Step: 0
Training loss: 0.2722912605290399
Validation loss: 2.496577560810271

Epoch: 5| Step: 1
Training loss: 0.1125499410843176
Validation loss: 2.5239730079310987

Epoch: 5| Step: 2
Training loss: 0.21191960868082085
Validation loss: 2.518259539840266

Epoch: 5| Step: 3
Training loss: 0.22548033979927778
Validation loss: 2.51665159096128

Epoch: 5| Step: 4
Training loss: 0.40042713277967684
Validation loss: 2.483361244072342

Epoch: 5| Step: 5
Training loss: 0.41970555256003444
Validation loss: 2.463568013597167

Epoch: 5| Step: 6
Training loss: 0.2992900942614592
Validation loss: 2.4620376099490224

Epoch: 5| Step: 7
Training loss: 0.4284017399361216
Validation loss: 2.4461293978197904

Epoch: 5| Step: 8
Training loss: 0.33493979473506
Validation loss: 2.4525460654188773

Epoch: 5| Step: 9
Training loss: 0.18322828116066514
Validation loss: 2.4267754655022094

Epoch: 5| Step: 10
Training loss: 0.27045328575366195
Validation loss: 2.39917582602473

Epoch: 503| Step: 0
Training loss: 0.28139640388441284
Validation loss: 2.4110716715724636

Epoch: 5| Step: 1
Training loss: 0.3228729305592379
Validation loss: 2.383556302729591

Epoch: 5| Step: 2
Training loss: 0.32558536907070906
Validation loss: 2.4245914463938276

Epoch: 5| Step: 3
Training loss: 0.35453140420183216
Validation loss: 2.418948504668281

Epoch: 5| Step: 4
Training loss: 0.2305009302205329
Validation loss: 2.4201637364442146

Epoch: 5| Step: 5
Training loss: 0.36022694818522016
Validation loss: 2.4418560521044546

Epoch: 5| Step: 6
Training loss: 0.37263254054238526
Validation loss: 2.4701133988235684

Epoch: 5| Step: 7
Training loss: 0.28449713945040134
Validation loss: 2.477600581932864

Epoch: 5| Step: 8
Training loss: 0.3147857399594426
Validation loss: 2.4395173514436057

Epoch: 5| Step: 9
Training loss: 0.29167221552248107
Validation loss: 2.4648643404255304

Epoch: 5| Step: 10
Training loss: 0.20316369348399707
Validation loss: 2.473187006777446

Epoch: 504| Step: 0
Training loss: 0.3128653179130654
Validation loss: 2.4975050895327255

Epoch: 5| Step: 1
Training loss: 0.34149898081525465
Validation loss: 2.488143401164505

Epoch: 5| Step: 2
Training loss: 0.16249373267999112
Validation loss: 2.4858398762358735

Epoch: 5| Step: 3
Training loss: 0.32230707537790915
Validation loss: 2.462839536743738

Epoch: 5| Step: 4
Training loss: 0.09102281943116217
Validation loss: 2.450698916335467

Epoch: 5| Step: 5
Training loss: 0.4273730628858672
Validation loss: 2.4289380403317

Epoch: 5| Step: 6
Training loss: 0.3178553423516726
Validation loss: 2.4629947062364996

Epoch: 5| Step: 7
Training loss: 0.36447231328073276
Validation loss: 2.4503610696692304

Epoch: 5| Step: 8
Training loss: 0.18703522297934544
Validation loss: 2.493006216320337

Epoch: 5| Step: 9
Training loss: 0.17995267457831968
Validation loss: 2.489405752644881

Epoch: 5| Step: 10
Training loss: 0.45783534595133696
Validation loss: 2.4742041501434713

Epoch: 505| Step: 0
Training loss: 0.22836903002566827
Validation loss: 2.4751226886980775

Epoch: 5| Step: 1
Training loss: 0.33740620811004957
Validation loss: 2.4566849100038817

Epoch: 5| Step: 2
Training loss: 0.19697791543123067
Validation loss: 2.5012792032017686

Epoch: 5| Step: 3
Training loss: 0.29459706792867896
Validation loss: 2.4676454149056704

Epoch: 5| Step: 4
Training loss: 0.17336819376611992
Validation loss: 2.4919099913295155

Epoch: 5| Step: 5
Training loss: 0.3482626651684522
Validation loss: 2.4600095177396386

Epoch: 5| Step: 6
Training loss: 0.18736561290507364
Validation loss: 2.460905645671842

Epoch: 5| Step: 7
Training loss: 0.27067425836778786
Validation loss: 2.4596478170452336

Epoch: 5| Step: 8
Training loss: 0.3664148602155191
Validation loss: 2.4285002805341422

Epoch: 5| Step: 9
Training loss: 0.41840831424045233
Validation loss: 2.4577434354153556

Epoch: 5| Step: 10
Training loss: 0.3910975459025478
Validation loss: 2.440087683665745

Epoch: 506| Step: 0
Training loss: 0.3110096320633975
Validation loss: 2.457129614620618

Epoch: 5| Step: 1
Training loss: 0.29125677268704026
Validation loss: 2.4246375633125106

Epoch: 5| Step: 2
Training loss: 0.24425873760351402
Validation loss: 2.4338720756340195

Epoch: 5| Step: 3
Training loss: 0.25453816054993333
Validation loss: 2.427118510188925

Epoch: 5| Step: 4
Training loss: 0.26973467903714493
Validation loss: 2.459510242719152

Epoch: 5| Step: 5
Training loss: 0.26938421966016163
Validation loss: 2.4602648316887943

Epoch: 5| Step: 6
Training loss: 0.4391091590063391
Validation loss: 2.44389014898475

Epoch: 5| Step: 7
Training loss: 0.2600702779496512
Validation loss: 2.4726665515857107

Epoch: 5| Step: 8
Training loss: 0.46417097885256436
Validation loss: 2.4822773595286285

Epoch: 5| Step: 9
Training loss: 0.24065056856971165
Validation loss: 2.513899814714392

Epoch: 5| Step: 10
Training loss: 0.22759275662405606
Validation loss: 2.478769359634959

Epoch: 507| Step: 0
Training loss: 0.16428418168950912
Validation loss: 2.4644792818163817

Epoch: 5| Step: 1
Training loss: 0.34486742896784134
Validation loss: 2.4712355284932332

Epoch: 5| Step: 2
Training loss: 0.4346704774782885
Validation loss: 2.443367549520287

Epoch: 5| Step: 3
Training loss: 0.20118996622162552
Validation loss: 2.465609930358315

Epoch: 5| Step: 4
Training loss: 0.4371847140623577
Validation loss: 2.439337247037556

Epoch: 5| Step: 5
Training loss: 0.25423701822659206
Validation loss: 2.4562890166671654

Epoch: 5| Step: 6
Training loss: 0.23017963767108612
Validation loss: 2.4391455521497485

Epoch: 5| Step: 7
Training loss: 0.16544800378855226
Validation loss: 2.4440236846032044

Epoch: 5| Step: 8
Training loss: 0.18898127481946314
Validation loss: 2.451103052796602

Epoch: 5| Step: 9
Training loss: 0.4254891329676465
Validation loss: 2.479281147683134

Epoch: 5| Step: 10
Training loss: 0.24459703127364799
Validation loss: 2.475414698133432

Epoch: 508| Step: 0
Training loss: 0.17894491918854125
Validation loss: 2.509642925529433

Epoch: 5| Step: 1
Training loss: 0.43260235900954386
Validation loss: 2.474318674956931

Epoch: 5| Step: 2
Training loss: 0.36841596894772316
Validation loss: 2.51203823263349

Epoch: 5| Step: 3
Training loss: 0.2919235914408873
Validation loss: 2.490727874158367

Epoch: 5| Step: 4
Training loss: 0.3494767305011613
Validation loss: 2.452103841647779

Epoch: 5| Step: 5
Training loss: 0.25135763901579194
Validation loss: 2.4660875162135736

Epoch: 5| Step: 6
Training loss: 0.23497826503620478
Validation loss: 2.432199362082635

Epoch: 5| Step: 7
Training loss: 0.34447325133966394
Validation loss: 2.459513707447748

Epoch: 5| Step: 8
Training loss: 0.2615766566557597
Validation loss: 2.45254233788463

Epoch: 5| Step: 9
Training loss: 0.15433439571157945
Validation loss: 2.456580875549655

Epoch: 5| Step: 10
Training loss: 0.3780380409124593
Validation loss: 2.4611462670065616

Epoch: 509| Step: 0
Training loss: 0.20549058761875957
Validation loss: 2.4674503555088823

Epoch: 5| Step: 1
Training loss: 0.39547857482594717
Validation loss: 2.47705656820438

Epoch: 5| Step: 2
Training loss: 0.2094980949125184
Validation loss: 2.489224848863727

Epoch: 5| Step: 3
Training loss: 0.24479881827411637
Validation loss: 2.4998996991371802

Epoch: 5| Step: 4
Training loss: 0.2911477525041594
Validation loss: 2.4971674767324235

Epoch: 5| Step: 5
Training loss: 0.4348331813645064
Validation loss: 2.5123686348645857

Epoch: 5| Step: 6
Training loss: 0.40922611674188386
Validation loss: 2.5341332322224797

Epoch: 5| Step: 7
Training loss: 0.23340988131124482
Validation loss: 2.512212994889901

Epoch: 5| Step: 8
Training loss: 0.3484815274635238
Validation loss: 2.4814408194397815

Epoch: 5| Step: 9
Training loss: 0.24012855587272022
Validation loss: 2.492800795249415

Epoch: 5| Step: 10
Training loss: 0.2237699413071057
Validation loss: 2.4972882689321967

Epoch: 510| Step: 0
Training loss: 0.27049737352411146
Validation loss: 2.445519924556177

Epoch: 5| Step: 1
Training loss: 0.23260571718161835
Validation loss: 2.4409044106831996

Epoch: 5| Step: 2
Training loss: 0.2519901898940157
Validation loss: 2.4876664978731924

Epoch: 5| Step: 3
Training loss: 0.24914181457503487
Validation loss: 2.480545606287254

Epoch: 5| Step: 4
Training loss: 0.21475753788380791
Validation loss: 2.4631316113362116

Epoch: 5| Step: 5
Training loss: 0.33374204265380863
Validation loss: 2.4704504681949193

Epoch: 5| Step: 6
Training loss: 0.3926885269324041
Validation loss: 2.4600919318760517

Epoch: 5| Step: 7
Training loss: 0.29881388811093423
Validation loss: 2.4711171296332135

Epoch: 5| Step: 8
Training loss: 0.432856216013198
Validation loss: 2.4488611797836413

Epoch: 5| Step: 9
Training loss: 0.35277244261068175
Validation loss: 2.4738521012110493

Epoch: 5| Step: 10
Training loss: 0.266019794246586
Validation loss: 2.4892067607492314

Epoch: 511| Step: 0
Training loss: 0.332827163874703
Validation loss: 2.4803902929260224

Epoch: 5| Step: 1
Training loss: 0.2953254893640274
Validation loss: 2.5139623411150978

Epoch: 5| Step: 2
Training loss: 0.3291481053072552
Validation loss: 2.540650521840779

Epoch: 5| Step: 3
Training loss: 0.1779718384713378
Validation loss: 2.5355516699815164

Epoch: 5| Step: 4
Training loss: 0.3563437957429108
Validation loss: 2.4821030515206886

Epoch: 5| Step: 5
Training loss: 0.244669509228741
Validation loss: 2.489113309748328

Epoch: 5| Step: 6
Training loss: 0.4378912742807303
Validation loss: 2.4999816868224096

Epoch: 5| Step: 7
Training loss: 0.292546565718208
Validation loss: 2.4216749528770887

Epoch: 5| Step: 8
Training loss: 0.2550351794603538
Validation loss: 2.4320234750882763

Epoch: 5| Step: 9
Training loss: 0.42872030469527844
Validation loss: 2.399791456548383

Epoch: 5| Step: 10
Training loss: 0.15020674449933064
Validation loss: 2.4368109095819515

Epoch: 512| Step: 0
Training loss: 0.3852269268379592
Validation loss: 2.4674280920662786

Epoch: 5| Step: 1
Training loss: 0.30752001241753524
Validation loss: 2.437503812590784

Epoch: 5| Step: 2
Training loss: 0.48163201849581055
Validation loss: 2.455168894197008

Epoch: 5| Step: 3
Training loss: 0.2835625570918113
Validation loss: 2.456123909543257

Epoch: 5| Step: 4
Training loss: 0.2263424561150328
Validation loss: 2.4591007996961896

Epoch: 5| Step: 5
Training loss: 0.26952923207287804
Validation loss: 2.4421756673582413

Epoch: 5| Step: 6
Training loss: 0.20160615211766134
Validation loss: 2.473928403473631

Epoch: 5| Step: 7
Training loss: 0.22137027943627585
Validation loss: 2.4191859013699517

Epoch: 5| Step: 8
Training loss: 0.2255030475604005
Validation loss: 2.423141968459188

Epoch: 5| Step: 9
Training loss: 0.3745281310383294
Validation loss: 2.4051418035187404

Epoch: 5| Step: 10
Training loss: 0.2537327687280594
Validation loss: 2.3978147519606425

Epoch: 513| Step: 0
Training loss: 0.26180570495886774
Validation loss: 2.454365801259017

Epoch: 5| Step: 1
Training loss: 0.31493665114960434
Validation loss: 2.4009414583250406

Epoch: 5| Step: 2
Training loss: 0.25387634688132327
Validation loss: 2.509434635883641

Epoch: 5| Step: 3
Training loss: 0.26475773204971204
Validation loss: 2.466172294857196

Epoch: 5| Step: 4
Training loss: 0.14827602161197992
Validation loss: 2.492791069483589

Epoch: 5| Step: 5
Training loss: 0.3206454500476932
Validation loss: 2.4718427951848674

Epoch: 5| Step: 6
Training loss: 0.387151033409914
Validation loss: 2.493002678852205

Epoch: 5| Step: 7
Training loss: 0.3359110844007207
Validation loss: 2.4955804337361465

Epoch: 5| Step: 8
Training loss: 0.37469249276596134
Validation loss: 2.469265407491034

Epoch: 5| Step: 9
Training loss: 0.3073175333203217
Validation loss: 2.489462276781038

Epoch: 5| Step: 10
Training loss: 0.23592837076019593
Validation loss: 2.513745986459534

Epoch: 514| Step: 0
Training loss: 0.27692604847250046
Validation loss: 2.505063379683029

Epoch: 5| Step: 1
Training loss: 0.20486159928491765
Validation loss: 2.5241483876104405

Epoch: 5| Step: 2
Training loss: 0.377987504819444
Validation loss: 2.513164721745674

Epoch: 5| Step: 3
Training loss: 0.23576396408573
Validation loss: 2.5518256681220195

Epoch: 5| Step: 4
Training loss: 0.4368049686605166
Validation loss: 2.5116441571725474

Epoch: 5| Step: 5
Training loss: 0.2600752913600555
Validation loss: 2.468828758976207

Epoch: 5| Step: 6
Training loss: 0.23011640511986667
Validation loss: 2.478786971633075

Epoch: 5| Step: 7
Training loss: 0.37568901262373866
Validation loss: 2.481848640247889

Epoch: 5| Step: 8
Training loss: 0.3316437872746002
Validation loss: 2.522062812005912

Epoch: 5| Step: 9
Training loss: 0.2555700223883359
Validation loss: 2.499645340794251

Epoch: 5| Step: 10
Training loss: 0.26491007241698417
Validation loss: 2.472880042703087

Epoch: 515| Step: 0
Training loss: 0.4154616773562139
Validation loss: 2.5030367527335007

Epoch: 5| Step: 1
Training loss: 0.2670324706780137
Validation loss: 2.486264655133757

Epoch: 5| Step: 2
Training loss: 0.128159614864844
Validation loss: 2.4887424180148074

Epoch: 5| Step: 3
Training loss: 0.2725560832275323
Validation loss: 2.4543362181106443

Epoch: 5| Step: 4
Training loss: 0.3323023306571453
Validation loss: 2.471932209332375

Epoch: 5| Step: 5
Training loss: 0.37703632760768785
Validation loss: 2.487430559420555

Epoch: 5| Step: 6
Training loss: 0.20240492834826124
Validation loss: 2.4916259542391703

Epoch: 5| Step: 7
Training loss: 0.39311799842166945
Validation loss: 2.4984238080654464

Epoch: 5| Step: 8
Training loss: 0.21401707522283936
Validation loss: 2.480154821018746

Epoch: 5| Step: 9
Training loss: 0.24765680836515327
Validation loss: 2.4999193650234197

Epoch: 5| Step: 10
Training loss: 0.23460955009746082
Validation loss: 2.4913146546896985

Epoch: 516| Step: 0
Training loss: 0.3040473522165087
Validation loss: 2.5013907061234937

Epoch: 5| Step: 1
Training loss: 0.16208403170928765
Validation loss: 2.4986746689789596

Epoch: 5| Step: 2
Training loss: 0.31733686848198683
Validation loss: 2.4639739004017223

Epoch: 5| Step: 3
Training loss: 0.3496475838182086
Validation loss: 2.444109470346312

Epoch: 5| Step: 4
Training loss: 0.28809326938415686
Validation loss: 2.4844181229634668

Epoch: 5| Step: 5
Training loss: 0.19210896631967606
Validation loss: 2.4353434907213334

Epoch: 5| Step: 6
Training loss: 0.34147669373135575
Validation loss: 2.4410193934931956

Epoch: 5| Step: 7
Training loss: 0.3674776675776219
Validation loss: 2.4865240315289925

Epoch: 5| Step: 8
Training loss: 0.2560093854901076
Validation loss: 2.481375747930285

Epoch: 5| Step: 9
Training loss: 0.210566061203786
Validation loss: 2.459124221167185

Epoch: 5| Step: 10
Training loss: 0.32777090494220606
Validation loss: 2.480258383472906

Epoch: 517| Step: 0
Training loss: 0.4228923152464854
Validation loss: 2.523903889518939

Epoch: 5| Step: 1
Training loss: 0.2894599476163355
Validation loss: 2.5038980212519615

Epoch: 5| Step: 2
Training loss: 0.3295547240584404
Validation loss: 2.4798327819829407

Epoch: 5| Step: 3
Training loss: 0.25451244469776885
Validation loss: 2.5181536247631193

Epoch: 5| Step: 4
Training loss: 0.22662194886128853
Validation loss: 2.4788408141968534

Epoch: 5| Step: 5
Training loss: 0.21365036272064583
Validation loss: 2.495881396097636

Epoch: 5| Step: 6
Training loss: 0.2030469395959215
Validation loss: 2.4850052751047853

Epoch: 5| Step: 7
Training loss: 0.18446167266441993
Validation loss: 2.479469285672517

Epoch: 5| Step: 8
Training loss: 0.1656952965203225
Validation loss: 2.4697255877932984

Epoch: 5| Step: 9
Training loss: 0.37620994953528425
Validation loss: 2.4295247721187443

Epoch: 5| Step: 10
Training loss: 0.2636440544992818
Validation loss: 2.4615193307010683

Epoch: 518| Step: 0
Training loss: 0.16987752335613207
Validation loss: 2.468447636481038

Epoch: 5| Step: 1
Training loss: 0.23938478487200113
Validation loss: 2.4773800076015338

Epoch: 5| Step: 2
Training loss: 0.3272949118587874
Validation loss: 2.457253427664444

Epoch: 5| Step: 3
Training loss: 0.26411042653185746
Validation loss: 2.4418801219169652

Epoch: 5| Step: 4
Training loss: 0.27319259575267496
Validation loss: 2.433725305074628

Epoch: 5| Step: 5
Training loss: 0.20153925044499085
Validation loss: 2.4527782411693764

Epoch: 5| Step: 6
Training loss: 0.23467592947383573
Validation loss: 2.471102502176794

Epoch: 5| Step: 7
Training loss: 0.4184141192695178
Validation loss: 2.473920451178072

Epoch: 5| Step: 8
Training loss: 0.287484397672143
Validation loss: 2.52401289378105

Epoch: 5| Step: 9
Training loss: 0.32887869513337703
Validation loss: 2.4914794547679677

Epoch: 5| Step: 10
Training loss: 0.27965457392126464
Validation loss: 2.5060889991582895

Epoch: 519| Step: 0
Training loss: 0.19554512475785368
Validation loss: 2.5166849308319588

Epoch: 5| Step: 1
Training loss: 0.39808869521224877
Validation loss: 2.5032278603511093

Epoch: 5| Step: 2
Training loss: 0.33574304941187677
Validation loss: 2.5434670425496546

Epoch: 5| Step: 3
Training loss: 0.22605771525642523
Validation loss: 2.5107842077052482

Epoch: 5| Step: 4
Training loss: 0.17023367610716156
Validation loss: 2.4903329722996186

Epoch: 5| Step: 5
Training loss: 0.18860344247950395
Validation loss: 2.4824182873366407

Epoch: 5| Step: 6
Training loss: 0.23370135772724468
Validation loss: 2.43313885604304

Epoch: 5| Step: 7
Training loss: 0.33847175634354093
Validation loss: 2.4527155545761334

Epoch: 5| Step: 8
Training loss: 0.25396610434839123
Validation loss: 2.445399083930707

Epoch: 5| Step: 9
Training loss: 0.38788632700710385
Validation loss: 2.429770961605095

Epoch: 5| Step: 10
Training loss: 0.2121514427942901
Validation loss: 2.466023484856101

Epoch: 520| Step: 0
Training loss: 0.25745242433938237
Validation loss: 2.44199682037229

Epoch: 5| Step: 1
Training loss: 0.15482018251957894
Validation loss: 2.428934764189712

Epoch: 5| Step: 2
Training loss: 0.24341694195364075
Validation loss: 2.473433473066936

Epoch: 5| Step: 3
Training loss: 0.400763287058047
Validation loss: 2.4560283907955265

Epoch: 5| Step: 4
Training loss: 0.34855050362881795
Validation loss: 2.4553889778416256

Epoch: 5| Step: 5
Training loss: 0.23085868306064347
Validation loss: 2.459530160672609

Epoch: 5| Step: 6
Training loss: 0.2638854821651697
Validation loss: 2.4704844097707452

Epoch: 5| Step: 7
Training loss: 0.1449532726752156
Validation loss: 2.5011528945901738

Epoch: 5| Step: 8
Training loss: 0.29948200417984966
Validation loss: 2.47650106295686

Epoch: 5| Step: 9
Training loss: 0.1760766990262659
Validation loss: 2.4649550290257003

Epoch: 5| Step: 10
Training loss: 0.2966566914428847
Validation loss: 2.49788890016065

Epoch: 521| Step: 0
Training loss: 0.2886180683004108
Validation loss: 2.522128894904691

Epoch: 5| Step: 1
Training loss: 0.2229283577461749
Validation loss: 2.495293056256558

Epoch: 5| Step: 2
Training loss: 0.2908920179191205
Validation loss: 2.4944523580962947

Epoch: 5| Step: 3
Training loss: 0.3521190899781906
Validation loss: 2.4650500760338416

Epoch: 5| Step: 4
Training loss: 0.3480058904935801
Validation loss: 2.4570342966954843

Epoch: 5| Step: 5
Training loss: 0.17809044101155827
Validation loss: 2.440188420637769

Epoch: 5| Step: 6
Training loss: 0.27028786155561124
Validation loss: 2.461471396050817

Epoch: 5| Step: 7
Training loss: 0.22246310573790568
Validation loss: 2.449013923377721

Epoch: 5| Step: 8
Training loss: 0.2975486966556971
Validation loss: 2.4682702278110713

Epoch: 5| Step: 9
Training loss: 0.2835868340691962
Validation loss: 2.477354075929076

Epoch: 5| Step: 10
Training loss: 0.3209600532244154
Validation loss: 2.4588067683593247

Epoch: 522| Step: 0
Training loss: 0.2899761966686879
Validation loss: 2.4790070650329743

Epoch: 5| Step: 1
Training loss: 0.30799369174903546
Validation loss: 2.4881084836323915

Epoch: 5| Step: 2
Training loss: 0.23674770813882987
Validation loss: 2.4953999683418244

Epoch: 5| Step: 3
Training loss: 0.11731784644490989
Validation loss: 2.5065660072216813

Epoch: 5| Step: 4
Training loss: 0.2523105953863761
Validation loss: 2.504811503120072

Epoch: 5| Step: 5
Training loss: 0.31383311116951323
Validation loss: 2.513320806164222

Epoch: 5| Step: 6
Training loss: 0.26234759038825883
Validation loss: 2.4882891017950723

Epoch: 5| Step: 7
Training loss: 0.38381313413497103
Validation loss: 2.4701184018396947

Epoch: 5| Step: 8
Training loss: 0.3431568555341088
Validation loss: 2.4819027810171845

Epoch: 5| Step: 9
Training loss: 0.12462231081602734
Validation loss: 2.469615115427149

Epoch: 5| Step: 10
Training loss: 0.18145122703217254
Validation loss: 2.449406565824227

Epoch: 523| Step: 0
Training loss: 0.30048999060639575
Validation loss: 2.432888115887383

Epoch: 5| Step: 1
Training loss: 0.2915438012917311
Validation loss: 2.4250809159864306

Epoch: 5| Step: 2
Training loss: 0.22193750857581743
Validation loss: 2.439949508691266

Epoch: 5| Step: 3
Training loss: 0.27787514940293
Validation loss: 2.4649352703528553

Epoch: 5| Step: 4
Training loss: 0.2246480659663538
Validation loss: 2.417199654904595

Epoch: 5| Step: 5
Training loss: 0.373148000701533
Validation loss: 2.4599106179650083

Epoch: 5| Step: 6
Training loss: 0.26806516942362524
Validation loss: 2.4728980035066632

Epoch: 5| Step: 7
Training loss: 0.11375931460631471
Validation loss: 2.45884992998605

Epoch: 5| Step: 8
Training loss: 0.2877334377823542
Validation loss: 2.4541465085583027

Epoch: 5| Step: 9
Training loss: 0.29463055097799234
Validation loss: 2.4524510308645318

Epoch: 5| Step: 10
Training loss: 0.1573979764266912
Validation loss: 2.494110674880671

Epoch: 524| Step: 0
Training loss: 0.21803395550462462
Validation loss: 2.474483740842263

Epoch: 5| Step: 1
Training loss: 0.1895911805044953
Validation loss: 2.4971128815412946

Epoch: 5| Step: 2
Training loss: 0.21866113697002915
Validation loss: 2.4522905824119348

Epoch: 5| Step: 3
Training loss: 0.27194764383518877
Validation loss: 2.49792565764566

Epoch: 5| Step: 4
Training loss: 0.2996673642256648
Validation loss: 2.4847271953961525

Epoch: 5| Step: 5
Training loss: 0.21801479290830975
Validation loss: 2.4704468205996317

Epoch: 5| Step: 6
Training loss: 0.21379863389299583
Validation loss: 2.4765804786090366

Epoch: 5| Step: 7
Training loss: 0.36963176852167456
Validation loss: 2.4781438638128246

Epoch: 5| Step: 8
Training loss: 0.4150061740186184
Validation loss: 2.4625161218269005

Epoch: 5| Step: 9
Training loss: 0.1957575020083334
Validation loss: 2.4759252050499305

Epoch: 5| Step: 10
Training loss: 0.1442391821046047
Validation loss: 2.4814136253523635

Epoch: 525| Step: 0
Training loss: 0.4462703976390482
Validation loss: 2.485996114455504

Epoch: 5| Step: 1
Training loss: 0.18549038880504423
Validation loss: 2.4489130097957856

Epoch: 5| Step: 2
Training loss: 0.26054767968827053
Validation loss: 2.46642550112923

Epoch: 5| Step: 3
Training loss: 0.28445130571570926
Validation loss: 2.4665777718235558

Epoch: 5| Step: 4
Training loss: 0.2628480403469718
Validation loss: 2.483914954498244

Epoch: 5| Step: 5
Training loss: 0.29585474780755183
Validation loss: 2.4839963814714325

Epoch: 5| Step: 6
Training loss: 0.1943287488671711
Validation loss: 2.4862508411622892

Epoch: 5| Step: 7
Training loss: 0.22023681733995412
Validation loss: 2.46857040674165

Epoch: 5| Step: 8
Training loss: 0.1453177215294335
Validation loss: 2.514643547036624

Epoch: 5| Step: 9
Training loss: 0.3257497465787006
Validation loss: 2.4723902518448972

Epoch: 5| Step: 10
Training loss: 0.15796591789204717
Validation loss: 2.4964381367823547

Epoch: 526| Step: 0
Training loss: 0.19139979799256482
Validation loss: 2.5154470983228507

Epoch: 5| Step: 1
Training loss: 0.2985943646626756
Validation loss: 2.4699403731275047

Epoch: 5| Step: 2
Training loss: 0.34012001690969723
Validation loss: 2.475592457435318

Epoch: 5| Step: 3
Training loss: 0.2970368546424189
Validation loss: 2.491115001249525

Epoch: 5| Step: 4
Training loss: 0.32289674400071383
Validation loss: 2.46497936053518

Epoch: 5| Step: 5
Training loss: 0.3135034306025152
Validation loss: 2.4508502321179906

Epoch: 5| Step: 6
Training loss: 0.204994729660486
Validation loss: 2.4548596854315825

Epoch: 5| Step: 7
Training loss: 0.315936080672852
Validation loss: 2.460775475442872

Epoch: 5| Step: 8
Training loss: 0.1384158390054105
Validation loss: 2.450868395158091

Epoch: 5| Step: 9
Training loss: 0.22323738353296232
Validation loss: 2.4416799913738774

Epoch: 5| Step: 10
Training loss: 0.15636022971094912
Validation loss: 2.425363005868252

Epoch: 527| Step: 0
Training loss: 0.20510241046797503
Validation loss: 2.4306115427517647

Epoch: 5| Step: 1
Training loss: 0.15587305257532114
Validation loss: 2.4311124982342984

Epoch: 5| Step: 2
Training loss: 0.34262531699270665
Validation loss: 2.461712642123734

Epoch: 5| Step: 3
Training loss: 0.27496291148900687
Validation loss: 2.473928967200675

Epoch: 5| Step: 4
Training loss: 0.40635808093856896
Validation loss: 2.4858756558164368

Epoch: 5| Step: 5
Training loss: 0.1528816325467545
Validation loss: 2.4897640121690374

Epoch: 5| Step: 6
Training loss: 0.14908621854235374
Validation loss: 2.4739256019348423

Epoch: 5| Step: 7
Training loss: 0.22433473132707768
Validation loss: 2.4863676970822146

Epoch: 5| Step: 8
Training loss: 0.30115903933394034
Validation loss: 2.4805441573216664

Epoch: 5| Step: 9
Training loss: 0.1982310907424531
Validation loss: 2.46958533501095

Epoch: 5| Step: 10
Training loss: 0.3208431175317101
Validation loss: 2.4987847050743346

Epoch: 528| Step: 0
Training loss: 0.16038355746261823
Validation loss: 2.481995064683133

Epoch: 5| Step: 1
Training loss: 0.11534197681255676
Validation loss: 2.473607470637777

Epoch: 5| Step: 2
Training loss: 0.335176026265464
Validation loss: 2.4886065950208978

Epoch: 5| Step: 3
Training loss: 0.27002509113126927
Validation loss: 2.471282942052108

Epoch: 5| Step: 4
Training loss: 0.32595313041127083
Validation loss: 2.5003217633644104

Epoch: 5| Step: 5
Training loss: 0.19327844024071475
Validation loss: 2.466065498280026

Epoch: 5| Step: 6
Training loss: 0.24589532088167315
Validation loss: 2.5102345260931984

Epoch: 5| Step: 7
Training loss: 0.32261160571683734
Validation loss: 2.5472975153381494

Epoch: 5| Step: 8
Training loss: 0.3349665760866919
Validation loss: 2.543003164268049

Epoch: 5| Step: 9
Training loss: 0.3384258793626063
Validation loss: 2.4978104447517357

Epoch: 5| Step: 10
Training loss: 0.28611392066223207
Validation loss: 2.5150631328279713

Epoch: 529| Step: 0
Training loss: 0.13070807321625133
Validation loss: 2.508547264085852

Epoch: 5| Step: 1
Training loss: 0.16546985449345789
Validation loss: 2.4993038623404584

Epoch: 5| Step: 2
Training loss: 0.281485856026113
Validation loss: 2.508705824184338

Epoch: 5| Step: 3
Training loss: 0.27637421022800074
Validation loss: 2.4704090025539234

Epoch: 5| Step: 4
Training loss: 0.22555160261167045
Validation loss: 2.51209496188414

Epoch: 5| Step: 5
Training loss: 0.2530424242373158
Validation loss: 2.4965947812266767

Epoch: 5| Step: 6
Training loss: 0.19049812456519433
Validation loss: 2.488187684903914

Epoch: 5| Step: 7
Training loss: 0.3210085888163678
Validation loss: 2.480950447396359

Epoch: 5| Step: 8
Training loss: 0.379455738211782
Validation loss: 2.4494404020708935

Epoch: 5| Step: 9
Training loss: 0.41874086953642553
Validation loss: 2.4703487994473763

Epoch: 5| Step: 10
Training loss: 0.43962307504769943
Validation loss: 2.4814623744837263

Epoch: 530| Step: 0
Training loss: 0.21377652132012478
Validation loss: 2.4288679052301756

Epoch: 5| Step: 1
Training loss: 0.2235280087029487
Validation loss: 2.455893034458946

Epoch: 5| Step: 2
Training loss: 0.2947736456027786
Validation loss: 2.475697946276797

Epoch: 5| Step: 3
Training loss: 0.3900663004358296
Validation loss: 2.477401705597513

Epoch: 5| Step: 4
Training loss: 0.29914249763291173
Validation loss: 2.4563203317863502

Epoch: 5| Step: 5
Training loss: 0.2859267967597266
Validation loss: 2.454974177528211

Epoch: 5| Step: 6
Training loss: 0.387479130890538
Validation loss: 2.4481160044535533

Epoch: 5| Step: 7
Training loss: 0.40102238010087915
Validation loss: 2.4362313234894857

Epoch: 5| Step: 8
Training loss: 0.15078833247138926
Validation loss: 2.4295828349981927

Epoch: 5| Step: 9
Training loss: 0.3336290063921193
Validation loss: 2.482101344218719

Epoch: 5| Step: 10
Training loss: 0.2282450696380313
Validation loss: 2.4707668192633774

Epoch: 531| Step: 0
Training loss: 0.31258217208061495
Validation loss: 2.4244836392819655

Epoch: 5| Step: 1
Training loss: 0.23665526895434325
Validation loss: 2.3933863527231436

Epoch: 5| Step: 2
Training loss: 0.29908768594652896
Validation loss: 2.401391129895071

Epoch: 5| Step: 3
Training loss: 0.16959733224441523
Validation loss: 2.373250482074461

Epoch: 5| Step: 4
Training loss: 0.3947416820773164
Validation loss: 2.402551017281784

Epoch: 5| Step: 5
Training loss: 0.32925601583559294
Validation loss: 2.3815760572521

Epoch: 5| Step: 6
Training loss: 0.3506681298097272
Validation loss: 2.4098529272127878

Epoch: 5| Step: 7
Training loss: 0.29020293259279245
Validation loss: 2.458105122224878

Epoch: 5| Step: 8
Training loss: 0.4493934954894466
Validation loss: 2.5015847782062943

Epoch: 5| Step: 9
Training loss: 0.3228788148578579
Validation loss: 2.5270179545773916

Epoch: 5| Step: 10
Training loss: 0.3316433154964158
Validation loss: 2.5402574578040777

Epoch: 532| Step: 0
Training loss: 0.3145210003307983
Validation loss: 2.5176608418908852

Epoch: 5| Step: 1
Training loss: 0.38595633055428036
Validation loss: 2.535799688440806

Epoch: 5| Step: 2
Training loss: 0.2748481195611039
Validation loss: 2.5047058202853596

Epoch: 5| Step: 3
Training loss: 0.423932989832943
Validation loss: 2.508784896868906

Epoch: 5| Step: 4
Training loss: 0.38064952840210875
Validation loss: 2.442728359253058

Epoch: 5| Step: 5
Training loss: 0.4328356464683075
Validation loss: 2.466847741002994

Epoch: 5| Step: 6
Training loss: 0.2613712822555312
Validation loss: 2.476059959144188

Epoch: 5| Step: 7
Training loss: 0.23134731680771484
Validation loss: 2.4589318888031677

Epoch: 5| Step: 8
Training loss: 0.31511871314823214
Validation loss: 2.4800312116586074

Epoch: 5| Step: 9
Training loss: 0.39309866636589086
Validation loss: 2.5184410016211918

Epoch: 5| Step: 10
Training loss: 0.2547831139385794
Validation loss: 2.4983977874922427

Epoch: 533| Step: 0
Training loss: 0.34715417976733903
Validation loss: 2.492423498836588

Epoch: 5| Step: 1
Training loss: 0.36684444309984465
Validation loss: 2.4752541178435084

Epoch: 5| Step: 2
Training loss: 0.25918916686372706
Validation loss: 2.5157450679985267

Epoch: 5| Step: 3
Training loss: 0.3573867280282562
Validation loss: 2.5097885813253127

Epoch: 5| Step: 4
Training loss: 0.3663120994715379
Validation loss: 2.477670929964897

Epoch: 5| Step: 5
Training loss: 0.38143042766321944
Validation loss: 2.519661948434287

Epoch: 5| Step: 6
Training loss: 0.20553851448086652
Validation loss: 2.5448144261966505

Epoch: 5| Step: 7
Training loss: 0.3849697442985209
Validation loss: 2.55585741380656

Epoch: 5| Step: 8
Training loss: 0.4016532157225959
Validation loss: 2.4763054919290277

Epoch: 5| Step: 9
Training loss: 0.3332480405920165
Validation loss: 2.4999432731673434

Epoch: 5| Step: 10
Training loss: 0.19044695066796014
Validation loss: 2.4713164468776987

Epoch: 534| Step: 0
Training loss: 0.29754231142040893
Validation loss: 2.435826838235333

Epoch: 5| Step: 1
Training loss: 0.2978663581550249
Validation loss: 2.4420357198428917

Epoch: 5| Step: 2
Training loss: 0.2995161102838648
Validation loss: 2.4360346137467888

Epoch: 5| Step: 3
Training loss: 0.42578674452849913
Validation loss: 2.39331087826796

Epoch: 5| Step: 4
Training loss: 0.4603383486004032
Validation loss: 2.3781343064999185

Epoch: 5| Step: 5
Training loss: 0.3961718976880825
Validation loss: 2.398153983803188

Epoch: 5| Step: 6
Training loss: 0.37615807845661703
Validation loss: 2.3698612058691966

Epoch: 5| Step: 7
Training loss: 0.1964575959721384
Validation loss: 2.3923053244894765

Epoch: 5| Step: 8
Training loss: 0.19630923570811293
Validation loss: 2.4339738935170177

Epoch: 5| Step: 9
Training loss: 0.4415056572440429
Validation loss: 2.467452360746558

Epoch: 5| Step: 10
Training loss: 0.3159103510555809
Validation loss: 2.5150807109746753

Epoch: 535| Step: 0
Training loss: 0.2084075418072749
Validation loss: 2.4870510917940156

Epoch: 5| Step: 1
Training loss: 0.47477298632312187
Validation loss: 2.510931919428957

Epoch: 5| Step: 2
Training loss: 0.2879367118602753
Validation loss: 2.4446663402321125

Epoch: 5| Step: 3
Training loss: 0.25257604317908905
Validation loss: 2.431369521754597

Epoch: 5| Step: 4
Training loss: 0.45121972957324835
Validation loss: 2.3922872901397505

Epoch: 5| Step: 5
Training loss: 0.3453385861067411
Validation loss: 2.412340621023508

Epoch: 5| Step: 6
Training loss: 0.2631569815293579
Validation loss: 2.4200622628578112

Epoch: 5| Step: 7
Training loss: 0.3443689193119515
Validation loss: 2.4510194431743253

Epoch: 5| Step: 8
Training loss: 0.4230818616888932
Validation loss: 2.4522102301027324

Epoch: 5| Step: 9
Training loss: 0.2547624237926278
Validation loss: 2.5105620665362256

Epoch: 5| Step: 10
Training loss: 0.35054725709864154
Validation loss: 2.5474509015814744

Epoch: 536| Step: 0
Training loss: 0.2649099739796666
Validation loss: 2.5335284549242814

Epoch: 5| Step: 1
Training loss: 0.25102316575844297
Validation loss: 2.5570399081471633

Epoch: 5| Step: 2
Training loss: 0.37846683309764295
Validation loss: 2.5345269860752424

Epoch: 5| Step: 3
Training loss: 0.3514383414691076
Validation loss: 2.516392662986954

Epoch: 5| Step: 4
Training loss: 0.3067390138264543
Validation loss: 2.476449567583251

Epoch: 5| Step: 5
Training loss: 0.1523102943658304
Validation loss: 2.4587137040300604

Epoch: 5| Step: 6
Training loss: 0.3290376799298721
Validation loss: 2.4160511228680117

Epoch: 5| Step: 7
Training loss: 0.31254279320493533
Validation loss: 2.471479111235869

Epoch: 5| Step: 8
Training loss: 0.39539744403101745
Validation loss: 2.4463465451442903

Epoch: 5| Step: 9
Training loss: 0.2577970384527551
Validation loss: 2.490104115389135

Epoch: 5| Step: 10
Training loss: 0.41169171615533473
Validation loss: 2.483638802685132

Epoch: 537| Step: 0
Training loss: 0.27902614036253887
Validation loss: 2.4952478768595197

Epoch: 5| Step: 1
Training loss: 0.4023980409602945
Validation loss: 2.490976997393012

Epoch: 5| Step: 2
Training loss: 0.2585679026936676
Validation loss: 2.474762706375319

Epoch: 5| Step: 3
Training loss: 0.3647432952732651
Validation loss: 2.5128890450833725

Epoch: 5| Step: 4
Training loss: 0.16188069955814627
Validation loss: 2.480742287759615

Epoch: 5| Step: 5
Training loss: 0.2876502023047696
Validation loss: 2.4887319143734405

Epoch: 5| Step: 6
Training loss: 0.24017856694002193
Validation loss: 2.4507218819892347

Epoch: 5| Step: 7
Training loss: 0.2935028167399362
Validation loss: 2.475368039483335

Epoch: 5| Step: 8
Training loss: 0.19504886954749312
Validation loss: 2.46347706060128

Epoch: 5| Step: 9
Training loss: 0.30895375125331315
Validation loss: 2.4526017101626585

Epoch: 5| Step: 10
Training loss: 0.35941080246756885
Validation loss: 2.472804217646577

Epoch: 538| Step: 0
Training loss: 0.3079965825231873
Validation loss: 2.462957198444265

Epoch: 5| Step: 1
Training loss: 0.21034291142461023
Validation loss: 2.474605514943316

Epoch: 5| Step: 2
Training loss: 0.23244602815164467
Validation loss: 2.474395549246136

Epoch: 5| Step: 3
Training loss: 0.2076431265387582
Validation loss: 2.4570011741132576

Epoch: 5| Step: 4
Training loss: 0.3170653295836243
Validation loss: 2.452965207026448

Epoch: 5| Step: 5
Training loss: 0.21332142489942546
Validation loss: 2.460164250392833

Epoch: 5| Step: 6
Training loss: 0.18654431730511248
Validation loss: 2.4554572758674675

Epoch: 5| Step: 7
Training loss: 0.32854707002681605
Validation loss: 2.4676536305254166

Epoch: 5| Step: 8
Training loss: 0.21516101126849743
Validation loss: 2.4366708107117065

Epoch: 5| Step: 9
Training loss: 0.3066673024229702
Validation loss: 2.4284371298144602

Epoch: 5| Step: 10
Training loss: 0.31411127499319463
Validation loss: 2.4555104199497384

Epoch: 539| Step: 0
Training loss: 0.27909993517583453
Validation loss: 2.421942069996905

Epoch: 5| Step: 1
Training loss: 0.3949350424664574
Validation loss: 2.4466367059320984

Epoch: 5| Step: 2
Training loss: 0.32902528235361994
Validation loss: 2.416749741339605

Epoch: 5| Step: 3
Training loss: 0.17309101136040544
Validation loss: 2.436717002019596

Epoch: 5| Step: 4
Training loss: 0.17230699176583697
Validation loss: 2.4665981918726017

Epoch: 5| Step: 5
Training loss: 0.2797658224565863
Validation loss: 2.4400846672918406

Epoch: 5| Step: 6
Training loss: 0.3290153752788113
Validation loss: 2.4737352966045068

Epoch: 5| Step: 7
Training loss: 0.24915595922832298
Validation loss: 2.473789866766552

Epoch: 5| Step: 8
Training loss: 0.2491349737172964
Validation loss: 2.504718411203525

Epoch: 5| Step: 9
Training loss: 0.28488716075094195
Validation loss: 2.5134794848412874

Epoch: 5| Step: 10
Training loss: 0.36896177530792307
Validation loss: 2.50888249078619

Epoch: 540| Step: 0
Training loss: 0.26815792946355693
Validation loss: 2.5153862458939664

Epoch: 5| Step: 1
Training loss: 0.26497829474322626
Validation loss: 2.5281824534529975

Epoch: 5| Step: 2
Training loss: 0.21491959706870392
Validation loss: 2.4915973752742784

Epoch: 5| Step: 3
Training loss: 0.36710606341543733
Validation loss: 2.5097077817696443

Epoch: 5| Step: 4
Training loss: 0.11122965640741837
Validation loss: 2.4909641224338026

Epoch: 5| Step: 5
Training loss: 0.21086090957970788
Validation loss: 2.5031058533245174

Epoch: 5| Step: 6
Training loss: 0.292121667126344
Validation loss: 2.4967210421686925

Epoch: 5| Step: 7
Training loss: 0.33299247505016805
Validation loss: 2.481178118825185

Epoch: 5| Step: 8
Training loss: 0.30304726459254894
Validation loss: 2.479541483095206

Epoch: 5| Step: 9
Training loss: 0.2389651396343861
Validation loss: 2.4738806375026834

Epoch: 5| Step: 10
Training loss: 0.2100278082527145
Validation loss: 2.427665437489422

Epoch: 541| Step: 0
Training loss: 0.32576685445984316
Validation loss: 2.433214556444045

Epoch: 5| Step: 1
Training loss: 0.26403074920097513
Validation loss: 2.452212895975334

Epoch: 5| Step: 2
Training loss: 0.2600892281332285
Validation loss: 2.4548294764182543

Epoch: 5| Step: 3
Training loss: 0.15672085269989253
Validation loss: 2.448857466531006

Epoch: 5| Step: 4
Training loss: 0.167424128539939
Validation loss: 2.4664755110545182

Epoch: 5| Step: 5
Training loss: 0.2621738974096896
Validation loss: 2.510010167915815

Epoch: 5| Step: 6
Training loss: 0.33756380316968876
Validation loss: 2.4849674434018487

Epoch: 5| Step: 7
Training loss: 0.2602394486467816
Validation loss: 2.4908141103604557

Epoch: 5| Step: 8
Training loss: 0.3746086502465963
Validation loss: 2.4937574875567794

Epoch: 5| Step: 9
Training loss: 0.16479803011753336
Validation loss: 2.510920529219778

Epoch: 5| Step: 10
Training loss: 0.19594287235250474
Validation loss: 2.503346231050835

Epoch: 542| Step: 0
Training loss: 0.25606064487629776
Validation loss: 2.4776238538723208

Epoch: 5| Step: 1
Training loss: 0.2525680047464044
Validation loss: 2.5065541369243975

Epoch: 5| Step: 2
Training loss: 0.3635815640429135
Validation loss: 2.4878965857605944

Epoch: 5| Step: 3
Training loss: 0.2913641666573349
Validation loss: 2.490260675956144

Epoch: 5| Step: 4
Training loss: 0.33964899116808805
Validation loss: 2.4690342681452018

Epoch: 5| Step: 5
Training loss: 0.2170653871255828
Validation loss: 2.4459850795486213

Epoch: 5| Step: 6
Training loss: 0.23235077932636308
Validation loss: 2.460853919794151

Epoch: 5| Step: 7
Training loss: 0.2139081959186595
Validation loss: 2.4574566176908776

Epoch: 5| Step: 8
Training loss: 0.24063545953633453
Validation loss: 2.4636145070645687

Epoch: 5| Step: 9
Training loss: 0.21004139445398912
Validation loss: 2.4376339219595557

Epoch: 5| Step: 10
Training loss: 0.17471005099710954
Validation loss: 2.409746194295301

Epoch: 543| Step: 0
Training loss: 0.2600349378265856
Validation loss: 2.422059913533275

Epoch: 5| Step: 1
Training loss: 0.2514730507705798
Validation loss: 2.472104236440039

Epoch: 5| Step: 2
Training loss: 0.18557790195650498
Validation loss: 2.4457997723760805

Epoch: 5| Step: 3
Training loss: 0.23337873271936008
Validation loss: 2.4617616376735287

Epoch: 5| Step: 4
Training loss: 0.2840302851321955
Validation loss: 2.479692129563001

Epoch: 5| Step: 5
Training loss: 0.26075173121213197
Validation loss: 2.4634233442978

Epoch: 5| Step: 6
Training loss: 0.43006497188900517
Validation loss: 2.4721769196078567

Epoch: 5| Step: 7
Training loss: 0.22161492901665653
Validation loss: 2.468244277290228

Epoch: 5| Step: 8
Training loss: 0.20442584618520063
Validation loss: 2.461494215371835

Epoch: 5| Step: 9
Training loss: 0.20020006685891784
Validation loss: 2.422302971484244

Epoch: 5| Step: 10
Training loss: 0.12391677159353794
Validation loss: 2.399691392214382

Epoch: 544| Step: 0
Training loss: 0.28679959459296106
Validation loss: 2.4564926903456543

Epoch: 5| Step: 1
Training loss: 0.19533145812531924
Validation loss: 2.4386843913593905

Epoch: 5| Step: 2
Training loss: 0.3067136665385485
Validation loss: 2.459252582066611

Epoch: 5| Step: 3
Training loss: 0.1704997780688651
Validation loss: 2.4523278911197632

Epoch: 5| Step: 4
Training loss: 0.30792252660620356
Validation loss: 2.4456991166364426

Epoch: 5| Step: 5
Training loss: 0.17373541706450957
Validation loss: 2.4620424445509537

Epoch: 5| Step: 6
Training loss: 0.20162411199067887
Validation loss: 2.4842783518993437

Epoch: 5| Step: 7
Training loss: 0.2779407389113036
Validation loss: 2.4659997115153365

Epoch: 5| Step: 8
Training loss: 0.2737994115035265
Validation loss: 2.4707278242833914

Epoch: 5| Step: 9
Training loss: 0.20868837481998265
Validation loss: 2.464360979672127

Epoch: 5| Step: 10
Training loss: 0.25970202936687625
Validation loss: 2.4827843902224753

Epoch: 545| Step: 0
Training loss: 0.27963313954340896
Validation loss: 2.4802029734154254

Epoch: 5| Step: 1
Training loss: 0.2256309332292018
Validation loss: 2.491194194408246

Epoch: 5| Step: 2
Training loss: 0.2861196495387492
Validation loss: 2.4969417262630187

Epoch: 5| Step: 3
Training loss: 0.17773745607493197
Validation loss: 2.4545811467884917

Epoch: 5| Step: 4
Training loss: 0.27951557426786966
Validation loss: 2.4762530710802455

Epoch: 5| Step: 5
Training loss: 0.20817795363349195
Validation loss: 2.4903367945958657

Epoch: 5| Step: 6
Training loss: 0.18358308679984334
Validation loss: 2.45890173398957

Epoch: 5| Step: 7
Training loss: 0.0937593226963194
Validation loss: 2.4616717884955412

Epoch: 5| Step: 8
Training loss: 0.23030985996332598
Validation loss: 2.469166405003718

Epoch: 5| Step: 9
Training loss: 0.34205826709706494
Validation loss: 2.4572395001560863

Epoch: 5| Step: 10
Training loss: 0.19622921387119402
Validation loss: 2.435990806871463

Epoch: 546| Step: 0
Training loss: 0.2705307823371877
Validation loss: 2.451099922376886

Epoch: 5| Step: 1
Training loss: 0.25531393253853685
Validation loss: 2.458336514331337

Epoch: 5| Step: 2
Training loss: 0.16354152865211674
Validation loss: 2.4502212815413467

Epoch: 5| Step: 3
Training loss: 0.23418189676879586
Validation loss: 2.426055316219774

Epoch: 5| Step: 4
Training loss: 0.18127261587978608
Validation loss: 2.4511867965768968

Epoch: 5| Step: 5
Training loss: 0.13318675967055038
Validation loss: 2.443710922345455

Epoch: 5| Step: 6
Training loss: 0.3459525528573064
Validation loss: 2.4415411384317847

Epoch: 5| Step: 7
Training loss: 0.23329456364173495
Validation loss: 2.44697470012322

Epoch: 5| Step: 8
Training loss: 0.30340548545811014
Validation loss: 2.4098838739598754

Epoch: 5| Step: 9
Training loss: 0.22914148683642768
Validation loss: 2.4095668862245416

Epoch: 5| Step: 10
Training loss: 0.2371442668575076
Validation loss: 2.4523831733674326

Epoch: 547| Step: 0
Training loss: 0.34027995692201946
Validation loss: 2.4724064078519046

Epoch: 5| Step: 1
Training loss: 0.16893674023881128
Validation loss: 2.4565265075190896

Epoch: 5| Step: 2
Training loss: 0.14398598271102106
Validation loss: 2.447675948568137

Epoch: 5| Step: 3
Training loss: 0.22417615492557164
Validation loss: 2.440321437625129

Epoch: 5| Step: 4
Training loss: 0.3085221074636311
Validation loss: 2.464641211630725

Epoch: 5| Step: 5
Training loss: 0.3219181268002876
Validation loss: 2.497943754465892

Epoch: 5| Step: 6
Training loss: 0.19397393252672315
Validation loss: 2.482741484637701

Epoch: 5| Step: 7
Training loss: 0.13219427224435235
Validation loss: 2.4904832881969727

Epoch: 5| Step: 8
Training loss: 0.2679075871946709
Validation loss: 2.4904794012748486

Epoch: 5| Step: 9
Training loss: 0.24410709150806922
Validation loss: 2.4368612737277235

Epoch: 5| Step: 10
Training loss: 0.1480958985762245
Validation loss: 2.4215725850519507

Epoch: 548| Step: 0
Training loss: 0.3172092726239367
Validation loss: 2.445109198286447

Epoch: 5| Step: 1
Training loss: 0.11351249375458301
Validation loss: 2.410111276027446

Epoch: 5| Step: 2
Training loss: 0.29923283217636276
Validation loss: 2.4307242776660147

Epoch: 5| Step: 3
Training loss: 0.273867731862363
Validation loss: 2.4611532647675385

Epoch: 5| Step: 4
Training loss: 0.27123402640777783
Validation loss: 2.4572234463082054

Epoch: 5| Step: 5
Training loss: 0.27376648321997504
Validation loss: 2.407807105111857

Epoch: 5| Step: 6
Training loss: 0.2515134893974719
Validation loss: 2.4742247683582

Epoch: 5| Step: 7
Training loss: 0.13668617814213707
Validation loss: 2.4959178524102983

Epoch: 5| Step: 8
Training loss: 0.20870042387812368
Validation loss: 2.5092291993721343

Epoch: 5| Step: 9
Training loss: 0.2648042030403195
Validation loss: 2.5161673564298854

Epoch: 5| Step: 10
Training loss: 0.27059345748714625
Validation loss: 2.5229967721000826

Epoch: 549| Step: 0
Training loss: 0.2299368750202616
Validation loss: 2.510619443855492

Epoch: 5| Step: 1
Training loss: 0.12863011116089756
Validation loss: 2.452518243618854

Epoch: 5| Step: 2
Training loss: 0.20672510111387998
Validation loss: 2.5002021851357

Epoch: 5| Step: 3
Training loss: 0.2727273301870473
Validation loss: 2.473731898430325

Epoch: 5| Step: 4
Training loss: 0.19716345152231401
Validation loss: 2.455828308255437

Epoch: 5| Step: 5
Training loss: 0.4159791240887306
Validation loss: 2.4414220849620882

Epoch: 5| Step: 6
Training loss: 0.27559406801121705
Validation loss: 2.455582121189367

Epoch: 5| Step: 7
Training loss: 0.23945904268603657
Validation loss: 2.467715705983121

Epoch: 5| Step: 8
Training loss: 0.17799994780507555
Validation loss: 2.472979618035673

Epoch: 5| Step: 9
Training loss: 0.1425387903066113
Validation loss: 2.4601807696056155

Epoch: 5| Step: 10
Training loss: 0.30241055551412377
Validation loss: 2.472045614641668

Epoch: 550| Step: 0
Training loss: 0.25328001409154977
Validation loss: 2.4909686137540694

Epoch: 5| Step: 1
Training loss: 0.1808680336611806
Validation loss: 2.4755211452273547

Epoch: 5| Step: 2
Training loss: 0.303306445156639
Validation loss: 2.510417474777125

Epoch: 5| Step: 3
Training loss: 0.2716585876476603
Validation loss: 2.505237372380609

Epoch: 5| Step: 4
Training loss: 0.32911634553482905
Validation loss: 2.4862953380232526

Epoch: 5| Step: 5
Training loss: 0.2093014851368897
Validation loss: 2.4969598389413243

Epoch: 5| Step: 6
Training loss: 0.30575835507253585
Validation loss: 2.4942275783201326

Epoch: 5| Step: 7
Training loss: 0.15559732497460627
Validation loss: 2.4242730660042535

Epoch: 5| Step: 8
Training loss: 0.17152163637310658
Validation loss: 2.4379212304980253

Epoch: 5| Step: 9
Training loss: 0.2257103267404073
Validation loss: 2.4001253647773964

Epoch: 5| Step: 10
Training loss: 0.31544793374401725
Validation loss: 2.4505945278540064

Epoch: 551| Step: 0
Training loss: 0.16112732733435858
Validation loss: 2.418311712995901

Epoch: 5| Step: 1
Training loss: 0.19314219097363317
Validation loss: 2.4314259463629804

Epoch: 5| Step: 2
Training loss: 0.2650177971693702
Validation loss: 2.451792066217491

Epoch: 5| Step: 3
Training loss: 0.24051620265544624
Validation loss: 2.442204757479449

Epoch: 5| Step: 4
Training loss: 0.12548586178833238
Validation loss: 2.455706253408546

Epoch: 5| Step: 5
Training loss: 0.1826827293729716
Validation loss: 2.5099975841366615

Epoch: 5| Step: 6
Training loss: 0.3044424049344126
Validation loss: 2.498379542607867

Epoch: 5| Step: 7
Training loss: 0.2751631372078323
Validation loss: 2.5016941257569627

Epoch: 5| Step: 8
Training loss: 0.2965830572096106
Validation loss: 2.4940750545540027

Epoch: 5| Step: 9
Training loss: 0.19430103659534914
Validation loss: 2.5012062054677284

Epoch: 5| Step: 10
Training loss: 0.31160053506935026
Validation loss: 2.5096850320695467

Epoch: 552| Step: 0
Training loss: 0.3393349840307338
Validation loss: 2.549535466379618

Epoch: 5| Step: 1
Training loss: 0.18568771437982787
Validation loss: 2.5153975896376517

Epoch: 5| Step: 2
Training loss: 0.25039038873860703
Validation loss: 2.4752077249377016

Epoch: 5| Step: 3
Training loss: 0.26947136918681475
Validation loss: 2.4834660457533384

Epoch: 5| Step: 4
Training loss: 0.23419956157940142
Validation loss: 2.5215201734157695

Epoch: 5| Step: 5
Training loss: 0.26317020304343036
Validation loss: 2.489990261530135

Epoch: 5| Step: 6
Training loss: 0.26230261568229774
Validation loss: 2.474125725998907

Epoch: 5| Step: 7
Training loss: 0.22720082565328853
Validation loss: 2.4750558101277744

Epoch: 5| Step: 8
Training loss: 0.19818413170917912
Validation loss: 2.4707558794188444

Epoch: 5| Step: 9
Training loss: 0.2081302139413834
Validation loss: 2.470465602285236

Epoch: 5| Step: 10
Training loss: 0.16621850463818957
Validation loss: 2.480566586221946

Epoch: 553| Step: 0
Training loss: 0.29915648228321406
Validation loss: 2.4802173061049793

Epoch: 5| Step: 1
Training loss: 0.23220933283999096
Validation loss: 2.500919132062016

Epoch: 5| Step: 2
Training loss: 0.20264054260322825
Validation loss: 2.485112102633615

Epoch: 5| Step: 3
Training loss: 0.29816264182798935
Validation loss: 2.5047822128135655

Epoch: 5| Step: 4
Training loss: 0.21891486392611834
Validation loss: 2.4860013979709374

Epoch: 5| Step: 5
Training loss: 0.2366526716055706
Validation loss: 2.488594698808424

Epoch: 5| Step: 6
Training loss: 0.2377315653454104
Validation loss: 2.4467394768098076

Epoch: 5| Step: 7
Training loss: 0.1848493414619216
Validation loss: 2.4734090651045397

Epoch: 5| Step: 8
Training loss: 0.25890553570443375
Validation loss: 2.4616744326661038

Epoch: 5| Step: 9
Training loss: 0.11893843081255907
Validation loss: 2.4285132422693296

Epoch: 5| Step: 10
Training loss: 0.2746251336428595
Validation loss: 2.406691732400787

Epoch: 554| Step: 0
Training loss: 0.18910992398025142
Validation loss: 2.423210291974832

Epoch: 5| Step: 1
Training loss: 0.26340817581271087
Validation loss: 2.4337833973045764

Epoch: 5| Step: 2
Training loss: 0.29261343708519744
Validation loss: 2.449999127483066

Epoch: 5| Step: 3
Training loss: 0.2885849849028717
Validation loss: 2.49154849106745

Epoch: 5| Step: 4
Training loss: 0.1317218993727919
Validation loss: 2.480692735964925

Epoch: 5| Step: 5
Training loss: 0.32848365800524626
Validation loss: 2.5020988718862367

Epoch: 5| Step: 6
Training loss: 0.22545335019154783
Validation loss: 2.483047341107486

Epoch: 5| Step: 7
Training loss: 0.2520611996956488
Validation loss: 2.497631050928667

Epoch: 5| Step: 8
Training loss: 0.111876334243682
Validation loss: 2.478845617060962

Epoch: 5| Step: 9
Training loss: 0.2961376092278486
Validation loss: 2.4660729956267797

Epoch: 5| Step: 10
Training loss: 0.18629953416959602
Validation loss: 2.478023659201105

Epoch: 555| Step: 0
Training loss: 0.22911297736385877
Validation loss: 2.4704264531172186

Epoch: 5| Step: 1
Training loss: 0.1658555100179773
Validation loss: 2.466250320152723

Epoch: 5| Step: 2
Training loss: 0.1218520616683915
Validation loss: 2.462586441675786

Epoch: 5| Step: 3
Training loss: 0.2705719248680366
Validation loss: 2.447994963144982

Epoch: 5| Step: 4
Training loss: 0.25133346532970813
Validation loss: 2.443420053189966

Epoch: 5| Step: 5
Training loss: 0.342915410475595
Validation loss: 2.421217462816141

Epoch: 5| Step: 6
Training loss: 0.22862443208285
Validation loss: 2.4252368374947992

Epoch: 5| Step: 7
Training loss: 0.2441375350756613
Validation loss: 2.41399802747647

Epoch: 5| Step: 8
Training loss: 0.25864864354495987
Validation loss: 2.4169747817779106

Epoch: 5| Step: 9
Training loss: 0.3482398160895426
Validation loss: 2.4338288133832844

Epoch: 5| Step: 10
Training loss: 0.1962926304431247
Validation loss: 2.474189355984135

Epoch: 556| Step: 0
Training loss: 0.2875478471456498
Validation loss: 2.457076326100195

Epoch: 5| Step: 1
Training loss: 0.3032987932086862
Validation loss: 2.471391210234425

Epoch: 5| Step: 2
Training loss: 0.2505074804135192
Validation loss: 2.4668401566361893

Epoch: 5| Step: 3
Training loss: 0.18342095217564836
Validation loss: 2.461945347722764

Epoch: 5| Step: 4
Training loss: 0.23007697411137604
Validation loss: 2.4685726120214517

Epoch: 5| Step: 5
Training loss: 0.19903752555063606
Validation loss: 2.4868612955477576

Epoch: 5| Step: 6
Training loss: 0.19307384216159496
Validation loss: 2.4562553689595257

Epoch: 5| Step: 7
Training loss: 0.30025005499150825
Validation loss: 2.471345173755542

Epoch: 5| Step: 8
Training loss: 0.2822111184933507
Validation loss: 2.4519920787209912

Epoch: 5| Step: 9
Training loss: 0.19668915999481462
Validation loss: 2.4624404747619146

Epoch: 5| Step: 10
Training loss: 0.20981555607296973
Validation loss: 2.4395938065136282

Epoch: 557| Step: 0
Training loss: 0.25482659432432553
Validation loss: 2.4180178685574854

Epoch: 5| Step: 1
Training loss: 0.1455219057157848
Validation loss: 2.415460472944347

Epoch: 5| Step: 2
Training loss: 0.2828404175694075
Validation loss: 2.3837292647029775

Epoch: 5| Step: 3
Training loss: 0.16662298067075504
Validation loss: 2.4375202092925554

Epoch: 5| Step: 4
Training loss: 0.3698149481236702
Validation loss: 2.4281240280626015

Epoch: 5| Step: 5
Training loss: 0.21947912907490696
Validation loss: 2.4399040909639313

Epoch: 5| Step: 6
Training loss: 0.19030732356080018
Validation loss: 2.4563454877536017

Epoch: 5| Step: 7
Training loss: 0.24410375698187944
Validation loss: 2.491049157683305

Epoch: 5| Step: 8
Training loss: 0.23968150712022607
Validation loss: 2.4789626638297784

Epoch: 5| Step: 9
Training loss: 0.35408884016138825
Validation loss: 2.4870824958060815

Epoch: 5| Step: 10
Training loss: 0.24294289331752492
Validation loss: 2.4777250637271955

Epoch: 558| Step: 0
Training loss: 0.20044068906451795
Validation loss: 2.518603195129632

Epoch: 5| Step: 1
Training loss: 0.21342973081989827
Validation loss: 2.5058960411469875

Epoch: 5| Step: 2
Training loss: 0.410210633078516
Validation loss: 2.504587075238732

Epoch: 5| Step: 3
Training loss: 0.28201330767168786
Validation loss: 2.4906041390084512

Epoch: 5| Step: 4
Training loss: 0.16481362695854765
Validation loss: 2.495922010756478

Epoch: 5| Step: 5
Training loss: 0.29169829514992296
Validation loss: 2.425761677412359

Epoch: 5| Step: 6
Training loss: 0.16633229067250432
Validation loss: 2.4418538578672755

Epoch: 5| Step: 7
Training loss: 0.25635349811981917
Validation loss: 2.446172193097132

Epoch: 5| Step: 8
Training loss: 0.1901738330921104
Validation loss: 2.4403013166645207

Epoch: 5| Step: 9
Training loss: 0.18039202442179825
Validation loss: 2.435905220912234

Epoch: 5| Step: 10
Training loss: 0.2196419107768974
Validation loss: 2.435334835560022

Epoch: 559| Step: 0
Training loss: 0.27186378203739625
Validation loss: 2.4338704766971637

Epoch: 5| Step: 1
Training loss: 0.16872997562492262
Validation loss: 2.463801177634942

Epoch: 5| Step: 2
Training loss: 0.22268627198582241
Validation loss: 2.4771812098036623

Epoch: 5| Step: 3
Training loss: 0.23386654537858895
Validation loss: 2.4629244167801967

Epoch: 5| Step: 4
Training loss: 0.29258831755094916
Validation loss: 2.468918952025748

Epoch: 5| Step: 5
Training loss: 0.21669414595124117
Validation loss: 2.4768224012865963

Epoch: 5| Step: 6
Training loss: 0.18286687946933303
Validation loss: 2.4636865426819754

Epoch: 5| Step: 7
Training loss: 0.2058883103767952
Validation loss: 2.4826029616136918

Epoch: 5| Step: 8
Training loss: 0.28432045560210617
Validation loss: 2.449788207090613

Epoch: 5| Step: 9
Training loss: 0.2376267010503984
Validation loss: 2.4820862903710355

Epoch: 5| Step: 10
Training loss: 0.3012184458348274
Validation loss: 2.477547099412443

Epoch: 560| Step: 0
Training loss: 0.28061389514556395
Validation loss: 2.467309673108914

Epoch: 5| Step: 1
Training loss: 0.12223131624695845
Validation loss: 2.467269461820421

Epoch: 5| Step: 2
Training loss: 0.1688419974301615
Validation loss: 2.454107328878987

Epoch: 5| Step: 3
Training loss: 0.27483719482325125
Validation loss: 2.431192829208452

Epoch: 5| Step: 4
Training loss: 0.358018013183982
Validation loss: 2.440013902783606

Epoch: 5| Step: 5
Training loss: 0.2129193732773309
Validation loss: 2.4037347514335585

Epoch: 5| Step: 6
Training loss: 0.275211790199333
Validation loss: 2.4291519932333703

Epoch: 5| Step: 7
Training loss: 0.21800156691517417
Validation loss: 2.4211827056442536

Epoch: 5| Step: 8
Training loss: 0.24202706037211186
Validation loss: 2.433805067903548

Epoch: 5| Step: 9
Training loss: 0.18405752246518778
Validation loss: 2.4225134741977987

Epoch: 5| Step: 10
Training loss: 0.19157867061573697
Validation loss: 2.41377744004822

Epoch: 561| Step: 0
Training loss: 0.2598139782409974
Validation loss: 2.4547902376685315

Epoch: 5| Step: 1
Training loss: 0.2468240437854523
Validation loss: 2.420443824576714

Epoch: 5| Step: 2
Training loss: 0.1500193111585431
Validation loss: 2.4447875243197292

Epoch: 5| Step: 3
Training loss: 0.16238942717146476
Validation loss: 2.459395583924614

Epoch: 5| Step: 4
Training loss: 0.28510964679062206
Validation loss: 2.444675862108883

Epoch: 5| Step: 5
Training loss: 0.3040795373995064
Validation loss: 2.4669884809204334

Epoch: 5| Step: 6
Training loss: 0.14896284799025392
Validation loss: 2.463135987918951

Epoch: 5| Step: 7
Training loss: 0.2681087328460009
Validation loss: 2.432881913543791

Epoch: 5| Step: 8
Training loss: 0.18387223489032065
Validation loss: 2.4752077306342026

Epoch: 5| Step: 9
Training loss: 0.33444132414477656
Validation loss: 2.4889266341244687

Epoch: 5| Step: 10
Training loss: 0.14819563434997646
Validation loss: 2.479730994947136

Epoch: 562| Step: 0
Training loss: 0.18298911912156038
Validation loss: 2.4691239438926766

Epoch: 5| Step: 1
Training loss: 0.2724937911376208
Validation loss: 2.4498097151844678

Epoch: 5| Step: 2
Training loss: 0.17997106692118872
Validation loss: 2.456266882719758

Epoch: 5| Step: 3
Training loss: 0.18056479123735866
Validation loss: 2.472036152558207

Epoch: 5| Step: 4
Training loss: 0.17913540735644193
Validation loss: 2.4583061874445393

Epoch: 5| Step: 5
Training loss: 0.2295106677467188
Validation loss: 2.448058714156557

Epoch: 5| Step: 6
Training loss: 0.17625662315213902
Validation loss: 2.4260945685088866

Epoch: 5| Step: 7
Training loss: 0.22032220426789986
Validation loss: 2.4301872930354396

Epoch: 5| Step: 8
Training loss: 0.3060577343738558
Validation loss: 2.4456177049605206

Epoch: 5| Step: 9
Training loss: 0.2546981347092876
Validation loss: 2.4201360805004746

Epoch: 5| Step: 10
Training loss: 0.33132977154913357
Validation loss: 2.432854723572672

Epoch: 563| Step: 0
Training loss: 0.12926045795222468
Validation loss: 2.4337222555339615

Epoch: 5| Step: 1
Training loss: 0.30927037049632883
Validation loss: 2.469376457153857

Epoch: 5| Step: 2
Training loss: 0.15337566421368073
Validation loss: 2.458170987819369

Epoch: 5| Step: 3
Training loss: 0.23021280495082344
Validation loss: 2.48859182261135

Epoch: 5| Step: 4
Training loss: 0.17969473533990452
Validation loss: 2.454457482521011

Epoch: 5| Step: 5
Training loss: 0.24607267743671093
Validation loss: 2.4728218643543363

Epoch: 5| Step: 6
Training loss: 0.31505497503800795
Validation loss: 2.4863814371982693

Epoch: 5| Step: 7
Training loss: 0.2448547904149103
Validation loss: 2.457461595878746

Epoch: 5| Step: 8
Training loss: 0.2516800783359466
Validation loss: 2.4530460336334663

Epoch: 5| Step: 9
Training loss: 0.23758668980061165
Validation loss: 2.4844837367436106

Epoch: 5| Step: 10
Training loss: 0.18168417090734182
Validation loss: 2.4596198212570255

Epoch: 564| Step: 0
Training loss: 0.2535478262883166
Validation loss: 2.4337477219780443

Epoch: 5| Step: 1
Training loss: 0.37427333123151857
Validation loss: 2.450330485567361

Epoch: 5| Step: 2
Training loss: 0.14560891805512224
Validation loss: 2.4505031022260564

Epoch: 5| Step: 3
Training loss: 0.1811348528785128
Validation loss: 2.4764449453748

Epoch: 5| Step: 4
Training loss: 0.09778546844147318
Validation loss: 2.434150925531847

Epoch: 5| Step: 5
Training loss: 0.19118544434910384
Validation loss: 2.4459108157133733

Epoch: 5| Step: 6
Training loss: 0.1750603037627968
Validation loss: 2.5180353453881725

Epoch: 5| Step: 7
Training loss: 0.2792892588397283
Validation loss: 2.4927446646039835

Epoch: 5| Step: 8
Training loss: 0.2057945905950649
Validation loss: 2.4841682325852763

Epoch: 5| Step: 9
Training loss: 0.26531024123130076
Validation loss: 2.4625605947034104

Epoch: 5| Step: 10
Training loss: 0.21316531597074395
Validation loss: 2.494671346875905

Epoch: 565| Step: 0
Training loss: 0.192851884102587
Validation loss: 2.479578971616266

Epoch: 5| Step: 1
Training loss: 0.1843030093968299
Validation loss: 2.4682240588566384

Epoch: 5| Step: 2
Training loss: 0.16451971740009272
Validation loss: 2.4535365985023074

Epoch: 5| Step: 3
Training loss: 0.28368055943354575
Validation loss: 2.4543250091775417

Epoch: 5| Step: 4
Training loss: 0.15760822057920487
Validation loss: 2.4418136357856066

Epoch: 5| Step: 5
Training loss: 0.234812947230945
Validation loss: 2.4706691833159513

Epoch: 5| Step: 6
Training loss: 0.2977141266471136
Validation loss: 2.474401514915202

Epoch: 5| Step: 7
Training loss: 0.20497219437922687
Validation loss: 2.4823467973642757

Epoch: 5| Step: 8
Training loss: 0.19584474521893572
Validation loss: 2.4784962071622867

Epoch: 5| Step: 9
Training loss: 0.33004197368495974
Validation loss: 2.518201568995582

Epoch: 5| Step: 10
Training loss: 0.18961848092110523
Validation loss: 2.486992618211085

Epoch: 566| Step: 0
Training loss: 0.2725431803517564
Validation loss: 2.485504419940119

Epoch: 5| Step: 1
Training loss: 0.21381325237606785
Validation loss: 2.511010069511557

Epoch: 5| Step: 2
Training loss: 0.169922823190784
Validation loss: 2.4574785333259026

Epoch: 5| Step: 3
Training loss: 0.2168142466415644
Validation loss: 2.477995659967974

Epoch: 5| Step: 4
Training loss: 0.25114306259420044
Validation loss: 2.493199206393421

Epoch: 5| Step: 5
Training loss: 0.17436536534159455
Validation loss: 2.512635184924308

Epoch: 5| Step: 6
Training loss: 0.136958511472926
Validation loss: 2.458474067787855

Epoch: 5| Step: 7
Training loss: 0.28907732023445987
Validation loss: 2.462173065800071

Epoch: 5| Step: 8
Training loss: 0.2121565701297823
Validation loss: 2.4537046024847737

Epoch: 5| Step: 9
Training loss: 0.22967627426533907
Validation loss: 2.4626715521685556

Epoch: 5| Step: 10
Training loss: 0.342102023557718
Validation loss: 2.416528298865534

Epoch: 567| Step: 0
Training loss: 0.18531826391471223
Validation loss: 2.446255836869495

Epoch: 5| Step: 1
Training loss: 0.14627099071971078
Validation loss: 2.4340229671495237

Epoch: 5| Step: 2
Training loss: 0.35220495437993815
Validation loss: 2.4545103787794558

Epoch: 5| Step: 3
Training loss: 0.26660235897406354
Validation loss: 2.4742048557598704

Epoch: 5| Step: 4
Training loss: 0.12656938804909065
Validation loss: 2.4845197721465855

Epoch: 5| Step: 5
Training loss: 0.1852562485437717
Validation loss: 2.4971484380026365

Epoch: 5| Step: 6
Training loss: 0.24971424848728527
Validation loss: 2.4947581044351668

Epoch: 5| Step: 7
Training loss: 0.2710962883558356
Validation loss: 2.490963171474944

Epoch: 5| Step: 8
Training loss: 0.25597699206493885
Validation loss: 2.532512556025346

Epoch: 5| Step: 9
Training loss: 0.2382973602977331
Validation loss: 2.5134059846555536

Epoch: 5| Step: 10
Training loss: 0.11875189227554063
Validation loss: 2.458580054939165

Epoch: 568| Step: 0
Training loss: 0.11066175850254945
Validation loss: 2.468277619790635

Epoch: 5| Step: 1
Training loss: 0.2668451167847944
Validation loss: 2.4767260334583976

Epoch: 5| Step: 2
Training loss: 0.2344193257696234
Validation loss: 2.4739639532589943

Epoch: 5| Step: 3
Training loss: 0.16552965618307494
Validation loss: 2.498183240443454

Epoch: 5| Step: 4
Training loss: 0.18940948691636608
Validation loss: 2.44837851233383

Epoch: 5| Step: 5
Training loss: 0.19171519550550897
Validation loss: 2.4542507715527213

Epoch: 5| Step: 6
Training loss: 0.2800898864702649
Validation loss: 2.472676579416569

Epoch: 5| Step: 7
Training loss: 0.24895229445333103
Validation loss: 2.4655677220116305

Epoch: 5| Step: 8
Training loss: 0.23882654987548282
Validation loss: 2.5078268014002147

Epoch: 5| Step: 9
Training loss: 0.20012568681945744
Validation loss: 2.4966852311307317

Epoch: 5| Step: 10
Training loss: 0.22020462587592562
Validation loss: 2.49911981285315

Epoch: 569| Step: 0
Training loss: 0.1881086781382159
Validation loss: 2.518605292983379

Epoch: 5| Step: 1
Training loss: 0.1715163314084038
Validation loss: 2.4917014683785577

Epoch: 5| Step: 2
Training loss: 0.15510843614932202
Validation loss: 2.4979749106986606

Epoch: 5| Step: 3
Training loss: 0.10343612461097655
Validation loss: 2.5295548570711417

Epoch: 5| Step: 4
Training loss: 0.20506559061164734
Validation loss: 2.4763851281466693

Epoch: 5| Step: 5
Training loss: 0.11451447831156335
Validation loss: 2.5185624841045966

Epoch: 5| Step: 6
Training loss: 0.27499569651097444
Validation loss: 2.496590939759464

Epoch: 5| Step: 7
Training loss: 0.31245476872215483
Validation loss: 2.465174302949078

Epoch: 5| Step: 8
Training loss: 0.19740351965608632
Validation loss: 2.464109241488788

Epoch: 5| Step: 9
Training loss: 0.26507020962671635
Validation loss: 2.447836441334742

Epoch: 5| Step: 10
Training loss: 0.25248413904815137
Validation loss: 2.4467160923809947

Epoch: 570| Step: 0
Training loss: 0.1952266695258218
Validation loss: 2.445539981614246

Epoch: 5| Step: 1
Training loss: 0.2436411899008924
Validation loss: 2.424488057080726

Epoch: 5| Step: 2
Training loss: 0.18889038827089094
Validation loss: 2.46953196905592

Epoch: 5| Step: 3
Training loss: 0.23759171509438914
Validation loss: 2.4590245945803417

Epoch: 5| Step: 4
Training loss: 0.24818713060090725
Validation loss: 2.4509052490632555

Epoch: 5| Step: 5
Training loss: 0.24940552663274
Validation loss: 2.484395118983279

Epoch: 5| Step: 6
Training loss: 0.2512471858858632
Validation loss: 2.444577860508532

Epoch: 5| Step: 7
Training loss: 0.13323934767310092
Validation loss: 2.4715389808165353

Epoch: 5| Step: 8
Training loss: 0.24310170948342738
Validation loss: 2.4683608395724486

Epoch: 5| Step: 9
Training loss: 0.146423187192175
Validation loss: 2.4866687136128687

Epoch: 5| Step: 10
Training loss: 0.1891286568713587
Validation loss: 2.472046269021594

Epoch: 571| Step: 0
Training loss: 0.13006425674788205
Validation loss: 2.483686186936116

Epoch: 5| Step: 1
Training loss: 0.16481667834176217
Validation loss: 2.4749148971031603

Epoch: 5| Step: 2
Training loss: 0.3013671271768486
Validation loss: 2.484798103080784

Epoch: 5| Step: 3
Training loss: 0.27565642982133676
Validation loss: 2.4914080912904337

Epoch: 5| Step: 4
Training loss: 0.11586649522361721
Validation loss: 2.463924813581996

Epoch: 5| Step: 5
Training loss: 0.15377844863243895
Validation loss: 2.4967377574386407

Epoch: 5| Step: 6
Training loss: 0.16599757152455694
Validation loss: 2.4733625474155363

Epoch: 5| Step: 7
Training loss: 0.21596349739108905
Validation loss: 2.5119621214958157

Epoch: 5| Step: 8
Training loss: 0.2065912555497249
Validation loss: 2.4967256596974763

Epoch: 5| Step: 9
Training loss: 0.31588796859343565
Validation loss: 2.4958698899544993

Epoch: 5| Step: 10
Training loss: 0.11997397344197346
Validation loss: 2.5105864431222327

Epoch: 572| Step: 0
Training loss: 0.19404578473256107
Validation loss: 2.4969794093980493

Epoch: 5| Step: 1
Training loss: 0.22643539546501332
Validation loss: 2.5047290537885663

Epoch: 5| Step: 2
Training loss: 0.2196270017766073
Validation loss: 2.4743567337115215

Epoch: 5| Step: 3
Training loss: 0.23644915547533682
Validation loss: 2.4743554044158005

Epoch: 5| Step: 4
Training loss: 0.1381782490266167
Validation loss: 2.4738662124002158

Epoch: 5| Step: 5
Training loss: 0.10599276384022756
Validation loss: 2.497366153565872

Epoch: 5| Step: 6
Training loss: 0.24379797732301975
Validation loss: 2.497188395042184

Epoch: 5| Step: 7
Training loss: 0.17319060334991046
Validation loss: 2.4490780315092406

Epoch: 5| Step: 8
Training loss: 0.09232865171400072
Validation loss: 2.484590386524182

Epoch: 5| Step: 9
Training loss: 0.3400464166134118
Validation loss: 2.4799200622729836

Epoch: 5| Step: 10
Training loss: 0.21886889598478496
Validation loss: 2.48922367529791

Epoch: 573| Step: 0
Training loss: 0.18643311115959904
Validation loss: 2.4595500513644204

Epoch: 5| Step: 1
Training loss: 0.2610357967415946
Validation loss: 2.483123608597793

Epoch: 5| Step: 2
Training loss: 0.332853376537833
Validation loss: 2.4800210419687403

Epoch: 5| Step: 3
Training loss: 0.14361385501501567
Validation loss: 2.4658244301115744

Epoch: 5| Step: 4
Training loss: 0.23216573240946123
Validation loss: 2.465340936215601

Epoch: 5| Step: 5
Training loss: 0.10964740312371751
Validation loss: 2.4553869627521627

Epoch: 5| Step: 6
Training loss: 0.13760402710720074
Validation loss: 2.440739546904658

Epoch: 5| Step: 7
Training loss: 0.1126598092322446
Validation loss: 2.447415893970522

Epoch: 5| Step: 8
Training loss: 0.23815967241057356
Validation loss: 2.459454965879095

Epoch: 5| Step: 9
Training loss: 0.25744243996981836
Validation loss: 2.459411904515133

Epoch: 5| Step: 10
Training loss: 0.15886403597727697
Validation loss: 2.436996037646874

Epoch: 574| Step: 0
Training loss: 0.25220081072048534
Validation loss: 2.446238070830868

Epoch: 5| Step: 1
Training loss: 0.22378146132858862
Validation loss: 2.449002676999681

Epoch: 5| Step: 2
Training loss: 0.1475926247012088
Validation loss: 2.4860784740425017

Epoch: 5| Step: 3
Training loss: 0.18730700017080107
Validation loss: 2.4387091558011718

Epoch: 5| Step: 4
Training loss: 0.29327765391954314
Validation loss: 2.4581042534609643

Epoch: 5| Step: 5
Training loss: 0.15836197331070176
Validation loss: 2.4429366486100528

Epoch: 5| Step: 6
Training loss: 0.2183220457812592
Validation loss: 2.470015818522939

Epoch: 5| Step: 7
Training loss: 0.2173595086945268
Validation loss: 2.461982695733113

Epoch: 5| Step: 8
Training loss: 0.2904263873961381
Validation loss: 2.4774528257303983

Epoch: 5| Step: 9
Training loss: 0.11964327278286145
Validation loss: 2.485281607234873

Epoch: 5| Step: 10
Training loss: 0.15337272525692278
Validation loss: 2.510042651760715

Epoch: 575| Step: 0
Training loss: 0.26389464398572304
Validation loss: 2.496826749298952

Epoch: 5| Step: 1
Training loss: 0.1205510931951952
Validation loss: 2.4860325543448734

Epoch: 5| Step: 2
Training loss: 0.1555803971545619
Validation loss: 2.4996704448350227

Epoch: 5| Step: 3
Training loss: 0.19567720694627294
Validation loss: 2.48059284912951

Epoch: 5| Step: 4
Training loss: 0.06560085099240907
Validation loss: 2.480738077616198

Epoch: 5| Step: 5
Training loss: 0.2646046000416708
Validation loss: 2.453426708559594

Epoch: 5| Step: 6
Training loss: 0.3689778690705526
Validation loss: 2.461832261280669

Epoch: 5| Step: 7
Training loss: 0.12272431085871549
Validation loss: 2.4352345105004716

Epoch: 5| Step: 8
Training loss: 0.3028897409768102
Validation loss: 2.4370252763822227

Epoch: 5| Step: 9
Training loss: 0.11848877200872422
Validation loss: 2.4096057293884736

Epoch: 5| Step: 10
Training loss: 0.21078109240685095
Validation loss: 2.3967771970623284

Epoch: 576| Step: 0
Training loss: 0.14860710693720675
Validation loss: 2.416474591077214

Epoch: 5| Step: 1
Training loss: 0.2877502036835507
Validation loss: 2.4238926173912483

Epoch: 5| Step: 2
Training loss: 0.24409708779284442
Validation loss: 2.4362064754570123

Epoch: 5| Step: 3
Training loss: 0.1719284949716117
Validation loss: 2.438607915136351

Epoch: 5| Step: 4
Training loss: 0.18102508763855243
Validation loss: 2.46890061701618

Epoch: 5| Step: 5
Training loss: 0.13171478638845294
Validation loss: 2.4575166463279277

Epoch: 5| Step: 6
Training loss: 0.2072628003936987
Validation loss: 2.486787893143509

Epoch: 5| Step: 7
Training loss: 0.10703046756653305
Validation loss: 2.487671767535551

Epoch: 5| Step: 8
Training loss: 0.2997833641993303
Validation loss: 2.4932897126458324

Epoch: 5| Step: 9
Training loss: 0.34116254527772666
Validation loss: 2.5025819520057304

Epoch: 5| Step: 10
Training loss: 0.22788282957138756
Validation loss: 2.5031234415722943

Epoch: 577| Step: 0
Training loss: 0.20229181558450965
Validation loss: 2.5015510526179727

Epoch: 5| Step: 1
Training loss: 0.1423746381383288
Validation loss: 2.4636140200630785

Epoch: 5| Step: 2
Training loss: 0.11093066187724225
Validation loss: 2.498302214444008

Epoch: 5| Step: 3
Training loss: 0.18278073825591712
Validation loss: 2.4723803141009624

Epoch: 5| Step: 4
Training loss: 0.24080941143871976
Validation loss: 2.4776204879341703

Epoch: 5| Step: 5
Training loss: 0.2776982097445082
Validation loss: 2.461747503961291

Epoch: 5| Step: 6
Training loss: 0.28987402025281744
Validation loss: 2.458346872794727

Epoch: 5| Step: 7
Training loss: 0.18285065277270993
Validation loss: 2.4775905740314745

Epoch: 5| Step: 8
Training loss: 0.18518635710261544
Validation loss: 2.448904672681036

Epoch: 5| Step: 9
Training loss: 0.2258096881631207
Validation loss: 2.4391940582351865

Epoch: 5| Step: 10
Training loss: 0.2089316043004833
Validation loss: 2.4228590856421115

Epoch: 578| Step: 0
Training loss: 0.2551627248116551
Validation loss: 2.436510096980429

Epoch: 5| Step: 1
Training loss: 0.26577834303228803
Validation loss: 2.4690004997637844

Epoch: 5| Step: 2
Training loss: 0.19900301865044578
Validation loss: 2.485390923204479

Epoch: 5| Step: 3
Training loss: 0.2460323893025127
Validation loss: 2.4698275406528674

Epoch: 5| Step: 4
Training loss: 0.19523063851483097
Validation loss: 2.4679890248105854

Epoch: 5| Step: 5
Training loss: 0.19736302681084963
Validation loss: 2.4861359962127962

Epoch: 5| Step: 6
Training loss: 0.08628406867673752
Validation loss: 2.5022644585478075

Epoch: 5| Step: 7
Training loss: 0.1961977162540291
Validation loss: 2.4818058403767433

Epoch: 5| Step: 8
Training loss: 0.18294554783980724
Validation loss: 2.45960463919335

Epoch: 5| Step: 9
Training loss: 0.2582107992950658
Validation loss: 2.4383934913913032

Epoch: 5| Step: 10
Training loss: 0.18271992083559788
Validation loss: 2.428700822084867

Epoch: 579| Step: 0
Training loss: 0.20645723299457588
Validation loss: 2.462816182354159

Epoch: 5| Step: 1
Training loss: 0.1972611115194223
Validation loss: 2.437982718074672

Epoch: 5| Step: 2
Training loss: 0.11880286602240182
Validation loss: 2.395368459434631

Epoch: 5| Step: 3
Training loss: 0.220947215043373
Validation loss: 2.4102770429940876

Epoch: 5| Step: 4
Training loss: 0.27763744707042204
Validation loss: 2.439647941889414

Epoch: 5| Step: 5
Training loss: 0.20509005920562753
Validation loss: 2.4012206604353916

Epoch: 5| Step: 6
Training loss: 0.1633508039020196
Validation loss: 2.4456810745375286

Epoch: 5| Step: 7
Training loss: 0.1363095699897917
Validation loss: 2.4249037678590892

Epoch: 5| Step: 8
Training loss: 0.10361755049500342
Validation loss: 2.4537070828484597

Epoch: 5| Step: 9
Training loss: 0.24279066317788278
Validation loss: 2.474059237552647

Epoch: 5| Step: 10
Training loss: 0.2773632929189279
Validation loss: 2.485812943753812

Epoch: 580| Step: 0
Training loss: 0.23863259193558833
Validation loss: 2.467887213627173

Epoch: 5| Step: 1
Training loss: 0.17484659086958632
Validation loss: 2.4898247780436096

Epoch: 5| Step: 2
Training loss: 0.22986629105852646
Validation loss: 2.4984179479832647

Epoch: 5| Step: 3
Training loss: 0.24413149244393556
Validation loss: 2.470514542542475

Epoch: 5| Step: 4
Training loss: 0.2993886589725148
Validation loss: 2.4595585478292654

Epoch: 5| Step: 5
Training loss: 0.20271383449745356
Validation loss: 2.4517080963370343

Epoch: 5| Step: 6
Training loss: 0.20246860930480168
Validation loss: 2.450175881575951

Epoch: 5| Step: 7
Training loss: 0.09137483223959712
Validation loss: 2.447142245278698

Epoch: 5| Step: 8
Training loss: 0.1750784812933834
Validation loss: 2.4076190021810433

Epoch: 5| Step: 9
Training loss: 0.1489452536938239
Validation loss: 2.4703350780851836

Epoch: 5| Step: 10
Training loss: 0.21723097222058516
Validation loss: 2.4442031001793754

Epoch: 581| Step: 0
Training loss: 0.2646790096177782
Validation loss: 2.4354759260117427

Epoch: 5| Step: 1
Training loss: 0.38286012236545525
Validation loss: 2.4593709928628966

Epoch: 5| Step: 2
Training loss: 0.11705083030064403
Validation loss: 2.434463326918493

Epoch: 5| Step: 3
Training loss: 0.1235952118257863
Validation loss: 2.4457665636829815

Epoch: 5| Step: 4
Training loss: 0.17140059673059116
Validation loss: 2.461803665514086

Epoch: 5| Step: 5
Training loss: 0.12386147368914721
Validation loss: 2.4661157774713387

Epoch: 5| Step: 6
Training loss: 0.1657533593585344
Validation loss: 2.483999607698122

Epoch: 5| Step: 7
Training loss: 0.2275205039777125
Validation loss: 2.486767770838685

Epoch: 5| Step: 8
Training loss: 0.16841738137495887
Validation loss: 2.4773971503586805

Epoch: 5| Step: 9
Training loss: 0.16366195034081057
Validation loss: 2.4880729819045997

Epoch: 5| Step: 10
Training loss: 0.09618505466617276
Validation loss: 2.4540633327360455

Epoch: 582| Step: 0
Training loss: 0.29804549860605223
Validation loss: 2.487103016535614

Epoch: 5| Step: 1
Training loss: 0.18909075581026075
Validation loss: 2.4782185205078107

Epoch: 5| Step: 2
Training loss: 0.11547552754123092
Validation loss: 2.4487197351133028

Epoch: 5| Step: 3
Training loss: 0.10735982923698907
Validation loss: 2.450613895306605

Epoch: 5| Step: 4
Training loss: 0.27983052949331894
Validation loss: 2.4762552550240433

Epoch: 5| Step: 5
Training loss: 0.2026255133414664
Validation loss: 2.4640578934251125

Epoch: 5| Step: 6
Training loss: 0.13242398263159866
Validation loss: 2.441773511732853

Epoch: 5| Step: 7
Training loss: 0.122020161817328
Validation loss: 2.4620931744988774

Epoch: 5| Step: 8
Training loss: 0.20017134360133526
Validation loss: 2.4594400069068203

Epoch: 5| Step: 9
Training loss: 0.23764884387934349
Validation loss: 2.416688119823494

Epoch: 5| Step: 10
Training loss: 0.1097293206584949
Validation loss: 2.431867616584006

Epoch: 583| Step: 0
Training loss: 0.24591734028001896
Validation loss: 2.453855315027239

Epoch: 5| Step: 1
Training loss: 0.13438883920863964
Validation loss: 2.440701481777543

Epoch: 5| Step: 2
Training loss: 0.3050814307274286
Validation loss: 2.470109493858914

Epoch: 5| Step: 3
Training loss: 0.1848387406187137
Validation loss: 2.4501426715089365

Epoch: 5| Step: 4
Training loss: 0.1491207784813007
Validation loss: 2.469756240785456

Epoch: 5| Step: 5
Training loss: 0.19523847130687036
Validation loss: 2.4557119753054275

Epoch: 5| Step: 6
Training loss: 0.18657972075825613
Validation loss: 2.445569652822537

Epoch: 5| Step: 7
Training loss: 0.21976635890421828
Validation loss: 2.4610483045971456

Epoch: 5| Step: 8
Training loss: 0.18416160664648232
Validation loss: 2.4478789941685553

Epoch: 5| Step: 9
Training loss: 0.1722839270058018
Validation loss: 2.464957863120697

Epoch: 5| Step: 10
Training loss: 0.16716615638681967
Validation loss: 2.449858747344384

Epoch: 584| Step: 0
Training loss: 0.25631847397140445
Validation loss: 2.4823656085539065

Epoch: 5| Step: 1
Training loss: 0.1800049900151364
Validation loss: 2.4437959223215544

Epoch: 5| Step: 2
Training loss: 0.22321884286860671
Validation loss: 2.4600510919752527

Epoch: 5| Step: 3
Training loss: 0.12534724373419528
Validation loss: 2.4654258985870867

Epoch: 5| Step: 4
Training loss: 0.16319927685822244
Validation loss: 2.4554807978670654

Epoch: 5| Step: 5
Training loss: 0.2662197355074597
Validation loss: 2.4826192236101225

Epoch: 5| Step: 6
Training loss: 0.17420914499465856
Validation loss: 2.4518117509638135

Epoch: 5| Step: 7
Training loss: 0.20163928979241666
Validation loss: 2.4915211305152942

Epoch: 5| Step: 8
Training loss: 0.2641338257702901
Validation loss: 2.501064168388213

Epoch: 5| Step: 9
Training loss: 0.13022915117420028
Validation loss: 2.517587018275534

Epoch: 5| Step: 10
Training loss: 0.17937073567934
Validation loss: 2.50310139709654

Epoch: 585| Step: 0
Training loss: 0.1683309774501479
Validation loss: 2.475977284426275

Epoch: 5| Step: 1
Training loss: 0.126013639449803
Validation loss: 2.515680217092337

Epoch: 5| Step: 2
Training loss: 0.29703139903603093
Validation loss: 2.4901950929114336

Epoch: 5| Step: 3
Training loss: 0.2175851358486109
Validation loss: 2.511829941572038

Epoch: 5| Step: 4
Training loss: 0.2949290622062791
Validation loss: 2.4682257310954334

Epoch: 5| Step: 5
Training loss: 0.2150696520482223
Validation loss: 2.4647459927955992

Epoch: 5| Step: 6
Training loss: 0.224327217010937
Validation loss: 2.4560872414551977

Epoch: 5| Step: 7
Training loss: 0.15196519058494287
Validation loss: 2.452136573510095

Epoch: 5| Step: 8
Training loss: 0.16468987967167106
Validation loss: 2.464439161138795

Epoch: 5| Step: 9
Training loss: 0.20093453860436644
Validation loss: 2.475799525832007

Epoch: 5| Step: 10
Training loss: 0.20006301043766192
Validation loss: 2.4846491787162237

Epoch: 586| Step: 0
Training loss: 0.21135372140824024
Validation loss: 2.4473188296424304

Epoch: 5| Step: 1
Training loss: 0.32716781786549143
Validation loss: 2.5059687795065986

Epoch: 5| Step: 2
Training loss: 0.13024506209837572
Validation loss: 2.471795231605614

Epoch: 5| Step: 3
Training loss: 0.11227513629386493
Validation loss: 2.4999779936119286

Epoch: 5| Step: 4
Training loss: 0.17551080774620684
Validation loss: 2.50514053035687

Epoch: 5| Step: 5
Training loss: 0.15025628269884325
Validation loss: 2.4618996089343717

Epoch: 5| Step: 6
Training loss: 0.25869616874553353
Validation loss: 2.5138350176764535

Epoch: 5| Step: 7
Training loss: 0.21717957063649346
Validation loss: 2.4930707392696405

Epoch: 5| Step: 8
Training loss: 0.24246960791155692
Validation loss: 2.525096195142608

Epoch: 5| Step: 9
Training loss: 0.14654064369314615
Validation loss: 2.493063539057722

Epoch: 5| Step: 10
Training loss: 0.1343918121710345
Validation loss: 2.5173334796328697

Epoch: 587| Step: 0
Training loss: 0.15951840806697307
Validation loss: 2.5162504133759005

Epoch: 5| Step: 1
Training loss: 0.21149059473931445
Validation loss: 2.451290704376318

Epoch: 5| Step: 2
Training loss: 0.15702298413057536
Validation loss: 2.527222264083079

Epoch: 5| Step: 3
Training loss: 0.20392992021116058
Validation loss: 2.4926904158116274

Epoch: 5| Step: 4
Training loss: 0.21406766126494547
Validation loss: 2.4555411624336596

Epoch: 5| Step: 5
Training loss: 0.2637439487992495
Validation loss: 2.465149763813136

Epoch: 5| Step: 6
Training loss: 0.09518635641551973
Validation loss: 2.457299354653627

Epoch: 5| Step: 7
Training loss: 0.22577063525634347
Validation loss: 2.4376044554687852

Epoch: 5| Step: 8
Training loss: 0.32980528395310915
Validation loss: 2.4834672545568406

Epoch: 5| Step: 9
Training loss: 0.1568343322785772
Validation loss: 2.4482169430338283

Epoch: 5| Step: 10
Training loss: 0.15082052638372923
Validation loss: 2.487909105636029

Epoch: 588| Step: 0
Training loss: 0.21843845457269567
Validation loss: 2.4576197534580024

Epoch: 5| Step: 1
Training loss: 0.18671205979496006
Validation loss: 2.4807435325097793

Epoch: 5| Step: 2
Training loss: 0.22529711543823763
Validation loss: 2.465434705989252

Epoch: 5| Step: 3
Training loss: 0.20562774938988881
Validation loss: 2.475825142436629

Epoch: 5| Step: 4
Training loss: 0.2667451548677074
Validation loss: 2.4748308882410672

Epoch: 5| Step: 5
Training loss: 0.17087903593832143
Validation loss: 2.4768881402061957

Epoch: 5| Step: 6
Training loss: 0.22117817651792335
Validation loss: 2.4792322439853365

Epoch: 5| Step: 7
Training loss: 0.15744668940113032
Validation loss: 2.482787349557048

Epoch: 5| Step: 8
Training loss: 0.2263378229588407
Validation loss: 2.481198776211075

Epoch: 5| Step: 9
Training loss: 0.1812768903877839
Validation loss: 2.47944212476147

Epoch: 5| Step: 10
Training loss: 0.08870351306782687
Validation loss: 2.485650110238873

Epoch: 589| Step: 0
Training loss: 0.1943601660265766
Validation loss: 2.5319687974669627

Epoch: 5| Step: 1
Training loss: 0.24346774644220104
Validation loss: 2.4736188005094633

Epoch: 5| Step: 2
Training loss: 0.11227739251196804
Validation loss: 2.4714953214326143

Epoch: 5| Step: 3
Training loss: 0.19870808543278254
Validation loss: 2.5145697444363013

Epoch: 5| Step: 4
Training loss: 0.267334304879053
Validation loss: 2.490441722726706

Epoch: 5| Step: 5
Training loss: 0.14149001101343284
Validation loss: 2.5168219569435646

Epoch: 5| Step: 6
Training loss: 0.19680265353791282
Validation loss: 2.486680328311598

Epoch: 5| Step: 7
Training loss: 0.2089476865133284
Validation loss: 2.495332059808547

Epoch: 5| Step: 8
Training loss: 0.18094754016605666
Validation loss: 2.5072496930335157

Epoch: 5| Step: 9
Training loss: 0.27009517996525456
Validation loss: 2.4853317901097527

Epoch: 5| Step: 10
Training loss: 0.25367169917376325
Validation loss: 2.444264772700618

Epoch: 590| Step: 0
Training loss: 0.2242306211033868
Validation loss: 2.4729696722934853

Epoch: 5| Step: 1
Training loss: 0.12091043656170987
Validation loss: 2.478027574971684

Epoch: 5| Step: 2
Training loss: 0.3272149658880523
Validation loss: 2.442969581477961

Epoch: 5| Step: 3
Training loss: 0.1544919109221441
Validation loss: 2.503638980526836

Epoch: 5| Step: 4
Training loss: 0.1746651876032595
Validation loss: 2.4797029860443605

Epoch: 5| Step: 5
Training loss: 0.24151878172292285
Validation loss: 2.456580593782823

Epoch: 5| Step: 6
Training loss: 0.2372037570895445
Validation loss: 2.450857711156218

Epoch: 5| Step: 7
Training loss: 0.20372437115536035
Validation loss: 2.4589427587497124

Epoch: 5| Step: 8
Training loss: 0.21695490395761355
Validation loss: 2.4497010331759026

Epoch: 5| Step: 9
Training loss: 0.11801983567186819
Validation loss: 2.439452665753191

Epoch: 5| Step: 10
Training loss: 0.11425115696359844
Validation loss: 2.44950221458305

Epoch: 591| Step: 0
Training loss: 0.25538358056081495
Validation loss: 2.449359272007951

Epoch: 5| Step: 1
Training loss: 0.18435995032424965
Validation loss: 2.45721783852184

Epoch: 5| Step: 2
Training loss: 0.251078380904832
Validation loss: 2.4554009242603225

Epoch: 5| Step: 3
Training loss: 0.17362023362722906
Validation loss: 2.44541269465542

Epoch: 5| Step: 4
Training loss: 0.22486153421590593
Validation loss: 2.439396635942869

Epoch: 5| Step: 5
Training loss: 0.25454768807457717
Validation loss: 2.437441651366639

Epoch: 5| Step: 6
Training loss: 0.1531116134280609
Validation loss: 2.4580175715974626

Epoch: 5| Step: 7
Training loss: 0.104193009582112
Validation loss: 2.47702181833114

Epoch: 5| Step: 8
Training loss: 0.289097899769524
Validation loss: 2.4817718139835194

Epoch: 5| Step: 9
Training loss: 0.11358707761910586
Validation loss: 2.48562091077269

Epoch: 5| Step: 10
Training loss: 0.14393776753500534
Validation loss: 2.43562525984497

Epoch: 592| Step: 0
Training loss: 0.20625831160993027
Validation loss: 2.471729375902691

Epoch: 5| Step: 1
Training loss: 0.2730187888701407
Validation loss: 2.467799534253821

Epoch: 5| Step: 2
Training loss: 0.25424167778194495
Validation loss: 2.4642721417934235

Epoch: 5| Step: 3
Training loss: 0.14022424337186695
Validation loss: 2.4687236542007924

Epoch: 5| Step: 4
Training loss: 0.16807469641782757
Validation loss: 2.488217473981574

Epoch: 5| Step: 5
Training loss: 0.26405971401482986
Validation loss: 2.446507600333354

Epoch: 5| Step: 6
Training loss: 0.25074536253937557
Validation loss: 2.429272888553885

Epoch: 5| Step: 7
Training loss: 0.17947007583720925
Validation loss: 2.4513289690143365

Epoch: 5| Step: 8
Training loss: 0.18846069031922036
Validation loss: 2.457812984354298

Epoch: 5| Step: 9
Training loss: 0.16660840287649845
Validation loss: 2.461969129495142

Epoch: 5| Step: 10
Training loss: 0.19913027238481032
Validation loss: 2.443803136037172

Epoch: 593| Step: 0
Training loss: 0.17081551311074225
Validation loss: 2.4536610201841866

Epoch: 5| Step: 1
Training loss: 0.26045212345341506
Validation loss: 2.5118592854381014

Epoch: 5| Step: 2
Training loss: 0.1330353116080114
Validation loss: 2.4975050710560738

Epoch: 5| Step: 3
Training loss: 0.3236474553572901
Validation loss: 2.4724400560967466

Epoch: 5| Step: 4
Training loss: 0.12630945033450558
Validation loss: 2.4800398943161976

Epoch: 5| Step: 5
Training loss: 0.1907522453017222
Validation loss: 2.4341646770872143

Epoch: 5| Step: 6
Training loss: 0.22797301664275071
Validation loss: 2.4111414662886177

Epoch: 5| Step: 7
Training loss: 0.2677224598335107
Validation loss: 2.379209323367974

Epoch: 5| Step: 8
Training loss: 0.24496065894360308
Validation loss: 2.4058462549209385

Epoch: 5| Step: 9
Training loss: 0.15807762584134263
Validation loss: 2.401696554639036

Epoch: 5| Step: 10
Training loss: 0.31441483353330574
Validation loss: 2.4272630096801358

Epoch: 594| Step: 0
Training loss: 0.1688518210361305
Validation loss: 2.4666042387605724

Epoch: 5| Step: 1
Training loss: 0.24763444720304348
Validation loss: 2.459310874494383

Epoch: 5| Step: 2
Training loss: 0.2193020768155093
Validation loss: 2.517699195489222

Epoch: 5| Step: 3
Training loss: 0.16429409075530532
Validation loss: 2.4796173624112963

Epoch: 5| Step: 4
Training loss: 0.1802909400353873
Validation loss: 2.5066327983297922

Epoch: 5| Step: 5
Training loss: 0.23001372143512486
Validation loss: 2.4670301672015063

Epoch: 5| Step: 6
Training loss: 0.2698943415288554
Validation loss: 2.443771464346915

Epoch: 5| Step: 7
Training loss: 0.16236119072920963
Validation loss: 2.438412968894378

Epoch: 5| Step: 8
Training loss: 0.259522259514585
Validation loss: 2.4667638658375948

Epoch: 5| Step: 9
Training loss: 0.29587121718695597
Validation loss: 2.4367536249264945

Epoch: 5| Step: 10
Training loss: 0.14876600981755625
Validation loss: 2.4065677149139537

Epoch: 595| Step: 0
Training loss: 0.19709907715001723
Validation loss: 2.3949615055032076

Epoch: 5| Step: 1
Training loss: 0.2926772638486389
Validation loss: 2.3839597095198553

Epoch: 5| Step: 2
Training loss: 0.23899018247244092
Validation loss: 2.366281131262914

Epoch: 5| Step: 3
Training loss: 0.205643428770913
Validation loss: 2.386399867455699

Epoch: 5| Step: 4
Training loss: 0.16905846417311324
Validation loss: 2.428536574485092

Epoch: 5| Step: 5
Training loss: 0.2714667829124134
Validation loss: 2.442541904465964

Epoch: 5| Step: 6
Training loss: 0.16001795985519918
Validation loss: 2.471923875183567

Epoch: 5| Step: 7
Training loss: 0.193611914511453
Validation loss: 2.4993666390064266

Epoch: 5| Step: 8
Training loss: 0.18090395079440083
Validation loss: 2.5022632731683374

Epoch: 5| Step: 9
Training loss: 0.32735568641622675
Validation loss: 2.525885249171664

Epoch: 5| Step: 10
Training loss: 0.1262788398893119
Validation loss: 2.516094111286215

Epoch: 596| Step: 0
Training loss: 0.13337805886948365
Validation loss: 2.512063510312227

Epoch: 5| Step: 1
Training loss: 0.29762196681316694
Validation loss: 2.4734136738114563

Epoch: 5| Step: 2
Training loss: 0.24608070853660644
Validation loss: 2.4828555557688303

Epoch: 5| Step: 3
Training loss: 0.18099156156780682
Validation loss: 2.4306929149185943

Epoch: 5| Step: 4
Training loss: 0.1777079111875355
Validation loss: 2.457805987513623

Epoch: 5| Step: 5
Training loss: 0.2883202327433053
Validation loss: 2.445074410622241

Epoch: 5| Step: 6
Training loss: 0.1384056315865808
Validation loss: 2.439553975134016

Epoch: 5| Step: 7
Training loss: 0.3036131256682254
Validation loss: 2.402469212680499

Epoch: 5| Step: 8
Training loss: 0.26580928973033763
Validation loss: 2.4180443316043254

Epoch: 5| Step: 9
Training loss: 0.16215983145613302
Validation loss: 2.4305234959290347

Epoch: 5| Step: 10
Training loss: 0.25443752167190237
Validation loss: 2.4130142802919936

Epoch: 597| Step: 0
Training loss: 0.21812911133594204
Validation loss: 2.41338087213494

Epoch: 5| Step: 1
Training loss: 0.2206417943759908
Validation loss: 2.4281764791425715

Epoch: 5| Step: 2
Training loss: 0.21374865517555727
Validation loss: 2.4252173915910125

Epoch: 5| Step: 3
Training loss: 0.3083695550962848
Validation loss: 2.466406535883025

Epoch: 5| Step: 4
Training loss: 0.2070718581482519
Validation loss: 2.455417062587342

Epoch: 5| Step: 5
Training loss: 0.293063021433426
Validation loss: 2.4790943749106913

Epoch: 5| Step: 6
Training loss: 0.18933123177200978
Validation loss: 2.4335419750682656

Epoch: 5| Step: 7
Training loss: 0.188011108597808
Validation loss: 2.5026121101092413

Epoch: 5| Step: 8
Training loss: 0.24489536354856054
Validation loss: 2.5149284126490477

Epoch: 5| Step: 9
Training loss: 0.1966856371255277
Validation loss: 2.4903663412729165

Epoch: 5| Step: 10
Training loss: 0.20082170138336056
Validation loss: 2.5027865415885278

Epoch: 598| Step: 0
Training loss: 0.13334310649156011
Validation loss: 2.470355955343096

Epoch: 5| Step: 1
Training loss: 0.19052863851368326
Validation loss: 2.475522758685925

Epoch: 5| Step: 2
Training loss: 0.18104305209371252
Validation loss: 2.4698769710161836

Epoch: 5| Step: 3
Training loss: 0.16817922490578582
Validation loss: 2.4504420731914034

Epoch: 5| Step: 4
Training loss: 0.1810824524167094
Validation loss: 2.436975938146899

Epoch: 5| Step: 5
Training loss: 0.2050270925332037
Validation loss: 2.4322159663518863

Epoch: 5| Step: 6
Training loss: 0.2883724662767011
Validation loss: 2.406312139183138

Epoch: 5| Step: 7
Training loss: 0.25265284524769127
Validation loss: 2.4441750816710894

Epoch: 5| Step: 8
Training loss: 0.2110214772661043
Validation loss: 2.4758626090522924

Epoch: 5| Step: 9
Training loss: 0.2566051534121839
Validation loss: 2.4942573877665026

Epoch: 5| Step: 10
Training loss: 0.26503688555549404
Validation loss: 2.5005043515736705

Epoch: 599| Step: 0
Training loss: 0.16202582653720968
Validation loss: 2.525537560596489

Epoch: 5| Step: 1
Training loss: 0.33488683742861886
Validation loss: 2.4570512266543765

Epoch: 5| Step: 2
Training loss: 0.14652161442744488
Validation loss: 2.4485926626582173

Epoch: 5| Step: 3
Training loss: 0.17663717631803774
Validation loss: 2.464744456792498

Epoch: 5| Step: 4
Training loss: 0.112599801955411
Validation loss: 2.4423466190792995

Epoch: 5| Step: 5
Training loss: 0.22347312956615195
Validation loss: 2.451392358278978

Epoch: 5| Step: 6
Training loss: 0.18326786215131655
Validation loss: 2.4428887488986852

Epoch: 5| Step: 7
Training loss: 0.1637627099196918
Validation loss: 2.4457282466093404

Epoch: 5| Step: 8
Training loss: 0.13758183260399937
Validation loss: 2.4517386867809035

Epoch: 5| Step: 9
Training loss: 0.20816187458889293
Validation loss: 2.4516131866767408

Epoch: 5| Step: 10
Training loss: 0.10791006131405344
Validation loss: 2.4488899151646106

Epoch: 600| Step: 0
Training loss: 0.16750892086079577
Validation loss: 2.4613336294099666

Epoch: 5| Step: 1
Training loss: 0.30362159175302655
Validation loss: 2.4390162202958114

Epoch: 5| Step: 2
Training loss: 0.15360497211505714
Validation loss: 2.449161203924545

Epoch: 5| Step: 3
Training loss: 0.18377909537033255
Validation loss: 2.431345093248733

Epoch: 5| Step: 4
Training loss: 0.212169967342762
Validation loss: 2.4620488118831863

Epoch: 5| Step: 5
Training loss: 0.15133126355541654
Validation loss: 2.4352870379251086

Epoch: 5| Step: 6
Training loss: 0.14062173495210983
Validation loss: 2.433574054839593

Epoch: 5| Step: 7
Training loss: 0.2876342206162512
Validation loss: 2.4757190667012186

Epoch: 5| Step: 8
Training loss: 0.14589599699254244
Validation loss: 2.46669899617349

Epoch: 5| Step: 9
Training loss: 0.1280416770145343
Validation loss: 2.4758962740057484

Epoch: 5| Step: 10
Training loss: 0.16091750238302152
Validation loss: 2.4722709890225

Epoch: 601| Step: 0
Training loss: 0.2140251865026559
Validation loss: 2.496231073526753

Epoch: 5| Step: 1
Training loss: 0.15392745738429234
Validation loss: 2.4890670031560687

Epoch: 5| Step: 2
Training loss: 0.24025844050257017
Validation loss: 2.4869400582279786

Epoch: 5| Step: 3
Training loss: 0.19987275725079176
Validation loss: 2.5102257921312408

Epoch: 5| Step: 4
Training loss: 0.22790077830265848
Validation loss: 2.447668247189505

Epoch: 5| Step: 5
Training loss: 0.14539040558812283
Validation loss: 2.5094238196610004

Epoch: 5| Step: 6
Training loss: 0.09381085645848505
Validation loss: 2.5222566844514525

Epoch: 5| Step: 7
Training loss: 0.1947330940551549
Validation loss: 2.5039087604948267

Epoch: 5| Step: 8
Training loss: 0.10799131319147032
Validation loss: 2.541028801755537

Epoch: 5| Step: 9
Training loss: 0.09096508382841814
Validation loss: 2.5334543200743247

Epoch: 5| Step: 10
Training loss: 0.2523804227559084
Validation loss: 2.514057406532594

Epoch: 602| Step: 0
Training loss: 0.20892404416294605
Validation loss: 2.505519612666473

Epoch: 5| Step: 1
Training loss: 0.0980513543173428
Validation loss: 2.5286899403673075

Epoch: 5| Step: 2
Training loss: 0.2411519491986935
Validation loss: 2.5024258580358834

Epoch: 5| Step: 3
Training loss: 0.1786100071293585
Validation loss: 2.524084639798636

Epoch: 5| Step: 4
Training loss: 0.1150939295676967
Validation loss: 2.495397027046818

Epoch: 5| Step: 5
Training loss: 0.11999630466622582
Validation loss: 2.4859074820290687

Epoch: 5| Step: 6
Training loss: 0.254919378354341
Validation loss: 2.4312726698481586

Epoch: 5| Step: 7
Training loss: 0.20335695887393201
Validation loss: 2.4755775535172764

Epoch: 5| Step: 8
Training loss: 0.09414329089746884
Validation loss: 2.4778361946617804

Epoch: 5| Step: 9
Training loss: 0.22695239817097504
Validation loss: 2.482812083508552

Epoch: 5| Step: 10
Training loss: 0.1429682254781638
Validation loss: 2.454830406911959

Epoch: 603| Step: 0
Training loss: 0.14530963330876467
Validation loss: 2.4440940697381657

Epoch: 5| Step: 1
Training loss: 0.18210949423584374
Validation loss: 2.507367093741855

Epoch: 5| Step: 2
Training loss: 0.1468307786173799
Validation loss: 2.4854459357561005

Epoch: 5| Step: 3
Training loss: 0.14269117550370594
Validation loss: 2.469741669496418

Epoch: 5| Step: 4
Training loss: 0.17139429363671835
Validation loss: 2.464069306221419

Epoch: 5| Step: 5
Training loss: 0.1898184429773259
Validation loss: 2.446258286534364

Epoch: 5| Step: 6
Training loss: 0.172497013936942
Validation loss: 2.468130987114171

Epoch: 5| Step: 7
Training loss: 0.23338520539255816
Validation loss: 2.456604407140411

Epoch: 5| Step: 8
Training loss: 0.2083649859622294
Validation loss: 2.4706622529749995

Epoch: 5| Step: 9
Training loss: 0.24015423748436404
Validation loss: 2.5022436205808942

Epoch: 5| Step: 10
Training loss: 0.18536266418268144
Validation loss: 2.504379537191296

Epoch: 604| Step: 0
Training loss: 0.1920225381388199
Validation loss: 2.4916301449562837

Epoch: 5| Step: 1
Training loss: 0.12908832378290824
Validation loss: 2.4557473952311804

Epoch: 5| Step: 2
Training loss: 0.2314210870997375
Validation loss: 2.5049602900908368

Epoch: 5| Step: 3
Training loss: 0.19944618369910408
Validation loss: 2.4951480615452106

Epoch: 5| Step: 4
Training loss: 0.12752671145444436
Validation loss: 2.4513845545845565

Epoch: 5| Step: 5
Training loss: 0.16025295478124563
Validation loss: 2.473238852541362

Epoch: 5| Step: 6
Training loss: 0.2301664794803257
Validation loss: 2.4618154589649857

Epoch: 5| Step: 7
Training loss: 0.14284950713842712
Validation loss: 2.457741023796644

Epoch: 5| Step: 8
Training loss: 0.131449649166765
Validation loss: 2.4872072894892554

Epoch: 5| Step: 9
Training loss: 0.2322610009840145
Validation loss: 2.4537562706380713

Epoch: 5| Step: 10
Training loss: 0.16427341028787376
Validation loss: 2.481241685741742

Epoch: 605| Step: 0
Training loss: 0.14653606138711733
Validation loss: 2.4873350560868315

Epoch: 5| Step: 1
Training loss: 0.3056162105068715
Validation loss: 2.500739409712391

Epoch: 5| Step: 2
Training loss: 0.20523717253208318
Validation loss: 2.4694796930223752

Epoch: 5| Step: 3
Training loss: 0.13751518019413667
Validation loss: 2.469617665971057

Epoch: 5| Step: 4
Training loss: 0.12674386310674865
Validation loss: 2.476441207228576

Epoch: 5| Step: 5
Training loss: 0.20779884838495577
Validation loss: 2.5201747979571225

Epoch: 5| Step: 6
Training loss: 0.18776241456625323
Validation loss: 2.4835152924065755

Epoch: 5| Step: 7
Training loss: 0.21076648455426228
Validation loss: 2.5108825943252198

Epoch: 5| Step: 8
Training loss: 0.15547455652214787
Validation loss: 2.4973156330259756

Epoch: 5| Step: 9
Training loss: 0.12558465070050404
Validation loss: 2.4547125353025763

Epoch: 5| Step: 10
Training loss: 0.130583850263095
Validation loss: 2.4734486542026177

Epoch: 606| Step: 0
Training loss: 0.13091282678084545
Validation loss: 2.4584450700692457

Epoch: 5| Step: 1
Training loss: 0.12541949394382967
Validation loss: 2.4898630044250183

Epoch: 5| Step: 2
Training loss: 0.11331890565563686
Validation loss: 2.4628118416360216

Epoch: 5| Step: 3
Training loss: 0.17957431919025138
Validation loss: 2.491681338426283

Epoch: 5| Step: 4
Training loss: 0.25240555883182847
Validation loss: 2.482162004877196

Epoch: 5| Step: 5
Training loss: 0.1866149078892973
Validation loss: 2.471088417741032

Epoch: 5| Step: 6
Training loss: 0.2232132937204934
Validation loss: 2.473619752954234

Epoch: 5| Step: 7
Training loss: 0.22699313508694124
Validation loss: 2.4810778888508263

Epoch: 5| Step: 8
Training loss: 0.1422965195097315
Validation loss: 2.4630864087437376

Epoch: 5| Step: 9
Training loss: 0.12765722890733022
Validation loss: 2.4882205180368886

Epoch: 5| Step: 10
Training loss: 0.23451375033198446
Validation loss: 2.4678298047297207

Epoch: 607| Step: 0
Training loss: 0.11491715686689855
Validation loss: 2.44834985367076

Epoch: 5| Step: 1
Training loss: 0.12050353696462897
Validation loss: 2.5006908221115296

Epoch: 5| Step: 2
Training loss: 0.2114196054027952
Validation loss: 2.4650695737896964

Epoch: 5| Step: 3
Training loss: 0.19373056637299726
Validation loss: 2.4636763846074623

Epoch: 5| Step: 4
Training loss: 0.14890812628485584
Validation loss: 2.467660789561748

Epoch: 5| Step: 5
Training loss: 0.15992380346972
Validation loss: 2.49593444210057

Epoch: 5| Step: 6
Training loss: 0.11850378367111516
Validation loss: 2.5106028822755553

Epoch: 5| Step: 7
Training loss: 0.24815856491573254
Validation loss: 2.4802328064543824

Epoch: 5| Step: 8
Training loss: 0.2607727747203361
Validation loss: 2.4940363726096217

Epoch: 5| Step: 9
Training loss: 0.19667801349613154
Validation loss: 2.489123929450573

Epoch: 5| Step: 10
Training loss: 0.14185152682038005
Validation loss: 2.4995758378742017

Epoch: 608| Step: 0
Training loss: 0.1750766939464744
Validation loss: 2.5110069591552397

Epoch: 5| Step: 1
Training loss: 0.14706257828922353
Validation loss: 2.5118234391510903

Epoch: 5| Step: 2
Training loss: 0.09496158762041984
Validation loss: 2.4943372478842014

Epoch: 5| Step: 3
Training loss: 0.2705744582062843
Validation loss: 2.516991039245913

Epoch: 5| Step: 4
Training loss: 0.13213135152444502
Validation loss: 2.490922929321486

Epoch: 5| Step: 5
Training loss: 0.1860172333181194
Validation loss: 2.5039937626031943

Epoch: 5| Step: 6
Training loss: 0.21789901260420988
Validation loss: 2.5039732134136963

Epoch: 5| Step: 7
Training loss: 0.19138734101296404
Validation loss: 2.4772163320703564

Epoch: 5| Step: 8
Training loss: 0.16943274725886687
Validation loss: 2.486205311328023

Epoch: 5| Step: 9
Training loss: 0.09599251687108308
Validation loss: 2.4761758796721334

Epoch: 5| Step: 10
Training loss: 0.1586627464824016
Validation loss: 2.4795035726796706

Epoch: 609| Step: 0
Training loss: 0.17789194437441536
Validation loss: 2.4901021968564376

Epoch: 5| Step: 1
Training loss: 0.12787898711545054
Validation loss: 2.4677002506366743

Epoch: 5| Step: 2
Training loss: 0.16662578093688435
Validation loss: 2.472674599669685

Epoch: 5| Step: 3
Training loss: 0.10437426642485625
Validation loss: 2.4651468124238995

Epoch: 5| Step: 4
Training loss: 0.22535573269454887
Validation loss: 2.4851061270857837

Epoch: 5| Step: 5
Training loss: 0.19282286801585818
Validation loss: 2.4920852665366358

Epoch: 5| Step: 6
Training loss: 0.22051854137069893
Validation loss: 2.4785739975816075

Epoch: 5| Step: 7
Training loss: 0.11514528516071011
Validation loss: 2.4966519004050722

Epoch: 5| Step: 8
Training loss: 0.11788599541120293
Validation loss: 2.503786487667444

Epoch: 5| Step: 9
Training loss: 0.23544915736042174
Validation loss: 2.4745013843788337

Epoch: 5| Step: 10
Training loss: 0.18388452229780863
Validation loss: 2.497149281890094

Epoch: 610| Step: 0
Training loss: 0.16935132692622193
Validation loss: 2.4668250985124347

Epoch: 5| Step: 1
Training loss: 0.16207747547707577
Validation loss: 2.49545513264798

Epoch: 5| Step: 2
Training loss: 0.20556340702433215
Validation loss: 2.4602186448422905

Epoch: 5| Step: 3
Training loss: 0.17276083186765484
Validation loss: 2.42496224215305

Epoch: 5| Step: 4
Training loss: 0.10004448757930448
Validation loss: 2.4457493711258014

Epoch: 5| Step: 5
Training loss: 0.0973796886137376
Validation loss: 2.4495126234872004

Epoch: 5| Step: 6
Training loss: 0.1512812401196895
Validation loss: 2.4626765869590246

Epoch: 5| Step: 7
Training loss: 0.16651319662447678
Validation loss: 2.449351490095913

Epoch: 5| Step: 8
Training loss: 0.2799456337532583
Validation loss: 2.451536920833465

Epoch: 5| Step: 9
Training loss: 0.1859061326888845
Validation loss: 2.446400016037087

Epoch: 5| Step: 10
Training loss: 0.18457258313916727
Validation loss: 2.4910145978621525

Epoch: 611| Step: 0
Training loss: 0.10785633142933222
Validation loss: 2.4893572012923144

Epoch: 5| Step: 1
Training loss: 0.200306912461786
Validation loss: 2.4984243498478707

Epoch: 5| Step: 2
Training loss: 0.12976365610979612
Validation loss: 2.4946789894722836

Epoch: 5| Step: 3
Training loss: 0.19666465012343567
Validation loss: 2.5259351353730426

Epoch: 5| Step: 4
Training loss: 0.19611303303048175
Validation loss: 2.507102311939156

Epoch: 5| Step: 5
Training loss: 0.1828003439162857
Validation loss: 2.500962322383706

Epoch: 5| Step: 6
Training loss: 0.14890272868857302
Validation loss: 2.469792478353867

Epoch: 5| Step: 7
Training loss: 0.19108945554772097
Validation loss: 2.489740184926895

Epoch: 5| Step: 8
Training loss: 0.14021786722764437
Validation loss: 2.4742465976371486

Epoch: 5| Step: 9
Training loss: 0.2533201201474203
Validation loss: 2.4583717389771467

Epoch: 5| Step: 10
Training loss: 0.18904638379347907
Validation loss: 2.470704643550278

Epoch: 612| Step: 0
Training loss: 0.15476674954209452
Validation loss: 2.439950672860088

Epoch: 5| Step: 1
Training loss: 0.2575358582732274
Validation loss: 2.4953939789040462

Epoch: 5| Step: 2
Training loss: 0.09347133148388355
Validation loss: 2.50973007670469

Epoch: 5| Step: 3
Training loss: 0.12483430848209755
Validation loss: 2.4926400123721466

Epoch: 5| Step: 4
Training loss: 0.16097724803324084
Validation loss: 2.5403698827764014

Epoch: 5| Step: 5
Training loss: 0.274707081154318
Validation loss: 2.54637927916904

Epoch: 5| Step: 6
Training loss: 0.187558909937012
Validation loss: 2.535253543169651

Epoch: 5| Step: 7
Training loss: 0.2651123541496351
Validation loss: 2.5363573236704693

Epoch: 5| Step: 8
Training loss: 0.23074845943060646
Validation loss: 2.505766601318338

Epoch: 5| Step: 9
Training loss: 0.19470748654883516
Validation loss: 2.484089878422807

Epoch: 5| Step: 10
Training loss: 0.09181685940343205
Validation loss: 2.4695491491627783

Epoch: 613| Step: 0
Training loss: 0.15213380922014408
Validation loss: 2.4059814699621587

Epoch: 5| Step: 1
Training loss: 0.23591312509903756
Validation loss: 2.415604010493447

Epoch: 5| Step: 2
Training loss: 0.20844564787968992
Validation loss: 2.4160908804127637

Epoch: 5| Step: 3
Training loss: 0.15222208960630138
Validation loss: 2.439627346702693

Epoch: 5| Step: 4
Training loss: 0.25891268674392237
Validation loss: 2.454185225899206

Epoch: 5| Step: 5
Training loss: 0.22124340801871553
Validation loss: 2.4416266208086057

Epoch: 5| Step: 6
Training loss: 0.27138484530027046
Validation loss: 2.4489284999623857

Epoch: 5| Step: 7
Training loss: 0.11962736089837127
Validation loss: 2.4623688128956713

Epoch: 5| Step: 8
Training loss: 0.14281783137814613
Validation loss: 2.52863587369394

Epoch: 5| Step: 9
Training loss: 0.19898585188294743
Validation loss: 2.5070574215368233

Epoch: 5| Step: 10
Training loss: 0.2853266585681947
Validation loss: 2.5002760498883974

Epoch: 614| Step: 0
Training loss: 0.2357045925095961
Validation loss: 2.531047082178931

Epoch: 5| Step: 1
Training loss: 0.17971083240782076
Validation loss: 2.4990109466342

Epoch: 5| Step: 2
Training loss: 0.15431677412330339
Validation loss: 2.476621085272647

Epoch: 5| Step: 3
Training loss: 0.15171271234553885
Validation loss: 2.446989323563775

Epoch: 5| Step: 4
Training loss: 0.22283858646791957
Validation loss: 2.485985636592961

Epoch: 5| Step: 5
Training loss: 0.18355704001416742
Validation loss: 2.477936464715678

Epoch: 5| Step: 6
Training loss: 0.18153596754768853
Validation loss: 2.478786765820912

Epoch: 5| Step: 7
Training loss: 0.20463815451001152
Validation loss: 2.475351441416406

Epoch: 5| Step: 8
Training loss: 0.1406756415841112
Validation loss: 2.4869585555762903

Epoch: 5| Step: 9
Training loss: 0.1592664599135251
Validation loss: 2.4490822740961904

Epoch: 5| Step: 10
Training loss: 0.16320662686912854
Validation loss: 2.4689737802384353

Epoch: 615| Step: 0
Training loss: 0.144058763316964
Validation loss: 2.4619797980786378

Epoch: 5| Step: 1
Training loss: 0.08134785167858376
Validation loss: 2.4676208748902404

Epoch: 5| Step: 2
Training loss: 0.14710081728913066
Validation loss: 2.437786540860486

Epoch: 5| Step: 3
Training loss: 0.14361448404967173
Validation loss: 2.4467980217720933

Epoch: 5| Step: 4
Training loss: 0.21193327574934132
Validation loss: 2.4719521132734323

Epoch: 5| Step: 5
Training loss: 0.10595039487527079
Validation loss: 2.4741890627526

Epoch: 5| Step: 6
Training loss: 0.19124217689009534
Validation loss: 2.5103953968267465

Epoch: 5| Step: 7
Training loss: 0.22436410532139067
Validation loss: 2.494373259130178

Epoch: 5| Step: 8
Training loss: 0.23012390037566063
Validation loss: 2.5308581643592567

Epoch: 5| Step: 9
Training loss: 0.21863538430101748
Validation loss: 2.483194762357742

Epoch: 5| Step: 10
Training loss: 0.14086248953999747
Validation loss: 2.477424516849263

Epoch: 616| Step: 0
Training loss: 0.13167914497673375
Validation loss: 2.458634186222288

Epoch: 5| Step: 1
Training loss: 0.23015519812007534
Validation loss: 2.45445309986383

Epoch: 5| Step: 2
Training loss: 0.12334188790337698
Validation loss: 2.477973770087033

Epoch: 5| Step: 3
Training loss: 0.12128758299043457
Validation loss: 2.4708063988188615

Epoch: 5| Step: 4
Training loss: 0.22345235781854342
Validation loss: 2.4829270099263057

Epoch: 5| Step: 5
Training loss: 0.19951819373410162
Validation loss: 2.45866218176385

Epoch: 5| Step: 6
Training loss: 0.24525096935601717
Validation loss: 2.4452583028896857

Epoch: 5| Step: 7
Training loss: 0.1238639060830599
Validation loss: 2.4484122604374994

Epoch: 5| Step: 8
Training loss: 0.18971350562296682
Validation loss: 2.448748532875372

Epoch: 5| Step: 9
Training loss: 0.11180417856049016
Validation loss: 2.4733098428947

Epoch: 5| Step: 10
Training loss: 0.11828684929629739
Validation loss: 2.4611252298547885

Epoch: 617| Step: 0
Training loss: 0.17404923681274292
Validation loss: 2.490136377094125

Epoch: 5| Step: 1
Training loss: 0.15515017865413788
Validation loss: 2.506682944441575

Epoch: 5| Step: 2
Training loss: 0.13737188732362632
Validation loss: 2.4871780969661845

Epoch: 5| Step: 3
Training loss: 0.24476308435947255
Validation loss: 2.515485276240134

Epoch: 5| Step: 4
Training loss: 0.13404113801631173
Validation loss: 2.4983273027358983

Epoch: 5| Step: 5
Training loss: 0.17190534150466558
Validation loss: 2.4844854001021828

Epoch: 5| Step: 6
Training loss: 0.12745048227548172
Validation loss: 2.466501456279062

Epoch: 5| Step: 7
Training loss: 0.15814013463368226
Validation loss: 2.443507911766297

Epoch: 5| Step: 8
Training loss: 0.134246690892704
Validation loss: 2.4084256038333307

Epoch: 5| Step: 9
Training loss: 0.3084553396096102
Validation loss: 2.403012632927866

Epoch: 5| Step: 10
Training loss: 0.13833256970715693
Validation loss: 2.4168914091765803

Epoch: 618| Step: 0
Training loss: 0.241483241214022
Validation loss: 2.4455291254755003

Epoch: 5| Step: 1
Training loss: 0.11876196957796872
Validation loss: 2.4537599681191464

Epoch: 5| Step: 2
Training loss: 0.1054935161334861
Validation loss: 2.452738854630432

Epoch: 5| Step: 3
Training loss: 0.1991447423462153
Validation loss: 2.4671597497274047

Epoch: 5| Step: 4
Training loss: 0.18805075263861934
Validation loss: 2.462191970987916

Epoch: 5| Step: 5
Training loss: 0.17273238216718836
Validation loss: 2.478305597488629

Epoch: 5| Step: 6
Training loss: 0.2010144293490454
Validation loss: 2.5032876362877716

Epoch: 5| Step: 7
Training loss: 0.2602678334587365
Validation loss: 2.4523470368519917

Epoch: 5| Step: 8
Training loss: 0.11395417729844765
Validation loss: 2.4643712264695603

Epoch: 5| Step: 9
Training loss: 0.1951221492163196
Validation loss: 2.4564178972605744

Epoch: 5| Step: 10
Training loss: 0.31045991651757415
Validation loss: 2.4158296840068973

Epoch: 619| Step: 0
Training loss: 0.1291336019813692
Validation loss: 2.432823339289511

Epoch: 5| Step: 1
Training loss: 0.15094215030496155
Validation loss: 2.4475281947587764

Epoch: 5| Step: 2
Training loss: 0.2130950593613042
Validation loss: 2.4550009810226836

Epoch: 5| Step: 3
Training loss: 0.16656241409771907
Validation loss: 2.4864570126656154

Epoch: 5| Step: 4
Training loss: 0.13474236163162762
Validation loss: 2.457577320256563

Epoch: 5| Step: 5
Training loss: 0.1646877703402072
Validation loss: 2.4899550689986287

Epoch: 5| Step: 6
Training loss: 0.2613635713403794
Validation loss: 2.466260475941547

Epoch: 5| Step: 7
Training loss: 0.24514701935292202
Validation loss: 2.5153151509665785

Epoch: 5| Step: 8
Training loss: 0.19506898958679683
Validation loss: 2.4883580617661765

Epoch: 5| Step: 9
Training loss: 0.12040583888200777
Validation loss: 2.472178606801786

Epoch: 5| Step: 10
Training loss: 0.1609350204276759
Validation loss: 2.498419731867205

Epoch: 620| Step: 0
Training loss: 0.19625281953001103
Validation loss: 2.5212361674839094

Epoch: 5| Step: 1
Training loss: 0.17552756971983743
Validation loss: 2.5403426090615726

Epoch: 5| Step: 2
Training loss: 0.21471025480982103
Validation loss: 2.529792843253162

Epoch: 5| Step: 3
Training loss: 0.13401907618827674
Validation loss: 2.521697374698063

Epoch: 5| Step: 4
Training loss: 0.18583517264160118
Validation loss: 2.5193026994259435

Epoch: 5| Step: 5
Training loss: 0.13815497381694733
Validation loss: 2.5041803070472723

Epoch: 5| Step: 6
Training loss: 0.23052665823466334
Validation loss: 2.4893987848708266

Epoch: 5| Step: 7
Training loss: 0.15907273473207345
Validation loss: 2.50948840522677

Epoch: 5| Step: 8
Training loss: 0.10669862720842951
Validation loss: 2.500253703462412

Epoch: 5| Step: 9
Training loss: 0.213716305675939
Validation loss: 2.498320097150592

Epoch: 5| Step: 10
Training loss: 0.1861535844290228
Validation loss: 2.491390440659589

Epoch: 621| Step: 0
Training loss: 0.14799124369501315
Validation loss: 2.4960023578681505

Epoch: 5| Step: 1
Training loss: 0.21059862042393626
Validation loss: 2.5108340350472664

Epoch: 5| Step: 2
Training loss: 0.22813274226702446
Validation loss: 2.493083060406665

Epoch: 5| Step: 3
Training loss: 0.1441823705063401
Validation loss: 2.512334360152074

Epoch: 5| Step: 4
Training loss: 0.13731614115275473
Validation loss: 2.4803754591796863

Epoch: 5| Step: 5
Training loss: 0.12839562979640837
Validation loss: 2.5221364385439404

Epoch: 5| Step: 6
Training loss: 0.18521494035839992
Validation loss: 2.4957019961240845

Epoch: 5| Step: 7
Training loss: 0.1900110876932678
Validation loss: 2.485259031083492

Epoch: 5| Step: 8
Training loss: 0.21976168881555136
Validation loss: 2.509899617353007

Epoch: 5| Step: 9
Training loss: 0.21982456988489213
Validation loss: 2.499299620894197

Epoch: 5| Step: 10
Training loss: 0.14119382889178766
Validation loss: 2.467201170744829

Epoch: 622| Step: 0
Training loss: 0.10578082414904795
Validation loss: 2.5026238915440984

Epoch: 5| Step: 1
Training loss: 0.10164278781651019
Validation loss: 2.4863190843421186

Epoch: 5| Step: 2
Training loss: 0.1315135546268975
Validation loss: 2.4808550004808176

Epoch: 5| Step: 3
Training loss: 0.1667709502412941
Validation loss: 2.5046381430797697

Epoch: 5| Step: 4
Training loss: 0.18917639667075564
Validation loss: 2.500388851483273

Epoch: 5| Step: 5
Training loss: 0.27691723708050875
Validation loss: 2.502236997966349

Epoch: 5| Step: 6
Training loss: 0.13120117670193357
Validation loss: 2.5194600713287385

Epoch: 5| Step: 7
Training loss: 0.14982077152889836
Validation loss: 2.4959369375033758

Epoch: 5| Step: 8
Training loss: 0.1175912062443072
Validation loss: 2.5044954561524326

Epoch: 5| Step: 9
Training loss: 0.12385488305260317
Validation loss: 2.4580466358938486

Epoch: 5| Step: 10
Training loss: 0.21101173224984307
Validation loss: 2.4735654681990837

Epoch: 623| Step: 0
Training loss: 0.2204313546036056
Validation loss: 2.4654088795190505

Epoch: 5| Step: 1
Training loss: 0.1987094821205482
Validation loss: 2.4779681197692356

Epoch: 5| Step: 2
Training loss: 0.09970303881476629
Validation loss: 2.4285076003839765

Epoch: 5| Step: 3
Training loss: 0.2379834393371498
Validation loss: 2.4336112780951953

Epoch: 5| Step: 4
Training loss: 0.15072275000343507
Validation loss: 2.4611848523588096

Epoch: 5| Step: 5
Training loss: 0.1083277007581194
Validation loss: 2.454587854637407

Epoch: 5| Step: 6
Training loss: 0.17435005675281567
Validation loss: 2.496254971807909

Epoch: 5| Step: 7
Training loss: 0.12559288948952646
Validation loss: 2.4772785518402984

Epoch: 5| Step: 8
Training loss: 0.09893077751112872
Validation loss: 2.488664447630031

Epoch: 5| Step: 9
Training loss: 0.16283359535530365
Validation loss: 2.479022876984808

Epoch: 5| Step: 10
Training loss: 0.17687426993216016
Validation loss: 2.4925528488771227

Epoch: 624| Step: 0
Training loss: 0.20930032821944847
Validation loss: 2.511703339849062

Epoch: 5| Step: 1
Training loss: 0.20384709680415972
Validation loss: 2.4866351331579626

Epoch: 5| Step: 2
Training loss: 0.17764168722409057
Validation loss: 2.465832317156157

Epoch: 5| Step: 3
Training loss: 0.15442443958504695
Validation loss: 2.478525442984793

Epoch: 5| Step: 4
Training loss: 0.10774954758154157
Validation loss: 2.483440778425379

Epoch: 5| Step: 5
Training loss: 0.2019513500880858
Validation loss: 2.4993315151627478

Epoch: 5| Step: 6
Training loss: 0.2125519499668886
Validation loss: 2.476883249709219

Epoch: 5| Step: 7
Training loss: 0.19154326731293986
Validation loss: 2.505785218533253

Epoch: 5| Step: 8
Training loss: 0.14658497852511287
Validation loss: 2.4819848963261153

Epoch: 5| Step: 9
Training loss: 0.1479093604958644
Validation loss: 2.486509975677883

Epoch: 5| Step: 10
Training loss: 0.1484830435101376
Validation loss: 2.459132309922851

Epoch: 625| Step: 0
Training loss: 0.1800341475898681
Validation loss: 2.4649300368469182

Epoch: 5| Step: 1
Training loss: 0.2462841463014282
Validation loss: 2.4726137669102273

Epoch: 5| Step: 2
Training loss: 0.16747153789408534
Validation loss: 2.467234693334057

Epoch: 5| Step: 3
Training loss: 0.176158600664451
Validation loss: 2.4579708387590724

Epoch: 5| Step: 4
Training loss: 0.14631933451662832
Validation loss: 2.5052879552285012

Epoch: 5| Step: 5
Training loss: 0.10027421870742789
Validation loss: 2.4921644185765697

Epoch: 5| Step: 6
Training loss: 0.18215529018063495
Validation loss: 2.4872098423499325

Epoch: 5| Step: 7
Training loss: 0.10710963907911827
Validation loss: 2.5015169135667237

Epoch: 5| Step: 8
Training loss: 0.12494165206128857
Validation loss: 2.4826393816050327

Epoch: 5| Step: 9
Training loss: 0.1562979386223005
Validation loss: 2.499460908745191

Epoch: 5| Step: 10
Training loss: 0.2732870778094368
Validation loss: 2.470338271302657

Epoch: 626| Step: 0
Training loss: 0.1710455016470189
Validation loss: 2.4760281533786634

Epoch: 5| Step: 1
Training loss: 0.21327718584149877
Validation loss: 2.447775815019709

Epoch: 5| Step: 2
Training loss: 0.22649296976172617
Validation loss: 2.4589013388457275

Epoch: 5| Step: 3
Training loss: 0.18472122400853846
Validation loss: 2.4455679090088966

Epoch: 5| Step: 4
Training loss: 0.09702277237872814
Validation loss: 2.4257590902680075

Epoch: 5| Step: 5
Training loss: 0.1814689440166999
Validation loss: 2.4599623443978964

Epoch: 5| Step: 6
Training loss: 0.10592723902237201
Validation loss: 2.4646530934398303

Epoch: 5| Step: 7
Training loss: 0.13464914346614457
Validation loss: 2.4527027447825986

Epoch: 5| Step: 8
Training loss: 0.1809439269919052
Validation loss: 2.4622862802703516

Epoch: 5| Step: 9
Training loss: 0.1276697181824805
Validation loss: 2.470750553963646

Epoch: 5| Step: 10
Training loss: 0.12280999194440419
Validation loss: 2.480157123498743

Epoch: 627| Step: 0
Training loss: 0.16431708111403934
Validation loss: 2.4883099422615502

Epoch: 5| Step: 1
Training loss: 0.14158300080811353
Validation loss: 2.4736345002554865

Epoch: 5| Step: 2
Training loss: 0.15307535661057448
Validation loss: 2.4710602740465877

Epoch: 5| Step: 3
Training loss: 0.1705485768217977
Validation loss: 2.482194022266467

Epoch: 5| Step: 4
Training loss: 0.13928413222644964
Validation loss: 2.480672816379187

Epoch: 5| Step: 5
Training loss: 0.17679224679968444
Validation loss: 2.4451731933366045

Epoch: 5| Step: 6
Training loss: 0.18991426014041546
Validation loss: 2.478435092680707

Epoch: 5| Step: 7
Training loss: 0.15599895217242524
Validation loss: 2.417584117450739

Epoch: 5| Step: 8
Training loss: 0.2294574711290278
Validation loss: 2.4382402775205594

Epoch: 5| Step: 9
Training loss: 0.22690552197481284
Validation loss: 2.4450760934511098

Epoch: 5| Step: 10
Training loss: 0.10854809971326179
Validation loss: 2.410680405443303

Epoch: 628| Step: 0
Training loss: 0.12474079750348802
Validation loss: 2.4206493932468214

Epoch: 5| Step: 1
Training loss: 0.21526030126427498
Validation loss: 2.4114004892878986

Epoch: 5| Step: 2
Training loss: 0.1610596288311135
Validation loss: 2.427025820488034

Epoch: 5| Step: 3
Training loss: 0.24975810418187558
Validation loss: 2.4604659069265646

Epoch: 5| Step: 4
Training loss: 0.12007136362481835
Validation loss: 2.4639669439459406

Epoch: 5| Step: 5
Training loss: 0.14946135850711187
Validation loss: 2.4539630326631734

Epoch: 5| Step: 6
Training loss: 0.15526232289774902
Validation loss: 2.4612622701900184

Epoch: 5| Step: 7
Training loss: 0.13393148095512744
Validation loss: 2.4640049877989236

Epoch: 5| Step: 8
Training loss: 0.2776036320956143
Validation loss: 2.439044333803349

Epoch: 5| Step: 9
Training loss: 0.15639882748432912
Validation loss: 2.426811059513824

Epoch: 5| Step: 10
Training loss: 0.1283782128704596
Validation loss: 2.4309580255718592

Epoch: 629| Step: 0
Training loss: 0.1441589082840375
Validation loss: 2.447908951732563

Epoch: 5| Step: 1
Training loss: 0.15965050418077037
Validation loss: 2.4594820306409115

Epoch: 5| Step: 2
Training loss: 0.1673912945337578
Validation loss: 2.4718403703564125

Epoch: 5| Step: 3
Training loss: 0.19193311114186007
Validation loss: 2.488927905167051

Epoch: 5| Step: 4
Training loss: 0.11106749611357628
Validation loss: 2.503194600356

Epoch: 5| Step: 5
Training loss: 0.1075130595824332
Validation loss: 2.48627863194474

Epoch: 5| Step: 6
Training loss: 0.10889451465154305
Validation loss: 2.498745790298569

Epoch: 5| Step: 7
Training loss: 0.18975760385232565
Validation loss: 2.5052087747271883

Epoch: 5| Step: 8
Training loss: 0.15742732197162418
Validation loss: 2.4736607688785757

Epoch: 5| Step: 9
Training loss: 0.19607131419313734
Validation loss: 2.469165779970162

Epoch: 5| Step: 10
Training loss: 0.224162910233781
Validation loss: 2.446333896395679

Epoch: 630| Step: 0
Training loss: 0.1985235707157711
Validation loss: 2.4696072260601665

Epoch: 5| Step: 1
Training loss: 0.21162752036989568
Validation loss: 2.4877025350919832

Epoch: 5| Step: 2
Training loss: 0.23104486549377076
Validation loss: 2.4462101429651453

Epoch: 5| Step: 3
Training loss: 0.10589298826667647
Validation loss: 2.460449826721957

Epoch: 5| Step: 4
Training loss: 0.12411033409657676
Validation loss: 2.4499347324082303

Epoch: 5| Step: 5
Training loss: 0.18245349013773957
Validation loss: 2.4118969858374943

Epoch: 5| Step: 6
Training loss: 0.0864662975234734
Validation loss: 2.425827187891555

Epoch: 5| Step: 7
Training loss: 0.11234499581140961
Validation loss: 2.4093231544594684

Epoch: 5| Step: 8
Training loss: 0.19270102813552334
Validation loss: 2.3992149004628502

Epoch: 5| Step: 9
Training loss: 0.15303921291377617
Validation loss: 2.428495352765871

Epoch: 5| Step: 10
Training loss: 0.16723560416628772
Validation loss: 2.4105172282435965

Epoch: 631| Step: 0
Training loss: 0.24726388156270204
Validation loss: 2.4452153836293347

Epoch: 5| Step: 1
Training loss: 0.1385033685110173
Validation loss: 2.4382727107870648

Epoch: 5| Step: 2
Training loss: 0.14686860872120083
Validation loss: 2.441747403499556

Epoch: 5| Step: 3
Training loss: 0.12283139055630589
Validation loss: 2.455483547366813

Epoch: 5| Step: 4
Training loss: 0.11090836948423613
Validation loss: 2.437471573661003

Epoch: 5| Step: 5
Training loss: 0.20367151795163188
Validation loss: 2.4552517789696195

Epoch: 5| Step: 6
Training loss: 0.18090320945776917
Validation loss: 2.467257809775755

Epoch: 5| Step: 7
Training loss: 0.11956349355600876
Validation loss: 2.4575866888377558

Epoch: 5| Step: 8
Training loss: 0.2346056756672083
Validation loss: 2.4692442277129927

Epoch: 5| Step: 9
Training loss: 0.10023367874099921
Validation loss: 2.4816434928900573

Epoch: 5| Step: 10
Training loss: 0.1287199827613524
Validation loss: 2.4622778822376796

Epoch: 632| Step: 0
Training loss: 0.16284172252556106
Validation loss: 2.4719250802974146

Epoch: 5| Step: 1
Training loss: 0.15020239804622823
Validation loss: 2.4818381195679446

Epoch: 5| Step: 2
Training loss: 0.14479041705061127
Validation loss: 2.4398757194278664

Epoch: 5| Step: 3
Training loss: 0.1873874823406049
Validation loss: 2.437126994614616

Epoch: 5| Step: 4
Training loss: 0.13582434329266108
Validation loss: 2.443149126404705

Epoch: 5| Step: 5
Training loss: 0.1833330088489724
Validation loss: 2.454011362869145

Epoch: 5| Step: 6
Training loss: 0.1842400355899025
Validation loss: 2.438078041626196

Epoch: 5| Step: 7
Training loss: 0.14689899258761546
Validation loss: 2.4554944792993276

Epoch: 5| Step: 8
Training loss: 0.2858163170341702
Validation loss: 2.4611034300259194

Epoch: 5| Step: 9
Training loss: 0.27880036296820854
Validation loss: 2.4590440598369976

Epoch: 5| Step: 10
Training loss: 0.10939019387161174
Validation loss: 2.450639818067867

Epoch: 633| Step: 0
Training loss: 0.12285915693937839
Validation loss: 2.4716644664572587

Epoch: 5| Step: 1
Training loss: 0.17563173505147922
Validation loss: 2.467360959734176

Epoch: 5| Step: 2
Training loss: 0.11794291049077733
Validation loss: 2.448401214950388

Epoch: 5| Step: 3
Training loss: 0.14154033652650935
Validation loss: 2.4387150615958895

Epoch: 5| Step: 4
Training loss: 0.20270705323796884
Validation loss: 2.4464549224328116

Epoch: 5| Step: 5
Training loss: 0.242520088587782
Validation loss: 2.423358956675011

Epoch: 5| Step: 6
Training loss: 0.20790888444145106
Validation loss: 2.438740643045991

Epoch: 5| Step: 7
Training loss: 0.14837170698790744
Validation loss: 2.4076426401656494

Epoch: 5| Step: 8
Training loss: 0.2387241952367216
Validation loss: 2.4253462024717045

Epoch: 5| Step: 9
Training loss: 0.32811059238955165
Validation loss: 2.424771699814033

Epoch: 5| Step: 10
Training loss: 0.13109572971745137
Validation loss: 2.469148976683175

Epoch: 634| Step: 0
Training loss: 0.20252594275364016
Validation loss: 2.4953330504542537

Epoch: 5| Step: 1
Training loss: 0.21259060113333617
Validation loss: 2.487058138300867

Epoch: 5| Step: 2
Training loss: 0.23210399591921116
Validation loss: 2.5044297790903527

Epoch: 5| Step: 3
Training loss: 0.1578333382964847
Validation loss: 2.514304587326058

Epoch: 5| Step: 4
Training loss: 0.357168201415793
Validation loss: 2.5231241844241548

Epoch: 5| Step: 5
Training loss: 0.13849398122759823
Validation loss: 2.475421824368012

Epoch: 5| Step: 6
Training loss: 0.16294757318654574
Validation loss: 2.4364950265982355

Epoch: 5| Step: 7
Training loss: 0.18136263668899913
Validation loss: 2.42252360222048

Epoch: 5| Step: 8
Training loss: 0.23641613038891582
Validation loss: 2.359814846321675

Epoch: 5| Step: 9
Training loss: 0.22502133281560383
Validation loss: 2.3964660607994808

Epoch: 5| Step: 10
Training loss: 0.2687755578108825
Validation loss: 2.409071342347501

Epoch: 635| Step: 0
Training loss: 0.2178267512044538
Validation loss: 2.4172089371083705

Epoch: 5| Step: 1
Training loss: 0.2798662584071781
Validation loss: 2.4231954255850536

Epoch: 5| Step: 2
Training loss: 0.25759618527493305
Validation loss: 2.4803455800533554

Epoch: 5| Step: 3
Training loss: 0.1644617853126964
Validation loss: 2.5129398671889187

Epoch: 5| Step: 4
Training loss: 0.24899377085178798
Validation loss: 2.5713067835692884

Epoch: 5| Step: 5
Training loss: 0.485234804904092
Validation loss: 2.612045843905297

Epoch: 5| Step: 6
Training loss: 0.19972270913363907
Validation loss: 2.569408814063927

Epoch: 5| Step: 7
Training loss: 0.21337891497928418
Validation loss: 2.5273761383607005

Epoch: 5| Step: 8
Training loss: 0.31615947000587497
Validation loss: 2.495501143491838

Epoch: 5| Step: 9
Training loss: 0.30995926354766906
Validation loss: 2.4225800101033856

Epoch: 5| Step: 10
Training loss: 0.37979644735064816
Validation loss: 2.388076267535464

Epoch: 636| Step: 0
Training loss: 0.43004537764354656
Validation loss: 2.395138541796847

Epoch: 5| Step: 1
Training loss: 0.3551063157107308
Validation loss: 2.351844747492753

Epoch: 5| Step: 2
Training loss: 0.26093473718516835
Validation loss: 2.414352410734731

Epoch: 5| Step: 3
Training loss: 0.23203752297293068
Validation loss: 2.4589755424093207

Epoch: 5| Step: 4
Training loss: 0.23974420581703587
Validation loss: 2.4712619113126224

Epoch: 5| Step: 5
Training loss: 0.3082282642318202
Validation loss: 2.475581106564805

Epoch: 5| Step: 6
Training loss: 0.20350348533403637
Validation loss: 2.4627489180597246

Epoch: 5| Step: 7
Training loss: 0.27825940452818776
Validation loss: 2.460306146840967

Epoch: 5| Step: 8
Training loss: 0.22560295437130037
Validation loss: 2.4524375443972444

Epoch: 5| Step: 9
Training loss: 0.4060439173970573
Validation loss: 2.4681694331512443

Epoch: 5| Step: 10
Training loss: 0.48957569204278706
Validation loss: 2.424669640360358

Epoch: 637| Step: 0
Training loss: 0.1622480695371592
Validation loss: 2.434376328232711

Epoch: 5| Step: 1
Training loss: 0.23469369202025153
Validation loss: 2.4819445504323565

Epoch: 5| Step: 2
Training loss: 0.3733209132714271
Validation loss: 2.4880469597246644

Epoch: 5| Step: 3
Training loss: 0.5353672697483114
Validation loss: 2.458081146105442

Epoch: 5| Step: 4
Training loss: 0.41509768801251834
Validation loss: 2.4762504083123176

Epoch: 5| Step: 5
Training loss: 0.377687874646895
Validation loss: 2.458856553727833

Epoch: 5| Step: 6
Training loss: 0.3617183742974392
Validation loss: 2.462579380319861

Epoch: 5| Step: 7
Training loss: 0.2723041753417985
Validation loss: 2.438268837364883

Epoch: 5| Step: 8
Training loss: 0.4540271657071728
Validation loss: 2.4716716921857604

Epoch: 5| Step: 9
Training loss: 0.42931103253471264
Validation loss: 2.5010168171440013

Epoch: 5| Step: 10
Training loss: 0.35268567066911355
Validation loss: 2.5391308059528552

Epoch: 638| Step: 0
Training loss: 0.43926743716919536
Validation loss: 2.57541627307831

Epoch: 5| Step: 1
Training loss: 0.4405861215145452
Validation loss: 2.552580173356561

Epoch: 5| Step: 2
Training loss: 0.38555385965902034
Validation loss: 2.542438876613106

Epoch: 5| Step: 3
Training loss: 0.3870327763071099
Validation loss: 2.488980611661964

Epoch: 5| Step: 4
Training loss: 0.18703914670279873
Validation loss: 2.446500694285953

Epoch: 5| Step: 5
Training loss: 0.3148628787531569
Validation loss: 2.439879101712226

Epoch: 5| Step: 6
Training loss: 0.32110161226397077
Validation loss: 2.4445161759602643

Epoch: 5| Step: 7
Training loss: 0.46196015916304506
Validation loss: 2.452068851067241

Epoch: 5| Step: 8
Training loss: 0.34565590142595554
Validation loss: 2.4824832445145173

Epoch: 5| Step: 9
Training loss: 0.3783575194283984
Validation loss: 2.4730771482555256

Epoch: 5| Step: 10
Training loss: 0.2923593541012238
Validation loss: 2.5028126112820135

Epoch: 639| Step: 0
Training loss: 0.19301179027492354
Validation loss: 2.55285812246078

Epoch: 5| Step: 1
Training loss: 0.47653501462628245
Validation loss: 2.560482364337902

Epoch: 5| Step: 2
Training loss: 0.6027097784772897
Validation loss: 2.52332022724066

Epoch: 5| Step: 3
Training loss: 0.2963990612696636
Validation loss: 2.5039056868788734

Epoch: 5| Step: 4
Training loss: 0.3840389845425634
Validation loss: 2.358934727155808

Epoch: 5| Step: 5
Training loss: 0.6046757088233609
Validation loss: 2.3059622827584936

Epoch: 5| Step: 6
Training loss: 0.3962824640904469
Validation loss: 2.321635778560413

Epoch: 5| Step: 7
Training loss: 0.38729849621416557
Validation loss: 2.4009062282366878

Epoch: 5| Step: 8
Training loss: 0.3607187648701477
Validation loss: 2.4480439148877484

Epoch: 5| Step: 9
Training loss: 0.21734775113084695
Validation loss: 2.4398659287441933

Epoch: 5| Step: 10
Training loss: 0.34464498532652527
Validation loss: 2.430093016632403

Epoch: 640| Step: 0
Training loss: 0.5877931076736653
Validation loss: 2.457401068275093

Epoch: 5| Step: 1
Training loss: 0.5287593631952452
Validation loss: 2.445022094512318

Epoch: 5| Step: 2
Training loss: 0.38289452666587187
Validation loss: 2.426238908675306

Epoch: 5| Step: 3
Training loss: 0.2717576058471824
Validation loss: 2.4295336906739817

Epoch: 5| Step: 4
Training loss: 0.4055915595084458
Validation loss: 2.369961493806574

Epoch: 5| Step: 5
Training loss: 0.3725874303454413
Validation loss: 2.299827756535884

Epoch: 5| Step: 6
Training loss: 0.5533136627950314
Validation loss: 2.3387807855414695

Epoch: 5| Step: 7
Training loss: 0.5200112498882112
Validation loss: 2.348764954610012

Epoch: 5| Step: 8
Training loss: 0.23601561762567613
Validation loss: 2.3875409744750558

Epoch: 5| Step: 9
Training loss: 0.28469972776832736
Validation loss: 2.416212245691041

Epoch: 5| Step: 10
Training loss: 0.5124136596151401
Validation loss: 2.467565834283507

Epoch: 641| Step: 0
Training loss: 0.38180785795416256
Validation loss: 2.464360443924693

Epoch: 5| Step: 1
Training loss: 0.33779242086242023
Validation loss: 2.469354397949652

Epoch: 5| Step: 2
Training loss: 0.3502004517722252
Validation loss: 2.4526713547307155

Epoch: 5| Step: 3
Training loss: 0.3258253643987452
Validation loss: 2.425806742741553

Epoch: 5| Step: 4
Training loss: 0.5313214366229932
Validation loss: 2.38168507758801

Epoch: 5| Step: 5
Training loss: 0.388257212825473
Validation loss: 2.349725215593303

Epoch: 5| Step: 6
Training loss: 0.2874544885106113
Validation loss: 2.3656641952846624

Epoch: 5| Step: 7
Training loss: 0.3883332929522503
Validation loss: 2.3226876265722924

Epoch: 5| Step: 8
Training loss: 0.39856172009015356
Validation loss: 2.344223593714312

Epoch: 5| Step: 9
Training loss: 0.5660233354273669
Validation loss: 2.3352904491415103

Epoch: 5| Step: 10
Training loss: 0.47186004160230755
Validation loss: 2.3990318890172184

Epoch: 642| Step: 0
Training loss: 0.3883662723657018
Validation loss: 2.4570019243193846

Epoch: 5| Step: 1
Training loss: 0.2805208317208576
Validation loss: 2.4750512712872683

Epoch: 5| Step: 2
Training loss: 0.3916802838508233
Validation loss: 2.506647365213102

Epoch: 5| Step: 3
Training loss: 0.24012127206461292
Validation loss: 2.5133205797194935

Epoch: 5| Step: 4
Training loss: 0.379050433854465
Validation loss: 2.530272880246984

Epoch: 5| Step: 5
Training loss: 0.23208867560155844
Validation loss: 2.5467889679259508

Epoch: 5| Step: 6
Training loss: 0.26425142527189577
Validation loss: 2.523379722275878

Epoch: 5| Step: 7
Training loss: 0.35878057661907875
Validation loss: 2.4969593604968447

Epoch: 5| Step: 8
Training loss: 0.5261450247367224
Validation loss: 2.546378026735924

Epoch: 5| Step: 9
Training loss: 0.3457855945215973
Validation loss: 2.481217110749781

Epoch: 5| Step: 10
Training loss: 0.22060032366139212
Validation loss: 2.4808539066586435

Epoch: 643| Step: 0
Training loss: 0.3953851580284258
Validation loss: 2.4720584367232776

Epoch: 5| Step: 1
Training loss: 0.4227927257314926
Validation loss: 2.473456852619749

Epoch: 5| Step: 2
Training loss: 0.3115607571146588
Validation loss: 2.44070851819883

Epoch: 5| Step: 3
Training loss: 0.3225918130518085
Validation loss: 2.46345934018876

Epoch: 5| Step: 4
Training loss: 0.4373411673646415
Validation loss: 2.4687936513397606

Epoch: 5| Step: 5
Training loss: 0.35898905222837546
Validation loss: 2.45463059644261

Epoch: 5| Step: 6
Training loss: 0.3865617375532077
Validation loss: 2.451021151730955

Epoch: 5| Step: 7
Training loss: 0.37733582356027745
Validation loss: 2.4469063350603237

Epoch: 5| Step: 8
Training loss: 0.4514264135983874
Validation loss: 2.4542507182795696

Epoch: 5| Step: 9
Training loss: 0.3739381697946958
Validation loss: 2.4792545337846303

Epoch: 5| Step: 10
Training loss: 0.564867257121083
Validation loss: 2.462161659311792

Epoch: 644| Step: 0
Training loss: 0.5910676800885165
Validation loss: 2.444480957474116

Epoch: 5| Step: 1
Training loss: 0.3801657988214907
Validation loss: 2.4052669465155265

Epoch: 5| Step: 2
Training loss: 0.4023565086638031
Validation loss: 2.46442474682867

Epoch: 5| Step: 3
Training loss: 0.3782305247076615
Validation loss: 2.422443354165408

Epoch: 5| Step: 4
Training loss: 0.30061442219767887
Validation loss: 2.436095926894891

Epoch: 5| Step: 5
Training loss: 0.3073395217658963
Validation loss: 2.425561812384056

Epoch: 5| Step: 6
Training loss: 0.4282902628337527
Validation loss: 2.429515113303377

Epoch: 5| Step: 7
Training loss: 0.3564861953491577
Validation loss: 2.3984835746764492

Epoch: 5| Step: 8
Training loss: 0.349189143451287
Validation loss: 2.3714343162234623

Epoch: 5| Step: 9
Training loss: 0.35584228926844824
Validation loss: 2.319865060169798

Epoch: 5| Step: 10
Training loss: 0.37548195147790825
Validation loss: 2.359152426106092

Epoch: 645| Step: 0
Training loss: 0.4093921082685506
Validation loss: 2.3463597535186844

Epoch: 5| Step: 1
Training loss: 0.3853852370910339
Validation loss: 2.3669706169643523

Epoch: 5| Step: 2
Training loss: 0.3637889268043975
Validation loss: 2.385945208689401

Epoch: 5| Step: 3
Training loss: 0.3675158635433012
Validation loss: 2.4212580545716142

Epoch: 5| Step: 4
Training loss: 0.3087982272887861
Validation loss: 2.46945844137434

Epoch: 5| Step: 5
Training loss: 0.3623944400140319
Validation loss: 2.4766481705035943

Epoch: 5| Step: 6
Training loss: 0.22913801581285312
Validation loss: 2.449799552939746

Epoch: 5| Step: 7
Training loss: 0.3207327017114893
Validation loss: 2.4999258112410394

Epoch: 5| Step: 8
Training loss: 0.29990882183346335
Validation loss: 2.488836832396031

Epoch: 5| Step: 9
Training loss: 0.41887413433945153
Validation loss: 2.4795624518816686

Epoch: 5| Step: 10
Training loss: 0.3071647829288491
Validation loss: 2.525979664917712

Epoch: 646| Step: 0
Training loss: 0.2281835866188702
Validation loss: 2.5134898261625866

Epoch: 5| Step: 1
Training loss: 0.2111630911205104
Validation loss: 2.454793203598123

Epoch: 5| Step: 2
Training loss: 0.2699432127229506
Validation loss: 2.5007743395083497

Epoch: 5| Step: 3
Training loss: 0.24979117732017336
Validation loss: 2.484848124456576

Epoch: 5| Step: 4
Training loss: 0.40240470646690085
Validation loss: 2.4484351957103674

Epoch: 5| Step: 5
Training loss: 0.21070013112737146
Validation loss: 2.4167503725038304

Epoch: 5| Step: 6
Training loss: 0.38047540333783697
Validation loss: 2.4271505185367763

Epoch: 5| Step: 7
Training loss: 0.20869279288874187
Validation loss: 2.439575588956313

Epoch: 5| Step: 8
Training loss: 0.3177016080342543
Validation loss: 2.453691675873164

Epoch: 5| Step: 9
Training loss: 0.2743921508729258
Validation loss: 2.5008371735724118

Epoch: 5| Step: 10
Training loss: 0.31088631750227563
Validation loss: 2.4862945873760403

Epoch: 647| Step: 0
Training loss: 0.24033717150347036
Validation loss: 2.4955959701539503

Epoch: 5| Step: 1
Training loss: 0.28333061242667057
Validation loss: 2.4894977200798185

Epoch: 5| Step: 2
Training loss: 0.30413800598788526
Validation loss: 2.4799669407504443

Epoch: 5| Step: 3
Training loss: 0.27109359499352503
Validation loss: 2.5128712425912005

Epoch: 5| Step: 4
Training loss: 0.34040477090281523
Validation loss: 2.506930020447008

Epoch: 5| Step: 5
Training loss: 0.28839257941302254
Validation loss: 2.4668041040743964

Epoch: 5| Step: 6
Training loss: 0.22645992390501898
Validation loss: 2.444587417337064

Epoch: 5| Step: 7
Training loss: 0.21204370497215289
Validation loss: 2.4535053565216174

Epoch: 5| Step: 8
Training loss: 0.252751895468233
Validation loss: 2.3949881911951625

Epoch: 5| Step: 9
Training loss: 0.29895576543513713
Validation loss: 2.430772283670402

Epoch: 5| Step: 10
Training loss: 0.24000432078872902
Validation loss: 2.4340938942421104

Epoch: 648| Step: 0
Training loss: 0.2473918195030794
Validation loss: 2.4034759689352274

Epoch: 5| Step: 1
Training loss: 0.23514227841462806
Validation loss: 2.3774461610936095

Epoch: 5| Step: 2
Training loss: 0.3231921892019603
Validation loss: 2.4303296622816037

Epoch: 5| Step: 3
Training loss: 0.2078096852076069
Validation loss: 2.4773005322047954

Epoch: 5| Step: 4
Training loss: 0.1931148003381609
Validation loss: 2.4204659164640807

Epoch: 5| Step: 5
Training loss: 0.23096140238393784
Validation loss: 2.44650037887387

Epoch: 5| Step: 6
Training loss: 0.2685558249709576
Validation loss: 2.4639219858421653

Epoch: 5| Step: 7
Training loss: 0.15521084225523463
Validation loss: 2.479627867441953

Epoch: 5| Step: 8
Training loss: 0.23938813066449766
Validation loss: 2.492053926596504

Epoch: 5| Step: 9
Training loss: 0.30943322982338095
Validation loss: 2.4806928351749127

Epoch: 5| Step: 10
Training loss: 0.281204153668743
Validation loss: 2.4940539929510965

Epoch: 649| Step: 0
Training loss: 0.2610518656019743
Validation loss: 2.4992918980585657

Epoch: 5| Step: 1
Training loss: 0.25419433096642746
Validation loss: 2.4836071517809786

Epoch: 5| Step: 2
Training loss: 0.24179388176909533
Validation loss: 2.490494024552571

Epoch: 5| Step: 3
Training loss: 0.2680949628451022
Validation loss: 2.4682044842305726

Epoch: 5| Step: 4
Training loss: 0.24916934058711956
Validation loss: 2.4635631788672088

Epoch: 5| Step: 5
Training loss: 0.18012291564304586
Validation loss: 2.4802947831104416

Epoch: 5| Step: 6
Training loss: 0.2759459827540561
Validation loss: 2.4759828052025417

Epoch: 5| Step: 7
Training loss: 0.2446931994348061
Validation loss: 2.4426917472108505

Epoch: 5| Step: 8
Training loss: 0.2145956601071345
Validation loss: 2.4832110576446182

Epoch: 5| Step: 9
Training loss: 0.18674989504409048
Validation loss: 2.464023119418461

Epoch: 5| Step: 10
Training loss: 0.35240437055923657
Validation loss: 2.4122217603945315

Epoch: 650| Step: 0
Training loss: 0.15860333860002374
Validation loss: 2.423502305154899

Epoch: 5| Step: 1
Training loss: 0.20015101989535797
Validation loss: 2.439648356964863

Epoch: 5| Step: 2
Training loss: 0.23891922484518424
Validation loss: 2.440661995933389

Epoch: 5| Step: 3
Training loss: 0.19178711697370432
Validation loss: 2.411391407984465

Epoch: 5| Step: 4
Training loss: 0.3363961039216612
Validation loss: 2.4448903011006213

Epoch: 5| Step: 5
Training loss: 0.18967220577817967
Validation loss: 2.4742860065202947

Epoch: 5| Step: 6
Training loss: 0.22867433628103978
Validation loss: 2.4754380579387116

Epoch: 5| Step: 7
Training loss: 0.2731390959683413
Validation loss: 2.4540653342872645

Epoch: 5| Step: 8
Training loss: 0.2840434006501
Validation loss: 2.468305904787771

Epoch: 5| Step: 9
Training loss: 0.23234321160629273
Validation loss: 2.475230750411663

Epoch: 5| Step: 10
Training loss: 0.28733607833187996
Validation loss: 2.4507961103975675

Epoch: 651| Step: 0
Training loss: 0.2522305137084934
Validation loss: 2.477451914081227

Epoch: 5| Step: 1
Training loss: 0.32244368749051056
Validation loss: 2.4356819395174156

Epoch: 5| Step: 2
Training loss: 0.17541494349594539
Validation loss: 2.4323595564567406

Epoch: 5| Step: 3
Training loss: 0.2155494198125235
Validation loss: 2.4017956975363304

Epoch: 5| Step: 4
Training loss: 0.20358596362362608
Validation loss: 2.3896312542277465

Epoch: 5| Step: 5
Training loss: 0.17857811374582497
Validation loss: 2.380123179358844

Epoch: 5| Step: 6
Training loss: 0.23899544323932634
Validation loss: 2.409603207352095

Epoch: 5| Step: 7
Training loss: 0.2557969927268759
Validation loss: 2.399310960203547

Epoch: 5| Step: 8
Training loss: 0.3208252826316372
Validation loss: 2.4091839013857848

Epoch: 5| Step: 9
Training loss: 0.18485373478909273
Validation loss: 2.3655725010856394

Epoch: 5| Step: 10
Training loss: 0.2851893523350672
Validation loss: 2.404114082998177

Epoch: 652| Step: 0
Training loss: 0.21117537825455585
Validation loss: 2.4135911747371885

Epoch: 5| Step: 1
Training loss: 0.2092177968078278
Validation loss: 2.440889070725275

Epoch: 5| Step: 2
Training loss: 0.21654193081404452
Validation loss: 2.486896921266926

Epoch: 5| Step: 3
Training loss: 0.21686518512250647
Validation loss: 2.4657926051255257

Epoch: 5| Step: 4
Training loss: 0.28481644803530126
Validation loss: 2.4790681447318854

Epoch: 5| Step: 5
Training loss: 0.22526190138016997
Validation loss: 2.5183958990189526

Epoch: 5| Step: 6
Training loss: 0.22486572563826185
Validation loss: 2.42775107210935

Epoch: 5| Step: 7
Training loss: 0.1976876889733549
Validation loss: 2.440675246534612

Epoch: 5| Step: 8
Training loss: 0.18866472289941172
Validation loss: 2.444811019472374

Epoch: 5| Step: 9
Training loss: 0.19188628045512668
Validation loss: 2.422556064414593

Epoch: 5| Step: 10
Training loss: 0.1725095771034867
Validation loss: 2.463908787165559

Epoch: 653| Step: 0
Training loss: 0.17444692261565392
Validation loss: 2.4333285050871725

Epoch: 5| Step: 1
Training loss: 0.1848468122285077
Validation loss: 2.436473306270902

Epoch: 5| Step: 2
Training loss: 0.17397187750355309
Validation loss: 2.4497187055541514

Epoch: 5| Step: 3
Training loss: 0.20743102935302976
Validation loss: 2.429799002191343

Epoch: 5| Step: 4
Training loss: 0.21174841880545764
Validation loss: 2.4437401835472046

Epoch: 5| Step: 5
Training loss: 0.1596518108813289
Validation loss: 2.4336048384653006

Epoch: 5| Step: 6
Training loss: 0.13953786086753678
Validation loss: 2.4345984320674754

Epoch: 5| Step: 7
Training loss: 0.2502095119428443
Validation loss: 2.450275804123371

Epoch: 5| Step: 8
Training loss: 0.24049611293482787
Validation loss: 2.408766287564517

Epoch: 5| Step: 9
Training loss: 0.18801321879860025
Validation loss: 2.4384194073913537

Epoch: 5| Step: 10
Training loss: 0.1029274849773637
Validation loss: 2.4379441056812876

Epoch: 654| Step: 0
Training loss: 0.20058440567219146
Validation loss: 2.4246596058874585

Epoch: 5| Step: 1
Training loss: 0.1981446256303633
Validation loss: 2.417183057785712

Epoch: 5| Step: 2
Training loss: 0.16734060113546192
Validation loss: 2.4152923306945975

Epoch: 5| Step: 3
Training loss: 0.11787606444540627
Validation loss: 2.422705520033797

Epoch: 5| Step: 4
Training loss: 0.22838695685818092
Validation loss: 2.3932970130150966

Epoch: 5| Step: 5
Training loss: 0.2101581002618391
Validation loss: 2.380619148701624

Epoch: 5| Step: 6
Training loss: 0.16190084005372632
Validation loss: 2.4127543892563845

Epoch: 5| Step: 7
Training loss: 0.22906590905456503
Validation loss: 2.4203131798489346

Epoch: 5| Step: 8
Training loss: 0.23144971465097103
Validation loss: 2.377510517416661

Epoch: 5| Step: 9
Training loss: 0.21801298164400648
Validation loss: 2.398038373913497

Epoch: 5| Step: 10
Training loss: 0.14649169903565368
Validation loss: 2.386206433864826

Epoch: 655| Step: 0
Training loss: 0.16441148017709703
Validation loss: 2.388990356623987

Epoch: 5| Step: 1
Training loss: 0.1315967438569457
Validation loss: 2.3977030288571908

Epoch: 5| Step: 2
Training loss: 0.20791662482953718
Validation loss: 2.3557122505888737

Epoch: 5| Step: 3
Training loss: 0.09668803901435813
Validation loss: 2.428007510161987

Epoch: 5| Step: 4
Training loss: 0.13849188984784966
Validation loss: 2.428074571776843

Epoch: 5| Step: 5
Training loss: 0.17342979890892046
Validation loss: 2.393224058438478

Epoch: 5| Step: 6
Training loss: 0.19861175590542368
Validation loss: 2.42866213337355

Epoch: 5| Step: 7
Training loss: 0.1913678364257026
Validation loss: 2.420515629357786

Epoch: 5| Step: 8
Training loss: 0.21459822062974995
Validation loss: 2.417495362330511

Epoch: 5| Step: 9
Training loss: 0.13086898967665042
Validation loss: 2.4451134917957886

Epoch: 5| Step: 10
Training loss: 0.17174146623455222
Validation loss: 2.4555692704950736

Epoch: 656| Step: 0
Training loss: 0.11332000283320924
Validation loss: 2.457957254811138

Epoch: 5| Step: 1
Training loss: 0.1720173311449503
Validation loss: 2.4362518221625797

Epoch: 5| Step: 2
Training loss: 0.17094090615249036
Validation loss: 2.4414851255739847

Epoch: 5| Step: 3
Training loss: 0.10193862409983444
Validation loss: 2.434706587865133

Epoch: 5| Step: 4
Training loss: 0.1273078291494527
Validation loss: 2.449581149195031

Epoch: 5| Step: 5
Training loss: 0.19450905531541998
Validation loss: 2.4009612078874123

Epoch: 5| Step: 6
Training loss: 0.2472166675836269
Validation loss: 2.4201749383462063

Epoch: 5| Step: 7
Training loss: 0.12422162088639419
Validation loss: 2.4123908759584856

Epoch: 5| Step: 8
Training loss: 0.11975118654565162
Validation loss: 2.4072269309819725

Epoch: 5| Step: 9
Training loss: 0.13460632252124208
Validation loss: 2.3906644801419277

Epoch: 5| Step: 10
Training loss: 0.14664953457771163
Validation loss: 2.4228429632342667

Epoch: 657| Step: 0
Training loss: 0.1708709585713704
Validation loss: 2.413869420038788

Epoch: 5| Step: 1
Training loss: 0.155504510591011
Validation loss: 2.3751800276739754

Epoch: 5| Step: 2
Training loss: 0.14831707486468595
Validation loss: 2.389054628388989

Epoch: 5| Step: 3
Training loss: 0.11298868612812006
Validation loss: 2.3824133528087432

Epoch: 5| Step: 4
Training loss: 0.17992048086602705
Validation loss: 2.367643496714778

Epoch: 5| Step: 5
Training loss: 0.18961686992253246
Validation loss: 2.363478791603061

Epoch: 5| Step: 6
Training loss: 0.11197170567237942
Validation loss: 2.3864776584620557

Epoch: 5| Step: 7
Training loss: 0.17531910650959492
Validation loss: 2.370752914255407

Epoch: 5| Step: 8
Training loss: 0.21430357737252104
Validation loss: 2.407960841528273

Epoch: 5| Step: 9
Training loss: 0.18041688660996608
Validation loss: 2.3873276178662617

Epoch: 5| Step: 10
Training loss: 0.14360516497596446
Validation loss: 2.404000208446821

Epoch: 658| Step: 0
Training loss: 0.20933502406344373
Validation loss: 2.408755795710428

Epoch: 5| Step: 1
Training loss: 0.17712729389896653
Validation loss: 2.4164980294523124

Epoch: 5| Step: 2
Training loss: 0.11796675121432995
Validation loss: 2.4057341796368665

Epoch: 5| Step: 3
Training loss: 0.1192101760220946
Validation loss: 2.407837477259125

Epoch: 5| Step: 4
Training loss: 0.09643232122893484
Validation loss: 2.4166957735367487

Epoch: 5| Step: 5
Training loss: 0.19213319453147673
Validation loss: 2.403998202535994

Epoch: 5| Step: 6
Training loss: 0.1588546910563918
Validation loss: 2.3987172628884244

Epoch: 5| Step: 7
Training loss: 0.1863721063876655
Validation loss: 2.3784380872282127

Epoch: 5| Step: 8
Training loss: 0.1870605365192567
Validation loss: 2.400392279346561

Epoch: 5| Step: 9
Training loss: 0.16669642038795557
Validation loss: 2.3905557087156444

Epoch: 5| Step: 10
Training loss: 0.1839652361300146
Validation loss: 2.401351931798481

Epoch: 659| Step: 0
Training loss: 0.13271036849290394
Validation loss: 2.399478042237483

Epoch: 5| Step: 1
Training loss: 0.12575620407807783
Validation loss: 2.4180219928254227

Epoch: 5| Step: 2
Training loss: 0.23399267006819516
Validation loss: 2.3972889373795443

Epoch: 5| Step: 3
Training loss: 0.18089631076288298
Validation loss: 2.3895840272175497

Epoch: 5| Step: 4
Training loss: 0.17625931792112798
Validation loss: 2.3726014502167003

Epoch: 5| Step: 5
Training loss: 0.18716358761265994
Validation loss: 2.4181827129311357

Epoch: 5| Step: 6
Training loss: 0.14351074039118786
Validation loss: 2.424081477490994

Epoch: 5| Step: 7
Training loss: 0.1263798166417387
Validation loss: 2.419937638669399

Epoch: 5| Step: 8
Training loss: 0.1320986285201089
Validation loss: 2.430539818950598

Epoch: 5| Step: 9
Training loss: 0.20184747895113828
Validation loss: 2.4127558768076245

Epoch: 5| Step: 10
Training loss: 0.11787067988464464
Validation loss: 2.4185636611780756

Epoch: 660| Step: 0
Training loss: 0.14711323222017741
Validation loss: 2.4454405784253126

Epoch: 5| Step: 1
Training loss: 0.18353902731703384
Validation loss: 2.4486118318378782

Epoch: 5| Step: 2
Training loss: 0.19070707805432394
Validation loss: 2.4446021274180967

Epoch: 5| Step: 3
Training loss: 0.16662314276329127
Validation loss: 2.454348738922457

Epoch: 5| Step: 4
Training loss: 0.11423102089188475
Validation loss: 2.4263167853989587

Epoch: 5| Step: 5
Training loss: 0.1444074383950715
Validation loss: 2.4116464550038983

Epoch: 5| Step: 6
Training loss: 0.17431519344987162
Validation loss: 2.4359489719698226

Epoch: 5| Step: 7
Training loss: 0.0939085533570495
Validation loss: 2.376279655661995

Epoch: 5| Step: 8
Training loss: 0.22473686580554686
Validation loss: 2.38847300541509

Epoch: 5| Step: 9
Training loss: 0.16069720949552435
Validation loss: 2.4034172249540595

Epoch: 5| Step: 10
Training loss: 0.18992482287034743
Validation loss: 2.3809162709065914

Epoch: 661| Step: 0
Training loss: 0.12151840567402439
Validation loss: 2.3871601058434813

Epoch: 5| Step: 1
Training loss: 0.23061286332209693
Validation loss: 2.398681681639075

Epoch: 5| Step: 2
Training loss: 0.16874380166538208
Validation loss: 2.4101698182937143

Epoch: 5| Step: 3
Training loss: 0.15249163834325258
Validation loss: 2.431346708080927

Epoch: 5| Step: 4
Training loss: 0.20822360705602372
Validation loss: 2.4104141589577375

Epoch: 5| Step: 5
Training loss: 0.12661219816133304
Validation loss: 2.468843710904159

Epoch: 5| Step: 6
Training loss: 0.17546848977325247
Validation loss: 2.4200789954213864

Epoch: 5| Step: 7
Training loss: 0.14883349952104666
Validation loss: 2.4195054608291104

Epoch: 5| Step: 8
Training loss: 0.1631822701291474
Validation loss: 2.4474502702151644

Epoch: 5| Step: 9
Training loss: 0.1313463657698644
Validation loss: 2.392296432175727

Epoch: 5| Step: 10
Training loss: 0.11525527716039345
Validation loss: 2.401951707861398

Epoch: 662| Step: 0
Training loss: 0.13757087955967806
Validation loss: 2.380135561716337

Epoch: 5| Step: 1
Training loss: 0.1015776705415585
Validation loss: 2.3806703123257016

Epoch: 5| Step: 2
Training loss: 0.13618516339559872
Validation loss: 2.3723731223515374

Epoch: 5| Step: 3
Training loss: 0.16477624858035303
Validation loss: 2.3889107565639294

Epoch: 5| Step: 4
Training loss: 0.28231101438981465
Validation loss: 2.391221577565527

Epoch: 5| Step: 5
Training loss: 0.13013478983743876
Validation loss: 2.3935321040937856

Epoch: 5| Step: 6
Training loss: 0.12033050482892743
Validation loss: 2.4206837190973793

Epoch: 5| Step: 7
Training loss: 0.15004564325966555
Validation loss: 2.3755849723410183

Epoch: 5| Step: 8
Training loss: 0.1766875743940026
Validation loss: 2.3881161177668506

Epoch: 5| Step: 9
Training loss: 0.11034014313614288
Validation loss: 2.3764838013033307

Epoch: 5| Step: 10
Training loss: 0.2013998961500726
Validation loss: 2.389256529036495

Epoch: 663| Step: 0
Training loss: 0.12422482967493621
Validation loss: 2.3828849707492523

Epoch: 5| Step: 1
Training loss: 0.14412447029911377
Validation loss: 2.379186154465263

Epoch: 5| Step: 2
Training loss: 0.1251971879958479
Validation loss: 2.3990804036320306

Epoch: 5| Step: 3
Training loss: 0.16763328164719418
Validation loss: 2.37405285302184

Epoch: 5| Step: 4
Training loss: 0.14873997713629897
Validation loss: 2.343378016441256

Epoch: 5| Step: 5
Training loss: 0.2135224895860321
Validation loss: 2.366615880790737

Epoch: 5| Step: 6
Training loss: 0.19039760221486168
Validation loss: 2.363086394837681

Epoch: 5| Step: 7
Training loss: 0.20441516711904112
Validation loss: 2.367368174841923

Epoch: 5| Step: 8
Training loss: 0.15625280139319148
Validation loss: 2.3769580852034036

Epoch: 5| Step: 9
Training loss: 0.13885413536401478
Validation loss: 2.3932647275739214

Epoch: 5| Step: 10
Training loss: 0.1961207071142055
Validation loss: 2.3942112878776305

Epoch: 664| Step: 0
Training loss: 0.1138300468698872
Validation loss: 2.414149264916156

Epoch: 5| Step: 1
Training loss: 0.19349647247009397
Validation loss: 2.41271713270518

Epoch: 5| Step: 2
Training loss: 0.13156168633886703
Validation loss: 2.3905009254205503

Epoch: 5| Step: 3
Training loss: 0.10030875392853343
Validation loss: 2.4380229770700494

Epoch: 5| Step: 4
Training loss: 0.1554660262535389
Validation loss: 2.454536221744661

Epoch: 5| Step: 5
Training loss: 0.1138579307575536
Validation loss: 2.439521124100832

Epoch: 5| Step: 6
Training loss: 0.14469657927136204
Validation loss: 2.4110419633885516

Epoch: 5| Step: 7
Training loss: 0.20518249399060862
Validation loss: 2.401705547978674

Epoch: 5| Step: 8
Training loss: 0.0843873806320782
Validation loss: 2.430417972973748

Epoch: 5| Step: 9
Training loss: 0.09914848813497584
Validation loss: 2.4151600284438044

Epoch: 5| Step: 10
Training loss: 0.22025367242249821
Validation loss: 2.4003705313801156

Epoch: 665| Step: 0
Training loss: 0.13825726651328937
Validation loss: 2.4262292140612516

Epoch: 5| Step: 1
Training loss: 0.18897330095158416
Validation loss: 2.4138306000826146

Epoch: 5| Step: 2
Training loss: 0.18577574618298384
Validation loss: 2.3790927858753963

Epoch: 5| Step: 3
Training loss: 0.13508220474498095
Validation loss: 2.38532529577933

Epoch: 5| Step: 4
Training loss: 0.08718555886661142
Validation loss: 2.4101900397599767

Epoch: 5| Step: 5
Training loss: 0.13624450310502842
Validation loss: 2.4053232597524348

Epoch: 5| Step: 6
Training loss: 0.18217212072274558
Validation loss: 2.415913270990352

Epoch: 5| Step: 7
Training loss: 0.08934805792422756
Validation loss: 2.406901816364486

Epoch: 5| Step: 8
Training loss: 0.19903625282304604
Validation loss: 2.4282095039801184

Epoch: 5| Step: 9
Training loss: 0.15685022224940107
Validation loss: 2.406353477764231

Epoch: 5| Step: 10
Training loss: 0.12605252304559478
Validation loss: 2.417606124127395

Epoch: 666| Step: 0
Training loss: 0.12400677336230576
Validation loss: 2.4081256057133262

Epoch: 5| Step: 1
Training loss: 0.1665090520964133
Validation loss: 2.384739574203984

Epoch: 5| Step: 2
Training loss: 0.09430522714997226
Validation loss: 2.4359453774277564

Epoch: 5| Step: 3
Training loss: 0.14192050661953778
Validation loss: 2.4237817874859386

Epoch: 5| Step: 4
Training loss: 0.11195249480118706
Validation loss: 2.4261647288349715

Epoch: 5| Step: 5
Training loss: 0.13292382287050764
Validation loss: 2.422861324592412

Epoch: 5| Step: 6
Training loss: 0.19033808338922392
Validation loss: 2.4213081874203493

Epoch: 5| Step: 7
Training loss: 0.1882511530362111
Validation loss: 2.4107257989561943

Epoch: 5| Step: 8
Training loss: 0.1106263385640536
Validation loss: 2.4026771989627984

Epoch: 5| Step: 9
Training loss: 0.19652651188992745
Validation loss: 2.3957155813106406

Epoch: 5| Step: 10
Training loss: 0.12980643156144459
Validation loss: 2.398402523870524

Epoch: 667| Step: 0
Training loss: 0.08974398381157395
Validation loss: 2.448209744941484

Epoch: 5| Step: 1
Training loss: 0.14325133860089137
Validation loss: 2.410440268360089

Epoch: 5| Step: 2
Training loss: 0.12448202788949818
Validation loss: 2.4154513602056937

Epoch: 5| Step: 3
Training loss: 0.16446769156016658
Validation loss: 2.4279064662985888

Epoch: 5| Step: 4
Training loss: 0.11942181860580421
Validation loss: 2.4215738363968278

Epoch: 5| Step: 5
Training loss: 0.13395665107143384
Validation loss: 2.4184159583906975

Epoch: 5| Step: 6
Training loss: 0.15139467543538948
Validation loss: 2.4416090820061473

Epoch: 5| Step: 7
Training loss: 0.17382822143894908
Validation loss: 2.4434486018032464

Epoch: 5| Step: 8
Training loss: 0.14898309073972354
Validation loss: 2.422567304991459

Epoch: 5| Step: 9
Training loss: 0.1261223090397973
Validation loss: 2.4602862575729243

Epoch: 5| Step: 10
Training loss: 0.23345613763957798
Validation loss: 2.471969898292353

Epoch: 668| Step: 0
Training loss: 0.10474847843145069
Validation loss: 2.4691951542997526

Epoch: 5| Step: 1
Training loss: 0.12647374685165824
Validation loss: 2.4638530721090977

Epoch: 5| Step: 2
Training loss: 0.140680825225946
Validation loss: 2.484207264263207

Epoch: 5| Step: 3
Training loss: 0.2212156994007514
Validation loss: 2.4711240462491815

Epoch: 5| Step: 4
Training loss: 0.17783229352333632
Validation loss: 2.4511455175439307

Epoch: 5| Step: 5
Training loss: 0.12573625873526012
Validation loss: 2.450830442368146

Epoch: 5| Step: 6
Training loss: 0.24343156463331223
Validation loss: 2.440573642047444

Epoch: 5| Step: 7
Training loss: 0.15145612380446322
Validation loss: 2.3969926687275627

Epoch: 5| Step: 8
Training loss: 0.13427061584263666
Validation loss: 2.403048653593129

Epoch: 5| Step: 9
Training loss: 0.11688257122760698
Validation loss: 2.3801433588201917

Epoch: 5| Step: 10
Training loss: 0.14544389588210718
Validation loss: 2.382828044386765

Epoch: 669| Step: 0
Training loss: 0.15680169816099615
Validation loss: 2.37440897869054

Epoch: 5| Step: 1
Training loss: 0.18207156426638432
Validation loss: 2.4173604572574123

Epoch: 5| Step: 2
Training loss: 0.1290047875835568
Validation loss: 2.4202068160803187

Epoch: 5| Step: 3
Training loss: 0.15510635263206185
Validation loss: 2.3954674233129047

Epoch: 5| Step: 4
Training loss: 0.13554539583481948
Validation loss: 2.3851261616702

Epoch: 5| Step: 5
Training loss: 0.15071841225179897
Validation loss: 2.40835577591726

Epoch: 5| Step: 6
Training loss: 0.1420830203905416
Validation loss: 2.46970405487748

Epoch: 5| Step: 7
Training loss: 0.18647120278626256
Validation loss: 2.4406912910624734

Epoch: 5| Step: 8
Training loss: 0.23081410120613435
Validation loss: 2.4283720571287977

Epoch: 5| Step: 9
Training loss: 0.12504190249258215
Validation loss: 2.408299637910872

Epoch: 5| Step: 10
Training loss: 0.17630238636296955
Validation loss: 2.4115506437143703

Epoch: 670| Step: 0
Training loss: 0.11521218781320831
Validation loss: 2.385739912102573

Epoch: 5| Step: 1
Training loss: 0.11177446170006215
Validation loss: 2.4083771680951656

Epoch: 5| Step: 2
Training loss: 0.22285661549569097
Validation loss: 2.3637547525002685

Epoch: 5| Step: 3
Training loss: 0.20866752384323814
Validation loss: 2.4257534118569435

Epoch: 5| Step: 4
Training loss: 0.16668370961927714
Validation loss: 2.3849827289822327

Epoch: 5| Step: 5
Training loss: 0.14010561953527542
Validation loss: 2.4201921780515177

Epoch: 5| Step: 6
Training loss: 0.1543866029425309
Validation loss: 2.438497335617255

Epoch: 5| Step: 7
Training loss: 0.184840987806408
Validation loss: 2.461196123796535

Epoch: 5| Step: 8
Training loss: 0.17737906436282644
Validation loss: 2.4470564050415518

Epoch: 5| Step: 9
Training loss: 0.12777002577861057
Validation loss: 2.4843007052929345

Epoch: 5| Step: 10
Training loss: 0.13471764249353038
Validation loss: 2.4808223948659394

Epoch: 671| Step: 0
Training loss: 0.13845935171160142
Validation loss: 2.4768488358628433

Epoch: 5| Step: 1
Training loss: 0.1262718333235829
Validation loss: 2.4854236406258483

Epoch: 5| Step: 2
Training loss: 0.22116963698354034
Validation loss: 2.471203567268094

Epoch: 5| Step: 3
Training loss: 0.15256730207779978
Validation loss: 2.478910996726129

Epoch: 5| Step: 4
Training loss: 0.20653405857932633
Validation loss: 2.407166077975656

Epoch: 5| Step: 5
Training loss: 0.10910866018741536
Validation loss: 2.460968378865865

Epoch: 5| Step: 6
Training loss: 0.14470058264608465
Validation loss: 2.414564229823511

Epoch: 5| Step: 7
Training loss: 0.11728447239761393
Validation loss: 2.4360497795863827

Epoch: 5| Step: 8
Training loss: 0.1644556410046567
Validation loss: 2.441261458240041

Epoch: 5| Step: 9
Training loss: 0.10820885137009963
Validation loss: 2.4291861065940292

Epoch: 5| Step: 10
Training loss: 0.19139847447697703
Validation loss: 2.4440633909550415

Epoch: 672| Step: 0
Training loss: 0.13894786369077158
Validation loss: 2.4450602643290393

Epoch: 5| Step: 1
Training loss: 0.1551505208086148
Validation loss: 2.44562375760018

Epoch: 5| Step: 2
Training loss: 0.1762701335695918
Validation loss: 2.4789785313919546

Epoch: 5| Step: 3
Training loss: 0.12286587678757517
Validation loss: 2.451606612380937

Epoch: 5| Step: 4
Training loss: 0.13564132126373607
Validation loss: 2.440436885429045

Epoch: 5| Step: 5
Training loss: 0.11546544974931512
Validation loss: 2.4418340862840338

Epoch: 5| Step: 6
Training loss: 0.21515005990669608
Validation loss: 2.4231186652351537

Epoch: 5| Step: 7
Training loss: 0.18283009485197954
Validation loss: 2.4190742284480176

Epoch: 5| Step: 8
Training loss: 0.15995334937946382
Validation loss: 2.425441768982606

Epoch: 5| Step: 9
Training loss: 0.10501503486223428
Validation loss: 2.418911652461196

Epoch: 5| Step: 10
Training loss: 0.16476987860386105
Validation loss: 2.3995159140791373

Epoch: 673| Step: 0
Training loss: 0.11009264421787462
Validation loss: 2.4118250366032767

Epoch: 5| Step: 1
Training loss: 0.1550657815128577
Validation loss: 2.3783231573896595

Epoch: 5| Step: 2
Training loss: 0.16142433267394599
Validation loss: 2.3293312737360665

Epoch: 5| Step: 3
Training loss: 0.14626727228385222
Validation loss: 2.3880119136141347

Epoch: 5| Step: 4
Training loss: 0.2155854600091351
Validation loss: 2.3845962236211147

Epoch: 5| Step: 5
Training loss: 0.10737333935207277
Validation loss: 2.398807128522818

Epoch: 5| Step: 6
Training loss: 0.123863045163937
Validation loss: 2.3676474001389574

Epoch: 5| Step: 7
Training loss: 0.08936634414445659
Validation loss: 2.429703570659863

Epoch: 5| Step: 8
Training loss: 0.10907972874683056
Validation loss: 2.3957766786130192

Epoch: 5| Step: 9
Training loss: 0.18712303892189733
Validation loss: 2.422160500890671

Epoch: 5| Step: 10
Training loss: 0.1561235631551359
Validation loss: 2.417759303201237

Epoch: 674| Step: 0
Training loss: 0.1348220527383202
Validation loss: 2.4703744082326913

Epoch: 5| Step: 1
Training loss: 0.08134488928807082
Validation loss: 2.481226328079264

Epoch: 5| Step: 2
Training loss: 0.2438796059512255
Validation loss: 2.432339272667029

Epoch: 5| Step: 3
Training loss: 0.1426784410692213
Validation loss: 2.434514741070966

Epoch: 5| Step: 4
Training loss: 0.12449816461726934
Validation loss: 2.415027797498826

Epoch: 5| Step: 5
Training loss: 0.16260677461001044
Validation loss: 2.441545001937546

Epoch: 5| Step: 6
Training loss: 0.12952456148730856
Validation loss: 2.3989644093271547

Epoch: 5| Step: 7
Training loss: 0.20616034199040797
Validation loss: 2.4142784475788366

Epoch: 5| Step: 8
Training loss: 0.15122215336814618
Validation loss: 2.385404838962216

Epoch: 5| Step: 9
Training loss: 0.10311734756340542
Validation loss: 2.3918493702383277

Epoch: 5| Step: 10
Training loss: 0.15173536868669094
Validation loss: 2.4254087455677906

Epoch: 675| Step: 0
Training loss: 0.14674831770886326
Validation loss: 2.37289243393307

Epoch: 5| Step: 1
Training loss: 0.12447176273491534
Validation loss: 2.4449668193590353

Epoch: 5| Step: 2
Training loss: 0.1441359268497959
Validation loss: 2.4164626760671957

Epoch: 5| Step: 3
Training loss: 0.14529518619060056
Validation loss: 2.4167614671771434

Epoch: 5| Step: 4
Training loss: 0.18640619357892418
Validation loss: 2.41245207856122

Epoch: 5| Step: 5
Training loss: 0.14349097829880283
Validation loss: 2.4279620918373372

Epoch: 5| Step: 6
Training loss: 0.15632670427141007
Validation loss: 2.422662104938748

Epoch: 5| Step: 7
Training loss: 0.14241580999395564
Validation loss: 2.4130095216969774

Epoch: 5| Step: 8
Training loss: 0.1921733645536423
Validation loss: 2.409842601258511

Epoch: 5| Step: 9
Training loss: 0.10099698308473103
Validation loss: 2.451721787058688

Epoch: 5| Step: 10
Training loss: 0.1229321611129485
Validation loss: 2.4563425811008406

Epoch: 676| Step: 0
Training loss: 0.12462883471469115
Validation loss: 2.442352994985849

Epoch: 5| Step: 1
Training loss: 0.15785347010142586
Validation loss: 2.409719709271899

Epoch: 5| Step: 2
Training loss: 0.11892507941630505
Validation loss: 2.4286600169401265

Epoch: 5| Step: 3
Training loss: 0.16822520350776843
Validation loss: 2.442971164490159

Epoch: 5| Step: 4
Training loss: 0.1415063669584418
Validation loss: 2.4471536725370906

Epoch: 5| Step: 5
Training loss: 0.09049269333014424
Validation loss: 2.458260769413577

Epoch: 5| Step: 6
Training loss: 0.1409618528772215
Validation loss: 2.452807917316614

Epoch: 5| Step: 7
Training loss: 0.12715490884324385
Validation loss: 2.447962150770804

Epoch: 5| Step: 8
Training loss: 0.08427098074504437
Validation loss: 2.4212909546022865

Epoch: 5| Step: 9
Training loss: 0.20960810090430268
Validation loss: 2.4208924787107398

Epoch: 5| Step: 10
Training loss: 0.193774759725575
Validation loss: 2.4265298939010953

Epoch: 677| Step: 0
Training loss: 0.10299870242069994
Validation loss: 2.4242467053189496

Epoch: 5| Step: 1
Training loss: 0.2616294879428154
Validation loss: 2.4176570071062757

Epoch: 5| Step: 2
Training loss: 0.1423835340986556
Validation loss: 2.3638962631120526

Epoch: 5| Step: 3
Training loss: 0.21130736032174108
Validation loss: 2.4055417620273603

Epoch: 5| Step: 4
Training loss: 0.15433788358194708
Validation loss: 2.374599057017925

Epoch: 5| Step: 5
Training loss: 0.19634910158729418
Validation loss: 2.3896319225935834

Epoch: 5| Step: 6
Training loss: 0.1781403338374139
Validation loss: 2.3930437127138915

Epoch: 5| Step: 7
Training loss: 0.143016832635616
Validation loss: 2.4115964986864658

Epoch: 5| Step: 8
Training loss: 0.12982849189815723
Validation loss: 2.415748587999467

Epoch: 5| Step: 9
Training loss: 0.10323950991728818
Validation loss: 2.423273685756743

Epoch: 5| Step: 10
Training loss: 0.13899279787080637
Validation loss: 2.4471003595414493

Epoch: 678| Step: 0
Training loss: 0.15248506667352305
Validation loss: 2.437571223469721

Epoch: 5| Step: 1
Training loss: 0.17195323767305223
Validation loss: 2.452796385751741

Epoch: 5| Step: 2
Training loss: 0.07876003972459315
Validation loss: 2.438724126300686

Epoch: 5| Step: 3
Training loss: 0.12764026575625165
Validation loss: 2.4585381529092514

Epoch: 5| Step: 4
Training loss: 0.11872036087176327
Validation loss: 2.444615395464024

Epoch: 5| Step: 5
Training loss: 0.14262453395172256
Validation loss: 2.4568040609939423

Epoch: 5| Step: 6
Training loss: 0.1505387122074783
Validation loss: 2.395721688328758

Epoch: 5| Step: 7
Training loss: 0.1727890343367451
Validation loss: 2.4247874414698454

Epoch: 5| Step: 8
Training loss: 0.21343740189579374
Validation loss: 2.4333179600519808

Epoch: 5| Step: 9
Training loss: 0.1729474313687758
Validation loss: 2.4120047975179304

Epoch: 5| Step: 10
Training loss: 0.22727399129407677
Validation loss: 2.3948487179732987

Epoch: 679| Step: 0
Training loss: 0.1685056035878029
Validation loss: 2.4087526400565933

Epoch: 5| Step: 1
Training loss: 0.10408104914514871
Validation loss: 2.4196370984936966

Epoch: 5| Step: 2
Training loss: 0.08028614252257042
Validation loss: 2.431103618688243

Epoch: 5| Step: 3
Training loss: 0.12181905446638103
Validation loss: 2.446362504271573

Epoch: 5| Step: 4
Training loss: 0.10920248731873725
Validation loss: 2.4106523493141427

Epoch: 5| Step: 5
Training loss: 0.09688144881564792
Validation loss: 2.39034214178806

Epoch: 5| Step: 6
Training loss: 0.13773854571219957
Validation loss: 2.441910310028302

Epoch: 5| Step: 7
Training loss: 0.16834205905701674
Validation loss: 2.443260970137883

Epoch: 5| Step: 8
Training loss: 0.26242941122996427
Validation loss: 2.441008429029572

Epoch: 5| Step: 9
Training loss: 0.19321314744447843
Validation loss: 2.467775467407473

Epoch: 5| Step: 10
Training loss: 0.15350720986750763
Validation loss: 2.471126477745808

Epoch: 680| Step: 0
Training loss: 0.11256578197756885
Validation loss: 2.4181666939851323

Epoch: 5| Step: 1
Training loss: 0.10446168775276926
Validation loss: 2.4491265816314614

Epoch: 5| Step: 2
Training loss: 0.08735441779944302
Validation loss: 2.4174296228838306

Epoch: 5| Step: 3
Training loss: 0.10364189184384505
Validation loss: 2.409067046324261

Epoch: 5| Step: 4
Training loss: 0.1813075488084135
Validation loss: 2.410071628329712

Epoch: 5| Step: 5
Training loss: 0.16804477723149924
Validation loss: 2.3973363462482546

Epoch: 5| Step: 6
Training loss: 0.14530296755872693
Validation loss: 2.3793922476274805

Epoch: 5| Step: 7
Training loss: 0.17168880260516353
Validation loss: 2.365937868246012

Epoch: 5| Step: 8
Training loss: 0.27028318918771643
Validation loss: 2.4031822285359414

Epoch: 5| Step: 9
Training loss: 0.1429294281962655
Validation loss: 2.383392487183456

Epoch: 5| Step: 10
Training loss: 0.1193300055295351
Validation loss: 2.397349734194159

Epoch: 681| Step: 0
Training loss: 0.10797375750902147
Validation loss: 2.433621983560316

Epoch: 5| Step: 1
Training loss: 0.125948577552216
Validation loss: 2.453166962617334

Epoch: 5| Step: 2
Training loss: 0.1408815361929335
Validation loss: 2.4056700620361875

Epoch: 5| Step: 3
Training loss: 0.23747592603240078
Validation loss: 2.4214919132308363

Epoch: 5| Step: 4
Training loss: 0.14963287960702867
Validation loss: 2.40657116105489

Epoch: 5| Step: 5
Training loss: 0.1567653798953383
Validation loss: 2.462009721513953

Epoch: 5| Step: 6
Training loss: 0.19446919535359555
Validation loss: 2.440428783030182

Epoch: 5| Step: 7
Training loss: 0.15183914808289767
Validation loss: 2.4553884015053264

Epoch: 5| Step: 8
Training loss: 0.1836986850592306
Validation loss: 2.4467300247831156

Epoch: 5| Step: 9
Training loss: 0.12606085685052493
Validation loss: 2.410098493484366

Epoch: 5| Step: 10
Training loss: 0.12472946723927046
Validation loss: 2.438706861756638

Epoch: 682| Step: 0
Training loss: 0.14539363400862526
Validation loss: 2.42986037720123

Epoch: 5| Step: 1
Training loss: 0.19070921702579918
Validation loss: 2.4044846151652544

Epoch: 5| Step: 2
Training loss: 0.18234545845009356
Validation loss: 2.3841874632491615

Epoch: 5| Step: 3
Training loss: 0.11521434205704711
Validation loss: 2.373793230096248

Epoch: 5| Step: 4
Training loss: 0.14979775722343744
Validation loss: 2.450282339093038

Epoch: 5| Step: 5
Training loss: 0.13823274472925556
Validation loss: 2.427383525405308

Epoch: 5| Step: 6
Training loss: 0.19084366037676806
Validation loss: 2.4139688045336363

Epoch: 5| Step: 7
Training loss: 0.11949082404659132
Validation loss: 2.4089168477681984

Epoch: 5| Step: 8
Training loss: 0.21896231089341706
Validation loss: 2.397023619476117

Epoch: 5| Step: 9
Training loss: 0.1389506787863662
Validation loss: 2.4224214168320684

Epoch: 5| Step: 10
Training loss: 0.21726465878619858
Validation loss: 2.433492154298692

Epoch: 683| Step: 0
Training loss: 0.12605468043092957
Validation loss: 2.4193376420889967

Epoch: 5| Step: 1
Training loss: 0.13040956365368703
Validation loss: 2.447205309293215

Epoch: 5| Step: 2
Training loss: 0.13592211373169297
Validation loss: 2.432399756225327

Epoch: 5| Step: 3
Training loss: 0.09837537633073798
Validation loss: 2.4508421630992645

Epoch: 5| Step: 4
Training loss: 0.21416016112056646
Validation loss: 2.4281798882810226

Epoch: 5| Step: 5
Training loss: 0.19890983791067016
Validation loss: 2.4271405112203417

Epoch: 5| Step: 6
Training loss: 0.2382701808672245
Validation loss: 2.4290507415694464

Epoch: 5| Step: 7
Training loss: 0.11472537076783758
Validation loss: 2.434470981613586

Epoch: 5| Step: 8
Training loss: 0.08941588938635357
Validation loss: 2.4582615192353043

Epoch: 5| Step: 9
Training loss: 0.15589902918317897
Validation loss: 2.4317850935088985

Epoch: 5| Step: 10
Training loss: 0.1369300299678439
Validation loss: 2.4110487641919507

Epoch: 684| Step: 0
Training loss: 0.17403609447069235
Validation loss: 2.430169863669978

Epoch: 5| Step: 1
Training loss: 0.15034920258229695
Validation loss: 2.4719009716861544

Epoch: 5| Step: 2
Training loss: 0.10295111652087714
Validation loss: 2.41460468816809

Epoch: 5| Step: 3
Training loss: 0.14224839295206906
Validation loss: 2.44309659959852

Epoch: 5| Step: 4
Training loss: 0.0965289617136329
Validation loss: 2.435681104330703

Epoch: 5| Step: 5
Training loss: 0.11983215427003772
Validation loss: 2.4136855476299

Epoch: 5| Step: 6
Training loss: 0.10483794184883077
Validation loss: 2.431489500240601

Epoch: 5| Step: 7
Training loss: 0.12679870457248865
Validation loss: 2.405662659909216

Epoch: 5| Step: 8
Training loss: 0.061284509566289024
Validation loss: 2.418486956284132

Epoch: 5| Step: 9
Training loss: 0.17210735524187656
Validation loss: 2.428779284851077

Epoch: 5| Step: 10
Training loss: 0.19183786540770595
Validation loss: 2.462659413560272

Epoch: 685| Step: 0
Training loss: 0.17266947104465422
Validation loss: 2.4037958691435692

Epoch: 5| Step: 1
Training loss: 0.14262205257178623
Validation loss: 2.41284201296061

Epoch: 5| Step: 2
Training loss: 0.13563540258374074
Validation loss: 2.3970322824911388

Epoch: 5| Step: 3
Training loss: 0.15079232852142635
Validation loss: 2.431337528881758

Epoch: 5| Step: 4
Training loss: 0.08737533834089006
Validation loss: 2.410980716483579

Epoch: 5| Step: 5
Training loss: 0.17439617607784194
Validation loss: 2.4436693156021065

Epoch: 5| Step: 6
Training loss: 0.1640329618202956
Validation loss: 2.4263620982230427

Epoch: 5| Step: 7
Training loss: 0.1334842006852339
Validation loss: 2.4336246068529617

Epoch: 5| Step: 8
Training loss: 0.12525709356657105
Validation loss: 2.4157440141370814

Epoch: 5| Step: 9
Training loss: 0.13677041576183266
Validation loss: 2.421281611814065

Epoch: 5| Step: 10
Training loss: 0.18335440435120712
Validation loss: 2.4579675575082556

Epoch: 686| Step: 0
Training loss: 0.18044131181877257
Validation loss: 2.4152759391232035

Epoch: 5| Step: 1
Training loss: 0.16577458554318042
Validation loss: 2.452674044665323

Epoch: 5| Step: 2
Training loss: 0.20534271247287006
Validation loss: 2.4314516361332963

Epoch: 5| Step: 3
Training loss: 0.12304517199836427
Validation loss: 2.4272962618768577

Epoch: 5| Step: 4
Training loss: 0.10826271598971872
Validation loss: 2.43972200284156

Epoch: 5| Step: 5
Training loss: 0.08704543632444148
Validation loss: 2.437044728528279

Epoch: 5| Step: 6
Training loss: 0.11890560170020723
Validation loss: 2.411883089251354

Epoch: 5| Step: 7
Training loss: 0.09613858626851465
Validation loss: 2.4176824227452247

Epoch: 5| Step: 8
Training loss: 0.1243339428815088
Validation loss: 2.420155249446217

Epoch: 5| Step: 9
Training loss: 0.08810840751467194
Validation loss: 2.4166091499089464

Epoch: 5| Step: 10
Training loss: 0.10738624502047474
Validation loss: 2.420370955824398

Epoch: 687| Step: 0
Training loss: 0.10248145347079946
Validation loss: 2.4149396034195214

Epoch: 5| Step: 1
Training loss: 0.13595888282053217
Validation loss: 2.445041664429194

Epoch: 5| Step: 2
Training loss: 0.1280125939014896
Validation loss: 2.427967785144554

Epoch: 5| Step: 3
Training loss: 0.07365219432822735
Validation loss: 2.4144758598099174

Epoch: 5| Step: 4
Training loss: 0.18526824308509482
Validation loss: 2.3926896031091274

Epoch: 5| Step: 5
Training loss: 0.12419562139458896
Validation loss: 2.390618858514498

Epoch: 5| Step: 6
Training loss: 0.08237149995211711
Validation loss: 2.396016802368176

Epoch: 5| Step: 7
Training loss: 0.09546051609537277
Validation loss: 2.4045309524599014

Epoch: 5| Step: 8
Training loss: 0.09453409836946691
Validation loss: 2.4295834069042175

Epoch: 5| Step: 9
Training loss: 0.14690440040913885
Validation loss: 2.4037733731543867

Epoch: 5| Step: 10
Training loss: 0.21267966220750326
Validation loss: 2.40314199286752

Epoch: 688| Step: 0
Training loss: 0.1990071931148791
Validation loss: 2.373433184022849

Epoch: 5| Step: 1
Training loss: 0.1855601556944014
Validation loss: 2.4296191096123256

Epoch: 5| Step: 2
Training loss: 0.10492507005145661
Validation loss: 2.4048290619840578

Epoch: 5| Step: 3
Training loss: 0.12185702955588769
Validation loss: 2.385960153527948

Epoch: 5| Step: 4
Training loss: 0.13719592609467066
Validation loss: 2.4257464282280132

Epoch: 5| Step: 5
Training loss: 0.10119962974344436
Validation loss: 2.4057316343602735

Epoch: 5| Step: 6
Training loss: 0.11548937853313344
Validation loss: 2.450477361623138

Epoch: 5| Step: 7
Training loss: 0.14999532145912803
Validation loss: 2.4602193346711663

Epoch: 5| Step: 8
Training loss: 0.14028733164749915
Validation loss: 2.476064984829842

Epoch: 5| Step: 9
Training loss: 0.11401033907150386
Validation loss: 2.4271957672101756

Epoch: 5| Step: 10
Training loss: 0.07840287442142016
Validation loss: 2.438208539878894

Epoch: 689| Step: 0
Training loss: 0.09337773521597058
Validation loss: 2.450506155468685

Epoch: 5| Step: 1
Training loss: 0.16702196067729208
Validation loss: 2.4062649316621423

Epoch: 5| Step: 2
Training loss: 0.15459945441594833
Validation loss: 2.4171858078945068

Epoch: 5| Step: 3
Training loss: 0.13732680933416824
Validation loss: 2.4200596955741216

Epoch: 5| Step: 4
Training loss: 0.18004938669992757
Validation loss: 2.429087896939142

Epoch: 5| Step: 5
Training loss: 0.09358042540137569
Validation loss: 2.409164148200408

Epoch: 5| Step: 6
Training loss: 0.12558729814708924
Validation loss: 2.4012806098412796

Epoch: 5| Step: 7
Training loss: 0.09141644315046064
Validation loss: 2.393013055449417

Epoch: 5| Step: 8
Training loss: 0.1031251912765463
Validation loss: 2.4042871974724545

Epoch: 5| Step: 9
Training loss: 0.12304281046375887
Validation loss: 2.3818513924672704

Epoch: 5| Step: 10
Training loss: 0.066517921825009
Validation loss: 2.395497503904292

Epoch: 690| Step: 0
Training loss: 0.14690216249542046
Validation loss: 2.394600884459661

Epoch: 5| Step: 1
Training loss: 0.1185644514974461
Validation loss: 2.402650267899271

Epoch: 5| Step: 2
Training loss: 0.10683728588585349
Validation loss: 2.3838939271056847

Epoch: 5| Step: 3
Training loss: 0.1686595749533479
Validation loss: 2.3935794845522067

Epoch: 5| Step: 4
Training loss: 0.13492516735060164
Validation loss: 2.385777622706718

Epoch: 5| Step: 5
Training loss: 0.07745182765769162
Validation loss: 2.395893743180536

Epoch: 5| Step: 6
Training loss: 0.08336291092503069
Validation loss: 2.420845130859329

Epoch: 5| Step: 7
Training loss: 0.09427387178206711
Validation loss: 2.4015916411522955

Epoch: 5| Step: 8
Training loss: 0.1267719002346802
Validation loss: 2.416953665636732

Epoch: 5| Step: 9
Training loss: 0.15511709415468525
Validation loss: 2.4496960141009554

Epoch: 5| Step: 10
Training loss: 0.0885652295716986
Validation loss: 2.4236431948490593

Epoch: 691| Step: 0
Training loss: 0.15683916000723
Validation loss: 2.4529525072295915

Epoch: 5| Step: 1
Training loss: 0.08689535668346107
Validation loss: 2.4193998848744713

Epoch: 5| Step: 2
Training loss: 0.15814501083544405
Validation loss: 2.389697446212908

Epoch: 5| Step: 3
Training loss: 0.08526823222777583
Validation loss: 2.412133753866208

Epoch: 5| Step: 4
Training loss: 0.09883062902301432
Validation loss: 2.4141473938071005

Epoch: 5| Step: 5
Training loss: 0.09989470399523827
Validation loss: 2.3748220259384256

Epoch: 5| Step: 6
Training loss: 0.10026693684155354
Validation loss: 2.3940516827070915

Epoch: 5| Step: 7
Training loss: 0.0904749898949254
Validation loss: 2.4343590947239924

Epoch: 5| Step: 8
Training loss: 0.10835125471931349
Validation loss: 2.410403809350186

Epoch: 5| Step: 9
Training loss: 0.0700104304508373
Validation loss: 2.415936399653328

Epoch: 5| Step: 10
Training loss: 0.18562981608915124
Validation loss: 2.4050699298740894

Epoch: 692| Step: 0
Training loss: 0.06807718957784104
Validation loss: 2.4188633744997046

Epoch: 5| Step: 1
Training loss: 0.21263280182888275
Validation loss: 2.4266405190602147

Epoch: 5| Step: 2
Training loss: 0.16298406240078359
Validation loss: 2.423064721844654

Epoch: 5| Step: 3
Training loss: 0.090730140385547
Validation loss: 2.3920511700345366

Epoch: 5| Step: 4
Training loss: 0.10350393733134877
Validation loss: 2.4222578473187215

Epoch: 5| Step: 5
Training loss: 0.18026384925347913
Validation loss: 2.430775706042815

Epoch: 5| Step: 6
Training loss: 0.10822071077133041
Validation loss: 2.4305031456597406

Epoch: 5| Step: 7
Training loss: 0.09327614757506197
Validation loss: 2.4469857510018254

Epoch: 5| Step: 8
Training loss: 0.07557165419989514
Validation loss: 2.4331075123025663

Epoch: 5| Step: 9
Training loss: 0.11139670986561707
Validation loss: 2.412128131593088

Epoch: 5| Step: 10
Training loss: 0.11804867462210328
Validation loss: 2.429222120132869

Epoch: 693| Step: 0
Training loss: 0.1163067062442573
Validation loss: 2.4092093271351747

Epoch: 5| Step: 1
Training loss: 0.11029064134128508
Validation loss: 2.415521961273994

Epoch: 5| Step: 2
Training loss: 0.1434264356214497
Validation loss: 2.435682298958112

Epoch: 5| Step: 3
Training loss: 0.17887157245700305
Validation loss: 2.4103745300686734

Epoch: 5| Step: 4
Training loss: 0.08820588209355523
Validation loss: 2.4032982763482775

Epoch: 5| Step: 5
Training loss: 0.06452170249425188
Validation loss: 2.4531704488452237

Epoch: 5| Step: 6
Training loss: 0.10256875380297022
Validation loss: 2.432352952254666

Epoch: 5| Step: 7
Training loss: 0.15413235693912644
Validation loss: 2.447494095089379

Epoch: 5| Step: 8
Training loss: 0.18936896667060152
Validation loss: 2.405712966962619

Epoch: 5| Step: 9
Training loss: 0.13578169405593515
Validation loss: 2.416604626474157

Epoch: 5| Step: 10
Training loss: 0.12953687072403386
Validation loss: 2.392479656671888

Epoch: 694| Step: 0
Training loss: 0.16586843023858322
Validation loss: 2.4294130726722076

Epoch: 5| Step: 1
Training loss: 0.17662527057265218
Validation loss: 2.4452212097557915

Epoch: 5| Step: 2
Training loss: 0.1116433616179977
Validation loss: 2.426330116455

Epoch: 5| Step: 3
Training loss: 0.16055549310724604
Validation loss: 2.408427982072149

Epoch: 5| Step: 4
Training loss: 0.052550365692766346
Validation loss: 2.4339825587841437

Epoch: 5| Step: 5
Training loss: 0.122796629190836
Validation loss: 2.431875100238439

Epoch: 5| Step: 6
Training loss: 0.10345960396737783
Validation loss: 2.4251087766488912

Epoch: 5| Step: 7
Training loss: 0.12354683726575379
Validation loss: 2.4435854836258755

Epoch: 5| Step: 8
Training loss: 0.11671359081432683
Validation loss: 2.4211557008852806

Epoch: 5| Step: 9
Training loss: 0.13061623973994285
Validation loss: 2.4483854748619205

Epoch: 5| Step: 10
Training loss: 0.11817552179935949
Validation loss: 2.4486309401432726

Epoch: 695| Step: 0
Training loss: 0.08098791715874697
Validation loss: 2.446616033881433

Epoch: 5| Step: 1
Training loss: 0.12024825396504381
Validation loss: 2.4229295216463598

Epoch: 5| Step: 2
Training loss: 0.17926427507420079
Validation loss: 2.456478074428394

Epoch: 5| Step: 3
Training loss: 0.09011886808418205
Validation loss: 2.4394268469056586

Epoch: 5| Step: 4
Training loss: 0.20162213500483012
Validation loss: 2.44306758830462

Epoch: 5| Step: 5
Training loss: 0.10067471502988178
Validation loss: 2.4150599485775763

Epoch: 5| Step: 6
Training loss: 0.08645650080621235
Validation loss: 2.4525522326672506

Epoch: 5| Step: 7
Training loss: 0.09703024492035033
Validation loss: 2.43265527374216

Epoch: 5| Step: 8
Training loss: 0.11932943579261147
Validation loss: 2.4323823147833723

Epoch: 5| Step: 9
Training loss: 0.08671612381180421
Validation loss: 2.4423747700887986

Epoch: 5| Step: 10
Training loss: 0.15309821887247857
Validation loss: 2.416901893822602

Epoch: 696| Step: 0
Training loss: 0.08800403906889097
Validation loss: 2.4019492295531926

Epoch: 5| Step: 1
Training loss: 0.11658241300029885
Validation loss: 2.419751811000692

Epoch: 5| Step: 2
Training loss: 0.13845894813152376
Validation loss: 2.4138072929933125

Epoch: 5| Step: 3
Training loss: 0.10845043464575085
Validation loss: 2.407407095936006

Epoch: 5| Step: 4
Training loss: 0.1149685590202734
Validation loss: 2.391171755254528

Epoch: 5| Step: 5
Training loss: 0.20378699999382144
Validation loss: 2.432206002539091

Epoch: 5| Step: 6
Training loss: 0.08401685463706254
Validation loss: 2.439181113844092

Epoch: 5| Step: 7
Training loss: 0.17832178990565756
Validation loss: 2.433102903638665

Epoch: 5| Step: 8
Training loss: 0.16027941852318267
Validation loss: 2.4441209810116193

Epoch: 5| Step: 9
Training loss: 0.12468119288628744
Validation loss: 2.428426151824172

Epoch: 5| Step: 10
Training loss: 0.0724377965349179
Validation loss: 2.3947498254093635

Epoch: 697| Step: 0
Training loss: 0.09021912813388186
Validation loss: 2.3840538660514365

Epoch: 5| Step: 1
Training loss: 0.10400588074005332
Validation loss: 2.412953183850925

Epoch: 5| Step: 2
Training loss: 0.115778527272858
Validation loss: 2.372150009705671

Epoch: 5| Step: 3
Training loss: 0.12894292511993494
Validation loss: 2.3830754210852434

Epoch: 5| Step: 4
Training loss: 0.20360004372870288
Validation loss: 2.3827226992717736

Epoch: 5| Step: 5
Training loss: 0.11127987451809328
Validation loss: 2.358719801390979

Epoch: 5| Step: 6
Training loss: 0.11614801803239086
Validation loss: 2.402640119590171

Epoch: 5| Step: 7
Training loss: 0.10780822462091073
Validation loss: 2.3639263002607525

Epoch: 5| Step: 8
Training loss: 0.08779991555231591
Validation loss: 2.432603936741316

Epoch: 5| Step: 9
Training loss: 0.08834108839691103
Validation loss: 2.4484806996735062

Epoch: 5| Step: 10
Training loss: 0.17069179030264167
Validation loss: 2.4549909415597035

Epoch: 698| Step: 0
Training loss: 0.06849417338685539
Validation loss: 2.422791581800334

Epoch: 5| Step: 1
Training loss: 0.09012427280254336
Validation loss: 2.4217145768092125

Epoch: 5| Step: 2
Training loss: 0.0848670610742787
Validation loss: 2.3702984599386476

Epoch: 5| Step: 3
Training loss: 0.08213024183677389
Validation loss: 2.4139368507942933

Epoch: 5| Step: 4
Training loss: 0.16529112533448317
Validation loss: 2.415648678440936

Epoch: 5| Step: 5
Training loss: 0.17860301985758675
Validation loss: 2.4338045391234266

Epoch: 5| Step: 6
Training loss: 0.15046901022511258
Validation loss: 2.4197310522980744

Epoch: 5| Step: 7
Training loss: 0.08385355319318014
Validation loss: 2.40028599193853

Epoch: 5| Step: 8
Training loss: 0.08223441204289104
Validation loss: 2.4321828662671083

Epoch: 5| Step: 9
Training loss: 0.13502244389693782
Validation loss: 2.4024256325036473

Epoch: 5| Step: 10
Training loss: 0.11165464769660918
Validation loss: 2.4140139349652574

Epoch: 699| Step: 0
Training loss: 0.10503177719698942
Validation loss: 2.4059975348742553

Epoch: 5| Step: 1
Training loss: 0.12723847378848047
Validation loss: 2.4115271721371943

Epoch: 5| Step: 2
Training loss: 0.265139500724571
Validation loss: 2.4402373629915473

Epoch: 5| Step: 3
Training loss: 0.12311058060449963
Validation loss: 2.4128320225336526

Epoch: 5| Step: 4
Training loss: 0.1240120717345011
Validation loss: 2.385072110333427

Epoch: 5| Step: 5
Training loss: 0.07913507234482053
Validation loss: 2.447564512400575

Epoch: 5| Step: 6
Training loss: 0.10987694125554545
Validation loss: 2.4385781408241773

Epoch: 5| Step: 7
Training loss: 0.10121557698424609
Validation loss: 2.4077920350163198

Epoch: 5| Step: 8
Training loss: 0.1027751656694731
Validation loss: 2.431645375600603

Epoch: 5| Step: 9
Training loss: 0.08562695682858273
Validation loss: 2.4182793321712746

Epoch: 5| Step: 10
Training loss: 0.08135502679962771
Validation loss: 2.4110200424695436

Epoch: 700| Step: 0
Training loss: 0.19825252261727583
Validation loss: 2.3960152493216427

Epoch: 5| Step: 1
Training loss: 0.09020527890744587
Validation loss: 2.4142347673183306

Epoch: 5| Step: 2
Training loss: 0.18549026830419674
Validation loss: 2.403240899055606

Epoch: 5| Step: 3
Training loss: 0.08470636078153813
Validation loss: 2.3882115397371386

Epoch: 5| Step: 4
Training loss: 0.09484885374065577
Validation loss: 2.3998953644783265

Epoch: 5| Step: 5
Training loss: 0.09676965707995493
Validation loss: 2.396123516669645

Epoch: 5| Step: 6
Training loss: 0.09652292662870911
Validation loss: 2.415424089710658

Epoch: 5| Step: 7
Training loss: 0.08005466931773687
Validation loss: 2.3777363831858325

Epoch: 5| Step: 8
Training loss: 0.10780742553848709
Validation loss: 2.390527387440242

Epoch: 5| Step: 9
Training loss: 0.14830599782333018
Validation loss: 2.4005907078907227

Epoch: 5| Step: 10
Training loss: 0.11311521776988473
Validation loss: 2.4014182458878355

Epoch: 701| Step: 0
Training loss: 0.10143534788767933
Validation loss: 2.420730953611964

Epoch: 5| Step: 1
Training loss: 0.10773736401865905
Validation loss: 2.4235491465028907

Epoch: 5| Step: 2
Training loss: 0.1610740207575153
Validation loss: 2.4190990998521578

Epoch: 5| Step: 3
Training loss: 0.13614420056428103
Validation loss: 2.4211565204350167

Epoch: 5| Step: 4
Training loss: 0.19039586084654145
Validation loss: 2.38353632532832

Epoch: 5| Step: 5
Training loss: 0.06891421556926075
Validation loss: 2.3873995322295927

Epoch: 5| Step: 6
Training loss: 0.13145974492369614
Validation loss: 2.3625162466002427

Epoch: 5| Step: 7
Training loss: 0.12992320472371716
Validation loss: 2.3418986741316794

Epoch: 5| Step: 8
Training loss: 0.1941370209603076
Validation loss: 2.351076074086078

Epoch: 5| Step: 9
Training loss: 0.06663204821035237
Validation loss: 2.3267243069791905

Epoch: 5| Step: 10
Training loss: 0.07893332498432638
Validation loss: 2.33894653309035

Epoch: 702| Step: 0
Training loss: 0.1304703666678219
Validation loss: 2.3635428438196504

Epoch: 5| Step: 1
Training loss: 0.1489076884801659
Validation loss: 2.3828589580276156

Epoch: 5| Step: 2
Training loss: 0.11298636580733679
Validation loss: 2.384465869379517

Epoch: 5| Step: 3
Training loss: 0.12191223208548478
Validation loss: 2.3986407195845043

Epoch: 5| Step: 4
Training loss: 0.12648156692516827
Validation loss: 2.405105737456109

Epoch: 5| Step: 5
Training loss: 0.08720680025332829
Validation loss: 2.4322133423304617

Epoch: 5| Step: 6
Training loss: 0.14791454878374385
Validation loss: 2.428659028918705

Epoch: 5| Step: 7
Training loss: 0.19178691302064663
Validation loss: 2.4339216126632395

Epoch: 5| Step: 8
Training loss: 0.1643147289444889
Validation loss: 2.399618952549329

Epoch: 5| Step: 9
Training loss: 0.1518332965033288
Validation loss: 2.42327106421838

Epoch: 5| Step: 10
Training loss: 0.0915393972218993
Validation loss: 2.417211416210123

Epoch: 703| Step: 0
Training loss: 0.12816968638676612
Validation loss: 2.399965960635525

Epoch: 5| Step: 1
Training loss: 0.19401968330082883
Validation loss: 2.4162905760735276

Epoch: 5| Step: 2
Training loss: 0.09267694575037388
Validation loss: 2.453195032045372

Epoch: 5| Step: 3
Training loss: 0.08327255106077576
Validation loss: 2.4073735509138077

Epoch: 5| Step: 4
Training loss: 0.1076011462293918
Validation loss: 2.4131974965937872

Epoch: 5| Step: 5
Training loss: 0.1792451035796461
Validation loss: 2.424902323705223

Epoch: 5| Step: 6
Training loss: 0.13657762191683298
Validation loss: 2.406525341358169

Epoch: 5| Step: 7
Training loss: 0.27739005978217873
Validation loss: 2.411583219065679

Epoch: 5| Step: 8
Training loss: 0.16443110112390816
Validation loss: 2.412428776750576

Epoch: 5| Step: 9
Training loss: 0.15496049691001312
Validation loss: 2.448824618603835

Epoch: 5| Step: 10
Training loss: 0.13263679550454036
Validation loss: 2.4388886506715743

Epoch: 704| Step: 0
Training loss: 0.11399315071444116
Validation loss: 2.4486330372212395

Epoch: 5| Step: 1
Training loss: 0.1218093906380558
Validation loss: 2.5002998848990003

Epoch: 5| Step: 2
Training loss: 0.16822385821416308
Validation loss: 2.4800380982454056

Epoch: 5| Step: 3
Training loss: 0.16926376010103725
Validation loss: 2.4438807090159997

Epoch: 5| Step: 4
Training loss: 0.14338459915563634
Validation loss: 2.409823709323139

Epoch: 5| Step: 5
Training loss: 0.183034491451844
Validation loss: 2.4018259811918616

Epoch: 5| Step: 6
Training loss: 0.13093807928189347
Validation loss: 2.393048010720208

Epoch: 5| Step: 7
Training loss: 0.166100558825913
Validation loss: 2.3969078999832236

Epoch: 5| Step: 8
Training loss: 0.14380290182719596
Validation loss: 2.3673362185688185

Epoch: 5| Step: 9
Training loss: 0.1957370150036269
Validation loss: 2.37203204461251

Epoch: 5| Step: 10
Training loss: 0.16238830881954636
Validation loss: 2.3957930462960175

Epoch: 705| Step: 0
Training loss: 0.12950451333371946
Validation loss: 2.398049804247827

Epoch: 5| Step: 1
Training loss: 0.12147104030664949
Validation loss: 2.3869756707313607

Epoch: 5| Step: 2
Training loss: 0.15217205912180046
Validation loss: 2.3677766956684194

Epoch: 5| Step: 3
Training loss: 0.15512802104444282
Validation loss: 2.3986921598438684

Epoch: 5| Step: 4
Training loss: 0.12852780826411506
Validation loss: 2.38006162529008

Epoch: 5| Step: 5
Training loss: 0.14579323802120087
Validation loss: 2.4092798951127388

Epoch: 5| Step: 6
Training loss: 0.13071311776815123
Validation loss: 2.423229587888001

Epoch: 5| Step: 7
Training loss: 0.2003325759361102
Validation loss: 2.408754900101168

Epoch: 5| Step: 8
Training loss: 0.17292888980678914
Validation loss: 2.3988459417922376

Epoch: 5| Step: 9
Training loss: 0.18509526757476846
Validation loss: 2.388346895515822

Epoch: 5| Step: 10
Training loss: 0.09013876990136722
Validation loss: 2.3957053736631595

Epoch: 706| Step: 0
Training loss: 0.17085793151385253
Validation loss: 2.3901710258833173

Epoch: 5| Step: 1
Training loss: 0.1346508726204687
Validation loss: 2.397391668420537

Epoch: 5| Step: 2
Training loss: 0.10537317590362144
Validation loss: 2.359587443239922

Epoch: 5| Step: 3
Training loss: 0.14253922153797513
Validation loss: 2.386180959619717

Epoch: 5| Step: 4
Training loss: 0.20546632990118946
Validation loss: 2.380287156359727

Epoch: 5| Step: 5
Training loss: 0.13932535505092125
Validation loss: 2.3545136438770666

Epoch: 5| Step: 6
Training loss: 0.09583646865912725
Validation loss: 2.381171663370744

Epoch: 5| Step: 7
Training loss: 0.123883427415789
Validation loss: 2.3779770802046265

Epoch: 5| Step: 8
Training loss: 0.1029196442946808
Validation loss: 2.3924866318594695

Epoch: 5| Step: 9
Training loss: 0.11179868899245923
Validation loss: 2.410360868001726

Epoch: 5| Step: 10
Training loss: 0.10852785804323786
Validation loss: 2.400185345812878

Epoch: 707| Step: 0
Training loss: 0.11233826011062256
Validation loss: 2.404438463564685

Epoch: 5| Step: 1
Training loss: 0.1692604257367358
Validation loss: 2.396012029274659

Epoch: 5| Step: 2
Training loss: 0.12319713833184234
Validation loss: 2.4138259089449305

Epoch: 5| Step: 3
Training loss: 0.11189646124777537
Validation loss: 2.4408506697314083

Epoch: 5| Step: 4
Training loss: 0.1900421895066875
Validation loss: 2.4252695937016573

Epoch: 5| Step: 5
Training loss: 0.13903715486691998
Validation loss: 2.4437092558862594

Epoch: 5| Step: 6
Training loss: 0.09648878342290974
Validation loss: 2.425147711269558

Epoch: 5| Step: 7
Training loss: 0.10819137833110073
Validation loss: 2.4232320497218933

Epoch: 5| Step: 8
Training loss: 0.07336521624099349
Validation loss: 2.4096339732493934

Epoch: 5| Step: 9
Training loss: 0.07991620883638138
Validation loss: 2.388470619381852

Epoch: 5| Step: 10
Training loss: 0.10516182515554572
Validation loss: 2.4096274163453537

Epoch: 708| Step: 0
Training loss: 0.1068200549396888
Validation loss: 2.3750548089249346

Epoch: 5| Step: 1
Training loss: 0.13942093758212884
Validation loss: 2.404527446354743

Epoch: 5| Step: 2
Training loss: 0.08493217715913791
Validation loss: 2.3874937039694797

Epoch: 5| Step: 3
Training loss: 0.16180472300130647
Validation loss: 2.378717173812413

Epoch: 5| Step: 4
Training loss: 0.08484482504144263
Validation loss: 2.388788801586111

Epoch: 5| Step: 5
Training loss: 0.11590998814145462
Validation loss: 2.410449435140495

Epoch: 5| Step: 6
Training loss: 0.10371739588310698
Validation loss: 2.4030204838231795

Epoch: 5| Step: 7
Training loss: 0.1438765777083791
Validation loss: 2.4405732943565996

Epoch: 5| Step: 8
Training loss: 0.1167468927279309
Validation loss: 2.478779854038709

Epoch: 5| Step: 9
Training loss: 0.1054995721355232
Validation loss: 2.431522817468191

Epoch: 5| Step: 10
Training loss: 0.18539914725255682
Validation loss: 2.4127412397948067

Epoch: 709| Step: 0
Training loss: 0.1269947937293431
Validation loss: 2.4268611489557856

Epoch: 5| Step: 1
Training loss: 0.13449822032559372
Validation loss: 2.425118574054123

Epoch: 5| Step: 2
Training loss: 0.16630028834411148
Validation loss: 2.4173097599930973

Epoch: 5| Step: 3
Training loss: 0.16918392089782527
Validation loss: 2.4064669618463745

Epoch: 5| Step: 4
Training loss: 0.10397303933593538
Validation loss: 2.4146564051892163

Epoch: 5| Step: 5
Training loss: 0.12429819310758368
Validation loss: 2.4236310009239577

Epoch: 5| Step: 6
Training loss: 0.11874130822671915
Validation loss: 2.397182165875795

Epoch: 5| Step: 7
Training loss: 0.12509182448123807
Validation loss: 2.4272094947980225

Epoch: 5| Step: 8
Training loss: 0.08658820853730943
Validation loss: 2.418387245719405

Epoch: 5| Step: 9
Training loss: 0.12049105464336218
Validation loss: 2.4300477986977405

Epoch: 5| Step: 10
Training loss: 0.07207492203690054
Validation loss: 2.4162623866802315

Epoch: 710| Step: 0
Training loss: 0.1754739512439512
Validation loss: 2.4280687873902695

Epoch: 5| Step: 1
Training loss: 0.10334876845845928
Validation loss: 2.4873291868860634

Epoch: 5| Step: 2
Training loss: 0.09152232364395178
Validation loss: 2.409304583520834

Epoch: 5| Step: 3
Training loss: 0.09657196825637267
Validation loss: 2.4339942774371575

Epoch: 5| Step: 4
Training loss: 0.09951409757277173
Validation loss: 2.4141598734372707

Epoch: 5| Step: 5
Training loss: 0.1233054275398643
Validation loss: 2.445810733179315

Epoch: 5| Step: 6
Training loss: 0.13440024560156588
Validation loss: 2.4463903981741657

Epoch: 5| Step: 7
Training loss: 0.07689348780646152
Validation loss: 2.4738033834657296

Epoch: 5| Step: 8
Training loss: 0.14842199570847392
Validation loss: 2.417847544990806

Epoch: 5| Step: 9
Training loss: 0.08098100277420678
Validation loss: 2.423571627648319

Epoch: 5| Step: 10
Training loss: 0.14311737480632344
Validation loss: 2.433270391461283

Epoch: 711| Step: 0
Training loss: 0.08663730813635233
Validation loss: 2.4377459656221885

Epoch: 5| Step: 1
Training loss: 0.1235537910730416
Validation loss: 2.433720995688066

Epoch: 5| Step: 2
Training loss: 0.10343674137234887
Validation loss: 2.415266095423228

Epoch: 5| Step: 3
Training loss: 0.07245221728166995
Validation loss: 2.401125158085702

Epoch: 5| Step: 4
Training loss: 0.167796617845018
Validation loss: 2.4309316983574307

Epoch: 5| Step: 5
Training loss: 0.10415960128982545
Validation loss: 2.425000889461563

Epoch: 5| Step: 6
Training loss: 0.1858925159919611
Validation loss: 2.4174807529531854

Epoch: 5| Step: 7
Training loss: 0.10796718040076198
Validation loss: 2.426815822209469

Epoch: 5| Step: 8
Training loss: 0.14537161655170572
Validation loss: 2.4070619625656855

Epoch: 5| Step: 9
Training loss: 0.09756068799250227
Validation loss: 2.4136389474192215

Epoch: 5| Step: 10
Training loss: 0.08630876917496424
Validation loss: 2.417704486316776

Epoch: 712| Step: 0
Training loss: 0.06463220311802899
Validation loss: 2.416442541571852

Epoch: 5| Step: 1
Training loss: 0.15964869578289048
Validation loss: 2.386693797883934

Epoch: 5| Step: 2
Training loss: 0.15232964597117404
Validation loss: 2.389988685258816

Epoch: 5| Step: 3
Training loss: 0.10082935767112654
Validation loss: 2.3823271947277

Epoch: 5| Step: 4
Training loss: 0.12957568173903528
Validation loss: 2.3933630607724674

Epoch: 5| Step: 5
Training loss: 0.1723306749317606
Validation loss: 2.4102672235508718

Epoch: 5| Step: 6
Training loss: 0.11234225598430815
Validation loss: 2.3948252389930746

Epoch: 5| Step: 7
Training loss: 0.07774915590606178
Validation loss: 2.4324669286124316

Epoch: 5| Step: 8
Training loss: 0.08614465281789684
Validation loss: 2.417062917507029

Epoch: 5| Step: 9
Training loss: 0.1046799550255532
Validation loss: 2.421254714038882

Epoch: 5| Step: 10
Training loss: 0.09975560524824564
Validation loss: 2.421008020694064

Epoch: 713| Step: 0
Training loss: 0.06106037763193805
Validation loss: 2.4644341138252734

Epoch: 5| Step: 1
Training loss: 0.1215779330623824
Validation loss: 2.4707348566442646

Epoch: 5| Step: 2
Training loss: 0.13519258176199994
Validation loss: 2.44027080976554

Epoch: 5| Step: 3
Training loss: 0.0739040006301319
Validation loss: 2.442963854396759

Epoch: 5| Step: 4
Training loss: 0.09763511905935476
Validation loss: 2.4100492199066337

Epoch: 5| Step: 5
Training loss: 0.07435779346452275
Validation loss: 2.365741547089477

Epoch: 5| Step: 6
Training loss: 0.17683604916854914
Validation loss: 2.4016922657053437

Epoch: 5| Step: 7
Training loss: 0.1208477405442129
Validation loss: 2.370373044824644

Epoch: 5| Step: 8
Training loss: 0.2009709660498814
Validation loss: 2.3594581976699485

Epoch: 5| Step: 9
Training loss: 0.14167519332198736
Validation loss: 2.406117551088491

Epoch: 5| Step: 10
Training loss: 0.21671351986867488
Validation loss: 2.3961705131510187

Epoch: 714| Step: 0
Training loss: 0.08797602478169926
Validation loss: 2.419248033613467

Epoch: 5| Step: 1
Training loss: 0.13733215328640483
Validation loss: 2.404392621351816

Epoch: 5| Step: 2
Training loss: 0.17891353317494932
Validation loss: 2.40674938000229

Epoch: 5| Step: 3
Training loss: 0.1179276181507285
Validation loss: 2.408510629002656

Epoch: 5| Step: 4
Training loss: 0.08546316850419464
Validation loss: 2.4251961305154914

Epoch: 5| Step: 5
Training loss: 0.07667251657350081
Validation loss: 2.4099259677276623

Epoch: 5| Step: 6
Training loss: 0.20031892635255216
Validation loss: 2.393746412410493

Epoch: 5| Step: 7
Training loss: 0.09456002451649863
Validation loss: 2.422597988262608

Epoch: 5| Step: 8
Training loss: 0.09085731880406667
Validation loss: 2.419913875534135

Epoch: 5| Step: 9
Training loss: 0.12236266413819986
Validation loss: 2.4247260347952015

Epoch: 5| Step: 10
Training loss: 0.13717964007556416
Validation loss: 2.45347240677222

Epoch: 715| Step: 0
Training loss: 0.11304642739830169
Validation loss: 2.4426314109212237

Epoch: 5| Step: 1
Training loss: 0.1277378551347378
Validation loss: 2.381512061343187

Epoch: 5| Step: 2
Training loss: 0.18284924700240068
Validation loss: 2.4210237518776125

Epoch: 5| Step: 3
Training loss: 0.1564210610993934
Validation loss: 2.4272794813693235

Epoch: 5| Step: 4
Training loss: 0.09163371255988585
Validation loss: 2.4078434160525486

Epoch: 5| Step: 5
Training loss: 0.1232436589608107
Validation loss: 2.4022457886845197

Epoch: 5| Step: 6
Training loss: 0.09408234260227222
Validation loss: 2.3921007650455888

Epoch: 5| Step: 7
Training loss: 0.1003338980060167
Validation loss: 2.4555217766832342

Epoch: 5| Step: 8
Training loss: 0.14952796758040618
Validation loss: 2.425862051832911

Epoch: 5| Step: 9
Training loss: 0.0921088760304222
Validation loss: 2.437617524445127

Epoch: 5| Step: 10
Training loss: 0.07553635395266586
Validation loss: 2.4291320156300347

Epoch: 716| Step: 0
Training loss: 0.16545786566953613
Validation loss: 2.420450074679982

Epoch: 5| Step: 1
Training loss: 0.08869341219019918
Validation loss: 2.43186269880165

Epoch: 5| Step: 2
Training loss: 0.12239953087909836
Validation loss: 2.4237161995093817

Epoch: 5| Step: 3
Training loss: 0.10017365617556397
Validation loss: 2.4050333478807766

Epoch: 5| Step: 4
Training loss: 0.10396744532235208
Validation loss: 2.432256395107455

Epoch: 5| Step: 5
Training loss: 0.06577388062391844
Validation loss: 2.4074505305637155

Epoch: 5| Step: 6
Training loss: 0.08663359404534826
Validation loss: 2.4037478109836137

Epoch: 5| Step: 7
Training loss: 0.0658978890812818
Validation loss: 2.3997782237718357

Epoch: 5| Step: 8
Training loss: 0.17236041209829
Validation loss: 2.4299289638911277

Epoch: 5| Step: 9
Training loss: 0.1509029406320745
Validation loss: 2.402859619094812

Epoch: 5| Step: 10
Training loss: 0.09090245541691155
Validation loss: 2.3867586309528397

Epoch: 717| Step: 0
Training loss: 0.10270458667097458
Validation loss: 2.3714736769513842

Epoch: 5| Step: 1
Training loss: 0.16594902834564715
Validation loss: 2.403399978255143

Epoch: 5| Step: 2
Training loss: 0.09313643363714126
Validation loss: 2.4145812547724264

Epoch: 5| Step: 3
Training loss: 0.15486918915030087
Validation loss: 2.410708146468071

Epoch: 5| Step: 4
Training loss: 0.1440993570421125
Validation loss: 2.402974582553279

Epoch: 5| Step: 5
Training loss: 0.09225630435329521
Validation loss: 2.3976488178504343

Epoch: 5| Step: 6
Training loss: 0.08305965936143415
Validation loss: 2.41369120344965

Epoch: 5| Step: 7
Training loss: 0.11176376686247481
Validation loss: 2.4440581363566474

Epoch: 5| Step: 8
Training loss: 0.09994649405590961
Validation loss: 2.393681867138519

Epoch: 5| Step: 9
Training loss: 0.08295243603938857
Validation loss: 2.401545740327509

Epoch: 5| Step: 10
Training loss: 0.11374899470099892
Validation loss: 2.403740471994485

Epoch: 718| Step: 0
Training loss: 0.08123301514204397
Validation loss: 2.428168477308867

Epoch: 5| Step: 1
Training loss: 0.1225646120090776
Validation loss: 2.4023556144495415

Epoch: 5| Step: 2
Training loss: 0.1488148135141989
Validation loss: 2.4000751515640677

Epoch: 5| Step: 3
Training loss: 0.08943219877122731
Validation loss: 2.3947639589799157

Epoch: 5| Step: 4
Training loss: 0.10482127517254723
Validation loss: 2.3865446082184323

Epoch: 5| Step: 5
Training loss: 0.06408567881529052
Validation loss: 2.3802608529881497

Epoch: 5| Step: 6
Training loss: 0.14831951747959507
Validation loss: 2.3897348776662657

Epoch: 5| Step: 7
Training loss: 0.06794163242434693
Validation loss: 2.3948205277542955

Epoch: 5| Step: 8
Training loss: 0.06971861449390479
Validation loss: 2.379907785397286

Epoch: 5| Step: 9
Training loss: 0.09762199754835799
Validation loss: 2.3506301526788005

Epoch: 5| Step: 10
Training loss: 0.16883184779280264
Validation loss: 2.417761100472478

Epoch: 719| Step: 0
Training loss: 0.11794775087517351
Validation loss: 2.369875650271103

Epoch: 5| Step: 1
Training loss: 0.0714884152338986
Validation loss: 2.3694535582292846

Epoch: 5| Step: 2
Training loss: 0.08748881894437908
Validation loss: 2.3700427730403075

Epoch: 5| Step: 3
Training loss: 0.11350469503139464
Validation loss: 2.3111077307726213

Epoch: 5| Step: 4
Training loss: 0.09974187565286644
Validation loss: 2.354255029571986

Epoch: 5| Step: 5
Training loss: 0.1690768022357698
Validation loss: 2.369333388460707

Epoch: 5| Step: 6
Training loss: 0.07347746253793254
Validation loss: 2.35753561684931

Epoch: 5| Step: 7
Training loss: 0.11041812239742935
Validation loss: 2.393808320344229

Epoch: 5| Step: 8
Training loss: 0.08007547327628854
Validation loss: 2.380747579843204

Epoch: 5| Step: 9
Training loss: 0.10849612362206268
Validation loss: 2.364591355007743

Epoch: 5| Step: 10
Training loss: 0.16660761470020383
Validation loss: 2.376256760274436

Epoch: 720| Step: 0
Training loss: 0.06988162235336173
Validation loss: 2.402696683249679

Epoch: 5| Step: 1
Training loss: 0.11359141491033872
Validation loss: 2.3936279383132852

Epoch: 5| Step: 2
Training loss: 0.09271045856057991
Validation loss: 2.406856764538086

Epoch: 5| Step: 3
Training loss: 0.06806442115548908
Validation loss: 2.4004615451409945

Epoch: 5| Step: 4
Training loss: 0.09152853582381759
Validation loss: 2.3840799383192874

Epoch: 5| Step: 5
Training loss: 0.08745461238310506
Validation loss: 2.4171585675735994

Epoch: 5| Step: 6
Training loss: 0.15808314612930863
Validation loss: 2.4133593899329746

Epoch: 5| Step: 7
Training loss: 0.1776903118806028
Validation loss: 2.3916258213305204

Epoch: 5| Step: 8
Training loss: 0.10106278322554083
Validation loss: 2.3947368254482715

Epoch: 5| Step: 9
Training loss: 0.09167689233427058
Validation loss: 2.384359603150673

Epoch: 5| Step: 10
Training loss: 0.12487887310369025
Validation loss: 2.426498534521085

Epoch: 721| Step: 0
Training loss: 0.19705483533651577
Validation loss: 2.3877718652520166

Epoch: 5| Step: 1
Training loss: 0.11761172913827696
Validation loss: 2.4151775151786126

Epoch: 5| Step: 2
Training loss: 0.11228859827641963
Validation loss: 2.3870578516447827

Epoch: 5| Step: 3
Training loss: 0.07725506367549101
Validation loss: 2.4225557913892

Epoch: 5| Step: 4
Training loss: 0.0715779402215634
Validation loss: 2.4041854680509926

Epoch: 5| Step: 5
Training loss: 0.09649805385135504
Validation loss: 2.364817360323143

Epoch: 5| Step: 6
Training loss: 0.11477205104638326
Validation loss: 2.4043535617533993

Epoch: 5| Step: 7
Training loss: 0.09873466143209617
Validation loss: 2.3694089839947967

Epoch: 5| Step: 8
Training loss: 0.0719715268423009
Validation loss: 2.3796873247876964

Epoch: 5| Step: 9
Training loss: 0.14069154277620874
Validation loss: 2.382900525421756

Epoch: 5| Step: 10
Training loss: 0.07013353446779215
Validation loss: 2.3854619324734694

Epoch: 722| Step: 0
Training loss: 0.07299092427083068
Validation loss: 2.3841344411913936

Epoch: 5| Step: 1
Training loss: 0.14502272939527117
Validation loss: 2.372663593284587

Epoch: 5| Step: 2
Training loss: 0.0772160825048642
Validation loss: 2.384108249085557

Epoch: 5| Step: 3
Training loss: 0.12011535767192694
Validation loss: 2.396675493303201

Epoch: 5| Step: 4
Training loss: 0.1477319298919598
Validation loss: 2.392414607340383

Epoch: 5| Step: 5
Training loss: 0.1255316826245747
Validation loss: 2.4060001059747895

Epoch: 5| Step: 6
Training loss: 0.1438556940820343
Validation loss: 2.4174211591620596

Epoch: 5| Step: 7
Training loss: 0.07259670016788365
Validation loss: 2.396346560949197

Epoch: 5| Step: 8
Training loss: 0.08055204783718843
Validation loss: 2.421614869987322

Epoch: 5| Step: 9
Training loss: 0.10318766229028722
Validation loss: 2.4030579003108032

Epoch: 5| Step: 10
Training loss: 0.05513530064879681
Validation loss: 2.3892394824349372

Epoch: 723| Step: 0
Training loss: 0.12507376133671216
Validation loss: 2.416242515236152

Epoch: 5| Step: 1
Training loss: 0.1519002020592661
Validation loss: 2.3878889588358154

Epoch: 5| Step: 2
Training loss: 0.10237032767260397
Validation loss: 2.3928711025994827

Epoch: 5| Step: 3
Training loss: 0.13774569245836482
Validation loss: 2.392936605017478

Epoch: 5| Step: 4
Training loss: 0.08417428247132792
Validation loss: 2.3917618043975715

Epoch: 5| Step: 5
Training loss: 0.09348372553517369
Validation loss: 2.378104063416787

Epoch: 5| Step: 6
Training loss: 0.07464826678661267
Validation loss: 2.4172093634610237

Epoch: 5| Step: 7
Training loss: 0.08915436632925557
Validation loss: 2.401796844974902

Epoch: 5| Step: 8
Training loss: 0.15624763367768407
Validation loss: 2.424909685603594

Epoch: 5| Step: 9
Training loss: 0.07868803805776316
Validation loss: 2.4144988246610577

Epoch: 5| Step: 10
Training loss: 0.07981357838627297
Validation loss: 2.4471253402659245

Epoch: 724| Step: 0
Training loss: 0.10517532097052519
Validation loss: 2.3874795504463426

Epoch: 5| Step: 1
Training loss: 0.1629782223897414
Validation loss: 2.3725944246726125

Epoch: 5| Step: 2
Training loss: 0.11062479373406184
Validation loss: 2.3980556786829665

Epoch: 5| Step: 3
Training loss: 0.11975109321985192
Validation loss: 2.393113702193601

Epoch: 5| Step: 4
Training loss: 0.11608707815691088
Validation loss: 2.3915465759069723

Epoch: 5| Step: 5
Training loss: 0.10839944271961857
Validation loss: 2.3712528235744386

Epoch: 5| Step: 6
Training loss: 0.0757506381224753
Validation loss: 2.3730356007948807

Epoch: 5| Step: 7
Training loss: 0.06379618503917797
Validation loss: 2.392328591375285

Epoch: 5| Step: 8
Training loss: 0.08166876244146763
Validation loss: 2.3717417903403746

Epoch: 5| Step: 9
Training loss: 0.1480031119914315
Validation loss: 2.409240440166195

Epoch: 5| Step: 10
Training loss: 0.11707051716590279
Validation loss: 2.4138274834561617

Epoch: 725| Step: 0
Training loss: 0.08781448350987595
Validation loss: 2.3877797592794527

Epoch: 5| Step: 1
Training loss: 0.1330841735911054
Validation loss: 2.411526831952323

Epoch: 5| Step: 2
Training loss: 0.07173544445811052
Validation loss: 2.4172574490882917

Epoch: 5| Step: 3
Training loss: 0.10507075397348503
Validation loss: 2.406571785301221

Epoch: 5| Step: 4
Training loss: 0.15913149917534786
Validation loss: 2.377354987642207

Epoch: 5| Step: 5
Training loss: 0.08231926209629566
Validation loss: 2.4068248953231133

Epoch: 5| Step: 6
Training loss: 0.0831011219658507
Validation loss: 2.38066368534071

Epoch: 5| Step: 7
Training loss: 0.1429486164132969
Validation loss: 2.3949929738220517

Epoch: 5| Step: 8
Training loss: 0.09315586073978692
Validation loss: 2.3947818633454734

Epoch: 5| Step: 9
Training loss: 0.07201614683383875
Validation loss: 2.397430972971402

Epoch: 5| Step: 10
Training loss: 0.061805811270858685
Validation loss: 2.4271363142507694

Epoch: 726| Step: 0
Training loss: 0.06407200957870546
Validation loss: 2.412377233546701

Epoch: 5| Step: 1
Training loss: 0.06837507135838197
Validation loss: 2.4233357004982152

Epoch: 5| Step: 2
Training loss: 0.08885052283680091
Validation loss: 2.4345920598085415

Epoch: 5| Step: 3
Training loss: 0.15449072937210978
Validation loss: 2.4149003141919123

Epoch: 5| Step: 4
Training loss: 0.13991096468955322
Validation loss: 2.436399380159813

Epoch: 5| Step: 5
Training loss: 0.11873647666147413
Validation loss: 2.411928186432262

Epoch: 5| Step: 6
Training loss: 0.09535803176331371
Validation loss: 2.3996985777304674

Epoch: 5| Step: 7
Training loss: 0.11013555061707174
Validation loss: 2.39490134305593

Epoch: 5| Step: 8
Training loss: 0.08329659045590682
Validation loss: 2.3771192662280325

Epoch: 5| Step: 9
Training loss: 0.17938734984001853
Validation loss: 2.419229421236106

Epoch: 5| Step: 10
Training loss: 0.10319669193053704
Validation loss: 2.4173761877860174

Epoch: 727| Step: 0
Training loss: 0.11735335375500157
Validation loss: 2.4021678839845912

Epoch: 5| Step: 1
Training loss: 0.07030597961180322
Validation loss: 2.3923503449372663

Epoch: 5| Step: 2
Training loss: 0.09853118911182326
Validation loss: 2.3899963901492685

Epoch: 5| Step: 3
Training loss: 0.09117456278561464
Validation loss: 2.3793295120664704

Epoch: 5| Step: 4
Training loss: 0.1678825312385793
Validation loss: 2.3972379011919047

Epoch: 5| Step: 5
Training loss: 0.1272297706000423
Validation loss: 2.4060276335201007

Epoch: 5| Step: 6
Training loss: 0.10207495334672294
Validation loss: 2.3773975964344163

Epoch: 5| Step: 7
Training loss: 0.10610582741519912
Validation loss: 2.388907027392324

Epoch: 5| Step: 8
Training loss: 0.14511532942761957
Validation loss: 2.3927706481475433

Epoch: 5| Step: 9
Training loss: 0.11720256708559305
Validation loss: 2.4179116423791718

Epoch: 5| Step: 10
Training loss: 0.0804665814033434
Validation loss: 2.414738003946854

Epoch: 728| Step: 0
Training loss: 0.1482428039316823
Validation loss: 2.419248430995276

Epoch: 5| Step: 1
Training loss: 0.1156872280631329
Validation loss: 2.419521179531095

Epoch: 5| Step: 2
Training loss: 0.11593731153992093
Validation loss: 2.383589062766943

Epoch: 5| Step: 3
Training loss: 0.09889161742928872
Validation loss: 2.386609258433346

Epoch: 5| Step: 4
Training loss: 0.05757964859102192
Validation loss: 2.3852494120226186

Epoch: 5| Step: 5
Training loss: 0.07759845438464419
Validation loss: 2.3699626620665692

Epoch: 5| Step: 6
Training loss: 0.1445828745119673
Validation loss: 2.3839799135006388

Epoch: 5| Step: 7
Training loss: 0.12953224770744967
Validation loss: 2.3821708634329557

Epoch: 5| Step: 8
Training loss: 0.10093466481635158
Validation loss: 2.3978526928380197

Epoch: 5| Step: 9
Training loss: 0.06394097924041836
Validation loss: 2.379305675222692

Epoch: 5| Step: 10
Training loss: 0.07560611881754159
Validation loss: 2.382038453767835

Epoch: 729| Step: 0
Training loss: 0.1149181698993463
Validation loss: 2.393273147110514

Epoch: 5| Step: 1
Training loss: 0.1278628910196143
Validation loss: 2.4137510544870038

Epoch: 5| Step: 2
Training loss: 0.060429139415275
Validation loss: 2.4087826127475185

Epoch: 5| Step: 3
Training loss: 0.08137142960564839
Validation loss: 2.407814861585334

Epoch: 5| Step: 4
Training loss: 0.11072464556748196
Validation loss: 2.405948233783068

Epoch: 5| Step: 5
Training loss: 0.10726599654336862
Validation loss: 2.3863420032848346

Epoch: 5| Step: 6
Training loss: 0.1978930607738805
Validation loss: 2.411619394485961

Epoch: 5| Step: 7
Training loss: 0.0927375422855162
Validation loss: 2.409596731222967

Epoch: 5| Step: 8
Training loss: 0.07957810332876405
Validation loss: 2.427575295800049

Epoch: 5| Step: 9
Training loss: 0.09010001620433823
Validation loss: 2.4238477063262094

Epoch: 5| Step: 10
Training loss: 0.09474496564348824
Validation loss: 2.447927529322484

Epoch: 730| Step: 0
Training loss: 0.10659897500934502
Validation loss: 2.414726274653455

Epoch: 5| Step: 1
Training loss: 0.05165971150053572
Validation loss: 2.401220295302283

Epoch: 5| Step: 2
Training loss: 0.09043845531727535
Validation loss: 2.436356845692417

Epoch: 5| Step: 3
Training loss: 0.154818606447567
Validation loss: 2.4091486130570945

Epoch: 5| Step: 4
Training loss: 0.11742254765255078
Validation loss: 2.393570909719483

Epoch: 5| Step: 5
Training loss: 0.07849999374208153
Validation loss: 2.3962175236888377

Epoch: 5| Step: 6
Training loss: 0.06061305190419909
Validation loss: 2.41603415178162

Epoch: 5| Step: 7
Training loss: 0.0507867172856015
Validation loss: 2.3592010762088007

Epoch: 5| Step: 8
Training loss: 0.11566706018064304
Validation loss: 2.3900247284432923

Epoch: 5| Step: 9
Training loss: 0.15253770537023015
Validation loss: 2.4078913442930316

Epoch: 5| Step: 10
Training loss: 0.08281523580800487
Validation loss: 2.405132320187792

Epoch: 731| Step: 0
Training loss: 0.06825061047371818
Validation loss: 2.381175070363659

Epoch: 5| Step: 1
Training loss: 0.1698673204562622
Validation loss: 2.3971384425238114

Epoch: 5| Step: 2
Training loss: 0.0936473940594424
Validation loss: 2.382940752144141

Epoch: 5| Step: 3
Training loss: 0.11537021373143858
Validation loss: 2.3691459142856193

Epoch: 5| Step: 4
Training loss: 0.0894703725570424
Validation loss: 2.3818626351691212

Epoch: 5| Step: 5
Training loss: 0.15918497650159252
Validation loss: 2.3674433696581967

Epoch: 5| Step: 6
Training loss: 0.11517589911936292
Validation loss: 2.3933972000858574

Epoch: 5| Step: 7
Training loss: 0.1139545042092326
Validation loss: 2.3935655276735095

Epoch: 5| Step: 8
Training loss: 0.08262084632689679
Validation loss: 2.3793218717607285

Epoch: 5| Step: 9
Training loss: 0.10083588775080264
Validation loss: 2.406342353747824

Epoch: 5| Step: 10
Training loss: 0.14548441039461776
Validation loss: 2.3970195264580054

Epoch: 732| Step: 0
Training loss: 0.07120126386507543
Validation loss: 2.4003147128693336

Epoch: 5| Step: 1
Training loss: 0.0934476247775192
Validation loss: 2.3981965859803807

Epoch: 5| Step: 2
Training loss: 0.11640969677756957
Validation loss: 2.4122324651371176

Epoch: 5| Step: 3
Training loss: 0.08445262395778949
Validation loss: 2.4015227837148396

Epoch: 5| Step: 4
Training loss: 0.0918540827058322
Validation loss: 2.440005638227668

Epoch: 5| Step: 5
Training loss: 0.07778773525083083
Validation loss: 2.4044423104537422

Epoch: 5| Step: 6
Training loss: 0.15482714832508718
Validation loss: 2.3920069531295676

Epoch: 5| Step: 7
Training loss: 0.10581383939865331
Validation loss: 2.4368799439559226

Epoch: 5| Step: 8
Training loss: 0.14612878873945215
Validation loss: 2.4037670572928507

Epoch: 5| Step: 9
Training loss: 0.1302223285465298
Validation loss: 2.4286884894125427

Epoch: 5| Step: 10
Training loss: 0.08898375798983582
Validation loss: 2.4212476136709573

Epoch: 733| Step: 0
Training loss: 0.11426215693373593
Validation loss: 2.457247398454253

Epoch: 5| Step: 1
Training loss: 0.14746853512018565
Validation loss: 2.408989528232922

Epoch: 5| Step: 2
Training loss: 0.0673508672040054
Validation loss: 2.4178698143420796

Epoch: 5| Step: 3
Training loss: 0.07548671155731163
Validation loss: 2.396232681020537

Epoch: 5| Step: 4
Training loss: 0.16528784605911886
Validation loss: 2.4204690271906797

Epoch: 5| Step: 5
Training loss: 0.11815098619225034
Validation loss: 2.4058209534690245

Epoch: 5| Step: 6
Training loss: 0.06639981589281924
Validation loss: 2.419071930884978

Epoch: 5| Step: 7
Training loss: 0.08389634131595997
Validation loss: 2.394647909753085

Epoch: 5| Step: 8
Training loss: 0.09109025236910276
Validation loss: 2.4233353228288

Epoch: 5| Step: 9
Training loss: 0.10340941576580369
Validation loss: 2.4112250988395756

Epoch: 5| Step: 10
Training loss: 0.04903585354620612
Validation loss: 2.4005304917564088

Epoch: 734| Step: 0
Training loss: 0.06947681058528167
Validation loss: 2.3971767534377717

Epoch: 5| Step: 1
Training loss: 0.07617516999576268
Validation loss: 2.3871293289857585

Epoch: 5| Step: 2
Training loss: 0.11085433697157202
Validation loss: 2.4139908441685876

Epoch: 5| Step: 3
Training loss: 0.1042154962612257
Validation loss: 2.4200528777198342

Epoch: 5| Step: 4
Training loss: 0.1403660642042112
Validation loss: 2.3910644907958845

Epoch: 5| Step: 5
Training loss: 0.1501735383758173
Validation loss: 2.3989230492142415

Epoch: 5| Step: 6
Training loss: 0.07850457607168979
Validation loss: 2.4195820497311677

Epoch: 5| Step: 7
Training loss: 0.07454300307427147
Validation loss: 2.423535773439964

Epoch: 5| Step: 8
Training loss: 0.07657458759762538
Validation loss: 2.393317254929058

Epoch: 5| Step: 9
Training loss: 0.12585745955039113
Validation loss: 2.394847591826765

Epoch: 5| Step: 10
Training loss: 0.12981255861307656
Validation loss: 2.3660006148705808

Epoch: 735| Step: 0
Training loss: 0.10368808738870933
Validation loss: 2.4114112045866105

Epoch: 5| Step: 1
Training loss: 0.05545825304858026
Validation loss: 2.3943586620019732

Epoch: 5| Step: 2
Training loss: 0.09486246683180719
Validation loss: 2.408459505423117

Epoch: 5| Step: 3
Training loss: 0.0849464722081176
Validation loss: 2.3882409307887746

Epoch: 5| Step: 4
Training loss: 0.1638529210933512
Validation loss: 2.4094478632283973

Epoch: 5| Step: 5
Training loss: 0.053837795433930385
Validation loss: 2.4167447556668193

Epoch: 5| Step: 6
Training loss: 0.11468341820128891
Validation loss: 2.403826279841226

Epoch: 5| Step: 7
Training loss: 0.04957960964835857
Validation loss: 2.4050954310924304

Epoch: 5| Step: 8
Training loss: 0.15287276264535676
Validation loss: 2.413898858980998

Epoch: 5| Step: 9
Training loss: 0.11367283751876592
Validation loss: 2.409412495772868

Epoch: 5| Step: 10
Training loss: 0.0803766790977714
Validation loss: 2.4396044993871913

Epoch: 736| Step: 0
Training loss: 0.11196355840298348
Validation loss: 2.4237977576869825

Epoch: 5| Step: 1
Training loss: 0.17026639410522423
Validation loss: 2.440741162348632

Epoch: 5| Step: 2
Training loss: 0.1331544289275278
Validation loss: 2.448168358117712

Epoch: 5| Step: 3
Training loss: 0.13182018327183861
Validation loss: 2.4176294009565376

Epoch: 5| Step: 4
Training loss: 0.1268009888127954
Validation loss: 2.390901304413183

Epoch: 5| Step: 5
Training loss: 0.07969376151411135
Validation loss: 2.3808696269158403

Epoch: 5| Step: 6
Training loss: 0.0937627843246299
Validation loss: 2.3787812570359232

Epoch: 5| Step: 7
Training loss: 0.11955779940143454
Validation loss: 2.371220145551587

Epoch: 5| Step: 8
Training loss: 0.06516003913290296
Validation loss: 2.388594136135102

Epoch: 5| Step: 9
Training loss: 0.1473330581139332
Validation loss: 2.392714687700067

Epoch: 5| Step: 10
Training loss: 0.06818050415766892
Validation loss: 2.378668842572491

Epoch: 737| Step: 0
Training loss: 0.16598158655712458
Validation loss: 2.379023752463243

Epoch: 5| Step: 1
Training loss: 0.1072255030303477
Validation loss: 2.393498648985857

Epoch: 5| Step: 2
Training loss: 0.08527413550985473
Validation loss: 2.4128601348642578

Epoch: 5| Step: 3
Training loss: 0.1301733939659501
Validation loss: 2.3964630825891566

Epoch: 5| Step: 4
Training loss: 0.14742752353458113
Validation loss: 2.4270815802866266

Epoch: 5| Step: 5
Training loss: 0.09459759102538044
Validation loss: 2.4047751107637736

Epoch: 5| Step: 6
Training loss: 0.09237872027957077
Validation loss: 2.4548669392154348

Epoch: 5| Step: 7
Training loss: 0.14327078272484092
Validation loss: 2.419177251984115

Epoch: 5| Step: 8
Training loss: 0.13762745639452134
Validation loss: 2.431423483336061

Epoch: 5| Step: 9
Training loss: 0.12408550091273798
Validation loss: 2.432226150416256

Epoch: 5| Step: 10
Training loss: 0.09758747540120963
Validation loss: 2.444796889481501

Epoch: 738| Step: 0
Training loss: 0.08061697557718892
Validation loss: 2.4413460541554124

Epoch: 5| Step: 1
Training loss: 0.10600900034773476
Validation loss: 2.409487545661561

Epoch: 5| Step: 2
Training loss: 0.14765644376227366
Validation loss: 2.4561949666271246

Epoch: 5| Step: 3
Training loss: 0.09364419668996585
Validation loss: 2.449909679873415

Epoch: 5| Step: 4
Training loss: 0.0971450539027682
Validation loss: 2.4141391968031765

Epoch: 5| Step: 5
Training loss: 0.07145757224805552
Validation loss: 2.4474807263810097

Epoch: 5| Step: 6
Training loss: 0.15083263514837497
Validation loss: 2.4418573067032954

Epoch: 5| Step: 7
Training loss: 0.12453440665189397
Validation loss: 2.4351739346997077

Epoch: 5| Step: 8
Training loss: 0.07634799721037389
Validation loss: 2.4535243493945464

Epoch: 5| Step: 9
Training loss: 0.1200783015319976
Validation loss: 2.417056705313549

Epoch: 5| Step: 10
Training loss: 0.06455611179520565
Validation loss: 2.4195707719757715

Epoch: 739| Step: 0
Training loss: 0.14721369700544812
Validation loss: 2.4273080719555438

Epoch: 5| Step: 1
Training loss: 0.11023441781057369
Validation loss: 2.4346022671031498

Epoch: 5| Step: 2
Training loss: 0.10592204716177889
Validation loss: 2.419850767709572

Epoch: 5| Step: 3
Training loss: 0.0739016566603265
Validation loss: 2.4411160409041956

Epoch: 5| Step: 4
Training loss: 0.10472424310707555
Validation loss: 2.4400215989028857

Epoch: 5| Step: 5
Training loss: 0.11837182813541917
Validation loss: 2.429161637134489

Epoch: 5| Step: 6
Training loss: 0.1478434206435414
Validation loss: 2.4207070732969136

Epoch: 5| Step: 7
Training loss: 0.067959086920607
Validation loss: 2.4210014734165055

Epoch: 5| Step: 8
Training loss: 0.0869358630110227
Validation loss: 2.4377665977362377

Epoch: 5| Step: 9
Training loss: 0.0759765094227348
Validation loss: 2.410904988402022

Epoch: 5| Step: 10
Training loss: 0.09816062377784343
Validation loss: 2.431495310755785

Epoch: 740| Step: 0
Training loss: 0.09542423113238853
Validation loss: 2.4171029256869505

Epoch: 5| Step: 1
Training loss: 0.14719013586336602
Validation loss: 2.4109772487333068

Epoch: 5| Step: 2
Training loss: 0.16058722520338403
Validation loss: 2.427858836030408

Epoch: 5| Step: 3
Training loss: 0.09518165009782911
Validation loss: 2.426222018360814

Epoch: 5| Step: 4
Training loss: 0.10749475434445863
Validation loss: 2.422196002901214

Epoch: 5| Step: 5
Training loss: 0.09764841525120828
Validation loss: 2.4395724547787365

Epoch: 5| Step: 6
Training loss: 0.07756589261987781
Validation loss: 2.4456442048030813

Epoch: 5| Step: 7
Training loss: 0.08771904250487919
Validation loss: 2.4142584727314698

Epoch: 5| Step: 8
Training loss: 0.11060299544050499
Validation loss: 2.4309068462473324

Epoch: 5| Step: 9
Training loss: 0.08834557405247784
Validation loss: 2.4371673198142214

Epoch: 5| Step: 10
Training loss: 0.11089775488342049
Validation loss: 2.4043118070628204

Epoch: 741| Step: 0
Training loss: 0.16348221881884334
Validation loss: 2.4284586633798937

Epoch: 5| Step: 1
Training loss: 0.15200752054490232
Validation loss: 2.42856260200531

Epoch: 5| Step: 2
Training loss: 0.08921533550502897
Validation loss: 2.4061692225227795

Epoch: 5| Step: 3
Training loss: 0.06683363544327653
Validation loss: 2.4416266428580267

Epoch: 5| Step: 4
Training loss: 0.051335052221650544
Validation loss: 2.413780874833788

Epoch: 5| Step: 5
Training loss: 0.09915225004423103
Validation loss: 2.418680546583681

Epoch: 5| Step: 6
Training loss: 0.05813902198695568
Validation loss: 2.40623868106715

Epoch: 5| Step: 7
Training loss: 0.12407599859765857
Validation loss: 2.405608772676209

Epoch: 5| Step: 8
Training loss: 0.10765485208293057
Validation loss: 2.424284054341271

Epoch: 5| Step: 9
Training loss: 0.07693814032514383
Validation loss: 2.3808156878409683

Epoch: 5| Step: 10
Training loss: 0.09056335420218833
Validation loss: 2.3948353925856973

Epoch: 742| Step: 0
Training loss: 0.1501923529800896
Validation loss: 2.371351975489289

Epoch: 5| Step: 1
Training loss: 0.050435304609602535
Validation loss: 2.4262216823496114

Epoch: 5| Step: 2
Training loss: 0.08904615135052783
Validation loss: 2.40094951566426

Epoch: 5| Step: 3
Training loss: 0.1227583643878346
Validation loss: 2.4396161794760984

Epoch: 5| Step: 4
Training loss: 0.1232781734010133
Validation loss: 2.4266955537555965

Epoch: 5| Step: 5
Training loss: 0.08322451298685207
Validation loss: 2.446898336852825

Epoch: 5| Step: 6
Training loss: 0.11211869968619659
Validation loss: 2.423126910154303

Epoch: 5| Step: 7
Training loss: 0.09789307488483458
Validation loss: 2.4377228325019105

Epoch: 5| Step: 8
Training loss: 0.06531313222255161
Validation loss: 2.4496522537363874

Epoch: 5| Step: 9
Training loss: 0.09888431380389698
Validation loss: 2.434381647959316

Epoch: 5| Step: 10
Training loss: 0.15080179632858337
Validation loss: 2.4143637553388073

Epoch: 743| Step: 0
Training loss: 0.060114857440729634
Validation loss: 2.419979608938518

Epoch: 5| Step: 1
Training loss: 0.10451399049836702
Validation loss: 2.425754069213232

Epoch: 5| Step: 2
Training loss: 0.10387394625224529
Validation loss: 2.4603325265093217

Epoch: 5| Step: 3
Training loss: 0.10296307045955812
Validation loss: 2.3937084792749452

Epoch: 5| Step: 4
Training loss: 0.0981935122662781
Validation loss: 2.4440357070296073

Epoch: 5| Step: 5
Training loss: 0.11778186828018825
Validation loss: 2.447719066623924

Epoch: 5| Step: 6
Training loss: 0.08323070948664378
Validation loss: 2.4482372230268616

Epoch: 5| Step: 7
Training loss: 0.09063850684470179
Validation loss: 2.4419098963871906

Epoch: 5| Step: 8
Training loss: 0.1491950180994443
Validation loss: 2.4600160060094733

Epoch: 5| Step: 9
Training loss: 0.09010423858268529
Validation loss: 2.403561261723863

Epoch: 5| Step: 10
Training loss: 0.17038482871291058
Validation loss: 2.4334699172950995

Epoch: 744| Step: 0
Training loss: 0.0957153857415497
Validation loss: 2.3970843679415745

Epoch: 5| Step: 1
Training loss: 0.10167380799196718
Validation loss: 2.4209985762167094

Epoch: 5| Step: 2
Training loss: 0.08076705799650684
Validation loss: 2.3959042865435265

Epoch: 5| Step: 3
Training loss: 0.0742733810786118
Validation loss: 2.3824953142129592

Epoch: 5| Step: 4
Training loss: 0.067866380102467
Validation loss: 2.3632322803462267

Epoch: 5| Step: 5
Training loss: 0.07781255650709774
Validation loss: 2.3778013790866015

Epoch: 5| Step: 6
Training loss: 0.08367739062646791
Validation loss: 2.387867219921405

Epoch: 5| Step: 7
Training loss: 0.0711576118634189
Validation loss: 2.381881061116719

Epoch: 5| Step: 8
Training loss: 0.12157524810008134
Validation loss: 2.374383307692074

Epoch: 5| Step: 9
Training loss: 0.19514749232449313
Validation loss: 2.396315808467087

Epoch: 5| Step: 10
Training loss: 0.07479984775753389
Validation loss: 2.4083571469639433

Epoch: 745| Step: 0
Training loss: 0.08728781447478215
Validation loss: 2.4174522068033126

Epoch: 5| Step: 1
Training loss: 0.13168510709895961
Validation loss: 2.3779799300975104

Epoch: 5| Step: 2
Training loss: 0.08031462137318725
Validation loss: 2.41137468796302

Epoch: 5| Step: 3
Training loss: 0.17805392495325506
Validation loss: 2.437808210577363

Epoch: 5| Step: 4
Training loss: 0.07624913234686059
Validation loss: 2.395518952047611

Epoch: 5| Step: 5
Training loss: 0.09822841873909009
Validation loss: 2.3764544018475613

Epoch: 5| Step: 6
Training loss: 0.0643172167782837
Validation loss: 2.4320155541663717

Epoch: 5| Step: 7
Training loss: 0.05950076311287256
Validation loss: 2.4153103047213587

Epoch: 5| Step: 8
Training loss: 0.044650173545654454
Validation loss: 2.410544021430899

Epoch: 5| Step: 9
Training loss: 0.10708134603032388
Validation loss: 2.400585217036404

Epoch: 5| Step: 10
Training loss: 0.15877785308798992
Validation loss: 2.3921432183555984

Epoch: 746| Step: 0
Training loss: 0.08041435979845442
Validation loss: 2.4180695496854763

Epoch: 5| Step: 1
Training loss: 0.1453314230503336
Validation loss: 2.4183105013067854

Epoch: 5| Step: 2
Training loss: 0.10117632090252048
Validation loss: 2.4010094889239557

Epoch: 5| Step: 3
Training loss: 0.09157910285151677
Validation loss: 2.4125934052911338

Epoch: 5| Step: 4
Training loss: 0.09010248660393717
Validation loss: 2.386495665815147

Epoch: 5| Step: 5
Training loss: 0.07132533861841032
Validation loss: 2.3942006712067516

Epoch: 5| Step: 6
Training loss: 0.11477854655307133
Validation loss: 2.395677525258928

Epoch: 5| Step: 7
Training loss: 0.08057368852475388
Validation loss: 2.400971935340622

Epoch: 5| Step: 8
Training loss: 0.16045390358491812
Validation loss: 2.421039526373877

Epoch: 5| Step: 9
Training loss: 0.0796420914636755
Validation loss: 2.398647561961441

Epoch: 5| Step: 10
Training loss: 0.05768512301065677
Validation loss: 2.405122584199147

Epoch: 747| Step: 0
Training loss: 0.11911209734213012
Validation loss: 2.378572672937412

Epoch: 5| Step: 1
Training loss: 0.08028862779296775
Validation loss: 2.372833801180747

Epoch: 5| Step: 2
Training loss: 0.15541527226114848
Validation loss: 2.3984903731441665

Epoch: 5| Step: 3
Training loss: 0.10237124652438485
Validation loss: 2.38916107100794

Epoch: 5| Step: 4
Training loss: 0.08935188327954197
Validation loss: 2.396418995229545

Epoch: 5| Step: 5
Training loss: 0.1416063702523495
Validation loss: 2.386480432138252

Epoch: 5| Step: 6
Training loss: 0.10447659777275077
Validation loss: 2.3656589442712215

Epoch: 5| Step: 7
Training loss: 0.11495905653943947
Validation loss: 2.3816635775208255

Epoch: 5| Step: 8
Training loss: 0.09481777636783921
Validation loss: 2.389350138860089

Epoch: 5| Step: 9
Training loss: 0.11147764688865744
Validation loss: 2.394444429452004

Epoch: 5| Step: 10
Training loss: 0.068079723823112
Validation loss: 2.412135350738178

Epoch: 748| Step: 0
Training loss: 0.10917959469158343
Validation loss: 2.3840957346672065

Epoch: 5| Step: 1
Training loss: 0.08950723464957759
Validation loss: 2.4061330727725

Epoch: 5| Step: 2
Training loss: 0.13559720646729193
Validation loss: 2.404857374736889

Epoch: 5| Step: 3
Training loss: 0.09426573615318155
Validation loss: 2.3888089582844505

Epoch: 5| Step: 4
Training loss: 0.08062343024326245
Validation loss: 2.4150660475477825

Epoch: 5| Step: 5
Training loss: 0.10891252477047535
Validation loss: 2.4011042052482403

Epoch: 5| Step: 6
Training loss: 0.09924543971682014
Validation loss: 2.385683021625913

Epoch: 5| Step: 7
Training loss: 0.10845595629417147
Validation loss: 2.383459801372967

Epoch: 5| Step: 8
Training loss: 0.08864027439110628
Validation loss: 2.3802811648343907

Epoch: 5| Step: 9
Training loss: 0.12960649080154324
Validation loss: 2.4068615459490745

Epoch: 5| Step: 10
Training loss: 0.05767036263331073
Validation loss: 2.3915170719206924

Epoch: 749| Step: 0
Training loss: 0.08901474827017779
Validation loss: 2.4191009258009784

Epoch: 5| Step: 1
Training loss: 0.049081310463503405
Validation loss: 2.3975039118102353

Epoch: 5| Step: 2
Training loss: 0.12227632685981452
Validation loss: 2.3843931811114807

Epoch: 5| Step: 3
Training loss: 0.07053759426714486
Validation loss: 2.4066518387576177

Epoch: 5| Step: 4
Training loss: 0.16049913012002948
Validation loss: 2.39860129163702

Epoch: 5| Step: 5
Training loss: 0.10878752137193466
Validation loss: 2.401859783542499

Epoch: 5| Step: 6
Training loss: 0.09963085840463062
Validation loss: 2.3845466251918674

Epoch: 5| Step: 7
Training loss: 0.09140992279498925
Validation loss: 2.414914489067339

Epoch: 5| Step: 8
Training loss: 0.07745520948564394
Validation loss: 2.3965203675589293

Epoch: 5| Step: 9
Training loss: 0.13084058484352878
Validation loss: 2.3929834787499105

Epoch: 5| Step: 10
Training loss: 0.09046575597311943
Validation loss: 2.385635479502221

Epoch: 750| Step: 0
Training loss: 0.07947392886650605
Validation loss: 2.39228328975128

Epoch: 5| Step: 1
Training loss: 0.08376279143429466
Validation loss: 2.3773067306156355

Epoch: 5| Step: 2
Training loss: 0.06711889842764089
Validation loss: 2.3589518384285126

Epoch: 5| Step: 3
Training loss: 0.12771971411372626
Validation loss: 2.401345773976319

Epoch: 5| Step: 4
Training loss: 0.09495264779002822
Validation loss: 2.362896093449952

Epoch: 5| Step: 5
Training loss: 0.14741082634735503
Validation loss: 2.407154502955763

Epoch: 5| Step: 6
Training loss: 0.08054431843700978
Validation loss: 2.3885373318869703

Epoch: 5| Step: 7
Training loss: 0.08359731985206026
Validation loss: 2.377133551536433

Epoch: 5| Step: 8
Training loss: 0.15248711882384985
Validation loss: 2.3857290164917613

Epoch: 5| Step: 9
Training loss: 0.07534026442901968
Validation loss: 2.375829854993532

Epoch: 5| Step: 10
Training loss: 0.12724640788393043
Validation loss: 2.3712723844404255

Testing loss: 2.6339008460177658
