Epoch: 1| Step: 0
Training loss: 6.659948333448182
Validation loss: 5.759560085543541

Epoch: 5| Step: 1
Training loss: 5.836363341537551
Validation loss: 5.741439660586452

Epoch: 5| Step: 2
Training loss: 5.399720587389222
Validation loss: 5.7248375227217885

Epoch: 5| Step: 3
Training loss: 5.405112439026188
Validation loss: 5.708689418123971

Epoch: 5| Step: 4
Training loss: 6.303925384254175
Validation loss: 5.690132978563546

Epoch: 5| Step: 5
Training loss: 5.603426783998593
Validation loss: 5.669365078734459

Epoch: 5| Step: 6
Training loss: 5.675511395103287
Validation loss: 5.645338263425807

Epoch: 5| Step: 7
Training loss: 5.4964754775930045
Validation loss: 5.616779193035184

Epoch: 5| Step: 8
Training loss: 5.6472320325551175
Validation loss: 5.584904424723352

Epoch: 5| Step: 9
Training loss: 5.419247213077229
Validation loss: 5.54781766025308

Epoch: 5| Step: 10
Training loss: 4.909651239443464
Validation loss: 5.504973693697178

Epoch: 2| Step: 0
Training loss: 5.9601819920755865
Validation loss: 5.458350202767159

Epoch: 5| Step: 1
Training loss: 5.128138069912599
Validation loss: 5.4059022545848645

Epoch: 5| Step: 2
Training loss: 5.00261219453606
Validation loss: 5.350393074491828

Epoch: 5| Step: 3
Training loss: 5.614797877056245
Validation loss: 5.2906342050591135

Epoch: 5| Step: 4
Training loss: 4.662271996208069
Validation loss: 5.225774955008937

Epoch: 5| Step: 5
Training loss: 5.547480676384407
Validation loss: 5.158442929169654

Epoch: 5| Step: 6
Training loss: 5.876029066498227
Validation loss: 5.089635666427941

Epoch: 5| Step: 7
Training loss: 5.3301665122984785
Validation loss: 5.01752408037817

Epoch: 5| Step: 8
Training loss: 5.143799702994031
Validation loss: 4.9417118723621405

Epoch: 5| Step: 9
Training loss: 4.378518569758801
Validation loss: 4.85955878360853

Epoch: 5| Step: 10
Training loss: 4.255840327731011
Validation loss: 4.777970525165768

Epoch: 3| Step: 0
Training loss: 3.6684884545127785
Validation loss: 4.701264339553552

Epoch: 5| Step: 1
Training loss: 5.279007475072848
Validation loss: 4.631491974031291

Epoch: 5| Step: 2
Training loss: 5.0297020847077105
Validation loss: 4.564782558779083

Epoch: 5| Step: 3
Training loss: 3.8937716953414068
Validation loss: 4.5033295686300026

Epoch: 5| Step: 4
Training loss: 5.329906534946429
Validation loss: 4.44252171051297

Epoch: 5| Step: 5
Training loss: 4.319483975920886
Validation loss: 4.384939109508663

Epoch: 5| Step: 6
Training loss: 4.5225270463547
Validation loss: 4.329064532845643

Epoch: 5| Step: 7
Training loss: 3.3992897806568974
Validation loss: 4.279396416954236

Epoch: 5| Step: 8
Training loss: 4.999711028331666
Validation loss: 4.240375719380403

Epoch: 5| Step: 9
Training loss: 4.748356785893168
Validation loss: 4.205756976694352

Epoch: 5| Step: 10
Training loss: 3.943795031307079
Validation loss: 4.1747659429107475

Epoch: 4| Step: 0
Training loss: 3.385807535153187
Validation loss: 4.148249709719977

Epoch: 5| Step: 1
Training loss: 4.8947108936755415
Validation loss: 4.121530412989292

Epoch: 5| Step: 2
Training loss: 4.222691030297328
Validation loss: 4.091693084940943

Epoch: 5| Step: 3
Training loss: 4.565414125140588
Validation loss: 4.064623587044508

Epoch: 5| Step: 4
Training loss: 3.791342766869162
Validation loss: 4.035095217558818

Epoch: 5| Step: 5
Training loss: 3.216851128014719
Validation loss: 4.013332216263139

Epoch: 5| Step: 6
Training loss: 4.779927388681177
Validation loss: 3.995099420251526

Epoch: 5| Step: 7
Training loss: 4.091884508309796
Validation loss: 3.9799076896413244

Epoch: 5| Step: 8
Training loss: 4.148283012660178
Validation loss: 3.962697651692342

Epoch: 5| Step: 9
Training loss: 3.846472667537974
Validation loss: 3.9424703791209295

Epoch: 5| Step: 10
Training loss: 4.7316177446972185
Validation loss: 3.9173448381749725

Epoch: 5| Step: 0
Training loss: 4.424661897145672
Validation loss: 3.887764385259612

Epoch: 5| Step: 1
Training loss: 4.084686262766625
Validation loss: 3.863564946188677

Epoch: 5| Step: 2
Training loss: 3.8491438570163674
Validation loss: 3.8430216976569778

Epoch: 5| Step: 3
Training loss: 3.4980880419653277
Validation loss: 3.824033634974938

Epoch: 5| Step: 4
Training loss: 2.91660931848731
Validation loss: 3.8028847063802695

Epoch: 5| Step: 5
Training loss: 4.228576067697344
Validation loss: 3.7838094502426918

Epoch: 5| Step: 6
Training loss: 3.9276064145770957
Validation loss: 3.7667506993102298

Epoch: 5| Step: 7
Training loss: 4.522599796609035
Validation loss: 3.7486948374044182

Epoch: 5| Step: 8
Training loss: 4.1740712303441025
Validation loss: 3.7347997985949406

Epoch: 5| Step: 9
Training loss: 4.25399816604668
Validation loss: 3.724876368556945

Epoch: 5| Step: 10
Training loss: 3.317305911264611
Validation loss: 3.705932499997902

Epoch: 6| Step: 0
Training loss: 4.160792113230543
Validation loss: 3.6939652643337295

Epoch: 5| Step: 1
Training loss: 3.9830282889895616
Validation loss: 3.6826796132016573

Epoch: 5| Step: 2
Training loss: 3.3640345705594266
Validation loss: 3.66801091739245

Epoch: 5| Step: 3
Training loss: 3.809679082135699
Validation loss: 3.6588609444518188

Epoch: 5| Step: 4
Training loss: 2.9105948508095527
Validation loss: 3.6449214970500603

Epoch: 5| Step: 5
Training loss: 3.635350019978988
Validation loss: 3.6341277505351988

Epoch: 5| Step: 6
Training loss: 3.672457774564199
Validation loss: 3.6248145913532506

Epoch: 5| Step: 7
Training loss: 3.8306439267271477
Validation loss: 3.615599267703014

Epoch: 5| Step: 8
Training loss: 4.192243025017818
Validation loss: 3.608362924023972

Epoch: 5| Step: 9
Training loss: 4.326064517925829
Validation loss: 3.5978675270659255

Epoch: 5| Step: 10
Training loss: 4.082760335980986
Validation loss: 3.5883663719349626

Epoch: 7| Step: 0
Training loss: 3.4301052664571463
Validation loss: 3.5768877759813757

Epoch: 5| Step: 1
Training loss: 4.244814233388378
Validation loss: 3.569629830735907

Epoch: 5| Step: 2
Training loss: 4.180115979059513
Validation loss: 3.5619562248929406

Epoch: 5| Step: 3
Training loss: 3.334979953962986
Validation loss: 3.5524565509337154

Epoch: 5| Step: 4
Training loss: 4.056839035831528
Validation loss: 3.544205031854386

Epoch: 5| Step: 5
Training loss: 4.2640181089378135
Validation loss: 3.5356597271733134

Epoch: 5| Step: 6
Training loss: 3.757533072949794
Validation loss: 3.5280659897289954

Epoch: 5| Step: 7
Training loss: 3.6617450339592987
Validation loss: 3.5189533276094895

Epoch: 5| Step: 8
Training loss: 2.9161797979990554
Validation loss: 3.5098454791605675

Epoch: 5| Step: 9
Training loss: 3.282501999098321
Validation loss: 3.5053129245320256

Epoch: 5| Step: 10
Training loss: 3.8312143744201617
Validation loss: 3.4952067853382136

Epoch: 8| Step: 0
Training loss: 4.11781610254097
Validation loss: 3.485148588220122

Epoch: 5| Step: 1
Training loss: 2.878516161718382
Validation loss: 3.476547156006598

Epoch: 5| Step: 2
Training loss: 4.025727029853923
Validation loss: 3.468309240876675

Epoch: 5| Step: 3
Training loss: 3.3107901424724395
Validation loss: 3.4600568722421725

Epoch: 5| Step: 4
Training loss: 3.5821266951995745
Validation loss: 3.4548622104275237

Epoch: 5| Step: 5
Training loss: 4.188051329800059
Validation loss: 3.44707000650556

Epoch: 5| Step: 6
Training loss: 3.076624315686042
Validation loss: 3.4398385961289306

Epoch: 5| Step: 7
Training loss: 4.360080456822537
Validation loss: 3.433896520960912

Epoch: 5| Step: 8
Training loss: 3.5635446723331343
Validation loss: 3.4296300687365155

Epoch: 5| Step: 9
Training loss: 3.4259335213272473
Validation loss: 3.4220144487204696

Epoch: 5| Step: 10
Training loss: 3.538787224781653
Validation loss: 3.4157054838688468

Epoch: 9| Step: 0
Training loss: 3.845229445656799
Validation loss: 3.408711148915321

Epoch: 5| Step: 1
Training loss: 3.9450075541570206
Validation loss: 3.402068507632537

Epoch: 5| Step: 2
Training loss: 3.958948964213244
Validation loss: 3.397840383252602

Epoch: 5| Step: 3
Training loss: 3.253868148598956
Validation loss: 3.3907823416008376

Epoch: 5| Step: 4
Training loss: 4.091581046664698
Validation loss: 3.3859139662016275

Epoch: 5| Step: 5
Training loss: 3.3383391621907452
Validation loss: 3.3862541981415633

Epoch: 5| Step: 6
Training loss: 3.2244354700228994
Validation loss: 3.382910287610704

Epoch: 5| Step: 7
Training loss: 4.058908371392288
Validation loss: 3.374208446366976

Epoch: 5| Step: 8
Training loss: 3.6142468621068238
Validation loss: 3.36638622135237

Epoch: 5| Step: 9
Training loss: 3.1282949243327356
Validation loss: 3.358410501495558

Epoch: 5| Step: 10
Training loss: 3.01564081217519
Validation loss: 3.358500309878167

Epoch: 10| Step: 0
Training loss: 3.6415466975536464
Validation loss: 3.4079768611035397

Epoch: 5| Step: 1
Training loss: 3.3155765281823006
Validation loss: 3.345503715095903

Epoch: 5| Step: 2
Training loss: 3.9197153171007533
Validation loss: 3.4033902323972836

Epoch: 5| Step: 3
Training loss: 2.754681330699363
Validation loss: 3.3650964800066787

Epoch: 5| Step: 4
Training loss: 3.926328038336077
Validation loss: 3.3601067667750644

Epoch: 5| Step: 5
Training loss: 4.100709081600868
Validation loss: 3.351500069068099

Epoch: 5| Step: 6
Training loss: 2.9364820299188166
Validation loss: 3.335358951485821

Epoch: 5| Step: 7
Training loss: 3.5405849525227144
Validation loss: 3.331103077668555

Epoch: 5| Step: 8
Training loss: 3.5726780640290468
Validation loss: 3.332600695071556

Epoch: 5| Step: 9
Training loss: 3.8827921139586814
Validation loss: 3.3471922492640327

Epoch: 5| Step: 10
Training loss: 3.7147332304389824
Validation loss: 3.3274102921352764

Epoch: 11| Step: 0
Training loss: 3.1789213940026966
Validation loss: 3.3112311817036537

Epoch: 5| Step: 1
Training loss: 2.8708489346091826
Validation loss: 3.311213675637644

Epoch: 5| Step: 2
Training loss: 3.3161701527230965
Validation loss: 3.3155455006213614

Epoch: 5| Step: 3
Training loss: 4.107205706761151
Validation loss: 3.315430637045171

Epoch: 5| Step: 4
Training loss: 3.3447389655335726
Validation loss: 3.310894865708583

Epoch: 5| Step: 5
Training loss: 3.9889243090399087
Validation loss: 3.305006888540664

Epoch: 5| Step: 6
Training loss: 3.610755029060101
Validation loss: 3.29090213009695

Epoch: 5| Step: 7
Training loss: 3.5366624521367607
Validation loss: 3.28078657667999

Epoch: 5| Step: 8
Training loss: 4.411144379032046
Validation loss: 3.2706474693970042

Epoch: 5| Step: 9
Training loss: 3.0165555634947894
Validation loss: 3.267993954653607

Epoch: 5| Step: 10
Training loss: 3.1762858572913433
Validation loss: 3.2663610788404993

Epoch: 12| Step: 0
Training loss: 3.6716779940085993
Validation loss: 3.265976554190793

Epoch: 5| Step: 1
Training loss: 3.4546150686468633
Validation loss: 3.257848764259376

Epoch: 5| Step: 2
Training loss: 3.184681263160382
Validation loss: 3.245802810851685

Epoch: 5| Step: 3
Training loss: 4.066215576626575
Validation loss: 3.2389507268895374

Epoch: 5| Step: 4
Training loss: 3.5916522994200313
Validation loss: 3.2285827503087767

Epoch: 5| Step: 5
Training loss: 3.114906949142919
Validation loss: 3.2209913950277302

Epoch: 5| Step: 6
Training loss: 2.9647369566570267
Validation loss: 3.2169489350998344

Epoch: 5| Step: 7
Training loss: 3.1959854573860693
Validation loss: 3.219704326923715

Epoch: 5| Step: 8
Training loss: 3.78786992447712
Validation loss: 3.2170044446571993

Epoch: 5| Step: 9
Training loss: 3.751252028945532
Validation loss: 3.2107645504234

Epoch: 5| Step: 10
Training loss: 3.4038151429184054
Validation loss: 3.1994623684959667

Epoch: 13| Step: 0
Training loss: 3.1462502276996807
Validation loss: 3.192889139872308

Epoch: 5| Step: 1
Training loss: 4.141640822843566
Validation loss: 3.1922727366410273

Epoch: 5| Step: 2
Training loss: 3.0132582473964837
Validation loss: 3.1942778365702114

Epoch: 5| Step: 3
Training loss: 3.753353145630641
Validation loss: 3.1924983338632975

Epoch: 5| Step: 4
Training loss: 3.8818869149561546
Validation loss: 3.1778093503337868

Epoch: 5| Step: 5
Training loss: 3.1020147728927916
Validation loss: 3.1790261372075332

Epoch: 5| Step: 6
Training loss: 2.714764095757046
Validation loss: 3.184264855809256

Epoch: 5| Step: 7
Training loss: 3.959936974919792
Validation loss: 3.2199078365148277

Epoch: 5| Step: 8
Training loss: 3.5214388776179018
Validation loss: 3.1688040712684877

Epoch: 5| Step: 9
Training loss: 3.281690876724372
Validation loss: 3.1628771669407323

Epoch: 5| Step: 10
Training loss: 3.0780717099606623
Validation loss: 3.170530894294256

Epoch: 14| Step: 0
Training loss: 3.476209849784499
Validation loss: 3.211475109841643

Epoch: 5| Step: 1
Training loss: 3.190886998044517
Validation loss: 3.1759859370852777

Epoch: 5| Step: 2
Training loss: 3.310917026227844
Validation loss: 3.162720957302912

Epoch: 5| Step: 3
Training loss: 2.8443485510410937
Validation loss: 3.1571568750099077

Epoch: 5| Step: 4
Training loss: 3.320002714178975
Validation loss: 3.156987063065501

Epoch: 5| Step: 5
Training loss: 3.619646262489162
Validation loss: 3.1560017144823824

Epoch: 5| Step: 6
Training loss: 3.347310105080674
Validation loss: 3.1555663231070863

Epoch: 5| Step: 7
Training loss: 3.329115169605882
Validation loss: 3.1530867606446584

Epoch: 5| Step: 8
Training loss: 3.223514031201134
Validation loss: 3.1495406020100805

Epoch: 5| Step: 9
Training loss: 4.1057674687649275
Validation loss: 3.1454581686407845

Epoch: 5| Step: 10
Training loss: 3.841101625694584
Validation loss: 3.1281724901351957

Epoch: 15| Step: 0
Training loss: 3.331057550478834
Validation loss: 3.118007875479563

Epoch: 5| Step: 1
Training loss: 2.90680730254911
Validation loss: 3.1137224231861134

Epoch: 5| Step: 2
Training loss: 3.359894752216456
Validation loss: 3.1138434282145537

Epoch: 5| Step: 3
Training loss: 3.3738151165789945
Validation loss: 3.116937771712115

Epoch: 5| Step: 4
Training loss: 2.654213337709996
Validation loss: 3.1122527504198265

Epoch: 5| Step: 5
Training loss: 2.9542365025998607
Validation loss: 3.1039788805385107

Epoch: 5| Step: 6
Training loss: 3.537033611057021
Validation loss: 3.099748533901649

Epoch: 5| Step: 7
Training loss: 3.730389754971861
Validation loss: 3.095253257766163

Epoch: 5| Step: 8
Training loss: 4.125121606132462
Validation loss: 3.087008022319225

Epoch: 5| Step: 9
Training loss: 3.4825344270755747
Validation loss: 3.0826735274185344

Epoch: 5| Step: 10
Training loss: 3.4751857131622184
Validation loss: 3.078594417038824

Epoch: 16| Step: 0
Training loss: 3.2127539330249806
Validation loss: 3.0769270806369335

Epoch: 5| Step: 1
Training loss: 3.5517537848822367
Validation loss: 3.0730654027506206

Epoch: 5| Step: 2
Training loss: 3.324427166691023
Validation loss: 3.0704686467673468

Epoch: 5| Step: 3
Training loss: 3.325524402079787
Validation loss: 3.0655079991335605

Epoch: 5| Step: 4
Training loss: 2.8783016320452206
Validation loss: 3.0613827671315827

Epoch: 5| Step: 5
Training loss: 3.6225543486820557
Validation loss: 3.057539824136362

Epoch: 5| Step: 6
Training loss: 3.6851298587024703
Validation loss: 3.05242838734747

Epoch: 5| Step: 7
Training loss: 3.3771277890504323
Validation loss: 3.0486962852365433

Epoch: 5| Step: 8
Training loss: 3.3358587394189687
Validation loss: 3.0458860447291043

Epoch: 5| Step: 9
Training loss: 2.92719783536378
Validation loss: 3.044882490489612

Epoch: 5| Step: 10
Training loss: 3.503622088184798
Validation loss: 3.040615301836874

Epoch: 17| Step: 0
Training loss: 3.2893779539935433
Validation loss: 3.0369018749697103

Epoch: 5| Step: 1
Training loss: 3.3904250125533038
Validation loss: 3.0350556878441393

Epoch: 5| Step: 2
Training loss: 3.187022453887332
Validation loss: 3.030225891383452

Epoch: 5| Step: 3
Training loss: 3.62584558029988
Validation loss: 3.0279904232507397

Epoch: 5| Step: 4
Training loss: 4.0694733851202605
Validation loss: 3.023536986804087

Epoch: 5| Step: 5
Training loss: 3.161361785034491
Validation loss: 3.018031825271332

Epoch: 5| Step: 6
Training loss: 2.864706936105847
Validation loss: 3.014587024780828

Epoch: 5| Step: 7
Training loss: 3.555743988991134
Validation loss: 3.0111048918348553

Epoch: 5| Step: 8
Training loss: 3.0924800231337706
Validation loss: 3.010922049136916

Epoch: 5| Step: 9
Training loss: 2.8605055944997817
Validation loss: 3.009624704181265

Epoch: 5| Step: 10
Training loss: 3.1745849458231654
Validation loss: 3.0065918457971317

Epoch: 18| Step: 0
Training loss: 1.919945345140433
Validation loss: 3.0034411120498294

Epoch: 5| Step: 1
Training loss: 4.037094728898203
Validation loss: 3.0022573088313944

Epoch: 5| Step: 2
Training loss: 2.9301604435968565
Validation loss: 2.999651746806349

Epoch: 5| Step: 3
Training loss: 3.6065908816326235
Validation loss: 2.9964372268716883

Epoch: 5| Step: 4
Training loss: 3.470085093309611
Validation loss: 2.991426728297194

Epoch: 5| Step: 5
Training loss: 3.1713835236824743
Validation loss: 2.9891064099694393

Epoch: 5| Step: 6
Training loss: 3.7456499936756065
Validation loss: 2.9868363702491116

Epoch: 5| Step: 7
Training loss: 2.684821191015944
Validation loss: 2.9842235456100195

Epoch: 5| Step: 8
Training loss: 3.9972836092459816
Validation loss: 2.9834751378222832

Epoch: 5| Step: 9
Training loss: 3.4946014458650208
Validation loss: 2.9794507678945985

Epoch: 5| Step: 10
Training loss: 2.311387180942611
Validation loss: 2.97732453317085

Epoch: 19| Step: 0
Training loss: 2.9879135803226577
Validation loss: 2.9747993893819267

Epoch: 5| Step: 1
Training loss: 3.588027644149792
Validation loss: 2.973873887122869

Epoch: 5| Step: 2
Training loss: 3.60279702565674
Validation loss: 2.972354552521204

Epoch: 5| Step: 3
Training loss: 3.7235632769127007
Validation loss: 2.9684024143157877

Epoch: 5| Step: 4
Training loss: 2.7137735356839405
Validation loss: 2.966678911188216

Epoch: 5| Step: 5
Training loss: 3.3022847560416944
Validation loss: 2.9653070801615353

Epoch: 5| Step: 6
Training loss: 2.546001822915215
Validation loss: 2.963761127084778

Epoch: 5| Step: 7
Training loss: 3.0779237633001872
Validation loss: 2.9597051964593835

Epoch: 5| Step: 8
Training loss: 3.2797715989117036
Validation loss: 2.9589640233799877

Epoch: 5| Step: 9
Training loss: 2.893499316568592
Validation loss: 2.956992676771157

Epoch: 5| Step: 10
Training loss: 4.0922795341078935
Validation loss: 2.9543072522226734

Epoch: 20| Step: 0
Training loss: 3.248708468351894
Validation loss: 2.95331404250672

Epoch: 5| Step: 1
Training loss: 3.408207182348946
Validation loss: 2.9500209878515924

Epoch: 5| Step: 2
Training loss: 3.558959674131918
Validation loss: 2.948652245182609

Epoch: 5| Step: 3
Training loss: 3.3170103639447075
Validation loss: 2.946276043656594

Epoch: 5| Step: 4
Training loss: 2.977703206313164
Validation loss: 2.9427250298191465

Epoch: 5| Step: 5
Training loss: 2.6674961548395872
Validation loss: 2.9430922803433957

Epoch: 5| Step: 6
Training loss: 3.0785907838318547
Validation loss: 2.943460906455649

Epoch: 5| Step: 7
Training loss: 3.469532646345559
Validation loss: 3.004449880272292

Epoch: 5| Step: 8
Training loss: 3.5230310717383806
Validation loss: 3.0087368015203446

Epoch: 5| Step: 9
Training loss: 3.664164917903295
Validation loss: 3.0034177071294406

Epoch: 5| Step: 10
Training loss: 2.861957988481318
Validation loss: 2.932288235411533

Epoch: 21| Step: 0
Training loss: 3.1821879085393285
Validation loss: 2.9361489408676857

Epoch: 5| Step: 1
Training loss: 2.9894235459712015
Validation loss: 2.9486054104666044

Epoch: 5| Step: 2
Training loss: 3.543674722507757
Validation loss: 2.973672061304643

Epoch: 5| Step: 3
Training loss: 3.5915758273386
Validation loss: 2.938745681807607

Epoch: 5| Step: 4
Training loss: 3.5241461673434133
Validation loss: 2.921699047027705

Epoch: 5| Step: 5
Training loss: 3.3327773266244933
Validation loss: 2.9171400175374904

Epoch: 5| Step: 6
Training loss: 2.9489506681758786
Validation loss: 2.9250531554530426

Epoch: 5| Step: 7
Training loss: 2.691750381238699
Validation loss: 2.990597651494562

Epoch: 5| Step: 8
Training loss: 3.115621608475931
Validation loss: 3.0673041216407255

Epoch: 5| Step: 9
Training loss: 3.471604281222212
Validation loss: 3.094328131778508

Epoch: 5| Step: 10
Training loss: 3.564069168104651
Validation loss: 3.023261588275631

Epoch: 22| Step: 0
Training loss: 3.5320212273138045
Validation loss: 2.9175134191455676

Epoch: 5| Step: 1
Training loss: 3.168585513809781
Validation loss: 2.9052000201089974

Epoch: 5| Step: 2
Training loss: 2.8019874773800786
Validation loss: 2.9236750107409186

Epoch: 5| Step: 3
Training loss: 3.4129572635347842
Validation loss: 2.9937543578990375

Epoch: 5| Step: 4
Training loss: 3.5811664032291475
Validation loss: 2.976135922695196

Epoch: 5| Step: 5
Training loss: 3.182011834976754
Validation loss: 2.9655009808323856

Epoch: 5| Step: 6
Training loss: 3.1205557692534507
Validation loss: 2.9564554897474236

Epoch: 5| Step: 7
Training loss: 3.413854527194901
Validation loss: 2.9468847213875504

Epoch: 5| Step: 8
Training loss: 3.011880081150307
Validation loss: 2.9257022441690412

Epoch: 5| Step: 9
Training loss: 3.4479705867796153
Validation loss: 2.9136157789943042

Epoch: 5| Step: 10
Training loss: 3.007923470964269
Validation loss: 2.910093493713025

Epoch: 23| Step: 0
Training loss: 3.7287510617210216
Validation loss: 2.928744545410072

Epoch: 5| Step: 1
Training loss: 2.6086278519596333
Validation loss: 2.901785796935233

Epoch: 5| Step: 2
Training loss: 2.895847201600017
Validation loss: 2.899860483532772

Epoch: 5| Step: 3
Training loss: 3.4528932795732437
Validation loss: 2.902563936006059

Epoch: 5| Step: 4
Training loss: 3.4639588680776634
Validation loss: 2.8990057737070707

Epoch: 5| Step: 5
Training loss: 3.1931240356706683
Validation loss: 2.895876608739383

Epoch: 5| Step: 6
Training loss: 3.340877118780415
Validation loss: 2.890731560345726

Epoch: 5| Step: 7
Training loss: 3.424791182118011
Validation loss: 2.8883462044613757

Epoch: 5| Step: 8
Training loss: 3.4927849653199154
Validation loss: 2.887346420177774

Epoch: 5| Step: 9
Training loss: 2.3940190176531106
Validation loss: 2.8834607173425084

Epoch: 5| Step: 10
Training loss: 3.1609908653351755
Validation loss: 2.8787998770818857

Epoch: 24| Step: 0
Training loss: 3.4917520341171464
Validation loss: 2.8780478648461547

Epoch: 5| Step: 1
Training loss: 2.784871347630185
Validation loss: 2.876833134675969

Epoch: 5| Step: 2
Training loss: 2.5984395846635504
Validation loss: 2.8752224975635454

Epoch: 5| Step: 3
Training loss: 2.785359208040529
Validation loss: 2.871896000874525

Epoch: 5| Step: 4
Training loss: 3.284325166826914
Validation loss: 2.868293140635032

Epoch: 5| Step: 5
Training loss: 3.4112178028526023
Validation loss: 2.864695555576024

Epoch: 5| Step: 6
Training loss: 4.010978890514914
Validation loss: 2.8651903928087368

Epoch: 5| Step: 7
Training loss: 3.3877540070855816
Validation loss: 2.864147388626654

Epoch: 5| Step: 8
Training loss: 3.6077089634342387
Validation loss: 2.8607584731378344

Epoch: 5| Step: 9
Training loss: 2.758030091257789
Validation loss: 2.858496642388627

Epoch: 5| Step: 10
Training loss: 2.6471204155257486
Validation loss: 2.8590303909662427

Epoch: 25| Step: 0
Training loss: 3.190092042653407
Validation loss: 2.859594360773916

Epoch: 5| Step: 1
Training loss: 3.2313758102509826
Validation loss: 2.87088488260702

Epoch: 5| Step: 2
Training loss: 3.752782425186162
Validation loss: 2.8596728836720517

Epoch: 5| Step: 3
Training loss: 3.0770072650395943
Validation loss: 2.856028628006276

Epoch: 5| Step: 4
Training loss: 2.711878984091866
Validation loss: 2.8530894570739767

Epoch: 5| Step: 5
Training loss: 3.223066232207279
Validation loss: 2.849119761595022

Epoch: 5| Step: 6
Training loss: 3.4029093468244316
Validation loss: 2.849626097577041

Epoch: 5| Step: 7
Training loss: 3.1650126973118935
Validation loss: 2.8464366991431684

Epoch: 5| Step: 8
Training loss: 2.8319157438729543
Validation loss: 2.8475420384969667

Epoch: 5| Step: 9
Training loss: 2.828931830374023
Validation loss: 2.84533456502101

Epoch: 5| Step: 10
Training loss: 3.454803473131846
Validation loss: 2.844661185783035

Epoch: 26| Step: 0
Training loss: 2.6666620274344464
Validation loss: 2.8408550377827986

Epoch: 5| Step: 1
Training loss: 3.5746026838705
Validation loss: 2.839884441618115

Epoch: 5| Step: 2
Training loss: 2.956047751220389
Validation loss: 2.838954455159791

Epoch: 5| Step: 3
Training loss: 3.116345590654712
Validation loss: 2.8399284140172663

Epoch: 5| Step: 4
Training loss: 3.446690567076386
Validation loss: 2.8401199100247045

Epoch: 5| Step: 5
Training loss: 3.017399241259324
Validation loss: 2.8369732397665595

Epoch: 5| Step: 6
Training loss: 3.3239975529557273
Validation loss: 2.835578765820223

Epoch: 5| Step: 7
Training loss: 2.750103341675105
Validation loss: 2.8359641131486253

Epoch: 5| Step: 8
Training loss: 3.2463842966578853
Validation loss: 2.832151352510723

Epoch: 5| Step: 9
Training loss: 3.3071398282176987
Validation loss: 2.830329358189205

Epoch: 5| Step: 10
Training loss: 3.3296104304086587
Validation loss: 2.8323342759415056

Epoch: 27| Step: 0
Training loss: 2.5553856691845804
Validation loss: 2.833104684158469

Epoch: 5| Step: 1
Training loss: 3.3687168551426327
Validation loss: 2.8382770349872253

Epoch: 5| Step: 2
Training loss: 3.132331183315036
Validation loss: 2.834549822476813

Epoch: 5| Step: 3
Training loss: 2.8287152259297397
Validation loss: 2.8281258593435417

Epoch: 5| Step: 4
Training loss: 2.8874180505526432
Validation loss: 2.8270851824850185

Epoch: 5| Step: 5
Training loss: 3.1364812891709297
Validation loss: 2.8246108204938842

Epoch: 5| Step: 6
Training loss: 3.125977935361695
Validation loss: 2.8239882668199696

Epoch: 5| Step: 7
Training loss: 3.359180107673385
Validation loss: 2.8250014136410044

Epoch: 5| Step: 8
Training loss: 3.9265544073079903
Validation loss: 2.821849010062896

Epoch: 5| Step: 9
Training loss: 3.1676541512064214
Validation loss: 2.8209402525194514

Epoch: 5| Step: 10
Training loss: 2.9861317202623257
Validation loss: 2.8216691056199745

Epoch: 28| Step: 0
Training loss: 3.087319212033668
Validation loss: 2.8174049220605

Epoch: 5| Step: 1
Training loss: 2.922897731060776
Validation loss: 2.818098354264437

Epoch: 5| Step: 2
Training loss: 2.6826459829634004
Validation loss: 2.816735521850977

Epoch: 5| Step: 3
Training loss: 3.471917021159758
Validation loss: 2.8153741778070613

Epoch: 5| Step: 4
Training loss: 2.8552533236752216
Validation loss: 2.815703896301512

Epoch: 5| Step: 5
Training loss: 2.976042133812383
Validation loss: 2.8208607464116606

Epoch: 5| Step: 6
Training loss: 3.417709672100747
Validation loss: 2.82014718774373

Epoch: 5| Step: 7
Training loss: 2.870859730843227
Validation loss: 2.8265538374402004

Epoch: 5| Step: 8
Training loss: 2.902986067782829
Validation loss: 2.841816114439397

Epoch: 5| Step: 9
Training loss: 3.540435861382326
Validation loss: 2.840165832989454

Epoch: 5| Step: 10
Training loss: 3.7855395742032454
Validation loss: 2.8396209486312616

Epoch: 29| Step: 0
Training loss: 3.416053034565028
Validation loss: 2.810181340823456

Epoch: 5| Step: 1
Training loss: 2.9621748540604136
Validation loss: 2.8088269330085986

Epoch: 5| Step: 2
Training loss: 2.2759198142342307
Validation loss: 2.8088013939354286

Epoch: 5| Step: 3
Training loss: 2.8768855007327234
Validation loss: 2.8089348304400135

Epoch: 5| Step: 4
Training loss: 3.1387874864461276
Validation loss: 2.8116698504046713

Epoch: 5| Step: 5
Training loss: 3.7857233494652673
Validation loss: 2.8088506377776055

Epoch: 5| Step: 6
Training loss: 3.2824523176229476
Validation loss: 2.8083226344631216

Epoch: 5| Step: 7
Training loss: 3.244685302427955
Validation loss: 2.8109326898388125

Epoch: 5| Step: 8
Training loss: 3.5243395139230578
Validation loss: 2.807423323791389

Epoch: 5| Step: 9
Training loss: 2.949501680861578
Validation loss: 2.8018231490497794

Epoch: 5| Step: 10
Training loss: 2.716609594607617
Validation loss: 2.801062824474426

Epoch: 30| Step: 0
Training loss: 2.327628780453083
Validation loss: 2.8009496895543733

Epoch: 5| Step: 1
Training loss: 3.551028873550737
Validation loss: 2.8255727742850136

Epoch: 5| Step: 2
Training loss: 3.042745285741376
Validation loss: 2.80471757958414

Epoch: 5| Step: 3
Training loss: 3.061007700529385
Validation loss: 2.800060391177677

Epoch: 5| Step: 4
Training loss: 2.9031918751022414
Validation loss: 2.7992269792265483

Epoch: 5| Step: 5
Training loss: 2.760597875633271
Validation loss: 2.7992133551756284

Epoch: 5| Step: 6
Training loss: 3.775635894370689
Validation loss: 2.7999327876407873

Epoch: 5| Step: 7
Training loss: 2.5963487589992478
Validation loss: 2.8002702246780458

Epoch: 5| Step: 8
Training loss: 3.436610158707934
Validation loss: 2.7999329725935813

Epoch: 5| Step: 9
Training loss: 3.4607538385505663
Validation loss: 2.7987592881446983

Epoch: 5| Step: 10
Training loss: 3.2545936105767987
Validation loss: 2.798138506596079

Epoch: 31| Step: 0
Training loss: 3.304935382898104
Validation loss: 2.799160970283678

Epoch: 5| Step: 1
Training loss: 2.7828374040143626
Validation loss: 2.796634330301009

Epoch: 5| Step: 2
Training loss: 2.8228939003865086
Validation loss: 2.7935104532064616

Epoch: 5| Step: 3
Training loss: 3.377902160691181
Validation loss: 2.7938148897144184

Epoch: 5| Step: 4
Training loss: 2.306566720112877
Validation loss: 2.7930798291136285

Epoch: 5| Step: 5
Training loss: 3.500393845333512
Validation loss: 2.792618250637945

Epoch: 5| Step: 6
Training loss: 3.0165090895607034
Validation loss: 2.7899393576276394

Epoch: 5| Step: 7
Training loss: 3.257585769191678
Validation loss: 2.7880424926998084

Epoch: 5| Step: 8
Training loss: 3.1473830660549957
Validation loss: 2.7956039933111017

Epoch: 5| Step: 9
Training loss: 2.939572029623733
Validation loss: 2.790687367841828

Epoch: 5| Step: 10
Training loss: 3.6763321466746364
Validation loss: 2.790146390020886

Epoch: 32| Step: 0
Training loss: 3.2228252204755687
Validation loss: 2.7871611935319733

Epoch: 5| Step: 1
Training loss: 3.244237927028912
Validation loss: 2.7867304254599468

Epoch: 5| Step: 2
Training loss: 3.8063086594444644
Validation loss: 2.789652159233293

Epoch: 5| Step: 3
Training loss: 2.0069251567378674
Validation loss: 2.789305788048423

Epoch: 5| Step: 4
Training loss: 3.1400689539050446
Validation loss: 2.797892207868915

Epoch: 5| Step: 5
Training loss: 2.2156879625937873
Validation loss: 2.796762012833128

Epoch: 5| Step: 6
Training loss: 3.5531321717578237
Validation loss: 2.7980681758319492

Epoch: 5| Step: 7
Training loss: 3.2241364380053805
Validation loss: 2.7959747744730956

Epoch: 5| Step: 8
Training loss: 2.3107356996358925
Validation loss: 2.7904351701213472

Epoch: 5| Step: 9
Training loss: 3.4079974530528405
Validation loss: 2.7863199412208446

Epoch: 5| Step: 10
Training loss: 3.736020543648479
Validation loss: 2.782408779497491

Epoch: 33| Step: 0
Training loss: 2.6522347114633655
Validation loss: 2.781057033317729

Epoch: 5| Step: 1
Training loss: 2.715097626815365
Validation loss: 2.7898876164257795

Epoch: 5| Step: 2
Training loss: 3.083344502471764
Validation loss: 2.7972926775902964

Epoch: 5| Step: 3
Training loss: 3.263137819344986
Validation loss: 2.8110302811943217

Epoch: 5| Step: 4
Training loss: 3.006242932095219
Validation loss: 2.7888924159141655

Epoch: 5| Step: 5
Training loss: 3.038250263004108
Validation loss: 2.784576347820451

Epoch: 5| Step: 6
Training loss: 3.3903243111738623
Validation loss: 2.7811659435785017

Epoch: 5| Step: 7
Training loss: 3.334900169880113
Validation loss: 2.777994468057936

Epoch: 5| Step: 8
Training loss: 3.1123491181720326
Validation loss: 2.776881608136193

Epoch: 5| Step: 9
Training loss: 3.101428742491269
Validation loss: 2.7759944883519214

Epoch: 5| Step: 10
Training loss: 3.417193829565897
Validation loss: 2.7738113893093574

Epoch: 34| Step: 0
Training loss: 2.808259861906631
Validation loss: 2.776721825694832

Epoch: 5| Step: 1
Training loss: 2.9040847423789082
Validation loss: 2.778164405441318

Epoch: 5| Step: 2
Training loss: 3.37656323999117
Validation loss: 2.7875341406232916

Epoch: 5| Step: 3
Training loss: 3.3430714141493505
Validation loss: 2.776762832056006

Epoch: 5| Step: 4
Training loss: 2.955138635110402
Validation loss: 2.770512730637326

Epoch: 5| Step: 5
Training loss: 3.266383324875452
Validation loss: 2.7677384075224825

Epoch: 5| Step: 6
Training loss: 2.5035102043027697
Validation loss: 2.767842693904527

Epoch: 5| Step: 7
Training loss: 3.5769846069243614
Validation loss: 2.7677686080091535

Epoch: 5| Step: 8
Training loss: 3.451935299953271
Validation loss: 2.7671252492436644

Epoch: 5| Step: 9
Training loss: 3.3249308700832443
Validation loss: 2.7654129604254254

Epoch: 5| Step: 10
Training loss: 2.0761842772148387
Validation loss: 2.76369142547537

Epoch: 35| Step: 0
Training loss: 2.8074777478960793
Validation loss: 2.761465760588109

Epoch: 5| Step: 1
Training loss: 2.9568504772084556
Validation loss: 2.7605347227150347

Epoch: 5| Step: 2
Training loss: 3.2387712611770785
Validation loss: 2.762771509061826

Epoch: 5| Step: 3
Training loss: 2.8612519654433473
Validation loss: 2.761672859305506

Epoch: 5| Step: 4
Training loss: 2.935703945970409
Validation loss: 2.762963101920682

Epoch: 5| Step: 5
Training loss: 2.699983038672401
Validation loss: 2.7620214947384505

Epoch: 5| Step: 6
Training loss: 3.405898889766761
Validation loss: 2.769607862932137

Epoch: 5| Step: 7
Training loss: 3.5923090160469853
Validation loss: 2.768545022975714

Epoch: 5| Step: 8
Training loss: 3.0762540291609066
Validation loss: 2.7583558023452963

Epoch: 5| Step: 9
Training loss: 3.0332801548694452
Validation loss: 2.759252172032165

Epoch: 5| Step: 10
Training loss: 3.2331502318563747
Validation loss: 2.757881842978401

Epoch: 36| Step: 0
Training loss: 2.9572723169467485
Validation loss: 2.754679648085976

Epoch: 5| Step: 1
Training loss: 3.2783121671964643
Validation loss: 2.7539881233048424

Epoch: 5| Step: 2
Training loss: 3.4207418995639847
Validation loss: 2.7533485072969524

Epoch: 5| Step: 3
Training loss: 3.0626964895312927
Validation loss: 2.752992217751738

Epoch: 5| Step: 4
Training loss: 2.9562174434361177
Validation loss: 2.7499754756382107

Epoch: 5| Step: 5
Training loss: 3.0920032232349173
Validation loss: 2.7496330523545973

Epoch: 5| Step: 6
Training loss: 3.243289769328672
Validation loss: 2.7517051127676933

Epoch: 5| Step: 7
Training loss: 2.9588930021473807
Validation loss: 2.749487319171274

Epoch: 5| Step: 8
Training loss: 2.8381940623005892
Validation loss: 2.7514181172261174

Epoch: 5| Step: 9
Training loss: 3.2791633874148913
Validation loss: 2.7528934526793063

Epoch: 5| Step: 10
Training loss: 2.6293444332071636
Validation loss: 2.755695043141282

Epoch: 37| Step: 0
Training loss: 3.0329828716615728
Validation loss: 2.7579388797943745

Epoch: 5| Step: 1
Training loss: 3.0771958551170435
Validation loss: 2.7706925693099693

Epoch: 5| Step: 2
Training loss: 3.831461546193052
Validation loss: 2.797351980036973

Epoch: 5| Step: 3
Training loss: 1.9687887520987681
Validation loss: 2.746931584779263

Epoch: 5| Step: 4
Training loss: 2.8844080698880408
Validation loss: 2.7493499162739443

Epoch: 5| Step: 5
Training loss: 2.931353367526272
Validation loss: 2.7661922339626863

Epoch: 5| Step: 6
Training loss: 3.2363455109483215
Validation loss: 2.7795120225279892

Epoch: 5| Step: 7
Training loss: 2.6287119823396763
Validation loss: 2.7905042986760273

Epoch: 5| Step: 8
Training loss: 3.368243908067074
Validation loss: 2.7687251126065213

Epoch: 5| Step: 9
Training loss: 3.550402932739078
Validation loss: 2.7549196306773447

Epoch: 5| Step: 10
Training loss: 3.1682979163434966
Validation loss: 2.7494088942504016

Epoch: 38| Step: 0
Training loss: 3.128652955278868
Validation loss: 2.7510089049016377

Epoch: 5| Step: 1
Training loss: 2.800475717050725
Validation loss: 2.7523565021543956

Epoch: 5| Step: 2
Training loss: 3.069667292158207
Validation loss: 2.763565609309831

Epoch: 5| Step: 3
Training loss: 3.82701150698361
Validation loss: 2.7519708378402834

Epoch: 5| Step: 4
Training loss: 2.64411794568498
Validation loss: 2.755834203226217

Epoch: 5| Step: 5
Training loss: 2.739621605744774
Validation loss: 2.7524422868942993

Epoch: 5| Step: 6
Training loss: 3.2811148479420438
Validation loss: 2.756601382755463

Epoch: 5| Step: 7
Training loss: 3.300989990857102
Validation loss: 2.7509867873100413

Epoch: 5| Step: 8
Training loss: 3.1160499581383108
Validation loss: 2.7513269316228284

Epoch: 5| Step: 9
Training loss: 2.6097238273225423
Validation loss: 2.7450100793027157

Epoch: 5| Step: 10
Training loss: 3.0784304704470675
Validation loss: 2.7412240296407995

Epoch: 39| Step: 0
Training loss: 2.8717835719983174
Validation loss: 2.7396362373193868

Epoch: 5| Step: 1
Training loss: 2.819254076898686
Validation loss: 2.7365413530373144

Epoch: 5| Step: 2
Training loss: 3.112248458809218
Validation loss: 2.7408003555383296

Epoch: 5| Step: 3
Training loss: 2.913859424213802
Validation loss: 2.7357787389204677

Epoch: 5| Step: 4
Training loss: 3.0006881560385508
Validation loss: 2.7385094643956

Epoch: 5| Step: 5
Training loss: 2.590365396153523
Validation loss: 2.739500262475104

Epoch: 5| Step: 6
Training loss: 3.338047048476003
Validation loss: 2.745238342260344

Epoch: 5| Step: 7
Training loss: 3.091046626045095
Validation loss: 2.7574728688912447

Epoch: 5| Step: 8
Training loss: 3.1758534703600154
Validation loss: 2.744759018747373

Epoch: 5| Step: 9
Training loss: 3.231001711959173
Validation loss: 2.7300748318376167

Epoch: 5| Step: 10
Training loss: 3.476253470069665
Validation loss: 2.7187253681934553

Epoch: 40| Step: 0
Training loss: 3.060367075027297
Validation loss: 2.7166513941451482

Epoch: 5| Step: 1
Training loss: 3.0879928504386713
Validation loss: 2.7147925889594884

Epoch: 5| Step: 2
Training loss: 3.0723106347028777
Validation loss: 2.7118038372352116

Epoch: 5| Step: 3
Training loss: 2.841026427186686
Validation loss: 2.713942383966074

Epoch: 5| Step: 4
Training loss: 2.871949111264486
Validation loss: 2.7113345805380153

Epoch: 5| Step: 5
Training loss: 3.2733160101075436
Validation loss: 2.7131122564817174

Epoch: 5| Step: 6
Training loss: 3.642043856386584
Validation loss: 2.7105112227972508

Epoch: 5| Step: 7
Training loss: 2.971829874716965
Validation loss: 2.7098378157424077

Epoch: 5| Step: 8
Training loss: 2.2709937316055497
Validation loss: 2.706089424568798

Epoch: 5| Step: 9
Training loss: 3.3015099798846332
Validation loss: 2.711060259760326

Epoch: 5| Step: 10
Training loss: 2.937967953033899
Validation loss: 2.7077341327155917

Epoch: 41| Step: 0
Training loss: 3.1953905464471366
Validation loss: 2.7134542357633054

Epoch: 5| Step: 1
Training loss: 2.7710291762204684
Validation loss: 2.7175601613502516

Epoch: 5| Step: 2
Training loss: 3.444739469246742
Validation loss: 2.7218884703035116

Epoch: 5| Step: 3
Training loss: 2.5806305703204426
Validation loss: 2.7473472663627474

Epoch: 5| Step: 4
Training loss: 3.042536537120288
Validation loss: 2.747702603791191

Epoch: 5| Step: 5
Training loss: 3.130727630718089
Validation loss: 2.764869450008339

Epoch: 5| Step: 6
Training loss: 3.0226379441303233
Validation loss: 2.7492054512053756

Epoch: 5| Step: 7
Training loss: 3.407456630506357
Validation loss: 2.7353321543700377

Epoch: 5| Step: 8
Training loss: 3.213331235222771
Validation loss: 2.7133970027005394

Epoch: 5| Step: 9
Training loss: 2.3066199525428437
Validation loss: 2.7080920825846997

Epoch: 5| Step: 10
Training loss: 3.2011557875968553
Validation loss: 2.705455931372026

Epoch: 42| Step: 0
Training loss: 3.073354209310445
Validation loss: 2.704835999751676

Epoch: 5| Step: 1
Training loss: 3.6296802430361566
Validation loss: 2.7031294403997586

Epoch: 5| Step: 2
Training loss: 3.1323355980039795
Validation loss: 2.7044132028956454

Epoch: 5| Step: 3
Training loss: 3.2338580764269294
Validation loss: 2.7014670963089062

Epoch: 5| Step: 4
Training loss: 3.284985114866583
Validation loss: 2.7026842772696353

Epoch: 5| Step: 5
Training loss: 2.9573147233469768
Validation loss: 2.7037039772211235

Epoch: 5| Step: 6
Training loss: 2.835484492163174
Validation loss: 2.7095632336768642

Epoch: 5| Step: 7
Training loss: 2.541190326851319
Validation loss: 2.7152128877391957

Epoch: 5| Step: 8
Training loss: 2.8849524022345983
Validation loss: 2.719977351099792

Epoch: 5| Step: 9
Training loss: 2.723941012753524
Validation loss: 2.714082495636119

Epoch: 5| Step: 10
Training loss: 3.0129327170439906
Validation loss: 2.716285353150962

Epoch: 43| Step: 0
Training loss: 3.0555151869293913
Validation loss: 2.7115186911285476

Epoch: 5| Step: 1
Training loss: 3.584330811764459
Validation loss: 2.7040423851236666

Epoch: 5| Step: 2
Training loss: 3.0411783810612905
Validation loss: 2.6947763017539783

Epoch: 5| Step: 3
Training loss: 2.932412144482324
Validation loss: 2.697804221105051

Epoch: 5| Step: 4
Training loss: 2.4976793962873183
Validation loss: 2.701028306953164

Epoch: 5| Step: 5
Training loss: 3.133386269250745
Validation loss: 2.7073698556087216

Epoch: 5| Step: 6
Training loss: 2.6237130416295327
Validation loss: 2.7076835834207067

Epoch: 5| Step: 7
Training loss: 3.4790186745848826
Validation loss: 2.705403766494404

Epoch: 5| Step: 8
Training loss: 3.224016492048919
Validation loss: 2.699186363552451

Epoch: 5| Step: 9
Training loss: 3.0413569636727873
Validation loss: 2.6972686113408124

Epoch: 5| Step: 10
Training loss: 2.657952963264312
Validation loss: 2.6938634000745703

Epoch: 44| Step: 0
Training loss: 3.166569674830194
Validation loss: 2.690634187462557

Epoch: 5| Step: 1
Training loss: 2.318740877611667
Validation loss: 2.700177351164158

Epoch: 5| Step: 2
Training loss: 3.1862612542499513
Validation loss: 2.720338977766545

Epoch: 5| Step: 3
Training loss: 3.4822424961688156
Validation loss: 2.7525323113784603

Epoch: 5| Step: 4
Training loss: 2.8482499622206685
Validation loss: 2.7001350934175643

Epoch: 5| Step: 5
Training loss: 2.8227487962271036
Validation loss: 2.6891999111450997

Epoch: 5| Step: 6
Training loss: 3.024841298125443
Validation loss: 2.6897970972413923

Epoch: 5| Step: 7
Training loss: 3.321888699866652
Validation loss: 2.689332046170533

Epoch: 5| Step: 8
Training loss: 2.802046528589875
Validation loss: 2.6935076748249043

Epoch: 5| Step: 9
Training loss: 3.5391845682073315
Validation loss: 2.6966355738212537

Epoch: 5| Step: 10
Training loss: 2.5868337870059332
Validation loss: 2.698649453053753

Epoch: 45| Step: 0
Training loss: 2.490236768534389
Validation loss: 2.7014520701037856

Epoch: 5| Step: 1
Training loss: 3.704786998067474
Validation loss: 2.6974053502728976

Epoch: 5| Step: 2
Training loss: 3.220013861063628
Validation loss: 2.6936684722246045

Epoch: 5| Step: 3
Training loss: 2.8922871527668303
Validation loss: 2.6928056874778026

Epoch: 5| Step: 4
Training loss: 3.4597876987483143
Validation loss: 2.6902005677542458

Epoch: 5| Step: 5
Training loss: 2.503460872751988
Validation loss: 2.6859594070827892

Epoch: 5| Step: 6
Training loss: 3.5602001328952126
Validation loss: 2.6869097340701886

Epoch: 5| Step: 7
Training loss: 2.4233263158718477
Validation loss: 2.683967079668043

Epoch: 5| Step: 8
Training loss: 3.086251003903318
Validation loss: 2.6852269176458305

Epoch: 5| Step: 9
Training loss: 2.4279444289847403
Validation loss: 2.6857028407713486

Epoch: 5| Step: 10
Training loss: 3.2143699695504035
Validation loss: 2.6881705141883523

Epoch: 46| Step: 0
Training loss: 3.1697508365651963
Validation loss: 2.6918023135609026

Epoch: 5| Step: 1
Training loss: 3.2635411088498385
Validation loss: 2.690693136653552

Epoch: 5| Step: 2
Training loss: 2.9314755285895258
Validation loss: 2.6843307640646996

Epoch: 5| Step: 3
Training loss: 2.780597567381169
Validation loss: 2.6826867138918775

Epoch: 5| Step: 4
Training loss: 3.2915609479578367
Validation loss: 2.6891526494430398

Epoch: 5| Step: 5
Training loss: 2.3977412601837074
Validation loss: 2.711351201909985

Epoch: 5| Step: 6
Training loss: 2.524581413698534
Validation loss: 2.7396901346648996

Epoch: 5| Step: 7
Training loss: 3.6333267340177278
Validation loss: 2.753075463810997

Epoch: 5| Step: 8
Training loss: 2.7692586874980987
Validation loss: 2.72022769059733

Epoch: 5| Step: 9
Training loss: 2.7307898860575914
Validation loss: 2.692884870253757

Epoch: 5| Step: 10
Training loss: 3.502230342311235
Validation loss: 2.675853345339988

Epoch: 47| Step: 0
Training loss: 2.4543111083999083
Validation loss: 2.6699736164257066

Epoch: 5| Step: 1
Training loss: 3.03908430939917
Validation loss: 2.6693632693408986

Epoch: 5| Step: 2
Training loss: 2.4685272888937613
Validation loss: 2.670656181576499

Epoch: 5| Step: 3
Training loss: 3.1538788604113988
Validation loss: 2.6708909775971583

Epoch: 5| Step: 4
Training loss: 3.214514158093414
Validation loss: 2.6736069804458307

Epoch: 5| Step: 5
Training loss: 2.5265118557885664
Validation loss: 2.6719167528942194

Epoch: 5| Step: 6
Training loss: 3.1635808130646854
Validation loss: 2.6758646705988536

Epoch: 5| Step: 7
Training loss: 3.2679029486823556
Validation loss: 2.6751034971633847

Epoch: 5| Step: 8
Training loss: 3.00553542306879
Validation loss: 2.668994794489191

Epoch: 5| Step: 9
Training loss: 3.6778492476583344
Validation loss: 2.6668272226462513

Epoch: 5| Step: 10
Training loss: 2.9917583107968744
Validation loss: 2.6650676169411027

Epoch: 48| Step: 0
Training loss: 3.177412639290381
Validation loss: 2.6717869604315347

Epoch: 5| Step: 1
Training loss: 3.1570294616890506
Validation loss: 2.702447032677483

Epoch: 5| Step: 2
Training loss: 3.3354180174965222
Validation loss: 2.715727512499678

Epoch: 5| Step: 3
Training loss: 2.6081946895749186
Validation loss: 2.6861068126933945

Epoch: 5| Step: 4
Training loss: 2.8087558832179114
Validation loss: 2.6715431345499585

Epoch: 5| Step: 5
Training loss: 2.554775411510624
Validation loss: 2.6637056938327057

Epoch: 5| Step: 6
Training loss: 3.103873441701844
Validation loss: 2.6634520217149977

Epoch: 5| Step: 7
Training loss: 2.54577706665527
Validation loss: 2.6622719648136415

Epoch: 5| Step: 8
Training loss: 3.0306757746821282
Validation loss: 2.663792217159139

Epoch: 5| Step: 9
Training loss: 2.958376781162482
Validation loss: 2.6627233180987315

Epoch: 5| Step: 10
Training loss: 3.747306110438157
Validation loss: 2.6577502999210454

Epoch: 49| Step: 0
Training loss: 3.5151412970196083
Validation loss: 2.655815622714621

Epoch: 5| Step: 1
Training loss: 3.375336524292308
Validation loss: 2.6549890641504663

Epoch: 5| Step: 2
Training loss: 2.8604519176232746
Validation loss: 2.6577051200481656

Epoch: 5| Step: 3
Training loss: 3.2238347158730942
Validation loss: 2.6598486134049732

Epoch: 5| Step: 4
Training loss: 2.7645141612073303
Validation loss: 2.675488782635292

Epoch: 5| Step: 5
Training loss: 2.9976317276696025
Validation loss: 2.720562937793485

Epoch: 5| Step: 6
Training loss: 2.8678489982192077
Validation loss: 2.6820168962647717

Epoch: 5| Step: 7
Training loss: 2.8036213923298456
Validation loss: 2.652364717431725

Epoch: 5| Step: 8
Training loss: 2.975144416445369
Validation loss: 2.650722938442828

Epoch: 5| Step: 9
Training loss: 2.652657087242442
Validation loss: 2.6481971400547093

Epoch: 5| Step: 10
Training loss: 2.9154916485447826
Validation loss: 2.6517904284602833

Epoch: 50| Step: 0
Training loss: 3.0589070945216754
Validation loss: 2.651569938442572

Epoch: 5| Step: 1
Training loss: 3.4975649673721243
Validation loss: 2.6525058453052917

Epoch: 5| Step: 2
Training loss: 2.9297635081286018
Validation loss: 2.654412820285644

Epoch: 5| Step: 3
Training loss: 3.054251325057617
Validation loss: 2.6447882150957884

Epoch: 5| Step: 4
Training loss: 3.137535131493348
Validation loss: 2.6446835906650277

Epoch: 5| Step: 5
Training loss: 2.3971284655225524
Validation loss: 2.64461114870905

Epoch: 5| Step: 6
Training loss: 3.10622150246886
Validation loss: 2.65078655375478

Epoch: 5| Step: 7
Training loss: 2.7570520492638244
Validation loss: 2.650725918223266

Epoch: 5| Step: 8
Training loss: 3.2617615839721132
Validation loss: 2.644109362124091

Epoch: 5| Step: 9
Training loss: 2.929781736765633
Validation loss: 2.64375052728325

Epoch: 5| Step: 10
Training loss: 2.630147065811924
Validation loss: 2.6411417929735532

Epoch: 51| Step: 0
Training loss: 2.911931872314994
Validation loss: 2.642090539945823

Epoch: 5| Step: 1
Training loss: 2.976339016431909
Validation loss: 2.6469954787937757

Epoch: 5| Step: 2
Training loss: 2.181119168355687
Validation loss: 2.6413567457467444

Epoch: 5| Step: 3
Training loss: 2.809298324811608
Validation loss: 2.64000963707113

Epoch: 5| Step: 4
Training loss: 3.4701076290797466
Validation loss: 2.6389802918708716

Epoch: 5| Step: 5
Training loss: 3.5575378392365833
Validation loss: 2.6373351801772853

Epoch: 5| Step: 6
Training loss: 2.876914506434201
Validation loss: 2.6365957249509497

Epoch: 5| Step: 7
Training loss: 1.9921493227423448
Validation loss: 2.638694510418943

Epoch: 5| Step: 8
Training loss: 3.4421388710109038
Validation loss: 2.6389213522954558

Epoch: 5| Step: 9
Training loss: 3.275104107548828
Validation loss: 2.6367013985546413

Epoch: 5| Step: 10
Training loss: 2.9246281183660434
Validation loss: 2.634901515292948

Epoch: 52| Step: 0
Training loss: 3.1988505802537945
Validation loss: 2.6368787394135347

Epoch: 5| Step: 1
Training loss: 3.0247711473389876
Validation loss: 2.6382062027486324

Epoch: 5| Step: 2
Training loss: 2.64971388945748
Validation loss: 2.6406019024980427

Epoch: 5| Step: 3
Training loss: 2.1707973962934437
Validation loss: 2.640394062492816

Epoch: 5| Step: 4
Training loss: 2.856919031231579
Validation loss: 2.644483255909441

Epoch: 5| Step: 5
Training loss: 3.307560819151735
Validation loss: 2.637442129573629

Epoch: 5| Step: 6
Training loss: 2.871008050379134
Validation loss: 2.630140045426425

Epoch: 5| Step: 7
Training loss: 3.4599822988773976
Validation loss: 2.6290096466254185

Epoch: 5| Step: 8
Training loss: 3.301667982547606
Validation loss: 2.6328011969526406

Epoch: 5| Step: 9
Training loss: 2.405652355931521
Validation loss: 2.6279175693609376

Epoch: 5| Step: 10
Training loss: 3.3029422705857674
Validation loss: 2.6259651265442403

Epoch: 53| Step: 0
Training loss: 3.802407209980953
Validation loss: 2.6291437019107193

Epoch: 5| Step: 1
Training loss: 2.9376848852534176
Validation loss: 2.629564675144442

Epoch: 5| Step: 2
Training loss: 2.3042432453842467
Validation loss: 2.627605426564887

Epoch: 5| Step: 3
Training loss: 2.5027602216881273
Validation loss: 2.6233907260155163

Epoch: 5| Step: 4
Training loss: 2.883517543516441
Validation loss: 2.625602280980056

Epoch: 5| Step: 5
Training loss: 3.021778213229139
Validation loss: 2.62936804007572

Epoch: 5| Step: 6
Training loss: 3.1509808663211327
Validation loss: 2.649320726602047

Epoch: 5| Step: 7
Training loss: 2.77506640243127
Validation loss: 2.649347252921874

Epoch: 5| Step: 8
Training loss: 3.330755922131999
Validation loss: 2.6430781760746074

Epoch: 5| Step: 9
Training loss: 2.9029226637055072
Validation loss: 2.6339608404174237

Epoch: 5| Step: 10
Training loss: 2.8344924650066874
Validation loss: 2.627806653892001

Epoch: 54| Step: 0
Training loss: 3.182397385925938
Validation loss: 2.62584616778253

Epoch: 5| Step: 1
Training loss: 2.8236549416154024
Validation loss: 2.6210666384469343

Epoch: 5| Step: 2
Training loss: 2.4427640755372493
Validation loss: 2.6191507977509887

Epoch: 5| Step: 3
Training loss: 2.9112332188215557
Validation loss: 2.619112229572402

Epoch: 5| Step: 4
Training loss: 3.10198833319255
Validation loss: 2.615251882596615

Epoch: 5| Step: 5
Training loss: 3.1959532302852773
Validation loss: 2.618340172939809

Epoch: 5| Step: 6
Training loss: 3.127857275299427
Validation loss: 2.615821896695212

Epoch: 5| Step: 7
Training loss: 2.6534080111794913
Validation loss: 2.614260657329382

Epoch: 5| Step: 8
Training loss: 3.184820507507301
Validation loss: 2.615006849888223

Epoch: 5| Step: 9
Training loss: 3.25209828645607
Validation loss: 2.614451843166192

Epoch: 5| Step: 10
Training loss: 2.5965147794570638
Validation loss: 2.6125965359046304

Epoch: 55| Step: 0
Training loss: 2.8802455649059087
Validation loss: 2.6191301096247006

Epoch: 5| Step: 1
Training loss: 2.6974627335089236
Validation loss: 2.6265188033557987

Epoch: 5| Step: 2
Training loss: 3.179225878749472
Validation loss: 2.626280552832676

Epoch: 5| Step: 3
Training loss: 2.5266933164306686
Validation loss: 2.617866131573538

Epoch: 5| Step: 4
Training loss: 3.5026688618221695
Validation loss: 2.6180058514457656

Epoch: 5| Step: 5
Training loss: 2.907488815272984
Validation loss: 2.6190155976552267

Epoch: 5| Step: 6
Training loss: 3.1658448273832587
Validation loss: 2.6155816779394323

Epoch: 5| Step: 7
Training loss: 2.280505855894861
Validation loss: 2.623667176941716

Epoch: 5| Step: 8
Training loss: 2.839164306293294
Validation loss: 2.619841943305425

Epoch: 5| Step: 9
Training loss: 3.260793223385793
Validation loss: 2.6127962679919596

Epoch: 5| Step: 10
Training loss: 3.125935681453238
Validation loss: 2.608148667980876

Epoch: 56| Step: 0
Training loss: 2.8059124410104874
Validation loss: 2.6074252513374954

Epoch: 5| Step: 1
Training loss: 3.088876141110956
Validation loss: 2.6098432026894254

Epoch: 5| Step: 2
Training loss: 3.2415982733591044
Validation loss: 2.6081259399670924

Epoch: 5| Step: 3
Training loss: 3.4388343302052435
Validation loss: 2.6038758940436537

Epoch: 5| Step: 4
Training loss: 2.5743518383950357
Validation loss: 2.6037416031650835

Epoch: 5| Step: 5
Training loss: 2.822080021335339
Validation loss: 2.603421063076698

Epoch: 5| Step: 6
Training loss: 3.018691485293956
Validation loss: 2.619562938592676

Epoch: 5| Step: 7
Training loss: 2.5091727777425876
Validation loss: 2.6746911520849905

Epoch: 5| Step: 8
Training loss: 2.6935843857129376
Validation loss: 2.6987393198311755

Epoch: 5| Step: 9
Training loss: 2.9486007346051886
Validation loss: 2.7114176060115978

Epoch: 5| Step: 10
Training loss: 3.4535894987715885
Validation loss: 2.6324896897072385

Epoch: 57| Step: 0
Training loss: 2.6098559273311968
Validation loss: 2.6036857078806968

Epoch: 5| Step: 1
Training loss: 2.910549961570216
Validation loss: 2.602029789181003

Epoch: 5| Step: 2
Training loss: 2.8166954114301186
Validation loss: 2.6066631864373377

Epoch: 5| Step: 3
Training loss: 3.1120921775483477
Validation loss: 2.609916224138806

Epoch: 5| Step: 4
Training loss: 2.9809368360930373
Validation loss: 2.6056684066466778

Epoch: 5| Step: 5
Training loss: 2.47900049202973
Validation loss: 2.6040915562452365

Epoch: 5| Step: 6
Training loss: 3.403528928998875
Validation loss: 2.60507182545516

Epoch: 5| Step: 7
Training loss: 3.3939770420626507
Validation loss: 2.6020262777602547

Epoch: 5| Step: 8
Training loss: 2.826839766180543
Validation loss: 2.603039767348892

Epoch: 5| Step: 9
Training loss: 3.242033658341827
Validation loss: 2.612967483365154

Epoch: 5| Step: 10
Training loss: 2.477957251548729
Validation loss: 2.626389908507093

Epoch: 58| Step: 0
Training loss: 2.7862642499885326
Validation loss: 2.633719066823269

Epoch: 5| Step: 1
Training loss: 3.1797450854736375
Validation loss: 2.654661929828804

Epoch: 5| Step: 2
Training loss: 2.9834051503606966
Validation loss: 2.6279616634322025

Epoch: 5| Step: 3
Training loss: 3.041635556693341
Validation loss: 2.6036613896260348

Epoch: 5| Step: 4
Training loss: 3.131811119863861
Validation loss: 2.6009418023386544

Epoch: 5| Step: 5
Training loss: 3.2636664691289012
Validation loss: 2.5965898052860537

Epoch: 5| Step: 6
Training loss: 2.5690965182065155
Validation loss: 2.5932746339908483

Epoch: 5| Step: 7
Training loss: 2.728988311608355
Validation loss: 2.592160346260772

Epoch: 5| Step: 8
Training loss: 2.7997873157378756
Validation loss: 2.5965409586220405

Epoch: 5| Step: 9
Training loss: 2.96515928255513
Validation loss: 2.5950772916732094

Epoch: 5| Step: 10
Training loss: 2.9935798294028046
Validation loss: 2.5966620300011254

Epoch: 59| Step: 0
Training loss: 2.4676466782096265
Validation loss: 2.605667092195175

Epoch: 5| Step: 1
Training loss: 2.5476938815175814
Validation loss: 2.595302071455662

Epoch: 5| Step: 2
Training loss: 3.409033381814798
Validation loss: 2.6011948174637833

Epoch: 5| Step: 3
Training loss: 2.8424028831941865
Validation loss: 2.6006612007565524

Epoch: 5| Step: 4
Training loss: 3.427351797114869
Validation loss: 2.5997028793966908

Epoch: 5| Step: 5
Training loss: 3.288261116602432
Validation loss: 2.592608056528519

Epoch: 5| Step: 6
Training loss: 3.277798390368577
Validation loss: 2.5943970943595933

Epoch: 5| Step: 7
Training loss: 2.5952252708074868
Validation loss: 2.5884831358505513

Epoch: 5| Step: 8
Training loss: 2.868740565465236
Validation loss: 2.589318364162464

Epoch: 5| Step: 9
Training loss: 2.4913191762489117
Validation loss: 2.588076430693439

Epoch: 5| Step: 10
Training loss: 2.9153256376094974
Validation loss: 2.597705156617034

Epoch: 60| Step: 0
Training loss: 2.903289928206717
Validation loss: 2.6004464814449837

Epoch: 5| Step: 1
Training loss: 2.4729199502393415
Validation loss: 2.6428343332462214

Epoch: 5| Step: 2
Training loss: 3.0501813115493963
Validation loss: 2.675878533221465

Epoch: 5| Step: 3
Training loss: 2.4372165221653015
Validation loss: 2.6667271294456025

Epoch: 5| Step: 4
Training loss: 2.5350775331757895
Validation loss: 2.594263686407669

Epoch: 5| Step: 5
Training loss: 2.877254928639004
Validation loss: 2.582925066275921

Epoch: 5| Step: 6
Training loss: 3.397961953752271
Validation loss: 2.5870270700955706

Epoch: 5| Step: 7
Training loss: 2.7825625462112944
Validation loss: 2.596784913238308

Epoch: 5| Step: 8
Training loss: 3.288089998048428
Validation loss: 2.608166330280256

Epoch: 5| Step: 9
Training loss: 3.0067652080427543
Validation loss: 2.6121507784432865

Epoch: 5| Step: 10
Training loss: 3.5680414568712147
Validation loss: 2.6034958268646995

Epoch: 61| Step: 0
Training loss: 2.719056736973209
Validation loss: 2.5982573873421115

Epoch: 5| Step: 1
Training loss: 3.0186748992866073
Validation loss: 2.592935125010229

Epoch: 5| Step: 2
Training loss: 2.672746482737622
Validation loss: 2.5909239912035575

Epoch: 5| Step: 3
Training loss: 2.353280792550355
Validation loss: 2.5878993128055887

Epoch: 5| Step: 4
Training loss: 3.3946096325638266
Validation loss: 2.58742581459747

Epoch: 5| Step: 5
Training loss: 2.8442405864395166
Validation loss: 2.5927024462502732

Epoch: 5| Step: 6
Training loss: 3.2350329038665313
Validation loss: 2.6165206145244113

Epoch: 5| Step: 7
Training loss: 3.270625616066625
Validation loss: 2.6339849937811874

Epoch: 5| Step: 8
Training loss: 2.7370074869875096
Validation loss: 2.6311001612685803

Epoch: 5| Step: 9
Training loss: 3.174339201639521
Validation loss: 2.613916353611743

Epoch: 5| Step: 10
Training loss: 2.8863199704471016
Validation loss: 2.605530059939789

Epoch: 62| Step: 0
Training loss: 3.317181284355561
Validation loss: 2.5846783718611435

Epoch: 5| Step: 1
Training loss: 3.257890366463024
Validation loss: 2.5824346027647596

Epoch: 5| Step: 2
Training loss: 2.5761868676710247
Validation loss: 2.588684745263185

Epoch: 5| Step: 3
Training loss: 2.848387238461353
Validation loss: 2.5933361501662877

Epoch: 5| Step: 4
Training loss: 2.917246043471379
Validation loss: 2.5978589178941727

Epoch: 5| Step: 5
Training loss: 2.9896372791345467
Validation loss: 2.602847407402519

Epoch: 5| Step: 6
Training loss: 2.4329647028848154
Validation loss: 2.5952759123914806

Epoch: 5| Step: 7
Training loss: 2.747552215801976
Validation loss: 2.5906867881458333

Epoch: 5| Step: 8
Training loss: 3.0522596462390092
Validation loss: 2.5833851004927055

Epoch: 5| Step: 9
Training loss: 2.9815513474532014
Validation loss: 2.5808943436539025

Epoch: 5| Step: 10
Training loss: 3.390065089813378
Validation loss: 2.584183638006785

Epoch: 63| Step: 0
Training loss: 2.7847324814030086
Validation loss: 2.585580783667111

Epoch: 5| Step: 1
Training loss: 2.8653829857186963
Validation loss: 2.5896910313965984

Epoch: 5| Step: 2
Training loss: 2.8347081233617897
Validation loss: 2.5988878783139318

Epoch: 5| Step: 3
Training loss: 2.5468549669098053
Validation loss: 2.5890961284689955

Epoch: 5| Step: 4
Training loss: 2.9804652302772467
Validation loss: 2.5810858695002663

Epoch: 5| Step: 5
Training loss: 3.5575878342101572
Validation loss: 2.574633820730454

Epoch: 5| Step: 6
Training loss: 2.836297466877844
Validation loss: 2.570726658699765

Epoch: 5| Step: 7
Training loss: 3.0115189343775106
Validation loss: 2.572092658086607

Epoch: 5| Step: 8
Training loss: 2.858737061424983
Validation loss: 2.5742805163949307

Epoch: 5| Step: 9
Training loss: 2.839596408320379
Validation loss: 2.572448291936349

Epoch: 5| Step: 10
Training loss: 3.0682148453190385
Validation loss: 2.572565402914391

Epoch: 64| Step: 0
Training loss: 2.5797858235078586
Validation loss: 2.5785359034980475

Epoch: 5| Step: 1
Training loss: 3.398699449988919
Validation loss: 2.590576735329858

Epoch: 5| Step: 2
Training loss: 2.954928054579207
Validation loss: 2.588112172762416

Epoch: 5| Step: 3
Training loss: 2.32153801712434
Validation loss: 2.5956554320343583

Epoch: 5| Step: 4
Training loss: 2.019633012048707
Validation loss: 2.5986329466686735

Epoch: 5| Step: 5
Training loss: 2.4476471015279477
Validation loss: 2.591914900024719

Epoch: 5| Step: 6
Training loss: 3.157124011199865
Validation loss: 2.61963448393095

Epoch: 5| Step: 7
Training loss: 3.2783546389139735
Validation loss: 2.6051607842420426

Epoch: 5| Step: 8
Training loss: 3.225847141870619
Validation loss: 2.5804326036551037

Epoch: 5| Step: 9
Training loss: 3.3394556723547133
Validation loss: 2.564738305756403

Epoch: 5| Step: 10
Training loss: 3.1896005328956543
Validation loss: 2.5645564201818605

Epoch: 65| Step: 0
Training loss: 2.6857059611971237
Validation loss: 2.5675255072355183

Epoch: 5| Step: 1
Training loss: 2.502694299340398
Validation loss: 2.570172810735015

Epoch: 5| Step: 2
Training loss: 3.4320066079918616
Validation loss: 2.5768714081971633

Epoch: 5| Step: 3
Training loss: 2.960615719343203
Validation loss: 2.5803724370432435

Epoch: 5| Step: 4
Training loss: 2.9991100898727874
Validation loss: 2.586445970234685

Epoch: 5| Step: 5
Training loss: 2.546817895916097
Validation loss: 2.584757760156062

Epoch: 5| Step: 6
Training loss: 3.172492206825442
Validation loss: 2.575488988043517

Epoch: 5| Step: 7
Training loss: 3.0085204245032675
Validation loss: 2.5756432365144946

Epoch: 5| Step: 8
Training loss: 3.065623967192901
Validation loss: 2.5783916137897513

Epoch: 5| Step: 9
Training loss: 3.4181375516353074
Validation loss: 2.570840471589227

Epoch: 5| Step: 10
Training loss: 2.4284236846990326
Validation loss: 2.570600148259053

Epoch: 66| Step: 0
Training loss: 3.209152282296943
Validation loss: 2.570505445100417

Epoch: 5| Step: 1
Training loss: 3.3798214417192622
Validation loss: 2.561139988149373

Epoch: 5| Step: 2
Training loss: 2.4489579495378715
Validation loss: 2.558678264986489

Epoch: 5| Step: 3
Training loss: 2.2381425584894235
Validation loss: 2.5596404118391756

Epoch: 5| Step: 4
Training loss: 3.049479618392811
Validation loss: 2.560265147535794

Epoch: 5| Step: 5
Training loss: 2.7897454288519397
Validation loss: 2.5663726210577984

Epoch: 5| Step: 6
Training loss: 2.982407645420786
Validation loss: 2.5702331612511014

Epoch: 5| Step: 7
Training loss: 2.634937368441214
Validation loss: 2.5680390166480436

Epoch: 5| Step: 8
Training loss: 2.934155122199222
Validation loss: 2.576097359155264

Epoch: 5| Step: 9
Training loss: 3.2332788351388495
Validation loss: 2.590275981698315

Epoch: 5| Step: 10
Training loss: 3.0164079193371447
Validation loss: 2.5805982453429546

Epoch: 67| Step: 0
Training loss: 2.9757437794019523
Validation loss: 2.582734280322745

Epoch: 5| Step: 1
Training loss: 2.79210857670465
Validation loss: 2.594862576625938

Epoch: 5| Step: 2
Training loss: 3.0690867377162037
Validation loss: 2.612023459458009

Epoch: 5| Step: 3
Training loss: 3.0766886346707096
Validation loss: 2.612730396181716

Epoch: 5| Step: 4
Training loss: 3.410492660865778
Validation loss: 2.5736825374472616

Epoch: 5| Step: 5
Training loss: 2.805945579142463
Validation loss: 2.5573181223822377

Epoch: 5| Step: 6
Training loss: 2.6101190111643198
Validation loss: 2.5632522243267033

Epoch: 5| Step: 7
Training loss: 2.7520019007110688
Validation loss: 2.567098915188932

Epoch: 5| Step: 8
Training loss: 2.9067011657324042
Validation loss: 2.570270488989265

Epoch: 5| Step: 9
Training loss: 2.8451653615832977
Validation loss: 2.573354950690302

Epoch: 5| Step: 10
Training loss: 3.192271980142456
Validation loss: 2.5733592693222214

Epoch: 68| Step: 0
Training loss: 3.086340460241455
Validation loss: 2.5711217581805452

Epoch: 5| Step: 1
Training loss: 2.8207831584425493
Validation loss: 2.5717292035894888

Epoch: 5| Step: 2
Training loss: 3.4946784026225286
Validation loss: 2.5668761510131897

Epoch: 5| Step: 3
Training loss: 2.9465624031619524
Validation loss: 2.566961472910443

Epoch: 5| Step: 4
Training loss: 3.1943492230215162
Validation loss: 2.5584893643771145

Epoch: 5| Step: 5
Training loss: 2.8027933254090063
Validation loss: 2.5565022865348834

Epoch: 5| Step: 6
Training loss: 2.950530996863471
Validation loss: 2.554817634171433

Epoch: 5| Step: 7
Training loss: 2.587799231876761
Validation loss: 2.5713760834028196

Epoch: 5| Step: 8
Training loss: 3.35299374624796
Validation loss: 2.5887207740461777

Epoch: 5| Step: 9
Training loss: 2.9315612497582215
Validation loss: 2.587501358595425

Epoch: 5| Step: 10
Training loss: 1.319017169881129
Validation loss: 2.60736741055222

Epoch: 69| Step: 0
Training loss: 2.758863297535513
Validation loss: 2.602219818549434

Epoch: 5| Step: 1
Training loss: 3.595852974624005
Validation loss: 2.596736436516004

Epoch: 5| Step: 2
Training loss: 3.2468498809107147
Validation loss: 2.5711913690994206

Epoch: 5| Step: 3
Training loss: 2.3517854401107976
Validation loss: 2.5577389086023614

Epoch: 5| Step: 4
Training loss: 2.7541370484514442
Validation loss: 2.5568437154934096

Epoch: 5| Step: 5
Training loss: 2.8363410095165964
Validation loss: 2.5542740336879857

Epoch: 5| Step: 6
Training loss: 2.9612974084011587
Validation loss: 2.5564178821249217

Epoch: 5| Step: 7
Training loss: 3.373648902873688
Validation loss: 2.5566676366127976

Epoch: 5| Step: 8
Training loss: 2.7804568584945644
Validation loss: 2.546612677045621

Epoch: 5| Step: 9
Training loss: 2.655434427154571
Validation loss: 2.5512998589198164

Epoch: 5| Step: 10
Training loss: 2.5077696229115425
Validation loss: 2.5539790971324448

Epoch: 70| Step: 0
Training loss: 2.7921152371286553
Validation loss: 2.557106933343951

Epoch: 5| Step: 1
Training loss: 3.3035055441159598
Validation loss: 2.5693624833890643

Epoch: 5| Step: 2
Training loss: 3.1303151514971894
Validation loss: 2.571731233185088

Epoch: 5| Step: 3
Training loss: 2.6755374546783526
Validation loss: 2.6032541536046105

Epoch: 5| Step: 4
Training loss: 3.1989793699552695
Validation loss: 2.6426282287571814

Epoch: 5| Step: 5
Training loss: 3.022772821903246
Validation loss: 2.671771491918912

Epoch: 5| Step: 6
Training loss: 3.28157288915408
Validation loss: 2.6981631671705917

Epoch: 5| Step: 7
Training loss: 2.5850734592529254
Validation loss: 2.599888274771669

Epoch: 5| Step: 8
Training loss: 2.8137480615704917
Validation loss: 2.5532544818836826

Epoch: 5| Step: 9
Training loss: 2.824269147874368
Validation loss: 2.54230494749742

Epoch: 5| Step: 10
Training loss: 2.2620022979778622
Validation loss: 2.550744708444793

Epoch: 71| Step: 0
Training loss: 2.80804539873098
Validation loss: 2.564780678263657

Epoch: 5| Step: 1
Training loss: 3.25586728356493
Validation loss: 2.575300461423137

Epoch: 5| Step: 2
Training loss: 2.954081385519937
Validation loss: 2.5743877819664416

Epoch: 5| Step: 3
Training loss: 2.7567453021542825
Validation loss: 2.5712459058912107

Epoch: 5| Step: 4
Training loss: 3.0292395777543897
Validation loss: 2.5644378607922125

Epoch: 5| Step: 5
Training loss: 2.4586609983020296
Validation loss: 2.5615687265021587

Epoch: 5| Step: 6
Training loss: 3.208383551530725
Validation loss: 2.5563519003800796

Epoch: 5| Step: 7
Training loss: 2.971127010202424
Validation loss: 2.5516104944279285

Epoch: 5| Step: 8
Training loss: 2.7456864425276115
Validation loss: 2.547208756970135

Epoch: 5| Step: 9
Training loss: 3.058756350193829
Validation loss: 2.545587094884335

Epoch: 5| Step: 10
Training loss: 2.9669982560541257
Validation loss: 2.562247755359726

Epoch: 72| Step: 0
Training loss: 3.242263094468875
Validation loss: 2.5783373941915224

Epoch: 5| Step: 1
Training loss: 2.8329489017056577
Validation loss: 2.570348330500874

Epoch: 5| Step: 2
Training loss: 2.9614415205295885
Validation loss: 2.551451251217396

Epoch: 5| Step: 3
Training loss: 2.814986592018624
Validation loss: 2.542475456877345

Epoch: 5| Step: 4
Training loss: 2.5673980422237523
Validation loss: 2.543443826756701

Epoch: 5| Step: 5
Training loss: 2.4009924584984854
Validation loss: 2.5383052330871347

Epoch: 5| Step: 6
Training loss: 3.174343257474209
Validation loss: 2.541798329149819

Epoch: 5| Step: 7
Training loss: 3.17645639372752
Validation loss: 2.543441347221289

Epoch: 5| Step: 8
Training loss: 2.6373608520828395
Validation loss: 2.5497008429485883

Epoch: 5| Step: 9
Training loss: 3.0217895748210313
Validation loss: 2.552436742532371

Epoch: 5| Step: 10
Training loss: 3.103132720046414
Validation loss: 2.5636535757176775

Epoch: 73| Step: 0
Training loss: 2.7286727302994014
Validation loss: 2.559861669534738

Epoch: 5| Step: 1
Training loss: 3.3637631167493094
Validation loss: 2.554155121468567

Epoch: 5| Step: 2
Training loss: 2.873215162793086
Validation loss: 2.545894159892375

Epoch: 5| Step: 3
Training loss: 3.1753986498852957
Validation loss: 2.5380166296940536

Epoch: 5| Step: 4
Training loss: 2.8990787095026587
Validation loss: 2.5336471908307363

Epoch: 5| Step: 5
Training loss: 2.6960913375980766
Validation loss: 2.5367286910155773

Epoch: 5| Step: 6
Training loss: 2.7095405431242368
Validation loss: 2.5376530786646194

Epoch: 5| Step: 7
Training loss: 3.0518264054791335
Validation loss: 2.537618895422103

Epoch: 5| Step: 8
Training loss: 2.879797705592231
Validation loss: 2.550225098985781

Epoch: 5| Step: 9
Training loss: 2.9514245683096623
Validation loss: 2.562169903879292

Epoch: 5| Step: 10
Training loss: 2.509171922573268
Validation loss: 2.5615677837400543

Epoch: 74| Step: 0
Training loss: 3.0675592478010154
Validation loss: 2.560467273702614

Epoch: 5| Step: 1
Training loss: 2.5196662807505517
Validation loss: 2.553411354627267

Epoch: 5| Step: 2
Training loss: 2.6046875292910165
Validation loss: 2.5767564538911265

Epoch: 5| Step: 3
Training loss: 3.065909531325486
Validation loss: 2.5763601597379324

Epoch: 5| Step: 4
Training loss: 2.9273322238293065
Validation loss: 2.540585700721047

Epoch: 5| Step: 5
Training loss: 2.364639673668147
Validation loss: 2.5361737949130636

Epoch: 5| Step: 6
Training loss: 3.1094875602859777
Validation loss: 2.532614041264451

Epoch: 5| Step: 7
Training loss: 2.789805764714451
Validation loss: 2.5332868496764984

Epoch: 5| Step: 8
Training loss: 3.0917959496405754
Validation loss: 2.5333063039433332

Epoch: 5| Step: 9
Training loss: 3.3771310365583886
Validation loss: 2.5398891489720525

Epoch: 5| Step: 10
Training loss: 2.9303843572267274
Validation loss: 2.539783089160653

Epoch: 75| Step: 0
Training loss: 2.6437842076029674
Validation loss: 2.5383433666619024

Epoch: 5| Step: 1
Training loss: 3.155587457292629
Validation loss: 2.5348171943616484

Epoch: 5| Step: 2
Training loss: 3.155795980601281
Validation loss: 2.534054469456211

Epoch: 5| Step: 3
Training loss: 3.054677509574456
Validation loss: 2.5294951859991377

Epoch: 5| Step: 4
Training loss: 3.0457974607039877
Validation loss: 2.528783152454302

Epoch: 5| Step: 5
Training loss: 2.967056915961288
Validation loss: 2.5326825626321456

Epoch: 5| Step: 6
Training loss: 2.5219945413649896
Validation loss: 2.54340884694096

Epoch: 5| Step: 7
Training loss: 2.5327311762203535
Validation loss: 2.5877843342222704

Epoch: 5| Step: 8
Training loss: 2.2722813134047763
Validation loss: 2.649770434360397

Epoch: 5| Step: 9
Training loss: 3.378306711622402
Validation loss: 2.720814919431023

Epoch: 5| Step: 10
Training loss: 3.1847125562375225
Validation loss: 2.6880142299925627

Epoch: 76| Step: 0
Training loss: 2.714311682067789
Validation loss: 2.6036091594543054

Epoch: 5| Step: 1
Training loss: 2.602146758952491
Validation loss: 2.568990531574036

Epoch: 5| Step: 2
Training loss: 2.948461170030767
Validation loss: 2.5613151260014067

Epoch: 5| Step: 3
Training loss: 2.963410243297503
Validation loss: 2.5375569236404467

Epoch: 5| Step: 4
Training loss: 2.8303069238733096
Validation loss: 2.5240953053417057

Epoch: 5| Step: 5
Training loss: 3.2131702243461984
Validation loss: 2.525849787675956

Epoch: 5| Step: 6
Training loss: 2.8797172325449774
Validation loss: 2.5291149108632838

Epoch: 5| Step: 7
Training loss: 2.7785668449770315
Validation loss: 2.5396946566721046

Epoch: 5| Step: 8
Training loss: 3.1506570040048416
Validation loss: 2.5430739319758784

Epoch: 5| Step: 9
Training loss: 2.4248450986803247
Validation loss: 2.5406945497948312

Epoch: 5| Step: 10
Training loss: 3.306885910174797
Validation loss: 2.540069323411585

Epoch: 77| Step: 0
Training loss: 3.126718430107565
Validation loss: 2.5379705224298146

Epoch: 5| Step: 1
Training loss: 2.8166538505337866
Validation loss: 2.53861354042254

Epoch: 5| Step: 2
Training loss: 3.160722792570106
Validation loss: 2.535951057832386

Epoch: 5| Step: 3
Training loss: 3.3894029515777646
Validation loss: 2.531714780191348

Epoch: 5| Step: 4
Training loss: 2.8354049476831684
Validation loss: 2.5289304373365225

Epoch: 5| Step: 5
Training loss: 2.7914538990377182
Validation loss: 2.5338706808217397

Epoch: 5| Step: 6
Training loss: 3.150569222502697
Validation loss: 2.5534434831230883

Epoch: 5| Step: 7
Training loss: 2.865079099352134
Validation loss: 2.553473377356273

Epoch: 5| Step: 8
Training loss: 2.7598876926129043
Validation loss: 2.6033319335644247

Epoch: 5| Step: 9
Training loss: 2.4096000437646587
Validation loss: 2.6633776058997127

Epoch: 5| Step: 10
Training loss: 2.4315947378953493
Validation loss: 2.725931359880698

Epoch: 78| Step: 0
Training loss: 3.1220953602959884
Validation loss: 2.681102882948391

Epoch: 5| Step: 1
Training loss: 3.119722258358798
Validation loss: 2.616419727036206

Epoch: 5| Step: 2
Training loss: 2.8689604638381487
Validation loss: 2.5322162971914777

Epoch: 5| Step: 3
Training loss: 2.5237730765645687
Validation loss: 2.518821988504135

Epoch: 5| Step: 4
Training loss: 2.9707188552550328
Validation loss: 2.5288362447940673

Epoch: 5| Step: 5
Training loss: 2.8220126873571956
Validation loss: 2.5427423242192493

Epoch: 5| Step: 6
Training loss: 3.0464303499164544
Validation loss: 2.545905305018867

Epoch: 5| Step: 7
Training loss: 2.923677755297476
Validation loss: 2.546254378150149

Epoch: 5| Step: 8
Training loss: 2.388019113876295
Validation loss: 2.536542699816965

Epoch: 5| Step: 9
Training loss: 3.3128009875323943
Validation loss: 2.530015365561708

Epoch: 5| Step: 10
Training loss: 3.1501561625690524
Validation loss: 2.5298394380212668

Epoch: 79| Step: 0
Training loss: 2.6059663174517187
Validation loss: 2.532217284290856

Epoch: 5| Step: 1
Training loss: 3.132152916021704
Validation loss: 2.5322792212231646

Epoch: 5| Step: 2
Training loss: 3.2666653522826166
Validation loss: 2.5348532130730264

Epoch: 5| Step: 3
Training loss: 2.8270673091230956
Validation loss: 2.5327476275185874

Epoch: 5| Step: 4
Training loss: 2.854103440375674
Validation loss: 2.527661203964839

Epoch: 5| Step: 5
Training loss: 2.796688393276179
Validation loss: 2.523830900135455

Epoch: 5| Step: 6
Training loss: 2.7046505366311324
Validation loss: 2.525557392783125

Epoch: 5| Step: 7
Training loss: 2.7815199303098983
Validation loss: 2.5216527929159493

Epoch: 5| Step: 8
Training loss: 2.7241319026072754
Validation loss: 2.521873398549415

Epoch: 5| Step: 9
Training loss: 3.261428107372681
Validation loss: 2.522599091949031

Epoch: 5| Step: 10
Training loss: 2.8825493255656265
Validation loss: 2.5226674178741377

Epoch: 80| Step: 0
Training loss: 2.768872956243197
Validation loss: 2.5409482827974177

Epoch: 5| Step: 1
Training loss: 2.337056890093123
Validation loss: 2.5597452943490695

Epoch: 5| Step: 2
Training loss: 2.837451037013885
Validation loss: 2.597704002946241

Epoch: 5| Step: 3
Training loss: 3.5141616149195425
Validation loss: 2.6245016454115575

Epoch: 5| Step: 4
Training loss: 2.9306287550459786
Validation loss: 2.5890993385922876

Epoch: 5| Step: 5
Training loss: 2.968473401485543
Validation loss: 2.548897803650752

Epoch: 5| Step: 6
Training loss: 2.9817998670916355
Validation loss: 2.5360195173413294

Epoch: 5| Step: 7
Training loss: 3.0344301825710125
Validation loss: 2.5270742643679336

Epoch: 5| Step: 8
Training loss: 2.5608753543595997
Validation loss: 2.521006677278461

Epoch: 5| Step: 9
Training loss: 2.7882309643760803
Validation loss: 2.5181316355106347

Epoch: 5| Step: 10
Training loss: 3.2339525914441754
Validation loss: 2.5189688599658355

Epoch: 81| Step: 0
Training loss: 2.2491054876071876
Validation loss: 2.5146672193600583

Epoch: 5| Step: 1
Training loss: 2.7475450134755244
Validation loss: 2.5176298325397592

Epoch: 5| Step: 2
Training loss: 2.91520868827036
Validation loss: 2.5185675247322576

Epoch: 5| Step: 3
Training loss: 2.675751489626928
Validation loss: 2.526899135442752

Epoch: 5| Step: 4
Training loss: 3.080216834622364
Validation loss: 2.5304314902719622

Epoch: 5| Step: 5
Training loss: 3.196277873634174
Validation loss: 2.5305413434453903

Epoch: 5| Step: 6
Training loss: 2.885264607266181
Validation loss: 2.5330701507792885

Epoch: 5| Step: 7
Training loss: 2.808295179687075
Validation loss: 2.5261619858059086

Epoch: 5| Step: 8
Training loss: 3.4054245254785003
Validation loss: 2.521374662551425

Epoch: 5| Step: 9
Training loss: 2.702115967572353
Validation loss: 2.5149887453318844

Epoch: 5| Step: 10
Training loss: 3.0139394209962247
Validation loss: 2.5143153453362905

Epoch: 82| Step: 0
Training loss: 2.982105610584686
Validation loss: 2.5128584400218754

Epoch: 5| Step: 1
Training loss: 3.2327845989367368
Validation loss: 2.513958275324886

Epoch: 5| Step: 2
Training loss: 2.469460783414374
Validation loss: 2.510799068559117

Epoch: 5| Step: 3
Training loss: 2.7820184053351067
Validation loss: 2.5109970353929314

Epoch: 5| Step: 4
Training loss: 2.462508508502958
Validation loss: 2.508371594374698

Epoch: 5| Step: 5
Training loss: 2.574839029558393
Validation loss: 2.5109825764418856

Epoch: 5| Step: 6
Training loss: 2.6041341448978397
Validation loss: 2.5148822582449766

Epoch: 5| Step: 7
Training loss: 3.0261297338980424
Validation loss: 2.5220534648948743

Epoch: 5| Step: 8
Training loss: 2.8943202138718593
Validation loss: 2.533848441473643

Epoch: 5| Step: 9
Training loss: 3.0934053479504615
Validation loss: 2.5586693427003326

Epoch: 5| Step: 10
Training loss: 3.492818958788106
Validation loss: 2.5787724541775665

Epoch: 83| Step: 0
Training loss: 2.3557157118151117
Validation loss: 2.543688983421772

Epoch: 5| Step: 1
Training loss: 3.259296765216012
Validation loss: 2.547864864389808

Epoch: 5| Step: 2
Training loss: 3.3941148649615167
Validation loss: 2.547300865694365

Epoch: 5| Step: 3
Training loss: 2.9892737641480625
Validation loss: 2.523166014171224

Epoch: 5| Step: 4
Training loss: 2.5475971157741046
Validation loss: 2.5128736655739106

Epoch: 5| Step: 5
Training loss: 2.8362335807153545
Validation loss: 2.508397191081447

Epoch: 5| Step: 6
Training loss: 2.7129981923868898
Validation loss: 2.5101974565882363

Epoch: 5| Step: 7
Training loss: 2.4700312126751265
Validation loss: 2.508522193693353

Epoch: 5| Step: 8
Training loss: 3.2156312517970993
Validation loss: 2.5049531593624086

Epoch: 5| Step: 9
Training loss: 3.413799074952348
Validation loss: 2.508898547704034

Epoch: 5| Step: 10
Training loss: 2.054841706613797
Validation loss: 2.5100773377043994

Epoch: 84| Step: 0
Training loss: 2.7315903789798273
Validation loss: 2.505753398225303

Epoch: 5| Step: 1
Training loss: 2.747318954959016
Validation loss: 2.511485802487678

Epoch: 5| Step: 2
Training loss: 2.7494897369010083
Validation loss: 2.51441769554491

Epoch: 5| Step: 3
Training loss: 2.9377731845522916
Validation loss: 2.5095186376533514

Epoch: 5| Step: 4
Training loss: 2.8354163833905783
Validation loss: 2.5126077132078115

Epoch: 5| Step: 5
Training loss: 2.766023596364379
Validation loss: 2.511226257145991

Epoch: 5| Step: 6
Training loss: 2.6902193904596206
Validation loss: 2.508931727996767

Epoch: 5| Step: 7
Training loss: 3.7651261755076253
Validation loss: 2.5158762234737186

Epoch: 5| Step: 8
Training loss: 2.7972636885117583
Validation loss: 2.5257009533763526

Epoch: 5| Step: 9
Training loss: 3.0019165910472085
Validation loss: 2.5329515963191014

Epoch: 5| Step: 10
Training loss: 2.329924841393071
Validation loss: 2.5453938960695592

Epoch: 85| Step: 0
Training loss: 2.9597682606993843
Validation loss: 2.5978235892016954

Epoch: 5| Step: 1
Training loss: 3.061245408278636
Validation loss: 2.6543858916217116

Epoch: 5| Step: 2
Training loss: 2.555598665187103
Validation loss: 2.660868324998866

Epoch: 5| Step: 3
Training loss: 3.2095702293023174
Validation loss: 2.696457541489002

Epoch: 5| Step: 4
Training loss: 3.338811203921559
Validation loss: 2.6027845637255114

Epoch: 5| Step: 5
Training loss: 2.3988183927501647
Validation loss: 2.5477251115894837

Epoch: 5| Step: 6
Training loss: 3.0681086971419425
Validation loss: 2.514503817678219

Epoch: 5| Step: 7
Training loss: 2.638859356051263
Validation loss: 2.514129078738816

Epoch: 5| Step: 8
Training loss: 2.920152942101018
Validation loss: 2.518198203339032

Epoch: 5| Step: 9
Training loss: 2.9826982990861786
Validation loss: 2.519030557307726

Epoch: 5| Step: 10
Training loss: 2.616096018466856
Validation loss: 2.521442851861218

Epoch: 86| Step: 0
Training loss: 3.267269322863513
Validation loss: 2.5280368626255623

Epoch: 5| Step: 1
Training loss: 2.905375195171742
Validation loss: 2.528856839305693

Epoch: 5| Step: 2
Training loss: 2.8778890937606207
Validation loss: 2.5208183402708255

Epoch: 5| Step: 3
Training loss: 3.5358169865520663
Validation loss: 2.516881073889595

Epoch: 5| Step: 4
Training loss: 2.552871665385708
Validation loss: 2.511391527825837

Epoch: 5| Step: 5
Training loss: 3.05454388449162
Validation loss: 2.512953591067443

Epoch: 5| Step: 6
Training loss: 2.8905817801878744
Validation loss: 2.5209934350223673

Epoch: 5| Step: 7
Training loss: 2.7975151139329175
Validation loss: 2.539184458338058

Epoch: 5| Step: 8
Training loss: 2.1960698786319885
Validation loss: 2.5739974157167405

Epoch: 5| Step: 9
Training loss: 2.5676800543805722
Validation loss: 2.623612843558714

Epoch: 5| Step: 10
Training loss: 2.7851164441788603
Validation loss: 2.647924700448294

Epoch: 87| Step: 0
Training loss: 3.1213821831679693
Validation loss: 2.7812278869273386

Epoch: 5| Step: 1
Training loss: 2.796953935415007
Validation loss: 2.8414170807282035

Epoch: 5| Step: 2
Training loss: 2.933230279788407
Validation loss: 2.6369795319891285

Epoch: 5| Step: 3
Training loss: 2.8547303879830284
Validation loss: 2.5350123976330496

Epoch: 5| Step: 4
Training loss: 3.179645509934662
Validation loss: 2.518687893695111

Epoch: 5| Step: 5
Training loss: 2.753291587682456
Validation loss: 2.543166295293021

Epoch: 5| Step: 6
Training loss: 3.03691798155979
Validation loss: 2.580468910089146

Epoch: 5| Step: 7
Training loss: 3.291777516361657
Validation loss: 2.60310909200051

Epoch: 5| Step: 8
Training loss: 3.197714203794703
Validation loss: 2.648251919674415

Epoch: 5| Step: 9
Training loss: 2.783276708868283
Validation loss: 2.6136838408893768

Epoch: 5| Step: 10
Training loss: 2.608568352378281
Validation loss: 2.575791514012244

Epoch: 88| Step: 0
Training loss: 2.524037576193183
Validation loss: 2.55766657105438

Epoch: 5| Step: 1
Training loss: 3.1670826755786146
Validation loss: 2.5470292717609673

Epoch: 5| Step: 2
Training loss: 3.1216562310930507
Validation loss: 2.5386868591352623

Epoch: 5| Step: 3
Training loss: 3.146468007988158
Validation loss: 2.5295076388296973

Epoch: 5| Step: 4
Training loss: 2.8846623138131586
Validation loss: 2.5207824820550115

Epoch: 5| Step: 5
Training loss: 2.9604166423270546
Validation loss: 2.517514382914242

Epoch: 5| Step: 6
Training loss: 2.375597928722665
Validation loss: 2.5263640559679157

Epoch: 5| Step: 7
Training loss: 2.7589087536259225
Validation loss: 2.5609885759863746

Epoch: 5| Step: 8
Training loss: 2.4617814811769287
Validation loss: 2.626054373318599

Epoch: 5| Step: 9
Training loss: 3.529324842298915
Validation loss: 2.6675638370744745

Epoch: 5| Step: 10
Training loss: 3.4182388286152747
Validation loss: 2.603843445110613

Epoch: 89| Step: 0
Training loss: 2.4134538494318476
Validation loss: 2.532498974075452

Epoch: 5| Step: 1
Training loss: 2.1641591184785822
Validation loss: 2.50745974379524

Epoch: 5| Step: 2
Training loss: 2.878417264697221
Validation loss: 2.5117430898437907

Epoch: 5| Step: 3
Training loss: 3.07984016771637
Validation loss: 2.517159407449423

Epoch: 5| Step: 4
Training loss: 3.1670599408802507
Validation loss: 2.5173520479662645

Epoch: 5| Step: 5
Training loss: 3.118476773144792
Validation loss: 2.5190341732260064

Epoch: 5| Step: 6
Training loss: 3.422808236842416
Validation loss: 2.52193503601575

Epoch: 5| Step: 7
Training loss: 2.5109848920032656
Validation loss: 2.5261274791096895

Epoch: 5| Step: 8
Training loss: 3.0514160746159815
Validation loss: 2.5254125926677

Epoch: 5| Step: 9
Training loss: 3.00352969742444
Validation loss: 2.5239663163829555

Epoch: 5| Step: 10
Training loss: 2.9488945587028317
Validation loss: 2.5210775402675734

Epoch: 90| Step: 0
Training loss: 2.9239916962741823
Validation loss: 2.5201817426938597

Epoch: 5| Step: 1
Training loss: 3.3934421350489803
Validation loss: 2.5145842592241565

Epoch: 5| Step: 2
Training loss: 2.755580961031683
Validation loss: 2.514779180721368

Epoch: 5| Step: 3
Training loss: 3.000995947504914
Validation loss: 2.5126244472685357

Epoch: 5| Step: 4
Training loss: 2.2657851590077525
Validation loss: 2.502950008655639

Epoch: 5| Step: 5
Training loss: 3.07956224377447
Validation loss: 2.5027388859253397

Epoch: 5| Step: 6
Training loss: 2.264483565513657
Validation loss: 2.5074076782769583

Epoch: 5| Step: 7
Training loss: 3.07350578911011
Validation loss: 2.5116739196507134

Epoch: 5| Step: 8
Training loss: 2.783354830706452
Validation loss: 2.540849739637645

Epoch: 5| Step: 9
Training loss: 3.0434900505714233
Validation loss: 2.549473877778898

Epoch: 5| Step: 10
Training loss: 3.1014565706780814
Validation loss: 2.5520057085465027

Epoch: 91| Step: 0
Training loss: 3.359961170244644
Validation loss: 2.5725427725971244

Epoch: 5| Step: 1
Training loss: 2.2488096055193783
Validation loss: 2.559305109717047

Epoch: 5| Step: 2
Training loss: 2.795966912009686
Validation loss: 2.558489036718711

Epoch: 5| Step: 3
Training loss: 2.879141436924966
Validation loss: 2.540848833582609

Epoch: 5| Step: 4
Training loss: 2.632283324538008
Validation loss: 2.513729817725872

Epoch: 5| Step: 5
Training loss: 2.752202799011586
Validation loss: 2.4964456106902158

Epoch: 5| Step: 6
Training loss: 3.0554051641579525
Validation loss: 2.4949353651293893

Epoch: 5| Step: 7
Training loss: 3.099011503559536
Validation loss: 2.4950209996955386

Epoch: 5| Step: 8
Training loss: 2.8178830659645384
Validation loss: 2.4919124120604033

Epoch: 5| Step: 9
Training loss: 2.906651294854257
Validation loss: 2.4963221527894444

Epoch: 5| Step: 10
Training loss: 2.898416771004885
Validation loss: 2.4959250669850013

Epoch: 92| Step: 0
Training loss: 3.5660893611783173
Validation loss: 2.4954893397302396

Epoch: 5| Step: 1
Training loss: 2.856106249908536
Validation loss: 2.499505350953026

Epoch: 5| Step: 2
Training loss: 2.4277907447070985
Validation loss: 2.5133897392751385

Epoch: 5| Step: 3
Training loss: 2.6615793955840963
Validation loss: 2.5241297443478166

Epoch: 5| Step: 4
Training loss: 3.298750935764332
Validation loss: 2.531934359277915

Epoch: 5| Step: 5
Training loss: 2.657390215123125
Validation loss: 2.55884006908021

Epoch: 5| Step: 6
Training loss: 2.6636436334475864
Validation loss: 2.575691882300307

Epoch: 5| Step: 7
Training loss: 2.3931938780354196
Validation loss: 2.5742817771620574

Epoch: 5| Step: 8
Training loss: 2.669113070159979
Validation loss: 2.538988391435219

Epoch: 5| Step: 9
Training loss: 2.9162455300150927
Validation loss: 2.532580283486932

Epoch: 5| Step: 10
Training loss: 3.1388505316297093
Validation loss: 2.5269832343492675

Epoch: 93| Step: 0
Training loss: 2.341872824104628
Validation loss: 2.5225591430931003

Epoch: 5| Step: 1
Training loss: 2.531224945321122
Validation loss: 2.5137370342114984

Epoch: 5| Step: 2
Training loss: 2.9556102487894145
Validation loss: 2.499239739315906

Epoch: 5| Step: 3
Training loss: 3.128397353717488
Validation loss: 2.4917704851520335

Epoch: 5| Step: 4
Training loss: 2.867329191194103
Validation loss: 2.491639119014252

Epoch: 5| Step: 5
Training loss: 2.414826207512208
Validation loss: 2.494051508513101

Epoch: 5| Step: 6
Training loss: 3.1334603797911966
Validation loss: 2.490954631354117

Epoch: 5| Step: 7
Training loss: 3.1692566235280424
Validation loss: 2.4911686936503226

Epoch: 5| Step: 8
Training loss: 2.8916076639478856
Validation loss: 2.490256343956173

Epoch: 5| Step: 9
Training loss: 3.0328055254439863
Validation loss: 2.4932169848318377

Epoch: 5| Step: 10
Training loss: 2.898707621446804
Validation loss: 2.492741083570101

Epoch: 94| Step: 0
Training loss: 3.3163457175258215
Validation loss: 2.4927165910938958

Epoch: 5| Step: 1
Training loss: 2.9174510082848326
Validation loss: 2.499174783752412

Epoch: 5| Step: 2
Training loss: 2.2240393547171253
Validation loss: 2.502118744872415

Epoch: 5| Step: 3
Training loss: 2.833652889706292
Validation loss: 2.5023928276207013

Epoch: 5| Step: 4
Training loss: 3.0844611777157995
Validation loss: 2.5063495531415776

Epoch: 5| Step: 5
Training loss: 2.5794193602126514
Validation loss: 2.5099213804760523

Epoch: 5| Step: 6
Training loss: 2.7632574950219833
Validation loss: 2.505889337134019

Epoch: 5| Step: 7
Training loss: 2.9088152977040718
Validation loss: 2.5102601385269496

Epoch: 5| Step: 8
Training loss: 2.616151519248738
Validation loss: 2.5035031580219087

Epoch: 5| Step: 9
Training loss: 3.337191415300956
Validation loss: 2.5073750064179134

Epoch: 5| Step: 10
Training loss: 2.599978953056245
Validation loss: 2.5128525197424456

Epoch: 95| Step: 0
Training loss: 2.9085003743846087
Validation loss: 2.506945477323918

Epoch: 5| Step: 1
Training loss: 2.7118201673968523
Validation loss: 2.5355033197682224

Epoch: 5| Step: 2
Training loss: 2.572447843477039
Validation loss: 2.546865172712908

Epoch: 5| Step: 3
Training loss: 2.8625012593495627
Validation loss: 2.553138446158686

Epoch: 5| Step: 4
Training loss: 3.1442437271500845
Validation loss: 2.5337515405519224

Epoch: 5| Step: 5
Training loss: 2.65815962420206
Validation loss: 2.5330962235551002

Epoch: 5| Step: 6
Training loss: 2.506266084462444
Validation loss: 2.5175316922944826

Epoch: 5| Step: 7
Training loss: 3.099073049949113
Validation loss: 2.5370594079007454

Epoch: 5| Step: 8
Training loss: 2.794139269990191
Validation loss: 2.525355853466231

Epoch: 5| Step: 9
Training loss: 3.130585523445174
Validation loss: 2.5248893387022098

Epoch: 5| Step: 10
Training loss: 2.9032950196510123
Validation loss: 2.5185319800506067

Epoch: 96| Step: 0
Training loss: 2.7042842429942047
Validation loss: 2.5091329349207485

Epoch: 5| Step: 1
Training loss: 2.8286014387402063
Validation loss: 2.5002861310408027

Epoch: 5| Step: 2
Training loss: 3.151214359479864
Validation loss: 2.4911394045037305

Epoch: 5| Step: 3
Training loss: 2.507470984096124
Validation loss: 2.4883626845111997

Epoch: 5| Step: 4
Training loss: 3.1314507090797385
Validation loss: 2.4921063355195514

Epoch: 5| Step: 5
Training loss: 3.249964787219096
Validation loss: 2.4836961485996656

Epoch: 5| Step: 6
Training loss: 2.426950955908012
Validation loss: 2.4936409162497517

Epoch: 5| Step: 7
Training loss: 2.9039463224152815
Validation loss: 2.4935612630981954

Epoch: 5| Step: 8
Training loss: 2.7285948778027915
Validation loss: 2.4919166156699486

Epoch: 5| Step: 9
Training loss: 2.72876010419344
Validation loss: 2.5002152309265173

Epoch: 5| Step: 10
Training loss: 2.932983009775598
Validation loss: 2.5242551439424474

Epoch: 97| Step: 0
Training loss: 2.9516121354783764
Validation loss: 2.5613881742236186

Epoch: 5| Step: 1
Training loss: 2.234884244067487
Validation loss: 2.6015167296354362

Epoch: 5| Step: 2
Training loss: 3.429050951303544
Validation loss: 2.6373378611096645

Epoch: 5| Step: 3
Training loss: 2.8336215901065493
Validation loss: 2.6115949036437134

Epoch: 5| Step: 4
Training loss: 3.0803165283052945
Validation loss: 2.544213802128243

Epoch: 5| Step: 5
Training loss: 2.9215294944766805
Validation loss: 2.496414677726439

Epoch: 5| Step: 6
Training loss: 2.5344284258948577
Validation loss: 2.494929861630349

Epoch: 5| Step: 7
Training loss: 3.3858635866611677
Validation loss: 2.4876145287276925

Epoch: 5| Step: 8
Training loss: 1.9896016411330109
Validation loss: 2.49470437624801

Epoch: 5| Step: 9
Training loss: 2.630776271626175
Validation loss: 2.499774346371001

Epoch: 5| Step: 10
Training loss: 3.265890448335986
Validation loss: 2.521985256516714

Epoch: 98| Step: 0
Training loss: 3.0505671114627337
Validation loss: 2.5150176690735417

Epoch: 5| Step: 1
Training loss: 3.0886438019425806
Validation loss: 2.5234148334417417

Epoch: 5| Step: 2
Training loss: 2.9760866761044653
Validation loss: 2.499173331226475

Epoch: 5| Step: 3
Training loss: 2.398495353473157
Validation loss: 2.4981730440795826

Epoch: 5| Step: 4
Training loss: 3.032246062236012
Validation loss: 2.4967119775354267

Epoch: 5| Step: 5
Training loss: 2.8755157671492646
Validation loss: 2.4935725531981507

Epoch: 5| Step: 6
Training loss: 2.595122743911979
Validation loss: 2.497741298247606

Epoch: 5| Step: 7
Training loss: 3.102201688996682
Validation loss: 2.5058095075652496

Epoch: 5| Step: 8
Training loss: 2.1679720491951247
Validation loss: 2.5078256881633396

Epoch: 5| Step: 9
Training loss: 2.7287833451781904
Validation loss: 2.5294693578608345

Epoch: 5| Step: 10
Training loss: 3.2353231173760877
Validation loss: 2.5319909859933767

Epoch: 99| Step: 0
Training loss: 2.903156233538424
Validation loss: 2.564105248649003

Epoch: 5| Step: 1
Training loss: 2.893076913548957
Validation loss: 2.541885270418186

Epoch: 5| Step: 2
Training loss: 2.551006499972674
Validation loss: 2.514500930335437

Epoch: 5| Step: 3
Training loss: 3.0441810631657433
Validation loss: 2.5044182180458354

Epoch: 5| Step: 4
Training loss: 2.865237370588925
Validation loss: 2.494232659389993

Epoch: 5| Step: 5
Training loss: 2.431837498305358
Validation loss: 2.4957600684314816

Epoch: 5| Step: 6
Training loss: 3.047235086144003
Validation loss: 2.4970857215829505

Epoch: 5| Step: 7
Training loss: 3.037929922062842
Validation loss: 2.4916934493411573

Epoch: 5| Step: 8
Training loss: 2.545344729655621
Validation loss: 2.495772846746299

Epoch: 5| Step: 9
Training loss: 3.2999233236941645
Validation loss: 2.4968468947528497

Epoch: 5| Step: 10
Training loss: 2.5001313175045117
Validation loss: 2.524122277253911

Epoch: 100| Step: 0
Training loss: 2.94941761281117
Validation loss: 2.5245160235912953

Epoch: 5| Step: 1
Training loss: 2.4187030324392573
Validation loss: 2.5391178137068398

Epoch: 5| Step: 2
Training loss: 2.6568200789908425
Validation loss: 2.5208929596041436

Epoch: 5| Step: 3
Training loss: 2.679600483451876
Validation loss: 2.532515162674313

Epoch: 5| Step: 4
Training loss: 2.8373639851374857
Validation loss: 2.5302347354797097

Epoch: 5| Step: 5
Training loss: 3.239076597235513
Validation loss: 2.532044788654255

Epoch: 5| Step: 6
Training loss: 2.57614725721511
Validation loss: 2.5169602834091287

Epoch: 5| Step: 7
Training loss: 2.7765080177745056
Validation loss: 2.5172554194396706

Epoch: 5| Step: 8
Training loss: 2.8393062203515926
Validation loss: 2.513815631983916

Epoch: 5| Step: 9
Training loss: 3.435009973503193
Validation loss: 2.5087980140106065

Epoch: 5| Step: 10
Training loss: 2.8047969871126175
Validation loss: 2.4953434585030707

Epoch: 101| Step: 0
Training loss: 2.7371662824835994
Validation loss: 2.49912450698925

Epoch: 5| Step: 1
Training loss: 3.1205537827851777
Validation loss: 2.4999181016202456

Epoch: 5| Step: 2
Training loss: 2.9887635882685766
Validation loss: 2.512507630974696

Epoch: 5| Step: 3
Training loss: 2.531841915293944
Validation loss: 2.539473691196045

Epoch: 5| Step: 4
Training loss: 2.7818442577753744
Validation loss: 2.588390837588825

Epoch: 5| Step: 5
Training loss: 2.382042932528645
Validation loss: 2.689265624846803

Epoch: 5| Step: 6
Training loss: 3.5198245587843697
Validation loss: 2.657418770716755

Epoch: 5| Step: 7
Training loss: 2.991727549607267
Validation loss: 2.613957098242439

Epoch: 5| Step: 8
Training loss: 2.2367786203593285
Validation loss: 2.4990681767741165

Epoch: 5| Step: 9
Training loss: 2.969932882661601
Validation loss: 2.4851580331494767

Epoch: 5| Step: 10
Training loss: 3.33506016506846
Validation loss: 2.498560299148515

Epoch: 102| Step: 0
Training loss: 2.2729536767377065
Validation loss: 2.5244924456517306

Epoch: 5| Step: 1
Training loss: 3.096554804472947
Validation loss: 2.5609825056995392

Epoch: 5| Step: 2
Training loss: 2.8399082265720423
Validation loss: 2.6042405293152004

Epoch: 5| Step: 3
Training loss: 3.1851822149113387
Validation loss: 2.602644036566689

Epoch: 5| Step: 4
Training loss: 3.4123680396643263
Validation loss: 2.5939204454911544

Epoch: 5| Step: 5
Training loss: 2.7810239378534334
Validation loss: 2.5780669015930253

Epoch: 5| Step: 6
Training loss: 2.8764886733677044
Validation loss: 2.5588255999450795

Epoch: 5| Step: 7
Training loss: 3.241159887506606
Validation loss: 2.5412649078873693

Epoch: 5| Step: 8
Training loss: 2.9650095615586602
Validation loss: 2.5323250605732404

Epoch: 5| Step: 9
Training loss: 3.3005473578837345
Validation loss: 2.525500971008843

Epoch: 5| Step: 10
Training loss: 2.2528351828832425
Validation loss: 2.520477573556517

Epoch: 103| Step: 0
Training loss: 2.9519452357290867
Validation loss: 2.5284193896112668

Epoch: 5| Step: 1
Training loss: 3.135919946641362
Validation loss: 2.5431609999970335

Epoch: 5| Step: 2
Training loss: 2.891486292186991
Validation loss: 2.570993916057193

Epoch: 5| Step: 3
Training loss: 2.7174682226490114
Validation loss: 2.6249437223574983

Epoch: 5| Step: 4
Training loss: 3.056466835614598
Validation loss: 2.7024995297266696

Epoch: 5| Step: 5
Training loss: 3.047901156827759
Validation loss: 2.7972583261729134

Epoch: 5| Step: 6
Training loss: 2.946858210429869
Validation loss: 2.766636609614583

Epoch: 5| Step: 7
Training loss: 3.1951068541518675
Validation loss: 2.659388687200558

Epoch: 5| Step: 8
Training loss: 2.3721870026168936
Validation loss: 2.541655141688993

Epoch: 5| Step: 9
Training loss: 2.8250436593792108
Validation loss: 2.507175749472754

Epoch: 5| Step: 10
Training loss: 3.040123604721101
Validation loss: 2.4928748885633727

Epoch: 104| Step: 0
Training loss: 3.0053275804755124
Validation loss: 2.490726895318909

Epoch: 5| Step: 1
Training loss: 2.49000506373737
Validation loss: 2.4913326415765176

Epoch: 5| Step: 2
Training loss: 3.154925984573909
Validation loss: 2.4924212071738894

Epoch: 5| Step: 3
Training loss: 2.9594721326023503
Validation loss: 2.4944347508462577

Epoch: 5| Step: 4
Training loss: 2.1444580955048913
Validation loss: 2.4952016887375583

Epoch: 5| Step: 5
Training loss: 2.702976994514296
Validation loss: 2.495604110195651

Epoch: 5| Step: 6
Training loss: 3.2500501775536037
Validation loss: 2.4971746722975965

Epoch: 5| Step: 7
Training loss: 3.0855823940266363
Validation loss: 2.4973906712731746

Epoch: 5| Step: 8
Training loss: 3.140516592403722
Validation loss: 2.496604405919294

Epoch: 5| Step: 9
Training loss: 2.913534571712085
Validation loss: 2.494372954910402

Epoch: 5| Step: 10
Training loss: 2.930708318247155
Validation loss: 2.495127994332619

Epoch: 105| Step: 0
Training loss: 3.000519071813639
Validation loss: 2.4930039910066673

Epoch: 5| Step: 1
Training loss: 2.8198686498799344
Validation loss: 2.4934135648828817

Epoch: 5| Step: 2
Training loss: 2.992328052855054
Validation loss: 2.490352494464323

Epoch: 5| Step: 3
Training loss: 2.475297478417278
Validation loss: 2.4942232701691456

Epoch: 5| Step: 4
Training loss: 2.8034138882554474
Validation loss: 2.489489216123235

Epoch: 5| Step: 5
Training loss: 3.0979588710746495
Validation loss: 2.484542699648602

Epoch: 5| Step: 6
Training loss: 2.4666289863629607
Validation loss: 2.4897232589567615

Epoch: 5| Step: 7
Training loss: 2.832212750110706
Validation loss: 2.496100226638497

Epoch: 5| Step: 8
Training loss: 3.1065136189342586
Validation loss: 2.5127736316825198

Epoch: 5| Step: 9
Training loss: 2.7930067366571034
Validation loss: 2.543879260198309

Epoch: 5| Step: 10
Training loss: 3.0546231860636905
Validation loss: 2.545830830722059

Epoch: 106| Step: 0
Training loss: 2.4228431981352494
Validation loss: 2.5378544455065293

Epoch: 5| Step: 1
Training loss: 3.2781998763065245
Validation loss: 2.5509177912635757

Epoch: 5| Step: 2
Training loss: 3.1727932507530214
Validation loss: 2.533723621900607

Epoch: 5| Step: 3
Training loss: 3.1034810548637073
Validation loss: 2.51772914298511

Epoch: 5| Step: 4
Training loss: 2.829526101053491
Validation loss: 2.4995304635793274

Epoch: 5| Step: 5
Training loss: 2.559132200468807
Validation loss: 2.494081339079831

Epoch: 5| Step: 6
Training loss: 2.2003469063607444
Validation loss: 2.4905697963786726

Epoch: 5| Step: 7
Training loss: 2.7457115374013075
Validation loss: 2.4823442030979757

Epoch: 5| Step: 8
Training loss: 2.941588134005519
Validation loss: 2.4817923579648973

Epoch: 5| Step: 9
Training loss: 3.144222798827556
Validation loss: 2.474163820878793

Epoch: 5| Step: 10
Training loss: 2.5812397954337296
Validation loss: 2.482768139633612

Epoch: 107| Step: 0
Training loss: 2.7824973406097784
Validation loss: 2.480312984796083

Epoch: 5| Step: 1
Training loss: 2.890257610996356
Validation loss: 2.4831186921817316

Epoch: 5| Step: 2
Training loss: 3.1622785649031457
Validation loss: 2.493084234726511

Epoch: 5| Step: 3
Training loss: 2.2286061327890536
Validation loss: 2.5027296254163134

Epoch: 5| Step: 4
Training loss: 2.9523340205375206
Validation loss: 2.5080155967724234

Epoch: 5| Step: 5
Training loss: 2.6946082922898
Validation loss: 2.522362286981014

Epoch: 5| Step: 6
Training loss: 2.684574575410402
Validation loss: 2.5373630517641566

Epoch: 5| Step: 7
Training loss: 2.9149425497004566
Validation loss: 2.5170605552599503

Epoch: 5| Step: 8
Training loss: 3.005142572610136
Validation loss: 2.502705833008426

Epoch: 5| Step: 9
Training loss: 3.1357916082897024
Validation loss: 2.5070799261469663

Epoch: 5| Step: 10
Training loss: 2.489542259824514
Validation loss: 2.5069646911679166

Epoch: 108| Step: 0
Training loss: 2.795626995888468
Validation loss: 2.4934569422741477

Epoch: 5| Step: 1
Training loss: 3.115444221723354
Validation loss: 2.5077451974765084

Epoch: 5| Step: 2
Training loss: 2.950487846511093
Validation loss: 2.4971223820670767

Epoch: 5| Step: 3
Training loss: 2.96425923452188
Validation loss: 2.512381305236704

Epoch: 5| Step: 4
Training loss: 2.3442409764063603
Validation loss: 2.524073295739031

Epoch: 5| Step: 5
Training loss: 2.610363984140853
Validation loss: 2.503357373076535

Epoch: 5| Step: 6
Training loss: 2.7228990662717854
Validation loss: 2.515750720597755

Epoch: 5| Step: 7
Training loss: 2.978996663255926
Validation loss: 2.5009486244469867

Epoch: 5| Step: 8
Training loss: 2.8553181202789233
Validation loss: 2.4908017460931813

Epoch: 5| Step: 9
Training loss: 3.0988350125092845
Validation loss: 2.496410544333781

Epoch: 5| Step: 10
Training loss: 2.380472704161417
Validation loss: 2.489610998702173

Epoch: 109| Step: 0
Training loss: 2.5635817500740528
Validation loss: 2.485806956999319

Epoch: 5| Step: 1
Training loss: 2.4585431758308247
Validation loss: 2.484052354774936

Epoch: 5| Step: 2
Training loss: 2.8289352015183464
Validation loss: 2.4904464671896367

Epoch: 5| Step: 3
Training loss: 2.880750130343929
Validation loss: 2.498772446934055

Epoch: 5| Step: 4
Training loss: 2.9312909023790383
Validation loss: 2.4876451465318885

Epoch: 5| Step: 5
Training loss: 2.7030814283089675
Validation loss: 2.501137829336217

Epoch: 5| Step: 6
Training loss: 2.2693663125172594
Validation loss: 2.517058123067057

Epoch: 5| Step: 7
Training loss: 2.8485700399644394
Validation loss: 2.516742453778303

Epoch: 5| Step: 8
Training loss: 3.1521225937950885
Validation loss: 2.524279614773714

Epoch: 5| Step: 9
Training loss: 3.085148268588134
Validation loss: 2.536868892958691

Epoch: 5| Step: 10
Training loss: 3.154637141815362
Validation loss: 2.553904375441439

Epoch: 110| Step: 0
Training loss: 3.4200604648710557
Validation loss: 2.5432526676448908

Epoch: 5| Step: 1
Training loss: 2.89482067890232
Validation loss: 2.538124699592459

Epoch: 5| Step: 2
Training loss: 2.5589212688455554
Validation loss: 2.5066325661671667

Epoch: 5| Step: 3
Training loss: 2.733362849781729
Validation loss: 2.4828185720772233

Epoch: 5| Step: 4
Training loss: 2.9782679520489186
Validation loss: 2.4802164812637195

Epoch: 5| Step: 5
Training loss: 2.968598693204244
Validation loss: 2.473311375910604

Epoch: 5| Step: 6
Training loss: 2.4116789769735263
Validation loss: 2.471812469100958

Epoch: 5| Step: 7
Training loss: 2.829371899299111
Validation loss: 2.4802065355997667

Epoch: 5| Step: 8
Training loss: 2.7974909098923226
Validation loss: 2.5105095210770028

Epoch: 5| Step: 9
Training loss: 2.5633137039041483
Validation loss: 2.511461562228025

Epoch: 5| Step: 10
Training loss: 2.737163233836183
Validation loss: 2.5136444691776405

Epoch: 111| Step: 0
Training loss: 2.5633872752307525
Validation loss: 2.5310736133530556

Epoch: 5| Step: 1
Training loss: 3.004642391411756
Validation loss: 2.550110358983432

Epoch: 5| Step: 2
Training loss: 2.772688643673916
Validation loss: 2.562388975197855

Epoch: 5| Step: 3
Training loss: 1.9979262926216526
Validation loss: 2.5160072019503197

Epoch: 5| Step: 4
Training loss: 3.0126019282528507
Validation loss: 2.5052313245966302

Epoch: 5| Step: 5
Training loss: 2.915783575883018
Validation loss: 2.505099239809069

Epoch: 5| Step: 6
Training loss: 3.0764904038955216
Validation loss: 2.510683450848484

Epoch: 5| Step: 7
Training loss: 2.7264900088579274
Validation loss: 2.5299419374104852

Epoch: 5| Step: 8
Training loss: 2.772174558397534
Validation loss: 2.5248334513144357

Epoch: 5| Step: 9
Training loss: 2.9479822661488857
Validation loss: 2.519284901551513

Epoch: 5| Step: 10
Training loss: 2.975551163082412
Validation loss: 2.5350045368393217

Epoch: 112| Step: 0
Training loss: 2.5436504522616734
Validation loss: 2.515834416711091

Epoch: 5| Step: 1
Training loss: 2.5330753102995036
Validation loss: 2.5075886964852114

Epoch: 5| Step: 2
Training loss: 2.990196581601058
Validation loss: 2.508921062366637

Epoch: 5| Step: 3
Training loss: 2.4195538626609716
Validation loss: 2.4899260911887353

Epoch: 5| Step: 4
Training loss: 3.1898555653559035
Validation loss: 2.495561964339239

Epoch: 5| Step: 5
Training loss: 3.295848957961929
Validation loss: 2.4951436661089366

Epoch: 5| Step: 6
Training loss: 2.53941882640923
Validation loss: 2.5053568218205053

Epoch: 5| Step: 7
Training loss: 2.877878323896923
Validation loss: 2.529254969268203

Epoch: 5| Step: 8
Training loss: 3.0334925270925375
Validation loss: 2.608233584319852

Epoch: 5| Step: 9
Training loss: 2.5759430871208973
Validation loss: 2.5784620495406014

Epoch: 5| Step: 10
Training loss: 2.6740356097307596
Validation loss: 2.5750369244835305

Epoch: 113| Step: 0
Training loss: 2.832465281934495
Validation loss: 2.521678739747275

Epoch: 5| Step: 1
Training loss: 2.930309016105743
Validation loss: 2.492107636830218

Epoch: 5| Step: 2
Training loss: 2.404350819358279
Validation loss: 2.4783736436139003

Epoch: 5| Step: 3
Training loss: 2.995022299911193
Validation loss: 2.477567447677904

Epoch: 5| Step: 4
Training loss: 2.9687332955944514
Validation loss: 2.480462537439105

Epoch: 5| Step: 5
Training loss: 2.85896306640423
Validation loss: 2.4817080333825596

Epoch: 5| Step: 6
Training loss: 2.6428258628908834
Validation loss: 2.479512080382991

Epoch: 5| Step: 7
Training loss: 2.7726602674139675
Validation loss: 2.487242717508755

Epoch: 5| Step: 8
Training loss: 2.9549491939921246
Validation loss: 2.483362793078385

Epoch: 5| Step: 9
Training loss: 2.8168706206868936
Validation loss: 2.505210692435908

Epoch: 5| Step: 10
Training loss: 2.7063796895515853
Validation loss: 2.5372103974970392

Epoch: 114| Step: 0
Training loss: 2.9165931329086145
Validation loss: 2.567807384589708

Epoch: 5| Step: 1
Training loss: 3.0053431295028203
Validation loss: 2.619420773781163

Epoch: 5| Step: 2
Training loss: 3.0437679783722924
Validation loss: 2.634165175402018

Epoch: 5| Step: 3
Training loss: 2.87172429433406
Validation loss: 2.6276274519208265

Epoch: 5| Step: 4
Training loss: 2.8529089688159672
Validation loss: 2.624323250805201

Epoch: 5| Step: 5
Training loss: 2.972031716948911
Validation loss: 2.5649907422425886

Epoch: 5| Step: 6
Training loss: 2.835210029047844
Validation loss: 2.5286549977485127

Epoch: 5| Step: 7
Training loss: 2.4454079508814335
Validation loss: 2.500715713187346

Epoch: 5| Step: 8
Training loss: 2.8508406888243756
Validation loss: 2.486036118230499

Epoch: 5| Step: 9
Training loss: 2.547285643628927
Validation loss: 2.4797381594355317

Epoch: 5| Step: 10
Training loss: 2.305653825322731
Validation loss: 2.4759961023330326

Epoch: 115| Step: 0
Training loss: 2.946801413854159
Validation loss: 2.476199315121647

Epoch: 5| Step: 1
Training loss: 3.5519036091879523
Validation loss: 2.4831503715088368

Epoch: 5| Step: 2
Training loss: 2.381077068787847
Validation loss: 2.4948683595109618

Epoch: 5| Step: 3
Training loss: 2.2976241155230137
Validation loss: 2.5056238313186707

Epoch: 5| Step: 4
Training loss: 2.426019088707757
Validation loss: 2.542835215770596

Epoch: 5| Step: 5
Training loss: 2.930136358844226
Validation loss: 2.5993351345179363

Epoch: 5| Step: 6
Training loss: 2.30796462005128
Validation loss: 2.640037883475548

Epoch: 5| Step: 7
Training loss: 2.602182675234959
Validation loss: 2.65984778258379

Epoch: 5| Step: 8
Training loss: 3.164351386551563
Validation loss: 2.7168449806363557

Epoch: 5| Step: 9
Training loss: 3.0021354704297574
Validation loss: 2.635066637124865

Epoch: 5| Step: 10
Training loss: 3.375933623985686
Validation loss: 2.5214920400315846

Epoch: 116| Step: 0
Training loss: 3.0830011618454556
Validation loss: 2.4815536631434436

Epoch: 5| Step: 1
Training loss: 2.4251295310751293
Validation loss: 2.479987675934397

Epoch: 5| Step: 2
Training loss: 2.8577405917390144
Validation loss: 2.4831227950462065

Epoch: 5| Step: 3
Training loss: 2.5092733056161562
Validation loss: 2.4842426329022467

Epoch: 5| Step: 4
Training loss: 2.767583638403118
Validation loss: 2.49224275752816

Epoch: 5| Step: 5
Training loss: 3.2538307794837937
Validation loss: 2.4953627437016936

Epoch: 5| Step: 6
Training loss: 2.894637503584973
Validation loss: 2.4957765251220625

Epoch: 5| Step: 7
Training loss: 3.0636210044247383
Validation loss: 2.501242932651696

Epoch: 5| Step: 8
Training loss: 3.0304787824700203
Validation loss: 2.529390307970316

Epoch: 5| Step: 9
Training loss: 2.5804967894317046
Validation loss: 2.52879077711446

Epoch: 5| Step: 10
Training loss: 2.2359793711753095
Validation loss: 2.544355196693018

Epoch: 117| Step: 0
Training loss: 3.2113056203881656
Validation loss: 2.557474580468699

Epoch: 5| Step: 1
Training loss: 2.974681029330258
Validation loss: 2.5486372792046694

Epoch: 5| Step: 2
Training loss: 2.8780372167199637
Validation loss: 2.5231326756069796

Epoch: 5| Step: 3
Training loss: 2.2240937048087193
Validation loss: 2.513919280320264

Epoch: 5| Step: 4
Training loss: 2.5601441323415832
Validation loss: 2.497543061842563

Epoch: 5| Step: 5
Training loss: 2.4755778476199177
Validation loss: 2.488789103276156

Epoch: 5| Step: 6
Training loss: 2.8959143830810574
Validation loss: 2.4855641889190787

Epoch: 5| Step: 7
Training loss: 2.6857177680001683
Validation loss: 2.483388708977864

Epoch: 5| Step: 8
Training loss: 2.4474283150606966
Validation loss: 2.48828270888415

Epoch: 5| Step: 9
Training loss: 3.1166072295806093
Validation loss: 2.5151422437772077

Epoch: 5| Step: 10
Training loss: 2.791901412507588
Validation loss: 2.5199761421036553

Epoch: 118| Step: 0
Training loss: 2.4937605243355616
Validation loss: 2.539268101902002

Epoch: 5| Step: 1
Training loss: 3.153228219708559
Validation loss: 2.5325185771273286

Epoch: 5| Step: 2
Training loss: 2.7772336956812342
Validation loss: 2.5245448351323505

Epoch: 5| Step: 3
Training loss: 2.558936642099849
Validation loss: 2.513707925417029

Epoch: 5| Step: 4
Training loss: 2.51958348419692
Validation loss: 2.519758141805565

Epoch: 5| Step: 5
Training loss: 3.1260773899605336
Validation loss: 2.5257726747884712

Epoch: 5| Step: 6
Training loss: 3.3515814222677527
Validation loss: 2.5347422567300537

Epoch: 5| Step: 7
Training loss: 2.6604088930769714
Validation loss: 2.526332068657332

Epoch: 5| Step: 8
Training loss: 2.290759190145557
Validation loss: 2.5050032091250163

Epoch: 5| Step: 9
Training loss: 2.416887624000822
Validation loss: 2.5097557841757983

Epoch: 5| Step: 10
Training loss: 2.6726281069534146
Validation loss: 2.510613343684556

Epoch: 119| Step: 0
Training loss: 2.581287271078149
Validation loss: 2.509839400329973

Epoch: 5| Step: 1
Training loss: 2.8969304775946214
Validation loss: 2.5030141206154677

Epoch: 5| Step: 2
Training loss: 2.280103421458954
Validation loss: 2.5111860268093986

Epoch: 5| Step: 3
Training loss: 3.4537383350419697
Validation loss: 2.507047042434179

Epoch: 5| Step: 4
Training loss: 2.580467870413584
Validation loss: 2.5148408829870577

Epoch: 5| Step: 5
Training loss: 2.882117872624515
Validation loss: 2.545311661444813

Epoch: 5| Step: 6
Training loss: 3.1104975068781857
Validation loss: 2.5688732935497867

Epoch: 5| Step: 7
Training loss: 2.4966977243906676
Validation loss: 2.5850733828913306

Epoch: 5| Step: 8
Training loss: 2.6347498797829205
Validation loss: 2.6083263215357975

Epoch: 5| Step: 9
Training loss: 2.621365892634297
Validation loss: 2.5585379765955545

Epoch: 5| Step: 10
Training loss: 2.5910679382168507
Validation loss: 2.522227988054987

Epoch: 120| Step: 0
Training loss: 2.642038181626796
Validation loss: 2.5110065385191973

Epoch: 5| Step: 1
Training loss: 3.0967345050927015
Validation loss: 2.531174106997091

Epoch: 5| Step: 2
Training loss: 2.9244158300038907
Validation loss: 2.5475949944980694

Epoch: 5| Step: 3
Training loss: 2.504907559575611
Validation loss: 2.5328153365483193

Epoch: 5| Step: 4
Training loss: 2.780457115738514
Validation loss: 2.5265364407302937

Epoch: 5| Step: 5
Training loss: 3.0777751898113928
Validation loss: 2.4985386812679162

Epoch: 5| Step: 6
Training loss: 2.444699341556231
Validation loss: 2.478953377067874

Epoch: 5| Step: 7
Training loss: 2.7094535173876895
Validation loss: 2.4889659599225307

Epoch: 5| Step: 8
Training loss: 2.8516962725471617
Validation loss: 2.48719603182428

Epoch: 5| Step: 9
Training loss: 2.4507393869576677
Validation loss: 2.5069621121507364

Epoch: 5| Step: 10
Training loss: 2.8365220657531283
Validation loss: 2.533225542054477

Epoch: 121| Step: 0
Training loss: 2.6436826620702254
Validation loss: 2.523108637672054

Epoch: 5| Step: 1
Training loss: 2.745761986955091
Validation loss: 2.512267198155745

Epoch: 5| Step: 2
Training loss: 2.884998020323499
Validation loss: 2.512847002433464

Epoch: 5| Step: 3
Training loss: 3.107778781652336
Validation loss: 2.5218930018546004

Epoch: 5| Step: 4
Training loss: 2.796818141252748
Validation loss: 2.524945991423413

Epoch: 5| Step: 5
Training loss: 2.6513940743054327
Validation loss: 2.5462386091585243

Epoch: 5| Step: 6
Training loss: 2.989178212503965
Validation loss: 2.573530077108213

Epoch: 5| Step: 7
Training loss: 2.462357175141574
Validation loss: 2.6012119415596513

Epoch: 5| Step: 8
Training loss: 2.605690004485395
Validation loss: 2.578181605558195

Epoch: 5| Step: 9
Training loss: 2.5571249436818877
Validation loss: 2.5448713032448516

Epoch: 5| Step: 10
Training loss: 2.5406180443850337
Validation loss: 2.513615290467859

Epoch: 122| Step: 0
Training loss: 2.764150538964346
Validation loss: 2.491268724485458

Epoch: 5| Step: 1
Training loss: 2.4976893236955306
Validation loss: 2.4831563920271322

Epoch: 5| Step: 2
Training loss: 3.466464827848389
Validation loss: 2.486408192366216

Epoch: 5| Step: 3
Training loss: 3.2275904756684186
Validation loss: 2.4849324740204026

Epoch: 5| Step: 4
Training loss: 2.467935741719453
Validation loss: 2.4869441176778833

Epoch: 5| Step: 5
Training loss: 2.450666714473526
Validation loss: 2.4861052005040887

Epoch: 5| Step: 6
Training loss: 2.799998409407028
Validation loss: 2.480236432422377

Epoch: 5| Step: 7
Training loss: 2.9024674606142127
Validation loss: 2.487118443048512

Epoch: 5| Step: 8
Training loss: 2.3900174634287477
Validation loss: 2.5027482380776567

Epoch: 5| Step: 9
Training loss: 2.492477256648182
Validation loss: 2.514097919776851

Epoch: 5| Step: 10
Training loss: 2.6775749042195436
Validation loss: 2.538612866341856

Epoch: 123| Step: 0
Training loss: 2.6749276017703982
Validation loss: 2.5688390202760156

Epoch: 5| Step: 1
Training loss: 2.4930906184100095
Validation loss: 2.609000312893042

Epoch: 5| Step: 2
Training loss: 3.167826055471577
Validation loss: 2.6677027626359187

Epoch: 5| Step: 3
Training loss: 3.3599061058185824
Validation loss: 2.671832657316418

Epoch: 5| Step: 4
Training loss: 3.1106296480867264
Validation loss: 2.5671188751857503

Epoch: 5| Step: 5
Training loss: 2.5818802736035034
Validation loss: 2.524128492047021

Epoch: 5| Step: 6
Training loss: 2.11547038698038
Validation loss: 2.5057458282841716

Epoch: 5| Step: 7
Training loss: 2.6862759131188643
Validation loss: 2.5085755503088345

Epoch: 5| Step: 8
Training loss: 2.8785908706154517
Validation loss: 2.4953771929914486

Epoch: 5| Step: 9
Training loss: 2.3493134652350185
Validation loss: 2.4941174218604822

Epoch: 5| Step: 10
Training loss: 2.770119931348012
Validation loss: 2.4970414488316357

Epoch: 124| Step: 0
Training loss: 2.4874783692306024
Validation loss: 2.502347209351071

Epoch: 5| Step: 1
Training loss: 3.037073891975199
Validation loss: 2.5130217558824923

Epoch: 5| Step: 2
Training loss: 2.9984435176341715
Validation loss: 2.5183796695395584

Epoch: 5| Step: 3
Training loss: 2.7936435551174594
Validation loss: 2.519379316364168

Epoch: 5| Step: 4
Training loss: 2.7336527715276424
Validation loss: 2.5544333653762097

Epoch: 5| Step: 5
Training loss: 2.555471784029506
Validation loss: 2.5869238080090944

Epoch: 5| Step: 6
Training loss: 3.273834277303013
Validation loss: 2.6026573982463748

Epoch: 5| Step: 7
Training loss: 2.9433196836553233
Validation loss: 2.619796110660037

Epoch: 5| Step: 8
Training loss: 2.561223340098198
Validation loss: 2.580284596834379

Epoch: 5| Step: 9
Training loss: 2.2979955729416184
Validation loss: 2.518046384746507

Epoch: 5| Step: 10
Training loss: 2.0431262916521185
Validation loss: 2.4944158125335583

Epoch: 125| Step: 0
Training loss: 3.1411402644986874
Validation loss: 2.480054883574548

Epoch: 5| Step: 1
Training loss: 2.595974714940724
Validation loss: 2.481997406255307

Epoch: 5| Step: 2
Training loss: 2.7408696238348953
Validation loss: 2.4838986906638816

Epoch: 5| Step: 3
Training loss: 2.462350203706979
Validation loss: 2.488931522587769

Epoch: 5| Step: 4
Training loss: 3.1173543861478836
Validation loss: 2.502608021781653

Epoch: 5| Step: 5
Training loss: 2.7880755048513217
Validation loss: 2.531219895463747

Epoch: 5| Step: 6
Training loss: 2.628114396843857
Validation loss: 2.5591021354199235

Epoch: 5| Step: 7
Training loss: 2.705705414350499
Validation loss: 2.6243096462944604

Epoch: 5| Step: 8
Training loss: 2.3431872900342343
Validation loss: 2.623750812291767

Epoch: 5| Step: 9
Training loss: 2.8106850596078847
Validation loss: 2.596127388786073

Epoch: 5| Step: 10
Training loss: 2.7543812443589073
Validation loss: 2.5581612059865866

Epoch: 126| Step: 0
Training loss: 2.5420244517497186
Validation loss: 2.527457669377734

Epoch: 5| Step: 1
Training loss: 3.365608429225978
Validation loss: 2.512518418106358

Epoch: 5| Step: 2
Training loss: 2.8302759242255826
Validation loss: 2.51088226606992

Epoch: 5| Step: 3
Training loss: 2.4942231190779465
Validation loss: 2.5145089612591063

Epoch: 5| Step: 4
Training loss: 2.632195737233249
Validation loss: 2.539568953444912

Epoch: 5| Step: 5
Training loss: 2.6978916378161286
Validation loss: 2.5280618921122215

Epoch: 5| Step: 6
Training loss: 2.409541863230772
Validation loss: 2.5259645092294107

Epoch: 5| Step: 7
Training loss: 2.593528646192875
Validation loss: 2.5395016162883977

Epoch: 5| Step: 8
Training loss: 2.6326167093255743
Validation loss: 2.5524093466576465

Epoch: 5| Step: 9
Training loss: 3.0191880755323957
Validation loss: 2.5540170609246933

Epoch: 5| Step: 10
Training loss: 2.6011454846541024
Validation loss: 2.5559950128650724

Epoch: 127| Step: 0
Training loss: 2.4548103714560825
Validation loss: 2.5368964243170042

Epoch: 5| Step: 1
Training loss: 2.3058389147419915
Validation loss: 2.524747409408716

Epoch: 5| Step: 2
Training loss: 2.414074548981359
Validation loss: 2.5182558133723063

Epoch: 5| Step: 3
Training loss: 2.8183140318164677
Validation loss: 2.506623045435521

Epoch: 5| Step: 4
Training loss: 2.8443874441170944
Validation loss: 2.5121642011029763

Epoch: 5| Step: 5
Training loss: 2.7558711407881367
Validation loss: 2.5216801874428754

Epoch: 5| Step: 6
Training loss: 2.805076720876572
Validation loss: 2.525818024251806

Epoch: 5| Step: 7
Training loss: 2.4190219933218478
Validation loss: 2.521346001871192

Epoch: 5| Step: 8
Training loss: 2.946428406290157
Validation loss: 2.539934151514312

Epoch: 5| Step: 9
Training loss: 3.0780472334124704
Validation loss: 2.5441962923825674

Epoch: 5| Step: 10
Training loss: 2.759712234920132
Validation loss: 2.552908598261948

Epoch: 128| Step: 0
Training loss: 2.698506196367445
Validation loss: 2.5816544255059037

Epoch: 5| Step: 1
Training loss: 2.716133612620194
Validation loss: 2.5877467840846684

Epoch: 5| Step: 2
Training loss: 1.80675635714618
Validation loss: 2.6022514385184077

Epoch: 5| Step: 3
Training loss: 2.704855040017136
Validation loss: 2.629296318882415

Epoch: 5| Step: 4
Training loss: 2.5832641243636636
Validation loss: 2.625358788483252

Epoch: 5| Step: 5
Training loss: 2.615627176700903
Validation loss: 2.5631458440021015

Epoch: 5| Step: 6
Training loss: 2.7995636020908865
Validation loss: 2.5360879325459695

Epoch: 5| Step: 7
Training loss: 3.1588913846424447
Validation loss: 2.530658184321184

Epoch: 5| Step: 8
Training loss: 3.106817525985475
Validation loss: 2.5233404969584456

Epoch: 5| Step: 9
Training loss: 2.800254953221144
Validation loss: 2.526357845659494

Epoch: 5| Step: 10
Training loss: 2.450099756195167
Validation loss: 2.5375736770428725

Epoch: 129| Step: 0
Training loss: 3.0450426118121015
Validation loss: 2.5239288157575324

Epoch: 5| Step: 1
Training loss: 2.3022538088915003
Validation loss: 2.5370203188056326

Epoch: 5| Step: 2
Training loss: 2.5204544623373595
Validation loss: 2.576864822178691

Epoch: 5| Step: 3
Training loss: 2.6409410817956296
Validation loss: 2.614427008272051

Epoch: 5| Step: 4
Training loss: 2.2070119131135755
Validation loss: 2.671146977995099

Epoch: 5| Step: 5
Training loss: 2.4380958024589137
Validation loss: 2.7574995257739494

Epoch: 5| Step: 6
Training loss: 2.636977978431775
Validation loss: 2.730749765595895

Epoch: 5| Step: 7
Training loss: 2.7930290162313485
Validation loss: 2.699917229751372

Epoch: 5| Step: 8
Training loss: 2.8008822924318597
Validation loss: 2.58722545666721

Epoch: 5| Step: 9
Training loss: 2.9228709762239493
Validation loss: 2.5207125733903375

Epoch: 5| Step: 10
Training loss: 3.4100917884353494
Validation loss: 2.5077950744667525

Epoch: 130| Step: 0
Training loss: 2.4871202571984914
Validation loss: 2.49976581276469

Epoch: 5| Step: 1
Training loss: 2.8760578033941453
Validation loss: 2.499171263221989

Epoch: 5| Step: 2
Training loss: 2.320882399729207
Validation loss: 2.484656664354419

Epoch: 5| Step: 3
Training loss: 2.5626726790141627
Validation loss: 2.4813659197852442

Epoch: 5| Step: 4
Training loss: 3.0988724042161375
Validation loss: 2.4763507860568525

Epoch: 5| Step: 5
Training loss: 2.7521413788797338
Validation loss: 2.473465758391637

Epoch: 5| Step: 6
Training loss: 2.5694005212093955
Validation loss: 2.485218004391435

Epoch: 5| Step: 7
Training loss: 3.0581918113734083
Validation loss: 2.5003264767757267

Epoch: 5| Step: 8
Training loss: 3.086969825846776
Validation loss: 2.5241253039078027

Epoch: 5| Step: 9
Training loss: 3.01477766238867
Validation loss: 2.563248713792427

Epoch: 5| Step: 10
Training loss: 2.042927320362964
Validation loss: 2.578111896003044

Epoch: 131| Step: 0
Training loss: 2.5052256329124845
Validation loss: 2.601079710061482

Epoch: 5| Step: 1
Training loss: 2.9444144825240657
Validation loss: 2.6176702131065195

Epoch: 5| Step: 2
Training loss: 2.813544693942503
Validation loss: 2.637500589962899

Epoch: 5| Step: 3
Training loss: 2.7991524912354193
Validation loss: 2.671473140608453

Epoch: 5| Step: 4
Training loss: 2.8644763903451405
Validation loss: 2.702249592333648

Epoch: 5| Step: 5
Training loss: 2.6349919294780215
Validation loss: 2.697263639490227

Epoch: 5| Step: 6
Training loss: 2.5886174171053384
Validation loss: 2.625327288630316

Epoch: 5| Step: 7
Training loss: 2.277502666182899
Validation loss: 2.566261587977555

Epoch: 5| Step: 8
Training loss: 2.8881705095989556
Validation loss: 2.5257868978400686

Epoch: 5| Step: 9
Training loss: 2.4880695821899943
Validation loss: 2.49509399344203

Epoch: 5| Step: 10
Training loss: 2.9512111375924803
Validation loss: 2.486584305928287

Epoch: 132| Step: 0
Training loss: 2.478560547237453
Validation loss: 2.4772447716551382

Epoch: 5| Step: 1
Training loss: 2.9961793730635167
Validation loss: 2.4929936150955436

Epoch: 5| Step: 2
Training loss: 3.1041743813915947
Validation loss: 2.4957208907787423

Epoch: 5| Step: 3
Training loss: 2.144854411806419
Validation loss: 2.4984346154739034

Epoch: 5| Step: 4
Training loss: 2.696347068485975
Validation loss: 2.508167251849173

Epoch: 5| Step: 5
Training loss: 2.5748746785898367
Validation loss: 2.543774162920079

Epoch: 5| Step: 6
Training loss: 2.4793933369425076
Validation loss: 2.5753760296138015

Epoch: 5| Step: 7
Training loss: 2.90697511220487
Validation loss: 2.6142162100714406

Epoch: 5| Step: 8
Training loss: 3.119022909390336
Validation loss: 2.750658134581883

Epoch: 5| Step: 9
Training loss: 2.70254757397301
Validation loss: 2.7744959986882622

Epoch: 5| Step: 10
Training loss: 2.6981606293376537
Validation loss: 2.7975125883355596

Epoch: 133| Step: 0
Training loss: 2.8741233152455017
Validation loss: 2.713337057716337

Epoch: 5| Step: 1
Training loss: 2.7670246612696134
Validation loss: 2.586226189909952

Epoch: 5| Step: 2
Training loss: 2.887629591110422
Validation loss: 2.5145554406053994

Epoch: 5| Step: 3
Training loss: 2.438384458049794
Validation loss: 2.511620302228904

Epoch: 5| Step: 4
Training loss: 2.988028003209044
Validation loss: 2.524630155863052

Epoch: 5| Step: 5
Training loss: 2.6848318472834114
Validation loss: 2.544523121436777

Epoch: 5| Step: 6
Training loss: 2.744153657386758
Validation loss: 2.555412090124307

Epoch: 5| Step: 7
Training loss: 2.6885711841719235
Validation loss: 2.555864107118741

Epoch: 5| Step: 8
Training loss: 3.030308528085981
Validation loss: 2.539161246803581

Epoch: 5| Step: 9
Training loss: 2.8822169735495606
Validation loss: 2.529307941224572

Epoch: 5| Step: 10
Training loss: 2.793565977039474
Validation loss: 2.5434607802633304

Epoch: 134| Step: 0
Training loss: 2.321969927032005
Validation loss: 2.572482144409118

Epoch: 5| Step: 1
Training loss: 2.3020211005681372
Validation loss: 2.5998605249793068

Epoch: 5| Step: 2
Training loss: 2.6520922264874973
Validation loss: 2.6248619973061147

Epoch: 5| Step: 3
Training loss: 3.3365174979733325
Validation loss: 2.6349086042336296

Epoch: 5| Step: 4
Training loss: 2.706685097761619
Validation loss: 2.6357353264554466

Epoch: 5| Step: 5
Training loss: 2.1164237471230742
Validation loss: 2.664281196965244

Epoch: 5| Step: 6
Training loss: 1.9396245444645672
Validation loss: 2.6684265373355105

Epoch: 5| Step: 7
Training loss: 2.9309097385362755
Validation loss: 2.64914699310693

Epoch: 5| Step: 8
Training loss: 2.7739646732965992
Validation loss: 2.6332025291089916

Epoch: 5| Step: 9
Training loss: 2.6729224756246603
Validation loss: 2.637712813885985

Epoch: 5| Step: 10
Training loss: 3.3810297472958752
Validation loss: 2.5883962978677406

Epoch: 135| Step: 0
Training loss: 2.8832693177395283
Validation loss: 2.550448985809777

Epoch: 5| Step: 1
Training loss: 1.8516109154403184
Validation loss: 2.4959673268824445

Epoch: 5| Step: 2
Training loss: 2.8148896979341207
Validation loss: 2.4772784566330226

Epoch: 5| Step: 3
Training loss: 2.7890969496023272
Validation loss: 2.4817307595997384

Epoch: 5| Step: 4
Training loss: 3.05467641686968
Validation loss: 2.469686958372606

Epoch: 5| Step: 5
Training loss: 1.9436863609763744
Validation loss: 2.488639049202256

Epoch: 5| Step: 6
Training loss: 2.724706154475169
Validation loss: 2.529006422505282

Epoch: 5| Step: 7
Training loss: 2.423831272661131
Validation loss: 2.5584127332524615

Epoch: 5| Step: 8
Training loss: 2.6911426077330516
Validation loss: 2.584364814796261

Epoch: 5| Step: 9
Training loss: 2.8029925396942796
Validation loss: 2.5860709944769344

Epoch: 5| Step: 10
Training loss: 3.250726031856867
Validation loss: 2.587984116936324

Epoch: 136| Step: 0
Training loss: 2.1612193025225808
Validation loss: 2.5688965958813927

Epoch: 5| Step: 1
Training loss: 2.884271185464583
Validation loss: 2.5644509466894423

Epoch: 5| Step: 2
Training loss: 2.575929481376321
Validation loss: 2.555289786648139

Epoch: 5| Step: 3
Training loss: 2.609377741098392
Validation loss: 2.575331756895569

Epoch: 5| Step: 4
Training loss: 2.152796315212491
Validation loss: 2.6177227650188883

Epoch: 5| Step: 5
Training loss: 2.9212544644166183
Validation loss: 2.634541011772155

Epoch: 5| Step: 6
Training loss: 3.519360537098734
Validation loss: 2.6269800460088018

Epoch: 5| Step: 7
Training loss: 2.6207447075426935
Validation loss: 2.6148007667755566

Epoch: 5| Step: 8
Training loss: 2.7007734179969423
Validation loss: 2.6426049663819833

Epoch: 5| Step: 9
Training loss: 1.9173839166907536
Validation loss: 2.610938689494618

Epoch: 5| Step: 10
Training loss: 2.6286846821388776
Validation loss: 2.603004431167003

Epoch: 137| Step: 0
Training loss: 2.877686613578984
Validation loss: 2.5830924308491015

Epoch: 5| Step: 1
Training loss: 2.0608176103242277
Validation loss: 2.551686045847285

Epoch: 5| Step: 2
Training loss: 2.4274438636645495
Validation loss: 2.570085702208277

Epoch: 5| Step: 3
Training loss: 3.0231526558529622
Validation loss: 2.5815877630525166

Epoch: 5| Step: 4
Training loss: 2.2969033375763095
Validation loss: 2.574793837565951

Epoch: 5| Step: 5
Training loss: 2.3300462002737534
Validation loss: 2.5789821478901893

Epoch: 5| Step: 6
Training loss: 2.8654493837613737
Validation loss: 2.5839933299226785

Epoch: 5| Step: 7
Training loss: 2.640815953680718
Validation loss: 2.62462869509491

Epoch: 5| Step: 8
Training loss: 2.4749047540390197
Validation loss: 2.6318179060894193

Epoch: 5| Step: 9
Training loss: 3.013556527027385
Validation loss: 2.657239519471859

Epoch: 5| Step: 10
Training loss: 2.5215674873441722
Validation loss: 2.658510930792138

Epoch: 138| Step: 0
Training loss: 2.3057567120574003
Validation loss: 2.6622466775688745

Epoch: 5| Step: 1
Training loss: 2.735599439857583
Validation loss: 2.6061785526652863

Epoch: 5| Step: 2
Training loss: 2.632873081676192
Validation loss: 2.5952762363932838

Epoch: 5| Step: 3
Training loss: 1.8406741461159184
Validation loss: 2.5646648691478364

Epoch: 5| Step: 4
Training loss: 2.626369482388192
Validation loss: 2.5625951225579526

Epoch: 5| Step: 5
Training loss: 2.9002124050884457
Validation loss: 2.5555706782411485

Epoch: 5| Step: 6
Training loss: 2.6060830554506005
Validation loss: 2.572301984416287

Epoch: 5| Step: 7
Training loss: 2.5907426427765987
Validation loss: 2.5800260612921644

Epoch: 5| Step: 8
Training loss: 2.8761740236223807
Validation loss: 2.6108620493267787

Epoch: 5| Step: 9
Training loss: 2.62507502130752
Validation loss: 2.610050753751114

Epoch: 5| Step: 10
Training loss: 2.7267628243643953
Validation loss: 2.6046385588967587

Epoch: 139| Step: 0
Training loss: 2.0595550319490044
Validation loss: 2.605106318773978

Epoch: 5| Step: 1
Training loss: 3.0100015180210073
Validation loss: 2.593368533850609

Epoch: 5| Step: 2
Training loss: 2.7142326270913637
Validation loss: 2.586528703926986

Epoch: 5| Step: 3
Training loss: 1.9126189101408746
Validation loss: 2.573264126239406

Epoch: 5| Step: 4
Training loss: 2.3252347889144187
Validation loss: 2.563359025283208

Epoch: 5| Step: 5
Training loss: 2.6902664495056876
Validation loss: 2.5843566934355535

Epoch: 5| Step: 6
Training loss: 2.3945227867088916
Validation loss: 2.631247332389901

Epoch: 5| Step: 7
Training loss: 2.8504935991596434
Validation loss: 2.6509147401072277

Epoch: 5| Step: 8
Training loss: 2.9072608420363135
Validation loss: 2.6251775795776546

Epoch: 5| Step: 9
Training loss: 2.5979893062157093
Validation loss: 2.631146038642894

Epoch: 5| Step: 10
Training loss: 2.6016223430910483
Validation loss: 2.6538591090367283

Epoch: 140| Step: 0
Training loss: 2.254392151710489
Validation loss: 2.619985187048401

Epoch: 5| Step: 1
Training loss: 2.238857760921608
Validation loss: 2.5935316630196525

Epoch: 5| Step: 2
Training loss: 3.131232036607577
Validation loss: 2.5649392218574127

Epoch: 5| Step: 3
Training loss: 2.932588082345997
Validation loss: 2.5476620875506786

Epoch: 5| Step: 4
Training loss: 2.722172128990655
Validation loss: 2.5484351130837806

Epoch: 5| Step: 5
Training loss: 2.7574193744510285
Validation loss: 2.5663102217951907

Epoch: 5| Step: 6
Training loss: 2.1868505331209596
Validation loss: 2.599974149144775

Epoch: 5| Step: 7
Training loss: 2.0765718091034167
Validation loss: 2.6402652925322854

Epoch: 5| Step: 8
Training loss: 2.737658725125827
Validation loss: 2.645766438504201

Epoch: 5| Step: 9
Training loss: 2.651020691994143
Validation loss: 2.6258554270930023

Epoch: 5| Step: 10
Training loss: 2.362336479058245
Validation loss: 2.604985497159749

Epoch: 141| Step: 0
Training loss: 2.275491003351903
Validation loss: 2.5590728764548167

Epoch: 5| Step: 1
Training loss: 2.2581022400056114
Validation loss: 2.566595309074889

Epoch: 5| Step: 2
Training loss: 2.418082929389677
Validation loss: 2.555092171315945

Epoch: 5| Step: 3
Training loss: 2.645689312076374
Validation loss: 2.574338068888732

Epoch: 5| Step: 4
Training loss: 2.7517227498775387
Validation loss: 2.5633415323019615

Epoch: 5| Step: 5
Training loss: 2.9859499944548245
Validation loss: 2.590270714418137

Epoch: 5| Step: 6
Training loss: 2.5417629494695975
Validation loss: 2.620706516938693

Epoch: 5| Step: 7
Training loss: 1.9978812438985656
Validation loss: 2.6116785388384587

Epoch: 5| Step: 8
Training loss: 2.53400186785815
Validation loss: 2.597330594272706

Epoch: 5| Step: 9
Training loss: 2.9549596829576665
Validation loss: 2.6053122171953613

Epoch: 5| Step: 10
Training loss: 2.6706013460225475
Validation loss: 2.5994234508365492

Epoch: 142| Step: 0
Training loss: 2.757200870284775
Validation loss: 2.6068825585879027

Epoch: 5| Step: 1
Training loss: 2.233921351763638
Validation loss: 2.6018568391813397

Epoch: 5| Step: 2
Training loss: 3.0428798990658765
Validation loss: 2.5967033375990303

Epoch: 5| Step: 3
Training loss: 2.3236567482954373
Validation loss: 2.604338967478645

Epoch: 5| Step: 4
Training loss: 2.6482425044020386
Validation loss: 2.6134607735410613

Epoch: 5| Step: 5
Training loss: 2.696851031394702
Validation loss: 2.6243395123353332

Epoch: 5| Step: 6
Training loss: 1.966513862438793
Validation loss: 2.6270705581438603

Epoch: 5| Step: 7
Training loss: 2.435218623723712
Validation loss: 2.646509873879944

Epoch: 5| Step: 8
Training loss: 2.6327146970428434
Validation loss: 2.6534087821822627

Epoch: 5| Step: 9
Training loss: 2.467393719858837
Validation loss: 2.640089823132288

Epoch: 5| Step: 10
Training loss: 2.7984519221170103
Validation loss: 2.5898040801607225

Epoch: 143| Step: 0
Training loss: 2.74996202616049
Validation loss: 2.51959944239503

Epoch: 5| Step: 1
Training loss: 3.2690563517859927
Validation loss: 2.4967814266956143

Epoch: 5| Step: 2
Training loss: 2.6616479217627242
Validation loss: 2.4937115129059695

Epoch: 5| Step: 3
Training loss: 3.1464657347853358
Validation loss: 2.4929289071011334

Epoch: 5| Step: 4
Training loss: 2.111519408758066
Validation loss: 2.482103453299384

Epoch: 5| Step: 5
Training loss: 2.85714584759147
Validation loss: 2.481092586138871

Epoch: 5| Step: 6
Training loss: 2.241724903621777
Validation loss: 2.4973355050667045

Epoch: 5| Step: 7
Training loss: 2.646425726546874
Validation loss: 2.5165689819880144

Epoch: 5| Step: 8
Training loss: 2.6606966385663036
Validation loss: 2.5247021158559773

Epoch: 5| Step: 9
Training loss: 2.3856601396490658
Validation loss: 2.559362113485772

Epoch: 5| Step: 10
Training loss: 2.1936117623184233
Validation loss: 2.5615565035945878

Epoch: 144| Step: 0
Training loss: 2.631225469841863
Validation loss: 2.5650313255487145

Epoch: 5| Step: 1
Training loss: 2.767457516558661
Validation loss: 2.5742334582684325

Epoch: 5| Step: 2
Training loss: 2.255520934772015
Validation loss: 2.5868799677942937

Epoch: 5| Step: 3
Training loss: 2.532137303189657
Validation loss: 2.5959405436999194

Epoch: 5| Step: 4
Training loss: 2.7974150578452557
Validation loss: 2.638089631662914

Epoch: 5| Step: 5
Training loss: 2.2515160433379555
Validation loss: 2.697171930917284

Epoch: 5| Step: 6
Training loss: 2.6084462414598812
Validation loss: 2.745181061175696

Epoch: 5| Step: 7
Training loss: 2.439647217871563
Validation loss: 2.744485070268307

Epoch: 5| Step: 8
Training loss: 2.830010728579832
Validation loss: 2.6745767769779034

Epoch: 5| Step: 9
Training loss: 2.708570078748283
Validation loss: 2.627252874760113

Epoch: 5| Step: 10
Training loss: 2.37927333461281
Validation loss: 2.5861185430140448

Epoch: 145| Step: 0
Training loss: 1.9764179282409233
Validation loss: 2.566773073033421

Epoch: 5| Step: 1
Training loss: 2.5753376082048214
Validation loss: 2.533629797274936

Epoch: 5| Step: 2
Training loss: 2.673195585077508
Validation loss: 2.516585471197528

Epoch: 5| Step: 3
Training loss: 2.9337905838072746
Validation loss: 2.5450234597215977

Epoch: 5| Step: 4
Training loss: 2.9890284183870337
Validation loss: 2.5356167926823487

Epoch: 5| Step: 5
Training loss: 2.0168455701347026
Validation loss: 2.5639448806968814

Epoch: 5| Step: 6
Training loss: 2.5019195816447772
Validation loss: 2.5891170486580624

Epoch: 5| Step: 7
Training loss: 2.876764999630339
Validation loss: 2.6285391113904057

Epoch: 5| Step: 8
Training loss: 1.86319871635704
Validation loss: 2.655227502938179

Epoch: 5| Step: 9
Training loss: 2.5463906043984017
Validation loss: 2.652190608200815

Epoch: 5| Step: 10
Training loss: 2.8011329674774914
Validation loss: 2.6801376445426777

Epoch: 146| Step: 0
Training loss: 2.4353727203485347
Validation loss: 2.6774074325859463

Epoch: 5| Step: 1
Training loss: 2.0206097613537906
Validation loss: 2.6528600903932618

Epoch: 5| Step: 2
Training loss: 3.0683122870451958
Validation loss: 2.645989068909281

Epoch: 5| Step: 3
Training loss: 2.454018788397137
Validation loss: 2.627447429835258

Epoch: 5| Step: 4
Training loss: 2.287264694034911
Validation loss: 2.6137275708907444

Epoch: 5| Step: 5
Training loss: 2.4435824285552643
Validation loss: 2.589762083417935

Epoch: 5| Step: 6
Training loss: 2.3992822010788597
Validation loss: 2.582531794413556

Epoch: 5| Step: 7
Training loss: 2.172424905442671
Validation loss: 2.5549031179463686

Epoch: 5| Step: 8
Training loss: 2.6862408549355914
Validation loss: 2.5438166226021437

Epoch: 5| Step: 9
Training loss: 3.0476533335789364
Validation loss: 2.5506067326698543

Epoch: 5| Step: 10
Training loss: 2.683565764302084
Validation loss: 2.5659792340947156

Epoch: 147| Step: 0
Training loss: 2.496858530384121
Validation loss: 2.603718974034492

Epoch: 5| Step: 1
Training loss: 2.170401423193201
Validation loss: 2.6502453643021173

Epoch: 5| Step: 2
Training loss: 2.8037201214583125
Validation loss: 2.6690456692589954

Epoch: 5| Step: 3
Training loss: 2.467968684308473
Validation loss: 2.703997187066816

Epoch: 5| Step: 4
Training loss: 2.3010040330781036
Validation loss: 2.6394393112264356

Epoch: 5| Step: 5
Training loss: 2.1935956764824107
Validation loss: 2.596196583014933

Epoch: 5| Step: 6
Training loss: 2.695684523408415
Validation loss: 2.574420154053657

Epoch: 5| Step: 7
Training loss: 2.362788680266438
Validation loss: 2.548441423504522

Epoch: 5| Step: 8
Training loss: 2.287202776167133
Validation loss: 2.5277354914770958

Epoch: 5| Step: 9
Training loss: 2.8455385724772833
Validation loss: 2.520410389523666

Epoch: 5| Step: 10
Training loss: 2.946515148922053
Validation loss: 2.5228292024810637

Epoch: 148| Step: 0
Training loss: 2.831166018152038
Validation loss: 2.537204677519693

Epoch: 5| Step: 1
Training loss: 2.578929243935756
Validation loss: 2.546127698899081

Epoch: 5| Step: 2
Training loss: 2.7325298950570276
Validation loss: 2.5686790346924413

Epoch: 5| Step: 3
Training loss: 2.699340022629564
Validation loss: 2.5791704869008862

Epoch: 5| Step: 4
Training loss: 2.1939931142485096
Validation loss: 2.61331678860795

Epoch: 5| Step: 5
Training loss: 2.225842918433438
Validation loss: 2.620709713776047

Epoch: 5| Step: 6
Training loss: 2.081263073029571
Validation loss: 2.6460561764250885

Epoch: 5| Step: 7
Training loss: 3.01515976869985
Validation loss: 2.653365665585495

Epoch: 5| Step: 8
Training loss: 2.412593061006173
Validation loss: 2.5940600319993488

Epoch: 5| Step: 9
Training loss: 1.7511000581710934
Validation loss: 2.567617652944391

Epoch: 5| Step: 10
Training loss: 2.6974705114865216
Validation loss: 2.542484162737333

Epoch: 149| Step: 0
Training loss: 2.6520025963691443
Validation loss: 2.5603191330488877

Epoch: 5| Step: 1
Training loss: 2.1574698052442756
Validation loss: 2.5863169596260653

Epoch: 5| Step: 2
Training loss: 2.2178983531393857
Validation loss: 2.5955592434350345

Epoch: 5| Step: 3
Training loss: 2.8440378902717294
Validation loss: 2.5759750037599933

Epoch: 5| Step: 4
Training loss: 1.7261963883347264
Validation loss: 2.579959852607864

Epoch: 5| Step: 5
Training loss: 2.3885756541075915
Validation loss: 2.5752640428018645

Epoch: 5| Step: 6
Training loss: 2.3698640805313858
Validation loss: 2.593512412401902

Epoch: 5| Step: 7
Training loss: 2.500019359513665
Validation loss: 2.601623068345907

Epoch: 5| Step: 8
Training loss: 2.512694458529538
Validation loss: 2.6405718815599055

Epoch: 5| Step: 9
Training loss: 2.4686184618710376
Validation loss: 2.6697367779158663

Epoch: 5| Step: 10
Training loss: 3.079788920117817
Validation loss: 2.7117583960623715

Epoch: 150| Step: 0
Training loss: 2.3688426258829334
Validation loss: 2.6726531875836015

Epoch: 5| Step: 1
Training loss: 2.366565081157861
Validation loss: 2.627943053287978

Epoch: 5| Step: 2
Training loss: 2.640869129339957
Validation loss: 2.5607083818164575

Epoch: 5| Step: 3
Training loss: 2.8885016813558897
Validation loss: 2.553395701621823

Epoch: 5| Step: 4
Training loss: 2.4206147883697473
Validation loss: 2.54421968369098

Epoch: 5| Step: 5
Training loss: 2.8834472619041636
Validation loss: 2.5483361693169395

Epoch: 5| Step: 6
Training loss: 2.304154777381212
Validation loss: 2.5536386183677067

Epoch: 5| Step: 7
Training loss: 2.789473303024887
Validation loss: 2.5523306737852756

Epoch: 5| Step: 8
Training loss: 2.491580327131817
Validation loss: 2.5670883404321736

Epoch: 5| Step: 9
Training loss: 1.9962840726711866
Validation loss: 2.585664473070486

Epoch: 5| Step: 10
Training loss: 1.5067451138174284
Validation loss: 2.633244712652537

Epoch: 151| Step: 0
Training loss: 2.320918970451386
Validation loss: 2.662022213372686

Epoch: 5| Step: 1
Training loss: 2.480577649707182
Validation loss: 2.6757520127501158

Epoch: 5| Step: 2
Training loss: 2.4079245153236393
Validation loss: 2.66409059338373

Epoch: 5| Step: 3
Training loss: 2.723826875061335
Validation loss: 2.6692935639900983

Epoch: 5| Step: 4
Training loss: 2.381853654896435
Validation loss: 2.6789055307008063

Epoch: 5| Step: 5
Training loss: 2.554011450859096
Validation loss: 2.6815489012464653

Epoch: 5| Step: 6
Training loss: 2.2662826109873784
Validation loss: 2.689793210504331

Epoch: 5| Step: 7
Training loss: 2.0950906361568604
Validation loss: 2.671383243315112

Epoch: 5| Step: 8
Training loss: 2.4056953682720383
Validation loss: 2.6571075753742033

Epoch: 5| Step: 9
Training loss: 2.8266375091536404
Validation loss: 2.6074473488373577

Epoch: 5| Step: 10
Training loss: 2.161909443916435
Validation loss: 2.5785882150238426

Epoch: 152| Step: 0
Training loss: 2.198727703664567
Validation loss: 2.5697038996400807

Epoch: 5| Step: 1
Training loss: 2.6292678108246825
Validation loss: 2.5959798590550953

Epoch: 5| Step: 2
Training loss: 2.443248718829704
Validation loss: 2.6367672587694835

Epoch: 5| Step: 3
Training loss: 1.8660576885705769
Validation loss: 2.651697006051504

Epoch: 5| Step: 4
Training loss: 2.203729857613985
Validation loss: 2.699917753889474

Epoch: 5| Step: 5
Training loss: 2.8014778324402814
Validation loss: 2.6968126247696107

Epoch: 5| Step: 6
Training loss: 2.355712169513084
Validation loss: 2.6834110634221084

Epoch: 5| Step: 7
Training loss: 2.047717670798823
Validation loss: 2.6788804550162784

Epoch: 5| Step: 8
Training loss: 2.613334712235742
Validation loss: 2.7000875844692223

Epoch: 5| Step: 9
Training loss: 2.7917605901452203
Validation loss: 2.6632669967010885

Epoch: 5| Step: 10
Training loss: 2.513158501262071
Validation loss: 2.6246398008686187

Epoch: 153| Step: 0
Training loss: 2.491990323771983
Validation loss: 2.5936725662717466

Epoch: 5| Step: 1
Training loss: 2.639903765716173
Validation loss: 2.5526587541779837

Epoch: 5| Step: 2
Training loss: 2.516581004202748
Validation loss: 2.5296011141813675

Epoch: 5| Step: 3
Training loss: 1.788344259889374
Validation loss: 2.5673971914705196

Epoch: 5| Step: 4
Training loss: 3.2151160605737057
Validation loss: 2.5582656190288247

Epoch: 5| Step: 5
Training loss: 2.0934063074225566
Validation loss: 2.591808575468088

Epoch: 5| Step: 6
Training loss: 2.378735465698421
Validation loss: 2.624328586012704

Epoch: 5| Step: 7
Training loss: 2.228997862892273
Validation loss: 2.662764262310378

Epoch: 5| Step: 8
Training loss: 2.505533293798793
Validation loss: 2.6945613471281735

Epoch: 5| Step: 9
Training loss: 2.6878638797422294
Validation loss: 2.630769878050701

Epoch: 5| Step: 10
Training loss: 1.5962786342887456
Validation loss: 2.59039401861787

Epoch: 154| Step: 0
Training loss: 2.8654590354790956
Validation loss: 2.5476595608008163

Epoch: 5| Step: 1
Training loss: 1.7013296761448535
Validation loss: 2.5898517987209377

Epoch: 5| Step: 2
Training loss: 2.4003041114456924
Validation loss: 2.603186762056791

Epoch: 5| Step: 3
Training loss: 2.4519356924339477
Validation loss: 2.627826668854251

Epoch: 5| Step: 4
Training loss: 2.6170382784535486
Validation loss: 2.6678892144874533

Epoch: 5| Step: 5
Training loss: 2.2659476214935004
Validation loss: 2.6920828467782467

Epoch: 5| Step: 6
Training loss: 2.7124385141180793
Validation loss: 2.7268980589408836

Epoch: 5| Step: 7
Training loss: 1.651610010883852
Validation loss: 2.6888242245956584

Epoch: 5| Step: 8
Training loss: 2.4102842522608774
Validation loss: 2.651465427879066

Epoch: 5| Step: 9
Training loss: 2.3254343139912046
Validation loss: 2.596134152565745

Epoch: 5| Step: 10
Training loss: 2.6840911359877184
Validation loss: 2.578586086433929

Epoch: 155| Step: 0
Training loss: 2.644312253643523
Validation loss: 2.5295623780580145

Epoch: 5| Step: 1
Training loss: 2.7502083265983983
Validation loss: 2.5067340580486968

Epoch: 5| Step: 2
Training loss: 2.496793789074038
Validation loss: 2.517550263239179

Epoch: 5| Step: 3
Training loss: 2.030324871958515
Validation loss: 2.5155110288470888

Epoch: 5| Step: 4
Training loss: 2.274497922053198
Validation loss: 2.547342521858093

Epoch: 5| Step: 5
Training loss: 1.9419251023021074
Validation loss: 2.5993761042540604

Epoch: 5| Step: 6
Training loss: 2.1364859780231535
Validation loss: 2.657797257699925

Epoch: 5| Step: 7
Training loss: 2.1752558678268485
Validation loss: 2.7189499099439307

Epoch: 5| Step: 8
Training loss: 2.9794483362882533
Validation loss: 2.7944752241184205

Epoch: 5| Step: 9
Training loss: 2.557766706444739
Validation loss: 2.819194461309297

Epoch: 5| Step: 10
Training loss: 2.4062670422235373
Validation loss: 2.773097825903461

Epoch: 156| Step: 0
Training loss: 1.5865535948771867
Validation loss: 2.6466477135315194

Epoch: 5| Step: 1
Training loss: 2.0311524587833216
Validation loss: 2.567405263629509

Epoch: 5| Step: 2
Training loss: 2.8310087054842032
Validation loss: 2.513008577645382

Epoch: 5| Step: 3
Training loss: 1.9570081637119154
Validation loss: 2.493841700770107

Epoch: 5| Step: 4
Training loss: 2.303844750412381
Validation loss: 2.497597963774648

Epoch: 5| Step: 5
Training loss: 2.52282877568675
Validation loss: 2.496539373574039

Epoch: 5| Step: 6
Training loss: 2.5550597500020076
Validation loss: 2.494730381394113

Epoch: 5| Step: 7
Training loss: 2.2055594338810813
Validation loss: 2.5274405659242585

Epoch: 5| Step: 8
Training loss: 2.803973178697155
Validation loss: 2.5352639008387925

Epoch: 5| Step: 9
Training loss: 2.3618228163838224
Validation loss: 2.5852248957247292

Epoch: 5| Step: 10
Training loss: 2.9432153495680717
Validation loss: 2.634802997864406

Epoch: 157| Step: 0
Training loss: 2.8912864134557457
Validation loss: 2.6759867007911313

Epoch: 5| Step: 1
Training loss: 1.606182227578897
Validation loss: 2.7336209421487876

Epoch: 5| Step: 2
Training loss: 2.2753609716750702
Validation loss: 2.7736168375459593

Epoch: 5| Step: 3
Training loss: 2.0194913465442457
Validation loss: 2.7980120156814956

Epoch: 5| Step: 4
Training loss: 2.2415715345123246
Validation loss: 2.778224710448515

Epoch: 5| Step: 5
Training loss: 2.866531504911876
Validation loss: 2.825632787877374

Epoch: 5| Step: 6
Training loss: 2.792693096509662
Validation loss: 2.7395635933462943

Epoch: 5| Step: 7
Training loss: 1.8304689167200094
Validation loss: 2.71948158417313

Epoch: 5| Step: 8
Training loss: 2.43602864778207
Validation loss: 2.6295016598098093

Epoch: 5| Step: 9
Training loss: 2.2386336922904686
Validation loss: 2.573906824094682

Epoch: 5| Step: 10
Training loss: 2.4284847508517795
Validation loss: 2.545633594922842

Epoch: 158| Step: 0
Training loss: 2.633820745371636
Validation loss: 2.513467121913819

Epoch: 5| Step: 1
Training loss: 2.41798452640249
Validation loss: 2.5113368957979993

Epoch: 5| Step: 2
Training loss: 2.5112803597179227
Validation loss: 2.5343523418017093

Epoch: 5| Step: 3
Training loss: 2.2834889124565
Validation loss: 2.534130407710906

Epoch: 5| Step: 4
Training loss: 2.395788662259045
Validation loss: 2.5769856938294944

Epoch: 5| Step: 5
Training loss: 2.2678228832699463
Validation loss: 2.585324577527963

Epoch: 5| Step: 6
Training loss: 1.826079046980588
Validation loss: 2.6246442206995244

Epoch: 5| Step: 7
Training loss: 2.169051825988033
Validation loss: 2.6481915107207317

Epoch: 5| Step: 8
Training loss: 2.0275952839128077
Validation loss: 2.661763881048139

Epoch: 5| Step: 9
Training loss: 3.0259407976489667
Validation loss: 2.693605434711835

Epoch: 5| Step: 10
Training loss: 2.081441541684266
Validation loss: 2.6965464664299175

Epoch: 159| Step: 0
Training loss: 1.9432177314704715
Validation loss: 2.6862769357019896

Epoch: 5| Step: 1
Training loss: 2.479903317381952
Validation loss: 2.6831967107770485

Epoch: 5| Step: 2
Training loss: 2.3087571242820975
Validation loss: 2.6403652509270157

Epoch: 5| Step: 3
Training loss: 2.397097632700734
Validation loss: 2.615170572248173

Epoch: 5| Step: 4
Training loss: 1.9502462916236871
Validation loss: 2.6302386181108313

Epoch: 5| Step: 5
Training loss: 2.694319920977902
Validation loss: 2.6126727768553546

Epoch: 5| Step: 6
Training loss: 2.601723789106885
Validation loss: 2.623703053652936

Epoch: 5| Step: 7
Training loss: 1.7100430593590503
Validation loss: 2.6306500207274883

Epoch: 5| Step: 8
Training loss: 2.4733376671409513
Validation loss: 2.6701108055171066

Epoch: 5| Step: 9
Training loss: 2.0397580885971647
Validation loss: 2.6788519425399446

Epoch: 5| Step: 10
Training loss: 2.5135762656642324
Validation loss: 2.71879931009017

Epoch: 160| Step: 0
Training loss: 2.872261069564081
Validation loss: 2.781424763594749

Epoch: 5| Step: 1
Training loss: 2.3334435255280153
Validation loss: 2.7996791381080337

Epoch: 5| Step: 2
Training loss: 2.1302848621851433
Validation loss: 2.7667424154407443

Epoch: 5| Step: 3
Training loss: 2.9050835350225275
Validation loss: 2.7184647875037378

Epoch: 5| Step: 4
Training loss: 1.6257200846423776
Validation loss: 2.702469767610782

Epoch: 5| Step: 5
Training loss: 2.0714830076647264
Validation loss: 2.691854089644928

Epoch: 5| Step: 6
Training loss: 2.5643774458678052
Validation loss: 2.650759753632125

Epoch: 5| Step: 7
Training loss: 1.6977323498370849
Validation loss: 2.6411695681544427

Epoch: 5| Step: 8
Training loss: 2.1993052599409224
Validation loss: 2.6797402477546974

Epoch: 5| Step: 9
Training loss: 2.24078144288147
Validation loss: 2.644672097952053

Epoch: 5| Step: 10
Training loss: 2.2605480267258278
Validation loss: 2.625892186741144

Epoch: 161| Step: 0
Training loss: 1.8059681893648971
Validation loss: 2.6037155889524914

Epoch: 5| Step: 1
Training loss: 2.633382401632923
Validation loss: 2.5519201960269653

Epoch: 5| Step: 2
Training loss: 2.1119985583473833
Validation loss: 2.5473336142130694

Epoch: 5| Step: 3
Training loss: 2.203994903890876
Validation loss: 2.554590053831673

Epoch: 5| Step: 4
Training loss: 2.3413927558354786
Validation loss: 2.55891112415027

Epoch: 5| Step: 5
Training loss: 2.437077118797246
Validation loss: 2.5885319315402784

Epoch: 5| Step: 6
Training loss: 2.3365120579844936
Validation loss: 2.6451582573463868

Epoch: 5| Step: 7
Training loss: 2.5576820671181006
Validation loss: 2.714330688920929

Epoch: 5| Step: 8
Training loss: 2.2347683860363015
Validation loss: 2.7445727338049606

Epoch: 5| Step: 9
Training loss: 2.042583363581564
Validation loss: 2.8610479762920265

Epoch: 5| Step: 10
Training loss: 2.8538747113748877
Validation loss: 2.8317211843899806

Epoch: 162| Step: 0
Training loss: 2.2424207825208335
Validation loss: 2.720326131915974

Epoch: 5| Step: 1
Training loss: 2.1627323180196707
Validation loss: 2.670873721452816

Epoch: 5| Step: 2
Training loss: 2.3959620123321184
Validation loss: 2.5534587844400347

Epoch: 5| Step: 3
Training loss: 2.3454305091766128
Validation loss: 2.4962482768204564

Epoch: 5| Step: 4
Training loss: 2.6118286839979463
Validation loss: 2.507574517432424

Epoch: 5| Step: 5
Training loss: 2.1311983700760346
Validation loss: 2.516159709564478

Epoch: 5| Step: 6
Training loss: 2.5759374412084015
Validation loss: 2.531866254070151

Epoch: 5| Step: 7
Training loss: 2.015002842184102
Validation loss: 2.550329232803322

Epoch: 5| Step: 8
Training loss: 1.9004299555724191
Validation loss: 2.5983478946276857

Epoch: 5| Step: 9
Training loss: 2.5107136995174946
Validation loss: 2.6428815861172352

Epoch: 5| Step: 10
Training loss: 2.5578698917910776
Validation loss: 2.724764840729721

Epoch: 163| Step: 0
Training loss: 2.1470092464935515
Validation loss: 2.784179832984579

Epoch: 5| Step: 1
Training loss: 2.599796188142284
Validation loss: 2.7829042810151674

Epoch: 5| Step: 2
Training loss: 2.3669696367682995
Validation loss: 2.7863176594184984

Epoch: 5| Step: 3
Training loss: 2.338409646661197
Validation loss: 2.7239572626234647

Epoch: 5| Step: 4
Training loss: 2.172145689417984
Validation loss: 2.7091440404135745

Epoch: 5| Step: 5
Training loss: 1.610365849622985
Validation loss: 2.6972155619541303

Epoch: 5| Step: 6
Training loss: 2.1911758056892623
Validation loss: 2.6953593949846533

Epoch: 5| Step: 7
Training loss: 2.3591120491276705
Validation loss: 2.70659289100025

Epoch: 5| Step: 8
Training loss: 1.8964063037081207
Validation loss: 2.7185851478408622

Epoch: 5| Step: 9
Training loss: 2.401994980717099
Validation loss: 2.7065497123402467

Epoch: 5| Step: 10
Training loss: 2.424692987887385
Validation loss: 2.70937733907062

Epoch: 164| Step: 0
Training loss: 2.0268250612217096
Validation loss: 2.757853831212982

Epoch: 5| Step: 1
Training loss: 2.0798521966872303
Validation loss: 2.779024297061858

Epoch: 5| Step: 2
Training loss: 2.476703724008452
Validation loss: 2.7599876471316303

Epoch: 5| Step: 3
Training loss: 2.638587300874454
Validation loss: 2.722149270426313

Epoch: 5| Step: 4
Training loss: 1.7352627381029113
Validation loss: 2.6669874629623944

Epoch: 5| Step: 5
Training loss: 2.6919847373303005
Validation loss: 2.635902492949823

Epoch: 5| Step: 6
Training loss: 2.223609331130137
Validation loss: 2.627154759441865

Epoch: 5| Step: 7
Training loss: 2.122660639494737
Validation loss: 2.5902523134935826

Epoch: 5| Step: 8
Training loss: 1.9967190533846804
Validation loss: 2.5936006576414576

Epoch: 5| Step: 9
Training loss: 1.5699299968007288
Validation loss: 2.62392880469067

Epoch: 5| Step: 10
Training loss: 2.701409914860514
Validation loss: 2.6519885224224966

Epoch: 165| Step: 0
Training loss: 1.8267932181596422
Validation loss: 2.678079699233686

Epoch: 5| Step: 1
Training loss: 1.8304383077137418
Validation loss: 2.7208429459966723

Epoch: 5| Step: 2
Training loss: 2.2039284830415475
Validation loss: 2.769317544192493

Epoch: 5| Step: 3
Training loss: 1.8284357572999381
Validation loss: 2.7961043566048507

Epoch: 5| Step: 4
Training loss: 2.2567487804662676
Validation loss: 2.7639895818432154

Epoch: 5| Step: 5
Training loss: 2.123241145449795
Validation loss: 2.750862797275771

Epoch: 5| Step: 6
Training loss: 2.1649261844376406
Validation loss: 2.7383780106351363

Epoch: 5| Step: 7
Training loss: 2.1474604934060477
Validation loss: 2.7233833997653374

Epoch: 5| Step: 8
Training loss: 2.228415056478579
Validation loss: 2.708676141541655

Epoch: 5| Step: 9
Training loss: 2.7328793168010503
Validation loss: 2.677768343041671

Epoch: 5| Step: 10
Training loss: 2.5667794941795687
Validation loss: 2.654460311305996

Epoch: 166| Step: 0
Training loss: 1.6516803103953872
Validation loss: 2.6071500458221

Epoch: 5| Step: 1
Training loss: 2.6247337751264044
Validation loss: 2.577349498228255

Epoch: 5| Step: 2
Training loss: 1.9776842756290587
Validation loss: 2.587531180855494

Epoch: 5| Step: 3
Training loss: 2.307643016875652
Validation loss: 2.627495008209249

Epoch: 5| Step: 4
Training loss: 2.0898083835354426
Validation loss: 2.655091355242199

Epoch: 5| Step: 5
Training loss: 2.3257162447024364
Validation loss: 2.72488355765066

Epoch: 5| Step: 6
Training loss: 2.2136902403991017
Validation loss: 2.766312713148676

Epoch: 5| Step: 7
Training loss: 2.6379513720411265
Validation loss: 2.7676247922016

Epoch: 5| Step: 8
Training loss: 2.1918111552873105
Validation loss: 2.764973325375398

Epoch: 5| Step: 9
Training loss: 2.297152028926306
Validation loss: 2.7056938946894773

Epoch: 5| Step: 10
Training loss: 1.5018004102912859
Validation loss: 2.6415447185091976

Epoch: 167| Step: 0
Training loss: 1.961737724039251
Validation loss: 2.6147349229131662

Epoch: 5| Step: 1
Training loss: 1.9646682205819692
Validation loss: 2.576527790555737

Epoch: 5| Step: 2
Training loss: 2.307265982617669
Validation loss: 2.578817511830047

Epoch: 5| Step: 3
Training loss: 1.8021175697323244
Validation loss: 2.6129521375863867

Epoch: 5| Step: 4
Training loss: 2.322712078122828
Validation loss: 2.6376140564183483

Epoch: 5| Step: 5
Training loss: 1.9777816812010023
Validation loss: 2.7155099859405163

Epoch: 5| Step: 6
Training loss: 2.236549226583696
Validation loss: 2.7013071161702684

Epoch: 5| Step: 7
Training loss: 2.492285651782429
Validation loss: 2.7195863833991845

Epoch: 5| Step: 8
Training loss: 1.8962629760620084
Validation loss: 2.6693208311107015

Epoch: 5| Step: 9
Training loss: 2.3726074816653604
Validation loss: 2.6085634355409764

Epoch: 5| Step: 10
Training loss: 2.4216132237872623
Validation loss: 2.5795978772584505

Epoch: 168| Step: 0
Training loss: 2.2379590080468406
Validation loss: 2.5769343446141186

Epoch: 5| Step: 1
Training loss: 1.8274369860638309
Validation loss: 2.580738923942088

Epoch: 5| Step: 2
Training loss: 2.464927031112133
Validation loss: 2.5703492301468174

Epoch: 5| Step: 3
Training loss: 2.2995978584344607
Validation loss: 2.601846450031398

Epoch: 5| Step: 4
Training loss: 1.9822033390553202
Validation loss: 2.6389087629478376

Epoch: 5| Step: 5
Training loss: 2.289551145716675
Validation loss: 2.6234998532924667

Epoch: 5| Step: 6
Training loss: 2.0576003861069503
Validation loss: 2.7120664143883237

Epoch: 5| Step: 7
Training loss: 1.892835916415572
Validation loss: 2.762168743997424

Epoch: 5| Step: 8
Training loss: 2.140362020335458
Validation loss: 2.783967920190536

Epoch: 5| Step: 9
Training loss: 2.3035401672742966
Validation loss: 2.8231314796970315

Epoch: 5| Step: 10
Training loss: 1.9009655732554744
Validation loss: 2.781297668328748

Epoch: 169| Step: 0
Training loss: 1.9624386091409884
Validation loss: 2.7459094517933247

Epoch: 5| Step: 1
Training loss: 2.0267788314942536
Validation loss: 2.639070604688649

Epoch: 5| Step: 2
Training loss: 2.0822293471806255
Validation loss: 2.6123411618694585

Epoch: 5| Step: 3
Training loss: 2.144542478660551
Validation loss: 2.5686506024135793

Epoch: 5| Step: 4
Training loss: 2.190734542741652
Validation loss: 2.5478808471927104

Epoch: 5| Step: 5
Training loss: 2.43178073218978
Validation loss: 2.573245117524563

Epoch: 5| Step: 6
Training loss: 2.3514143684850857
Validation loss: 2.5945860138969277

Epoch: 5| Step: 7
Training loss: 2.302883463685137
Validation loss: 2.6190509546948784

Epoch: 5| Step: 8
Training loss: 1.9850084390148586
Validation loss: 2.666443385369624

Epoch: 5| Step: 9
Training loss: 1.640598696543236
Validation loss: 2.680611424734635

Epoch: 5| Step: 10
Training loss: 2.1370506795926056
Validation loss: 2.726265049982871

Epoch: 170| Step: 0
Training loss: 2.084436112041308
Validation loss: 2.7192024624844993

Epoch: 5| Step: 1
Training loss: 2.1542847011357074
Validation loss: 2.7320997578435997

Epoch: 5| Step: 2
Training loss: 1.913505005904947
Validation loss: 2.704024194307355

Epoch: 5| Step: 3
Training loss: 2.053467943415482
Validation loss: 2.671279759365918

Epoch: 5| Step: 4
Training loss: 2.2418758162408454
Validation loss: 2.6404054456641575

Epoch: 5| Step: 5
Training loss: 2.635128553320159
Validation loss: 2.625944763507747

Epoch: 5| Step: 6
Training loss: 2.24068983082638
Validation loss: 2.5992409762880087

Epoch: 5| Step: 7
Training loss: 1.840576155683156
Validation loss: 2.608170358317536

Epoch: 5| Step: 8
Training loss: 1.5913700959223926
Validation loss: 2.6106840321634497

Epoch: 5| Step: 9
Training loss: 2.106052183375992
Validation loss: 2.668728380086135

Epoch: 5| Step: 10
Training loss: 2.115082880655275
Validation loss: 2.728445499979569

Epoch: 171| Step: 0
Training loss: 2.4366320507480035
Validation loss: 2.7425615197992648

Epoch: 5| Step: 1
Training loss: 2.15488180345304
Validation loss: 2.6985607954876065

Epoch: 5| Step: 2
Training loss: 2.47531048147001
Validation loss: 2.6764247411849484

Epoch: 5| Step: 3
Training loss: 2.25932688892684
Validation loss: 2.6518555997425453

Epoch: 5| Step: 4
Training loss: 2.145099168632495
Validation loss: 2.6329121678361904

Epoch: 5| Step: 5
Training loss: 1.6688060222465866
Validation loss: 2.6608537198661413

Epoch: 5| Step: 6
Training loss: 1.9917495545360075
Validation loss: 2.6590009232640988

Epoch: 5| Step: 7
Training loss: 1.7807684799664283
Validation loss: 2.7077676818155756

Epoch: 5| Step: 8
Training loss: 1.7370228530750833
Validation loss: 2.6976051655942537

Epoch: 5| Step: 9
Training loss: 2.1532343910012055
Validation loss: 2.7117560033059513

Epoch: 5| Step: 10
Training loss: 1.8187102769007275
Validation loss: 2.726723868777972

Epoch: 172| Step: 0
Training loss: 2.439645751971192
Validation loss: 2.712761680165507

Epoch: 5| Step: 1
Training loss: 1.3793846791683564
Validation loss: 2.6818767764752596

Epoch: 5| Step: 2
Training loss: 2.344338203371239
Validation loss: 2.6517736889859895

Epoch: 5| Step: 3
Training loss: 2.0641338928027397
Validation loss: 2.6524397080138593

Epoch: 5| Step: 4
Training loss: 2.3203317146918527
Validation loss: 2.6527324957485954

Epoch: 5| Step: 5
Training loss: 1.9042336477884938
Validation loss: 2.6504354478654992

Epoch: 5| Step: 6
Training loss: 2.312535156807556
Validation loss: 2.658737980517056

Epoch: 5| Step: 7
Training loss: 1.6666653474166735
Validation loss: 2.661946185856686

Epoch: 5| Step: 8
Training loss: 1.9331070104305232
Validation loss: 2.6527114616414105

Epoch: 5| Step: 9
Training loss: 1.7691731543234082
Validation loss: 2.633029918421053

Epoch: 5| Step: 10
Training loss: 2.0552863927119485
Validation loss: 2.5903076356294172

Epoch: 173| Step: 0
Training loss: 1.9746891839475555
Validation loss: 2.6173382292804255

Epoch: 5| Step: 1
Training loss: 1.8219296062785673
Validation loss: 2.6044964869842167

Epoch: 5| Step: 2
Training loss: 2.1636727873866892
Validation loss: 2.6413901110684286

Epoch: 5| Step: 3
Training loss: 2.051778031566844
Validation loss: 2.6583360909670026

Epoch: 5| Step: 4
Training loss: 1.891748709166903
Validation loss: 2.6513678295299625

Epoch: 5| Step: 5
Training loss: 2.2610631859043337
Validation loss: 2.6501120523703037

Epoch: 5| Step: 6
Training loss: 2.1788759532421067
Validation loss: 2.644353517826621

Epoch: 5| Step: 7
Training loss: 2.189635950600211
Validation loss: 2.6073520878581897

Epoch: 5| Step: 8
Training loss: 1.6902760171928979
Validation loss: 2.571360637960878

Epoch: 5| Step: 9
Training loss: 2.2052142470371656
Validation loss: 2.557357995407989

Epoch: 5| Step: 10
Training loss: 1.8186421077226975
Validation loss: 2.533460635428479

Epoch: 174| Step: 0
Training loss: 2.078969224666247
Validation loss: 2.5703276664844226

Epoch: 5| Step: 1
Training loss: 1.6762644109028264
Validation loss: 2.613171161319498

Epoch: 5| Step: 2
Training loss: 1.6465676355634795
Validation loss: 2.6908510687674885

Epoch: 5| Step: 3
Training loss: 2.182621338432854
Validation loss: 2.7583359305804485

Epoch: 5| Step: 4
Training loss: 1.8975640316539215
Validation loss: 2.7731549297135585

Epoch: 5| Step: 5
Training loss: 2.038995383608664
Validation loss: 2.7324335390525563

Epoch: 5| Step: 6
Training loss: 2.6364056888801963
Validation loss: 2.69467616024889

Epoch: 5| Step: 7
Training loss: 1.4215649277185627
Validation loss: 2.6536832236805292

Epoch: 5| Step: 8
Training loss: 2.22342801229419
Validation loss: 2.65124147039645

Epoch: 5| Step: 9
Training loss: 2.5670106777003268
Validation loss: 2.621098312741472

Epoch: 5| Step: 10
Training loss: 1.338449714955826
Validation loss: 2.5882823457082877

Epoch: 175| Step: 0
Training loss: 2.0099047732214115
Validation loss: 2.636906988245077

Epoch: 5| Step: 1
Training loss: 1.9798183840485288
Validation loss: 2.6271843735813545

Epoch: 5| Step: 2
Training loss: 2.322266446330805
Validation loss: 2.6418422556641037

Epoch: 5| Step: 3
Training loss: 1.6284584509351534
Validation loss: 2.652828501549084

Epoch: 5| Step: 4
Training loss: 1.848431543516363
Validation loss: 2.695266848322141

Epoch: 5| Step: 5
Training loss: 2.2873199392023102
Validation loss: 2.739619822177061

Epoch: 5| Step: 6
Training loss: 1.9793698725198836
Validation loss: 2.7226133166770543

Epoch: 5| Step: 7
Training loss: 2.1169404170715698
Validation loss: 2.728022622014512

Epoch: 5| Step: 8
Training loss: 1.6840487615407542
Validation loss: 2.725683446967824

Epoch: 5| Step: 9
Training loss: 1.9588240218401978
Validation loss: 2.7183984169169264

Epoch: 5| Step: 10
Training loss: 2.049610668521485
Validation loss: 2.7182531821070826

Epoch: 176| Step: 0
Training loss: 2.104111837547721
Validation loss: 2.6358212399567518

Epoch: 5| Step: 1
Training loss: 2.1577746764340926
Validation loss: 2.6079573562552296

Epoch: 5| Step: 2
Training loss: 2.119181802235309
Validation loss: 2.5530658095671974

Epoch: 5| Step: 3
Training loss: 2.326500447446812
Validation loss: 2.5405085023099567

Epoch: 5| Step: 4
Training loss: 2.268840113339832
Validation loss: 2.556062283606025

Epoch: 5| Step: 5
Training loss: 1.8969127670123096
Validation loss: 2.578190550805147

Epoch: 5| Step: 6
Training loss: 1.8864039440799731
Validation loss: 2.6152401546764334

Epoch: 5| Step: 7
Training loss: 2.1200476889374777
Validation loss: 2.704288135447781

Epoch: 5| Step: 8
Training loss: 1.5339687889634248
Validation loss: 2.784090614520499

Epoch: 5| Step: 9
Training loss: 1.4288592831926352
Validation loss: 2.7831274786043605

Epoch: 5| Step: 10
Training loss: 2.036543302072367
Validation loss: 2.7827092023277826

Epoch: 177| Step: 0
Training loss: 2.0964032343143115
Validation loss: 2.6967675308417642

Epoch: 5| Step: 1
Training loss: 1.8907010402047693
Validation loss: 2.6406468954026217

Epoch: 5| Step: 2
Training loss: 2.2436799189851975
Validation loss: 2.5639247560062297

Epoch: 5| Step: 3
Training loss: 1.6680428624717925
Validation loss: 2.5285661618789024

Epoch: 5| Step: 4
Training loss: 1.769903754295412
Validation loss: 2.5369458443969513

Epoch: 5| Step: 5
Training loss: 2.0008593143723634
Validation loss: 2.5551259647775724

Epoch: 5| Step: 6
Training loss: 1.6631113118752021
Validation loss: 2.5582694741086183

Epoch: 5| Step: 7
Training loss: 2.573786280979816
Validation loss: 2.5928152124359474

Epoch: 5| Step: 8
Training loss: 2.057928394017232
Validation loss: 2.626258447849854

Epoch: 5| Step: 9
Training loss: 1.9421460221665199
Validation loss: 2.6536508659740066

Epoch: 5| Step: 10
Training loss: 1.7327394764186705
Validation loss: 2.6867378052629007

Epoch: 178| Step: 0
Training loss: 2.244420020072327
Validation loss: 2.65889549860013

Epoch: 5| Step: 1
Training loss: 1.9657760440789926
Validation loss: 2.649448990647828

Epoch: 5| Step: 2
Training loss: 2.389430526818613
Validation loss: 2.615773368986312

Epoch: 5| Step: 3
Training loss: 2.1753606475337324
Validation loss: 2.5878199763066534

Epoch: 5| Step: 4
Training loss: 0.9810794584931734
Validation loss: 2.547715400281613

Epoch: 5| Step: 5
Training loss: 2.2698090952787218
Validation loss: 2.5346732276777257

Epoch: 5| Step: 6
Training loss: 1.369824030775456
Validation loss: 2.5622332494373126

Epoch: 5| Step: 7
Training loss: 1.6467028707058444
Validation loss: 2.5856753456428536

Epoch: 5| Step: 8
Training loss: 1.948043989076498
Validation loss: 2.614803111973603

Epoch: 5| Step: 9
Training loss: 2.1916079504852988
Validation loss: 2.656625406277297

Epoch: 5| Step: 10
Training loss: 1.9392481884816963
Validation loss: 2.6489150603808804

Epoch: 179| Step: 0
Training loss: 2.0214704577570437
Validation loss: 2.6523284532294764

Epoch: 5| Step: 1
Training loss: 1.352720260876953
Validation loss: 2.6506368280144113

Epoch: 5| Step: 2
Training loss: 2.2071674676229387
Validation loss: 2.648676402745423

Epoch: 5| Step: 3
Training loss: 1.5741154563467281
Validation loss: 2.6541878297713883

Epoch: 5| Step: 4
Training loss: 2.202465526817632
Validation loss: 2.6433959400749427

Epoch: 5| Step: 5
Training loss: 2.4744307431703523
Validation loss: 2.6540426117261995

Epoch: 5| Step: 6
Training loss: 2.0515811776954664
Validation loss: 2.691647232682944

Epoch: 5| Step: 7
Training loss: 2.1675545511563876
Validation loss: 2.7110592403786598

Epoch: 5| Step: 8
Training loss: 1.5359841169887147
Validation loss: 2.7271320624788986

Epoch: 5| Step: 9
Training loss: 1.9916258974039178
Validation loss: 2.6938892394087763

Epoch: 5| Step: 10
Training loss: 1.5163886908920268
Validation loss: 2.637047076822435

Epoch: 180| Step: 0
Training loss: 2.1961618321307097
Validation loss: 2.581502145997116

Epoch: 5| Step: 1
Training loss: 2.3844707784751944
Validation loss: 2.544921619131731

Epoch: 5| Step: 2
Training loss: 1.6544963982071095
Validation loss: 2.5186550465183632

Epoch: 5| Step: 3
Training loss: 1.9892457672338744
Validation loss: 2.529869814348386

Epoch: 5| Step: 4
Training loss: 1.8125569564815065
Validation loss: 2.5495365885535817

Epoch: 5| Step: 5
Training loss: 2.071885227736233
Validation loss: 2.563892754353139

Epoch: 5| Step: 6
Training loss: 2.1190553428260133
Validation loss: 2.6226894329459713

Epoch: 5| Step: 7
Training loss: 1.814198848781782
Validation loss: 2.6658420938237097

Epoch: 5| Step: 8
Training loss: 1.9348383433314111
Validation loss: 2.698945243784299

Epoch: 5| Step: 9
Training loss: 1.8420591845163021
Validation loss: 2.7028524221184185

Epoch: 5| Step: 10
Training loss: 1.258352602038526
Validation loss: 2.6880052792187334

Epoch: 181| Step: 0
Training loss: 1.8825623912021612
Validation loss: 2.6592681049279494

Epoch: 5| Step: 1
Training loss: 1.667567041699377
Validation loss: 2.6315442101296713

Epoch: 5| Step: 2
Training loss: 1.7742115633712745
Validation loss: 2.604051911481596

Epoch: 5| Step: 3
Training loss: 2.410303145372796
Validation loss: 2.58075105599822

Epoch: 5| Step: 4
Training loss: 2.034933418478148
Validation loss: 2.587218533350558

Epoch: 5| Step: 5
Training loss: 1.942090901974777
Validation loss: 2.597855759054943

Epoch: 5| Step: 6
Training loss: 1.588238930126674
Validation loss: 2.5953636818159964

Epoch: 5| Step: 7
Training loss: 1.8589571314973874
Validation loss: 2.584654938056425

Epoch: 5| Step: 8
Training loss: 1.9037290694951563
Validation loss: 2.6287476731723163

Epoch: 5| Step: 9
Training loss: 2.023046978709087
Validation loss: 2.6526625060801923

Epoch: 5| Step: 10
Training loss: 1.773215258952996
Validation loss: 2.6825505549963213

Epoch: 182| Step: 0
Training loss: 2.3339258418065665
Validation loss: 2.70961719559303

Epoch: 5| Step: 1
Training loss: 2.1664500372747044
Validation loss: 2.6917567756885346

Epoch: 5| Step: 2
Training loss: 1.908323067494506
Validation loss: 2.635218486916356

Epoch: 5| Step: 3
Training loss: 1.4541664083456922
Validation loss: 2.5517456812412633

Epoch: 5| Step: 4
Training loss: 1.753751888151777
Validation loss: 2.542541301639999

Epoch: 5| Step: 5
Training loss: 2.285337783254225
Validation loss: 2.5588059745094234

Epoch: 5| Step: 6
Training loss: 2.229344500522083
Validation loss: 2.555137199065622

Epoch: 5| Step: 7
Training loss: 1.6189201029948888
Validation loss: 2.5873457016251646

Epoch: 5| Step: 8
Training loss: 2.0620701659850957
Validation loss: 2.612619029757896

Epoch: 5| Step: 9
Training loss: 1.6745056419197777
Validation loss: 2.5981054543855118

Epoch: 5| Step: 10
Training loss: 1.3214745007269237
Validation loss: 2.619127805496056

Epoch: 183| Step: 0
Training loss: 1.6547265153559207
Validation loss: 2.6265748032403757

Epoch: 5| Step: 1
Training loss: 1.5433702163875502
Validation loss: 2.655474585914306

Epoch: 5| Step: 2
Training loss: 1.9658981739889694
Validation loss: 2.6798617848236503

Epoch: 5| Step: 3
Training loss: 1.9960819251499675
Validation loss: 2.70751287813343

Epoch: 5| Step: 4
Training loss: 2.345409162080945
Validation loss: 2.692856276147128

Epoch: 5| Step: 5
Training loss: 1.9256336704988788
Validation loss: 2.621106176483053

Epoch: 5| Step: 6
Training loss: 1.5371770007757295
Validation loss: 2.5622565191062754

Epoch: 5| Step: 7
Training loss: 2.488072169456176
Validation loss: 2.5463827515467

Epoch: 5| Step: 8
Training loss: 1.7831711698345045
Validation loss: 2.5297890592906462

Epoch: 5| Step: 9
Training loss: 2.103243017640535
Validation loss: 2.568266049080717

Epoch: 5| Step: 10
Training loss: 1.300152463408894
Validation loss: 2.586390063949696

Epoch: 184| Step: 0
Training loss: 1.8401625047324603
Validation loss: 2.569849394401906

Epoch: 5| Step: 1
Training loss: 1.9621575196404886
Validation loss: 2.6048082712276357

Epoch: 5| Step: 2
Training loss: 1.8560866441357042
Validation loss: 2.6147312040291757

Epoch: 5| Step: 3
Training loss: 1.8592240087927048
Validation loss: 2.6163042973524706

Epoch: 5| Step: 4
Training loss: 1.921988941319593
Validation loss: 2.650879489889241

Epoch: 5| Step: 5
Training loss: 1.4741501250919438
Validation loss: 2.6491939456460103

Epoch: 5| Step: 6
Training loss: 1.9483370267878175
Validation loss: 2.6577388376676634

Epoch: 5| Step: 7
Training loss: 1.7556046926017204
Validation loss: 2.6679800847057376

Epoch: 5| Step: 8
Training loss: 2.0457747902298746
Validation loss: 2.648296397332538

Epoch: 5| Step: 9
Training loss: 1.9281777719358186
Validation loss: 2.6799437305522735

Epoch: 5| Step: 10
Training loss: 1.977963038076996
Validation loss: 2.654407485182907

Epoch: 185| Step: 0
Training loss: 2.339257779885405
Validation loss: 2.6431853120953335

Epoch: 5| Step: 1
Training loss: 1.9506595767646973
Validation loss: 2.646832823255999

Epoch: 5| Step: 2
Training loss: 1.8249109168062325
Validation loss: 2.6534366386133215

Epoch: 5| Step: 3
Training loss: 2.020914043374737
Validation loss: 2.67710834094239

Epoch: 5| Step: 4
Training loss: 1.6109376006399247
Validation loss: 2.684236444663624

Epoch: 5| Step: 5
Training loss: 1.6720460465538216
Validation loss: 2.6519746040384544

Epoch: 5| Step: 6
Training loss: 1.7241103075544084
Validation loss: 2.667708369056529

Epoch: 5| Step: 7
Training loss: 1.8568912875431514
Validation loss: 2.6637962380742923

Epoch: 5| Step: 8
Training loss: 1.9059609365953418
Validation loss: 2.667000039922523

Epoch: 5| Step: 9
Training loss: 1.5641000565965364
Validation loss: 2.675513852738283

Epoch: 5| Step: 10
Training loss: 1.7164096504077035
Validation loss: 2.6929779343025526

Epoch: 186| Step: 0
Training loss: 2.0560498960578135
Validation loss: 2.646682462183542

Epoch: 5| Step: 1
Training loss: 1.4471811123161062
Validation loss: 2.587371881416345

Epoch: 5| Step: 2
Training loss: 1.937235291148885
Validation loss: 2.573988567447347

Epoch: 5| Step: 3
Training loss: 1.9644082043590816
Validation loss: 2.547094543363867

Epoch: 5| Step: 4
Training loss: 0.9166136133851498
Validation loss: 2.590316665682862

Epoch: 5| Step: 5
Training loss: 2.038951534598877
Validation loss: 2.591987617001515

Epoch: 5| Step: 6
Training loss: 1.630338921562252
Validation loss: 2.615081619677976

Epoch: 5| Step: 7
Training loss: 1.923775454347201
Validation loss: 2.6378100418016057

Epoch: 5| Step: 8
Training loss: 1.987002398020541
Validation loss: 2.6770133351733048

Epoch: 5| Step: 9
Training loss: 1.9926221186453903
Validation loss: 2.6281205598413897

Epoch: 5| Step: 10
Training loss: 1.9108483556508238
Validation loss: 2.609752244349572

Epoch: 187| Step: 0
Training loss: 1.6780916661764762
Validation loss: 2.5927435835813286

Epoch: 5| Step: 1
Training loss: 1.4978430657836577
Validation loss: 2.587598435230371

Epoch: 5| Step: 2
Training loss: 1.7342221304392
Validation loss: 2.596850025599922

Epoch: 5| Step: 3
Training loss: 2.2241345469029183
Validation loss: 2.595558480928509

Epoch: 5| Step: 4
Training loss: 1.5503450255777713
Validation loss: 2.6171196326497324

Epoch: 5| Step: 5
Training loss: 1.8055235012176098
Validation loss: 2.6302849871222627

Epoch: 5| Step: 6
Training loss: 1.4994827014297987
Validation loss: 2.657807326862959

Epoch: 5| Step: 7
Training loss: 1.730260143235416
Validation loss: 2.688459634737835

Epoch: 5| Step: 8
Training loss: 1.8623726666850215
Validation loss: 2.660537099536269

Epoch: 5| Step: 9
Training loss: 2.1624003613400062
Validation loss: 2.6558376506130137

Epoch: 5| Step: 10
Training loss: 1.932560376782329
Validation loss: 2.6323551338052438

Epoch: 188| Step: 0
Training loss: 1.8952769276927985
Validation loss: 2.6499296009512996

Epoch: 5| Step: 1
Training loss: 1.9704835918781982
Validation loss: 2.6206401963573493

Epoch: 5| Step: 2
Training loss: 1.8831106242717763
Validation loss: 2.623433473358175

Epoch: 5| Step: 3
Training loss: 2.0884062484510375
Validation loss: 2.5575361979302027

Epoch: 5| Step: 4
Training loss: 1.3100762467362628
Validation loss: 2.560368888029583

Epoch: 5| Step: 5
Training loss: 1.6880249337257678
Validation loss: 2.566167339600466

Epoch: 5| Step: 6
Training loss: 1.7763323578610244
Validation loss: 2.574118256686672

Epoch: 5| Step: 7
Training loss: 1.2301733237551862
Validation loss: 2.6193657004839754

Epoch: 5| Step: 8
Training loss: 1.738765211991792
Validation loss: 2.655116564836384

Epoch: 5| Step: 9
Training loss: 1.9042623193980135
Validation loss: 2.724471665932556

Epoch: 5| Step: 10
Training loss: 2.0036387720488498
Validation loss: 2.767596651176601

Epoch: 189| Step: 0
Training loss: 1.6724126076210992
Validation loss: 2.760797702698586

Epoch: 5| Step: 1
Training loss: 1.7637316924942186
Validation loss: 2.742055232469097

Epoch: 5| Step: 2
Training loss: 2.100605913578889
Validation loss: 2.725779870413292

Epoch: 5| Step: 3
Training loss: 1.3898392932942616
Validation loss: 2.670721899435271

Epoch: 5| Step: 4
Training loss: 1.7933849774101258
Validation loss: 2.6142018292366194

Epoch: 5| Step: 5
Training loss: 1.6337074127133702
Validation loss: 2.587565404695381

Epoch: 5| Step: 6
Training loss: 2.0304748229772227
Validation loss: 2.570810612273495

Epoch: 5| Step: 7
Training loss: 1.7675178981236308
Validation loss: 2.5559316982581692

Epoch: 5| Step: 8
Training loss: 1.9005132559153683
Validation loss: 2.5661309801781895

Epoch: 5| Step: 9
Training loss: 2.100515452203937
Validation loss: 2.578842390426837

Epoch: 5| Step: 10
Training loss: 0.9144361987333808
Validation loss: 2.5914432326313497

Epoch: 190| Step: 0
Training loss: 1.8843983662992752
Validation loss: 2.5775047493344996

Epoch: 5| Step: 1
Training loss: 1.8756274127277337
Validation loss: 2.592583852899056

Epoch: 5| Step: 2
Training loss: 2.28769088115473
Validation loss: 2.620149534692959

Epoch: 5| Step: 3
Training loss: 1.7597129212678697
Validation loss: 2.5949486597951776

Epoch: 5| Step: 4
Training loss: 1.185893729184941
Validation loss: 2.606683094270407

Epoch: 5| Step: 5
Training loss: 1.4963593807410662
Validation loss: 2.636370211603441

Epoch: 5| Step: 6
Training loss: 1.2937780883983363
Validation loss: 2.6382390656926185

Epoch: 5| Step: 7
Training loss: 1.7037848497998063
Validation loss: 2.6720905410113875

Epoch: 5| Step: 8
Training loss: 1.7588828663907967
Validation loss: 2.6784904257953377

Epoch: 5| Step: 9
Training loss: 1.8195006561655496
Validation loss: 2.6859697338421817

Epoch: 5| Step: 10
Training loss: 1.8938161227828407
Validation loss: 2.648566240453475

Epoch: 191| Step: 0
Training loss: 2.2657828440436
Validation loss: 2.5753538799112223

Epoch: 5| Step: 1
Training loss: 1.8880054201395822
Validation loss: 2.5986726844612713

Epoch: 5| Step: 2
Training loss: 1.599519720115145
Validation loss: 2.6204975127894987

Epoch: 5| Step: 3
Training loss: 1.4406197736070208
Validation loss: 2.6342129915563306

Epoch: 5| Step: 4
Training loss: 1.8855741515872648
Validation loss: 2.6266020209355547

Epoch: 5| Step: 5
Training loss: 1.6579111513920262
Validation loss: 2.6294035109180016

Epoch: 5| Step: 6
Training loss: 1.5564382845183435
Validation loss: 2.619289450766602

Epoch: 5| Step: 7
Training loss: 1.7079273377223432
Validation loss: 2.6468525064452137

Epoch: 5| Step: 8
Training loss: 1.4079239524900407
Validation loss: 2.6154908231080305

Epoch: 5| Step: 9
Training loss: 1.732811162619595
Validation loss: 2.5838821323068513

Epoch: 5| Step: 10
Training loss: 1.67906731089931
Validation loss: 2.5353400162240023

Epoch: 192| Step: 0
Training loss: 1.6771927160129
Validation loss: 2.5460172137638475

Epoch: 5| Step: 1
Training loss: 1.5285610021635399
Validation loss: 2.558638349412241

Epoch: 5| Step: 2
Training loss: 2.1470422271498983
Validation loss: 2.5798524560065803

Epoch: 5| Step: 3
Training loss: 1.890414770118525
Validation loss: 2.6117408249547194

Epoch: 5| Step: 4
Training loss: 1.7336605765694093
Validation loss: 2.6448187804214274

Epoch: 5| Step: 5
Training loss: 1.4894555932961697
Validation loss: 2.692364671451963

Epoch: 5| Step: 6
Training loss: 1.4784720047798832
Validation loss: 2.677196038897674

Epoch: 5| Step: 7
Training loss: 1.781479536291764
Validation loss: 2.6842399306762896

Epoch: 5| Step: 8
Training loss: 1.907345691403982
Validation loss: 2.6837386442810867

Epoch: 5| Step: 9
Training loss: 1.4644408625641083
Validation loss: 2.6586381044394036

Epoch: 5| Step: 10
Training loss: 1.6064255733494726
Validation loss: 2.597417529345653

Epoch: 193| Step: 0
Training loss: 1.5362925122107935
Validation loss: 2.555877779556152

Epoch: 5| Step: 1
Training loss: 1.5244411976834995
Validation loss: 2.500940516151558

Epoch: 5| Step: 2
Training loss: 1.4016416274308963
Validation loss: 2.5071581937428924

Epoch: 5| Step: 3
Training loss: 1.609613567558464
Validation loss: 2.5450154948684065

Epoch: 5| Step: 4
Training loss: 1.9011850451045975
Validation loss: 2.611097671417765

Epoch: 5| Step: 5
Training loss: 1.7548023135361073
Validation loss: 2.6671808872443337

Epoch: 5| Step: 6
Training loss: 1.924840732277611
Validation loss: 2.707790784865491

Epoch: 5| Step: 7
Training loss: 1.5835993777505837
Validation loss: 2.727527324881433

Epoch: 5| Step: 8
Training loss: 1.4653491152994438
Validation loss: 2.720877225735673

Epoch: 5| Step: 9
Training loss: 1.858137664700437
Validation loss: 2.6857110355801503

Epoch: 5| Step: 10
Training loss: 1.8838830334138568
Validation loss: 2.6970325918284175

Epoch: 194| Step: 0
Training loss: 1.8723313732131297
Validation loss: 2.6885035101484496

Epoch: 5| Step: 1
Training loss: 2.067780641561433
Validation loss: 2.6479379265824248

Epoch: 5| Step: 2
Training loss: 1.9991423436866733
Validation loss: 2.566434115787389

Epoch: 5| Step: 3
Training loss: 1.7182448598517566
Validation loss: 2.5965975912057626

Epoch: 5| Step: 4
Training loss: 1.6137465574905943
Validation loss: 2.565701569348674

Epoch: 5| Step: 5
Training loss: 1.361014856883851
Validation loss: 2.6182049995257977

Epoch: 5| Step: 6
Training loss: 1.645208296414934
Validation loss: 2.631808429102204

Epoch: 5| Step: 7
Training loss: 1.3154055360249237
Validation loss: 2.727258275378454

Epoch: 5| Step: 8
Training loss: 1.3505056582166033
Validation loss: 2.7474598530947048

Epoch: 5| Step: 9
Training loss: 1.380776236916654
Validation loss: 2.7004706059595773

Epoch: 5| Step: 10
Training loss: 1.5754220306270192
Validation loss: 2.667905455026329

Epoch: 195| Step: 0
Training loss: 1.3584840858602814
Validation loss: 2.6397871491704716

Epoch: 5| Step: 1
Training loss: 1.6264711469781794
Validation loss: 2.628695377750201

Epoch: 5| Step: 2
Training loss: 1.4509223733771164
Validation loss: 2.621441993938792

Epoch: 5| Step: 3
Training loss: 1.2462515417183204
Validation loss: 2.6051841133036464

Epoch: 5| Step: 4
Training loss: 1.4192858587280437
Validation loss: 2.5872996658877927

Epoch: 5| Step: 5
Training loss: 2.1924443633481223
Validation loss: 2.5662122019919105

Epoch: 5| Step: 6
Training loss: 1.7090652882631192
Validation loss: 2.5720132835463763

Epoch: 5| Step: 7
Training loss: 1.4443923908211749
Validation loss: 2.59424829619969

Epoch: 5| Step: 8
Training loss: 1.7597443540178792
Validation loss: 2.6176156945240487

Epoch: 5| Step: 9
Training loss: 1.7944416985361187
Validation loss: 2.6368428125215018

Epoch: 5| Step: 10
Training loss: 1.5715295430973866
Validation loss: 2.6675479106404576

Epoch: 196| Step: 0
Training loss: 1.811308699473452
Validation loss: 2.6766502694365935

Epoch: 5| Step: 1
Training loss: 1.588132494984205
Validation loss: 2.6727777383414852

Epoch: 5| Step: 2
Training loss: 1.5705912328415408
Validation loss: 2.646503438882057

Epoch: 5| Step: 3
Training loss: 1.4084446629794272
Validation loss: 2.62807229922379

Epoch: 5| Step: 4
Training loss: 1.4320334276847702
Validation loss: 2.563333330331907

Epoch: 5| Step: 5
Training loss: 1.8249813340160046
Validation loss: 2.6063927692670816

Epoch: 5| Step: 6
Training loss: 1.1515397710122837
Validation loss: 2.614191195929109

Epoch: 5| Step: 7
Training loss: 1.7589791050678885
Validation loss: 2.6056374755379994

Epoch: 5| Step: 8
Training loss: 2.0239326725417963
Validation loss: 2.6080533588950625

Epoch: 5| Step: 9
Training loss: 1.405775625962382
Validation loss: 2.5845786542242184

Epoch: 5| Step: 10
Training loss: 1.582864574844792
Validation loss: 2.602558070026063

Epoch: 197| Step: 0
Training loss: 1.5283823993978283
Validation loss: 2.6171027879836766

Epoch: 5| Step: 1
Training loss: 1.3367127962944103
Validation loss: 2.625024000449755

Epoch: 5| Step: 2
Training loss: 1.4157598435472134
Validation loss: 2.6219111491591143

Epoch: 5| Step: 3
Training loss: 2.0969273385851177
Validation loss: 2.6138102217730528

Epoch: 5| Step: 4
Training loss: 1.3161478666293107
Validation loss: 2.5965891289782057

Epoch: 5| Step: 5
Training loss: 1.13112430401082
Validation loss: 2.5994309935457327

Epoch: 5| Step: 6
Training loss: 1.7740568852297973
Validation loss: 2.6397352909638983

Epoch: 5| Step: 7
Training loss: 1.6885335370981387
Validation loss: 2.6773114166897023

Epoch: 5| Step: 8
Training loss: 1.7060019316265445
Validation loss: 2.6490620246918746

Epoch: 5| Step: 9
Training loss: 2.051744797822835
Validation loss: 2.650099194048345

Epoch: 5| Step: 10
Training loss: 1.0695567003319246
Validation loss: 2.577113836578478

Epoch: 198| Step: 0
Training loss: 1.4180007804846937
Validation loss: 2.5425455183409196

Epoch: 5| Step: 1
Training loss: 1.40937737170779
Validation loss: 2.510427745994969

Epoch: 5| Step: 2
Training loss: 1.4410351945019293
Validation loss: 2.526064658094705

Epoch: 5| Step: 3
Training loss: 1.4398086916152881
Validation loss: 2.584786946576631

Epoch: 5| Step: 4
Training loss: 1.9021380742173926
Validation loss: 2.624843009672513

Epoch: 5| Step: 5
Training loss: 1.7732297800896606
Validation loss: 2.63811446827883

Epoch: 5| Step: 6
Training loss: 1.6534649447130034
Validation loss: 2.692556433628839

Epoch: 5| Step: 7
Training loss: 1.5966304106501574
Validation loss: 2.6901395683999576

Epoch: 5| Step: 8
Training loss: 1.1801864377330995
Validation loss: 2.679487385652189

Epoch: 5| Step: 9
Training loss: 1.7050607162583153
Validation loss: 2.6503592969071357

Epoch: 5| Step: 10
Training loss: 1.8856176476466417
Validation loss: 2.6241589745405833

Epoch: 199| Step: 0
Training loss: 1.331122617044715
Validation loss: 2.6039007055179635

Epoch: 5| Step: 1
Training loss: 1.4844031080295155
Validation loss: 2.5691873003985193

Epoch: 5| Step: 2
Training loss: 2.1461943412233366
Validation loss: 2.555741517324736

Epoch: 5| Step: 3
Training loss: 1.6096955507906927
Validation loss: 2.574305627553077

Epoch: 5| Step: 4
Training loss: 1.5618915899219201
Validation loss: 2.562958407974275

Epoch: 5| Step: 5
Training loss: 1.3295893057977244
Validation loss: 2.588942164619147

Epoch: 5| Step: 6
Training loss: 0.9427752216417854
Validation loss: 2.578200200022954

Epoch: 5| Step: 7
Training loss: 1.6072641251240465
Validation loss: 2.609416237015817

Epoch: 5| Step: 8
Training loss: 1.3185928703094525
Validation loss: 2.632586767744413

Epoch: 5| Step: 9
Training loss: 1.5752438220260305
Validation loss: 2.5756206003936595

Epoch: 5| Step: 10
Training loss: 2.0255274050517613
Validation loss: 2.5185149167558416

Epoch: 200| Step: 0
Training loss: 1.3110638890589803
Validation loss: 2.4955385853938536

Epoch: 5| Step: 1
Training loss: 1.8604265333072791
Validation loss: 2.4753860630155304

Epoch: 5| Step: 2
Training loss: 1.5023911014896645
Validation loss: 2.512052151767881

Epoch: 5| Step: 3
Training loss: 1.6685654870368858
Validation loss: 2.576946160316791

Epoch: 5| Step: 4
Training loss: 1.6958498476741162
Validation loss: 2.6271412891329957

Epoch: 5| Step: 5
Training loss: 1.7108013499534904
Validation loss: 2.728233536397199

Epoch: 5| Step: 6
Training loss: 1.3467663024091256
Validation loss: 2.740728314877289

Epoch: 5| Step: 7
Training loss: 1.4791955631639322
Validation loss: 2.706408905681766

Epoch: 5| Step: 8
Training loss: 1.664568183966853
Validation loss: 2.6740602821723494

Epoch: 5| Step: 9
Training loss: 1.0839851448125082
Validation loss: 2.601187094582857

Epoch: 5| Step: 10
Training loss: 1.710182058001074
Validation loss: 2.5728634948404197

Epoch: 201| Step: 0
Training loss: 1.3588214492611934
Validation loss: 2.5332795552999037

Epoch: 5| Step: 1
Training loss: 1.4992608792506772
Validation loss: 2.5298380892374097

Epoch: 5| Step: 2
Training loss: 1.7829925981069508
Validation loss: 2.5395904401070535

Epoch: 5| Step: 3
Training loss: 1.759648360432054
Validation loss: 2.5834715809847633

Epoch: 5| Step: 4
Training loss: 1.058389116053654
Validation loss: 2.629359375213472

Epoch: 5| Step: 5
Training loss: 1.5317045821573927
Validation loss: 2.6127132592698468

Epoch: 5| Step: 6
Training loss: 1.0872095465556044
Validation loss: 2.600342676654892

Epoch: 5| Step: 7
Training loss: 1.827039086369013
Validation loss: 2.6353784613754474

Epoch: 5| Step: 8
Training loss: 1.3542322240757523
Validation loss: 2.6285796771486627

Epoch: 5| Step: 9
Training loss: 1.3876867220221438
Validation loss: 2.5717880273192866

Epoch: 5| Step: 10
Training loss: 1.9167964172673695
Validation loss: 2.5498875915922286

Epoch: 202| Step: 0
Training loss: 1.2755531569663996
Validation loss: 2.6185548063932633

Epoch: 5| Step: 1
Training loss: 1.2741303226700709
Validation loss: 2.6198275204493315

Epoch: 5| Step: 2
Training loss: 1.534129257878801
Validation loss: 2.640348701174452

Epoch: 5| Step: 3
Training loss: 1.3497899951778252
Validation loss: 2.6292200641570305

Epoch: 5| Step: 4
Training loss: 1.554814012450289
Validation loss: 2.6269544375836773

Epoch: 5| Step: 5
Training loss: 1.197368125821723
Validation loss: 2.6121468252441145

Epoch: 5| Step: 6
Training loss: 1.3140852301374633
Validation loss: 2.646001253491137

Epoch: 5| Step: 7
Training loss: 1.8240693580507668
Validation loss: 2.638854633606222

Epoch: 5| Step: 8
Training loss: 1.3032460730497353
Validation loss: 2.6043071700719405

Epoch: 5| Step: 9
Training loss: 2.0224147259025194
Validation loss: 2.5853636299152267

Epoch: 5| Step: 10
Training loss: 1.6692280716757628
Validation loss: 2.5662365534495124

Epoch: 203| Step: 0
Training loss: 1.3484935868181114
Validation loss: 2.5139658868214347

Epoch: 5| Step: 1
Training loss: 1.6494181820968759
Validation loss: 2.506973679870816

Epoch: 5| Step: 2
Training loss: 1.528905747871141
Validation loss: 2.549516865972568

Epoch: 5| Step: 3
Training loss: 1.0308513448792012
Validation loss: 2.5582513901565984

Epoch: 5| Step: 4
Training loss: 1.719401010852502
Validation loss: 2.580807192712217

Epoch: 5| Step: 5
Training loss: 1.2812269255258346
Validation loss: 2.633859743494593

Epoch: 5| Step: 6
Training loss: 1.1187719566705314
Validation loss: 2.6715193226708207

Epoch: 5| Step: 7
Training loss: 1.6876402902568117
Validation loss: 2.68244378510482

Epoch: 5| Step: 8
Training loss: 1.7015259962133387
Validation loss: 2.6723689829380786

Epoch: 5| Step: 9
Training loss: 1.3768655086264652
Validation loss: 2.6626923392206887

Epoch: 5| Step: 10
Training loss: 1.8294202340609846
Validation loss: 2.6183833287750384

Epoch: 204| Step: 0
Training loss: 1.3653322547676128
Validation loss: 2.5827857087748223

Epoch: 5| Step: 1
Training loss: 1.1012067287919844
Validation loss: 2.5496923799168956

Epoch: 5| Step: 2
Training loss: 1.406071036925061
Validation loss: 2.5220739226777433

Epoch: 5| Step: 3
Training loss: 0.9499750774025625
Validation loss: 2.5397455576128505

Epoch: 5| Step: 4
Training loss: 1.8264618832014983
Validation loss: 2.586785181279173

Epoch: 5| Step: 5
Training loss: 1.4834086434752183
Validation loss: 2.6235037102327055

Epoch: 5| Step: 6
Training loss: 1.4256262289975967
Validation loss: 2.5895194783899362

Epoch: 5| Step: 7
Training loss: 1.7341826048666544
Validation loss: 2.6376414284566447

Epoch: 5| Step: 8
Training loss: 1.7213657242179685
Validation loss: 2.6448918932479786

Epoch: 5| Step: 9
Training loss: 1.408278718525173
Validation loss: 2.655593738884084

Epoch: 5| Step: 10
Training loss: 1.4427222057276932
Validation loss: 2.661830227771367

Epoch: 205| Step: 0
Training loss: 1.8778123109728215
Validation loss: 2.651781778858894

Epoch: 5| Step: 1
Training loss: 1.5780087418743163
Validation loss: 2.6071088447444852

Epoch: 5| Step: 2
Training loss: 1.546602706833605
Validation loss: 2.601721624264928

Epoch: 5| Step: 3
Training loss: 1.2026161504946635
Validation loss: 2.551375853614438

Epoch: 5| Step: 4
Training loss: 1.2931038131932588
Validation loss: 2.5244935261513204

Epoch: 5| Step: 5
Training loss: 0.9937284323313202
Validation loss: 2.515632891797045

Epoch: 5| Step: 6
Training loss: 1.4652976998435745
Validation loss: 2.5229807413998357

Epoch: 5| Step: 7
Training loss: 1.0748108497815918
Validation loss: 2.6093751621080497

Epoch: 5| Step: 8
Training loss: 1.681650832939401
Validation loss: 2.6881895733128403

Epoch: 5| Step: 9
Training loss: 1.5701553493834646
Validation loss: 2.7048524667599625

Epoch: 5| Step: 10
Training loss: 1.4144525148168647
Validation loss: 2.6729892570242555

Epoch: 206| Step: 0
Training loss: 1.0077967088038837
Validation loss: 2.605774109596193

Epoch: 5| Step: 1
Training loss: 1.122576912111982
Validation loss: 2.560389653446546

Epoch: 5| Step: 2
Training loss: 1.401294368752672
Validation loss: 2.602759586970977

Epoch: 5| Step: 3
Training loss: 1.554773222893836
Validation loss: 2.620488594563976

Epoch: 5| Step: 4
Training loss: 1.2576126034566149
Validation loss: 2.6182834819104057

Epoch: 5| Step: 5
Training loss: 1.9098203398805182
Validation loss: 2.642913535381129

Epoch: 5| Step: 6
Training loss: 1.545510894722181
Validation loss: 2.6369643570583663

Epoch: 5| Step: 7
Training loss: 1.369343915314043
Validation loss: 2.6635358563714537

Epoch: 5| Step: 8
Training loss: 1.3105875341529554
Validation loss: 2.6542800460550313

Epoch: 5| Step: 9
Training loss: 1.2629169644252956
Validation loss: 2.6362256343812502

Epoch: 5| Step: 10
Training loss: 1.6336916514267703
Validation loss: 2.65859415031302

Epoch: 207| Step: 0
Training loss: 1.4998213343709241
Validation loss: 2.6234251895514005

Epoch: 5| Step: 1
Training loss: 1.387175793616633
Validation loss: 2.5766564406172523

Epoch: 5| Step: 2
Training loss: 1.5129797749904093
Validation loss: 2.5535486718644576

Epoch: 5| Step: 3
Training loss: 1.3177679699255274
Validation loss: 2.5250056522273225

Epoch: 5| Step: 4
Training loss: 1.8323518842554165
Validation loss: 2.585486042728366

Epoch: 5| Step: 5
Training loss: 1.5540222584960368
Validation loss: 2.598778240370807

Epoch: 5| Step: 6
Training loss: 1.390387611272291
Validation loss: 2.665615504464948

Epoch: 5| Step: 7
Training loss: 0.8476435928454502
Validation loss: 2.6734488111744916

Epoch: 5| Step: 8
Training loss: 1.438190377352101
Validation loss: 2.7069961386236665

Epoch: 5| Step: 9
Training loss: 1.4335411956051596
Validation loss: 2.7028315314464955

Epoch: 5| Step: 10
Training loss: 0.8473969515601816
Validation loss: 2.6575202602156365

Epoch: 208| Step: 0
Training loss: 0.9352644014083328
Validation loss: 2.6008716353139785

Epoch: 5| Step: 1
Training loss: 1.392864096278346
Validation loss: 2.5570951848748473

Epoch: 5| Step: 2
Training loss: 1.2990989001260276
Validation loss: 2.529193345985187

Epoch: 5| Step: 3
Training loss: 1.4362354521516776
Validation loss: 2.5426122707492707

Epoch: 5| Step: 4
Training loss: 1.6010733997358
Validation loss: 2.593694230394471

Epoch: 5| Step: 5
Training loss: 1.5289494886019908
Validation loss: 2.6020127749042787

Epoch: 5| Step: 6
Training loss: 1.0842209016652409
Validation loss: 2.6556398452195076

Epoch: 5| Step: 7
Training loss: 1.435684550424088
Validation loss: 2.662642615904467

Epoch: 5| Step: 8
Training loss: 1.2813206164740885
Validation loss: 2.669356637811657

Epoch: 5| Step: 9
Training loss: 1.6030195353954284
Validation loss: 2.658215676012431

Epoch: 5| Step: 10
Training loss: 1.4850938361476342
Validation loss: 2.6268883186590144

Epoch: 209| Step: 0
Training loss: 1.5365127122814315
Validation loss: 2.6349707868333203

Epoch: 5| Step: 1
Training loss: 1.3711367869347382
Validation loss: 2.606856365267016

Epoch: 5| Step: 2
Training loss: 1.0353936265087207
Validation loss: 2.6117129341038083

Epoch: 5| Step: 3
Training loss: 1.6868252288158307
Validation loss: 2.5496918399791455

Epoch: 5| Step: 4
Training loss: 1.2944742985631283
Validation loss: 2.569244848242723

Epoch: 5| Step: 5
Training loss: 1.174440906293366
Validation loss: 2.510636647605566

Epoch: 5| Step: 6
Training loss: 1.4398186270084228
Validation loss: 2.531969554317162

Epoch: 5| Step: 7
Training loss: 1.4184741756171313
Validation loss: 2.5528797488287203

Epoch: 5| Step: 8
Training loss: 1.4086094877069486
Validation loss: 2.615503798642202

Epoch: 5| Step: 9
Training loss: 1.1298949456119833
Validation loss: 2.68541706828272

Epoch: 5| Step: 10
Training loss: 1.5377620101606062
Validation loss: 2.5951577576953984

Epoch: 210| Step: 0
Training loss: 1.2104713773372682
Validation loss: 2.5685820275081883

Epoch: 5| Step: 1
Training loss: 1.3984792266246646
Validation loss: 2.4980026008104863

Epoch: 5| Step: 2
Training loss: 1.3705656333274152
Validation loss: 2.4778815275416504

Epoch: 5| Step: 3
Training loss: 1.3992077714669324
Validation loss: 2.485969055276222

Epoch: 5| Step: 4
Training loss: 1.4666749621647985
Validation loss: 2.508725064399881

Epoch: 5| Step: 5
Training loss: 1.2669768472315894
Validation loss: 2.584503241037047

Epoch: 5| Step: 6
Training loss: 1.4184547621270576
Validation loss: 2.633981548319726

Epoch: 5| Step: 7
Training loss: 1.1424492657371377
Validation loss: 2.659142570469599

Epoch: 5| Step: 8
Training loss: 0.9934797507316546
Validation loss: 2.6943824365408333

Epoch: 5| Step: 9
Training loss: 1.6496920760695184
Validation loss: 2.7251211914075384

Epoch: 5| Step: 10
Training loss: 1.6423026816701072
Validation loss: 2.734771563812788

Epoch: 211| Step: 0
Training loss: 1.7225680166471535
Validation loss: 2.6780952605409563

Epoch: 5| Step: 1
Training loss: 1.183691392150632
Validation loss: 2.625928207807282

Epoch: 5| Step: 2
Training loss: 1.0506644485392933
Validation loss: 2.5838701072239676

Epoch: 5| Step: 3
Training loss: 1.1740664019708926
Validation loss: 2.5722461524385976

Epoch: 5| Step: 4
Training loss: 1.744866197806666
Validation loss: 2.607102823826038

Epoch: 5| Step: 5
Training loss: 0.9958851913825097
Validation loss: 2.657988489079024

Epoch: 5| Step: 6
Training loss: 1.4263110704912545
Validation loss: 2.6586446754381012

Epoch: 5| Step: 7
Training loss: 1.2880408660198757
Validation loss: 2.698962960656585

Epoch: 5| Step: 8
Training loss: 1.181521676121784
Validation loss: 2.7169245106523676

Epoch: 5| Step: 9
Training loss: 1.3702748344577602
Validation loss: 2.680656140123338

Epoch: 5| Step: 10
Training loss: 1.5425664063291347
Validation loss: 2.6301392456714976

Epoch: 212| Step: 0
Training loss: 1.2280098218028033
Validation loss: 2.5708442120815422

Epoch: 5| Step: 1
Training loss: 1.2675089060453566
Validation loss: 2.5172137369183676

Epoch: 5| Step: 2
Training loss: 1.5665687990394879
Validation loss: 2.527111130947629

Epoch: 5| Step: 3
Training loss: 1.1776990489817567
Validation loss: 2.514587783663409

Epoch: 5| Step: 4
Training loss: 1.6091695858128663
Validation loss: 2.539504109765551

Epoch: 5| Step: 5
Training loss: 1.0216224241608138
Validation loss: 2.6194564463627477

Epoch: 5| Step: 6
Training loss: 0.9616784751261861
Validation loss: 2.651564364611166

Epoch: 5| Step: 7
Training loss: 1.4510136514201601
Validation loss: 2.718962862241213

Epoch: 5| Step: 8
Training loss: 1.6938733439560911
Validation loss: 2.708382487896172

Epoch: 5| Step: 9
Training loss: 1.286616414765567
Validation loss: 2.710439353188923

Epoch: 5| Step: 10
Training loss: 1.4725703611548195
Validation loss: 2.6123757289779284

Epoch: 213| Step: 0
Training loss: 1.6998549399475278
Validation loss: 2.5130463401795984

Epoch: 5| Step: 1
Training loss: 1.5618048075045694
Validation loss: 2.499728950040205

Epoch: 5| Step: 2
Training loss: 1.1961202447848338
Validation loss: 2.4293147524170178

Epoch: 5| Step: 3
Training loss: 0.9264703109706959
Validation loss: 2.4326871839475026

Epoch: 5| Step: 4
Training loss: 1.3278663383373037
Validation loss: 2.476923451895361

Epoch: 5| Step: 5
Training loss: 1.403514787528778
Validation loss: 2.5563127407455006

Epoch: 5| Step: 6
Training loss: 1.3341003188855496
Validation loss: 2.672962387947551

Epoch: 5| Step: 7
Training loss: 1.0933565249445092
Validation loss: 2.7687754724569205

Epoch: 5| Step: 8
Training loss: 1.310115373641416
Validation loss: 2.8261769547953173

Epoch: 5| Step: 9
Training loss: 1.4670505837610783
Validation loss: 2.810847745291218

Epoch: 5| Step: 10
Training loss: 1.3952145652105876
Validation loss: 2.7376622311378456

Epoch: 214| Step: 0
Training loss: 1.5041316668523494
Validation loss: 2.6308671744853793

Epoch: 5| Step: 1
Training loss: 1.0909555431612399
Validation loss: 2.5071862988029303

Epoch: 5| Step: 2
Training loss: 1.3422773852909151
Validation loss: 2.4871384460404284

Epoch: 5| Step: 3
Training loss: 1.3157487353493311
Validation loss: 2.479634124483082

Epoch: 5| Step: 4
Training loss: 1.563250323384781
Validation loss: 2.551474780986796

Epoch: 5| Step: 5
Training loss: 1.363647542893217
Validation loss: 2.6620240287072563

Epoch: 5| Step: 6
Training loss: 1.4011486348249953
Validation loss: 2.757602947112087

Epoch: 5| Step: 7
Training loss: 0.890532170862116
Validation loss: 2.8239222066362464

Epoch: 5| Step: 8
Training loss: 1.4664011089903473
Validation loss: 2.8430596322390262

Epoch: 5| Step: 9
Training loss: 1.129793128935857
Validation loss: 2.779317988797442

Epoch: 5| Step: 10
Training loss: 1.607104505353818
Validation loss: 2.6936380643323683

Epoch: 215| Step: 0
Training loss: 1.2248567030258632
Validation loss: 2.6219566172838427

Epoch: 5| Step: 1
Training loss: 1.4874608940305427
Validation loss: 2.531649488258107

Epoch: 5| Step: 2
Training loss: 1.2845725731280948
Validation loss: 2.501560907271856

Epoch: 5| Step: 3
Training loss: 1.4659107442124704
Validation loss: 2.4965962953237977

Epoch: 5| Step: 4
Training loss: 1.347344846268254
Validation loss: 2.564696724223087

Epoch: 5| Step: 5
Training loss: 0.8776391623261263
Validation loss: 2.6315952234245206

Epoch: 5| Step: 6
Training loss: 1.6299870333711646
Validation loss: 2.7068744125026707

Epoch: 5| Step: 7
Training loss: 1.0983099026320138
Validation loss: 2.755970387044772

Epoch: 5| Step: 8
Training loss: 0.913431389886425
Validation loss: 2.725980336931112

Epoch: 5| Step: 9
Training loss: 1.4498126106194742
Validation loss: 2.6757629331628436

Epoch: 5| Step: 10
Training loss: 1.6630813500010129
Validation loss: 2.681543217643335

Epoch: 216| Step: 0
Training loss: 1.5455983606272548
Validation loss: 2.644754123964507

Epoch: 5| Step: 1
Training loss: 1.2182917589294808
Validation loss: 2.623548759891061

Epoch: 5| Step: 2
Training loss: 1.638734363914867
Validation loss: 2.5900224136432395

Epoch: 5| Step: 3
Training loss: 1.4358599885727221
Validation loss: 2.5683970653485773

Epoch: 5| Step: 4
Training loss: 1.2151549698071322
Validation loss: 2.5957805119820967

Epoch: 5| Step: 5
Training loss: 1.222258823140555
Validation loss: 2.590423233572915

Epoch: 5| Step: 6
Training loss: 0.9474298079265415
Validation loss: 2.5848336449575062

Epoch: 5| Step: 7
Training loss: 1.0467467158274928
Validation loss: 2.6319396875497056

Epoch: 5| Step: 8
Training loss: 1.100478538546561
Validation loss: 2.669170436376685

Epoch: 5| Step: 9
Training loss: 1.2610134834548825
Validation loss: 2.656550243378502

Epoch: 5| Step: 10
Training loss: 1.3039157435104143
Validation loss: 2.642537843983102

Epoch: 217| Step: 0
Training loss: 1.1794081098136997
Validation loss: 2.5839581663445026

Epoch: 5| Step: 1
Training loss: 1.1279933102321427
Validation loss: 2.5567937786105714

Epoch: 5| Step: 2
Training loss: 1.169241833344903
Validation loss: 2.501868670423695

Epoch: 5| Step: 3
Training loss: 1.2608759282429118
Validation loss: 2.5277977070846718

Epoch: 5| Step: 4
Training loss: 1.465478052772111
Validation loss: 2.5488658356115392

Epoch: 5| Step: 5
Training loss: 1.5022615232693854
Validation loss: 2.5691709666859284

Epoch: 5| Step: 6
Training loss: 1.1745748318818634
Validation loss: 2.6408224200114527

Epoch: 5| Step: 7
Training loss: 1.3600995117132773
Validation loss: 2.6945458152665447

Epoch: 5| Step: 8
Training loss: 1.291430985063282
Validation loss: 2.7079978741428605

Epoch: 5| Step: 9
Training loss: 1.0418982566247017
Validation loss: 2.6714563008704912

Epoch: 5| Step: 10
Training loss: 1.4450320409898545
Validation loss: 2.6263736913959637

Epoch: 218| Step: 0
Training loss: 1.5126745076038632
Validation loss: 2.5591966950781857

Epoch: 5| Step: 1
Training loss: 1.1814034720535624
Validation loss: 2.5491138228197463

Epoch: 5| Step: 2
Training loss: 1.1078769078652
Validation loss: 2.505494670064339

Epoch: 5| Step: 3
Training loss: 1.216609640396254
Validation loss: 2.5378755193900133

Epoch: 5| Step: 4
Training loss: 1.1861902844559995
Validation loss: 2.5886387056094398

Epoch: 5| Step: 5
Training loss: 1.364249292891817
Validation loss: 2.6862396333546026

Epoch: 5| Step: 6
Training loss: 1.1425746819859983
Validation loss: 2.7229654693228342

Epoch: 5| Step: 7
Training loss: 1.4769376247977892
Validation loss: 2.7584509136316697

Epoch: 5| Step: 8
Training loss: 0.8880402720422252
Validation loss: 2.669185893550398

Epoch: 5| Step: 9
Training loss: 1.3220303437419563
Validation loss: 2.6111809661476437

Epoch: 5| Step: 10
Training loss: 1.4934958269631187
Validation loss: 2.531850268896206

Epoch: 219| Step: 0
Training loss: 0.8520514807930509
Validation loss: 2.513102277511062

Epoch: 5| Step: 1
Training loss: 1.4365689123283172
Validation loss: 2.466611442416116

Epoch: 5| Step: 2
Training loss: 1.3292391871855016
Validation loss: 2.4557315190165148

Epoch: 5| Step: 3
Training loss: 1.1040387829312468
Validation loss: 2.5016593112812693

Epoch: 5| Step: 4
Training loss: 1.3223756099244814
Validation loss: 2.537797433420737

Epoch: 5| Step: 5
Training loss: 1.4941653579958651
Validation loss: 2.6707857477461876

Epoch: 5| Step: 6
Training loss: 1.2138073784478687
Validation loss: 2.740983406326047

Epoch: 5| Step: 7
Training loss: 1.5137588180675756
Validation loss: 2.803676311768168

Epoch: 5| Step: 8
Training loss: 0.8710757198092861
Validation loss: 2.7768353531599255

Epoch: 5| Step: 9
Training loss: 1.5417109130833393
Validation loss: 2.7389479011382507

Epoch: 5| Step: 10
Training loss: 0.9512408033771057
Validation loss: 2.6572490958201365

Epoch: 220| Step: 0
Training loss: 1.4963448814195177
Validation loss: 2.6231456081931683

Epoch: 5| Step: 1
Training loss: 1.1951770082362447
Validation loss: 2.5757388182326633

Epoch: 5| Step: 2
Training loss: 1.121815890824421
Validation loss: 2.5233632891477455

Epoch: 5| Step: 3
Training loss: 1.2122392610029809
Validation loss: 2.5153248028904054

Epoch: 5| Step: 4
Training loss: 1.1808977298142014
Validation loss: 2.5339628990355396

Epoch: 5| Step: 5
Training loss: 1.3037201727493588
Validation loss: 2.5722999542743885

Epoch: 5| Step: 6
Training loss: 1.0201743717369003
Validation loss: 2.6369054040201916

Epoch: 5| Step: 7
Training loss: 1.4004458705161467
Validation loss: 2.7357103256801136

Epoch: 5| Step: 8
Training loss: 1.3346796639403773
Validation loss: 2.70142615411634

Epoch: 5| Step: 9
Training loss: 1.3914202869870278
Validation loss: 2.658466799537131

Epoch: 5| Step: 10
Training loss: 1.038238715110715
Validation loss: 2.656163938456425

Epoch: 221| Step: 0
Training loss: 1.6689642407910317
Validation loss: 2.613986986453599

Epoch: 5| Step: 1
Training loss: 1.469323715814268
Validation loss: 2.546286001419763

Epoch: 5| Step: 2
Training loss: 1.1848039137290745
Validation loss: 2.5223845351117884

Epoch: 5| Step: 3
Training loss: 1.4723482088047586
Validation loss: 2.5129770589555958

Epoch: 5| Step: 4
Training loss: 1.2492282392321543
Validation loss: 2.5339074404244615

Epoch: 5| Step: 5
Training loss: 0.910242166679809
Validation loss: 2.5922616750072183

Epoch: 5| Step: 6
Training loss: 1.4117936959398953
Validation loss: 2.7068202813080577

Epoch: 5| Step: 7
Training loss: 0.9186797939127601
Validation loss: 2.7447810669699555

Epoch: 5| Step: 8
Training loss: 1.0057290594626709
Validation loss: 2.7246864428209414

Epoch: 5| Step: 9
Training loss: 0.9320090662961402
Validation loss: 2.7077039803025773

Epoch: 5| Step: 10
Training loss: 1.157866250462313
Validation loss: 2.68409575783017

Epoch: 222| Step: 0
Training loss: 1.2008530604594974
Validation loss: 2.6326449123534275

Epoch: 5| Step: 1
Training loss: 1.7814393863050344
Validation loss: 2.5798386999594665

Epoch: 5| Step: 2
Training loss: 0.9447825183586722
Validation loss: 2.5038360697980253

Epoch: 5| Step: 3
Training loss: 1.0867821132635533
Validation loss: 2.4678867087704397

Epoch: 5| Step: 4
Training loss: 1.3484317041230542
Validation loss: 2.4594068604353945

Epoch: 5| Step: 5
Training loss: 0.9528488947447429
Validation loss: 2.4495033176955947

Epoch: 5| Step: 6
Training loss: 1.0191681313887577
Validation loss: 2.5077100212834096

Epoch: 5| Step: 7
Training loss: 1.5678561912928486
Validation loss: 2.5796110678702697

Epoch: 5| Step: 8
Training loss: 1.2994697076100288
Validation loss: 2.647862119151485

Epoch: 5| Step: 9
Training loss: 1.1100095626487876
Validation loss: 2.6515574043150467

Epoch: 5| Step: 10
Training loss: 1.0295749701223695
Validation loss: 2.6511035166312693

Epoch: 223| Step: 0
Training loss: 1.162669276146702
Validation loss: 2.6617915768430627

Epoch: 5| Step: 1
Training loss: 1.0136036638598622
Validation loss: 2.6415880523124473

Epoch: 5| Step: 2
Training loss: 1.1420718383674489
Validation loss: 2.6569655437254354

Epoch: 5| Step: 3
Training loss: 1.3931776470985753
Validation loss: 2.599536829807001

Epoch: 5| Step: 4
Training loss: 1.089109330559211
Validation loss: 2.576320526571855

Epoch: 5| Step: 5
Training loss: 1.3617181862213317
Validation loss: 2.4983674420423245

Epoch: 5| Step: 6
Training loss: 0.9418096034401433
Validation loss: 2.5258857586752015

Epoch: 5| Step: 7
Training loss: 1.2938823871786787
Validation loss: 2.5141575198641193

Epoch: 5| Step: 8
Training loss: 1.591629562478045
Validation loss: 2.5287064062982045

Epoch: 5| Step: 9
Training loss: 1.0729769100324995
Validation loss: 2.5755782837910868

Epoch: 5| Step: 10
Training loss: 1.3546708806656327
Validation loss: 2.5978629609264705

Epoch: 224| Step: 0
Training loss: 1.2320217444247288
Validation loss: 2.6598791049411714

Epoch: 5| Step: 1
Training loss: 0.8737902793822938
Validation loss: 2.6508779560831064

Epoch: 5| Step: 2
Training loss: 1.35129540069843
Validation loss: 2.592875441315662

Epoch: 5| Step: 3
Training loss: 1.5689702916587644
Validation loss: 2.567839684388563

Epoch: 5| Step: 4
Training loss: 1.0747003758738722
Validation loss: 2.5371225301092095

Epoch: 5| Step: 5
Training loss: 1.202632357318015
Validation loss: 2.545080740051829

Epoch: 5| Step: 6
Training loss: 1.4356840522256076
Validation loss: 2.5586741309810725

Epoch: 5| Step: 7
Training loss: 1.1259194960942727
Validation loss: 2.559216343061672

Epoch: 5| Step: 8
Training loss: 1.0667420022904712
Validation loss: 2.617613353804641

Epoch: 5| Step: 9
Training loss: 1.2685812814463677
Validation loss: 2.658518591295479

Epoch: 5| Step: 10
Training loss: 1.0953001753566702
Validation loss: 2.7055838092433957

Epoch: 225| Step: 0
Training loss: 0.981200412542083
Validation loss: 2.7234662038318764

Epoch: 5| Step: 1
Training loss: 1.2836598319505086
Validation loss: 2.7097368760600458

Epoch: 5| Step: 2
Training loss: 1.3580545172415692
Validation loss: 2.683137244321607

Epoch: 5| Step: 3
Training loss: 1.1431992627565264
Validation loss: 2.606261816731058

Epoch: 5| Step: 4
Training loss: 0.9482478761355015
Validation loss: 2.564400974997374

Epoch: 5| Step: 5
Training loss: 1.2676874475109081
Validation loss: 2.492577932298426

Epoch: 5| Step: 6
Training loss: 1.379591039653159
Validation loss: 2.529076774986283

Epoch: 5| Step: 7
Training loss: 1.345063299653616
Validation loss: 2.5369744814299766

Epoch: 5| Step: 8
Training loss: 0.6948477659973654
Validation loss: 2.5812902883074926

Epoch: 5| Step: 9
Training loss: 1.676920328057243
Validation loss: 2.641114761030925

Epoch: 5| Step: 10
Training loss: 0.7845805700465841
Validation loss: 2.680673974044978

Epoch: 226| Step: 0
Training loss: 1.0477911513122204
Validation loss: 2.685118176621298

Epoch: 5| Step: 1
Training loss: 1.6820991413821595
Validation loss: 2.753449836960005

Epoch: 5| Step: 2
Training loss: 1.181887463726328
Validation loss: 2.7313141767193616

Epoch: 5| Step: 3
Training loss: 1.1872904743260662
Validation loss: 2.7194459133177813

Epoch: 5| Step: 4
Training loss: 1.4247553230503485
Validation loss: 2.625737106776652

Epoch: 5| Step: 5
Training loss: 1.1171515932515077
Validation loss: 2.5365275597401458

Epoch: 5| Step: 6
Training loss: 1.2688102670270993
Validation loss: 2.4841903945050485

Epoch: 5| Step: 7
Training loss: 0.9982549819917504
Validation loss: 2.506166536638772

Epoch: 5| Step: 8
Training loss: 1.3831095834347775
Validation loss: 2.5402724161971753

Epoch: 5| Step: 9
Training loss: 0.8418329147094137
Validation loss: 2.5541191952893616

Epoch: 5| Step: 10
Training loss: 0.6217852407882314
Validation loss: 2.621327439198337

Epoch: 227| Step: 0
Training loss: 1.232240690766158
Validation loss: 2.6603800496508074

Epoch: 5| Step: 1
Training loss: 1.132786612379309
Validation loss: 2.6807725672484812

Epoch: 5| Step: 2
Training loss: 1.103323644632017
Validation loss: 2.694588326210926

Epoch: 5| Step: 3
Training loss: 1.4443440259767601
Validation loss: 2.698036759095455

Epoch: 5| Step: 4
Training loss: 1.0971307548727538
Validation loss: 2.661976188690281

Epoch: 5| Step: 5
Training loss: 0.6590279863779506
Validation loss: 2.578555636767832

Epoch: 5| Step: 6
Training loss: 0.8536233724851479
Validation loss: 2.571872523393616

Epoch: 5| Step: 7
Training loss: 1.5168453691163823
Validation loss: 2.581179202184796

Epoch: 5| Step: 8
Training loss: 1.1264289152437037
Validation loss: 2.601218400887165

Epoch: 5| Step: 9
Training loss: 1.2584951218854157
Validation loss: 2.620420415507425

Epoch: 5| Step: 10
Training loss: 1.166954442136049
Validation loss: 2.6105224432644407

Epoch: 228| Step: 0
Training loss: 1.4032368485829934
Validation loss: 2.604065578016337

Epoch: 5| Step: 1
Training loss: 1.1168579469135653
Validation loss: 2.61874406149044

Epoch: 5| Step: 2
Training loss: 1.2570157104062745
Validation loss: 2.576048555825995

Epoch: 5| Step: 3
Training loss: 0.6227572015845927
Validation loss: 2.550289486115199

Epoch: 5| Step: 4
Training loss: 1.0220127817761828
Validation loss: 2.5438938314770514

Epoch: 5| Step: 5
Training loss: 1.1696266476871406
Validation loss: 2.5340992083836507

Epoch: 5| Step: 6
Training loss: 0.9587955949428297
Validation loss: 2.5570617898937513

Epoch: 5| Step: 7
Training loss: 1.4728866923014698
Validation loss: 2.5759417714343034

Epoch: 5| Step: 8
Training loss: 1.2734386233459385
Validation loss: 2.5983524267663625

Epoch: 5| Step: 9
Training loss: 0.9042239396608993
Validation loss: 2.599979421417418

Epoch: 5| Step: 10
Training loss: 1.2710418165367616
Validation loss: 2.6055472982115884

Epoch: 229| Step: 0
Training loss: 0.7540626561290771
Validation loss: 2.595805655637555

Epoch: 5| Step: 1
Training loss: 1.0241671574660993
Validation loss: 2.559176437883337

Epoch: 5| Step: 2
Training loss: 1.5440832048736874
Validation loss: 2.5651536332832574

Epoch: 5| Step: 3
Training loss: 1.179104540955246
Validation loss: 2.5255556569971933

Epoch: 5| Step: 4
Training loss: 0.9784020150450061
Validation loss: 2.558202736415779

Epoch: 5| Step: 5
Training loss: 1.0151408288532116
Validation loss: 2.598854589778605

Epoch: 5| Step: 6
Training loss: 1.1043262306416373
Validation loss: 2.6036477711860555

Epoch: 5| Step: 7
Training loss: 1.1087684585084163
Validation loss: 2.5732077841194507

Epoch: 5| Step: 8
Training loss: 1.2347835395862623
Validation loss: 2.585919938676721

Epoch: 5| Step: 9
Training loss: 0.8404169300200605
Validation loss: 2.629273399746604

Epoch: 5| Step: 10
Training loss: 1.5034474651519427
Validation loss: 2.6409508987694874

Epoch: 230| Step: 0
Training loss: 1.2662158575849431
Validation loss: 2.6104814839680617

Epoch: 5| Step: 1
Training loss: 0.671720864114498
Validation loss: 2.550938431614488

Epoch: 5| Step: 2
Training loss: 1.3419462562265767
Validation loss: 2.534502553493397

Epoch: 5| Step: 3
Training loss: 1.0180650596701226
Validation loss: 2.5292754417807104

Epoch: 5| Step: 4
Training loss: 1.1049528501989212
Validation loss: 2.53600526777437

Epoch: 5| Step: 5
Training loss: 1.4818061685846409
Validation loss: 2.576666192587186

Epoch: 5| Step: 6
Training loss: 1.234866032535117
Validation loss: 2.5784607152542875

Epoch: 5| Step: 7
Training loss: 1.0166525704287332
Validation loss: 2.570584614381792

Epoch: 5| Step: 8
Training loss: 0.8952157013178368
Validation loss: 2.625882513610492

Epoch: 5| Step: 9
Training loss: 1.0525790579454841
Validation loss: 2.6147732330911806

Epoch: 5| Step: 10
Training loss: 1.0343600107818371
Validation loss: 2.6502458440937837

Epoch: 231| Step: 0
Training loss: 1.1665369143312863
Validation loss: 2.6332615669936597

Epoch: 5| Step: 1
Training loss: 1.0919680111534895
Validation loss: 2.594161998072488

Epoch: 5| Step: 2
Training loss: 0.8309318550322685
Validation loss: 2.588246133523999

Epoch: 5| Step: 3
Training loss: 0.9989698886037279
Validation loss: 2.564589991969516

Epoch: 5| Step: 4
Training loss: 1.272005457830416
Validation loss: 2.612595314233663

Epoch: 5| Step: 5
Training loss: 1.0195023105065701
Validation loss: 2.58366579925975

Epoch: 5| Step: 6
Training loss: 1.3533244472753756
Validation loss: 2.6081572047574615

Epoch: 5| Step: 7
Training loss: 1.3630983945969055
Validation loss: 2.606304651238566

Epoch: 5| Step: 8
Training loss: 1.0962996601439992
Validation loss: 2.600232343846544

Epoch: 5| Step: 9
Training loss: 0.8023894002644085
Validation loss: 2.5957407511478

Epoch: 5| Step: 10
Training loss: 1.1656928709995642
Validation loss: 2.5753961693425

Epoch: 232| Step: 0
Training loss: 1.1001953948481573
Validation loss: 2.5484775796104615

Epoch: 5| Step: 1
Training loss: 1.1763561782182412
Validation loss: 2.5435693939216195

Epoch: 5| Step: 2
Training loss: 1.2955376957334295
Validation loss: 2.5113584249482064

Epoch: 5| Step: 3
Training loss: 1.2403654735091327
Validation loss: 2.5748944229925232

Epoch: 5| Step: 4
Training loss: 1.0228066283563597
Validation loss: 2.6402047552173813

Epoch: 5| Step: 5
Training loss: 1.1716733123153105
Validation loss: 2.673349378247316

Epoch: 5| Step: 6
Training loss: 0.9963019060041036
Validation loss: 2.681331758968639

Epoch: 5| Step: 7
Training loss: 0.484650472017336
Validation loss: 2.6423955482500276

Epoch: 5| Step: 8
Training loss: 1.4070733944661702
Validation loss: 2.6106909796657667

Epoch: 5| Step: 9
Training loss: 0.9475906600959639
Validation loss: 2.5800864098659084

Epoch: 5| Step: 10
Training loss: 1.1066974510848075
Validation loss: 2.525536675947914

Epoch: 233| Step: 0
Training loss: 1.038139047636726
Validation loss: 2.5518982556260634

Epoch: 5| Step: 1
Training loss: 0.8613590226286598
Validation loss: 2.542085570362966

Epoch: 5| Step: 2
Training loss: 1.4791689680197995
Validation loss: 2.556662536736267

Epoch: 5| Step: 3
Training loss: 0.8568109234336169
Validation loss: 2.572148698714709

Epoch: 5| Step: 4
Training loss: 0.7816633656790629
Validation loss: 2.5968661388187146

Epoch: 5| Step: 5
Training loss: 0.8892631492060824
Validation loss: 2.580754531797454

Epoch: 5| Step: 6
Training loss: 1.2795925119100435
Validation loss: 2.599187970807778

Epoch: 5| Step: 7
Training loss: 1.4117341657682452
Validation loss: 2.5889789473328992

Epoch: 5| Step: 8
Training loss: 0.9568484696211703
Validation loss: 2.518505251609775

Epoch: 5| Step: 9
Training loss: 1.0154140546783634
Validation loss: 2.4605808127829603

Epoch: 5| Step: 10
Training loss: 1.0724305962289715
Validation loss: 2.4807983727195464

Epoch: 234| Step: 0
Training loss: 0.8309790535385904
Validation loss: 2.469813065928283

Epoch: 5| Step: 1
Training loss: 1.089773086936892
Validation loss: 2.4722186272849154

Epoch: 5| Step: 2
Training loss: 1.066755021181128
Validation loss: 2.5277404803439625

Epoch: 5| Step: 3
Training loss: 1.0838348010543686
Validation loss: 2.611687532792549

Epoch: 5| Step: 4
Training loss: 0.7740873438914373
Validation loss: 2.617745271134879

Epoch: 5| Step: 5
Training loss: 0.8655799537258021
Validation loss: 2.6790743057798627

Epoch: 5| Step: 6
Training loss: 1.3109945564447982
Validation loss: 2.685835382650146

Epoch: 5| Step: 7
Training loss: 1.027728454735181
Validation loss: 2.694018836794258

Epoch: 5| Step: 8
Training loss: 1.3252570658655345
Validation loss: 2.667609010466796

Epoch: 5| Step: 9
Training loss: 1.3483048799260806
Validation loss: 2.6416667978474266

Epoch: 5| Step: 10
Training loss: 0.8057898220976982
Validation loss: 2.5506807479050737

Epoch: 235| Step: 0
Training loss: 1.0000381462450882
Validation loss: 2.539535080162949

Epoch: 5| Step: 1
Training loss: 1.3815318928977898
Validation loss: 2.52360997394289

Epoch: 5| Step: 2
Training loss: 0.636999758629027
Validation loss: 2.529209188814166

Epoch: 5| Step: 3
Training loss: 1.3469530122826718
Validation loss: 2.5259567907849316

Epoch: 5| Step: 4
Training loss: 0.9900675676388432
Validation loss: 2.570763118663446

Epoch: 5| Step: 5
Training loss: 0.703265832996022
Validation loss: 2.6049216421794026

Epoch: 5| Step: 6
Training loss: 1.1400964635894029
Validation loss: 2.5822659208172545

Epoch: 5| Step: 7
Training loss: 1.062257851327209
Validation loss: 2.613491303068147

Epoch: 5| Step: 8
Training loss: 0.9089330877598181
Validation loss: 2.6134761722463122

Epoch: 5| Step: 9
Training loss: 1.0450125681655227
Validation loss: 2.576303974883876

Epoch: 5| Step: 10
Training loss: 1.1519434864136384
Validation loss: 2.5781068952265924

Epoch: 236| Step: 0
Training loss: 0.6799512767867
Validation loss: 2.568314705830699

Epoch: 5| Step: 1
Training loss: 1.2199287582921503
Validation loss: 2.564483893064104

Epoch: 5| Step: 2
Training loss: 1.0103806295883442
Validation loss: 2.5555239727939374

Epoch: 5| Step: 3
Training loss: 0.9369758730299128
Validation loss: 2.5590894499309864

Epoch: 5| Step: 4
Training loss: 1.334440184169162
Validation loss: 2.5522685218373855

Epoch: 5| Step: 5
Training loss: 1.3649191649399512
Validation loss: 2.529335044046729

Epoch: 5| Step: 6
Training loss: 1.1676604205240435
Validation loss: 2.5116448073597444

Epoch: 5| Step: 7
Training loss: 0.725626270513219
Validation loss: 2.5355577152099644

Epoch: 5| Step: 8
Training loss: 0.8457965402790822
Validation loss: 2.5263576427079806

Epoch: 5| Step: 9
Training loss: 0.8859628488725512
Validation loss: 2.5814756345716114

Epoch: 5| Step: 10
Training loss: 0.9760867982008927
Validation loss: 2.619092884093399

Epoch: 237| Step: 0
Training loss: 1.0289716116174674
Validation loss: 2.667545609891405

Epoch: 5| Step: 1
Training loss: 1.0396554158714875
Validation loss: 2.689585217083898

Epoch: 5| Step: 2
Training loss: 1.476064042823839
Validation loss: 2.635283245999446

Epoch: 5| Step: 3
Training loss: 0.7863454590358808
Validation loss: 2.6364704392221845

Epoch: 5| Step: 4
Training loss: 0.7837223225137235
Validation loss: 2.626553473763594

Epoch: 5| Step: 5
Training loss: 0.8234286023696156
Validation loss: 2.5758532397080844

Epoch: 5| Step: 6
Training loss: 1.15420733264292
Validation loss: 2.5920137182588237

Epoch: 5| Step: 7
Training loss: 0.957673273966863
Validation loss: 2.6019646960890155

Epoch: 5| Step: 8
Training loss: 0.9990337591299949
Validation loss: 2.531073449775049

Epoch: 5| Step: 9
Training loss: 0.9245896537556708
Validation loss: 2.4893029301709118

Epoch: 5| Step: 10
Training loss: 1.17364317695306
Validation loss: 2.4711058718059777

Epoch: 238| Step: 0
Training loss: 1.1589258521835533
Validation loss: 2.474964315978173

Epoch: 5| Step: 1
Training loss: 0.7417897815174351
Validation loss: 2.4852437807699563

Epoch: 5| Step: 2
Training loss: 1.097171228299564
Validation loss: 2.542781185716242

Epoch: 5| Step: 3
Training loss: 0.7550742633245228
Validation loss: 2.5952872267475735

Epoch: 5| Step: 4
Training loss: 1.3731720217543906
Validation loss: 2.656971652344436

Epoch: 5| Step: 5
Training loss: 1.110142724252084
Validation loss: 2.683247371691042

Epoch: 5| Step: 6
Training loss: 1.1491028292220673
Validation loss: 2.692394191060551

Epoch: 5| Step: 7
Training loss: 0.8412662967049974
Validation loss: 2.619208398874583

Epoch: 5| Step: 8
Training loss: 0.7541547770818734
Validation loss: 2.5402006853492143

Epoch: 5| Step: 9
Training loss: 1.0861798571732522
Validation loss: 2.4697514599495616

Epoch: 5| Step: 10
Training loss: 1.0522917487557868
Validation loss: 2.4485068366243192

Epoch: 239| Step: 0
Training loss: 0.879433537306
Validation loss: 2.506769304184773

Epoch: 5| Step: 1
Training loss: 1.0742954850966335
Validation loss: 2.5398031093931586

Epoch: 5| Step: 2
Training loss: 0.9210447678552958
Validation loss: 2.614203057021439

Epoch: 5| Step: 3
Training loss: 0.8717491182082683
Validation loss: 2.6460017243636416

Epoch: 5| Step: 4
Training loss: 1.0414588085055707
Validation loss: 2.6958541166617

Epoch: 5| Step: 5
Training loss: 1.0279855790147212
Validation loss: 2.648481155642149

Epoch: 5| Step: 6
Training loss: 0.8107851712258307
Validation loss: 2.6283532224239163

Epoch: 5| Step: 7
Training loss: 1.1491330693796815
Validation loss: 2.589903049213596

Epoch: 5| Step: 8
Training loss: 0.8387069460283628
Validation loss: 2.5848408563326353

Epoch: 5| Step: 9
Training loss: 1.3947606686069374
Validation loss: 2.5301778313504637

Epoch: 5| Step: 10
Training loss: 0.9180842550129446
Validation loss: 2.509630864970704

Epoch: 240| Step: 0
Training loss: 0.8388882901931322
Validation loss: 2.489965228230725

Epoch: 5| Step: 1
Training loss: 0.8317316796521284
Validation loss: 2.4652128663318718

Epoch: 5| Step: 2
Training loss: 1.409307250701522
Validation loss: 2.5109937437989114

Epoch: 5| Step: 3
Training loss: 0.9993518576647257
Validation loss: 2.5115832414388306

Epoch: 5| Step: 4
Training loss: 1.0294779377593242
Validation loss: 2.5125702195693007

Epoch: 5| Step: 5
Training loss: 0.6863845098583848
Validation loss: 2.5572791630036362

Epoch: 5| Step: 6
Training loss: 0.9670971953058581
Validation loss: 2.6031158263137373

Epoch: 5| Step: 7
Training loss: 0.8270208447261421
Validation loss: 2.629657129999945

Epoch: 5| Step: 8
Training loss: 0.7774474875082077
Validation loss: 2.621822962098516

Epoch: 5| Step: 9
Training loss: 1.1030586849520383
Validation loss: 2.614539607186179

Epoch: 5| Step: 10
Training loss: 1.2121917136055904
Validation loss: 2.62947710257798

Epoch: 241| Step: 0
Training loss: 0.794030892239597
Validation loss: 2.6069979378447488

Epoch: 5| Step: 1
Training loss: 0.919031964066845
Validation loss: 2.5558694914458644

Epoch: 5| Step: 2
Training loss: 0.8789330033363125
Validation loss: 2.519891115501786

Epoch: 5| Step: 3
Training loss: 0.8168029551414289
Validation loss: 2.4812143499871055

Epoch: 5| Step: 4
Training loss: 0.8195216408339849
Validation loss: 2.5062340232281164

Epoch: 5| Step: 5
Training loss: 1.0244386159101697
Validation loss: 2.5115748587049813

Epoch: 5| Step: 6
Training loss: 0.8493586729387801
Validation loss: 2.5725814490031427

Epoch: 5| Step: 7
Training loss: 0.9793754348315726
Validation loss: 2.644610723149954

Epoch: 5| Step: 8
Training loss: 1.5737341804709175
Validation loss: 2.6593551485966684

Epoch: 5| Step: 9
Training loss: 1.058977289855062
Validation loss: 2.664887888359738

Epoch: 5| Step: 10
Training loss: 0.9148775037472464
Validation loss: 2.6155722871850817

Epoch: 242| Step: 0
Training loss: 0.8204735734020835
Validation loss: 2.5968857634034666

Epoch: 5| Step: 1
Training loss: 0.7385751452119256
Validation loss: 2.5588663461508867

Epoch: 5| Step: 2
Training loss: 0.9780352664041938
Validation loss: 2.49589192742818

Epoch: 5| Step: 3
Training loss: 1.0320392247367653
Validation loss: 2.4737990682444844

Epoch: 5| Step: 4
Training loss: 0.8898394617206777
Validation loss: 2.494378657997262

Epoch: 5| Step: 5
Training loss: 0.9665680585640324
Validation loss: 2.4869822254665697

Epoch: 5| Step: 6
Training loss: 1.1860514891353013
Validation loss: 2.488673576599452

Epoch: 5| Step: 7
Training loss: 1.5176851094951325
Validation loss: 2.518411083967468

Epoch: 5| Step: 8
Training loss: 1.0817358391797838
Validation loss: 2.532768231725632

Epoch: 5| Step: 9
Training loss: 0.5508380617101334
Validation loss: 2.6074893124327265

Epoch: 5| Step: 10
Training loss: 0.5565860119179422
Validation loss: 2.616907663679536

Epoch: 243| Step: 0
Training loss: 1.4583611440277446
Validation loss: 2.6226976633601446

Epoch: 5| Step: 1
Training loss: 1.1729711365234032
Validation loss: 2.591555372030692

Epoch: 5| Step: 2
Training loss: 0.9020705036428586
Validation loss: 2.567631612750309

Epoch: 5| Step: 3
Training loss: 0.8967553354641107
Validation loss: 2.553051747523753

Epoch: 5| Step: 4
Training loss: 1.1201211252450947
Validation loss: 2.512399243851906

Epoch: 5| Step: 5
Training loss: 1.102328744160301
Validation loss: 2.5351523142674

Epoch: 5| Step: 6
Training loss: 0.8680183966418695
Validation loss: 2.549618502902381

Epoch: 5| Step: 7
Training loss: 0.5022050396100106
Validation loss: 2.5920849914522797

Epoch: 5| Step: 8
Training loss: 0.7466465764308959
Validation loss: 2.6088807938132623

Epoch: 5| Step: 9
Training loss: 0.7718957890479341
Validation loss: 2.6352993873675654

Epoch: 5| Step: 10
Training loss: 0.4682646623027676
Validation loss: 2.629632685359109

Epoch: 244| Step: 0
Training loss: 1.3735358939658746
Validation loss: 2.6281079216814653

Epoch: 5| Step: 1
Training loss: 0.7798704173581216
Validation loss: 2.6289369385420147

Epoch: 5| Step: 2
Training loss: 0.9032458135453465
Validation loss: 2.5652507701152167

Epoch: 5| Step: 3
Training loss: 0.6653050634309876
Validation loss: 2.5631216852255427

Epoch: 5| Step: 4
Training loss: 0.8774574715614177
Validation loss: 2.48883955689194

Epoch: 5| Step: 5
Training loss: 0.8335042460332867
Validation loss: 2.4864515110215106

Epoch: 5| Step: 6
Training loss: 1.0882634015615353
Validation loss: 2.475775940594076

Epoch: 5| Step: 7
Training loss: 1.1662088869786287
Validation loss: 2.539202423657569

Epoch: 5| Step: 8
Training loss: 0.9206073903810034
Validation loss: 2.580546723623864

Epoch: 5| Step: 9
Training loss: 0.7701330010621225
Validation loss: 2.60832684147295

Epoch: 5| Step: 10
Training loss: 0.7594928791247236
Validation loss: 2.640273139968255

Epoch: 245| Step: 0
Training loss: 1.213135379784195
Validation loss: 2.644856652902706

Epoch: 5| Step: 1
Training loss: 0.8192543834886802
Validation loss: 2.6311130763881656

Epoch: 5| Step: 2
Training loss: 0.7647985941851038
Validation loss: 2.6172976646201778

Epoch: 5| Step: 3
Training loss: 1.0037695646932698
Validation loss: 2.6228882283478874

Epoch: 5| Step: 4
Training loss: 0.8024858150238633
Validation loss: 2.601281762846504

Epoch: 5| Step: 5
Training loss: 1.107458635423138
Validation loss: 2.5650352284285605

Epoch: 5| Step: 6
Training loss: 0.7910421484750749
Validation loss: 2.5331902784436293

Epoch: 5| Step: 7
Training loss: 0.791172454734327
Validation loss: 2.5607659149764435

Epoch: 5| Step: 8
Training loss: 0.9602304353913278
Validation loss: 2.538193972126638

Epoch: 5| Step: 9
Training loss: 0.9792028210776182
Validation loss: 2.5495616543321633

Epoch: 5| Step: 10
Training loss: 1.0964874887235359
Validation loss: 2.5364596930837506

Epoch: 246| Step: 0
Training loss: 1.092691290582799
Validation loss: 2.5838683173471098

Epoch: 5| Step: 1
Training loss: 0.9445866722336226
Validation loss: 2.56449225679938

Epoch: 5| Step: 2
Training loss: 0.8781389405036585
Validation loss: 2.586389027149919

Epoch: 5| Step: 3
Training loss: 1.023003522574139
Validation loss: 2.598944782314886

Epoch: 5| Step: 4
Training loss: 0.9283666764874039
Validation loss: 2.5701809709297914

Epoch: 5| Step: 5
Training loss: 0.716575484426436
Validation loss: 2.526324573570658

Epoch: 5| Step: 6
Training loss: 0.7802177094191973
Validation loss: 2.5682541809661297

Epoch: 5| Step: 7
Training loss: 0.613617774331808
Validation loss: 2.555346148623082

Epoch: 5| Step: 8
Training loss: 0.6585146339473311
Validation loss: 2.5877915987961164

Epoch: 5| Step: 9
Training loss: 0.8862084083859011
Validation loss: 2.577893313540744

Epoch: 5| Step: 10
Training loss: 1.4066320959847993
Validation loss: 2.5860438934518366

Epoch: 247| Step: 0
Training loss: 0.6773991044073208
Validation loss: 2.565335122748479

Epoch: 5| Step: 1
Training loss: 1.3698780723945978
Validation loss: 2.5372192810681575

Epoch: 5| Step: 2
Training loss: 0.6352649778651824
Validation loss: 2.5262978956104902

Epoch: 5| Step: 3
Training loss: 0.6488956533403119
Validation loss: 2.4921503122426265

Epoch: 5| Step: 4
Training loss: 0.9233281595266473
Validation loss: 2.4862795754153173

Epoch: 5| Step: 5
Training loss: 0.9472538583555596
Validation loss: 2.5487109774542787

Epoch: 5| Step: 6
Training loss: 1.0121023268400864
Validation loss: 2.6193622230691105

Epoch: 5| Step: 7
Training loss: 0.8006883893018856
Validation loss: 2.6519598145878365

Epoch: 5| Step: 8
Training loss: 0.8861097353410022
Validation loss: 2.658240078660358

Epoch: 5| Step: 9
Training loss: 0.950644031361744
Validation loss: 2.608176954731184

Epoch: 5| Step: 10
Training loss: 1.0063779216511204
Validation loss: 2.581091495211873

Epoch: 248| Step: 0
Training loss: 0.8351031979731329
Validation loss: 2.551987605322203

Epoch: 5| Step: 1
Training loss: 0.8071134350004096
Validation loss: 2.5457700568006887

Epoch: 5| Step: 2
Training loss: 0.9936559728607713
Validation loss: 2.506860868802178

Epoch: 5| Step: 3
Training loss: 1.1304692203122673
Validation loss: 2.5300426178640008

Epoch: 5| Step: 4
Training loss: 0.9133296865601607
Validation loss: 2.5058661435456364

Epoch: 5| Step: 5
Training loss: 1.0364336301584924
Validation loss: 2.4970612111480928

Epoch: 5| Step: 6
Training loss: 0.9536954704685091
Validation loss: 2.4952996536365877

Epoch: 5| Step: 7
Training loss: 0.9191479839479434
Validation loss: 2.4767410670967904

Epoch: 5| Step: 8
Training loss: 0.7973578243220727
Validation loss: 2.5147896736895827

Epoch: 5| Step: 9
Training loss: 0.7200917698073453
Validation loss: 2.4541377280230594

Epoch: 5| Step: 10
Training loss: 0.734079748010326
Validation loss: 2.5138430354303605

Epoch: 249| Step: 0
Training loss: 1.0116324958707388
Validation loss: 2.5240673012122383

Epoch: 5| Step: 1
Training loss: 1.1170000039000754
Validation loss: 2.521160762115684

Epoch: 5| Step: 2
Training loss: 0.6848201540677366
Validation loss: 2.5212191418104357

Epoch: 5| Step: 3
Training loss: 1.2338695698532527
Validation loss: 2.5526975189417325

Epoch: 5| Step: 4
Training loss: 0.8422781504464076
Validation loss: 2.514809929592018

Epoch: 5| Step: 5
Training loss: 0.7875878179116609
Validation loss: 2.5161789584997747

Epoch: 5| Step: 6
Training loss: 0.8562871075685268
Validation loss: 2.5278714774256574

Epoch: 5| Step: 7
Training loss: 0.5268998715106419
Validation loss: 2.5497755138842346

Epoch: 5| Step: 8
Training loss: 1.2315994154172665
Validation loss: 2.5600828289980986

Epoch: 5| Step: 9
Training loss: 0.5161806926895047
Validation loss: 2.5459465978511666

Epoch: 5| Step: 10
Training loss: 0.47970087051396115
Validation loss: 2.532302981779634

Epoch: 250| Step: 0
Training loss: 0.5188225235857086
Validation loss: 2.5391680578308655

Epoch: 5| Step: 1
Training loss: 1.1596975222385546
Validation loss: 2.5688521865444978

Epoch: 5| Step: 2
Training loss: 0.9498909975560389
Validation loss: 2.5430909358322387

Epoch: 5| Step: 3
Training loss: 1.0460205006897136
Validation loss: 2.55079874569985

Epoch: 5| Step: 4
Training loss: 0.7803348139947496
Validation loss: 2.5511199164028096

Epoch: 5| Step: 5
Training loss: 0.8655793684076583
Validation loss: 2.581240953483561

Epoch: 5| Step: 6
Training loss: 0.7017786699736749
Validation loss: 2.573023015989936

Epoch: 5| Step: 7
Training loss: 0.8234102885257883
Validation loss: 2.546770973579943

Epoch: 5| Step: 8
Training loss: 0.759410431902597
Validation loss: 2.547096427523804

Epoch: 5| Step: 9
Training loss: 1.0731977014459428
Validation loss: 2.5686757421612363

Epoch: 5| Step: 10
Training loss: 0.7422299423128775
Validation loss: 2.548051400482991

Epoch: 251| Step: 0
Training loss: 1.1057190089478688
Validation loss: 2.5508565747270584

Epoch: 5| Step: 1
Training loss: 0.8454722734729311
Validation loss: 2.5058781470293865

Epoch: 5| Step: 2
Training loss: 0.9413174155967915
Validation loss: 2.5262452974101297

Epoch: 5| Step: 3
Training loss: 0.8581957963049762
Validation loss: 2.5261574230982236

Epoch: 5| Step: 4
Training loss: 1.004011571680688
Validation loss: 2.5637311191535264

Epoch: 5| Step: 5
Training loss: 0.3242632708947709
Validation loss: 2.5865833613651783

Epoch: 5| Step: 6
Training loss: 0.9343648303955259
Validation loss: 2.5587160698856737

Epoch: 5| Step: 7
Training loss: 0.7559339304189625
Validation loss: 2.5799889949326347

Epoch: 5| Step: 8
Training loss: 0.8613350450579441
Validation loss: 2.5733008311922103

Epoch: 5| Step: 9
Training loss: 0.901149107567314
Validation loss: 2.5520164743839953

Epoch: 5| Step: 10
Training loss: 0.7074138386026091
Validation loss: 2.608662062400543

Epoch: 252| Step: 0
Training loss: 0.3946858282650348
Validation loss: 2.5590834612924684

Epoch: 5| Step: 1
Training loss: 1.0384516246844109
Validation loss: 2.5371325760034997

Epoch: 5| Step: 2
Training loss: 0.6015700302643541
Validation loss: 2.5431109335525073

Epoch: 5| Step: 3
Training loss: 0.8049353060582489
Validation loss: 2.5148688573354603

Epoch: 5| Step: 4
Training loss: 1.043813927343119
Validation loss: 2.5403156055146985

Epoch: 5| Step: 5
Training loss: 0.6544257876809275
Validation loss: 2.5384506086519636

Epoch: 5| Step: 6
Training loss: 1.26898359957559
Validation loss: 2.5816714498255444

Epoch: 5| Step: 7
Training loss: 0.6986017755104172
Validation loss: 2.5862039442962543

Epoch: 5| Step: 8
Training loss: 0.7601954952824099
Validation loss: 2.5237249080360558

Epoch: 5| Step: 9
Training loss: 1.0695891894745022
Validation loss: 2.517437089040567

Epoch: 5| Step: 10
Training loss: 0.8143597007245349
Validation loss: 2.4607079537708243

Epoch: 253| Step: 0
Training loss: 0.9840035721745044
Validation loss: 2.492492595386001

Epoch: 5| Step: 1
Training loss: 0.5931792778849643
Validation loss: 2.487198960141415

Epoch: 5| Step: 2
Training loss: 0.8838384625027499
Validation loss: 2.5186979189659073

Epoch: 5| Step: 3
Training loss: 0.998321256601677
Validation loss: 2.5553560285699475

Epoch: 5| Step: 4
Training loss: 0.8096057253686029
Validation loss: 2.621845028208852

Epoch: 5| Step: 5
Training loss: 0.8074939638390526
Validation loss: 2.6274495042051496

Epoch: 5| Step: 6
Training loss: 0.8115111348933031
Validation loss: 2.6266374856982084

Epoch: 5| Step: 7
Training loss: 0.9366883897355257
Validation loss: 2.5933536840059443

Epoch: 5| Step: 8
Training loss: 1.0873832683834295
Validation loss: 2.560335660909426

Epoch: 5| Step: 9
Training loss: 0.7489148873225643
Validation loss: 2.489698542179484

Epoch: 5| Step: 10
Training loss: 0.6641984239482014
Validation loss: 2.477512552507223

Epoch: 254| Step: 0
Training loss: 0.9812827815514673
Validation loss: 2.467167952936521

Epoch: 5| Step: 1
Training loss: 0.9781456893341545
Validation loss: 2.500319599929224

Epoch: 5| Step: 2
Training loss: 0.7496115552782054
Validation loss: 2.5240217069971047

Epoch: 5| Step: 3
Training loss: 0.6249982357000244
Validation loss: 2.6011006284861837

Epoch: 5| Step: 4
Training loss: 0.9602746305437726
Validation loss: 2.6170095408629575

Epoch: 5| Step: 5
Training loss: 0.9304675508198349
Validation loss: 2.6410384374212317

Epoch: 5| Step: 6
Training loss: 1.1566073922095368
Validation loss: 2.6312385041864554

Epoch: 5| Step: 7
Training loss: 0.6101381462820719
Validation loss: 2.480283997437553

Epoch: 5| Step: 8
Training loss: 0.7090016092354787
Validation loss: 2.4698491275047516

Epoch: 5| Step: 9
Training loss: 0.84626740622263
Validation loss: 2.440729610010066

Epoch: 5| Step: 10
Training loss: 0.95216687306872
Validation loss: 2.4541104815782915

Epoch: 255| Step: 0
Training loss: 0.9327388025049806
Validation loss: 2.4461949570625228

Epoch: 5| Step: 1
Training loss: 0.8666369090718024
Validation loss: 2.4759155910884645

Epoch: 5| Step: 2
Training loss: 0.9926091897510249
Validation loss: 2.5108545873061705

Epoch: 5| Step: 3
Training loss: 0.6882997975789318
Validation loss: 2.5611120787738617

Epoch: 5| Step: 4
Training loss: 0.6034394990877042
Validation loss: 2.552012112602924

Epoch: 5| Step: 5
Training loss: 0.8305815482847757
Validation loss: 2.564248466692897

Epoch: 5| Step: 6
Training loss: 0.8898611306493363
Validation loss: 2.508256542409581

Epoch: 5| Step: 7
Training loss: 0.6463836176513016
Validation loss: 2.4830748136148246

Epoch: 5| Step: 8
Training loss: 0.7965943833469421
Validation loss: 2.4794656942538826

Epoch: 5| Step: 9
Training loss: 0.6880606619323246
Validation loss: 2.5482513223922436

Epoch: 5| Step: 10
Training loss: 1.3188530795774276
Validation loss: 2.5585347010738784

Epoch: 256| Step: 0
Training loss: 0.6683250503153599
Validation loss: 2.556279212689866

Epoch: 5| Step: 1
Training loss: 0.6977212096042074
Validation loss: 2.5798538352840046

Epoch: 5| Step: 2
Training loss: 0.903654294519452
Validation loss: 2.5696069670626955

Epoch: 5| Step: 3
Training loss: 1.0098521566299308
Validation loss: 2.557939603764597

Epoch: 5| Step: 4
Training loss: 0.9144269754548384
Validation loss: 2.5414580342403

Epoch: 5| Step: 5
Training loss: 0.8575370554799957
Validation loss: 2.5104011824847756

Epoch: 5| Step: 6
Training loss: 1.0559155132062712
Validation loss: 2.548266767058718

Epoch: 5| Step: 7
Training loss: 0.6063868053673477
Validation loss: 2.490997737155391

Epoch: 5| Step: 8
Training loss: 0.6574360937166409
Validation loss: 2.5254759892294625

Epoch: 5| Step: 9
Training loss: 0.6700496273734585
Validation loss: 2.561891344939413

Epoch: 5| Step: 10
Training loss: 0.9289777915874662
Validation loss: 2.589719005980652

Epoch: 257| Step: 0
Training loss: 0.6028021882452226
Validation loss: 2.5871792572732324

Epoch: 5| Step: 1
Training loss: 0.5721459637935665
Validation loss: 2.6269180558393503

Epoch: 5| Step: 2
Training loss: 0.6485089641854427
Validation loss: 2.60798894204856

Epoch: 5| Step: 3
Training loss: 0.6775062462916417
Validation loss: 2.627867295851623

Epoch: 5| Step: 4
Training loss: 1.0211650867249664
Validation loss: 2.6095842455994913

Epoch: 5| Step: 5
Training loss: 1.1748510590975445
Validation loss: 2.5550900963962824

Epoch: 5| Step: 6
Training loss: 0.7108411199613535
Validation loss: 2.5118988502778854

Epoch: 5| Step: 7
Training loss: 0.8532281037792325
Validation loss: 2.5237810789991353

Epoch: 5| Step: 8
Training loss: 0.5633400895580714
Validation loss: 2.5611858134390872

Epoch: 5| Step: 9
Training loss: 0.9420190296781952
Validation loss: 2.552552666032558

Epoch: 5| Step: 10
Training loss: 1.0151600286863487
Validation loss: 2.5703958198065657

Epoch: 258| Step: 0
Training loss: 0.9123711547289709
Validation loss: 2.5871798580073913

Epoch: 5| Step: 1
Training loss: 0.654371570479798
Validation loss: 2.6237664535015863

Epoch: 5| Step: 2
Training loss: 0.6381788071188008
Validation loss: 2.635574155342535

Epoch: 5| Step: 3
Training loss: 0.8985479535747394
Validation loss: 2.638979145558178

Epoch: 5| Step: 4
Training loss: 0.6127184089196258
Validation loss: 2.595723402319003

Epoch: 5| Step: 5
Training loss: 0.9990438121757714
Validation loss: 2.52497466708284

Epoch: 5| Step: 6
Training loss: 0.8175377556484505
Validation loss: 2.4997597937908616

Epoch: 5| Step: 7
Training loss: 0.7617804086623182
Validation loss: 2.4521039838338927

Epoch: 5| Step: 8
Training loss: 0.9046097743455753
Validation loss: 2.450375883714515

Epoch: 5| Step: 9
Training loss: 0.8677149362912003
Validation loss: 2.4907173899546358

Epoch: 5| Step: 10
Training loss: 0.8186466559497256
Validation loss: 2.4770287132845947

Epoch: 259| Step: 0
Training loss: 0.7758535545437325
Validation loss: 2.5077016578048434

Epoch: 5| Step: 1
Training loss: 0.7508486079427467
Validation loss: 2.57181095335656

Epoch: 5| Step: 2
Training loss: 0.6477566787290023
Validation loss: 2.6258642441053444

Epoch: 5| Step: 3
Training loss: 0.7384617902624636
Validation loss: 2.6137951261449803

Epoch: 5| Step: 4
Training loss: 0.8692117040479896
Validation loss: 2.570638124384026

Epoch: 5| Step: 5
Training loss: 0.4993615544673036
Validation loss: 2.4669702100217585

Epoch: 5| Step: 6
Training loss: 0.93221797687406
Validation loss: 2.462127788341875

Epoch: 5| Step: 7
Training loss: 0.7505503463148645
Validation loss: 2.4740965552757386

Epoch: 5| Step: 8
Training loss: 0.9893060128311795
Validation loss: 2.480214078059237

Epoch: 5| Step: 9
Training loss: 0.9401418972457227
Validation loss: 2.463167314344846

Epoch: 5| Step: 10
Training loss: 1.0906568112693662
Validation loss: 2.517257691549061

Epoch: 260| Step: 0
Training loss: 0.7317579591824566
Validation loss: 2.56796058601001

Epoch: 5| Step: 1
Training loss: 0.6515034728905488
Validation loss: 2.630897717374973

Epoch: 5| Step: 2
Training loss: 0.9056851501181643
Validation loss: 2.652689521822012

Epoch: 5| Step: 3
Training loss: 0.5783218358002724
Validation loss: 2.6192439324267642

Epoch: 5| Step: 4
Training loss: 0.863066978962865
Validation loss: 2.607577219359744

Epoch: 5| Step: 5
Training loss: 0.8045484552342159
Validation loss: 2.583310395759849

Epoch: 5| Step: 6
Training loss: 1.1316321702192953
Validation loss: 2.5670215249181325

Epoch: 5| Step: 7
Training loss: 0.5825650116655866
Validation loss: 2.549166855781309

Epoch: 5| Step: 8
Training loss: 0.34791111979755074
Validation loss: 2.5947616572119787

Epoch: 5| Step: 9
Training loss: 1.041428303467172
Validation loss: 2.5359203125721246

Epoch: 5| Step: 10
Training loss: 0.8996003959230847
Validation loss: 2.5444646779473423

Epoch: 261| Step: 0
Training loss: 0.6804544353183865
Validation loss: 2.576699077790411

Epoch: 5| Step: 1
Training loss: 0.5927346482382502
Validation loss: 2.564688124751206

Epoch: 5| Step: 2
Training loss: 0.839038622638938
Validation loss: 2.5820248121745077

Epoch: 5| Step: 3
Training loss: 0.9674334039365429
Validation loss: 2.6200085308835024

Epoch: 5| Step: 4
Training loss: 0.666753477663197
Validation loss: 2.5220415821056923

Epoch: 5| Step: 5
Training loss: 0.8526905882109174
Validation loss: 2.4979088086933596

Epoch: 5| Step: 6
Training loss: 0.8468943041188423
Validation loss: 2.52822132732996

Epoch: 5| Step: 7
Training loss: 0.8603099245697282
Validation loss: 2.4966092310873007

Epoch: 5| Step: 8
Training loss: 0.4301486228657438
Validation loss: 2.4851697802449735

Epoch: 5| Step: 9
Training loss: 0.713527321961348
Validation loss: 2.511511419513746

Epoch: 5| Step: 10
Training loss: 1.1067356896898153
Validation loss: 2.50749370378639

Epoch: 262| Step: 0
Training loss: 0.6768944892648838
Validation loss: 2.514572706124549

Epoch: 5| Step: 1
Training loss: 0.9213559580703379
Validation loss: 2.5251108849625563

Epoch: 5| Step: 2
Training loss: 0.5246711541197615
Validation loss: 2.5284885792576057

Epoch: 5| Step: 3
Training loss: 0.8092133732550982
Validation loss: 2.5385009023383898

Epoch: 5| Step: 4
Training loss: 0.8953736182850156
Validation loss: 2.597965263240256

Epoch: 5| Step: 5
Training loss: 0.6174015446602492
Validation loss: 2.5981029559722164

Epoch: 5| Step: 6
Training loss: 0.8718899564930014
Validation loss: 2.616806728903634

Epoch: 5| Step: 7
Training loss: 0.8628804584006144
Validation loss: 2.6100395829540335

Epoch: 5| Step: 8
Training loss: 0.9006780467668594
Validation loss: 2.5819918135989046

Epoch: 5| Step: 9
Training loss: 0.5556535770117478
Validation loss: 2.497632969323502

Epoch: 5| Step: 10
Training loss: 0.9744046594437878
Validation loss: 2.5062032177273803

Epoch: 263| Step: 0
Training loss: 0.8305180718891839
Validation loss: 2.4965863979690313

Epoch: 5| Step: 1
Training loss: 1.0357223977865857
Validation loss: 2.486082048174271

Epoch: 5| Step: 2
Training loss: 0.645542784420175
Validation loss: 2.5551381331637972

Epoch: 5| Step: 3
Training loss: 0.6179062484982752
Validation loss: 2.5562767531261175

Epoch: 5| Step: 4
Training loss: 0.8141344942850973
Validation loss: 2.5880994303648235

Epoch: 5| Step: 5
Training loss: 0.6716770279663358
Validation loss: 2.5876502058990667

Epoch: 5| Step: 6
Training loss: 0.8578318525955863
Validation loss: 2.637242292644273

Epoch: 5| Step: 7
Training loss: 1.1644423716245973
Validation loss: 2.6218295525191566

Epoch: 5| Step: 8
Training loss: 0.5191113775896877
Validation loss: 2.6180517075984016

Epoch: 5| Step: 9
Training loss: 0.6215044019578498
Validation loss: 2.5559776530335476

Epoch: 5| Step: 10
Training loss: 0.5129179843366087
Validation loss: 2.5345162723842254

Epoch: 264| Step: 0
Training loss: 0.586427051755623
Validation loss: 2.546115885169011

Epoch: 5| Step: 1
Training loss: 0.8618830409238525
Validation loss: 2.516154722698391

Epoch: 5| Step: 2
Training loss: 0.7060823764885336
Validation loss: 2.534271258180199

Epoch: 5| Step: 3
Training loss: 0.44869398896514295
Validation loss: 2.5647831716536422

Epoch: 5| Step: 4
Training loss: 0.7680669494743391
Validation loss: 2.541741401492157

Epoch: 5| Step: 5
Training loss: 0.6679934893036686
Validation loss: 2.5669917774760083

Epoch: 5| Step: 6
Training loss: 0.7133358753759182
Validation loss: 2.5306216449646572

Epoch: 5| Step: 7
Training loss: 1.012808253612756
Validation loss: 2.552499103309558

Epoch: 5| Step: 8
Training loss: 1.1376058780734255
Validation loss: 2.5042499677917016

Epoch: 5| Step: 9
Training loss: 0.6568572776791984
Validation loss: 2.46290161591482

Epoch: 5| Step: 10
Training loss: 0.6661149339665188
Validation loss: 2.4749062591348037

Epoch: 265| Step: 0
Training loss: 0.8538355107860164
Validation loss: 2.45310678887438

Epoch: 5| Step: 1
Training loss: 0.42992106938620245
Validation loss: 2.4928882184826664

Epoch: 5| Step: 2
Training loss: 0.7252765884285768
Validation loss: 2.568378793184572

Epoch: 5| Step: 3
Training loss: 0.7379058206264814
Validation loss: 2.6243760338613242

Epoch: 5| Step: 4
Training loss: 0.7678538208316154
Validation loss: 2.6289485468504155

Epoch: 5| Step: 5
Training loss: 0.7450679897800176
Validation loss: 2.658538797406472

Epoch: 5| Step: 6
Training loss: 0.8364309832961773
Validation loss: 2.609284706216313

Epoch: 5| Step: 7
Training loss: 0.6069363189660634
Validation loss: 2.593637463248017

Epoch: 5| Step: 8
Training loss: 0.9387241636294311
Validation loss: 2.518813538768365

Epoch: 5| Step: 9
Training loss: 0.9687934988777084
Validation loss: 2.5161914604222484

Epoch: 5| Step: 10
Training loss: 0.8425022365189476
Validation loss: 2.47824814028631

Epoch: 266| Step: 0
Training loss: 0.6423826065132736
Validation loss: 2.4651905379649732

Epoch: 5| Step: 1
Training loss: 0.9119288002338022
Validation loss: 2.5436959828858705

Epoch: 5| Step: 2
Training loss: 0.7360733765301147
Validation loss: 2.5593388087359843

Epoch: 5| Step: 3
Training loss: 0.6144936113545351
Validation loss: 2.598782492092608

Epoch: 5| Step: 4
Training loss: 0.9570790804374201
Validation loss: 2.617109353067046

Epoch: 5| Step: 5
Training loss: 0.7595664501214597
Validation loss: 2.620089525734588

Epoch: 5| Step: 6
Training loss: 0.5334344159636599
Validation loss: 2.6086733855242707

Epoch: 5| Step: 7
Training loss: 0.83141719742801
Validation loss: 2.6254918398954645

Epoch: 5| Step: 8
Training loss: 0.8791402208650548
Validation loss: 2.6120668914118164

Epoch: 5| Step: 9
Training loss: 0.7299810403164568
Validation loss: 2.5493668088769885

Epoch: 5| Step: 10
Training loss: 0.6528250694616995
Validation loss: 2.523612291124097

Epoch: 267| Step: 0
Training loss: 0.6888959108036659
Validation loss: 2.491503716572781

Epoch: 5| Step: 1
Training loss: 0.7888601440205915
Validation loss: 2.5057404569781077

Epoch: 5| Step: 2
Training loss: 0.795924423823277
Validation loss: 2.498448301028497

Epoch: 5| Step: 3
Training loss: 0.7045612924227572
Validation loss: 2.510840214322287

Epoch: 5| Step: 4
Training loss: 1.0384111585786042
Validation loss: 2.5472541213356292

Epoch: 5| Step: 5
Training loss: 0.9071399988240973
Validation loss: 2.5134702307556878

Epoch: 5| Step: 6
Training loss: 0.6100125279078152
Validation loss: 2.5259273275249257

Epoch: 5| Step: 7
Training loss: 0.7656952183500788
Validation loss: 2.563569356759429

Epoch: 5| Step: 8
Training loss: 0.6220844452838026
Validation loss: 2.5306716343265925

Epoch: 5| Step: 9
Training loss: 0.6571786758185962
Validation loss: 2.5257403084962906

Epoch: 5| Step: 10
Training loss: 0.6858404677457604
Validation loss: 2.5203960684904625

Epoch: 268| Step: 0
Training loss: 0.4220723467649399
Validation loss: 2.5619844277642643

Epoch: 5| Step: 1
Training loss: 0.5878297894706938
Validation loss: 2.532479435659331

Epoch: 5| Step: 2
Training loss: 0.6173717368658148
Validation loss: 2.509117220760732

Epoch: 5| Step: 3
Training loss: 0.7728649293458439
Validation loss: 2.4881074862463657

Epoch: 5| Step: 4
Training loss: 0.8822774024960286
Validation loss: 2.5302110238926976

Epoch: 5| Step: 5
Training loss: 0.7664336779991477
Validation loss: 2.507690505434388

Epoch: 5| Step: 6
Training loss: 0.6917900485752556
Validation loss: 2.546062060665913

Epoch: 5| Step: 7
Training loss: 0.6609563775218692
Validation loss: 2.55077914946271

Epoch: 5| Step: 8
Training loss: 0.7543345208357453
Validation loss: 2.561538770617093

Epoch: 5| Step: 9
Training loss: 0.9181861782270893
Validation loss: 2.5828280412893125

Epoch: 5| Step: 10
Training loss: 1.0205910388648065
Validation loss: 2.547750683215017

Epoch: 269| Step: 0
Training loss: 0.8804243413359282
Validation loss: 2.526138410036086

Epoch: 5| Step: 1
Training loss: 0.8845293685389032
Validation loss: 2.5424531828886026

Epoch: 5| Step: 2
Training loss: 0.4270029476932832
Validation loss: 2.549584009001895

Epoch: 5| Step: 3
Training loss: 0.8044613270352102
Validation loss: 2.5647517159794937

Epoch: 5| Step: 4
Training loss: 0.9207368063643014
Validation loss: 2.5303919188624633

Epoch: 5| Step: 5
Training loss: 0.7856612218550266
Validation loss: 2.543103563018481

Epoch: 5| Step: 6
Training loss: 0.4143587528110305
Validation loss: 2.556703095815166

Epoch: 5| Step: 7
Training loss: 0.621462298755823
Validation loss: 2.566638396053759

Epoch: 5| Step: 8
Training loss: 0.7016794179503771
Validation loss: 2.5939952637025163

Epoch: 5| Step: 9
Training loss: 0.8644808551462184
Validation loss: 2.5728929317701987

Epoch: 5| Step: 10
Training loss: 0.4723687992400627
Validation loss: 2.590202836607226

Epoch: 270| Step: 0
Training loss: 0.6879606870880103
Validation loss: 2.577542242299182

Epoch: 5| Step: 1
Training loss: 0.8711032952439997
Validation loss: 2.581166943520363

Epoch: 5| Step: 2
Training loss: 0.7071813771736728
Validation loss: 2.563052920883548

Epoch: 5| Step: 3
Training loss: 0.5457699373668932
Validation loss: 2.5798821957672917

Epoch: 5| Step: 4
Training loss: 0.7495143430583129
Validation loss: 2.577557740213293

Epoch: 5| Step: 5
Training loss: 0.7246158321946329
Validation loss: 2.578112308673565

Epoch: 5| Step: 6
Training loss: 0.6097308855834024
Validation loss: 2.5874635789458034

Epoch: 5| Step: 7
Training loss: 0.6388382767818527
Validation loss: 2.5438449545295305

Epoch: 5| Step: 8
Training loss: 0.9668603124902342
Validation loss: 2.541949928297412

Epoch: 5| Step: 9
Training loss: 0.8381920119085854
Validation loss: 2.5788038198506626

Epoch: 5| Step: 10
Training loss: 0.49832565882470886
Validation loss: 2.5593872473090133

Epoch: 271| Step: 0
Training loss: 0.8815814186400172
Validation loss: 2.5360942605483037

Epoch: 5| Step: 1
Training loss: 0.7202292437649409
Validation loss: 2.5259646990186093

Epoch: 5| Step: 2
Training loss: 0.6417110355527456
Validation loss: 2.5526822748256124

Epoch: 5| Step: 3
Training loss: 0.7446209015963198
Validation loss: 2.552256362872313

Epoch: 5| Step: 4
Training loss: 0.34334155221973306
Validation loss: 2.5392564026505138

Epoch: 5| Step: 5
Training loss: 0.6944538343642448
Validation loss: 2.476230895064013

Epoch: 5| Step: 6
Training loss: 0.7062477491562346
Validation loss: 2.4922279428950116

Epoch: 5| Step: 7
Training loss: 0.8437136183065207
Validation loss: 2.5217582204625515

Epoch: 5| Step: 8
Training loss: 0.7633833083891677
Validation loss: 2.5398989951757485

Epoch: 5| Step: 9
Training loss: 0.7386467246015841
Validation loss: 2.586036397942969

Epoch: 5| Step: 10
Training loss: 0.8089341999520989
Validation loss: 2.556637602745966

Epoch: 272| Step: 0
Training loss: 0.9113964423102027
Validation loss: 2.5678546133925186

Epoch: 5| Step: 1
Training loss: 0.8628404967985969
Validation loss: 2.4915109902320887

Epoch: 5| Step: 2
Training loss: 0.3538807621887276
Validation loss: 2.5164139981050315

Epoch: 5| Step: 3
Training loss: 0.674129916070788
Validation loss: 2.5091395945071158

Epoch: 5| Step: 4
Training loss: 0.6843919725795647
Validation loss: 2.5032764949757893

Epoch: 5| Step: 5
Training loss: 0.6387321607035812
Validation loss: 2.5575576809947953

Epoch: 5| Step: 6
Training loss: 0.9348967011145741
Validation loss: 2.5224937158076193

Epoch: 5| Step: 7
Training loss: 0.756791006415784
Validation loss: 2.5652857139300553

Epoch: 5| Step: 8
Training loss: 0.6708557470696008
Validation loss: 2.5573413154767

Epoch: 5| Step: 9
Training loss: 0.652486637022491
Validation loss: 2.5544315433317215

Epoch: 5| Step: 10
Training loss: 0.6143247631563253
Validation loss: 2.5281809344428403

Epoch: 273| Step: 0
Training loss: 0.6082666049137918
Validation loss: 2.517009735893541

Epoch: 5| Step: 1
Training loss: 0.5648201142110547
Validation loss: 2.51919163262969

Epoch: 5| Step: 2
Training loss: 0.5084757654834838
Validation loss: 2.490729292497089

Epoch: 5| Step: 3
Training loss: 0.7198444823685091
Validation loss: 2.512591255541674

Epoch: 5| Step: 4
Training loss: 0.8284830363050049
Validation loss: 2.511738222812499

Epoch: 5| Step: 5
Training loss: 0.7172810844581077
Validation loss: 2.5257777314766634

Epoch: 5| Step: 6
Training loss: 0.8546625806673109
Validation loss: 2.512365176700058

Epoch: 5| Step: 7
Training loss: 0.3368144233536854
Validation loss: 2.536033677364824

Epoch: 5| Step: 8
Training loss: 0.781954333384176
Validation loss: 2.50889418759784

Epoch: 5| Step: 9
Training loss: 0.970292125248418
Validation loss: 2.5364858523028215

Epoch: 5| Step: 10
Training loss: 0.7412552449650333
Validation loss: 2.522185646730233

Epoch: 274| Step: 0
Training loss: 0.6187532097318994
Validation loss: 2.51344406811984

Epoch: 5| Step: 1
Training loss: 0.7847498510967599
Validation loss: 2.517946675482021

Epoch: 5| Step: 2
Training loss: 0.7995751579056224
Validation loss: 2.553424700845786

Epoch: 5| Step: 3
Training loss: 0.7141462581601393
Validation loss: 2.5290370926688883

Epoch: 5| Step: 4
Training loss: 0.8346178565754434
Validation loss: 2.534978610104235

Epoch: 5| Step: 5
Training loss: 0.7884170989830456
Validation loss: 2.5531053624146174

Epoch: 5| Step: 6
Training loss: 0.6166365373399363
Validation loss: 2.4504983421520086

Epoch: 5| Step: 7
Training loss: 0.24767175228805827
Validation loss: 2.4880269995854154

Epoch: 5| Step: 8
Training loss: 0.7985553602210103
Validation loss: 2.5187255782057902

Epoch: 5| Step: 9
Training loss: 0.6874669240451037
Validation loss: 2.5038351779938783

Epoch: 5| Step: 10
Training loss: 0.701946075522933
Validation loss: 2.503480391876168

Epoch: 275| Step: 0
Training loss: 0.6589534795242444
Validation loss: 2.581952950496103

Epoch: 5| Step: 1
Training loss: 0.46216234627472147
Validation loss: 2.5528655898573094

Epoch: 5| Step: 2
Training loss: 0.7583851960721134
Validation loss: 2.5864413334776133

Epoch: 5| Step: 3
Training loss: 0.47197507213982154
Validation loss: 2.553196451125149

Epoch: 5| Step: 4
Training loss: 0.6545035192498463
Validation loss: 2.549497244799285

Epoch: 5| Step: 5
Training loss: 0.9090665589127552
Validation loss: 2.594841598033162

Epoch: 5| Step: 6
Training loss: 0.5412147238250301
Validation loss: 2.591278114019714

Epoch: 5| Step: 7
Training loss: 0.508700430796047
Validation loss: 2.5942042556278935

Epoch: 5| Step: 8
Training loss: 0.808911026337618
Validation loss: 2.5940245191384124

Epoch: 5| Step: 9
Training loss: 0.801565614214642
Validation loss: 2.5700261138226757

Epoch: 5| Step: 10
Training loss: 0.8970446196933373
Validation loss: 2.544089441729946

Epoch: 276| Step: 0
Training loss: 0.649110674440893
Validation loss: 2.5213744530982245

Epoch: 5| Step: 1
Training loss: 0.533317330115349
Validation loss: 2.4952495962282306

Epoch: 5| Step: 2
Training loss: 0.6783926457601391
Validation loss: 2.5097679222763247

Epoch: 5| Step: 3
Training loss: 0.8929731300493553
Validation loss: 2.523207381949738

Epoch: 5| Step: 4
Training loss: 0.661355571323749
Validation loss: 2.5353696987241197

Epoch: 5| Step: 5
Training loss: 0.614230108318632
Validation loss: 2.5505938571767377

Epoch: 5| Step: 6
Training loss: 0.42125529232153147
Validation loss: 2.562004777830399

Epoch: 5| Step: 7
Training loss: 1.049412456250661
Validation loss: 2.5575812047034487

Epoch: 5| Step: 8
Training loss: 0.6401262435230586
Validation loss: 2.5468351601467214

Epoch: 5| Step: 9
Training loss: 0.5559023059771753
Validation loss: 2.543500027903118

Epoch: 5| Step: 10
Training loss: 0.7800725838316825
Validation loss: 2.517004533765043

Epoch: 277| Step: 0
Training loss: 0.48209883032211587
Validation loss: 2.5202481465128685

Epoch: 5| Step: 1
Training loss: 0.8952164004214437
Validation loss: 2.499628010628608

Epoch: 5| Step: 2
Training loss: 0.6561943666400605
Validation loss: 2.540368531510294

Epoch: 5| Step: 3
Training loss: 0.6820005106252846
Validation loss: 2.521067686144591

Epoch: 5| Step: 4
Training loss: 0.6719805168864055
Validation loss: 2.593701734413765

Epoch: 5| Step: 5
Training loss: 0.8681421952985479
Validation loss: 2.5980787532091005

Epoch: 5| Step: 6
Training loss: 0.9214424152855103
Validation loss: 2.6258084370239576

Epoch: 5| Step: 7
Training loss: 0.44810882778593875
Validation loss: 2.5763215957832606

Epoch: 5| Step: 8
Training loss: 0.5406794140283534
Validation loss: 2.5699449142873445

Epoch: 5| Step: 9
Training loss: 0.601158650570692
Validation loss: 2.5403720141222292

Epoch: 5| Step: 10
Training loss: 0.7056441848282277
Validation loss: 2.544653967842023

Epoch: 278| Step: 0
Training loss: 0.6652937302062768
Validation loss: 2.508027760671891

Epoch: 5| Step: 1
Training loss: 0.944756809560356
Validation loss: 2.5126993196275325

Epoch: 5| Step: 2
Training loss: 0.25499217292516557
Validation loss: 2.502929012515235

Epoch: 5| Step: 3
Training loss: 0.7570370511520665
Validation loss: 2.48250092207357

Epoch: 5| Step: 4
Training loss: 0.707104147003609
Validation loss: 2.501327265892569

Epoch: 5| Step: 5
Training loss: 0.8589117709047126
Validation loss: 2.5271932456915844

Epoch: 5| Step: 6
Training loss: 0.5851160522018004
Validation loss: 2.5234293186872057

Epoch: 5| Step: 7
Training loss: 0.8518081100857918
Validation loss: 2.5006852564412854

Epoch: 5| Step: 8
Training loss: 0.7536739327430413
Validation loss: 2.5022432599439197

Epoch: 5| Step: 9
Training loss: 0.34004498147386886
Validation loss: 2.5272137201967504

Epoch: 5| Step: 10
Training loss: 0.601755185664757
Validation loss: 2.5336324574140376

Epoch: 279| Step: 0
Training loss: 0.8241487084589968
Validation loss: 2.560488189507588

Epoch: 5| Step: 1
Training loss: 0.7526295183569142
Validation loss: 2.537686379518201

Epoch: 5| Step: 2
Training loss: 0.6019401603357137
Validation loss: 2.5901591746226966

Epoch: 5| Step: 3
Training loss: 0.6832790195194026
Validation loss: 2.604166381507776

Epoch: 5| Step: 4
Training loss: 0.28306978967384777
Validation loss: 2.5398734525001307

Epoch: 5| Step: 5
Training loss: 0.5167021049630869
Validation loss: 2.5491178989136007

Epoch: 5| Step: 6
Training loss: 0.4210199415247895
Validation loss: 2.5631549047348425

Epoch: 5| Step: 7
Training loss: 0.8211631723776969
Validation loss: 2.5424497969025617

Epoch: 5| Step: 8
Training loss: 0.6742970037741964
Validation loss: 2.5343744583769614

Epoch: 5| Step: 9
Training loss: 0.9109930031358036
Validation loss: 2.521288049118649

Epoch: 5| Step: 10
Training loss: 0.9080099577210691
Validation loss: 2.540551519096293

Epoch: 280| Step: 0
Training loss: 0.8356300216329903
Validation loss: 2.5161707637745394

Epoch: 5| Step: 1
Training loss: 0.6833808349365852
Validation loss: 2.4955025046705033

Epoch: 5| Step: 2
Training loss: 0.6824971586035524
Validation loss: 2.505308194835371

Epoch: 5| Step: 3
Training loss: 0.6371527754679399
Validation loss: 2.5322846243143244

Epoch: 5| Step: 4
Training loss: 0.7430340406287871
Validation loss: 2.5873077076602

Epoch: 5| Step: 5
Training loss: 0.41971488996759665
Validation loss: 2.6246951385683004

Epoch: 5| Step: 6
Training loss: 0.7981716527126613
Validation loss: 2.615758004386017

Epoch: 5| Step: 7
Training loss: 0.3783260110673078
Validation loss: 2.5892945377004124

Epoch: 5| Step: 8
Training loss: 0.7575759518507506
Validation loss: 2.587094582336136

Epoch: 5| Step: 9
Training loss: 0.8679200935631862
Validation loss: 2.5666831403421244

Epoch: 5| Step: 10
Training loss: 0.5744563279464041
Validation loss: 2.5404958652526526

Epoch: 281| Step: 0
Training loss: 0.656295729360849
Validation loss: 2.5980141640402348

Epoch: 5| Step: 1
Training loss: 0.5344028320649336
Validation loss: 2.529070600735534

Epoch: 5| Step: 2
Training loss: 0.49971866143107574
Validation loss: 2.550904865080886

Epoch: 5| Step: 3
Training loss: 0.45833140250001586
Validation loss: 2.5007663721174325

Epoch: 5| Step: 4
Training loss: 0.6181813700152878
Validation loss: 2.535873982188889

Epoch: 5| Step: 5
Training loss: 0.5697941449359601
Validation loss: 2.535619678223347

Epoch: 5| Step: 6
Training loss: 0.5940398211617638
Validation loss: 2.501648692528938

Epoch: 5| Step: 7
Training loss: 0.5834196032582019
Validation loss: 2.497111696282976

Epoch: 5| Step: 8
Training loss: 0.9039599654080464
Validation loss: 2.51747102951246

Epoch: 5| Step: 9
Training loss: 0.8262169647538017
Validation loss: 2.5524262998734923

Epoch: 5| Step: 10
Training loss: 0.9113380716094168
Validation loss: 2.5812281096290826

Epoch: 282| Step: 0
Training loss: 0.6517107284955848
Validation loss: 2.563308234200782

Epoch: 5| Step: 1
Training loss: 0.6898067313227236
Validation loss: 2.5882707194336603

Epoch: 5| Step: 2
Training loss: 0.7312433552236327
Validation loss: 2.5805920443528927

Epoch: 5| Step: 3
Training loss: 0.6590076363284627
Validation loss: 2.5528888173779345

Epoch: 5| Step: 4
Training loss: 0.24855300749277376
Validation loss: 2.547816746839229

Epoch: 5| Step: 5
Training loss: 0.8394269041827408
Validation loss: 2.542376933585033

Epoch: 5| Step: 6
Training loss: 0.691453878195458
Validation loss: 2.5478596160881755

Epoch: 5| Step: 7
Training loss: 0.8025987051040085
Validation loss: 2.5223343886250458

Epoch: 5| Step: 8
Training loss: 0.39939563214373586
Validation loss: 2.5573144382938016

Epoch: 5| Step: 9
Training loss: 0.5042120722614277
Validation loss: 2.553152943005362

Epoch: 5| Step: 10
Training loss: 0.8428046263828043
Validation loss: 2.5718291109241243

Epoch: 283| Step: 0
Training loss: 0.6006105991665542
Validation loss: 2.5668120121591187

Epoch: 5| Step: 1
Training loss: 0.7139525147256511
Validation loss: 2.586012287456897

Epoch: 5| Step: 2
Training loss: 0.6225291525667217
Validation loss: 2.5788782137530815

Epoch: 5| Step: 3
Training loss: 0.485266864225124
Validation loss: 2.5239958299584484

Epoch: 5| Step: 4
Training loss: 0.6983400716395827
Validation loss: 2.5184346160286433

Epoch: 5| Step: 5
Training loss: 0.6408274958567475
Validation loss: 2.507451792023848

Epoch: 5| Step: 6
Training loss: 0.8636786465355656
Validation loss: 2.535282118423058

Epoch: 5| Step: 7
Training loss: 0.6759016558154904
Validation loss: 2.596608250157149

Epoch: 5| Step: 8
Training loss: 0.576414257727095
Validation loss: 2.6025679480533013

Epoch: 5| Step: 9
Training loss: 0.7420079064166463
Validation loss: 2.589438906957561

Epoch: 5| Step: 10
Training loss: 0.5561141887702004
Validation loss: 2.569970359588228

Epoch: 284| Step: 0
Training loss: 0.4240693140009543
Validation loss: 2.5847761317603437

Epoch: 5| Step: 1
Training loss: 0.6915450953496861
Validation loss: 2.5483482111763585

Epoch: 5| Step: 2
Training loss: 0.7308046517204771
Validation loss: 2.564058377715036

Epoch: 5| Step: 3
Training loss: 0.7010441400749782
Validation loss: 2.5477754284715917

Epoch: 5| Step: 4
Training loss: 0.4758347442069351
Validation loss: 2.554698769331704

Epoch: 5| Step: 5
Training loss: 0.8589037209845359
Validation loss: 2.557952401191612

Epoch: 5| Step: 6
Training loss: 0.6995737889971515
Validation loss: 2.5826189923793073

Epoch: 5| Step: 7
Training loss: 0.5551889329088953
Validation loss: 2.586214877546389

Epoch: 5| Step: 8
Training loss: 0.6167025048779233
Validation loss: 2.5592906071498693

Epoch: 5| Step: 9
Training loss: 0.7574694928865509
Validation loss: 2.5747676025679263

Epoch: 5| Step: 10
Training loss: 0.4016305657970823
Validation loss: 2.5558558310006676

Epoch: 285| Step: 0
Training loss: 0.4426117866556259
Validation loss: 2.5131641066345836

Epoch: 5| Step: 1
Training loss: 0.7400008263454463
Validation loss: 2.5003801241418593

Epoch: 5| Step: 2
Training loss: 0.6846346097128606
Validation loss: 2.4994867515800596

Epoch: 5| Step: 3
Training loss: 0.6282847395892263
Validation loss: 2.469248083691992

Epoch: 5| Step: 4
Training loss: 0.7545414358760073
Validation loss: 2.4637685653619603

Epoch: 5| Step: 5
Training loss: 0.6683346376461832
Validation loss: 2.481456544598394

Epoch: 5| Step: 6
Training loss: 0.49519413758268127
Validation loss: 2.5351895477521507

Epoch: 5| Step: 7
Training loss: 0.5082310638840589
Validation loss: 2.5579604590578318

Epoch: 5| Step: 8
Training loss: 0.7833354581303558
Validation loss: 2.583696332575443

Epoch: 5| Step: 9
Training loss: 0.6355782808821825
Validation loss: 2.565242587241539

Epoch: 5| Step: 10
Training loss: 0.7117774947509907
Validation loss: 2.595793724307631

Epoch: 286| Step: 0
Training loss: 0.6294169277707631
Validation loss: 2.565325806889048

Epoch: 5| Step: 1
Training loss: 0.7534811768436734
Validation loss: 2.530826378704178

Epoch: 5| Step: 2
Training loss: 0.46643214960568036
Validation loss: 2.5035541343087875

Epoch: 5| Step: 3
Training loss: 0.4669060040843437
Validation loss: 2.524996388604469

Epoch: 5| Step: 4
Training loss: 0.7263881104900533
Validation loss: 2.541326156742217

Epoch: 5| Step: 5
Training loss: 0.9420827753626911
Validation loss: 2.5603896184021058

Epoch: 5| Step: 6
Training loss: 0.42422638916106503
Validation loss: 2.575921381191867

Epoch: 5| Step: 7
Training loss: 0.5817551950272754
Validation loss: 2.538825390316976

Epoch: 5| Step: 8
Training loss: 0.5979506571564108
Validation loss: 2.587435733551306

Epoch: 5| Step: 9
Training loss: 0.8275630411757501
Validation loss: 2.560943399854093

Epoch: 5| Step: 10
Training loss: 0.4291790815366302
Validation loss: 2.555055530876497

Epoch: 287| Step: 0
Training loss: 0.4508377423250064
Validation loss: 2.5536038545011395

Epoch: 5| Step: 1
Training loss: 0.5244982206134414
Validation loss: 2.5168287459187417

Epoch: 5| Step: 2
Training loss: 0.4232388984330572
Validation loss: 2.554998787225712

Epoch: 5| Step: 3
Training loss: 0.44304215430211913
Validation loss: 2.5418369499091087

Epoch: 5| Step: 4
Training loss: 0.7367319067450718
Validation loss: 2.5440322156658493

Epoch: 5| Step: 5
Training loss: 0.9926912125468385
Validation loss: 2.529542275761073

Epoch: 5| Step: 6
Training loss: 0.4830121741616606
Validation loss: 2.522984569105212

Epoch: 5| Step: 7
Training loss: 0.4986788760169959
Validation loss: 2.5125768322931816

Epoch: 5| Step: 8
Training loss: 0.3337628259944599
Validation loss: 2.5223185788437417

Epoch: 5| Step: 9
Training loss: 0.9392121892308688
Validation loss: 2.5444203227883317

Epoch: 5| Step: 10
Training loss: 0.7586160312762928
Validation loss: 2.5312019524874945

Epoch: 288| Step: 0
Training loss: 0.7325911669583698
Validation loss: 2.5773173002024206

Epoch: 5| Step: 1
Training loss: 0.4829167287473773
Validation loss: 2.590593138925264

Epoch: 5| Step: 2
Training loss: 0.6050720391850933
Validation loss: 2.582110836837947

Epoch: 5| Step: 3
Training loss: 0.5091564879932244
Validation loss: 2.515227140427733

Epoch: 5| Step: 4
Training loss: 0.7117001142689606
Validation loss: 2.4499467030684787

Epoch: 5| Step: 5
Training loss: 0.661205969500148
Validation loss: 2.4870888474785535

Epoch: 5| Step: 6
Training loss: 0.610731253969843
Validation loss: 2.47016442745207

Epoch: 5| Step: 7
Training loss: 0.5028503651702122
Validation loss: 2.5586006114986386

Epoch: 5| Step: 8
Training loss: 0.8470019790779421
Validation loss: 2.605776486530144

Epoch: 5| Step: 9
Training loss: 0.8059684409643503
Validation loss: 2.6412620419198047

Epoch: 5| Step: 10
Training loss: 0.639758314639907
Validation loss: 2.5883458623991005

Epoch: 289| Step: 0
Training loss: 0.44428278007708044
Validation loss: 2.5266853293074

Epoch: 5| Step: 1
Training loss: 0.6800392380781625
Validation loss: 2.518756762363463

Epoch: 5| Step: 2
Training loss: 0.5741797453420086
Validation loss: 2.5061467561038877

Epoch: 5| Step: 3
Training loss: 0.637236472432585
Validation loss: 2.5208301596713514

Epoch: 5| Step: 4
Training loss: 0.8133506723285893
Validation loss: 2.5249875879282166

Epoch: 5| Step: 5
Training loss: 0.5356320403180528
Validation loss: 2.552836268451026

Epoch: 5| Step: 6
Training loss: 0.6031036205159039
Validation loss: 2.593454653760267

Epoch: 5| Step: 7
Training loss: 0.5486366508135051
Validation loss: 2.597489042141246

Epoch: 5| Step: 8
Training loss: 0.7018387579796213
Validation loss: 2.6427827763765843

Epoch: 5| Step: 9
Training loss: 0.8140449507390427
Validation loss: 2.604684944672488

Epoch: 5| Step: 10
Training loss: 0.5385355654530137
Validation loss: 2.589828649795564

Epoch: 290| Step: 0
Training loss: 0.7786275719039655
Validation loss: 2.5072475856783587

Epoch: 5| Step: 1
Training loss: 0.47309182329149
Validation loss: 2.5257690999819187

Epoch: 5| Step: 2
Training loss: 0.6667539469884955
Validation loss: 2.475544365259571

Epoch: 5| Step: 3
Training loss: 0.8507039352890977
Validation loss: 2.490839614748538

Epoch: 5| Step: 4
Training loss: 0.37352556203850046
Validation loss: 2.5023934935298153

Epoch: 5| Step: 5
Training loss: 0.46571140895643726
Validation loss: 2.5059492864143946

Epoch: 5| Step: 6
Training loss: 0.3317399261586551
Validation loss: 2.5367114125760764

Epoch: 5| Step: 7
Training loss: 0.802914564416651
Validation loss: 2.59029728997409

Epoch: 5| Step: 8
Training loss: 0.6308285259817855
Validation loss: 2.5649682270010663

Epoch: 5| Step: 9
Training loss: 0.8367765974747506
Validation loss: 2.595215487323564

Epoch: 5| Step: 10
Training loss: 0.4524337988579682
Validation loss: 2.5584626806210338

Epoch: 291| Step: 0
Training loss: 0.4650934173976491
Validation loss: 2.545046425395613

Epoch: 5| Step: 1
Training loss: 0.6775026832330363
Validation loss: 2.5073074222195446

Epoch: 5| Step: 2
Training loss: 0.6905552427525253
Validation loss: 2.499344369584673

Epoch: 5| Step: 3
Training loss: 0.7266841089345556
Validation loss: 2.500490472733759

Epoch: 5| Step: 4
Training loss: 0.6235837626201058
Validation loss: 2.4785799107865567

Epoch: 5| Step: 5
Training loss: 0.7424475364902628
Validation loss: 2.464530461427564

Epoch: 5| Step: 6
Training loss: 0.5459854247746829
Validation loss: 2.462937181217235

Epoch: 5| Step: 7
Training loss: 0.7152279097776857
Validation loss: 2.4937035897722537

Epoch: 5| Step: 8
Training loss: 0.41744982512147477
Validation loss: 2.5314626590468534

Epoch: 5| Step: 9
Training loss: 0.5061013368448338
Validation loss: 2.564759594053036

Epoch: 5| Step: 10
Training loss: 0.6656318520923081
Validation loss: 2.5928092621441667

Epoch: 292| Step: 0
Training loss: 0.7269359162275412
Validation loss: 2.6235698480092036

Epoch: 5| Step: 1
Training loss: 0.6827872177785773
Validation loss: 2.591927311113399

Epoch: 5| Step: 2
Training loss: 0.5970586144795987
Validation loss: 2.541825841407574

Epoch: 5| Step: 3
Training loss: 0.32999790503458243
Validation loss: 2.5092683433767498

Epoch: 5| Step: 4
Training loss: 0.6002934185452728
Validation loss: 2.5214372923449915

Epoch: 5| Step: 5
Training loss: 0.40754619468196646
Validation loss: 2.5060706685864034

Epoch: 5| Step: 6
Training loss: 0.6905140697059572
Validation loss: 2.5263001037743

Epoch: 5| Step: 7
Training loss: 0.6745056726458926
Validation loss: 2.50160018202714

Epoch: 5| Step: 8
Training loss: 0.5765874883100744
Validation loss: 2.5026373723631745

Epoch: 5| Step: 9
Training loss: 0.7330146933562225
Validation loss: 2.508519373047736

Epoch: 5| Step: 10
Training loss: 0.6903748874957759
Validation loss: 2.5266435872488535

Epoch: 293| Step: 0
Training loss: 0.5424637126652466
Validation loss: 2.57649501610002

Epoch: 5| Step: 1
Training loss: 0.7002331073089398
Validation loss: 2.511098147710401

Epoch: 5| Step: 2
Training loss: 0.790722112006478
Validation loss: 2.5004395559960684

Epoch: 5| Step: 3
Training loss: 0.6248276949835262
Validation loss: 2.5060215025255266

Epoch: 5| Step: 4
Training loss: 0.6865971228612326
Validation loss: 2.5014450214239186

Epoch: 5| Step: 5
Training loss: 0.42768805614492694
Validation loss: 2.5179446636221314

Epoch: 5| Step: 6
Training loss: 0.3489061988013948
Validation loss: 2.532930424789804

Epoch: 5| Step: 7
Training loss: 0.5509679491410389
Validation loss: 2.5250827042713166

Epoch: 5| Step: 8
Training loss: 0.8060168054736028
Validation loss: 2.571388053257416

Epoch: 5| Step: 9
Training loss: 0.5085457423181092
Validation loss: 2.5550934826883838

Epoch: 5| Step: 10
Training loss: 0.4700473792209691
Validation loss: 2.5676937647410822

Epoch: 294| Step: 0
Training loss: 0.6832882879886139
Validation loss: 2.6038856243127193

Epoch: 5| Step: 1
Training loss: 0.6816518831826259
Validation loss: 2.575223715327256

Epoch: 5| Step: 2
Training loss: 0.7008705873222905
Validation loss: 2.5818620065040965

Epoch: 5| Step: 3
Training loss: 0.6342690036334017
Validation loss: 2.5550496953278046

Epoch: 5| Step: 4
Training loss: 0.777885746463114
Validation loss: 2.5331883576278846

Epoch: 5| Step: 5
Training loss: 0.515863594570578
Validation loss: 2.482656720385652

Epoch: 5| Step: 6
Training loss: 0.6362201634214324
Validation loss: 2.472153099666563

Epoch: 5| Step: 7
Training loss: 0.49683791388055504
Validation loss: 2.5068002505054667

Epoch: 5| Step: 8
Training loss: 0.2811570278783207
Validation loss: 2.519664012339289

Epoch: 5| Step: 9
Training loss: 0.5376959909143127
Validation loss: 2.5437049420710283

Epoch: 5| Step: 10
Training loss: 0.5151018320717924
Validation loss: 2.5633747209592954

Epoch: 295| Step: 0
Training loss: 0.7036443275945682
Validation loss: 2.573653169315411

Epoch: 5| Step: 1
Training loss: 0.46229173249697925
Validation loss: 2.5862898671258243

Epoch: 5| Step: 2
Training loss: 0.8430410514986036
Validation loss: 2.5855571617196227

Epoch: 5| Step: 3
Training loss: 0.627543637745501
Validation loss: 2.571638986646454

Epoch: 5| Step: 4
Training loss: 0.7304947384377826
Validation loss: 2.509255604158837

Epoch: 5| Step: 5
Training loss: 0.6268572630041676
Validation loss: 2.529277065546518

Epoch: 5| Step: 6
Training loss: 0.35887208247020264
Validation loss: 2.5154488186627124

Epoch: 5| Step: 7
Training loss: 0.4300185402211064
Validation loss: 2.5279073410616544

Epoch: 5| Step: 8
Training loss: 0.6412333879308229
Validation loss: 2.5611847744439835

Epoch: 5| Step: 9
Training loss: 0.5421544837243459
Validation loss: 2.5615649144184363

Epoch: 5| Step: 10
Training loss: 0.3746650113506732
Validation loss: 2.571819237940222

Epoch: 296| Step: 0
Training loss: 0.5030014135083004
Validation loss: 2.5354617420940375

Epoch: 5| Step: 1
Training loss: 0.2899738713735248
Validation loss: 2.5578813295118215

Epoch: 5| Step: 2
Training loss: 0.4310786528811043
Validation loss: 2.5203428436184536

Epoch: 5| Step: 3
Training loss: 0.8801834998305017
Validation loss: 2.526546762093112

Epoch: 5| Step: 4
Training loss: 0.8070978526783882
Validation loss: 2.5282944672897143

Epoch: 5| Step: 5
Training loss: 0.37941670199583344
Validation loss: 2.557414852114591

Epoch: 5| Step: 6
Training loss: 0.6076040945233449
Validation loss: 2.5562828752040576

Epoch: 5| Step: 7
Training loss: 0.37295183498986206
Validation loss: 2.5855710083079484

Epoch: 5| Step: 8
Training loss: 0.6867937882429648
Validation loss: 2.5913493530335363

Epoch: 5| Step: 9
Training loss: 0.7018479724344109
Validation loss: 2.5679029994015194

Epoch: 5| Step: 10
Training loss: 0.5085053632260199
Validation loss: 2.5737071917566134

Epoch: 297| Step: 0
Training loss: 0.4604309984568601
Validation loss: 2.55182106389855

Epoch: 5| Step: 1
Training loss: 0.6387733355550149
Validation loss: 2.5111532943623778

Epoch: 5| Step: 2
Training loss: 0.8415854203948444
Validation loss: 2.5275744844322645

Epoch: 5| Step: 3
Training loss: 0.6411147687768348
Validation loss: 2.4837064560047315

Epoch: 5| Step: 4
Training loss: 0.46373909235668326
Validation loss: 2.4627934481483735

Epoch: 5| Step: 5
Training loss: 0.5813592705510839
Validation loss: 2.517987950835684

Epoch: 5| Step: 6
Training loss: 0.7010309826932812
Validation loss: 2.5405304532830675

Epoch: 5| Step: 7
Training loss: 0.38275638480439245
Validation loss: 2.5317884475364587

Epoch: 5| Step: 8
Training loss: 0.38721742171095963
Validation loss: 2.5938918229000567

Epoch: 5| Step: 9
Training loss: 0.5133612966610359
Validation loss: 2.6121639452621266

Epoch: 5| Step: 10
Training loss: 0.6425773829308025
Validation loss: 2.6026047036781663

Epoch: 298| Step: 0
Training loss: 0.6880402176518571
Validation loss: 2.5877749327456856

Epoch: 5| Step: 1
Training loss: 0.6353124053549708
Validation loss: 2.5652957174912907

Epoch: 5| Step: 2
Training loss: 0.5841244430718929
Validation loss: 2.5361515140996516

Epoch: 5| Step: 3
Training loss: 0.3400582918868309
Validation loss: 2.5453712477700043

Epoch: 5| Step: 4
Training loss: 0.6209064897109298
Validation loss: 2.561413905202195

Epoch: 5| Step: 5
Training loss: 0.7678170645193477
Validation loss: 2.539687485680608

Epoch: 5| Step: 6
Training loss: 0.48279432058829896
Validation loss: 2.5686886397972497

Epoch: 5| Step: 7
Training loss: 0.47606993061971026
Validation loss: 2.55624997105656

Epoch: 5| Step: 8
Training loss: 0.5487132647998549
Validation loss: 2.6057677107532906

Epoch: 5| Step: 9
Training loss: 0.6500799909302896
Validation loss: 2.5672864413627368

Epoch: 5| Step: 10
Training loss: 0.3730387661836514
Validation loss: 2.5892464593610924

Epoch: 299| Step: 0
Training loss: 0.5758613654912058
Validation loss: 2.588299504718481

Epoch: 5| Step: 1
Training loss: 0.5678159075200694
Validation loss: 2.5198138548547258

Epoch: 5| Step: 2
Training loss: 0.4348974989289998
Validation loss: 2.5834666173757683

Epoch: 5| Step: 3
Training loss: 0.18747025492287145
Validation loss: 2.571550914910322

Epoch: 5| Step: 4
Training loss: 0.857118035706389
Validation loss: 2.5637875585402337

Epoch: 5| Step: 5
Training loss: 0.3865100605766871
Validation loss: 2.5555584878386015

Epoch: 5| Step: 6
Training loss: 0.5066140043607599
Validation loss: 2.5384923868188265

Epoch: 5| Step: 7
Training loss: 0.31834821154908527
Validation loss: 2.5127793741157607

Epoch: 5| Step: 8
Training loss: 0.6183947815099359
Validation loss: 2.5361876614415197

Epoch: 5| Step: 9
Training loss: 0.5751777477853205
Validation loss: 2.5211801848799493

Epoch: 5| Step: 10
Training loss: 0.9184883432764793
Validation loss: 2.5515368754062338

Epoch: 300| Step: 0
Training loss: 0.4888711798851989
Validation loss: 2.5262327366580584

Epoch: 5| Step: 1
Training loss: 0.5199786389530079
Validation loss: 2.501572939099828

Epoch: 5| Step: 2
Training loss: 0.4005364129352107
Validation loss: 2.489462867369513

Epoch: 5| Step: 3
Training loss: 0.800846748464628
Validation loss: 2.4380386931029996

Epoch: 5| Step: 4
Training loss: 0.8069296404526936
Validation loss: 2.523941283863161

Epoch: 5| Step: 5
Training loss: 0.6600952120219674
Validation loss: 2.5255203329867637

Epoch: 5| Step: 6
Training loss: 0.48485605901004836
Validation loss: 2.5312408863360836

Epoch: 5| Step: 7
Training loss: 0.44740281645447244
Validation loss: 2.481692075063431

Epoch: 5| Step: 8
Training loss: 0.46887477167846525
Validation loss: 2.551932440979133

Epoch: 5| Step: 9
Training loss: 0.4957193779291205
Validation loss: 2.495444237854508

Epoch: 5| Step: 10
Training loss: 0.5434944297624404
Validation loss: 2.4992562397686164

Epoch: 301| Step: 0
Training loss: 0.6629255547478128
Validation loss: 2.524082361646608

Epoch: 5| Step: 1
Training loss: 0.5560109374853864
Validation loss: 2.5533464498265195

Epoch: 5| Step: 2
Training loss: 0.4595608114872738
Validation loss: 2.560740725606769

Epoch: 5| Step: 3
Training loss: 0.44267049702541666
Validation loss: 2.562898433312484

Epoch: 5| Step: 4
Training loss: 0.672456223789594
Validation loss: 2.5564078969734965

Epoch: 5| Step: 5
Training loss: 0.5445808793031854
Validation loss: 2.5574465729521774

Epoch: 5| Step: 6
Training loss: 0.4830892942245187
Validation loss: 2.5047284939229866

Epoch: 5| Step: 7
Training loss: 0.518107075582496
Validation loss: 2.5199706495473393

Epoch: 5| Step: 8
Training loss: 0.6801069653403266
Validation loss: 2.494531113356425

Epoch: 5| Step: 9
Training loss: 0.7194935642773742
Validation loss: 2.531321937898986

Epoch: 5| Step: 10
Training loss: 0.4410003551343323
Validation loss: 2.554753419366132

Epoch: 302| Step: 0
Training loss: 0.6730598382039075
Validation loss: 2.5678774974248118

Epoch: 5| Step: 1
Training loss: 0.4647217598492428
Validation loss: 2.5494096274243176

Epoch: 5| Step: 2
Training loss: 0.4352191324873954
Validation loss: 2.524547852140276

Epoch: 5| Step: 3
Training loss: 0.5911700009910792
Validation loss: 2.523327892283404

Epoch: 5| Step: 4
Training loss: 0.5585218263218594
Validation loss: 2.511315034691568

Epoch: 5| Step: 5
Training loss: 0.662612273941213
Validation loss: 2.460677482123243

Epoch: 5| Step: 6
Training loss: 0.51288559062082
Validation loss: 2.4586234431653002

Epoch: 5| Step: 7
Training loss: 0.5781235050491387
Validation loss: 2.488712194077137

Epoch: 5| Step: 8
Training loss: 0.6297475506945777
Validation loss: 2.4953732777348074

Epoch: 5| Step: 9
Training loss: 0.4871387084351588
Validation loss: 2.5277419539797203

Epoch: 5| Step: 10
Training loss: 0.6018486828462468
Validation loss: 2.556092457625562

Epoch: 303| Step: 0
Training loss: 0.5919854395628743
Validation loss: 2.580206161859044

Epoch: 5| Step: 1
Training loss: 0.5652118586106768
Validation loss: 2.5384547018681496

Epoch: 5| Step: 2
Training loss: 0.60520008648382
Validation loss: 2.5244546024866623

Epoch: 5| Step: 3
Training loss: 0.6287076174366021
Validation loss: 2.5020291625225126

Epoch: 5| Step: 4
Training loss: 0.2876772940302791
Validation loss: 2.521913795382706

Epoch: 5| Step: 5
Training loss: 0.6818429815955107
Validation loss: 2.5121509755064646

Epoch: 5| Step: 6
Training loss: 0.5617139410203027
Validation loss: 2.5402481458520834

Epoch: 5| Step: 7
Training loss: 0.6080828930664699
Validation loss: 2.5779114068861095

Epoch: 5| Step: 8
Training loss: 0.4320507259014483
Validation loss: 2.6200392923334044

Epoch: 5| Step: 9
Training loss: 0.5952167714363908
Validation loss: 2.6311055241444925

Epoch: 5| Step: 10
Training loss: 0.675806430942862
Validation loss: 2.494049725102423

Epoch: 304| Step: 0
Training loss: 0.5346592732597706
Validation loss: 2.500267147844313

Epoch: 5| Step: 1
Training loss: 0.3817502679355483
Validation loss: 2.495912918056479

Epoch: 5| Step: 2
Training loss: 0.5269662706956654
Validation loss: 2.5052379618085205

Epoch: 5| Step: 3
Training loss: 0.37987027968887915
Validation loss: 2.540745065946277

Epoch: 5| Step: 4
Training loss: 0.6994725624467658
Validation loss: 2.525167402763124

Epoch: 5| Step: 5
Training loss: 0.45621531759674944
Validation loss: 2.539265048875054

Epoch: 5| Step: 6
Training loss: 0.6268333724739585
Validation loss: 2.5813528503293237

Epoch: 5| Step: 7
Training loss: 0.6371001523003481
Validation loss: 2.607936784784211

Epoch: 5| Step: 8
Training loss: 0.6033509162409673
Validation loss: 2.592105919167629

Epoch: 5| Step: 9
Training loss: 0.697920291568585
Validation loss: 2.578761568407415

Epoch: 5| Step: 10
Training loss: 0.5373407039128936
Validation loss: 2.557586788896186

Epoch: 305| Step: 0
Training loss: 0.3897982813554067
Validation loss: 2.5550278465178002

Epoch: 5| Step: 1
Training loss: 0.5113400812696427
Validation loss: 2.5355637007706786

Epoch: 5| Step: 2
Training loss: 0.9887634427860388
Validation loss: 2.5016360938465447

Epoch: 5| Step: 3
Training loss: 0.5415855738263857
Validation loss: 2.54203581150811

Epoch: 5| Step: 4
Training loss: 0.607266985902644
Validation loss: 2.5785808260951297

Epoch: 5| Step: 5
Training loss: 0.5344921641707685
Validation loss: 2.5446527367239002

Epoch: 5| Step: 6
Training loss: 0.3512559720037368
Validation loss: 2.5409995122487925

Epoch: 5| Step: 7
Training loss: 0.5466413271175606
Validation loss: 2.5548377172103662

Epoch: 5| Step: 8
Training loss: 0.4843937962484438
Validation loss: 2.5559331426009404

Epoch: 5| Step: 9
Training loss: 0.4690788069501174
Validation loss: 2.5985769898385196

Epoch: 5| Step: 10
Training loss: 0.4023069901941709
Validation loss: 2.552372765133287

Epoch: 306| Step: 0
Training loss: 0.6912814097658008
Validation loss: 2.567565616141808

Epoch: 5| Step: 1
Training loss: 0.673803644150232
Validation loss: 2.5541296701719984

Epoch: 5| Step: 2
Training loss: 0.32959740524095266
Validation loss: 2.55041709551448

Epoch: 5| Step: 3
Training loss: 0.5106285654454786
Validation loss: 2.52464848165803

Epoch: 5| Step: 4
Training loss: 0.5523836350777114
Validation loss: 2.5473882974636908

Epoch: 5| Step: 5
Training loss: 0.27112453956441795
Validation loss: 2.5760551717964204

Epoch: 5| Step: 6
Training loss: 0.3209289573416528
Validation loss: 2.5619100346241224

Epoch: 5| Step: 7
Training loss: 0.5809950084652419
Validation loss: 2.5738234316861672

Epoch: 5| Step: 8
Training loss: 0.8420093383316527
Validation loss: 2.5262748056717013

Epoch: 5| Step: 9
Training loss: 0.3064321185663951
Validation loss: 2.5732192224078396

Epoch: 5| Step: 10
Training loss: 0.6153613489307882
Validation loss: 2.526911548818304

Epoch: 307| Step: 0
Training loss: 0.39154626926841235
Validation loss: 2.519776983250163

Epoch: 5| Step: 1
Training loss: 0.5364450959235953
Validation loss: 2.5076682036116438

Epoch: 5| Step: 2
Training loss: 0.5826884917598878
Validation loss: 2.5232877055398126

Epoch: 5| Step: 3
Training loss: 0.5910065412611191
Validation loss: 2.548639083764977

Epoch: 5| Step: 4
Training loss: 0.562115140226594
Validation loss: 2.599965945400232

Epoch: 5| Step: 5
Training loss: 0.6446343772920693
Validation loss: 2.6081057802079273

Epoch: 5| Step: 6
Training loss: 0.28955106429653904
Validation loss: 2.6138675620027576

Epoch: 5| Step: 7
Training loss: 0.692068397143386
Validation loss: 2.566148107483351

Epoch: 5| Step: 8
Training loss: 0.4486590007865845
Validation loss: 2.5447870600863367

Epoch: 5| Step: 9
Training loss: 0.5195620534842849
Validation loss: 2.5303513412769925

Epoch: 5| Step: 10
Training loss: 0.6101347026854531
Validation loss: 2.4728811032493985

Epoch: 308| Step: 0
Training loss: 0.5914264690616511
Validation loss: 2.5110054991803237

Epoch: 5| Step: 1
Training loss: 0.37280165516635294
Validation loss: 2.4735257389794816

Epoch: 5| Step: 2
Training loss: 0.5859685762429653
Validation loss: 2.5207417924966165

Epoch: 5| Step: 3
Training loss: 0.3169805941809181
Validation loss: 2.5452161870645247

Epoch: 5| Step: 4
Training loss: 0.4821331380187454
Validation loss: 2.5483224926331545

Epoch: 5| Step: 5
Training loss: 0.3701417054281296
Validation loss: 2.556670115353674

Epoch: 5| Step: 6
Training loss: 0.46920623828671004
Validation loss: 2.595463627122833

Epoch: 5| Step: 7
Training loss: 0.8861232556102456
Validation loss: 2.5555378717613477

Epoch: 5| Step: 8
Training loss: 0.4751589226890594
Validation loss: 2.5341718666116733

Epoch: 5| Step: 9
Training loss: 0.6059456946383007
Validation loss: 2.4736360708982588

Epoch: 5| Step: 10
Training loss: 0.6643453108002414
Validation loss: 2.4645242034884207

Epoch: 309| Step: 0
Training loss: 0.5140578701657219
Validation loss: 2.462205954298874

Epoch: 5| Step: 1
Training loss: 0.7700144223930869
Validation loss: 2.3908822461901695

Epoch: 5| Step: 2
Training loss: 0.38342281269897927
Validation loss: 2.468094029992688

Epoch: 5| Step: 3
Training loss: 0.42036898563130953
Validation loss: 2.480939475473688

Epoch: 5| Step: 4
Training loss: 0.29695655304922974
Validation loss: 2.5220787092830004

Epoch: 5| Step: 5
Training loss: 0.4807653674557326
Validation loss: 2.5524659289196623

Epoch: 5| Step: 6
Training loss: 0.5109041442249042
Validation loss: 2.591200990296462

Epoch: 5| Step: 7
Training loss: 0.7878776946399235
Validation loss: 2.5712143184037317

Epoch: 5| Step: 8
Training loss: 0.5113204687374425
Validation loss: 2.530485350911527

Epoch: 5| Step: 9
Training loss: 0.7117723028174421
Validation loss: 2.510835190854656

Epoch: 5| Step: 10
Training loss: 0.5835248995896937
Validation loss: 2.4890985527054217

Epoch: 310| Step: 0
Training loss: 0.4246443171718403
Validation loss: 2.501065612640887

Epoch: 5| Step: 1
Training loss: 0.42304674537776465
Validation loss: 2.516186346261641

Epoch: 5| Step: 2
Training loss: 0.6747451954741583
Validation loss: 2.5135304403493985

Epoch: 5| Step: 3
Training loss: 0.6259859890756198
Validation loss: 2.582089658334732

Epoch: 5| Step: 4
Training loss: 0.7087137005103519
Validation loss: 2.6064041809368383

Epoch: 5| Step: 5
Training loss: 0.6047119579248175
Validation loss: 2.589688472398542

Epoch: 5| Step: 6
Training loss: 0.6088421276806913
Validation loss: 2.6168785376905097

Epoch: 5| Step: 7
Training loss: 0.5971162138850099
Validation loss: 2.5775821291980483

Epoch: 5| Step: 8
Training loss: 0.3758153198088184
Validation loss: 2.5573920967523622

Epoch: 5| Step: 9
Training loss: 0.3056919828588108
Validation loss: 2.476837116063406

Epoch: 5| Step: 10
Training loss: 0.546134993014912
Validation loss: 2.4569477476835697

Epoch: 311| Step: 0
Training loss: 0.5317153855676111
Validation loss: 2.454473535137267

Epoch: 5| Step: 1
Training loss: 0.7551122319253905
Validation loss: 2.4684938106007337

Epoch: 5| Step: 2
Training loss: 0.760534216447766
Validation loss: 2.4525258283729063

Epoch: 5| Step: 3
Training loss: 0.6552048034653748
Validation loss: 2.4699597087661234

Epoch: 5| Step: 4
Training loss: 0.4113743631977541
Validation loss: 2.5134368105040807

Epoch: 5| Step: 5
Training loss: 0.37991776097223673
Validation loss: 2.579408658060044

Epoch: 5| Step: 6
Training loss: 0.3960347562418129
Validation loss: 2.581159048979173

Epoch: 5| Step: 7
Training loss: 0.38510266176892244
Validation loss: 2.5526846605222357

Epoch: 5| Step: 8
Training loss: 0.4386535830942867
Validation loss: 2.5676307495938926

Epoch: 5| Step: 9
Training loss: 0.3661109686142762
Validation loss: 2.556837841914199

Epoch: 5| Step: 10
Training loss: 0.6591806143294989
Validation loss: 2.571125663780391

Epoch: 312| Step: 0
Training loss: 0.5997500922380689
Validation loss: 2.503963844336096

Epoch: 5| Step: 1
Training loss: 0.6063999767219795
Validation loss: 2.515067444652556

Epoch: 5| Step: 2
Training loss: 0.5549187782498719
Validation loss: 2.4964667342686924

Epoch: 5| Step: 3
Training loss: 0.36455047550183484
Validation loss: 2.5294062154453796

Epoch: 5| Step: 4
Training loss: 0.363820035359996
Validation loss: 2.5237667806480992

Epoch: 5| Step: 5
Training loss: 0.5775033598550269
Validation loss: 2.539624208676594

Epoch: 5| Step: 6
Training loss: 0.4734937640708998
Validation loss: 2.5508038110684903

Epoch: 5| Step: 7
Training loss: 0.4251623467706052
Validation loss: 2.590873038952778

Epoch: 5| Step: 8
Training loss: 0.553928608301869
Validation loss: 2.586031123018863

Epoch: 5| Step: 9
Training loss: 0.6103350583706112
Validation loss: 2.602490218155787

Epoch: 5| Step: 10
Training loss: 0.6207605103744817
Validation loss: 2.592081735575138

Epoch: 313| Step: 0
Training loss: 0.39658294354493306
Validation loss: 2.5136988649274543

Epoch: 5| Step: 1
Training loss: 0.36928226639768424
Validation loss: 2.4883587721261495

Epoch: 5| Step: 2
Training loss: 0.5174126414495045
Validation loss: 2.396719203707852

Epoch: 5| Step: 3
Training loss: 0.4496397947730648
Validation loss: 2.392138380733235

Epoch: 5| Step: 4
Training loss: 0.582916814964481
Validation loss: 2.4000344579027817

Epoch: 5| Step: 5
Training loss: 0.5600719234140771
Validation loss: 2.3931689709356876

Epoch: 5| Step: 6
Training loss: 0.7660730958006479
Validation loss: 2.467433234037518

Epoch: 5| Step: 7
Training loss: 0.43645138753980056
Validation loss: 2.505547914140999

Epoch: 5| Step: 8
Training loss: 0.49685209989258494
Validation loss: 2.5673992744174883

Epoch: 5| Step: 9
Training loss: 0.7951558211706425
Validation loss: 2.606867687383161

Epoch: 5| Step: 10
Training loss: 0.562725948941658
Validation loss: 2.5719546593381186

Epoch: 314| Step: 0
Training loss: 0.6091735702554855
Validation loss: 2.4982438328318723

Epoch: 5| Step: 1
Training loss: 0.4976157323131909
Validation loss: 2.462529770158091

Epoch: 5| Step: 2
Training loss: 0.737938210854778
Validation loss: 2.4127681363199893

Epoch: 5| Step: 3
Training loss: 0.45246905500284595
Validation loss: 2.3859358618052022

Epoch: 5| Step: 4
Training loss: 0.3537313951445741
Validation loss: 2.409606672026155

Epoch: 5| Step: 5
Training loss: 0.5748998793219829
Validation loss: 2.5404730754026104

Epoch: 5| Step: 6
Training loss: 0.3749258842341336
Validation loss: 2.5883685219341275

Epoch: 5| Step: 7
Training loss: 0.5994299704093017
Validation loss: 2.646317565986358

Epoch: 5| Step: 8
Training loss: 0.6851070982332996
Validation loss: 2.6701457672867623

Epoch: 5| Step: 9
Training loss: 0.3843673736311914
Validation loss: 2.6474676616399915

Epoch: 5| Step: 10
Training loss: 0.5942689986427687
Validation loss: 2.624313217772315

Epoch: 315| Step: 0
Training loss: 0.6102754835397137
Validation loss: 2.566689011367723

Epoch: 5| Step: 1
Training loss: 0.3385326482109578
Validation loss: 2.5105163107837902

Epoch: 5| Step: 2
Training loss: 0.40110872583253904
Validation loss: 2.457755110662277

Epoch: 5| Step: 3
Training loss: 0.5804898120863408
Validation loss: 2.423732760352729

Epoch: 5| Step: 4
Training loss: 0.49678032590894483
Validation loss: 2.471501107391666

Epoch: 5| Step: 5
Training loss: 0.5976148354137274
Validation loss: 2.5288389819527044

Epoch: 5| Step: 6
Training loss: 0.727374085020128
Validation loss: 2.559835844336711

Epoch: 5| Step: 7
Training loss: 0.6069024615846458
Validation loss: 2.6096168284671566

Epoch: 5| Step: 8
Training loss: 0.5128711507895922
Validation loss: 2.6727030450326295

Epoch: 5| Step: 9
Training loss: 0.6011410016813321
Validation loss: 2.6505113354852776

Epoch: 5| Step: 10
Training loss: 0.4277832316884211
Validation loss: 2.6356078190473227

Epoch: 316| Step: 0
Training loss: 0.3211539427869354
Validation loss: 2.5325557329216037

Epoch: 5| Step: 1
Training loss: 0.5415465301166533
Validation loss: 2.4870462264353286

Epoch: 5| Step: 2
Training loss: 0.4283965746074795
Validation loss: 2.47000229458974

Epoch: 5| Step: 3
Training loss: 0.6057658051299604
Validation loss: 2.4320742556567643

Epoch: 5| Step: 4
Training loss: 0.6115862998951096
Validation loss: 2.4533933408242423

Epoch: 5| Step: 5
Training loss: 0.4546141981572765
Validation loss: 2.4859680663130437

Epoch: 5| Step: 6
Training loss: 0.5551535032393888
Validation loss: 2.4750232192659736

Epoch: 5| Step: 7
Training loss: 0.700379776963721
Validation loss: 2.5255264428303943

Epoch: 5| Step: 8
Training loss: 0.5197342210826824
Validation loss: 2.526177190036133

Epoch: 5| Step: 9
Training loss: 0.6646588732998427
Validation loss: 2.497089855911301

Epoch: 5| Step: 10
Training loss: 0.44507908978189414
Validation loss: 2.487356207048175

Epoch: 317| Step: 0
Training loss: 0.6225551709847699
Validation loss: 2.4134311686119627

Epoch: 5| Step: 1
Training loss: 0.5275962790087569
Validation loss: 2.3912125150446966

Epoch: 5| Step: 2
Training loss: 0.5954045282153898
Validation loss: 2.397157047825143

Epoch: 5| Step: 3
Training loss: 0.4214134870847623
Validation loss: 2.430321123231234

Epoch: 5| Step: 4
Training loss: 0.4556606313851779
Validation loss: 2.432681711925017

Epoch: 5| Step: 5
Training loss: 0.4307615208803707
Validation loss: 2.509213553757428

Epoch: 5| Step: 6
Training loss: 0.608900668084625
Validation loss: 2.5045104551470025

Epoch: 5| Step: 7
Training loss: 0.6041838024164767
Validation loss: 2.5411304649297204

Epoch: 5| Step: 8
Training loss: 0.3958810810938583
Validation loss: 2.568407743015618

Epoch: 5| Step: 9
Training loss: 0.4834325913202863
Validation loss: 2.5442127995305315

Epoch: 5| Step: 10
Training loss: 0.6913005510992113
Validation loss: 2.5513897962800036

Epoch: 318| Step: 0
Training loss: 0.5090320614589265
Validation loss: 2.5693975458924925

Epoch: 5| Step: 1
Training loss: 0.4541289618645073
Validation loss: 2.520682642015915

Epoch: 5| Step: 2
Training loss: 0.47917903144749846
Validation loss: 2.4872955462915702

Epoch: 5| Step: 3
Training loss: 0.5232282476501272
Validation loss: 2.420820635864186

Epoch: 5| Step: 4
Training loss: 0.5072589498174994
Validation loss: 2.4190574677391252

Epoch: 5| Step: 5
Training loss: 0.3398875942667667
Validation loss: 2.476795286391527

Epoch: 5| Step: 6
Training loss: 0.7376243050123832
Validation loss: 2.502568195323481

Epoch: 5| Step: 7
Training loss: 0.5492630182389454
Validation loss: 2.5119462494948874

Epoch: 5| Step: 8
Training loss: 0.5063962995804522
Validation loss: 2.481136452231588

Epoch: 5| Step: 9
Training loss: 0.37968384697809066
Validation loss: 2.5140398254373375

Epoch: 5| Step: 10
Training loss: 0.39407632112277363
Validation loss: 2.5629512830683177

Epoch: 319| Step: 0
Training loss: 0.5916970045970962
Validation loss: 2.6064988205270545

Epoch: 5| Step: 1
Training loss: 0.5849093763142853
Validation loss: 2.6338769593868436

Epoch: 5| Step: 2
Training loss: 0.421542760925567
Validation loss: 2.6501315216006174

Epoch: 5| Step: 3
Training loss: 0.2845956831640532
Validation loss: 2.5879934423681545

Epoch: 5| Step: 4
Training loss: 0.625690031606468
Validation loss: 2.5483936246710717

Epoch: 5| Step: 5
Training loss: 0.5387548868174533
Validation loss: 2.489888380586283

Epoch: 5| Step: 6
Training loss: 0.5864453467313995
Validation loss: 2.455443770935764

Epoch: 5| Step: 7
Training loss: 0.35535305362123126
Validation loss: 2.4585574019987204

Epoch: 5| Step: 8
Training loss: 0.4896772798397982
Validation loss: 2.450205426019977

Epoch: 5| Step: 9
Training loss: 0.4463548006686052
Validation loss: 2.4907331152144123

Epoch: 5| Step: 10
Training loss: 0.529974668860133
Validation loss: 2.5259099635271225

Epoch: 320| Step: 0
Training loss: 0.5938608668369291
Validation loss: 2.5384074704178827

Epoch: 5| Step: 1
Training loss: 0.42136581917184557
Validation loss: 2.5112040030581015

Epoch: 5| Step: 2
Training loss: 0.5325351765256574
Validation loss: 2.564993928562576

Epoch: 5| Step: 3
Training loss: 0.7169752184949296
Validation loss: 2.564092167986263

Epoch: 5| Step: 4
Training loss: 0.48103489898980817
Validation loss: 2.5890702413823368

Epoch: 5| Step: 5
Training loss: 0.5440931684251985
Validation loss: 2.5533183327695315

Epoch: 5| Step: 6
Training loss: 0.42670609708595564
Validation loss: 2.565544093108614

Epoch: 5| Step: 7
Training loss: 0.25748228831625963
Validation loss: 2.5345510188880893

Epoch: 5| Step: 8
Training loss: 0.3881782771292262
Validation loss: 2.5697245691712665

Epoch: 5| Step: 9
Training loss: 0.3472869819278613
Validation loss: 2.5067544015440224

Epoch: 5| Step: 10
Training loss: 0.5343420698939386
Validation loss: 2.476147995173873

Epoch: 321| Step: 0
Training loss: 0.40013559174156665
Validation loss: 2.510107682022309

Epoch: 5| Step: 1
Training loss: 0.48656816188921115
Validation loss: 2.5031782579800814

Epoch: 5| Step: 2
Training loss: 0.4076121309384419
Validation loss: 2.4940990289996336

Epoch: 5| Step: 3
Training loss: 0.5071539202918739
Validation loss: 2.5140563378632987

Epoch: 5| Step: 4
Training loss: 0.45810652850436506
Validation loss: 2.5389312705179754

Epoch: 5| Step: 5
Training loss: 0.41715485662984475
Validation loss: 2.540920461382075

Epoch: 5| Step: 6
Training loss: 0.6638779776522026
Validation loss: 2.5661646152840834

Epoch: 5| Step: 7
Training loss: 0.6148604210189387
Validation loss: 2.5765790782249285

Epoch: 5| Step: 8
Training loss: 0.5033639754932219
Validation loss: 2.5586176379154124

Epoch: 5| Step: 9
Training loss: 0.34504738810481705
Validation loss: 2.538568724523411

Epoch: 5| Step: 10
Training loss: 0.4820966976009144
Validation loss: 2.568787773428851

Epoch: 322| Step: 0
Training loss: 0.36661572274046683
Validation loss: 2.570982369151135

Epoch: 5| Step: 1
Training loss: 0.4405102539806695
Validation loss: 2.533443993459869

Epoch: 5| Step: 2
Training loss: 0.4455316405925067
Validation loss: 2.5360526976167725

Epoch: 5| Step: 3
Training loss: 0.6850415402367769
Validation loss: 2.519245925904308

Epoch: 5| Step: 4
Training loss: 0.5687926171653265
Validation loss: 2.559375586435702

Epoch: 5| Step: 5
Training loss: 0.7285850021422893
Validation loss: 2.5637628128389878

Epoch: 5| Step: 6
Training loss: 0.4966004404802324
Validation loss: 2.589073725816703

Epoch: 5| Step: 7
Training loss: 0.5316139545239499
Validation loss: 2.6088015244417178

Epoch: 5| Step: 8
Training loss: 0.334661177250988
Validation loss: 2.581948153755166

Epoch: 5| Step: 9
Training loss: 0.566928859200337
Validation loss: 2.5963543940978373

Epoch: 5| Step: 10
Training loss: 0.4269083311938989
Validation loss: 2.5351037258709646

Epoch: 323| Step: 0
Training loss: 0.6184843658762594
Validation loss: 2.53429960982328

Epoch: 5| Step: 1
Training loss: 0.6172039174660783
Validation loss: 2.5009687300360484

Epoch: 5| Step: 2
Training loss: 0.29815079713366516
Validation loss: 2.5026285760345224

Epoch: 5| Step: 3
Training loss: 0.706953286777882
Validation loss: 2.473734384621653

Epoch: 5| Step: 4
Training loss: 0.5140044437542907
Validation loss: 2.450802683729425

Epoch: 5| Step: 5
Training loss: 0.5036597129332075
Validation loss: 2.4954008456956536

Epoch: 5| Step: 6
Training loss: 0.3397835206778913
Validation loss: 2.4888330263372054

Epoch: 5| Step: 7
Training loss: 0.2753343321709569
Validation loss: 2.534066056148378

Epoch: 5| Step: 8
Training loss: 0.6147976248476241
Validation loss: 2.5110096912458792

Epoch: 5| Step: 9
Training loss: 0.2652144906367319
Validation loss: 2.5060505057231492

Epoch: 5| Step: 10
Training loss: 0.2763607711855936
Validation loss: 2.5348680981763905

Epoch: 324| Step: 0
Training loss: 0.6665038391783964
Validation loss: 2.499633210460122

Epoch: 5| Step: 1
Training loss: 0.5943631720343776
Validation loss: 2.482034240020769

Epoch: 5| Step: 2
Training loss: 0.3009709094665898
Validation loss: 2.4579082334902105

Epoch: 5| Step: 3
Training loss: 0.2843577295864972
Validation loss: 2.4989955401895845

Epoch: 5| Step: 4
Training loss: 0.46165488070834465
Validation loss: 2.4897892045149685

Epoch: 5| Step: 5
Training loss: 0.46758209010126456
Validation loss: 2.4668938853137177

Epoch: 5| Step: 6
Training loss: 0.505590448366025
Validation loss: 2.48387810449936

Epoch: 5| Step: 7
Training loss: 0.5193116433786986
Validation loss: 2.482899492934032

Epoch: 5| Step: 8
Training loss: 0.478854359216038
Validation loss: 2.4800340967500603

Epoch: 5| Step: 9
Training loss: 0.47763321149307003
Validation loss: 2.498223294838779

Epoch: 5| Step: 10
Training loss: 0.33549088353990336
Validation loss: 2.511539263544662

Epoch: 325| Step: 0
Training loss: 0.38573326390241947
Validation loss: 2.5303622347068218

Epoch: 5| Step: 1
Training loss: 0.36706664754692797
Validation loss: 2.527181546334625

Epoch: 5| Step: 2
Training loss: 0.3873748415663211
Validation loss: 2.50471240157227

Epoch: 5| Step: 3
Training loss: 0.45913508761255295
Validation loss: 2.5402017026504287

Epoch: 5| Step: 4
Training loss: 0.48055872811236133
Validation loss: 2.4951365715420004

Epoch: 5| Step: 5
Training loss: 0.5138504530162026
Validation loss: 2.4783997156400086

Epoch: 5| Step: 6
Training loss: 0.6373809226404848
Validation loss: 2.491138423767766

Epoch: 5| Step: 7
Training loss: 0.3537662102722365
Validation loss: 2.5018665708323264

Epoch: 5| Step: 8
Training loss: 0.43337426343821694
Validation loss: 2.500007752437262

Epoch: 5| Step: 9
Training loss: 0.568016473163562
Validation loss: 2.517655305589399

Epoch: 5| Step: 10
Training loss: 0.4809300139143859
Validation loss: 2.519856652139518

Epoch: 326| Step: 0
Training loss: 0.6541245646403311
Validation loss: 2.522128703302161

Epoch: 5| Step: 1
Training loss: 0.6047000558421943
Validation loss: 2.5158949131213357

Epoch: 5| Step: 2
Training loss: 0.27779346593954335
Validation loss: 2.512068847687745

Epoch: 5| Step: 3
Training loss: 0.3324754996702371
Validation loss: 2.4949788470716268

Epoch: 5| Step: 4
Training loss: 0.5909706365855674
Validation loss: 2.4983310276315756

Epoch: 5| Step: 5
Training loss: 0.316018384867194
Validation loss: 2.566775556997135

Epoch: 5| Step: 6
Training loss: 0.49022501294440823
Validation loss: 2.5200234860388524

Epoch: 5| Step: 7
Training loss: 0.47126502218005856
Validation loss: 2.5723453595051047

Epoch: 5| Step: 8
Training loss: 0.2881633719133105
Validation loss: 2.5582672684866035

Epoch: 5| Step: 9
Training loss: 0.459030084160137
Validation loss: 2.5731672092182216

Epoch: 5| Step: 10
Training loss: 0.338938329083306
Validation loss: 2.5851189812707016

Epoch: 327| Step: 0
Training loss: 0.4459634172945244
Validation loss: 2.5743988296292626

Epoch: 5| Step: 1
Training loss: 0.3262422565659367
Validation loss: 2.5746010037434166

Epoch: 5| Step: 2
Training loss: 0.5145503607571025
Validation loss: 2.57705321744535

Epoch: 5| Step: 3
Training loss: 0.6429906292109414
Validation loss: 2.5768188349848242

Epoch: 5| Step: 4
Training loss: 0.17284889003605833
Validation loss: 2.573647243452564

Epoch: 5| Step: 5
Training loss: 0.4877805966019676
Validation loss: 2.578031246982761

Epoch: 5| Step: 6
Training loss: 0.2761480992940236
Validation loss: 2.5614771818822266

Epoch: 5| Step: 7
Training loss: 0.5217034954663945
Validation loss: 2.569263760829352

Epoch: 5| Step: 8
Training loss: 0.4468174984089818
Validation loss: 2.551286946730991

Epoch: 5| Step: 9
Training loss: 0.48236434222801805
Validation loss: 2.5620360215766285

Epoch: 5| Step: 10
Training loss: 0.5455634056360859
Validation loss: 2.6010618527846385

Epoch: 328| Step: 0
Training loss: 0.4115809809098821
Validation loss: 2.638538135720055

Epoch: 5| Step: 1
Training loss: 0.48970483395023384
Validation loss: 2.5623927790522094

Epoch: 5| Step: 2
Training loss: 0.5064007134445342
Validation loss: 2.6250286540212264

Epoch: 5| Step: 3
Training loss: 0.31420247531364437
Validation loss: 2.6159352460362353

Epoch: 5| Step: 4
Training loss: 0.4802420787028929
Validation loss: 2.6287942381698484

Epoch: 5| Step: 5
Training loss: 0.579009204723804
Validation loss: 2.629362640505861

Epoch: 5| Step: 6
Training loss: 0.5281166064707075
Validation loss: 2.604236010869

Epoch: 5| Step: 7
Training loss: 0.19095426833885268
Validation loss: 2.6257152159231674

Epoch: 5| Step: 8
Training loss: 0.32807845966343663
Validation loss: 2.583721724802963

Epoch: 5| Step: 9
Training loss: 0.3733270401970622
Validation loss: 2.5319182135418434

Epoch: 5| Step: 10
Training loss: 0.6446945445960507
Validation loss: 2.519305531911972

Epoch: 329| Step: 0
Training loss: 0.3968942900347602
Validation loss: 2.5061986473251388

Epoch: 5| Step: 1
Training loss: 0.6893732386659064
Validation loss: 2.5153205206818865

Epoch: 5| Step: 2
Training loss: 0.41506293733031224
Validation loss: 2.4781075184463366

Epoch: 5| Step: 3
Training loss: 0.28800259693948477
Validation loss: 2.5089149325209474

Epoch: 5| Step: 4
Training loss: 0.4326232151963507
Validation loss: 2.5720140869224872

Epoch: 5| Step: 5
Training loss: 0.5537566850659124
Validation loss: 2.573623482089706

Epoch: 5| Step: 6
Training loss: 0.4054148232057746
Validation loss: 2.568949083733801

Epoch: 5| Step: 7
Training loss: 0.3812581053638293
Validation loss: 2.555975849642394

Epoch: 5| Step: 8
Training loss: 0.29806759613521505
Validation loss: 2.589460246624714

Epoch: 5| Step: 9
Training loss: 0.4292992311504987
Validation loss: 2.5524305200808044

Epoch: 5| Step: 10
Training loss: 0.5176292538130705
Validation loss: 2.5737153686357135

Epoch: 330| Step: 0
Training loss: 0.3127411984402796
Validation loss: 2.494659798156197

Epoch: 5| Step: 1
Training loss: 0.5748514335929658
Validation loss: 2.5011322800355607

Epoch: 5| Step: 2
Training loss: 0.414049436255169
Validation loss: 2.519600111896414

Epoch: 5| Step: 3
Training loss: 0.48639776504914456
Validation loss: 2.523187218862054

Epoch: 5| Step: 4
Training loss: 0.5772454298077222
Validation loss: 2.505686411790389

Epoch: 5| Step: 5
Training loss: 0.19184101125213504
Validation loss: 2.529260401118918

Epoch: 5| Step: 6
Training loss: 0.4155280430358669
Validation loss: 2.536409973450316

Epoch: 5| Step: 7
Training loss: 0.5052687979102889
Validation loss: 2.587863206213163

Epoch: 5| Step: 8
Training loss: 0.34145679448897975
Validation loss: 2.5728466583554535

Epoch: 5| Step: 9
Training loss: 0.4306823830373239
Validation loss: 2.5872042853503503

Epoch: 5| Step: 10
Training loss: 0.4592809490019365
Validation loss: 2.6000844283275133

Epoch: 331| Step: 0
Training loss: 0.47570561150702745
Validation loss: 2.5893315025333172

Epoch: 5| Step: 1
Training loss: 0.4872245340420518
Validation loss: 2.511298578251934

Epoch: 5| Step: 2
Training loss: 0.1551643624254569
Validation loss: 2.519143881769361

Epoch: 5| Step: 3
Training loss: 0.5512798027926491
Validation loss: 2.5089740942561645

Epoch: 5| Step: 4
Training loss: 0.5295945066218262
Validation loss: 2.5105774551005986

Epoch: 5| Step: 5
Training loss: 0.3862397473712137
Validation loss: 2.511242489979602

Epoch: 5| Step: 6
Training loss: 0.48212337139152267
Validation loss: 2.544661712185979

Epoch: 5| Step: 7
Training loss: 0.397778639479825
Validation loss: 2.55574887598777

Epoch: 5| Step: 8
Training loss: 0.44268729402999685
Validation loss: 2.5806027505386604

Epoch: 5| Step: 9
Training loss: 0.2966219425823505
Validation loss: 2.570197706180357

Epoch: 5| Step: 10
Training loss: 0.5122331261692475
Validation loss: 2.612073903938109

Epoch: 332| Step: 0
Training loss: 0.2750086062341774
Validation loss: 2.5998965694783434

Epoch: 5| Step: 1
Training loss: 0.5008659017491949
Validation loss: 2.5776195161093427

Epoch: 5| Step: 2
Training loss: 0.44185509268608053
Validation loss: 2.544001484428822

Epoch: 5| Step: 3
Training loss: 0.43060913081611896
Validation loss: 2.5327009465673944

Epoch: 5| Step: 4
Training loss: 0.31381422496854144
Validation loss: 2.4928425208943956

Epoch: 5| Step: 5
Training loss: 0.37364233137449465
Validation loss: 2.4671322657387083

Epoch: 5| Step: 6
Training loss: 0.32457841893117007
Validation loss: 2.4676759698498585

Epoch: 5| Step: 7
Training loss: 0.6129182117640636
Validation loss: 2.502153162593043

Epoch: 5| Step: 8
Training loss: 0.4544119153775035
Validation loss: 2.5437260324901523

Epoch: 5| Step: 9
Training loss: 0.42018532583935847
Validation loss: 2.5376464944117685

Epoch: 5| Step: 10
Training loss: 0.5562783651941984
Validation loss: 2.540624575024657

Epoch: 333| Step: 0
Training loss: 0.29924158402609574
Validation loss: 2.5213467003952625

Epoch: 5| Step: 1
Training loss: 0.523679847980979
Validation loss: 2.4972112688531896

Epoch: 5| Step: 2
Training loss: 0.24525875395716662
Validation loss: 2.485543860737603

Epoch: 5| Step: 3
Training loss: 0.5052055935605143
Validation loss: 2.494423072562541

Epoch: 5| Step: 4
Training loss: 0.47319765845748885
Validation loss: 2.4913185269312863

Epoch: 5| Step: 5
Training loss: 0.3644014131712285
Validation loss: 2.4810838880496426

Epoch: 5| Step: 6
Training loss: 0.3066644598572221
Validation loss: 2.5118267745654763

Epoch: 5| Step: 7
Training loss: 0.46181701543956966
Validation loss: 2.5367790794757386

Epoch: 5| Step: 8
Training loss: 0.4367762437347806
Validation loss: 2.569985577968312

Epoch: 5| Step: 9
Training loss: 0.503358765311185
Validation loss: 2.5553913123494563

Epoch: 5| Step: 10
Training loss: 0.5302290362180233
Validation loss: 2.546117381396613

Epoch: 334| Step: 0
Training loss: 0.33635271272712275
Validation loss: 2.5351715479282917

Epoch: 5| Step: 1
Training loss: 0.3215361459607522
Validation loss: 2.533934356456256

Epoch: 5| Step: 2
Training loss: 0.39272573172819036
Validation loss: 2.5425109083160033

Epoch: 5| Step: 3
Training loss: 0.5816897984425783
Validation loss: 2.529779844598746

Epoch: 5| Step: 4
Training loss: 0.27132807836249356
Validation loss: 2.5228076431808657

Epoch: 5| Step: 5
Training loss: 0.6378145208705229
Validation loss: 2.52392624594888

Epoch: 5| Step: 6
Training loss: 0.4210535812328007
Validation loss: 2.510324316037068

Epoch: 5| Step: 7
Training loss: 0.40676542743342065
Validation loss: 2.510282285580445

Epoch: 5| Step: 8
Training loss: 0.44836685009587873
Validation loss: 2.5000488427733565

Epoch: 5| Step: 9
Training loss: 0.4573843317562918
Validation loss: 2.5013919165137177

Epoch: 5| Step: 10
Training loss: 0.29001551831177025
Validation loss: 2.538199631293205

Epoch: 335| Step: 0
Training loss: 0.3420266931926462
Validation loss: 2.537868100821135

Epoch: 5| Step: 1
Training loss: 0.34668132083131964
Validation loss: 2.553071579360671

Epoch: 5| Step: 2
Training loss: 0.5983453405746315
Validation loss: 2.535430062686216

Epoch: 5| Step: 3
Training loss: 0.4487058946192125
Validation loss: 2.5350472637467023

Epoch: 5| Step: 4
Training loss: 0.5015363335839954
Validation loss: 2.537743056690457

Epoch: 5| Step: 5
Training loss: 0.5140709142952874
Validation loss: 2.525766871053978

Epoch: 5| Step: 6
Training loss: 0.35466114988210207
Validation loss: 2.5643325803699115

Epoch: 5| Step: 7
Training loss: 0.29199109029404274
Validation loss: 2.519943415487819

Epoch: 5| Step: 8
Training loss: 0.3500718941247898
Validation loss: 2.478075095483982

Epoch: 5| Step: 9
Training loss: 0.20838244375904835
Validation loss: 2.472767951900906

Epoch: 5| Step: 10
Training loss: 0.5558522045024183
Validation loss: 2.464413417859283

Epoch: 336| Step: 0
Training loss: 0.3741742021967226
Validation loss: 2.5220624160847236

Epoch: 5| Step: 1
Training loss: 0.48155432467047093
Validation loss: 2.5431111613769213

Epoch: 5| Step: 2
Training loss: 0.3854476576880541
Validation loss: 2.535945954709079

Epoch: 5| Step: 3
Training loss: 0.48747531755025136
Validation loss: 2.5447322070986047

Epoch: 5| Step: 4
Training loss: 0.43180554031503465
Validation loss: 2.5859299298292027

Epoch: 5| Step: 5
Training loss: 0.4633955796742178
Validation loss: 2.5322214194737613

Epoch: 5| Step: 6
Training loss: 0.39025623080859184
Validation loss: 2.5349744005369574

Epoch: 5| Step: 7
Training loss: 0.4420281476922931
Validation loss: 2.532737437706577

Epoch: 5| Step: 8
Training loss: 0.4786663674345427
Validation loss: 2.550855749612341

Epoch: 5| Step: 9
Training loss: 0.36338476531531844
Validation loss: 2.4966604836742223

Epoch: 5| Step: 10
Training loss: 0.429381174656699
Validation loss: 2.5311906504538135

Epoch: 337| Step: 0
Training loss: 0.3640104584069155
Validation loss: 2.527630463351187

Epoch: 5| Step: 1
Training loss: 0.60863579640319
Validation loss: 2.559240181090154

Epoch: 5| Step: 2
Training loss: 0.28938839558025364
Validation loss: 2.5367233317508284

Epoch: 5| Step: 3
Training loss: 0.5747028308543135
Validation loss: 2.5334756582377937

Epoch: 5| Step: 4
Training loss: 0.31642763042033245
Validation loss: 2.497769963949894

Epoch: 5| Step: 5
Training loss: 0.4200687949854441
Validation loss: 2.4915859450370226

Epoch: 5| Step: 6
Training loss: 0.5095245258878435
Validation loss: 2.520310739200085

Epoch: 5| Step: 7
Training loss: 0.5345573136599777
Validation loss: 2.4914053899259923

Epoch: 5| Step: 8
Training loss: 0.21342127399009458
Validation loss: 2.533976593531969

Epoch: 5| Step: 9
Training loss: 0.1652680676065076
Validation loss: 2.5391063964684086

Epoch: 5| Step: 10
Training loss: 0.41848270511098185
Validation loss: 2.56056976802472

Epoch: 338| Step: 0
Training loss: 0.48652046107756536
Validation loss: 2.4890079800562024

Epoch: 5| Step: 1
Training loss: 0.48627657023405757
Validation loss: 2.524134367089454

Epoch: 5| Step: 2
Training loss: 0.45174403056204865
Validation loss: 2.507472733423484

Epoch: 5| Step: 3
Training loss: 0.429419225694501
Validation loss: 2.4889773537817703

Epoch: 5| Step: 4
Training loss: 0.31881206600067685
Validation loss: 2.534282156003822

Epoch: 5| Step: 5
Training loss: 0.3357363253753519
Validation loss: 2.5500627814391503

Epoch: 5| Step: 6
Training loss: 0.2809014810082412
Validation loss: 2.5992240640857966

Epoch: 5| Step: 7
Training loss: 0.578982336112527
Validation loss: 2.6129244421570155

Epoch: 5| Step: 8
Training loss: 0.3757883170369436
Validation loss: 2.6360318660205158

Epoch: 5| Step: 9
Training loss: 0.38998635537169585
Validation loss: 2.6579260318861184

Epoch: 5| Step: 10
Training loss: 0.5429558237856169
Validation loss: 2.646441564072528

Epoch: 339| Step: 0
Training loss: 0.4453102747543686
Validation loss: 2.6229233953712887

Epoch: 5| Step: 1
Training loss: 0.43099692838773584
Validation loss: 2.5927289358236822

Epoch: 5| Step: 2
Training loss: 0.3689489321028793
Validation loss: 2.54135631910446

Epoch: 5| Step: 3
Training loss: 0.6289271475595631
Validation loss: 2.5160518786717745

Epoch: 5| Step: 4
Training loss: 0.23780138913389326
Validation loss: 2.468030977248429

Epoch: 5| Step: 5
Training loss: 0.32640645163654475
Validation loss: 2.478684536083393

Epoch: 5| Step: 6
Training loss: 0.5041269513978465
Validation loss: 2.472925093231522

Epoch: 5| Step: 7
Training loss: 0.5020829563482407
Validation loss: 2.5256808487665423

Epoch: 5| Step: 8
Training loss: 0.30609955400978406
Validation loss: 2.5477886412051474

Epoch: 5| Step: 9
Training loss: 0.4880341476800923
Validation loss: 2.5710519449563725

Epoch: 5| Step: 10
Training loss: 0.319590440877902
Validation loss: 2.591541912551708

Epoch: 340| Step: 0
Training loss: 0.4520033568588866
Validation loss: 2.620857558841203

Epoch: 5| Step: 1
Training loss: 0.4850312678591042
Validation loss: 2.57526059742072

Epoch: 5| Step: 2
Training loss: 0.3381825106958974
Validation loss: 2.6147986686450873

Epoch: 5| Step: 3
Training loss: 0.48373182725902364
Validation loss: 2.5893971557656212

Epoch: 5| Step: 4
Training loss: 0.29343745567800816
Validation loss: 2.53746523612805

Epoch: 5| Step: 5
Training loss: 0.4500887531600925
Validation loss: 2.492792238798882

Epoch: 5| Step: 6
Training loss: 0.47684867271253817
Validation loss: 2.5049707474323917

Epoch: 5| Step: 7
Training loss: 0.23305152905043794
Validation loss: 2.457661039535842

Epoch: 5| Step: 8
Training loss: 0.42482913593664556
Validation loss: 2.545738926609925

Epoch: 5| Step: 9
Training loss: 0.5658444742792333
Validation loss: 2.546173106690095

Epoch: 5| Step: 10
Training loss: 0.22740475534144736
Validation loss: 2.545398528033427

Epoch: 341| Step: 0
Training loss: 0.24466296965799014
Validation loss: 2.5334103104932497

Epoch: 5| Step: 1
Training loss: 0.3306422407201738
Validation loss: 2.580156073029681

Epoch: 5| Step: 2
Training loss: 0.48332400278698795
Validation loss: 2.561281112922096

Epoch: 5| Step: 3
Training loss: 0.4087004119354815
Validation loss: 2.604156197475596

Epoch: 5| Step: 4
Training loss: 0.30497288176877196
Validation loss: 2.5659674163478363

Epoch: 5| Step: 5
Training loss: 0.45867281139644006
Validation loss: 2.590759793902882

Epoch: 5| Step: 6
Training loss: 0.25877429272231905
Validation loss: 2.5848297947830945

Epoch: 5| Step: 7
Training loss: 0.49172717472371097
Validation loss: 2.5371980713895512

Epoch: 5| Step: 8
Training loss: 0.4993006762886777
Validation loss: 2.5439956346087294

Epoch: 5| Step: 9
Training loss: 0.4063427709145072
Validation loss: 2.518020644833926

Epoch: 5| Step: 10
Training loss: 0.5063135766504224
Validation loss: 2.532246215243415

Epoch: 342| Step: 0
Training loss: 0.44204075538444715
Validation loss: 2.5438588810280405

Epoch: 5| Step: 1
Training loss: 0.47929731087637606
Validation loss: 2.5098977491904577

Epoch: 5| Step: 2
Training loss: 0.2637569855266626
Validation loss: 2.5472549818357084

Epoch: 5| Step: 3
Training loss: 0.4272496860898083
Validation loss: 2.575835125934015

Epoch: 5| Step: 4
Training loss: 0.579292510331959
Validation loss: 2.552996342077811

Epoch: 5| Step: 5
Training loss: 0.5486120429882821
Validation loss: 2.573010857458747

Epoch: 5| Step: 6
Training loss: 0.43896134728385366
Validation loss: 2.5770421781773707

Epoch: 5| Step: 7
Training loss: 0.277461497067136
Validation loss: 2.5424941733303172

Epoch: 5| Step: 8
Training loss: 0.21098166462591697
Validation loss: 2.5372996844595317

Epoch: 5| Step: 9
Training loss: 0.3233417691813165
Validation loss: 2.548935477023731

Epoch: 5| Step: 10
Training loss: 0.3159663592249905
Validation loss: 2.579869459424839

Epoch: 343| Step: 0
Training loss: 0.5690748293199314
Validation loss: 2.5816955819836265

Epoch: 5| Step: 1
Training loss: 0.5475982515585122
Validation loss: 2.580645661264289

Epoch: 5| Step: 2
Training loss: 0.24205333315913008
Validation loss: 2.5917383481274188

Epoch: 5| Step: 3
Training loss: 0.49430545877208776
Validation loss: 2.5421430358884747

Epoch: 5| Step: 4
Training loss: 0.3861846510841793
Validation loss: 2.523736160206973

Epoch: 5| Step: 5
Training loss: 0.29912108976468127
Validation loss: 2.571411288933038

Epoch: 5| Step: 6
Training loss: 0.4278123340369516
Validation loss: 2.56921239298567

Epoch: 5| Step: 7
Training loss: 0.382933266722309
Validation loss: 2.5091682985729276

Epoch: 5| Step: 8
Training loss: 0.3962751503613265
Validation loss: 2.5295386738504058

Epoch: 5| Step: 9
Training loss: 0.27626901237517276
Validation loss: 2.514054815416657

Epoch: 5| Step: 10
Training loss: 0.16431810132168836
Validation loss: 2.5358262821081263

Epoch: 344| Step: 0
Training loss: 0.42101072154584757
Validation loss: 2.558519210174266

Epoch: 5| Step: 1
Training loss: 0.44643918774107005
Validation loss: 2.5211054347364734

Epoch: 5| Step: 2
Training loss: 0.461444349773129
Validation loss: 2.5269999097357596

Epoch: 5| Step: 3
Training loss: 0.30543296048198404
Validation loss: 2.536345414904857

Epoch: 5| Step: 4
Training loss: 0.2595670701305911
Validation loss: 2.502517202026295

Epoch: 5| Step: 5
Training loss: 0.4087047870956723
Validation loss: 2.531901887091792

Epoch: 5| Step: 6
Training loss: 0.44771716384143434
Validation loss: 2.5192340003612683

Epoch: 5| Step: 7
Training loss: 0.4170302433989387
Validation loss: 2.536977675653256

Epoch: 5| Step: 8
Training loss: 0.5269732834089877
Validation loss: 2.536602458778618

Epoch: 5| Step: 9
Training loss: 0.22035177503013267
Validation loss: 2.5120235010658716

Epoch: 5| Step: 10
Training loss: 0.3722143820431964
Validation loss: 2.47438869357846

Epoch: 345| Step: 0
Training loss: 0.449598831596672
Validation loss: 2.5100267655794175

Epoch: 5| Step: 1
Training loss: 0.46850926257354053
Validation loss: 2.5161157515456405

Epoch: 5| Step: 2
Training loss: 0.5523799663146931
Validation loss: 2.4796969069996124

Epoch: 5| Step: 3
Training loss: 0.266053023209195
Validation loss: 2.498644571082696

Epoch: 5| Step: 4
Training loss: 0.3558010392680973
Validation loss: 2.545248070003517

Epoch: 5| Step: 5
Training loss: 0.4208478078461702
Validation loss: 2.527406671085717

Epoch: 5| Step: 6
Training loss: 0.2820816459962161
Validation loss: 2.5440946524634733

Epoch: 5| Step: 7
Training loss: 0.29920820611050525
Validation loss: 2.5870208468585814

Epoch: 5| Step: 8
Training loss: 0.5117818196574144
Validation loss: 2.584578735559924

Epoch: 5| Step: 9
Training loss: 0.4721164142665246
Validation loss: 2.563362690683224

Epoch: 5| Step: 10
Training loss: 0.20132104657674502
Validation loss: 2.529234323263799

Epoch: 346| Step: 0
Training loss: 0.4077202710915432
Validation loss: 2.525293666527459

Epoch: 5| Step: 1
Training loss: 0.3102588037206965
Validation loss: 2.4597378131116514

Epoch: 5| Step: 2
Training loss: 0.5631857506671187
Validation loss: 2.455473190397097

Epoch: 5| Step: 3
Training loss: 0.25405505294958863
Validation loss: 2.51673130225265

Epoch: 5| Step: 4
Training loss: 0.3616411863344508
Validation loss: 2.5061003458572957

Epoch: 5| Step: 5
Training loss: 0.46340607863931166
Validation loss: 2.547938768102846

Epoch: 5| Step: 6
Training loss: 0.4949931002386466
Validation loss: 2.579708939054634

Epoch: 5| Step: 7
Training loss: 0.2866338047932764
Validation loss: 2.5976534491613417

Epoch: 5| Step: 8
Training loss: 0.22288557423278524
Validation loss: 2.5975975141624343

Epoch: 5| Step: 9
Training loss: 0.6042669119924396
Validation loss: 2.6161368291039264

Epoch: 5| Step: 10
Training loss: 0.3877578992315708
Validation loss: 2.6181125162654557

Epoch: 347| Step: 0
Training loss: 0.4950442740118564
Validation loss: 2.5635699047746074

Epoch: 5| Step: 1
Training loss: 0.4545927611031019
Validation loss: 2.552723336014091

Epoch: 5| Step: 2
Training loss: 0.5433465206070994
Validation loss: 2.5214878491258377

Epoch: 5| Step: 3
Training loss: 0.30987687680690545
Validation loss: 2.5492571831595265

Epoch: 5| Step: 4
Training loss: 0.5278824209603526
Validation loss: 2.486243699565694

Epoch: 5| Step: 5
Training loss: 0.486488989763256
Validation loss: 2.5245110831893416

Epoch: 5| Step: 6
Training loss: 0.30057431818841857
Validation loss: 2.538188780590259

Epoch: 5| Step: 7
Training loss: 0.2473934457897959
Validation loss: 2.5805187350435204

Epoch: 5| Step: 8
Training loss: 0.3239138214875193
Validation loss: 2.5268438068897754

Epoch: 5| Step: 9
Training loss: 0.33943490395407505
Validation loss: 2.5510889469622318

Epoch: 5| Step: 10
Training loss: 0.23247674086064868
Validation loss: 2.593995186615262

Epoch: 348| Step: 0
Training loss: 0.2613844658256353
Validation loss: 2.5988261887356465

Epoch: 5| Step: 1
Training loss: 0.4044876569920619
Validation loss: 2.560684391264172

Epoch: 5| Step: 2
Training loss: 0.31244424084074296
Validation loss: 2.5449182988860377

Epoch: 5| Step: 3
Training loss: 0.3848028407034636
Validation loss: 2.524167895043386

Epoch: 5| Step: 4
Training loss: 0.32185161468589146
Validation loss: 2.47601618793128

Epoch: 5| Step: 5
Training loss: 0.4172794326471826
Validation loss: 2.4347964644849904

Epoch: 5| Step: 6
Training loss: 0.5100993675311022
Validation loss: 2.4238387652627806

Epoch: 5| Step: 7
Training loss: 0.39214483234182035
Validation loss: 2.4260653755643697

Epoch: 5| Step: 8
Training loss: 0.3705942908650691
Validation loss: 2.4564763816689155

Epoch: 5| Step: 9
Training loss: 0.429424517523428
Validation loss: 2.539419363483564

Epoch: 5| Step: 10
Training loss: 0.5399363249306621
Validation loss: 2.5025771357926048

Epoch: 349| Step: 0
Training loss: 0.5498541747023956
Validation loss: 2.587320294430487

Epoch: 5| Step: 1
Training loss: 0.3439326234693966
Validation loss: 2.59581679682907

Epoch: 5| Step: 2
Training loss: 0.3519340247455339
Validation loss: 2.548862845376442

Epoch: 5| Step: 3
Training loss: 0.35360729230367105
Validation loss: 2.53202323289754

Epoch: 5| Step: 4
Training loss: 0.35796764791544616
Validation loss: 2.521870147582082

Epoch: 5| Step: 5
Training loss: 0.39385554549083407
Validation loss: 2.51433420921411

Epoch: 5| Step: 6
Training loss: 0.29043251862265185
Validation loss: 2.4376513168868406

Epoch: 5| Step: 7
Training loss: 0.46758970662164684
Validation loss: 2.487677282969561

Epoch: 5| Step: 8
Training loss: 0.4578202764482094
Validation loss: 2.491412403537686

Epoch: 5| Step: 9
Training loss: 0.4590170016765613
Validation loss: 2.4647076493785605

Epoch: 5| Step: 10
Training loss: 0.29835620092325277
Validation loss: 2.461590430176122

Epoch: 350| Step: 0
Training loss: 0.25312352945348
Validation loss: 2.4880146410450323

Epoch: 5| Step: 1
Training loss: 0.37340089466935844
Validation loss: 2.538181684126662

Epoch: 5| Step: 2
Training loss: 0.42564813475395624
Validation loss: 2.5178709832369712

Epoch: 5| Step: 3
Training loss: 0.33813552580930456
Validation loss: 2.556533143268453

Epoch: 5| Step: 4
Training loss: 0.3395167564391846
Validation loss: 2.5577333648341236

Epoch: 5| Step: 5
Training loss: 0.38149578036028275
Validation loss: 2.521835955243743

Epoch: 5| Step: 6
Training loss: 0.44416886426919977
Validation loss: 2.5580608254718102

Epoch: 5| Step: 7
Training loss: 0.5897546915689996
Validation loss: 2.5571220969451045

Epoch: 5| Step: 8
Training loss: 0.36284110364769434
Validation loss: 2.5612100385214327

Epoch: 5| Step: 9
Training loss: 0.2845612157285361
Validation loss: 2.5480207308003497

Epoch: 5| Step: 10
Training loss: 0.4641756176756086
Validation loss: 2.5166265895884727

Epoch: 351| Step: 0
Training loss: 0.29808857977226816
Validation loss: 2.554783712201475

Epoch: 5| Step: 1
Training loss: 0.4535491043862916
Validation loss: 2.547626963389718

Epoch: 5| Step: 2
Training loss: 0.4430089397464851
Validation loss: 2.5288265085954063

Epoch: 5| Step: 3
Training loss: 0.4800209812208063
Validation loss: 2.5164162006792634

Epoch: 5| Step: 4
Training loss: 0.20653460871233373
Validation loss: 2.499527117397597

Epoch: 5| Step: 5
Training loss: 0.33832048624684113
Validation loss: 2.5247163012756513

Epoch: 5| Step: 6
Training loss: 0.22425154502627723
Validation loss: 2.5615587704364327

Epoch: 5| Step: 7
Training loss: 0.603190609224413
Validation loss: 2.568306213300349

Epoch: 5| Step: 8
Training loss: 0.3056207083769368
Validation loss: 2.5933157839936416

Epoch: 5| Step: 9
Training loss: 0.5158088240812002
Validation loss: 2.5771492039614063

Epoch: 5| Step: 10
Training loss: 0.24954424980091167
Validation loss: 2.5564034073029642

Epoch: 352| Step: 0
Training loss: 0.3691959440571131
Validation loss: 2.530873420399987

Epoch: 5| Step: 1
Training loss: 0.366032060805792
Validation loss: 2.5013905201066544

Epoch: 5| Step: 2
Training loss: 0.25583730121936027
Validation loss: 2.487719338782308

Epoch: 5| Step: 3
Training loss: 0.45658073065129023
Validation loss: 2.4459213384252525

Epoch: 5| Step: 4
Training loss: 0.42085110072911663
Validation loss: 2.45457035935923

Epoch: 5| Step: 5
Training loss: 0.5162603047984244
Validation loss: 2.5214168476981835

Epoch: 5| Step: 6
Training loss: 0.45156288542945544
Validation loss: 2.544238777263925

Epoch: 5| Step: 7
Training loss: 0.37051442753221026
Validation loss: 2.5732630971024126

Epoch: 5| Step: 8
Training loss: 0.43878721859107367
Validation loss: 2.585711701899927

Epoch: 5| Step: 9
Training loss: 0.31131847658606565
Validation loss: 2.602776639211735

Epoch: 5| Step: 10
Training loss: 0.31515515784479575
Validation loss: 2.601301028404006

Epoch: 353| Step: 0
Training loss: 0.424965821322354
Validation loss: 2.5536327414321676

Epoch: 5| Step: 1
Training loss: 0.4024232952409083
Validation loss: 2.53572134847766

Epoch: 5| Step: 2
Training loss: 0.4479202410828851
Validation loss: 2.531501088107796

Epoch: 5| Step: 3
Training loss: 0.3255867306448481
Validation loss: 2.534186039235257

Epoch: 5| Step: 4
Training loss: 0.3474427864432859
Validation loss: 2.5020583385379522

Epoch: 5| Step: 5
Training loss: 0.478425340504178
Validation loss: 2.5068618188436136

Epoch: 5| Step: 6
Training loss: 0.3772146276533642
Validation loss: 2.523632074949787

Epoch: 5| Step: 7
Training loss: 0.09252264859514571
Validation loss: 2.4871038071389955

Epoch: 5| Step: 8
Training loss: 0.49959623902614064
Validation loss: 2.5217137642928695

Epoch: 5| Step: 9
Training loss: 0.33005233528465094
Validation loss: 2.4946628852190944

Epoch: 5| Step: 10
Training loss: 0.3446127511851249
Validation loss: 2.495756774204185

Epoch: 354| Step: 0
Training loss: 0.4423613048318824
Validation loss: 2.500335086392732

Epoch: 5| Step: 1
Training loss: 0.46458042925053866
Validation loss: 2.530569426878171

Epoch: 5| Step: 2
Training loss: 0.3036207206160659
Validation loss: 2.495704717234358

Epoch: 5| Step: 3
Training loss: 0.3251866634467379
Validation loss: 2.5627209647907465

Epoch: 5| Step: 4
Training loss: 0.22356182121001042
Validation loss: 2.5337672810193075

Epoch: 5| Step: 5
Training loss: 0.457397363203052
Validation loss: 2.516438898695491

Epoch: 5| Step: 6
Training loss: 0.14940018682937353
Validation loss: 2.5019571354993593

Epoch: 5| Step: 7
Training loss: 0.45574169323371994
Validation loss: 2.5301778475620713

Epoch: 5| Step: 8
Training loss: 0.4971690651277027
Validation loss: 2.519218970982703

Epoch: 5| Step: 9
Training loss: 0.39360642388909944
Validation loss: 2.5228221156537485

Epoch: 5| Step: 10
Training loss: 0.2682068253752748
Validation loss: 2.526881022792485

Epoch: 355| Step: 0
Training loss: 0.36920054519593437
Validation loss: 2.5769036481064904

Epoch: 5| Step: 1
Training loss: 0.1980271041752786
Validation loss: 2.573894085574882

Epoch: 5| Step: 2
Training loss: 0.30473300398419556
Validation loss: 2.536885797434042

Epoch: 5| Step: 3
Training loss: 0.33637779790578687
Validation loss: 2.612371545502841

Epoch: 5| Step: 4
Training loss: 0.5537803377663085
Validation loss: 2.5592591055038048

Epoch: 5| Step: 5
Training loss: 0.20987385562973251
Validation loss: 2.537930348851055

Epoch: 5| Step: 6
Training loss: 0.4321517679664915
Validation loss: 2.5455768597868165

Epoch: 5| Step: 7
Training loss: 0.5284057942900084
Validation loss: 2.5535257881789803

Epoch: 5| Step: 8
Training loss: 0.29274218381632444
Validation loss: 2.509689245749195

Epoch: 5| Step: 9
Training loss: 0.23371637309029056
Validation loss: 2.5249164706782294

Epoch: 5| Step: 10
Training loss: 0.47641401635505354
Validation loss: 2.478290449208191

Epoch: 356| Step: 0
Training loss: 0.22117700593063958
Validation loss: 2.4595367596512876

Epoch: 5| Step: 1
Training loss: 0.3787859302889675
Validation loss: 2.4697747170994178

Epoch: 5| Step: 2
Training loss: 0.4921218131904233
Validation loss: 2.487291444126004

Epoch: 5| Step: 3
Training loss: 0.3649099612552434
Validation loss: 2.522101279595169

Epoch: 5| Step: 4
Training loss: 0.39976843896486397
Validation loss: 2.49019690070205

Epoch: 5| Step: 5
Training loss: 0.24110947919206394
Validation loss: 2.5413776847350906

Epoch: 5| Step: 6
Training loss: 0.30075318341778173
Validation loss: 2.5766495326800856

Epoch: 5| Step: 7
Training loss: 0.6249283987993103
Validation loss: 2.546937371134531

Epoch: 5| Step: 8
Training loss: 0.23909187790867306
Validation loss: 2.559866177175318

Epoch: 5| Step: 9
Training loss: 0.2425937705899296
Validation loss: 2.4928978389749497

Epoch: 5| Step: 10
Training loss: 0.3851321648114186
Validation loss: 2.491348569270824

Epoch: 357| Step: 0
Training loss: 0.2829442123230333
Validation loss: 2.520632866461843

Epoch: 5| Step: 1
Training loss: 0.4098602316622274
Validation loss: 2.4947444289517495

Epoch: 5| Step: 2
Training loss: 0.3209813508308776
Validation loss: 2.5403333852199284

Epoch: 5| Step: 3
Training loss: 0.40162681851181614
Validation loss: 2.5557611296795235

Epoch: 5| Step: 4
Training loss: 0.44431437345725
Validation loss: 2.547748655646947

Epoch: 5| Step: 5
Training loss: 0.25948428930838324
Validation loss: 2.555890669555429

Epoch: 5| Step: 6
Training loss: 0.15154181221236604
Validation loss: 2.5447898828439612

Epoch: 5| Step: 7
Training loss: 0.4481563278111991
Validation loss: 2.503872696974535

Epoch: 5| Step: 8
Training loss: 0.4605135827168559
Validation loss: 2.520479616959721

Epoch: 5| Step: 9
Training loss: 0.37095201696898256
Validation loss: 2.552373297473004

Epoch: 5| Step: 10
Training loss: 0.3110254546708009
Validation loss: 2.515477962345697

Epoch: 358| Step: 0
Training loss: 0.3130598060901728
Validation loss: 2.5232543807754864

Epoch: 5| Step: 1
Training loss: 0.2571703832824004
Validation loss: 2.48811551426521

Epoch: 5| Step: 2
Training loss: 0.46113871369065795
Validation loss: 2.4653541966360906

Epoch: 5| Step: 3
Training loss: 0.23053755783701255
Validation loss: 2.524103107684542

Epoch: 5| Step: 4
Training loss: 0.409281151329903
Validation loss: 2.5272243202921936

Epoch: 5| Step: 5
Training loss: 0.4137348822283685
Validation loss: 2.580279082628408

Epoch: 5| Step: 6
Training loss: 0.29203852155111865
Validation loss: 2.5577514664809486

Epoch: 5| Step: 7
Training loss: 0.2875146924286661
Validation loss: 2.5143978667472693

Epoch: 5| Step: 8
Training loss: 0.4636289446527434
Validation loss: 2.542866862405932

Epoch: 5| Step: 9
Training loss: 0.2937855460594677
Validation loss: 2.5305710315784555

Epoch: 5| Step: 10
Training loss: 0.4831718761605818
Validation loss: 2.5026700989005524

Epoch: 359| Step: 0
Training loss: 0.30573548527588756
Validation loss: 2.5149170823345512

Epoch: 5| Step: 1
Training loss: 0.14452773167219854
Validation loss: 2.51537564712565

Epoch: 5| Step: 2
Training loss: 0.3362734356941716
Validation loss: 2.5472402747926277

Epoch: 5| Step: 3
Training loss: 0.445510519070496
Validation loss: 2.5513754215473377

Epoch: 5| Step: 4
Training loss: 0.4584193871371212
Validation loss: 2.5446446669414287

Epoch: 5| Step: 5
Training loss: 0.4473944399378627
Validation loss: 2.5449737482344617

Epoch: 5| Step: 6
Training loss: 0.4199684294687974
Validation loss: 2.568181061010548

Epoch: 5| Step: 7
Training loss: 0.3085441790977939
Validation loss: 2.539160260384388

Epoch: 5| Step: 8
Training loss: 0.41588730243342115
Validation loss: 2.544999742376365

Epoch: 5| Step: 9
Training loss: 0.22001627154756806
Validation loss: 2.543669561193811

Epoch: 5| Step: 10
Training loss: 0.2916657271824193
Validation loss: 2.5179089571687885

Epoch: 360| Step: 0
Training loss: 0.2874616939484443
Validation loss: 2.559682097545319

Epoch: 5| Step: 1
Training loss: 0.4183290301376443
Validation loss: 2.568900955938722

Epoch: 5| Step: 2
Training loss: 0.24336947149209315
Validation loss: 2.557724972482305

Epoch: 5| Step: 3
Training loss: 0.4470622504004431
Validation loss: 2.5586694148402223

Epoch: 5| Step: 4
Training loss: 0.4513974967364028
Validation loss: 2.534437742033604

Epoch: 5| Step: 5
Training loss: 0.30584764908764356
Validation loss: 2.5194469242240745

Epoch: 5| Step: 6
Training loss: 0.3315235857009781
Validation loss: 2.4959829779821625

Epoch: 5| Step: 7
Training loss: 0.23865648335526235
Validation loss: 2.490227215487382

Epoch: 5| Step: 8
Training loss: 0.3504166154354903
Validation loss: 2.438822570209812

Epoch: 5| Step: 9
Training loss: 0.5230817012574022
Validation loss: 2.504707885255548

Epoch: 5| Step: 10
Training loss: 0.41958029405287994
Validation loss: 2.4923674594679275

Epoch: 361| Step: 0
Training loss: 0.30750715921953375
Validation loss: 2.60822904920143

Epoch: 5| Step: 1
Training loss: 0.26545989290654587
Validation loss: 2.6063870604626684

Epoch: 5| Step: 2
Training loss: 0.4254376836411792
Validation loss: 2.5899088181094583

Epoch: 5| Step: 3
Training loss: 0.41996520062875564
Validation loss: 2.6092364602525353

Epoch: 5| Step: 4
Training loss: 0.3743106346969256
Validation loss: 2.5761379645322617

Epoch: 5| Step: 5
Training loss: 0.4538085320187209
Validation loss: 2.5819868868609874

Epoch: 5| Step: 6
Training loss: 0.2483456381820454
Validation loss: 2.537365230091311

Epoch: 5| Step: 7
Training loss: 0.36547837292420604
Validation loss: 2.5363381798627627

Epoch: 5| Step: 8
Training loss: 0.2928363882516828
Validation loss: 2.4685278964339714

Epoch: 5| Step: 9
Training loss: 0.5414719292681702
Validation loss: 2.45935579466951

Epoch: 5| Step: 10
Training loss: 0.35428947769063657
Validation loss: 2.4181620462446043

Epoch: 362| Step: 0
Training loss: 0.24068782624059382
Validation loss: 2.5182977257661183

Epoch: 5| Step: 1
Training loss: 0.46698642218208675
Validation loss: 2.516085430269159

Epoch: 5| Step: 2
Training loss: 0.5323791005338743
Validation loss: 2.5851505733951976

Epoch: 5| Step: 3
Training loss: 0.4484571220012749
Validation loss: 2.631715769273793

Epoch: 5| Step: 4
Training loss: 0.28240901500922394
Validation loss: 2.6526876788379954

Epoch: 5| Step: 5
Training loss: 0.27721535034210804
Validation loss: 2.6291401165178643

Epoch: 5| Step: 6
Training loss: 0.42496675052729266
Validation loss: 2.6374870665446526

Epoch: 5| Step: 7
Training loss: 0.38597285460108055
Validation loss: 2.5243319000051883

Epoch: 5| Step: 8
Training loss: 0.37590648443906227
Validation loss: 2.571661869152765

Epoch: 5| Step: 9
Training loss: 0.19408629787500517
Validation loss: 2.4740508763740103

Epoch: 5| Step: 10
Training loss: 0.2970127865121231
Validation loss: 2.4737565073654197

Epoch: 363| Step: 0
Training loss: 0.39669933035678373
Validation loss: 2.4449356303970933

Epoch: 5| Step: 1
Training loss: 0.3997968597465778
Validation loss: 2.486717825190994

Epoch: 5| Step: 2
Training loss: 0.2776300000784319
Validation loss: 2.5090651017660797

Epoch: 5| Step: 3
Training loss: 0.43514791100557365
Validation loss: 2.5184280309011804

Epoch: 5| Step: 4
Training loss: 0.397417708161911
Validation loss: 2.553488952579441

Epoch: 5| Step: 5
Training loss: 0.3579944547751187
Validation loss: 2.5690653683097837

Epoch: 5| Step: 6
Training loss: 0.4684119276990034
Validation loss: 2.6010564703459313

Epoch: 5| Step: 7
Training loss: 0.26325809365606834
Validation loss: 2.6141101242407276

Epoch: 5| Step: 8
Training loss: 0.2371166881709233
Validation loss: 2.5844938454797686

Epoch: 5| Step: 9
Training loss: 0.35950413747165366
Validation loss: 2.5850618959000315

Epoch: 5| Step: 10
Training loss: 0.3679615951458019
Validation loss: 2.518681549442516

Epoch: 364| Step: 0
Training loss: 0.40052780034521057
Validation loss: 2.473572276918801

Epoch: 5| Step: 1
Training loss: 0.24421259010146532
Validation loss: 2.485840711586769

Epoch: 5| Step: 2
Training loss: 0.40283578581938734
Validation loss: 2.5029161621635803

Epoch: 5| Step: 3
Training loss: 0.1543885272678553
Validation loss: 2.5195045189323024

Epoch: 5| Step: 4
Training loss: 0.3528477065307377
Validation loss: 2.503108480354761

Epoch: 5| Step: 5
Training loss: 0.25705534117710366
Validation loss: 2.5156003767003474

Epoch: 5| Step: 6
Training loss: 0.29509495083985604
Validation loss: 2.5701836431111555

Epoch: 5| Step: 7
Training loss: 0.4301966338456465
Validation loss: 2.6068881699330224

Epoch: 5| Step: 8
Training loss: 0.3940082898768552
Validation loss: 2.5913815765480943

Epoch: 5| Step: 9
Training loss: 0.3022655918321471
Validation loss: 2.6089802724004008

Epoch: 5| Step: 10
Training loss: 0.6683656728995129
Validation loss: 2.626850464286318

Epoch: 365| Step: 0
Training loss: 0.31314335401883947
Validation loss: 2.599476444611647

Epoch: 5| Step: 1
Training loss: 0.23686593707720988
Validation loss: 2.5622711599691095

Epoch: 5| Step: 2
Training loss: 0.221380965162712
Validation loss: 2.56877475378592

Epoch: 5| Step: 3
Training loss: 0.41376738557851184
Validation loss: 2.5165170280216684

Epoch: 5| Step: 4
Training loss: 0.47006658987835803
Validation loss: 2.516748534000157

Epoch: 5| Step: 5
Training loss: 0.36644659979235994
Validation loss: 2.5097646025121736

Epoch: 5| Step: 6
Training loss: 0.4055125990073329
Validation loss: 2.455139441851935

Epoch: 5| Step: 7
Training loss: 0.28586135851059036
Validation loss: 2.535023669481275

Epoch: 5| Step: 8
Training loss: 0.46413810448057674
Validation loss: 2.567510087056465

Epoch: 5| Step: 9
Training loss: 0.24539499384000807
Validation loss: 2.5661714145809587

Epoch: 5| Step: 10
Training loss: 0.4274998723135863
Validation loss: 2.6149698087920763

Epoch: 366| Step: 0
Training loss: 0.3344852751418917
Validation loss: 2.6278109230349727

Epoch: 5| Step: 1
Training loss: 0.20228570157012848
Validation loss: 2.6349651389719044

Epoch: 5| Step: 2
Training loss: 0.2919936291713273
Validation loss: 2.621667750947509

Epoch: 5| Step: 3
Training loss: 0.27009378691821656
Validation loss: 2.5260521553074673

Epoch: 5| Step: 4
Training loss: 0.4221681177022981
Validation loss: 2.5307418169301594

Epoch: 5| Step: 5
Training loss: 0.3640006540837542
Validation loss: 2.5038622186649975

Epoch: 5| Step: 6
Training loss: 0.36055648476801416
Validation loss: 2.5039210057760886

Epoch: 5| Step: 7
Training loss: 0.4927839268230613
Validation loss: 2.4676288022945863

Epoch: 5| Step: 8
Training loss: 0.4295471308919977
Validation loss: 2.4637022406852496

Epoch: 5| Step: 9
Training loss: 0.3649182711182178
Validation loss: 2.4753950415916464

Epoch: 5| Step: 10
Training loss: 0.30168385509836215
Validation loss: 2.486428403158496

Epoch: 367| Step: 0
Training loss: 0.1750236290919287
Validation loss: 2.4816634635673496

Epoch: 5| Step: 1
Training loss: 0.3740232781392448
Validation loss: 2.518234368131728

Epoch: 5| Step: 2
Training loss: 0.32558859564892345
Validation loss: 2.5287637830174554

Epoch: 5| Step: 3
Training loss: 0.3353075175168466
Validation loss: 2.530654566777215

Epoch: 5| Step: 4
Training loss: 0.2539501739069491
Validation loss: 2.549133397665442

Epoch: 5| Step: 5
Training loss: 0.29490093131573175
Validation loss: 2.4967913427859894

Epoch: 5| Step: 6
Training loss: 0.2724211058675522
Validation loss: 2.500055148429081

Epoch: 5| Step: 7
Training loss: 0.3489462568081768
Validation loss: 2.440190939954318

Epoch: 5| Step: 8
Training loss: 0.43317680244517726
Validation loss: 2.4965488983600714

Epoch: 5| Step: 9
Training loss: 0.5123374925552954
Validation loss: 2.54882152183896

Epoch: 5| Step: 10
Training loss: 0.3783101180420863
Validation loss: 2.588561988530106

Epoch: 368| Step: 0
Training loss: 0.33136526522516735
Validation loss: 2.593847073061562

Epoch: 5| Step: 1
Training loss: 0.2335650914451393
Validation loss: 2.5818981424093117

Epoch: 5| Step: 2
Training loss: 0.43763250660389763
Validation loss: 2.565368885210214

Epoch: 5| Step: 3
Training loss: 0.47800447839869586
Validation loss: 2.562677861965856

Epoch: 5| Step: 4
Training loss: 0.4273294422048876
Validation loss: 2.5729120805897185

Epoch: 5| Step: 5
Training loss: 0.26566528968432246
Validation loss: 2.5496428137581835

Epoch: 5| Step: 6
Training loss: 0.2348262733915947
Validation loss: 2.519667914015571

Epoch: 5| Step: 7
Training loss: 0.4092722858543314
Validation loss: 2.5226687471183515

Epoch: 5| Step: 8
Training loss: 0.3532135869202072
Validation loss: 2.517589732533425

Epoch: 5| Step: 9
Training loss: 0.19375941768953578
Validation loss: 2.5469663200864416

Epoch: 5| Step: 10
Training loss: 0.2509896538433465
Validation loss: 2.539239339294519

Epoch: 369| Step: 0
Training loss: 0.3970920434832407
Validation loss: 2.5970977950227065

Epoch: 5| Step: 1
Training loss: 0.3229010588452843
Validation loss: 2.5422992036886103

Epoch: 5| Step: 2
Training loss: 0.26836492596567035
Validation loss: 2.583846027124904

Epoch: 5| Step: 3
Training loss: 0.3563140209294679
Validation loss: 2.566982918041583

Epoch: 5| Step: 4
Training loss: 0.294595019370861
Validation loss: 2.624263267438794

Epoch: 5| Step: 5
Training loss: 0.42211040357612317
Validation loss: 2.564902397246071

Epoch: 5| Step: 6
Training loss: 0.3820198962312852
Validation loss: 2.578137223906762

Epoch: 5| Step: 7
Training loss: 0.30993577822595275
Validation loss: 2.547065483643703

Epoch: 5| Step: 8
Training loss: 0.28303717651092625
Validation loss: 2.5755242986058637

Epoch: 5| Step: 9
Training loss: 0.3615915317798687
Validation loss: 2.56384399993425

Epoch: 5| Step: 10
Training loss: 0.2826558843877061
Validation loss: 2.549570955897552

Epoch: 370| Step: 0
Training loss: 0.187893831380343
Validation loss: 2.6220218564371383

Epoch: 5| Step: 1
Training loss: 0.4351920491530979
Validation loss: 2.5828833755464

Epoch: 5| Step: 2
Training loss: 0.3055654616568361
Validation loss: 2.5764809147668974

Epoch: 5| Step: 3
Training loss: 0.3865994741509261
Validation loss: 2.5846643608003603

Epoch: 5| Step: 4
Training loss: 0.36892221438074935
Validation loss: 2.5679846144075293

Epoch: 5| Step: 5
Training loss: 0.3762207229287491
Validation loss: 2.520076613383908

Epoch: 5| Step: 6
Training loss: 0.4346537306370635
Validation loss: 2.5416392770868614

Epoch: 5| Step: 7
Training loss: 0.19914189894617793
Validation loss: 2.5369005028616343

Epoch: 5| Step: 8
Training loss: 0.331963094560249
Validation loss: 2.5123392673554985

Epoch: 5| Step: 9
Training loss: 0.1864445904154914
Validation loss: 2.5020879045860185

Epoch: 5| Step: 10
Training loss: 0.29450018842914555
Validation loss: 2.5177751576351004

Epoch: 371| Step: 0
Training loss: 0.32163190087195687
Validation loss: 2.560853873098755

Epoch: 5| Step: 1
Training loss: 0.37886267342647645
Validation loss: 2.5306748722145223

Epoch: 5| Step: 2
Training loss: 0.32671835798534665
Validation loss: 2.5846449062679167

Epoch: 5| Step: 3
Training loss: 0.3127448076751766
Validation loss: 2.561823181522179

Epoch: 5| Step: 4
Training loss: 0.3716256996992487
Validation loss: 2.5682964051315045

Epoch: 5| Step: 5
Training loss: 0.36318143888584564
Validation loss: 2.5478498076918026

Epoch: 5| Step: 6
Training loss: 0.26228368338468844
Validation loss: 2.525518286556352

Epoch: 5| Step: 7
Training loss: 0.353717535537696
Validation loss: 2.5578637720081687

Epoch: 5| Step: 8
Training loss: 0.3781339108386582
Validation loss: 2.540237494640691

Epoch: 5| Step: 9
Training loss: 0.15661010968164343
Validation loss: 2.537528085060673

Epoch: 5| Step: 10
Training loss: 0.2944890186783459
Validation loss: 2.5342626960774153

Epoch: 372| Step: 0
Training loss: 0.33604289774581514
Validation loss: 2.5384070846205633

Epoch: 5| Step: 1
Training loss: 0.19444731774553545
Validation loss: 2.5623737527205073

Epoch: 5| Step: 2
Training loss: 0.31836046323999806
Validation loss: 2.570406170511598

Epoch: 5| Step: 3
Training loss: 0.1883241798400997
Validation loss: 2.554517721451707

Epoch: 5| Step: 4
Training loss: 0.33724761153083005
Validation loss: 2.5292725003496086

Epoch: 5| Step: 5
Training loss: 0.409836526415128
Validation loss: 2.5391543913337147

Epoch: 5| Step: 6
Training loss: 0.3089767566035883
Validation loss: 2.5428855527903087

Epoch: 5| Step: 7
Training loss: 0.5069489105091753
Validation loss: 2.530425431277188

Epoch: 5| Step: 8
Training loss: 0.21255305413309009
Validation loss: 2.5320797057557973

Epoch: 5| Step: 9
Training loss: 0.27330368037183145
Validation loss: 2.515651739680648

Epoch: 5| Step: 10
Training loss: 0.3356769349675212
Validation loss: 2.5034432049512083

Epoch: 373| Step: 0
Training loss: 0.28578126683138655
Validation loss: 2.52565709087371

Epoch: 5| Step: 1
Training loss: 0.3548684973340994
Validation loss: 2.4848420729589775

Epoch: 5| Step: 2
Training loss: 0.25289449852023593
Validation loss: 2.504199295386928

Epoch: 5| Step: 3
Training loss: 0.27225892976823174
Validation loss: 2.509604706235318

Epoch: 5| Step: 4
Training loss: 0.22767152327893317
Validation loss: 2.54902476462658

Epoch: 5| Step: 5
Training loss: 0.4082084910938975
Validation loss: 2.5092235325925336

Epoch: 5| Step: 6
Training loss: 0.48092733378630587
Validation loss: 2.501571598133663

Epoch: 5| Step: 7
Training loss: 0.3025174501997556
Validation loss: 2.5048874323820556

Epoch: 5| Step: 8
Training loss: 0.36134429070678786
Validation loss: 2.4715668721937054

Epoch: 5| Step: 9
Training loss: 0.17867233818404488
Validation loss: 2.4894823803957324

Epoch: 5| Step: 10
Training loss: 0.3796529393106312
Validation loss: 2.517592659611109

Epoch: 374| Step: 0
Training loss: 0.4182300820188216
Validation loss: 2.5420170967228266

Epoch: 5| Step: 1
Training loss: 0.3701941176207329
Validation loss: 2.5287448554489287

Epoch: 5| Step: 2
Training loss: 0.21057331471229035
Validation loss: 2.5873828592724344

Epoch: 5| Step: 3
Training loss: 0.2824143705518585
Validation loss: 2.54591266693824

Epoch: 5| Step: 4
Training loss: 0.3163000211057496
Validation loss: 2.567525330503327

Epoch: 5| Step: 5
Training loss: 0.24208542764751395
Validation loss: 2.5683068810849585

Epoch: 5| Step: 6
Training loss: 0.39838921497456165
Validation loss: 2.4894794382878946

Epoch: 5| Step: 7
Training loss: 0.49953443488620214
Validation loss: 2.5025885071217093

Epoch: 5| Step: 8
Training loss: 0.19997615448539424
Validation loss: 2.4976894591809775

Epoch: 5| Step: 9
Training loss: 0.19966543832433203
Validation loss: 2.4791205014026936

Epoch: 5| Step: 10
Training loss: 0.3922262560172014
Validation loss: 2.4902310580207985

Epoch: 375| Step: 0
Training loss: 0.19454932837378916
Validation loss: 2.4857430834645036

Epoch: 5| Step: 1
Training loss: 0.252109094884981
Validation loss: 2.479788823046569

Epoch: 5| Step: 2
Training loss: 0.5229679392821744
Validation loss: 2.5095636035512703

Epoch: 5| Step: 3
Training loss: 0.32699347854302885
Validation loss: 2.504573959073818

Epoch: 5| Step: 4
Training loss: 0.30558602796434003
Validation loss: 2.4950396056437625

Epoch: 5| Step: 5
Training loss: 0.20673014679313473
Validation loss: 2.50805903797747

Epoch: 5| Step: 6
Training loss: 0.2991889072207413
Validation loss: 2.513100574946981

Epoch: 5| Step: 7
Training loss: 0.4532924704361211
Validation loss: 2.5183475014107986

Epoch: 5| Step: 8
Training loss: 0.3738915033935523
Validation loss: 2.554225422620113

Epoch: 5| Step: 9
Training loss: 0.15474051665165112
Validation loss: 2.527604286524814

Epoch: 5| Step: 10
Training loss: 0.2215066562189584
Validation loss: 2.548315898222063

Epoch: 376| Step: 0
Training loss: 0.2801047159551075
Validation loss: 2.5251545904533885

Epoch: 5| Step: 1
Training loss: 0.21069510979660158
Validation loss: 2.5387155462068627

Epoch: 5| Step: 2
Training loss: 0.3161267352842804
Validation loss: 2.532455988551155

Epoch: 5| Step: 3
Training loss: 0.3498103027915413
Validation loss: 2.564628381465848

Epoch: 5| Step: 4
Training loss: 0.26439000986655653
Validation loss: 2.5380160524240813

Epoch: 5| Step: 5
Training loss: 0.2735482808906771
Validation loss: 2.507753993236687

Epoch: 5| Step: 6
Training loss: 0.2629514530316189
Validation loss: 2.5066758963406905

Epoch: 5| Step: 7
Training loss: 0.3417590311080793
Validation loss: 2.517334661989559

Epoch: 5| Step: 8
Training loss: 0.4133829262166484
Validation loss: 2.5192144201233257

Epoch: 5| Step: 9
Training loss: 0.44522013459238335
Validation loss: 2.566370254079115

Epoch: 5| Step: 10
Training loss: 0.35625781000510887
Validation loss: 2.5525286415118393

Epoch: 377| Step: 0
Training loss: 0.1549414077695315
Validation loss: 2.5426815833516665

Epoch: 5| Step: 1
Training loss: 0.41908137461736233
Validation loss: 2.5377244001565877

Epoch: 5| Step: 2
Training loss: 0.2209113750497329
Validation loss: 2.541361455244956

Epoch: 5| Step: 3
Training loss: 0.1522701403485137
Validation loss: 2.5497453958176175

Epoch: 5| Step: 4
Training loss: 0.439620956585609
Validation loss: 2.5414033812578727

Epoch: 5| Step: 5
Training loss: 0.2356673690030272
Validation loss: 2.511559138387964

Epoch: 5| Step: 6
Training loss: 0.3304554965921528
Validation loss: 2.5270448222526025

Epoch: 5| Step: 7
Training loss: 0.40719079242467215
Validation loss: 2.5422869637662218

Epoch: 5| Step: 8
Training loss: 0.2891014949168134
Validation loss: 2.5573336987497353

Epoch: 5| Step: 9
Training loss: 0.37199359012664995
Validation loss: 2.5900176843072793

Epoch: 5| Step: 10
Training loss: 0.25836799482622186
Validation loss: 2.5602046992322145

Epoch: 378| Step: 0
Training loss: 0.4455571422835361
Validation loss: 2.5390444912835815

Epoch: 5| Step: 1
Training loss: 0.2608446498529477
Validation loss: 2.514955934448255

Epoch: 5| Step: 2
Training loss: 0.3225411826460554
Validation loss: 2.520210301667133

Epoch: 5| Step: 3
Training loss: 0.42113787219970394
Validation loss: 2.5135724644285173

Epoch: 5| Step: 4
Training loss: 0.3820169707518016
Validation loss: 2.459331936026686

Epoch: 5| Step: 5
Training loss: 0.1751613441546615
Validation loss: 2.549416177274781

Epoch: 5| Step: 6
Training loss: 0.3145013381295779
Validation loss: 2.5156524239901747

Epoch: 5| Step: 7
Training loss: 0.24849686393207676
Validation loss: 2.542224188112054

Epoch: 5| Step: 8
Training loss: 0.42428848648839956
Validation loss: 2.5476416118488445

Epoch: 5| Step: 9
Training loss: 0.20017701042066638
Validation loss: 2.584043104281788

Epoch: 5| Step: 10
Training loss: 0.22701674995928678
Validation loss: 2.545634268655056

Epoch: 379| Step: 0
Training loss: 0.1859087677402161
Validation loss: 2.519441885864593

Epoch: 5| Step: 1
Training loss: 0.22943302771798127
Validation loss: 2.4979988251374654

Epoch: 5| Step: 2
Training loss: 0.28638605882196205
Validation loss: 2.47521863940972

Epoch: 5| Step: 3
Training loss: 0.40545547257809983
Validation loss: 2.4399570820828282

Epoch: 5| Step: 4
Training loss: 0.39243874044475935
Validation loss: 2.4698476120613853

Epoch: 5| Step: 5
Training loss: 0.2538060210546344
Validation loss: 2.5153586383494684

Epoch: 5| Step: 6
Training loss: 0.4026772866547286
Validation loss: 2.5378968072489934

Epoch: 5| Step: 7
Training loss: 0.2969913003896469
Validation loss: 2.539415512092737

Epoch: 5| Step: 8
Training loss: 0.3180733314254519
Validation loss: 2.525461320820449

Epoch: 5| Step: 9
Training loss: 0.45333459544824234
Validation loss: 2.51197904457975

Epoch: 5| Step: 10
Training loss: 0.20665252882016805
Validation loss: 2.54660254069895

Epoch: 380| Step: 0
Training loss: 0.47443975549432355
Validation loss: 2.545900859259134

Epoch: 5| Step: 1
Training loss: 0.37223263701455217
Validation loss: 2.500518077575229

Epoch: 5| Step: 2
Training loss: 0.3115014454125352
Validation loss: 2.484463942484751

Epoch: 5| Step: 3
Training loss: 0.23220226587447582
Validation loss: 2.513195719885396

Epoch: 5| Step: 4
Training loss: 0.25078440334440977
Validation loss: 2.5635784059950604

Epoch: 5| Step: 5
Training loss: 0.4150474996270186
Validation loss: 2.5386597693071606

Epoch: 5| Step: 6
Training loss: 0.250418402310882
Validation loss: 2.535223969531335

Epoch: 5| Step: 7
Training loss: 0.2612042565430502
Validation loss: 2.543089923719115

Epoch: 5| Step: 8
Training loss: 0.3524860331629376
Validation loss: 2.576115966673847

Epoch: 5| Step: 9
Training loss: 0.3581240900637266
Validation loss: 2.598662741807959

Epoch: 5| Step: 10
Training loss: 0.2235409827116724
Validation loss: 2.6105347187507837

Epoch: 381| Step: 0
Training loss: 0.5107686198234661
Validation loss: 2.6337023779673814

Epoch: 5| Step: 1
Training loss: 0.18639664060024802
Validation loss: 2.604270438475001

Epoch: 5| Step: 2
Training loss: 0.34443619902587796
Validation loss: 2.577953948719607

Epoch: 5| Step: 3
Training loss: 0.25278557165995164
Validation loss: 2.5894313183119233

Epoch: 5| Step: 4
Training loss: 0.2149655257076257
Validation loss: 2.532294939458595

Epoch: 5| Step: 5
Training loss: 0.26613202510231815
Validation loss: 2.56344597135965

Epoch: 5| Step: 6
Training loss: 0.4054189765383452
Validation loss: 2.5291642873637663

Epoch: 5| Step: 7
Training loss: 0.3341101359455174
Validation loss: 2.574618819015636

Epoch: 5| Step: 8
Training loss: 0.24967943441089963
Validation loss: 2.5487274231750883

Epoch: 5| Step: 9
Training loss: 0.3407368161470057
Validation loss: 2.5413125946590593

Epoch: 5| Step: 10
Training loss: 0.19864009517496098
Validation loss: 2.5796277764780293

Epoch: 382| Step: 0
Training loss: 0.3434482138388328
Validation loss: 2.5856281905115517

Epoch: 5| Step: 1
Training loss: 0.30173583706832474
Validation loss: 2.575830071969269

Epoch: 5| Step: 2
Training loss: 0.24542401779744155
Validation loss: 2.591439651466462

Epoch: 5| Step: 3
Training loss: 0.23326111588459672
Validation loss: 2.573613270832126

Epoch: 5| Step: 4
Training loss: 0.41141730317227587
Validation loss: 2.5568269309379676

Epoch: 5| Step: 5
Training loss: 0.41964503189149516
Validation loss: 2.5366691432180417

Epoch: 5| Step: 6
Training loss: 0.3911921199057094
Validation loss: 2.5249310742253397

Epoch: 5| Step: 7
Training loss: 0.27584511879140217
Validation loss: 2.5013560831807

Epoch: 5| Step: 8
Training loss: 0.23159846940261603
Validation loss: 2.493580501936581

Epoch: 5| Step: 9
Training loss: 0.2712290956423017
Validation loss: 2.510285605681233

Epoch: 5| Step: 10
Training loss: 0.38477681719772394
Validation loss: 2.533756074407443

Epoch: 383| Step: 0
Training loss: 0.15746268909968697
Validation loss: 2.535667647839289

Epoch: 5| Step: 1
Training loss: 0.2066846591493534
Validation loss: 2.5728579652275885

Epoch: 5| Step: 2
Training loss: 0.36819397174960433
Validation loss: 2.5475272656937267

Epoch: 5| Step: 3
Training loss: 0.2992756428427815
Validation loss: 2.5241064258566186

Epoch: 5| Step: 4
Training loss: 0.29303527076829095
Validation loss: 2.5135746725524593

Epoch: 5| Step: 5
Training loss: 0.3250710762688065
Validation loss: 2.47574290617935

Epoch: 5| Step: 6
Training loss: 0.4488802256278666
Validation loss: 2.513392649314272

Epoch: 5| Step: 7
Training loss: 0.38251760373714566
Validation loss: 2.4869204216536662

Epoch: 5| Step: 8
Training loss: 0.2572740654323908
Validation loss: 2.4967956064617187

Epoch: 5| Step: 9
Training loss: 0.29164886704127874
Validation loss: 2.485888817011811

Epoch: 5| Step: 10
Training loss: 0.32330306710125517
Validation loss: 2.4636924271036458

Epoch: 384| Step: 0
Training loss: 0.19290482431327066
Validation loss: 2.529649082141848

Epoch: 5| Step: 1
Training loss: 0.22833070037941045
Validation loss: 2.5129439290158944

Epoch: 5| Step: 2
Training loss: 0.46527268950999756
Validation loss: 2.5582696730253667

Epoch: 5| Step: 3
Training loss: 0.2571424243820235
Validation loss: 2.560717879662357

Epoch: 5| Step: 4
Training loss: 0.25537046647587425
Validation loss: 2.5694597684105247

Epoch: 5| Step: 5
Training loss: 0.25615852281605267
Validation loss: 2.559862110684983

Epoch: 5| Step: 6
Training loss: 0.4766504644289018
Validation loss: 2.5375727799208274

Epoch: 5| Step: 7
Training loss: 0.2777632911533868
Validation loss: 2.5736069872676706

Epoch: 5| Step: 8
Training loss: 0.32695698616181657
Validation loss: 2.5028309636671078

Epoch: 5| Step: 9
Training loss: 0.23941985112264486
Validation loss: 2.5216033313468817

Epoch: 5| Step: 10
Training loss: 0.41890202367543755
Validation loss: 2.484968219209782

Epoch: 385| Step: 0
Training loss: 0.4428923411461403
Validation loss: 2.477853136650109

Epoch: 5| Step: 1
Training loss: 0.3294880462549045
Validation loss: 2.486516861848565

Epoch: 5| Step: 2
Training loss: 0.2368102161345666
Validation loss: 2.475111564059994

Epoch: 5| Step: 3
Training loss: 0.42133655448416135
Validation loss: 2.505876521401143

Epoch: 5| Step: 4
Training loss: 0.3223231639936108
Validation loss: 2.5398057438881567

Epoch: 5| Step: 5
Training loss: 0.2324446739106206
Validation loss: 2.5449706184432968

Epoch: 5| Step: 6
Training loss: 0.24674018848859414
Validation loss: 2.563113893136371

Epoch: 5| Step: 7
Training loss: 0.33575741798247577
Validation loss: 2.576793750307971

Epoch: 5| Step: 8
Training loss: 0.31407021375454214
Validation loss: 2.537406967529182

Epoch: 5| Step: 9
Training loss: 0.20241321049015892
Validation loss: 2.550905365567176

Epoch: 5| Step: 10
Training loss: 0.255232487074003
Validation loss: 2.539097496782277

Epoch: 386| Step: 0
Training loss: 0.2021149870244856
Validation loss: 2.5110635116002555

Epoch: 5| Step: 1
Training loss: 0.1486858498865374
Validation loss: 2.531180752144133

Epoch: 5| Step: 2
Training loss: 0.27704335452517187
Validation loss: 2.5259775244727725

Epoch: 5| Step: 3
Training loss: 0.3640908684544881
Validation loss: 2.5154371171690464

Epoch: 5| Step: 4
Training loss: 0.3460203967063627
Validation loss: 2.512628871302546

Epoch: 5| Step: 5
Training loss: 0.24638884124265004
Validation loss: 2.5128251697680133

Epoch: 5| Step: 6
Training loss: 0.3055099732664366
Validation loss: 2.5330339174539733

Epoch: 5| Step: 7
Training loss: 0.35841787425874516
Validation loss: 2.5228009587035585

Epoch: 5| Step: 8
Training loss: 0.3840419140195814
Validation loss: 2.574138212549221

Epoch: 5| Step: 9
Training loss: 0.29454768360138855
Validation loss: 2.535766845559173

Epoch: 5| Step: 10
Training loss: 0.3028788314227485
Validation loss: 2.54091865033106

Epoch: 387| Step: 0
Training loss: 0.39417887521927913
Validation loss: 2.5369050245209537

Epoch: 5| Step: 1
Training loss: 0.3916553260635877
Validation loss: 2.5197149267175933

Epoch: 5| Step: 2
Training loss: 0.2203762621629763
Validation loss: 2.4941671088370603

Epoch: 5| Step: 3
Training loss: 0.40634900500590077
Validation loss: 2.4812712921620124

Epoch: 5| Step: 4
Training loss: 0.19549946419405867
Validation loss: 2.4731958933079117

Epoch: 5| Step: 5
Training loss: 0.35770048945289207
Validation loss: 2.4283479225734546

Epoch: 5| Step: 6
Training loss: 0.20437387616318084
Validation loss: 2.487689803948687

Epoch: 5| Step: 7
Training loss: 0.15176817786167765
Validation loss: 2.5061792035869974

Epoch: 5| Step: 8
Training loss: 0.38329965384736664
Validation loss: 2.547964932220147

Epoch: 5| Step: 9
Training loss: 0.27288887298571984
Validation loss: 2.577006240789737

Epoch: 5| Step: 10
Training loss: 0.3382504261941755
Validation loss: 2.5601165195322633

Epoch: 388| Step: 0
Training loss: 0.27014031907650693
Validation loss: 2.5084237420869373

Epoch: 5| Step: 1
Training loss: 0.18161158175696115
Validation loss: 2.499592118163236

Epoch: 5| Step: 2
Training loss: 0.3052569960293126
Validation loss: 2.513568915617407

Epoch: 5| Step: 3
Training loss: 0.14846042405848534
Validation loss: 2.451551268178715

Epoch: 5| Step: 4
Training loss: 0.4048758705379482
Validation loss: 2.451913752349652

Epoch: 5| Step: 5
Training loss: 0.3202568564116533
Validation loss: 2.4454289376871894

Epoch: 5| Step: 6
Training loss: 0.3327997290260846
Validation loss: 2.4580036239089336

Epoch: 5| Step: 7
Training loss: 0.23496080146462173
Validation loss: 2.461506847665377

Epoch: 5| Step: 8
Training loss: 0.41543983407625307
Validation loss: 2.4830291372678706

Epoch: 5| Step: 9
Training loss: 0.3283882220655379
Validation loss: 2.5070501571920567

Epoch: 5| Step: 10
Training loss: 0.2812448342166789
Validation loss: 2.5163646780713917

Epoch: 389| Step: 0
Training loss: 0.22039353760556343
Validation loss: 2.491387100523516

Epoch: 5| Step: 1
Training loss: 0.3640395627961752
Validation loss: 2.488371646657219

Epoch: 5| Step: 2
Training loss: 0.13599756629296736
Validation loss: 2.5352660354659218

Epoch: 5| Step: 3
Training loss: 0.28400078611953494
Validation loss: 2.468099233937873

Epoch: 5| Step: 4
Training loss: 0.16812958890119098
Validation loss: 2.4965682338052724

Epoch: 5| Step: 5
Training loss: 0.2782422140202583
Validation loss: 2.479787307991551

Epoch: 5| Step: 6
Training loss: 0.4315437795126853
Validation loss: 2.493261136300098

Epoch: 5| Step: 7
Training loss: 0.27001133607979344
Validation loss: 2.466705941286962

Epoch: 5| Step: 8
Training loss: 0.22716374202217235
Validation loss: 2.4477541120531088

Epoch: 5| Step: 9
Training loss: 0.25046064733772055
Validation loss: 2.495266804233799

Epoch: 5| Step: 10
Training loss: 0.5205449418500501
Validation loss: 2.538939640174314

Epoch: 390| Step: 0
Training loss: 0.34067087258293494
Validation loss: 2.5619293415847

Epoch: 5| Step: 1
Training loss: 0.2941386452009183
Validation loss: 2.5641421237008686

Epoch: 5| Step: 2
Training loss: 0.29170434855958954
Validation loss: 2.5512926240827656

Epoch: 5| Step: 3
Training loss: 0.2527643053353206
Validation loss: 2.52746441964139

Epoch: 5| Step: 4
Training loss: 0.36761587599736334
Validation loss: 2.5574320097243115

Epoch: 5| Step: 5
Training loss: 0.20372256998295063
Validation loss: 2.5360647988120104

Epoch: 5| Step: 6
Training loss: 0.20166586436028003
Validation loss: 2.4715494794709296

Epoch: 5| Step: 7
Training loss: 0.264989218245105
Validation loss: 2.4925628666424924

Epoch: 5| Step: 8
Training loss: 0.1728470904100429
Validation loss: 2.460228883883653

Epoch: 5| Step: 9
Training loss: 0.44496320108891657
Validation loss: 2.4679707047064734

Epoch: 5| Step: 10
Training loss: 0.3480210158720492
Validation loss: 2.4818622556045953

Epoch: 391| Step: 0
Training loss: 0.23531167099845932
Validation loss: 2.472345809578911

Epoch: 5| Step: 1
Training loss: 0.187055836545806
Validation loss: 2.514215446299506

Epoch: 5| Step: 2
Training loss: 0.5187022256108831
Validation loss: 2.5112165884484243

Epoch: 5| Step: 3
Training loss: 0.31780335954258204
Validation loss: 2.546048415063345

Epoch: 5| Step: 4
Training loss: 0.2981706879553225
Validation loss: 2.558515799358156

Epoch: 5| Step: 5
Training loss: 0.21495311727688085
Validation loss: 2.572590714671956

Epoch: 5| Step: 6
Training loss: 0.21650561967377344
Validation loss: 2.571693683413477

Epoch: 5| Step: 7
Training loss: 0.41528752687458326
Validation loss: 2.547236138327108

Epoch: 5| Step: 8
Training loss: 0.2998120807146167
Validation loss: 2.5321080778875578

Epoch: 5| Step: 9
Training loss: 0.2809156708940639
Validation loss: 2.505074280229115

Epoch: 5| Step: 10
Training loss: 0.2939168593110687
Validation loss: 2.4592091366589877

Epoch: 392| Step: 0
Training loss: 0.1564276341178403
Validation loss: 2.4758997623987424

Epoch: 5| Step: 1
Training loss: 0.29216294414943655
Validation loss: 2.4572928399100573

Epoch: 5| Step: 2
Training loss: 0.277170126928551
Validation loss: 2.489488680634563

Epoch: 5| Step: 3
Training loss: 0.3177192665261739
Validation loss: 2.5082506874133825

Epoch: 5| Step: 4
Training loss: 0.32381043518120806
Validation loss: 2.4932519943091744

Epoch: 5| Step: 5
Training loss: 0.22295521858820908
Validation loss: 2.5598187228689517

Epoch: 5| Step: 6
Training loss: 0.2795494378166298
Validation loss: 2.57209796558292

Epoch: 5| Step: 7
Training loss: 0.38371860546584974
Validation loss: 2.542678585843779

Epoch: 5| Step: 8
Training loss: 0.38805772192125876
Validation loss: 2.5504012125391475

Epoch: 5| Step: 9
Training loss: 0.2650217330315998
Validation loss: 2.505867107263918

Epoch: 5| Step: 10
Training loss: 0.38820833331272514
Validation loss: 2.4830494194433896

Epoch: 393| Step: 0
Training loss: 0.41156074199141734
Validation loss: 2.461931680531992

Epoch: 5| Step: 1
Training loss: 0.2276483199781263
Validation loss: 2.457111975720378

Epoch: 5| Step: 2
Training loss: 0.21225621249966134
Validation loss: 2.418128295789665

Epoch: 5| Step: 3
Training loss: 0.38501417777968855
Validation loss: 2.4654438741807274

Epoch: 5| Step: 4
Training loss: 0.3484602322027029
Validation loss: 2.438505980604998

Epoch: 5| Step: 5
Training loss: 0.42696876462333166
Validation loss: 2.486566369750984

Epoch: 5| Step: 6
Training loss: 0.22045221666866366
Validation loss: 2.4656807816522366

Epoch: 5| Step: 7
Training loss: 0.2805563001077255
Validation loss: 2.5063680289643386

Epoch: 5| Step: 8
Training loss: 0.2774992224965931
Validation loss: 2.527835387629279

Epoch: 5| Step: 9
Training loss: 0.19540274442526376
Validation loss: 2.5368509818529366

Epoch: 5| Step: 10
Training loss: 0.3060467795084935
Validation loss: 2.544127955157123

Epoch: 394| Step: 0
Training loss: 0.2272732864719794
Validation loss: 2.547646398717998

Epoch: 5| Step: 1
Training loss: 0.319876734957326
Validation loss: 2.516104509617631

Epoch: 5| Step: 2
Training loss: 0.21124224372032616
Validation loss: 2.534871168635268

Epoch: 5| Step: 3
Training loss: 0.43269054746677327
Validation loss: 2.4712521780643892

Epoch: 5| Step: 4
Training loss: 0.1988956318079065
Validation loss: 2.49525244317555

Epoch: 5| Step: 5
Training loss: 0.25236732975062676
Validation loss: 2.4395111575474733

Epoch: 5| Step: 6
Training loss: 0.41258674923176103
Validation loss: 2.483570447147926

Epoch: 5| Step: 7
Training loss: 0.18706554504743061
Validation loss: 2.4837239246155787

Epoch: 5| Step: 8
Training loss: 0.31262725384878615
Validation loss: 2.484454289334095

Epoch: 5| Step: 9
Training loss: 0.20491268205692206
Validation loss: 2.4942894744712643

Epoch: 5| Step: 10
Training loss: 0.26700227965317547
Validation loss: 2.5010723803219546

Epoch: 395| Step: 0
Training loss: 0.34501538591353714
Validation loss: 2.485173930786142

Epoch: 5| Step: 1
Training loss: 0.173325470879211
Validation loss: 2.4667472124737366

Epoch: 5| Step: 2
Training loss: 0.3724139371441725
Validation loss: 2.483657943942186

Epoch: 5| Step: 3
Training loss: 0.23531372114323137
Validation loss: 2.4557000711141725

Epoch: 5| Step: 4
Training loss: 0.3289622909210395
Validation loss: 2.488056394406305

Epoch: 5| Step: 5
Training loss: 0.286168704857582
Validation loss: 2.480447026639587

Epoch: 5| Step: 6
Training loss: 0.3382387738067146
Validation loss: 2.4504562093396234

Epoch: 5| Step: 7
Training loss: 0.26384835165407833
Validation loss: 2.4336410404884856

Epoch: 5| Step: 8
Training loss: 0.2044670628777299
Validation loss: 2.5163028491418844

Epoch: 5| Step: 9
Training loss: 0.289922915749518
Validation loss: 2.5252595809483394

Epoch: 5| Step: 10
Training loss: 0.34525812463157357
Validation loss: 2.556623121146041

Epoch: 396| Step: 0
Training loss: 0.3663395566777598
Validation loss: 2.540479959605749

Epoch: 5| Step: 1
Training loss: 0.18270354855324467
Validation loss: 2.5056546119694216

Epoch: 5| Step: 2
Training loss: 0.09259810191918029
Validation loss: 2.50301784468172

Epoch: 5| Step: 3
Training loss: 0.19358538895132896
Validation loss: 2.491066420433374

Epoch: 5| Step: 4
Training loss: 0.3946639489330548
Validation loss: 2.5355945575274865

Epoch: 5| Step: 5
Training loss: 0.2439735909313106
Validation loss: 2.5026073805149305

Epoch: 5| Step: 6
Training loss: 0.3914121897659824
Validation loss: 2.493308716063454

Epoch: 5| Step: 7
Training loss: 0.19249124908063697
Validation loss: 2.5030264983005237

Epoch: 5| Step: 8
Training loss: 0.25488747486512664
Validation loss: 2.4925145372385287

Epoch: 5| Step: 9
Training loss: 0.2788774502200726
Validation loss: 2.514378013832834

Epoch: 5| Step: 10
Training loss: 0.38826377568366194
Validation loss: 2.5098396056386263

Epoch: 397| Step: 0
Training loss: 0.39800336036509537
Validation loss: 2.521550903118775

Epoch: 5| Step: 1
Training loss: 0.2504214072982087
Validation loss: 2.5226237536415694

Epoch: 5| Step: 2
Training loss: 0.2091477815887721
Validation loss: 2.5118854069161793

Epoch: 5| Step: 3
Training loss: 0.22280806669450004
Validation loss: 2.5037401381103392

Epoch: 5| Step: 4
Training loss: 0.31223390694433145
Validation loss: 2.4854623049888103

Epoch: 5| Step: 5
Training loss: 0.32446475060750035
Validation loss: 2.4236947454492244

Epoch: 5| Step: 6
Training loss: 0.28823604229270977
Validation loss: 2.4650660742305144

Epoch: 5| Step: 7
Training loss: 0.25526533982290817
Validation loss: 2.449454767190953

Epoch: 5| Step: 8
Training loss: 0.28072711233733255
Validation loss: 2.491094095745619

Epoch: 5| Step: 9
Training loss: 0.31134384383625474
Validation loss: 2.4846316712113685

Epoch: 5| Step: 10
Training loss: 0.2594449925490622
Validation loss: 2.5035554102130604

Epoch: 398| Step: 0
Training loss: 0.3696624861547629
Validation loss: 2.5766220440207266

Epoch: 5| Step: 1
Training loss: 0.33661182502577763
Validation loss: 2.563758856024507

Epoch: 5| Step: 2
Training loss: 0.15310189306339583
Validation loss: 2.5344905439661876

Epoch: 5| Step: 3
Training loss: 0.1844369416527358
Validation loss: 2.560927055606022

Epoch: 5| Step: 4
Training loss: 0.30683227187212575
Validation loss: 2.4769252579872183

Epoch: 5| Step: 5
Training loss: 0.3641975087010971
Validation loss: 2.4388220940253875

Epoch: 5| Step: 6
Training loss: 0.1615053090597298
Validation loss: 2.4749237618917204

Epoch: 5| Step: 7
Training loss: 0.3152480296187571
Validation loss: 2.4808738206569125

Epoch: 5| Step: 8
Training loss: 0.2742871435574669
Validation loss: 2.4936540487978394

Epoch: 5| Step: 9
Training loss: 0.2529530164645466
Validation loss: 2.5353574364709326

Epoch: 5| Step: 10
Training loss: 0.34395879126613976
Validation loss: 2.486280510636618

Epoch: 399| Step: 0
Training loss: 0.18328381817084274
Validation loss: 2.50179427116366

Epoch: 5| Step: 1
Training loss: 0.23666080986978527
Validation loss: 2.5086313952072765

Epoch: 5| Step: 2
Training loss: 0.30356477857366415
Validation loss: 2.5004358670503435

Epoch: 5| Step: 3
Training loss: 0.3024804557839208
Validation loss: 2.5400180186784853

Epoch: 5| Step: 4
Training loss: 0.38147673821681066
Validation loss: 2.543759298689301

Epoch: 5| Step: 5
Training loss: 0.20557865640922834
Validation loss: 2.5232670940218016

Epoch: 5| Step: 6
Training loss: 0.4191379948770815
Validation loss: 2.514341485141486

Epoch: 5| Step: 7
Training loss: 0.2632943735898619
Validation loss: 2.4883557818132176

Epoch: 5| Step: 8
Training loss: 0.29642810563996336
Validation loss: 2.4548884153444317

Epoch: 5| Step: 9
Training loss: 0.23454416845578457
Validation loss: 2.467487144607533

Epoch: 5| Step: 10
Training loss: 0.3290652472951018
Validation loss: 2.4470412288431906

Epoch: 400| Step: 0
Training loss: 0.32037697119967806
Validation loss: 2.42358033328107

Epoch: 5| Step: 1
Training loss: 0.2700536061424548
Validation loss: 2.4617961197586

Epoch: 5| Step: 2
Training loss: 0.3129736529426646
Validation loss: 2.442635698290476

Epoch: 5| Step: 3
Training loss: 0.28508091284114523
Validation loss: 2.4235874722997064

Epoch: 5| Step: 4
Training loss: 0.32622511651888253
Validation loss: 2.4464776774801225

Epoch: 5| Step: 5
Training loss: 0.2270854800382399
Validation loss: 2.5327461092219896

Epoch: 5| Step: 6
Training loss: 0.3536304898461221
Validation loss: 2.531166401400076

Epoch: 5| Step: 7
Training loss: 0.34169179118441123
Validation loss: 2.5152196285575745

Epoch: 5| Step: 8
Training loss: 0.1776110672006396
Validation loss: 2.541895588961832

Epoch: 5| Step: 9
Training loss: 0.3698528221316654
Validation loss: 2.4985664451632923

Epoch: 5| Step: 10
Training loss: 0.4288320174885822
Validation loss: 2.4743644431981897

Epoch: 401| Step: 0
Training loss: 0.2682948988706808
Validation loss: 2.4753769003188797

Epoch: 5| Step: 1
Training loss: 0.32009411554707645
Validation loss: 2.529876072783066

Epoch: 5| Step: 2
Training loss: 0.24635174261490672
Validation loss: 2.5261837148777966

Epoch: 5| Step: 3
Training loss: 0.24995028478305173
Validation loss: 2.5480856726594863

Epoch: 5| Step: 4
Training loss: 0.3855515214046796
Validation loss: 2.5690928420274415

Epoch: 5| Step: 5
Training loss: 0.2780237860229239
Validation loss: 2.5572679471478383

Epoch: 5| Step: 6
Training loss: 0.16123400891655515
Validation loss: 2.5307687149675595

Epoch: 5| Step: 7
Training loss: 0.27713211473891103
Validation loss: 2.567808022552731

Epoch: 5| Step: 8
Training loss: 0.28102406062513907
Validation loss: 2.558212250579214

Epoch: 5| Step: 9
Training loss: 0.2979801338233624
Validation loss: 2.53731718218584

Epoch: 5| Step: 10
Training loss: 0.2976085234098257
Validation loss: 2.5166904601002082

Epoch: 402| Step: 0
Training loss: 0.2796236407511676
Validation loss: 2.5225296818166147

Epoch: 5| Step: 1
Training loss: 0.3325414664361852
Validation loss: 2.4924734911191564

Epoch: 5| Step: 2
Training loss: 0.277572027472819
Validation loss: 2.4611862002259035

Epoch: 5| Step: 3
Training loss: 0.35152760438455516
Validation loss: 2.482182302400684

Epoch: 5| Step: 4
Training loss: 0.4029545453198291
Validation loss: 2.4919080500106956

Epoch: 5| Step: 5
Training loss: 0.368298857522498
Validation loss: 2.4709109984332267

Epoch: 5| Step: 6
Training loss: 0.26188446605935656
Validation loss: 2.466734506205751

Epoch: 5| Step: 7
Training loss: 0.22409226142741057
Validation loss: 2.5056533020914498

Epoch: 5| Step: 8
Training loss: 0.22179725655001897
Validation loss: 2.501834454754892

Epoch: 5| Step: 9
Training loss: 0.20674076934744373
Validation loss: 2.5268975258742863

Epoch: 5| Step: 10
Training loss: 0.22635058653999646
Validation loss: 2.537206651878284

Epoch: 403| Step: 0
Training loss: 0.3386672801725739
Validation loss: 2.4866101300023162

Epoch: 5| Step: 1
Training loss: 0.2696188494096182
Validation loss: 2.475616668861872

Epoch: 5| Step: 2
Training loss: 0.3072314553619939
Validation loss: 2.5319757275738164

Epoch: 5| Step: 3
Training loss: 0.15699966715630098
Validation loss: 2.5046071168189616

Epoch: 5| Step: 4
Training loss: 0.3185768788628733
Validation loss: 2.516396889375944

Epoch: 5| Step: 5
Training loss: 0.33686225603376424
Validation loss: 2.505013991729807

Epoch: 5| Step: 6
Training loss: 0.32368517252395923
Validation loss: 2.4833247149160242

Epoch: 5| Step: 7
Training loss: 0.3565814450686398
Validation loss: 2.483864172753196

Epoch: 5| Step: 8
Training loss: 0.2998798909752467
Validation loss: 2.534362270209506

Epoch: 5| Step: 9
Training loss: 0.21637246112557054
Validation loss: 2.5222557432579227

Epoch: 5| Step: 10
Training loss: 0.32182028083114905
Validation loss: 2.592802407130078

Epoch: 404| Step: 0
Training loss: 0.3079408789399577
Validation loss: 2.5810655516798224

Epoch: 5| Step: 1
Training loss: 0.30206268612686
Validation loss: 2.5749322964570447

Epoch: 5| Step: 2
Training loss: 0.27263268147560604
Validation loss: 2.5593223988975136

Epoch: 5| Step: 3
Training loss: 0.30716519528010866
Validation loss: 2.526992818880199

Epoch: 5| Step: 4
Training loss: 0.38225561625095256
Validation loss: 2.507903266505952

Epoch: 5| Step: 5
Training loss: 0.32938231539700624
Validation loss: 2.504721574915727

Epoch: 5| Step: 6
Training loss: 0.19680958145390742
Validation loss: 2.465878963774017

Epoch: 5| Step: 7
Training loss: 0.14915457488933015
Validation loss: 2.5056293256530346

Epoch: 5| Step: 8
Training loss: 0.32008937880155003
Validation loss: 2.5415770876178163

Epoch: 5| Step: 9
Training loss: 0.29085619610922564
Validation loss: 2.5587976593146657

Epoch: 5| Step: 10
Training loss: 0.35909181300895626
Validation loss: 2.5920982621753095

Epoch: 405| Step: 0
Training loss: 0.3845673258264904
Validation loss: 2.57486010939163

Epoch: 5| Step: 1
Training loss: 0.30959656901879606
Validation loss: 2.60154310088208

Epoch: 5| Step: 2
Training loss: 0.34546367520763477
Validation loss: 2.5728672164489965

Epoch: 5| Step: 3
Training loss: 0.17005711687260958
Validation loss: 2.5727499777122187

Epoch: 5| Step: 4
Training loss: 0.24533487053937883
Validation loss: 2.5577783591173855

Epoch: 5| Step: 5
Training loss: 0.2718637957401785
Validation loss: 2.5260425758339036

Epoch: 5| Step: 6
Training loss: 0.3239094051238699
Validation loss: 2.537836447410835

Epoch: 5| Step: 7
Training loss: 0.35950115311640624
Validation loss: 2.5313872342297508

Epoch: 5| Step: 8
Training loss: 0.3112355998166582
Validation loss: 2.499044552881468

Epoch: 5| Step: 9
Training loss: 0.3528825349452575
Validation loss: 2.5004296897457734

Epoch: 5| Step: 10
Training loss: 0.39281261140613905
Validation loss: 2.5409100178049715

Epoch: 406| Step: 0
Training loss: 0.20177438008767712
Validation loss: 2.5515914861592504

Epoch: 5| Step: 1
Training loss: 0.2570195430188194
Validation loss: 2.5289532526409064

Epoch: 5| Step: 2
Training loss: 0.23639742568162686
Validation loss: 2.533787348784563

Epoch: 5| Step: 3
Training loss: 0.40393890898132834
Validation loss: 2.5303382963533294

Epoch: 5| Step: 4
Training loss: 0.28412366754057466
Validation loss: 2.5319853473751213

Epoch: 5| Step: 5
Training loss: 0.35011360632237354
Validation loss: 2.513872712727117

Epoch: 5| Step: 6
Training loss: 0.2216295866289928
Validation loss: 2.47624054610725

Epoch: 5| Step: 7
Training loss: 0.2921222664946351
Validation loss: 2.439283726421762

Epoch: 5| Step: 8
Training loss: 0.34391277967369605
Validation loss: 2.4467882818382822

Epoch: 5| Step: 9
Training loss: 0.2977441938148047
Validation loss: 2.4741156511961644

Epoch: 5| Step: 10
Training loss: 0.4263133128121679
Validation loss: 2.4903515628310644

Epoch: 407| Step: 0
Training loss: 0.2980419238517957
Validation loss: 2.480313217355086

Epoch: 5| Step: 1
Training loss: 0.26795127355679005
Validation loss: 2.4944377796063257

Epoch: 5| Step: 2
Training loss: 0.301399709809549
Validation loss: 2.485661232576102

Epoch: 5| Step: 3
Training loss: 0.23229565118072282
Validation loss: 2.4443327732423032

Epoch: 5| Step: 4
Training loss: 0.37954677438532436
Validation loss: 2.4869034110327157

Epoch: 5| Step: 5
Training loss: 0.23665323043150127
Validation loss: 2.4557365424590305

Epoch: 5| Step: 6
Training loss: 0.32416833922282384
Validation loss: 2.4679149369593456

Epoch: 5| Step: 7
Training loss: 0.2611625511794181
Validation loss: 2.4859759532576686

Epoch: 5| Step: 8
Training loss: 0.3373652215567371
Validation loss: 2.5265540180711668

Epoch: 5| Step: 9
Training loss: 0.30229083147641217
Validation loss: 2.5441528747065885

Epoch: 5| Step: 10
Training loss: 0.22495646817244952
Validation loss: 2.5693467424732472

Epoch: 408| Step: 0
Training loss: 0.23723262901595782
Validation loss: 2.5521784175582516

Epoch: 5| Step: 1
Training loss: 0.3515882376680425
Validation loss: 2.5371097892874506

Epoch: 5| Step: 2
Training loss: 0.26160274610725853
Validation loss: 2.5728874156721147

Epoch: 5| Step: 3
Training loss: 0.22389244433671535
Validation loss: 2.5011143828420623

Epoch: 5| Step: 4
Training loss: 0.31509067044110006
Validation loss: 2.496808242916773

Epoch: 5| Step: 5
Training loss: 0.22019404378636812
Validation loss: 2.505133861162843

Epoch: 5| Step: 6
Training loss: 0.31269031928112656
Validation loss: 2.4853187564511012

Epoch: 5| Step: 7
Training loss: 0.24781758682013785
Validation loss: 2.461275483839858

Epoch: 5| Step: 8
Training loss: 0.4117842924294131
Validation loss: 2.4503973636333893

Epoch: 5| Step: 9
Training loss: 0.2292864750025913
Validation loss: 2.4795817517760765

Epoch: 5| Step: 10
Training loss: 0.23703701322837786
Validation loss: 2.472995522432081

Epoch: 409| Step: 0
Training loss: 0.335260496399776
Validation loss: 2.485798917915266

Epoch: 5| Step: 1
Training loss: 0.34483636074679297
Validation loss: 2.4838236267032867

Epoch: 5| Step: 2
Training loss: 0.26859211054063586
Validation loss: 2.4876560373516536

Epoch: 5| Step: 3
Training loss: 0.16791978388473108
Validation loss: 2.5278955643854526

Epoch: 5| Step: 4
Training loss: 0.2711757030343253
Validation loss: 2.4836775381855625

Epoch: 5| Step: 5
Training loss: 0.2953348489408339
Validation loss: 2.4689242715672486

Epoch: 5| Step: 6
Training loss: 0.19502445915769673
Validation loss: 2.459623714212398

Epoch: 5| Step: 7
Training loss: 0.2583049636819499
Validation loss: 2.4297533794285067

Epoch: 5| Step: 8
Training loss: 0.2718110349102099
Validation loss: 2.47795352602971

Epoch: 5| Step: 9
Training loss: 0.285676690272035
Validation loss: 2.4416283102136607

Epoch: 5| Step: 10
Training loss: 0.2460719204863524
Validation loss: 2.435485786974275

Epoch: 410| Step: 0
Training loss: 0.3104033228333808
Validation loss: 2.4680525855269932

Epoch: 5| Step: 1
Training loss: 0.19647569466560422
Validation loss: 2.497519447902716

Epoch: 5| Step: 2
Training loss: 0.2501180191419419
Validation loss: 2.49405869045432

Epoch: 5| Step: 3
Training loss: 0.23853027900988938
Validation loss: 2.5017814293295926

Epoch: 5| Step: 4
Training loss: 0.30242990749672677
Validation loss: 2.45070832533356

Epoch: 5| Step: 5
Training loss: 0.3226484394744538
Validation loss: 2.448231280515194

Epoch: 5| Step: 6
Training loss: 0.30960558139845806
Validation loss: 2.4506277270900974

Epoch: 5| Step: 7
Training loss: 0.24667818064467253
Validation loss: 2.407087069916511

Epoch: 5| Step: 8
Training loss: 0.3076224553701661
Validation loss: 2.409610787816273

Epoch: 5| Step: 9
Training loss: 0.22016050932955686
Validation loss: 2.411592040262857

Epoch: 5| Step: 10
Training loss: 0.16251878285977808
Validation loss: 2.4138646814498905

Epoch: 411| Step: 0
Training loss: 0.2312347001092083
Validation loss: 2.4335722123605614

Epoch: 5| Step: 1
Training loss: 0.33735199261375526
Validation loss: 2.4638485667373176

Epoch: 5| Step: 2
Training loss: 0.1399430255569932
Validation loss: 2.4697770754476114

Epoch: 5| Step: 3
Training loss: 0.18177370098296744
Validation loss: 2.486357659511347

Epoch: 5| Step: 4
Training loss: 0.3268660394049438
Validation loss: 2.467982251586906

Epoch: 5| Step: 5
Training loss: 0.20148070250318834
Validation loss: 2.4628023961236436

Epoch: 5| Step: 6
Training loss: 0.15567605583866026
Validation loss: 2.4617904369959285

Epoch: 5| Step: 7
Training loss: 0.3074856189140662
Validation loss: 2.483441476255922

Epoch: 5| Step: 8
Training loss: 0.19609424545407872
Validation loss: 2.4590689377348887

Epoch: 5| Step: 9
Training loss: 0.3322946401341455
Validation loss: 2.495656873951351

Epoch: 5| Step: 10
Training loss: 0.334052263019178
Validation loss: 2.462691563226738

Epoch: 412| Step: 0
Training loss: 0.30024904999912216
Validation loss: 2.4817078732652913

Epoch: 5| Step: 1
Training loss: 0.20434978667888143
Validation loss: 2.48963630844049

Epoch: 5| Step: 2
Training loss: 0.30861556302008025
Validation loss: 2.489319367757752

Epoch: 5| Step: 3
Training loss: 0.3685803475718635
Validation loss: 2.4680499445541706

Epoch: 5| Step: 4
Training loss: 0.27883749309352873
Validation loss: 2.488051749454206

Epoch: 5| Step: 5
Training loss: 0.17078603590343508
Validation loss: 2.4588333106026

Epoch: 5| Step: 6
Training loss: 0.1415690549170754
Validation loss: 2.4492278176987154

Epoch: 5| Step: 7
Training loss: 0.2762618925805696
Validation loss: 2.4131504280178078

Epoch: 5| Step: 8
Training loss: 0.23647223563364578
Validation loss: 2.4157717797892904

Epoch: 5| Step: 9
Training loss: 0.16258180099943564
Validation loss: 2.4207286110237383

Epoch: 5| Step: 10
Training loss: 0.17181259886501848
Validation loss: 2.4284955543949747

Epoch: 413| Step: 0
Training loss: 0.21736368196251513
Validation loss: 2.4220916026650623

Epoch: 5| Step: 1
Training loss: 0.27374699651908163
Validation loss: 2.442647738568487

Epoch: 5| Step: 2
Training loss: 0.2782842110760647
Validation loss: 2.4366433484362684

Epoch: 5| Step: 3
Training loss: 0.1586462514163808
Validation loss: 2.4630679923265038

Epoch: 5| Step: 4
Training loss: 0.24373949285015595
Validation loss: 2.448988739730904

Epoch: 5| Step: 5
Training loss: 0.11492079563787998
Validation loss: 2.5097073547869155

Epoch: 5| Step: 6
Training loss: 0.3288672430870081
Validation loss: 2.5014901590962793

Epoch: 5| Step: 7
Training loss: 0.14483170596091177
Validation loss: 2.4690295521041823

Epoch: 5| Step: 8
Training loss: 0.19658910299923324
Validation loss: 2.4765730596537012

Epoch: 5| Step: 9
Training loss: 0.33197469790686457
Validation loss: 2.468852422003714

Epoch: 5| Step: 10
Training loss: 0.4225475284263993
Validation loss: 2.45341868354209

Epoch: 414| Step: 0
Training loss: 0.3404435969633678
Validation loss: 2.4468278228369527

Epoch: 5| Step: 1
Training loss: 0.1125946034582541
Validation loss: 2.4593977823166577

Epoch: 5| Step: 2
Training loss: 0.30706175053258705
Validation loss: 2.483822404655462

Epoch: 5| Step: 3
Training loss: 0.216915845446315
Validation loss: 2.478666419662033

Epoch: 5| Step: 4
Training loss: 0.3191895689022373
Validation loss: 2.4930258080442362

Epoch: 5| Step: 5
Training loss: 0.2738227038316205
Validation loss: 2.53019100198083

Epoch: 5| Step: 6
Training loss: 0.21776590205955904
Validation loss: 2.5246463553161687

Epoch: 5| Step: 7
Training loss: 0.2397675514330247
Validation loss: 2.4663051359683688

Epoch: 5| Step: 8
Training loss: 0.3047942561410942
Validation loss: 2.456095562539311

Epoch: 5| Step: 9
Training loss: 0.11604832243052009
Validation loss: 2.478361738624911

Epoch: 5| Step: 10
Training loss: 0.23926597114198656
Validation loss: 2.504218512897867

Epoch: 415| Step: 0
Training loss: 0.3665546482737974
Validation loss: 2.4963543654575475

Epoch: 5| Step: 1
Training loss: 0.3876309473528068
Validation loss: 2.4656175829742315

Epoch: 5| Step: 2
Training loss: 0.2953702284887215
Validation loss: 2.486937723371235

Epoch: 5| Step: 3
Training loss: 0.20749774594116766
Validation loss: 2.48738910835789

Epoch: 5| Step: 4
Training loss: 0.21668861022810038
Validation loss: 2.5122820589110746

Epoch: 5| Step: 5
Training loss: 0.23712276816838548
Validation loss: 2.529525050595472

Epoch: 5| Step: 6
Training loss: 0.14484755597468968
Validation loss: 2.5209720745940003

Epoch: 5| Step: 7
Training loss: 0.21717919326924143
Validation loss: 2.555633370821456

Epoch: 5| Step: 8
Training loss: 0.22513163014380863
Validation loss: 2.5043509737601046

Epoch: 5| Step: 9
Training loss: 0.17372148435883292
Validation loss: 2.4926688138746647

Epoch: 5| Step: 10
Training loss: 0.2543612438250183
Validation loss: 2.477007020301092

Epoch: 416| Step: 0
Training loss: 0.23274134470225002
Validation loss: 2.452943998856703

Epoch: 5| Step: 1
Training loss: 0.18622659360137447
Validation loss: 2.48094500845771

Epoch: 5| Step: 2
Training loss: 0.330316886096803
Validation loss: 2.496563456820817

Epoch: 5| Step: 3
Training loss: 0.3519272289846963
Validation loss: 2.465361155416676

Epoch: 5| Step: 4
Training loss: 0.24678887482585604
Validation loss: 2.4556526020165714

Epoch: 5| Step: 5
Training loss: 0.238873028313381
Validation loss: 2.5196489422836623

Epoch: 5| Step: 6
Training loss: 0.1637978462758843
Validation loss: 2.4854092092831683

Epoch: 5| Step: 7
Training loss: 0.27671884600283886
Validation loss: 2.5378613459043846

Epoch: 5| Step: 8
Training loss: 0.1608033829701765
Validation loss: 2.5199743109137707

Epoch: 5| Step: 9
Training loss: 0.2806949701990607
Validation loss: 2.532802813439461

Epoch: 5| Step: 10
Training loss: 0.281811207236825
Validation loss: 2.5436141328006365

Epoch: 417| Step: 0
Training loss: 0.18757077709138714
Validation loss: 2.578834803404775

Epoch: 5| Step: 1
Training loss: 0.2103679526628176
Validation loss: 2.5349106332074287

Epoch: 5| Step: 2
Training loss: 0.2181672952356116
Validation loss: 2.4575908718805133

Epoch: 5| Step: 3
Training loss: 0.30192179992371615
Validation loss: 2.480653284178711

Epoch: 5| Step: 4
Training loss: 0.18599752611263487
Validation loss: 2.4740476843215964

Epoch: 5| Step: 5
Training loss: 0.3636444900970142
Validation loss: 2.4539587922462673

Epoch: 5| Step: 6
Training loss: 0.2331416820688535
Validation loss: 2.447018985055581

Epoch: 5| Step: 7
Training loss: 0.1497764120560197
Validation loss: 2.463673082860026

Epoch: 5| Step: 8
Training loss: 0.11208491174775317
Validation loss: 2.4982852982523998

Epoch: 5| Step: 9
Training loss: 0.3587290722528046
Validation loss: 2.5131501773373293

Epoch: 5| Step: 10
Training loss: 0.31840015220437773
Validation loss: 2.5198030903065316

Epoch: 418| Step: 0
Training loss: 0.3031724897524979
Validation loss: 2.5126792594392056

Epoch: 5| Step: 1
Training loss: 0.2896929387113924
Validation loss: 2.5928052102427457

Epoch: 5| Step: 2
Training loss: 0.16898801297042862
Validation loss: 2.5440553777199315

Epoch: 5| Step: 3
Training loss: 0.3352208699884534
Validation loss: 2.530400225075069

Epoch: 5| Step: 4
Training loss: 0.10761178742168508
Validation loss: 2.5069242170630575

Epoch: 5| Step: 5
Training loss: 0.37488558136296174
Validation loss: 2.547654954079565

Epoch: 5| Step: 6
Training loss: 0.22239158192277744
Validation loss: 2.485671690663076

Epoch: 5| Step: 7
Training loss: 0.3000809331840486
Validation loss: 2.4768372040423245

Epoch: 5| Step: 8
Training loss: 0.17069499849752115
Validation loss: 2.4862453256572796

Epoch: 5| Step: 9
Training loss: 0.14979908769826952
Validation loss: 2.4763420319725555

Epoch: 5| Step: 10
Training loss: 0.27395092581874325
Validation loss: 2.4697305329466466

Epoch: 419| Step: 0
Training loss: 0.3644993162985984
Validation loss: 2.4929140842051116

Epoch: 5| Step: 1
Training loss: 0.14964990763986402
Validation loss: 2.4892635741655313

Epoch: 5| Step: 2
Training loss: 0.2594702913279182
Validation loss: 2.4853883145804154

Epoch: 5| Step: 3
Training loss: 0.22206290139586923
Validation loss: 2.523618504125548

Epoch: 5| Step: 4
Training loss: 0.21571235200406372
Validation loss: 2.5026979501292956

Epoch: 5| Step: 5
Training loss: 0.38254331349741805
Validation loss: 2.45131385691725

Epoch: 5| Step: 6
Training loss: 0.19870041753579146
Validation loss: 2.4843410036352753

Epoch: 5| Step: 7
Training loss: 0.19789077355175563
Validation loss: 2.4779746023995335

Epoch: 5| Step: 8
Training loss: 0.13821829235502234
Validation loss: 2.493262772210133

Epoch: 5| Step: 9
Training loss: 0.1623850225408792
Validation loss: 2.4703346370327215

Epoch: 5| Step: 10
Training loss: 0.1487412356751877
Validation loss: 2.4818094072330257

Epoch: 420| Step: 0
Training loss: 0.23564869971447758
Validation loss: 2.4895032088133147

Epoch: 5| Step: 1
Training loss: 0.2425739681115013
Validation loss: 2.4986264280372756

Epoch: 5| Step: 2
Training loss: 0.2825236357447779
Validation loss: 2.472686671487335

Epoch: 5| Step: 3
Training loss: 0.283307496931131
Validation loss: 2.480373938281575

Epoch: 5| Step: 4
Training loss: 0.2629314056553439
Validation loss: 2.4866589123154856

Epoch: 5| Step: 5
Training loss: 0.18688248235018645
Validation loss: 2.4725667578338095

Epoch: 5| Step: 6
Training loss: 0.1701778369447975
Validation loss: 2.5016749851823907

Epoch: 5| Step: 7
Training loss: 0.27426082092730203
Validation loss: 2.478951707929028

Epoch: 5| Step: 8
Training loss: 0.23746138371687497
Validation loss: 2.4906826454038358

Epoch: 5| Step: 9
Training loss: 0.3394205154541334
Validation loss: 2.4472005820888825

Epoch: 5| Step: 10
Training loss: 0.21700762050900466
Validation loss: 2.4406116839586005

Epoch: 421| Step: 0
Training loss: 0.23308639736011905
Validation loss: 2.4754837744157823

Epoch: 5| Step: 1
Training loss: 0.22253332593024824
Validation loss: 2.428175459250733

Epoch: 5| Step: 2
Training loss: 0.20971113914522968
Validation loss: 2.4312977749733524

Epoch: 5| Step: 3
Training loss: 0.38327553052402075
Validation loss: 2.437791166960543

Epoch: 5| Step: 4
Training loss: 0.23953840967913453
Validation loss: 2.517934614480095

Epoch: 5| Step: 5
Training loss: 0.19214481794713628
Validation loss: 2.451490980529219

Epoch: 5| Step: 6
Training loss: 0.1712806460358248
Validation loss: 2.465296666359273

Epoch: 5| Step: 7
Training loss: 0.14116431504713134
Validation loss: 2.4744735395468838

Epoch: 5| Step: 8
Training loss: 0.18253601024319913
Validation loss: 2.4717004999849963

Epoch: 5| Step: 9
Training loss: 0.2766184658600954
Validation loss: 2.4278404374962665

Epoch: 5| Step: 10
Training loss: 0.3581489297351559
Validation loss: 2.420605034162701

Epoch: 422| Step: 0
Training loss: 0.18825702036473954
Validation loss: 2.40341003162232

Epoch: 5| Step: 1
Training loss: 0.20295420214970478
Validation loss: 2.4225108274968408

Epoch: 5| Step: 2
Training loss: 0.40974343733451724
Validation loss: 2.4789535807978793

Epoch: 5| Step: 3
Training loss: 0.27478054458421763
Validation loss: 2.445583562928359

Epoch: 5| Step: 4
Training loss: 0.20760197516447595
Validation loss: 2.4553300300489433

Epoch: 5| Step: 5
Training loss: 0.34085245718658563
Validation loss: 2.473840239361096

Epoch: 5| Step: 6
Training loss: 0.17402129744595668
Validation loss: 2.489866865539028

Epoch: 5| Step: 7
Training loss: 0.19166471585718384
Validation loss: 2.4898444771722565

Epoch: 5| Step: 8
Training loss: 0.24528722450619178
Validation loss: 2.518970669496507

Epoch: 5| Step: 9
Training loss: 0.19052687879043226
Validation loss: 2.5360081311390847

Epoch: 5| Step: 10
Training loss: 0.25897148468481257
Validation loss: 2.5456787768832925

Epoch: 423| Step: 0
Training loss: 0.3826065677339341
Validation loss: 2.5656611030605143

Epoch: 5| Step: 1
Training loss: 0.2571500590570402
Validation loss: 2.5217533364168285

Epoch: 5| Step: 2
Training loss: 0.22353062523032324
Validation loss: 2.522069144195267

Epoch: 5| Step: 3
Training loss: 0.2723572509798354
Validation loss: 2.484768653464359

Epoch: 5| Step: 4
Training loss: 0.14014930535657052
Validation loss: 2.5034774979638983

Epoch: 5| Step: 5
Training loss: 0.2523424260721819
Validation loss: 2.4500311204743186

Epoch: 5| Step: 6
Training loss: 0.3257128403555828
Validation loss: 2.4519066550291195

Epoch: 5| Step: 7
Training loss: 0.232002095596842
Validation loss: 2.4435717462694115

Epoch: 5| Step: 8
Training loss: 0.15360237708558944
Validation loss: 2.457922228655549

Epoch: 5| Step: 9
Training loss: 0.14957305452389288
Validation loss: 2.5167541568426097

Epoch: 5| Step: 10
Training loss: 0.1643512319561586
Validation loss: 2.511317700092784

Epoch: 424| Step: 0
Training loss: 0.2883551293584805
Validation loss: 2.5069320493273204

Epoch: 5| Step: 1
Training loss: 0.2531432939912263
Validation loss: 2.5130135875871398

Epoch: 5| Step: 2
Training loss: 0.22556725957261348
Validation loss: 2.471834763579713

Epoch: 5| Step: 3
Training loss: 0.2511890713988293
Validation loss: 2.4311750221643385

Epoch: 5| Step: 4
Training loss: 0.2870494494537379
Validation loss: 2.3959845728351787

Epoch: 5| Step: 5
Training loss: 0.25539698569801256
Validation loss: 2.3731716476838387

Epoch: 5| Step: 6
Training loss: 0.3285342570678605
Validation loss: 2.4296310898868865

Epoch: 5| Step: 7
Training loss: 0.15981939991708485
Validation loss: 2.46654579779466

Epoch: 5| Step: 8
Training loss: 0.3194721642966347
Validation loss: 2.5242541364642515

Epoch: 5| Step: 9
Training loss: 0.25103043746104425
Validation loss: 2.5727633232569773

Epoch: 5| Step: 10
Training loss: 0.2864623531868679
Validation loss: 2.5654743769237043

Epoch: 425| Step: 0
Training loss: 0.2612470389841737
Validation loss: 2.5710737099428966

Epoch: 5| Step: 1
Training loss: 0.35472662453660864
Validation loss: 2.566880554451923

Epoch: 5| Step: 2
Training loss: 0.16750323304927783
Validation loss: 2.5185401457169556

Epoch: 5| Step: 3
Training loss: 0.290822944603583
Validation loss: 2.4997711138390253

Epoch: 5| Step: 4
Training loss: 0.33369787096611003
Validation loss: 2.475270998791583

Epoch: 5| Step: 5
Training loss: 0.21144665093089063
Validation loss: 2.4798482066847267

Epoch: 5| Step: 6
Training loss: 0.31730204801719025
Validation loss: 2.4938303157712762

Epoch: 5| Step: 7
Training loss: 0.14543633337458695
Validation loss: 2.506536656617774

Epoch: 5| Step: 8
Training loss: 0.168964484124776
Validation loss: 2.5358164605295817

Epoch: 5| Step: 9
Training loss: 0.21311267157104752
Validation loss: 2.556840652370394

Epoch: 5| Step: 10
Training loss: 0.2316907796228862
Validation loss: 2.620727145666328

Epoch: 426| Step: 0
Training loss: 0.34289618139312844
Validation loss: 2.5973299240799244

Epoch: 5| Step: 1
Training loss: 0.21125750639800783
Validation loss: 2.5716815534879647

Epoch: 5| Step: 2
Training loss: 0.19586133139583822
Validation loss: 2.5275955720126455

Epoch: 5| Step: 3
Training loss: 0.18974036631674362
Validation loss: 2.4873685255721227

Epoch: 5| Step: 4
Training loss: 0.24069888479230392
Validation loss: 2.4570658563779113

Epoch: 5| Step: 5
Training loss: 0.21099935613665038
Validation loss: 2.395799595049997

Epoch: 5| Step: 6
Training loss: 0.21702016895532206
Validation loss: 2.4008886375577814

Epoch: 5| Step: 7
Training loss: 0.27189898220705133
Validation loss: 2.4134280578431384

Epoch: 5| Step: 8
Training loss: 0.2017611973230239
Validation loss: 2.4165859608510383

Epoch: 5| Step: 9
Training loss: 0.28337348549467145
Validation loss: 2.4572734859755387

Epoch: 5| Step: 10
Training loss: 0.30782621033628155
Validation loss: 2.48921837184461

Epoch: 427| Step: 0
Training loss: 0.1632292055388816
Validation loss: 2.504160134082069

Epoch: 5| Step: 1
Training loss: 0.42606075107326863
Validation loss: 2.5091062616595474

Epoch: 5| Step: 2
Training loss: 0.1764960115285348
Validation loss: 2.546128344307966

Epoch: 5| Step: 3
Training loss: 0.24581887773804015
Validation loss: 2.505066625853522

Epoch: 5| Step: 4
Training loss: 0.21528492626418566
Validation loss: 2.558539353836439

Epoch: 5| Step: 5
Training loss: 0.2999247456577422
Validation loss: 2.5090660448423914

Epoch: 5| Step: 6
Training loss: 0.20811490986682252
Validation loss: 2.486072051213741

Epoch: 5| Step: 7
Training loss: 0.23043895787501376
Validation loss: 2.4979099581656063

Epoch: 5| Step: 8
Training loss: 0.20356199135393233
Validation loss: 2.48563245817067

Epoch: 5| Step: 9
Training loss: 0.14189642099591024
Validation loss: 2.4813205720426623

Epoch: 5| Step: 10
Training loss: 0.2221220870377095
Validation loss: 2.473595080474455

Epoch: 428| Step: 0
Training loss: 0.15464303263763154
Validation loss: 2.469063606660409

Epoch: 5| Step: 1
Training loss: 0.33917681705007535
Validation loss: 2.4676826311950957

Epoch: 5| Step: 2
Training loss: 0.19345070387127294
Validation loss: 2.5228049624819993

Epoch: 5| Step: 3
Training loss: 0.29300390668370446
Validation loss: 2.494429580260256

Epoch: 5| Step: 4
Training loss: 0.29555055418858
Validation loss: 2.4946221457523845

Epoch: 5| Step: 5
Training loss: 0.2595952701553943
Validation loss: 2.5025498041325704

Epoch: 5| Step: 6
Training loss: 0.30826408547258644
Validation loss: 2.512618325437409

Epoch: 5| Step: 7
Training loss: 0.1814125125832436
Validation loss: 2.5421190627478283

Epoch: 5| Step: 8
Training loss: 0.16402062381185262
Validation loss: 2.5143302225353326

Epoch: 5| Step: 9
Training loss: 0.12620220380793776
Validation loss: 2.50930221350506

Epoch: 5| Step: 10
Training loss: 0.16445132003119847
Validation loss: 2.555186285662874

Epoch: 429| Step: 0
Training loss: 0.23632020385330085
Validation loss: 2.5348293307847594

Epoch: 5| Step: 1
Training loss: 0.13062424673200917
Validation loss: 2.523519029249197

Epoch: 5| Step: 2
Training loss: 0.3212243452663846
Validation loss: 2.532092112464525

Epoch: 5| Step: 3
Training loss: 0.28172495263370334
Validation loss: 2.5206516983168585

Epoch: 5| Step: 4
Training loss: 0.1737284964180932
Validation loss: 2.528044438832528

Epoch: 5| Step: 5
Training loss: 0.30792739002068026
Validation loss: 2.5255063662692607

Epoch: 5| Step: 6
Training loss: 0.16921259844228234
Validation loss: 2.4952483499814133

Epoch: 5| Step: 7
Training loss: 0.3403322063867017
Validation loss: 2.522972398059073

Epoch: 5| Step: 8
Training loss: 0.20706603819590177
Validation loss: 2.4926953442029363

Epoch: 5| Step: 9
Training loss: 0.21114584558791463
Validation loss: 2.5032576696404925

Epoch: 5| Step: 10
Training loss: 0.15445717198960313
Validation loss: 2.52163817343332

Epoch: 430| Step: 0
Training loss: 0.17556639362063137
Validation loss: 2.4957924527038995

Epoch: 5| Step: 1
Training loss: 0.1290121077328013
Validation loss: 2.4941165419994333

Epoch: 5| Step: 2
Training loss: 0.20627774463790655
Validation loss: 2.4881376209346904

Epoch: 5| Step: 3
Training loss: 0.27407120433107807
Validation loss: 2.469652053419541

Epoch: 5| Step: 4
Training loss: 0.11909056612436887
Validation loss: 2.509055012973043

Epoch: 5| Step: 5
Training loss: 0.2803208314386839
Validation loss: 2.5064700051182145

Epoch: 5| Step: 6
Training loss: 0.19462905516286189
Validation loss: 2.498925527791857

Epoch: 5| Step: 7
Training loss: 0.30257675005115053
Validation loss: 2.519820861629641

Epoch: 5| Step: 8
Training loss: 0.10811540235799758
Validation loss: 2.5258435410868367

Epoch: 5| Step: 9
Training loss: 0.25002680575189107
Validation loss: 2.5118264540882764

Epoch: 5| Step: 10
Training loss: 0.29994323958437563
Validation loss: 2.5034133041697664

Epoch: 431| Step: 0
Training loss: 0.2774008302647983
Validation loss: 2.4980060378071407

Epoch: 5| Step: 1
Training loss: 0.1432613567823584
Validation loss: 2.452734322571895

Epoch: 5| Step: 2
Training loss: 0.19292758162732276
Validation loss: 2.459421728922621

Epoch: 5| Step: 3
Training loss: 0.1650496428670287
Validation loss: 2.4244697138581097

Epoch: 5| Step: 4
Training loss: 0.2853905877615348
Validation loss: 2.464312058689304

Epoch: 5| Step: 5
Training loss: 0.3461075157889518
Validation loss: 2.43358228435155

Epoch: 5| Step: 6
Training loss: 0.13505747884978384
Validation loss: 2.5098478904926975

Epoch: 5| Step: 7
Training loss: 0.22683156413438968
Validation loss: 2.4985297504604254

Epoch: 5| Step: 8
Training loss: 0.2434335234394369
Validation loss: 2.547688171995974

Epoch: 5| Step: 9
Training loss: 0.27222322875494215
Validation loss: 2.536882650590815

Epoch: 5| Step: 10
Training loss: 0.2609159911879092
Validation loss: 2.5201355308939

Epoch: 432| Step: 0
Training loss: 0.2718423911522357
Validation loss: 2.512632973934135

Epoch: 5| Step: 1
Training loss: 0.29357321370460165
Validation loss: 2.537136513716451

Epoch: 5| Step: 2
Training loss: 0.18159446334830048
Validation loss: 2.5281106817609507

Epoch: 5| Step: 3
Training loss: 0.209740856065118
Validation loss: 2.5176860060962274

Epoch: 5| Step: 4
Training loss: 0.2689872310108992
Validation loss: 2.4753131690697625

Epoch: 5| Step: 5
Training loss: 0.10950969168261789
Validation loss: 2.501790155369167

Epoch: 5| Step: 6
Training loss: 0.26216146403498003
Validation loss: 2.4630984874822346

Epoch: 5| Step: 7
Training loss: 0.21432444493493205
Validation loss: 2.4649330352977246

Epoch: 5| Step: 8
Training loss: 0.23954178442935256
Validation loss: 2.483603291257618

Epoch: 5| Step: 9
Training loss: 0.19538817846878273
Validation loss: 2.511642048400984

Epoch: 5| Step: 10
Training loss: 0.2625354578275588
Validation loss: 2.5385475372281987

Epoch: 433| Step: 0
Training loss: 0.21902432441021594
Validation loss: 2.5333568717897097

Epoch: 5| Step: 1
Training loss: 0.1901874076938311
Validation loss: 2.5012814693249865

Epoch: 5| Step: 2
Training loss: 0.2677456407984642
Validation loss: 2.4809895162643816

Epoch: 5| Step: 3
Training loss: 0.2646117378492028
Validation loss: 2.4907243797717853

Epoch: 5| Step: 4
Training loss: 0.30675209351939003
Validation loss: 2.473112193011391

Epoch: 5| Step: 5
Training loss: 0.3008687399905144
Validation loss: 2.456607079723786

Epoch: 5| Step: 6
Training loss: 0.19402742097995962
Validation loss: 2.5026456697917006

Epoch: 5| Step: 7
Training loss: 0.22607865957425907
Validation loss: 2.5170188389559645

Epoch: 5| Step: 8
Training loss: 0.21881894319468082
Validation loss: 2.525301954485442

Epoch: 5| Step: 9
Training loss: 0.19870897593953915
Validation loss: 2.5417815329909463

Epoch: 5| Step: 10
Training loss: 0.13792307258501763
Validation loss: 2.515946933429491

Epoch: 434| Step: 0
Training loss: 0.21206072816746582
Validation loss: 2.4713247291325113

Epoch: 5| Step: 1
Training loss: 0.12693859163873294
Validation loss: 2.431046507473684

Epoch: 5| Step: 2
Training loss: 0.23663916493239637
Validation loss: 2.435622344779542

Epoch: 5| Step: 3
Training loss: 0.23558385947703642
Validation loss: 2.432981544282643

Epoch: 5| Step: 4
Training loss: 0.30710201418606475
Validation loss: 2.4471131635663244

Epoch: 5| Step: 5
Training loss: 0.19969390788714247
Validation loss: 2.4778990351476815

Epoch: 5| Step: 6
Training loss: 0.12923805564248436
Validation loss: 2.5072274649997572

Epoch: 5| Step: 7
Training loss: 0.3245687778393922
Validation loss: 2.544300634659878

Epoch: 5| Step: 8
Training loss: 0.35645352706849714
Validation loss: 2.5766636161763325

Epoch: 5| Step: 9
Training loss: 0.21960975933278806
Validation loss: 2.5689076970977114

Epoch: 5| Step: 10
Training loss: 0.2545495174355804
Validation loss: 2.60078727605081

Epoch: 435| Step: 0
Training loss: 0.13220345874253267
Validation loss: 2.5935712906707695

Epoch: 5| Step: 1
Training loss: 0.17405006620250507
Validation loss: 2.5136582493824084

Epoch: 5| Step: 2
Training loss: 0.3614937273921718
Validation loss: 2.5117362636472986

Epoch: 5| Step: 3
Training loss: 0.24983394591638317
Validation loss: 2.4522205412637077

Epoch: 5| Step: 4
Training loss: 0.22314030749707953
Validation loss: 2.459491285647491

Epoch: 5| Step: 5
Training loss: 0.2750539954235261
Validation loss: 2.423445184062771

Epoch: 5| Step: 6
Training loss: 0.20868752689709852
Validation loss: 2.458717189691915

Epoch: 5| Step: 7
Training loss: 0.26735987429036884
Validation loss: 2.4722095018463395

Epoch: 5| Step: 8
Training loss: 0.18038466216120444
Validation loss: 2.465749127312739

Epoch: 5| Step: 9
Training loss: 0.11098967520705379
Validation loss: 2.4735223311895065

Epoch: 5| Step: 10
Training loss: 0.12742246289705256
Validation loss: 2.494810099463752

Epoch: 436| Step: 0
Training loss: 0.23130325593388434
Validation loss: 2.501745983291592

Epoch: 5| Step: 1
Training loss: 0.17001043401632
Validation loss: 2.5188446699300555

Epoch: 5| Step: 2
Training loss: 0.2741879111661452
Validation loss: 2.514413741624995

Epoch: 5| Step: 3
Training loss: 0.14941397523565797
Validation loss: 2.46895980722263

Epoch: 5| Step: 4
Training loss: 0.30052996951561567
Validation loss: 2.4681965425758357

Epoch: 5| Step: 5
Training loss: 0.15226878253448053
Validation loss: 2.4849846926912793

Epoch: 5| Step: 6
Training loss: 0.16804113602603726
Validation loss: 2.4900354431465845

Epoch: 5| Step: 7
Training loss: 0.1517808553024133
Validation loss: 2.455593754512353

Epoch: 5| Step: 8
Training loss: 0.1596942669970618
Validation loss: 2.51019177718574

Epoch: 5| Step: 9
Training loss: 0.3687579477391195
Validation loss: 2.462804582106146

Epoch: 5| Step: 10
Training loss: 0.23379419204833696
Validation loss: 2.4946644513573992

Epoch: 437| Step: 0
Training loss: 0.14818925553347467
Validation loss: 2.495581037772182

Epoch: 5| Step: 1
Training loss: 0.24654700153167958
Validation loss: 2.505690417337539

Epoch: 5| Step: 2
Training loss: 0.1460510010316551
Validation loss: 2.4483212114258506

Epoch: 5| Step: 3
Training loss: 0.15520792604772735
Validation loss: 2.518157643057085

Epoch: 5| Step: 4
Training loss: 0.3237177298270423
Validation loss: 2.4964972866363313

Epoch: 5| Step: 5
Training loss: 0.11756170845753926
Validation loss: 2.474927788223035

Epoch: 5| Step: 6
Training loss: 0.1967959903940973
Validation loss: 2.49866607621276

Epoch: 5| Step: 7
Training loss: 0.3014975724960773
Validation loss: 2.4786801042124615

Epoch: 5| Step: 8
Training loss: 0.27632361833576746
Validation loss: 2.469911429067794

Epoch: 5| Step: 9
Training loss: 0.16115899884688822
Validation loss: 2.503926938982387

Epoch: 5| Step: 10
Training loss: 0.13214767475003894
Validation loss: 2.508445137829178

Epoch: 438| Step: 0
Training loss: 0.21138290781087418
Validation loss: 2.485733204776402

Epoch: 5| Step: 1
Training loss: 0.11816162705867245
Validation loss: 2.497168196392536

Epoch: 5| Step: 2
Training loss: 0.1821505761230629
Validation loss: 2.5004698260611065

Epoch: 5| Step: 3
Training loss: 0.1866857012625986
Validation loss: 2.5165941138166854

Epoch: 5| Step: 4
Training loss: 0.24004911241840046
Validation loss: 2.4894171465508568

Epoch: 5| Step: 5
Training loss: 0.2274403091738339
Validation loss: 2.479300043398327

Epoch: 5| Step: 6
Training loss: 0.2699846103706263
Validation loss: 2.4589375917256757

Epoch: 5| Step: 7
Training loss: 0.2456214247387536
Validation loss: 2.4241885045848623

Epoch: 5| Step: 8
Training loss: 0.1989976272842914
Validation loss: 2.4241011757465643

Epoch: 5| Step: 9
Training loss: 0.24644365110274183
Validation loss: 2.4443220722105345

Epoch: 5| Step: 10
Training loss: 0.28003143868462876
Validation loss: 2.4219473815750647

Epoch: 439| Step: 0
Training loss: 0.1635766897441919
Validation loss: 2.435109761090128

Epoch: 5| Step: 1
Training loss: 0.2828149173696486
Validation loss: 2.480240991749182

Epoch: 5| Step: 2
Training loss: 0.2615503936846291
Validation loss: 2.4459337105065013

Epoch: 5| Step: 3
Training loss: 0.3336011126418221
Validation loss: 2.458699254589989

Epoch: 5| Step: 4
Training loss: 0.21150251057839184
Validation loss: 2.502025175705009

Epoch: 5| Step: 5
Training loss: 0.11968607801459184
Validation loss: 2.4764665728882167

Epoch: 5| Step: 6
Training loss: 0.1842914674943122
Validation loss: 2.4718332244623156

Epoch: 5| Step: 7
Training loss: 0.23598364479817305
Validation loss: 2.437468093903049

Epoch: 5| Step: 8
Training loss: 0.17955327203542326
Validation loss: 2.45573390076844

Epoch: 5| Step: 9
Training loss: 0.20363829022329666
Validation loss: 2.4581034337146606

Epoch: 5| Step: 10
Training loss: 0.1632411868851358
Validation loss: 2.4548689046049503

Epoch: 440| Step: 0
Training loss: 0.1380040110526912
Validation loss: 2.4805907604675563

Epoch: 5| Step: 1
Training loss: 0.23579971888301357
Validation loss: 2.4929973860089722

Epoch: 5| Step: 2
Training loss: 0.2199939626575165
Validation loss: 2.498997881220249

Epoch: 5| Step: 3
Training loss: 0.2362502419001234
Validation loss: 2.5189638282831646

Epoch: 5| Step: 4
Training loss: 0.18885645357575398
Validation loss: 2.5087846255636115

Epoch: 5| Step: 5
Training loss: 0.18764272860268205
Validation loss: 2.4748512391576023

Epoch: 5| Step: 6
Training loss: 0.21668792255075436
Validation loss: 2.482984476560932

Epoch: 5| Step: 7
Training loss: 0.287782852310888
Validation loss: 2.5018558592000333

Epoch: 5| Step: 8
Training loss: 0.25892494520927306
Validation loss: 2.492526062984963

Epoch: 5| Step: 9
Training loss: 0.1601363960613671
Validation loss: 2.502338075967067

Epoch: 5| Step: 10
Training loss: 0.22357970027647225
Validation loss: 2.4845369502516803

Epoch: 441| Step: 0
Training loss: 0.218600136647919
Validation loss: 2.4721567644473943

Epoch: 5| Step: 1
Training loss: 0.166898483622421
Validation loss: 2.4472277022372375

Epoch: 5| Step: 2
Training loss: 0.1224715314964396
Validation loss: 2.4786777160668234

Epoch: 5| Step: 3
Training loss: 0.15366877907144408
Validation loss: 2.473788243887177

Epoch: 5| Step: 4
Training loss: 0.29672480849699306
Validation loss: 2.494435358242956

Epoch: 5| Step: 5
Training loss: 0.23267258817950123
Validation loss: 2.533641758266416

Epoch: 5| Step: 6
Training loss: 0.24455516716502082
Validation loss: 2.4877982278396105

Epoch: 5| Step: 7
Training loss: 0.13618315281785795
Validation loss: 2.4785174516528756

Epoch: 5| Step: 8
Training loss: 0.33638017896239775
Validation loss: 2.4713027604530295

Epoch: 5| Step: 9
Training loss: 0.25793982742808697
Validation loss: 2.4898375631376943

Epoch: 5| Step: 10
Training loss: 0.12716943945346984
Validation loss: 2.453907372821126

Epoch: 442| Step: 0
Training loss: 0.13806934823579226
Validation loss: 2.4895616162204544

Epoch: 5| Step: 1
Training loss: 0.3059148521340083
Validation loss: 2.477991733801324

Epoch: 5| Step: 2
Training loss: 0.18588593272783024
Validation loss: 2.4954673962965974

Epoch: 5| Step: 3
Training loss: 0.13460561679546446
Validation loss: 2.5192450863658356

Epoch: 5| Step: 4
Training loss: 0.2570421674549033
Validation loss: 2.5354116934837587

Epoch: 5| Step: 5
Training loss: 0.3384744528535759
Validation loss: 2.555431551515879

Epoch: 5| Step: 6
Training loss: 0.23076128578226135
Validation loss: 2.5334686462215896

Epoch: 5| Step: 7
Training loss: 0.25163149450271344
Validation loss: 2.530329271603668

Epoch: 5| Step: 8
Training loss: 0.1770536044822015
Validation loss: 2.5377247123121975

Epoch: 5| Step: 9
Training loss: 0.11838013621126985
Validation loss: 2.504057036994184

Epoch: 5| Step: 10
Training loss: 0.11850363042029578
Validation loss: 2.4645933644837603

Epoch: 443| Step: 0
Training loss: 0.16221186833343545
Validation loss: 2.4899043170045903

Epoch: 5| Step: 1
Training loss: 0.2349291290797185
Validation loss: 2.4758102782318985

Epoch: 5| Step: 2
Training loss: 0.23875862517929583
Validation loss: 2.489652074509354

Epoch: 5| Step: 3
Training loss: 0.19339170089389116
Validation loss: 2.5136769101365535

Epoch: 5| Step: 4
Training loss: 0.18093096632352948
Validation loss: 2.5467601422832997

Epoch: 5| Step: 5
Training loss: 0.17776067769698045
Validation loss: 2.5044125501050103

Epoch: 5| Step: 6
Training loss: 0.13987952898822162
Validation loss: 2.5297536271827523

Epoch: 5| Step: 7
Training loss: 0.13162301848533053
Validation loss: 2.5457781884718957

Epoch: 5| Step: 8
Training loss: 0.3269191906636536
Validation loss: 2.543527377623534

Epoch: 5| Step: 9
Training loss: 0.3241457339877384
Validation loss: 2.522964683670491

Epoch: 5| Step: 10
Training loss: 0.1701473242237536
Validation loss: 2.5117868717778253

Epoch: 444| Step: 0
Training loss: 0.18653392262971846
Validation loss: 2.5160254198817946

Epoch: 5| Step: 1
Training loss: 0.2703354076094448
Validation loss: 2.5274168519598623

Epoch: 5| Step: 2
Training loss: 0.3010479747656895
Validation loss: 2.4662101955422107

Epoch: 5| Step: 3
Training loss: 0.2359065401846359
Validation loss: 2.453708345492617

Epoch: 5| Step: 4
Training loss: 0.3319066655413468
Validation loss: 2.4701015821999732

Epoch: 5| Step: 5
Training loss: 0.12144361989880742
Validation loss: 2.436939484269709

Epoch: 5| Step: 6
Training loss: 0.27056166735930964
Validation loss: 2.486439903502316

Epoch: 5| Step: 7
Training loss: 0.17283598511758186
Validation loss: 2.5049940557460295

Epoch: 5| Step: 8
Training loss: 0.1954971489680131
Validation loss: 2.5042940547547436

Epoch: 5| Step: 9
Training loss: 0.2543728575745136
Validation loss: 2.508837787556715

Epoch: 5| Step: 10
Training loss: 0.34452446478911525
Validation loss: 2.4960840812286706

Epoch: 445| Step: 0
Training loss: 0.22802789103995735
Validation loss: 2.551501539832267

Epoch: 5| Step: 1
Training loss: 0.18044985882855835
Validation loss: 2.5370256814849825

Epoch: 5| Step: 2
Training loss: 0.3063426422594093
Validation loss: 2.5499167578934196

Epoch: 5| Step: 3
Training loss: 0.21242914140401092
Validation loss: 2.4879040235015975

Epoch: 5| Step: 4
Training loss: 0.2392742384896772
Validation loss: 2.491600592687802

Epoch: 5| Step: 5
Training loss: 0.15728352385616146
Validation loss: 2.4570055657895438

Epoch: 5| Step: 6
Training loss: 0.2709073858013979
Validation loss: 2.396198138640483

Epoch: 5| Step: 7
Training loss: 0.24860866636149237
Validation loss: 2.354142021647686

Epoch: 5| Step: 8
Training loss: 0.2534783646014956
Validation loss: 2.3922431365396917

Epoch: 5| Step: 9
Training loss: 0.22272640929868645
Validation loss: 2.4041663024004074

Epoch: 5| Step: 10
Training loss: 0.1800747616633774
Validation loss: 2.4357800159172824

Epoch: 446| Step: 0
Training loss: 0.3305246842395742
Validation loss: 2.4439485576527904

Epoch: 5| Step: 1
Training loss: 0.17728348014554463
Validation loss: 2.469980039618452

Epoch: 5| Step: 2
Training loss: 0.27817859722573773
Validation loss: 2.480332792543438

Epoch: 5| Step: 3
Training loss: 0.24428503724522652
Validation loss: 2.5013091361563435

Epoch: 5| Step: 4
Training loss: 0.266666236829908
Validation loss: 2.4577826426630343

Epoch: 5| Step: 5
Training loss: 0.29015567631580047
Validation loss: 2.4474447280237146

Epoch: 5| Step: 6
Training loss: 0.18052615495385474
Validation loss: 2.4084749917900696

Epoch: 5| Step: 7
Training loss: 0.23279368689389712
Validation loss: 2.403308039994889

Epoch: 5| Step: 8
Training loss: 0.22317696634035075
Validation loss: 2.379730874839473

Epoch: 5| Step: 9
Training loss: 0.28878551822047255
Validation loss: 2.397163217476734

Epoch: 5| Step: 10
Training loss: 0.22648500070686137
Validation loss: 2.379204413113834

Epoch: 447| Step: 0
Training loss: 0.19878709066128522
Validation loss: 2.45867291318195

Epoch: 5| Step: 1
Training loss: 0.2174861878087191
Validation loss: 2.4823030414781724

Epoch: 5| Step: 2
Training loss: 0.14535994344864842
Validation loss: 2.557355401048755

Epoch: 5| Step: 3
Training loss: 0.3129862697495023
Validation loss: 2.5511602601224928

Epoch: 5| Step: 4
Training loss: 0.2198650347634732
Validation loss: 2.5490816895358237

Epoch: 5| Step: 5
Training loss: 0.21954403395440425
Validation loss: 2.535925374804406

Epoch: 5| Step: 6
Training loss: 0.24901013058282476
Validation loss: 2.4948214280983536

Epoch: 5| Step: 7
Training loss: 0.3366455113535925
Validation loss: 2.4431812809727607

Epoch: 5| Step: 8
Training loss: 0.21962526317541586
Validation loss: 2.4196943158392457

Epoch: 5| Step: 9
Training loss: 0.30671336289279116
Validation loss: 2.435181728229765

Epoch: 5| Step: 10
Training loss: 0.26465244923609066
Validation loss: 2.4295998654999895

Epoch: 448| Step: 0
Training loss: 0.20924550970049663
Validation loss: 2.475016862006581

Epoch: 5| Step: 1
Training loss: 0.1815494903492951
Validation loss: 2.545156259676167

Epoch: 5| Step: 2
Training loss: 0.2933448158034293
Validation loss: 2.592388390199726

Epoch: 5| Step: 3
Training loss: 0.37440361840173625
Validation loss: 2.601131542582106

Epoch: 5| Step: 4
Training loss: 0.17832524730459864
Validation loss: 2.5581665413847148

Epoch: 5| Step: 5
Training loss: 0.2931865264194956
Validation loss: 2.490730935216399

Epoch: 5| Step: 6
Training loss: 0.156330195350797
Validation loss: 2.4234152276912853

Epoch: 5| Step: 7
Training loss: 0.28016844055409224
Validation loss: 2.3418442260713803

Epoch: 5| Step: 8
Training loss: 0.30170887176763456
Validation loss: 2.3599038409150386

Epoch: 5| Step: 9
Training loss: 0.3355102483545712
Validation loss: 2.3931517502739577

Epoch: 5| Step: 10
Training loss: 0.31187249601196027
Validation loss: 2.415423139791002

Epoch: 449| Step: 0
Training loss: 0.36367516029586716
Validation loss: 2.430155336290126

Epoch: 5| Step: 1
Training loss: 0.2122545363808613
Validation loss: 2.4874665459497933

Epoch: 5| Step: 2
Training loss: 0.28351147406601707
Validation loss: 2.570526707576474

Epoch: 5| Step: 3
Training loss: 0.36717719205631977
Validation loss: 2.5803929600163036

Epoch: 5| Step: 4
Training loss: 0.1650758228331034
Validation loss: 2.5411810939806165

Epoch: 5| Step: 5
Training loss: 0.2154570754929314
Validation loss: 2.5319079505270246

Epoch: 5| Step: 6
Training loss: 0.24181997962223561
Validation loss: 2.460736880025064

Epoch: 5| Step: 7
Training loss: 0.4244676151537095
Validation loss: 2.481751484695362

Epoch: 5| Step: 8
Training loss: 0.27954244155186947
Validation loss: 2.465332614100662

Epoch: 5| Step: 9
Training loss: 0.15218963530489626
Validation loss: 2.470797051311026

Epoch: 5| Step: 10
Training loss: 0.2553945060194705
Validation loss: 2.508528765989732

Epoch: 450| Step: 0
Training loss: 0.25546769016524323
Validation loss: 2.5452211346169666

Epoch: 5| Step: 1
Training loss: 0.2479521578073313
Validation loss: 2.5515594413478815

Epoch: 5| Step: 2
Training loss: 0.3677365884740606
Validation loss: 2.5516775190716414

Epoch: 5| Step: 3
Training loss: 0.26832456959951406
Validation loss: 2.5050615386153594

Epoch: 5| Step: 4
Training loss: 0.43860714333757983
Validation loss: 2.497469607950706

Epoch: 5| Step: 5
Training loss: 0.2824695557461369
Validation loss: 2.5091398146879835

Epoch: 5| Step: 6
Training loss: 0.263237008246063
Validation loss: 2.4833176438787867

Epoch: 5| Step: 7
Training loss: 0.2567555842149836
Validation loss: 2.5129388322202773

Epoch: 5| Step: 8
Training loss: 0.3101294969603997
Validation loss: 2.511361689523005

Epoch: 5| Step: 9
Training loss: 0.30362822948919693
Validation loss: 2.5457012492347917

Epoch: 5| Step: 10
Training loss: 0.23317296617469002
Validation loss: 2.5685653356272833

Epoch: 451| Step: 0
Training loss: 0.3518912791319781
Validation loss: 2.591241292709581

Epoch: 5| Step: 1
Training loss: 0.37365569120912306
Validation loss: 2.6071026605933665

Epoch: 5| Step: 2
Training loss: 0.3613433422286575
Validation loss: 2.5763286170432247

Epoch: 5| Step: 3
Training loss: 0.22663218972026097
Validation loss: 2.5936322443088375

Epoch: 5| Step: 4
Training loss: 0.26716448143747357
Validation loss: 2.567370612279778

Epoch: 5| Step: 5
Training loss: 0.25820248902396914
Validation loss: 2.5510880716766486

Epoch: 5| Step: 6
Training loss: 0.2383217542648785
Validation loss: 2.5816545605569443

Epoch: 5| Step: 7
Training loss: 0.32941657138784164
Validation loss: 2.587802701181248

Epoch: 5| Step: 8
Training loss: 0.2195297292066143
Validation loss: 2.5439833141684427

Epoch: 5| Step: 9
Training loss: 0.37691975974624947
Validation loss: 2.529437084479349

Epoch: 5| Step: 10
Training loss: 0.35105590348093074
Validation loss: 2.474305943332062

Epoch: 452| Step: 0
Training loss: 0.30242948868908004
Validation loss: 2.4165413187154843

Epoch: 5| Step: 1
Training loss: 0.2703443232860843
Validation loss: 2.4440927989804337

Epoch: 5| Step: 2
Training loss: 0.2780954222006761
Validation loss: 2.435667795510217

Epoch: 5| Step: 3
Training loss: 0.24757263324360887
Validation loss: 2.5076881474719945

Epoch: 5| Step: 4
Training loss: 0.2460741080665294
Validation loss: 2.5658880546487666

Epoch: 5| Step: 5
Training loss: 0.33231016673584934
Validation loss: 2.5564956991842207

Epoch: 5| Step: 6
Training loss: 0.27148158943338946
Validation loss: 2.59278081564532

Epoch: 5| Step: 7
Training loss: 0.34850219074720973
Validation loss: 2.576508682538543

Epoch: 5| Step: 8
Training loss: 0.2535564066526401
Validation loss: 2.5393778842522994

Epoch: 5| Step: 9
Training loss: 0.2799907281949822
Validation loss: 2.4952948829563795

Epoch: 5| Step: 10
Training loss: 0.33632080256236696
Validation loss: 2.508881275324212

Epoch: 453| Step: 0
Training loss: 0.24933810828816452
Validation loss: 2.454071272073655

Epoch: 5| Step: 1
Training loss: 0.38883619812472664
Validation loss: 2.496509166756571

Epoch: 5| Step: 2
Training loss: 0.3315860793298082
Validation loss: 2.480512948547158

Epoch: 5| Step: 3
Training loss: 0.27393840141940085
Validation loss: 2.427331719400584

Epoch: 5| Step: 4
Training loss: 0.18712416373405555
Validation loss: 2.383171843342597

Epoch: 5| Step: 5
Training loss: 0.23179849002431077
Validation loss: 2.366234230198835

Epoch: 5| Step: 6
Training loss: 0.2671475112838742
Validation loss: 2.3485669880821316

Epoch: 5| Step: 7
Training loss: 0.17431869825891902
Validation loss: 2.370411058300515

Epoch: 5| Step: 8
Training loss: 0.30951947778598077
Validation loss: 2.3974084506742845

Epoch: 5| Step: 9
Training loss: 0.23864528333055804
Validation loss: 2.41967200288824

Epoch: 5| Step: 10
Training loss: 0.229450132696625
Validation loss: 2.453785443915296

Epoch: 454| Step: 0
Training loss: 0.2377382720768253
Validation loss: 2.4602159897287383

Epoch: 5| Step: 1
Training loss: 0.3101529676133971
Validation loss: 2.4554652054777195

Epoch: 5| Step: 2
Training loss: 0.12246497632778426
Validation loss: 2.4712662081417975

Epoch: 5| Step: 3
Training loss: 0.17507402353108398
Validation loss: 2.434385180044953

Epoch: 5| Step: 4
Training loss: 0.16265676758507014
Validation loss: 2.455474711579761

Epoch: 5| Step: 5
Training loss: 0.21794677473199145
Validation loss: 2.4758489001275574

Epoch: 5| Step: 6
Training loss: 0.24018639961613988
Validation loss: 2.4807208525367552

Epoch: 5| Step: 7
Training loss: 0.2106614072049844
Validation loss: 2.464359171654107

Epoch: 5| Step: 8
Training loss: 0.3898304678999311
Validation loss: 2.491616450246939

Epoch: 5| Step: 9
Training loss: 0.21267021213246026
Validation loss: 2.5404379416590492

Epoch: 5| Step: 10
Training loss: 0.29793441120512754
Validation loss: 2.4636258537557962

Epoch: 455| Step: 0
Training loss: 0.19511120914010463
Validation loss: 2.4441096963855053

Epoch: 5| Step: 1
Training loss: 0.18181312737564836
Validation loss: 2.4334238792673744

Epoch: 5| Step: 2
Training loss: 0.26326560757859013
Validation loss: 2.451306553923725

Epoch: 5| Step: 3
Training loss: 0.194244727578651
Validation loss: 2.442138526353086

Epoch: 5| Step: 4
Training loss: 0.102437823135653
Validation loss: 2.475034680936129

Epoch: 5| Step: 5
Training loss: 0.28432382290796987
Validation loss: 2.490762218725607

Epoch: 5| Step: 6
Training loss: 0.3269655314180166
Validation loss: 2.501558047007657

Epoch: 5| Step: 7
Training loss: 0.25239296896696317
Validation loss: 2.5089293625155533

Epoch: 5| Step: 8
Training loss: 0.2824555362464071
Validation loss: 2.5496352207883053

Epoch: 5| Step: 9
Training loss: 0.19248369157126202
Validation loss: 2.5416701145508482

Epoch: 5| Step: 10
Training loss: 0.18254907123041553
Validation loss: 2.5133332942533855

Epoch: 456| Step: 0
Training loss: 0.18599620421315297
Validation loss: 2.506647352684576

Epoch: 5| Step: 1
Training loss: 0.27568071386148546
Validation loss: 2.4760540694293427

Epoch: 5| Step: 2
Training loss: 0.14887695762907016
Validation loss: 2.469722292056926

Epoch: 5| Step: 3
Training loss: 0.2854837078984252
Validation loss: 2.4830237152720938

Epoch: 5| Step: 4
Training loss: 0.3433844291390842
Validation loss: 2.4723393085603096

Epoch: 5| Step: 5
Training loss: 0.17051768804137762
Validation loss: 2.462385537515922

Epoch: 5| Step: 6
Training loss: 0.2653017461324932
Validation loss: 2.4453874000123936

Epoch: 5| Step: 7
Training loss: 0.23212421815316323
Validation loss: 2.503385833148868

Epoch: 5| Step: 8
Training loss: 0.14720414393568051
Validation loss: 2.4844224248997864

Epoch: 5| Step: 9
Training loss: 0.19997015596286877
Validation loss: 2.430923738812789

Epoch: 5| Step: 10
Training loss: 0.15452222423596934
Validation loss: 2.4660754656295376

Epoch: 457| Step: 0
Training loss: 0.20230064558936406
Validation loss: 2.490030716432609

Epoch: 5| Step: 1
Training loss: 0.34842744222588273
Validation loss: 2.4613585555128243

Epoch: 5| Step: 2
Training loss: 0.1328161884244481
Validation loss: 2.470839696888169

Epoch: 5| Step: 3
Training loss: 0.2086952294805868
Validation loss: 2.485932061185486

Epoch: 5| Step: 4
Training loss: 0.2690021186181487
Validation loss: 2.4592535713486767

Epoch: 5| Step: 5
Training loss: 0.14239044116688665
Validation loss: 2.4580692450442605

Epoch: 5| Step: 6
Training loss: 0.2631725669914705
Validation loss: 2.4597010602778195

Epoch: 5| Step: 7
Training loss: 0.15605479205800016
Validation loss: 2.480317204963406

Epoch: 5| Step: 8
Training loss: 0.1845081164001425
Validation loss: 2.481912356292667

Epoch: 5| Step: 9
Training loss: 0.22668004275367584
Validation loss: 2.4713303692242667

Epoch: 5| Step: 10
Training loss: 0.18200663125879252
Validation loss: 2.4712020931141723

Epoch: 458| Step: 0
Training loss: 0.20700811760702806
Validation loss: 2.4967415114024236

Epoch: 5| Step: 1
Training loss: 0.13912528420922246
Validation loss: 2.5386161862506103

Epoch: 5| Step: 2
Training loss: 0.24021513016693982
Validation loss: 2.514907482872959

Epoch: 5| Step: 3
Training loss: 0.2960964207792989
Validation loss: 2.56154339490426

Epoch: 5| Step: 4
Training loss: 0.16744202820513207
Validation loss: 2.556891490713563

Epoch: 5| Step: 5
Training loss: 0.12085073836598786
Validation loss: 2.5198060880656294

Epoch: 5| Step: 6
Training loss: 0.2342884380707886
Validation loss: 2.4878225636721765

Epoch: 5| Step: 7
Training loss: 0.2484967814799294
Validation loss: 2.46251672564483

Epoch: 5| Step: 8
Training loss: 0.192335471510434
Validation loss: 2.476891811436417

Epoch: 5| Step: 9
Training loss: 0.22195703742698847
Validation loss: 2.4916745429230556

Epoch: 5| Step: 10
Training loss: 0.2578741780109406
Validation loss: 2.4823024600302905

Epoch: 459| Step: 0
Training loss: 0.1564836543195625
Validation loss: 2.4993260336527934

Epoch: 5| Step: 1
Training loss: 0.16254846441629867
Validation loss: 2.490634958861263

Epoch: 5| Step: 2
Training loss: 0.21214352327575248
Validation loss: 2.483000437156646

Epoch: 5| Step: 3
Training loss: 0.2570806722462048
Validation loss: 2.5177529563409555

Epoch: 5| Step: 4
Training loss: 0.14879024779552946
Validation loss: 2.4938916101412523

Epoch: 5| Step: 5
Training loss: 0.29014796001237164
Validation loss: 2.4591793344752366

Epoch: 5| Step: 6
Training loss: 0.2777437093161421
Validation loss: 2.4482454634603616

Epoch: 5| Step: 7
Training loss: 0.2287966068529109
Validation loss: 2.456854477806945

Epoch: 5| Step: 8
Training loss: 0.12795049192435393
Validation loss: 2.4657863191990423

Epoch: 5| Step: 9
Training loss: 0.2250727145264028
Validation loss: 2.432338096423372

Epoch: 5| Step: 10
Training loss: 0.19658739752534854
Validation loss: 2.4451199794890393

Epoch: 460| Step: 0
Training loss: 0.2531369954080852
Validation loss: 2.465854083885566

Epoch: 5| Step: 1
Training loss: 0.19282249128029497
Validation loss: 2.474304030681585

Epoch: 5| Step: 2
Training loss: 0.21722927446461157
Validation loss: 2.4617474206500436

Epoch: 5| Step: 3
Training loss: 0.21287677439858996
Validation loss: 2.4964321226219215

Epoch: 5| Step: 4
Training loss: 0.18059504453621172
Validation loss: 2.491856528893535

Epoch: 5| Step: 5
Training loss: 0.13575017342986662
Validation loss: 2.496256679699517

Epoch: 5| Step: 6
Training loss: 0.237910623445828
Validation loss: 2.51347573190723

Epoch: 5| Step: 7
Training loss: 0.2070255818580749
Validation loss: 2.5285736553905003

Epoch: 5| Step: 8
Training loss: 0.2462816883166028
Validation loss: 2.508251379363545

Epoch: 5| Step: 9
Training loss: 0.2814342372179078
Validation loss: 2.493734145151997

Epoch: 5| Step: 10
Training loss: 0.18885119665356065
Validation loss: 2.478054796906664

Epoch: 461| Step: 0
Training loss: 0.219763833169857
Validation loss: 2.463950376764642

Epoch: 5| Step: 1
Training loss: 0.13250527189221323
Validation loss: 2.4284472220475464

Epoch: 5| Step: 2
Training loss: 0.2710272968645664
Validation loss: 2.4264840717959917

Epoch: 5| Step: 3
Training loss: 0.1662444108995123
Validation loss: 2.4432268140594675

Epoch: 5| Step: 4
Training loss: 0.21035327184579428
Validation loss: 2.463778121628838

Epoch: 5| Step: 5
Training loss: 0.20947575066688395
Validation loss: 2.5098182605988697

Epoch: 5| Step: 6
Training loss: 0.2190046616220337
Validation loss: 2.486189150124405

Epoch: 5| Step: 7
Training loss: 0.1429042678564578
Validation loss: 2.4654591752205466

Epoch: 5| Step: 8
Training loss: 0.23960400661478307
Validation loss: 2.4957906335585553

Epoch: 5| Step: 9
Training loss: 0.15205996932124055
Validation loss: 2.499654903999474

Epoch: 5| Step: 10
Training loss: 0.17033148865317543
Validation loss: 2.4996173094028515

Epoch: 462| Step: 0
Training loss: 0.11427176626700333
Validation loss: 2.4686163537312855

Epoch: 5| Step: 1
Training loss: 0.17872123480141858
Validation loss: 2.4317645403156165

Epoch: 5| Step: 2
Training loss: 0.30667092240445515
Validation loss: 2.440928376450317

Epoch: 5| Step: 3
Training loss: 0.1274431089674813
Validation loss: 2.3883593844389606

Epoch: 5| Step: 4
Training loss: 0.1513417191767937
Validation loss: 2.411620820549669

Epoch: 5| Step: 5
Training loss: 0.2082212722914099
Validation loss: 2.476613209942391

Epoch: 5| Step: 6
Training loss: 0.15301090047455407
Validation loss: 2.481997211296526

Epoch: 5| Step: 7
Training loss: 0.13571247626430294
Validation loss: 2.4724839118749227

Epoch: 5| Step: 8
Training loss: 0.3015231853019015
Validation loss: 2.4999123578450053

Epoch: 5| Step: 9
Training loss: 0.18155441494337737
Validation loss: 2.4396658951515815

Epoch: 5| Step: 10
Training loss: 0.244859377478543
Validation loss: 2.4717964118904163

Epoch: 463| Step: 0
Training loss: 0.17096489840160678
Validation loss: 2.471926558687137

Epoch: 5| Step: 1
Training loss: 0.27760226330751747
Validation loss: 2.5169183102931063

Epoch: 5| Step: 2
Training loss: 0.1645812337526164
Validation loss: 2.5162845705615813

Epoch: 5| Step: 3
Training loss: 0.23368028358423493
Validation loss: 2.471361999973024

Epoch: 5| Step: 4
Training loss: 0.15253489069783785
Validation loss: 2.4746836503931524

Epoch: 5| Step: 5
Training loss: 0.23756941797269393
Validation loss: 2.443518548168197

Epoch: 5| Step: 6
Training loss: 0.2366316792587756
Validation loss: 2.4236634139087156

Epoch: 5| Step: 7
Training loss: 0.18143134212195228
Validation loss: 2.4344495770501187

Epoch: 5| Step: 8
Training loss: 0.20962962247213823
Validation loss: 2.40575828636835

Epoch: 5| Step: 9
Training loss: 0.16962208006657079
Validation loss: 2.4080843843183155

Epoch: 5| Step: 10
Training loss: 0.1600243502114412
Validation loss: 2.4603598514899794

Epoch: 464| Step: 0
Training loss: 0.12051519884444405
Validation loss: 2.403578496332921

Epoch: 5| Step: 1
Training loss: 0.1711517309769689
Validation loss: 2.4338953485782278

Epoch: 5| Step: 2
Training loss: 0.133394683349419
Validation loss: 2.4755446324409056

Epoch: 5| Step: 3
Training loss: 0.1761643632272719
Validation loss: 2.4640719691475974

Epoch: 5| Step: 4
Training loss: 0.262450206666103
Validation loss: 2.4729574541318518

Epoch: 5| Step: 5
Training loss: 0.17688200997389197
Validation loss: 2.4721818748941886

Epoch: 5| Step: 6
Training loss: 0.2317493228717282
Validation loss: 2.4775950461363263

Epoch: 5| Step: 7
Training loss: 0.17323418741774294
Validation loss: 2.4891258739707203

Epoch: 5| Step: 8
Training loss: 0.25706352912405606
Validation loss: 2.493635615508542

Epoch: 5| Step: 9
Training loss: 0.21747790584758447
Validation loss: 2.4353099031127226

Epoch: 5| Step: 10
Training loss: 0.17495438223854923
Validation loss: 2.453073463815628

Epoch: 465| Step: 0
Training loss: 0.16717279717155104
Validation loss: 2.4476576445310805

Epoch: 5| Step: 1
Training loss: 0.2283756202168387
Validation loss: 2.4453710010225636

Epoch: 5| Step: 2
Training loss: 0.2992222623892823
Validation loss: 2.4366190075238485

Epoch: 5| Step: 3
Training loss: 0.13225630393309507
Validation loss: 2.46946721415073

Epoch: 5| Step: 4
Training loss: 0.13539091119004085
Validation loss: 2.4854073820222737

Epoch: 5| Step: 5
Training loss: 0.11324538699101226
Validation loss: 2.4714646166211645

Epoch: 5| Step: 6
Training loss: 0.08541912366320327
Validation loss: 2.462605614877912

Epoch: 5| Step: 7
Training loss: 0.24927904063442802
Validation loss: 2.4353190904984485

Epoch: 5| Step: 8
Training loss: 0.2381435919059299
Validation loss: 2.471809454622253

Epoch: 5| Step: 9
Training loss: 0.11590361229067123
Validation loss: 2.4613936942074943

Epoch: 5| Step: 10
Training loss: 0.1529203409624901
Validation loss: 2.4679528420455346

Epoch: 466| Step: 0
Training loss: 0.14161317711913304
Validation loss: 2.4722421811305826

Epoch: 5| Step: 1
Training loss: 0.11609735066797315
Validation loss: 2.471240569177134

Epoch: 5| Step: 2
Training loss: 0.15948492751647614
Validation loss: 2.4443504131139027

Epoch: 5| Step: 3
Training loss: 0.1538169374170744
Validation loss: 2.422674724898636

Epoch: 5| Step: 4
Training loss: 0.27419315555601376
Validation loss: 2.42940623832933

Epoch: 5| Step: 5
Training loss: 0.28003251623483183
Validation loss: 2.466033354654842

Epoch: 5| Step: 6
Training loss: 0.1964105353574515
Validation loss: 2.490543477070594

Epoch: 5| Step: 7
Training loss: 0.12439387859904587
Validation loss: 2.473055510796657

Epoch: 5| Step: 8
Training loss: 0.21035104041357963
Validation loss: 2.476995306424998

Epoch: 5| Step: 9
Training loss: 0.12851830105763667
Validation loss: 2.492495210460127

Epoch: 5| Step: 10
Training loss: 0.18257283370806415
Validation loss: 2.5024795787189866

Epoch: 467| Step: 0
Training loss: 0.2584269166968144
Validation loss: 2.469977749966806

Epoch: 5| Step: 1
Training loss: 0.22225527881751145
Validation loss: 2.4770319340968636

Epoch: 5| Step: 2
Training loss: 0.24059673056569095
Validation loss: 2.4648057154528233

Epoch: 5| Step: 3
Training loss: 0.19201244973012593
Validation loss: 2.5135183071593175

Epoch: 5| Step: 4
Training loss: 0.158777078830893
Validation loss: 2.470922775391411

Epoch: 5| Step: 5
Training loss: 0.14700645235637333
Validation loss: 2.4709162047458637

Epoch: 5| Step: 6
Training loss: 0.18594356094227135
Validation loss: 2.4421953697808143

Epoch: 5| Step: 7
Training loss: 0.12969099666293749
Validation loss: 2.475233749525036

Epoch: 5| Step: 8
Training loss: 0.24206468329071684
Validation loss: 2.467095240660572

Epoch: 5| Step: 9
Training loss: 0.11629376545123477
Validation loss: 2.4415042098542683

Epoch: 5| Step: 10
Training loss: 0.14218874894107147
Validation loss: 2.4465129429317205

Epoch: 468| Step: 0
Training loss: 0.2622587980461927
Validation loss: 2.4889403312736325

Epoch: 5| Step: 1
Training loss: 0.12768844980473848
Validation loss: 2.4852852217106847

Epoch: 5| Step: 2
Training loss: 0.23973302553069692
Validation loss: 2.469617962859595

Epoch: 5| Step: 3
Training loss: 0.2516238108254847
Validation loss: 2.445467277272084

Epoch: 5| Step: 4
Training loss: 0.18005343162385645
Validation loss: 2.4550570426383773

Epoch: 5| Step: 5
Training loss: 0.14045111183712353
Validation loss: 2.4383539566071692

Epoch: 5| Step: 6
Training loss: 0.1888894514750614
Validation loss: 2.488981891946943

Epoch: 5| Step: 7
Training loss: 0.13924725132682908
Validation loss: 2.491881002045686

Epoch: 5| Step: 8
Training loss: 0.16670244858511835
Validation loss: 2.4754649686665346

Epoch: 5| Step: 9
Training loss: 0.17230102452146784
Validation loss: 2.496787825568899

Epoch: 5| Step: 10
Training loss: 0.21286097153792458
Validation loss: 2.5149743643746896

Epoch: 469| Step: 0
Training loss: 0.2500297558480831
Validation loss: 2.4861532781257583

Epoch: 5| Step: 1
Training loss: 0.2613340796232718
Validation loss: 2.476335808023412

Epoch: 5| Step: 2
Training loss: 0.12312203337150071
Validation loss: 2.4695582159174183

Epoch: 5| Step: 3
Training loss: 0.13607331922969432
Validation loss: 2.5042663123872253

Epoch: 5| Step: 4
Training loss: 0.2303461702520077
Validation loss: 2.4836650836841265

Epoch: 5| Step: 5
Training loss: 0.19304788912634507
Validation loss: 2.5028411308120857

Epoch: 5| Step: 6
Training loss: 0.09261488164688433
Validation loss: 2.497690031914832

Epoch: 5| Step: 7
Training loss: 0.10930533404333222
Validation loss: 2.515410350746713

Epoch: 5| Step: 8
Training loss: 0.27002938168098656
Validation loss: 2.5351352227821997

Epoch: 5| Step: 9
Training loss: 0.1828625504538169
Validation loss: 2.5092119670709696

Epoch: 5| Step: 10
Training loss: 0.1260808025505527
Validation loss: 2.4730028702245317

Epoch: 470| Step: 0
Training loss: 0.11570504613874516
Validation loss: 2.462232200644592

Epoch: 5| Step: 1
Training loss: 0.14540438208250286
Validation loss: 2.441155944199917

Epoch: 5| Step: 2
Training loss: 0.22923681782124294
Validation loss: 2.418831960240154

Epoch: 5| Step: 3
Training loss: 0.27072546565358996
Validation loss: 2.4344836425043686

Epoch: 5| Step: 4
Training loss: 0.164657269667449
Validation loss: 2.440485140524056

Epoch: 5| Step: 5
Training loss: 0.14963669490124412
Validation loss: 2.4352579978115068

Epoch: 5| Step: 6
Training loss: 0.23646890372262108
Validation loss: 2.457121090454779

Epoch: 5| Step: 7
Training loss: 0.15865808577280377
Validation loss: 2.4625150849254207

Epoch: 5| Step: 8
Training loss: 0.19478044520064505
Validation loss: 2.449051359464393

Epoch: 5| Step: 9
Training loss: 0.21663713154553726
Validation loss: 2.479462035623274

Epoch: 5| Step: 10
Training loss: 0.14811699547849005
Validation loss: 2.5002029295566253

Epoch: 471| Step: 0
Training loss: 0.24070945533320143
Validation loss: 2.4570311435742673

Epoch: 5| Step: 1
Training loss: 0.1557624721209923
Validation loss: 2.4894711875980144

Epoch: 5| Step: 2
Training loss: 0.18386334044251235
Validation loss: 2.4818630003617295

Epoch: 5| Step: 3
Training loss: 0.22321849240017547
Validation loss: 2.4816033723342743

Epoch: 5| Step: 4
Training loss: 0.25776124213479557
Validation loss: 2.5353894342850527

Epoch: 5| Step: 5
Training loss: 0.19407073092550853
Validation loss: 2.4822207595685213

Epoch: 5| Step: 6
Training loss: 0.24864112078980974
Validation loss: 2.4752415691728684

Epoch: 5| Step: 7
Training loss: 0.10289926386941528
Validation loss: 2.467638936307128

Epoch: 5| Step: 8
Training loss: 0.20033527226972267
Validation loss: 2.4863346621340567

Epoch: 5| Step: 9
Training loss: 0.12612394095534804
Validation loss: 2.4856529496162287

Epoch: 5| Step: 10
Training loss: 0.10547663517898531
Validation loss: 2.531451388558607

Epoch: 472| Step: 0
Training loss: 0.14327378589486467
Validation loss: 2.4688021933543487

Epoch: 5| Step: 1
Training loss: 0.2028029621655874
Validation loss: 2.5193655964528463

Epoch: 5| Step: 2
Training loss: 0.188493836555093
Validation loss: 2.5188152160971136

Epoch: 5| Step: 3
Training loss: 0.09704776978038014
Validation loss: 2.5402437270277636

Epoch: 5| Step: 4
Training loss: 0.09158950575844567
Validation loss: 2.475692992332763

Epoch: 5| Step: 5
Training loss: 0.14029416268196612
Validation loss: 2.510327018233524

Epoch: 5| Step: 6
Training loss: 0.1610813521083111
Validation loss: 2.5389271831187745

Epoch: 5| Step: 7
Training loss: 0.1328229128738585
Validation loss: 2.5459184489149767

Epoch: 5| Step: 8
Training loss: 0.1909394118030691
Validation loss: 2.559741548154151

Epoch: 5| Step: 9
Training loss: 0.25607168692602184
Validation loss: 2.4943347195335686

Epoch: 5| Step: 10
Training loss: 0.262874655500686
Validation loss: 2.4879180323202603

Epoch: 473| Step: 0
Training loss: 0.12788767525190453
Validation loss: 2.4834305814058215

Epoch: 5| Step: 1
Training loss: 0.15886288694512732
Validation loss: 2.4777534198730202

Epoch: 5| Step: 2
Training loss: 0.17805357973565017
Validation loss: 2.4029787134367595

Epoch: 5| Step: 3
Training loss: 0.20849777328207825
Validation loss: 2.3708484300630555

Epoch: 5| Step: 4
Training loss: 0.1546595271182067
Validation loss: 2.398460365360912

Epoch: 5| Step: 5
Training loss: 0.09964317795388826
Validation loss: 2.3643244063601307

Epoch: 5| Step: 6
Training loss: 0.12892857271595626
Validation loss: 2.4128130628946405

Epoch: 5| Step: 7
Training loss: 0.1216634148605159
Validation loss: 2.416945995769033

Epoch: 5| Step: 8
Training loss: 0.18675719587602851
Validation loss: 2.421853088216271

Epoch: 5| Step: 9
Training loss: 0.36647148527638995
Validation loss: 2.4764584217022465

Epoch: 5| Step: 10
Training loss: 0.13781048307218796
Validation loss: 2.468624645044932

Epoch: 474| Step: 0
Training loss: 0.12073239122905803
Validation loss: 2.5056161136513766

Epoch: 5| Step: 1
Training loss: 0.24154777020530901
Validation loss: 2.456041030325547

Epoch: 5| Step: 2
Training loss: 0.12157200002078217
Validation loss: 2.479890871837467

Epoch: 5| Step: 3
Training loss: 0.12692376310753792
Validation loss: 2.468146654772334

Epoch: 5| Step: 4
Training loss: 0.25781729722617175
Validation loss: 2.4550909746103495

Epoch: 5| Step: 5
Training loss: 0.26598364796068813
Validation loss: 2.4162219144482044

Epoch: 5| Step: 6
Training loss: 0.19868415274054957
Validation loss: 2.4328795984617786

Epoch: 5| Step: 7
Training loss: 0.1575141964959174
Validation loss: 2.4223612021753094

Epoch: 5| Step: 8
Training loss: 0.18950544205176284
Validation loss: 2.4418257866805964

Epoch: 5| Step: 9
Training loss: 0.15869503897397017
Validation loss: 2.4590869827324355

Epoch: 5| Step: 10
Training loss: 0.16449390752903595
Validation loss: 2.502810677395566

Epoch: 475| Step: 0
Training loss: 0.17037697936368512
Validation loss: 2.4732820328469014

Epoch: 5| Step: 1
Training loss: 0.14573916022868882
Validation loss: 2.4724183280368734

Epoch: 5| Step: 2
Training loss: 0.07905173498397298
Validation loss: 2.513271649839357

Epoch: 5| Step: 3
Training loss: 0.22129551540572015
Validation loss: 2.5165452424912003

Epoch: 5| Step: 4
Training loss: 0.20097554450337987
Validation loss: 2.5111367546796712

Epoch: 5| Step: 5
Training loss: 0.18889972639218028
Validation loss: 2.4781199419118205

Epoch: 5| Step: 6
Training loss: 0.11745284953687062
Validation loss: 2.4587694875812374

Epoch: 5| Step: 7
Training loss: 0.21081166576036087
Validation loss: 2.43318947109579

Epoch: 5| Step: 8
Training loss: 0.2532167021334226
Validation loss: 2.4662421393589495

Epoch: 5| Step: 9
Training loss: 0.13771155782330366
Validation loss: 2.4327238285292614

Epoch: 5| Step: 10
Training loss: 0.23406896479124328
Validation loss: 2.436657010173162

Epoch: 476| Step: 0
Training loss: 0.19396205380378542
Validation loss: 2.443785243329278

Epoch: 5| Step: 1
Training loss: 0.20847370465245932
Validation loss: 2.4630386000888214

Epoch: 5| Step: 2
Training loss: 0.1320056317660575
Validation loss: 2.4980657252361578

Epoch: 5| Step: 3
Training loss: 0.2413274352414841
Validation loss: 2.5667546744480934

Epoch: 5| Step: 4
Training loss: 0.2070093323244038
Validation loss: 2.5522303562536868

Epoch: 5| Step: 5
Training loss: 0.10306578185799758
Validation loss: 2.565955460671027

Epoch: 5| Step: 6
Training loss: 0.11336722071422853
Validation loss: 2.505271883355849

Epoch: 5| Step: 7
Training loss: 0.09997146374374996
Validation loss: 2.453584896358743

Epoch: 5| Step: 8
Training loss: 0.16231784285240855
Validation loss: 2.49963680623472

Epoch: 5| Step: 9
Training loss: 0.26011118455574656
Validation loss: 2.4374388830927893

Epoch: 5| Step: 10
Training loss: 0.18313077624588336
Validation loss: 2.458392398208793

Epoch: 477| Step: 0
Training loss: 0.27203546480247415
Validation loss: 2.4265337152761792

Epoch: 5| Step: 1
Training loss: 0.2079654256410246
Validation loss: 2.3732224792788124

Epoch: 5| Step: 2
Training loss: 0.12545587440354303
Validation loss: 2.385199710021455

Epoch: 5| Step: 3
Training loss: 0.18673446461456195
Validation loss: 2.392681423667031

Epoch: 5| Step: 4
Training loss: 0.1860603255419388
Validation loss: 2.4159849780382476

Epoch: 5| Step: 5
Training loss: 0.23951101334570693
Validation loss: 2.4779503922855484

Epoch: 5| Step: 6
Training loss: 0.19128297222367385
Validation loss: 2.494958382899617

Epoch: 5| Step: 7
Training loss: 0.18874892878702115
Validation loss: 2.512221521421299

Epoch: 5| Step: 8
Training loss: 0.12646856265693968
Validation loss: 2.530685860235544

Epoch: 5| Step: 9
Training loss: 0.18406391813577078
Validation loss: 2.5147461367093333

Epoch: 5| Step: 10
Training loss: 0.1693407073443622
Validation loss: 2.5105808595652035

Epoch: 478| Step: 0
Training loss: 0.17134002310251217
Validation loss: 2.5021638980545466

Epoch: 5| Step: 1
Training loss: 0.27751708994040025
Validation loss: 2.5212796605212278

Epoch: 5| Step: 2
Training loss: 0.20935947410466701
Validation loss: 2.4956362437885184

Epoch: 5| Step: 3
Training loss: 0.17831847867827064
Validation loss: 2.491644491909894

Epoch: 5| Step: 4
Training loss: 0.17577297403138914
Validation loss: 2.5142905939928055

Epoch: 5| Step: 5
Training loss: 0.10506259456008478
Validation loss: 2.495570504102404

Epoch: 5| Step: 6
Training loss: 0.13941125134225532
Validation loss: 2.495354460582544

Epoch: 5| Step: 7
Training loss: 0.14339797880036498
Validation loss: 2.5051385286795083

Epoch: 5| Step: 8
Training loss: 0.1138173031686342
Validation loss: 2.4992481567555367

Epoch: 5| Step: 9
Training loss: 0.21646798592530758
Validation loss: 2.5378589932455933

Epoch: 5| Step: 10
Training loss: 0.17047680750964259
Validation loss: 2.497662425583099

Epoch: 479| Step: 0
Training loss: 0.14093628180795714
Validation loss: 2.5076879762346653

Epoch: 5| Step: 1
Training loss: 0.10785865849463212
Validation loss: 2.4945079241262484

Epoch: 5| Step: 2
Training loss: 0.24932474345795788
Validation loss: 2.4936289032077825

Epoch: 5| Step: 3
Training loss: 0.14574684760322593
Validation loss: 2.4640952637766618

Epoch: 5| Step: 4
Training loss: 0.14757526462583873
Validation loss: 2.46589963912278

Epoch: 5| Step: 5
Training loss: 0.30166608533531014
Validation loss: 2.4401787751403177

Epoch: 5| Step: 6
Training loss: 0.1065718397539051
Validation loss: 2.4193649754944238

Epoch: 5| Step: 7
Training loss: 0.19322891843699289
Validation loss: 2.4622804424641638

Epoch: 5| Step: 8
Training loss: 0.11496871293293634
Validation loss: 2.411729793666205

Epoch: 5| Step: 9
Training loss: 0.18308392207210628
Validation loss: 2.410205399068667

Epoch: 5| Step: 10
Training loss: 0.15418878221616542
Validation loss: 2.434965008686406

Epoch: 480| Step: 0
Training loss: 0.18607321923016398
Validation loss: 2.3951509107492774

Epoch: 5| Step: 1
Training loss: 0.15719870800383418
Validation loss: 2.430145611937815

Epoch: 5| Step: 2
Training loss: 0.26531925556761654
Validation loss: 2.3972298051768224

Epoch: 5| Step: 3
Training loss: 0.09696522844646503
Validation loss: 2.4443057064529894

Epoch: 5| Step: 4
Training loss: 0.11521907074373823
Validation loss: 2.477468205232395

Epoch: 5| Step: 5
Training loss: 0.22517138947118273
Validation loss: 2.494249759295605

Epoch: 5| Step: 6
Training loss: 0.15721864858103518
Validation loss: 2.4671774918799523

Epoch: 5| Step: 7
Training loss: 0.14509876411519287
Validation loss: 2.513432057419934

Epoch: 5| Step: 8
Training loss: 0.10595718067352025
Validation loss: 2.491782793684932

Epoch: 5| Step: 9
Training loss: 0.23271965537337566
Validation loss: 2.5109246326006596

Epoch: 5| Step: 10
Training loss: 0.08710035172586753
Validation loss: 2.50747563090399

Epoch: 481| Step: 0
Training loss: 0.11754833141785118
Validation loss: 2.4904730891309734

Epoch: 5| Step: 1
Training loss: 0.13183770355172003
Validation loss: 2.4895327530264497

Epoch: 5| Step: 2
Training loss: 0.19179011797219264
Validation loss: 2.4967327179182104

Epoch: 5| Step: 3
Training loss: 0.2559788112113743
Validation loss: 2.4582629693419036

Epoch: 5| Step: 4
Training loss: 0.2008230462710914
Validation loss: 2.4583400432842013

Epoch: 5| Step: 5
Training loss: 0.14069658020615972
Validation loss: 2.4550819959189116

Epoch: 5| Step: 6
Training loss: 0.1567862606589917
Validation loss: 2.476269535246194

Epoch: 5| Step: 7
Training loss: 0.15497894070021637
Validation loss: 2.4638194397781903

Epoch: 5| Step: 8
Training loss: 0.16971414847677904
Validation loss: 2.4777128007265716

Epoch: 5| Step: 9
Training loss: 0.1703788652083059
Validation loss: 2.459174401463852

Epoch: 5| Step: 10
Training loss: 0.22002403468007056
Validation loss: 2.4906411697225743

Epoch: 482| Step: 0
Training loss: 0.23356637539148123
Validation loss: 2.529328845087292

Epoch: 5| Step: 1
Training loss: 0.12911526034543006
Validation loss: 2.5457098413447246

Epoch: 5| Step: 2
Training loss: 0.19280252324202737
Validation loss: 2.5303582165442466

Epoch: 5| Step: 3
Training loss: 0.2158121133342939
Validation loss: 2.531899829745313

Epoch: 5| Step: 4
Training loss: 0.24563921474743275
Validation loss: 2.4817381228494666

Epoch: 5| Step: 5
Training loss: 0.10471157412786221
Validation loss: 2.4825952147196646

Epoch: 5| Step: 6
Training loss: 0.2401402374295228
Validation loss: 2.4844242828097745

Epoch: 5| Step: 7
Training loss: 0.08636629352598628
Validation loss: 2.4431210653785302

Epoch: 5| Step: 8
Training loss: 0.20788873478812508
Validation loss: 2.407622995190071

Epoch: 5| Step: 9
Training loss: 0.15029841853740286
Validation loss: 2.4353623999627327

Epoch: 5| Step: 10
Training loss: 0.1773032839648728
Validation loss: 2.4576152137100062

Epoch: 483| Step: 0
Training loss: 0.14588494040527106
Validation loss: 2.468041559901175

Epoch: 5| Step: 1
Training loss: 0.17842868758118136
Validation loss: 2.4393705054230415

Epoch: 5| Step: 2
Training loss: 0.24477359353301256
Validation loss: 2.460460569618959

Epoch: 5| Step: 3
Training loss: 0.23875030877058426
Validation loss: 2.470196175356794

Epoch: 5| Step: 4
Training loss: 0.21681228789107196
Validation loss: 2.5086166702036747

Epoch: 5| Step: 5
Training loss: 0.10684185360388403
Validation loss: 2.5131761517676496

Epoch: 5| Step: 6
Training loss: 0.12146275962787316
Validation loss: 2.530749706159323

Epoch: 5| Step: 7
Training loss: 0.2759937148760684
Validation loss: 2.5690850286326232

Epoch: 5| Step: 8
Training loss: 0.15185687318992644
Validation loss: 2.525433073995729

Epoch: 5| Step: 9
Training loss: 0.1779076496634076
Validation loss: 2.5064427752317955

Epoch: 5| Step: 10
Training loss: 0.11538494908417535
Validation loss: 2.526860240717567

Epoch: 484| Step: 0
Training loss: 0.09623907331427255
Validation loss: 2.5173087304681334

Epoch: 5| Step: 1
Training loss: 0.216212869306444
Validation loss: 2.5200614150735134

Epoch: 5| Step: 2
Training loss: 0.21193028752668852
Validation loss: 2.509605298723605

Epoch: 5| Step: 3
Training loss: 0.15911506441005108
Validation loss: 2.5089390543326386

Epoch: 5| Step: 4
Training loss: 0.12743229303624906
Validation loss: 2.4608344745833013

Epoch: 5| Step: 5
Training loss: 0.17500057113928918
Validation loss: 2.4517259199832004

Epoch: 5| Step: 6
Training loss: 0.22028894298496246
Validation loss: 2.491483124047984

Epoch: 5| Step: 7
Training loss: 0.2353069057280884
Validation loss: 2.4669256981709276

Epoch: 5| Step: 8
Training loss: 0.1228789023163397
Validation loss: 2.5039924510885396

Epoch: 5| Step: 9
Training loss: 0.10813789157143924
Validation loss: 2.503537717479264

Epoch: 5| Step: 10
Training loss: 0.23620274267905716
Validation loss: 2.5284825201696113

Epoch: 485| Step: 0
Training loss: 0.09868896415674022
Validation loss: 2.532423896475745

Epoch: 5| Step: 1
Training loss: 0.2546053578427695
Validation loss: 2.5513693233645776

Epoch: 5| Step: 2
Training loss: 0.22726981150317319
Validation loss: 2.5647508143700923

Epoch: 5| Step: 3
Training loss: 0.1334239265140323
Validation loss: 2.5260984694540203

Epoch: 5| Step: 4
Training loss: 0.22240566072631143
Validation loss: 2.5035287993847195

Epoch: 5| Step: 5
Training loss: 0.11634314653981423
Validation loss: 2.4704592026849896

Epoch: 5| Step: 6
Training loss: 0.14879385936693143
Validation loss: 2.5206678745198223

Epoch: 5| Step: 7
Training loss: 0.10460554195672006
Validation loss: 2.502296510708936

Epoch: 5| Step: 8
Training loss: 0.130748680609999
Validation loss: 2.489037059965002

Epoch: 5| Step: 9
Training loss: 0.19909971084018097
Validation loss: 2.4701104756791796

Epoch: 5| Step: 10
Training loss: 0.232525225509138
Validation loss: 2.449552138300962

Epoch: 486| Step: 0
Training loss: 0.12312554312116629
Validation loss: 2.443591554937899

Epoch: 5| Step: 1
Training loss: 0.2070430536324126
Validation loss: 2.3967961806015023

Epoch: 5| Step: 2
Training loss: 0.3074336639819504
Validation loss: 2.417679539064225

Epoch: 5| Step: 3
Training loss: 0.16574436353540212
Validation loss: 2.433946403972055

Epoch: 5| Step: 4
Training loss: 0.1498873700047256
Validation loss: 2.417018702081812

Epoch: 5| Step: 5
Training loss: 0.1748244737903046
Validation loss: 2.4418485318470124

Epoch: 5| Step: 6
Training loss: 0.209781001857575
Validation loss: 2.4889448447860447

Epoch: 5| Step: 7
Training loss: 0.2084354696646752
Validation loss: 2.488255132119965

Epoch: 5| Step: 8
Training loss: 0.21404327911903037
Validation loss: 2.5528246544780666

Epoch: 5| Step: 9
Training loss: 0.12200229275563866
Validation loss: 2.545983058741969

Epoch: 5| Step: 10
Training loss: 0.15303306641921344
Validation loss: 2.542066013857468

Epoch: 487| Step: 0
Training loss: 0.11267309300361183
Validation loss: 2.5299609168219432

Epoch: 5| Step: 1
Training loss: 0.1484093827671832
Validation loss: 2.493670820094118

Epoch: 5| Step: 2
Training loss: 0.25432965115743555
Validation loss: 2.488976671923283

Epoch: 5| Step: 3
Training loss: 0.18872226255495544
Validation loss: 2.493085052225552

Epoch: 5| Step: 4
Training loss: 0.20297172155106485
Validation loss: 2.459054983499308

Epoch: 5| Step: 5
Training loss: 0.11438288730514412
Validation loss: 2.4711501667520666

Epoch: 5| Step: 6
Training loss: 0.21503671303556132
Validation loss: 2.4794962612114873

Epoch: 5| Step: 7
Training loss: 0.21435800607348302
Validation loss: 2.4979284276489295

Epoch: 5| Step: 8
Training loss: 0.21089321130705752
Validation loss: 2.5178332238257517

Epoch: 5| Step: 9
Training loss: 0.11003494837974656
Validation loss: 2.5162407069288344

Epoch: 5| Step: 10
Training loss: 0.11042570897705581
Validation loss: 2.522673747021506

Epoch: 488| Step: 0
Training loss: 0.18588925945969692
Validation loss: 2.5530340935447895

Epoch: 5| Step: 1
Training loss: 0.2592632483837424
Validation loss: 2.5193148932887124

Epoch: 5| Step: 2
Training loss: 0.1668673321841052
Validation loss: 2.487579054474689

Epoch: 5| Step: 3
Training loss: 0.140436702070274
Validation loss: 2.466199203779814

Epoch: 5| Step: 4
Training loss: 0.14200383627857313
Validation loss: 2.443346325718731

Epoch: 5| Step: 5
Training loss: 0.23454343783169035
Validation loss: 2.4113073878271374

Epoch: 5| Step: 6
Training loss: 0.21307125652869055
Validation loss: 2.4394573958860915

Epoch: 5| Step: 7
Training loss: 0.12809426154113387
Validation loss: 2.4344500109140434

Epoch: 5| Step: 8
Training loss: 0.2916103405151833
Validation loss: 2.4301186846255427

Epoch: 5| Step: 9
Training loss: 0.12080887387305786
Validation loss: 2.441311256972516

Epoch: 5| Step: 10
Training loss: 0.1331237623667609
Validation loss: 2.4674940464635204

Epoch: 489| Step: 0
Training loss: 0.16905489989101252
Validation loss: 2.4957085713650855

Epoch: 5| Step: 1
Training loss: 0.2289881833012609
Validation loss: 2.5097432673046463

Epoch: 5| Step: 2
Training loss: 0.19814800975711128
Validation loss: 2.5237996537323166

Epoch: 5| Step: 3
Training loss: 0.23469739833382486
Validation loss: 2.537259291106801

Epoch: 5| Step: 4
Training loss: 0.1701595244955179
Validation loss: 2.533683410326724

Epoch: 5| Step: 5
Training loss: 0.14586328442998703
Validation loss: 2.5100238955565146

Epoch: 5| Step: 6
Training loss: 0.0906369244606417
Validation loss: 2.469943746417996

Epoch: 5| Step: 7
Training loss: 0.1377443740231532
Validation loss: 2.3919835464653345

Epoch: 5| Step: 8
Training loss: 0.24550244273137797
Validation loss: 2.46446194673877

Epoch: 5| Step: 9
Training loss: 0.1205370743834998
Validation loss: 2.4485481255905412

Epoch: 5| Step: 10
Training loss: 0.1901796704854747
Validation loss: 2.443556507512294

Epoch: 490| Step: 0
Training loss: 0.1603273547690969
Validation loss: 2.4814101426445396

Epoch: 5| Step: 1
Training loss: 0.21879137022643336
Validation loss: 2.4979797619553583

Epoch: 5| Step: 2
Training loss: 0.22050520369115867
Validation loss: 2.471239666647535

Epoch: 5| Step: 3
Training loss: 0.22017391864926453
Validation loss: 2.4891271176182697

Epoch: 5| Step: 4
Training loss: 0.21894271059557516
Validation loss: 2.4765384996785293

Epoch: 5| Step: 5
Training loss: 0.16014891700704478
Validation loss: 2.489653473896313

Epoch: 5| Step: 6
Training loss: 0.1597415276334347
Validation loss: 2.413200053649208

Epoch: 5| Step: 7
Training loss: 0.15251521706875848
Validation loss: 2.4646471104157395

Epoch: 5| Step: 8
Training loss: 0.15867597064729133
Validation loss: 2.452380139710292

Epoch: 5| Step: 9
Training loss: 0.12358843743761723
Validation loss: 2.4455230705050286

Epoch: 5| Step: 10
Training loss: 0.15156211607186368
Validation loss: 2.477190891296152

Epoch: 491| Step: 0
Training loss: 0.13905253347836036
Validation loss: 2.494194698352255

Epoch: 5| Step: 1
Training loss: 0.2546330540038247
Validation loss: 2.5303507131201965

Epoch: 5| Step: 2
Training loss: 0.12826643731650822
Validation loss: 2.5516559945379895

Epoch: 5| Step: 3
Training loss: 0.22863168296098274
Validation loss: 2.523582751729734

Epoch: 5| Step: 4
Training loss: 0.1492633059024099
Validation loss: 2.542485047539016

Epoch: 5| Step: 5
Training loss: 0.16586647065231316
Validation loss: 2.546119902628752

Epoch: 5| Step: 6
Training loss: 0.07266564103419469
Validation loss: 2.5261489207708574

Epoch: 5| Step: 7
Training loss: 0.2624364094685415
Validation loss: 2.538322266363388

Epoch: 5| Step: 8
Training loss: 0.12624192197847184
Validation loss: 2.5137941004221527

Epoch: 5| Step: 9
Training loss: 0.15692657379040656
Validation loss: 2.5375108292394692

Epoch: 5| Step: 10
Training loss: 0.09169427230705184
Validation loss: 2.504882976253165

Epoch: 492| Step: 0
Training loss: 0.24526081208846406
Validation loss: 2.517976182745404

Epoch: 5| Step: 1
Training loss: 0.11512439943368188
Validation loss: 2.557324525164941

Epoch: 5| Step: 2
Training loss: 0.21936716144501428
Validation loss: 2.488492507300327

Epoch: 5| Step: 3
Training loss: 0.1416061795238335
Validation loss: 2.5159051945846125

Epoch: 5| Step: 4
Training loss: 0.20932885771786394
Validation loss: 2.479330725621755

Epoch: 5| Step: 5
Training loss: 0.10033036605436303
Validation loss: 2.479592309944773

Epoch: 5| Step: 6
Training loss: 0.19918308686824834
Validation loss: 2.4738420999075057

Epoch: 5| Step: 7
Training loss: 0.19113118005519703
Validation loss: 2.4434438510685372

Epoch: 5| Step: 8
Training loss: 0.19621616167468575
Validation loss: 2.4807400080412143

Epoch: 5| Step: 9
Training loss: 0.13369521448411203
Validation loss: 2.469396736747273

Epoch: 5| Step: 10
Training loss: 0.12343634170278496
Validation loss: 2.471649066919172

Epoch: 493| Step: 0
Training loss: 0.08959128837510168
Validation loss: 2.474797859857654

Epoch: 5| Step: 1
Training loss: 0.14120171096016063
Validation loss: 2.5224651684582904

Epoch: 5| Step: 2
Training loss: 0.1380292616975826
Validation loss: 2.540056211823982

Epoch: 5| Step: 3
Training loss: 0.14255226240354735
Validation loss: 2.4885515379903183

Epoch: 5| Step: 4
Training loss: 0.1718150272641442
Validation loss: 2.5515253956811104

Epoch: 5| Step: 5
Training loss: 0.2341555919452148
Validation loss: 2.5255579368654875

Epoch: 5| Step: 6
Training loss: 0.20740746557613188
Validation loss: 2.4302692237250985

Epoch: 5| Step: 7
Training loss: 0.26145269620879946
Validation loss: 2.446715731941773

Epoch: 5| Step: 8
Training loss: 0.29058327016363905
Validation loss: 2.3826959246262494

Epoch: 5| Step: 9
Training loss: 0.1728568642013335
Validation loss: 2.44121787642731

Epoch: 5| Step: 10
Training loss: 0.20517138222686132
Validation loss: 2.449574377924015

Epoch: 494| Step: 0
Training loss: 0.18169185982319638
Validation loss: 2.426923870615587

Epoch: 5| Step: 1
Training loss: 0.12121713412860743
Validation loss: 2.447918456807177

Epoch: 5| Step: 2
Training loss: 0.1570898492327676
Validation loss: 2.4815071354179907

Epoch: 5| Step: 3
Training loss: 0.22951793931989756
Validation loss: 2.5037003132777347

Epoch: 5| Step: 4
Training loss: 0.20866876460606137
Validation loss: 2.5097327560469265

Epoch: 5| Step: 5
Training loss: 0.255382938730284
Validation loss: 2.560681162538957

Epoch: 5| Step: 6
Training loss: 0.09494780727829372
Validation loss: 2.5165700658895758

Epoch: 5| Step: 7
Training loss: 0.12662946083518603
Validation loss: 2.525588538264445

Epoch: 5| Step: 8
Training loss: 0.1971449435630982
Validation loss: 2.5050391898494433

Epoch: 5| Step: 9
Training loss: 0.10555980425295401
Validation loss: 2.481523971246225

Epoch: 5| Step: 10
Training loss: 0.1280766436575062
Validation loss: 2.496335893570962

Epoch: 495| Step: 0
Training loss: 0.17060690946358242
Validation loss: 2.4568001888752264

Epoch: 5| Step: 1
Training loss: 0.13218032924555612
Validation loss: 2.4848836389860143

Epoch: 5| Step: 2
Training loss: 0.13127449720967835
Validation loss: 2.478346125717719

Epoch: 5| Step: 3
Training loss: 0.13791949372500953
Validation loss: 2.495174420643541

Epoch: 5| Step: 4
Training loss: 0.1367785050733552
Validation loss: 2.455545375061511

Epoch: 5| Step: 5
Training loss: 0.2710274068251375
Validation loss: 2.4784252743380017

Epoch: 5| Step: 6
Training loss: 0.10005767768233514
Validation loss: 2.499912908021513

Epoch: 5| Step: 7
Training loss: 0.1418743728317145
Validation loss: 2.5330529010241816

Epoch: 5| Step: 8
Training loss: 0.20277239382377324
Validation loss: 2.5180640325512984

Epoch: 5| Step: 9
Training loss: 0.19538590005670203
Validation loss: 2.4918849629124344

Epoch: 5| Step: 10
Training loss: 0.17886208567994222
Validation loss: 2.483435892831868

Epoch: 496| Step: 0
Training loss: 0.13699129051565304
Validation loss: 2.4590756500223936

Epoch: 5| Step: 1
Training loss: 0.11540977012503836
Validation loss: 2.450895428173541

Epoch: 5| Step: 2
Training loss: 0.17668759020704214
Validation loss: 2.4158428978381963

Epoch: 5| Step: 3
Training loss: 0.13034676028268982
Validation loss: 2.4226400590042023

Epoch: 5| Step: 4
Training loss: 0.1666827988764413
Validation loss: 2.4219064308902976

Epoch: 5| Step: 5
Training loss: 0.29437541228668435
Validation loss: 2.4058552591217626

Epoch: 5| Step: 6
Training loss: 0.1889135108637755
Validation loss: 2.4633281814457155

Epoch: 5| Step: 7
Training loss: 0.2146380566906176
Validation loss: 2.4936711722042877

Epoch: 5| Step: 8
Training loss: 0.1420799265019117
Validation loss: 2.5036059942759747

Epoch: 5| Step: 9
Training loss: 0.13318534715658778
Validation loss: 2.5007993696829374

Epoch: 5| Step: 10
Training loss: 0.1450315014558144
Validation loss: 2.506660510415394

Epoch: 497| Step: 0
Training loss: 0.13073298058006108
Validation loss: 2.523353535895897

Epoch: 5| Step: 1
Training loss: 0.18422693271598956
Validation loss: 2.532405956462421

Epoch: 5| Step: 2
Training loss: 0.1429796118336315
Validation loss: 2.5211889703751833

Epoch: 5| Step: 3
Training loss: 0.1605171057674492
Validation loss: 2.5137484789685787

Epoch: 5| Step: 4
Training loss: 0.12306670377302144
Validation loss: 2.4769295429219436

Epoch: 5| Step: 5
Training loss: 0.12751432503139407
Validation loss: 2.46350653606266

Epoch: 5| Step: 6
Training loss: 0.2704421697080731
Validation loss: 2.476495359072303

Epoch: 5| Step: 7
Training loss: 0.10055097879839639
Validation loss: 2.453338490441044

Epoch: 5| Step: 8
Training loss: 0.23032650356344375
Validation loss: 2.455483109911012

Epoch: 5| Step: 9
Training loss: 0.2265576822492124
Validation loss: 2.4735802018324575

Epoch: 5| Step: 10
Training loss: 0.21098372164923637
Validation loss: 2.4563580938198553

Epoch: 498| Step: 0
Training loss: 0.16325628212945653
Validation loss: 2.448637530804126

Epoch: 5| Step: 1
Training loss: 0.20706340252224487
Validation loss: 2.5030579046732973

Epoch: 5| Step: 2
Training loss: 0.11290419655370316
Validation loss: 2.509553198037892

Epoch: 5| Step: 3
Training loss: 0.0882391113802188
Validation loss: 2.557961089454504

Epoch: 5| Step: 4
Training loss: 0.24342942982275007
Validation loss: 2.5708135889466224

Epoch: 5| Step: 5
Training loss: 0.15793322274975746
Validation loss: 2.541855398749553

Epoch: 5| Step: 6
Training loss: 0.15521294237073646
Validation loss: 2.5215040901176953

Epoch: 5| Step: 7
Training loss: 0.11550529604954902
Validation loss: 2.499309729577109

Epoch: 5| Step: 8
Training loss: 0.15715129306369252
Validation loss: 2.531970623525887

Epoch: 5| Step: 9
Training loss: 0.149377893296157
Validation loss: 2.529536053999386

Epoch: 5| Step: 10
Training loss: 0.26589993665442657
Validation loss: 2.494750748271652

Epoch: 499| Step: 0
Training loss: 0.16166187474884902
Validation loss: 2.4837930794558893

Epoch: 5| Step: 1
Training loss: 0.11251948588548649
Validation loss: 2.500798421951486

Epoch: 5| Step: 2
Training loss: 0.11761823806369526
Validation loss: 2.4912173054023476

Epoch: 5| Step: 3
Training loss: 0.20760714308376677
Validation loss: 2.4872851146155592

Epoch: 5| Step: 4
Training loss: 0.22037727641424526
Validation loss: 2.5080407994888665

Epoch: 5| Step: 5
Training loss: 0.21905321155941856
Validation loss: 2.5027002579905733

Epoch: 5| Step: 6
Training loss: 0.12887192037817433
Validation loss: 2.5377946614761946

Epoch: 5| Step: 7
Training loss: 0.21331616838946255
Validation loss: 2.4882097347800043

Epoch: 5| Step: 8
Training loss: 0.08417406671880891
Validation loss: 2.477511230595945

Epoch: 5| Step: 9
Training loss: 0.14447235505517597
Validation loss: 2.5059940079228475

Epoch: 5| Step: 10
Training loss: 0.1430629625654596
Validation loss: 2.4878611351081585

Epoch: 500| Step: 0
Training loss: 0.14842507034261218
Validation loss: 2.4822334041216845

Epoch: 5| Step: 1
Training loss: 0.27329803724948537
Validation loss: 2.465649410739223

Epoch: 5| Step: 2
Training loss: 0.1892131780344227
Validation loss: 2.476064435048905

Epoch: 5| Step: 3
Training loss: 0.13004443502743943
Validation loss: 2.458251765799219

Epoch: 5| Step: 4
Training loss: 0.25535237697770785
Validation loss: 2.4421949233839806

Epoch: 5| Step: 5
Training loss: 0.15198946986419573
Validation loss: 2.4649080324953907

Epoch: 5| Step: 6
Training loss: 0.1546034061750477
Validation loss: 2.4425849210815804

Epoch: 5| Step: 7
Training loss: 0.11280816046063805
Validation loss: 2.46088990170176

Epoch: 5| Step: 8
Training loss: 0.11871282190030395
Validation loss: 2.4458419581494226

Epoch: 5| Step: 9
Training loss: 0.11705072686524945
Validation loss: 2.4522358662681336

Epoch: 5| Step: 10
Training loss: 0.1293387454715169
Validation loss: 2.4809877244976537

Epoch: 501| Step: 0
Training loss: 0.1271178131022476
Validation loss: 2.515576286152532

Epoch: 5| Step: 1
Training loss: 0.1285688579889884
Validation loss: 2.49634300116078

Epoch: 5| Step: 2
Training loss: 0.08780131570855589
Validation loss: 2.5065936760670775

Epoch: 5| Step: 3
Training loss: 0.19860213351318606
Validation loss: 2.5144983672042147

Epoch: 5| Step: 4
Training loss: 0.20304487555452522
Validation loss: 2.506687945037447

Epoch: 5| Step: 5
Training loss: 0.1385448975891406
Validation loss: 2.4644939621064452

Epoch: 5| Step: 6
Training loss: 0.12278047742937959
Validation loss: 2.4320962782653894

Epoch: 5| Step: 7
Training loss: 0.2682240479483958
Validation loss: 2.425467817029349

Epoch: 5| Step: 8
Training loss: 0.12995054156978372
Validation loss: 2.407640223617095

Epoch: 5| Step: 9
Training loss: 0.1816774761596035
Validation loss: 2.417154717589141

Epoch: 5| Step: 10
Training loss: 0.2120433360332856
Validation loss: 2.4315973198850553

Epoch: 502| Step: 0
Training loss: 0.10490497269760485
Validation loss: 2.422557740662842

Epoch: 5| Step: 1
Training loss: 0.16172922326234832
Validation loss: 2.464357562329702

Epoch: 5| Step: 2
Training loss: 0.16320552552988254
Validation loss: 2.445009146374914

Epoch: 5| Step: 3
Training loss: 0.15762739443907758
Validation loss: 2.4949048542600853

Epoch: 5| Step: 4
Training loss: 0.23331744492596973
Validation loss: 2.5012151267187024

Epoch: 5| Step: 5
Training loss: 0.2794316773453216
Validation loss: 2.5271824725061043

Epoch: 5| Step: 6
Training loss: 0.21600704831416534
Validation loss: 2.517935495181583

Epoch: 5| Step: 7
Training loss: 0.14841758443845643
Validation loss: 2.518610097377419

Epoch: 5| Step: 8
Training loss: 0.16225698943064595
Validation loss: 2.4854232904416613

Epoch: 5| Step: 9
Training loss: 0.21356588416283165
Validation loss: 2.4678469203332996

Epoch: 5| Step: 10
Training loss: 0.12616050952470134
Validation loss: 2.464264825186199

Epoch: 503| Step: 0
Training loss: 0.2329480442283934
Validation loss: 2.4243850535537512

Epoch: 5| Step: 1
Training loss: 0.1980648374970279
Validation loss: 2.4045491263382965

Epoch: 5| Step: 2
Training loss: 0.21417830321194903
Validation loss: 2.43139004770968

Epoch: 5| Step: 3
Training loss: 0.24014414666824177
Validation loss: 2.4792032708760763

Epoch: 5| Step: 4
Training loss: 0.20002292561265356
Validation loss: 2.48601756245755

Epoch: 5| Step: 5
Training loss: 0.1428990410401013
Validation loss: 2.4876951843434867

Epoch: 5| Step: 6
Training loss: 0.12381718223187327
Validation loss: 2.4557569419981187

Epoch: 5| Step: 7
Training loss: 0.1327900587083704
Validation loss: 2.4919318601249603

Epoch: 5| Step: 8
Training loss: 0.1525957212346186
Validation loss: 2.4812690666559085

Epoch: 5| Step: 9
Training loss: 0.1649962318867961
Validation loss: 2.5020504264665258

Epoch: 5| Step: 10
Training loss: 0.14565858773878518
Validation loss: 2.52747549388913

Epoch: 504| Step: 0
Training loss: 0.27490453905546897
Validation loss: 2.5162760206109853

Epoch: 5| Step: 1
Training loss: 0.09629625811975785
Validation loss: 2.5007207467314574

Epoch: 5| Step: 2
Training loss: 0.19427301356206117
Validation loss: 2.5065172441397814

Epoch: 5| Step: 3
Training loss: 0.20735025121159878
Validation loss: 2.4878003382735416

Epoch: 5| Step: 4
Training loss: 0.15187731276034544
Validation loss: 2.451631349292891

Epoch: 5| Step: 5
Training loss: 0.1747536931166106
Validation loss: 2.4149274504730047

Epoch: 5| Step: 6
Training loss: 0.12541791226818258
Validation loss: 2.4201224462623703

Epoch: 5| Step: 7
Training loss: 0.16138653863783473
Validation loss: 2.4103046035919644

Epoch: 5| Step: 8
Training loss: 0.1417466965472075
Validation loss: 2.4124919108262044

Epoch: 5| Step: 9
Training loss: 0.22189335881425368
Validation loss: 2.3586635058737118

Epoch: 5| Step: 10
Training loss: 0.12972954619990115
Validation loss: 2.419520435716154

Epoch: 505| Step: 0
Training loss: 0.16595357969649352
Validation loss: 2.4017111079224045

Epoch: 5| Step: 1
Training loss: 0.24258232235924443
Validation loss: 2.4281580756246863

Epoch: 5| Step: 2
Training loss: 0.20024076736611587
Validation loss: 2.3937186097589485

Epoch: 5| Step: 3
Training loss: 0.080654575769118
Validation loss: 2.3635647988652493

Epoch: 5| Step: 4
Training loss: 0.16939703687136223
Validation loss: 2.4026737285643645

Epoch: 5| Step: 5
Training loss: 0.15009867209275035
Validation loss: 2.418905134483934

Epoch: 5| Step: 6
Training loss: 0.09964240685835239
Validation loss: 2.4443707849672713

Epoch: 5| Step: 7
Training loss: 0.15618727140116057
Validation loss: 2.415670614665276

Epoch: 5| Step: 8
Training loss: 0.206994764243935
Validation loss: 2.466344934726134

Epoch: 5| Step: 9
Training loss: 0.14936082801666783
Validation loss: 2.43053439799611

Epoch: 5| Step: 10
Training loss: 0.16991337941296536
Validation loss: 2.4558992893384994

Epoch: 506| Step: 0
Training loss: 0.1941055772795693
Validation loss: 2.445466451193084

Epoch: 5| Step: 1
Training loss: 0.2022630486410824
Validation loss: 2.437151558715935

Epoch: 5| Step: 2
Training loss: 0.10851478776135035
Validation loss: 2.426808776142064

Epoch: 5| Step: 3
Training loss: 0.10466708937992902
Validation loss: 2.451609310280823

Epoch: 5| Step: 4
Training loss: 0.16537533309618965
Validation loss: 2.428408489707663

Epoch: 5| Step: 5
Training loss: 0.19295059690148364
Validation loss: 2.446211915927082

Epoch: 5| Step: 6
Training loss: 0.2237117994320842
Validation loss: 2.420988019833296

Epoch: 5| Step: 7
Training loss: 0.16545158385440653
Validation loss: 2.428616813850171

Epoch: 5| Step: 8
Training loss: 0.2018120680733811
Validation loss: 2.4795535499137116

Epoch: 5| Step: 9
Training loss: 0.13593247338571057
Validation loss: 2.4375607730387614

Epoch: 5| Step: 10
Training loss: 0.14280469085285988
Validation loss: 2.4766800438699583

Epoch: 507| Step: 0
Training loss: 0.14229446438286536
Validation loss: 2.4702887323807894

Epoch: 5| Step: 1
Training loss: 0.1542917624966551
Validation loss: 2.444985312353924

Epoch: 5| Step: 2
Training loss: 0.2590080773970084
Validation loss: 2.4221898927779884

Epoch: 5| Step: 3
Training loss: 0.1890177985223496
Validation loss: 2.4535168810972237

Epoch: 5| Step: 4
Training loss: 0.1374401271034684
Validation loss: 2.449537533299843

Epoch: 5| Step: 5
Training loss: 0.10870632487389721
Validation loss: 2.412821943345982

Epoch: 5| Step: 6
Training loss: 0.13510947658463973
Validation loss: 2.403795287636111

Epoch: 5| Step: 7
Training loss: 0.22728495673308302
Validation loss: 2.3993546551847658

Epoch: 5| Step: 8
Training loss: 0.21152630501984665
Validation loss: 2.459067915017734

Epoch: 5| Step: 9
Training loss: 0.12979974456614662
Validation loss: 2.444225476576395

Epoch: 5| Step: 10
Training loss: 0.2430599479997437
Validation loss: 2.4834543984730506

Epoch: 508| Step: 0
Training loss: 0.18257913856078106
Validation loss: 2.5246652313609346

Epoch: 5| Step: 1
Training loss: 0.12644464928067428
Validation loss: 2.5255195422283836

Epoch: 5| Step: 2
Training loss: 0.13949752202405336
Validation loss: 2.5399773465836266

Epoch: 5| Step: 3
Training loss: 0.15076621331459786
Validation loss: 2.5344197237204242

Epoch: 5| Step: 4
Training loss: 0.22358076664345564
Validation loss: 2.5383307784137825

Epoch: 5| Step: 5
Training loss: 0.13621266566614182
Validation loss: 2.506762073776533

Epoch: 5| Step: 6
Training loss: 0.1470240886334689
Validation loss: 2.502280906270333

Epoch: 5| Step: 7
Training loss: 0.1378192343980261
Validation loss: 2.517608563730722

Epoch: 5| Step: 8
Training loss: 0.23527353029915873
Validation loss: 2.459324253948926

Epoch: 5| Step: 9
Training loss: 0.16859053145545705
Validation loss: 2.455128954994264

Epoch: 5| Step: 10
Training loss: 0.22241293009869326
Validation loss: 2.4303013556628215

Epoch: 509| Step: 0
Training loss: 0.14340532408419746
Validation loss: 2.40434142780417

Epoch: 5| Step: 1
Training loss: 0.29269185014156074
Validation loss: 2.423601881438772

Epoch: 5| Step: 2
Training loss: 0.1663914073897398
Validation loss: 2.4190717152233905

Epoch: 5| Step: 3
Training loss: 0.09339648889689077
Validation loss: 2.4576137470524966

Epoch: 5| Step: 4
Training loss: 0.18036907961164375
Validation loss: 2.464500484340122

Epoch: 5| Step: 5
Training loss: 0.14046483720754846
Validation loss: 2.434655531564909

Epoch: 5| Step: 6
Training loss: 0.22440532039815803
Validation loss: 2.4721948658169057

Epoch: 5| Step: 7
Training loss: 0.1168700488145898
Validation loss: 2.4277305270032934

Epoch: 5| Step: 8
Training loss: 0.12484994464730963
Validation loss: 2.4386733307210355

Epoch: 5| Step: 9
Training loss: 0.10278728957219035
Validation loss: 2.423754326194157

Epoch: 5| Step: 10
Training loss: 0.11756774089747832
Validation loss: 2.397862248793817

Epoch: 510| Step: 0
Training loss: 0.16720425931764835
Validation loss: 2.422628064792926

Epoch: 5| Step: 1
Training loss: 0.17612002364594642
Validation loss: 2.4106076260078546

Epoch: 5| Step: 2
Training loss: 0.2321118362563331
Validation loss: 2.4349566138126515

Epoch: 5| Step: 3
Training loss: 0.09724522399666628
Validation loss: 2.433180902044242

Epoch: 5| Step: 4
Training loss: 0.11778120407509458
Validation loss: 2.424732997045413

Epoch: 5| Step: 5
Training loss: 0.13317023511676065
Validation loss: 2.4446197500090463

Epoch: 5| Step: 6
Training loss: 0.24179870407571272
Validation loss: 2.447645002557866

Epoch: 5| Step: 7
Training loss: 0.14580494030937333
Validation loss: 2.4827415434950226

Epoch: 5| Step: 8
Training loss: 0.16065356336438583
Validation loss: 2.45424408210713

Epoch: 5| Step: 9
Training loss: 0.10032952133790882
Validation loss: 2.462502807603927

Epoch: 5| Step: 10
Training loss: 0.2131828874269633
Validation loss: 2.4492261356290093

Epoch: 511| Step: 0
Training loss: 0.1432380232818144
Validation loss: 2.4928446239726463

Epoch: 5| Step: 1
Training loss: 0.19106076649112463
Validation loss: 2.4678525486358533

Epoch: 5| Step: 2
Training loss: 0.12701848621691084
Validation loss: 2.5085649373279684

Epoch: 5| Step: 3
Training loss: 0.15767533365443867
Validation loss: 2.4993274542922874

Epoch: 5| Step: 4
Training loss: 0.07658625034850913
Validation loss: 2.4972233262577626

Epoch: 5| Step: 5
Training loss: 0.22877287445452413
Validation loss: 2.4861601900323747

Epoch: 5| Step: 6
Training loss: 0.1462009166918892
Validation loss: 2.433719664211428

Epoch: 5| Step: 7
Training loss: 0.20830394815790806
Validation loss: 2.444641662878427

Epoch: 5| Step: 8
Training loss: 0.1536189226786722
Validation loss: 2.446029222041259

Epoch: 5| Step: 9
Training loss: 0.21445531409697557
Validation loss: 2.4102701740680184

Epoch: 5| Step: 10
Training loss: 0.12484622228368311
Validation loss: 2.4469162725400313

Epoch: 512| Step: 0
Training loss: 0.2634499498957313
Validation loss: 2.4065936764310725

Epoch: 5| Step: 1
Training loss: 0.18063264522080302
Validation loss: 2.415197966451733

Epoch: 5| Step: 2
Training loss: 0.14458762821992557
Validation loss: 2.4162951648160114

Epoch: 5| Step: 3
Training loss: 0.09853737056425585
Validation loss: 2.415140782699003

Epoch: 5| Step: 4
Training loss: 0.14860390445938876
Validation loss: 2.445102575572821

Epoch: 5| Step: 5
Training loss: 0.19452367752534103
Validation loss: 2.444699601622094

Epoch: 5| Step: 6
Training loss: 0.1745303414627648
Validation loss: 2.477369559009068

Epoch: 5| Step: 7
Training loss: 0.10075202673454291
Validation loss: 2.485122373217947

Epoch: 5| Step: 8
Training loss: 0.10308718638297813
Validation loss: 2.488576397505604

Epoch: 5| Step: 9
Training loss: 0.09636277942139441
Validation loss: 2.496555344551982

Epoch: 5| Step: 10
Training loss: 0.13383927760332767
Validation loss: 2.487294446540812

Epoch: 513| Step: 0
Training loss: 0.18254681623608604
Validation loss: 2.4874726070372213

Epoch: 5| Step: 1
Training loss: 0.13612472367849757
Validation loss: 2.4861342365124823

Epoch: 5| Step: 2
Training loss: 0.20410054037759914
Validation loss: 2.4338663713851107

Epoch: 5| Step: 3
Training loss: 0.237957382544302
Validation loss: 2.4058219785751374

Epoch: 5| Step: 4
Training loss: 0.17529778221555936
Validation loss: 2.422107640107357

Epoch: 5| Step: 5
Training loss: 0.15739166286955295
Validation loss: 2.3909899648635915

Epoch: 5| Step: 6
Training loss: 0.14130050620218182
Validation loss: 2.4045230659817256

Epoch: 5| Step: 7
Training loss: 0.1108514510811567
Validation loss: 2.3754007943636557

Epoch: 5| Step: 8
Training loss: 0.16765439758628392
Validation loss: 2.406598977143809

Epoch: 5| Step: 9
Training loss: 0.1448331463583576
Validation loss: 2.455122774378785

Epoch: 5| Step: 10
Training loss: 0.2113669756365003
Validation loss: 2.4185175567012567

Epoch: 514| Step: 0
Training loss: 0.23708174480102706
Validation loss: 2.443336200595194

Epoch: 5| Step: 1
Training loss: 0.20865217883560502
Validation loss: 2.4989650306761866

Epoch: 5| Step: 2
Training loss: 0.12946301932960472
Validation loss: 2.4788786432220618

Epoch: 5| Step: 3
Training loss: 0.13798011923028272
Validation loss: 2.517407977203407

Epoch: 5| Step: 4
Training loss: 0.13678790114775427
Validation loss: 2.4865683064767103

Epoch: 5| Step: 5
Training loss: 0.10737807941656172
Validation loss: 2.4982726446404384

Epoch: 5| Step: 6
Training loss: 0.09974590929685456
Validation loss: 2.464684253401957

Epoch: 5| Step: 7
Training loss: 0.22218909529959632
Validation loss: 2.4739292449190984

Epoch: 5| Step: 8
Training loss: 0.20086737614960665
Validation loss: 2.449147546516286

Epoch: 5| Step: 9
Training loss: 0.14500041797183075
Validation loss: 2.4448535578543082

Epoch: 5| Step: 10
Training loss: 0.17631098082914629
Validation loss: 2.4577493371954566

Epoch: 515| Step: 0
Training loss: 0.14345019942934914
Validation loss: 2.4629542995943066

Epoch: 5| Step: 1
Training loss: 0.19704025916512877
Validation loss: 2.4754798846541557

Epoch: 5| Step: 2
Training loss: 0.16373883973739953
Validation loss: 2.4644298966267

Epoch: 5| Step: 3
Training loss: 0.10028221979085397
Validation loss: 2.4616965763114775

Epoch: 5| Step: 4
Training loss: 0.1407766385545689
Validation loss: 2.515599386137931

Epoch: 5| Step: 5
Training loss: 0.13277876649932474
Validation loss: 2.538673305168832

Epoch: 5| Step: 6
Training loss: 0.12304833577817875
Validation loss: 2.5350537996359166

Epoch: 5| Step: 7
Training loss: 0.20052294090121223
Validation loss: 2.5043744127291445

Epoch: 5| Step: 8
Training loss: 0.186845930032857
Validation loss: 2.481207497661682

Epoch: 5| Step: 9
Training loss: 0.20337145782286298
Validation loss: 2.443461463783569

Epoch: 5| Step: 10
Training loss: 0.1549412394669026
Validation loss: 2.4297147707844187

Epoch: 516| Step: 0
Training loss: 0.20876192571358765
Validation loss: 2.3911699095865844

Epoch: 5| Step: 1
Training loss: 0.18582662273772596
Validation loss: 2.3743350701677914

Epoch: 5| Step: 2
Training loss: 0.1524005869454091
Validation loss: 2.371935503752156

Epoch: 5| Step: 3
Training loss: 0.14538101457649166
Validation loss: 2.4013140291276636

Epoch: 5| Step: 4
Training loss: 0.13369356352888628
Validation loss: 2.4200720219008316

Epoch: 5| Step: 5
Training loss: 0.1435827824614218
Validation loss: 2.4518262493591068

Epoch: 5| Step: 6
Training loss: 0.18399763322751492
Validation loss: 2.4360937832443827

Epoch: 5| Step: 7
Training loss: 0.2934638354231462
Validation loss: 2.484317200227549

Epoch: 5| Step: 8
Training loss: 0.21068003624511536
Validation loss: 2.4583284245214854

Epoch: 5| Step: 9
Training loss: 0.1361149534006981
Validation loss: 2.423614226772336

Epoch: 5| Step: 10
Training loss: 0.1120563871987085
Validation loss: 2.431703694897815

Epoch: 517| Step: 0
Training loss: 0.16031394150106312
Validation loss: 2.427188769775555

Epoch: 5| Step: 1
Training loss: 0.15028056539076964
Validation loss: 2.455713724965085

Epoch: 5| Step: 2
Training loss: 0.21023718824598797
Validation loss: 2.4376065741274564

Epoch: 5| Step: 3
Training loss: 0.1752904078899543
Validation loss: 2.408646300885923

Epoch: 5| Step: 4
Training loss: 0.15790011976215176
Validation loss: 2.4231355327460116

Epoch: 5| Step: 5
Training loss: 0.13461570417122587
Validation loss: 2.387453231284726

Epoch: 5| Step: 6
Training loss: 0.14709342227848227
Validation loss: 2.4011243349019282

Epoch: 5| Step: 7
Training loss: 0.0975859770658329
Validation loss: 2.419874577019208

Epoch: 5| Step: 8
Training loss: 0.09122029283074158
Validation loss: 2.387788352224772

Epoch: 5| Step: 9
Training loss: 0.2141776596549404
Validation loss: 2.429997956929052

Epoch: 5| Step: 10
Training loss: 0.22747569368279508
Validation loss: 2.439948948671228

Epoch: 518| Step: 0
Training loss: 0.20994306976229962
Validation loss: 2.4150589640151954

Epoch: 5| Step: 1
Training loss: 0.20985262538861857
Validation loss: 2.40741263658881

Epoch: 5| Step: 2
Training loss: 0.10646386378608284
Validation loss: 2.430348026148819

Epoch: 5| Step: 3
Training loss: 0.15507641774542189
Validation loss: 2.4402978561745465

Epoch: 5| Step: 4
Training loss: 0.12837803150728053
Validation loss: 2.396431543178868

Epoch: 5| Step: 5
Training loss: 0.10777991189344475
Validation loss: 2.4218661612125447

Epoch: 5| Step: 6
Training loss: 0.15164629522233963
Validation loss: 2.421252330134496

Epoch: 5| Step: 7
Training loss: 0.14717277260820583
Validation loss: 2.436592132811932

Epoch: 5| Step: 8
Training loss: 0.2427861597804762
Validation loss: 2.453875275747199

Epoch: 5| Step: 9
Training loss: 0.21030707991419081
Validation loss: 2.43698524128048

Epoch: 5| Step: 10
Training loss: 0.15465535398213312
Validation loss: 2.4308283255985805

Epoch: 519| Step: 0
Training loss: 0.14485120798352225
Validation loss: 2.4391076366219124

Epoch: 5| Step: 1
Training loss: 0.2167411251385145
Validation loss: 2.4619547673668047

Epoch: 5| Step: 2
Training loss: 0.15305841759720074
Validation loss: 2.4367041580958513

Epoch: 5| Step: 3
Training loss: 0.171885403404962
Validation loss: 2.502803262443161

Epoch: 5| Step: 4
Training loss: 0.1277090018266831
Validation loss: 2.5006655729989995

Epoch: 5| Step: 5
Training loss: 0.17007332662315428
Validation loss: 2.463648708272454

Epoch: 5| Step: 6
Training loss: 0.25035216442267333
Validation loss: 2.4395267336845508

Epoch: 5| Step: 7
Training loss: 0.15442639962399343
Validation loss: 2.4128987937975874

Epoch: 5| Step: 8
Training loss: 0.15327323506677956
Validation loss: 2.436547801462538

Epoch: 5| Step: 9
Training loss: 0.13780466431553148
Validation loss: 2.401982443153373

Epoch: 5| Step: 10
Training loss: 0.19099974771053568
Validation loss: 2.3681168393161895

Epoch: 520| Step: 0
Training loss: 0.1725756064179824
Validation loss: 2.405117604269422

Epoch: 5| Step: 1
Training loss: 0.24179432856831976
Validation loss: 2.3987111260904004

Epoch: 5| Step: 2
Training loss: 0.08940884814508986
Validation loss: 2.458342196735514

Epoch: 5| Step: 3
Training loss: 0.1394394130537082
Validation loss: 2.432423580241427

Epoch: 5| Step: 4
Training loss: 0.2138697306163902
Validation loss: 2.4414715150046664

Epoch: 5| Step: 5
Training loss: 0.08443317152028486
Validation loss: 2.4106810286255445

Epoch: 5| Step: 6
Training loss: 0.16331357544691968
Validation loss: 2.432115567714207

Epoch: 5| Step: 7
Training loss: 0.16516206322384655
Validation loss: 2.4149059931755845

Epoch: 5| Step: 8
Training loss: 0.1596856238727134
Validation loss: 2.4091372289971122

Epoch: 5| Step: 9
Training loss: 0.22315078325924778
Validation loss: 2.4187416992062025

Epoch: 5| Step: 10
Training loss: 0.19037959100105567
Validation loss: 2.4087509584585947

Epoch: 521| Step: 0
Training loss: 0.08415911482854721
Validation loss: 2.4267156731696375

Epoch: 5| Step: 1
Training loss: 0.18023351969224555
Validation loss: 2.4430968346508197

Epoch: 5| Step: 2
Training loss: 0.1516339320534015
Validation loss: 2.4820389509766674

Epoch: 5| Step: 3
Training loss: 0.1518604363613285
Validation loss: 2.4944808951024697

Epoch: 5| Step: 4
Training loss: 0.10110661084354251
Validation loss: 2.446693943082652

Epoch: 5| Step: 5
Training loss: 0.15765697492313732
Validation loss: 2.460524979651071

Epoch: 5| Step: 6
Training loss: 0.14233873467345803
Validation loss: 2.493786856979588

Epoch: 5| Step: 7
Training loss: 0.11666434656827836
Validation loss: 2.4637379557153767

Epoch: 5| Step: 8
Training loss: 0.09706769014803777
Validation loss: 2.46935654906295

Epoch: 5| Step: 9
Training loss: 0.27455985109721714
Validation loss: 2.4428617017906658

Epoch: 5| Step: 10
Training loss: 0.2006111106937117
Validation loss: 2.4282293830687465

Epoch: 522| Step: 0
Training loss: 0.20585159489734442
Validation loss: 2.41916539267424

Epoch: 5| Step: 1
Training loss: 0.1004564970889091
Validation loss: 2.457718344868586

Epoch: 5| Step: 2
Training loss: 0.16642702402815493
Validation loss: 2.4525089089871943

Epoch: 5| Step: 3
Training loss: 0.13077551731183415
Validation loss: 2.461940795124863

Epoch: 5| Step: 4
Training loss: 0.15149685013009806
Validation loss: 2.45210005698495

Epoch: 5| Step: 5
Training loss: 0.20109075929363684
Validation loss: 2.4577173841753104

Epoch: 5| Step: 6
Training loss: 0.12470567593476567
Validation loss: 2.4717581073160124

Epoch: 5| Step: 7
Training loss: 0.1502323680352838
Validation loss: 2.412704752864514

Epoch: 5| Step: 8
Training loss: 0.12533530325093942
Validation loss: 2.4437308300718215

Epoch: 5| Step: 9
Training loss: 0.15311513523517317
Validation loss: 2.451884545301089

Epoch: 5| Step: 10
Training loss: 0.26222936439239
Validation loss: 2.4462587644152247

Epoch: 523| Step: 0
Training loss: 0.13031160947783563
Validation loss: 2.448002157679918

Epoch: 5| Step: 1
Training loss: 0.11996942829204646
Validation loss: 2.4198911339602107

Epoch: 5| Step: 2
Training loss: 0.18575449921792472
Validation loss: 2.437982130262758

Epoch: 5| Step: 3
Training loss: 0.11004850667983895
Validation loss: 2.437971420283837

Epoch: 5| Step: 4
Training loss: 0.1816981644914048
Validation loss: 2.432816363310177

Epoch: 5| Step: 5
Training loss: 0.12920326636008297
Validation loss: 2.425256475627522

Epoch: 5| Step: 6
Training loss: 0.1999019799837158
Validation loss: 2.4146551263712626

Epoch: 5| Step: 7
Training loss: 0.20387216845872672
Validation loss: 2.3894259798275086

Epoch: 5| Step: 8
Training loss: 0.18076874045939217
Validation loss: 2.410165122158053

Epoch: 5| Step: 9
Training loss: 0.13133450977660627
Validation loss: 2.4374606999925206

Epoch: 5| Step: 10
Training loss: 0.1848672970165842
Validation loss: 2.4126949103623945

Epoch: 524| Step: 0
Training loss: 0.25409717717297303
Validation loss: 2.4240002450841

Epoch: 5| Step: 1
Training loss: 0.11795760474703712
Validation loss: 2.443519358119177

Epoch: 5| Step: 2
Training loss: 0.1144786111427981
Validation loss: 2.458215466303916

Epoch: 5| Step: 3
Training loss: 0.1443644024522344
Validation loss: 2.4027312244975705

Epoch: 5| Step: 4
Training loss: 0.12557452017942877
Validation loss: 2.3955891495901915

Epoch: 5| Step: 5
Training loss: 0.2007497321153186
Validation loss: 2.426608864241641

Epoch: 5| Step: 6
Training loss: 0.13423377977624892
Validation loss: 2.384084988672572

Epoch: 5| Step: 7
Training loss: 0.15991114841783965
Validation loss: 2.4005247622110146

Epoch: 5| Step: 8
Training loss: 0.17924191332709108
Validation loss: 2.409713207922801

Epoch: 5| Step: 9
Training loss: 0.13974064003934314
Validation loss: 2.437287693963962

Epoch: 5| Step: 10
Training loss: 0.1289703469876575
Validation loss: 2.451606524542286

Epoch: 525| Step: 0
Training loss: 0.16380742657674188
Validation loss: 2.471244123273247

Epoch: 5| Step: 1
Training loss: 0.1928528885760042
Validation loss: 2.436402312183352

Epoch: 5| Step: 2
Training loss: 0.115741776444075
Validation loss: 2.471696668057273

Epoch: 5| Step: 3
Training loss: 0.12071746768734483
Validation loss: 2.4633569291507893

Epoch: 5| Step: 4
Training loss: 0.11527094018416305
Validation loss: 2.4689436452758136

Epoch: 5| Step: 5
Training loss: 0.10131893387597146
Validation loss: 2.4548631880531815

Epoch: 5| Step: 6
Training loss: 0.14537191765667185
Validation loss: 2.4407354242615824

Epoch: 5| Step: 7
Training loss: 0.1747268311575025
Validation loss: 2.43286612415602

Epoch: 5| Step: 8
Training loss: 0.26758422287724115
Validation loss: 2.457141998083764

Epoch: 5| Step: 9
Training loss: 0.20379599370972792
Validation loss: 2.442809229148285

Epoch: 5| Step: 10
Training loss: 0.14977013165773032
Validation loss: 2.4267197129315834

Epoch: 526| Step: 0
Training loss: 0.10963615676225355
Validation loss: 2.4172670667352913

Epoch: 5| Step: 1
Training loss: 0.162192007628775
Validation loss: 2.422647531480504

Epoch: 5| Step: 2
Training loss: 0.21031816832001823
Validation loss: 2.4336847653590796

Epoch: 5| Step: 3
Training loss: 0.1675402198283699
Validation loss: 2.452711419660903

Epoch: 5| Step: 4
Training loss: 0.15368127548795918
Validation loss: 2.488009994984584

Epoch: 5| Step: 5
Training loss: 0.11403922013257965
Validation loss: 2.447835930247997

Epoch: 5| Step: 6
Training loss: 0.18094742693377378
Validation loss: 2.5013271029315365

Epoch: 5| Step: 7
Training loss: 0.19581000860451403
Validation loss: 2.4713260206389327

Epoch: 5| Step: 8
Training loss: 0.17348406527434115
Validation loss: 2.4732777167160362

Epoch: 5| Step: 9
Training loss: 0.1903687795410514
Validation loss: 2.471221083801045

Epoch: 5| Step: 10
Training loss: 0.08550209589182343
Validation loss: 2.475502149728624

Epoch: 527| Step: 0
Training loss: 0.18657107518806437
Validation loss: 2.4856452328555236

Epoch: 5| Step: 1
Training loss: 0.10069801049750805
Validation loss: 2.49330493662405

Epoch: 5| Step: 2
Training loss: 0.13814152458000703
Validation loss: 2.508056514260198

Epoch: 5| Step: 3
Training loss: 0.16378374487307382
Validation loss: 2.4788290221124707

Epoch: 5| Step: 4
Training loss: 0.15788717863539287
Validation loss: 2.4482640945180436

Epoch: 5| Step: 5
Training loss: 0.12775912088897434
Validation loss: 2.470482403880993

Epoch: 5| Step: 6
Training loss: 0.17388527712866542
Validation loss: 2.4727147982257716

Epoch: 5| Step: 7
Training loss: 0.08529170641391917
Validation loss: 2.4831473062680716

Epoch: 5| Step: 8
Training loss: 0.24343697426657168
Validation loss: 2.4469051815347616

Epoch: 5| Step: 9
Training loss: 0.17901392823845483
Validation loss: 2.411717940254163

Epoch: 5| Step: 10
Training loss: 0.1834918002874356
Validation loss: 2.4023202621014725

Epoch: 528| Step: 0
Training loss: 0.14827674392590529
Validation loss: 2.4301222355665435

Epoch: 5| Step: 1
Training loss: 0.10269820715276994
Validation loss: 2.443890677680666

Epoch: 5| Step: 2
Training loss: 0.10808478763218216
Validation loss: 2.4592238332934238

Epoch: 5| Step: 3
Training loss: 0.11957532110756323
Validation loss: 2.4908909181235055

Epoch: 5| Step: 4
Training loss: 0.2025542125719142
Validation loss: 2.4868676075812104

Epoch: 5| Step: 5
Training loss: 0.20003973335223646
Validation loss: 2.4907763648277816

Epoch: 5| Step: 6
Training loss: 0.18996870536069477
Validation loss: 2.537690448711418

Epoch: 5| Step: 7
Training loss: 0.12327458867084891
Validation loss: 2.4937222672320902

Epoch: 5| Step: 8
Training loss: 0.2202160448265732
Validation loss: 2.5211338520713618

Epoch: 5| Step: 9
Training loss: 0.1345879447691222
Validation loss: 2.5320378835422077

Epoch: 5| Step: 10
Training loss: 0.12499791009467175
Validation loss: 2.5240343772743654

Epoch: 529| Step: 0
Training loss: 0.167285939675193
Validation loss: 2.519257982663537

Epoch: 5| Step: 1
Training loss: 0.1071988391300276
Validation loss: 2.4890109057265914

Epoch: 5| Step: 2
Training loss: 0.09403444887350856
Validation loss: 2.4789200054533596

Epoch: 5| Step: 3
Training loss: 0.1532084852950918
Validation loss: 2.4614745445256263

Epoch: 5| Step: 4
Training loss: 0.12350717989204389
Validation loss: 2.427333194849881

Epoch: 5| Step: 5
Training loss: 0.11122329695491637
Validation loss: 2.4383663145159087

Epoch: 5| Step: 6
Training loss: 0.18438960114547073
Validation loss: 2.3828456565020026

Epoch: 5| Step: 7
Training loss: 0.1887380831316509
Validation loss: 2.4081083158190895

Epoch: 5| Step: 8
Training loss: 0.1773100493251314
Validation loss: 2.4021440635251334

Epoch: 5| Step: 9
Training loss: 0.13302275199845692
Validation loss: 2.40280410060168

Epoch: 5| Step: 10
Training loss: 0.16532936747478594
Validation loss: 2.394727006515408

Epoch: 530| Step: 0
Training loss: 0.19010124247840743
Validation loss: 2.4324956342310617

Epoch: 5| Step: 1
Training loss: 0.11466007254860021
Validation loss: 2.4314613647515704

Epoch: 5| Step: 2
Training loss: 0.1936099230558661
Validation loss: 2.4433022889950147

Epoch: 5| Step: 3
Training loss: 0.16875020375945893
Validation loss: 2.452327308837105

Epoch: 5| Step: 4
Training loss: 0.16408799177762887
Validation loss: 2.440435583878649

Epoch: 5| Step: 5
Training loss: 0.08088149387869513
Validation loss: 2.416962906357743

Epoch: 5| Step: 6
Training loss: 0.09045127009646148
Validation loss: 2.430986909302262

Epoch: 5| Step: 7
Training loss: 0.18439782373143326
Validation loss: 2.4540444714829843

Epoch: 5| Step: 8
Training loss: 0.09757636617659006
Validation loss: 2.4340915803128214

Epoch: 5| Step: 9
Training loss: 0.14608138281959343
Validation loss: 2.449167034272225

Epoch: 5| Step: 10
Training loss: 0.07174266898874203
Validation loss: 2.4399434724460005

Epoch: 531| Step: 0
Training loss: 0.16905357221803774
Validation loss: 2.4267271121015583

Epoch: 5| Step: 1
Training loss: 0.0961603753630976
Validation loss: 2.433448710412495

Epoch: 5| Step: 2
Training loss: 0.0973940954546312
Validation loss: 2.4165409410450795

Epoch: 5| Step: 3
Training loss: 0.24748009033270532
Validation loss: 2.4321021236968337

Epoch: 5| Step: 4
Training loss: 0.11304841283715777
Validation loss: 2.4385847250132815

Epoch: 5| Step: 5
Training loss: 0.13207509988650679
Validation loss: 2.4770785971111846

Epoch: 5| Step: 6
Training loss: 0.09906498020659373
Validation loss: 2.4438664440934947

Epoch: 5| Step: 7
Training loss: 0.1934743982229056
Validation loss: 2.468644377303998

Epoch: 5| Step: 8
Training loss: 0.12277396530586512
Validation loss: 2.496103271351185

Epoch: 5| Step: 9
Training loss: 0.07205348516195453
Validation loss: 2.458669647465815

Epoch: 5| Step: 10
Training loss: 0.13118314544671106
Validation loss: 2.465145486481496

Epoch: 532| Step: 0
Training loss: 0.14648375193145485
Validation loss: 2.4648303100184155

Epoch: 5| Step: 1
Training loss: 0.12039754295648009
Validation loss: 2.4495246571739586

Epoch: 5| Step: 2
Training loss: 0.24076918641701353
Validation loss: 2.4436643685908326

Epoch: 5| Step: 3
Training loss: 0.1998459722053866
Validation loss: 2.450368812280221

Epoch: 5| Step: 4
Training loss: 0.08627360626866751
Validation loss: 2.4040184769813675

Epoch: 5| Step: 5
Training loss: 0.11681462411393287
Validation loss: 2.405502789295597

Epoch: 5| Step: 6
Training loss: 0.09598256692048111
Validation loss: 2.408063882212223

Epoch: 5| Step: 7
Training loss: 0.1349640988036251
Validation loss: 2.4099849665925226

Epoch: 5| Step: 8
Training loss: 0.10247735028386885
Validation loss: 2.4371325024142627

Epoch: 5| Step: 9
Training loss: 0.19463706528194508
Validation loss: 2.4768481092638015

Epoch: 5| Step: 10
Training loss: 0.11105099282440295
Validation loss: 2.483833353521964

Epoch: 533| Step: 0
Training loss: 0.09617255360157069
Validation loss: 2.4675213388914443

Epoch: 5| Step: 1
Training loss: 0.18226379226829226
Validation loss: 2.4874439128468895

Epoch: 5| Step: 2
Training loss: 0.1628583587963201
Validation loss: 2.5002055791191125

Epoch: 5| Step: 3
Training loss: 0.2448989458926114
Validation loss: 2.4798938914823316

Epoch: 5| Step: 4
Training loss: 0.13408505630136927
Validation loss: 2.436070031428416

Epoch: 5| Step: 5
Training loss: 0.12753481748330828
Validation loss: 2.4056641017592306

Epoch: 5| Step: 6
Training loss: 0.11866516075452331
Validation loss: 2.4042237594404585

Epoch: 5| Step: 7
Training loss: 0.18269950113150102
Validation loss: 2.413757226331718

Epoch: 5| Step: 8
Training loss: 0.14191890541337282
Validation loss: 2.395098026501224

Epoch: 5| Step: 9
Training loss: 0.08115691609360827
Validation loss: 2.4266509061202615

Epoch: 5| Step: 10
Training loss: 0.158643756461706
Validation loss: 2.434769876058506

Epoch: 534| Step: 0
Training loss: 0.10741219910479946
Validation loss: 2.4716310586624752

Epoch: 5| Step: 1
Training loss: 0.13935239129521212
Validation loss: 2.49087655756655

Epoch: 5| Step: 2
Training loss: 0.23697865227584067
Validation loss: 2.4738443922003155

Epoch: 5| Step: 3
Training loss: 0.07420161325477516
Validation loss: 2.519725543606587

Epoch: 5| Step: 4
Training loss: 0.20331812810686334
Validation loss: 2.516256465240604

Epoch: 5| Step: 5
Training loss: 0.10020331876864808
Validation loss: 2.5312821702572577

Epoch: 5| Step: 6
Training loss: 0.1511355072948617
Validation loss: 2.5066916912590895

Epoch: 5| Step: 7
Training loss: 0.11169570755246663
Validation loss: 2.5009497263940834

Epoch: 5| Step: 8
Training loss: 0.1312216540789954
Validation loss: 2.455408443729507

Epoch: 5| Step: 9
Training loss: 0.1479577417719918
Validation loss: 2.4389891386523472

Epoch: 5| Step: 10
Training loss: 0.19605964804859125
Validation loss: 2.40927642943672

Epoch: 535| Step: 0
Training loss: 0.07509152259630716
Validation loss: 2.403617208023723

Epoch: 5| Step: 1
Training loss: 0.15260306931340897
Validation loss: 2.362705640019023

Epoch: 5| Step: 2
Training loss: 0.14187770095220387
Validation loss: 2.3900804676290046

Epoch: 5| Step: 3
Training loss: 0.2548953086157541
Validation loss: 2.4083889623726837

Epoch: 5| Step: 4
Training loss: 0.13950606070704283
Validation loss: 2.4614353148460526

Epoch: 5| Step: 5
Training loss: 0.08328859300430089
Validation loss: 2.461022806064489

Epoch: 5| Step: 6
Training loss: 0.12781657977226624
Validation loss: 2.4861818516149365

Epoch: 5| Step: 7
Training loss: 0.13455237226117286
Validation loss: 2.5033507943717686

Epoch: 5| Step: 8
Training loss: 0.1989527965361091
Validation loss: 2.498859434518318

Epoch: 5| Step: 9
Training loss: 0.1002004142488551
Validation loss: 2.479350233085386

Epoch: 5| Step: 10
Training loss: 0.09187607696446948
Validation loss: 2.4346950795475863

Epoch: 536| Step: 0
Training loss: 0.09874148095179427
Validation loss: 2.4263569532113727

Epoch: 5| Step: 1
Training loss: 0.20168283995359504
Validation loss: 2.428063079538154

Epoch: 5| Step: 2
Training loss: 0.1527452923514418
Validation loss: 2.3974395104728443

Epoch: 5| Step: 3
Training loss: 0.17360764890768351
Validation loss: 2.384648039406893

Epoch: 5| Step: 4
Training loss: 0.15378718151427595
Validation loss: 2.418516225334645

Epoch: 5| Step: 5
Training loss: 0.18884278330097037
Validation loss: 2.472858172332883

Epoch: 5| Step: 6
Training loss: 0.13201926871115988
Validation loss: 2.4771771209011346

Epoch: 5| Step: 7
Training loss: 0.17386414122628593
Validation loss: 2.4805516894530864

Epoch: 5| Step: 8
Training loss: 0.13750636887972398
Validation loss: 2.484114287737031

Epoch: 5| Step: 9
Training loss: 0.0922519381850636
Validation loss: 2.518591119967565

Epoch: 5| Step: 10
Training loss: 0.18631438078662013
Validation loss: 2.4867240525368195

Epoch: 537| Step: 0
Training loss: 0.19171886800064397
Validation loss: 2.4886813746206107

Epoch: 5| Step: 1
Training loss: 0.11722660604296253
Validation loss: 2.5056131050541004

Epoch: 5| Step: 2
Training loss: 0.1834775475777489
Validation loss: 2.4604158509139107

Epoch: 5| Step: 3
Training loss: 0.14884020738792786
Validation loss: 2.465281560851499

Epoch: 5| Step: 4
Training loss: 0.06762637127787792
Validation loss: 2.457794681753567

Epoch: 5| Step: 5
Training loss: 0.10203403353727869
Validation loss: 2.4368494247336967

Epoch: 5| Step: 6
Training loss: 0.11746972590642624
Validation loss: 2.4516747804992387

Epoch: 5| Step: 7
Training loss: 0.12100898944893897
Validation loss: 2.400271014537956

Epoch: 5| Step: 8
Training loss: 0.2084995778706163
Validation loss: 2.4501143484278898

Epoch: 5| Step: 9
Training loss: 0.12417723288784531
Validation loss: 2.467997055946512

Epoch: 5| Step: 10
Training loss: 0.16834298295235248
Validation loss: 2.461737457645966

Epoch: 538| Step: 0
Training loss: 0.11612009456783512
Validation loss: 2.473716559434732

Epoch: 5| Step: 1
Training loss: 0.1302662903227762
Validation loss: 2.488442049738707

Epoch: 5| Step: 2
Training loss: 0.14927319512048345
Validation loss: 2.4578187670591065

Epoch: 5| Step: 3
Training loss: 0.09127587736970243
Validation loss: 2.450759860519729

Epoch: 5| Step: 4
Training loss: 0.14420284515206558
Validation loss: 2.4455014356040508

Epoch: 5| Step: 5
Training loss: 0.13546572462969375
Validation loss: 2.4442962785773954

Epoch: 5| Step: 6
Training loss: 0.10159217877670534
Validation loss: 2.427403912917411

Epoch: 5| Step: 7
Training loss: 0.199816620098445
Validation loss: 2.452062937705994

Epoch: 5| Step: 8
Training loss: 0.19898504686186
Validation loss: 2.4402058267717393

Epoch: 5| Step: 9
Training loss: 0.11945219807361858
Validation loss: 2.4216393781215193

Epoch: 5| Step: 10
Training loss: 0.1808521631833914
Validation loss: 2.4597753512345037

Epoch: 539| Step: 0
Training loss: 0.10178955081052837
Validation loss: 2.4343450736168393

Epoch: 5| Step: 1
Training loss: 0.09219251756429434
Validation loss: 2.476157620656966

Epoch: 5| Step: 2
Training loss: 0.25776482632597636
Validation loss: 2.467800987585886

Epoch: 5| Step: 3
Training loss: 0.10423313096696057
Validation loss: 2.4809893096016187

Epoch: 5| Step: 4
Training loss: 0.2164992187846011
Validation loss: 2.511959081717394

Epoch: 5| Step: 5
Training loss: 0.14513529386040394
Validation loss: 2.5191646348944654

Epoch: 5| Step: 6
Training loss: 0.14105846567938554
Validation loss: 2.503761213457701

Epoch: 5| Step: 7
Training loss: 0.09880710065308881
Validation loss: 2.49280987204813

Epoch: 5| Step: 8
Training loss: 0.07850560817116005
Validation loss: 2.4810183765501757

Epoch: 5| Step: 9
Training loss: 0.10282454033182424
Validation loss: 2.4600120636528904

Epoch: 5| Step: 10
Training loss: 0.09837874653545575
Validation loss: 2.453083268408854

Epoch: 540| Step: 0
Training loss: 0.1802963122468089
Validation loss: 2.457693766753424

Epoch: 5| Step: 1
Training loss: 0.1328745865155997
Validation loss: 2.438507401983972

Epoch: 5| Step: 2
Training loss: 0.08512506854653924
Validation loss: 2.423510566751842

Epoch: 5| Step: 3
Training loss: 0.09517335721503997
Validation loss: 2.447974260150575

Epoch: 5| Step: 4
Training loss: 0.14432284433860257
Validation loss: 2.438538754113349

Epoch: 5| Step: 5
Training loss: 0.1032589212626347
Validation loss: 2.4295938700172477

Epoch: 5| Step: 6
Training loss: 0.10835974664356222
Validation loss: 2.446912303839217

Epoch: 5| Step: 7
Training loss: 0.15484053767208616
Validation loss: 2.4299335384838407

Epoch: 5| Step: 8
Training loss: 0.1708979143407171
Validation loss: 2.4213025298052586

Epoch: 5| Step: 9
Training loss: 0.21416383140879072
Validation loss: 2.4296739998144212

Epoch: 5| Step: 10
Training loss: 0.22549263977622902
Validation loss: 2.4445234489010343

Epoch: 541| Step: 0
Training loss: 0.158810251190015
Validation loss: 2.470422848033548

Epoch: 5| Step: 1
Training loss: 0.11957528216463095
Validation loss: 2.493230216267514

Epoch: 5| Step: 2
Training loss: 0.25109200104897783
Validation loss: 2.5193071127501936

Epoch: 5| Step: 3
Training loss: 0.0691995858288492
Validation loss: 2.497084801188335

Epoch: 5| Step: 4
Training loss: 0.06871995513235724
Validation loss: 2.5092453220129394

Epoch: 5| Step: 5
Training loss: 0.1981651081138079
Validation loss: 2.4958920260340105

Epoch: 5| Step: 6
Training loss: 0.10789594945123648
Validation loss: 2.495195943352324

Epoch: 5| Step: 7
Training loss: 0.11899403637430275
Validation loss: 2.488974278207115

Epoch: 5| Step: 8
Training loss: 0.12172153619679567
Validation loss: 2.4949845569936673

Epoch: 5| Step: 9
Training loss: 0.17846457379544248
Validation loss: 2.443412050914991

Epoch: 5| Step: 10
Training loss: 0.19011384251326383
Validation loss: 2.4926416281201536

Epoch: 542| Step: 0
Training loss: 0.17289451561130048
Validation loss: 2.4935626541226967

Epoch: 5| Step: 1
Training loss: 0.131445568135482
Validation loss: 2.5013799601693587

Epoch: 5| Step: 2
Training loss: 0.15778550611155023
Validation loss: 2.4987639653081555

Epoch: 5| Step: 3
Training loss: 0.1345245097905344
Validation loss: 2.5359522102795715

Epoch: 5| Step: 4
Training loss: 0.12188550310849326
Validation loss: 2.522896472491763

Epoch: 5| Step: 5
Training loss: 0.20576338946112738
Validation loss: 2.481042903912627

Epoch: 5| Step: 6
Training loss: 0.13044795795761796
Validation loss: 2.463368890003861

Epoch: 5| Step: 7
Training loss: 0.18710034215224036
Validation loss: 2.4480507244265586

Epoch: 5| Step: 8
Training loss: 0.0736185259834487
Validation loss: 2.427455499296347

Epoch: 5| Step: 9
Training loss: 0.15850387055878698
Validation loss: 2.410168780145373

Epoch: 5| Step: 10
Training loss: 0.13494581808590572
Validation loss: 2.3873124668160948

Epoch: 543| Step: 0
Training loss: 0.10835350239358245
Validation loss: 2.4321625788957166

Epoch: 5| Step: 1
Training loss: 0.12856178063593343
Validation loss: 2.397871335362693

Epoch: 5| Step: 2
Training loss: 0.12537101728963237
Validation loss: 2.4561235181276158

Epoch: 5| Step: 3
Training loss: 0.1412095134446978
Validation loss: 2.4472353788131014

Epoch: 5| Step: 4
Training loss: 0.11113322078582906
Validation loss: 2.486836438989799

Epoch: 5| Step: 5
Training loss: 0.19961766899480493
Validation loss: 2.5324433740750627

Epoch: 5| Step: 6
Training loss: 0.1278526059372395
Validation loss: 2.5290885973521138

Epoch: 5| Step: 7
Training loss: 0.1417807727529907
Validation loss: 2.4859221043567006

Epoch: 5| Step: 8
Training loss: 0.23171503309688665
Validation loss: 2.508938580216153

Epoch: 5| Step: 9
Training loss: 0.11649153196835896
Validation loss: 2.4822491779642872

Epoch: 5| Step: 10
Training loss: 0.19152936090268127
Validation loss: 2.4398348321879393

Epoch: 544| Step: 0
Training loss: 0.11744063773158316
Validation loss: 2.457633964108514

Epoch: 5| Step: 1
Training loss: 0.0721393364513827
Validation loss: 2.4612216726142537

Epoch: 5| Step: 2
Training loss: 0.13965846072419208
Validation loss: 2.4441487158911928

Epoch: 5| Step: 3
Training loss: 0.11841209247926308
Validation loss: 2.4234837413178747

Epoch: 5| Step: 4
Training loss: 0.11629558733932364
Validation loss: 2.434110541408194

Epoch: 5| Step: 5
Training loss: 0.19591610145230406
Validation loss: 2.4270267241430905

Epoch: 5| Step: 6
Training loss: 0.10268599564059262
Validation loss: 2.449543792895722

Epoch: 5| Step: 7
Training loss: 0.2063073512015266
Validation loss: 2.4558741277568745

Epoch: 5| Step: 8
Training loss: 0.20419883235418684
Validation loss: 2.467866703479561

Epoch: 5| Step: 9
Training loss: 0.11150029739043002
Validation loss: 2.443920955821008

Epoch: 5| Step: 10
Training loss: 0.11574444384633419
Validation loss: 2.484136159112707

Epoch: 545| Step: 0
Training loss: 0.18879623184782798
Validation loss: 2.4540042705705156

Epoch: 5| Step: 1
Training loss: 0.1735383254037143
Validation loss: 2.468086385055311

Epoch: 5| Step: 2
Training loss: 0.0849185404829129
Validation loss: 2.419757690490629

Epoch: 5| Step: 3
Training loss: 0.10524061926459904
Validation loss: 2.415592920055601

Epoch: 5| Step: 4
Training loss: 0.10356006478126788
Validation loss: 2.4567855348736978

Epoch: 5| Step: 5
Training loss: 0.08468899559269893
Validation loss: 2.438022446050172

Epoch: 5| Step: 6
Training loss: 0.12046629872283483
Validation loss: 2.429891813469327

Epoch: 5| Step: 7
Training loss: 0.11135311013652191
Validation loss: 2.4281465763906054

Epoch: 5| Step: 8
Training loss: 0.1180422564940467
Validation loss: 2.4663950751741313

Epoch: 5| Step: 9
Training loss: 0.16762285324758802
Validation loss: 2.4441507444416244

Epoch: 5| Step: 10
Training loss: 0.18910217223594122
Validation loss: 2.444025662908207

Epoch: 546| Step: 0
Training loss: 0.19420794005014172
Validation loss: 2.4325681287170484

Epoch: 5| Step: 1
Training loss: 0.10319688596211068
Validation loss: 2.4664648853035014

Epoch: 5| Step: 2
Training loss: 0.21484991411556278
Validation loss: 2.45048372291294

Epoch: 5| Step: 3
Training loss: 0.10960772992324998
Validation loss: 2.45486480464608

Epoch: 5| Step: 4
Training loss: 0.16061515307579505
Validation loss: 2.448511359755376

Epoch: 5| Step: 5
Training loss: 0.1499181422255414
Validation loss: 2.439481590777035

Epoch: 5| Step: 6
Training loss: 0.1018528730403677
Validation loss: 2.468096876063869

Epoch: 5| Step: 7
Training loss: 0.11900780653717201
Validation loss: 2.498970690455013

Epoch: 5| Step: 8
Training loss: 0.08704334994190134
Validation loss: 2.490015037185803

Epoch: 5| Step: 9
Training loss: 0.10068852091590745
Validation loss: 2.498392078188118

Epoch: 5| Step: 10
Training loss: 0.18361433400766422
Validation loss: 2.5109915650553347

Epoch: 547| Step: 0
Training loss: 0.16919664199771067
Validation loss: 2.493455962449726

Epoch: 5| Step: 1
Training loss: 0.13819231470848206
Validation loss: 2.5277545848183447

Epoch: 5| Step: 2
Training loss: 0.17546975298566853
Validation loss: 2.5109639599858924

Epoch: 5| Step: 3
Training loss: 0.10595622260141094
Validation loss: 2.524983766305211

Epoch: 5| Step: 4
Training loss: 0.1558691270306143
Validation loss: 2.488121384702176

Epoch: 5| Step: 5
Training loss: 0.13594838816785793
Validation loss: 2.489438154700642

Epoch: 5| Step: 6
Training loss: 0.14223232532110988
Validation loss: 2.4785481259804576

Epoch: 5| Step: 7
Training loss: 0.10447976671355896
Validation loss: 2.4804836917085136

Epoch: 5| Step: 8
Training loss: 0.09071689788643876
Validation loss: 2.4828412272092533

Epoch: 5| Step: 9
Training loss: 0.139349577631531
Validation loss: 2.5007409453911897

Epoch: 5| Step: 10
Training loss: 0.1510899928216562
Validation loss: 2.468873143061702

Epoch: 548| Step: 0
Training loss: 0.1273655062502916
Validation loss: 2.465664551423925

Epoch: 5| Step: 1
Training loss: 0.1650874952770194
Validation loss: 2.4802137152526806

Epoch: 5| Step: 2
Training loss: 0.13100700449007646
Validation loss: 2.4807376353130386

Epoch: 5| Step: 3
Training loss: 0.1925452074620876
Validation loss: 2.45704999911629

Epoch: 5| Step: 4
Training loss: 0.16661026429932915
Validation loss: 2.4234335783664904

Epoch: 5| Step: 5
Training loss: 0.19352345296391446
Validation loss: 2.4559036213969434

Epoch: 5| Step: 6
Training loss: 0.19616807463750238
Validation loss: 2.495153353936116

Epoch: 5| Step: 7
Training loss: 0.07464146385875402
Validation loss: 2.5095322785962213

Epoch: 5| Step: 8
Training loss: 0.09729946765658468
Validation loss: 2.4602020060486782

Epoch: 5| Step: 9
Training loss: 0.20874742640547808
Validation loss: 2.4655052285417427

Epoch: 5| Step: 10
Training loss: 0.11197922026462899
Validation loss: 2.4858181539201483

Epoch: 549| Step: 0
Training loss: 0.2026659749064618
Validation loss: 2.442214434864656

Epoch: 5| Step: 1
Training loss: 0.110770611420314
Validation loss: 2.446981059518123

Epoch: 5| Step: 2
Training loss: 0.12347138307998687
Validation loss: 2.434253011890035

Epoch: 5| Step: 3
Training loss: 0.1926001178339274
Validation loss: 2.4298587903953335

Epoch: 5| Step: 4
Training loss: 0.11055263834511195
Validation loss: 2.4682446802861935

Epoch: 5| Step: 5
Training loss: 0.11131135914692879
Validation loss: 2.4657283176191362

Epoch: 5| Step: 6
Training loss: 0.11278284118234895
Validation loss: 2.461750764553005

Epoch: 5| Step: 7
Training loss: 0.21600718628333396
Validation loss: 2.4855546988795045

Epoch: 5| Step: 8
Training loss: 0.17005790549082356
Validation loss: 2.5153145598232607

Epoch: 5| Step: 9
Training loss: 0.11851479756362539
Validation loss: 2.5341418261235398

Epoch: 5| Step: 10
Training loss: 0.12203763524419864
Validation loss: 2.569599800730802

Epoch: 550| Step: 0
Training loss: 0.15460409892728894
Validation loss: 2.572053686275878

Epoch: 5| Step: 1
Training loss: 0.21020477684788041
Validation loss: 2.6084321880377277

Epoch: 5| Step: 2
Training loss: 0.1770187054303015
Validation loss: 2.5894461866902647

Epoch: 5| Step: 3
Training loss: 0.16168684644718154
Validation loss: 2.527320624476769

Epoch: 5| Step: 4
Training loss: 0.17536877876280688
Validation loss: 2.4791865330354517

Epoch: 5| Step: 5
Training loss: 0.1684923217959684
Validation loss: 2.4557951652317604

Epoch: 5| Step: 6
Training loss: 0.19093654376350863
Validation loss: 2.4374702636907437

Epoch: 5| Step: 7
Training loss: 0.2539910688313152
Validation loss: 2.4163465199420133

Epoch: 5| Step: 8
Training loss: 0.17618170264632949
Validation loss: 2.415769831407351

Epoch: 5| Step: 9
Training loss: 0.16154456271461073
Validation loss: 2.445419874248115

Epoch: 5| Step: 10
Training loss: 0.19443918485472478
Validation loss: 2.5663481660020877

Epoch: 551| Step: 0
Training loss: 0.20498722423309512
Validation loss: 2.548149137951388

Epoch: 5| Step: 1
Training loss: 0.20592804040441506
Validation loss: 2.52108668558733

Epoch: 5| Step: 2
Training loss: 0.18478807591179078
Validation loss: 2.46064833377641

Epoch: 5| Step: 3
Training loss: 0.20581126184667387
Validation loss: 2.4468213153119795

Epoch: 5| Step: 4
Training loss: 0.1514991738565191
Validation loss: 2.4216016082525287

Epoch: 5| Step: 5
Training loss: 0.15972061339261467
Validation loss: 2.4001778402546328

Epoch: 5| Step: 6
Training loss: 0.12340718829724887
Validation loss: 2.415658748222062

Epoch: 5| Step: 7
Training loss: 0.12848931133033756
Validation loss: 2.452892121285945

Epoch: 5| Step: 8
Training loss: 0.1668456644979761
Validation loss: 2.453268119734202

Epoch: 5| Step: 9
Training loss: 0.14539159063175375
Validation loss: 2.4784266573075064

Epoch: 5| Step: 10
Training loss: 0.1382318014968431
Validation loss: 2.5076433263409688

Epoch: 552| Step: 0
Training loss: 0.16990093124053327
Validation loss: 2.498939300423457

Epoch: 5| Step: 1
Training loss: 0.16079847154611482
Validation loss: 2.498681210747481

Epoch: 5| Step: 2
Training loss: 0.1789846981250472
Validation loss: 2.4756306374424715

Epoch: 5| Step: 3
Training loss: 0.19373818099981915
Validation loss: 2.451067197589566

Epoch: 5| Step: 4
Training loss: 0.20829894954342812
Validation loss: 2.4662988201641243

Epoch: 5| Step: 5
Training loss: 0.21294894863161562
Validation loss: 2.4509817772257567

Epoch: 5| Step: 6
Training loss: 0.12100818518197572
Validation loss: 2.4478537852306097

Epoch: 5| Step: 7
Training loss: 0.1334690387493164
Validation loss: 2.4312387882206865

Epoch: 5| Step: 8
Training loss: 0.18827843011034437
Validation loss: 2.4227637040145287

Epoch: 5| Step: 9
Training loss: 0.1485447245368251
Validation loss: 2.4445193740642823

Epoch: 5| Step: 10
Training loss: 0.14188127843055728
Validation loss: 2.4342332441297097

Epoch: 553| Step: 0
Training loss: 0.23521846157434873
Validation loss: 2.410052855731583

Epoch: 5| Step: 1
Training loss: 0.2578860524768041
Validation loss: 2.456975160913223

Epoch: 5| Step: 2
Training loss: 0.22574014058449987
Validation loss: 2.4319421390084233

Epoch: 5| Step: 3
Training loss: 0.1271731304327488
Validation loss: 2.414822014088569

Epoch: 5| Step: 4
Training loss: 0.16637978723934152
Validation loss: 2.4628953335393122

Epoch: 5| Step: 5
Training loss: 0.15354264897502856
Validation loss: 2.4505595444915556

Epoch: 5| Step: 6
Training loss: 0.13536875286728417
Validation loss: 2.490667534316756

Epoch: 5| Step: 7
Training loss: 0.17206194854049356
Validation loss: 2.527055989642081

Epoch: 5| Step: 8
Training loss: 0.14704250184198764
Validation loss: 2.519311143450692

Epoch: 5| Step: 9
Training loss: 0.14284242667029806
Validation loss: 2.479303927166534

Epoch: 5| Step: 10
Training loss: 0.11575687079707275
Validation loss: 2.5230184725463074

Epoch: 554| Step: 0
Training loss: 0.16613684323980157
Validation loss: 2.5170272376795197

Epoch: 5| Step: 1
Training loss: 0.12322567256295842
Validation loss: 2.5402178002777736

Epoch: 5| Step: 2
Training loss: 0.1567889099112748
Validation loss: 2.489559391946827

Epoch: 5| Step: 3
Training loss: 0.26934133279443606
Validation loss: 2.4855482679930514

Epoch: 5| Step: 4
Training loss: 0.14840181448785025
Validation loss: 2.5079236909831724

Epoch: 5| Step: 5
Training loss: 0.21375993103246804
Validation loss: 2.4590500293878086

Epoch: 5| Step: 6
Training loss: 0.1279136269075678
Validation loss: 2.4856775849205177

Epoch: 5| Step: 7
Training loss: 0.1763232880935848
Validation loss: 2.4406740816610193

Epoch: 5| Step: 8
Training loss: 0.15197355579227168
Validation loss: 2.46331745573807

Epoch: 5| Step: 9
Training loss: 0.19992009295153432
Validation loss: 2.49190443279576

Epoch: 5| Step: 10
Training loss: 0.17830372886799487
Validation loss: 2.5665573545376867

Epoch: 555| Step: 0
Training loss: 0.26308199986468384
Validation loss: 2.565398332689399

Epoch: 5| Step: 1
Training loss: 0.19811205045456637
Validation loss: 2.538172163057336

Epoch: 5| Step: 2
Training loss: 0.1785044493401197
Validation loss: 2.50898972705915

Epoch: 5| Step: 3
Training loss: 0.19075616092031752
Validation loss: 2.478811312162058

Epoch: 5| Step: 4
Training loss: 0.2019416285623794
Validation loss: 2.4677699957953365

Epoch: 5| Step: 5
Training loss: 0.21780916100601252
Validation loss: 2.4772617673619055

Epoch: 5| Step: 6
Training loss: 0.19714213745741557
Validation loss: 2.481456729010181

Epoch: 5| Step: 7
Training loss: 0.15843226474938263
Validation loss: 2.502594417877295

Epoch: 5| Step: 8
Training loss: 0.1655276475751671
Validation loss: 2.5195069579212315

Epoch: 5| Step: 9
Training loss: 0.1867577344506872
Validation loss: 2.548446315503345

Epoch: 5| Step: 10
Training loss: 0.08221696652667794
Validation loss: 2.5250318123360653

Epoch: 556| Step: 0
Training loss: 0.2327006615444496
Validation loss: 2.505113370446888

Epoch: 5| Step: 1
Training loss: 0.15883610510680063
Validation loss: 2.4987198310463103

Epoch: 5| Step: 2
Training loss: 0.1039181476607681
Validation loss: 2.5312872179648336

Epoch: 5| Step: 3
Training loss: 0.13774574654774507
Validation loss: 2.4756579727190764

Epoch: 5| Step: 4
Training loss: 0.18301168455996547
Validation loss: 2.4846619749651113

Epoch: 5| Step: 5
Training loss: 0.10741900526895243
Validation loss: 2.4674661054121287

Epoch: 5| Step: 6
Training loss: 0.1432078511820814
Validation loss: 2.4982064838106046

Epoch: 5| Step: 7
Training loss: 0.10025962193491987
Validation loss: 2.487878731690972

Epoch: 5| Step: 8
Training loss: 0.11917677706050114
Validation loss: 2.5713343111049043

Epoch: 5| Step: 9
Training loss: 0.25705055871575183
Validation loss: 2.5475440078694342

Epoch: 5| Step: 10
Training loss: 0.21593646553001544
Validation loss: 2.5176196568926836

Epoch: 557| Step: 0
Training loss: 0.15132678323287754
Validation loss: 2.483130059185202

Epoch: 5| Step: 1
Training loss: 0.2171655389948492
Validation loss: 2.5025145794974826

Epoch: 5| Step: 2
Training loss: 0.10856839765688404
Validation loss: 2.4667987804804783

Epoch: 5| Step: 3
Training loss: 0.2255916842434615
Validation loss: 2.473736627269795

Epoch: 5| Step: 4
Training loss: 0.187078459063061
Validation loss: 2.48471236019936

Epoch: 5| Step: 5
Training loss: 0.15495017127525806
Validation loss: 2.4792277872422877

Epoch: 5| Step: 6
Training loss: 0.11268896204015318
Validation loss: 2.4797138295551218

Epoch: 5| Step: 7
Training loss: 0.1329542693648032
Validation loss: 2.49584136985701

Epoch: 5| Step: 8
Training loss: 0.10925671448358713
Validation loss: 2.526611112383818

Epoch: 5| Step: 9
Training loss: 0.11282477817925664
Validation loss: 2.497276471564573

Epoch: 5| Step: 10
Training loss: 0.07995340182730035
Validation loss: 2.494892694198285

Epoch: 558| Step: 0
Training loss: 0.2202216356672218
Validation loss: 2.4777946829382005

Epoch: 5| Step: 1
Training loss: 0.21378884121538194
Validation loss: 2.4445126511718125

Epoch: 5| Step: 2
Training loss: 0.1368080052172879
Validation loss: 2.452524977493452

Epoch: 5| Step: 3
Training loss: 0.1489890355089851
Validation loss: 2.4531144428724887

Epoch: 5| Step: 4
Training loss: 0.15557127404364784
Validation loss: 2.459463292246935

Epoch: 5| Step: 5
Training loss: 0.10745413469214894
Validation loss: 2.487655017112235

Epoch: 5| Step: 6
Training loss: 0.10506650371173282
Validation loss: 2.5152138850704806

Epoch: 5| Step: 7
Training loss: 0.13129304792988503
Validation loss: 2.516245253996922

Epoch: 5| Step: 8
Training loss: 0.1322498041910478
Validation loss: 2.481659842783503

Epoch: 5| Step: 9
Training loss: 0.17852780073116714
Validation loss: 2.489077102928006

Epoch: 5| Step: 10
Training loss: 0.11672463000728714
Validation loss: 2.5292563979301996

Epoch: 559| Step: 0
Training loss: 0.20590883670571006
Validation loss: 2.4643233459924256

Epoch: 5| Step: 1
Training loss: 0.08967831140893551
Validation loss: 2.4694240398100664

Epoch: 5| Step: 2
Training loss: 0.21985481757615258
Validation loss: 2.463543352837033

Epoch: 5| Step: 3
Training loss: 0.17114781305031418
Validation loss: 2.469634528352991

Epoch: 5| Step: 4
Training loss: 0.09907315885048097
Validation loss: 2.4381736074924407

Epoch: 5| Step: 5
Training loss: 0.08860109125564822
Validation loss: 2.4532925702882173

Epoch: 5| Step: 6
Training loss: 0.10715005469414263
Validation loss: 2.4137383825601892

Epoch: 5| Step: 7
Training loss: 0.13284021677385546
Validation loss: 2.450554671543261

Epoch: 5| Step: 8
Training loss: 0.11476514130627398
Validation loss: 2.430783016931317

Epoch: 5| Step: 9
Training loss: 0.0872336790117544
Validation loss: 2.4555703667060818

Epoch: 5| Step: 10
Training loss: 0.1253395386489834
Validation loss: 2.493643455070512

Epoch: 560| Step: 0
Training loss: 0.16315215588123463
Validation loss: 2.483650059958685

Epoch: 5| Step: 1
Training loss: 0.13817396905492704
Validation loss: 2.481040062359273

Epoch: 5| Step: 2
Training loss: 0.11187064425417668
Validation loss: 2.4988420840261902

Epoch: 5| Step: 3
Training loss: 0.19340244930870276
Validation loss: 2.4838406336451238

Epoch: 5| Step: 4
Training loss: 0.11063862066819768
Validation loss: 2.4637724704916124

Epoch: 5| Step: 5
Training loss: 0.1501184638944625
Validation loss: 2.442588756697393

Epoch: 5| Step: 6
Training loss: 0.11330194530865606
Validation loss: 2.408396564222298

Epoch: 5| Step: 7
Training loss: 0.1692685799570972
Validation loss: 2.4251904772135062

Epoch: 5| Step: 8
Training loss: 0.17916523665774195
Validation loss: 2.392140855809523

Epoch: 5| Step: 9
Training loss: 0.11102840164829962
Validation loss: 2.3697552630957106

Epoch: 5| Step: 10
Training loss: 0.09195118474250233
Validation loss: 2.40020761775392

Epoch: 561| Step: 0
Training loss: 0.11488804255010758
Validation loss: 2.429842095108783

Epoch: 5| Step: 1
Training loss: 0.08858740959656727
Validation loss: 2.4248809144990218

Epoch: 5| Step: 2
Training loss: 0.1961554646739885
Validation loss: 2.4284506677543427

Epoch: 5| Step: 3
Training loss: 0.15902710253756325
Validation loss: 2.4863464165589964

Epoch: 5| Step: 4
Training loss: 0.1285147356738826
Validation loss: 2.480791019081298

Epoch: 5| Step: 5
Training loss: 0.1569371254505168
Validation loss: 2.46310549739077

Epoch: 5| Step: 6
Training loss: 0.18973622357764502
Validation loss: 2.449084251455325

Epoch: 5| Step: 7
Training loss: 0.1880620341100275
Validation loss: 2.4420636316736353

Epoch: 5| Step: 8
Training loss: 0.090618308823307
Validation loss: 2.450385384450967

Epoch: 5| Step: 9
Training loss: 0.143188034278076
Validation loss: 2.4047609272930335

Epoch: 5| Step: 10
Training loss: 0.1265207042086754
Validation loss: 2.422040729230952

Epoch: 562| Step: 0
Training loss: 0.1197354834563888
Validation loss: 2.406933670714595

Epoch: 5| Step: 1
Training loss: 0.1387583234799164
Validation loss: 2.409154186949067

Epoch: 5| Step: 2
Training loss: 0.16847793891639898
Validation loss: 2.418388296240707

Epoch: 5| Step: 3
Training loss: 0.12476729547747438
Validation loss: 2.410284549544284

Epoch: 5| Step: 4
Training loss: 0.13007623568013355
Validation loss: 2.453573397701678

Epoch: 5| Step: 5
Training loss: 0.20384174218096146
Validation loss: 2.4915839226955

Epoch: 5| Step: 6
Training loss: 0.1044079672907106
Validation loss: 2.477095364201828

Epoch: 5| Step: 7
Training loss: 0.10857436363840497
Validation loss: 2.4447675229572297

Epoch: 5| Step: 8
Training loss: 0.1998426913963358
Validation loss: 2.4905476994602327

Epoch: 5| Step: 9
Training loss: 0.1499444175597708
Validation loss: 2.489684170626055

Epoch: 5| Step: 10
Training loss: 0.07809800039091633
Validation loss: 2.4665223971669383

Epoch: 563| Step: 0
Training loss: 0.10841076583176854
Validation loss: 2.4924536481991866

Epoch: 5| Step: 1
Training loss: 0.11498606728942491
Validation loss: 2.483691877919351

Epoch: 5| Step: 2
Training loss: 0.15066838314397682
Validation loss: 2.4775665862558665

Epoch: 5| Step: 3
Training loss: 0.11317135972660562
Validation loss: 2.459957469232712

Epoch: 5| Step: 4
Training loss: 0.16072865866071712
Validation loss: 2.4649291964896034

Epoch: 5| Step: 5
Training loss: 0.10508619795067836
Validation loss: 2.4686676184025846

Epoch: 5| Step: 6
Training loss: 0.13235889135395518
Validation loss: 2.4830263382537248

Epoch: 5| Step: 7
Training loss: 0.17961757792175345
Validation loss: 2.503214530188128

Epoch: 5| Step: 8
Training loss: 0.1366673645456259
Validation loss: 2.5128994378037355

Epoch: 5| Step: 9
Training loss: 0.08675513041376877
Validation loss: 2.475038439851054

Epoch: 5| Step: 10
Training loss: 0.18672940730561366
Validation loss: 2.474110958829572

Epoch: 564| Step: 0
Training loss: 0.0905035864263621
Validation loss: 2.473984926833184

Epoch: 5| Step: 1
Training loss: 0.11527729851394566
Validation loss: 2.483309130630878

Epoch: 5| Step: 2
Training loss: 0.17305156753067608
Validation loss: 2.441567855244469

Epoch: 5| Step: 3
Training loss: 0.1523158341286654
Validation loss: 2.4399551214928725

Epoch: 5| Step: 4
Training loss: 0.11440795423691388
Validation loss: 2.439486182135887

Epoch: 5| Step: 5
Training loss: 0.1500016793514658
Validation loss: 2.439160135292379

Epoch: 5| Step: 6
Training loss: 0.2047924959088984
Validation loss: 2.4665135801367724

Epoch: 5| Step: 7
Training loss: 0.0774242925795748
Validation loss: 2.456652748516902

Epoch: 5| Step: 8
Training loss: 0.08406397462813561
Validation loss: 2.472008617523361

Epoch: 5| Step: 9
Training loss: 0.18321137480878585
Validation loss: 2.4683298075543605

Epoch: 5| Step: 10
Training loss: 0.07720155637664977
Validation loss: 2.4616138399357186

Epoch: 565| Step: 0
Training loss: 0.15133492525898554
Validation loss: 2.4621064503286947

Epoch: 5| Step: 1
Training loss: 0.1661484915920289
Validation loss: 2.5141436909016757

Epoch: 5| Step: 2
Training loss: 0.11976079871350184
Validation loss: 2.5014697379438595

Epoch: 5| Step: 3
Training loss: 0.13120367532605373
Validation loss: 2.519343126286132

Epoch: 5| Step: 4
Training loss: 0.11519137081156174
Validation loss: 2.5137000097288453

Epoch: 5| Step: 5
Training loss: 0.18082149965889982
Validation loss: 2.4353492951992943

Epoch: 5| Step: 6
Training loss: 0.12596919163868053
Validation loss: 2.4179346904316943

Epoch: 5| Step: 7
Training loss: 0.17849603875223338
Validation loss: 2.4139278629323773

Epoch: 5| Step: 8
Training loss: 0.10661286981482497
Validation loss: 2.4118167084041935

Epoch: 5| Step: 9
Training loss: 0.10501581085039927
Validation loss: 2.3993882337848764

Epoch: 5| Step: 10
Training loss: 0.10469845440473162
Validation loss: 2.4639474228982836

Epoch: 566| Step: 0
Training loss: 0.15332529946739115
Validation loss: 2.4719775581835233

Epoch: 5| Step: 1
Training loss: 0.16504297308267118
Validation loss: 2.489180224136142

Epoch: 5| Step: 2
Training loss: 0.10375727033419607
Validation loss: 2.4540428846448363

Epoch: 5| Step: 3
Training loss: 0.0908788779328575
Validation loss: 2.4643350608059973

Epoch: 5| Step: 4
Training loss: 0.11592375106979924
Validation loss: 2.465055949920623

Epoch: 5| Step: 5
Training loss: 0.19171057078193018
Validation loss: 2.4717940471716164

Epoch: 5| Step: 6
Training loss: 0.16824392577779682
Validation loss: 2.4727160744913603

Epoch: 5| Step: 7
Training loss: 0.15579749984891364
Validation loss: 2.487396792396214

Epoch: 5| Step: 8
Training loss: 0.15059107265795743
Validation loss: 2.4760549862523598

Epoch: 5| Step: 9
Training loss: 0.12093218284692507
Validation loss: 2.4900210519167505

Epoch: 5| Step: 10
Training loss: 0.09332454023528973
Validation loss: 2.4805424303437453

Epoch: 567| Step: 0
Training loss: 0.08815259568193672
Validation loss: 2.4843607782354242

Epoch: 5| Step: 1
Training loss: 0.1075527001410186
Validation loss: 2.4821711629255163

Epoch: 5| Step: 2
Training loss: 0.14927106759007935
Validation loss: 2.478032858407147

Epoch: 5| Step: 3
Training loss: 0.08013801544836188
Validation loss: 2.4316927240111896

Epoch: 5| Step: 4
Training loss: 0.17274131060495848
Validation loss: 2.4749704221845557

Epoch: 5| Step: 5
Training loss: 0.1025677867801871
Validation loss: 2.4484750184646535

Epoch: 5| Step: 6
Training loss: 0.15810563768986893
Validation loss: 2.4815070636176624

Epoch: 5| Step: 7
Training loss: 0.1009114978133914
Validation loss: 2.4121942535846976

Epoch: 5| Step: 8
Training loss: 0.11849131862361807
Validation loss: 2.437341933677232

Epoch: 5| Step: 9
Training loss: 0.1490607353721789
Validation loss: 2.4246937174279006

Epoch: 5| Step: 10
Training loss: 0.20153237420808273
Validation loss: 2.45951350393156

Epoch: 568| Step: 0
Training loss: 0.14051422418426135
Validation loss: 2.4377854403332306

Epoch: 5| Step: 1
Training loss: 0.20122207089435762
Validation loss: 2.4423696992205115

Epoch: 5| Step: 2
Training loss: 0.06172570403674976
Validation loss: 2.4488751847777315

Epoch: 5| Step: 3
Training loss: 0.13053545788345033
Validation loss: 2.4261375597411683

Epoch: 5| Step: 4
Training loss: 0.11725002448721225
Validation loss: 2.4281645233649436

Epoch: 5| Step: 5
Training loss: 0.135506885687044
Validation loss: 2.3960753557143843

Epoch: 5| Step: 6
Training loss: 0.12180108326143836
Validation loss: 2.4233172824337816

Epoch: 5| Step: 7
Training loss: 0.15720905182751177
Validation loss: 2.3837976520858772

Epoch: 5| Step: 8
Training loss: 0.13329456300868966
Validation loss: 2.4120336701309206

Epoch: 5| Step: 9
Training loss: 0.12501965308663943
Validation loss: 2.4157493679960163

Epoch: 5| Step: 10
Training loss: 0.09434871429101539
Validation loss: 2.4279083183567396

Epoch: 569| Step: 0
Training loss: 0.1726965020153235
Validation loss: 2.453434156755478

Epoch: 5| Step: 1
Training loss: 0.14299312055527513
Validation loss: 2.508075247868474

Epoch: 5| Step: 2
Training loss: 0.10361539782808027
Validation loss: 2.4875693546693056

Epoch: 5| Step: 3
Training loss: 0.1032097724517886
Validation loss: 2.4546844310079043

Epoch: 5| Step: 4
Training loss: 0.06069907547418118
Validation loss: 2.505371873983988

Epoch: 5| Step: 5
Training loss: 0.15076401419287594
Validation loss: 2.458321439054847

Epoch: 5| Step: 6
Training loss: 0.09035450423845122
Validation loss: 2.4555463522648573

Epoch: 5| Step: 7
Training loss: 0.10813437336468404
Validation loss: 2.4486412883627953

Epoch: 5| Step: 8
Training loss: 0.16356562691513968
Validation loss: 2.451459120577969

Epoch: 5| Step: 9
Training loss: 0.12833470738462863
Validation loss: 2.4613919090068364

Epoch: 5| Step: 10
Training loss: 0.09414545735346513
Validation loss: 2.4812306159184363

Epoch: 570| Step: 0
Training loss: 0.11731879111738329
Validation loss: 2.4759586977913854

Epoch: 5| Step: 1
Training loss: 0.15409341507757116
Validation loss: 2.533956803463496

Epoch: 5| Step: 2
Training loss: 0.13272985523649816
Validation loss: 2.5225136029224586

Epoch: 5| Step: 3
Training loss: 0.11834675482392068
Validation loss: 2.524649341739449

Epoch: 5| Step: 4
Training loss: 0.09952448050864775
Validation loss: 2.506231022532955

Epoch: 5| Step: 5
Training loss: 0.12103370362155402
Validation loss: 2.4585009441797743

Epoch: 5| Step: 6
Training loss: 0.09798453940686616
Validation loss: 2.4307601887883976

Epoch: 5| Step: 7
Training loss: 0.09856358544290808
Validation loss: 2.4283253650299614

Epoch: 5| Step: 8
Training loss: 0.10230130833466666
Validation loss: 2.4126265871175585

Epoch: 5| Step: 9
Training loss: 0.19417866616219334
Validation loss: 2.398574977476812

Epoch: 5| Step: 10
Training loss: 0.1762784707293753
Validation loss: 2.4272872395168044

Epoch: 571| Step: 0
Training loss: 0.16505039334196864
Validation loss: 2.4167827907861987

Epoch: 5| Step: 1
Training loss: 0.15763037814283423
Validation loss: 2.4463478034658914

Epoch: 5| Step: 2
Training loss: 0.11809223135561993
Validation loss: 2.479429842336229

Epoch: 5| Step: 3
Training loss: 0.140616138496939
Validation loss: 2.470175469029489

Epoch: 5| Step: 4
Training loss: 0.15867265443784176
Validation loss: 2.508231913720763

Epoch: 5| Step: 5
Training loss: 0.16797240386359852
Validation loss: 2.5000868305386

Epoch: 5| Step: 6
Training loss: 0.08614018229227736
Validation loss: 2.518969121523499

Epoch: 5| Step: 7
Training loss: 0.1304093351248302
Validation loss: 2.550125627521623

Epoch: 5| Step: 8
Training loss: 0.12660629138865823
Validation loss: 2.5612683761678072

Epoch: 5| Step: 9
Training loss: 0.0861817108672723
Validation loss: 2.559118510356734

Epoch: 5| Step: 10
Training loss: 0.13282864837085664
Validation loss: 2.521572508239602

Epoch: 572| Step: 0
Training loss: 0.14210166750868417
Validation loss: 2.523272097311316

Epoch: 5| Step: 1
Training loss: 0.19296588741140644
Validation loss: 2.5529815184870728

Epoch: 5| Step: 2
Training loss: 0.10199012048585251
Validation loss: 2.5313463535805525

Epoch: 5| Step: 3
Training loss: 0.14828482104022112
Validation loss: 2.503084699741519

Epoch: 5| Step: 4
Training loss: 0.10032931247834824
Validation loss: 2.4965485923516626

Epoch: 5| Step: 5
Training loss: 0.18261755468974197
Validation loss: 2.462872694266944

Epoch: 5| Step: 6
Training loss: 0.13887284719359108
Validation loss: 2.507801948192674

Epoch: 5| Step: 7
Training loss: 0.15057246869087765
Validation loss: 2.490990009164672

Epoch: 5| Step: 8
Training loss: 0.087765769224573
Validation loss: 2.464355151982134

Epoch: 5| Step: 9
Training loss: 0.10849023488978875
Validation loss: 2.503119379684318

Epoch: 5| Step: 10
Training loss: 0.158070219986824
Validation loss: 2.523957799056602

Epoch: 573| Step: 0
Training loss: 0.14236943112719555
Validation loss: 2.482547433755208

Epoch: 5| Step: 1
Training loss: 0.07668205422272666
Validation loss: 2.465218702393501

Epoch: 5| Step: 2
Training loss: 0.09910047250854206
Validation loss: 2.4793480337728493

Epoch: 5| Step: 3
Training loss: 0.12649865600565557
Validation loss: 2.4931385746926784

Epoch: 5| Step: 4
Training loss: 0.14533026314936276
Validation loss: 2.487220237493217

Epoch: 5| Step: 5
Training loss: 0.11231336560098859
Validation loss: 2.465536536822308

Epoch: 5| Step: 6
Training loss: 0.19113362612883442
Validation loss: 2.5123940704418932

Epoch: 5| Step: 7
Training loss: 0.15375112640735836
Validation loss: 2.5132562915420675

Epoch: 5| Step: 8
Training loss: 0.13847833209931462
Validation loss: 2.4477374435162518

Epoch: 5| Step: 9
Training loss: 0.10439370318263681
Validation loss: 2.516731489172898

Epoch: 5| Step: 10
Training loss: 0.10239115447081096
Validation loss: 2.491802221670124

Epoch: 574| Step: 0
Training loss: 0.17380786627683564
Validation loss: 2.476936226991312

Epoch: 5| Step: 1
Training loss: 0.134179999005485
Validation loss: 2.446710228950321

Epoch: 5| Step: 2
Training loss: 0.17503958109715193
Validation loss: 2.472501652630968

Epoch: 5| Step: 3
Training loss: 0.07801162718995344
Validation loss: 2.4711796819241147

Epoch: 5| Step: 4
Training loss: 0.16599716757101507
Validation loss: 2.4559518664412794

Epoch: 5| Step: 5
Training loss: 0.12170567411059141
Validation loss: 2.515852972671491

Epoch: 5| Step: 6
Training loss: 0.09194396794179031
Validation loss: 2.4826936982274628

Epoch: 5| Step: 7
Training loss: 0.19018225611923564
Validation loss: 2.4513866691769484

Epoch: 5| Step: 8
Training loss: 0.11150987746446726
Validation loss: 2.4684047070684105

Epoch: 5| Step: 9
Training loss: 0.13991766100596997
Validation loss: 2.4364751402429525

Epoch: 5| Step: 10
Training loss: 0.13326808682204117
Validation loss: 2.4601204693834102

Epoch: 575| Step: 0
Training loss: 0.11559867655900286
Validation loss: 2.43259911371492

Epoch: 5| Step: 1
Training loss: 0.1106606518010781
Validation loss: 2.4210950401990003

Epoch: 5| Step: 2
Training loss: 0.18506175418459983
Validation loss: 2.460784741732677

Epoch: 5| Step: 3
Training loss: 0.14949089767421936
Validation loss: 2.4259448810106385

Epoch: 5| Step: 4
Training loss: 0.0799207915375283
Validation loss: 2.4632654459050167

Epoch: 5| Step: 5
Training loss: 0.07719231215044303
Validation loss: 2.4698478653273277

Epoch: 5| Step: 6
Training loss: 0.16384922083681638
Validation loss: 2.490845252850415

Epoch: 5| Step: 7
Training loss: 0.11239733813265157
Validation loss: 2.4816172943036343

Epoch: 5| Step: 8
Training loss: 0.15411614444526858
Validation loss: 2.478274300008975

Epoch: 5| Step: 9
Training loss: 0.20639188574998565
Validation loss: 2.4612708841728566

Epoch: 5| Step: 10
Training loss: 0.10200882920918898
Validation loss: 2.4507023370327103

Epoch: 576| Step: 0
Training loss: 0.10347621095395305
Validation loss: 2.4351202699411107

Epoch: 5| Step: 1
Training loss: 0.101651661506043
Validation loss: 2.4215209268114055

Epoch: 5| Step: 2
Training loss: 0.14112839403370728
Validation loss: 2.4140452680255824

Epoch: 5| Step: 3
Training loss: 0.09742621030545158
Validation loss: 2.419264591663369

Epoch: 5| Step: 4
Training loss: 0.1751177664004136
Validation loss: 2.434216816861839

Epoch: 5| Step: 5
Training loss: 0.0962622522011869
Validation loss: 2.4118454302058545

Epoch: 5| Step: 6
Training loss: 0.09408882623406498
Validation loss: 2.431899026905255

Epoch: 5| Step: 7
Training loss: 0.1225564660119398
Validation loss: 2.4498141924817727

Epoch: 5| Step: 8
Training loss: 0.11679584700473294
Validation loss: 2.4521879223853817

Epoch: 5| Step: 9
Training loss: 0.14291747090773252
Validation loss: 2.4741398812191404

Epoch: 5| Step: 10
Training loss: 0.19229086988028465
Validation loss: 2.4215714543946025

Epoch: 577| Step: 0
Training loss: 0.11928132223112595
Validation loss: 2.3913513609319463

Epoch: 5| Step: 1
Training loss: 0.10886271601357767
Validation loss: 2.3901317049151736

Epoch: 5| Step: 2
Training loss: 0.13564406766324782
Validation loss: 2.4053914872254456

Epoch: 5| Step: 3
Training loss: 0.15946400298301167
Validation loss: 2.3755711838502496

Epoch: 5| Step: 4
Training loss: 0.0770516391894945
Validation loss: 2.4120082273877452

Epoch: 5| Step: 5
Training loss: 0.12423952681647649
Validation loss: 2.413292669921241

Epoch: 5| Step: 6
Training loss: 0.11011363855646544
Validation loss: 2.4320333089387227

Epoch: 5| Step: 7
Training loss: 0.12288092594346528
Validation loss: 2.4493131160637325

Epoch: 5| Step: 8
Training loss: 0.15797406556480473
Validation loss: 2.45127848483345

Epoch: 5| Step: 9
Training loss: 0.15079888132017794
Validation loss: 2.419664150926671

Epoch: 5| Step: 10
Training loss: 0.14596148307113152
Validation loss: 2.429990345641035

Epoch: 578| Step: 0
Training loss: 0.1455152688900172
Validation loss: 2.41843086688096

Epoch: 5| Step: 1
Training loss: 0.10344745532615955
Validation loss: 2.4115345860293185

Epoch: 5| Step: 2
Training loss: 0.16732880200569594
Validation loss: 2.405130236344183

Epoch: 5| Step: 3
Training loss: 0.11974489855725921
Validation loss: 2.4685450243329754

Epoch: 5| Step: 4
Training loss: 0.18482138697569112
Validation loss: 2.474023128539653

Epoch: 5| Step: 5
Training loss: 0.1553777068701026
Validation loss: 2.4778424582964886

Epoch: 5| Step: 6
Training loss: 0.08299078766756275
Validation loss: 2.467877868566874

Epoch: 5| Step: 7
Training loss: 0.12861613659306848
Validation loss: 2.471659920351834

Epoch: 5| Step: 8
Training loss: 0.11202848719671032
Validation loss: 2.4734669622360257

Epoch: 5| Step: 9
Training loss: 0.09538400246659566
Validation loss: 2.4907295518738946

Epoch: 5| Step: 10
Training loss: 0.07984598752001444
Validation loss: 2.48592815580333

Epoch: 579| Step: 0
Training loss: 0.1819843506051944
Validation loss: 2.5090462595788283

Epoch: 5| Step: 1
Training loss: 0.11742001751580926
Validation loss: 2.4844761597803915

Epoch: 5| Step: 2
Training loss: 0.11164859189383255
Validation loss: 2.5096813546706174

Epoch: 5| Step: 3
Training loss: 0.18161276121641262
Validation loss: 2.514129426454215

Epoch: 5| Step: 4
Training loss: 0.06581515311782951
Validation loss: 2.4537969969512314

Epoch: 5| Step: 5
Training loss: 0.0987145255372259
Validation loss: 2.460928423360691

Epoch: 5| Step: 6
Training loss: 0.09567080165978034
Validation loss: 2.456336469291212

Epoch: 5| Step: 7
Training loss: 0.11398866121810447
Validation loss: 2.4298828054944877

Epoch: 5| Step: 8
Training loss: 0.08297668883315219
Validation loss: 2.4599146709538227

Epoch: 5| Step: 9
Training loss: 0.06504242790954479
Validation loss: 2.471736507057879

Epoch: 5| Step: 10
Training loss: 0.16592085882389956
Validation loss: 2.461898457227293

Epoch: 580| Step: 0
Training loss: 0.08616593193421773
Validation loss: 2.4365880662801596

Epoch: 5| Step: 1
Training loss: 0.06466065216496505
Validation loss: 2.4565498496965463

Epoch: 5| Step: 2
Training loss: 0.10584124818142157
Validation loss: 2.464736975947053

Epoch: 5| Step: 3
Training loss: 0.15720308021853405
Validation loss: 2.443283133769272

Epoch: 5| Step: 4
Training loss: 0.1361317635910366
Validation loss: 2.4637887485619676

Epoch: 5| Step: 5
Training loss: 0.08052499458204308
Validation loss: 2.488581194457438

Epoch: 5| Step: 6
Training loss: 0.12143843953760156
Validation loss: 2.490397608773823

Epoch: 5| Step: 7
Training loss: 0.11144551145105959
Validation loss: 2.489649340605411

Epoch: 5| Step: 8
Training loss: 0.13627046934408799
Validation loss: 2.4853378837381963

Epoch: 5| Step: 9
Training loss: 0.10873801079657604
Validation loss: 2.4953827869383893

Epoch: 5| Step: 10
Training loss: 0.15602382144591354
Validation loss: 2.506114864687797

Epoch: 581| Step: 0
Training loss: 0.11188857069501525
Validation loss: 2.5103608189319564

Epoch: 5| Step: 1
Training loss: 0.13974109989949474
Validation loss: 2.458424378953479

Epoch: 5| Step: 2
Training loss: 0.0911673713395474
Validation loss: 2.4596221580732784

Epoch: 5| Step: 3
Training loss: 0.10142666646452467
Validation loss: 2.477566212196834

Epoch: 5| Step: 4
Training loss: 0.12954081058306235
Validation loss: 2.414468284267737

Epoch: 5| Step: 5
Training loss: 0.1027083996834776
Validation loss: 2.423237677970473

Epoch: 5| Step: 6
Training loss: 0.10215453755124074
Validation loss: 2.4200661415855653

Epoch: 5| Step: 7
Training loss: 0.14923362807553348
Validation loss: 2.418918132267036

Epoch: 5| Step: 8
Training loss: 0.10902039059270185
Validation loss: 2.436447091262487

Epoch: 5| Step: 9
Training loss: 0.13393009020307503
Validation loss: 2.446044718941303

Epoch: 5| Step: 10
Training loss: 0.20687939814937312
Validation loss: 2.449548778007181

Epoch: 582| Step: 0
Training loss: 0.11080507749892171
Validation loss: 2.4449908349555973

Epoch: 5| Step: 1
Training loss: 0.07526775685103121
Validation loss: 2.4504731219746407

Epoch: 5| Step: 2
Training loss: 0.07510178806362726
Validation loss: 2.4634252185655905

Epoch: 5| Step: 3
Training loss: 0.14680595068413246
Validation loss: 2.458772776103076

Epoch: 5| Step: 4
Training loss: 0.12231940984676133
Validation loss: 2.4722278833487694

Epoch: 5| Step: 5
Training loss: 0.10464131774262918
Validation loss: 2.470171130865095

Epoch: 5| Step: 6
Training loss: 0.07362413001032217
Validation loss: 2.4759994347582435

Epoch: 5| Step: 7
Training loss: 0.14844127700417373
Validation loss: 2.438306610328496

Epoch: 5| Step: 8
Training loss: 0.1365260400919683
Validation loss: 2.4270959686819356

Epoch: 5| Step: 9
Training loss: 0.12048924981685023
Validation loss: 2.451492292942017

Epoch: 5| Step: 10
Training loss: 0.16792541876489817
Validation loss: 2.4113848431014597

Epoch: 583| Step: 0
Training loss: 0.10704872604733016
Validation loss: 2.4181570300885253

Epoch: 5| Step: 1
Training loss: 0.16673970236501637
Validation loss: 2.430233708845065

Epoch: 5| Step: 2
Training loss: 0.17632749772034206
Validation loss: 2.38262380319826

Epoch: 5| Step: 3
Training loss: 0.07677769609679522
Validation loss: 2.395671009344789

Epoch: 5| Step: 4
Training loss: 0.137233039318709
Validation loss: 2.405203169796264

Epoch: 5| Step: 5
Training loss: 0.10880839092240528
Validation loss: 2.4077707914940976

Epoch: 5| Step: 6
Training loss: 0.1614555017674222
Validation loss: 2.4197582212808904

Epoch: 5| Step: 7
Training loss: 0.16402937350305352
Validation loss: 2.4473817183636846

Epoch: 5| Step: 8
Training loss: 0.09869932538120112
Validation loss: 2.425434763316715

Epoch: 5| Step: 9
Training loss: 0.10005986035103968
Validation loss: 2.473783145826469

Epoch: 5| Step: 10
Training loss: 0.12177268556986895
Validation loss: 2.4436164348848126

Epoch: 584| Step: 0
Training loss: 0.14301392175149275
Validation loss: 2.477285570262247

Epoch: 5| Step: 1
Training loss: 0.10131328524097555
Validation loss: 2.4713632821239204

Epoch: 5| Step: 2
Training loss: 0.18016190720978537
Validation loss: 2.520616178448546

Epoch: 5| Step: 3
Training loss: 0.19266330777224594
Validation loss: 2.4905642492645983

Epoch: 5| Step: 4
Training loss: 0.1382687848609798
Validation loss: 2.472108209290066

Epoch: 5| Step: 5
Training loss: 0.1496450471307296
Validation loss: 2.4137156438734757

Epoch: 5| Step: 6
Training loss: 0.17198505454398333
Validation loss: 2.3834477210509757

Epoch: 5| Step: 7
Training loss: 0.16418964137077488
Validation loss: 2.3470974928258244

Epoch: 5| Step: 8
Training loss: 0.15687175664740535
Validation loss: 2.3464656112886133

Epoch: 5| Step: 9
Training loss: 0.17712908158549687
Validation loss: 2.354806674908508

Epoch: 5| Step: 10
Training loss: 0.11210765970227106
Validation loss: 2.4043298823692623

Epoch: 585| Step: 0
Training loss: 0.15883435193496084
Validation loss: 2.4338707884793997

Epoch: 5| Step: 1
Training loss: 0.2116791878226409
Validation loss: 2.5388690056286336

Epoch: 5| Step: 2
Training loss: 0.22227899481011337
Validation loss: 2.531157037265294

Epoch: 5| Step: 3
Training loss: 0.12870968657422605
Validation loss: 2.529587936679192

Epoch: 5| Step: 4
Training loss: 0.15130351173155587
Validation loss: 2.4168019322300416

Epoch: 5| Step: 5
Training loss: 0.15966915281830824
Validation loss: 2.387360770721861

Epoch: 5| Step: 6
Training loss: 0.16142848659309245
Validation loss: 2.356409769654696

Epoch: 5| Step: 7
Training loss: 0.19779180469699648
Validation loss: 2.347753903891378

Epoch: 5| Step: 8
Training loss: 0.15656267709588792
Validation loss: 2.386714008795782

Epoch: 5| Step: 9
Training loss: 0.11588812317705853
Validation loss: 2.422277964697596

Epoch: 5| Step: 10
Training loss: 0.16667591506411575
Validation loss: 2.5141245992220562

Epoch: 586| Step: 0
Training loss: 0.18136101397742221
Validation loss: 2.558641906350224

Epoch: 5| Step: 1
Training loss: 0.14448214676274196
Validation loss: 2.6188886471587463

Epoch: 5| Step: 2
Training loss: 0.20556103298386358
Validation loss: 2.60102107567984

Epoch: 5| Step: 3
Training loss: 0.1305694357178885
Validation loss: 2.543806900908203

Epoch: 5| Step: 4
Training loss: 0.2065502192530026
Validation loss: 2.565028459601794

Epoch: 5| Step: 5
Training loss: 0.14050691998314677
Validation loss: 2.5122757668516704

Epoch: 5| Step: 6
Training loss: 0.21068008045065534
Validation loss: 2.434366993013779

Epoch: 5| Step: 7
Training loss: 0.14846659049027489
Validation loss: 2.438308724697157

Epoch: 5| Step: 8
Training loss: 0.14346692912608677
Validation loss: 2.450572475332817

Epoch: 5| Step: 9
Training loss: 0.17587052303586193
Validation loss: 2.4661555522572085

Epoch: 5| Step: 10
Training loss: 0.13315054003763213
Validation loss: 2.504180818919434

Epoch: 587| Step: 0
Training loss: 0.14172464480437166
Validation loss: 2.4840685845781656

Epoch: 5| Step: 1
Training loss: 0.16580590858399877
Validation loss: 2.500597701353976

Epoch: 5| Step: 2
Training loss: 0.2176261797423269
Validation loss: 2.511663300879096

Epoch: 5| Step: 3
Training loss: 0.11527275400014046
Validation loss: 2.4846784334526517

Epoch: 5| Step: 4
Training loss: 0.17234280710489824
Validation loss: 2.4944030529608625

Epoch: 5| Step: 5
Training loss: 0.09181483580011641
Validation loss: 2.478373694299716

Epoch: 5| Step: 6
Training loss: 0.13374929463565965
Validation loss: 2.467288037023426

Epoch: 5| Step: 7
Training loss: 0.15092575555724114
Validation loss: 2.496687191324989

Epoch: 5| Step: 8
Training loss: 0.08827134695041348
Validation loss: 2.4978930280280327

Epoch: 5| Step: 9
Training loss: 0.11025356904240984
Validation loss: 2.4987254739388822

Epoch: 5| Step: 10
Training loss: 0.23113515650579422
Validation loss: 2.523879450596135

Epoch: 588| Step: 0
Training loss: 0.15836026781919174
Validation loss: 2.4662136123965186

Epoch: 5| Step: 1
Training loss: 0.1624453922822465
Validation loss: 2.4722409429882566

Epoch: 5| Step: 2
Training loss: 0.13598045185754504
Validation loss: 2.4409535660627353

Epoch: 5| Step: 3
Training loss: 0.15662793705036715
Validation loss: 2.434171359575732

Epoch: 5| Step: 4
Training loss: 0.11874501020212662
Validation loss: 2.4194400552043507

Epoch: 5| Step: 5
Training loss: 0.12068719064291604
Validation loss: 2.423370748386983

Epoch: 5| Step: 6
Training loss: 0.1052703359780427
Validation loss: 2.409217776077624

Epoch: 5| Step: 7
Training loss: 0.10584763623709137
Validation loss: 2.4014713960818455

Epoch: 5| Step: 8
Training loss: 0.2146422481599066
Validation loss: 2.3896653170454036

Epoch: 5| Step: 9
Training loss: 0.11483859533951443
Validation loss: 2.449071778050383

Epoch: 5| Step: 10
Training loss: 0.0999643228635148
Validation loss: 2.4227985665395777

Epoch: 589| Step: 0
Training loss: 0.13710318059595167
Validation loss: 2.421514872154202

Epoch: 5| Step: 1
Training loss: 0.1502889004281258
Validation loss: 2.399439561325504

Epoch: 5| Step: 2
Training loss: 0.1434749070177709
Validation loss: 2.4288115763553235

Epoch: 5| Step: 3
Training loss: 0.13563404303608248
Validation loss: 2.4552529764739495

Epoch: 5| Step: 4
Training loss: 0.1625923579730306
Validation loss: 2.448677141401482

Epoch: 5| Step: 5
Training loss: 0.11967609409062656
Validation loss: 2.4353752730687943

Epoch: 5| Step: 6
Training loss: 0.12595044094406407
Validation loss: 2.3999218115751746

Epoch: 5| Step: 7
Training loss: 0.11147773043206292
Validation loss: 2.4452072163349374

Epoch: 5| Step: 8
Training loss: 0.08229792764492763
Validation loss: 2.4225413760280503

Epoch: 5| Step: 9
Training loss: 0.18148511977582774
Validation loss: 2.4112325264189844

Epoch: 5| Step: 10
Training loss: 0.11347947371354761
Validation loss: 2.4059003062595044

Epoch: 590| Step: 0
Training loss: 0.11827931025210868
Validation loss: 2.4084263433575472

Epoch: 5| Step: 1
Training loss: 0.21703926489073494
Validation loss: 2.4087989867768367

Epoch: 5| Step: 2
Training loss: 0.16705967838745964
Validation loss: 2.4324082052433837

Epoch: 5| Step: 3
Training loss: 0.1230899379701173
Validation loss: 2.4653279382930315

Epoch: 5| Step: 4
Training loss: 0.11095404938040254
Validation loss: 2.479007547976358

Epoch: 5| Step: 5
Training loss: 0.10748322642256537
Validation loss: 2.4390508547201772

Epoch: 5| Step: 6
Training loss: 0.15206089414900253
Validation loss: 2.481388459036569

Epoch: 5| Step: 7
Training loss: 0.19476476158810663
Validation loss: 2.4625641946403447

Epoch: 5| Step: 8
Training loss: 0.1062296774305723
Validation loss: 2.452384246959188

Epoch: 5| Step: 9
Training loss: 0.11282729992910207
Validation loss: 2.4604044008525374

Epoch: 5| Step: 10
Training loss: 0.10363688653960594
Validation loss: 2.4203994352455807

Epoch: 591| Step: 0
Training loss: 0.20976756750304923
Validation loss: 2.3983167969537647

Epoch: 5| Step: 1
Training loss: 0.1036669551670881
Validation loss: 2.437245302800279

Epoch: 5| Step: 2
Training loss: 0.13207837172444242
Validation loss: 2.4585232394536556

Epoch: 5| Step: 3
Training loss: 0.15181750715399603
Validation loss: 2.483375238772642

Epoch: 5| Step: 4
Training loss: 0.18139069292519197
Validation loss: 2.516521591908781

Epoch: 5| Step: 5
Training loss: 0.18018440287981857
Validation loss: 2.508253760815378

Epoch: 5| Step: 6
Training loss: 0.11071485875172028
Validation loss: 2.515503756812108

Epoch: 5| Step: 7
Training loss: 0.11397059931926927
Validation loss: 2.5680468152562836

Epoch: 5| Step: 8
Training loss: 0.08709233998401796
Validation loss: 2.5165617007856786

Epoch: 5| Step: 9
Training loss: 0.11919242483245203
Validation loss: 2.5007241236085287

Epoch: 5| Step: 10
Training loss: 0.06973140055971064
Validation loss: 2.50594760200851

Epoch: 592| Step: 0
Training loss: 0.1043975526320726
Validation loss: 2.4979287488829005

Epoch: 5| Step: 1
Training loss: 0.16392978341080205
Validation loss: 2.4703759181641303

Epoch: 5| Step: 2
Training loss: 0.2228298681533496
Validation loss: 2.446410884553934

Epoch: 5| Step: 3
Training loss: 0.10937935956713409
Validation loss: 2.4669356423000988

Epoch: 5| Step: 4
Training loss: 0.13976479064709424
Validation loss: 2.4615068872420873

Epoch: 5| Step: 5
Training loss: 0.11477138159475468
Validation loss: 2.4792549383515285

Epoch: 5| Step: 6
Training loss: 0.11461354980718114
Validation loss: 2.4757420218591375

Epoch: 5| Step: 7
Training loss: 0.1225603339083111
Validation loss: 2.4639267160812386

Epoch: 5| Step: 8
Training loss: 0.1012314757131976
Validation loss: 2.4810644923787843

Epoch: 5| Step: 9
Training loss: 0.10766955778562182
Validation loss: 2.512295535865598

Epoch: 5| Step: 10
Training loss: 0.10802491588964457
Validation loss: 2.477503865131384

Epoch: 593| Step: 0
Training loss: 0.17341906926454317
Validation loss: 2.47635465167505

Epoch: 5| Step: 1
Training loss: 0.14282774955458957
Validation loss: 2.4642053656333527

Epoch: 5| Step: 2
Training loss: 0.08005896490271126
Validation loss: 2.450386625266817

Epoch: 5| Step: 3
Training loss: 0.14160362768311505
Validation loss: 2.4256349791335823

Epoch: 5| Step: 4
Training loss: 0.21065214069966504
Validation loss: 2.427242204315703

Epoch: 5| Step: 5
Training loss: 0.11015348887534004
Validation loss: 2.428162224901124

Epoch: 5| Step: 6
Training loss: 0.12838156441589263
Validation loss: 2.4437822947243286

Epoch: 5| Step: 7
Training loss: 0.14495070908360838
Validation loss: 2.463917138020501

Epoch: 5| Step: 8
Training loss: 0.10365623694670775
Validation loss: 2.4363049847938214

Epoch: 5| Step: 9
Training loss: 0.11932568170459452
Validation loss: 2.4389638246905734

Epoch: 5| Step: 10
Training loss: 0.0834661675524639
Validation loss: 2.464539975212183

Epoch: 594| Step: 0
Training loss: 0.13107001020336745
Validation loss: 2.499899289963685

Epoch: 5| Step: 1
Training loss: 0.12647496186655666
Validation loss: 2.528721539977218

Epoch: 5| Step: 2
Training loss: 0.10644191771527209
Validation loss: 2.486226295060354

Epoch: 5| Step: 3
Training loss: 0.09639188526533651
Validation loss: 2.538485753742525

Epoch: 5| Step: 4
Training loss: 0.11588352225037499
Validation loss: 2.555555617287278

Epoch: 5| Step: 5
Training loss: 0.16422224215306966
Validation loss: 2.533223554472993

Epoch: 5| Step: 6
Training loss: 0.187745737929674
Validation loss: 2.511922749523338

Epoch: 5| Step: 7
Training loss: 0.08932540471177192
Validation loss: 2.521664850367051

Epoch: 5| Step: 8
Training loss: 0.12975784255454678
Validation loss: 2.5020066196550843

Epoch: 5| Step: 9
Training loss: 0.1515120090365097
Validation loss: 2.4866148209483345

Epoch: 5| Step: 10
Training loss: 0.12780963564556813
Validation loss: 2.4589569690524007

Epoch: 595| Step: 0
Training loss: 0.07947046887679822
Validation loss: 2.4031298429329735

Epoch: 5| Step: 1
Training loss: 0.09270968003134268
Validation loss: 2.48421121569364

Epoch: 5| Step: 2
Training loss: 0.19386249168376793
Validation loss: 2.4289088820904756

Epoch: 5| Step: 3
Training loss: 0.1269654488083917
Validation loss: 2.4580244520664216

Epoch: 5| Step: 4
Training loss: 0.14330522439616203
Validation loss: 2.412304895328449

Epoch: 5| Step: 5
Training loss: 0.09488860261446337
Validation loss: 2.461315280599771

Epoch: 5| Step: 6
Training loss: 0.1607243417912705
Validation loss: 2.5220983963759744

Epoch: 5| Step: 7
Training loss: 0.16934319318914587
Validation loss: 2.5421555240787077

Epoch: 5| Step: 8
Training loss: 0.11422513021608638
Validation loss: 2.5071919451354967

Epoch: 5| Step: 9
Training loss: 0.13361289963474654
Validation loss: 2.5251564605267376

Epoch: 5| Step: 10
Training loss: 0.1642346784287463
Validation loss: 2.5146074223560975

Epoch: 596| Step: 0
Training loss: 0.12631630735496394
Validation loss: 2.483019586948413

Epoch: 5| Step: 1
Training loss: 0.12346178823852766
Validation loss: 2.4461132107936012

Epoch: 5| Step: 2
Training loss: 0.1479788269027611
Validation loss: 2.44337372419756

Epoch: 5| Step: 3
Training loss: 0.10929400561603796
Validation loss: 2.460248394839416

Epoch: 5| Step: 4
Training loss: 0.19116553916144124
Validation loss: 2.4338832829089756

Epoch: 5| Step: 5
Training loss: 0.11600197509459177
Validation loss: 2.424357198321152

Epoch: 5| Step: 6
Training loss: 0.13174617678634312
Validation loss: 2.4093112008905626

Epoch: 5| Step: 7
Training loss: 0.20026477446029112
Validation loss: 2.4008497889719917

Epoch: 5| Step: 8
Training loss: 0.07813269458071843
Validation loss: 2.4120702596794885

Epoch: 5| Step: 9
Training loss: 0.07794573004477796
Validation loss: 2.4297384581128303

Epoch: 5| Step: 10
Training loss: 0.14099243295643646
Validation loss: 2.470445339767803

Epoch: 597| Step: 0
Training loss: 0.12088110157015858
Validation loss: 2.487126506728887

Epoch: 5| Step: 1
Training loss: 0.1288392369606157
Validation loss: 2.5166968694725944

Epoch: 5| Step: 2
Training loss: 0.10408474015089302
Validation loss: 2.5149209895913716

Epoch: 5| Step: 3
Training loss: 0.10752639021031302
Validation loss: 2.5017636364353186

Epoch: 5| Step: 4
Training loss: 0.1419153223210178
Validation loss: 2.476325721507076

Epoch: 5| Step: 5
Training loss: 0.16426353966234655
Validation loss: 2.497095233505206

Epoch: 5| Step: 6
Training loss: 0.055291348089642714
Validation loss: 2.4610872696114834

Epoch: 5| Step: 7
Training loss: 0.06733724878045483
Validation loss: 2.4502565841387884

Epoch: 5| Step: 8
Training loss: 0.1450811120497634
Validation loss: 2.466127054439875

Epoch: 5| Step: 9
Training loss: 0.09138516667925839
Validation loss: 2.4932249938278295

Epoch: 5| Step: 10
Training loss: 0.19846690177867782
Validation loss: 2.477904557849885

Epoch: 598| Step: 0
Training loss: 0.16763002041133604
Validation loss: 2.4354854717146153

Epoch: 5| Step: 1
Training loss: 0.12023453678990237
Validation loss: 2.470540837594324

Epoch: 5| Step: 2
Training loss: 0.13740125328992292
Validation loss: 2.4523288669917362

Epoch: 5| Step: 3
Training loss: 0.09135548004908464
Validation loss: 2.4620696266450337

Epoch: 5| Step: 4
Training loss: 0.1700837142895057
Validation loss: 2.481063550024923

Epoch: 5| Step: 5
Training loss: 0.11565292849122152
Validation loss: 2.4919095751857836

Epoch: 5| Step: 6
Training loss: 0.09194379574453858
Validation loss: 2.467405020078773

Epoch: 5| Step: 7
Training loss: 0.09876474677807211
Validation loss: 2.528922711217741

Epoch: 5| Step: 8
Training loss: 0.10942062635388862
Validation loss: 2.513233952403944

Epoch: 5| Step: 9
Training loss: 0.18327899085926563
Validation loss: 2.494726867950909

Epoch: 5| Step: 10
Training loss: 0.12649854557092718
Validation loss: 2.478035621679755

Epoch: 599| Step: 0
Training loss: 0.09948659323221455
Validation loss: 2.45203168531314

Epoch: 5| Step: 1
Training loss: 0.1443702858200634
Validation loss: 2.4504630728537604

Epoch: 5| Step: 2
Training loss: 0.12256734748369752
Validation loss: 2.415969340319198

Epoch: 5| Step: 3
Training loss: 0.16664313483013615
Validation loss: 2.3682059782137443

Epoch: 5| Step: 4
Training loss: 0.1905983104938898
Validation loss: 2.418476728145115

Epoch: 5| Step: 5
Training loss: 0.14408257150154444
Validation loss: 2.4351820651101455

Epoch: 5| Step: 6
Training loss: 0.13518448711085415
Validation loss: 2.4262848632604905

Epoch: 5| Step: 7
Training loss: 0.10188796548161409
Validation loss: 2.437424232329727

Epoch: 5| Step: 8
Training loss: 0.1005566193157439
Validation loss: 2.429340385366577

Epoch: 5| Step: 9
Training loss: 0.10362501033080018
Validation loss: 2.490767106159471

Epoch: 5| Step: 10
Training loss: 0.07870527772456638
Validation loss: 2.4773450470197558

Epoch: 600| Step: 0
Training loss: 0.09496906053549434
Validation loss: 2.4683289506980826

Epoch: 5| Step: 1
Training loss: 0.1807274578317845
Validation loss: 2.483697778423522

Epoch: 5| Step: 2
Training loss: 0.06655926465960656
Validation loss: 2.439924058645228

Epoch: 5| Step: 3
Training loss: 0.06742273751167968
Validation loss: 2.440371572794634

Epoch: 5| Step: 4
Training loss: 0.07229290911108863
Validation loss: 2.44257538265719

Epoch: 5| Step: 5
Training loss: 0.10246654852898528
Validation loss: 2.405081620986185

Epoch: 5| Step: 6
Training loss: 0.15707295181952347
Validation loss: 2.4261442611692843

Epoch: 5| Step: 7
Training loss: 0.13411589192860016
Validation loss: 2.394476514835521

Epoch: 5| Step: 8
Training loss: 0.0941482964235198
Validation loss: 2.446497081190948

Epoch: 5| Step: 9
Training loss: 0.13407672113071042
Validation loss: 2.4187513030021304

Epoch: 5| Step: 10
Training loss: 0.13543234942174504
Validation loss: 2.461768048428722

Epoch: 601| Step: 0
Training loss: 0.16361920321784382
Validation loss: 2.4592682989907826

Epoch: 5| Step: 1
Training loss: 0.10508326886573018
Validation loss: 2.4761319122406076

Epoch: 5| Step: 2
Training loss: 0.09148757650440184
Validation loss: 2.437582129774185

Epoch: 5| Step: 3
Training loss: 0.1817863966410167
Validation loss: 2.4573846545218947

Epoch: 5| Step: 4
Training loss: 0.13024717864112806
Validation loss: 2.4349902631474802

Epoch: 5| Step: 5
Training loss: 0.09586160053290559
Validation loss: 2.455432211031087

Epoch: 5| Step: 6
Training loss: 0.10052867759559352
Validation loss: 2.434164557023423

Epoch: 5| Step: 7
Training loss: 0.10376582857257603
Validation loss: 2.4451269258704587

Epoch: 5| Step: 8
Training loss: 0.09571241800771277
Validation loss: 2.4754960774554475

Epoch: 5| Step: 9
Training loss: 0.09347512758574816
Validation loss: 2.470273894535486

Epoch: 5| Step: 10
Training loss: 0.07140516272474598
Validation loss: 2.4648564920167084

Epoch: 602| Step: 0
Training loss: 0.0811562361627243
Validation loss: 2.4737906408982924

Epoch: 5| Step: 1
Training loss: 0.14462180136281402
Validation loss: 2.4745878244937867

Epoch: 5| Step: 2
Training loss: 0.08067759441916122
Validation loss: 2.507240334154503

Epoch: 5| Step: 3
Training loss: 0.10344556470906056
Validation loss: 2.4805302753203042

Epoch: 5| Step: 4
Training loss: 0.14150256280675955
Validation loss: 2.465328598095624

Epoch: 5| Step: 5
Training loss: 0.08962581469585855
Validation loss: 2.522186222033021

Epoch: 5| Step: 6
Training loss: 0.11354028747607539
Validation loss: 2.516790404520922

Epoch: 5| Step: 7
Training loss: 0.2158774304647968
Validation loss: 2.489474624015732

Epoch: 5| Step: 8
Training loss: 0.1675768538740273
Validation loss: 2.4756747403703274

Epoch: 5| Step: 9
Training loss: 0.12192396546624591
Validation loss: 2.4669942940764042

Epoch: 5| Step: 10
Training loss: 0.11020286213037446
Validation loss: 2.4609180143007765

Epoch: 603| Step: 0
Training loss: 0.09615534382350678
Validation loss: 2.400922746742798

Epoch: 5| Step: 1
Training loss: 0.08241256010382284
Validation loss: 2.450184294930728

Epoch: 5| Step: 2
Training loss: 0.10311693662128382
Validation loss: 2.4415740512730424

Epoch: 5| Step: 3
Training loss: 0.169628783924891
Validation loss: 2.426170834231187

Epoch: 5| Step: 4
Training loss: 0.16101950505193674
Validation loss: 2.440040559095363

Epoch: 5| Step: 5
Training loss: 0.11635385268512506
Validation loss: 2.454445681916709

Epoch: 5| Step: 6
Training loss: 0.07595801899415612
Validation loss: 2.440612927642616

Epoch: 5| Step: 7
Training loss: 0.092381885838448
Validation loss: 2.4599329619498658

Epoch: 5| Step: 8
Training loss: 0.129755387864125
Validation loss: 2.4773303678574012

Epoch: 5| Step: 9
Training loss: 0.08782007511817105
Validation loss: 2.475623593617699

Epoch: 5| Step: 10
Training loss: 0.17402864527589712
Validation loss: 2.467925488946172

Epoch: 604| Step: 0
Training loss: 0.1444324400509454
Validation loss: 2.428668065710773

Epoch: 5| Step: 1
Training loss: 0.12437507386780466
Validation loss: 2.4539309697479164

Epoch: 5| Step: 2
Training loss: 0.09725816652127978
Validation loss: 2.4623648191261753

Epoch: 5| Step: 3
Training loss: 0.08448709243283013
Validation loss: 2.45641666784052

Epoch: 5| Step: 4
Training loss: 0.11852327634546359
Validation loss: 2.4524942965064507

Epoch: 5| Step: 5
Training loss: 0.15175221603462885
Validation loss: 2.4365942875975564

Epoch: 5| Step: 6
Training loss: 0.08647385838687079
Validation loss: 2.4199519773749296

Epoch: 5| Step: 7
Training loss: 0.14163920461254928
Validation loss: 2.4198835152494373

Epoch: 5| Step: 8
Training loss: 0.11108778643127434
Validation loss: 2.43134594205064

Epoch: 5| Step: 9
Training loss: 0.11274337503958867
Validation loss: 2.4541805816054785

Epoch: 5| Step: 10
Training loss: 0.11115288745865791
Validation loss: 2.438651110475995

Epoch: 605| Step: 0
Training loss: 0.13749450894792278
Validation loss: 2.4506412909913475

Epoch: 5| Step: 1
Training loss: 0.17319310922015793
Validation loss: 2.456590765544989

Epoch: 5| Step: 2
Training loss: 0.15475288439767962
Validation loss: 2.4645186986524874

Epoch: 5| Step: 3
Training loss: 0.06256571682416003
Validation loss: 2.5092788736927507

Epoch: 5| Step: 4
Training loss: 0.1129888056460174
Validation loss: 2.495041093969777

Epoch: 5| Step: 5
Training loss: 0.10712017260188332
Validation loss: 2.4641550755516275

Epoch: 5| Step: 6
Training loss: 0.0656276597324167
Validation loss: 2.4846697112881015

Epoch: 5| Step: 7
Training loss: 0.14933193043754267
Validation loss: 2.4564367100241467

Epoch: 5| Step: 8
Training loss: 0.13362959944032765
Validation loss: 2.4671477859508286

Epoch: 5| Step: 9
Training loss: 0.0956131745955121
Validation loss: 2.4423173766079165

Epoch: 5| Step: 10
Training loss: 0.09074700380927875
Validation loss: 2.442305816504628

Epoch: 606| Step: 0
Training loss: 0.10789072716257174
Validation loss: 2.4459514027674296

Epoch: 5| Step: 1
Training loss: 0.13594749074155074
Validation loss: 2.426411968188691

Epoch: 5| Step: 2
Training loss: 0.10109149858865599
Validation loss: 2.4344088503625736

Epoch: 5| Step: 3
Training loss: 0.1108285251165439
Validation loss: 2.4249165225760043

Epoch: 5| Step: 4
Training loss: 0.0781672512483029
Validation loss: 2.4184875202138465

Epoch: 5| Step: 5
Training loss: 0.16983471750773796
Validation loss: 2.4170196291004915

Epoch: 5| Step: 6
Training loss: 0.1558203392573879
Validation loss: 2.4399730688174266

Epoch: 5| Step: 7
Training loss: 0.13033121906509365
Validation loss: 2.43788830409547

Epoch: 5| Step: 8
Training loss: 0.12161434464223611
Validation loss: 2.3996136802203947

Epoch: 5| Step: 9
Training loss: 0.1241715627990135
Validation loss: 2.40549596854968

Epoch: 5| Step: 10
Training loss: 0.08783915390101364
Validation loss: 2.4155068639564834

Epoch: 607| Step: 0
Training loss: 0.12937819899644462
Validation loss: 2.4046016801229175

Epoch: 5| Step: 1
Training loss: 0.12653782480379627
Validation loss: 2.4589140803781095

Epoch: 5| Step: 2
Training loss: 0.12755215243219156
Validation loss: 2.4644996953276035

Epoch: 5| Step: 3
Training loss: 0.07286839789212163
Validation loss: 2.4409294781862165

Epoch: 5| Step: 4
Training loss: 0.20090368597424077
Validation loss: 2.4745495517327787

Epoch: 5| Step: 5
Training loss: 0.09870953927599022
Validation loss: 2.5035123516685354

Epoch: 5| Step: 6
Training loss: 0.12276398974680863
Validation loss: 2.501532474604159

Epoch: 5| Step: 7
Training loss: 0.10846099251372936
Validation loss: 2.5019935288989745

Epoch: 5| Step: 8
Training loss: 0.10584277043904365
Validation loss: 2.530827863711645

Epoch: 5| Step: 9
Training loss: 0.08358776904483986
Validation loss: 2.5048699598900757

Epoch: 5| Step: 10
Training loss: 0.07886372827403874
Validation loss: 2.4553003167782865

Epoch: 608| Step: 0
Training loss: 0.11675723082422095
Validation loss: 2.4794332647539568

Epoch: 5| Step: 1
Training loss: 0.08862294704126877
Validation loss: 2.4519047970500947

Epoch: 5| Step: 2
Training loss: 0.08922815894570903
Validation loss: 2.47517579118234

Epoch: 5| Step: 3
Training loss: 0.1396372530533172
Validation loss: 2.4339744917763935

Epoch: 5| Step: 4
Training loss: 0.09842990550763328
Validation loss: 2.453666627740999

Epoch: 5| Step: 5
Training loss: 0.09990968500126045
Validation loss: 2.4423701243299316

Epoch: 5| Step: 6
Training loss: 0.08868650261134654
Validation loss: 2.442097535279652

Epoch: 5| Step: 7
Training loss: 0.15660630965655895
Validation loss: 2.471618751942279

Epoch: 5| Step: 8
Training loss: 0.10402729774300183
Validation loss: 2.4676468704063064

Epoch: 5| Step: 9
Training loss: 0.0737526525509378
Validation loss: 2.440165438845663

Epoch: 5| Step: 10
Training loss: 0.1558494201387468
Validation loss: 2.458774953156332

Epoch: 609| Step: 0
Training loss: 0.07910449705449654
Validation loss: 2.455166053501038

Epoch: 5| Step: 1
Training loss: 0.09357119934172642
Validation loss: 2.450878554017008

Epoch: 5| Step: 2
Training loss: 0.10098798270364547
Validation loss: 2.435875439875642

Epoch: 5| Step: 3
Training loss: 0.0872252230663104
Validation loss: 2.446957630252182

Epoch: 5| Step: 4
Training loss: 0.10625412596376974
Validation loss: 2.4259059169130976

Epoch: 5| Step: 5
Training loss: 0.1405109101654752
Validation loss: 2.4665459352506383

Epoch: 5| Step: 6
Training loss: 0.09717388710132278
Validation loss: 2.48004342804938

Epoch: 5| Step: 7
Training loss: 0.09760231913080407
Validation loss: 2.4728361872116102

Epoch: 5| Step: 8
Training loss: 0.22318411878686134
Validation loss: 2.4635968974249196

Epoch: 5| Step: 9
Training loss: 0.16967502289945133
Validation loss: 2.5082135395280667

Epoch: 5| Step: 10
Training loss: 0.08538609216513303
Validation loss: 2.5042710690478254

Epoch: 610| Step: 0
Training loss: 0.15792217739684314
Validation loss: 2.5007805139113106

Epoch: 5| Step: 1
Training loss: 0.12349750864888653
Validation loss: 2.4840758521435857

Epoch: 5| Step: 2
Training loss: 0.08200233381245917
Validation loss: 2.4217315631352494

Epoch: 5| Step: 3
Training loss: 0.1581854457160408
Validation loss: 2.4223698539505896

Epoch: 5| Step: 4
Training loss: 0.17403653862956234
Validation loss: 2.3945041341734643

Epoch: 5| Step: 5
Training loss: 0.15583482658933848
Validation loss: 2.4083689301625557

Epoch: 5| Step: 6
Training loss: 0.10472520355686103
Validation loss: 2.422557993581511

Epoch: 5| Step: 7
Training loss: 0.10456010803603707
Validation loss: 2.4515106935751945

Epoch: 5| Step: 8
Training loss: 0.1501180110077973
Validation loss: 2.4775144952757477

Epoch: 5| Step: 9
Training loss: 0.08124611551829311
Validation loss: 2.485459099226962

Epoch: 5| Step: 10
Training loss: 0.14092967354217026
Validation loss: 2.4770836476386737

Epoch: 611| Step: 0
Training loss: 0.14000081240895113
Validation loss: 2.495580910133627

Epoch: 5| Step: 1
Training loss: 0.11660282591194397
Validation loss: 2.451236531721586

Epoch: 5| Step: 2
Training loss: 0.09795071552232144
Validation loss: 2.415486698675183

Epoch: 5| Step: 3
Training loss: 0.1687622291054461
Validation loss: 2.404493834503959

Epoch: 5| Step: 4
Training loss: 0.16505277452557876
Validation loss: 2.4011595003992987

Epoch: 5| Step: 5
Training loss: 0.08601199789914514
Validation loss: 2.382023536522383

Epoch: 5| Step: 6
Training loss: 0.10157807395809378
Validation loss: 2.3947901555103197

Epoch: 5| Step: 7
Training loss: 0.09731074248119044
Validation loss: 2.393469543143565

Epoch: 5| Step: 8
Training loss: 0.10661039762413226
Validation loss: 2.3856322588776804

Epoch: 5| Step: 9
Training loss: 0.0933827568445939
Validation loss: 2.41359084227841

Epoch: 5| Step: 10
Training loss: 0.07311753155398805
Validation loss: 2.4385239328129065

Epoch: 612| Step: 0
Training loss: 0.12253534620861868
Validation loss: 2.4749908299595775

Epoch: 5| Step: 1
Training loss: 0.14465536124161812
Validation loss: 2.500552346114154

Epoch: 5| Step: 2
Training loss: 0.11493203538990057
Validation loss: 2.48072800486558

Epoch: 5| Step: 3
Training loss: 0.17635099478195798
Validation loss: 2.4936259341218237

Epoch: 5| Step: 4
Training loss: 0.1081909177965872
Validation loss: 2.4876821841932584

Epoch: 5| Step: 5
Training loss: 0.15819500678625997
Validation loss: 2.491121939524589

Epoch: 5| Step: 6
Training loss: 0.10413691026139212
Validation loss: 2.434671436231092

Epoch: 5| Step: 7
Training loss: 0.08009848103334641
Validation loss: 2.432045272050374

Epoch: 5| Step: 8
Training loss: 0.15449813199572904
Validation loss: 2.405929727898633

Epoch: 5| Step: 9
Training loss: 0.06155136397983415
Validation loss: 2.4162082981765822

Epoch: 5| Step: 10
Training loss: 0.12886626172434218
Validation loss: 2.3786657095141597

Epoch: 613| Step: 0
Training loss: 0.10920829926918636
Validation loss: 2.4006853583774

Epoch: 5| Step: 1
Training loss: 0.0621006789357557
Validation loss: 2.3759277163933623

Epoch: 5| Step: 2
Training loss: 0.12974686068391877
Validation loss: 2.4436511320998004

Epoch: 5| Step: 3
Training loss: 0.14588496594108002
Validation loss: 2.4201198064802565

Epoch: 5| Step: 4
Training loss: 0.14136352921174564
Validation loss: 2.42847849925832

Epoch: 5| Step: 5
Training loss: 0.08976215824806646
Validation loss: 2.460569670846518

Epoch: 5| Step: 6
Training loss: 0.07337794120748986
Validation loss: 2.5065439418835456

Epoch: 5| Step: 7
Training loss: 0.16147898277909914
Validation loss: 2.480458292714204

Epoch: 5| Step: 8
Training loss: 0.13330311476233478
Validation loss: 2.4601374729327117

Epoch: 5| Step: 9
Training loss: 0.12121074162626283
Validation loss: 2.445204614118078

Epoch: 5| Step: 10
Training loss: 0.13896357387624658
Validation loss: 2.3863212381030747

Epoch: 614| Step: 0
Training loss: 0.11151693462112203
Validation loss: 2.393047444009448

Epoch: 5| Step: 1
Training loss: 0.09939572852851514
Validation loss: 2.36499463634433

Epoch: 5| Step: 2
Training loss: 0.09886471707962652
Validation loss: 2.3831991300597757

Epoch: 5| Step: 3
Training loss: 0.12881660957064733
Validation loss: 2.3895168311031827

Epoch: 5| Step: 4
Training loss: 0.08920100677014561
Validation loss: 2.369975026116222

Epoch: 5| Step: 5
Training loss: 0.11526381391364453
Validation loss: 2.3835684887115702

Epoch: 5| Step: 6
Training loss: 0.12163044069172925
Validation loss: 2.3816584328254256

Epoch: 5| Step: 7
Training loss: 0.14490517368373504
Validation loss: 2.3976567151781865

Epoch: 5| Step: 8
Training loss: 0.1920046211477559
Validation loss: 2.3653045543897

Epoch: 5| Step: 9
Training loss: 0.06253330267330445
Validation loss: 2.4199338884509074

Epoch: 5| Step: 10
Training loss: 0.11553729781076688
Validation loss: 2.395971590808312

Epoch: 615| Step: 0
Training loss: 0.11874231216365892
Validation loss: 2.4102444659439746

Epoch: 5| Step: 1
Training loss: 0.13789130526799018
Validation loss: 2.424980417258572

Epoch: 5| Step: 2
Training loss: 0.15228475137392308
Validation loss: 2.4353849496964517

Epoch: 5| Step: 3
Training loss: 0.15156639280924034
Validation loss: 2.4406583804972417

Epoch: 5| Step: 4
Training loss: 0.075427140771237
Validation loss: 2.4180910621356655

Epoch: 5| Step: 5
Training loss: 0.0881309112170951
Validation loss: 2.405322762014638

Epoch: 5| Step: 6
Training loss: 0.10526468704177201
Validation loss: 2.4142321699452616

Epoch: 5| Step: 7
Training loss: 0.11101999640666817
Validation loss: 2.400694452414744

Epoch: 5| Step: 8
Training loss: 0.14875479090412455
Validation loss: 2.3948088828939347

Epoch: 5| Step: 9
Training loss: 0.05567382216641713
Validation loss: 2.4151829690099067

Epoch: 5| Step: 10
Training loss: 0.15419755225703413
Validation loss: 2.420432916249021

Epoch: 616| Step: 0
Training loss: 0.07599960923917914
Validation loss: 2.4432330418188393

Epoch: 5| Step: 1
Training loss: 0.07168949681135083
Validation loss: 2.4449145995115615

Epoch: 5| Step: 2
Training loss: 0.14229923563505298
Validation loss: 2.4485618004766865

Epoch: 5| Step: 3
Training loss: 0.08620929274396595
Validation loss: 2.449771366120264

Epoch: 5| Step: 4
Training loss: 0.11047889317586503
Validation loss: 2.4618769901834505

Epoch: 5| Step: 5
Training loss: 0.13991804706613148
Validation loss: 2.4781326084237154

Epoch: 5| Step: 6
Training loss: 0.13598002037335383
Validation loss: 2.415082479819715

Epoch: 5| Step: 7
Training loss: 0.10586295368156147
Validation loss: 2.476800865895556

Epoch: 5| Step: 8
Training loss: 0.13743290347834636
Validation loss: 2.431985834338027

Epoch: 5| Step: 9
Training loss: 0.08906779859073659
Validation loss: 2.4479475614177346

Epoch: 5| Step: 10
Training loss: 0.1128315797585119
Validation loss: 2.408375392029509

Epoch: 617| Step: 0
Training loss: 0.0780648417121607
Validation loss: 2.4421297346614037

Epoch: 5| Step: 1
Training loss: 0.14455865909390322
Validation loss: 2.435176074948931

Epoch: 5| Step: 2
Training loss: 0.09304791053560874
Validation loss: 2.438308169557278

Epoch: 5| Step: 3
Training loss: 0.07804747549748166
Validation loss: 2.4205720686765284

Epoch: 5| Step: 4
Training loss: 0.17016650819638737
Validation loss: 2.4612398070308044

Epoch: 5| Step: 5
Training loss: 0.18955258580350667
Validation loss: 2.4720434337196804

Epoch: 5| Step: 6
Training loss: 0.09477495157021221
Validation loss: 2.470823261388691

Epoch: 5| Step: 7
Training loss: 0.07625166980583976
Validation loss: 2.4688752026973266

Epoch: 5| Step: 8
Training loss: 0.11843383354359768
Validation loss: 2.4877275731262216

Epoch: 5| Step: 9
Training loss: 0.10779892034286345
Validation loss: 2.46472384742316

Epoch: 5| Step: 10
Training loss: 0.0918455958429143
Validation loss: 2.4581691053737855

Epoch: 618| Step: 0
Training loss: 0.07035412152543247
Validation loss: 2.4702024391643382

Epoch: 5| Step: 1
Training loss: 0.08856519802468817
Validation loss: 2.472811107253926

Epoch: 5| Step: 2
Training loss: 0.1255272311312068
Validation loss: 2.470966377972531

Epoch: 5| Step: 3
Training loss: 0.14369981268014093
Validation loss: 2.466934534512168

Epoch: 5| Step: 4
Training loss: 0.10754718407593851
Validation loss: 2.448067119079323

Epoch: 5| Step: 5
Training loss: 0.2171949392183586
Validation loss: 2.4844435764082924

Epoch: 5| Step: 6
Training loss: 0.08919860537263596
Validation loss: 2.4716331517841788

Epoch: 5| Step: 7
Training loss: 0.09590464900113944
Validation loss: 2.4437157444225868

Epoch: 5| Step: 8
Training loss: 0.11495076856833267
Validation loss: 2.466411971021927

Epoch: 5| Step: 9
Training loss: 0.10929357103094366
Validation loss: 2.43495803094644

Epoch: 5| Step: 10
Training loss: 0.07353600695296549
Validation loss: 2.4834989020825633

Epoch: 619| Step: 0
Training loss: 0.16643159588237738
Validation loss: 2.440220802797416

Epoch: 5| Step: 1
Training loss: 0.06265683909921702
Validation loss: 2.4557755019760394

Epoch: 5| Step: 2
Training loss: 0.13816496383118465
Validation loss: 2.4460612145530134

Epoch: 5| Step: 3
Training loss: 0.14478063975913047
Validation loss: 2.4399224500152004

Epoch: 5| Step: 4
Training loss: 0.12975498592208762
Validation loss: 2.4579437855183692

Epoch: 5| Step: 5
Training loss: 0.11161748191082833
Validation loss: 2.486521005501595

Epoch: 5| Step: 6
Training loss: 0.09273665853579573
Validation loss: 2.4346567467021294

Epoch: 5| Step: 7
Training loss: 0.12294613029109581
Validation loss: 2.4429715002963928

Epoch: 5| Step: 8
Training loss: 0.11812344948694593
Validation loss: 2.423363035356019

Epoch: 5| Step: 9
Training loss: 0.0928059972546522
Validation loss: 2.3844723309772866

Epoch: 5| Step: 10
Training loss: 0.10101696364599279
Validation loss: 2.385446899612238

Epoch: 620| Step: 0
Training loss: 0.14053417292603262
Validation loss: 2.4009401652615905

Epoch: 5| Step: 1
Training loss: 0.08520734341296254
Validation loss: 2.373999604612786

Epoch: 5| Step: 2
Training loss: 0.09566872328763287
Validation loss: 2.3997971280212163

Epoch: 5| Step: 3
Training loss: 0.11865746914817715
Validation loss: 2.41109533471904

Epoch: 5| Step: 4
Training loss: 0.16978218102335907
Validation loss: 2.4606969415976367

Epoch: 5| Step: 5
Training loss: 0.11942387741752904
Validation loss: 2.458918858566055

Epoch: 5| Step: 6
Training loss: 0.09381412260277545
Validation loss: 2.5139795393247613

Epoch: 5| Step: 7
Training loss: 0.12920573874793925
Validation loss: 2.504873130575097

Epoch: 5| Step: 8
Training loss: 0.13682302857844444
Validation loss: 2.5208241703989325

Epoch: 5| Step: 9
Training loss: 0.14556370372200805
Validation loss: 2.5010318872270214

Epoch: 5| Step: 10
Training loss: 0.10155847431420723
Validation loss: 2.457775493447247

Epoch: 621| Step: 0
Training loss: 0.17258771058103786
Validation loss: 2.442457880025232

Epoch: 5| Step: 1
Training loss: 0.11753755975449125
Validation loss: 2.433152496365521

Epoch: 5| Step: 2
Training loss: 0.11772598683497931
Validation loss: 2.4085021163758205

Epoch: 5| Step: 3
Training loss: 0.09846349384337304
Validation loss: 2.3967017523730534

Epoch: 5| Step: 4
Training loss: 0.1403917855696134
Validation loss: 2.3727223928527534

Epoch: 5| Step: 5
Training loss: 0.10830403418510043
Validation loss: 2.384241381956493

Epoch: 5| Step: 6
Training loss: 0.12236911823693285
Validation loss: 2.399028979177747

Epoch: 5| Step: 7
Training loss: 0.11023703683441599
Validation loss: 2.3977667142515284

Epoch: 5| Step: 8
Training loss: 0.1450260559052798
Validation loss: 2.43114595296806

Epoch: 5| Step: 9
Training loss: 0.09985675200275093
Validation loss: 2.489673731453265

Epoch: 5| Step: 10
Training loss: 0.10764267510588038
Validation loss: 2.454724014002399

Epoch: 622| Step: 0
Training loss: 0.10871669084468977
Validation loss: 2.4782560559370856

Epoch: 5| Step: 1
Training loss: 0.14152741957518186
Validation loss: 2.4759498822666166

Epoch: 5| Step: 2
Training loss: 0.10371171624130153
Validation loss: 2.4925675453571046

Epoch: 5| Step: 3
Training loss: 0.10292150385279934
Validation loss: 2.472781352368678

Epoch: 5| Step: 4
Training loss: 0.1647836921539138
Validation loss: 2.4288392221776807

Epoch: 5| Step: 5
Training loss: 0.1206694522047898
Validation loss: 2.4348413710167685

Epoch: 5| Step: 6
Training loss: 0.10064397452326485
Validation loss: 2.4041658604055502

Epoch: 5| Step: 7
Training loss: 0.10186115698872886
Validation loss: 2.37192268030207

Epoch: 5| Step: 8
Training loss: 0.15319962215941912
Validation loss: 2.376525764450823

Epoch: 5| Step: 9
Training loss: 0.11041649452531939
Validation loss: 2.405780131086878

Epoch: 5| Step: 10
Training loss: 0.16160389212260895
Validation loss: 2.416792026856749

Epoch: 623| Step: 0
Training loss: 0.08104671875721844
Validation loss: 2.441777754937465

Epoch: 5| Step: 1
Training loss: 0.11336736447831323
Validation loss: 2.4043263061307645

Epoch: 5| Step: 2
Training loss: 0.16851570102865018
Validation loss: 2.458518583542297

Epoch: 5| Step: 3
Training loss: 0.10252944810389084
Validation loss: 2.4686582087955986

Epoch: 5| Step: 4
Training loss: 0.195560202881637
Validation loss: 2.4724926381446517

Epoch: 5| Step: 5
Training loss: 0.14378944975187577
Validation loss: 2.4912180967581765

Epoch: 5| Step: 6
Training loss: 0.11472705926680438
Validation loss: 2.4683440437884117

Epoch: 5| Step: 7
Training loss: 0.13028474155321482
Validation loss: 2.455540265618024

Epoch: 5| Step: 8
Training loss: 0.0822470585067356
Validation loss: 2.46617814424119

Epoch: 5| Step: 9
Training loss: 0.12541922661976893
Validation loss: 2.4462073419079866

Epoch: 5| Step: 10
Training loss: 0.1001997357409004
Validation loss: 2.398230154070794

Epoch: 624| Step: 0
Training loss: 0.11683160861842938
Validation loss: 2.3917255472898336

Epoch: 5| Step: 1
Training loss: 0.09664339771625932
Validation loss: 2.4093393151987677

Epoch: 5| Step: 2
Training loss: 0.12899877377738633
Validation loss: 2.3706640430676402

Epoch: 5| Step: 3
Training loss: 0.1650754786837586
Validation loss: 2.3975100848463926

Epoch: 5| Step: 4
Training loss: 0.0900499527607285
Validation loss: 2.4016001627954147

Epoch: 5| Step: 5
Training loss: 0.14613745617008114
Validation loss: 2.4355064108672853

Epoch: 5| Step: 6
Training loss: 0.14313655734770764
Validation loss: 2.433546813608079

Epoch: 5| Step: 7
Training loss: 0.13964859088809253
Validation loss: 2.442051489835512

Epoch: 5| Step: 8
Training loss: 0.14207774369673082
Validation loss: 2.450190678953755

Epoch: 5| Step: 9
Training loss: 0.11941725633971542
Validation loss: 2.4767660870753683

Epoch: 5| Step: 10
Training loss: 0.12907368449871245
Validation loss: 2.476995460637015

Epoch: 625| Step: 0
Training loss: 0.13184544564327874
Validation loss: 2.4563743109172798

Epoch: 5| Step: 1
Training loss: 0.1263456261354235
Validation loss: 2.4168228025426

Epoch: 5| Step: 2
Training loss: 0.13508527275708615
Validation loss: 2.3657159359187134

Epoch: 5| Step: 3
Training loss: 0.1340610912889214
Validation loss: 2.3879084762904674

Epoch: 5| Step: 4
Training loss: 0.1848517094379336
Validation loss: 2.358957833050169

Epoch: 5| Step: 5
Training loss: 0.1333658108669523
Validation loss: 2.352881536453276

Epoch: 5| Step: 6
Training loss: 0.09600012781431462
Validation loss: 2.399844431257409

Epoch: 5| Step: 7
Training loss: 0.12148385124461616
Validation loss: 2.4116915900943874

Epoch: 5| Step: 8
Training loss: 0.07347918630982228
Validation loss: 2.420352974362998

Epoch: 5| Step: 9
Training loss: 0.1073110528980545
Validation loss: 2.479997747040161

Epoch: 5| Step: 10
Training loss: 0.16205242604421755
Validation loss: 2.4813154309540173

Epoch: 626| Step: 0
Training loss: 0.11544092707769611
Validation loss: 2.4553149488425037

Epoch: 5| Step: 1
Training loss: 0.12956588483392284
Validation loss: 2.457696598269128

Epoch: 5| Step: 2
Training loss: 0.10927250862504073
Validation loss: 2.4519211204507516

Epoch: 5| Step: 3
Training loss: 0.12209771420965952
Validation loss: 2.444029479479903

Epoch: 5| Step: 4
Training loss: 0.08192224867322798
Validation loss: 2.4271458658183986

Epoch: 5| Step: 5
Training loss: 0.17232438964385624
Validation loss: 2.3871031128212477

Epoch: 5| Step: 6
Training loss: 0.15677822946821263
Validation loss: 2.3316315745958724

Epoch: 5| Step: 7
Training loss: 0.16268777497818254
Validation loss: 2.3297588046827467

Epoch: 5| Step: 8
Training loss: 0.09999389387651259
Validation loss: 2.360411574576675

Epoch: 5| Step: 9
Training loss: 0.1222924842826095
Validation loss: 2.351613758899265

Epoch: 5| Step: 10
Training loss: 0.1301382321162814
Validation loss: 2.414587164371156

Epoch: 627| Step: 0
Training loss: 0.12755497808301244
Validation loss: 2.4524837993834225

Epoch: 5| Step: 1
Training loss: 0.15001489098465368
Validation loss: 2.458564101605826

Epoch: 5| Step: 2
Training loss: 0.19669573206079718
Validation loss: 2.4575598598214277

Epoch: 5| Step: 3
Training loss: 0.06811197334605047
Validation loss: 2.4574430934933753

Epoch: 5| Step: 4
Training loss: 0.10973692939731403
Validation loss: 2.421127759791109

Epoch: 5| Step: 5
Training loss: 0.08933426131096689
Validation loss: 2.431447873097103

Epoch: 5| Step: 6
Training loss: 0.14520838991868254
Validation loss: 2.4213055574012423

Epoch: 5| Step: 7
Training loss: 0.14008296374182969
Validation loss: 2.4132178424786734

Epoch: 5| Step: 8
Training loss: 0.14282642586672561
Validation loss: 2.4341387142077275

Epoch: 5| Step: 9
Training loss: 0.1765296791595621
Validation loss: 2.4513757725226974

Epoch: 5| Step: 10
Training loss: 0.12403372849549202
Validation loss: 2.458951303707526

Epoch: 628| Step: 0
Training loss: 0.11406754685040633
Validation loss: 2.4409236880281178

Epoch: 5| Step: 1
Training loss: 0.12062453686793269
Validation loss: 2.4339243196332316

Epoch: 5| Step: 2
Training loss: 0.16804100855470586
Validation loss: 2.4561058563452005

Epoch: 5| Step: 3
Training loss: 0.13390083934130567
Validation loss: 2.4733044923611573

Epoch: 5| Step: 4
Training loss: 0.1889984731789129
Validation loss: 2.4548362112631543

Epoch: 5| Step: 5
Training loss: 0.15444327905286787
Validation loss: 2.455383324624019

Epoch: 5| Step: 6
Training loss: 0.1957346359742073
Validation loss: 2.440886646655457

Epoch: 5| Step: 7
Training loss: 0.12786824447093362
Validation loss: 2.445022691116883

Epoch: 5| Step: 8
Training loss: 0.12514523175491185
Validation loss: 2.372728792431167

Epoch: 5| Step: 9
Training loss: 0.11401558737605863
Validation loss: 2.3983629060164087

Epoch: 5| Step: 10
Training loss: 0.11370354896058532
Validation loss: 2.397336968621773

Epoch: 629| Step: 0
Training loss: 0.08685059051419294
Validation loss: 2.39228000949204

Epoch: 5| Step: 1
Training loss: 0.12606793424158858
Validation loss: 2.3775236029425035

Epoch: 5| Step: 2
Training loss: 0.17274312211572673
Validation loss: 2.325757231220039

Epoch: 5| Step: 3
Training loss: 0.16891260326586727
Validation loss: 2.377524435375974

Epoch: 5| Step: 4
Training loss: 0.1614505871073343
Validation loss: 2.4291084696139116

Epoch: 5| Step: 5
Training loss: 0.14414762154322847
Validation loss: 2.4101956633630968

Epoch: 5| Step: 6
Training loss: 0.18555896117349055
Validation loss: 2.434607397322646

Epoch: 5| Step: 7
Training loss: 0.15487432468627302
Validation loss: 2.4675338343569826

Epoch: 5| Step: 8
Training loss: 0.10438795327711813
Validation loss: 2.4612104065016216

Epoch: 5| Step: 9
Training loss: 0.10045229728145294
Validation loss: 2.4243320477595134

Epoch: 5| Step: 10
Training loss: 0.12027133571848679
Validation loss: 2.399701260274891

Epoch: 630| Step: 0
Training loss: 0.08629700662992082
Validation loss: 2.4308628467748328

Epoch: 5| Step: 1
Training loss: 0.12742023365219599
Validation loss: 2.425793857960137

Epoch: 5| Step: 2
Training loss: 0.12841236261815145
Validation loss: 2.3998741333097655

Epoch: 5| Step: 3
Training loss: 0.15206342974063794
Validation loss: 2.399528227347135

Epoch: 5| Step: 4
Training loss: 0.10785434107947191
Validation loss: 2.4128616521000166

Epoch: 5| Step: 5
Training loss: 0.0920511589228707
Validation loss: 2.4436441796873076

Epoch: 5| Step: 6
Training loss: 0.10302737990826158
Validation loss: 2.4359952837837775

Epoch: 5| Step: 7
Training loss: 0.1732789967083422
Validation loss: 2.458709919114942

Epoch: 5| Step: 8
Training loss: 0.11417547748045899
Validation loss: 2.4596601471814794

Epoch: 5| Step: 9
Training loss: 0.10160651536988885
Validation loss: 2.452720260176442

Epoch: 5| Step: 10
Training loss: 0.15308522466876612
Validation loss: 2.4368378976050216

Epoch: 631| Step: 0
Training loss: 0.10511150609840657
Validation loss: 2.409364042367181

Epoch: 5| Step: 1
Training loss: 0.0875088266833787
Validation loss: 2.4299775922359848

Epoch: 5| Step: 2
Training loss: 0.09590570263039862
Validation loss: 2.4160025373241942

Epoch: 5| Step: 3
Training loss: 0.1351624740975575
Validation loss: 2.3365121249142047

Epoch: 5| Step: 4
Training loss: 0.13748398248621008
Validation loss: 2.414700394203432

Epoch: 5| Step: 5
Training loss: 0.11852004677904407
Validation loss: 2.446448550143314

Epoch: 5| Step: 6
Training loss: 0.16081162432703863
Validation loss: 2.41766037063651

Epoch: 5| Step: 7
Training loss: 0.14775191266012766
Validation loss: 2.4395810381597434

Epoch: 5| Step: 8
Training loss: 0.12256641287006852
Validation loss: 2.4816955256102435

Epoch: 5| Step: 9
Training loss: 0.12850036443526916
Validation loss: 2.5043187359901693

Epoch: 5| Step: 10
Training loss: 0.1847226962005379
Validation loss: 2.5047131538644627

Epoch: 632| Step: 0
Training loss: 0.15892864393956657
Validation loss: 2.53496449829246

Epoch: 5| Step: 1
Training loss: 0.12971472799048023
Validation loss: 2.501191564871551

Epoch: 5| Step: 2
Training loss: 0.12268694202055243
Validation loss: 2.49460141454164

Epoch: 5| Step: 3
Training loss: 0.13946303484671296
Validation loss: 2.4464282574186624

Epoch: 5| Step: 4
Training loss: 0.11739856071640863
Validation loss: 2.4479932461927993

Epoch: 5| Step: 5
Training loss: 0.14393056589519176
Validation loss: 2.406943899975436

Epoch: 5| Step: 6
Training loss: 0.14237595948523124
Validation loss: 2.3800059503765456

Epoch: 5| Step: 7
Training loss: 0.14961955332184038
Validation loss: 2.4020248071975727

Epoch: 5| Step: 8
Training loss: 0.10920017609767636
Validation loss: 2.410584030391321

Epoch: 5| Step: 9
Training loss: 0.1400303320510903
Validation loss: 2.468396856414778

Epoch: 5| Step: 10
Training loss: 0.07800073874296438
Validation loss: 2.5017587873924008

Epoch: 633| Step: 0
Training loss: 0.18197156639874137
Validation loss: 2.4897988843459844

Epoch: 5| Step: 1
Training loss: 0.07589007790018587
Validation loss: 2.532320302447005

Epoch: 5| Step: 2
Training loss: 0.1486756773004905
Validation loss: 2.5320345929763226

Epoch: 5| Step: 3
Training loss: 0.1151208399078997
Validation loss: 2.5050877432565466

Epoch: 5| Step: 4
Training loss: 0.0973973992123243
Validation loss: 2.4746365112564517

Epoch: 5| Step: 5
Training loss: 0.14643536701553864
Validation loss: 2.419370716053127

Epoch: 5| Step: 6
Training loss: 0.08306341552911528
Validation loss: 2.417550154264751

Epoch: 5| Step: 7
Training loss: 0.18757695367297253
Validation loss: 2.391087510827973

Epoch: 5| Step: 8
Training loss: 0.17112238788004358
Validation loss: 2.440931975469918

Epoch: 5| Step: 9
Training loss: 0.1253798866427366
Validation loss: 2.4605181447251643

Epoch: 5| Step: 10
Training loss: 0.10708519888139102
Validation loss: 2.45488596123757

Epoch: 634| Step: 0
Training loss: 0.13183695474867962
Validation loss: 2.453731253203093

Epoch: 5| Step: 1
Training loss: 0.12741968547125684
Validation loss: 2.4588742968852606

Epoch: 5| Step: 2
Training loss: 0.13434506182619088
Validation loss: 2.491920146449579

Epoch: 5| Step: 3
Training loss: 0.18940240633346284
Validation loss: 2.469250367790875

Epoch: 5| Step: 4
Training loss: 0.10766715743309305
Validation loss: 2.4476263390316606

Epoch: 5| Step: 5
Training loss: 0.07877776903302583
Validation loss: 2.43823108799909

Epoch: 5| Step: 6
Training loss: 0.11702514766857175
Validation loss: 2.4399915140304653

Epoch: 5| Step: 7
Training loss: 0.15374758282366324
Validation loss: 2.4206181848580237

Epoch: 5| Step: 8
Training loss: 0.0701028227370245
Validation loss: 2.4422746219021985

Epoch: 5| Step: 9
Training loss: 0.10979414565957021
Validation loss: 2.4487452842844846

Epoch: 5| Step: 10
Training loss: 0.14761107424786332
Validation loss: 2.4506440579510316

Epoch: 635| Step: 0
Training loss: 0.12138569540634349
Validation loss: 2.4656243226633063

Epoch: 5| Step: 1
Training loss: 0.1462551994499875
Validation loss: 2.4936849332476143

Epoch: 5| Step: 2
Training loss: 0.059821517682847915
Validation loss: 2.4857726336932413

Epoch: 5| Step: 3
Training loss: 0.14378088691846327
Validation loss: 2.4837097868584093

Epoch: 5| Step: 4
Training loss: 0.11515624420290224
Validation loss: 2.5137963267083183

Epoch: 5| Step: 5
Training loss: 0.14152031244612345
Validation loss: 2.4940686266209924

Epoch: 5| Step: 6
Training loss: 0.08922680205505133
Validation loss: 2.478607696558445

Epoch: 5| Step: 7
Training loss: 0.12813582083900882
Validation loss: 2.529133752543598

Epoch: 5| Step: 8
Training loss: 0.06033017233136327
Validation loss: 2.471963304502958

Epoch: 5| Step: 9
Training loss: 0.13768551838990392
Validation loss: 2.4930890348302537

Epoch: 5| Step: 10
Training loss: 0.052116869272447915
Validation loss: 2.4680555100700015

Epoch: 636| Step: 0
Training loss: 0.09991420589660142
Validation loss: 2.5138030820419037

Epoch: 5| Step: 1
Training loss: 0.0827187920025516
Validation loss: 2.4748101494739356

Epoch: 5| Step: 2
Training loss: 0.07470562877460565
Validation loss: 2.4668358614507304

Epoch: 5| Step: 3
Training loss: 0.1369419115832342
Validation loss: 2.4675520117334084

Epoch: 5| Step: 4
Training loss: 0.1552665876880985
Validation loss: 2.4579838281304713

Epoch: 5| Step: 5
Training loss: 0.06818873360677935
Validation loss: 2.485448752158859

Epoch: 5| Step: 6
Training loss: 0.09633732876273034
Validation loss: 2.5053871808466197

Epoch: 5| Step: 7
Training loss: 0.08513320525730689
Validation loss: 2.4886383811579385

Epoch: 5| Step: 8
Training loss: 0.16607379455225108
Validation loss: 2.464028138441916

Epoch: 5| Step: 9
Training loss: 0.12861124151490788
Validation loss: 2.4731157516740323

Epoch: 5| Step: 10
Training loss: 0.11989577363477005
Validation loss: 2.4697425127575703

Epoch: 637| Step: 0
Training loss: 0.09309158985171025
Validation loss: 2.4757219702795057

Epoch: 5| Step: 1
Training loss: 0.11718911328794708
Validation loss: 2.4700032307845854

Epoch: 5| Step: 2
Training loss: 0.10543847090919121
Validation loss: 2.4623960215793836

Epoch: 5| Step: 3
Training loss: 0.09219042644058455
Validation loss: 2.452502305733018

Epoch: 5| Step: 4
Training loss: 0.10465464485642695
Validation loss: 2.4649970304998785

Epoch: 5| Step: 5
Training loss: 0.12408054343709182
Validation loss: 2.4382131567667398

Epoch: 5| Step: 6
Training loss: 0.0765688224536963
Validation loss: 2.466084180270178

Epoch: 5| Step: 7
Training loss: 0.08608551716427094
Validation loss: 2.4385734194986446

Epoch: 5| Step: 8
Training loss: 0.12487248905743743
Validation loss: 2.4313034182922824

Epoch: 5| Step: 9
Training loss: 0.14461543878859476
Validation loss: 2.435606704728206

Epoch: 5| Step: 10
Training loss: 0.08084941056263137
Validation loss: 2.44608309813332

Epoch: 638| Step: 0
Training loss: 0.14568113079206094
Validation loss: 2.4413857105990857

Epoch: 5| Step: 1
Training loss: 0.0874168208189344
Validation loss: 2.481865022877202

Epoch: 5| Step: 2
Training loss: 0.0644748535521413
Validation loss: 2.4495956639322323

Epoch: 5| Step: 3
Training loss: 0.08469214066849921
Validation loss: 2.4491096303883384

Epoch: 5| Step: 4
Training loss: 0.1837175438885615
Validation loss: 2.406858451986343

Epoch: 5| Step: 5
Training loss: 0.07326483694186804
Validation loss: 2.4551761731717545

Epoch: 5| Step: 6
Training loss: 0.10728163668437533
Validation loss: 2.4126392638212786

Epoch: 5| Step: 7
Training loss: 0.13364607416499444
Validation loss: 2.4121933534067703

Epoch: 5| Step: 8
Training loss: 0.05698450496563056
Validation loss: 2.4088015314729927

Epoch: 5| Step: 9
Training loss: 0.09245336431472645
Validation loss: 2.4175635294205184

Epoch: 5| Step: 10
Training loss: 0.1005057367005948
Validation loss: 2.4190745765794963

Epoch: 639| Step: 0
Training loss: 0.09431452952508665
Validation loss: 2.4181580812399215

Epoch: 5| Step: 1
Training loss: 0.07831798202776492
Validation loss: 2.418151135044923

Epoch: 5| Step: 2
Training loss: 0.11820115539715056
Validation loss: 2.451068876303971

Epoch: 5| Step: 3
Training loss: 0.1086911639324822
Validation loss: 2.4714571081418586

Epoch: 5| Step: 4
Training loss: 0.06513402810323049
Validation loss: 2.452019195536106

Epoch: 5| Step: 5
Training loss: 0.1744839907211782
Validation loss: 2.4706223717483597

Epoch: 5| Step: 6
Training loss: 0.08662850639597412
Validation loss: 2.471258602064393

Epoch: 5| Step: 7
Training loss: 0.16289951611228037
Validation loss: 2.4801770539450176

Epoch: 5| Step: 8
Training loss: 0.102395183801127
Validation loss: 2.4409136893915537

Epoch: 5| Step: 9
Training loss: 0.07880706773814401
Validation loss: 2.4240220285261675

Epoch: 5| Step: 10
Training loss: 0.10297470194237923
Validation loss: 2.421559497237364

Epoch: 640| Step: 0
Training loss: 0.09798810839091264
Validation loss: 2.3904475999415316

Epoch: 5| Step: 1
Training loss: 0.09806299381058832
Validation loss: 2.4115300084266926

Epoch: 5| Step: 2
Training loss: 0.1173192118514147
Validation loss: 2.391113115736287

Epoch: 5| Step: 3
Training loss: 0.11186014177976354
Validation loss: 2.4235109116014995

Epoch: 5| Step: 4
Training loss: 0.17233711130458487
Validation loss: 2.4644971680933216

Epoch: 5| Step: 5
Training loss: 0.0955472474703075
Validation loss: 2.4580542838966406

Epoch: 5| Step: 6
Training loss: 0.08703197560273272
Validation loss: 2.4965757750966087

Epoch: 5| Step: 7
Training loss: 0.1136286768155757
Validation loss: 2.494526282113297

Epoch: 5| Step: 8
Training loss: 0.12605533059461194
Validation loss: 2.4450492005538087

Epoch: 5| Step: 9
Training loss: 0.1135475629258383
Validation loss: 2.472493970515587

Epoch: 5| Step: 10
Training loss: 0.11803497404046637
Validation loss: 2.4586840428601033

Epoch: 641| Step: 0
Training loss: 0.07688812812498372
Validation loss: 2.4800192329628197

Epoch: 5| Step: 1
Training loss: 0.14504987867952523
Validation loss: 2.4576989134441236

Epoch: 5| Step: 2
Training loss: 0.07974205790744916
Validation loss: 2.4174153116366885

Epoch: 5| Step: 3
Training loss: 0.11667307955992513
Validation loss: 2.4008566624262264

Epoch: 5| Step: 4
Training loss: 0.07216244174404657
Validation loss: 2.4075889819947194

Epoch: 5| Step: 5
Training loss: 0.1667581167015005
Validation loss: 2.41915177098074

Epoch: 5| Step: 6
Training loss: 0.07975474049827408
Validation loss: 2.385326731114395

Epoch: 5| Step: 7
Training loss: 0.09402193426428986
Validation loss: 2.3836786335027136

Epoch: 5| Step: 8
Training loss: 0.07857340043960083
Validation loss: 2.394100896292583

Epoch: 5| Step: 9
Training loss: 0.11338826583620076
Validation loss: 2.416082727140037

Epoch: 5| Step: 10
Training loss: 0.1192788510424877
Validation loss: 2.405768499847257

Epoch: 642| Step: 0
Training loss: 0.0959716358247791
Validation loss: 2.433856815118752

Epoch: 5| Step: 1
Training loss: 0.1088142667163544
Validation loss: 2.411626205354374

Epoch: 5| Step: 2
Training loss: 0.07441156838710342
Validation loss: 2.4259610493792283

Epoch: 5| Step: 3
Training loss: 0.13985583769913135
Validation loss: 2.47103249211128

Epoch: 5| Step: 4
Training loss: 0.14512469912735196
Validation loss: 2.47322980135289

Epoch: 5| Step: 5
Training loss: 0.1826849928855806
Validation loss: 2.485568545599386

Epoch: 5| Step: 6
Training loss: 0.0863187040392661
Validation loss: 2.5006822865068195

Epoch: 5| Step: 7
Training loss: 0.1136116807381249
Validation loss: 2.4971731118400813

Epoch: 5| Step: 8
Training loss: 0.10759913817593679
Validation loss: 2.4972114290030056

Epoch: 5| Step: 9
Training loss: 0.08639206740578707
Validation loss: 2.435060512485438

Epoch: 5| Step: 10
Training loss: 0.11089365237031294
Validation loss: 2.4490581761465013

Epoch: 643| Step: 0
Training loss: 0.13610822053221977
Validation loss: 2.398083371185762

Epoch: 5| Step: 1
Training loss: 0.13997267049744058
Validation loss: 2.4272209419647166

Epoch: 5| Step: 2
Training loss: 0.1853011863754408
Validation loss: 2.4482478158453684

Epoch: 5| Step: 3
Training loss: 0.13953938260785761
Validation loss: 2.4117340262162896

Epoch: 5| Step: 4
Training loss: 0.11039306906541041
Validation loss: 2.437973039665112

Epoch: 5| Step: 5
Training loss: 0.12344774538690349
Validation loss: 2.434447176580721

Epoch: 5| Step: 6
Training loss: 0.10912666056703377
Validation loss: 2.429126607364458

Epoch: 5| Step: 7
Training loss: 0.10105339241156425
Validation loss: 2.4425484265410247

Epoch: 5| Step: 8
Training loss: 0.10510741697681944
Validation loss: 2.4154977264515862

Epoch: 5| Step: 9
Training loss: 0.18226150308551814
Validation loss: 2.4100333436904156

Epoch: 5| Step: 10
Training loss: 0.09889815774238134
Validation loss: 2.4234220170447416

Epoch: 644| Step: 0
Training loss: 0.11921431263831243
Validation loss: 2.4119002920312407

Epoch: 5| Step: 1
Training loss: 0.11774276077665526
Validation loss: 2.3453590388175707

Epoch: 5| Step: 2
Training loss: 0.08003053763116112
Validation loss: 2.3781803255484366

Epoch: 5| Step: 3
Training loss: 0.10945011863146592
Validation loss: 2.403662315236329

Epoch: 5| Step: 4
Training loss: 0.06341228531892863
Validation loss: 2.374953255465926

Epoch: 5| Step: 5
Training loss: 0.1842923468065429
Validation loss: 2.401739676250072

Epoch: 5| Step: 6
Training loss: 0.14185721240730848
Validation loss: 2.385592183929321

Epoch: 5| Step: 7
Training loss: 0.1034727772617637
Validation loss: 2.411448726893165

Epoch: 5| Step: 8
Training loss: 0.11934132165828089
Validation loss: 2.3953341277420206

Epoch: 5| Step: 9
Training loss: 0.09827537734372387
Validation loss: 2.451696770299598

Epoch: 5| Step: 10
Training loss: 0.1592472143812895
Validation loss: 2.4646673696338763

Epoch: 645| Step: 0
Training loss: 0.10354656081110966
Validation loss: 2.471008762811749

Epoch: 5| Step: 1
Training loss: 0.09052177296835971
Validation loss: 2.477952871140617

Epoch: 5| Step: 2
Training loss: 0.07836280927900538
Validation loss: 2.4512539158797395

Epoch: 5| Step: 3
Training loss: 0.10283983713575202
Validation loss: 2.453089327448647

Epoch: 5| Step: 4
Training loss: 0.10376800504395334
Validation loss: 2.452030901175318

Epoch: 5| Step: 5
Training loss: 0.08957720692149312
Validation loss: 2.4775772383779664

Epoch: 5| Step: 6
Training loss: 0.10260761784866743
Validation loss: 2.436260521418996

Epoch: 5| Step: 7
Training loss: 0.11442357046253443
Validation loss: 2.4445197447902847

Epoch: 5| Step: 8
Training loss: 0.12115660312931725
Validation loss: 2.4495607809041093

Epoch: 5| Step: 9
Training loss: 0.08804249622707806
Validation loss: 2.4662467037670557

Epoch: 5| Step: 10
Training loss: 0.17651383016112263
Validation loss: 2.4655292967527784

Epoch: 646| Step: 0
Training loss: 0.0926581821272365
Validation loss: 2.455892466591923

Epoch: 5| Step: 1
Training loss: 0.08143340533736984
Validation loss: 2.4718790656882765

Epoch: 5| Step: 2
Training loss: 0.07102349866101366
Validation loss: 2.4755242789398935

Epoch: 5| Step: 3
Training loss: 0.09373404446566005
Validation loss: 2.4741919224061797

Epoch: 5| Step: 4
Training loss: 0.07515796130050179
Validation loss: 2.4730394533639823

Epoch: 5| Step: 5
Training loss: 0.15697806131289746
Validation loss: 2.478200236197926

Epoch: 5| Step: 6
Training loss: 0.09645059202629512
Validation loss: 2.4464245928689294

Epoch: 5| Step: 7
Training loss: 0.07824055351459443
Validation loss: 2.47939119867302

Epoch: 5| Step: 8
Training loss: 0.15935458772502017
Validation loss: 2.4496513620905565

Epoch: 5| Step: 9
Training loss: 0.11417885848223021
Validation loss: 2.469790668083998

Epoch: 5| Step: 10
Training loss: 0.12631635896553448
Validation loss: 2.4440193026414323

Epoch: 647| Step: 0
Training loss: 0.0730059373858695
Validation loss: 2.4716595594012847

Epoch: 5| Step: 1
Training loss: 0.12311550905589322
Validation loss: 2.459520244451722

Epoch: 5| Step: 2
Training loss: 0.12066843342914647
Validation loss: 2.4625707571202824

Epoch: 5| Step: 3
Training loss: 0.11160112671304712
Validation loss: 2.4540059044440454

Epoch: 5| Step: 4
Training loss: 0.1298391369116082
Validation loss: 2.4206537036637394

Epoch: 5| Step: 5
Training loss: 0.13661364193513312
Validation loss: 2.4432656855530754

Epoch: 5| Step: 6
Training loss: 0.12927829632002558
Validation loss: 2.4774506443944784

Epoch: 5| Step: 7
Training loss: 0.07659130892488125
Validation loss: 2.5175701293243007

Epoch: 5| Step: 8
Training loss: 0.15179278929233558
Validation loss: 2.520998960942329

Epoch: 5| Step: 9
Training loss: 0.0996481268431914
Validation loss: 2.5411648718101083

Epoch: 5| Step: 10
Training loss: 0.0974457140253438
Validation loss: 2.522061829572348

Epoch: 648| Step: 0
Training loss: 0.09485704735702742
Validation loss: 2.5176610149955727

Epoch: 5| Step: 1
Training loss: 0.20096409817405553
Validation loss: 2.493643923356464

Epoch: 5| Step: 2
Training loss: 0.1371693338757785
Validation loss: 2.48138878241176

Epoch: 5| Step: 3
Training loss: 0.1288071887537615
Validation loss: 2.4275594117016164

Epoch: 5| Step: 4
Training loss: 0.13443305956939308
Validation loss: 2.42373703143902

Epoch: 5| Step: 5
Training loss: 0.1017940614096309
Validation loss: 2.399252008194834

Epoch: 5| Step: 6
Training loss: 0.08805235182272449
Validation loss: 2.397789057839862

Epoch: 5| Step: 7
Training loss: 0.1003595415375593
Validation loss: 2.3916732537562373

Epoch: 5| Step: 8
Training loss: 0.08126119366896872
Validation loss: 2.4251208669456825

Epoch: 5| Step: 9
Training loss: 0.09973836475587394
Validation loss: 2.4116671520131496

Epoch: 5| Step: 10
Training loss: 0.06624565269381424
Validation loss: 2.43596935041304

Epoch: 649| Step: 0
Training loss: 0.13528234134708828
Validation loss: 2.472172373926288

Epoch: 5| Step: 1
Training loss: 0.0757444752116031
Validation loss: 2.453834114028207

Epoch: 5| Step: 2
Training loss: 0.158018333924086
Validation loss: 2.49047930966035

Epoch: 5| Step: 3
Training loss: 0.12007489661702327
Validation loss: 2.490437096635033

Epoch: 5| Step: 4
Training loss: 0.06501532771650619
Validation loss: 2.5020249789767637

Epoch: 5| Step: 5
Training loss: 0.13959714307604515
Validation loss: 2.464068863007015

Epoch: 5| Step: 6
Training loss: 0.11971893815225201
Validation loss: 2.453104297453131

Epoch: 5| Step: 7
Training loss: 0.1098940573077246
Validation loss: 2.4345341732612353

Epoch: 5| Step: 8
Training loss: 0.13987780454694407
Validation loss: 2.4241156399977744

Epoch: 5| Step: 9
Training loss: 0.09087324138327595
Validation loss: 2.4110930359324194

Epoch: 5| Step: 10
Training loss: 0.08187811897885372
Validation loss: 2.458509444791653

Epoch: 650| Step: 0
Training loss: 0.11822745695502396
Validation loss: 2.4672783068015347

Epoch: 5| Step: 1
Training loss: 0.1374248052483071
Validation loss: 2.446345332669731

Epoch: 5| Step: 2
Training loss: 0.08227075795791002
Validation loss: 2.4878424765044276

Epoch: 5| Step: 3
Training loss: 0.1420613551993675
Validation loss: 2.4888524510820282

Epoch: 5| Step: 4
Training loss: 0.09794553823963084
Validation loss: 2.504693875538089

Epoch: 5| Step: 5
Training loss: 0.07131301137948125
Validation loss: 2.497643017007854

Epoch: 5| Step: 6
Training loss: 0.09620118938597297
Validation loss: 2.483303617883383

Epoch: 5| Step: 7
Training loss: 0.21483102240576046
Validation loss: 2.4760172911383194

Epoch: 5| Step: 8
Training loss: 0.09747800773092827
Validation loss: 2.420340483171693

Epoch: 5| Step: 9
Training loss: 0.08558291194413352
Validation loss: 2.399814851688031

Epoch: 5| Step: 10
Training loss: 0.07578693840464316
Validation loss: 2.4022409596676098

Testing loss: 2.436222605713534
