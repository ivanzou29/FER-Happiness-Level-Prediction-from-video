Epoch: 1| Step: 0
Training loss: 6.280501743367125
Validation loss: 5.753219560954485

Epoch: 5| Step: 1
Training loss: 5.488013818273025
Validation loss: 5.738146226495689

Epoch: 5| Step: 2
Training loss: 5.843525764936655
Validation loss: 5.726956848973567

Epoch: 5| Step: 3
Training loss: 4.986049645817483
Validation loss: 5.717684337123887

Epoch: 5| Step: 4
Training loss: 6.000581395273197
Validation loss: 5.707684047567527

Epoch: 5| Step: 5
Training loss: 6.090383685573513
Validation loss: 5.696573443951874

Epoch: 5| Step: 6
Training loss: 5.653695725815763
Validation loss: 5.683491881742844

Epoch: 5| Step: 7
Training loss: 4.788119896977012
Validation loss: 5.6687471936454985

Epoch: 5| Step: 8
Training loss: 6.0122400049157205
Validation loss: 5.651245960323129

Epoch: 5| Step: 9
Training loss: 6.097873329535996
Validation loss: 5.632387365122716

Epoch: 5| Step: 10
Training loss: 5.543742066112118
Validation loss: 5.610133746551135

Epoch: 2| Step: 0
Training loss: 5.130523868158413
Validation loss: 5.584555899645225

Epoch: 5| Step: 1
Training loss: 4.696105788460905
Validation loss: 5.5556467167064385

Epoch: 5| Step: 2
Training loss: 5.219652840189156
Validation loss: 5.522854941897975

Epoch: 5| Step: 3
Training loss: 6.276437310586373
Validation loss: 5.486813360568336

Epoch: 5| Step: 4
Training loss: 5.717900114016262
Validation loss: 5.446630208802943

Epoch: 5| Step: 5
Training loss: 5.74111384520406
Validation loss: 5.403150529356972

Epoch: 5| Step: 6
Training loss: 5.086140008929138
Validation loss: 5.357872349438806

Epoch: 5| Step: 7
Training loss: 5.98760468903128
Validation loss: 5.311223576833599

Epoch: 5| Step: 8
Training loss: 5.219370913544495
Validation loss: 5.2636853368833085

Epoch: 5| Step: 9
Training loss: 4.799989167837
Validation loss: 5.215694156439092

Epoch: 5| Step: 10
Training loss: 5.758387212137797
Validation loss: 5.168235615348311

Epoch: 3| Step: 0
Training loss: 5.201498057916468
Validation loss: 5.120943298229829

Epoch: 5| Step: 1
Training loss: 6.065782110821885
Validation loss: 5.074979678427055

Epoch: 5| Step: 2
Training loss: 5.070155442542945
Validation loss: 5.027111634506775

Epoch: 5| Step: 3
Training loss: 5.270404220221752
Validation loss: 4.980192430533211

Epoch: 5| Step: 4
Training loss: 4.025409341219832
Validation loss: 4.9314451287621495

Epoch: 5| Step: 5
Training loss: 3.8581050374082992
Validation loss: 4.886165131352043

Epoch: 5| Step: 6
Training loss: 5.532985781283356
Validation loss: 4.840534136896419

Epoch: 5| Step: 7
Training loss: 3.808078515830136
Validation loss: 4.798153423280434

Epoch: 5| Step: 8
Training loss: 5.69037362747506
Validation loss: 4.759791157033364

Epoch: 5| Step: 9
Training loss: 4.918633837945971
Validation loss: 4.724352767896779

Epoch: 5| Step: 10
Training loss: 4.638940987259524
Validation loss: 4.690851989864876

Epoch: 4| Step: 0
Training loss: 5.299740536654542
Validation loss: 4.657189409261068

Epoch: 5| Step: 1
Training loss: 4.957397735972178
Validation loss: 4.623077787996758

Epoch: 5| Step: 2
Training loss: 4.797705562892839
Validation loss: 4.589742522405233

Epoch: 5| Step: 3
Training loss: 4.4207786036539325
Validation loss: 4.556947236108274

Epoch: 5| Step: 4
Training loss: 4.8156803075942625
Validation loss: 4.514443067803648

Epoch: 5| Step: 5
Training loss: 4.906386841244532
Validation loss: 4.470209673986872

Epoch: 5| Step: 6
Training loss: 4.334295948410561
Validation loss: 4.43666761195017

Epoch: 5| Step: 7
Training loss: 4.511823591855452
Validation loss: 4.402086238410633

Epoch: 5| Step: 8
Training loss: 4.858445645970389
Validation loss: 4.371348121144213

Epoch: 5| Step: 9
Training loss: 3.639664289902089
Validation loss: 4.345355088115657

Epoch: 5| Step: 10
Training loss: 3.6407289940384504
Validation loss: 4.333768627904569

Epoch: 5| Step: 0
Training loss: 4.303353381554678
Validation loss: 4.301037898414039

Epoch: 5| Step: 1
Training loss: 5.158590629376801
Validation loss: 4.287365119730897

Epoch: 5| Step: 2
Training loss: 4.5308831428136624
Validation loss: 4.270203414230947

Epoch: 5| Step: 3
Training loss: 4.543547471267052
Validation loss: 4.25736310532254

Epoch: 5| Step: 4
Training loss: 3.6807994417843046
Validation loss: 4.248622132869142

Epoch: 5| Step: 5
Training loss: 4.614848362507217
Validation loss: 4.240923211018734

Epoch: 5| Step: 6
Training loss: 4.408958955057623
Validation loss: 4.233750023430419

Epoch: 5| Step: 7
Training loss: 4.45305861038779
Validation loss: 4.22129059695919

Epoch: 5| Step: 8
Training loss: 4.527282661769701
Validation loss: 4.204769426588455

Epoch: 5| Step: 9
Training loss: 3.5764426728353462
Validation loss: 4.196345343476504

Epoch: 5| Step: 10
Training loss: 4.053522607834643
Validation loss: 4.181888699083923

Epoch: 6| Step: 0
Training loss: 4.872348357689211
Validation loss: 4.1782305673337214

Epoch: 5| Step: 1
Training loss: 4.222149418878024
Validation loss: 4.18000588885846

Epoch: 5| Step: 2
Training loss: 3.9671755093021086
Validation loss: 4.173459597546311

Epoch: 5| Step: 3
Training loss: 3.4515967115690045
Validation loss: 4.158172917578899

Epoch: 5| Step: 4
Training loss: 4.224377305230128
Validation loss: 4.141626760569864

Epoch: 5| Step: 5
Training loss: 4.105034337893315
Validation loss: 4.128369806649281

Epoch: 5| Step: 6
Training loss: 4.433364445474394
Validation loss: 4.119065740437128

Epoch: 5| Step: 7
Training loss: 4.739526143270458
Validation loss: 4.110033200680307

Epoch: 5| Step: 8
Training loss: 4.389700252579339
Validation loss: 4.099323860839834

Epoch: 5| Step: 9
Training loss: 4.384282754592454
Validation loss: 4.079683594319213

Epoch: 5| Step: 10
Training loss: 3.955708500111453
Validation loss: 4.043973724566311

Epoch: 7| Step: 0
Training loss: 4.282901194898579
Validation loss: 4.0241630998247375

Epoch: 5| Step: 1
Training loss: 4.379214845072317
Validation loss: 4.020197979725115

Epoch: 5| Step: 2
Training loss: 3.6754540714346557
Validation loss: 4.011684317207938

Epoch: 5| Step: 3
Training loss: 4.358927385873991
Validation loss: 4.0162094569984195

Epoch: 5| Step: 4
Training loss: 4.221656984563348
Validation loss: 4.009214515387628

Epoch: 5| Step: 5
Training loss: 4.1463656954283
Validation loss: 3.9950871266143233

Epoch: 5| Step: 6
Training loss: 2.9901996114692184
Validation loss: 3.9874339763750646

Epoch: 5| Step: 7
Training loss: 4.885939233265402
Validation loss: 3.978617144377351

Epoch: 5| Step: 8
Training loss: 4.800578026935943
Validation loss: 3.97138128240787

Epoch: 5| Step: 9
Training loss: 3.788394578090973
Validation loss: 3.9606881969835164

Epoch: 5| Step: 10
Training loss: 3.6512860893390937
Validation loss: 3.9477810543227077

Epoch: 8| Step: 0
Training loss: 3.984977527014187
Validation loss: 3.9381707318964665

Epoch: 5| Step: 1
Training loss: 4.939637506135101
Validation loss: 3.930446541255912

Epoch: 5| Step: 2
Training loss: 4.145454095463219
Validation loss: 3.9244125243730896

Epoch: 5| Step: 3
Training loss: 4.366973926323967
Validation loss: 3.915545449477832

Epoch: 5| Step: 4
Training loss: 3.5360199436988937
Validation loss: 3.906213666193169

Epoch: 5| Step: 5
Training loss: 3.4520850363255047
Validation loss: 3.898931699955551

Epoch: 5| Step: 6
Training loss: 3.317361970285204
Validation loss: 3.8912212812517013

Epoch: 5| Step: 7
Training loss: 4.348997390784882
Validation loss: 3.888523302947193

Epoch: 5| Step: 8
Training loss: 4.4463378581840916
Validation loss: 3.8919346250850455

Epoch: 5| Step: 9
Training loss: 4.013573504725188
Validation loss: 3.8893536192344254

Epoch: 5| Step: 10
Training loss: 3.8866073515756985
Validation loss: 3.8762669551281843

Epoch: 9| Step: 0
Training loss: 4.161984954220195
Validation loss: 3.8694546610651135

Epoch: 5| Step: 1
Training loss: 3.9531516575574135
Validation loss: 3.873308571447995

Epoch: 5| Step: 2
Training loss: 3.143013269088753
Validation loss: 3.870156976178064

Epoch: 5| Step: 3
Training loss: 4.058587640605364
Validation loss: 3.864350857895813

Epoch: 5| Step: 4
Training loss: 3.950402087256559
Validation loss: 3.856187441781424

Epoch: 5| Step: 5
Training loss: 3.8963076596832353
Validation loss: 3.853102585300754

Epoch: 5| Step: 6
Training loss: 4.487009158691961
Validation loss: 3.8525650505774895

Epoch: 5| Step: 7
Training loss: 4.1334239601126335
Validation loss: 3.8500529109417774

Epoch: 5| Step: 8
Training loss: 4.432470560852846
Validation loss: 3.8468347365681512

Epoch: 5| Step: 9
Training loss: 3.324797780477317
Validation loss: 3.8431636170605805

Epoch: 5| Step: 10
Training loss: 4.551402142126158
Validation loss: 3.840182794307898

Epoch: 10| Step: 0
Training loss: 3.715886913208987
Validation loss: 3.835972128269186

Epoch: 5| Step: 1
Training loss: 4.294282998398791
Validation loss: 3.8323300753259115

Epoch: 5| Step: 2
Training loss: 3.540710200389822
Validation loss: 3.8308639107265736

Epoch: 5| Step: 3
Training loss: 3.1958085027241516
Validation loss: 3.82817808427936

Epoch: 5| Step: 4
Training loss: 4.362615222010461
Validation loss: 3.8253434382723146

Epoch: 5| Step: 5
Training loss: 3.800016006636788
Validation loss: 3.821980070637022

Epoch: 5| Step: 6
Training loss: 3.347906078867064
Validation loss: 3.818667432417626

Epoch: 5| Step: 7
Training loss: 4.21113135859426
Validation loss: 3.8164112786578253

Epoch: 5| Step: 8
Training loss: 4.126257733577864
Validation loss: 3.8111659956738593

Epoch: 5| Step: 9
Training loss: 4.616693822089984
Validation loss: 3.8089529220136513

Epoch: 5| Step: 10
Training loss: 4.514622771767571
Validation loss: 3.8067045295925186

Epoch: 11| Step: 0
Training loss: 4.384374765082073
Validation loss: 3.802124087050225

Epoch: 5| Step: 1
Training loss: 3.6378835416905297
Validation loss: 3.7988594136345535

Epoch: 5| Step: 2
Training loss: 4.091484549535999
Validation loss: 3.796120756448159

Epoch: 5| Step: 3
Training loss: 4.449963970252776
Validation loss: 3.7936406213062344

Epoch: 5| Step: 4
Training loss: 3.9071643217049625
Validation loss: 3.791262634307575

Epoch: 5| Step: 5
Training loss: 2.933606428380559
Validation loss: 3.7881741391405575

Epoch: 5| Step: 6
Training loss: 4.1935886130284965
Validation loss: 3.786430539671246

Epoch: 5| Step: 7
Training loss: 3.146623036545473
Validation loss: 3.7841820559089014

Epoch: 5| Step: 8
Training loss: 4.086825505873
Validation loss: 3.7821942862842204

Epoch: 5| Step: 9
Training loss: 3.6337332922436887
Validation loss: 3.778658262153652

Epoch: 5| Step: 10
Training loss: 4.905002119431344
Validation loss: 3.7759911064975165

Epoch: 12| Step: 0
Training loss: 3.637699113882242
Validation loss: 3.7713325744257595

Epoch: 5| Step: 1
Training loss: 4.14243032577571
Validation loss: 3.769270954924642

Epoch: 5| Step: 2
Training loss: 4.063021582352487
Validation loss: 3.7665366140447163

Epoch: 5| Step: 3
Training loss: 2.9341840492982456
Validation loss: 3.76397097287855

Epoch: 5| Step: 4
Training loss: 3.8805249112763254
Validation loss: 3.7611732384250884

Epoch: 5| Step: 5
Training loss: 4.213783335818383
Validation loss: 3.7578598755244763

Epoch: 5| Step: 6
Training loss: 3.8550222461023926
Validation loss: 3.756954737610191

Epoch: 5| Step: 7
Training loss: 4.024696404990537
Validation loss: 3.7560700159600158

Epoch: 5| Step: 8
Training loss: 4.488569152469306
Validation loss: 3.752508731213822

Epoch: 5| Step: 9
Training loss: 3.5276489801666076
Validation loss: 3.7477467456779183

Epoch: 5| Step: 10
Training loss: 4.403885010537305
Validation loss: 3.742804626661993

Epoch: 13| Step: 0
Training loss: 3.164827080171632
Validation loss: 3.7408260479250632

Epoch: 5| Step: 1
Training loss: 3.822711838614889
Validation loss: 3.7357327195073977

Epoch: 5| Step: 2
Training loss: 3.5275581438340438
Validation loss: 3.7310114179719864

Epoch: 5| Step: 3
Training loss: 4.39982385282787
Validation loss: 3.725543459768641

Epoch: 5| Step: 4
Training loss: 3.6182636942254094
Validation loss: 3.722911171805485

Epoch: 5| Step: 5
Training loss: 3.2560630876488728
Validation loss: 3.723969230518307

Epoch: 5| Step: 6
Training loss: 4.382274139033143
Validation loss: 3.725037350535824

Epoch: 5| Step: 7
Training loss: 4.515778324467712
Validation loss: 3.7358304997047975

Epoch: 5| Step: 8
Training loss: 4.020524060835214
Validation loss: 3.730014880320386

Epoch: 5| Step: 9
Training loss: 3.595553269130806
Validation loss: 3.738200914058038

Epoch: 5| Step: 10
Training loss: 4.606674800006258
Validation loss: 3.7467296258738787

Epoch: 14| Step: 0
Training loss: 4.539076576933314
Validation loss: 3.7505134531807807

Epoch: 5| Step: 1
Training loss: 2.930131639511393
Validation loss: 3.746973425648768

Epoch: 5| Step: 2
Training loss: 4.193098737970188
Validation loss: 3.7450670700719013

Epoch: 5| Step: 3
Training loss: 3.75705030804911
Validation loss: 3.7387050397405788

Epoch: 5| Step: 4
Training loss: 3.71720251374582
Validation loss: 3.733724802415158

Epoch: 5| Step: 5
Training loss: 3.2972312120120284
Validation loss: 3.7289481104422366

Epoch: 5| Step: 6
Training loss: 4.446427726636096
Validation loss: 3.724146993229536

Epoch: 5| Step: 7
Training loss: 4.8659791870173805
Validation loss: 3.724822187863168

Epoch: 5| Step: 8
Training loss: 3.8475075320243852
Validation loss: 3.7168413756767733

Epoch: 5| Step: 9
Training loss: 3.85938228961704
Validation loss: 3.714639030942015

Epoch: 5| Step: 10
Training loss: 3.011812636597966
Validation loss: 3.712686165596319

Epoch: 15| Step: 0
Training loss: 3.702010876417541
Validation loss: 3.7085851759159634

Epoch: 5| Step: 1
Training loss: 3.045699142095318
Validation loss: 3.702960453970184

Epoch: 5| Step: 2
Training loss: 4.3084421278143665
Validation loss: 3.69868145246641

Epoch: 5| Step: 3
Training loss: 4.310511033635542
Validation loss: 3.6932617607732343

Epoch: 5| Step: 4
Training loss: 4.203865524914242
Validation loss: 3.6867234427560276

Epoch: 5| Step: 5
Training loss: 3.308486954768086
Validation loss: 3.6754531060902282

Epoch: 5| Step: 6
Training loss: 4.494623999564473
Validation loss: 3.668901594842211

Epoch: 5| Step: 7
Training loss: 3.2666865179535653
Validation loss: 3.661451527214852

Epoch: 5| Step: 8
Training loss: 4.219217232156224
Validation loss: 3.6587154005502813

Epoch: 5| Step: 9
Training loss: 4.121247173906537
Validation loss: 3.652194050586847

Epoch: 5| Step: 10
Training loss: 3.0870113773809758
Validation loss: 3.646892265612653

Epoch: 16| Step: 0
Training loss: 3.7126448066804465
Validation loss: 3.644713202239932

Epoch: 5| Step: 1
Training loss: 3.621833865546787
Validation loss: 3.6425512440249417

Epoch: 5| Step: 2
Training loss: 4.224960164440995
Validation loss: 3.6376951729608655

Epoch: 5| Step: 3
Training loss: 3.954050551311794
Validation loss: 3.6312783892059426

Epoch: 5| Step: 4
Training loss: 3.1153001927804156
Validation loss: 3.626679241214342

Epoch: 5| Step: 5
Training loss: 4.0304287805884265
Validation loss: 3.6247891996687533

Epoch: 5| Step: 6
Training loss: 4.287659907347958
Validation loss: 3.6232694838236825

Epoch: 5| Step: 7
Training loss: 4.06312039846674
Validation loss: 3.6189797041485403

Epoch: 5| Step: 8
Training loss: 2.9336106544952365
Validation loss: 3.6151131727479746

Epoch: 5| Step: 9
Training loss: 3.582090088206104
Validation loss: 3.611692567672979

Epoch: 5| Step: 10
Training loss: 4.336288520419763
Validation loss: 3.6136979664254105

Epoch: 17| Step: 0
Training loss: 3.3843958014837856
Validation loss: 3.604087343373829

Epoch: 5| Step: 1
Training loss: 3.9471033847240062
Validation loss: 3.601793322316806

Epoch: 5| Step: 2
Training loss: 3.454813410665567
Validation loss: 3.602852260107599

Epoch: 5| Step: 3
Training loss: 4.437207279490345
Validation loss: 3.602502083662744

Epoch: 5| Step: 4
Training loss: 3.8050652224430923
Validation loss: 3.602593232068157

Epoch: 5| Step: 5
Training loss: 3.352370513759396
Validation loss: 3.598758889595273

Epoch: 5| Step: 6
Training loss: 4.00861622743284
Validation loss: 3.5958694863616145

Epoch: 5| Step: 7
Training loss: 3.9558003536178497
Validation loss: 3.593102704392382

Epoch: 5| Step: 8
Training loss: 4.2336204391401315
Validation loss: 3.590883246014361

Epoch: 5| Step: 9
Training loss: 3.340057758814113
Validation loss: 3.5887668211017867

Epoch: 5| Step: 10
Training loss: 3.6637355764333535
Validation loss: 3.5884249190882964

Epoch: 18| Step: 0
Training loss: 3.3747739362946594
Validation loss: 3.5871584385200004

Epoch: 5| Step: 1
Training loss: 2.8383219129325528
Validation loss: 3.587903273514484

Epoch: 5| Step: 2
Training loss: 3.9341034544784854
Validation loss: 3.586152900290551

Epoch: 5| Step: 3
Training loss: 4.270942252406215
Validation loss: 3.584862228107585

Epoch: 5| Step: 4
Training loss: 3.011601743886754
Validation loss: 3.581554426775825

Epoch: 5| Step: 5
Training loss: 3.6940570013071334
Validation loss: 3.580732640000912

Epoch: 5| Step: 6
Training loss: 3.9198136098495695
Validation loss: 3.578948882623565

Epoch: 5| Step: 7
Training loss: 4.279012276236266
Validation loss: 3.576245935226447

Epoch: 5| Step: 8
Training loss: 3.4951054545416365
Validation loss: 3.5746351677635673

Epoch: 5| Step: 9
Training loss: 3.6480050004205395
Validation loss: 3.5735271277593776

Epoch: 5| Step: 10
Training loss: 4.88310780357029
Validation loss: 3.5719576991845283

Epoch: 19| Step: 0
Training loss: 4.099465144556732
Validation loss: 3.5707539446860483

Epoch: 5| Step: 1
Training loss: 3.372177356531143
Validation loss: 3.567682912706184

Epoch: 5| Step: 2
Training loss: 3.5500600353053837
Validation loss: 3.5653417882273355

Epoch: 5| Step: 3
Training loss: 3.557281017520244
Validation loss: 3.5622968228972995

Epoch: 5| Step: 4
Training loss: 3.6628435461991966
Validation loss: 3.5595748656691493

Epoch: 5| Step: 5
Training loss: 3.8332558637890255
Validation loss: 3.556316892884814

Epoch: 5| Step: 6
Training loss: 4.624315984508948
Validation loss: 3.5519486766467003

Epoch: 5| Step: 7
Training loss: 4.334296168440366
Validation loss: 3.5478617148693306

Epoch: 5| Step: 8
Training loss: 3.3360847244115592
Validation loss: 3.5429158916886125

Epoch: 5| Step: 9
Training loss: 3.4311178435565384
Validation loss: 3.5409252213420706

Epoch: 5| Step: 10
Training loss: 3.2536414360373698
Validation loss: 3.53919708076473

Epoch: 20| Step: 0
Training loss: 4.085368187885986
Validation loss: 3.5358844169179093

Epoch: 5| Step: 1
Training loss: 4.026347646728292
Validation loss: 3.53399052236222

Epoch: 5| Step: 2
Training loss: 3.7496571702014263
Validation loss: 3.5322672556358006

Epoch: 5| Step: 3
Training loss: 3.9911279037346983
Validation loss: 3.5295574311035955

Epoch: 5| Step: 4
Training loss: 3.8105627672576725
Validation loss: 3.52948887750021

Epoch: 5| Step: 5
Training loss: 3.2897841144447946
Validation loss: 3.5270506522048586

Epoch: 5| Step: 6
Training loss: 3.678655070545723
Validation loss: 3.526513972848066

Epoch: 5| Step: 7
Training loss: 3.9386785045395087
Validation loss: 3.5244745521365664

Epoch: 5| Step: 8
Training loss: 2.4450160812753996
Validation loss: 3.5223679142037803

Epoch: 5| Step: 9
Training loss: 4.059125467079715
Validation loss: 3.521377203760761

Epoch: 5| Step: 10
Training loss: 3.7555679946206855
Validation loss: 3.5210106597436233

Epoch: 21| Step: 0
Training loss: 4.201255410896592
Validation loss: 3.518888651601779

Epoch: 5| Step: 1
Training loss: 3.6402729175245225
Validation loss: 3.5184938148428166

Epoch: 5| Step: 2
Training loss: 3.779618092373135
Validation loss: 3.516460988905414

Epoch: 5| Step: 3
Training loss: 4.167628723975806
Validation loss: 3.515717413449926

Epoch: 5| Step: 4
Training loss: 2.8122027769923243
Validation loss: 3.5136299742086083

Epoch: 5| Step: 5
Training loss: 3.5685725072758516
Validation loss: 3.512982297251303

Epoch: 5| Step: 6
Training loss: 3.4208619172686645
Validation loss: 3.5115004425357164

Epoch: 5| Step: 7
Training loss: 3.6909043712645584
Validation loss: 3.5100604261449857

Epoch: 5| Step: 8
Training loss: 3.396247526469083
Validation loss: 3.5091160220614808

Epoch: 5| Step: 9
Training loss: 3.712300325412087
Validation loss: 3.5077289467477706

Epoch: 5| Step: 10
Training loss: 4.451943759518424
Validation loss: 3.5066133284687213

Epoch: 22| Step: 0
Training loss: 3.475153330980969
Validation loss: 3.5041004660777264

Epoch: 5| Step: 1
Training loss: 4.129043446898683
Validation loss: 3.5037084056658285

Epoch: 5| Step: 2
Training loss: 3.5636395422102107
Validation loss: 3.503068368567844

Epoch: 5| Step: 3
Training loss: 3.321156544833153
Validation loss: 3.5008954266600836

Epoch: 5| Step: 4
Training loss: 3.3937655903438806
Validation loss: 3.501161622800344

Epoch: 5| Step: 5
Training loss: 4.096108492472397
Validation loss: 3.499698332928083

Epoch: 5| Step: 6
Training loss: 3.39915974275807
Validation loss: 3.5088994902484014

Epoch: 5| Step: 7
Training loss: 4.031230128039684
Validation loss: 3.503567209391177

Epoch: 5| Step: 8
Training loss: 3.6079789801871307
Validation loss: 3.494804188030552

Epoch: 5| Step: 9
Training loss: 3.9997304587147626
Validation loss: 3.4953214282589333

Epoch: 5| Step: 10
Training loss: 3.740749520863999
Validation loss: 3.4941234887299024

Epoch: 23| Step: 0
Training loss: 2.705113379734165
Validation loss: 3.4939536358384773

Epoch: 5| Step: 1
Training loss: 3.150423015468177
Validation loss: 3.4936099955524624

Epoch: 5| Step: 2
Training loss: 4.103685044173402
Validation loss: 3.4954665499017494

Epoch: 5| Step: 3
Training loss: 3.6331659616772716
Validation loss: 3.4941431518516937

Epoch: 5| Step: 4
Training loss: 3.6505673581565357
Validation loss: 3.4932135726563596

Epoch: 5| Step: 5
Training loss: 3.441976372282511
Validation loss: 3.489405292688663

Epoch: 5| Step: 6
Training loss: 4.203543830055917
Validation loss: 3.488413581827181

Epoch: 5| Step: 7
Training loss: 3.755800212011276
Validation loss: 3.48886652076634

Epoch: 5| Step: 8
Training loss: 3.767330938746764
Validation loss: 3.487188709897828

Epoch: 5| Step: 9
Training loss: 4.0818027560152474
Validation loss: 3.485701160855766

Epoch: 5| Step: 10
Training loss: 4.055259473144875
Validation loss: 3.4837481980034877

Epoch: 24| Step: 0
Training loss: 3.3917767374859276
Validation loss: 3.482263405770259

Epoch: 5| Step: 1
Training loss: 3.761489560126081
Validation loss: 3.4814055879217487

Epoch: 5| Step: 2
Training loss: 4.13458594651226
Validation loss: 3.4802216498674268

Epoch: 5| Step: 3
Training loss: 3.3412019522223835
Validation loss: 3.4799748725370554

Epoch: 5| Step: 4
Training loss: 4.301751272519149
Validation loss: 3.4772572351289144

Epoch: 5| Step: 5
Training loss: 3.6549305939770664
Validation loss: 3.475947373140673

Epoch: 5| Step: 6
Training loss: 3.7455360546400946
Validation loss: 3.4749210860696103

Epoch: 5| Step: 7
Training loss: 3.3573829599802614
Validation loss: 3.473784925736478

Epoch: 5| Step: 8
Training loss: 3.224980518370936
Validation loss: 3.4721316979752803

Epoch: 5| Step: 9
Training loss: 3.692674271713867
Validation loss: 3.47060632778163

Epoch: 5| Step: 10
Training loss: 3.9104614748425828
Validation loss: 3.469417022691117

Epoch: 25| Step: 0
Training loss: 3.764204841731536
Validation loss: 3.4690884572193896

Epoch: 5| Step: 1
Training loss: 4.14415363169853
Validation loss: 3.4671546883796682

Epoch: 5| Step: 2
Training loss: 3.183709527467235
Validation loss: 3.4659872895786616

Epoch: 5| Step: 3
Training loss: 3.559801920405743
Validation loss: 3.465174626714479

Epoch: 5| Step: 4
Training loss: 3.4450511876526413
Validation loss: 3.4637266926454533

Epoch: 5| Step: 5
Training loss: 3.4288875541950867
Validation loss: 3.4622765329436023

Epoch: 5| Step: 6
Training loss: 4.275881108728521
Validation loss: 3.4613315268439666

Epoch: 5| Step: 7
Training loss: 3.867309814984846
Validation loss: 3.4602763596948627

Epoch: 5| Step: 8
Training loss: 2.8374507009113903
Validation loss: 3.4584345120157325

Epoch: 5| Step: 9
Training loss: 4.376989293832041
Validation loss: 3.4574557299215467

Epoch: 5| Step: 10
Training loss: 3.245971383589741
Validation loss: 3.455675610697606

Epoch: 26| Step: 0
Training loss: 3.099860735810707
Validation loss: 3.4548248411685574

Epoch: 5| Step: 1
Training loss: 4.319645366241064
Validation loss: 3.4533437446989694

Epoch: 5| Step: 2
Training loss: 4.046201436314364
Validation loss: 3.451846769864915

Epoch: 5| Step: 3
Training loss: 4.158966553407036
Validation loss: 3.4508525138092305

Epoch: 5| Step: 4
Training loss: 4.038967345424722
Validation loss: 3.449894080454014

Epoch: 5| Step: 5
Training loss: 3.7097674964786793
Validation loss: 3.448792948520735

Epoch: 5| Step: 6
Training loss: 3.8850049711806847
Validation loss: 3.447330640056413

Epoch: 5| Step: 7
Training loss: 3.099196908353131
Validation loss: 3.4460090456009995

Epoch: 5| Step: 8
Training loss: 3.4207470572058267
Validation loss: 3.4451228903859183

Epoch: 5| Step: 9
Training loss: 2.859826224322939
Validation loss: 3.4442104958011552

Epoch: 5| Step: 10
Training loss: 3.37664133356752
Validation loss: 3.4431867394453186

Epoch: 27| Step: 0
Training loss: 3.900992189033314
Validation loss: 3.44235176760719

Epoch: 5| Step: 1
Training loss: 3.9272362285501017
Validation loss: 3.4410216026534592

Epoch: 5| Step: 2
Training loss: 3.490750078847822
Validation loss: 3.4403354856739816

Epoch: 5| Step: 3
Training loss: 2.8186972264257566
Validation loss: 3.4389526400330688

Epoch: 5| Step: 4
Training loss: 4.247793634693128
Validation loss: 3.4379573185942482

Epoch: 5| Step: 5
Training loss: 4.154486949107282
Validation loss: 3.4370273865553598

Epoch: 5| Step: 6
Training loss: 3.437774647231328
Validation loss: 3.43585758443188

Epoch: 5| Step: 7
Training loss: 3.4024450766610213
Validation loss: 3.4348825178941174

Epoch: 5| Step: 8
Training loss: 3.463583044890089
Validation loss: 3.434175751791159

Epoch: 5| Step: 9
Training loss: 3.869972166606951
Validation loss: 3.43322100966841

Epoch: 5| Step: 10
Training loss: 3.263023983323915
Validation loss: 3.431955406606031

Epoch: 28| Step: 0
Training loss: 3.0212760513186288
Validation loss: 3.431111621089242

Epoch: 5| Step: 1
Training loss: 4.4237875963927165
Validation loss: 3.430219860994302

Epoch: 5| Step: 2
Training loss: 3.586828582351658
Validation loss: 3.4293010552911896

Epoch: 5| Step: 3
Training loss: 3.627956105850985
Validation loss: 3.4280313725949156

Epoch: 5| Step: 4
Training loss: 3.337459458237055
Validation loss: 3.4277002468980515

Epoch: 5| Step: 5
Training loss: 2.734269930319493
Validation loss: 3.426203695653728

Epoch: 5| Step: 6
Training loss: 3.342869722950498
Validation loss: 3.4252881813233667

Epoch: 5| Step: 7
Training loss: 3.4090047074025542
Validation loss: 3.4244405849639525

Epoch: 5| Step: 8
Training loss: 3.679849868075423
Validation loss: 3.423253683161364

Epoch: 5| Step: 9
Training loss: 4.001780590473085
Validation loss: 3.4224222663080353

Epoch: 5| Step: 10
Training loss: 4.733904824657548
Validation loss: 3.4220030539588255

Epoch: 29| Step: 0
Training loss: 3.692131883458205
Validation loss: 3.4206465754697892

Epoch: 5| Step: 1
Training loss: 3.235971987184571
Validation loss: 3.4197309280516106

Epoch: 5| Step: 2
Training loss: 3.8300911972702085
Validation loss: 3.419010464935046

Epoch: 5| Step: 3
Training loss: 3.5035864302376654
Validation loss: 3.417821812437795

Epoch: 5| Step: 4
Training loss: 3.309140210922903
Validation loss: 3.4170800570982376

Epoch: 5| Step: 5
Training loss: 3.953016196702412
Validation loss: 3.415908381676106

Epoch: 5| Step: 6
Training loss: 3.419564080816094
Validation loss: 3.4149478898060095

Epoch: 5| Step: 7
Training loss: 3.426304706525029
Validation loss: 3.414070300404503

Epoch: 5| Step: 8
Training loss: 3.9615011021146596
Validation loss: 3.413305595777788

Epoch: 5| Step: 9
Training loss: 3.8679611511094185
Validation loss: 3.4124032323988938

Epoch: 5| Step: 10
Training loss: 3.8049623362698517
Validation loss: 3.411038933456497

Epoch: 30| Step: 0
Training loss: 3.186896323091371
Validation loss: 3.410196300867599

Epoch: 5| Step: 1
Training loss: 4.0761552635771965
Validation loss: 3.4092834007383512

Epoch: 5| Step: 2
Training loss: 3.8251407123688126
Validation loss: 3.408568054965643

Epoch: 5| Step: 3
Training loss: 2.8504850677489895
Validation loss: 3.407819275237747

Epoch: 5| Step: 4
Training loss: 4.025013439084949
Validation loss: 3.4066922187782045

Epoch: 5| Step: 5
Training loss: 3.215748396601348
Validation loss: 3.4053075246127853

Epoch: 5| Step: 6
Training loss: 3.429642453256277
Validation loss: 3.4046490645644782

Epoch: 5| Step: 7
Training loss: 3.7875742083540835
Validation loss: 3.4036502902912535

Epoch: 5| Step: 8
Training loss: 3.275700408352877
Validation loss: 3.4028206818714812

Epoch: 5| Step: 9
Training loss: 4.337250381894518
Validation loss: 3.4014900021438796

Epoch: 5| Step: 10
Training loss: 3.6954756009196146
Validation loss: 3.4006054266215044

Epoch: 31| Step: 0
Training loss: 4.443534294290541
Validation loss: 3.39939518175055

Epoch: 5| Step: 1
Training loss: 3.4944256942911753
Validation loss: 3.3986498573875683

Epoch: 5| Step: 2
Training loss: 3.884367663989578
Validation loss: 3.3980188051717497

Epoch: 5| Step: 3
Training loss: 3.634704622128807
Validation loss: 3.3968674075322762

Epoch: 5| Step: 4
Training loss: 3.769375022062119
Validation loss: 3.395937101881302

Epoch: 5| Step: 5
Training loss: 3.3277058941934023
Validation loss: 3.3945556739436262

Epoch: 5| Step: 6
Training loss: 3.719622597777557
Validation loss: 3.3935388684651024

Epoch: 5| Step: 7
Training loss: 2.8957958264746377
Validation loss: 3.3923621818118237

Epoch: 5| Step: 8
Training loss: 3.1115714898151494
Validation loss: 3.3916761865961207

Epoch: 5| Step: 9
Training loss: 3.637745909883015
Validation loss: 3.390620350001631

Epoch: 5| Step: 10
Training loss: 3.7563551140674862
Validation loss: 3.390120089368255

Epoch: 32| Step: 0
Training loss: 3.666368486822424
Validation loss: 3.389336107530355

Epoch: 5| Step: 1
Training loss: 2.855358867905463
Validation loss: 3.388296533866802

Epoch: 5| Step: 2
Training loss: 3.6734774075850916
Validation loss: 3.3870123246208297

Epoch: 5| Step: 3
Training loss: 3.268658119208639
Validation loss: 3.3855891625669328

Epoch: 5| Step: 4
Training loss: 4.560652267251166
Validation loss: 3.385531448172761

Epoch: 5| Step: 5
Training loss: 3.8133020026469335
Validation loss: 3.384463423314647

Epoch: 5| Step: 6
Training loss: 3.3275542866830516
Validation loss: 3.3835740964598617

Epoch: 5| Step: 7
Training loss: 4.047411084108537
Validation loss: 3.3827358690833744

Epoch: 5| Step: 8
Training loss: 3.542091807859471
Validation loss: 3.3817350728411992

Epoch: 5| Step: 9
Training loss: 3.3267713489255955
Validation loss: 3.3800630484987666

Epoch: 5| Step: 10
Training loss: 3.3910397043066425
Validation loss: 3.3791588530400753

Epoch: 33| Step: 0
Training loss: 3.0102967939082936
Validation loss: 3.3788864443391353

Epoch: 5| Step: 1
Training loss: 3.6375896587005863
Validation loss: 3.377945852849764

Epoch: 5| Step: 2
Training loss: 2.9637878709012173
Validation loss: 3.3768334795957817

Epoch: 5| Step: 3
Training loss: 4.051069876560437
Validation loss: 3.376363786366633

Epoch: 5| Step: 4
Training loss: 3.814572380768271
Validation loss: 3.3742134137750077

Epoch: 5| Step: 5
Training loss: 3.444296204716603
Validation loss: 3.3737496384630874

Epoch: 5| Step: 6
Training loss: 3.5325653867076183
Validation loss: 3.3728671290460714

Epoch: 5| Step: 7
Training loss: 3.635866255773252
Validation loss: 3.3715076494019325

Epoch: 5| Step: 8
Training loss: 4.107900376684023
Validation loss: 3.3713106038046132

Epoch: 5| Step: 9
Training loss: 3.5664087903451387
Validation loss: 3.3684229257816525

Epoch: 5| Step: 10
Training loss: 3.765161382856336
Validation loss: 3.369131169816384

Epoch: 34| Step: 0
Training loss: 3.080670229083887
Validation loss: 3.3665459934011643

Epoch: 5| Step: 1
Training loss: 3.901960291079239
Validation loss: 3.365753386913705

Epoch: 5| Step: 2
Training loss: 2.996975327643181
Validation loss: 3.36429772548532

Epoch: 5| Step: 3
Training loss: 4.103262993844688
Validation loss: 3.3629136423601946

Epoch: 5| Step: 4
Training loss: 3.222896534602671
Validation loss: 3.3616065948265064

Epoch: 5| Step: 5
Training loss: 4.229078520559371
Validation loss: 3.361426732857063

Epoch: 5| Step: 6
Training loss: 3.53200853691063
Validation loss: 3.360024914995843

Epoch: 5| Step: 7
Training loss: 2.9632671924099725
Validation loss: 3.3585901173859254

Epoch: 5| Step: 8
Training loss: 3.690635511882389
Validation loss: 3.3577532849593146

Epoch: 5| Step: 9
Training loss: 3.2663925218054164
Validation loss: 3.354942165377719

Epoch: 5| Step: 10
Training loss: 4.345919718970353
Validation loss: 3.353679089325996

Epoch: 35| Step: 0
Training loss: 3.8213535754760657
Validation loss: 3.351293669566481

Epoch: 5| Step: 1
Training loss: 2.997202681685057
Validation loss: 3.3501955306186573

Epoch: 5| Step: 2
Training loss: 4.286785250774161
Validation loss: 3.348166689861128

Epoch: 5| Step: 3
Training loss: 3.909933200080195
Validation loss: 3.3470611983429857

Epoch: 5| Step: 4
Training loss: 3.0512669917801283
Validation loss: 3.34585608313197

Epoch: 5| Step: 5
Training loss: 3.4485841471884164
Validation loss: 3.3450623065537424

Epoch: 5| Step: 6
Training loss: 4.012089817080044
Validation loss: 3.344102332039753

Epoch: 5| Step: 7
Training loss: 3.854690241261819
Validation loss: 3.3455240586167765

Epoch: 5| Step: 8
Training loss: 4.106651418913571
Validation loss: 3.343741658334234

Epoch: 5| Step: 9
Training loss: 3.011197333217741
Validation loss: 3.3403361706550267

Epoch: 5| Step: 10
Training loss: 2.1990339021936034
Validation loss: 3.343492766575502

Epoch: 36| Step: 0
Training loss: 4.263375272407873
Validation loss: 3.347380422924441

Epoch: 5| Step: 1
Training loss: 4.249745080819922
Validation loss: 3.3459705274442473

Epoch: 5| Step: 2
Training loss: 2.992518155226931
Validation loss: 3.338964966090459

Epoch: 5| Step: 3
Training loss: 3.3496277388800544
Validation loss: 3.3367846915282127

Epoch: 5| Step: 4
Training loss: 3.7461141162115825
Validation loss: 3.3351168680657506

Epoch: 5| Step: 5
Training loss: 3.4786738124650713
Validation loss: 3.3332630908907332

Epoch: 5| Step: 6
Training loss: 2.531624001082156
Validation loss: 3.333288382924442

Epoch: 5| Step: 7
Training loss: 3.471449617684249
Validation loss: 3.3321766435892965

Epoch: 5| Step: 8
Training loss: 3.879862656866222
Validation loss: 3.3330116598726374

Epoch: 5| Step: 9
Training loss: 3.54583402305683
Validation loss: 3.330138324716309

Epoch: 5| Step: 10
Training loss: 3.453369546231529
Validation loss: 3.3267275171556827

Epoch: 37| Step: 0
Training loss: 3.0324006403835937
Validation loss: 3.3244786962503445

Epoch: 5| Step: 1
Training loss: 3.9202948194692726
Validation loss: 3.324036459319702

Epoch: 5| Step: 2
Training loss: 3.2507094562563017
Validation loss: 3.326258379558291

Epoch: 5| Step: 3
Training loss: 3.9393855832862705
Validation loss: 3.329072256594004

Epoch: 5| Step: 4
Training loss: 3.8781662587592365
Validation loss: 3.3291049138421624

Epoch: 5| Step: 5
Training loss: 3.6484043029973914
Validation loss: 3.3233650674682136

Epoch: 5| Step: 6
Training loss: 2.890094110349143
Validation loss: 3.3206488542337333

Epoch: 5| Step: 7
Training loss: 4.379806929561436
Validation loss: 3.318638378920653

Epoch: 5| Step: 8
Training loss: 2.9749790094741044
Validation loss: 3.3175465031813913

Epoch: 5| Step: 9
Training loss: 3.694509664993974
Validation loss: 3.317438216451642

Epoch: 5| Step: 10
Training loss: 3.233888451289076
Validation loss: 3.3170026908141246

Epoch: 38| Step: 0
Training loss: 3.4790883007855786
Validation loss: 3.316687281035346

Epoch: 5| Step: 1
Training loss: 3.3987876974739097
Validation loss: 3.314855159716597

Epoch: 5| Step: 2
Training loss: 3.6701063725909653
Validation loss: 3.314293286004837

Epoch: 5| Step: 3
Training loss: 4.216481595004966
Validation loss: 3.312931214597064

Epoch: 5| Step: 4
Training loss: 3.629703364376585
Validation loss: 3.311376697343657

Epoch: 5| Step: 5
Training loss: 3.611331161902117
Validation loss: 3.3107229850163127

Epoch: 5| Step: 6
Training loss: 3.0069962620155333
Validation loss: 3.309206217534007

Epoch: 5| Step: 7
Training loss: 3.922791514508053
Validation loss: 3.3077394636591086

Epoch: 5| Step: 8
Training loss: 3.439298818009
Validation loss: 3.3063867694169966

Epoch: 5| Step: 9
Training loss: 3.1196576038186428
Validation loss: 3.3061466254459866

Epoch: 5| Step: 10
Training loss: 3.424279469903192
Validation loss: 3.3051848015926564

Epoch: 39| Step: 0
Training loss: 3.571348344719206
Validation loss: 3.304635415139122

Epoch: 5| Step: 1
Training loss: 3.7544370468496773
Validation loss: 3.303492413553538

Epoch: 5| Step: 2
Training loss: 3.5761945422718275
Validation loss: 3.302343093117937

Epoch: 5| Step: 3
Training loss: 2.745467872977707
Validation loss: 3.3010437827676147

Epoch: 5| Step: 4
Training loss: 3.872257000149592
Validation loss: 3.3013460694832624

Epoch: 5| Step: 5
Training loss: 3.1910185000541738
Validation loss: 3.301144330377295

Epoch: 5| Step: 6
Training loss: 3.2432108171878253
Validation loss: 3.297220764551241

Epoch: 5| Step: 7
Training loss: 4.094476300522096
Validation loss: 3.2982300111874934

Epoch: 5| Step: 8
Training loss: 3.547543903748541
Validation loss: 3.2969824419592135

Epoch: 5| Step: 9
Training loss: 3.3082936768993627
Validation loss: 3.2960632418162863

Epoch: 5| Step: 10
Training loss: 3.947019543874102
Validation loss: 3.294854558282127

Epoch: 40| Step: 0
Training loss: 2.8578528850323615
Validation loss: 3.293575914381653

Epoch: 5| Step: 1
Training loss: 3.8059409581394275
Validation loss: 3.2925584601935878

Epoch: 5| Step: 2
Training loss: 3.7158414862652314
Validation loss: 3.292964331119921

Epoch: 5| Step: 3
Training loss: 4.327019174926955
Validation loss: 3.291589801202917

Epoch: 5| Step: 4
Training loss: 3.918043476278286
Validation loss: 3.2904149784857415

Epoch: 5| Step: 5
Training loss: 3.287248487243142
Validation loss: 3.2899364759736605

Epoch: 5| Step: 6
Training loss: 2.6750442715127583
Validation loss: 3.288476135787386

Epoch: 5| Step: 7
Training loss: 3.581657165495807
Validation loss: 3.287612623143665

Epoch: 5| Step: 8
Training loss: 3.342908806919781
Validation loss: 3.285206482096594

Epoch: 5| Step: 9
Training loss: 3.3657319713371203
Validation loss: 3.2850486631721174

Epoch: 5| Step: 10
Training loss: 3.7461440288841064
Validation loss: 3.284913353671233

Epoch: 41| Step: 0
Training loss: 3.6828652690073587
Validation loss: 3.2833988401995926

Epoch: 5| Step: 1
Training loss: 4.5348786656005196
Validation loss: 3.2847742221408223

Epoch: 5| Step: 2
Training loss: 3.5400181842056737
Validation loss: 3.2806562739140572

Epoch: 5| Step: 3
Training loss: 3.727139794121207
Validation loss: 3.2803851369269137

Epoch: 5| Step: 4
Training loss: 3.278893051139074
Validation loss: 3.2805808592633907

Epoch: 5| Step: 5
Training loss: 3.1323932928495535
Validation loss: 3.2788828102995717

Epoch: 5| Step: 6
Training loss: 3.016924642277327
Validation loss: 3.278894083196251

Epoch: 5| Step: 7
Training loss: 3.8417526886439637
Validation loss: 3.2783130015905275

Epoch: 5| Step: 8
Training loss: 3.5008505741364684
Validation loss: 3.276847668342071

Epoch: 5| Step: 9
Training loss: 3.3040577534207016
Validation loss: 3.2770501310481475

Epoch: 5| Step: 10
Training loss: 2.865525930973926
Validation loss: 3.275184357316954

Epoch: 42| Step: 0
Training loss: 3.5175613157219137
Validation loss: 3.2748398600846294

Epoch: 5| Step: 1
Training loss: 3.308069541144849
Validation loss: 3.2738378371362256

Epoch: 5| Step: 2
Training loss: 4.108018078163432
Validation loss: 3.273058275960433

Epoch: 5| Step: 3
Training loss: 3.1567385455940533
Validation loss: 3.270909298250504

Epoch: 5| Step: 4
Training loss: 2.860577273230109
Validation loss: 3.27103243717503

Epoch: 5| Step: 5
Training loss: 3.6231840123136116
Validation loss: 3.270521262049153

Epoch: 5| Step: 6
Training loss: 3.8716323739573606
Validation loss: 3.2691374401040907

Epoch: 5| Step: 7
Training loss: 3.757390178971469
Validation loss: 3.2688071644786163

Epoch: 5| Step: 8
Training loss: 3.464568908869356
Validation loss: 3.2669259041524317

Epoch: 5| Step: 9
Training loss: 2.9121357374833736
Validation loss: 3.268430482613916

Epoch: 5| Step: 10
Training loss: 3.9743642670507033
Validation loss: 3.2669654493787585

Epoch: 43| Step: 0
Training loss: 3.814989996580755
Validation loss: 3.2655625967108284

Epoch: 5| Step: 1
Training loss: 3.3470506865963383
Validation loss: 3.2649195276513234

Epoch: 5| Step: 2
Training loss: 3.7155947081644083
Validation loss: 3.2632451371166913

Epoch: 5| Step: 3
Training loss: 3.2660748477635733
Validation loss: 3.262571551670995

Epoch: 5| Step: 4
Training loss: 3.767861109933592
Validation loss: 3.262694245460568

Epoch: 5| Step: 5
Training loss: 3.815633892826899
Validation loss: 3.2620228277429617

Epoch: 5| Step: 6
Training loss: 3.7841200852161045
Validation loss: 3.2606925542287684

Epoch: 5| Step: 7
Training loss: 3.184701176972321
Validation loss: 3.2611377470008516

Epoch: 5| Step: 8
Training loss: 3.4235754795726434
Validation loss: 3.25958540121163

Epoch: 5| Step: 9
Training loss: 2.5884276786488
Validation loss: 3.25885477363969

Epoch: 5| Step: 10
Training loss: 3.772183986039935
Validation loss: 3.257046959536728

Epoch: 44| Step: 0
Training loss: 3.399616747180476
Validation loss: 3.2561482645215243

Epoch: 5| Step: 1
Training loss: 3.533589086333425
Validation loss: 3.2554791821754234

Epoch: 5| Step: 2
Training loss: 3.436146140084922
Validation loss: 3.253897009111849

Epoch: 5| Step: 3
Training loss: 3.365520870259077
Validation loss: 3.255255363403543

Epoch: 5| Step: 4
Training loss: 3.7113140999284386
Validation loss: 3.2518570235106843

Epoch: 5| Step: 5
Training loss: 3.757164151733822
Validation loss: 3.2520858698630954

Epoch: 5| Step: 6
Training loss: 3.3139974700144545
Validation loss: 3.25190370682213

Epoch: 5| Step: 7
Training loss: 3.5432478722224316
Validation loss: 3.2502385186827407

Epoch: 5| Step: 8
Training loss: 3.5440703070665323
Validation loss: 3.248885377714864

Epoch: 5| Step: 9
Training loss: 3.3637720474320134
Validation loss: 3.249319879378638

Epoch: 5| Step: 10
Training loss: 3.5596753349561827
Validation loss: 3.2470709425402617

Epoch: 45| Step: 0
Training loss: 3.3545150733844493
Validation loss: 3.2479851837551728

Epoch: 5| Step: 1
Training loss: 3.867891004902499
Validation loss: 3.2469525496699445

Epoch: 5| Step: 2
Training loss: 3.2674994678686593
Validation loss: 3.2452744646695377

Epoch: 5| Step: 3
Training loss: 3.3251025305980053
Validation loss: 3.243875791476982

Epoch: 5| Step: 4
Training loss: 3.2591356842459316
Validation loss: 3.2425323164591933

Epoch: 5| Step: 5
Training loss: 3.95247297978681
Validation loss: 3.242046666166019

Epoch: 5| Step: 6
Training loss: 3.4246951113690343
Validation loss: 3.2416743971951822

Epoch: 5| Step: 7
Training loss: 2.9829587122239904
Validation loss: 3.240780824340769

Epoch: 5| Step: 8
Training loss: 3.754253391247826
Validation loss: 3.2399008190800145

Epoch: 5| Step: 9
Training loss: 3.0054589513584746
Validation loss: 3.2397543799328696

Epoch: 5| Step: 10
Training loss: 4.136839320052995
Validation loss: 3.239439547854572

Epoch: 46| Step: 0
Training loss: 3.4578802585642494
Validation loss: 3.24048174056704

Epoch: 5| Step: 1
Training loss: 3.8859033083820713
Validation loss: 3.238702688708869

Epoch: 5| Step: 2
Training loss: 3.45974759212057
Validation loss: 3.2414390541207543

Epoch: 5| Step: 3
Training loss: 4.120720464062606
Validation loss: 3.249532236020125

Epoch: 5| Step: 4
Training loss: 2.597821636241246
Validation loss: 3.2516612878228095

Epoch: 5| Step: 5
Training loss: 3.3660732470207897
Validation loss: 3.252181586214044

Epoch: 5| Step: 6
Training loss: 4.160008387557157
Validation loss: 3.2454315114590044

Epoch: 5| Step: 7
Training loss: 3.0195179848916256
Validation loss: 3.233335772205681

Epoch: 5| Step: 8
Training loss: 3.208003353307403
Validation loss: 3.23191509695126

Epoch: 5| Step: 9
Training loss: 3.4722665368537164
Validation loss: 3.2351811590145902

Epoch: 5| Step: 10
Training loss: 3.309726777800392
Validation loss: 3.2401771841262397

Epoch: 47| Step: 0
Training loss: 3.282026217247242
Validation loss: 3.232362770903606

Epoch: 5| Step: 1
Training loss: 3.7189990048428974
Validation loss: 3.2336075101893806

Epoch: 5| Step: 2
Training loss: 3.3860703213865055
Validation loss: 3.2402154117055457

Epoch: 5| Step: 3
Training loss: 3.1608252271096875
Validation loss: 3.2504458251798507

Epoch: 5| Step: 4
Training loss: 4.080971845930255
Validation loss: 3.2644583173438564

Epoch: 5| Step: 5
Training loss: 3.5360334288108715
Validation loss: 3.255830364165836

Epoch: 5| Step: 6
Training loss: 3.0391428331284875
Validation loss: 3.239301324941316

Epoch: 5| Step: 7
Training loss: 4.021343982797109
Validation loss: 3.228342086090038

Epoch: 5| Step: 8
Training loss: 3.672640586743349
Validation loss: 3.2245151060807618

Epoch: 5| Step: 9
Training loss: 2.989747967766949
Validation loss: 3.224102951295224

Epoch: 5| Step: 10
Training loss: 3.216306481100813
Validation loss: 3.229256515496725

Epoch: 48| Step: 0
Training loss: 3.372231230775244
Validation loss: 3.2255420699527826

Epoch: 5| Step: 1
Training loss: 3.9152579242812933
Validation loss: 3.223194876735354

Epoch: 5| Step: 2
Training loss: 3.100438449986279
Validation loss: 3.2217698920709683

Epoch: 5| Step: 3
Training loss: 3.7095754593350674
Validation loss: 3.221642309474197

Epoch: 5| Step: 4
Training loss: 3.8356006109224654
Validation loss: 3.2197758120906186

Epoch: 5| Step: 5
Training loss: 3.6593602962833733
Validation loss: 3.2178393520449777

Epoch: 5| Step: 6
Training loss: 2.7357539596298888
Validation loss: 3.2189022593292793

Epoch: 5| Step: 7
Training loss: 3.9988458875802135
Validation loss: 3.2208910220086864

Epoch: 5| Step: 8
Training loss: 3.44307630979879
Validation loss: 3.2218804528843803

Epoch: 5| Step: 9
Training loss: 3.23078121717556
Validation loss: 3.2222702651378516

Epoch: 5| Step: 10
Training loss: 2.8540095450783687
Validation loss: 3.218016084700609

Epoch: 49| Step: 0
Training loss: 4.093311548413221
Validation loss: 3.2156620332155637

Epoch: 5| Step: 1
Training loss: 2.831935275852224
Validation loss: 3.2132550207434587

Epoch: 5| Step: 2
Training loss: 3.336554655569798
Validation loss: 3.2161920109825166

Epoch: 5| Step: 3
Training loss: 3.2616896576640455
Validation loss: 3.2163517291916763

Epoch: 5| Step: 4
Training loss: 3.4306118008579802
Validation loss: 3.212529004911181

Epoch: 5| Step: 5
Training loss: 4.069704680354919
Validation loss: 3.211941257497204

Epoch: 5| Step: 6
Training loss: 3.9908017256042596
Validation loss: 3.2110481783056017

Epoch: 5| Step: 7
Training loss: 2.989654983211296
Validation loss: 3.2102953075490164

Epoch: 5| Step: 8
Training loss: 3.4334479291241387
Validation loss: 3.2148835100448405

Epoch: 5| Step: 9
Training loss: 2.803027498554698
Validation loss: 3.2112182737145414

Epoch: 5| Step: 10
Training loss: 3.546295790916195
Validation loss: 3.208715328738372

Epoch: 50| Step: 0
Training loss: 3.4314576188663155
Validation loss: 3.2072205954448765

Epoch: 5| Step: 1
Training loss: 2.829758314724241
Validation loss: 3.207989123806568

Epoch: 5| Step: 2
Training loss: 3.098228834611978
Validation loss: 3.2054456162552465

Epoch: 5| Step: 3
Training loss: 3.402800046540831
Validation loss: 3.2049416885470974

Epoch: 5| Step: 4
Training loss: 3.523721958358709
Validation loss: 3.2042180935171904

Epoch: 5| Step: 5
Training loss: 3.3803355110276048
Validation loss: 3.2036996385508227

Epoch: 5| Step: 6
Training loss: 3.7827092657298005
Validation loss: 3.2043666758986276

Epoch: 5| Step: 7
Training loss: 2.9473853469305267
Validation loss: 3.2009407029109647

Epoch: 5| Step: 8
Training loss: 3.695749398145334
Validation loss: 3.2023691281459956

Epoch: 5| Step: 9
Training loss: 3.8259643685356246
Validation loss: 3.204389578732674

Epoch: 5| Step: 10
Training loss: 3.9501674278604804
Validation loss: 3.2031357087467285

Epoch: 51| Step: 0
Training loss: 3.2904519523772597
Validation loss: 3.2012137492791877

Epoch: 5| Step: 1
Training loss: 3.5945793190096467
Validation loss: 3.2020719784687897

Epoch: 5| Step: 2
Training loss: 3.4065408844940483
Validation loss: 3.1977408477261178

Epoch: 5| Step: 3
Training loss: 3.8715009581012763
Validation loss: 3.197786524467599

Epoch: 5| Step: 4
Training loss: 2.8079895303373426
Validation loss: 3.1948304115406123

Epoch: 5| Step: 5
Training loss: 3.1230215294664143
Validation loss: 3.194401637051035

Epoch: 5| Step: 6
Training loss: 3.80027612385649
Validation loss: 3.1939131475203646

Epoch: 5| Step: 7
Training loss: 3.6491403168253043
Validation loss: 3.1931247429927527

Epoch: 5| Step: 8
Training loss: 3.7560419364594937
Validation loss: 3.1919406534762333

Epoch: 5| Step: 9
Training loss: 2.9498689654715426
Validation loss: 3.1906709206330968

Epoch: 5| Step: 10
Training loss: 3.5401500521394
Validation loss: 3.1947430172553055

Epoch: 52| Step: 0
Training loss: 3.3836767489026567
Validation loss: 3.1924251056118496

Epoch: 5| Step: 1
Training loss: 3.772846815423516
Validation loss: 3.191045154902387

Epoch: 5| Step: 2
Training loss: 3.6238840950626776
Validation loss: 3.1870177030978106

Epoch: 5| Step: 3
Training loss: 3.506010208498014
Validation loss: 3.187059562248818

Epoch: 5| Step: 4
Training loss: 3.416894222838325
Validation loss: 3.1864415308835876

Epoch: 5| Step: 5
Training loss: 3.240472473263056
Validation loss: 3.1862882071667293

Epoch: 5| Step: 6
Training loss: 3.603130537096651
Validation loss: 3.1835855829791058

Epoch: 5| Step: 7
Training loss: 3.1818400976739114
Validation loss: 3.184415593688022

Epoch: 5| Step: 8
Training loss: 3.4847617169963234
Validation loss: 3.185334558467653

Epoch: 5| Step: 9
Training loss: 3.889677368945253
Validation loss: 3.1848766164766977

Epoch: 5| Step: 10
Training loss: 2.402122723095709
Validation loss: 3.1842994264672595

Epoch: 53| Step: 0
Training loss: 3.629963600669778
Validation loss: 3.1846897316573517

Epoch: 5| Step: 1
Training loss: 2.904881801334457
Validation loss: 3.1956758781684753

Epoch: 5| Step: 2
Training loss: 3.4496467298891864
Validation loss: 3.200021812790186

Epoch: 5| Step: 3
Training loss: 2.3327662142066536
Validation loss: 3.1853762023163172

Epoch: 5| Step: 4
Training loss: 3.838870044397627
Validation loss: 3.1826801458007923

Epoch: 5| Step: 5
Training loss: 3.514195537296271
Validation loss: 3.179910054213393

Epoch: 5| Step: 6
Training loss: 3.9377816720153445
Validation loss: 3.1787789548351237

Epoch: 5| Step: 7
Training loss: 3.4887403845987697
Validation loss: 3.176861216451346

Epoch: 5| Step: 8
Training loss: 3.36372952015914
Validation loss: 3.1770465275115067

Epoch: 5| Step: 9
Training loss: 3.5551622010904103
Validation loss: 3.1752317528589282

Epoch: 5| Step: 10
Training loss: 3.4611828719187563
Validation loss: 3.177926877725177

Epoch: 54| Step: 0
Training loss: 3.5399640347652745
Validation loss: 3.173182066785928

Epoch: 5| Step: 1
Training loss: 3.9030423842055924
Validation loss: 3.172746368197436

Epoch: 5| Step: 2
Training loss: 3.5225307879649037
Validation loss: 3.1725850139314056

Epoch: 5| Step: 3
Training loss: 3.5088012932920702
Validation loss: 3.1738539678564295

Epoch: 5| Step: 4
Training loss: 3.850967825581584
Validation loss: 3.171818351472114

Epoch: 5| Step: 5
Training loss: 3.062489100845561
Validation loss: 3.1701737517238793

Epoch: 5| Step: 6
Training loss: 3.4966383184902714
Validation loss: 3.173607230022342

Epoch: 5| Step: 7
Training loss: 3.445582372774339
Validation loss: 3.1741829438761466

Epoch: 5| Step: 8
Training loss: 3.4107717196779506
Validation loss: 3.17497656634869

Epoch: 5| Step: 9
Training loss: 2.685051090599741
Validation loss: 3.175540340527909

Epoch: 5| Step: 10
Training loss: 3.01412610372035
Validation loss: 3.174661505621544

Epoch: 55| Step: 0
Training loss: 3.008973370744515
Validation loss: 3.17418276942294

Epoch: 5| Step: 1
Training loss: 3.2047528852156217
Validation loss: 3.1784953986565254

Epoch: 5| Step: 2
Training loss: 3.4581132994977315
Validation loss: 3.1752255941054086

Epoch: 5| Step: 3
Training loss: 3.358665497841606
Validation loss: 3.1761939477078713

Epoch: 5| Step: 4
Training loss: 3.13967364881013
Validation loss: 3.1757825779214253

Epoch: 5| Step: 5
Training loss: 3.551024845106202
Validation loss: 3.17794274229124

Epoch: 5| Step: 6
Training loss: 3.75348272723056
Validation loss: 3.1750869196798233

Epoch: 5| Step: 7
Training loss: 3.6234281354736284
Validation loss: 3.1710651438180864

Epoch: 5| Step: 8
Training loss: 3.6713987650358466
Validation loss: 3.1654856999617507

Epoch: 5| Step: 9
Training loss: 3.6833092103286145
Validation loss: 3.1678229154852198

Epoch: 5| Step: 10
Training loss: 2.8719359946596783
Validation loss: 3.1670952983411054

Epoch: 56| Step: 0
Training loss: 3.4594012224121897
Validation loss: 3.1636691897362517

Epoch: 5| Step: 1
Training loss: 3.4365635376585515
Validation loss: 3.1626854066538237

Epoch: 5| Step: 2
Training loss: 3.7452080945616126
Validation loss: 3.1623857465776215

Epoch: 5| Step: 3
Training loss: 3.8144933773637817
Validation loss: 3.1626147378320644

Epoch: 5| Step: 4
Training loss: 3.240486158231047
Validation loss: 3.162227307541357

Epoch: 5| Step: 5
Training loss: 3.951411543104995
Validation loss: 3.1602805747326506

Epoch: 5| Step: 6
Training loss: 3.3248116920324353
Validation loss: 3.162088031452659

Epoch: 5| Step: 7
Training loss: 2.600359847769271
Validation loss: 3.158259293679763

Epoch: 5| Step: 8
Training loss: 3.3402681850648968
Validation loss: 3.15834991345096

Epoch: 5| Step: 9
Training loss: 3.2935416921221115
Validation loss: 3.160029421661969

Epoch: 5| Step: 10
Training loss: 3.037400131781599
Validation loss: 3.158221438618977

Epoch: 57| Step: 0
Training loss: 2.9868524464092787
Validation loss: 3.155199608559353

Epoch: 5| Step: 1
Training loss: 3.7042995473386835
Validation loss: 3.155679513729571

Epoch: 5| Step: 2
Training loss: 3.5742987952102445
Validation loss: 3.1513835892662523

Epoch: 5| Step: 3
Training loss: 3.188628501835434
Validation loss: 3.1553433542688

Epoch: 5| Step: 4
Training loss: 3.2458472496847617
Validation loss: 3.153601528705432

Epoch: 5| Step: 5
Training loss: 3.3539845355956324
Validation loss: 3.1543522330494382

Epoch: 5| Step: 6
Training loss: 2.525737080776322
Validation loss: 3.1505213606995546

Epoch: 5| Step: 7
Training loss: 3.533315274054482
Validation loss: 3.1476168480926257

Epoch: 5| Step: 8
Training loss: 3.730812320566268
Validation loss: 3.148526524832963

Epoch: 5| Step: 9
Training loss: 3.331904597854888
Validation loss: 3.1493791463508987

Epoch: 5| Step: 10
Training loss: 4.0625619736859475
Validation loss: 3.1544168843451565

Epoch: 58| Step: 0
Training loss: 3.3647918321630987
Validation loss: 3.148169861539752

Epoch: 5| Step: 1
Training loss: 3.67455567249413
Validation loss: 3.1468026495248766

Epoch: 5| Step: 2
Training loss: 2.3583736694804496
Validation loss: 3.1437972880274154

Epoch: 5| Step: 3
Training loss: 3.157085043853126
Validation loss: 3.1448764406467773

Epoch: 5| Step: 4
Training loss: 3.349361951047688
Validation loss: 3.1451767060475517

Epoch: 5| Step: 5
Training loss: 3.459053163797577
Validation loss: 3.1423641037045273

Epoch: 5| Step: 6
Training loss: 3.6164668706270175
Validation loss: 3.1388445791861384

Epoch: 5| Step: 7
Training loss: 3.421816333285262
Validation loss: 3.132621842189978

Epoch: 5| Step: 8
Training loss: 3.656927714341967
Validation loss: 3.1232390973813744

Epoch: 5| Step: 9
Training loss: 3.481371350459092
Validation loss: 3.113218197568979

Epoch: 5| Step: 10
Training loss: 3.558140278804694
Validation loss: 3.114549892991068

Epoch: 59| Step: 0
Training loss: 3.1697057061517304
Validation loss: 3.113995579362093

Epoch: 5| Step: 1
Training loss: 3.6194718400281602
Validation loss: 3.118005867655113

Epoch: 5| Step: 2
Training loss: 3.539028411768433
Validation loss: 3.121360840381536

Epoch: 5| Step: 3
Training loss: 3.4343674691753763
Validation loss: 3.1145869100129464

Epoch: 5| Step: 4
Training loss: 3.4800827891268975
Validation loss: 3.109873804574083

Epoch: 5| Step: 5
Training loss: 3.545352558634282
Validation loss: 3.111447736759138

Epoch: 5| Step: 6
Training loss: 3.547257860669016
Validation loss: 3.113466922399131

Epoch: 5| Step: 7
Training loss: 3.2167151972876655
Validation loss: 3.1058614387491783

Epoch: 5| Step: 8
Training loss: 3.1975823806517774
Validation loss: 3.106696573253276

Epoch: 5| Step: 9
Training loss: 2.4887901755845023
Validation loss: 3.103125365686147

Epoch: 5| Step: 10
Training loss: 3.664300906756145
Validation loss: 3.1022444909484514

Epoch: 60| Step: 0
Training loss: 2.7300772761492187
Validation loss: 3.102347826709377

Epoch: 5| Step: 1
Training loss: 4.2490713563504
Validation loss: 3.105171033834319

Epoch: 5| Step: 2
Training loss: 2.8038905294492604
Validation loss: 3.1034984531486525

Epoch: 5| Step: 3
Training loss: 2.959841885338819
Validation loss: 3.1113925357060834

Epoch: 5| Step: 4
Training loss: 3.4942029901592706
Validation loss: 3.1222508912467246

Epoch: 5| Step: 5
Training loss: 3.6554757627096657
Validation loss: 3.112289463629953

Epoch: 5| Step: 6
Training loss: 3.769582228241755
Validation loss: 3.1003996632117383

Epoch: 5| Step: 7
Training loss: 2.8672822941797347
Validation loss: 3.097002681394249

Epoch: 5| Step: 8
Training loss: 3.385168933118333
Validation loss: 3.098795375053532

Epoch: 5| Step: 9
Training loss: 3.1585869022194197
Validation loss: 3.0994677830729436

Epoch: 5| Step: 10
Training loss: 3.510335647749839
Validation loss: 3.0984967839475535

Epoch: 61| Step: 0
Training loss: 3.1377516930528233
Validation loss: 3.0985221977105235

Epoch: 5| Step: 1
Training loss: 3.502744143878566
Validation loss: 3.0958817728800043

Epoch: 5| Step: 2
Training loss: 3.317535603496781
Validation loss: 3.0965534169106594

Epoch: 5| Step: 3
Training loss: 3.1193115340425894
Validation loss: 3.0941716637358696

Epoch: 5| Step: 4
Training loss: 3.858911030791834
Validation loss: 3.093504442579518

Epoch: 5| Step: 5
Training loss: 3.2268644103889255
Validation loss: 3.092016265259533

Epoch: 5| Step: 6
Training loss: 3.3896572999830124
Validation loss: 3.0901761743012592

Epoch: 5| Step: 7
Training loss: 3.155534719867004
Validation loss: 3.088112046081016

Epoch: 5| Step: 8
Training loss: 3.5816145626471605
Validation loss: 3.0862775809149934

Epoch: 5| Step: 9
Training loss: 3.214971157437008
Validation loss: 3.0868850634341465

Epoch: 5| Step: 10
Training loss: 3.258647711011422
Validation loss: 3.092213993190845

Epoch: 62| Step: 0
Training loss: 3.1777964974528548
Validation loss: 3.10093082322732

Epoch: 5| Step: 1
Training loss: 3.226915982075005
Validation loss: 3.112267816315013

Epoch: 5| Step: 2
Training loss: 3.542697143237911
Validation loss: 3.115184512867485

Epoch: 5| Step: 3
Training loss: 3.919820178831549
Validation loss: 3.088296192635334

Epoch: 5| Step: 4
Training loss: 3.334748031500094
Validation loss: 3.0792149713329517

Epoch: 5| Step: 5
Training loss: 3.4799576886115107
Validation loss: 3.083480304872488

Epoch: 5| Step: 6
Training loss: 3.4191376349524227
Validation loss: 3.0865166092316074

Epoch: 5| Step: 7
Training loss: 2.9137499439660077
Validation loss: 3.088264925369834

Epoch: 5| Step: 8
Training loss: 3.338690379019961
Validation loss: 3.0883888553094505

Epoch: 5| Step: 9
Training loss: 3.1354836660600536
Validation loss: 3.0992938838859234

Epoch: 5| Step: 10
Training loss: 3.240204795440258
Validation loss: 3.085807609602311

Epoch: 63| Step: 0
Training loss: 3.3267211818878786
Validation loss: 3.082629138070603

Epoch: 5| Step: 1
Training loss: 3.8155665337709435
Validation loss: 3.080805871434535

Epoch: 5| Step: 2
Training loss: 2.9481728019017215
Validation loss: 3.0797844867101367

Epoch: 5| Step: 3
Training loss: 4.1747890396271075
Validation loss: 3.076494707055696

Epoch: 5| Step: 4
Training loss: 2.518152519145768
Validation loss: 3.0777582100272016

Epoch: 5| Step: 5
Training loss: 3.374941931330961
Validation loss: 3.077926500248868

Epoch: 5| Step: 6
Training loss: 3.3812333929813985
Validation loss: 3.076773368026791

Epoch: 5| Step: 7
Training loss: 3.4105827003723426
Validation loss: 3.070184119586451

Epoch: 5| Step: 8
Training loss: 3.375708187824911
Validation loss: 3.0733825819821687

Epoch: 5| Step: 9
Training loss: 2.5311397010413597
Validation loss: 3.072244810501373

Epoch: 5| Step: 10
Training loss: 3.5228649951492397
Validation loss: 3.0731291113336288

Epoch: 64| Step: 0
Training loss: 3.833648806872961
Validation loss: 3.0711785864315857

Epoch: 5| Step: 1
Training loss: 2.8485631767499973
Validation loss: 3.070918747915114

Epoch: 5| Step: 2
Training loss: 3.3355827053534335
Validation loss: 3.0682400419996707

Epoch: 5| Step: 3
Training loss: 3.7341551137375304
Validation loss: 3.067731168644443

Epoch: 5| Step: 4
Training loss: 3.5685484553678273
Validation loss: 3.063634060163653

Epoch: 5| Step: 5
Training loss: 3.0590662487746307
Validation loss: 3.063529779222765

Epoch: 5| Step: 6
Training loss: 2.985943606703266
Validation loss: 3.0630549668221327

Epoch: 5| Step: 7
Training loss: 3.3709786087122398
Validation loss: 3.060478762272824

Epoch: 5| Step: 8
Training loss: 2.7651389174374317
Validation loss: 3.060510527850436

Epoch: 5| Step: 9
Training loss: 3.4112003296800064
Validation loss: 3.060221485969589

Epoch: 5| Step: 10
Training loss: 3.564159341489019
Validation loss: 3.0588704135997085

Epoch: 65| Step: 0
Training loss: 2.6483424346876268
Validation loss: 3.059015358798349

Epoch: 5| Step: 1
Training loss: 3.3909089281592073
Validation loss: 3.0571090859785883

Epoch: 5| Step: 2
Training loss: 2.969462901399936
Validation loss: 3.0569030659537693

Epoch: 5| Step: 3
Training loss: 3.640835211583028
Validation loss: 3.0559202577544426

Epoch: 5| Step: 4
Training loss: 2.8221225161056784
Validation loss: 3.0565034472480797

Epoch: 5| Step: 5
Training loss: 3.2151575873925027
Validation loss: 3.0544540273668748

Epoch: 5| Step: 6
Training loss: 3.3753317210749705
Validation loss: 3.054474566946823

Epoch: 5| Step: 7
Training loss: 4.124257107509518
Validation loss: 3.056758721730611

Epoch: 5| Step: 8
Training loss: 3.1835985429411773
Validation loss: 3.0530736041113857

Epoch: 5| Step: 9
Training loss: 3.364268017491779
Validation loss: 3.0511214995223486

Epoch: 5| Step: 10
Training loss: 3.587708677808683
Validation loss: 3.052501368590239

Epoch: 66| Step: 0
Training loss: 3.129938267351943
Validation loss: 3.05034422234001

Epoch: 5| Step: 1
Training loss: 3.9950733839797974
Validation loss: 3.0490187943577176

Epoch: 5| Step: 2
Training loss: 2.9533189175026466
Validation loss: 3.049223576458033

Epoch: 5| Step: 3
Training loss: 2.639725571442853
Validation loss: 3.0480533480525387

Epoch: 5| Step: 4
Training loss: 3.687384781411357
Validation loss: 3.0478547100083704

Epoch: 5| Step: 5
Training loss: 3.23027715149395
Validation loss: 3.0459407008125883

Epoch: 5| Step: 6
Training loss: 3.5091931996595203
Validation loss: 3.0459750831932104

Epoch: 5| Step: 7
Training loss: 3.072424863264401
Validation loss: 3.046254756071988

Epoch: 5| Step: 8
Training loss: 3.701680090643874
Validation loss: 3.044831031718098

Epoch: 5| Step: 9
Training loss: 3.3709762039996853
Validation loss: 3.0451489949208446

Epoch: 5| Step: 10
Training loss: 2.853676709818433
Validation loss: 3.046207234693608

Epoch: 67| Step: 0
Training loss: 3.574022364823395
Validation loss: 3.047228438179594

Epoch: 5| Step: 1
Training loss: 3.616796221075381
Validation loss: 3.0467940873771133

Epoch: 5| Step: 2
Training loss: 3.5006852160415
Validation loss: 3.054498680969298

Epoch: 5| Step: 3
Training loss: 3.4267813289571394
Validation loss: 3.045352145671719

Epoch: 5| Step: 4
Training loss: 3.2718478692650517
Validation loss: 3.042527553308105

Epoch: 5| Step: 5
Training loss: 3.482191967181199
Validation loss: 3.0386117407453983

Epoch: 5| Step: 6
Training loss: 2.922795604574183
Validation loss: 3.0381943007477443

Epoch: 5| Step: 7
Training loss: 3.2020958712615086
Validation loss: 3.038410109468048

Epoch: 5| Step: 8
Training loss: 3.021879834838913
Validation loss: 3.040187500194501

Epoch: 5| Step: 9
Training loss: 3.7099944833884133
Validation loss: 3.0399134110811548

Epoch: 5| Step: 10
Training loss: 2.366536671018875
Validation loss: 3.041652057953693

Epoch: 68| Step: 0
Training loss: 3.350993643904634
Validation loss: 3.0394776092405187

Epoch: 5| Step: 1
Training loss: 3.3068847566127952
Validation loss: 3.0419915335254912

Epoch: 5| Step: 2
Training loss: 3.116242765134392
Validation loss: 3.043737769765077

Epoch: 5| Step: 3
Training loss: 3.6416437254531537
Validation loss: 3.0406835880323433

Epoch: 5| Step: 4
Training loss: 3.0872140296362214
Validation loss: 3.035368967308944

Epoch: 5| Step: 5
Training loss: 2.8060732847447
Validation loss: 3.0344354003647993

Epoch: 5| Step: 6
Training loss: 3.3269232787678793
Validation loss: 3.0337740022153024

Epoch: 5| Step: 7
Training loss: 3.8788828930723014
Validation loss: 3.0322123772594494

Epoch: 5| Step: 8
Training loss: 3.3774684779731325
Validation loss: 3.0314784791116858

Epoch: 5| Step: 9
Training loss: 3.529159332111638
Validation loss: 3.0318243989827027

Epoch: 5| Step: 10
Training loss: 2.613009269029285
Validation loss: 3.032750657998583

Epoch: 69| Step: 0
Training loss: 3.597849887271609
Validation loss: 3.040767078705462

Epoch: 5| Step: 1
Training loss: 3.166588799037915
Validation loss: 3.028867254662373

Epoch: 5| Step: 2
Training loss: 2.8887228816173742
Validation loss: 3.0266510243987614

Epoch: 5| Step: 3
Training loss: 3.479030187674854
Validation loss: 3.026901361623978

Epoch: 5| Step: 4
Training loss: 2.3667429893795187
Validation loss: 3.025821167676801

Epoch: 5| Step: 5
Training loss: 3.532047282998683
Validation loss: 3.0247632490230125

Epoch: 5| Step: 6
Training loss: 3.341285867152452
Validation loss: 3.023864307269726

Epoch: 5| Step: 7
Training loss: 2.9624378761183903
Validation loss: 3.0232182701727717

Epoch: 5| Step: 8
Training loss: 3.20904529813212
Validation loss: 3.025177075552516

Epoch: 5| Step: 9
Training loss: 4.005600584720289
Validation loss: 3.025455682369972

Epoch: 5| Step: 10
Training loss: 3.477455007452637
Validation loss: 3.02343227340129

Epoch: 70| Step: 0
Training loss: 3.3236777810137363
Validation loss: 3.021061548276598

Epoch: 5| Step: 1
Training loss: 3.4372903933342482
Validation loss: 3.0199376363575876

Epoch: 5| Step: 2
Training loss: 2.9466666187384187
Validation loss: 3.019529305744929

Epoch: 5| Step: 3
Training loss: 3.0981995922633803
Validation loss: 3.0176079353771312

Epoch: 5| Step: 4
Training loss: 3.34380704171556
Validation loss: 3.0164603907656793

Epoch: 5| Step: 5
Training loss: 3.7570961251530597
Validation loss: 3.0166579865125827

Epoch: 5| Step: 6
Training loss: 3.1090695025017885
Validation loss: 3.0151957085677634

Epoch: 5| Step: 7
Training loss: 3.4636667482358163
Validation loss: 3.0154520910042417

Epoch: 5| Step: 8
Training loss: 3.3106674307418884
Validation loss: 3.015032378100936

Epoch: 5| Step: 9
Training loss: 3.134408900799267
Validation loss: 3.013217445082206

Epoch: 5| Step: 10
Training loss: 3.185165447926381
Validation loss: 3.0132720318142674

Epoch: 71| Step: 0
Training loss: 2.62810387347753
Validation loss: 3.011813826568702

Epoch: 5| Step: 1
Training loss: 3.326300609021552
Validation loss: 3.0151515008541536

Epoch: 5| Step: 2
Training loss: 3.443889021101093
Validation loss: 3.0154105073041593

Epoch: 5| Step: 3
Training loss: 2.970758180528212
Validation loss: 3.0202281313133432

Epoch: 5| Step: 4
Training loss: 3.8944164018139835
Validation loss: 3.0082417252555027

Epoch: 5| Step: 5
Training loss: 3.4235072314683395
Validation loss: 3.008435529329059

Epoch: 5| Step: 6
Training loss: 2.938844413717254
Validation loss: 3.0083409783073582

Epoch: 5| Step: 7
Training loss: 2.9393627672470144
Validation loss: 3.0106777709951182

Epoch: 5| Step: 8
Training loss: 3.495048562778028
Validation loss: 3.010777193226463

Epoch: 5| Step: 9
Training loss: 3.4281041133386903
Validation loss: 3.010351953081645

Epoch: 5| Step: 10
Training loss: 3.4879790001070803
Validation loss: 3.0101616287961597

Epoch: 72| Step: 0
Training loss: 4.181480978386416
Validation loss: 3.010551394836286

Epoch: 5| Step: 1
Training loss: 3.0517467187298357
Validation loss: 3.0083148913351816

Epoch: 5| Step: 2
Training loss: 3.4475071290228083
Validation loss: 3.007636639285951

Epoch: 5| Step: 3
Training loss: 3.589574893019737
Validation loss: 3.0045948944744683

Epoch: 5| Step: 4
Training loss: 3.736769032523846
Validation loss: 3.00338021961253

Epoch: 5| Step: 5
Training loss: 2.8376380718769143
Validation loss: 3.0010041022910867

Epoch: 5| Step: 6
Training loss: 2.4602715454026454
Validation loss: 2.9994367203990104

Epoch: 5| Step: 7
Training loss: 3.507346209351306
Validation loss: 3.001134464807196

Epoch: 5| Step: 8
Training loss: 2.8690144801341173
Validation loss: 3.0061901689057633

Epoch: 5| Step: 9
Training loss: 2.9882496551638575
Validation loss: 3.0073130902164054

Epoch: 5| Step: 10
Training loss: 3.024144447338238
Validation loss: 3.0004210638071034

Epoch: 73| Step: 0
Training loss: 2.8896423319152293
Validation loss: 3.000952884638366

Epoch: 5| Step: 1
Training loss: 3.1765117860752845
Validation loss: 3.000892074981021

Epoch: 5| Step: 2
Training loss: 3.209127913995294
Validation loss: 2.9999919843395713

Epoch: 5| Step: 3
Training loss: 3.245702102482839
Validation loss: 3.009953200271105

Epoch: 5| Step: 4
Training loss: 3.3381893231898183
Validation loss: 3.042928556693648

Epoch: 5| Step: 5
Training loss: 3.440702576416676
Validation loss: 3.0401728259081273

Epoch: 5| Step: 6
Training loss: 3.327331305053109
Validation loss: 3.0077152547043875

Epoch: 5| Step: 7
Training loss: 2.8622567085922515
Validation loss: 2.9926961687433136

Epoch: 5| Step: 8
Training loss: 3.6312216936541284
Validation loss: 2.9972254816596062

Epoch: 5| Step: 9
Training loss: 3.0688542987323695
Validation loss: 3.0383780233975926

Epoch: 5| Step: 10
Training loss: 3.859855838119405
Validation loss: 3.01799217989032

Epoch: 74| Step: 0
Training loss: 3.4088972811185987
Validation loss: 2.9932831219934717

Epoch: 5| Step: 1
Training loss: 3.314768032743902
Validation loss: 2.9905445745511994

Epoch: 5| Step: 2
Training loss: 3.4732087492854906
Validation loss: 2.997417955594981

Epoch: 5| Step: 3
Training loss: 3.744664019804156
Validation loss: 3.0437654499100573

Epoch: 5| Step: 4
Training loss: 2.8727549204247667
Validation loss: 3.003586751939605

Epoch: 5| Step: 5
Training loss: 3.0737358596184854
Validation loss: 2.9958816224122438

Epoch: 5| Step: 6
Training loss: 2.1601836218315555
Validation loss: 2.9948746179735486

Epoch: 5| Step: 7
Training loss: 4.297544780895113
Validation loss: 2.994299884381998

Epoch: 5| Step: 8
Training loss: 2.757339653132714
Validation loss: 3.000249953094672

Epoch: 5| Step: 9
Training loss: 3.4352753810079584
Validation loss: 3.0000790641989816

Epoch: 5| Step: 10
Training loss: 2.982856883642502
Validation loss: 2.9958805116853924

Epoch: 75| Step: 0
Training loss: 3.0895123985277575
Validation loss: 2.9943019802943387

Epoch: 5| Step: 1
Training loss: 2.394314281596891
Validation loss: 2.991211376313556

Epoch: 5| Step: 2
Training loss: 3.7051983272376985
Validation loss: 2.994422456828777

Epoch: 5| Step: 3
Training loss: 3.3464823459562543
Validation loss: 2.992691887291292

Epoch: 5| Step: 4
Training loss: 3.222603278447223
Validation loss: 2.990722456951524

Epoch: 5| Step: 5
Training loss: 3.3947926586360757
Validation loss: 2.9870647466044593

Epoch: 5| Step: 6
Training loss: 3.9417597420304045
Validation loss: 2.98568522786877

Epoch: 5| Step: 7
Training loss: 3.4016645171778417
Validation loss: 2.9863354321951503

Epoch: 5| Step: 8
Training loss: 3.3356347404510736
Validation loss: 2.9820976912511763

Epoch: 5| Step: 9
Training loss: 3.072424397667471
Validation loss: 2.9856693360437663

Epoch: 5| Step: 10
Training loss: 2.722279504791797
Validation loss: 2.9846534678546113

Epoch: 76| Step: 0
Training loss: 3.0759844622969865
Validation loss: 2.983028426554992

Epoch: 5| Step: 1
Training loss: 3.4455491588043414
Validation loss: 2.9829819356187044

Epoch: 5| Step: 2
Training loss: 2.9273359703284334
Validation loss: 2.983018031129027

Epoch: 5| Step: 3
Training loss: 3.10790244653649
Validation loss: 2.982032709282191

Epoch: 5| Step: 4
Training loss: 3.2878359140723203
Validation loss: 2.9818381692788622

Epoch: 5| Step: 5
Training loss: 3.4968944122893793
Validation loss: 2.982452839615698

Epoch: 5| Step: 6
Training loss: 3.282985555235324
Validation loss: 2.978178018728281

Epoch: 5| Step: 7
Training loss: 3.5593621338301125
Validation loss: 2.9774892863499174

Epoch: 5| Step: 8
Training loss: 2.7533186048832667
Validation loss: 2.980546963841888

Epoch: 5| Step: 9
Training loss: 3.5112116938749365
Validation loss: 2.986711644458975

Epoch: 5| Step: 10
Training loss: 3.303527484144937
Validation loss: 2.9856135748864565

Epoch: 77| Step: 0
Training loss: 3.3889915645310906
Validation loss: 2.9823970870875836

Epoch: 5| Step: 1
Training loss: 3.568686751625251
Validation loss: 2.9872721160159

Epoch: 5| Step: 2
Training loss: 3.52347512235665
Validation loss: 2.9756109630774707

Epoch: 5| Step: 3
Training loss: 3.779937642506526
Validation loss: 2.9754967045732914

Epoch: 5| Step: 4
Training loss: 2.8606924555207334
Validation loss: 2.9729202022020247

Epoch: 5| Step: 5
Training loss: 3.3252640009884225
Validation loss: 2.9694635247275905

Epoch: 5| Step: 6
Training loss: 2.923696674253674
Validation loss: 2.9682560577267614

Epoch: 5| Step: 7
Training loss: 3.5567797864558357
Validation loss: 2.967336062127948

Epoch: 5| Step: 8
Training loss: 2.5642701524595495
Validation loss: 2.965638373354392

Epoch: 5| Step: 9
Training loss: 3.3063901298263025
Validation loss: 2.9689433045160634

Epoch: 5| Step: 10
Training loss: 2.6739584847125637
Validation loss: 2.9669985636566047

Epoch: 78| Step: 0
Training loss: 2.478076171393944
Validation loss: 2.96733257693713

Epoch: 5| Step: 1
Training loss: 2.8617985361501654
Validation loss: 2.967971536484279

Epoch: 5| Step: 2
Training loss: 3.1736831397172725
Validation loss: 2.965179126508647

Epoch: 5| Step: 3
Training loss: 3.430393989111488
Validation loss: 2.966353027680746

Epoch: 5| Step: 4
Training loss: 3.282862820936389
Validation loss: 2.965947903120689

Epoch: 5| Step: 5
Training loss: 3.3328543000924196
Validation loss: 2.9656000460686487

Epoch: 5| Step: 6
Training loss: 3.6702778690761915
Validation loss: 2.9651278572146755

Epoch: 5| Step: 7
Training loss: 3.3271124647215147
Validation loss: 2.9640307547401994

Epoch: 5| Step: 8
Training loss: 3.019065988876432
Validation loss: 2.966013103516929

Epoch: 5| Step: 9
Training loss: 3.495533682007069
Validation loss: 2.964261650912772

Epoch: 5| Step: 10
Training loss: 3.4572449009280026
Validation loss: 2.9635793392029526

Epoch: 79| Step: 0
Training loss: 3.357955277763678
Validation loss: 2.9687884429186973

Epoch: 5| Step: 1
Training loss: 2.947005293909657
Validation loss: 2.9761994200482733

Epoch: 5| Step: 2
Training loss: 3.467292548191758
Validation loss: 2.9829288280159574

Epoch: 5| Step: 3
Training loss: 2.6410022894933527
Validation loss: 2.991602633545048

Epoch: 5| Step: 4
Training loss: 3.4929793652684817
Validation loss: 2.9838200071196375

Epoch: 5| Step: 5
Training loss: 3.321077864453451
Validation loss: 2.9697934487141535

Epoch: 5| Step: 6
Training loss: 3.3982619667760203
Validation loss: 2.9625858570840755

Epoch: 5| Step: 7
Training loss: 3.35456681480853
Validation loss: 2.9573590579215856

Epoch: 5| Step: 8
Training loss: 3.2129099187300634
Validation loss: 2.9582041311120215

Epoch: 5| Step: 9
Training loss: 3.4899339338460065
Validation loss: 2.9581135462070045

Epoch: 5| Step: 10
Training loss: 2.7920622094664655
Validation loss: 2.95535032659686

Epoch: 80| Step: 0
Training loss: 2.7642002207257
Validation loss: 2.956126063109266

Epoch: 5| Step: 1
Training loss: 3.3049672686965845
Validation loss: 2.9545345715374607

Epoch: 5| Step: 2
Training loss: 2.9550024452780272
Validation loss: 2.95325156267979

Epoch: 5| Step: 3
Training loss: 3.055858182852014
Validation loss: 2.9555267448258804

Epoch: 5| Step: 4
Training loss: 3.4413106430923586
Validation loss: 2.9524340450901545

Epoch: 5| Step: 5
Training loss: 3.123604424707261
Validation loss: 2.9541925220864265

Epoch: 5| Step: 6
Training loss: 3.870716311380052
Validation loss: 2.9563397529514432

Epoch: 5| Step: 7
Training loss: 3.228151239692863
Validation loss: 2.960401326690426

Epoch: 5| Step: 8
Training loss: 3.479530422055225
Validation loss: 2.96211156497022

Epoch: 5| Step: 9
Training loss: 2.880347875671912
Validation loss: 2.9612428453225568

Epoch: 5| Step: 10
Training loss: 3.370937728365516
Validation loss: 2.958776217846842

Epoch: 81| Step: 0
Training loss: 3.1063719389715683
Validation loss: 2.9533687173472805

Epoch: 5| Step: 1
Training loss: 3.130798910393604
Validation loss: 2.9493070099572027

Epoch: 5| Step: 2
Training loss: 3.364961742620096
Validation loss: 2.948464140187569

Epoch: 5| Step: 3
Training loss: 3.4148166268798157
Validation loss: 2.94541493721836

Epoch: 5| Step: 4
Training loss: 3.818841007228341
Validation loss: 2.944680779053793

Epoch: 5| Step: 5
Training loss: 3.1873806201794457
Validation loss: 2.943453736693222

Epoch: 5| Step: 6
Training loss: 2.804686649928057
Validation loss: 2.942920003703791

Epoch: 5| Step: 7
Training loss: 3.091349585657078
Validation loss: 2.94272232742024

Epoch: 5| Step: 8
Training loss: 2.4953414428026104
Validation loss: 2.9399677803283675

Epoch: 5| Step: 9
Training loss: 3.3148527606928853
Validation loss: 2.9402723240401714

Epoch: 5| Step: 10
Training loss: 3.6833806709481247
Validation loss: 2.9425999310639

Epoch: 82| Step: 0
Training loss: 3.472331492082195
Validation loss: 2.9380854981163322

Epoch: 5| Step: 1
Training loss: 3.7841314261035404
Validation loss: 2.939547878955748

Epoch: 5| Step: 2
Training loss: 3.5029597710497296
Validation loss: 2.936563218958477

Epoch: 5| Step: 3
Training loss: 2.3416150350976173
Validation loss: 2.9377197867620968

Epoch: 5| Step: 4
Training loss: 3.1349578893531533
Validation loss: 2.9387154456963005

Epoch: 5| Step: 5
Training loss: 2.7291206666598122
Validation loss: 2.9373468251329613

Epoch: 5| Step: 6
Training loss: 3.1731474630700185
Validation loss: 2.936802112881164

Epoch: 5| Step: 7
Training loss: 3.3054714851124647
Validation loss: 2.936385045019522

Epoch: 5| Step: 8
Training loss: 3.307866580685018
Validation loss: 2.9376674264894724

Epoch: 5| Step: 9
Training loss: 3.4818393393343876
Validation loss: 2.9398579364071873

Epoch: 5| Step: 10
Training loss: 2.9160293609438708
Validation loss: 2.9368132602542336

Epoch: 83| Step: 0
Training loss: 3.361604740125318
Validation loss: 2.9402936063130043

Epoch: 5| Step: 1
Training loss: 3.454332511672304
Validation loss: 2.94085466896118

Epoch: 5| Step: 2
Training loss: 3.1243105318515436
Validation loss: 2.9392491223070865

Epoch: 5| Step: 3
Training loss: 3.4044747582434214
Validation loss: 2.943207818598482

Epoch: 5| Step: 4
Training loss: 3.465060221931759
Validation loss: 2.941477327395415

Epoch: 5| Step: 5
Training loss: 3.0662874429611664
Validation loss: 2.9411938878568527

Epoch: 5| Step: 6
Training loss: 2.9261943693547856
Validation loss: 2.939590724190617

Epoch: 5| Step: 7
Training loss: 3.144409177318031
Validation loss: 2.941777234662057

Epoch: 5| Step: 8
Training loss: 2.4462929609499873
Validation loss: 2.9285838508756963

Epoch: 5| Step: 9
Training loss: 3.6349753883504596
Validation loss: 2.9260782171366966

Epoch: 5| Step: 10
Training loss: 3.1482655972864055
Validation loss: 2.926221247997671

Epoch: 84| Step: 0
Training loss: 2.874589144333197
Validation loss: 2.92505075838207

Epoch: 5| Step: 1
Training loss: 3.259166116138146
Validation loss: 2.92582242261406

Epoch: 5| Step: 2
Training loss: 3.5148144953303686
Validation loss: 2.9233528292482407

Epoch: 5| Step: 3
Training loss: 2.851941394455227
Validation loss: 2.9230859850758417

Epoch: 5| Step: 4
Training loss: 3.565973161554672
Validation loss: 2.9250326361113794

Epoch: 5| Step: 5
Training loss: 3.2791937788569974
Validation loss: 2.9238667815271087

Epoch: 5| Step: 6
Training loss: 3.1195446462174012
Validation loss: 2.9214604818368377

Epoch: 5| Step: 7
Training loss: 2.87460092179675
Validation loss: 2.9222583160683366

Epoch: 5| Step: 8
Training loss: 3.815114360010202
Validation loss: 2.92014074171664

Epoch: 5| Step: 9
Training loss: 2.578550176529132
Validation loss: 2.9182467128845673

Epoch: 5| Step: 10
Training loss: 3.408128972599492
Validation loss: 2.9187381074587617

Epoch: 85| Step: 0
Training loss: 3.3268000154646367
Validation loss: 2.9180002272463823

Epoch: 5| Step: 1
Training loss: 2.943961807697767
Validation loss: 2.9180297581613694

Epoch: 5| Step: 2
Training loss: 2.741427672229904
Validation loss: 2.9162450992612374

Epoch: 5| Step: 3
Training loss: 2.51792139475739
Validation loss: 2.9189277978604773

Epoch: 5| Step: 4
Training loss: 3.132244715049585
Validation loss: 2.9192301675349226

Epoch: 5| Step: 5
Training loss: 3.652122972312819
Validation loss: 2.921804641667057

Epoch: 5| Step: 6
Training loss: 3.32766118645856
Validation loss: 2.921367371947998

Epoch: 5| Step: 7
Training loss: 3.3454417289707017
Validation loss: 2.920241787314951

Epoch: 5| Step: 8
Training loss: 3.6291501196313596
Validation loss: 2.9207332938774537

Epoch: 5| Step: 9
Training loss: 3.294863408083814
Validation loss: 2.9157078047266305

Epoch: 5| Step: 10
Training loss: 3.165957036732346
Validation loss: 2.913202466931716

Epoch: 86| Step: 0
Training loss: 3.6960260133859957
Validation loss: 2.917511641519953

Epoch: 5| Step: 1
Training loss: 3.29242163261469
Validation loss: 2.913258903039602

Epoch: 5| Step: 2
Training loss: 3.0525959786487147
Validation loss: 2.9119384629197613

Epoch: 5| Step: 3
Training loss: 3.20254645356339
Validation loss: 2.9121773186966804

Epoch: 5| Step: 4
Training loss: 3.392766741932185
Validation loss: 2.9107763754665994

Epoch: 5| Step: 5
Training loss: 2.9948404767025565
Validation loss: 2.908727355008964

Epoch: 5| Step: 6
Training loss: 3.2339537710213215
Validation loss: 2.909069363141023

Epoch: 5| Step: 7
Training loss: 2.773460624490964
Validation loss: 2.906792064284446

Epoch: 5| Step: 8
Training loss: 3.3766642105480225
Validation loss: 2.909870993896526

Epoch: 5| Step: 9
Training loss: 2.8270991872869087
Validation loss: 2.9083421832952925

Epoch: 5| Step: 10
Training loss: 3.292349651961943
Validation loss: 2.911689333671079

Epoch: 87| Step: 0
Training loss: 2.7503472022307665
Validation loss: 2.911602064191375

Epoch: 5| Step: 1
Training loss: 2.784772207097443
Validation loss: 2.9108418719287164

Epoch: 5| Step: 2
Training loss: 3.265523808567889
Validation loss: 2.905891319579592

Epoch: 5| Step: 3
Training loss: 2.743280524405679
Validation loss: 2.908435433393784

Epoch: 5| Step: 4
Training loss: 3.1059592957196784
Validation loss: 2.9037795525457133

Epoch: 5| Step: 5
Training loss: 3.2463653487554507
Validation loss: 2.9055882658861223

Epoch: 5| Step: 6
Training loss: 3.864709048355695
Validation loss: 2.9043329280251253

Epoch: 5| Step: 7
Training loss: 2.928559027456152
Validation loss: 2.9036488240220764

Epoch: 5| Step: 8
Training loss: 3.2941129422955613
Validation loss: 2.905504471335884

Epoch: 5| Step: 9
Training loss: 3.4703818941628035
Validation loss: 2.9023707700254535

Epoch: 5| Step: 10
Training loss: 3.509520117187234
Validation loss: 2.901784132477317

Epoch: 88| Step: 0
Training loss: 3.8786246052473516
Validation loss: 2.9005926197831435

Epoch: 5| Step: 1
Training loss: 3.327786853787105
Validation loss: 2.8999434103870487

Epoch: 5| Step: 2
Training loss: 3.5822737849836455
Validation loss: 2.8990315178347568

Epoch: 5| Step: 3
Training loss: 3.425321332796407
Validation loss: 2.897359215099118

Epoch: 5| Step: 4
Training loss: 3.3165681437774404
Validation loss: 2.898040764675284

Epoch: 5| Step: 5
Training loss: 2.7774261591149343
Validation loss: 2.8988869261153254

Epoch: 5| Step: 6
Training loss: 2.5589563010965293
Validation loss: 2.9029170947203062

Epoch: 5| Step: 7
Training loss: 2.8051969867698276
Validation loss: 2.913389364014295

Epoch: 5| Step: 8
Training loss: 3.6111078767680493
Validation loss: 2.9550869044649057

Epoch: 5| Step: 9
Training loss: 2.865953559302235
Validation loss: 2.998937269887818

Epoch: 5| Step: 10
Training loss: 2.7016704372291054
Validation loss: 3.033547599999851

Epoch: 89| Step: 0
Training loss: 3.2198283046652407
Validation loss: 2.948407416283656

Epoch: 5| Step: 1
Training loss: 3.430595816420181
Validation loss: 2.9115114725418185

Epoch: 5| Step: 2
Training loss: 3.2850292421662255
Validation loss: 2.8990513554782096

Epoch: 5| Step: 3
Training loss: 2.6351531629547122
Validation loss: 2.898037383687569

Epoch: 5| Step: 4
Training loss: 3.7202368576774356
Validation loss: 2.9260815499537642

Epoch: 5| Step: 5
Training loss: 3.664301687538815
Validation loss: 2.8977712007942755

Epoch: 5| Step: 6
Training loss: 3.2487023036929714
Validation loss: 2.8949824780216526

Epoch: 5| Step: 7
Training loss: 2.7183510498585965
Validation loss: 2.9011737209233956

Epoch: 5| Step: 8
Training loss: 2.6157718302761817
Validation loss: 3.0177455381095903

Epoch: 5| Step: 9
Training loss: 3.1270449241873295
Validation loss: 3.0260001448991205

Epoch: 5| Step: 10
Training loss: 3.580489930455027
Validation loss: 2.9878512294078297

Epoch: 90| Step: 0
Training loss: 2.9633247997846195
Validation loss: 2.8935508068912936

Epoch: 5| Step: 1
Training loss: 2.9971328385767615
Validation loss: 2.886723257896623

Epoch: 5| Step: 2
Training loss: 3.390302370253008
Validation loss: 2.883170246761656

Epoch: 5| Step: 3
Training loss: 3.3752954141816396
Validation loss: 2.8890788849276086

Epoch: 5| Step: 4
Training loss: 3.1675964964610137
Validation loss: 2.9155965218878084

Epoch: 5| Step: 5
Training loss: 3.110985573627568
Validation loss: 2.9347959162705455

Epoch: 5| Step: 6
Training loss: 3.307888780091846
Validation loss: 2.925564379076084

Epoch: 5| Step: 7
Training loss: 3.131054620491157
Validation loss: 2.8947364291898174

Epoch: 5| Step: 8
Training loss: 3.472694971750512
Validation loss: 2.893211974246147

Epoch: 5| Step: 9
Training loss: 3.2547560883765496
Validation loss: 2.8977305359941106

Epoch: 5| Step: 10
Training loss: 2.8041277568624867
Validation loss: 2.887359628371498

Epoch: 91| Step: 0
Training loss: 3.044420554615722
Validation loss: 2.8882748944520222

Epoch: 5| Step: 1
Training loss: 4.012477249603899
Validation loss: 2.906635398684806

Epoch: 5| Step: 2
Training loss: 3.7226330655347692
Validation loss: 2.9035884036835466

Epoch: 5| Step: 3
Training loss: 3.0847745225016516
Validation loss: 2.883200422509015

Epoch: 5| Step: 4
Training loss: 2.49020086527699
Validation loss: 2.884320597146178

Epoch: 5| Step: 5
Training loss: 3.352434947316468
Validation loss: 2.8861833348080714

Epoch: 5| Step: 6
Training loss: 3.1572315464989273
Validation loss: 2.8841599740865975

Epoch: 5| Step: 7
Training loss: 3.075528826637228
Validation loss: 2.8828862127437644

Epoch: 5| Step: 8
Training loss: 2.919002977798997
Validation loss: 2.8837259235400508

Epoch: 5| Step: 9
Training loss: 2.9715293322236658
Validation loss: 2.879901299890388

Epoch: 5| Step: 10
Training loss: 2.8838583437008833
Validation loss: 2.8797427378196336

Epoch: 92| Step: 0
Training loss: 2.6667864792452
Validation loss: 2.890906571030711

Epoch: 5| Step: 1
Training loss: 3.3196814083146533
Validation loss: 2.8907224382087744

Epoch: 5| Step: 2
Training loss: 2.7626125502637455
Validation loss: 2.8836891292543436

Epoch: 5| Step: 3
Training loss: 2.7745909965085835
Validation loss: 2.8856653130282353

Epoch: 5| Step: 4
Training loss: 3.475722719412642
Validation loss: 2.8766538349325943

Epoch: 5| Step: 5
Training loss: 3.6391330002949123
Validation loss: 2.876054007924869

Epoch: 5| Step: 6
Training loss: 2.7199287928348492
Validation loss: 2.8736039892489598

Epoch: 5| Step: 7
Training loss: 3.3062780714375712
Validation loss: 2.874794321786316

Epoch: 5| Step: 8
Training loss: 3.367357431181896
Validation loss: 2.878501754254252

Epoch: 5| Step: 9
Training loss: 3.3675090875198554
Validation loss: 2.8806470418065264

Epoch: 5| Step: 10
Training loss: 3.3924708813378337
Validation loss: 2.878254587817417

Epoch: 93| Step: 0
Training loss: 2.8465001149407865
Validation loss: 2.8757909344003583

Epoch: 5| Step: 1
Training loss: 3.2230197770816535
Validation loss: 2.875466635679806

Epoch: 5| Step: 2
Training loss: 3.6487838286673995
Validation loss: 2.8732654284318713

Epoch: 5| Step: 3
Training loss: 2.424179654139609
Validation loss: 2.8710155135698345

Epoch: 5| Step: 4
Training loss: 3.3940387188529897
Validation loss: 2.8730514088097

Epoch: 5| Step: 5
Training loss: 2.7700731960499905
Validation loss: 2.873005343149885

Epoch: 5| Step: 6
Training loss: 3.971211788772926
Validation loss: 2.872336164286906

Epoch: 5| Step: 7
Training loss: 3.052647526555714
Validation loss: 2.8693492101586564

Epoch: 5| Step: 8
Training loss: 2.9957884790903035
Validation loss: 2.8708378472185467

Epoch: 5| Step: 9
Training loss: 3.390102785740896
Validation loss: 2.8722477205343395

Epoch: 5| Step: 10
Training loss: 2.696532749989352
Validation loss: 2.8681296249513712

Epoch: 94| Step: 0
Training loss: 2.737062713673909
Validation loss: 2.8721564552796823

Epoch: 5| Step: 1
Training loss: 3.14496157527187
Validation loss: 2.8690342697705002

Epoch: 5| Step: 2
Training loss: 3.638945228845859
Validation loss: 2.867227336826642

Epoch: 5| Step: 3
Training loss: 3.3867559199949873
Validation loss: 2.8658967578829007

Epoch: 5| Step: 4
Training loss: 3.452481723435937
Validation loss: 2.8653497351222303

Epoch: 5| Step: 5
Training loss: 3.7696472466365747
Validation loss: 2.86377847292084

Epoch: 5| Step: 6
Training loss: 2.9520395696102097
Validation loss: 2.8628379365442784

Epoch: 5| Step: 7
Training loss: 3.463370473354759
Validation loss: 2.863324032218941

Epoch: 5| Step: 8
Training loss: 2.584641976272113
Validation loss: 2.863257370899456

Epoch: 5| Step: 9
Training loss: 2.884208692589645
Validation loss: 2.8601603965577853

Epoch: 5| Step: 10
Training loss: 2.253268093692089
Validation loss: 2.8619486277260027

Epoch: 95| Step: 0
Training loss: 3.6956566293499327
Validation loss: 2.8633142166199574

Epoch: 5| Step: 1
Training loss: 3.3729267110001544
Validation loss: 2.8635557567127865

Epoch: 5| Step: 2
Training loss: 2.6064658937752894
Validation loss: 2.8623169310926153

Epoch: 5| Step: 3
Training loss: 2.5341782762821214
Validation loss: 2.862588030402841

Epoch: 5| Step: 4
Training loss: 2.592929204654759
Validation loss: 2.8629963513759833

Epoch: 5| Step: 5
Training loss: 3.7358474701452185
Validation loss: 2.858639472829135

Epoch: 5| Step: 6
Training loss: 3.2300136480840265
Validation loss: 2.855840924113463

Epoch: 5| Step: 7
Training loss: 3.088239289396036
Validation loss: 2.858649045303939

Epoch: 5| Step: 8
Training loss: 3.0062505456364823
Validation loss: 2.8673404816975814

Epoch: 5| Step: 9
Training loss: 3.3049193677429884
Validation loss: 2.876235020739205

Epoch: 5| Step: 10
Training loss: 3.26090786842296
Validation loss: 2.8673437683451337

Epoch: 96| Step: 0
Training loss: 2.7044309427193713
Validation loss: 2.8780114647310997

Epoch: 5| Step: 1
Training loss: 3.2146626417983164
Validation loss: 2.8708726684108266

Epoch: 5| Step: 2
Training loss: 3.3869354284329827
Validation loss: 2.8767343803071137

Epoch: 5| Step: 3
Training loss: 3.3813353522452134
Validation loss: 2.862246708406869

Epoch: 5| Step: 4
Training loss: 2.837220629412415
Validation loss: 2.8521650112989847

Epoch: 5| Step: 5
Training loss: 2.953373974189672
Validation loss: 2.8503901394679936

Epoch: 5| Step: 6
Training loss: 3.0168109992750094
Validation loss: 2.851172562168845

Epoch: 5| Step: 7
Training loss: 3.0733501753549017
Validation loss: 2.8516251230548773

Epoch: 5| Step: 8
Training loss: 3.0140063433362076
Validation loss: 2.8512213102363417

Epoch: 5| Step: 9
Training loss: 3.61293415773792
Validation loss: 2.8532630155169687

Epoch: 5| Step: 10
Training loss: 3.4272032062625937
Validation loss: 2.8531642468184812

Epoch: 97| Step: 0
Training loss: 3.4810043933186456
Validation loss: 2.8566915794407475

Epoch: 5| Step: 1
Training loss: 3.4371493073953197
Validation loss: 2.8543114619079923

Epoch: 5| Step: 2
Training loss: 3.086025420276425
Validation loss: 2.853035070979758

Epoch: 5| Step: 3
Training loss: 3.6596882621706364
Validation loss: 2.8530155163169812

Epoch: 5| Step: 4
Training loss: 3.231331245389683
Validation loss: 2.8502989820306555

Epoch: 5| Step: 5
Training loss: 2.5311721978181025
Validation loss: 2.8502196549153918

Epoch: 5| Step: 6
Training loss: 2.771560334555218
Validation loss: 2.850078582903642

Epoch: 5| Step: 7
Training loss: 3.193765802213689
Validation loss: 2.8453267227239682

Epoch: 5| Step: 8
Training loss: 3.2277872564366663
Validation loss: 2.845693572939899

Epoch: 5| Step: 9
Training loss: 2.851054274327076
Validation loss: 2.8437902354635245

Epoch: 5| Step: 10
Training loss: 3.0061377680839385
Validation loss: 2.844649718748101

Epoch: 98| Step: 0
Training loss: 2.9312305506729985
Validation loss: 2.8421592513777183

Epoch: 5| Step: 1
Training loss: 2.8311970080538527
Validation loss: 2.8422793218859024

Epoch: 5| Step: 2
Training loss: 3.424280166162236
Validation loss: 2.841503217194063

Epoch: 5| Step: 3
Training loss: 3.547104882676301
Validation loss: 2.8478215272580636

Epoch: 5| Step: 4
Training loss: 2.9184017651644605
Validation loss: 2.86231344073362

Epoch: 5| Step: 5
Training loss: 3.065929438944243
Validation loss: 2.8626928098757514

Epoch: 5| Step: 6
Training loss: 3.6199751919481193
Validation loss: 2.8639900167332115

Epoch: 5| Step: 7
Training loss: 3.2182853881910085
Validation loss: 2.8591019121053733

Epoch: 5| Step: 8
Training loss: 2.962154249142899
Validation loss: 2.850900316184899

Epoch: 5| Step: 9
Training loss: 3.198855797529972
Validation loss: 2.8435102738326425

Epoch: 5| Step: 10
Training loss: 2.6390051754766657
Validation loss: 2.8442739594255237

Epoch: 99| Step: 0
Training loss: 3.6916408242267633
Validation loss: 2.8364730722926415

Epoch: 5| Step: 1
Training loss: 3.057549972063423
Validation loss: 2.839941155784353

Epoch: 5| Step: 2
Training loss: 2.9518507372949188
Validation loss: 2.835722985648185

Epoch: 5| Step: 3
Training loss: 2.621484491413349
Validation loss: 2.832095708909095

Epoch: 5| Step: 4
Training loss: 3.1948768673184667
Validation loss: 2.831765252769626

Epoch: 5| Step: 5
Training loss: 2.998273034527575
Validation loss: 2.8340432434646115

Epoch: 5| Step: 6
Training loss: 3.1971409423230193
Validation loss: 2.8316207725183165

Epoch: 5| Step: 7
Training loss: 3.405528140791764
Validation loss: 2.8287638081760296

Epoch: 5| Step: 8
Training loss: 3.1800722831332227
Validation loss: 2.8319496432135343

Epoch: 5| Step: 9
Training loss: 2.7651235697004375
Validation loss: 2.830163442580182

Epoch: 5| Step: 10
Training loss: 3.318827362020948
Validation loss: 2.833072085403559

Epoch: 100| Step: 0
Training loss: 3.5228574152647925
Validation loss: 2.831833593297687

Epoch: 5| Step: 1
Training loss: 3.546662311646888
Validation loss: 2.8273944109364213

Epoch: 5| Step: 2
Training loss: 3.231530897079856
Validation loss: 2.834046515356403

Epoch: 5| Step: 3
Training loss: 3.189628339300849
Validation loss: 2.829464277297991

Epoch: 5| Step: 4
Training loss: 2.6158666209711336
Validation loss: 2.8322551227212047

Epoch: 5| Step: 5
Training loss: 3.2703064577180805
Validation loss: 2.830006333262918

Epoch: 5| Step: 6
Training loss: 2.8194322559696654
Validation loss: 2.8290047386299477

Epoch: 5| Step: 7
Training loss: 2.97831998589045
Validation loss: 2.8274217518852685

Epoch: 5| Step: 8
Training loss: 2.6834013979633298
Validation loss: 2.8264163842187915

Epoch: 5| Step: 9
Training loss: 3.614005153413781
Validation loss: 2.8286265584150327

Epoch: 5| Step: 10
Training loss: 2.6464112218902565
Validation loss: 2.8297043716914208

Epoch: 101| Step: 0
Training loss: 3.8144710011021856
Validation loss: 2.8325466050607218

Epoch: 5| Step: 1
Training loss: 2.791643759410496
Validation loss: 2.838929323923696

Epoch: 5| Step: 2
Training loss: 2.862002806816084
Validation loss: 2.8382501942298224

Epoch: 5| Step: 3
Training loss: 2.9920158635805194
Validation loss: 2.827712588306228

Epoch: 5| Step: 4
Training loss: 3.118067414040071
Validation loss: 2.8300998690617165

Epoch: 5| Step: 5
Training loss: 3.0590327351001103
Validation loss: 2.825110803148649

Epoch: 5| Step: 6
Training loss: 2.851126692403846
Validation loss: 2.8193525568468365

Epoch: 5| Step: 7
Training loss: 3.118018629898096
Validation loss: 2.8173881137875014

Epoch: 5| Step: 8
Training loss: 3.2130871188014516
Validation loss: 2.8184783309865007

Epoch: 5| Step: 9
Training loss: 3.251623188499146
Validation loss: 2.820216911540606

Epoch: 5| Step: 10
Training loss: 3.1965444563601513
Validation loss: 2.821922477421159

Epoch: 102| Step: 0
Training loss: 2.927467094777227
Validation loss: 2.8469101120900033

Epoch: 5| Step: 1
Training loss: 2.4310369638498903
Validation loss: 2.8172244844869825

Epoch: 5| Step: 2
Training loss: 3.2468285859272035
Validation loss: 2.822161642813811

Epoch: 5| Step: 3
Training loss: 2.9550355251390776
Validation loss: 2.8210986682418016

Epoch: 5| Step: 4
Training loss: 3.58975129947603
Validation loss: 2.8189131073449194

Epoch: 5| Step: 5
Training loss: 3.351123843352968
Validation loss: 2.8152823373252702

Epoch: 5| Step: 6
Training loss: 2.7328464268213706
Validation loss: 2.814451286835262

Epoch: 5| Step: 7
Training loss: 2.996173007120689
Validation loss: 2.813381138165882

Epoch: 5| Step: 8
Training loss: 3.474054765101623
Validation loss: 2.817583766721705

Epoch: 5| Step: 9
Training loss: 3.3106621016082856
Validation loss: 2.8305503024264382

Epoch: 5| Step: 10
Training loss: 3.3049020539744816
Validation loss: 2.8427969989841575

Epoch: 103| Step: 0
Training loss: 2.9319184214235587
Validation loss: 2.8200292439640067

Epoch: 5| Step: 1
Training loss: 2.955130728526348
Validation loss: 2.819852551784617

Epoch: 5| Step: 2
Training loss: 3.6397436818853355
Validation loss: 2.8676401609004567

Epoch: 5| Step: 3
Training loss: 3.199639633868335
Validation loss: 2.8845805384968917

Epoch: 5| Step: 4
Training loss: 2.623148492249369
Validation loss: 2.8171180166024428

Epoch: 5| Step: 5
Training loss: 3.5734047218090437
Validation loss: 2.814148429612726

Epoch: 5| Step: 6
Training loss: 3.3848207076356873
Validation loss: 2.81185291462103

Epoch: 5| Step: 7
Training loss: 3.027760965454212
Validation loss: 2.8130577582590024

Epoch: 5| Step: 8
Training loss: 2.5228465424632645
Validation loss: 2.8131772674042

Epoch: 5| Step: 9
Training loss: 3.593823506805988
Validation loss: 2.8274380471608853

Epoch: 5| Step: 10
Training loss: 2.674536377846781
Validation loss: 2.832216151746308

Epoch: 104| Step: 0
Training loss: 2.9405556876337497
Validation loss: 2.8426781290469245

Epoch: 5| Step: 1
Training loss: 3.155356403418285
Validation loss: 2.8387394029682107

Epoch: 5| Step: 2
Training loss: 2.7098505221030798
Validation loss: 2.8180694236496278

Epoch: 5| Step: 3
Training loss: 3.536392653262202
Validation loss: 2.8144640902015796

Epoch: 5| Step: 4
Training loss: 2.5595346366087246
Validation loss: 2.8113059003134544

Epoch: 5| Step: 5
Training loss: 3.1529020172003315
Validation loss: 2.809850903126294

Epoch: 5| Step: 6
Training loss: 3.6988196474913413
Validation loss: 2.806366360096382

Epoch: 5| Step: 7
Training loss: 2.9698818257772532
Validation loss: 2.809644531598247

Epoch: 5| Step: 8
Training loss: 3.29460145198429
Validation loss: 2.8069735768481956

Epoch: 5| Step: 9
Training loss: 2.832284639795717
Validation loss: 2.8100231389331713

Epoch: 5| Step: 10
Training loss: 3.335323661414526
Validation loss: 2.8093267361708567

Epoch: 105| Step: 0
Training loss: 3.257274995002173
Validation loss: 2.806052184060317

Epoch: 5| Step: 1
Training loss: 2.5441420231948118
Validation loss: 2.805373056717391

Epoch: 5| Step: 2
Training loss: 3.001262716944014
Validation loss: 2.8054184994041305

Epoch: 5| Step: 3
Training loss: 3.5642706502950485
Validation loss: 2.8067038658088723

Epoch: 5| Step: 4
Training loss: 3.3988231922390506
Validation loss: 2.803697229170139

Epoch: 5| Step: 5
Training loss: 3.547926692235419
Validation loss: 2.800062943775063

Epoch: 5| Step: 6
Training loss: 2.9538697610501687
Validation loss: 2.8026468247367644

Epoch: 5| Step: 7
Training loss: 2.5825488427298815
Validation loss: 2.805425599757441

Epoch: 5| Step: 8
Training loss: 3.1220105940781386
Validation loss: 2.813241508568534

Epoch: 5| Step: 9
Training loss: 2.9134659962015945
Validation loss: 2.8110072012864538

Epoch: 5| Step: 10
Training loss: 3.2049016723784614
Validation loss: 2.8062285840432115

Epoch: 106| Step: 0
Training loss: 3.3480758493051193
Validation loss: 2.802554851663816

Epoch: 5| Step: 1
Training loss: 3.432393668264949
Validation loss: 2.798927364850257

Epoch: 5| Step: 2
Training loss: 3.132110440934193
Validation loss: 2.8011819429826246

Epoch: 5| Step: 3
Training loss: 2.798077969269805
Validation loss: 2.7996375709279455

Epoch: 5| Step: 4
Training loss: 2.5088760164901305
Validation loss: 2.794809076720816

Epoch: 5| Step: 5
Training loss: 3.1246719188131937
Validation loss: 2.7959346394603153

Epoch: 5| Step: 6
Training loss: 3.68293531404854
Validation loss: 2.802616327764022

Epoch: 5| Step: 7
Training loss: 2.4598791359463896
Validation loss: 2.8006179630850676

Epoch: 5| Step: 8
Training loss: 3.3084569765394853
Validation loss: 2.805087946642585

Epoch: 5| Step: 9
Training loss: 3.2352839128057926
Validation loss: 2.801704474141578

Epoch: 5| Step: 10
Training loss: 2.8697785771250843
Validation loss: 2.799843671934983

Epoch: 107| Step: 0
Training loss: 2.7620852819337953
Validation loss: 2.800189182743381

Epoch: 5| Step: 1
Training loss: 3.2367785088033547
Validation loss: 2.7958387025987856

Epoch: 5| Step: 2
Training loss: 2.864791991986265
Validation loss: 2.796615547304443

Epoch: 5| Step: 3
Training loss: 3.1207406580720303
Validation loss: 2.7970193585165006

Epoch: 5| Step: 4
Training loss: 3.12831092914518
Validation loss: 2.7993509187772

Epoch: 5| Step: 5
Training loss: 3.36059278549694
Validation loss: 2.7976824012722123

Epoch: 5| Step: 6
Training loss: 2.9239408156619127
Validation loss: 2.799519702630301

Epoch: 5| Step: 7
Training loss: 3.377045188341661
Validation loss: 2.7941186562980826

Epoch: 5| Step: 8
Training loss: 2.9403664421544384
Validation loss: 2.7910513575515132

Epoch: 5| Step: 9
Training loss: 3.3908981002305953
Validation loss: 2.7898163994894243

Epoch: 5| Step: 10
Training loss: 2.941727700469317
Validation loss: 2.7882424115125626

Epoch: 108| Step: 0
Training loss: 2.6601463911459198
Validation loss: 2.7918549463300755

Epoch: 5| Step: 1
Training loss: 3.006834510240405
Validation loss: 2.7896030704490204

Epoch: 5| Step: 2
Training loss: 3.1800066063770314
Validation loss: 2.7933255866697073

Epoch: 5| Step: 3
Training loss: 3.543292012971069
Validation loss: 2.8050900980217417

Epoch: 5| Step: 4
Training loss: 3.2298068160637405
Validation loss: 2.798992386449994

Epoch: 5| Step: 5
Training loss: 3.210405514495775
Validation loss: 2.7890120937450074

Epoch: 5| Step: 6
Training loss: 3.3530803524575163
Validation loss: 2.7877373292544996

Epoch: 5| Step: 7
Training loss: 3.8534596937464034
Validation loss: 2.7850365684858085

Epoch: 5| Step: 8
Training loss: 3.167834785912132
Validation loss: 2.785418815175398

Epoch: 5| Step: 9
Training loss: 1.974506017015514
Validation loss: 2.785174711718192

Epoch: 5| Step: 10
Training loss: 2.375967230349275
Validation loss: 2.7825172627862367

Epoch: 109| Step: 0
Training loss: 3.2856195329544824
Validation loss: 2.781622938736024

Epoch: 5| Step: 1
Training loss: 2.9694295005156657
Validation loss: 2.785602840693162

Epoch: 5| Step: 2
Training loss: 3.1987129901565092
Validation loss: 2.7855221515578834

Epoch: 5| Step: 3
Training loss: 2.9111572182703056
Validation loss: 2.784905323444356

Epoch: 5| Step: 4
Training loss: 2.6971197731090113
Validation loss: 2.7844838045694513

Epoch: 5| Step: 5
Training loss: 3.0797656958497686
Validation loss: 2.7836103886379377

Epoch: 5| Step: 6
Training loss: 2.6289654706658605
Validation loss: 2.7815142869250122

Epoch: 5| Step: 7
Training loss: 2.6756616718832844
Validation loss: 2.780896201080598

Epoch: 5| Step: 8
Training loss: 3.5746691143857987
Validation loss: 2.7776954910094993

Epoch: 5| Step: 9
Training loss: 3.665844839647022
Validation loss: 2.780074422448326

Epoch: 5| Step: 10
Training loss: 3.194357433147638
Validation loss: 2.7806216215973065

Epoch: 110| Step: 0
Training loss: 2.823920902992402
Validation loss: 2.795914160039055

Epoch: 5| Step: 1
Training loss: 3.0592743370944184
Validation loss: 2.820202355325703

Epoch: 5| Step: 2
Training loss: 3.060019286350482
Validation loss: 2.8347847392117864

Epoch: 5| Step: 3
Training loss: 3.235020964612052
Validation loss: 2.8002262264338267

Epoch: 5| Step: 4
Training loss: 3.211663602607452
Validation loss: 2.7810175126675056

Epoch: 5| Step: 5
Training loss: 2.7532440471565764
Validation loss: 2.7758906162755355

Epoch: 5| Step: 6
Training loss: 3.129252630103593
Validation loss: 2.7749011829109023

Epoch: 5| Step: 7
Training loss: 3.3826140242006257
Validation loss: 2.7736883049760452

Epoch: 5| Step: 8
Training loss: 3.294310670795232
Validation loss: 2.774434184094968

Epoch: 5| Step: 9
Training loss: 2.907160134496795
Validation loss: 2.773282783626307

Epoch: 5| Step: 10
Training loss: 3.102376758915695
Validation loss: 2.775030220160597

Epoch: 111| Step: 0
Training loss: 3.3798774514187473
Validation loss: 2.7748379730338

Epoch: 5| Step: 1
Training loss: 3.026999570908908
Validation loss: 2.771499469212455

Epoch: 5| Step: 2
Training loss: 3.0103241973367734
Validation loss: 2.7737986441437275

Epoch: 5| Step: 3
Training loss: 3.5666092045038194
Validation loss: 2.7705602293084506

Epoch: 5| Step: 4
Training loss: 2.733534591134964
Validation loss: 2.77109820604704

Epoch: 5| Step: 5
Training loss: 3.3162503874225298
Validation loss: 2.770723815525106

Epoch: 5| Step: 6
Training loss: 3.239055398361878
Validation loss: 2.7701922608090817

Epoch: 5| Step: 7
Training loss: 2.5924507471922067
Validation loss: 2.7773552346247747

Epoch: 5| Step: 8
Training loss: 2.668872417706517
Validation loss: 2.778971689346819

Epoch: 5| Step: 9
Training loss: 3.186430807868729
Validation loss: 2.770312440182296

Epoch: 5| Step: 10
Training loss: 3.074492969424872
Validation loss: 2.7690828375945755

Epoch: 112| Step: 0
Training loss: 2.7862152183692683
Validation loss: 2.7678068441961545

Epoch: 5| Step: 1
Training loss: 3.398685840872364
Validation loss: 2.767366443512806

Epoch: 5| Step: 2
Training loss: 3.1290936931799025
Validation loss: 2.7677576486189914

Epoch: 5| Step: 3
Training loss: 3.084177795104226
Validation loss: 2.768385394637737

Epoch: 5| Step: 4
Training loss: 3.0097570697680163
Validation loss: 2.770026714474078

Epoch: 5| Step: 5
Training loss: 2.9049784842398547
Validation loss: 2.7742193506244774

Epoch: 5| Step: 6
Training loss: 2.7384801947445334
Validation loss: 2.7791626016997553

Epoch: 5| Step: 7
Training loss: 3.2414252798496888
Validation loss: 2.785248457039814

Epoch: 5| Step: 8
Training loss: 3.370052101570147
Validation loss: 2.7771366807693836

Epoch: 5| Step: 9
Training loss: 3.2373306112272746
Validation loss: 2.7679039295601684

Epoch: 5| Step: 10
Training loss: 2.8628798719993513
Validation loss: 2.766214807354157

Epoch: 113| Step: 0
Training loss: 3.077966986148855
Validation loss: 2.761263511316901

Epoch: 5| Step: 1
Training loss: 3.4366875815533664
Validation loss: 2.7661502210329973

Epoch: 5| Step: 2
Training loss: 3.1497787761207894
Validation loss: 2.7648379382769295

Epoch: 5| Step: 3
Training loss: 3.120121313817694
Validation loss: 2.76098392266781

Epoch: 5| Step: 4
Training loss: 2.882814815696055
Validation loss: 2.7780061696272402

Epoch: 5| Step: 5
Training loss: 3.437153191844813
Validation loss: 2.7808730655917624

Epoch: 5| Step: 6
Training loss: 3.2927786160170442
Validation loss: 2.779495799534037

Epoch: 5| Step: 7
Training loss: 2.664156288442562
Validation loss: 2.788295886027183

Epoch: 5| Step: 8
Training loss: 2.0464725244291477
Validation loss: 2.7790025159078326

Epoch: 5| Step: 9
Training loss: 3.268773801290243
Validation loss: 2.7790199760841374

Epoch: 5| Step: 10
Training loss: 3.197123044888976
Validation loss: 2.7737918232841126

Epoch: 114| Step: 0
Training loss: 2.6773637755830264
Validation loss: 2.7658316445416324

Epoch: 5| Step: 1
Training loss: 3.091856560097867
Validation loss: 2.7592807651533646

Epoch: 5| Step: 2
Training loss: 2.968767668018972
Validation loss: 2.7581233808276617

Epoch: 5| Step: 3
Training loss: 3.4217348113585153
Validation loss: 2.7618654491808736

Epoch: 5| Step: 4
Training loss: 2.8948572466874305
Validation loss: 2.7567163302793762

Epoch: 5| Step: 5
Training loss: 3.256485703150969
Validation loss: 2.7590576073696305

Epoch: 5| Step: 6
Training loss: 2.5509198605321135
Validation loss: 2.757593096388392

Epoch: 5| Step: 7
Training loss: 3.4342480623009703
Validation loss: 2.757409856843833

Epoch: 5| Step: 8
Training loss: 3.017030378583857
Validation loss: 2.7564405140168224

Epoch: 5| Step: 9
Training loss: 3.17643297553389
Validation loss: 2.7547965844781754

Epoch: 5| Step: 10
Training loss: 3.11725388841037
Validation loss: 2.755745336904973

Epoch: 115| Step: 0
Training loss: 2.68566361607058
Validation loss: 2.7668995627881054

Epoch: 5| Step: 1
Training loss: 2.698668670913017
Validation loss: 2.765402475615031

Epoch: 5| Step: 2
Training loss: 2.8358394721457323
Validation loss: 2.772867060729693

Epoch: 5| Step: 3
Training loss: 3.4817834633726763
Validation loss: 2.7770542639873272

Epoch: 5| Step: 4
Training loss: 3.418454625063876
Validation loss: 2.769117844972931

Epoch: 5| Step: 5
Training loss: 2.9714044850284957
Validation loss: 2.761518615460042

Epoch: 5| Step: 6
Training loss: 2.8147701002867467
Validation loss: 2.765268538166974

Epoch: 5| Step: 7
Training loss: 3.0705418780113685
Validation loss: 2.7610753585117105

Epoch: 5| Step: 8
Training loss: 2.6262570050893737
Validation loss: 2.762892119782806

Epoch: 5| Step: 9
Training loss: 3.212238131882188
Validation loss: 2.760686348023784

Epoch: 5| Step: 10
Training loss: 3.765015485511333
Validation loss: 2.751427053649575

Epoch: 116| Step: 0
Training loss: 2.987282819315594
Validation loss: 2.7505346358365808

Epoch: 5| Step: 1
Training loss: 3.3497268166820597
Validation loss: 2.7528876351348766

Epoch: 5| Step: 2
Training loss: 2.888342703840578
Validation loss: 2.7504115500559454

Epoch: 5| Step: 3
Training loss: 3.3603749760790684
Validation loss: 2.751393814219026

Epoch: 5| Step: 4
Training loss: 3.6282783679598336
Validation loss: 2.750291499390043

Epoch: 5| Step: 5
Training loss: 3.0936689269877555
Validation loss: 2.7527751716786395

Epoch: 5| Step: 6
Training loss: 2.804525641656184
Validation loss: 2.7491447119916708

Epoch: 5| Step: 7
Training loss: 3.06359687936148
Validation loss: 2.746592561303739

Epoch: 5| Step: 8
Training loss: 2.697130557579463
Validation loss: 2.7455109456680744

Epoch: 5| Step: 9
Training loss: 2.1158631183720877
Validation loss: 2.752824054821571

Epoch: 5| Step: 10
Training loss: 3.5192314130310267
Validation loss: 2.750729958987729

Epoch: 117| Step: 0
Training loss: 3.461609234860724
Validation loss: 2.7578458219560953

Epoch: 5| Step: 1
Training loss: 2.446412640341717
Validation loss: 2.753976300134899

Epoch: 5| Step: 2
Training loss: 2.913461249865488
Validation loss: 2.7626376231578793

Epoch: 5| Step: 3
Training loss: 2.7887194339679247
Validation loss: 2.7897430910384453

Epoch: 5| Step: 4
Training loss: 2.6597423259439026
Validation loss: 2.7886345896060525

Epoch: 5| Step: 5
Training loss: 2.748462854282526
Validation loss: 2.7751632906418635

Epoch: 5| Step: 6
Training loss: 2.975246829524273
Validation loss: 2.760858329472915

Epoch: 5| Step: 7
Training loss: 3.4270579483035113
Validation loss: 2.739665232609815

Epoch: 5| Step: 8
Training loss: 3.289936592859227
Validation loss: 2.7556627092236043

Epoch: 5| Step: 9
Training loss: 3.3370898219735463
Validation loss: 2.782238468334781

Epoch: 5| Step: 10
Training loss: 3.5739844740502096
Validation loss: 2.7837752349231497

Epoch: 118| Step: 0
Training loss: 3.1698761453109374
Validation loss: 2.7826582691690076

Epoch: 5| Step: 1
Training loss: 2.8891429504119452
Validation loss: 2.7670747676381855

Epoch: 5| Step: 2
Training loss: 3.4352609451438285
Validation loss: 2.756031407439292

Epoch: 5| Step: 3
Training loss: 2.5968187860861174
Validation loss: 2.751151936212014

Epoch: 5| Step: 4
Training loss: 3.2883821993517834
Validation loss: 2.749819761766715

Epoch: 5| Step: 5
Training loss: 3.174960284848264
Validation loss: 2.746327629253708

Epoch: 5| Step: 6
Training loss: 3.0545466944250257
Validation loss: 2.745081838558647

Epoch: 5| Step: 7
Training loss: 3.0886555351036424
Validation loss: 2.743845635551009

Epoch: 5| Step: 8
Training loss: 3.316908296252996
Validation loss: 2.7436642623326057

Epoch: 5| Step: 9
Training loss: 2.43518631506269
Validation loss: 2.7434484364441323

Epoch: 5| Step: 10
Training loss: 3.2290686971918205
Validation loss: 2.75439708195718

Epoch: 119| Step: 0
Training loss: 3.051881247503701
Validation loss: 2.761776770430609

Epoch: 5| Step: 1
Training loss: 2.853111536134203
Validation loss: 2.7736464074392884

Epoch: 5| Step: 2
Training loss: 2.3729783538847062
Validation loss: 2.7680830708534274

Epoch: 5| Step: 3
Training loss: 3.2816359520038745
Validation loss: 2.7746562641033927

Epoch: 5| Step: 4
Training loss: 3.0749603889209074
Validation loss: 2.7604015465243155

Epoch: 5| Step: 5
Training loss: 2.797004568838862
Validation loss: 2.7598483351316117

Epoch: 5| Step: 6
Training loss: 3.408875459741
Validation loss: 2.7572903860911655

Epoch: 5| Step: 7
Training loss: 3.314361481082399
Validation loss: 2.744243273688921

Epoch: 5| Step: 8
Training loss: 2.9070479415336443
Validation loss: 2.7375039532574315

Epoch: 5| Step: 9
Training loss: 2.9822776574700613
Validation loss: 2.7329825976383737

Epoch: 5| Step: 10
Training loss: 3.4440917189964413
Validation loss: 2.737189589772604

Epoch: 120| Step: 0
Training loss: 3.046163935707592
Validation loss: 2.737277062688595

Epoch: 5| Step: 1
Training loss: 2.9979988417365524
Validation loss: 2.74075591519175

Epoch: 5| Step: 2
Training loss: 2.9199011352210764
Validation loss: 2.747842621128502

Epoch: 5| Step: 3
Training loss: 3.0223632796723034
Validation loss: 2.75178360267512

Epoch: 5| Step: 4
Training loss: 3.494295921734085
Validation loss: 2.7582068159220374

Epoch: 5| Step: 5
Training loss: 3.3478906965563957
Validation loss: 2.7408425157230476

Epoch: 5| Step: 6
Training loss: 3.3605009809031996
Validation loss: 2.7371350624875057

Epoch: 5| Step: 7
Training loss: 2.9013962771492734
Validation loss: 2.742438513658194

Epoch: 5| Step: 8
Training loss: 2.8979342041655056
Validation loss: 2.753813546496119

Epoch: 5| Step: 9
Training loss: 2.802659515550796
Validation loss: 2.763307596407907

Epoch: 5| Step: 10
Training loss: 2.707646816003225
Validation loss: 2.815368316358136

Epoch: 121| Step: 0
Training loss: 3.3094719055799886
Validation loss: 2.9314189237145367

Epoch: 5| Step: 1
Training loss: 3.504582130457018
Validation loss: 2.8462435537958055

Epoch: 5| Step: 2
Training loss: 2.7243701241841873
Validation loss: 2.7337507988095804

Epoch: 5| Step: 3
Training loss: 2.632336310272382
Validation loss: 2.739419081978051

Epoch: 5| Step: 4
Training loss: 2.9284246952899244
Validation loss: 2.7736867854735285

Epoch: 5| Step: 5
Training loss: 2.9083987260551534
Validation loss: 2.8506269344333317

Epoch: 5| Step: 6
Training loss: 3.0082509699683353
Validation loss: 2.859702110576069

Epoch: 5| Step: 7
Training loss: 2.424206011852712
Validation loss: 2.853908993956802

Epoch: 5| Step: 8
Training loss: 3.4724214386481096
Validation loss: 2.91786297788495

Epoch: 5| Step: 9
Training loss: 3.45647713051129
Validation loss: 2.8157014197962216

Epoch: 5| Step: 10
Training loss: 3.8292678061415795
Validation loss: 2.751284340407852

Epoch: 122| Step: 0
Training loss: 2.710571616159242
Validation loss: 2.737963062835688

Epoch: 5| Step: 1
Training loss: 3.2053154131673507
Validation loss: 2.7456919429342213

Epoch: 5| Step: 2
Training loss: 3.152029860892425
Validation loss: 2.75236149464041

Epoch: 5| Step: 3
Training loss: 3.3606918238075525
Validation loss: 2.7841220639594195

Epoch: 5| Step: 4
Training loss: 3.032234739823917
Validation loss: 2.8273375720349985

Epoch: 5| Step: 5
Training loss: 2.7022049060100795
Validation loss: 2.8801435139777105

Epoch: 5| Step: 6
Training loss: 3.5560465132650325
Validation loss: 2.8528361215055926

Epoch: 5| Step: 7
Training loss: 2.8354409363712554
Validation loss: 2.8015963192950957

Epoch: 5| Step: 8
Training loss: 3.1074982926846615
Validation loss: 2.7304278849543935

Epoch: 5| Step: 9
Training loss: 2.916543921658038
Validation loss: 2.723336109997346

Epoch: 5| Step: 10
Training loss: 3.154318492331111
Validation loss: 2.722224281435264

Epoch: 123| Step: 0
Training loss: 3.3198540584245992
Validation loss: 2.722276485617454

Epoch: 5| Step: 1
Training loss: 2.89397240725362
Validation loss: 2.72389387572378

Epoch: 5| Step: 2
Training loss: 2.5085999390446467
Validation loss: 2.7268379199958357

Epoch: 5| Step: 3
Training loss: 3.1136233956637103
Validation loss: 2.727045857586663

Epoch: 5| Step: 4
Training loss: 2.9607648572689897
Validation loss: 2.742152209586994

Epoch: 5| Step: 5
Training loss: 2.8940193660591644
Validation loss: 2.746115942475743

Epoch: 5| Step: 6
Training loss: 3.204154542289055
Validation loss: 2.7546971944916483

Epoch: 5| Step: 7
Training loss: 2.9073308760047936
Validation loss: 2.717789448808141

Epoch: 5| Step: 8
Training loss: 3.7139725972337128
Validation loss: 2.7172430140751884

Epoch: 5| Step: 9
Training loss: 2.9739780369699913
Validation loss: 2.715608246150242

Epoch: 5| Step: 10
Training loss: 2.9818040249016904
Validation loss: 2.716158971097077

Epoch: 124| Step: 0
Training loss: 3.3288662223853462
Validation loss: 2.7167993793827065

Epoch: 5| Step: 1
Training loss: 3.0794273758203263
Validation loss: 2.726150150077711

Epoch: 5| Step: 2
Training loss: 3.6739943860654347
Validation loss: 2.7352930490254383

Epoch: 5| Step: 3
Training loss: 2.584731543969011
Validation loss: 2.7389076872360523

Epoch: 5| Step: 4
Training loss: 2.7546566637447807
Validation loss: 2.773920255961289

Epoch: 5| Step: 5
Training loss: 2.9890979722864968
Validation loss: 2.810300269872303

Epoch: 5| Step: 6
Training loss: 3.1600504740776314
Validation loss: 2.7683675488284005

Epoch: 5| Step: 7
Training loss: 3.067807017338262
Validation loss: 2.7189491490405118

Epoch: 5| Step: 8
Training loss: 3.1136405479033464
Validation loss: 2.7100427128512328

Epoch: 5| Step: 9
Training loss: 3.1553730265639874
Validation loss: 2.713623883315043

Epoch: 5| Step: 10
Training loss: 2.2176098110185616
Validation loss: 2.7111032672938173

Epoch: 125| Step: 0
Training loss: 2.866676056277252
Validation loss: 2.7106074756772722

Epoch: 5| Step: 1
Training loss: 2.8989331420578814
Validation loss: 2.7134062599187323

Epoch: 5| Step: 2
Training loss: 3.577411163954505
Validation loss: 2.715006056075759

Epoch: 5| Step: 3
Training loss: 2.6480476745163086
Validation loss: 2.7197306308004165

Epoch: 5| Step: 4
Training loss: 3.131474311393124
Validation loss: 2.7264240790495564

Epoch: 5| Step: 5
Training loss: 3.247119801079639
Validation loss: 2.7206875327199804

Epoch: 5| Step: 6
Training loss: 3.144537163959889
Validation loss: 2.7204845309351353

Epoch: 5| Step: 7
Training loss: 2.899609927547772
Validation loss: 2.7140750146321895

Epoch: 5| Step: 8
Training loss: 2.9189792910576697
Validation loss: 2.7096744574021803

Epoch: 5| Step: 9
Training loss: 2.689786160417894
Validation loss: 2.712200337228726

Epoch: 5| Step: 10
Training loss: 3.311602776852948
Validation loss: 2.7128589545917006

Epoch: 126| Step: 0
Training loss: 3.4927120625496575
Validation loss: 2.716236682636817

Epoch: 5| Step: 1
Training loss: 3.3739392061663973
Validation loss: 2.7141318716340117

Epoch: 5| Step: 2
Training loss: 3.200620239468807
Validation loss: 2.716365390315403

Epoch: 5| Step: 3
Training loss: 3.134788289686368
Validation loss: 2.71670463869408

Epoch: 5| Step: 4
Training loss: 1.7025301533183999
Validation loss: 2.7156271287566662

Epoch: 5| Step: 5
Training loss: 2.5857123423857336
Validation loss: 2.7123561210234866

Epoch: 5| Step: 6
Training loss: 2.673621248388407
Validation loss: 2.712016659536486

Epoch: 5| Step: 7
Training loss: 3.1760033111074564
Validation loss: 2.706465753230913

Epoch: 5| Step: 8
Training loss: 3.667217531150336
Validation loss: 2.7073596630302355

Epoch: 5| Step: 9
Training loss: 3.086649134224299
Validation loss: 2.7150608134434546

Epoch: 5| Step: 10
Training loss: 2.7379510655958876
Validation loss: 2.702530973396079

Epoch: 127| Step: 0
Training loss: 3.387640276605053
Validation loss: 2.705353852151034

Epoch: 5| Step: 1
Training loss: 2.966690634155611
Validation loss: 2.7027295949818018

Epoch: 5| Step: 2
Training loss: 3.2239110364921393
Validation loss: 2.7032438061580133

Epoch: 5| Step: 3
Training loss: 2.8242700764699804
Validation loss: 2.7025927839415207

Epoch: 5| Step: 4
Training loss: 3.1638941590538114
Validation loss: 2.7038511938789425

Epoch: 5| Step: 5
Training loss: 2.674551175691735
Validation loss: 2.707603205352856

Epoch: 5| Step: 6
Training loss: 2.755096827499924
Validation loss: 2.7162059526020776

Epoch: 5| Step: 7
Training loss: 3.346794382472548
Validation loss: 2.7246002325312646

Epoch: 5| Step: 8
Training loss: 3.2652094088313093
Validation loss: 2.7201967530732403

Epoch: 5| Step: 9
Training loss: 3.2350395367666467
Validation loss: 2.7327218163517015

Epoch: 5| Step: 10
Training loss: 2.0662694067254237
Validation loss: 2.7272509442575372

Epoch: 128| Step: 0
Training loss: 2.6816077289383426
Validation loss: 2.723600131833036

Epoch: 5| Step: 1
Training loss: 3.1172912121492233
Validation loss: 2.710919727100388

Epoch: 5| Step: 2
Training loss: 2.397910889707799
Validation loss: 2.7020641291085945

Epoch: 5| Step: 3
Training loss: 3.354482521365258
Validation loss: 2.6999537909885905

Epoch: 5| Step: 4
Training loss: 2.954491031919107
Validation loss: 2.7013045082150957

Epoch: 5| Step: 5
Training loss: 2.8040311677645313
Validation loss: 2.6996275443226496

Epoch: 5| Step: 6
Training loss: 3.632131598865472
Validation loss: 2.702980061802374

Epoch: 5| Step: 7
Training loss: 2.7599824575889484
Validation loss: 2.7012166581348245

Epoch: 5| Step: 8
Training loss: 3.4108568588279358
Validation loss: 2.700156728425852

Epoch: 5| Step: 9
Training loss: 2.6714921643561502
Validation loss: 2.7049691110432366

Epoch: 5| Step: 10
Training loss: 3.286346111205312
Validation loss: 2.709449508404572

Epoch: 129| Step: 0
Training loss: 3.317801641392749
Validation loss: 2.7170225423193046

Epoch: 5| Step: 1
Training loss: 2.707131476150096
Validation loss: 2.7163166929215614

Epoch: 5| Step: 2
Training loss: 2.8753690068153
Validation loss: 2.7200419187995233

Epoch: 5| Step: 3
Training loss: 3.1762198019862833
Validation loss: 2.7243366299152174

Epoch: 5| Step: 4
Training loss: 3.4849001912036686
Validation loss: 2.694072842667076

Epoch: 5| Step: 5
Training loss: 3.2665697401290035
Validation loss: 2.69153916918528

Epoch: 5| Step: 6
Training loss: 2.8338736598592296
Validation loss: 2.6913726464966503

Epoch: 5| Step: 7
Training loss: 3.06202117913594
Validation loss: 2.687422068010398

Epoch: 5| Step: 8
Training loss: 2.573502714515501
Validation loss: 2.6880570063639047

Epoch: 5| Step: 9
Training loss: 2.784265148252135
Validation loss: 2.6884604099920026

Epoch: 5| Step: 10
Training loss: 3.0628116993999885
Validation loss: 2.690226907307188

Epoch: 130| Step: 0
Training loss: 2.796846101920585
Validation loss: 2.695399760693982

Epoch: 5| Step: 1
Training loss: 2.6906237523588863
Validation loss: 2.700181376762027

Epoch: 5| Step: 2
Training loss: 3.01308353834699
Validation loss: 2.704680501286962

Epoch: 5| Step: 3
Training loss: 3.517655392422468
Validation loss: 2.7146862202401145

Epoch: 5| Step: 4
Training loss: 3.2327635063046776
Validation loss: 2.7065971154362005

Epoch: 5| Step: 5
Training loss: 3.084540019312005
Validation loss: 2.7071368598127106

Epoch: 5| Step: 6
Training loss: 2.8970917819162514
Validation loss: 2.705751207786916

Epoch: 5| Step: 7
Training loss: 3.2073800458353623
Validation loss: 2.6923300858127166

Epoch: 5| Step: 8
Training loss: 2.519767620029227
Validation loss: 2.688311515133005

Epoch: 5| Step: 9
Training loss: 2.7048969084155963
Validation loss: 2.6885623992604804

Epoch: 5| Step: 10
Training loss: 3.4727507193280878
Validation loss: 2.6869428600399337

Epoch: 131| Step: 0
Training loss: 2.589523088445446
Validation loss: 2.6857631553152563

Epoch: 5| Step: 1
Training loss: 2.1700351524142696
Validation loss: 2.69076301173397

Epoch: 5| Step: 2
Training loss: 3.0745410483649516
Validation loss: 2.693224775141819

Epoch: 5| Step: 3
Training loss: 3.0304204061201787
Validation loss: 2.692043109373398

Epoch: 5| Step: 4
Training loss: 3.4350606412684908
Validation loss: 2.692500342620052

Epoch: 5| Step: 5
Training loss: 3.31610458314017
Validation loss: 2.692450329032232

Epoch: 5| Step: 6
Training loss: 2.8624772716436144
Validation loss: 2.6936758290746607

Epoch: 5| Step: 7
Training loss: 2.9676368634254464
Validation loss: 2.6891585972408487

Epoch: 5| Step: 8
Training loss: 3.2153514215555226
Validation loss: 2.691306891843486

Epoch: 5| Step: 9
Training loss: 3.2729631685724834
Validation loss: 2.6932271005962063

Epoch: 5| Step: 10
Training loss: 2.939318317351037
Validation loss: 2.6943403067503557

Epoch: 132| Step: 0
Training loss: 3.265841390202824
Validation loss: 2.704259202609699

Epoch: 5| Step: 1
Training loss: 2.594534054564833
Validation loss: 2.693134367381566

Epoch: 5| Step: 2
Training loss: 3.2441151966474084
Validation loss: 2.6985751974934424

Epoch: 5| Step: 3
Training loss: 3.246332593593506
Validation loss: 2.6974114680542147

Epoch: 5| Step: 4
Training loss: 3.360883932781873
Validation loss: 2.7092637829438724

Epoch: 5| Step: 5
Training loss: 2.6515516129170735
Validation loss: 2.7169458374054667

Epoch: 5| Step: 6
Training loss: 2.9762219011373414
Validation loss: 2.7063240100829584

Epoch: 5| Step: 7
Training loss: 2.486266753464874
Validation loss: 2.715236353260329

Epoch: 5| Step: 8
Training loss: 2.978996343123185
Validation loss: 2.7062820500878333

Epoch: 5| Step: 9
Training loss: 2.5926792738315254
Validation loss: 2.700699460046086

Epoch: 5| Step: 10
Training loss: 3.5769783414889385
Validation loss: 2.6883134252428786

Epoch: 133| Step: 0
Training loss: 3.1329663778741925
Validation loss: 2.678990272202898

Epoch: 5| Step: 1
Training loss: 3.1932894917812122
Validation loss: 2.6776713759710034

Epoch: 5| Step: 2
Training loss: 3.091142731011282
Validation loss: 2.674326271821207

Epoch: 5| Step: 3
Training loss: 2.7883463990094812
Validation loss: 2.6814109951831684

Epoch: 5| Step: 4
Training loss: 3.16580988352553
Validation loss: 2.682023336861729

Epoch: 5| Step: 5
Training loss: 2.8846958696923526
Validation loss: 2.6833846550554914

Epoch: 5| Step: 6
Training loss: 3.1937849128740883
Validation loss: 2.6839646181978565

Epoch: 5| Step: 7
Training loss: 2.9534411387289445
Validation loss: 2.676731889199518

Epoch: 5| Step: 8
Training loss: 2.637537759808895
Validation loss: 2.680507249790256

Epoch: 5| Step: 9
Training loss: 3.0807010308617637
Validation loss: 2.6773471031195615

Epoch: 5| Step: 10
Training loss: 3.009364136609903
Validation loss: 2.6789244997552135

Epoch: 134| Step: 0
Training loss: 2.6557214547675176
Validation loss: 2.6724796854659485

Epoch: 5| Step: 1
Training loss: 3.1351597238155904
Validation loss: 2.6731613450659246

Epoch: 5| Step: 2
Training loss: 3.1164669265252885
Validation loss: 2.671429923071229

Epoch: 5| Step: 3
Training loss: 3.087206306852021
Validation loss: 2.6714302061682855

Epoch: 5| Step: 4
Training loss: 2.9464012177754064
Validation loss: 2.6693837631111363

Epoch: 5| Step: 5
Training loss: 2.4300758566613547
Validation loss: 2.677941925644966

Epoch: 5| Step: 6
Training loss: 2.6734881076894257
Validation loss: 2.690964149112789

Epoch: 5| Step: 7
Training loss: 3.4318561345160052
Validation loss: 2.715587581997578

Epoch: 5| Step: 8
Training loss: 3.498555566551158
Validation loss: 2.742635632289952

Epoch: 5| Step: 9
Training loss: 3.1069261885642736
Validation loss: 2.7640719133037073

Epoch: 5| Step: 10
Training loss: 2.937292051056667
Validation loss: 2.743801258542804

Epoch: 135| Step: 0
Training loss: 3.1302452317960077
Validation loss: 2.695299564358471

Epoch: 5| Step: 1
Training loss: 3.26693684634892
Validation loss: 2.678001391632398

Epoch: 5| Step: 2
Training loss: 3.1368880932844956
Validation loss: 2.6700286242573097

Epoch: 5| Step: 3
Training loss: 2.9492100191302884
Validation loss: 2.6741904024066825

Epoch: 5| Step: 4
Training loss: 2.418086873313713
Validation loss: 2.6765610057763256

Epoch: 5| Step: 5
Training loss: 2.99404905095816
Validation loss: 2.682867488029635

Epoch: 5| Step: 6
Training loss: 3.2613547116273187
Validation loss: 2.689677016584469

Epoch: 5| Step: 7
Training loss: 3.033039312121106
Validation loss: 2.6890606918977644

Epoch: 5| Step: 8
Training loss: 3.278158711713722
Validation loss: 2.678323690049409

Epoch: 5| Step: 9
Training loss: 2.8817035640768776
Validation loss: 2.6723719462569853

Epoch: 5| Step: 10
Training loss: 2.618915408789676
Validation loss: 2.6710594154380303

Epoch: 136| Step: 0
Training loss: 2.6483182176943223
Validation loss: 2.666776705466044

Epoch: 5| Step: 1
Training loss: 2.6128946654165484
Validation loss: 2.6725711775481753

Epoch: 5| Step: 2
Training loss: 2.8401432850112567
Validation loss: 2.678222770637446

Epoch: 5| Step: 3
Training loss: 2.3916242916947703
Validation loss: 2.680938991954261

Epoch: 5| Step: 4
Training loss: 2.8907942438841325
Validation loss: 2.6902593158482593

Epoch: 5| Step: 5
Training loss: 3.288147860318687
Validation loss: 2.6857416649481434

Epoch: 5| Step: 6
Training loss: 3.0508628375174007
Validation loss: 2.6833736557919035

Epoch: 5| Step: 7
Training loss: 2.947339723741319
Validation loss: 2.6792118584711737

Epoch: 5| Step: 8
Training loss: 3.1301346366614853
Validation loss: 2.679888794225911

Epoch: 5| Step: 9
Training loss: 3.2915815189470887
Validation loss: 2.682382146780951

Epoch: 5| Step: 10
Training loss: 3.732733074251798
Validation loss: 2.6763747940586207

Epoch: 137| Step: 0
Training loss: 3.2191370759085065
Validation loss: 2.6749167804962277

Epoch: 5| Step: 1
Training loss: 3.04108665545056
Validation loss: 2.668158755623716

Epoch: 5| Step: 2
Training loss: 2.775844850893232
Validation loss: 2.669670431788594

Epoch: 5| Step: 3
Training loss: 2.873532127826038
Validation loss: 2.6673512048054815

Epoch: 5| Step: 4
Training loss: 3.2847570659858465
Validation loss: 2.670297889916958

Epoch: 5| Step: 5
Training loss: 2.846606653758672
Validation loss: 2.6678381600697882

Epoch: 5| Step: 6
Training loss: 2.7875512567434826
Validation loss: 2.6887222033057196

Epoch: 5| Step: 7
Training loss: 3.3104716874758346
Validation loss: 2.6850021756758533

Epoch: 5| Step: 8
Training loss: 2.8747059215573705
Validation loss: 2.683447303089186

Epoch: 5| Step: 9
Training loss: 2.9356245181639813
Validation loss: 2.6764984503829936

Epoch: 5| Step: 10
Training loss: 2.9137283419962383
Validation loss: 2.6695330145548417

Epoch: 138| Step: 0
Training loss: 3.244389753519404
Validation loss: 2.6688383114654624

Epoch: 5| Step: 1
Training loss: 3.28617518314066
Validation loss: 2.6625323998298107

Epoch: 5| Step: 2
Training loss: 3.20862208136308
Validation loss: 2.6611576652589357

Epoch: 5| Step: 3
Training loss: 3.100457674512405
Validation loss: 2.6606778343979833

Epoch: 5| Step: 4
Training loss: 2.738640645994035
Validation loss: 2.66110645857277

Epoch: 5| Step: 5
Training loss: 2.820893626693303
Validation loss: 2.6616391471969765

Epoch: 5| Step: 6
Training loss: 2.9393196151677454
Validation loss: 2.6590989818814266

Epoch: 5| Step: 7
Training loss: 2.742608279904725
Validation loss: 2.66125341046745

Epoch: 5| Step: 8
Training loss: 2.9273454180005922
Validation loss: 2.6645536536835244

Epoch: 5| Step: 9
Training loss: 2.7091202595245574
Validation loss: 2.667653676642182

Epoch: 5| Step: 10
Training loss: 3.1230178650349005
Validation loss: 2.6784064274999317

Epoch: 139| Step: 0
Training loss: 2.596147922498243
Validation loss: 2.675338310129664

Epoch: 5| Step: 1
Training loss: 3.3380143358621
Validation loss: 2.6934865755688198

Epoch: 5| Step: 2
Training loss: 2.753999575934173
Validation loss: 2.698224294873184

Epoch: 5| Step: 3
Training loss: 3.1153214684631947
Validation loss: 2.682942195530506

Epoch: 5| Step: 4
Training loss: 3.138238104214318
Validation loss: 2.6675951495580934

Epoch: 5| Step: 5
Training loss: 2.3693527541830663
Validation loss: 2.6766953450315274

Epoch: 5| Step: 6
Training loss: 2.797988243825454
Validation loss: 2.6668501622251086

Epoch: 5| Step: 7
Training loss: 3.269611024965758
Validation loss: 2.6624653166674945

Epoch: 5| Step: 8
Training loss: 3.1258836641245344
Validation loss: 2.6590365854809637

Epoch: 5| Step: 9
Training loss: 2.952591782321462
Validation loss: 2.658104672625414

Epoch: 5| Step: 10
Training loss: 3.188414947241569
Validation loss: 2.661482885733225

Epoch: 140| Step: 0
Training loss: 3.3693022492935722
Validation loss: 2.657033706472236

Epoch: 5| Step: 1
Training loss: 3.0351889275911432
Validation loss: 2.656139107500036

Epoch: 5| Step: 2
Training loss: 3.2667606697051323
Validation loss: 2.652452382949642

Epoch: 5| Step: 3
Training loss: 3.1723516697999172
Validation loss: 2.6546901458713723

Epoch: 5| Step: 4
Training loss: 2.470462060559436
Validation loss: 2.6562103770399474

Epoch: 5| Step: 5
Training loss: 3.0682136020234316
Validation loss: 2.6594586897565535

Epoch: 5| Step: 6
Training loss: 2.6791673160945724
Validation loss: 2.6748207681631935

Epoch: 5| Step: 7
Training loss: 2.9721911914984207
Validation loss: 2.6815224133542555

Epoch: 5| Step: 8
Training loss: 3.1471980757730225
Validation loss: 2.710989422224239

Epoch: 5| Step: 9
Training loss: 2.9906507086371317
Validation loss: 2.677145743230129

Epoch: 5| Step: 10
Training loss: 2.3876632594666045
Validation loss: 2.6707701860849427

Epoch: 141| Step: 0
Training loss: 3.042508953648654
Validation loss: 2.6547305486207793

Epoch: 5| Step: 1
Training loss: 2.856569007738423
Validation loss: 2.6496073860561715

Epoch: 5| Step: 2
Training loss: 3.3792469007293424
Validation loss: 2.6484473095145105

Epoch: 5| Step: 3
Training loss: 3.329353356567636
Validation loss: 2.650439238525813

Epoch: 5| Step: 4
Training loss: 3.332491164313792
Validation loss: 2.6477012296912563

Epoch: 5| Step: 5
Training loss: 2.518764361395016
Validation loss: 2.64839529273124

Epoch: 5| Step: 6
Training loss: 2.7130823802258734
Validation loss: 2.646653588307795

Epoch: 5| Step: 7
Training loss: 3.145341207313573
Validation loss: 2.6456409504228273

Epoch: 5| Step: 8
Training loss: 2.7367820390488267
Validation loss: 2.648239360162146

Epoch: 5| Step: 9
Training loss: 2.2542138377370318
Validation loss: 2.657166099976739

Epoch: 5| Step: 10
Training loss: 3.294378555808322
Validation loss: 2.6719661481933454

Epoch: 142| Step: 0
Training loss: 3.2120237717372326
Validation loss: 2.6772783266739633

Epoch: 5| Step: 1
Training loss: 2.9489762162277526
Validation loss: 2.7035315669789215

Epoch: 5| Step: 2
Training loss: 3.176970499671996
Validation loss: 2.7283767459436974

Epoch: 5| Step: 3
Training loss: 3.4811215115023257
Validation loss: 2.7285591175049104

Epoch: 5| Step: 4
Training loss: 2.8624574483182483
Validation loss: 2.7313652704520193

Epoch: 5| Step: 5
Training loss: 3.203225929717029
Validation loss: 2.717966999723938

Epoch: 5| Step: 6
Training loss: 3.126030561272126
Validation loss: 2.6992362627771063

Epoch: 5| Step: 7
Training loss: 2.6179288355084953
Validation loss: 2.6768753592152668

Epoch: 5| Step: 8
Training loss: 2.542603169076277
Validation loss: 2.6708792117945137

Epoch: 5| Step: 9
Training loss: 2.748992735452444
Validation loss: 2.6697924003795155

Epoch: 5| Step: 10
Training loss: 2.9529489939076354
Validation loss: 2.666033290495145

Epoch: 143| Step: 0
Training loss: 2.5729450322079224
Validation loss: 2.66984572963897

Epoch: 5| Step: 1
Training loss: 3.376147887385136
Validation loss: 2.673280973649229

Epoch: 5| Step: 2
Training loss: 3.06933826782643
Validation loss: 2.67854278365531

Epoch: 5| Step: 3
Training loss: 2.9653583627829136
Validation loss: 2.676443652151312

Epoch: 5| Step: 4
Training loss: 2.6274880017152724
Validation loss: 2.682357128446425

Epoch: 5| Step: 5
Training loss: 2.9204440769457274
Validation loss: 2.6780146903586015

Epoch: 5| Step: 6
Training loss: 2.8064426041671724
Validation loss: 2.6853246267167417

Epoch: 5| Step: 7
Training loss: 3.2062737596014457
Validation loss: 2.6923419759260785

Epoch: 5| Step: 8
Training loss: 3.214744519988546
Validation loss: 2.685097929926477

Epoch: 5| Step: 9
Training loss: 3.340708552601207
Validation loss: 2.68647232973537

Epoch: 5| Step: 10
Training loss: 2.829508406197046
Validation loss: 2.6789137721408043

Epoch: 144| Step: 0
Training loss: 3.1956989828730338
Validation loss: 2.688798434792267

Epoch: 5| Step: 1
Training loss: 2.9686719382212354
Validation loss: 2.6696755548964894

Epoch: 5| Step: 2
Training loss: 3.348209865022193
Validation loss: 2.6668989678946406

Epoch: 5| Step: 3
Training loss: 2.280664969899248
Validation loss: 2.657212766101614

Epoch: 5| Step: 4
Training loss: 2.340894460001085
Validation loss: 2.651776182270435

Epoch: 5| Step: 5
Training loss: 3.015078480270041
Validation loss: 2.6582515811863905

Epoch: 5| Step: 6
Training loss: 3.4183191784646696
Validation loss: 2.6506586465187274

Epoch: 5| Step: 7
Training loss: 3.4958839737168668
Validation loss: 2.675824978809962

Epoch: 5| Step: 8
Training loss: 2.7373521564571655
Validation loss: 2.6719583439465002

Epoch: 5| Step: 9
Training loss: 2.973829240997919
Validation loss: 2.6586842182458166

Epoch: 5| Step: 10
Training loss: 2.694425663658662
Validation loss: 2.6585115440960885

Epoch: 145| Step: 0
Training loss: 2.361281881202996
Validation loss: 2.683114340799959

Epoch: 5| Step: 1
Training loss: 2.548489111793434
Validation loss: 2.700974873917905

Epoch: 5| Step: 2
Training loss: 3.142650501468059
Validation loss: 2.7311993775285455

Epoch: 5| Step: 3
Training loss: 2.607786597414096
Validation loss: 2.753506594094403

Epoch: 5| Step: 4
Training loss: 3.552249281839205
Validation loss: 2.7689976017162983

Epoch: 5| Step: 5
Training loss: 2.582542841981555
Validation loss: 2.687837123116178

Epoch: 5| Step: 6
Training loss: 3.3321853727269333
Validation loss: 2.6656488570692796

Epoch: 5| Step: 7
Training loss: 2.782144809752296
Validation loss: 2.6440271774567474

Epoch: 5| Step: 8
Training loss: 2.9100189381405945
Validation loss: 2.6421970717550725

Epoch: 5| Step: 9
Training loss: 2.8270698391492286
Validation loss: 2.65654416274134

Epoch: 5| Step: 10
Training loss: 3.994597601456071
Validation loss: 2.648962357693223

Epoch: 146| Step: 0
Training loss: 2.1915932641833917
Validation loss: 2.638681161199739

Epoch: 5| Step: 1
Training loss: 3.5608882269603446
Validation loss: 2.6419699599748494

Epoch: 5| Step: 2
Training loss: 3.0486983101166962
Validation loss: 2.643951596295745

Epoch: 5| Step: 3
Training loss: 2.30646903799244
Validation loss: 2.64367107870021

Epoch: 5| Step: 4
Training loss: 3.192019680278025
Validation loss: 2.6417844639000334

Epoch: 5| Step: 5
Training loss: 2.4332180069893763
Validation loss: 2.6408285955803628

Epoch: 5| Step: 6
Training loss: 3.231917917663391
Validation loss: 2.6522002897741

Epoch: 5| Step: 7
Training loss: 2.6756106134289426
Validation loss: 2.65080360410498

Epoch: 5| Step: 8
Training loss: 3.0140150447133305
Validation loss: 2.6688628628927016

Epoch: 5| Step: 9
Training loss: 3.5690842400140816
Validation loss: 2.6587213860299914

Epoch: 5| Step: 10
Training loss: 3.3185509171194223
Validation loss: 2.6607549098319323

Epoch: 147| Step: 0
Training loss: 2.8795092506319713
Validation loss: 2.6324154133936335

Epoch: 5| Step: 1
Training loss: 2.7784636180638205
Validation loss: 2.625472788465497

Epoch: 5| Step: 2
Training loss: 2.6029139035876208
Validation loss: 2.62226000115907

Epoch: 5| Step: 3
Training loss: 3.1503658021728205
Validation loss: 2.628491271021351

Epoch: 5| Step: 4
Training loss: 3.335620445175449
Validation loss: 2.6327548118851913

Epoch: 5| Step: 5
Training loss: 3.1740162203878475
Validation loss: 2.6366795997037458

Epoch: 5| Step: 6
Training loss: 2.8179977935825695
Validation loss: 2.6396603755289383

Epoch: 5| Step: 7
Training loss: 3.3201390120117007
Validation loss: 2.6276737889594703

Epoch: 5| Step: 8
Training loss: 2.951828444915607
Validation loss: 2.629224369519717

Epoch: 5| Step: 9
Training loss: 2.748596700337457
Validation loss: 2.626856003699049

Epoch: 5| Step: 10
Training loss: 2.746046866264965
Validation loss: 2.629114183948306

Epoch: 148| Step: 0
Training loss: 2.792259627799773
Validation loss: 2.6246078518629345

Epoch: 5| Step: 1
Training loss: 3.5485209540460247
Validation loss: 2.626204974399748

Epoch: 5| Step: 2
Training loss: 3.0237153785619038
Validation loss: 2.6232733724576835

Epoch: 5| Step: 3
Training loss: 2.5763673281617163
Validation loss: 2.6277034138350572

Epoch: 5| Step: 4
Training loss: 2.765732068074471
Validation loss: 2.6273677195168235

Epoch: 5| Step: 5
Training loss: 2.831567850018398
Validation loss: 2.635125815659225

Epoch: 5| Step: 6
Training loss: 2.9118933901397472
Validation loss: 2.631930088270263

Epoch: 5| Step: 7
Training loss: 3.2319052291987864
Validation loss: 2.6312991425615446

Epoch: 5| Step: 8
Training loss: 2.918803186360884
Validation loss: 2.6347281465194174

Epoch: 5| Step: 9
Training loss: 2.8140116549849026
Validation loss: 2.6335461380865604

Epoch: 5| Step: 10
Training loss: 3.064590830289141
Validation loss: 2.638238413665628

Epoch: 149| Step: 0
Training loss: 3.201712692409156
Validation loss: 2.630560937665682

Epoch: 5| Step: 1
Training loss: 2.6027706422530428
Validation loss: 2.6276087433074817

Epoch: 5| Step: 2
Training loss: 2.9797736841069145
Validation loss: 2.62205505030562

Epoch: 5| Step: 3
Training loss: 3.0628148131200774
Validation loss: 2.6241526263897432

Epoch: 5| Step: 4
Training loss: 2.828263674544904
Validation loss: 2.6206286627673334

Epoch: 5| Step: 5
Training loss: 3.029484657552211
Validation loss: 2.6194826311319113

Epoch: 5| Step: 6
Training loss: 2.7853738451005485
Validation loss: 2.6219561039605264

Epoch: 5| Step: 7
Training loss: 2.8634456155394075
Validation loss: 2.620337635589201

Epoch: 5| Step: 8
Training loss: 3.0111164128943857
Validation loss: 2.6189837493840873

Epoch: 5| Step: 9
Training loss: 3.075204771093345
Validation loss: 2.6273067425593544

Epoch: 5| Step: 10
Training loss: 2.9962119983082225
Validation loss: 2.6334714943886026

Epoch: 150| Step: 0
Training loss: 2.7743226264191816
Validation loss: 2.642814543497101

Epoch: 5| Step: 1
Training loss: 3.134632523702704
Validation loss: 2.659145057808871

Epoch: 5| Step: 2
Training loss: 2.5564543887179876
Validation loss: 2.662542438568449

Epoch: 5| Step: 3
Training loss: 3.3046606617372074
Validation loss: 2.653002375653472

Epoch: 5| Step: 4
Training loss: 3.142447934201144
Validation loss: 2.6743527878498665

Epoch: 5| Step: 5
Training loss: 3.563078314705024
Validation loss: 2.6334811698217804

Epoch: 5| Step: 6
Training loss: 2.813938535917823
Validation loss: 2.620321404501539

Epoch: 5| Step: 7
Training loss: 2.6679303234902023
Validation loss: 2.615539718717444

Epoch: 5| Step: 8
Training loss: 2.773950921475035
Validation loss: 2.620216237531761

Epoch: 5| Step: 9
Training loss: 2.9994204279230985
Validation loss: 2.616262997424761

Epoch: 5| Step: 10
Training loss: 2.6515907263616216
Validation loss: 2.6204154504688097

Epoch: 151| Step: 0
Training loss: 3.594031944824971
Validation loss: 2.6200758586344985

Epoch: 5| Step: 1
Training loss: 3.2154273503453816
Validation loss: 2.6166240538050913

Epoch: 5| Step: 2
Training loss: 2.699773132541622
Validation loss: 2.6256054523285175

Epoch: 5| Step: 3
Training loss: 2.7782965419402723
Validation loss: 2.6308098218073837

Epoch: 5| Step: 4
Training loss: 3.0317976938558626
Validation loss: 2.6444207250149994

Epoch: 5| Step: 5
Training loss: 3.240258215045662
Validation loss: 2.6637379621207544

Epoch: 5| Step: 6
Training loss: 2.95600774631337
Validation loss: 2.653359982482498

Epoch: 5| Step: 7
Training loss: 2.7364307632093268
Validation loss: 2.631118276520639

Epoch: 5| Step: 8
Training loss: 2.6508516094877286
Validation loss: 2.615904369683826

Epoch: 5| Step: 9
Training loss: 2.473550306435921
Validation loss: 2.6145087663206334

Epoch: 5| Step: 10
Training loss: 3.006857822062288
Validation loss: 2.6178033752125294

Epoch: 152| Step: 0
Training loss: 3.0028887192327347
Validation loss: 2.6128544880114335

Epoch: 5| Step: 1
Training loss: 3.219719601855912
Validation loss: 2.6116816809589825

Epoch: 5| Step: 2
Training loss: 3.0094636422765717
Validation loss: 2.6120280331362657

Epoch: 5| Step: 3
Training loss: 2.7301806733147993
Validation loss: 2.6126480526115423

Epoch: 5| Step: 4
Training loss: 3.551344152301483
Validation loss: 2.6096203964761924

Epoch: 5| Step: 5
Training loss: 3.035375874353685
Validation loss: 2.6139546483256777

Epoch: 5| Step: 6
Training loss: 2.7700087293081075
Validation loss: 2.6105982753857577

Epoch: 5| Step: 7
Training loss: 2.355201313785
Validation loss: 2.609829187241001

Epoch: 5| Step: 8
Training loss: 3.0841246096500576
Validation loss: 2.6085251186828065

Epoch: 5| Step: 9
Training loss: 3.135846198348973
Validation loss: 2.607480706612789

Epoch: 5| Step: 10
Training loss: 2.2825533135529223
Validation loss: 2.6102205227662068

Epoch: 153| Step: 0
Training loss: 2.9999381694779843
Validation loss: 2.6190640320095144

Epoch: 5| Step: 1
Training loss: 3.171199783089993
Validation loss: 2.6308536257393516

Epoch: 5| Step: 2
Training loss: 2.9029078801723283
Validation loss: 2.63416485521032

Epoch: 5| Step: 3
Training loss: 3.183843422677144
Validation loss: 2.640151354494468

Epoch: 5| Step: 4
Training loss: 2.934403430935051
Validation loss: 2.6276512254389215

Epoch: 5| Step: 5
Training loss: 3.334351781390648
Validation loss: 2.6286335201963276

Epoch: 5| Step: 6
Training loss: 2.528761594239459
Validation loss: 2.6310567170886907

Epoch: 5| Step: 7
Training loss: 2.9371428576941754
Validation loss: 2.6465774912678977

Epoch: 5| Step: 8
Training loss: 2.833636735117338
Validation loss: 2.6387679318604884

Epoch: 5| Step: 9
Training loss: 2.8937888486820933
Validation loss: 2.628315817347056

Epoch: 5| Step: 10
Training loss: 2.4985656438223227
Validation loss: 2.612858330249642

Epoch: 154| Step: 0
Training loss: 3.1205083992809426
Validation loss: 2.6131916287982118

Epoch: 5| Step: 1
Training loss: 3.2462274223191745
Validation loss: 2.6118757812904634

Epoch: 5| Step: 2
Training loss: 2.281909794956167
Validation loss: 2.610892459991999

Epoch: 5| Step: 3
Training loss: 2.835999207048615
Validation loss: 2.610142049381776

Epoch: 5| Step: 4
Training loss: 3.264570294037473
Validation loss: 2.605659679699512

Epoch: 5| Step: 5
Training loss: 3.047747051936944
Validation loss: 2.6090176382882815

Epoch: 5| Step: 6
Training loss: 2.8352843654316806
Validation loss: 2.6053188237975524

Epoch: 5| Step: 7
Training loss: 2.654227170948259
Validation loss: 2.608259241893773

Epoch: 5| Step: 8
Training loss: 2.824760754337327
Validation loss: 2.610097347825497

Epoch: 5| Step: 9
Training loss: 3.3396664221016277
Validation loss: 2.610881362511546

Epoch: 5| Step: 10
Training loss: 2.5952437362426273
Validation loss: 2.6226007109602443

Epoch: 155| Step: 0
Training loss: 2.9382247030856496
Validation loss: 2.6306543817341765

Epoch: 5| Step: 1
Training loss: 3.015742482481236
Validation loss: 2.6545688344616623

Epoch: 5| Step: 2
Training loss: 3.449530063633612
Validation loss: 2.650811461929399

Epoch: 5| Step: 3
Training loss: 2.947342959451764
Validation loss: 2.644851887854777

Epoch: 5| Step: 4
Training loss: 3.0159875523338155
Validation loss: 2.6391642724908033

Epoch: 5| Step: 5
Training loss: 2.5923352347153577
Validation loss: 2.630208779092022

Epoch: 5| Step: 6
Training loss: 2.955142184998402
Validation loss: 2.633008227432687

Epoch: 5| Step: 7
Training loss: 2.6815761661214648
Validation loss: 2.6326749847333217

Epoch: 5| Step: 8
Training loss: 2.908536442292759
Validation loss: 2.628193318797349

Epoch: 5| Step: 9
Training loss: 2.949901294673337
Validation loss: 2.6278662641973574

Epoch: 5| Step: 10
Training loss: 2.692781891300785
Validation loss: 2.620436365202305

Epoch: 156| Step: 0
Training loss: 2.6600917186556097
Validation loss: 2.614092765418958

Epoch: 5| Step: 1
Training loss: 2.848000839168982
Validation loss: 2.6125244131633942

Epoch: 5| Step: 2
Training loss: 3.208223778641816
Validation loss: 2.6141724367588743

Epoch: 5| Step: 3
Training loss: 3.2463187863858654
Validation loss: 2.623525405538042

Epoch: 5| Step: 4
Training loss: 2.6276207511587675
Validation loss: 2.623880463555137

Epoch: 5| Step: 5
Training loss: 3.507981328151167
Validation loss: 2.631108270860317

Epoch: 5| Step: 6
Training loss: 2.7028265110216823
Validation loss: 2.6379246319994607

Epoch: 5| Step: 7
Training loss: 3.049715253952078
Validation loss: 2.6398998589321296

Epoch: 5| Step: 8
Training loss: 2.522732473800759
Validation loss: 2.631747843374718

Epoch: 5| Step: 9
Training loss: 2.729940164070993
Validation loss: 2.632372874238461

Epoch: 5| Step: 10
Training loss: 3.048601962003156
Validation loss: 2.6232934796659064

Epoch: 157| Step: 0
Training loss: 2.752878676446288
Validation loss: 2.625823087705825

Epoch: 5| Step: 1
Training loss: 3.100606083842029
Validation loss: 2.6316624602908476

Epoch: 5| Step: 2
Training loss: 2.7754693983202126
Validation loss: 2.6271949825987475

Epoch: 5| Step: 3
Training loss: 3.575210517073651
Validation loss: 2.620032383318548

Epoch: 5| Step: 4
Training loss: 2.9940810623764103
Validation loss: 2.6250321463917956

Epoch: 5| Step: 5
Training loss: 2.8204190981683457
Validation loss: 2.6221531022458078

Epoch: 5| Step: 6
Training loss: 2.7874609358577755
Validation loss: 2.6156546719928135

Epoch: 5| Step: 7
Training loss: 2.8276290880277153
Validation loss: 2.6059301640884702

Epoch: 5| Step: 8
Training loss: 2.883909931485365
Validation loss: 2.604577547863553

Epoch: 5| Step: 9
Training loss: 3.0914004873627423
Validation loss: 2.619829279887416

Epoch: 5| Step: 10
Training loss: 2.390626894881551
Validation loss: 2.6167228725874327

Epoch: 158| Step: 0
Training loss: 3.1504113609922815
Validation loss: 2.6238793365372914

Epoch: 5| Step: 1
Training loss: 3.1218884044890216
Validation loss: 2.624759682604299

Epoch: 5| Step: 2
Training loss: 2.591840477744098
Validation loss: 2.618776890643582

Epoch: 5| Step: 3
Training loss: 2.607057101561921
Validation loss: 2.6170001307420407

Epoch: 5| Step: 4
Training loss: 3.01539682108117
Validation loss: 2.614565763736006

Epoch: 5| Step: 5
Training loss: 3.393165445302775
Validation loss: 2.6090169681497923

Epoch: 5| Step: 6
Training loss: 2.942720198255717
Validation loss: 2.614595909727375

Epoch: 5| Step: 7
Training loss: 3.170330705209712
Validation loss: 2.616156192522125

Epoch: 5| Step: 8
Training loss: 2.7108059282282784
Validation loss: 2.6064489369801023

Epoch: 5| Step: 9
Training loss: 2.734544498094801
Validation loss: 2.603222580282913

Epoch: 5| Step: 10
Training loss: 2.512352467470853
Validation loss: 2.6034133399067456

Epoch: 159| Step: 0
Training loss: 3.260239975176635
Validation loss: 2.601768851307082

Epoch: 5| Step: 1
Training loss: 3.174852298695212
Validation loss: 2.594711445756468

Epoch: 5| Step: 2
Training loss: 2.15497518255189
Validation loss: 2.592628681398348

Epoch: 5| Step: 3
Training loss: 3.0779547474826963
Validation loss: 2.5916828250635184

Epoch: 5| Step: 4
Training loss: 3.232060143090578
Validation loss: 2.5940286501746628

Epoch: 5| Step: 5
Training loss: 2.2863021716155725
Validation loss: 2.591986762450413

Epoch: 5| Step: 6
Training loss: 3.297736611253565
Validation loss: 2.5933083322397925

Epoch: 5| Step: 7
Training loss: 3.044795808757758
Validation loss: 2.6033361236878525

Epoch: 5| Step: 8
Training loss: 3.0437082902686323
Validation loss: 2.6172552862497094

Epoch: 5| Step: 9
Training loss: 2.6078784785715348
Validation loss: 2.622172391906526

Epoch: 5| Step: 10
Training loss: 2.7448317773965774
Validation loss: 2.627759078233888

Epoch: 160| Step: 0
Training loss: 2.3663784948606006
Validation loss: 2.6353167816057015

Epoch: 5| Step: 1
Training loss: 2.591857771456315
Validation loss: 2.6427047121097367

Epoch: 5| Step: 2
Training loss: 2.5926471801591813
Validation loss: 2.639853025629136

Epoch: 5| Step: 3
Training loss: 3.4707517604393394
Validation loss: 2.6449942365666885

Epoch: 5| Step: 4
Training loss: 2.954657424458992
Validation loss: 2.6490978816741118

Epoch: 5| Step: 5
Training loss: 3.05778498571431
Validation loss: 2.642477267535201

Epoch: 5| Step: 6
Training loss: 3.160851627226178
Validation loss: 2.6266844736239703

Epoch: 5| Step: 7
Training loss: 3.3708058894061486
Validation loss: 2.612756712136733

Epoch: 5| Step: 8
Training loss: 2.4673168030110966
Validation loss: 2.6005909620844627

Epoch: 5| Step: 9
Training loss: 2.970279821449892
Validation loss: 2.5908466679445254

Epoch: 5| Step: 10
Training loss: 2.8519214978963876
Validation loss: 2.5928552643271456

Epoch: 161| Step: 0
Training loss: 2.872542118464249
Validation loss: 2.596722343414808

Epoch: 5| Step: 1
Training loss: 2.986357664432469
Validation loss: 2.5995396217131046

Epoch: 5| Step: 2
Training loss: 2.9424406666959944
Validation loss: 2.595361118533332

Epoch: 5| Step: 3
Training loss: 3.258024872002876
Validation loss: 2.596090511829934

Epoch: 5| Step: 4
Training loss: 2.794151557208753
Validation loss: 2.594229833561207

Epoch: 5| Step: 5
Training loss: 2.7452309611005696
Validation loss: 2.593424102871689

Epoch: 5| Step: 6
Training loss: 3.2333247004390446
Validation loss: 2.592462674129917

Epoch: 5| Step: 7
Training loss: 3.1209321057758217
Validation loss: 2.587687115955195

Epoch: 5| Step: 8
Training loss: 3.0526820475461647
Validation loss: 2.5879438390850384

Epoch: 5| Step: 9
Training loss: 2.557752165085681
Validation loss: 2.597680258333489

Epoch: 5| Step: 10
Training loss: 2.670226720835072
Validation loss: 2.6068154063906213

Epoch: 162| Step: 0
Training loss: 3.0794574158070516
Validation loss: 2.61929003410406

Epoch: 5| Step: 1
Training loss: 3.1451356295161195
Validation loss: 2.61534304469912

Epoch: 5| Step: 2
Training loss: 2.8040593115863808
Validation loss: 2.6103684075192435

Epoch: 5| Step: 3
Training loss: 3.286670095610877
Validation loss: 2.6131919594080415

Epoch: 5| Step: 4
Training loss: 2.6197583681168224
Validation loss: 2.594485454761178

Epoch: 5| Step: 5
Training loss: 2.9619272636121905
Validation loss: 2.5924623992206035

Epoch: 5| Step: 6
Training loss: 3.013037010859408
Validation loss: 2.590248632699149

Epoch: 5| Step: 7
Training loss: 2.9880276840439066
Validation loss: 2.589548511647364

Epoch: 5| Step: 8
Training loss: 2.7425447323679712
Validation loss: 2.589521120809891

Epoch: 5| Step: 9
Training loss: 2.672713655615227
Validation loss: 2.5941105945406666

Epoch: 5| Step: 10
Training loss: 2.750830178230585
Validation loss: 2.592492397785823

Epoch: 163| Step: 0
Training loss: 2.7775648756030153
Validation loss: 2.601862838738885

Epoch: 5| Step: 1
Training loss: 2.6363304473916465
Validation loss: 2.6040245772124475

Epoch: 5| Step: 2
Training loss: 2.9045203199288165
Validation loss: 2.6215475263700387

Epoch: 5| Step: 3
Training loss: 3.034289851305145
Validation loss: 2.6123970230861278

Epoch: 5| Step: 4
Training loss: 2.396994190659404
Validation loss: 2.5940193543455585

Epoch: 5| Step: 5
Training loss: 2.9463347019584103
Validation loss: 2.5901298082232906

Epoch: 5| Step: 6
Training loss: 3.216739656348277
Validation loss: 2.5901730332304997

Epoch: 5| Step: 7
Training loss: 2.696126444553963
Validation loss: 2.587209513292498

Epoch: 5| Step: 8
Training loss: 3.0242932904930675
Validation loss: 2.5841011982884194

Epoch: 5| Step: 9
Training loss: 3.15499974028621
Validation loss: 2.5865463671695013

Epoch: 5| Step: 10
Training loss: 3.1909197246193526
Validation loss: 2.5862370809373747

Epoch: 164| Step: 0
Training loss: 2.921889034788318
Validation loss: 2.5922398911147617

Epoch: 5| Step: 1
Training loss: 2.7771915442371937
Validation loss: 2.590496056747951

Epoch: 5| Step: 2
Training loss: 3.0684858717360823
Validation loss: 2.594158898966942

Epoch: 5| Step: 3
Training loss: 3.2792832065863147
Validation loss: 2.595723425034726

Epoch: 5| Step: 4
Training loss: 2.9665975698360945
Validation loss: 2.5876390543140855

Epoch: 5| Step: 5
Training loss: 2.418471473606054
Validation loss: 2.588326216645524

Epoch: 5| Step: 6
Training loss: 3.1943934081787453
Validation loss: 2.5896079680974213

Epoch: 5| Step: 7
Training loss: 2.5565740403261223
Validation loss: 2.589600337378264

Epoch: 5| Step: 8
Training loss: 2.3413864425111566
Validation loss: 2.5912375153743294

Epoch: 5| Step: 9
Training loss: 3.335653610121091
Validation loss: 2.5903512901631016

Epoch: 5| Step: 10
Training loss: 2.931196063425927
Validation loss: 2.5930858047780068

Epoch: 165| Step: 0
Training loss: 2.607249416405754
Validation loss: 2.5863640457003787

Epoch: 5| Step: 1
Training loss: 2.8997699317434575
Validation loss: 2.5926744860586823

Epoch: 5| Step: 2
Training loss: 2.953946438334127
Validation loss: 2.5909398216800072

Epoch: 5| Step: 3
Training loss: 3.5362006399270265
Validation loss: 2.59374236664067

Epoch: 5| Step: 4
Training loss: 2.982974377851076
Validation loss: 2.5888426112159806

Epoch: 5| Step: 5
Training loss: 2.465313995047537
Validation loss: 2.585277949495995

Epoch: 5| Step: 6
Training loss: 2.8262184418675678
Validation loss: 2.5892283155188656

Epoch: 5| Step: 7
Training loss: 3.0287871433047657
Validation loss: 2.5854206035166554

Epoch: 5| Step: 8
Training loss: 2.7432088226979694
Validation loss: 2.583588220074095

Epoch: 5| Step: 9
Training loss: 2.911348198642724
Validation loss: 2.587561736921673

Epoch: 5| Step: 10
Training loss: 2.835075142216114
Validation loss: 2.5966144958321196

Epoch: 166| Step: 0
Training loss: 2.439821458287785
Validation loss: 2.59687202255706

Epoch: 5| Step: 1
Training loss: 2.7007864830930823
Validation loss: 2.594310328832983

Epoch: 5| Step: 2
Training loss: 3.092997912302925
Validation loss: 2.600133611682841

Epoch: 5| Step: 3
Training loss: 2.386154582622255
Validation loss: 2.5936160259929384

Epoch: 5| Step: 4
Training loss: 2.922964617081425
Validation loss: 2.609992996688585

Epoch: 5| Step: 5
Training loss: 3.1754174205894428
Validation loss: 2.595546650196225

Epoch: 5| Step: 6
Training loss: 3.0359369596990318
Validation loss: 2.5934722075571965

Epoch: 5| Step: 7
Training loss: 3.511765731140823
Validation loss: 2.579323885066331

Epoch: 5| Step: 8
Training loss: 2.7577355565908506
Validation loss: 2.583278057672733

Epoch: 5| Step: 9
Training loss: 2.982877185693645
Validation loss: 2.580167548079648

Epoch: 5| Step: 10
Training loss: 2.696830786279599
Validation loss: 2.580133124763858

Epoch: 167| Step: 0
Training loss: 3.3004468037387125
Validation loss: 2.57877691583885

Epoch: 5| Step: 1
Training loss: 2.5166736573212733
Validation loss: 2.575902201000023

Epoch: 5| Step: 2
Training loss: 2.896492277045863
Validation loss: 2.587050188100734

Epoch: 5| Step: 3
Training loss: 2.9903042197713305
Validation loss: 2.588021723560461

Epoch: 5| Step: 4
Training loss: 2.7784066399703358
Validation loss: 2.5934181519998996

Epoch: 5| Step: 5
Training loss: 3.0779344528783943
Validation loss: 2.6088168641723533

Epoch: 5| Step: 6
Training loss: 2.7778324174805276
Validation loss: 2.640243531845127

Epoch: 5| Step: 7
Training loss: 3.131929268322077
Validation loss: 2.6439129186552646

Epoch: 5| Step: 8
Training loss: 2.9881594963452245
Validation loss: 2.6254942722114856

Epoch: 5| Step: 9
Training loss: 2.9554276143094507
Validation loss: 2.5985838858528902

Epoch: 5| Step: 10
Training loss: 2.2851685613316866
Validation loss: 2.5792774715838847

Epoch: 168| Step: 0
Training loss: 2.9241779248106137
Validation loss: 2.573079343225413

Epoch: 5| Step: 1
Training loss: 3.2010905434108325
Validation loss: 2.5729250959863013

Epoch: 5| Step: 2
Training loss: 2.989802194131608
Validation loss: 2.5735571843964435

Epoch: 5| Step: 3
Training loss: 2.7958750722150647
Validation loss: 2.573158109018714

Epoch: 5| Step: 4
Training loss: 2.973582139859714
Validation loss: 2.5693790613347685

Epoch: 5| Step: 5
Training loss: 2.334600467849354
Validation loss: 2.574196925957645

Epoch: 5| Step: 6
Training loss: 2.5654018068051028
Validation loss: 2.567083489950741

Epoch: 5| Step: 7
Training loss: 3.056329388357734
Validation loss: 2.5742189551534858

Epoch: 5| Step: 8
Training loss: 3.348446693710401
Validation loss: 2.573741698029836

Epoch: 5| Step: 9
Training loss: 2.777427360896438
Validation loss: 2.5862538768398835

Epoch: 5| Step: 10
Training loss: 2.8168533541717595
Validation loss: 2.5959018558453324

Epoch: 169| Step: 0
Training loss: 3.248572109235282
Validation loss: 2.6207133742869795

Epoch: 5| Step: 1
Training loss: 3.102367844268294
Validation loss: 2.6353760800115547

Epoch: 5| Step: 2
Training loss: 3.0923420177865615
Validation loss: 2.6417301499014108

Epoch: 5| Step: 3
Training loss: 2.7809226882871054
Validation loss: 2.6586855238422253

Epoch: 5| Step: 4
Training loss: 2.250863757172084
Validation loss: 2.645336116676652

Epoch: 5| Step: 5
Training loss: 2.894688569811739
Validation loss: 2.6185444433526435

Epoch: 5| Step: 6
Training loss: 3.292315036962943
Validation loss: 2.5978975331844203

Epoch: 5| Step: 7
Training loss: 2.4440647634737913
Validation loss: 2.5907284012935476

Epoch: 5| Step: 8
Training loss: 3.307339661417667
Validation loss: 2.5743301698373355

Epoch: 5| Step: 9
Training loss: 2.546778390374344
Validation loss: 2.569359157809344

Epoch: 5| Step: 10
Training loss: 2.6854995556910715
Validation loss: 2.565709484973012

Epoch: 170| Step: 0
Training loss: 2.92880162387731
Validation loss: 2.5666296742376673

Epoch: 5| Step: 1
Training loss: 2.939343137996267
Validation loss: 2.567944886417076

Epoch: 5| Step: 2
Training loss: 3.021569909806595
Validation loss: 2.5777043004001747

Epoch: 5| Step: 3
Training loss: 2.7948327306876872
Validation loss: 2.577192359698036

Epoch: 5| Step: 4
Training loss: 3.0764046910906013
Validation loss: 2.574966360195596

Epoch: 5| Step: 5
Training loss: 2.9992112076414346
Validation loss: 2.583270086717655

Epoch: 5| Step: 6
Training loss: 2.949687592079734
Validation loss: 2.583368942883314

Epoch: 5| Step: 7
Training loss: 2.8773101150075577
Validation loss: 2.583501102452585

Epoch: 5| Step: 8
Training loss: 2.8543887829265095
Validation loss: 2.5819195190817115

Epoch: 5| Step: 9
Training loss: 2.3833413459625357
Validation loss: 2.5877356601598227

Epoch: 5| Step: 10
Training loss: 2.820052792751627
Validation loss: 2.5916683676639267

Epoch: 171| Step: 0
Training loss: 2.531561655709079
Validation loss: 2.6018050486991804

Epoch: 5| Step: 1
Training loss: 3.514464597989637
Validation loss: 2.602477886008318

Epoch: 5| Step: 2
Training loss: 2.9830200954352466
Validation loss: 2.603222966322533

Epoch: 5| Step: 3
Training loss: 3.761247425122836
Validation loss: 2.6009372830900825

Epoch: 5| Step: 4
Training loss: 2.701736711099643
Validation loss: 2.5899093090787253

Epoch: 5| Step: 5
Training loss: 2.2283528943036632
Validation loss: 2.5753464548256

Epoch: 5| Step: 6
Training loss: 2.405735704030874
Validation loss: 2.5629210727668905

Epoch: 5| Step: 7
Training loss: 3.118403682706957
Validation loss: 2.5632225391573065

Epoch: 5| Step: 8
Training loss: 2.595537603768376
Validation loss: 2.5623800638315215

Epoch: 5| Step: 9
Training loss: 2.7171533215014545
Validation loss: 2.562024895588594

Epoch: 5| Step: 10
Training loss: 2.8719499414273315
Validation loss: 2.5597058686402487

Epoch: 172| Step: 0
Training loss: 2.4906660356575263
Validation loss: 2.565604293703913

Epoch: 5| Step: 1
Training loss: 2.599798389100768
Validation loss: 2.580300090199761

Epoch: 5| Step: 2
Training loss: 2.9875640606895164
Validation loss: 2.589567528890617

Epoch: 5| Step: 3
Training loss: 2.727444743742699
Validation loss: 2.59620784694829

Epoch: 5| Step: 4
Training loss: 2.6758860323918148
Validation loss: 2.609664909729506

Epoch: 5| Step: 5
Training loss: 3.0433614181219877
Validation loss: 2.606405699603827

Epoch: 5| Step: 6
Training loss: 2.852304858420834
Validation loss: 2.5950439562324856

Epoch: 5| Step: 7
Training loss: 2.8107222130581087
Validation loss: 2.5947409954498104

Epoch: 5| Step: 8
Training loss: 2.864380670950143
Validation loss: 2.607466261592179

Epoch: 5| Step: 9
Training loss: 3.318663423202767
Validation loss: 2.602525968148722

Epoch: 5| Step: 10
Training loss: 3.271419513116338
Validation loss: 2.617459046809492

Epoch: 173| Step: 0
Training loss: 2.9315451467317812
Validation loss: 2.5861330240043516

Epoch: 5| Step: 1
Training loss: 3.0619836488731935
Validation loss: 2.5994710224002078

Epoch: 5| Step: 2
Training loss: 2.949270326277077
Validation loss: 2.5847002085718245

Epoch: 5| Step: 3
Training loss: 3.139702960500528
Validation loss: 2.582041663277828

Epoch: 5| Step: 4
Training loss: 2.699051450190219
Validation loss: 2.5841768444361235

Epoch: 5| Step: 5
Training loss: 2.832504506524214
Validation loss: 2.5974539916818684

Epoch: 5| Step: 6
Training loss: 2.8935579833553624
Validation loss: 2.616172856118241

Epoch: 5| Step: 7
Training loss: 2.5094538276044087
Validation loss: 2.6132634192015893

Epoch: 5| Step: 8
Training loss: 2.9187566262931677
Validation loss: 2.5983215244979974

Epoch: 5| Step: 9
Training loss: 2.6063965570971543
Validation loss: 2.592482750342074

Epoch: 5| Step: 10
Training loss: 3.2343088041893795
Validation loss: 2.581102292690036

Epoch: 174| Step: 0
Training loss: 3.1256000705602798
Validation loss: 2.584667729175016

Epoch: 5| Step: 1
Training loss: 2.9584494733623536
Validation loss: 2.5747244465148613

Epoch: 5| Step: 2
Training loss: 2.6955729040873666
Validation loss: 2.5711801411447155

Epoch: 5| Step: 3
Training loss: 2.8605822740047344
Validation loss: 2.5620469043651997

Epoch: 5| Step: 4
Training loss: 3.0955190513590223
Validation loss: 2.560492546862017

Epoch: 5| Step: 5
Training loss: 2.7950767831372385
Validation loss: 2.553981405832153

Epoch: 5| Step: 6
Training loss: 3.2813511424143895
Validation loss: 2.550934226777113

Epoch: 5| Step: 7
Training loss: 2.2727601395744723
Validation loss: 2.5503760394138517

Epoch: 5| Step: 8
Training loss: 2.9627044156528353
Validation loss: 2.5534983050971327

Epoch: 5| Step: 9
Training loss: 2.9550508547052186
Validation loss: 2.5559545087484543

Epoch: 5| Step: 10
Training loss: 2.7893009885234035
Validation loss: 2.5552114001120514

Epoch: 175| Step: 0
Training loss: 3.2308606206453137
Validation loss: 2.5705651879274543

Epoch: 5| Step: 1
Training loss: 2.7340371059363777
Validation loss: 2.5816218233821178

Epoch: 5| Step: 2
Training loss: 2.6612800095471143
Validation loss: 2.6038959354243

Epoch: 5| Step: 3
Training loss: 2.8370036493492385
Validation loss: 2.6215664469272757

Epoch: 5| Step: 4
Training loss: 2.4104276779393676
Validation loss: 2.635634910389021

Epoch: 5| Step: 5
Training loss: 2.532889412165773
Validation loss: 2.645368616790222

Epoch: 5| Step: 6
Training loss: 3.4551148356055665
Validation loss: 2.6116236262118258

Epoch: 5| Step: 7
Training loss: 2.8762653717465807
Validation loss: 2.581335624782899

Epoch: 5| Step: 8
Training loss: 3.019689637208751
Validation loss: 2.5650651159958273

Epoch: 5| Step: 9
Training loss: 2.9868642601431534
Validation loss: 2.557323883584181

Epoch: 5| Step: 10
Training loss: 2.9707246336951467
Validation loss: 2.5507335462712124

Epoch: 176| Step: 0
Training loss: 2.4830111232697387
Validation loss: 2.55274252967873

Epoch: 5| Step: 1
Training loss: 2.921513172940613
Validation loss: 2.5500772942625884

Epoch: 5| Step: 2
Training loss: 2.934926143152375
Validation loss: 2.555220452359807

Epoch: 5| Step: 3
Training loss: 2.9252332675873567
Validation loss: 2.5482373021918554

Epoch: 5| Step: 4
Training loss: 2.4697322581426513
Validation loss: 2.55203410225237

Epoch: 5| Step: 5
Training loss: 2.9715004477348934
Validation loss: 2.572064656252443

Epoch: 5| Step: 6
Training loss: 3.119951060473702
Validation loss: 2.560694689118388

Epoch: 5| Step: 7
Training loss: 3.141236203061281
Validation loss: 2.568284874046913

Epoch: 5| Step: 8
Training loss: 3.3298117791213064
Validation loss: 2.5722289959712703

Epoch: 5| Step: 9
Training loss: 2.243276404763293
Validation loss: 2.578358823254103

Epoch: 5| Step: 10
Training loss: 3.051160879118981
Validation loss: 2.5850906236954487

Epoch: 177| Step: 0
Training loss: 3.056103936510006
Validation loss: 2.575856848514009

Epoch: 5| Step: 1
Training loss: 2.7265963401989803
Validation loss: 2.5769720826465177

Epoch: 5| Step: 2
Training loss: 3.358362515482864
Validation loss: 2.5737340581206434

Epoch: 5| Step: 3
Training loss: 3.0074779770346836
Validation loss: 2.576419834964257

Epoch: 5| Step: 4
Training loss: 2.503737516862486
Validation loss: 2.569367811491614

Epoch: 5| Step: 5
Training loss: 3.071605458663102
Validation loss: 2.5599232946332955

Epoch: 5| Step: 6
Training loss: 2.41353910136234
Validation loss: 2.55690812495157

Epoch: 5| Step: 7
Training loss: 2.941125458667659
Validation loss: 2.5538392231766105

Epoch: 5| Step: 8
Training loss: 2.7568733842490856
Validation loss: 2.544446225859858

Epoch: 5| Step: 9
Training loss: 2.5975358289757042
Validation loss: 2.5419126849143425

Epoch: 5| Step: 10
Training loss: 3.0559660048266655
Validation loss: 2.536866403965271

Epoch: 178| Step: 0
Training loss: 3.172802418392489
Validation loss: 2.5370246891830064

Epoch: 5| Step: 1
Training loss: 3.4177285071818844
Validation loss: 2.533460597987714

Epoch: 5| Step: 2
Training loss: 2.985128417455633
Validation loss: 2.5350949633164896

Epoch: 5| Step: 3
Training loss: 2.8030451904638847
Validation loss: 2.536007108112063

Epoch: 5| Step: 4
Training loss: 2.7374048503904946
Validation loss: 2.540785630906175

Epoch: 5| Step: 5
Training loss: 2.5975650169011764
Validation loss: 2.5471955422350776

Epoch: 5| Step: 6
Training loss: 2.658004091815081
Validation loss: 2.548691439598865

Epoch: 5| Step: 7
Training loss: 3.5425921558569593
Validation loss: 2.553739170699622

Epoch: 5| Step: 8
Training loss: 2.545646043330373
Validation loss: 2.5653099842410043

Epoch: 5| Step: 9
Training loss: 2.5678865526934134
Validation loss: 2.5777497486763674

Epoch: 5| Step: 10
Training loss: 2.2154471300446215
Validation loss: 2.578117433737612

Epoch: 179| Step: 0
Training loss: 3.4040562275995354
Validation loss: 2.6103650536484375

Epoch: 5| Step: 1
Training loss: 2.650433623626427
Validation loss: 2.596815037595629

Epoch: 5| Step: 2
Training loss: 2.774841640868353
Validation loss: 2.604547135318961

Epoch: 5| Step: 3
Training loss: 2.3117711748712977
Validation loss: 2.5744798852020834

Epoch: 5| Step: 4
Training loss: 2.9197381513583642
Validation loss: 2.5653653575858955

Epoch: 5| Step: 5
Training loss: 2.587242511708574
Validation loss: 2.5616349831939673

Epoch: 5| Step: 6
Training loss: 2.565630977126488
Validation loss: 2.545964725401947

Epoch: 5| Step: 7
Training loss: 3.01441322449539
Validation loss: 2.54181272223903

Epoch: 5| Step: 8
Training loss: 2.7222210003943093
Validation loss: 2.5361903027245742

Epoch: 5| Step: 9
Training loss: 3.326773355591369
Validation loss: 2.534852432305578

Epoch: 5| Step: 10
Training loss: 3.132899104797709
Validation loss: 2.533396462156942

Epoch: 180| Step: 0
Training loss: 3.411487297731089
Validation loss: 2.5329098836422235

Epoch: 5| Step: 1
Training loss: 3.1679053811768676
Validation loss: 2.53600814781887

Epoch: 5| Step: 2
Training loss: 3.0358931384573347
Validation loss: 2.535348995330704

Epoch: 5| Step: 3
Training loss: 3.0086890590630957
Validation loss: 2.5360042295827285

Epoch: 5| Step: 4
Training loss: 2.6557389609218656
Validation loss: 2.5330003565584582

Epoch: 5| Step: 5
Training loss: 3.2646471229525473
Validation loss: 2.5375485777113687

Epoch: 5| Step: 6
Training loss: 2.0039839404180286
Validation loss: 2.5409132080897687

Epoch: 5| Step: 7
Training loss: 2.7552271495578
Validation loss: 2.5541189784841314

Epoch: 5| Step: 8
Training loss: 2.5745730814678476
Validation loss: 2.573792947587948

Epoch: 5| Step: 9
Training loss: 2.846103239501748
Validation loss: 2.5951991949355415

Epoch: 5| Step: 10
Training loss: 2.59750700787213
Validation loss: 2.5857508545255494

Epoch: 181| Step: 0
Training loss: 2.69044563856433
Validation loss: 2.5679811382952953

Epoch: 5| Step: 1
Training loss: 2.894321531865763
Validation loss: 2.567017804322097

Epoch: 5| Step: 2
Training loss: 2.7029141911679133
Validation loss: 2.5504478871562326

Epoch: 5| Step: 3
Training loss: 2.8699897563897725
Validation loss: 2.5483133127656132

Epoch: 5| Step: 4
Training loss: 2.889931590448664
Validation loss: 2.5412423599877503

Epoch: 5| Step: 5
Training loss: 3.1150937039653983
Validation loss: 2.5386351321167675

Epoch: 5| Step: 6
Training loss: 3.382515627760779
Validation loss: 2.5376342067914828

Epoch: 5| Step: 7
Training loss: 2.537938734939902
Validation loss: 2.534239449579689

Epoch: 5| Step: 8
Training loss: 2.288064576398101
Validation loss: 2.530577750236779

Epoch: 5| Step: 9
Training loss: 3.1077932043612906
Validation loss: 2.5354486713908333

Epoch: 5| Step: 10
Training loss: 2.798734079020077
Validation loss: 2.5376159949800847

Epoch: 182| Step: 0
Training loss: 3.2884236709810013
Validation loss: 2.5458229116957556

Epoch: 5| Step: 1
Training loss: 2.7190788333263276
Validation loss: 2.5480548283250544

Epoch: 5| Step: 2
Training loss: 2.277690566597928
Validation loss: 2.5431168297627345

Epoch: 5| Step: 3
Training loss: 2.7350334028753194
Validation loss: 2.543985964489033

Epoch: 5| Step: 4
Training loss: 3.086433467363571
Validation loss: 2.545420744019544

Epoch: 5| Step: 5
Training loss: 3.1542897699707133
Validation loss: 2.5557859267749823

Epoch: 5| Step: 6
Training loss: 3.021374849037033
Validation loss: 2.5570459286413465

Epoch: 5| Step: 7
Training loss: 2.502576739861878
Validation loss: 2.5485799067985306

Epoch: 5| Step: 8
Training loss: 2.3203330504666546
Validation loss: 2.547748734133483

Epoch: 5| Step: 9
Training loss: 3.1362035192798414
Validation loss: 2.556929567673747

Epoch: 5| Step: 10
Training loss: 2.968865803919424
Validation loss: 2.553173919231969

Epoch: 183| Step: 0
Training loss: 2.3230004972604323
Validation loss: 2.553056716040954

Epoch: 5| Step: 1
Training loss: 3.4427063788534937
Validation loss: 2.561284913417177

Epoch: 5| Step: 2
Training loss: 2.981334155672309
Validation loss: 2.5651587442617885

Epoch: 5| Step: 3
Training loss: 2.9328329468686554
Validation loss: 2.5662843406153013

Epoch: 5| Step: 4
Training loss: 2.6147427655937037
Validation loss: 2.566811499792895

Epoch: 5| Step: 5
Training loss: 2.5790534919554644
Validation loss: 2.587071197173026

Epoch: 5| Step: 6
Training loss: 2.9541091490088536
Validation loss: 2.5773926172899104

Epoch: 5| Step: 7
Training loss: 2.7132648075395296
Validation loss: 2.5652422174725715

Epoch: 5| Step: 8
Training loss: 2.9665697624867486
Validation loss: 2.5528549912893554

Epoch: 5| Step: 9
Training loss: 2.7114395424280495
Validation loss: 2.551565917860361

Epoch: 5| Step: 10
Training loss: 2.981122066543865
Validation loss: 2.5442047202915403

Epoch: 184| Step: 0
Training loss: 2.7429325145912817
Validation loss: 2.5346476141340264

Epoch: 5| Step: 1
Training loss: 2.7472784273393587
Validation loss: 2.538547372616967

Epoch: 5| Step: 2
Training loss: 2.8031312668133856
Validation loss: 2.5352339289066514

Epoch: 5| Step: 3
Training loss: 2.685674268995458
Validation loss: 2.5285943843495544

Epoch: 5| Step: 4
Training loss: 2.953208639585239
Validation loss: 2.540295700332093

Epoch: 5| Step: 5
Training loss: 3.007444205587069
Validation loss: 2.540318768288935

Epoch: 5| Step: 6
Training loss: 2.9169367710567147
Validation loss: 2.542519381135646

Epoch: 5| Step: 7
Training loss: 2.3678374452599766
Validation loss: 2.557233358935259

Epoch: 5| Step: 8
Training loss: 3.095707129827851
Validation loss: 2.5641882642598337

Epoch: 5| Step: 9
Training loss: 2.9857120414824534
Validation loss: 2.5747361867295697

Epoch: 5| Step: 10
Training loss: 2.999325040547046
Validation loss: 2.5952742518816034

Epoch: 185| Step: 0
Training loss: 3.2660469622158548
Validation loss: 2.56198637402088

Epoch: 5| Step: 1
Training loss: 3.0897689019359693
Validation loss: 2.5440680031423586

Epoch: 5| Step: 2
Training loss: 2.304093209924358
Validation loss: 2.538815551562004

Epoch: 5| Step: 3
Training loss: 3.203874304983544
Validation loss: 2.5284319663694923

Epoch: 5| Step: 4
Training loss: 2.9467484998199978
Validation loss: 2.5261330607788786

Epoch: 5| Step: 5
Training loss: 2.7989851168188773
Validation loss: 2.5303757612581474

Epoch: 5| Step: 6
Training loss: 2.8584344703272078
Validation loss: 2.5289874673553605

Epoch: 5| Step: 7
Training loss: 2.563128417579514
Validation loss: 2.526536007459422

Epoch: 5| Step: 8
Training loss: 2.426647578293618
Validation loss: 2.527324207232443

Epoch: 5| Step: 9
Training loss: 2.813232496030357
Validation loss: 2.5307563919274987

Epoch: 5| Step: 10
Training loss: 2.833185547359043
Validation loss: 2.53450351036897

Epoch: 186| Step: 0
Training loss: 2.3389258009030827
Validation loss: 2.543134585851635

Epoch: 5| Step: 1
Training loss: 2.8147354566762677
Validation loss: 2.548768162842208

Epoch: 5| Step: 2
Training loss: 3.556735142766953
Validation loss: 2.5573552196039033

Epoch: 5| Step: 3
Training loss: 3.053792759037346
Validation loss: 2.5629457935863416

Epoch: 5| Step: 4
Training loss: 2.595053012284366
Validation loss: 2.5650083479103483

Epoch: 5| Step: 5
Training loss: 2.664105725427139
Validation loss: 2.5463479027149116

Epoch: 5| Step: 6
Training loss: 2.2219246731341444
Validation loss: 2.545948658573274

Epoch: 5| Step: 7
Training loss: 2.642536983465771
Validation loss: 2.5431445313846766

Epoch: 5| Step: 8
Training loss: 3.6485319921767183
Validation loss: 2.5352639139842985

Epoch: 5| Step: 9
Training loss: 2.8726876952997453
Validation loss: 2.528437467921102

Epoch: 5| Step: 10
Training loss: 2.501230795203682
Validation loss: 2.5345751273331287

Epoch: 187| Step: 0
Training loss: 2.8849900867946356
Validation loss: 2.5448209919038063

Epoch: 5| Step: 1
Training loss: 2.692848738078668
Validation loss: 2.548906949228281

Epoch: 5| Step: 2
Training loss: 2.7557659390166886
Validation loss: 2.5428849751134055

Epoch: 5| Step: 3
Training loss: 2.4793152537550447
Validation loss: 2.555233462558312

Epoch: 5| Step: 4
Training loss: 2.9270930895297727
Validation loss: 2.5680113050424542

Epoch: 5| Step: 5
Training loss: 2.983569131266672
Validation loss: 2.5647022179540646

Epoch: 5| Step: 6
Training loss: 3.083060089238447
Validation loss: 2.571924290645542

Epoch: 5| Step: 7
Training loss: 2.725612092174537
Validation loss: 2.561450524247279

Epoch: 5| Step: 8
Training loss: 2.8914526501993296
Validation loss: 2.55576735580835

Epoch: 5| Step: 9
Training loss: 2.7140604549525436
Validation loss: 2.5410643788055194

Epoch: 5| Step: 10
Training loss: 3.109208145648784
Validation loss: 2.5349360408174912

Epoch: 188| Step: 0
Training loss: 3.0749472078583273
Validation loss: 2.53469157492356

Epoch: 5| Step: 1
Training loss: 3.064248033787938
Validation loss: 2.527518299386634

Epoch: 5| Step: 2
Training loss: 2.499886605552119
Validation loss: 2.5220069478775664

Epoch: 5| Step: 3
Training loss: 3.204216152515085
Validation loss: 2.5207961647617694

Epoch: 5| Step: 4
Training loss: 2.615994491822163
Validation loss: 2.526063842134829

Epoch: 5| Step: 5
Training loss: 2.9008224833686547
Validation loss: 2.526258511121976

Epoch: 5| Step: 6
Training loss: 3.153102098122819
Validation loss: 2.5229738287544676

Epoch: 5| Step: 7
Training loss: 2.898184299977022
Validation loss: 2.521900026233552

Epoch: 5| Step: 8
Training loss: 2.393665648884042
Validation loss: 2.530929313185254

Epoch: 5| Step: 9
Training loss: 2.8796246692014624
Validation loss: 2.5390622889768704

Epoch: 5| Step: 10
Training loss: 2.4685433216740282
Validation loss: 2.569733245067282

Epoch: 189| Step: 0
Training loss: 2.825476148870217
Validation loss: 2.608078186656635

Epoch: 5| Step: 1
Training loss: 3.1387013479675634
Validation loss: 2.6615847615812958

Epoch: 5| Step: 2
Training loss: 2.8557364237891005
Validation loss: 2.731547165618107

Epoch: 5| Step: 3
Training loss: 3.165873746146249
Validation loss: 2.6550105214863033

Epoch: 5| Step: 4
Training loss: 3.2663332522469117
Validation loss: 2.592563820978941

Epoch: 5| Step: 5
Training loss: 2.4087493598751055
Validation loss: 2.549424762898064

Epoch: 5| Step: 6
Training loss: 2.466196212066001
Validation loss: 2.528878583237867

Epoch: 5| Step: 7
Training loss: 3.1939380926296583
Validation loss: 2.5318597980444797

Epoch: 5| Step: 8
Training loss: 2.5464672862224296
Validation loss: 2.551904294278111

Epoch: 5| Step: 9
Training loss: 2.995003990718367
Validation loss: 2.557062313737993

Epoch: 5| Step: 10
Training loss: 2.5597816563416713
Validation loss: 2.5562746455714445

Epoch: 190| Step: 0
Training loss: 2.8853145172730175
Validation loss: 2.5563482640389505

Epoch: 5| Step: 1
Training loss: 2.664556999961247
Validation loss: 2.545880129731986

Epoch: 5| Step: 2
Training loss: 2.745838658082128
Validation loss: 2.5269891407985603

Epoch: 5| Step: 3
Training loss: 2.7577483518234334
Validation loss: 2.517785713465185

Epoch: 5| Step: 4
Training loss: 3.0243366491444696
Validation loss: 2.5258587528161858

Epoch: 5| Step: 5
Training loss: 3.2227679608952533
Validation loss: 2.545232399529484

Epoch: 5| Step: 6
Training loss: 2.565230240926698
Validation loss: 2.5546774890185824

Epoch: 5| Step: 7
Training loss: 3.4225166450803495
Validation loss: 2.5434804500195702

Epoch: 5| Step: 8
Training loss: 3.161184551486149
Validation loss: 2.5489463553995053

Epoch: 5| Step: 9
Training loss: 2.2306062084805585
Validation loss: 2.540580541317105

Epoch: 5| Step: 10
Training loss: 2.8039689272520687
Validation loss: 2.5408692106621023

Epoch: 191| Step: 0
Training loss: 3.1076218152894333
Validation loss: 2.5385310114191304

Epoch: 5| Step: 1
Training loss: 3.191833392802586
Validation loss: 2.538178413646153

Epoch: 5| Step: 2
Training loss: 2.170086350546758
Validation loss: 2.5368787215787627

Epoch: 5| Step: 3
Training loss: 2.521823425900088
Validation loss: 2.540277351175979

Epoch: 5| Step: 4
Training loss: 2.6843652407520957
Validation loss: 2.5274025721489184

Epoch: 5| Step: 5
Training loss: 3.0693076627316818
Validation loss: 2.5389485621228696

Epoch: 5| Step: 6
Training loss: 2.728168703059082
Validation loss: 2.527054589663184

Epoch: 5| Step: 7
Training loss: 3.286424317261972
Validation loss: 2.5332385635082444

Epoch: 5| Step: 8
Training loss: 2.307723189416297
Validation loss: 2.5379661284282613

Epoch: 5| Step: 9
Training loss: 2.5739591291038635
Validation loss: 2.5483266212992377

Epoch: 5| Step: 10
Training loss: 3.3731741028046613
Validation loss: 2.547322992628396

Epoch: 192| Step: 0
Training loss: 3.0155946403912197
Validation loss: 2.5544935693909574

Epoch: 5| Step: 1
Training loss: 2.9654183415239377
Validation loss: 2.584199231009289

Epoch: 5| Step: 2
Training loss: 3.45914400702725
Validation loss: 2.6155594364697308

Epoch: 5| Step: 3
Training loss: 2.9272080979732773
Validation loss: 2.5747028866375823

Epoch: 5| Step: 4
Training loss: 2.501680000400102
Validation loss: 2.554374869120566

Epoch: 5| Step: 5
Training loss: 2.5150034829754535
Validation loss: 2.5342015172712973

Epoch: 5| Step: 6
Training loss: 3.0201413820026963
Validation loss: 2.528192388852065

Epoch: 5| Step: 7
Training loss: 2.6816681862544876
Validation loss: 2.525005188234746

Epoch: 5| Step: 8
Training loss: 2.8482744045720443
Validation loss: 2.5270540824242618

Epoch: 5| Step: 9
Training loss: 2.3195263079766946
Validation loss: 2.526370183051362

Epoch: 5| Step: 10
Training loss: 2.8568145461144505
Validation loss: 2.5275797474690176

Epoch: 193| Step: 0
Training loss: 2.677103025213072
Validation loss: 2.526165702133347

Epoch: 5| Step: 1
Training loss: 2.7389614332477565
Validation loss: 2.5265251584137545

Epoch: 5| Step: 2
Training loss: 3.1249566647385913
Validation loss: 2.525580877545002

Epoch: 5| Step: 3
Training loss: 2.580343228508642
Validation loss: 2.5211362701637223

Epoch: 5| Step: 4
Training loss: 2.668397659520773
Validation loss: 2.526595752477534

Epoch: 5| Step: 5
Training loss: 2.93887832445803
Validation loss: 2.531532711869797

Epoch: 5| Step: 6
Training loss: 3.2608816934442957
Validation loss: 2.5423886250311796

Epoch: 5| Step: 7
Training loss: 2.6395865661392546
Validation loss: 2.5379762952271894

Epoch: 5| Step: 8
Training loss: 2.6998327415370365
Validation loss: 2.555979614897006

Epoch: 5| Step: 9
Training loss: 2.9119515225913144
Validation loss: 2.5895320252045684

Epoch: 5| Step: 10
Training loss: 2.8810043660547553
Validation loss: 2.5734671331466843

Epoch: 194| Step: 0
Training loss: 3.01539824428802
Validation loss: 2.57249942076803

Epoch: 5| Step: 1
Training loss: 3.212348869123341
Validation loss: 2.571572337719347

Epoch: 5| Step: 2
Training loss: 3.1534385623538834
Validation loss: 2.5729441065672467

Epoch: 5| Step: 3
Training loss: 2.6140122011479296
Validation loss: 2.5949543680773988

Epoch: 5| Step: 4
Training loss: 2.438798314118956
Validation loss: 2.597586650534351

Epoch: 5| Step: 5
Training loss: 2.375485621545916
Validation loss: 2.5495426669873007

Epoch: 5| Step: 6
Training loss: 2.8731413098964174
Validation loss: 2.537942653219808

Epoch: 5| Step: 7
Training loss: 2.7787198334230623
Validation loss: 2.5235969769651123

Epoch: 5| Step: 8
Training loss: 2.9712196116805236
Validation loss: 2.526913707240954

Epoch: 5| Step: 9
Training loss: 2.826833862302239
Validation loss: 2.5465331636767576

Epoch: 5| Step: 10
Training loss: 2.885272705306099
Validation loss: 2.603316185336349

Epoch: 195| Step: 0
Training loss: 3.2172689641538397
Validation loss: 2.6246403976683204

Epoch: 5| Step: 1
Training loss: 2.61410003288581
Validation loss: 2.6109496158842007

Epoch: 5| Step: 2
Training loss: 3.187592598561155
Validation loss: 2.603747425090774

Epoch: 5| Step: 3
Training loss: 2.8585013633993013
Validation loss: 2.5809414650861267

Epoch: 5| Step: 4
Training loss: 2.3591135650698822
Validation loss: 2.5681353216108818

Epoch: 5| Step: 5
Training loss: 3.433670824246941
Validation loss: 2.585531021062444

Epoch: 5| Step: 6
Training loss: 2.1386271711580718
Validation loss: 2.578158062983583

Epoch: 5| Step: 7
Training loss: 3.1447806881366227
Validation loss: 2.627176209917207

Epoch: 5| Step: 8
Training loss: 2.9306928613525858
Validation loss: 2.6334569144882063

Epoch: 5| Step: 9
Training loss: 2.47227901817355
Validation loss: 2.617875962611002

Epoch: 5| Step: 10
Training loss: 3.295932146818357
Validation loss: 2.5754419405507445

Epoch: 196| Step: 0
Training loss: 2.4161295019772235
Validation loss: 2.567468910376132

Epoch: 5| Step: 1
Training loss: 2.7633564583700787
Validation loss: 2.57127818094121

Epoch: 5| Step: 2
Training loss: 2.8845097370852892
Validation loss: 2.573273713233461

Epoch: 5| Step: 3
Training loss: 3.1893635706292156
Validation loss: 2.5681657151434534

Epoch: 5| Step: 4
Training loss: 2.8291192599010677
Validation loss: 2.5705991719093624

Epoch: 5| Step: 5
Training loss: 2.913200516833975
Validation loss: 2.5709210360626726

Epoch: 5| Step: 6
Training loss: 3.017459607806078
Validation loss: 2.5665517379217007

Epoch: 5| Step: 7
Training loss: 3.089609631567728
Validation loss: 2.5683909277286134

Epoch: 5| Step: 8
Training loss: 2.8429493877509455
Validation loss: 2.5654861674629594

Epoch: 5| Step: 9
Training loss: 3.129993111843537
Validation loss: 2.558170527893934

Epoch: 5| Step: 10
Training loss: 2.3835216029928477
Validation loss: 2.555055455624492

Epoch: 197| Step: 0
Training loss: 3.1060325254762557
Validation loss: 2.5614216103831917

Epoch: 5| Step: 1
Training loss: 2.5922194411670767
Validation loss: 2.5708582127029507

Epoch: 5| Step: 2
Training loss: 2.9341635728419067
Validation loss: 2.5740239623343553

Epoch: 5| Step: 3
Training loss: 2.6231481286884093
Validation loss: 2.5860683367292974

Epoch: 5| Step: 4
Training loss: 3.1795282347436746
Validation loss: 2.604820362041559

Epoch: 5| Step: 5
Training loss: 2.931520910696957
Validation loss: 2.5905135474642607

Epoch: 5| Step: 6
Training loss: 3.25045919842264
Validation loss: 2.6003469415928917

Epoch: 5| Step: 7
Training loss: 2.699863649386902
Validation loss: 2.5945490587118853

Epoch: 5| Step: 8
Training loss: 2.617558421709906
Validation loss: 2.5784186868705103

Epoch: 5| Step: 9
Training loss: 2.570688515844657
Validation loss: 2.5692681591781787

Epoch: 5| Step: 10
Training loss: 2.84937559950735
Validation loss: 2.5383081246617425

Epoch: 198| Step: 0
Training loss: 2.5077453794439655
Validation loss: 2.5270232177587406

Epoch: 5| Step: 1
Training loss: 2.2614326361964
Validation loss: 2.518446786609996

Epoch: 5| Step: 2
Training loss: 3.3022882215471356
Validation loss: 2.508859982930287

Epoch: 5| Step: 3
Training loss: 2.761276274418366
Validation loss: 2.515783401890108

Epoch: 5| Step: 4
Training loss: 2.6072720945393058
Validation loss: 2.5126227617258534

Epoch: 5| Step: 5
Training loss: 2.5898402517533876
Validation loss: 2.505981132367748

Epoch: 5| Step: 6
Training loss: 2.8304027847660183
Validation loss: 2.514254030383159

Epoch: 5| Step: 7
Training loss: 2.6704637693323328
Validation loss: 2.521514931282474

Epoch: 5| Step: 8
Training loss: 2.9010978067788527
Validation loss: 2.5221460684293984

Epoch: 5| Step: 9
Training loss: 3.24366700759001
Validation loss: 2.529218198808721

Epoch: 5| Step: 10
Training loss: 3.232886667631501
Validation loss: 2.5346476576258894

Epoch: 199| Step: 0
Training loss: 2.4558794630274847
Validation loss: 2.5468254031680724

Epoch: 5| Step: 1
Training loss: 3.059270440439449
Validation loss: 2.544548249699451

Epoch: 5| Step: 2
Training loss: 3.1442984737697657
Validation loss: 2.5477648127537584

Epoch: 5| Step: 3
Training loss: 3.3054799962601904
Validation loss: 2.5462856742046505

Epoch: 5| Step: 4
Training loss: 2.662710702644999
Validation loss: 2.5229903812721686

Epoch: 5| Step: 5
Training loss: 2.7359345266695274
Validation loss: 2.522511171922147

Epoch: 5| Step: 6
Training loss: 2.710114191894037
Validation loss: 2.5177330407867395

Epoch: 5| Step: 7
Training loss: 2.5017066852063516
Validation loss: 2.5146768085246425

Epoch: 5| Step: 8
Training loss: 2.5207307547723974
Validation loss: 2.512765943116728

Epoch: 5| Step: 9
Training loss: 2.8219096979012512
Validation loss: 2.5099192947707416

Epoch: 5| Step: 10
Training loss: 2.959832058085856
Validation loss: 2.5179082818723786

Epoch: 200| Step: 0
Training loss: 2.3916448275358744
Validation loss: 2.5141803463570054

Epoch: 5| Step: 1
Training loss: 2.6061260532390014
Validation loss: 2.521334278432511

Epoch: 5| Step: 2
Training loss: 2.6096904815192694
Validation loss: 2.5065145593147364

Epoch: 5| Step: 3
Training loss: 2.52167139755918
Validation loss: 2.5154019405094394

Epoch: 5| Step: 4
Training loss: 3.4016572279349817
Validation loss: 2.525148807633661

Epoch: 5| Step: 5
Training loss: 2.8300260614064574
Validation loss: 2.5277582653358874

Epoch: 5| Step: 6
Training loss: 3.127191309342857
Validation loss: 2.5353922563828872

Epoch: 5| Step: 7
Training loss: 2.961440876468638
Validation loss: 2.5488553853632623

Epoch: 5| Step: 8
Training loss: 3.0662180848915837
Validation loss: 2.551805816555891

Epoch: 5| Step: 9
Training loss: 2.7297758825063605
Validation loss: 2.54309517228743

Epoch: 5| Step: 10
Training loss: 2.4332703303537473
Validation loss: 2.5451984616134493

Epoch: 201| Step: 0
Training loss: 3.017996216485323
Validation loss: 2.5394235197485786

Epoch: 5| Step: 1
Training loss: 3.455603077170919
Validation loss: 2.545386652503165

Epoch: 5| Step: 2
Training loss: 2.0492114062219486
Validation loss: 2.5507163556645134

Epoch: 5| Step: 3
Training loss: 2.20507271886793
Validation loss: 2.5314971831496034

Epoch: 5| Step: 4
Training loss: 3.1685316383018685
Validation loss: 2.5404034038355734

Epoch: 5| Step: 5
Training loss: 2.2553052874039228
Validation loss: 2.532419203830413

Epoch: 5| Step: 6
Training loss: 2.92138912628651
Validation loss: 2.511942242696906

Epoch: 5| Step: 7
Training loss: 3.0066767145850304
Validation loss: 2.520071369265076

Epoch: 5| Step: 8
Training loss: 2.3565226106261083
Validation loss: 2.522454776529069

Epoch: 5| Step: 9
Training loss: 3.053806031408318
Validation loss: 2.526808314205197

Epoch: 5| Step: 10
Training loss: 3.030687574927321
Validation loss: 2.515066035961764

Epoch: 202| Step: 0
Training loss: 3.0519059339053585
Validation loss: 2.5236066327690483

Epoch: 5| Step: 1
Training loss: 3.0723471075991324
Validation loss: 2.514719554589612

Epoch: 5| Step: 2
Training loss: 2.5446985224321486
Validation loss: 2.512302714633321

Epoch: 5| Step: 3
Training loss: 2.7321419453196425
Validation loss: 2.5100302647559265

Epoch: 5| Step: 4
Training loss: 2.842116672835026
Validation loss: 2.499979824066785

Epoch: 5| Step: 5
Training loss: 2.518328901733431
Validation loss: 2.5060083585748245

Epoch: 5| Step: 6
Training loss: 2.4824712404734584
Validation loss: 2.5122028386312354

Epoch: 5| Step: 7
Training loss: 2.775834973473257
Validation loss: 2.519066407895474

Epoch: 5| Step: 8
Training loss: 3.1239191856530493
Validation loss: 2.526600966820041

Epoch: 5| Step: 9
Training loss: 2.689877633782418
Validation loss: 2.5376041820344764

Epoch: 5| Step: 10
Training loss: 2.997568575700618
Validation loss: 2.5314809566470315

Epoch: 203| Step: 0
Training loss: 2.2770426372813204
Validation loss: 2.526000587189401

Epoch: 5| Step: 1
Training loss: 2.8872240008934966
Validation loss: 2.5191872124884336

Epoch: 5| Step: 2
Training loss: 2.8699897563897725
Validation loss: 2.5313273075866696

Epoch: 5| Step: 3
Training loss: 2.839949699010128
Validation loss: 2.5290101579678264

Epoch: 5| Step: 4
Training loss: 2.5115731346908614
Validation loss: 2.5277602318598733

Epoch: 5| Step: 5
Training loss: 3.2263400760862235
Validation loss: 2.541736507683396

Epoch: 5| Step: 6
Training loss: 2.236541444690793
Validation loss: 2.516264488523643

Epoch: 5| Step: 7
Training loss: 3.379157296264551
Validation loss: 2.513424044474895

Epoch: 5| Step: 8
Training loss: 2.8779755825891735
Validation loss: 2.4959815883065213

Epoch: 5| Step: 9
Training loss: 2.6508196804634827
Validation loss: 2.5036683712440384

Epoch: 5| Step: 10
Training loss: 2.9249385338218206
Validation loss: 2.511598111854996

Epoch: 204| Step: 0
Training loss: 2.6210338056961047
Validation loss: 2.5115016477964622

Epoch: 5| Step: 1
Training loss: 3.1334377054998312
Validation loss: 2.51314202374069

Epoch: 5| Step: 2
Training loss: 2.398595550001666
Validation loss: 2.5087119657818144

Epoch: 5| Step: 3
Training loss: 2.7890168514843667
Validation loss: 2.529091733619944

Epoch: 5| Step: 4
Training loss: 2.503842833574364
Validation loss: 2.5424381233836555

Epoch: 5| Step: 5
Training loss: 2.6404478476426316
Validation loss: 2.545383615879586

Epoch: 5| Step: 6
Training loss: 2.5666812186220835
Validation loss: 2.536073602493822

Epoch: 5| Step: 7
Training loss: 2.3534923251569686
Validation loss: 2.532558484281178

Epoch: 5| Step: 8
Training loss: 3.4672683438214595
Validation loss: 2.544924709696342

Epoch: 5| Step: 9
Training loss: 3.1462105194391228
Validation loss: 2.5490811776286457

Epoch: 5| Step: 10
Training loss: 2.8870884061146587
Validation loss: 2.5401505050481834

Epoch: 205| Step: 0
Training loss: 2.327479535431838
Validation loss: 2.5281325781331767

Epoch: 5| Step: 1
Training loss: 2.537595448319585
Validation loss: 2.5312787956606235

Epoch: 5| Step: 2
Training loss: 2.659319192769225
Validation loss: 2.5410265887352916

Epoch: 5| Step: 3
Training loss: 3.0172653875664213
Validation loss: 2.5342323248597336

Epoch: 5| Step: 4
Training loss: 2.577465551018483
Validation loss: 2.5175560024144255

Epoch: 5| Step: 5
Training loss: 3.056857145885552
Validation loss: 2.517084247629081

Epoch: 5| Step: 6
Training loss: 2.4150798345287092
Validation loss: 2.5118460684423223

Epoch: 5| Step: 7
Training loss: 3.171887026608973
Validation loss: 2.513667578246977

Epoch: 5| Step: 8
Training loss: 2.933181185099895
Validation loss: 2.527046552957728

Epoch: 5| Step: 9
Training loss: 2.3252309951062986
Validation loss: 2.5214925392389618

Epoch: 5| Step: 10
Training loss: 3.5456602730451467
Validation loss: 2.521055020786776

Epoch: 206| Step: 0
Training loss: 2.5775903320763422
Validation loss: 2.520266395329579

Epoch: 5| Step: 1
Training loss: 3.147908282231985
Validation loss: 2.5219807706236437

Epoch: 5| Step: 2
Training loss: 2.7525181078683327
Validation loss: 2.513000991303444

Epoch: 5| Step: 3
Training loss: 2.996754480191993
Validation loss: 2.531074324385506

Epoch: 5| Step: 4
Training loss: 2.7800402635636257
Validation loss: 2.5159282884932477

Epoch: 5| Step: 5
Training loss: 2.59050372936199
Validation loss: 2.516495249608868

Epoch: 5| Step: 6
Training loss: 2.4674194226930513
Validation loss: 2.5143173550021354

Epoch: 5| Step: 7
Training loss: 2.7291439919342726
Validation loss: 2.520180790552969

Epoch: 5| Step: 8
Training loss: 2.8284095916028664
Validation loss: 2.526939435699885

Epoch: 5| Step: 9
Training loss: 2.522064685896496
Validation loss: 2.5140070827288192

Epoch: 5| Step: 10
Training loss: 3.183270659170937
Validation loss: 2.5193608443783257

Epoch: 207| Step: 0
Training loss: 2.7711830970076865
Validation loss: 2.523386281273831

Epoch: 5| Step: 1
Training loss: 2.4354291090526425
Validation loss: 2.53486656496826

Epoch: 5| Step: 2
Training loss: 2.7858065023983505
Validation loss: 2.5381135425217662

Epoch: 5| Step: 3
Training loss: 2.942179746612527
Validation loss: 2.5469202777062208

Epoch: 5| Step: 4
Training loss: 2.7697025563535496
Validation loss: 2.52538589949013

Epoch: 5| Step: 5
Training loss: 2.996216454411632
Validation loss: 2.522289508101994

Epoch: 5| Step: 6
Training loss: 2.5960560853598174
Validation loss: 2.511910463643349

Epoch: 5| Step: 7
Training loss: 3.033925556876432
Validation loss: 2.507117689017892

Epoch: 5| Step: 8
Training loss: 2.113145411386326
Validation loss: 2.5018621523600104

Epoch: 5| Step: 9
Training loss: 3.116134121389481
Validation loss: 2.511649043779421

Epoch: 5| Step: 10
Training loss: 2.9949546349453877
Validation loss: 2.5036521978422046

Epoch: 208| Step: 0
Training loss: 3.2411963728864537
Validation loss: 2.5076809907639737

Epoch: 5| Step: 1
Training loss: 2.9337689668670484
Validation loss: 2.517806780700721

Epoch: 5| Step: 2
Training loss: 2.901485352114526
Validation loss: 2.531617320643205

Epoch: 5| Step: 3
Training loss: 2.9933478991261
Validation loss: 2.560078548554148

Epoch: 5| Step: 4
Training loss: 2.4544699316897014
Validation loss: 2.5738627741159164

Epoch: 5| Step: 5
Training loss: 2.6804482850883735
Validation loss: 2.5652367378899723

Epoch: 5| Step: 6
Training loss: 2.5950620159463753
Validation loss: 2.5467485911982495

Epoch: 5| Step: 7
Training loss: 2.525605395419641
Validation loss: 2.5265276454185184

Epoch: 5| Step: 8
Training loss: 2.9285520260530316
Validation loss: 2.5207038930232346

Epoch: 5| Step: 9
Training loss: 2.897729998092594
Validation loss: 2.522818756161404

Epoch: 5| Step: 10
Training loss: 2.610556329358722
Validation loss: 2.509381520248489

Epoch: 209| Step: 0
Training loss: 2.925438161782868
Validation loss: 2.502687480217917

Epoch: 5| Step: 1
Training loss: 3.0949268607277935
Validation loss: 2.512050521970737

Epoch: 5| Step: 2
Training loss: 2.299411955585971
Validation loss: 2.51181050876502

Epoch: 5| Step: 3
Training loss: 3.0612521061981544
Validation loss: 2.5243726271580065

Epoch: 5| Step: 4
Training loss: 1.8779088027594213
Validation loss: 2.5329430246948705

Epoch: 5| Step: 5
Training loss: 2.796629228928622
Validation loss: 2.538732288933964

Epoch: 5| Step: 6
Training loss: 2.6902196563322494
Validation loss: 2.533936734005087

Epoch: 5| Step: 7
Training loss: 2.869330413545071
Validation loss: 2.5378861370779755

Epoch: 5| Step: 8
Training loss: 3.074647904994173
Validation loss: 2.5199053615769924

Epoch: 5| Step: 9
Training loss: 2.8276054790327723
Validation loss: 2.5243416108853647

Epoch: 5| Step: 10
Training loss: 2.8818092978373087
Validation loss: 2.521879890305915

Epoch: 210| Step: 0
Training loss: 2.471398779597378
Validation loss: 2.535441791726991

Epoch: 5| Step: 1
Training loss: 3.0345967487745944
Validation loss: 2.55055852663047

Epoch: 5| Step: 2
Training loss: 2.676819180964935
Validation loss: 2.5346381288443434

Epoch: 5| Step: 3
Training loss: 2.6451519867292976
Validation loss: 2.5382495724114067

Epoch: 5| Step: 4
Training loss: 3.0146085775426066
Validation loss: 2.529278439969196

Epoch: 5| Step: 5
Training loss: 2.511509721995756
Validation loss: 2.5277424316687593

Epoch: 5| Step: 6
Training loss: 2.9877772884889446
Validation loss: 2.524960532865321

Epoch: 5| Step: 7
Training loss: 3.0283714863360025
Validation loss: 2.531378285630979

Epoch: 5| Step: 8
Training loss: 3.0319349950399577
Validation loss: 2.5186607465332713

Epoch: 5| Step: 9
Training loss: 2.653264061616194
Validation loss: 2.50986896256025

Epoch: 5| Step: 10
Training loss: 2.27731150478351
Validation loss: 2.5178335863025003

Epoch: 211| Step: 0
Training loss: 2.648286528208748
Validation loss: 2.520454366726735

Epoch: 5| Step: 1
Training loss: 2.8462084529023954
Validation loss: 2.508226900871675

Epoch: 5| Step: 2
Training loss: 2.495500903102472
Validation loss: 2.520280476530774

Epoch: 5| Step: 3
Training loss: 2.9727719017519982
Validation loss: 2.522089610999228

Epoch: 5| Step: 4
Training loss: 2.3527796437409845
Validation loss: 2.53819955857153

Epoch: 5| Step: 5
Training loss: 2.7238200476551415
Validation loss: 2.5368078790731152

Epoch: 5| Step: 6
Training loss: 2.7818326018407915
Validation loss: 2.543075398742535

Epoch: 5| Step: 7
Training loss: 3.1862386563960796
Validation loss: 2.5331632072551016

Epoch: 5| Step: 8
Training loss: 3.2580269210105963
Validation loss: 2.526670880991813

Epoch: 5| Step: 9
Training loss: 2.3611275940363377
Validation loss: 2.5053104255924925

Epoch: 5| Step: 10
Training loss: 2.95466807584465
Validation loss: 2.503973756043059

Epoch: 212| Step: 0
Training loss: 3.1594857729425323
Validation loss: 2.498933790354032

Epoch: 5| Step: 1
Training loss: 3.01336332114948
Validation loss: 2.507386395351803

Epoch: 5| Step: 2
Training loss: 2.588872897308396
Validation loss: 2.5346852899448202

Epoch: 5| Step: 3
Training loss: 2.224570792301503
Validation loss: 2.561697771547241

Epoch: 5| Step: 4
Training loss: 3.4279388627572924
Validation loss: 2.5401577383149676

Epoch: 5| Step: 5
Training loss: 2.851331393139173
Validation loss: 2.538030682111744

Epoch: 5| Step: 6
Training loss: 2.5887063867568947
Validation loss: 2.5758892006460914

Epoch: 5| Step: 7
Training loss: 2.7348212177765268
Validation loss: 2.5965822760445114

Epoch: 5| Step: 8
Training loss: 3.008282988770728
Validation loss: 2.633673239136965

Epoch: 5| Step: 9
Training loss: 2.401634744365391
Validation loss: 2.640479358380644

Epoch: 5| Step: 10
Training loss: 2.8807125558456432
Validation loss: 2.627636953743845

Epoch: 213| Step: 0
Training loss: 2.654572349776697
Validation loss: 2.5801557262635875

Epoch: 5| Step: 1
Training loss: 3.310798927996984
Validation loss: 2.5546888426887904

Epoch: 5| Step: 2
Training loss: 2.4111709808010766
Validation loss: 2.51575857939137

Epoch: 5| Step: 3
Training loss: 3.3455986545550918
Validation loss: 2.5065094811520736

Epoch: 5| Step: 4
Training loss: 2.550448292240806
Validation loss: 2.505170574768819

Epoch: 5| Step: 5
Training loss: 2.510494806068152
Validation loss: 2.5190847324403305

Epoch: 5| Step: 6
Training loss: 2.5536076774653846
Validation loss: 2.531704258135148

Epoch: 5| Step: 7
Training loss: 2.589636792965844
Validation loss: 2.5363511459168455

Epoch: 5| Step: 8
Training loss: 2.8875968949875768
Validation loss: 2.541461136077921

Epoch: 5| Step: 9
Training loss: 2.949922470108474
Validation loss: 2.5324412411179558

Epoch: 5| Step: 10
Training loss: 2.810042515633304
Validation loss: 2.5269524053410706

Epoch: 214| Step: 0
Training loss: 3.2756448009047525
Validation loss: 2.514933737828259

Epoch: 5| Step: 1
Training loss: 2.8744483086713584
Validation loss: 2.5062541984240827

Epoch: 5| Step: 2
Training loss: 2.281796951568223
Validation loss: 2.519405909354886

Epoch: 5| Step: 3
Training loss: 3.36189324672759
Validation loss: 2.533636702095789

Epoch: 5| Step: 4
Training loss: 2.9735672265447857
Validation loss: 2.530353165970285

Epoch: 5| Step: 5
Training loss: 2.455502566700353
Validation loss: 2.5318894808431693

Epoch: 5| Step: 6
Training loss: 2.497704596554194
Validation loss: 2.532015699982971

Epoch: 5| Step: 7
Training loss: 2.6633440318586996
Validation loss: 2.551940909641685

Epoch: 5| Step: 8
Training loss: 2.5008151632748628
Validation loss: 2.5419310323510595

Epoch: 5| Step: 9
Training loss: 2.800996439606359
Validation loss: 2.553757850779021

Epoch: 5| Step: 10
Training loss: 2.6142180492866904
Validation loss: 2.5563096649518258

Epoch: 215| Step: 0
Training loss: 2.7151902670605486
Validation loss: 2.5549808346459977

Epoch: 5| Step: 1
Training loss: 2.545394467134053
Validation loss: 2.5402794836086393

Epoch: 5| Step: 2
Training loss: 2.7737650073463334
Validation loss: 2.517850995306927

Epoch: 5| Step: 3
Training loss: 2.9047127216263955
Validation loss: 2.51783911304826

Epoch: 5| Step: 4
Training loss: 3.1710731733114588
Validation loss: 2.503806034970125

Epoch: 5| Step: 5
Training loss: 2.7985527930692506
Validation loss: 2.512815311339201

Epoch: 5| Step: 6
Training loss: 2.9142303827520024
Validation loss: 2.5037737174860797

Epoch: 5| Step: 7
Training loss: 2.2528192024274127
Validation loss: 2.5075336748919166

Epoch: 5| Step: 8
Training loss: 3.0302358287526805
Validation loss: 2.5141276685025544

Epoch: 5| Step: 9
Training loss: 2.7885309134841134
Validation loss: 2.5056595135824784

Epoch: 5| Step: 10
Training loss: 2.637981287718514
Validation loss: 2.5075233059396096

Epoch: 216| Step: 0
Training loss: 2.96050200870641
Validation loss: 2.506185747248246

Epoch: 5| Step: 1
Training loss: 2.51440817268444
Validation loss: 2.505945905836727

Epoch: 5| Step: 2
Training loss: 2.9715768305502857
Validation loss: 2.512351081747716

Epoch: 5| Step: 3
Training loss: 2.304277907359901
Validation loss: 2.5021980641380224

Epoch: 5| Step: 4
Training loss: 2.902431481576959
Validation loss: 2.5065028483299585

Epoch: 5| Step: 5
Training loss: 2.928118069212048
Validation loss: 2.5031993288408065

Epoch: 5| Step: 6
Training loss: 2.8472694165626766
Validation loss: 2.5033501389581425

Epoch: 5| Step: 7
Training loss: 2.7968261543995454
Validation loss: 2.5046065743268175

Epoch: 5| Step: 8
Training loss: 2.6415298988084213
Validation loss: 2.4957067059336855

Epoch: 5| Step: 9
Training loss: 2.5184220585655575
Validation loss: 2.5045962167986153

Epoch: 5| Step: 10
Training loss: 3.040466925500265
Validation loss: 2.513849626449558

Epoch: 217| Step: 0
Training loss: 2.2177218351823633
Validation loss: 2.520405451245546

Epoch: 5| Step: 1
Training loss: 3.0074285088696477
Validation loss: 2.5185505934967733

Epoch: 5| Step: 2
Training loss: 3.4748946743378712
Validation loss: 2.5089441715152137

Epoch: 5| Step: 3
Training loss: 3.12349970089157
Validation loss: 2.515563097858218

Epoch: 5| Step: 4
Training loss: 3.24896737346429
Validation loss: 2.5032878749052725

Epoch: 5| Step: 5
Training loss: 2.4052571812280537
Validation loss: 2.501217285279472

Epoch: 5| Step: 6
Training loss: 2.0097772507104223
Validation loss: 2.506887945353326

Epoch: 5| Step: 7
Training loss: 2.9598542901853153
Validation loss: 2.5027802758486666

Epoch: 5| Step: 8
Training loss: 2.005046795039725
Validation loss: 2.5135856856053995

Epoch: 5| Step: 9
Training loss: 2.787463159702603
Validation loss: 2.517342010716013

Epoch: 5| Step: 10
Training loss: 2.7465895399202918
Validation loss: 2.522399973512056

Epoch: 218| Step: 0
Training loss: 2.7858528025916085
Validation loss: 2.518781714093548

Epoch: 5| Step: 1
Training loss: 2.476430028988617
Validation loss: 2.5272306988917674

Epoch: 5| Step: 2
Training loss: 2.6678888579843667
Validation loss: 2.537291727692823

Epoch: 5| Step: 3
Training loss: 2.843070651222765
Validation loss: 2.5399177447452246

Epoch: 5| Step: 4
Training loss: 3.026698519949429
Validation loss: 2.547482189980975

Epoch: 5| Step: 5
Training loss: 2.9924045414307194
Validation loss: 2.5550427119163897

Epoch: 5| Step: 6
Training loss: 2.2219627652761056
Validation loss: 2.534085101791296

Epoch: 5| Step: 7
Training loss: 2.727074954780392
Validation loss: 2.534040533588895

Epoch: 5| Step: 8
Training loss: 3.304050681799229
Validation loss: 2.5421169580784206

Epoch: 5| Step: 9
Training loss: 2.4476398933806536
Validation loss: 2.5415795790587787

Epoch: 5| Step: 10
Training loss: 2.821250104519661
Validation loss: 2.526109231532196

Epoch: 219| Step: 0
Training loss: 2.8544719746226708
Validation loss: 2.52672263175703

Epoch: 5| Step: 1
Training loss: 2.739146489075921
Validation loss: 2.5233817714565925

Epoch: 5| Step: 2
Training loss: 2.5598888584687427
Validation loss: 2.5332482513778474

Epoch: 5| Step: 3
Training loss: 2.818107186584958
Validation loss: 2.5376540358675816

Epoch: 5| Step: 4
Training loss: 2.9319219994259353
Validation loss: 2.536809317124306

Epoch: 5| Step: 5
Training loss: 2.8213979053727773
Validation loss: 2.5354858449128583

Epoch: 5| Step: 6
Training loss: 2.856547307206822
Validation loss: 2.5377198622784674

Epoch: 5| Step: 7
Training loss: 3.1883700810129514
Validation loss: 2.5144540676459846

Epoch: 5| Step: 8
Training loss: 2.5891228272264977
Validation loss: 2.5106965718558634

Epoch: 5| Step: 9
Training loss: 2.8406334871641636
Validation loss: 2.5250161422949398

Epoch: 5| Step: 10
Training loss: 2.3262287584551564
Validation loss: 2.551133963972093

Epoch: 220| Step: 0
Training loss: 2.9949076665996768
Validation loss: 2.560792936134026

Epoch: 5| Step: 1
Training loss: 2.433156667680139
Validation loss: 2.560762791472021

Epoch: 5| Step: 2
Training loss: 2.9995765387169393
Validation loss: 2.5652780868130014

Epoch: 5| Step: 3
Training loss: 2.6196091109893977
Validation loss: 2.5226532168681626

Epoch: 5| Step: 4
Training loss: 2.7162143677903576
Validation loss: 2.5013830696852972

Epoch: 5| Step: 5
Training loss: 1.9982704194160408
Validation loss: 2.524618293325407

Epoch: 5| Step: 6
Training loss: 3.4250395612450597
Validation loss: 2.541797366951677

Epoch: 5| Step: 7
Training loss: 2.8454014939662264
Validation loss: 2.5583528334019516

Epoch: 5| Step: 8
Training loss: 3.215153879662631
Validation loss: 2.532246187908673

Epoch: 5| Step: 9
Training loss: 3.0382851045191224
Validation loss: 2.512651787184299

Epoch: 5| Step: 10
Training loss: 2.1710155076255413
Validation loss: 2.509355329797268

Epoch: 221| Step: 0
Training loss: 2.7861194630332133
Validation loss: 2.5190599658795265

Epoch: 5| Step: 1
Training loss: 2.903834826330244
Validation loss: 2.544615600400482

Epoch: 5| Step: 2
Training loss: 2.922795767718381
Validation loss: 2.5834148650811293

Epoch: 5| Step: 3
Training loss: 3.07521841622593
Validation loss: 2.580449491980144

Epoch: 5| Step: 4
Training loss: 3.202028561390261
Validation loss: 2.5914785088195624

Epoch: 5| Step: 5
Training loss: 2.410680679813661
Validation loss: 2.567921274951058

Epoch: 5| Step: 6
Training loss: 2.803772248355453
Validation loss: 2.5717882864955968

Epoch: 5| Step: 7
Training loss: 2.477561388227158
Validation loss: 2.545418235187955

Epoch: 5| Step: 8
Training loss: 2.431990044548338
Validation loss: 2.543711764616254

Epoch: 5| Step: 9
Training loss: 2.1997940097086697
Validation loss: 2.5469044152000646

Epoch: 5| Step: 10
Training loss: 3.1674680866900924
Validation loss: 2.551389214499791

Epoch: 222| Step: 0
Training loss: 2.512676145537565
Validation loss: 2.537415583683587

Epoch: 5| Step: 1
Training loss: 2.7878357997194723
Validation loss: 2.5358876218833992

Epoch: 5| Step: 2
Training loss: 3.479163818967343
Validation loss: 2.542924284567903

Epoch: 5| Step: 3
Training loss: 2.8648732171625046
Validation loss: 2.5612432768193116

Epoch: 5| Step: 4
Training loss: 3.029825091963334
Validation loss: 2.5310715086148026

Epoch: 5| Step: 5
Training loss: 2.700226745974362
Validation loss: 2.505090691594123

Epoch: 5| Step: 6
Training loss: 2.238945188463934
Validation loss: 2.500599655918262

Epoch: 5| Step: 7
Training loss: 2.683857156633552
Validation loss: 2.496984235381442

Epoch: 5| Step: 8
Training loss: 2.550937057807246
Validation loss: 2.48733521223449

Epoch: 5| Step: 9
Training loss: 2.904791517277978
Validation loss: 2.4917185259808243

Epoch: 5| Step: 10
Training loss: 2.6540456264170125
Validation loss: 2.5057917928928553

Epoch: 223| Step: 0
Training loss: 3.2982351381072146
Validation loss: 2.5077168819525557

Epoch: 5| Step: 1
Training loss: 2.85674160455839
Validation loss: 2.5023773364757425

Epoch: 5| Step: 2
Training loss: 2.80844654870032
Validation loss: 2.5056884324695092

Epoch: 5| Step: 3
Training loss: 2.638634828975232
Validation loss: 2.494939549773961

Epoch: 5| Step: 4
Training loss: 2.935124674655904
Validation loss: 2.498232520229803

Epoch: 5| Step: 5
Training loss: 2.393523410202112
Validation loss: 2.499507103803968

Epoch: 5| Step: 6
Training loss: 2.7018177200941493
Validation loss: 2.501135366284638

Epoch: 5| Step: 7
Training loss: 2.4686055201492456
Validation loss: 2.5008916925866194

Epoch: 5| Step: 8
Training loss: 2.6983633273057728
Validation loss: 2.508346194661278

Epoch: 5| Step: 9
Training loss: 2.7370569645755536
Validation loss: 2.5029030218784425

Epoch: 5| Step: 10
Training loss: 2.699468708747941
Validation loss: 2.5116457076186616

Epoch: 224| Step: 0
Training loss: 2.80209051837969
Validation loss: 2.5207242936183056

Epoch: 5| Step: 1
Training loss: 2.7047168256292635
Validation loss: 2.5038389684152813

Epoch: 5| Step: 2
Training loss: 3.060808298403413
Validation loss: 2.521064416851175

Epoch: 5| Step: 3
Training loss: 2.91168852540407
Validation loss: 2.5214118290346565

Epoch: 5| Step: 4
Training loss: 2.3847646252429313
Validation loss: 2.5382850273222717

Epoch: 5| Step: 5
Training loss: 2.650231038224637
Validation loss: 2.5445899398424756

Epoch: 5| Step: 6
Training loss: 2.892239011762283
Validation loss: 2.5543204799648906

Epoch: 5| Step: 7
Training loss: 2.691969061085637
Validation loss: 2.5492293840402573

Epoch: 5| Step: 8
Training loss: 2.562017162703264
Validation loss: 2.539005700825745

Epoch: 5| Step: 9
Training loss: 2.7489356668936824
Validation loss: 2.543252544162867

Epoch: 5| Step: 10
Training loss: 2.8025479032044855
Validation loss: 2.5263331970789613

Epoch: 225| Step: 0
Training loss: 2.6565041813127324
Validation loss: 2.529497612314385

Epoch: 5| Step: 1
Training loss: 2.188598357066615
Validation loss: 2.5251507660374006

Epoch: 5| Step: 2
Training loss: 2.506011791752551
Validation loss: 2.5281219610579306

Epoch: 5| Step: 3
Training loss: 2.6236740578196875
Validation loss: 2.5091379914263423

Epoch: 5| Step: 4
Training loss: 2.993924983571061
Validation loss: 2.5093265762778314

Epoch: 5| Step: 5
Training loss: 3.0814231591771173
Validation loss: 2.514773201758954

Epoch: 5| Step: 6
Training loss: 2.6868959679576268
Validation loss: 2.499500654455179

Epoch: 5| Step: 7
Training loss: 2.1252860830376266
Validation loss: 2.4899938887328275

Epoch: 5| Step: 8
Training loss: 3.2917227599438745
Validation loss: 2.4909599583839928

Epoch: 5| Step: 9
Training loss: 3.1333870301481563
Validation loss: 2.4956492322951265

Epoch: 5| Step: 10
Training loss: 2.747918468259771
Validation loss: 2.49036132591853

Epoch: 226| Step: 0
Training loss: 2.718348418645518
Validation loss: 2.4993438238987786

Epoch: 5| Step: 1
Training loss: 3.002627493686942
Validation loss: 2.483838870254381

Epoch: 5| Step: 2
Training loss: 2.693851329198715
Validation loss: 2.497602504752029

Epoch: 5| Step: 3
Training loss: 2.4100096424590514
Validation loss: 2.506408435338086

Epoch: 5| Step: 4
Training loss: 2.7282394892034714
Validation loss: 2.505166330975271

Epoch: 5| Step: 5
Training loss: 2.9565651852618013
Validation loss: 2.5108321400120914

Epoch: 5| Step: 6
Training loss: 3.045688809063604
Validation loss: 2.505917403227082

Epoch: 5| Step: 7
Training loss: 2.6825816371188274
Validation loss: 2.5249794025001364

Epoch: 5| Step: 8
Training loss: 2.2000107634887955
Validation loss: 2.515178024417831

Epoch: 5| Step: 9
Training loss: 2.687247064797348
Validation loss: 2.517217314708771

Epoch: 5| Step: 10
Training loss: 2.891088665040977
Validation loss: 2.5313262137998347

Epoch: 227| Step: 0
Training loss: 2.828196993591165
Validation loss: 2.5154649870481918

Epoch: 5| Step: 1
Training loss: 2.3548316916480445
Validation loss: 2.5167005773665214

Epoch: 5| Step: 2
Training loss: 3.0013580427379885
Validation loss: 2.520727895919702

Epoch: 5| Step: 3
Training loss: 2.8827248329954345
Validation loss: 2.5141251223256087

Epoch: 5| Step: 4
Training loss: 2.4708184377426075
Validation loss: 2.513424608523415

Epoch: 5| Step: 5
Training loss: 2.719935892976497
Validation loss: 2.51802334691606

Epoch: 5| Step: 6
Training loss: 3.115489066782957
Validation loss: 2.5049062147656254

Epoch: 5| Step: 7
Training loss: 2.856976947054522
Validation loss: 2.513909192651879

Epoch: 5| Step: 8
Training loss: 2.678479781626562
Validation loss: 2.5070961173159523

Epoch: 5| Step: 9
Training loss: 2.7137836389903507
Validation loss: 2.51868578471383

Epoch: 5| Step: 10
Training loss: 2.407904811428828
Validation loss: 2.5194887931459924

Epoch: 228| Step: 0
Training loss: 2.515989099536565
Validation loss: 2.5308255956814727

Epoch: 5| Step: 1
Training loss: 2.46029189587763
Validation loss: 2.4964138048366338

Epoch: 5| Step: 2
Training loss: 2.9382845865650093
Validation loss: 2.4957626251268765

Epoch: 5| Step: 3
Training loss: 2.507372856225559
Validation loss: 2.505622102186742

Epoch: 5| Step: 4
Training loss: 2.593615241169375
Validation loss: 2.511749652691646

Epoch: 5| Step: 5
Training loss: 2.0019773007305504
Validation loss: 2.4956094714731267

Epoch: 5| Step: 6
Training loss: 3.367545761556442
Validation loss: 2.4930649992566214

Epoch: 5| Step: 7
Training loss: 2.678879774601921
Validation loss: 2.4976824826973036

Epoch: 5| Step: 8
Training loss: 3.0141270529249953
Validation loss: 2.4952691395161133

Epoch: 5| Step: 9
Training loss: 2.7405482769691245
Validation loss: 2.493404123739609

Epoch: 5| Step: 10
Training loss: 3.0922120249943292
Validation loss: 2.514564458247403

Epoch: 229| Step: 0
Training loss: 2.3502457185886203
Validation loss: 2.522195283542837

Epoch: 5| Step: 1
Training loss: 2.762923650923072
Validation loss: 2.5308164627622727

Epoch: 5| Step: 2
Training loss: 2.9365762110218845
Validation loss: 2.5183386551033533

Epoch: 5| Step: 3
Training loss: 2.451119836505628
Validation loss: 2.5071749007799213

Epoch: 5| Step: 4
Training loss: 2.545211716934565
Validation loss: 2.505830538908305

Epoch: 5| Step: 5
Training loss: 2.957407757311354
Validation loss: 2.50706703776264

Epoch: 5| Step: 6
Training loss: 2.558261715842299
Validation loss: 2.5165809965624995

Epoch: 5| Step: 7
Training loss: 2.6061116902268897
Validation loss: 2.519003334456577

Epoch: 5| Step: 8
Training loss: 3.3142709856222825
Validation loss: 2.5260765869108517

Epoch: 5| Step: 9
Training loss: 2.5106306077221707
Validation loss: 2.5375124164162144

Epoch: 5| Step: 10
Training loss: 2.9142549262036677
Validation loss: 2.5470886946085174

Epoch: 230| Step: 0
Training loss: 2.6991040968662574
Validation loss: 2.5660984815416827

Epoch: 5| Step: 1
Training loss: 2.4789312448572947
Validation loss: 2.578326929163746

Epoch: 5| Step: 2
Training loss: 3.253619452725204
Validation loss: 2.594568187020888

Epoch: 5| Step: 3
Training loss: 2.588787156763507
Validation loss: 2.6429942871044174

Epoch: 5| Step: 4
Training loss: 2.775814359614005
Validation loss: 2.7191932721386203

Epoch: 5| Step: 5
Training loss: 2.8872945208739194
Validation loss: 2.717603715984781

Epoch: 5| Step: 6
Training loss: 2.6515430708236867
Validation loss: 2.7737333351107147

Epoch: 5| Step: 7
Training loss: 3.0690395055510935
Validation loss: 2.801122707891643

Epoch: 5| Step: 8
Training loss: 2.964651229699258
Validation loss: 2.6682983554212534

Epoch: 5| Step: 9
Training loss: 2.6580643684222593
Validation loss: 2.5903973320378735

Epoch: 5| Step: 10
Training loss: 2.685257353001638
Validation loss: 2.557159803042659

Epoch: 231| Step: 0
Training loss: 3.159408348805509
Validation loss: 2.562504846151608

Epoch: 5| Step: 1
Training loss: 2.514317427394939
Validation loss: 2.562941971547578

Epoch: 5| Step: 2
Training loss: 3.330980392338794
Validation loss: 2.558531232162594

Epoch: 5| Step: 3
Training loss: 2.4623931939058887
Validation loss: 2.538631207836715

Epoch: 5| Step: 4
Training loss: 2.5762570174046227
Validation loss: 2.5560703674899665

Epoch: 5| Step: 5
Training loss: 3.281706569332814
Validation loss: 2.5363498764027845

Epoch: 5| Step: 6
Training loss: 2.623071779770545
Validation loss: 2.549098010168945

Epoch: 5| Step: 7
Training loss: 2.958532156553703
Validation loss: 2.559217025238872

Epoch: 5| Step: 8
Training loss: 2.371638076870831
Validation loss: 2.5514463659848454

Epoch: 5| Step: 9
Training loss: 2.268063200095285
Validation loss: 2.5582249594581485

Epoch: 5| Step: 10
Training loss: 2.6739887108518126
Validation loss: 2.551483605850334

Epoch: 232| Step: 0
Training loss: 3.0837275450669424
Validation loss: 2.5545706091110114

Epoch: 5| Step: 1
Training loss: 2.4786904997039776
Validation loss: 2.55307049288124

Epoch: 5| Step: 2
Training loss: 2.228380605366931
Validation loss: 2.5517707464178416

Epoch: 5| Step: 3
Training loss: 3.0555590388730933
Validation loss: 2.55143950936131

Epoch: 5| Step: 4
Training loss: 2.335989246624534
Validation loss: 2.543528875373822

Epoch: 5| Step: 5
Training loss: 2.959806120425426
Validation loss: 2.564810897647086

Epoch: 5| Step: 6
Training loss: 3.171165198972965
Validation loss: 2.561521557947071

Epoch: 5| Step: 7
Training loss: 2.4895536561950165
Validation loss: 2.5368195380774448

Epoch: 5| Step: 8
Training loss: 2.6364030663163542
Validation loss: 2.5393747203061983

Epoch: 5| Step: 9
Training loss: 2.741477243977788
Validation loss: 2.537541977527947

Epoch: 5| Step: 10
Training loss: 2.91007907432273
Validation loss: 2.5263569729678714

Epoch: 233| Step: 0
Training loss: 2.9357585208863046
Validation loss: 2.5285157750153897

Epoch: 5| Step: 1
Training loss: 2.987341719388808
Validation loss: 2.532593891319505

Epoch: 5| Step: 2
Training loss: 2.6264490033828194
Validation loss: 2.523373743372711

Epoch: 5| Step: 3
Training loss: 2.6480502855476176
Validation loss: 2.5132070783616753

Epoch: 5| Step: 4
Training loss: 2.927927856974029
Validation loss: 2.4950142089214253

Epoch: 5| Step: 5
Training loss: 2.8604295797443204
Validation loss: 2.5211653765737276

Epoch: 5| Step: 6
Training loss: 2.5880610571826868
Validation loss: 2.5295162616213487

Epoch: 5| Step: 7
Training loss: 2.8016556953549703
Validation loss: 2.5499128147818197

Epoch: 5| Step: 8
Training loss: 2.367804519259257
Validation loss: 2.5425721170726754

Epoch: 5| Step: 9
Training loss: 2.65347225581117
Validation loss: 2.535875939891917

Epoch: 5| Step: 10
Training loss: 2.5661007773395985
Validation loss: 2.580365498319974

Epoch: 234| Step: 0
Training loss: 2.983523901566036
Validation loss: 2.6108297716674076

Epoch: 5| Step: 1
Training loss: 2.4952712158915578
Validation loss: 2.6406965698088634

Epoch: 5| Step: 2
Training loss: 2.255229383081131
Validation loss: 2.64187125296282

Epoch: 5| Step: 3
Training loss: 2.5960158596700538
Validation loss: 2.6603176466780742

Epoch: 5| Step: 4
Training loss: 2.848285118961317
Validation loss: 2.6740534542515135

Epoch: 5| Step: 5
Training loss: 3.2353039573071016
Validation loss: 2.6308026204771817

Epoch: 5| Step: 6
Training loss: 2.775592149670235
Validation loss: 2.571123184019318

Epoch: 5| Step: 7
Training loss: 2.5434260506518127
Validation loss: 2.5529913995515665

Epoch: 5| Step: 8
Training loss: 2.9226580707755456
Validation loss: 2.5093413670979134

Epoch: 5| Step: 9
Training loss: 2.7067548602476217
Validation loss: 2.517478650755068

Epoch: 5| Step: 10
Training loss: 2.710734335022671
Validation loss: 2.485155602744565

Epoch: 235| Step: 0
Training loss: 2.7877890193255253
Validation loss: 2.499237055904868

Epoch: 5| Step: 1
Training loss: 2.5651631356575786
Validation loss: 2.504463317487025

Epoch: 5| Step: 2
Training loss: 1.974950321393593
Validation loss: 2.4999568945747392

Epoch: 5| Step: 3
Training loss: 2.993067360540261
Validation loss: 2.499995847924179

Epoch: 5| Step: 4
Training loss: 2.804250614067909
Validation loss: 2.505457994973816

Epoch: 5| Step: 5
Training loss: 2.6394618254536937
Validation loss: 2.509879855003171

Epoch: 5| Step: 6
Training loss: 2.9346601678735
Validation loss: 2.506830110377012

Epoch: 5| Step: 7
Training loss: 2.9445926181129893
Validation loss: 2.5104070911846934

Epoch: 5| Step: 8
Training loss: 2.943815706009754
Validation loss: 2.5058468517100865

Epoch: 5| Step: 9
Training loss: 2.4955254565992533
Validation loss: 2.492973360863536

Epoch: 5| Step: 10
Training loss: 2.9816258735346803
Validation loss: 2.4858772780236436

Epoch: 236| Step: 0
Training loss: 2.827624787832604
Validation loss: 2.480147957496667

Epoch: 5| Step: 1
Training loss: 2.9043627117726953
Validation loss: 2.4747020477041817

Epoch: 5| Step: 2
Training loss: 2.8544305461292594
Validation loss: 2.473425531617814

Epoch: 5| Step: 3
Training loss: 2.8576201176532208
Validation loss: 2.4863185213621075

Epoch: 5| Step: 4
Training loss: 2.422067449983441
Validation loss: 2.49396386650336

Epoch: 5| Step: 5
Training loss: 2.9259152146191196
Validation loss: 2.5008098736397617

Epoch: 5| Step: 6
Training loss: 2.9074458461451353
Validation loss: 2.504591672635828

Epoch: 5| Step: 7
Training loss: 2.7235085071580025
Validation loss: 2.509752532323446

Epoch: 5| Step: 8
Training loss: 2.1445602665173236
Validation loss: 2.5180027371032754

Epoch: 5| Step: 9
Training loss: 2.5105360221717246
Validation loss: 2.5199045039458063

Epoch: 5| Step: 10
Training loss: 2.7784897040299414
Validation loss: 2.523488966584843

Epoch: 237| Step: 0
Training loss: 2.7512706075379243
Validation loss: 2.5349105533120624

Epoch: 5| Step: 1
Training loss: 2.345133258799141
Validation loss: 2.5182346949196552

Epoch: 5| Step: 2
Training loss: 2.752429236005669
Validation loss: 2.5103568106246836

Epoch: 5| Step: 3
Training loss: 3.050808289782939
Validation loss: 2.495537739934435

Epoch: 5| Step: 4
Training loss: 2.336223674072723
Validation loss: 2.48355060070722

Epoch: 5| Step: 5
Training loss: 3.1260503910955206
Validation loss: 2.5051203211195583

Epoch: 5| Step: 6
Training loss: 2.5652787563852444
Validation loss: 2.5151607345142346

Epoch: 5| Step: 7
Training loss: 2.551671852623146
Validation loss: 2.5154798625436836

Epoch: 5| Step: 8
Training loss: 3.0950176069655497
Validation loss: 2.5120197005421327

Epoch: 5| Step: 9
Training loss: 2.6959917622335663
Validation loss: 2.5166915602479323

Epoch: 5| Step: 10
Training loss: 2.5188119733962315
Validation loss: 2.5373367267953215

Epoch: 238| Step: 0
Training loss: 2.684725993149893
Validation loss: 2.540869977473153

Epoch: 5| Step: 1
Training loss: 2.8135889276524733
Validation loss: 2.5468351611533198

Epoch: 5| Step: 2
Training loss: 2.445075952953292
Validation loss: 2.5540003752344753

Epoch: 5| Step: 3
Training loss: 2.3488123835003343
Validation loss: 2.5609299837037027

Epoch: 5| Step: 4
Training loss: 3.1731310833130117
Validation loss: 2.5541461362072004

Epoch: 5| Step: 5
Training loss: 2.4666512175239435
Validation loss: 2.536729924968765

Epoch: 5| Step: 6
Training loss: 2.6204331954246323
Validation loss: 2.5431464265355577

Epoch: 5| Step: 7
Training loss: 2.877041299353138
Validation loss: 2.5559598768370595

Epoch: 5| Step: 8
Training loss: 2.4577765615543408
Validation loss: 2.555818565568834

Epoch: 5| Step: 9
Training loss: 3.139080066166551
Validation loss: 2.575435050757535

Epoch: 5| Step: 10
Training loss: 3.04834293314606
Validation loss: 2.5709331177238828

Epoch: 239| Step: 0
Training loss: 3.0032167672735364
Validation loss: 2.5735116162559066

Epoch: 5| Step: 1
Training loss: 2.746864438606243
Validation loss: 2.5789455903993534

Epoch: 5| Step: 2
Training loss: 2.5616362441801837
Validation loss: 2.590501106840723

Epoch: 5| Step: 3
Training loss: 3.0299390337258774
Validation loss: 2.5854469237720745

Epoch: 5| Step: 4
Training loss: 3.0442612612236344
Validation loss: 2.6030904558451726

Epoch: 5| Step: 5
Training loss: 2.4999245632234306
Validation loss: 2.594661378077782

Epoch: 5| Step: 6
Training loss: 2.401427154598951
Validation loss: 2.5997772866443287

Epoch: 5| Step: 7
Training loss: 2.535637244161371
Validation loss: 2.581678853741008

Epoch: 5| Step: 8
Training loss: 2.5812300969942896
Validation loss: 2.562245155946092

Epoch: 5| Step: 9
Training loss: 2.8156877889628587
Validation loss: 2.564640534754496

Epoch: 5| Step: 10
Training loss: 2.7596427744352483
Validation loss: 2.543117978962657

Epoch: 240| Step: 0
Training loss: 2.7923148716937143
Validation loss: 2.531734364000123

Epoch: 5| Step: 1
Training loss: 2.8459849535503454
Validation loss: 2.510370747251736

Epoch: 5| Step: 2
Training loss: 2.965734777639644
Validation loss: 2.501969753058124

Epoch: 5| Step: 3
Training loss: 2.7196367944117217
Validation loss: 2.5159603515231868

Epoch: 5| Step: 4
Training loss: 2.688315866519623
Validation loss: 2.544100802344679

Epoch: 5| Step: 5
Training loss: 2.8573592955489273
Validation loss: 2.559974250013429

Epoch: 5| Step: 6
Training loss: 2.1650964353373046
Validation loss: 2.525290945829785

Epoch: 5| Step: 7
Training loss: 2.7033348222564597
Validation loss: 2.504090303962242

Epoch: 5| Step: 8
Training loss: 2.908021284558088
Validation loss: 2.5233242830260028

Epoch: 5| Step: 9
Training loss: 2.9163917048592554
Validation loss: 2.541002181319647

Epoch: 5| Step: 10
Training loss: 2.259028124002213
Validation loss: 2.5568239149201504

Epoch: 241| Step: 0
Training loss: 2.4891232393927405
Validation loss: 2.5916234359984225

Epoch: 5| Step: 1
Training loss: 2.7464875417774377
Validation loss: 2.612325063631152

Epoch: 5| Step: 2
Training loss: 2.6541784848160184
Validation loss: 2.5834258215467814

Epoch: 5| Step: 3
Training loss: 2.7445427759429646
Validation loss: 2.559151767805377

Epoch: 5| Step: 4
Training loss: 3.5045150517126706
Validation loss: 2.5334125084100343

Epoch: 5| Step: 5
Training loss: 2.691433622666728
Validation loss: 2.5033418469368702

Epoch: 5| Step: 6
Training loss: 2.142100027845776
Validation loss: 2.475727580678974

Epoch: 5| Step: 7
Training loss: 2.5989438185863056
Validation loss: 2.484575972009918

Epoch: 5| Step: 8
Training loss: 2.6001945312792243
Validation loss: 2.4950307979413653

Epoch: 5| Step: 9
Training loss: 3.0183758616352026
Validation loss: 2.5072033533061204

Epoch: 5| Step: 10
Training loss: 2.3514308955984444
Validation loss: 2.5121904030899547

Epoch: 242| Step: 0
Training loss: 3.042215080116619
Validation loss: 2.525735909458055

Epoch: 5| Step: 1
Training loss: 2.50331220557808
Validation loss: 2.5431185545704933

Epoch: 5| Step: 2
Training loss: 2.7914620984029264
Validation loss: 2.5499110915536733

Epoch: 5| Step: 3
Training loss: 2.6600202842168454
Validation loss: 2.5419771898093924

Epoch: 5| Step: 4
Training loss: 3.0141357539536466
Validation loss: 2.5323515621604313

Epoch: 5| Step: 5
Training loss: 3.114369583875405
Validation loss: 2.526299986567124

Epoch: 5| Step: 6
Training loss: 2.690981273567537
Validation loss: 2.5153884445270203

Epoch: 5| Step: 7
Training loss: 2.531812628865554
Validation loss: 2.513920107360428

Epoch: 5| Step: 8
Training loss: 2.358080275025763
Validation loss: 2.5150329080564955

Epoch: 5| Step: 9
Training loss: 2.580162122053636
Validation loss: 2.5489431319211397

Epoch: 5| Step: 10
Training loss: 2.3894799176569754
Validation loss: 2.5719685632094156

Epoch: 243| Step: 0
Training loss: 2.9645571362822856
Validation loss: 2.5685639418044093

Epoch: 5| Step: 1
Training loss: 2.2751793759233476
Validation loss: 2.543162649170924

Epoch: 5| Step: 2
Training loss: 2.1659953715802422
Validation loss: 2.509077697885009

Epoch: 5| Step: 3
Training loss: 3.2700706775271615
Validation loss: 2.4859016955690127

Epoch: 5| Step: 4
Training loss: 2.6950567594082107
Validation loss: 2.4909446915140463

Epoch: 5| Step: 5
Training loss: 2.6055382943773435
Validation loss: 2.5030166524894963

Epoch: 5| Step: 6
Training loss: 2.698070762288838
Validation loss: 2.5110352927101354

Epoch: 5| Step: 7
Training loss: 2.6883889435867556
Validation loss: 2.529922445619516

Epoch: 5| Step: 8
Training loss: 3.2605838103102975
Validation loss: 2.5316560835509336

Epoch: 5| Step: 9
Training loss: 2.5416061102318492
Validation loss: 2.526113907483318

Epoch: 5| Step: 10
Training loss: 2.688396836500629
Validation loss: 2.5353759092036037

Epoch: 244| Step: 0
Training loss: 2.2374017661923387
Validation loss: 2.534651955225121

Epoch: 5| Step: 1
Training loss: 2.4831445873994435
Validation loss: 2.5226381539991602

Epoch: 5| Step: 2
Training loss: 2.443131519307953
Validation loss: 2.510316139985782

Epoch: 5| Step: 3
Training loss: 2.8001399243678553
Validation loss: 2.5496293260781613

Epoch: 5| Step: 4
Training loss: 3.3846732081295645
Validation loss: 2.5584147844345124

Epoch: 5| Step: 5
Training loss: 2.3674421016135088
Validation loss: 2.5677218322126176

Epoch: 5| Step: 6
Training loss: 3.2468394537293426
Validation loss: 2.589699319167146

Epoch: 5| Step: 7
Training loss: 2.7851428102487357
Validation loss: 2.588751447285871

Epoch: 5| Step: 8
Training loss: 2.8359304380723023
Validation loss: 2.5780304365319764

Epoch: 5| Step: 9
Training loss: 2.441776534419759
Validation loss: 2.6070939758138416

Epoch: 5| Step: 10
Training loss: 1.897440644694144
Validation loss: 2.6079050577863425

Epoch: 245| Step: 0
Training loss: 2.4559416909891354
Validation loss: 2.6286732638162644

Epoch: 5| Step: 1
Training loss: 2.8253223167799932
Validation loss: 2.6687115441623908

Epoch: 5| Step: 2
Training loss: 3.1550198414415935
Validation loss: 2.6798781470016615

Epoch: 5| Step: 3
Training loss: 2.6431807389857607
Validation loss: 2.6145765342635436

Epoch: 5| Step: 4
Training loss: 2.7075685350474066
Validation loss: 2.571592839207382

Epoch: 5| Step: 5
Training loss: 2.4986359689788453
Validation loss: 2.561888960311162

Epoch: 5| Step: 6
Training loss: 2.6932425248854885
Validation loss: 2.558768111325246

Epoch: 5| Step: 7
Training loss: 2.1052922049200022
Validation loss: 2.539843845849719

Epoch: 5| Step: 8
Training loss: 2.519284636973815
Validation loss: 2.5444918974035837

Epoch: 5| Step: 9
Training loss: 2.5589726058370217
Validation loss: 2.5396508238720945

Epoch: 5| Step: 10
Training loss: 3.3098048636087984
Validation loss: 2.528461359887302

Epoch: 246| Step: 0
Training loss: 2.7694463676497825
Validation loss: 2.5225807477088806

Epoch: 5| Step: 1
Training loss: 2.736957747172643
Validation loss: 2.5068991289052303

Epoch: 5| Step: 2
Training loss: 2.5975260078075393
Validation loss: 2.5152326841123673

Epoch: 5| Step: 3
Training loss: 2.626965468140147
Validation loss: 2.515348451476055

Epoch: 5| Step: 4
Training loss: 2.7552193615601936
Validation loss: 2.4997241985817107

Epoch: 5| Step: 5
Training loss: 2.957396954557533
Validation loss: 2.507812037937675

Epoch: 5| Step: 6
Training loss: 2.8331843692290737
Validation loss: 2.5193728710780414

Epoch: 5| Step: 7
Training loss: 2.7245155673815296
Validation loss: 2.510181435554162

Epoch: 5| Step: 8
Training loss: 2.6550996870159027
Validation loss: 2.5462358806358245

Epoch: 5| Step: 9
Training loss: 2.5757970298628527
Validation loss: 2.5421352193302265

Epoch: 5| Step: 10
Training loss: 2.1615660000991004
Validation loss: 2.5463586793850066

Epoch: 247| Step: 0
Training loss: 2.8672929375410616
Validation loss: 2.5512715012557026

Epoch: 5| Step: 1
Training loss: 3.123576793837397
Validation loss: 2.561351713929671

Epoch: 5| Step: 2
Training loss: 2.410373375013987
Validation loss: 2.55886808639116

Epoch: 5| Step: 3
Training loss: 2.420224026958605
Validation loss: 2.5480888046610826

Epoch: 5| Step: 4
Training loss: 2.131731702673922
Validation loss: 2.5527568073336697

Epoch: 5| Step: 5
Training loss: 2.2930762608553046
Validation loss: 2.5469765742606705

Epoch: 5| Step: 6
Training loss: 2.5116537272578388
Validation loss: 2.559455790113473

Epoch: 5| Step: 7
Training loss: 2.9886326003619597
Validation loss: 2.5586803209653683

Epoch: 5| Step: 8
Training loss: 2.9001170430735015
Validation loss: 2.5444243580385266

Epoch: 5| Step: 9
Training loss: 2.8372159235917382
Validation loss: 2.532458086064881

Epoch: 5| Step: 10
Training loss: 2.8347844914195806
Validation loss: 2.524033973536903

Epoch: 248| Step: 0
Training loss: 2.6980059006317516
Validation loss: 2.5301985800966693

Epoch: 5| Step: 1
Training loss: 3.1739628877639436
Validation loss: 2.5433498909933734

Epoch: 5| Step: 2
Training loss: 2.7668094146241855
Validation loss: 2.558108245243234

Epoch: 5| Step: 3
Training loss: 2.236683326731155
Validation loss: 2.564914366327239

Epoch: 5| Step: 4
Training loss: 2.3867232452200406
Validation loss: 2.603953075550632

Epoch: 5| Step: 5
Training loss: 2.940015811228892
Validation loss: 2.663072067489294

Epoch: 5| Step: 6
Training loss: 2.6829949700716793
Validation loss: 2.686996209558013

Epoch: 5| Step: 7
Training loss: 2.3441956160035127
Validation loss: 2.639613723479578

Epoch: 5| Step: 8
Training loss: 2.791873316921242
Validation loss: 2.5973121071536247

Epoch: 5| Step: 9
Training loss: 2.5160432076981807
Validation loss: 2.5573435599908874

Epoch: 5| Step: 10
Training loss: 2.8383912959501867
Validation loss: 2.5235301482400248

Epoch: 249| Step: 0
Training loss: 2.679384264457245
Validation loss: 2.5221698034904056

Epoch: 5| Step: 1
Training loss: 2.3288190178464494
Validation loss: 2.5176532741496227

Epoch: 5| Step: 2
Training loss: 3.3116076725039325
Validation loss: 2.523292012327087

Epoch: 5| Step: 3
Training loss: 2.6697665813297986
Validation loss: 2.509434689006886

Epoch: 5| Step: 4
Training loss: 2.1072960675492642
Validation loss: 2.509577112470698

Epoch: 5| Step: 5
Training loss: 2.4830986919108815
Validation loss: 2.5117199084622883

Epoch: 5| Step: 6
Training loss: 2.8637839756802177
Validation loss: 2.5100429254834156

Epoch: 5| Step: 7
Training loss: 2.6828511861279147
Validation loss: 2.5191093420353288

Epoch: 5| Step: 8
Training loss: 2.882853189817006
Validation loss: 2.513622230889691

Epoch: 5| Step: 9
Training loss: 2.7309013755252054
Validation loss: 2.4974828846047

Epoch: 5| Step: 10
Training loss: 2.844871886575104
Validation loss: 2.4898480664907443

Epoch: 250| Step: 0
Training loss: 2.5677527577939996
Validation loss: 2.4962764451478123

Epoch: 5| Step: 1
Training loss: 2.8871460470606793
Validation loss: 2.504081642758111

Epoch: 5| Step: 2
Training loss: 3.01278157164802
Validation loss: 2.527098753551316

Epoch: 5| Step: 3
Training loss: 2.219160659825839
Validation loss: 2.5195631689918065

Epoch: 5| Step: 4
Training loss: 2.9036878551413228
Validation loss: 2.5184594345464464

Epoch: 5| Step: 5
Training loss: 2.372998146844101
Validation loss: 2.506449506914781

Epoch: 5| Step: 6
Training loss: 2.6539948707766725
Validation loss: 2.495980091810897

Epoch: 5| Step: 7
Training loss: 2.4563259938061766
Validation loss: 2.5137387312452453

Epoch: 5| Step: 8
Training loss: 2.5476180788775964
Validation loss: 2.5378947308976354

Epoch: 5| Step: 9
Training loss: 2.8506679019990724
Validation loss: 2.562992231752217

Epoch: 5| Step: 10
Training loss: 2.925371984319783
Validation loss: 2.578665630475936

Epoch: 251| Step: 0
Training loss: 3.063695246169463
Validation loss: 2.6036528400779737

Epoch: 5| Step: 1
Training loss: 2.386350312959543
Validation loss: 2.614070217558892

Epoch: 5| Step: 2
Training loss: 2.7747800344630096
Validation loss: 2.627997743928719

Epoch: 5| Step: 3
Training loss: 2.417887795715442
Validation loss: 2.6246291097308414

Epoch: 5| Step: 4
Training loss: 2.3966982620908452
Validation loss: 2.6359442758658185

Epoch: 5| Step: 5
Training loss: 2.4723631095984113
Validation loss: 2.648906339450512

Epoch: 5| Step: 6
Training loss: 2.862234717990749
Validation loss: 2.651283851851408

Epoch: 5| Step: 7
Training loss: 3.011055602453142
Validation loss: 2.661303052812733

Epoch: 5| Step: 8
Training loss: 2.4883301159718028
Validation loss: 2.671535477807427

Epoch: 5| Step: 9
Training loss: 3.4132454808919896
Validation loss: 2.6656108173997652

Epoch: 5| Step: 10
Training loss: 2.418554872828417
Validation loss: 2.592559203074327

Epoch: 252| Step: 0
Training loss: 2.5758745023295893
Validation loss: 2.53947427873459

Epoch: 5| Step: 1
Training loss: 2.968541027544399
Validation loss: 2.5179373624713492

Epoch: 5| Step: 2
Training loss: 2.3272675849101843
Validation loss: 2.510009846695988

Epoch: 5| Step: 3
Training loss: 2.726415329598371
Validation loss: 2.500337449751509

Epoch: 5| Step: 4
Training loss: 2.8975652734416495
Validation loss: 2.5084890621488842

Epoch: 5| Step: 5
Training loss: 2.6879037952918146
Validation loss: 2.5139860208726894

Epoch: 5| Step: 6
Training loss: 2.436636943122699
Validation loss: 2.544746999156466

Epoch: 5| Step: 7
Training loss: 2.6122660810523404
Validation loss: 2.5316289883621343

Epoch: 5| Step: 8
Training loss: 2.869149267133002
Validation loss: 2.5102905495697163

Epoch: 5| Step: 9
Training loss: 2.6297112829319476
Validation loss: 2.5140317257126776

Epoch: 5| Step: 10
Training loss: 2.791124965055603
Validation loss: 2.512155288119891

Epoch: 253| Step: 0
Training loss: 2.519988262512483
Validation loss: 2.51280403883191

Epoch: 5| Step: 1
Training loss: 2.8259046068336824
Validation loss: 2.5284907175768603

Epoch: 5| Step: 2
Training loss: 3.046946050353476
Validation loss: 2.5244018262423515

Epoch: 5| Step: 3
Training loss: 2.3125092789747326
Validation loss: 2.5275299251704677

Epoch: 5| Step: 4
Training loss: 2.756125650174233
Validation loss: 2.5328901398948807

Epoch: 5| Step: 5
Training loss: 2.6515954918683087
Validation loss: 2.541425551972822

Epoch: 5| Step: 6
Training loss: 2.5364502600528978
Validation loss: 2.548433329504354

Epoch: 5| Step: 7
Training loss: 2.6658722667786505
Validation loss: 2.575377281881081

Epoch: 5| Step: 8
Training loss: 3.0375197547301607
Validation loss: 2.5680887029209236

Epoch: 5| Step: 9
Training loss: 2.8150052251140556
Validation loss: 2.560298344530594

Epoch: 5| Step: 10
Training loss: 2.6083709246899343
Validation loss: 2.5451984379431716

Epoch: 254| Step: 0
Training loss: 2.6706167013198754
Validation loss: 2.561211404816458

Epoch: 5| Step: 1
Training loss: 2.864078676102113
Validation loss: 2.5664667280438946

Epoch: 5| Step: 2
Training loss: 1.997136271163977
Validation loss: 2.5632869993595304

Epoch: 5| Step: 3
Training loss: 2.6681950977202344
Validation loss: 2.574679059342947

Epoch: 5| Step: 4
Training loss: 2.6447524819182595
Validation loss: 2.5731793829513214

Epoch: 5| Step: 5
Training loss: 2.7236039251448534
Validation loss: 2.577035915906017

Epoch: 5| Step: 6
Training loss: 3.0553742634329493
Validation loss: 2.5735133695046404

Epoch: 5| Step: 7
Training loss: 2.6405710971003136
Validation loss: 2.5781386369162442

Epoch: 5| Step: 8
Training loss: 2.811018490008893
Validation loss: 2.5904691395775004

Epoch: 5| Step: 9
Training loss: 2.6851098721150293
Validation loss: 2.5934356269629832

Epoch: 5| Step: 10
Training loss: 2.6728150794173895
Validation loss: 2.583942787678377

Epoch: 255| Step: 0
Training loss: 2.596196594864455
Validation loss: 2.5754008419122467

Epoch: 5| Step: 1
Training loss: 2.4876766698006514
Validation loss: 2.5797269625243593

Epoch: 5| Step: 2
Training loss: 3.1175708200445365
Validation loss: 2.6067063708604823

Epoch: 5| Step: 3
Training loss: 2.8122205807380336
Validation loss: 2.5799342474731017

Epoch: 5| Step: 4
Training loss: 3.1614572607768636
Validation loss: 2.5692624087945672

Epoch: 5| Step: 5
Training loss: 2.8062240089623214
Validation loss: 2.5574591833894877

Epoch: 5| Step: 6
Training loss: 2.1406228838165293
Validation loss: 2.5561166958761414

Epoch: 5| Step: 7
Training loss: 2.661456312762325
Validation loss: 2.547753121325751

Epoch: 5| Step: 8
Training loss: 2.7443320211000186
Validation loss: 2.545252276176807

Epoch: 5| Step: 9
Training loss: 2.2224448158785055
Validation loss: 2.530141843352098

Epoch: 5| Step: 10
Training loss: 2.356509761505986
Validation loss: 2.5334015167831683

Epoch: 256| Step: 0
Training loss: 2.540358555935048
Validation loss: 2.5315554530878264

Epoch: 5| Step: 1
Training loss: 2.708469113589819
Validation loss: 2.540871262890106

Epoch: 5| Step: 2
Training loss: 2.5578889997317575
Validation loss: 2.5606868761283716

Epoch: 5| Step: 3
Training loss: 3.0864915567687663
Validation loss: 2.5610738267599555

Epoch: 5| Step: 4
Training loss: 2.511172506637738
Validation loss: 2.6036577681578774

Epoch: 5| Step: 5
Training loss: 2.319513870641832
Validation loss: 2.6300820798654656

Epoch: 5| Step: 6
Training loss: 2.527100163650341
Validation loss: 2.5975918852148676

Epoch: 5| Step: 7
Training loss: 2.5381656882249763
Validation loss: 2.5661900271394162

Epoch: 5| Step: 8
Training loss: 2.8685578857453913
Validation loss: 2.55919742534396

Epoch: 5| Step: 9
Training loss: 2.6617552311096064
Validation loss: 2.5769813036787115

Epoch: 5| Step: 10
Training loss: 2.5396746557733993
Validation loss: 2.5967228034780234

Epoch: 257| Step: 0
Training loss: 2.2925629914759713
Validation loss: 2.6053100996154206

Epoch: 5| Step: 1
Training loss: 3.131800157409816
Validation loss: 2.611576288777158

Epoch: 5| Step: 2
Training loss: 3.018599234344541
Validation loss: 2.613828328369107

Epoch: 5| Step: 3
Training loss: 2.6576811581407167
Validation loss: 2.575345927234575

Epoch: 5| Step: 4
Training loss: 2.652245948123201
Validation loss: 2.541035378253153

Epoch: 5| Step: 5
Training loss: 2.7730475353041895
Validation loss: 2.5671373939933253

Epoch: 5| Step: 6
Training loss: 2.669074034840677
Validation loss: 2.5818648234805637

Epoch: 5| Step: 7
Training loss: 2.7351772330426387
Validation loss: 2.6254569474833773

Epoch: 5| Step: 8
Training loss: 2.146374631094683
Validation loss: 2.6100696171929147

Epoch: 5| Step: 9
Training loss: 2.6888654034835096
Validation loss: 2.5852494211188466

Epoch: 5| Step: 10
Training loss: 2.6320826936734814
Validation loss: 2.5559329279556082

Epoch: 258| Step: 0
Training loss: 3.0652189057729005
Validation loss: 2.490795988500345

Epoch: 5| Step: 1
Training loss: 3.1407189805881797
Validation loss: 2.478295071077949

Epoch: 5| Step: 2
Training loss: 2.328575756292977
Validation loss: 2.4861676876196293

Epoch: 5| Step: 3
Training loss: 2.6282267946539473
Validation loss: 2.501700732387719

Epoch: 5| Step: 4
Training loss: 2.589334797511422
Validation loss: 2.5131661911771137

Epoch: 5| Step: 5
Training loss: 2.431585521150239
Validation loss: 2.538034346717368

Epoch: 5| Step: 6
Training loss: 2.651282388866089
Validation loss: 2.521345717174281

Epoch: 5| Step: 7
Training loss: 2.7036304332098835
Validation loss: 2.46872163389978

Epoch: 5| Step: 8
Training loss: 2.8121708995279526
Validation loss: 2.455587074989299

Epoch: 5| Step: 9
Training loss: 2.6869011145150337
Validation loss: 2.4446921593231417

Epoch: 5| Step: 10
Training loss: 2.288709281255001
Validation loss: 2.4713459668066187

Epoch: 259| Step: 0
Training loss: 2.772815043485746
Validation loss: 2.48533116862586

Epoch: 5| Step: 1
Training loss: 2.752798130752696
Validation loss: 2.480366347730269

Epoch: 5| Step: 2
Training loss: 2.968750963712837
Validation loss: 2.515636745968887

Epoch: 5| Step: 3
Training loss: 2.622834720397002
Validation loss: 2.5325086090981714

Epoch: 5| Step: 4
Training loss: 2.227955807204762
Validation loss: 2.527488335005919

Epoch: 5| Step: 5
Training loss: 3.007619717847903
Validation loss: 2.5145399887063378

Epoch: 5| Step: 6
Training loss: 2.8181439883805806
Validation loss: 2.510276299992384

Epoch: 5| Step: 7
Training loss: 2.396784607377684
Validation loss: 2.502719185855538

Epoch: 5| Step: 8
Training loss: 2.679391116108709
Validation loss: 2.506407030986134

Epoch: 5| Step: 9
Training loss: 2.582276487030146
Validation loss: 2.5361515808150186

Epoch: 5| Step: 10
Training loss: 2.236057101822282
Validation loss: 2.5626188271156374

Epoch: 260| Step: 0
Training loss: 2.793292260273914
Validation loss: 2.614163551873049

Epoch: 5| Step: 1
Training loss: 2.753967717343721
Validation loss: 2.652143494121723

Epoch: 5| Step: 2
Training loss: 2.5937700385732905
Validation loss: 2.654235322885657

Epoch: 5| Step: 3
Training loss: 2.7501227611537664
Validation loss: 2.653742520322554

Epoch: 5| Step: 4
Training loss: 2.8620352955047292
Validation loss: 2.624855452589732

Epoch: 5| Step: 5
Training loss: 2.622511637964599
Validation loss: 2.6580394780605245

Epoch: 5| Step: 6
Training loss: 2.276553820172626
Validation loss: 2.6179671586823634

Epoch: 5| Step: 7
Training loss: 2.4617704404817355
Validation loss: 2.5934134753168228

Epoch: 5| Step: 8
Training loss: 2.738044935360667
Validation loss: 2.5644385635735696

Epoch: 5| Step: 9
Training loss: 2.022450563559826
Validation loss: 2.5536647662500482

Epoch: 5| Step: 10
Training loss: 3.063233890960261
Validation loss: 2.5505746292506313

Epoch: 261| Step: 0
Training loss: 2.8656705330628887
Validation loss: 2.5377703502614266

Epoch: 5| Step: 1
Training loss: 2.706775647711398
Validation loss: 2.5598802388397983

Epoch: 5| Step: 2
Training loss: 3.054888238189271
Validation loss: 2.5713155443566174

Epoch: 5| Step: 3
Training loss: 2.611093377894072
Validation loss: 2.546398476857924

Epoch: 5| Step: 4
Training loss: 2.68918875930391
Validation loss: 2.518487125416452

Epoch: 5| Step: 5
Training loss: 2.5133601827561765
Validation loss: 2.5181753124793658

Epoch: 5| Step: 6
Training loss: 2.5374333715852275
Validation loss: 2.4963073079363753

Epoch: 5| Step: 7
Training loss: 2.967396317095167
Validation loss: 2.4756299425879633

Epoch: 5| Step: 8
Training loss: 2.477755382628604
Validation loss: 2.463424004090178

Epoch: 5| Step: 9
Training loss: 2.602899889239796
Validation loss: 2.4735996323509526

Epoch: 5| Step: 10
Training loss: 2.287149196053315
Validation loss: 2.458553931751473

Epoch: 262| Step: 0
Training loss: 2.4944998318933433
Validation loss: 2.460999489644978

Epoch: 5| Step: 1
Training loss: 2.814615344230935
Validation loss: 2.4698717422725975

Epoch: 5| Step: 2
Training loss: 2.548360379734389
Validation loss: 2.4706740881884195

Epoch: 5| Step: 3
Training loss: 2.7192244718601364
Validation loss: 2.474577410731286

Epoch: 5| Step: 4
Training loss: 2.5721444787163237
Validation loss: 2.4775537445648546

Epoch: 5| Step: 5
Training loss: 2.568198961245218
Validation loss: 2.492323965910802

Epoch: 5| Step: 6
Training loss: 3.108991282954224
Validation loss: 2.518279495005267

Epoch: 5| Step: 7
Training loss: 2.41317406759342
Validation loss: 2.514544973167393

Epoch: 5| Step: 8
Training loss: 3.0690193073638636
Validation loss: 2.5442392296878693

Epoch: 5| Step: 9
Training loss: 2.4373896647203432
Validation loss: 2.5657721756153613

Epoch: 5| Step: 10
Training loss: 1.875875840667884
Validation loss: 2.5948235634607166

Epoch: 263| Step: 0
Training loss: 2.1754570930123163
Validation loss: 2.6123865404282585

Epoch: 5| Step: 1
Training loss: 2.289247681089474
Validation loss: 2.5912185187968313

Epoch: 5| Step: 2
Training loss: 2.6053741300636615
Validation loss: 2.5701904068396235

Epoch: 5| Step: 3
Training loss: 2.7313758314813237
Validation loss: 2.564456302990836

Epoch: 5| Step: 4
Training loss: 3.049989331336201
Validation loss: 2.556029242721283

Epoch: 5| Step: 5
Training loss: 2.2939675542371076
Validation loss: 2.548581148090501

Epoch: 5| Step: 6
Training loss: 2.9646602367757158
Validation loss: 2.5397737996949434

Epoch: 5| Step: 7
Training loss: 2.97730844517288
Validation loss: 2.5368799140264793

Epoch: 5| Step: 8
Training loss: 2.017135054470179
Validation loss: 2.5171650415956286

Epoch: 5| Step: 9
Training loss: 3.10253598864736
Validation loss: 2.5317258743262334

Epoch: 5| Step: 10
Training loss: 2.4091403990450186
Validation loss: 2.5244092031417713

Epoch: 264| Step: 0
Training loss: 2.69009061639456
Validation loss: 2.520163769447994

Epoch: 5| Step: 1
Training loss: 2.387203785360981
Validation loss: 2.528705798516003

Epoch: 5| Step: 2
Training loss: 2.511636166082565
Validation loss: 2.518524468367439

Epoch: 5| Step: 3
Training loss: 2.766172710430103
Validation loss: 2.5349809320631578

Epoch: 5| Step: 4
Training loss: 2.6103187727376125
Validation loss: 2.533920082010861

Epoch: 5| Step: 5
Training loss: 2.6156704733483696
Validation loss: 2.5217881995583005

Epoch: 5| Step: 6
Training loss: 2.885167429014272
Validation loss: 2.545625324820209

Epoch: 5| Step: 7
Training loss: 2.193291110218851
Validation loss: 2.530375392472897

Epoch: 5| Step: 8
Training loss: 2.568812062796916
Validation loss: 2.5467859903516294

Epoch: 5| Step: 9
Training loss: 2.6315245605169184
Validation loss: 2.5459026692834277

Epoch: 5| Step: 10
Training loss: 2.5774607409531547
Validation loss: 2.5435288310259123

Epoch: 265| Step: 0
Training loss: 2.7741270255864916
Validation loss: 2.553322970438556

Epoch: 5| Step: 1
Training loss: 2.562403514255111
Validation loss: 2.5567027157867326

Epoch: 5| Step: 2
Training loss: 2.753371339617249
Validation loss: 2.553393434059086

Epoch: 5| Step: 3
Training loss: 2.5027006820713753
Validation loss: 2.5588672227832965

Epoch: 5| Step: 4
Training loss: 2.1795345785990827
Validation loss: 2.5576068121013

Epoch: 5| Step: 5
Training loss: 2.322912127799716
Validation loss: 2.5566433564567768

Epoch: 5| Step: 6
Training loss: 2.3659589242021855
Validation loss: 2.5631400788829315

Epoch: 5| Step: 7
Training loss: 2.3925344782370894
Validation loss: 2.575105637110766

Epoch: 5| Step: 8
Training loss: 3.1419841804907453
Validation loss: 2.5884039757155057

Epoch: 5| Step: 9
Training loss: 2.721533567121709
Validation loss: 2.5864744982993324

Epoch: 5| Step: 10
Training loss: 2.2916586673481363
Validation loss: 2.594623193833065

Epoch: 266| Step: 0
Training loss: 2.735336570603329
Validation loss: 2.5809551621146016

Epoch: 5| Step: 1
Training loss: 2.490841971678403
Validation loss: 2.5782452766252204

Epoch: 5| Step: 2
Training loss: 2.571426103984315
Validation loss: 2.5837300337055655

Epoch: 5| Step: 3
Training loss: 3.0568877196451916
Validation loss: 2.5859606862364743

Epoch: 5| Step: 4
Training loss: 2.3865924808047128
Validation loss: 2.5845705642844083

Epoch: 5| Step: 5
Training loss: 2.18107456933688
Validation loss: 2.568034042177805

Epoch: 5| Step: 6
Training loss: 2.8690538698379693
Validation loss: 2.5784380561435807

Epoch: 5| Step: 7
Training loss: 2.3547900789492826
Validation loss: 2.594075721781059

Epoch: 5| Step: 8
Training loss: 2.731543857295693
Validation loss: 2.5909094954327436

Epoch: 5| Step: 9
Training loss: 2.219368324624252
Validation loss: 2.602506628421002

Epoch: 5| Step: 10
Training loss: 2.575894772518737
Validation loss: 2.588640577357335

Epoch: 267| Step: 0
Training loss: 2.4403163582879643
Validation loss: 2.571123610773706

Epoch: 5| Step: 1
Training loss: 2.453562703536542
Validation loss: 2.5392337137431094

Epoch: 5| Step: 2
Training loss: 2.4267610546067377
Validation loss: 2.506819810101209

Epoch: 5| Step: 3
Training loss: 2.6068607483764414
Validation loss: 2.5023365750768822

Epoch: 5| Step: 4
Training loss: 3.087904059654124
Validation loss: 2.5058817481656046

Epoch: 5| Step: 5
Training loss: 2.3334762211600184
Validation loss: 2.499894114272115

Epoch: 5| Step: 6
Training loss: 2.3386470938000885
Validation loss: 2.5040840711743955

Epoch: 5| Step: 7
Training loss: 2.682856873649074
Validation loss: 2.484648697901201

Epoch: 5| Step: 8
Training loss: 2.942260131911842
Validation loss: 2.483705295830291

Epoch: 5| Step: 9
Training loss: 2.176080378408265
Validation loss: 2.464603544783457

Epoch: 5| Step: 10
Training loss: 2.6120420063607637
Validation loss: 2.474372675879781

Epoch: 268| Step: 0
Training loss: 2.4011437869473173
Validation loss: 2.4975754825303818

Epoch: 5| Step: 1
Training loss: 2.9050812370772965
Validation loss: 2.5011737898180515

Epoch: 5| Step: 2
Training loss: 2.0868783036463188
Validation loss: 2.496599007757952

Epoch: 5| Step: 3
Training loss: 2.572065874249863
Validation loss: 2.5083821887550384

Epoch: 5| Step: 4
Training loss: 2.591962175193353
Validation loss: 2.5082359448434377

Epoch: 5| Step: 5
Training loss: 2.4095933154754325
Validation loss: 2.522592575620282

Epoch: 5| Step: 6
Training loss: 2.726390844149954
Validation loss: 2.530296745763964

Epoch: 5| Step: 7
Training loss: 2.9372360435554925
Validation loss: 2.5577966989895664

Epoch: 5| Step: 8
Training loss: 2.5831470012120112
Validation loss: 2.5689853863061995

Epoch: 5| Step: 9
Training loss: 2.2884776960023223
Validation loss: 2.573292655984626

Epoch: 5| Step: 10
Training loss: 2.3265871434799203
Validation loss: 2.574981516194193

Epoch: 269| Step: 0
Training loss: 2.5886457845726674
Validation loss: 2.56322705739019

Epoch: 5| Step: 1
Training loss: 2.3015058895071365
Validation loss: 2.588496102169965

Epoch: 5| Step: 2
Training loss: 2.8210254729593798
Validation loss: 2.5791413388065654

Epoch: 5| Step: 3
Training loss: 2.4474567603557444
Validation loss: 2.5803147051846973

Epoch: 5| Step: 4
Training loss: 2.472858342353572
Validation loss: 2.565311209442905

Epoch: 5| Step: 5
Training loss: 2.4262452104178256
Validation loss: 2.595487804885348

Epoch: 5| Step: 6
Training loss: 2.097100949798612
Validation loss: 2.5867296073977757

Epoch: 5| Step: 7
Training loss: 2.8611011402075723
Validation loss: 2.593326995195062

Epoch: 5| Step: 8
Training loss: 2.522490899605493
Validation loss: 2.589119662679651

Epoch: 5| Step: 9
Training loss: 2.4345699207781473
Validation loss: 2.563596710374032

Epoch: 5| Step: 10
Training loss: 2.81900399833577
Validation loss: 2.550563038148514

Epoch: 270| Step: 0
Training loss: 2.620387247892658
Validation loss: 2.5366386886312235

Epoch: 5| Step: 1
Training loss: 3.111800431528214
Validation loss: 2.553322826860706

Epoch: 5| Step: 2
Training loss: 2.4486270171473654
Validation loss: 2.54879138344696

Epoch: 5| Step: 3
Training loss: 2.215618879258669
Validation loss: 2.5604269174306045

Epoch: 5| Step: 4
Training loss: 2.0976256753692986
Validation loss: 2.5393848895420374

Epoch: 5| Step: 5
Training loss: 2.45222271890678
Validation loss: 2.5627277011984892

Epoch: 5| Step: 6
Training loss: 2.0445144670123403
Validation loss: 2.5587693376557494

Epoch: 5| Step: 7
Training loss: 2.3623990516691697
Validation loss: 2.5727525067246733

Epoch: 5| Step: 8
Training loss: 2.8159427340764407
Validation loss: 2.5899117738222293

Epoch: 5| Step: 9
Training loss: 2.9135267158882097
Validation loss: 2.601143864357759

Epoch: 5| Step: 10
Training loss: 2.2136140938671724
Validation loss: 2.5998647704938787

Epoch: 271| Step: 0
Training loss: 2.325855147085082
Validation loss: 2.6001114959017246

Epoch: 5| Step: 1
Training loss: 3.001539788862706
Validation loss: 2.6264265816109402

Epoch: 5| Step: 2
Training loss: 2.7070504500243526
Validation loss: 2.6054920497378338

Epoch: 5| Step: 3
Training loss: 2.3605139806293423
Validation loss: 2.597769553135825

Epoch: 5| Step: 4
Training loss: 2.4695268205544445
Validation loss: 2.5616018270399965

Epoch: 5| Step: 5
Training loss: 2.1729757689219125
Validation loss: 2.5560096429550847

Epoch: 5| Step: 6
Training loss: 2.503430968597391
Validation loss: 2.5176761453175316

Epoch: 5| Step: 7
Training loss: 2.5113728286530996
Validation loss: 2.523802976366499

Epoch: 5| Step: 8
Training loss: 2.570687959374427
Validation loss: 2.531760586219578

Epoch: 5| Step: 9
Training loss: 2.2630674462004543
Validation loss: 2.5565676988381663

Epoch: 5| Step: 10
Training loss: 2.8293181373674687
Validation loss: 2.5583367441655738

Epoch: 272| Step: 0
Training loss: 2.41758051946253
Validation loss: 2.5294757642448

Epoch: 5| Step: 1
Training loss: 2.689677044225549
Validation loss: 2.49853931331834

Epoch: 5| Step: 2
Training loss: 2.5429966891346334
Validation loss: 2.485950159205245

Epoch: 5| Step: 3
Training loss: 3.0931454462781174
Validation loss: 2.4806433506006154

Epoch: 5| Step: 4
Training loss: 2.2024484231302837
Validation loss: 2.5021341064719147

Epoch: 5| Step: 5
Training loss: 2.104308762489337
Validation loss: 2.4953183705188944

Epoch: 5| Step: 6
Training loss: 2.851883041969078
Validation loss: 2.53057375875615

Epoch: 5| Step: 7
Training loss: 2.1339744225482384
Validation loss: 2.530409565669091

Epoch: 5| Step: 8
Training loss: 2.423371867626029
Validation loss: 2.5364356359051774

Epoch: 5| Step: 9
Training loss: 2.5723358816691415
Validation loss: 2.54754247021432

Epoch: 5| Step: 10
Training loss: 2.529979810973421
Validation loss: 2.527846375062408

Epoch: 273| Step: 0
Training loss: 1.8220765566690762
Validation loss: 2.5428926492328654

Epoch: 5| Step: 1
Training loss: 2.8034313225903995
Validation loss: 2.558145953340779

Epoch: 5| Step: 2
Training loss: 2.698909493380742
Validation loss: 2.5720254956335764

Epoch: 5| Step: 3
Training loss: 2.2674480601358478
Validation loss: 2.580349218475899

Epoch: 5| Step: 4
Training loss: 2.180465067331067
Validation loss: 2.591828745768053

Epoch: 5| Step: 5
Training loss: 2.4386584145747174
Validation loss: 2.57914769089168

Epoch: 5| Step: 6
Training loss: 2.1702862973481807
Validation loss: 2.572220905063562

Epoch: 5| Step: 7
Training loss: 2.927803267774746
Validation loss: 2.5588380873685734

Epoch: 5| Step: 8
Training loss: 2.514981300026631
Validation loss: 2.5655508640723523

Epoch: 5| Step: 9
Training loss: 2.5550480859341076
Validation loss: 2.5977657981223534

Epoch: 5| Step: 10
Training loss: 3.016626221471729
Validation loss: 2.572888522180816

Epoch: 274| Step: 0
Training loss: 2.289061145977362
Validation loss: 2.574922637980011

Epoch: 5| Step: 1
Training loss: 2.693761141371201
Validation loss: 2.5771495048757833

Epoch: 5| Step: 2
Training loss: 2.3003304368532316
Validation loss: 2.5592617119571814

Epoch: 5| Step: 3
Training loss: 1.878929280796187
Validation loss: 2.5653036023886893

Epoch: 5| Step: 4
Training loss: 2.661234946434552
Validation loss: 2.566233568470336

Epoch: 5| Step: 5
Training loss: 2.4168899915263284
Validation loss: 2.546628535328882

Epoch: 5| Step: 6
Training loss: 2.170026692520726
Validation loss: 2.560317882428254

Epoch: 5| Step: 7
Training loss: 2.5743088655805257
Validation loss: 2.5578954642269744

Epoch: 5| Step: 8
Training loss: 2.8330490493271654
Validation loss: 2.566258049592601

Epoch: 5| Step: 9
Training loss: 2.3290363550554907
Validation loss: 2.552015133302861

Epoch: 5| Step: 10
Training loss: 2.9374496780305726
Validation loss: 2.5408119847164623

Epoch: 275| Step: 0
Training loss: 2.528732366420267
Validation loss: 2.542248649342503

Epoch: 5| Step: 1
Training loss: 1.948948782226821
Validation loss: 2.5477111800623025

Epoch: 5| Step: 2
Training loss: 2.443577354947417
Validation loss: 2.5341658666355826

Epoch: 5| Step: 3
Training loss: 2.7356007471680686
Validation loss: 2.5425544871255763

Epoch: 5| Step: 4
Training loss: 2.451837675698796
Validation loss: 2.53435096203824

Epoch: 5| Step: 5
Training loss: 2.2902375938396813
Validation loss: 2.538511459846346

Epoch: 5| Step: 6
Training loss: 2.174682778212043
Validation loss: 2.5470846122478314

Epoch: 5| Step: 7
Training loss: 2.8346070250370086
Validation loss: 2.535302591814161

Epoch: 5| Step: 8
Training loss: 2.2217879652529233
Validation loss: 2.5667205816337377

Epoch: 5| Step: 9
Training loss: 2.1132499988663764
Validation loss: 2.58179671474138

Epoch: 5| Step: 10
Training loss: 3.148855479776665
Validation loss: 2.5916667745802733

Epoch: 276| Step: 0
Training loss: 2.6664407356238464
Validation loss: 2.600883770055966

Epoch: 5| Step: 1
Training loss: 2.1389324987460205
Validation loss: 2.633161009857268

Epoch: 5| Step: 2
Training loss: 2.8817652839420145
Validation loss: 2.6557024937394202

Epoch: 5| Step: 3
Training loss: 2.3290739237746894
Validation loss: 2.6665194288747025

Epoch: 5| Step: 4
Training loss: 2.2164408528124797
Validation loss: 2.661599271198959

Epoch: 5| Step: 5
Training loss: 2.7494955467164472
Validation loss: 2.6671463402929407

Epoch: 5| Step: 6
Training loss: 2.2448081409059304
Validation loss: 2.6491312414318475

Epoch: 5| Step: 7
Training loss: 2.6019825639191847
Validation loss: 2.6158066950694847

Epoch: 5| Step: 8
Training loss: 2.4923316650786393
Validation loss: 2.59532807220969

Epoch: 5| Step: 9
Training loss: 2.258950761613895
Validation loss: 2.5934848365697296

Epoch: 5| Step: 10
Training loss: 2.246677276442895
Validation loss: 2.6125710867612986

Epoch: 277| Step: 0
Training loss: 2.19874830617834
Validation loss: 2.6175263970438682

Epoch: 5| Step: 1
Training loss: 2.6117276304814623
Validation loss: 2.5754523491154706

Epoch: 5| Step: 2
Training loss: 2.5063375253210647
Validation loss: 2.567541843927285

Epoch: 5| Step: 3
Training loss: 1.8932993865775603
Validation loss: 2.5540727744606957

Epoch: 5| Step: 4
Training loss: 2.3770564361664226
Validation loss: 2.530787211064431

Epoch: 5| Step: 5
Training loss: 2.5969449324206217
Validation loss: 2.5190518344646278

Epoch: 5| Step: 6
Training loss: 2.5066452399650228
Validation loss: 2.525190224148104

Epoch: 5| Step: 7
Training loss: 2.0084298813697496
Validation loss: 2.5724698109153246

Epoch: 5| Step: 8
Training loss: 2.570535389242368
Validation loss: 2.593631424894895

Epoch: 5| Step: 9
Training loss: 2.8710781382441195
Validation loss: 2.6304699998588

Epoch: 5| Step: 10
Training loss: 2.854977921702836
Validation loss: 2.6611148601437096

Epoch: 278| Step: 0
Training loss: 2.6753349878778323
Validation loss: 2.671124388199298

Epoch: 5| Step: 1
Training loss: 2.7673593890989
Validation loss: 2.6620369151395136

Epoch: 5| Step: 2
Training loss: 2.423752678274059
Validation loss: 2.6453403013212564

Epoch: 5| Step: 3
Training loss: 2.760805834322269
Validation loss: 2.6023007651392565

Epoch: 5| Step: 4
Training loss: 2.2201333904572804
Validation loss: 2.5840990355484585

Epoch: 5| Step: 5
Training loss: 2.527382521648847
Validation loss: 2.554081732879099

Epoch: 5| Step: 6
Training loss: 2.318120775422057
Validation loss: 2.530167780133785

Epoch: 5| Step: 7
Training loss: 2.2644326064815608
Validation loss: 2.5140532093517196

Epoch: 5| Step: 8
Training loss: 2.5028571015250347
Validation loss: 2.517159996122556

Epoch: 5| Step: 9
Training loss: 1.580443614659904
Validation loss: 2.5078286220372346

Epoch: 5| Step: 10
Training loss: 2.747582847172255
Validation loss: 2.5137955648964625

Epoch: 279| Step: 0
Training loss: 2.4319289683772976
Validation loss: 2.5262206710721435

Epoch: 5| Step: 1
Training loss: 2.144260187858475
Validation loss: 2.5309856787744316

Epoch: 5| Step: 2
Training loss: 3.2347644810973404
Validation loss: 2.538284038542586

Epoch: 5| Step: 3
Training loss: 2.6059110572023205
Validation loss: 2.553003803045057

Epoch: 5| Step: 4
Training loss: 2.7566512907799456
Validation loss: 2.5517377986549845

Epoch: 5| Step: 5
Training loss: 2.7097321834758046
Validation loss: 2.564517423815564

Epoch: 5| Step: 6
Training loss: 2.5239290402347647
Validation loss: 2.558842281221619

Epoch: 5| Step: 7
Training loss: 2.529244841404928
Validation loss: 2.556441395262569

Epoch: 5| Step: 8
Training loss: 1.9640435168578751
Validation loss: 2.5481768316485236

Epoch: 5| Step: 9
Training loss: 1.625948335786338
Validation loss: 2.559748422099643

Epoch: 5| Step: 10
Training loss: 1.546250727906977
Validation loss: 2.5772539215353287

Epoch: 280| Step: 0
Training loss: 2.0426753400530493
Validation loss: 2.594875036845742

Epoch: 5| Step: 1
Training loss: 2.688961873452032
Validation loss: 2.610123380937342

Epoch: 5| Step: 2
Training loss: 2.0343047427279424
Validation loss: 2.6016064091119557

Epoch: 5| Step: 3
Training loss: 2.0921271568296795
Validation loss: 2.57945086411848

Epoch: 5| Step: 4
Training loss: 2.2009813417495696
Validation loss: 2.583266326506329

Epoch: 5| Step: 5
Training loss: 2.423338810714695
Validation loss: 2.5809788475366386

Epoch: 5| Step: 6
Training loss: 2.4777885795532675
Validation loss: 2.5893788357585783

Epoch: 5| Step: 7
Training loss: 2.5747844902148658
Validation loss: 2.588351228679846

Epoch: 5| Step: 8
Training loss: 2.5114165935636805
Validation loss: 2.6171114121214334

Epoch: 5| Step: 9
Training loss: 2.675947599043361
Validation loss: 2.6373316224455547

Epoch: 5| Step: 10
Training loss: 2.7667188474797646
Validation loss: 2.589271132802285

Epoch: 281| Step: 0
Training loss: 2.059433014997506
Validation loss: 2.572416005655948

Epoch: 5| Step: 1
Training loss: 2.5233444338427957
Validation loss: 2.5719863493697837

Epoch: 5| Step: 2
Training loss: 2.5233993291182304
Validation loss: 2.5712081924939953

Epoch: 5| Step: 3
Training loss: 2.472577761207377
Validation loss: 2.5697228746919794

Epoch: 5| Step: 4
Training loss: 2.4439390182566494
Validation loss: 2.5721955109296233

Epoch: 5| Step: 5
Training loss: 2.754547693747804
Validation loss: 2.5736101350285736

Epoch: 5| Step: 6
Training loss: 2.5246417594059127
Validation loss: 2.5861168805895827

Epoch: 5| Step: 7
Training loss: 2.137359578835129
Validation loss: 2.58497948518266

Epoch: 5| Step: 8
Training loss: 2.2529638690447182
Validation loss: 2.5821507340807663

Epoch: 5| Step: 9
Training loss: 2.170777297318738
Validation loss: 2.5303887538119056

Epoch: 5| Step: 10
Training loss: 2.1265399065576287
Validation loss: 2.5020662567320153

Epoch: 282| Step: 0
Training loss: 2.488985019011911
Validation loss: 2.517508913500083

Epoch: 5| Step: 1
Training loss: 2.411020875034282
Validation loss: 2.5057805312478187

Epoch: 5| Step: 2
Training loss: 2.6753445234098745
Validation loss: 2.5094650640814105

Epoch: 5| Step: 3
Training loss: 2.8972695354606546
Validation loss: 2.518288592968785

Epoch: 5| Step: 4
Training loss: 2.2073870616807745
Validation loss: 2.535628372235395

Epoch: 5| Step: 5
Training loss: 2.228519583455347
Validation loss: 2.5485603468140385

Epoch: 5| Step: 6
Training loss: 2.669018919928085
Validation loss: 2.562319717448252

Epoch: 5| Step: 7
Training loss: 1.4528110944446142
Validation loss: 2.5453909380138597

Epoch: 5| Step: 8
Training loss: 2.1950950650633625
Validation loss: 2.5720693707564366

Epoch: 5| Step: 9
Training loss: 2.417263834166582
Validation loss: 2.5578164118501467

Epoch: 5| Step: 10
Training loss: 2.455366920352641
Validation loss: 2.583855157150146

Epoch: 283| Step: 0
Training loss: 1.877627248705932
Validation loss: 2.6042716650355886

Epoch: 5| Step: 1
Training loss: 2.2871039542794427
Validation loss: 2.609735014206257

Epoch: 5| Step: 2
Training loss: 2.490080609529653
Validation loss: 2.6368558482658067

Epoch: 5| Step: 3
Training loss: 2.961850792938244
Validation loss: 2.681261741367131

Epoch: 5| Step: 4
Training loss: 2.3115899640894053
Validation loss: 2.6564296075369844

Epoch: 5| Step: 5
Training loss: 2.4527247399998884
Validation loss: 2.619117737389335

Epoch: 5| Step: 6
Training loss: 2.2154228085909913
Validation loss: 2.599719329937293

Epoch: 5| Step: 7
Training loss: 1.9960763710295615
Validation loss: 2.5838671540257043

Epoch: 5| Step: 8
Training loss: 2.758999922804574
Validation loss: 2.581308786885353

Epoch: 5| Step: 9
Training loss: 2.1152361784387512
Validation loss: 2.5709448752516866

Epoch: 5| Step: 10
Training loss: 2.2246805368885973
Validation loss: 2.5600382787844644

Epoch: 284| Step: 0
Training loss: 2.352076882915814
Validation loss: 2.5552729397152842

Epoch: 5| Step: 1
Training loss: 2.236227161510475
Validation loss: 2.5567684789164415

Epoch: 5| Step: 2
Training loss: 2.3453479659965177
Validation loss: 2.545613483581671

Epoch: 5| Step: 3
Training loss: 2.3209098278248645
Validation loss: 2.5484295400226586

Epoch: 5| Step: 4
Training loss: 1.833314360896112
Validation loss: 2.5634061260244385

Epoch: 5| Step: 5
Training loss: 1.9151934960717756
Validation loss: 2.5913534823986

Epoch: 5| Step: 6
Training loss: 2.1859505751834316
Validation loss: 2.59066092140685

Epoch: 5| Step: 7
Training loss: 2.502294822307432
Validation loss: 2.578973163638615

Epoch: 5| Step: 8
Training loss: 2.9641356898045745
Validation loss: 2.5717329557482693

Epoch: 5| Step: 9
Training loss: 2.4530357781968384
Validation loss: 2.561263605749072

Epoch: 5| Step: 10
Training loss: 2.4052786910278092
Validation loss: 2.5628986943880547

Epoch: 285| Step: 0
Training loss: 2.224573900376997
Validation loss: 2.557611823892228

Epoch: 5| Step: 1
Training loss: 2.096673774444387
Validation loss: 2.557167186697759

Epoch: 5| Step: 2
Training loss: 2.604613293813275
Validation loss: 2.5415762786554885

Epoch: 5| Step: 3
Training loss: 2.4365024970918787
Validation loss: 2.5584612457224725

Epoch: 5| Step: 4
Training loss: 1.9922706137878514
Validation loss: 2.555819902648124

Epoch: 5| Step: 5
Training loss: 2.528421022038272
Validation loss: 2.590926538097166

Epoch: 5| Step: 6
Training loss: 2.09370513412459
Validation loss: 2.5594453014705265

Epoch: 5| Step: 7
Training loss: 2.057853551178544
Validation loss: 2.5671025782449544

Epoch: 5| Step: 8
Training loss: 2.906046706441927
Validation loss: 2.5689634589272474

Epoch: 5| Step: 9
Training loss: 2.094188131922432
Validation loss: 2.573636167660559

Epoch: 5| Step: 10
Training loss: 2.131472771152336
Validation loss: 2.585703755301993

Epoch: 286| Step: 0
Training loss: 2.484484496192824
Validation loss: 2.587900616469224

Epoch: 5| Step: 1
Training loss: 1.7881706713564263
Validation loss: 2.569208599228128

Epoch: 5| Step: 2
Training loss: 2.5503582684028325
Validation loss: 2.5750824228235816

Epoch: 5| Step: 3
Training loss: 2.637565872309908
Validation loss: 2.5607805403347688

Epoch: 5| Step: 4
Training loss: 2.6046368187251168
Validation loss: 2.5680050347248518

Epoch: 5| Step: 5
Training loss: 1.9718154777333399
Validation loss: 2.558855154283749

Epoch: 5| Step: 6
Training loss: 1.9198967281025767
Validation loss: 2.545426964219194

Epoch: 5| Step: 7
Training loss: 2.061937891338344
Validation loss: 2.5288593057697994

Epoch: 5| Step: 8
Training loss: 2.639363997895139
Validation loss: 2.5354468958650327

Epoch: 5| Step: 9
Training loss: 2.4584873172788977
Validation loss: 2.528203248995603

Epoch: 5| Step: 10
Training loss: 2.4079612492900035
Validation loss: 2.553212777586608

Epoch: 287| Step: 0
Training loss: 2.467558947692913
Validation loss: 2.594413331508175

Epoch: 5| Step: 1
Training loss: 2.3997792023182365
Validation loss: 2.6408435303693523

Epoch: 5| Step: 2
Training loss: 2.2125352673494576
Validation loss: 2.71040181255871

Epoch: 5| Step: 3
Training loss: 2.397372727024117
Validation loss: 2.7895615203859148

Epoch: 5| Step: 4
Training loss: 2.4986156445440257
Validation loss: 2.818496919168177

Epoch: 5| Step: 5
Training loss: 2.5016519810471927
Validation loss: 2.761751828032775

Epoch: 5| Step: 6
Training loss: 2.7122359890058596
Validation loss: 2.665312294911242

Epoch: 5| Step: 7
Training loss: 2.2579555796130304
Validation loss: 2.604443218354469

Epoch: 5| Step: 8
Training loss: 2.3874596477513736
Validation loss: 2.5832471452745476

Epoch: 5| Step: 9
Training loss: 2.481695397515784
Validation loss: 2.58303661474988

Epoch: 5| Step: 10
Training loss: 1.8772312240118827
Validation loss: 2.5270829999526643

Epoch: 288| Step: 0
Training loss: 2.9419577032247552
Validation loss: 2.499867730076898

Epoch: 5| Step: 1
Training loss: 2.433605506341989
Validation loss: 2.484076648870566

Epoch: 5| Step: 2
Training loss: 2.541666802161375
Validation loss: 2.4650078289803985

Epoch: 5| Step: 3
Training loss: 2.460953000943245
Validation loss: 2.4925640684630763

Epoch: 5| Step: 4
Training loss: 2.065187264141952
Validation loss: 2.5445183186168143

Epoch: 5| Step: 5
Training loss: 1.9837268762136162
Validation loss: 2.6527076007798205

Epoch: 5| Step: 6
Training loss: 3.002985740076456
Validation loss: 2.7479296056644062

Epoch: 5| Step: 7
Training loss: 1.8289435094845385
Validation loss: 2.6986725268179743

Epoch: 5| Step: 8
Training loss: 2.454131096245886
Validation loss: 2.6305594962903904

Epoch: 5| Step: 9
Training loss: 2.7708437544165423
Validation loss: 2.5967541863102497

Epoch: 5| Step: 10
Training loss: 1.748798911860582
Validation loss: 2.562746995996922

Epoch: 289| Step: 0
Training loss: 2.452778202497024
Validation loss: 2.552558308932382

Epoch: 5| Step: 1
Training loss: 2.2030118006850348
Validation loss: 2.581102254947113

Epoch: 5| Step: 2
Training loss: 2.4870661908380853
Validation loss: 2.608152420824042

Epoch: 5| Step: 3
Training loss: 2.6622466669762996
Validation loss: 2.6057022299319184

Epoch: 5| Step: 4
Training loss: 2.3474620668964126
Validation loss: 2.598415624783845

Epoch: 5| Step: 5
Training loss: 2.5349826371239743
Validation loss: 2.6178905450690424

Epoch: 5| Step: 6
Training loss: 2.246981609505202
Validation loss: 2.6614405636221994

Epoch: 5| Step: 7
Training loss: 1.8367836808086135
Validation loss: 2.651717821011179

Epoch: 5| Step: 8
Training loss: 2.485259372522747
Validation loss: 2.651743229929067

Epoch: 5| Step: 9
Training loss: 2.382770575482869
Validation loss: 2.652047363957066

Epoch: 5| Step: 10
Training loss: 1.994886955462046
Validation loss: 2.6188586205740285

Epoch: 290| Step: 0
Training loss: 2.067173489085585
Validation loss: 2.5987496638847167

Epoch: 5| Step: 1
Training loss: 2.169888253213309
Validation loss: 2.5577322422471562

Epoch: 5| Step: 2
Training loss: 2.6646512183717532
Validation loss: 2.522918992302152

Epoch: 5| Step: 3
Training loss: 1.7621703658037906
Validation loss: 2.4950689815519165

Epoch: 5| Step: 4
Training loss: 2.478909027646273
Validation loss: 2.4622451154765224

Epoch: 5| Step: 5
Training loss: 2.8004412371520493
Validation loss: 2.4852784693209586

Epoch: 5| Step: 6
Training loss: 2.0455443738228514
Validation loss: 2.50478020675586

Epoch: 5| Step: 7
Training loss: 2.258448738818657
Validation loss: 2.5342202523437627

Epoch: 5| Step: 8
Training loss: 2.0333309371600596
Validation loss: 2.559545703309577

Epoch: 5| Step: 9
Training loss: 2.4436044791131395
Validation loss: 2.5832513193481823

Epoch: 5| Step: 10
Training loss: 2.5160743833259778
Validation loss: 2.594976112388079

Epoch: 291| Step: 0
Training loss: 2.1498042527624026
Validation loss: 2.619505715203748

Epoch: 5| Step: 1
Training loss: 1.6074144588035175
Validation loss: 2.6692509217598843

Epoch: 5| Step: 2
Training loss: 2.718394990740601
Validation loss: 2.696202203314592

Epoch: 5| Step: 3
Training loss: 2.0557429282674384
Validation loss: 2.6820878375644392

Epoch: 5| Step: 4
Training loss: 1.9164260284734378
Validation loss: 2.6878039871841133

Epoch: 5| Step: 5
Training loss: 2.4497694646624764
Validation loss: 2.6319479825457313

Epoch: 5| Step: 6
Training loss: 2.603080421240066
Validation loss: 2.5963311900913717

Epoch: 5| Step: 7
Training loss: 2.335298891072518
Validation loss: 2.578902908853224

Epoch: 5| Step: 8
Training loss: 2.307435340512703
Validation loss: 2.564556689085788

Epoch: 5| Step: 9
Training loss: 2.484943444819257
Validation loss: 2.539878739509867

Epoch: 5| Step: 10
Training loss: 1.8673721286039942
Validation loss: 2.533198876555686

Epoch: 292| Step: 0
Training loss: 2.543412739658629
Validation loss: 2.5428170623811157

Epoch: 5| Step: 1
Training loss: 2.2220234967490735
Validation loss: 2.541101707260319

Epoch: 5| Step: 2
Training loss: 2.313975919949356
Validation loss: 2.557789141751356

Epoch: 5| Step: 3
Training loss: 2.2168616197180655
Validation loss: 2.5739957185724247

Epoch: 5| Step: 4
Training loss: 1.8405420229590517
Validation loss: 2.536769277755612

Epoch: 5| Step: 5
Training loss: 1.9951012937983548
Validation loss: 2.519065174449146

Epoch: 5| Step: 6
Training loss: 2.281897883973089
Validation loss: 2.554235915133389

Epoch: 5| Step: 7
Training loss: 2.3958510577886885
Validation loss: 2.5632076911927992

Epoch: 5| Step: 8
Training loss: 2.1908463087407455
Validation loss: 2.599429053627718

Epoch: 5| Step: 9
Training loss: 2.7122708869894248
Validation loss: 2.6590024600977102

Epoch: 5| Step: 10
Training loss: 2.4061003799490814
Validation loss: 2.7258059197711906

Epoch: 293| Step: 0
Training loss: 2.3651140152463572
Validation loss: 2.730994912166367

Epoch: 5| Step: 1
Training loss: 2.395802096840501
Validation loss: 2.669237269388869

Epoch: 5| Step: 2
Training loss: 1.966251604548804
Validation loss: 2.5784117210155677

Epoch: 5| Step: 3
Training loss: 2.8873270552725554
Validation loss: 2.5716470275468857

Epoch: 5| Step: 4
Training loss: 2.743868581516443
Validation loss: 2.576443439193564

Epoch: 5| Step: 5
Training loss: 2.0396081187138826
Validation loss: 2.5773091098835446

Epoch: 5| Step: 6
Training loss: 2.247668011488388
Validation loss: 2.5630686479407356

Epoch: 5| Step: 7
Training loss: 2.1972312280293784
Validation loss: 2.558964785585514

Epoch: 5| Step: 8
Training loss: 2.1216479397666714
Validation loss: 2.5325515977784323

Epoch: 5| Step: 9
Training loss: 2.311742091343065
Validation loss: 2.509287846443393

Epoch: 5| Step: 10
Training loss: 1.788843133129299
Validation loss: 2.509358782915

Epoch: 294| Step: 0
Training loss: 2.3744381691808054
Validation loss: 2.526224453275973

Epoch: 5| Step: 1
Training loss: 2.0033769707944074
Validation loss: 2.5374305022513552

Epoch: 5| Step: 2
Training loss: 2.3439396082158113
Validation loss: 2.5449247651008235

Epoch: 5| Step: 3
Training loss: 2.0457564930622243
Validation loss: 2.543157674428583

Epoch: 5| Step: 4
Training loss: 2.246150007787305
Validation loss: 2.5244760299220332

Epoch: 5| Step: 5
Training loss: 2.3942215736361057
Validation loss: 2.5229451313697497

Epoch: 5| Step: 6
Training loss: 2.0993370553778448
Validation loss: 2.5270729719330216

Epoch: 5| Step: 7
Training loss: 2.382152928853757
Validation loss: 2.5434347905519767

Epoch: 5| Step: 8
Training loss: 2.0371949277561874
Validation loss: 2.5101154721815693

Epoch: 5| Step: 9
Training loss: 2.0265639023492885
Validation loss: 2.509017015643627

Epoch: 5| Step: 10
Training loss: 2.2900517640239446
Validation loss: 2.5358177808592863

Epoch: 295| Step: 0
Training loss: 1.9433282744252929
Validation loss: 2.555306581300328

Epoch: 5| Step: 1
Training loss: 1.8791439040920674
Validation loss: 2.5833300220998874

Epoch: 5| Step: 2
Training loss: 2.2172743497348693
Validation loss: 2.6005991914594304

Epoch: 5| Step: 3
Training loss: 2.270919401538437
Validation loss: 2.584507452759089

Epoch: 5| Step: 4
Training loss: 2.377341270884244
Validation loss: 2.579011072633601

Epoch: 5| Step: 5
Training loss: 2.512839913979515
Validation loss: 2.5820956849575674

Epoch: 5| Step: 6
Training loss: 2.153612043553101
Validation loss: 2.593976873385959

Epoch: 5| Step: 7
Training loss: 2.4000586582009147
Validation loss: 2.5613483829534776

Epoch: 5| Step: 8
Training loss: 2.394209524324972
Validation loss: 2.519970517294493

Epoch: 5| Step: 9
Training loss: 1.9304352828814109
Validation loss: 2.5076384140373773

Epoch: 5| Step: 10
Training loss: 1.4760192194568655
Validation loss: 2.5152702552746327

Epoch: 296| Step: 0
Training loss: 2.4991672082459244
Validation loss: 2.512014276825566

Epoch: 5| Step: 1
Training loss: 1.9861714199071492
Validation loss: 2.5157090671550577

Epoch: 5| Step: 2
Training loss: 2.060236526909948
Validation loss: 2.5119820501450913

Epoch: 5| Step: 3
Training loss: 2.2327354124201553
Validation loss: 2.510704960074844

Epoch: 5| Step: 4
Training loss: 2.402226341293823
Validation loss: 2.5109075737639728

Epoch: 5| Step: 5
Training loss: 2.06586690112447
Validation loss: 2.5055761099089158

Epoch: 5| Step: 6
Training loss: 2.6147710319918365
Validation loss: 2.5168658827658588

Epoch: 5| Step: 7
Training loss: 1.8156915386567742
Validation loss: 2.5280220092999426

Epoch: 5| Step: 8
Training loss: 1.5807931835738027
Validation loss: 2.5517758691313523

Epoch: 5| Step: 9
Training loss: 2.302847952464337
Validation loss: 2.5860819372110453

Epoch: 5| Step: 10
Training loss: 1.833733197156689
Validation loss: 2.602902367290064

Epoch: 297| Step: 0
Training loss: 1.6777759409186361
Validation loss: 2.6067431699213452

Epoch: 5| Step: 1
Training loss: 1.6025056620481446
Validation loss: 2.6099111070017655

Epoch: 5| Step: 2
Training loss: 2.0952065938175086
Validation loss: 2.6139295684212223

Epoch: 5| Step: 3
Training loss: 2.225634786514152
Validation loss: 2.6037233643946154

Epoch: 5| Step: 4
Training loss: 2.0396683183939635
Validation loss: 2.600147956940471

Epoch: 5| Step: 5
Training loss: 1.9579673249203964
Validation loss: 2.5904217184016067

Epoch: 5| Step: 6
Training loss: 2.339636384312126
Validation loss: 2.581870921126889

Epoch: 5| Step: 7
Training loss: 2.0212531948123327
Validation loss: 2.5751320896742937

Epoch: 5| Step: 8
Training loss: 2.244312621747363
Validation loss: 2.57851364870627

Epoch: 5| Step: 9
Training loss: 2.706113012780407
Validation loss: 2.571882524261176

Epoch: 5| Step: 10
Training loss: 2.3420017079673685
Validation loss: 2.584805604607088

Epoch: 298| Step: 0
Training loss: 2.3029748792648927
Validation loss: 2.635718183492461

Epoch: 5| Step: 1
Training loss: 1.9864137644202915
Validation loss: 2.6513614014880234

Epoch: 5| Step: 2
Training loss: 2.1455271480836737
Validation loss: 2.6066562518037193

Epoch: 5| Step: 3
Training loss: 2.2663795004117193
Validation loss: 2.5737102158801117

Epoch: 5| Step: 4
Training loss: 1.3023560759676764
Validation loss: 2.5743219789774296

Epoch: 5| Step: 5
Training loss: 2.1863224674906143
Validation loss: 2.6001949788967904

Epoch: 5| Step: 6
Training loss: 2.5577606475551784
Validation loss: 2.588481665102153

Epoch: 5| Step: 7
Training loss: 2.0275052103711784
Validation loss: 2.5961244431123025

Epoch: 5| Step: 8
Training loss: 2.0366210352171232
Validation loss: 2.5642061833694414

Epoch: 5| Step: 9
Training loss: 2.2904392307616486
Validation loss: 2.548718529422919

Epoch: 5| Step: 10
Training loss: 2.143539783191351
Validation loss: 2.5631964892765606

Epoch: 299| Step: 0
Training loss: 1.8667641642630723
Validation loss: 2.567209140128976

Epoch: 5| Step: 1
Training loss: 2.1568118482932137
Validation loss: 2.5814522680239276

Epoch: 5| Step: 2
Training loss: 2.2751787471765827
Validation loss: 2.5952198239087307

Epoch: 5| Step: 3
Training loss: 1.6281979711072225
Validation loss: 2.6245181808067795

Epoch: 5| Step: 4
Training loss: 2.10884030947502
Validation loss: 2.655793148664349

Epoch: 5| Step: 5
Training loss: 1.7481401642355445
Validation loss: 2.6104762073724834

Epoch: 5| Step: 6
Training loss: 2.095929505990025
Validation loss: 2.600871374107392

Epoch: 5| Step: 7
Training loss: 2.3913991833906127
Validation loss: 2.604558022574338

Epoch: 5| Step: 8
Training loss: 2.023428427186163
Validation loss: 2.5806424287043224

Epoch: 5| Step: 9
Training loss: 2.5604856063298165
Validation loss: 2.5523583688172953

Epoch: 5| Step: 10
Training loss: 2.0606681317995053
Validation loss: 2.509934253182077

Epoch: 300| Step: 0
Training loss: 2.224847822664483
Validation loss: 2.5035054764051283

Epoch: 5| Step: 1
Training loss: 2.2417789312941707
Validation loss: 2.4990212585788254

Epoch: 5| Step: 2
Training loss: 1.4073284252607619
Validation loss: 2.523114629396172

Epoch: 5| Step: 3
Training loss: 2.050988875278487
Validation loss: 2.5166094848513714

Epoch: 5| Step: 4
Training loss: 2.105715480636994
Validation loss: 2.5742568385557516

Epoch: 5| Step: 5
Training loss: 2.250298586212909
Validation loss: 2.625721388457397

Epoch: 5| Step: 6
Training loss: 2.1809229477149414
Validation loss: 2.665617731383047

Epoch: 5| Step: 7
Training loss: 2.0391558044834377
Validation loss: 2.722635003758209

Epoch: 5| Step: 8
Training loss: 2.9458771424945533
Validation loss: 2.701873146101221

Epoch: 5| Step: 9
Training loss: 2.141434119793673
Validation loss: 2.6696597995078073

Epoch: 5| Step: 10
Training loss: 1.68800508922786
Validation loss: 2.6262988428692347

Epoch: 301| Step: 0
Training loss: 2.193351765973556
Validation loss: 2.593970720190959

Epoch: 5| Step: 1
Training loss: 2.0560856112827772
Validation loss: 2.5645043962380125

Epoch: 5| Step: 2
Training loss: 1.8582626990791864
Validation loss: 2.536892652971091

Epoch: 5| Step: 3
Training loss: 2.5236485632151076
Validation loss: 2.520131522874485

Epoch: 5| Step: 4
Training loss: 2.3823970244850856
Validation loss: 2.507574718837081

Epoch: 5| Step: 5
Training loss: 2.0504508197340283
Validation loss: 2.5043130524688366

Epoch: 5| Step: 6
Training loss: 1.7422620817223426
Validation loss: 2.4920371552203013

Epoch: 5| Step: 7
Training loss: 2.1613174821545753
Validation loss: 2.49505520194111

Epoch: 5| Step: 8
Training loss: 2.131660681391295
Validation loss: 2.5013620839648416

Epoch: 5| Step: 9
Training loss: 2.3803789563171427
Validation loss: 2.52937217059013

Epoch: 5| Step: 10
Training loss: 2.3594896907593306
Validation loss: 2.6282440518333168

Epoch: 302| Step: 0
Training loss: 2.036231403113695
Validation loss: 2.652226246964816

Epoch: 5| Step: 1
Training loss: 2.01137336803055
Validation loss: 2.659684422868564

Epoch: 5| Step: 2
Training loss: 2.3516452305837596
Validation loss: 2.6568409560955066

Epoch: 5| Step: 3
Training loss: 1.9086020295771218
Validation loss: 2.6574433417876895

Epoch: 5| Step: 4
Training loss: 2.3805717563659012
Validation loss: 2.6603366441955694

Epoch: 5| Step: 5
Training loss: 1.434724200923245
Validation loss: 2.605265932134043

Epoch: 5| Step: 6
Training loss: 2.1617820650512725
Validation loss: 2.59445117991491

Epoch: 5| Step: 7
Training loss: 2.317258321100387
Validation loss: 2.576667516360905

Epoch: 5| Step: 8
Training loss: 2.8474482707615754
Validation loss: 2.5636528757211154

Epoch: 5| Step: 9
Training loss: 2.329624793822532
Validation loss: 2.526010817371218

Epoch: 5| Step: 10
Training loss: 1.6212037566214181
Validation loss: 2.508425441693292

Epoch: 303| Step: 0
Training loss: 2.5286363836570875
Validation loss: 2.541401862584309

Epoch: 5| Step: 1
Training loss: 1.9975539389001007
Validation loss: 2.595277790218444

Epoch: 5| Step: 2
Training loss: 2.4759647839434478
Validation loss: 2.628217288135381

Epoch: 5| Step: 3
Training loss: 2.137638542637868
Validation loss: 2.6617198297320774

Epoch: 5| Step: 4
Training loss: 1.6727960491600795
Validation loss: 2.653114510477326

Epoch: 5| Step: 5
Training loss: 1.976836053667844
Validation loss: 2.638977480489531

Epoch: 5| Step: 6
Training loss: 2.1399189696613066
Validation loss: 2.576786634307724

Epoch: 5| Step: 7
Training loss: 2.096345914899488
Validation loss: 2.5331025215850342

Epoch: 5| Step: 8
Training loss: 2.1595087167325913
Validation loss: 2.4840539265708945

Epoch: 5| Step: 9
Training loss: 2.4152313661811076
Validation loss: 2.49135534945621

Epoch: 5| Step: 10
Training loss: 1.88657348579063
Validation loss: 2.471988053419643

Epoch: 304| Step: 0
Training loss: 2.2500079472719348
Validation loss: 2.492083765643844

Epoch: 5| Step: 1
Training loss: 1.608407850301654
Validation loss: 2.5080307781275675

Epoch: 5| Step: 2
Training loss: 1.9081251583355445
Validation loss: 2.525447582179334

Epoch: 5| Step: 3
Training loss: 2.382233796433583
Validation loss: 2.56232226676052

Epoch: 5| Step: 4
Training loss: 1.8629055324157149
Validation loss: 2.586569217899928

Epoch: 5| Step: 5
Training loss: 2.4594176428077748
Validation loss: 2.6134761026001874

Epoch: 5| Step: 6
Training loss: 2.1592410806513844
Validation loss: 2.6404581693804197

Epoch: 5| Step: 7
Training loss: 1.984370975039748
Validation loss: 2.6226577602727197

Epoch: 5| Step: 8
Training loss: 1.888038694801467
Validation loss: 2.611791932541544

Epoch: 5| Step: 9
Training loss: 1.8155295604630515
Validation loss: 2.5833330389281337

Epoch: 5| Step: 10
Training loss: 2.2450683376047014
Validation loss: 2.542589547258219

Epoch: 305| Step: 0
Training loss: 2.0960838633278183
Validation loss: 2.539929697321656

Epoch: 5| Step: 1
Training loss: 1.94671421029982
Validation loss: 2.5153639493683606

Epoch: 5| Step: 2
Training loss: 2.5274021430838802
Validation loss: 2.515963666678494

Epoch: 5| Step: 3
Training loss: 1.6868226846650873
Validation loss: 2.498822480451508

Epoch: 5| Step: 4
Training loss: 2.1202060253871298
Validation loss: 2.495371595949893

Epoch: 5| Step: 5
Training loss: 2.440777751133033
Validation loss: 2.499728214708238

Epoch: 5| Step: 6
Training loss: 2.284998492150675
Validation loss: 2.534827688325565

Epoch: 5| Step: 7
Training loss: 2.1753390563124206
Validation loss: 2.6011675808026826

Epoch: 5| Step: 8
Training loss: 2.0581245249525555
Validation loss: 2.6747096650813305

Epoch: 5| Step: 9
Training loss: 2.197836622856727
Validation loss: 2.7143423523230044

Epoch: 5| Step: 10
Training loss: 2.118728358515488
Validation loss: 2.700012786896483

Epoch: 306| Step: 0
Training loss: 2.1154246293131522
Validation loss: 2.6865875954202183

Epoch: 5| Step: 1
Training loss: 1.729016523468684
Validation loss: 2.6616849508821083

Epoch: 5| Step: 2
Training loss: 1.9844260622198138
Validation loss: 2.650898883853183

Epoch: 5| Step: 3
Training loss: 1.9605641408563983
Validation loss: 2.6639093938389338

Epoch: 5| Step: 4
Training loss: 2.2476300367643978
Validation loss: 2.6479213428334196

Epoch: 5| Step: 5
Training loss: 2.1990011592027523
Validation loss: 2.6475925344536972

Epoch: 5| Step: 6
Training loss: 2.335839310945866
Validation loss: 2.603398184977787

Epoch: 5| Step: 7
Training loss: 1.7475223713371955
Validation loss: 2.5673970856256143

Epoch: 5| Step: 8
Training loss: 2.12308505672313
Validation loss: 2.525288918502038

Epoch: 5| Step: 9
Training loss: 2.370738975466283
Validation loss: 2.5038177995242834

Epoch: 5| Step: 10
Training loss: 2.3056630284437536
Validation loss: 2.5185937308458333

Epoch: 307| Step: 0
Training loss: 2.3206955307799495
Validation loss: 2.543658817476425

Epoch: 5| Step: 1
Training loss: 1.8490569468961713
Validation loss: 2.5693425108883434

Epoch: 5| Step: 2
Training loss: 2.0193265298346965
Validation loss: 2.574289905410495

Epoch: 5| Step: 3
Training loss: 2.412191808118258
Validation loss: 2.5880533327515134

Epoch: 5| Step: 4
Training loss: 1.8003158133340047
Validation loss: 2.5833115747139477

Epoch: 5| Step: 5
Training loss: 2.270716136276265
Validation loss: 2.5750028945328345

Epoch: 5| Step: 6
Training loss: 1.6538752679531252
Validation loss: 2.5489025740798126

Epoch: 5| Step: 7
Training loss: 1.778803366465693
Validation loss: 2.5329324834499563

Epoch: 5| Step: 8
Training loss: 2.287444600752917
Validation loss: 2.5584899084703348

Epoch: 5| Step: 9
Training loss: 2.0172818493514733
Validation loss: 2.556180445179133

Epoch: 5| Step: 10
Training loss: 1.973204583734137
Validation loss: 2.5712886477373793

Epoch: 308| Step: 0
Training loss: 2.406122873093979
Validation loss: 2.6078264331324377

Epoch: 5| Step: 1
Training loss: 2.141051980753749
Validation loss: 2.6072339081616627

Epoch: 5| Step: 2
Training loss: 1.397969258091831
Validation loss: 2.595115015803318

Epoch: 5| Step: 3
Training loss: 1.7222743573381623
Validation loss: 2.5995344294162406

Epoch: 5| Step: 4
Training loss: 2.1100491047067322
Validation loss: 2.6166687918030567

Epoch: 5| Step: 5
Training loss: 1.7542721508987553
Validation loss: 2.624180047985691

Epoch: 5| Step: 6
Training loss: 2.0198672105558844
Validation loss: 2.6509741276860144

Epoch: 5| Step: 7
Training loss: 2.3175289013160243
Validation loss: 2.6507585176342223

Epoch: 5| Step: 8
Training loss: 1.6412528153778125
Validation loss: 2.631733791642906

Epoch: 5| Step: 9
Training loss: 2.373283569085665
Validation loss: 2.6102458308086005

Epoch: 5| Step: 10
Training loss: 2.174851169098026
Validation loss: 2.6291912359376757

Epoch: 309| Step: 0
Training loss: 1.4701283257453872
Validation loss: 2.6308601935377824

Epoch: 5| Step: 1
Training loss: 2.0816085414951666
Validation loss: 2.6277174998023294

Epoch: 5| Step: 2
Training loss: 2.296796317277412
Validation loss: 2.643877832041301

Epoch: 5| Step: 3
Training loss: 2.0574049005049013
Validation loss: 2.6438410887740975

Epoch: 5| Step: 4
Training loss: 2.380714368276949
Validation loss: 2.610957099767

Epoch: 5| Step: 5
Training loss: 1.837407858478138
Validation loss: 2.5598595834588833

Epoch: 5| Step: 6
Training loss: 1.727551207383822
Validation loss: 2.5020510166452112

Epoch: 5| Step: 7
Training loss: 1.9563403099591266
Validation loss: 2.4930458315072204

Epoch: 5| Step: 8
Training loss: 1.7514580374745785
Validation loss: 2.4786016137930686

Epoch: 5| Step: 9
Training loss: 1.9260363922404526
Validation loss: 2.4747525782261763

Epoch: 5| Step: 10
Training loss: 2.56381740665587
Validation loss: 2.4917855705169405

Epoch: 310| Step: 0
Training loss: 1.7380266667505242
Validation loss: 2.492406584917396

Epoch: 5| Step: 1
Training loss: 2.37535574407049
Validation loss: 2.5349566909499126

Epoch: 5| Step: 2
Training loss: 1.927801160032349
Validation loss: 2.5751317979817814

Epoch: 5| Step: 3
Training loss: 1.8923898451681622
Validation loss: 2.6318682068998913

Epoch: 5| Step: 4
Training loss: 1.9625115023719322
Validation loss: 2.6923214512360416

Epoch: 5| Step: 5
Training loss: 1.5705971531006546
Validation loss: 2.7085019995433823

Epoch: 5| Step: 6
Training loss: 2.3976968124801843
Validation loss: 2.6921446458099223

Epoch: 5| Step: 7
Training loss: 2.1986491954742395
Validation loss: 2.602386041735604

Epoch: 5| Step: 8
Training loss: 1.683331250041516
Validation loss: 2.556278506662431

Epoch: 5| Step: 9
Training loss: 1.9464941151233828
Validation loss: 2.543057516228651

Epoch: 5| Step: 10
Training loss: 2.3323888456593074
Validation loss: 2.550609773126151

Epoch: 311| Step: 0
Training loss: 1.6922810254796952
Validation loss: 2.548997803775154

Epoch: 5| Step: 1
Training loss: 1.9387609623907123
Validation loss: 2.5277088035597752

Epoch: 5| Step: 2
Training loss: 1.7959896394307588
Validation loss: 2.5277133675239583

Epoch: 5| Step: 3
Training loss: 1.882583034350832
Validation loss: 2.559544292054976

Epoch: 5| Step: 4
Training loss: 1.878282978947828
Validation loss: 2.5828186316975374

Epoch: 5| Step: 5
Training loss: 1.9518856541528802
Validation loss: 2.6258307195793575

Epoch: 5| Step: 6
Training loss: 2.260387496642832
Validation loss: 2.642541494630176

Epoch: 5| Step: 7
Training loss: 2.634403461198476
Validation loss: 2.6618515355759804

Epoch: 5| Step: 8
Training loss: 1.8540064138817978
Validation loss: 2.6607036298751745

Epoch: 5| Step: 9
Training loss: 1.8263990291544423
Validation loss: 2.620545094081597

Epoch: 5| Step: 10
Training loss: 2.019760030335079
Validation loss: 2.570012974017436

Epoch: 312| Step: 0
Training loss: 1.9644173677094987
Validation loss: 2.5484339029056597

Epoch: 5| Step: 1
Training loss: 2.2441688847899735
Validation loss: 2.55156517938203

Epoch: 5| Step: 2
Training loss: 1.488104541931132
Validation loss: 2.5750585383113127

Epoch: 5| Step: 3
Training loss: 1.5908977192311295
Validation loss: 2.576344278483716

Epoch: 5| Step: 4
Training loss: 1.9590981660542335
Validation loss: 2.5907690831211947

Epoch: 5| Step: 5
Training loss: 1.8125021046593384
Validation loss: 2.6031653709419293

Epoch: 5| Step: 6
Training loss: 1.9302183957634504
Validation loss: 2.584428791815028

Epoch: 5| Step: 7
Training loss: 1.9322582834929696
Validation loss: 2.571002839446739

Epoch: 5| Step: 8
Training loss: 2.043303540662387
Validation loss: 2.5675270908352847

Epoch: 5| Step: 9
Training loss: 2.0578299160323894
Validation loss: 2.588370557300958

Epoch: 5| Step: 10
Training loss: 2.1358734634723406
Validation loss: 2.5788854427755585

Epoch: 313| Step: 0
Training loss: 2.1451930847050815
Validation loss: 2.5608825010584533

Epoch: 5| Step: 1
Training loss: 1.938033676480805
Validation loss: 2.5778068179577636

Epoch: 5| Step: 2
Training loss: 1.616755920908963
Validation loss: 2.5610080220293514

Epoch: 5| Step: 3
Training loss: 1.8974134406851286
Validation loss: 2.5456150264302964

Epoch: 5| Step: 4
Training loss: 1.7300329757590591
Validation loss: 2.5349403429844233

Epoch: 5| Step: 5
Training loss: 1.8778703970830806
Validation loss: 2.5349622794724254

Epoch: 5| Step: 6
Training loss: 2.0268852876819117
Validation loss: 2.5086046103317066

Epoch: 5| Step: 7
Training loss: 1.8918582267509165
Validation loss: 2.5027777785623297

Epoch: 5| Step: 8
Training loss: 1.7764977757885294
Validation loss: 2.505995505599521

Epoch: 5| Step: 9
Training loss: 1.991527552780653
Validation loss: 2.529834496868181

Epoch: 5| Step: 10
Training loss: 2.004096604019424
Validation loss: 2.549148425662459

Epoch: 314| Step: 0
Training loss: 1.652447059233468
Validation loss: 2.5720379119935104

Epoch: 5| Step: 1
Training loss: 1.8365868252098576
Validation loss: 2.5910887089158186

Epoch: 5| Step: 2
Training loss: 1.5542420175539744
Validation loss: 2.6039242629576536

Epoch: 5| Step: 3
Training loss: 2.2762685236420666
Validation loss: 2.5943337613942967

Epoch: 5| Step: 4
Training loss: 1.6477237258920792
Validation loss: 2.590122476964061

Epoch: 5| Step: 5
Training loss: 2.1219879569773448
Validation loss: 2.605725894557711

Epoch: 5| Step: 6
Training loss: 2.119707360493051
Validation loss: 2.6040530790762584

Epoch: 5| Step: 7
Training loss: 1.7838088946387063
Validation loss: 2.553336123340172

Epoch: 5| Step: 8
Training loss: 1.874097606946487
Validation loss: 2.5517750626487494

Epoch: 5| Step: 9
Training loss: 2.0785792721884544
Validation loss: 2.531082050520109

Epoch: 5| Step: 10
Training loss: 1.1644127849973807
Validation loss: 2.5375733567865035

Epoch: 315| Step: 0
Training loss: 1.9698720489621215
Validation loss: 2.514200505202113

Epoch: 5| Step: 1
Training loss: 1.7984035458909913
Validation loss: 2.527156803329937

Epoch: 5| Step: 2
Training loss: 1.768063574459207
Validation loss: 2.5545821459016143

Epoch: 5| Step: 3
Training loss: 1.466106064179724
Validation loss: 2.564950515112054

Epoch: 5| Step: 4
Training loss: 1.479907410019365
Validation loss: 2.596933111459663

Epoch: 5| Step: 5
Training loss: 2.2554973625585433
Validation loss: 2.6239737259019353

Epoch: 5| Step: 6
Training loss: 2.227204561517418
Validation loss: 2.6011390133185115

Epoch: 5| Step: 7
Training loss: 2.0731787076657087
Validation loss: 2.6056634882727208

Epoch: 5| Step: 8
Training loss: 1.5910407581587325
Validation loss: 2.5965334608334807

Epoch: 5| Step: 9
Training loss: 1.6429471974539613
Validation loss: 2.577899836269038

Epoch: 5| Step: 10
Training loss: 1.873319190380337
Validation loss: 2.5955099674718496

Epoch: 316| Step: 0
Training loss: 1.388384525062046
Validation loss: 2.5839918139574496

Epoch: 5| Step: 1
Training loss: 2.134474669066026
Validation loss: 2.5764076486813035

Epoch: 5| Step: 2
Training loss: 2.2402637483089585
Validation loss: 2.5465717790709435

Epoch: 5| Step: 3
Training loss: 1.8251327414117564
Validation loss: 2.5769875133572775

Epoch: 5| Step: 4
Training loss: 1.9618052352259852
Validation loss: 2.586325793472296

Epoch: 5| Step: 5
Training loss: 1.543295214918988
Validation loss: 2.5944550909085207

Epoch: 5| Step: 6
Training loss: 1.7570491235213206
Validation loss: 2.615669109037104

Epoch: 5| Step: 7
Training loss: 1.3957228071189973
Validation loss: 2.6208697463048534

Epoch: 5| Step: 8
Training loss: 1.6125148033231445
Validation loss: 2.628066809198051

Epoch: 5| Step: 9
Training loss: 2.1949098699743437
Validation loss: 2.66585877957924

Epoch: 5| Step: 10
Training loss: 2.015859545878561
Validation loss: 2.665881591899015

Epoch: 317| Step: 0
Training loss: 2.270393352289663
Validation loss: 2.6442293840125455

Epoch: 5| Step: 1
Training loss: 1.945531625930331
Validation loss: 2.5944664454045703

Epoch: 5| Step: 2
Training loss: 1.7831962393119043
Validation loss: 2.5473529350377935

Epoch: 5| Step: 3
Training loss: 1.6626140756118382
Validation loss: 2.5217088463581527

Epoch: 5| Step: 4
Training loss: 1.776772409349564
Validation loss: 2.5042185692029513

Epoch: 5| Step: 5
Training loss: 1.4237591343453555
Validation loss: 2.5312294138186853

Epoch: 5| Step: 6
Training loss: 2.0963045165696195
Validation loss: 2.5200156883591953

Epoch: 5| Step: 7
Training loss: 1.963189704846418
Validation loss: 2.535327707313556

Epoch: 5| Step: 8
Training loss: 1.7889059073202709
Validation loss: 2.5540029750092956

Epoch: 5| Step: 9
Training loss: 1.6190805458546045
Validation loss: 2.6029618112268436

Epoch: 5| Step: 10
Training loss: 1.9196478491936848
Validation loss: 2.622523693104106

Epoch: 318| Step: 0
Training loss: 1.9338194436030354
Validation loss: 2.6644386942726603

Epoch: 5| Step: 1
Training loss: 2.0041105229476983
Validation loss: 2.6681597520017752

Epoch: 5| Step: 2
Training loss: 1.5106574381832336
Validation loss: 2.652779855462292

Epoch: 5| Step: 3
Training loss: 1.9926739865374177
Validation loss: 2.6256243992982515

Epoch: 5| Step: 4
Training loss: 2.19134466999318
Validation loss: 2.612873701108291

Epoch: 5| Step: 5
Training loss: 1.6922694023508953
Validation loss: 2.5809458435342583

Epoch: 5| Step: 6
Training loss: 1.4212765115296715
Validation loss: 2.5675538671028786

Epoch: 5| Step: 7
Training loss: 1.9473677965179461
Validation loss: 2.5491955757674813

Epoch: 5| Step: 8
Training loss: 1.9728917953819465
Validation loss: 2.5412740385646297

Epoch: 5| Step: 9
Training loss: 1.7758791076307625
Validation loss: 2.564450140444152

Epoch: 5| Step: 10
Training loss: 1.7132094118127401
Validation loss: 2.5698619000844882

Epoch: 319| Step: 0
Training loss: 1.8095124714598947
Validation loss: 2.583396111664003

Epoch: 5| Step: 1
Training loss: 1.9627866499203293
Validation loss: 2.6067517280196064

Epoch: 5| Step: 2
Training loss: 1.2060306191455967
Validation loss: 2.6435969633253382

Epoch: 5| Step: 3
Training loss: 1.9127210626433784
Validation loss: 2.6624389403029483

Epoch: 5| Step: 4
Training loss: 1.7168293017904273
Validation loss: 2.6499736083394585

Epoch: 5| Step: 5
Training loss: 1.5610991492591844
Validation loss: 2.61709718776451

Epoch: 5| Step: 6
Training loss: 1.9289991255224765
Validation loss: 2.6177050653470726

Epoch: 5| Step: 7
Training loss: 1.9876766222322184
Validation loss: 2.605191721010416

Epoch: 5| Step: 8
Training loss: 1.9149654205028879
Validation loss: 2.6031671958065674

Epoch: 5| Step: 9
Training loss: 1.8940249680924721
Validation loss: 2.5771825923110554

Epoch: 5| Step: 10
Training loss: 1.8806566107322316
Validation loss: 2.5787163755666835

Epoch: 320| Step: 0
Training loss: 1.610469482990193
Validation loss: 2.548271619151589

Epoch: 5| Step: 1
Training loss: 1.6020100782270275
Validation loss: 2.520876419755468

Epoch: 5| Step: 2
Training loss: 1.650856376704078
Validation loss: 2.4967034334620934

Epoch: 5| Step: 3
Training loss: 1.9763791447811276
Validation loss: 2.5107757191770883

Epoch: 5| Step: 4
Training loss: 2.2298220684073855
Validation loss: 2.5099275722119705

Epoch: 5| Step: 5
Training loss: 1.144761723042011
Validation loss: 2.5290867839104076

Epoch: 5| Step: 6
Training loss: 2.282056483018554
Validation loss: 2.5747256393573705

Epoch: 5| Step: 7
Training loss: 1.4933582925555602
Validation loss: 2.589441708761092

Epoch: 5| Step: 8
Training loss: 1.6224768196413277
Validation loss: 2.6199882487553534

Epoch: 5| Step: 9
Training loss: 1.8859595751793874
Validation loss: 2.6295842136374805

Epoch: 5| Step: 10
Training loss: 2.225114532266072
Validation loss: 2.6327528001203464

Epoch: 321| Step: 0
Training loss: 1.6435678881581433
Validation loss: 2.5905359495405578

Epoch: 5| Step: 1
Training loss: 1.8371596793235347
Validation loss: 2.537576437105554

Epoch: 5| Step: 2
Training loss: 1.4023305738249814
Validation loss: 2.506420758416006

Epoch: 5| Step: 3
Training loss: 1.9278247815917522
Validation loss: 2.4984562599071776

Epoch: 5| Step: 4
Training loss: 1.5539137865500368
Validation loss: 2.5039906204955082

Epoch: 5| Step: 5
Training loss: 1.8790223527911578
Validation loss: 2.525446350834494

Epoch: 5| Step: 6
Training loss: 1.452084240395451
Validation loss: 2.525794243289646

Epoch: 5| Step: 7
Training loss: 1.7789973688390273
Validation loss: 2.5498598968700468

Epoch: 5| Step: 8
Training loss: 2.116124072578367
Validation loss: 2.577253258058397

Epoch: 5| Step: 9
Training loss: 1.9897907275477023
Validation loss: 2.621767068016345

Epoch: 5| Step: 10
Training loss: 2.0669820232154064
Validation loss: 2.63782210088842

Epoch: 322| Step: 0
Training loss: 1.362762308681328
Validation loss: 2.676512849459519

Epoch: 5| Step: 1
Training loss: 1.8067011312714194
Validation loss: 2.705004008952482

Epoch: 5| Step: 2
Training loss: 1.6316917259829926
Validation loss: 2.681560547576088

Epoch: 5| Step: 3
Training loss: 1.9312640093940323
Validation loss: 2.665224526234819

Epoch: 5| Step: 4
Training loss: 1.869312178851669
Validation loss: 2.653123672689676

Epoch: 5| Step: 5
Training loss: 1.9265838250606568
Validation loss: 2.6425795695211014

Epoch: 5| Step: 6
Training loss: 1.5203960870109852
Validation loss: 2.613493834836004

Epoch: 5| Step: 7
Training loss: 2.0792841152535653
Validation loss: 2.6094667387740818

Epoch: 5| Step: 8
Training loss: 1.7942046516367514
Validation loss: 2.6166158983431425

Epoch: 5| Step: 9
Training loss: 1.473460172800357
Validation loss: 2.598348471813523

Epoch: 5| Step: 10
Training loss: 1.8321263790850262
Validation loss: 2.6075762883161313

Epoch: 323| Step: 0
Training loss: 1.6352565306320386
Validation loss: 2.5937249698511007

Epoch: 5| Step: 1
Training loss: 1.7487475136554487
Validation loss: 2.5978481979565

Epoch: 5| Step: 2
Training loss: 1.761092250086525
Validation loss: 2.633298232990926

Epoch: 5| Step: 3
Training loss: 2.3730446646723244
Validation loss: 2.642171631192068

Epoch: 5| Step: 4
Training loss: 1.164030650682425
Validation loss: 2.638718835165325

Epoch: 5| Step: 5
Training loss: 1.6822820452561633
Validation loss: 2.6624310994634386

Epoch: 5| Step: 6
Training loss: 1.4317791755944824
Validation loss: 2.667514885955832

Epoch: 5| Step: 7
Training loss: 1.9567906275555162
Validation loss: 2.6547891864616524

Epoch: 5| Step: 8
Training loss: 1.4622601728158844
Validation loss: 2.6481879830632113

Epoch: 5| Step: 9
Training loss: 1.6298235681919186
Validation loss: 2.621015567926911

Epoch: 5| Step: 10
Training loss: 1.9169204239862832
Validation loss: 2.638415780444858

Epoch: 324| Step: 0
Training loss: 1.4971816288421493
Validation loss: 2.5958462045649657

Epoch: 5| Step: 1
Training loss: 2.0233702188153595
Validation loss: 2.597468046269168

Epoch: 5| Step: 2
Training loss: 1.5176066392259655
Validation loss: 2.5915599036828456

Epoch: 5| Step: 3
Training loss: 1.8689289989670372
Validation loss: 2.6215232041392915

Epoch: 5| Step: 4
Training loss: 1.4360354052883582
Validation loss: 2.6300571946896145

Epoch: 5| Step: 5
Training loss: 1.6478803515702924
Validation loss: 2.648160046250506

Epoch: 5| Step: 6
Training loss: 1.8072236970841462
Validation loss: 2.6208937835986448

Epoch: 5| Step: 7
Training loss: 2.1434038600125502
Validation loss: 2.642692731568184

Epoch: 5| Step: 8
Training loss: 2.0213759830919016
Validation loss: 2.628571316906565

Epoch: 5| Step: 9
Training loss: 1.3292548366628674
Validation loss: 2.6107035175284588

Epoch: 5| Step: 10
Training loss: 1.276834835666227
Validation loss: 2.623682282213775

Epoch: 325| Step: 0
Training loss: 2.1406971717418406
Validation loss: 2.623314577654197

Epoch: 5| Step: 1
Training loss: 1.612074208783024
Validation loss: 2.6043689956000677

Epoch: 5| Step: 2
Training loss: 1.2560090588346224
Validation loss: 2.6041079633105464

Epoch: 5| Step: 3
Training loss: 1.5016318028361888
Validation loss: 2.603190909082381

Epoch: 5| Step: 4
Training loss: 1.9926243920068953
Validation loss: 2.6183484072342162

Epoch: 5| Step: 5
Training loss: 1.8255952465293042
Validation loss: 2.6376110783483298

Epoch: 5| Step: 6
Training loss: 1.3778738420120464
Validation loss: 2.6368243943671916

Epoch: 5| Step: 7
Training loss: 1.969159764834575
Validation loss: 2.647708830454468

Epoch: 5| Step: 8
Training loss: 1.3183200406458522
Validation loss: 2.6060643343204077

Epoch: 5| Step: 9
Training loss: 1.7860773494028546
Validation loss: 2.640799181531243

Epoch: 5| Step: 10
Training loss: 1.682975567042518
Validation loss: 2.635104618148153

Epoch: 326| Step: 0
Training loss: 1.6116062733414256
Validation loss: 2.635667427023795

Epoch: 5| Step: 1
Training loss: 1.7272260952773824
Validation loss: 2.6398130885743245

Epoch: 5| Step: 2
Training loss: 1.8557906022253323
Validation loss: 2.6384087067573128

Epoch: 5| Step: 3
Training loss: 1.3859800708515944
Validation loss: 2.6480049227479894

Epoch: 5| Step: 4
Training loss: 1.4938924745423898
Validation loss: 2.6308772950724943

Epoch: 5| Step: 5
Training loss: 1.5697090165981562
Validation loss: 2.620811973341399

Epoch: 5| Step: 6
Training loss: 1.6727935549359647
Validation loss: 2.607365894411843

Epoch: 5| Step: 7
Training loss: 1.5879927223480808
Validation loss: 2.6280186485579655

Epoch: 5| Step: 8
Training loss: 1.7500428467001186
Validation loss: 2.601182498886197

Epoch: 5| Step: 9
Training loss: 1.8107310245693624
Validation loss: 2.595790206426358

Epoch: 5| Step: 10
Training loss: 2.0603279467523965
Validation loss: 2.5965918282846827

Epoch: 327| Step: 0
Training loss: 1.569996740374249
Validation loss: 2.604977485356792

Epoch: 5| Step: 1
Training loss: 1.5803678079634709
Validation loss: 2.619177073667483

Epoch: 5| Step: 2
Training loss: 1.3861301516157574
Validation loss: 2.667813114892568

Epoch: 5| Step: 3
Training loss: 1.8484684971381333
Validation loss: 2.6786484926098533

Epoch: 5| Step: 4
Training loss: 1.9426290241924127
Validation loss: 2.6616366987893856

Epoch: 5| Step: 5
Training loss: 1.477768662710609
Validation loss: 2.6644461866730684

Epoch: 5| Step: 6
Training loss: 1.8702442255521228
Validation loss: 2.6602558599617434

Epoch: 5| Step: 7
Training loss: 1.8089622962442855
Validation loss: 2.6334986919125534

Epoch: 5| Step: 8
Training loss: 1.6547811220535806
Validation loss: 2.626107259226347

Epoch: 5| Step: 9
Training loss: 1.6402963218247255
Validation loss: 2.6029727848890873

Epoch: 5| Step: 10
Training loss: 1.6014153389659305
Validation loss: 2.6115740820384126

Epoch: 328| Step: 0
Training loss: 2.0104860547466044
Validation loss: 2.6220415459760154

Epoch: 5| Step: 1
Training loss: 1.7874301976800016
Validation loss: 2.6593343452145652

Epoch: 5| Step: 2
Training loss: 1.4958579572317356
Validation loss: 2.6400643370157546

Epoch: 5| Step: 3
Training loss: 1.303395756830693
Validation loss: 2.6410691868924

Epoch: 5| Step: 4
Training loss: 1.0480883385030535
Validation loss: 2.639642693785421

Epoch: 5| Step: 5
Training loss: 2.05311924949549
Validation loss: 2.6179896597596506

Epoch: 5| Step: 6
Training loss: 1.7914633820411558
Validation loss: 2.6383175652608877

Epoch: 5| Step: 7
Training loss: 1.505906951588122
Validation loss: 2.65050097358437

Epoch: 5| Step: 8
Training loss: 1.4776496719741548
Validation loss: 2.6494969102685246

Epoch: 5| Step: 9
Training loss: 1.8962453736743556
Validation loss: 2.626252185795068

Epoch: 5| Step: 10
Training loss: 1.7302697887526435
Validation loss: 2.646007818570187

Epoch: 329| Step: 0
Training loss: 1.7326412986614599
Validation loss: 2.661087387553755

Epoch: 5| Step: 1
Training loss: 1.5494169676876204
Validation loss: 2.6614509956318595

Epoch: 5| Step: 2
Training loss: 2.1478485964901775
Validation loss: 2.6699859075914456

Epoch: 5| Step: 3
Training loss: 1.3992162060142066
Validation loss: 2.6769996541567695

Epoch: 5| Step: 4
Training loss: 1.6777173220175252
Validation loss: 2.6804466429107037

Epoch: 5| Step: 5
Training loss: 1.1846047795022987
Validation loss: 2.670683071935532

Epoch: 5| Step: 6
Training loss: 1.2612142115072045
Validation loss: 2.6841155154244545

Epoch: 5| Step: 7
Training loss: 1.6751350633056912
Validation loss: 2.649258158928793

Epoch: 5| Step: 8
Training loss: 1.7819063416303358
Validation loss: 2.6286460880479585

Epoch: 5| Step: 9
Training loss: 1.3072548008719536
Validation loss: 2.6262736221669822

Epoch: 5| Step: 10
Training loss: 2.003119777250102
Validation loss: 2.5861867242963927

Epoch: 330| Step: 0
Training loss: 1.646596594772608
Validation loss: 2.6239564328214726

Epoch: 5| Step: 1
Training loss: 1.501719522353948
Validation loss: 2.594207871516861

Epoch: 5| Step: 2
Training loss: 1.7463621065585198
Validation loss: 2.58144326356916

Epoch: 5| Step: 3
Training loss: 1.8483876883469266
Validation loss: 2.604254367130973

Epoch: 5| Step: 4
Training loss: 1.531519496324108
Validation loss: 2.58014480360459

Epoch: 5| Step: 5
Training loss: 1.4588383572189505
Validation loss: 2.6072756618240103

Epoch: 5| Step: 6
Training loss: 1.8885043522605607
Validation loss: 2.6166165185275303

Epoch: 5| Step: 7
Training loss: 1.0121733479984125
Validation loss: 2.614494247366718

Epoch: 5| Step: 8
Training loss: 1.6967082804065197
Validation loss: 2.646130940335742

Epoch: 5| Step: 9
Training loss: 1.5578024631433265
Validation loss: 2.667363128415159

Epoch: 5| Step: 10
Training loss: 1.8196248732672462
Validation loss: 2.6621499405666746

Epoch: 331| Step: 0
Training loss: 1.603322248612205
Validation loss: 2.6572110757966905

Epoch: 5| Step: 1
Training loss: 1.6073303567412345
Validation loss: 2.6842174663492293

Epoch: 5| Step: 2
Training loss: 0.6731271829808788
Validation loss: 2.645603070757599

Epoch: 5| Step: 3
Training loss: 1.4802106566906421
Validation loss: 2.655387131198677

Epoch: 5| Step: 4
Training loss: 1.638832275397008
Validation loss: 2.626275665251038

Epoch: 5| Step: 5
Training loss: 1.6411926740642304
Validation loss: 2.6100583826325403

Epoch: 5| Step: 6
Training loss: 1.6211953740266412
Validation loss: 2.610121568793652

Epoch: 5| Step: 7
Training loss: 1.8955909518169016
Validation loss: 2.592747094719796

Epoch: 5| Step: 8
Training loss: 2.0260461906899065
Validation loss: 2.6065359072538814

Epoch: 5| Step: 9
Training loss: 1.762958099135615
Validation loss: 2.600488434783236

Epoch: 5| Step: 10
Training loss: 1.460789310874981
Validation loss: 2.603510913281959

Epoch: 332| Step: 0
Training loss: 1.705340003738501
Validation loss: 2.6425313119995506

Epoch: 5| Step: 1
Training loss: 1.39744114678509
Validation loss: 2.6626074622189613

Epoch: 5| Step: 2
Training loss: 1.4084219795558548
Validation loss: 2.6653334969692044

Epoch: 5| Step: 3
Training loss: 1.5098656624916544
Validation loss: 2.6579560805812057

Epoch: 5| Step: 4
Training loss: 1.483603025772
Validation loss: 2.651934429012636

Epoch: 5| Step: 5
Training loss: 1.4710420620711593
Validation loss: 2.6254789908630816

Epoch: 5| Step: 6
Training loss: 1.5779199750308373
Validation loss: 2.627350225328387

Epoch: 5| Step: 7
Training loss: 2.1207466192698576
Validation loss: 2.6083993387649382

Epoch: 5| Step: 8
Training loss: 1.5852247619111832
Validation loss: 2.5959554024480154

Epoch: 5| Step: 9
Training loss: 1.5031694465140886
Validation loss: 2.5993466496625377

Epoch: 5| Step: 10
Training loss: 1.755317307286185
Validation loss: 2.62767938614993

Epoch: 333| Step: 0
Training loss: 1.247580141004603
Validation loss: 2.624189077735629

Epoch: 5| Step: 1
Training loss: 1.8779780579525212
Validation loss: 2.6346138902010368

Epoch: 5| Step: 2
Training loss: 1.592707498706959
Validation loss: 2.630500330028033

Epoch: 5| Step: 3
Training loss: 1.2452593075293943
Validation loss: 2.6144313178937275

Epoch: 5| Step: 4
Training loss: 1.8118618466550191
Validation loss: 2.5990432898651727

Epoch: 5| Step: 5
Training loss: 1.581713307774621
Validation loss: 2.5907978129412297

Epoch: 5| Step: 6
Training loss: 1.4152002973294202
Validation loss: 2.58874515342638

Epoch: 5| Step: 7
Training loss: 1.922347344140345
Validation loss: 2.5837203783494287

Epoch: 5| Step: 8
Training loss: 1.7886059440862947
Validation loss: 2.580146295996457

Epoch: 5| Step: 9
Training loss: 1.4246094787614354
Validation loss: 2.590188505058139

Epoch: 5| Step: 10
Training loss: 1.6033336243394574
Validation loss: 2.6006077722408016

Epoch: 334| Step: 0
Training loss: 1.383878867843332
Validation loss: 2.6078832187709002

Epoch: 5| Step: 1
Training loss: 1.6163423697974968
Validation loss: 2.5721611683010366

Epoch: 5| Step: 2
Training loss: 1.6661632333816598
Validation loss: 2.5874631598403575

Epoch: 5| Step: 3
Training loss: 1.4619551597429796
Validation loss: 2.541399066326127

Epoch: 5| Step: 4
Training loss: 1.8094206993643596
Validation loss: 2.5222007305974015

Epoch: 5| Step: 5
Training loss: 1.3595103930868395
Validation loss: 2.5251400836321416

Epoch: 5| Step: 6
Training loss: 2.045404386387034
Validation loss: 2.5280516469066345

Epoch: 5| Step: 7
Training loss: 1.9056732055532306
Validation loss: 2.5381523052026895

Epoch: 5| Step: 8
Training loss: 0.9114689018000103
Validation loss: 2.584029681073858

Epoch: 5| Step: 9
Training loss: 1.8116925512790816
Validation loss: 2.6264353137381433

Epoch: 5| Step: 10
Training loss: 1.0823649638924713
Validation loss: 2.652071577347893

Epoch: 335| Step: 0
Training loss: 1.5719942415486248
Validation loss: 2.664134179690881

Epoch: 5| Step: 1
Training loss: 1.3857298857859974
Validation loss: 2.669172029785066

Epoch: 5| Step: 2
Training loss: 1.8694496018992162
Validation loss: 2.695276553505932

Epoch: 5| Step: 3
Training loss: 1.6836675995032586
Validation loss: 2.6780261414547546

Epoch: 5| Step: 4
Training loss: 1.5204338785864522
Validation loss: 2.6522135980132444

Epoch: 5| Step: 5
Training loss: 1.6257697263104856
Validation loss: 2.6477189525070397

Epoch: 5| Step: 6
Training loss: 1.1909009518566935
Validation loss: 2.623142664028832

Epoch: 5| Step: 7
Training loss: 1.6033881226190936
Validation loss: 2.5780967763062512

Epoch: 5| Step: 8
Training loss: 1.5837661084783783
Validation loss: 2.5625721810992372

Epoch: 5| Step: 9
Training loss: 1.4918268377027495
Validation loss: 2.5760794630499326

Epoch: 5| Step: 10
Training loss: 1.7552940128895191
Validation loss: 2.5476160159838392

Epoch: 336| Step: 0
Training loss: 1.803193898595322
Validation loss: 2.56438135973994

Epoch: 5| Step: 1
Training loss: 1.1394298510549734
Validation loss: 2.5668065868647916

Epoch: 5| Step: 2
Training loss: 1.6661671684722028
Validation loss: 2.5597257846306594

Epoch: 5| Step: 3
Training loss: 1.5918154475526938
Validation loss: 2.5603783300622256

Epoch: 5| Step: 4
Training loss: 1.4105999531210314
Validation loss: 2.5670661711506146

Epoch: 5| Step: 5
Training loss: 1.674733080876292
Validation loss: 2.5727706312411773

Epoch: 5| Step: 6
Training loss: 1.3955705974275092
Validation loss: 2.5902990073661267

Epoch: 5| Step: 7
Training loss: 1.0078421300036604
Validation loss: 2.6054545614595996

Epoch: 5| Step: 8
Training loss: 1.6703990945948781
Validation loss: 2.6104609726528127

Epoch: 5| Step: 9
Training loss: 1.85407463302513
Validation loss: 2.6254726156339943

Epoch: 5| Step: 10
Training loss: 1.583324741875612
Validation loss: 2.625165536625178

Epoch: 337| Step: 0
Training loss: 1.5927659530978355
Validation loss: 2.631463130419261

Epoch: 5| Step: 1
Training loss: 1.538679820861211
Validation loss: 2.635379197768993

Epoch: 5| Step: 2
Training loss: 1.615425513696473
Validation loss: 2.6428412980851737

Epoch: 5| Step: 3
Training loss: 1.6281407155982612
Validation loss: 2.6467439458579847

Epoch: 5| Step: 4
Training loss: 1.5782435155499959
Validation loss: 2.6601579818008

Epoch: 5| Step: 5
Training loss: 1.4237550316404364
Validation loss: 2.6173942360598854

Epoch: 5| Step: 6
Training loss: 1.7179489349707442
Validation loss: 2.6027786844881557

Epoch: 5| Step: 7
Training loss: 1.2993105802581006
Validation loss: 2.585856451624448

Epoch: 5| Step: 8
Training loss: 1.6143598668492734
Validation loss: 2.5658125272474126

Epoch: 5| Step: 9
Training loss: 1.3276449794589456
Validation loss: 2.5587917992376905

Epoch: 5| Step: 10
Training loss: 1.5074787462295653
Validation loss: 2.552309646935315

Epoch: 338| Step: 0
Training loss: 1.085017521272867
Validation loss: 2.5605822944990053

Epoch: 5| Step: 1
Training loss: 1.5765223154895627
Validation loss: 2.546442545368693

Epoch: 5| Step: 2
Training loss: 1.2225532366466672
Validation loss: 2.5522596826120196

Epoch: 5| Step: 3
Training loss: 1.833405327105843
Validation loss: 2.5611643397869908

Epoch: 5| Step: 4
Training loss: 1.1579154109135852
Validation loss: 2.5798476543664517

Epoch: 5| Step: 5
Training loss: 1.3927381511835404
Validation loss: 2.5749056397291143

Epoch: 5| Step: 6
Training loss: 1.5745451709449523
Validation loss: 2.5998199509010655

Epoch: 5| Step: 7
Training loss: 1.2233499137541306
Validation loss: 2.6049729091408773

Epoch: 5| Step: 8
Training loss: 1.8714679511075538
Validation loss: 2.6251921458903977

Epoch: 5| Step: 9
Training loss: 2.0074460181250293
Validation loss: 2.6255779548133944

Epoch: 5| Step: 10
Training loss: 1.4673751727275584
Validation loss: 2.610104677000242

Epoch: 339| Step: 0
Training loss: 1.7062721223060777
Validation loss: 2.6055685772839974

Epoch: 5| Step: 1
Training loss: 1.1274258103248125
Validation loss: 2.5872565751960455

Epoch: 5| Step: 2
Training loss: 1.5081966088783334
Validation loss: 2.5745031786101222

Epoch: 5| Step: 3
Training loss: 1.8331410639540575
Validation loss: 2.573072158667159

Epoch: 5| Step: 4
Training loss: 1.6499255365851013
Validation loss: 2.562604258267432

Epoch: 5| Step: 5
Training loss: 1.2221791857068658
Validation loss: 2.559485434332823

Epoch: 5| Step: 6
Training loss: 1.608024697346596
Validation loss: 2.5585939564063316

Epoch: 5| Step: 7
Training loss: 1.5920162868816805
Validation loss: 2.585261720419218

Epoch: 5| Step: 8
Training loss: 1.673947912000569
Validation loss: 2.5438278141190085

Epoch: 5| Step: 9
Training loss: 1.4150660204902779
Validation loss: 2.5167170081604096

Epoch: 5| Step: 10
Training loss: 1.2506212121390459
Validation loss: 2.5022542572991933

Epoch: 340| Step: 0
Training loss: 1.2415302385142062
Validation loss: 2.5278154825464143

Epoch: 5| Step: 1
Training loss: 1.6709710645470397
Validation loss: 2.534777224664059

Epoch: 5| Step: 2
Training loss: 1.3087636808829837
Validation loss: 2.558556531459927

Epoch: 5| Step: 3
Training loss: 1.5063406920928968
Validation loss: 2.5917558571671098

Epoch: 5| Step: 4
Training loss: 1.7402524593967748
Validation loss: 2.6269515752721073

Epoch: 5| Step: 5
Training loss: 1.1685971512013709
Validation loss: 2.6265584262233292

Epoch: 5| Step: 6
Training loss: 1.8069296775733787
Validation loss: 2.626566638657658

Epoch: 5| Step: 7
Training loss: 1.457046795064109
Validation loss: 2.602280268155265

Epoch: 5| Step: 8
Training loss: 1.8075898187462451
Validation loss: 2.5523351344604657

Epoch: 5| Step: 9
Training loss: 1.2062386191033807
Validation loss: 2.550683914913189

Epoch: 5| Step: 10
Training loss: 1.5869707772317283
Validation loss: 2.53347661752503

Epoch: 341| Step: 0
Training loss: 1.4422985096174532
Validation loss: 2.552662921024139

Epoch: 5| Step: 1
Training loss: 1.634770948248688
Validation loss: 2.5483392436684125

Epoch: 5| Step: 2
Training loss: 1.1088994040996125
Validation loss: 2.5628685084742604

Epoch: 5| Step: 3
Training loss: 0.9739408168475535
Validation loss: 2.579863430582623

Epoch: 5| Step: 4
Training loss: 1.8416179032004847
Validation loss: 2.5642731637183487

Epoch: 5| Step: 5
Training loss: 1.3766804743082814
Validation loss: 2.540550204253989

Epoch: 5| Step: 6
Training loss: 1.3889814801612133
Validation loss: 2.54165546294402

Epoch: 5| Step: 7
Training loss: 1.6102811614055061
Validation loss: 2.5672187737012555

Epoch: 5| Step: 8
Training loss: 1.377164783848748
Validation loss: 2.560226808769328

Epoch: 5| Step: 9
Training loss: 1.7379869533395922
Validation loss: 2.5585606130511174

Epoch: 5| Step: 10
Training loss: 1.811349964318686
Validation loss: 2.5725609882791995

Epoch: 342| Step: 0
Training loss: 2.0266554294241184
Validation loss: 2.5824414565110043

Epoch: 5| Step: 1
Training loss: 1.4323616241941102
Validation loss: 2.5986856635694116

Epoch: 5| Step: 2
Training loss: 1.094353917832193
Validation loss: 2.615674465326888

Epoch: 5| Step: 3
Training loss: 1.6049371660714178
Validation loss: 2.6259285114302786

Epoch: 5| Step: 4
Training loss: 1.3689348662091172
Validation loss: 2.623796915877538

Epoch: 5| Step: 5
Training loss: 1.3815031587755813
Validation loss: 2.5732424285970126

Epoch: 5| Step: 6
Training loss: 1.7185316467301346
Validation loss: 2.5495261088774965

Epoch: 5| Step: 7
Training loss: 1.6171013998064128
Validation loss: 2.502475565983576

Epoch: 5| Step: 8
Training loss: 0.9682843104202242
Validation loss: 2.511788179222671

Epoch: 5| Step: 9
Training loss: 1.5168119678831968
Validation loss: 2.516062012770609

Epoch: 5| Step: 10
Training loss: 1.5102494070465233
Validation loss: 2.497495083379352

Epoch: 343| Step: 0
Training loss: 1.4355071808393907
Validation loss: 2.5121897622282896

Epoch: 5| Step: 1
Training loss: 1.0091671378283946
Validation loss: 2.5063927869465608

Epoch: 5| Step: 2
Training loss: 1.4012130386691126
Validation loss: 2.5530066910259874

Epoch: 5| Step: 3
Training loss: 1.727815475475104
Validation loss: 2.569632000680019

Epoch: 5| Step: 4
Training loss: 1.9224494137700057
Validation loss: 2.612297079899233

Epoch: 5| Step: 5
Training loss: 1.580796652478755
Validation loss: 2.628819930094125

Epoch: 5| Step: 6
Training loss: 1.4325842356256353
Validation loss: 2.6119489260218214

Epoch: 5| Step: 7
Training loss: 1.5764215170031872
Validation loss: 2.6109237510587353

Epoch: 5| Step: 8
Training loss: 1.5695672995195036
Validation loss: 2.5861022974034915

Epoch: 5| Step: 9
Training loss: 1.363601821765371
Validation loss: 2.57388902929283

Epoch: 5| Step: 10
Training loss: 0.9152464412816957
Validation loss: 2.556604127082777

Epoch: 344| Step: 0
Training loss: 1.2987001284293687
Validation loss: 2.5607079783549525

Epoch: 5| Step: 1
Training loss: 1.745948051501321
Validation loss: 2.5559693802921344

Epoch: 5| Step: 2
Training loss: 1.433826729035871
Validation loss: 2.540560604910468

Epoch: 5| Step: 3
Training loss: 1.5384617131489875
Validation loss: 2.5631154819623294

Epoch: 5| Step: 4
Training loss: 1.6963905387573204
Validation loss: 2.573859825869917

Epoch: 5| Step: 5
Training loss: 1.4071969552668064
Validation loss: 2.571338368923877

Epoch: 5| Step: 6
Training loss: 1.5870473201261455
Validation loss: 2.5856597937653967

Epoch: 5| Step: 7
Training loss: 1.236778574958698
Validation loss: 2.5845785351963517

Epoch: 5| Step: 8
Training loss: 1.6835304478474233
Validation loss: 2.5741069309500366

Epoch: 5| Step: 9
Training loss: 1.6994860910159042
Validation loss: 2.522669212556909

Epoch: 5| Step: 10
Training loss: 0.9069577117470083
Validation loss: 2.498910065421822

Epoch: 345| Step: 0
Training loss: 1.7987211611876772
Validation loss: 2.483841482569984

Epoch: 5| Step: 1
Training loss: 1.9185480614180472
Validation loss: 2.481092971548867

Epoch: 5| Step: 2
Training loss: 1.389494447090993
Validation loss: 2.470439978879351

Epoch: 5| Step: 3
Training loss: 1.7146405423316424
Validation loss: 2.4960290504785148

Epoch: 5| Step: 4
Training loss: 1.1487568521554705
Validation loss: 2.4980896152020566

Epoch: 5| Step: 5
Training loss: 1.4448074695664437
Validation loss: 2.5246584411188975

Epoch: 5| Step: 6
Training loss: 1.449634667116539
Validation loss: 2.557359609362753

Epoch: 5| Step: 7
Training loss: 1.2512514049205838
Validation loss: 2.5792737482912735

Epoch: 5| Step: 8
Training loss: 1.4678054369536626
Validation loss: 2.6153835838032604

Epoch: 5| Step: 9
Training loss: 1.266902796586678
Validation loss: 2.6502404241840796

Epoch: 5| Step: 10
Training loss: 0.8322028757666764
Validation loss: 2.654181344810504

Epoch: 346| Step: 0
Training loss: 1.47484848408061
Validation loss: 2.6395942708804974

Epoch: 5| Step: 1
Training loss: 1.238538119752434
Validation loss: 2.6473226550276943

Epoch: 5| Step: 2
Training loss: 1.446630423453678
Validation loss: 2.628459818461947

Epoch: 5| Step: 3
Training loss: 1.408010101845656
Validation loss: 2.624111112934271

Epoch: 5| Step: 4
Training loss: 1.7113754199749633
Validation loss: 2.63450584899725

Epoch: 5| Step: 5
Training loss: 1.3459317438070277
Validation loss: 2.604332335750146

Epoch: 5| Step: 6
Training loss: 1.1331038527874584
Validation loss: 2.568174266535138

Epoch: 5| Step: 7
Training loss: 1.7931919332984427
Validation loss: 2.565729557695809

Epoch: 5| Step: 8
Training loss: 1.3819181491942234
Validation loss: 2.524030866533743

Epoch: 5| Step: 9
Training loss: 1.6805478753509033
Validation loss: 2.529560756502299

Epoch: 5| Step: 10
Training loss: 1.1966709570599703
Validation loss: 2.4676354133802225

Epoch: 347| Step: 0
Training loss: 1.5419931152031725
Validation loss: 2.473176861809722

Epoch: 5| Step: 1
Training loss: 1.293791494763709
Validation loss: 2.493144970576349

Epoch: 5| Step: 2
Training loss: 1.2568650557220882
Validation loss: 2.5025703076434445

Epoch: 5| Step: 3
Training loss: 1.7666882714563956
Validation loss: 2.511979432394835

Epoch: 5| Step: 4
Training loss: 1.9592678667436403
Validation loss: 2.480936700968698

Epoch: 5| Step: 5
Training loss: 1.2586292908266057
Validation loss: 2.5085811250439174

Epoch: 5| Step: 6
Training loss: 0.8945305170447666
Validation loss: 2.5554679558283677

Epoch: 5| Step: 7
Training loss: 1.3671324800592066
Validation loss: 2.588932550486593

Epoch: 5| Step: 8
Training loss: 1.1910159112586518
Validation loss: 2.6301060680553423

Epoch: 5| Step: 9
Training loss: 1.7856012703691087
Validation loss: 2.657112904090723

Epoch: 5| Step: 10
Training loss: 1.4359606918437942
Validation loss: 2.63909702469691

Epoch: 348| Step: 0
Training loss: 1.3054457419905938
Validation loss: 2.617966064861465

Epoch: 5| Step: 1
Training loss: 1.3334658328421778
Validation loss: 2.597249496729419

Epoch: 5| Step: 2
Training loss: 1.364705475832277
Validation loss: 2.554206020289797

Epoch: 5| Step: 3
Training loss: 1.2281138334664503
Validation loss: 2.5416428134336186

Epoch: 5| Step: 4
Training loss: 1.3004810800257744
Validation loss: 2.514564763082899

Epoch: 5| Step: 5
Training loss: 1.0637715528660332
Validation loss: 2.515053161999954

Epoch: 5| Step: 6
Training loss: 1.5495922229030108
Validation loss: 2.50090801710159

Epoch: 5| Step: 7
Training loss: 1.540534385507876
Validation loss: 2.527075342749148

Epoch: 5| Step: 8
Training loss: 1.4387382481656
Validation loss: 2.502546018929456

Epoch: 5| Step: 9
Training loss: 1.5530427446593
Validation loss: 2.495929455909552

Epoch: 5| Step: 10
Training loss: 2.1005580160714046
Validation loss: 2.4999658859140372

Epoch: 349| Step: 0
Training loss: 1.259515497970182
Validation loss: 2.5393020978763503

Epoch: 5| Step: 1
Training loss: 0.9936446056017796
Validation loss: 2.5846509566888214

Epoch: 5| Step: 2
Training loss: 1.500256993213101
Validation loss: 2.580207822130299

Epoch: 5| Step: 3
Training loss: 0.991438936216248
Validation loss: 2.6417102955946183

Epoch: 5| Step: 4
Training loss: 1.6644819563772593
Validation loss: 2.6623888550146413

Epoch: 5| Step: 5
Training loss: 1.2888707336201264
Validation loss: 2.647836427066745

Epoch: 5| Step: 6
Training loss: 1.8772235401669883
Validation loss: 2.6739527092347637

Epoch: 5| Step: 7
Training loss: 1.3832588983908316
Validation loss: 2.6408215176772556

Epoch: 5| Step: 8
Training loss: 1.703391168076588
Validation loss: 2.6140806934650906

Epoch: 5| Step: 9
Training loss: 1.9373163936125561
Validation loss: 2.5807830542337786

Epoch: 5| Step: 10
Training loss: 1.0035980582764665
Validation loss: 2.53881239802268

Epoch: 350| Step: 0
Training loss: 1.4733380022161968
Validation loss: 2.5090529173517386

Epoch: 5| Step: 1
Training loss: 1.1441450802034823
Validation loss: 2.4821821139115334

Epoch: 5| Step: 2
Training loss: 1.2578776087998755
Validation loss: 2.475328739484277

Epoch: 5| Step: 3
Training loss: 1.43485265021818
Validation loss: 2.4833404580830507

Epoch: 5| Step: 4
Training loss: 1.8357358131821584
Validation loss: 2.4721199131384712

Epoch: 5| Step: 5
Training loss: 0.926627275541057
Validation loss: 2.4767621682752945

Epoch: 5| Step: 6
Training loss: 1.5375183414512728
Validation loss: 2.4859192797244734

Epoch: 5| Step: 7
Training loss: 1.2207252927674686
Validation loss: 2.493843567596558

Epoch: 5| Step: 8
Training loss: 1.6639106215535
Validation loss: 2.4971157314974963

Epoch: 5| Step: 9
Training loss: 1.5125308356806773
Validation loss: 2.5005348904916485

Epoch: 5| Step: 10
Training loss: 1.58358786026208
Validation loss: 2.5083240172265255

Epoch: 351| Step: 0
Training loss: 1.5643042256603097
Validation loss: 2.524384936676834

Epoch: 5| Step: 1
Training loss: 1.6824917826799037
Validation loss: 2.532327145034662

Epoch: 5| Step: 2
Training loss: 1.4570778028808453
Validation loss: 2.522063642982787

Epoch: 5| Step: 3
Training loss: 1.3452578667547315
Validation loss: 2.5128048455794625

Epoch: 5| Step: 4
Training loss: 1.8547037896820444
Validation loss: 2.5019703063684866

Epoch: 5| Step: 5
Training loss: 1.1170357020827393
Validation loss: 2.5120134537504226

Epoch: 5| Step: 6
Training loss: 1.244717977516046
Validation loss: 2.5324726673815903

Epoch: 5| Step: 7
Training loss: 0.947942873134892
Validation loss: 2.523819272549013

Epoch: 5| Step: 8
Training loss: 1.4270731050816263
Validation loss: 2.552878409707406

Epoch: 5| Step: 9
Training loss: 1.5392391664992093
Validation loss: 2.5585465366190965

Epoch: 5| Step: 10
Training loss: 1.148317707068025
Validation loss: 2.5430261421384013

Epoch: 352| Step: 0
Training loss: 1.0665432908311978
Validation loss: 2.5407329819974884

Epoch: 5| Step: 1
Training loss: 1.6226729824211774
Validation loss: 2.508236022011164

Epoch: 5| Step: 2
Training loss: 1.749500543982941
Validation loss: 2.516848913090492

Epoch: 5| Step: 3
Training loss: 1.2881086577406518
Validation loss: 2.5137715605659574

Epoch: 5| Step: 4
Training loss: 1.6445953284168384
Validation loss: 2.483960145476925

Epoch: 5| Step: 5
Training loss: 1.381026067748772
Validation loss: 2.4915038858355705

Epoch: 5| Step: 6
Training loss: 1.3189532715398975
Validation loss: 2.502345520983775

Epoch: 5| Step: 7
Training loss: 1.164814085553881
Validation loss: 2.497162801503192

Epoch: 5| Step: 8
Training loss: 1.2651487796728262
Validation loss: 2.51738753751284

Epoch: 5| Step: 9
Training loss: 1.462166661804772
Validation loss: 2.5151293569547346

Epoch: 5| Step: 10
Training loss: 1.1856386755605544
Validation loss: 2.5065440185919727

Epoch: 353| Step: 0
Training loss: 1.1302270257813332
Validation loss: 2.5183554671328583

Epoch: 5| Step: 1
Training loss: 1.5517621145314815
Validation loss: 2.5294414162695174

Epoch: 5| Step: 2
Training loss: 1.6590641513628708
Validation loss: 2.528255642702137

Epoch: 5| Step: 3
Training loss: 1.4805714916320307
Validation loss: 2.5470110008074034

Epoch: 5| Step: 4
Training loss: 1.2855575537897301
Validation loss: 2.5394765521642424

Epoch: 5| Step: 5
Training loss: 1.3846951616058483
Validation loss: 2.5649851971568363

Epoch: 5| Step: 6
Training loss: 1.190105090429614
Validation loss: 2.555188786659417

Epoch: 5| Step: 7
Training loss: 1.039975446447885
Validation loss: 2.5687684254516547

Epoch: 5| Step: 8
Training loss: 1.3850167158474587
Validation loss: 2.5627468279383345

Epoch: 5| Step: 9
Training loss: 1.1475790539273611
Validation loss: 2.5330071770671636

Epoch: 5| Step: 10
Training loss: 1.9871503990322483
Validation loss: 2.502647782046273

Epoch: 354| Step: 0
Training loss: 1.5812899889808631
Validation loss: 2.4873027477402347

Epoch: 5| Step: 1
Training loss: 1.4151932215781118
Validation loss: 2.464229040806899

Epoch: 5| Step: 2
Training loss: 1.9073480039061463
Validation loss: 2.4829025037572983

Epoch: 5| Step: 3
Training loss: 1.1532726617154037
Validation loss: 2.489139406264567

Epoch: 5| Step: 4
Training loss: 1.5951985526792873
Validation loss: 2.512117198894704

Epoch: 5| Step: 5
Training loss: 1.1083187393910323
Validation loss: 2.489111746296921

Epoch: 5| Step: 6
Training loss: 0.796596628073821
Validation loss: 2.4846608173004103

Epoch: 5| Step: 7
Training loss: 1.356266281803685
Validation loss: 2.483449817173857

Epoch: 5| Step: 8
Training loss: 1.4254445971878738
Validation loss: 2.4777298449566065

Epoch: 5| Step: 9
Training loss: 1.3641010868867698
Validation loss: 2.4671972876676374

Epoch: 5| Step: 10
Training loss: 1.1437230299808043
Validation loss: 2.5085849982256176

Epoch: 355| Step: 0
Training loss: 1.2762339492520844
Validation loss: 2.4776512364835948

Epoch: 5| Step: 1
Training loss: 1.1280848276694304
Validation loss: 2.479876830078721

Epoch: 5| Step: 2
Training loss: 1.0257024962851655
Validation loss: 2.520615769078231

Epoch: 5| Step: 3
Training loss: 1.8191982018531494
Validation loss: 2.545939440944795

Epoch: 5| Step: 4
Training loss: 1.2074057482626979
Validation loss: 2.5480066751225343

Epoch: 5| Step: 5
Training loss: 1.3673841062598775
Validation loss: 2.535264427670193

Epoch: 5| Step: 6
Training loss: 1.3632294828101152
Validation loss: 2.5721801770529513

Epoch: 5| Step: 7
Training loss: 1.400848994662038
Validation loss: 2.571825799000537

Epoch: 5| Step: 8
Training loss: 1.6603706490694359
Validation loss: 2.5543894648322976

Epoch: 5| Step: 9
Training loss: 1.3066712790686756
Validation loss: 2.548972948689042

Epoch: 5| Step: 10
Training loss: 1.2683569538926307
Validation loss: 2.5293353227765625

Epoch: 356| Step: 0
Training loss: 1.8394326562688406
Validation loss: 2.5173314835772507

Epoch: 5| Step: 1
Training loss: 1.144712570461589
Validation loss: 2.5168280828103455

Epoch: 5| Step: 2
Training loss: 1.2483549260223064
Validation loss: 2.514888723959498

Epoch: 5| Step: 3
Training loss: 1.5304621791260409
Validation loss: 2.5303012736517574

Epoch: 5| Step: 4
Training loss: 1.372532103672024
Validation loss: 2.5109346740630385

Epoch: 5| Step: 5
Training loss: 1.452736915530768
Validation loss: 2.5348052995992476

Epoch: 5| Step: 6
Training loss: 1.1784646978808089
Validation loss: 2.5264230003705097

Epoch: 5| Step: 7
Training loss: 1.0101606824737803
Validation loss: 2.493857120550214

Epoch: 5| Step: 8
Training loss: 1.0684021099128298
Validation loss: 2.4931947766737097

Epoch: 5| Step: 9
Training loss: 1.3690664404607966
Validation loss: 2.460553245410573

Epoch: 5| Step: 10
Training loss: 1.5493627253358182
Validation loss: 2.473595867103984

Epoch: 357| Step: 0
Training loss: 1.4875746924616813
Validation loss: 2.4687173253725927

Epoch: 5| Step: 1
Training loss: 1.6117515423795297
Validation loss: 2.443750129705788

Epoch: 5| Step: 2
Training loss: 0.8724474118296378
Validation loss: 2.4982732285284115

Epoch: 5| Step: 3
Training loss: 1.2533045480767224
Validation loss: 2.452944044842338

Epoch: 5| Step: 4
Training loss: 1.0252965684168642
Validation loss: 2.4863408156855527

Epoch: 5| Step: 5
Training loss: 0.8495039249619132
Validation loss: 2.4856292980092087

Epoch: 5| Step: 6
Training loss: 1.4569128566227296
Validation loss: 2.4973455939831606

Epoch: 5| Step: 7
Training loss: 1.6261550026429983
Validation loss: 2.4758930558578975

Epoch: 5| Step: 8
Training loss: 1.6642445925807678
Validation loss: 2.4931617982530025

Epoch: 5| Step: 9
Training loss: 1.3109059417527096
Validation loss: 2.5127669353062445

Epoch: 5| Step: 10
Training loss: 1.296839794002792
Validation loss: 2.5072607410261085

Epoch: 358| Step: 0
Training loss: 1.7952886461975672
Validation loss: 2.5267551822982197

Epoch: 5| Step: 1
Training loss: 1.137852997555493
Validation loss: 2.5028765454641713

Epoch: 5| Step: 2
Training loss: 1.4565229168341924
Validation loss: 2.4987222215823555

Epoch: 5| Step: 3
Training loss: 1.1271097745396919
Validation loss: 2.50522165425181

Epoch: 5| Step: 4
Training loss: 1.455269000955776
Validation loss: 2.4800223217104174

Epoch: 5| Step: 5
Training loss: 1.1969670332541347
Validation loss: 2.4940054477973224

Epoch: 5| Step: 6
Training loss: 0.9258918857056991
Validation loss: 2.4941440755414708

Epoch: 5| Step: 7
Training loss: 1.6966621897750178
Validation loss: 2.5009772574877642

Epoch: 5| Step: 8
Training loss: 1.229198660137813
Validation loss: 2.5054477903564663

Epoch: 5| Step: 9
Training loss: 1.1687119584853825
Validation loss: 2.5150949058108836

Epoch: 5| Step: 10
Training loss: 1.246006116506097
Validation loss: 2.5162011089846303

Epoch: 359| Step: 0
Training loss: 1.3720710944448395
Validation loss: 2.517007425365549

Epoch: 5| Step: 1
Training loss: 1.7136083510698479
Validation loss: 2.508633068102836

Epoch: 5| Step: 2
Training loss: 1.3058928900459341
Validation loss: 2.4498091260244843

Epoch: 5| Step: 3
Training loss: 1.3124047199360884
Validation loss: 2.4513092312373526

Epoch: 5| Step: 4
Training loss: 1.2588734387632492
Validation loss: 2.455076333118556

Epoch: 5| Step: 5
Training loss: 1.3887486604260044
Validation loss: 2.458901975871785

Epoch: 5| Step: 6
Training loss: 1.4268506363916187
Validation loss: 2.4363629371223783

Epoch: 5| Step: 7
Training loss: 1.4931577553874724
Validation loss: 2.4514066656847526

Epoch: 5| Step: 8
Training loss: 0.9234972758560194
Validation loss: 2.471334590207818

Epoch: 5| Step: 9
Training loss: 1.3730869423024608
Validation loss: 2.494531560407805

Epoch: 5| Step: 10
Training loss: 0.7448581230196424
Validation loss: 2.4864990437525427

Epoch: 360| Step: 0
Training loss: 1.2003039690313908
Validation loss: 2.505086329977221

Epoch: 5| Step: 1
Training loss: 1.0818662552064178
Validation loss: 2.5268386792863664

Epoch: 5| Step: 2
Training loss: 1.6350529827200952
Validation loss: 2.550467440706165

Epoch: 5| Step: 3
Training loss: 1.232614783228943
Validation loss: 2.5397431249373126

Epoch: 5| Step: 4
Training loss: 1.001340444530256
Validation loss: 2.540376665334259

Epoch: 5| Step: 5
Training loss: 1.544263542719888
Validation loss: 2.5167831784552375

Epoch: 5| Step: 6
Training loss: 0.9108028816223631
Validation loss: 2.5052738317151886

Epoch: 5| Step: 7
Training loss: 1.4121534833970673
Validation loss: 2.508589402812844

Epoch: 5| Step: 8
Training loss: 1.2306825966673653
Validation loss: 2.513733056784165

Epoch: 5| Step: 9
Training loss: 1.6016969205689657
Validation loss: 2.499150796450401

Epoch: 5| Step: 10
Training loss: 1.4775018681031888
Validation loss: 2.4919801226438607

Epoch: 361| Step: 0
Training loss: 1.2375643125834517
Validation loss: 2.4794257664476844

Epoch: 5| Step: 1
Training loss: 1.0946588827101138
Validation loss: 2.488205219418971

Epoch: 5| Step: 2
Training loss: 1.2935948080700619
Validation loss: 2.4931995670532854

Epoch: 5| Step: 3
Training loss: 1.0552636727335443
Validation loss: 2.492982758905238

Epoch: 5| Step: 4
Training loss: 1.3109822353145846
Validation loss: 2.487583354036333

Epoch: 5| Step: 5
Training loss: 1.590668185683935
Validation loss: 2.4803120514590633

Epoch: 5| Step: 6
Training loss: 1.7788772841999057
Validation loss: 2.494400112545851

Epoch: 5| Step: 7
Training loss: 1.3163978282081774
Validation loss: 2.4820081751864964

Epoch: 5| Step: 8
Training loss: 1.2315926883368968
Validation loss: 2.4995133613384697

Epoch: 5| Step: 9
Training loss: 1.171860351470946
Validation loss: 2.5135864648193937

Epoch: 5| Step: 10
Training loss: 1.2001480329123237
Validation loss: 2.517827095313498

Epoch: 362| Step: 0
Training loss: 1.2034020043078573
Validation loss: 2.537828234733414

Epoch: 5| Step: 1
Training loss: 1.5762616478219627
Validation loss: 2.5232985288815417

Epoch: 5| Step: 2
Training loss: 1.3318936453077603
Validation loss: 2.5299319572026207

Epoch: 5| Step: 3
Training loss: 1.529970997304849
Validation loss: 2.520666717118745

Epoch: 5| Step: 4
Training loss: 0.648568450390194
Validation loss: 2.5320571064364077

Epoch: 5| Step: 5
Training loss: 1.0905557036587323
Validation loss: 2.495160703261732

Epoch: 5| Step: 6
Training loss: 1.7753393251836274
Validation loss: 2.506076711275928

Epoch: 5| Step: 7
Training loss: 1.1230742078025764
Validation loss: 2.510860665449568

Epoch: 5| Step: 8
Training loss: 1.2749801839896748
Validation loss: 2.51302903662993

Epoch: 5| Step: 9
Training loss: 0.9064733953385526
Validation loss: 2.5151940854830688

Epoch: 5| Step: 10
Training loss: 1.5349032360977515
Validation loss: 2.4987697537875446

Epoch: 363| Step: 0
Training loss: 0.7530966646554444
Validation loss: 2.5220611973179534

Epoch: 5| Step: 1
Training loss: 1.6049650195579082
Validation loss: 2.507156481007118

Epoch: 5| Step: 2
Training loss: 1.2043430553370829
Validation loss: 2.509224769854979

Epoch: 5| Step: 3
Training loss: 1.2223858031468315
Validation loss: 2.5079064788449785

Epoch: 5| Step: 4
Training loss: 1.8191436158119405
Validation loss: 2.5015049537204512

Epoch: 5| Step: 5
Training loss: 1.3419377282187617
Validation loss: 2.521958193642075

Epoch: 5| Step: 6
Training loss: 1.210867996682299
Validation loss: 2.52469825724557

Epoch: 5| Step: 7
Training loss: 1.383964446697125
Validation loss: 2.5192930281437382

Epoch: 5| Step: 8
Training loss: 1.1942112655634707
Validation loss: 2.5191983312634223

Epoch: 5| Step: 9
Training loss: 0.8881761446782529
Validation loss: 2.5107067520766053

Epoch: 5| Step: 10
Training loss: 1.3735648381524495
Validation loss: 2.515185932906306

Epoch: 364| Step: 0
Training loss: 1.5462350773997138
Validation loss: 2.5240738045926494

Epoch: 5| Step: 1
Training loss: 1.2431941721731734
Validation loss: 2.5288184177087545

Epoch: 5| Step: 2
Training loss: 1.114971123137547
Validation loss: 2.5198909623888497

Epoch: 5| Step: 3
Training loss: 1.251939080169977
Validation loss: 2.522387431216524

Epoch: 5| Step: 4
Training loss: 1.3957150774533909
Validation loss: 2.5345645696122716

Epoch: 5| Step: 5
Training loss: 1.089789604564756
Validation loss: 2.503837963984885

Epoch: 5| Step: 6
Training loss: 1.161973397129337
Validation loss: 2.518200033784381

Epoch: 5| Step: 7
Training loss: 1.674468551135391
Validation loss: 2.5179013746462293

Epoch: 5| Step: 8
Training loss: 1.08750769075327
Validation loss: 2.517160026676521

Epoch: 5| Step: 9
Training loss: 1.1816744208428942
Validation loss: 2.5222038510357496

Epoch: 5| Step: 10
Training loss: 1.3251028344897071
Validation loss: 2.5011031393425878

Epoch: 365| Step: 0
Training loss: 1.2285165953518624
Validation loss: 2.5224744413768847

Epoch: 5| Step: 1
Training loss: 1.276041142470064
Validation loss: 2.5303419077639213

Epoch: 5| Step: 2
Training loss: 1.125637033028599
Validation loss: 2.5202669308906827

Epoch: 5| Step: 3
Training loss: 1.3152148008235376
Validation loss: 2.522712773364058

Epoch: 5| Step: 4
Training loss: 0.9982050940112109
Validation loss: 2.5405939398022332

Epoch: 5| Step: 5
Training loss: 1.921623709772821
Validation loss: 2.5207000994849325

Epoch: 5| Step: 6
Training loss: 1.1269591544533788
Validation loss: 2.542411253012245

Epoch: 5| Step: 7
Training loss: 0.9685291530768716
Validation loss: 2.518021173745861

Epoch: 5| Step: 8
Training loss: 0.9704076674226852
Validation loss: 2.5310292068537277

Epoch: 5| Step: 9
Training loss: 1.4731190407089867
Validation loss: 2.493594588870907

Epoch: 5| Step: 10
Training loss: 1.3606542947372735
Validation loss: 2.483724409738329

Epoch: 366| Step: 0
Training loss: 0.9695580711620154
Validation loss: 2.4860936944872076

Epoch: 5| Step: 1
Training loss: 1.0322241372591543
Validation loss: 2.4892336956474703

Epoch: 5| Step: 2
Training loss: 1.4465851001041252
Validation loss: 2.5065762149573603

Epoch: 5| Step: 3
Training loss: 1.340645686347904
Validation loss: 2.4946988208576246

Epoch: 5| Step: 4
Training loss: 1.387974731748489
Validation loss: 2.5029206566189592

Epoch: 5| Step: 5
Training loss: 1.3112191808113407
Validation loss: 2.4931029826371005

Epoch: 5| Step: 6
Training loss: 1.0652630725515952
Validation loss: 2.5109156437476043

Epoch: 5| Step: 7
Training loss: 1.023894113497537
Validation loss: 2.52288239979454

Epoch: 5| Step: 8
Training loss: 1.7576734021570994
Validation loss: 2.5132205391351707

Epoch: 5| Step: 9
Training loss: 1.1771707530459556
Validation loss: 2.5178872852308425

Epoch: 5| Step: 10
Training loss: 1.3215234834689562
Validation loss: 2.5238451280352567

Epoch: 367| Step: 0
Training loss: 1.4064025796131003
Validation loss: 2.508059680916782

Epoch: 5| Step: 1
Training loss: 0.9372336963081094
Validation loss: 2.4695027746940608

Epoch: 5| Step: 2
Training loss: 0.9680624336923875
Validation loss: 2.4817954470881776

Epoch: 5| Step: 3
Training loss: 1.1766468803067762
Validation loss: 2.4416141271547

Epoch: 5| Step: 4
Training loss: 1.057724824819032
Validation loss: 2.4472895530904046

Epoch: 5| Step: 5
Training loss: 1.281346898950528
Validation loss: 2.466081156190448

Epoch: 5| Step: 6
Training loss: 1.2981971068322256
Validation loss: 2.458382635385208

Epoch: 5| Step: 7
Training loss: 1.2918924421471882
Validation loss: 2.451641864705394

Epoch: 5| Step: 8
Training loss: 1.4131696210967466
Validation loss: 2.5108579760796865

Epoch: 5| Step: 9
Training loss: 1.6537795445808292
Validation loss: 2.471727822717664

Epoch: 5| Step: 10
Training loss: 1.3926268752287219
Validation loss: 2.483702007290187

Epoch: 368| Step: 0
Training loss: 0.9414059334275596
Validation loss: 2.5253617226078373

Epoch: 5| Step: 1
Training loss: 1.639243134326412
Validation loss: 2.522586100941966

Epoch: 5| Step: 2
Training loss: 1.7418224824749857
Validation loss: 2.5401555361421626

Epoch: 5| Step: 3
Training loss: 1.122268433505938
Validation loss: 2.5601282105767336

Epoch: 5| Step: 4
Training loss: 1.3321772967956091
Validation loss: 2.5565322287328116

Epoch: 5| Step: 5
Training loss: 1.4787050072991064
Validation loss: 2.534260215651876

Epoch: 5| Step: 6
Training loss: 0.8976416338468524
Validation loss: 2.5053011362155764

Epoch: 5| Step: 7
Training loss: 1.0430562414840654
Validation loss: 2.45679462290584

Epoch: 5| Step: 8
Training loss: 0.8944188343025264
Validation loss: 2.473034210055768

Epoch: 5| Step: 9
Training loss: 0.9999097843006962
Validation loss: 2.439707161408631

Epoch: 5| Step: 10
Training loss: 1.4080385913572404
Validation loss: 2.4566354166511273

Epoch: 369| Step: 0
Training loss: 0.9665139757340846
Validation loss: 2.4419405896272206

Epoch: 5| Step: 1
Training loss: 1.0591240149513328
Validation loss: 2.434126118401528

Epoch: 5| Step: 2
Training loss: 1.197434729228798
Validation loss: 2.410732349150766

Epoch: 5| Step: 3
Training loss: 1.077031451709086
Validation loss: 2.4271037290003905

Epoch: 5| Step: 4
Training loss: 1.2333469213991577
Validation loss: 2.457501998945787

Epoch: 5| Step: 5
Training loss: 1.279748641755415
Validation loss: 2.44274212444136

Epoch: 5| Step: 6
Training loss: 1.8759858400749898
Validation loss: 2.4683191046191433

Epoch: 5| Step: 7
Training loss: 1.450286389711569
Validation loss: 2.495066424145745

Epoch: 5| Step: 8
Training loss: 1.1745959419114136
Validation loss: 2.515570967429067

Epoch: 5| Step: 9
Training loss: 1.1174643113584115
Validation loss: 2.508154077236223

Epoch: 5| Step: 10
Training loss: 1.0567105141476278
Validation loss: 2.5533688767828755

Epoch: 370| Step: 0
Training loss: 1.382254191477301
Validation loss: 2.557176516238807

Epoch: 5| Step: 1
Training loss: 1.3859829092059184
Validation loss: 2.5639515488968474

Epoch: 5| Step: 2
Training loss: 1.9462705038040475
Validation loss: 2.5452467223344555

Epoch: 5| Step: 3
Training loss: 1.3180498678211745
Validation loss: 2.519544825541566

Epoch: 5| Step: 4
Training loss: 1.4131826540335095
Validation loss: 2.508646905982334

Epoch: 5| Step: 5
Training loss: 1.0744050575299215
Validation loss: 2.4959861281161726

Epoch: 5| Step: 6
Training loss: 1.0431596674109633
Validation loss: 2.500336820206266

Epoch: 5| Step: 7
Training loss: 1.0190338441433844
Validation loss: 2.469360339461214

Epoch: 5| Step: 8
Training loss: 0.6650775332533934
Validation loss: 2.4742047531812874

Epoch: 5| Step: 9
Training loss: 0.9388331788618964
Validation loss: 2.447302938556139

Epoch: 5| Step: 10
Training loss: 0.9047163779174365
Validation loss: 2.4806293906111083

Epoch: 371| Step: 0
Training loss: 1.021662446760597
Validation loss: 2.491385592007113

Epoch: 5| Step: 1
Training loss: 1.182937591267339
Validation loss: 2.4860480473104922

Epoch: 5| Step: 2
Training loss: 1.041969191807817
Validation loss: 2.502279276256065

Epoch: 5| Step: 3
Training loss: 1.012698431939054
Validation loss: 2.5055006957253507

Epoch: 5| Step: 4
Training loss: 1.3653396325745282
Validation loss: 2.517456464157922

Epoch: 5| Step: 5
Training loss: 1.2240977214686384
Validation loss: 2.510525751396867

Epoch: 5| Step: 6
Training loss: 1.2322645374105379
Validation loss: 2.547700972616927

Epoch: 5| Step: 7
Training loss: 1.2179214399837814
Validation loss: 2.502732938634834

Epoch: 5| Step: 8
Training loss: 1.6563173676231373
Validation loss: 2.5529365651859

Epoch: 5| Step: 9
Training loss: 1.1426606498976786
Validation loss: 2.563718134578934

Epoch: 5| Step: 10
Training loss: 1.2510416935590645
Validation loss: 2.5668686354873564

Epoch: 372| Step: 0
Training loss: 1.4347352516704481
Validation loss: 2.5352170417307924

Epoch: 5| Step: 1
Training loss: 1.325672578151172
Validation loss: 2.521415927542835

Epoch: 5| Step: 2
Training loss: 1.1453296363454117
Validation loss: 2.5059287215467054

Epoch: 5| Step: 3
Training loss: 0.9574621981935075
Validation loss: 2.4910992578180298

Epoch: 5| Step: 4
Training loss: 0.803657761734758
Validation loss: 2.4888459133507626

Epoch: 5| Step: 5
Training loss: 1.496888908050846
Validation loss: 2.496974400139599

Epoch: 5| Step: 6
Training loss: 1.110233189858208
Validation loss: 2.514656967497473

Epoch: 5| Step: 7
Training loss: 1.1815156728711529
Validation loss: 2.485442268909419

Epoch: 5| Step: 8
Training loss: 1.347909566319124
Validation loss: 2.518508354232586

Epoch: 5| Step: 9
Training loss: 1.0209730921981617
Validation loss: 2.517668935031424

Epoch: 5| Step: 10
Training loss: 1.292579845935717
Validation loss: 2.530626160114578

Epoch: 373| Step: 0
Training loss: 0.9542081962665195
Validation loss: 2.543953614265369

Epoch: 5| Step: 1
Training loss: 1.4347251148980469
Validation loss: 2.575906899523281

Epoch: 5| Step: 2
Training loss: 1.4744303815724091
Validation loss: 2.5614681112114503

Epoch: 5| Step: 3
Training loss: 1.0609092023218996
Validation loss: 2.5782947115260524

Epoch: 5| Step: 4
Training loss: 1.084581914943061
Validation loss: 2.5491531805372625

Epoch: 5| Step: 5
Training loss: 1.3227179020022686
Validation loss: 2.548691721241173

Epoch: 5| Step: 6
Training loss: 0.9701022585324369
Validation loss: 2.5265610771812663

Epoch: 5| Step: 7
Training loss: 1.1790736034769316
Validation loss: 2.5316922606492165

Epoch: 5| Step: 8
Training loss: 1.0220727338421418
Validation loss: 2.5055213029876664

Epoch: 5| Step: 9
Training loss: 0.9518309704622057
Validation loss: 2.485382393849764

Epoch: 5| Step: 10
Training loss: 1.5873931067816074
Validation loss: 2.4999164280202524

Epoch: 374| Step: 0
Training loss: 0.9958997649748611
Validation loss: 2.477916563321918

Epoch: 5| Step: 1
Training loss: 1.4769633722845223
Validation loss: 2.4874291876409034

Epoch: 5| Step: 2
Training loss: 1.226712260245509
Validation loss: 2.4870167753501407

Epoch: 5| Step: 3
Training loss: 1.1590024817492004
Validation loss: 2.5179884629553344

Epoch: 5| Step: 4
Training loss: 0.8811799204131255
Validation loss: 2.4927284902610385

Epoch: 5| Step: 5
Training loss: 1.3320375593377196
Validation loss: 2.521200339106301

Epoch: 5| Step: 6
Training loss: 1.2857354432968866
Validation loss: 2.5245610869224158

Epoch: 5| Step: 7
Training loss: 0.9742812099180865
Validation loss: 2.521628915739363

Epoch: 5| Step: 8
Training loss: 1.1653069622207946
Validation loss: 2.5363700713043067

Epoch: 5| Step: 9
Training loss: 1.3611595016536289
Validation loss: 2.5353433904708695

Epoch: 5| Step: 10
Training loss: 1.1079796087991465
Validation loss: 2.5319729077430146

Epoch: 375| Step: 0
Training loss: 0.9856079191519072
Validation loss: 2.5055538910727613

Epoch: 5| Step: 1
Training loss: 1.3696814759853286
Validation loss: 2.5048276536841994

Epoch: 5| Step: 2
Training loss: 0.9947506395171575
Validation loss: 2.482245703658319

Epoch: 5| Step: 3
Training loss: 1.131533565072284
Validation loss: 2.484236000482313

Epoch: 5| Step: 4
Training loss: 1.2627187728177558
Validation loss: 2.479567570757249

Epoch: 5| Step: 5
Training loss: 1.3152439408256094
Validation loss: 2.482187792334568

Epoch: 5| Step: 6
Training loss: 1.13351019059065
Validation loss: 2.473129062664748

Epoch: 5| Step: 7
Training loss: 1.5185115108914113
Validation loss: 2.4998766161096904

Epoch: 5| Step: 8
Training loss: 0.9306261469191535
Validation loss: 2.5123528021667543

Epoch: 5| Step: 9
Training loss: 1.152710419848358
Validation loss: 2.5278301464222745

Epoch: 5| Step: 10
Training loss: 1.1257677637334123
Validation loss: 2.5231271645206514

Epoch: 376| Step: 0
Training loss: 1.226452913673539
Validation loss: 2.532747645738141

Epoch: 5| Step: 1
Training loss: 1.32919331387363
Validation loss: 2.521785043533011

Epoch: 5| Step: 2
Training loss: 1.276935197080625
Validation loss: 2.5172580367954454

Epoch: 5| Step: 3
Training loss: 0.8399584669676361
Validation loss: 2.5294590844032836

Epoch: 5| Step: 4
Training loss: 1.6206687278159082
Validation loss: 2.535416226392842

Epoch: 5| Step: 5
Training loss: 1.0936038873352245
Validation loss: 2.523045805504944

Epoch: 5| Step: 6
Training loss: 0.7822349443117567
Validation loss: 2.5478435028491666

Epoch: 5| Step: 7
Training loss: 1.40573559995491
Validation loss: 2.5565817234930184

Epoch: 5| Step: 8
Training loss: 1.0971303202506721
Validation loss: 2.566945787181121

Epoch: 5| Step: 9
Training loss: 0.7819860043236704
Validation loss: 2.5235613390589866

Epoch: 5| Step: 10
Training loss: 1.143005291243193
Validation loss: 2.5176678353107844

Epoch: 377| Step: 0
Training loss: 1.0215349057246608
Validation loss: 2.5045395183222348

Epoch: 5| Step: 1
Training loss: 1.4091015197264916
Validation loss: 2.502311118203026

Epoch: 5| Step: 2
Training loss: 0.9748910561853598
Validation loss: 2.4912582343254033

Epoch: 5| Step: 3
Training loss: 1.1868058735833593
Validation loss: 2.473093473926212

Epoch: 5| Step: 4
Training loss: 1.1722143063471298
Validation loss: 2.4976276103367008

Epoch: 5| Step: 5
Training loss: 1.3194211400076539
Validation loss: 2.4912033614450086

Epoch: 5| Step: 6
Training loss: 1.0072596016599238
Validation loss: 2.5030197773838867

Epoch: 5| Step: 7
Training loss: 0.9664673523023973
Validation loss: 2.5184486667539447

Epoch: 5| Step: 8
Training loss: 1.1703686505892772
Validation loss: 2.5213943144714035

Epoch: 5| Step: 9
Training loss: 1.0990607348035533
Validation loss: 2.5307273796176246

Epoch: 5| Step: 10
Training loss: 1.516307480517399
Validation loss: 2.5256486741556823

Epoch: 378| Step: 0
Training loss: 1.2309624060120412
Validation loss: 2.5341945512689654

Epoch: 5| Step: 1
Training loss: 1.2117457491967576
Validation loss: 2.5524127535810863

Epoch: 5| Step: 2
Training loss: 1.7232912584305233
Validation loss: 2.5144074630565627

Epoch: 5| Step: 3
Training loss: 0.9600761709194147
Validation loss: 2.5319058647079555

Epoch: 5| Step: 4
Training loss: 1.1137491949316127
Validation loss: 2.5452393413659813

Epoch: 5| Step: 5
Training loss: 1.0328986543164853
Validation loss: 2.5308208387880073

Epoch: 5| Step: 6
Training loss: 1.0260821816954209
Validation loss: 2.5247425354609767

Epoch: 5| Step: 7
Training loss: 0.9427266654801606
Validation loss: 2.502195015059179

Epoch: 5| Step: 8
Training loss: 0.9883595009685264
Validation loss: 2.4964753541161144

Epoch: 5| Step: 9
Training loss: 1.2380447883947048
Validation loss: 2.509122293645643

Epoch: 5| Step: 10
Training loss: 1.0701365082554979
Validation loss: 2.5184455732191116

Epoch: 379| Step: 0
Training loss: 1.2917261520142282
Validation loss: 2.4961085807173164

Epoch: 5| Step: 1
Training loss: 1.248479442822871
Validation loss: 2.5206943786556515

Epoch: 5| Step: 2
Training loss: 0.9949257379164065
Validation loss: 2.5325909183134536

Epoch: 5| Step: 3
Training loss: 1.3640556431408997
Validation loss: 2.5336889348774836

Epoch: 5| Step: 4
Training loss: 1.105194489119407
Validation loss: 2.5300934272473374

Epoch: 5| Step: 5
Training loss: 1.300421862744127
Validation loss: 2.524726776298892

Epoch: 5| Step: 6
Training loss: 0.5606760813173611
Validation loss: 2.502294131783673

Epoch: 5| Step: 7
Training loss: 0.9854442904406483
Validation loss: 2.511539774937753

Epoch: 5| Step: 8
Training loss: 1.062326922063889
Validation loss: 2.5061032970954176

Epoch: 5| Step: 9
Training loss: 0.9673900903573965
Validation loss: 2.5333909723863024

Epoch: 5| Step: 10
Training loss: 1.6143991508848379
Validation loss: 2.5741462312019596

Epoch: 380| Step: 0
Training loss: 0.86622497478409
Validation loss: 2.6020124231689694

Epoch: 5| Step: 1
Training loss: 1.403814835244277
Validation loss: 2.587458972745345

Epoch: 5| Step: 2
Training loss: 1.2759689725553478
Validation loss: 2.560586546568061

Epoch: 5| Step: 3
Training loss: 1.6102209738022468
Validation loss: 2.5061843714134318

Epoch: 5| Step: 4
Training loss: 1.1708226883337587
Validation loss: 2.503571528944514

Epoch: 5| Step: 5
Training loss: 1.450481265867873
Validation loss: 2.490249824580557

Epoch: 5| Step: 6
Training loss: 0.8865172707628312
Validation loss: 2.4886224685674225

Epoch: 5| Step: 7
Training loss: 0.79593659291929
Validation loss: 2.508042067999819

Epoch: 5| Step: 8
Training loss: 0.9080078571374546
Validation loss: 2.506844461355929

Epoch: 5| Step: 9
Training loss: 0.9882178003501835
Validation loss: 2.4839545082604557

Epoch: 5| Step: 10
Training loss: 1.0175192554160915
Validation loss: 2.4890887517064653

Epoch: 381| Step: 0
Training loss: 1.3615395861981192
Validation loss: 2.501608774962959

Epoch: 5| Step: 1
Training loss: 1.2175935491540135
Validation loss: 2.506094132901487

Epoch: 5| Step: 2
Training loss: 0.9900267193300064
Validation loss: 2.507694100389911

Epoch: 5| Step: 3
Training loss: 0.9193598170164559
Validation loss: 2.486330561476422

Epoch: 5| Step: 4
Training loss: 1.1311771559050252
Validation loss: 2.503602824034151

Epoch: 5| Step: 5
Training loss: 1.296515219546491
Validation loss: 2.5016033179141153

Epoch: 5| Step: 6
Training loss: 1.1581703425845102
Validation loss: 2.5060526580730595

Epoch: 5| Step: 7
Training loss: 1.150735333906351
Validation loss: 2.5187444874261353

Epoch: 5| Step: 8
Training loss: 0.743488857360236
Validation loss: 2.5135949484451285

Epoch: 5| Step: 9
Training loss: 1.343768319293391
Validation loss: 2.5213485377058316

Epoch: 5| Step: 10
Training loss: 0.9887813765204831
Validation loss: 2.554678323937538

Epoch: 382| Step: 0
Training loss: 1.0849161628116226
Validation loss: 2.5617589972162214

Epoch: 5| Step: 1
Training loss: 1.0816910963037811
Validation loss: 2.6065065453737173

Epoch: 5| Step: 2
Training loss: 1.1673765180091615
Validation loss: 2.593572949305574

Epoch: 5| Step: 3
Training loss: 1.5249555018452283
Validation loss: 2.563517307783905

Epoch: 5| Step: 4
Training loss: 1.0877461911106077
Validation loss: 2.5400412506437124

Epoch: 5| Step: 5
Training loss: 0.8380349486217082
Validation loss: 2.5155801241054183

Epoch: 5| Step: 6
Training loss: 1.2904622194656317
Validation loss: 2.5064086603616325

Epoch: 5| Step: 7
Training loss: 1.0605467625963914
Validation loss: 2.4641779490882696

Epoch: 5| Step: 8
Training loss: 1.1907240618648411
Validation loss: 2.4987323192634565

Epoch: 5| Step: 9
Training loss: 0.8666025199136869
Validation loss: 2.4660628827277367

Epoch: 5| Step: 10
Training loss: 1.272117492278792
Validation loss: 2.4622131697812106

Epoch: 383| Step: 0
Training loss: 0.9712604480903138
Validation loss: 2.452850306561241

Epoch: 5| Step: 1
Training loss: 1.0000970912529834
Validation loss: 2.4743485362038498

Epoch: 5| Step: 2
Training loss: 1.1739455178663347
Validation loss: 2.4625227117628463

Epoch: 5| Step: 3
Training loss: 1.3558726739519702
Validation loss: 2.4770569407879424

Epoch: 5| Step: 4
Training loss: 0.7928044942978654
Validation loss: 2.480105586197553

Epoch: 5| Step: 5
Training loss: 0.8282197142365357
Validation loss: 2.4781578181484365

Epoch: 5| Step: 6
Training loss: 1.487087461822642
Validation loss: 2.479012064061219

Epoch: 5| Step: 7
Training loss: 0.9505431743069149
Validation loss: 2.513351925799941

Epoch: 5| Step: 8
Training loss: 1.133764353769574
Validation loss: 2.5595753825447574

Epoch: 5| Step: 9
Training loss: 1.150251603591156
Validation loss: 2.5669624666230346

Epoch: 5| Step: 10
Training loss: 1.4732036028718252
Validation loss: 2.5916073159027544

Epoch: 384| Step: 0
Training loss: 1.1589384012647201
Validation loss: 2.5694770760659598

Epoch: 5| Step: 1
Training loss: 1.1091694171239932
Validation loss: 2.541589430817805

Epoch: 5| Step: 2
Training loss: 1.0295763595408682
Validation loss: 2.513207617977277

Epoch: 5| Step: 3
Training loss: 0.8018892020248597
Validation loss: 2.4915795533827083

Epoch: 5| Step: 4
Training loss: 0.9817526568577668
Validation loss: 2.4751528079865537

Epoch: 5| Step: 5
Training loss: 1.6497573269494779
Validation loss: 2.4358667613455363

Epoch: 5| Step: 6
Training loss: 1.1693416423922867
Validation loss: 2.4573757248975285

Epoch: 5| Step: 7
Training loss: 1.1726718990494014
Validation loss: 2.4586953372318483

Epoch: 5| Step: 8
Training loss: 1.0372389085700258
Validation loss: 2.4774444532394204

Epoch: 5| Step: 9
Training loss: 1.1727351782843474
Validation loss: 2.453803826568976

Epoch: 5| Step: 10
Training loss: 0.7540951823152624
Validation loss: 2.4626843533100367

Epoch: 385| Step: 0
Training loss: 1.1507640808855055
Validation loss: 2.4834921061257775

Epoch: 5| Step: 1
Training loss: 1.3309911431462833
Validation loss: 2.4725092268892657

Epoch: 5| Step: 2
Training loss: 1.4133105307140084
Validation loss: 2.5458258742845223

Epoch: 5| Step: 3
Training loss: 0.7174621737541115
Validation loss: 2.5426418653291756

Epoch: 5| Step: 4
Training loss: 1.1809572876450716
Validation loss: 2.5424577723142403

Epoch: 5| Step: 5
Training loss: 1.232928237027075
Validation loss: 2.5386259197436165

Epoch: 5| Step: 6
Training loss: 1.0637850003250204
Validation loss: 2.4993932151696363

Epoch: 5| Step: 7
Training loss: 0.8457426982545273
Validation loss: 2.503782369516329

Epoch: 5| Step: 8
Training loss: 0.7388784828704129
Validation loss: 2.5010258969260213

Epoch: 5| Step: 9
Training loss: 1.0227266128614976
Validation loss: 2.476804568824461

Epoch: 5| Step: 10
Training loss: 1.2555206459015942
Validation loss: 2.458467004005145

Epoch: 386| Step: 0
Training loss: 1.0742630273190192
Validation loss: 2.4589238598582197

Epoch: 5| Step: 1
Training loss: 1.103076678722536
Validation loss: 2.451350055201728

Epoch: 5| Step: 2
Training loss: 1.3833190507419573
Validation loss: 2.4322073907084114

Epoch: 5| Step: 3
Training loss: 1.1704252303341962
Validation loss: 2.4522392680945875

Epoch: 5| Step: 4
Training loss: 0.820996208458624
Validation loss: 2.4788066581597006

Epoch: 5| Step: 5
Training loss: 1.1832350889354877
Validation loss: 2.498706402962706

Epoch: 5| Step: 6
Training loss: 1.0122521956691544
Validation loss: 2.554011861401083

Epoch: 5| Step: 7
Training loss: 0.8931357480384118
Validation loss: 2.565231803957052

Epoch: 5| Step: 8
Training loss: 0.8990671687954632
Validation loss: 2.5679932387793953

Epoch: 5| Step: 9
Training loss: 1.2524889485219974
Validation loss: 2.6069935908590023

Epoch: 5| Step: 10
Training loss: 1.276289385151451
Validation loss: 2.604964914029523

Epoch: 387| Step: 0
Training loss: 1.108190952324262
Validation loss: 2.5870612104280837

Epoch: 5| Step: 1
Training loss: 1.0367894945535185
Validation loss: 2.5377179792385034

Epoch: 5| Step: 2
Training loss: 0.8474770281781343
Validation loss: 2.508605189770996

Epoch: 5| Step: 3
Training loss: 1.1653301326269834
Validation loss: 2.496646875087007

Epoch: 5| Step: 4
Training loss: 1.3160280312564525
Validation loss: 2.501055890313505

Epoch: 5| Step: 5
Training loss: 0.9283925502479848
Validation loss: 2.4728873058293224

Epoch: 5| Step: 6
Training loss: 1.1975392562548006
Validation loss: 2.4982588149727483

Epoch: 5| Step: 7
Training loss: 0.9729882711544565
Validation loss: 2.499360205706682

Epoch: 5| Step: 8
Training loss: 0.8580926170268012
Validation loss: 2.5112766489253153

Epoch: 5| Step: 9
Training loss: 0.783139804173469
Validation loss: 2.5386616476091985

Epoch: 5| Step: 10
Training loss: 1.479748392110996
Validation loss: 2.525436820834505

Epoch: 388| Step: 0
Training loss: 1.1689015111787642
Validation loss: 2.5525682689691385

Epoch: 5| Step: 1
Training loss: 1.2030601483986485
Validation loss: 2.5642333692280035

Epoch: 5| Step: 2
Training loss: 0.6890808916124392
Validation loss: 2.540375318108392

Epoch: 5| Step: 3
Training loss: 0.7318536207039296
Validation loss: 2.5561334891070073

Epoch: 5| Step: 4
Training loss: 1.3867016858407617
Validation loss: 2.5536542392648824

Epoch: 5| Step: 5
Training loss: 1.1172657118943243
Validation loss: 2.5284589457585502

Epoch: 5| Step: 6
Training loss: 0.7874569184765434
Validation loss: 2.5920319978839736

Epoch: 5| Step: 7
Training loss: 0.9531820311446656
Validation loss: 2.6028638735266783

Epoch: 5| Step: 8
Training loss: 1.3098191174995584
Validation loss: 2.592859051170399

Epoch: 5| Step: 9
Training loss: 0.8860444180998757
Validation loss: 2.5474702466753443

Epoch: 5| Step: 10
Training loss: 1.179385519218332
Validation loss: 2.4983071250949824

Epoch: 389| Step: 0
Training loss: 0.9241771401642275
Validation loss: 2.49059219160671

Epoch: 5| Step: 1
Training loss: 1.1806643654039624
Validation loss: 2.45770269939466

Epoch: 5| Step: 2
Training loss: 1.2436901097279154
Validation loss: 2.4661679330185518

Epoch: 5| Step: 3
Training loss: 1.1891184368836627
Validation loss: 2.4432658539605927

Epoch: 5| Step: 4
Training loss: 0.9546401066730529
Validation loss: 2.456535438665002

Epoch: 5| Step: 5
Training loss: 0.9305293014643811
Validation loss: 2.428513505652001

Epoch: 5| Step: 6
Training loss: 0.9595913025004305
Validation loss: 2.424820920562714

Epoch: 5| Step: 7
Training loss: 1.0281977711812
Validation loss: 2.4298086503825007

Epoch: 5| Step: 8
Training loss: 1.2270803148181795
Validation loss: 2.4389099458499652

Epoch: 5| Step: 9
Training loss: 0.868774474094266
Validation loss: 2.4286080481568204

Epoch: 5| Step: 10
Training loss: 1.1394141053537137
Validation loss: 2.488401007530037

Epoch: 390| Step: 0
Training loss: 1.1069823777227092
Validation loss: 2.4790292441366684

Epoch: 5| Step: 1
Training loss: 1.123000009636951
Validation loss: 2.5385947832401956

Epoch: 5| Step: 2
Training loss: 1.1289221950579706
Validation loss: 2.53980253353862

Epoch: 5| Step: 3
Training loss: 1.3730604190077018
Validation loss: 2.605852743048229

Epoch: 5| Step: 4
Training loss: 1.2087241341033492
Validation loss: 2.6163500917115137

Epoch: 5| Step: 5
Training loss: 1.3874866347485424
Validation loss: 2.5836700912306236

Epoch: 5| Step: 6
Training loss: 0.6109478044738457
Validation loss: 2.520308902150152

Epoch: 5| Step: 7
Training loss: 0.9620768298004603
Validation loss: 2.504414131642976

Epoch: 5| Step: 8
Training loss: 0.8694448560105048
Validation loss: 2.456506382057304

Epoch: 5| Step: 9
Training loss: 0.9144506363995766
Validation loss: 2.4326089905545207

Epoch: 5| Step: 10
Training loss: 1.1989958615012883
Validation loss: 2.4035451250644866

Epoch: 391| Step: 0
Training loss: 1.5408520823290988
Validation loss: 2.405700320364447

Epoch: 5| Step: 1
Training loss: 0.781085798173854
Validation loss: 2.4095943512118807

Epoch: 5| Step: 2
Training loss: 0.9972293738094272
Validation loss: 2.3871770427187813

Epoch: 5| Step: 3
Training loss: 1.3224900476409318
Validation loss: 2.4078229555479

Epoch: 5| Step: 4
Training loss: 0.7607064587646473
Validation loss: 2.4555830910700562

Epoch: 5| Step: 5
Training loss: 1.062615332234255
Validation loss: 2.474464880871107

Epoch: 5| Step: 6
Training loss: 1.1481600056369807
Validation loss: 2.491466956949775

Epoch: 5| Step: 7
Training loss: 1.0309610829079947
Validation loss: 2.505725503201378

Epoch: 5| Step: 8
Training loss: 0.9365263015019099
Validation loss: 2.4997257266796433

Epoch: 5| Step: 9
Training loss: 1.0655241731168743
Validation loss: 2.4782689617452696

Epoch: 5| Step: 10
Training loss: 1.0501129407541046
Validation loss: 2.4787074120650257

Epoch: 392| Step: 0
Training loss: 0.9718208248825264
Validation loss: 2.4529989688420426

Epoch: 5| Step: 1
Training loss: 1.1553294667243272
Validation loss: 2.4422914683805956

Epoch: 5| Step: 2
Training loss: 0.9175351031705719
Validation loss: 2.451317352055529

Epoch: 5| Step: 3
Training loss: 1.117848447542136
Validation loss: 2.4270616601086052

Epoch: 5| Step: 4
Training loss: 1.0698246087509273
Validation loss: 2.415150023987475

Epoch: 5| Step: 5
Training loss: 1.0955896981836093
Validation loss: 2.459676775569956

Epoch: 5| Step: 6
Training loss: 0.8366808571948235
Validation loss: 2.4712154963673014

Epoch: 5| Step: 7
Training loss: 1.12716075234105
Validation loss: 2.435121010043813

Epoch: 5| Step: 8
Training loss: 0.9950381201721384
Validation loss: 2.4582309572966854

Epoch: 5| Step: 9
Training loss: 0.7975432641901032
Validation loss: 2.4666513001499046

Epoch: 5| Step: 10
Training loss: 0.8994356995671187
Validation loss: 2.446802834622019

Epoch: 393| Step: 0
Training loss: 1.0295263392935876
Validation loss: 2.4521054323544593

Epoch: 5| Step: 1
Training loss: 0.9270970132797136
Validation loss: 2.441617980570194

Epoch: 5| Step: 2
Training loss: 1.0367767892673667
Validation loss: 2.475131546009987

Epoch: 5| Step: 3
Training loss: 1.4791624400476953
Validation loss: 2.466609679699866

Epoch: 5| Step: 4
Training loss: 0.9740308064850742
Validation loss: 2.4551507817671063

Epoch: 5| Step: 5
Training loss: 0.9459748903010794
Validation loss: 2.486654344136861

Epoch: 5| Step: 6
Training loss: 0.7614927690254089
Validation loss: 2.4669471950644772

Epoch: 5| Step: 7
Training loss: 1.028150988311211
Validation loss: 2.4406288822456164

Epoch: 5| Step: 8
Training loss: 1.0625673160545928
Validation loss: 2.4663842193619416

Epoch: 5| Step: 9
Training loss: 0.8445525061713981
Validation loss: 2.4586617792826253

Epoch: 5| Step: 10
Training loss: 0.6156698714038459
Validation loss: 2.4955639993798835

Epoch: 394| Step: 0
Training loss: 1.0555555374301664
Validation loss: 2.502828675388003

Epoch: 5| Step: 1
Training loss: 1.3926862377771674
Validation loss: 2.486749058670708

Epoch: 5| Step: 2
Training loss: 0.6651879590653063
Validation loss: 2.4832449352698602

Epoch: 5| Step: 3
Training loss: 0.9068034553831352
Validation loss: 2.4934454023238923

Epoch: 5| Step: 4
Training loss: 1.1172737675151303
Validation loss: 2.473583784695569

Epoch: 5| Step: 5
Training loss: 1.0297349146112833
Validation loss: 2.459432043205282

Epoch: 5| Step: 6
Training loss: 1.0319760974178542
Validation loss: 2.458577828183504

Epoch: 5| Step: 7
Training loss: 1.0367820783646815
Validation loss: 2.4326464488314326

Epoch: 5| Step: 8
Training loss: 0.7197056512369865
Validation loss: 2.467853241524926

Epoch: 5| Step: 9
Training loss: 0.6615676914636666
Validation loss: 2.4879005076312315

Epoch: 5| Step: 10
Training loss: 1.0636222746537647
Validation loss: 2.4778858666915617

Epoch: 395| Step: 0
Training loss: 1.1641429386892892
Validation loss: 2.4776415236792015

Epoch: 5| Step: 1
Training loss: 0.7870465199100771
Validation loss: 2.455762545291009

Epoch: 5| Step: 2
Training loss: 1.0105128226129652
Validation loss: 2.4493801255263263

Epoch: 5| Step: 3
Training loss: 1.257544968864627
Validation loss: 2.428501970625456

Epoch: 5| Step: 4
Training loss: 1.0175014474282058
Validation loss: 2.433419663636478

Epoch: 5| Step: 5
Training loss: 0.9041868270583577
Validation loss: 2.403930590311714

Epoch: 5| Step: 6
Training loss: 1.0020932105219342
Validation loss: 2.404473281524769

Epoch: 5| Step: 7
Training loss: 0.973618028044486
Validation loss: 2.4054276683702693

Epoch: 5| Step: 8
Training loss: 0.8230710830351026
Validation loss: 2.4098711098910512

Epoch: 5| Step: 9
Training loss: 0.9896558166192665
Validation loss: 2.418327877273466

Epoch: 5| Step: 10
Training loss: 0.529111766470364
Validation loss: 2.42005376755896

Epoch: 396| Step: 0
Training loss: 1.0487991414247748
Validation loss: 2.428335482009089

Epoch: 5| Step: 1
Training loss: 0.9455045079467241
Validation loss: 2.4337025619402035

Epoch: 5| Step: 2
Training loss: 0.7539811171284511
Validation loss: 2.396771380462142

Epoch: 5| Step: 3
Training loss: 1.1802479000254678
Validation loss: 2.422747984128691

Epoch: 5| Step: 4
Training loss: 0.6922629270080196
Validation loss: 2.4274228216960125

Epoch: 5| Step: 5
Training loss: 0.6229277350379036
Validation loss: 2.419779344731755

Epoch: 5| Step: 6
Training loss: 1.0940875486215749
Validation loss: 2.432223783062518

Epoch: 5| Step: 7
Training loss: 0.5840351503682738
Validation loss: 2.45783384228962

Epoch: 5| Step: 8
Training loss: 0.9549656901262945
Validation loss: 2.442436251561027

Epoch: 5| Step: 9
Training loss: 1.3796453899381316
Validation loss: 2.4736187870363575

Epoch: 5| Step: 10
Training loss: 1.0024436657076947
Validation loss: 2.4761207388164355

Epoch: 397| Step: 0
Training loss: 0.8899124373534236
Validation loss: 2.4444945090755135

Epoch: 5| Step: 1
Training loss: 0.8528834605372504
Validation loss: 2.4313444331864247

Epoch: 5| Step: 2
Training loss: 0.8599417464908818
Validation loss: 2.4112440526245242

Epoch: 5| Step: 3
Training loss: 0.794689660048765
Validation loss: 2.4178317957926083

Epoch: 5| Step: 4
Training loss: 1.061279156467454
Validation loss: 2.387805369998166

Epoch: 5| Step: 5
Training loss: 1.0678592606225956
Validation loss: 2.4203147972751315

Epoch: 5| Step: 6
Training loss: 1.0898901816701034
Validation loss: 2.408550871845779

Epoch: 5| Step: 7
Training loss: 1.127275708340034
Validation loss: 2.410674126820061

Epoch: 5| Step: 8
Training loss: 0.9417382758828253
Validation loss: 2.4253709070288165

Epoch: 5| Step: 9
Training loss: 0.9446265514119245
Validation loss: 2.4570931102203266

Epoch: 5| Step: 10
Training loss: 0.9472340057444313
Validation loss: 2.478860824517946

Epoch: 398| Step: 0
Training loss: 0.9636987231673724
Validation loss: 2.4898506436717684

Epoch: 5| Step: 1
Training loss: 1.1962741648466513
Validation loss: 2.4957114989390856

Epoch: 5| Step: 2
Training loss: 0.8215104937425894
Validation loss: 2.5011020528381485

Epoch: 5| Step: 3
Training loss: 1.0545769527568336
Validation loss: 2.537308096881871

Epoch: 5| Step: 4
Training loss: 0.9537606542949612
Validation loss: 2.498052256691251

Epoch: 5| Step: 5
Training loss: 0.9597695238393635
Validation loss: 2.4708821362962436

Epoch: 5| Step: 6
Training loss: 0.797659880118932
Validation loss: 2.4626353792412465

Epoch: 5| Step: 7
Training loss: 1.0895982144411165
Validation loss: 2.434212999122792

Epoch: 5| Step: 8
Training loss: 0.9039182591279343
Validation loss: 2.4079418831931876

Epoch: 5| Step: 9
Training loss: 0.8585631957791723
Validation loss: 2.410891920833909

Epoch: 5| Step: 10
Training loss: 0.7590476912290292
Validation loss: 2.4216043369342377

Epoch: 399| Step: 0
Training loss: 0.4720309511377575
Validation loss: 2.4183926053873877

Epoch: 5| Step: 1
Training loss: 0.9534678233478081
Validation loss: 2.408160502369441

Epoch: 5| Step: 2
Training loss: 1.1778114002654827
Validation loss: 2.419966771524721

Epoch: 5| Step: 3
Training loss: 0.9360604041509655
Validation loss: 2.40455918769483

Epoch: 5| Step: 4
Training loss: 0.7650052111579076
Validation loss: 2.4518440371188635

Epoch: 5| Step: 5
Training loss: 0.8230646740727313
Validation loss: 2.5106110788366025

Epoch: 5| Step: 6
Training loss: 1.2477815492279933
Validation loss: 2.5011049187488386

Epoch: 5| Step: 7
Training loss: 0.9335028951321103
Validation loss: 2.548086301474764

Epoch: 5| Step: 8
Training loss: 1.133368414915566
Validation loss: 2.5139401540781137

Epoch: 5| Step: 9
Training loss: 1.0851766541816796
Validation loss: 2.486042375642322

Epoch: 5| Step: 10
Training loss: 0.8703442415376637
Validation loss: 2.459939833934997

Epoch: 400| Step: 0
Training loss: 1.0051645193615204
Validation loss: 2.4438460360408745

Epoch: 5| Step: 1
Training loss: 0.8677377072262838
Validation loss: 2.4028587420926892

Epoch: 5| Step: 2
Training loss: 0.9134380457247117
Validation loss: 2.4033702397755174

Epoch: 5| Step: 3
Training loss: 1.0336974030736539
Validation loss: 2.407694530688152

Epoch: 5| Step: 4
Training loss: 0.8197995716636416
Validation loss: 2.388846406879269

Epoch: 5| Step: 5
Training loss: 1.2032754977338544
Validation loss: 2.4022876006283482

Epoch: 5| Step: 6
Training loss: 0.8467931264454198
Validation loss: 2.380567119224719

Epoch: 5| Step: 7
Training loss: 0.9594259080830805
Validation loss: 2.4256469304688566

Epoch: 5| Step: 8
Training loss: 0.9332290000729448
Validation loss: 2.3982694427420497

Epoch: 5| Step: 9
Training loss: 0.6624613813624505
Validation loss: 2.432469798451791

Epoch: 5| Step: 10
Training loss: 0.8992031318110266
Validation loss: 2.443013052813451

Epoch: 401| Step: 0
Training loss: 0.8350797512892623
Validation loss: 2.462051008947396

Epoch: 5| Step: 1
Training loss: 0.9267380996713893
Validation loss: 2.4636622160943067

Epoch: 5| Step: 2
Training loss: 0.7596549613006744
Validation loss: 2.476667734290335

Epoch: 5| Step: 3
Training loss: 0.6480919250318379
Validation loss: 2.463989182477915

Epoch: 5| Step: 4
Training loss: 0.7463152891061736
Validation loss: 2.447756728840748

Epoch: 5| Step: 5
Training loss: 1.2448740762967037
Validation loss: 2.460847233192544

Epoch: 5| Step: 6
Training loss: 0.8132550326032446
Validation loss: 2.465504721117648

Epoch: 5| Step: 7
Training loss: 0.9374935785709443
Validation loss: 2.4460953268610304

Epoch: 5| Step: 8
Training loss: 1.1185358620403774
Validation loss: 2.4323674715155517

Epoch: 5| Step: 9
Training loss: 1.0749606812849453
Validation loss: 2.409299613831232

Epoch: 5| Step: 10
Training loss: 0.9954776728668309
Validation loss: 2.395133672761966

Epoch: 402| Step: 0
Training loss: 1.055301459302411
Validation loss: 2.414208764790674

Epoch: 5| Step: 1
Training loss: 0.87985683322366
Validation loss: 2.4493633686225924

Epoch: 5| Step: 2
Training loss: 1.1150995764295641
Validation loss: 2.454904847876336

Epoch: 5| Step: 3
Training loss: 0.7393543578464404
Validation loss: 2.484643674100901

Epoch: 5| Step: 4
Training loss: 1.2519800239803596
Validation loss: 2.4990947520079576

Epoch: 5| Step: 5
Training loss: 0.6541876175030156
Validation loss: 2.4630371970297866

Epoch: 5| Step: 6
Training loss: 0.8108425841893351
Validation loss: 2.4381741300677224

Epoch: 5| Step: 7
Training loss: 0.9748591712579339
Validation loss: 2.399299651809156

Epoch: 5| Step: 8
Training loss: 0.9867570001311832
Validation loss: 2.39082605282046

Epoch: 5| Step: 9
Training loss: 1.1558670750162003
Validation loss: 2.4012418135051705

Epoch: 5| Step: 10
Training loss: 0.6425319759412477
Validation loss: 2.3915996051464887

Epoch: 403| Step: 0
Training loss: 0.6362159709786346
Validation loss: 2.360045487382809

Epoch: 5| Step: 1
Training loss: 1.067777876411228
Validation loss: 2.3526704381926704

Epoch: 5| Step: 2
Training loss: 0.9505090616969154
Validation loss: 2.3662425606497672

Epoch: 5| Step: 3
Training loss: 0.9989857298296709
Validation loss: 2.3746490618624745

Epoch: 5| Step: 4
Training loss: 0.7069191185146007
Validation loss: 2.4059329314753417

Epoch: 5| Step: 5
Training loss: 1.0578103633165967
Validation loss: 2.40729491387576

Epoch: 5| Step: 6
Training loss: 0.937275923335078
Validation loss: 2.445925707022255

Epoch: 5| Step: 7
Training loss: 0.876256585416114
Validation loss: 2.4725698180466953

Epoch: 5| Step: 8
Training loss: 1.0538465184618593
Validation loss: 2.482935418136488

Epoch: 5| Step: 9
Training loss: 1.0825913835148437
Validation loss: 2.513075311780005

Epoch: 5| Step: 10
Training loss: 0.9072910446065587
Validation loss: 2.4922130520529384

Epoch: 404| Step: 0
Training loss: 1.1035855161426409
Validation loss: 2.450605120421181

Epoch: 5| Step: 1
Training loss: 1.1211430874378907
Validation loss: 2.445808407275189

Epoch: 5| Step: 2
Training loss: 0.7610079848212704
Validation loss: 2.4444893461200925

Epoch: 5| Step: 3
Training loss: 0.8829339543069753
Validation loss: 2.4402549100770945

Epoch: 5| Step: 4
Training loss: 0.9985476915090323
Validation loss: 2.41130146912718

Epoch: 5| Step: 5
Training loss: 0.7189048931902473
Validation loss: 2.4284815247697615

Epoch: 5| Step: 6
Training loss: 0.9996633559063305
Validation loss: 2.444530526232934

Epoch: 5| Step: 7
Training loss: 0.6713650564687152
Validation loss: 2.4622867102705097

Epoch: 5| Step: 8
Training loss: 1.2250126565551875
Validation loss: 2.4313064307985384

Epoch: 5| Step: 9
Training loss: 0.7335457279302717
Validation loss: 2.439908459827551

Epoch: 5| Step: 10
Training loss: 0.799014342598263
Validation loss: 2.4685476647761373

Epoch: 405| Step: 0
Training loss: 0.8201731245529151
Validation loss: 2.450460334459868

Epoch: 5| Step: 1
Training loss: 0.9194467860656557
Validation loss: 2.4501504571860244

Epoch: 5| Step: 2
Training loss: 0.8431722994488863
Validation loss: 2.4423808465097308

Epoch: 5| Step: 3
Training loss: 0.9623414615009918
Validation loss: 2.463995618650757

Epoch: 5| Step: 4
Training loss: 0.7314246955278214
Validation loss: 2.432781289216096

Epoch: 5| Step: 5
Training loss: 1.021060833914841
Validation loss: 2.437111627198718

Epoch: 5| Step: 6
Training loss: 0.8605872533938019
Validation loss: 2.3936543539824577

Epoch: 5| Step: 7
Training loss: 0.8829941689243657
Validation loss: 2.386256955028033

Epoch: 5| Step: 8
Training loss: 0.9601380038409467
Validation loss: 2.3879156639814503

Epoch: 5| Step: 9
Training loss: 1.0051924485185186
Validation loss: 2.3899824606159665

Epoch: 5| Step: 10
Training loss: 1.1229744796638605
Validation loss: 2.387687979197322

Epoch: 406| Step: 0
Training loss: 1.0010202091284457
Validation loss: 2.426827942031376

Epoch: 5| Step: 1
Training loss: 0.9779959572199478
Validation loss: 2.426895438180445

Epoch: 5| Step: 2
Training loss: 0.7386637105747776
Validation loss: 2.4452900727429663

Epoch: 5| Step: 3
Training loss: 1.1451408663557128
Validation loss: 2.4546529696907444

Epoch: 5| Step: 4
Training loss: 0.9057991616460619
Validation loss: 2.496145273012231

Epoch: 5| Step: 5
Training loss: 0.9664332158636932
Validation loss: 2.5130222843163215

Epoch: 5| Step: 6
Training loss: 0.8259199042291597
Validation loss: 2.50946439289768

Epoch: 5| Step: 7
Training loss: 0.9243889169116075
Validation loss: 2.49471671809026

Epoch: 5| Step: 8
Training loss: 1.0214625514892108
Validation loss: 2.488819371860136

Epoch: 5| Step: 9
Training loss: 0.7936222033611369
Validation loss: 2.4624621393851505

Epoch: 5| Step: 10
Training loss: 0.556421792365752
Validation loss: 2.437655416876262

Epoch: 407| Step: 0
Training loss: 0.8278394242685909
Validation loss: 2.3926919817207843

Epoch: 5| Step: 1
Training loss: 0.9370745965276991
Validation loss: 2.3895312075163253

Epoch: 5| Step: 2
Training loss: 0.9733968159851801
Validation loss: 2.3814995305910602

Epoch: 5| Step: 3
Training loss: 1.1878997732134482
Validation loss: 2.381716272469061

Epoch: 5| Step: 4
Training loss: 0.6669034884945167
Validation loss: 2.3763521670554555

Epoch: 5| Step: 5
Training loss: 0.8665971206919177
Validation loss: 2.385107214229452

Epoch: 5| Step: 6
Training loss: 0.7272241922325466
Validation loss: 2.4017527637268294

Epoch: 5| Step: 7
Training loss: 0.7479600582091934
Validation loss: 2.4173702690978236

Epoch: 5| Step: 8
Training loss: 0.9710965807897258
Validation loss: 2.4444722746249568

Epoch: 5| Step: 9
Training loss: 0.9089003645004833
Validation loss: 2.455389167865521

Epoch: 5| Step: 10
Training loss: 0.7219421570160138
Validation loss: 2.449341913129206

Epoch: 408| Step: 0
Training loss: 0.7202758763202337
Validation loss: 2.442700944614673

Epoch: 5| Step: 1
Training loss: 0.9374435407803923
Validation loss: 2.4435003525276873

Epoch: 5| Step: 2
Training loss: 1.0288635731668394
Validation loss: 2.4422378435020686

Epoch: 5| Step: 3
Training loss: 0.7904397634397053
Validation loss: 2.456491116568809

Epoch: 5| Step: 4
Training loss: 0.7871395890942224
Validation loss: 2.423286699251243

Epoch: 5| Step: 5
Training loss: 0.9090574778565297
Validation loss: 2.434408956724206

Epoch: 5| Step: 6
Training loss: 1.01426147483783
Validation loss: 2.4146443803454027

Epoch: 5| Step: 7
Training loss: 0.8383052840258234
Validation loss: 2.4238782411814994

Epoch: 5| Step: 8
Training loss: 0.8534107623945694
Validation loss: 2.4326685431903106

Epoch: 5| Step: 9
Training loss: 0.9022040320884531
Validation loss: 2.4087983556577175

Epoch: 5| Step: 10
Training loss: 0.6751097060167933
Validation loss: 2.421748444541655

Epoch: 409| Step: 0
Training loss: 0.7772088628700413
Validation loss: 2.421636762753737

Epoch: 5| Step: 1
Training loss: 0.6853994662050407
Validation loss: 2.423555001178002

Epoch: 5| Step: 2
Training loss: 1.0148720517811647
Validation loss: 2.406940092232962

Epoch: 5| Step: 3
Training loss: 1.1858332129500957
Validation loss: 2.413326600604789

Epoch: 5| Step: 4
Training loss: 1.143293473065111
Validation loss: 2.4224688783291906

Epoch: 5| Step: 5
Training loss: 0.9463624404156452
Validation loss: 2.436234395144556

Epoch: 5| Step: 6
Training loss: 0.9093785380920587
Validation loss: 2.4117867000752944

Epoch: 5| Step: 7
Training loss: 0.4540649071122259
Validation loss: 2.4111751422980707

Epoch: 5| Step: 8
Training loss: 0.6752689602791103
Validation loss: 2.4269698787787832

Epoch: 5| Step: 9
Training loss: 0.6760356402214266
Validation loss: 2.4275714855690387

Epoch: 5| Step: 10
Training loss: 0.7402115065934927
Validation loss: 2.444732503925201

Epoch: 410| Step: 0
Training loss: 1.023928167934301
Validation loss: 2.426768806488573

Epoch: 5| Step: 1
Training loss: 0.8654069922072821
Validation loss: 2.4456074403873895

Epoch: 5| Step: 2
Training loss: 0.7881117276458908
Validation loss: 2.3982757538404305

Epoch: 5| Step: 3
Training loss: 0.7037831299336915
Validation loss: 2.3783311878755216

Epoch: 5| Step: 4
Training loss: 0.8132221240740417
Validation loss: 2.399723529230606

Epoch: 5| Step: 5
Training loss: 0.9468410838382415
Validation loss: 2.3890835508702803

Epoch: 5| Step: 6
Training loss: 0.766411746877387
Validation loss: 2.3942746207219585

Epoch: 5| Step: 7
Training loss: 0.6352520766000986
Validation loss: 2.3670277492373537

Epoch: 5| Step: 8
Training loss: 0.8706953566056198
Validation loss: 2.3817067615234686

Epoch: 5| Step: 9
Training loss: 0.8663482041173068
Validation loss: 2.3917576814735475

Epoch: 5| Step: 10
Training loss: 1.0207763902521352
Validation loss: 2.3766878970497425

Epoch: 411| Step: 0
Training loss: 1.0658486274256223
Validation loss: 2.3579130238732833

Epoch: 5| Step: 1
Training loss: 0.676677946852478
Validation loss: 2.3614140406912885

Epoch: 5| Step: 2
Training loss: 1.225057662852338
Validation loss: 2.396394926132933

Epoch: 5| Step: 3
Training loss: 0.8783083768359786
Validation loss: 2.386479203213178

Epoch: 5| Step: 4
Training loss: 0.6318577758222453
Validation loss: 2.393194724300222

Epoch: 5| Step: 5
Training loss: 0.5947619397895917
Validation loss: 2.4068422295868332

Epoch: 5| Step: 6
Training loss: 0.9533886779268126
Validation loss: 2.4116749130800725

Epoch: 5| Step: 7
Training loss: 0.6547120783887754
Validation loss: 2.391086339487289

Epoch: 5| Step: 8
Training loss: 0.7710291811297978
Validation loss: 2.391225949605764

Epoch: 5| Step: 9
Training loss: 0.8881673869058909
Validation loss: 2.3959214884914317

Epoch: 5| Step: 10
Training loss: 0.8098384840961691
Validation loss: 2.4124376490524293

Epoch: 412| Step: 0
Training loss: 0.7932161593523948
Validation loss: 2.4165269268852456

Epoch: 5| Step: 1
Training loss: 0.42917413388703335
Validation loss: 2.4153001384906947

Epoch: 5| Step: 2
Training loss: 0.8960379026881293
Validation loss: 2.40130569329962

Epoch: 5| Step: 3
Training loss: 1.0572860354318974
Validation loss: 2.4094381116938948

Epoch: 5| Step: 4
Training loss: 1.055641477556743
Validation loss: 2.414654020609904

Epoch: 5| Step: 5
Training loss: 0.8995693872056012
Validation loss: 2.419246565154657

Epoch: 5| Step: 6
Training loss: 0.6195339313463487
Validation loss: 2.402130021936647

Epoch: 5| Step: 7
Training loss: 0.7357079603529078
Validation loss: 2.409898157062626

Epoch: 5| Step: 8
Training loss: 0.9121659320556742
Validation loss: 2.385071110704829

Epoch: 5| Step: 9
Training loss: 0.9317756411046533
Validation loss: 2.404093451060531

Epoch: 5| Step: 10
Training loss: 0.6914197198450119
Validation loss: 2.3943586721736265

Epoch: 413| Step: 0
Training loss: 0.5923888264346708
Validation loss: 2.403040666235358

Epoch: 5| Step: 1
Training loss: 0.8603893189475312
Validation loss: 2.4029081844548124

Epoch: 5| Step: 2
Training loss: 1.0708149753783078
Validation loss: 2.416852195698754

Epoch: 5| Step: 3
Training loss: 0.9487553788084163
Validation loss: 2.432176798097747

Epoch: 5| Step: 4
Training loss: 1.03023299729948
Validation loss: 2.4304709441365415

Epoch: 5| Step: 5
Training loss: 0.9259560335527237
Validation loss: 2.4353430949131196

Epoch: 5| Step: 6
Training loss: 0.7213231756023379
Validation loss: 2.407934999088484

Epoch: 5| Step: 7
Training loss: 0.7121027106529343
Validation loss: 2.4305400415053344

Epoch: 5| Step: 8
Training loss: 0.8925882084316584
Validation loss: 2.416329852244331

Epoch: 5| Step: 9
Training loss: 0.46313898047428104
Validation loss: 2.4116688081914224

Epoch: 5| Step: 10
Training loss: 0.6354262684789723
Validation loss: 2.394242163223284

Epoch: 414| Step: 0
Training loss: 0.9676578887723538
Validation loss: 2.386943861504503

Epoch: 5| Step: 1
Training loss: 0.8070792051914444
Validation loss: 2.4244049238188716

Epoch: 5| Step: 2
Training loss: 0.6145337672100797
Validation loss: 2.397017920050764

Epoch: 5| Step: 3
Training loss: 0.8045535300128248
Validation loss: 2.403249470321092

Epoch: 5| Step: 4
Training loss: 0.797265275116862
Validation loss: 2.408259814548524

Epoch: 5| Step: 5
Training loss: 0.965947095612891
Validation loss: 2.426966928493858

Epoch: 5| Step: 6
Training loss: 1.0040425605111922
Validation loss: 2.4375016701784347

Epoch: 5| Step: 7
Training loss: 0.9503333999959797
Validation loss: 2.4177947044271413

Epoch: 5| Step: 8
Training loss: 0.7182835433621294
Validation loss: 2.419238416953793

Epoch: 5| Step: 9
Training loss: 0.6851497053923394
Validation loss: 2.414220625087241

Epoch: 5| Step: 10
Training loss: 0.6519495063987588
Validation loss: 2.4247441725517898

Epoch: 415| Step: 0
Training loss: 0.41760412693697496
Validation loss: 2.441544652285014

Epoch: 5| Step: 1
Training loss: 1.0675633898100934
Validation loss: 2.425665467710426

Epoch: 5| Step: 2
Training loss: 0.809575392611662
Validation loss: 2.4290234137251803

Epoch: 5| Step: 3
Training loss: 0.7953790198426415
Validation loss: 2.446530765130961

Epoch: 5| Step: 4
Training loss: 0.8762358044768256
Validation loss: 2.419199334243571

Epoch: 5| Step: 5
Training loss: 0.5379919672777582
Validation loss: 2.4066977228880138

Epoch: 5| Step: 6
Training loss: 0.6014983898531322
Validation loss: 2.3765991183521633

Epoch: 5| Step: 7
Training loss: 0.6200169519829527
Validation loss: 2.3813508961260523

Epoch: 5| Step: 8
Training loss: 1.1265416179102528
Validation loss: 2.389235052036865

Epoch: 5| Step: 9
Training loss: 1.0627832035288014
Validation loss: 2.3920925439365974

Epoch: 5| Step: 10
Training loss: 0.8767562339328314
Validation loss: 2.368776337076766

Epoch: 416| Step: 0
Training loss: 0.9766157212060117
Validation loss: 2.3932334850498655

Epoch: 5| Step: 1
Training loss: 0.641633705019169
Validation loss: 2.406509770004833

Epoch: 5| Step: 2
Training loss: 0.7884775391828466
Validation loss: 2.4034853937368625

Epoch: 5| Step: 3
Training loss: 0.6962392823988425
Validation loss: 2.432137239734335

Epoch: 5| Step: 4
Training loss: 0.7046563321344926
Validation loss: 2.441327881176661

Epoch: 5| Step: 5
Training loss: 1.0906611832789437
Validation loss: 2.4527257078748077

Epoch: 5| Step: 6
Training loss: 0.5422697713913514
Validation loss: 2.457670293054899

Epoch: 5| Step: 7
Training loss: 0.8409842620402171
Validation loss: 2.4134965230418675

Epoch: 5| Step: 8
Training loss: 0.7821779843222882
Validation loss: 2.4000163120587925

Epoch: 5| Step: 9
Training loss: 0.9308776290198706
Validation loss: 2.442887481186968

Epoch: 5| Step: 10
Training loss: 0.7948386033890588
Validation loss: 2.409142230413526

Epoch: 417| Step: 0
Training loss: 0.553444907786648
Validation loss: 2.402311085111168

Epoch: 5| Step: 1
Training loss: 0.8034970635109435
Validation loss: 2.4113327178276363

Epoch: 5| Step: 2
Training loss: 0.9028453671185838
Validation loss: 2.374025774341127

Epoch: 5| Step: 3
Training loss: 0.8261670773053478
Validation loss: 2.381316974905858

Epoch: 5| Step: 4
Training loss: 0.494303122478403
Validation loss: 2.401452720121113

Epoch: 5| Step: 5
Training loss: 1.0036795393558433
Validation loss: 2.4265663911153985

Epoch: 5| Step: 6
Training loss: 0.7018633649749961
Validation loss: 2.418008162187061

Epoch: 5| Step: 7
Training loss: 0.8363577241038381
Validation loss: 2.4222583701525475

Epoch: 5| Step: 8
Training loss: 0.7911039326671901
Validation loss: 2.4328976933454336

Epoch: 5| Step: 9
Training loss: 0.9029736982805074
Validation loss: 2.4505794023356486

Epoch: 5| Step: 10
Training loss: 0.9772815041117688
Validation loss: 2.447499334455128

Epoch: 418| Step: 0
Training loss: 0.8488035041338563
Validation loss: 2.4351628354823456

Epoch: 5| Step: 1
Training loss: 0.9870721711128384
Validation loss: 2.4219292451021386

Epoch: 5| Step: 2
Training loss: 1.1830336753231276
Validation loss: 2.438930979110338

Epoch: 5| Step: 3
Training loss: 0.7328049128613431
Validation loss: 2.435815549389696

Epoch: 5| Step: 4
Training loss: 0.5434737567093005
Validation loss: 2.411234754900987

Epoch: 5| Step: 5
Training loss: 0.7530406667257737
Validation loss: 2.3961993449280774

Epoch: 5| Step: 6
Training loss: 0.7390896846618628
Validation loss: 2.390476752766414

Epoch: 5| Step: 7
Training loss: 0.66750757013093
Validation loss: 2.396676436747819

Epoch: 5| Step: 8
Training loss: 0.6875351550043917
Validation loss: 2.3849245197716744

Epoch: 5| Step: 9
Training loss: 0.9535859666106973
Validation loss: 2.392467333915809

Epoch: 5| Step: 10
Training loss: 0.7285166477063238
Validation loss: 2.4201232703992144

Epoch: 419| Step: 0
Training loss: 0.9776574367072762
Validation loss: 2.4065477543637805

Epoch: 5| Step: 1
Training loss: 0.850408980206958
Validation loss: 2.426335312768172

Epoch: 5| Step: 2
Training loss: 0.9423877775229472
Validation loss: 2.4552069950207573

Epoch: 5| Step: 3
Training loss: 0.646026472212125
Validation loss: 2.4414003360143424

Epoch: 5| Step: 4
Training loss: 1.0840845010239804
Validation loss: 2.463539586789019

Epoch: 5| Step: 5
Training loss: 0.6368357545030752
Validation loss: 2.4898308076491933

Epoch: 5| Step: 6
Training loss: 0.6976681997679068
Validation loss: 2.5108839384868307

Epoch: 5| Step: 7
Training loss: 0.5234266536215177
Validation loss: 2.474645016527166

Epoch: 5| Step: 8
Training loss: 0.9493809000300287
Validation loss: 2.4765462945032852

Epoch: 5| Step: 9
Training loss: 0.5458944794813327
Validation loss: 2.49144910634295

Epoch: 5| Step: 10
Training loss: 0.8871991036984153
Validation loss: 2.46721771557775

Epoch: 420| Step: 0
Training loss: 0.9489524059480421
Validation loss: 2.462619912831218

Epoch: 5| Step: 1
Training loss: 0.953030128134862
Validation loss: 2.4461032145046984

Epoch: 5| Step: 2
Training loss: 0.8411737246460701
Validation loss: 2.466680323516679

Epoch: 5| Step: 3
Training loss: 0.5731582970135214
Validation loss: 2.446805238685994

Epoch: 5| Step: 4
Training loss: 0.8545074635911303
Validation loss: 2.4232634090562266

Epoch: 5| Step: 5
Training loss: 0.6767245197776824
Validation loss: 2.4429612445432998

Epoch: 5| Step: 6
Training loss: 0.7070734422434367
Validation loss: 2.4360555834338165

Epoch: 5| Step: 7
Training loss: 0.76203763106934
Validation loss: 2.418800395069509

Epoch: 5| Step: 8
Training loss: 0.7159404575748038
Validation loss: 2.4115814288838604

Epoch: 5| Step: 9
Training loss: 0.7372933292145608
Validation loss: 2.429971372968394

Epoch: 5| Step: 10
Training loss: 0.8693995400865671
Validation loss: 2.409022268046557

Epoch: 421| Step: 0
Training loss: 1.0276653526150097
Validation loss: 2.4126524791874293

Epoch: 5| Step: 1
Training loss: 0.7619753283188664
Validation loss: 2.4127026729047922

Epoch: 5| Step: 2
Training loss: 0.6919368712097018
Validation loss: 2.4064700672318837

Epoch: 5| Step: 3
Training loss: 0.7129700498884676
Validation loss: 2.3980860469846967

Epoch: 5| Step: 4
Training loss: 0.7404376634043924
Validation loss: 2.415027411099437

Epoch: 5| Step: 5
Training loss: 0.7820279253756558
Validation loss: 2.386512677230249

Epoch: 5| Step: 6
Training loss: 0.9495147745832049
Validation loss: 2.416731810902841

Epoch: 5| Step: 7
Training loss: 0.7977374776193904
Validation loss: 2.399755862382243

Epoch: 5| Step: 8
Training loss: 0.5473288151747757
Validation loss: 2.441104637367291

Epoch: 5| Step: 9
Training loss: 0.7961979027657005
Validation loss: 2.4525349078863954

Epoch: 5| Step: 10
Training loss: 0.7998511146046886
Validation loss: 2.470173720272749

Epoch: 422| Step: 0
Training loss: 0.942131143279391
Validation loss: 2.4586852242254564

Epoch: 5| Step: 1
Training loss: 0.3586898159757279
Validation loss: 2.4685586086949107

Epoch: 5| Step: 2
Training loss: 0.5653212316459751
Validation loss: 2.4444721749936913

Epoch: 5| Step: 3
Training loss: 0.8943975756852898
Validation loss: 2.457097817349088

Epoch: 5| Step: 4
Training loss: 0.9207250243711392
Validation loss: 2.459288805792882

Epoch: 5| Step: 5
Training loss: 0.9993504262244496
Validation loss: 2.452721961799564

Epoch: 5| Step: 6
Training loss: 0.8195072399655149
Validation loss: 2.4306300537325836

Epoch: 5| Step: 7
Training loss: 0.41452809913148075
Validation loss: 2.4144247231780427

Epoch: 5| Step: 8
Training loss: 0.6387055414408278
Validation loss: 2.400156294354931

Epoch: 5| Step: 9
Training loss: 1.02076745631651
Validation loss: 2.414623976938399

Epoch: 5| Step: 10
Training loss: 0.716775005121282
Validation loss: 2.385053566617291

Epoch: 423| Step: 0
Training loss: 0.8806913431273388
Validation loss: 2.3726688034043892

Epoch: 5| Step: 1
Training loss: 0.7422029192477242
Validation loss: 2.383259553224102

Epoch: 5| Step: 2
Training loss: 0.505498809156515
Validation loss: 2.3885500387684355

Epoch: 5| Step: 3
Training loss: 0.8591832727356147
Validation loss: 2.3966611896959877

Epoch: 5| Step: 4
Training loss: 0.5946318953513053
Validation loss: 2.4045038939594887

Epoch: 5| Step: 5
Training loss: 0.8363639243034953
Validation loss: 2.3920740889390477

Epoch: 5| Step: 6
Training loss: 0.9031584393603537
Validation loss: 2.40342150467623

Epoch: 5| Step: 7
Training loss: 1.005114114460223
Validation loss: 2.4200355660464

Epoch: 5| Step: 8
Training loss: 0.6416490789785696
Validation loss: 2.4437540841344507

Epoch: 5| Step: 9
Training loss: 0.6692084692807284
Validation loss: 2.4492781327158233

Epoch: 5| Step: 10
Training loss: 0.8305964747597727
Validation loss: 2.461526651563397

Epoch: 424| Step: 0
Training loss: 0.8610412742810141
Validation loss: 2.46751784280948

Epoch: 5| Step: 1
Training loss: 0.7966171670310421
Validation loss: 2.4634474536625626

Epoch: 5| Step: 2
Training loss: 0.412792020083245
Validation loss: 2.4551352285275656

Epoch: 5| Step: 3
Training loss: 0.7994785785155147
Validation loss: 2.4378011100488206

Epoch: 5| Step: 4
Training loss: 0.7163130871216429
Validation loss: 2.424097030623348

Epoch: 5| Step: 5
Training loss: 0.7657234751372598
Validation loss: 2.389626549913961

Epoch: 5| Step: 6
Training loss: 0.7748751139769183
Validation loss: 2.376172358733441

Epoch: 5| Step: 7
Training loss: 0.8727219081347124
Validation loss: 2.3956983548770663

Epoch: 5| Step: 8
Training loss: 0.9906895059949475
Validation loss: 2.4005675855597013

Epoch: 5| Step: 9
Training loss: 0.6130375225957513
Validation loss: 2.360471105084018

Epoch: 5| Step: 10
Training loss: 0.8688292556397228
Validation loss: 2.3647260674764436

Epoch: 425| Step: 0
Training loss: 0.7673408588097848
Validation loss: 2.369309575481533

Epoch: 5| Step: 1
Training loss: 0.5288251062352957
Validation loss: 2.377982278682667

Epoch: 5| Step: 2
Training loss: 0.7763485696347641
Validation loss: 2.3963095884914285

Epoch: 5| Step: 3
Training loss: 0.9978876752099747
Validation loss: 2.414317212816294

Epoch: 5| Step: 4
Training loss: 0.8161754373140572
Validation loss: 2.4294932361318833

Epoch: 5| Step: 5
Training loss: 0.840819603612869
Validation loss: 2.441090126752958

Epoch: 5| Step: 6
Training loss: 0.7722290694171798
Validation loss: 2.4370943567542223

Epoch: 5| Step: 7
Training loss: 0.5592075523498158
Validation loss: 2.4639877529086296

Epoch: 5| Step: 8
Training loss: 0.5866793196390189
Validation loss: 2.4276906406375507

Epoch: 5| Step: 9
Training loss: 0.9517798703223087
Validation loss: 2.4264545311823422

Epoch: 5| Step: 10
Training loss: 0.680302002334732
Validation loss: 2.418745980165747

Epoch: 426| Step: 0
Training loss: 0.5906941933442881
Validation loss: 2.4529254989749147

Epoch: 5| Step: 1
Training loss: 0.6975287574049153
Validation loss: 2.4323118668852404

Epoch: 5| Step: 2
Training loss: 0.6447903892451026
Validation loss: 2.440078303581685

Epoch: 5| Step: 3
Training loss: 0.8926071729879108
Validation loss: 2.461978281956565

Epoch: 5| Step: 4
Training loss: 0.7410158244822972
Validation loss: 2.4291210539723855

Epoch: 5| Step: 5
Training loss: 1.045806567291574
Validation loss: 2.398195581132523

Epoch: 5| Step: 6
Training loss: 1.0026817721102401
Validation loss: 2.4171886884524656

Epoch: 5| Step: 7
Training loss: 0.7313337864925101
Validation loss: 2.427052168417407

Epoch: 5| Step: 8
Training loss: 0.713271616675347
Validation loss: 2.40667236727321

Epoch: 5| Step: 9
Training loss: 0.6196601204491302
Validation loss: 2.4096476359799457

Epoch: 5| Step: 10
Training loss: 0.43802692833952744
Validation loss: 2.4266865389341645

Epoch: 427| Step: 0
Training loss: 0.6895610087335456
Validation loss: 2.4166152656556994

Epoch: 5| Step: 1
Training loss: 0.7009754809065388
Validation loss: 2.410856355507898

Epoch: 5| Step: 2
Training loss: 0.7634071613268695
Validation loss: 2.410149105235144

Epoch: 5| Step: 3
Training loss: 0.926572887754831
Validation loss: 2.4086361525615154

Epoch: 5| Step: 4
Training loss: 0.7697165793696128
Validation loss: 2.4059916009810993

Epoch: 5| Step: 5
Training loss: 0.9179353099170137
Validation loss: 2.4287084696085937

Epoch: 5| Step: 6
Training loss: 0.9589080469401496
Validation loss: 2.4495052701198534

Epoch: 5| Step: 7
Training loss: 0.869095533251386
Validation loss: 2.4231302904255063

Epoch: 5| Step: 8
Training loss: 0.6415170645848752
Validation loss: 2.404730314932124

Epoch: 5| Step: 9
Training loss: 0.4401091193497956
Validation loss: 2.420119975968761

Epoch: 5| Step: 10
Training loss: 0.2965941229783642
Validation loss: 2.412785696703833

Epoch: 428| Step: 0
Training loss: 0.9152752908246128
Validation loss: 2.4002353025181704

Epoch: 5| Step: 1
Training loss: 0.9563155943370041
Validation loss: 2.4296496109754364

Epoch: 5| Step: 2
Training loss: 0.8708211361032396
Validation loss: 2.4301725062491637

Epoch: 5| Step: 3
Training loss: 0.6345007006128048
Validation loss: 2.403701162094199

Epoch: 5| Step: 4
Training loss: 0.7082142075241175
Validation loss: 2.397172863875376

Epoch: 5| Step: 5
Training loss: 0.5055041741482748
Validation loss: 2.3915224695643444

Epoch: 5| Step: 6
Training loss: 0.6841657806472834
Validation loss: 2.40335350395216

Epoch: 5| Step: 7
Training loss: 0.9415173286974485
Validation loss: 2.404834694925487

Epoch: 5| Step: 8
Training loss: 0.45298957445240245
Validation loss: 2.4213063308431484

Epoch: 5| Step: 9
Training loss: 0.6566584542127241
Validation loss: 2.4149355566904536

Epoch: 5| Step: 10
Training loss: 0.7176253600711846
Validation loss: 2.427502604685369

Epoch: 429| Step: 0
Training loss: 0.516152401166048
Validation loss: 2.390503616141422

Epoch: 5| Step: 1
Training loss: 0.5798753326128898
Validation loss: 2.4000514040653886

Epoch: 5| Step: 2
Training loss: 0.6621907952133503
Validation loss: 2.398085124406336

Epoch: 5| Step: 3
Training loss: 0.7094340514085027
Validation loss: 2.402326954201725

Epoch: 5| Step: 4
Training loss: 1.044521704368371
Validation loss: 2.4063004998611968

Epoch: 5| Step: 5
Training loss: 1.0123355119631723
Validation loss: 2.3967459318681237

Epoch: 5| Step: 6
Training loss: 0.5657675726753609
Validation loss: 2.3953811536240726

Epoch: 5| Step: 7
Training loss: 0.6967597216039818
Validation loss: 2.397285245836923

Epoch: 5| Step: 8
Training loss: 0.8157153331674947
Validation loss: 2.4120710440540205

Epoch: 5| Step: 9
Training loss: 0.6631649683737006
Validation loss: 2.425101627308894

Epoch: 5| Step: 10
Training loss: 0.6360935582062506
Validation loss: 2.448570775331742

Epoch: 430| Step: 0
Training loss: 0.6491963875014298
Validation loss: 2.4183499948507095

Epoch: 5| Step: 1
Training loss: 0.8016490421089346
Validation loss: 2.4178660386501973

Epoch: 5| Step: 2
Training loss: 0.8661217541462465
Validation loss: 2.402390036815253

Epoch: 5| Step: 3
Training loss: 0.6381442956127451
Validation loss: 2.424153009546388

Epoch: 5| Step: 4
Training loss: 0.8638165225567457
Validation loss: 2.431879017578161

Epoch: 5| Step: 5
Training loss: 0.7334080681505032
Validation loss: 2.4175445382254925

Epoch: 5| Step: 6
Training loss: 0.60328815704241
Validation loss: 2.4038896521110606

Epoch: 5| Step: 7
Training loss: 0.6474702123837831
Validation loss: 2.429411000685936

Epoch: 5| Step: 8
Training loss: 0.7120475905458057
Validation loss: 2.4007809220034733

Epoch: 5| Step: 9
Training loss: 0.8815858133472692
Validation loss: 2.3857759184676217

Epoch: 5| Step: 10
Training loss: 0.6186404930852437
Validation loss: 2.397651046661585

Epoch: 431| Step: 0
Training loss: 0.9341810924687748
Validation loss: 2.3792407392724746

Epoch: 5| Step: 1
Training loss: 0.9352766375384776
Validation loss: 2.3948010960711814

Epoch: 5| Step: 2
Training loss: 0.6426151809906853
Validation loss: 2.4141619718533605

Epoch: 5| Step: 3
Training loss: 0.5055320888733281
Validation loss: 2.4029421337471377

Epoch: 5| Step: 4
Training loss: 0.9396909543561603
Validation loss: 2.41149250864672

Epoch: 5| Step: 5
Training loss: 0.705858195335023
Validation loss: 2.4199263096017853

Epoch: 5| Step: 6
Training loss: 0.6132759045410452
Validation loss: 2.399202776855192

Epoch: 5| Step: 7
Training loss: 0.6353987602670863
Validation loss: 2.4027483247549095

Epoch: 5| Step: 8
Training loss: 0.6472992616061969
Validation loss: 2.4106969260989306

Epoch: 5| Step: 9
Training loss: 0.7886055860392674
Validation loss: 2.43952156546982

Epoch: 5| Step: 10
Training loss: 0.49179194465329207
Validation loss: 2.4335335494756487

Epoch: 432| Step: 0
Training loss: 0.7986730224457843
Validation loss: 2.4269931661507416

Epoch: 5| Step: 1
Training loss: 0.8634329269901082
Validation loss: 2.4376534738912405

Epoch: 5| Step: 2
Training loss: 0.7264816075075493
Validation loss: 2.427115825203386

Epoch: 5| Step: 3
Training loss: 0.8864304330083236
Validation loss: 2.4060019248163185

Epoch: 5| Step: 4
Training loss: 0.6578454650447736
Validation loss: 2.382021349591783

Epoch: 5| Step: 5
Training loss: 0.24190642597520778
Validation loss: 2.3779990739366847

Epoch: 5| Step: 6
Training loss: 0.7117042179906198
Validation loss: 2.382037778428306

Epoch: 5| Step: 7
Training loss: 0.7674706459023546
Validation loss: 2.399284281453628

Epoch: 5| Step: 8
Training loss: 0.6843342503299815
Validation loss: 2.422810973105235

Epoch: 5| Step: 9
Training loss: 0.932131432059749
Validation loss: 2.3938108092225945

Epoch: 5| Step: 10
Training loss: 0.564293703579695
Validation loss: 2.404907058500307

Epoch: 433| Step: 0
Training loss: 0.5774110045124002
Validation loss: 2.4189790801703057

Epoch: 5| Step: 1
Training loss: 0.879635724293823
Validation loss: 2.4101479447539935

Epoch: 5| Step: 2
Training loss: 1.0265257156725953
Validation loss: 2.4360180176153916

Epoch: 5| Step: 3
Training loss: 0.6180083453855634
Validation loss: 2.4346080786132975

Epoch: 5| Step: 4
Training loss: 0.9073203113353935
Validation loss: 2.4595824678546343

Epoch: 5| Step: 5
Training loss: 0.6474664610199913
Validation loss: 2.441329127646126

Epoch: 5| Step: 6
Training loss: 0.5635238706936628
Validation loss: 2.438513192622886

Epoch: 5| Step: 7
Training loss: 0.7578217024096944
Validation loss: 2.4311090505003876

Epoch: 5| Step: 8
Training loss: 0.5605428077470447
Validation loss: 2.4183834581145955

Epoch: 5| Step: 9
Training loss: 0.8085983939659441
Validation loss: 2.4430654549687625

Epoch: 5| Step: 10
Training loss: 0.41369969289757663
Validation loss: 2.432841221731278

Epoch: 434| Step: 0
Training loss: 0.7245982290063622
Validation loss: 2.4206267973226785

Epoch: 5| Step: 1
Training loss: 0.7978276934374239
Validation loss: 2.4262086835408825

Epoch: 5| Step: 2
Training loss: 0.6780338120567483
Validation loss: 2.4338087893747375

Epoch: 5| Step: 3
Training loss: 0.4654983431451651
Validation loss: 2.4481372937173824

Epoch: 5| Step: 4
Training loss: 0.7087866136892804
Validation loss: 2.4237387259095047

Epoch: 5| Step: 5
Training loss: 0.8932735146652513
Validation loss: 2.444590137665272

Epoch: 5| Step: 6
Training loss: 0.8136475968275656
Validation loss: 2.4193563278084276

Epoch: 5| Step: 7
Training loss: 0.8248619354203105
Validation loss: 2.413950830607302

Epoch: 5| Step: 8
Training loss: 0.7023767092294122
Validation loss: 2.3977650292256096

Epoch: 5| Step: 9
Training loss: 0.5178506961195737
Validation loss: 2.409275515399752

Epoch: 5| Step: 10
Training loss: 0.6368792512955809
Validation loss: 2.4130115753628227

Epoch: 435| Step: 0
Training loss: 0.7811766399272939
Validation loss: 2.4195431219689767

Epoch: 5| Step: 1
Training loss: 0.6566316766259657
Validation loss: 2.426365590210578

Epoch: 5| Step: 2
Training loss: 0.6320435125531175
Validation loss: 2.4112254204608297

Epoch: 5| Step: 3
Training loss: 0.9370700486054109
Validation loss: 2.399628794199012

Epoch: 5| Step: 4
Training loss: 0.8322071014972232
Validation loss: 2.4213222273753887

Epoch: 5| Step: 5
Training loss: 0.6955235621686506
Validation loss: 2.4029190987229105

Epoch: 5| Step: 6
Training loss: 0.8415720699203881
Validation loss: 2.425920776203528

Epoch: 5| Step: 7
Training loss: 0.5065775894562727
Validation loss: 2.412002329539174

Epoch: 5| Step: 8
Training loss: 0.6430680746347948
Validation loss: 2.4221048516618597

Epoch: 5| Step: 9
Training loss: 0.6989713902587525
Validation loss: 2.416575968663109

Epoch: 5| Step: 10
Training loss: 0.45616364249673125
Validation loss: 2.4094018673467126

Epoch: 436| Step: 0
Training loss: 0.5626093969988958
Validation loss: 2.374038013562949

Epoch: 5| Step: 1
Training loss: 0.7753199009386409
Validation loss: 2.3767895888795865

Epoch: 5| Step: 2
Training loss: 1.0144817079462036
Validation loss: 2.4020275394409176

Epoch: 5| Step: 3
Training loss: 0.6730895043863554
Validation loss: 2.4090488831173116

Epoch: 5| Step: 4
Training loss: 0.8340261122826061
Validation loss: 2.4002850670015743

Epoch: 5| Step: 5
Training loss: 0.6326803846553606
Validation loss: 2.381097519020963

Epoch: 5| Step: 6
Training loss: 0.37161062283489477
Validation loss: 2.3927261091804843

Epoch: 5| Step: 7
Training loss: 0.6831361819623369
Validation loss: 2.4203739009095027

Epoch: 5| Step: 8
Training loss: 0.7588016307678556
Validation loss: 2.4046737287453888

Epoch: 5| Step: 9
Training loss: 0.6922648212310668
Validation loss: 2.4464776397560652

Epoch: 5| Step: 10
Training loss: 0.6650670475610269
Validation loss: 2.4009972878909696

Epoch: 437| Step: 0
Training loss: 0.7641518101830568
Validation loss: 2.4351398578466483

Epoch: 5| Step: 1
Training loss: 0.874274702557103
Validation loss: 2.4082931439055013

Epoch: 5| Step: 2
Training loss: 0.44553302859095606
Validation loss: 2.398431783625712

Epoch: 5| Step: 3
Training loss: 0.8894965736254551
Validation loss: 2.392324182772165

Epoch: 5| Step: 4
Training loss: 0.946274606694683
Validation loss: 2.4204324512750324

Epoch: 5| Step: 5
Training loss: 0.7355877217170923
Validation loss: 2.41459312810354

Epoch: 5| Step: 6
Training loss: 0.5477774666846997
Validation loss: 2.4168822673597323

Epoch: 5| Step: 7
Training loss: 0.6551064791653478
Validation loss: 2.4116071270078314

Epoch: 5| Step: 8
Training loss: 0.6294169751198571
Validation loss: 2.3692007828936767

Epoch: 5| Step: 9
Training loss: 0.7025252857612612
Validation loss: 2.4051149117774377

Epoch: 5| Step: 10
Training loss: 0.4810605010449189
Validation loss: 2.4197348123661766

Epoch: 438| Step: 0
Training loss: 0.6676441095285301
Validation loss: 2.431975310888641

Epoch: 5| Step: 1
Training loss: 0.7036637043936519
Validation loss: 2.4585018576424207

Epoch: 5| Step: 2
Training loss: 0.5917181837685099
Validation loss: 2.4436631416717374

Epoch: 5| Step: 3
Training loss: 0.7954390809178388
Validation loss: 2.442011153430624

Epoch: 5| Step: 4
Training loss: 0.6434353383469363
Validation loss: 2.443633686511213

Epoch: 5| Step: 5
Training loss: 0.7819826505424268
Validation loss: 2.4535405721611667

Epoch: 5| Step: 6
Training loss: 0.7680666778622175
Validation loss: 2.424855593868462

Epoch: 5| Step: 7
Training loss: 0.47766788671891863
Validation loss: 2.4219468107767943

Epoch: 5| Step: 8
Training loss: 0.6668068668843713
Validation loss: 2.4092840798274224

Epoch: 5| Step: 9
Training loss: 0.8424202719411993
Validation loss: 2.4061591210188378

Epoch: 5| Step: 10
Training loss: 0.6585360853623824
Validation loss: 2.42224771130543

Epoch: 439| Step: 0
Training loss: 0.7354842391772825
Validation loss: 2.4124358504718963

Epoch: 5| Step: 1
Training loss: 0.8349255292199789
Validation loss: 2.398024524235068

Epoch: 5| Step: 2
Training loss: 0.6233650758212246
Validation loss: 2.3877452825065126

Epoch: 5| Step: 3
Training loss: 0.849126919972644
Validation loss: 2.402385354284149

Epoch: 5| Step: 4
Training loss: 0.7520803368703337
Validation loss: 2.4226343611131003

Epoch: 5| Step: 5
Training loss: 0.7051977124862981
Validation loss: 2.3984673311719806

Epoch: 5| Step: 6
Training loss: 0.47460962617341607
Validation loss: 2.4297667116763266

Epoch: 5| Step: 7
Training loss: 0.4000870274702495
Validation loss: 2.4031180753839747

Epoch: 5| Step: 8
Training loss: 0.8300171953166584
Validation loss: 2.423298302477218

Epoch: 5| Step: 9
Training loss: 0.6002121421174956
Validation loss: 2.4368748395610913

Epoch: 5| Step: 10
Training loss: 0.7003283726716082
Validation loss: 2.4093238067221145

Epoch: 440| Step: 0
Training loss: 0.49329063377601967
Validation loss: 2.4175772438358347

Epoch: 5| Step: 1
Training loss: 0.47873782234540607
Validation loss: 2.4436984933754853

Epoch: 5| Step: 2
Training loss: 0.5398836929847355
Validation loss: 2.4398463357008584

Epoch: 5| Step: 3
Training loss: 0.6496676530691885
Validation loss: 2.443704372425163

Epoch: 5| Step: 4
Training loss: 0.6568949119097884
Validation loss: 2.419138609134637

Epoch: 5| Step: 5
Training loss: 0.5535925413975025
Validation loss: 2.4194863206418438

Epoch: 5| Step: 6
Training loss: 0.9736763993190038
Validation loss: 2.40889452544872

Epoch: 5| Step: 7
Training loss: 0.8766933812638784
Validation loss: 2.4085537611342773

Epoch: 5| Step: 8
Training loss: 0.8376682937971596
Validation loss: 2.417509789752923

Epoch: 5| Step: 9
Training loss: 0.8376249590214633
Validation loss: 2.4356296316471506

Epoch: 5| Step: 10
Training loss: 0.5341977355251354
Validation loss: 2.4198104903081243

Epoch: 441| Step: 0
Training loss: 0.7567824609383458
Validation loss: 2.403484494563743

Epoch: 5| Step: 1
Training loss: 0.6535059917353309
Validation loss: 2.444637998796599

Epoch: 5| Step: 2
Training loss: 0.6412106604899407
Validation loss: 2.420356753589724

Epoch: 5| Step: 3
Training loss: 0.7874581295568713
Validation loss: 2.443439316458461

Epoch: 5| Step: 4
Training loss: 0.5024893008464296
Validation loss: 2.430856165737371

Epoch: 5| Step: 5
Training loss: 0.6910905925653593
Validation loss: 2.4584819178018718

Epoch: 5| Step: 6
Training loss: 0.5894548510911063
Validation loss: 2.422611164118819

Epoch: 5| Step: 7
Training loss: 0.6629903328336068
Validation loss: 2.458349367245513

Epoch: 5| Step: 8
Training loss: 0.5219434225033932
Validation loss: 2.4615245717189604

Epoch: 5| Step: 9
Training loss: 0.5224048620060544
Validation loss: 2.4231508554918624

Epoch: 5| Step: 10
Training loss: 1.0080823906575096
Validation loss: 2.446826653558262

Epoch: 442| Step: 0
Training loss: 0.6013462123700501
Validation loss: 2.487182395674847

Epoch: 5| Step: 1
Training loss: 0.6211159420247327
Validation loss: 2.4632698815725447

Epoch: 5| Step: 2
Training loss: 0.9159471042927335
Validation loss: 2.431293569890865

Epoch: 5| Step: 3
Training loss: 0.6595204242684505
Validation loss: 2.422877665904254

Epoch: 5| Step: 4
Training loss: 0.7320827258401896
Validation loss: 2.439397570221475

Epoch: 5| Step: 5
Training loss: 0.3884381113638329
Validation loss: 2.440296619683769

Epoch: 5| Step: 6
Training loss: 0.769243912859646
Validation loss: 2.438105515080279

Epoch: 5| Step: 7
Training loss: 0.6804234258577251
Validation loss: 2.4345092742093044

Epoch: 5| Step: 8
Training loss: 0.5009146609367983
Validation loss: 2.4217960351408676

Epoch: 5| Step: 9
Training loss: 0.8034108970389287
Validation loss: 2.453651670048381

Epoch: 5| Step: 10
Training loss: 0.5243087179693493
Validation loss: 2.427991558147921

Epoch: 443| Step: 0
Training loss: 0.49206187143555785
Validation loss: 2.40410290543227

Epoch: 5| Step: 1
Training loss: 0.6853208250696008
Validation loss: 2.4302406975123394

Epoch: 5| Step: 2
Training loss: 0.7695607213607232
Validation loss: 2.438635403646132

Epoch: 5| Step: 3
Training loss: 0.6134115675945883
Validation loss: 2.42621670451782

Epoch: 5| Step: 4
Training loss: 0.6775082037664807
Validation loss: 2.4303968322853344

Epoch: 5| Step: 5
Training loss: 0.668430213585331
Validation loss: 2.429279313812011

Epoch: 5| Step: 6
Training loss: 0.7210131136195038
Validation loss: 2.4445663058512914

Epoch: 5| Step: 7
Training loss: 0.5285711909122375
Validation loss: 2.426156688666188

Epoch: 5| Step: 8
Training loss: 0.8598686187769106
Validation loss: 2.403639646546698

Epoch: 5| Step: 9
Training loss: 0.5787096933125547
Validation loss: 2.417782328318439

Epoch: 5| Step: 10
Training loss: 0.626054517917678
Validation loss: 2.391657445017355

Epoch: 444| Step: 0
Training loss: 0.7645269421632088
Validation loss: 2.4095285456872992

Epoch: 5| Step: 1
Training loss: 0.7430969689218189
Validation loss: 2.428893895424672

Epoch: 5| Step: 2
Training loss: 0.5137745859709202
Validation loss: 2.419935833480207

Epoch: 5| Step: 3
Training loss: 0.5448184445026116
Validation loss: 2.432615474975103

Epoch: 5| Step: 4
Training loss: 0.5552233404692375
Validation loss: 2.4502755603433455

Epoch: 5| Step: 5
Training loss: 0.6449926170030073
Validation loss: 2.437646710503427

Epoch: 5| Step: 6
Training loss: 0.59156127369346
Validation loss: 2.45776829309991

Epoch: 5| Step: 7
Training loss: 0.6505018030401131
Validation loss: 2.447593421164092

Epoch: 5| Step: 8
Training loss: 0.6144156442743478
Validation loss: 2.4327782732671985

Epoch: 5| Step: 9
Training loss: 0.8488883982367649
Validation loss: 2.4408931353430066

Epoch: 5| Step: 10
Training loss: 0.6166044934178639
Validation loss: 2.4332122680186106

Epoch: 445| Step: 0
Training loss: 0.3749709118051855
Validation loss: 2.438782999282352

Epoch: 5| Step: 1
Training loss: 0.366964434781805
Validation loss: 2.4209113663385073

Epoch: 5| Step: 2
Training loss: 0.9677468920780733
Validation loss: 2.408719485219708

Epoch: 5| Step: 3
Training loss: 0.4651853764608661
Validation loss: 2.4100483891336917

Epoch: 5| Step: 4
Training loss: 0.5642471729726624
Validation loss: 2.3984205785092088

Epoch: 5| Step: 5
Training loss: 0.7526503464061599
Validation loss: 2.445148767486379

Epoch: 5| Step: 6
Training loss: 0.7817264629855022
Validation loss: 2.4493020798725724

Epoch: 5| Step: 7
Training loss: 0.6582014497005525
Validation loss: 2.441247190614114

Epoch: 5| Step: 8
Training loss: 0.7375869715858794
Validation loss: 2.453158069892191

Epoch: 5| Step: 9
Training loss: 0.788319303805766
Validation loss: 2.4619469055173675

Epoch: 5| Step: 10
Training loss: 0.4361525801446636
Validation loss: 2.4631167361007873

Epoch: 446| Step: 0
Training loss: 0.5895829287236671
Validation loss: 2.4690830270373247

Epoch: 5| Step: 1
Training loss: 0.4310959879591377
Validation loss: 2.4606874483771852

Epoch: 5| Step: 2
Training loss: 0.5629789115079745
Validation loss: 2.450247229381892

Epoch: 5| Step: 3
Training loss: 0.5715965552010654
Validation loss: 2.416893535385219

Epoch: 5| Step: 4
Training loss: 0.8005424329482377
Validation loss: 2.417002981954621

Epoch: 5| Step: 5
Training loss: 0.6700852086556834
Validation loss: 2.417997181377829

Epoch: 5| Step: 6
Training loss: 0.7992030152443452
Validation loss: 2.418919337292803

Epoch: 5| Step: 7
Training loss: 0.3220478246644395
Validation loss: 2.399549617560348

Epoch: 5| Step: 8
Training loss: 0.5777022646220575
Validation loss: 2.41757579742626

Epoch: 5| Step: 9
Training loss: 0.9163144403047719
Validation loss: 2.41242960723512

Epoch: 5| Step: 10
Training loss: 0.528374660326684
Validation loss: 2.4088187480119663

Epoch: 447| Step: 0
Training loss: 0.768301431306645
Validation loss: 2.399030544699605

Epoch: 5| Step: 1
Training loss: 0.6718124316158077
Validation loss: 2.4044276521528394

Epoch: 5| Step: 2
Training loss: 0.5631505065797825
Validation loss: 2.4020114896013376

Epoch: 5| Step: 3
Training loss: 0.6565677690907337
Validation loss: 2.400237440811137

Epoch: 5| Step: 4
Training loss: 0.4824907199678744
Validation loss: 2.430111179737918

Epoch: 5| Step: 5
Training loss: 0.7080342886348082
Validation loss: 2.391070676168029

Epoch: 5| Step: 6
Training loss: 0.7780652172608983
Validation loss: 2.404978121543572

Epoch: 5| Step: 7
Training loss: 0.43543945150977015
Validation loss: 2.399554934902074

Epoch: 5| Step: 8
Training loss: 0.48172457876771535
Validation loss: 2.4022270072225522

Epoch: 5| Step: 9
Training loss: 0.7784076866587811
Validation loss: 2.3916457944032614

Epoch: 5| Step: 10
Training loss: 0.5489543077392449
Validation loss: 2.4171578187892235

Epoch: 448| Step: 0
Training loss: 0.5563452756916826
Validation loss: 2.442964029646167

Epoch: 5| Step: 1
Training loss: 0.6007466915196672
Validation loss: 2.435788173248135

Epoch: 5| Step: 2
Training loss: 0.6680238489102467
Validation loss: 2.448823579045644

Epoch: 5| Step: 3
Training loss: 0.7573990628061673
Validation loss: 2.415950884136355

Epoch: 5| Step: 4
Training loss: 0.6863626913225511
Validation loss: 2.4406184275754774

Epoch: 5| Step: 5
Training loss: 0.6988461743194065
Validation loss: 2.4555188442596645

Epoch: 5| Step: 6
Training loss: 0.6159315730428592
Validation loss: 2.440278257144192

Epoch: 5| Step: 7
Training loss: 0.5848457847190885
Validation loss: 2.4181330697557137

Epoch: 5| Step: 8
Training loss: 0.491388671754672
Validation loss: 2.400354649889378

Epoch: 5| Step: 9
Training loss: 0.7165179632481359
Validation loss: 2.4043031276259943

Epoch: 5| Step: 10
Training loss: 0.4752940510035417
Validation loss: 2.403601108003774

Epoch: 449| Step: 0
Training loss: 0.4990063569193389
Validation loss: 2.388716518537737

Epoch: 5| Step: 1
Training loss: 0.5969146915040797
Validation loss: 2.3785107898831255

Epoch: 5| Step: 2
Training loss: 0.6556094994908184
Validation loss: 2.3812678260126305

Epoch: 5| Step: 3
Training loss: 0.4686372780370491
Validation loss: 2.391386774664562

Epoch: 5| Step: 4
Training loss: 0.4156608680793784
Validation loss: 2.420326395682797

Epoch: 5| Step: 5
Training loss: 0.48721751501717026
Validation loss: 2.4213850761004534

Epoch: 5| Step: 6
Training loss: 0.5931300138737926
Validation loss: 2.408680801782515

Epoch: 5| Step: 7
Training loss: 0.799024860806947
Validation loss: 2.4212895167639257

Epoch: 5| Step: 8
Training loss: 0.8128947619470844
Validation loss: 2.4395056540673554

Epoch: 5| Step: 9
Training loss: 0.5677910549079994
Validation loss: 2.4055071780090724

Epoch: 5| Step: 10
Training loss: 0.8088212361277743
Validation loss: 2.4171818625002732

Epoch: 450| Step: 0
Training loss: 0.5403492262776048
Validation loss: 2.4114702787395563

Epoch: 5| Step: 1
Training loss: 0.470099065516147
Validation loss: 2.4239994296686453

Epoch: 5| Step: 2
Training loss: 0.7564799597557254
Validation loss: 2.3937549823306554

Epoch: 5| Step: 3
Training loss: 0.5156538984118977
Validation loss: 2.3982044654695733

Epoch: 5| Step: 4
Training loss: 0.5573283982575565
Validation loss: 2.4125294237628814

Epoch: 5| Step: 5
Training loss: 0.6135111335406369
Validation loss: 2.4150094896367573

Epoch: 5| Step: 6
Training loss: 0.44841103292906903
Validation loss: 2.428418716659375

Epoch: 5| Step: 7
Training loss: 0.6963737618184214
Validation loss: 2.426340192093997

Epoch: 5| Step: 8
Training loss: 0.7164833984102135
Validation loss: 2.4291087988934947

Epoch: 5| Step: 9
Training loss: 0.6295751958994812
Validation loss: 2.4304365260389127

Epoch: 5| Step: 10
Training loss: 0.7568953952199172
Validation loss: 2.436689969521439

Epoch: 451| Step: 0
Training loss: 0.5595052524845093
Validation loss: 2.4262549350817646

Epoch: 5| Step: 1
Training loss: 0.793191023619411
Validation loss: 2.438240155554597

Epoch: 5| Step: 2
Training loss: 0.564723969523703
Validation loss: 2.4369069301624515

Epoch: 5| Step: 3
Training loss: 0.4096437794906242
Validation loss: 2.443257319724545

Epoch: 5| Step: 4
Training loss: 0.5249385377692206
Validation loss: 2.4117517984873205

Epoch: 5| Step: 5
Training loss: 0.6149262883044083
Validation loss: 2.403882361812214

Epoch: 5| Step: 6
Training loss: 0.9297792084925067
Validation loss: 2.404908955986746

Epoch: 5| Step: 7
Training loss: 0.5096956694677393
Validation loss: 2.408309865627779

Epoch: 5| Step: 8
Training loss: 0.578116365316707
Validation loss: 2.4066885016059323

Epoch: 5| Step: 9
Training loss: 0.422387253626727
Validation loss: 2.390702454070067

Epoch: 5| Step: 10
Training loss: 0.6087105870265768
Validation loss: 2.393653804551503

Epoch: 452| Step: 0
Training loss: 0.7433757706005207
Validation loss: 2.365951967243326

Epoch: 5| Step: 1
Training loss: 0.6147259746043777
Validation loss: 2.387069104729095

Epoch: 5| Step: 2
Training loss: 0.8210045937608262
Validation loss: 2.368141897317912

Epoch: 5| Step: 3
Training loss: 0.5551941666456731
Validation loss: 2.389538781920101

Epoch: 5| Step: 4
Training loss: 0.5978719035504498
Validation loss: 2.3787956166940623

Epoch: 5| Step: 5
Training loss: 0.6377882604931914
Validation loss: 2.365938067892323

Epoch: 5| Step: 6
Training loss: 0.6849243511069475
Validation loss: 2.403202250642494

Epoch: 5| Step: 7
Training loss: 0.4458926587726626
Validation loss: 2.3757162692538514

Epoch: 5| Step: 8
Training loss: 0.3697430977244817
Validation loss: 2.3953178478962274

Epoch: 5| Step: 9
Training loss: 0.5022953217746688
Validation loss: 2.372603570193774

Epoch: 5| Step: 10
Training loss: 0.4978556696055288
Validation loss: 2.3985038150385556

Epoch: 453| Step: 0
Training loss: 0.6625321650344232
Validation loss: 2.3788950660682855

Epoch: 5| Step: 1
Training loss: 0.7007395014240115
Validation loss: 2.3773104041151316

Epoch: 5| Step: 2
Training loss: 0.5706699505301865
Validation loss: 2.397502616892787

Epoch: 5| Step: 3
Training loss: 0.18663605690400062
Validation loss: 2.410336589529827

Epoch: 5| Step: 4
Training loss: 0.5968791671927015
Validation loss: 2.3991121807072764

Epoch: 5| Step: 5
Training loss: 0.7823951720443719
Validation loss: 2.434862441528805

Epoch: 5| Step: 6
Training loss: 0.4606238930894655
Validation loss: 2.4355579661517024

Epoch: 5| Step: 7
Training loss: 0.546321779811849
Validation loss: 2.3989109925264116

Epoch: 5| Step: 8
Training loss: 0.5910784701198335
Validation loss: 2.4042818724698822

Epoch: 5| Step: 9
Training loss: 0.730825979427049
Validation loss: 2.4230827842221916

Epoch: 5| Step: 10
Training loss: 0.5698436220554368
Validation loss: 2.4445280465210666

Epoch: 454| Step: 0
Training loss: 0.6595213280252068
Validation loss: 2.4158097219857524

Epoch: 5| Step: 1
Training loss: 0.6613752182733222
Validation loss: 2.4246127455492834

Epoch: 5| Step: 2
Training loss: 0.645407202839858
Validation loss: 2.4460284443638556

Epoch: 5| Step: 3
Training loss: 0.524217224118873
Validation loss: 2.424177657523762

Epoch: 5| Step: 4
Training loss: 0.5517875730877385
Validation loss: 2.4264798245625174

Epoch: 5| Step: 5
Training loss: 0.4520216860980782
Validation loss: 2.390655881181058

Epoch: 5| Step: 6
Training loss: 0.7995722133571574
Validation loss: 2.419259379633196

Epoch: 5| Step: 7
Training loss: 0.6418631614031617
Validation loss: 2.388013513197137

Epoch: 5| Step: 8
Training loss: 0.3219723378377444
Validation loss: 2.398491144323589

Epoch: 5| Step: 9
Training loss: 0.5933046678608614
Validation loss: 2.409231473623191

Epoch: 5| Step: 10
Training loss: 0.5900458690625745
Validation loss: 2.423451669730286

Epoch: 455| Step: 0
Training loss: 0.2851083140384587
Validation loss: 2.416768935023033

Epoch: 5| Step: 1
Training loss: 0.5657562999180724
Validation loss: 2.42283311747664

Epoch: 5| Step: 2
Training loss: 0.4723348233978595
Validation loss: 2.4398474337224108

Epoch: 5| Step: 3
Training loss: 0.8488905397896195
Validation loss: 2.424145532192856

Epoch: 5| Step: 4
Training loss: 0.8022640363250495
Validation loss: 2.4415825892927545

Epoch: 5| Step: 5
Training loss: 0.7075084951315345
Validation loss: 2.463974227102872

Epoch: 5| Step: 6
Training loss: 0.5293072914140227
Validation loss: 2.4326353154242404

Epoch: 5| Step: 7
Training loss: 0.7031541606366313
Validation loss: 2.4160759585446003

Epoch: 5| Step: 8
Training loss: 0.2731656630643858
Validation loss: 2.410657819232131

Epoch: 5| Step: 9
Training loss: 0.6683766419116047
Validation loss: 2.3926273908601137

Epoch: 5| Step: 10
Training loss: 0.41248244985179383
Validation loss: 2.3838117285294778

Epoch: 456| Step: 0
Training loss: 0.4977825585393059
Validation loss: 2.3474838747470193

Epoch: 5| Step: 1
Training loss: 0.1975591289005772
Validation loss: 2.3571578426956354

Epoch: 5| Step: 2
Training loss: 0.8342992469603134
Validation loss: 2.3850581445165635

Epoch: 5| Step: 3
Training loss: 0.5693672917469218
Validation loss: 2.3489791017547414

Epoch: 5| Step: 4
Training loss: 0.7066064686109043
Validation loss: 2.3926396388604543

Epoch: 5| Step: 5
Training loss: 0.572975369538205
Validation loss: 2.4108225208541056

Epoch: 5| Step: 6
Training loss: 0.59425608499354
Validation loss: 2.430855697484017

Epoch: 5| Step: 7
Training loss: 0.5784032770519758
Validation loss: 2.448672215500424

Epoch: 5| Step: 8
Training loss: 0.6495599797887334
Validation loss: 2.436000555248026

Epoch: 5| Step: 9
Training loss: 0.43782031730953674
Validation loss: 2.4701877798267673

Epoch: 5| Step: 10
Training loss: 0.6622128701131923
Validation loss: 2.446612240729518

Epoch: 457| Step: 0
Training loss: 0.7417121167847626
Validation loss: 2.4668264313463792

Epoch: 5| Step: 1
Training loss: 0.46291080865435374
Validation loss: 2.4477603521208353

Epoch: 5| Step: 2
Training loss: 0.44920566373920595
Validation loss: 2.4693325482631248

Epoch: 5| Step: 3
Training loss: 0.6027875292141112
Validation loss: 2.482327821565597

Epoch: 5| Step: 4
Training loss: 0.6620466039379338
Validation loss: 2.455915239626801

Epoch: 5| Step: 5
Training loss: 0.4919632900545441
Validation loss: 2.4635114114889336

Epoch: 5| Step: 6
Training loss: 0.5105996452676218
Validation loss: 2.479147420760046

Epoch: 5| Step: 7
Training loss: 0.639801845645538
Validation loss: 2.460936269712621

Epoch: 5| Step: 8
Training loss: 0.49876374655974803
Validation loss: 2.4480309230415136

Epoch: 5| Step: 9
Training loss: 0.7964062153331801
Validation loss: 2.4470072994429644

Epoch: 5| Step: 10
Training loss: 0.4932590959592883
Validation loss: 2.4332132752632196

Epoch: 458| Step: 0
Training loss: 0.46073154115363274
Validation loss: 2.4364409037659662

Epoch: 5| Step: 1
Training loss: 0.5757560652008805
Validation loss: 2.396359437708388

Epoch: 5| Step: 2
Training loss: 0.5178731976919005
Validation loss: 2.4175291163194674

Epoch: 5| Step: 3
Training loss: 0.5982402366833042
Validation loss: 2.414240987834951

Epoch: 5| Step: 4
Training loss: 0.8660338692814588
Validation loss: 2.4172113456817015

Epoch: 5| Step: 5
Training loss: 0.790700439955132
Validation loss: 2.4027804006128766

Epoch: 5| Step: 6
Training loss: 0.5899499961708833
Validation loss: 2.4382494512359933

Epoch: 5| Step: 7
Training loss: 0.4589149422580556
Validation loss: 2.391875839847828

Epoch: 5| Step: 8
Training loss: 0.6130182710743663
Validation loss: 2.4273994993692996

Epoch: 5| Step: 9
Training loss: 0.23233456133622152
Validation loss: 2.4226753640429353

Epoch: 5| Step: 10
Training loss: 0.371469989582316
Validation loss: 2.42647265601851

Epoch: 459| Step: 0
Training loss: 0.676692876961967
Validation loss: 2.409878091654121

Epoch: 5| Step: 1
Training loss: 0.5135942987961908
Validation loss: 2.433972676985616

Epoch: 5| Step: 2
Training loss: 0.48826989732896114
Validation loss: 2.4121277383523227

Epoch: 5| Step: 3
Training loss: 0.9092491115201774
Validation loss: 2.413695622945774

Epoch: 5| Step: 4
Training loss: 0.5460579899988827
Validation loss: 2.431077362649396

Epoch: 5| Step: 5
Training loss: 0.42058369137530993
Validation loss: 2.430028633939149

Epoch: 5| Step: 6
Training loss: 0.5601653551880635
Validation loss: 2.4670678531132593

Epoch: 5| Step: 7
Training loss: 0.6632756452020331
Validation loss: 2.429353641790416

Epoch: 5| Step: 8
Training loss: 0.4533969786380511
Validation loss: 2.42895521467384

Epoch: 5| Step: 9
Training loss: 0.36097869472825433
Validation loss: 2.424656822491459

Epoch: 5| Step: 10
Training loss: 0.5555101660889235
Validation loss: 2.400527732178377

Epoch: 460| Step: 0
Training loss: 0.706407303297797
Validation loss: 2.4244270335403546

Epoch: 5| Step: 1
Training loss: 0.6852304972977195
Validation loss: 2.397949967652425

Epoch: 5| Step: 2
Training loss: 0.732277248090492
Validation loss: 2.3938209371316628

Epoch: 5| Step: 3
Training loss: 0.6131134289535282
Validation loss: 2.406111135898661

Epoch: 5| Step: 4
Training loss: 0.47126239775481016
Validation loss: 2.4002347951806486

Epoch: 5| Step: 5
Training loss: 0.6288026759945491
Validation loss: 2.4027216596315606

Epoch: 5| Step: 6
Training loss: 0.5777000721412893
Validation loss: 2.420022235274297

Epoch: 5| Step: 7
Training loss: 0.32275390625
Validation loss: 2.4086901327797565

Epoch: 5| Step: 8
Training loss: 0.48777068338283375
Validation loss: 2.415826797583761

Epoch: 5| Step: 9
Training loss: 0.4900486810986196
Validation loss: 2.388629333161802

Epoch: 5| Step: 10
Training loss: 0.4269889886282756
Validation loss: 2.4512660069063354

Epoch: 461| Step: 0
Training loss: 0.3285923989450031
Validation loss: 2.433430416298967

Epoch: 5| Step: 1
Training loss: 0.5606558291784121
Validation loss: 2.43742126261947

Epoch: 5| Step: 2
Training loss: 0.4930763846536315
Validation loss: 2.448906908755783

Epoch: 5| Step: 3
Training loss: 0.7059781572539938
Validation loss: 2.4396576619921513

Epoch: 5| Step: 4
Training loss: 0.6104342229182405
Validation loss: 2.432244840413929

Epoch: 5| Step: 5
Training loss: 0.4838130213472637
Validation loss: 2.4464472145906493

Epoch: 5| Step: 6
Training loss: 0.7131746745214557
Validation loss: 2.434988879196742

Epoch: 5| Step: 7
Training loss: 0.48192097841581444
Validation loss: 2.4232147903833687

Epoch: 5| Step: 8
Training loss: 0.5439152597997811
Validation loss: 2.4243733413250252

Epoch: 5| Step: 9
Training loss: 0.6015036913377187
Validation loss: 2.4087464394242337

Epoch: 5| Step: 10
Training loss: 0.5985224063490612
Validation loss: 2.4163674037365297

Epoch: 462| Step: 0
Training loss: 0.599367521635147
Validation loss: 2.4076169311377527

Epoch: 5| Step: 1
Training loss: 0.4796437414383525
Validation loss: 2.428791508871461

Epoch: 5| Step: 2
Training loss: 0.6567551167538901
Validation loss: 2.41345917756656

Epoch: 5| Step: 3
Training loss: 0.40041719674119325
Validation loss: 2.420948730283098

Epoch: 5| Step: 4
Training loss: 0.615740540597905
Validation loss: 2.4634234525287386

Epoch: 5| Step: 5
Training loss: 0.5813013915446419
Validation loss: 2.457081288364664

Epoch: 5| Step: 6
Training loss: 0.6968517624611528
Validation loss: 2.4685567175543204

Epoch: 5| Step: 7
Training loss: 0.6201243242468879
Validation loss: 2.482376769618529

Epoch: 5| Step: 8
Training loss: 0.3596063366881147
Validation loss: 2.4641759536703933

Epoch: 5| Step: 9
Training loss: 0.6081743884050721
Validation loss: 2.4673470762922696

Epoch: 5| Step: 10
Training loss: 0.44527048615475545
Validation loss: 2.4380185401588284

Epoch: 463| Step: 0
Training loss: 0.7523055402613342
Validation loss: 2.439245862438571

Epoch: 5| Step: 1
Training loss: 0.6864298815081737
Validation loss: 2.4273346153782427

Epoch: 5| Step: 2
Training loss: 0.5937253545364348
Validation loss: 2.400091068016691

Epoch: 5| Step: 3
Training loss: 0.48992493730846265
Validation loss: 2.4127355780292894

Epoch: 5| Step: 4
Training loss: 0.6375074124372795
Validation loss: 2.4043396364954055

Epoch: 5| Step: 5
Training loss: 0.45561497665494466
Validation loss: 2.3837536574209817

Epoch: 5| Step: 6
Training loss: 0.335222914763662
Validation loss: 2.382656703020048

Epoch: 5| Step: 7
Training loss: 0.6275963974045756
Validation loss: 2.384686484868884

Epoch: 5| Step: 8
Training loss: 0.36966482413778395
Validation loss: 2.409689212037214

Epoch: 5| Step: 9
Training loss: 0.39219660273470963
Validation loss: 2.414633250198102

Epoch: 5| Step: 10
Training loss: 0.6605427304797143
Validation loss: 2.4336191472091984

Epoch: 464| Step: 0
Training loss: 0.5003298625042049
Validation loss: 2.4266117494608106

Epoch: 5| Step: 1
Training loss: 0.5394567071020926
Validation loss: 2.4084402577600676

Epoch: 5| Step: 2
Training loss: 0.22450915049328013
Validation loss: 2.4544264183371025

Epoch: 5| Step: 3
Training loss: 0.9171357616278262
Validation loss: 2.4381538830851794

Epoch: 5| Step: 4
Training loss: 0.3062723827940874
Validation loss: 2.407076045144228

Epoch: 5| Step: 5
Training loss: 0.4506417995924446
Validation loss: 2.4485893374305014

Epoch: 5| Step: 6
Training loss: 0.6651854501004664
Validation loss: 2.4236756039686207

Epoch: 5| Step: 7
Training loss: 0.3556842150941181
Validation loss: 2.404616827784056

Epoch: 5| Step: 8
Training loss: 0.6730170856067025
Validation loss: 2.4141161252575634

Epoch: 5| Step: 9
Training loss: 0.5345287403002054
Validation loss: 2.421047922383579

Epoch: 5| Step: 10
Training loss: 0.6029818004135947
Validation loss: 2.4040531442658777

Epoch: 465| Step: 0
Training loss: 0.6105705173671663
Validation loss: 2.3848046689482563

Epoch: 5| Step: 1
Training loss: 0.7982409121375073
Validation loss: 2.4183539722616616

Epoch: 5| Step: 2
Training loss: 0.533614059664931
Validation loss: 2.4036424964097076

Epoch: 5| Step: 3
Training loss: 0.5825540639485258
Validation loss: 2.4039423776114757

Epoch: 5| Step: 4
Training loss: 0.5464312796877326
Validation loss: 2.3985533920613444

Epoch: 5| Step: 5
Training loss: 0.4130588098731443
Validation loss: 2.4362015601193305

Epoch: 5| Step: 6
Training loss: 0.5222223895942925
Validation loss: 2.4104484056210085

Epoch: 5| Step: 7
Training loss: 0.5928706383236056
Validation loss: 2.4262172803872293

Epoch: 5| Step: 8
Training loss: 0.6520219797352514
Validation loss: 2.410646388594203

Epoch: 5| Step: 9
Training loss: 0.3172936886585019
Validation loss: 2.412093923657985

Epoch: 5| Step: 10
Training loss: 0.22213266113080748
Validation loss: 2.4330281101461124

Epoch: 466| Step: 0
Training loss: 0.6031347017051458
Validation loss: 2.4242882810995456

Epoch: 5| Step: 1
Training loss: 0.5214877182071117
Validation loss: 2.4505279941242146

Epoch: 5| Step: 2
Training loss: 0.34814475595860234
Validation loss: 2.422735563484401

Epoch: 5| Step: 3
Training loss: 0.6123872789474456
Validation loss: 2.4147894816321616

Epoch: 5| Step: 4
Training loss: 0.2874310566295471
Validation loss: 2.432329016351267

Epoch: 5| Step: 5
Training loss: 0.6434381637088119
Validation loss: 2.4461643266363793

Epoch: 5| Step: 6
Training loss: 0.6947050763170542
Validation loss: 2.4448309785351747

Epoch: 5| Step: 7
Training loss: 0.6438101925532211
Validation loss: 2.452181896402363

Epoch: 5| Step: 8
Training loss: 0.4321286821095376
Validation loss: 2.439519043360242

Epoch: 5| Step: 9
Training loss: 0.4750488977611584
Validation loss: 2.4469363998726443

Epoch: 5| Step: 10
Training loss: 0.5399319644294939
Validation loss: 2.4328263409566393

Epoch: 467| Step: 0
Training loss: 0.5299861122507074
Validation loss: 2.420458257725886

Epoch: 5| Step: 1
Training loss: 0.5830703267330584
Validation loss: 2.420597326087245

Epoch: 5| Step: 2
Training loss: 0.35731390067375307
Validation loss: 2.4132291082268758

Epoch: 5| Step: 3
Training loss: 0.5917364914306704
Validation loss: 2.405321360461187

Epoch: 5| Step: 4
Training loss: 0.4714932122465038
Validation loss: 2.3883692617516052

Epoch: 5| Step: 5
Training loss: 0.5546101529634089
Validation loss: 2.397687656285629

Epoch: 5| Step: 6
Training loss: 0.5592190104097846
Validation loss: 2.39107791653912

Epoch: 5| Step: 7
Training loss: 0.44659376698315684
Validation loss: 2.370669126732591

Epoch: 5| Step: 8
Training loss: 0.44924046007852547
Validation loss: 2.386713326723263

Epoch: 5| Step: 9
Training loss: 0.5380399930139141
Validation loss: 2.398081009681145

Epoch: 5| Step: 10
Training loss: 0.8499935991382817
Validation loss: 2.386471399953884

Epoch: 468| Step: 0
Training loss: 0.8097484654891669
Validation loss: 2.4003260330361753

Epoch: 5| Step: 1
Training loss: 0.701317115978596
Validation loss: 2.384793324554174

Epoch: 5| Step: 2
Training loss: 0.3919896512027906
Validation loss: 2.3952014048685624

Epoch: 5| Step: 3
Training loss: 0.4146711446588269
Validation loss: 2.426952240394697

Epoch: 5| Step: 4
Training loss: 0.3842330383585302
Validation loss: 2.4684334164229873

Epoch: 5| Step: 5
Training loss: 0.6689863651793534
Validation loss: 2.435602066058499

Epoch: 5| Step: 6
Training loss: 0.49009866849900946
Validation loss: 2.468053048281232

Epoch: 5| Step: 7
Training loss: 0.43281400866193903
Validation loss: 2.471195940768414

Epoch: 5| Step: 8
Training loss: 0.5715737179781039
Validation loss: 2.4448949882077082

Epoch: 5| Step: 9
Training loss: 0.5596048500893148
Validation loss: 2.474142584596914

Epoch: 5| Step: 10
Training loss: 0.30810903556197977
Validation loss: 2.4952571034908195

Epoch: 469| Step: 0
Training loss: 0.6362207255345674
Validation loss: 2.474427060000287

Epoch: 5| Step: 1
Training loss: 0.44429908012700164
Validation loss: 2.45693168149503

Epoch: 5| Step: 2
Training loss: 0.6862827275155493
Validation loss: 2.4491057385154154

Epoch: 5| Step: 3
Training loss: 0.4360196408782498
Validation loss: 2.4229689346115855

Epoch: 5| Step: 4
Training loss: 0.5086394106383718
Validation loss: 2.4096371341325056

Epoch: 5| Step: 5
Training loss: 0.4089622192794135
Validation loss: 2.421448419205572

Epoch: 5| Step: 6
Training loss: 0.6848341233527513
Validation loss: 2.4181031578351684

Epoch: 5| Step: 7
Training loss: 0.2479038802557431
Validation loss: 2.416103598890304

Epoch: 5| Step: 8
Training loss: 0.6411708739096141
Validation loss: 2.4280919428029097

Epoch: 5| Step: 9
Training loss: 0.5170929560148904
Validation loss: 2.428985976622995

Epoch: 5| Step: 10
Training loss: 0.4984217859499689
Validation loss: 2.4119041950453197

Epoch: 470| Step: 0
Training loss: 0.6945588173989622
Validation loss: 2.423335754450984

Epoch: 5| Step: 1
Training loss: 0.521260931600205
Validation loss: 2.4319428853490797

Epoch: 5| Step: 2
Training loss: 0.575113494701587
Validation loss: 2.409979656307052

Epoch: 5| Step: 3
Training loss: 0.596667175661257
Validation loss: 2.4414270344167366

Epoch: 5| Step: 4
Training loss: 0.46784182627970833
Validation loss: 2.438978357415277

Epoch: 5| Step: 5
Training loss: 0.4996915849538974
Validation loss: 2.4629261300893788

Epoch: 5| Step: 6
Training loss: 0.451983394944434
Validation loss: 2.449471316240699

Epoch: 5| Step: 7
Training loss: 0.42856506785713433
Validation loss: 2.450714313619778

Epoch: 5| Step: 8
Training loss: 0.3740128797032044
Validation loss: 2.4266256504430634

Epoch: 5| Step: 9
Training loss: 0.4966954164643349
Validation loss: 2.4124684340609295

Epoch: 5| Step: 10
Training loss: 0.5288702170692867
Validation loss: 2.4168390775486914

Epoch: 471| Step: 0
Training loss: 0.4606257046832591
Validation loss: 2.3986912407049283

Epoch: 5| Step: 1
Training loss: 0.4694615843974541
Validation loss: 2.388618936387159

Epoch: 5| Step: 2
Training loss: 0.6953637607838083
Validation loss: 2.3876243492351787

Epoch: 5| Step: 3
Training loss: 0.2692417718759983
Validation loss: 2.369959335769235

Epoch: 5| Step: 4
Training loss: 0.4730411727649793
Validation loss: 2.3849574727744716

Epoch: 5| Step: 5
Training loss: 0.5912144378871022
Validation loss: 2.401363059182219

Epoch: 5| Step: 6
Training loss: 0.42065868939958523
Validation loss: 2.3758125426425956

Epoch: 5| Step: 7
Training loss: 0.47331793631888835
Validation loss: 2.373054586283463

Epoch: 5| Step: 8
Training loss: 0.6462910296772462
Validation loss: 2.4139532057921596

Epoch: 5| Step: 9
Training loss: 0.6525690295072964
Validation loss: 2.4138318172067277

Epoch: 5| Step: 10
Training loss: 0.5337290144196386
Validation loss: 2.38678913869613

Epoch: 472| Step: 0
Training loss: 0.47371350417059527
Validation loss: 2.4105409872314523

Epoch: 5| Step: 1
Training loss: 0.36204426909553444
Validation loss: 2.3672707301167333

Epoch: 5| Step: 2
Training loss: 0.40397059593979967
Validation loss: 2.4060749666296513

Epoch: 5| Step: 3
Training loss: 0.40564613210827
Validation loss: 2.3879259607539427

Epoch: 5| Step: 4
Training loss: 0.47948945271941595
Validation loss: 2.406064558934033

Epoch: 5| Step: 5
Training loss: 0.4917424021057802
Validation loss: 2.4235027251112746

Epoch: 5| Step: 6
Training loss: 0.6546456161976325
Validation loss: 2.423525812021715

Epoch: 5| Step: 7
Training loss: 0.3267745771285835
Validation loss: 2.437056415625702

Epoch: 5| Step: 8
Training loss: 0.4598557013702925
Validation loss: 2.4406214590457784

Epoch: 5| Step: 9
Training loss: 0.4077134914718405
Validation loss: 2.4853180225289124

Epoch: 5| Step: 10
Training loss: 0.9858486105239532
Validation loss: 2.465621866765163

Epoch: 473| Step: 0
Training loss: 0.48738482777621506
Validation loss: 2.478431392705095

Epoch: 5| Step: 1
Training loss: 0.6688795516832864
Validation loss: 2.4269606835538227

Epoch: 5| Step: 2
Training loss: 0.5547422999861475
Validation loss: 2.411747002322949

Epoch: 5| Step: 3
Training loss: 0.48523316196037597
Validation loss: 2.3991269361335292

Epoch: 5| Step: 4
Training loss: 0.2547996794661552
Validation loss: 2.4297062063603296

Epoch: 5| Step: 5
Training loss: 0.35327126292740446
Validation loss: 2.404981156098984

Epoch: 5| Step: 6
Training loss: 0.5384174302003272
Validation loss: 2.3809621468173794

Epoch: 5| Step: 7
Training loss: 0.5834616934240435
Validation loss: 2.402609941695015

Epoch: 5| Step: 8
Training loss: 0.5401248139493869
Validation loss: 2.419109192891537

Epoch: 5| Step: 9
Training loss: 0.4844117919730853
Validation loss: 2.4312791725949925

Epoch: 5| Step: 10
Training loss: 0.5856974046256587
Validation loss: 2.432937350511962

Epoch: 474| Step: 0
Training loss: 0.2690145266361417
Validation loss: 2.4490836024546203

Epoch: 5| Step: 1
Training loss: 0.5851684609782843
Validation loss: 2.4329633867999516

Epoch: 5| Step: 2
Training loss: 0.3196123775657244
Validation loss: 2.447279859109814

Epoch: 5| Step: 3
Training loss: 0.5627724199781647
Validation loss: 2.461899284040567

Epoch: 5| Step: 4
Training loss: 0.3507039607312771
Validation loss: 2.4461274033994944

Epoch: 5| Step: 5
Training loss: 0.8191173020782212
Validation loss: 2.4800416097564097

Epoch: 5| Step: 6
Training loss: 0.6342296508995056
Validation loss: 2.471214388423127

Epoch: 5| Step: 7
Training loss: 0.16736041846193553
Validation loss: 2.4644540231909393

Epoch: 5| Step: 8
Training loss: 0.4357721404788413
Validation loss: 2.4672249356259766

Epoch: 5| Step: 9
Training loss: 0.5188486304221045
Validation loss: 2.4582305203298014

Epoch: 5| Step: 10
Training loss: 0.5772349491247152
Validation loss: 2.4466446478887494

Epoch: 475| Step: 0
Training loss: 0.4801018717567429
Validation loss: 2.4419947118214536

Epoch: 5| Step: 1
Training loss: 0.5940233153654569
Validation loss: 2.4202596113960055

Epoch: 5| Step: 2
Training loss: 0.6245955827727826
Validation loss: 2.4322314500760225

Epoch: 5| Step: 3
Training loss: 0.5671728274126352
Validation loss: 2.4345061098158896

Epoch: 5| Step: 4
Training loss: 0.42837118185059875
Validation loss: 2.428815595743059

Epoch: 5| Step: 5
Training loss: 0.2908282861071248
Validation loss: 2.4133147560980306

Epoch: 5| Step: 6
Training loss: 0.5144608099500306
Validation loss: 2.4415094578739414

Epoch: 5| Step: 7
Training loss: 0.3213578472307942
Validation loss: 2.452692587730542

Epoch: 5| Step: 8
Training loss: 0.6431057048309085
Validation loss: 2.450227406512032

Epoch: 5| Step: 9
Training loss: 0.4725006887895115
Validation loss: 2.4387664313149204

Epoch: 5| Step: 10
Training loss: 0.5048769686746242
Validation loss: 2.421127398189645

Epoch: 476| Step: 0
Training loss: 0.4599513966083109
Validation loss: 2.4374307302345746

Epoch: 5| Step: 1
Training loss: 0.4937154878554077
Validation loss: 2.44146560695233

Epoch: 5| Step: 2
Training loss: 0.3000417014781831
Validation loss: 2.4215878388172047

Epoch: 5| Step: 3
Training loss: 0.4956700926492132
Validation loss: 2.425697356253865

Epoch: 5| Step: 4
Training loss: 0.3604892788032188
Validation loss: 2.4073917214362277

Epoch: 5| Step: 5
Training loss: 0.4062825703402501
Validation loss: 2.4383235662308436

Epoch: 5| Step: 6
Training loss: 0.6579086142883305
Validation loss: 2.4125475618287147

Epoch: 5| Step: 7
Training loss: 0.5005327902750715
Validation loss: 2.4189296494060795

Epoch: 5| Step: 8
Training loss: 0.5516149825503284
Validation loss: 2.408403384204746

Epoch: 5| Step: 9
Training loss: 0.6965139274724528
Validation loss: 2.436021439984779

Epoch: 5| Step: 10
Training loss: 0.38574572211469
Validation loss: 2.4102237248082945

Epoch: 477| Step: 0
Training loss: 0.5903867028906077
Validation loss: 2.4387826429266455

Epoch: 5| Step: 1
Training loss: 0.5860693719604809
Validation loss: 2.4541927470040097

Epoch: 5| Step: 2
Training loss: 0.44876213086555267
Validation loss: 2.429986017498295

Epoch: 5| Step: 3
Training loss: 0.24655483586882151
Validation loss: 2.4579962010321834

Epoch: 5| Step: 4
Training loss: 0.43221844968495055
Validation loss: 2.4672738108015877

Epoch: 5| Step: 5
Training loss: 0.5510638709062603
Validation loss: 2.438748559732968

Epoch: 5| Step: 6
Training loss: 0.6207189808783491
Validation loss: 2.434589623677382

Epoch: 5| Step: 7
Training loss: 0.5697529281567748
Validation loss: 2.4159591869424326

Epoch: 5| Step: 8
Training loss: 0.27607228751058627
Validation loss: 2.417241738467985

Epoch: 5| Step: 9
Training loss: 0.3604237967357354
Validation loss: 2.4383545435409113

Epoch: 5| Step: 10
Training loss: 0.5474788329417881
Validation loss: 2.4527855146963633

Epoch: 478| Step: 0
Training loss: 0.47953201097494524
Validation loss: 2.440769828423688

Epoch: 5| Step: 1
Training loss: 0.5116606817713488
Validation loss: 2.459619644067478

Epoch: 5| Step: 2
Training loss: 0.3861765673192369
Validation loss: 2.4670834838792435

Epoch: 5| Step: 3
Training loss: 0.574770759413366
Validation loss: 2.4660661984283894

Epoch: 5| Step: 4
Training loss: 0.458593551141803
Validation loss: 2.468666232042921

Epoch: 5| Step: 5
Training loss: 0.4827647052798974
Validation loss: 2.4760986744687066

Epoch: 5| Step: 6
Training loss: 0.4068139270353643
Validation loss: 2.4611139508007716

Epoch: 5| Step: 7
Training loss: 0.6385680414657395
Validation loss: 2.5002381144716406

Epoch: 5| Step: 8
Training loss: 0.4967481247243056
Validation loss: 2.48331133314558

Epoch: 5| Step: 9
Training loss: 0.34802455894777123
Validation loss: 2.4518429601537735

Epoch: 5| Step: 10
Training loss: 0.5335194973086587
Validation loss: 2.4552433389947437

Epoch: 479| Step: 0
Training loss: 0.4949847915268588
Validation loss: 2.46327742905792

Epoch: 5| Step: 1
Training loss: 0.4923091162942675
Validation loss: 2.4633826647384196

Epoch: 5| Step: 2
Training loss: 0.3982711706610875
Validation loss: 2.433436422345874

Epoch: 5| Step: 3
Training loss: 0.5319817776301887
Validation loss: 2.4380902537241123

Epoch: 5| Step: 4
Training loss: 0.45594126171000904
Validation loss: 2.4419621426945652

Epoch: 5| Step: 5
Training loss: 0.36290081161803506
Validation loss: 2.419712486545084

Epoch: 5| Step: 6
Training loss: 0.36086214277977924
Validation loss: 2.452257120810814

Epoch: 5| Step: 7
Training loss: 0.5050031271450552
Validation loss: 2.444520566994288

Epoch: 5| Step: 8
Training loss: 0.44705450080851816
Validation loss: 2.447015195671267

Epoch: 5| Step: 9
Training loss: 0.5944894151844182
Validation loss: 2.4108901710780777

Epoch: 5| Step: 10
Training loss: 0.6596826513591993
Validation loss: 2.4348236604112374

Epoch: 480| Step: 0
Training loss: 0.4438429896211117
Validation loss: 2.4242056448940614

Epoch: 5| Step: 1
Training loss: 0.3297994441675461
Validation loss: 2.4494242183478034

Epoch: 5| Step: 2
Training loss: 0.37954767737363276
Validation loss: 2.422104833668464

Epoch: 5| Step: 3
Training loss: 0.7831454743359825
Validation loss: 2.4496350068204884

Epoch: 5| Step: 4
Training loss: 0.517306447252603
Validation loss: 2.447264032718805

Epoch: 5| Step: 5
Training loss: 0.3730892137398193
Validation loss: 2.457114843902237

Epoch: 5| Step: 6
Training loss: 0.2239266260383199
Validation loss: 2.4706116253055654

Epoch: 5| Step: 7
Training loss: 0.2958851046438284
Validation loss: 2.4606247288582037

Epoch: 5| Step: 8
Training loss: 0.4070159770128303
Validation loss: 2.4627337547655674

Epoch: 5| Step: 9
Training loss: 0.7940496960252822
Validation loss: 2.495117700203993

Epoch: 5| Step: 10
Training loss: 0.3418750455566878
Validation loss: 2.472279586424502

Epoch: 481| Step: 0
Training loss: 0.5203356431276046
Validation loss: 2.488224382729944

Epoch: 5| Step: 1
Training loss: 0.48998693475529365
Validation loss: 2.4409841006623574

Epoch: 5| Step: 2
Training loss: 0.5347978268743971
Validation loss: 2.4645049354686335

Epoch: 5| Step: 3
Training loss: 0.3078634578138074
Validation loss: 2.439795270322987

Epoch: 5| Step: 4
Training loss: 0.6053244880351762
Validation loss: 2.424906688409209

Epoch: 5| Step: 5
Training loss: 0.5058827634139815
Validation loss: 2.45732113085024

Epoch: 5| Step: 6
Training loss: 0.44897344774735876
Validation loss: 2.407929742838778

Epoch: 5| Step: 7
Training loss: 0.5714058259498748
Validation loss: 2.4446682037124567

Epoch: 5| Step: 8
Training loss: 0.25044743909503236
Validation loss: 2.422086127344483

Epoch: 5| Step: 9
Training loss: 0.48696125901967396
Validation loss: 2.4483560524308463

Epoch: 5| Step: 10
Training loss: 0.4607050681433049
Validation loss: 2.413729097631175

Epoch: 482| Step: 0
Training loss: 0.4641244596482801
Validation loss: 2.4747200812664927

Epoch: 5| Step: 1
Training loss: 0.42173895585004356
Validation loss: 2.4410426865135313

Epoch: 5| Step: 2
Training loss: 0.526825459414908
Validation loss: 2.463121424952883

Epoch: 5| Step: 3
Training loss: 0.41236601878894347
Validation loss: 2.5041433117216116

Epoch: 5| Step: 4
Training loss: 0.43011924554001435
Validation loss: 2.4840748975157143

Epoch: 5| Step: 5
Training loss: 0.5947912772912812
Validation loss: 2.4987675048797398

Epoch: 5| Step: 6
Training loss: 0.51970942030673
Validation loss: 2.47919701067943

Epoch: 5| Step: 7
Training loss: 0.3629601813301304
Validation loss: 2.4966048187133465

Epoch: 5| Step: 8
Training loss: 0.627372910141338
Validation loss: 2.4908647071886567

Epoch: 5| Step: 9
Training loss: 0.4770976798081295
Validation loss: 2.470129131227934

Epoch: 5| Step: 10
Training loss: 0.29260616753802704
Validation loss: 2.483482743396443

Epoch: 483| Step: 0
Training loss: 0.345496832725427
Validation loss: 2.4600244367746193

Epoch: 5| Step: 1
Training loss: 0.43197360076642355
Validation loss: 2.482799385111694

Epoch: 5| Step: 2
Training loss: 0.5441328235732419
Validation loss: 2.467063326594526

Epoch: 5| Step: 3
Training loss: 0.32626758244882137
Validation loss: 2.4423767513038834

Epoch: 5| Step: 4
Training loss: 0.4593559384445993
Validation loss: 2.42744303250814

Epoch: 5| Step: 5
Training loss: 0.18379402397180225
Validation loss: 2.4431425120190147

Epoch: 5| Step: 6
Training loss: 0.5729737311178691
Validation loss: 2.450019189727214

Epoch: 5| Step: 7
Training loss: 0.6105472830724055
Validation loss: 2.4398134063827817

Epoch: 5| Step: 8
Training loss: 0.4957718443076028
Validation loss: 2.4702843850751766

Epoch: 5| Step: 9
Training loss: 0.5942211540468442
Validation loss: 2.463618154369677

Epoch: 5| Step: 10
Training loss: 0.5732792285084012
Validation loss: 2.440217731432683

Epoch: 484| Step: 0
Training loss: 0.3763909570446337
Validation loss: 2.4350339532625043

Epoch: 5| Step: 1
Training loss: 0.5160324914039821
Validation loss: 2.4384165498110253

Epoch: 5| Step: 2
Training loss: 0.32900852506978584
Validation loss: 2.4079821185070602

Epoch: 5| Step: 3
Training loss: 0.461154434104364
Validation loss: 2.452216158790367

Epoch: 5| Step: 4
Training loss: 0.570632296219941
Validation loss: 2.42891805516356

Epoch: 5| Step: 5
Training loss: 0.41332654506482475
Validation loss: 2.435895003817057

Epoch: 5| Step: 6
Training loss: 0.3991814754575575
Validation loss: 2.4233530965012915

Epoch: 5| Step: 7
Training loss: 0.5648344395293593
Validation loss: 2.4162082838528383

Epoch: 5| Step: 8
Training loss: 0.564650266862754
Validation loss: 2.416228550273884

Epoch: 5| Step: 9
Training loss: 0.5850798879182478
Validation loss: 2.412460975218698

Epoch: 5| Step: 10
Training loss: 0.2877858813771969
Validation loss: 2.4702154913501677

Epoch: 485| Step: 0
Training loss: 0.2957687597363087
Validation loss: 2.449839174049444

Epoch: 5| Step: 1
Training loss: 0.31007707195338646
Validation loss: 2.487701337621187

Epoch: 5| Step: 2
Training loss: 0.4366728593057161
Validation loss: 2.4970442891160003

Epoch: 5| Step: 3
Training loss: 0.3626745346436592
Validation loss: 2.487750833287307

Epoch: 5| Step: 4
Training loss: 0.5688658617241658
Validation loss: 2.5095971703850246

Epoch: 5| Step: 5
Training loss: 0.4396086862523778
Validation loss: 2.481102208971599

Epoch: 5| Step: 6
Training loss: 0.53279494986618
Validation loss: 2.453970311035986

Epoch: 5| Step: 7
Training loss: 0.5587734386895895
Validation loss: 2.4583809710503806

Epoch: 5| Step: 8
Training loss: 0.6397976533822292
Validation loss: 2.484924180377949

Epoch: 5| Step: 9
Training loss: 0.5513349414872714
Validation loss: 2.4779350225011028

Epoch: 5| Step: 10
Training loss: 0.32831510077883697
Validation loss: 2.4967650259142222

Epoch: 486| Step: 0
Training loss: 0.15995732607275523
Validation loss: 2.4541555361129115

Epoch: 5| Step: 1
Training loss: 0.368221086290218
Validation loss: 2.4752745212081595

Epoch: 5| Step: 2
Training loss: 0.6583557404756971
Validation loss: 2.493252350077303

Epoch: 5| Step: 3
Training loss: 0.20376493446052316
Validation loss: 2.458026175048812

Epoch: 5| Step: 4
Training loss: 0.4187430224620181
Validation loss: 2.47229783104739

Epoch: 5| Step: 5
Training loss: 0.5863342467820146
Validation loss: 2.480489937289127

Epoch: 5| Step: 6
Training loss: 0.42075294050933304
Validation loss: 2.5110469866403444

Epoch: 5| Step: 7
Training loss: 0.3752937954157257
Validation loss: 2.481337517102873

Epoch: 5| Step: 8
Training loss: 0.509298439357021
Validation loss: 2.5085976376329033

Epoch: 5| Step: 9
Training loss: 0.5312685402271607
Validation loss: 2.472714255994132

Epoch: 5| Step: 10
Training loss: 0.5233235306287422
Validation loss: 2.4579267615784377

Epoch: 487| Step: 0
Training loss: 0.32689231981668027
Validation loss: 2.4731285889394177

Epoch: 5| Step: 1
Training loss: 0.4553077674991558
Validation loss: 2.466737071160262

Epoch: 5| Step: 2
Training loss: 0.39735803045186574
Validation loss: 2.4505506250429807

Epoch: 5| Step: 3
Training loss: 0.33589384993033217
Validation loss: 2.4324517356917967

Epoch: 5| Step: 4
Training loss: 0.4114853351119012
Validation loss: 2.4519231760288593

Epoch: 5| Step: 5
Training loss: 0.467615120682193
Validation loss: 2.4686515983720674

Epoch: 5| Step: 6
Training loss: 0.5452016843546558
Validation loss: 2.4613115955101645

Epoch: 5| Step: 7
Training loss: 0.4385166617156455
Validation loss: 2.4798743562481556

Epoch: 5| Step: 8
Training loss: 0.5189751825720148
Validation loss: 2.46318127390512

Epoch: 5| Step: 9
Training loss: 0.5769975339086448
Validation loss: 2.4383835875165123

Epoch: 5| Step: 10
Training loss: 0.5789398688105523
Validation loss: 2.4076998428192624

Epoch: 488| Step: 0
Training loss: 0.5525223557881673
Validation loss: 2.4228037397412874

Epoch: 5| Step: 1
Training loss: 0.4593433842840827
Validation loss: 2.412645473575392

Epoch: 5| Step: 2
Training loss: 0.6353030233431631
Validation loss: 2.4187264110630315

Epoch: 5| Step: 3
Training loss: 0.5169006231984289
Validation loss: 2.4119918570758148

Epoch: 5| Step: 4
Training loss: 0.5463542911564552
Validation loss: 2.439177712724416

Epoch: 5| Step: 5
Training loss: 0.2807147973699701
Validation loss: 2.4201752455371146

Epoch: 5| Step: 6
Training loss: 0.38823122895865575
Validation loss: 2.4612873496077956

Epoch: 5| Step: 7
Training loss: 0.41223395756031384
Validation loss: 2.4444348255681687

Epoch: 5| Step: 8
Training loss: 0.25659655885061483
Validation loss: 2.445153558419578

Epoch: 5| Step: 9
Training loss: 0.2995064460382321
Validation loss: 2.455088155752743

Epoch: 5| Step: 10
Training loss: 0.5140617834393455
Validation loss: 2.4809942777696743

Epoch: 489| Step: 0
Training loss: 0.25727019928295375
Validation loss: 2.4545483665805357

Epoch: 5| Step: 1
Training loss: 0.575252536589042
Validation loss: 2.4658041169796108

Epoch: 5| Step: 2
Training loss: 0.5181950760815396
Validation loss: 2.4938580776014234

Epoch: 5| Step: 3
Training loss: 0.45883536659318613
Validation loss: 2.490138163307502

Epoch: 5| Step: 4
Training loss: 0.43752741727750283
Validation loss: 2.4537816493088807

Epoch: 5| Step: 5
Training loss: 0.5002659745894728
Validation loss: 2.454769960639809

Epoch: 5| Step: 6
Training loss: 0.4177305665920739
Validation loss: 2.4975384294015477

Epoch: 5| Step: 7
Training loss: 0.4816156051337229
Validation loss: 2.479493612782813

Epoch: 5| Step: 8
Training loss: 0.38676132584295564
Validation loss: 2.4420361765043417

Epoch: 5| Step: 9
Training loss: 0.4960778001038493
Validation loss: 2.4252107647685444

Epoch: 5| Step: 10
Training loss: 0.2555262457166425
Validation loss: 2.4332023925742217

Epoch: 490| Step: 0
Training loss: 0.47902008247087136
Validation loss: 2.4505539470862945

Epoch: 5| Step: 1
Training loss: 0.612318193934655
Validation loss: 2.4606650466487983

Epoch: 5| Step: 2
Training loss: 0.31795831002382086
Validation loss: 2.4483485688920017

Epoch: 5| Step: 3
Training loss: 0.5191362356397895
Validation loss: 2.440568600000136

Epoch: 5| Step: 4
Training loss: 0.4372811962392907
Validation loss: 2.44153047504016

Epoch: 5| Step: 5
Training loss: 0.28437753718156084
Validation loss: 2.4637886028880738

Epoch: 5| Step: 6
Training loss: 0.46591591803587745
Validation loss: 2.4422774413782355

Epoch: 5| Step: 7
Training loss: 0.518953446628509
Validation loss: 2.467287388654876

Epoch: 5| Step: 8
Training loss: 0.36492194618154167
Validation loss: 2.4760192832256185

Epoch: 5| Step: 9
Training loss: 0.43914232919793594
Validation loss: 2.47114062187635

Epoch: 5| Step: 10
Training loss: 0.37505002482853683
Validation loss: 2.4848423401722934

Epoch: 491| Step: 0
Training loss: 0.4220371464554312
Validation loss: 2.4905801792995708

Epoch: 5| Step: 1
Training loss: 0.48736344099854334
Validation loss: 2.461843313153463

Epoch: 5| Step: 2
Training loss: 0.46706192918964895
Validation loss: 2.45191079757492

Epoch: 5| Step: 3
Training loss: 0.3718962575142067
Validation loss: 2.427735882939966

Epoch: 5| Step: 4
Training loss: 0.19176164058703835
Validation loss: 2.421853898532383

Epoch: 5| Step: 5
Training loss: 0.4138767437553943
Validation loss: 2.433809716318275

Epoch: 5| Step: 6
Training loss: 0.313073395152412
Validation loss: 2.440969673089319

Epoch: 5| Step: 7
Training loss: 0.5202468303673687
Validation loss: 2.384427924072757

Epoch: 5| Step: 8
Training loss: 0.468066511944083
Validation loss: 2.3917667965936076

Epoch: 5| Step: 9
Training loss: 0.5618761364731206
Validation loss: 2.416857061287051

Epoch: 5| Step: 10
Training loss: 0.42129179591537624
Validation loss: 2.4245503489838423

Epoch: 492| Step: 0
Training loss: 0.26989102884303356
Validation loss: 2.421256921649778

Epoch: 5| Step: 1
Training loss: 0.3080038879570241
Validation loss: 2.4362066012078674

Epoch: 5| Step: 2
Training loss: 0.5387413616328705
Validation loss: 2.4325829367729894

Epoch: 5| Step: 3
Training loss: 0.5641193128806731
Validation loss: 2.445952250693072

Epoch: 5| Step: 4
Training loss: 0.33696566200415695
Validation loss: 2.458911643321442

Epoch: 5| Step: 5
Training loss: 0.4143823611783689
Validation loss: 2.4438387957018284

Epoch: 5| Step: 6
Training loss: 0.4595620598398583
Validation loss: 2.462803138316968

Epoch: 5| Step: 7
Training loss: 0.5477566016272519
Validation loss: 2.445992131165361

Epoch: 5| Step: 8
Training loss: 0.3347423162547107
Validation loss: 2.4653680954601183

Epoch: 5| Step: 9
Training loss: 0.4247200366336054
Validation loss: 2.4207693497078258

Epoch: 5| Step: 10
Training loss: 0.46786147784322446
Validation loss: 2.4369583201121583

Epoch: 493| Step: 0
Training loss: 0.4076460180610512
Validation loss: 2.435721666602991

Epoch: 5| Step: 1
Training loss: 0.6644739335001507
Validation loss: 2.4359519103237948

Epoch: 5| Step: 2
Training loss: 0.3417112188638749
Validation loss: 2.422993031753032

Epoch: 5| Step: 3
Training loss: 0.4335570964270289
Validation loss: 2.4359371727380132

Epoch: 5| Step: 4
Training loss: 0.21965570790908703
Validation loss: 2.4621344480381775

Epoch: 5| Step: 5
Training loss: 0.5071652909714746
Validation loss: 2.4676039748528615

Epoch: 5| Step: 6
Training loss: 0.34830169554400914
Validation loss: 2.4867167061124604

Epoch: 5| Step: 7
Training loss: 0.4503278226978797
Validation loss: 2.4823884642970038

Epoch: 5| Step: 8
Training loss: 0.3489163952389003
Validation loss: 2.507047647797799

Epoch: 5| Step: 9
Training loss: 0.5303791425526544
Validation loss: 2.492719765924773

Epoch: 5| Step: 10
Training loss: 0.3255808609610747
Validation loss: 2.4904766754847394

Epoch: 494| Step: 0
Training loss: 0.35586483864301033
Validation loss: 2.4420316949196623

Epoch: 5| Step: 1
Training loss: 0.31055229710098015
Validation loss: 2.4502303926127897

Epoch: 5| Step: 2
Training loss: 0.4571348382654175
Validation loss: 2.427221579911891

Epoch: 5| Step: 3
Training loss: 0.4690711351904835
Validation loss: 2.462005705295045

Epoch: 5| Step: 4
Training loss: 0.35278373111038563
Validation loss: 2.47768725226877

Epoch: 5| Step: 5
Training loss: 0.4152475708437426
Validation loss: 2.503566519051961

Epoch: 5| Step: 6
Training loss: 0.3566181338719272
Validation loss: 2.4740524783568865

Epoch: 5| Step: 7
Training loss: 0.4610562737235701
Validation loss: 2.476395282746271

Epoch: 5| Step: 8
Training loss: 0.4693179980789235
Validation loss: 2.4809858795138955

Epoch: 5| Step: 9
Training loss: 0.5079621901333524
Validation loss: 2.5046993198402085

Epoch: 5| Step: 10
Training loss: 0.5581229566769506
Validation loss: 2.4889264281207475

Epoch: 495| Step: 0
Training loss: 0.3989179183203736
Validation loss: 2.4889466658448742

Epoch: 5| Step: 1
Training loss: 0.4821188279880149
Validation loss: 2.4627503192010622

Epoch: 5| Step: 2
Training loss: 0.36389903381190036
Validation loss: 2.4547515319588378

Epoch: 5| Step: 3
Training loss: 0.40300570356625676
Validation loss: 2.4558654791865657

Epoch: 5| Step: 4
Training loss: 0.47653073064253065
Validation loss: 2.424618736431713

Epoch: 5| Step: 5
Training loss: 0.2120282089869905
Validation loss: 2.4232325543605047

Epoch: 5| Step: 6
Training loss: 0.5789301137600242
Validation loss: 2.417891307363763

Epoch: 5| Step: 7
Training loss: 0.6170601532330355
Validation loss: 2.430082295093319

Epoch: 5| Step: 8
Training loss: 0.18726717878643184
Validation loss: 2.4396547154915846

Epoch: 5| Step: 9
Training loss: 0.3788996037165768
Validation loss: 2.4654396139966415

Epoch: 5| Step: 10
Training loss: 0.3847695752246066
Validation loss: 2.475430723588406

Epoch: 496| Step: 0
Training loss: 0.4375428110702327
Validation loss: 2.4745211360807158

Epoch: 5| Step: 1
Training loss: 0.3992177392159224
Validation loss: 2.5115702746008837

Epoch: 5| Step: 2
Training loss: 0.3855940135828464
Validation loss: 2.493936332513704

Epoch: 5| Step: 3
Training loss: 0.5042077278987027
Validation loss: 2.494797641451476

Epoch: 5| Step: 4
Training loss: 0.3512413253256023
Validation loss: 2.4991161219593523

Epoch: 5| Step: 5
Training loss: 0.6274399813030999
Validation loss: 2.4315112793211267

Epoch: 5| Step: 6
Training loss: 0.36627776489864994
Validation loss: 2.43096512605118

Epoch: 5| Step: 7
Training loss: 0.5768738172359885
Validation loss: 2.4205260442898973

Epoch: 5| Step: 8
Training loss: 0.3709343216397541
Validation loss: 2.4028305407558532

Epoch: 5| Step: 9
Training loss: 0.3371018701736845
Validation loss: 2.415892875646864

Epoch: 5| Step: 10
Training loss: 0.4269629712029577
Validation loss: 2.4229760161805873

Epoch: 497| Step: 0
Training loss: 0.3855359648887533
Validation loss: 2.469855715520688

Epoch: 5| Step: 1
Training loss: 0.29010602390007567
Validation loss: 2.4535465498777675

Epoch: 5| Step: 2
Training loss: 0.4230186185267649
Validation loss: 2.485327476853606

Epoch: 5| Step: 3
Training loss: 0.44788549189052324
Validation loss: 2.507142767830916

Epoch: 5| Step: 4
Training loss: 0.6865281692276705
Validation loss: 2.498921529867374

Epoch: 5| Step: 5
Training loss: 0.4473826659207415
Validation loss: 2.5084542326251187

Epoch: 5| Step: 6
Training loss: 0.4271775370498556
Validation loss: 2.469461681403425

Epoch: 5| Step: 7
Training loss: 0.3323173412381455
Validation loss: 2.4599288224918685

Epoch: 5| Step: 8
Training loss: 0.38450447165985624
Validation loss: 2.428468031339688

Epoch: 5| Step: 9
Training loss: 0.46878137483500415
Validation loss: 2.4138444387263562

Epoch: 5| Step: 10
Training loss: 0.3678352850935824
Validation loss: 2.4004943916542407

Epoch: 498| Step: 0
Training loss: 0.6894022460837831
Validation loss: 2.3892078771752217

Epoch: 5| Step: 1
Training loss: 0.38148630823336516
Validation loss: 2.374661392335203

Epoch: 5| Step: 2
Training loss: 0.41370084551263075
Validation loss: 2.38811560302395

Epoch: 5| Step: 3
Training loss: 0.4248575462691123
Validation loss: 2.395604275047893

Epoch: 5| Step: 4
Training loss: 0.46309592929262694
Validation loss: 2.426639259763501

Epoch: 5| Step: 5
Training loss: 0.39861910552065494
Validation loss: 2.442033122644885

Epoch: 5| Step: 6
Training loss: 0.6469775160121134
Validation loss: 2.4565802989711956

Epoch: 5| Step: 7
Training loss: 0.35937732198213856
Validation loss: 2.474355576664799

Epoch: 5| Step: 8
Training loss: 0.27707867648339196
Validation loss: 2.454723173284236

Epoch: 5| Step: 9
Training loss: 0.35045596930660794
Validation loss: 2.4640805753890422

Epoch: 5| Step: 10
Training loss: 0.4123191480391208
Validation loss: 2.4578958194677982

Epoch: 499| Step: 0
Training loss: 0.4077111889338434
Validation loss: 2.455890327694548

Epoch: 5| Step: 1
Training loss: 0.490659005511293
Validation loss: 2.4257661732032108

Epoch: 5| Step: 2
Training loss: 0.48243069351105483
Validation loss: 2.4240204066992272

Epoch: 5| Step: 3
Training loss: 0.43379333988641716
Validation loss: 2.4773691295572116

Epoch: 5| Step: 4
Training loss: 0.19498090251609548
Validation loss: 2.4726351060060323

Epoch: 5| Step: 5
Training loss: 0.36488049748883605
Validation loss: 2.4674264172089155

Epoch: 5| Step: 6
Training loss: 0.47636539260257094
Validation loss: 2.508241755924321

Epoch: 5| Step: 7
Training loss: 0.3249733657193639
Validation loss: 2.536192432528692

Epoch: 5| Step: 8
Training loss: 0.5152217559773038
Validation loss: 2.539115133568241

Epoch: 5| Step: 9
Training loss: 0.4510502837182419
Validation loss: 2.5584773041153666

Epoch: 5| Step: 10
Training loss: 0.5021358409772043
Validation loss: 2.515591253728036

Epoch: 500| Step: 0
Training loss: 0.42863428912216534
Validation loss: 2.506075453022835

Epoch: 5| Step: 1
Training loss: 0.5847908753554052
Validation loss: 2.5190048661250475

Epoch: 5| Step: 2
Training loss: 0.418567745202647
Validation loss: 2.4924155818941744

Epoch: 5| Step: 3
Training loss: 0.5410532473486526
Validation loss: 2.48108850781549

Epoch: 5| Step: 4
Training loss: 0.38182686407133376
Validation loss: 2.451450860096965

Epoch: 5| Step: 5
Training loss: 0.3329032331011456
Validation loss: 2.455822439439272

Epoch: 5| Step: 6
Training loss: 0.5149427003372169
Validation loss: 2.4587139970218694

Epoch: 5| Step: 7
Training loss: 0.2958525442660002
Validation loss: 2.4482134539407934

Epoch: 5| Step: 8
Training loss: 0.30408770873278645
Validation loss: 2.434871872240089

Epoch: 5| Step: 9
Training loss: 0.5012440998843164
Validation loss: 2.4558111548209314

Epoch: 5| Step: 10
Training loss: 0.21547510838964515
Validation loss: 2.500988424418071

Epoch: 501| Step: 0
Training loss: 0.3785735370437175
Validation loss: 2.521964653668024

Epoch: 5| Step: 1
Training loss: 0.48886915291098876
Validation loss: 2.509810227944659

Epoch: 5| Step: 2
Training loss: 0.2969925547302376
Validation loss: 2.524587332875339

Epoch: 5| Step: 3
Training loss: 0.3718987417255686
Validation loss: 2.547503615937729

Epoch: 5| Step: 4
Training loss: 0.34580869194318165
Validation loss: 2.5639863269431356

Epoch: 5| Step: 5
Training loss: 0.5704904043642717
Validation loss: 2.5751009221922825

Epoch: 5| Step: 6
Training loss: 0.3974791951403013
Validation loss: 2.5635779529840237

Epoch: 5| Step: 7
Training loss: 0.3878159227304707
Validation loss: 2.5292780446707144

Epoch: 5| Step: 8
Training loss: 0.5003000789437164
Validation loss: 2.513658637958305

Epoch: 5| Step: 9
Training loss: 0.4735718520742486
Validation loss: 2.4929460977040434

Epoch: 5| Step: 10
Training loss: 0.2658900593356345
Validation loss: 2.484120333783487

Epoch: 502| Step: 0
Training loss: 0.41150760556813776
Validation loss: 2.449183435583387

Epoch: 5| Step: 1
Training loss: 0.5548546230375541
Validation loss: 2.4275245531283316

Epoch: 5| Step: 2
Training loss: 0.34720115663947215
Validation loss: 2.4397505211727957

Epoch: 5| Step: 3
Training loss: 0.5362493391855432
Validation loss: 2.4221152735200184

Epoch: 5| Step: 4
Training loss: 0.40251452330930193
Validation loss: 2.4203198264362578

Epoch: 5| Step: 5
Training loss: 0.42751634170574204
Validation loss: 2.4354620534393234

Epoch: 5| Step: 6
Training loss: 0.42348022949162445
Validation loss: 2.407177187535492

Epoch: 5| Step: 7
Training loss: 0.24244164391477332
Validation loss: 2.447464328323953

Epoch: 5| Step: 8
Training loss: 0.3930506732706346
Validation loss: 2.449554277499834

Epoch: 5| Step: 9
Training loss: 0.36242903968552664
Validation loss: 2.4761187100559616

Epoch: 5| Step: 10
Training loss: 0.5488779174372701
Validation loss: 2.444190457120318

Epoch: 503| Step: 0
Training loss: 0.4610013271041684
Validation loss: 2.4442900731925548

Epoch: 5| Step: 1
Training loss: 0.28549363805042594
Validation loss: 2.423199264385086

Epoch: 5| Step: 2
Training loss: 0.32384162248889753
Validation loss: 2.431397822791197

Epoch: 5| Step: 3
Training loss: 0.5748618281249551
Validation loss: 2.4420964781610723

Epoch: 5| Step: 4
Training loss: 0.4041578634358629
Validation loss: 2.4518260151436806

Epoch: 5| Step: 5
Training loss: 0.41183661523687404
Validation loss: 2.4054847654325404

Epoch: 5| Step: 6
Training loss: 0.5135859138301798
Validation loss: 2.439270129843809

Epoch: 5| Step: 7
Training loss: 0.5040996091820327
Validation loss: 2.488726982253812

Epoch: 5| Step: 8
Training loss: 0.626204069931696
Validation loss: 2.509881221662308

Epoch: 5| Step: 9
Training loss: 0.2753249962706164
Validation loss: 2.5090858595804826

Epoch: 5| Step: 10
Training loss: 0.2151175401669838
Validation loss: 2.4780242499293745

Epoch: 504| Step: 0
Training loss: 0.4156208583080471
Validation loss: 2.473697550596785

Epoch: 5| Step: 1
Training loss: 0.5339191087129388
Validation loss: 2.4947648804922773

Epoch: 5| Step: 2
Training loss: 0.4572411242760822
Validation loss: 2.4911153120418503

Epoch: 5| Step: 3
Training loss: 0.511898620675299
Validation loss: 2.4818151577837497

Epoch: 5| Step: 4
Training loss: 0.3513764630928099
Validation loss: 2.453712198198844

Epoch: 5| Step: 5
Training loss: 0.30922916038225506
Validation loss: 2.454787412721698

Epoch: 5| Step: 6
Training loss: 0.4243866014088664
Validation loss: 2.4063887016125785

Epoch: 5| Step: 7
Training loss: 0.3714849919294977
Validation loss: 2.4242833944714133

Epoch: 5| Step: 8
Training loss: 0.25554422086190476
Validation loss: 2.4575524022229334

Epoch: 5| Step: 9
Training loss: 0.4712530540498887
Validation loss: 2.4535060022629036

Epoch: 5| Step: 10
Training loss: 0.5626745482999341
Validation loss: 2.4709691351412437

Epoch: 505| Step: 0
Training loss: 0.3716462489615358
Validation loss: 2.4628623662886535

Epoch: 5| Step: 1
Training loss: 0.3072780616895118
Validation loss: 2.447558483413965

Epoch: 5| Step: 2
Training loss: 0.339919662766479
Validation loss: 2.444991141125669

Epoch: 5| Step: 3
Training loss: 0.5889851972212683
Validation loss: 2.506346755622356

Epoch: 5| Step: 4
Training loss: 0.46141893492771474
Validation loss: 2.488544969593396

Epoch: 5| Step: 5
Training loss: 0.46420495836127723
Validation loss: 2.481798538273566

Epoch: 5| Step: 6
Training loss: 0.4536408743457728
Validation loss: 2.4744728562818556

Epoch: 5| Step: 7
Training loss: 0.46612393382823375
Validation loss: 2.4874559129879112

Epoch: 5| Step: 8
Training loss: 0.29446414769999013
Validation loss: 2.488560113142393

Epoch: 5| Step: 9
Training loss: 0.42634450770898447
Validation loss: 2.466686837890727

Epoch: 5| Step: 10
Training loss: 0.43060830029909564
Validation loss: 2.4697657943849056

Epoch: 506| Step: 0
Training loss: 0.29895505515681564
Validation loss: 2.46950719500578

Epoch: 5| Step: 1
Training loss: 0.4224303969491414
Validation loss: 2.414898824776842

Epoch: 5| Step: 2
Training loss: 0.29083996790247385
Validation loss: 2.4161648825191318

Epoch: 5| Step: 3
Training loss: 0.4859628032953118
Validation loss: 2.432658761965301

Epoch: 5| Step: 4
Training loss: 0.49436476678782637
Validation loss: 2.405270526684663

Epoch: 5| Step: 5
Training loss: 0.48816424684596604
Validation loss: 2.422921139563405

Epoch: 5| Step: 6
Training loss: 0.33413523339877793
Validation loss: 2.4360099110428908

Epoch: 5| Step: 7
Training loss: 0.43294349230549517
Validation loss: 2.4311395373885314

Epoch: 5| Step: 8
Training loss: 0.37954394762542637
Validation loss: 2.4215302443265156

Epoch: 5| Step: 9
Training loss: 0.36914647819278573
Validation loss: 2.4729994306144745

Epoch: 5| Step: 10
Training loss: 0.5518368554676408
Validation loss: 2.4770118681198054

Epoch: 507| Step: 0
Training loss: 0.37144874859202537
Validation loss: 2.479106783089789

Epoch: 5| Step: 1
Training loss: 0.6053300760264851
Validation loss: 2.468632113849716

Epoch: 5| Step: 2
Training loss: 0.2966035681206717
Validation loss: 2.4868030473923373

Epoch: 5| Step: 3
Training loss: 0.45127570208532447
Validation loss: 2.4813602828741046

Epoch: 5| Step: 4
Training loss: 0.16106375167990916
Validation loss: 2.466825211270734

Epoch: 5| Step: 5
Training loss: 0.44361364324720615
Validation loss: 2.454806704798528

Epoch: 5| Step: 6
Training loss: 0.30616655575316415
Validation loss: 2.43911736097992

Epoch: 5| Step: 7
Training loss: 0.4781445835815167
Validation loss: 2.4858644333724254

Epoch: 5| Step: 8
Training loss: 0.3645816008208754
Validation loss: 2.4649702166167224

Epoch: 5| Step: 9
Training loss: 0.32886207764182396
Validation loss: 2.478607303521854

Epoch: 5| Step: 10
Training loss: 0.31762660126956155
Validation loss: 2.4606861335757673

Epoch: 508| Step: 0
Training loss: 0.3587371514508392
Validation loss: 2.4778600530865504

Epoch: 5| Step: 1
Training loss: 0.3898914697830795
Validation loss: 2.466198172584914

Epoch: 5| Step: 2
Training loss: 0.3897858379824639
Validation loss: 2.4617025717137166

Epoch: 5| Step: 3
Training loss: 0.5133083783417015
Validation loss: 2.4481668575272217

Epoch: 5| Step: 4
Training loss: 0.4238787677938293
Validation loss: 2.445448698813748

Epoch: 5| Step: 5
Training loss: 0.33861026313485365
Validation loss: 2.4438135477101626

Epoch: 5| Step: 6
Training loss: 0.24094604124522598
Validation loss: 2.4745244606501253

Epoch: 5| Step: 7
Training loss: 0.21465865745199592
Validation loss: 2.4636556416933844

Epoch: 5| Step: 8
Training loss: 0.5460585357707245
Validation loss: 2.430143208799408

Epoch: 5| Step: 9
Training loss: 0.2709016240048725
Validation loss: 2.44972568363346

Epoch: 5| Step: 10
Training loss: 0.4296009843599685
Validation loss: 2.4732911066478906

Epoch: 509| Step: 0
Training loss: 0.33697132232159666
Validation loss: 2.4887158051157097

Epoch: 5| Step: 1
Training loss: 0.44231926333161864
Validation loss: 2.4764764771538355

Epoch: 5| Step: 2
Training loss: 0.3121738042681588
Validation loss: 2.4956350136571537

Epoch: 5| Step: 3
Training loss: 0.4992853958942405
Validation loss: 2.507923311740873

Epoch: 5| Step: 4
Training loss: 0.31968521708384634
Validation loss: 2.4537629985031972

Epoch: 5| Step: 5
Training loss: 0.32302187415804823
Validation loss: 2.474358221527242

Epoch: 5| Step: 6
Training loss: 0.4230870742930504
Validation loss: 2.451220192780488

Epoch: 5| Step: 7
Training loss: 0.23909701179270834
Validation loss: 2.4803227450203122

Epoch: 5| Step: 8
Training loss: 0.2913059348312094
Validation loss: 2.459095772179788

Epoch: 5| Step: 9
Training loss: 0.436775424944361
Validation loss: 2.476574745923023

Epoch: 5| Step: 10
Training loss: 0.5500977516004932
Validation loss: 2.4323320080885775

Epoch: 510| Step: 0
Training loss: 0.363041172889897
Validation loss: 2.4363384818697837

Epoch: 5| Step: 1
Training loss: 0.21110706225250603
Validation loss: 2.471088988340682

Epoch: 5| Step: 2
Training loss: 0.3117885358512961
Validation loss: 2.465363303775035

Epoch: 5| Step: 3
Training loss: 0.371011162652921
Validation loss: 2.462997879826456

Epoch: 5| Step: 4
Training loss: 0.2200000840696261
Validation loss: 2.434751680318613

Epoch: 5| Step: 5
Training loss: 0.4663808876438921
Validation loss: 2.4452765714182707

Epoch: 5| Step: 6
Training loss: 0.2261282359899132
Validation loss: 2.4589181141577208

Epoch: 5| Step: 7
Training loss: 0.5187815943828777
Validation loss: 2.4628878259988927

Epoch: 5| Step: 8
Training loss: 0.3507198832300785
Validation loss: 2.4595816314029246

Epoch: 5| Step: 9
Training loss: 0.45465897015077694
Validation loss: 2.4394889943257807

Epoch: 5| Step: 10
Training loss: 0.5014015165196489
Validation loss: 2.4568326035614945

Epoch: 511| Step: 0
Training loss: 0.2670711113255377
Validation loss: 2.463379916250013

Epoch: 5| Step: 1
Training loss: 0.4245978717947823
Validation loss: 2.433640915131772

Epoch: 5| Step: 2
Training loss: 0.351400889232381
Validation loss: 2.4673542154375854

Epoch: 5| Step: 3
Training loss: 0.24983738289330895
Validation loss: 2.442331494702157

Epoch: 5| Step: 4
Training loss: 0.4190724853418333
Validation loss: 2.4449070194566644

Epoch: 5| Step: 5
Training loss: 0.43533982286331085
Validation loss: 2.4461359428187444

Epoch: 5| Step: 6
Training loss: 0.3752201149570079
Validation loss: 2.4339762802340026

Epoch: 5| Step: 7
Training loss: 0.3575352556677595
Validation loss: 2.424954624045388

Epoch: 5| Step: 8
Training loss: 0.4178946955310192
Validation loss: 2.445676938211412

Epoch: 5| Step: 9
Training loss: 0.4383782359369005
Validation loss: 2.427492324766107

Epoch: 5| Step: 10
Training loss: 0.37619774987903065
Validation loss: 2.439631173833047

Epoch: 512| Step: 0
Training loss: 0.4036171031284541
Validation loss: 2.4358538855746095

Epoch: 5| Step: 1
Training loss: 0.4665774064898919
Validation loss: 2.4441654435152866

Epoch: 5| Step: 2
Training loss: 0.27939331950431917
Validation loss: 2.463671879953147

Epoch: 5| Step: 3
Training loss: 0.37037911117800537
Validation loss: 2.441134927484786

Epoch: 5| Step: 4
Training loss: 0.35048231968522164
Validation loss: 2.4648308409833253

Epoch: 5| Step: 5
Training loss: 0.3211697179953396
Validation loss: 2.484654352114897

Epoch: 5| Step: 6
Training loss: 0.4887625039249987
Validation loss: 2.4498485711759974

Epoch: 5| Step: 7
Training loss: 0.3595792770304298
Validation loss: 2.4560336766718036

Epoch: 5| Step: 8
Training loss: 0.28925360986308324
Validation loss: 2.4583835009222983

Epoch: 5| Step: 9
Training loss: 0.4391046456306023
Validation loss: 2.468772166370565

Epoch: 5| Step: 10
Training loss: 0.3129786997264328
Validation loss: 2.4719150369726606

Epoch: 513| Step: 0
Training loss: 0.49235599903303817
Validation loss: 2.4680900506810928

Epoch: 5| Step: 1
Training loss: 0.3099551892002955
Validation loss: 2.4929944686161263

Epoch: 5| Step: 2
Training loss: 0.18725087583194436
Validation loss: 2.4714312128674085

Epoch: 5| Step: 3
Training loss: 0.2744013284464089
Validation loss: 2.449847029756708

Epoch: 5| Step: 4
Training loss: 0.274571261738748
Validation loss: 2.502963590142477

Epoch: 5| Step: 5
Training loss: 0.2596011680938233
Validation loss: 2.447504851384109

Epoch: 5| Step: 6
Training loss: 0.472348404563914
Validation loss: 2.450742401724479

Epoch: 5| Step: 7
Training loss: 0.36658863172859496
Validation loss: 2.4717725893194182

Epoch: 5| Step: 8
Training loss: 0.45537019124556216
Validation loss: 2.4550951760022235

Epoch: 5| Step: 9
Training loss: 0.5294157507027996
Validation loss: 2.4490824133173996

Epoch: 5| Step: 10
Training loss: 0.2748313256470508
Validation loss: 2.466387112101706

Epoch: 514| Step: 0
Training loss: 0.4294487376524182
Validation loss: 2.446716118575704

Epoch: 5| Step: 1
Training loss: 0.5008330557891703
Validation loss: 2.4713531006241585

Epoch: 5| Step: 2
Training loss: 0.3725223148625756
Validation loss: 2.4633020701045187

Epoch: 5| Step: 3
Training loss: 0.43551380733299133
Validation loss: 2.45655620935003

Epoch: 5| Step: 4
Training loss: 0.21586748185951735
Validation loss: 2.4728363240587483

Epoch: 5| Step: 5
Training loss: 0.370446956545355
Validation loss: 2.4732710377892717

Epoch: 5| Step: 6
Training loss: 0.42309640751167565
Validation loss: 2.478696697055154

Epoch: 5| Step: 7
Training loss: 0.3056100669676304
Validation loss: 2.4841323138595532

Epoch: 5| Step: 8
Training loss: 0.43604609186314924
Validation loss: 2.4760726486184477

Epoch: 5| Step: 9
Training loss: 0.31214546119131226
Validation loss: 2.4719553308478557

Epoch: 5| Step: 10
Training loss: 0.20812768123950154
Validation loss: 2.443563896616512

Epoch: 515| Step: 0
Training loss: 0.40101935171821745
Validation loss: 2.401117548162694

Epoch: 5| Step: 1
Training loss: 0.5288927569562893
Validation loss: 2.412770737394166

Epoch: 5| Step: 2
Training loss: 0.359376554900413
Validation loss: 2.3913148896208196

Epoch: 5| Step: 3
Training loss: 0.5628139891067283
Validation loss: 2.4277905884255793

Epoch: 5| Step: 4
Training loss: 0.3415155397331193
Validation loss: 2.4035538504359946

Epoch: 5| Step: 5
Training loss: 0.23153267994018328
Validation loss: 2.4211122802353082

Epoch: 5| Step: 6
Training loss: 0.3904909666899505
Validation loss: 2.4234603810831685

Epoch: 5| Step: 7
Training loss: 0.20552260052178514
Validation loss: 2.424461507342462

Epoch: 5| Step: 8
Training loss: 0.2658636199406019
Validation loss: 2.415458753031653

Epoch: 5| Step: 9
Training loss: 0.3172079455546465
Validation loss: 2.4471615588647144

Epoch: 5| Step: 10
Training loss: 0.2930262445618511
Validation loss: 2.477292940515263

Epoch: 516| Step: 0
Training loss: 0.29628525683096996
Validation loss: 2.4577769579220896

Epoch: 5| Step: 1
Training loss: 0.34899838298406605
Validation loss: 2.464787333204096

Epoch: 5| Step: 2
Training loss: 0.27795633977726836
Validation loss: 2.477144323022305

Epoch: 5| Step: 3
Training loss: 0.4274612321062179
Validation loss: 2.467374856605164

Epoch: 5| Step: 4
Training loss: 0.29267305074391153
Validation loss: 2.4519480691938784

Epoch: 5| Step: 5
Training loss: 0.5605890344589096
Validation loss: 2.4387832557743327

Epoch: 5| Step: 6
Training loss: 0.42153972089119235
Validation loss: 2.431980233713966

Epoch: 5| Step: 7
Training loss: 0.3994875702684864
Validation loss: 2.4372312883044174

Epoch: 5| Step: 8
Training loss: 0.43494260464125933
Validation loss: 2.430207270930533

Epoch: 5| Step: 9
Training loss: 0.2066178062257479
Validation loss: 2.4425355041249714

Epoch: 5| Step: 10
Training loss: 0.3206403496620562
Validation loss: 2.4297892653345143

Epoch: 517| Step: 0
Training loss: 0.5178260353451155
Validation loss: 2.4633390871508323

Epoch: 5| Step: 1
Training loss: 0.25681444085381816
Validation loss: 2.4686697732297302

Epoch: 5| Step: 2
Training loss: 0.2664581304245674
Validation loss: 2.458871894716546

Epoch: 5| Step: 3
Training loss: 0.4174586597122413
Validation loss: 2.4657359116440873

Epoch: 5| Step: 4
Training loss: 0.5119427489182882
Validation loss: 2.4776812220824374

Epoch: 5| Step: 5
Training loss: 0.23773577274459434
Validation loss: 2.4801358832334897

Epoch: 5| Step: 6
Training loss: 0.3269839428377342
Validation loss: 2.475781776607487

Epoch: 5| Step: 7
Training loss: 0.38630361141735625
Validation loss: 2.493034018177106

Epoch: 5| Step: 8
Training loss: 0.3585346181480716
Validation loss: 2.4757528620084748

Epoch: 5| Step: 9
Training loss: 0.2062232787711207
Validation loss: 2.470650534957971

Epoch: 5| Step: 10
Training loss: 0.3615370687576538
Validation loss: 2.440818543803703

Epoch: 518| Step: 0
Training loss: 0.2230014634544096
Validation loss: 2.42541187003778

Epoch: 5| Step: 1
Training loss: 0.4035704901325055
Validation loss: 2.4730329199597434

Epoch: 5| Step: 2
Training loss: 0.4094232457975137
Validation loss: 2.43902179635468

Epoch: 5| Step: 3
Training loss: 0.26364922602829455
Validation loss: 2.429324874773423

Epoch: 5| Step: 4
Training loss: 0.4542682628854819
Validation loss: 2.4345337336206367

Epoch: 5| Step: 5
Training loss: 0.40087903634927663
Validation loss: 2.4411845066890367

Epoch: 5| Step: 6
Training loss: 0.2837900459708325
Validation loss: 2.414502426179709

Epoch: 5| Step: 7
Training loss: 0.3377252626127334
Validation loss: 2.4405709193431915

Epoch: 5| Step: 8
Training loss: 0.28121444689360797
Validation loss: 2.479475806769721

Epoch: 5| Step: 9
Training loss: 0.5321112551590822
Validation loss: 2.442380912637566

Epoch: 5| Step: 10
Training loss: 0.25376089777353517
Validation loss: 2.484730614128566

Epoch: 519| Step: 0
Training loss: 0.2250026576891869
Validation loss: 2.4355641206296768

Epoch: 5| Step: 1
Training loss: 0.22117492580701467
Validation loss: 2.4666993126403653

Epoch: 5| Step: 2
Training loss: 0.2999442704412933
Validation loss: 2.476148180498683

Epoch: 5| Step: 3
Training loss: 0.4377093155002726
Validation loss: 2.4366720301044698

Epoch: 5| Step: 4
Training loss: 0.2926595836761145
Validation loss: 2.4655456120941412

Epoch: 5| Step: 5
Training loss: 0.32805000310952187
Validation loss: 2.4539851476923538

Epoch: 5| Step: 6
Training loss: 0.4030523818797602
Validation loss: 2.4596283920044373

Epoch: 5| Step: 7
Training loss: 0.5623266694786401
Validation loss: 2.4633033143009344

Epoch: 5| Step: 8
Training loss: 0.45859615058855485
Validation loss: 2.4381251788929794

Epoch: 5| Step: 9
Training loss: 0.27057338429405375
Validation loss: 2.4584335858019717

Epoch: 5| Step: 10
Training loss: 0.27246060935380106
Validation loss: 2.46067291363562

Epoch: 520| Step: 0
Training loss: 0.3139891192364207
Validation loss: 2.4710514177035305

Epoch: 5| Step: 1
Training loss: 0.4537812610765714
Validation loss: 2.4644729868188

Epoch: 5| Step: 2
Training loss: 0.2756727680671184
Validation loss: 2.4625711946183233

Epoch: 5| Step: 3
Training loss: 0.3581148111515073
Validation loss: 2.4895095398927563

Epoch: 5| Step: 4
Training loss: 0.2735851161864612
Validation loss: 2.4978976372324073

Epoch: 5| Step: 5
Training loss: 0.4788575021598424
Validation loss: 2.4934479398014977

Epoch: 5| Step: 6
Training loss: 0.5040848289884196
Validation loss: 2.4702121365926533

Epoch: 5| Step: 7
Training loss: 0.2993816783733532
Validation loss: 2.484105618804599

Epoch: 5| Step: 8
Training loss: 0.3145748874128417
Validation loss: 2.4960052989633827

Epoch: 5| Step: 9
Training loss: 0.2815271177933927
Validation loss: 2.493016734088378

Epoch: 5| Step: 10
Training loss: 0.24166875319703732
Validation loss: 2.4663099081527182

Epoch: 521| Step: 0
Training loss: 0.394650469603598
Validation loss: 2.4316994807653813

Epoch: 5| Step: 1
Training loss: 0.37489686978341646
Validation loss: 2.4287954802662757

Epoch: 5| Step: 2
Training loss: 0.2642079590365286
Validation loss: 2.4269285396045266

Epoch: 5| Step: 3
Training loss: 0.5073539717819074
Validation loss: 2.42165057160964

Epoch: 5| Step: 4
Training loss: 0.1796766049772377
Validation loss: 2.41455328325413

Epoch: 5| Step: 5
Training loss: 0.2333708311856883
Validation loss: 2.4484874917685957

Epoch: 5| Step: 6
Training loss: 0.23549671366498298
Validation loss: 2.431353796881059

Epoch: 5| Step: 7
Training loss: 0.42912586961119736
Validation loss: 2.4385361184978454

Epoch: 5| Step: 8
Training loss: 0.3143958519377444
Validation loss: 2.4660238008898725

Epoch: 5| Step: 9
Training loss: 0.45042545948156515
Validation loss: 2.4926249563478433

Epoch: 5| Step: 10
Training loss: 0.44922878420030565
Validation loss: 2.5175200264492195

Epoch: 522| Step: 0
Training loss: 0.2338967052390347
Validation loss: 2.487487877696521

Epoch: 5| Step: 1
Training loss: 0.32691280932236966
Validation loss: 2.498127964487443

Epoch: 5| Step: 2
Training loss: 0.36762815777493474
Validation loss: 2.4980926970002564

Epoch: 5| Step: 3
Training loss: 0.4041864179753334
Validation loss: 2.457186510844307

Epoch: 5| Step: 4
Training loss: 0.21565314330386848
Validation loss: 2.446674227639009

Epoch: 5| Step: 5
Training loss: 0.3105912806593827
Validation loss: 2.438090605975039

Epoch: 5| Step: 6
Training loss: 0.3808169023355434
Validation loss: 2.428246581426674

Epoch: 5| Step: 7
Training loss: 0.3199105182723304
Validation loss: 2.4399228513847775

Epoch: 5| Step: 8
Training loss: 0.35156051847111386
Validation loss: 2.4517286172289765

Epoch: 5| Step: 9
Training loss: 0.6178577260669064
Validation loss: 2.476459274710519

Epoch: 5| Step: 10
Training loss: 0.22488504990125147
Validation loss: 2.4669280862620377

Epoch: 523| Step: 0
Training loss: 0.3721337452079692
Validation loss: 2.443532029830251

Epoch: 5| Step: 1
Training loss: 0.4587456752095107
Validation loss: 2.4789440975103436

Epoch: 5| Step: 2
Training loss: 0.24836882775753127
Validation loss: 2.475017477276065

Epoch: 5| Step: 3
Training loss: 0.1476627446820137
Validation loss: 2.520767900239243

Epoch: 5| Step: 4
Training loss: 0.34086300383058477
Validation loss: 2.494920913794568

Epoch: 5| Step: 5
Training loss: 0.5147596669746037
Validation loss: 2.5042097067671696

Epoch: 5| Step: 6
Training loss: 0.1488456260223343
Validation loss: 2.496679667826129

Epoch: 5| Step: 7
Training loss: 0.45142804754385896
Validation loss: 2.494909960153106

Epoch: 5| Step: 8
Training loss: 0.2659157536106539
Validation loss: 2.4900175987505024

Epoch: 5| Step: 9
Training loss: 0.3221120063624296
Validation loss: 2.492223562881759

Epoch: 5| Step: 10
Training loss: 0.3495704160326332
Validation loss: 2.4849765075469765

Epoch: 524| Step: 0
Training loss: 0.36244778750377526
Validation loss: 2.4809209696733987

Epoch: 5| Step: 1
Training loss: 0.29780545737714603
Validation loss: 2.4874664707143013

Epoch: 5| Step: 2
Training loss: 0.15972628680415532
Validation loss: 2.477814362863746

Epoch: 5| Step: 3
Training loss: 0.5487466663441816
Validation loss: 2.463485676205641

Epoch: 5| Step: 4
Training loss: 0.18446462117957135
Validation loss: 2.4583100793516284

Epoch: 5| Step: 5
Training loss: 0.46128537902989464
Validation loss: 2.4085299671095854

Epoch: 5| Step: 6
Training loss: 0.3147604962402375
Validation loss: 2.415124483510537

Epoch: 5| Step: 7
Training loss: 0.17266180107203352
Validation loss: 2.3998487250958687

Epoch: 5| Step: 8
Training loss: 0.4181658734527815
Validation loss: 2.3904823948616367

Epoch: 5| Step: 9
Training loss: 0.35784224507327955
Validation loss: 2.4147956091534954

Epoch: 5| Step: 10
Training loss: 0.4145259962097661
Validation loss: 2.400121526991128

Epoch: 525| Step: 0
Training loss: 0.3009559817397659
Validation loss: 2.3962165693648334

Epoch: 5| Step: 1
Training loss: 0.22132192638697118
Validation loss: 2.409869847150393

Epoch: 5| Step: 2
Training loss: 0.2837234058815332
Validation loss: 2.432884001014577

Epoch: 5| Step: 3
Training loss: 0.3197621875040406
Validation loss: 2.4658510345718687

Epoch: 5| Step: 4
Training loss: 0.4171143292613159
Validation loss: 2.4829792754195843

Epoch: 5| Step: 5
Training loss: 0.47642244563563196
Validation loss: 2.4867548792411585

Epoch: 5| Step: 6
Training loss: 0.2420057568505752
Validation loss: 2.5008492719264805

Epoch: 5| Step: 7
Training loss: 0.35560676494434856
Validation loss: 2.4988795566601922

Epoch: 5| Step: 8
Training loss: 0.34554061733912816
Validation loss: 2.464964035716322

Epoch: 5| Step: 9
Training loss: 0.40047959990581244
Validation loss: 2.480425816762631

Epoch: 5| Step: 10
Training loss: 0.3917983552366612
Validation loss: 2.436514465616697

Epoch: 526| Step: 0
Training loss: 0.4527813660769393
Validation loss: 2.4494546101984205

Epoch: 5| Step: 1
Training loss: 0.294856310497533
Validation loss: 2.4121215272653536

Epoch: 5| Step: 2
Training loss: 0.24803760841662162
Validation loss: 2.406888765406754

Epoch: 5| Step: 3
Training loss: 0.32569475741033604
Validation loss: 2.389817226516306

Epoch: 5| Step: 4
Training loss: 0.37805731538032405
Validation loss: 2.4316141812963568

Epoch: 5| Step: 5
Training loss: 0.2979469771849447
Validation loss: 2.4144993873987013

Epoch: 5| Step: 6
Training loss: 0.3675457849981421
Validation loss: 2.401282720513097

Epoch: 5| Step: 7
Training loss: 0.4378748037592094
Validation loss: 2.399017679606064

Epoch: 5| Step: 8
Training loss: 0.30890134378182926
Validation loss: 2.3984541327759654

Epoch: 5| Step: 9
Training loss: 0.3754534364165851
Validation loss: 2.4444025181117226

Epoch: 5| Step: 10
Training loss: 0.25376707811152704
Validation loss: 2.458936383374461

Epoch: 527| Step: 0
Training loss: 0.1913175766740827
Validation loss: 2.45967090864041

Epoch: 5| Step: 1
Training loss: 0.20309932253004762
Validation loss: 2.4745607312153592

Epoch: 5| Step: 2
Training loss: 0.41741912569586037
Validation loss: 2.5100983036700253

Epoch: 5| Step: 3
Training loss: 0.3906739776424145
Validation loss: 2.4905774165636676

Epoch: 5| Step: 4
Training loss: 0.39395265359615445
Validation loss: 2.4822986708044317

Epoch: 5| Step: 5
Training loss: 0.2398466144229186
Validation loss: 2.4633291461951234

Epoch: 5| Step: 6
Training loss: 0.4490723744622775
Validation loss: 2.45963224533937

Epoch: 5| Step: 7
Training loss: 0.4632696539471318
Validation loss: 2.460192119629051

Epoch: 5| Step: 8
Training loss: 0.31770412906095397
Validation loss: 2.4552464171449766

Epoch: 5| Step: 9
Training loss: 0.28751611768075913
Validation loss: 2.428329601117607

Epoch: 5| Step: 10
Training loss: 0.26114203836924416
Validation loss: 2.4414415005015644

Epoch: 528| Step: 0
Training loss: 0.1890628570364111
Validation loss: 2.430105802662628

Epoch: 5| Step: 1
Training loss: 0.28785743056171026
Validation loss: 2.4561643805401245

Epoch: 5| Step: 2
Training loss: 0.45010914670977026
Validation loss: 2.4559974263338304

Epoch: 5| Step: 3
Training loss: 0.4477506115375136
Validation loss: 2.443773430792022

Epoch: 5| Step: 4
Training loss: 0.3532335726332789
Validation loss: 2.4554786090187584

Epoch: 5| Step: 5
Training loss: 0.355037280630248
Validation loss: 2.4553004010913853

Epoch: 5| Step: 6
Training loss: 0.2531583775778322
Validation loss: 2.4787098591351078

Epoch: 5| Step: 7
Training loss: 0.21955605566990297
Validation loss: 2.4550433966218694

Epoch: 5| Step: 8
Training loss: 0.34686308831734797
Validation loss: 2.4861017372584184

Epoch: 5| Step: 9
Training loss: 0.3522478628682593
Validation loss: 2.4721983480258976

Epoch: 5| Step: 10
Training loss: 0.3292441582708229
Validation loss: 2.479249264327064

Epoch: 529| Step: 0
Training loss: 0.28698813544980245
Validation loss: 2.493718375078121

Epoch: 5| Step: 1
Training loss: 0.26416012804521277
Validation loss: 2.4784589970587363

Epoch: 5| Step: 2
Training loss: 0.21264241999739522
Validation loss: 2.4959935530495008

Epoch: 5| Step: 3
Training loss: 0.50272381466887
Validation loss: 2.4698660713438394

Epoch: 5| Step: 4
Training loss: 0.26694371551551316
Validation loss: 2.4493045144539187

Epoch: 5| Step: 5
Training loss: 0.3799890011839485
Validation loss: 2.4555727929847073

Epoch: 5| Step: 6
Training loss: 0.3306149062579139
Validation loss: 2.4577720236605978

Epoch: 5| Step: 7
Training loss: 0.35852202485607493
Validation loss: 2.429430050546627

Epoch: 5| Step: 8
Training loss: 0.31092219195231613
Validation loss: 2.4761103791269994

Epoch: 5| Step: 9
Training loss: 0.36466110853135597
Validation loss: 2.445547578576458

Epoch: 5| Step: 10
Training loss: 0.3548821650296038
Validation loss: 2.440962697022991

Epoch: 530| Step: 0
Training loss: 0.2731354953006386
Validation loss: 2.453633265358053

Epoch: 5| Step: 1
Training loss: 0.4617669837143509
Validation loss: 2.4510536224481

Epoch: 5| Step: 2
Training loss: 0.29677521132782275
Validation loss: 2.4122324433503977

Epoch: 5| Step: 3
Training loss: 0.2881696805629978
Validation loss: 2.4360144173870553

Epoch: 5| Step: 4
Training loss: 0.33374925334718314
Validation loss: 2.406293257351266

Epoch: 5| Step: 5
Training loss: 0.5153184904510251
Validation loss: 2.393889922934542

Epoch: 5| Step: 6
Training loss: 0.31705365058118945
Validation loss: 2.400228875878941

Epoch: 5| Step: 7
Training loss: 0.22041202015356975
Validation loss: 2.411913854765423

Epoch: 5| Step: 8
Training loss: 0.19580209403418428
Validation loss: 2.3794477553570186

Epoch: 5| Step: 9
Training loss: 0.35257163914353523
Validation loss: 2.382593630551702

Epoch: 5| Step: 10
Training loss: 0.3022300087341672
Validation loss: 2.3721608914957124

Epoch: 531| Step: 0
Training loss: 0.4067772598182261
Validation loss: 2.3698626623344916

Epoch: 5| Step: 1
Training loss: 0.11357226480786008
Validation loss: 2.4054879717333337

Epoch: 5| Step: 2
Training loss: 0.2954267260735795
Validation loss: 2.407846922120431

Epoch: 5| Step: 3
Training loss: 0.20138009415712124
Validation loss: 2.409909651353755

Epoch: 5| Step: 4
Training loss: 0.36311584727033946
Validation loss: 2.406280557869638

Epoch: 5| Step: 5
Training loss: 0.407622549609388
Validation loss: 2.399650623671541

Epoch: 5| Step: 6
Training loss: 0.11493221771279459
Validation loss: 2.443848197543324

Epoch: 5| Step: 7
Training loss: 0.3903297262002027
Validation loss: 2.394706476765224

Epoch: 5| Step: 8
Training loss: 0.43350847797617365
Validation loss: 2.4406912837098496

Epoch: 5| Step: 9
Training loss: 0.3670170571029963
Validation loss: 2.448223006525366

Epoch: 5| Step: 10
Training loss: 0.3579757026719814
Validation loss: 2.4437190180583452

Epoch: 532| Step: 0
Training loss: 0.2062337467985472
Validation loss: 2.4570347693503014

Epoch: 5| Step: 1
Training loss: 0.2183084715196581
Validation loss: 2.4622849902694264

Epoch: 5| Step: 2
Training loss: 0.4301565211441067
Validation loss: 2.4734096890658126

Epoch: 5| Step: 3
Training loss: 0.3100632434406222
Validation loss: 2.4626620837365167

Epoch: 5| Step: 4
Training loss: 0.4386926131471554
Validation loss: 2.4633771407002967

Epoch: 5| Step: 5
Training loss: 0.2538741751732098
Validation loss: 2.4778590784754333

Epoch: 5| Step: 6
Training loss: 0.2759676765150605
Validation loss: 2.474831926197798

Epoch: 5| Step: 7
Training loss: 0.21497636516817206
Validation loss: 2.471595642318134

Epoch: 5| Step: 8
Training loss: 0.45948806072036824
Validation loss: 2.4648831552874015

Epoch: 5| Step: 9
Training loss: 0.3539752606607896
Validation loss: 2.4673009446134655

Epoch: 5| Step: 10
Training loss: 0.32806283498170263
Validation loss: 2.4722531667649017

Epoch: 533| Step: 0
Training loss: 0.5234054726438804
Validation loss: 2.4500949445898406

Epoch: 5| Step: 1
Training loss: 0.19027590288582794
Validation loss: 2.446451204480029

Epoch: 5| Step: 2
Training loss: 0.1417874530152508
Validation loss: 2.4371769777559087

Epoch: 5| Step: 3
Training loss: 0.255255372065618
Validation loss: 2.4393814625356147

Epoch: 5| Step: 4
Training loss: 0.44847443325526415
Validation loss: 2.464702436192138

Epoch: 5| Step: 5
Training loss: 0.32259153589968637
Validation loss: 2.479789099074916

Epoch: 5| Step: 6
Training loss: 0.2010406047335103
Validation loss: 2.44767183237123

Epoch: 5| Step: 7
Training loss: 0.3228562924130327
Validation loss: 2.4663457226286143

Epoch: 5| Step: 8
Training loss: 0.23682057485155977
Validation loss: 2.436411268170241

Epoch: 5| Step: 9
Training loss: 0.4894979652756045
Validation loss: 2.4529217944877226

Epoch: 5| Step: 10
Training loss: 0.25888704568273163
Validation loss: 2.460551176725154

Epoch: 534| Step: 0
Training loss: 0.29869486760936537
Validation loss: 2.4699937421946863

Epoch: 5| Step: 1
Training loss: 0.2193501448339728
Validation loss: 2.467173183773466

Epoch: 5| Step: 2
Training loss: 0.1711758079320734
Validation loss: 2.496160589210337

Epoch: 5| Step: 3
Training loss: 0.3471174243557783
Validation loss: 2.4885526979657655

Epoch: 5| Step: 4
Training loss: 0.33994329025154146
Validation loss: 2.5044761517113097

Epoch: 5| Step: 5
Training loss: 0.33864467472021764
Validation loss: 2.5177930109828845

Epoch: 5| Step: 6
Training loss: 0.26839604633872316
Validation loss: 2.515769534480173

Epoch: 5| Step: 7
Training loss: 0.45907924564427727
Validation loss: 2.5189367863787226

Epoch: 5| Step: 8
Training loss: 0.3213107440902734
Validation loss: 2.4956494582887907

Epoch: 5| Step: 9
Training loss: 0.3707293277078086
Validation loss: 2.5282623360796372

Epoch: 5| Step: 10
Training loss: 0.4208522160545959
Validation loss: 2.5027686539198597

Epoch: 535| Step: 0
Training loss: 0.2876504742707153
Validation loss: 2.4979129160015816

Epoch: 5| Step: 1
Training loss: 0.31872563268981846
Validation loss: 2.455686839991476

Epoch: 5| Step: 2
Training loss: 0.25290551677669687
Validation loss: 2.4538237281568294

Epoch: 5| Step: 3
Training loss: 0.2506372703963656
Validation loss: 2.447711488969707

Epoch: 5| Step: 4
Training loss: 0.29885328099698055
Validation loss: 2.4249328278369164

Epoch: 5| Step: 5
Training loss: 0.3218289046011628
Validation loss: 2.4284135976465544

Epoch: 5| Step: 6
Training loss: 0.2723572373018797
Validation loss: 2.421550556194626

Epoch: 5| Step: 7
Training loss: 0.3401669905249963
Validation loss: 2.416666311116205

Epoch: 5| Step: 8
Training loss: 0.23406175502510845
Validation loss: 2.4363789742725643

Epoch: 5| Step: 9
Training loss: 0.24341449327672868
Validation loss: 2.4434356253929588

Epoch: 5| Step: 10
Training loss: 0.6039446691454491
Validation loss: 2.430692228311792

Epoch: 536| Step: 0
Training loss: 0.29943196989035537
Validation loss: 2.4303233837881923

Epoch: 5| Step: 1
Training loss: 0.2524005259131289
Validation loss: 2.4410962210744556

Epoch: 5| Step: 2
Training loss: 0.31396193673551526
Validation loss: 2.4209073751269106

Epoch: 5| Step: 3
Training loss: 0.3657538040403969
Validation loss: 2.437222439991877

Epoch: 5| Step: 4
Training loss: 0.4472821494968751
Validation loss: 2.451023860211766

Epoch: 5| Step: 5
Training loss: 0.24932168789867526
Validation loss: 2.423735006957749

Epoch: 5| Step: 6
Training loss: 0.3528808669758911
Validation loss: 2.4249796603176215

Epoch: 5| Step: 7
Training loss: 0.3233523800469598
Validation loss: 2.4500461117806367

Epoch: 5| Step: 8
Training loss: 0.20720019734572986
Validation loss: 2.4373333129599186

Epoch: 5| Step: 9
Training loss: 0.3274149705709086
Validation loss: 2.4827952899732764

Epoch: 5| Step: 10
Training loss: 0.28586066782393943
Validation loss: 2.4700411474155004

Epoch: 537| Step: 0
Training loss: 0.20320855769573334
Validation loss: 2.460606145028594

Epoch: 5| Step: 1
Training loss: 0.22657027724499157
Validation loss: 2.442841391863407

Epoch: 5| Step: 2
Training loss: 0.2096056127192799
Validation loss: 2.4329744728696485

Epoch: 5| Step: 3
Training loss: 0.14987517244195442
Validation loss: 2.4245302980418555

Epoch: 5| Step: 4
Training loss: 0.3108950648272846
Validation loss: 2.41464514955074

Epoch: 5| Step: 5
Training loss: 0.48798956742039895
Validation loss: 2.4295505389721765

Epoch: 5| Step: 6
Training loss: 0.30599010007557625
Validation loss: 2.409556895783683

Epoch: 5| Step: 7
Training loss: 0.4088597833851005
Validation loss: 2.421897869551245

Epoch: 5| Step: 8
Training loss: 0.2152822527796326
Validation loss: 2.416564787208373

Epoch: 5| Step: 9
Training loss: 0.3910125717059119
Validation loss: 2.402548766873533

Epoch: 5| Step: 10
Training loss: 0.4495621073888313
Validation loss: 2.4345262202295066

Epoch: 538| Step: 0
Training loss: 0.11991515653348382
Validation loss: 2.426292264813182

Epoch: 5| Step: 1
Training loss: 0.4400395189766309
Validation loss: 2.4238951599910363

Epoch: 5| Step: 2
Training loss: 0.16971058699001768
Validation loss: 2.4347440849442186

Epoch: 5| Step: 3
Training loss: 0.24878321261782413
Validation loss: 2.4327046289997045

Epoch: 5| Step: 4
Training loss: 0.2987054560584776
Validation loss: 2.4101140655848172

Epoch: 5| Step: 5
Training loss: 0.42138173265037837
Validation loss: 2.4313609526152815

Epoch: 5| Step: 6
Training loss: 0.3407853991270329
Validation loss: 2.452823973412269

Epoch: 5| Step: 7
Training loss: 0.3495581179077657
Validation loss: 2.4186222998844387

Epoch: 5| Step: 8
Training loss: 0.25622895898729653
Validation loss: 2.4334657559988795

Epoch: 5| Step: 9
Training loss: 0.47241843364730773
Validation loss: 2.437272737782084

Epoch: 5| Step: 10
Training loss: 0.27369600066080874
Validation loss: 2.4300448574245603

Epoch: 539| Step: 0
Training loss: 0.4591567669416859
Validation loss: 2.418251460674603

Epoch: 5| Step: 1
Training loss: 0.19236696245767249
Validation loss: 2.4303772641686168

Epoch: 5| Step: 2
Training loss: 0.33611301893598305
Validation loss: 2.4240854497280773

Epoch: 5| Step: 3
Training loss: 0.2155326030246809
Validation loss: 2.456995421829735

Epoch: 5| Step: 4
Training loss: 0.354423873666342
Validation loss: 2.462666974888106

Epoch: 5| Step: 5
Training loss: 0.3810693797647486
Validation loss: 2.463449470483953

Epoch: 5| Step: 6
Training loss: 0.21214987998588597
Validation loss: 2.4555208905618393

Epoch: 5| Step: 7
Training loss: 0.4237131235230349
Validation loss: 2.5003957660751888

Epoch: 5| Step: 8
Training loss: 0.3035127661728712
Validation loss: 2.452632144169664

Epoch: 5| Step: 9
Training loss: 0.31777147410887596
Validation loss: 2.491657846931599

Epoch: 5| Step: 10
Training loss: 0.2853155866708739
Validation loss: 2.4635455454464745

Epoch: 540| Step: 0
Training loss: 0.2898695093723058
Validation loss: 2.4556418093763144

Epoch: 5| Step: 1
Training loss: 0.374343496089282
Validation loss: 2.4614700733360833

Epoch: 5| Step: 2
Training loss: 0.41928685988919334
Validation loss: 2.4237375243375476

Epoch: 5| Step: 3
Training loss: 0.2053388300869274
Validation loss: 2.4106555737331306

Epoch: 5| Step: 4
Training loss: 0.3204059348254122
Validation loss: 2.4258636666162348

Epoch: 5| Step: 5
Training loss: 0.214137685756281
Validation loss: 2.4103901955761478

Epoch: 5| Step: 6
Training loss: 0.2956754517802803
Validation loss: 2.424014187482568

Epoch: 5| Step: 7
Training loss: 0.28320937314211403
Validation loss: 2.4329812840179184

Epoch: 5| Step: 8
Training loss: 0.22917742144028558
Validation loss: 2.467524410556399

Epoch: 5| Step: 9
Training loss: 0.3943377105083539
Validation loss: 2.453672973971129

Epoch: 5| Step: 10
Training loss: 0.40385733774963983
Validation loss: 2.4671222725242115

Epoch: 541| Step: 0
Training loss: 0.26479045815620994
Validation loss: 2.4345693358277907

Epoch: 5| Step: 1
Training loss: 0.4519871533243488
Validation loss: 2.450687966933932

Epoch: 5| Step: 2
Training loss: 0.174498204122623
Validation loss: 2.4368759378695377

Epoch: 5| Step: 3
Training loss: 0.3619757544633417
Validation loss: 2.4163408629107237

Epoch: 5| Step: 4
Training loss: 0.24747107348800673
Validation loss: 2.417611324345921

Epoch: 5| Step: 5
Training loss: 0.32945870510312075
Validation loss: 2.3846748604000356

Epoch: 5| Step: 6
Training loss: 0.17696328628703795
Validation loss: 2.423403838714431

Epoch: 5| Step: 7
Training loss: 0.3110266404356024
Validation loss: 2.419699352646919

Epoch: 5| Step: 8
Training loss: 0.3837279059918216
Validation loss: 2.405240346086321

Epoch: 5| Step: 9
Training loss: 0.4466948052547257
Validation loss: 2.4270051065726848

Epoch: 5| Step: 10
Training loss: 0.1382954956518605
Validation loss: 2.4767716868291085

Epoch: 542| Step: 0
Training loss: 0.3941914634317836
Validation loss: 2.4401538937622274

Epoch: 5| Step: 1
Training loss: 0.31393455015129823
Validation loss: 2.4590241817329956

Epoch: 5| Step: 2
Training loss: 0.17536988337496648
Validation loss: 2.487321249606133

Epoch: 5| Step: 3
Training loss: 0.27675534006978275
Validation loss: 2.465121431162573

Epoch: 5| Step: 4
Training loss: 0.1768836843057083
Validation loss: 2.500315691386595

Epoch: 5| Step: 5
Training loss: 0.3722812725353082
Validation loss: 2.505409921479824

Epoch: 5| Step: 6
Training loss: 0.34990998881806473
Validation loss: 2.4637581391661394

Epoch: 5| Step: 7
Training loss: 0.28994312690591767
Validation loss: 2.4785328855747206

Epoch: 5| Step: 8
Training loss: 0.2906740603517322
Validation loss: 2.4909201319731307

Epoch: 5| Step: 9
Training loss: 0.40543044392593935
Validation loss: 2.491638146706162

Epoch: 5| Step: 10
Training loss: 0.21942040200470106
Validation loss: 2.4750784151282383

Epoch: 543| Step: 0
Training loss: 0.29351231059116256
Validation loss: 2.4584791523640868

Epoch: 5| Step: 1
Training loss: 0.23823009004290235
Validation loss: 2.4559387494113025

Epoch: 5| Step: 2
Training loss: 0.5321840881757968
Validation loss: 2.447755598233824

Epoch: 5| Step: 3
Training loss: 0.26334645004490764
Validation loss: 2.4481800214337937

Epoch: 5| Step: 4
Training loss: 0.28926086063569134
Validation loss: 2.4461729225198687

Epoch: 5| Step: 5
Training loss: 0.22049401935318838
Validation loss: 2.43311580134299

Epoch: 5| Step: 6
Training loss: 0.13271994731821982
Validation loss: 2.46272703319035

Epoch: 5| Step: 7
Training loss: 0.4247577334357277
Validation loss: 2.4554431967004544

Epoch: 5| Step: 8
Training loss: 0.37123920200198834
Validation loss: 2.438702360650501

Epoch: 5| Step: 9
Training loss: 0.19736277199386437
Validation loss: 2.4273032563611787

Epoch: 5| Step: 10
Training loss: 0.2469563051530072
Validation loss: 2.4320873496065785

Epoch: 544| Step: 0
Training loss: 0.42918731013280365
Validation loss: 2.415182661184023

Epoch: 5| Step: 1
Training loss: 0.2336502791424077
Validation loss: 2.4014906222042547

Epoch: 5| Step: 2
Training loss: 0.32144615715602887
Validation loss: 2.429479934039972

Epoch: 5| Step: 3
Training loss: 0.3484985777006311
Validation loss: 2.4142211241762475

Epoch: 5| Step: 4
Training loss: 0.1218691809194259
Validation loss: 2.408361449575873

Epoch: 5| Step: 5
Training loss: 0.3363112433225203
Validation loss: 2.421019334110756

Epoch: 5| Step: 6
Training loss: 0.37628672303349964
Validation loss: 2.437881228512467

Epoch: 5| Step: 7
Training loss: 0.3811334259788312
Validation loss: 2.4560815423522206

Epoch: 5| Step: 8
Training loss: 0.12228111756983195
Validation loss: 2.4700045042996193

Epoch: 5| Step: 9
Training loss: 0.1909177150870977
Validation loss: 2.462017961146082

Epoch: 5| Step: 10
Training loss: 0.3046350556256942
Validation loss: 2.4803333176057643

Epoch: 545| Step: 0
Training loss: 0.3993548510249057
Validation loss: 2.475500790497626

Epoch: 5| Step: 1
Training loss: 0.5286767853443588
Validation loss: 2.4556416851427056

Epoch: 5| Step: 2
Training loss: 0.24774235332709982
Validation loss: 2.4855366871983904

Epoch: 5| Step: 3
Training loss: 0.1859195880917553
Validation loss: 2.436034087555392

Epoch: 5| Step: 4
Training loss: 0.26560121317551927
Validation loss: 2.433203466200172

Epoch: 5| Step: 5
Training loss: 0.22827392413625588
Validation loss: 2.434335156430775

Epoch: 5| Step: 6
Training loss: 0.31857748692618076
Validation loss: 2.448874265630478

Epoch: 5| Step: 7
Training loss: 0.2637462793557847
Validation loss: 2.4282498558577514

Epoch: 5| Step: 8
Training loss: 0.23435961354931054
Validation loss: 2.441866745045458

Epoch: 5| Step: 9
Training loss: 0.12881051467724125
Validation loss: 2.4485757150477756

Epoch: 5| Step: 10
Training loss: 0.3692965102673096
Validation loss: 2.4489749719679628

Epoch: 546| Step: 0
Training loss: 0.2706081190636817
Validation loss: 2.434303868112665

Epoch: 5| Step: 1
Training loss: 0.1828020047981722
Validation loss: 2.476149798207678

Epoch: 5| Step: 2
Training loss: 0.38732840907350247
Validation loss: 2.4573844474388538

Epoch: 5| Step: 3
Training loss: 0.3953412871000244
Validation loss: 2.424184785265587

Epoch: 5| Step: 4
Training loss: 0.23141374654430555
Validation loss: 2.4162621108216964

Epoch: 5| Step: 5
Training loss: 0.4203070360133454
Validation loss: 2.4855735252426197

Epoch: 5| Step: 6
Training loss: 0.28112054865659936
Validation loss: 2.4410524903311406

Epoch: 5| Step: 7
Training loss: 0.2848960263927487
Validation loss: 2.459807428642288

Epoch: 5| Step: 8
Training loss: 0.28393195191827525
Validation loss: 2.476988513841856

Epoch: 5| Step: 9
Training loss: 0.3249732740123819
Validation loss: 2.4484464855298698

Epoch: 5| Step: 10
Training loss: 0.26285883979173724
Validation loss: 2.4432747543600506

Epoch: 547| Step: 0
Training loss: 0.23117223153662123
Validation loss: 2.427650939475471

Epoch: 5| Step: 1
Training loss: 0.2639941612387297
Validation loss: 2.399259205177703

Epoch: 5| Step: 2
Training loss: 0.4785991984974789
Validation loss: 2.383645670886789

Epoch: 5| Step: 3
Training loss: 0.37669126279808285
Validation loss: 2.370232875949765

Epoch: 5| Step: 4
Training loss: 0.33806691504635267
Validation loss: 2.386564361711572

Epoch: 5| Step: 5
Training loss: 0.40739254576174977
Validation loss: 2.3887128362850576

Epoch: 5| Step: 6
Training loss: 0.19970436374216544
Validation loss: 2.418486356313652

Epoch: 5| Step: 7
Training loss: 0.2956164687863291
Validation loss: 2.4062383699662107

Epoch: 5| Step: 8
Training loss: 0.23440674725728855
Validation loss: 2.4218472810310807

Epoch: 5| Step: 9
Training loss: 0.30101125765972964
Validation loss: 2.4119215172513564

Epoch: 5| Step: 10
Training loss: 0.2402948675520131
Validation loss: 2.4280172557478132

Epoch: 548| Step: 0
Training loss: 0.2962995272091593
Validation loss: 2.419701237474019

Epoch: 5| Step: 1
Training loss: 0.33985813154286254
Validation loss: 2.4262218831110274

Epoch: 5| Step: 2
Training loss: 0.16799262342905147
Validation loss: 2.4219394967670276

Epoch: 5| Step: 3
Training loss: 0.29936668384445625
Validation loss: 2.4338947871651753

Epoch: 5| Step: 4
Training loss: 0.4128291276446233
Validation loss: 2.4182542848369266

Epoch: 5| Step: 5
Training loss: 0.22032885761273097
Validation loss: 2.4272504510708237

Epoch: 5| Step: 6
Training loss: 0.26576086384376496
Validation loss: 2.458380796899992

Epoch: 5| Step: 7
Training loss: 0.45197053709259083
Validation loss: 2.4595042534385336

Epoch: 5| Step: 8
Training loss: 0.23881656674913584
Validation loss: 2.4578415159876497

Epoch: 5| Step: 9
Training loss: 0.35299517853013407
Validation loss: 2.4589866227599857

Epoch: 5| Step: 10
Training loss: 0.353044965839732
Validation loss: 2.445145186992915

Epoch: 549| Step: 0
Training loss: 0.27690160457759916
Validation loss: 2.4963005627674657

Epoch: 5| Step: 1
Training loss: 0.37982192936765047
Validation loss: 2.4728493716728517

Epoch: 5| Step: 2
Training loss: 0.44360600136463024
Validation loss: 2.4637317420678073

Epoch: 5| Step: 3
Training loss: 0.38834585960934387
Validation loss: 2.4620212432463857

Epoch: 5| Step: 4
Training loss: 0.1948844319465715
Validation loss: 2.41021610159834

Epoch: 5| Step: 5
Training loss: 0.2999694818630246
Validation loss: 2.4107737158849214

Epoch: 5| Step: 6
Training loss: 0.19844196382142648
Validation loss: 2.3977275723760867

Epoch: 5| Step: 7
Training loss: 0.23011526381220027
Validation loss: 2.3883346051065604

Epoch: 5| Step: 8
Training loss: 0.39947195962557824
Validation loss: 2.3793291893661386

Epoch: 5| Step: 9
Training loss: 0.35676257502147174
Validation loss: 2.377009225709875

Epoch: 5| Step: 10
Training loss: 0.21931638791879748
Validation loss: 2.3866846934653068

Epoch: 550| Step: 0
Training loss: 0.3210548196289444
Validation loss: 2.3878584334723985

Epoch: 5| Step: 1
Training loss: 0.32334951134564116
Validation loss: 2.383411026613439

Epoch: 5| Step: 2
Training loss: 0.2728069938025354
Validation loss: 2.390636739233519

Epoch: 5| Step: 3
Training loss: 0.3384496221370338
Validation loss: 2.422962625406051

Epoch: 5| Step: 4
Training loss: 0.181236525149795
Validation loss: 2.416754192369853

Epoch: 5| Step: 5
Training loss: 0.36764739029532806
Validation loss: 2.44863427054933

Epoch: 5| Step: 6
Training loss: 0.29292110055621773
Validation loss: 2.4448095052865355

Epoch: 5| Step: 7
Training loss: 0.14701828612640477
Validation loss: 2.4658376229530523

Epoch: 5| Step: 8
Training loss: 0.3339897289181617
Validation loss: 2.4546176979457526

Epoch: 5| Step: 9
Training loss: 0.3754948490198424
Validation loss: 2.4229825718772937

Epoch: 5| Step: 10
Training loss: 0.33331825798435966
Validation loss: 2.4368672544863683

Epoch: 551| Step: 0
Training loss: 0.2181241243940557
Validation loss: 2.4384805974965915

Epoch: 5| Step: 1
Training loss: 0.34761618265439054
Validation loss: 2.4766739035793948

Epoch: 5| Step: 2
Training loss: 0.3340904335140672
Validation loss: 2.4611668477418767

Epoch: 5| Step: 3
Training loss: 0.3262063881894092
Validation loss: 2.464543545212417

Epoch: 5| Step: 4
Training loss: 0.31575356971341756
Validation loss: 2.4402321101349327

Epoch: 5| Step: 5
Training loss: 0.3891834553596765
Validation loss: 2.4649298517187224

Epoch: 5| Step: 6
Training loss: 0.18727678681848892
Validation loss: 2.4618319655359118

Epoch: 5| Step: 7
Training loss: 0.23173940459765624
Validation loss: 2.4427108409552205

Epoch: 5| Step: 8
Training loss: 0.3981486376657524
Validation loss: 2.4345522763811704

Epoch: 5| Step: 9
Training loss: 0.3658708544601525
Validation loss: 2.462762970034717

Epoch: 5| Step: 10
Training loss: 0.21618778135772687
Validation loss: 2.4399360492622892

Epoch: 552| Step: 0
Training loss: 0.38066366008739233
Validation loss: 2.4583322731156216

Epoch: 5| Step: 1
Training loss: 0.2297238499559598
Validation loss: 2.44194316802659

Epoch: 5| Step: 2
Training loss: 0.3140506182268675
Validation loss: 2.4368885181474345

Epoch: 5| Step: 3
Training loss: 0.2131405159959975
Validation loss: 2.4427603278287315

Epoch: 5| Step: 4
Training loss: 0.23898721301066903
Validation loss: 2.453990862110781

Epoch: 5| Step: 5
Training loss: 0.2434937337361842
Validation loss: 2.447452323263432

Epoch: 5| Step: 6
Training loss: 0.22829030821190027
Validation loss: 2.4560720855697515

Epoch: 5| Step: 7
Training loss: 0.3389334600103374
Validation loss: 2.453402533114792

Epoch: 5| Step: 8
Training loss: 0.33060123817926806
Validation loss: 2.4107608201444286

Epoch: 5| Step: 9
Training loss: 0.2792206373401762
Validation loss: 2.4673438636181864

Epoch: 5| Step: 10
Training loss: 0.470531653991392
Validation loss: 2.483364770498557

Epoch: 553| Step: 0
Training loss: 0.3468119946385199
Validation loss: 2.480546569507846

Epoch: 5| Step: 1
Training loss: 0.49189152977008566
Validation loss: 2.482716777862921

Epoch: 5| Step: 2
Training loss: 0.15481068373566825
Validation loss: 2.4501600362239446

Epoch: 5| Step: 3
Training loss: 0.24791717893216292
Validation loss: 2.4774673644715066

Epoch: 5| Step: 4
Training loss: 0.1323774167489532
Validation loss: 2.4889628400436425

Epoch: 5| Step: 5
Training loss: 0.28139294859243325
Validation loss: 2.473193492610656

Epoch: 5| Step: 6
Training loss: 0.3962421899019829
Validation loss: 2.4325867391544187

Epoch: 5| Step: 7
Training loss: 0.1894088477079454
Validation loss: 2.4572855348635767

Epoch: 5| Step: 8
Training loss: 0.36727037914828753
Validation loss: 2.450366274133567

Epoch: 5| Step: 9
Training loss: 0.24475768120541258
Validation loss: 2.4552080788635444

Epoch: 5| Step: 10
Training loss: 0.24518994471186667
Validation loss: 2.4456395317108752

Epoch: 554| Step: 0
Training loss: 0.2517699085582142
Validation loss: 2.4621436243538075

Epoch: 5| Step: 1
Training loss: 0.19153652817867275
Validation loss: 2.4402271945014706

Epoch: 5| Step: 2
Training loss: 0.3116121315332322
Validation loss: 2.440989046804095

Epoch: 5| Step: 3
Training loss: 0.32296388291159833
Validation loss: 2.4063037056077503

Epoch: 5| Step: 4
Training loss: 0.4026435364805908
Validation loss: 2.431541406384958

Epoch: 5| Step: 5
Training loss: 0.2761257316533036
Validation loss: 2.4123905481164276

Epoch: 5| Step: 6
Training loss: 0.2743451177795638
Validation loss: 2.413226427175323

Epoch: 5| Step: 7
Training loss: 0.3715522744172942
Validation loss: 2.452486657820748

Epoch: 5| Step: 8
Training loss: 0.20820928496504074
Validation loss: 2.437612934299225

Epoch: 5| Step: 9
Training loss: 0.3358056452832706
Validation loss: 2.473403070093195

Epoch: 5| Step: 10
Training loss: 0.1849447619929073
Validation loss: 2.4407260403647295

Epoch: 555| Step: 0
Training loss: 0.35332128546788
Validation loss: 2.474441060161563

Epoch: 5| Step: 1
Training loss: 0.3739429118271543
Validation loss: 2.4841659570428565

Epoch: 5| Step: 2
Training loss: 0.21844398858634526
Validation loss: 2.485297236916698

Epoch: 5| Step: 3
Training loss: 0.20673069640432995
Validation loss: 2.4955959002998678

Epoch: 5| Step: 4
Training loss: 0.347056503751077
Validation loss: 2.492446118092676

Epoch: 5| Step: 5
Training loss: 0.3443820734214939
Validation loss: 2.4631207536305446

Epoch: 5| Step: 6
Training loss: 0.20019570327348485
Validation loss: 2.4897426355688324

Epoch: 5| Step: 7
Training loss: 0.2938039192467394
Validation loss: 2.4894913889703174

Epoch: 5| Step: 8
Training loss: 0.19966248106297543
Validation loss: 2.456986356712751

Epoch: 5| Step: 9
Training loss: 0.31292593062682167
Validation loss: 2.441004925957082

Epoch: 5| Step: 10
Training loss: 0.21561399583794696
Validation loss: 2.428098274578315

Epoch: 556| Step: 0
Training loss: 0.34109418298446564
Validation loss: 2.4231633925003915

Epoch: 5| Step: 1
Training loss: 0.15828906185910224
Validation loss: 2.4294909779681526

Epoch: 5| Step: 2
Training loss: 0.256884247620348
Validation loss: 2.421314578227821

Epoch: 5| Step: 3
Training loss: 0.3533615176844148
Validation loss: 2.42654303678601

Epoch: 5| Step: 4
Training loss: 0.2679400398066392
Validation loss: 2.432454485927848

Epoch: 5| Step: 5
Training loss: 0.3363338726939334
Validation loss: 2.4534018204705585

Epoch: 5| Step: 6
Training loss: 0.2767756244362944
Validation loss: 2.428224148578109

Epoch: 5| Step: 7
Training loss: 0.3000485549813774
Validation loss: 2.453302580127177

Epoch: 5| Step: 8
Training loss: 0.41537300587628034
Validation loss: 2.4391000259078446

Epoch: 5| Step: 9
Training loss: 0.16256194538739027
Validation loss: 2.4657369471911323

Epoch: 5| Step: 10
Training loss: 0.2684020562358949
Validation loss: 2.451307918726545

Epoch: 557| Step: 0
Training loss: 0.3134717851791712
Validation loss: 2.467713011147803

Epoch: 5| Step: 1
Training loss: 0.2501725257186999
Validation loss: 2.4774390868003393

Epoch: 5| Step: 2
Training loss: 0.326758605080491
Validation loss: 2.4635839673062203

Epoch: 5| Step: 3
Training loss: 0.29223268230971694
Validation loss: 2.4667478983983324

Epoch: 5| Step: 4
Training loss: 0.17821590463051512
Validation loss: 2.4660726504915176

Epoch: 5| Step: 5
Training loss: 0.15042588204617696
Validation loss: 2.4771127655917238

Epoch: 5| Step: 6
Training loss: 0.2825957394932424
Validation loss: 2.4905600927809712

Epoch: 5| Step: 7
Training loss: 0.17720514670469079
Validation loss: 2.4989545748756057

Epoch: 5| Step: 8
Training loss: 0.49708249839729646
Validation loss: 2.4921962179702106

Epoch: 5| Step: 9
Training loss: 0.33948425483850725
Validation loss: 2.4556372597077933

Epoch: 5| Step: 10
Training loss: 0.26718702762405844
Validation loss: 2.474932471790055

Epoch: 558| Step: 0
Training loss: 0.2630886833880227
Validation loss: 2.466479047071459

Epoch: 5| Step: 1
Training loss: 0.248333217518948
Validation loss: 2.4637599309765847

Epoch: 5| Step: 2
Training loss: 0.2811160563364624
Validation loss: 2.4369874672525604

Epoch: 5| Step: 3
Training loss: 0.321875573129977
Validation loss: 2.434358429160269

Epoch: 5| Step: 4
Training loss: 0.34202025607142594
Validation loss: 2.4606381855594703

Epoch: 5| Step: 5
Training loss: 0.37849917617189155
Validation loss: 2.4480127117207098

Epoch: 5| Step: 6
Training loss: 0.3053774236176136
Validation loss: 2.4206416265339663

Epoch: 5| Step: 7
Training loss: 0.29809621549994997
Validation loss: 2.457053323849349

Epoch: 5| Step: 8
Training loss: 0.3361496144805041
Validation loss: 2.4585231987861587

Epoch: 5| Step: 9
Training loss: 0.20644249963783912
Validation loss: 2.4633296946555134

Epoch: 5| Step: 10
Training loss: 0.1676728781002797
Validation loss: 2.4585168421353347

Epoch: 559| Step: 0
Training loss: 0.340886707998015
Validation loss: 2.473853077400774

Epoch: 5| Step: 1
Training loss: 0.3353729161266373
Validation loss: 2.4739384759301397

Epoch: 5| Step: 2
Training loss: 0.33630114102636505
Validation loss: 2.4335169173249738

Epoch: 5| Step: 3
Training loss: 0.2612436166467137
Validation loss: 2.440346823647141

Epoch: 5| Step: 4
Training loss: 0.35144094909014784
Validation loss: 2.4185764392606695

Epoch: 5| Step: 5
Training loss: 0.2735665970273923
Validation loss: 2.4118555684811693

Epoch: 5| Step: 6
Training loss: 0.22086325887281644
Validation loss: 2.390051411333934

Epoch: 5| Step: 7
Training loss: 0.19785658443061283
Validation loss: 2.4055839014024087

Epoch: 5| Step: 8
Training loss: 0.35958717136758567
Validation loss: 2.431450349806085

Epoch: 5| Step: 9
Training loss: 0.17143798126691354
Validation loss: 2.395858082012597

Epoch: 5| Step: 10
Training loss: 0.3776552450776688
Validation loss: 2.4038759571875157

Epoch: 560| Step: 0
Training loss: 0.35157968691034786
Validation loss: 2.412388780850368

Epoch: 5| Step: 1
Training loss: 0.37613609199231235
Validation loss: 2.4242012826291854

Epoch: 5| Step: 2
Training loss: 0.19414623144946552
Validation loss: 2.431354148526341

Epoch: 5| Step: 3
Training loss: 0.3011000912587
Validation loss: 2.4399988109646915

Epoch: 5| Step: 4
Training loss: 0.23060821903760184
Validation loss: 2.4259949117230675

Epoch: 5| Step: 5
Training loss: 0.2906341356461815
Validation loss: 2.423047945888871

Epoch: 5| Step: 6
Training loss: 0.4648185210233596
Validation loss: 2.3885128721036533

Epoch: 5| Step: 7
Training loss: 0.37209061694874573
Validation loss: 2.3930995197755602

Epoch: 5| Step: 8
Training loss: 0.2540457122436394
Validation loss: 2.386162765098674

Epoch: 5| Step: 9
Training loss: 0.23216697595742988
Validation loss: 2.400737268999073

Epoch: 5| Step: 10
Training loss: 0.202027206188661
Validation loss: 2.4107090004092955

Epoch: 561| Step: 0
Training loss: 0.33843324343328435
Validation loss: 2.437874669764664

Epoch: 5| Step: 1
Training loss: 0.3604968638673892
Validation loss: 2.4368676353186993

Epoch: 5| Step: 2
Training loss: 0.1958440128840217
Validation loss: 2.490175049099456

Epoch: 5| Step: 3
Training loss: 0.34270789669128865
Validation loss: 2.537503420717698

Epoch: 5| Step: 4
Training loss: 0.26369337771298723
Validation loss: 2.522745288249633

Epoch: 5| Step: 5
Training loss: 0.34944846003672453
Validation loss: 2.513043360880413

Epoch: 5| Step: 6
Training loss: 0.25456530793325105
Validation loss: 2.5031750277955127

Epoch: 5| Step: 7
Training loss: 0.20497330302761863
Validation loss: 2.5223599371441403

Epoch: 5| Step: 8
Training loss: 0.3897109017461684
Validation loss: 2.4934724394879

Epoch: 5| Step: 9
Training loss: 0.21896886945546745
Validation loss: 2.4963042126373147

Epoch: 5| Step: 10
Training loss: 0.24007914730689794
Validation loss: 2.464475643067365

Epoch: 562| Step: 0
Training loss: 0.3251514806218923
Validation loss: 2.4584674378016564

Epoch: 5| Step: 1
Training loss: 0.28478271370307223
Validation loss: 2.4352860515396335

Epoch: 5| Step: 2
Training loss: 0.23884066592786643
Validation loss: 2.4297994300276313

Epoch: 5| Step: 3
Training loss: 0.411838315797495
Validation loss: 2.401198765162408

Epoch: 5| Step: 4
Training loss: 0.14530156386661766
Validation loss: 2.369210186602678

Epoch: 5| Step: 5
Training loss: 0.28590016460040363
Validation loss: 2.406063483320417

Epoch: 5| Step: 6
Training loss: 0.40594768279403665
Validation loss: 2.4008582406377346

Epoch: 5| Step: 7
Training loss: 0.23765960494111815
Validation loss: 2.3659249264156297

Epoch: 5| Step: 8
Training loss: 0.26602095656016556
Validation loss: 2.371387762481891

Epoch: 5| Step: 9
Training loss: 0.18923734390856595
Validation loss: 2.373185502508467

Epoch: 5| Step: 10
Training loss: 0.32982916161366455
Validation loss: 2.4113353789241008

Epoch: 563| Step: 0
Training loss: 0.3073028654008367
Validation loss: 2.4131407307529926

Epoch: 5| Step: 1
Training loss: 0.3127580769133999
Validation loss: 2.464026554911988

Epoch: 5| Step: 2
Training loss: 0.17559372117693534
Validation loss: 2.4308348696101687

Epoch: 5| Step: 3
Training loss: 0.2914607976223481
Validation loss: 2.43922688450783

Epoch: 5| Step: 4
Training loss: 0.21857795591468496
Validation loss: 2.4607197045491493

Epoch: 5| Step: 5
Training loss: 0.32332974080829713
Validation loss: 2.4559272993538896

Epoch: 5| Step: 6
Training loss: 0.16470792946784876
Validation loss: 2.4523922121172275

Epoch: 5| Step: 7
Training loss: 0.32559781753660344
Validation loss: 2.4464205563039343

Epoch: 5| Step: 8
Training loss: 0.4058376016366254
Validation loss: 2.426812896034035

Epoch: 5| Step: 9
Training loss: 0.24207934918109789
Validation loss: 2.430091590331791

Epoch: 5| Step: 10
Training loss: 0.24616565864774576
Validation loss: 2.4116200238037804

Epoch: 564| Step: 0
Training loss: 0.27644425251126736
Validation loss: 2.4103294463631446

Epoch: 5| Step: 1
Training loss: 0.30238952684456843
Validation loss: 2.416039483775776

Epoch: 5| Step: 2
Training loss: 0.23568033862456317
Validation loss: 2.446848378371712

Epoch: 5| Step: 3
Training loss: 0.3005435797260562
Validation loss: 2.44985349523499

Epoch: 5| Step: 4
Training loss: 0.23546137167262374
Validation loss: 2.461496556136868

Epoch: 5| Step: 5
Training loss: 0.2529211595194875
Validation loss: 2.47642392534602

Epoch: 5| Step: 6
Training loss: 0.27607692937124095
Validation loss: 2.5121679085435775

Epoch: 5| Step: 7
Training loss: 0.33627149701090886
Validation loss: 2.5049284296240324

Epoch: 5| Step: 8
Training loss: 0.15156415613980312
Validation loss: 2.494674857314368

Epoch: 5| Step: 9
Training loss: 0.33373725404224885
Validation loss: 2.5099073729194594

Epoch: 5| Step: 10
Training loss: 0.45852051691203866
Validation loss: 2.478209884744202

Epoch: 565| Step: 0
Training loss: 0.4556280587071442
Validation loss: 2.4720814051321867

Epoch: 5| Step: 1
Training loss: 0.18738650821097358
Validation loss: 2.4568988173474064

Epoch: 5| Step: 2
Training loss: 0.1982410130207618
Validation loss: 2.425318145814512

Epoch: 5| Step: 3
Training loss: 0.20751086946249758
Validation loss: 2.4187401782395486

Epoch: 5| Step: 4
Training loss: 0.28450675050272406
Validation loss: 2.4108202792303755

Epoch: 5| Step: 5
Training loss: 0.2019896136732008
Validation loss: 2.4128464127622276

Epoch: 5| Step: 6
Training loss: 0.25413324039869656
Validation loss: 2.4096878917512266

Epoch: 5| Step: 7
Training loss: 0.3737567917260923
Validation loss: 2.4664146891065974

Epoch: 5| Step: 8
Training loss: 0.2450507556515819
Validation loss: 2.4700211564602275

Epoch: 5| Step: 9
Training loss: 0.21645610248883487
Validation loss: 2.455943670132494

Epoch: 5| Step: 10
Training loss: 0.4407590662131426
Validation loss: 2.469293560741227

Epoch: 566| Step: 0
Training loss: 0.10596810999316768
Validation loss: 2.473740598534529

Epoch: 5| Step: 1
Training loss: 0.4236144305014016
Validation loss: 2.4909057988584027

Epoch: 5| Step: 2
Training loss: 0.20281368938561636
Validation loss: 2.47224084966092

Epoch: 5| Step: 3
Training loss: 0.37120514251896775
Validation loss: 2.4665751859163456

Epoch: 5| Step: 4
Training loss: 0.2046906853202316
Validation loss: 2.4727022542935937

Epoch: 5| Step: 5
Training loss: 0.24603173821874588
Validation loss: 2.455753073187034

Epoch: 5| Step: 6
Training loss: 0.2862106842210663
Validation loss: 2.447683028829575

Epoch: 5| Step: 7
Training loss: 0.34548410924121725
Validation loss: 2.449357032159542

Epoch: 5| Step: 8
Training loss: 0.3581150608114856
Validation loss: 2.3932629643949497

Epoch: 5| Step: 9
Training loss: 0.21907639845756843
Validation loss: 2.40660790822182

Epoch: 5| Step: 10
Training loss: 0.18159083227407596
Validation loss: 2.4114560937181158

Epoch: 567| Step: 0
Training loss: 0.40781374890951044
Validation loss: 2.4110834367202014

Epoch: 5| Step: 1
Training loss: 0.34163277092521455
Validation loss: 2.408534017150295

Epoch: 5| Step: 2
Training loss: 0.3030296485412458
Validation loss: 2.4391937891741673

Epoch: 5| Step: 3
Training loss: 0.2678341858540086
Validation loss: 2.445226134221477

Epoch: 5| Step: 4
Training loss: 0.31321493859680527
Validation loss: 2.4221670132830657

Epoch: 5| Step: 5
Training loss: 0.20377629658903482
Validation loss: 2.4449027688380616

Epoch: 5| Step: 6
Training loss: 0.22285633968010513
Validation loss: 2.451836909274127

Epoch: 5| Step: 7
Training loss: 0.12401520709264993
Validation loss: 2.414192846904708

Epoch: 5| Step: 8
Training loss: 0.2107375751658821
Validation loss: 2.4137520969361557

Epoch: 5| Step: 9
Training loss: 0.18836232414452572
Validation loss: 2.4215018883095

Epoch: 5| Step: 10
Training loss: 0.3729052649340881
Validation loss: 2.4462189689859324

Epoch: 568| Step: 0
Training loss: 0.3308220104750956
Validation loss: 2.4138655597635905

Epoch: 5| Step: 1
Training loss: 0.3441127791813794
Validation loss: 2.426749112983977

Epoch: 5| Step: 2
Training loss: 0.23789128458467193
Validation loss: 2.400728258950897

Epoch: 5| Step: 3
Training loss: 0.18745658292360853
Validation loss: 2.429569316029121

Epoch: 5| Step: 4
Training loss: 0.24855274520419685
Validation loss: 2.4271535520409815

Epoch: 5| Step: 5
Training loss: 0.33620245044270225
Validation loss: 2.426968429516461

Epoch: 5| Step: 6
Training loss: 0.28525941106231184
Validation loss: 2.4190012182882525

Epoch: 5| Step: 7
Training loss: 0.17420031317418302
Validation loss: 2.462137913238885

Epoch: 5| Step: 8
Training loss: 0.23860452953637332
Validation loss: 2.4332515534101735

Epoch: 5| Step: 9
Training loss: 0.32420489270114755
Validation loss: 2.448757719569749

Epoch: 5| Step: 10
Training loss: 0.22220599509305503
Validation loss: 2.4480491782099887

Epoch: 569| Step: 0
Training loss: 0.2837959792783489
Validation loss: 2.45682125053951

Epoch: 5| Step: 1
Training loss: 0.16274960609137862
Validation loss: 2.4429838474398156

Epoch: 5| Step: 2
Training loss: 0.15366641542542758
Validation loss: 2.4700810956286032

Epoch: 5| Step: 3
Training loss: 0.2903529308814941
Validation loss: 2.4335326139992004

Epoch: 5| Step: 4
Training loss: 0.26591652412036154
Validation loss: 2.443703976922086

Epoch: 5| Step: 5
Training loss: 0.22228615101195415
Validation loss: 2.4516997093859825

Epoch: 5| Step: 6
Training loss: 0.3958345170588947
Validation loss: 2.419767457648478

Epoch: 5| Step: 7
Training loss: 0.28845350448412344
Validation loss: 2.435321085348747

Epoch: 5| Step: 8
Training loss: 0.3198108000524688
Validation loss: 2.4132800141778343

Epoch: 5| Step: 9
Training loss: 0.3121332519908547
Validation loss: 2.3916931918643014

Epoch: 5| Step: 10
Training loss: 0.1644183228516951
Validation loss: 2.393290453128596

Epoch: 570| Step: 0
Training loss: 0.2233058004449965
Validation loss: 2.4067241114791487

Epoch: 5| Step: 1
Training loss: 0.17187073550569204
Validation loss: 2.3871267397079805

Epoch: 5| Step: 2
Training loss: 0.22506713660288663
Validation loss: 2.4246188072733332

Epoch: 5| Step: 3
Training loss: 0.40937217973509316
Validation loss: 2.3942291171400254

Epoch: 5| Step: 4
Training loss: 0.20890348419778063
Validation loss: 2.4137744226583493

Epoch: 5| Step: 5
Training loss: 0.3226178411940642
Validation loss: 2.4289831037229437

Epoch: 5| Step: 6
Training loss: 0.253514280741791
Validation loss: 2.410203043059181

Epoch: 5| Step: 7
Training loss: 0.25040224616685547
Validation loss: 2.4129648218934645

Epoch: 5| Step: 8
Training loss: 0.2324577271834837
Validation loss: 2.416750967601378

Epoch: 5| Step: 9
Training loss: 0.33475397906527465
Validation loss: 2.4071669890860976

Epoch: 5| Step: 10
Training loss: 0.16674321559983515
Validation loss: 2.434521097210206

Epoch: 571| Step: 0
Training loss: 0.2930214262336042
Validation loss: 2.401580792906343

Epoch: 5| Step: 1
Training loss: 0.27764324350972286
Validation loss: 2.426357953264295

Epoch: 5| Step: 2
Training loss: 0.29359898489953956
Validation loss: 2.4110391679933487

Epoch: 5| Step: 3
Training loss: 0.24698451214710096
Validation loss: 2.4021552790208873

Epoch: 5| Step: 4
Training loss: 0.1850900547792899
Validation loss: 2.444805800560581

Epoch: 5| Step: 5
Training loss: 0.28925330076749417
Validation loss: 2.423232329547719

Epoch: 5| Step: 6
Training loss: 0.32315894492759156
Validation loss: 2.427205435783248

Epoch: 5| Step: 7
Training loss: 0.2874229949987416
Validation loss: 2.4575399603237362

Epoch: 5| Step: 8
Training loss: 0.22276121308995467
Validation loss: 2.426191008451668

Epoch: 5| Step: 9
Training loss: 0.2576822761174538
Validation loss: 2.4378228427328366

Epoch: 5| Step: 10
Training loss: 0.15081343109746126
Validation loss: 2.4466313332170726

Epoch: 572| Step: 0
Training loss: 0.28166827252643134
Validation loss: 2.4321000819347103

Epoch: 5| Step: 1
Training loss: 0.31450711847051477
Validation loss: 2.4388724975781986

Epoch: 5| Step: 2
Training loss: 0.2244312409282675
Validation loss: 2.456553051440791

Epoch: 5| Step: 3
Training loss: 0.15743537329077456
Validation loss: 2.4390709796899563

Epoch: 5| Step: 4
Training loss: 0.3626823410648062
Validation loss: 2.427508033994381

Epoch: 5| Step: 5
Training loss: 0.22277930690599176
Validation loss: 2.447800752980059

Epoch: 5| Step: 6
Training loss: 0.34453149306792596
Validation loss: 2.437151213692588

Epoch: 5| Step: 7
Training loss: 0.14429259572192213
Validation loss: 2.440958043325293

Epoch: 5| Step: 8
Training loss: 0.31120189227939166
Validation loss: 2.4398543475692556

Epoch: 5| Step: 9
Training loss: 0.22391078780661125
Validation loss: 2.419103397135202

Epoch: 5| Step: 10
Training loss: 0.10364415178979616
Validation loss: 2.399756961654736

Epoch: 573| Step: 0
Training loss: 0.2558774577732318
Validation loss: 2.391155366659706

Epoch: 5| Step: 1
Training loss: 0.3086228658726736
Validation loss: 2.416513421868554

Epoch: 5| Step: 2
Training loss: 0.26032427897370397
Validation loss: 2.3905778902095545

Epoch: 5| Step: 3
Training loss: 0.15508415873437867
Validation loss: 2.387264462619961

Epoch: 5| Step: 4
Training loss: 0.2653231307956375
Validation loss: 2.430356496539976

Epoch: 5| Step: 5
Training loss: 0.35326729793743844
Validation loss: 2.4148552013871525

Epoch: 5| Step: 6
Training loss: 0.18772827597310038
Validation loss: 2.435617712454999

Epoch: 5| Step: 7
Training loss: 0.29686674307333116
Validation loss: 2.4585869750217957

Epoch: 5| Step: 8
Training loss: 0.25935757647442936
Validation loss: 2.4457853986290004

Epoch: 5| Step: 9
Training loss: 0.29878915270817585
Validation loss: 2.4151493265930584

Epoch: 5| Step: 10
Training loss: 0.1532968454564091
Validation loss: 2.456811141297102

Epoch: 574| Step: 0
Training loss: 0.3486557854101141
Validation loss: 2.4291282215607035

Epoch: 5| Step: 1
Training loss: 0.20185625457241607
Validation loss: 2.4375747467267397

Epoch: 5| Step: 2
Training loss: 0.15517111471756403
Validation loss: 2.4247409954144885

Epoch: 5| Step: 3
Training loss: 0.24543567498987867
Validation loss: 2.440534248674765

Epoch: 5| Step: 4
Training loss: 0.24286427843005332
Validation loss: 2.453243502781427

Epoch: 5| Step: 5
Training loss: 0.29306468664400165
Validation loss: 2.432522713340649

Epoch: 5| Step: 6
Training loss: 0.2693591190179586
Validation loss: 2.4365707910725063

Epoch: 5| Step: 7
Training loss: 0.13948900952507326
Validation loss: 2.445714847284186

Epoch: 5| Step: 8
Training loss: 0.22302723813173456
Validation loss: 2.4704823457693155

Epoch: 5| Step: 9
Training loss: 0.27861350160116044
Validation loss: 2.4622067674733374

Epoch: 5| Step: 10
Training loss: 0.3088311597972691
Validation loss: 2.475430385971644

Epoch: 575| Step: 0
Training loss: 0.14907123154232493
Validation loss: 2.4573890397750446

Epoch: 5| Step: 1
Training loss: 0.1859969953510929
Validation loss: 2.4362096955187105

Epoch: 5| Step: 2
Training loss: 0.364627231498222
Validation loss: 2.433399318624135

Epoch: 5| Step: 3
Training loss: 0.1297490643102795
Validation loss: 2.4303710195529007

Epoch: 5| Step: 4
Training loss: 0.40412160050283547
Validation loss: 2.4374772126778916

Epoch: 5| Step: 5
Training loss: 0.2649080192882138
Validation loss: 2.429283052241722

Epoch: 5| Step: 6
Training loss: 0.1965379228676775
Validation loss: 2.435005072266051

Epoch: 5| Step: 7
Training loss: 0.15522410250782295
Validation loss: 2.4263896705239603

Epoch: 5| Step: 8
Training loss: 0.21218190647893284
Validation loss: 2.4634332390835523

Epoch: 5| Step: 9
Training loss: 0.14666668673017574
Validation loss: 2.4641512157644327

Epoch: 5| Step: 10
Training loss: 0.37513863464587577
Validation loss: 2.4530479811478476

Epoch: 576| Step: 0
Training loss: 0.1828046234585922
Validation loss: 2.4778756457776723

Epoch: 5| Step: 1
Training loss: 0.19190473262470864
Validation loss: 2.4368670146250904

Epoch: 5| Step: 2
Training loss: 0.14485790095084897
Validation loss: 2.404395635588122

Epoch: 5| Step: 3
Training loss: 0.11750238551853208
Validation loss: 2.452079156549744

Epoch: 5| Step: 4
Training loss: 0.22317777590531052
Validation loss: 2.445401791299954

Epoch: 5| Step: 5
Training loss: 0.27966692225448725
Validation loss: 2.413875409174902

Epoch: 5| Step: 6
Training loss: 0.3426027443542061
Validation loss: 2.4063371041402646

Epoch: 5| Step: 7
Training loss: 0.4521119203919377
Validation loss: 2.4198501023931147

Epoch: 5| Step: 8
Training loss: 0.24156430264746626
Validation loss: 2.4520241016443736

Epoch: 5| Step: 9
Training loss: 0.235207184949819
Validation loss: 2.4352547659642116

Epoch: 5| Step: 10
Training loss: 0.2544907664261531
Validation loss: 2.443208661365866

Epoch: 577| Step: 0
Training loss: 0.35588324139119726
Validation loss: 2.4192746283794833

Epoch: 5| Step: 1
Training loss: 0.21761961495136567
Validation loss: 2.460945710407604

Epoch: 5| Step: 2
Training loss: 0.14161217748383176
Validation loss: 2.454014629561

Epoch: 5| Step: 3
Training loss: 0.20903737296365352
Validation loss: 2.440572676181063

Epoch: 5| Step: 4
Training loss: 0.2927542727905398
Validation loss: 2.4285622504836355

Epoch: 5| Step: 5
Training loss: 0.35414436447757813
Validation loss: 2.4148777085303537

Epoch: 5| Step: 6
Training loss: 0.20376912106268208
Validation loss: 2.3650532596538936

Epoch: 5| Step: 7
Training loss: 0.34647035323094033
Validation loss: 2.3847725383624105

Epoch: 5| Step: 8
Training loss: 0.1569433208078861
Validation loss: 2.392931420813915

Epoch: 5| Step: 9
Training loss: 0.19564949526700984
Validation loss: 2.3690375400058463

Epoch: 5| Step: 10
Training loss: 0.29214050200582625
Validation loss: 2.398786347273882

Epoch: 578| Step: 0
Training loss: 0.2905758088022591
Validation loss: 2.401351243207848

Epoch: 5| Step: 1
Training loss: 0.27103102175407073
Validation loss: 2.4230925173459683

Epoch: 5| Step: 2
Training loss: 0.2698742991584558
Validation loss: 2.414725441242949

Epoch: 5| Step: 3
Training loss: 0.34017706562462746
Validation loss: 2.422336567464989

Epoch: 5| Step: 4
Training loss: 0.2022006018224508
Validation loss: 2.436320513558218

Epoch: 5| Step: 5
Training loss: 0.20392127949948718
Validation loss: 2.465969439886478

Epoch: 5| Step: 6
Training loss: 0.19918199274884074
Validation loss: 2.4427802711132096

Epoch: 5| Step: 7
Training loss: 0.20927335243139347
Validation loss: 2.4490486671209624

Epoch: 5| Step: 8
Training loss: 0.2826339395088679
Validation loss: 2.437456868402466

Epoch: 5| Step: 9
Training loss: 0.13146194817529772
Validation loss: 2.435055634841166

Epoch: 5| Step: 10
Training loss: 0.3855655507180197
Validation loss: 2.443249293963683

Epoch: 579| Step: 0
Training loss: 0.2521123604705574
Validation loss: 2.415843092033861

Epoch: 5| Step: 1
Training loss: 0.2507730542088515
Validation loss: 2.392778680501835

Epoch: 5| Step: 2
Training loss: 0.18106286648708936
Validation loss: 2.4121026940975834

Epoch: 5| Step: 3
Training loss: 0.39624551803629326
Validation loss: 2.4091365351827814

Epoch: 5| Step: 4
Training loss: 0.23468275527627802
Validation loss: 2.4359358256339263

Epoch: 5| Step: 5
Training loss: 0.2881428290620476
Validation loss: 2.3897512652749655

Epoch: 5| Step: 6
Training loss: 0.1216933074419145
Validation loss: 2.436509693996487

Epoch: 5| Step: 7
Training loss: 0.29384555581363636
Validation loss: 2.4182890946989715

Epoch: 5| Step: 8
Training loss: 0.32157018357597755
Validation loss: 2.425094605860572

Epoch: 5| Step: 9
Training loss: 0.11199588198068168
Validation loss: 2.433990352969135

Epoch: 5| Step: 10
Training loss: 0.16049420938525977
Validation loss: 2.3977859936008574

Epoch: 580| Step: 0
Training loss: 0.19089466938181707
Validation loss: 2.4063084827907684

Epoch: 5| Step: 1
Training loss: 0.2976098377358172
Validation loss: 2.4076795312280193

Epoch: 5| Step: 2
Training loss: 0.2150344002726742
Validation loss: 2.4231248206259264

Epoch: 5| Step: 3
Training loss: 0.22433113611109115
Validation loss: 2.4040635516051188

Epoch: 5| Step: 4
Training loss: 0.20851462145635685
Validation loss: 2.420543140102306

Epoch: 5| Step: 5
Training loss: 0.23445428460917078
Validation loss: 2.421582305719097

Epoch: 5| Step: 6
Training loss: 0.2008305960253663
Validation loss: 2.4129516008008167

Epoch: 5| Step: 7
Training loss: 0.42631338271925046
Validation loss: 2.421396646618511

Epoch: 5| Step: 8
Training loss: 0.244631540737319
Validation loss: 2.4117886219120894

Epoch: 5| Step: 9
Training loss: 0.19276844624992398
Validation loss: 2.4350363684192597

Epoch: 5| Step: 10
Training loss: 0.23613445764162588
Validation loss: 2.3959976061501678

Epoch: 581| Step: 0
Training loss: 0.17663497239204126
Validation loss: 2.429906432102797

Epoch: 5| Step: 1
Training loss: 0.40519432306789455
Validation loss: 2.399691870822129

Epoch: 5| Step: 2
Training loss: 0.17357344132609115
Validation loss: 2.3879915301092565

Epoch: 5| Step: 3
Training loss: 0.1474280668089435
Validation loss: 2.407376870774229

Epoch: 5| Step: 4
Training loss: 0.24161243614700376
Validation loss: 2.3951163832732334

Epoch: 5| Step: 5
Training loss: 0.22999986538416614
Validation loss: 2.398323425399862

Epoch: 5| Step: 6
Training loss: 0.20774505029731216
Validation loss: 2.3890249259572216

Epoch: 5| Step: 7
Training loss: 0.3694392212679368
Validation loss: 2.4091294209140277

Epoch: 5| Step: 8
Training loss: 0.21151077112823996
Validation loss: 2.4112448404574263

Epoch: 5| Step: 9
Training loss: 0.2245081963912008
Validation loss: 2.422193051035188

Epoch: 5| Step: 10
Training loss: 0.22306121005141968
Validation loss: 2.4194497849691987

Epoch: 582| Step: 0
Training loss: 0.15976025308844094
Validation loss: 2.438053582546983

Epoch: 5| Step: 1
Training loss: 0.35972097577468637
Validation loss: 2.4212479450783935

Epoch: 5| Step: 2
Training loss: 0.2312236239237572
Validation loss: 2.444567958617373

Epoch: 5| Step: 3
Training loss: 0.3150566067809437
Validation loss: 2.3979842597561634

Epoch: 5| Step: 4
Training loss: 0.15265397738792505
Validation loss: 2.404606381793154

Epoch: 5| Step: 5
Training loss: 0.19284453390231343
Validation loss: 2.4305179504751275

Epoch: 5| Step: 6
Training loss: 0.24979706812998043
Validation loss: 2.4217461135235805

Epoch: 5| Step: 7
Training loss: 0.3072759885613931
Validation loss: 2.41695136181511

Epoch: 5| Step: 8
Training loss: 0.25990855078202285
Validation loss: 2.4394749927196617

Epoch: 5| Step: 9
Training loss: 0.19133528542194306
Validation loss: 2.4128707979939583

Epoch: 5| Step: 10
Training loss: 0.14054791006414288
Validation loss: 2.3917199842308166

Epoch: 583| Step: 0
Training loss: 0.28409003452686593
Validation loss: 2.401530644818165

Epoch: 5| Step: 1
Training loss: 0.3395500887451483
Validation loss: 2.399805056736999

Epoch: 5| Step: 2
Training loss: 0.1666593916368173
Validation loss: 2.3631658482679443

Epoch: 5| Step: 3
Training loss: 0.2911017117765465
Validation loss: 2.3881441321732453

Epoch: 5| Step: 4
Training loss: 0.1625183072231443
Validation loss: 2.412707054897028

Epoch: 5| Step: 5
Training loss: 0.16235431298081632
Validation loss: 2.3864153970695527

Epoch: 5| Step: 6
Training loss: 0.30462095560982266
Validation loss: 2.4199131058847536

Epoch: 5| Step: 7
Training loss: 0.1843076582952137
Validation loss: 2.435915230635017

Epoch: 5| Step: 8
Training loss: 0.20664840063454082
Validation loss: 2.4384565083206984

Epoch: 5| Step: 9
Training loss: 0.07638675690184
Validation loss: 2.4391772923137434

Epoch: 5| Step: 10
Training loss: 0.33974128581584495
Validation loss: 2.4428112976411875

Epoch: 584| Step: 0
Training loss: 0.3167819394731352
Validation loss: 2.444568184089817

Epoch: 5| Step: 1
Training loss: 0.13241426282850993
Validation loss: 2.4119121583649132

Epoch: 5| Step: 2
Training loss: 0.15267926341352547
Validation loss: 2.4042291410858883

Epoch: 5| Step: 3
Training loss: 0.25467012381225107
Validation loss: 2.402611686810884

Epoch: 5| Step: 4
Training loss: 0.24473584668205858
Validation loss: 2.4038153814234575

Epoch: 5| Step: 5
Training loss: 0.24837788700351482
Validation loss: 2.408806039761213

Epoch: 5| Step: 6
Training loss: 0.2808289820497174
Validation loss: 2.400422350020522

Epoch: 5| Step: 7
Training loss: 0.28510364935682475
Validation loss: 2.393438221888532

Epoch: 5| Step: 8
Training loss: 0.2087950517385977
Validation loss: 2.391508903743964

Epoch: 5| Step: 9
Training loss: 0.2956666573697755
Validation loss: 2.398177119650675

Epoch: 5| Step: 10
Training loss: 0.2287675251657441
Validation loss: 2.4259414761286937

Epoch: 585| Step: 0
Training loss: 0.3536338397741909
Validation loss: 2.439001549051186

Epoch: 5| Step: 1
Training loss: 0.14855883056657057
Validation loss: 2.4246567516509496

Epoch: 5| Step: 2
Training loss: 0.3128100049646283
Validation loss: 2.433068132916331

Epoch: 5| Step: 3
Training loss: 0.18914456162891957
Validation loss: 2.462804204243595

Epoch: 5| Step: 4
Training loss: 0.147717391832813
Validation loss: 2.4375501742693038

Epoch: 5| Step: 5
Training loss: 0.1485614698127171
Validation loss: 2.444331506279505

Epoch: 5| Step: 6
Training loss: 0.177043494249755
Validation loss: 2.4458525183671656

Epoch: 5| Step: 7
Training loss: 0.4040167939488995
Validation loss: 2.4041684686538813

Epoch: 5| Step: 8
Training loss: 0.29038953317555494
Validation loss: 2.4011388286605757

Epoch: 5| Step: 9
Training loss: 0.21751229062376945
Validation loss: 2.4007957072171564

Epoch: 5| Step: 10
Training loss: 0.19798627787842096
Validation loss: 2.389843640324786

Epoch: 586| Step: 0
Training loss: 0.19785443800016256
Validation loss: 2.398538473850407

Epoch: 5| Step: 1
Training loss: 0.11666185187795634
Validation loss: 2.384440821652751

Epoch: 5| Step: 2
Training loss: 0.21595947819003417
Validation loss: 2.4259789876882163

Epoch: 5| Step: 3
Training loss: 0.27165529647584324
Validation loss: 2.4372728839889617

Epoch: 5| Step: 4
Training loss: 0.39131936348131335
Validation loss: 2.4578333828265815

Epoch: 5| Step: 5
Training loss: 0.1939315614310495
Validation loss: 2.4639178382591074

Epoch: 5| Step: 6
Training loss: 0.3023308926196945
Validation loss: 2.4406801066459383

Epoch: 5| Step: 7
Training loss: 0.1799748445191992
Validation loss: 2.463854609968526

Epoch: 5| Step: 8
Training loss: 0.3194114525776876
Validation loss: 2.433287363493293

Epoch: 5| Step: 9
Training loss: 0.14460885696483217
Validation loss: 2.456462948088712

Epoch: 5| Step: 10
Training loss: 0.2533614696518435
Validation loss: 2.4318418110296034

Epoch: 587| Step: 0
Training loss: 0.21684052483281835
Validation loss: 2.4608808675989406

Epoch: 5| Step: 1
Training loss: 0.23988818213722796
Validation loss: 2.4269982765402185

Epoch: 5| Step: 2
Training loss: 0.22982984011925153
Validation loss: 2.4226698276085745

Epoch: 5| Step: 3
Training loss: 0.31404286033751394
Validation loss: 2.4220006279675834

Epoch: 5| Step: 4
Training loss: 0.3205046310127424
Validation loss: 2.3917638248581996

Epoch: 5| Step: 5
Training loss: 0.14983714422277752
Validation loss: 2.4215476967055154

Epoch: 5| Step: 6
Training loss: 0.29179890081680354
Validation loss: 2.4019804046057116

Epoch: 5| Step: 7
Training loss: 0.14396162807592722
Validation loss: 2.4088508997492877

Epoch: 5| Step: 8
Training loss: 0.24833552018878566
Validation loss: 2.406046458834042

Epoch: 5| Step: 9
Training loss: 0.2993667585078714
Validation loss: 2.4103041994175203

Epoch: 5| Step: 10
Training loss: 0.22220545861142948
Validation loss: 2.4116911388486493

Epoch: 588| Step: 0
Training loss: 0.17764129926365824
Validation loss: 2.37834636811452

Epoch: 5| Step: 1
Training loss: 0.20156752927553098
Validation loss: 2.3952050857086595

Epoch: 5| Step: 2
Training loss: 0.24381049151401285
Validation loss: 2.4289366809021846

Epoch: 5| Step: 3
Training loss: 0.2795260629444538
Validation loss: 2.4130888080786104

Epoch: 5| Step: 4
Training loss: 0.2246895854200589
Validation loss: 2.4120262269499677

Epoch: 5| Step: 5
Training loss: 0.18133572655768615
Validation loss: 2.3668150428563037

Epoch: 5| Step: 6
Training loss: 0.33560483562909493
Validation loss: 2.4058997761413803

Epoch: 5| Step: 7
Training loss: 0.3045165120135925
Validation loss: 2.4345897026529277

Epoch: 5| Step: 8
Training loss: 0.3028058736723734
Validation loss: 2.4115003096100187

Epoch: 5| Step: 9
Training loss: 0.22842886492250578
Validation loss: 2.447840354077276

Epoch: 5| Step: 10
Training loss: 0.2346555699419751
Validation loss: 2.435299670361186

Epoch: 589| Step: 0
Training loss: 0.16606555636633105
Validation loss: 2.466565820294833

Epoch: 5| Step: 1
Training loss: 0.20638509899004504
Validation loss: 2.4730455928304584

Epoch: 5| Step: 2
Training loss: 0.21496584630702834
Validation loss: 2.451715904229896

Epoch: 5| Step: 3
Training loss: 0.18799685173810032
Validation loss: 2.4501397951653154

Epoch: 5| Step: 4
Training loss: 0.20190822685134768
Validation loss: 2.420651030041177

Epoch: 5| Step: 5
Training loss: 0.3999272898810254
Validation loss: 2.462826991437732

Epoch: 5| Step: 6
Training loss: 0.40473766531477745
Validation loss: 2.4211502615668867

Epoch: 5| Step: 7
Training loss: 0.26347106068199316
Validation loss: 2.4708966550785476

Epoch: 5| Step: 8
Training loss: 0.17118298411392974
Validation loss: 2.4598255526408956

Epoch: 5| Step: 9
Training loss: 0.17112293212273744
Validation loss: 2.4560720834821574

Epoch: 5| Step: 10
Training loss: 0.18071667704085104
Validation loss: 2.433640573297675

Epoch: 590| Step: 0
Training loss: 0.35337694092802135
Validation loss: 2.430262349067143

Epoch: 5| Step: 1
Training loss: 0.3009188696381746
Validation loss: 2.444284264250037

Epoch: 5| Step: 2
Training loss: 0.3229558546632049
Validation loss: 2.440437866581185

Epoch: 5| Step: 3
Training loss: 0.2022136177722782
Validation loss: 2.440576187226952

Epoch: 5| Step: 4
Training loss: 0.15808748210079815
Validation loss: 2.455898032518186

Epoch: 5| Step: 5
Training loss: 0.20911604752904855
Validation loss: 2.425670814467369

Epoch: 5| Step: 6
Training loss: 0.27536252737435213
Validation loss: 2.475436005317023

Epoch: 5| Step: 7
Training loss: 0.1801256042744324
Validation loss: 2.470617902068107

Epoch: 5| Step: 8
Training loss: 0.2409524265939911
Validation loss: 2.492323074101848

Epoch: 5| Step: 9
Training loss: 0.1704056966028649
Validation loss: 2.5286239899013254

Epoch: 5| Step: 10
Training loss: 0.17699624940298292
Validation loss: 2.504104030783265

Epoch: 591| Step: 0
Training loss: 0.3378923559420135
Validation loss: 2.488146163512015

Epoch: 5| Step: 1
Training loss: 0.27187927944279244
Validation loss: 2.506031918099719

Epoch: 5| Step: 2
Training loss: 0.3051990469647073
Validation loss: 2.4912186020320526

Epoch: 5| Step: 3
Training loss: 0.26736245199723213
Validation loss: 2.4964810236469006

Epoch: 5| Step: 4
Training loss: 0.16844475190010236
Validation loss: 2.4776084603330006

Epoch: 5| Step: 5
Training loss: 0.1572128550554664
Validation loss: 2.4389200178716437

Epoch: 5| Step: 6
Training loss: 0.16642846218922835
Validation loss: 2.461159284409357

Epoch: 5| Step: 7
Training loss: 0.24131826568943787
Validation loss: 2.4709214608486896

Epoch: 5| Step: 8
Training loss: 0.21502337316226514
Validation loss: 2.46475137646981

Epoch: 5| Step: 9
Training loss: 0.19828293292366236
Validation loss: 2.4594968835597277

Epoch: 5| Step: 10
Training loss: 0.3073499699687059
Validation loss: 2.430288614438564

Epoch: 592| Step: 0
Training loss: 0.22864470137632376
Validation loss: 2.439154118114364

Epoch: 5| Step: 1
Training loss: 0.2552189419286648
Validation loss: 2.4231817651840646

Epoch: 5| Step: 2
Training loss: 0.25801965309481967
Validation loss: 2.4490226490073486

Epoch: 5| Step: 3
Training loss: 0.22980314250026607
Validation loss: 2.4641415714718886

Epoch: 5| Step: 4
Training loss: 0.20033211104733667
Validation loss: 2.459339414289253

Epoch: 5| Step: 5
Training loss: 0.19760400247407833
Validation loss: 2.463191024994829

Epoch: 5| Step: 6
Training loss: 0.23140910223491615
Validation loss: 2.406975081698074

Epoch: 5| Step: 7
Training loss: 0.12726475541465798
Validation loss: 2.444646952401866

Epoch: 5| Step: 8
Training loss: 0.40084467008715136
Validation loss: 2.4449788513030586

Epoch: 5| Step: 9
Training loss: 0.12716187407580376
Validation loss: 2.4103973385628015

Epoch: 5| Step: 10
Training loss: 0.215906669635064
Validation loss: 2.4096279812845673

Epoch: 593| Step: 0
Training loss: 0.12129198276610068
Validation loss: 2.415363069085003

Epoch: 5| Step: 1
Training loss: 0.33126977105787336
Validation loss: 2.400794345600596

Epoch: 5| Step: 2
Training loss: 0.2680230722335091
Validation loss: 2.3998496085392262

Epoch: 5| Step: 3
Training loss: 0.18957547042247022
Validation loss: 2.4275104080591627

Epoch: 5| Step: 4
Training loss: 0.27803368783940857
Validation loss: 2.4010490054521405

Epoch: 5| Step: 5
Training loss: 0.1798806603517302
Validation loss: 2.376015528607744

Epoch: 5| Step: 6
Training loss: 0.2631523099576476
Validation loss: 2.427732285213303

Epoch: 5| Step: 7
Training loss: 0.16338038560707163
Validation loss: 2.3886135845044643

Epoch: 5| Step: 8
Training loss: 0.2908402753118047
Validation loss: 2.4042388796262397

Epoch: 5| Step: 9
Training loss: 0.15168362427936366
Validation loss: 2.402012497655663

Epoch: 5| Step: 10
Training loss: 0.26035442880138715
Validation loss: 2.4223138459903284

Epoch: 594| Step: 0
Training loss: 0.16651095937517738
Validation loss: 2.408470521733758

Epoch: 5| Step: 1
Training loss: 0.2405384744166597
Validation loss: 2.425265610719365

Epoch: 5| Step: 2
Training loss: 0.20332483402028725
Validation loss: 2.4281495516372216

Epoch: 5| Step: 3
Training loss: 0.13427180885698448
Validation loss: 2.4306027209681065

Epoch: 5| Step: 4
Training loss: 0.2891750245553771
Validation loss: 2.4616889323346927

Epoch: 5| Step: 5
Training loss: 0.36254714297535556
Validation loss: 2.4528155105815643

Epoch: 5| Step: 6
Training loss: 0.25006369435016323
Validation loss: 2.4342959654055267

Epoch: 5| Step: 7
Training loss: 0.23205169883041238
Validation loss: 2.4654411155122045

Epoch: 5| Step: 8
Training loss: 0.27400024272392826
Validation loss: 2.441152421910849

Epoch: 5| Step: 9
Training loss: 0.17152367795346599
Validation loss: 2.459352143649186

Epoch: 5| Step: 10
Training loss: 0.1681437966411228
Validation loss: 2.4760630528307543

Epoch: 595| Step: 0
Training loss: 0.17729527865547037
Validation loss: 2.4381961385867665

Epoch: 5| Step: 1
Training loss: 0.11803785788269631
Validation loss: 2.4460887702247724

Epoch: 5| Step: 2
Training loss: 0.1609596188631976
Validation loss: 2.409730419278057

Epoch: 5| Step: 3
Training loss: 0.18682704801505057
Validation loss: 2.4339221814431764

Epoch: 5| Step: 4
Training loss: 0.15791426295293826
Validation loss: 2.44704584897153

Epoch: 5| Step: 5
Training loss: 0.28684759856860065
Validation loss: 2.4243357562782535

Epoch: 5| Step: 6
Training loss: 0.28988874759620264
Validation loss: 2.4310755103691846

Epoch: 5| Step: 7
Training loss: 0.36026928383613427
Validation loss: 2.4380688299373854

Epoch: 5| Step: 8
Training loss: 0.36031049789044506
Validation loss: 2.4312942837431435

Epoch: 5| Step: 9
Training loss: 0.18743806054342163
Validation loss: 2.4304865339082125

Epoch: 5| Step: 10
Training loss: 0.21071108393193586
Validation loss: 2.4714976926609276

Epoch: 596| Step: 0
Training loss: 0.3343067732395538
Validation loss: 2.457630372596805

Epoch: 5| Step: 1
Training loss: 0.34243181381754273
Validation loss: 2.452335182185977

Epoch: 5| Step: 2
Training loss: 0.25541300092424085
Validation loss: 2.455103143329316

Epoch: 5| Step: 3
Training loss: 0.20563534013496085
Validation loss: 2.483863918852183

Epoch: 5| Step: 4
Training loss: 0.10342344642375514
Validation loss: 2.485961378684144

Epoch: 5| Step: 5
Training loss: 0.10388451201850404
Validation loss: 2.455220352462181

Epoch: 5| Step: 6
Training loss: 0.21264909464551232
Validation loss: 2.4640276515221777

Epoch: 5| Step: 7
Training loss: 0.253189513144568
Validation loss: 2.5069462207650828

Epoch: 5| Step: 8
Training loss: 0.20843824884031373
Validation loss: 2.469346003191317

Epoch: 5| Step: 9
Training loss: 0.25417398861724844
Validation loss: 2.48603516796462

Epoch: 5| Step: 10
Training loss: 0.16100695347467714
Validation loss: 2.497670759040568

Epoch: 597| Step: 0
Training loss: 0.2100425827613921
Validation loss: 2.459935749722915

Epoch: 5| Step: 1
Training loss: 0.21403690031917014
Validation loss: 2.4380186721253763

Epoch: 5| Step: 2
Training loss: 0.1929912723880449
Validation loss: 2.4395050245869787

Epoch: 5| Step: 3
Training loss: 0.19549213731484066
Validation loss: 2.4379521001410174

Epoch: 5| Step: 4
Training loss: 0.20764973762983835
Validation loss: 2.4091286435627697

Epoch: 5| Step: 5
Training loss: 0.1462117710339459
Validation loss: 2.4182109191641006

Epoch: 5| Step: 6
Training loss: 0.32736823825691674
Validation loss: 2.4085761478137675

Epoch: 5| Step: 7
Training loss: 0.318840704428815
Validation loss: 2.4505550711714164

Epoch: 5| Step: 8
Training loss: 0.31865080851478184
Validation loss: 2.4453327191617182

Epoch: 5| Step: 9
Training loss: 0.2617626722687645
Validation loss: 2.456623257087519

Epoch: 5| Step: 10
Training loss: 0.163744038353206
Validation loss: 2.425570453799992

Epoch: 598| Step: 0
Training loss: 0.16526431450473447
Validation loss: 2.475049536333484

Epoch: 5| Step: 1
Training loss: 0.3693093817336012
Validation loss: 2.486099597024835

Epoch: 5| Step: 2
Training loss: 0.1941793760006727
Validation loss: 2.4708115576236707

Epoch: 5| Step: 3
Training loss: 0.15789173823270428
Validation loss: 2.465440540485923

Epoch: 5| Step: 4
Training loss: 0.23320927795523047
Validation loss: 2.451868052794685

Epoch: 5| Step: 5
Training loss: 0.19640836364045794
Validation loss: 2.4347996569297896

Epoch: 5| Step: 6
Training loss: 0.2866907116435829
Validation loss: 2.4413287832131783

Epoch: 5| Step: 7
Training loss: 0.23206080913107488
Validation loss: 2.4289438126213767

Epoch: 5| Step: 8
Training loss: 0.29209084263525237
Validation loss: 2.397509767266365

Epoch: 5| Step: 9
Training loss: 0.22478871856367225
Validation loss: 2.381227643161561

Epoch: 5| Step: 10
Training loss: 0.2050373400141436
Validation loss: 2.397406302372712

Epoch: 599| Step: 0
Training loss: 0.2772170838714575
Validation loss: 2.380832267132524

Epoch: 5| Step: 1
Training loss: 0.14237029461457532
Validation loss: 2.3829786092472443

Epoch: 5| Step: 2
Training loss: 0.21343542088212264
Validation loss: 2.406748165687627

Epoch: 5| Step: 3
Training loss: 0.22487122572614807
Validation loss: 2.462374399581132

Epoch: 5| Step: 4
Training loss: 0.1411836178259801
Validation loss: 2.4310185355863254

Epoch: 5| Step: 5
Training loss: 0.268227214559223
Validation loss: 2.418506222041528

Epoch: 5| Step: 6
Training loss: 0.26510657882092664
Validation loss: 2.440159859096534

Epoch: 5| Step: 7
Training loss: 0.21502618846416294
Validation loss: 2.471283759501398

Epoch: 5| Step: 8
Training loss: 0.35978018682543605
Validation loss: 2.450866227817831

Epoch: 5| Step: 9
Training loss: 0.14230003410058809
Validation loss: 2.460992936256902

Epoch: 5| Step: 10
Training loss: 0.13023935584215957
Validation loss: 2.4441476460242066

Epoch: 600| Step: 0
Training loss: 0.2769266941818039
Validation loss: 2.439650702402529

Epoch: 5| Step: 1
Training loss: 0.10413149498183234
Validation loss: 2.4421360342397564

Epoch: 5| Step: 2
Training loss: 0.20224024581374964
Validation loss: 2.4557097088888264

Epoch: 5| Step: 3
Training loss: 0.15198100135873244
Validation loss: 2.4052183989386067

Epoch: 5| Step: 4
Training loss: 0.21699671083915267
Validation loss: 2.436341178262564

Epoch: 5| Step: 5
Training loss: 0.1899166924645525
Validation loss: 2.4558625490001944

Epoch: 5| Step: 6
Training loss: 0.21643209268665373
Validation loss: 2.437509315857861

Epoch: 5| Step: 7
Training loss: 0.34111207207728356
Validation loss: 2.434535143629366

Epoch: 5| Step: 8
Training loss: 0.2682552263260931
Validation loss: 2.4758389586633767

Epoch: 5| Step: 9
Training loss: 0.19650064518570237
Validation loss: 2.466732328382678

Epoch: 5| Step: 10
Training loss: 0.27057294371344415
Validation loss: 2.4674575109790693

Testing loss: 2.667206803892421
