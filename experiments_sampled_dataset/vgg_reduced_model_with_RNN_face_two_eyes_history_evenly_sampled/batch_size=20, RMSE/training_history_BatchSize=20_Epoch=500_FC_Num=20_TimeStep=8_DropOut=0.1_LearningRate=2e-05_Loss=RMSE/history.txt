Epoch: 1| Step: 0
Training loss: 6.012839249459755
Validation loss: 5.778539265199155

Epoch: 5| Step: 1
Training loss: 4.9520903749246035
Validation loss: 5.754404783986562

Epoch: 5| Step: 2
Training loss: 6.657756223084876
Validation loss: 5.730591002430208

Epoch: 5| Step: 3
Training loss: 6.09017291595569
Validation loss: 5.706494903511545

Epoch: 5| Step: 4
Training loss: 5.539656979789935
Validation loss: 5.678039726115318

Epoch: 5| Step: 5
Training loss: 4.321421806753509
Validation loss: 5.647676716468512

Epoch: 5| Step: 6
Training loss: 6.295085491784599
Validation loss: 5.61266047396324

Epoch: 5| Step: 7
Training loss: 5.304405238601472
Validation loss: 5.574467993736348

Epoch: 5| Step: 8
Training loss: 4.5855355029700755
Validation loss: 5.532470898382076

Epoch: 5| Step: 9
Training loss: 5.752907722675986
Validation loss: 5.486805000762712

Epoch: 5| Step: 10
Training loss: 6.488926772147831
Validation loss: 5.438205026896159

Epoch: 2| Step: 0
Training loss: 5.7763195561487155
Validation loss: 5.387579635420987

Epoch: 5| Step: 1
Training loss: 4.771490970689772
Validation loss: 5.336232969276833

Epoch: 5| Step: 2
Training loss: 6.516212199072391
Validation loss: 5.286432465019646

Epoch: 5| Step: 3
Training loss: 4.440173566020445
Validation loss: 5.236306003433056

Epoch: 5| Step: 4
Training loss: 4.632918512633494
Validation loss: 5.187778327553143

Epoch: 5| Step: 5
Training loss: 4.88705909086612
Validation loss: 5.140175944999387

Epoch: 5| Step: 6
Training loss: 5.946320096224856
Validation loss: 5.092021273082257

Epoch: 5| Step: 7
Training loss: 5.000265686605614
Validation loss: 5.043320884371761

Epoch: 5| Step: 8
Training loss: 4.537023614934212
Validation loss: 4.987901554436825

Epoch: 5| Step: 9
Training loss: 5.216384077289256
Validation loss: 4.92782864499488

Epoch: 5| Step: 10
Training loss: 5.088136352931248
Validation loss: 4.87883427909044

Epoch: 3| Step: 0
Training loss: 4.1664093446746895
Validation loss: 4.835300224981796

Epoch: 5| Step: 1
Training loss: 4.362796438906356
Validation loss: 4.795794022991842

Epoch: 5| Step: 2
Training loss: 4.846345070965851
Validation loss: 4.750662657580207

Epoch: 5| Step: 3
Training loss: 4.799699479868078
Validation loss: 4.706557831061166

Epoch: 5| Step: 4
Training loss: 5.721955281834563
Validation loss: 4.670497540729819

Epoch: 5| Step: 5
Training loss: 4.893987797480665
Validation loss: 4.629598602345909

Epoch: 5| Step: 6
Training loss: 4.794455648158423
Validation loss: 4.59010860952233

Epoch: 5| Step: 7
Training loss: 4.7778154391398795
Validation loss: 4.544521205031942

Epoch: 5| Step: 8
Training loss: 3.5452168491686646
Validation loss: 4.496069877101201

Epoch: 5| Step: 9
Training loss: 5.59408329658016
Validation loss: 4.445284601158567

Epoch: 5| Step: 10
Training loss: 3.868393342027801
Validation loss: 4.396209392005101

Epoch: 4| Step: 0
Training loss: 4.715442028502728
Validation loss: 4.344529700532189

Epoch: 5| Step: 1
Training loss: 4.465670504915435
Validation loss: 4.295265709300574

Epoch: 5| Step: 2
Training loss: 4.208804919318185
Validation loss: 4.245223310115224

Epoch: 5| Step: 3
Training loss: 4.85132484038218
Validation loss: 4.1991571936325

Epoch: 5| Step: 4
Training loss: 3.6637217804502975
Validation loss: 4.161176028664997

Epoch: 5| Step: 5
Training loss: 4.684930529491564
Validation loss: 4.121600453413203

Epoch: 5| Step: 6
Training loss: 3.7638474697134785
Validation loss: 4.089673521737766

Epoch: 5| Step: 7
Training loss: 3.7260400177899813
Validation loss: 4.051622353084824

Epoch: 5| Step: 8
Training loss: 4.541684258569833
Validation loss: 4.016836426792014

Epoch: 5| Step: 9
Training loss: 3.9393366813944555
Validation loss: 3.987200822593263

Epoch: 5| Step: 10
Training loss: 4.28585901470131
Validation loss: 3.973687683229365

Epoch: 5| Step: 0
Training loss: 3.9886067973999566
Validation loss: 3.9402829811420332

Epoch: 5| Step: 1
Training loss: 4.321700743984553
Validation loss: 3.9193079077691273

Epoch: 5| Step: 2
Training loss: 3.9006651971301687
Validation loss: 3.9037816514543033

Epoch: 5| Step: 3
Training loss: 3.9089055914633746
Validation loss: 3.8947666838546566

Epoch: 5| Step: 4
Training loss: 4.003069891688035
Validation loss: 3.867559479023808

Epoch: 5| Step: 5
Training loss: 4.045356848669973
Validation loss: 3.8396770361946713

Epoch: 5| Step: 6
Training loss: 3.9248794051189093
Validation loss: 3.818734991882842

Epoch: 5| Step: 7
Training loss: 4.196898432344535
Validation loss: 3.815356734411558

Epoch: 5| Step: 8
Training loss: 3.251140394405591
Validation loss: 3.7786231669930346

Epoch: 5| Step: 9
Training loss: 4.4956489296547675
Validation loss: 3.76693642022679

Epoch: 5| Step: 10
Training loss: 4.019583209622255
Validation loss: 3.7460999200978344

Epoch: 6| Step: 0
Training loss: 3.892753049726163
Validation loss: 3.7260650084617

Epoch: 5| Step: 1
Training loss: 3.8298252611662185
Validation loss: 3.7088911091696506

Epoch: 5| Step: 2
Training loss: 4.430330744467177
Validation loss: 3.6941528151753076

Epoch: 5| Step: 3
Training loss: 3.8935347251102885
Validation loss: 3.675166091809888

Epoch: 5| Step: 4
Training loss: 3.988432968198047
Validation loss: 3.659251009824353

Epoch: 5| Step: 5
Training loss: 4.153682518042678
Validation loss: 3.6455707358206757

Epoch: 5| Step: 6
Training loss: 3.216409072707955
Validation loss: 3.632245814697415

Epoch: 5| Step: 7
Training loss: 4.103321330478775
Validation loss: 3.6239114922687206

Epoch: 5| Step: 8
Training loss: 3.5511644951833174
Validation loss: 3.6056685260080794

Epoch: 5| Step: 9
Training loss: 3.0445062281456696
Validation loss: 3.5937024984122887

Epoch: 5| Step: 10
Training loss: 4.025392046488104
Validation loss: 3.5777953284800907

Epoch: 7| Step: 0
Training loss: 3.446605898052706
Validation loss: 3.562091002979579

Epoch: 5| Step: 1
Training loss: 3.4496992560620976
Validation loss: 3.548290934802525

Epoch: 5| Step: 2
Training loss: 4.225532561375678
Validation loss: 3.5333205256710776

Epoch: 5| Step: 3
Training loss: 2.9882129536721678
Validation loss: 3.5201706038962883

Epoch: 5| Step: 4
Training loss: 3.9180322795977225
Validation loss: 3.514357413286478

Epoch: 5| Step: 5
Training loss: 4.026526707707383
Validation loss: 3.49923064745923

Epoch: 5| Step: 6
Training loss: 3.4447980224132397
Validation loss: 3.4875509741096002

Epoch: 5| Step: 7
Training loss: 3.3024083568208513
Validation loss: 3.4750604496335

Epoch: 5| Step: 8
Training loss: 3.9065189116423134
Validation loss: 3.470357746798278

Epoch: 5| Step: 9
Training loss: 4.226527751561179
Validation loss: 3.459007790945059

Epoch: 5| Step: 10
Training loss: 3.700555481324571
Validation loss: 3.445390271956821

Epoch: 8| Step: 0
Training loss: 3.680785450663143
Validation loss: 3.4651732787436984

Epoch: 5| Step: 1
Training loss: 3.4238899604014
Validation loss: 3.449808952031745

Epoch: 5| Step: 2
Training loss: 3.6861148107555315
Validation loss: 3.4326021011528174

Epoch: 5| Step: 3
Training loss: 3.0947150064374807
Validation loss: 3.4245176046999646

Epoch: 5| Step: 4
Training loss: 3.8219514853184533
Validation loss: 3.427292814241173

Epoch: 5| Step: 5
Training loss: 3.2457826100321188
Validation loss: 3.421562464869886

Epoch: 5| Step: 6
Training loss: 4.0070297934383925
Validation loss: 3.4124174899959674

Epoch: 5| Step: 7
Training loss: 3.3392523347892578
Validation loss: 3.4024623853321554

Epoch: 5| Step: 8
Training loss: 4.5166419972852205
Validation loss: 3.3831761207912607

Epoch: 5| Step: 9
Training loss: 3.784653574158618
Validation loss: 3.371554864358429

Epoch: 5| Step: 10
Training loss: 3.0914587919230305
Validation loss: 3.3942507910207262

Epoch: 9| Step: 0
Training loss: 3.3632816753320722
Validation loss: 3.4113330243481714

Epoch: 5| Step: 1
Training loss: 3.381365389450341
Validation loss: 3.3924445199067352

Epoch: 5| Step: 2
Training loss: 3.139375352625948
Validation loss: 3.354547515038866

Epoch: 5| Step: 3
Training loss: 3.399362582874712
Validation loss: 3.346704169572584

Epoch: 5| Step: 4
Training loss: 3.5123196810122477
Validation loss: 3.352297723410458

Epoch: 5| Step: 5
Training loss: 4.034387831072862
Validation loss: 3.35114213849851

Epoch: 5| Step: 6
Training loss: 3.23318636517607
Validation loss: 3.3417606164921168

Epoch: 5| Step: 7
Training loss: 3.3233582652644835
Validation loss: 3.3414181772764295

Epoch: 5| Step: 8
Training loss: 4.072661148732786
Validation loss: 3.334910778348942

Epoch: 5| Step: 9
Training loss: 3.694799149646106
Validation loss: 3.299943564433637

Epoch: 5| Step: 10
Training loss: 4.12444833476698
Validation loss: 3.2968243313797267

Epoch: 10| Step: 0
Training loss: 2.7783105296949913
Validation loss: 3.302501666072096

Epoch: 5| Step: 1
Training loss: 2.524374867472559
Validation loss: 3.3013953128801625

Epoch: 5| Step: 2
Training loss: 3.109956466517307
Validation loss: 3.3037337188824227

Epoch: 5| Step: 3
Training loss: 3.749509906532395
Validation loss: 3.2947892850084792

Epoch: 5| Step: 4
Training loss: 3.4872290721377195
Validation loss: 3.2784752789878002

Epoch: 5| Step: 5
Training loss: 3.9640139458388863
Validation loss: 3.260349078897942

Epoch: 5| Step: 6
Training loss: 3.4981043995653973
Validation loss: 3.2488213335188094

Epoch: 5| Step: 7
Training loss: 3.927161434351473
Validation loss: 3.23673487373796

Epoch: 5| Step: 8
Training loss: 4.300670819852692
Validation loss: 3.225437294169287

Epoch: 5| Step: 9
Training loss: 3.0639897051406697
Validation loss: 3.217841965207709

Epoch: 5| Step: 10
Training loss: 3.7620279060314368
Validation loss: 3.207663153777793

Epoch: 11| Step: 0
Training loss: 3.176439880916627
Validation loss: 3.2036279859182133

Epoch: 5| Step: 1
Training loss: 3.369225400880879
Validation loss: 3.198158152162813

Epoch: 5| Step: 2
Training loss: 3.9311022174270494
Validation loss: 3.194807700169596

Epoch: 5| Step: 3
Training loss: 2.992098575396154
Validation loss: 3.1836244433808436

Epoch: 5| Step: 4
Training loss: 2.642675562920915
Validation loss: 3.177726662450326

Epoch: 5| Step: 5
Training loss: 4.172541761515026
Validation loss: 3.175893130881636

Epoch: 5| Step: 6
Training loss: 4.0494696941040065
Validation loss: 3.1721646410893896

Epoch: 5| Step: 7
Training loss: 3.135974990628226
Validation loss: 3.1583240719832957

Epoch: 5| Step: 8
Training loss: 2.824629588866572
Validation loss: 3.150066786639298

Epoch: 5| Step: 9
Training loss: 3.360255210357593
Validation loss: 3.147978746152747

Epoch: 5| Step: 10
Training loss: 3.862040722648584
Validation loss: 3.1449949623366367

Epoch: 12| Step: 0
Training loss: 2.6544677140454485
Validation loss: 3.1415884554012905

Epoch: 5| Step: 1
Training loss: 3.1720982364966037
Validation loss: 3.1399007488758093

Epoch: 5| Step: 2
Training loss: 3.973770330472467
Validation loss: 3.137818974840411

Epoch: 5| Step: 3
Training loss: 3.884761942635887
Validation loss: 3.124422645968727

Epoch: 5| Step: 4
Training loss: 3.3593383787066418
Validation loss: 3.1184590309412696

Epoch: 5| Step: 5
Training loss: 3.293390249334509
Validation loss: 3.1124610305733884

Epoch: 5| Step: 6
Training loss: 3.442047994577161
Validation loss: 3.1062947656586504

Epoch: 5| Step: 7
Training loss: 3.4048108901781866
Validation loss: 3.1082258157450955

Epoch: 5| Step: 8
Training loss: 3.2249037794796074
Validation loss: 3.1038483046733853

Epoch: 5| Step: 9
Training loss: 3.4653913028717325
Validation loss: 3.1036412554977493

Epoch: 5| Step: 10
Training loss: 3.252127024723438
Validation loss: 3.098017901231738

Epoch: 13| Step: 0
Training loss: 4.084923000100252
Validation loss: 3.0922678950900075

Epoch: 5| Step: 1
Training loss: 3.965510089673366
Validation loss: 3.0925954182998026

Epoch: 5| Step: 2
Training loss: 3.658008641553446
Validation loss: 3.090162455842098

Epoch: 5| Step: 3
Training loss: 2.983439673405694
Validation loss: 3.0835610238846534

Epoch: 5| Step: 4
Training loss: 3.8015346740883342
Validation loss: 3.0817579983224785

Epoch: 5| Step: 5
Training loss: 2.915784393565605
Validation loss: 3.086339659503518

Epoch: 5| Step: 6
Training loss: 2.4413898436948744
Validation loss: 3.068370268341747

Epoch: 5| Step: 7
Training loss: 2.8042613266210012
Validation loss: 3.0688224440913356

Epoch: 5| Step: 8
Training loss: 3.17190762207093
Validation loss: 3.071063826511689

Epoch: 5| Step: 9
Training loss: 3.1137477472604194
Validation loss: 3.0683662462150054

Epoch: 5| Step: 10
Training loss: 3.6824282666255392
Validation loss: 3.066871692077879

Epoch: 14| Step: 0
Training loss: 2.3623733163604883
Validation loss: 3.066669201972452

Epoch: 5| Step: 1
Training loss: 3.4909273814043695
Validation loss: 3.0613692278140245

Epoch: 5| Step: 2
Training loss: 3.2772877339428477
Validation loss: 3.059910797871495

Epoch: 5| Step: 3
Training loss: 2.7140825041372483
Validation loss: 3.055378529208193

Epoch: 5| Step: 4
Training loss: 4.133261528211795
Validation loss: 3.053857115646658

Epoch: 5| Step: 5
Training loss: 3.619245499863369
Validation loss: 3.045378157821885

Epoch: 5| Step: 6
Training loss: 3.784416701246938
Validation loss: 3.0402201945399163

Epoch: 5| Step: 7
Training loss: 3.024621697092458
Validation loss: 3.036490542127827

Epoch: 5| Step: 8
Training loss: 3.413299824530314
Validation loss: 3.0382747158964682

Epoch: 5| Step: 9
Training loss: 3.6197711459156796
Validation loss: 3.0426399695415194

Epoch: 5| Step: 10
Training loss: 2.814313515794846
Validation loss: 3.0267660766267084

Epoch: 15| Step: 0
Training loss: 2.7295108801350088
Validation loss: 3.025760615485489

Epoch: 5| Step: 1
Training loss: 3.1746209947146458
Validation loss: 3.0294291265880364

Epoch: 5| Step: 2
Training loss: 3.020468503472392
Validation loss: 3.0310977863321753

Epoch: 5| Step: 3
Training loss: 3.740520830863077
Validation loss: 3.029233528407321

Epoch: 5| Step: 4
Training loss: 2.8562279564739335
Validation loss: 3.0167214051155398

Epoch: 5| Step: 5
Training loss: 3.668657817039882
Validation loss: 3.012674619978202

Epoch: 5| Step: 6
Training loss: 3.081672599240733
Validation loss: 3.005978671081639

Epoch: 5| Step: 7
Training loss: 3.219600528081831
Validation loss: 3.0048341752594623

Epoch: 5| Step: 8
Training loss: 3.7538371481673174
Validation loss: 3.0028352448486957

Epoch: 5| Step: 9
Training loss: 3.1853694901466807
Validation loss: 3.0125279659429562

Epoch: 5| Step: 10
Training loss: 3.8608682191654404
Validation loss: 3.0034624101981686

Epoch: 16| Step: 0
Training loss: 2.481373635389923
Validation loss: 2.9990111228637226

Epoch: 5| Step: 1
Training loss: 3.3036146654517813
Validation loss: 3.009513780614008

Epoch: 5| Step: 2
Training loss: 3.4591124396200366
Validation loss: 3.0178068593685063

Epoch: 5| Step: 3
Training loss: 3.804045010000585
Validation loss: 3.0128703639988466

Epoch: 5| Step: 4
Training loss: 4.153537410010583
Validation loss: 2.99748654337554

Epoch: 5| Step: 5
Training loss: 3.5221141013054567
Validation loss: 2.9830298291096895

Epoch: 5| Step: 6
Training loss: 3.146902311144054
Validation loss: 2.9775817235422903

Epoch: 5| Step: 7
Training loss: 3.501042347054537
Validation loss: 2.980151528184338

Epoch: 5| Step: 8
Training loss: 2.9657162876369147
Validation loss: 2.9711288359950943

Epoch: 5| Step: 9
Training loss: 2.4771973190411374
Validation loss: 2.967857607537399

Epoch: 5| Step: 10
Training loss: 2.977878710078447
Validation loss: 2.9661478033610877

Epoch: 17| Step: 0
Training loss: 3.1190912461358344
Validation loss: 2.9649502679967226

Epoch: 5| Step: 1
Training loss: 3.6015166902421503
Validation loss: 2.964378951608587

Epoch: 5| Step: 2
Training loss: 3.3642811988936794
Validation loss: 2.960516671766678

Epoch: 5| Step: 3
Training loss: 3.0334904836112733
Validation loss: 2.9898537442798423

Epoch: 5| Step: 4
Training loss: 2.994887446101996
Validation loss: 3.026589042066958

Epoch: 5| Step: 5
Training loss: 3.0802541427293413
Validation loss: 3.0145618899023585

Epoch: 5| Step: 6
Training loss: 4.087688122074581
Validation loss: 3.004577496006659

Epoch: 5| Step: 7
Training loss: 3.124969024504686
Validation loss: 2.9547784693477044

Epoch: 5| Step: 8
Training loss: 3.49077985756436
Validation loss: 2.950385601064367

Epoch: 5| Step: 9
Training loss: 2.7941524958135053
Validation loss: 2.941636820834665

Epoch: 5| Step: 10
Training loss: 3.1667720542905275
Validation loss: 2.952206077741751

Epoch: 18| Step: 0
Training loss: 2.5398819290713193
Validation loss: 2.943518347537025

Epoch: 5| Step: 1
Training loss: 3.6387468331315658
Validation loss: 2.938055140032521

Epoch: 5| Step: 2
Training loss: 3.0104604187704243
Validation loss: 2.9423455946487045

Epoch: 5| Step: 3
Training loss: 3.8307365384561476
Validation loss: 2.9551439113597935

Epoch: 5| Step: 4
Training loss: 3.098369655741646
Validation loss: 2.955390177323082

Epoch: 5| Step: 5
Training loss: 2.893574792159315
Validation loss: 2.9454124688096486

Epoch: 5| Step: 6
Training loss: 3.6892409013704603
Validation loss: 2.9484345219561527

Epoch: 5| Step: 7
Training loss: 3.2014337308055056
Validation loss: 2.9385923049163316

Epoch: 5| Step: 8
Training loss: 3.031086081565864
Validation loss: 2.927691456078052

Epoch: 5| Step: 9
Training loss: 3.450470469365147
Validation loss: 2.9332904732370566

Epoch: 5| Step: 10
Training loss: 3.0697500864006084
Validation loss: 2.9294640056721573

Epoch: 19| Step: 0
Training loss: 3.3799289456635586
Validation loss: 2.9285304054604735

Epoch: 5| Step: 1
Training loss: 2.87967037168926
Validation loss: 2.9302910260903827

Epoch: 5| Step: 2
Training loss: 3.2060868130624702
Validation loss: 2.910758196911767

Epoch: 5| Step: 3
Training loss: 2.714697173847761
Validation loss: 2.91010745494122

Epoch: 5| Step: 4
Training loss: 3.352103378650072
Validation loss: 2.9106590266685393

Epoch: 5| Step: 5
Training loss: 2.954051361918499
Validation loss: 2.9290021809890403

Epoch: 5| Step: 6
Training loss: 3.231450329589638
Validation loss: 2.958033153192864

Epoch: 5| Step: 7
Training loss: 3.1638506029547893
Validation loss: 2.9459913828197135

Epoch: 5| Step: 8
Training loss: 4.2437129922188594
Validation loss: 2.918650389968032

Epoch: 5| Step: 9
Training loss: 2.402568626733595
Validation loss: 2.9035594666700373

Epoch: 5| Step: 10
Training loss: 3.769831164194328
Validation loss: 2.904359124534113

Epoch: 20| Step: 0
Training loss: 3.6016660332020902
Validation loss: 2.933139263605658

Epoch: 5| Step: 1
Training loss: 2.9300481548843877
Validation loss: 2.9908865458201297

Epoch: 5| Step: 2
Training loss: 2.558188929091014
Validation loss: 2.9599174188059933

Epoch: 5| Step: 3
Training loss: 3.1766492870238325
Validation loss: 2.9016880428694494

Epoch: 5| Step: 4
Training loss: 4.042732622558053
Validation loss: 2.8864369143318522

Epoch: 5| Step: 5
Training loss: 3.5525774719252445
Validation loss: 2.881878708473001

Epoch: 5| Step: 6
Training loss: 2.939165982133746
Validation loss: 2.88842178364042

Epoch: 5| Step: 7
Training loss: 3.2737560617944994
Validation loss: 2.89573987159456

Epoch: 5| Step: 8
Training loss: 2.3216997616999886
Validation loss: 2.900903565756563

Epoch: 5| Step: 9
Training loss: 3.5418086902340975
Validation loss: 2.9156982261444035

Epoch: 5| Step: 10
Training loss: 3.187901789455545
Validation loss: 2.90824126990436

Epoch: 21| Step: 0
Training loss: 2.6200913446824674
Validation loss: 2.900566000808594

Epoch: 5| Step: 1
Training loss: 2.8156396931086
Validation loss: 2.902618903499542

Epoch: 5| Step: 2
Training loss: 3.756246069780728
Validation loss: 2.897090206791293

Epoch: 5| Step: 3
Training loss: 4.00727825805441
Validation loss: 2.8927574639705607

Epoch: 5| Step: 4
Training loss: 3.0177410390387593
Validation loss: 2.8781121277762622

Epoch: 5| Step: 5
Training loss: 3.6594717063471967
Validation loss: 2.873030594807594

Epoch: 5| Step: 6
Training loss: 2.7488164955967584
Validation loss: 2.8700108059318135

Epoch: 5| Step: 7
Training loss: 2.8272579824146216
Validation loss: 2.869166345812675

Epoch: 5| Step: 8
Training loss: 3.161075793044602
Validation loss: 2.8669272111818023

Epoch: 5| Step: 9
Training loss: 3.095573119312758
Validation loss: 2.871095926924212

Epoch: 5| Step: 10
Training loss: 3.2022800726793705
Validation loss: 2.865480359862528

Epoch: 22| Step: 0
Training loss: 3.3724166025040154
Validation loss: 2.8681868692826513

Epoch: 5| Step: 1
Training loss: 3.448944184552597
Validation loss: 2.8697106980296776

Epoch: 5| Step: 2
Training loss: 3.0824873167397344
Validation loss: 2.8767990201242677

Epoch: 5| Step: 3
Training loss: 3.028800997554657
Validation loss: 2.8761292318012637

Epoch: 5| Step: 4
Training loss: 3.035861253787151
Validation loss: 2.8680219781306118

Epoch: 5| Step: 5
Training loss: 3.387571586049563
Validation loss: 2.8617664138534114

Epoch: 5| Step: 6
Training loss: 3.161921777750563
Validation loss: 2.857151303007824

Epoch: 5| Step: 7
Training loss: 3.1034822840307115
Validation loss: 2.859669751367886

Epoch: 5| Step: 8
Training loss: 3.2391605080821697
Validation loss: 2.859272205969078

Epoch: 5| Step: 9
Training loss: 3.238903469040517
Validation loss: 2.8568091663322375

Epoch: 5| Step: 10
Training loss: 2.7961852858877463
Validation loss: 2.85543584183901

Epoch: 23| Step: 0
Training loss: 2.5289974786603313
Validation loss: 2.8594484167941268

Epoch: 5| Step: 1
Training loss: 2.851746101216878
Validation loss: 2.8571254040438445

Epoch: 5| Step: 2
Training loss: 3.686890891248306
Validation loss: 2.860261891306387

Epoch: 5| Step: 3
Training loss: 3.0271153517673013
Validation loss: 2.8607919742464585

Epoch: 5| Step: 4
Training loss: 2.755450482655372
Validation loss: 2.8628463326393017

Epoch: 5| Step: 5
Training loss: 2.928855024954658
Validation loss: 2.8597979914961136

Epoch: 5| Step: 6
Training loss: 3.4499021654493154
Validation loss: 2.8629211961343115

Epoch: 5| Step: 7
Training loss: 3.696125094406435
Validation loss: 2.859662943480314

Epoch: 5| Step: 8
Training loss: 2.82052163487282
Validation loss: 2.8499615737722324

Epoch: 5| Step: 9
Training loss: 3.163521124595459
Validation loss: 2.84762906191619

Epoch: 5| Step: 10
Training loss: 3.755191261510186
Validation loss: 2.8465137882578695

Epoch: 24| Step: 0
Training loss: 2.653216615854147
Validation loss: 2.849495296661401

Epoch: 5| Step: 1
Training loss: 3.1767843804126508
Validation loss: 2.8476175186055483

Epoch: 5| Step: 2
Training loss: 2.7654863743064455
Validation loss: 2.8446220134655533

Epoch: 5| Step: 3
Training loss: 3.4087960063653995
Validation loss: 2.843988467403436

Epoch: 5| Step: 4
Training loss: 3.5203898374390223
Validation loss: 2.8427223720675916

Epoch: 5| Step: 5
Training loss: 3.053115635430959
Validation loss: 2.842274568518652

Epoch: 5| Step: 6
Training loss: 3.604064469551508
Validation loss: 2.847717484356346

Epoch: 5| Step: 7
Training loss: 3.2446839797926614
Validation loss: 2.8443785933572374

Epoch: 5| Step: 8
Training loss: 2.6851663437787625
Validation loss: 2.8425030278249186

Epoch: 5| Step: 9
Training loss: 3.52603344749646
Validation loss: 2.8426402244620936

Epoch: 5| Step: 10
Training loss: 2.992443263026733
Validation loss: 2.840091344547854

Epoch: 25| Step: 0
Training loss: 3.453382663693587
Validation loss: 2.83868508422081

Epoch: 5| Step: 1
Training loss: 3.2655530127662926
Validation loss: 2.840728088101779

Epoch: 5| Step: 2
Training loss: 2.8476167317645453
Validation loss: 2.8355430446895924

Epoch: 5| Step: 3
Training loss: 2.7703936139499383
Validation loss: 2.8359336056365168

Epoch: 5| Step: 4
Training loss: 2.47798900255129
Validation loss: 2.835148394342032

Epoch: 5| Step: 5
Training loss: 3.195140880648674
Validation loss: 2.8335012413908167

Epoch: 5| Step: 6
Training loss: 3.2372671271859526
Validation loss: 2.83330265664342

Epoch: 5| Step: 7
Training loss: 3.5263721906552017
Validation loss: 2.8338770794032597

Epoch: 5| Step: 8
Training loss: 3.405899169773393
Validation loss: 2.8336564660317745

Epoch: 5| Step: 9
Training loss: 2.9347615565283593
Validation loss: 2.832313814419702

Epoch: 5| Step: 10
Training loss: 3.3802222362794705
Validation loss: 2.829768727780047

Epoch: 26| Step: 0
Training loss: 3.261075003137221
Validation loss: 2.833260590152111

Epoch: 5| Step: 1
Training loss: 3.406225081886351
Validation loss: 2.8387767365138203

Epoch: 5| Step: 2
Training loss: 3.223323054831474
Validation loss: 2.830168874824096

Epoch: 5| Step: 3
Training loss: 3.121557093902132
Validation loss: 2.826587592482318

Epoch: 5| Step: 4
Training loss: 2.9779456421840096
Validation loss: 2.8265200321102255

Epoch: 5| Step: 5
Training loss: 2.7208335171553903
Validation loss: 2.8240310832846727

Epoch: 5| Step: 6
Training loss: 3.452828787272301
Validation loss: 2.822770877381142

Epoch: 5| Step: 7
Training loss: 2.6809958775455547
Validation loss: 2.8266621383894632

Epoch: 5| Step: 8
Training loss: 3.1693547200385543
Validation loss: 2.8237204733018357

Epoch: 5| Step: 9
Training loss: 3.3169386293738863
Validation loss: 2.826651313016029

Epoch: 5| Step: 10
Training loss: 3.108378188258738
Validation loss: 2.8274172301381806

Epoch: 27| Step: 0
Training loss: 3.1209243136404585
Validation loss: 2.828516188245493

Epoch: 5| Step: 1
Training loss: 3.581916898776236
Validation loss: 2.8231549254214663

Epoch: 5| Step: 2
Training loss: 3.2611441648657737
Validation loss: 2.818790349882302

Epoch: 5| Step: 3
Training loss: 3.594983494578792
Validation loss: 2.8233784777394186

Epoch: 5| Step: 4
Training loss: 2.7167500122328674
Validation loss: 2.822389637392301

Epoch: 5| Step: 5
Training loss: 2.6876842524332334
Validation loss: 2.821195476297952

Epoch: 5| Step: 6
Training loss: 3.320522167093333
Validation loss: 2.823187195551512

Epoch: 5| Step: 7
Training loss: 2.414150001890607
Validation loss: 2.8165559807242566

Epoch: 5| Step: 8
Training loss: 3.1255379785949886
Validation loss: 2.816365845425272

Epoch: 5| Step: 9
Training loss: 3.2689702909793574
Validation loss: 2.811586451768093

Epoch: 5| Step: 10
Training loss: 3.117072617175389
Validation loss: 2.8133880562245523

Epoch: 28| Step: 0
Training loss: 3.0816472228863643
Validation loss: 2.8112995042126707

Epoch: 5| Step: 1
Training loss: 3.0984883098889617
Validation loss: 2.8117284849143243

Epoch: 5| Step: 2
Training loss: 3.875562319409401
Validation loss: 2.8121223241702364

Epoch: 5| Step: 3
Training loss: 3.0765334918900513
Validation loss: 2.8100946967626563

Epoch: 5| Step: 4
Training loss: 2.7429651967120425
Validation loss: 2.8106006439102353

Epoch: 5| Step: 5
Training loss: 3.550003083993351
Validation loss: 2.8122843970786344

Epoch: 5| Step: 6
Training loss: 2.148692167967372
Validation loss: 2.8095565342121445

Epoch: 5| Step: 7
Training loss: 2.6917029938347663
Validation loss: 2.8048046246536167

Epoch: 5| Step: 8
Training loss: 3.768225946888562
Validation loss: 2.814860810844524

Epoch: 5| Step: 9
Training loss: 2.940303357621262
Validation loss: 2.8039429402681417

Epoch: 5| Step: 10
Training loss: 2.984586538437095
Validation loss: 2.8098050412580733

Epoch: 29| Step: 0
Training loss: 3.2511436210925386
Validation loss: 2.803116919109554

Epoch: 5| Step: 1
Training loss: 2.6918009564074414
Validation loss: 2.801972683732642

Epoch: 5| Step: 2
Training loss: 2.885941458855822
Validation loss: 2.803194796224534

Epoch: 5| Step: 3
Training loss: 3.294279550332258
Validation loss: 2.807223444953724

Epoch: 5| Step: 4
Training loss: 2.938479645696704
Validation loss: 2.8094506836839397

Epoch: 5| Step: 5
Training loss: 3.5880778787638805
Validation loss: 2.8044251098615507

Epoch: 5| Step: 6
Training loss: 3.446692088886215
Validation loss: 2.797883423520009

Epoch: 5| Step: 7
Training loss: 2.4966075768330502
Validation loss: 2.800040741227072

Epoch: 5| Step: 8
Training loss: 2.878417761675671
Validation loss: 2.7954572644357016

Epoch: 5| Step: 9
Training loss: 3.298923091300689
Validation loss: 2.794832038142155

Epoch: 5| Step: 10
Training loss: 3.4122004898037845
Validation loss: 2.8014011384422504

Epoch: 30| Step: 0
Training loss: 3.577888980727413
Validation loss: 2.8005781719789904

Epoch: 5| Step: 1
Training loss: 2.7266576362342185
Validation loss: 2.810242202174452

Epoch: 5| Step: 2
Training loss: 2.796448744360244
Validation loss: 2.8047899665159552

Epoch: 5| Step: 3
Training loss: 3.1486525544962163
Validation loss: 2.801996182072486

Epoch: 5| Step: 4
Training loss: 3.524726986965317
Validation loss: 2.795118117305702

Epoch: 5| Step: 5
Training loss: 3.1913688965646014
Validation loss: 2.7923506252611654

Epoch: 5| Step: 6
Training loss: 3.1003640114967435
Validation loss: 2.7926593127496573

Epoch: 5| Step: 7
Training loss: 3.3508490667864748
Validation loss: 2.7885207711777156

Epoch: 5| Step: 8
Training loss: 2.514201549338195
Validation loss: 2.7907284528523215

Epoch: 5| Step: 9
Training loss: 3.217538253687193
Validation loss: 2.7887049165095523

Epoch: 5| Step: 10
Training loss: 2.9671428948254226
Validation loss: 2.796853876667158

Epoch: 31| Step: 0
Training loss: 2.9621990002657306
Validation loss: 2.7866283059378354

Epoch: 5| Step: 1
Training loss: 2.9519712424596203
Validation loss: 2.7909308862662736

Epoch: 5| Step: 2
Training loss: 3.4500931768688723
Validation loss: 2.788383886884244

Epoch: 5| Step: 3
Training loss: 3.1854173925152374
Validation loss: 2.7878167689271844

Epoch: 5| Step: 4
Training loss: 2.629685897056014
Validation loss: 2.7897203891501783

Epoch: 5| Step: 5
Training loss: 3.2323242172747855
Validation loss: 2.78861837463649

Epoch: 5| Step: 6
Training loss: 2.772374338891678
Validation loss: 2.78868834434131

Epoch: 5| Step: 7
Training loss: 2.8507339737062054
Validation loss: 2.7861264713272225

Epoch: 5| Step: 8
Training loss: 3.545841284868863
Validation loss: 2.787712112421094

Epoch: 5| Step: 9
Training loss: 2.9820051920159294
Validation loss: 2.7869127600896193

Epoch: 5| Step: 10
Training loss: 3.5263786812243456
Validation loss: 2.7834451568090772

Epoch: 32| Step: 0
Training loss: 3.3758943573662323
Validation loss: 2.7815875818336253

Epoch: 5| Step: 1
Training loss: 3.4720060170996074
Validation loss: 2.7838511307773093

Epoch: 5| Step: 2
Training loss: 3.1726023774879337
Validation loss: 2.77876359096669

Epoch: 5| Step: 3
Training loss: 2.915384028740327
Validation loss: 2.78311439290679

Epoch: 5| Step: 4
Training loss: 2.9314963491418062
Validation loss: 2.7773533645227397

Epoch: 5| Step: 5
Training loss: 3.0377969730083594
Validation loss: 2.784019618550691

Epoch: 5| Step: 6
Training loss: 3.0124023295037805
Validation loss: 2.7872630663470406

Epoch: 5| Step: 7
Training loss: 3.037138891536634
Validation loss: 2.7866563946072964

Epoch: 5| Step: 8
Training loss: 3.283985559838314
Validation loss: 2.784630643057359

Epoch: 5| Step: 9
Training loss: 2.7198764615894953
Validation loss: 2.7875248545943836

Epoch: 5| Step: 10
Training loss: 3.1585174573977777
Validation loss: 2.787313427892224

Epoch: 33| Step: 0
Training loss: 2.9433015388623427
Validation loss: 2.7842349710926175

Epoch: 5| Step: 1
Training loss: 2.456988845240944
Validation loss: 2.782407334781823

Epoch: 5| Step: 2
Training loss: 2.3806148212562777
Validation loss: 2.7796943224771704

Epoch: 5| Step: 3
Training loss: 3.4668798130484073
Validation loss: 2.786838665087343

Epoch: 5| Step: 4
Training loss: 3.301422887432787
Validation loss: 2.7875364324660157

Epoch: 5| Step: 5
Training loss: 3.4551363649521907
Validation loss: 2.783305262425964

Epoch: 5| Step: 6
Training loss: 3.2529972633985893
Validation loss: 2.7752611038363932

Epoch: 5| Step: 7
Training loss: 2.935064401781082
Validation loss: 2.7713976357975696

Epoch: 5| Step: 8
Training loss: 3.4760891367081386
Validation loss: 2.7700943801507742

Epoch: 5| Step: 9
Training loss: 3.0169368124146283
Validation loss: 2.773206697456666

Epoch: 5| Step: 10
Training loss: 3.1693474983130954
Validation loss: 2.7686257244684063

Epoch: 34| Step: 0
Training loss: 2.7335710488047544
Validation loss: 2.765323703845201

Epoch: 5| Step: 1
Training loss: 3.027077546259649
Validation loss: 2.7675911980093977

Epoch: 5| Step: 2
Training loss: 3.003923235027972
Validation loss: 2.7692888315985456

Epoch: 5| Step: 3
Training loss: 3.7572551480513794
Validation loss: 2.7652884389148045

Epoch: 5| Step: 4
Training loss: 3.2657323208198736
Validation loss: 2.7638972666304897

Epoch: 5| Step: 5
Training loss: 2.7976789118305145
Validation loss: 2.7607512218890298

Epoch: 5| Step: 6
Training loss: 3.0684718858668836
Validation loss: 2.76249065502455

Epoch: 5| Step: 7
Training loss: 2.694395224349984
Validation loss: 2.761614543345107

Epoch: 5| Step: 8
Training loss: 3.251252446567857
Validation loss: 2.7638833033243713

Epoch: 5| Step: 9
Training loss: 2.9037192205669005
Validation loss: 2.7579101835232653

Epoch: 5| Step: 10
Training loss: 3.347127616744823
Validation loss: 2.7579696095992405

Epoch: 35| Step: 0
Training loss: 3.033087890951372
Validation loss: 2.758001692455256

Epoch: 5| Step: 1
Training loss: 3.139916335285119
Validation loss: 2.7575361407403407

Epoch: 5| Step: 2
Training loss: 2.9921540340613824
Validation loss: 2.7573186685618603

Epoch: 5| Step: 3
Training loss: 3.0358906253920384
Validation loss: 2.759495117254767

Epoch: 5| Step: 4
Training loss: 2.6403340738060534
Validation loss: 2.7562401394554548

Epoch: 5| Step: 5
Training loss: 3.384312250994498
Validation loss: 2.7582920590237126

Epoch: 5| Step: 6
Training loss: 2.813286056874625
Validation loss: 2.755897154090183

Epoch: 5| Step: 7
Training loss: 3.3574636300304936
Validation loss: 2.758295451442777

Epoch: 5| Step: 8
Training loss: 2.7262535466691866
Validation loss: 2.7526229103521187

Epoch: 5| Step: 9
Training loss: 3.866471657823126
Validation loss: 2.7551410951490913

Epoch: 5| Step: 10
Training loss: 2.636143510023351
Validation loss: 2.753960884603639

Epoch: 36| Step: 0
Training loss: 3.4984390320120724
Validation loss: 2.751750826849929

Epoch: 5| Step: 1
Training loss: 2.546637120283533
Validation loss: 2.7501850364236597

Epoch: 5| Step: 2
Training loss: 3.0002304624409755
Validation loss: 2.7526766558647884

Epoch: 5| Step: 3
Training loss: 2.9980860008644017
Validation loss: 2.75678337040396

Epoch: 5| Step: 4
Training loss: 3.2442489504886307
Validation loss: 2.764508088060302

Epoch: 5| Step: 5
Training loss: 2.925094544276568
Validation loss: 2.770545314117581

Epoch: 5| Step: 6
Training loss: 2.8240237346764836
Validation loss: 2.7619624435829615

Epoch: 5| Step: 7
Training loss: 2.990998113909005
Validation loss: 2.7531846978634533

Epoch: 5| Step: 8
Training loss: 3.2817141250064124
Validation loss: 2.7523357105881994

Epoch: 5| Step: 9
Training loss: 3.5027088853953643
Validation loss: 2.748274432381415

Epoch: 5| Step: 10
Training loss: 2.8974925349010183
Validation loss: 2.7462039787044983

Epoch: 37| Step: 0
Training loss: 3.180981721788962
Validation loss: 2.7484067130913705

Epoch: 5| Step: 1
Training loss: 3.6168966814956516
Validation loss: 2.747216936305698

Epoch: 5| Step: 2
Training loss: 3.325353623709407
Validation loss: 2.749357921374599

Epoch: 5| Step: 3
Training loss: 2.7541322006708344
Validation loss: 2.748055290637656

Epoch: 5| Step: 4
Training loss: 3.3570500334919293
Validation loss: 2.7677240875323244

Epoch: 5| Step: 5
Training loss: 2.6408857408714015
Validation loss: 2.768343099206825

Epoch: 5| Step: 6
Training loss: 2.7001419807120177
Validation loss: 2.7551098815708053

Epoch: 5| Step: 7
Training loss: 2.9475535965593305
Validation loss: 2.7530673698820607

Epoch: 5| Step: 8
Training loss: 3.3210772901372576
Validation loss: 2.750227090030179

Epoch: 5| Step: 9
Training loss: 2.6366001130717565
Validation loss: 2.7490780805518042

Epoch: 5| Step: 10
Training loss: 3.134395817604799
Validation loss: 2.7476916987204723

Epoch: 38| Step: 0
Training loss: 2.390086693089223
Validation loss: 2.7369466381814016

Epoch: 5| Step: 1
Training loss: 3.169895099143692
Validation loss: 2.739805403377785

Epoch: 5| Step: 2
Training loss: 3.4524318638071567
Validation loss: 2.756949774263241

Epoch: 5| Step: 3
Training loss: 3.4173227626157296
Validation loss: 2.765351516645498

Epoch: 5| Step: 4
Training loss: 2.2891830048072372
Validation loss: 2.7745698162486234

Epoch: 5| Step: 5
Training loss: 3.183279946430441
Validation loss: 2.7705776075929087

Epoch: 5| Step: 6
Training loss: 3.6979507802903093
Validation loss: 2.7542490532644597

Epoch: 5| Step: 7
Training loss: 2.44653903803269
Validation loss: 2.741418305771423

Epoch: 5| Step: 8
Training loss: 3.0978121820482567
Validation loss: 2.7374593385875734

Epoch: 5| Step: 9
Training loss: 3.188359163468482
Validation loss: 2.7410448856840204

Epoch: 5| Step: 10
Training loss: 3.318020808397822
Validation loss: 2.7435985405932923

Epoch: 39| Step: 0
Training loss: 2.8339290179702883
Validation loss: 2.74997658407286

Epoch: 5| Step: 1
Training loss: 3.267484144830507
Validation loss: 2.761418938239825

Epoch: 5| Step: 2
Training loss: 3.5447229250732066
Validation loss: 2.750849103306992

Epoch: 5| Step: 3
Training loss: 2.623560647079192
Validation loss: 2.7324221775792124

Epoch: 5| Step: 4
Training loss: 3.070004202625492
Validation loss: 2.733467187150131

Epoch: 5| Step: 5
Training loss: 3.0363303801512114
Validation loss: 2.7275369561613734

Epoch: 5| Step: 6
Training loss: 3.182484289521593
Validation loss: 2.7264823399934306

Epoch: 5| Step: 7
Training loss: 2.708964484594877
Validation loss: 2.7273898233021794

Epoch: 5| Step: 8
Training loss: 3.1545399480646217
Validation loss: 2.72429336360083

Epoch: 5| Step: 9
Training loss: 2.4810957469123758
Validation loss: 2.7241797902556817

Epoch: 5| Step: 10
Training loss: 3.6237361941119004
Validation loss: 2.7235394729531612

Epoch: 40| Step: 0
Training loss: 2.8516705218195613
Validation loss: 2.7225998563251013

Epoch: 5| Step: 1
Training loss: 3.1961591200576263
Validation loss: 2.722559296902088

Epoch: 5| Step: 2
Training loss: 3.0930953440975957
Validation loss: 2.7211988154033158

Epoch: 5| Step: 3
Training loss: 3.0103276821479503
Validation loss: 2.7201991327502864

Epoch: 5| Step: 4
Training loss: 3.0815791389519793
Validation loss: 2.7242253790116893

Epoch: 5| Step: 5
Training loss: 3.2651136080033947
Validation loss: 2.7209226389879286

Epoch: 5| Step: 6
Training loss: 2.9572063681427747
Validation loss: 2.723908630368134

Epoch: 5| Step: 7
Training loss: 2.7937045748642486
Validation loss: 2.72184131562337

Epoch: 5| Step: 8
Training loss: 3.0218932473737303
Validation loss: 2.723243712028758

Epoch: 5| Step: 9
Training loss: 2.62363052975781
Validation loss: 2.7202047421827524

Epoch: 5| Step: 10
Training loss: 3.6490309434803443
Validation loss: 2.7302006316945033

Epoch: 41| Step: 0
Training loss: 3.168243283419013
Validation loss: 2.7276948537359775

Epoch: 5| Step: 1
Training loss: 3.4258110366970436
Validation loss: 2.7445374002693055

Epoch: 5| Step: 2
Training loss: 3.351573455010141
Validation loss: 2.7514033740672343

Epoch: 5| Step: 3
Training loss: 2.447372884751693
Validation loss: 2.73931801381974

Epoch: 5| Step: 4
Training loss: 3.16324889471984
Validation loss: 2.741428061251449

Epoch: 5| Step: 5
Training loss: 2.7255698421909216
Validation loss: 2.712469331255971

Epoch: 5| Step: 6
Training loss: 3.0185859651404447
Validation loss: 2.714233122963087

Epoch: 5| Step: 7
Training loss: 2.7662670015346125
Validation loss: 2.7148116264411026

Epoch: 5| Step: 8
Training loss: 3.0246614250937567
Validation loss: 2.7111414553994306

Epoch: 5| Step: 9
Training loss: 3.5842814558838256
Validation loss: 2.7131560393711767

Epoch: 5| Step: 10
Training loss: 2.6261910052711306
Validation loss: 2.7113188242267188

Epoch: 42| Step: 0
Training loss: 2.7464718293863926
Validation loss: 2.708719613773328

Epoch: 5| Step: 1
Training loss: 2.473218326653833
Validation loss: 2.707468897937314

Epoch: 5| Step: 2
Training loss: 3.8939569751966467
Validation loss: 2.710957217058349

Epoch: 5| Step: 3
Training loss: 2.9412736394202157
Validation loss: 2.7206450201583574

Epoch: 5| Step: 4
Training loss: 3.1342806527113902
Validation loss: 2.732428259648836

Epoch: 5| Step: 5
Training loss: 3.2985818069673307
Validation loss: 2.748081718427008

Epoch: 5| Step: 6
Training loss: 3.5816403906846364
Validation loss: 2.7529550618342684

Epoch: 5| Step: 7
Training loss: 2.186086470440704
Validation loss: 2.7301260285809823

Epoch: 5| Step: 8
Training loss: 2.4353514763488437
Validation loss: 2.7117582949067693

Epoch: 5| Step: 9
Training loss: 2.561902046219056
Validation loss: 2.7081802331201317

Epoch: 5| Step: 10
Training loss: 3.8303371966258997
Validation loss: 2.70544000437128

Epoch: 43| Step: 0
Training loss: 3.0807524180670183
Validation loss: 2.701792724219277

Epoch: 5| Step: 1
Training loss: 2.9452631210113887
Validation loss: 2.701514229880317

Epoch: 5| Step: 2
Training loss: 3.2242269491392297
Validation loss: 2.7021001755324905

Epoch: 5| Step: 3
Training loss: 3.0763502862449195
Validation loss: 2.7065578989670804

Epoch: 5| Step: 4
Training loss: 2.8970242985479002
Validation loss: 2.70347912790116

Epoch: 5| Step: 5
Training loss: 2.899718790560742
Validation loss: 2.706854078507519

Epoch: 5| Step: 6
Training loss: 2.814405431614677
Validation loss: 2.7143472248882343

Epoch: 5| Step: 7
Training loss: 3.160859924360107
Validation loss: 2.726954740713155

Epoch: 5| Step: 8
Training loss: 2.9808414971084574
Validation loss: 2.739167192634641

Epoch: 5| Step: 9
Training loss: 3.083199592645338
Validation loss: 2.715043018435141

Epoch: 5| Step: 10
Training loss: 3.259764308483482
Validation loss: 2.7123615321226726

Epoch: 44| Step: 0
Training loss: 3.0889605816480703
Validation loss: 2.712815526956738

Epoch: 5| Step: 1
Training loss: 3.1104407856119587
Validation loss: 2.7311827905918293

Epoch: 5| Step: 2
Training loss: 2.635405307991569
Validation loss: 2.7445246947690505

Epoch: 5| Step: 3
Training loss: 3.0236939314098454
Validation loss: 2.714654868256855

Epoch: 5| Step: 4
Training loss: 3.203441325129487
Validation loss: 2.6942021752566174

Epoch: 5| Step: 5
Training loss: 2.9600662922523897
Validation loss: 2.6901348139944306

Epoch: 5| Step: 6
Training loss: 2.554740975196488
Validation loss: 2.694017821431991

Epoch: 5| Step: 7
Training loss: 3.325232740015134
Validation loss: 2.6960110713060397

Epoch: 5| Step: 8
Training loss: 3.220192595224981
Validation loss: 2.701378951628346

Epoch: 5| Step: 9
Training loss: 3.280693370290519
Validation loss: 2.7014356189040587

Epoch: 5| Step: 10
Training loss: 2.9514925849998477
Validation loss: 2.70000297577746

Epoch: 45| Step: 0
Training loss: 2.7367052013117377
Validation loss: 2.6952418478131865

Epoch: 5| Step: 1
Training loss: 3.0988573244874145
Validation loss: 2.696174853387662

Epoch: 5| Step: 2
Training loss: 3.095716525749781
Validation loss: 2.694810624826135

Epoch: 5| Step: 3
Training loss: 2.90288849720365
Validation loss: 2.6935910727567305

Epoch: 5| Step: 4
Training loss: 3.430748152034834
Validation loss: 2.6890088801418504

Epoch: 5| Step: 5
Training loss: 2.8012660842563113
Validation loss: 2.6906816861100857

Epoch: 5| Step: 6
Training loss: 3.102687987012387
Validation loss: 2.7044151158522034

Epoch: 5| Step: 7
Training loss: 3.0697600277729844
Validation loss: 2.6931901967403364

Epoch: 5| Step: 8
Training loss: 3.26195381825101
Validation loss: 2.6933983600809386

Epoch: 5| Step: 9
Training loss: 2.619554684628297
Validation loss: 2.6860705802750187

Epoch: 5| Step: 10
Training loss: 3.2971043800721294
Validation loss: 2.6832893823387094

Epoch: 46| Step: 0
Training loss: 3.1998187609846616
Validation loss: 2.6838925583025115

Epoch: 5| Step: 1
Training loss: 3.098511701610089
Validation loss: 2.6847110709106587

Epoch: 5| Step: 2
Training loss: 2.9734127971767643
Validation loss: 2.6831915762232152

Epoch: 5| Step: 3
Training loss: 3.2188495509483857
Validation loss: 2.683242774183769

Epoch: 5| Step: 4
Training loss: 3.3010040027463554
Validation loss: 2.691003175562523

Epoch: 5| Step: 5
Training loss: 2.912362510481148
Validation loss: 2.69194594510068

Epoch: 5| Step: 6
Training loss: 1.896455711517427
Validation loss: 2.688248106916049

Epoch: 5| Step: 7
Training loss: 3.1242389515182865
Validation loss: 2.694695828850948

Epoch: 5| Step: 8
Training loss: 3.092033295258448
Validation loss: 2.6859025015787807

Epoch: 5| Step: 9
Training loss: 3.068874653384135
Validation loss: 2.6959091403589137

Epoch: 5| Step: 10
Training loss: 3.1592793043606364
Validation loss: 2.692724555883399

Epoch: 47| Step: 0
Training loss: 3.1314030470916645
Validation loss: 2.691805577393126

Epoch: 5| Step: 1
Training loss: 3.170429219691358
Validation loss: 2.684422984868969

Epoch: 5| Step: 2
Training loss: 3.2710986829546935
Validation loss: 2.687578792041823

Epoch: 5| Step: 3
Training loss: 2.8866997538807486
Validation loss: 2.6807904309972

Epoch: 5| Step: 4
Training loss: 2.9264956571050447
Validation loss: 2.686559221994646

Epoch: 5| Step: 5
Training loss: 3.236467062638887
Validation loss: 2.6801232912453226

Epoch: 5| Step: 6
Training loss: 2.546744220394932
Validation loss: 2.6767761091210422

Epoch: 5| Step: 7
Training loss: 2.9204563225874676
Validation loss: 2.679878580353124

Epoch: 5| Step: 8
Training loss: 3.1332639145432215
Validation loss: 2.6814771923171588

Epoch: 5| Step: 9
Training loss: 3.160068430582147
Validation loss: 2.6814937224633377

Epoch: 5| Step: 10
Training loss: 2.6459178360388216
Validation loss: 2.6727023122083384

Epoch: 48| Step: 0
Training loss: 2.552206345272913
Validation loss: 2.678742487182467

Epoch: 5| Step: 1
Training loss: 3.207728209133666
Validation loss: 2.6787949319890387

Epoch: 5| Step: 2
Training loss: 2.854080384521185
Validation loss: 2.674312276052772

Epoch: 5| Step: 3
Training loss: 3.359240578024647
Validation loss: 2.6740507947898458

Epoch: 5| Step: 4
Training loss: 2.312736086779528
Validation loss: 2.672085549176537

Epoch: 5| Step: 5
Training loss: 3.1305052520703023
Validation loss: 2.6741039523631986

Epoch: 5| Step: 6
Training loss: 3.4336869332403284
Validation loss: 2.678965274824666

Epoch: 5| Step: 7
Training loss: 3.0826386021301255
Validation loss: 2.693257791075445

Epoch: 5| Step: 8
Training loss: 2.6407489634653296
Validation loss: 2.703068441643016

Epoch: 5| Step: 9
Training loss: 3.233257155815529
Validation loss: 2.6848087357335855

Epoch: 5| Step: 10
Training loss: 3.201838239540314
Validation loss: 2.6698565849097986

Epoch: 49| Step: 0
Training loss: 2.978885094912425
Validation loss: 2.6752267580215867

Epoch: 5| Step: 1
Training loss: 3.083739915451675
Validation loss: 2.6654014332172973

Epoch: 5| Step: 2
Training loss: 3.1896204159950323
Validation loss: 2.6627281955831763

Epoch: 5| Step: 3
Training loss: 2.86174171765541
Validation loss: 2.665106226610891

Epoch: 5| Step: 4
Training loss: 3.3028257640464362
Validation loss: 2.6661192373102245

Epoch: 5| Step: 5
Training loss: 2.9525115168102176
Validation loss: 2.6613543732369362

Epoch: 5| Step: 6
Training loss: 3.153319858847521
Validation loss: 2.669517856615812

Epoch: 5| Step: 7
Training loss: 2.8007149362627612
Validation loss: 2.6626986455543307

Epoch: 5| Step: 8
Training loss: 2.9791450410782705
Validation loss: 2.6610713847863003

Epoch: 5| Step: 9
Training loss: 2.465330435559124
Validation loss: 2.6637182323919277

Epoch: 5| Step: 10
Training loss: 3.205600433285224
Validation loss: 2.6608390125253503

Epoch: 50| Step: 0
Training loss: 2.845263570902146
Validation loss: 2.6681167190840602

Epoch: 5| Step: 1
Training loss: 2.7971677147475926
Validation loss: 2.685969370671549

Epoch: 5| Step: 2
Training loss: 2.990754822849976
Validation loss: 2.683129687547394

Epoch: 5| Step: 3
Training loss: 3.2223020046778026
Validation loss: 2.6792792562335572

Epoch: 5| Step: 4
Training loss: 2.8049334149948963
Validation loss: 2.67581458080333

Epoch: 5| Step: 5
Training loss: 2.9308026848879782
Validation loss: 2.662683219561866

Epoch: 5| Step: 6
Training loss: 3.2699608742709287
Validation loss: 2.6556416827760083

Epoch: 5| Step: 7
Training loss: 3.4438668676024657
Validation loss: 2.655456049840846

Epoch: 5| Step: 8
Training loss: 2.6612282272172085
Validation loss: 2.6581917457113677

Epoch: 5| Step: 9
Training loss: 2.7949955768584327
Validation loss: 2.658073475958305

Epoch: 5| Step: 10
Training loss: 3.2367841068992065
Validation loss: 2.660462670603782

Epoch: 51| Step: 0
Training loss: 2.7400003171489002
Validation loss: 2.6592404869686446

Epoch: 5| Step: 1
Training loss: 2.8567784928549798
Validation loss: 2.6616858528855736

Epoch: 5| Step: 2
Training loss: 3.1184227964805964
Validation loss: 2.658124175902044

Epoch: 5| Step: 3
Training loss: 3.4150591689606844
Validation loss: 2.655897265954568

Epoch: 5| Step: 4
Training loss: 2.554027413767017
Validation loss: 2.654350507857571

Epoch: 5| Step: 5
Training loss: 3.1833831530229273
Validation loss: 2.6531650897076635

Epoch: 5| Step: 6
Training loss: 3.0486848591019027
Validation loss: 2.6520019573928977

Epoch: 5| Step: 7
Training loss: 2.2204225710189447
Validation loss: 2.6527232249127195

Epoch: 5| Step: 8
Training loss: 3.242163674140618
Validation loss: 2.6503693449970194

Epoch: 5| Step: 9
Training loss: 3.205884684372953
Validation loss: 2.6489167046858086

Epoch: 5| Step: 10
Training loss: 3.3106557642490513
Validation loss: 2.652496544682211

Epoch: 52| Step: 0
Training loss: 3.1809517411448085
Validation loss: 2.6585064303325634

Epoch: 5| Step: 1
Training loss: 2.9041564948525482
Validation loss: 2.649532963589979

Epoch: 5| Step: 2
Training loss: 3.380482635575321
Validation loss: 2.65200454326405

Epoch: 5| Step: 3
Training loss: 2.961234608743458
Validation loss: 2.646379310978366

Epoch: 5| Step: 4
Training loss: 3.4056530350602134
Validation loss: 2.653364401815939

Epoch: 5| Step: 5
Training loss: 2.561076443378472
Validation loss: 2.647580722242615

Epoch: 5| Step: 6
Training loss: 2.799296689259338
Validation loss: 2.6519732371366795

Epoch: 5| Step: 7
Training loss: 2.328252904053938
Validation loss: 2.6467609525116638

Epoch: 5| Step: 8
Training loss: 2.5923387295951006
Validation loss: 2.645634806920816

Epoch: 5| Step: 9
Training loss: 3.2832567164071285
Validation loss: 2.643593972600087

Epoch: 5| Step: 10
Training loss: 3.447855523403803
Validation loss: 2.6434538459588848

Epoch: 53| Step: 0
Training loss: 2.8224506251541595
Validation loss: 2.647000827867107

Epoch: 5| Step: 1
Training loss: 3.244060958628228
Validation loss: 2.642162611473688

Epoch: 5| Step: 2
Training loss: 3.3110161102741733
Validation loss: 2.6437221421195343

Epoch: 5| Step: 3
Training loss: 2.3790519682253874
Validation loss: 2.6481998845321977

Epoch: 5| Step: 4
Training loss: 3.14797977878227
Validation loss: 2.6502635363508324

Epoch: 5| Step: 5
Training loss: 3.255058899564834
Validation loss: 2.64444288563989

Epoch: 5| Step: 6
Training loss: 2.9520366621041036
Validation loss: 2.6551627262860644

Epoch: 5| Step: 7
Training loss: 2.3863055531752915
Validation loss: 2.6498608975035753

Epoch: 5| Step: 8
Training loss: 2.511665687771788
Validation loss: 2.648160247611912

Epoch: 5| Step: 9
Training loss: 3.370093558622975
Validation loss: 2.6399603372044957

Epoch: 5| Step: 10
Training loss: 3.284275658118658
Validation loss: 2.6422148062635165

Epoch: 54| Step: 0
Training loss: 3.199899528833508
Validation loss: 2.6350078999381332

Epoch: 5| Step: 1
Training loss: 2.358058536906275
Validation loss: 2.6507255705340302

Epoch: 5| Step: 2
Training loss: 3.464886137177312
Validation loss: 2.6451682825493807

Epoch: 5| Step: 3
Training loss: 2.629376078959743
Validation loss: 2.643431228987866

Epoch: 5| Step: 4
Training loss: 3.0514981139500836
Validation loss: 2.6370256332411928

Epoch: 5| Step: 5
Training loss: 3.098019976625995
Validation loss: 2.637861992281334

Epoch: 5| Step: 6
Training loss: 2.910400380385061
Validation loss: 2.648883781616182

Epoch: 5| Step: 7
Training loss: 3.2253258947081913
Validation loss: 2.642258223191001

Epoch: 5| Step: 8
Training loss: 3.1585817693935536
Validation loss: 2.6478476930417383

Epoch: 5| Step: 9
Training loss: 2.7252727617013655
Validation loss: 2.6439602259410275

Epoch: 5| Step: 10
Training loss: 2.7831650045360883
Validation loss: 2.6366226729340796

Epoch: 55| Step: 0
Training loss: 2.8646553354173103
Validation loss: 2.6460086556747275

Epoch: 5| Step: 1
Training loss: 3.597119418671365
Validation loss: 2.6404187900495493

Epoch: 5| Step: 2
Training loss: 2.7703619438875458
Validation loss: 2.641051621356653

Epoch: 5| Step: 3
Training loss: 3.1964371993914287
Validation loss: 2.634741961407441

Epoch: 5| Step: 4
Training loss: 2.8224055166454423
Validation loss: 2.6304139016221755

Epoch: 5| Step: 5
Training loss: 3.1732726376870395
Validation loss: 2.6282777786987657

Epoch: 5| Step: 6
Training loss: 2.9478936256254107
Validation loss: 2.635524195193912

Epoch: 5| Step: 7
Training loss: 2.6673204296130146
Validation loss: 2.6313490392245824

Epoch: 5| Step: 8
Training loss: 3.1011324567556384
Validation loss: 2.6339839912886283

Epoch: 5| Step: 9
Training loss: 2.4693360417758323
Validation loss: 2.631720773389198

Epoch: 5| Step: 10
Training loss: 2.989842065831117
Validation loss: 2.6282216112353023

Epoch: 56| Step: 0
Training loss: 2.8079435102480934
Validation loss: 2.6283995222836345

Epoch: 5| Step: 1
Training loss: 3.1711424935432135
Validation loss: 2.6334234574148954

Epoch: 5| Step: 2
Training loss: 2.752743826035642
Validation loss: 2.635422992872993

Epoch: 5| Step: 3
Training loss: 2.562414958752271
Validation loss: 2.6386974231435323

Epoch: 5| Step: 4
Training loss: 2.64152222688744
Validation loss: 2.647926351177229

Epoch: 5| Step: 5
Training loss: 2.791456888392407
Validation loss: 2.6472346927710193

Epoch: 5| Step: 6
Training loss: 2.8322888487371243
Validation loss: 2.650354528210409

Epoch: 5| Step: 7
Training loss: 2.9512870761040197
Validation loss: 2.6366882803739036

Epoch: 5| Step: 8
Training loss: 3.459782185837354
Validation loss: 2.6393919355367075

Epoch: 5| Step: 9
Training loss: 3.422336494992995
Validation loss: 2.62902575483939

Epoch: 5| Step: 10
Training loss: 3.2712174856153786
Validation loss: 2.627150114515574

Epoch: 57| Step: 0
Training loss: 3.0604457582909257
Validation loss: 2.631698455954694

Epoch: 5| Step: 1
Training loss: 3.009832164863106
Validation loss: 2.6340658440364897

Epoch: 5| Step: 2
Training loss: 3.1713997621099175
Validation loss: 2.6379892984113003

Epoch: 5| Step: 3
Training loss: 2.534565296860405
Validation loss: 2.636691830709204

Epoch: 5| Step: 4
Training loss: 3.3643945851642636
Validation loss: 2.625415191004985

Epoch: 5| Step: 5
Training loss: 2.904198199137002
Validation loss: 2.623356751622537

Epoch: 5| Step: 6
Training loss: 2.609305375135392
Validation loss: 2.628555062538019

Epoch: 5| Step: 7
Training loss: 3.179563327773527
Validation loss: 2.6362780583036085

Epoch: 5| Step: 8
Training loss: 3.1736403189626747
Validation loss: 2.652604741299027

Epoch: 5| Step: 9
Training loss: 3.1131293093412755
Validation loss: 2.6683920814492157

Epoch: 5| Step: 10
Training loss: 2.6005803450876313
Validation loss: 2.6517468746705504

Epoch: 58| Step: 0
Training loss: 3.3248535697645356
Validation loss: 2.6433487933831707

Epoch: 5| Step: 1
Training loss: 2.832863899686236
Validation loss: 2.6211694484237973

Epoch: 5| Step: 2
Training loss: 3.2188896963674245
Validation loss: 2.623887175334529

Epoch: 5| Step: 3
Training loss: 3.3088760705902693
Validation loss: 2.619501365975428

Epoch: 5| Step: 4
Training loss: 3.1445696147213233
Validation loss: 2.621206203369067

Epoch: 5| Step: 5
Training loss: 2.5529885898787854
Validation loss: 2.6213149159643976

Epoch: 5| Step: 6
Training loss: 2.863797129622451
Validation loss: 2.6213203947032335

Epoch: 5| Step: 7
Training loss: 2.908397742344286
Validation loss: 2.6183013646847475

Epoch: 5| Step: 8
Training loss: 2.5494067006759944
Validation loss: 2.619377246486092

Epoch: 5| Step: 9
Training loss: 2.822375612854643
Validation loss: 2.628022720792973

Epoch: 5| Step: 10
Training loss: 3.038841102204227
Validation loss: 2.6469425637407493

Epoch: 59| Step: 0
Training loss: 2.8138890544978756
Validation loss: 2.6604498276177715

Epoch: 5| Step: 1
Training loss: 3.061336374119612
Validation loss: 2.625678790645967

Epoch: 5| Step: 2
Training loss: 2.969697660476755
Validation loss: 2.622945086680104

Epoch: 5| Step: 3
Training loss: 3.08844417699061
Validation loss: 2.6166557074163754

Epoch: 5| Step: 4
Training loss: 2.584213927114733
Validation loss: 2.615202431666456

Epoch: 5| Step: 5
Training loss: 3.501802525258002
Validation loss: 2.612211859909837

Epoch: 5| Step: 6
Training loss: 2.8639929330621405
Validation loss: 2.6108271410873534

Epoch: 5| Step: 7
Training loss: 2.8289473376046486
Validation loss: 2.612714277773677

Epoch: 5| Step: 8
Training loss: 3.4002366488508526
Validation loss: 2.614299656480251

Epoch: 5| Step: 9
Training loss: 2.3359255583084706
Validation loss: 2.615395984485513

Epoch: 5| Step: 10
Training loss: 3.1080966794602882
Validation loss: 2.6205772012071007

Epoch: 60| Step: 0
Training loss: 3.122316658006713
Validation loss: 2.6337701246236773

Epoch: 5| Step: 1
Training loss: 2.8011811421828474
Validation loss: 2.640115953769015

Epoch: 5| Step: 2
Training loss: 3.0657309790908314
Validation loss: 2.6273511376557783

Epoch: 5| Step: 3
Training loss: 3.442276981972496
Validation loss: 2.621031709620859

Epoch: 5| Step: 4
Training loss: 2.7591447503008597
Validation loss: 2.6230613456367666

Epoch: 5| Step: 5
Training loss: 2.9371814960930167
Validation loss: 2.608239984976386

Epoch: 5| Step: 6
Training loss: 3.225810778522666
Validation loss: 2.6057326191564765

Epoch: 5| Step: 7
Training loss: 2.7612037448281286
Validation loss: 2.606546438029521

Epoch: 5| Step: 8
Training loss: 2.9411025986089694
Validation loss: 2.6074587322950142

Epoch: 5| Step: 9
Training loss: 2.8591785467648347
Validation loss: 2.606585718322684

Epoch: 5| Step: 10
Training loss: 2.654960049833319
Validation loss: 2.603049419984859

Epoch: 61| Step: 0
Training loss: 3.0332419545868605
Validation loss: 2.615941359326548

Epoch: 5| Step: 1
Training loss: 2.8432663726375487
Validation loss: 2.615098469030264

Epoch: 5| Step: 2
Training loss: 3.2413287760572933
Validation loss: 2.6158548722861252

Epoch: 5| Step: 3
Training loss: 2.4022979980081844
Validation loss: 2.605241537114798

Epoch: 5| Step: 4
Training loss: 3.2906561318398397
Validation loss: 2.608087597513751

Epoch: 5| Step: 5
Training loss: 2.6352853453313854
Validation loss: 2.6020215081713394

Epoch: 5| Step: 6
Training loss: 3.2994627717576015
Validation loss: 2.601488933159287

Epoch: 5| Step: 7
Training loss: 2.9242164083884727
Validation loss: 2.603525187250464

Epoch: 5| Step: 8
Training loss: 2.765141676572127
Validation loss: 2.6051090397618335

Epoch: 5| Step: 9
Training loss: 2.2424127020370994
Validation loss: 2.6017928995326423

Epoch: 5| Step: 10
Training loss: 3.744636260067838
Validation loss: 2.5994610655416

Epoch: 62| Step: 0
Training loss: 2.975134960286909
Validation loss: 2.6037309448621837

Epoch: 5| Step: 1
Training loss: 3.12800423220375
Validation loss: 2.6082677301468373

Epoch: 5| Step: 2
Training loss: 2.8000633777530095
Validation loss: 2.623272429394073

Epoch: 5| Step: 3
Training loss: 3.5868519799197864
Validation loss: 2.6495578313005064

Epoch: 5| Step: 4
Training loss: 3.145046935830475
Validation loss: 2.619181214951042

Epoch: 5| Step: 5
Training loss: 2.719963416807206
Validation loss: 2.606658530567078

Epoch: 5| Step: 6
Training loss: 2.4523018591864534
Validation loss: 2.599454635378887

Epoch: 5| Step: 7
Training loss: 3.240805899151716
Validation loss: 2.5980467341305835

Epoch: 5| Step: 8
Training loss: 2.6341489574975907
Validation loss: 2.604694379600376

Epoch: 5| Step: 9
Training loss: 2.5433142173951966
Validation loss: 2.6004689448425715

Epoch: 5| Step: 10
Training loss: 3.163971624128993
Validation loss: 2.5954785518161416

Epoch: 63| Step: 0
Training loss: 2.571676802385505
Validation loss: 2.5965045496162173

Epoch: 5| Step: 1
Training loss: 3.050497083336474
Validation loss: 2.5986772535211746

Epoch: 5| Step: 2
Training loss: 3.5463479612560143
Validation loss: 2.5979443264774336

Epoch: 5| Step: 3
Training loss: 2.7480610167268944
Validation loss: 2.607897078545377

Epoch: 5| Step: 4
Training loss: 3.1120865083747127
Validation loss: 2.6031881023809116

Epoch: 5| Step: 5
Training loss: 2.776782787989072
Validation loss: 2.6069162481122388

Epoch: 5| Step: 6
Training loss: 2.716785378778022
Validation loss: 2.6220843202026547

Epoch: 5| Step: 7
Training loss: 3.1078825009202595
Validation loss: 2.629805922125315

Epoch: 5| Step: 8
Training loss: 2.8995888780344523
Validation loss: 2.6422970181949808

Epoch: 5| Step: 9
Training loss: 3.2738019426266303
Validation loss: 2.618179560835059

Epoch: 5| Step: 10
Training loss: 2.4204735423444426
Validation loss: 2.6082395426710803

Epoch: 64| Step: 0
Training loss: 3.0441603867613725
Validation loss: 2.6020251506365404

Epoch: 5| Step: 1
Training loss: 3.0603717493371008
Validation loss: 2.5927073654804307

Epoch: 5| Step: 2
Training loss: 3.1452570675827434
Validation loss: 2.597312969822973

Epoch: 5| Step: 3
Training loss: 2.4014867230822112
Validation loss: 2.5984282623283286

Epoch: 5| Step: 4
Training loss: 2.9916564629539244
Validation loss: 2.5983293131217895

Epoch: 5| Step: 5
Training loss: 3.374455302046577
Validation loss: 2.594308701303152

Epoch: 5| Step: 6
Training loss: 3.134849285780046
Validation loss: 2.6004063966240194

Epoch: 5| Step: 7
Training loss: 2.7524415361811436
Validation loss: 2.6007078408207582

Epoch: 5| Step: 8
Training loss: 2.99651404346095
Validation loss: 2.5976975220504053

Epoch: 5| Step: 9
Training loss: 2.6031124778711985
Validation loss: 2.6077086455619933

Epoch: 5| Step: 10
Training loss: 2.9029957589576116
Validation loss: 2.609331777704791

Epoch: 65| Step: 0
Training loss: 3.3115001105046877
Validation loss: 2.6043979258245966

Epoch: 5| Step: 1
Training loss: 2.823066529147112
Validation loss: 2.6124800703141573

Epoch: 5| Step: 2
Training loss: 2.789985055370708
Validation loss: 2.6187150973872892

Epoch: 5| Step: 3
Training loss: 3.1002069773334697
Validation loss: 2.620441844799664

Epoch: 5| Step: 4
Training loss: 2.92528119162053
Validation loss: 2.5942915632631127

Epoch: 5| Step: 5
Training loss: 3.0831282951295615
Validation loss: 2.6006564345786947

Epoch: 5| Step: 6
Training loss: 2.439534243234469
Validation loss: 2.586157064965559

Epoch: 5| Step: 7
Training loss: 2.9946877812597696
Validation loss: 2.5855458563441838

Epoch: 5| Step: 8
Training loss: 3.078987426771787
Validation loss: 2.588241888265933

Epoch: 5| Step: 9
Training loss: 2.574977641332646
Validation loss: 2.5875368619075236

Epoch: 5| Step: 10
Training loss: 3.2460822921165113
Validation loss: 2.5858638177807483

Epoch: 66| Step: 0
Training loss: 2.8734408587570432
Validation loss: 2.5856502204727154

Epoch: 5| Step: 1
Training loss: 3.087730331169233
Validation loss: 2.5923679414234786

Epoch: 5| Step: 2
Training loss: 3.1230659603563957
Validation loss: 2.585583448856503

Epoch: 5| Step: 3
Training loss: 2.894333229035358
Validation loss: 2.5846733451067445

Epoch: 5| Step: 4
Training loss: 2.8313206274389566
Validation loss: 2.584088308133081

Epoch: 5| Step: 5
Training loss: 3.1737274623459752
Validation loss: 2.5849574921506435

Epoch: 5| Step: 6
Training loss: 2.8332050705843486
Validation loss: 2.5834667185930003

Epoch: 5| Step: 7
Training loss: 2.6764075666971445
Validation loss: 2.5929804595754153

Epoch: 5| Step: 8
Training loss: 2.726184720425748
Validation loss: 2.5920052865627214

Epoch: 5| Step: 9
Training loss: 3.2667256375913154
Validation loss: 2.6072123447447977

Epoch: 5| Step: 10
Training loss: 2.9296225578739667
Validation loss: 2.6140937564160662

Epoch: 67| Step: 0
Training loss: 2.5060656396500023
Validation loss: 2.61730389618586

Epoch: 5| Step: 1
Training loss: 2.607895665931121
Validation loss: 2.6472921157062963

Epoch: 5| Step: 2
Training loss: 3.0199585448192425
Validation loss: 2.6288930490384157

Epoch: 5| Step: 3
Training loss: 2.9902321424918186
Validation loss: 2.6380905334738585

Epoch: 5| Step: 4
Training loss: 2.671831721797477
Validation loss: 2.5962867296482277

Epoch: 5| Step: 5
Training loss: 2.8929277475342543
Validation loss: 2.5840780598531774

Epoch: 5| Step: 6
Training loss: 2.8726641246365077
Validation loss: 2.5758482634092172

Epoch: 5| Step: 7
Training loss: 3.3557657414586988
Validation loss: 2.583400684422141

Epoch: 5| Step: 8
Training loss: 2.918134610570204
Validation loss: 2.5817563830590213

Epoch: 5| Step: 9
Training loss: 3.291577172974155
Validation loss: 2.5840978738190445

Epoch: 5| Step: 10
Training loss: 3.2142005545824492
Validation loss: 2.581955190494614

Epoch: 68| Step: 0
Training loss: 2.667469698475534
Validation loss: 2.5780401251312357

Epoch: 5| Step: 1
Training loss: 2.4046749558347784
Validation loss: 2.58077112199389

Epoch: 5| Step: 2
Training loss: 2.525596049746305
Validation loss: 2.5754475034368625

Epoch: 5| Step: 3
Training loss: 3.015294506562122
Validation loss: 2.5823627902144577

Epoch: 5| Step: 4
Training loss: 2.938520538315423
Validation loss: 2.598344947524668

Epoch: 5| Step: 5
Training loss: 3.155102058368043
Validation loss: 2.6296586937316992

Epoch: 5| Step: 6
Training loss: 3.2956128348479217
Validation loss: 2.643188422581247

Epoch: 5| Step: 7
Training loss: 3.3172482701043426
Validation loss: 2.6195601856430177

Epoch: 5| Step: 8
Training loss: 3.1530393379000548
Validation loss: 2.594220796376397

Epoch: 5| Step: 9
Training loss: 2.807138885889049
Validation loss: 2.5755076875519856

Epoch: 5| Step: 10
Training loss: 3.063460530271645
Validation loss: 2.5753404034495984

Epoch: 69| Step: 0
Training loss: 2.8580617755275926
Validation loss: 2.5744756700206963

Epoch: 5| Step: 1
Training loss: 3.119458893534606
Validation loss: 2.574653273242051

Epoch: 5| Step: 2
Training loss: 3.3020921259782057
Validation loss: 2.5787608188284916

Epoch: 5| Step: 3
Training loss: 2.717298361308323
Validation loss: 2.5757158654473526

Epoch: 5| Step: 4
Training loss: 3.2649165941132576
Validation loss: 2.575877472155658

Epoch: 5| Step: 5
Training loss: 2.9205662045151546
Validation loss: 2.5763315515182286

Epoch: 5| Step: 6
Training loss: 2.8008198968197484
Validation loss: 2.5732690896029404

Epoch: 5| Step: 7
Training loss: 2.930173787766465
Validation loss: 2.5678513178075097

Epoch: 5| Step: 8
Training loss: 2.6969709076519885
Validation loss: 2.5727740201698106

Epoch: 5| Step: 9
Training loss: 2.9793924810730146
Validation loss: 2.5808097163125345

Epoch: 5| Step: 10
Training loss: 2.6203404806664228
Validation loss: 2.584485673935859

Epoch: 70| Step: 0
Training loss: 2.553898960872131
Validation loss: 2.615748978854105

Epoch: 5| Step: 1
Training loss: 2.8648196221202404
Validation loss: 2.633155858544523

Epoch: 5| Step: 2
Training loss: 3.202910923200645
Validation loss: 2.636545306250943

Epoch: 5| Step: 3
Training loss: 2.3193793170285377
Validation loss: 2.58492898899796

Epoch: 5| Step: 4
Training loss: 2.6452287799275016
Validation loss: 2.569814346044272

Epoch: 5| Step: 5
Training loss: 3.135947468755565
Validation loss: 2.567979599899494

Epoch: 5| Step: 6
Training loss: 2.6652941052328383
Validation loss: 2.569279356573989

Epoch: 5| Step: 7
Training loss: 2.9452937198920495
Validation loss: 2.5691437093410534

Epoch: 5| Step: 8
Training loss: 3.2030291287100767
Validation loss: 2.5712062023678346

Epoch: 5| Step: 9
Training loss: 3.4812187645433728
Validation loss: 2.572406283915141

Epoch: 5| Step: 10
Training loss: 3.099047662211521
Validation loss: 2.570971531165961

Epoch: 71| Step: 0
Training loss: 3.183879366741216
Validation loss: 2.572304090300619

Epoch: 5| Step: 1
Training loss: 2.6957022122584857
Validation loss: 2.571478545190313

Epoch: 5| Step: 2
Training loss: 2.9266867770617053
Validation loss: 2.563344834685128

Epoch: 5| Step: 3
Training loss: 2.710106450203672
Validation loss: 2.5592526915336355

Epoch: 5| Step: 4
Training loss: 2.79226278706274
Validation loss: 2.5815349452667755

Epoch: 5| Step: 5
Training loss: 2.8020952831897454
Validation loss: 2.5762693258020604

Epoch: 5| Step: 6
Training loss: 3.4751581334421604
Validation loss: 2.5746256368109774

Epoch: 5| Step: 7
Training loss: 2.682520578239698
Validation loss: 2.591272410500493

Epoch: 5| Step: 8
Training loss: 3.150257578415417
Validation loss: 2.580545828526483

Epoch: 5| Step: 9
Training loss: 2.8339845432568005
Validation loss: 2.573585243705246

Epoch: 5| Step: 10
Training loss: 2.8486192537494426
Validation loss: 2.575796231647743

Epoch: 72| Step: 0
Training loss: 3.07064840794296
Validation loss: 2.5608480707848806

Epoch: 5| Step: 1
Training loss: 2.3358201217504564
Validation loss: 2.559393924378379

Epoch: 5| Step: 2
Training loss: 2.858950724158089
Validation loss: 2.5584241444974376

Epoch: 5| Step: 3
Training loss: 3.2687234735233117
Validation loss: 2.5568318610365597

Epoch: 5| Step: 4
Training loss: 2.664755901587454
Validation loss: 2.5601341697344053

Epoch: 5| Step: 5
Training loss: 2.7893421877008726
Validation loss: 2.559199596105327

Epoch: 5| Step: 6
Training loss: 3.106528968488088
Validation loss: 2.5623453305174593

Epoch: 5| Step: 7
Training loss: 2.8623543314954496
Validation loss: 2.5576670862549027

Epoch: 5| Step: 8
Training loss: 3.2538685882330505
Validation loss: 2.564807304284882

Epoch: 5| Step: 9
Training loss: 3.08165820901665
Validation loss: 2.571165168135667

Epoch: 5| Step: 10
Training loss: 2.6871412170803803
Validation loss: 2.5760814364740856

Epoch: 73| Step: 0
Training loss: 2.6228997138831165
Validation loss: 2.58855336138079

Epoch: 5| Step: 1
Training loss: 2.657029968638281
Validation loss: 2.629546348352537

Epoch: 5| Step: 2
Training loss: 2.929117783147142
Validation loss: 2.662752429789617

Epoch: 5| Step: 3
Training loss: 3.314325513389355
Validation loss: 2.618996443319741

Epoch: 5| Step: 4
Training loss: 2.301767238359731
Validation loss: 2.585198108119756

Epoch: 5| Step: 5
Training loss: 3.061513780885887
Validation loss: 2.560963322737773

Epoch: 5| Step: 6
Training loss: 2.7336293975084414
Validation loss: 2.5543233825155154

Epoch: 5| Step: 7
Training loss: 2.8299200778634592
Validation loss: 2.551878521159277

Epoch: 5| Step: 8
Training loss: 3.575374295574463
Validation loss: 2.556473499216184

Epoch: 5| Step: 9
Training loss: 3.2231655019035452
Validation loss: 2.5623944448625045

Epoch: 5| Step: 10
Training loss: 2.7103330614437553
Validation loss: 2.5611202968663163

Epoch: 74| Step: 0
Training loss: 2.6415622108898864
Validation loss: 2.556617407499574

Epoch: 5| Step: 1
Training loss: 2.8337918826770205
Validation loss: 2.549938805827301

Epoch: 5| Step: 2
Training loss: 3.106563811693796
Validation loss: 2.54785910091688

Epoch: 5| Step: 3
Training loss: 3.4150020607178306
Validation loss: 2.5528061041472427

Epoch: 5| Step: 4
Training loss: 3.11071825006879
Validation loss: 2.5736123085751523

Epoch: 5| Step: 5
Training loss: 2.9928169086507874
Validation loss: 2.6325285195987966

Epoch: 5| Step: 6
Training loss: 2.8200401956656003
Validation loss: 2.6577089784728725

Epoch: 5| Step: 7
Training loss: 3.129811359607559
Validation loss: 2.642899970789565

Epoch: 5| Step: 8
Training loss: 2.464915811056622
Validation loss: 2.6058261005961003

Epoch: 5| Step: 9
Training loss: 2.812741671881376
Validation loss: 2.571131874639104

Epoch: 5| Step: 10
Training loss: 2.8497838992456783
Validation loss: 2.5582869456542485

Epoch: 75| Step: 0
Training loss: 3.5841832742407536
Validation loss: 2.5454366772078063

Epoch: 5| Step: 1
Training loss: 2.844025315591888
Validation loss: 2.548211701243741

Epoch: 5| Step: 2
Training loss: 2.693730694553383
Validation loss: 2.553439586119381

Epoch: 5| Step: 3
Training loss: 2.755561926109716
Validation loss: 2.5616362641958332

Epoch: 5| Step: 4
Training loss: 3.165908538682881
Validation loss: 2.562103414873093

Epoch: 5| Step: 5
Training loss: 3.131996562229964
Validation loss: 2.5611432493283446

Epoch: 5| Step: 6
Training loss: 2.848896776797754
Validation loss: 2.556245672159758

Epoch: 5| Step: 7
Training loss: 3.2569767819995104
Validation loss: 2.5524855343030106

Epoch: 5| Step: 8
Training loss: 2.278566846659282
Validation loss: 2.560507208824625

Epoch: 5| Step: 9
Training loss: 2.8903961915882994
Validation loss: 2.5851271686631283

Epoch: 5| Step: 10
Training loss: 2.6197071301956725
Validation loss: 2.604002423101028

Epoch: 76| Step: 0
Training loss: 2.318452648417233
Validation loss: 2.589006477088627

Epoch: 5| Step: 1
Training loss: 3.278735841581641
Validation loss: 2.5858367839834613

Epoch: 5| Step: 2
Training loss: 2.7260607063659608
Validation loss: 2.584558175399105

Epoch: 5| Step: 3
Training loss: 2.8526418654981858
Validation loss: 2.5619520966733

Epoch: 5| Step: 4
Training loss: 3.4042370649238958
Validation loss: 2.56497153228728

Epoch: 5| Step: 5
Training loss: 2.7625271101091724
Validation loss: 2.5519999609549653

Epoch: 5| Step: 6
Training loss: 2.6883777693095103
Validation loss: 2.5492553388110406

Epoch: 5| Step: 7
Training loss: 3.250914665038563
Validation loss: 2.5425030283566503

Epoch: 5| Step: 8
Training loss: 2.8875019420270456
Validation loss: 2.538213553415473

Epoch: 5| Step: 9
Training loss: 3.0017841120281465
Validation loss: 2.5451784818059773

Epoch: 5| Step: 10
Training loss: 2.6562514361209355
Validation loss: 2.5495148498645066

Epoch: 77| Step: 0
Training loss: 2.888737572676678
Validation loss: 2.5544958776256963

Epoch: 5| Step: 1
Training loss: 3.298922657670826
Validation loss: 2.549946704028464

Epoch: 5| Step: 2
Training loss: 2.793196576836619
Validation loss: 2.5542575223082937

Epoch: 5| Step: 3
Training loss: 3.182018128837958
Validation loss: 2.5499568793607805

Epoch: 5| Step: 4
Training loss: 2.948892941699309
Validation loss: 2.547573613587339

Epoch: 5| Step: 5
Training loss: 3.0400895685252043
Validation loss: 2.544940278308129

Epoch: 5| Step: 6
Training loss: 2.499815934080881
Validation loss: 2.541352010649816

Epoch: 5| Step: 7
Training loss: 3.1483619245446297
Validation loss: 2.5450419005728606

Epoch: 5| Step: 8
Training loss: 2.7514698262072237
Validation loss: 2.5430711194106443

Epoch: 5| Step: 9
Training loss: 2.2592920649543355
Validation loss: 2.536909680573614

Epoch: 5| Step: 10
Training loss: 3.2220866861740722
Validation loss: 2.5347284257848184

Epoch: 78| Step: 0
Training loss: 2.57506773035545
Validation loss: 2.5447075581791476

Epoch: 5| Step: 1
Training loss: 2.645950815390993
Validation loss: 2.5596152644766894

Epoch: 5| Step: 2
Training loss: 2.6463387875084106
Validation loss: 2.568595512480571

Epoch: 5| Step: 3
Training loss: 3.3506741713644623
Validation loss: 2.5825043663807006

Epoch: 5| Step: 4
Training loss: 2.9833864502111878
Validation loss: 2.6080128818040067

Epoch: 5| Step: 5
Training loss: 2.962836227973788
Validation loss: 2.59288332539641

Epoch: 5| Step: 6
Training loss: 3.1378709854922713
Validation loss: 2.571052933099528

Epoch: 5| Step: 7
Training loss: 2.919789921767636
Validation loss: 2.5419380769973534

Epoch: 5| Step: 8
Training loss: 3.2070874524041537
Validation loss: 2.538601852292563

Epoch: 5| Step: 9
Training loss: 2.913118347540124
Validation loss: 2.5448963545319083

Epoch: 5| Step: 10
Training loss: 2.7459442401845373
Validation loss: 2.565794397043039

Epoch: 79| Step: 0
Training loss: 1.871079351254293
Validation loss: 2.614929113274107

Epoch: 5| Step: 1
Training loss: 3.184661948141119
Validation loss: 2.6643322839404013

Epoch: 5| Step: 2
Training loss: 3.342323212723896
Validation loss: 2.653762668127293

Epoch: 5| Step: 3
Training loss: 3.1303544520815056
Validation loss: 2.584429309616208

Epoch: 5| Step: 4
Training loss: 2.6543690023945055
Validation loss: 2.539207881681022

Epoch: 5| Step: 5
Training loss: 3.0790010551408704
Validation loss: 2.5349854161886123

Epoch: 5| Step: 6
Training loss: 3.10683164619643
Validation loss: 2.5459499414260662

Epoch: 5| Step: 7
Training loss: 2.7594757683780933
Validation loss: 2.581665255385322

Epoch: 5| Step: 8
Training loss: 2.509223897334705
Validation loss: 2.6315987479960525

Epoch: 5| Step: 9
Training loss: 3.234166972523922
Validation loss: 2.713419284973438

Epoch: 5| Step: 10
Training loss: 3.3816045494133817
Validation loss: 2.608404436753879

Epoch: 80| Step: 0
Training loss: 2.696238925223139
Validation loss: 2.5670819779808034

Epoch: 5| Step: 1
Training loss: 3.2406549347512965
Validation loss: 2.5404676755990256

Epoch: 5| Step: 2
Training loss: 3.3464752214951563
Validation loss: 2.536292557585206

Epoch: 5| Step: 3
Training loss: 2.886806460894733
Validation loss: 2.533725651585696

Epoch: 5| Step: 4
Training loss: 2.8150663746788736
Validation loss: 2.530322204769085

Epoch: 5| Step: 5
Training loss: 2.7184073572080583
Validation loss: 2.5337239082421212

Epoch: 5| Step: 6
Training loss: 2.835475411088018
Validation loss: 2.5347935605336223

Epoch: 5| Step: 7
Training loss: 2.9377269251403093
Validation loss: 2.5380298902006824

Epoch: 5| Step: 8
Training loss: 2.470174064835006
Validation loss: 2.537627015833917

Epoch: 5| Step: 9
Training loss: 2.816572335222985
Validation loss: 2.538540046901401

Epoch: 5| Step: 10
Training loss: 3.163510724216671
Validation loss: 2.5351800644900937

Epoch: 81| Step: 0
Training loss: 2.7184712935786597
Validation loss: 2.535762117143999

Epoch: 5| Step: 1
Training loss: 3.2001388400475776
Validation loss: 2.535190116059115

Epoch: 5| Step: 2
Training loss: 2.8407174174064975
Validation loss: 2.5354463296378644

Epoch: 5| Step: 3
Training loss: 3.1489599660519425
Validation loss: 2.5375416825247057

Epoch: 5| Step: 4
Training loss: 2.7931119015160975
Validation loss: 2.5349205483039636

Epoch: 5| Step: 5
Training loss: 2.751873158686687
Validation loss: 2.5472754898316934

Epoch: 5| Step: 6
Training loss: 2.652766737546022
Validation loss: 2.552342658630562

Epoch: 5| Step: 7
Training loss: 2.6817005481401197
Validation loss: 2.5602362573339303

Epoch: 5| Step: 8
Training loss: 3.1455352507243983
Validation loss: 2.5685207438992497

Epoch: 5| Step: 9
Training loss: 3.3434289795977077
Validation loss: 2.547427795559726

Epoch: 5| Step: 10
Training loss: 2.576488275887339
Validation loss: 2.534069449289971

Epoch: 82| Step: 0
Training loss: 2.922441723375486
Validation loss: 2.5350530669659004

Epoch: 5| Step: 1
Training loss: 3.038879545926972
Validation loss: 2.530712652501499

Epoch: 5| Step: 2
Training loss: 2.5459232541284242
Validation loss: 2.5337076019013653

Epoch: 5| Step: 3
Training loss: 3.0362659914703576
Validation loss: 2.5287047218439223

Epoch: 5| Step: 4
Training loss: 3.0688078398993213
Validation loss: 2.5304649591054234

Epoch: 5| Step: 5
Training loss: 3.1723954097981544
Validation loss: 2.5309578207754617

Epoch: 5| Step: 6
Training loss: 2.765538532176929
Validation loss: 2.5442447917752213

Epoch: 5| Step: 7
Training loss: 3.059013094357426
Validation loss: 2.54604479824143

Epoch: 5| Step: 8
Training loss: 3.1949082097821067
Validation loss: 2.5367165454885354

Epoch: 5| Step: 9
Training loss: 2.461790681718432
Validation loss: 2.5337410947445678

Epoch: 5| Step: 10
Training loss: 2.5580440017995825
Validation loss: 2.52260904070014

Epoch: 83| Step: 0
Training loss: 3.2631487789577234
Validation loss: 2.52633558381082

Epoch: 5| Step: 1
Training loss: 3.12725626556064
Validation loss: 2.5237270473440576

Epoch: 5| Step: 2
Training loss: 2.8228460962312156
Validation loss: 2.5283202060331607

Epoch: 5| Step: 3
Training loss: 3.0283324368408535
Validation loss: 2.52843891985827

Epoch: 5| Step: 4
Training loss: 2.7638406978305783
Validation loss: 2.5255604461393437

Epoch: 5| Step: 5
Training loss: 2.5444606266404834
Validation loss: 2.523338016464158

Epoch: 5| Step: 6
Training loss: 2.581637769487706
Validation loss: 2.530277640196976

Epoch: 5| Step: 7
Training loss: 2.8329685948789325
Validation loss: 2.5271233743759054

Epoch: 5| Step: 8
Training loss: 2.680226085577859
Validation loss: 2.554699626320701

Epoch: 5| Step: 9
Training loss: 2.919583977888437
Validation loss: 2.572271199240234

Epoch: 5| Step: 10
Training loss: 3.4144476841314906
Validation loss: 2.5555716643450666

Epoch: 84| Step: 0
Training loss: 3.0606746293932843
Validation loss: 2.526429005543534

Epoch: 5| Step: 1
Training loss: 2.5474749835492165
Validation loss: 2.530320983901756

Epoch: 5| Step: 2
Training loss: 3.2084785197381476
Validation loss: 2.5306232425404995

Epoch: 5| Step: 3
Training loss: 2.7642947516112315
Validation loss: 2.5422739200865894

Epoch: 5| Step: 4
Training loss: 3.5074057566243404
Validation loss: 2.550916977223526

Epoch: 5| Step: 5
Training loss: 2.6129078049393626
Validation loss: 2.5490487200899445

Epoch: 5| Step: 6
Training loss: 2.479749103590977
Validation loss: 2.598275172132999

Epoch: 5| Step: 7
Training loss: 2.864344379978046
Validation loss: 2.5461273313884885

Epoch: 5| Step: 8
Training loss: 2.940248380536176
Validation loss: 2.526473316338455

Epoch: 5| Step: 9
Training loss: 2.3445154593119315
Validation loss: 2.5318209207978026

Epoch: 5| Step: 10
Training loss: 3.476362518387996
Validation loss: 2.54989713879187

Epoch: 85| Step: 0
Training loss: 2.9842478140846715
Validation loss: 2.561675905883024

Epoch: 5| Step: 1
Training loss: 2.817092367502964
Validation loss: 2.555664674403819

Epoch: 5| Step: 2
Training loss: 2.8731904347312165
Validation loss: 2.5435356666423266

Epoch: 5| Step: 3
Training loss: 2.902147083627452
Validation loss: 2.5488875225059413

Epoch: 5| Step: 4
Training loss: 2.654171837562622
Validation loss: 2.552644732073069

Epoch: 5| Step: 5
Training loss: 3.160018484085684
Validation loss: 2.5649543381558377

Epoch: 5| Step: 6
Training loss: 2.7111765291663037
Validation loss: 2.5674048642160043

Epoch: 5| Step: 7
Training loss: 3.366215045462753
Validation loss: 2.5473244579548195

Epoch: 5| Step: 8
Training loss: 2.9179488134149922
Validation loss: 2.523662440661809

Epoch: 5| Step: 9
Training loss: 2.137679028960937
Validation loss: 2.5166236812514655

Epoch: 5| Step: 10
Training loss: 3.15567177489851
Validation loss: 2.5155508562546314

Epoch: 86| Step: 0
Training loss: 3.1044179998115125
Validation loss: 2.520861306607759

Epoch: 5| Step: 1
Training loss: 2.533902697410429
Validation loss: 2.518748193323551

Epoch: 5| Step: 2
Training loss: 3.0898727627825626
Validation loss: 2.529893103024179

Epoch: 5| Step: 3
Training loss: 2.912204180580766
Validation loss: 2.5209769680344674

Epoch: 5| Step: 4
Training loss: 2.194840893029682
Validation loss: 2.5285631070828614

Epoch: 5| Step: 5
Training loss: 2.9485049969296213
Validation loss: 2.5156534323655277

Epoch: 5| Step: 6
Training loss: 2.592987499991055
Validation loss: 2.514941675627106

Epoch: 5| Step: 7
Training loss: 3.034321281044029
Validation loss: 2.5188216460166006

Epoch: 5| Step: 8
Training loss: 3.130545768808996
Validation loss: 2.514526806191661

Epoch: 5| Step: 9
Training loss: 3.1668044277810203
Validation loss: 2.534263665182656

Epoch: 5| Step: 10
Training loss: 3.06170472698889
Validation loss: 2.538988831668512

Epoch: 87| Step: 0
Training loss: 3.035581345412153
Validation loss: 2.55843893955971

Epoch: 5| Step: 1
Training loss: 3.1111908024466315
Validation loss: 2.5505596257389205

Epoch: 5| Step: 2
Training loss: 3.339007999187803
Validation loss: 2.534952618379691

Epoch: 5| Step: 3
Training loss: 2.8754149427760245
Validation loss: 2.526729106996285

Epoch: 5| Step: 4
Training loss: 2.9631400660284894
Validation loss: 2.520614004971106

Epoch: 5| Step: 5
Training loss: 2.8250591879526685
Validation loss: 2.507993367349271

Epoch: 5| Step: 6
Training loss: 2.757534196767829
Validation loss: 2.5122519179054406

Epoch: 5| Step: 7
Training loss: 2.8577482672011905
Validation loss: 2.5086400120892764

Epoch: 5| Step: 8
Training loss: 2.676070639004398
Validation loss: 2.510087200758659

Epoch: 5| Step: 9
Training loss: 2.801567275920314
Validation loss: 2.509425478236632

Epoch: 5| Step: 10
Training loss: 2.4308266866926784
Validation loss: 2.509983127599221

Epoch: 88| Step: 0
Training loss: 3.4087697080092125
Validation loss: 2.5143441697657622

Epoch: 5| Step: 1
Training loss: 2.3731692435656493
Validation loss: 2.5282265834431317

Epoch: 5| Step: 2
Training loss: 3.1110651224763943
Validation loss: 2.5209727183077217

Epoch: 5| Step: 3
Training loss: 2.924961683234273
Validation loss: 2.5406490057443416

Epoch: 5| Step: 4
Training loss: 2.4433478607467505
Validation loss: 2.5738918201346586

Epoch: 5| Step: 5
Training loss: 2.9395089280417417
Validation loss: 2.5545668171925984

Epoch: 5| Step: 6
Training loss: 2.489042587823238
Validation loss: 2.5536864043588885

Epoch: 5| Step: 7
Training loss: 3.10959643624987
Validation loss: 2.528013029521261

Epoch: 5| Step: 8
Training loss: 2.89799261663219
Validation loss: 2.547136711173964

Epoch: 5| Step: 9
Training loss: 3.0501497325726947
Validation loss: 2.5186203932036975

Epoch: 5| Step: 10
Training loss: 2.941146859412636
Validation loss: 2.507972642402657

Epoch: 89| Step: 0
Training loss: 3.085470043461631
Validation loss: 2.5071383760402632

Epoch: 5| Step: 1
Training loss: 3.4094892026408887
Validation loss: 2.5073594356299926

Epoch: 5| Step: 2
Training loss: 3.2881291530795353
Validation loss: 2.5121385019499036

Epoch: 5| Step: 3
Training loss: 2.9234552852837874
Validation loss: 2.50942577654516

Epoch: 5| Step: 4
Training loss: 2.2114003913417433
Validation loss: 2.5125500884573517

Epoch: 5| Step: 5
Training loss: 2.4608836334630473
Validation loss: 2.5080706098377177

Epoch: 5| Step: 6
Training loss: 2.6649892319395514
Validation loss: 2.5142229897202566

Epoch: 5| Step: 7
Training loss: 2.4715189796751575
Validation loss: 2.5277887447644694

Epoch: 5| Step: 8
Training loss: 2.6833921576107915
Validation loss: 2.5255024464589098

Epoch: 5| Step: 9
Training loss: 2.764654646650569
Validation loss: 2.555248742622036

Epoch: 5| Step: 10
Training loss: 3.569892174083486
Validation loss: 2.572031207944046

Epoch: 90| Step: 0
Training loss: 2.65170536589261
Validation loss: 2.5645580615949886

Epoch: 5| Step: 1
Training loss: 2.810320624389918
Validation loss: 2.5419502374127876

Epoch: 5| Step: 2
Training loss: 2.574194576630382
Validation loss: 2.5308330652827684

Epoch: 5| Step: 3
Training loss: 2.7876371272959837
Validation loss: 2.5362588113695317

Epoch: 5| Step: 4
Training loss: 3.2280230230009086
Validation loss: 2.535111621751005

Epoch: 5| Step: 5
Training loss: 2.8371771002733386
Validation loss: 2.5357562361842794

Epoch: 5| Step: 6
Training loss: 2.76556086061748
Validation loss: 2.523929916813087

Epoch: 5| Step: 7
Training loss: 2.7025649532448925
Validation loss: 2.5223461094481263

Epoch: 5| Step: 8
Training loss: 3.2862200199702576
Validation loss: 2.519528346033403

Epoch: 5| Step: 9
Training loss: 3.066783167519678
Validation loss: 2.517479259720278

Epoch: 5| Step: 10
Training loss: 2.8805831104294333
Validation loss: 2.523999980134491

Epoch: 91| Step: 0
Training loss: 2.796584641712845
Validation loss: 2.5218597227039092

Epoch: 5| Step: 1
Training loss: 2.9004762784595806
Validation loss: 2.527464013916059

Epoch: 5| Step: 2
Training loss: 2.63378399320517
Validation loss: 2.527011469933332

Epoch: 5| Step: 3
Training loss: 2.8393174724053747
Validation loss: 2.5181836401544166

Epoch: 5| Step: 4
Training loss: 3.114982264730013
Validation loss: 2.5285707313926755

Epoch: 5| Step: 5
Training loss: 2.9433149854607294
Validation loss: 2.5099608512541085

Epoch: 5| Step: 6
Training loss: 2.4943199481590526
Validation loss: 2.530314110559677

Epoch: 5| Step: 7
Training loss: 3.034833854137125
Validation loss: 2.5348373923716925

Epoch: 5| Step: 8
Training loss: 2.9134745068538703
Validation loss: 2.5335907417807113

Epoch: 5| Step: 9
Training loss: 2.9544681138806523
Validation loss: 2.5526468371010385

Epoch: 5| Step: 10
Training loss: 2.995672283344628
Validation loss: 2.543041696162698

Epoch: 92| Step: 0
Training loss: 2.2167209427386374
Validation loss: 2.5247371842616855

Epoch: 5| Step: 1
Training loss: 2.5576793638335378
Validation loss: 2.518433717178591

Epoch: 5| Step: 2
Training loss: 3.1407507116864566
Validation loss: 2.5127250298791255

Epoch: 5| Step: 3
Training loss: 3.0313283379254004
Validation loss: 2.5219076971176526

Epoch: 5| Step: 4
Training loss: 2.75717596645509
Validation loss: 2.5067999559752

Epoch: 5| Step: 5
Training loss: 2.9079076490049682
Validation loss: 2.5116409827868003

Epoch: 5| Step: 6
Training loss: 2.4510346271647796
Validation loss: 2.5154214495262504

Epoch: 5| Step: 7
Training loss: 3.3451207283710898
Validation loss: 2.5107953029396888

Epoch: 5| Step: 8
Training loss: 3.027633869667018
Validation loss: 2.5072977660168116

Epoch: 5| Step: 9
Training loss: 3.192522915822876
Validation loss: 2.5073930871826278

Epoch: 5| Step: 10
Training loss: 2.8561962364696067
Validation loss: 2.5016242493465857

Epoch: 93| Step: 0
Training loss: 2.7915722750368026
Validation loss: 2.5100064159226823

Epoch: 5| Step: 1
Training loss: 2.9528437081846746
Validation loss: 2.519123959911033

Epoch: 5| Step: 2
Training loss: 2.737438817842895
Validation loss: 2.5130265158635186

Epoch: 5| Step: 3
Training loss: 2.670179755057027
Validation loss: 2.5260219527958414

Epoch: 5| Step: 4
Training loss: 3.0318959914412433
Validation loss: 2.541666569164267

Epoch: 5| Step: 5
Training loss: 2.3949362581885416
Validation loss: 2.539011611617834

Epoch: 5| Step: 6
Training loss: 2.905154770423136
Validation loss: 2.517423019430585

Epoch: 5| Step: 7
Training loss: 3.090280764765254
Validation loss: 2.503484880198453

Epoch: 5| Step: 8
Training loss: 2.893893317016617
Validation loss: 2.5150674548456844

Epoch: 5| Step: 9
Training loss: 2.9721124179161604
Validation loss: 2.532000996053911

Epoch: 5| Step: 10
Training loss: 3.1035428199032706
Validation loss: 2.550265850916818

Epoch: 94| Step: 0
Training loss: 3.1738013820988695
Validation loss: 2.530074557249464

Epoch: 5| Step: 1
Training loss: 2.4556198554253323
Validation loss: 2.5220406642112643

Epoch: 5| Step: 2
Training loss: 3.0069597893358364
Validation loss: 2.528849344605713

Epoch: 5| Step: 3
Training loss: 2.589139586586271
Validation loss: 2.5305146841067243

Epoch: 5| Step: 4
Training loss: 2.681734509918805
Validation loss: 2.539990190101563

Epoch: 5| Step: 5
Training loss: 3.1807883416674088
Validation loss: 2.542190295753989

Epoch: 5| Step: 6
Training loss: 2.9990444250934467
Validation loss: 2.5346865178128284

Epoch: 5| Step: 7
Training loss: 2.482771157844174
Validation loss: 2.5240712471197346

Epoch: 5| Step: 8
Training loss: 2.5411984893186674
Validation loss: 2.5162669306530967

Epoch: 5| Step: 9
Training loss: 3.027819393078063
Validation loss: 2.5184371466511886

Epoch: 5| Step: 10
Training loss: 3.2100586813913656
Validation loss: 2.503336456135429

Epoch: 95| Step: 0
Training loss: 2.9618955486459795
Validation loss: 2.49853832112223

Epoch: 5| Step: 1
Training loss: 3.178444209239413
Validation loss: 2.496824103338266

Epoch: 5| Step: 2
Training loss: 2.6739106928335343
Validation loss: 2.4968608888196058

Epoch: 5| Step: 3
Training loss: 2.698740054134755
Validation loss: 2.49304748709654

Epoch: 5| Step: 4
Training loss: 2.911892243854387
Validation loss: 2.4966396471955763

Epoch: 5| Step: 5
Training loss: 3.2497297321329937
Validation loss: 2.4963312650515843

Epoch: 5| Step: 6
Training loss: 2.654775232545941
Validation loss: 2.5053765164991004

Epoch: 5| Step: 7
Training loss: 2.767008807003893
Validation loss: 2.498877465072977

Epoch: 5| Step: 8
Training loss: 2.7215882317788145
Validation loss: 2.509407386575388

Epoch: 5| Step: 9
Training loss: 3.0936818741512755
Validation loss: 2.5286258558880705

Epoch: 5| Step: 10
Training loss: 2.2804023526527355
Validation loss: 2.542754539768986

Epoch: 96| Step: 0
Training loss: 2.5917911716332314
Validation loss: 2.5609138846308843

Epoch: 5| Step: 1
Training loss: 3.0434328638564967
Validation loss: 2.5859339151759415

Epoch: 5| Step: 2
Training loss: 2.817460496383515
Validation loss: 2.552577547024279

Epoch: 5| Step: 3
Training loss: 2.947327104436641
Validation loss: 2.5536017010694425

Epoch: 5| Step: 4
Training loss: 3.0481414510389757
Validation loss: 2.533639354132912

Epoch: 5| Step: 5
Training loss: 2.4116301396399744
Validation loss: 2.5276506569205806

Epoch: 5| Step: 6
Training loss: 3.1144386351451785
Validation loss: 2.517500843266651

Epoch: 5| Step: 7
Training loss: 3.121967981002024
Validation loss: 2.5248876166718883

Epoch: 5| Step: 8
Training loss: 2.574574933569037
Validation loss: 2.500861890461769

Epoch: 5| Step: 9
Training loss: 2.956319383125569
Validation loss: 2.5017608409611745

Epoch: 5| Step: 10
Training loss: 2.711108023697323
Validation loss: 2.4925618165274983

Epoch: 97| Step: 0
Training loss: 2.9755542078633193
Validation loss: 2.493517540530496

Epoch: 5| Step: 1
Training loss: 2.065038563735398
Validation loss: 2.487798899716232

Epoch: 5| Step: 2
Training loss: 3.354567525536821
Validation loss: 2.4921373353324228

Epoch: 5| Step: 3
Training loss: 2.938674529618384
Validation loss: 2.4985519578844113

Epoch: 5| Step: 4
Training loss: 2.497641022665304
Validation loss: 2.5252610268448947

Epoch: 5| Step: 5
Training loss: 2.7031611622061797
Validation loss: 2.5638305817135536

Epoch: 5| Step: 6
Training loss: 2.827140341633486
Validation loss: 2.58796568588522

Epoch: 5| Step: 7
Training loss: 3.175963824702717
Validation loss: 2.575258413319451

Epoch: 5| Step: 8
Training loss: 2.7884138619270566
Validation loss: 2.560252621011798

Epoch: 5| Step: 9
Training loss: 3.3483470083906526
Validation loss: 2.5115440875799395

Epoch: 5| Step: 10
Training loss: 2.584417259304393
Validation loss: 2.4956584702830886

Epoch: 98| Step: 0
Training loss: 2.3785259775984873
Validation loss: 2.4875165646807904

Epoch: 5| Step: 1
Training loss: 2.9703547908655903
Validation loss: 2.4946317133129816

Epoch: 5| Step: 2
Training loss: 2.8033901603766087
Validation loss: 2.4961813464988207

Epoch: 5| Step: 3
Training loss: 3.352750980958745
Validation loss: 2.5136598546798163

Epoch: 5| Step: 4
Training loss: 2.8587607469177403
Validation loss: 2.498951559797041

Epoch: 5| Step: 5
Training loss: 3.1479337303427917
Validation loss: 2.496161291701177

Epoch: 5| Step: 6
Training loss: 3.0765437213252915
Validation loss: 2.487930128580615

Epoch: 5| Step: 7
Training loss: 2.525782390279185
Validation loss: 2.489720458201125

Epoch: 5| Step: 8
Training loss: 2.9744455413886004
Validation loss: 2.5029862472989963

Epoch: 5| Step: 9
Training loss: 3.3353871376180737
Validation loss: 2.5055675909466966

Epoch: 5| Step: 10
Training loss: 1.929351035989683
Validation loss: 2.5519693000502244

Epoch: 99| Step: 0
Training loss: 2.539191421757025
Validation loss: 2.5330448732290516

Epoch: 5| Step: 1
Training loss: 3.28513070367594
Validation loss: 2.5493607511416

Epoch: 5| Step: 2
Training loss: 2.8602962156432583
Validation loss: 2.5072786896925163

Epoch: 5| Step: 3
Training loss: 2.798763127979806
Validation loss: 2.500825715858441

Epoch: 5| Step: 4
Training loss: 3.010735377212132
Validation loss: 2.494304865274397

Epoch: 5| Step: 5
Training loss: 2.416657568377326
Validation loss: 2.4942924453368835

Epoch: 5| Step: 6
Training loss: 2.84411652267548
Validation loss: 2.4874863936114533

Epoch: 5| Step: 7
Training loss: 2.965891857621987
Validation loss: 2.4834418478815743

Epoch: 5| Step: 8
Training loss: 2.795953694769185
Validation loss: 2.4879915775817554

Epoch: 5| Step: 9
Training loss: 3.1300858882539755
Validation loss: 2.505394667965036

Epoch: 5| Step: 10
Training loss: 2.5746708705886876
Validation loss: 2.520828848780324

Epoch: 100| Step: 0
Training loss: 2.8906606311148573
Validation loss: 2.5343748579382686

Epoch: 5| Step: 1
Training loss: 2.8592757744587596
Validation loss: 2.5207127137404917

Epoch: 5| Step: 2
Training loss: 2.6672339928658255
Validation loss: 2.525356654935045

Epoch: 5| Step: 3
Training loss: 3.2031558151623685
Validation loss: 2.4966271772623756

Epoch: 5| Step: 4
Training loss: 2.4161330543789186
Validation loss: 2.488617343593484

Epoch: 5| Step: 5
Training loss: 2.9691727186711083
Validation loss: 2.4854046615001066

Epoch: 5| Step: 6
Training loss: 2.51372480003287
Validation loss: 2.479737539134325

Epoch: 5| Step: 7
Training loss: 2.677652281233838
Validation loss: 2.4815873738273733

Epoch: 5| Step: 8
Training loss: 2.9212582187104412
Validation loss: 2.48526604347304

Epoch: 5| Step: 9
Training loss: 2.633390731025029
Validation loss: 2.4991312445363185

Epoch: 5| Step: 10
Training loss: 3.572607992794371
Validation loss: 2.531090287112725

Epoch: 101| Step: 0
Training loss: 2.648433629035934
Validation loss: 2.554994707469902

Epoch: 5| Step: 1
Training loss: 3.2207679718873496
Validation loss: 2.5899067987993964

Epoch: 5| Step: 2
Training loss: 2.9703116074289326
Validation loss: 2.587672324652242

Epoch: 5| Step: 3
Training loss: 3.1867043493216234
Validation loss: 2.555042544354416

Epoch: 5| Step: 4
Training loss: 2.443573549734619
Validation loss: 2.5141621787858925

Epoch: 5| Step: 5
Training loss: 3.279971936501262
Validation loss: 2.4951364893455965

Epoch: 5| Step: 6
Training loss: 2.888008706996399
Validation loss: 2.497811422868011

Epoch: 5| Step: 7
Training loss: 2.828305739217772
Validation loss: 2.4859121743009926

Epoch: 5| Step: 8
Training loss: 2.4613701334124425
Validation loss: 2.491292663165773

Epoch: 5| Step: 9
Training loss: 2.835470197865066
Validation loss: 2.488324901792717

Epoch: 5| Step: 10
Training loss: 2.4087058081777277
Validation loss: 2.4983128156094954

Epoch: 102| Step: 0
Training loss: 2.7640695454285034
Validation loss: 2.5190074256885517

Epoch: 5| Step: 1
Training loss: 3.0485323579812453
Validation loss: 2.528287000328187

Epoch: 5| Step: 2
Training loss: 2.6090970376721803
Validation loss: 2.5599812915742324

Epoch: 5| Step: 3
Training loss: 2.892122447860389
Validation loss: 2.5159532275162966

Epoch: 5| Step: 4
Training loss: 2.2157922291562686
Validation loss: 2.510800521506752

Epoch: 5| Step: 5
Training loss: 2.856851600379228
Validation loss: 2.512460019907718

Epoch: 5| Step: 6
Training loss: 3.4440958725171047
Validation loss: 2.5221332001131467

Epoch: 5| Step: 7
Training loss: 2.888440270518
Validation loss: 2.5042619472870986

Epoch: 5| Step: 8
Training loss: 2.765399298644741
Validation loss: 2.4876353336233583

Epoch: 5| Step: 9
Training loss: 2.8860311760437862
Validation loss: 2.498665641187154

Epoch: 5| Step: 10
Training loss: 2.7448067613412226
Validation loss: 2.4876976421526

Epoch: 103| Step: 0
Training loss: 2.9435749949535053
Validation loss: 2.491917007636116

Epoch: 5| Step: 1
Training loss: 2.444719821658239
Validation loss: 2.498774673266311

Epoch: 5| Step: 2
Training loss: 3.232626917118386
Validation loss: 2.501216587796008

Epoch: 5| Step: 3
Training loss: 2.9382199967442157
Validation loss: 2.493665654606512

Epoch: 5| Step: 4
Training loss: 3.128031823964686
Validation loss: 2.4914526367561405

Epoch: 5| Step: 5
Training loss: 2.807325732154795
Validation loss: 2.4851087519958757

Epoch: 5| Step: 6
Training loss: 2.953667807773372
Validation loss: 2.490903256218121

Epoch: 5| Step: 7
Training loss: 2.484108292760675
Validation loss: 2.50483371779498

Epoch: 5| Step: 8
Training loss: 2.8721639494044036
Validation loss: 2.500498886988292

Epoch: 5| Step: 9
Training loss: 2.641672321718663
Validation loss: 2.5368795770084738

Epoch: 5| Step: 10
Training loss: 2.737827845759992
Validation loss: 2.512929407813962

Epoch: 104| Step: 0
Training loss: 2.705835471881303
Validation loss: 2.4938086733362814

Epoch: 5| Step: 1
Training loss: 2.5900487574108295
Validation loss: 2.499269778244081

Epoch: 5| Step: 2
Training loss: 3.2748899310303194
Validation loss: 2.5036343399096315

Epoch: 5| Step: 3
Training loss: 2.9427412633263055
Validation loss: 2.481590188410903

Epoch: 5| Step: 4
Training loss: 2.817163035053271
Validation loss: 2.489840829159094

Epoch: 5| Step: 5
Training loss: 3.100004712993362
Validation loss: 2.4818339536349296

Epoch: 5| Step: 6
Training loss: 2.567350216873008
Validation loss: 2.492709656228972

Epoch: 5| Step: 7
Training loss: 2.7110540271526995
Validation loss: 2.480182251143173

Epoch: 5| Step: 8
Training loss: 2.9251947973871983
Validation loss: 2.4976120306159335

Epoch: 5| Step: 9
Training loss: 2.5296420417834034
Validation loss: 2.520277808401965

Epoch: 5| Step: 10
Training loss: 2.9256960114106323
Validation loss: 2.518688503385799

Epoch: 105| Step: 0
Training loss: 2.7187097480688123
Validation loss: 2.526887470233147

Epoch: 5| Step: 1
Training loss: 3.1874459953969065
Validation loss: 2.536544141050542

Epoch: 5| Step: 2
Training loss: 2.62331881501746
Validation loss: 2.5704647113519337

Epoch: 5| Step: 3
Training loss: 2.610782997221627
Validation loss: 2.5269662666729507

Epoch: 5| Step: 4
Training loss: 3.30074181166343
Validation loss: 2.4937380753185088

Epoch: 5| Step: 5
Training loss: 2.6640586517395684
Validation loss: 2.4858571297844225

Epoch: 5| Step: 6
Training loss: 3.245263977128825
Validation loss: 2.482972312326151

Epoch: 5| Step: 7
Training loss: 2.9706300905819294
Validation loss: 2.497157241315794

Epoch: 5| Step: 8
Training loss: 2.8550119934899034
Validation loss: 2.495061192192128

Epoch: 5| Step: 9
Training loss: 2.6398650210004226
Validation loss: 2.5175290660583687

Epoch: 5| Step: 10
Training loss: 2.0218556233675944
Validation loss: 2.5176997982916047

Epoch: 106| Step: 0
Training loss: 3.0541776343786666
Validation loss: 2.526643021078127

Epoch: 5| Step: 1
Training loss: 3.081509196616653
Validation loss: 2.4962633664485026

Epoch: 5| Step: 2
Training loss: 2.729369896075292
Validation loss: 2.4906500052997136

Epoch: 5| Step: 3
Training loss: 3.163084580744152
Validation loss: 2.4879764656062626

Epoch: 5| Step: 4
Training loss: 3.285877561362657
Validation loss: 2.491227871885714

Epoch: 5| Step: 5
Training loss: 2.3524772411060377
Validation loss: 2.5002683044351075

Epoch: 5| Step: 6
Training loss: 2.6007468288042572
Validation loss: 2.4867972068320676

Epoch: 5| Step: 7
Training loss: 2.5448589185420873
Validation loss: 2.493674236845738

Epoch: 5| Step: 8
Training loss: 2.82691702150887
Validation loss: 2.5057119172454363

Epoch: 5| Step: 9
Training loss: 2.765659913957982
Validation loss: 2.4904080274124

Epoch: 5| Step: 10
Training loss: 2.5521401120052465
Validation loss: 2.5048069209670403

Epoch: 107| Step: 0
Training loss: 2.9412710455106277
Validation loss: 2.5133278290007306

Epoch: 5| Step: 1
Training loss: 3.0027499311036
Validation loss: 2.518091252321998

Epoch: 5| Step: 2
Training loss: 3.090404204069631
Validation loss: 2.51861026380065

Epoch: 5| Step: 3
Training loss: 2.4989911905036486
Validation loss: 2.5102066512491223

Epoch: 5| Step: 4
Training loss: 2.8951888064680094
Validation loss: 2.496728688758862

Epoch: 5| Step: 5
Training loss: 2.9053325230336324
Validation loss: 2.4983357437725147

Epoch: 5| Step: 6
Training loss: 2.476595327839653
Validation loss: 2.4992371779714113

Epoch: 5| Step: 7
Training loss: 2.586062886405009
Validation loss: 2.502889971148137

Epoch: 5| Step: 8
Training loss: 2.4540690166775962
Validation loss: 2.5043336950958857

Epoch: 5| Step: 9
Training loss: 3.109777069933248
Validation loss: 2.506323723788755

Epoch: 5| Step: 10
Training loss: 3.1831990564863095
Validation loss: 2.548156496406298

Epoch: 108| Step: 0
Training loss: 2.8704874864792878
Validation loss: 2.5816532001159893

Epoch: 5| Step: 1
Training loss: 3.290470066752298
Validation loss: 2.640386797976548

Epoch: 5| Step: 2
Training loss: 2.815057312431086
Validation loss: 2.669400756139134

Epoch: 5| Step: 3
Training loss: 2.7090109539859593
Validation loss: 2.6190441820689165

Epoch: 5| Step: 4
Training loss: 2.290490964374153
Validation loss: 2.552241028732656

Epoch: 5| Step: 5
Training loss: 2.524994361040221
Validation loss: 2.5081739048005476

Epoch: 5| Step: 6
Training loss: 2.999879675677423
Validation loss: 2.499899960639003

Epoch: 5| Step: 7
Training loss: 2.8944976434030854
Validation loss: 2.487814024105602

Epoch: 5| Step: 8
Training loss: 3.1325535845606924
Validation loss: 2.503554092324767

Epoch: 5| Step: 9
Training loss: 3.146878066909038
Validation loss: 2.4971654378654162

Epoch: 5| Step: 10
Training loss: 2.4986394040782574
Validation loss: 2.5054970761353363

Epoch: 109| Step: 0
Training loss: 2.6333613064241903
Validation loss: 2.5026449558041794

Epoch: 5| Step: 1
Training loss: 3.319597521825376
Validation loss: 2.483272783436346

Epoch: 5| Step: 2
Training loss: 2.9408679890142286
Validation loss: 2.4927355238042583

Epoch: 5| Step: 3
Training loss: 2.999884444236473
Validation loss: 2.4881441203436747

Epoch: 5| Step: 4
Training loss: 2.6364735129009955
Validation loss: 2.4861945090191706

Epoch: 5| Step: 5
Training loss: 3.0806231745170622
Validation loss: 2.49375751325736

Epoch: 5| Step: 6
Training loss: 2.6486497642053948
Validation loss: 2.498165632807502

Epoch: 5| Step: 7
Training loss: 2.1997327728966902
Validation loss: 2.4867866488415604

Epoch: 5| Step: 8
Training loss: 2.6700884997956007
Validation loss: 2.483158122349162

Epoch: 5| Step: 9
Training loss: 2.773754005102607
Validation loss: 2.50596553552775

Epoch: 5| Step: 10
Training loss: 3.128441708258707
Validation loss: 2.5033394690049904

Epoch: 110| Step: 0
Training loss: 2.9061929020348756
Validation loss: 2.516513620381809

Epoch: 5| Step: 1
Training loss: 3.079656849112994
Validation loss: 2.526612441582575

Epoch: 5| Step: 2
Training loss: 2.6097526048650384
Validation loss: 2.5139499397715475

Epoch: 5| Step: 3
Training loss: 3.138408732940947
Validation loss: 2.5177048391190575

Epoch: 5| Step: 4
Training loss: 2.71046914224066
Validation loss: 2.5114390927978913

Epoch: 5| Step: 5
Training loss: 2.5989210677803847
Validation loss: 2.5142055137884336

Epoch: 5| Step: 6
Training loss: 2.528816560481151
Validation loss: 2.502677958819331

Epoch: 5| Step: 7
Training loss: 2.7594725715779482
Validation loss: 2.531618716073625

Epoch: 5| Step: 8
Training loss: 2.7196892179325696
Validation loss: 2.539487796121648

Epoch: 5| Step: 9
Training loss: 3.0037357594457674
Validation loss: 2.5530345484267305

Epoch: 5| Step: 10
Training loss: 3.047319428724792
Validation loss: 2.5217097531904535

Epoch: 111| Step: 0
Training loss: 2.6893746690796463
Validation loss: 2.485669163811773

Epoch: 5| Step: 1
Training loss: 2.829931030241778
Validation loss: 2.4848791297034474

Epoch: 5| Step: 2
Training loss: 3.1572495190357794
Validation loss: 2.4705054585435766

Epoch: 5| Step: 3
Training loss: 3.187506881407247
Validation loss: 2.4682891174582835

Epoch: 5| Step: 4
Training loss: 2.8147179229505057
Validation loss: 2.4743064883232053

Epoch: 5| Step: 5
Training loss: 3.0141980842244562
Validation loss: 2.4651534858031923

Epoch: 5| Step: 6
Training loss: 2.8423741963510927
Validation loss: 2.475369738483626

Epoch: 5| Step: 7
Training loss: 2.3163113502245762
Validation loss: 2.472179828383396

Epoch: 5| Step: 8
Training loss: 2.5741581772202924
Validation loss: 2.4771328876722034

Epoch: 5| Step: 9
Training loss: 2.809972008399422
Validation loss: 2.5184612882145325

Epoch: 5| Step: 10
Training loss: 2.926372147544268
Validation loss: 2.5304362169971313

Epoch: 112| Step: 0
Training loss: 2.735251673080174
Validation loss: 2.5399074857925097

Epoch: 5| Step: 1
Training loss: 3.0384677805181792
Validation loss: 2.525328336892782

Epoch: 5| Step: 2
Training loss: 2.528587353727794
Validation loss: 2.4931733312898405

Epoch: 5| Step: 3
Training loss: 2.798445787955343
Validation loss: 2.479285922809612

Epoch: 5| Step: 4
Training loss: 2.7562891397270612
Validation loss: 2.4797391157329223

Epoch: 5| Step: 5
Training loss: 3.054284110593292
Validation loss: 2.4968778485438703

Epoch: 5| Step: 6
Training loss: 2.8138858347862903
Validation loss: 2.491402036433025

Epoch: 5| Step: 7
Training loss: 2.706568734866868
Validation loss: 2.4774092327957105

Epoch: 5| Step: 8
Training loss: 2.348670778344387
Validation loss: 2.478008071579575

Epoch: 5| Step: 9
Training loss: 2.8562448180170446
Validation loss: 2.4797034088889256

Epoch: 5| Step: 10
Training loss: 3.376022184073072
Validation loss: 2.484826566283765

Epoch: 113| Step: 0
Training loss: 2.5790362972738965
Validation loss: 2.494618853105427

Epoch: 5| Step: 1
Training loss: 3.030383743309396
Validation loss: 2.492076662365832

Epoch: 5| Step: 2
Training loss: 2.859839229733356
Validation loss: 2.4890949684858152

Epoch: 5| Step: 3
Training loss: 2.775822691067218
Validation loss: 2.4856086248434117

Epoch: 5| Step: 4
Training loss: 2.7414148008224615
Validation loss: 2.4792311230790225

Epoch: 5| Step: 5
Training loss: 2.9064240762403735
Validation loss: 2.4856853634624887

Epoch: 5| Step: 6
Training loss: 2.9424489314882774
Validation loss: 2.470575692115478

Epoch: 5| Step: 7
Training loss: 3.015332143527644
Validation loss: 2.4675459734016796

Epoch: 5| Step: 8
Training loss: 2.6563012510853006
Validation loss: 2.4636760974086807

Epoch: 5| Step: 9
Training loss: 2.712143159941881
Validation loss: 2.4717846691724152

Epoch: 5| Step: 10
Training loss: 2.694660140992118
Validation loss: 2.493048133907224

Epoch: 114| Step: 0
Training loss: 2.7050522124774234
Validation loss: 2.512175246871888

Epoch: 5| Step: 1
Training loss: 2.8909110262838684
Validation loss: 2.5382844172886805

Epoch: 5| Step: 2
Training loss: 2.604693112885046
Validation loss: 2.5252678441459016

Epoch: 5| Step: 3
Training loss: 2.7177436105980965
Validation loss: 2.501741035839169

Epoch: 5| Step: 4
Training loss: 2.9161374474825195
Validation loss: 2.4955011650652414

Epoch: 5| Step: 5
Training loss: 3.212129617557902
Validation loss: 2.488719230730257

Epoch: 5| Step: 6
Training loss: 3.303415906036416
Validation loss: 2.4761797755876866

Epoch: 5| Step: 7
Training loss: 2.7166468937472157
Validation loss: 2.4780899098954716

Epoch: 5| Step: 8
Training loss: 2.5558335652914606
Validation loss: 2.487939763092957

Epoch: 5| Step: 9
Training loss: 2.4578838476264195
Validation loss: 2.493887739838933

Epoch: 5| Step: 10
Training loss: 2.6682108242862173
Validation loss: 2.5014329269761024

Epoch: 115| Step: 0
Training loss: 2.76462498058311
Validation loss: 2.5037670364600157

Epoch: 5| Step: 1
Training loss: 2.882577943434589
Validation loss: 2.517546015874482

Epoch: 5| Step: 2
Training loss: 2.8607621293874645
Validation loss: 2.5568860874831043

Epoch: 5| Step: 3
Training loss: 3.2317092893746295
Validation loss: 2.537794175577441

Epoch: 5| Step: 4
Training loss: 3.140285188880921
Validation loss: 2.5473002588263234

Epoch: 5| Step: 5
Training loss: 2.8013332360364607
Validation loss: 2.527223720776043

Epoch: 5| Step: 6
Training loss: 2.841325334052872
Validation loss: 2.5152939390266518

Epoch: 5| Step: 7
Training loss: 2.5416592978282067
Validation loss: 2.5220861854766885

Epoch: 5| Step: 8
Training loss: 2.636478577024546
Validation loss: 2.487590289794846

Epoch: 5| Step: 9
Training loss: 2.4402186564670036
Validation loss: 2.49312210470256

Epoch: 5| Step: 10
Training loss: 2.5186658215714037
Validation loss: 2.4798181356381446

Epoch: 116| Step: 0
Training loss: 3.2163057398200676
Validation loss: 2.489032539409986

Epoch: 5| Step: 1
Training loss: 2.850561347690704
Validation loss: 2.493756426636577

Epoch: 5| Step: 2
Training loss: 2.796092515312577
Validation loss: 2.500613968838924

Epoch: 5| Step: 3
Training loss: 2.64858171188538
Validation loss: 2.523824570842621

Epoch: 5| Step: 4
Training loss: 2.7619441478642597
Validation loss: 2.5492021206367714

Epoch: 5| Step: 5
Training loss: 2.5941898938086934
Validation loss: 2.573706588126794

Epoch: 5| Step: 6
Training loss: 2.7430572434646843
Validation loss: 2.5856143898385215

Epoch: 5| Step: 7
Training loss: 3.2432112582665766
Validation loss: 2.5345817048984336

Epoch: 5| Step: 8
Training loss: 2.86346626464624
Validation loss: 2.5057313533553645

Epoch: 5| Step: 9
Training loss: 2.8152639583061734
Validation loss: 2.4984917131125006

Epoch: 5| Step: 10
Training loss: 2.1257898321402586
Validation loss: 2.4912564983097627

Epoch: 117| Step: 0
Training loss: 2.621260113275944
Validation loss: 2.52114356764328

Epoch: 5| Step: 1
Training loss: 2.9180350953593797
Validation loss: 2.5462229155822875

Epoch: 5| Step: 2
Training loss: 2.7306767331263146
Validation loss: 2.5631844961707233

Epoch: 5| Step: 3
Training loss: 2.878259883871928
Validation loss: 2.5272779251850843

Epoch: 5| Step: 4
Training loss: 2.7588996797513547
Validation loss: 2.5137135163061664

Epoch: 5| Step: 5
Training loss: 2.8411939263170543
Validation loss: 2.4932096534263817

Epoch: 5| Step: 6
Training loss: 2.826370959859016
Validation loss: 2.4839821606353247

Epoch: 5| Step: 7
Training loss: 3.2569299321143887
Validation loss: 2.477955117212914

Epoch: 5| Step: 8
Training loss: 3.0067994628755557
Validation loss: 2.4964063072141043

Epoch: 5| Step: 9
Training loss: 2.3558372601518087
Validation loss: 2.5122084553203288

Epoch: 5| Step: 10
Training loss: 2.69332193040165
Validation loss: 2.5454378213317725

Epoch: 118| Step: 0
Training loss: 3.0736506905477863
Validation loss: 2.5365625515751558

Epoch: 5| Step: 1
Training loss: 2.668078664635125
Validation loss: 2.517773893009679

Epoch: 5| Step: 2
Training loss: 3.2229876723519766
Validation loss: 2.4955330544609486

Epoch: 5| Step: 3
Training loss: 2.427002333788856
Validation loss: 2.491085710442514

Epoch: 5| Step: 4
Training loss: 3.3464814910217235
Validation loss: 2.4750572716285024

Epoch: 5| Step: 5
Training loss: 2.146329199030086
Validation loss: 2.4694543209979853

Epoch: 5| Step: 6
Training loss: 2.7433590899432962
Validation loss: 2.479682431989703

Epoch: 5| Step: 7
Training loss: 2.997830719253719
Validation loss: 2.4799413049035812

Epoch: 5| Step: 8
Training loss: 2.817561533001282
Validation loss: 2.5006594998056344

Epoch: 5| Step: 9
Training loss: 2.5748440297120427
Validation loss: 2.490970051510015

Epoch: 5| Step: 10
Training loss: 2.5614647053229116
Validation loss: 2.494269337140605

Epoch: 119| Step: 0
Training loss: 2.711065020021771
Validation loss: 2.4938194287854047

Epoch: 5| Step: 1
Training loss: 1.831988173509097
Validation loss: 2.4803969966092048

Epoch: 5| Step: 2
Training loss: 2.56818206523179
Validation loss: 2.4969004659506444

Epoch: 5| Step: 3
Training loss: 2.9002632087437643
Validation loss: 2.509137575585592

Epoch: 5| Step: 4
Training loss: 3.188042987126829
Validation loss: 2.497696919080464

Epoch: 5| Step: 5
Training loss: 2.9123318930641964
Validation loss: 2.508863841375821

Epoch: 5| Step: 6
Training loss: 2.8396442663344597
Validation loss: 2.5072583535186443

Epoch: 5| Step: 7
Training loss: 2.8779590140493405
Validation loss: 2.5402743922082442

Epoch: 5| Step: 8
Training loss: 3.251137901054393
Validation loss: 2.5819406969946783

Epoch: 5| Step: 9
Training loss: 2.5428452703495763
Validation loss: 2.529564181024055

Epoch: 5| Step: 10
Training loss: 2.713901625253792
Validation loss: 2.497643414233895

Epoch: 120| Step: 0
Training loss: 3.0196811100930563
Validation loss: 2.4816866034021228

Epoch: 5| Step: 1
Training loss: 3.1179097421635413
Validation loss: 2.486201707470178

Epoch: 5| Step: 2
Training loss: 2.7692428460224616
Validation loss: 2.463371131681686

Epoch: 5| Step: 3
Training loss: 2.9153282546039794
Validation loss: 2.4880943285441126

Epoch: 5| Step: 4
Training loss: 2.345642648087222
Validation loss: 2.4793815412820517

Epoch: 5| Step: 5
Training loss: 2.9234812192435955
Validation loss: 2.4825269419763942

Epoch: 5| Step: 6
Training loss: 3.084277979166436
Validation loss: 2.475024837710258

Epoch: 5| Step: 7
Training loss: 2.8537783022064858
Validation loss: 2.495886178496103

Epoch: 5| Step: 8
Training loss: 2.148981531794287
Validation loss: 2.504081334598878

Epoch: 5| Step: 9
Training loss: 2.9940423619618626
Validation loss: 2.497771648225438

Epoch: 5| Step: 10
Training loss: 2.376709473408559
Validation loss: 2.505824728885711

Epoch: 121| Step: 0
Training loss: 2.9207542840452283
Validation loss: 2.5169915373089284

Epoch: 5| Step: 1
Training loss: 2.7916372686707605
Validation loss: 2.493368651659405

Epoch: 5| Step: 2
Training loss: 2.2358609040454125
Validation loss: 2.488974999206203

Epoch: 5| Step: 3
Training loss: 1.9151245907325622
Validation loss: 2.478259410667495

Epoch: 5| Step: 4
Training loss: 2.4011154880608334
Validation loss: 2.4805116576899633

Epoch: 5| Step: 5
Training loss: 2.7328958052625927
Validation loss: 2.463454430317355

Epoch: 5| Step: 6
Training loss: 2.770925668502093
Validation loss: 2.4687542814708556

Epoch: 5| Step: 7
Training loss: 2.7664905637590156
Validation loss: 2.4562926842430923

Epoch: 5| Step: 8
Training loss: 3.011742498994398
Validation loss: 2.4675355943351547

Epoch: 5| Step: 9
Training loss: 3.429823192788378
Validation loss: 2.4715100881524794

Epoch: 5| Step: 10
Training loss: 3.5029382633798702
Validation loss: 2.463367295643089

Epoch: 122| Step: 0
Training loss: 2.5859675564128457
Validation loss: 2.49373428804856

Epoch: 5| Step: 1
Training loss: 2.9359665784466724
Validation loss: 2.5315018456041756

Epoch: 5| Step: 2
Training loss: 3.0172111806626694
Validation loss: 2.566094238606013

Epoch: 5| Step: 3
Training loss: 3.240955090977565
Validation loss: 2.5721834461613975

Epoch: 5| Step: 4
Training loss: 2.6776353635505936
Validation loss: 2.5766451180776726

Epoch: 5| Step: 5
Training loss: 2.8540085426208064
Validation loss: 2.5576975149764034

Epoch: 5| Step: 6
Training loss: 3.176594047183333
Validation loss: 2.5183853767945488

Epoch: 5| Step: 7
Training loss: 1.9476419006871817
Validation loss: 2.4990937036118224

Epoch: 5| Step: 8
Training loss: 2.6166465086271855
Validation loss: 2.4972766840655094

Epoch: 5| Step: 9
Training loss: 2.527635701929513
Validation loss: 2.4913705994035715

Epoch: 5| Step: 10
Training loss: 2.9802151593358253
Validation loss: 2.481949577630218

Epoch: 123| Step: 0
Training loss: 2.526568097714066
Validation loss: 2.496630487797486

Epoch: 5| Step: 1
Training loss: 2.6660120478455855
Validation loss: 2.507361488701529

Epoch: 5| Step: 2
Training loss: 2.7650925290731116
Validation loss: 2.4949825214803987

Epoch: 5| Step: 3
Training loss: 2.1896627361540877
Validation loss: 2.4969687686902975

Epoch: 5| Step: 4
Training loss: 2.9420567334045074
Validation loss: 2.4921030148596874

Epoch: 5| Step: 5
Training loss: 2.489984190097852
Validation loss: 2.51773535115795

Epoch: 5| Step: 6
Training loss: 3.0621658454298313
Validation loss: 2.5536936765855365

Epoch: 5| Step: 7
Training loss: 3.179431801902154
Validation loss: 2.583054365390719

Epoch: 5| Step: 8
Training loss: 2.9686292121809457
Validation loss: 2.55930655616281

Epoch: 5| Step: 9
Training loss: 3.0185685887135425
Validation loss: 2.565875364741984

Epoch: 5| Step: 10
Training loss: 2.878382144669459
Validation loss: 2.5524591423284657

Epoch: 124| Step: 0
Training loss: 2.5502284153381143
Validation loss: 2.5886659616903946

Epoch: 5| Step: 1
Training loss: 2.5573638988686325
Validation loss: 2.5295305436887916

Epoch: 5| Step: 2
Training loss: 3.3121939463750185
Validation loss: 2.5286007447920986

Epoch: 5| Step: 3
Training loss: 2.8162615734934304
Validation loss: 2.517311947608524

Epoch: 5| Step: 4
Training loss: 2.877893236005158
Validation loss: 2.517454931547374

Epoch: 5| Step: 5
Training loss: 2.9981006331703095
Validation loss: 2.54240523113833

Epoch: 5| Step: 6
Training loss: 2.7767049964313872
Validation loss: 2.5415605018212575

Epoch: 5| Step: 7
Training loss: 2.3146328755686785
Validation loss: 2.533957097872375

Epoch: 5| Step: 8
Training loss: 2.641285650009997
Validation loss: 2.6776085927978905

Epoch: 5| Step: 9
Training loss: 2.5544102136225555
Validation loss: 2.6159039139741243

Epoch: 5| Step: 10
Training loss: 3.036196418751149
Validation loss: 2.575799813660993

Epoch: 125| Step: 0
Training loss: 2.9465214603198615
Validation loss: 2.503478961304951

Epoch: 5| Step: 1
Training loss: 3.1607309391792993
Validation loss: 2.4848003842346675

Epoch: 5| Step: 2
Training loss: 2.909057409733015
Validation loss: 2.518486299876041

Epoch: 5| Step: 3
Training loss: 2.774297532531655
Validation loss: 2.668172953735728

Epoch: 5| Step: 4
Training loss: 3.4588157746265087
Validation loss: 2.8040185252151075

Epoch: 5| Step: 5
Training loss: 2.7521868593629497
Validation loss: 2.837830718864796

Epoch: 5| Step: 6
Training loss: 2.762508899795212
Validation loss: 2.793045387332437

Epoch: 5| Step: 7
Training loss: 3.2449515820198798
Validation loss: 2.683319885530011

Epoch: 5| Step: 8
Training loss: 2.441191592125725
Validation loss: 2.623501120699094

Epoch: 5| Step: 9
Training loss: 2.9770318409706875
Validation loss: 2.56102546388113

Epoch: 5| Step: 10
Training loss: 2.032161214823629
Validation loss: 2.5298726263898477

Epoch: 126| Step: 0
Training loss: 2.9919674147499156
Validation loss: 2.516123070208898

Epoch: 5| Step: 1
Training loss: 2.709838732464191
Validation loss: 2.5095691914146916

Epoch: 5| Step: 2
Training loss: 2.7968541149872728
Validation loss: 2.563840750939922

Epoch: 5| Step: 3
Training loss: 3.108972571319784
Validation loss: 2.6145767122276435

Epoch: 5| Step: 4
Training loss: 2.575340570686369
Validation loss: 2.6028837198053845

Epoch: 5| Step: 5
Training loss: 3.088972313605875
Validation loss: 2.5918265924436903

Epoch: 5| Step: 6
Training loss: 2.034263019439001
Validation loss: 2.5435349742119513

Epoch: 5| Step: 7
Training loss: 3.0786401927476628
Validation loss: 2.5271242660774123

Epoch: 5| Step: 8
Training loss: 2.660601652839134
Validation loss: 2.5132141178370135

Epoch: 5| Step: 9
Training loss: 2.9800330727297286
Validation loss: 2.51824602863173

Epoch: 5| Step: 10
Training loss: 3.031819240959308
Validation loss: 2.513871737800698

Epoch: 127| Step: 0
Training loss: 2.766418860341299
Validation loss: 2.4948961406169516

Epoch: 5| Step: 1
Training loss: 2.9020516208760814
Validation loss: 2.5015681383659008

Epoch: 5| Step: 2
Training loss: 2.469097644134296
Validation loss: 2.498670907659505

Epoch: 5| Step: 3
Training loss: 2.5736090671810024
Validation loss: 2.5001622249923936

Epoch: 5| Step: 4
Training loss: 2.977479007624525
Validation loss: 2.5165374472772717

Epoch: 5| Step: 5
Training loss: 2.825301810827584
Validation loss: 2.512452488540158

Epoch: 5| Step: 6
Training loss: 3.0533658263575085
Validation loss: 2.5136055692555237

Epoch: 5| Step: 7
Training loss: 2.751995403108528
Validation loss: 2.5038510266680065

Epoch: 5| Step: 8
Training loss: 2.932763847065394
Validation loss: 2.503327289493332

Epoch: 5| Step: 9
Training loss: 2.8515419319142636
Validation loss: 2.485844128272138

Epoch: 5| Step: 10
Training loss: 2.4065181037860692
Validation loss: 2.474440834303007

Epoch: 128| Step: 0
Training loss: 3.0407029458510455
Validation loss: 2.473534036638236

Epoch: 5| Step: 1
Training loss: 3.0640139827359416
Validation loss: 2.4575219363053895

Epoch: 5| Step: 2
Training loss: 2.56996843533855
Validation loss: 2.4530520188256753

Epoch: 5| Step: 3
Training loss: 2.6476622040277276
Validation loss: 2.443167486779429

Epoch: 5| Step: 4
Training loss: 2.823173361130317
Validation loss: 2.45000111875159

Epoch: 5| Step: 5
Training loss: 2.9705862690691918
Validation loss: 2.4522608022574475

Epoch: 5| Step: 6
Training loss: 2.39389711729705
Validation loss: 2.448436218157097

Epoch: 5| Step: 7
Training loss: 3.1080302488703464
Validation loss: 2.444876649718963

Epoch: 5| Step: 8
Training loss: 1.8896636410281473
Validation loss: 2.4442960258104

Epoch: 5| Step: 9
Training loss: 3.081478248174036
Validation loss: 2.4520282811076584

Epoch: 5| Step: 10
Training loss: 2.5169610687082193
Validation loss: 2.469711147764287

Epoch: 129| Step: 0
Training loss: 3.630090099509129
Validation loss: 2.493880713657222

Epoch: 5| Step: 1
Training loss: 3.054514223925801
Validation loss: 2.524395998029728

Epoch: 5| Step: 2
Training loss: 2.9450772543134605
Validation loss: 2.5621266076751446

Epoch: 5| Step: 3
Training loss: 2.32137205034134
Validation loss: 2.549534055617205

Epoch: 5| Step: 4
Training loss: 2.829200666520137
Validation loss: 2.535900369856487

Epoch: 5| Step: 5
Training loss: 2.7126049882813255
Validation loss: 2.4942631974964393

Epoch: 5| Step: 6
Training loss: 2.5228203647755074
Validation loss: 2.478676909330228

Epoch: 5| Step: 7
Training loss: 2.3365612409301812
Validation loss: 2.4630584843054177

Epoch: 5| Step: 8
Training loss: 2.890951931997507
Validation loss: 2.4604194717020995

Epoch: 5| Step: 9
Training loss: 2.3299875681467714
Validation loss: 2.4550245820574474

Epoch: 5| Step: 10
Training loss: 2.7735440945624825
Validation loss: 2.4635532221657206

Epoch: 130| Step: 0
Training loss: 2.725983478963471
Validation loss: 2.4586590964203423

Epoch: 5| Step: 1
Training loss: 2.6130389228079585
Validation loss: 2.470888756834204

Epoch: 5| Step: 2
Training loss: 2.492058538370837
Validation loss: 2.4803234385601467

Epoch: 5| Step: 3
Training loss: 2.5622387264382227
Validation loss: 2.4661713842356567

Epoch: 5| Step: 4
Training loss: 2.470394986806487
Validation loss: 2.4815010726736073

Epoch: 5| Step: 5
Training loss: 2.8694023703680407
Validation loss: 2.486059198803596

Epoch: 5| Step: 6
Training loss: 3.0716046824611696
Validation loss: 2.500059652129544

Epoch: 5| Step: 7
Training loss: 2.6473541294505254
Validation loss: 2.49987995925984

Epoch: 5| Step: 8
Training loss: 3.0282669333311483
Validation loss: 2.521521295857169

Epoch: 5| Step: 9
Training loss: 2.6133520461729467
Validation loss: 2.5340207561600443

Epoch: 5| Step: 10
Training loss: 3.0012360251791272
Validation loss: 2.5857050263627173

Epoch: 131| Step: 0
Training loss: 2.606939218261047
Validation loss: 2.57906798875829

Epoch: 5| Step: 1
Training loss: 3.022084961217567
Validation loss: 2.573809543313249

Epoch: 5| Step: 2
Training loss: 3.322058651603307
Validation loss: 2.554999936098221

Epoch: 5| Step: 3
Training loss: 2.465187496150002
Validation loss: 2.5116994673933006

Epoch: 5| Step: 4
Training loss: 2.4711421531256734
Validation loss: 2.4930664203789545

Epoch: 5| Step: 5
Training loss: 2.5098765782867534
Validation loss: 2.477377887255889

Epoch: 5| Step: 6
Training loss: 3.24372992536915
Validation loss: 2.467447252062697

Epoch: 5| Step: 7
Training loss: 2.8359339690383494
Validation loss: 2.4595916823546076

Epoch: 5| Step: 8
Training loss: 2.359622866513645
Validation loss: 2.460204581460981

Epoch: 5| Step: 9
Training loss: 2.7178591441581608
Validation loss: 2.4512565420043306

Epoch: 5| Step: 10
Training loss: 2.6711583654371056
Validation loss: 2.4559813883751866

Epoch: 132| Step: 0
Training loss: 2.7440412292941967
Validation loss: 2.4659199691415594

Epoch: 5| Step: 1
Training loss: 2.3368194854255644
Validation loss: 2.4856202269620704

Epoch: 5| Step: 2
Training loss: 2.5527986315554707
Validation loss: 2.4666337464881543

Epoch: 5| Step: 3
Training loss: 2.163696037690615
Validation loss: 2.4756436428875017

Epoch: 5| Step: 4
Training loss: 2.7230930935695787
Validation loss: 2.480673554259301

Epoch: 5| Step: 5
Training loss: 2.748325705192842
Validation loss: 2.4759434471415083

Epoch: 5| Step: 6
Training loss: 2.9143100664045636
Validation loss: 2.482749670954954

Epoch: 5| Step: 7
Training loss: 3.04536063878945
Validation loss: 2.5076784625769712

Epoch: 5| Step: 8
Training loss: 2.9709859358519815
Validation loss: 2.524193357973296

Epoch: 5| Step: 9
Training loss: 2.5836771049237797
Validation loss: 2.55510005158059

Epoch: 5| Step: 10
Training loss: 3.1218787818557394
Validation loss: 2.5456618190138087

Epoch: 133| Step: 0
Training loss: 3.0872375067815576
Validation loss: 2.53615203265996

Epoch: 5| Step: 1
Training loss: 2.4724179796397983
Validation loss: 2.5690981058272846

Epoch: 5| Step: 2
Training loss: 2.8128392332849614
Validation loss: 2.543091050249384

Epoch: 5| Step: 3
Training loss: 3.07156525114493
Validation loss: 2.582211349704853

Epoch: 5| Step: 4
Training loss: 3.1838606459251477
Validation loss: 2.577722183235829

Epoch: 5| Step: 5
Training loss: 2.7683011485538334
Validation loss: 2.5276305586903667

Epoch: 5| Step: 6
Training loss: 2.55936472684594
Validation loss: 2.495391707434261

Epoch: 5| Step: 7
Training loss: 2.0603580334082903
Validation loss: 2.4606031413051097

Epoch: 5| Step: 8
Training loss: 2.90723607552189
Validation loss: 2.4732484779443404

Epoch: 5| Step: 9
Training loss: 2.432233647723911
Validation loss: 2.4705069165100095

Epoch: 5| Step: 10
Training loss: 2.5698947740973486
Validation loss: 2.477207114308739

Epoch: 134| Step: 0
Training loss: 2.923821927703018
Validation loss: 2.4771269378954326

Epoch: 5| Step: 1
Training loss: 2.6168979769313667
Validation loss: 2.466910162012617

Epoch: 5| Step: 2
Training loss: 3.106885517281362
Validation loss: 2.486675929248259

Epoch: 5| Step: 3
Training loss: 2.8424985039135864
Validation loss: 2.4831968178575643

Epoch: 5| Step: 4
Training loss: 2.2384496495674595
Validation loss: 2.4929107625644575

Epoch: 5| Step: 5
Training loss: 2.603802607202195
Validation loss: 2.4954774598915233

Epoch: 5| Step: 6
Training loss: 2.971791847261054
Validation loss: 2.5283792143379937

Epoch: 5| Step: 7
Training loss: 2.5518960897044622
Validation loss: 2.5366894992990203

Epoch: 5| Step: 8
Training loss: 2.4127463299003296
Validation loss: 2.535371873708164

Epoch: 5| Step: 9
Training loss: 2.656471871478235
Validation loss: 2.5271123178597525

Epoch: 5| Step: 10
Training loss: 2.810279223731716
Validation loss: 2.5106389216204517

Epoch: 135| Step: 0
Training loss: 2.6934993228971695
Validation loss: 2.492000347913679

Epoch: 5| Step: 1
Training loss: 2.2232006726967093
Validation loss: 2.4785707094736087

Epoch: 5| Step: 2
Training loss: 2.245878683657366
Validation loss: 2.4636473929702287

Epoch: 5| Step: 3
Training loss: 3.296288750037018
Validation loss: 2.4637175587849165

Epoch: 5| Step: 4
Training loss: 2.093579982857785
Validation loss: 2.4546044254783936

Epoch: 5| Step: 5
Training loss: 3.05552751547538
Validation loss: 2.4601565782085033

Epoch: 5| Step: 6
Training loss: 3.0098445221042915
Validation loss: 2.486307234926421

Epoch: 5| Step: 7
Training loss: 2.7002270991573885
Validation loss: 2.48718697061415

Epoch: 5| Step: 8
Training loss: 2.723743106856077
Validation loss: 2.5031742688961236

Epoch: 5| Step: 9
Training loss: 2.7842274704883354
Validation loss: 2.53077486886769

Epoch: 5| Step: 10
Training loss: 2.7558230391607053
Validation loss: 2.566163390489637

Epoch: 136| Step: 0
Training loss: 2.5743088655805257
Validation loss: 2.5863845667254868

Epoch: 5| Step: 1
Training loss: 2.7672369618144432
Validation loss: 2.645893748973296

Epoch: 5| Step: 2
Training loss: 3.0816648625694705
Validation loss: 2.6403350224270916

Epoch: 5| Step: 3
Training loss: 2.760958770687288
Validation loss: 2.638651859718245

Epoch: 5| Step: 4
Training loss: 2.681506015319166
Validation loss: 2.6407281212653464

Epoch: 5| Step: 5
Training loss: 2.2008432246193794
Validation loss: 2.6461486305562065

Epoch: 5| Step: 6
Training loss: 2.8799882819679077
Validation loss: 2.6371187505389315

Epoch: 5| Step: 7
Training loss: 2.501692580415655
Validation loss: 2.6064360698070304

Epoch: 5| Step: 8
Training loss: 2.726332777778907
Validation loss: 2.5966700092111816

Epoch: 5| Step: 9
Training loss: 2.8391876512234733
Validation loss: 2.5503916431017912

Epoch: 5| Step: 10
Training loss: 2.8440172677676117
Validation loss: 2.5250815478785587

Epoch: 137| Step: 0
Training loss: 2.7936452619816428
Validation loss: 2.5280497952001943

Epoch: 5| Step: 1
Training loss: 2.9005859309242643
Validation loss: 2.5031439096593964

Epoch: 5| Step: 2
Training loss: 2.6354406805540123
Validation loss: 2.515841393809017

Epoch: 5| Step: 3
Training loss: 2.159893992613103
Validation loss: 2.490495918593243

Epoch: 5| Step: 4
Training loss: 2.7079472388870856
Validation loss: 2.4960476581562827

Epoch: 5| Step: 5
Training loss: 2.69136000816362
Validation loss: 2.4986877976426465

Epoch: 5| Step: 6
Training loss: 2.9427673513970216
Validation loss: 2.5061127932047595

Epoch: 5| Step: 7
Training loss: 3.116557963578447
Validation loss: 2.5608729627787965

Epoch: 5| Step: 8
Training loss: 2.4619063150661518
Validation loss: 2.625665050119444

Epoch: 5| Step: 9
Training loss: 3.0083535240390455
Validation loss: 2.7069660992130666

Epoch: 5| Step: 10
Training loss: 2.561266253202447
Validation loss: 2.702105524627882

Epoch: 138| Step: 0
Training loss: 2.6487992751329927
Validation loss: 2.6790201822422253

Epoch: 5| Step: 1
Training loss: 2.2616037395534088
Validation loss: 2.636502756427366

Epoch: 5| Step: 2
Training loss: 2.856372027638963
Validation loss: 2.5741305145593367

Epoch: 5| Step: 3
Training loss: 2.891943388642031
Validation loss: 2.556375278740943

Epoch: 5| Step: 4
Training loss: 2.6284474940433697
Validation loss: 2.5358407823886724

Epoch: 5| Step: 5
Training loss: 2.616810239104878
Validation loss: 2.5565865848740845

Epoch: 5| Step: 6
Training loss: 2.756665042413912
Validation loss: 2.554514285221312

Epoch: 5| Step: 7
Training loss: 2.990023555088714
Validation loss: 2.564783457026444

Epoch: 5| Step: 8
Training loss: 2.7727127202728012
Validation loss: 2.5798641122688015

Epoch: 5| Step: 9
Training loss: 2.604878920745059
Validation loss: 2.562015534671766

Epoch: 5| Step: 10
Training loss: 2.6286260900530096
Validation loss: 2.546791309315619

Epoch: 139| Step: 0
Training loss: 2.945418702495082
Validation loss: 2.544976738002408

Epoch: 5| Step: 1
Training loss: 2.3172325989031473
Validation loss: 2.5226173877833316

Epoch: 5| Step: 2
Training loss: 2.6560657212904597
Validation loss: 2.50973343839516

Epoch: 5| Step: 3
Training loss: 2.9436153308169044
Validation loss: 2.4895139885271047

Epoch: 5| Step: 4
Training loss: 2.2570217556223917
Validation loss: 2.4886038898428353

Epoch: 5| Step: 5
Training loss: 2.9345409017349
Validation loss: 2.4891751713747543

Epoch: 5| Step: 6
Training loss: 2.5101466264489796
Validation loss: 2.4873589146138486

Epoch: 5| Step: 7
Training loss: 2.716616440135136
Validation loss: 2.48913599101263

Epoch: 5| Step: 8
Training loss: 2.2701178890654834
Validation loss: 2.522431738307791

Epoch: 5| Step: 9
Training loss: 2.5931241302966876
Validation loss: 2.5471293487664934

Epoch: 5| Step: 10
Training loss: 3.006881926613225
Validation loss: 2.5772042229599053

Epoch: 140| Step: 0
Training loss: 2.5607932384698437
Validation loss: 2.6235206281303403

Epoch: 5| Step: 1
Training loss: 2.4461925738830352
Validation loss: 2.650987994266811

Epoch: 5| Step: 2
Training loss: 2.7286251977260503
Validation loss: 2.6398202575551726

Epoch: 5| Step: 3
Training loss: 2.86174321727827
Validation loss: 2.648988214993913

Epoch: 5| Step: 4
Training loss: 2.5719955175072986
Validation loss: 2.628371926225784

Epoch: 5| Step: 5
Training loss: 2.5750887475877176
Validation loss: 2.621091920010781

Epoch: 5| Step: 6
Training loss: 3.2223051122622186
Validation loss: 2.600072600934198

Epoch: 5| Step: 7
Training loss: 2.4213952358409143
Validation loss: 2.562306458582323

Epoch: 5| Step: 8
Training loss: 2.294367452976385
Validation loss: 2.5393917393418937

Epoch: 5| Step: 9
Training loss: 2.4614337723505226
Validation loss: 2.522108557002622

Epoch: 5| Step: 10
Training loss: 2.87914027759992
Validation loss: 2.505907798958252

Epoch: 141| Step: 0
Training loss: 3.075093436953761
Validation loss: 2.499174500633016

Epoch: 5| Step: 1
Training loss: 2.47323847419986
Validation loss: 2.4999060213206414

Epoch: 5| Step: 2
Training loss: 2.8371485286607117
Validation loss: 2.5063864391889332

Epoch: 5| Step: 3
Training loss: 2.2993186356069306
Validation loss: 2.4985703379735127

Epoch: 5| Step: 4
Training loss: 3.0174134638529106
Validation loss: 2.514333578075359

Epoch: 5| Step: 5
Training loss: 2.6642101616083678
Validation loss: 2.5342443335874187

Epoch: 5| Step: 6
Training loss: 2.3375586558443704
Validation loss: 2.5469401542663683

Epoch: 5| Step: 7
Training loss: 2.666631002982395
Validation loss: 2.5742737185988203

Epoch: 5| Step: 8
Training loss: 2.5972817516701174
Validation loss: 2.5473862062051915

Epoch: 5| Step: 9
Training loss: 2.36450385633716
Validation loss: 2.5502251582961515

Epoch: 5| Step: 10
Training loss: 2.82162783058811
Validation loss: 2.5621490968581027

Epoch: 142| Step: 0
Training loss: 2.603342266564015
Validation loss: 2.5493167898935627

Epoch: 5| Step: 1
Training loss: 2.53181564227575
Validation loss: 2.51589717117475

Epoch: 5| Step: 2
Training loss: 3.0297149232013796
Validation loss: 2.5272387634149402

Epoch: 5| Step: 3
Training loss: 2.9082190293491403
Validation loss: 2.5220546491047577

Epoch: 5| Step: 4
Training loss: 2.424283903121111
Validation loss: 2.521255378170566

Epoch: 5| Step: 5
Training loss: 2.538765006610313
Validation loss: 2.523111632011797

Epoch: 5| Step: 6
Training loss: 2.8804066447760497
Validation loss: 2.524208918356968

Epoch: 5| Step: 7
Training loss: 2.502088246802578
Validation loss: 2.51990292093896

Epoch: 5| Step: 8
Training loss: 2.3899781592420575
Validation loss: 2.5252808751621436

Epoch: 5| Step: 9
Training loss: 2.5019562696664956
Validation loss: 2.5407678402396234

Epoch: 5| Step: 10
Training loss: 2.269326809786704
Validation loss: 2.551295972207129

Epoch: 143| Step: 0
Training loss: 2.44633145781003
Validation loss: 2.58536990969585

Epoch: 5| Step: 1
Training loss: 2.404163496344827
Validation loss: 2.598441994945169

Epoch: 5| Step: 2
Training loss: 2.9687260676975327
Validation loss: 2.5934287291213876

Epoch: 5| Step: 3
Training loss: 2.7373546823052144
Validation loss: 2.534590055539559

Epoch: 5| Step: 4
Training loss: 2.6344615627923056
Validation loss: 2.517948622178926

Epoch: 5| Step: 5
Training loss: 2.2741251426625024
Validation loss: 2.5044370612721565

Epoch: 5| Step: 6
Training loss: 2.51242136286566
Validation loss: 2.506893497252694

Epoch: 5| Step: 7
Training loss: 2.4559212073880126
Validation loss: 2.5023927210752266

Epoch: 5| Step: 8
Training loss: 2.7920323222565657
Validation loss: 2.480789344978482

Epoch: 5| Step: 9
Training loss: 2.394021606972435
Validation loss: 2.4925819064568224

Epoch: 5| Step: 10
Training loss: 3.197893587872027
Validation loss: 2.5054005260542493

Epoch: 144| Step: 0
Training loss: 2.587529640212272
Validation loss: 2.519666549357985

Epoch: 5| Step: 1
Training loss: 2.5816754486972227
Validation loss: 2.527456964428048

Epoch: 5| Step: 2
Training loss: 2.6569359286403853
Validation loss: 2.5388736949356003

Epoch: 5| Step: 3
Training loss: 2.677095099001509
Validation loss: 2.5512845260651273

Epoch: 5| Step: 4
Training loss: 2.0441475671103215
Validation loss: 2.588794573007507

Epoch: 5| Step: 5
Training loss: 2.5573094529869045
Validation loss: 2.6001160875755494

Epoch: 5| Step: 6
Training loss: 3.0122801261216625
Validation loss: 2.6481867497372726

Epoch: 5| Step: 7
Training loss: 2.21020754568876
Validation loss: 2.6543452923922466

Epoch: 5| Step: 8
Training loss: 2.646696705763814
Validation loss: 2.6396652995131067

Epoch: 5| Step: 9
Training loss: 2.930018861469061
Validation loss: 2.589654472627312

Epoch: 5| Step: 10
Training loss: 2.533269382807352
Validation loss: 2.5700628874636866

Epoch: 145| Step: 0
Training loss: 2.434200499013377
Validation loss: 2.5557997621276254

Epoch: 5| Step: 1
Training loss: 2.5102439810425503
Validation loss: 2.564845286718359

Epoch: 5| Step: 2
Training loss: 2.9839707345422295
Validation loss: 2.580507868561549

Epoch: 5| Step: 3
Training loss: 2.650232837452665
Validation loss: 2.591596026533297

Epoch: 5| Step: 4
Training loss: 2.9003526473208048
Validation loss: 2.568543969581975

Epoch: 5| Step: 5
Training loss: 2.4818814797702298
Validation loss: 2.5291836780603703

Epoch: 5| Step: 6
Training loss: 2.4411473495536207
Validation loss: 2.515698229504058

Epoch: 5| Step: 7
Training loss: 2.3637142068542403
Validation loss: 2.4907161383522625

Epoch: 5| Step: 8
Training loss: 2.326304088457719
Validation loss: 2.500121334166882

Epoch: 5| Step: 9
Training loss: 2.755324065019864
Validation loss: 2.516104049587514

Epoch: 5| Step: 10
Training loss: 2.442510687688522
Validation loss: 2.550291814238745

Epoch: 146| Step: 0
Training loss: 2.7257005263555643
Validation loss: 2.5981831723898483

Epoch: 5| Step: 1
Training loss: 2.926152489694332
Validation loss: 2.617310848644491

Epoch: 5| Step: 2
Training loss: 2.3515607764152215
Validation loss: 2.5718670330174156

Epoch: 5| Step: 3
Training loss: 2.51180047692781
Validation loss: 2.5459734399727685

Epoch: 5| Step: 4
Training loss: 2.802083966752634
Validation loss: 2.547693072484984

Epoch: 5| Step: 5
Training loss: 2.9367923289968574
Validation loss: 2.556046521964746

Epoch: 5| Step: 6
Training loss: 2.238387979089881
Validation loss: 2.5319111055782346

Epoch: 5| Step: 7
Training loss: 2.651927887305802
Validation loss: 2.5342804363095297

Epoch: 5| Step: 8
Training loss: 2.089948362780319
Validation loss: 2.553289969409733

Epoch: 5| Step: 9
Training loss: 2.6164500549786447
Validation loss: 2.5124817700358077

Epoch: 5| Step: 10
Training loss: 2.2512118996420227
Validation loss: 2.510461846586174

Epoch: 147| Step: 0
Training loss: 2.126503244397101
Validation loss: 2.487509480309545

Epoch: 5| Step: 1
Training loss: 2.905008850872062
Validation loss: 2.485227652512557

Epoch: 5| Step: 2
Training loss: 2.4305549863784366
Validation loss: 2.4927708609136463

Epoch: 5| Step: 3
Training loss: 2.7068005748409374
Validation loss: 2.506574430741643

Epoch: 5| Step: 4
Training loss: 2.496576826603831
Validation loss: 2.533756719932296

Epoch: 5| Step: 5
Training loss: 2.085110504003039
Validation loss: 2.5196275928415037

Epoch: 5| Step: 6
Training loss: 2.6950694983585612
Validation loss: 2.5257845390093916

Epoch: 5| Step: 7
Training loss: 2.5865450142572057
Validation loss: 2.5387673150082204

Epoch: 5| Step: 8
Training loss: 2.2664600806433053
Validation loss: 2.546580597771153

Epoch: 5| Step: 9
Training loss: 2.7497946922651106
Validation loss: 2.5380441809250507

Epoch: 5| Step: 10
Training loss: 2.7763883983702167
Validation loss: 2.543398714961185

Epoch: 148| Step: 0
Training loss: 2.5966785856992773
Validation loss: 2.5492400027100643

Epoch: 5| Step: 1
Training loss: 2.37140906058343
Validation loss: 2.5554017649627303

Epoch: 5| Step: 2
Training loss: 2.6958387662743406
Validation loss: 2.556262728302408

Epoch: 5| Step: 3
Training loss: 2.5153866293618004
Validation loss: 2.5494617316301293

Epoch: 5| Step: 4
Training loss: 2.5944167050120543
Validation loss: 2.5547703760929004

Epoch: 5| Step: 5
Training loss: 2.195529696217443
Validation loss: 2.5521215667438977

Epoch: 5| Step: 6
Training loss: 2.759643983961136
Validation loss: 2.5472441173718536

Epoch: 5| Step: 7
Training loss: 2.460757778810784
Validation loss: 2.5250326733022037

Epoch: 5| Step: 8
Training loss: 2.4160291444713193
Validation loss: 2.5219305500333498

Epoch: 5| Step: 9
Training loss: 2.4376007450509505
Validation loss: 2.5005366169899896

Epoch: 5| Step: 10
Training loss: 2.575142354641289
Validation loss: 2.521592568846156

Epoch: 149| Step: 0
Training loss: 2.73859676877829
Validation loss: 2.5153002123246506

Epoch: 5| Step: 1
Training loss: 2.231090345467586
Validation loss: 2.516667681840989

Epoch: 5| Step: 2
Training loss: 2.5867491770723015
Validation loss: 2.502036291850338

Epoch: 5| Step: 3
Training loss: 2.808325657895369
Validation loss: 2.4962757457703373

Epoch: 5| Step: 4
Training loss: 2.2114224929768276
Validation loss: 2.494158601271687

Epoch: 5| Step: 5
Training loss: 2.3157318831884823
Validation loss: 2.5125442368342408

Epoch: 5| Step: 6
Training loss: 2.0908371890374466
Validation loss: 2.4969219968826497

Epoch: 5| Step: 7
Training loss: 2.1163117684432087
Validation loss: 2.498926677822324

Epoch: 5| Step: 8
Training loss: 2.9807915868938357
Validation loss: 2.5303691788386002

Epoch: 5| Step: 9
Training loss: 2.893398130045818
Validation loss: 2.517719600065993

Epoch: 5| Step: 10
Training loss: 2.095683898553174
Validation loss: 2.556122662380083

Epoch: 150| Step: 0
Training loss: 2.080811792928503
Validation loss: 2.589500087558653

Epoch: 5| Step: 1
Training loss: 2.478764370459656
Validation loss: 2.59786546746518

Epoch: 5| Step: 2
Training loss: 2.801832696040933
Validation loss: 2.642983484461277

Epoch: 5| Step: 3
Training loss: 2.532049829779149
Validation loss: 2.662176677062655

Epoch: 5| Step: 4
Training loss: 2.4820144282927563
Validation loss: 2.620784694536511

Epoch: 5| Step: 5
Training loss: 2.805072811086084
Validation loss: 2.613805109807407

Epoch: 5| Step: 6
Training loss: 2.6587175464308386
Validation loss: 2.578804182704463

Epoch: 5| Step: 7
Training loss: 2.8302914240918877
Validation loss: 2.5352635762458786

Epoch: 5| Step: 8
Training loss: 2.249557663564475
Validation loss: 2.533623131231324

Epoch: 5| Step: 9
Training loss: 2.291218546200392
Validation loss: 2.519151552904713

Epoch: 5| Step: 10
Training loss: 2.520987818584496
Validation loss: 2.5114858157576427

Epoch: 151| Step: 0
Training loss: 2.1976729223200016
Validation loss: 2.5009700943892743

Epoch: 5| Step: 1
Training loss: 2.286217910766656
Validation loss: 2.4764723813941316

Epoch: 5| Step: 2
Training loss: 2.717411808102418
Validation loss: 2.470038577588871

Epoch: 5| Step: 3
Training loss: 2.664245778153031
Validation loss: 2.4746455811269277

Epoch: 5| Step: 4
Training loss: 2.880184309148129
Validation loss: 2.479390222595813

Epoch: 5| Step: 5
Training loss: 2.622079587099519
Validation loss: 2.505430751018821

Epoch: 5| Step: 6
Training loss: 2.579188087222415
Validation loss: 2.5236905681359256

Epoch: 5| Step: 7
Training loss: 2.159014491503919
Validation loss: 2.53788506430056

Epoch: 5| Step: 8
Training loss: 2.6940285098373415
Validation loss: 2.526976367146191

Epoch: 5| Step: 9
Training loss: 2.3615135959328364
Validation loss: 2.5151844559910916

Epoch: 5| Step: 10
Training loss: 2.7012082398808492
Validation loss: 2.5319283236237973

Epoch: 152| Step: 0
Training loss: 2.646740485041915
Validation loss: 2.5184353479346204

Epoch: 5| Step: 1
Training loss: 2.3965933105780324
Validation loss: 2.499359533860808

Epoch: 5| Step: 2
Training loss: 2.2775884009413954
Validation loss: 2.4930800731895015

Epoch: 5| Step: 3
Training loss: 2.520719688523083
Validation loss: 2.507186759958059

Epoch: 5| Step: 4
Training loss: 2.271181750618396
Validation loss: 2.485082723535124

Epoch: 5| Step: 5
Training loss: 2.5678865526934134
Validation loss: 2.5006186058344735

Epoch: 5| Step: 6
Training loss: 2.383573816966904
Validation loss: 2.4911681657263047

Epoch: 5| Step: 7
Training loss: 2.7081532540730384
Validation loss: 2.5159944346980483

Epoch: 5| Step: 8
Training loss: 2.0137192344091313
Validation loss: 2.5041495433382526

Epoch: 5| Step: 9
Training loss: 2.35388130101334
Validation loss: 2.5087839092357433

Epoch: 5| Step: 10
Training loss: 2.7451157978696235
Validation loss: 2.5137028250711633

Epoch: 153| Step: 0
Training loss: 2.4757003486875586
Validation loss: 2.5052832470584794

Epoch: 5| Step: 1
Training loss: 2.602172596736344
Validation loss: 2.5034192810776474

Epoch: 5| Step: 2
Training loss: 2.473631463123892
Validation loss: 2.5059303947119567

Epoch: 5| Step: 3
Training loss: 2.264561475866468
Validation loss: 2.525203583481418

Epoch: 5| Step: 4
Training loss: 2.438498072592353
Validation loss: 2.520420805139303

Epoch: 5| Step: 5
Training loss: 2.7004802312100886
Validation loss: 2.5139749759215686

Epoch: 5| Step: 6
Training loss: 2.214105392180577
Validation loss: 2.517946370037809

Epoch: 5| Step: 7
Training loss: 2.1587185205440615
Validation loss: 2.5085522895802397

Epoch: 5| Step: 8
Training loss: 2.3531395576097673
Validation loss: 2.5346251277295617

Epoch: 5| Step: 9
Training loss: 2.175783770301222
Validation loss: 2.5249553405181455

Epoch: 5| Step: 10
Training loss: 2.770356866316693
Validation loss: 2.5442848646430076

Epoch: 154| Step: 0
Training loss: 2.6479136981442246
Validation loss: 2.540802219742943

Epoch: 5| Step: 1
Training loss: 2.0438153644340002
Validation loss: 2.5535795351744124

Epoch: 5| Step: 2
Training loss: 2.7814950727864507
Validation loss: 2.572184291344856

Epoch: 5| Step: 3
Training loss: 2.262021270179749
Validation loss: 2.549245547349744

Epoch: 5| Step: 4
Training loss: 2.8976157943851213
Validation loss: 2.522016440012877

Epoch: 5| Step: 5
Training loss: 2.208564482293585
Validation loss: 2.520387047809965

Epoch: 5| Step: 6
Training loss: 2.125743399342313
Validation loss: 2.5013883775811268

Epoch: 5| Step: 7
Training loss: 2.366628750868986
Validation loss: 2.50361767785217

Epoch: 5| Step: 8
Training loss: 1.7772254988349414
Validation loss: 2.501666187519351

Epoch: 5| Step: 9
Training loss: 2.442767882011003
Validation loss: 2.5058612584499187

Epoch: 5| Step: 10
Training loss: 2.7222476253059504
Validation loss: 2.4867899817549906

Epoch: 155| Step: 0
Training loss: 2.146142462034194
Validation loss: 2.4956021501779406

Epoch: 5| Step: 1
Training loss: 2.0546590708807364
Validation loss: 2.496287972010598

Epoch: 5| Step: 2
Training loss: 2.2393199913685127
Validation loss: 2.4938615891846703

Epoch: 5| Step: 3
Training loss: 3.0489898384603022
Validation loss: 2.489948105078351

Epoch: 5| Step: 4
Training loss: 2.2067415030352473
Validation loss: 2.474918850939513

Epoch: 5| Step: 5
Training loss: 2.1612883596728194
Validation loss: 2.4893708600281723

Epoch: 5| Step: 6
Training loss: 2.539285315493843
Validation loss: 2.4651957303604557

Epoch: 5| Step: 7
Training loss: 2.518215764564636
Validation loss: 2.472086848535002

Epoch: 5| Step: 8
Training loss: 2.805676639155592
Validation loss: 2.520988858892509

Epoch: 5| Step: 9
Training loss: 1.8853700607468797
Validation loss: 2.5531012173772485

Epoch: 5| Step: 10
Training loss: 2.2725466526391997
Validation loss: 2.541927042561335

Epoch: 156| Step: 0
Training loss: 1.9691426324635486
Validation loss: 2.5811290751276337

Epoch: 5| Step: 1
Training loss: 1.6826162664817197
Validation loss: 2.5849062080685288

Epoch: 5| Step: 2
Training loss: 2.7187476322558384
Validation loss: 2.5929154823894285

Epoch: 5| Step: 3
Training loss: 2.3227616559184625
Validation loss: 2.599590265047825

Epoch: 5| Step: 4
Training loss: 2.672933892907887
Validation loss: 2.6102254571072967

Epoch: 5| Step: 5
Training loss: 2.6128371792273217
Validation loss: 2.5964038910065557

Epoch: 5| Step: 6
Training loss: 2.2415663227562965
Validation loss: 2.582434976028349

Epoch: 5| Step: 7
Training loss: 2.2470307361179636
Validation loss: 2.553776724467247

Epoch: 5| Step: 8
Training loss: 2.4403542655412176
Validation loss: 2.544302443303575

Epoch: 5| Step: 9
Training loss: 2.2494052524763437
Validation loss: 2.5340892394903936

Epoch: 5| Step: 10
Training loss: 2.4381998475728155
Validation loss: 2.5133814650760598

Epoch: 157| Step: 0
Training loss: 2.172193764545977
Validation loss: 2.527951930686177

Epoch: 5| Step: 1
Training loss: 2.5579230208337926
Validation loss: 2.5064764201694447

Epoch: 5| Step: 2
Training loss: 2.7964678420030906
Validation loss: 2.475129002183722

Epoch: 5| Step: 3
Training loss: 2.5261632411579784
Validation loss: 2.5133770362467707

Epoch: 5| Step: 4
Training loss: 2.2860731583951264
Validation loss: 2.511656074862782

Epoch: 5| Step: 5
Training loss: 1.9531138915699728
Validation loss: 2.5264728617478207

Epoch: 5| Step: 6
Training loss: 2.1965513161843835
Validation loss: 2.534620301096768

Epoch: 5| Step: 7
Training loss: 2.1569982142752737
Validation loss: 2.547908194663369

Epoch: 5| Step: 8
Training loss: 2.2603158767191873
Validation loss: 2.552106269966071

Epoch: 5| Step: 9
Training loss: 1.9960825820879182
Validation loss: 2.557430273518981

Epoch: 5| Step: 10
Training loss: 2.5932933911023652
Validation loss: 2.5431269195187056

Epoch: 158| Step: 0
Training loss: 1.7852350463839215
Validation loss: 2.5349836332592113

Epoch: 5| Step: 1
Training loss: 2.638812554800234
Validation loss: 2.5527956208208744

Epoch: 5| Step: 2
Training loss: 2.3115427252509093
Validation loss: 2.5596194790909172

Epoch: 5| Step: 3
Training loss: 2.0738883752166815
Validation loss: 2.5635839671240186

Epoch: 5| Step: 4
Training loss: 1.9916622890706281
Validation loss: 2.578567790032563

Epoch: 5| Step: 5
Training loss: 2.0861450549244047
Validation loss: 2.5829515767197844

Epoch: 5| Step: 6
Training loss: 2.3467125035093663
Validation loss: 2.601150451979668

Epoch: 5| Step: 7
Training loss: 2.7295208378415845
Validation loss: 2.608563732340133

Epoch: 5| Step: 8
Training loss: 2.5321493552633974
Validation loss: 2.609469085818646

Epoch: 5| Step: 9
Training loss: 2.19782826997677
Validation loss: 2.6129907250676676

Epoch: 5| Step: 10
Training loss: 2.37258758495806
Validation loss: 2.567352899989142

Epoch: 159| Step: 0
Training loss: 1.977957011196368
Validation loss: 2.5514457666338894

Epoch: 5| Step: 1
Training loss: 2.3159574488814116
Validation loss: 2.5335383086458423

Epoch: 5| Step: 2
Training loss: 2.333212190843868
Validation loss: 2.499156470169762

Epoch: 5| Step: 3
Training loss: 2.4926984018164355
Validation loss: 2.5021601184150697

Epoch: 5| Step: 4
Training loss: 2.470205047220024
Validation loss: 2.5150974469288596

Epoch: 5| Step: 5
Training loss: 1.894776066958269
Validation loss: 2.5550842669466265

Epoch: 5| Step: 6
Training loss: 2.5623099093758723
Validation loss: 2.5578745552843385

Epoch: 5| Step: 7
Training loss: 2.06840698072133
Validation loss: 2.5197016186613093

Epoch: 5| Step: 8
Training loss: 2.526278948044681
Validation loss: 2.5327066180077664

Epoch: 5| Step: 9
Training loss: 2.0782834329658884
Validation loss: 2.523272095787318

Epoch: 5| Step: 10
Training loss: 2.4316574892738494
Validation loss: 2.5484774226822804

Epoch: 160| Step: 0
Training loss: 1.9480606338691284
Validation loss: 2.583844504127986

Epoch: 5| Step: 1
Training loss: 2.300921450425158
Validation loss: 2.601241797828751

Epoch: 5| Step: 2
Training loss: 2.259308738317236
Validation loss: 2.5732465641046542

Epoch: 5| Step: 3
Training loss: 2.1078492474586996
Validation loss: 2.519210620271564

Epoch: 5| Step: 4
Training loss: 2.035639436440464
Validation loss: 2.51280492133159

Epoch: 5| Step: 5
Training loss: 2.564753588167405
Validation loss: 2.509842756766841

Epoch: 5| Step: 6
Training loss: 2.6257301405041518
Validation loss: 2.5247715119573795

Epoch: 5| Step: 7
Training loss: 1.772963136929843
Validation loss: 2.5229621962019144

Epoch: 5| Step: 8
Training loss: 2.6701518966386626
Validation loss: 2.53716406440033

Epoch: 5| Step: 9
Training loss: 2.289900590496336
Validation loss: 2.5394224203631337

Epoch: 5| Step: 10
Training loss: 2.4280673694031036
Validation loss: 2.5613235196016024

Epoch: 161| Step: 0
Training loss: 2.2125053103970522
Validation loss: 2.585383979403191

Epoch: 5| Step: 1
Training loss: 2.2884082054379147
Validation loss: 2.5932706015994675

Epoch: 5| Step: 2
Training loss: 2.0147829884555977
Validation loss: 2.5452055385130845

Epoch: 5| Step: 3
Training loss: 2.393674015602114
Validation loss: 2.5019588589669612

Epoch: 5| Step: 4
Training loss: 2.4151581188430855
Validation loss: 2.475978167627056

Epoch: 5| Step: 5
Training loss: 2.4651733758397643
Validation loss: 2.4840887101712443

Epoch: 5| Step: 6
Training loss: 2.6773133729492065
Validation loss: 2.487306732388572

Epoch: 5| Step: 7
Training loss: 2.3749362535454592
Validation loss: 2.516461099357833

Epoch: 5| Step: 8
Training loss: 2.096697426566785
Validation loss: 2.5553426563215966

Epoch: 5| Step: 9
Training loss: 1.890741644169382
Validation loss: 2.532699311331782

Epoch: 5| Step: 10
Training loss: 2.053024605396874
Validation loss: 2.5061710753887048

Epoch: 162| Step: 0
Training loss: 2.2858665470941797
Validation loss: 2.5527581490294313

Epoch: 5| Step: 1
Training loss: 1.9052134963421519
Validation loss: 2.582983238031514

Epoch: 5| Step: 2
Training loss: 2.1952525500599975
Validation loss: 2.6398698047610423

Epoch: 5| Step: 3
Training loss: 2.283664836162115
Validation loss: 2.6748761507302317

Epoch: 5| Step: 4
Training loss: 2.531022614991833
Validation loss: 2.6632059926701066

Epoch: 5| Step: 5
Training loss: 2.1778842481009453
Validation loss: 2.5491407945123603

Epoch: 5| Step: 6
Training loss: 2.4131060930967223
Validation loss: 2.5081376133445343

Epoch: 5| Step: 7
Training loss: 2.0349568509112914
Validation loss: 2.4525213178721863

Epoch: 5| Step: 8
Training loss: 2.2018792708975665
Validation loss: 2.428233144230173

Epoch: 5| Step: 9
Training loss: 2.147456496556345
Validation loss: 2.4141198770801173

Epoch: 5| Step: 10
Training loss: 2.8566427883128003
Validation loss: 2.4078750098732375

Epoch: 163| Step: 0
Training loss: 2.4100360562171774
Validation loss: 2.400602693535879

Epoch: 5| Step: 1
Training loss: 2.39657212075762
Validation loss: 2.416689507359172

Epoch: 5| Step: 2
Training loss: 2.5656632228889498
Validation loss: 2.4597484877251308

Epoch: 5| Step: 3
Training loss: 2.351136938983621
Validation loss: 2.4817008890432914

Epoch: 5| Step: 4
Training loss: 2.6297326794084843
Validation loss: 2.5029999801748293

Epoch: 5| Step: 5
Training loss: 2.5081818210639892
Validation loss: 2.5202971535433325

Epoch: 5| Step: 6
Training loss: 1.9067878589705336
Validation loss: 2.5064827513343277

Epoch: 5| Step: 7
Training loss: 1.8529075533579362
Validation loss: 2.499414952845563

Epoch: 5| Step: 8
Training loss: 2.041359145171769
Validation loss: 2.513799509590429

Epoch: 5| Step: 9
Training loss: 1.9610206616765824
Validation loss: 2.5326305267276226

Epoch: 5| Step: 10
Training loss: 1.3687298167931021
Validation loss: 2.5763806679044654

Epoch: 164| Step: 0
Training loss: 1.809112738015375
Validation loss: 2.5755858067492308

Epoch: 5| Step: 1
Training loss: 2.1291109599112628
Validation loss: 2.6178266797453413

Epoch: 5| Step: 2
Training loss: 2.4404965101895884
Validation loss: 2.6386773546196176

Epoch: 5| Step: 3
Training loss: 1.6361215453291018
Validation loss: 2.6419335618234294

Epoch: 5| Step: 4
Training loss: 2.6967552856891435
Validation loss: 2.60046150372806

Epoch: 5| Step: 5
Training loss: 2.24121710749423
Validation loss: 2.55005737278751

Epoch: 5| Step: 6
Training loss: 1.8933153793106043
Validation loss: 2.532011471821103

Epoch: 5| Step: 7
Training loss: 2.1737433431566213
Validation loss: 2.538172258505564

Epoch: 5| Step: 8
Training loss: 2.477495469013155
Validation loss: 2.537482740795232

Epoch: 5| Step: 9
Training loss: 2.2557877170031158
Validation loss: 2.5076941417934635

Epoch: 5| Step: 10
Training loss: 2.0533754053801077
Validation loss: 2.4916552880820597

Epoch: 165| Step: 0
Training loss: 2.0575995750017455
Validation loss: 2.530129868854777

Epoch: 5| Step: 1
Training loss: 2.580598049637472
Validation loss: 2.538318796088805

Epoch: 5| Step: 2
Training loss: 1.916254897736563
Validation loss: 2.5578842009610216

Epoch: 5| Step: 3
Training loss: 1.9701723682689054
Validation loss: 2.570643417431124

Epoch: 5| Step: 4
Training loss: 2.084174050134115
Validation loss: 2.6163601689987326

Epoch: 5| Step: 5
Training loss: 1.9709092666590067
Validation loss: 2.632254725140853

Epoch: 5| Step: 6
Training loss: 2.1497959350618485
Validation loss: 2.5978883340916887

Epoch: 5| Step: 7
Training loss: 2.2149214688882957
Validation loss: 2.5974894546941707

Epoch: 5| Step: 8
Training loss: 2.167336861565983
Validation loss: 2.601393128776756

Epoch: 5| Step: 9
Training loss: 2.0116432546134484
Validation loss: 2.588571271275004

Epoch: 5| Step: 10
Training loss: 2.3243859495401002
Validation loss: 2.591911753228644

Epoch: 166| Step: 0
Training loss: 1.5240539868421887
Validation loss: 2.588278591788214

Epoch: 5| Step: 1
Training loss: 2.0530384248685696
Validation loss: 2.5939001204745122

Epoch: 5| Step: 2
Training loss: 2.0600021727096802
Validation loss: 2.573102656286333

Epoch: 5| Step: 3
Training loss: 2.031732707255482
Validation loss: 2.5456709510404636

Epoch: 5| Step: 4
Training loss: 2.314193208803474
Validation loss: 2.5478212456035836

Epoch: 5| Step: 5
Training loss: 2.219783381126356
Validation loss: 2.550155478717447

Epoch: 5| Step: 6
Training loss: 2.4221557454466454
Validation loss: 2.5107531680503907

Epoch: 5| Step: 7
Training loss: 2.194535521804927
Validation loss: 2.5217752109818066

Epoch: 5| Step: 8
Training loss: 2.0847148383739262
Validation loss: 2.536246536231412

Epoch: 5| Step: 9
Training loss: 2.102993842877323
Validation loss: 2.5676301627571925

Epoch: 5| Step: 10
Training loss: 2.038508899121933
Validation loss: 2.5887380856282354

Epoch: 167| Step: 0
Training loss: 2.447201617622402
Validation loss: 2.597956756128011

Epoch: 5| Step: 1
Training loss: 1.5345014189871762
Validation loss: 2.6140621119913523

Epoch: 5| Step: 2
Training loss: 1.979080466016174
Validation loss: 2.6029628429027682

Epoch: 5| Step: 3
Training loss: 2.0842085970636957
Validation loss: 2.575405285524184

Epoch: 5| Step: 4
Training loss: 2.048902366609485
Validation loss: 2.5668782673413437

Epoch: 5| Step: 5
Training loss: 1.4657010837481954
Validation loss: 2.5485761346352676

Epoch: 5| Step: 6
Training loss: 2.4293760241090947
Validation loss: 2.5258141774958975

Epoch: 5| Step: 7
Training loss: 2.3802760898509265
Validation loss: 2.4983156108371953

Epoch: 5| Step: 8
Training loss: 2.2413059322528697
Validation loss: 2.540692466648606

Epoch: 5| Step: 9
Training loss: 2.2810771301822155
Validation loss: 2.574716606399339

Epoch: 5| Step: 10
Training loss: 1.7775556836211976
Validation loss: 2.590056137378983

Epoch: 168| Step: 0
Training loss: 1.7146601480896018
Validation loss: 2.5913732486500565

Epoch: 5| Step: 1
Training loss: 1.8109559684384384
Validation loss: 2.6588046486204195

Epoch: 5| Step: 2
Training loss: 2.2510420187744353
Validation loss: 2.688351367773251

Epoch: 5| Step: 3
Training loss: 1.4357062218906629
Validation loss: 2.734659064050865

Epoch: 5| Step: 4
Training loss: 2.1614025307924405
Validation loss: 2.7599410597922276

Epoch: 5| Step: 5
Training loss: 2.368137886453272
Validation loss: 2.7331834260014234

Epoch: 5| Step: 6
Training loss: 1.9056035180662336
Validation loss: 2.632254906292448

Epoch: 5| Step: 7
Training loss: 2.1668969056480356
Validation loss: 2.576276441738536

Epoch: 5| Step: 8
Training loss: 2.4185589145616375
Validation loss: 2.5244775582700716

Epoch: 5| Step: 9
Training loss: 1.9810430232098317
Validation loss: 2.4956198683533763

Epoch: 5| Step: 10
Training loss: 2.270390306939207
Validation loss: 2.4645063793010675

Epoch: 169| Step: 0
Training loss: 1.82921861069365
Validation loss: 2.451204805472018

Epoch: 5| Step: 1
Training loss: 1.9208248339593923
Validation loss: 2.4441786504747154

Epoch: 5| Step: 2
Training loss: 2.1447675953410203
Validation loss: 2.439338105144492

Epoch: 5| Step: 3
Training loss: 2.079165205512237
Validation loss: 2.448316876422103

Epoch: 5| Step: 4
Training loss: 1.6231925155352411
Validation loss: 2.4323572108393052

Epoch: 5| Step: 5
Training loss: 1.5997437361296374
Validation loss: 2.4685645988549956

Epoch: 5| Step: 6
Training loss: 2.3142412177186373
Validation loss: 2.4655247382951075

Epoch: 5| Step: 7
Training loss: 2.187211480868331
Validation loss: 2.477492039779458

Epoch: 5| Step: 8
Training loss: 1.966422627819969
Validation loss: 2.503607843581851

Epoch: 5| Step: 9
Training loss: 2.3757615123406826
Validation loss: 2.537786658782579

Epoch: 5| Step: 10
Training loss: 2.1075855718324785
Validation loss: 2.5879550656332597

Epoch: 170| Step: 0
Training loss: 2.139139258468312
Validation loss: 2.6515090085296578

Epoch: 5| Step: 1
Training loss: 2.1797672380198256
Validation loss: 2.685116459964141

Epoch: 5| Step: 2
Training loss: 1.8012505372871905
Validation loss: 2.654828589219783

Epoch: 5| Step: 3
Training loss: 2.1448990970167006
Validation loss: 2.629248312882456

Epoch: 5| Step: 4
Training loss: 1.7861177288438417
Validation loss: 2.6112210917418097

Epoch: 5| Step: 5
Training loss: 2.020499316529987
Validation loss: 2.5901798585824367

Epoch: 5| Step: 6
Training loss: 1.9707632518779095
Validation loss: 2.56027176423932

Epoch: 5| Step: 7
Training loss: 2.2177216201701944
Validation loss: 2.542354344120859

Epoch: 5| Step: 8
Training loss: 1.7559496694055885
Validation loss: 2.5148617857937214

Epoch: 5| Step: 9
Training loss: 2.062104273892926
Validation loss: 2.5308683050124734

Epoch: 5| Step: 10
Training loss: 1.853368144303031
Validation loss: 2.5094330478045683

Epoch: 171| Step: 0
Training loss: 2.06180838346332
Validation loss: 2.5289905535703983

Epoch: 5| Step: 1
Training loss: 1.6879186464158558
Validation loss: 2.552928575815115

Epoch: 5| Step: 2
Training loss: 1.6800540967587587
Validation loss: 2.625797867315601

Epoch: 5| Step: 3
Training loss: 2.4013257854998953
Validation loss: 2.6494315048600416

Epoch: 5| Step: 4
Training loss: 1.911811283243251
Validation loss: 2.6849993198669124

Epoch: 5| Step: 5
Training loss: 2.5367056369002
Validation loss: 2.644587708928382

Epoch: 5| Step: 6
Training loss: 1.532362708807544
Validation loss: 2.586050576044982

Epoch: 5| Step: 7
Training loss: 2.2824803000328044
Validation loss: 2.524740707728149

Epoch: 5| Step: 8
Training loss: 2.16867202486693
Validation loss: 2.512184525116964

Epoch: 5| Step: 9
Training loss: 1.5462418618755152
Validation loss: 2.4679145806550062

Epoch: 5| Step: 10
Training loss: 1.7275053185962115
Validation loss: 2.4418460289389374

Epoch: 172| Step: 0
Training loss: 2.0311509328305655
Validation loss: 2.4207228826870133

Epoch: 5| Step: 1
Training loss: 1.5728869993262504
Validation loss: 2.456066480373551

Epoch: 5| Step: 2
Training loss: 2.035004417920765
Validation loss: 2.4291860780995895

Epoch: 5| Step: 3
Training loss: 2.209280842416311
Validation loss: 2.3983584828514632

Epoch: 5| Step: 4
Training loss: 2.110612746302826
Validation loss: 2.456392821353084

Epoch: 5| Step: 5
Training loss: 1.8874636615008853
Validation loss: 2.4780198810197693

Epoch: 5| Step: 6
Training loss: 1.8598066838617044
Validation loss: 2.5138943812870185

Epoch: 5| Step: 7
Training loss: 1.9767474061623997
Validation loss: 2.5290790739810687

Epoch: 5| Step: 8
Training loss: 1.5969390378530097
Validation loss: 2.6230362262374833

Epoch: 5| Step: 9
Training loss: 2.350291367993622
Validation loss: 2.661199832917886

Epoch: 5| Step: 10
Training loss: 2.1254209213747703
Validation loss: 2.594486218571172

Epoch: 173| Step: 0
Training loss: 1.6838475011789407
Validation loss: 2.5820463089285597

Epoch: 5| Step: 1
Training loss: 2.1326432492798064
Validation loss: 2.5233354506257033

Epoch: 5| Step: 2
Training loss: 1.6881985101721049
Validation loss: 2.500522792666982

Epoch: 5| Step: 3
Training loss: 1.895988485953221
Validation loss: 2.4434010510228883

Epoch: 5| Step: 4
Training loss: 1.7735529790578985
Validation loss: 2.429976747176132

Epoch: 5| Step: 5
Training loss: 2.3711250215130506
Validation loss: 2.403538162770203

Epoch: 5| Step: 6
Training loss: 1.7558455249210432
Validation loss: 2.397186432934501

Epoch: 5| Step: 7
Training loss: 2.089626179715733
Validation loss: 2.428421505772563

Epoch: 5| Step: 8
Training loss: 2.063269153864285
Validation loss: 2.457329479054006

Epoch: 5| Step: 9
Training loss: 1.9576419326754353
Validation loss: 2.5143082967086836

Epoch: 5| Step: 10
Training loss: 2.1116738684736416
Validation loss: 2.594801921610729

Epoch: 174| Step: 0
Training loss: 1.7880455358369145
Validation loss: 2.6522930845467285

Epoch: 5| Step: 1
Training loss: 1.7472429355484527
Validation loss: 2.6781332511553146

Epoch: 5| Step: 2
Training loss: 2.0235183287276586
Validation loss: 2.7107680957170817

Epoch: 5| Step: 3
Training loss: 1.9356534834217334
Validation loss: 2.68982495424985

Epoch: 5| Step: 4
Training loss: 1.894664264217485
Validation loss: 2.6533520404174555

Epoch: 5| Step: 5
Training loss: 1.9629321041753882
Validation loss: 2.587668976040104

Epoch: 5| Step: 6
Training loss: 1.8175972920105465
Validation loss: 2.521981342923611

Epoch: 5| Step: 7
Training loss: 2.3187311094599337
Validation loss: 2.5376719241313466

Epoch: 5| Step: 8
Training loss: 1.6985065239126054
Validation loss: 2.491530493391589

Epoch: 5| Step: 9
Training loss: 2.2313557746669734
Validation loss: 2.4860162136163706

Epoch: 5| Step: 10
Training loss: 2.0082395819259977
Validation loss: 2.459802180057434

Epoch: 175| Step: 0
Training loss: 1.6394042059812428
Validation loss: 2.473911325799339

Epoch: 5| Step: 1
Training loss: 1.7472973116878303
Validation loss: 2.4759727938683085

Epoch: 5| Step: 2
Training loss: 1.863354759445702
Validation loss: 2.4860596752209956

Epoch: 5| Step: 3
Training loss: 2.1474239663640473
Validation loss: 2.4879595224851814

Epoch: 5| Step: 4
Training loss: 2.4651261785993865
Validation loss: 2.5252710876935467

Epoch: 5| Step: 5
Training loss: 1.669948858745805
Validation loss: 2.5641869345435344

Epoch: 5| Step: 6
Training loss: 1.9840283428982521
Validation loss: 2.577072429856914

Epoch: 5| Step: 7
Training loss: 1.9510482122661434
Validation loss: 2.5810566600999536

Epoch: 5| Step: 8
Training loss: 1.6049413255561036
Validation loss: 2.583978277380336

Epoch: 5| Step: 9
Training loss: 1.9656087246995808
Validation loss: 2.5673552765466803

Epoch: 5| Step: 10
Training loss: 1.6879747923736068
Validation loss: 2.5884793733080342

Epoch: 176| Step: 0
Training loss: 1.9766236548330234
Validation loss: 2.5905935832538347

Epoch: 5| Step: 1
Training loss: 1.7607758360666184
Validation loss: 2.5467779555140306

Epoch: 5| Step: 2
Training loss: 1.7508152016680245
Validation loss: 2.543909585778375

Epoch: 5| Step: 3
Training loss: 1.438473993468726
Validation loss: 2.509347327331902

Epoch: 5| Step: 4
Training loss: 1.5493502608675096
Validation loss: 2.4845645992396452

Epoch: 5| Step: 5
Training loss: 2.0345316274326337
Validation loss: 2.5148033166235897

Epoch: 5| Step: 6
Training loss: 1.9273425228639183
Validation loss: 2.503923846959461

Epoch: 5| Step: 7
Training loss: 2.0419949896860254
Validation loss: 2.541404725416879

Epoch: 5| Step: 8
Training loss: 2.196386868549498
Validation loss: 2.5688365273298386

Epoch: 5| Step: 9
Training loss: 1.8118178300631431
Validation loss: 2.5638426777887897

Epoch: 5| Step: 10
Training loss: 2.0451541102011497
Validation loss: 2.5894929594500002

Epoch: 177| Step: 0
Training loss: 2.031205631651852
Validation loss: 2.6184057587191654

Epoch: 5| Step: 1
Training loss: 1.817614081998795
Validation loss: 2.5733577470924667

Epoch: 5| Step: 2
Training loss: 1.5646461243946281
Validation loss: 2.5552737252792364

Epoch: 5| Step: 3
Training loss: 1.559416895362844
Validation loss: 2.5729828915229658

Epoch: 5| Step: 4
Training loss: 2.0223897334761727
Validation loss: 2.567247036098924

Epoch: 5| Step: 5
Training loss: 1.4715388989454607
Validation loss: 2.5514325984609707

Epoch: 5| Step: 6
Training loss: 1.9812488712343677
Validation loss: 2.5476415816604465

Epoch: 5| Step: 7
Training loss: 2.0143407234402684
Validation loss: 2.5897840178299827

Epoch: 5| Step: 8
Training loss: 2.0209549804988542
Validation loss: 2.5281129532407896

Epoch: 5| Step: 9
Training loss: 1.7623725574491904
Validation loss: 2.56735702601116

Epoch: 5| Step: 10
Training loss: 2.094693099601599
Validation loss: 2.58324559612187

Epoch: 178| Step: 0
Training loss: 1.873478908256185
Validation loss: 2.6363858401786637

Epoch: 5| Step: 1
Training loss: 1.6229294276521338
Validation loss: 2.635319909161299

Epoch: 5| Step: 2
Training loss: 1.5204687683149374
Validation loss: 2.6558490235782584

Epoch: 5| Step: 3
Training loss: 1.8643683694995878
Validation loss: 2.6303329498358394

Epoch: 5| Step: 4
Training loss: 1.6884543934255312
Validation loss: 2.6195943345408943

Epoch: 5| Step: 5
Training loss: 1.5106492312929907
Validation loss: 2.598119150226138

Epoch: 5| Step: 6
Training loss: 2.1498185591320773
Validation loss: 2.591641170361919

Epoch: 5| Step: 7
Training loss: 2.2688037540173376
Validation loss: 2.5812950892504025

Epoch: 5| Step: 8
Training loss: 1.6638831100122928
Validation loss: 2.5408337580103497

Epoch: 5| Step: 9
Training loss: 2.337710826974324
Validation loss: 2.5578240912852195

Epoch: 5| Step: 10
Training loss: 1.492631776190368
Validation loss: 2.5497514616881873

Epoch: 179| Step: 0
Training loss: 1.9148140190988332
Validation loss: 2.533102326258293

Epoch: 5| Step: 1
Training loss: 2.2050645015217993
Validation loss: 2.5295624814321562

Epoch: 5| Step: 2
Training loss: 1.8473613092297319
Validation loss: 2.5499408628204385

Epoch: 5| Step: 3
Training loss: 1.7515912314788527
Validation loss: 2.551251618748856

Epoch: 5| Step: 4
Training loss: 1.74721482576396
Validation loss: 2.591380952302923

Epoch: 5| Step: 5
Training loss: 2.010568708557316
Validation loss: 2.6160236433334974

Epoch: 5| Step: 6
Training loss: 1.4341067194153019
Validation loss: 2.6114966653610536

Epoch: 5| Step: 7
Training loss: 1.595264014871954
Validation loss: 2.659371150123545

Epoch: 5| Step: 8
Training loss: 1.7792364417992388
Validation loss: 2.7198264245085646

Epoch: 5| Step: 9
Training loss: 1.9002511109503315
Validation loss: 2.712083877288337

Epoch: 5| Step: 10
Training loss: 1.9529977985922442
Validation loss: 2.6804208222364614

Epoch: 180| Step: 0
Training loss: 1.8770881469303553
Validation loss: 2.6284244397348515

Epoch: 5| Step: 1
Training loss: 2.0715169605883923
Validation loss: 2.5890749536355955

Epoch: 5| Step: 2
Training loss: 1.9757373881873317
Validation loss: 2.573600169762187

Epoch: 5| Step: 3
Training loss: 1.7170399568604104
Validation loss: 2.5227906545338845

Epoch: 5| Step: 4
Training loss: 1.6624306571094223
Validation loss: 2.539034688211967

Epoch: 5| Step: 5
Training loss: 2.074110010317655
Validation loss: 2.5559374425249004

Epoch: 5| Step: 6
Training loss: 1.97869733633108
Validation loss: 2.614702765618034

Epoch: 5| Step: 7
Training loss: 1.5756012026462387
Validation loss: 2.6007206150881648

Epoch: 5| Step: 8
Training loss: 1.3970888763478568
Validation loss: 2.6373494567426556

Epoch: 5| Step: 9
Training loss: 1.4509483360331201
Validation loss: 2.677733621532635

Epoch: 5| Step: 10
Training loss: 2.063838986489038
Validation loss: 2.6457800368474627

Epoch: 181| Step: 0
Training loss: 1.9169037575518895
Validation loss: 2.629563476955598

Epoch: 5| Step: 1
Training loss: 2.151963769841729
Validation loss: 2.5891012832794775

Epoch: 5| Step: 2
Training loss: 1.451625583620643
Validation loss: 2.5720909826099096

Epoch: 5| Step: 3
Training loss: 1.698951507249034
Validation loss: 2.5084438245538627

Epoch: 5| Step: 4
Training loss: 1.4397543769209515
Validation loss: 2.519056243139893

Epoch: 5| Step: 5
Training loss: 2.174743733710253
Validation loss: 2.5248815946332672

Epoch: 5| Step: 6
Training loss: 1.7717856221472672
Validation loss: 2.519049861142336

Epoch: 5| Step: 7
Training loss: 1.6590632172692739
Validation loss: 2.506379875594732

Epoch: 5| Step: 8
Training loss: 1.7600398215210484
Validation loss: 2.545540117633093

Epoch: 5| Step: 9
Training loss: 1.638875773569564
Validation loss: 2.535269724291514

Epoch: 5| Step: 10
Training loss: 1.7759799293982024
Validation loss: 2.5672652504112414

Epoch: 182| Step: 0
Training loss: 1.6976500537827701
Validation loss: 2.5480867089469807

Epoch: 5| Step: 1
Training loss: 1.8674016215240246
Validation loss: 2.5339275111266106

Epoch: 5| Step: 2
Training loss: 1.4288562797205757
Validation loss: 2.5299500095043235

Epoch: 5| Step: 3
Training loss: 2.3546807282065036
Validation loss: 2.5563640910105065

Epoch: 5| Step: 4
Training loss: 1.6497128150010716
Validation loss: 2.58195434056633

Epoch: 5| Step: 5
Training loss: 1.8494191056768021
Validation loss: 2.5949452711758734

Epoch: 5| Step: 6
Training loss: 1.6336085373123916
Validation loss: 2.6066333057160302

Epoch: 5| Step: 7
Training loss: 1.315793491909517
Validation loss: 2.6252000442434005

Epoch: 5| Step: 8
Training loss: 1.8619008579104044
Validation loss: 2.624301690556077

Epoch: 5| Step: 9
Training loss: 1.5217570891712624
Validation loss: 2.5918051164713978

Epoch: 5| Step: 10
Training loss: 2.044832331492246
Validation loss: 2.5947605629948685

Epoch: 183| Step: 0
Training loss: 1.9927609085934919
Validation loss: 2.546328774617245

Epoch: 5| Step: 1
Training loss: 1.8585447493351814
Validation loss: 2.5437247112261074

Epoch: 5| Step: 2
Training loss: 2.059563829855848
Validation loss: 2.5026936130242703

Epoch: 5| Step: 3
Training loss: 1.3746555937411409
Validation loss: 2.5248098722776513

Epoch: 5| Step: 4
Training loss: 1.9211320138714256
Validation loss: 2.555678922693293

Epoch: 5| Step: 5
Training loss: 1.94604380393053
Validation loss: 2.5366402803962442

Epoch: 5| Step: 6
Training loss: 1.3894285562877835
Validation loss: 2.571207531445246

Epoch: 5| Step: 7
Training loss: 1.7301784986679287
Validation loss: 2.5696227682401003

Epoch: 5| Step: 8
Training loss: 1.4962715063246503
Validation loss: 2.5834839175262294

Epoch: 5| Step: 9
Training loss: 1.606352328592208
Validation loss: 2.5599732686096885

Epoch: 5| Step: 10
Training loss: 1.559690620115045
Validation loss: 2.5983803628584083

Epoch: 184| Step: 0
Training loss: 1.778200450295372
Validation loss: 2.6157235299990726

Epoch: 5| Step: 1
Training loss: 1.8287596293865345
Validation loss: 2.6129925283537707

Epoch: 5| Step: 2
Training loss: 1.2914248927271372
Validation loss: 2.5932940840867578

Epoch: 5| Step: 3
Training loss: 1.4103700259154015
Validation loss: 2.5854290199987804

Epoch: 5| Step: 4
Training loss: 1.9754970528656168
Validation loss: 2.578355907989352

Epoch: 5| Step: 5
Training loss: 1.9546072256557565
Validation loss: 2.6141712020949797

Epoch: 5| Step: 6
Training loss: 1.6944041125738432
Validation loss: 2.583870488217551

Epoch: 5| Step: 7
Training loss: 2.0824010924885625
Validation loss: 2.5926921024878324

Epoch: 5| Step: 8
Training loss: 1.2639186800891247
Validation loss: 2.54946999934361

Epoch: 5| Step: 9
Training loss: 1.5896697827884088
Validation loss: 2.581027422557698

Epoch: 5| Step: 10
Training loss: 1.766792519003377
Validation loss: 2.561873763882761

Epoch: 185| Step: 0
Training loss: 1.7396058939614862
Validation loss: 2.5947203814421766

Epoch: 5| Step: 1
Training loss: 1.3957509922773608
Validation loss: 2.620744217459064

Epoch: 5| Step: 2
Training loss: 1.9350205830901184
Validation loss: 2.653824195461621

Epoch: 5| Step: 3
Training loss: 1.7152427261347314
Validation loss: 2.655154758716297

Epoch: 5| Step: 4
Training loss: 1.4561561226771769
Validation loss: 2.6908150345675756

Epoch: 5| Step: 5
Training loss: 1.7425947183837849
Validation loss: 2.628510990125051

Epoch: 5| Step: 6
Training loss: 1.980110753073334
Validation loss: 2.6456534709132837

Epoch: 5| Step: 7
Training loss: 1.6074708951981997
Validation loss: 2.62845418684575

Epoch: 5| Step: 8
Training loss: 1.6914985754879268
Validation loss: 2.635285932910554

Epoch: 5| Step: 9
Training loss: 1.4920897926177261
Validation loss: 2.6026477205161864

Epoch: 5| Step: 10
Training loss: 1.6480291502605902
Validation loss: 2.586318999581117

Epoch: 186| Step: 0
Training loss: 1.499947070141583
Validation loss: 2.587522495776956

Epoch: 5| Step: 1
Training loss: 1.8717958411290265
Validation loss: 2.607084924221059

Epoch: 5| Step: 2
Training loss: 1.8617533371210189
Validation loss: 2.580776188136446

Epoch: 5| Step: 3
Training loss: 1.3158699550609863
Validation loss: 2.6424469264009507

Epoch: 5| Step: 4
Training loss: 2.0426660025290926
Validation loss: 2.6003509925873947

Epoch: 5| Step: 5
Training loss: 1.7753943851376572
Validation loss: 2.599042991978824

Epoch: 5| Step: 6
Training loss: 0.9458370172258019
Validation loss: 2.605192024098002

Epoch: 5| Step: 7
Training loss: 1.6308060871486916
Validation loss: 2.5719282996883575

Epoch: 5| Step: 8
Training loss: 1.563520860967731
Validation loss: 2.598947166481189

Epoch: 5| Step: 9
Training loss: 1.7851211243894503
Validation loss: 2.5905954100471127

Epoch: 5| Step: 10
Training loss: 1.7506110623127282
Validation loss: 2.5769541130291653

Epoch: 187| Step: 0
Training loss: 1.3829430556224285
Validation loss: 2.5524977012157017

Epoch: 5| Step: 1
Training loss: 1.6600144987737053
Validation loss: 2.5646537325729666

Epoch: 5| Step: 2
Training loss: 1.528297692274695
Validation loss: 2.576685180541302

Epoch: 5| Step: 3
Training loss: 2.0032243962852885
Validation loss: 2.563105303857173

Epoch: 5| Step: 4
Training loss: 1.7993092509610102
Validation loss: 2.5873041395974345

Epoch: 5| Step: 5
Training loss: 1.6504058656609535
Validation loss: 2.6181719468047353

Epoch: 5| Step: 6
Training loss: 1.3498903636211728
Validation loss: 2.612285350489932

Epoch: 5| Step: 7
Training loss: 1.3801073241309878
Validation loss: 2.6640677455193322

Epoch: 5| Step: 8
Training loss: 1.701509251737818
Validation loss: 2.6653636636587197

Epoch: 5| Step: 9
Training loss: 1.8254528241588086
Validation loss: 2.6638135044578544

Epoch: 5| Step: 10
Training loss: 1.7406526655809924
Validation loss: 2.6950195020085372

Epoch: 188| Step: 0
Training loss: 1.4704121862948396
Validation loss: 2.7068764099045746

Epoch: 5| Step: 1
Training loss: 1.6425163629375812
Validation loss: 2.669222607280753

Epoch: 5| Step: 2
Training loss: 1.5119840009741043
Validation loss: 2.6491702967434496

Epoch: 5| Step: 3
Training loss: 1.5589984569138187
Validation loss: 2.6303637942426312

Epoch: 5| Step: 4
Training loss: 1.9206850663539274
Validation loss: 2.6255442127953597

Epoch: 5| Step: 5
Training loss: 1.643019318720706
Validation loss: 2.6118166177750264

Epoch: 5| Step: 6
Training loss: 1.4594580355103641
Validation loss: 2.5861717182242607

Epoch: 5| Step: 7
Training loss: 1.5446868987856897
Validation loss: 2.577557434870872

Epoch: 5| Step: 8
Training loss: 1.7976369817796136
Validation loss: 2.5708039897866777

Epoch: 5| Step: 9
Training loss: 1.6971293615288092
Validation loss: 2.5833553524316097

Epoch: 5| Step: 10
Training loss: 1.6273970164400702
Validation loss: 2.58576156017193

Epoch: 189| Step: 0
Training loss: 1.7788890785859452
Validation loss: 2.560570462356334

Epoch: 5| Step: 1
Training loss: 1.4562811262872692
Validation loss: 2.559138907254631

Epoch: 5| Step: 2
Training loss: 2.1102223142686194
Validation loss: 2.5505201268912496

Epoch: 5| Step: 3
Training loss: 1.5636705210344188
Validation loss: 2.616820972473611

Epoch: 5| Step: 4
Training loss: 1.6679202928137578
Validation loss: 2.6066052382582154

Epoch: 5| Step: 5
Training loss: 1.680714138244767
Validation loss: 2.5870535444504643

Epoch: 5| Step: 6
Training loss: 1.510114030006084
Validation loss: 2.6305770178638612

Epoch: 5| Step: 7
Training loss: 1.4253328637305813
Validation loss: 2.630920402140063

Epoch: 5| Step: 8
Training loss: 1.7674739237889208
Validation loss: 2.5916932569340654

Epoch: 5| Step: 9
Training loss: 1.143211984469073
Validation loss: 2.6080395107638368

Epoch: 5| Step: 10
Training loss: 1.30883422463958
Validation loss: 2.6036296223452613

Epoch: 190| Step: 0
Training loss: 1.7217867293812519
Validation loss: 2.5958105008420453

Epoch: 5| Step: 1
Training loss: 1.5491872133093223
Validation loss: 2.626221950061206

Epoch: 5| Step: 2
Training loss: 1.4555032608273513
Validation loss: 2.6456248474404003

Epoch: 5| Step: 3
Training loss: 1.3899852695645099
Validation loss: 2.6884035183295043

Epoch: 5| Step: 4
Training loss: 1.441784899425975
Validation loss: 2.711313484798248

Epoch: 5| Step: 5
Training loss: 1.578244195345835
Validation loss: 2.6844099136670745

Epoch: 5| Step: 6
Training loss: 1.9569459694804607
Validation loss: 2.645037263795817

Epoch: 5| Step: 7
Training loss: 1.6605375682253234
Validation loss: 2.599702677240377

Epoch: 5| Step: 8
Training loss: 1.349008826804498
Validation loss: 2.554355834252174

Epoch: 5| Step: 9
Training loss: 1.4734262735013972
Validation loss: 2.537067124397994

Epoch: 5| Step: 10
Training loss: 2.1153788706561425
Validation loss: 2.503799682702235

Epoch: 191| Step: 0
Training loss: 1.4004277393312299
Validation loss: 2.5435413633112725

Epoch: 5| Step: 1
Training loss: 1.496702224858452
Validation loss: 2.5542442396584084

Epoch: 5| Step: 2
Training loss: 1.5588580602955606
Validation loss: 2.5651287948219808

Epoch: 5| Step: 3
Training loss: 1.663898800243874
Validation loss: 2.60275876747564

Epoch: 5| Step: 4
Training loss: 1.4797918135904164
Validation loss: 2.581692143199637

Epoch: 5| Step: 5
Training loss: 1.424127827146917
Validation loss: 2.6618620902149783

Epoch: 5| Step: 6
Training loss: 1.3430991703636703
Validation loss: 2.7046536389879337

Epoch: 5| Step: 7
Training loss: 1.63809546789324
Validation loss: 2.733451615627302

Epoch: 5| Step: 8
Training loss: 1.7569071833194718
Validation loss: 2.7326860997399596

Epoch: 5| Step: 9
Training loss: 1.7435741978559316
Validation loss: 2.7330396597503794

Epoch: 5| Step: 10
Training loss: 1.8856677174494725
Validation loss: 2.7428486447750773

Epoch: 192| Step: 0
Training loss: 1.5226673233467285
Validation loss: 2.693316269738991

Epoch: 5| Step: 1
Training loss: 1.9296540168606333
Validation loss: 2.6576802195695977

Epoch: 5| Step: 2
Training loss: 1.414777374817038
Validation loss: 2.6628760948460384

Epoch: 5| Step: 3
Training loss: 1.857747367313898
Validation loss: 2.642507126154247

Epoch: 5| Step: 4
Training loss: 1.8442523724474909
Validation loss: 2.617066888382472

Epoch: 5| Step: 5
Training loss: 1.0962185386919154
Validation loss: 2.645104232633407

Epoch: 5| Step: 6
Training loss: 1.5579968220013585
Validation loss: 2.7056600631001024

Epoch: 5| Step: 7
Training loss: 1.5373821864696398
Validation loss: 2.725901404052976

Epoch: 5| Step: 8
Training loss: 1.847646959212899
Validation loss: 2.7045747187778058

Epoch: 5| Step: 9
Training loss: 1.379481122835201
Validation loss: 2.7189753892424062

Epoch: 5| Step: 10
Training loss: 1.4180949341506703
Validation loss: 2.680803098120761

Epoch: 193| Step: 0
Training loss: 1.8552846074332794
Validation loss: 2.6389240073296145

Epoch: 5| Step: 1
Training loss: 1.7587177573517627
Validation loss: 2.5362970474779782

Epoch: 5| Step: 2
Training loss: 1.4077618419411317
Validation loss: 2.517538299114436

Epoch: 5| Step: 3
Training loss: 1.510453120701545
Validation loss: 2.489210509592049

Epoch: 5| Step: 4
Training loss: 1.6573936544511143
Validation loss: 2.524723060899636

Epoch: 5| Step: 5
Training loss: 1.5392523324145486
Validation loss: 2.4785834522899908

Epoch: 5| Step: 6
Training loss: 1.804663059349856
Validation loss: 2.536511013695705

Epoch: 5| Step: 7
Training loss: 0.9904834501779657
Validation loss: 2.5698455517054692

Epoch: 5| Step: 8
Training loss: 1.4092052771980297
Validation loss: 2.6565364695235782

Epoch: 5| Step: 9
Training loss: 1.6223785089228098
Validation loss: 2.6621220029334114

Epoch: 5| Step: 10
Training loss: 1.5950928061340708
Validation loss: 2.661415929275698

Epoch: 194| Step: 0
Training loss: 1.6522039981117171
Validation loss: 2.7349443190467913

Epoch: 5| Step: 1
Training loss: 2.0738598644179533
Validation loss: 2.7375601588398726

Epoch: 5| Step: 2
Training loss: 1.6555208724540018
Validation loss: 2.7145754256831482

Epoch: 5| Step: 3
Training loss: 1.4423393392758872
Validation loss: 2.6307568423587417

Epoch: 5| Step: 4
Training loss: 1.5098381863980772
Validation loss: 2.5701636570423494

Epoch: 5| Step: 5
Training loss: 1.2387491298945785
Validation loss: 2.5203234021950083

Epoch: 5| Step: 6
Training loss: 1.418578886224612
Validation loss: 2.5047420493900896

Epoch: 5| Step: 7
Training loss: 1.722543518114624
Validation loss: 2.545734176435414

Epoch: 5| Step: 8
Training loss: 1.6597838219668373
Validation loss: 2.5517981662274147

Epoch: 5| Step: 9
Training loss: 1.6297590552738372
Validation loss: 2.595401968759142

Epoch: 5| Step: 10
Training loss: 1.3947237026226411
Validation loss: 2.6424271987527805

Epoch: 195| Step: 0
Training loss: 1.9800146059981023
Validation loss: 2.6915648108113026

Epoch: 5| Step: 1
Training loss: 1.3253933358719836
Validation loss: 2.712414128389509

Epoch: 5| Step: 2
Training loss: 1.3649959328699128
Validation loss: 2.7957139177685506

Epoch: 5| Step: 3
Training loss: 1.3462610071098866
Validation loss: 2.742329924754373

Epoch: 5| Step: 4
Training loss: 2.1523846243353995
Validation loss: 2.6762360054269374

Epoch: 5| Step: 5
Training loss: 1.6881208337409686
Validation loss: 2.558687003887251

Epoch: 5| Step: 6
Training loss: 1.3328600679341247
Validation loss: 2.5294709632590044

Epoch: 5| Step: 7
Training loss: 1.1446798182590845
Validation loss: 2.4967301165236413

Epoch: 5| Step: 8
Training loss: 1.5023964176874647
Validation loss: 2.4884593985685965

Epoch: 5| Step: 9
Training loss: 1.84371256386203
Validation loss: 2.5076138973581505

Epoch: 5| Step: 10
Training loss: 1.3360275773582868
Validation loss: 2.513103352706718

Epoch: 196| Step: 0
Training loss: 1.8876476962679847
Validation loss: 2.5601142984781227

Epoch: 5| Step: 1
Training loss: 1.560619137729669
Validation loss: 2.55562884468053

Epoch: 5| Step: 2
Training loss: 1.8019844718966884
Validation loss: 2.6080635847215996

Epoch: 5| Step: 3
Training loss: 1.818452072648944
Validation loss: 2.6419688382477866

Epoch: 5| Step: 4
Training loss: 1.5550961364760898
Validation loss: 2.702084730647969

Epoch: 5| Step: 5
Training loss: 1.3567938579965746
Validation loss: 2.681667438672342

Epoch: 5| Step: 6
Training loss: 1.5218101221312221
Validation loss: 2.689543497797708

Epoch: 5| Step: 7
Training loss: 1.5554494093071431
Validation loss: 2.6736024181400615

Epoch: 5| Step: 8
Training loss: 1.2826917026902414
Validation loss: 2.629797478045602

Epoch: 5| Step: 9
Training loss: 1.4657456533389353
Validation loss: 2.6200156992592465

Epoch: 5| Step: 10
Training loss: 1.096820553898227
Validation loss: 2.6069667855159544

Epoch: 197| Step: 0
Training loss: 1.79593607379252
Validation loss: 2.614318730005414

Epoch: 5| Step: 1
Training loss: 1.4672673635308473
Validation loss: 2.5957994998643006

Epoch: 5| Step: 2
Training loss: 1.5089695103461491
Validation loss: 2.609207014296705

Epoch: 5| Step: 3
Training loss: 1.5833181915897676
Validation loss: 2.5958210504386403

Epoch: 5| Step: 4
Training loss: 1.1800742115510199
Validation loss: 2.5831300372323187

Epoch: 5| Step: 5
Training loss: 1.8567875401698046
Validation loss: 2.5790865335930016

Epoch: 5| Step: 6
Training loss: 1.2901995643495539
Validation loss: 2.5581181656324476

Epoch: 5| Step: 7
Training loss: 1.5048581764338491
Validation loss: 2.5231062946266682

Epoch: 5| Step: 8
Training loss: 1.056409658971826
Validation loss: 2.580971046285575

Epoch: 5| Step: 9
Training loss: 1.750991199983262
Validation loss: 2.561239710481812

Epoch: 5| Step: 10
Training loss: 1.4849020574361875
Validation loss: 2.538692169822538

Epoch: 198| Step: 0
Training loss: 1.9005475660642652
Validation loss: 2.5669837839125793

Epoch: 5| Step: 1
Training loss: 1.5471994079119271
Validation loss: 2.5915364865990975

Epoch: 5| Step: 2
Training loss: 0.9261108326836818
Validation loss: 2.5686440033013294

Epoch: 5| Step: 3
Training loss: 1.3924404680823235
Validation loss: 2.566998332399158

Epoch: 5| Step: 4
Training loss: 1.261312885966175
Validation loss: 2.6092159602744847

Epoch: 5| Step: 5
Training loss: 1.5243810617123834
Validation loss: 2.6248043942562735

Epoch: 5| Step: 6
Training loss: 1.834120285312019
Validation loss: 2.665424535109871

Epoch: 5| Step: 7
Training loss: 1.3913673819543375
Validation loss: 2.7023530410600096

Epoch: 5| Step: 8
Training loss: 1.1401632236446757
Validation loss: 2.7363707175978838

Epoch: 5| Step: 9
Training loss: 1.433339608348743
Validation loss: 2.7640500235974637

Epoch: 5| Step: 10
Training loss: 1.8416720820328623
Validation loss: 2.7728116004130907

Epoch: 199| Step: 0
Training loss: 1.8231925610253699
Validation loss: 2.7358781799301193

Epoch: 5| Step: 1
Training loss: 1.3904529850901226
Validation loss: 2.744112383278529

Epoch: 5| Step: 2
Training loss: 1.236765273490872
Validation loss: 2.712944860920354

Epoch: 5| Step: 3
Training loss: 1.7377995541547742
Validation loss: 2.7271691528415025

Epoch: 5| Step: 4
Training loss: 1.2970842859003475
Validation loss: 2.6662458653710233

Epoch: 5| Step: 5
Training loss: 1.3901555844237072
Validation loss: 2.6097128525775894

Epoch: 5| Step: 6
Training loss: 1.3153269613662362
Validation loss: 2.583686475668371

Epoch: 5| Step: 7
Training loss: 1.678974088822183
Validation loss: 2.5587006567318022

Epoch: 5| Step: 8
Training loss: 1.1322966354714974
Validation loss: 2.565679790764168

Epoch: 5| Step: 9
Training loss: 1.5399414496004813
Validation loss: 2.5557323962044123

Epoch: 5| Step: 10
Training loss: 1.5429729992771788
Validation loss: 2.5976153148207883

Epoch: 200| Step: 0
Training loss: 1.3750716970997974
Validation loss: 2.6424011617960277

Epoch: 5| Step: 1
Training loss: 1.331471837504071
Validation loss: 2.636960121206186

Epoch: 5| Step: 2
Training loss: 1.6145877304837637
Validation loss: 2.6919537666358746

Epoch: 5| Step: 3
Training loss: 1.3862778513443579
Validation loss: 2.70890918380726

Epoch: 5| Step: 4
Training loss: 1.4869412374474744
Validation loss: 2.706479179209866

Epoch: 5| Step: 5
Training loss: 1.7482829525903738
Validation loss: 2.717470816035269

Epoch: 5| Step: 6
Training loss: 1.4850664636400024
Validation loss: 2.6760820380663315

Epoch: 5| Step: 7
Training loss: 1.4697353223368517
Validation loss: 2.646923988257871

Epoch: 5| Step: 8
Training loss: 1.2035549931214569
Validation loss: 2.610036410372154

Epoch: 5| Step: 9
Training loss: 1.393707031819314
Validation loss: 2.611852487460298

Epoch: 5| Step: 10
Training loss: 1.323696652455026
Validation loss: 2.5935422208972696

Epoch: 201| Step: 0
Training loss: 1.1061614868616017
Validation loss: 2.6277417603087962

Epoch: 5| Step: 1
Training loss: 1.398285884203698
Validation loss: 2.6325906600621023

Epoch: 5| Step: 2
Training loss: 2.0012977681126896
Validation loss: 2.653108453853015

Epoch: 5| Step: 3
Training loss: 1.4987756977948419
Validation loss: 2.6600687950028368

Epoch: 5| Step: 4
Training loss: 0.9694958553569903
Validation loss: 2.6360401063204275

Epoch: 5| Step: 5
Training loss: 1.5922585783152514
Validation loss: 2.6709419717412937

Epoch: 5| Step: 6
Training loss: 1.3665747877188323
Validation loss: 2.681772950852462

Epoch: 5| Step: 7
Training loss: 1.179387591304388
Validation loss: 2.6848232754844936

Epoch: 5| Step: 8
Training loss: 1.4647123964544686
Validation loss: 2.675298726002213

Epoch: 5| Step: 9
Training loss: 1.415100054219541
Validation loss: 2.702342311583621

Epoch: 5| Step: 10
Training loss: 1.4771911251765266
Validation loss: 2.7217011013266155

Epoch: 202| Step: 0
Training loss: 1.5042893751537434
Validation loss: 2.6498893997584085

Epoch: 5| Step: 1
Training loss: 1.0332616201763085
Validation loss: 2.6691081611212857

Epoch: 5| Step: 2
Training loss: 1.501337567649232
Validation loss: 2.6283845036188724

Epoch: 5| Step: 3
Training loss: 1.0986313476552734
Validation loss: 2.6581501919431125

Epoch: 5| Step: 4
Training loss: 1.553761805691295
Validation loss: 2.6175274293454716

Epoch: 5| Step: 5
Training loss: 1.488362147417911
Validation loss: 2.629033573416295

Epoch: 5| Step: 6
Training loss: 1.4987681416868321
Validation loss: 2.647688934805411

Epoch: 5| Step: 7
Training loss: 1.6763646104106809
Validation loss: 2.642998788758513

Epoch: 5| Step: 8
Training loss: 1.1844146198500243
Validation loss: 2.6374916825743875

Epoch: 5| Step: 9
Training loss: 1.613734590322377
Validation loss: 2.6493293058581724

Epoch: 5| Step: 10
Training loss: 1.1867350574048505
Validation loss: 2.6373278605764554

Epoch: 203| Step: 0
Training loss: 1.3398760466394928
Validation loss: 2.626100218767134

Epoch: 5| Step: 1
Training loss: 1.2338511647157984
Validation loss: 2.6212567048795865

Epoch: 5| Step: 2
Training loss: 1.67218214404525
Validation loss: 2.590331915950441

Epoch: 5| Step: 3
Training loss: 1.3326894079433638
Validation loss: 2.601934788012686

Epoch: 5| Step: 4
Training loss: 1.8147764708273588
Validation loss: 2.591774114871456

Epoch: 5| Step: 5
Training loss: 1.221400484401119
Validation loss: 2.584731121445054

Epoch: 5| Step: 6
Training loss: 1.0902606344528805
Validation loss: 2.578578418126973

Epoch: 5| Step: 7
Training loss: 0.9670965481640996
Validation loss: 2.571079277793306

Epoch: 5| Step: 8
Training loss: 1.3227295730735276
Validation loss: 2.563000337789605

Epoch: 5| Step: 9
Training loss: 1.8200980129678985
Validation loss: 2.5648248562372054

Epoch: 5| Step: 10
Training loss: 1.3430246125165146
Validation loss: 2.5912611587509162

Epoch: 204| Step: 0
Training loss: 1.4457665632296188
Validation loss: 2.6049863877959467

Epoch: 5| Step: 1
Training loss: 1.0366399532404773
Validation loss: 2.6320503353463938

Epoch: 5| Step: 2
Training loss: 1.4334688470047934
Validation loss: 2.6483397145583147

Epoch: 5| Step: 3
Training loss: 1.095358238408012
Validation loss: 2.6531755851757417

Epoch: 5| Step: 4
Training loss: 1.5597694952936112
Validation loss: 2.7172554405064746

Epoch: 5| Step: 5
Training loss: 1.3748552939824175
Validation loss: 2.6817474670184365

Epoch: 5| Step: 6
Training loss: 1.415100054219541
Validation loss: 2.682490627907522

Epoch: 5| Step: 7
Training loss: 1.2619434074009286
Validation loss: 2.661569418711148

Epoch: 5| Step: 8
Training loss: 1.6450256184493341
Validation loss: 2.682406317154902

Epoch: 5| Step: 9
Training loss: 1.5109469392751864
Validation loss: 2.669429712416827

Epoch: 5| Step: 10
Training loss: 1.2770997260547046
Validation loss: 2.69033593544727

Epoch: 205| Step: 0
Training loss: 1.3547813145449612
Validation loss: 2.7050194381164974

Epoch: 5| Step: 1
Training loss: 1.037822987940815
Validation loss: 2.6966179947186255

Epoch: 5| Step: 2
Training loss: 1.1264617747912788
Validation loss: 2.6832168609873444

Epoch: 5| Step: 3
Training loss: 1.3856085403008496
Validation loss: 2.6611770016584884

Epoch: 5| Step: 4
Training loss: 1.1836493954309342
Validation loss: 2.6946234242070948

Epoch: 5| Step: 5
Training loss: 1.67372713262821
Validation loss: 2.680421259325916

Epoch: 5| Step: 6
Training loss: 1.5505340148481657
Validation loss: 2.68741203635383

Epoch: 5| Step: 7
Training loss: 1.6912206675712924
Validation loss: 2.635992093787086

Epoch: 5| Step: 8
Training loss: 1.4068735647511967
Validation loss: 2.613294305175121

Epoch: 5| Step: 9
Training loss: 1.4130803274848687
Validation loss: 2.614433315320068

Epoch: 5| Step: 10
Training loss: 1.280879967452143
Validation loss: 2.614994462066065

Epoch: 206| Step: 0
Training loss: 1.398460899455617
Validation loss: 2.5918569544487147

Epoch: 5| Step: 1
Training loss: 1.514629076127463
Validation loss: 2.641761533744943

Epoch: 5| Step: 2
Training loss: 1.3095491935284433
Validation loss: 2.6714146962440006

Epoch: 5| Step: 3
Training loss: 1.6150747310248663
Validation loss: 2.667538979609749

Epoch: 5| Step: 4
Training loss: 1.4927592355585877
Validation loss: 2.700278186785413

Epoch: 5| Step: 5
Training loss: 1.4270851339435588
Validation loss: 2.6553565610481344

Epoch: 5| Step: 6
Training loss: 1.6456476259686341
Validation loss: 2.6479575008686163

Epoch: 5| Step: 7
Training loss: 1.0324994234540683
Validation loss: 2.6142376897301447

Epoch: 5| Step: 8
Training loss: 1.1690907272361377
Validation loss: 2.6300726112446378

Epoch: 5| Step: 9
Training loss: 1.014776139213312
Validation loss: 2.661246620974132

Epoch: 5| Step: 10
Training loss: 1.2762616441514942
Validation loss: 2.6921316606651358

Epoch: 207| Step: 0
Training loss: 1.250734828490206
Validation loss: 2.724328789370008

Epoch: 5| Step: 1
Training loss: 1.4565202159428043
Validation loss: 2.735013773149849

Epoch: 5| Step: 2
Training loss: 1.299703523867741
Validation loss: 2.7607115229158143

Epoch: 5| Step: 3
Training loss: 1.150509943060783
Validation loss: 2.7527867113077598

Epoch: 5| Step: 4
Training loss: 1.4355472902050845
Validation loss: 2.7370007168133252

Epoch: 5| Step: 5
Training loss: 1.3228230280539437
Validation loss: 2.665586263910398

Epoch: 5| Step: 6
Training loss: 1.4890066066311003
Validation loss: 2.635979367907229

Epoch: 5| Step: 7
Training loss: 1.237364131520216
Validation loss: 2.6332508529335974

Epoch: 5| Step: 8
Training loss: 1.4968482921025472
Validation loss: 2.6342575408094806

Epoch: 5| Step: 9
Training loss: 1.2105948671008715
Validation loss: 2.6047298513164074

Epoch: 5| Step: 10
Training loss: 1.5409699833327288
Validation loss: 2.589928494421851

Epoch: 208| Step: 0
Training loss: 1.3982379280768253
Validation loss: 2.60218204175863

Epoch: 5| Step: 1
Training loss: 1.1387592890640081
Validation loss: 2.6194727865506553

Epoch: 5| Step: 2
Training loss: 0.7061666819283066
Validation loss: 2.6474199880483624

Epoch: 5| Step: 3
Training loss: 1.3412775758893072
Validation loss: 2.6196170858722345

Epoch: 5| Step: 4
Training loss: 1.3196222430893534
Validation loss: 2.652261789557865

Epoch: 5| Step: 5
Training loss: 1.7359196425926346
Validation loss: 2.650158417072908

Epoch: 5| Step: 6
Training loss: 1.2417091072219806
Validation loss: 2.595753075797528

Epoch: 5| Step: 7
Training loss: 1.0470679945049306
Validation loss: 2.6023503755263024

Epoch: 5| Step: 8
Training loss: 1.40054882225403
Validation loss: 2.589209267565596

Epoch: 5| Step: 9
Training loss: 1.6509876503115712
Validation loss: 2.588871212886521

Epoch: 5| Step: 10
Training loss: 1.3597378739722636
Validation loss: 2.614612444035864

Epoch: 209| Step: 0
Training loss: 1.3639820997176684
Validation loss: 2.6249941478122962

Epoch: 5| Step: 1
Training loss: 1.4074584007552646
Validation loss: 2.6591639740443163

Epoch: 5| Step: 2
Training loss: 0.9845307242121623
Validation loss: 2.684022397677898

Epoch: 5| Step: 3
Training loss: 1.137561917977776
Validation loss: 2.7508583891933562

Epoch: 5| Step: 4
Training loss: 1.4168767586298774
Validation loss: 2.714150301684066

Epoch: 5| Step: 5
Training loss: 1.7733204672760179
Validation loss: 2.7010689115945063

Epoch: 5| Step: 6
Training loss: 1.2689698371789548
Validation loss: 2.7196860130136993

Epoch: 5| Step: 7
Training loss: 1.2579004955905477
Validation loss: 2.673035989296495

Epoch: 5| Step: 8
Training loss: 1.2773231248036188
Validation loss: 2.6526175961736858

Epoch: 5| Step: 9
Training loss: 1.5384450535624632
Validation loss: 2.644816614020005

Epoch: 5| Step: 10
Training loss: 0.8104508676315654
Validation loss: 2.6220428385307004

Epoch: 210| Step: 0
Training loss: 1.2587908618283785
Validation loss: 2.6284580257873693

Epoch: 5| Step: 1
Training loss: 1.3150712213701587
Validation loss: 2.6046245774509096

Epoch: 5| Step: 2
Training loss: 0.9970955093592556
Validation loss: 2.604579388471562

Epoch: 5| Step: 3
Training loss: 1.5085139249033126
Validation loss: 2.605089859935133

Epoch: 5| Step: 4
Training loss: 1.7295228598926455
Validation loss: 2.570668264439197

Epoch: 5| Step: 5
Training loss: 1.0971304289062087
Validation loss: 2.611096078897338

Epoch: 5| Step: 6
Training loss: 1.646891949618882
Validation loss: 2.6398546377045484

Epoch: 5| Step: 7
Training loss: 1.3001950521126466
Validation loss: 2.6156240618629543

Epoch: 5| Step: 8
Training loss: 0.9140132662563707
Validation loss: 2.6276687907958776

Epoch: 5| Step: 9
Training loss: 1.4082746553705732
Validation loss: 2.63219499897513

Epoch: 5| Step: 10
Training loss: 0.9743674060068038
Validation loss: 2.6964341958707805

Epoch: 211| Step: 0
Training loss: 1.201928323880994
Validation loss: 2.6988802302633914

Epoch: 5| Step: 1
Training loss: 1.1512142011810997
Validation loss: 2.698785634712117

Epoch: 5| Step: 2
Training loss: 1.1825829145787266
Validation loss: 2.7617578357645263

Epoch: 5| Step: 3
Training loss: 1.7406190389260583
Validation loss: 2.7921640825070333

Epoch: 5| Step: 4
Training loss: 1.4421012050811175
Validation loss: 2.7532491665295304

Epoch: 5| Step: 5
Training loss: 1.1420299290878917
Validation loss: 2.7484015669757826

Epoch: 5| Step: 6
Training loss: 1.4687763779889054
Validation loss: 2.7013346732195918

Epoch: 5| Step: 7
Training loss: 1.0930970559057236
Validation loss: 2.6785891615812396

Epoch: 5| Step: 8
Training loss: 1.1689482699223763
Validation loss: 2.6656406246279856

Epoch: 5| Step: 9
Training loss: 1.4106074744586448
Validation loss: 2.611055898362637

Epoch: 5| Step: 10
Training loss: 1.2506693001850222
Validation loss: 2.5699205879930047

Epoch: 212| Step: 0
Training loss: 1.297311640391125
Validation loss: 2.6376907872157562

Epoch: 5| Step: 1
Training loss: 0.9913578319224605
Validation loss: 2.6481220583727643

Epoch: 5| Step: 2
Training loss: 1.3946057895432455
Validation loss: 2.6763743898340584

Epoch: 5| Step: 3
Training loss: 1.197030870531921
Validation loss: 2.7014841855026286

Epoch: 5| Step: 4
Training loss: 1.3003351403107875
Validation loss: 2.7461370836014543

Epoch: 5| Step: 5
Training loss: 1.6531465352319688
Validation loss: 2.761434134353569

Epoch: 5| Step: 6
Training loss: 1.3124510438053925
Validation loss: 2.737786190686091

Epoch: 5| Step: 7
Training loss: 1.3791138057816277
Validation loss: 2.730168064388847

Epoch: 5| Step: 8
Training loss: 1.3713874610986339
Validation loss: 2.7258442263683804

Epoch: 5| Step: 9
Training loss: 1.3817307718649747
Validation loss: 2.6726869180558133

Epoch: 5| Step: 10
Training loss: 0.7339611510642201
Validation loss: 2.574570890310929

Epoch: 213| Step: 0
Training loss: 1.0419628993658003
Validation loss: 2.576275031190531

Epoch: 5| Step: 1
Training loss: 1.2444485413582287
Validation loss: 2.5621108923458604

Epoch: 5| Step: 2
Training loss: 1.2773386170637024
Validation loss: 2.553939068966645

Epoch: 5| Step: 3
Training loss: 1.4465125797910132
Validation loss: 2.5471526587901745

Epoch: 5| Step: 4
Training loss: 1.1636729260581073
Validation loss: 2.622724075777318

Epoch: 5| Step: 5
Training loss: 1.057060116122101
Validation loss: 2.642558939667023

Epoch: 5| Step: 6
Training loss: 1.2844909058780156
Validation loss: 2.706354601299111

Epoch: 5| Step: 7
Training loss: 1.2867404715876543
Validation loss: 2.7139058912124043

Epoch: 5| Step: 8
Training loss: 1.5077247396436284
Validation loss: 2.7291721856509907

Epoch: 5| Step: 9
Training loss: 1.2849681217974416
Validation loss: 2.753116486218345

Epoch: 5| Step: 10
Training loss: 1.421042481557205
Validation loss: 2.7790260396575044

Epoch: 214| Step: 0
Training loss: 1.6675855567178552
Validation loss: 2.787951041978362

Epoch: 5| Step: 1
Training loss: 1.177043452754762
Validation loss: 2.7435718145233103

Epoch: 5| Step: 2
Training loss: 1.1588630018718968
Validation loss: 2.7275847821481634

Epoch: 5| Step: 3
Training loss: 1.5346220606152519
Validation loss: 2.6685810107558114

Epoch: 5| Step: 4
Training loss: 1.2485563047405923
Validation loss: 2.652324262212122

Epoch: 5| Step: 5
Training loss: 1.4387897841904564
Validation loss: 2.624373110614512

Epoch: 5| Step: 6
Training loss: 0.9336002940183992
Validation loss: 2.6072461224356798

Epoch: 5| Step: 7
Training loss: 1.5010781387179641
Validation loss: 2.6121793682962453

Epoch: 5| Step: 8
Training loss: 1.1565030826209217
Validation loss: 2.611202742237824

Epoch: 5| Step: 9
Training loss: 1.226472887786892
Validation loss: 2.5464517209060324

Epoch: 5| Step: 10
Training loss: 0.881658525669705
Validation loss: 2.5397239824249254

Epoch: 215| Step: 0
Training loss: 1.2318105012448841
Validation loss: 2.5983327525800965

Epoch: 5| Step: 1
Training loss: 1.5505913683047452
Validation loss: 2.598678241025023

Epoch: 5| Step: 2
Training loss: 1.3292983762164836
Validation loss: 2.646099049780292

Epoch: 5| Step: 3
Training loss: 1.3222991623562599
Validation loss: 2.644814595920977

Epoch: 5| Step: 4
Training loss: 1.2927265228459044
Validation loss: 2.6265427294120633

Epoch: 5| Step: 5
Training loss: 1.5064661211267856
Validation loss: 2.637937278036957

Epoch: 5| Step: 6
Training loss: 0.9700281878436222
Validation loss: 2.6269408774403953

Epoch: 5| Step: 7
Training loss: 1.2364456096831153
Validation loss: 2.6162203582987362

Epoch: 5| Step: 8
Training loss: 0.9756340801591137
Validation loss: 2.6033009549996446

Epoch: 5| Step: 9
Training loss: 0.9668444072714126
Validation loss: 2.6254072581461902

Epoch: 5| Step: 10
Training loss: 1.1660871883137691
Validation loss: 2.627766928384129

Epoch: 216| Step: 0
Training loss: 1.0272125044269558
Validation loss: 2.58027790030163

Epoch: 5| Step: 1
Training loss: 1.1784557960807631
Validation loss: 2.6522407845818576

Epoch: 5| Step: 2
Training loss: 1.484750399051066
Validation loss: 2.648605335069835

Epoch: 5| Step: 3
Training loss: 1.067604593338988
Validation loss: 2.665288447564443

Epoch: 5| Step: 4
Training loss: 1.0402687356440155
Validation loss: 2.632506915046195

Epoch: 5| Step: 5
Training loss: 1.1134672846037064
Validation loss: 2.656847780005402

Epoch: 5| Step: 6
Training loss: 1.6924549402186193
Validation loss: 2.63950361564347

Epoch: 5| Step: 7
Training loss: 1.1004685726054595
Validation loss: 2.6356611075644407

Epoch: 5| Step: 8
Training loss: 1.1297109303346382
Validation loss: 2.6562193036944777

Epoch: 5| Step: 9
Training loss: 1.390262599400249
Validation loss: 2.636512957965607

Epoch: 5| Step: 10
Training loss: 1.1374386215418235
Validation loss: 2.6376281594392523

Epoch: 217| Step: 0
Training loss: 1.0360767805964661
Validation loss: 2.634735895631607

Epoch: 5| Step: 1
Training loss: 0.938263582163324
Validation loss: 2.620954107686085

Epoch: 5| Step: 2
Training loss: 1.3372139883393201
Validation loss: 2.6388239826826134

Epoch: 5| Step: 3
Training loss: 1.2365705544703733
Validation loss: 2.6383323612229095

Epoch: 5| Step: 4
Training loss: 1.2081690490238886
Validation loss: 2.6356270997227087

Epoch: 5| Step: 5
Training loss: 1.1931441841961121
Validation loss: 2.6817239369403025

Epoch: 5| Step: 6
Training loss: 0.95046331501601
Validation loss: 2.696760518951531

Epoch: 5| Step: 7
Training loss: 1.0586188619527814
Validation loss: 2.6950776722964087

Epoch: 5| Step: 8
Training loss: 1.34122269296001
Validation loss: 2.6694014524149607

Epoch: 5| Step: 9
Training loss: 1.4996581482762277
Validation loss: 2.6602535625429105

Epoch: 5| Step: 10
Training loss: 1.3751321642387107
Validation loss: 2.68416176840972

Epoch: 218| Step: 0
Training loss: 1.27787942182613
Validation loss: 2.664546464656333

Epoch: 5| Step: 1
Training loss: 0.9321624446088732
Validation loss: 2.5945780984312816

Epoch: 5| Step: 2
Training loss: 1.2410720039123269
Validation loss: 2.5989813179191508

Epoch: 5| Step: 3
Training loss: 1.402037010542398
Validation loss: 2.5738743897738803

Epoch: 5| Step: 4
Training loss: 1.2173037139298173
Validation loss: 2.5815096209066977

Epoch: 5| Step: 5
Training loss: 1.1477081162461782
Validation loss: 2.58731055635993

Epoch: 5| Step: 6
Training loss: 0.8498500439255972
Validation loss: 2.5777352961756264

Epoch: 5| Step: 7
Training loss: 1.258875758793852
Validation loss: 2.589445103592475

Epoch: 5| Step: 8
Training loss: 0.9998806345747849
Validation loss: 2.5795100385011973

Epoch: 5| Step: 9
Training loss: 1.1374070223861659
Validation loss: 2.639924497891992

Epoch: 5| Step: 10
Training loss: 1.5467725006977577
Validation loss: 2.6026767861038462

Epoch: 219| Step: 0
Training loss: 1.6736922325780477
Validation loss: 2.6743397556203425

Epoch: 5| Step: 1
Training loss: 1.3619980333624937
Validation loss: 2.6657220972681284

Epoch: 5| Step: 2
Training loss: 0.8935431474451194
Validation loss: 2.6705441910176

Epoch: 5| Step: 3
Training loss: 0.8797450153527235
Validation loss: 2.6523293241019474

Epoch: 5| Step: 4
Training loss: 1.3406218557609908
Validation loss: 2.687876131065358

Epoch: 5| Step: 5
Training loss: 1.2641066874736775
Validation loss: 2.66954759429056

Epoch: 5| Step: 6
Training loss: 0.8574262197466979
Validation loss: 2.6514053411176066

Epoch: 5| Step: 7
Training loss: 0.911084990559881
Validation loss: 2.632762218204671

Epoch: 5| Step: 8
Training loss: 1.1832735239056515
Validation loss: 2.586690173251091

Epoch: 5| Step: 9
Training loss: 1.1430288094354946
Validation loss: 2.6115867118622753

Epoch: 5| Step: 10
Training loss: 1.234687475901077
Validation loss: 2.620290086729985

Epoch: 220| Step: 0
Training loss: 1.1019653773987341
Validation loss: 2.5725629773573027

Epoch: 5| Step: 1
Training loss: 1.282535931119209
Validation loss: 2.5942251089308446

Epoch: 5| Step: 2
Training loss: 1.2197863256444494
Validation loss: 2.6688746817706868

Epoch: 5| Step: 3
Training loss: 0.8689512582285274
Validation loss: 2.649737169725675

Epoch: 5| Step: 4
Training loss: 1.1176291706437025
Validation loss: 2.696844561567896

Epoch: 5| Step: 5
Training loss: 1.5268420397854445
Validation loss: 2.700418735910711

Epoch: 5| Step: 6
Training loss: 1.1377745244688304
Validation loss: 2.692331878331366

Epoch: 5| Step: 7
Training loss: 0.988043654759253
Validation loss: 2.662547478143478

Epoch: 5| Step: 8
Training loss: 1.2477271397276781
Validation loss: 2.665997080479427

Epoch: 5| Step: 9
Training loss: 0.9720623853780654
Validation loss: 2.6406565231865864

Epoch: 5| Step: 10
Training loss: 1.3701467694374223
Validation loss: 2.5831683645723222

Epoch: 221| Step: 0
Training loss: 1.143745334803338
Validation loss: 2.615326958076776

Epoch: 5| Step: 1
Training loss: 1.219480735617265
Validation loss: 2.5986372706450824

Epoch: 5| Step: 2
Training loss: 0.9458671392933615
Validation loss: 2.6223223546463985

Epoch: 5| Step: 3
Training loss: 1.3372938621175328
Validation loss: 2.663186311944469

Epoch: 5| Step: 4
Training loss: 1.4708691993353267
Validation loss: 2.6488484637217558

Epoch: 5| Step: 5
Training loss: 1.013802286627052
Validation loss: 2.6876801327631563

Epoch: 5| Step: 6
Training loss: 1.0864869518418165
Validation loss: 2.6701200083011614

Epoch: 5| Step: 7
Training loss: 1.2367009328497336
Validation loss: 2.690863088317139

Epoch: 5| Step: 8
Training loss: 1.2386419210237702
Validation loss: 2.6962351361987262

Epoch: 5| Step: 9
Training loss: 0.8483619389335854
Validation loss: 2.643992160231719

Epoch: 5| Step: 10
Training loss: 1.0263318201825975
Validation loss: 2.651261486846569

Epoch: 222| Step: 0
Training loss: 1.424585379128309
Validation loss: 2.6228987051988613

Epoch: 5| Step: 1
Training loss: 1.1504021273233855
Validation loss: 2.623898142576666

Epoch: 5| Step: 2
Training loss: 1.2081886347368274
Validation loss: 2.589017705960405

Epoch: 5| Step: 3
Training loss: 1.1304331554405915
Validation loss: 2.6002639169978714

Epoch: 5| Step: 4
Training loss: 1.118759649650685
Validation loss: 2.5884464570178216

Epoch: 5| Step: 5
Training loss: 0.9159806820319149
Validation loss: 2.5789830345838234

Epoch: 5| Step: 6
Training loss: 1.171171358576751
Validation loss: 2.591457905462991

Epoch: 5| Step: 7
Training loss: 1.2594367965795474
Validation loss: 2.590088022638111

Epoch: 5| Step: 8
Training loss: 0.9028583727016833
Validation loss: 2.6274326242897073

Epoch: 5| Step: 9
Training loss: 1.1282998010356782
Validation loss: 2.6319365550033065

Epoch: 5| Step: 10
Training loss: 1.0345694552189906
Validation loss: 2.6542002771042523

Epoch: 223| Step: 0
Training loss: 1.4198929102906759
Validation loss: 2.6669817752424385

Epoch: 5| Step: 1
Training loss: 1.0007939167397373
Validation loss: 2.6970082878058665

Epoch: 5| Step: 2
Training loss: 0.6541710348246654
Validation loss: 2.7008287268510727

Epoch: 5| Step: 3
Training loss: 1.26683819868387
Validation loss: 2.725732433175501

Epoch: 5| Step: 4
Training loss: 1.1835668076070538
Validation loss: 2.6880265693269467

Epoch: 5| Step: 5
Training loss: 1.4806054688788222
Validation loss: 2.675120381025348

Epoch: 5| Step: 6
Training loss: 0.6835792103992264
Validation loss: 2.639095448100841

Epoch: 5| Step: 7
Training loss: 0.8360258394427791
Validation loss: 2.650228927515792

Epoch: 5| Step: 8
Training loss: 1.1629167076519957
Validation loss: 2.5628295434425072

Epoch: 5| Step: 9
Training loss: 0.9945238794861255
Validation loss: 2.6105203397313077

Epoch: 5| Step: 10
Training loss: 1.5150777871082295
Validation loss: 2.558178656224682

Epoch: 224| Step: 0
Training loss: 0.81570513978316
Validation loss: 2.5948024077021965

Epoch: 5| Step: 1
Training loss: 0.8151465009881799
Validation loss: 2.567969275353009

Epoch: 5| Step: 2
Training loss: 1.3506245528277319
Validation loss: 2.6632133730250516

Epoch: 5| Step: 3
Training loss: 1.3090809384903124
Validation loss: 2.6598713153488114

Epoch: 5| Step: 4
Training loss: 1.1141654802961365
Validation loss: 2.655048528605148

Epoch: 5| Step: 5
Training loss: 1.084962420801613
Validation loss: 2.6913241931982057

Epoch: 5| Step: 6
Training loss: 1.4455369929644015
Validation loss: 2.685514937493378

Epoch: 5| Step: 7
Training loss: 1.092787073508812
Validation loss: 2.69697969654275

Epoch: 5| Step: 8
Training loss: 1.0270800814212804
Validation loss: 2.7098052175196705

Epoch: 5| Step: 9
Training loss: 1.2073880257824559
Validation loss: 2.7298574155107014

Epoch: 5| Step: 10
Training loss: 0.8565944076434805
Validation loss: 2.7324944874208263

Epoch: 225| Step: 0
Training loss: 1.024772995723581
Validation loss: 2.713331726983603

Epoch: 5| Step: 1
Training loss: 0.981482661661069
Validation loss: 2.688974775704693

Epoch: 5| Step: 2
Training loss: 1.105179010709942
Validation loss: 2.665525950616878

Epoch: 5| Step: 3
Training loss: 1.3516213288486205
Validation loss: 2.64935384164193

Epoch: 5| Step: 4
Training loss: 0.9894858395920757
Validation loss: 2.614899033869536

Epoch: 5| Step: 5
Training loss: 0.9430763657292751
Validation loss: 2.6339588110809573

Epoch: 5| Step: 6
Training loss: 1.198925317905725
Validation loss: 2.5875515291491626

Epoch: 5| Step: 7
Training loss: 1.3084157794236462
Validation loss: 2.6206128776122415

Epoch: 5| Step: 8
Training loss: 1.1493255918253888
Validation loss: 2.613687285644185

Epoch: 5| Step: 9
Training loss: 0.7193096718510061
Validation loss: 2.631255062524075

Epoch: 5| Step: 10
Training loss: 1.2692523356474987
Validation loss: 2.6307308896697372

Epoch: 226| Step: 0
Training loss: 1.2601443645486752
Validation loss: 2.7172331255351305

Epoch: 5| Step: 1
Training loss: 0.6798242234143926
Validation loss: 2.6620279973999015

Epoch: 5| Step: 2
Training loss: 1.0869834857166991
Validation loss: 2.6869365602788555

Epoch: 5| Step: 3
Training loss: 1.0945351643461692
Validation loss: 2.712301720209745

Epoch: 5| Step: 4
Training loss: 1.0203300649816374
Validation loss: 2.6791021010832963

Epoch: 5| Step: 5
Training loss: 0.8789929834591389
Validation loss: 2.6769290099287177

Epoch: 5| Step: 6
Training loss: 1.0122443052900936
Validation loss: 2.6464625191751923

Epoch: 5| Step: 7
Training loss: 1.195480683904974
Validation loss: 2.632601371939967

Epoch: 5| Step: 8
Training loss: 1.210531794357778
Validation loss: 2.6381767881279834

Epoch: 5| Step: 9
Training loss: 1.1518283531939808
Validation loss: 2.616010576299606

Epoch: 5| Step: 10
Training loss: 1.3945960876608006
Validation loss: 2.569836571425192

Epoch: 227| Step: 0
Training loss: 1.3023491193984478
Validation loss: 2.5973725959654335

Epoch: 5| Step: 1
Training loss: 1.0221097064176257
Validation loss: 2.552646052737289

Epoch: 5| Step: 2
Training loss: 1.2076377949567425
Validation loss: 2.580166492881929

Epoch: 5| Step: 3
Training loss: 0.9256359903840904
Validation loss: 2.5688928480624087

Epoch: 5| Step: 4
Training loss: 1.1186822348588568
Validation loss: 2.6287120350029554

Epoch: 5| Step: 5
Training loss: 0.981805505654678
Validation loss: 2.6263775997542833

Epoch: 5| Step: 6
Training loss: 0.9446973454261747
Validation loss: 2.6763733783145067

Epoch: 5| Step: 7
Training loss: 1.4606180096688754
Validation loss: 2.741457604284041

Epoch: 5| Step: 8
Training loss: 1.2561097555496734
Validation loss: 2.7359573497063745

Epoch: 5| Step: 9
Training loss: 0.8759343063726328
Validation loss: 2.717672014321373

Epoch: 5| Step: 10
Training loss: 0.9283467088987917
Validation loss: 2.7046555195471225

Epoch: 228| Step: 0
Training loss: 1.2412504584550732
Validation loss: 2.721763565364795

Epoch: 5| Step: 1
Training loss: 1.1417465966267706
Validation loss: 2.694427862483878

Epoch: 5| Step: 2
Training loss: 0.8394940380068763
Validation loss: 2.6849194696080496

Epoch: 5| Step: 3
Training loss: 1.2442266174014018
Validation loss: 2.6372735315894986

Epoch: 5| Step: 4
Training loss: 1.1143839411181615
Validation loss: 2.632454710859471

Epoch: 5| Step: 5
Training loss: 1.0646949423397463
Validation loss: 2.637055975018965

Epoch: 5| Step: 6
Training loss: 0.9152266433265507
Validation loss: 2.589292198111204

Epoch: 5| Step: 7
Training loss: 1.3500074139144205
Validation loss: 2.588248395809867

Epoch: 5| Step: 8
Training loss: 0.7256506663801253
Validation loss: 2.6158243360426976

Epoch: 5| Step: 9
Training loss: 0.6864913781007376
Validation loss: 2.619175416564948

Epoch: 5| Step: 10
Training loss: 1.4442209606820264
Validation loss: 2.622383937280606

Epoch: 229| Step: 0
Training loss: 1.146215144036165
Validation loss: 2.646093176679366

Epoch: 5| Step: 1
Training loss: 1.1405732130025916
Validation loss: 2.6316985718772568

Epoch: 5| Step: 2
Training loss: 1.0251054058307147
Validation loss: 2.6687644819582514

Epoch: 5| Step: 3
Training loss: 0.893729871243111
Validation loss: 2.7272635224899546

Epoch: 5| Step: 4
Training loss: 1.0775276408887489
Validation loss: 2.747091246571966

Epoch: 5| Step: 5
Training loss: 0.6697839088841021
Validation loss: 2.716484356345762

Epoch: 5| Step: 6
Training loss: 1.367684889643559
Validation loss: 2.723935451484793

Epoch: 5| Step: 7
Training loss: 1.0328415813189555
Validation loss: 2.6806378355565728

Epoch: 5| Step: 8
Training loss: 1.1451091153821484
Validation loss: 2.6690219196240204

Epoch: 5| Step: 9
Training loss: 1.0563728712496279
Validation loss: 2.561116551181162

Epoch: 5| Step: 10
Training loss: 1.2837861244891169
Validation loss: 2.5610165247467274

Epoch: 230| Step: 0
Training loss: 1.1065457762235753
Validation loss: 2.5377382854879227

Epoch: 5| Step: 1
Training loss: 1.1482487218456434
Validation loss: 2.520184365148426

Epoch: 5| Step: 2
Training loss: 1.0492325612151188
Validation loss: 2.546320375888195

Epoch: 5| Step: 3
Training loss: 0.8062133396300867
Validation loss: 2.5408366532657314

Epoch: 5| Step: 4
Training loss: 1.3987631818134896
Validation loss: 2.5502965061652105

Epoch: 5| Step: 5
Training loss: 1.0169071613986547
Validation loss: 2.543935723312558

Epoch: 5| Step: 6
Training loss: 0.9389677003052297
Validation loss: 2.617612625145118

Epoch: 5| Step: 7
Training loss: 0.9233504949850031
Validation loss: 2.6468676818304053

Epoch: 5| Step: 8
Training loss: 1.3366607136169695
Validation loss: 2.6173509742937977

Epoch: 5| Step: 9
Training loss: 0.8069314501670556
Validation loss: 2.666001180767212

Epoch: 5| Step: 10
Training loss: 1.2633084418697267
Validation loss: 2.663090903847319

Epoch: 231| Step: 0
Training loss: 1.0950363224572097
Validation loss: 2.5952590108998534

Epoch: 5| Step: 1
Training loss: 0.6270677693443221
Validation loss: 2.593966061305369

Epoch: 5| Step: 2
Training loss: 1.4209187404584698
Validation loss: 2.630331015164971

Epoch: 5| Step: 3
Training loss: 1.3169823356666124
Validation loss: 2.6114573833459054

Epoch: 5| Step: 4
Training loss: 1.3028406102731744
Validation loss: 2.6254353609033445

Epoch: 5| Step: 5
Training loss: 1.139497434783097
Validation loss: 2.6203127811449907

Epoch: 5| Step: 6
Training loss: 0.9723350270238786
Validation loss: 2.604141075418717

Epoch: 5| Step: 7
Training loss: 0.9723325443495656
Validation loss: 2.626065640974378

Epoch: 5| Step: 8
Training loss: 0.8360041654154482
Validation loss: 2.662896886925233

Epoch: 5| Step: 9
Training loss: 0.9940560235559335
Validation loss: 2.6923091401557495

Epoch: 5| Step: 10
Training loss: 0.7677681956940753
Validation loss: 2.6719792063916366

Epoch: 232| Step: 0
Training loss: 1.013661232012257
Validation loss: 2.680503374449361

Epoch: 5| Step: 1
Training loss: 1.1645352728428846
Validation loss: 2.6703135512958647

Epoch: 5| Step: 2
Training loss: 0.6525286109907125
Validation loss: 2.5926311702547076

Epoch: 5| Step: 3
Training loss: 1.176731169466281
Validation loss: 2.576897256664692

Epoch: 5| Step: 4
Training loss: 0.9456644585262851
Validation loss: 2.5789623363710765

Epoch: 5| Step: 5
Training loss: 1.2239223177325227
Validation loss: 2.5259618724774597

Epoch: 5| Step: 6
Training loss: 1.0467778630526279
Validation loss: 2.544260856264672

Epoch: 5| Step: 7
Training loss: 1.072070995239552
Validation loss: 2.5319079697651534

Epoch: 5| Step: 8
Training loss: 1.3281613962010888
Validation loss: 2.5563599833481763

Epoch: 5| Step: 9
Training loss: 0.8177183640628157
Validation loss: 2.5643082448227457

Epoch: 5| Step: 10
Training loss: 0.9534789819486278
Validation loss: 2.557653961138418

Epoch: 233| Step: 0
Training loss: 1.0083619623349769
Validation loss: 2.56373957609109

Epoch: 5| Step: 1
Training loss: 0.9819476460001934
Validation loss: 2.592413577633071

Epoch: 5| Step: 2
Training loss: 0.8816424016972642
Validation loss: 2.551873122383734

Epoch: 5| Step: 3
Training loss: 1.3074413178442554
Validation loss: 2.5781650116252806

Epoch: 5| Step: 4
Training loss: 0.8270441234976926
Validation loss: 2.5986055085375237

Epoch: 5| Step: 5
Training loss: 0.8832344127243839
Validation loss: 2.5543290691767155

Epoch: 5| Step: 6
Training loss: 1.2799854085507794
Validation loss: 2.610949463692712

Epoch: 5| Step: 7
Training loss: 1.1032034913578348
Validation loss: 2.6198971103153195

Epoch: 5| Step: 8
Training loss: 1.0133241266430508
Validation loss: 2.641119100875612

Epoch: 5| Step: 9
Training loss: 0.9684244039412611
Validation loss: 2.678208351558835

Epoch: 5| Step: 10
Training loss: 1.1798952942800358
Validation loss: 2.6926950332320434

Epoch: 234| Step: 0
Training loss: 1.2197724479553367
Validation loss: 2.6957435428503453

Epoch: 5| Step: 1
Training loss: 1.209296215556734
Validation loss: 2.647832515527606

Epoch: 5| Step: 2
Training loss: 0.7912115160606377
Validation loss: 2.6504487785076067

Epoch: 5| Step: 3
Training loss: 1.179729536709646
Validation loss: 2.6018915918870293

Epoch: 5| Step: 4
Training loss: 1.201106917943192
Validation loss: 2.6093547816086113

Epoch: 5| Step: 5
Training loss: 0.7678868883651153
Validation loss: 2.5834233029828457

Epoch: 5| Step: 6
Training loss: 0.6929504693167141
Validation loss: 2.5717792731256517

Epoch: 5| Step: 7
Training loss: 1.064332111724318
Validation loss: 2.6162451477524735

Epoch: 5| Step: 8
Training loss: 1.3515716728825284
Validation loss: 2.5770900683819407

Epoch: 5| Step: 9
Training loss: 0.7801453983064819
Validation loss: 2.6184040492369753

Epoch: 5| Step: 10
Training loss: 1.014725506878132
Validation loss: 2.6267194395207207

Epoch: 235| Step: 0
Training loss: 1.013239538647465
Validation loss: 2.6096760595361133

Epoch: 5| Step: 1
Training loss: 0.6255221331665187
Validation loss: 2.617078962235037

Epoch: 5| Step: 2
Training loss: 1.1984880439216048
Validation loss: 2.623373880572433

Epoch: 5| Step: 3
Training loss: 1.1915658312375064
Validation loss: 2.6322351042066625

Epoch: 5| Step: 4
Training loss: 1.127335825553213
Validation loss: 2.6632978678238146

Epoch: 5| Step: 5
Training loss: 1.3596304730165518
Validation loss: 2.629449744022909

Epoch: 5| Step: 6
Training loss: 1.107260233067184
Validation loss: 2.6382663428204554

Epoch: 5| Step: 7
Training loss: 0.638824281385871
Validation loss: 2.6323542758025607

Epoch: 5| Step: 8
Training loss: 0.9952775490940617
Validation loss: 2.629097841276369

Epoch: 5| Step: 9
Training loss: 0.9733643309891625
Validation loss: 2.6185473197491356

Epoch: 5| Step: 10
Training loss: 0.9931498088582787
Validation loss: 2.5865492741940392

Epoch: 236| Step: 0
Training loss: 0.7206922080601017
Validation loss: 2.622115471844914

Epoch: 5| Step: 1
Training loss: 1.116254083128293
Validation loss: 2.569989180050723

Epoch: 5| Step: 2
Training loss: 1.175911728218945
Validation loss: 2.5909757824954176

Epoch: 5| Step: 3
Training loss: 1.0428388993371427
Validation loss: 2.541138986741739

Epoch: 5| Step: 4
Training loss: 1.1878691149805378
Validation loss: 2.52828696990869

Epoch: 5| Step: 5
Training loss: 1.1026270707096608
Validation loss: 2.5535739301712477

Epoch: 5| Step: 6
Training loss: 0.791038494015
Validation loss: 2.55315249768354

Epoch: 5| Step: 7
Training loss: 1.202973096101171
Validation loss: 2.5784650909551843

Epoch: 5| Step: 8
Training loss: 0.9794760310018614
Validation loss: 2.62494729394928

Epoch: 5| Step: 9
Training loss: 0.9778838107085057
Validation loss: 2.6439688061076096

Epoch: 5| Step: 10
Training loss: 0.7859940495253652
Validation loss: 2.6454872297072876

Epoch: 237| Step: 0
Training loss: 0.7147440189352827
Validation loss: 2.720990594920531

Epoch: 5| Step: 1
Training loss: 1.2973980136252201
Validation loss: 2.7048472121896436

Epoch: 5| Step: 2
Training loss: 0.7804938280813406
Validation loss: 2.7150124184152915

Epoch: 5| Step: 3
Training loss: 0.9624633460063301
Validation loss: 2.68835650105476

Epoch: 5| Step: 4
Training loss: 1.1055742085436526
Validation loss: 2.697098391290799

Epoch: 5| Step: 5
Training loss: 1.0512030226544973
Validation loss: 2.6475139593591672

Epoch: 5| Step: 6
Training loss: 0.8482000478825896
Validation loss: 2.6375728092661928

Epoch: 5| Step: 7
Training loss: 1.03091326909123
Validation loss: 2.602116127358907

Epoch: 5| Step: 8
Training loss: 1.1842702814273631
Validation loss: 2.6387386284279053

Epoch: 5| Step: 9
Training loss: 1.079732056511259
Validation loss: 2.608880826241015

Epoch: 5| Step: 10
Training loss: 0.9872718149027209
Validation loss: 2.608951629803186

Epoch: 238| Step: 0
Training loss: 0.880532180681125
Validation loss: 2.6604716157531634

Epoch: 5| Step: 1
Training loss: 0.5337374737987227
Validation loss: 2.702314164293226

Epoch: 5| Step: 2
Training loss: 1.4181040969861543
Validation loss: 2.7070278927754803

Epoch: 5| Step: 3
Training loss: 0.9848601039065473
Validation loss: 2.7121778549495206

Epoch: 5| Step: 4
Training loss: 1.055830047008174
Validation loss: 2.7049171102191916

Epoch: 5| Step: 5
Training loss: 0.8546262101927409
Validation loss: 2.7347199440702976

Epoch: 5| Step: 6
Training loss: 1.1174821798452665
Validation loss: 2.6944643326546074

Epoch: 5| Step: 7
Training loss: 0.9699600107759211
Validation loss: 2.6748525055765495

Epoch: 5| Step: 8
Training loss: 0.9686098612666754
Validation loss: 2.702819435175676

Epoch: 5| Step: 9
Training loss: 0.9391921031714963
Validation loss: 2.7148340689674706

Epoch: 5| Step: 10
Training loss: 1.1054400113417426
Validation loss: 2.6661123409740966

Epoch: 239| Step: 0
Training loss: 0.756371534055587
Validation loss: 2.6687488796924095

Epoch: 5| Step: 1
Training loss: 1.159669664883628
Validation loss: 2.6476954259855217

Epoch: 5| Step: 2
Training loss: 1.187356137044041
Validation loss: 2.6579682421331055

Epoch: 5| Step: 3
Training loss: 1.3984103493212592
Validation loss: 2.6620251545029805

Epoch: 5| Step: 4
Training loss: 0.9596968915374838
Validation loss: 2.6492143409372417

Epoch: 5| Step: 5
Training loss: 0.8570493962219401
Validation loss: 2.6244939491107306

Epoch: 5| Step: 6
Training loss: 0.8248601650448072
Validation loss: 2.649023469571838

Epoch: 5| Step: 7
Training loss: 0.9292827975540573
Validation loss: 2.6527201227077195

Epoch: 5| Step: 8
Training loss: 1.0601485542349756
Validation loss: 2.664743794102985

Epoch: 5| Step: 9
Training loss: 1.0136968062023206
Validation loss: 2.6620859756556636

Epoch: 5| Step: 10
Training loss: 0.9293968964635109
Validation loss: 2.6520198786365166

Epoch: 240| Step: 0
Training loss: 1.1538303936591128
Validation loss: 2.646000769054316

Epoch: 5| Step: 1
Training loss: 0.9847266159593285
Validation loss: 2.6306433481296305

Epoch: 5| Step: 2
Training loss: 1.0575719878311785
Validation loss: 2.6471025366527963

Epoch: 5| Step: 3
Training loss: 1.0918483005484427
Validation loss: 2.647241647969554

Epoch: 5| Step: 4
Training loss: 0.9700971588653904
Validation loss: 2.6490698005846554

Epoch: 5| Step: 5
Training loss: 0.9197399178128874
Validation loss: 2.6168732054177295

Epoch: 5| Step: 6
Training loss: 1.0684422769409039
Validation loss: 2.626471319546875

Epoch: 5| Step: 7
Training loss: 0.7500573374765498
Validation loss: 2.599717203857217

Epoch: 5| Step: 8
Training loss: 1.1381531150399522
Validation loss: 2.629238423937356

Epoch: 5| Step: 9
Training loss: 0.8305207990697948
Validation loss: 2.6870640894589237

Epoch: 5| Step: 10
Training loss: 0.8733523045789486
Validation loss: 2.6364163531683613

Epoch: 241| Step: 0
Training loss: 0.6654699556904511
Validation loss: 2.6481734086764153

Epoch: 5| Step: 1
Training loss: 1.0008594872463665
Validation loss: 2.661794305377581

Epoch: 5| Step: 2
Training loss: 1.0419253727406967
Validation loss: 2.656252902160256

Epoch: 5| Step: 3
Training loss: 1.103670740619108
Validation loss: 2.6628900390448753

Epoch: 5| Step: 4
Training loss: 1.2147403194640776
Validation loss: 2.6675925903323097

Epoch: 5| Step: 5
Training loss: 0.7734196978745523
Validation loss: 2.678771397987597

Epoch: 5| Step: 6
Training loss: 1.2670232795768532
Validation loss: 2.5719867839549915

Epoch: 5| Step: 7
Training loss: 1.1486047116990172
Validation loss: 2.61687608952914

Epoch: 5| Step: 8
Training loss: 0.6480060198910447
Validation loss: 2.534034995641105

Epoch: 5| Step: 9
Training loss: 0.9577300965051532
Validation loss: 2.524657877549312

Epoch: 5| Step: 10
Training loss: 0.84547502291539
Validation loss: 2.551686524579632

Epoch: 242| Step: 0
Training loss: 1.1090937513138783
Validation loss: 2.551429332908354

Epoch: 5| Step: 1
Training loss: 1.020875709328861
Validation loss: 2.5692934176082187

Epoch: 5| Step: 2
Training loss: 0.8849033139103291
Validation loss: 2.5818158362487473

Epoch: 5| Step: 3
Training loss: 1.1410277713702446
Validation loss: 2.641026212470458

Epoch: 5| Step: 4
Training loss: 0.8718420671922396
Validation loss: 2.662732709125765

Epoch: 5| Step: 5
Training loss: 1.1134620921170442
Validation loss: 2.7042481465245425

Epoch: 5| Step: 6
Training loss: 0.7348969410636298
Validation loss: 2.7076117874086933

Epoch: 5| Step: 7
Training loss: 1.0783160496485655
Validation loss: 2.774090932718687

Epoch: 5| Step: 8
Training loss: 0.7358428003242901
Validation loss: 2.7707797210364733

Epoch: 5| Step: 9
Training loss: 1.0146330464199012
Validation loss: 2.7979504888102285

Epoch: 5| Step: 10
Training loss: 1.060717208981213
Validation loss: 2.7598356518152047

Epoch: 243| Step: 0
Training loss: 1.267451722318528
Validation loss: 2.705438454117985

Epoch: 5| Step: 1
Training loss: 0.9598196707674577
Validation loss: 2.6879800614334353

Epoch: 5| Step: 2
Training loss: 1.018201406479334
Validation loss: 2.6664432796105904

Epoch: 5| Step: 3
Training loss: 1.012528496800404
Validation loss: 2.62977916262459

Epoch: 5| Step: 4
Training loss: 1.052355526502116
Validation loss: 2.6025982152852527

Epoch: 5| Step: 5
Training loss: 0.9169272825368535
Validation loss: 2.607453383708213

Epoch: 5| Step: 6
Training loss: 1.0574836681899462
Validation loss: 2.644172932945832

Epoch: 5| Step: 7
Training loss: 0.8654475928890467
Validation loss: 2.629700205887764

Epoch: 5| Step: 8
Training loss: 0.7174522044381972
Validation loss: 2.623157751309078

Epoch: 5| Step: 9
Training loss: 0.8390498112406382
Validation loss: 2.6326882543708963

Epoch: 5| Step: 10
Training loss: 0.9224898340859111
Validation loss: 2.671073551102386

Epoch: 244| Step: 0
Training loss: 1.24047954869354
Validation loss: 2.638745060016143

Epoch: 5| Step: 1
Training loss: 0.7552238375069801
Validation loss: 2.6635389180671147

Epoch: 5| Step: 2
Training loss: 0.9916821191422598
Validation loss: 2.697089820456151

Epoch: 5| Step: 3
Training loss: 0.8461816504301838
Validation loss: 2.6999462755844608

Epoch: 5| Step: 4
Training loss: 1.157763650252322
Validation loss: 2.6901130345356643

Epoch: 5| Step: 5
Training loss: 0.7291491415551731
Validation loss: 2.6754190615242757

Epoch: 5| Step: 6
Training loss: 0.5870290634037383
Validation loss: 2.62558665168308

Epoch: 5| Step: 7
Training loss: 1.2331349385127366
Validation loss: 2.640161245289007

Epoch: 5| Step: 8
Training loss: 0.9720694368897691
Validation loss: 2.615239172446027

Epoch: 5| Step: 9
Training loss: 0.7209101020491467
Validation loss: 2.6088151326838918

Epoch: 5| Step: 10
Training loss: 1.0683526242895438
Validation loss: 2.6200788634848546

Epoch: 245| Step: 0
Training loss: 1.059156317631554
Validation loss: 2.608201929736394

Epoch: 5| Step: 1
Training loss: 0.9639118651883379
Validation loss: 2.657586055954342

Epoch: 5| Step: 2
Training loss: 0.6849045746877609
Validation loss: 2.664998625563505

Epoch: 5| Step: 3
Training loss: 1.177355349457624
Validation loss: 2.674765086370094

Epoch: 5| Step: 4
Training loss: 0.9218216250210644
Validation loss: 2.6571715221615517

Epoch: 5| Step: 5
Training loss: 1.128972404679968
Validation loss: 2.6620708369464903

Epoch: 5| Step: 6
Training loss: 0.4147244686042591
Validation loss: 2.6450186545784624

Epoch: 5| Step: 7
Training loss: 1.1432144870843854
Validation loss: 2.618247340004111

Epoch: 5| Step: 8
Training loss: 1.1451804757623405
Validation loss: 2.6587630996100997

Epoch: 5| Step: 9
Training loss: 0.7593824896423468
Validation loss: 2.6320037052279193

Epoch: 5| Step: 10
Training loss: 0.8203532980809748
Validation loss: 2.586891672663256

Epoch: 246| Step: 0
Training loss: 0.956813398205919
Validation loss: 2.6495775939054518

Epoch: 5| Step: 1
Training loss: 0.7359277258869834
Validation loss: 2.6602433595315653

Epoch: 5| Step: 2
Training loss: 1.1519167351367503
Validation loss: 2.653641277606674

Epoch: 5| Step: 3
Training loss: 1.0600381266736736
Validation loss: 2.667558290895867

Epoch: 5| Step: 4
Training loss: 1.094040913721654
Validation loss: 2.6743288619889496

Epoch: 5| Step: 5
Training loss: 0.6239768236208902
Validation loss: 2.6563681617817685

Epoch: 5| Step: 6
Training loss: 0.6799717889571731
Validation loss: 2.6241560632637113

Epoch: 5| Step: 7
Training loss: 0.7895822229771787
Validation loss: 2.6541599367931856

Epoch: 5| Step: 8
Training loss: 0.9444313671727579
Validation loss: 2.655504569670041

Epoch: 5| Step: 9
Training loss: 0.9562318850029373
Validation loss: 2.664609033173193

Epoch: 5| Step: 10
Training loss: 1.1956311966635274
Validation loss: 2.6655654293327

Epoch: 247| Step: 0
Training loss: 0.9052932885224909
Validation loss: 2.688318101811698

Epoch: 5| Step: 1
Training loss: 1.0071196429254674
Validation loss: 2.676860374058351

Epoch: 5| Step: 2
Training loss: 1.2800244773819125
Validation loss: 2.6904874291421264

Epoch: 5| Step: 3
Training loss: 0.9129323901643706
Validation loss: 2.7074690948877693

Epoch: 5| Step: 4
Training loss: 0.7568872840445208
Validation loss: 2.6737909524392776

Epoch: 5| Step: 5
Training loss: 1.0069682407125111
Validation loss: 2.7000510297910862

Epoch: 5| Step: 6
Training loss: 1.167461068037256
Validation loss: 2.6889444095971897

Epoch: 5| Step: 7
Training loss: 0.6896379995623011
Validation loss: 2.6988331285830687

Epoch: 5| Step: 8
Training loss: 0.9674928568297869
Validation loss: 2.7127817832374985

Epoch: 5| Step: 9
Training loss: 0.42597799392732544
Validation loss: 2.733994312887574

Epoch: 5| Step: 10
Training loss: 0.8081473256130205
Validation loss: 2.7019848087742036

Epoch: 248| Step: 0
Training loss: 0.8132681516679071
Validation loss: 2.6930756382162184

Epoch: 5| Step: 1
Training loss: 1.0404848388124568
Validation loss: 2.711013851974215

Epoch: 5| Step: 2
Training loss: 0.9654072340064186
Validation loss: 2.7037679891588198

Epoch: 5| Step: 3
Training loss: 0.8967183790457065
Validation loss: 2.7343059065801354

Epoch: 5| Step: 4
Training loss: 1.116599935464039
Validation loss: 2.67179711024495

Epoch: 5| Step: 5
Training loss: 0.7118552436130147
Validation loss: 2.6773572806884287

Epoch: 5| Step: 6
Training loss: 0.9482088092936248
Validation loss: 2.6347890937807334

Epoch: 5| Step: 7
Training loss: 0.7603777305005909
Validation loss: 2.631843150614093

Epoch: 5| Step: 8
Training loss: 1.0496513219188055
Validation loss: 2.6385822952075664

Epoch: 5| Step: 9
Training loss: 0.8420415111262677
Validation loss: 2.6781389630545833

Epoch: 5| Step: 10
Training loss: 1.012242126592502
Validation loss: 2.644502710353299

Epoch: 249| Step: 0
Training loss: 0.723881852389091
Validation loss: 2.684176711849494

Epoch: 5| Step: 1
Training loss: 1.0610566714159804
Validation loss: 2.691764347291798

Epoch: 5| Step: 2
Training loss: 0.5712099460691551
Validation loss: 2.6839443188628924

Epoch: 5| Step: 3
Training loss: 1.0848696830822286
Validation loss: 2.6806594548240996

Epoch: 5| Step: 4
Training loss: 1.017283860196898
Validation loss: 2.7065642518027504

Epoch: 5| Step: 5
Training loss: 0.8790004086390425
Validation loss: 2.685225248794236

Epoch: 5| Step: 6
Training loss: 1.134947560313094
Validation loss: 2.686207533251949

Epoch: 5| Step: 7
Training loss: 0.914462466642368
Validation loss: 2.6682828176846343

Epoch: 5| Step: 8
Training loss: 0.9002408380929416
Validation loss: 2.6794493558739343

Epoch: 5| Step: 9
Training loss: 0.6952752949908295
Validation loss: 2.657503904118042

Epoch: 5| Step: 10
Training loss: 1.0246635256909205
Validation loss: 2.6034597593286346

Epoch: 250| Step: 0
Training loss: 0.9563051856080163
Validation loss: 2.6135621671186056

Epoch: 5| Step: 1
Training loss: 0.9835534982118447
Validation loss: 2.6014113976814826

Epoch: 5| Step: 2
Training loss: 0.861283247074818
Validation loss: 2.633403485964076

Epoch: 5| Step: 3
Training loss: 0.9389524335036119
Validation loss: 2.630245334621243

Epoch: 5| Step: 4
Training loss: 0.9851885264688439
Validation loss: 2.617587250234205

Epoch: 5| Step: 5
Training loss: 0.6044299166009107
Validation loss: 2.62751169258564

Epoch: 5| Step: 6
Training loss: 0.8856694739460796
Validation loss: 2.6581909616294266

Epoch: 5| Step: 7
Training loss: 1.1703940125053451
Validation loss: 2.6940652394882543

Epoch: 5| Step: 8
Training loss: 0.6828598442511585
Validation loss: 2.636358811008917

Epoch: 5| Step: 9
Training loss: 1.0479830102162169
Validation loss: 2.6691284359402045

Epoch: 5| Step: 10
Training loss: 0.8382565426273925
Validation loss: 2.6502722305670567

Epoch: 251| Step: 0
Training loss: 1.1896367675128696
Validation loss: 2.6485285449147113

Epoch: 5| Step: 1
Training loss: 0.8606932845829519
Validation loss: 2.6755848361518217

Epoch: 5| Step: 2
Training loss: 1.1321401771386477
Validation loss: 2.677188766993359

Epoch: 5| Step: 3
Training loss: 0.9961828752924076
Validation loss: 2.665525773649967

Epoch: 5| Step: 4
Training loss: 1.066172200323997
Validation loss: 2.677681580072252

Epoch: 5| Step: 5
Training loss: 0.7092309528249863
Validation loss: 2.7092332945999296

Epoch: 5| Step: 6
Training loss: 0.49810647046937856
Validation loss: 2.7192724563011126

Epoch: 5| Step: 7
Training loss: 0.9830329465845689
Validation loss: 2.7394107886074415

Epoch: 5| Step: 8
Training loss: 0.5495167549137087
Validation loss: 2.736450562645114

Epoch: 5| Step: 9
Training loss: 0.5759905513644107
Validation loss: 2.6910304294359406

Epoch: 5| Step: 10
Training loss: 1.0675835451225095
Validation loss: 2.6942775142710675

Epoch: 252| Step: 0
Training loss: 0.5135547228759698
Validation loss: 2.6731464071804196

Epoch: 5| Step: 1
Training loss: 0.962348057780137
Validation loss: 2.725152553741066

Epoch: 5| Step: 2
Training loss: 1.0926735621842412
Validation loss: 2.704114919632812

Epoch: 5| Step: 3
Training loss: 0.8987494217468863
Validation loss: 2.7185161529139403

Epoch: 5| Step: 4
Training loss: 1.1868763339982815
Validation loss: 2.6965210960701413

Epoch: 5| Step: 5
Training loss: 0.8874058015289393
Validation loss: 2.690456799488769

Epoch: 5| Step: 6
Training loss: 0.973921875432811
Validation loss: 2.6834203213837613

Epoch: 5| Step: 7
Training loss: 0.7078821531133418
Validation loss: 2.646613292795465

Epoch: 5| Step: 8
Training loss: 0.9278775716995478
Validation loss: 2.6336478320720365

Epoch: 5| Step: 9
Training loss: 0.543875342205679
Validation loss: 2.6576831577880493

Epoch: 5| Step: 10
Training loss: 0.9048540940349731
Validation loss: 2.6473228031913516

Epoch: 253| Step: 0
Training loss: 1.075038195086754
Validation loss: 2.676703639249077

Epoch: 5| Step: 1
Training loss: 0.9907413967836162
Validation loss: 2.650913029346154

Epoch: 5| Step: 2
Training loss: 1.1374413988717438
Validation loss: 2.6495639444197066

Epoch: 5| Step: 3
Training loss: 0.7733333787287775
Validation loss: 2.655195567637909

Epoch: 5| Step: 4
Training loss: 0.7520841806324196
Validation loss: 2.6530644327557282

Epoch: 5| Step: 5
Training loss: 0.8741535793145413
Validation loss: 2.633833149769081

Epoch: 5| Step: 6
Training loss: 0.831587193870382
Validation loss: 2.653584501203036

Epoch: 5| Step: 7
Training loss: 0.7210164203281875
Validation loss: 2.6839195634384603

Epoch: 5| Step: 8
Training loss: 1.2948829794633356
Validation loss: 2.664501796425042

Epoch: 5| Step: 9
Training loss: 0.47028712334084083
Validation loss: 2.6630374946714093

Epoch: 5| Step: 10
Training loss: 0.535592395675926
Validation loss: 2.6441404074705575

Epoch: 254| Step: 0
Training loss: 0.7314368783543486
Validation loss: 2.6299312923653275

Epoch: 5| Step: 1
Training loss: 1.15383359645466
Validation loss: 2.6534648986019658

Epoch: 5| Step: 2
Training loss: 0.9975179924453632
Validation loss: 2.58455097216243

Epoch: 5| Step: 3
Training loss: 1.064359160309338
Validation loss: 2.5977069349862347

Epoch: 5| Step: 4
Training loss: 0.6542447197467457
Validation loss: 2.5884543862818923

Epoch: 5| Step: 5
Training loss: 1.1483730375921528
Validation loss: 2.564857105137658

Epoch: 5| Step: 6
Training loss: 0.5492613362152555
Validation loss: 2.598469124518323

Epoch: 5| Step: 7
Training loss: 0.8531797258759088
Validation loss: 2.618162799853612

Epoch: 5| Step: 8
Training loss: 0.8014055005369588
Validation loss: 2.6312515150831683

Epoch: 5| Step: 9
Training loss: 0.8919950287641892
Validation loss: 2.636734662359268

Epoch: 5| Step: 10
Training loss: 0.7357065830674029
Validation loss: 2.7119743130760554

Epoch: 255| Step: 0
Training loss: 1.0136117200697736
Validation loss: 2.718713837692974

Epoch: 5| Step: 1
Training loss: 0.6317426798418664
Validation loss: 2.741258180764868

Epoch: 5| Step: 2
Training loss: 0.931355654720245
Validation loss: 2.762115339110945

Epoch: 5| Step: 3
Training loss: 0.8880574208587582
Validation loss: 2.7352148001053607

Epoch: 5| Step: 4
Training loss: 0.9572378130276731
Validation loss: 2.7268276328392207

Epoch: 5| Step: 5
Training loss: 1.0047714127164118
Validation loss: 2.6575860791059442

Epoch: 5| Step: 6
Training loss: 0.8937260364440988
Validation loss: 2.592438865688632

Epoch: 5| Step: 7
Training loss: 0.5598393138184857
Validation loss: 2.5974609681555823

Epoch: 5| Step: 8
Training loss: 0.9593799031781578
Validation loss: 2.540210024724235

Epoch: 5| Step: 9
Training loss: 0.9541228652184572
Validation loss: 2.519553514989379

Epoch: 5| Step: 10
Training loss: 0.969803821447942
Validation loss: 2.5832756039668836

Epoch: 256| Step: 0
Training loss: 0.682011063704147
Validation loss: 2.588742146866434

Epoch: 5| Step: 1
Training loss: 0.9518923057941687
Validation loss: 2.6116705524757458

Epoch: 5| Step: 2
Training loss: 0.9077897310274112
Validation loss: 2.6676203524671944

Epoch: 5| Step: 3
Training loss: 0.7258812776914545
Validation loss: 2.682276401462399

Epoch: 5| Step: 4
Training loss: 0.9164430966981959
Validation loss: 2.686132792495811

Epoch: 5| Step: 5
Training loss: 0.7154252235716976
Validation loss: 2.7115646837322873

Epoch: 5| Step: 6
Training loss: 0.7264677826865164
Validation loss: 2.630881802843131

Epoch: 5| Step: 7
Training loss: 1.1670359072615935
Validation loss: 2.7200906927586748

Epoch: 5| Step: 8
Training loss: 0.8896239159027908
Validation loss: 2.723290975159955

Epoch: 5| Step: 9
Training loss: 0.99892764410639
Validation loss: 2.67202525210224

Epoch: 5| Step: 10
Training loss: 0.8421949609203052
Validation loss: 2.67737232434553

Epoch: 257| Step: 0
Training loss: 0.8910373603146512
Validation loss: 2.6868032304371416

Epoch: 5| Step: 1
Training loss: 0.9716398758136572
Validation loss: 2.6569370237859213

Epoch: 5| Step: 2
Training loss: 1.1621676390331217
Validation loss: 2.6758451308806324

Epoch: 5| Step: 3
Training loss: 0.7659298426145346
Validation loss: 2.6530597839105092

Epoch: 5| Step: 4
Training loss: 1.0505399178678616
Validation loss: 2.6380955002309836

Epoch: 5| Step: 5
Training loss: 1.0404734962310442
Validation loss: 2.5990890229057775

Epoch: 5| Step: 6
Training loss: 0.5955405341717456
Validation loss: 2.6405809426338216

Epoch: 5| Step: 7
Training loss: 0.6797187841823243
Validation loss: 2.6046754604981395

Epoch: 5| Step: 8
Training loss: 0.7564668801540213
Validation loss: 2.6292119404532586

Epoch: 5| Step: 9
Training loss: 0.6236351608103126
Validation loss: 2.680360386520782

Epoch: 5| Step: 10
Training loss: 0.9522187974804669
Validation loss: 2.711745029309517

Epoch: 258| Step: 0
Training loss: 0.7672275198697472
Validation loss: 2.6651992997081857

Epoch: 5| Step: 1
Training loss: 0.9087800193351445
Validation loss: 2.696989759625905

Epoch: 5| Step: 2
Training loss: 0.5794078409378746
Validation loss: 2.693141044119773

Epoch: 5| Step: 3
Training loss: 0.8509344182009443
Validation loss: 2.7042534321209892

Epoch: 5| Step: 4
Training loss: 1.1158410341330884
Validation loss: 2.6954859457375826

Epoch: 5| Step: 5
Training loss: 0.8101978331794664
Validation loss: 2.6954480475223455

Epoch: 5| Step: 6
Training loss: 0.9263286018740339
Validation loss: 2.667379630695287

Epoch: 5| Step: 7
Training loss: 0.5155524578506119
Validation loss: 2.6890683178068513

Epoch: 5| Step: 8
Training loss: 0.9630421486382156
Validation loss: 2.6336665615443184

Epoch: 5| Step: 9
Training loss: 0.90552139589971
Validation loss: 2.654464612913404

Epoch: 5| Step: 10
Training loss: 1.1044200330618807
Validation loss: 2.6225092713109346

Epoch: 259| Step: 0
Training loss: 0.808859003023491
Validation loss: 2.679507634557144

Epoch: 5| Step: 1
Training loss: 0.7272328801374237
Validation loss: 2.660321971578837

Epoch: 5| Step: 2
Training loss: 0.7273794114234257
Validation loss: 2.6432168348141802

Epoch: 5| Step: 3
Training loss: 0.8226250159845147
Validation loss: 2.64651869473225

Epoch: 5| Step: 4
Training loss: 0.8698381004197994
Validation loss: 2.667881764427874

Epoch: 5| Step: 5
Training loss: 0.9307680662309136
Validation loss: 2.67008061517006

Epoch: 5| Step: 6
Training loss: 0.7873257701627877
Validation loss: 2.671574205595138

Epoch: 5| Step: 7
Training loss: 0.6802454226100447
Validation loss: 2.652307238069159

Epoch: 5| Step: 8
Training loss: 0.9712901499144011
Validation loss: 2.645272234609203

Epoch: 5| Step: 9
Training loss: 1.163063183617164
Validation loss: 2.6280324445759433

Epoch: 5| Step: 10
Training loss: 0.7492608958493568
Validation loss: 2.660186766921223

Epoch: 260| Step: 0
Training loss: 0.47080163201929975
Validation loss: 2.670329027293907

Epoch: 5| Step: 1
Training loss: 1.0876328661202013
Validation loss: 2.636453529062759

Epoch: 5| Step: 2
Training loss: 0.8364420998891555
Validation loss: 2.650411924177349

Epoch: 5| Step: 3
Training loss: 0.5029632260889364
Validation loss: 2.664137872434361

Epoch: 5| Step: 4
Training loss: 0.747116745646466
Validation loss: 2.6126272933681745

Epoch: 5| Step: 5
Training loss: 1.0289507578938897
Validation loss: 2.67581642127165

Epoch: 5| Step: 6
Training loss: 0.9261285959185034
Validation loss: 2.600383325883023

Epoch: 5| Step: 7
Training loss: 0.7915872651151871
Validation loss: 2.577718086733794

Epoch: 5| Step: 8
Training loss: 0.9190412059860665
Validation loss: 2.6113201738900194

Epoch: 5| Step: 9
Training loss: 0.9218382100668455
Validation loss: 2.6115585621727657

Epoch: 5| Step: 10
Training loss: 0.7477486516442318
Validation loss: 2.6043499166351114

Epoch: 261| Step: 0
Training loss: 0.9799604884279021
Validation loss: 2.646609521840286

Epoch: 5| Step: 1
Training loss: 0.5894534859931099
Validation loss: 2.623012628355329

Epoch: 5| Step: 2
Training loss: 1.0411168491183238
Validation loss: 2.67784485284967

Epoch: 5| Step: 3
Training loss: 0.8723089525981944
Validation loss: 2.6464816423052464

Epoch: 5| Step: 4
Training loss: 0.9883156570657227
Validation loss: 2.6580463403662677

Epoch: 5| Step: 5
Training loss: 0.7708691425425696
Validation loss: 2.67943640966722

Epoch: 5| Step: 6
Training loss: 0.6877756433174785
Validation loss: 2.6654948581197977

Epoch: 5| Step: 7
Training loss: 0.6801024737701948
Validation loss: 2.6726736839440357

Epoch: 5| Step: 8
Training loss: 0.672335976660542
Validation loss: 2.643726608594511

Epoch: 5| Step: 9
Training loss: 0.8370772461949133
Validation loss: 2.6145237480080348

Epoch: 5| Step: 10
Training loss: 0.9216974701714974
Validation loss: 2.6236017119406676

Epoch: 262| Step: 0
Training loss: 0.544138793504074
Validation loss: 2.6094823938849054

Epoch: 5| Step: 1
Training loss: 0.880785649295233
Validation loss: 2.5858088397737418

Epoch: 5| Step: 2
Training loss: 0.6985233621069593
Validation loss: 2.655365124664826

Epoch: 5| Step: 3
Training loss: 1.0158205284290052
Validation loss: 2.682048705284051

Epoch: 5| Step: 4
Training loss: 0.677333614357129
Validation loss: 2.681379301934424

Epoch: 5| Step: 5
Training loss: 0.6901351321968529
Validation loss: 2.7150607010801364

Epoch: 5| Step: 6
Training loss: 0.9818491546123697
Validation loss: 2.675958892767449

Epoch: 5| Step: 7
Training loss: 1.0064619611136336
Validation loss: 2.7098103669240006

Epoch: 5| Step: 8
Training loss: 0.736362932025046
Validation loss: 2.688809163014401

Epoch: 5| Step: 9
Training loss: 0.9709298619318888
Validation loss: 2.638796320768486

Epoch: 5| Step: 10
Training loss: 0.8421275469614192
Validation loss: 2.623995321575269

Epoch: 263| Step: 0
Training loss: 1.018758605265402
Validation loss: 2.5965339090821806

Epoch: 5| Step: 1
Training loss: 0.8746604260516643
Validation loss: 2.586653470976298

Epoch: 5| Step: 2
Training loss: 1.0321341683459981
Validation loss: 2.5694002019267272

Epoch: 5| Step: 3
Training loss: 0.7015592944575357
Validation loss: 2.588381128306934

Epoch: 5| Step: 4
Training loss: 0.5938067660049361
Validation loss: 2.5549582271798577

Epoch: 5| Step: 5
Training loss: 0.9183027593181354
Validation loss: 2.6330678747866423

Epoch: 5| Step: 6
Training loss: 0.6037679842132324
Validation loss: 2.7036591433094865

Epoch: 5| Step: 7
Training loss: 0.8865108834516763
Validation loss: 2.6925602173566747

Epoch: 5| Step: 8
Training loss: 0.8170331893142092
Validation loss: 2.729349569995633

Epoch: 5| Step: 9
Training loss: 0.8865184473677612
Validation loss: 2.6847785015461683

Epoch: 5| Step: 10
Training loss: 0.7741264973482286
Validation loss: 2.6750160267407006

Epoch: 264| Step: 0
Training loss: 0.615245758435735
Validation loss: 2.639563554731666

Epoch: 5| Step: 1
Training loss: 0.600164026449841
Validation loss: 2.6168930610496988

Epoch: 5| Step: 2
Training loss: 0.836677971994027
Validation loss: 2.617521848154011

Epoch: 5| Step: 3
Training loss: 0.9766231365452176
Validation loss: 2.575108580943794

Epoch: 5| Step: 4
Training loss: 0.8518874222205856
Validation loss: 2.5976600742550953

Epoch: 5| Step: 5
Training loss: 0.9455351133922282
Validation loss: 2.567396147500059

Epoch: 5| Step: 6
Training loss: 0.9301204795117488
Validation loss: 2.6149872897294184

Epoch: 5| Step: 7
Training loss: 0.7038879070368804
Validation loss: 2.609678488910563

Epoch: 5| Step: 8
Training loss: 1.217046182481823
Validation loss: 2.668001611481663

Epoch: 5| Step: 9
Training loss: 0.5989853534961658
Validation loss: 2.59080547179793

Epoch: 5| Step: 10
Training loss: 0.3642587533892632
Validation loss: 2.644704745811774

Epoch: 265| Step: 0
Training loss: 0.7408268955138364
Validation loss: 2.6791073535182997

Epoch: 5| Step: 1
Training loss: 1.1777607929056673
Validation loss: 2.671597992995338

Epoch: 5| Step: 2
Training loss: 0.686182254754882
Validation loss: 2.6441829870926377

Epoch: 5| Step: 3
Training loss: 0.7732692882378075
Validation loss: 2.6255355772999236

Epoch: 5| Step: 4
Training loss: 0.6718569021227151
Validation loss: 2.5916486590581216

Epoch: 5| Step: 5
Training loss: 0.9239162217570905
Validation loss: 2.564666754393944

Epoch: 5| Step: 6
Training loss: 0.8140561899830235
Validation loss: 2.5931020817738832

Epoch: 5| Step: 7
Training loss: 0.77678541518583
Validation loss: 2.578765206943921

Epoch: 5| Step: 8
Training loss: 0.6070447039003114
Validation loss: 2.558450532054985

Epoch: 5| Step: 9
Training loss: 0.8317911939014038
Validation loss: 2.628436694036468

Epoch: 5| Step: 10
Training loss: 0.7403406957600618
Validation loss: 2.607096755693769

Epoch: 266| Step: 0
Training loss: 0.8953745169738805
Validation loss: 2.594560901897669

Epoch: 5| Step: 1
Training loss: 0.7083546597879299
Validation loss: 2.6022467038229355

Epoch: 5| Step: 2
Training loss: 0.6279801130441326
Validation loss: 2.582096858509175

Epoch: 5| Step: 3
Training loss: 0.6933307050768237
Validation loss: 2.618819426472046

Epoch: 5| Step: 4
Training loss: 1.0864129432176874
Validation loss: 2.5904586161832426

Epoch: 5| Step: 5
Training loss: 0.80249431946785
Validation loss: 2.636867044487587

Epoch: 5| Step: 6
Training loss: 0.7183162375478777
Validation loss: 2.6843181718456206

Epoch: 5| Step: 7
Training loss: 0.7970041282599541
Validation loss: 2.6530418436012653

Epoch: 5| Step: 8
Training loss: 0.7318746735191757
Validation loss: 2.662311446523881

Epoch: 5| Step: 9
Training loss: 0.7393689090997039
Validation loss: 2.63704338648761

Epoch: 5| Step: 10
Training loss: 0.930497273633305
Validation loss: 2.665137401076202

Epoch: 267| Step: 0
Training loss: 0.5726785309374507
Validation loss: 2.643011533218799

Epoch: 5| Step: 1
Training loss: 0.743722072044912
Validation loss: 2.615617975274632

Epoch: 5| Step: 2
Training loss: 0.7277103504058668
Validation loss: 2.6183758798253436

Epoch: 5| Step: 3
Training loss: 0.768361475698744
Validation loss: 2.611392670545305

Epoch: 5| Step: 4
Training loss: 0.8625745340291027
Validation loss: 2.6150351663705327

Epoch: 5| Step: 5
Training loss: 0.8970420615350857
Validation loss: 2.5632525573771416

Epoch: 5| Step: 6
Training loss: 0.8492103077908413
Validation loss: 2.579852389427608

Epoch: 5| Step: 7
Training loss: 0.9516250188925974
Validation loss: 2.6192363895153306

Epoch: 5| Step: 8
Training loss: 0.8373245425547458
Validation loss: 2.647259171463791

Epoch: 5| Step: 9
Training loss: 0.839813373814763
Validation loss: 2.645914472001653

Epoch: 5| Step: 10
Training loss: 0.7111589694641017
Validation loss: 2.686835229439238

Epoch: 268| Step: 0
Training loss: 0.9116843497382121
Validation loss: 2.644771335339506

Epoch: 5| Step: 1
Training loss: 0.81663320206827
Validation loss: 2.6457148796646197

Epoch: 5| Step: 2
Training loss: 0.5437267145016085
Validation loss: 2.6077125120948446

Epoch: 5| Step: 3
Training loss: 0.7591147098355763
Validation loss: 2.6256049323955732

Epoch: 5| Step: 4
Training loss: 0.5842099726819245
Validation loss: 2.640160832606881

Epoch: 5| Step: 5
Training loss: 1.1366020745768115
Validation loss: 2.589029181341749

Epoch: 5| Step: 6
Training loss: 0.7398323034027394
Validation loss: 2.568427848051329

Epoch: 5| Step: 7
Training loss: 1.0214917272007757
Validation loss: 2.566406029238145

Epoch: 5| Step: 8
Training loss: 0.6941355484501514
Validation loss: 2.5677300633458224

Epoch: 5| Step: 9
Training loss: 0.6730275360003529
Validation loss: 2.5454780718093484

Epoch: 5| Step: 10
Training loss: 0.5793514388066133
Validation loss: 2.5565067780373476

Epoch: 269| Step: 0
Training loss: 0.970445687064953
Validation loss: 2.5543429164348477

Epoch: 5| Step: 1
Training loss: 0.8698274106354404
Validation loss: 2.592300660963125

Epoch: 5| Step: 2
Training loss: 0.7399329223388105
Validation loss: 2.6550013261961714

Epoch: 5| Step: 3
Training loss: 0.9728661123097946
Validation loss: 2.672528089041129

Epoch: 5| Step: 4
Training loss: 0.9283994198349862
Validation loss: 2.6472895639681293

Epoch: 5| Step: 5
Training loss: 0.5005434778061602
Validation loss: 2.6791047871084586

Epoch: 5| Step: 6
Training loss: 0.5476979739066874
Validation loss: 2.673195100773761

Epoch: 5| Step: 7
Training loss: 0.6391786903392687
Validation loss: 2.667322032776717

Epoch: 5| Step: 8
Training loss: 0.7278077723806955
Validation loss: 2.651751604126037

Epoch: 5| Step: 9
Training loss: 0.8419544753953777
Validation loss: 2.6501653597615493

Epoch: 5| Step: 10
Training loss: 0.6986421733225884
Validation loss: 2.6501392411504994

Epoch: 270| Step: 0
Training loss: 0.5183190279036319
Validation loss: 2.6253032792350672

Epoch: 5| Step: 1
Training loss: 0.9239248987203136
Validation loss: 2.6042901357278465

Epoch: 5| Step: 2
Training loss: 0.6686535721181621
Validation loss: 2.624472578790419

Epoch: 5| Step: 3
Training loss: 0.8025143732584149
Validation loss: 2.6135450052525564

Epoch: 5| Step: 4
Training loss: 0.8579131437367946
Validation loss: 2.6163321784525544

Epoch: 5| Step: 5
Training loss: 0.7058619108085914
Validation loss: 2.6175491516583262

Epoch: 5| Step: 6
Training loss: 0.8120219217968051
Validation loss: 2.601855536598616

Epoch: 5| Step: 7
Training loss: 0.8316339251533714
Validation loss: 2.625972991331866

Epoch: 5| Step: 8
Training loss: 0.47694523872772704
Validation loss: 2.6283142908566957

Epoch: 5| Step: 9
Training loss: 0.8756252166834909
Validation loss: 2.6186251643335825

Epoch: 5| Step: 10
Training loss: 0.8540814791432926
Validation loss: 2.6699116738887247

Epoch: 271| Step: 0
Training loss: 0.7332177885740463
Validation loss: 2.6118373176981184

Epoch: 5| Step: 1
Training loss: 0.7489378083183942
Validation loss: 2.647679673420796

Epoch: 5| Step: 2
Training loss: 0.8816171841596088
Validation loss: 2.6566614526022336

Epoch: 5| Step: 3
Training loss: 0.7826078440539477
Validation loss: 2.6164546655005845

Epoch: 5| Step: 4
Training loss: 0.9229145977149202
Validation loss: 2.643761679760935

Epoch: 5| Step: 5
Training loss: 0.6202993530878891
Validation loss: 2.6108607865857407

Epoch: 5| Step: 6
Training loss: 0.782203931159624
Validation loss: 2.6527585018503994

Epoch: 5| Step: 7
Training loss: 0.8984331545517364
Validation loss: 2.6199562322628513

Epoch: 5| Step: 8
Training loss: 0.382422072943382
Validation loss: 2.608141773665608

Epoch: 5| Step: 9
Training loss: 0.8418422607082444
Validation loss: 2.630524653555551

Epoch: 5| Step: 10
Training loss: 0.6044075803446716
Validation loss: 2.635863517268949

Epoch: 272| Step: 0
Training loss: 0.6682792075952979
Validation loss: 2.6143652019264323

Epoch: 5| Step: 1
Training loss: 0.5722763529217894
Validation loss: 2.6385093155477017

Epoch: 5| Step: 2
Training loss: 0.7677002632479547
Validation loss: 2.606905821104452

Epoch: 5| Step: 3
Training loss: 0.7071117966437331
Validation loss: 2.624777781060136

Epoch: 5| Step: 4
Training loss: 0.9070713333354785
Validation loss: 2.6220484780507975

Epoch: 5| Step: 5
Training loss: 0.696719556843508
Validation loss: 2.643078111088287

Epoch: 5| Step: 6
Training loss: 0.5203979834365771
Validation loss: 2.658109808379975

Epoch: 5| Step: 7
Training loss: 0.8016698233753107
Validation loss: 2.655242209499472

Epoch: 5| Step: 8
Training loss: 0.877112019508475
Validation loss: 2.622691689958794

Epoch: 5| Step: 9
Training loss: 0.8640805854767161
Validation loss: 2.6303753679898207

Epoch: 5| Step: 10
Training loss: 0.8003421230709977
Validation loss: 2.6630869184481885

Epoch: 273| Step: 0
Training loss: 0.8890598330600206
Validation loss: 2.632510366333029

Epoch: 5| Step: 1
Training loss: 0.7131199298113385
Validation loss: 2.6664645976626247

Epoch: 5| Step: 2
Training loss: 0.8465589813463459
Validation loss: 2.663888334425312

Epoch: 5| Step: 3
Training loss: 0.7953751604918456
Validation loss: 2.6656303090354

Epoch: 5| Step: 4
Training loss: 0.7807325175194133
Validation loss: 2.6249430562848812

Epoch: 5| Step: 5
Training loss: 0.8192821753303473
Validation loss: 2.605925642669307

Epoch: 5| Step: 6
Training loss: 0.9306842365460009
Validation loss: 2.6330648273149424

Epoch: 5| Step: 7
Training loss: 0.49424193779829456
Validation loss: 2.613576264561669

Epoch: 5| Step: 8
Training loss: 0.7495021359703975
Validation loss: 2.615032303757116

Epoch: 5| Step: 9
Training loss: 0.6247677609978497
Validation loss: 2.625577024294476

Epoch: 5| Step: 10
Training loss: 0.4672011536098961
Validation loss: 2.642919836529272

Epoch: 274| Step: 0
Training loss: 0.7320071661212745
Validation loss: 2.6454908152335443

Epoch: 5| Step: 1
Training loss: 0.9340156017078642
Validation loss: 2.672052835781617

Epoch: 5| Step: 2
Training loss: 0.9789183924135785
Validation loss: 2.6274532187477067

Epoch: 5| Step: 3
Training loss: 0.5024657841320941
Validation loss: 2.644095149206268

Epoch: 5| Step: 4
Training loss: 0.50065096560421
Validation loss: 2.5803238000152513

Epoch: 5| Step: 5
Training loss: 0.7694088213975893
Validation loss: 2.638158804914913

Epoch: 5| Step: 6
Training loss: 0.7623226803829098
Validation loss: 2.561528647797661

Epoch: 5| Step: 7
Training loss: 1.0340921943115418
Validation loss: 2.550579767433054

Epoch: 5| Step: 8
Training loss: 0.6360602454870555
Validation loss: 2.613325014205777

Epoch: 5| Step: 9
Training loss: 0.6862221459605629
Validation loss: 2.6235911313877396

Epoch: 5| Step: 10
Training loss: 0.5762035296521691
Validation loss: 2.6392089897515167

Epoch: 275| Step: 0
Training loss: 0.6992356708546399
Validation loss: 2.6548168806630135

Epoch: 5| Step: 1
Training loss: 0.7842633308466923
Validation loss: 2.6683079036095214

Epoch: 5| Step: 2
Training loss: 0.7987911896689197
Validation loss: 2.655632178825463

Epoch: 5| Step: 3
Training loss: 0.7699157606217883
Validation loss: 2.6545710836843734

Epoch: 5| Step: 4
Training loss: 0.8179812046913624
Validation loss: 2.5940901632933144

Epoch: 5| Step: 5
Training loss: 0.8212873932847559
Validation loss: 2.6292853497812523

Epoch: 5| Step: 6
Training loss: 0.513229411626899
Validation loss: 2.6059693966129474

Epoch: 5| Step: 7
Training loss: 0.8833436633951532
Validation loss: 2.592037977653288

Epoch: 5| Step: 8
Training loss: 0.7454208615140406
Validation loss: 2.6074142502031123

Epoch: 5| Step: 9
Training loss: 0.78179264296561
Validation loss: 2.5600059932143804

Epoch: 5| Step: 10
Training loss: 0.6384576794109528
Validation loss: 2.5649038365372827

Epoch: 276| Step: 0
Training loss: 1.0452828897749986
Validation loss: 2.5786013504029657

Epoch: 5| Step: 1
Training loss: 0.5055150218697443
Validation loss: 2.605149321858609

Epoch: 5| Step: 2
Training loss: 0.5691500011711185
Validation loss: 2.614656280086975

Epoch: 5| Step: 3
Training loss: 0.744640592889849
Validation loss: 2.634142092303215

Epoch: 5| Step: 4
Training loss: 0.4334320247884648
Validation loss: 2.654447009984833

Epoch: 5| Step: 5
Training loss: 0.8335270934549932
Validation loss: 2.7177460395879613

Epoch: 5| Step: 6
Training loss: 0.7345160490896296
Validation loss: 2.687636625456731

Epoch: 5| Step: 7
Training loss: 0.9161289364613986
Validation loss: 2.706726899019633

Epoch: 5| Step: 8
Training loss: 0.8754287078213292
Validation loss: 2.6865851478018206

Epoch: 5| Step: 9
Training loss: 0.7655324685370104
Validation loss: 2.644553672407191

Epoch: 5| Step: 10
Training loss: 0.4772981843568566
Validation loss: 2.645736456788188

Epoch: 277| Step: 0
Training loss: 0.8155290189078787
Validation loss: 2.6319961604099595

Epoch: 5| Step: 1
Training loss: 0.6463821422497308
Validation loss: 2.582849536320998

Epoch: 5| Step: 2
Training loss: 0.8546515267174768
Validation loss: 2.5852022269812323

Epoch: 5| Step: 3
Training loss: 0.5233782834391236
Validation loss: 2.632704431611386

Epoch: 5| Step: 4
Training loss: 0.6548037942371535
Validation loss: 2.6393704444717123

Epoch: 5| Step: 5
Training loss: 0.7404549302829747
Validation loss: 2.6289877908226167

Epoch: 5| Step: 6
Training loss: 0.7242510544568761
Validation loss: 2.6453204460056927

Epoch: 5| Step: 7
Training loss: 0.7463340971316538
Validation loss: 2.614105951386834

Epoch: 5| Step: 8
Training loss: 0.6250096558778648
Validation loss: 2.6319161388135512

Epoch: 5| Step: 9
Training loss: 0.9528333811913128
Validation loss: 2.6475619198128317

Epoch: 5| Step: 10
Training loss: 0.7594895829772789
Validation loss: 2.622279545197013

Epoch: 278| Step: 0
Training loss: 0.8028940380796332
Validation loss: 2.6541573897260307

Epoch: 5| Step: 1
Training loss: 0.9843867165004453
Validation loss: 2.6670534846128238

Epoch: 5| Step: 2
Training loss: 0.544996523102335
Validation loss: 2.6776153838875283

Epoch: 5| Step: 3
Training loss: 0.46036791766330487
Validation loss: 2.6512169955953584

Epoch: 5| Step: 4
Training loss: 0.7541874178425377
Validation loss: 2.6972079011007826

Epoch: 5| Step: 5
Training loss: 0.8045733843135112
Validation loss: 2.702747668356747

Epoch: 5| Step: 6
Training loss: 0.8388240212468633
Validation loss: 2.630313722945321

Epoch: 5| Step: 7
Training loss: 0.6660465893301498
Validation loss: 2.6347790407614458

Epoch: 5| Step: 8
Training loss: 0.7450648298154323
Validation loss: 2.600966940453912

Epoch: 5| Step: 9
Training loss: 0.7181091768996618
Validation loss: 2.6061182711935693

Epoch: 5| Step: 10
Training loss: 0.5928501286928858
Validation loss: 2.6059668663887154

Epoch: 279| Step: 0
Training loss: 0.5807598231367904
Validation loss: 2.607855778185878

Epoch: 5| Step: 1
Training loss: 0.48316751223971877
Validation loss: 2.578715505184901

Epoch: 5| Step: 2
Training loss: 0.7528668289564525
Validation loss: 2.6243186565493453

Epoch: 5| Step: 3
Training loss: 0.6807839768245458
Validation loss: 2.6379026809583825

Epoch: 5| Step: 4
Training loss: 0.9105805811786463
Validation loss: 2.6326361268144822

Epoch: 5| Step: 5
Training loss: 0.7817112133479432
Validation loss: 2.6228213080510114

Epoch: 5| Step: 6
Training loss: 0.5671958681019961
Validation loss: 2.6712639433801164

Epoch: 5| Step: 7
Training loss: 0.6561282817041207
Validation loss: 2.6784706286221396

Epoch: 5| Step: 8
Training loss: 0.8471525251316581
Validation loss: 2.6987277571357966

Epoch: 5| Step: 9
Training loss: 0.9217803389230526
Validation loss: 2.65736794926491

Epoch: 5| Step: 10
Training loss: 0.6228017294833377
Validation loss: 2.6559252082547773

Epoch: 280| Step: 0
Training loss: 0.620851337461958
Validation loss: 2.626922883671167

Epoch: 5| Step: 1
Training loss: 0.7056264251208042
Validation loss: 2.601790969751049

Epoch: 5| Step: 2
Training loss: 0.7236722659991572
Validation loss: 2.6253637070665103

Epoch: 5| Step: 3
Training loss: 0.680723847181399
Validation loss: 2.5754167419247027

Epoch: 5| Step: 4
Training loss: 0.8514681772612411
Validation loss: 2.58964165169216

Epoch: 5| Step: 5
Training loss: 0.7408236370017104
Validation loss: 2.5898993550545897

Epoch: 5| Step: 6
Training loss: 0.5986002031066581
Validation loss: 2.5629545979575346

Epoch: 5| Step: 7
Training loss: 0.5936086888051397
Validation loss: 2.609072607727793

Epoch: 5| Step: 8
Training loss: 0.7391678265286893
Validation loss: 2.5798067372131013

Epoch: 5| Step: 9
Training loss: 0.6963603450032191
Validation loss: 2.5932504484457484

Epoch: 5| Step: 10
Training loss: 0.8800327795599295
Validation loss: 2.6341077524374725

Epoch: 281| Step: 0
Training loss: 0.8959171270762503
Validation loss: 2.612203905601343

Epoch: 5| Step: 1
Training loss: 0.8062363320308431
Validation loss: 2.6436514552210038

Epoch: 5| Step: 2
Training loss: 0.9097778450524764
Validation loss: 2.651575832285204

Epoch: 5| Step: 3
Training loss: 0.7585117614000191
Validation loss: 2.6589509366398985

Epoch: 5| Step: 4
Training loss: 0.6554741814880487
Validation loss: 2.6334532629294367

Epoch: 5| Step: 5
Training loss: 0.7189966276219721
Validation loss: 2.6333697322615977

Epoch: 5| Step: 6
Training loss: 0.3411940462924273
Validation loss: 2.6150169142152517

Epoch: 5| Step: 7
Training loss: 0.500715101994311
Validation loss: 2.604714385156442

Epoch: 5| Step: 8
Training loss: 0.6923142198770444
Validation loss: 2.5909335722203917

Epoch: 5| Step: 9
Training loss: 0.7382561411952576
Validation loss: 2.609341347133338

Epoch: 5| Step: 10
Training loss: 0.6140390318834099
Validation loss: 2.6085734254675415

Epoch: 282| Step: 0
Training loss: 0.5180511328542793
Validation loss: 2.6069831105666506

Epoch: 5| Step: 1
Training loss: 0.6677506743370202
Validation loss: 2.6297146998677334

Epoch: 5| Step: 2
Training loss: 0.9303013994594506
Validation loss: 2.6584205970967463

Epoch: 5| Step: 3
Training loss: 0.7734233970512284
Validation loss: 2.6145711791563264

Epoch: 5| Step: 4
Training loss: 0.7518425401893286
Validation loss: 2.6515539055483766

Epoch: 5| Step: 5
Training loss: 0.5855143735898358
Validation loss: 2.660026812768698

Epoch: 5| Step: 6
Training loss: 0.853400844651424
Validation loss: 2.688618777430095

Epoch: 5| Step: 7
Training loss: 0.6121818747853487
Validation loss: 2.6200471347917222

Epoch: 5| Step: 8
Training loss: 0.7658565326853123
Validation loss: 2.6491668265168085

Epoch: 5| Step: 9
Training loss: 0.5656602353243863
Validation loss: 2.626250744983467

Epoch: 5| Step: 10
Training loss: 0.6548648020574124
Validation loss: 2.6551681989073854

Epoch: 283| Step: 0
Training loss: 0.7917379966189713
Validation loss: 2.6457768703020608

Epoch: 5| Step: 1
Training loss: 0.8640499231344095
Validation loss: 2.6430092111107415

Epoch: 5| Step: 2
Training loss: 0.530680687973515
Validation loss: 2.615520238016381

Epoch: 5| Step: 3
Training loss: 0.6370585184480909
Validation loss: 2.6592325856035868

Epoch: 5| Step: 4
Training loss: 0.7329181261537849
Validation loss: 2.6512036639810974

Epoch: 5| Step: 5
Training loss: 0.6967836311553879
Validation loss: 2.6518780162903433

Epoch: 5| Step: 6
Training loss: 0.8448404753508476
Validation loss: 2.636383859627507

Epoch: 5| Step: 7
Training loss: 0.756960045267804
Validation loss: 2.6972052321532156

Epoch: 5| Step: 8
Training loss: 0.47463883987454236
Validation loss: 2.687153914370865

Epoch: 5| Step: 9
Training loss: 0.6771994466744431
Validation loss: 2.7159794821274623

Epoch: 5| Step: 10
Training loss: 0.6540976605394356
Validation loss: 2.695258654983506

Epoch: 284| Step: 0
Training loss: 0.5966605325424384
Validation loss: 2.7263623217103596

Epoch: 5| Step: 1
Training loss: 0.5579435125201976
Validation loss: 2.677391187445799

Epoch: 5| Step: 2
Training loss: 0.6817689135480467
Validation loss: 2.6928201916657866

Epoch: 5| Step: 3
Training loss: 0.8361056862743491
Validation loss: 2.664759465035258

Epoch: 5| Step: 4
Training loss: 0.6440032414582817
Validation loss: 2.6345022446281754

Epoch: 5| Step: 5
Training loss: 0.7142086438766109
Validation loss: 2.63620858966588

Epoch: 5| Step: 6
Training loss: 0.7183483909111511
Validation loss: 2.575605035083539

Epoch: 5| Step: 7
Training loss: 0.5915338164487522
Validation loss: 2.5855705631162516

Epoch: 5| Step: 8
Training loss: 0.8701167422378034
Validation loss: 2.5592345874827003

Epoch: 5| Step: 9
Training loss: 0.7129081828424305
Validation loss: 2.588471600604832

Epoch: 5| Step: 10
Training loss: 0.758540089336775
Validation loss: 2.6093234962890692

Epoch: 285| Step: 0
Training loss: 0.5660471863302606
Validation loss: 2.612360049007949

Epoch: 5| Step: 1
Training loss: 0.8432488542645675
Validation loss: 2.641568812234251

Epoch: 5| Step: 2
Training loss: 0.7557908059100258
Validation loss: 2.6724877030671323

Epoch: 5| Step: 3
Training loss: 0.5237103505478776
Validation loss: 2.6423255816652698

Epoch: 5| Step: 4
Training loss: 0.6799261178523461
Validation loss: 2.6472526859928744

Epoch: 5| Step: 5
Training loss: 0.6985024560681732
Validation loss: 2.6345198674549244

Epoch: 5| Step: 6
Training loss: 0.7878878319633579
Validation loss: 2.630824664865851

Epoch: 5| Step: 7
Training loss: 0.6118764155277014
Validation loss: 2.6062339680708964

Epoch: 5| Step: 8
Training loss: 0.9308148449080791
Validation loss: 2.641554537121741

Epoch: 5| Step: 9
Training loss: 0.6987404705960537
Validation loss: 2.579967555562047

Epoch: 5| Step: 10
Training loss: 0.22659931212650783
Validation loss: 2.63474626212551

Epoch: 286| Step: 0
Training loss: 0.7118490055954795
Validation loss: 2.622008541373557

Epoch: 5| Step: 1
Training loss: 0.7090945828115892
Validation loss: 2.609279924350089

Epoch: 5| Step: 2
Training loss: 0.7298585107282957
Validation loss: 2.6115651436476104

Epoch: 5| Step: 3
Training loss: 0.4656730595050655
Validation loss: 2.5963040194173224

Epoch: 5| Step: 4
Training loss: 0.5803617047560259
Validation loss: 2.636905983946748

Epoch: 5| Step: 5
Training loss: 0.8280933661986687
Validation loss: 2.5980479133048546

Epoch: 5| Step: 6
Training loss: 0.8586890170392633
Validation loss: 2.6281804976039975

Epoch: 5| Step: 7
Training loss: 0.6734413916880306
Validation loss: 2.627097147625631

Epoch: 5| Step: 8
Training loss: 0.6341405049899981
Validation loss: 2.607375928747345

Epoch: 5| Step: 9
Training loss: 0.3973888734913822
Validation loss: 2.6147618290234393

Epoch: 5| Step: 10
Training loss: 0.7544932476750212
Validation loss: 2.5837202275307134

Epoch: 287| Step: 0
Training loss: 0.6862428832597102
Validation loss: 2.602904443984984

Epoch: 5| Step: 1
Training loss: 0.7756153232730078
Validation loss: 2.6502486309464843

Epoch: 5| Step: 2
Training loss: 0.60828843201445
Validation loss: 2.675560411562163

Epoch: 5| Step: 3
Training loss: 0.41839789703849933
Validation loss: 2.666785007460741

Epoch: 5| Step: 4
Training loss: 0.6850934607727
Validation loss: 2.685609171900858

Epoch: 5| Step: 5
Training loss: 0.6935206910644808
Validation loss: 2.660128515976934

Epoch: 5| Step: 6
Training loss: 0.8904862546764892
Validation loss: 2.6326384678099903

Epoch: 5| Step: 7
Training loss: 0.8428725165588371
Validation loss: 2.627612763980271

Epoch: 5| Step: 8
Training loss: 0.4771019274684868
Validation loss: 2.5959391917333066

Epoch: 5| Step: 9
Training loss: 0.641491188066099
Validation loss: 2.626927960350723

Epoch: 5| Step: 10
Training loss: 0.6105156517709284
Validation loss: 2.637889634837599

Epoch: 288| Step: 0
Training loss: 0.6106566132216966
Validation loss: 2.6166687898435876

Epoch: 5| Step: 1
Training loss: 0.7562442952721179
Validation loss: 2.636965646187149

Epoch: 5| Step: 2
Training loss: 0.8251423655119957
Validation loss: 2.649278697909254

Epoch: 5| Step: 3
Training loss: 0.6559600870896957
Validation loss: 2.667908057193299

Epoch: 5| Step: 4
Training loss: 0.7546044708765569
Validation loss: 2.6650768121293984

Epoch: 5| Step: 5
Training loss: 0.7669416511503506
Validation loss: 2.7266349854539156

Epoch: 5| Step: 6
Training loss: 0.6961988949811034
Validation loss: 2.711659037699066

Epoch: 5| Step: 7
Training loss: 0.6312369760737185
Validation loss: 2.6723488411081244

Epoch: 5| Step: 8
Training loss: 0.5029751358977801
Validation loss: 2.7344592665947025

Epoch: 5| Step: 9
Training loss: 0.3058074882801438
Validation loss: 2.7013550478121173

Epoch: 5| Step: 10
Training loss: 0.9082795141765572
Validation loss: 2.6862075824020946

Epoch: 289| Step: 0
Training loss: 0.564637388360755
Validation loss: 2.652511707106992

Epoch: 5| Step: 1
Training loss: 0.5269586640583632
Validation loss: 2.6904046792042995

Epoch: 5| Step: 2
Training loss: 0.30388441375107345
Validation loss: 2.6217399829828847

Epoch: 5| Step: 3
Training loss: 0.81989364829871
Validation loss: 2.6034519378026504

Epoch: 5| Step: 4
Training loss: 0.8436938373099611
Validation loss: 2.6085534278860685

Epoch: 5| Step: 5
Training loss: 0.6339471088017055
Validation loss: 2.6304134927711846

Epoch: 5| Step: 6
Training loss: 0.5444894257386556
Validation loss: 2.5572932499205088

Epoch: 5| Step: 7
Training loss: 0.7867653144458684
Validation loss: 2.589677796845134

Epoch: 5| Step: 8
Training loss: 0.7867901251651764
Validation loss: 2.594084387883977

Epoch: 5| Step: 9
Training loss: 0.7098920072441707
Validation loss: 2.57451814315933

Epoch: 5| Step: 10
Training loss: 0.7915651273024941
Validation loss: 2.598894015921226

Epoch: 290| Step: 0
Training loss: 0.5922699601629013
Validation loss: 2.6314198208319084

Epoch: 5| Step: 1
Training loss: 0.4405330697332091
Validation loss: 2.6317228278305524

Epoch: 5| Step: 2
Training loss: 0.6046518044199636
Validation loss: 2.6375979938507252

Epoch: 5| Step: 3
Training loss: 0.6886515509970506
Validation loss: 2.647448293862757

Epoch: 5| Step: 4
Training loss: 0.6635150447956559
Validation loss: 2.6838434761160666

Epoch: 5| Step: 5
Training loss: 0.6724758123281099
Validation loss: 2.679038396427509

Epoch: 5| Step: 6
Training loss: 0.8832989593031583
Validation loss: 2.656992546590571

Epoch: 5| Step: 7
Training loss: 0.5219609800768867
Validation loss: 2.694443474947622

Epoch: 5| Step: 8
Training loss: 0.7607001120374549
Validation loss: 2.677062471721143

Epoch: 5| Step: 9
Training loss: 0.7790567510938248
Validation loss: 2.7114868458562915

Epoch: 5| Step: 10
Training loss: 0.7017055595005923
Validation loss: 2.700753181401342

Epoch: 291| Step: 0
Training loss: 0.4563197931705584
Validation loss: 2.6970166478782276

Epoch: 5| Step: 1
Training loss: 0.7401179320209382
Validation loss: 2.640175820209305

Epoch: 5| Step: 2
Training loss: 0.6219081697292035
Validation loss: 2.640270556686569

Epoch: 5| Step: 3
Training loss: 0.7856332648911538
Validation loss: 2.6155666655562175

Epoch: 5| Step: 4
Training loss: 0.668172883190462
Validation loss: 2.61107692733948

Epoch: 5| Step: 5
Training loss: 0.7273765433649582
Validation loss: 2.5828089510975647

Epoch: 5| Step: 6
Training loss: 0.5396469651877621
Validation loss: 2.6146697313752676

Epoch: 5| Step: 7
Training loss: 0.6623666089201861
Validation loss: 2.5793348290921334

Epoch: 5| Step: 8
Training loss: 0.663662711580365
Validation loss: 2.6179231489225434

Epoch: 5| Step: 9
Training loss: 0.6087868860259082
Validation loss: 2.613206518952565

Epoch: 5| Step: 10
Training loss: 0.7327579795223317
Validation loss: 2.632032532350235

Epoch: 292| Step: 0
Training loss: 0.8751401788958701
Validation loss: 2.6383756409031567

Epoch: 5| Step: 1
Training loss: 0.6650015978686418
Validation loss: 2.6566035364168603

Epoch: 5| Step: 2
Training loss: 0.7178473817274194
Validation loss: 2.668350678842979

Epoch: 5| Step: 3
Training loss: 0.861198640462969
Validation loss: 2.664285720385824

Epoch: 5| Step: 4
Training loss: 0.7626874974591609
Validation loss: 2.638924780621169

Epoch: 5| Step: 5
Training loss: 0.6713708716169527
Validation loss: 2.6317841510463302

Epoch: 5| Step: 6
Training loss: 0.6676946825089103
Validation loss: 2.6235193920027746

Epoch: 5| Step: 7
Training loss: 0.43343719886708815
Validation loss: 2.5966364227121286

Epoch: 5| Step: 8
Training loss: 0.2531921174111647
Validation loss: 2.6384847002945238

Epoch: 5| Step: 9
Training loss: 0.5893463412180908
Validation loss: 2.658220069913644

Epoch: 5| Step: 10
Training loss: 0.4362096832358473
Validation loss: 2.6308512558709665

Epoch: 293| Step: 0
Training loss: 0.769582795096641
Validation loss: 2.668185302198056

Epoch: 5| Step: 1
Training loss: 0.457294323188637
Validation loss: 2.677291090848636

Epoch: 5| Step: 2
Training loss: 0.7602796605328865
Validation loss: 2.643592184369754

Epoch: 5| Step: 3
Training loss: 0.756813137572399
Validation loss: 2.651716176509627

Epoch: 5| Step: 4
Training loss: 0.6437894077646132
Validation loss: 2.659273441847642

Epoch: 5| Step: 5
Training loss: 0.7394565330301895
Validation loss: 2.6094728220262944

Epoch: 5| Step: 6
Training loss: 0.6446132954482994
Validation loss: 2.6216872270389624

Epoch: 5| Step: 7
Training loss: 0.7209098540099467
Validation loss: 2.577972770067207

Epoch: 5| Step: 8
Training loss: 0.4319361714875461
Validation loss: 2.573472522483559

Epoch: 5| Step: 9
Training loss: 0.5250541715829853
Validation loss: 2.594967592512682

Epoch: 5| Step: 10
Training loss: 0.5921263076851537
Validation loss: 2.5653370954438293

Epoch: 294| Step: 0
Training loss: 0.8533093794674339
Validation loss: 2.5906585939368854

Epoch: 5| Step: 1
Training loss: 0.518146246277765
Validation loss: 2.614035266839079

Epoch: 5| Step: 2
Training loss: 0.8157388980307589
Validation loss: 2.5958172264370396

Epoch: 5| Step: 3
Training loss: 0.6827161550747982
Validation loss: 2.5913841210133852

Epoch: 5| Step: 4
Training loss: 0.6727048495255518
Validation loss: 2.659478463616947

Epoch: 5| Step: 5
Training loss: 0.6627492372860255
Validation loss: 2.640553997182509

Epoch: 5| Step: 6
Training loss: 0.5057680791413305
Validation loss: 2.688583755518116

Epoch: 5| Step: 7
Training loss: 0.39842863634011566
Validation loss: 2.698993254415011

Epoch: 5| Step: 8
Training loss: 0.3987948740998013
Validation loss: 2.682298014213458

Epoch: 5| Step: 9
Training loss: 0.6316488186429247
Validation loss: 2.7148047980819756

Epoch: 5| Step: 10
Training loss: 0.7470294218154683
Validation loss: 2.6681665479243617

Epoch: 295| Step: 0
Training loss: 0.7508153457124054
Validation loss: 2.680514549991487

Epoch: 5| Step: 1
Training loss: 0.7200884174655555
Validation loss: 2.688347311110263

Epoch: 5| Step: 2
Training loss: 0.6654877122594409
Validation loss: 2.6677343348756053

Epoch: 5| Step: 3
Training loss: 0.7086870394936604
Validation loss: 2.648450918136719

Epoch: 5| Step: 4
Training loss: 0.6608198994653679
Validation loss: 2.6442386283961374

Epoch: 5| Step: 5
Training loss: 0.8208725606836492
Validation loss: 2.623771011595223

Epoch: 5| Step: 6
Training loss: 0.3867307911549178
Validation loss: 2.5990168873355555

Epoch: 5| Step: 7
Training loss: 0.47746201344128275
Validation loss: 2.6578892465121218

Epoch: 5| Step: 8
Training loss: 0.6659186060430116
Validation loss: 2.6530875782984924

Epoch: 5| Step: 9
Training loss: 0.7076778511158381
Validation loss: 2.653694452274734

Epoch: 5| Step: 10
Training loss: 0.2261002445276778
Validation loss: 2.6534286581312614

Epoch: 296| Step: 0
Training loss: 0.4495122531222213
Validation loss: 2.693584212492966

Epoch: 5| Step: 1
Training loss: 1.038548564728556
Validation loss: 2.7470968458865705

Epoch: 5| Step: 2
Training loss: 0.5152694169651749
Validation loss: 2.6845723592039628

Epoch: 5| Step: 3
Training loss: 0.5973370266754774
Validation loss: 2.7017725986856234

Epoch: 5| Step: 4
Training loss: 0.5111589645907892
Validation loss: 2.7045110700266224

Epoch: 5| Step: 5
Training loss: 0.6474028686443973
Validation loss: 2.6859844815826466

Epoch: 5| Step: 6
Training loss: 0.5446986353004635
Validation loss: 2.6549575257426805

Epoch: 5| Step: 7
Training loss: 0.6916818446673305
Validation loss: 2.6042574483163374

Epoch: 5| Step: 8
Training loss: 0.6295403074217494
Validation loss: 2.6129597422988358

Epoch: 5| Step: 9
Training loss: 0.6259709683791695
Validation loss: 2.5715791047736825

Epoch: 5| Step: 10
Training loss: 0.679289361386811
Validation loss: 2.5744218797967235

Epoch: 297| Step: 0
Training loss: 0.4013608760291096
Validation loss: 2.6575626495814157

Epoch: 5| Step: 1
Training loss: 0.7330064805565312
Validation loss: 2.648701375286483

Epoch: 5| Step: 2
Training loss: 0.6503715168663364
Validation loss: 2.6493853674100833

Epoch: 5| Step: 3
Training loss: 0.8404046603019589
Validation loss: 2.682570888769703

Epoch: 5| Step: 4
Training loss: 0.657245924779215
Validation loss: 2.6701042516945392

Epoch: 5| Step: 5
Training loss: 0.5454421209054569
Validation loss: 2.668585230039665

Epoch: 5| Step: 6
Training loss: 0.5359837336936588
Validation loss: 2.6500712793182246

Epoch: 5| Step: 7
Training loss: 0.6538338916263081
Validation loss: 2.6891504443978103

Epoch: 5| Step: 8
Training loss: 0.35995680940675423
Validation loss: 2.6803364798536893

Epoch: 5| Step: 9
Training loss: 0.7585971348978695
Validation loss: 2.665117193049918

Epoch: 5| Step: 10
Training loss: 0.712746090803662
Validation loss: 2.6925972893247576

Epoch: 298| Step: 0
Training loss: 0.4122450184980884
Validation loss: 2.6757762219362538

Epoch: 5| Step: 1
Training loss: 0.8285513446163661
Validation loss: 2.659130669772295

Epoch: 5| Step: 2
Training loss: 0.68650381567576
Validation loss: 2.633502700185774

Epoch: 5| Step: 3
Training loss: 0.9088758048876505
Validation loss: 2.586662115364312

Epoch: 5| Step: 4
Training loss: 0.6072392327087089
Validation loss: 2.621488283841351

Epoch: 5| Step: 5
Training loss: 0.6977671254255905
Validation loss: 2.5824228320286267

Epoch: 5| Step: 6
Training loss: 0.25080522856353793
Validation loss: 2.6001007270785226

Epoch: 5| Step: 7
Training loss: 0.3831841552580932
Validation loss: 2.5756958177971723

Epoch: 5| Step: 8
Training loss: 0.7337149230527084
Validation loss: 2.6270288419517818

Epoch: 5| Step: 9
Training loss: 0.5704647279094502
Validation loss: 2.6222961219778145

Epoch: 5| Step: 10
Training loss: 0.5504096651269665
Validation loss: 2.686786469130179

Epoch: 299| Step: 0
Training loss: 0.7136617591946939
Validation loss: 2.6829005817321483

Epoch: 5| Step: 1
Training loss: 0.6503054588849578
Validation loss: 2.7250505641578506

Epoch: 5| Step: 2
Training loss: 0.7378740348182762
Validation loss: 2.7284325419593487

Epoch: 5| Step: 3
Training loss: 0.5967077819903004
Validation loss: 2.7005764334143953

Epoch: 5| Step: 4
Training loss: 0.5686605645171359
Validation loss: 2.6846733223456316

Epoch: 5| Step: 5
Training loss: 0.7482906173530751
Validation loss: 2.6470175297293874

Epoch: 5| Step: 6
Training loss: 0.36070790027203026
Validation loss: 2.640540655422162

Epoch: 5| Step: 7
Training loss: 0.6088053167851609
Validation loss: 2.687506956877007

Epoch: 5| Step: 8
Training loss: 0.28092871965174615
Validation loss: 2.6438987235894706

Epoch: 5| Step: 9
Training loss: 0.7598816456994381
Validation loss: 2.658594162366574

Epoch: 5| Step: 10
Training loss: 0.6053245372688051
Validation loss: 2.6403381712250864

Epoch: 300| Step: 0
Training loss: 0.6358857586030939
Validation loss: 2.6576324195273284

Epoch: 5| Step: 1
Training loss: 0.39563402587453866
Validation loss: 2.669281656687013

Epoch: 5| Step: 2
Training loss: 0.5377813124272323
Validation loss: 2.6506241560030888

Epoch: 5| Step: 3
Training loss: 0.6027795691861528
Validation loss: 2.6838148835902387

Epoch: 5| Step: 4
Training loss: 0.6861229456868885
Validation loss: 2.6963143784707766

Epoch: 5| Step: 5
Training loss: 0.31363646567494413
Validation loss: 2.7080674428235745

Epoch: 5| Step: 6
Training loss: 0.6626879659347241
Validation loss: 2.721774182488651

Epoch: 5| Step: 7
Training loss: 0.8767680629199854
Validation loss: 2.7331121713387185

Epoch: 5| Step: 8
Training loss: 0.9539535235813906
Validation loss: 2.778784647926108

Epoch: 5| Step: 9
Training loss: 0.4902256664703273
Validation loss: 2.7351992797719222

Epoch: 5| Step: 10
Training loss: 0.34884071028370167
Validation loss: 2.737239672845292

Epoch: 301| Step: 0
Training loss: 0.6463233770331883
Validation loss: 2.6911830900370086

Epoch: 5| Step: 1
Training loss: 0.60486141631358
Validation loss: 2.686921022745084

Epoch: 5| Step: 2
Training loss: 0.3879249910956306
Validation loss: 2.6316465737634887

Epoch: 5| Step: 3
Training loss: 0.8161124471925146
Validation loss: 2.6437509956475322

Epoch: 5| Step: 4
Training loss: 0.6668874454498912
Validation loss: 2.65525337357115

Epoch: 5| Step: 5
Training loss: 0.3133479653760948
Validation loss: 2.6530404299005137

Epoch: 5| Step: 6
Training loss: 0.4714646095867279
Validation loss: 2.6398618085148167

Epoch: 5| Step: 7
Training loss: 0.3979671357222828
Validation loss: 2.6472223008125573

Epoch: 5| Step: 8
Training loss: 0.6554510839398173
Validation loss: 2.6855601984105597

Epoch: 5| Step: 9
Training loss: 0.732439208779261
Validation loss: 2.6917266443061347

Epoch: 5| Step: 10
Training loss: 0.7554917340889935
Validation loss: 2.654876326764698

Epoch: 302| Step: 0
Training loss: 0.5887563167727202
Validation loss: 2.6524082494777907

Epoch: 5| Step: 1
Training loss: 0.6999937057212132
Validation loss: 2.610892909703095

Epoch: 5| Step: 2
Training loss: 0.3869739037519954
Validation loss: 2.6495735272233194

Epoch: 5| Step: 3
Training loss: 0.4703828980743042
Validation loss: 2.6430708743180658

Epoch: 5| Step: 4
Training loss: 0.7245770470330241
Validation loss: 2.6006058484802854

Epoch: 5| Step: 5
Training loss: 0.23733878185102655
Validation loss: 2.554696587721415

Epoch: 5| Step: 6
Training loss: 0.5759509164010245
Validation loss: 2.560148146813706

Epoch: 5| Step: 7
Training loss: 0.6862265106169536
Validation loss: 2.563918121732902

Epoch: 5| Step: 8
Training loss: 0.7252105111302486
Validation loss: 2.59121804885213

Epoch: 5| Step: 9
Training loss: 0.6275037445093418
Validation loss: 2.5975477345385727

Epoch: 5| Step: 10
Training loss: 0.7534845783804588
Validation loss: 2.611066197849999

Epoch: 303| Step: 0
Training loss: 0.6418592844063428
Validation loss: 2.6540524821453872

Epoch: 5| Step: 1
Training loss: 0.5536408018336316
Validation loss: 2.587496901079252

Epoch: 5| Step: 2
Training loss: 0.6965343155770121
Validation loss: 2.664797414881531

Epoch: 5| Step: 3
Training loss: 0.8318441834391495
Validation loss: 2.6338350906276142

Epoch: 5| Step: 4
Training loss: 0.5761736853619599
Validation loss: 2.648740064305811

Epoch: 5| Step: 5
Training loss: 0.2890323674760569
Validation loss: 2.6307597921318746

Epoch: 5| Step: 6
Training loss: 0.7108077884599429
Validation loss: 2.634009859611048

Epoch: 5| Step: 7
Training loss: 0.39604041889816183
Validation loss: 2.6035660245869923

Epoch: 5| Step: 8
Training loss: 0.7035425006280516
Validation loss: 2.6488071466461363

Epoch: 5| Step: 9
Training loss: 0.47338528801592444
Validation loss: 2.6687604454738896

Epoch: 5| Step: 10
Training loss: 0.6306240717689178
Validation loss: 2.659345734074213

Epoch: 304| Step: 0
Training loss: 0.8191269072556001
Validation loss: 2.6597951868337955

Epoch: 5| Step: 1
Training loss: 0.6024804975590204
Validation loss: 2.634254375011198

Epoch: 5| Step: 2
Training loss: 0.5139175233796172
Validation loss: 2.636516900397657

Epoch: 5| Step: 3
Training loss: 0.5946933129447968
Validation loss: 2.654304183542674

Epoch: 5| Step: 4
Training loss: 0.5308538249934799
Validation loss: 2.6500070276939187

Epoch: 5| Step: 5
Training loss: 0.5538709298347821
Validation loss: 2.6581185637336056

Epoch: 5| Step: 6
Training loss: 0.4319157478773671
Validation loss: 2.624001625164828

Epoch: 5| Step: 7
Training loss: 0.7315259412831736
Validation loss: 2.6380184002575655

Epoch: 5| Step: 8
Training loss: 0.6536531840565861
Validation loss: 2.656846079819084

Epoch: 5| Step: 9
Training loss: 0.6384821618769029
Validation loss: 2.626351388068074

Epoch: 5| Step: 10
Training loss: 0.3290052867395069
Validation loss: 2.6354975521177217

Epoch: 305| Step: 0
Training loss: 0.4652081031331804
Validation loss: 2.6533721177573804

Epoch: 5| Step: 1
Training loss: 0.4859567779445912
Validation loss: 2.6388433000922435

Epoch: 5| Step: 2
Training loss: 0.6349607197184146
Validation loss: 2.614352200148531

Epoch: 5| Step: 3
Training loss: 0.5555970967841731
Validation loss: 2.614288015976899

Epoch: 5| Step: 4
Training loss: 0.7101499785932175
Validation loss: 2.6637301183680138

Epoch: 5| Step: 5
Training loss: 0.6513984821356944
Validation loss: 2.652611924998409

Epoch: 5| Step: 6
Training loss: 0.5161987349431507
Validation loss: 2.6315263988384228

Epoch: 5| Step: 7
Training loss: 0.7831102729989651
Validation loss: 2.607342927038724

Epoch: 5| Step: 8
Training loss: 0.4241958640091632
Validation loss: 2.6018703054049106

Epoch: 5| Step: 9
Training loss: 0.6109884616445982
Validation loss: 2.642776318722662

Epoch: 5| Step: 10
Training loss: 0.6279080685324504
Validation loss: 2.6345187834258033

Epoch: 306| Step: 0
Training loss: 0.7940225974141512
Validation loss: 2.6180368107284

Epoch: 5| Step: 1
Training loss: 0.6542581347483455
Validation loss: 2.617410223294785

Epoch: 5| Step: 2
Training loss: 0.5662942709890154
Validation loss: 2.6238187777906683

Epoch: 5| Step: 3
Training loss: 0.6519749221220709
Validation loss: 2.6575213647671094

Epoch: 5| Step: 4
Training loss: 0.2624361539580422
Validation loss: 2.665711613210779

Epoch: 5| Step: 5
Training loss: 0.47618050195829253
Validation loss: 2.683351789928327

Epoch: 5| Step: 6
Training loss: 0.6413022392588973
Validation loss: 2.671858627191452

Epoch: 5| Step: 7
Training loss: 0.7030298380563085
Validation loss: 2.6853585321602305

Epoch: 5| Step: 8
Training loss: 0.5892249138954025
Validation loss: 2.6422170766756325

Epoch: 5| Step: 9
Training loss: 0.5209703233489289
Validation loss: 2.614890014196417

Epoch: 5| Step: 10
Training loss: 0.5362301375082921
Validation loss: 2.636476081914197

Epoch: 307| Step: 0
Training loss: 0.5465544442335075
Validation loss: 2.644578554949356

Epoch: 5| Step: 1
Training loss: 0.5526226456477024
Validation loss: 2.635882021889997

Epoch: 5| Step: 2
Training loss: 0.5265244795659254
Validation loss: 2.644972741590025

Epoch: 5| Step: 3
Training loss: 0.7108151676440194
Validation loss: 2.6590785756362028

Epoch: 5| Step: 4
Training loss: 0.6069965652120402
Validation loss: 2.6229528823321844

Epoch: 5| Step: 5
Training loss: 0.6947949444199264
Validation loss: 2.6804825879127194

Epoch: 5| Step: 6
Training loss: 0.4841162698137342
Validation loss: 2.6107093111633413

Epoch: 5| Step: 7
Training loss: 0.541190191536909
Validation loss: 2.6515617512391714

Epoch: 5| Step: 8
Training loss: 0.4322221041249918
Validation loss: 2.6519525827204307

Epoch: 5| Step: 9
Training loss: 0.6028704110860134
Validation loss: 2.633095180170419

Epoch: 5| Step: 10
Training loss: 0.7674222210294295
Validation loss: 2.635919951774937

Epoch: 308| Step: 0
Training loss: 0.4748392686447258
Validation loss: 2.582184448433388

Epoch: 5| Step: 1
Training loss: 0.6803382301634056
Validation loss: 2.582310806323477

Epoch: 5| Step: 2
Training loss: 0.628064605314568
Validation loss: 2.593359071557607

Epoch: 5| Step: 3
Training loss: 0.6114782569494387
Validation loss: 2.635536384384424

Epoch: 5| Step: 4
Training loss: 0.576577176576638
Validation loss: 2.6351781488535284

Epoch: 5| Step: 5
Training loss: 0.6101763908783935
Validation loss: 2.5978938523670587

Epoch: 5| Step: 6
Training loss: 0.4027961668753144
Validation loss: 2.6120477607125134

Epoch: 5| Step: 7
Training loss: 0.605609852746084
Validation loss: 2.582352156847417

Epoch: 5| Step: 8
Training loss: 0.753753369894766
Validation loss: 2.6065248374517953

Epoch: 5| Step: 9
Training loss: 0.6365340497377978
Validation loss: 2.5836295997664207

Epoch: 5| Step: 10
Training loss: 0.5682234978560615
Validation loss: 2.6325256808768507

Epoch: 309| Step: 0
Training loss: 0.39688925905219
Validation loss: 2.622017879011096

Epoch: 5| Step: 1
Training loss: 0.4583595243108808
Validation loss: 2.5679854829356987

Epoch: 5| Step: 2
Training loss: 0.7257039319462129
Validation loss: 2.6024078096552334

Epoch: 5| Step: 3
Training loss: 0.5977842156538415
Validation loss: 2.5987253615891808

Epoch: 5| Step: 4
Training loss: 0.492764331735008
Validation loss: 2.618672529026158

Epoch: 5| Step: 5
Training loss: 0.553491727303673
Validation loss: 2.638502095395203

Epoch: 5| Step: 6
Training loss: 0.5565004406470571
Validation loss: 2.6238090794288027

Epoch: 5| Step: 7
Training loss: 0.6927532716864507
Validation loss: 2.6366014675245877

Epoch: 5| Step: 8
Training loss: 0.820368011049594
Validation loss: 2.637679643087049

Epoch: 5| Step: 9
Training loss: 0.48297206686232935
Validation loss: 2.642182491489833

Epoch: 5| Step: 10
Training loss: 0.649146301597303
Validation loss: 2.6093751395111706

Epoch: 310| Step: 0
Training loss: 0.5998893357583174
Validation loss: 2.596316577385306

Epoch: 5| Step: 1
Training loss: 0.5014030321873268
Validation loss: 2.6128685353089325

Epoch: 5| Step: 2
Training loss: 0.5326129315845876
Validation loss: 2.587461302102635

Epoch: 5| Step: 3
Training loss: 0.5100337817653553
Validation loss: 2.5730673184694686

Epoch: 5| Step: 4
Training loss: 0.5129477034081859
Validation loss: 2.616191265814316

Epoch: 5| Step: 5
Training loss: 0.8163265937749196
Validation loss: 2.5461333555348804

Epoch: 5| Step: 6
Training loss: 0.6786728223897461
Validation loss: 2.622855688168498

Epoch: 5| Step: 7
Training loss: 0.5032334382619397
Validation loss: 2.6534518690938262

Epoch: 5| Step: 8
Training loss: 0.7872319658478518
Validation loss: 2.673842876907813

Epoch: 5| Step: 9
Training loss: 0.6278155565733341
Validation loss: 2.6528972557021024

Epoch: 5| Step: 10
Training loss: 0.6147189448681483
Validation loss: 2.665245093189696

Epoch: 311| Step: 0
Training loss: 0.7667403368868039
Validation loss: 2.6245755855022925

Epoch: 5| Step: 1
Training loss: 0.301329323942031
Validation loss: 2.6021147672709444

Epoch: 5| Step: 2
Training loss: 0.539947805575449
Validation loss: 2.6319716245046325

Epoch: 5| Step: 3
Training loss: 0.27252161040928125
Validation loss: 2.595894122155526

Epoch: 5| Step: 4
Training loss: 0.4886416669088013
Validation loss: 2.607690751098579

Epoch: 5| Step: 5
Training loss: 0.545800242864835
Validation loss: 2.5833921948441185

Epoch: 5| Step: 6
Training loss: 0.6897693589602322
Validation loss: 2.6071496751136363

Epoch: 5| Step: 7
Training loss: 0.6969280547743032
Validation loss: 2.566393646315671

Epoch: 5| Step: 8
Training loss: 0.6254056091229065
Validation loss: 2.576203752980197

Epoch: 5| Step: 9
Training loss: 0.7247282275179376
Validation loss: 2.579766244735464

Epoch: 5| Step: 10
Training loss: 0.7292842543112207
Validation loss: 2.6169254167468896

Epoch: 312| Step: 0
Training loss: 0.6046506461413612
Validation loss: 2.600899823786106

Epoch: 5| Step: 1
Training loss: 0.469855055018097
Validation loss: 2.6489660023897823

Epoch: 5| Step: 2
Training loss: 0.8488252726619737
Validation loss: 2.682396567794606

Epoch: 5| Step: 3
Training loss: 0.5431238680126479
Validation loss: 2.6842735270106735

Epoch: 5| Step: 4
Training loss: 0.6406200920475225
Validation loss: 2.737886612186737

Epoch: 5| Step: 5
Training loss: 0.7277040025778952
Validation loss: 2.713955533026057

Epoch: 5| Step: 6
Training loss: 0.3978020706068209
Validation loss: 2.662121337014374

Epoch: 5| Step: 7
Training loss: 0.6175402104262534
Validation loss: 2.6468893522226087

Epoch: 5| Step: 8
Training loss: 0.4110225067403662
Validation loss: 2.652081674532867

Epoch: 5| Step: 9
Training loss: 0.5592375026904364
Validation loss: 2.6329391398887965

Epoch: 5| Step: 10
Training loss: 0.4991633150129352
Validation loss: 2.5964150562902293

Epoch: 313| Step: 0
Training loss: 0.6293251585331793
Validation loss: 2.59585902942146

Epoch: 5| Step: 1
Training loss: 0.5419990607848246
Validation loss: 2.6200160260725247

Epoch: 5| Step: 2
Training loss: 0.6688935642692461
Validation loss: 2.5750791354931617

Epoch: 5| Step: 3
Training loss: 0.6744452262989451
Validation loss: 2.5792924034639215

Epoch: 5| Step: 4
Training loss: 0.6131981957439547
Validation loss: 2.6589845463860184

Epoch: 5| Step: 5
Training loss: 0.5759948975913233
Validation loss: 2.686954539282274

Epoch: 5| Step: 6
Training loss: 0.6183221985370488
Validation loss: 2.6900408238950977

Epoch: 5| Step: 7
Training loss: 0.5260218688965931
Validation loss: 2.710682206466561

Epoch: 5| Step: 8
Training loss: 0.5766868488229127
Validation loss: 2.685954774130279

Epoch: 5| Step: 9
Training loss: 0.4903157383244724
Validation loss: 2.6650912709914047

Epoch: 5| Step: 10
Training loss: 0.6447525338133848
Validation loss: 2.692482727949352

Epoch: 314| Step: 0
Training loss: 0.5800831084888258
Validation loss: 2.612160639823684

Epoch: 5| Step: 1
Training loss: 0.5664070392471603
Validation loss: 2.6467850994862685

Epoch: 5| Step: 2
Training loss: 0.8136340443373211
Validation loss: 2.545036697822598

Epoch: 5| Step: 3
Training loss: 0.538896673376788
Validation loss: 2.55234748891309

Epoch: 5| Step: 4
Training loss: 0.5013720046652712
Validation loss: 2.5706739059680412

Epoch: 5| Step: 5
Training loss: 0.5917818174555364
Validation loss: 2.577940790152721

Epoch: 5| Step: 6
Training loss: 0.7482257360264395
Validation loss: 2.6010352479941727

Epoch: 5| Step: 7
Training loss: 0.4113245356186687
Validation loss: 2.6452623711626853

Epoch: 5| Step: 8
Training loss: 0.575871897048821
Validation loss: 2.610304541811315

Epoch: 5| Step: 9
Training loss: 0.5232398955439841
Validation loss: 2.6767693781550204

Epoch: 5| Step: 10
Training loss: 0.6550407849419475
Validation loss: 2.685109253429239

Epoch: 315| Step: 0
Training loss: 0.7648232212760077
Validation loss: 2.7195861778996706

Epoch: 5| Step: 1
Training loss: 0.6556332278394484
Validation loss: 2.7376342643865867

Epoch: 5| Step: 2
Training loss: 0.8038262508169165
Validation loss: 2.6803215781305543

Epoch: 5| Step: 3
Training loss: 0.44534268193273785
Validation loss: 2.632182955014618

Epoch: 5| Step: 4
Training loss: 0.4426106419953367
Validation loss: 2.5881083343990974

Epoch: 5| Step: 5
Training loss: 0.36920439961458096
Validation loss: 2.594594060751743

Epoch: 5| Step: 6
Training loss: 0.4541747987818245
Validation loss: 2.6082427144899127

Epoch: 5| Step: 7
Training loss: 0.64989672629023
Validation loss: 2.5726954150083428

Epoch: 5| Step: 8
Training loss: 0.48589109217574084
Validation loss: 2.5359022830578617

Epoch: 5| Step: 9
Training loss: 0.48608389240840727
Validation loss: 2.5702932240930036

Epoch: 5| Step: 10
Training loss: 0.7478091108577716
Validation loss: 2.5969835889416855

Epoch: 316| Step: 0
Training loss: 0.4027112190108986
Validation loss: 2.61653670262614

Epoch: 5| Step: 1
Training loss: 0.5510355585501281
Validation loss: 2.6421669272808166

Epoch: 5| Step: 2
Training loss: 0.5938420224404768
Validation loss: 2.674921794841097

Epoch: 5| Step: 3
Training loss: 0.4613521456622142
Validation loss: 2.653847072106631

Epoch: 5| Step: 4
Training loss: 0.6372750081602286
Validation loss: 2.652549792555347

Epoch: 5| Step: 5
Training loss: 0.559418529543007
Validation loss: 2.6290404929057205

Epoch: 5| Step: 6
Training loss: 0.4712193614197567
Validation loss: 2.6279151870893847

Epoch: 5| Step: 7
Training loss: 0.6182555120479257
Validation loss: 2.6279467125032405

Epoch: 5| Step: 8
Training loss: 0.6743588776026784
Validation loss: 2.593158803300656

Epoch: 5| Step: 9
Training loss: 0.7500338149395025
Validation loss: 2.578132791964184

Epoch: 5| Step: 10
Training loss: 0.5854510004240769
Validation loss: 2.5927465291410687

Epoch: 317| Step: 0
Training loss: 0.5528642751148124
Validation loss: 2.615260473627474

Epoch: 5| Step: 1
Training loss: 0.4449329431779786
Validation loss: 2.6164702734116396

Epoch: 5| Step: 2
Training loss: 0.508810119778907
Validation loss: 2.637412127102279

Epoch: 5| Step: 3
Training loss: 0.5512868846395383
Validation loss: 2.6584096893424394

Epoch: 5| Step: 4
Training loss: 0.6756352393673923
Validation loss: 2.6304307061226098

Epoch: 5| Step: 5
Training loss: 0.7271195603957911
Validation loss: 2.606395966693725

Epoch: 5| Step: 6
Training loss: 0.5250904970282277
Validation loss: 2.607056742640401

Epoch: 5| Step: 7
Training loss: 0.5873327301201264
Validation loss: 2.58413899138101

Epoch: 5| Step: 8
Training loss: 0.38346458871004413
Validation loss: 2.61472782732107

Epoch: 5| Step: 9
Training loss: 0.7674262986225087
Validation loss: 2.6161560254446607

Epoch: 5| Step: 10
Training loss: 0.5155006316502102
Validation loss: 2.6225426814005237

Epoch: 318| Step: 0
Training loss: 0.7079385657812263
Validation loss: 2.666860874920657

Epoch: 5| Step: 1
Training loss: 0.4295958334506741
Validation loss: 2.625079214812089

Epoch: 5| Step: 2
Training loss: 0.6770976920928405
Validation loss: 2.655485412079857

Epoch: 5| Step: 3
Training loss: 0.5634769327304622
Validation loss: 2.691902081037855

Epoch: 5| Step: 4
Training loss: 0.3653383973848482
Validation loss: 2.6844829920138236

Epoch: 5| Step: 5
Training loss: 0.6454399177060502
Validation loss: 2.690285858751978

Epoch: 5| Step: 6
Training loss: 0.45065899386072233
Validation loss: 2.6448502584700635

Epoch: 5| Step: 7
Training loss: 0.5872965500993825
Validation loss: 2.6208141077415945

Epoch: 5| Step: 8
Training loss: 0.7189625135632028
Validation loss: 2.6116925109880373

Epoch: 5| Step: 9
Training loss: 0.5382564156925534
Validation loss: 2.6527052523681447

Epoch: 5| Step: 10
Training loss: 0.6701330847370779
Validation loss: 2.606522981497257

Epoch: 319| Step: 0
Training loss: 0.5281912598436044
Validation loss: 2.591789593956718

Epoch: 5| Step: 1
Training loss: 0.5866127192644236
Validation loss: 2.624532030878356

Epoch: 5| Step: 2
Training loss: 0.6126995608201032
Validation loss: 2.6108171313083353

Epoch: 5| Step: 3
Training loss: 0.6717501235950443
Validation loss: 2.6285219019880803

Epoch: 5| Step: 4
Training loss: 0.6655657862799668
Validation loss: 2.6989006404829445

Epoch: 5| Step: 5
Training loss: 0.3684025606667497
Validation loss: 2.670160648990827

Epoch: 5| Step: 6
Training loss: 0.5966578852639536
Validation loss: 2.6975285861536262

Epoch: 5| Step: 7
Training loss: 0.44709743019211007
Validation loss: 2.694406438371364

Epoch: 5| Step: 8
Training loss: 0.6011938724372432
Validation loss: 2.709566012504312

Epoch: 5| Step: 9
Training loss: 0.5914025834447366
Validation loss: 2.7411294906161547

Epoch: 5| Step: 10
Training loss: 0.5040375294563529
Validation loss: 2.738487548228482

Epoch: 320| Step: 0
Training loss: 0.7595286649476748
Validation loss: 2.7172479569165184

Epoch: 5| Step: 1
Training loss: 0.539053184318213
Validation loss: 2.7035920612561855

Epoch: 5| Step: 2
Training loss: 0.5174317926800994
Validation loss: 2.6204005024662007

Epoch: 5| Step: 3
Training loss: 0.5156261848667287
Validation loss: 2.5897615142175687

Epoch: 5| Step: 4
Training loss: 0.5944022059907962
Validation loss: 2.5674680716284937

Epoch: 5| Step: 5
Training loss: 0.6248268841362905
Validation loss: 2.5710326765874965

Epoch: 5| Step: 6
Training loss: 0.5041014123359938
Validation loss: 2.5798131452962605

Epoch: 5| Step: 7
Training loss: 0.6569400293118071
Validation loss: 2.6232107210244826

Epoch: 5| Step: 8
Training loss: 0.42883151363869354
Validation loss: 2.6356921060355822

Epoch: 5| Step: 9
Training loss: 0.6806280490537222
Validation loss: 2.606238965536174

Epoch: 5| Step: 10
Training loss: 0.46336105842908415
Validation loss: 2.6453365401808187

Epoch: 321| Step: 0
Training loss: 0.6617085416652695
Validation loss: 2.679522886194623

Epoch: 5| Step: 1
Training loss: 0.34242321935829745
Validation loss: 2.6838558623270012

Epoch: 5| Step: 2
Training loss: 0.518724058260939
Validation loss: 2.6482789775055857

Epoch: 5| Step: 3
Training loss: 0.4722575878787783
Validation loss: 2.602885445390308

Epoch: 5| Step: 4
Training loss: 0.3753718678117954
Validation loss: 2.5298049936462212

Epoch: 5| Step: 5
Training loss: 0.6003468603639657
Validation loss: 2.5200379907778716

Epoch: 5| Step: 6
Training loss: 0.7202250644799141
Validation loss: 2.528400807752204

Epoch: 5| Step: 7
Training loss: 0.902783373464865
Validation loss: 2.50354208077012

Epoch: 5| Step: 8
Training loss: 0.6566773567160612
Validation loss: 2.5078262672714726

Epoch: 5| Step: 9
Training loss: 0.5591560681225046
Validation loss: 2.54041927666015

Epoch: 5| Step: 10
Training loss: 0.30893057536862034
Validation loss: 2.5988721278175726

Epoch: 322| Step: 0
Training loss: 0.5687577205175867
Validation loss: 2.6166034936447513

Epoch: 5| Step: 1
Training loss: 0.44538311649370954
Validation loss: 2.6190608595921048

Epoch: 5| Step: 2
Training loss: 0.5108995651021507
Validation loss: 2.6327407587115994

Epoch: 5| Step: 3
Training loss: 0.39380484456375464
Validation loss: 2.6446339785455026

Epoch: 5| Step: 4
Training loss: 0.7555270388502773
Validation loss: 2.658234446483907

Epoch: 5| Step: 5
Training loss: 0.681537303362616
Validation loss: 2.6396710548328612

Epoch: 5| Step: 6
Training loss: 0.5146230152083513
Validation loss: 2.639707338503781

Epoch: 5| Step: 7
Training loss: 0.22176239386579055
Validation loss: 2.605491310800868

Epoch: 5| Step: 8
Training loss: 0.5576016612655516
Validation loss: 2.5918007464769857

Epoch: 5| Step: 9
Training loss: 0.6081885500847772
Validation loss: 2.5790790203491785

Epoch: 5| Step: 10
Training loss: 0.5371408349273757
Validation loss: 2.561724132389368

Epoch: 323| Step: 0
Training loss: 0.6044104895285507
Validation loss: 2.592701361546408

Epoch: 5| Step: 1
Training loss: 0.46560252794660145
Validation loss: 2.5523856301460994

Epoch: 5| Step: 2
Training loss: 0.3135538570383075
Validation loss: 2.559825744327028

Epoch: 5| Step: 3
Training loss: 0.5522812242742664
Validation loss: 2.5728458512536254

Epoch: 5| Step: 4
Training loss: 0.6056678936691676
Validation loss: 2.5944550998016274

Epoch: 5| Step: 5
Training loss: 0.5549255182790297
Validation loss: 2.5776769383573312

Epoch: 5| Step: 6
Training loss: 0.5050483004444826
Validation loss: 2.5922041396982465

Epoch: 5| Step: 7
Training loss: 0.621586873769064
Validation loss: 2.592443454140911

Epoch: 5| Step: 8
Training loss: 0.5635389164583104
Validation loss: 2.601260462011458

Epoch: 5| Step: 9
Training loss: 0.4037982427338222
Validation loss: 2.604315138163269

Epoch: 5| Step: 10
Training loss: 0.6957789153293972
Validation loss: 2.617719355934098

Epoch: 324| Step: 0
Training loss: 0.46058382593032743
Validation loss: 2.6316788600975376

Epoch: 5| Step: 1
Training loss: 0.5508501537321052
Validation loss: 2.641717859250081

Epoch: 5| Step: 2
Training loss: 0.6055483119742321
Validation loss: 2.654822016983883

Epoch: 5| Step: 3
Training loss: 0.41962999357491454
Validation loss: 2.634659429073087

Epoch: 5| Step: 4
Training loss: 0.8275449628801923
Validation loss: 2.651264623151126

Epoch: 5| Step: 5
Training loss: 0.31646693789721486
Validation loss: 2.6852360213657733

Epoch: 5| Step: 6
Training loss: 0.5546965799797372
Validation loss: 2.683128758833757

Epoch: 5| Step: 7
Training loss: 0.22214306702284126
Validation loss: 2.7182595453344804

Epoch: 5| Step: 8
Training loss: 0.49042741234911336
Validation loss: 2.6612900751660065

Epoch: 5| Step: 9
Training loss: 0.6363175186949985
Validation loss: 2.6859729470172704

Epoch: 5| Step: 10
Training loss: 0.5776883099847546
Validation loss: 2.68237590583842

Epoch: 325| Step: 0
Training loss: 0.5061805324223274
Validation loss: 2.641330871002425

Epoch: 5| Step: 1
Training loss: 0.4293876815711116
Validation loss: 2.6347191849988754

Epoch: 5| Step: 2
Training loss: 0.49225667437111087
Validation loss: 2.6673753326156184

Epoch: 5| Step: 3
Training loss: 0.5369148595754758
Validation loss: 2.6118248284664136

Epoch: 5| Step: 4
Training loss: 0.42036556490343696
Validation loss: 2.6308892816716707

Epoch: 5| Step: 5
Training loss: 0.567760505962047
Validation loss: 2.653134981919757

Epoch: 5| Step: 6
Training loss: 0.536131422808849
Validation loss: 2.635699395649619

Epoch: 5| Step: 7
Training loss: 0.7039673316187042
Validation loss: 2.6340825938512893

Epoch: 5| Step: 8
Training loss: 0.4709972238418338
Validation loss: 2.6159392542708355

Epoch: 5| Step: 9
Training loss: 0.49024856972376335
Validation loss: 2.574768530540082

Epoch: 5| Step: 10
Training loss: 0.6259875363535101
Validation loss: 2.6412898597559153

Epoch: 326| Step: 0
Training loss: 0.3589229435706568
Validation loss: 2.6081651104658845

Epoch: 5| Step: 1
Training loss: 0.36312425974443785
Validation loss: 2.5472294102660444

Epoch: 5| Step: 2
Training loss: 0.4217552792253205
Validation loss: 2.6101568930914376

Epoch: 5| Step: 3
Training loss: 0.4258315380392035
Validation loss: 2.57624549408814

Epoch: 5| Step: 4
Training loss: 0.5991109957539645
Validation loss: 2.5814177158522598

Epoch: 5| Step: 5
Training loss: 0.7179473458670423
Validation loss: 2.6088204676693434

Epoch: 5| Step: 6
Training loss: 0.4368892562024556
Validation loss: 2.590178840125466

Epoch: 5| Step: 7
Training loss: 0.530685292964592
Validation loss: 2.5542482905025836

Epoch: 5| Step: 8
Training loss: 0.4076832285061792
Validation loss: 2.5665550092049587

Epoch: 5| Step: 9
Training loss: 0.6699131111483749
Validation loss: 2.5882016144261097

Epoch: 5| Step: 10
Training loss: 0.6275414294362361
Validation loss: 2.5431134184504316

Epoch: 327| Step: 0
Training loss: 0.42430508053044214
Validation loss: 2.579133800872573

Epoch: 5| Step: 1
Training loss: 0.4140518115121595
Validation loss: 2.6082924320248755

Epoch: 5| Step: 2
Training loss: 0.5828980002187841
Validation loss: 2.566760746065746

Epoch: 5| Step: 3
Training loss: 0.704837958942725
Validation loss: 2.5854149039323806

Epoch: 5| Step: 4
Training loss: 0.2709832540683672
Validation loss: 2.6252465051793865

Epoch: 5| Step: 5
Training loss: 0.5173735016171863
Validation loss: 2.6473460744664905

Epoch: 5| Step: 6
Training loss: 0.513673557525316
Validation loss: 2.6404167574236053

Epoch: 5| Step: 7
Training loss: 0.5739342380411461
Validation loss: 2.6565325485988294

Epoch: 5| Step: 8
Training loss: 0.4368468074679308
Validation loss: 2.613940039006558

Epoch: 5| Step: 9
Training loss: 0.6080087849835621
Validation loss: 2.636911661678637

Epoch: 5| Step: 10
Training loss: 0.5472922776761787
Validation loss: 2.6490930390937173

Epoch: 328| Step: 0
Training loss: 0.41672820193166915
Validation loss: 2.6162176753245605

Epoch: 5| Step: 1
Training loss: 0.47686153160364264
Validation loss: 2.613719208261345

Epoch: 5| Step: 2
Training loss: 0.5945823256500338
Validation loss: 2.6308510385679607

Epoch: 5| Step: 3
Training loss: 0.6207189088594685
Validation loss: 2.5743291022884396

Epoch: 5| Step: 4
Training loss: 0.5731250701787775
Validation loss: 2.5990431971455843

Epoch: 5| Step: 5
Training loss: 0.4189364736909515
Validation loss: 2.61402536741733

Epoch: 5| Step: 6
Training loss: 0.5449403875891125
Validation loss: 2.611104255527051

Epoch: 5| Step: 7
Training loss: 0.36480258979034946
Validation loss: 2.606713918558141

Epoch: 5| Step: 8
Training loss: 0.5223423332996195
Validation loss: 2.6065019915134817

Epoch: 5| Step: 9
Training loss: 0.42684827321554397
Validation loss: 2.6718376688138425

Epoch: 5| Step: 10
Training loss: 0.5641935867195913
Validation loss: 2.65535084455312

Epoch: 329| Step: 0
Training loss: 0.519014861959844
Validation loss: 2.6521938618165466

Epoch: 5| Step: 1
Training loss: 0.31516752184113533
Validation loss: 2.6494217086657526

Epoch: 5| Step: 2
Training loss: 0.5945595191921748
Validation loss: 2.6532640094402353

Epoch: 5| Step: 3
Training loss: 0.6158690554574091
Validation loss: 2.643659894808905

Epoch: 5| Step: 4
Training loss: 0.4191809571726582
Validation loss: 2.596206457597532

Epoch: 5| Step: 5
Training loss: 0.6032722500927835
Validation loss: 2.5888309676520773

Epoch: 5| Step: 6
Training loss: 0.6229950934151057
Validation loss: 2.587625433780666

Epoch: 5| Step: 7
Training loss: 0.26207319143490554
Validation loss: 2.6249529533545535

Epoch: 5| Step: 8
Training loss: 0.46048344053115564
Validation loss: 2.5683919967475544

Epoch: 5| Step: 9
Training loss: 0.46503745779299727
Validation loss: 2.6220239859415218

Epoch: 5| Step: 10
Training loss: 0.536394621636624
Validation loss: 2.6112047519516914

Epoch: 330| Step: 0
Training loss: 0.34242278419006644
Validation loss: 2.608084088351239

Epoch: 5| Step: 1
Training loss: 0.1317313238389406
Validation loss: 2.6161533752320807

Epoch: 5| Step: 2
Training loss: 0.4329077990997186
Validation loss: 2.647356534417264

Epoch: 5| Step: 3
Training loss: 0.5946894291151372
Validation loss: 2.6632960995614403

Epoch: 5| Step: 4
Training loss: 0.4255474568617421
Validation loss: 2.6609931190676352

Epoch: 5| Step: 5
Training loss: 0.32632358243747317
Validation loss: 2.663019890649864

Epoch: 5| Step: 6
Training loss: 0.6851158852251907
Validation loss: 2.6216056097390474

Epoch: 5| Step: 7
Training loss: 0.45921165845028417
Validation loss: 2.651708879202957

Epoch: 5| Step: 8
Training loss: 0.5733560842151133
Validation loss: 2.606912196502359

Epoch: 5| Step: 9
Training loss: 0.7584508193535773
Validation loss: 2.614625614146168

Epoch: 5| Step: 10
Training loss: 0.4701299382736227
Validation loss: 2.6230352532792374

Epoch: 331| Step: 0
Training loss: 0.6501634218113294
Validation loss: 2.6236340161723817

Epoch: 5| Step: 1
Training loss: 0.7455064948942051
Validation loss: 2.5938755049019515

Epoch: 5| Step: 2
Training loss: 0.41537205520972775
Validation loss: 2.622193890960762

Epoch: 5| Step: 3
Training loss: 0.3841701101050857
Validation loss: 2.6542432874202184

Epoch: 5| Step: 4
Training loss: 0.485922985534763
Validation loss: 2.6369774174787386

Epoch: 5| Step: 5
Training loss: 0.5590954108490469
Validation loss: 2.6863553508738014

Epoch: 5| Step: 6
Training loss: 0.24092711611833048
Validation loss: 2.688446843488583

Epoch: 5| Step: 7
Training loss: 0.614665613216289
Validation loss: 2.702755927680023

Epoch: 5| Step: 8
Training loss: 0.45839881068028787
Validation loss: 2.679664435924649

Epoch: 5| Step: 9
Training loss: 0.32699307980345604
Validation loss: 2.656829394391423

Epoch: 5| Step: 10
Training loss: 0.5339256952019658
Validation loss: 2.672194034815279

Epoch: 332| Step: 0
Training loss: 0.32044743975272655
Validation loss: 2.662061231718307

Epoch: 5| Step: 1
Training loss: 0.5524551171416495
Validation loss: 2.612649928746037

Epoch: 5| Step: 2
Training loss: 0.45951291758194895
Validation loss: 2.58998161318577

Epoch: 5| Step: 3
Training loss: 0.407990030400635
Validation loss: 2.602069569187944

Epoch: 5| Step: 4
Training loss: 0.4792056033305986
Validation loss: 2.574419071604876

Epoch: 5| Step: 5
Training loss: 0.5870317541043613
Validation loss: 2.6118171252387095

Epoch: 5| Step: 6
Training loss: 0.4250476361673767
Validation loss: 2.592430844777652

Epoch: 5| Step: 7
Training loss: 0.5304013373753644
Validation loss: 2.6457460379513607

Epoch: 5| Step: 8
Training loss: 0.6461625695622218
Validation loss: 2.6502404096742227

Epoch: 5| Step: 9
Training loss: 0.5409456614072026
Validation loss: 2.671106936810603

Epoch: 5| Step: 10
Training loss: 0.5516330274062223
Validation loss: 2.684764818084421

Epoch: 333| Step: 0
Training loss: 0.5309583761097496
Validation loss: 2.6909417209138207

Epoch: 5| Step: 1
Training loss: 0.41711104260311527
Validation loss: 2.6619261019181826

Epoch: 5| Step: 2
Training loss: 0.5862167710116766
Validation loss: 2.6527120830511492

Epoch: 5| Step: 3
Training loss: 0.5983757724250954
Validation loss: 2.6313793249191386

Epoch: 5| Step: 4
Training loss: 0.49026437492830055
Validation loss: 2.6299543900022444

Epoch: 5| Step: 5
Training loss: 0.49702766700179896
Validation loss: 2.6147995858420487

Epoch: 5| Step: 6
Training loss: 0.5423347559001501
Validation loss: 2.6048345087639078

Epoch: 5| Step: 7
Training loss: 0.2951030048671106
Validation loss: 2.568709702237173

Epoch: 5| Step: 8
Training loss: 0.42531136298886024
Validation loss: 2.5737611523037653

Epoch: 5| Step: 9
Training loss: 0.4052033329273518
Validation loss: 2.6175373194402

Epoch: 5| Step: 10
Training loss: 0.5836723029648625
Validation loss: 2.6114885999079105

Epoch: 334| Step: 0
Training loss: 0.3738600570768785
Validation loss: 2.598387047269672

Epoch: 5| Step: 1
Training loss: 0.3787239855465707
Validation loss: 2.6473277410067904

Epoch: 5| Step: 2
Training loss: 0.5604162828333036
Validation loss: 2.6329881097039918

Epoch: 5| Step: 3
Training loss: 0.42432227092241315
Validation loss: 2.601687926597429

Epoch: 5| Step: 4
Training loss: 0.2384542712541569
Validation loss: 2.6130705717748794

Epoch: 5| Step: 5
Training loss: 0.5472525519498432
Validation loss: 2.6030244221348156

Epoch: 5| Step: 6
Training loss: 0.5655832823232539
Validation loss: 2.6431387474799664

Epoch: 5| Step: 7
Training loss: 0.5439350394301026
Validation loss: 2.636351901003286

Epoch: 5| Step: 8
Training loss: 0.4617764548244858
Validation loss: 2.6263247056244885

Epoch: 5| Step: 9
Training loss: 0.5637239808804664
Validation loss: 2.6225888643871453

Epoch: 5| Step: 10
Training loss: 0.6237866544942788
Validation loss: 2.6262540463541364

Epoch: 335| Step: 0
Training loss: 0.535081482279523
Validation loss: 2.6393560222138794

Epoch: 5| Step: 1
Training loss: 0.5733363839371423
Validation loss: 2.659023775136284

Epoch: 5| Step: 2
Training loss: 0.5995943148333911
Validation loss: 2.658198327457732

Epoch: 5| Step: 3
Training loss: 0.15703231350932412
Validation loss: 2.6633953620455397

Epoch: 5| Step: 4
Training loss: 0.4037357804360193
Validation loss: 2.668742655859522

Epoch: 5| Step: 5
Training loss: 0.4609262174098331
Validation loss: 2.6786257134096783

Epoch: 5| Step: 6
Training loss: 0.595697972009603
Validation loss: 2.6737731363691277

Epoch: 5| Step: 7
Training loss: 0.45338011827464214
Validation loss: 2.666235851153014

Epoch: 5| Step: 8
Training loss: 0.3722096179888887
Validation loss: 2.6408844284166646

Epoch: 5| Step: 9
Training loss: 0.517875729776946
Validation loss: 2.671549123471891

Epoch: 5| Step: 10
Training loss: 0.5481058166522377
Validation loss: 2.6333041034751754

Epoch: 336| Step: 0
Training loss: 0.4789534764861493
Validation loss: 2.629688385935561

Epoch: 5| Step: 1
Training loss: 0.5897934999598023
Validation loss: 2.6061624507895513

Epoch: 5| Step: 2
Training loss: 0.5628660388583084
Validation loss: 2.5988439434929913

Epoch: 5| Step: 3
Training loss: 0.44971922486183213
Validation loss: 2.5799726985529987

Epoch: 5| Step: 4
Training loss: 0.4861660729475366
Validation loss: 2.5511243992931485

Epoch: 5| Step: 5
Training loss: 0.47785818908183025
Validation loss: 2.584442513511242

Epoch: 5| Step: 6
Training loss: 0.40933344826686335
Validation loss: 2.5818592560517772

Epoch: 5| Step: 7
Training loss: 0.29559689759202756
Validation loss: 2.589600444295605

Epoch: 5| Step: 8
Training loss: 0.39696214575184885
Validation loss: 2.579480776471495

Epoch: 5| Step: 9
Training loss: 0.5408106666991472
Validation loss: 2.5782357767269843

Epoch: 5| Step: 10
Training loss: 0.6157792358055751
Validation loss: 2.6385262003864827

Epoch: 337| Step: 0
Training loss: 0.5711011789571904
Validation loss: 2.658972381769292

Epoch: 5| Step: 1
Training loss: 0.39791418752180935
Validation loss: 2.616742480514578

Epoch: 5| Step: 2
Training loss: 0.3241000820060351
Validation loss: 2.633773540187197

Epoch: 5| Step: 3
Training loss: 0.5672114995077212
Validation loss: 2.639208537094435

Epoch: 5| Step: 4
Training loss: 0.580291195151231
Validation loss: 2.5991893240435098

Epoch: 5| Step: 5
Training loss: 0.5312456803987702
Validation loss: 2.6364889191636998

Epoch: 5| Step: 6
Training loss: 0.39869322704478166
Validation loss: 2.6108490202843293

Epoch: 5| Step: 7
Training loss: 0.5987383452298541
Validation loss: 2.634531536795814

Epoch: 5| Step: 8
Training loss: 0.33706699162367076
Validation loss: 2.6651835140102573

Epoch: 5| Step: 9
Training loss: 0.5267012178529703
Validation loss: 2.63391942023113

Epoch: 5| Step: 10
Training loss: 0.33507252383203406
Validation loss: 2.617499635413156

Epoch: 338| Step: 0
Training loss: 0.45570013407918075
Validation loss: 2.598622442029803

Epoch: 5| Step: 1
Training loss: 0.5204537025367602
Validation loss: 2.6191419405201044

Epoch: 5| Step: 2
Training loss: 0.549894146052833
Validation loss: 2.5941914482845325

Epoch: 5| Step: 3
Training loss: 0.5082227956731271
Validation loss: 2.608169681080859

Epoch: 5| Step: 4
Training loss: 0.5270221153211817
Validation loss: 2.6525439810949663

Epoch: 5| Step: 5
Training loss: 0.3232519027310255
Validation loss: 2.636955582993914

Epoch: 5| Step: 6
Training loss: 0.4398143894024329
Validation loss: 2.643135212108857

Epoch: 5| Step: 7
Training loss: 0.46018900147545017
Validation loss: 2.6353035271492566

Epoch: 5| Step: 8
Training loss: 0.58172427793423
Validation loss: 2.6140940682785123

Epoch: 5| Step: 9
Training loss: 0.4064101490389568
Validation loss: 2.5989703007707208

Epoch: 5| Step: 10
Training loss: 0.42678356311196675
Validation loss: 2.6060319421486717

Epoch: 339| Step: 0
Training loss: 0.41563428495547855
Validation loss: 2.6151022506227046

Epoch: 5| Step: 1
Training loss: 0.5324705072303771
Validation loss: 2.5828704090901

Epoch: 5| Step: 2
Training loss: 0.5206412310777779
Validation loss: 2.5645893582041315

Epoch: 5| Step: 3
Training loss: 0.5014662106503704
Validation loss: 2.5558315812486754

Epoch: 5| Step: 4
Training loss: 0.4033912245363313
Validation loss: 2.5406876121898145

Epoch: 5| Step: 5
Training loss: 0.2996751834856412
Validation loss: 2.5415653445259485

Epoch: 5| Step: 6
Training loss: 0.17162981751995302
Validation loss: 2.557138827932191

Epoch: 5| Step: 7
Training loss: 0.45128555847249896
Validation loss: 2.61048838388879

Epoch: 5| Step: 8
Training loss: 0.6905988084133219
Validation loss: 2.5990333668776926

Epoch: 5| Step: 9
Training loss: 0.31026013649942835
Validation loss: 2.5913389603403054

Epoch: 5| Step: 10
Training loss: 0.7350016010682191
Validation loss: 2.6147548928277486

Epoch: 340| Step: 0
Training loss: 0.661817210505001
Validation loss: 2.625199302064852

Epoch: 5| Step: 1
Training loss: 0.4989280236209304
Validation loss: 2.6480962497328155

Epoch: 5| Step: 2
Training loss: 0.6031036946382924
Validation loss: 2.5837470413723613

Epoch: 5| Step: 3
Training loss: 0.2517036267218212
Validation loss: 2.5749449925053383

Epoch: 5| Step: 4
Training loss: 0.40610514405761
Validation loss: 2.569476802688323

Epoch: 5| Step: 5
Training loss: 0.3945536465472578
Validation loss: 2.5613831297865217

Epoch: 5| Step: 6
Training loss: 0.5400830435477167
Validation loss: 2.558462033313542

Epoch: 5| Step: 7
Training loss: 0.4327621389347039
Validation loss: 2.5301242524332683

Epoch: 5| Step: 8
Training loss: 0.5850620596319317
Validation loss: 2.545944483759004

Epoch: 5| Step: 9
Training loss: 0.46008661905856724
Validation loss: 2.567470056664128

Epoch: 5| Step: 10
Training loss: 0.3238944304426399
Validation loss: 2.5783063037373792

Epoch: 341| Step: 0
Training loss: 0.47713928026491476
Validation loss: 2.572130322634329

Epoch: 5| Step: 1
Training loss: 0.5199673478713849
Validation loss: 2.5582571672946988

Epoch: 5| Step: 2
Training loss: 0.5742599576320068
Validation loss: 2.6001997952174927

Epoch: 5| Step: 3
Training loss: 0.4338465975787695
Validation loss: 2.6038387428468295

Epoch: 5| Step: 4
Training loss: 0.480676621540771
Validation loss: 2.605131538728999

Epoch: 5| Step: 5
Training loss: 0.5383103416786698
Validation loss: 2.5887428648364357

Epoch: 5| Step: 6
Training loss: 0.4832812388753412
Validation loss: 2.5868353320277193

Epoch: 5| Step: 7
Training loss: 0.5480838493985452
Validation loss: 2.6420956059171528

Epoch: 5| Step: 8
Training loss: 0.46156194383384963
Validation loss: 2.6184455787642906

Epoch: 5| Step: 9
Training loss: 0.30910085708150076
Validation loss: 2.61820052476247

Epoch: 5| Step: 10
Training loss: 0.2264882163241472
Validation loss: 2.62943660818845

Epoch: 342| Step: 0
Training loss: 0.440048154016573
Validation loss: 2.6226356482151854

Epoch: 5| Step: 1
Training loss: 0.3914143026593356
Validation loss: 2.6131069098769943

Epoch: 5| Step: 2
Training loss: 0.5214694588917497
Validation loss: 2.6098462360201915

Epoch: 5| Step: 3
Training loss: 0.2858864045480784
Validation loss: 2.62908646960306

Epoch: 5| Step: 4
Training loss: 0.419107045786565
Validation loss: 2.5821123965998924

Epoch: 5| Step: 5
Training loss: 0.2795881473171347
Validation loss: 2.569444316437938

Epoch: 5| Step: 6
Training loss: 0.48134110504911637
Validation loss: 2.599567332525308

Epoch: 5| Step: 7
Training loss: 0.3897407632691203
Validation loss: 2.6094548443638366

Epoch: 5| Step: 8
Training loss: 0.6718013190743436
Validation loss: 2.6107910177214424

Epoch: 5| Step: 9
Training loss: 0.4908914607828611
Validation loss: 2.605697245703202

Epoch: 5| Step: 10
Training loss: 0.6320452807629069
Validation loss: 2.6154867720385875

Epoch: 343| Step: 0
Training loss: 0.3428988974306253
Validation loss: 2.6304692240817538

Epoch: 5| Step: 1
Training loss: 0.3714962232366939
Validation loss: 2.6440103422916454

Epoch: 5| Step: 2
Training loss: 0.45850711114583403
Validation loss: 2.650000770485151

Epoch: 5| Step: 3
Training loss: 0.5730287846763258
Validation loss: 2.6338417454060186

Epoch: 5| Step: 4
Training loss: 0.29708869671539034
Validation loss: 2.6560414135255273

Epoch: 5| Step: 5
Training loss: 0.4992023602632362
Validation loss: 2.641145250448646

Epoch: 5| Step: 6
Training loss: 0.43488010979589264
Validation loss: 2.6262314540408918

Epoch: 5| Step: 7
Training loss: 0.5253608439914261
Validation loss: 2.6330366326794663

Epoch: 5| Step: 8
Training loss: 0.33949358208479274
Validation loss: 2.6375394909092202

Epoch: 5| Step: 9
Training loss: 0.6525938045920183
Validation loss: 2.6271260398090828

Epoch: 5| Step: 10
Training loss: 0.4591929509670243
Validation loss: 2.5998165518675886

Epoch: 344| Step: 0
Training loss: 0.441776407376508
Validation loss: 2.6136108702642344

Epoch: 5| Step: 1
Training loss: 0.4722138375662995
Validation loss: 2.5943728431905364

Epoch: 5| Step: 2
Training loss: 0.5515506591822676
Validation loss: 2.541363508588606

Epoch: 5| Step: 3
Training loss: 0.5038870282905787
Validation loss: 2.5796489170559274

Epoch: 5| Step: 4
Training loss: 0.5623651183854883
Validation loss: 2.5971328552247743

Epoch: 5| Step: 5
Training loss: 0.30408175482949623
Validation loss: 2.6116790109911436

Epoch: 5| Step: 6
Training loss: 0.581154950891979
Validation loss: 2.665215282499821

Epoch: 5| Step: 7
Training loss: 0.2894831380586568
Validation loss: 2.639107988959108

Epoch: 5| Step: 8
Training loss: 0.4457396416244165
Validation loss: 2.680239235530091

Epoch: 5| Step: 9
Training loss: 0.4631748534022748
Validation loss: 2.638407381410449

Epoch: 5| Step: 10
Training loss: 0.4187328448980607
Validation loss: 2.7190144954420328

Epoch: 345| Step: 0
Training loss: 0.3200756453347518
Validation loss: 2.6685255042643368

Epoch: 5| Step: 1
Training loss: 0.4558632099477355
Validation loss: 2.679027080757462

Epoch: 5| Step: 2
Training loss: 0.27027385799299714
Validation loss: 2.6557510409216025

Epoch: 5| Step: 3
Training loss: 0.4546338970665721
Validation loss: 2.611794745702123

Epoch: 5| Step: 4
Training loss: 0.4499587887860787
Validation loss: 2.6235457912614035

Epoch: 5| Step: 5
Training loss: 0.5033218484425082
Validation loss: 2.5996290607270534

Epoch: 5| Step: 6
Training loss: 0.47217069859785615
Validation loss: 2.5820367495424077

Epoch: 5| Step: 7
Training loss: 0.6289904283377498
Validation loss: 2.633053680159179

Epoch: 5| Step: 8
Training loss: 0.49655314823800867
Validation loss: 2.631105914862314

Epoch: 5| Step: 9
Training loss: 0.553679315649703
Validation loss: 2.64479313534902

Epoch: 5| Step: 10
Training loss: 0.45707025932048934
Validation loss: 2.640149231357666

Epoch: 346| Step: 0
Training loss: 0.284557458486456
Validation loss: 2.6381778317841595

Epoch: 5| Step: 1
Training loss: 0.40565660127289993
Validation loss: 2.648197640546936

Epoch: 5| Step: 2
Training loss: 0.4191058369302207
Validation loss: 2.650916956648481

Epoch: 5| Step: 3
Training loss: 0.2630563545161768
Validation loss: 2.640989540190744

Epoch: 5| Step: 4
Training loss: 0.5857915315008122
Validation loss: 2.650455975788393

Epoch: 5| Step: 5
Training loss: 0.29842901067992306
Validation loss: 2.6504425194399825

Epoch: 5| Step: 6
Training loss: 0.648447013693269
Validation loss: 2.625243512103113

Epoch: 5| Step: 7
Training loss: 0.603343803365848
Validation loss: 2.5875457718407042

Epoch: 5| Step: 8
Training loss: 0.331109000282783
Validation loss: 2.646838537807854

Epoch: 5| Step: 9
Training loss: 0.5189214009614789
Validation loss: 2.6411372163256424

Epoch: 5| Step: 10
Training loss: 0.49822387542031105
Validation loss: 2.6536266346296262

Epoch: 347| Step: 0
Training loss: 0.4820952912361195
Validation loss: 2.6221284693480773

Epoch: 5| Step: 1
Training loss: 0.3858217374646517
Validation loss: 2.608456479505683

Epoch: 5| Step: 2
Training loss: 0.3339522719988332
Validation loss: 2.6085285663189213

Epoch: 5| Step: 3
Training loss: 0.3787544772383946
Validation loss: 2.637543704447374

Epoch: 5| Step: 4
Training loss: 0.4268941421461638
Validation loss: 2.6395704747831084

Epoch: 5| Step: 5
Training loss: 0.4449311179255146
Validation loss: 2.5813929643672586

Epoch: 5| Step: 6
Training loss: 0.4611603796093454
Validation loss: 2.6300224729938053

Epoch: 5| Step: 7
Training loss: 0.5968591947609946
Validation loss: 2.6008920320175055

Epoch: 5| Step: 8
Training loss: 0.4473292376329094
Validation loss: 2.618405229034368

Epoch: 5| Step: 9
Training loss: 0.5007104892102853
Validation loss: 2.608682710210462

Epoch: 5| Step: 10
Training loss: 0.49579585886103333
Validation loss: 2.6062043632658196

Epoch: 348| Step: 0
Training loss: 0.29827771577894435
Validation loss: 2.6038115195656952

Epoch: 5| Step: 1
Training loss: 0.5170310241846288
Validation loss: 2.6279692764133276

Epoch: 5| Step: 2
Training loss: 0.4226043366088726
Validation loss: 2.651894628465725

Epoch: 5| Step: 3
Training loss: 0.49520020099371587
Validation loss: 2.659524359459456

Epoch: 5| Step: 4
Training loss: 0.46614436108518287
Validation loss: 2.6520238197665167

Epoch: 5| Step: 5
Training loss: 0.4565581620080129
Validation loss: 2.6418673248285494

Epoch: 5| Step: 6
Training loss: 0.45268680497036745
Validation loss: 2.6487126095139537

Epoch: 5| Step: 7
Training loss: 0.3738880759133212
Validation loss: 2.6397279585947224

Epoch: 5| Step: 8
Training loss: 0.43148883895319273
Validation loss: 2.6374675467440034

Epoch: 5| Step: 9
Training loss: 0.40946433424823103
Validation loss: 2.603961890916627

Epoch: 5| Step: 10
Training loss: 0.604187082625332
Validation loss: 2.5756834857573043

Epoch: 349| Step: 0
Training loss: 0.4426381971863685
Validation loss: 2.5817157736999516

Epoch: 5| Step: 1
Training loss: 0.4716906496910514
Validation loss: 2.57999068018521

Epoch: 5| Step: 2
Training loss: 0.36711608922792915
Validation loss: 2.5817922861018303

Epoch: 5| Step: 3
Training loss: 0.5071419029399561
Validation loss: 2.5807504033540583

Epoch: 5| Step: 4
Training loss: 0.44937167674442074
Validation loss: 2.609833927826527

Epoch: 5| Step: 5
Training loss: 0.5775182994403788
Validation loss: 2.6198648970012024

Epoch: 5| Step: 6
Training loss: 0.5034529547092144
Validation loss: 2.6357395526042255

Epoch: 5| Step: 7
Training loss: 0.25816178503083875
Validation loss: 2.655014287268513

Epoch: 5| Step: 8
Training loss: 0.4561488771072076
Validation loss: 2.662339830893514

Epoch: 5| Step: 9
Training loss: 0.5303143227343011
Validation loss: 2.6457394993538776

Epoch: 5| Step: 10
Training loss: 0.4135689222769064
Validation loss: 2.626651366563374

Epoch: 350| Step: 0
Training loss: 0.430789124891095
Validation loss: 2.6278651666923754

Epoch: 5| Step: 1
Training loss: 0.5403287638240208
Validation loss: 2.6050186768429655

Epoch: 5| Step: 2
Training loss: 0.5969971656604238
Validation loss: 2.5958371967097373

Epoch: 5| Step: 3
Training loss: 0.5404801455793755
Validation loss: 2.574545028942178

Epoch: 5| Step: 4
Training loss: 0.4282842785332591
Validation loss: 2.5876676782040575

Epoch: 5| Step: 5
Training loss: 0.3828454100806601
Validation loss: 2.610549005380126

Epoch: 5| Step: 6
Training loss: 0.45151777342943156
Validation loss: 2.5930883376845877

Epoch: 5| Step: 7
Training loss: 0.39334850731907456
Validation loss: 2.5908379118515468

Epoch: 5| Step: 8
Training loss: 0.38654103675164014
Validation loss: 2.611186699815692

Epoch: 5| Step: 9
Training loss: 0.3619109942599003
Validation loss: 2.6399999797379166

Epoch: 5| Step: 10
Training loss: 0.43070841796545484
Validation loss: 2.6366840489396903

Epoch: 351| Step: 0
Training loss: 0.6005171821750129
Validation loss: 2.6162980202914925

Epoch: 5| Step: 1
Training loss: 0.37166844088867895
Validation loss: 2.6732567207680646

Epoch: 5| Step: 2
Training loss: 0.31688647855099206
Validation loss: 2.568161219075516

Epoch: 5| Step: 3
Training loss: 0.4126650061178513
Validation loss: 2.5872532409089164

Epoch: 5| Step: 4
Training loss: 0.34964742400195403
Validation loss: 2.5669123241047096

Epoch: 5| Step: 5
Training loss: 0.33104610150661373
Validation loss: 2.5870910476712434

Epoch: 5| Step: 6
Training loss: 0.6080204017284282
Validation loss: 2.581713144237821

Epoch: 5| Step: 7
Training loss: 0.47975664168586474
Validation loss: 2.5988937239363796

Epoch: 5| Step: 8
Training loss: 0.4496727349440004
Validation loss: 2.570572346581491

Epoch: 5| Step: 9
Training loss: 0.5219206967020326
Validation loss: 2.5915676278018727

Epoch: 5| Step: 10
Training loss: 0.40135554832790293
Validation loss: 2.543122813661205

Epoch: 352| Step: 0
Training loss: 0.44451218347941246
Validation loss: 2.5637071373877927

Epoch: 5| Step: 1
Training loss: 0.5435394471389918
Validation loss: 2.6170031347157146

Epoch: 5| Step: 2
Training loss: 0.5909779740245532
Validation loss: 2.6255603901147087

Epoch: 5| Step: 3
Training loss: 0.3723390064585668
Validation loss: 2.579396713498876

Epoch: 5| Step: 4
Training loss: 0.39215007618625286
Validation loss: 2.618351790043261

Epoch: 5| Step: 5
Training loss: 0.4257142950487273
Validation loss: 2.615811253312351

Epoch: 5| Step: 6
Training loss: 0.39800429635867957
Validation loss: 2.6235565654753317

Epoch: 5| Step: 7
Training loss: 0.2892721292377182
Validation loss: 2.647597708028692

Epoch: 5| Step: 8
Training loss: 0.5658703077124689
Validation loss: 2.6042148188579453

Epoch: 5| Step: 9
Training loss: 0.3300618162019852
Validation loss: 2.6293911606978626

Epoch: 5| Step: 10
Training loss: 0.37935383896359026
Validation loss: 2.6736210038779356

Epoch: 353| Step: 0
Training loss: 0.49741082060704894
Validation loss: 2.601018695385799

Epoch: 5| Step: 1
Training loss: 0.43091892304742946
Validation loss: 2.6366745709691157

Epoch: 5| Step: 2
Training loss: 0.35006379584910485
Validation loss: 2.590634057407554

Epoch: 5| Step: 3
Training loss: 0.4103326327402893
Validation loss: 2.5587338259322467

Epoch: 5| Step: 4
Training loss: 0.4715775720855908
Validation loss: 2.5794628456988744

Epoch: 5| Step: 5
Training loss: 0.40282709292072477
Validation loss: 2.579631656777127

Epoch: 5| Step: 6
Training loss: 0.4635046094019141
Validation loss: 2.5949253108340575

Epoch: 5| Step: 7
Training loss: 0.2874540997228588
Validation loss: 2.585183835100829

Epoch: 5| Step: 8
Training loss: 0.5506334850597113
Validation loss: 2.613718334332661

Epoch: 5| Step: 9
Training loss: 0.4973259439016363
Validation loss: 2.6479328204756647

Epoch: 5| Step: 10
Training loss: 0.46524777204952733
Validation loss: 2.636844705955696

Epoch: 354| Step: 0
Training loss: 0.30776823664721703
Validation loss: 2.622284754048131

Epoch: 5| Step: 1
Training loss: 0.3237732158533381
Validation loss: 2.6426755988143498

Epoch: 5| Step: 2
Training loss: 0.5556270540111495
Validation loss: 2.6262867279427864

Epoch: 5| Step: 3
Training loss: 0.4171043441706285
Validation loss: 2.64135560434771

Epoch: 5| Step: 4
Training loss: 0.6503867301022406
Validation loss: 2.601563947586612

Epoch: 5| Step: 5
Training loss: 0.31307408529920344
Validation loss: 2.6414085857074587

Epoch: 5| Step: 6
Training loss: 0.44771495054753196
Validation loss: 2.6195807294478484

Epoch: 5| Step: 7
Training loss: 0.3942283373984934
Validation loss: 2.5876649438297976

Epoch: 5| Step: 8
Training loss: 0.5668891426770033
Validation loss: 2.614548294688266

Epoch: 5| Step: 9
Training loss: 0.49558574468140315
Validation loss: 2.5876901415736615

Epoch: 5| Step: 10
Training loss: 0.38290087010769674
Validation loss: 2.611779312544188

Epoch: 355| Step: 0
Training loss: 0.43619209019959154
Validation loss: 2.606077914555667

Epoch: 5| Step: 1
Training loss: 0.5391319893539361
Validation loss: 2.59348816185679

Epoch: 5| Step: 2
Training loss: 0.38067467930620486
Validation loss: 2.6199878681214783

Epoch: 5| Step: 3
Training loss: 0.5840565563489339
Validation loss: 2.640559691342194

Epoch: 5| Step: 4
Training loss: 0.374350800440582
Validation loss: 2.639941771829359

Epoch: 5| Step: 5
Training loss: 0.42470452892753074
Validation loss: 2.6592089045050216

Epoch: 5| Step: 6
Training loss: 0.6167268361773708
Validation loss: 2.6472934404786894

Epoch: 5| Step: 7
Training loss: 0.4681218070518482
Validation loss: 2.6948813653737003

Epoch: 5| Step: 8
Training loss: 0.40892773065641214
Validation loss: 2.6847424729751403

Epoch: 5| Step: 9
Training loss: 0.39983750261298473
Validation loss: 2.6322027487271487

Epoch: 5| Step: 10
Training loss: 0.3258667392305563
Validation loss: 2.633186486849887

Epoch: 356| Step: 0
Training loss: 0.4312293911584431
Validation loss: 2.6017121337223634

Epoch: 5| Step: 1
Training loss: 0.5352873815554674
Validation loss: 2.6350305532106235

Epoch: 5| Step: 2
Training loss: 0.4664160320080466
Validation loss: 2.643891418766016

Epoch: 5| Step: 3
Training loss: 0.5421831224248318
Validation loss: 2.6235161839314416

Epoch: 5| Step: 4
Training loss: 0.4097280174140073
Validation loss: 2.6390831043799032

Epoch: 5| Step: 5
Training loss: 0.4779315419973694
Validation loss: 2.6273999842751046

Epoch: 5| Step: 6
Training loss: 0.48998983903003174
Validation loss: 2.599766603706975

Epoch: 5| Step: 7
Training loss: 0.32837961173113656
Validation loss: 2.5888002403939616

Epoch: 5| Step: 8
Training loss: 0.5382294783589169
Validation loss: 2.569747713641224

Epoch: 5| Step: 9
Training loss: 0.46205835326769634
Validation loss: 2.562457026019489

Epoch: 5| Step: 10
Training loss: 0.4032305231895219
Validation loss: 2.594641210531204

Epoch: 357| Step: 0
Training loss: 0.49663316131499374
Validation loss: 2.5480404800537246

Epoch: 5| Step: 1
Training loss: 0.46698318338747896
Validation loss: 2.517049409726909

Epoch: 5| Step: 2
Training loss: 0.5296767444700161
Validation loss: 2.509930749786119

Epoch: 5| Step: 3
Training loss: 0.4807624694458817
Validation loss: 2.5291478239070693

Epoch: 5| Step: 4
Training loss: 0.20058057976599655
Validation loss: 2.5773264951322647

Epoch: 5| Step: 5
Training loss: 0.4773595741758274
Validation loss: 2.568265547485664

Epoch: 5| Step: 6
Training loss: 0.35737209286062716
Validation loss: 2.5515066801671145

Epoch: 5| Step: 7
Training loss: 0.33225520939470893
Validation loss: 2.5911689079956925

Epoch: 5| Step: 8
Training loss: 0.41760396636567326
Validation loss: 2.6051931065533784

Epoch: 5| Step: 9
Training loss: 0.5668686130588665
Validation loss: 2.6194275796880255

Epoch: 5| Step: 10
Training loss: 0.34448431434895543
Validation loss: 2.6386413540877753

Epoch: 358| Step: 0
Training loss: 0.4816975580800957
Validation loss: 2.63429163542757

Epoch: 5| Step: 1
Training loss: 0.37125616033176057
Validation loss: 2.6418658750660557

Epoch: 5| Step: 2
Training loss: 0.4049868754038134
Validation loss: 2.6446255866574857

Epoch: 5| Step: 3
Training loss: 0.5239942635666276
Validation loss: 2.6233147232648104

Epoch: 5| Step: 4
Training loss: 0.47692828914329793
Validation loss: 2.614523475418377

Epoch: 5| Step: 5
Training loss: 0.5961253686521018
Validation loss: 2.607560152304194

Epoch: 5| Step: 6
Training loss: 0.3621951037736869
Validation loss: 2.5925914713759797

Epoch: 5| Step: 7
Training loss: 0.3435583230455714
Validation loss: 2.5857103455765182

Epoch: 5| Step: 8
Training loss: 0.40287247888200545
Validation loss: 2.6138797138937337

Epoch: 5| Step: 9
Training loss: 0.3430530244697004
Validation loss: 2.5839662963987786

Epoch: 5| Step: 10
Training loss: 0.3457252150552362
Validation loss: 2.599388048728102

Epoch: 359| Step: 0
Training loss: 0.5698214990964448
Validation loss: 2.630099521767288

Epoch: 5| Step: 1
Training loss: 0.4900745420052824
Validation loss: 2.6208133183463076

Epoch: 5| Step: 2
Training loss: 0.4166922640885026
Validation loss: 2.5991970074895936

Epoch: 5| Step: 3
Training loss: 0.46481108350334055
Validation loss: 2.594820452301517

Epoch: 5| Step: 4
Training loss: 0.3739995724706195
Validation loss: 2.6186478790515406

Epoch: 5| Step: 5
Training loss: 0.2680020281088654
Validation loss: 2.607174131926157

Epoch: 5| Step: 6
Training loss: 0.4315839531750355
Validation loss: 2.6112481317442917

Epoch: 5| Step: 7
Training loss: 0.3443085727214931
Validation loss: 2.65160220358992

Epoch: 5| Step: 8
Training loss: 0.36766573017055276
Validation loss: 2.6141287926542844

Epoch: 5| Step: 9
Training loss: 0.4757208035661599
Validation loss: 2.6429982766120856

Epoch: 5| Step: 10
Training loss: 0.2775256540923902
Validation loss: 2.623280762546487

Epoch: 360| Step: 0
Training loss: 0.3115891055548231
Validation loss: 2.646871986091551

Epoch: 5| Step: 1
Training loss: 0.49871486671533094
Validation loss: 2.640481197749498

Epoch: 5| Step: 2
Training loss: 0.3701874356801925
Validation loss: 2.633719101865375

Epoch: 5| Step: 3
Training loss: 0.4735252966221144
Validation loss: 2.6258828904610207

Epoch: 5| Step: 4
Training loss: 0.3380172800818758
Validation loss: 2.584992323290586

Epoch: 5| Step: 5
Training loss: 0.5804448622130567
Validation loss: 2.6497625792538186

Epoch: 5| Step: 6
Training loss: 0.3136384967607651
Validation loss: 2.6451031665108578

Epoch: 5| Step: 7
Training loss: 0.22870023720303215
Validation loss: 2.6102279360601677

Epoch: 5| Step: 8
Training loss: 0.45339786600823107
Validation loss: 2.62361552483325

Epoch: 5| Step: 9
Training loss: 0.3698013890918062
Validation loss: 2.5847977464704477

Epoch: 5| Step: 10
Training loss: 0.44732917101011327
Validation loss: 2.6504915750063387

Epoch: 361| Step: 0
Training loss: 0.4800921724404407
Validation loss: 2.6259598586072808

Epoch: 5| Step: 1
Training loss: 0.4348364197431528
Validation loss: 2.6024653528457806

Epoch: 5| Step: 2
Training loss: 0.4930923560860358
Validation loss: 2.608368581571491

Epoch: 5| Step: 3
Training loss: 0.32644373591289844
Validation loss: 2.625495334579237

Epoch: 5| Step: 4
Training loss: 0.3691166057542927
Validation loss: 2.591303786131465

Epoch: 5| Step: 5
Training loss: 0.31230783514615923
Validation loss: 2.6040544032027926

Epoch: 5| Step: 6
Training loss: 0.29428606781586125
Validation loss: 2.5885215730931876

Epoch: 5| Step: 7
Training loss: 0.41913271538345204
Validation loss: 2.6182885420507964

Epoch: 5| Step: 8
Training loss: 0.5111505105231093
Validation loss: 2.578547305226357

Epoch: 5| Step: 9
Training loss: 0.3844097641211405
Validation loss: 2.627372316246995

Epoch: 5| Step: 10
Training loss: 0.4363826891763388
Validation loss: 2.613578526501689

Epoch: 362| Step: 0
Training loss: 0.25371491485602693
Validation loss: 2.6569988239985722

Epoch: 5| Step: 1
Training loss: 0.4106239195741232
Validation loss: 2.6658984495413

Epoch: 5| Step: 2
Training loss: 0.3223576269893302
Validation loss: 2.681059157032707

Epoch: 5| Step: 3
Training loss: 0.3660905970894752
Validation loss: 2.6636869186061904

Epoch: 5| Step: 4
Training loss: 0.5298610650453205
Validation loss: 2.6246933442991724

Epoch: 5| Step: 5
Training loss: 0.6439446293946133
Validation loss: 2.6531426647091063

Epoch: 5| Step: 6
Training loss: 0.24166868383015175
Validation loss: 2.666738812626851

Epoch: 5| Step: 7
Training loss: 0.44707379954300147
Validation loss: 2.6623837053674166

Epoch: 5| Step: 8
Training loss: 0.21122735912275634
Validation loss: 2.5929631891700065

Epoch: 5| Step: 9
Training loss: 0.3859590138296175
Validation loss: 2.598598755136626

Epoch: 5| Step: 10
Training loss: 0.5372801353200296
Validation loss: 2.5850731751282794

Epoch: 363| Step: 0
Training loss: 0.22315659271297253
Validation loss: 2.5973227710690203

Epoch: 5| Step: 1
Training loss: 0.4223606352089261
Validation loss: 2.6168540687093946

Epoch: 5| Step: 2
Training loss: 0.3401638365194352
Validation loss: 2.617296542114

Epoch: 5| Step: 3
Training loss: 0.5532995239618412
Validation loss: 2.617593909103172

Epoch: 5| Step: 4
Training loss: 0.2297923215437129
Validation loss: 2.599146641544497

Epoch: 5| Step: 5
Training loss: 0.5233525733944254
Validation loss: 2.5962587576980156

Epoch: 5| Step: 6
Training loss: 0.4217723085668605
Validation loss: 2.626583024407826

Epoch: 5| Step: 7
Training loss: 0.4801166764153344
Validation loss: 2.6052135550349904

Epoch: 5| Step: 8
Training loss: 0.31047583913172894
Validation loss: 2.6094043281296715

Epoch: 5| Step: 9
Training loss: 0.35106749123612174
Validation loss: 2.5942360207288475

Epoch: 5| Step: 10
Training loss: 0.36122061702332564
Validation loss: 2.609844855894422

Epoch: 364| Step: 0
Training loss: 0.403270173362248
Validation loss: 2.5924315068424435

Epoch: 5| Step: 1
Training loss: 0.3707920454200302
Validation loss: 2.5910706066668485

Epoch: 5| Step: 2
Training loss: 0.17093376339519314
Validation loss: 2.558328956040968

Epoch: 5| Step: 3
Training loss: 0.2178439979683145
Validation loss: 2.5537545851881522

Epoch: 5| Step: 4
Training loss: 0.4459387575117103
Validation loss: 2.5798278832805717

Epoch: 5| Step: 5
Training loss: 0.5956514930236954
Validation loss: 2.597371269419562

Epoch: 5| Step: 6
Training loss: 0.3354207877780643
Validation loss: 2.564009381230743

Epoch: 5| Step: 7
Training loss: 0.4823013649357435
Validation loss: 2.5600505109435727

Epoch: 5| Step: 8
Training loss: 0.43548458663236156
Validation loss: 2.613342241280316

Epoch: 5| Step: 9
Training loss: 0.4353681976165901
Validation loss: 2.5972524421142684

Epoch: 5| Step: 10
Training loss: 0.38180288186371975
Validation loss: 2.6475014834952892

Epoch: 365| Step: 0
Training loss: 0.4696651109243707
Validation loss: 2.5984468717381835

Epoch: 5| Step: 1
Training loss: 0.427068444511971
Validation loss: 2.623945949446587

Epoch: 5| Step: 2
Training loss: 0.37411744851069345
Validation loss: 2.5970238411022613

Epoch: 5| Step: 3
Training loss: 0.28540189169953173
Validation loss: 2.629969625850904

Epoch: 5| Step: 4
Training loss: 0.4231980206127335
Validation loss: 2.634479914751215

Epoch: 5| Step: 5
Training loss: 0.29397755189429214
Validation loss: 2.6552332322503007

Epoch: 5| Step: 6
Training loss: 0.5229246559393974
Validation loss: 2.635778062282499

Epoch: 5| Step: 7
Training loss: 0.30589569626409135
Validation loss: 2.648788716835241

Epoch: 5| Step: 8
Training loss: 0.505111081965048
Validation loss: 2.6275337109218406

Epoch: 5| Step: 9
Training loss: 0.4500511915176515
Validation loss: 2.620169263740661

Epoch: 5| Step: 10
Training loss: 0.3432819582967001
Validation loss: 2.5723476955720326

Epoch: 366| Step: 0
Training loss: 0.3804463421060558
Validation loss: 2.5758448193071417

Epoch: 5| Step: 1
Training loss: 0.28476688505084946
Validation loss: 2.600242480147657

Epoch: 5| Step: 2
Training loss: 0.2785765689551997
Validation loss: 2.6381825923670097

Epoch: 5| Step: 3
Training loss: 0.2869937170716649
Validation loss: 2.6123150370203736

Epoch: 5| Step: 4
Training loss: 0.457363904216339
Validation loss: 2.665456705164423

Epoch: 5| Step: 5
Training loss: 0.5595768633553884
Validation loss: 2.629872966883015

Epoch: 5| Step: 6
Training loss: 0.3182463064848416
Validation loss: 2.636177884637021

Epoch: 5| Step: 7
Training loss: 0.43399726718050974
Validation loss: 2.5868750008150134

Epoch: 5| Step: 8
Training loss: 0.44507462020546695
Validation loss: 2.587664535654841

Epoch: 5| Step: 9
Training loss: 0.5157780853516462
Validation loss: 2.583284139082079

Epoch: 5| Step: 10
Training loss: 0.3818957581942018
Validation loss: 2.5935492340877895

Epoch: 367| Step: 0
Training loss: 0.4133429483031143
Validation loss: 2.568154895218859

Epoch: 5| Step: 1
Training loss: 0.3838021467856499
Validation loss: 2.5568117345034858

Epoch: 5| Step: 2
Training loss: 0.5201053172528604
Validation loss: 2.583202925085489

Epoch: 5| Step: 3
Training loss: 0.38462660548458055
Validation loss: 2.587935718059154

Epoch: 5| Step: 4
Training loss: 0.4985980107272724
Validation loss: 2.6039250363055766

Epoch: 5| Step: 5
Training loss: 0.41826164820971307
Validation loss: 2.6071431031419743

Epoch: 5| Step: 6
Training loss: 0.4363428548787156
Validation loss: 2.624853543182012

Epoch: 5| Step: 7
Training loss: 0.3526633933665975
Validation loss: 2.610017760816747

Epoch: 5| Step: 8
Training loss: 0.2777085658447101
Validation loss: 2.610110031940421

Epoch: 5| Step: 9
Training loss: 0.3655413393342165
Validation loss: 2.570191881072724

Epoch: 5| Step: 10
Training loss: 0.34102035597832797
Validation loss: 2.609359874783437

Epoch: 368| Step: 0
Training loss: 0.3952145843467304
Validation loss: 2.603743366580784

Epoch: 5| Step: 1
Training loss: 0.46592987819299236
Validation loss: 2.5963322604424452

Epoch: 5| Step: 2
Training loss: 0.5908253819271796
Validation loss: 2.6238600799434417

Epoch: 5| Step: 3
Training loss: 0.4292220282108306
Validation loss: 2.6460323933883267

Epoch: 5| Step: 4
Training loss: 0.2823917209255921
Validation loss: 2.6465245542960107

Epoch: 5| Step: 5
Training loss: 0.3004293984736757
Validation loss: 2.6410617999853794

Epoch: 5| Step: 6
Training loss: 0.30498251937191473
Validation loss: 2.6445553174850924

Epoch: 5| Step: 7
Training loss: 0.43596770821097497
Validation loss: 2.6699969562459245

Epoch: 5| Step: 8
Training loss: 0.3836518641811
Validation loss: 2.642709554755329

Epoch: 5| Step: 9
Training loss: 0.18146668586456993
Validation loss: 2.6790202229118427

Epoch: 5| Step: 10
Training loss: 0.3802737110138915
Validation loss: 2.651560203325059

Epoch: 369| Step: 0
Training loss: 0.36696027258639985
Validation loss: 2.6390042564923126

Epoch: 5| Step: 1
Training loss: 0.5019937342978416
Validation loss: 2.666240775095345

Epoch: 5| Step: 2
Training loss: 0.42646278291749856
Validation loss: 2.653347434588553

Epoch: 5| Step: 3
Training loss: 0.4920631584658263
Validation loss: 2.6398673958871326

Epoch: 5| Step: 4
Training loss: 0.31265162127574847
Validation loss: 2.6207261302765725

Epoch: 5| Step: 5
Training loss: 0.3568784825143403
Validation loss: 2.6402885269727867

Epoch: 5| Step: 6
Training loss: 0.3439243698026165
Validation loss: 2.601323607611506

Epoch: 5| Step: 7
Training loss: 0.51038364057026
Validation loss: 2.6070303927491603

Epoch: 5| Step: 8
Training loss: 0.3355806140568453
Validation loss: 2.615441008142521

Epoch: 5| Step: 9
Training loss: 0.27859581144792916
Validation loss: 2.613660308149089

Epoch: 5| Step: 10
Training loss: 0.2550691676064042
Validation loss: 2.5742605969890793

Epoch: 370| Step: 0
Training loss: 0.3324479685671837
Validation loss: 2.597415036192635

Epoch: 5| Step: 1
Training loss: 0.36960782150945143
Validation loss: 2.5927448877755306

Epoch: 5| Step: 2
Training loss: 0.4817940182305019
Validation loss: 2.5699433246958345

Epoch: 5| Step: 3
Training loss: 0.4443870431204343
Validation loss: 2.5937723345881536

Epoch: 5| Step: 4
Training loss: 0.32500814372643416
Validation loss: 2.588830968642347

Epoch: 5| Step: 5
Training loss: 0.1585996215654196
Validation loss: 2.604813015045731

Epoch: 5| Step: 6
Training loss: 0.24777004233001776
Validation loss: 2.597927303206747

Epoch: 5| Step: 7
Training loss: 0.5173964271467761
Validation loss: 2.5902557864405664

Epoch: 5| Step: 8
Training loss: 0.5265413749826636
Validation loss: 2.593711258220479

Epoch: 5| Step: 9
Training loss: 0.27467146777864926
Validation loss: 2.5831460484611757

Epoch: 5| Step: 10
Training loss: 0.3567196769886111
Validation loss: 2.5911672112150947

Epoch: 371| Step: 0
Training loss: 0.3964854649120064
Validation loss: 2.603051766906448

Epoch: 5| Step: 1
Training loss: 0.33724868300642413
Validation loss: 2.5633809120939977

Epoch: 5| Step: 2
Training loss: 0.5004794385175378
Validation loss: 2.5902120065795957

Epoch: 5| Step: 3
Training loss: 0.5227227526495692
Validation loss: 2.5813720491128773

Epoch: 5| Step: 4
Training loss: 0.29365705379137785
Validation loss: 2.5765978036511523

Epoch: 5| Step: 5
Training loss: 0.3946926428912091
Validation loss: 2.5972650547197937

Epoch: 5| Step: 6
Training loss: 0.4817965698241221
Validation loss: 2.574472783219917

Epoch: 5| Step: 7
Training loss: 0.1770965323484564
Validation loss: 2.6137493291971414

Epoch: 5| Step: 8
Training loss: 0.36137530044654015
Validation loss: 2.6023303769176667

Epoch: 5| Step: 9
Training loss: 0.28650802123573127
Validation loss: 2.6183185609759128

Epoch: 5| Step: 10
Training loss: 0.25714423528370084
Validation loss: 2.6427498515862426

Epoch: 372| Step: 0
Training loss: 0.4814971833983501
Validation loss: 2.5873513484051944

Epoch: 5| Step: 1
Training loss: 0.2770518660902285
Validation loss: 2.6120783352168844

Epoch: 5| Step: 2
Training loss: 0.2567553520694126
Validation loss: 2.6750397729930926

Epoch: 5| Step: 3
Training loss: 0.45255648365823664
Validation loss: 2.6520940805184283

Epoch: 5| Step: 4
Training loss: 0.4278058902405419
Validation loss: 2.6735954682318215

Epoch: 5| Step: 5
Training loss: 0.36882994965059723
Validation loss: 2.651090128359556

Epoch: 5| Step: 6
Training loss: 0.46899873174260004
Validation loss: 2.590522698523559

Epoch: 5| Step: 7
Training loss: 0.35097961849013665
Validation loss: 2.576696324811808

Epoch: 5| Step: 8
Training loss: 0.428361372190777
Validation loss: 2.609291477646158

Epoch: 5| Step: 9
Training loss: 0.33843594025017343
Validation loss: 2.53660587278313

Epoch: 5| Step: 10
Training loss: 0.3424453469338353
Validation loss: 2.559044648003445

Epoch: 373| Step: 0
Training loss: 0.35671138500174776
Validation loss: 2.564710723417913

Epoch: 5| Step: 1
Training loss: 0.5082899929810951
Validation loss: 2.5987004064909343

Epoch: 5| Step: 2
Training loss: 0.3956513509366466
Validation loss: 2.5618444355017607

Epoch: 5| Step: 3
Training loss: 0.38744532599362697
Validation loss: 2.5680534927708107

Epoch: 5| Step: 4
Training loss: 0.3992423548877134
Validation loss: 2.587145399918297

Epoch: 5| Step: 5
Training loss: 0.41594179599758857
Validation loss: 2.622473933525583

Epoch: 5| Step: 6
Training loss: 0.4317166015593632
Validation loss: 2.586448133985728

Epoch: 5| Step: 7
Training loss: 0.3585076438562418
Validation loss: 2.609231281356944

Epoch: 5| Step: 8
Training loss: 0.3581286254086825
Validation loss: 2.601535729849437

Epoch: 5| Step: 9
Training loss: 0.35062741855052393
Validation loss: 2.5981770982260377

Epoch: 5| Step: 10
Training loss: 0.36567047928529617
Validation loss: 2.610089943982673

Epoch: 374| Step: 0
Training loss: 0.2098082231001039
Validation loss: 2.601544545523196

Epoch: 5| Step: 1
Training loss: 0.29007463847108794
Validation loss: 2.6084891452568453

Epoch: 5| Step: 2
Training loss: 0.31326727847863006
Validation loss: 2.5560719331126727

Epoch: 5| Step: 3
Training loss: 0.2807727844711306
Validation loss: 2.5827461394700086

Epoch: 5| Step: 4
Training loss: 0.4280497115824997
Validation loss: 2.555147238345632

Epoch: 5| Step: 5
Training loss: 0.33650880849328324
Validation loss: 2.5568087144570546

Epoch: 5| Step: 6
Training loss: 0.29384869987021023
Validation loss: 2.5923118528201807

Epoch: 5| Step: 7
Training loss: 0.49686039237376467
Validation loss: 2.601434305078694

Epoch: 5| Step: 8
Training loss: 0.3555439251228529
Validation loss: 2.5871637084905954

Epoch: 5| Step: 9
Training loss: 0.5143663766260949
Validation loss: 2.594913428805551

Epoch: 5| Step: 10
Training loss: 0.5090428340009935
Validation loss: 2.582642343407799

Epoch: 375| Step: 0
Training loss: 0.34466104722391805
Validation loss: 2.6112254370896806

Epoch: 5| Step: 1
Training loss: 0.2495607824292729
Validation loss: 2.576611436710611

Epoch: 5| Step: 2
Training loss: 0.39757298195425167
Validation loss: 2.5935398653703925

Epoch: 5| Step: 3
Training loss: 0.3384290715803335
Validation loss: 2.5940082756028944

Epoch: 5| Step: 4
Training loss: 0.3752239273970937
Validation loss: 2.59891356304838

Epoch: 5| Step: 5
Training loss: 0.2816488431453733
Validation loss: 2.569591906069732

Epoch: 5| Step: 6
Training loss: 0.4654155388081043
Validation loss: 2.5982383483542173

Epoch: 5| Step: 7
Training loss: 0.3299316216559558
Validation loss: 2.595824469517946

Epoch: 5| Step: 8
Training loss: 0.45662439609532557
Validation loss: 2.5983681019755145

Epoch: 5| Step: 9
Training loss: 0.2796646044859334
Validation loss: 2.6011500084688426

Epoch: 5| Step: 10
Training loss: 0.47826584505472863
Validation loss: 2.605532851327499

Epoch: 376| Step: 0
Training loss: 0.4483719515328615
Validation loss: 2.63620087794684

Epoch: 5| Step: 1
Training loss: 0.4544868229580986
Validation loss: 2.6146229079645344

Epoch: 5| Step: 2
Training loss: 0.32942650032243165
Validation loss: 2.613859148820284

Epoch: 5| Step: 3
Training loss: 0.3922878539733583
Validation loss: 2.622349255739396

Epoch: 5| Step: 4
Training loss: 0.5345387759957027
Validation loss: 2.570132620824178

Epoch: 5| Step: 5
Training loss: 0.24312854032463968
Validation loss: 2.5998484692775574

Epoch: 5| Step: 6
Training loss: 0.21131767345821154
Validation loss: 2.5818649555417754

Epoch: 5| Step: 7
Training loss: 0.434986797877824
Validation loss: 2.5838407427682344

Epoch: 5| Step: 8
Training loss: 0.23108474394070483
Validation loss: 2.6019416544368936

Epoch: 5| Step: 9
Training loss: 0.273238272976324
Validation loss: 2.6129807471237

Epoch: 5| Step: 10
Training loss: 0.39318809757966444
Validation loss: 2.5970953292020664

Epoch: 377| Step: 0
Training loss: 0.2621842983627803
Validation loss: 2.645196917746895

Epoch: 5| Step: 1
Training loss: 0.3296516869063099
Validation loss: 2.5991561508248733

Epoch: 5| Step: 2
Training loss: 0.3676332649279893
Validation loss: 2.6092171864753086

Epoch: 5| Step: 3
Training loss: 0.5133590035501778
Validation loss: 2.612300871925914

Epoch: 5| Step: 4
Training loss: 0.2855177638795725
Validation loss: 2.6430123977039948

Epoch: 5| Step: 5
Training loss: 0.3397315048238994
Validation loss: 2.6165029566901197

Epoch: 5| Step: 6
Training loss: 0.34067675564790073
Validation loss: 2.5993375286820033

Epoch: 5| Step: 7
Training loss: 0.43199067571961713
Validation loss: 2.633948561204631

Epoch: 5| Step: 8
Training loss: 0.43682802911036855
Validation loss: 2.6382152874953095

Epoch: 5| Step: 9
Training loss: 0.40901058590324135
Validation loss: 2.5998814492692253

Epoch: 5| Step: 10
Training loss: 0.456928861185486
Validation loss: 2.6187624310847397

Epoch: 378| Step: 0
Training loss: 0.34451659294662684
Validation loss: 2.658985892328937

Epoch: 5| Step: 1
Training loss: 0.38408449561606106
Validation loss: 2.6478919141443873

Epoch: 5| Step: 2
Training loss: 0.46051018514563147
Validation loss: 2.6689829444455726

Epoch: 5| Step: 3
Training loss: 0.37100937536634565
Validation loss: 2.655087025683459

Epoch: 5| Step: 4
Training loss: 0.3249988019444318
Validation loss: 2.6543989334467097

Epoch: 5| Step: 5
Training loss: 0.25650625499828417
Validation loss: 2.6132198952970476

Epoch: 5| Step: 6
Training loss: 0.16886451751730136
Validation loss: 2.6257543051404126

Epoch: 5| Step: 7
Training loss: 0.26803458047465273
Validation loss: 2.639925576788061

Epoch: 5| Step: 8
Training loss: 0.2657997594282972
Validation loss: 2.6285995565116256

Epoch: 5| Step: 9
Training loss: 0.5576530485096037
Validation loss: 2.66841436772562

Epoch: 5| Step: 10
Training loss: 0.4338911256774565
Validation loss: 2.629570924436236

Epoch: 379| Step: 0
Training loss: 0.15451845724577024
Validation loss: 2.66004671347692

Epoch: 5| Step: 1
Training loss: 0.34422460217724066
Validation loss: 2.6458166049399052

Epoch: 5| Step: 2
Training loss: 0.5651194721264604
Validation loss: 2.6630490790004133

Epoch: 5| Step: 3
Training loss: 0.34738527946321135
Validation loss: 2.624999587864216

Epoch: 5| Step: 4
Training loss: 0.2881979255900092
Validation loss: 2.6147403575922805

Epoch: 5| Step: 5
Training loss: 0.3297904527288005
Validation loss: 2.674387838911931

Epoch: 5| Step: 6
Training loss: 0.32982455338238437
Validation loss: 2.6245753955180056

Epoch: 5| Step: 7
Training loss: 0.3483538860873302
Validation loss: 2.602508734491127

Epoch: 5| Step: 8
Training loss: 0.33913853799124627
Validation loss: 2.6551107956849873

Epoch: 5| Step: 9
Training loss: 0.38879082167971074
Validation loss: 2.6243403661202724

Epoch: 5| Step: 10
Training loss: 0.33093544266865443
Validation loss: 2.6383797520520433

Epoch: 380| Step: 0
Training loss: 0.24055965236020016
Validation loss: 2.652001174380949

Epoch: 5| Step: 1
Training loss: 0.5125078130917342
Validation loss: 2.6568438325223322

Epoch: 5| Step: 2
Training loss: 0.38247145817425354
Validation loss: 2.6894889782266653

Epoch: 5| Step: 3
Training loss: 0.3100545687677051
Validation loss: 2.6248577653640774

Epoch: 5| Step: 4
Training loss: 0.2874344782180028
Validation loss: 2.6193669552100745

Epoch: 5| Step: 5
Training loss: 0.35799607810743905
Validation loss: 2.6709038058911987

Epoch: 5| Step: 6
Training loss: 0.2344903185387232
Validation loss: 2.6001162315274002

Epoch: 5| Step: 7
Training loss: 0.38338831977106114
Validation loss: 2.6063293904107803

Epoch: 5| Step: 8
Training loss: 0.4430280951789679
Validation loss: 2.5685211062095354

Epoch: 5| Step: 9
Training loss: 0.4412087530358128
Validation loss: 2.6036697924367718

Epoch: 5| Step: 10
Training loss: 0.4310294091608441
Validation loss: 2.6074083184791657

Epoch: 381| Step: 0
Training loss: 0.29166980157030287
Validation loss: 2.554973121580191

Epoch: 5| Step: 1
Training loss: 0.27789273797176467
Validation loss: 2.6032087320584947

Epoch: 5| Step: 2
Training loss: 0.4618552979072826
Validation loss: 2.5663662858012404

Epoch: 5| Step: 3
Training loss: 0.4159664071210317
Validation loss: 2.6161252506717045

Epoch: 5| Step: 4
Training loss: 0.30759038657043425
Validation loss: 2.5776842791548944

Epoch: 5| Step: 5
Training loss: 0.45686668302321304
Validation loss: 2.6172180203387896

Epoch: 5| Step: 6
Training loss: 0.3942687417113013
Validation loss: 2.6137746732002185

Epoch: 5| Step: 7
Training loss: 0.36617706142144013
Validation loss: 2.606447155723347

Epoch: 5| Step: 8
Training loss: 0.32409976016662206
Validation loss: 2.590174434725346

Epoch: 5| Step: 9
Training loss: 0.38783699732892435
Validation loss: 2.5992938327448156

Epoch: 5| Step: 10
Training loss: 0.3257863513172067
Validation loss: 2.600419477987792

Epoch: 382| Step: 0
Training loss: 0.3426941891430817
Validation loss: 2.622229031122694

Epoch: 5| Step: 1
Training loss: 0.29732493136055616
Validation loss: 2.550472133817288

Epoch: 5| Step: 2
Training loss: 0.3201353350761822
Validation loss: 2.6017402741665725

Epoch: 5| Step: 3
Training loss: 0.2310295394406898
Validation loss: 2.598104809801032

Epoch: 5| Step: 4
Training loss: 0.33403336015153084
Validation loss: 2.555203263345498

Epoch: 5| Step: 5
Training loss: 0.4441156029677412
Validation loss: 2.5767454591178085

Epoch: 5| Step: 6
Training loss: 0.4984242374724491
Validation loss: 2.578965548919142

Epoch: 5| Step: 7
Training loss: 0.2801809789761161
Validation loss: 2.57906930086204

Epoch: 5| Step: 8
Training loss: 0.4143711415279486
Validation loss: 2.5964951584861287

Epoch: 5| Step: 9
Training loss: 0.26469126843919094
Validation loss: 2.5622497024168642

Epoch: 5| Step: 10
Training loss: 0.28858729557157836
Validation loss: 2.544784071102955

Epoch: 383| Step: 0
Training loss: 0.48142835111317883
Validation loss: 2.5399031668054337

Epoch: 5| Step: 1
Training loss: 0.2614333318760627
Validation loss: 2.6035683316563314

Epoch: 5| Step: 2
Training loss: 0.441219830602796
Validation loss: 2.569040171503083

Epoch: 5| Step: 3
Training loss: 0.19253313417260381
Validation loss: 2.5423859997669793

Epoch: 5| Step: 4
Training loss: 0.2391705801620916
Validation loss: 2.5659045781102017

Epoch: 5| Step: 5
Training loss: 0.1426977478809483
Validation loss: 2.6010025201705407

Epoch: 5| Step: 6
Training loss: 0.4580687622639515
Validation loss: 2.5974542532321157

Epoch: 5| Step: 7
Training loss: 0.3097272048156444
Validation loss: 2.5704961714163264

Epoch: 5| Step: 8
Training loss: 0.4354660746119577
Validation loss: 2.5321622536725865

Epoch: 5| Step: 9
Training loss: 0.3300533511102491
Validation loss: 2.5718511918009264

Epoch: 5| Step: 10
Training loss: 0.3683285130894532
Validation loss: 2.5795736688282083

Epoch: 384| Step: 0
Training loss: 0.194562052007834
Validation loss: 2.5740422342637763

Epoch: 5| Step: 1
Training loss: 0.2550233475431051
Validation loss: 2.5942282959079277

Epoch: 5| Step: 2
Training loss: 0.508598482312103
Validation loss: 2.5854005686489563

Epoch: 5| Step: 3
Training loss: 0.4194256356564596
Validation loss: 2.630026716120546

Epoch: 5| Step: 4
Training loss: 0.43588202885834265
Validation loss: 2.587305707127975

Epoch: 5| Step: 5
Training loss: 0.2294977065701052
Validation loss: 2.6147126683579276

Epoch: 5| Step: 6
Training loss: 0.3888069761478966
Validation loss: 2.5878275132101978

Epoch: 5| Step: 7
Training loss: 0.29425220374268213
Validation loss: 2.5711128656150826

Epoch: 5| Step: 8
Training loss: 0.2754379529393131
Validation loss: 2.6092063471544646

Epoch: 5| Step: 9
Training loss: 0.29834161686097227
Validation loss: 2.585858693198593

Epoch: 5| Step: 10
Training loss: 0.37858024809247254
Validation loss: 2.561435696537126

Epoch: 385| Step: 0
Training loss: 0.3589141835194049
Validation loss: 2.5854469941732425

Epoch: 5| Step: 1
Training loss: 0.22690600629950253
Validation loss: 2.5434264891090583

Epoch: 5| Step: 2
Training loss: 0.4172353638469877
Validation loss: 2.5053873875433696

Epoch: 5| Step: 3
Training loss: 0.36639657973682715
Validation loss: 2.5476033462575227

Epoch: 5| Step: 4
Training loss: 0.3193745371036945
Validation loss: 2.553193039222905

Epoch: 5| Step: 5
Training loss: 0.3140792282356117
Validation loss: 2.518357737231784

Epoch: 5| Step: 6
Training loss: 0.393087483664308
Validation loss: 2.536459792133926

Epoch: 5| Step: 7
Training loss: 0.42891193101243913
Validation loss: 2.535433448946749

Epoch: 5| Step: 8
Training loss: 0.3119685780485471
Validation loss: 2.519360444979791

Epoch: 5| Step: 9
Training loss: 0.22366248687697626
Validation loss: 2.514602147970673

Epoch: 5| Step: 10
Training loss: 0.37359945703707986
Validation loss: 2.560298367059966

Epoch: 386| Step: 0
Training loss: 0.29624335955569514
Validation loss: 2.5473878023246823

Epoch: 5| Step: 1
Training loss: 0.339907256583382
Validation loss: 2.5818945450263087

Epoch: 5| Step: 2
Training loss: 0.4064171153914667
Validation loss: 2.5611211096652573

Epoch: 5| Step: 3
Training loss: 0.35142042680149976
Validation loss: 2.569217972852444

Epoch: 5| Step: 4
Training loss: 0.26383080108071577
Validation loss: 2.59559011784725

Epoch: 5| Step: 5
Training loss: 0.31205555782469413
Validation loss: 2.5590026403497164

Epoch: 5| Step: 6
Training loss: 0.45634978587957536
Validation loss: 2.578875555551327

Epoch: 5| Step: 7
Training loss: 0.38808068404843965
Validation loss: 2.57782297164472

Epoch: 5| Step: 8
Training loss: 0.31291362092169334
Validation loss: 2.5947720189064363

Epoch: 5| Step: 9
Training loss: 0.3363544405080264
Validation loss: 2.5935585316018983

Epoch: 5| Step: 10
Training loss: 0.33825120814531284
Validation loss: 2.6033440893351565

Epoch: 387| Step: 0
Training loss: 0.44248014815029907
Validation loss: 2.5780802484520686

Epoch: 5| Step: 1
Training loss: 0.31985772809082663
Validation loss: 2.596026743696793

Epoch: 5| Step: 2
Training loss: 0.5213686639660969
Validation loss: 2.595280153058226

Epoch: 5| Step: 3
Training loss: 0.32988870140045695
Validation loss: 2.6114068219136715

Epoch: 5| Step: 4
Training loss: 0.16932881658204635
Validation loss: 2.613957303219358

Epoch: 5| Step: 5
Training loss: 0.31699796378748263
Validation loss: 2.627636551778109

Epoch: 5| Step: 6
Training loss: 0.29305294098724777
Validation loss: 2.6302172803325568

Epoch: 5| Step: 7
Training loss: 0.25887238222858866
Validation loss: 2.586712911214602

Epoch: 5| Step: 8
Training loss: 0.14374602794342495
Validation loss: 2.622105826822925

Epoch: 5| Step: 9
Training loss: 0.44320706343384464
Validation loss: 2.589905058627992

Epoch: 5| Step: 10
Training loss: 0.43022219594768396
Validation loss: 2.6423633026310447

Epoch: 388| Step: 0
Training loss: 0.35116374395714556
Validation loss: 2.62873007503972

Epoch: 5| Step: 1
Training loss: 0.3403420795725074
Validation loss: 2.610960950688625

Epoch: 5| Step: 2
Training loss: 0.5376737646405763
Validation loss: 2.615555504104892

Epoch: 5| Step: 3
Training loss: 0.343264605535792
Validation loss: 2.609252838405341

Epoch: 5| Step: 4
Training loss: 0.41043413830213
Validation loss: 2.5924395420902973

Epoch: 5| Step: 5
Training loss: 0.2308804181314619
Validation loss: 2.6021696017497598

Epoch: 5| Step: 6
Training loss: 0.3793872847288463
Validation loss: 2.5932269339284137

Epoch: 5| Step: 7
Training loss: 0.3542528631933207
Validation loss: 2.6049068286710266

Epoch: 5| Step: 8
Training loss: 0.22654406702758925
Validation loss: 2.5822480059095114

Epoch: 5| Step: 9
Training loss: 0.34305869293880376
Validation loss: 2.548668950360144

Epoch: 5| Step: 10
Training loss: 0.24967715159564643
Validation loss: 2.6085777712947804

Epoch: 389| Step: 0
Training loss: 0.37931135485871137
Validation loss: 2.553021312383472

Epoch: 5| Step: 1
Training loss: 0.3127593156645382
Validation loss: 2.5700664734777487

Epoch: 5| Step: 2
Training loss: 0.26516212074735684
Validation loss: 2.6028436163773656

Epoch: 5| Step: 3
Training loss: 0.33316342921224223
Validation loss: 2.640665406307944

Epoch: 5| Step: 4
Training loss: 0.5606691712209362
Validation loss: 2.637216932601075

Epoch: 5| Step: 5
Training loss: 0.31708122596508287
Validation loss: 2.6180572107919358

Epoch: 5| Step: 6
Training loss: 0.16646995645790896
Validation loss: 2.618919841218053

Epoch: 5| Step: 7
Training loss: 0.3015332296723366
Validation loss: 2.643631941661841

Epoch: 5| Step: 8
Training loss: 0.3273445793997151
Validation loss: 2.6516796830078664

Epoch: 5| Step: 9
Training loss: 0.4132840919036361
Validation loss: 2.6474223968286874

Epoch: 5| Step: 10
Training loss: 0.2682129228481827
Validation loss: 2.617444973217254

Epoch: 390| Step: 0
Training loss: 0.3280962749805151
Validation loss: 2.6707099860215613

Epoch: 5| Step: 1
Training loss: 0.3960807324138223
Validation loss: 2.6322114509789887

Epoch: 5| Step: 2
Training loss: 0.5134032384640268
Validation loss: 2.613703383339106

Epoch: 5| Step: 3
Training loss: 0.3185212127666986
Validation loss: 2.638612972256765

Epoch: 5| Step: 4
Training loss: 0.3034723086481871
Validation loss: 2.6045971724182033

Epoch: 5| Step: 5
Training loss: 0.3392145426843765
Validation loss: 2.645152856087763

Epoch: 5| Step: 6
Training loss: 0.2198433290272839
Validation loss: 2.5918058474407712

Epoch: 5| Step: 7
Training loss: 0.31601462440662387
Validation loss: 2.62478619049985

Epoch: 5| Step: 8
Training loss: 0.2885055331157398
Validation loss: 2.6212103209080015

Epoch: 5| Step: 9
Training loss: 0.3447469105537139
Validation loss: 2.6442305600434217

Epoch: 5| Step: 10
Training loss: 0.3881637472201527
Validation loss: 2.6125075957838506

Epoch: 391| Step: 0
Training loss: 0.2930220491881538
Validation loss: 2.6134082124407545

Epoch: 5| Step: 1
Training loss: 0.2546927082956812
Validation loss: 2.663878303645753

Epoch: 5| Step: 2
Training loss: 0.4303776487124369
Validation loss: 2.635959825271003

Epoch: 5| Step: 3
Training loss: 0.16469390598809583
Validation loss: 2.6230973195714236

Epoch: 5| Step: 4
Training loss: 0.3032004306774742
Validation loss: 2.6259381209335433

Epoch: 5| Step: 5
Training loss: 0.3605613614661296
Validation loss: 2.61023699737896

Epoch: 5| Step: 6
Training loss: 0.4428324151524328
Validation loss: 2.6564500939648608

Epoch: 5| Step: 7
Training loss: 0.22584045386320642
Validation loss: 2.6050818632145214

Epoch: 5| Step: 8
Training loss: 0.356640655083044
Validation loss: 2.5986021449110037

Epoch: 5| Step: 9
Training loss: 0.386229407770795
Validation loss: 2.6043266618042686

Epoch: 5| Step: 10
Training loss: 0.3853582475394627
Validation loss: 2.6373699932038726

Epoch: 392| Step: 0
Training loss: 0.3379885360774127
Validation loss: 2.6147610226040077

Epoch: 5| Step: 1
Training loss: 0.25430933428125463
Validation loss: 2.618032920274388

Epoch: 5| Step: 2
Training loss: 0.44292803716852525
Validation loss: 2.6148900220396247

Epoch: 5| Step: 3
Training loss: 0.34676875729835605
Validation loss: 2.6143210275857744

Epoch: 5| Step: 4
Training loss: 0.19487167201158156
Validation loss: 2.6525523788589163

Epoch: 5| Step: 5
Training loss: 0.2755642877695082
Validation loss: 2.6036470829266603

Epoch: 5| Step: 6
Training loss: 0.30454428069967004
Validation loss: 2.636399164068775

Epoch: 5| Step: 7
Training loss: 0.13821466049519854
Validation loss: 2.5915814618138824

Epoch: 5| Step: 8
Training loss: 0.4155335296995208
Validation loss: 2.5988273458541213

Epoch: 5| Step: 9
Training loss: 0.40352582890920724
Validation loss: 2.616752179594806

Epoch: 5| Step: 10
Training loss: 0.3665051105254849
Validation loss: 2.5909619964537867

Epoch: 393| Step: 0
Training loss: 0.2939001663365239
Validation loss: 2.6064504310316274

Epoch: 5| Step: 1
Training loss: 0.2659304349388907
Validation loss: 2.602839961268385

Epoch: 5| Step: 2
Training loss: 0.2816424413402891
Validation loss: 2.6014562957931524

Epoch: 5| Step: 3
Training loss: 0.3482872027251688
Validation loss: 2.58101566228967

Epoch: 5| Step: 4
Training loss: 0.36549510930881846
Validation loss: 2.623845557042562

Epoch: 5| Step: 5
Training loss: 0.2700989728786976
Validation loss: 2.631158590108838

Epoch: 5| Step: 6
Training loss: 0.290064505543235
Validation loss: 2.6235284631134927

Epoch: 5| Step: 7
Training loss: 0.26326904608177787
Validation loss: 2.6189761279030312

Epoch: 5| Step: 8
Training loss: 0.28004297224740443
Validation loss: 2.6577865046134974

Epoch: 5| Step: 9
Training loss: 0.4789905915660316
Validation loss: 2.641178566998034

Epoch: 5| Step: 10
Training loss: 0.48066885588114766
Validation loss: 2.6431653474799535

Epoch: 394| Step: 0
Training loss: 0.24273113793706125
Validation loss: 2.6477298549232864

Epoch: 5| Step: 1
Training loss: 0.3601481372639441
Validation loss: 2.6625165492141467

Epoch: 5| Step: 2
Training loss: 0.22834823868358126
Validation loss: 2.625241799749459

Epoch: 5| Step: 3
Training loss: 0.3453845911161193
Validation loss: 2.598632370532556

Epoch: 5| Step: 4
Training loss: 0.39703965413500286
Validation loss: 2.622018013938627

Epoch: 5| Step: 5
Training loss: 0.4255516062908225
Validation loss: 2.615520545788082

Epoch: 5| Step: 6
Training loss: 0.3170114310411759
Validation loss: 2.617244299007647

Epoch: 5| Step: 7
Training loss: 0.10447737776006684
Validation loss: 2.6247409608754952

Epoch: 5| Step: 8
Training loss: 0.18665606591729553
Validation loss: 2.602901253349635

Epoch: 5| Step: 9
Training loss: 0.3583962339078842
Validation loss: 2.5905317377235337

Epoch: 5| Step: 10
Training loss: 0.5037027288080865
Validation loss: 2.577085324266244

Epoch: 395| Step: 0
Training loss: 0.32117955390957276
Validation loss: 2.5879073725270882

Epoch: 5| Step: 1
Training loss: 0.27914587353849535
Validation loss: 2.6170457939044596

Epoch: 5| Step: 2
Training loss: 0.38686029175144726
Validation loss: 2.590480454145556

Epoch: 5| Step: 3
Training loss: 0.4286602224883541
Validation loss: 2.5978921185325157

Epoch: 5| Step: 4
Training loss: 0.49296157759150594
Validation loss: 2.5811775609126624

Epoch: 5| Step: 5
Training loss: 0.2868285849677106
Validation loss: 2.5960351272745377

Epoch: 5| Step: 6
Training loss: 0.3354079597342135
Validation loss: 2.573710493788516

Epoch: 5| Step: 7
Training loss: 0.1752174129601756
Validation loss: 2.5669651831017246

Epoch: 5| Step: 8
Training loss: 0.27351228508739256
Validation loss: 2.5900789907977333

Epoch: 5| Step: 9
Training loss: 0.30782525428257096
Validation loss: 2.603207093350347

Epoch: 5| Step: 10
Training loss: 0.33375398597765893
Validation loss: 2.592243415792028

Epoch: 396| Step: 0
Training loss: 0.28274138067482996
Validation loss: 2.5624577998766553

Epoch: 5| Step: 1
Training loss: 0.226869835072305
Validation loss: 2.606956649300423

Epoch: 5| Step: 2
Training loss: 0.43650814430705265
Validation loss: 2.6147573772909394

Epoch: 5| Step: 3
Training loss: 0.3921333944378567
Validation loss: 2.619561575330018

Epoch: 5| Step: 4
Training loss: 0.19549206109098682
Validation loss: 2.622755756446883

Epoch: 5| Step: 5
Training loss: 0.25908275709111656
Validation loss: 2.6219757685716294

Epoch: 5| Step: 6
Training loss: 0.35990545266412466
Validation loss: 2.67034220486273

Epoch: 5| Step: 7
Training loss: 0.45202551009024533
Validation loss: 2.678066143084538

Epoch: 5| Step: 8
Training loss: 0.29467547146387363
Validation loss: 2.6642022894159534

Epoch: 5| Step: 9
Training loss: 0.28226701651113256
Validation loss: 2.662926480964574

Epoch: 5| Step: 10
Training loss: 0.4054527345702732
Validation loss: 2.6599394951939277

Epoch: 397| Step: 0
Training loss: 0.41615427420040346
Validation loss: 2.6410916619880944

Epoch: 5| Step: 1
Training loss: 0.37006295242114406
Validation loss: 2.633401759932968

Epoch: 5| Step: 2
Training loss: 0.2590528331512943
Validation loss: 2.5994426961419475

Epoch: 5| Step: 3
Training loss: 0.2649619437953191
Validation loss: 2.577513806338417

Epoch: 5| Step: 4
Training loss: 0.23408762479933487
Validation loss: 2.5888338424031625

Epoch: 5| Step: 5
Training loss: 0.3669267093538319
Validation loss: 2.578116533322072

Epoch: 5| Step: 6
Training loss: 0.2445832931419959
Validation loss: 2.5569365313938324

Epoch: 5| Step: 7
Training loss: 0.40554076420723983
Validation loss: 2.6596640587070906

Epoch: 5| Step: 8
Training loss: 0.34414669468838854
Validation loss: 2.6407896581414456

Epoch: 5| Step: 9
Training loss: 0.4324563203099485
Validation loss: 2.6309163222098397

Epoch: 5| Step: 10
Training loss: 0.3096649314132323
Validation loss: 2.673407128236927

Epoch: 398| Step: 0
Training loss: 0.22113127238389763
Validation loss: 2.715851622710651

Epoch: 5| Step: 1
Training loss: 0.2519885784902503
Validation loss: 2.637203452445116

Epoch: 5| Step: 2
Training loss: 0.3592727349771924
Validation loss: 2.6529859723759177

Epoch: 5| Step: 3
Training loss: 0.3057539932507983
Validation loss: 2.6916703162312534

Epoch: 5| Step: 4
Training loss: 0.41408065540169176
Validation loss: 2.608327947199064

Epoch: 5| Step: 5
Training loss: 0.34531676259581645
Validation loss: 2.634644992946637

Epoch: 5| Step: 6
Training loss: 0.3282155752056609
Validation loss: 2.655499161458875

Epoch: 5| Step: 7
Training loss: 0.2076212016854283
Validation loss: 2.676124083602297

Epoch: 5| Step: 8
Training loss: 0.3225928292742192
Validation loss: 2.650020511406187

Epoch: 5| Step: 9
Training loss: 0.4284684835982202
Validation loss: 2.6577456845927423

Epoch: 5| Step: 10
Training loss: 0.42642350709520427
Validation loss: 2.658239678429035

Epoch: 399| Step: 0
Training loss: 0.3398832100946021
Validation loss: 2.62344716498618

Epoch: 5| Step: 1
Training loss: 0.2880499736514723
Validation loss: 2.6525159442198913

Epoch: 5| Step: 2
Training loss: 0.26114922802157514
Validation loss: 2.6654010831142165

Epoch: 5| Step: 3
Training loss: 0.46394890316425413
Validation loss: 2.6536630346974133

Epoch: 5| Step: 4
Training loss: 0.29162858248888013
Validation loss: 2.5989877462937008

Epoch: 5| Step: 5
Training loss: 0.26157564549472645
Validation loss: 2.6244831416259573

Epoch: 5| Step: 6
Training loss: 0.35436122356191496
Validation loss: 2.6033535635885885

Epoch: 5| Step: 7
Training loss: 0.2996900134135351
Validation loss: 2.5922174473923882

Epoch: 5| Step: 8
Training loss: 0.30941580878941133
Validation loss: 2.603590003041421

Epoch: 5| Step: 9
Training loss: 0.44723374032391117
Validation loss: 2.6069534528073026

Epoch: 5| Step: 10
Training loss: 0.20966825267557537
Validation loss: 2.6117626474188604

Epoch: 400| Step: 0
Training loss: 0.25994965480793264
Validation loss: 2.5860447529407526

Epoch: 5| Step: 1
Training loss: 0.23862917310493764
Validation loss: 2.581069067778692

Epoch: 5| Step: 2
Training loss: 0.2789642113476327
Validation loss: 2.627897003418472

Epoch: 5| Step: 3
Training loss: 0.4099379548949812
Validation loss: 2.6290007416729537

Epoch: 5| Step: 4
Training loss: 0.3723160340322481
Validation loss: 2.631092121806035

Epoch: 5| Step: 5
Training loss: 0.37873620219010024
Validation loss: 2.6448456058490564

Epoch: 5| Step: 6
Training loss: 0.297408878732864
Validation loss: 2.6339192488055283

Epoch: 5| Step: 7
Training loss: 0.30640813189857
Validation loss: 2.645780837203809

Epoch: 5| Step: 8
Training loss: 0.35924913441308853
Validation loss: 2.588615610703929

Epoch: 5| Step: 9
Training loss: 0.273958527210781
Validation loss: 2.637297481585743

Epoch: 5| Step: 10
Training loss: 0.27091834525274067
Validation loss: 2.587306597905021

Epoch: 401| Step: 0
Training loss: 0.2670709160439028
Validation loss: 2.5976509700514545

Epoch: 5| Step: 1
Training loss: 0.3371942322724476
Validation loss: 2.6196911437669907

Epoch: 5| Step: 2
Training loss: 0.3345120594733209
Validation loss: 2.607548410927033

Epoch: 5| Step: 3
Training loss: 0.4126282449252057
Validation loss: 2.6080009625777727

Epoch: 5| Step: 4
Training loss: 0.39542876030476815
Validation loss: 2.589428210574434

Epoch: 5| Step: 5
Training loss: 0.19683488709657218
Validation loss: 2.579954709342885

Epoch: 5| Step: 6
Training loss: 0.34534679518715283
Validation loss: 2.601635130605291

Epoch: 5| Step: 7
Training loss: 0.28691912205794323
Validation loss: 2.6062368536275016

Epoch: 5| Step: 8
Training loss: 0.2996242365328054
Validation loss: 2.6220892566607557

Epoch: 5| Step: 9
Training loss: 0.3061746105510882
Validation loss: 2.6282837969532817

Epoch: 5| Step: 10
Training loss: 0.252904691897115
Validation loss: 2.6200740054297276

Epoch: 402| Step: 0
Training loss: 0.2692449956976103
Validation loss: 2.678420239159958

Epoch: 5| Step: 1
Training loss: 0.3895197490917733
Validation loss: 2.6280361358581317

Epoch: 5| Step: 2
Training loss: 0.2414361157507224
Validation loss: 2.6691389473968625

Epoch: 5| Step: 3
Training loss: 0.21015514884007916
Validation loss: 2.6213628178667085

Epoch: 5| Step: 4
Training loss: 0.29917813665394233
Validation loss: 2.649817619173387

Epoch: 5| Step: 5
Training loss: 0.30774821563841775
Validation loss: 2.6547589440328694

Epoch: 5| Step: 6
Training loss: 0.451204802397355
Validation loss: 2.6578904705131676

Epoch: 5| Step: 7
Training loss: 0.3714070453242098
Validation loss: 2.6850072695301304

Epoch: 5| Step: 8
Training loss: 0.3255708033036899
Validation loss: 2.6428789738595846

Epoch: 5| Step: 9
Training loss: 0.29162054747441596
Validation loss: 2.6265261618638176

Epoch: 5| Step: 10
Training loss: 0.22162565337405898
Validation loss: 2.650084587607682

Epoch: 403| Step: 0
Training loss: 0.3359551314229314
Validation loss: 2.665556857130542

Epoch: 5| Step: 1
Training loss: 0.25229169586227673
Validation loss: 2.6351366368944276

Epoch: 5| Step: 2
Training loss: 0.34103031847782966
Validation loss: 2.6525660062015453

Epoch: 5| Step: 3
Training loss: 0.3917352538556005
Validation loss: 2.6104750701483654

Epoch: 5| Step: 4
Training loss: 0.1740995602388815
Validation loss: 2.60365708777817

Epoch: 5| Step: 5
Training loss: 0.2916130487794874
Validation loss: 2.6101307630771706

Epoch: 5| Step: 6
Training loss: 0.3754624058968918
Validation loss: 2.563651321728064

Epoch: 5| Step: 7
Training loss: 0.30342603856292677
Validation loss: 2.578351676275854

Epoch: 5| Step: 8
Training loss: 0.20989018512317095
Validation loss: 2.604432407397509

Epoch: 5| Step: 9
Training loss: 0.4131994970620022
Validation loss: 2.5836021699923886

Epoch: 5| Step: 10
Training loss: 0.21793233950188146
Validation loss: 2.568769121060205

Epoch: 404| Step: 0
Training loss: 0.3627198300884957
Validation loss: 2.607413920827116

Epoch: 5| Step: 1
Training loss: 0.2820744219888575
Validation loss: 2.5741132252452785

Epoch: 5| Step: 2
Training loss: 0.32087351353371235
Validation loss: 2.572319899825855

Epoch: 5| Step: 3
Training loss: 0.2644814531037904
Validation loss: 2.578372269770673

Epoch: 5| Step: 4
Training loss: 0.29561038206949086
Validation loss: 2.6137822122568664

Epoch: 5| Step: 5
Training loss: 0.3203036842063443
Validation loss: 2.62084885654958

Epoch: 5| Step: 6
Training loss: 0.2859571783663247
Validation loss: 2.6289239600726804

Epoch: 5| Step: 7
Training loss: 0.2364772452271134
Validation loss: 2.650192911231479

Epoch: 5| Step: 8
Training loss: 0.4670817411765947
Validation loss: 2.652233416223817

Epoch: 5| Step: 9
Training loss: 0.20537351497106282
Validation loss: 2.599106060267396

Epoch: 5| Step: 10
Training loss: 0.32931927913595677
Validation loss: 2.620700473946781

Epoch: 405| Step: 0
Training loss: 0.41487295978247923
Validation loss: 2.5812465252254877

Epoch: 5| Step: 1
Training loss: 0.3955788254270392
Validation loss: 2.6005785805129267

Epoch: 5| Step: 2
Training loss: 0.2928156516272949
Validation loss: 2.6062718607273747

Epoch: 5| Step: 3
Training loss: 0.3599814812215115
Validation loss: 2.5520890082437897

Epoch: 5| Step: 4
Training loss: 0.33574712149393776
Validation loss: 2.5565789573750988

Epoch: 5| Step: 5
Training loss: 0.29277830927830933
Validation loss: 2.5936221207230092

Epoch: 5| Step: 6
Training loss: 0.21826539687230026
Validation loss: 2.5842926699915236

Epoch: 5| Step: 7
Training loss: 0.24794451035622445
Validation loss: 2.5935522192596774

Epoch: 5| Step: 8
Training loss: 0.26882270616847415
Validation loss: 2.621587643891337

Epoch: 5| Step: 9
Training loss: 0.30423709394795473
Validation loss: 2.618307456784646

Epoch: 5| Step: 10
Training loss: 0.3087127673328863
Validation loss: 2.6465727118823104

Epoch: 406| Step: 0
Training loss: 0.1836145267499109
Validation loss: 2.662850977004558

Epoch: 5| Step: 1
Training loss: 0.277053936794787
Validation loss: 2.6008850649935122

Epoch: 5| Step: 2
Training loss: 0.32378687302480447
Validation loss: 2.5860384738075393

Epoch: 5| Step: 3
Training loss: 0.3693690930134634
Validation loss: 2.6006388228103456

Epoch: 5| Step: 4
Training loss: 0.3290311924893306
Validation loss: 2.6158324508504256

Epoch: 5| Step: 5
Training loss: 0.3811613401914549
Validation loss: 2.636423542081962

Epoch: 5| Step: 6
Training loss: 0.47635624283733613
Validation loss: 2.6026096687111884

Epoch: 5| Step: 7
Training loss: 0.17111376684490262
Validation loss: 2.635539546697324

Epoch: 5| Step: 8
Training loss: 0.3380121442543021
Validation loss: 2.6412780686165407

Epoch: 5| Step: 9
Training loss: 0.24882604966428512
Validation loss: 2.6124505353098284

Epoch: 5| Step: 10
Training loss: 0.27746250404024164
Validation loss: 2.615693652809622

Epoch: 407| Step: 0
Training loss: 0.27607788741997347
Validation loss: 2.5659114750102945

Epoch: 5| Step: 1
Training loss: 0.2553347968423931
Validation loss: 2.6304810293175085

Epoch: 5| Step: 2
Training loss: 0.22321174994799453
Validation loss: 2.62530608572958

Epoch: 5| Step: 3
Training loss: 0.3060766123384201
Validation loss: 2.6084431514629305

Epoch: 5| Step: 4
Training loss: 0.2787404152372724
Validation loss: 2.6151066257933437

Epoch: 5| Step: 5
Training loss: 0.3065237442118128
Validation loss: 2.651243444925095

Epoch: 5| Step: 6
Training loss: 0.4959352946097188
Validation loss: 2.619297458432113

Epoch: 5| Step: 7
Training loss: 0.25631957854045195
Validation loss: 2.6506785160088584

Epoch: 5| Step: 8
Training loss: 0.37683133149082804
Validation loss: 2.652069022233456

Epoch: 5| Step: 9
Training loss: 0.4308258583126263
Validation loss: 2.6634358598993684

Epoch: 5| Step: 10
Training loss: 0.3106430432626679
Validation loss: 2.6243234671834146

Epoch: 408| Step: 0
Training loss: 0.24612464408112575
Validation loss: 2.6065732885117736

Epoch: 5| Step: 1
Training loss: 0.29118057031239974
Validation loss: 2.584487763941112

Epoch: 5| Step: 2
Training loss: 0.3216900627533683
Validation loss: 2.5277764061827126

Epoch: 5| Step: 3
Training loss: 0.38165813706513313
Validation loss: 2.5549885797968823

Epoch: 5| Step: 4
Training loss: 0.4154487652112824
Validation loss: 2.538850249323917

Epoch: 5| Step: 5
Training loss: 0.3783215996873471
Validation loss: 2.483186133575987

Epoch: 5| Step: 6
Training loss: 0.2794710829768698
Validation loss: 2.540822369166654

Epoch: 5| Step: 7
Training loss: 0.29389353704868065
Validation loss: 2.5439557552054426

Epoch: 5| Step: 8
Training loss: 0.390028364391058
Validation loss: 2.5750387045698

Epoch: 5| Step: 9
Training loss: 0.1638027587375352
Validation loss: 2.6026789255263063

Epoch: 5| Step: 10
Training loss: 0.3210108169600372
Validation loss: 2.605975879563513

Epoch: 409| Step: 0
Training loss: 0.21684099727850942
Validation loss: 2.6133343865488947

Epoch: 5| Step: 1
Training loss: 0.39038816902040047
Validation loss: 2.6607774913145

Epoch: 5| Step: 2
Training loss: 0.30920477624963405
Validation loss: 2.6296063491581214

Epoch: 5| Step: 3
Training loss: 0.3268827241783636
Validation loss: 2.6380231727897705

Epoch: 5| Step: 4
Training loss: 0.20142176764395622
Validation loss: 2.635298419909715

Epoch: 5| Step: 5
Training loss: 0.2638676799371446
Validation loss: 2.6214512081726653

Epoch: 5| Step: 6
Training loss: 0.35180497814370704
Validation loss: 2.649756873910547

Epoch: 5| Step: 7
Training loss: 0.3155446979610998
Validation loss: 2.6220102790600435

Epoch: 5| Step: 8
Training loss: 0.2515124229677119
Validation loss: 2.617358079425708

Epoch: 5| Step: 9
Training loss: 0.25953328347141535
Validation loss: 2.627030992770059

Epoch: 5| Step: 10
Training loss: 0.4262670492862487
Validation loss: 2.6213124572763777

Epoch: 410| Step: 0
Training loss: 0.42925457385875054
Validation loss: 2.6104813238928273

Epoch: 5| Step: 1
Training loss: 0.2562742582329597
Validation loss: 2.607869929086067

Epoch: 5| Step: 2
Training loss: 0.3632598173320508
Validation loss: 2.6201619627187998

Epoch: 5| Step: 3
Training loss: 0.3664507271586514
Validation loss: 2.634143427582003

Epoch: 5| Step: 4
Training loss: 0.19743571172183924
Validation loss: 2.620521277618746

Epoch: 5| Step: 5
Training loss: 0.1804171756850265
Validation loss: 2.6538252996194025

Epoch: 5| Step: 6
Training loss: 0.46763631128795996
Validation loss: 2.6518717731635437

Epoch: 5| Step: 7
Training loss: 0.26934307550898423
Validation loss: 2.6456244685569157

Epoch: 5| Step: 8
Training loss: 0.26703683721189314
Validation loss: 2.674775006355782

Epoch: 5| Step: 9
Training loss: 0.2784749722338381
Validation loss: 2.6664671406651657

Epoch: 5| Step: 10
Training loss: 0.2917513922974381
Validation loss: 2.6399450250037013

Epoch: 411| Step: 0
Training loss: 0.33270805045163415
Validation loss: 2.59886630286191

Epoch: 5| Step: 1
Training loss: 0.3220046634055017
Validation loss: 2.5926582884493574

Epoch: 5| Step: 2
Training loss: 0.2574859197942817
Validation loss: 2.6106540982823105

Epoch: 5| Step: 3
Training loss: 0.2435954377224186
Validation loss: 2.5625278402357328

Epoch: 5| Step: 4
Training loss: 0.17076870490029827
Validation loss: 2.6277798545202677

Epoch: 5| Step: 5
Training loss: 0.12468788549655226
Validation loss: 2.6322680339062954

Epoch: 5| Step: 6
Training loss: 0.3536319857298729
Validation loss: 2.61969991595994

Epoch: 5| Step: 7
Training loss: 0.39418380848559426
Validation loss: 2.6155291516190644

Epoch: 5| Step: 8
Training loss: 0.3371731080138272
Validation loss: 2.643393123691571

Epoch: 5| Step: 9
Training loss: 0.2933575656799517
Validation loss: 2.6266157019031766

Epoch: 5| Step: 10
Training loss: 0.40756244666560315
Validation loss: 2.583562033695512

Epoch: 412| Step: 0
Training loss: 0.2796329796786074
Validation loss: 2.602042987016471

Epoch: 5| Step: 1
Training loss: 0.4183069981718036
Validation loss: 2.638488884145892

Epoch: 5| Step: 2
Training loss: 0.23997798667227055
Validation loss: 2.610303733523801

Epoch: 5| Step: 3
Training loss: 0.2937888809607277
Validation loss: 2.6469760862542375

Epoch: 5| Step: 4
Training loss: 0.2586537997314198
Validation loss: 2.6240709167559713

Epoch: 5| Step: 5
Training loss: 0.34851721976385014
Validation loss: 2.600553317389493

Epoch: 5| Step: 6
Training loss: 0.4158295228582234
Validation loss: 2.6160636877901964

Epoch: 5| Step: 7
Training loss: 0.5040548829876618
Validation loss: 2.584411815417739

Epoch: 5| Step: 8
Training loss: 0.20386654953309505
Validation loss: 2.5861669580555624

Epoch: 5| Step: 9
Training loss: 0.3181861101710984
Validation loss: 2.6371615251909053

Epoch: 5| Step: 10
Training loss: 0.30396251745963215
Validation loss: 2.6356783744275285

Epoch: 413| Step: 0
Training loss: 0.30302835772262027
Validation loss: 2.678249016444529

Epoch: 5| Step: 1
Training loss: 0.2327617836442096
Validation loss: 2.6297549706317636

Epoch: 5| Step: 2
Training loss: 0.3381974255175651
Validation loss: 2.611169110963592

Epoch: 5| Step: 3
Training loss: 0.2621762561319494
Validation loss: 2.5806442834034833

Epoch: 5| Step: 4
Training loss: 0.1810347697342045
Validation loss: 2.5768696781253606

Epoch: 5| Step: 5
Training loss: 0.28999766301578195
Validation loss: 2.5425858756061728

Epoch: 5| Step: 6
Training loss: 0.4526284226333173
Validation loss: 2.525507214892428

Epoch: 5| Step: 7
Training loss: 0.43576441237514035
Validation loss: 2.554414104629223

Epoch: 5| Step: 8
Training loss: 0.3377204642959619
Validation loss: 2.5242285786797716

Epoch: 5| Step: 9
Training loss: 0.22231655811073184
Validation loss: 2.542725632093873

Epoch: 5| Step: 10
Training loss: 0.4180941170889636
Validation loss: 2.5632170687593194

Epoch: 414| Step: 0
Training loss: 0.33609620492873016
Validation loss: 2.601258136141099

Epoch: 5| Step: 1
Training loss: 0.2934773163599827
Validation loss: 2.6160601491482898

Epoch: 5| Step: 2
Training loss: 0.47860724681388433
Validation loss: 2.6374357064723375

Epoch: 5| Step: 3
Training loss: 0.3529881921271108
Validation loss: 2.625987846109773

Epoch: 5| Step: 4
Training loss: 0.3291454116179867
Validation loss: 2.6343639534068695

Epoch: 5| Step: 5
Training loss: 0.313353992873397
Validation loss: 2.6256256900891537

Epoch: 5| Step: 6
Training loss: 0.30231435618088026
Validation loss: 2.598762711169109

Epoch: 5| Step: 7
Training loss: 0.2617766330535447
Validation loss: 2.555754928612667

Epoch: 5| Step: 8
Training loss: 0.31045132492613353
Validation loss: 2.574105521703028

Epoch: 5| Step: 9
Training loss: 0.2520303386097066
Validation loss: 2.573172506029623

Epoch: 5| Step: 10
Training loss: 0.21539889484755576
Validation loss: 2.5772564829326754

Epoch: 415| Step: 0
Training loss: 0.172098361445179
Validation loss: 2.532866415210979

Epoch: 5| Step: 1
Training loss: 0.3054089441316247
Validation loss: 2.5613981129366876

Epoch: 5| Step: 2
Training loss: 0.24788448695227677
Validation loss: 2.5618897128252263

Epoch: 5| Step: 3
Training loss: 0.21496969346256567
Validation loss: 2.606768146861938

Epoch: 5| Step: 4
Training loss: 0.29079111130692314
Validation loss: 2.5962342276848425

Epoch: 5| Step: 5
Training loss: 0.24644900217769447
Validation loss: 2.600253498807361

Epoch: 5| Step: 6
Training loss: 0.2303690937338667
Validation loss: 2.6474610261030502

Epoch: 5| Step: 7
Training loss: 0.4234216736373161
Validation loss: 2.6173757119016123

Epoch: 5| Step: 8
Training loss: 0.3814456047060893
Validation loss: 2.638997537745243

Epoch: 5| Step: 9
Training loss: 0.41587800449493395
Validation loss: 2.658143089757947

Epoch: 5| Step: 10
Training loss: 0.22827123958146134
Validation loss: 2.625751941409442

Epoch: 416| Step: 0
Training loss: 0.25122509239818397
Validation loss: 2.621769244663445

Epoch: 5| Step: 1
Training loss: 0.251596331246605
Validation loss: 2.627948978658258

Epoch: 5| Step: 2
Training loss: 0.2737095977632822
Validation loss: 2.6393157184901987

Epoch: 5| Step: 3
Training loss: 0.513037402148484
Validation loss: 2.6301066343728254

Epoch: 5| Step: 4
Training loss: 0.2985801790108784
Validation loss: 2.5896418259250455

Epoch: 5| Step: 5
Training loss: 0.24330966680598382
Validation loss: 2.617472081147

Epoch: 5| Step: 6
Training loss: 0.36733405252537416
Validation loss: 2.563888747744034

Epoch: 5| Step: 7
Training loss: 0.3305867581885247
Validation loss: 2.5701870793387998

Epoch: 5| Step: 8
Training loss: 0.159066856508233
Validation loss: 2.591356734244224

Epoch: 5| Step: 9
Training loss: 0.2726750233480308
Validation loss: 2.5818172343364756

Epoch: 5| Step: 10
Training loss: 0.17699837516588457
Validation loss: 2.5617573910368288

Epoch: 417| Step: 0
Training loss: 0.2386716162122956
Validation loss: 2.5963200293841036

Epoch: 5| Step: 1
Training loss: 0.16641916148819338
Validation loss: 2.609931987058122

Epoch: 5| Step: 2
Training loss: 0.12500776326390892
Validation loss: 2.609644661165951

Epoch: 5| Step: 3
Training loss: 0.31515245093957533
Validation loss: 2.597158046987766

Epoch: 5| Step: 4
Training loss: 0.29730538492067077
Validation loss: 2.613970633549821

Epoch: 5| Step: 5
Training loss: 0.3448726139338634
Validation loss: 2.608740662852188

Epoch: 5| Step: 6
Training loss: 0.25367067118818143
Validation loss: 2.6103263026242334

Epoch: 5| Step: 7
Training loss: 0.41845968416991064
Validation loss: 2.6303105290086473

Epoch: 5| Step: 8
Training loss: 0.3853520605564524
Validation loss: 2.6131802320533737

Epoch: 5| Step: 9
Training loss: 0.38212783076317514
Validation loss: 2.5782873645119344

Epoch: 5| Step: 10
Training loss: 0.18014424779503102
Validation loss: 2.5759651307427376

Epoch: 418| Step: 0
Training loss: 0.3595392017902605
Validation loss: 2.5616950654950217

Epoch: 5| Step: 1
Training loss: 0.3385516849893924
Validation loss: 2.56882097580193

Epoch: 5| Step: 2
Training loss: 0.22578357939525004
Validation loss: 2.5857319455371255

Epoch: 5| Step: 3
Training loss: 0.23523498750452973
Validation loss: 2.5589357264195143

Epoch: 5| Step: 4
Training loss: 0.37264269758169
Validation loss: 2.570436064446193

Epoch: 5| Step: 5
Training loss: 0.1943605781154225
Validation loss: 2.6405179134974275

Epoch: 5| Step: 6
Training loss: 0.40359646485021455
Validation loss: 2.6182359917029387

Epoch: 5| Step: 7
Training loss: 0.27634003846228644
Validation loss: 2.636571197817264

Epoch: 5| Step: 8
Training loss: 0.2120707850891008
Validation loss: 2.6105717609084746

Epoch: 5| Step: 9
Training loss: 0.2971807336087103
Validation loss: 2.608456854942521

Epoch: 5| Step: 10
Training loss: 0.12046095263137589
Validation loss: 2.6281859844659294

Epoch: 419| Step: 0
Training loss: 0.37401403509926323
Validation loss: 2.6003616785462644

Epoch: 5| Step: 1
Training loss: 0.2724643283209142
Validation loss: 2.620017452700069

Epoch: 5| Step: 2
Training loss: 0.30153304435487854
Validation loss: 2.6073152261058907

Epoch: 5| Step: 3
Training loss: 0.31730061567080275
Validation loss: 2.628923964948517

Epoch: 5| Step: 4
Training loss: 0.4888607858382714
Validation loss: 2.640016272886401

Epoch: 5| Step: 5
Training loss: 0.17173974177002943
Validation loss: 2.6211910476403473

Epoch: 5| Step: 6
Training loss: 0.11732892800626699
Validation loss: 2.5577741174143753

Epoch: 5| Step: 7
Training loss: 0.22872261714675998
Validation loss: 2.6008157020067926

Epoch: 5| Step: 8
Training loss: 0.20812524695281537
Validation loss: 2.6031895795925886

Epoch: 5| Step: 9
Training loss: 0.21356079938511194
Validation loss: 2.6113911280267925

Epoch: 5| Step: 10
Training loss: 0.2825445871486772
Validation loss: 2.6216774904781155

Epoch: 420| Step: 0
Training loss: 0.3309005108226731
Validation loss: 2.639820268237736

Epoch: 5| Step: 1
Training loss: 0.2655599879197415
Validation loss: 2.658952332253783

Epoch: 5| Step: 2
Training loss: 0.2431549928498087
Validation loss: 2.647519207648198

Epoch: 5| Step: 3
Training loss: 0.34814840477798875
Validation loss: 2.595070704440718

Epoch: 5| Step: 4
Training loss: 0.21555301459798623
Validation loss: 2.6091393274747996

Epoch: 5| Step: 5
Training loss: 0.35103777827628896
Validation loss: 2.582653701198678

Epoch: 5| Step: 6
Training loss: 0.4134138893196139
Validation loss: 2.631439026975546

Epoch: 5| Step: 7
Training loss: 0.28819877871480276
Validation loss: 2.6211727845578454

Epoch: 5| Step: 8
Training loss: 0.28347758443962795
Validation loss: 2.6352555707528897

Epoch: 5| Step: 9
Training loss: 0.16712836240176418
Validation loss: 2.599562607733881

Epoch: 5| Step: 10
Training loss: 0.3515032188449927
Validation loss: 2.604248426240913

Epoch: 421| Step: 0
Training loss: 0.24881905040632282
Validation loss: 2.618474764668346

Epoch: 5| Step: 1
Training loss: 0.32768728943271774
Validation loss: 2.5995771548569593

Epoch: 5| Step: 2
Training loss: 0.4038698087740574
Validation loss: 2.616234210162541

Epoch: 5| Step: 3
Training loss: 0.31985884617306193
Validation loss: 2.6255509003050443

Epoch: 5| Step: 4
Training loss: 0.2650891818150209
Validation loss: 2.6237595245001324

Epoch: 5| Step: 5
Training loss: 0.41048697806879
Validation loss: 2.57696198513572

Epoch: 5| Step: 6
Training loss: 0.42625411487506104
Validation loss: 2.612735283590719

Epoch: 5| Step: 7
Training loss: 0.2167621876915592
Validation loss: 2.6569004717330458

Epoch: 5| Step: 8
Training loss: 0.2655595670777375
Validation loss: 2.6561823204727104

Epoch: 5| Step: 9
Training loss: 0.39533570866061485
Validation loss: 2.639666358119943

Epoch: 5| Step: 10
Training loss: 0.3040964311131273
Validation loss: 2.6405767892813956

Epoch: 422| Step: 0
Training loss: 0.297092433409313
Validation loss: 2.6435043598251133

Epoch: 5| Step: 1
Training loss: 0.30279152853657143
Validation loss: 2.6344758325485995

Epoch: 5| Step: 2
Training loss: 0.30827519114553903
Validation loss: 2.680597995435765

Epoch: 5| Step: 3
Training loss: 0.3003932506312594
Validation loss: 2.6037442093965764

Epoch: 5| Step: 4
Training loss: 0.39338648303969176
Validation loss: 2.653906903625796

Epoch: 5| Step: 5
Training loss: 0.29594325365155133
Validation loss: 2.6266422701250725

Epoch: 5| Step: 6
Training loss: 0.32340408143335564
Validation loss: 2.645324824499354

Epoch: 5| Step: 7
Training loss: 0.2847791163593669
Validation loss: 2.628106868173572

Epoch: 5| Step: 8
Training loss: 0.31662633094176545
Validation loss: 2.6054679805540903

Epoch: 5| Step: 9
Training loss: 0.3258137135602902
Validation loss: 2.5991284829734442

Epoch: 5| Step: 10
Training loss: 0.3079092304616283
Validation loss: 2.6577822392490793

Epoch: 423| Step: 0
Training loss: 0.27721690917519254
Validation loss: 2.620841886087542

Epoch: 5| Step: 1
Training loss: 0.3088375046316758
Validation loss: 2.6450124359691443

Epoch: 5| Step: 2
Training loss: 0.23210969363164716
Validation loss: 2.606891769212177

Epoch: 5| Step: 3
Training loss: 0.21873075536815914
Validation loss: 2.6387438106182044

Epoch: 5| Step: 4
Training loss: 0.34332410481505055
Validation loss: 2.623136130171162

Epoch: 5| Step: 5
Training loss: 0.35355488680323
Validation loss: 2.6591879187338545

Epoch: 5| Step: 6
Training loss: 0.3653467586825135
Validation loss: 2.6447533833959596

Epoch: 5| Step: 7
Training loss: 0.14303558590488447
Validation loss: 2.6324439915677735

Epoch: 5| Step: 8
Training loss: 0.21776924642455867
Validation loss: 2.6380279059553633

Epoch: 5| Step: 9
Training loss: 0.4107751083059994
Validation loss: 2.603168875902076

Epoch: 5| Step: 10
Training loss: 0.2747712440989954
Validation loss: 2.6045117162356846

Epoch: 424| Step: 0
Training loss: 0.1832427260619255
Validation loss: 2.6086786068023122

Epoch: 5| Step: 1
Training loss: 0.31223693742604036
Validation loss: 2.608130409899169

Epoch: 5| Step: 2
Training loss: 0.3412628688935877
Validation loss: 2.606681187778897

Epoch: 5| Step: 3
Training loss: 0.3631097942720691
Validation loss: 2.591838332342447

Epoch: 5| Step: 4
Training loss: 0.17758015869358984
Validation loss: 2.6047314231235017

Epoch: 5| Step: 5
Training loss: 0.17772734282279234
Validation loss: 2.6383532913381083

Epoch: 5| Step: 6
Training loss: 0.31248501503302467
Validation loss: 2.651588344088483

Epoch: 5| Step: 7
Training loss: 0.20144476483092869
Validation loss: 2.6317379755112786

Epoch: 5| Step: 8
Training loss: 0.44273495500592885
Validation loss: 2.635586899228536

Epoch: 5| Step: 9
Training loss: 0.2055180961763682
Validation loss: 2.66186505559968

Epoch: 5| Step: 10
Training loss: 0.30089548344494826
Validation loss: 2.6621868452194146

Epoch: 425| Step: 0
Training loss: 0.217790731248026
Validation loss: 2.6694704327613286

Epoch: 5| Step: 1
Training loss: 0.22322256447562117
Validation loss: 2.6572005653947985

Epoch: 5| Step: 2
Training loss: 0.19022137912796472
Validation loss: 2.655197189708616

Epoch: 5| Step: 3
Training loss: 0.20662121384135157
Validation loss: 2.6897072061935865

Epoch: 5| Step: 4
Training loss: 0.25819313964926743
Validation loss: 2.654558445905932

Epoch: 5| Step: 5
Training loss: 0.22916563622647593
Validation loss: 2.616446457090404

Epoch: 5| Step: 6
Training loss: 0.3180901494825367
Validation loss: 2.642525054551776

Epoch: 5| Step: 7
Training loss: 0.2978810905453395
Validation loss: 2.59956924472712

Epoch: 5| Step: 8
Training loss: 0.4376180523590828
Validation loss: 2.611503030778537

Epoch: 5| Step: 9
Training loss: 0.3399775997840045
Validation loss: 2.631442690584621

Epoch: 5| Step: 10
Training loss: 0.2754677468388165
Validation loss: 2.593667037038339

Epoch: 426| Step: 0
Training loss: 0.36413926146210435
Validation loss: 2.617382634785464

Epoch: 5| Step: 1
Training loss: 0.2628286512539809
Validation loss: 2.598836809939341

Epoch: 5| Step: 2
Training loss: 0.338215291594625
Validation loss: 2.613918243547399

Epoch: 5| Step: 3
Training loss: 0.17526346877578325
Validation loss: 2.6028450681761672

Epoch: 5| Step: 4
Training loss: 0.3332478058385767
Validation loss: 2.580170452355134

Epoch: 5| Step: 5
Training loss: 0.31045946054523194
Validation loss: 2.602540034747783

Epoch: 5| Step: 6
Training loss: 0.1484274296105187
Validation loss: 2.640727899921057

Epoch: 5| Step: 7
Training loss: 0.29923843438561815
Validation loss: 2.640479963251092

Epoch: 5| Step: 8
Training loss: 0.30747580533870117
Validation loss: 2.630896510048874

Epoch: 5| Step: 9
Training loss: 0.21853520713080737
Validation loss: 2.600637556091188

Epoch: 5| Step: 10
Training loss: 0.38508538451175084
Validation loss: 2.5601066915032966

Epoch: 427| Step: 0
Training loss: 0.2538988845930656
Validation loss: 2.5790093668600846

Epoch: 5| Step: 1
Training loss: 0.36655885572646374
Validation loss: 2.5812949283583766

Epoch: 5| Step: 2
Training loss: 0.2560598447092645
Validation loss: 2.549811476129189

Epoch: 5| Step: 3
Training loss: 0.30514755728861365
Validation loss: 2.5579216472700046

Epoch: 5| Step: 4
Training loss: 0.3942495227767291
Validation loss: 2.566260787795501

Epoch: 5| Step: 5
Training loss: 0.2355952208518987
Validation loss: 2.58347472268037

Epoch: 5| Step: 6
Training loss: 0.3231194715561882
Validation loss: 2.611109697762919

Epoch: 5| Step: 7
Training loss: 0.14325399111427267
Validation loss: 2.621295836132793

Epoch: 5| Step: 8
Training loss: 0.3700614625555133
Validation loss: 2.653577299848333

Epoch: 5| Step: 9
Training loss: 0.15831051231187648
Validation loss: 2.6497175427954516

Epoch: 5| Step: 10
Training loss: 0.20816825445861045
Validation loss: 2.6249494982352473

Epoch: 428| Step: 0
Training loss: 0.16350840482887474
Validation loss: 2.6600067702370773

Epoch: 5| Step: 1
Training loss: 0.2539011734675048
Validation loss: 2.6310321353958437

Epoch: 5| Step: 2
Training loss: 0.20730124268545766
Validation loss: 2.6600428025450955

Epoch: 5| Step: 3
Training loss: 0.26210866891052376
Validation loss: 2.6750193254295827

Epoch: 5| Step: 4
Training loss: 0.3816865985085782
Validation loss: 2.603646696949924

Epoch: 5| Step: 5
Training loss: 0.19940485395939103
Validation loss: 2.616229877053436

Epoch: 5| Step: 6
Training loss: 0.41458855806186307
Validation loss: 2.6441958198902453

Epoch: 5| Step: 7
Training loss: 0.2695784320169557
Validation loss: 2.5726542161915344

Epoch: 5| Step: 8
Training loss: 0.3806425602312001
Validation loss: 2.611356189799796

Epoch: 5| Step: 9
Training loss: 0.15167425449965277
Validation loss: 2.62248291342897

Epoch: 5| Step: 10
Training loss: 0.2982232697987914
Validation loss: 2.640544335044068

Epoch: 429| Step: 0
Training loss: 0.22751959525071497
Validation loss: 2.6031292377677677

Epoch: 5| Step: 1
Training loss: 0.21499006317707137
Validation loss: 2.5927792375822323

Epoch: 5| Step: 2
Training loss: 0.2114087509802419
Validation loss: 2.5930017636701983

Epoch: 5| Step: 3
Training loss: 0.3673380076593588
Validation loss: 2.6005394046745223

Epoch: 5| Step: 4
Training loss: 0.3124431439176307
Validation loss: 2.616546897258159

Epoch: 5| Step: 5
Training loss: 0.34234719795708857
Validation loss: 2.5466904710810785

Epoch: 5| Step: 6
Training loss: 0.2688403604212401
Validation loss: 2.5814197189612975

Epoch: 5| Step: 7
Training loss: 0.3688456249711368
Validation loss: 2.5890074177808127

Epoch: 5| Step: 8
Training loss: 0.19418392274236324
Validation loss: 2.611646209428208

Epoch: 5| Step: 9
Training loss: 0.17264353092519288
Validation loss: 2.5611909873881973

Epoch: 5| Step: 10
Training loss: 0.16485989455400715
Validation loss: 2.582879438097946

Epoch: 430| Step: 0
Training loss: 0.3468917842618982
Validation loss: 2.5916377566448654

Epoch: 5| Step: 1
Training loss: 0.2150619352616531
Validation loss: 2.595662919519556

Epoch: 5| Step: 2
Training loss: 0.2850930653423471
Validation loss: 2.582798972686625

Epoch: 5| Step: 3
Training loss: 0.22545325931199
Validation loss: 2.622353074289885

Epoch: 5| Step: 4
Training loss: 0.16557751235711782
Validation loss: 2.605170811818059

Epoch: 5| Step: 5
Training loss: 0.35005854942859127
Validation loss: 2.605976788552561

Epoch: 5| Step: 6
Training loss: 0.21859488778026126
Validation loss: 2.6062453991253816

Epoch: 5| Step: 7
Training loss: 0.3386094930146127
Validation loss: 2.623096257209797

Epoch: 5| Step: 8
Training loss: 0.22336853436866536
Validation loss: 2.5997652729590843

Epoch: 5| Step: 9
Training loss: 0.22412040394529348
Validation loss: 2.6348370708296347

Epoch: 5| Step: 10
Training loss: 0.43122895921986926
Validation loss: 2.637719808770755

Epoch: 431| Step: 0
Training loss: 0.23053809108824858
Validation loss: 2.6346264990982973

Epoch: 5| Step: 1
Training loss: 0.1589461526686803
Validation loss: 2.6324351420569436

Epoch: 5| Step: 2
Training loss: 0.41008472727284334
Validation loss: 2.6195576078695453

Epoch: 5| Step: 3
Training loss: 0.22050925829593332
Validation loss: 2.6366650599061265

Epoch: 5| Step: 4
Training loss: 0.4458097225098944
Validation loss: 2.629043914126254

Epoch: 5| Step: 5
Training loss: 0.1950576645613288
Validation loss: 2.610739307256845

Epoch: 5| Step: 6
Training loss: 0.26070358047697056
Validation loss: 2.5843299196471885

Epoch: 5| Step: 7
Training loss: 0.22148135215136228
Validation loss: 2.578796468322262

Epoch: 5| Step: 8
Training loss: 0.22451565487245717
Validation loss: 2.615772531026449

Epoch: 5| Step: 9
Training loss: 0.3990784893253032
Validation loss: 2.6055488616542286

Epoch: 5| Step: 10
Training loss: 0.2750644646210167
Validation loss: 2.6156190161704505

Epoch: 432| Step: 0
Training loss: 0.2857202674035203
Validation loss: 2.588904183190727

Epoch: 5| Step: 1
Training loss: 0.26997739383757063
Validation loss: 2.639576671248864

Epoch: 5| Step: 2
Training loss: 0.3068575850826482
Validation loss: 2.605122057164592

Epoch: 5| Step: 3
Training loss: 0.2758934084701144
Validation loss: 2.632960381609751

Epoch: 5| Step: 4
Training loss: 0.1602593648237742
Validation loss: 2.614503504716745

Epoch: 5| Step: 5
Training loss: 0.22986420043170316
Validation loss: 2.58251282016231

Epoch: 5| Step: 6
Training loss: 0.16015021382563807
Validation loss: 2.582872889731699

Epoch: 5| Step: 7
Training loss: 0.34876329987983395
Validation loss: 2.6147970283764956

Epoch: 5| Step: 8
Training loss: 0.3205496328943233
Validation loss: 2.603099310571561

Epoch: 5| Step: 9
Training loss: 0.4017789264892747
Validation loss: 2.5975030691506586

Epoch: 5| Step: 10
Training loss: 0.2686502321382858
Validation loss: 2.612616547676891

Epoch: 433| Step: 0
Training loss: 0.19167141161276677
Validation loss: 2.6115983560620584

Epoch: 5| Step: 1
Training loss: 0.27922742820535745
Validation loss: 2.629222047910683

Epoch: 5| Step: 2
Training loss: 0.12700132042046344
Validation loss: 2.6579194412669778

Epoch: 5| Step: 3
Training loss: 0.2631907559412889
Validation loss: 2.655223024913121

Epoch: 5| Step: 4
Training loss: 0.26227036036357515
Validation loss: 2.6566504314763004

Epoch: 5| Step: 5
Training loss: 0.243526104960702
Validation loss: 2.626229940981514

Epoch: 5| Step: 6
Training loss: 0.2982983724236725
Validation loss: 2.660971933487866

Epoch: 5| Step: 7
Training loss: 0.3699099682802077
Validation loss: 2.6443848821693305

Epoch: 5| Step: 8
Training loss: 0.41158594092231554
Validation loss: 2.6558218749110116

Epoch: 5| Step: 9
Training loss: 0.24487576240714903
Validation loss: 2.5946983306750764

Epoch: 5| Step: 10
Training loss: 0.27329615618280967
Validation loss: 2.566179996095082

Epoch: 434| Step: 0
Training loss: 0.3838630197333125
Validation loss: 2.5957278575598703

Epoch: 5| Step: 1
Training loss: 0.26077463183910504
Validation loss: 2.565263424136431

Epoch: 5| Step: 2
Training loss: 0.2962929516048587
Validation loss: 2.5415594890986766

Epoch: 5| Step: 3
Training loss: 0.288219408054587
Validation loss: 2.5346196638834533

Epoch: 5| Step: 4
Training loss: 0.3130540823243637
Validation loss: 2.571013481862007

Epoch: 5| Step: 5
Training loss: 0.2190696815668556
Validation loss: 2.5861325903093864

Epoch: 5| Step: 6
Training loss: 0.25275957432959006
Validation loss: 2.5831836163513073

Epoch: 5| Step: 7
Training loss: 0.28987204112870024
Validation loss: 2.622968062089231

Epoch: 5| Step: 8
Training loss: 0.34555309078759006
Validation loss: 2.6734152034698235

Epoch: 5| Step: 9
Training loss: 0.2346801519703946
Validation loss: 2.65739856380714

Epoch: 5| Step: 10
Training loss: 0.19977588912141606
Validation loss: 2.579137034329386

Epoch: 435| Step: 0
Training loss: 0.3073109146598622
Validation loss: 2.581407538405634

Epoch: 5| Step: 1
Training loss: 0.18712627398287207
Validation loss: 2.5906981250178984

Epoch: 5| Step: 2
Training loss: 0.3804165931686269
Validation loss: 2.562388833128488

Epoch: 5| Step: 3
Training loss: 0.27041500441261224
Validation loss: 2.5688706781367836

Epoch: 5| Step: 4
Training loss: 0.3284006890666356
Validation loss: 2.570808145670889

Epoch: 5| Step: 5
Training loss: 0.17435741743535227
Validation loss: 2.562927898673699

Epoch: 5| Step: 6
Training loss: 0.23672817198883933
Validation loss: 2.566145887653584

Epoch: 5| Step: 7
Training loss: 0.252199880137744
Validation loss: 2.588320044074467

Epoch: 5| Step: 8
Training loss: 0.3019355324657581
Validation loss: 2.6114323815546965

Epoch: 5| Step: 9
Training loss: 0.2502456590559877
Validation loss: 2.613760780838787

Epoch: 5| Step: 10
Training loss: 0.3387262782451497
Validation loss: 2.5959686800490727

Epoch: 436| Step: 0
Training loss: 0.2714029780153863
Validation loss: 2.60263877609447

Epoch: 5| Step: 1
Training loss: 0.13401640072758508
Validation loss: 2.6138364297576344

Epoch: 5| Step: 2
Training loss: 0.254514493864924
Validation loss: 2.630883301533863

Epoch: 5| Step: 3
Training loss: 0.388067763219288
Validation loss: 2.597376047054253

Epoch: 5| Step: 4
Training loss: 0.28200733685756524
Validation loss: 2.5998750359232385

Epoch: 5| Step: 5
Training loss: 0.13984222571112326
Validation loss: 2.5995892931760833

Epoch: 5| Step: 6
Training loss: 0.20263964179814747
Validation loss: 2.627038506958021

Epoch: 5| Step: 7
Training loss: 0.1995450321118684
Validation loss: 2.6348238665011294

Epoch: 5| Step: 8
Training loss: 0.31522771551762807
Validation loss: 2.6051663186028033

Epoch: 5| Step: 9
Training loss: 0.26950426934139154
Validation loss: 2.603061144723082

Epoch: 5| Step: 10
Training loss: 0.2284583892220969
Validation loss: 2.6029190842185685

Epoch: 437| Step: 0
Training loss: 0.3305136949894637
Validation loss: 2.5918883882842945

Epoch: 5| Step: 1
Training loss: 0.23444895372299657
Validation loss: 2.616824480696397

Epoch: 5| Step: 2
Training loss: 0.3685784676404804
Validation loss: 2.598930999088004

Epoch: 5| Step: 3
Training loss: 0.1846498792191355
Validation loss: 2.6210715641065567

Epoch: 5| Step: 4
Training loss: 0.35305817655407
Validation loss: 2.616652145081572

Epoch: 5| Step: 5
Training loss: 0.13443154930501044
Validation loss: 2.6632729859444195

Epoch: 5| Step: 6
Training loss: 0.21071736894042106
Validation loss: 2.6671796530890677

Epoch: 5| Step: 7
Training loss: 0.19059439163237607
Validation loss: 2.6186727375499146

Epoch: 5| Step: 8
Training loss: 0.2408656687846851
Validation loss: 2.685494127697105

Epoch: 5| Step: 9
Training loss: 0.2513008990614004
Validation loss: 2.646363969559834

Epoch: 5| Step: 10
Training loss: 0.1839725360989439
Validation loss: 2.6827948100245784

Epoch: 438| Step: 0
Training loss: 0.2390569115901825
Validation loss: 2.599997158932455

Epoch: 5| Step: 1
Training loss: 0.39316829521830493
Validation loss: 2.605582030719857

Epoch: 5| Step: 2
Training loss: 0.34156008556381645
Validation loss: 2.6330850943959265

Epoch: 5| Step: 3
Training loss: 0.28444408950347866
Validation loss: 2.6398520700369805

Epoch: 5| Step: 4
Training loss: 0.2597758068871396
Validation loss: 2.5916545771456088

Epoch: 5| Step: 5
Training loss: 0.20457292728089627
Validation loss: 2.6057055976752173

Epoch: 5| Step: 6
Training loss: 0.16854067398288994
Validation loss: 2.6393874461856055

Epoch: 5| Step: 7
Training loss: 0.16922224093153518
Validation loss: 2.5762915770939254

Epoch: 5| Step: 8
Training loss: 0.2632277810790279
Validation loss: 2.621701957466621

Epoch: 5| Step: 9
Training loss: 0.18721791744667882
Validation loss: 2.625819022310894

Epoch: 5| Step: 10
Training loss: 0.31276114996009685
Validation loss: 2.6110435683795314

Epoch: 439| Step: 0
Training loss: 0.27998515332404017
Validation loss: 2.6355789940675654

Epoch: 5| Step: 1
Training loss: 0.21576557932583942
Validation loss: 2.590871350883821

Epoch: 5| Step: 2
Training loss: 0.1981708229035209
Validation loss: 2.5562550030582707

Epoch: 5| Step: 3
Training loss: 0.10749330313332553
Validation loss: 2.5753406453456384

Epoch: 5| Step: 4
Training loss: 0.2072362604487613
Validation loss: 2.568548661104466

Epoch: 5| Step: 5
Training loss: 0.28674506084907714
Validation loss: 2.5541550853348713

Epoch: 5| Step: 6
Training loss: 0.3133053534883803
Validation loss: 2.537121314535115

Epoch: 5| Step: 7
Training loss: 0.32454126472062983
Validation loss: 2.6002076699072716

Epoch: 5| Step: 8
Training loss: 0.3234585041099909
Validation loss: 2.5750978220490315

Epoch: 5| Step: 9
Training loss: 0.2723397426343224
Validation loss: 2.5817032986260315

Epoch: 5| Step: 10
Training loss: 0.19872181754062448
Validation loss: 2.5946740032783646

Epoch: 440| Step: 0
Training loss: 0.23542752761318428
Validation loss: 2.6360980308269255

Epoch: 5| Step: 1
Training loss: 0.23770686789943277
Validation loss: 2.601549456902818

Epoch: 5| Step: 2
Training loss: 0.23937270850636053
Validation loss: 2.6399944475121155

Epoch: 5| Step: 3
Training loss: 0.3783602369016274
Validation loss: 2.6267539247734035

Epoch: 5| Step: 4
Training loss: 0.2848646031173465
Validation loss: 2.620813183356755

Epoch: 5| Step: 5
Training loss: 0.1690388073510913
Validation loss: 2.654821850891316

Epoch: 5| Step: 6
Training loss: 0.26264568838639635
Validation loss: 2.632692140695913

Epoch: 5| Step: 7
Training loss: 0.2124799389345605
Validation loss: 2.6155513423783368

Epoch: 5| Step: 8
Training loss: 0.20458913361419304
Validation loss: 2.550542479191096

Epoch: 5| Step: 9
Training loss: 0.1677075950732676
Validation loss: 2.55984008888268

Epoch: 5| Step: 10
Training loss: 0.2933960913222912
Validation loss: 2.61888649405846

Epoch: 441| Step: 0
Training loss: 0.3069163498144476
Validation loss: 2.5836785893218424

Epoch: 5| Step: 1
Training loss: 0.31790291060029935
Validation loss: 2.580408005655166

Epoch: 5| Step: 2
Training loss: 0.1960090994024248
Validation loss: 2.6062838336004317

Epoch: 5| Step: 3
Training loss: 0.16604281932027082
Validation loss: 2.6194639098560466

Epoch: 5| Step: 4
Training loss: 0.14457300588206176
Validation loss: 2.6146095848816526

Epoch: 5| Step: 5
Training loss: 0.17524364170567835
Validation loss: 2.5961732423147366

Epoch: 5| Step: 6
Training loss: 0.20284102837301876
Validation loss: 2.6204113923376506

Epoch: 5| Step: 7
Training loss: 0.34741282781337673
Validation loss: 2.6285022726960263

Epoch: 5| Step: 8
Training loss: 0.226251898989427
Validation loss: 2.624267433910491

Epoch: 5| Step: 9
Training loss: 0.32698053634752045
Validation loss: 2.603570918368008

Epoch: 5| Step: 10
Training loss: 0.17839762838475431
Validation loss: 2.598759287077148

Epoch: 442| Step: 0
Training loss: 0.31805520065756093
Validation loss: 2.592256264406626

Epoch: 5| Step: 1
Training loss: 0.17644646131383468
Validation loss: 2.553801365156801

Epoch: 5| Step: 2
Training loss: 0.2876135493033762
Validation loss: 2.5928356042927594

Epoch: 5| Step: 3
Training loss: 0.20314645653886854
Validation loss: 2.537058135204418

Epoch: 5| Step: 4
Training loss: 0.23692569373905623
Validation loss: 2.544178833402688

Epoch: 5| Step: 5
Training loss: 0.2972138879895926
Validation loss: 2.505317561955374

Epoch: 5| Step: 6
Training loss: 0.34321138058985684
Validation loss: 2.5287383463399338

Epoch: 5| Step: 7
Training loss: 0.2312205466638748
Validation loss: 2.529710506841882

Epoch: 5| Step: 8
Training loss: 0.34308817398330865
Validation loss: 2.5534172943205844

Epoch: 5| Step: 9
Training loss: 0.19961350729709249
Validation loss: 2.5950031813798553

Epoch: 5| Step: 10
Training loss: 0.24168551627726823
Validation loss: 2.623286737538268

Epoch: 443| Step: 0
Training loss: 0.18132588590187004
Validation loss: 2.652124631242932

Epoch: 5| Step: 1
Training loss: 0.3018201745045563
Validation loss: 2.658280330050733

Epoch: 5| Step: 2
Training loss: 0.2683753784827312
Validation loss: 2.7072648154787595

Epoch: 5| Step: 3
Training loss: 0.1825136309262428
Validation loss: 2.686034257651165

Epoch: 5| Step: 4
Training loss: 0.2910024524754154
Validation loss: 2.6620443160702765

Epoch: 5| Step: 5
Training loss: 0.38240578513348267
Validation loss: 2.6096287309804937

Epoch: 5| Step: 6
Training loss: 0.33930024720021895
Validation loss: 2.612223675031071

Epoch: 5| Step: 7
Training loss: 0.24435817943548593
Validation loss: 2.558006284181528

Epoch: 5| Step: 8
Training loss: 0.24489655766906665
Validation loss: 2.5269206988944273

Epoch: 5| Step: 9
Training loss: 0.31624272912981605
Validation loss: 2.5494666980936804

Epoch: 5| Step: 10
Training loss: 0.2643198175984627
Validation loss: 2.5239162328117857

Epoch: 444| Step: 0
Training loss: 0.2369054096148145
Validation loss: 2.5446647879543978

Epoch: 5| Step: 1
Training loss: 0.3473572248692863
Validation loss: 2.480388685734408

Epoch: 5| Step: 2
Training loss: 0.30866247932811886
Validation loss: 2.5241994055210517

Epoch: 5| Step: 3
Training loss: 0.33449976456210484
Validation loss: 2.529950487789768

Epoch: 5| Step: 4
Training loss: 0.19557954651676437
Validation loss: 2.5821358167441044

Epoch: 5| Step: 5
Training loss: 0.2533977110893337
Validation loss: 2.5631957291447565

Epoch: 5| Step: 6
Training loss: 0.2700687246366716
Validation loss: 2.6204908857564493

Epoch: 5| Step: 7
Training loss: 0.3236240655134846
Validation loss: 2.6155709051799776

Epoch: 5| Step: 8
Training loss: 0.2439038616359178
Validation loss: 2.629734412722134

Epoch: 5| Step: 9
Training loss: 0.23872623168011567
Validation loss: 2.599285800439529

Epoch: 5| Step: 10
Training loss: 0.26783474221113196
Validation loss: 2.5872711300769695

Epoch: 445| Step: 0
Training loss: 0.2871352463049441
Validation loss: 2.5826475160628544

Epoch: 5| Step: 1
Training loss: 0.2253854116302977
Validation loss: 2.5261097861517015

Epoch: 5| Step: 2
Training loss: 0.38545939062636936
Validation loss: 2.5455817180139713

Epoch: 5| Step: 3
Training loss: 0.2574101111078584
Validation loss: 2.545573301713659

Epoch: 5| Step: 4
Training loss: 0.38388665974882685
Validation loss: 2.553033858572629

Epoch: 5| Step: 5
Training loss: 0.26914532993672236
Validation loss: 2.5686669005113916

Epoch: 5| Step: 6
Training loss: 0.2137241843456215
Validation loss: 2.564670612846662

Epoch: 5| Step: 7
Training loss: 0.24491941216552307
Validation loss: 2.590583204351864

Epoch: 5| Step: 8
Training loss: 0.18285247618331438
Validation loss: 2.606409472661245

Epoch: 5| Step: 9
Training loss: 0.21990054553928334
Validation loss: 2.6207857915828945

Epoch: 5| Step: 10
Training loss: 0.22314385512101392
Validation loss: 2.6417862383125157

Epoch: 446| Step: 0
Training loss: 0.200409583817815
Validation loss: 2.6132619427793435

Epoch: 5| Step: 1
Training loss: 0.14788573385453938
Validation loss: 2.622747070716863

Epoch: 5| Step: 2
Training loss: 0.21679958135616784
Validation loss: 2.5911254017944136

Epoch: 5| Step: 3
Training loss: 0.23653417069946067
Validation loss: 2.6032610766204365

Epoch: 5| Step: 4
Training loss: 0.19633675939940354
Validation loss: 2.6285105941449007

Epoch: 5| Step: 5
Training loss: 0.23769805235839148
Validation loss: 2.618132358581879

Epoch: 5| Step: 6
Training loss: 0.42435875649468413
Validation loss: 2.601312801428887

Epoch: 5| Step: 7
Training loss: 0.23461225739701827
Validation loss: 2.6218093583032216

Epoch: 5| Step: 8
Training loss: 0.22008520738542126
Validation loss: 2.614063389367699

Epoch: 5| Step: 9
Training loss: 0.2916747444033351
Validation loss: 2.6350600039249272

Epoch: 5| Step: 10
Training loss: 0.3767883256784288
Validation loss: 2.5743610538750743

Epoch: 447| Step: 0
Training loss: 0.3377767602539387
Validation loss: 2.609828508470176

Epoch: 5| Step: 1
Training loss: 0.17271891315536012
Validation loss: 2.600947576320279

Epoch: 5| Step: 2
Training loss: 0.17625301421070289
Validation loss: 2.6094822032929694

Epoch: 5| Step: 3
Training loss: 0.2952210506754573
Validation loss: 2.607024614539167

Epoch: 5| Step: 4
Training loss: 0.3395046098512711
Validation loss: 2.6071996524322834

Epoch: 5| Step: 5
Training loss: 0.40947197646365063
Validation loss: 2.5856519084801355

Epoch: 5| Step: 6
Training loss: 0.26252641885510436
Validation loss: 2.605817242837831

Epoch: 5| Step: 7
Training loss: 0.21340986677549595
Validation loss: 2.562780426432207

Epoch: 5| Step: 8
Training loss: 0.20597058428417966
Validation loss: 2.5738005903104946

Epoch: 5| Step: 9
Training loss: 0.24215824965762564
Validation loss: 2.5704532338777755

Epoch: 5| Step: 10
Training loss: 0.22924343181673204
Validation loss: 2.55584489677425

Epoch: 448| Step: 0
Training loss: 0.28953034970534164
Validation loss: 2.5563577580273753

Epoch: 5| Step: 1
Training loss: 0.24059765957659585
Validation loss: 2.553711329016423

Epoch: 5| Step: 2
Training loss: 0.3436541315256085
Validation loss: 2.5459242862613114

Epoch: 5| Step: 3
Training loss: 0.28261282336827204
Validation loss: 2.5484653935048596

Epoch: 5| Step: 4
Training loss: 0.17077030282913327
Validation loss: 2.576119044693568

Epoch: 5| Step: 5
Training loss: 0.2344764728227582
Validation loss: 2.5957087298955517

Epoch: 5| Step: 6
Training loss: 0.340493490922922
Validation loss: 2.6198942955802598

Epoch: 5| Step: 7
Training loss: 0.2842935812377496
Validation loss: 2.625050255665008

Epoch: 5| Step: 8
Training loss: 0.2720501034386061
Validation loss: 2.6178405524884445

Epoch: 5| Step: 9
Training loss: 0.18390397990080756
Validation loss: 2.6124313058529336

Epoch: 5| Step: 10
Training loss: 0.14453719101113766
Validation loss: 2.5760340758675344

Epoch: 449| Step: 0
Training loss: 0.18887303214117848
Validation loss: 2.5491224315866785

Epoch: 5| Step: 1
Training loss: 0.23654902199329528
Validation loss: 2.53749397439169

Epoch: 5| Step: 2
Training loss: 0.19980064194089753
Validation loss: 2.5476245955983163

Epoch: 5| Step: 3
Training loss: 0.29280973569528007
Validation loss: 2.5331209287857175

Epoch: 5| Step: 4
Training loss: 0.3429753287690216
Validation loss: 2.497080679684804

Epoch: 5| Step: 5
Training loss: 0.21948793805311825
Validation loss: 2.571613916739952

Epoch: 5| Step: 6
Training loss: 0.3226243652217788
Validation loss: 2.492620794044049

Epoch: 5| Step: 7
Training loss: 0.19602742004180201
Validation loss: 2.503928332439153

Epoch: 5| Step: 8
Training loss: 0.3222788143348888
Validation loss: 2.535078733549614

Epoch: 5| Step: 9
Training loss: 0.24836294807006992
Validation loss: 2.563530767396067

Epoch: 5| Step: 10
Training loss: 0.2540887176996823
Validation loss: 2.5638986887626567

Epoch: 450| Step: 0
Training loss: 0.21408133041090321
Validation loss: 2.562139778419654

Epoch: 5| Step: 1
Training loss: 0.32537866412432365
Validation loss: 2.5943425397802526

Epoch: 5| Step: 2
Training loss: 0.1665772419179637
Validation loss: 2.6028141074555293

Epoch: 5| Step: 3
Training loss: 0.23794920251804458
Validation loss: 2.610309083636077

Epoch: 5| Step: 4
Training loss: 0.3507038013964151
Validation loss: 2.5988164247264995

Epoch: 5| Step: 5
Training loss: 0.2559655093142879
Validation loss: 2.5920452332728208

Epoch: 5| Step: 6
Training loss: 0.24604214021140278
Validation loss: 2.601737036284431

Epoch: 5| Step: 7
Training loss: 0.19006028169606265
Validation loss: 2.6005976132116495

Epoch: 5| Step: 8
Training loss: 0.22133478566013057
Validation loss: 2.591405971456759

Epoch: 5| Step: 9
Training loss: 0.2289024811652505
Validation loss: 2.590497532290479

Epoch: 5| Step: 10
Training loss: 0.26746339496270805
Validation loss: 2.5958873004709253

Epoch: 451| Step: 0
Training loss: 0.1837789838826641
Validation loss: 2.5956405379882446

Epoch: 5| Step: 1
Training loss: 0.3381799109993967
Validation loss: 2.589247785118986

Epoch: 5| Step: 2
Training loss: 0.15416184081652154
Validation loss: 2.629809146894851

Epoch: 5| Step: 3
Training loss: 0.18480144137456694
Validation loss: 2.6103336704406193

Epoch: 5| Step: 4
Training loss: 0.26262828439749514
Validation loss: 2.596999491067804

Epoch: 5| Step: 5
Training loss: 0.2535238761323229
Validation loss: 2.606093791684123

Epoch: 5| Step: 6
Training loss: 0.2986571626983552
Validation loss: 2.655152097704878

Epoch: 5| Step: 7
Training loss: 0.21454351427622773
Validation loss: 2.663971005357387

Epoch: 5| Step: 8
Training loss: 0.29916599595482607
Validation loss: 2.6333579029818175

Epoch: 5| Step: 9
Training loss: 0.30465633281832244
Validation loss: 2.6275292461914868

Epoch: 5| Step: 10
Training loss: 0.16485809245698482
Validation loss: 2.631952581503904

Epoch: 452| Step: 0
Training loss: 0.20747635336077247
Validation loss: 2.581867314769493

Epoch: 5| Step: 1
Training loss: 0.2721914236791055
Validation loss: 2.615897234142809

Epoch: 5| Step: 2
Training loss: 0.16744197258452478
Validation loss: 2.539667305045194

Epoch: 5| Step: 3
Training loss: 0.32409608197920403
Validation loss: 2.5548823370356906

Epoch: 5| Step: 4
Training loss: 0.32680096748884696
Validation loss: 2.5719328210677843

Epoch: 5| Step: 5
Training loss: 0.23208572217104523
Validation loss: 2.570433797454294

Epoch: 5| Step: 6
Training loss: 0.2020587630098912
Validation loss: 2.6322925280919827

Epoch: 5| Step: 7
Training loss: 0.17628112818222286
Validation loss: 2.6275250644026356

Epoch: 5| Step: 8
Training loss: 0.21643869349629513
Validation loss: 2.6131282382504164

Epoch: 5| Step: 9
Training loss: 0.3661505077094434
Validation loss: 2.629836486113741

Epoch: 5| Step: 10
Training loss: 0.1421914605752358
Validation loss: 2.637384475653076

Epoch: 453| Step: 0
Training loss: 0.36629218662488167
Validation loss: 2.6587839653147847

Epoch: 5| Step: 1
Training loss: 0.24618427942682083
Validation loss: 2.6619937750560805

Epoch: 5| Step: 2
Training loss: 0.2055693782491885
Validation loss: 2.6218537315941313

Epoch: 5| Step: 3
Training loss: 0.15663584513993678
Validation loss: 2.6878468145909

Epoch: 5| Step: 4
Training loss: 0.2774565561328055
Validation loss: 2.641816489508704

Epoch: 5| Step: 5
Training loss: 0.19081769685699826
Validation loss: 2.61445224421735

Epoch: 5| Step: 6
Training loss: 0.17454380408602532
Validation loss: 2.6543814527410463

Epoch: 5| Step: 7
Training loss: 0.23454362842949955
Validation loss: 2.609093459121646

Epoch: 5| Step: 8
Training loss: 0.23227300604606035
Validation loss: 2.620784676928986

Epoch: 5| Step: 9
Training loss: 0.2631179784395173
Validation loss: 2.6342551243704957

Epoch: 5| Step: 10
Training loss: 0.2909306267644533
Validation loss: 2.6068864086446086

Epoch: 454| Step: 0
Training loss: 0.31049501237917676
Validation loss: 2.594794485980708

Epoch: 5| Step: 1
Training loss: 0.20359763764587552
Validation loss: 2.6638269153975727

Epoch: 5| Step: 2
Training loss: 0.2889372064356681
Validation loss: 2.657072327232419

Epoch: 5| Step: 3
Training loss: 0.2172667249084526
Validation loss: 2.6076873456115766

Epoch: 5| Step: 4
Training loss: 0.18694136767912384
Validation loss: 2.671121793004676

Epoch: 5| Step: 5
Training loss: 0.25848601249172
Validation loss: 2.6106794217612475

Epoch: 5| Step: 6
Training loss: 0.17943985085722883
Validation loss: 2.623837681969856

Epoch: 5| Step: 7
Training loss: 0.21537059862407362
Validation loss: 2.6291279776304206

Epoch: 5| Step: 8
Training loss: 0.3181570849698535
Validation loss: 2.6073480644562017

Epoch: 5| Step: 9
Training loss: 0.26361730505365216
Validation loss: 2.612824960673585

Epoch: 5| Step: 10
Training loss: 0.1958107315541274
Validation loss: 2.5521428166368305

Epoch: 455| Step: 0
Training loss: 0.2194831856617776
Validation loss: 2.5750635539677535

Epoch: 5| Step: 1
Training loss: 0.2633524337211402
Validation loss: 2.5559732358262606

Epoch: 5| Step: 2
Training loss: 0.2451285705354993
Validation loss: 2.5650314454836507

Epoch: 5| Step: 3
Training loss: 0.2329904749672129
Validation loss: 2.5786617005057084

Epoch: 5| Step: 4
Training loss: 0.2185035577578239
Validation loss: 2.6055660210888947

Epoch: 5| Step: 5
Training loss: 0.2847169078289582
Validation loss: 2.566992062103932

Epoch: 5| Step: 6
Training loss: 0.24596094150626208
Validation loss: 2.5806043380346337

Epoch: 5| Step: 7
Training loss: 0.2817192137297052
Validation loss: 2.633405145795518

Epoch: 5| Step: 8
Training loss: 0.3684191642126646
Validation loss: 2.6458015029797375

Epoch: 5| Step: 9
Training loss: 0.27111143114986536
Validation loss: 2.664615760221129

Epoch: 5| Step: 10
Training loss: 0.2645250856432746
Validation loss: 2.635020820227356

Epoch: 456| Step: 0
Training loss: 0.25838461887262343
Validation loss: 2.6102290969635953

Epoch: 5| Step: 1
Training loss: 0.19700333181942717
Validation loss: 2.5972814358148764

Epoch: 5| Step: 2
Training loss: 0.24199888360193567
Validation loss: 2.5336123681849085

Epoch: 5| Step: 3
Training loss: 0.20051454352550402
Validation loss: 2.5259141851559477

Epoch: 5| Step: 4
Training loss: 0.16757709285000294
Validation loss: 2.523513084708786

Epoch: 5| Step: 5
Training loss: 0.2225092603465528
Validation loss: 2.544956225081527

Epoch: 5| Step: 6
Training loss: 0.21140905935221027
Validation loss: 2.5217225255634506

Epoch: 5| Step: 7
Training loss: 0.226269063344051
Validation loss: 2.5676965633149944

Epoch: 5| Step: 8
Training loss: 0.2787511469086116
Validation loss: 2.593555079881435

Epoch: 5| Step: 9
Training loss: 0.42845006839450267
Validation loss: 2.570620620601063

Epoch: 5| Step: 10
Training loss: 0.13500088736675167
Validation loss: 2.617243151011075

Epoch: 457| Step: 0
Training loss: 0.349593977349336
Validation loss: 2.624996642361089

Epoch: 5| Step: 1
Training loss: 0.2704218648715565
Validation loss: 2.632395203485115

Epoch: 5| Step: 2
Training loss: 0.15425914592847625
Validation loss: 2.6332759055603088

Epoch: 5| Step: 3
Training loss: 0.2686160763021168
Validation loss: 2.614900211326742

Epoch: 5| Step: 4
Training loss: 0.19990204520825194
Validation loss: 2.584724634800987

Epoch: 5| Step: 5
Training loss: 0.23584176293770986
Validation loss: 2.567377566152788

Epoch: 5| Step: 6
Training loss: 0.2882332118257958
Validation loss: 2.555970825616613

Epoch: 5| Step: 7
Training loss: 0.18110543026584427
Validation loss: 2.565298633606993

Epoch: 5| Step: 8
Training loss: 0.1871874807513805
Validation loss: 2.6097266392742475

Epoch: 5| Step: 9
Training loss: 0.2993742620861221
Validation loss: 2.6053440023357806

Epoch: 5| Step: 10
Training loss: 0.20371990933873246
Validation loss: 2.625495124644467

Epoch: 458| Step: 0
Training loss: 0.2613578272021273
Validation loss: 2.6078194622697253

Epoch: 5| Step: 1
Training loss: 0.24916742687258217
Validation loss: 2.5856719671788144

Epoch: 5| Step: 2
Training loss: 0.1909919458858135
Validation loss: 2.581245044394716

Epoch: 5| Step: 3
Training loss: 0.35117281403378886
Validation loss: 2.5455553199233925

Epoch: 5| Step: 4
Training loss: 0.23019569191091444
Validation loss: 2.6078216697279846

Epoch: 5| Step: 5
Training loss: 0.24725216743041878
Validation loss: 2.5837415107426334

Epoch: 5| Step: 6
Training loss: 0.17321892402594763
Validation loss: 2.585720293914582

Epoch: 5| Step: 7
Training loss: 0.2838244626779946
Validation loss: 2.557499364960424

Epoch: 5| Step: 8
Training loss: 0.30715692389314647
Validation loss: 2.592544815331627

Epoch: 5| Step: 9
Training loss: 0.23198794079548624
Validation loss: 2.582628394012783

Epoch: 5| Step: 10
Training loss: 0.24900422115606727
Validation loss: 2.592135398673592

Epoch: 459| Step: 0
Training loss: 0.3919094901292019
Validation loss: 2.573325848052737

Epoch: 5| Step: 1
Training loss: 0.18018393769449412
Validation loss: 2.6045187530410985

Epoch: 5| Step: 2
Training loss: 0.23031337802569493
Validation loss: 2.556878858426166

Epoch: 5| Step: 3
Training loss: 0.13777203147350275
Validation loss: 2.6108079198032708

Epoch: 5| Step: 4
Training loss: 0.39433134320980373
Validation loss: 2.5543508772946453

Epoch: 5| Step: 5
Training loss: 0.16422687538545075
Validation loss: 2.5521609112264354

Epoch: 5| Step: 6
Training loss: 0.1926679579649318
Validation loss: 2.5748726942844264

Epoch: 5| Step: 7
Training loss: 0.2188215649570418
Validation loss: 2.564606097454812

Epoch: 5| Step: 8
Training loss: 0.19903179821238978
Validation loss: 2.5641807498540006

Epoch: 5| Step: 9
Training loss: 0.20970498385926134
Validation loss: 2.554240417646914

Epoch: 5| Step: 10
Training loss: 0.19260592037583318
Validation loss: 2.59562037656806

Epoch: 460| Step: 0
Training loss: 0.166700409413998
Validation loss: 2.6145951753243653

Epoch: 5| Step: 1
Training loss: 0.20492698913196136
Validation loss: 2.5815811682121432

Epoch: 5| Step: 2
Training loss: 0.1880413030187955
Validation loss: 2.6086575073894167

Epoch: 5| Step: 3
Training loss: 0.21327743037789434
Validation loss: 2.566380636503477

Epoch: 5| Step: 4
Training loss: 0.2820458014794663
Validation loss: 2.599017198047947

Epoch: 5| Step: 5
Training loss: 0.22311070559364213
Validation loss: 2.576035595520606

Epoch: 5| Step: 6
Training loss: 0.1472676760179077
Validation loss: 2.5705792399336023

Epoch: 5| Step: 7
Training loss: 0.3038204032640617
Validation loss: 2.526174528135394

Epoch: 5| Step: 8
Training loss: 0.2526302553580615
Validation loss: 2.523796209199263

Epoch: 5| Step: 9
Training loss: 0.2653934647725704
Validation loss: 2.517493526062922

Epoch: 5| Step: 10
Training loss: 0.2873434423141118
Validation loss: 2.5323913241446037

Epoch: 461| Step: 0
Training loss: 0.30556115803976897
Validation loss: 2.513410199236998

Epoch: 5| Step: 1
Training loss: 0.17346802391335978
Validation loss: 2.5167068033563447

Epoch: 5| Step: 2
Training loss: 0.15291453075692926
Validation loss: 2.5058787127764135

Epoch: 5| Step: 3
Training loss: 0.25890192413860114
Validation loss: 2.557991651981224

Epoch: 5| Step: 4
Training loss: 0.2896546407538207
Validation loss: 2.55085313456978

Epoch: 5| Step: 5
Training loss: 0.16508710037940413
Validation loss: 2.541532913056189

Epoch: 5| Step: 6
Training loss: 0.19663637663624822
Validation loss: 2.587477559987147

Epoch: 5| Step: 7
Training loss: 0.2237743862411534
Validation loss: 2.6165592258023764

Epoch: 5| Step: 8
Training loss: 0.26023463881063247
Validation loss: 2.6369003178692445

Epoch: 5| Step: 9
Training loss: 0.27716292275553217
Validation loss: 2.627798160462163

Epoch: 5| Step: 10
Training loss: 0.1623179862935341
Validation loss: 2.640268106426262

Epoch: 462| Step: 0
Training loss: 0.12959468404186308
Validation loss: 2.668802806161497

Epoch: 5| Step: 1
Training loss: 0.3437824559061846
Validation loss: 2.60455237864888

Epoch: 5| Step: 2
Training loss: 0.13339883740031452
Validation loss: 2.6095811294429754

Epoch: 5| Step: 3
Training loss: 0.3264554213231899
Validation loss: 2.603905587840076

Epoch: 5| Step: 4
Training loss: 0.1886207542902232
Validation loss: 2.6150679097394414

Epoch: 5| Step: 5
Training loss: 0.14441695720401615
Validation loss: 2.556557324194129

Epoch: 5| Step: 6
Training loss: 0.12425872681277456
Validation loss: 2.5904415927075477

Epoch: 5| Step: 7
Training loss: 0.2596736687834054
Validation loss: 2.5753610362042143

Epoch: 5| Step: 8
Training loss: 0.2369652820893308
Validation loss: 2.5648977325376836

Epoch: 5| Step: 9
Training loss: 0.24052153846342186
Validation loss: 2.5777956029054434

Epoch: 5| Step: 10
Training loss: 0.2860820582035744
Validation loss: 2.5992965992685786

Epoch: 463| Step: 0
Training loss: 0.2131537115496485
Validation loss: 2.59770680669105

Epoch: 5| Step: 1
Training loss: 0.1604065218933762
Validation loss: 2.584513295197756

Epoch: 5| Step: 2
Training loss: 0.255066786977032
Validation loss: 2.6082273748227074

Epoch: 5| Step: 3
Training loss: 0.14498044781361608
Validation loss: 2.6254964438156954

Epoch: 5| Step: 4
Training loss: 0.2045947873194268
Validation loss: 2.60028914398969

Epoch: 5| Step: 5
Training loss: 0.2494056535944794
Validation loss: 2.585230452930489

Epoch: 5| Step: 6
Training loss: 0.2822303375730843
Validation loss: 2.5947639113471714

Epoch: 5| Step: 7
Training loss: 0.21154829180408066
Validation loss: 2.5398846321205792

Epoch: 5| Step: 8
Training loss: 0.14108555927349486
Validation loss: 2.5518493511598748

Epoch: 5| Step: 9
Training loss: 0.31508323373963654
Validation loss: 2.540057798419507

Epoch: 5| Step: 10
Training loss: 0.28033115709745654
Validation loss: 2.5063352773222713

Epoch: 464| Step: 0
Training loss: 0.23181084848218286
Validation loss: 2.5061893428278545

Epoch: 5| Step: 1
Training loss: 0.13366754958502503
Validation loss: 2.5462236656784323

Epoch: 5| Step: 2
Training loss: 0.17522209030880792
Validation loss: 2.544224864936455

Epoch: 5| Step: 3
Training loss: 0.28439393766456655
Validation loss: 2.54878172196703

Epoch: 5| Step: 4
Training loss: 0.23614555589541536
Validation loss: 2.561582573655895

Epoch: 5| Step: 5
Training loss: 0.2110453877226117
Validation loss: 2.568724423087485

Epoch: 5| Step: 6
Training loss: 0.13724458255264274
Validation loss: 2.5992076419727463

Epoch: 5| Step: 7
Training loss: 0.29969712356295025
Validation loss: 2.612967426460061

Epoch: 5| Step: 8
Training loss: 0.31936542713129257
Validation loss: 2.6414562600642078

Epoch: 5| Step: 9
Training loss: 0.1920324126255731
Validation loss: 2.598650245983988

Epoch: 5| Step: 10
Training loss: 0.2560384429504182
Validation loss: 2.6016664679775134

Epoch: 465| Step: 0
Training loss: 0.26687543726043256
Validation loss: 2.5679001052118275

Epoch: 5| Step: 1
Training loss: 0.3257929262406132
Validation loss: 2.5747522611085447

Epoch: 5| Step: 2
Training loss: 0.23577262283731015
Validation loss: 2.553423269140136

Epoch: 5| Step: 3
Training loss: 0.1830000306778241
Validation loss: 2.556945721911221

Epoch: 5| Step: 4
Training loss: 0.1814319375716696
Validation loss: 2.504962760639159

Epoch: 5| Step: 5
Training loss: 0.23091932476877755
Validation loss: 2.509441195574326

Epoch: 5| Step: 6
Training loss: 0.20688767222923443
Validation loss: 2.539002740376021

Epoch: 5| Step: 7
Training loss: 0.22964835838995226
Validation loss: 2.5621005911783823

Epoch: 5| Step: 8
Training loss: 0.23084360285034283
Validation loss: 2.5600784429073538

Epoch: 5| Step: 9
Training loss: 0.26084664927537493
Validation loss: 2.559426574255505

Epoch: 5| Step: 10
Training loss: 0.1242321203641576
Validation loss: 2.59495303634359

Epoch: 466| Step: 0
Training loss: 0.14539526100290193
Validation loss: 2.5618832053724887

Epoch: 5| Step: 1
Training loss: 0.18623896570930232
Validation loss: 2.5803235615669675

Epoch: 5| Step: 2
Training loss: 0.19609442592975493
Validation loss: 2.5944221822528597

Epoch: 5| Step: 3
Training loss: 0.15841661577066724
Validation loss: 2.595595544215162

Epoch: 5| Step: 4
Training loss: 0.24002875080106278
Validation loss: 2.5726544573436496

Epoch: 5| Step: 5
Training loss: 0.15952496438715766
Validation loss: 2.634337898064848

Epoch: 5| Step: 6
Training loss: 0.2195105020214593
Validation loss: 2.5881310950674647

Epoch: 5| Step: 7
Training loss: 0.3192986982838147
Validation loss: 2.602532342455238

Epoch: 5| Step: 8
Training loss: 0.22916691230991953
Validation loss: 2.5619682552652137

Epoch: 5| Step: 9
Training loss: 0.2871877861644162
Validation loss: 2.5675260893533265

Epoch: 5| Step: 10
Training loss: 0.24252670898039852
Validation loss: 2.6012788821413704

Epoch: 467| Step: 0
Training loss: 0.16772859060568157
Validation loss: 2.5626411184035205

Epoch: 5| Step: 1
Training loss: 0.18245047849431414
Validation loss: 2.5532089178839863

Epoch: 5| Step: 2
Training loss: 0.25182596590759515
Validation loss: 2.5852567959462256

Epoch: 5| Step: 3
Training loss: 0.229818817798793
Validation loss: 2.5633561744684674

Epoch: 5| Step: 4
Training loss: 0.21458350805781637
Validation loss: 2.540474708157256

Epoch: 5| Step: 5
Training loss: 0.20713595675528404
Validation loss: 2.5494290743019894

Epoch: 5| Step: 6
Training loss: 0.31252180261849216
Validation loss: 2.5799674422834755

Epoch: 5| Step: 7
Training loss: 0.22038931183963
Validation loss: 2.563767925590227

Epoch: 5| Step: 8
Training loss: 0.13426220201603611
Validation loss: 2.5823844142042147

Epoch: 5| Step: 9
Training loss: 0.17877056607063901
Validation loss: 2.5443502535022278

Epoch: 5| Step: 10
Training loss: 0.16496893278705452
Validation loss: 2.569637547710312

Epoch: 468| Step: 0
Training loss: 0.33632537716619176
Validation loss: 2.56640327720528

Epoch: 5| Step: 1
Training loss: 0.2509020535194968
Validation loss: 2.573297756775247

Epoch: 5| Step: 2
Training loss: 0.0889821252463122
Validation loss: 2.564474962985919

Epoch: 5| Step: 3
Training loss: 0.2348474826376516
Validation loss: 2.549584694761875

Epoch: 5| Step: 4
Training loss: 0.19025136961801112
Validation loss: 2.5573678941474336

Epoch: 5| Step: 5
Training loss: 0.2010702506105033
Validation loss: 2.5444076900460946

Epoch: 5| Step: 6
Training loss: 0.24767341433951537
Validation loss: 2.531517493727339

Epoch: 5| Step: 7
Training loss: 0.1505562007056596
Validation loss: 2.5391486676584654

Epoch: 5| Step: 8
Training loss: 0.22563217151688564
Validation loss: 2.5415206795303917

Epoch: 5| Step: 9
Training loss: 0.21358793133537893
Validation loss: 2.5542333045551486

Epoch: 5| Step: 10
Training loss: 0.14814440124345077
Validation loss: 2.5761986047041474

Epoch: 469| Step: 0
Training loss: 0.24829193085058243
Validation loss: 2.589302045559589

Epoch: 5| Step: 1
Training loss: 0.1588550838589898
Validation loss: 2.591032186460422

Epoch: 5| Step: 2
Training loss: 0.30841120620395557
Validation loss: 2.6353101753011012

Epoch: 5| Step: 3
Training loss: 0.1372062574480168
Validation loss: 2.6322515598555953

Epoch: 5| Step: 4
Training loss: 0.23095653929063206
Validation loss: 2.634207313847036

Epoch: 5| Step: 5
Training loss: 0.2023016399766095
Validation loss: 2.6256882858516217

Epoch: 5| Step: 6
Training loss: 0.32642161921596635
Validation loss: 2.619428949871335

Epoch: 5| Step: 7
Training loss: 0.2069904179163569
Validation loss: 2.589544054685071

Epoch: 5| Step: 8
Training loss: 0.18977550724284878
Validation loss: 2.5906943755878498

Epoch: 5| Step: 9
Training loss: 0.13641234531745122
Validation loss: 2.621361488791434

Epoch: 5| Step: 10
Training loss: 0.15202498710254628
Validation loss: 2.6207893497662877

Epoch: 470| Step: 0
Training loss: 0.16175639548253332
Validation loss: 2.619399491750938

Epoch: 5| Step: 1
Training loss: 0.11113596108908955
Validation loss: 2.594351150148878

Epoch: 5| Step: 2
Training loss: 0.15047100940881683
Validation loss: 2.6033574247727236

Epoch: 5| Step: 3
Training loss: 0.251893650102786
Validation loss: 2.570228596984271

Epoch: 5| Step: 4
Training loss: 0.2944673104536917
Validation loss: 2.5985549362814497

Epoch: 5| Step: 5
Training loss: 0.15023539322117738
Validation loss: 2.5851547503455636

Epoch: 5| Step: 6
Training loss: 0.22356100470405704
Validation loss: 2.563929135517121

Epoch: 5| Step: 7
Training loss: 0.14869930369124962
Validation loss: 2.5724890954269566

Epoch: 5| Step: 8
Training loss: 0.25337168835064594
Validation loss: 2.583608746278353

Epoch: 5| Step: 9
Training loss: 0.18525227700312843
Validation loss: 2.578455268734141

Epoch: 5| Step: 10
Training loss: 0.335597542699853
Validation loss: 2.5670849959278392

Epoch: 471| Step: 0
Training loss: 0.1991534593591049
Validation loss: 2.564761399764257

Epoch: 5| Step: 1
Training loss: 0.21792839934697755
Validation loss: 2.5494982966017754

Epoch: 5| Step: 2
Training loss: 0.27254215520301667
Validation loss: 2.5378909898243847

Epoch: 5| Step: 3
Training loss: 0.24969850181719072
Validation loss: 2.545958275925682

Epoch: 5| Step: 4
Training loss: 0.2709766415324652
Validation loss: 2.5782247962169476

Epoch: 5| Step: 5
Training loss: 0.25721030274415885
Validation loss: 2.576984228457087

Epoch: 5| Step: 6
Training loss: 0.18945589751741643
Validation loss: 2.592890680488501

Epoch: 5| Step: 7
Training loss: 0.16430122740672204
Validation loss: 2.576835457484242

Epoch: 5| Step: 8
Training loss: 0.24442000616137433
Validation loss: 2.5745042231838884

Epoch: 5| Step: 9
Training loss: 0.1703777446364826
Validation loss: 2.5962704331208246

Epoch: 5| Step: 10
Training loss: 0.17830650760824973
Validation loss: 2.610255047243684

Epoch: 472| Step: 0
Training loss: 0.16928291766729184
Validation loss: 2.620312916160322

Epoch: 5| Step: 1
Training loss: 0.17865863931168155
Validation loss: 2.599726460576281

Epoch: 5| Step: 2
Training loss: 0.30477301302366894
Validation loss: 2.6144336545980282

Epoch: 5| Step: 3
Training loss: 0.27179206591696753
Validation loss: 2.6131130317462397

Epoch: 5| Step: 4
Training loss: 0.3166171654275229
Validation loss: 2.658995838401765

Epoch: 5| Step: 5
Training loss: 0.20321880522071245
Validation loss: 2.6249931768005417

Epoch: 5| Step: 6
Training loss: 0.18015643793908512
Validation loss: 2.6038302992295748

Epoch: 5| Step: 7
Training loss: 0.16208454309574263
Validation loss: 2.541026554432706

Epoch: 5| Step: 8
Training loss: 0.14137350988994066
Validation loss: 2.581965355853508

Epoch: 5| Step: 9
Training loss: 0.19510202511211033
Validation loss: 2.571846408117138

Epoch: 5| Step: 10
Training loss: 0.20661327166598129
Validation loss: 2.5538970897613438

Epoch: 473| Step: 0
Training loss: 0.21690879544719846
Validation loss: 2.55441920096585

Epoch: 5| Step: 1
Training loss: 0.2410052731607822
Validation loss: 2.5814250996401484

Epoch: 5| Step: 2
Training loss: 0.15302982267454554
Validation loss: 2.5514079288658515

Epoch: 5| Step: 3
Training loss: 0.24014580652416542
Validation loss: 2.56728292136618

Epoch: 5| Step: 4
Training loss: 0.3195167752743818
Validation loss: 2.599408751958593

Epoch: 5| Step: 5
Training loss: 0.1937414498134567
Validation loss: 2.579007133249352

Epoch: 5| Step: 6
Training loss: 0.21570098823392608
Validation loss: 2.569860864597128

Epoch: 5| Step: 7
Training loss: 0.2578465121404111
Validation loss: 2.6196657058071064

Epoch: 5| Step: 8
Training loss: 0.1214667926956458
Validation loss: 2.596215898650834

Epoch: 5| Step: 9
Training loss: 0.18078060000013446
Validation loss: 2.6193680171267792

Epoch: 5| Step: 10
Training loss: 0.19399618996978674
Validation loss: 2.6111932444289367

Epoch: 474| Step: 0
Training loss: 0.2244815130767568
Validation loss: 2.6325864142511777

Epoch: 5| Step: 1
Training loss: 0.19028254962326335
Validation loss: 2.6662944494191594

Epoch: 5| Step: 2
Training loss: 0.15843172981732506
Validation loss: 2.627021363843496

Epoch: 5| Step: 3
Training loss: 0.1766301162762306
Validation loss: 2.6478224094004763

Epoch: 5| Step: 4
Training loss: 0.17520324727337108
Validation loss: 2.6598432877595806

Epoch: 5| Step: 5
Training loss: 0.17223499808674167
Validation loss: 2.6234201305238285

Epoch: 5| Step: 6
Training loss: 0.3844354054817666
Validation loss: 2.65205988948566

Epoch: 5| Step: 7
Training loss: 0.19627347096632428
Validation loss: 2.607709308171895

Epoch: 5| Step: 8
Training loss: 0.2149886422983135
Validation loss: 2.592177026642409

Epoch: 5| Step: 9
Training loss: 0.2465740315867628
Validation loss: 2.5890093684782554

Epoch: 5| Step: 10
Training loss: 0.19184372984157022
Validation loss: 2.5707460061494984

Epoch: 475| Step: 0
Training loss: 0.19767972708733614
Validation loss: 2.555015398166183

Epoch: 5| Step: 1
Training loss: 0.2755924864814741
Validation loss: 2.558667710534794

Epoch: 5| Step: 2
Training loss: 0.31338087148457316
Validation loss: 2.535187778112211

Epoch: 5| Step: 3
Training loss: 0.21653172026539244
Validation loss: 2.568637069823779

Epoch: 5| Step: 4
Training loss: 0.20809059107786382
Validation loss: 2.5439805026086004

Epoch: 5| Step: 5
Training loss: 0.13951936505653806
Validation loss: 2.591942279907153

Epoch: 5| Step: 6
Training loss: 0.31843156522661764
Validation loss: 2.562283569568179

Epoch: 5| Step: 7
Training loss: 0.12116958181890934
Validation loss: 2.5769758619903835

Epoch: 5| Step: 8
Training loss: 0.1270274531581779
Validation loss: 2.604479769352801

Epoch: 5| Step: 9
Training loss: 0.21371821436261992
Validation loss: 2.6271803122445565

Epoch: 5| Step: 10
Training loss: 0.2104968572453327
Validation loss: 2.630301613840505

Epoch: 476| Step: 0
Training loss: 0.22251274269293922
Validation loss: 2.6424644288170844

Epoch: 5| Step: 1
Training loss: 0.13434260083106578
Validation loss: 2.6117816359160964

Epoch: 5| Step: 2
Training loss: 0.20729938273869325
Validation loss: 2.594047803074958

Epoch: 5| Step: 3
Training loss: 0.1671437250744755
Validation loss: 2.5802488347635557

Epoch: 5| Step: 4
Training loss: 0.1682851605682645
Validation loss: 2.584542901974223

Epoch: 5| Step: 5
Training loss: 0.33751108098382915
Validation loss: 2.5571241055515777

Epoch: 5| Step: 6
Training loss: 0.17487758309983553
Validation loss: 2.538844951084506

Epoch: 5| Step: 7
Training loss: 0.2249075361837586
Validation loss: 2.56619518500503

Epoch: 5| Step: 8
Training loss: 0.20233769242045463
Validation loss: 2.548379644487128

Epoch: 5| Step: 9
Training loss: 0.27128354884697237
Validation loss: 2.5722153675909936

Epoch: 5| Step: 10
Training loss: 0.09563793667537898
Validation loss: 2.5629395558881045

Epoch: 477| Step: 0
Training loss: 0.21709722042206442
Validation loss: 2.6425546439028715

Epoch: 5| Step: 1
Training loss: 0.2407415510271638
Validation loss: 2.6219444871825726

Epoch: 5| Step: 2
Training loss: 0.19125812014625967
Validation loss: 2.6232606171271584

Epoch: 5| Step: 3
Training loss: 0.1890299879445977
Validation loss: 2.5980889363952246

Epoch: 5| Step: 4
Training loss: 0.21903816044394436
Validation loss: 2.6357368719914245

Epoch: 5| Step: 5
Training loss: 0.24945664964545974
Validation loss: 2.6309212362496903

Epoch: 5| Step: 6
Training loss: 0.2252105876443367
Validation loss: 2.635801764718018

Epoch: 5| Step: 7
Training loss: 0.1298880253369557
Validation loss: 2.6498473220371883

Epoch: 5| Step: 8
Training loss: 0.22608186449341713
Validation loss: 2.6567038740052618

Epoch: 5| Step: 9
Training loss: 0.2457262807587396
Validation loss: 2.633798314327259

Epoch: 5| Step: 10
Training loss: 0.17771131764179796
Validation loss: 2.616033090286

Epoch: 478| Step: 0
Training loss: 0.138512728263313
Validation loss: 2.6411166664478443

Epoch: 5| Step: 1
Training loss: 0.19099297964590517
Validation loss: 2.6397329310115385

Epoch: 5| Step: 2
Training loss: 0.2383512566083213
Validation loss: 2.61217871859725

Epoch: 5| Step: 3
Training loss: 0.25369685415130155
Validation loss: 2.629842226874927

Epoch: 5| Step: 4
Training loss: 0.20479544275850686
Validation loss: 2.6334276181553147

Epoch: 5| Step: 5
Training loss: 0.10998104565455057
Validation loss: 2.606962773319904

Epoch: 5| Step: 6
Training loss: 0.2786326345841313
Validation loss: 2.6229222527925304

Epoch: 5| Step: 7
Training loss: 0.19505376844777467
Validation loss: 2.6046115231123874

Epoch: 5| Step: 8
Training loss: 0.24956676077602954
Validation loss: 2.5812652823417315

Epoch: 5| Step: 9
Training loss: 0.32535176909540114
Validation loss: 2.602695189807503

Epoch: 5| Step: 10
Training loss: 0.1509868642986112
Validation loss: 2.558387146947928

Epoch: 479| Step: 0
Training loss: 0.20460792406987116
Validation loss: 2.572214010130996

Epoch: 5| Step: 1
Training loss: 0.21980458887510526
Validation loss: 2.561252108062535

Epoch: 5| Step: 2
Training loss: 0.14222945731343656
Validation loss: 2.5277154375325526

Epoch: 5| Step: 3
Training loss: 0.17136240512286802
Validation loss: 2.56348493502217

Epoch: 5| Step: 4
Training loss: 0.2068617774880917
Validation loss: 2.5497210673389095

Epoch: 5| Step: 5
Training loss: 0.27430105088286794
Validation loss: 2.5510447602414548

Epoch: 5| Step: 6
Training loss: 0.2913812989708212
Validation loss: 2.572584211367782

Epoch: 5| Step: 7
Training loss: 0.23534778734400508
Validation loss: 2.589841372301487

Epoch: 5| Step: 8
Training loss: 0.15327040959637928
Validation loss: 2.6269430156439593

Epoch: 5| Step: 9
Training loss: 0.30344059923909106
Validation loss: 2.6146797313077745

Epoch: 5| Step: 10
Training loss: 0.12189487056871376
Validation loss: 2.6244615685263875

Epoch: 480| Step: 0
Training loss: 0.23193303961436681
Validation loss: 2.621513240579858

Epoch: 5| Step: 1
Training loss: 0.18375861090965123
Validation loss: 2.6331065393992854

Epoch: 5| Step: 2
Training loss: 0.14569382011422033
Validation loss: 2.5926020256661286

Epoch: 5| Step: 3
Training loss: 0.1335354301245619
Validation loss: 2.6084943295570895

Epoch: 5| Step: 4
Training loss: 0.28970788100066625
Validation loss: 2.5598392473850384

Epoch: 5| Step: 5
Training loss: 0.19008627027815084
Validation loss: 2.570008290654405

Epoch: 5| Step: 6
Training loss: 0.293497625453448
Validation loss: 2.59849439803886

Epoch: 5| Step: 7
Training loss: 0.21228213361525045
Validation loss: 2.5972535831538828

Epoch: 5| Step: 8
Training loss: 0.10357025342468985
Validation loss: 2.6213100289040447

Epoch: 5| Step: 9
Training loss: 0.15995416452230843
Validation loss: 2.6080941548184966

Epoch: 5| Step: 10
Training loss: 0.2961037052866398
Validation loss: 2.632264770270152

Epoch: 481| Step: 0
Training loss: 0.209021636279306
Validation loss: 2.6124156904936164

Epoch: 5| Step: 1
Training loss: 0.18774966664608495
Validation loss: 2.6507596859327243

Epoch: 5| Step: 2
Training loss: 0.17208260222765379
Validation loss: 2.6571113960737156

Epoch: 5| Step: 3
Training loss: 0.10374281800931177
Validation loss: 2.653792354367528

Epoch: 5| Step: 4
Training loss: 0.1569034146225748
Validation loss: 2.61731398694183

Epoch: 5| Step: 5
Training loss: 0.12568359908524082
Validation loss: 2.665709337804729

Epoch: 5| Step: 6
Training loss: 0.24780813126723888
Validation loss: 2.6242372349003102

Epoch: 5| Step: 7
Training loss: 0.2902651974521447
Validation loss: 2.611298418414111

Epoch: 5| Step: 8
Training loss: 0.19898906257418938
Validation loss: 2.61962002372331

Epoch: 5| Step: 9
Training loss: 0.25977435850218966
Validation loss: 2.6463384615240235

Epoch: 5| Step: 10
Training loss: 0.18694274267754432
Validation loss: 2.621412714913815

Epoch: 482| Step: 0
Training loss: 0.13142667045865022
Validation loss: 2.620822126888666

Epoch: 5| Step: 1
Training loss: 0.1625643515629904
Validation loss: 2.6201330832697103

Epoch: 5| Step: 2
Training loss: 0.24479755519656302
Validation loss: 2.568844248668887

Epoch: 5| Step: 3
Training loss: 0.12426566701442489
Validation loss: 2.5922397368358494

Epoch: 5| Step: 4
Training loss: 0.14888378238997613
Validation loss: 2.6103153480904573

Epoch: 5| Step: 5
Training loss: 0.27081190843691416
Validation loss: 2.576853794042093

Epoch: 5| Step: 6
Training loss: 0.15453095727281452
Validation loss: 2.5701548893362305

Epoch: 5| Step: 7
Training loss: 0.19832757698716075
Validation loss: 2.5979283472433696

Epoch: 5| Step: 8
Training loss: 0.22916873295170354
Validation loss: 2.6210679295262054

Epoch: 5| Step: 9
Training loss: 0.19175530738771712
Validation loss: 2.6296644865503316

Epoch: 5| Step: 10
Training loss: 0.24088270426417324
Validation loss: 2.600218278566451

Epoch: 483| Step: 0
Training loss: 0.23262675255264406
Validation loss: 2.6049917345591176

Epoch: 5| Step: 1
Training loss: 0.3580574471571123
Validation loss: 2.6185290558504923

Epoch: 5| Step: 2
Training loss: 0.1538282109420637
Validation loss: 2.5798581738420463

Epoch: 5| Step: 3
Training loss: 0.15625813582219872
Validation loss: 2.5771395149970697

Epoch: 5| Step: 4
Training loss: 0.13697976673076978
Validation loss: 2.607537613827493

Epoch: 5| Step: 5
Training loss: 0.11078555924625524
Validation loss: 2.6049896019567536

Epoch: 5| Step: 6
Training loss: 0.22752025018945685
Validation loss: 2.599350219933832

Epoch: 5| Step: 7
Training loss: 0.2320884829876706
Validation loss: 2.5799629528708268

Epoch: 5| Step: 8
Training loss: 0.08943022014105723
Validation loss: 2.6302213662205465

Epoch: 5| Step: 9
Training loss: 0.1483764146297092
Validation loss: 2.631401699861766

Epoch: 5| Step: 10
Training loss: 0.16727375252196816
Validation loss: 2.5799141481387187

Epoch: 484| Step: 0
Training loss: 0.3095818646799594
Validation loss: 2.592015639000305

Epoch: 5| Step: 1
Training loss: 0.23908562984645576
Validation loss: 2.622690080041228

Epoch: 5| Step: 2
Training loss: 0.17016947454059456
Validation loss: 2.595738994147132

Epoch: 5| Step: 3
Training loss: 0.12316083172481619
Validation loss: 2.523409923394023

Epoch: 5| Step: 4
Training loss: 0.1659845042511434
Validation loss: 2.564400489141426

Epoch: 5| Step: 5
Training loss: 0.2598725722586227
Validation loss: 2.5164113951528875

Epoch: 5| Step: 6
Training loss: 0.206189062046125
Validation loss: 2.5427555338677608

Epoch: 5| Step: 7
Training loss: 0.23210325761384248
Validation loss: 2.5250553405668814

Epoch: 5| Step: 8
Training loss: 0.2698826641303762
Validation loss: 2.5307847140637914

Epoch: 5| Step: 9
Training loss: 0.18078053818004533
Validation loss: 2.5490028757398466

Epoch: 5| Step: 10
Training loss: 0.19774276325244045
Validation loss: 2.575106913402671

Epoch: 485| Step: 0
Training loss: 0.22088354888578468
Validation loss: 2.5665663542826516

Epoch: 5| Step: 1
Training loss: 0.19155748387189858
Validation loss: 2.559024119117925

Epoch: 5| Step: 2
Training loss: 0.16066602081989964
Validation loss: 2.5507583852067697

Epoch: 5| Step: 3
Training loss: 0.23494462093735669
Validation loss: 2.5704234418737055

Epoch: 5| Step: 4
Training loss: 0.17277881470777007
Validation loss: 2.5698050603889935

Epoch: 5| Step: 5
Training loss: 0.2199537078016142
Validation loss: 2.53457008212769

Epoch: 5| Step: 6
Training loss: 0.1805943638153655
Validation loss: 2.5677868778378254

Epoch: 5| Step: 7
Training loss: 0.18258661636435916
Validation loss: 2.587992986696677

Epoch: 5| Step: 8
Training loss: 0.22745269151192832
Validation loss: 2.54622050872867

Epoch: 5| Step: 9
Training loss: 0.17892248629728005
Validation loss: 2.5914710359544717

Epoch: 5| Step: 10
Training loss: 0.3594942102496587
Validation loss: 2.5870834144830086

Epoch: 486| Step: 0
Training loss: 0.2551930027204242
Validation loss: 2.6019909795409415

Epoch: 5| Step: 1
Training loss: 0.20990008869700855
Validation loss: 2.592992008378055

Epoch: 5| Step: 2
Training loss: 0.1900029805853105
Validation loss: 2.618688137424004

Epoch: 5| Step: 3
Training loss: 0.17584693529149992
Validation loss: 2.591011954551049

Epoch: 5| Step: 4
Training loss: 0.11907627760026356
Validation loss: 2.604204362822031

Epoch: 5| Step: 5
Training loss: 0.21001138302912598
Validation loss: 2.615753448010513

Epoch: 5| Step: 6
Training loss: 0.33451161401341317
Validation loss: 2.590166340488296

Epoch: 5| Step: 7
Training loss: 0.208783525584415
Validation loss: 2.6127029348762427

Epoch: 5| Step: 8
Training loss: 0.19146202209068325
Validation loss: 2.590211253386111

Epoch: 5| Step: 9
Training loss: 0.2210940553103654
Validation loss: 2.545112115003933

Epoch: 5| Step: 10
Training loss: 0.21742303309952896
Validation loss: 2.550994721900917

Epoch: 487| Step: 0
Training loss: 0.21501730064713281
Validation loss: 2.576527159726771

Epoch: 5| Step: 1
Training loss: 0.143830378492481
Validation loss: 2.5741566235936997

Epoch: 5| Step: 2
Training loss: 0.25030170057814843
Validation loss: 2.598125493901917

Epoch: 5| Step: 3
Training loss: 0.30188705244547265
Validation loss: 2.5938896895726224

Epoch: 5| Step: 4
Training loss: 0.26940438145736334
Validation loss: 2.584796185353496

Epoch: 5| Step: 5
Training loss: 0.2315215938746364
Validation loss: 2.5726074282676406

Epoch: 5| Step: 6
Training loss: 0.2619096998837065
Validation loss: 2.612477456115432

Epoch: 5| Step: 7
Training loss: 0.294857940312135
Validation loss: 2.569353012509841

Epoch: 5| Step: 8
Training loss: 0.1878069510885836
Validation loss: 2.5625299911684825

Epoch: 5| Step: 9
Training loss: 0.22764251060105506
Validation loss: 2.553559691219292

Epoch: 5| Step: 10
Training loss: 0.124445583506537
Validation loss: 2.557819431709054

Epoch: 488| Step: 0
Training loss: 0.13151750608415302
Validation loss: 2.540280068942421

Epoch: 5| Step: 1
Training loss: 0.15434351952422243
Validation loss: 2.5545091388956496

Epoch: 5| Step: 2
Training loss: 0.2810774777353167
Validation loss: 2.5366800044637823

Epoch: 5| Step: 3
Training loss: 0.16213254877853064
Validation loss: 2.549069429883799

Epoch: 5| Step: 4
Training loss: 0.20866181980987236
Validation loss: 2.5894664120227238

Epoch: 5| Step: 5
Training loss: 0.23080269009505414
Validation loss: 2.6009045146068255

Epoch: 5| Step: 6
Training loss: 0.22804314111395213
Validation loss: 2.5820566496663155

Epoch: 5| Step: 7
Training loss: 0.19087563164799468
Validation loss: 2.6070901319636683

Epoch: 5| Step: 8
Training loss: 0.17578586996153198
Validation loss: 2.6424025452917066

Epoch: 5| Step: 9
Training loss: 0.2409312522513532
Validation loss: 2.6462506704810935

Epoch: 5| Step: 10
Training loss: 0.2289260536714913
Validation loss: 2.609027762075041

Epoch: 489| Step: 0
Training loss: 0.2782534870433034
Validation loss: 2.6576236828294957

Epoch: 5| Step: 1
Training loss: 0.2923533397388219
Validation loss: 2.6543666544869104

Epoch: 5| Step: 2
Training loss: 0.18189732041007942
Validation loss: 2.639315011363492

Epoch: 5| Step: 3
Training loss: 0.2522515739764208
Validation loss: 2.6284067604339993

Epoch: 5| Step: 4
Training loss: 0.1948853494827318
Validation loss: 2.6145409951293357

Epoch: 5| Step: 5
Training loss: 0.23607584200588427
Validation loss: 2.6321626702737153

Epoch: 5| Step: 6
Training loss: 0.16058739338824735
Validation loss: 2.600411892796255

Epoch: 5| Step: 7
Training loss: 0.27659341563906126
Validation loss: 2.583776975427464

Epoch: 5| Step: 8
Training loss: 0.24453443427648153
Validation loss: 2.6010228192561633

Epoch: 5| Step: 9
Training loss: 0.23243596330787608
Validation loss: 2.5852351682161574

Epoch: 5| Step: 10
Training loss: 0.15170723036533873
Validation loss: 2.586684447227032

Epoch: 490| Step: 0
Training loss: 0.14237700608793571
Validation loss: 2.609764692418819

Epoch: 5| Step: 1
Training loss: 0.19908647259638548
Validation loss: 2.5960832951663706

Epoch: 5| Step: 2
Training loss: 0.17327105809500978
Validation loss: 2.642936237292085

Epoch: 5| Step: 3
Training loss: 0.1141902936015333
Validation loss: 2.6093914941968017

Epoch: 5| Step: 4
Training loss: 0.1510231106694246
Validation loss: 2.6476516392590272

Epoch: 5| Step: 5
Training loss: 0.31369321235111625
Validation loss: 2.63901062914678

Epoch: 5| Step: 6
Training loss: 0.19627872838388238
Validation loss: 2.638678547698409

Epoch: 5| Step: 7
Training loss: 0.3011517657779061
Validation loss: 2.594025214892347

Epoch: 5| Step: 8
Training loss: 0.14767718091083726
Validation loss: 2.6304093131311284

Epoch: 5| Step: 9
Training loss: 0.20486155382385118
Validation loss: 2.6345051045747754

Epoch: 5| Step: 10
Training loss: 0.3285760390786746
Validation loss: 2.5869660192955783

Epoch: 491| Step: 0
Training loss: 0.2424777583486593
Validation loss: 2.5746935907330704

Epoch: 5| Step: 1
Training loss: 0.1898725428940215
Validation loss: 2.585499642802741

Epoch: 5| Step: 2
Training loss: 0.25258919910775585
Validation loss: 2.6032040778883068

Epoch: 5| Step: 3
Training loss: 0.2411338744826841
Validation loss: 2.61719955027706

Epoch: 5| Step: 4
Training loss: 0.19223292558258967
Validation loss: 2.609996731164017

Epoch: 5| Step: 5
Training loss: 0.18726893930124197
Validation loss: 2.5967927439857665

Epoch: 5| Step: 6
Training loss: 0.28116276500768955
Validation loss: 2.600122078332128

Epoch: 5| Step: 7
Training loss: 0.17585598628415525
Validation loss: 2.632276154508898

Epoch: 5| Step: 8
Training loss: 0.3181218156111848
Validation loss: 2.6265086776871063

Epoch: 5| Step: 9
Training loss: 0.22567340261640517
Validation loss: 2.64973758768889

Epoch: 5| Step: 10
Training loss: 0.14196630396783563
Validation loss: 2.637190828649655

Epoch: 492| Step: 0
Training loss: 0.17230744038183493
Validation loss: 2.644316291091544

Epoch: 5| Step: 1
Training loss: 0.20127513235443412
Validation loss: 2.6036086090355677

Epoch: 5| Step: 2
Training loss: 0.2528597171575818
Validation loss: 2.628520800855584

Epoch: 5| Step: 3
Training loss: 0.280172535879832
Validation loss: 2.643606482420541

Epoch: 5| Step: 4
Training loss: 0.2126466070058756
Validation loss: 2.6402910427545487

Epoch: 5| Step: 5
Training loss: 0.2673625634650765
Validation loss: 2.618503889546128

Epoch: 5| Step: 6
Training loss: 0.19661540332311622
Validation loss: 2.6137603080813308

Epoch: 5| Step: 7
Training loss: 0.18868179216246025
Validation loss: 2.5887801069052414

Epoch: 5| Step: 8
Training loss: 0.32174832990371494
Validation loss: 2.620140376055335

Epoch: 5| Step: 9
Training loss: 0.11025087016193683
Validation loss: 2.6040418165898953

Epoch: 5| Step: 10
Training loss: 0.22402164022827234
Validation loss: 2.548503800564325

Epoch: 493| Step: 0
Training loss: 0.2322271878015106
Validation loss: 2.5611845772550774

Epoch: 5| Step: 1
Training loss: 0.2703840337488351
Validation loss: 2.577579417443575

Epoch: 5| Step: 2
Training loss: 0.2081285135442266
Validation loss: 2.534214029927659

Epoch: 5| Step: 3
Training loss: 0.19895997724969045
Validation loss: 2.5372805245229975

Epoch: 5| Step: 4
Training loss: 0.13893557714160437
Validation loss: 2.5554774270042175

Epoch: 5| Step: 5
Training loss: 0.20027630725974893
Validation loss: 2.5655515855346724

Epoch: 5| Step: 6
Training loss: 0.23720895539497072
Validation loss: 2.613667203601355

Epoch: 5| Step: 7
Training loss: 0.2743708077547101
Validation loss: 2.5954723113095515

Epoch: 5| Step: 8
Training loss: 0.1928925128101225
Validation loss: 2.6078957514547616

Epoch: 5| Step: 9
Training loss: 0.17923542872995338
Validation loss: 2.6296645699036536

Epoch: 5| Step: 10
Training loss: 0.297990060093257
Validation loss: 2.5827018784427516

Epoch: 494| Step: 0
Training loss: 0.23816698492683822
Validation loss: 2.5813674638229225

Epoch: 5| Step: 1
Training loss: 0.3052799626859306
Validation loss: 2.535795817398653

Epoch: 5| Step: 2
Training loss: 0.274294681306703
Validation loss: 2.5316884288946007

Epoch: 5| Step: 3
Training loss: 0.22904829558896045
Validation loss: 2.5013606475700847

Epoch: 5| Step: 4
Training loss: 0.2817552848987073
Validation loss: 2.5086800313545643

Epoch: 5| Step: 5
Training loss: 0.23134124605276107
Validation loss: 2.5032365327023722

Epoch: 5| Step: 6
Training loss: 0.2060476636367439
Validation loss: 2.5194999706237367

Epoch: 5| Step: 7
Training loss: 0.23055878189968815
Validation loss: 2.5760826777003785

Epoch: 5| Step: 8
Training loss: 0.27146524595201593
Validation loss: 2.565705889871726

Epoch: 5| Step: 9
Training loss: 0.18925578861315756
Validation loss: 2.6299244551529473

Epoch: 5| Step: 10
Training loss: 0.16702720765663398
Validation loss: 2.6018028041129115

Epoch: 495| Step: 0
Training loss: 0.2977706924466078
Validation loss: 2.611601658285628

Epoch: 5| Step: 1
Training loss: 0.19819613330494718
Validation loss: 2.624605821155399

Epoch: 5| Step: 2
Training loss: 0.2301963877851047
Validation loss: 2.638556710971436

Epoch: 5| Step: 3
Training loss: 0.29960722742218676
Validation loss: 2.5906166674531668

Epoch: 5| Step: 4
Training loss: 0.13917536066884637
Validation loss: 2.553102326436477

Epoch: 5| Step: 5
Training loss: 0.1932188158955987
Validation loss: 2.553247945895909

Epoch: 5| Step: 6
Training loss: 0.20267065292624023
Validation loss: 2.5523369205865523

Epoch: 5| Step: 7
Training loss: 0.22737012985397168
Validation loss: 2.5231785012867243

Epoch: 5| Step: 8
Training loss: 0.2501388104833037
Validation loss: 2.596766897098423

Epoch: 5| Step: 9
Training loss: 0.22499147339400263
Validation loss: 2.5863314851018537

Epoch: 5| Step: 10
Training loss: 0.3063429827541887
Validation loss: 2.602486235506036

Epoch: 496| Step: 0
Training loss: 0.24874089986363093
Validation loss: 2.6100529342756977

Epoch: 5| Step: 1
Training loss: 0.23633956093349817
Validation loss: 2.620348730688047

Epoch: 5| Step: 2
Training loss: 0.21985363147057987
Validation loss: 2.606375237571588

Epoch: 5| Step: 3
Training loss: 0.2869123963891273
Validation loss: 2.600969733781865

Epoch: 5| Step: 4
Training loss: 0.18590285635624196
Validation loss: 2.5368407913434123

Epoch: 5| Step: 5
Training loss: 0.20329452739577142
Validation loss: 2.5843144400252553

Epoch: 5| Step: 6
Training loss: 0.16564665913662868
Validation loss: 2.5754262372900714

Epoch: 5| Step: 7
Training loss: 0.17777922347428016
Validation loss: 2.554865609835117

Epoch: 5| Step: 8
Training loss: 0.2788444803261056
Validation loss: 2.5629623300149955

Epoch: 5| Step: 9
Training loss: 0.2739451464439421
Validation loss: 2.5686098726856623

Epoch: 5| Step: 10
Training loss: 0.31542782148157655
Validation loss: 2.5859243999025834

Epoch: 497| Step: 0
Training loss: 0.20160400865146597
Validation loss: 2.5881358640053644

Epoch: 5| Step: 1
Training loss: 0.14839155966938444
Validation loss: 2.58910816393541

Epoch: 5| Step: 2
Training loss: 0.19569925163532376
Validation loss: 2.637504246610189

Epoch: 5| Step: 3
Training loss: 0.13336397426788632
Validation loss: 2.607507599582892

Epoch: 5| Step: 4
Training loss: 0.12609180088498484
Validation loss: 2.619513197151413

Epoch: 5| Step: 5
Training loss: 0.31738253079915385
Validation loss: 2.6293380610128385

Epoch: 5| Step: 6
Training loss: 0.21151121144700022
Validation loss: 2.656114323605558

Epoch: 5| Step: 7
Training loss: 0.29782538377126627
Validation loss: 2.62018507994245

Epoch: 5| Step: 8
Training loss: 0.35841980748299707
Validation loss: 2.6052785443215694

Epoch: 5| Step: 9
Training loss: 0.22875735547272918
Validation loss: 2.6118727326491316

Epoch: 5| Step: 10
Training loss: 0.1539477672347316
Validation loss: 2.5838496664389847

Epoch: 498| Step: 0
Training loss: 0.2923039714188135
Validation loss: 2.510217350225659

Epoch: 5| Step: 1
Training loss: 0.3538444212405421
Validation loss: 2.540908376249532

Epoch: 5| Step: 2
Training loss: 0.24582296187268673
Validation loss: 2.525651910108962

Epoch: 5| Step: 3
Training loss: 0.1877898618190167
Validation loss: 2.579995424920481

Epoch: 5| Step: 4
Training loss: 0.22662150502547715
Validation loss: 2.5548198447784842

Epoch: 5| Step: 5
Training loss: 0.22133356540778595
Validation loss: 2.569550071842949

Epoch: 5| Step: 6
Training loss: 0.19501346584433238
Validation loss: 2.587831642251098

Epoch: 5| Step: 7
Training loss: 0.2263454844855876
Validation loss: 2.6129879485148146

Epoch: 5| Step: 8
Training loss: 0.22648211401409216
Validation loss: 2.6324178393123727

Epoch: 5| Step: 9
Training loss: 0.28468265135705184
Validation loss: 2.6123190311823574

Epoch: 5| Step: 10
Training loss: 0.14511312810218227
Validation loss: 2.628869135596363

Epoch: 499| Step: 0
Training loss: 0.17485839402318437
Validation loss: 2.649034151291645

Epoch: 5| Step: 1
Training loss: 0.29866190257824754
Validation loss: 2.6665269644608642

Epoch: 5| Step: 2
Training loss: 0.1740534639838178
Validation loss: 2.654188194875953

Epoch: 5| Step: 3
Training loss: 0.14562305264951392
Validation loss: 2.6395129256265393

Epoch: 5| Step: 4
Training loss: 0.29568549321569465
Validation loss: 2.5746523427390464

Epoch: 5| Step: 5
Training loss: 0.2978530758678574
Validation loss: 2.6069130137086454

Epoch: 5| Step: 6
Training loss: 0.24932484057781004
Validation loss: 2.5943229923043485

Epoch: 5| Step: 7
Training loss: 0.35034330680069875
Validation loss: 2.569338573642275

Epoch: 5| Step: 8
Training loss: 0.1782812884311484
Validation loss: 2.5913530203928214

Epoch: 5| Step: 9
Training loss: 0.1749486490249258
Validation loss: 2.5947752348518205

Epoch: 5| Step: 10
Training loss: 0.11942886053080871
Validation loss: 2.579582417440631

Epoch: 500| Step: 0
Training loss: 0.1782205032845665
Validation loss: 2.6099742613674373

Epoch: 5| Step: 1
Training loss: 0.26793582702890356
Validation loss: 2.5804620396787543

Epoch: 5| Step: 2
Training loss: 0.17259664110673203
Validation loss: 2.5534984255737623

Epoch: 5| Step: 3
Training loss: 0.27379304386334957
Validation loss: 2.566829220813228

Epoch: 5| Step: 4
Training loss: 0.2841638514769895
Validation loss: 2.5853938749556375

Epoch: 5| Step: 5
Training loss: 0.1348238625674383
Validation loss: 2.6060262414074447

Epoch: 5| Step: 6
Training loss: 0.24302129882515022
Validation loss: 2.618970435760084

Epoch: 5| Step: 7
Training loss: 0.19967690312859032
Validation loss: 2.5914207483737743

Epoch: 5| Step: 8
Training loss: 0.20375336144020653
Validation loss: 2.6275647286850203

Epoch: 5| Step: 9
Training loss: 0.2565518682974258
Validation loss: 2.624947486348262

Epoch: 5| Step: 10
Training loss: 0.25638285077413797
Validation loss: 2.597919222270152

Testing loss: 2.422817006006294
