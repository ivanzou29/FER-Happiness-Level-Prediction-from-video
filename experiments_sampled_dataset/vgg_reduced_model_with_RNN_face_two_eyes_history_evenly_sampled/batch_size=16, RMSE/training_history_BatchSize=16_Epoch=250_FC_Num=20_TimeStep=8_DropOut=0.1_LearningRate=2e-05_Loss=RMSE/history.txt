Epoch: 1| Step: 0
Training loss: 5.173430148493625
Validation loss: 5.762674619857383

Epoch: 6| Step: 1
Training loss: 4.550027809477278
Validation loss: 5.7396379994573135

Epoch: 6| Step: 2
Training loss: 6.0104200163710155
Validation loss: 5.721723176677182

Epoch: 6| Step: 3
Training loss: 5.724475100246297
Validation loss: 5.703728131025591

Epoch: 6| Step: 4
Training loss: 4.547653498646308
Validation loss: 5.684243220955455

Epoch: 6| Step: 5
Training loss: 5.1064343870902915
Validation loss: 5.662773283536692

Epoch: 6| Step: 6
Training loss: 6.601114363950019
Validation loss: 5.637911032338562

Epoch: 6| Step: 7
Training loss: 5.966083670039346
Validation loss: 5.6101623881958504

Epoch: 6| Step: 8
Training loss: 6.114199087448578
Validation loss: 5.57771554332668

Epoch: 6| Step: 9
Training loss: 6.0737885448538345
Validation loss: 5.541572543478378

Epoch: 6| Step: 10
Training loss: 5.503171179955124
Validation loss: 5.50148343751309

Epoch: 6| Step: 11
Training loss: 5.669837438550584
Validation loss: 5.456511644943964

Epoch: 6| Step: 12
Training loss: 6.087359554856084
Validation loss: 5.407243212402161

Epoch: 6| Step: 13
Training loss: 5.1981687108805295
Validation loss: 5.355343985091372

Epoch: 2| Step: 0
Training loss: 2.4517266242265685
Validation loss: 5.298117302197868

Epoch: 6| Step: 1
Training loss: 4.673173908846558
Validation loss: 5.242641317524234

Epoch: 6| Step: 2
Training loss: 5.065874646840366
Validation loss: 5.187675756765207

Epoch: 6| Step: 3
Training loss: 5.627736422073099
Validation loss: 5.131771009765509

Epoch: 6| Step: 4
Training loss: 5.468900493186004
Validation loss: 5.078438100194368

Epoch: 6| Step: 5
Training loss: 4.789716218573682
Validation loss: 5.025335758382979

Epoch: 6| Step: 6
Training loss: 4.7403828488026845
Validation loss: 4.973971248181076

Epoch: 6| Step: 7
Training loss: 3.924667276263061
Validation loss: 4.925140459143953

Epoch: 6| Step: 8
Training loss: 5.327152465483124
Validation loss: 4.880840283404667

Epoch: 6| Step: 9
Training loss: 5.71368751119502
Validation loss: 4.841964838362914

Epoch: 6| Step: 10
Training loss: 5.787480476626594
Validation loss: 4.800173402887719

Epoch: 6| Step: 11
Training loss: 6.385740320695743
Validation loss: 4.7566761514943225

Epoch: 6| Step: 12
Training loss: 4.804090013027595
Validation loss: 4.719726835174178

Epoch: 6| Step: 13
Training loss: 3.7536291998684392
Validation loss: 4.685324439530099

Epoch: 3| Step: 0
Training loss: 4.770013508327718
Validation loss: 4.652829960372434

Epoch: 6| Step: 1
Training loss: 5.62865786828382
Validation loss: 4.621188370471674

Epoch: 6| Step: 2
Training loss: 5.206041040153984
Validation loss: 4.588219846583056

Epoch: 6| Step: 3
Training loss: 3.687076350299713
Validation loss: 4.554991813448706

Epoch: 6| Step: 4
Training loss: 4.958748594360306
Validation loss: 4.52370802476876

Epoch: 6| Step: 5
Training loss: 3.8046265896850477
Validation loss: 4.495964298387685

Epoch: 6| Step: 6
Training loss: 4.254710560153722
Validation loss: 4.462937999552971

Epoch: 6| Step: 7
Training loss: 4.738896693980647
Validation loss: 4.4279306271458525

Epoch: 6| Step: 8
Training loss: 4.724935557415415
Validation loss: 4.397115263383681

Epoch: 6| Step: 9
Training loss: 2.733458272668154
Validation loss: 4.370119129243952

Epoch: 6| Step: 10
Training loss: 5.276872976723581
Validation loss: 4.356410354843377

Epoch: 6| Step: 11
Training loss: 4.84902607685739
Validation loss: 4.336447871209569

Epoch: 6| Step: 12
Training loss: 4.050587486701992
Validation loss: 4.308210822597929

Epoch: 6| Step: 13
Training loss: 4.641321817094659
Validation loss: 4.283769188975734

Epoch: 4| Step: 0
Training loss: 4.334805727502725
Validation loss: 4.261101434689907

Epoch: 6| Step: 1
Training loss: 5.276335828237136
Validation loss: 4.2351446951772145

Epoch: 6| Step: 2
Training loss: 3.499316148707624
Validation loss: 4.207218929482861

Epoch: 6| Step: 3
Training loss: 4.4709616570071065
Validation loss: 4.1870111526933265

Epoch: 6| Step: 4
Training loss: 4.397584442837314
Validation loss: 4.1673763351694175

Epoch: 6| Step: 5
Training loss: 4.3864939522487925
Validation loss: 4.150486958282717

Epoch: 6| Step: 6
Training loss: 2.5409810960374974
Validation loss: 4.136930530441998

Epoch: 6| Step: 7
Training loss: 4.97306971842507
Validation loss: 4.131208938256313

Epoch: 6| Step: 8
Training loss: 3.8766603911839144
Validation loss: 4.113664112811347

Epoch: 6| Step: 9
Training loss: 4.564181292384317
Validation loss: 4.096475307283666

Epoch: 6| Step: 10
Training loss: 4.244175229236517
Validation loss: 4.081683818721625

Epoch: 6| Step: 11
Training loss: 4.168169869430084
Validation loss: 4.072192222878185

Epoch: 6| Step: 12
Training loss: 3.6721717227599786
Validation loss: 4.060111439948204

Epoch: 6| Step: 13
Training loss: 5.199557344229192
Validation loss: 4.041943759551445

Epoch: 5| Step: 0
Training loss: 3.7234805496422902
Validation loss: 4.026629434708311

Epoch: 6| Step: 1
Training loss: 4.598193037642698
Validation loss: 4.015475306452628

Epoch: 6| Step: 2
Training loss: 4.927554774025896
Validation loss: 4.0102462423374785

Epoch: 6| Step: 3
Training loss: 3.818682675931003
Validation loss: 4.004213713239079

Epoch: 6| Step: 4
Training loss: 3.223266987582969
Validation loss: 3.99052766860192

Epoch: 6| Step: 5
Training loss: 3.9898732265132764
Validation loss: 3.981757496289998

Epoch: 6| Step: 6
Training loss: 3.1781626051156766
Validation loss: 3.9670728298873885

Epoch: 6| Step: 7
Training loss: 5.084960468629948
Validation loss: 3.955782796031515

Epoch: 6| Step: 8
Training loss: 4.290724024286331
Validation loss: 3.93873144355089

Epoch: 6| Step: 9
Training loss: 4.303972742242543
Validation loss: 3.9313513372741595

Epoch: 6| Step: 10
Training loss: 5.108947549374124
Validation loss: 3.9237347834212133

Epoch: 6| Step: 11
Training loss: 3.499817025987654
Validation loss: 3.9058068189351105

Epoch: 6| Step: 12
Training loss: 3.3979121361161804
Validation loss: 3.892643200434751

Epoch: 6| Step: 13
Training loss: 3.681057102091053
Validation loss: 3.8855634054210975

Epoch: 6| Step: 0
Training loss: 4.573486060955675
Validation loss: 3.877725096169004

Epoch: 6| Step: 1
Training loss: 4.468844326064145
Validation loss: 3.865785993670698

Epoch: 6| Step: 2
Training loss: 4.242192895369497
Validation loss: 3.8558594068073235

Epoch: 6| Step: 3
Training loss: 3.9063564438622222
Validation loss: 3.8486962489856515

Epoch: 6| Step: 4
Training loss: 4.016481775695265
Validation loss: 3.8380344080356545

Epoch: 6| Step: 5
Training loss: 4.196962511594602
Validation loss: 3.8243886420587225

Epoch: 6| Step: 6
Training loss: 4.509174319723545
Validation loss: 3.810987755275834

Epoch: 6| Step: 7
Training loss: 3.6539017398945868
Validation loss: 3.804424639908321

Epoch: 6| Step: 8
Training loss: 3.8662475676703116
Validation loss: 3.7951299885061065

Epoch: 6| Step: 9
Training loss: 3.4306598927173635
Validation loss: 3.7872241685132435

Epoch: 6| Step: 10
Training loss: 5.012231362010174
Validation loss: 3.7723452135893267

Epoch: 6| Step: 11
Training loss: 1.471129417696091
Validation loss: 3.7638947828990603

Epoch: 6| Step: 12
Training loss: 3.6745513901708255
Validation loss: 3.779005586799464

Epoch: 6| Step: 13
Training loss: 3.4454748413868
Validation loss: 3.742464782004201

Epoch: 7| Step: 0
Training loss: 4.264456676297527
Validation loss: 3.734871230877653

Epoch: 6| Step: 1
Training loss: 3.2692639094610563
Validation loss: 3.73598990351957

Epoch: 6| Step: 2
Training loss: 3.854560598225887
Validation loss: 3.73081328395531

Epoch: 6| Step: 3
Training loss: 2.870258734069193
Validation loss: 3.7166460758343147

Epoch: 6| Step: 4
Training loss: 4.053543311586328
Validation loss: 3.7018746800379674

Epoch: 6| Step: 5
Training loss: 4.339364671745685
Validation loss: 3.703944745361119

Epoch: 6| Step: 6
Training loss: 4.253940326424579
Validation loss: 3.6785809730109107

Epoch: 6| Step: 7
Training loss: 4.275027688812355
Validation loss: 3.6764337820663364

Epoch: 6| Step: 8
Training loss: 4.011536888450293
Validation loss: 3.670247733438073

Epoch: 6| Step: 9
Training loss: 2.8478913386757396
Validation loss: 3.648779561063985

Epoch: 6| Step: 10
Training loss: 2.543987111280889
Validation loss: 3.6325514727074215

Epoch: 6| Step: 11
Training loss: 4.826145395895592
Validation loss: 3.6196374135125136

Epoch: 6| Step: 12
Training loss: 4.075693626112683
Validation loss: 3.609103696872653

Epoch: 6| Step: 13
Training loss: 3.958837671107109
Validation loss: 3.600226349135299

Epoch: 8| Step: 0
Training loss: 4.210669797410177
Validation loss: 3.604736266518449

Epoch: 6| Step: 1
Training loss: 4.307382394310994
Validation loss: 3.597493349078704

Epoch: 6| Step: 2
Training loss: 3.8943392630712643
Validation loss: 3.572762007056521

Epoch: 6| Step: 3
Training loss: 4.246227609723038
Validation loss: 3.5751149833207982

Epoch: 6| Step: 4
Training loss: 3.9003074916027756
Validation loss: 3.5878926399623605

Epoch: 6| Step: 5
Training loss: 2.7241551830772814
Validation loss: 3.568748464897045

Epoch: 6| Step: 6
Training loss: 4.032004115814046
Validation loss: 3.5576919121262662

Epoch: 6| Step: 7
Training loss: 3.8210343691077084
Validation loss: 3.555165451824427

Epoch: 6| Step: 8
Training loss: 3.992764604813703
Validation loss: 3.5473990249094887

Epoch: 6| Step: 9
Training loss: 2.9549254726558156
Validation loss: 3.543907317166921

Epoch: 6| Step: 10
Training loss: 3.837454750216729
Validation loss: 3.535971351918873

Epoch: 6| Step: 11
Training loss: 3.519717263440771
Validation loss: 3.524206099996228

Epoch: 6| Step: 12
Training loss: 3.3697463223660633
Validation loss: 3.5081795351217755

Epoch: 6| Step: 13
Training loss: 3.3601162824491047
Validation loss: 3.5059221093729667

Epoch: 9| Step: 0
Training loss: 3.9546083825983067
Validation loss: 3.499910936526199

Epoch: 6| Step: 1
Training loss: 3.7953989432907984
Validation loss: 3.490952242758259

Epoch: 6| Step: 2
Training loss: 4.034990807656332
Validation loss: 3.4817106880941684

Epoch: 6| Step: 3
Training loss: 2.521776154387886
Validation loss: 3.467978840648581

Epoch: 6| Step: 4
Training loss: 3.4689234784709946
Validation loss: 3.460522529688813

Epoch: 6| Step: 5
Training loss: 3.803185763849263
Validation loss: 3.453614110777753

Epoch: 6| Step: 6
Training loss: 2.9286609529641687
Validation loss: 3.4414089213532444

Epoch: 6| Step: 7
Training loss: 3.8751875309019823
Validation loss: 3.434237182901135

Epoch: 6| Step: 8
Training loss: 3.6900127061247776
Validation loss: 3.4285394935175386

Epoch: 6| Step: 9
Training loss: 4.917690860087257
Validation loss: 3.418737176306171

Epoch: 6| Step: 10
Training loss: 2.933264905680524
Validation loss: 3.4130757492791006

Epoch: 6| Step: 11
Training loss: 3.961061735292797
Validation loss: 3.4085541031740556

Epoch: 6| Step: 12
Training loss: 3.6785842958772874
Validation loss: 3.4156583343072047

Epoch: 6| Step: 13
Training loss: 2.6851867656289
Validation loss: 3.4002536370232845

Epoch: 10| Step: 0
Training loss: 3.10659880800042
Validation loss: 3.40624995634755

Epoch: 6| Step: 1
Training loss: 3.706468063037821
Validation loss: 3.419630573891377

Epoch: 6| Step: 2
Training loss: 4.142234172867475
Validation loss: 3.410964681864963

Epoch: 6| Step: 3
Training loss: 3.3341113771943958
Validation loss: 3.392268480085603

Epoch: 6| Step: 4
Training loss: 3.172849909346676
Validation loss: 3.3798158211285796

Epoch: 6| Step: 5
Training loss: 3.0647901419006818
Validation loss: 3.3786055987417525

Epoch: 6| Step: 6
Training loss: 3.763237160489148
Validation loss: 3.380793616252487

Epoch: 6| Step: 7
Training loss: 2.9993635138204087
Validation loss: 3.363477282748098

Epoch: 6| Step: 8
Training loss: 3.703534711231934
Validation loss: 3.361260005699734

Epoch: 6| Step: 9
Training loss: 4.300022151801249
Validation loss: 3.3636053115312596

Epoch: 6| Step: 10
Training loss: 3.8636589212830064
Validation loss: 3.3608108142169852

Epoch: 6| Step: 11
Training loss: 4.37316158360609
Validation loss: 3.355826041098247

Epoch: 6| Step: 12
Training loss: 3.361057445703705
Validation loss: 3.347635148269393

Epoch: 6| Step: 13
Training loss: 2.8725920835232266
Validation loss: 3.3380232402006964

Epoch: 11| Step: 0
Training loss: 3.4775745761753734
Validation loss: 3.3390395780401905

Epoch: 6| Step: 1
Training loss: 3.431144109596371
Validation loss: 3.3360364510744285

Epoch: 6| Step: 2
Training loss: 3.359567893944249
Validation loss: 3.33223481894398

Epoch: 6| Step: 3
Training loss: 3.6439493743109965
Validation loss: 3.318779143562799

Epoch: 6| Step: 4
Training loss: 3.7310533634685266
Validation loss: 3.314344543054847

Epoch: 6| Step: 5
Training loss: 3.138142529841125
Validation loss: 3.3160744634951915

Epoch: 6| Step: 6
Training loss: 3.713085187522937
Validation loss: 3.313724312463109

Epoch: 6| Step: 7
Training loss: 3.5410379786766852
Validation loss: 3.3028894332503813

Epoch: 6| Step: 8
Training loss: 3.54763449717029
Validation loss: 3.293516853790371

Epoch: 6| Step: 9
Training loss: 4.023048989509955
Validation loss: 3.287489982049149

Epoch: 6| Step: 10
Training loss: 3.4893948784039392
Validation loss: 3.2752886065959177

Epoch: 6| Step: 11
Training loss: 3.3196001073995154
Validation loss: 3.278963001988412

Epoch: 6| Step: 12
Training loss: 3.2393356833702285
Validation loss: 3.344547471426306

Epoch: 6| Step: 13
Training loss: 4.342141272047239
Validation loss: 3.304585895747548

Epoch: 12| Step: 0
Training loss: 3.8654413770208143
Validation loss: 3.2800566034912877

Epoch: 6| Step: 1
Training loss: 3.519986714858214
Validation loss: 3.3026250491477036

Epoch: 6| Step: 2
Training loss: 3.18470941197094
Validation loss: 3.3127743109598686

Epoch: 6| Step: 3
Training loss: 3.135961305749359
Validation loss: 3.2995270139952493

Epoch: 6| Step: 4
Training loss: 3.7131210167373383
Validation loss: 3.294677566593787

Epoch: 6| Step: 5
Training loss: 3.6273861628100073
Validation loss: 3.3161583246895914

Epoch: 6| Step: 6
Training loss: 3.4051842378355266
Validation loss: 3.28705937320214

Epoch: 6| Step: 7
Training loss: 3.153926787499704
Validation loss: 3.2726559054505975

Epoch: 6| Step: 8
Training loss: 2.9764128719978897
Validation loss: 3.2647170633664455

Epoch: 6| Step: 9
Training loss: 4.028960294806702
Validation loss: 3.260095726702422

Epoch: 6| Step: 10
Training loss: 3.1363088831689603
Validation loss: 3.25338798385849

Epoch: 6| Step: 11
Training loss: 3.6575650189683513
Validation loss: 3.248864077135088

Epoch: 6| Step: 12
Training loss: 3.951287245751377
Validation loss: 3.233556855491828

Epoch: 6| Step: 13
Training loss: 3.886870752170644
Validation loss: 3.22438594495005

Epoch: 13| Step: 0
Training loss: 3.0529961550026457
Validation loss: 3.213314784256048

Epoch: 6| Step: 1
Training loss: 3.163321250461003
Validation loss: 3.2084444205511136

Epoch: 6| Step: 2
Training loss: 3.502395491310379
Validation loss: 3.1986711264189207

Epoch: 6| Step: 3
Training loss: 3.4068773724315546
Validation loss: 3.1963864721537494

Epoch: 6| Step: 4
Training loss: 3.9458014761186897
Validation loss: 3.196665500494077

Epoch: 6| Step: 5
Training loss: 2.8585772626202757
Validation loss: 3.192128868589134

Epoch: 6| Step: 6
Training loss: 3.8917282562501208
Validation loss: 3.191103163656332

Epoch: 6| Step: 7
Training loss: 3.1246095031898493
Validation loss: 3.1966317219988287

Epoch: 6| Step: 8
Training loss: 3.112724608624371
Validation loss: 3.1985152911052346

Epoch: 6| Step: 9
Training loss: 4.277522336811223
Validation loss: 3.191184619644348

Epoch: 6| Step: 10
Training loss: 3.5154508420404253
Validation loss: 3.188225261705631

Epoch: 6| Step: 11
Training loss: 3.616361255905628
Validation loss: 3.182222202072484

Epoch: 6| Step: 12
Training loss: 3.339696834076782
Validation loss: 3.1787154442368495

Epoch: 6| Step: 13
Training loss: 3.074852147463316
Validation loss: 3.1720378305953583

Epoch: 14| Step: 0
Training loss: 4.308807340084925
Validation loss: 3.1665713774091233

Epoch: 6| Step: 1
Training loss: 3.3281565203539647
Validation loss: 3.165446161726761

Epoch: 6| Step: 2
Training loss: 2.8907048394801813
Validation loss: 3.1623549054254845

Epoch: 6| Step: 3
Training loss: 3.0753954873421487
Validation loss: 3.159352122655549

Epoch: 6| Step: 4
Training loss: 3.590209676628339
Validation loss: 3.157255933714228

Epoch: 6| Step: 5
Training loss: 3.4680463747401986
Validation loss: 3.1528748512426965

Epoch: 6| Step: 6
Training loss: 3.3877226189804643
Validation loss: 3.152770722389925

Epoch: 6| Step: 7
Training loss: 3.3465897809907097
Validation loss: 3.1473615330435214

Epoch: 6| Step: 8
Training loss: 3.4972610655965477
Validation loss: 3.1445984389084134

Epoch: 6| Step: 9
Training loss: 3.643798100201456
Validation loss: 3.1410711162717213

Epoch: 6| Step: 10
Training loss: 3.28185913244831
Validation loss: 3.1339116666552425

Epoch: 6| Step: 11
Training loss: 3.2310232588350862
Validation loss: 3.1279050454106105

Epoch: 6| Step: 12
Training loss: 3.0595498959480785
Validation loss: 3.122076953831338

Epoch: 6| Step: 13
Training loss: 3.634856274687388
Validation loss: 3.1185404065007107

Epoch: 15| Step: 0
Training loss: 3.0631478072124705
Validation loss: 3.1154838366206272

Epoch: 6| Step: 1
Training loss: 3.4969410471606315
Validation loss: 3.1655707921487837

Epoch: 6| Step: 2
Training loss: 3.7389426926748217
Validation loss: 3.172214307447649

Epoch: 6| Step: 3
Training loss: 2.4995007970220704
Validation loss: 3.111175531925513

Epoch: 6| Step: 4
Training loss: 3.2453881333435857
Validation loss: 3.1111051342824236

Epoch: 6| Step: 5
Training loss: 4.060133259282247
Validation loss: 3.1287597107388847

Epoch: 6| Step: 6
Training loss: 3.1754731313859823
Validation loss: 3.1239894996950732

Epoch: 6| Step: 7
Training loss: 2.527792559104246
Validation loss: 3.112966561431591

Epoch: 6| Step: 8
Training loss: 4.3794938032722905
Validation loss: 3.1065275342157865

Epoch: 6| Step: 9
Training loss: 3.3676232146764624
Validation loss: 3.104089677484556

Epoch: 6| Step: 10
Training loss: 3.6377118288215655
Validation loss: 3.1007219570801907

Epoch: 6| Step: 11
Training loss: 2.8047240528498123
Validation loss: 3.1005123161662147

Epoch: 6| Step: 12
Training loss: 3.5302049558969872
Validation loss: 3.1009315557123265

Epoch: 6| Step: 13
Training loss: 3.45837321124391
Validation loss: 3.0979215411646535

Epoch: 16| Step: 0
Training loss: 2.7337762667593664
Validation loss: 3.097271597623936

Epoch: 6| Step: 1
Training loss: 3.146698956835746
Validation loss: 3.0923701930314778

Epoch: 6| Step: 2
Training loss: 2.8434855579206
Validation loss: 3.0900928272518864

Epoch: 6| Step: 3
Training loss: 3.7629950112201547
Validation loss: 3.087149874303734

Epoch: 6| Step: 4
Training loss: 4.205222815235984
Validation loss: 3.0868883820878255

Epoch: 6| Step: 5
Training loss: 3.554625257010004
Validation loss: 3.082170274298323

Epoch: 6| Step: 6
Training loss: 3.486964337082606
Validation loss: 3.08268632782519

Epoch: 6| Step: 7
Training loss: 4.019100599880278
Validation loss: 3.0776169839039484

Epoch: 6| Step: 8
Training loss: 3.9317343748525246
Validation loss: 3.075583677790822

Epoch: 6| Step: 9
Training loss: 3.4348095161673107
Validation loss: 3.072855223216438

Epoch: 6| Step: 10
Training loss: 3.0401944991683405
Validation loss: 3.078732508201652

Epoch: 6| Step: 11
Training loss: 2.41413242275859
Validation loss: 3.076076742440593

Epoch: 6| Step: 12
Training loss: 2.3527093163019863
Validation loss: 3.0777856566751045

Epoch: 6| Step: 13
Training loss: 3.646178107535357
Validation loss: 3.0838075942117684

Epoch: 17| Step: 0
Training loss: 3.4134812896917546
Validation loss: 3.096196620563713

Epoch: 6| Step: 1
Training loss: 3.2757720270261292
Validation loss: 3.0748784536528317

Epoch: 6| Step: 2
Training loss: 3.22722332632082
Validation loss: 3.071051400893007

Epoch: 6| Step: 3
Training loss: 3.0305615459335926
Validation loss: 3.0675868166237934

Epoch: 6| Step: 4
Training loss: 2.891163708775825
Validation loss: 3.0657436896832304

Epoch: 6| Step: 5
Training loss: 3.1183073475045684
Validation loss: 3.0629608497326264

Epoch: 6| Step: 6
Training loss: 3.3224283814299813
Validation loss: 3.0668997886867304

Epoch: 6| Step: 7
Training loss: 3.517938014062865
Validation loss: 3.0726764304872987

Epoch: 6| Step: 8
Training loss: 3.650330275133157
Validation loss: 3.062275548281079

Epoch: 6| Step: 9
Training loss: 3.3427088177091098
Validation loss: 3.0564272660396603

Epoch: 6| Step: 10
Training loss: 3.6493683307610936
Validation loss: 3.0565338668623534

Epoch: 6| Step: 11
Training loss: 3.1836536612460886
Validation loss: 3.054949077393064

Epoch: 6| Step: 12
Training loss: 3.450024624059401
Validation loss: 3.062150520473043

Epoch: 6| Step: 13
Training loss: 4.011810985125184
Validation loss: 3.078948457196616

Epoch: 18| Step: 0
Training loss: 2.8554052927712954
Validation loss: 3.0776482052442824

Epoch: 6| Step: 1
Training loss: 2.840299420221183
Validation loss: 3.074663578721807

Epoch: 6| Step: 2
Training loss: 3.4500870956263157
Validation loss: 3.076431313997812

Epoch: 6| Step: 3
Training loss: 3.4399826794565316
Validation loss: 3.0615881390433732

Epoch: 6| Step: 4
Training loss: 2.975767815505248
Validation loss: 3.051133019039604

Epoch: 6| Step: 5
Training loss: 3.8538464937308037
Validation loss: 3.0477832972736594

Epoch: 6| Step: 6
Training loss: 3.6128789894328257
Validation loss: 3.0451525661606156

Epoch: 6| Step: 7
Training loss: 3.5699075348149996
Validation loss: 3.0430748281911373

Epoch: 6| Step: 8
Training loss: 2.5504716623957213
Validation loss: 3.0437554606949457

Epoch: 6| Step: 9
Training loss: 3.7790467960703595
Validation loss: 3.040658512054532

Epoch: 6| Step: 10
Training loss: 3.479291963129462
Validation loss: 3.037270429429774

Epoch: 6| Step: 11
Training loss: 3.7205920105209658
Validation loss: 3.0342936330296655

Epoch: 6| Step: 12
Training loss: 2.956455834866407
Validation loss: 3.033784926788602

Epoch: 6| Step: 13
Training loss: 3.1823443435995786
Validation loss: 3.0331913091853595

Epoch: 19| Step: 0
Training loss: 3.7398554597555345
Validation loss: 3.0305938179623966

Epoch: 6| Step: 1
Training loss: 3.6431069488784975
Validation loss: 3.029752157644943

Epoch: 6| Step: 2
Training loss: 3.812019568017809
Validation loss: 3.03812386423254

Epoch: 6| Step: 3
Training loss: 3.720218656943265
Validation loss: 3.0496465849070975

Epoch: 6| Step: 4
Training loss: 2.808320733861836
Validation loss: 3.029878044312531

Epoch: 6| Step: 5
Training loss: 3.523996380720759
Validation loss: 3.0237557450198174

Epoch: 6| Step: 6
Training loss: 3.0406065012103483
Validation loss: 3.023185785428265

Epoch: 6| Step: 7
Training loss: 3.661714041161363
Validation loss: 3.0276020707540203

Epoch: 6| Step: 8
Training loss: 3.167478474074927
Validation loss: 3.023605699400393

Epoch: 6| Step: 9
Training loss: 3.0258126798691993
Validation loss: 3.028306308749713

Epoch: 6| Step: 10
Training loss: 3.062837543180828
Validation loss: 3.0291318217392003

Epoch: 6| Step: 11
Training loss: 3.1465731797097227
Validation loss: 3.057797347028564

Epoch: 6| Step: 12
Training loss: 3.219761661688805
Validation loss: 3.0134534915593

Epoch: 6| Step: 13
Training loss: 2.0693177334469466
Validation loss: 3.015108967514234

Epoch: 20| Step: 0
Training loss: 3.0938033282375073
Validation loss: 3.0305393241368273

Epoch: 6| Step: 1
Training loss: 3.0893520344955823
Validation loss: 3.055798237604648

Epoch: 6| Step: 2
Training loss: 2.6694444454147686
Validation loss: 3.0937896192327186

Epoch: 6| Step: 3
Training loss: 4.074939872438519
Validation loss: 3.0932009630219164

Epoch: 6| Step: 4
Training loss: 3.220321123684475
Validation loss: 3.026980984242871

Epoch: 6| Step: 5
Training loss: 4.128749876931836
Validation loss: 3.0429025286581393

Epoch: 6| Step: 6
Training loss: 2.6372328419544426
Validation loss: 3.055862459696695

Epoch: 6| Step: 7
Training loss: 3.3100643200113655
Validation loss: 3.0676934408171133

Epoch: 6| Step: 8
Training loss: 3.9770346850215246
Validation loss: 3.11031222017285

Epoch: 6| Step: 9
Training loss: 3.1877566963504216
Validation loss: 3.0494988060435264

Epoch: 6| Step: 10
Training loss: 3.2117865337919738
Validation loss: 3.0483838834320807

Epoch: 6| Step: 11
Training loss: 3.53517391980218
Validation loss: 3.05972118765104

Epoch: 6| Step: 12
Training loss: 2.7311055719174417
Validation loss: 3.0310830874930836

Epoch: 6| Step: 13
Training loss: 3.611436263549608
Validation loss: 3.025337448356631

Epoch: 21| Step: 0
Training loss: 2.9585676145242843
Validation loss: 3.0243360591658184

Epoch: 6| Step: 1
Training loss: 3.735367136405442
Validation loss: 3.0327784663181068

Epoch: 6| Step: 2
Training loss: 3.682622755274563
Validation loss: 3.034506515566468

Epoch: 6| Step: 3
Training loss: 2.916882824835163
Validation loss: 3.0389384498440877

Epoch: 6| Step: 4
Training loss: 2.8850247958223454
Validation loss: 3.0374523021862907

Epoch: 6| Step: 5
Training loss: 3.155480621534675
Validation loss: 3.052900249871747

Epoch: 6| Step: 6
Training loss: 3.2848628907643325
Validation loss: 3.0225129043533117

Epoch: 6| Step: 7
Training loss: 3.5018836810773566
Validation loss: 3.008668426752486

Epoch: 6| Step: 8
Training loss: 3.5465922642076575
Validation loss: 2.9976732467002787

Epoch: 6| Step: 9
Training loss: 3.421198669204623
Validation loss: 2.9989018600943567

Epoch: 6| Step: 10
Training loss: 3.068751901909575
Validation loss: 2.994296475096617

Epoch: 6| Step: 11
Training loss: 3.147254134582475
Validation loss: 2.9936765970185197

Epoch: 6| Step: 12
Training loss: 3.1121739963637283
Validation loss: 2.997790336368621

Epoch: 6| Step: 13
Training loss: 4.041279462901028
Validation loss: 3.0039129614103297

Epoch: 22| Step: 0
Training loss: 3.5541130523990647
Validation loss: 2.9975380007136514

Epoch: 6| Step: 1
Training loss: 3.3390549826994813
Validation loss: 3.000088355427936

Epoch: 6| Step: 2
Training loss: 3.585161910610589
Validation loss: 2.989995387712335

Epoch: 6| Step: 3
Training loss: 3.3517281017872778
Validation loss: 2.999829560910784

Epoch: 6| Step: 4
Training loss: 3.1611595117327065
Validation loss: 2.9833126830706638

Epoch: 6| Step: 5
Training loss: 3.5526322344357366
Validation loss: 2.9821370298087504

Epoch: 6| Step: 6
Training loss: 3.1448909198420663
Validation loss: 2.982193264304126

Epoch: 6| Step: 7
Training loss: 2.8618625180900517
Validation loss: 2.980930480599602

Epoch: 6| Step: 8
Training loss: 3.416008366380224
Validation loss: 2.9828574311172877

Epoch: 6| Step: 9
Training loss: 3.083090093829949
Validation loss: 2.984013637833548

Epoch: 6| Step: 10
Training loss: 3.7003556209500434
Validation loss: 2.9784109116627198

Epoch: 6| Step: 11
Training loss: 3.277296027289613
Validation loss: 2.9829091726175614

Epoch: 6| Step: 12
Training loss: 2.743615455196156
Validation loss: 2.973858595965198

Epoch: 6| Step: 13
Training loss: 2.7620360800494836
Validation loss: 2.9717766747897243

Epoch: 23| Step: 0
Training loss: 4.188991451834788
Validation loss: 2.9719737556062924

Epoch: 6| Step: 1
Training loss: 3.384256032893965
Validation loss: 2.9698536848997454

Epoch: 6| Step: 2
Training loss: 2.7827477012256714
Validation loss: 2.969202048875347

Epoch: 6| Step: 3
Training loss: 3.1189417288945536
Validation loss: 2.9667879176159713

Epoch: 6| Step: 4
Training loss: 3.2363857340131337
Validation loss: 2.9642667933042985

Epoch: 6| Step: 5
Training loss: 3.7324671001479066
Validation loss: 2.957439863674169

Epoch: 6| Step: 6
Training loss: 2.8894471114177147
Validation loss: 2.9562407208073997

Epoch: 6| Step: 7
Training loss: 2.583956509971165
Validation loss: 2.951445407957621

Epoch: 6| Step: 8
Training loss: 2.9472112631666443
Validation loss: 2.9488801916824094

Epoch: 6| Step: 9
Training loss: 3.5762996098671787
Validation loss: 2.9528627441408393

Epoch: 6| Step: 10
Training loss: 3.0577533293209957
Validation loss: 2.9552674034416766

Epoch: 6| Step: 11
Training loss: 3.6369235496341945
Validation loss: 2.948558615001636

Epoch: 6| Step: 12
Training loss: 2.768815953005221
Validation loss: 2.9512793607292354

Epoch: 6| Step: 13
Training loss: 3.362843129401648
Validation loss: 2.956038384875506

Epoch: 24| Step: 0
Training loss: 3.625182969309842
Validation loss: 2.9582470363201034

Epoch: 6| Step: 1
Training loss: 3.538963468062886
Validation loss: 2.9709306179057484

Epoch: 6| Step: 2
Training loss: 3.650468216219919
Validation loss: 2.948787542453988

Epoch: 6| Step: 3
Training loss: 3.0366015828510715
Validation loss: 2.943521448968175

Epoch: 6| Step: 4
Training loss: 2.708542879263423
Validation loss: 2.941652855545396

Epoch: 6| Step: 5
Training loss: 3.0618811780124
Validation loss: 2.9427530520336664

Epoch: 6| Step: 6
Training loss: 2.6334452335709915
Validation loss: 2.9460630361747424

Epoch: 6| Step: 7
Training loss: 3.068705596913354
Validation loss: 2.962227646583794

Epoch: 6| Step: 8
Training loss: 3.392839403034384
Validation loss: 2.9474936126325546

Epoch: 6| Step: 9
Training loss: 2.8442531601676273
Validation loss: 2.938824430325458

Epoch: 6| Step: 10
Training loss: 3.768731193432295
Validation loss: 2.93466799682657

Epoch: 6| Step: 11
Training loss: 2.4530357781968384
Validation loss: 2.932401749715259

Epoch: 6| Step: 12
Training loss: 3.4064862930512567
Validation loss: 2.9482761770994905

Epoch: 6| Step: 13
Training loss: 4.235915688487048
Validation loss: 2.954130455695479

Epoch: 25| Step: 0
Training loss: 3.387499375008951
Validation loss: 2.935795293063

Epoch: 6| Step: 1
Training loss: 2.699739132747402
Validation loss: 2.926890175085456

Epoch: 6| Step: 2
Training loss: 2.6072744720741414
Validation loss: 2.9299387606818574

Epoch: 6| Step: 3
Training loss: 3.0244183193887544
Validation loss: 2.937233234860724

Epoch: 6| Step: 4
Training loss: 3.5098153494495183
Validation loss: 2.946627554859663

Epoch: 6| Step: 5
Training loss: 3.0618855385444212
Validation loss: 2.94919823710922

Epoch: 6| Step: 6
Training loss: 3.3645310688191477
Validation loss: 2.946458726826372

Epoch: 6| Step: 7
Training loss: 3.215934929773017
Validation loss: 2.9370197618347924

Epoch: 6| Step: 8
Training loss: 3.204299785757318
Validation loss: 2.938224252868664

Epoch: 6| Step: 9
Training loss: 3.3860030072419116
Validation loss: 2.935894199287724

Epoch: 6| Step: 10
Training loss: 3.259726129273165
Validation loss: 2.9477380373558337

Epoch: 6| Step: 11
Training loss: 3.1925899780307314
Validation loss: 2.9529658370871914

Epoch: 6| Step: 12
Training loss: 3.782266653544298
Validation loss: 2.9325030870689495

Epoch: 6| Step: 13
Training loss: 3.4845355215004115
Validation loss: 2.9244463033758863

Epoch: 26| Step: 0
Training loss: 3.2500815748100726
Validation loss: 2.9363823402780715

Epoch: 6| Step: 1
Training loss: 4.198192552662219
Validation loss: 2.9635695987378967

Epoch: 6| Step: 2
Training loss: 2.9072667466046327
Validation loss: 2.9246264011653342

Epoch: 6| Step: 3
Training loss: 3.3108779966688116
Validation loss: 2.91874991055035

Epoch: 6| Step: 4
Training loss: 3.337939624192358
Validation loss: 2.919925653834718

Epoch: 6| Step: 5
Training loss: 3.352319022918448
Validation loss: 2.9213720720922964

Epoch: 6| Step: 6
Training loss: 2.998721486091608
Validation loss: 2.914990558489722

Epoch: 6| Step: 7
Training loss: 2.8143655311989386
Validation loss: 2.917894123285731

Epoch: 6| Step: 8
Training loss: 2.420463889246842
Validation loss: 2.917446976686246

Epoch: 6| Step: 9
Training loss: 2.907516039658943
Validation loss: 2.910743817805856

Epoch: 6| Step: 10
Training loss: 3.105895889944607
Validation loss: 2.9110458239994736

Epoch: 6| Step: 11
Training loss: 3.9822039504805193
Validation loss: 2.913540463566091

Epoch: 6| Step: 12
Training loss: 2.7387758425978044
Validation loss: 2.912071374080578

Epoch: 6| Step: 13
Training loss: 3.5397326106580502
Validation loss: 2.913604361611716

Epoch: 27| Step: 0
Training loss: 3.5022869812625426
Validation loss: 2.91141252167784

Epoch: 6| Step: 1
Training loss: 3.2964299339972962
Validation loss: 2.9111859881784308

Epoch: 6| Step: 2
Training loss: 2.8130171406342686
Validation loss: 2.9065363497345307

Epoch: 6| Step: 3
Training loss: 2.6779403996804563
Validation loss: 2.905627531232027

Epoch: 6| Step: 4
Training loss: 3.396161880669759
Validation loss: 2.905651909130728

Epoch: 6| Step: 5
Training loss: 3.0475103253885143
Validation loss: 2.902771164247958

Epoch: 6| Step: 6
Training loss: 3.2165685872622864
Validation loss: 2.9057442900701167

Epoch: 6| Step: 7
Training loss: 3.6375672429217505
Validation loss: 2.909939810062695

Epoch: 6| Step: 8
Training loss: 3.268343875082764
Validation loss: 2.9092212871711145

Epoch: 6| Step: 9
Training loss: 2.8301478786046688
Validation loss: 2.9182877431913097

Epoch: 6| Step: 10
Training loss: 3.493268078371685
Validation loss: 2.9157041786909432

Epoch: 6| Step: 11
Training loss: 2.9105258783717893
Validation loss: 2.9194839114514384

Epoch: 6| Step: 12
Training loss: 3.363105866824916
Validation loss: 2.918207658622909

Epoch: 6| Step: 13
Training loss: 3.2675092453887826
Validation loss: 2.908325257980466

Epoch: 28| Step: 0
Training loss: 3.227734812284401
Validation loss: 2.8977070823335858

Epoch: 6| Step: 1
Training loss: 3.619839118628199
Validation loss: 2.9011010322072046

Epoch: 6| Step: 2
Training loss: 3.398557603840355
Validation loss: 2.8929905748967046

Epoch: 6| Step: 3
Training loss: 3.4304626562090035
Validation loss: 2.901540282610561

Epoch: 6| Step: 4
Training loss: 3.3139180441042217
Validation loss: 2.8957270353904785

Epoch: 6| Step: 5
Training loss: 3.399039519908227
Validation loss: 2.8959315783435127

Epoch: 6| Step: 6
Training loss: 2.9991240812138136
Validation loss: 2.8894337459639234

Epoch: 6| Step: 7
Training loss: 3.6241964567715406
Validation loss: 2.8878113715354736

Epoch: 6| Step: 8
Training loss: 2.3322582038590354
Validation loss: 2.891042846881579

Epoch: 6| Step: 9
Training loss: 2.9183767664139304
Validation loss: 2.888408023802551

Epoch: 6| Step: 10
Training loss: 3.114280932661513
Validation loss: 2.8920640870274035

Epoch: 6| Step: 11
Training loss: 2.6237506618199053
Validation loss: 2.8924258931556754

Epoch: 6| Step: 12
Training loss: 3.327607307108191
Validation loss: 2.8971238576454046

Epoch: 6| Step: 13
Training loss: 3.264135577751986
Validation loss: 2.9005913152447524

Epoch: 29| Step: 0
Training loss: 2.5817961477567857
Validation loss: 2.8973956694431884

Epoch: 6| Step: 1
Training loss: 3.6638683275775854
Validation loss: 2.9021793110712393

Epoch: 6| Step: 2
Training loss: 2.8865038387841992
Validation loss: 2.9140513166220554

Epoch: 6| Step: 3
Training loss: 2.598776118453218
Validation loss: 2.9277612482610067

Epoch: 6| Step: 4
Training loss: 3.0918122976163036
Validation loss: 2.913152208377785

Epoch: 6| Step: 5
Training loss: 3.7532756486144767
Validation loss: 2.8980471568720496

Epoch: 6| Step: 6
Training loss: 3.3917729416551663
Validation loss: 2.889320512430565

Epoch: 6| Step: 7
Training loss: 2.6204875125569282
Validation loss: 2.885455046462505

Epoch: 6| Step: 8
Training loss: 3.5564674029412378
Validation loss: 2.8866382212263857

Epoch: 6| Step: 9
Training loss: 3.8681625832331177
Validation loss: 2.90109832284763

Epoch: 6| Step: 10
Training loss: 3.5402730256737933
Validation loss: 2.9605285983846525

Epoch: 6| Step: 11
Training loss: 3.364577270754302
Validation loss: 2.8846046783379

Epoch: 6| Step: 12
Training loss: 2.235605394609638
Validation loss: 2.8820573300259853

Epoch: 6| Step: 13
Training loss: 3.206190772745788
Validation loss: 2.894027712439814

Epoch: 30| Step: 0
Training loss: 2.6600535368730385
Validation loss: 2.918510937393582

Epoch: 6| Step: 1
Training loss: 3.9424763069094015
Validation loss: 2.9445581480632077

Epoch: 6| Step: 2
Training loss: 3.6586352010167196
Validation loss: 2.9329990708190956

Epoch: 6| Step: 3
Training loss: 2.766712384439859
Validation loss: 2.9044187370853534

Epoch: 6| Step: 4
Training loss: 3.1920110159853574
Validation loss: 2.8873386911011916

Epoch: 6| Step: 5
Training loss: 3.777073342586601
Validation loss: 2.882308035875713

Epoch: 6| Step: 6
Training loss: 3.770755043411347
Validation loss: 2.8910906726170342

Epoch: 6| Step: 7
Training loss: 3.331337537921509
Validation loss: 2.881463397542941

Epoch: 6| Step: 8
Training loss: 2.002239165921811
Validation loss: 2.877718853932899

Epoch: 6| Step: 9
Training loss: 3.4378793680487645
Validation loss: 2.876280552477992

Epoch: 6| Step: 10
Training loss: 3.3429173653922137
Validation loss: 2.876380452562624

Epoch: 6| Step: 11
Training loss: 2.9082672337523388
Validation loss: 2.879674101854841

Epoch: 6| Step: 12
Training loss: 2.228007814554587
Validation loss: 2.8799589004184676

Epoch: 6| Step: 13
Training loss: 2.9047437476693228
Validation loss: 2.881049106997114

Epoch: 31| Step: 0
Training loss: 3.278922572537256
Validation loss: 2.8850646644812925

Epoch: 6| Step: 1
Training loss: 3.795623196181056
Validation loss: 2.885681585015593

Epoch: 6| Step: 2
Training loss: 2.8864886407673267
Validation loss: 2.8973334207191557

Epoch: 6| Step: 3
Training loss: 3.048459311152591
Validation loss: 2.894808900456053

Epoch: 6| Step: 4
Training loss: 3.5093213343062493
Validation loss: 2.889948547198486

Epoch: 6| Step: 5
Training loss: 2.3517062628008163
Validation loss: 2.884266926165021

Epoch: 6| Step: 6
Training loss: 2.7094098714764536
Validation loss: 2.8820005844729444

Epoch: 6| Step: 7
Training loss: 3.660025188171764
Validation loss: 2.8798984174747537

Epoch: 6| Step: 8
Training loss: 3.373028497253786
Validation loss: 2.875719414683004

Epoch: 6| Step: 9
Training loss: 3.1722076692560983
Validation loss: 2.876479279686906

Epoch: 6| Step: 10
Training loss: 3.0345456799198964
Validation loss: 2.8718756221561814

Epoch: 6| Step: 11
Training loss: 3.6083073874253615
Validation loss: 2.871600689478396

Epoch: 6| Step: 12
Training loss: 2.835315814853523
Validation loss: 2.875230958247969

Epoch: 6| Step: 13
Training loss: 2.5925405968896604
Validation loss: 2.8775324606750825

Epoch: 32| Step: 0
Training loss: 3.0354349408530186
Validation loss: 2.877802210366342

Epoch: 6| Step: 1
Training loss: 2.969768791061567
Validation loss: 2.8692005788148367

Epoch: 6| Step: 2
Training loss: 3.2164544373174118
Validation loss: 2.869542421808483

Epoch: 6| Step: 3
Training loss: 3.4660352101240726
Validation loss: 2.869645352699551

Epoch: 6| Step: 4
Training loss: 2.9689554243792013
Validation loss: 2.8643877737165684

Epoch: 6| Step: 5
Training loss: 3.5651790517220032
Validation loss: 2.864183647187081

Epoch: 6| Step: 6
Training loss: 3.1903654196541957
Validation loss: 2.8647462973381033

Epoch: 6| Step: 7
Training loss: 2.729802433732059
Validation loss: 2.8659517013923925

Epoch: 6| Step: 8
Training loss: 3.369329138747778
Validation loss: 2.864760377545719

Epoch: 6| Step: 9
Training loss: 3.510224122937097
Validation loss: 2.8619702944688528

Epoch: 6| Step: 10
Training loss: 2.781747323480674
Validation loss: 2.864614143690651

Epoch: 6| Step: 11
Training loss: 3.3686126737612914
Validation loss: 2.867576054867786

Epoch: 6| Step: 12
Training loss: 2.848491530499716
Validation loss: 2.8662260891962728

Epoch: 6| Step: 13
Training loss: 3.2924397361529234
Validation loss: 2.868857948030392

Epoch: 33| Step: 0
Training loss: 3.4540927273176516
Validation loss: 2.8638168255103738

Epoch: 6| Step: 1
Training loss: 2.6563096881218886
Validation loss: 2.8605978184714718

Epoch: 6| Step: 2
Training loss: 3.12387919353811
Validation loss: 2.861740144573477

Epoch: 6| Step: 3
Training loss: 2.648287518510912
Validation loss: 2.8625661122013915

Epoch: 6| Step: 4
Training loss: 3.0087180619868454
Validation loss: 2.8580702645879583

Epoch: 6| Step: 5
Training loss: 3.581675670950322
Validation loss: 2.859039756792735

Epoch: 6| Step: 6
Training loss: 3.491117650633035
Validation loss: 2.8589718854642094

Epoch: 6| Step: 7
Training loss: 2.601372330963597
Validation loss: 2.858628460049124

Epoch: 6| Step: 8
Training loss: 3.3719141946376
Validation loss: 2.855305636578048

Epoch: 6| Step: 9
Training loss: 2.7828532537767177
Validation loss: 2.8577572676321545

Epoch: 6| Step: 10
Training loss: 3.2985144421427677
Validation loss: 2.856029462796733

Epoch: 6| Step: 11
Training loss: 3.3021530641399393
Validation loss: 2.8512570561315673

Epoch: 6| Step: 12
Training loss: 3.1780857860205196
Validation loss: 2.8561401179465125

Epoch: 6| Step: 13
Training loss: 3.57847959935235
Validation loss: 2.8582881119453054

Epoch: 34| Step: 0
Training loss: 3.0251570353455994
Validation loss: 2.858251928383295

Epoch: 6| Step: 1
Training loss: 2.9268773957885608
Validation loss: 2.8716479775164716

Epoch: 6| Step: 2
Training loss: 3.0779217493175284
Validation loss: 2.8712594611807805

Epoch: 6| Step: 3
Training loss: 2.620944568919688
Validation loss: 2.866441735483568

Epoch: 6| Step: 4
Training loss: 2.516952448738638
Validation loss: 2.869956907540733

Epoch: 6| Step: 5
Training loss: 3.182323066485756
Validation loss: 2.855183322333028

Epoch: 6| Step: 6
Training loss: 3.161208082639934
Validation loss: 2.8502924143949073

Epoch: 6| Step: 7
Training loss: 3.0625439076292813
Validation loss: 2.846945567229166

Epoch: 6| Step: 8
Training loss: 3.639386273300632
Validation loss: 2.8433412756009067

Epoch: 6| Step: 9
Training loss: 3.223102034745316
Validation loss: 2.8450610971968575

Epoch: 6| Step: 10
Training loss: 3.8128465588757647
Validation loss: 2.847049442040671

Epoch: 6| Step: 11
Training loss: 2.781135385273339
Validation loss: 2.842910140446004

Epoch: 6| Step: 12
Training loss: 3.2809020811640393
Validation loss: 2.8416713467970416

Epoch: 6| Step: 13
Training loss: 3.6703881682630106
Validation loss: 2.8440994260770487

Epoch: 35| Step: 0
Training loss: 3.5185979183525866
Validation loss: 2.844043705253622

Epoch: 6| Step: 1
Training loss: 3.02178657662732
Validation loss: 2.8428766901290765

Epoch: 6| Step: 2
Training loss: 3.0711555391285574
Validation loss: 2.8407846374249126

Epoch: 6| Step: 3
Training loss: 3.1778024995578766
Validation loss: 2.844349323463913

Epoch: 6| Step: 4
Training loss: 3.0819464648905197
Validation loss: 2.8431483888494413

Epoch: 6| Step: 5
Training loss: 2.6793042679053585
Validation loss: 2.844641177020709

Epoch: 6| Step: 6
Training loss: 3.2899747113586444
Validation loss: 2.842911921433942

Epoch: 6| Step: 7
Training loss: 2.7518356438949514
Validation loss: 2.8397245009545995

Epoch: 6| Step: 8
Training loss: 3.692195682782934
Validation loss: 2.83814173027187

Epoch: 6| Step: 9
Training loss: 3.5762892099129027
Validation loss: 2.8346959305447954

Epoch: 6| Step: 10
Training loss: 3.3754012257891053
Validation loss: 2.8331702985913467

Epoch: 6| Step: 11
Training loss: 2.80480395742073
Validation loss: 2.8321863108084897

Epoch: 6| Step: 12
Training loss: 2.8803472134779913
Validation loss: 2.8310700472719925

Epoch: 6| Step: 13
Training loss: 2.8601168311204863
Validation loss: 2.8312062948167167

Epoch: 36| Step: 0
Training loss: 2.567081914066599
Validation loss: 2.833599519320146

Epoch: 6| Step: 1
Training loss: 2.6938784115093415
Validation loss: 2.8434134952140884

Epoch: 6| Step: 2
Training loss: 3.093944813152933
Validation loss: 2.843278645916391

Epoch: 6| Step: 3
Training loss: 3.217526101315494
Validation loss: 2.8493922397828944

Epoch: 6| Step: 4
Training loss: 3.5749580327485084
Validation loss: 2.8540694215174023

Epoch: 6| Step: 5
Training loss: 3.6810897455485536
Validation loss: 2.8379491622101427

Epoch: 6| Step: 6
Training loss: 3.5002482189988315
Validation loss: 2.831356247914863

Epoch: 6| Step: 7
Training loss: 3.5175633491065983
Validation loss: 2.82786743898477

Epoch: 6| Step: 8
Training loss: 2.679048957038483
Validation loss: 2.8253900164894015

Epoch: 6| Step: 9
Training loss: 3.4583413610403504
Validation loss: 2.8261737146126444

Epoch: 6| Step: 10
Training loss: 1.8739532091778568
Validation loss: 2.829493764593661

Epoch: 6| Step: 11
Training loss: 3.4939258183168924
Validation loss: 2.8308241323981633

Epoch: 6| Step: 12
Training loss: 3.332990787707398
Validation loss: 2.8242599263496584

Epoch: 6| Step: 13
Training loss: 2.118683233868927
Validation loss: 2.823094663005791

Epoch: 37| Step: 0
Training loss: 3.4284476643885307
Validation loss: 2.823373636254759

Epoch: 6| Step: 1
Training loss: 2.8780589208980145
Validation loss: 2.8227436185334005

Epoch: 6| Step: 2
Training loss: 3.1001043855873767
Validation loss: 2.8242225824522205

Epoch: 6| Step: 3
Training loss: 2.4853947304085087
Validation loss: 2.822525006931019

Epoch: 6| Step: 4
Training loss: 3.5441588366114263
Validation loss: 2.8256845758629696

Epoch: 6| Step: 5
Training loss: 3.1750033881702517
Validation loss: 2.8273732499449395

Epoch: 6| Step: 6
Training loss: 3.341147577647554
Validation loss: 2.8338184436029574

Epoch: 6| Step: 7
Training loss: 2.6711842497327862
Validation loss: 2.8437825349490193

Epoch: 6| Step: 8
Training loss: 2.704588829986608
Validation loss: 2.8462779517109564

Epoch: 6| Step: 9
Training loss: 3.620589236572261
Validation loss: 2.8839075633318445

Epoch: 6| Step: 10
Training loss: 3.183943316218672
Validation loss: 2.858638803812928

Epoch: 6| Step: 11
Training loss: 3.149222529301875
Validation loss: 2.8325014545958376

Epoch: 6| Step: 12
Training loss: 3.059063131239001
Validation loss: 2.814719791908242

Epoch: 6| Step: 13
Training loss: 3.368764981323222
Validation loss: 2.8164280377179116

Epoch: 38| Step: 0
Training loss: 3.3172136274288997
Validation loss: 2.8176532855456977

Epoch: 6| Step: 1
Training loss: 2.644535667607324
Validation loss: 2.834765779428027

Epoch: 6| Step: 2
Training loss: 4.13755114198177
Validation loss: 2.868282623434319

Epoch: 6| Step: 3
Training loss: 3.3931622131409367
Validation loss: 2.8603078825614996

Epoch: 6| Step: 4
Training loss: 3.098031828192876
Validation loss: 2.854950517792001

Epoch: 6| Step: 5
Training loss: 3.946034461712475
Validation loss: 2.844416462158588

Epoch: 6| Step: 6
Training loss: 3.511100061080005
Validation loss: 2.8171269493686357

Epoch: 6| Step: 7
Training loss: 2.47732031747063
Validation loss: 2.816217101385559

Epoch: 6| Step: 8
Training loss: 2.695930918637643
Validation loss: 2.8153308727301276

Epoch: 6| Step: 9
Training loss: 2.7577391012220382
Validation loss: 2.8173416138948406

Epoch: 6| Step: 10
Training loss: 3.1927913055508
Validation loss: 2.8203589654546213

Epoch: 6| Step: 11
Training loss: 2.6940577143184243
Validation loss: 2.8347260579760096

Epoch: 6| Step: 12
Training loss: 2.576679171111973
Validation loss: 2.835627550519977

Epoch: 6| Step: 13
Training loss: 3.0212632673522273
Validation loss: 2.8361887248637685

Epoch: 39| Step: 0
Training loss: 3.1458619139596165
Validation loss: 2.8342802310082202

Epoch: 6| Step: 1
Training loss: 3.5437002888309483
Validation loss: 2.824796444827069

Epoch: 6| Step: 2
Training loss: 3.7457708034593282
Validation loss: 2.8212364323427757

Epoch: 6| Step: 3
Training loss: 3.532698882619869
Validation loss: 2.818910006142774

Epoch: 6| Step: 4
Training loss: 3.402836760617409
Validation loss: 2.8178755803227737

Epoch: 6| Step: 5
Training loss: 2.392042948755094
Validation loss: 2.81616469232521

Epoch: 6| Step: 6
Training loss: 2.917024390672174
Validation loss: 2.814908261088832

Epoch: 6| Step: 7
Training loss: 2.648422826315591
Validation loss: 2.813301204741814

Epoch: 6| Step: 8
Training loss: 2.6744046199305664
Validation loss: 2.8102123222118935

Epoch: 6| Step: 9
Training loss: 2.8206257738602174
Validation loss: 2.8084599289638454

Epoch: 6| Step: 10
Training loss: 3.26486839765276
Validation loss: 2.806233882649937

Epoch: 6| Step: 11
Training loss: 2.8517287114444736
Validation loss: 2.806725101342976

Epoch: 6| Step: 12
Training loss: 3.1810599699390503
Validation loss: 2.809804744731005

Epoch: 6| Step: 13
Training loss: 3.210463291616019
Validation loss: 2.808323061687441

Epoch: 40| Step: 0
Training loss: 3.323250366165002
Validation loss: 2.8053219876458617

Epoch: 6| Step: 1
Training loss: 3.133646485392083
Validation loss: 2.805974251944814

Epoch: 6| Step: 2
Training loss: 2.484224134938775
Validation loss: 2.806496976953247

Epoch: 6| Step: 3
Training loss: 2.9402073497703447
Validation loss: 2.8030800142244225

Epoch: 6| Step: 4
Training loss: 3.6570733602340804
Validation loss: 2.8070296125025713

Epoch: 6| Step: 5
Training loss: 2.57464457160692
Validation loss: 2.8102121890221206

Epoch: 6| Step: 6
Training loss: 3.5131813881703464
Validation loss: 2.811910147665563

Epoch: 6| Step: 7
Training loss: 3.194980296281642
Validation loss: 2.8163136284716543

Epoch: 6| Step: 8
Training loss: 3.5790633258104183
Validation loss: 2.820981464909485

Epoch: 6| Step: 9
Training loss: 3.33602497781235
Validation loss: 2.8109834362708264

Epoch: 6| Step: 10
Training loss: 3.0133747144687804
Validation loss: 2.803782397667533

Epoch: 6| Step: 11
Training loss: 2.880855402539634
Validation loss: 2.8028238799089986

Epoch: 6| Step: 12
Training loss: 2.619309023820608
Validation loss: 2.8000950011970476

Epoch: 6| Step: 13
Training loss: 2.7754936225995146
Validation loss: 2.801011772003708

Epoch: 41| Step: 0
Training loss: 2.958275718307018
Validation loss: 2.800328170498322

Epoch: 6| Step: 1
Training loss: 3.2507434874864467
Validation loss: 2.825305532017045

Epoch: 6| Step: 2
Training loss: 2.842833318836425
Validation loss: 2.8321177941303497

Epoch: 6| Step: 3
Training loss: 3.7580662758643655
Validation loss: 2.842413370784982

Epoch: 6| Step: 4
Training loss: 2.818112854938813
Validation loss: 2.801227225778359

Epoch: 6| Step: 5
Training loss: 3.340517852749201
Validation loss: 2.798039771095037

Epoch: 6| Step: 6
Training loss: 3.163181964185716
Validation loss: 2.7924714254699294

Epoch: 6| Step: 7
Training loss: 3.287236157407227
Validation loss: 2.7937589936819256

Epoch: 6| Step: 8
Training loss: 3.280465749842341
Validation loss: 2.7937743731398115

Epoch: 6| Step: 9
Training loss: 2.0540385218558046
Validation loss: 2.7910890019821575

Epoch: 6| Step: 10
Training loss: 3.5736960106981517
Validation loss: 2.79097372119885

Epoch: 6| Step: 11
Training loss: 2.7286611967363603
Validation loss: 2.7925279586866676

Epoch: 6| Step: 12
Training loss: 2.8568649531496355
Validation loss: 2.7922150910846093

Epoch: 6| Step: 13
Training loss: 3.1897633314681526
Validation loss: 2.7889433795385266

Epoch: 42| Step: 0
Training loss: 3.5066856834369795
Validation loss: 2.788893621946986

Epoch: 6| Step: 1
Training loss: 3.54133798906679
Validation loss: 2.7922868078109873

Epoch: 6| Step: 2
Training loss: 3.6607292972482863
Validation loss: 2.789455495627537

Epoch: 6| Step: 3
Training loss: 3.5382507605912017
Validation loss: 2.788446010062086

Epoch: 6| Step: 4
Training loss: 3.059779924943445
Validation loss: 2.7885453058978333

Epoch: 6| Step: 5
Training loss: 2.6508616827902207
Validation loss: 2.7842027052757508

Epoch: 6| Step: 6
Training loss: 2.363702506360354
Validation loss: 2.7867027303574226

Epoch: 6| Step: 7
Training loss: 2.858533057824552
Validation loss: 2.7865738435451535

Epoch: 6| Step: 8
Training loss: 2.9648310443671266
Validation loss: 2.781856487791484

Epoch: 6| Step: 9
Training loss: 2.976852442920029
Validation loss: 2.7906506201111143

Epoch: 6| Step: 10
Training loss: 2.5755265521586113
Validation loss: 2.7882701589005374

Epoch: 6| Step: 11
Training loss: 2.5891619629249862
Validation loss: 2.7960151518858423

Epoch: 6| Step: 12
Training loss: 3.3365026348188787
Validation loss: 2.7974005341934487

Epoch: 6| Step: 13
Training loss: 3.5570469665515265
Validation loss: 2.8131668931774687

Epoch: 43| Step: 0
Training loss: 2.9690437573105433
Validation loss: 2.806575939530214

Epoch: 6| Step: 1
Training loss: 2.5869675166712107
Validation loss: 2.800196957363106

Epoch: 6| Step: 2
Training loss: 3.417830075311828
Validation loss: 2.789886464119141

Epoch: 6| Step: 3
Training loss: 3.1493990733654935
Validation loss: 2.7860208891168425

Epoch: 6| Step: 4
Training loss: 3.8191972286481195
Validation loss: 2.7875209404186276

Epoch: 6| Step: 5
Training loss: 2.390852674226745
Validation loss: 2.790421726396086

Epoch: 6| Step: 6
Training loss: 3.190005495790154
Validation loss: 2.791037594391659

Epoch: 6| Step: 7
Training loss: 3.5421309821252023
Validation loss: 2.7821746474523263

Epoch: 6| Step: 8
Training loss: 3.491670506246879
Validation loss: 2.7799583589137202

Epoch: 6| Step: 9
Training loss: 2.669317080709627
Validation loss: 2.7751958763318614

Epoch: 6| Step: 10
Training loss: 3.2981793322921336
Validation loss: 2.7751262888449792

Epoch: 6| Step: 11
Training loss: 2.806410576319149
Validation loss: 2.776220197284808

Epoch: 6| Step: 12
Training loss: 2.8949522878243257
Validation loss: 2.773093638059549

Epoch: 6| Step: 13
Training loss: 2.236775102881459
Validation loss: 2.773206000434953

Epoch: 44| Step: 0
Training loss: 3.4465717254883215
Validation loss: 2.7707561217239705

Epoch: 6| Step: 1
Training loss: 3.5559826849310987
Validation loss: 2.771355015393567

Epoch: 6| Step: 2
Training loss: 2.864932137263123
Validation loss: 2.776215049166583

Epoch: 6| Step: 3
Training loss: 3.1402288538151955
Validation loss: 2.777415914414172

Epoch: 6| Step: 4
Training loss: 2.5687498774841724
Validation loss: 2.778537334829504

Epoch: 6| Step: 5
Training loss: 2.1353818068721586
Validation loss: 2.781204130156956

Epoch: 6| Step: 6
Training loss: 3.2219989268077955
Validation loss: 2.7848390735368325

Epoch: 6| Step: 7
Training loss: 3.3649869662935092
Validation loss: 2.8036212012195505

Epoch: 6| Step: 8
Training loss: 3.540696733089815
Validation loss: 2.8008202359450163

Epoch: 6| Step: 9
Training loss: 2.3887678924002236
Validation loss: 2.775527963519905

Epoch: 6| Step: 10
Training loss: 2.994328223595422
Validation loss: 2.7666679535274823

Epoch: 6| Step: 11
Training loss: 2.894598791490159
Validation loss: 2.7670753216734303

Epoch: 6| Step: 12
Training loss: 3.1556114835066227
Validation loss: 2.7664166436737707

Epoch: 6| Step: 13
Training loss: 3.764087283890945
Validation loss: 2.7703215571849906

Epoch: 45| Step: 0
Training loss: 3.163434905929429
Validation loss: 2.7690410110988903

Epoch: 6| Step: 1
Training loss: 2.642658601763314
Validation loss: 2.7715904212487343

Epoch: 6| Step: 2
Training loss: 3.4918117107652726
Validation loss: 2.7767478024617

Epoch: 6| Step: 3
Training loss: 3.1307538277105276
Validation loss: 2.771943384339192

Epoch: 6| Step: 4
Training loss: 2.5716528832525043
Validation loss: 2.7738920956252096

Epoch: 6| Step: 5
Training loss: 3.609260986641163
Validation loss: 2.7729038240970763

Epoch: 6| Step: 6
Training loss: 2.3634866420303
Validation loss: 2.767145238548659

Epoch: 6| Step: 7
Training loss: 3.028833428846371
Validation loss: 2.7660862439726572

Epoch: 6| Step: 8
Training loss: 3.895007013552109
Validation loss: 2.764599129153608

Epoch: 6| Step: 9
Training loss: 2.598979045247714
Validation loss: 2.763313193478718

Epoch: 6| Step: 10
Training loss: 3.0257359326724362
Validation loss: 2.7608016399043196

Epoch: 6| Step: 11
Training loss: 2.8538924222371516
Validation loss: 2.7597381507057457

Epoch: 6| Step: 12
Training loss: 3.5476808682788614
Validation loss: 2.757763389213568

Epoch: 6| Step: 13
Training loss: 2.792859652862703
Validation loss: 2.7573322736853076

Epoch: 46| Step: 0
Training loss: 3.3355375313686615
Validation loss: 2.7556322923322734

Epoch: 6| Step: 1
Training loss: 3.3172873684569923
Validation loss: 2.760529501697105

Epoch: 6| Step: 2
Training loss: 2.6324295988024766
Validation loss: 2.757624669525468

Epoch: 6| Step: 3
Training loss: 2.8840731213806308
Validation loss: 2.7581586788112387

Epoch: 6| Step: 4
Training loss: 3.2528237033826604
Validation loss: 2.7549296305452042

Epoch: 6| Step: 5
Training loss: 3.3932344441971782
Validation loss: 2.759030808973523

Epoch: 6| Step: 6
Training loss: 2.7722673553465698
Validation loss: 2.7562276571848647

Epoch: 6| Step: 7
Training loss: 2.967028470068952
Validation loss: 2.756432124910073

Epoch: 6| Step: 8
Training loss: 2.8689521535485016
Validation loss: 2.754402669212274

Epoch: 6| Step: 9
Training loss: 2.4963139062302884
Validation loss: 2.75708296190298

Epoch: 6| Step: 10
Training loss: 3.738098331388814
Validation loss: 2.7609151135178966

Epoch: 6| Step: 11
Training loss: 3.1969193053694593
Validation loss: 2.7642724602420743

Epoch: 6| Step: 12
Training loss: 3.125869782520992
Validation loss: 2.764149100472627

Epoch: 6| Step: 13
Training loss: 2.331593023431942
Validation loss: 2.7684734385153384

Epoch: 47| Step: 0
Training loss: 3.6600832936965895
Validation loss: 2.7805408017408233

Epoch: 6| Step: 1
Training loss: 3.200508798442631
Validation loss: 2.756063340773909

Epoch: 6| Step: 2
Training loss: 2.1933830715132454
Validation loss: 2.750726850814089

Epoch: 6| Step: 3
Training loss: 2.95201663253978
Validation loss: 2.7481370770538214

Epoch: 6| Step: 4
Training loss: 3.7299597268065283
Validation loss: 2.7491620316865304

Epoch: 6| Step: 5
Training loss: 2.537941835018007
Validation loss: 2.7485365254969993

Epoch: 6| Step: 6
Training loss: 3.7648868074664166
Validation loss: 2.7458350196621697

Epoch: 6| Step: 7
Training loss: 2.890465314423738
Validation loss: 2.7471105044334543

Epoch: 6| Step: 8
Training loss: 2.9653543427166764
Validation loss: 2.7477193746381263

Epoch: 6| Step: 9
Training loss: 2.9527691016115094
Validation loss: 2.7456640495685574

Epoch: 6| Step: 10
Training loss: 3.2363026352628514
Validation loss: 2.7427898108126323

Epoch: 6| Step: 11
Training loss: 2.8231549508476084
Validation loss: 2.744604829416685

Epoch: 6| Step: 12
Training loss: 2.5267408733827743
Validation loss: 2.741492357524994

Epoch: 6| Step: 13
Training loss: 3.172492507432728
Validation loss: 2.744289091517893

Epoch: 48| Step: 0
Training loss: 3.8963672591656886
Validation loss: 2.746358453508417

Epoch: 6| Step: 1
Training loss: 3.1509545348339794
Validation loss: 2.746460253890086

Epoch: 6| Step: 2
Training loss: 2.9903150631055153
Validation loss: 2.7436073221463433

Epoch: 6| Step: 3
Training loss: 3.730860760448583
Validation loss: 2.74197355915925

Epoch: 6| Step: 4
Training loss: 2.468306489532759
Validation loss: 2.743341502791986

Epoch: 6| Step: 5
Training loss: 3.425972075242201
Validation loss: 2.743662249665083

Epoch: 6| Step: 6
Training loss: 2.935725711088253
Validation loss: 2.738567513166073

Epoch: 6| Step: 7
Training loss: 2.3013691434420527
Validation loss: 2.7376546094890024

Epoch: 6| Step: 8
Training loss: 2.7117181802681447
Validation loss: 2.73874723384613

Epoch: 6| Step: 9
Training loss: 3.5444862959838046
Validation loss: 2.736112195006011

Epoch: 6| Step: 10
Training loss: 2.7917995326369924
Validation loss: 2.735148655073218

Epoch: 6| Step: 11
Training loss: 2.900680291196084
Validation loss: 2.7472938971637397

Epoch: 6| Step: 12
Training loss: 3.0614626937753817
Validation loss: 2.7729028357712986

Epoch: 6| Step: 13
Training loss: 1.7738173829950286
Validation loss: 2.767661593709362

Epoch: 49| Step: 0
Training loss: 2.392782197929539
Validation loss: 2.776119880672624

Epoch: 6| Step: 1
Training loss: 2.687134740093931
Validation loss: 2.772765031603354

Epoch: 6| Step: 2
Training loss: 3.2508476325721873
Validation loss: 2.774855969397728

Epoch: 6| Step: 3
Training loss: 3.2047570513501817
Validation loss: 2.805258651713521

Epoch: 6| Step: 4
Training loss: 3.097614379445899
Validation loss: 2.8154800278107843

Epoch: 6| Step: 5
Training loss: 3.0177163891766523
Validation loss: 2.8144380589364624

Epoch: 6| Step: 6
Training loss: 3.492545636478954
Validation loss: 2.8175108067792176

Epoch: 6| Step: 7
Training loss: 3.254455593306086
Validation loss: 2.824619822140102

Epoch: 6| Step: 8
Training loss: 3.6438456030420108
Validation loss: 2.8591280818871647

Epoch: 6| Step: 9
Training loss: 2.4518910602993618
Validation loss: 2.801701916634563

Epoch: 6| Step: 10
Training loss: 2.207423352544962
Validation loss: 2.8033747934341404

Epoch: 6| Step: 11
Training loss: 3.6848253798292783
Validation loss: 2.8035903637111774

Epoch: 6| Step: 12
Training loss: 3.1454147329832773
Validation loss: 2.8024452934206745

Epoch: 6| Step: 13
Training loss: 3.4496327688507944
Validation loss: 2.8095773348384645

Epoch: 50| Step: 0
Training loss: 3.485928039674733
Validation loss: 2.8206535130690797

Epoch: 6| Step: 1
Training loss: 3.187553854094689
Validation loss: 2.791869904698214

Epoch: 6| Step: 2
Training loss: 2.537485049349333
Validation loss: 2.7562411802622004

Epoch: 6| Step: 3
Training loss: 3.1695988949465184
Validation loss: 2.752437772366816

Epoch: 6| Step: 4
Training loss: 2.723597009641653
Validation loss: 2.7412509852817593

Epoch: 6| Step: 5
Training loss: 3.2802779438138887
Validation loss: 2.73283830675063

Epoch: 6| Step: 6
Training loss: 3.562940603749887
Validation loss: 2.735412963187895

Epoch: 6| Step: 7
Training loss: 2.7372956291100565
Validation loss: 2.7322774362773874

Epoch: 6| Step: 8
Training loss: 3.265249422369324
Validation loss: 2.732036748471548

Epoch: 6| Step: 9
Training loss: 2.7259017887070005
Validation loss: 2.7304090934380447

Epoch: 6| Step: 10
Training loss: 2.816093692022866
Validation loss: 2.7317782699436974

Epoch: 6| Step: 11
Training loss: 3.2807814490611693
Validation loss: 2.733750464961988

Epoch: 6| Step: 12
Training loss: 2.863214302060949
Validation loss: 2.740986576054499

Epoch: 6| Step: 13
Training loss: 3.223081322581715
Validation loss: 2.7455247353598935

Epoch: 51| Step: 0
Training loss: 3.277807118846656
Validation loss: 2.7298805569994897

Epoch: 6| Step: 1
Training loss: 2.424137068124435
Validation loss: 2.7294751853750143

Epoch: 6| Step: 2
Training loss: 2.915555760582604
Validation loss: 2.7285818932449994

Epoch: 6| Step: 3
Training loss: 3.23084054857704
Validation loss: 2.7221462916037127

Epoch: 6| Step: 4
Training loss: 3.3895605147863104
Validation loss: 2.71810034511335

Epoch: 6| Step: 5
Training loss: 3.452991465752708
Validation loss: 2.720650505231561

Epoch: 6| Step: 6
Training loss: 2.7242090949808295
Validation loss: 2.7208943645010133

Epoch: 6| Step: 7
Training loss: 2.93686555544708
Validation loss: 2.7231479067329007

Epoch: 6| Step: 8
Training loss: 2.429697116452533
Validation loss: 2.7239074812084882

Epoch: 6| Step: 9
Training loss: 2.9861660521034095
Validation loss: 2.717951836478092

Epoch: 6| Step: 10
Training loss: 3.6570991768953216
Validation loss: 2.7186562862989367

Epoch: 6| Step: 11
Training loss: 3.1651668175581507
Validation loss: 2.717972942946201

Epoch: 6| Step: 12
Training loss: 3.0622930651447287
Validation loss: 2.7227344766230983

Epoch: 6| Step: 13
Training loss: 2.581052193440197
Validation loss: 2.7302506795891124

Epoch: 52| Step: 0
Training loss: 2.8881584572685743
Validation loss: 2.738950119912716

Epoch: 6| Step: 1
Training loss: 2.833785825014089
Validation loss: 2.761821778496417

Epoch: 6| Step: 2
Training loss: 2.9414012245246743
Validation loss: 2.7733446617827866

Epoch: 6| Step: 3
Training loss: 2.97643401902419
Validation loss: 2.7903482491790133

Epoch: 6| Step: 4
Training loss: 2.6436194421442
Validation loss: 2.7707859201481937

Epoch: 6| Step: 5
Training loss: 2.9787336626137098
Validation loss: 2.7477710645901183

Epoch: 6| Step: 6
Training loss: 3.4318047247065304
Validation loss: 2.721995430648026

Epoch: 6| Step: 7
Training loss: 3.3362609563528265
Validation loss: 2.7150865124173458

Epoch: 6| Step: 8
Training loss: 3.26771529617192
Validation loss: 2.7141990738388024

Epoch: 6| Step: 9
Training loss: 3.4078025429434575
Validation loss: 2.71262179561008

Epoch: 6| Step: 10
Training loss: 2.895480310524956
Validation loss: 2.710009614772789

Epoch: 6| Step: 11
Training loss: 3.2440568429691607
Validation loss: 2.712459128540538

Epoch: 6| Step: 12
Training loss: 2.876143186758494
Validation loss: 2.716806981217506

Epoch: 6| Step: 13
Training loss: 2.612975782665407
Validation loss: 2.7144421564675367

Epoch: 53| Step: 0
Training loss: 2.773846749212446
Validation loss: 2.7106625072688098

Epoch: 6| Step: 1
Training loss: 2.5132049862025463
Validation loss: 2.7129317749997175

Epoch: 6| Step: 2
Training loss: 2.9804441118534393
Validation loss: 2.715792822198045

Epoch: 6| Step: 3
Training loss: 3.1032774673607113
Validation loss: 2.7149305321347414

Epoch: 6| Step: 4
Training loss: 2.9762690041490862
Validation loss: 2.714221681998712

Epoch: 6| Step: 5
Training loss: 3.0232816749654075
Validation loss: 2.7177501589611506

Epoch: 6| Step: 6
Training loss: 3.4122044026549827
Validation loss: 2.7430851081975507

Epoch: 6| Step: 7
Training loss: 3.1329583112692974
Validation loss: 2.7369819629312593

Epoch: 6| Step: 8
Training loss: 2.3216456427059255
Validation loss: 2.7293019534010146

Epoch: 6| Step: 9
Training loss: 3.3565184757537345
Validation loss: 2.7171281638374323

Epoch: 6| Step: 10
Training loss: 3.422310022023256
Validation loss: 2.719981405829803

Epoch: 6| Step: 11
Training loss: 2.735130336522132
Validation loss: 2.714975679428742

Epoch: 6| Step: 12
Training loss: 3.55130883925078
Validation loss: 2.7116208635006234

Epoch: 6| Step: 13
Training loss: 3.2096975489464565
Validation loss: 2.7137141837854077

Epoch: 54| Step: 0
Training loss: 3.3403331375733623
Validation loss: 2.709077944441077

Epoch: 6| Step: 1
Training loss: 2.6669444495796224
Validation loss: 2.708268139403955

Epoch: 6| Step: 2
Training loss: 3.4374901511311324
Validation loss: 2.708573381057791

Epoch: 6| Step: 3
Training loss: 2.563766538658716
Validation loss: 2.708366757952567

Epoch: 6| Step: 4
Training loss: 2.6072113752226405
Validation loss: 2.707647668136596

Epoch: 6| Step: 5
Training loss: 3.826157044581072
Validation loss: 2.704568349894154

Epoch: 6| Step: 6
Training loss: 3.2749136644005357
Validation loss: 2.704148217846213

Epoch: 6| Step: 7
Training loss: 2.4748289376685078
Validation loss: 2.70234061156011

Epoch: 6| Step: 8
Training loss: 2.3700997847463174
Validation loss: 2.7038392074142936

Epoch: 6| Step: 9
Training loss: 2.9173182894907552
Validation loss: 2.698607255930463

Epoch: 6| Step: 10
Training loss: 3.0405945826358685
Validation loss: 2.7017211588103396

Epoch: 6| Step: 11
Training loss: 3.8148122560793607
Validation loss: 2.701594368729173

Epoch: 6| Step: 12
Training loss: 2.8488679879675383
Validation loss: 2.7018079012964917

Epoch: 6| Step: 13
Training loss: 2.4976884645944564
Validation loss: 2.707186889009728

Epoch: 55| Step: 0
Training loss: 2.9622500285988003
Validation loss: 2.7185928370965016

Epoch: 6| Step: 1
Training loss: 2.459586508355366
Validation loss: 2.705051829597239

Epoch: 6| Step: 2
Training loss: 2.666437963771581
Validation loss: 2.706991405774183

Epoch: 6| Step: 3
Training loss: 3.285004420633114
Validation loss: 2.7008977123045956

Epoch: 6| Step: 4
Training loss: 2.7038820121800833
Validation loss: 2.7016407656162658

Epoch: 6| Step: 5
Training loss: 3.420744966270882
Validation loss: 2.699443372975164

Epoch: 6| Step: 6
Training loss: 3.22094592398936
Validation loss: 2.6954543732810166

Epoch: 6| Step: 7
Training loss: 3.044318902272781
Validation loss: 2.696739703720962

Epoch: 6| Step: 8
Training loss: 3.3495772023782915
Validation loss: 2.694753488594081

Epoch: 6| Step: 9
Training loss: 2.254134935119257
Validation loss: 2.6959979364733466

Epoch: 6| Step: 10
Training loss: 2.5461995920127163
Validation loss: 2.696290959351988

Epoch: 6| Step: 11
Training loss: 3.352411193809305
Validation loss: 2.703971030952357

Epoch: 6| Step: 12
Training loss: 3.3475343199061034
Validation loss: 2.7124806406778106

Epoch: 6| Step: 13
Training loss: 3.704905922708182
Validation loss: 2.6939390711667683

Epoch: 56| Step: 0
Training loss: 3.3825903416514382
Validation loss: 2.6885815423780746

Epoch: 6| Step: 1
Training loss: 2.4057757418057153
Validation loss: 2.687991914518221

Epoch: 6| Step: 2
Training loss: 2.6840658202990766
Validation loss: 2.693890578380485

Epoch: 6| Step: 3
Training loss: 2.904606508271905
Validation loss: 2.6932316306098545

Epoch: 6| Step: 4
Training loss: 3.4238605747980944
Validation loss: 2.6906701554836245

Epoch: 6| Step: 5
Training loss: 2.55373875910992
Validation loss: 2.6928096231805125

Epoch: 6| Step: 6
Training loss: 2.977463473232885
Validation loss: 2.6894923582977697

Epoch: 6| Step: 7
Training loss: 3.281663850389483
Validation loss: 2.6876086484711212

Epoch: 6| Step: 8
Training loss: 3.0688086168086666
Validation loss: 2.6917003041900363

Epoch: 6| Step: 9
Training loss: 2.647806548183149
Validation loss: 2.6883469353870533

Epoch: 6| Step: 10
Training loss: 2.8227052128459906
Validation loss: 2.691735336030726

Epoch: 6| Step: 11
Training loss: 3.5407223209160312
Validation loss: 2.6896075793881415

Epoch: 6| Step: 12
Training loss: 3.282363266780858
Validation loss: 2.6870372180121955

Epoch: 6| Step: 13
Training loss: 3.1971774826064387
Validation loss: 2.688615445843629

Epoch: 57| Step: 0
Training loss: 2.909364405693654
Validation loss: 2.6880067794410825

Epoch: 6| Step: 1
Training loss: 2.683306238578653
Validation loss: 2.6983945170537105

Epoch: 6| Step: 2
Training loss: 3.5264759031116393
Validation loss: 2.7020024734572825

Epoch: 6| Step: 3
Training loss: 2.5558439198032064
Validation loss: 2.7125353252162903

Epoch: 6| Step: 4
Training loss: 2.6036918105473856
Validation loss: 2.767128951389467

Epoch: 6| Step: 5
Training loss: 3.0681130488231503
Validation loss: 2.743620652336915

Epoch: 6| Step: 6
Training loss: 2.762755030946998
Validation loss: 2.730985759627133

Epoch: 6| Step: 7
Training loss: 3.15153771061148
Validation loss: 2.690594222854249

Epoch: 6| Step: 8
Training loss: 2.6086278519596333
Validation loss: 2.682290049830299

Epoch: 6| Step: 9
Training loss: 2.5250824565454324
Validation loss: 2.680230509394274

Epoch: 6| Step: 10
Training loss: 3.6101287451106803
Validation loss: 2.684255644419101

Epoch: 6| Step: 11
Training loss: 3.623108732204428
Validation loss: 2.6872680556341546

Epoch: 6| Step: 12
Training loss: 3.1861023175991146
Validation loss: 2.686853333397757

Epoch: 6| Step: 13
Training loss: 3.1930430964361007
Validation loss: 2.6899939886757056

Epoch: 58| Step: 0
Training loss: 3.4460332207476023
Validation loss: 2.6906041587988665

Epoch: 6| Step: 1
Training loss: 2.8867258528646547
Validation loss: 2.6891405517018243

Epoch: 6| Step: 2
Training loss: 3.144219614070612
Validation loss: 2.69091861420495

Epoch: 6| Step: 3
Training loss: 3.132932437113443
Validation loss: 2.685302160007558

Epoch: 6| Step: 4
Training loss: 2.526993929252986
Validation loss: 2.6838362824016517

Epoch: 6| Step: 5
Training loss: 2.817724504030732
Validation loss: 2.6822790900434454

Epoch: 6| Step: 6
Training loss: 3.4233698954451355
Validation loss: 2.6818183972824907

Epoch: 6| Step: 7
Training loss: 2.6124250665896893
Validation loss: 2.6799049773517845

Epoch: 6| Step: 8
Training loss: 2.6977245208382623
Validation loss: 2.6898468542231644

Epoch: 6| Step: 9
Training loss: 2.817563056138652
Validation loss: 2.694085959289588

Epoch: 6| Step: 10
Training loss: 3.422152155273101
Validation loss: 2.7075211802053465

Epoch: 6| Step: 11
Training loss: 3.1841390505480596
Validation loss: 2.721867938597823

Epoch: 6| Step: 12
Training loss: 3.1094309739485273
Validation loss: 2.7406757699647706

Epoch: 6| Step: 13
Training loss: 2.770594727608735
Validation loss: 2.7147859125888316

Epoch: 59| Step: 0
Training loss: 2.8279842109832933
Validation loss: 2.7012204657964385

Epoch: 6| Step: 1
Training loss: 3.5139451824465415
Validation loss: 2.6881426257297925

Epoch: 6| Step: 2
Training loss: 3.265098419809124
Validation loss: 2.6808797211797826

Epoch: 6| Step: 3
Training loss: 3.2397849131646588
Validation loss: 2.679163838791733

Epoch: 6| Step: 4
Training loss: 3.188755162263682
Validation loss: 2.675738033541197

Epoch: 6| Step: 5
Training loss: 3.0467261644837884
Validation loss: 2.6787903545936254

Epoch: 6| Step: 6
Training loss: 2.544150644754423
Validation loss: 2.674919002066846

Epoch: 6| Step: 7
Training loss: 3.035867693575111
Validation loss: 2.675480395539147

Epoch: 6| Step: 8
Training loss: 2.205206354567106
Validation loss: 2.67540530240479

Epoch: 6| Step: 9
Training loss: 2.6463510402297348
Validation loss: 2.677467520363717

Epoch: 6| Step: 10
Training loss: 2.980483148822526
Validation loss: 2.6779632708679126

Epoch: 6| Step: 11
Training loss: 2.9451586938662007
Validation loss: 2.6746853264311614

Epoch: 6| Step: 12
Training loss: 3.400305083555722
Validation loss: 2.6783838328871505

Epoch: 6| Step: 13
Training loss: 3.075326954897089
Validation loss: 2.6831321736701756

Epoch: 60| Step: 0
Training loss: 2.9846568349006457
Validation loss: 2.6945647274963638

Epoch: 6| Step: 1
Training loss: 2.7825149916855936
Validation loss: 2.705463334818021

Epoch: 6| Step: 2
Training loss: 2.828672745914416
Validation loss: 2.713833542820822

Epoch: 6| Step: 3
Training loss: 3.1145699967488993
Validation loss: 2.7062116075549256

Epoch: 6| Step: 4
Training loss: 2.471431676026339
Validation loss: 2.7086008745921193

Epoch: 6| Step: 5
Training loss: 3.137317035097176
Validation loss: 2.679984020429788

Epoch: 6| Step: 6
Training loss: 3.6807727549701394
Validation loss: 2.6728663902940415

Epoch: 6| Step: 7
Training loss: 2.1245480225042592
Validation loss: 2.6679696551639265

Epoch: 6| Step: 8
Training loss: 3.066729213933672
Validation loss: 2.6638434520952288

Epoch: 6| Step: 9
Training loss: 2.6621210177776398
Validation loss: 2.664604201464382

Epoch: 6| Step: 10
Training loss: 3.5702681590859813
Validation loss: 2.6629058691456513

Epoch: 6| Step: 11
Training loss: 2.3987184043183003
Validation loss: 2.6675917936370377

Epoch: 6| Step: 12
Training loss: 3.831956215220076
Validation loss: 2.6644840062799355

Epoch: 6| Step: 13
Training loss: 2.6186741492455217
Validation loss: 2.6707912507471807

Epoch: 61| Step: 0
Training loss: 2.7998610598288094
Validation loss: 2.6698793092993496

Epoch: 6| Step: 1
Training loss: 2.881239712711265
Validation loss: 2.6722092955765153

Epoch: 6| Step: 2
Training loss: 2.8280695282780624
Validation loss: 2.6702710523230238

Epoch: 6| Step: 3
Training loss: 2.8474985086840707
Validation loss: 2.6811643843087136

Epoch: 6| Step: 4
Training loss: 3.2300887893425054
Validation loss: 2.713401601079762

Epoch: 6| Step: 5
Training loss: 3.2231190482087038
Validation loss: 2.7331321205053216

Epoch: 6| Step: 6
Training loss: 2.7948485977302275
Validation loss: 2.728227037628118

Epoch: 6| Step: 7
Training loss: 2.4179188564495937
Validation loss: 2.667927498413628

Epoch: 6| Step: 8
Training loss: 2.9543212405406374
Validation loss: 2.6603904848553563

Epoch: 6| Step: 9
Training loss: 3.411692060467079
Validation loss: 2.663402278892339

Epoch: 6| Step: 10
Training loss: 2.1878744622294
Validation loss: 2.663820594411936

Epoch: 6| Step: 11
Training loss: 3.258382697028231
Validation loss: 2.664102899181743

Epoch: 6| Step: 12
Training loss: 3.7930767385744195
Validation loss: 2.665691557641879

Epoch: 6| Step: 13
Training loss: 3.196049313829601
Validation loss: 2.6669400335240754

Epoch: 62| Step: 0
Training loss: 2.7665036632210924
Validation loss: 2.665231784612379

Epoch: 6| Step: 1
Training loss: 2.6049908567183926
Validation loss: 2.665929831590416

Epoch: 6| Step: 2
Training loss: 3.112592862747011
Validation loss: 2.661152393772907

Epoch: 6| Step: 3
Training loss: 2.483988221968341
Validation loss: 2.661223702452974

Epoch: 6| Step: 4
Training loss: 3.0169583076021405
Validation loss: 2.6589797526640138

Epoch: 6| Step: 5
Training loss: 2.4757725752500677
Validation loss: 2.658423073539373

Epoch: 6| Step: 6
Training loss: 3.3429418995584177
Validation loss: 2.6598130584598523

Epoch: 6| Step: 7
Training loss: 3.4346629139226152
Validation loss: 2.6655358107329192

Epoch: 6| Step: 8
Training loss: 3.119757565591661
Validation loss: 2.666469049117276

Epoch: 6| Step: 9
Training loss: 3.697330367483203
Validation loss: 2.6642400614862427

Epoch: 6| Step: 10
Training loss: 3.1712558687040753
Validation loss: 2.6649259960680727

Epoch: 6| Step: 11
Training loss: 3.1240847964043024
Validation loss: 2.6588923187489937

Epoch: 6| Step: 12
Training loss: 2.5426168593836205
Validation loss: 2.665380092234498

Epoch: 6| Step: 13
Training loss: 2.652329817048502
Validation loss: 2.6665530581141357

Epoch: 63| Step: 0
Training loss: 2.3292801826489242
Validation loss: 2.663117670364956

Epoch: 6| Step: 1
Training loss: 2.953003573065746
Validation loss: 2.6606023042034055

Epoch: 6| Step: 2
Training loss: 3.0284012454922036
Validation loss: 2.6620357710510483

Epoch: 6| Step: 3
Training loss: 3.2396130003393573
Validation loss: 2.6596699076240697

Epoch: 6| Step: 4
Training loss: 2.458165330049213
Validation loss: 2.6618137488740303

Epoch: 6| Step: 5
Training loss: 3.5108604867499187
Validation loss: 2.6588678131343078

Epoch: 6| Step: 6
Training loss: 3.065508240820131
Validation loss: 2.6570136461871403

Epoch: 6| Step: 7
Training loss: 2.8086143779395036
Validation loss: 2.6619020422120383

Epoch: 6| Step: 8
Training loss: 3.488083033894516
Validation loss: 2.676080648990872

Epoch: 6| Step: 9
Training loss: 2.746710543868446
Validation loss: 2.6831740093631224

Epoch: 6| Step: 10
Training loss: 2.7565695579550025
Validation loss: 2.7045369337034435

Epoch: 6| Step: 11
Training loss: 3.2701253590484267
Validation loss: 2.7409122225563967

Epoch: 6| Step: 12
Training loss: 3.3598819793682044
Validation loss: 2.6868926962533273

Epoch: 6| Step: 13
Training loss: 2.33832879290567
Validation loss: 2.653275969302561

Epoch: 64| Step: 0
Training loss: 2.7010758411164413
Validation loss: 2.652022724525434

Epoch: 6| Step: 1
Training loss: 3.0632960005164023
Validation loss: 2.6515682590430854

Epoch: 6| Step: 2
Training loss: 2.4289494709084756
Validation loss: 2.6536996593585624

Epoch: 6| Step: 3
Training loss: 3.143810270122287
Validation loss: 2.6472206990343867

Epoch: 6| Step: 4
Training loss: 2.313131400849073
Validation loss: 2.6524628135818817

Epoch: 6| Step: 5
Training loss: 3.020799220100803
Validation loss: 2.6512957123489844

Epoch: 6| Step: 6
Training loss: 3.2971986729260214
Validation loss: 2.6539014602812028

Epoch: 6| Step: 7
Training loss: 3.408466562839888
Validation loss: 2.652298280849745

Epoch: 6| Step: 8
Training loss: 2.7635171044891687
Validation loss: 2.6526182504649407

Epoch: 6| Step: 9
Training loss: 3.524181481961145
Validation loss: 2.652260764009312

Epoch: 6| Step: 10
Training loss: 2.968372361106694
Validation loss: 2.649760582336696

Epoch: 6| Step: 11
Training loss: 3.2588565168981423
Validation loss: 2.658565796828011

Epoch: 6| Step: 12
Training loss: 2.702489701074108
Validation loss: 2.6591565554562187

Epoch: 6| Step: 13
Training loss: 3.1069835878840526
Validation loss: 2.6645540130381624

Epoch: 65| Step: 0
Training loss: 2.914909014844089
Validation loss: 2.6565739858124577

Epoch: 6| Step: 1
Training loss: 2.9003245336535524
Validation loss: 2.6543915165111778

Epoch: 6| Step: 2
Training loss: 3.0171463839605286
Validation loss: 2.657769356302235

Epoch: 6| Step: 3
Training loss: 3.1396286935615585
Validation loss: 2.6621861191301446

Epoch: 6| Step: 4
Training loss: 3.3804998443562857
Validation loss: 2.673715991636496

Epoch: 6| Step: 5
Training loss: 3.2482361041634755
Validation loss: 2.6609802208366085

Epoch: 6| Step: 6
Training loss: 2.4633815678411044
Validation loss: 2.6513848679234293

Epoch: 6| Step: 7
Training loss: 2.6301166984282416
Validation loss: 2.650301938492533

Epoch: 6| Step: 8
Training loss: 2.427037109022142
Validation loss: 2.6436681743646506

Epoch: 6| Step: 9
Training loss: 2.9206675926415424
Validation loss: 2.6430190407722423

Epoch: 6| Step: 10
Training loss: 2.929698567687428
Validation loss: 2.6456812597755976

Epoch: 6| Step: 11
Training loss: 2.964771053744799
Validation loss: 2.6445055342797614

Epoch: 6| Step: 12
Training loss: 3.1228089853307237
Validation loss: 2.6403048091165084

Epoch: 6| Step: 13
Training loss: 3.8978349300250814
Validation loss: 2.642121347033774

Epoch: 66| Step: 0
Training loss: 2.4391747614399635
Validation loss: 2.645533808222059

Epoch: 6| Step: 1
Training loss: 2.917281349441935
Validation loss: 2.6476589593672037

Epoch: 6| Step: 2
Training loss: 2.9751840037655164
Validation loss: 2.66000557034039

Epoch: 6| Step: 3
Training loss: 2.7669800278329206
Validation loss: 2.652602884725634

Epoch: 6| Step: 4
Training loss: 2.8977354284161527
Validation loss: 2.660558365664342

Epoch: 6| Step: 5
Training loss: 3.2288888299021226
Validation loss: 2.680919287450269

Epoch: 6| Step: 6
Training loss: 2.9163191088725853
Validation loss: 2.7232533462204165

Epoch: 6| Step: 7
Training loss: 3.0206044252856374
Validation loss: 2.7179315796984396

Epoch: 6| Step: 8
Training loss: 3.369823866409786
Validation loss: 2.700369031321345

Epoch: 6| Step: 9
Training loss: 3.042494221464765
Validation loss: 2.6438797228614406

Epoch: 6| Step: 10
Training loss: 2.5626939839697704
Validation loss: 2.6356437540196245

Epoch: 6| Step: 11
Training loss: 2.8032989039746785
Validation loss: 2.6388885969396783

Epoch: 6| Step: 12
Training loss: 3.2116306419971825
Validation loss: 2.6511985457915124

Epoch: 6| Step: 13
Training loss: 3.8393030261286265
Validation loss: 2.654770211049677

Epoch: 67| Step: 0
Training loss: 3.6625838234328336
Validation loss: 2.649192895684891

Epoch: 6| Step: 1
Training loss: 3.2060468047896546
Validation loss: 2.6480349029830976

Epoch: 6| Step: 2
Training loss: 2.590335482811673
Validation loss: 2.6459519722478144

Epoch: 6| Step: 3
Training loss: 3.091232354298479
Validation loss: 2.648116888726481

Epoch: 6| Step: 4
Training loss: 3.096556344368314
Validation loss: 2.6452890714347057

Epoch: 6| Step: 5
Training loss: 2.501175032087458
Validation loss: 2.643871157920223

Epoch: 6| Step: 6
Training loss: 3.0650918074979603
Validation loss: 2.6462103300814

Epoch: 6| Step: 7
Training loss: 3.2083625957260966
Validation loss: 2.6423400582980516

Epoch: 6| Step: 8
Training loss: 2.537546027757341
Validation loss: 2.6444911528720665

Epoch: 6| Step: 9
Training loss: 2.9387610143457525
Validation loss: 2.6468884291957546

Epoch: 6| Step: 10
Training loss: 3.1559695884099943
Validation loss: 2.6628436293412854

Epoch: 6| Step: 11
Training loss: 2.9281512899450126
Validation loss: 2.686747386201418

Epoch: 6| Step: 12
Training loss: 2.638909047590746
Validation loss: 2.740430653073707

Epoch: 6| Step: 13
Training loss: 2.8284777005122246
Validation loss: 2.7560951156094116

Epoch: 68| Step: 0
Training loss: 3.5226172869116548
Validation loss: 2.8383823126890886

Epoch: 6| Step: 1
Training loss: 3.2581936181074584
Validation loss: 2.663424698361917

Epoch: 6| Step: 2
Training loss: 3.05628055487027
Validation loss: 2.635938841138396

Epoch: 6| Step: 3
Training loss: 2.5676311200173294
Validation loss: 2.6332784436186647

Epoch: 6| Step: 4
Training loss: 3.4625179910020245
Validation loss: 2.6400428475401507

Epoch: 6| Step: 5
Training loss: 3.3604063358293925
Validation loss: 2.6479347655220438

Epoch: 6| Step: 6
Training loss: 2.7968702262965546
Validation loss: 2.639298578384819

Epoch: 6| Step: 7
Training loss: 2.5775368684338904
Validation loss: 2.6405871600290305

Epoch: 6| Step: 8
Training loss: 3.0765911482624557
Validation loss: 2.6361438854070167

Epoch: 6| Step: 9
Training loss: 3.004502732045707
Validation loss: 2.6327546444004715

Epoch: 6| Step: 10
Training loss: 2.401786925750605
Validation loss: 2.637272367037501

Epoch: 6| Step: 11
Training loss: 2.9866913598890394
Validation loss: 2.6411519654308564

Epoch: 6| Step: 12
Training loss: 2.8770545584206264
Validation loss: 2.660612359860003

Epoch: 6| Step: 13
Training loss: 3.044973239624496
Validation loss: 2.6696031697996303

Epoch: 69| Step: 0
Training loss: 3.149152726560374
Validation loss: 2.6942946376483095

Epoch: 6| Step: 1
Training loss: 2.6926996364981854
Validation loss: 2.6922963091106937

Epoch: 6| Step: 2
Training loss: 2.2805590693696747
Validation loss: 2.6551264703676773

Epoch: 6| Step: 3
Training loss: 3.323133567180571
Validation loss: 2.634278974321878

Epoch: 6| Step: 4
Training loss: 2.841088695050637
Validation loss: 2.6290115203476137

Epoch: 6| Step: 5
Training loss: 3.1888734439057878
Validation loss: 2.6251705190470207

Epoch: 6| Step: 6
Training loss: 3.4610185118551877
Validation loss: 2.6246683953335648

Epoch: 6| Step: 7
Training loss: 2.7685253215759604
Validation loss: 2.6258568778845777

Epoch: 6| Step: 8
Training loss: 2.797368352415656
Validation loss: 2.624862491504301

Epoch: 6| Step: 9
Training loss: 3.097390393156734
Validation loss: 2.622004619902972

Epoch: 6| Step: 10
Training loss: 2.9829086775783082
Validation loss: 2.6229367993761117

Epoch: 6| Step: 11
Training loss: 3.0995164555621866
Validation loss: 2.6197435073733333

Epoch: 6| Step: 12
Training loss: 2.893671688066542
Validation loss: 2.622708006080336

Epoch: 6| Step: 13
Training loss: 2.957593010337109
Validation loss: 2.618736471617515

Epoch: 70| Step: 0
Training loss: 2.8905939873758673
Validation loss: 2.6300809286997753

Epoch: 6| Step: 1
Training loss: 3.2433800399987516
Validation loss: 2.643646585208694

Epoch: 6| Step: 2
Training loss: 2.674254400855383
Validation loss: 2.6452402430856092

Epoch: 6| Step: 3
Training loss: 2.733896965747563
Validation loss: 2.6528497540948055

Epoch: 6| Step: 4
Training loss: 2.6402168635682037
Validation loss: 2.654508004288126

Epoch: 6| Step: 5
Training loss: 3.3529178039869945
Validation loss: 2.6655656351498482

Epoch: 6| Step: 6
Training loss: 2.8292979131789133
Validation loss: 2.6490708109167773

Epoch: 6| Step: 7
Training loss: 2.7786783051433144
Validation loss: 2.656627207929661

Epoch: 6| Step: 8
Training loss: 2.9297125649969447
Validation loss: 2.6411661126524777

Epoch: 6| Step: 9
Training loss: 3.2436055586744317
Validation loss: 2.6325451448069965

Epoch: 6| Step: 10
Training loss: 3.3243822714261166
Validation loss: 2.6204664710507592

Epoch: 6| Step: 11
Training loss: 2.692877247060626
Validation loss: 2.6147479541625223

Epoch: 6| Step: 12
Training loss: 3.015802407852346
Validation loss: 2.6117664029216927

Epoch: 6| Step: 13
Training loss: 3.1739014414608753
Validation loss: 2.6117781287721553

Epoch: 71| Step: 0
Training loss: 2.3508535945126936
Validation loss: 2.616881916521707

Epoch: 6| Step: 1
Training loss: 2.980120277281679
Validation loss: 2.61897509029922

Epoch: 6| Step: 2
Training loss: 2.4624752024065217
Validation loss: 2.6206665042960173

Epoch: 6| Step: 3
Training loss: 3.432474520283794
Validation loss: 2.637877147470403

Epoch: 6| Step: 4
Training loss: 2.636953657070707
Validation loss: 2.6291910340985605

Epoch: 6| Step: 5
Training loss: 3.3309062386758366
Validation loss: 2.6248910122467644

Epoch: 6| Step: 6
Training loss: 3.596809478083439
Validation loss: 2.6263257110406673

Epoch: 6| Step: 7
Training loss: 3.0180284478911514
Validation loss: 2.6192754760763943

Epoch: 6| Step: 8
Training loss: 3.5054155414131656
Validation loss: 2.613307952805746

Epoch: 6| Step: 9
Training loss: 3.1260722037559696
Validation loss: 2.612667744106669

Epoch: 6| Step: 10
Training loss: 2.062380469355356
Validation loss: 2.612489770499404

Epoch: 6| Step: 11
Training loss: 2.5568770145621857
Validation loss: 2.6174312619455278

Epoch: 6| Step: 12
Training loss: 2.992378089352793
Validation loss: 2.6312858795587335

Epoch: 6| Step: 13
Training loss: 3.2989061796937897
Validation loss: 2.661271935061029

Epoch: 72| Step: 0
Training loss: 3.288622176536448
Validation loss: 2.7827920292522177

Epoch: 6| Step: 1
Training loss: 2.9248434888912054
Validation loss: 2.867707273706431

Epoch: 6| Step: 2
Training loss: 2.8003291958342156
Validation loss: 2.8454431584307445

Epoch: 6| Step: 3
Training loss: 3.142181162777983
Validation loss: 2.7789440488411548

Epoch: 6| Step: 4
Training loss: 3.655265088572485
Validation loss: 2.730248906801314

Epoch: 6| Step: 5
Training loss: 2.5844761156368543
Validation loss: 2.6856492956474556

Epoch: 6| Step: 6
Training loss: 3.1294744882831274
Validation loss: 2.6685391288141567

Epoch: 6| Step: 7
Training loss: 2.9439937158600453
Validation loss: 2.6557384608855314

Epoch: 6| Step: 8
Training loss: 3.203386993858512
Validation loss: 2.627841673146915

Epoch: 6| Step: 9
Training loss: 2.5520558466047434
Validation loss: 2.6229609350131593

Epoch: 6| Step: 10
Training loss: 2.7560771204562813
Validation loss: 2.60803708870948

Epoch: 6| Step: 11
Training loss: 3.3698450916581404
Validation loss: 2.6020154252332337

Epoch: 6| Step: 12
Training loss: 2.5057995284345633
Validation loss: 2.6050832950682197

Epoch: 6| Step: 13
Training loss: 3.328873384533258
Validation loss: 2.610915511022559

Epoch: 73| Step: 0
Training loss: 3.433697765107181
Validation loss: 2.599995279583933

Epoch: 6| Step: 1
Training loss: 3.3164003549620014
Validation loss: 2.6113978304287726

Epoch: 6| Step: 2
Training loss: 2.8689488294259027
Validation loss: 2.6274718362642093

Epoch: 6| Step: 3
Training loss: 2.835929429224053
Validation loss: 2.6393095680356304

Epoch: 6| Step: 4
Training loss: 2.5040072749522744
Validation loss: 2.662061277943671

Epoch: 6| Step: 5
Training loss: 2.6213819001447023
Validation loss: 2.6864038871126112

Epoch: 6| Step: 6
Training loss: 2.906100033408142
Validation loss: 2.727271453298406

Epoch: 6| Step: 7
Training loss: 3.1759530146508044
Validation loss: 2.6991260972648714

Epoch: 6| Step: 8
Training loss: 2.998353506306302
Validation loss: 2.6627515141871614

Epoch: 6| Step: 9
Training loss: 2.4378626626991555
Validation loss: 2.646211451948091

Epoch: 6| Step: 10
Training loss: 3.1087078356366384
Validation loss: 2.6318704823413137

Epoch: 6| Step: 11
Training loss: 3.263389881125967
Validation loss: 2.6048752921120615

Epoch: 6| Step: 12
Training loss: 2.789137211501528
Validation loss: 2.603613028136568

Epoch: 6| Step: 13
Training loss: 3.047359330245496
Validation loss: 2.601348861283221

Epoch: 74| Step: 0
Training loss: 2.994643993330351
Validation loss: 2.60877381246393

Epoch: 6| Step: 1
Training loss: 3.6137127592845855
Validation loss: 2.6075015019140624

Epoch: 6| Step: 2
Training loss: 2.4524838526949555
Validation loss: 2.60978484280153

Epoch: 6| Step: 3
Training loss: 2.566512525149263
Validation loss: 2.612710258704233

Epoch: 6| Step: 4
Training loss: 3.419265100145533
Validation loss: 2.619101677866596

Epoch: 6| Step: 5
Training loss: 2.9924893139845166
Validation loss: 2.622065419025827

Epoch: 6| Step: 6
Training loss: 2.7886846377220555
Validation loss: 2.6248348875606644

Epoch: 6| Step: 7
Training loss: 3.3107902864976197
Validation loss: 2.627122373595722

Epoch: 6| Step: 8
Training loss: 2.202585898379446
Validation loss: 2.635242083968803

Epoch: 6| Step: 9
Training loss: 2.6830719241960206
Validation loss: 2.637001072677204

Epoch: 6| Step: 10
Training loss: 3.111877967540386
Validation loss: 2.6402632894030345

Epoch: 6| Step: 11
Training loss: 3.3858885137925068
Validation loss: 2.6375344988054774

Epoch: 6| Step: 12
Training loss: 3.176529199188306
Validation loss: 2.6369605557775175

Epoch: 6| Step: 13
Training loss: 2.631050946822929
Validation loss: 2.634002862417073

Epoch: 75| Step: 0
Training loss: 3.080085556030985
Validation loss: 2.640007533727358

Epoch: 6| Step: 1
Training loss: 3.1891813144857473
Validation loss: 2.642123706793385

Epoch: 6| Step: 2
Training loss: 2.661997959998859
Validation loss: 2.640740172851412

Epoch: 6| Step: 3
Training loss: 2.638810476733162
Validation loss: 2.635428463683564

Epoch: 6| Step: 4
Training loss: 3.1995496194517727
Validation loss: 2.6314254285649117

Epoch: 6| Step: 5
Training loss: 3.318056736033915
Validation loss: 2.6346004482988996

Epoch: 6| Step: 6
Training loss: 3.0279463235993194
Validation loss: 2.621121333680581

Epoch: 6| Step: 7
Training loss: 3.1926718248745294
Validation loss: 2.614467237014794

Epoch: 6| Step: 8
Training loss: 2.672607143099265
Validation loss: 2.6023678840955435

Epoch: 6| Step: 9
Training loss: 2.5190472751616855
Validation loss: 2.5975937534721583

Epoch: 6| Step: 10
Training loss: 3.093124172220603
Validation loss: 2.594661741678094

Epoch: 6| Step: 11
Training loss: 2.7289174575204207
Validation loss: 2.5946079188909614

Epoch: 6| Step: 12
Training loss: 2.998386744019428
Validation loss: 2.596267723605866

Epoch: 6| Step: 13
Training loss: 3.244252331008773
Validation loss: 2.5957516644755123

Epoch: 76| Step: 0
Training loss: 3.2899181856690594
Validation loss: 2.593355914157128

Epoch: 6| Step: 1
Training loss: 2.5122000557938873
Validation loss: 2.590894077384637

Epoch: 6| Step: 2
Training loss: 3.2502913711223465
Validation loss: 2.606619253338178

Epoch: 6| Step: 3
Training loss: 1.9782449550325705
Validation loss: 2.602945523004212

Epoch: 6| Step: 4
Training loss: 2.9630567067822753
Validation loss: 2.6064956023259676

Epoch: 6| Step: 5
Training loss: 3.0645755818725173
Validation loss: 2.610991158919622

Epoch: 6| Step: 6
Training loss: 3.4326942836736882
Validation loss: 2.609380593213124

Epoch: 6| Step: 7
Training loss: 3.3133293409214746
Validation loss: 2.6031782828411845

Epoch: 6| Step: 8
Training loss: 2.483583048185155
Validation loss: 2.5993322925856166

Epoch: 6| Step: 9
Training loss: 3.0794066263800337
Validation loss: 2.5931154422005864

Epoch: 6| Step: 10
Training loss: 3.5574704186287964
Validation loss: 2.602496354162978

Epoch: 6| Step: 11
Training loss: 2.3283948293914554
Validation loss: 2.6019282289792702

Epoch: 6| Step: 12
Training loss: 2.5727208689785477
Validation loss: 2.593796123870917

Epoch: 6| Step: 13
Training loss: 2.799896398398762
Validation loss: 2.601236526636414

Epoch: 77| Step: 0
Training loss: 2.119806225575932
Validation loss: 2.626166889557949

Epoch: 6| Step: 1
Training loss: 2.9532499741041054
Validation loss: 2.6265680734397225

Epoch: 6| Step: 2
Training loss: 3.277640255415609
Validation loss: 2.645409554386871

Epoch: 6| Step: 3
Training loss: 2.984667698751849
Validation loss: 2.681256336346466

Epoch: 6| Step: 4
Training loss: 2.4134597766623114
Validation loss: 2.6823293420232646

Epoch: 6| Step: 5
Training loss: 2.7716317329185607
Validation loss: 2.6635947219310503

Epoch: 6| Step: 6
Training loss: 3.1691222624903284
Validation loss: 2.634474524685446

Epoch: 6| Step: 7
Training loss: 3.1183593383009205
Validation loss: 2.6090842297400783

Epoch: 6| Step: 8
Training loss: 2.205626994667438
Validation loss: 2.5919965541649077

Epoch: 6| Step: 9
Training loss: 2.5718861316611505
Validation loss: 2.5835708149436307

Epoch: 6| Step: 10
Training loss: 2.7019146100153595
Validation loss: 2.584294339541511

Epoch: 6| Step: 11
Training loss: 3.5964964613592803
Validation loss: 2.578897712533515

Epoch: 6| Step: 12
Training loss: 3.4110149687542313
Validation loss: 2.582559537825578

Epoch: 6| Step: 13
Training loss: 3.5991402712083196
Validation loss: 2.5834400308455354

Epoch: 78| Step: 0
Training loss: 2.913885607221089
Validation loss: 2.591253623919701

Epoch: 6| Step: 1
Training loss: 2.684608145593271
Validation loss: 2.593714027239345

Epoch: 6| Step: 2
Training loss: 2.887746006117853
Validation loss: 2.5972777590596374

Epoch: 6| Step: 3
Training loss: 3.0339055964267883
Validation loss: 2.6046434526311395

Epoch: 6| Step: 4
Training loss: 2.3252335584908415
Validation loss: 2.6028509787815177

Epoch: 6| Step: 5
Training loss: 2.5284468588575093
Validation loss: 2.6044029548669068

Epoch: 6| Step: 6
Training loss: 2.384685243193836
Validation loss: 2.6021596010310977

Epoch: 6| Step: 7
Training loss: 2.8311178483921107
Validation loss: 2.5980016083572366

Epoch: 6| Step: 8
Training loss: 3.6281175033399884
Validation loss: 2.5952110015680483

Epoch: 6| Step: 9
Training loss: 3.6425211802268054
Validation loss: 2.5913067155200116

Epoch: 6| Step: 10
Training loss: 3.097570353179328
Validation loss: 2.597826992816474

Epoch: 6| Step: 11
Training loss: 3.3342847102202584
Validation loss: 2.5981646538421854

Epoch: 6| Step: 12
Training loss: 2.6733211596807127
Validation loss: 2.587118068362244

Epoch: 6| Step: 13
Training loss: 3.329459196056922
Validation loss: 2.5878515944011267

Epoch: 79| Step: 0
Training loss: 2.778568561102781
Validation loss: 2.592165253662743

Epoch: 6| Step: 1
Training loss: 2.938460010546603
Validation loss: 2.5998453587081074

Epoch: 6| Step: 2
Training loss: 2.838843503996926
Validation loss: 2.6209015413353054

Epoch: 6| Step: 3
Training loss: 3.402623757403725
Validation loss: 2.659693331116051

Epoch: 6| Step: 4
Training loss: 3.034077377730769
Validation loss: 2.7100862596500686

Epoch: 6| Step: 5
Training loss: 2.6777832561013026
Validation loss: 2.7348736661343387

Epoch: 6| Step: 6
Training loss: 2.848230542120728
Validation loss: 2.7213589770629842

Epoch: 6| Step: 7
Training loss: 2.8058054616518326
Validation loss: 2.669621150541543

Epoch: 6| Step: 8
Training loss: 3.024036436860502
Validation loss: 2.6372399868423897

Epoch: 6| Step: 9
Training loss: 2.6671273509094457
Validation loss: 2.625551825951123

Epoch: 6| Step: 10
Training loss: 3.4856409074086203
Validation loss: 2.609449568639614

Epoch: 6| Step: 11
Training loss: 3.2265880666832865
Validation loss: 2.593527985890871

Epoch: 6| Step: 12
Training loss: 3.031492400554813
Validation loss: 2.596764126892338

Epoch: 6| Step: 13
Training loss: 2.5500131943305244
Validation loss: 2.5741406550465373

Epoch: 80| Step: 0
Training loss: 3.540205410962285
Validation loss: 2.579465259301528

Epoch: 6| Step: 1
Training loss: 2.363568450879087
Validation loss: 2.5803037861792983

Epoch: 6| Step: 2
Training loss: 2.9929198322565296
Validation loss: 2.5856303289201885

Epoch: 6| Step: 3
Training loss: 2.8517333933167066
Validation loss: 2.5885969712219152

Epoch: 6| Step: 4
Training loss: 2.873995895850026
Validation loss: 2.5928709969932124

Epoch: 6| Step: 5
Training loss: 3.0127157300260325
Validation loss: 2.5951986763196793

Epoch: 6| Step: 6
Training loss: 2.4092007664321575
Validation loss: 2.6105008765682025

Epoch: 6| Step: 7
Training loss: 2.753066693834918
Validation loss: 2.628034413130356

Epoch: 6| Step: 8
Training loss: 3.4504461469904513
Validation loss: 2.6483969083189614

Epoch: 6| Step: 9
Training loss: 2.974181016021798
Validation loss: 2.649791367007612

Epoch: 6| Step: 10
Training loss: 2.5509405159409617
Validation loss: 2.636655119048766

Epoch: 6| Step: 11
Training loss: 3.391976223502409
Validation loss: 2.6004709451067387

Epoch: 6| Step: 12
Training loss: 2.5371608714221465
Validation loss: 2.583815009404128

Epoch: 6| Step: 13
Training loss: 3.351061519002327
Validation loss: 2.5763528778567046

Epoch: 81| Step: 0
Training loss: 2.5974972783828
Validation loss: 2.5765174375781745

Epoch: 6| Step: 1
Training loss: 2.879650501131516
Validation loss: 2.5786211885561015

Epoch: 6| Step: 2
Training loss: 3.369133548452713
Validation loss: 2.5771446703463345

Epoch: 6| Step: 3
Training loss: 2.7903970042149187
Validation loss: 2.583461957409504

Epoch: 6| Step: 4
Training loss: 3.098656664785678
Validation loss: 2.5790983429148073

Epoch: 6| Step: 5
Training loss: 2.9691189185353934
Validation loss: 2.5760887738568328

Epoch: 6| Step: 6
Training loss: 2.382697230818469
Validation loss: 2.5762901123218

Epoch: 6| Step: 7
Training loss: 2.7627862704295856
Validation loss: 2.5732808065698882

Epoch: 6| Step: 8
Training loss: 3.2763519059349284
Validation loss: 2.573695714797091

Epoch: 6| Step: 9
Training loss: 3.0234969574357993
Validation loss: 2.572113231176991

Epoch: 6| Step: 10
Training loss: 2.773531372200972
Validation loss: 2.570474319757609

Epoch: 6| Step: 11
Training loss: 2.977939557509304
Validation loss: 2.571074228439504

Epoch: 6| Step: 12
Training loss: 2.6545106466298622
Validation loss: 2.5712608225960683

Epoch: 6| Step: 13
Training loss: 3.7731975218479343
Validation loss: 2.568366764388147

Epoch: 82| Step: 0
Training loss: 3.0220950593873837
Validation loss: 2.569511368765089

Epoch: 6| Step: 1
Training loss: 2.4005366281751357
Validation loss: 2.57141561382022

Epoch: 6| Step: 2
Training loss: 2.3761991184171016
Validation loss: 2.5745311539217486

Epoch: 6| Step: 3
Training loss: 3.079932906670976
Validation loss: 2.5796594433046858

Epoch: 6| Step: 4
Training loss: 2.6124577386531596
Validation loss: 2.5851386494142856

Epoch: 6| Step: 5
Training loss: 2.6538075605880005
Validation loss: 2.5990773029352643

Epoch: 6| Step: 6
Training loss: 2.3956330146526104
Validation loss: 2.6258433530784533

Epoch: 6| Step: 7
Training loss: 3.2238324972234227
Validation loss: 2.652662188121229

Epoch: 6| Step: 8
Training loss: 3.5137051235659396
Validation loss: 2.634590785733857

Epoch: 6| Step: 9
Training loss: 3.2973064122266282
Validation loss: 2.601400453895672

Epoch: 6| Step: 10
Training loss: 3.080757216226165
Validation loss: 2.570248630424703

Epoch: 6| Step: 11
Training loss: 3.032999064992779
Validation loss: 2.5735928203036975

Epoch: 6| Step: 12
Training loss: 3.136810567421736
Validation loss: 2.56772460978934

Epoch: 6| Step: 13
Training loss: 3.002518709173681
Validation loss: 2.5672169212860494

Epoch: 83| Step: 0
Training loss: 2.510779411310022
Validation loss: 2.567485146080006

Epoch: 6| Step: 1
Training loss: 2.825658745044211
Validation loss: 2.5711919454019623

Epoch: 6| Step: 2
Training loss: 3.0872429126778935
Validation loss: 2.5696903157313824

Epoch: 6| Step: 3
Training loss: 3.5831016347333913
Validation loss: 2.5755121459104378

Epoch: 6| Step: 4
Training loss: 2.5706795195611725
Validation loss: 2.5768630005745377

Epoch: 6| Step: 5
Training loss: 3.0254002393024284
Validation loss: 2.584891605159061

Epoch: 6| Step: 6
Training loss: 2.3066080657960852
Validation loss: 2.577449688510971

Epoch: 6| Step: 7
Training loss: 3.050366714194287
Validation loss: 2.582852405818758

Epoch: 6| Step: 8
Training loss: 3.247994023923591
Validation loss: 2.587931621379253

Epoch: 6| Step: 9
Training loss: 2.7208945925146457
Validation loss: 2.59503254004962

Epoch: 6| Step: 10
Training loss: 2.6512752847216707
Validation loss: 2.597461620055437

Epoch: 6| Step: 11
Training loss: 3.0527909188821267
Validation loss: 2.604833630870197

Epoch: 6| Step: 12
Training loss: 3.3348312509099913
Validation loss: 2.61331043962553

Epoch: 6| Step: 13
Training loss: 2.7853388358640516
Validation loss: 2.6172981034357257

Epoch: 84| Step: 0
Training loss: 3.1483169418993366
Validation loss: 2.6378512988503777

Epoch: 6| Step: 1
Training loss: 2.961360367746744
Validation loss: 2.617842250587061

Epoch: 6| Step: 2
Training loss: 3.2367665759877773
Validation loss: 2.6142014820832986

Epoch: 6| Step: 3
Training loss: 2.6063008731112416
Validation loss: 2.618543783484521

Epoch: 6| Step: 4
Training loss: 3.531924833109193
Validation loss: 2.625581732541062

Epoch: 6| Step: 5
Training loss: 2.851036713084465
Validation loss: 2.6361677630048224

Epoch: 6| Step: 6
Training loss: 3.0011016094696505
Validation loss: 2.6753072799260518

Epoch: 6| Step: 7
Training loss: 2.576384725735829
Validation loss: 2.7305621427920572

Epoch: 6| Step: 8
Training loss: 3.1420494379322164
Validation loss: 2.723734044777852

Epoch: 6| Step: 9
Training loss: 2.996492560749313
Validation loss: 2.6789170344502136

Epoch: 6| Step: 10
Training loss: 2.135972138398154
Validation loss: 2.6614870160932487

Epoch: 6| Step: 11
Training loss: 3.2917818620700876
Validation loss: 2.6521481465063252

Epoch: 6| Step: 12
Training loss: 2.6334799081917
Validation loss: 2.643549515710308

Epoch: 6| Step: 13
Training loss: 3.139758545648946
Validation loss: 2.638894207259473

Epoch: 85| Step: 0
Training loss: 2.5696779528754456
Validation loss: 2.6366480736962172

Epoch: 6| Step: 1
Training loss: 2.736624702320824
Validation loss: 2.6324455633826966

Epoch: 6| Step: 2
Training loss: 2.7481364091224676
Validation loss: 2.628049974218194

Epoch: 6| Step: 3
Training loss: 3.0061598163488688
Validation loss: 2.62261091623322

Epoch: 6| Step: 4
Training loss: 2.954819611854272
Validation loss: 2.5975684257894573

Epoch: 6| Step: 5
Training loss: 2.754397257867933
Validation loss: 2.5725995637630925

Epoch: 6| Step: 6
Training loss: 2.650067303360673
Validation loss: 2.568344498339412

Epoch: 6| Step: 7
Training loss: 2.8645356515326124
Validation loss: 2.560159882774931

Epoch: 6| Step: 8
Training loss: 3.6389423460265315
Validation loss: 2.592242618685299

Epoch: 6| Step: 9
Training loss: 3.2045526067874075
Validation loss: 2.5845372064058743

Epoch: 6| Step: 10
Training loss: 3.0235184059850813
Validation loss: 2.5625411319707974

Epoch: 6| Step: 11
Training loss: 3.273583602376088
Validation loss: 2.563602593468082

Epoch: 6| Step: 12
Training loss: 2.558531129958897
Validation loss: 2.569719012851291

Epoch: 6| Step: 13
Training loss: 2.951757689726971
Validation loss: 2.5752188622499097

Epoch: 86| Step: 0
Training loss: 2.3978640588402285
Validation loss: 2.5788778936556334

Epoch: 6| Step: 1
Training loss: 3.0562009842575404
Validation loss: 2.5985777415937648

Epoch: 6| Step: 2
Training loss: 2.619928547270699
Validation loss: 2.608448986482728

Epoch: 6| Step: 3
Training loss: 2.9951036550578705
Validation loss: 2.6238646759792896

Epoch: 6| Step: 4
Training loss: 2.165629346438583
Validation loss: 2.6400889744406046

Epoch: 6| Step: 5
Training loss: 3.3002923546959964
Validation loss: 2.6474388369984925

Epoch: 6| Step: 6
Training loss: 2.9682687469715487
Validation loss: 2.61320028252125

Epoch: 6| Step: 7
Training loss: 3.0541170568110356
Validation loss: 2.5773294612958417

Epoch: 6| Step: 8
Training loss: 3.5098023070391116
Validation loss: 2.565727634262352

Epoch: 6| Step: 9
Training loss: 3.1980753475089867
Validation loss: 2.5638344214261846

Epoch: 6| Step: 10
Training loss: 2.8942231749218794
Validation loss: 2.567259132054407

Epoch: 6| Step: 11
Training loss: 2.937195782431102
Validation loss: 2.5687439053794026

Epoch: 6| Step: 12
Training loss: 2.710792999374043
Validation loss: 2.569985627844868

Epoch: 6| Step: 13
Training loss: 3.297124627231297
Validation loss: 2.5640145044887106

Epoch: 87| Step: 0
Training loss: 3.001724859927137
Validation loss: 2.563974726981076

Epoch: 6| Step: 1
Training loss: 3.077428128900788
Validation loss: 2.565724251014341

Epoch: 6| Step: 2
Training loss: 3.037199807737242
Validation loss: 2.5637085048519554

Epoch: 6| Step: 3
Training loss: 2.770840656777554
Validation loss: 2.5581887867883966

Epoch: 6| Step: 4
Training loss: 2.353911281900633
Validation loss: 2.559144032248949

Epoch: 6| Step: 5
Training loss: 3.068393097612666
Validation loss: 2.558217015664623

Epoch: 6| Step: 6
Training loss: 2.451989074900497
Validation loss: 2.5616402372991076

Epoch: 6| Step: 7
Training loss: 2.952448045756373
Validation loss: 2.556436342067157

Epoch: 6| Step: 8
Training loss: 3.0190361377010095
Validation loss: 2.564271899030074

Epoch: 6| Step: 9
Training loss: 3.0678730754733574
Validation loss: 2.5737425436976604

Epoch: 6| Step: 10
Training loss: 3.202195195411898
Validation loss: 2.5969238571235183

Epoch: 6| Step: 11
Training loss: 2.356262781730812
Validation loss: 2.6040071841391397

Epoch: 6| Step: 12
Training loss: 2.702828892713135
Validation loss: 2.6103425212210776

Epoch: 6| Step: 13
Training loss: 3.8828218333325952
Validation loss: 2.613457212736958

Epoch: 88| Step: 0
Training loss: 2.527247525819878
Validation loss: 2.6186408841298667

Epoch: 6| Step: 1
Training loss: 2.6562085316730895
Validation loss: 2.638266915160005

Epoch: 6| Step: 2
Training loss: 2.466617290758707
Validation loss: 2.6350147375810145

Epoch: 6| Step: 3
Training loss: 2.778775432296969
Validation loss: 2.6361974577484633

Epoch: 6| Step: 4
Training loss: 2.910331731024306
Validation loss: 2.656302489329708

Epoch: 6| Step: 5
Training loss: 2.7882829533061657
Validation loss: 2.6751366140806065

Epoch: 6| Step: 6
Training loss: 3.196946004039884
Validation loss: 2.693996525381131

Epoch: 6| Step: 7
Training loss: 3.1795466811281674
Validation loss: 2.639056971287796

Epoch: 6| Step: 8
Training loss: 3.1792102802396456
Validation loss: 2.6119469257140957

Epoch: 6| Step: 9
Training loss: 3.104858799179408
Validation loss: 2.591579648575519

Epoch: 6| Step: 10
Training loss: 3.236648424007446
Validation loss: 2.5952142782151553

Epoch: 6| Step: 11
Training loss: 3.024921536019119
Validation loss: 2.570064528352522

Epoch: 6| Step: 12
Training loss: 2.813978696567607
Validation loss: 2.5628913662567525

Epoch: 6| Step: 13
Training loss: 3.0889568768100326
Validation loss: 2.5489493053060883

Epoch: 89| Step: 0
Training loss: 2.615287797309571
Validation loss: 2.551756426073349

Epoch: 6| Step: 1
Training loss: 2.765849045121438
Validation loss: 2.551775631029383

Epoch: 6| Step: 2
Training loss: 2.8754477774173357
Validation loss: 2.551744004460674

Epoch: 6| Step: 3
Training loss: 3.4058750891188985
Validation loss: 2.5515747765694723

Epoch: 6| Step: 4
Training loss: 2.8750767904889942
Validation loss: 2.5531534495776675

Epoch: 6| Step: 5
Training loss: 2.534533031724741
Validation loss: 2.5536393361680965

Epoch: 6| Step: 6
Training loss: 3.186433800790672
Validation loss: 2.55129275169743

Epoch: 6| Step: 7
Training loss: 3.398554517112552
Validation loss: 2.5521972431597213

Epoch: 6| Step: 8
Training loss: 3.048313837950199
Validation loss: 2.5524505829820043

Epoch: 6| Step: 9
Training loss: 2.7923433897521854
Validation loss: 2.5566624103923625

Epoch: 6| Step: 10
Training loss: 2.888999358127268
Validation loss: 2.563318010449729

Epoch: 6| Step: 11
Training loss: 2.9098711322159123
Validation loss: 2.5733221617267072

Epoch: 6| Step: 12
Training loss: 2.474285535088699
Validation loss: 2.588259343700364

Epoch: 6| Step: 13
Training loss: 2.8171509328321287
Validation loss: 2.5942457901189107

Epoch: 90| Step: 0
Training loss: 2.6421955561952135
Validation loss: 2.62146812660309

Epoch: 6| Step: 1
Training loss: 2.775286678593126
Validation loss: 2.6252172558910156

Epoch: 6| Step: 2
Training loss: 3.034072977233204
Validation loss: 2.6547333056577287

Epoch: 6| Step: 3
Training loss: 2.70740263181757
Validation loss: 2.6351773618154355

Epoch: 6| Step: 4
Training loss: 3.4947613612006077
Validation loss: 2.596020640292962

Epoch: 6| Step: 5
Training loss: 2.892278250038708
Validation loss: 2.5691431834698273

Epoch: 6| Step: 6
Training loss: 3.4184662026395505
Validation loss: 2.550703882250984

Epoch: 6| Step: 7
Training loss: 2.5723299497817993
Validation loss: 2.550895819126021

Epoch: 6| Step: 8
Training loss: 3.1239500189188565
Validation loss: 2.5503899583946064

Epoch: 6| Step: 9
Training loss: 2.8652819712091397
Validation loss: 2.550077646124143

Epoch: 6| Step: 10
Training loss: 2.63237815466272
Validation loss: 2.553457736276896

Epoch: 6| Step: 11
Training loss: 2.840397797784353
Validation loss: 2.550577784329054

Epoch: 6| Step: 12
Training loss: 2.4690804562134807
Validation loss: 2.553668545955191

Epoch: 6| Step: 13
Training loss: 3.259631776433057
Validation loss: 2.555534132941531

Epoch: 91| Step: 0
Training loss: 2.615203560953175
Validation loss: 2.5506542457928387

Epoch: 6| Step: 1
Training loss: 2.9411050305385524
Validation loss: 2.5553963084210256

Epoch: 6| Step: 2
Training loss: 2.150355034723361
Validation loss: 2.550655775541484

Epoch: 6| Step: 3
Training loss: 2.66623176564895
Validation loss: 2.565178046758779

Epoch: 6| Step: 4
Training loss: 2.837778718006068
Validation loss: 2.569578462243166

Epoch: 6| Step: 5
Training loss: 2.9177402881823165
Validation loss: 2.5585436087996816

Epoch: 6| Step: 6
Training loss: 3.2418756909550788
Validation loss: 2.572986062963841

Epoch: 6| Step: 7
Training loss: 2.933869411149666
Validation loss: 2.590264255502645

Epoch: 6| Step: 8
Training loss: 3.1300703495395124
Validation loss: 2.6054111432588276

Epoch: 6| Step: 9
Training loss: 3.2849511480545615
Validation loss: 2.59318847350153

Epoch: 6| Step: 10
Training loss: 3.068383928828396
Validation loss: 2.585525781794095

Epoch: 6| Step: 11
Training loss: 2.760904540128055
Validation loss: 2.577231212025381

Epoch: 6| Step: 12
Training loss: 2.91663400540911
Validation loss: 2.5755008820455343

Epoch: 6| Step: 13
Training loss: 3.2240916251800527
Validation loss: 2.562120090818154

Epoch: 92| Step: 0
Training loss: 2.9953209627655784
Validation loss: 2.551908645192898

Epoch: 6| Step: 1
Training loss: 2.995136928835332
Validation loss: 2.556745970480979

Epoch: 6| Step: 2
Training loss: 2.4326368872458564
Validation loss: 2.548071486545585

Epoch: 6| Step: 3
Training loss: 2.858253801164291
Validation loss: 2.553744067608114

Epoch: 6| Step: 4
Training loss: 3.3227357884907414
Validation loss: 2.543299074284817

Epoch: 6| Step: 5
Training loss: 2.915090262060836
Validation loss: 2.549632298823667

Epoch: 6| Step: 6
Training loss: 2.642326935123676
Validation loss: 2.5581780038346453

Epoch: 6| Step: 7
Training loss: 2.292240579584705
Validation loss: 2.562372293999231

Epoch: 6| Step: 8
Training loss: 2.392875160930281
Validation loss: 2.5664616516349734

Epoch: 6| Step: 9
Training loss: 3.3810565434815976
Validation loss: 2.5770795674506712

Epoch: 6| Step: 10
Training loss: 2.888828028339405
Validation loss: 2.5866329847912053

Epoch: 6| Step: 11
Training loss: 3.0599617852212075
Validation loss: 2.5748812229038665

Epoch: 6| Step: 12
Training loss: 3.22220818381339
Validation loss: 2.590259829463606

Epoch: 6| Step: 13
Training loss: 2.9401402072820546
Validation loss: 2.55778572695483

Epoch: 93| Step: 0
Training loss: 3.08048866259732
Validation loss: 2.5562843795210717

Epoch: 6| Step: 1
Training loss: 2.860735126798397
Validation loss: 2.5352906133786055

Epoch: 6| Step: 2
Training loss: 2.7605345694835925
Validation loss: 2.5336105741707518

Epoch: 6| Step: 3
Training loss: 2.7104856790664953
Validation loss: 2.534221778861653

Epoch: 6| Step: 4
Training loss: 3.5027144668777397
Validation loss: 2.5349027518713894

Epoch: 6| Step: 5
Training loss: 2.4949668764350474
Validation loss: 2.538515660013551

Epoch: 6| Step: 6
Training loss: 2.6543743916603577
Validation loss: 2.5366960643074785

Epoch: 6| Step: 7
Training loss: 3.126110642479475
Validation loss: 2.534165319343177

Epoch: 6| Step: 8
Training loss: 2.771810220780711
Validation loss: 2.5384589112185476

Epoch: 6| Step: 9
Training loss: 3.0290812176419584
Validation loss: 2.533625133677051

Epoch: 6| Step: 10
Training loss: 2.819359362048731
Validation loss: 2.529044098218923

Epoch: 6| Step: 11
Training loss: 2.6492446974639803
Validation loss: 2.5352370788075453

Epoch: 6| Step: 12
Training loss: 3.3582289049242386
Validation loss: 2.541832758255798

Epoch: 6| Step: 13
Training loss: 2.704625765990115
Validation loss: 2.545971728678905

Epoch: 94| Step: 0
Training loss: 3.4415004687017285
Validation loss: 2.5355832457523753

Epoch: 6| Step: 1
Training loss: 2.8273324435477853
Validation loss: 2.5449588537384438

Epoch: 6| Step: 2
Training loss: 2.8009314077818175
Validation loss: 2.5597550581661745

Epoch: 6| Step: 3
Training loss: 2.873865816056611
Validation loss: 2.56063673486658

Epoch: 6| Step: 4
Training loss: 3.0831346361901693
Validation loss: 2.5767693528663465

Epoch: 6| Step: 5
Training loss: 2.483612903330321
Validation loss: 2.5676812954248116

Epoch: 6| Step: 6
Training loss: 2.5661394279580176
Validation loss: 2.5679465037012097

Epoch: 6| Step: 7
Training loss: 2.2939028031595012
Validation loss: 2.555836235421433

Epoch: 6| Step: 8
Training loss: 3.4459694303107553
Validation loss: 2.5672426692382846

Epoch: 6| Step: 9
Training loss: 3.4733209134817624
Validation loss: 2.5837566867067157

Epoch: 6| Step: 10
Training loss: 2.913489073104885
Validation loss: 2.5879127288202532

Epoch: 6| Step: 11
Training loss: 2.4574307115475067
Validation loss: 2.6011969314949557

Epoch: 6| Step: 12
Training loss: 2.725522255503811
Validation loss: 2.6164596140498393

Epoch: 6| Step: 13
Training loss: 2.7370612328466994
Validation loss: 2.5724491111218204

Epoch: 95| Step: 0
Training loss: 2.591643707647978
Validation loss: 2.535481252472977

Epoch: 6| Step: 1
Training loss: 3.014790473856736
Validation loss: 2.527709281255079

Epoch: 6| Step: 2
Training loss: 2.9589850195956395
Validation loss: 2.531698803174547

Epoch: 6| Step: 3
Training loss: 2.9521019187742428
Validation loss: 2.544161026661497

Epoch: 6| Step: 4
Training loss: 3.030301604415096
Validation loss: 2.5458226337640695

Epoch: 6| Step: 5
Training loss: 3.122228079715301
Validation loss: 2.5445329628066946

Epoch: 6| Step: 6
Training loss: 3.047567592055903
Validation loss: 2.539263914085002

Epoch: 6| Step: 7
Training loss: 2.8803520143804655
Validation loss: 2.5433040865504317

Epoch: 6| Step: 8
Training loss: 3.2437538867258295
Validation loss: 2.5429717764015662

Epoch: 6| Step: 9
Training loss: 2.9601718043394127
Validation loss: 2.5415243602865547

Epoch: 6| Step: 10
Training loss: 2.591639751854712
Validation loss: 2.5421166847838945

Epoch: 6| Step: 11
Training loss: 2.2752147950438495
Validation loss: 2.5350047785391188

Epoch: 6| Step: 12
Training loss: 3.072215027098444
Validation loss: 2.5310809981547093

Epoch: 6| Step: 13
Training loss: 3.0214010472511057
Validation loss: 2.5383855505735546

Epoch: 96| Step: 0
Training loss: 3.2887797834438928
Validation loss: 2.537332850015181

Epoch: 6| Step: 1
Training loss: 2.6550904379633944
Validation loss: 2.525391271648031

Epoch: 6| Step: 2
Training loss: 2.86163140990797
Validation loss: 2.5291747500466526

Epoch: 6| Step: 3
Training loss: 3.046429410776851
Validation loss: 2.5348879134932836

Epoch: 6| Step: 4
Training loss: 2.985352840304764
Validation loss: 2.541550245464755

Epoch: 6| Step: 5
Training loss: 2.860818467302049
Validation loss: 2.5481951153701883

Epoch: 6| Step: 6
Training loss: 2.8684962141687906
Validation loss: 2.552458000347383

Epoch: 6| Step: 7
Training loss: 2.9623675352974974
Validation loss: 2.5629402330732054

Epoch: 6| Step: 8
Training loss: 2.6383744982144535
Validation loss: 2.55143229099681

Epoch: 6| Step: 9
Training loss: 3.3776325272678513
Validation loss: 2.5438593385584296

Epoch: 6| Step: 10
Training loss: 2.9415873234956815
Validation loss: 2.5309000080931545

Epoch: 6| Step: 11
Training loss: 2.997538192289366
Validation loss: 2.546017693058654

Epoch: 6| Step: 12
Training loss: 1.7899891148667784
Validation loss: 2.558371059931462

Epoch: 6| Step: 13
Training loss: 3.008984622214955
Validation loss: 2.5953458326236447

Epoch: 97| Step: 0
Training loss: 2.825892120202824
Validation loss: 2.62629223828408

Epoch: 6| Step: 1
Training loss: 3.3130469680344623
Validation loss: 2.6404088380805155

Epoch: 6| Step: 2
Training loss: 2.634906694327387
Validation loss: 2.6111758333259094

Epoch: 6| Step: 3
Training loss: 2.524357300347095
Validation loss: 2.584038548534186

Epoch: 6| Step: 4
Training loss: 2.6421572962680813
Validation loss: 2.5585652767883773

Epoch: 6| Step: 5
Training loss: 2.3247898458029357
Validation loss: 2.5561987935070785

Epoch: 6| Step: 6
Training loss: 2.864565281666607
Validation loss: 2.5291816072262083

Epoch: 6| Step: 7
Training loss: 2.7108599297146863
Validation loss: 2.52190634815788

Epoch: 6| Step: 8
Training loss: 2.7148761555226493
Validation loss: 2.5270723957137897

Epoch: 6| Step: 9
Training loss: 3.401352187152898
Validation loss: 2.5207782767485463

Epoch: 6| Step: 10
Training loss: 3.2148781608881336
Validation loss: 2.519289706684719

Epoch: 6| Step: 11
Training loss: 2.604035356389982
Validation loss: 2.523279177286846

Epoch: 6| Step: 12
Training loss: 3.2327250082088224
Validation loss: 2.5249042409167317

Epoch: 6| Step: 13
Training loss: 3.25980555908171
Validation loss: 2.5239683346158746

Epoch: 98| Step: 0
Training loss: 2.9045731824158394
Validation loss: 2.5260238671360202

Epoch: 6| Step: 1
Training loss: 2.7151692805899823
Validation loss: 2.523527425641044

Epoch: 6| Step: 2
Training loss: 3.542110520019831
Validation loss: 2.5295557195382288

Epoch: 6| Step: 3
Training loss: 2.357037529511854
Validation loss: 2.5214098768775877

Epoch: 6| Step: 4
Training loss: 2.7566953130645877
Validation loss: 2.516748806993523

Epoch: 6| Step: 5
Training loss: 2.511992586434717
Validation loss: 2.5180208820552696

Epoch: 6| Step: 6
Training loss: 3.0069547148409956
Validation loss: 2.5185146999393853

Epoch: 6| Step: 7
Training loss: 3.12549343028253
Validation loss: 2.5212266754614285

Epoch: 6| Step: 8
Training loss: 2.677720485125354
Validation loss: 2.5260300120440156

Epoch: 6| Step: 9
Training loss: 2.71609297079481
Validation loss: 2.5458830902402196

Epoch: 6| Step: 10
Training loss: 2.9459472296106863
Validation loss: 2.5744209337749897

Epoch: 6| Step: 11
Training loss: 3.1315647599018264
Validation loss: 2.591410766519671

Epoch: 6| Step: 12
Training loss: 2.9784057997170374
Validation loss: 2.5786696091545935

Epoch: 6| Step: 13
Training loss: 3.037650204308078
Validation loss: 2.5805756566598848

Epoch: 99| Step: 0
Training loss: 2.925662599813796
Validation loss: 2.5318287722372554

Epoch: 6| Step: 1
Training loss: 3.1398021322217735
Validation loss: 2.522465501812377

Epoch: 6| Step: 2
Training loss: 3.057049630682827
Validation loss: 2.522508057961803

Epoch: 6| Step: 3
Training loss: 2.73088627189363
Validation loss: 2.5159170024214244

Epoch: 6| Step: 4
Training loss: 2.468491069880314
Validation loss: 2.5167111061256513

Epoch: 6| Step: 5
Training loss: 2.807974671534885
Validation loss: 2.5214663637616552

Epoch: 6| Step: 6
Training loss: 2.60072473548822
Validation loss: 2.5160188646207136

Epoch: 6| Step: 7
Training loss: 3.0561878783108507
Validation loss: 2.518870439079698

Epoch: 6| Step: 8
Training loss: 2.5754984104786263
Validation loss: 2.5151190132010055

Epoch: 6| Step: 9
Training loss: 2.773304165066262
Validation loss: 2.520919252899426

Epoch: 6| Step: 10
Training loss: 2.8097505481813454
Validation loss: 2.5266891037133106

Epoch: 6| Step: 11
Training loss: 3.148820801681333
Validation loss: 2.5279070069039773

Epoch: 6| Step: 12
Training loss: 3.143681950524685
Validation loss: 2.5237926742562964

Epoch: 6| Step: 13
Training loss: 3.1235378659540576
Validation loss: 2.5249090180950438

Epoch: 100| Step: 0
Training loss: 2.164840062777388
Validation loss: 2.5137030519913903

Epoch: 6| Step: 1
Training loss: 2.4738911080847203
Validation loss: 2.516772889373837

Epoch: 6| Step: 2
Training loss: 3.0695604174891575
Validation loss: 2.51648028741017

Epoch: 6| Step: 3
Training loss: 2.262711117837008
Validation loss: 2.5165320796492523

Epoch: 6| Step: 4
Training loss: 2.4874619792543733
Validation loss: 2.5254726109349237

Epoch: 6| Step: 5
Training loss: 3.228455660079085
Validation loss: 2.52813894734288

Epoch: 6| Step: 6
Training loss: 2.3244273885478437
Validation loss: 2.5367207718717415

Epoch: 6| Step: 7
Training loss: 3.1848720114007576
Validation loss: 2.5400100108782593

Epoch: 6| Step: 8
Training loss: 3.4865321850294304
Validation loss: 2.5363321930974627

Epoch: 6| Step: 9
Training loss: 3.1512885046925057
Validation loss: 2.5215341301866885

Epoch: 6| Step: 10
Training loss: 3.28364257776196
Validation loss: 2.5154588211723263

Epoch: 6| Step: 11
Training loss: 3.423549712591088
Validation loss: 2.515019387668479

Epoch: 6| Step: 12
Training loss: 2.7922858410356373
Validation loss: 2.517970411438393

Epoch: 6| Step: 13
Training loss: 2.786302755890923
Validation loss: 2.5239259402125773

Epoch: 101| Step: 0
Training loss: 2.9847303248877757
Validation loss: 2.537740670585208

Epoch: 6| Step: 1
Training loss: 3.2984667366065707
Validation loss: 2.555680851683292

Epoch: 6| Step: 2
Training loss: 3.180077681162449
Validation loss: 2.5832363746249523

Epoch: 6| Step: 3
Training loss: 2.9234246209338504
Validation loss: 2.622060338798023

Epoch: 6| Step: 4
Training loss: 2.8758487277934783
Validation loss: 2.5641274725250023

Epoch: 6| Step: 5
Training loss: 2.5120560818504463
Validation loss: 2.5687527138298702

Epoch: 6| Step: 6
Training loss: 3.1098267500234047
Validation loss: 2.5389163244180866

Epoch: 6| Step: 7
Training loss: 2.5724055803207873
Validation loss: 2.530298118619588

Epoch: 6| Step: 8
Training loss: 2.7171108522402645
Validation loss: 2.522434417370627

Epoch: 6| Step: 9
Training loss: 2.407520503732235
Validation loss: 2.529642628565142

Epoch: 6| Step: 10
Training loss: 2.9632177907805133
Validation loss: 2.5325981225580554

Epoch: 6| Step: 11
Training loss: 3.0964071249490206
Validation loss: 2.5237182513837455

Epoch: 6| Step: 12
Training loss: 2.704557006438248
Validation loss: 2.5212279007325415

Epoch: 6| Step: 13
Training loss: 2.4013074174774918
Validation loss: 2.526390936685676

Epoch: 102| Step: 0
Training loss: 2.5631288826723977
Validation loss: 2.5174959461243755

Epoch: 6| Step: 1
Training loss: 2.8836824091880415
Validation loss: 2.529213685199756

Epoch: 6| Step: 2
Training loss: 2.800680799824372
Validation loss: 2.52109513278877

Epoch: 6| Step: 3
Training loss: 2.431085411325699
Validation loss: 2.526790255691431

Epoch: 6| Step: 4
Training loss: 3.3943720913043807
Validation loss: 2.5270771353159622

Epoch: 6| Step: 5
Training loss: 2.7481009255023414
Validation loss: 2.5146521004987545

Epoch: 6| Step: 6
Training loss: 2.7290798687903615
Validation loss: 2.5223913233443223

Epoch: 6| Step: 7
Training loss: 2.6481312262412606
Validation loss: 2.527184749892362

Epoch: 6| Step: 8
Training loss: 3.0767128120618072
Validation loss: 2.5381428491711153

Epoch: 6| Step: 9
Training loss: 2.455428190318104
Validation loss: 2.5352100689122836

Epoch: 6| Step: 10
Training loss: 2.6889319042919606
Validation loss: 2.545948711941574

Epoch: 6| Step: 11
Training loss: 3.231793981690029
Validation loss: 2.5226217983573194

Epoch: 6| Step: 12
Training loss: 2.968155811476819
Validation loss: 2.516328827706088

Epoch: 6| Step: 13
Training loss: 3.605933856825075
Validation loss: 2.5070070860668867

Epoch: 103| Step: 0
Training loss: 3.023577861829897
Validation loss: 2.5000431774881804

Epoch: 6| Step: 1
Training loss: 3.0714455569231673
Validation loss: 2.502865400273685

Epoch: 6| Step: 2
Training loss: 2.5742099512902077
Validation loss: 2.506650087737124

Epoch: 6| Step: 3
Training loss: 2.9309600101008795
Validation loss: 2.4965419274175984

Epoch: 6| Step: 4
Training loss: 3.262195885760129
Validation loss: 2.4985961069108775

Epoch: 6| Step: 5
Training loss: 2.3137939544575015
Validation loss: 2.4938837153349325

Epoch: 6| Step: 6
Training loss: 3.1695126911660867
Validation loss: 2.4975084645988064

Epoch: 6| Step: 7
Training loss: 2.4271646139481153
Validation loss: 2.492299396303123

Epoch: 6| Step: 8
Training loss: 2.6467994868328306
Validation loss: 2.498150507463843

Epoch: 6| Step: 9
Training loss: 2.420931921662344
Validation loss: 2.4963048216330868

Epoch: 6| Step: 10
Training loss: 2.6776856710844728
Validation loss: 2.4919551988366

Epoch: 6| Step: 11
Training loss: 3.4483623543119335
Validation loss: 2.4965221650980625

Epoch: 6| Step: 12
Training loss: 3.0734651410130653
Validation loss: 2.5006069020944808

Epoch: 6| Step: 13
Training loss: 2.8859237794493144
Validation loss: 2.5021510048396376

Epoch: 104| Step: 0
Training loss: 3.6685555245683306
Validation loss: 2.511742064078307

Epoch: 6| Step: 1
Training loss: 2.748889178559845
Validation loss: 2.5130211856226943

Epoch: 6| Step: 2
Training loss: 2.7897878179228544
Validation loss: 2.5209490482461083

Epoch: 6| Step: 3
Training loss: 2.640194107202358
Validation loss: 2.523062408354589

Epoch: 6| Step: 4
Training loss: 2.133334588507442
Validation loss: 2.5549364633789375

Epoch: 6| Step: 5
Training loss: 2.4354664071134757
Validation loss: 2.5622490770775026

Epoch: 6| Step: 6
Training loss: 2.912105772654546
Validation loss: 2.5827214875695033

Epoch: 6| Step: 7
Training loss: 2.7856078564221387
Validation loss: 2.55374627914448

Epoch: 6| Step: 8
Training loss: 3.4848510690661914
Validation loss: 2.535650933659182

Epoch: 6| Step: 9
Training loss: 2.239797135431185
Validation loss: 2.5035024074141607

Epoch: 6| Step: 10
Training loss: 2.6170902063305514
Validation loss: 2.4982390457110695

Epoch: 6| Step: 11
Training loss: 3.2312643969453054
Validation loss: 2.502833147465986

Epoch: 6| Step: 12
Training loss: 2.9667597473915337
Validation loss: 2.5032390766409973

Epoch: 6| Step: 13
Training loss: 3.2252870121479082
Validation loss: 2.5015806625795323

Epoch: 105| Step: 0
Training loss: 3.0268932376479913
Validation loss: 2.5129248884119475

Epoch: 6| Step: 1
Training loss: 2.7088313207315116
Validation loss: 2.515272131677631

Epoch: 6| Step: 2
Training loss: 3.065160568785747
Validation loss: 2.5146773478248603

Epoch: 6| Step: 3
Training loss: 2.3707989127594122
Validation loss: 2.521444839578474

Epoch: 6| Step: 4
Training loss: 3.090292954615973
Validation loss: 2.518339899085403

Epoch: 6| Step: 5
Training loss: 3.3728486727921347
Validation loss: 2.5105393827830085

Epoch: 6| Step: 6
Training loss: 2.5116416717615397
Validation loss: 2.506025751520334

Epoch: 6| Step: 7
Training loss: 2.0764189866463534
Validation loss: 2.5046386384814503

Epoch: 6| Step: 8
Training loss: 3.4994607237481126
Validation loss: 2.51009259340319

Epoch: 6| Step: 9
Training loss: 2.9061464680924716
Validation loss: 2.5116015261640197

Epoch: 6| Step: 10
Training loss: 2.9845371701582395
Validation loss: 2.5219056396233324

Epoch: 6| Step: 11
Training loss: 2.8652235575694744
Validation loss: 2.5386167871157608

Epoch: 6| Step: 12
Training loss: 2.861856353225826
Validation loss: 2.5498149166864295

Epoch: 6| Step: 13
Training loss: 2.8614074487724785
Validation loss: 2.5452431094094665

Epoch: 106| Step: 0
Training loss: 3.3820932517885938
Validation loss: 2.515102631086972

Epoch: 6| Step: 1
Training loss: 2.706687299887776
Validation loss: 2.5094228322792986

Epoch: 6| Step: 2
Training loss: 2.6730139017196715
Validation loss: 2.5031538686521064

Epoch: 6| Step: 3
Training loss: 3.2273288213956652
Validation loss: 2.502463958006336

Epoch: 6| Step: 4
Training loss: 2.7733878977463586
Validation loss: 2.50807463917534

Epoch: 6| Step: 5
Training loss: 2.874805609724103
Validation loss: 2.5058314340946

Epoch: 6| Step: 6
Training loss: 2.60184236687917
Validation loss: 2.5041896353891238

Epoch: 6| Step: 7
Training loss: 2.813078757183348
Validation loss: 2.5061845268981475

Epoch: 6| Step: 8
Training loss: 2.7536681593111405
Validation loss: 2.5093415979882834

Epoch: 6| Step: 9
Training loss: 3.030230006436267
Validation loss: 2.5088251238130734

Epoch: 6| Step: 10
Training loss: 2.8325511376258725
Validation loss: 2.5380432183137582

Epoch: 6| Step: 11
Training loss: 2.5862297515297734
Validation loss: 2.5473753171413764

Epoch: 6| Step: 12
Training loss: 3.1288928390005974
Validation loss: 2.557804737300663

Epoch: 6| Step: 13
Training loss: 2.367272101675078
Validation loss: 2.5712984115906514

Epoch: 107| Step: 0
Training loss: 3.1747923715540876
Validation loss: 2.5660267463129505

Epoch: 6| Step: 1
Training loss: 2.8592931183311103
Validation loss: 2.5901497362368704

Epoch: 6| Step: 2
Training loss: 2.9782834822444877
Validation loss: 2.5848845278160177

Epoch: 6| Step: 3
Training loss: 3.3807331416443103
Validation loss: 2.5753477648436025

Epoch: 6| Step: 4
Training loss: 2.9332055699816686
Validation loss: 2.5665549382855795

Epoch: 6| Step: 5
Training loss: 2.6946418259501415
Validation loss: 2.5547104901867392

Epoch: 6| Step: 6
Training loss: 3.274834746639569
Validation loss: 2.54569958760681

Epoch: 6| Step: 7
Training loss: 2.475253171206162
Validation loss: 2.499765363572732

Epoch: 6| Step: 8
Training loss: 2.8008020206037707
Validation loss: 2.4972200298543425

Epoch: 6| Step: 9
Training loss: 2.666321453955842
Validation loss: 2.5011810989041834

Epoch: 6| Step: 10
Training loss: 3.1516971799549114
Validation loss: 2.501469843503793

Epoch: 6| Step: 11
Training loss: 2.090767173323437
Validation loss: 2.506094214227015

Epoch: 6| Step: 12
Training loss: 2.485712327236037
Validation loss: 2.49426793109302

Epoch: 6| Step: 13
Training loss: 3.1901709641709877
Validation loss: 2.503865659904771

Epoch: 108| Step: 0
Training loss: 3.3380957596781506
Validation loss: 2.5131015889367525

Epoch: 6| Step: 1
Training loss: 2.7153462116520797
Validation loss: 2.5180526430424224

Epoch: 6| Step: 2
Training loss: 3.3831247093134316
Validation loss: 2.5334707727482164

Epoch: 6| Step: 3
Training loss: 3.0928462085889286
Validation loss: 2.5322285245415093

Epoch: 6| Step: 4
Training loss: 2.503635623964767
Validation loss: 2.534690385492023

Epoch: 6| Step: 5
Training loss: 2.3773182045538466
Validation loss: 2.515042288904234

Epoch: 6| Step: 6
Training loss: 2.7922544192773473
Validation loss: 2.5183281494366554

Epoch: 6| Step: 7
Training loss: 2.821433396706068
Validation loss: 2.5140170404975937

Epoch: 6| Step: 8
Training loss: 3.1350716604897966
Validation loss: 2.5039462768371674

Epoch: 6| Step: 9
Training loss: 2.7851394717017413
Validation loss: 2.504232099789761

Epoch: 6| Step: 10
Training loss: 2.4629703905104603
Validation loss: 2.5048382824999083

Epoch: 6| Step: 11
Training loss: 2.558848314506992
Validation loss: 2.5079244832007292

Epoch: 6| Step: 12
Training loss: 2.7408791923301257
Validation loss: 2.518360352423929

Epoch: 6| Step: 13
Training loss: 3.4353043913591566
Validation loss: 2.5272748475297355

Epoch: 109| Step: 0
Training loss: 2.848646036404428
Validation loss: 2.5234177034734864

Epoch: 6| Step: 1
Training loss: 2.499380988733663
Validation loss: 2.538388095644441

Epoch: 6| Step: 2
Training loss: 2.4835967758366673
Validation loss: 2.554238322965394

Epoch: 6| Step: 3
Training loss: 2.6659821784188606
Validation loss: 2.5221576976309183

Epoch: 6| Step: 4
Training loss: 2.9088767701684923
Validation loss: 2.5314491818500744

Epoch: 6| Step: 5
Training loss: 2.9069462424164003
Validation loss: 2.5120243368945694

Epoch: 6| Step: 6
Training loss: 2.7621410430098408
Validation loss: 2.510087114966493

Epoch: 6| Step: 7
Training loss: 2.9791799336029077
Validation loss: 2.5078088137216494

Epoch: 6| Step: 8
Training loss: 2.812210237623294
Validation loss: 2.5092989799655543

Epoch: 6| Step: 9
Training loss: 3.4439889869912608
Validation loss: 2.505620858029539

Epoch: 6| Step: 10
Training loss: 2.0643990761314117
Validation loss: 2.512165410384368

Epoch: 6| Step: 11
Training loss: 3.104965994582654
Validation loss: 2.500292784456083

Epoch: 6| Step: 12
Training loss: 2.9609255828214995
Validation loss: 2.5019593374800504

Epoch: 6| Step: 13
Training loss: 3.5684034723773608
Validation loss: 2.5051454444884755

Epoch: 110| Step: 0
Training loss: 2.451586587178514
Validation loss: 2.5106742967354125

Epoch: 6| Step: 1
Training loss: 2.7747881971755195
Validation loss: 2.5097877233014465

Epoch: 6| Step: 2
Training loss: 3.375744772786606
Validation loss: 2.5058035481240335

Epoch: 6| Step: 3
Training loss: 2.817556117395075
Validation loss: 2.4939170933364316

Epoch: 6| Step: 4
Training loss: 2.8242726934196094
Validation loss: 2.4909471718464586

Epoch: 6| Step: 5
Training loss: 2.8958251367539876
Validation loss: 2.4909832526849054

Epoch: 6| Step: 6
Training loss: 2.5355628676461825
Validation loss: 2.490641729152229

Epoch: 6| Step: 7
Training loss: 3.0924464089908605
Validation loss: 2.490905566773757

Epoch: 6| Step: 8
Training loss: 2.7987384236050765
Validation loss: 2.4910451769630244

Epoch: 6| Step: 9
Training loss: 2.6681390710755872
Validation loss: 2.4875631155267297

Epoch: 6| Step: 10
Training loss: 2.637642163246457
Validation loss: 2.500673203426812

Epoch: 6| Step: 11
Training loss: 2.921996088629787
Validation loss: 2.523228233735342

Epoch: 6| Step: 12
Training loss: 3.300180522720529
Validation loss: 2.531962262220615

Epoch: 6| Step: 13
Training loss: 2.367370497677266
Validation loss: 2.5341360010905474

Epoch: 111| Step: 0
Training loss: 2.925400509271925
Validation loss: 2.5374910455183346

Epoch: 6| Step: 1
Training loss: 3.1889713855606803
Validation loss: 2.5343785187261467

Epoch: 6| Step: 2
Training loss: 3.187491622614604
Validation loss: 2.5325369759187666

Epoch: 6| Step: 3
Training loss: 2.880202189341793
Validation loss: 2.560749787841668

Epoch: 6| Step: 4
Training loss: 3.1520862876002522
Validation loss: 2.548301747594457

Epoch: 6| Step: 5
Training loss: 2.74003346930897
Validation loss: 2.5440661127087645

Epoch: 6| Step: 6
Training loss: 2.52095831148753
Validation loss: 2.5094124277146137

Epoch: 6| Step: 7
Training loss: 2.627346443313275
Validation loss: 2.5019104682178286

Epoch: 6| Step: 8
Training loss: 2.7216971198031166
Validation loss: 2.495237045374475

Epoch: 6| Step: 9
Training loss: 2.8354110018869543
Validation loss: 2.4860004961596416

Epoch: 6| Step: 10
Training loss: 1.080169949758522
Validation loss: 2.481943946176329

Epoch: 6| Step: 11
Training loss: 3.2710338134230788
Validation loss: 2.478711611177883

Epoch: 6| Step: 12
Training loss: 2.998263810351725
Validation loss: 2.4801749246204325

Epoch: 6| Step: 13
Training loss: 3.2429885058627197
Validation loss: 2.4803319667069963

Epoch: 112| Step: 0
Training loss: 2.680708176435748
Validation loss: 2.4816183134095913

Epoch: 6| Step: 1
Training loss: 3.1065437039884114
Validation loss: 2.4850380099830707

Epoch: 6| Step: 2
Training loss: 3.006544762513371
Validation loss: 2.4813096864774162

Epoch: 6| Step: 3
Training loss: 3.1765294994135553
Validation loss: 2.484258951242367

Epoch: 6| Step: 4
Training loss: 2.241970570135459
Validation loss: 2.493504298281935

Epoch: 6| Step: 5
Training loss: 2.794772076807644
Validation loss: 2.5316933957952816

Epoch: 6| Step: 6
Training loss: 2.0045536177922516
Validation loss: 2.5335982578700627

Epoch: 6| Step: 7
Training loss: 2.554884970029572
Validation loss: 2.5073413106571003

Epoch: 6| Step: 8
Training loss: 2.7522723606367965
Validation loss: 2.5008771834117836

Epoch: 6| Step: 9
Training loss: 2.8639464809063044
Validation loss: 2.505966470563396

Epoch: 6| Step: 10
Training loss: 2.9004741412639117
Validation loss: 2.509588430118765

Epoch: 6| Step: 11
Training loss: 2.9483476375436264
Validation loss: 2.5011963196923213

Epoch: 6| Step: 12
Training loss: 3.434242369543972
Validation loss: 2.5323294744866054

Epoch: 6| Step: 13
Training loss: 3.1939822834744147
Validation loss: 2.5408733050268473

Epoch: 113| Step: 0
Training loss: 2.979477943928999
Validation loss: 2.546813316864036

Epoch: 6| Step: 1
Training loss: 2.25446818997532
Validation loss: 2.5858774376790805

Epoch: 6| Step: 2
Training loss: 3.294646174140823
Validation loss: 2.596149316817717

Epoch: 6| Step: 3
Training loss: 2.4037464543721616
Validation loss: 2.584724272778323

Epoch: 6| Step: 4
Training loss: 2.3644503137309303
Validation loss: 2.5924326396205704

Epoch: 6| Step: 5
Training loss: 2.979073654181134
Validation loss: 2.624727512364245

Epoch: 6| Step: 6
Training loss: 3.0751480190968805
Validation loss: 2.6037581670165726

Epoch: 6| Step: 7
Training loss: 2.909690215410947
Validation loss: 2.5634911033893792

Epoch: 6| Step: 8
Training loss: 3.4745248373639503
Validation loss: 2.52332788059968

Epoch: 6| Step: 9
Training loss: 2.0127467223389366
Validation loss: 2.4969200502201003

Epoch: 6| Step: 10
Training loss: 3.689038618399047
Validation loss: 2.483763489677206

Epoch: 6| Step: 11
Training loss: 2.8456292283537628
Validation loss: 2.4829048981645525

Epoch: 6| Step: 12
Training loss: 2.6632806520022156
Validation loss: 2.4864977848717014

Epoch: 6| Step: 13
Training loss: 2.9044290395806667
Validation loss: 2.4873180833448205

Epoch: 114| Step: 0
Training loss: 2.7643327010573473
Validation loss: 2.4957265743499852

Epoch: 6| Step: 1
Training loss: 3.0418926486022015
Validation loss: 2.5124326228045533

Epoch: 6| Step: 2
Training loss: 2.602759741611294
Validation loss: 2.5306061827691777

Epoch: 6| Step: 3
Training loss: 2.6376578911983595
Validation loss: 2.5193223135758838

Epoch: 6| Step: 4
Training loss: 3.2145441223904396
Validation loss: 2.5134711854386396

Epoch: 6| Step: 5
Training loss: 2.970894611113669
Validation loss: 2.5127414723854935

Epoch: 6| Step: 6
Training loss: 3.359034463345076
Validation loss: 2.496634375411587

Epoch: 6| Step: 7
Training loss: 2.5016266299336642
Validation loss: 2.4987475795912952

Epoch: 6| Step: 8
Training loss: 2.53749068685993
Validation loss: 2.4854233703806186

Epoch: 6| Step: 9
Training loss: 2.6350803286271693
Validation loss: 2.499740626098311

Epoch: 6| Step: 10
Training loss: 2.948806269013007
Validation loss: 2.4930089198064063

Epoch: 6| Step: 11
Training loss: 2.941428297145129
Validation loss: 2.5161462986471728

Epoch: 6| Step: 12
Training loss: 2.271576739308703
Validation loss: 2.527768142564937

Epoch: 6| Step: 13
Training loss: 3.446901123833248
Validation loss: 2.5668624652491667

Epoch: 115| Step: 0
Training loss: 2.3616758331932153
Validation loss: 2.5977399895359947

Epoch: 6| Step: 1
Training loss: 2.9095368206121823
Validation loss: 2.6234234628185353

Epoch: 6| Step: 2
Training loss: 2.777946739356325
Validation loss: 2.662196737925241

Epoch: 6| Step: 3
Training loss: 2.952774269227122
Validation loss: 2.6665043778283906

Epoch: 6| Step: 4
Training loss: 2.332854823592802
Validation loss: 2.6121631110515127

Epoch: 6| Step: 5
Training loss: 2.4254547243376883
Validation loss: 2.566837251811915

Epoch: 6| Step: 6
Training loss: 2.0730390911915766
Validation loss: 2.5272109817850406

Epoch: 6| Step: 7
Training loss: 2.3681261071378485
Validation loss: 2.498442246558652

Epoch: 6| Step: 8
Training loss: 3.392979942336695
Validation loss: 2.4953421557977604

Epoch: 6| Step: 9
Training loss: 3.5947924884864104
Validation loss: 2.496118446587522

Epoch: 6| Step: 10
Training loss: 2.950308773885725
Validation loss: 2.5004676473750584

Epoch: 6| Step: 11
Training loss: 3.0398898922906694
Validation loss: 2.5106043322733536

Epoch: 6| Step: 12
Training loss: 2.960250895666685
Validation loss: 2.5174570578533184

Epoch: 6| Step: 13
Training loss: 3.509667260899039
Validation loss: 2.5134262853685385

Epoch: 116| Step: 0
Training loss: 3.381409951197376
Validation loss: 2.515374309441065

Epoch: 6| Step: 1
Training loss: 2.7316193564389017
Validation loss: 2.5141788617133627

Epoch: 6| Step: 2
Training loss: 2.8795521398514468
Validation loss: 2.498354311695193

Epoch: 6| Step: 3
Training loss: 2.2794652776933173
Validation loss: 2.4970321369061446

Epoch: 6| Step: 4
Training loss: 3.2778194841508146
Validation loss: 2.493198029042966

Epoch: 6| Step: 5
Training loss: 3.289333160209677
Validation loss: 2.4974195955759315

Epoch: 6| Step: 6
Training loss: 2.969759317786311
Validation loss: 2.4912325191483924

Epoch: 6| Step: 7
Training loss: 2.733829988932419
Validation loss: 2.512678014695238

Epoch: 6| Step: 8
Training loss: 2.7574591477827326
Validation loss: 2.5377356559180932

Epoch: 6| Step: 9
Training loss: 2.975131915076939
Validation loss: 2.5769654789784155

Epoch: 6| Step: 10
Training loss: 2.830116540241348
Validation loss: 2.5794816808831853

Epoch: 6| Step: 11
Training loss: 2.7686902317459126
Validation loss: 2.5746838785879005

Epoch: 6| Step: 12
Training loss: 2.757461828138801
Validation loss: 2.537840255740546

Epoch: 6| Step: 13
Training loss: 2.3114191570861555
Validation loss: 2.4929922782554894

Epoch: 117| Step: 0
Training loss: 2.704956580781354
Validation loss: 2.496761689887843

Epoch: 6| Step: 1
Training loss: 2.584990451876274
Validation loss: 2.4820413296909707

Epoch: 6| Step: 2
Training loss: 3.0357676397170974
Validation loss: 2.4856164376370673

Epoch: 6| Step: 3
Training loss: 3.0555254867307253
Validation loss: 2.4863360860721766

Epoch: 6| Step: 4
Training loss: 2.740218365731923
Validation loss: 2.494030249352487

Epoch: 6| Step: 5
Training loss: 2.7795078092994787
Validation loss: 2.4901226067358238

Epoch: 6| Step: 6
Training loss: 3.2755440645894818
Validation loss: 2.4941922551681768

Epoch: 6| Step: 7
Training loss: 2.9446554488225396
Validation loss: 2.492097584316255

Epoch: 6| Step: 8
Training loss: 2.7333814287218665
Validation loss: 2.4864537215786258

Epoch: 6| Step: 9
Training loss: 3.258618591257807
Validation loss: 2.4841781933477884

Epoch: 6| Step: 10
Training loss: 2.6582428580964623
Validation loss: 2.4798411107445593

Epoch: 6| Step: 11
Training loss: 3.2653458033311007
Validation loss: 2.481815756906285

Epoch: 6| Step: 12
Training loss: 2.2033208665288284
Validation loss: 2.477769313285652

Epoch: 6| Step: 13
Training loss: 2.2773767275900787
Validation loss: 2.491461608366568

Epoch: 118| Step: 0
Training loss: 2.9094125911197626
Validation loss: 2.502343933015921

Epoch: 6| Step: 1
Training loss: 2.8646666543576025
Validation loss: 2.5276611370253756

Epoch: 6| Step: 2
Training loss: 3.098831473353164
Validation loss: 2.5497621113633855

Epoch: 6| Step: 3
Training loss: 3.0611156526667633
Validation loss: 2.563649630734555

Epoch: 6| Step: 4
Training loss: 2.712308245794094
Validation loss: 2.6278852221821856

Epoch: 6| Step: 5
Training loss: 2.719442695856966
Validation loss: 2.693111583149589

Epoch: 6| Step: 6
Training loss: 3.062007163738938
Validation loss: 2.639678874899601

Epoch: 6| Step: 7
Training loss: 2.631065445541624
Validation loss: 2.5562586154627582

Epoch: 6| Step: 8
Training loss: 2.403191939315789
Validation loss: 2.506238850826104

Epoch: 6| Step: 9
Training loss: 3.0272193144789
Validation loss: 2.494579542429116

Epoch: 6| Step: 10
Training loss: 2.5703678762853572
Validation loss: 2.483731234476423

Epoch: 6| Step: 11
Training loss: 2.53046499253807
Validation loss: 2.483839450310473

Epoch: 6| Step: 12
Training loss: 3.324654932688166
Validation loss: 2.485857925940497

Epoch: 6| Step: 13
Training loss: 3.231654252934595
Validation loss: 2.4915226049944383

Epoch: 119| Step: 0
Training loss: 2.8607922986453893
Validation loss: 2.4964176363071426

Epoch: 6| Step: 1
Training loss: 2.724967774366862
Validation loss: 2.4936502747651503

Epoch: 6| Step: 2
Training loss: 3.392256383842215
Validation loss: 2.4897565959444123

Epoch: 6| Step: 3
Training loss: 2.9075683556850316
Validation loss: 2.491188303941586

Epoch: 6| Step: 4
Training loss: 2.434412835234804
Validation loss: 2.4852076919083608

Epoch: 6| Step: 5
Training loss: 2.9193375120734864
Validation loss: 2.488318778904572

Epoch: 6| Step: 6
Training loss: 3.065221861484031
Validation loss: 2.4783836462843944

Epoch: 6| Step: 7
Training loss: 3.065358754455678
Validation loss: 2.480135150361758

Epoch: 6| Step: 8
Training loss: 2.8187950891918865
Validation loss: 2.4722827097285003

Epoch: 6| Step: 9
Training loss: 3.469084440037719
Validation loss: 2.468816711388412

Epoch: 6| Step: 10
Training loss: 2.0011555194651756
Validation loss: 2.4880135364601452

Epoch: 6| Step: 11
Training loss: 2.8704514388345816
Validation loss: 2.514169055497724

Epoch: 6| Step: 12
Training loss: 2.351218974726569
Validation loss: 2.566749885261017

Epoch: 6| Step: 13
Training loss: 2.8510266780401206
Validation loss: 2.656689573105245

Epoch: 120| Step: 0
Training loss: 2.8470299219047037
Validation loss: 2.6110492296929073

Epoch: 6| Step: 1
Training loss: 2.8085356853568464
Validation loss: 2.5350783482569823

Epoch: 6| Step: 2
Training loss: 2.9691775365461517
Validation loss: 2.5120718317145454

Epoch: 6| Step: 3
Training loss: 3.109657926483035
Validation loss: 2.4915807942621466

Epoch: 6| Step: 4
Training loss: 3.0951870749883286
Validation loss: 2.4893872168398854

Epoch: 6| Step: 5
Training loss: 2.4628660365668913
Validation loss: 2.483362901988803

Epoch: 6| Step: 6
Training loss: 2.4166051812955307
Validation loss: 2.4812826118362548

Epoch: 6| Step: 7
Training loss: 2.7560166517510383
Validation loss: 2.48195956692207

Epoch: 6| Step: 8
Training loss: 2.92385258788614
Validation loss: 2.4880086688619465

Epoch: 6| Step: 9
Training loss: 3.494039091593565
Validation loss: 2.4904429446146388

Epoch: 6| Step: 10
Training loss: 2.325759197690528
Validation loss: 2.4725464435853364

Epoch: 6| Step: 11
Training loss: 3.0508037571192816
Validation loss: 2.47062022121836

Epoch: 6| Step: 12
Training loss: 2.5578761368410508
Validation loss: 2.474112051488106

Epoch: 6| Step: 13
Training loss: 2.996178736469843
Validation loss: 2.46359727776741

Epoch: 121| Step: 0
Training loss: 3.26883025499366
Validation loss: 2.463710371641393

Epoch: 6| Step: 1
Training loss: 2.9000484791353833
Validation loss: 2.461890918010326

Epoch: 6| Step: 2
Training loss: 1.65913334468001
Validation loss: 2.460515915034862

Epoch: 6| Step: 3
Training loss: 2.9595064514677607
Validation loss: 2.4589899745875026

Epoch: 6| Step: 4
Training loss: 3.1962375933928895
Validation loss: 2.4657620694707743

Epoch: 6| Step: 5
Training loss: 3.0961708846628104
Validation loss: 2.467824239743698

Epoch: 6| Step: 6
Training loss: 2.870674694386107
Validation loss: 2.500241450473598

Epoch: 6| Step: 7
Training loss: 2.6426667214800035
Validation loss: 2.537618753986484

Epoch: 6| Step: 8
Training loss: 2.7062258712714855
Validation loss: 2.5663388558179205

Epoch: 6| Step: 9
Training loss: 3.060130701452659
Validation loss: 2.597052510613426

Epoch: 6| Step: 10
Training loss: 2.969959855755597
Validation loss: 2.615975820062915

Epoch: 6| Step: 11
Training loss: 3.0990588943877446
Validation loss: 2.634499612384685

Epoch: 6| Step: 12
Training loss: 2.719848936878833
Validation loss: 2.5737107766773266

Epoch: 6| Step: 13
Training loss: 2.2691929576563443
Validation loss: 2.5327236783081015

Epoch: 122| Step: 0
Training loss: 2.6725127591148814
Validation loss: 2.485425723163485

Epoch: 6| Step: 1
Training loss: 3.157074773309555
Validation loss: 2.4642089725306113

Epoch: 6| Step: 2
Training loss: 3.681848106305483
Validation loss: 2.459436277312635

Epoch: 6| Step: 3
Training loss: 2.4987530459547154
Validation loss: 2.465627844304682

Epoch: 6| Step: 4
Training loss: 2.662302907176749
Validation loss: 2.4697372043206656

Epoch: 6| Step: 5
Training loss: 2.644543871715633
Validation loss: 2.469323169221205

Epoch: 6| Step: 6
Training loss: 2.85576063509035
Validation loss: 2.468272106707511

Epoch: 6| Step: 7
Training loss: 2.696585622669108
Validation loss: 2.471085624913207

Epoch: 6| Step: 8
Training loss: 2.6734752659050365
Validation loss: 2.466446578304543

Epoch: 6| Step: 9
Training loss: 2.3878441887060706
Validation loss: 2.4650154273049942

Epoch: 6| Step: 10
Training loss: 2.3429159078970483
Validation loss: 2.454645627544688

Epoch: 6| Step: 11
Training loss: 3.3801363255021966
Validation loss: 2.4578012342817845

Epoch: 6| Step: 12
Training loss: 2.905300190265481
Validation loss: 2.4641744430609998

Epoch: 6| Step: 13
Training loss: 2.94949602251032
Validation loss: 2.4813925203366267

Epoch: 123| Step: 0
Training loss: 2.6687466337732175
Validation loss: 2.506065592593186

Epoch: 6| Step: 1
Training loss: 2.786894995204239
Validation loss: 2.5599619644137657

Epoch: 6| Step: 2
Training loss: 3.042903718265705
Validation loss: 2.634733616826747

Epoch: 6| Step: 3
Training loss: 3.2797606948456015
Validation loss: 2.6731189076729116

Epoch: 6| Step: 4
Training loss: 2.788462854885934
Validation loss: 2.6274179474565935

Epoch: 6| Step: 5
Training loss: 2.9781108843858157
Validation loss: 2.564573376068799

Epoch: 6| Step: 6
Training loss: 3.0127537157527873
Validation loss: 2.5263511523099904

Epoch: 6| Step: 7
Training loss: 2.789700133366747
Validation loss: 2.502049035037754

Epoch: 6| Step: 8
Training loss: 2.376657911162369
Validation loss: 2.484930257983308

Epoch: 6| Step: 9
Training loss: 2.2410801934563156
Validation loss: 2.473466526924304

Epoch: 6| Step: 10
Training loss: 2.895850330183979
Validation loss: 2.4718422216478126

Epoch: 6| Step: 11
Training loss: 2.815572459146644
Validation loss: 2.46528798429125

Epoch: 6| Step: 12
Training loss: 2.564412775470362
Validation loss: 2.465777003605349

Epoch: 6| Step: 13
Training loss: 3.2526545320902054
Validation loss: 2.460237661957241

Epoch: 124| Step: 0
Training loss: 2.806750715481769
Validation loss: 2.466990242326844

Epoch: 6| Step: 1
Training loss: 3.2001206613680138
Validation loss: 2.4671374187176593

Epoch: 6| Step: 2
Training loss: 3.056952609876902
Validation loss: 2.4617944098284594

Epoch: 6| Step: 3
Training loss: 2.662738012143417
Validation loss: 2.465047288844707

Epoch: 6| Step: 4
Training loss: 2.699482575039727
Validation loss: 2.457208374636049

Epoch: 6| Step: 5
Training loss: 2.7878600875851784
Validation loss: 2.457400325493448

Epoch: 6| Step: 6
Training loss: 2.6087276546616147
Validation loss: 2.4629684159726204

Epoch: 6| Step: 7
Training loss: 2.9131206391454736
Validation loss: 2.4682758966938225

Epoch: 6| Step: 8
Training loss: 2.9994417306893597
Validation loss: 2.4674690155851073

Epoch: 6| Step: 9
Training loss: 2.9033280317022343
Validation loss: 2.492403806720108

Epoch: 6| Step: 10
Training loss: 2.5766757475218784
Validation loss: 2.5377270388299826

Epoch: 6| Step: 11
Training loss: 2.8845467661985857
Validation loss: 2.6263890222007293

Epoch: 6| Step: 12
Training loss: 2.3869692706849697
Validation loss: 2.6539560931804322

Epoch: 6| Step: 13
Training loss: 3.133246717540921
Validation loss: 2.6458320285004864

Epoch: 125| Step: 0
Training loss: 3.0666404294536345
Validation loss: 2.5780803826959415

Epoch: 6| Step: 1
Training loss: 3.6745343905957526
Validation loss: 2.5002093299268413

Epoch: 6| Step: 2
Training loss: 2.434395892111139
Validation loss: 2.480822106551959

Epoch: 6| Step: 3
Training loss: 3.3112939042391667
Validation loss: 2.4694094137444447

Epoch: 6| Step: 4
Training loss: 2.7688065671631823
Validation loss: 2.4639434961962046

Epoch: 6| Step: 5
Training loss: 2.872444343791314
Validation loss: 2.4702374053548026

Epoch: 6| Step: 6
Training loss: 2.590400831511507
Validation loss: 2.4682841019059647

Epoch: 6| Step: 7
Training loss: 2.9124748261636717
Validation loss: 2.463020836969377

Epoch: 6| Step: 8
Training loss: 2.5848380802878452
Validation loss: 2.4708637261065243

Epoch: 6| Step: 9
Training loss: 2.315940565674204
Validation loss: 2.4642956576775923

Epoch: 6| Step: 10
Training loss: 2.904714199064526
Validation loss: 2.474081690011501

Epoch: 6| Step: 11
Training loss: 2.207235519273538
Validation loss: 2.482813868795926

Epoch: 6| Step: 12
Training loss: 2.798971573107778
Validation loss: 2.5108966520861675

Epoch: 6| Step: 13
Training loss: 2.3463815792626166
Validation loss: 2.528537452936486

Epoch: 126| Step: 0
Training loss: 2.835992481549927
Validation loss: 2.5550667604574566

Epoch: 6| Step: 1
Training loss: 2.8771056052599735
Validation loss: 2.537194157011878

Epoch: 6| Step: 2
Training loss: 2.8986997254401157
Validation loss: 2.512989110085989

Epoch: 6| Step: 3
Training loss: 3.1074362993654847
Validation loss: 2.5073093638847905

Epoch: 6| Step: 4
Training loss: 2.7602012598215477
Validation loss: 2.4752793589558935

Epoch: 6| Step: 5
Training loss: 3.0869653462799516
Validation loss: 2.4913364155185245

Epoch: 6| Step: 6
Training loss: 2.922883374837318
Validation loss: 2.4749211287690107

Epoch: 6| Step: 7
Training loss: 2.469872907388132
Validation loss: 2.459525224195542

Epoch: 6| Step: 8
Training loss: 2.481694436807127
Validation loss: 2.46611916327013

Epoch: 6| Step: 9
Training loss: 3.077259542335283
Validation loss: 2.4620413751707284

Epoch: 6| Step: 10
Training loss: 2.7538205397233932
Validation loss: 2.4676727981206743

Epoch: 6| Step: 11
Training loss: 2.9062504922189603
Validation loss: 2.4736216049867035

Epoch: 6| Step: 12
Training loss: 2.7923737005429423
Validation loss: 2.4856725157568227

Epoch: 6| Step: 13
Training loss: 2.417544621999588
Validation loss: 2.4812608971509773

Epoch: 127| Step: 0
Training loss: 2.8239851521271877
Validation loss: 2.512538499475455

Epoch: 6| Step: 1
Training loss: 2.4704970926014065
Validation loss: 2.5255818063336113

Epoch: 6| Step: 2
Training loss: 3.1219621770255053
Validation loss: 2.530347245083982

Epoch: 6| Step: 3
Training loss: 3.068276077004284
Validation loss: 2.5481465623865414

Epoch: 6| Step: 4
Training loss: 2.3467822995017844
Validation loss: 2.538779054885656

Epoch: 6| Step: 5
Training loss: 2.9156875783535914
Validation loss: 2.536101197072019

Epoch: 6| Step: 6
Training loss: 2.774774879053263
Validation loss: 2.5267023262650268

Epoch: 6| Step: 7
Training loss: 2.3958909622116815
Validation loss: 2.5304374449007137

Epoch: 6| Step: 8
Training loss: 2.8824409721001403
Validation loss: 2.528047947548715

Epoch: 6| Step: 9
Training loss: 2.833125293798156
Validation loss: 2.519508674980232

Epoch: 6| Step: 10
Training loss: 2.7389588218342857
Validation loss: 2.500770126184612

Epoch: 6| Step: 11
Training loss: 2.541838926721072
Validation loss: 2.488681903072151

Epoch: 6| Step: 12
Training loss: 3.3499316535923884
Validation loss: 2.4801609578596775

Epoch: 6| Step: 13
Training loss: 3.0722719884807748
Validation loss: 2.472579969652426

Epoch: 128| Step: 0
Training loss: 2.4700648995031624
Validation loss: 2.464899599712685

Epoch: 6| Step: 1
Training loss: 2.515415064421691
Validation loss: 2.4674162329711233

Epoch: 6| Step: 2
Training loss: 3.1673557803253103
Validation loss: 2.484110850096135

Epoch: 6| Step: 3
Training loss: 1.8739110963673338
Validation loss: 2.474533210804294

Epoch: 6| Step: 4
Training loss: 2.820697282659093
Validation loss: 2.4850764203790963

Epoch: 6| Step: 5
Training loss: 2.5666150802118155
Validation loss: 2.4919151249634104

Epoch: 6| Step: 6
Training loss: 2.860274710099771
Validation loss: 2.4938178148284944

Epoch: 6| Step: 7
Training loss: 2.9772371743996064
Validation loss: 2.5044341920090676

Epoch: 6| Step: 8
Training loss: 2.849888140173053
Validation loss: 2.4832831689932755

Epoch: 6| Step: 9
Training loss: 3.140730974677368
Validation loss: 2.491573671029567

Epoch: 6| Step: 10
Training loss: 2.887320944778945
Validation loss: 2.489047314353738

Epoch: 6| Step: 11
Training loss: 2.658643833151627
Validation loss: 2.486047571922075

Epoch: 6| Step: 12
Training loss: 3.5874897707484283
Validation loss: 2.4731023929276517

Epoch: 6| Step: 13
Training loss: 1.9900054350735614
Validation loss: 2.465148008371338

Epoch: 129| Step: 0
Training loss: 2.8201402099058535
Validation loss: 2.4653026176501864

Epoch: 6| Step: 1
Training loss: 2.036838648829594
Validation loss: 2.467904025505162

Epoch: 6| Step: 2
Training loss: 3.271486415577722
Validation loss: 2.4830932427073664

Epoch: 6| Step: 3
Training loss: 2.284326334172697
Validation loss: 2.469938099527114

Epoch: 6| Step: 4
Training loss: 2.0044296800549417
Validation loss: 2.4738826375282104

Epoch: 6| Step: 5
Training loss: 3.010241194278208
Validation loss: 2.4757123348184886

Epoch: 6| Step: 6
Training loss: 2.4076090356016167
Validation loss: 2.461682791100727

Epoch: 6| Step: 7
Training loss: 3.034475910618508
Validation loss: 2.4623587618273355

Epoch: 6| Step: 8
Training loss: 2.9156601031808
Validation loss: 2.4660092840862675

Epoch: 6| Step: 9
Training loss: 2.7568041116875324
Validation loss: 2.460931726707071

Epoch: 6| Step: 10
Training loss: 3.2438839805731257
Validation loss: 2.4538734411981156

Epoch: 6| Step: 11
Training loss: 2.846321703745193
Validation loss: 2.4640339533798143

Epoch: 6| Step: 12
Training loss: 3.209714633461872
Validation loss: 2.465198694170318

Epoch: 6| Step: 13
Training loss: 2.9477684244326303
Validation loss: 2.4675815735798636

Epoch: 130| Step: 0
Training loss: 2.1819448506547614
Validation loss: 2.503566038286068

Epoch: 6| Step: 1
Training loss: 2.6823457484055364
Validation loss: 2.504704201572718

Epoch: 6| Step: 2
Training loss: 2.669164431552465
Validation loss: 2.526816512985551

Epoch: 6| Step: 3
Training loss: 2.2736801594750156
Validation loss: 2.5359255562661644

Epoch: 6| Step: 4
Training loss: 3.2063802413811335
Validation loss: 2.544793244560859

Epoch: 6| Step: 5
Training loss: 2.3138109563694234
Validation loss: 2.5220952961366043

Epoch: 6| Step: 6
Training loss: 2.854413840921484
Validation loss: 2.524497134244815

Epoch: 6| Step: 7
Training loss: 3.2076043791225732
Validation loss: 2.535307979361524

Epoch: 6| Step: 8
Training loss: 2.9788985409600617
Validation loss: 2.5190493349906435

Epoch: 6| Step: 9
Training loss: 2.548865727991299
Validation loss: 2.483797326738919

Epoch: 6| Step: 10
Training loss: 3.2832045773531884
Validation loss: 2.4628748297027285

Epoch: 6| Step: 11
Training loss: 3.0594114961872863
Validation loss: 2.4573252741793605

Epoch: 6| Step: 12
Training loss: 2.827781276996332
Validation loss: 2.4577400359919297

Epoch: 6| Step: 13
Training loss: 2.7331131121457375
Validation loss: 2.448198743568302

Epoch: 131| Step: 0
Training loss: 3.1639184236101547
Validation loss: 2.4537330575595173

Epoch: 6| Step: 1
Training loss: 2.7287742585009522
Validation loss: 2.4531257607969805

Epoch: 6| Step: 2
Training loss: 2.4214895618504397
Validation loss: 2.4540285330626963

Epoch: 6| Step: 3
Training loss: 2.7036248775741236
Validation loss: 2.4477489716832537

Epoch: 6| Step: 4
Training loss: 2.834039899201942
Validation loss: 2.452048463711399

Epoch: 6| Step: 5
Training loss: 3.2806419172412213
Validation loss: 2.4453942101343316

Epoch: 6| Step: 6
Training loss: 2.7366755807462693
Validation loss: 2.4549081264328985

Epoch: 6| Step: 7
Training loss: 2.9632361354556633
Validation loss: 2.465126534266793

Epoch: 6| Step: 8
Training loss: 3.1273355530119904
Validation loss: 2.478979956970093

Epoch: 6| Step: 9
Training loss: 2.779137312597294
Validation loss: 2.5116359093751397

Epoch: 6| Step: 10
Training loss: 2.818912993664549
Validation loss: 2.567950713626799

Epoch: 6| Step: 11
Training loss: 2.5196497216574834
Validation loss: 2.5905966282384476

Epoch: 6| Step: 12
Training loss: 2.941888817746008
Validation loss: 2.602263386542257

Epoch: 6| Step: 13
Training loss: 2.1063702693299993
Validation loss: 2.5501580150577454

Epoch: 132| Step: 0
Training loss: 2.818174783077017
Validation loss: 2.4853112542397913

Epoch: 6| Step: 1
Training loss: 2.696102391474805
Validation loss: 2.4717604222849414

Epoch: 6| Step: 2
Training loss: 2.4968010462955825
Validation loss: 2.454170202423356

Epoch: 6| Step: 3
Training loss: 2.652421593401597
Validation loss: 2.456223004582687

Epoch: 6| Step: 4
Training loss: 2.951006093850432
Validation loss: 2.4647473798001163

Epoch: 6| Step: 5
Training loss: 2.4392277389750734
Validation loss: 2.46726844977592

Epoch: 6| Step: 6
Training loss: 2.976836104346135
Validation loss: 2.4639741698781514

Epoch: 6| Step: 7
Training loss: 3.1841409973478263
Validation loss: 2.4697415058785492

Epoch: 6| Step: 8
Training loss: 3.1531262945015617
Validation loss: 2.4682829568131233

Epoch: 6| Step: 9
Training loss: 3.1187208032865876
Validation loss: 2.4643403288649184

Epoch: 6| Step: 10
Training loss: 2.776308277107593
Validation loss: 2.4625160624861646

Epoch: 6| Step: 11
Training loss: 3.0789446828592784
Validation loss: 2.461536567512636

Epoch: 6| Step: 12
Training loss: 2.5036201015986155
Validation loss: 2.4610797424929656

Epoch: 6| Step: 13
Training loss: 2.601817075628442
Validation loss: 2.4698797620968143

Epoch: 133| Step: 0
Training loss: 2.2888829287767227
Validation loss: 2.460453842354724

Epoch: 6| Step: 1
Training loss: 2.496032714097508
Validation loss: 2.4820349372138852

Epoch: 6| Step: 2
Training loss: 2.6774211230088705
Validation loss: 2.5117469510050334

Epoch: 6| Step: 3
Training loss: 3.165933992720734
Validation loss: 2.577391934950054

Epoch: 6| Step: 4
Training loss: 3.123048249149557
Validation loss: 2.611235362834581

Epoch: 6| Step: 5
Training loss: 3.6438267590140767
Validation loss: 2.6145103685288835

Epoch: 6| Step: 6
Training loss: 2.8254874560000567
Validation loss: 2.5985943146833486

Epoch: 6| Step: 7
Training loss: 3.112645255380035
Validation loss: 2.5721593523359467

Epoch: 6| Step: 8
Training loss: 2.978855001157311
Validation loss: 2.5246301436776286

Epoch: 6| Step: 9
Training loss: 2.5452533075745603
Validation loss: 2.497058857008466

Epoch: 6| Step: 10
Training loss: 2.2147337332822605
Validation loss: 2.4884997042549206

Epoch: 6| Step: 11
Training loss: 2.6280331118165536
Validation loss: 2.455105527257154

Epoch: 6| Step: 12
Training loss: 2.633915429625158
Validation loss: 2.460793134443096

Epoch: 6| Step: 13
Training loss: 2.354147368045351
Validation loss: 2.464763856854809

Epoch: 134| Step: 0
Training loss: 2.4531605711866686
Validation loss: 2.4592073040039892

Epoch: 6| Step: 1
Training loss: 2.965193857220954
Validation loss: 2.4601458918188444

Epoch: 6| Step: 2
Training loss: 3.0054695813599546
Validation loss: 2.4503509520835998

Epoch: 6| Step: 3
Training loss: 2.98376842146302
Validation loss: 2.4602805213062164

Epoch: 6| Step: 4
Training loss: 2.3522149381713495
Validation loss: 2.4625022199191915

Epoch: 6| Step: 5
Training loss: 2.8710700001675016
Validation loss: 2.4562597875403482

Epoch: 6| Step: 6
Training loss: 3.0073400349300976
Validation loss: 2.4601653596662647

Epoch: 6| Step: 7
Training loss: 3.2568454542121077
Validation loss: 2.470949245588638

Epoch: 6| Step: 8
Training loss: 2.798141363290772
Validation loss: 2.4770578225688156

Epoch: 6| Step: 9
Training loss: 2.781415184344807
Validation loss: 2.4820280117535765

Epoch: 6| Step: 10
Training loss: 2.4890108820369665
Validation loss: 2.5053571543811786

Epoch: 6| Step: 11
Training loss: 2.757098399960845
Validation loss: 2.5113620804958745

Epoch: 6| Step: 12
Training loss: 2.4971808751065763
Validation loss: 2.530788020436523

Epoch: 6| Step: 13
Training loss: 2.2870313987828315
Validation loss: 2.5513465964776394

Epoch: 135| Step: 0
Training loss: 2.4986577245286967
Validation loss: 2.5607446380293934

Epoch: 6| Step: 1
Training loss: 2.6420588465973003
Validation loss: 2.537764143621285

Epoch: 6| Step: 2
Training loss: 2.9090242987831236
Validation loss: 2.51918115850547

Epoch: 6| Step: 3
Training loss: 2.81186567146838
Validation loss: 2.49668234782491

Epoch: 6| Step: 4
Training loss: 3.1227755449578845
Validation loss: 2.497110925787769

Epoch: 6| Step: 5
Training loss: 2.739937057189829
Validation loss: 2.4828199484693845

Epoch: 6| Step: 6
Training loss: 2.894205051837219
Validation loss: 2.474376697927452

Epoch: 6| Step: 7
Training loss: 2.3942565262534172
Validation loss: 2.469174404796303

Epoch: 6| Step: 8
Training loss: 2.1228656147467095
Validation loss: 2.4683053480854866

Epoch: 6| Step: 9
Training loss: 3.0737631628647444
Validation loss: 2.4517610330915596

Epoch: 6| Step: 10
Training loss: 2.8329027821145925
Validation loss: 2.453930091148564

Epoch: 6| Step: 11
Training loss: 2.5789046524722408
Validation loss: 2.4516736835920754

Epoch: 6| Step: 12
Training loss: 3.0482440709191176
Validation loss: 2.4450382289971664

Epoch: 6| Step: 13
Training loss: 3.1092582949105747
Validation loss: 2.4467179537763037

Epoch: 136| Step: 0
Training loss: 2.769726142428658
Validation loss: 2.4484566355907167

Epoch: 6| Step: 1
Training loss: 2.7185826743364174
Validation loss: 2.459927864746189

Epoch: 6| Step: 2
Training loss: 2.868266804211917
Validation loss: 2.4712940875556875

Epoch: 6| Step: 3
Training loss: 2.2689475065491456
Validation loss: 2.5309031745302275

Epoch: 6| Step: 4
Training loss: 2.9708238284978634
Validation loss: 2.602877618198835

Epoch: 6| Step: 5
Training loss: 2.5955153742529435
Validation loss: 2.7391068494809168

Epoch: 6| Step: 6
Training loss: 3.3412453370752133
Validation loss: 2.7602635575451324

Epoch: 6| Step: 7
Training loss: 3.210857752345678
Validation loss: 2.6274869284448052

Epoch: 6| Step: 8
Training loss: 3.184142644639007
Validation loss: 2.5423613684351674

Epoch: 6| Step: 9
Training loss: 3.3457872120745282
Validation loss: 2.5001952536023935

Epoch: 6| Step: 10
Training loss: 2.3172507073597535
Validation loss: 2.4739294905133495

Epoch: 6| Step: 11
Training loss: 2.5594735300104148
Validation loss: 2.449504033043929

Epoch: 6| Step: 12
Training loss: 2.529893488093163
Validation loss: 2.4548862713950403

Epoch: 6| Step: 13
Training loss: 2.322910382956543
Validation loss: 2.448668078992221

Epoch: 137| Step: 0
Training loss: 2.1804466976306704
Validation loss: 2.4506466261471114

Epoch: 6| Step: 1
Training loss: 2.159832176470565
Validation loss: 2.4618834339609235

Epoch: 6| Step: 2
Training loss: 2.8787132829982305
Validation loss: 2.472158534615476

Epoch: 6| Step: 3
Training loss: 3.0663644192509065
Validation loss: 2.4814942490337284

Epoch: 6| Step: 4
Training loss: 2.7903969187723874
Validation loss: 2.464289892772251

Epoch: 6| Step: 5
Training loss: 3.004533838557345
Validation loss: 2.448103475849929

Epoch: 6| Step: 6
Training loss: 2.8941333821633792
Validation loss: 2.4586561184710614

Epoch: 6| Step: 7
Training loss: 2.383086942283307
Validation loss: 2.451053973881942

Epoch: 6| Step: 8
Training loss: 2.5415760920494286
Validation loss: 2.4451210397564505

Epoch: 6| Step: 9
Training loss: 3.0788131951472457
Validation loss: 2.4767096737668064

Epoch: 6| Step: 10
Training loss: 3.093355404128339
Validation loss: 2.4877383528052577

Epoch: 6| Step: 11
Training loss: 2.7637661651594065
Validation loss: 2.556361597933034

Epoch: 6| Step: 12
Training loss: 3.283122808868531
Validation loss: 2.623443182880629

Epoch: 6| Step: 13
Training loss: 2.8996816263058167
Validation loss: 2.63632049652067

Epoch: 138| Step: 0
Training loss: 2.6712254855754125
Validation loss: 2.601331256173824

Epoch: 6| Step: 1
Training loss: 2.7895786010914767
Validation loss: 2.586436661029522

Epoch: 6| Step: 2
Training loss: 3.019283940895104
Validation loss: 2.571050873054942

Epoch: 6| Step: 3
Training loss: 2.623021061046658
Validation loss: 2.5165987376668686

Epoch: 6| Step: 4
Training loss: 2.860315720531243
Validation loss: 2.489070628614304

Epoch: 6| Step: 5
Training loss: 2.796590353690322
Validation loss: 2.472745466778171

Epoch: 6| Step: 6
Training loss: 2.8830114776668663
Validation loss: 2.4481295372421563

Epoch: 6| Step: 7
Training loss: 2.8332062487057095
Validation loss: 2.462476235160466

Epoch: 6| Step: 8
Training loss: 3.179770728669263
Validation loss: 2.4574961768974872

Epoch: 6| Step: 9
Training loss: 2.8317194063223456
Validation loss: 2.4563038935903245

Epoch: 6| Step: 10
Training loss: 2.744608188314106
Validation loss: 2.4477037929397256

Epoch: 6| Step: 11
Training loss: 2.6615866513806417
Validation loss: 2.4469282194640556

Epoch: 6| Step: 12
Training loss: 2.1683763825318754
Validation loss: 2.4550781511054893

Epoch: 6| Step: 13
Training loss: 2.914676059632146
Validation loss: 2.4540841744871313

Epoch: 139| Step: 0
Training loss: 2.8271805677416446
Validation loss: 2.4720763236441745

Epoch: 6| Step: 1
Training loss: 2.2788630500075464
Validation loss: 2.4752833847087894

Epoch: 6| Step: 2
Training loss: 2.7814624148059286
Validation loss: 2.4778342412818763

Epoch: 6| Step: 3
Training loss: 2.9237292928561756
Validation loss: 2.479382587673554

Epoch: 6| Step: 4
Training loss: 2.7108656464214524
Validation loss: 2.4787031963967845

Epoch: 6| Step: 5
Training loss: 2.9638247139666727
Validation loss: 2.471082977326114

Epoch: 6| Step: 6
Training loss: 3.3834643715974946
Validation loss: 2.4865717680415584

Epoch: 6| Step: 7
Training loss: 2.745552975625816
Validation loss: 2.4543351025467697

Epoch: 6| Step: 8
Training loss: 2.686096623419012
Validation loss: 2.448008410205807

Epoch: 6| Step: 9
Training loss: 3.06424756694858
Validation loss: 2.4627981220017734

Epoch: 6| Step: 10
Training loss: 2.6162029179375033
Validation loss: 2.4463569931499527

Epoch: 6| Step: 11
Training loss: 2.976853724373013
Validation loss: 2.4795344633043084

Epoch: 6| Step: 12
Training loss: 2.373984973239663
Validation loss: 2.51025120142167

Epoch: 6| Step: 13
Training loss: 2.059059047050551
Validation loss: 2.5173553994783116

Epoch: 140| Step: 0
Training loss: 3.264126228378743
Validation loss: 2.5268919940845236

Epoch: 6| Step: 1
Training loss: 2.4461190840397005
Validation loss: 2.527500342303969

Epoch: 6| Step: 2
Training loss: 2.0613071575764677
Validation loss: 2.565751810467084

Epoch: 6| Step: 3
Training loss: 3.113817271727579
Validation loss: 2.55291155764897

Epoch: 6| Step: 4
Training loss: 2.6649571144418
Validation loss: 2.575487175420259

Epoch: 6| Step: 5
Training loss: 3.0026616369186114
Validation loss: 2.6424282659549845

Epoch: 6| Step: 6
Training loss: 2.670918254325479
Validation loss: 2.6980849322183067

Epoch: 6| Step: 7
Training loss: 2.782066482539381
Validation loss: 2.7296151947476104

Epoch: 6| Step: 8
Training loss: 2.077187577682776
Validation loss: 2.6684880147776933

Epoch: 6| Step: 9
Training loss: 3.087078878123437
Validation loss: 2.6017084883555097

Epoch: 6| Step: 10
Training loss: 2.937136039100439
Validation loss: 2.5169401935213265

Epoch: 6| Step: 11
Training loss: 3.1887046183276895
Validation loss: 2.448875485227841

Epoch: 6| Step: 12
Training loss: 2.9128739538504766
Validation loss: 2.4257868702203336

Epoch: 6| Step: 13
Training loss: 2.614624681690421
Validation loss: 2.4450930296699367

Epoch: 141| Step: 0
Training loss: 2.718871102979227
Validation loss: 2.4519698275693522

Epoch: 6| Step: 1
Training loss: 2.9165082797687156
Validation loss: 2.46494473057307

Epoch: 6| Step: 2
Training loss: 2.927218034751363
Validation loss: 2.461400723552692

Epoch: 6| Step: 3
Training loss: 2.6863580096059283
Validation loss: 2.457231441163643

Epoch: 6| Step: 4
Training loss: 3.2174540753410468
Validation loss: 2.4514768132236315

Epoch: 6| Step: 5
Training loss: 2.8351506594500027
Validation loss: 2.44617235344439

Epoch: 6| Step: 6
Training loss: 2.8744423366886735
Validation loss: 2.435706496615365

Epoch: 6| Step: 7
Training loss: 2.1030860115053667
Validation loss: 2.432517654605625

Epoch: 6| Step: 8
Training loss: 2.886419422700075
Validation loss: 2.431290837848671

Epoch: 6| Step: 9
Training loss: 2.444811492393105
Validation loss: 2.433491541171982

Epoch: 6| Step: 10
Training loss: 2.032766744229178
Validation loss: 2.47039943561632

Epoch: 6| Step: 11
Training loss: 2.9110176603671998
Validation loss: 2.473791753906555

Epoch: 6| Step: 12
Training loss: 3.006208353685999
Validation loss: 2.512095026176836

Epoch: 6| Step: 13
Training loss: 3.8127946583430705
Validation loss: 2.5388845861306373

Epoch: 142| Step: 0
Training loss: 2.002086385618087
Validation loss: 2.580495295255603

Epoch: 6| Step: 1
Training loss: 3.043101629800897
Validation loss: 2.5733122869993563

Epoch: 6| Step: 2
Training loss: 2.248019300303299
Validation loss: 2.518823737072753

Epoch: 6| Step: 3
Training loss: 3.0778461465537013
Validation loss: 2.501714817662141

Epoch: 6| Step: 4
Training loss: 2.476417031814352
Validation loss: 2.454455729876871

Epoch: 6| Step: 5
Training loss: 2.32922716101995
Validation loss: 2.4473075173365424

Epoch: 6| Step: 6
Training loss: 2.713054435074199
Validation loss: 2.4398674092224923

Epoch: 6| Step: 7
Training loss: 3.4095911560627714
Validation loss: 2.4361685794307313

Epoch: 6| Step: 8
Training loss: 2.6520105975760657
Validation loss: 2.44214359350238

Epoch: 6| Step: 9
Training loss: 2.853823416087611
Validation loss: 2.4460674369300346

Epoch: 6| Step: 10
Training loss: 3.193848962612961
Validation loss: 2.4374705339937774

Epoch: 6| Step: 11
Training loss: 2.7251191349409996
Validation loss: 2.441428455145155

Epoch: 6| Step: 12
Training loss: 2.4816697464670403
Validation loss: 2.4439281660206147

Epoch: 6| Step: 13
Training loss: 3.259129393002001
Validation loss: 2.475146571725236

Epoch: 143| Step: 0
Training loss: 2.6889979601334866
Validation loss: 2.4846556160568922

Epoch: 6| Step: 1
Training loss: 2.3168839835277555
Validation loss: 2.488088672874518

Epoch: 6| Step: 2
Training loss: 2.742903135118442
Validation loss: 2.5043657146318483

Epoch: 6| Step: 3
Training loss: 3.240041735109513
Validation loss: 2.4804937230769024

Epoch: 6| Step: 4
Training loss: 2.57892517619106
Validation loss: 2.4783486719311463

Epoch: 6| Step: 5
Training loss: 2.7296118530901556
Validation loss: 2.4939851935592077

Epoch: 6| Step: 6
Training loss: 2.5039853754500103
Validation loss: 2.469076963377443

Epoch: 6| Step: 7
Training loss: 2.8715594063282524
Validation loss: 2.45394655830469

Epoch: 6| Step: 8
Training loss: 3.24973677522909
Validation loss: 2.467125211159025

Epoch: 6| Step: 9
Training loss: 2.6852959754956593
Validation loss: 2.443875832716048

Epoch: 6| Step: 10
Training loss: 2.0747943086821508
Validation loss: 2.4322848423445342

Epoch: 6| Step: 11
Training loss: 3.0568424828515157
Validation loss: 2.4322070597402474

Epoch: 6| Step: 12
Training loss: 2.4861650076292023
Validation loss: 2.4293750975843884

Epoch: 6| Step: 13
Training loss: 3.1229059451179797
Validation loss: 2.435784424278881

Epoch: 144| Step: 0
Training loss: 3.2701763943099986
Validation loss: 2.447033981195717

Epoch: 6| Step: 1
Training loss: 2.6171809409899156
Validation loss: 2.4628062767617225

Epoch: 6| Step: 2
Training loss: 2.871027316408275
Validation loss: 2.4740063675695287

Epoch: 6| Step: 3
Training loss: 3.020200588562589
Validation loss: 2.514975616136919

Epoch: 6| Step: 4
Training loss: 2.8448123833819103
Validation loss: 2.55421304613643

Epoch: 6| Step: 5
Training loss: 2.807406751624599
Validation loss: 2.548895261027525

Epoch: 6| Step: 6
Training loss: 2.8035997922120335
Validation loss: 2.56516183243121

Epoch: 6| Step: 7
Training loss: 2.1173192507582193
Validation loss: 2.5728807088541235

Epoch: 6| Step: 8
Training loss: 2.730970432106067
Validation loss: 2.585028662377188

Epoch: 6| Step: 9
Training loss: 2.8208817940347566
Validation loss: 2.545398857376916

Epoch: 6| Step: 10
Training loss: 2.7653870561041467
Validation loss: 2.495211909572581

Epoch: 6| Step: 11
Training loss: 2.8793603753723933
Validation loss: 2.4829875363240577

Epoch: 6| Step: 12
Training loss: 2.070524154496399
Validation loss: 2.4666841091932254

Epoch: 6| Step: 13
Training loss: 3.0808756200440226
Validation loss: 2.4689653468054966

Epoch: 145| Step: 0
Training loss: 2.2822673044742734
Validation loss: 2.477115232865849

Epoch: 6| Step: 1
Training loss: 2.607322388083298
Validation loss: 2.4736801935823896

Epoch: 6| Step: 2
Training loss: 2.6170545857399365
Validation loss: 2.4558734680239183

Epoch: 6| Step: 3
Training loss: 2.98935256404062
Validation loss: 2.44435456846557

Epoch: 6| Step: 4
Training loss: 2.8078114742559515
Validation loss: 2.42345860602194

Epoch: 6| Step: 5
Training loss: 2.8179675045914907
Validation loss: 2.445051947629283

Epoch: 6| Step: 6
Training loss: 2.6043742796473723
Validation loss: 2.4406320208437657

Epoch: 6| Step: 7
Training loss: 2.813745773766427
Validation loss: 2.426068488093292

Epoch: 6| Step: 8
Training loss: 2.90297571954353
Validation loss: 2.4188628753086894

Epoch: 6| Step: 9
Training loss: 2.6891447844874463
Validation loss: 2.434735414490296

Epoch: 6| Step: 10
Training loss: 2.9623313179763295
Validation loss: 2.4403989626511344

Epoch: 6| Step: 11
Training loss: 2.4233301528776865
Validation loss: 2.4421460635632646

Epoch: 6| Step: 12
Training loss: 3.0033255265021888
Validation loss: 2.469177679460574

Epoch: 6| Step: 13
Training loss: 2.714639999098781
Validation loss: 2.5298864666550283

Epoch: 146| Step: 0
Training loss: 2.267978156500957
Validation loss: 2.537295985450201

Epoch: 6| Step: 1
Training loss: 3.1341306429510816
Validation loss: 2.5552536486769593

Epoch: 6| Step: 2
Training loss: 2.8535674271264777
Validation loss: 2.5264598947184695

Epoch: 6| Step: 3
Training loss: 2.390500233704253
Validation loss: 2.4819119978660837

Epoch: 6| Step: 4
Training loss: 2.793308221420389
Validation loss: 2.476382462415029

Epoch: 6| Step: 5
Training loss: 2.8060698011693193
Validation loss: 2.440452128959128

Epoch: 6| Step: 6
Training loss: 3.06365726948498
Validation loss: 2.428993520871904

Epoch: 6| Step: 7
Training loss: 2.9439655330340373
Validation loss: 2.423052165281215

Epoch: 6| Step: 8
Training loss: 2.5361349746994537
Validation loss: 2.409632495473941

Epoch: 6| Step: 9
Training loss: 2.7923502203816377
Validation loss: 2.4164731355204188

Epoch: 6| Step: 10
Training loss: 2.6698013200311257
Validation loss: 2.4283647938785484

Epoch: 6| Step: 11
Training loss: 2.8379208693760023
Validation loss: 2.4269410549857735

Epoch: 6| Step: 12
Training loss: 2.8245719382804686
Validation loss: 2.4111744150466867

Epoch: 6| Step: 13
Training loss: 2.0907994447011524
Validation loss: 2.4204216106830345

Epoch: 147| Step: 0
Training loss: 2.7568293648079636
Validation loss: 2.455106830428292

Epoch: 6| Step: 1
Training loss: 2.9163110970426125
Validation loss: 2.473366162725395

Epoch: 6| Step: 2
Training loss: 2.8609771409093194
Validation loss: 2.4845434539206135

Epoch: 6| Step: 3
Training loss: 2.6761313995921987
Validation loss: 2.4905706754340273

Epoch: 6| Step: 4
Training loss: 2.609281618194808
Validation loss: 2.5158310315837293

Epoch: 6| Step: 5
Training loss: 3.011276034459958
Validation loss: 2.5099606520836937

Epoch: 6| Step: 6
Training loss: 2.4579203199441464
Validation loss: 2.4844211948914094

Epoch: 6| Step: 7
Training loss: 2.7076926916420603
Validation loss: 2.456336133224736

Epoch: 6| Step: 8
Training loss: 3.0457714723357587
Validation loss: 2.439534922098324

Epoch: 6| Step: 9
Training loss: 2.8670052202787266
Validation loss: 2.4239863015478247

Epoch: 6| Step: 10
Training loss: 2.072120654242244
Validation loss: 2.4430271375050494

Epoch: 6| Step: 11
Training loss: 2.388115856369792
Validation loss: 2.427216896699761

Epoch: 6| Step: 12
Training loss: 2.8119515626026677
Validation loss: 2.430882533317834

Epoch: 6| Step: 13
Training loss: 2.6880596376626587
Validation loss: 2.4128001661005722

Epoch: 148| Step: 0
Training loss: 2.487947306838556
Validation loss: 2.434734161486326

Epoch: 6| Step: 1
Training loss: 2.61507556025673
Validation loss: 2.4327641376693228

Epoch: 6| Step: 2
Training loss: 2.893918032947875
Validation loss: 2.477062818286217

Epoch: 6| Step: 3
Training loss: 3.1106797744315657
Validation loss: 2.5079302229372296

Epoch: 6| Step: 4
Training loss: 2.319494340807883
Validation loss: 2.5191050433623405

Epoch: 6| Step: 5
Training loss: 3.227402990938375
Validation loss: 2.533584598767592

Epoch: 6| Step: 6
Training loss: 2.9128223879273585
Validation loss: 2.5516002272275

Epoch: 6| Step: 7
Training loss: 2.8410787927053103
Validation loss: 2.522557786351405

Epoch: 6| Step: 8
Training loss: 2.3311957263509395
Validation loss: 2.501739206672944

Epoch: 6| Step: 9
Training loss: 2.482214414029698
Validation loss: 2.484930412734566

Epoch: 6| Step: 10
Training loss: 2.71851786356872
Validation loss: 2.452852906937833

Epoch: 6| Step: 11
Training loss: 2.315619143582865
Validation loss: 2.4497984300776614

Epoch: 6| Step: 12
Training loss: 2.539160248268695
Validation loss: 2.4434088581814737

Epoch: 6| Step: 13
Training loss: 3.177035638836847
Validation loss: 2.4431421059317713

Epoch: 149| Step: 0
Training loss: 2.505976685344749
Validation loss: 2.446666639414119

Epoch: 6| Step: 1
Training loss: 2.2343648630192363
Validation loss: 2.4615210546219912

Epoch: 6| Step: 2
Training loss: 2.929262013373533
Validation loss: 2.470889251739714

Epoch: 6| Step: 3
Training loss: 2.402909077442246
Validation loss: 2.4809762774130117

Epoch: 6| Step: 4
Training loss: 2.903060639718168
Validation loss: 2.5051678762204386

Epoch: 6| Step: 5
Training loss: 2.8879058420571626
Validation loss: 2.453879264528572

Epoch: 6| Step: 6
Training loss: 2.7827154006595993
Validation loss: 2.457894792611935

Epoch: 6| Step: 7
Training loss: 2.3402691233167094
Validation loss: 2.4227116976376473

Epoch: 6| Step: 8
Training loss: 3.0384301162625302
Validation loss: 2.4211188346252817

Epoch: 6| Step: 9
Training loss: 2.582270024003624
Validation loss: 2.421755836669965

Epoch: 6| Step: 10
Training loss: 3.2348505674868084
Validation loss: 2.4221913713593684

Epoch: 6| Step: 11
Training loss: 2.859942103780267
Validation loss: 2.424313787954127

Epoch: 6| Step: 12
Training loss: 2.4865952653153607
Validation loss: 2.4324069215299384

Epoch: 6| Step: 13
Training loss: 2.1284921785891497
Validation loss: 2.4425539766935342

Epoch: 150| Step: 0
Training loss: 2.676809116276861
Validation loss: 2.507653230660761

Epoch: 6| Step: 1
Training loss: 2.5682158571474885
Validation loss: 2.5652042189297735

Epoch: 6| Step: 2
Training loss: 3.0947746352569494
Validation loss: 2.5978500058327314

Epoch: 6| Step: 3
Training loss: 2.786449586848617
Validation loss: 2.638330503351364

Epoch: 6| Step: 4
Training loss: 3.0836715684557023
Validation loss: 2.5783559736126738

Epoch: 6| Step: 5
Training loss: 2.764738899995829
Validation loss: 2.580900933296096

Epoch: 6| Step: 6
Training loss: 2.5878218040672185
Validation loss: 2.5790099851534127

Epoch: 6| Step: 7
Training loss: 1.9017613829623976
Validation loss: 2.5343225775878824

Epoch: 6| Step: 8
Training loss: 2.656884330853374
Validation loss: 2.481013186270046

Epoch: 6| Step: 9
Training loss: 2.859286614391307
Validation loss: 2.424837209550602

Epoch: 6| Step: 10
Training loss: 2.649305623327954
Validation loss: 2.413438143262953

Epoch: 6| Step: 11
Training loss: 2.831016453421968
Validation loss: 2.4315969150326247

Epoch: 6| Step: 12
Training loss: 2.5650067977369035
Validation loss: 2.4435376406977207

Epoch: 6| Step: 13
Training loss: 2.46117048825792
Validation loss: 2.4549585693898783

Epoch: 151| Step: 0
Training loss: 2.8586161289136656
Validation loss: 2.4786930574577677

Epoch: 6| Step: 1
Training loss: 2.647877051544583
Validation loss: 2.492902747417051

Epoch: 6| Step: 2
Training loss: 2.4227184180654677
Validation loss: 2.539728250236536

Epoch: 6| Step: 3
Training loss: 3.0358461752058057
Validation loss: 2.589091824204282

Epoch: 6| Step: 4
Training loss: 2.262028542814949
Validation loss: 2.569711288154864

Epoch: 6| Step: 5
Training loss: 3.3807733393696155
Validation loss: 2.5645181625627993

Epoch: 6| Step: 6
Training loss: 3.1621325976795496
Validation loss: 2.511826394891847

Epoch: 6| Step: 7
Training loss: 2.545956685958609
Validation loss: 2.506640998668113

Epoch: 6| Step: 8
Training loss: 2.330673666067692
Validation loss: 2.5155665791425315

Epoch: 6| Step: 9
Training loss: 2.6899465026641
Validation loss: 2.5458827428338195

Epoch: 6| Step: 10
Training loss: 2.7791283905581
Validation loss: 2.5602485976915665

Epoch: 6| Step: 11
Training loss: 2.623470950978387
Validation loss: 2.548039933729196

Epoch: 6| Step: 12
Training loss: 3.034292994293683
Validation loss: 2.5574935369927454

Epoch: 6| Step: 13
Training loss: 3.379186223949904
Validation loss: 2.5881529878323972

Epoch: 152| Step: 0
Training loss: 2.5617020457829223
Validation loss: 2.6008791757947027

Epoch: 6| Step: 1
Training loss: 3.5369431505582276
Validation loss: 2.600170233614473

Epoch: 6| Step: 2
Training loss: 2.7346478135388876
Validation loss: 2.6060936726552053

Epoch: 6| Step: 3
Training loss: 2.8479606559907547
Validation loss: 2.6233328844607327

Epoch: 6| Step: 4
Training loss: 2.8148337959835623
Validation loss: 2.642321483447201

Epoch: 6| Step: 5
Training loss: 3.3284714209561828
Validation loss: 2.597570326632572

Epoch: 6| Step: 6
Training loss: 2.7177565941132755
Validation loss: 2.57396497855352

Epoch: 6| Step: 7
Training loss: 1.801603315805836
Validation loss: 2.5156430387936157

Epoch: 6| Step: 8
Training loss: 2.371722017161934
Validation loss: 2.5077044824371377

Epoch: 6| Step: 9
Training loss: 2.600973709882888
Validation loss: 2.4886103236497408

Epoch: 6| Step: 10
Training loss: 2.4854927667402427
Validation loss: 2.466269132756977

Epoch: 6| Step: 11
Training loss: 3.2567977239605965
Validation loss: 2.4644696247644258

Epoch: 6| Step: 12
Training loss: 2.8043322324881763
Validation loss: 2.451611816815382

Epoch: 6| Step: 13
Training loss: 2.5188607203378064
Validation loss: 2.444127344684943

Epoch: 153| Step: 0
Training loss: 3.3507804758538393
Validation loss: 2.420407989704279

Epoch: 6| Step: 1
Training loss: 2.8121435151410314
Validation loss: 2.4404055282712087

Epoch: 6| Step: 2
Training loss: 2.3636464238786346
Validation loss: 2.4478224843342864

Epoch: 6| Step: 3
Training loss: 2.5917649543826053
Validation loss: 2.454925409402762

Epoch: 6| Step: 4
Training loss: 2.9709767874546307
Validation loss: 2.4861672586563692

Epoch: 6| Step: 5
Training loss: 2.2666123968060212
Validation loss: 2.5202832606179455

Epoch: 6| Step: 6
Training loss: 2.2813258746344975
Validation loss: 2.499823389685661

Epoch: 6| Step: 7
Training loss: 2.626007976464667
Validation loss: 2.509787741687675

Epoch: 6| Step: 8
Training loss: 2.994066410426453
Validation loss: 2.5116593074091282

Epoch: 6| Step: 9
Training loss: 2.68816349799326
Validation loss: 2.4872876882679797

Epoch: 6| Step: 10
Training loss: 2.7788312016547603
Validation loss: 2.463882368270227

Epoch: 6| Step: 11
Training loss: 2.290173153723457
Validation loss: 2.444816297094771

Epoch: 6| Step: 12
Training loss: 2.5445048531418353
Validation loss: 2.435432394353371

Epoch: 6| Step: 13
Training loss: 3.40194065583603
Validation loss: 2.417969169857206

Epoch: 154| Step: 0
Training loss: 2.906124153283771
Validation loss: 2.4214718147305967

Epoch: 6| Step: 1
Training loss: 3.010177197991119
Validation loss: 2.413530594255899

Epoch: 6| Step: 2
Training loss: 2.24714617412552
Validation loss: 2.421281081357759

Epoch: 6| Step: 3
Training loss: 2.124429289530103
Validation loss: 2.4280463887977866

Epoch: 6| Step: 4
Training loss: 3.2757356356195433
Validation loss: 2.4459291081918217

Epoch: 6| Step: 5
Training loss: 2.933541898104087
Validation loss: 2.4470179248247854

Epoch: 6| Step: 6
Training loss: 2.792089620026289
Validation loss: 2.4720050023022297

Epoch: 6| Step: 7
Training loss: 2.3677069468619343
Validation loss: 2.5330222784724192

Epoch: 6| Step: 8
Training loss: 2.24332667530691
Validation loss: 2.5568659383159367

Epoch: 6| Step: 9
Training loss: 2.2404476420118993
Validation loss: 2.5639204464802194

Epoch: 6| Step: 10
Training loss: 2.3476994109034273
Validation loss: 2.586344070675721

Epoch: 6| Step: 11
Training loss: 3.4468199185131763
Validation loss: 2.569439164096854

Epoch: 6| Step: 12
Training loss: 2.715742530518206
Validation loss: 2.5361553522520937

Epoch: 6| Step: 13
Training loss: 2.2193859424713414
Validation loss: 2.4954106424500124

Epoch: 155| Step: 0
Training loss: 1.6833534157691283
Validation loss: 2.4934685623661004

Epoch: 6| Step: 1
Training loss: 2.6831645150321632
Validation loss: 2.4564410661821867

Epoch: 6| Step: 2
Training loss: 3.448386553105831
Validation loss: 2.4552940799502414

Epoch: 6| Step: 3
Training loss: 2.747308627849313
Validation loss: 2.4613304114906946

Epoch: 6| Step: 4
Training loss: 3.014906723578672
Validation loss: 2.435892046450443

Epoch: 6| Step: 5
Training loss: 2.4654190190170624
Validation loss: 2.459237131910133

Epoch: 6| Step: 6
Training loss: 2.926998766201269
Validation loss: 2.4752017197825436

Epoch: 6| Step: 7
Training loss: 2.592878815831713
Validation loss: 2.517275840853052

Epoch: 6| Step: 8
Training loss: 2.5600302354696036
Validation loss: 2.544622403880766

Epoch: 6| Step: 9
Training loss: 2.5395125239709917
Validation loss: 2.5309551831480626

Epoch: 6| Step: 10
Training loss: 2.1356509816702336
Validation loss: 2.5452833508796204

Epoch: 6| Step: 11
Training loss: 2.7670627456019394
Validation loss: 2.5376332298811914

Epoch: 6| Step: 12
Training loss: 2.5202393475657336
Validation loss: 2.5185704445661825

Epoch: 6| Step: 13
Training loss: 3.094012008515463
Validation loss: 2.489670753531677

Epoch: 156| Step: 0
Training loss: 2.915154382926219
Validation loss: 2.4750102462962498

Epoch: 6| Step: 1
Training loss: 2.525445759017263
Validation loss: 2.4381663177133035

Epoch: 6| Step: 2
Training loss: 2.6585609705291686
Validation loss: 2.4521648146881976

Epoch: 6| Step: 3
Training loss: 2.805657094328712
Validation loss: 2.416323329424656

Epoch: 6| Step: 4
Training loss: 2.197778694438497
Validation loss: 2.4012409626029676

Epoch: 6| Step: 5
Training loss: 2.7502035585838844
Validation loss: 2.406787380285336

Epoch: 6| Step: 6
Training loss: 2.9899299411794953
Validation loss: 2.4016580543000146

Epoch: 6| Step: 7
Training loss: 2.969892101447169
Validation loss: 2.4047538368588826

Epoch: 6| Step: 8
Training loss: 2.8911026843481906
Validation loss: 2.3994089724252468

Epoch: 6| Step: 9
Training loss: 2.4981838305095336
Validation loss: 2.4441214708482786

Epoch: 6| Step: 10
Training loss: 2.026814003825589
Validation loss: 2.490008985375777

Epoch: 6| Step: 11
Training loss: 2.583663170789961
Validation loss: 2.5560145009107864

Epoch: 6| Step: 12
Training loss: 2.634816841549557
Validation loss: 2.5682716429818946

Epoch: 6| Step: 13
Training loss: 3.1362649439687154
Validation loss: 2.564875282447925

Epoch: 157| Step: 0
Training loss: 2.641271297659628
Validation loss: 2.589603622114565

Epoch: 6| Step: 1
Training loss: 2.9116167947755662
Validation loss: 2.549639473517847

Epoch: 6| Step: 2
Training loss: 2.9495251224868646
Validation loss: 2.5009004704222613

Epoch: 6| Step: 3
Training loss: 2.9465387761367308
Validation loss: 2.459329867877574

Epoch: 6| Step: 4
Training loss: 2.6943283274516485
Validation loss: 2.4288937444915155

Epoch: 6| Step: 5
Training loss: 2.4880297187857865
Validation loss: 2.4211712119287707

Epoch: 6| Step: 6
Training loss: 2.874276609219466
Validation loss: 2.4237643564821205

Epoch: 6| Step: 7
Training loss: 2.2078508053835995
Validation loss: 2.4178207797222986

Epoch: 6| Step: 8
Training loss: 2.356928384197034
Validation loss: 2.40596406716308

Epoch: 6| Step: 9
Training loss: 2.5025877910690877
Validation loss: 2.4106866851136406

Epoch: 6| Step: 10
Training loss: 3.0274151012256967
Validation loss: 2.4004886780421737

Epoch: 6| Step: 11
Training loss: 2.817062068776764
Validation loss: 2.412506041406855

Epoch: 6| Step: 12
Training loss: 2.5397460017525315
Validation loss: 2.413540024937643

Epoch: 6| Step: 13
Training loss: 2.1345890457262544
Validation loss: 2.4581738213926343

Epoch: 158| Step: 0
Training loss: 1.9148682435927085
Validation loss: 2.4724025370975036

Epoch: 6| Step: 1
Training loss: 2.779997125528071
Validation loss: 2.508757682911277

Epoch: 6| Step: 2
Training loss: 2.9006179874584452
Validation loss: 2.5342963454603664

Epoch: 6| Step: 3
Training loss: 2.5195641803807294
Validation loss: 2.4562363424085567

Epoch: 6| Step: 4
Training loss: 2.5736848454058396
Validation loss: 2.423155067299178

Epoch: 6| Step: 5
Training loss: 1.889548002821908
Validation loss: 2.3971881178324077

Epoch: 6| Step: 6
Training loss: 3.155202559605115
Validation loss: 2.3927704692219107

Epoch: 6| Step: 7
Training loss: 2.51511941887918
Validation loss: 2.3906957069110413

Epoch: 6| Step: 8
Training loss: 2.718973347927843
Validation loss: 2.3801555622758497

Epoch: 6| Step: 9
Training loss: 3.3422553028364512
Validation loss: 2.395107548492185

Epoch: 6| Step: 10
Training loss: 2.7837474625314247
Validation loss: 2.407696710271126

Epoch: 6| Step: 11
Training loss: 2.5144201200961303
Validation loss: 2.4022336376855518

Epoch: 6| Step: 12
Training loss: 2.613149961814459
Validation loss: 2.4485724170188883

Epoch: 6| Step: 13
Training loss: 2.26412672290053
Validation loss: 2.4609526394640273

Epoch: 159| Step: 0
Training loss: 2.1093941016568563
Validation loss: 2.487027658613525

Epoch: 6| Step: 1
Training loss: 2.1938966142399208
Validation loss: 2.479253236068

Epoch: 6| Step: 2
Training loss: 2.9559174106607684
Validation loss: 2.489679319680324

Epoch: 6| Step: 3
Training loss: 2.8036044694170146
Validation loss: 2.4696828435677274

Epoch: 6| Step: 4
Training loss: 1.9932018614740195
Validation loss: 2.4779153435338515

Epoch: 6| Step: 5
Training loss: 2.957949617958834
Validation loss: 2.4650151121819515

Epoch: 6| Step: 6
Training loss: 2.7325020615411995
Validation loss: 2.4834810819470152

Epoch: 6| Step: 7
Training loss: 3.0388625993662743
Validation loss: 2.5083727186116622

Epoch: 6| Step: 8
Training loss: 2.463344208517403
Validation loss: 2.5212054888536404

Epoch: 6| Step: 9
Training loss: 2.527247525819878
Validation loss: 2.5670334207025576

Epoch: 6| Step: 10
Training loss: 2.1279579220247085
Validation loss: 2.548968735580581

Epoch: 6| Step: 11
Training loss: 2.674259125975598
Validation loss: 2.5020541601640587

Epoch: 6| Step: 12
Training loss: 2.4700080466815058
Validation loss: 2.4912227481553666

Epoch: 6| Step: 13
Training loss: 3.291882101485496
Validation loss: 2.507388605856184

Epoch: 160| Step: 0
Training loss: 2.0483584088290088
Validation loss: 2.501568190631385

Epoch: 6| Step: 1
Training loss: 2.611292425808944
Validation loss: 2.5728534818432562

Epoch: 6| Step: 2
Training loss: 2.473981312427546
Validation loss: 2.5807476114855015

Epoch: 6| Step: 3
Training loss: 2.4083434077209462
Validation loss: 2.5523927197614307

Epoch: 6| Step: 4
Training loss: 2.547743385974892
Validation loss: 2.5221096751162997

Epoch: 6| Step: 5
Training loss: 2.897076968628587
Validation loss: 2.4832910211061914

Epoch: 6| Step: 6
Training loss: 2.421453722338102
Validation loss: 2.4713021001707247

Epoch: 6| Step: 7
Training loss: 2.695208119015964
Validation loss: 2.4708519665052964

Epoch: 6| Step: 8
Training loss: 2.6132644629972783
Validation loss: 2.4630542949358194

Epoch: 6| Step: 9
Training loss: 2.797292497045291
Validation loss: 2.466429739861567

Epoch: 6| Step: 10
Training loss: 2.8167569475170375
Validation loss: 2.4778754419590396

Epoch: 6| Step: 11
Training loss: 3.1084894040549775
Validation loss: 2.4836039849135947

Epoch: 6| Step: 12
Training loss: 2.8875235750631387
Validation loss: 2.4792506344284706

Epoch: 6| Step: 13
Training loss: 1.8896652181506206
Validation loss: 2.476634612398186

Epoch: 161| Step: 0
Training loss: 2.6559469611146054
Validation loss: 2.484871760285758

Epoch: 6| Step: 1
Training loss: 2.7151421472139607
Validation loss: 2.4850175165616384

Epoch: 6| Step: 2
Training loss: 2.1164003154548925
Validation loss: 2.4908327631716314

Epoch: 6| Step: 3
Training loss: 3.081319168273949
Validation loss: 2.5082700205517323

Epoch: 6| Step: 4
Training loss: 2.5915319311642953
Validation loss: 2.480697490805816

Epoch: 6| Step: 5
Training loss: 2.2158080462557135
Validation loss: 2.474958296766602

Epoch: 6| Step: 6
Training loss: 3.0026166948165747
Validation loss: 2.5004274966708206

Epoch: 6| Step: 7
Training loss: 2.963586754391655
Validation loss: 2.4929290469587584

Epoch: 6| Step: 8
Training loss: 2.15656377748375
Validation loss: 2.4853443987207817

Epoch: 6| Step: 9
Training loss: 2.2941977539431946
Validation loss: 2.4883021956205003

Epoch: 6| Step: 10
Training loss: 1.8572229706074281
Validation loss: 2.465081375535416

Epoch: 6| Step: 11
Training loss: 2.7328890005127424
Validation loss: 2.4585125605630327

Epoch: 6| Step: 12
Training loss: 2.578060264930643
Validation loss: 2.472366886055044

Epoch: 6| Step: 13
Training loss: 2.792231279658618
Validation loss: 2.483696789588149

Epoch: 162| Step: 0
Training loss: 2.7249010155574793
Validation loss: 2.4687474350599863

Epoch: 6| Step: 1
Training loss: 2.550112860182939
Validation loss: 2.455329643727309

Epoch: 6| Step: 2
Training loss: 2.675985643140202
Validation loss: 2.413169680075092

Epoch: 6| Step: 3
Training loss: 2.4959730140009713
Validation loss: 2.426460278740502

Epoch: 6| Step: 4
Training loss: 2.24523845808025
Validation loss: 2.4168995782837697

Epoch: 6| Step: 5
Training loss: 2.140053665878633
Validation loss: 2.4522598702660137

Epoch: 6| Step: 6
Training loss: 2.330521240052468
Validation loss: 2.5083437376658604

Epoch: 6| Step: 7
Training loss: 2.844347880466154
Validation loss: 2.575403376285048

Epoch: 6| Step: 8
Training loss: 2.4661907016065636
Validation loss: 2.595989019483862

Epoch: 6| Step: 9
Training loss: 2.849514327578679
Validation loss: 2.5898888427083278

Epoch: 6| Step: 10
Training loss: 2.8571201459799433
Validation loss: 2.557801848723449

Epoch: 6| Step: 11
Training loss: 2.6213887214972744
Validation loss: 2.510000236637706

Epoch: 6| Step: 12
Training loss: 2.409707990659915
Validation loss: 2.4949486213605674

Epoch: 6| Step: 13
Training loss: 2.0884368438925165
Validation loss: 2.4721522493204895

Epoch: 163| Step: 0
Training loss: 2.5799542959733848
Validation loss: 2.4348634049223326

Epoch: 6| Step: 1
Training loss: 2.182809432948476
Validation loss: 2.4444333929531132

Epoch: 6| Step: 2
Training loss: 2.639838197402556
Validation loss: 2.44109673777308

Epoch: 6| Step: 3
Training loss: 2.36859451629125
Validation loss: 2.434354633758597

Epoch: 6| Step: 4
Training loss: 2.776038269460769
Validation loss: 2.4329746477848953

Epoch: 6| Step: 5
Training loss: 2.329883295500935
Validation loss: 2.431374675665606

Epoch: 6| Step: 6
Training loss: 2.2871187569859877
Validation loss: 2.4458098569038427

Epoch: 6| Step: 7
Training loss: 1.9718228534265978
Validation loss: 2.4670332929947167

Epoch: 6| Step: 8
Training loss: 2.486257835287614
Validation loss: 2.4766219760073596

Epoch: 6| Step: 9
Training loss: 2.2347206968696507
Validation loss: 2.5101662988664786

Epoch: 6| Step: 10
Training loss: 2.74904468589146
Validation loss: 2.5328647765396672

Epoch: 6| Step: 11
Training loss: 2.2160741224390033
Validation loss: 2.579270186011625

Epoch: 6| Step: 12
Training loss: 3.015932690038809
Validation loss: 2.609867729543061

Epoch: 6| Step: 13
Training loss: 3.3469505322906383
Validation loss: 2.5487950939363633

Epoch: 164| Step: 0
Training loss: 2.012255787692643
Validation loss: 2.5310988498184424

Epoch: 6| Step: 1
Training loss: 2.8197415690674394
Validation loss: 2.5161810828273987

Epoch: 6| Step: 2
Training loss: 1.8950360127149812
Validation loss: 2.5166459179746647

Epoch: 6| Step: 3
Training loss: 2.6598606477532445
Validation loss: 2.5071349822391436

Epoch: 6| Step: 4
Training loss: 2.031256573006192
Validation loss: 2.5046660962734313

Epoch: 6| Step: 5
Training loss: 2.128319671734383
Validation loss: 2.4880562377887183

Epoch: 6| Step: 6
Training loss: 2.5600862998125264
Validation loss: 2.4705594732905354

Epoch: 6| Step: 7
Training loss: 1.9445402765122015
Validation loss: 2.4533946543092684

Epoch: 6| Step: 8
Training loss: 2.8461013965572035
Validation loss: 2.472692529306929

Epoch: 6| Step: 9
Training loss: 2.448542986887605
Validation loss: 2.4754856436946877

Epoch: 6| Step: 10
Training loss: 2.6759175732267266
Validation loss: 2.4685611769466718

Epoch: 6| Step: 11
Training loss: 2.7353555719468114
Validation loss: 2.4920226870786504

Epoch: 6| Step: 12
Training loss: 2.957065758447092
Validation loss: 2.4753312282144613

Epoch: 6| Step: 13
Training loss: 2.692621894988704
Validation loss: 2.494094893825085

Epoch: 165| Step: 0
Training loss: 2.67471662072072
Validation loss: 2.4960783317120923

Epoch: 6| Step: 1
Training loss: 2.4127924766544657
Validation loss: 2.5006827427103064

Epoch: 6| Step: 2
Training loss: 2.521682270537123
Validation loss: 2.4921094607214163

Epoch: 6| Step: 3
Training loss: 2.6496264284359246
Validation loss: 2.4712317420085457

Epoch: 6| Step: 4
Training loss: 2.3323493881090993
Validation loss: 2.441745483719181

Epoch: 6| Step: 5
Training loss: 2.2544912441859437
Validation loss: 2.478100913056074

Epoch: 6| Step: 6
Training loss: 2.3074180849689014
Validation loss: 2.485662502194333

Epoch: 6| Step: 7
Training loss: 2.595636899403247
Validation loss: 2.516880971013177

Epoch: 6| Step: 8
Training loss: 2.7503061991063418
Validation loss: 2.5239711105722553

Epoch: 6| Step: 9
Training loss: 2.6533934548370084
Validation loss: 2.556565466678795

Epoch: 6| Step: 10
Training loss: 2.4757353066069334
Validation loss: 2.5445969942548845

Epoch: 6| Step: 11
Training loss: 1.8374157737060677
Validation loss: 2.526088334009698

Epoch: 6| Step: 12
Training loss: 2.361942738199882
Validation loss: 2.534288218422687

Epoch: 6| Step: 13
Training loss: 2.5708389438792567
Validation loss: 2.53262841518528

Epoch: 166| Step: 0
Training loss: 2.5204530434346393
Validation loss: 2.5524843822900283

Epoch: 6| Step: 1
Training loss: 1.7561332310856959
Validation loss: 2.533974402174704

Epoch: 6| Step: 2
Training loss: 2.565838197870982
Validation loss: 2.5387650086299094

Epoch: 6| Step: 3
Training loss: 2.379951034651269
Validation loss: 2.5332896265535227

Epoch: 6| Step: 4
Training loss: 2.4600493266424883
Validation loss: 2.519659861634856

Epoch: 6| Step: 5
Training loss: 2.475022279273047
Validation loss: 2.504901529417433

Epoch: 6| Step: 6
Training loss: 2.8093487357502056
Validation loss: 2.4794463102225586

Epoch: 6| Step: 7
Training loss: 2.7959081587654087
Validation loss: 2.4874046129717735

Epoch: 6| Step: 8
Training loss: 2.803201690951582
Validation loss: 2.512740486817592

Epoch: 6| Step: 9
Training loss: 2.3224081215480252
Validation loss: 2.597003726945798

Epoch: 6| Step: 10
Training loss: 1.8733592165768678
Validation loss: 2.5915431401904585

Epoch: 6| Step: 11
Training loss: 2.4629787154027247
Validation loss: 2.5764513785322674

Epoch: 6| Step: 12
Training loss: 2.3045235268403093
Validation loss: 2.6125537564740338

Epoch: 6| Step: 13
Training loss: 2.3299332323454034
Validation loss: 2.5162553964864314

Epoch: 167| Step: 0
Training loss: 2.678640978682246
Validation loss: 2.4920410777758017

Epoch: 6| Step: 1
Training loss: 2.7078704634074056
Validation loss: 2.4692491281483795

Epoch: 6| Step: 2
Training loss: 2.4113548921242356
Validation loss: 2.4681365420603063

Epoch: 6| Step: 3
Training loss: 2.631659280655079
Validation loss: 2.4591010472926365

Epoch: 6| Step: 4
Training loss: 2.1278317600946695
Validation loss: 2.4594559582068367

Epoch: 6| Step: 5
Training loss: 2.4868589255673164
Validation loss: 2.4479598698483214

Epoch: 6| Step: 6
Training loss: 1.6881752076180396
Validation loss: 2.496171897850982

Epoch: 6| Step: 7
Training loss: 2.533047261733539
Validation loss: 2.535119787104671

Epoch: 6| Step: 8
Training loss: 2.7309045184669407
Validation loss: 2.6276785822313777

Epoch: 6| Step: 9
Training loss: 2.721765008361704
Validation loss: 2.6546928508024066

Epoch: 6| Step: 10
Training loss: 2.1599158486115835
Validation loss: 2.6438745090428353

Epoch: 6| Step: 11
Training loss: 2.099454936180516
Validation loss: 2.556928603148643

Epoch: 6| Step: 12
Training loss: 2.4858754743106695
Validation loss: 2.5578633139760063

Epoch: 6| Step: 13
Training loss: 1.9462322221065302
Validation loss: 2.5294517734139252

Epoch: 168| Step: 0
Training loss: 2.6096648095283848
Validation loss: 2.4795565596302636

Epoch: 6| Step: 1
Training loss: 2.318872383774637
Validation loss: 2.488668547532424

Epoch: 6| Step: 2
Training loss: 2.0666442618642513
Validation loss: 2.466651552185051

Epoch: 6| Step: 3
Training loss: 2.158360761176065
Validation loss: 2.500407288301979

Epoch: 6| Step: 4
Training loss: 2.3942990462708775
Validation loss: 2.5212044638874893

Epoch: 6| Step: 5
Training loss: 2.289021254027931
Validation loss: 2.561909761439693

Epoch: 6| Step: 6
Training loss: 2.5191890513739734
Validation loss: 2.5525918220868826

Epoch: 6| Step: 7
Training loss: 2.9077298898251565
Validation loss: 2.5708836699053066

Epoch: 6| Step: 8
Training loss: 2.207739576254423
Validation loss: 2.5467898326096603

Epoch: 6| Step: 9
Training loss: 2.287244159170255
Validation loss: 2.5559600323028357

Epoch: 6| Step: 10
Training loss: 2.5625530330473505
Validation loss: 2.572555914927235

Epoch: 6| Step: 11
Training loss: 2.314143447438967
Validation loss: 2.5563423712699764

Epoch: 6| Step: 12
Training loss: 1.9805953908905756
Validation loss: 2.541805200686337

Epoch: 6| Step: 13
Training loss: 2.6059113316766536
Validation loss: 2.5175677729779418

Epoch: 169| Step: 0
Training loss: 2.755526970728752
Validation loss: 2.5437436996695975

Epoch: 6| Step: 1
Training loss: 2.050473260913071
Validation loss: 2.5437069794132463

Epoch: 6| Step: 2
Training loss: 1.7352388996911823
Validation loss: 2.559172649283256

Epoch: 6| Step: 3
Training loss: 2.929181922521968
Validation loss: 2.573004445885319

Epoch: 6| Step: 4
Training loss: 1.674857073706945
Validation loss: 2.553589394850106

Epoch: 6| Step: 5
Training loss: 2.9796843890297406
Validation loss: 2.5516190877384988

Epoch: 6| Step: 6
Training loss: 2.2747454993453644
Validation loss: 2.498513126699222

Epoch: 6| Step: 7
Training loss: 2.548052743650301
Validation loss: 2.4902310611092355

Epoch: 6| Step: 8
Training loss: 1.9907459503749658
Validation loss: 2.4818497517083795

Epoch: 6| Step: 9
Training loss: 2.340158788396041
Validation loss: 2.451899061040689

Epoch: 6| Step: 10
Training loss: 1.9822789934654936
Validation loss: 2.47214959406114

Epoch: 6| Step: 11
Training loss: 2.465739865643165
Validation loss: 2.526580487856675

Epoch: 6| Step: 12
Training loss: 2.5521709401151718
Validation loss: 2.5437190562888685

Epoch: 6| Step: 13
Training loss: 2.445662793306893
Validation loss: 2.621182679481029

Epoch: 170| Step: 0
Training loss: 1.6291953729050095
Validation loss: 2.6598963273578313

Epoch: 6| Step: 1
Training loss: 2.4250589422554425
Validation loss: 2.614454037670309

Epoch: 6| Step: 2
Training loss: 2.9923854194700965
Validation loss: 2.553440080084884

Epoch: 6| Step: 3
Training loss: 2.6227007287429553
Validation loss: 2.5213442398001513

Epoch: 6| Step: 4
Training loss: 2.29891555347633
Validation loss: 2.475100258629625

Epoch: 6| Step: 5
Training loss: 2.382591962770707
Validation loss: 2.444307510425485

Epoch: 6| Step: 6
Training loss: 2.4018166064495525
Validation loss: 2.433253977711169

Epoch: 6| Step: 7
Training loss: 2.453229573930501
Validation loss: 2.436968410719725

Epoch: 6| Step: 8
Training loss: 2.35238663435721
Validation loss: 2.449750328610521

Epoch: 6| Step: 9
Training loss: 2.4785684349981127
Validation loss: 2.5043853884420897

Epoch: 6| Step: 10
Training loss: 2.346349469912983
Validation loss: 2.5391198183820243

Epoch: 6| Step: 11
Training loss: 1.944596921149789
Validation loss: 2.5700728445006824

Epoch: 6| Step: 12
Training loss: 2.1809170444249104
Validation loss: 2.604625914082346

Epoch: 6| Step: 13
Training loss: 2.250766305764613
Validation loss: 2.634010771335027

Epoch: 171| Step: 0
Training loss: 2.486080615841066
Validation loss: 2.66263658576757

Epoch: 6| Step: 1
Training loss: 2.1401609488596707
Validation loss: 2.6365025721643627

Epoch: 6| Step: 2
Training loss: 2.069913314625982
Validation loss: 2.5532382400311318

Epoch: 6| Step: 3
Training loss: 2.2320226277260615
Validation loss: 2.4939478424378274

Epoch: 6| Step: 4
Training loss: 1.860706269498251
Validation loss: 2.503073096637525

Epoch: 6| Step: 5
Training loss: 2.9608215470369768
Validation loss: 2.45473400025004

Epoch: 6| Step: 6
Training loss: 1.9842910148089206
Validation loss: 2.4801833075333515

Epoch: 6| Step: 7
Training loss: 2.255269555603635
Validation loss: 2.5067797406849253

Epoch: 6| Step: 8
Training loss: 2.378870169831071
Validation loss: 2.503692213893747

Epoch: 6| Step: 9
Training loss: 2.0745927433991365
Validation loss: 2.5394077991981336

Epoch: 6| Step: 10
Training loss: 2.6079057223123936
Validation loss: 2.5443828616583284

Epoch: 6| Step: 11
Training loss: 2.344546780253566
Validation loss: 2.580519909312283

Epoch: 6| Step: 12
Training loss: 2.730738897971398
Validation loss: 2.622378227117025

Epoch: 6| Step: 13
Training loss: 1.9305154977693615
Validation loss: 2.615249329004298

Epoch: 172| Step: 0
Training loss: 2.3567820062249547
Validation loss: 2.6229804689415035

Epoch: 6| Step: 1
Training loss: 2.52666727295854
Validation loss: 2.637934169619834

Epoch: 6| Step: 2
Training loss: 2.247415329608064
Validation loss: 2.643632324224989

Epoch: 6| Step: 3
Training loss: 2.8375357335735245
Validation loss: 2.6500919832226755

Epoch: 6| Step: 4
Training loss: 1.782031373087115
Validation loss: 2.6187929413897137

Epoch: 6| Step: 5
Training loss: 1.664750794098449
Validation loss: 2.5859763091695496

Epoch: 6| Step: 6
Training loss: 2.300413558931145
Validation loss: 2.5617876991219224

Epoch: 6| Step: 7
Training loss: 1.7266088971424323
Validation loss: 2.514586096378239

Epoch: 6| Step: 8
Training loss: 2.4974400765348843
Validation loss: 2.4980643541654155

Epoch: 6| Step: 9
Training loss: 2.497548809013702
Validation loss: 2.5058690183304977

Epoch: 6| Step: 10
Training loss: 2.690398582652544
Validation loss: 2.5052033470100263

Epoch: 6| Step: 11
Training loss: 2.6884377196499316
Validation loss: 2.546549507690159

Epoch: 6| Step: 12
Training loss: 1.9329596202123784
Validation loss: 2.5563991643213986

Epoch: 6| Step: 13
Training loss: 2.156142301219451
Validation loss: 2.6234919390717746

Epoch: 173| Step: 0
Training loss: 1.663420289097666
Validation loss: 2.6866784085975666

Epoch: 6| Step: 1
Training loss: 2.5797979302340415
Validation loss: 2.676577116115535

Epoch: 6| Step: 2
Training loss: 1.8290734072512698
Validation loss: 2.6196863407734

Epoch: 6| Step: 3
Training loss: 2.6187734780363034
Validation loss: 2.6148210254132005

Epoch: 6| Step: 4
Training loss: 1.8306232564650204
Validation loss: 2.604279255719923

Epoch: 6| Step: 5
Training loss: 2.405370278989626
Validation loss: 2.5664338201095585

Epoch: 6| Step: 6
Training loss: 2.4617273425573023
Validation loss: 2.505284379844381

Epoch: 6| Step: 7
Training loss: 2.333157214829581
Validation loss: 2.4820828302970854

Epoch: 6| Step: 8
Training loss: 2.122300958365622
Validation loss: 2.443964564956978

Epoch: 6| Step: 9
Training loss: 2.3872554194414533
Validation loss: 2.4570306072719768

Epoch: 6| Step: 10
Training loss: 2.6450299422474868
Validation loss: 2.450530577611213

Epoch: 6| Step: 11
Training loss: 2.353497187751952
Validation loss: 2.4898837411110537

Epoch: 6| Step: 12
Training loss: 2.0282159299994698
Validation loss: 2.518708166085819

Epoch: 6| Step: 13
Training loss: 2.2940207672376416
Validation loss: 2.6008125753442703

Epoch: 174| Step: 0
Training loss: 2.234517553090232
Validation loss: 2.642133051692427

Epoch: 6| Step: 1
Training loss: 1.9657078808897175
Validation loss: 2.6515784321076215

Epoch: 6| Step: 2
Training loss: 2.1862847358469826
Validation loss: 2.628424998611837

Epoch: 6| Step: 3
Training loss: 1.5854842567155458
Validation loss: 2.5664205105762554

Epoch: 6| Step: 4
Training loss: 2.0613987612553943
Validation loss: 2.530715587193672

Epoch: 6| Step: 5
Training loss: 1.8465020282402644
Validation loss: 2.485575523079282

Epoch: 6| Step: 6
Training loss: 3.0376450241067454
Validation loss: 2.483993114990045

Epoch: 6| Step: 7
Training loss: 2.6883749313904333
Validation loss: 2.497902890955545

Epoch: 6| Step: 8
Training loss: 1.9478643141730465
Validation loss: 2.5230003361011457

Epoch: 6| Step: 9
Training loss: 2.6879738678229597
Validation loss: 2.584846486765163

Epoch: 6| Step: 10
Training loss: 1.895126658210258
Validation loss: 2.591418811362873

Epoch: 6| Step: 11
Training loss: 2.0573959774823125
Validation loss: 2.609096461881569

Epoch: 6| Step: 12
Training loss: 2.4065056206807753
Validation loss: 2.612602139392941

Epoch: 6| Step: 13
Training loss: 2.5008484354381997
Validation loss: 2.6273943386784153

Epoch: 175| Step: 0
Training loss: 1.7974898903340935
Validation loss: 2.6480872095337973

Epoch: 6| Step: 1
Training loss: 2.385418776687511
Validation loss: 2.6737499038205432

Epoch: 6| Step: 2
Training loss: 1.6550127122281324
Validation loss: 2.6824311744704845

Epoch: 6| Step: 3
Training loss: 2.711385816282657
Validation loss: 2.647878268555598

Epoch: 6| Step: 4
Training loss: 2.0632581762246365
Validation loss: 2.6347109522439656

Epoch: 6| Step: 5
Training loss: 2.602417035131697
Validation loss: 2.5877741629920856

Epoch: 6| Step: 6
Training loss: 2.2251327475048663
Validation loss: 2.597520049554871

Epoch: 6| Step: 7
Training loss: 2.2811176836493368
Validation loss: 2.5490032247324854

Epoch: 6| Step: 8
Training loss: 2.3842896932437956
Validation loss: 2.5298865771093224

Epoch: 6| Step: 9
Training loss: 2.3590043136731884
Validation loss: 2.554917701609597

Epoch: 6| Step: 10
Training loss: 1.4951316987273418
Validation loss: 2.555420894368267

Epoch: 6| Step: 11
Training loss: 1.9949887795001306
Validation loss: 2.5977190736558122

Epoch: 6| Step: 12
Training loss: 2.3548795807781384
Validation loss: 2.5999393501023214

Epoch: 6| Step: 13
Training loss: 2.188948015790352
Validation loss: 2.623326456131007

Epoch: 176| Step: 0
Training loss: 1.7547992565406492
Validation loss: 2.622640147180153

Epoch: 6| Step: 1
Training loss: 2.212152046386181
Validation loss: 2.5820027249693767

Epoch: 6| Step: 2
Training loss: 2.1881467680514337
Validation loss: 2.580359135820212

Epoch: 6| Step: 3
Training loss: 1.9870479333526199
Validation loss: 2.5787716837250256

Epoch: 6| Step: 4
Training loss: 2.646154989880364
Validation loss: 2.5826706603660763

Epoch: 6| Step: 5
Training loss: 2.707115447261126
Validation loss: 2.5776546085191727

Epoch: 6| Step: 6
Training loss: 2.1518889845039957
Validation loss: 2.553132371265129

Epoch: 6| Step: 7
Training loss: 2.2256520333880507
Validation loss: 2.5415906008818667

Epoch: 6| Step: 8
Training loss: 1.465554352381356
Validation loss: 2.5153959620081126

Epoch: 6| Step: 9
Training loss: 2.664073060314022
Validation loss: 2.4873175174988686

Epoch: 6| Step: 10
Training loss: 2.1513727285873943
Validation loss: 2.4634286122250737

Epoch: 6| Step: 11
Training loss: 2.1713117788570617
Validation loss: 2.494488518755636

Epoch: 6| Step: 12
Training loss: 1.9967822177208268
Validation loss: 2.489943148598223

Epoch: 6| Step: 13
Training loss: 1.7874908206944091
Validation loss: 2.5290315174090083

Epoch: 177| Step: 0
Training loss: 2.5828340006797066
Validation loss: 2.573625045003226

Epoch: 6| Step: 1
Training loss: 2.01898977078118
Validation loss: 2.6070978875082003

Epoch: 6| Step: 2
Training loss: 2.0624509863375957
Validation loss: 2.6250273043398566

Epoch: 6| Step: 3
Training loss: 2.35153877525148
Validation loss: 2.6769322976411916

Epoch: 6| Step: 4
Training loss: 2.17078410682828
Validation loss: 2.6739318688984848

Epoch: 6| Step: 5
Training loss: 2.042183077631557
Validation loss: 2.630813446826765

Epoch: 6| Step: 6
Training loss: 1.72614210715592
Validation loss: 2.6375584648995667

Epoch: 6| Step: 7
Training loss: 2.499622221059886
Validation loss: 2.650381898284899

Epoch: 6| Step: 8
Training loss: 1.9807312921162739
Validation loss: 2.6609691395607102

Epoch: 6| Step: 9
Training loss: 2.4982660002114465
Validation loss: 2.6700292627601345

Epoch: 6| Step: 10
Training loss: 1.6946038377901846
Validation loss: 2.5982937323194917

Epoch: 6| Step: 11
Training loss: 1.9827694141946317
Validation loss: 2.609785548106311

Epoch: 6| Step: 12
Training loss: 2.029211929202907
Validation loss: 2.595244652941917

Epoch: 6| Step: 13
Training loss: 2.4988672551270783
Validation loss: 2.563984146736196

Epoch: 178| Step: 0
Training loss: 2.208175497592464
Validation loss: 2.541470548492746

Epoch: 6| Step: 1
Training loss: 1.5508830231678639
Validation loss: 2.523209471911364

Epoch: 6| Step: 2
Training loss: 1.731326060913778
Validation loss: 2.5135544117951283

Epoch: 6| Step: 3
Training loss: 2.0846487343096882
Validation loss: 2.5312745834852235

Epoch: 6| Step: 4
Training loss: 2.343971547146118
Validation loss: 2.560346020744106

Epoch: 6| Step: 5
Training loss: 2.2005157169681335
Validation loss: 2.5189314050351284

Epoch: 6| Step: 6
Training loss: 2.4273572338799125
Validation loss: 2.51263300658375

Epoch: 6| Step: 7
Training loss: 2.1062717923358556
Validation loss: 2.4829200193247747

Epoch: 6| Step: 8
Training loss: 2.2193325513702935
Validation loss: 2.499576199408845

Epoch: 6| Step: 9
Training loss: 2.232002759624129
Validation loss: 2.4824828056203705

Epoch: 6| Step: 10
Training loss: 2.540892707261937
Validation loss: 2.498789760975407

Epoch: 6| Step: 11
Training loss: 1.9117852814028882
Validation loss: 2.499848863688819

Epoch: 6| Step: 12
Training loss: 1.9112687878779901
Validation loss: 2.51322720727127

Epoch: 6| Step: 13
Training loss: 2.053204135153534
Validation loss: 2.5661598289918612

Epoch: 179| Step: 0
Training loss: 1.808176408571567
Validation loss: 2.610432910995498

Epoch: 6| Step: 1
Training loss: 2.152559965319637
Validation loss: 2.7139301105079885

Epoch: 6| Step: 2
Training loss: 2.1369892067750476
Validation loss: 2.776064041146957

Epoch: 6| Step: 3
Training loss: 2.4619475698706488
Validation loss: 2.7580090570981755

Epoch: 6| Step: 4
Training loss: 2.470797402011814
Validation loss: 2.6741190253472755

Epoch: 6| Step: 5
Training loss: 2.1177424868262507
Validation loss: 2.625725833805629

Epoch: 6| Step: 6
Training loss: 2.207032330267988
Validation loss: 2.552199287785558

Epoch: 6| Step: 7
Training loss: 2.176010914158097
Validation loss: 2.5305718096145906

Epoch: 6| Step: 8
Training loss: 1.9432067504451465
Validation loss: 2.501186309856489

Epoch: 6| Step: 9
Training loss: 1.7188284422573894
Validation loss: 2.4858190552819415

Epoch: 6| Step: 10
Training loss: 2.168149098635981
Validation loss: 2.4758044246825484

Epoch: 6| Step: 11
Training loss: 2.238118909770538
Validation loss: 2.491776028037562

Epoch: 6| Step: 12
Training loss: 1.7246521612888654
Validation loss: 2.553854105030308

Epoch: 6| Step: 13
Training loss: 2.439065186170996
Validation loss: 2.6025373879082347

Epoch: 180| Step: 0
Training loss: 2.0249597427699313
Validation loss: 2.6575164217751146

Epoch: 6| Step: 1
Training loss: 1.9023408674339686
Validation loss: 2.736038985224038

Epoch: 6| Step: 2
Training loss: 2.0099473580066736
Validation loss: 2.766676998217976

Epoch: 6| Step: 3
Training loss: 2.47726161006186
Validation loss: 2.7167985018110334

Epoch: 6| Step: 4
Training loss: 2.0726400858582736
Validation loss: 2.6221279971215816

Epoch: 6| Step: 5
Training loss: 1.8607948075557434
Validation loss: 2.576281263965954

Epoch: 6| Step: 6
Training loss: 2.5304608468865375
Validation loss: 2.5614442688957175

Epoch: 6| Step: 7
Training loss: 2.678926676852805
Validation loss: 2.5347854391356504

Epoch: 6| Step: 8
Training loss: 2.157618212947842
Validation loss: 2.5473876926292385

Epoch: 6| Step: 9
Training loss: 2.0920276674807927
Validation loss: 2.516076180673662

Epoch: 6| Step: 10
Training loss: 1.7827000655243734
Validation loss: 2.534971144627815

Epoch: 6| Step: 11
Training loss: 1.6563497549281778
Validation loss: 2.5394924398675873

Epoch: 6| Step: 12
Training loss: 2.0285022637455934
Validation loss: 2.5593116247266905

Epoch: 6| Step: 13
Training loss: 1.9292834395570098
Validation loss: 2.5462465540764203

Epoch: 181| Step: 0
Training loss: 2.2930384142819236
Validation loss: 2.541846037179965

Epoch: 6| Step: 1
Training loss: 2.1828427464895634
Validation loss: 2.530765532154411

Epoch: 6| Step: 2
Training loss: 1.5129071278833006
Validation loss: 2.5085535496568676

Epoch: 6| Step: 3
Training loss: 2.016262692850818
Validation loss: 2.491995656817905

Epoch: 6| Step: 4
Training loss: 1.5900319430903291
Validation loss: 2.510474472459439

Epoch: 6| Step: 5
Training loss: 1.9180235689801441
Validation loss: 2.5377411403309154

Epoch: 6| Step: 6
Training loss: 2.2605230303466364
Validation loss: 2.5698153157089605

Epoch: 6| Step: 7
Training loss: 2.1936767565897997
Validation loss: 2.616118419024779

Epoch: 6| Step: 8
Training loss: 2.192911919379624
Validation loss: 2.667323043884264

Epoch: 6| Step: 9
Training loss: 2.5365091954535877
Validation loss: 2.71937450515488

Epoch: 6| Step: 10
Training loss: 2.585375768034209
Validation loss: 2.698018789090786

Epoch: 6| Step: 11
Training loss: 2.046117511391358
Validation loss: 2.6210433568530336

Epoch: 6| Step: 12
Training loss: 1.9613833585467069
Validation loss: 2.5583789331027136

Epoch: 6| Step: 13
Training loss: 1.1284566333704753
Validation loss: 2.531574874077187

Epoch: 182| Step: 0
Training loss: 1.5854265865194377
Validation loss: 2.502825048348662

Epoch: 6| Step: 1
Training loss: 2.3333362397675352
Validation loss: 2.495024171594137

Epoch: 6| Step: 2
Training loss: 2.2189272957469868
Validation loss: 2.505844558000504

Epoch: 6| Step: 3
Training loss: 2.4574934823307757
Validation loss: 2.5169043880220507

Epoch: 6| Step: 4
Training loss: 2.1480074365369903
Validation loss: 2.5590235991815886

Epoch: 6| Step: 5
Training loss: 2.155963491672133
Validation loss: 2.5488500978632818

Epoch: 6| Step: 6
Training loss: 2.451946388467526
Validation loss: 2.574698329298701

Epoch: 6| Step: 7
Training loss: 1.903205441433222
Validation loss: 2.598579074429629

Epoch: 6| Step: 8
Training loss: 2.10989396104531
Validation loss: 2.63204658735721

Epoch: 6| Step: 9
Training loss: 1.909095828661009
Validation loss: 2.6379148698487453

Epoch: 6| Step: 10
Training loss: 1.843835861017202
Validation loss: 2.6581242048356883

Epoch: 6| Step: 11
Training loss: 2.0383908857495143
Validation loss: 2.637138498455429

Epoch: 6| Step: 12
Training loss: 1.6701233145590597
Validation loss: 2.603250563083036

Epoch: 6| Step: 13
Training loss: 1.4481531219978767
Validation loss: 2.5663419675409576

Epoch: 183| Step: 0
Training loss: 2.205141375760535
Validation loss: 2.56570868961474

Epoch: 6| Step: 1
Training loss: 2.2781920120995376
Validation loss: 2.55291759089156

Epoch: 6| Step: 2
Training loss: 1.5806978611200226
Validation loss: 2.566335429421897

Epoch: 6| Step: 3
Training loss: 2.3183439490456674
Validation loss: 2.5750621402664504

Epoch: 6| Step: 4
Training loss: 1.8434233295253641
Validation loss: 2.5730471087025126

Epoch: 6| Step: 5
Training loss: 1.5539638042579524
Validation loss: 2.5661888742856034

Epoch: 6| Step: 6
Training loss: 2.490575669780108
Validation loss: 2.6017810350728383

Epoch: 6| Step: 7
Training loss: 1.9761901022166053
Validation loss: 2.6331605123485766

Epoch: 6| Step: 8
Training loss: 2.0524690785094193
Validation loss: 2.6397190985405294

Epoch: 6| Step: 9
Training loss: 2.0507605560711863
Validation loss: 2.639380378987395

Epoch: 6| Step: 10
Training loss: 1.958883904783549
Validation loss: 2.6374772366780386

Epoch: 6| Step: 11
Training loss: 1.6967083506656728
Validation loss: 2.6123657290580145

Epoch: 6| Step: 12
Training loss: 1.9289627258512252
Validation loss: 2.6108977426196356

Epoch: 6| Step: 13
Training loss: 1.8955627779334214
Validation loss: 2.5514967059387383

Epoch: 184| Step: 0
Training loss: 2.186768763802605
Validation loss: 2.546434214970988

Epoch: 6| Step: 1
Training loss: 2.1960834493432833
Validation loss: 2.498704424858718

Epoch: 6| Step: 2
Training loss: 1.870417016597904
Validation loss: 2.5100196722250296

Epoch: 6| Step: 3
Training loss: 1.569792400411406
Validation loss: 2.523028058421351

Epoch: 6| Step: 4
Training loss: 2.4127918837681466
Validation loss: 2.526802520966063

Epoch: 6| Step: 5
Training loss: 2.1413238943770003
Validation loss: 2.543679340859953

Epoch: 6| Step: 6
Training loss: 2.06992448733529
Validation loss: 2.5614213261371397

Epoch: 6| Step: 7
Training loss: 1.531957424005463
Validation loss: 2.5918202056553046

Epoch: 6| Step: 8
Training loss: 2.1763334549486912
Validation loss: 2.629927973190451

Epoch: 6| Step: 9
Training loss: 1.9012791594125786
Validation loss: 2.67924299080841

Epoch: 6| Step: 10
Training loss: 1.3193678777909958
Validation loss: 2.695022899875814

Epoch: 6| Step: 11
Training loss: 1.9834855857346527
Validation loss: 2.7507700844019074

Epoch: 6| Step: 12
Training loss: 2.4167609580049922
Validation loss: 2.701828072112179

Epoch: 6| Step: 13
Training loss: 1.5942044077804518
Validation loss: 2.66353001786881

Epoch: 185| Step: 0
Training loss: 1.511573252218734
Validation loss: 2.6093629047461513

Epoch: 6| Step: 1
Training loss: 1.550760033604081
Validation loss: 2.5761710977988908

Epoch: 6| Step: 2
Training loss: 1.822475605240179
Validation loss: 2.535236324449614

Epoch: 6| Step: 3
Training loss: 2.4268515371111414
Validation loss: 2.4954558399603672

Epoch: 6| Step: 4
Training loss: 1.981531824711622
Validation loss: 2.497461341570952

Epoch: 6| Step: 5
Training loss: 2.0232732404219935
Validation loss: 2.503158840964468

Epoch: 6| Step: 6
Training loss: 1.8784713400389959
Validation loss: 2.489330743521795

Epoch: 6| Step: 7
Training loss: 2.212170583911145
Validation loss: 2.550441825957539

Epoch: 6| Step: 8
Training loss: 2.0142098123613863
Validation loss: 2.5760826893936284

Epoch: 6| Step: 9
Training loss: 1.7924080431133917
Validation loss: 2.610560564844073

Epoch: 6| Step: 10
Training loss: 2.1480788052841397
Validation loss: 2.634413358003075

Epoch: 6| Step: 11
Training loss: 2.2216882726482474
Validation loss: 2.657114200810997

Epoch: 6| Step: 12
Training loss: 1.980912920559693
Validation loss: 2.6610483086859196

Epoch: 6| Step: 13
Training loss: 1.2388226501840403
Validation loss: 2.654897329235777

Epoch: 186| Step: 0
Training loss: 2.3588725180209322
Validation loss: 2.6096678764668404

Epoch: 6| Step: 1
Training loss: 1.8027579821593858
Validation loss: 2.613424437416357

Epoch: 6| Step: 2
Training loss: 2.2813047637636883
Validation loss: 2.5718334824573663

Epoch: 6| Step: 3
Training loss: 1.9838466992333252
Validation loss: 2.5761512188851947

Epoch: 6| Step: 4
Training loss: 2.047402117465699
Validation loss: 2.5738426741826377

Epoch: 6| Step: 5
Training loss: 1.4173745836216447
Validation loss: 2.602864199538732

Epoch: 6| Step: 6
Training loss: 2.191306589617744
Validation loss: 2.60828735249179

Epoch: 6| Step: 7
Training loss: 1.3181326664158592
Validation loss: 2.612792617975331

Epoch: 6| Step: 8
Training loss: 1.3687658735774453
Validation loss: 2.6393942146905056

Epoch: 6| Step: 9
Training loss: 1.8332017360042283
Validation loss: 2.645544786507201

Epoch: 6| Step: 10
Training loss: 1.3412119827499749
Validation loss: 2.632494844271244

Epoch: 6| Step: 11
Training loss: 2.174392996963272
Validation loss: 2.6473182323871294

Epoch: 6| Step: 12
Training loss: 2.300858760234078
Validation loss: 2.6115519006765266

Epoch: 6| Step: 13
Training loss: 2.381061648631753
Validation loss: 2.58854761273801

Epoch: 187| Step: 0
Training loss: 2.0744435678834474
Validation loss: 2.5448055630947457

Epoch: 6| Step: 1
Training loss: 1.83431675573159
Validation loss: 2.514027530528398

Epoch: 6| Step: 2
Training loss: 1.8031726110245037
Validation loss: 2.5048765990829396

Epoch: 6| Step: 3
Training loss: 2.0540256377034387
Validation loss: 2.488499786670541

Epoch: 6| Step: 4
Training loss: 1.6529335069708027
Validation loss: 2.514580810223716

Epoch: 6| Step: 5
Training loss: 2.264355007570871
Validation loss: 2.5364662819334147

Epoch: 6| Step: 6
Training loss: 1.8652909994268252
Validation loss: 2.561593056049612

Epoch: 6| Step: 7
Training loss: 1.6861803051435091
Validation loss: 2.602932712380437

Epoch: 6| Step: 8
Training loss: 1.8466789128600967
Validation loss: 2.576818369378197

Epoch: 6| Step: 9
Training loss: 1.7791006941106948
Validation loss: 2.5952496187200493

Epoch: 6| Step: 10
Training loss: 2.014300717159777
Validation loss: 2.5734884443716557

Epoch: 6| Step: 11
Training loss: 1.7930955364137486
Validation loss: 2.5730893244574884

Epoch: 6| Step: 12
Training loss: 2.1657186292524955
Validation loss: 2.57570555996739

Epoch: 6| Step: 13
Training loss: 1.8216901813023647
Validation loss: 2.6027007185761653

Epoch: 188| Step: 0
Training loss: 1.7196910709355813
Validation loss: 2.6176723334193457

Epoch: 6| Step: 1
Training loss: 2.070929208706948
Validation loss: 2.640876040145798

Epoch: 6| Step: 2
Training loss: 1.5287046491582048
Validation loss: 2.6678629532471536

Epoch: 6| Step: 3
Training loss: 1.3017638564774356
Validation loss: 2.6956579956218256

Epoch: 6| Step: 4
Training loss: 2.032213540060691
Validation loss: 2.715828169113358

Epoch: 6| Step: 5
Training loss: 2.519033362112788
Validation loss: 2.7063367206265374

Epoch: 6| Step: 6
Training loss: 1.5201132476179189
Validation loss: 2.6447940494139686

Epoch: 6| Step: 7
Training loss: 1.9499544578515962
Validation loss: 2.6268960128243988

Epoch: 6| Step: 8
Training loss: 1.8358042567174566
Validation loss: 2.5962098692570903

Epoch: 6| Step: 9
Training loss: 1.528400416605817
Validation loss: 2.5612660800420644

Epoch: 6| Step: 10
Training loss: 2.5637414297688794
Validation loss: 2.5478701992129413

Epoch: 6| Step: 11
Training loss: 1.694470877866811
Validation loss: 2.536893119842191

Epoch: 6| Step: 12
Training loss: 1.731097862637487
Validation loss: 2.528973592772713

Epoch: 6| Step: 13
Training loss: 1.7203865582760318
Validation loss: 2.534609806274213

Epoch: 189| Step: 0
Training loss: 1.5850706691210295
Validation loss: 2.564692833822781

Epoch: 6| Step: 1
Training loss: 1.614696556141217
Validation loss: 2.566498321021928

Epoch: 6| Step: 2
Training loss: 1.9034844019986987
Validation loss: 2.580575605001134

Epoch: 6| Step: 3
Training loss: 1.734516584786075
Validation loss: 2.6180181408050283

Epoch: 6| Step: 4
Training loss: 2.1068664327903885
Validation loss: 2.6430913158877525

Epoch: 6| Step: 5
Training loss: 1.9691736885598874
Validation loss: 2.599749008098039

Epoch: 6| Step: 6
Training loss: 1.5806426559312867
Validation loss: 2.5655475315533245

Epoch: 6| Step: 7
Training loss: 2.1467702604061656
Validation loss: 2.5612871414635543

Epoch: 6| Step: 8
Training loss: 2.2418752845017416
Validation loss: 2.555963356259171

Epoch: 6| Step: 9
Training loss: 1.8314752121272946
Validation loss: 2.542494347769189

Epoch: 6| Step: 10
Training loss: 1.816870714096615
Validation loss: 2.525520070077394

Epoch: 6| Step: 11
Training loss: 1.8797849634640011
Validation loss: 2.5345553399151184

Epoch: 6| Step: 12
Training loss: 1.6766704343269339
Validation loss: 2.5570833726889304

Epoch: 6| Step: 13
Training loss: 1.9826130892234266
Validation loss: 2.5600914439393923

Epoch: 190| Step: 0
Training loss: 1.357118026427368
Validation loss: 2.6322768820310793

Epoch: 6| Step: 1
Training loss: 1.7662118932199808
Validation loss: 2.6380988888153447

Epoch: 6| Step: 2
Training loss: 1.868499933052419
Validation loss: 2.7060229143489263

Epoch: 6| Step: 3
Training loss: 1.87472913692966
Validation loss: 2.719492340297376

Epoch: 6| Step: 4
Training loss: 1.541289523964508
Validation loss: 2.744790072636292

Epoch: 6| Step: 5
Training loss: 1.9747773201870005
Validation loss: 2.72408310501245

Epoch: 6| Step: 6
Training loss: 1.6395122569220195
Validation loss: 2.7267942627734336

Epoch: 6| Step: 7
Training loss: 1.3412656662622422
Validation loss: 2.7091738621605668

Epoch: 6| Step: 8
Training loss: 1.8158312471940041
Validation loss: 2.638609870950964

Epoch: 6| Step: 9
Training loss: 1.8592474116299282
Validation loss: 2.5676530158414548

Epoch: 6| Step: 10
Training loss: 2.681465826706983
Validation loss: 2.5222357636489163

Epoch: 6| Step: 11
Training loss: 1.9921095290539828
Validation loss: 2.5058335579867466

Epoch: 6| Step: 12
Training loss: 1.877994942882745
Validation loss: 2.4949600814035104

Epoch: 6| Step: 13
Training loss: 2.0777971970007116
Validation loss: 2.524383967841376

Epoch: 191| Step: 0
Training loss: 2.0009025682923873
Validation loss: 2.5442294194259034

Epoch: 6| Step: 1
Training loss: 1.4581314310454447
Validation loss: 2.5145018397672074

Epoch: 6| Step: 2
Training loss: 1.7363375308422475
Validation loss: 2.5669975798846445

Epoch: 6| Step: 3
Training loss: 1.3375497202678253
Validation loss: 2.5782042450470466

Epoch: 6| Step: 4
Training loss: 1.8980586925954395
Validation loss: 2.646697197822205

Epoch: 6| Step: 5
Training loss: 1.643499490192962
Validation loss: 2.66451638059926

Epoch: 6| Step: 6
Training loss: 1.8930470738913245
Validation loss: 2.646370433474642

Epoch: 6| Step: 7
Training loss: 1.9445952046698625
Validation loss: 2.6277854309974216

Epoch: 6| Step: 8
Training loss: 2.0144035719390665
Validation loss: 2.6021152579076112

Epoch: 6| Step: 9
Training loss: 1.8726189435760725
Validation loss: 2.5554827579736807

Epoch: 6| Step: 10
Training loss: 1.624677332607651
Validation loss: 2.5382381714677016

Epoch: 6| Step: 11
Training loss: 1.8446790003463605
Validation loss: 2.554242601654183

Epoch: 6| Step: 12
Training loss: 1.9989544996814896
Validation loss: 2.5469216204634857

Epoch: 6| Step: 13
Training loss: 2.2417766978925693
Validation loss: 2.5596617951157845

Epoch: 192| Step: 0
Training loss: 1.9579418142711211
Validation loss: 2.5489979742488487

Epoch: 6| Step: 1
Training loss: 2.076155338598303
Validation loss: 2.554099910592872

Epoch: 6| Step: 2
Training loss: 1.6018211341996422
Validation loss: 2.5837889374428586

Epoch: 6| Step: 3
Training loss: 1.3720341687855087
Validation loss: 2.5883341809440354

Epoch: 6| Step: 4
Training loss: 1.9747878238326555
Validation loss: 2.5879108793302286

Epoch: 6| Step: 5
Training loss: 1.5418433612226194
Validation loss: 2.6522998988929136

Epoch: 6| Step: 6
Training loss: 1.684709006971645
Validation loss: 2.646543483242816

Epoch: 6| Step: 7
Training loss: 1.295119602763168
Validation loss: 2.6762408333782552

Epoch: 6| Step: 8
Training loss: 2.192419569221385
Validation loss: 2.6610008755103434

Epoch: 6| Step: 9
Training loss: 1.8120069161929417
Validation loss: 2.6193275749240064

Epoch: 6| Step: 10
Training loss: 2.176557364803481
Validation loss: 2.589782457738936

Epoch: 6| Step: 11
Training loss: 1.9360752404622494
Validation loss: 2.568630176249814

Epoch: 6| Step: 12
Training loss: 1.5937285328335555
Validation loss: 2.5477435842041127

Epoch: 6| Step: 13
Training loss: 1.8057212346022589
Validation loss: 2.5355405187771933

Epoch: 193| Step: 0
Training loss: 1.932596832060248
Validation loss: 2.5140968949721514

Epoch: 6| Step: 1
Training loss: 1.8115756867886097
Validation loss: 2.5369017892793306

Epoch: 6| Step: 2
Training loss: 2.0058493906457935
Validation loss: 2.5260017218485142

Epoch: 6| Step: 3
Training loss: 2.01452535751642
Validation loss: 2.5204644780387175

Epoch: 6| Step: 4
Training loss: 1.4404936591991626
Validation loss: 2.5572800973219034

Epoch: 6| Step: 5
Training loss: 1.8894403702875395
Validation loss: 2.574235652202279

Epoch: 6| Step: 6
Training loss: 1.8387289050958373
Validation loss: 2.6182402857531404

Epoch: 6| Step: 7
Training loss: 2.1794052761678095
Validation loss: 2.636897329270955

Epoch: 6| Step: 8
Training loss: 1.8160032420024417
Validation loss: 2.6404425542289527

Epoch: 6| Step: 9
Training loss: 1.591161832921511
Validation loss: 2.6555168438163874

Epoch: 6| Step: 10
Training loss: 1.5031677811020667
Validation loss: 2.6031396671001077

Epoch: 6| Step: 11
Training loss: 1.8307878060714697
Validation loss: 2.5969255945660685

Epoch: 6| Step: 12
Training loss: 1.5501677022471898
Validation loss: 2.5689210017285022

Epoch: 6| Step: 13
Training loss: 0.972713453456802
Validation loss: 2.5461071635340895

Epoch: 194| Step: 0
Training loss: 1.5831900414661093
Validation loss: 2.536619781418318

Epoch: 6| Step: 1
Training loss: 2.207988808105963
Validation loss: 2.52785445993286

Epoch: 6| Step: 2
Training loss: 1.8874366294883844
Validation loss: 2.532743133358018

Epoch: 6| Step: 3
Training loss: 1.6711613210291612
Validation loss: 2.5641209487555696

Epoch: 6| Step: 4
Training loss: 1.6228466438331857
Validation loss: 2.6146825227322483

Epoch: 6| Step: 5
Training loss: 1.4149405772264463
Validation loss: 2.6136164308713883

Epoch: 6| Step: 6
Training loss: 1.5724745712286239
Validation loss: 2.6758202008863816

Epoch: 6| Step: 7
Training loss: 1.881259008240281
Validation loss: 2.682806663084707

Epoch: 6| Step: 8
Training loss: 1.9785400871127823
Validation loss: 2.708413923845643

Epoch: 6| Step: 9
Training loss: 1.7620159837298741
Validation loss: 2.703959664132287

Epoch: 6| Step: 10
Training loss: 1.6560098006055213
Validation loss: 2.7008928107297625

Epoch: 6| Step: 11
Training loss: 1.5077573143540166
Validation loss: 2.6729168561626633

Epoch: 6| Step: 12
Training loss: 1.8429049478817077
Validation loss: 2.6172807309854296

Epoch: 6| Step: 13
Training loss: 1.8651832453725181
Validation loss: 2.589413206456446

Epoch: 195| Step: 0
Training loss: 1.2058347926277095
Validation loss: 2.588801244539071

Epoch: 6| Step: 1
Training loss: 1.7820282290114067
Validation loss: 2.5657916403574985

Epoch: 6| Step: 2
Training loss: 1.799457584882867
Validation loss: 2.5816569318931872

Epoch: 6| Step: 3
Training loss: 2.269565286561684
Validation loss: 2.587747330447114

Epoch: 6| Step: 4
Training loss: 1.3855287415721602
Validation loss: 2.576856155868011

Epoch: 6| Step: 5
Training loss: 1.5261533346971006
Validation loss: 2.590888233502866

Epoch: 6| Step: 6
Training loss: 1.8995076997324263
Validation loss: 2.620186074995071

Epoch: 6| Step: 7
Training loss: 1.8095172147582879
Validation loss: 2.6567945970445477

Epoch: 6| Step: 8
Training loss: 1.2722987600807265
Validation loss: 2.6709487730625527

Epoch: 6| Step: 9
Training loss: 1.4946395938445063
Validation loss: 2.6622749461119715

Epoch: 6| Step: 10
Training loss: 1.3481961702918006
Validation loss: 2.6629490806153626

Epoch: 6| Step: 11
Training loss: 2.0589261157659604
Validation loss: 2.6545675316692763

Epoch: 6| Step: 12
Training loss: 2.271331020961279
Validation loss: 2.6492127093971374

Epoch: 6| Step: 13
Training loss: 1.6425837858014078
Validation loss: 2.5957683741233954

Epoch: 196| Step: 0
Training loss: 1.7005129741430618
Validation loss: 2.5990246521750358

Epoch: 6| Step: 1
Training loss: 1.4949328348133328
Validation loss: 2.567243413192886

Epoch: 6| Step: 2
Training loss: 1.2986705254184752
Validation loss: 2.536923361184165

Epoch: 6| Step: 3
Training loss: 1.5504496721983263
Validation loss: 2.560923469807994

Epoch: 6| Step: 4
Training loss: 1.7233141553218727
Validation loss: 2.556272770683731

Epoch: 6| Step: 5
Training loss: 1.4318074835615682
Validation loss: 2.5754273362377393

Epoch: 6| Step: 6
Training loss: 1.4665045923212503
Validation loss: 2.5516837360754785

Epoch: 6| Step: 7
Training loss: 2.0779856011237863
Validation loss: 2.5965360466547622

Epoch: 6| Step: 8
Training loss: 1.6291476649406336
Validation loss: 2.6639579993270295

Epoch: 6| Step: 9
Training loss: 1.560399130844504
Validation loss: 2.6859711240073696

Epoch: 6| Step: 10
Training loss: 1.9754119057213422
Validation loss: 2.7075451697171804

Epoch: 6| Step: 11
Training loss: 1.429703592512104
Validation loss: 2.7260179376326263

Epoch: 6| Step: 12
Training loss: 2.5568711400568214
Validation loss: 2.7419850217674107

Epoch: 6| Step: 13
Training loss: 2.1738473183606297
Validation loss: 2.7145321841700993

Epoch: 197| Step: 0
Training loss: 1.1262764576843072
Validation loss: 2.640311182515808

Epoch: 6| Step: 1
Training loss: 1.7136235164430276
Validation loss: 2.597035177457491

Epoch: 6| Step: 2
Training loss: 1.8471283430688925
Validation loss: 2.5384440628250933

Epoch: 6| Step: 3
Training loss: 1.5267634155123777
Validation loss: 2.5288395638519736

Epoch: 6| Step: 4
Training loss: 1.8377474040901907
Validation loss: 2.4914155800305

Epoch: 6| Step: 5
Training loss: 1.4762650447534278
Validation loss: 2.4780229298428895

Epoch: 6| Step: 6
Training loss: 2.0475353311510918
Validation loss: 2.4965126068361534

Epoch: 6| Step: 7
Training loss: 1.8479569494880703
Validation loss: 2.506666569069411

Epoch: 6| Step: 8
Training loss: 1.4305326538145715
Validation loss: 2.565923359955216

Epoch: 6| Step: 9
Training loss: 1.8099800218354234
Validation loss: 2.5925035631046134

Epoch: 6| Step: 10
Training loss: 1.6995006809710231
Validation loss: 2.609071638896903

Epoch: 6| Step: 11
Training loss: 1.6083203906525116
Validation loss: 2.6335526105859

Epoch: 6| Step: 12
Training loss: 1.948819901324194
Validation loss: 2.6266142954518474

Epoch: 6| Step: 13
Training loss: 2.146733721619732
Validation loss: 2.598712308198243

Epoch: 198| Step: 0
Training loss: 1.4326513035410402
Validation loss: 2.602752963037941

Epoch: 6| Step: 1
Training loss: 1.663813755983406
Validation loss: 2.5873367682136537

Epoch: 6| Step: 2
Training loss: 1.5367782604522704
Validation loss: 2.6006650541088527

Epoch: 6| Step: 3
Training loss: 1.5701895138989133
Validation loss: 2.5745271240378003

Epoch: 6| Step: 4
Training loss: 1.8929335946326709
Validation loss: 2.55678940091508

Epoch: 6| Step: 5
Training loss: 1.914429360868595
Validation loss: 2.54784706127368

Epoch: 6| Step: 6
Training loss: 2.021505014802542
Validation loss: 2.5624526084761436

Epoch: 6| Step: 7
Training loss: 1.3092964676861425
Validation loss: 2.578112146588525

Epoch: 6| Step: 8
Training loss: 1.6344261409424174
Validation loss: 2.578098957008538

Epoch: 6| Step: 9
Training loss: 1.5818743592633624
Validation loss: 2.593649224602944

Epoch: 6| Step: 10
Training loss: 1.7282826412103245
Validation loss: 2.6340189264693437

Epoch: 6| Step: 11
Training loss: 1.7554825324284422
Validation loss: 2.654613711357743

Epoch: 6| Step: 12
Training loss: 1.7419912458653133
Validation loss: 2.6872307093273275

Epoch: 6| Step: 13
Training loss: 1.4393474483130653
Validation loss: 2.7094961606033188

Epoch: 199| Step: 0
Training loss: 1.4207990998351192
Validation loss: 2.692876211275742

Epoch: 6| Step: 1
Training loss: 1.7030839827611692
Validation loss: 2.6918543572608384

Epoch: 6| Step: 2
Training loss: 1.4495868061254704
Validation loss: 2.69503862637118

Epoch: 6| Step: 3
Training loss: 1.7468271102209656
Validation loss: 2.6739240080697515

Epoch: 6| Step: 4
Training loss: 2.215412046800634
Validation loss: 2.653562724146131

Epoch: 6| Step: 5
Training loss: 1.8083578989965003
Validation loss: 2.608168332504542

Epoch: 6| Step: 6
Training loss: 1.7660567844372768
Validation loss: 2.5895750384332827

Epoch: 6| Step: 7
Training loss: 1.6556753925216172
Validation loss: 2.608827636323903

Epoch: 6| Step: 8
Training loss: 1.6023031615534085
Validation loss: 2.5756816095701156

Epoch: 6| Step: 9
Training loss: 1.213437852252808
Validation loss: 2.596072253869293

Epoch: 6| Step: 10
Training loss: 1.8596679713140984
Validation loss: 2.537094230221101

Epoch: 6| Step: 11
Training loss: 1.6906645031613328
Validation loss: 2.5514519565710554

Epoch: 6| Step: 12
Training loss: 1.2918777703494047
Validation loss: 2.5647590817765797

Epoch: 6| Step: 13
Training loss: 1.611269752138699
Validation loss: 2.584226875173482

Epoch: 200| Step: 0
Training loss: 1.3906296719247584
Validation loss: 2.6174024875323587

Epoch: 6| Step: 1
Training loss: 1.8634088180665807
Validation loss: 2.6426268502302084

Epoch: 6| Step: 2
Training loss: 1.7057054202535598
Validation loss: 2.662081874152565

Epoch: 6| Step: 3
Training loss: 1.0973554857558832
Validation loss: 2.67696064381845

Epoch: 6| Step: 4
Training loss: 2.1982425128761975
Validation loss: 2.6694307217656723

Epoch: 6| Step: 5
Training loss: 1.320883633029884
Validation loss: 2.634283504493896

Epoch: 6| Step: 6
Training loss: 1.3022415166773706
Validation loss: 2.570147302603021

Epoch: 6| Step: 7
Training loss: 1.6233191967504648
Validation loss: 2.544255365753406

Epoch: 6| Step: 8
Training loss: 1.7883130631923072
Validation loss: 2.503689085742854

Epoch: 6| Step: 9
Training loss: 2.001227240733839
Validation loss: 2.545679579506657

Epoch: 6| Step: 10
Training loss: 1.8198534341631272
Validation loss: 2.566734325085579

Epoch: 6| Step: 11
Training loss: 1.579354741850053
Validation loss: 2.5657327341056186

Epoch: 6| Step: 12
Training loss: 1.1326898968877566
Validation loss: 2.6054027824711308

Epoch: 6| Step: 13
Training loss: 1.969872956705816
Validation loss: 2.613621399017182

Epoch: 201| Step: 0
Training loss: 1.183444375662099
Validation loss: 2.637665415933677

Epoch: 6| Step: 1
Training loss: 1.7038872789029071
Validation loss: 2.674395446268968

Epoch: 6| Step: 2
Training loss: 1.4562632809798761
Validation loss: 2.6756925983322746

Epoch: 6| Step: 3
Training loss: 1.789387769157212
Validation loss: 2.694526332048841

Epoch: 6| Step: 4
Training loss: 1.4712477203844117
Validation loss: 2.666210026508276

Epoch: 6| Step: 5
Training loss: 1.328227947957439
Validation loss: 2.670861375821573

Epoch: 6| Step: 6
Training loss: 1.8520745321893566
Validation loss: 2.6282352935265663

Epoch: 6| Step: 7
Training loss: 1.1028921340809918
Validation loss: 2.5996010034421015

Epoch: 6| Step: 8
Training loss: 1.70105849018487
Validation loss: 2.555718190343252

Epoch: 6| Step: 9
Training loss: 1.8220137476229699
Validation loss: 2.5725913365009765

Epoch: 6| Step: 10
Training loss: 1.9652682807012927
Validation loss: 2.5609041822928806

Epoch: 6| Step: 11
Training loss: 2.077961965490031
Validation loss: 2.5577582229930353

Epoch: 6| Step: 12
Training loss: 1.0764942828574522
Validation loss: 2.5896800756993423

Epoch: 6| Step: 13
Training loss: 2.05908544701593
Validation loss: 2.5807780020117352

Epoch: 202| Step: 0
Training loss: 1.0134394090642131
Validation loss: 2.6194859038426475

Epoch: 6| Step: 1
Training loss: 1.2567749957149972
Validation loss: 2.622214144296905

Epoch: 6| Step: 2
Training loss: 1.85099751669018
Validation loss: 2.6731222839877966

Epoch: 6| Step: 3
Training loss: 1.6564887252640388
Validation loss: 2.6791540651926598

Epoch: 6| Step: 4
Training loss: 1.4530675733150296
Validation loss: 2.6693473786134354

Epoch: 6| Step: 5
Training loss: 1.4983689659444595
Validation loss: 2.691408233163202

Epoch: 6| Step: 6
Training loss: 1.7571261952326875
Validation loss: 2.6778344693876814

Epoch: 6| Step: 7
Training loss: 1.8005584115530122
Validation loss: 2.6513220419611643

Epoch: 6| Step: 8
Training loss: 1.8258862603561719
Validation loss: 2.602594485954178

Epoch: 6| Step: 9
Training loss: 1.8167889591783584
Validation loss: 2.5757259101153975

Epoch: 6| Step: 10
Training loss: 1.5656246984789894
Validation loss: 2.556688996622175

Epoch: 6| Step: 11
Training loss: 1.3658173589293998
Validation loss: 2.5550938117855693

Epoch: 6| Step: 12
Training loss: 1.6589580924528047
Validation loss: 2.556343747186616

Epoch: 6| Step: 13
Training loss: 1.9723472428730993
Validation loss: 2.5543342238943194

Epoch: 203| Step: 0
Training loss: 1.843505261228755
Validation loss: 2.555781700823656

Epoch: 6| Step: 1
Training loss: 1.3544877869769
Validation loss: 2.5361132757970486

Epoch: 6| Step: 2
Training loss: 1.5202708663022817
Validation loss: 2.5349167133385446

Epoch: 6| Step: 3
Training loss: 1.4232668928292673
Validation loss: 2.529126705682391

Epoch: 6| Step: 4
Training loss: 1.0933530904760325
Validation loss: 2.517600005547908

Epoch: 6| Step: 5
Training loss: 1.709011300011113
Validation loss: 2.5125774694849894

Epoch: 6| Step: 6
Training loss: 1.49014981931131
Validation loss: 2.5262556290956413

Epoch: 6| Step: 7
Training loss: 1.4232862406823334
Validation loss: 2.545077256832124

Epoch: 6| Step: 8
Training loss: 1.8934302837550998
Validation loss: 2.5746485425592924

Epoch: 6| Step: 9
Training loss: 1.6750444691007358
Validation loss: 2.6212116314772316

Epoch: 6| Step: 10
Training loss: 2.0658507438727205
Validation loss: 2.6198825194553153

Epoch: 6| Step: 11
Training loss: 1.4776851685186976
Validation loss: 2.6366140217037723

Epoch: 6| Step: 12
Training loss: 1.4958620215651695
Validation loss: 2.657031476701503

Epoch: 6| Step: 13
Training loss: 1.784885644749137
Validation loss: 2.654422919671437

Epoch: 204| Step: 0
Training loss: 1.4861402756313953
Validation loss: 2.6679498491077305

Epoch: 6| Step: 1
Training loss: 1.502653715042875
Validation loss: 2.6656255561170106

Epoch: 6| Step: 2
Training loss: 1.4452095613680154
Validation loss: 2.6773933552575393

Epoch: 6| Step: 3
Training loss: 1.3621274771333967
Validation loss: 2.6753719626695656

Epoch: 6| Step: 4
Training loss: 1.7676697090828184
Validation loss: 2.64704480743558

Epoch: 6| Step: 5
Training loss: 1.6921863474890393
Validation loss: 2.673231627579228

Epoch: 6| Step: 6
Training loss: 1.2738194741122322
Validation loss: 2.637703692419524

Epoch: 6| Step: 7
Training loss: 1.579868826189405
Validation loss: 2.60465518594195

Epoch: 6| Step: 8
Training loss: 1.627272996907287
Validation loss: 2.609174794767052

Epoch: 6| Step: 9
Training loss: 2.142257624729783
Validation loss: 2.601370691591374

Epoch: 6| Step: 10
Training loss: 1.4137844845101613
Validation loss: 2.615538443532343

Epoch: 6| Step: 11
Training loss: 1.3814763656096685
Validation loss: 2.5784957842848306

Epoch: 6| Step: 12
Training loss: 1.736147138433694
Validation loss: 2.571116811610673

Epoch: 6| Step: 13
Training loss: 1.1187684403929614
Validation loss: 2.5520524934500406

Epoch: 205| Step: 0
Training loss: 1.3945665542023198
Validation loss: 2.5329654420270464

Epoch: 6| Step: 1
Training loss: 2.2094544737684174
Validation loss: 2.551460634816576

Epoch: 6| Step: 2
Training loss: 1.1941122873404857
Validation loss: 2.5580136483558817

Epoch: 6| Step: 3
Training loss: 1.7577259635817286
Validation loss: 2.5518716867937488

Epoch: 6| Step: 4
Training loss: 1.8127908144506875
Validation loss: 2.5600804056338213

Epoch: 6| Step: 5
Training loss: 1.5510410504396477
Validation loss: 2.5950284817405995

Epoch: 6| Step: 6
Training loss: 1.4127393401605637
Validation loss: 2.628202694694342

Epoch: 6| Step: 7
Training loss: 1.0161844326700082
Validation loss: 2.647502902090349

Epoch: 6| Step: 8
Training loss: 2.166802939995681
Validation loss: 2.652145864296656

Epoch: 6| Step: 9
Training loss: 1.5060972429114896
Validation loss: 2.6295954222967874

Epoch: 6| Step: 10
Training loss: 0.9686261682428258
Validation loss: 2.602843013594993

Epoch: 6| Step: 11
Training loss: 1.2644617834021596
Validation loss: 2.588365510974908

Epoch: 6| Step: 12
Training loss: 1.2619328272938328
Validation loss: 2.58791147271255

Epoch: 6| Step: 13
Training loss: 1.4561837111681295
Validation loss: 2.521495623952007

Epoch: 206| Step: 0
Training loss: 1.3866627856499818
Validation loss: 2.5682461334358897

Epoch: 6| Step: 1
Training loss: 1.6706352985377193
Validation loss: 2.5383145137876695

Epoch: 6| Step: 2
Training loss: 1.7196008136964742
Validation loss: 2.557365346412344

Epoch: 6| Step: 3
Training loss: 1.180337587816625
Validation loss: 2.5700920881458917

Epoch: 6| Step: 4
Training loss: 1.4509778310185093
Validation loss: 2.593737566004242

Epoch: 6| Step: 5
Training loss: 1.580274949233959
Validation loss: 2.593152719345073

Epoch: 6| Step: 6
Training loss: 1.3818685035777154
Validation loss: 2.628339866524826

Epoch: 6| Step: 7
Training loss: 1.229204915416037
Validation loss: 2.6443934619275082

Epoch: 6| Step: 8
Training loss: 1.951534019977087
Validation loss: 2.64687899357644

Epoch: 6| Step: 9
Training loss: 1.431270535917254
Validation loss: 2.628642843321444

Epoch: 6| Step: 10
Training loss: 1.0618957596535157
Validation loss: 2.637178347694675

Epoch: 6| Step: 11
Training loss: 1.2537732395440968
Validation loss: 2.641114569809691

Epoch: 6| Step: 12
Training loss: 1.8940646826022345
Validation loss: 2.6476161713054363

Epoch: 6| Step: 13
Training loss: 2.105234221523088
Validation loss: 2.633217854717706

Epoch: 207| Step: 0
Training loss: 1.5797160975191038
Validation loss: 2.6443523563925937

Epoch: 6| Step: 1
Training loss: 1.375174294608972
Validation loss: 2.601138549108471

Epoch: 6| Step: 2
Training loss: 2.0088786697244987
Validation loss: 2.615204101089272

Epoch: 6| Step: 3
Training loss: 1.91842894461974
Validation loss: 2.608774784353522

Epoch: 6| Step: 4
Training loss: 1.3369766120405748
Validation loss: 2.620621303351688

Epoch: 6| Step: 5
Training loss: 1.0546300801788588
Validation loss: 2.597039778518932

Epoch: 6| Step: 6
Training loss: 1.1520991178860336
Validation loss: 2.5995032428725273

Epoch: 6| Step: 7
Training loss: 1.2655818131225187
Validation loss: 2.6205563091198054

Epoch: 6| Step: 8
Training loss: 1.2531810814539628
Validation loss: 2.5854031963439885

Epoch: 6| Step: 9
Training loss: 1.3607176365505365
Validation loss: 2.6031092476049023

Epoch: 6| Step: 10
Training loss: 0.7860856510018864
Validation loss: 2.6059849418946945

Epoch: 6| Step: 11
Training loss: 2.077387399204123
Validation loss: 2.6235577830193075

Epoch: 6| Step: 12
Training loss: 1.6196004953040235
Validation loss: 2.598021047733799

Epoch: 6| Step: 13
Training loss: 1.5709826809069911
Validation loss: 2.579244921912825

Epoch: 208| Step: 0
Training loss: 1.7172324677151456
Validation loss: 2.575213907621818

Epoch: 6| Step: 1
Training loss: 1.7986426905048956
Validation loss: 2.6116335887266855

Epoch: 6| Step: 2
Training loss: 1.6294109193905404
Validation loss: 2.6329872655388478

Epoch: 6| Step: 3
Training loss: 1.4014035954547555
Validation loss: 2.679612525721748

Epoch: 6| Step: 4
Training loss: 1.343759581065952
Validation loss: 2.66848868439183

Epoch: 6| Step: 5
Training loss: 1.0555503424019381
Validation loss: 2.686306619073385

Epoch: 6| Step: 6
Training loss: 1.7181509187643789
Validation loss: 2.647916711099339

Epoch: 6| Step: 7
Training loss: 1.7395002912546886
Validation loss: 2.6604905466466326

Epoch: 6| Step: 8
Training loss: 1.2082547896716678
Validation loss: 2.6170909106461173

Epoch: 6| Step: 9
Training loss: 1.015783326939465
Validation loss: 2.580775598080354

Epoch: 6| Step: 10
Training loss: 1.452900530797817
Validation loss: 2.5926678225162525

Epoch: 6| Step: 11
Training loss: 1.5787088050813725
Validation loss: 2.604400306967586

Epoch: 6| Step: 12
Training loss: 1.4896911190846045
Validation loss: 2.613226046332364

Epoch: 6| Step: 13
Training loss: 1.3023799202420852
Validation loss: 2.6132993455461406

Epoch: 209| Step: 0
Training loss: 1.0591590751317863
Validation loss: 2.6378294754865568

Epoch: 6| Step: 1
Training loss: 1.170134612596636
Validation loss: 2.630961762355671

Epoch: 6| Step: 2
Training loss: 1.3549508636264644
Validation loss: 2.6843956142512972

Epoch: 6| Step: 3
Training loss: 1.6894731641694491
Validation loss: 2.6725069920239375

Epoch: 6| Step: 4
Training loss: 0.9870963853193478
Validation loss: 2.679943870216222

Epoch: 6| Step: 5
Training loss: 1.1331619249945906
Validation loss: 2.6451729830616757

Epoch: 6| Step: 6
Training loss: 1.7254136349761104
Validation loss: 2.625383693781742

Epoch: 6| Step: 7
Training loss: 1.8277088571957387
Validation loss: 2.6112383592043606

Epoch: 6| Step: 8
Training loss: 1.7988454215246403
Validation loss: 2.614452593298503

Epoch: 6| Step: 9
Training loss: 1.6724990678222977
Validation loss: 2.587431166933491

Epoch: 6| Step: 10
Training loss: 1.9280256149917223
Validation loss: 2.5617754932707766

Epoch: 6| Step: 11
Training loss: 0.9056273985436731
Validation loss: 2.579312381414907

Epoch: 6| Step: 12
Training loss: 1.290577731987241
Validation loss: 2.5962278556891474

Epoch: 6| Step: 13
Training loss: 1.5212276766164898
Validation loss: 2.5921601197802873

Epoch: 210| Step: 0
Training loss: 1.0559562680985983
Validation loss: 2.6261293645055677

Epoch: 6| Step: 1
Training loss: 1.4280301686527486
Validation loss: 2.5970328971601275

Epoch: 6| Step: 2
Training loss: 1.6093250748381092
Validation loss: 2.6378824333979374

Epoch: 6| Step: 3
Training loss: 2.1206818632084836
Validation loss: 2.6553749655489796

Epoch: 6| Step: 4
Training loss: 1.0903655959693221
Validation loss: 2.6107719689941495

Epoch: 6| Step: 5
Training loss: 1.5469039760149117
Validation loss: 2.5936599460807113

Epoch: 6| Step: 6
Training loss: 1.311593105712552
Validation loss: 2.561649996895904

Epoch: 6| Step: 7
Training loss: 1.635788974377523
Validation loss: 2.562926802368673

Epoch: 6| Step: 8
Training loss: 1.1414779191490236
Validation loss: 2.515426263058845

Epoch: 6| Step: 9
Training loss: 1.4610585861209113
Validation loss: 2.5306845341893034

Epoch: 6| Step: 10
Training loss: 1.3831009213798984
Validation loss: 2.5209031169537384

Epoch: 6| Step: 11
Training loss: 1.4019908407839945
Validation loss: 2.5640709796305954

Epoch: 6| Step: 12
Training loss: 1.4983968114648918
Validation loss: 2.5539093337675016

Epoch: 6| Step: 13
Training loss: 1.6272439868398036
Validation loss: 2.637497117990073

Epoch: 211| Step: 0
Training loss: 1.7543491407553593
Validation loss: 2.6609191084995545

Epoch: 6| Step: 1
Training loss: 1.249770334126044
Validation loss: 2.6769239907245788

Epoch: 6| Step: 2
Training loss: 1.3432073606407555
Validation loss: 2.6680646187983403

Epoch: 6| Step: 3
Training loss: 1.1936563225384682
Validation loss: 2.6785436201629738

Epoch: 6| Step: 4
Training loss: 2.125465117770205
Validation loss: 2.6547397825105

Epoch: 6| Step: 5
Training loss: 1.0771243662491983
Validation loss: 2.6380290152670436

Epoch: 6| Step: 6
Training loss: 1.6862888935147968
Validation loss: 2.6442276185109654

Epoch: 6| Step: 7
Training loss: 1.029039035764769
Validation loss: 2.5777945457422797

Epoch: 6| Step: 8
Training loss: 1.7922113019564951
Validation loss: 2.6029122055991123

Epoch: 6| Step: 9
Training loss: 1.2259711522664696
Validation loss: 2.577778257617592

Epoch: 6| Step: 10
Training loss: 1.3899645147665391
Validation loss: 2.564963906234951

Epoch: 6| Step: 11
Training loss: 1.5317882448218771
Validation loss: 2.535582596648268

Epoch: 6| Step: 12
Training loss: 1.3111149882584339
Validation loss: 2.5732662811493183

Epoch: 6| Step: 13
Training loss: 1.7382455200637943
Validation loss: 2.5519002708557355

Epoch: 212| Step: 0
Training loss: 1.216110991387971
Validation loss: 2.567342696743586

Epoch: 6| Step: 1
Training loss: 1.1745371779545597
Validation loss: 2.570001959372434

Epoch: 6| Step: 2
Training loss: 1.820768896689689
Validation loss: 2.585853538863988

Epoch: 6| Step: 3
Training loss: 1.4571233725380397
Validation loss: 2.6115920097734695

Epoch: 6| Step: 4
Training loss: 1.4138080515524452
Validation loss: 2.6172096806166203

Epoch: 6| Step: 5
Training loss: 1.7064363678257548
Validation loss: 2.608213128062231

Epoch: 6| Step: 6
Training loss: 1.466764853543198
Validation loss: 2.5755996482181467

Epoch: 6| Step: 7
Training loss: 1.5173982295140498
Validation loss: 2.5183546578370066

Epoch: 6| Step: 8
Training loss: 1.100580900869548
Validation loss: 2.4842765294823757

Epoch: 6| Step: 9
Training loss: 1.5699148101533777
Validation loss: 2.4669166368094153

Epoch: 6| Step: 10
Training loss: 1.3259861497227607
Validation loss: 2.4554768403986675

Epoch: 6| Step: 11
Training loss: 1.9187448955057942
Validation loss: 2.465634085925976

Epoch: 6| Step: 12
Training loss: 1.3503626971988696
Validation loss: 2.491884544192533

Epoch: 6| Step: 13
Training loss: 1.3596693136883522
Validation loss: 2.5230064937076553

Epoch: 213| Step: 0
Training loss: 0.9269330549418394
Validation loss: 2.6132802572232694

Epoch: 6| Step: 1
Training loss: 1.430390732209053
Validation loss: 2.706911095704317

Epoch: 6| Step: 2
Training loss: 1.6845363447662325
Validation loss: 2.7352380443557247

Epoch: 6| Step: 3
Training loss: 1.6520982203668704
Validation loss: 2.6885829002031154

Epoch: 6| Step: 4
Training loss: 1.5353460995293426
Validation loss: 2.6647209768530113

Epoch: 6| Step: 5
Training loss: 1.6747629054782769
Validation loss: 2.6097514427673203

Epoch: 6| Step: 6
Training loss: 1.257890876555342
Validation loss: 2.505111172261941

Epoch: 6| Step: 7
Training loss: 0.9929627821268002
Validation loss: 2.4990279635768955

Epoch: 6| Step: 8
Training loss: 1.8292222601828454
Validation loss: 2.475783584567687

Epoch: 6| Step: 9
Training loss: 1.6227474739831973
Validation loss: 2.4662082828501752

Epoch: 6| Step: 10
Training loss: 1.5739055160994888
Validation loss: 2.455206700566276

Epoch: 6| Step: 11
Training loss: 1.0776859992944403
Validation loss: 2.44783553122323

Epoch: 6| Step: 12
Training loss: 1.3799668250726487
Validation loss: 2.473683165881292

Epoch: 6| Step: 13
Training loss: 1.6273616355759208
Validation loss: 2.4625659352673046

Epoch: 214| Step: 0
Training loss: 1.5896518600845098
Validation loss: 2.5301191942995294

Epoch: 6| Step: 1
Training loss: 1.3899413582212103
Validation loss: 2.5789990904454148

Epoch: 6| Step: 2
Training loss: 1.2535949510751405
Validation loss: 2.6397577288582266

Epoch: 6| Step: 3
Training loss: 1.0783287629782876
Validation loss: 2.6808279291814596

Epoch: 6| Step: 4
Training loss: 2.052079086170223
Validation loss: 2.6829321050797823

Epoch: 6| Step: 5
Training loss: 1.6686561472357089
Validation loss: 2.6596181864813957

Epoch: 6| Step: 6
Training loss: 1.460917916396149
Validation loss: 2.637664375962495

Epoch: 6| Step: 7
Training loss: 1.2985413198818945
Validation loss: 2.601495472605855

Epoch: 6| Step: 8
Training loss: 1.0591685856387334
Validation loss: 2.5609976974061612

Epoch: 6| Step: 9
Training loss: 1.4626317119791588
Validation loss: 2.5593389086536456

Epoch: 6| Step: 10
Training loss: 1.4477414727280176
Validation loss: 2.558120556782231

Epoch: 6| Step: 11
Training loss: 0.9547540469786803
Validation loss: 2.5252708552140577

Epoch: 6| Step: 12
Training loss: 1.551389637332843
Validation loss: 2.56099028225092

Epoch: 6| Step: 13
Training loss: 1.6517604943784026
Validation loss: 2.5862791834912517

Epoch: 215| Step: 0
Training loss: 1.4328190427940684
Validation loss: 2.61626496111645

Epoch: 6| Step: 1
Training loss: 1.271539596085089
Validation loss: 2.6196553628189516

Epoch: 6| Step: 2
Training loss: 1.5531312447312995
Validation loss: 2.595759493401888

Epoch: 6| Step: 3
Training loss: 1.331208274079936
Validation loss: 2.58697345463408

Epoch: 6| Step: 4
Training loss: 1.287115858232439
Validation loss: 2.565272622297479

Epoch: 6| Step: 5
Training loss: 1.2042342682884535
Validation loss: 2.558899321348799

Epoch: 6| Step: 6
Training loss: 1.199215071980058
Validation loss: 2.5580692036934702

Epoch: 6| Step: 7
Training loss: 1.4721660253407571
Validation loss: 2.594808084690523

Epoch: 6| Step: 8
Training loss: 1.1411955986970304
Validation loss: 2.5791720891941203

Epoch: 6| Step: 9
Training loss: 0.821926092147995
Validation loss: 2.6100304983586664

Epoch: 6| Step: 10
Training loss: 1.6506368419564759
Validation loss: 2.6127892485737343

Epoch: 6| Step: 11
Training loss: 1.620807815520864
Validation loss: 2.6101316499933103

Epoch: 6| Step: 12
Training loss: 1.8752588093475318
Validation loss: 2.6138870265782996

Epoch: 6| Step: 13
Training loss: 1.4817128452246526
Validation loss: 2.590666698510762

Epoch: 216| Step: 0
Training loss: 1.2500198362683903
Validation loss: 2.5632968867043533

Epoch: 6| Step: 1
Training loss: 1.3233837995026736
Validation loss: 2.5400739888031336

Epoch: 6| Step: 2
Training loss: 1.573714864276499
Validation loss: 2.5110111910357773

Epoch: 6| Step: 3
Training loss: 1.436560282179602
Validation loss: 2.5243086818928044

Epoch: 6| Step: 4
Training loss: 1.388226015004308
Validation loss: 2.5279542743109467

Epoch: 6| Step: 5
Training loss: 1.428139437345822
Validation loss: 2.538491241584296

Epoch: 6| Step: 6
Training loss: 1.4906835516540307
Validation loss: 2.5657275283485714

Epoch: 6| Step: 7
Training loss: 1.351960845634241
Validation loss: 2.615075148517518

Epoch: 6| Step: 8
Training loss: 1.823491149479208
Validation loss: 2.6494866140674223

Epoch: 6| Step: 9
Training loss: 1.1156928995450657
Validation loss: 2.6915793626421163

Epoch: 6| Step: 10
Training loss: 1.5964467289917008
Validation loss: 2.664104568755058

Epoch: 6| Step: 11
Training loss: 1.309227087001386
Validation loss: 2.6184554409144534

Epoch: 6| Step: 12
Training loss: 0.784455931238406
Validation loss: 2.6358862195984227

Epoch: 6| Step: 13
Training loss: 1.069741869655522
Validation loss: 2.6156231101606258

Epoch: 217| Step: 0
Training loss: 1.1019739775795856
Validation loss: 2.61763374443646

Epoch: 6| Step: 1
Training loss: 1.1836345401193726
Validation loss: 2.590674038125568

Epoch: 6| Step: 2
Training loss: 1.9581647624518115
Validation loss: 2.609956748327274

Epoch: 6| Step: 3
Training loss: 1.4956603854337749
Validation loss: 2.6076174731597916

Epoch: 6| Step: 4
Training loss: 0.9508133042009328
Validation loss: 2.5948827715968714

Epoch: 6| Step: 5
Training loss: 1.5337151128132396
Validation loss: 2.617708703617277

Epoch: 6| Step: 6
Training loss: 1.5132570941279169
Validation loss: 2.6155053590737625

Epoch: 6| Step: 7
Training loss: 1.3381958550656523
Validation loss: 2.6111561526704103

Epoch: 6| Step: 8
Training loss: 1.2467752823118288
Validation loss: 2.5915719138581803

Epoch: 6| Step: 9
Training loss: 1.6041249686762609
Validation loss: 2.610338172439223

Epoch: 6| Step: 10
Training loss: 1.0996935525929772
Validation loss: 2.592698299257841

Epoch: 6| Step: 11
Training loss: 1.3282462120842191
Validation loss: 2.6295075275581308

Epoch: 6| Step: 12
Training loss: 0.9730505699354024
Validation loss: 2.617915513581837

Epoch: 6| Step: 13
Training loss: 1.579626294619033
Validation loss: 2.608629217987964

Epoch: 218| Step: 0
Training loss: 1.4741455965637058
Validation loss: 2.60435883696932

Epoch: 6| Step: 1
Training loss: 1.5951623829183685
Validation loss: 2.582931698378787

Epoch: 6| Step: 2
Training loss: 0.9941857708046431
Validation loss: 2.512041275888025

Epoch: 6| Step: 3
Training loss: 1.4935483469179358
Validation loss: 2.5091911469544175

Epoch: 6| Step: 4
Training loss: 1.4808141461476212
Validation loss: 2.4949947530303422

Epoch: 6| Step: 5
Training loss: 1.2751559966154515
Validation loss: 2.51711812258335

Epoch: 6| Step: 6
Training loss: 0.8963587720724214
Validation loss: 2.54081515191773

Epoch: 6| Step: 7
Training loss: 1.301985266489323
Validation loss: 2.5309045126171283

Epoch: 6| Step: 8
Training loss: 1.1100436599839745
Validation loss: 2.570783822060244

Epoch: 6| Step: 9
Training loss: 1.3137839259041928
Validation loss: 2.55710787674814

Epoch: 6| Step: 10
Training loss: 1.4489048209091275
Validation loss: 2.5951011796356562

Epoch: 6| Step: 11
Training loss: 1.9438599828287575
Validation loss: 2.569219256060435

Epoch: 6| Step: 12
Training loss: 1.0274883792155085
Validation loss: 2.59886955023931

Epoch: 6| Step: 13
Training loss: 0.6749516063579228
Validation loss: 2.6114298801843705

Epoch: 219| Step: 0
Training loss: 1.277251353990573
Validation loss: 2.642197261927695

Epoch: 6| Step: 1
Training loss: 1.3904756615849863
Validation loss: 2.623048958714064

Epoch: 6| Step: 2
Training loss: 1.4990646306941842
Validation loss: 2.6321073123064065

Epoch: 6| Step: 3
Training loss: 0.8355149243823605
Validation loss: 2.6508548618456267

Epoch: 6| Step: 4
Training loss: 1.189986486758914
Validation loss: 2.674277842316184

Epoch: 6| Step: 5
Training loss: 1.6824848390890923
Validation loss: 2.6414111722436675

Epoch: 6| Step: 6
Training loss: 1.6921139969717047
Validation loss: 2.5604395642531617

Epoch: 6| Step: 7
Training loss: 1.6661995789553576
Validation loss: 2.5726714844194984

Epoch: 6| Step: 8
Training loss: 1.1503216086443864
Validation loss: 2.5448144090708866

Epoch: 6| Step: 9
Training loss: 1.1563190233403187
Validation loss: 2.567532925982615

Epoch: 6| Step: 10
Training loss: 1.3593277320097845
Validation loss: 2.5849128043434955

Epoch: 6| Step: 11
Training loss: 1.3460329756077076
Validation loss: 2.595753731583004

Epoch: 6| Step: 12
Training loss: 1.1707327807453514
Validation loss: 2.5953508426583727

Epoch: 6| Step: 13
Training loss: 0.9252419812489644
Validation loss: 2.5894920545748037

Epoch: 220| Step: 0
Training loss: 1.429802478273426
Validation loss: 2.6352251751689963

Epoch: 6| Step: 1
Training loss: 1.9410006984137527
Validation loss: 2.6673336412678688

Epoch: 6| Step: 2
Training loss: 1.0284963314044748
Validation loss: 2.6604350448092977

Epoch: 6| Step: 3
Training loss: 1.3028830196101227
Validation loss: 2.6297351448469595

Epoch: 6| Step: 4
Training loss: 0.9713035583948545
Validation loss: 2.5812509319583117

Epoch: 6| Step: 5
Training loss: 0.9507625568592846
Validation loss: 2.528466258097775

Epoch: 6| Step: 6
Training loss: 0.6938554735166159
Validation loss: 2.51328903842158

Epoch: 6| Step: 7
Training loss: 1.596946204104099
Validation loss: 2.482021241206586

Epoch: 6| Step: 8
Training loss: 1.5550801917002248
Validation loss: 2.4971576093603387

Epoch: 6| Step: 9
Training loss: 1.2975056505172085
Validation loss: 2.497256956304865

Epoch: 6| Step: 10
Training loss: 1.7144838272582374
Validation loss: 2.5087580855306038

Epoch: 6| Step: 11
Training loss: 1.231904079765614
Validation loss: 2.5391175663406154

Epoch: 6| Step: 12
Training loss: 1.1691425255920276
Validation loss: 2.6038701324627618

Epoch: 6| Step: 13
Training loss: 1.4474874267295592
Validation loss: 2.6362887551986836

Epoch: 221| Step: 0
Training loss: 1.4831705929210195
Validation loss: 2.652570154312084

Epoch: 6| Step: 1
Training loss: 1.4772955472557447
Validation loss: 2.724580607146779

Epoch: 6| Step: 2
Training loss: 1.0973100761190822
Validation loss: 2.6967922871554726

Epoch: 6| Step: 3
Training loss: 1.2180351704122028
Validation loss: 2.6910499846440668

Epoch: 6| Step: 4
Training loss: 1.499325282619014
Validation loss: 2.6639946200658806

Epoch: 6| Step: 5
Training loss: 1.3063141966746188
Validation loss: 2.6311488447513294

Epoch: 6| Step: 6
Training loss: 0.5531807973703672
Validation loss: 2.5923422491933397

Epoch: 6| Step: 7
Training loss: 2.0663107145035258
Validation loss: 2.586758671472622

Epoch: 6| Step: 8
Training loss: 1.0584468387701975
Validation loss: 2.525494132258614

Epoch: 6| Step: 9
Training loss: 1.132694264522704
Validation loss: 2.5296674769746805

Epoch: 6| Step: 10
Training loss: 1.3043304685806048
Validation loss: 2.5129222236952575

Epoch: 6| Step: 11
Training loss: 1.0206595422116955
Validation loss: 2.5228756433680766

Epoch: 6| Step: 12
Training loss: 1.2794414875325606
Validation loss: 2.512783724929898

Epoch: 6| Step: 13
Training loss: 1.2573320407068587
Validation loss: 2.5072804284180146

Epoch: 222| Step: 0
Training loss: 1.3804731678743594
Validation loss: 2.5591059651970474

Epoch: 6| Step: 1
Training loss: 1.143608893356621
Validation loss: 2.545120181289719

Epoch: 6| Step: 2
Training loss: 1.394989793118015
Validation loss: 2.571470909523737

Epoch: 6| Step: 3
Training loss: 1.336738480155338
Validation loss: 2.6066192267833608

Epoch: 6| Step: 4
Training loss: 1.663162632874456
Validation loss: 2.5903563534040304

Epoch: 6| Step: 5
Training loss: 0.7229250846028225
Validation loss: 2.623181382579945

Epoch: 6| Step: 6
Training loss: 1.7664974386508143
Validation loss: 2.6294061945750435

Epoch: 6| Step: 7
Training loss: 1.3139202063557909
Validation loss: 2.6338149081596867

Epoch: 6| Step: 8
Training loss: 1.067720546497492
Validation loss: 2.6053542771719274

Epoch: 6| Step: 9
Training loss: 1.179888221893767
Validation loss: 2.546313560835836

Epoch: 6| Step: 10
Training loss: 1.0770820880835963
Validation loss: 2.5107521153327905

Epoch: 6| Step: 11
Training loss: 1.1870588185778443
Validation loss: 2.531107649502866

Epoch: 6| Step: 12
Training loss: 1.245805713045448
Validation loss: 2.5279971508012276

Epoch: 6| Step: 13
Training loss: 1.418553759745153
Validation loss: 2.531396951464772

Epoch: 223| Step: 0
Training loss: 1.0419603251740228
Validation loss: 2.554186952044634

Epoch: 6| Step: 1
Training loss: 1.200351838348922
Validation loss: 2.618647785068112

Epoch: 6| Step: 2
Training loss: 1.58933274213302
Validation loss: 2.5880177374664615

Epoch: 6| Step: 3
Training loss: 2.0596501862623438
Validation loss: 2.6152497789464646

Epoch: 6| Step: 4
Training loss: 1.044638222671308
Validation loss: 2.6613522583456204

Epoch: 6| Step: 5
Training loss: 1.3305247449039637
Validation loss: 2.6692139046773797

Epoch: 6| Step: 6
Training loss: 1.3650335292401088
Validation loss: 2.6507444825377973

Epoch: 6| Step: 7
Training loss: 0.9902657648713002
Validation loss: 2.6294745706000713

Epoch: 6| Step: 8
Training loss: 1.4079661599828528
Validation loss: 2.592357083075526

Epoch: 6| Step: 9
Training loss: 1.0532463117055468
Validation loss: 2.5904066566994977

Epoch: 6| Step: 10
Training loss: 1.1181524417723112
Validation loss: 2.5634511727493288

Epoch: 6| Step: 11
Training loss: 0.9149029120544528
Validation loss: 2.5608134928861075

Epoch: 6| Step: 12
Training loss: 0.9834492281058972
Validation loss: 2.602324332629238

Epoch: 6| Step: 13
Training loss: 1.527123632935787
Validation loss: 2.60940139007536

Epoch: 224| Step: 0
Training loss: 1.1586770540257616
Validation loss: 2.605470597849991

Epoch: 6| Step: 1
Training loss: 0.9964967996801425
Validation loss: 2.600401820250758

Epoch: 6| Step: 2
Training loss: 1.1063878851698266
Validation loss: 2.5820802649164625

Epoch: 6| Step: 3
Training loss: 1.0704348417654355
Validation loss: 2.578403284610241

Epoch: 6| Step: 4
Training loss: 1.3270272598916284
Validation loss: 2.6110997352128287

Epoch: 6| Step: 5
Training loss: 1.1591508921233893
Validation loss: 2.5682059068859915

Epoch: 6| Step: 6
Training loss: 1.2223023703816103
Validation loss: 2.5536358154305443

Epoch: 6| Step: 7
Training loss: 1.623022783929209
Validation loss: 2.586808428299687

Epoch: 6| Step: 8
Training loss: 1.0698679536822968
Validation loss: 2.5605749327060523

Epoch: 6| Step: 9
Training loss: 1.7474579740827254
Validation loss: 2.5157824541987295

Epoch: 6| Step: 10
Training loss: 1.382363284147525
Validation loss: 2.538727953810212

Epoch: 6| Step: 11
Training loss: 0.9861073464036695
Validation loss: 2.5326057549656973

Epoch: 6| Step: 12
Training loss: 1.29124007820387
Validation loss: 2.5609184074374625

Epoch: 6| Step: 13
Training loss: 1.41659193215804
Validation loss: 2.5905528343454116

Epoch: 225| Step: 0
Training loss: 1.7824946288125543
Validation loss: 2.675003437633834

Epoch: 6| Step: 1
Training loss: 1.4912333208863653
Validation loss: 2.6451143879137478

Epoch: 6| Step: 2
Training loss: 1.2199252892897456
Validation loss: 2.6886482237455143

Epoch: 6| Step: 3
Training loss: 0.9371094207954475
Validation loss: 2.6533155413953655

Epoch: 6| Step: 4
Training loss: 0.9576934080777522
Validation loss: 2.647466908273774

Epoch: 6| Step: 5
Training loss: 1.054868555422888
Validation loss: 2.567444536657448

Epoch: 6| Step: 6
Training loss: 1.508754218726909
Validation loss: 2.58628175081886

Epoch: 6| Step: 7
Training loss: 1.285182871441362
Validation loss: 2.5482720688474747

Epoch: 6| Step: 8
Training loss: 1.4034181692133756
Validation loss: 2.550076757422295

Epoch: 6| Step: 9
Training loss: 1.5090398191199916
Validation loss: 2.5540450638912593

Epoch: 6| Step: 10
Training loss: 0.7921980321059888
Validation loss: 2.5631599896932427

Epoch: 6| Step: 11
Training loss: 1.0423014931625714
Validation loss: 2.586369710483034

Epoch: 6| Step: 12
Training loss: 0.9250352002225082
Validation loss: 2.5812095995479094

Epoch: 6| Step: 13
Training loss: 1.2446918314504762
Validation loss: 2.6054175370736585

Epoch: 226| Step: 0
Training loss: 1.149687210335971
Validation loss: 2.5955696192301994

Epoch: 6| Step: 1
Training loss: 0.9260658438365311
Validation loss: 2.6368884879001646

Epoch: 6| Step: 2
Training loss: 0.9224026996192566
Validation loss: 2.6519691799283236

Epoch: 6| Step: 3
Training loss: 1.5331153407144422
Validation loss: 2.6645006841836474

Epoch: 6| Step: 4
Training loss: 1.240550083617743
Validation loss: 2.65773987942967

Epoch: 6| Step: 5
Training loss: 0.996432497355691
Validation loss: 2.6368096550843103

Epoch: 6| Step: 6
Training loss: 0.7051049224748777
Validation loss: 2.657380153062123

Epoch: 6| Step: 7
Training loss: 1.6175268434540533
Validation loss: 2.621389424657914

Epoch: 6| Step: 8
Training loss: 1.521004793439205
Validation loss: 2.6287687478660295

Epoch: 6| Step: 9
Training loss: 1.27378437957937
Validation loss: 2.6228285097914474

Epoch: 6| Step: 10
Training loss: 0.9311967348060353
Validation loss: 2.596567924416371

Epoch: 6| Step: 11
Training loss: 1.374861016618662
Validation loss: 2.603256803654522

Epoch: 6| Step: 12
Training loss: 1.376771176268331
Validation loss: 2.5949631814112872

Epoch: 6| Step: 13
Training loss: 1.1856205774364525
Validation loss: 2.540476293482301

Epoch: 227| Step: 0
Training loss: 1.2190229648182485
Validation loss: 2.5638196654991203

Epoch: 6| Step: 1
Training loss: 1.3280741064754817
Validation loss: 2.5902578312113915

Epoch: 6| Step: 2
Training loss: 1.1971930377606093
Validation loss: 2.5866235384941634

Epoch: 6| Step: 3
Training loss: 1.3792077618303085
Validation loss: 2.5651748246890245

Epoch: 6| Step: 4
Training loss: 1.0413140590237744
Validation loss: 2.5891726990234525

Epoch: 6| Step: 5
Training loss: 1.6771298119716982
Validation loss: 2.659444817215968

Epoch: 6| Step: 6
Training loss: 1.1776877120407068
Validation loss: 2.6317243674428537

Epoch: 6| Step: 7
Training loss: 0.7368139389532704
Validation loss: 2.600112772736896

Epoch: 6| Step: 8
Training loss: 0.8437439600410443
Validation loss: 2.627275959840456

Epoch: 6| Step: 9
Training loss: 0.7975450578355772
Validation loss: 2.6131722542043088

Epoch: 6| Step: 10
Training loss: 1.2187119502461317
Validation loss: 2.628983418275049

Epoch: 6| Step: 11
Training loss: 1.2580102800576929
Validation loss: 2.6387253396676886

Epoch: 6| Step: 12
Training loss: 1.3015164883507442
Validation loss: 2.584920346748236

Epoch: 6| Step: 13
Training loss: 1.623353637644051
Validation loss: 2.5926427146803577

Epoch: 228| Step: 0
Training loss: 0.9100091512450473
Validation loss: 2.5756456531987832

Epoch: 6| Step: 1
Training loss: 0.9927597198048931
Validation loss: 2.5874700210734516

Epoch: 6| Step: 2
Training loss: 1.231739175509318
Validation loss: 2.58321164552786

Epoch: 6| Step: 3
Training loss: 1.3220122191719998
Validation loss: 2.5586741329849545

Epoch: 6| Step: 4
Training loss: 1.2832091170218975
Validation loss: 2.5753342445497664

Epoch: 6| Step: 5
Training loss: 0.9939856867536833
Validation loss: 2.5818881063634818

Epoch: 6| Step: 6
Training loss: 1.352428357382759
Validation loss: 2.590012245263303

Epoch: 6| Step: 7
Training loss: 1.3819778854737204
Validation loss: 2.5977182170426163

Epoch: 6| Step: 8
Training loss: 1.1469774891640676
Validation loss: 2.6138723786307096

Epoch: 6| Step: 9
Training loss: 1.1420942276262593
Validation loss: 2.6295843121046443

Epoch: 6| Step: 10
Training loss: 1.1469059287741943
Validation loss: 2.642117582281348

Epoch: 6| Step: 11
Training loss: 0.9275049829477706
Validation loss: 2.6145275779877757

Epoch: 6| Step: 12
Training loss: 1.262353695994226
Validation loss: 2.598250382913108

Epoch: 6| Step: 13
Training loss: 1.8194289785153275
Validation loss: 2.5886933798972263

Epoch: 229| Step: 0
Training loss: 1.0369683293699634
Validation loss: 2.591098783035673

Epoch: 6| Step: 1
Training loss: 1.7074335876775253
Validation loss: 2.5520948043542004

Epoch: 6| Step: 2
Training loss: 0.7908830319643835
Validation loss: 2.540081244491861

Epoch: 6| Step: 3
Training loss: 0.9049663660743924
Validation loss: 2.558573694439373

Epoch: 6| Step: 4
Training loss: 1.636414128545632
Validation loss: 2.5741040865609355

Epoch: 6| Step: 5
Training loss: 1.1381582472510237
Validation loss: 2.560721762085691

Epoch: 6| Step: 6
Training loss: 0.9437746196339742
Validation loss: 2.5552372700417005

Epoch: 6| Step: 7
Training loss: 1.3703723977024291
Validation loss: 2.613721191519295

Epoch: 6| Step: 8
Training loss: 1.1687916692149658
Validation loss: 2.568387687730114

Epoch: 6| Step: 9
Training loss: 1.1830415350264407
Validation loss: 2.595861418397045

Epoch: 6| Step: 10
Training loss: 1.2221330979874787
Validation loss: 2.6298916520779856

Epoch: 6| Step: 11
Training loss: 1.267680911935442
Validation loss: 2.6069288355979072

Epoch: 6| Step: 12
Training loss: 0.5885681607744951
Validation loss: 2.6475244239723925

Epoch: 6| Step: 13
Training loss: 1.0939285677510473
Validation loss: 2.6167278338555926

Epoch: 230| Step: 0
Training loss: 0.825731092245193
Validation loss: 2.6439093290498703

Epoch: 6| Step: 1
Training loss: 0.5792934878064431
Validation loss: 2.6617437519110525

Epoch: 6| Step: 2
Training loss: 1.6468614031177917
Validation loss: 2.652252743258695

Epoch: 6| Step: 3
Training loss: 1.6592496662975835
Validation loss: 2.640642150912526

Epoch: 6| Step: 4
Training loss: 0.9108188820193044
Validation loss: 2.6023256369475765

Epoch: 6| Step: 5
Training loss: 1.6846082423266087
Validation loss: 2.561526442980332

Epoch: 6| Step: 6
Training loss: 0.9755694413723582
Validation loss: 2.5857756624486146

Epoch: 6| Step: 7
Training loss: 1.3196743658858872
Validation loss: 2.544589407889419

Epoch: 6| Step: 8
Training loss: 0.9893620427645322
Validation loss: 2.5520019595290737

Epoch: 6| Step: 9
Training loss: 0.9710626070855216
Validation loss: 2.5730016142265137

Epoch: 6| Step: 10
Training loss: 1.0755294848718349
Validation loss: 2.587785815273687

Epoch: 6| Step: 11
Training loss: 1.1630262332329082
Validation loss: 2.5677594310812504

Epoch: 6| Step: 12
Training loss: 1.1402223477279774
Validation loss: 2.5712244504509214

Epoch: 6| Step: 13
Training loss: 1.0088007613294907
Validation loss: 2.6086649909687605

Epoch: 231| Step: 0
Training loss: 1.1420962108028485
Validation loss: 2.5964931368932027

Epoch: 6| Step: 1
Training loss: 1.013067164338152
Validation loss: 2.6345943520321304

Epoch: 6| Step: 2
Training loss: 1.5470773583805435
Validation loss: 2.600603569342234

Epoch: 6| Step: 3
Training loss: 0.9878647420380278
Validation loss: 2.6121550790618073

Epoch: 6| Step: 4
Training loss: 1.1988115644507489
Validation loss: 2.5587845885894245

Epoch: 6| Step: 5
Training loss: 0.6633063555348141
Validation loss: 2.556515017953367

Epoch: 6| Step: 6
Training loss: 1.0873314123910494
Validation loss: 2.558649396944859

Epoch: 6| Step: 7
Training loss: 1.397044334986054
Validation loss: 2.5883621246320483

Epoch: 6| Step: 8
Training loss: 1.2713209477884673
Validation loss: 2.5881105700606954

Epoch: 6| Step: 9
Training loss: 1.2676854257177805
Validation loss: 2.637385610022375

Epoch: 6| Step: 10
Training loss: 0.9062333269887501
Validation loss: 2.6420413924364534

Epoch: 6| Step: 11
Training loss: 0.7744577402735245
Validation loss: 2.599338012939019

Epoch: 6| Step: 12
Training loss: 1.4137254597821642
Validation loss: 2.655859570217664

Epoch: 6| Step: 13
Training loss: 1.433037174293715
Validation loss: 2.640448931179413

Epoch: 232| Step: 0
Training loss: 1.0887629574553201
Validation loss: 2.6533744433566677

Epoch: 6| Step: 1
Training loss: 1.2628795846302525
Validation loss: 2.6330010876136494

Epoch: 6| Step: 2
Training loss: 1.224047031299978
Validation loss: 2.61103352997475

Epoch: 6| Step: 3
Training loss: 0.6776097427674334
Validation loss: 2.5912826867193783

Epoch: 6| Step: 4
Training loss: 0.6947013655225611
Validation loss: 2.5938090349682716

Epoch: 6| Step: 5
Training loss: 1.1907271654244973
Validation loss: 2.590997640340164

Epoch: 6| Step: 6
Training loss: 0.9988853978224632
Validation loss: 2.5965708063986948

Epoch: 6| Step: 7
Training loss: 1.6410418026404159
Validation loss: 2.5823677628943726

Epoch: 6| Step: 8
Training loss: 0.9705300742928121
Validation loss: 2.5800592623735423

Epoch: 6| Step: 9
Training loss: 1.2107967171817633
Validation loss: 2.5740468664651086

Epoch: 6| Step: 10
Training loss: 1.3237604569120258
Validation loss: 2.540606064775014

Epoch: 6| Step: 11
Training loss: 0.842883265335265
Validation loss: 2.540208478592769

Epoch: 6| Step: 12
Training loss: 1.4612561862576394
Validation loss: 2.5227861670243503

Epoch: 6| Step: 13
Training loss: 1.367863645932975
Validation loss: 2.5650336452892826

Epoch: 233| Step: 0
Training loss: 1.5867386471558735
Validation loss: 2.5324671371406273

Epoch: 6| Step: 1
Training loss: 1.1210412202550744
Validation loss: 2.54102103877269

Epoch: 6| Step: 2
Training loss: 0.7862038526956411
Validation loss: 2.5427267592896503

Epoch: 6| Step: 3
Training loss: 1.118258623014447
Validation loss: 2.531049123126266

Epoch: 6| Step: 4
Training loss: 0.8222458354534812
Validation loss: 2.5971246405309953

Epoch: 6| Step: 5
Training loss: 1.4670140172994683
Validation loss: 2.6108783107452473

Epoch: 6| Step: 6
Training loss: 1.397671665641845
Validation loss: 2.625569002094615

Epoch: 6| Step: 7
Training loss: 0.9303077103578326
Validation loss: 2.6474903961561798

Epoch: 6| Step: 8
Training loss: 1.0760834202354401
Validation loss: 2.5970458464585557

Epoch: 6| Step: 9
Training loss: 0.4558778865295017
Validation loss: 2.5936278833235753

Epoch: 6| Step: 10
Training loss: 0.7939513183967181
Validation loss: 2.6018957252121675

Epoch: 6| Step: 11
Training loss: 1.6527387719489195
Validation loss: 2.623057474851874

Epoch: 6| Step: 12
Training loss: 1.383915606670916
Validation loss: 2.6251889877144086

Epoch: 6| Step: 13
Training loss: 0.6934746659828321
Validation loss: 2.6124734671022

Epoch: 234| Step: 0
Training loss: 1.0012382946687475
Validation loss: 2.6394965327304907

Epoch: 6| Step: 1
Training loss: 1.0138579622252044
Validation loss: 2.611999847961988

Epoch: 6| Step: 2
Training loss: 1.0724289844360932
Validation loss: 2.627764765973245

Epoch: 6| Step: 3
Training loss: 1.1781613412609795
Validation loss: 2.6288018789714362

Epoch: 6| Step: 4
Training loss: 1.3879225542822935
Validation loss: 2.563367971250294

Epoch: 6| Step: 5
Training loss: 1.2700404627804618
Validation loss: 2.556782161557945

Epoch: 6| Step: 6
Training loss: 1.1850219268218816
Validation loss: 2.5630675036851795

Epoch: 6| Step: 7
Training loss: 1.044640676149134
Validation loss: 2.583513480530012

Epoch: 6| Step: 8
Training loss: 0.9772693669763421
Validation loss: 2.5683236754614347

Epoch: 6| Step: 9
Training loss: 0.892231212286697
Validation loss: 2.558982601017357

Epoch: 6| Step: 10
Training loss: 1.2627189144280084
Validation loss: 2.5936391682968933

Epoch: 6| Step: 11
Training loss: 0.9684642247183559
Validation loss: 2.594829219655168

Epoch: 6| Step: 12
Training loss: 1.229091879083498
Validation loss: 2.6153850923551323

Epoch: 6| Step: 13
Training loss: 1.504673670371447
Validation loss: 2.635178512700478

Epoch: 235| Step: 0
Training loss: 1.0621647025229395
Validation loss: 2.6085536706333325

Epoch: 6| Step: 1
Training loss: 1.0228130969247728
Validation loss: 2.6051394388582283

Epoch: 6| Step: 2
Training loss: 0.7722736425760232
Validation loss: 2.64343474844605

Epoch: 6| Step: 3
Training loss: 1.4248400782477073
Validation loss: 2.634193201757067

Epoch: 6| Step: 4
Training loss: 1.3631151857857973
Validation loss: 2.6178346688718

Epoch: 6| Step: 5
Training loss: 1.0813094944103776
Validation loss: 2.5998963200064527

Epoch: 6| Step: 6
Training loss: 1.1058093513431437
Validation loss: 2.547446765457964

Epoch: 6| Step: 7
Training loss: 1.0206938797553573
Validation loss: 2.579743634854642

Epoch: 6| Step: 8
Training loss: 1.1802519401626461
Validation loss: 2.5651230821317568

Epoch: 6| Step: 9
Training loss: 0.847149816313087
Validation loss: 2.5672020929287647

Epoch: 6| Step: 10
Training loss: 1.4304140673216617
Validation loss: 2.5554560809446936

Epoch: 6| Step: 11
Training loss: 0.9253632128782966
Validation loss: 2.576997989793238

Epoch: 6| Step: 12
Training loss: 1.0167506508976372
Validation loss: 2.601894506399216

Epoch: 6| Step: 13
Training loss: 1.4208212500512398
Validation loss: 2.62237111994519

Epoch: 236| Step: 0
Training loss: 1.3935436095964953
Validation loss: 2.6271228859095817

Epoch: 6| Step: 1
Training loss: 0.8770462360525528
Validation loss: 2.6310235734529415

Epoch: 6| Step: 2
Training loss: 0.9998716033523042
Validation loss: 2.6269588174120506

Epoch: 6| Step: 3
Training loss: 1.2839433227698196
Validation loss: 2.6007507953887536

Epoch: 6| Step: 4
Training loss: 0.9065823767612265
Validation loss: 2.636159080620641

Epoch: 6| Step: 5
Training loss: 0.8453840045689114
Validation loss: 2.647027352254094

Epoch: 6| Step: 6
Training loss: 1.0078159894069618
Validation loss: 2.643297360991983

Epoch: 6| Step: 7
Training loss: 1.240288103997357
Validation loss: 2.609777556933046

Epoch: 6| Step: 8
Training loss: 1.0501699832290161
Validation loss: 2.6389240996194476

Epoch: 6| Step: 9
Training loss: 1.2283625423956104
Validation loss: 2.630072819839287

Epoch: 6| Step: 10
Training loss: 0.7606274343183645
Validation loss: 2.6164862383677487

Epoch: 6| Step: 11
Training loss: 0.8893777915069028
Validation loss: 2.5914537950604

Epoch: 6| Step: 12
Training loss: 1.5912756318022965
Validation loss: 2.61604598473312

Epoch: 6| Step: 13
Training loss: 1.303671709820649
Validation loss: 2.5887784451996545

Epoch: 237| Step: 0
Training loss: 1.214492796222026
Validation loss: 2.638366899710658

Epoch: 6| Step: 1
Training loss: 1.2867676624296187
Validation loss: 2.6212040908050125

Epoch: 6| Step: 2
Training loss: 0.8734063212881162
Validation loss: 2.6195496288910065

Epoch: 6| Step: 3
Training loss: 1.3065110671242193
Validation loss: 2.592603214238577

Epoch: 6| Step: 4
Training loss: 1.005690477135073
Validation loss: 2.5980229887031574

Epoch: 6| Step: 5
Training loss: 1.1828466896749656
Validation loss: 2.5828987639942045

Epoch: 6| Step: 6
Training loss: 1.093701933758287
Validation loss: 2.576153375360673

Epoch: 6| Step: 7
Training loss: 1.2743130347886755
Validation loss: 2.548295677267019

Epoch: 6| Step: 8
Training loss: 0.5984055054879263
Validation loss: 2.5555031628236784

Epoch: 6| Step: 9
Training loss: 1.6024580521828762
Validation loss: 2.559056699079785

Epoch: 6| Step: 10
Training loss: 0.8299854181916123
Validation loss: 2.5366334595497704

Epoch: 6| Step: 11
Training loss: 0.9492106496206258
Validation loss: 2.6135609272619176

Epoch: 6| Step: 12
Training loss: 0.8359871608920929
Validation loss: 2.594841938884781

Epoch: 6| Step: 13
Training loss: 1.0198584722055644
Validation loss: 2.6024884873834435

Epoch: 238| Step: 0
Training loss: 1.0634586273166249
Validation loss: 2.6460853765378745

Epoch: 6| Step: 1
Training loss: 1.2291490047069535
Validation loss: 2.6188425663147563

Epoch: 6| Step: 2
Training loss: 1.1854710562530082
Validation loss: 2.6197253144439827

Epoch: 6| Step: 3
Training loss: 1.1543737085786463
Validation loss: 2.5894386584582323

Epoch: 6| Step: 4
Training loss: 0.7412511842277549
Validation loss: 2.603478607996993

Epoch: 6| Step: 5
Training loss: 1.4207453170019886
Validation loss: 2.5866805973297358

Epoch: 6| Step: 6
Training loss: 1.0913331713885088
Validation loss: 2.567697903194825

Epoch: 6| Step: 7
Training loss: 0.8769062259087202
Validation loss: 2.6239049407782216

Epoch: 6| Step: 8
Training loss: 0.8685741164185589
Validation loss: 2.6114184786960273

Epoch: 6| Step: 9
Training loss: 0.999090138405957
Validation loss: 2.6018431492210925

Epoch: 6| Step: 10
Training loss: 1.3798957710710529
Validation loss: 2.590588833189443

Epoch: 6| Step: 11
Training loss: 1.3618503701730071
Validation loss: 2.601734135390861

Epoch: 6| Step: 12
Training loss: 0.7503552390258773
Validation loss: 2.581327984506909

Epoch: 6| Step: 13
Training loss: 0.695873248693374
Validation loss: 2.5738408454594115

Epoch: 239| Step: 0
Training loss: 1.1784187719636827
Validation loss: 2.5223207549178817

Epoch: 6| Step: 1
Training loss: 0.914359997973703
Validation loss: 2.5836233742994548

Epoch: 6| Step: 2
Training loss: 1.046242252261918
Validation loss: 2.5714591464254526

Epoch: 6| Step: 3
Training loss: 1.134727910739726
Validation loss: 2.6237898096173393

Epoch: 6| Step: 4
Training loss: 1.400664192410559
Validation loss: 2.618918282820945

Epoch: 6| Step: 5
Training loss: 1.489825871424828
Validation loss: 2.6644115417217233

Epoch: 6| Step: 6
Training loss: 0.7194873510631329
Validation loss: 2.629781856134201

Epoch: 6| Step: 7
Training loss: 1.0285250178341756
Validation loss: 2.607936587198215

Epoch: 6| Step: 8
Training loss: 0.9120911100139399
Validation loss: 2.6100781614375737

Epoch: 6| Step: 9
Training loss: 0.37715979331338073
Validation loss: 2.5847218368108065

Epoch: 6| Step: 10
Training loss: 1.1367576041905854
Validation loss: 2.5478398684514616

Epoch: 6| Step: 11
Training loss: 0.9419557226226999
Validation loss: 2.516451542461255

Epoch: 6| Step: 12
Training loss: 1.5254776034791302
Validation loss: 2.514755187309023

Epoch: 6| Step: 13
Training loss: 0.3993531159627199
Validation loss: 2.521287463442935

Epoch: 240| Step: 0
Training loss: 1.1372655752729293
Validation loss: 2.506843494945406

Epoch: 6| Step: 1
Training loss: 1.2123477722250706
Validation loss: 2.552995801834652

Epoch: 6| Step: 2
Training loss: 0.9332249124314124
Validation loss: 2.5702725905535297

Epoch: 6| Step: 3
Training loss: 1.0521087202779822
Validation loss: 2.5908563521548333

Epoch: 6| Step: 4
Training loss: 0.8391561132737836
Validation loss: 2.611959665626216

Epoch: 6| Step: 5
Training loss: 0.8628974510188822
Validation loss: 2.6361263804123514

Epoch: 6| Step: 6
Training loss: 1.32564294798417
Validation loss: 2.594534322832037

Epoch: 6| Step: 7
Training loss: 1.0110498522155873
Validation loss: 2.6307666193773875

Epoch: 6| Step: 8
Training loss: 1.281424487258264
Validation loss: 2.628012936492694

Epoch: 6| Step: 9
Training loss: 0.9737009466545312
Validation loss: 2.600504152816132

Epoch: 6| Step: 10
Training loss: 1.1749154892418228
Validation loss: 2.5379786588884676

Epoch: 6| Step: 11
Training loss: 1.1126664455071518
Validation loss: 2.5266870460540134

Epoch: 6| Step: 12
Training loss: 0.6823766500142461
Validation loss: 2.5254657254125625

Epoch: 6| Step: 13
Training loss: 1.2903921956464264
Validation loss: 2.5366913800705753

Epoch: 241| Step: 0
Training loss: 1.0088284125689908
Validation loss: 2.5319868762529225

Epoch: 6| Step: 1
Training loss: 1.3568130115633006
Validation loss: 2.546857483385421

Epoch: 6| Step: 2
Training loss: 0.9939169641501076
Validation loss: 2.563372515729609

Epoch: 6| Step: 3
Training loss: 0.867558305523419
Validation loss: 2.5971552347537803

Epoch: 6| Step: 4
Training loss: 1.677807274545798
Validation loss: 2.566311379589288

Epoch: 6| Step: 5
Training loss: 0.8937639835570871
Validation loss: 2.542992471165589

Epoch: 6| Step: 6
Training loss: 1.162406819208441
Validation loss: 2.5473127655121206

Epoch: 6| Step: 7
Training loss: 1.2020400964551985
Validation loss: 2.5332662952271683

Epoch: 6| Step: 8
Training loss: 0.7216951732496819
Validation loss: 2.5081635160083935

Epoch: 6| Step: 9
Training loss: 1.1010449864467688
Validation loss: 2.51882177985646

Epoch: 6| Step: 10
Training loss: 1.192153146231311
Validation loss: 2.517911913656593

Epoch: 6| Step: 11
Training loss: 0.2565370132806357
Validation loss: 2.5650859183526507

Epoch: 6| Step: 12
Training loss: 0.9411741105043048
Validation loss: 2.562858444423377

Epoch: 6| Step: 13
Training loss: 1.0306849231961874
Validation loss: 2.6043095089693966

Epoch: 242| Step: 0
Training loss: 1.2174558860259581
Validation loss: 2.631732687957777

Epoch: 6| Step: 1
Training loss: 0.9789164439870847
Validation loss: 2.6183991655554752

Epoch: 6| Step: 2
Training loss: 0.9840420053770088
Validation loss: 2.666791583860381

Epoch: 6| Step: 3
Training loss: 1.3850735213118064
Validation loss: 2.6983958176875364

Epoch: 6| Step: 4
Training loss: 0.9294514075798282
Validation loss: 2.6798641811848944

Epoch: 6| Step: 5
Training loss: 0.7484441354732198
Validation loss: 2.638612828461965

Epoch: 6| Step: 6
Training loss: 1.2156812228265854
Validation loss: 2.581616555326462

Epoch: 6| Step: 7
Training loss: 1.1161848250411033
Validation loss: 2.563656742699736

Epoch: 6| Step: 8
Training loss: 0.9611607734133936
Validation loss: 2.578467704838862

Epoch: 6| Step: 9
Training loss: 1.2221119799650508
Validation loss: 2.513571506724274

Epoch: 6| Step: 10
Training loss: 0.6391192627859501
Validation loss: 2.44991397438763

Epoch: 6| Step: 11
Training loss: 0.7496399014982693
Validation loss: 2.536273061533586

Epoch: 6| Step: 12
Training loss: 0.9465084864764414
Validation loss: 2.524491776432298

Epoch: 6| Step: 13
Training loss: 1.6243851305362065
Validation loss: 2.5936631999766937

Epoch: 243| Step: 0
Training loss: 1.4638500861555288
Validation loss: 2.6021375344882163

Epoch: 6| Step: 1
Training loss: 0.5075372390050785
Validation loss: 2.6174291845332096

Epoch: 6| Step: 2
Training loss: 1.2190769441712597
Validation loss: 2.6205428342416752

Epoch: 6| Step: 3
Training loss: 1.2131191167438182
Validation loss: 2.6394488200628414

Epoch: 6| Step: 4
Training loss: 0.8064890573637822
Validation loss: 2.601329572920447

Epoch: 6| Step: 5
Training loss: 1.2355606565572184
Validation loss: 2.5987868863532246

Epoch: 6| Step: 6
Training loss: 0.911306546606139
Validation loss: 2.5796733016737536

Epoch: 6| Step: 7
Training loss: 0.9818117283298345
Validation loss: 2.5625539594401974

Epoch: 6| Step: 8
Training loss: 0.7503692592138802
Validation loss: 2.527156998101778

Epoch: 6| Step: 9
Training loss: 1.0656479035989725
Validation loss: 2.5433451807080028

Epoch: 6| Step: 10
Training loss: 1.3117597854130039
Validation loss: 2.5025140549913902

Epoch: 6| Step: 11
Training loss: 1.0524243975961598
Validation loss: 2.5461467399027193

Epoch: 6| Step: 12
Training loss: 0.8569616242522059
Validation loss: 2.5423151090459317

Epoch: 6| Step: 13
Training loss: 0.5763060332753449
Validation loss: 2.583130582090123

Epoch: 244| Step: 0
Training loss: 1.056839055240215
Validation loss: 2.6003174979983403

Epoch: 6| Step: 1
Training loss: 0.7901747767347302
Validation loss: 2.558488643929376

Epoch: 6| Step: 2
Training loss: 1.051232053351781
Validation loss: 2.624168955897206

Epoch: 6| Step: 3
Training loss: 0.7977857060608146
Validation loss: 2.595652010757056

Epoch: 6| Step: 4
Training loss: 1.1592832421033925
Validation loss: 2.5688029421789853

Epoch: 6| Step: 5
Training loss: 1.0040063474158145
Validation loss: 2.508812146296239

Epoch: 6| Step: 6
Training loss: 1.4167863103421678
Validation loss: 2.5332388428205785

Epoch: 6| Step: 7
Training loss: 1.0269009756470144
Validation loss: 2.547094981189618

Epoch: 6| Step: 8
Training loss: 1.4358801630006521
Validation loss: 2.5027550129885148

Epoch: 6| Step: 9
Training loss: 0.7587960143488856
Validation loss: 2.48666754451095

Epoch: 6| Step: 10
Training loss: 0.8106218050597441
Validation loss: 2.469819385201769

Epoch: 6| Step: 11
Training loss: 1.2902603594906057
Validation loss: 2.485878931168233

Epoch: 6| Step: 12
Training loss: 0.835581266846585
Validation loss: 2.5127612152900425

Epoch: 6| Step: 13
Training loss: 0.776193237010722
Validation loss: 2.5169401293523954

Epoch: 245| Step: 0
Training loss: 0.8195619328285314
Validation loss: 2.568089758089926

Epoch: 6| Step: 1
Training loss: 0.9957877493178902
Validation loss: 2.578328860101283

Epoch: 6| Step: 2
Training loss: 1.1713699269651496
Validation loss: 2.5913464830516895

Epoch: 6| Step: 3
Training loss: 0.9447016988956038
Validation loss: 2.631691855179179

Epoch: 6| Step: 4
Training loss: 1.2849558294252428
Validation loss: 2.6191134491824104

Epoch: 6| Step: 5
Training loss: 0.8655289607015176
Validation loss: 2.6117223436428665

Epoch: 6| Step: 6
Training loss: 0.961825820825649
Validation loss: 2.577053534785057

Epoch: 6| Step: 7
Training loss: 0.9636183459039438
Validation loss: 2.5592154134572063

Epoch: 6| Step: 8
Training loss: 1.2045910807813116
Validation loss: 2.541088353825267

Epoch: 6| Step: 9
Training loss: 0.7838902301455435
Validation loss: 2.5188407641796595

Epoch: 6| Step: 10
Training loss: 0.9093021429181164
Validation loss: 2.5083504606700675

Epoch: 6| Step: 11
Training loss: 0.8662813280614095
Validation loss: 2.5148649754825176

Epoch: 6| Step: 12
Training loss: 1.4087374833370918
Validation loss: 2.5394599566866916

Epoch: 6| Step: 13
Training loss: 0.8876700990493295
Validation loss: 2.527457452821269

Epoch: 246| Step: 0
Training loss: 0.9136166911851876
Validation loss: 2.5787012057295158

Epoch: 6| Step: 1
Training loss: 1.0037757996584293
Validation loss: 2.5736506790402003

Epoch: 6| Step: 2
Training loss: 0.7499242187997487
Validation loss: 2.5877984923456627

Epoch: 6| Step: 3
Training loss: 1.1126202679036217
Validation loss: 2.594633245337164

Epoch: 6| Step: 4
Training loss: 1.4867105681233825
Validation loss: 2.582971321910645

Epoch: 6| Step: 5
Training loss: 1.3979650370628582
Validation loss: 2.599067034848316

Epoch: 6| Step: 6
Training loss: 0.611839446222327
Validation loss: 2.588794854248015

Epoch: 6| Step: 7
Training loss: 1.2130324423619239
Validation loss: 2.597858401782933

Epoch: 6| Step: 8
Training loss: 0.5963913990597293
Validation loss: 2.600378754891456

Epoch: 6| Step: 9
Training loss: 1.074992618979021
Validation loss: 2.5446873941840953

Epoch: 6| Step: 10
Training loss: 0.8313075397051796
Validation loss: 2.525101728328307

Epoch: 6| Step: 11
Training loss: 1.0795308773754038
Validation loss: 2.51341997067405

Epoch: 6| Step: 12
Training loss: 1.018146085479814
Validation loss: 2.5090304651782573

Epoch: 6| Step: 13
Training loss: 0.4088929840256574
Validation loss: 2.5220621162213943

Epoch: 247| Step: 0
Training loss: 0.8694905808801253
Validation loss: 2.5002713415087436

Epoch: 6| Step: 1
Training loss: 1.038524459701423
Validation loss: 2.543046106596892

Epoch: 6| Step: 2
Training loss: 0.7367520920458741
Validation loss: 2.5342717892643076

Epoch: 6| Step: 3
Training loss: 0.3781158816601677
Validation loss: 2.5673692682349474

Epoch: 6| Step: 4
Training loss: 1.0948134565619796
Validation loss: 2.553835497931399

Epoch: 6| Step: 5
Training loss: 0.7337323481371463
Validation loss: 2.5566422815225933

Epoch: 6| Step: 6
Training loss: 0.8994218823883045
Validation loss: 2.522798273932832

Epoch: 6| Step: 7
Training loss: 1.2452717045667503
Validation loss: 2.526370647807996

Epoch: 6| Step: 8
Training loss: 1.1126411605602462
Validation loss: 2.5109233068387464

Epoch: 6| Step: 9
Training loss: 1.1487914078547883
Validation loss: 2.5140262986888064

Epoch: 6| Step: 10
Training loss: 1.3612600388870468
Validation loss: 2.5555019911041543

Epoch: 6| Step: 11
Training loss: 1.0491630261039644
Validation loss: 2.5546028725543675

Epoch: 6| Step: 12
Training loss: 0.7702553532509404
Validation loss: 2.5542021630917784

Epoch: 6| Step: 13
Training loss: 1.2932908040277151
Validation loss: 2.5621485275267997

Epoch: 248| Step: 0
Training loss: 0.8228706797695429
Validation loss: 2.567066189126595

Epoch: 6| Step: 1
Training loss: 0.6996512540532999
Validation loss: 2.588998753497759

Epoch: 6| Step: 2
Training loss: 0.7518754398791769
Validation loss: 2.6210932912802143

Epoch: 6| Step: 3
Training loss: 1.1712254058959
Validation loss: 2.5637949371067474

Epoch: 6| Step: 4
Training loss: 1.2561188662585456
Validation loss: 2.639168960383424

Epoch: 6| Step: 5
Training loss: 0.8598215156909382
Validation loss: 2.5874401763108272

Epoch: 6| Step: 6
Training loss: 1.296900185949433
Validation loss: 2.558807113156497

Epoch: 6| Step: 7
Training loss: 1.2420745894260687
Validation loss: 2.5779011638843774

Epoch: 6| Step: 8
Training loss: 1.2163930256442606
Validation loss: 2.54123599436402

Epoch: 6| Step: 9
Training loss: 0.9264399120940469
Validation loss: 2.5599283870123104

Epoch: 6| Step: 10
Training loss: 0.759761074807631
Validation loss: 2.5509791796872507

Epoch: 6| Step: 11
Training loss: 0.5244348617776489
Validation loss: 2.6028346164871463

Epoch: 6| Step: 12
Training loss: 1.18940962788643
Validation loss: 2.613811712597682

Epoch: 6| Step: 13
Training loss: 0.8328300187950397
Validation loss: 2.6077066110339513

Epoch: 249| Step: 0
Training loss: 0.9304974978319539
Validation loss: 2.6202775918032657

Epoch: 6| Step: 1
Training loss: 0.8176503899974986
Validation loss: 2.6078651937777546

Epoch: 6| Step: 2
Training loss: 1.1284090947157557
Validation loss: 2.5434356765348745

Epoch: 6| Step: 3
Training loss: 1.0487501516785358
Validation loss: 2.55719511907764

Epoch: 6| Step: 4
Training loss: 1.3018376639987652
Validation loss: 2.5125030067379734

Epoch: 6| Step: 5
Training loss: 0.9923609784672474
Validation loss: 2.497598216279484

Epoch: 6| Step: 6
Training loss: 1.0008272087509027
Validation loss: 2.4913595725279025

Epoch: 6| Step: 7
Training loss: 1.1200474764774924
Validation loss: 2.5161596316208916

Epoch: 6| Step: 8
Training loss: 0.8195670600973123
Validation loss: 2.45776604213954

Epoch: 6| Step: 9
Training loss: 0.780968119313714
Validation loss: 2.5267131375165404

Epoch: 6| Step: 10
Training loss: 0.8802787745051387
Validation loss: 2.484611693437554

Epoch: 6| Step: 11
Training loss: 0.9477986831739607
Validation loss: 2.5641842321179835

Epoch: 6| Step: 12
Training loss: 0.8626980429794632
Validation loss: 2.5785930627540523

Epoch: 6| Step: 13
Training loss: 1.2789854646174434
Validation loss: 2.5956647289178303

Epoch: 250| Step: 0
Training loss: 1.054591647843454
Validation loss: 2.625218368174602

Epoch: 6| Step: 1
Training loss: 0.7996050127783505
Validation loss: 2.615123285293863

Epoch: 6| Step: 2
Training loss: 1.1569356174343426
Validation loss: 2.5666210702549153

Epoch: 6| Step: 3
Training loss: 0.8801930480773508
Validation loss: 2.564974614685221

Epoch: 6| Step: 4
Training loss: 1.1115431753499792
Validation loss: 2.5565496038512805

Epoch: 6| Step: 5
Training loss: 0.8617367283457881
Validation loss: 2.540318455442903

Epoch: 6| Step: 6
Training loss: 0.8477704722712025
Validation loss: 2.5182064393145795

Epoch: 6| Step: 7
Training loss: 0.635647111806292
Validation loss: 2.533455353239413

Epoch: 6| Step: 8
Training loss: 1.1865210764669154
Validation loss: 2.545338431701344

Epoch: 6| Step: 9
Training loss: 1.1493684278324114
Validation loss: 2.513832301914022

Epoch: 6| Step: 10
Training loss: 1.0099607533676225
Validation loss: 2.5331598457906703

Epoch: 6| Step: 11
Training loss: 0.8449772280948407
Validation loss: 2.551025083488615

Epoch: 6| Step: 12
Training loss: 1.0665950957267967
Validation loss: 2.563339665083431

Epoch: 6| Step: 13
Training loss: 0.8620408065899533
Validation loss: 2.609302407985899

Testing loss: 2.5808849607187074
