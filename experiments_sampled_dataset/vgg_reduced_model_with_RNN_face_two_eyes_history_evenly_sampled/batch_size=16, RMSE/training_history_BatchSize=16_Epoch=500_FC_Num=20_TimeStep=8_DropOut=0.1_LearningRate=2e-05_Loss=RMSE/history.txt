Epoch: 1| Step: 0
Training loss: 6.83742059804502
Validation loss: 5.822331333967114

Epoch: 6| Step: 1
Training loss: 6.178239153519871
Validation loss: 5.804456491217935

Epoch: 6| Step: 2
Training loss: 5.77913878786403
Validation loss: 5.788880400461528

Epoch: 6| Step: 3
Training loss: 5.907181277852751
Validation loss: 5.772281832622777

Epoch: 6| Step: 4
Training loss: 5.570757277013987
Validation loss: 5.7545508040320525

Epoch: 6| Step: 5
Training loss: 5.248686853307409
Validation loss: 5.734514275274153

Epoch: 6| Step: 6
Training loss: 4.740479615810519
Validation loss: 5.712693036629934

Epoch: 6| Step: 7
Training loss: 7.039374104333547
Validation loss: 5.687578080182362

Epoch: 6| Step: 8
Training loss: 6.054022140860673
Validation loss: 5.659891045654878

Epoch: 6| Step: 9
Training loss: 6.290863120531993
Validation loss: 5.6292226530996405

Epoch: 6| Step: 10
Training loss: 5.463116692620832
Validation loss: 5.594603019235556

Epoch: 6| Step: 11
Training loss: 5.003391069608148
Validation loss: 5.556697638373959

Epoch: 6| Step: 12
Training loss: 4.742745330529953
Validation loss: 5.515339100266951

Epoch: 6| Step: 13
Training loss: 3.603488101182149
Validation loss: 5.4707231778353504

Epoch: 2| Step: 0
Training loss: 4.6611556255006885
Validation loss: 5.425201682495689

Epoch: 6| Step: 1
Training loss: 5.295694855510988
Validation loss: 5.377571870011178

Epoch: 6| Step: 2
Training loss: 5.795864788365885
Validation loss: 5.32857020527542

Epoch: 6| Step: 3
Training loss: 4.796735432237718
Validation loss: 5.276743953436995

Epoch: 6| Step: 4
Training loss: 6.366992484072549
Validation loss: 5.222685171927995

Epoch: 6| Step: 5
Training loss: 6.1499071315793685
Validation loss: 5.165569364878426

Epoch: 6| Step: 6
Training loss: 5.521893880452389
Validation loss: 5.106289269004671

Epoch: 6| Step: 7
Training loss: 5.891554539039302
Validation loss: 5.038347414545963

Epoch: 6| Step: 8
Training loss: 3.960824336555312
Validation loss: 4.967715472915457

Epoch: 6| Step: 9
Training loss: 4.846612097018878
Validation loss: 4.896838943092484

Epoch: 6| Step: 10
Training loss: 4.614928956647366
Validation loss: 4.830840093954755

Epoch: 6| Step: 11
Training loss: 3.6647029878138286
Validation loss: 4.764658448531911

Epoch: 6| Step: 12
Training loss: 4.6253985671406985
Validation loss: 4.706360636283354

Epoch: 6| Step: 13
Training loss: 4.914313232623643
Validation loss: 4.652873450536198

Epoch: 3| Step: 0
Training loss: 5.413492808568949
Validation loss: 4.6046535999324565

Epoch: 6| Step: 1
Training loss: 3.905353656926469
Validation loss: 4.560719076024835

Epoch: 6| Step: 2
Training loss: 4.864081651629699
Validation loss: 4.5223995191487445

Epoch: 6| Step: 3
Training loss: 4.1038772300218485
Validation loss: 4.4909783401070875

Epoch: 6| Step: 4
Training loss: 4.7006602371410615
Validation loss: 4.462563097709843

Epoch: 6| Step: 5
Training loss: 4.807584555958981
Validation loss: 4.4373087907516

Epoch: 6| Step: 6
Training loss: 3.885352181043534
Validation loss: 4.412188896305057

Epoch: 6| Step: 7
Training loss: 4.640067635404986
Validation loss: 4.385732055076294

Epoch: 6| Step: 8
Training loss: 4.552014988343246
Validation loss: 4.3603775801009474

Epoch: 6| Step: 9
Training loss: 4.866493236813362
Validation loss: 4.343031320870336

Epoch: 6| Step: 10
Training loss: 4.046813257401829
Validation loss: 4.321528771362766

Epoch: 6| Step: 11
Training loss: 5.15553972380681
Validation loss: 4.302786320362303

Epoch: 6| Step: 12
Training loss: 4.107649176054357
Validation loss: 4.292193388323305

Epoch: 6| Step: 13
Training loss: 3.6127207388310247
Validation loss: 4.265732562018298

Epoch: 4| Step: 0
Training loss: 4.429833895839274
Validation loss: 4.253716679236019

Epoch: 6| Step: 1
Training loss: 4.507278490087675
Validation loss: 4.241362766569604

Epoch: 6| Step: 2
Training loss: 3.7380484545380255
Validation loss: 4.223351165373577

Epoch: 6| Step: 3
Training loss: 3.8934852473350685
Validation loss: 4.205099870065144

Epoch: 6| Step: 4
Training loss: 3.4198287349895398
Validation loss: 4.186058312966596

Epoch: 6| Step: 5
Training loss: 4.406140914540644
Validation loss: 4.205900579329931

Epoch: 6| Step: 6
Training loss: 4.700248573710021
Validation loss: 4.1655402172389255

Epoch: 6| Step: 7
Training loss: 4.215033356341128
Validation loss: 4.162391183589849

Epoch: 6| Step: 8
Training loss: 5.362715944863932
Validation loss: 4.156910611492866

Epoch: 6| Step: 9
Training loss: 5.409097087206711
Validation loss: 4.143522257298508

Epoch: 6| Step: 10
Training loss: 4.114735635119689
Validation loss: 4.123142317592538

Epoch: 6| Step: 11
Training loss: 4.120356402490557
Validation loss: 4.11161170070943

Epoch: 6| Step: 12
Training loss: 3.5638213802322074
Validation loss: 4.105673510496399

Epoch: 6| Step: 13
Training loss: 3.5249691359879973
Validation loss: 4.1192371986831215

Epoch: 5| Step: 0
Training loss: 4.1144282959649106
Validation loss: 4.084229712242594

Epoch: 6| Step: 1
Training loss: 4.101911954979211
Validation loss: 4.072080665437308

Epoch: 6| Step: 2
Training loss: 3.533234705238219
Validation loss: 4.064295092111731

Epoch: 6| Step: 3
Training loss: 3.794980428089842
Validation loss: 4.054983344124465

Epoch: 6| Step: 4
Training loss: 3.8103662992596514
Validation loss: 4.043734440270612

Epoch: 6| Step: 5
Training loss: 4.251361853124381
Validation loss: 4.030087190661603

Epoch: 6| Step: 6
Training loss: 4.563735376615142
Validation loss: 4.013911955083131

Epoch: 6| Step: 7
Training loss: 4.695529824811398
Validation loss: 3.997168642528742

Epoch: 6| Step: 8
Training loss: 5.071772995426616
Validation loss: 3.9859151869356215

Epoch: 6| Step: 9
Training loss: 3.5250321731722414
Validation loss: 3.971897261300384

Epoch: 6| Step: 10
Training loss: 4.390455140870265
Validation loss: 3.965414305379472

Epoch: 6| Step: 11
Training loss: 4.095682401518268
Validation loss: 3.9610143566140503

Epoch: 6| Step: 12
Training loss: 4.335113062104663
Validation loss: 3.9448405211428854

Epoch: 6| Step: 13
Training loss: 3.2397129404977556
Validation loss: 3.9285523657994825

Epoch: 6| Step: 0
Training loss: 3.543478797613405
Validation loss: 3.912805501592705

Epoch: 6| Step: 1
Training loss: 3.458856167778574
Validation loss: 3.8965582737656446

Epoch: 6| Step: 2
Training loss: 4.210706488619312
Validation loss: 3.8881653098387394

Epoch: 6| Step: 3
Training loss: 4.0733052854514025
Validation loss: 3.874584951147479

Epoch: 6| Step: 4
Training loss: 4.552693527607942
Validation loss: 3.8726511282445726

Epoch: 6| Step: 5
Training loss: 3.93749927339093
Validation loss: 3.862328404874299

Epoch: 6| Step: 6
Training loss: 4.788426417663014
Validation loss: 3.8406223284794363

Epoch: 6| Step: 7
Training loss: 4.846853529429396
Validation loss: 3.8341858376441658

Epoch: 6| Step: 8
Training loss: 3.642478372880121
Validation loss: 3.8408990186759024

Epoch: 6| Step: 9
Training loss: 3.7344738296774684
Validation loss: 3.842892440160569

Epoch: 6| Step: 10
Training loss: 3.16192268258716
Validation loss: 3.831763861555869

Epoch: 6| Step: 11
Training loss: 3.654167690878666
Validation loss: 3.8191677847729872

Epoch: 6| Step: 12
Training loss: 3.991974886553402
Validation loss: 3.799088458512802

Epoch: 6| Step: 13
Training loss: 4.415359495567451
Validation loss: 3.7917741455798035

Epoch: 7| Step: 0
Training loss: 3.496925093195717
Validation loss: 3.7848939706448586

Epoch: 6| Step: 1
Training loss: 3.401401253463129
Validation loss: 3.773758971555359

Epoch: 6| Step: 2
Training loss: 3.9732865965311173
Validation loss: 3.762723390042198

Epoch: 6| Step: 3
Training loss: 3.668460638277293
Validation loss: 3.7502313522017356

Epoch: 6| Step: 4
Training loss: 4.01032070028578
Validation loss: 3.745379039368363

Epoch: 6| Step: 5
Training loss: 3.340242346463123
Validation loss: 3.7433568460936875

Epoch: 6| Step: 6
Training loss: 3.6665509523570607
Validation loss: 3.740051612232466

Epoch: 6| Step: 7
Training loss: 4.175112493221552
Validation loss: 3.7347839367718714

Epoch: 6| Step: 8
Training loss: 3.5391006299253194
Validation loss: 3.719035829000301

Epoch: 6| Step: 9
Training loss: 4.851803882632453
Validation loss: 3.7075641083608466

Epoch: 6| Step: 10
Training loss: 4.321626156520106
Validation loss: 3.700382192860955

Epoch: 6| Step: 11
Training loss: 4.167505840990794
Validation loss: 3.696912609723122

Epoch: 6| Step: 12
Training loss: 3.7719301486783645
Validation loss: 3.686678436678257

Epoch: 6| Step: 13
Training loss: 4.214372638609517
Validation loss: 3.680792265142578

Epoch: 8| Step: 0
Training loss: 3.7821683162633555
Validation loss: 3.6797611433075

Epoch: 6| Step: 1
Training loss: 3.2724498633615964
Validation loss: 3.6714203793315745

Epoch: 6| Step: 2
Training loss: 2.7438180971493247
Validation loss: 3.666233366220201

Epoch: 6| Step: 3
Training loss: 3.001522949212356
Validation loss: 3.6622870840618633

Epoch: 6| Step: 4
Training loss: 4.262056416002547
Validation loss: 3.6606291265202016

Epoch: 6| Step: 5
Training loss: 4.568964728489983
Validation loss: 3.6553530213757375

Epoch: 6| Step: 6
Training loss: 4.175776910735
Validation loss: 3.6516250781559227

Epoch: 6| Step: 7
Training loss: 3.7922901996275176
Validation loss: 3.6465012803678793

Epoch: 6| Step: 8
Training loss: 4.89581822602667
Validation loss: 3.63856889030113

Epoch: 6| Step: 9
Training loss: 3.576089204908743
Validation loss: 3.6348495969620536

Epoch: 6| Step: 10
Training loss: 3.8663523995732136
Validation loss: 3.632200160415881

Epoch: 6| Step: 11
Training loss: 3.012895524901208
Validation loss: 3.6269718474746355

Epoch: 6| Step: 12
Training loss: 3.6724803669030126
Validation loss: 3.6417624833627165

Epoch: 6| Step: 13
Training loss: 4.865868256453329
Validation loss: 3.6204498710081805

Epoch: 9| Step: 0
Training loss: 4.067691244495688
Validation loss: 3.6205289734137605

Epoch: 6| Step: 1
Training loss: 4.228484501184534
Validation loss: 3.6175205649058766

Epoch: 6| Step: 2
Training loss: 3.128088073817391
Validation loss: 3.6138940825249817

Epoch: 6| Step: 3
Training loss: 4.0029321890621
Validation loss: 3.6072078698453103

Epoch: 6| Step: 4
Training loss: 3.67562194543876
Validation loss: 3.6014762670388314

Epoch: 6| Step: 5
Training loss: 3.322620980591085
Validation loss: 3.5974056118333375

Epoch: 6| Step: 6
Training loss: 4.4382869398781954
Validation loss: 3.5911482243485064

Epoch: 6| Step: 7
Training loss: 3.1682267278013554
Validation loss: 3.5880116464910543

Epoch: 6| Step: 8
Training loss: 4.059630334119971
Validation loss: 3.605048739894715

Epoch: 6| Step: 9
Training loss: 3.858792527449158
Validation loss: 3.5725920782163465

Epoch: 6| Step: 10
Training loss: 3.211613716146941
Validation loss: 3.5903541075134147

Epoch: 6| Step: 11
Training loss: 4.0065606673739085
Validation loss: 3.610010169425691

Epoch: 6| Step: 12
Training loss: 4.01772624453501
Validation loss: 3.6053515256679516

Epoch: 6| Step: 13
Training loss: 3.7384470680635418
Validation loss: 3.5896553014100667

Epoch: 10| Step: 0
Training loss: 3.5301306646873036
Validation loss: 3.587441946157851

Epoch: 6| Step: 1
Training loss: 3.985796626168754
Validation loss: 3.5819961120826584

Epoch: 6| Step: 2
Training loss: 4.124613425896533
Validation loss: 3.5707003331480935

Epoch: 6| Step: 3
Training loss: 3.5486687649105484
Validation loss: 3.6036429839492756

Epoch: 6| Step: 4
Training loss: 2.9364393226645973
Validation loss: 3.558188873326562

Epoch: 6| Step: 5
Training loss: 3.7772046352517603
Validation loss: 3.5599837571322346

Epoch: 6| Step: 6
Training loss: 3.2927981657143572
Validation loss: 3.5520404691235674

Epoch: 6| Step: 7
Training loss: 3.810398210356022
Validation loss: 3.5486261243475647

Epoch: 6| Step: 8
Training loss: 3.679457088310948
Validation loss: 3.544582539521567

Epoch: 6| Step: 9
Training loss: 4.165587069202073
Validation loss: 3.5416387080344287

Epoch: 6| Step: 10
Training loss: 3.4863418023191093
Validation loss: 3.5415299048369615

Epoch: 6| Step: 11
Training loss: 4.746686683319691
Validation loss: 3.535562949252075

Epoch: 6| Step: 12
Training loss: 4.069649376915091
Validation loss: 3.525479937756503

Epoch: 6| Step: 13
Training loss: 2.60499845318007
Validation loss: 3.5192989105917625

Epoch: 11| Step: 0
Training loss: 3.998749179774418
Validation loss: 3.514889388882663

Epoch: 6| Step: 1
Training loss: 3.321912097454617
Validation loss: 3.5123073340093685

Epoch: 6| Step: 2
Training loss: 3.893220089632848
Validation loss: 3.5098343885353134

Epoch: 6| Step: 3
Training loss: 3.5067344997164334
Validation loss: 3.499926995542947

Epoch: 6| Step: 4
Training loss: 4.662564904627941
Validation loss: 3.4961202802285634

Epoch: 6| Step: 5
Training loss: 3.8549111686792736
Validation loss: 3.488403254974964

Epoch: 6| Step: 6
Training loss: 3.0047384034604376
Validation loss: 3.488075603327589

Epoch: 6| Step: 7
Training loss: 3.948618857442138
Validation loss: 3.48646532225771

Epoch: 6| Step: 8
Training loss: 2.586289304099979
Validation loss: 3.4847986092663006

Epoch: 6| Step: 9
Training loss: 3.4000936046505754
Validation loss: 3.4757083261508708

Epoch: 6| Step: 10
Training loss: 2.9840905817923487
Validation loss: 3.4883555432273883

Epoch: 6| Step: 11
Training loss: 4.922752084239642
Validation loss: 3.5326648723165954

Epoch: 6| Step: 12
Training loss: 3.430393433096991
Validation loss: 3.4608794510040606

Epoch: 6| Step: 13
Training loss: 3.7512341058096275
Validation loss: 3.4691632146730633

Epoch: 12| Step: 0
Training loss: 3.9991288428569063
Validation loss: 3.480346998706491

Epoch: 6| Step: 1
Training loss: 2.968743896478101
Validation loss: 3.4845733122619063

Epoch: 6| Step: 2
Training loss: 3.505201833793581
Validation loss: 3.467624795542075

Epoch: 6| Step: 3
Training loss: 4.032102036441462
Validation loss: 3.4495760471851424

Epoch: 6| Step: 4
Training loss: 4.0380220530390964
Validation loss: 3.442381833926594

Epoch: 6| Step: 5
Training loss: 4.10714138812874
Validation loss: 3.4412888305786145

Epoch: 6| Step: 6
Training loss: 3.538494409772083
Validation loss: 3.4889776363854823

Epoch: 6| Step: 7
Training loss: 3.786689439915515
Validation loss: 3.4327923067587354

Epoch: 6| Step: 8
Training loss: 3.236789557667443
Validation loss: 3.445196102191594

Epoch: 6| Step: 9
Training loss: 3.557804560327864
Validation loss: 3.471660781808182

Epoch: 6| Step: 10
Training loss: 3.4315402993836375
Validation loss: 3.479161026284269

Epoch: 6| Step: 11
Training loss: 3.681125886181698
Validation loss: 3.470341952818086

Epoch: 6| Step: 12
Training loss: 3.864929773203445
Validation loss: 3.441018233657281

Epoch: 6| Step: 13
Training loss: 3.5242858000871324
Validation loss: 3.4316618997020125

Epoch: 13| Step: 0
Training loss: 4.590516489926499
Validation loss: 3.4498995928177556

Epoch: 6| Step: 1
Training loss: 4.048369260659691
Validation loss: 3.424565569538066

Epoch: 6| Step: 2
Training loss: 3.9581264776422564
Validation loss: 3.4191292507726105

Epoch: 6| Step: 3
Training loss: 3.3514368705056734
Validation loss: 3.4109789048894634

Epoch: 6| Step: 4
Training loss: 3.5100271459763275
Validation loss: 3.4059167800367205

Epoch: 6| Step: 5
Training loss: 3.469866048992269
Validation loss: 3.3969942050489212

Epoch: 6| Step: 6
Training loss: 3.7447554472054647
Validation loss: 3.3973437016161596

Epoch: 6| Step: 7
Training loss: 4.073626496232877
Validation loss: 3.3932385239774994

Epoch: 6| Step: 8
Training loss: 2.87486316521134
Validation loss: 3.3867779838093286

Epoch: 6| Step: 9
Training loss: 3.21484375
Validation loss: 3.3865012749473133

Epoch: 6| Step: 10
Training loss: 3.433641661221832
Validation loss: 3.383716252511419

Epoch: 6| Step: 11
Training loss: 3.4288078692062443
Validation loss: 3.3782477481733353

Epoch: 6| Step: 12
Training loss: 3.1864290121142136
Validation loss: 3.3748004342359335

Epoch: 6| Step: 13
Training loss: 3.5097993181465674
Validation loss: 3.3729626679227698

Epoch: 14| Step: 0
Training loss: 3.146603790991244
Validation loss: 3.3827759687407415

Epoch: 6| Step: 1
Training loss: 2.4260751051759692
Validation loss: 3.3704649020097146

Epoch: 6| Step: 2
Training loss: 4.115611402623823
Validation loss: 3.3681982998752664

Epoch: 6| Step: 3
Training loss: 3.5280728521285893
Validation loss: 3.3725243105614546

Epoch: 6| Step: 4
Training loss: 3.652998823690447
Validation loss: 3.365805424765001

Epoch: 6| Step: 5
Training loss: 4.095680305879446
Validation loss: 3.36465257803063

Epoch: 6| Step: 6
Training loss: 3.685927362820219
Validation loss: 3.362076649271214

Epoch: 6| Step: 7
Training loss: 3.4923976348533396
Validation loss: 3.3602334164189496

Epoch: 6| Step: 8
Training loss: 3.4588935275778048
Validation loss: 3.3580309305113922

Epoch: 6| Step: 9
Training loss: 3.8098351592601567
Validation loss: 3.357855555594356

Epoch: 6| Step: 10
Training loss: 3.800549899016208
Validation loss: 3.358618434488055

Epoch: 6| Step: 11
Training loss: 3.4122398976001693
Validation loss: 3.367950764841294

Epoch: 6| Step: 12
Training loss: 3.6871102337210306
Validation loss: 3.360805965829934

Epoch: 6| Step: 13
Training loss: 3.7427341006239856
Validation loss: 3.3520903787980094

Epoch: 15| Step: 0
Training loss: 3.971415668282322
Validation loss: 3.353336962039005

Epoch: 6| Step: 1
Training loss: 3.7208412765526364
Validation loss: 3.361884208870816

Epoch: 6| Step: 2
Training loss: 3.540744407101549
Validation loss: 3.35901643633316

Epoch: 6| Step: 3
Training loss: 4.212328056652325
Validation loss: 3.3539359940061844

Epoch: 6| Step: 4
Training loss: 3.4758235531832984
Validation loss: 3.3461006128183612

Epoch: 6| Step: 5
Training loss: 3.7416325358736526
Validation loss: 3.3453498488452063

Epoch: 6| Step: 6
Training loss: 3.722073520391387
Validation loss: 3.348470764743703

Epoch: 6| Step: 7
Training loss: 3.8716024455276683
Validation loss: 3.341085691788896

Epoch: 6| Step: 8
Training loss: 3.687990834818476
Validation loss: 3.3363683678360134

Epoch: 6| Step: 9
Training loss: 3.1134811203192596
Validation loss: 3.3405158052237534

Epoch: 6| Step: 10
Training loss: 3.1678444194737865
Validation loss: 3.3476479027517527

Epoch: 6| Step: 11
Training loss: 2.7471664742767476
Validation loss: 3.367555592694364

Epoch: 6| Step: 12
Training loss: 3.431081849027231
Validation loss: 3.3457404886099735

Epoch: 6| Step: 13
Training loss: 3.4046263018321046
Validation loss: 3.331875452022779

Epoch: 16| Step: 0
Training loss: 3.2972889138682637
Validation loss: 3.321177144785169

Epoch: 6| Step: 1
Training loss: 4.1640334137263935
Validation loss: 3.3188131102186933

Epoch: 6| Step: 2
Training loss: 3.783869064872311
Validation loss: 3.3154258460148065

Epoch: 6| Step: 3
Training loss: 3.5163878566868565
Validation loss: 3.3158833512197887

Epoch: 6| Step: 4
Training loss: 4.1934730859058575
Validation loss: 3.314437754505106

Epoch: 6| Step: 5
Training loss: 3.6247734788296975
Validation loss: 3.3087948838254753

Epoch: 6| Step: 6
Training loss: 4.079068714143834
Validation loss: 3.310782842091105

Epoch: 6| Step: 7
Training loss: 3.2176842267603094
Validation loss: 3.306622923288111

Epoch: 6| Step: 8
Training loss: 2.8616417410255064
Validation loss: 3.3013558927508355

Epoch: 6| Step: 9
Training loss: 2.71512897557444
Validation loss: 3.303513167889011

Epoch: 6| Step: 10
Training loss: 3.989301440818652
Validation loss: 3.307434574004964

Epoch: 6| Step: 11
Training loss: 3.269451618933947
Validation loss: 3.321514778369359

Epoch: 6| Step: 12
Training loss: 3.6077007687772737
Validation loss: 3.4275709233559204

Epoch: 6| Step: 13
Training loss: 2.6389941534719865
Validation loss: 3.36016194388144

Epoch: 17| Step: 0
Training loss: 3.385230770386919
Validation loss: 3.2990639853494166

Epoch: 6| Step: 1
Training loss: 3.8682097962220054
Validation loss: 3.300693159680913

Epoch: 6| Step: 2
Training loss: 3.6209004339242163
Validation loss: 3.309331321402887

Epoch: 6| Step: 3
Training loss: 4.095377125497581
Validation loss: 3.3235393774816897

Epoch: 6| Step: 4
Training loss: 3.5775639123225917
Validation loss: 3.3099762304508573

Epoch: 6| Step: 5
Training loss: 1.9285616659997156
Validation loss: 3.303800538088056

Epoch: 6| Step: 6
Training loss: 3.1511288633445824
Validation loss: 3.3007705365010924

Epoch: 6| Step: 7
Training loss: 3.4602719736977336
Validation loss: 3.2988414280004146

Epoch: 6| Step: 8
Training loss: 4.15988298691727
Validation loss: 3.2973670252124996

Epoch: 6| Step: 9
Training loss: 3.923164550815252
Validation loss: 3.2955087026267824

Epoch: 6| Step: 10
Training loss: 3.159175008449008
Validation loss: 3.2905512039047493

Epoch: 6| Step: 11
Training loss: 3.517796909405828
Validation loss: 3.2926031369103232

Epoch: 6| Step: 12
Training loss: 3.5042231829996178
Validation loss: 3.295947002361485

Epoch: 6| Step: 13
Training loss: 3.8776509231129297
Validation loss: 3.320318564132567

Epoch: 18| Step: 0
Training loss: 3.6451976694267674
Validation loss: 3.3186288308348963

Epoch: 6| Step: 1
Training loss: 3.9789982438851754
Validation loss: 3.291206530716885

Epoch: 6| Step: 2
Training loss: 2.8390285995886386
Validation loss: 3.2824263144457064

Epoch: 6| Step: 3
Training loss: 2.924240868026408
Validation loss: 3.2795628575246702

Epoch: 6| Step: 4
Training loss: 3.052760928887231
Validation loss: 3.2772915239157476

Epoch: 6| Step: 5
Training loss: 2.6787941558516675
Validation loss: 3.2735963000168686

Epoch: 6| Step: 6
Training loss: 3.4477346474045207
Validation loss: 3.2747271181977267

Epoch: 6| Step: 7
Training loss: 4.333437747186434
Validation loss: 3.2730292045231475

Epoch: 6| Step: 8
Training loss: 3.8637983787960914
Validation loss: 3.269574336030977

Epoch: 6| Step: 9
Training loss: 4.066162805663123
Validation loss: 3.269735074456242

Epoch: 6| Step: 10
Training loss: 3.6679697900025148
Validation loss: 3.270695503099699

Epoch: 6| Step: 11
Training loss: 3.630137650373156
Validation loss: 3.267256644574194

Epoch: 6| Step: 12
Training loss: 2.9112903817219165
Validation loss: 3.2624408184261773

Epoch: 6| Step: 13
Training loss: 3.916707315978007
Validation loss: 3.2644825286340664

Epoch: 19| Step: 0
Training loss: 4.1537105288195715
Validation loss: 3.263459287595022

Epoch: 6| Step: 1
Training loss: 2.8203483431326934
Validation loss: 3.258520296990077

Epoch: 6| Step: 2
Training loss: 3.9068319878951314
Validation loss: 3.25735740131853

Epoch: 6| Step: 3
Training loss: 3.1259405628003623
Validation loss: 3.2568762239371263

Epoch: 6| Step: 4
Training loss: 2.9908916167196478
Validation loss: 3.257349235076604

Epoch: 6| Step: 5
Training loss: 3.0699941067219685
Validation loss: 3.2560136373673263

Epoch: 6| Step: 6
Training loss: 3.889871669898169
Validation loss: 3.262303684017075

Epoch: 6| Step: 7
Training loss: 3.3573767108109718
Validation loss: 3.259404269233431

Epoch: 6| Step: 8
Training loss: 3.654599852569014
Validation loss: 3.255603884317789

Epoch: 6| Step: 9
Training loss: 4.138615188822506
Validation loss: 3.2521685046253372

Epoch: 6| Step: 10
Training loss: 2.9601457085702383
Validation loss: 3.249019392829246

Epoch: 6| Step: 11
Training loss: 2.7042741923611784
Validation loss: 3.2519281061854444

Epoch: 6| Step: 12
Training loss: 4.12707767758984
Validation loss: 3.248628486280844

Epoch: 6| Step: 13
Training loss: 3.699654542415458
Validation loss: 3.247820130235218

Epoch: 20| Step: 0
Training loss: 2.945943992367226
Validation loss: 3.2452858874871615

Epoch: 6| Step: 1
Training loss: 3.84731617310559
Validation loss: 3.2444462380067383

Epoch: 6| Step: 2
Training loss: 2.9323671013912596
Validation loss: 3.2447511000879063

Epoch: 6| Step: 3
Training loss: 3.7001320377194133
Validation loss: 3.2444409739380755

Epoch: 6| Step: 4
Training loss: 3.5342515999781683
Validation loss: 3.248376341343496

Epoch: 6| Step: 5
Training loss: 3.3662406847032007
Validation loss: 3.2801422812027976

Epoch: 6| Step: 6
Training loss: 4.5885892151856185
Validation loss: 3.261454299975252

Epoch: 6| Step: 7
Training loss: 3.1730867523539072
Validation loss: 3.242747586567659

Epoch: 6| Step: 8
Training loss: 2.741483157740497
Validation loss: 3.2373501600004

Epoch: 6| Step: 9
Training loss: 3.504858867726092
Validation loss: 3.237395956534369

Epoch: 6| Step: 10
Training loss: 3.629534417552174
Validation loss: 3.2370912158950085

Epoch: 6| Step: 11
Training loss: 3.204369428855617
Validation loss: 3.236916803013942

Epoch: 6| Step: 12
Training loss: 3.58287299696117
Validation loss: 3.2369334880513896

Epoch: 6| Step: 13
Training loss: 3.8369601686988672
Validation loss: 3.2339259810841052

Epoch: 21| Step: 0
Training loss: 3.096176582978335
Validation loss: 3.2292091935791416

Epoch: 6| Step: 1
Training loss: 4.092514667053599
Validation loss: 3.2292658006983253

Epoch: 6| Step: 2
Training loss: 3.554579647230578
Validation loss: 3.2303320733071614

Epoch: 6| Step: 3
Training loss: 3.0863586910942113
Validation loss: 3.2282723772655313

Epoch: 6| Step: 4
Training loss: 3.398943282450723
Validation loss: 3.224828781335869

Epoch: 6| Step: 5
Training loss: 2.8906149374296985
Validation loss: 3.2254029359239675

Epoch: 6| Step: 6
Training loss: 3.9961099782783873
Validation loss: 3.2241246174288376

Epoch: 6| Step: 7
Training loss: 3.565601805495331
Validation loss: 3.222264613185176

Epoch: 6| Step: 8
Training loss: 3.74837318737327
Validation loss: 3.2231264357940144

Epoch: 6| Step: 9
Training loss: 3.4112197598423597
Validation loss: 3.2206573712919706

Epoch: 6| Step: 10
Training loss: 3.68191117726886
Validation loss: 3.218131039606567

Epoch: 6| Step: 11
Training loss: 2.4472033712714905
Validation loss: 3.2187817009777393

Epoch: 6| Step: 12
Training loss: 3.4220606087289647
Validation loss: 3.2174446815518314

Epoch: 6| Step: 13
Training loss: 4.143335685903219
Validation loss: 3.2165833494666667

Epoch: 22| Step: 0
Training loss: 2.7518040201744016
Validation loss: 3.215629025892892

Epoch: 6| Step: 1
Training loss: 3.5687901696718574
Validation loss: 3.2150977927498667

Epoch: 6| Step: 2
Training loss: 3.499869889157
Validation loss: 3.2117893059314016

Epoch: 6| Step: 3
Training loss: 2.444301603459425
Validation loss: 3.2124207557853217

Epoch: 6| Step: 4
Training loss: 3.535467279566832
Validation loss: 3.2099459244109623

Epoch: 6| Step: 5
Training loss: 3.6365329518780953
Validation loss: 3.2086362537261723

Epoch: 6| Step: 6
Training loss: 3.2615561804546185
Validation loss: 3.2082460250662446

Epoch: 6| Step: 7
Training loss: 3.8834121210403696
Validation loss: 3.2070407098637093

Epoch: 6| Step: 8
Training loss: 3.117295954067657
Validation loss: 3.2057891739057305

Epoch: 6| Step: 9
Training loss: 3.6780202534684765
Validation loss: 3.205239458390322

Epoch: 6| Step: 10
Training loss: 3.8380812114732876
Validation loss: 3.203428423036593

Epoch: 6| Step: 11
Training loss: 3.335635884070477
Validation loss: 3.2025938060309413

Epoch: 6| Step: 12
Training loss: 4.015979320761644
Validation loss: 3.2007870092815236

Epoch: 6| Step: 13
Training loss: 3.505513072642266
Validation loss: 3.20142217074019

Epoch: 23| Step: 0
Training loss: 3.1788769937904786
Validation loss: 3.200199958010603

Epoch: 6| Step: 1
Training loss: 3.6345941584102754
Validation loss: 3.1982125305789673

Epoch: 6| Step: 2
Training loss: 3.84896286210072
Validation loss: 3.197521370602406

Epoch: 6| Step: 3
Training loss: 3.8271555393130714
Validation loss: 3.198634305048005

Epoch: 6| Step: 4
Training loss: 3.1100791248915094
Validation loss: 3.1978738251555727

Epoch: 6| Step: 5
Training loss: 3.4957372046717095
Validation loss: 3.199166778302977

Epoch: 6| Step: 6
Training loss: 3.7463326641504966
Validation loss: 3.2003592335015916

Epoch: 6| Step: 7
Training loss: 3.437872016890187
Validation loss: 3.203882593122475

Epoch: 6| Step: 8
Training loss: 3.588001463397524
Validation loss: 3.199149475585698

Epoch: 6| Step: 9
Training loss: 3.59066560488219
Validation loss: 3.191678830086155

Epoch: 6| Step: 10
Training loss: 3.097026592590054
Validation loss: 3.190339728224644

Epoch: 6| Step: 11
Training loss: 2.9115740503415948
Validation loss: 3.1895753079137092

Epoch: 6| Step: 12
Training loss: 3.159311603698682
Validation loss: 3.189545649175433

Epoch: 6| Step: 13
Training loss: 3.393637869933758
Validation loss: 3.187896034752246

Epoch: 24| Step: 0
Training loss: 3.669536738871773
Validation loss: 3.1873877938081465

Epoch: 6| Step: 1
Training loss: 3.366730342552384
Validation loss: 3.185851645485047

Epoch: 6| Step: 2
Training loss: 4.340388472438245
Validation loss: 3.1851019302583206

Epoch: 6| Step: 3
Training loss: 3.504001781985731
Validation loss: 3.182944719762309

Epoch: 6| Step: 4
Training loss: 3.1673642109681475
Validation loss: 3.182082565272226

Epoch: 6| Step: 5
Training loss: 2.9167507341167678
Validation loss: 3.1820605983793486

Epoch: 6| Step: 6
Training loss: 3.8376041062737642
Validation loss: 3.180575115050991

Epoch: 6| Step: 7
Training loss: 3.693527209797123
Validation loss: 3.178156000321038

Epoch: 6| Step: 8
Training loss: 2.5027384065369627
Validation loss: 3.177423186190823

Epoch: 6| Step: 9
Training loss: 3.5567454658319058
Validation loss: 3.177557028415554

Epoch: 6| Step: 10
Training loss: 3.1752064314888817
Validation loss: 3.1759154342587084

Epoch: 6| Step: 11
Training loss: 3.039363424509336
Validation loss: 3.1749143152396617

Epoch: 6| Step: 12
Training loss: 3.1563012147279705
Validation loss: 3.1740666929180583

Epoch: 6| Step: 13
Training loss: 3.9821531795389915
Validation loss: 3.1774691671049577

Epoch: 25| Step: 0
Training loss: 3.5761076058363384
Validation loss: 3.172216950113173

Epoch: 6| Step: 1
Training loss: 3.1166450200544613
Validation loss: 3.1704325382248855

Epoch: 6| Step: 2
Training loss: 4.152545626192722
Validation loss: 3.1707261208967914

Epoch: 6| Step: 3
Training loss: 3.3564184618961654
Validation loss: 3.1740865764030617

Epoch: 6| Step: 4
Training loss: 3.81068527306654
Validation loss: 3.169525356825579

Epoch: 6| Step: 5
Training loss: 4.282279231966574
Validation loss: 3.1696503178008197

Epoch: 6| Step: 6
Training loss: 3.5547881059767197
Validation loss: 3.170188325633372

Epoch: 6| Step: 7
Training loss: 2.6308425189117584
Validation loss: 3.1673609555900955

Epoch: 6| Step: 8
Training loss: 2.612788908101054
Validation loss: 3.165808446148262

Epoch: 6| Step: 9
Training loss: 3.3495389080142464
Validation loss: 3.1659648289680558

Epoch: 6| Step: 10
Training loss: 3.1478810161706834
Validation loss: 3.164415691781724

Epoch: 6| Step: 11
Training loss: 3.6118023789460776
Validation loss: 3.161631441557489

Epoch: 6| Step: 12
Training loss: 3.371229255224892
Validation loss: 3.1600628190840387

Epoch: 6| Step: 13
Training loss: 2.3507451763028535
Validation loss: 3.1624315116211092

Epoch: 26| Step: 0
Training loss: 3.3031420690118933
Validation loss: 3.161153430990529

Epoch: 6| Step: 1
Training loss: 3.925283098641419
Validation loss: 3.162698079389883

Epoch: 6| Step: 2
Training loss: 3.3149110188919684
Validation loss: 3.162895913070215

Epoch: 6| Step: 3
Training loss: 3.3172765877072394
Validation loss: 3.174763701991659

Epoch: 6| Step: 4
Training loss: 2.91602151184101
Validation loss: 3.1613802790321084

Epoch: 6| Step: 5
Training loss: 3.614913588212606
Validation loss: 3.160154853046875

Epoch: 6| Step: 6
Training loss: 2.720168521933839
Validation loss: 3.1569823239209684

Epoch: 6| Step: 7
Training loss: 3.304975059749899
Validation loss: 3.159906546581689

Epoch: 6| Step: 8
Training loss: 2.8171065011548424
Validation loss: 3.1601255663746257

Epoch: 6| Step: 9
Training loss: 4.26587539329195
Validation loss: 3.15820468678788

Epoch: 6| Step: 10
Training loss: 3.290465864226173
Validation loss: 3.153396721930597

Epoch: 6| Step: 11
Training loss: 3.5390352833356062
Validation loss: 3.1518561597120387

Epoch: 6| Step: 12
Training loss: 3.4427195369443897
Validation loss: 3.150408395693531

Epoch: 6| Step: 13
Training loss: 3.8903922505446857
Validation loss: 3.148453316108984

Epoch: 27| Step: 0
Training loss: 3.750015131601958
Validation loss: 3.1479055605228567

Epoch: 6| Step: 1
Training loss: 3.3917425748561456
Validation loss: 3.1476886534241677

Epoch: 6| Step: 2
Training loss: 3.876133414603106
Validation loss: 3.148279525086041

Epoch: 6| Step: 3
Training loss: 3.243361809642438
Validation loss: 3.152144901076754

Epoch: 6| Step: 4
Training loss: 3.018490551526667
Validation loss: 3.1525664455133118

Epoch: 6| Step: 5
Training loss: 3.9370927145895265
Validation loss: 3.1451245439610926

Epoch: 6| Step: 6
Training loss: 3.6703351627070795
Validation loss: 3.1425273474121247

Epoch: 6| Step: 7
Training loss: 3.4320414813275817
Validation loss: 3.1422528777519667

Epoch: 6| Step: 8
Training loss: 3.0745505089710847
Validation loss: 3.1413935136983535

Epoch: 6| Step: 9
Training loss: 3.6793399330776233
Validation loss: 3.1407158249286837

Epoch: 6| Step: 10
Training loss: 3.1096487260267494
Validation loss: 3.1387896067581496

Epoch: 6| Step: 11
Training loss: 3.557796384752287
Validation loss: 3.1393539819084486

Epoch: 6| Step: 12
Training loss: 2.4389798489434567
Validation loss: 3.136319927952036

Epoch: 6| Step: 13
Training loss: 2.8252636676724734
Validation loss: 3.137573218977391

Epoch: 28| Step: 0
Training loss: 3.8527156813522967
Validation loss: 3.1370622326298196

Epoch: 6| Step: 1
Training loss: 2.9923318773302725
Validation loss: 3.1370789641558483

Epoch: 6| Step: 2
Training loss: 3.8607566923925685
Validation loss: 3.1372724121655886

Epoch: 6| Step: 3
Training loss: 3.7284801995026737
Validation loss: 3.1403318082694933

Epoch: 6| Step: 4
Training loss: 2.634968856540617
Validation loss: 3.14412468302428

Epoch: 6| Step: 5
Training loss: 3.3025218459857144
Validation loss: 3.1567887827440533

Epoch: 6| Step: 6
Training loss: 4.126381844925037
Validation loss: 3.1690608711787407

Epoch: 6| Step: 7
Training loss: 2.046474737970008
Validation loss: 3.1399582140895705

Epoch: 6| Step: 8
Training loss: 3.35333333217047
Validation loss: 3.128295108720442

Epoch: 6| Step: 9
Training loss: 2.851044406594542
Validation loss: 3.1304831050566384

Epoch: 6| Step: 10
Training loss: 4.091725555016872
Validation loss: 3.1319944389562213

Epoch: 6| Step: 11
Training loss: 3.410620868576201
Validation loss: 3.1295976251718107

Epoch: 6| Step: 12
Training loss: 3.3982853997931466
Validation loss: 3.1328652418654603

Epoch: 6| Step: 13
Training loss: 3.1676490330730322
Validation loss: 3.126277714878495

Epoch: 29| Step: 0
Training loss: 3.2701037781839237
Validation loss: 3.1209883012322583

Epoch: 6| Step: 1
Training loss: 3.7853489876916453
Validation loss: 3.1231104144192607

Epoch: 6| Step: 2
Training loss: 3.654072430974863
Validation loss: 3.1244659344834464

Epoch: 6| Step: 3
Training loss: 3.575625416929517
Validation loss: 3.1266884489835824

Epoch: 6| Step: 4
Training loss: 3.9405302467419636
Validation loss: 3.1231657440885394

Epoch: 6| Step: 5
Training loss: 2.8791540238525632
Validation loss: 3.121169550395152

Epoch: 6| Step: 6
Training loss: 3.139081281394085
Validation loss: 3.121281668916872

Epoch: 6| Step: 7
Training loss: 3.806766263279077
Validation loss: 3.1201955142997813

Epoch: 6| Step: 8
Training loss: 3.47380947878865
Validation loss: 3.1200767736189303

Epoch: 6| Step: 9
Training loss: 3.4448014829711275
Validation loss: 3.118945179474388

Epoch: 6| Step: 10
Training loss: 2.9105275166909244
Validation loss: 3.117418221688715

Epoch: 6| Step: 11
Training loss: 3.594143257185755
Validation loss: 3.1187288804123883

Epoch: 6| Step: 12
Training loss: 2.5705430875267474
Validation loss: 3.1177922645830667

Epoch: 6| Step: 13
Training loss: 2.661198841640691
Validation loss: 3.116198422885156

Epoch: 30| Step: 0
Training loss: 3.1766564921496014
Validation loss: 3.115141487106167

Epoch: 6| Step: 1
Training loss: 3.1644531008903223
Validation loss: 3.1150265864335873

Epoch: 6| Step: 2
Training loss: 3.6387046366111
Validation loss: 3.111883480567604

Epoch: 6| Step: 3
Training loss: 3.1261129304838273
Validation loss: 3.1122287272089735

Epoch: 6| Step: 4
Training loss: 3.796987147303708
Validation loss: 3.113793698592062

Epoch: 6| Step: 5
Training loss: 3.47371599914449
Validation loss: 3.114731661671265

Epoch: 6| Step: 6
Training loss: 3.611484324087857
Validation loss: 3.111303802962266

Epoch: 6| Step: 7
Training loss: 3.222288834405821
Validation loss: 3.1105534853526207

Epoch: 6| Step: 8
Training loss: 2.602005654471819
Validation loss: 3.1114841727407083

Epoch: 6| Step: 9
Training loss: 3.4954984872078354
Validation loss: 3.1106363797765844

Epoch: 6| Step: 10
Training loss: 2.94244034258602
Validation loss: 3.1195863489826707

Epoch: 6| Step: 11
Training loss: 4.08014310398832
Validation loss: 3.1082330532888642

Epoch: 6| Step: 12
Training loss: 3.2548434040237324
Validation loss: 3.1027276755428517

Epoch: 6| Step: 13
Training loss: 3.2979274715038542
Validation loss: 3.10005354409977

Epoch: 31| Step: 0
Training loss: 3.3390875423136746
Validation loss: 3.1018692343920393

Epoch: 6| Step: 1
Training loss: 3.169824698622168
Validation loss: 3.098389664250819

Epoch: 6| Step: 2
Training loss: 2.8297883090046323
Validation loss: 3.0979623185448677

Epoch: 6| Step: 3
Training loss: 3.822602192402749
Validation loss: 3.0965613167348987

Epoch: 6| Step: 4
Training loss: 3.164544867021649
Validation loss: 3.097393338032222

Epoch: 6| Step: 5
Training loss: 2.7718554645525133
Validation loss: 3.095508250243298

Epoch: 6| Step: 6
Training loss: 3.3612634363327927
Validation loss: 3.0940055306597163

Epoch: 6| Step: 7
Training loss: 3.615773791892372
Validation loss: 3.094741895961502

Epoch: 6| Step: 8
Training loss: 3.674814938407507
Validation loss: 3.0917688197370063

Epoch: 6| Step: 9
Training loss: 2.8524843998849345
Validation loss: 3.0910949948891076

Epoch: 6| Step: 10
Training loss: 4.622057829484781
Validation loss: 3.0906452017830115

Epoch: 6| Step: 11
Training loss: 3.0848740688940706
Validation loss: 3.0913916273085658

Epoch: 6| Step: 12
Training loss: 2.8553992809607096
Validation loss: 3.086131588517872

Epoch: 6| Step: 13
Training loss: 3.369920935453242
Validation loss: 3.086609087787738

Epoch: 32| Step: 0
Training loss: 4.183028609485993
Validation loss: 3.084329318413645

Epoch: 6| Step: 1
Training loss: 3.3778863503200802
Validation loss: 3.0867182076246937

Epoch: 6| Step: 2
Training loss: 2.941793672091106
Validation loss: 3.0836789060287306

Epoch: 6| Step: 3
Training loss: 3.4026969086948378
Validation loss: 3.0861014822458483

Epoch: 6| Step: 4
Training loss: 2.3347529339010626
Validation loss: 3.094692815362883

Epoch: 6| Step: 5
Training loss: 3.9671680571660723
Validation loss: 3.1018563685122995

Epoch: 6| Step: 6
Training loss: 2.183062166259342
Validation loss: 3.096434515581001

Epoch: 6| Step: 7
Training loss: 3.6504807560602495
Validation loss: 3.075708632141324

Epoch: 6| Step: 8
Training loss: 3.1402885294730236
Validation loss: 3.0730110355581877

Epoch: 6| Step: 9
Training loss: 3.3703207851514994
Validation loss: 3.067530508702592

Epoch: 6| Step: 10
Training loss: 3.897349479073712
Validation loss: 3.067340144238484

Epoch: 6| Step: 11
Training loss: 3.1983294060149405
Validation loss: 3.0676595157952495

Epoch: 6| Step: 12
Training loss: 3.159063312916449
Validation loss: 3.0675380971611625

Epoch: 6| Step: 13
Training loss: 3.4223200539095697
Validation loss: 3.0664177940291912

Epoch: 33| Step: 0
Training loss: 3.49688186713014
Validation loss: 3.0655413123951334

Epoch: 6| Step: 1
Training loss: 3.9239734643628057
Validation loss: 3.0648342944286906

Epoch: 6| Step: 2
Training loss: 3.6736505638909334
Validation loss: 3.064219081246897

Epoch: 6| Step: 3
Training loss: 3.357766409478199
Validation loss: 3.0657727114475297

Epoch: 6| Step: 4
Training loss: 3.514682762188252
Validation loss: 3.0626989872977424

Epoch: 6| Step: 5
Training loss: 3.8022647483429792
Validation loss: 3.064744504796447

Epoch: 6| Step: 6
Training loss: 3.954664209629598
Validation loss: 3.0649388822902313

Epoch: 6| Step: 7
Training loss: 2.9246163793199482
Validation loss: 3.0623163683452033

Epoch: 6| Step: 8
Training loss: 2.3825845578089906
Validation loss: 3.067337794006723

Epoch: 6| Step: 9
Training loss: 2.966294728941363
Validation loss: 3.0671422571089266

Epoch: 6| Step: 10
Training loss: 2.5563003162011517
Validation loss: 3.064248590983207

Epoch: 6| Step: 11
Training loss: 2.040531725307123
Validation loss: 3.0614076314868175

Epoch: 6| Step: 12
Training loss: 4.039500465480864
Validation loss: 3.058548947475022

Epoch: 6| Step: 13
Training loss: 3.086910818617799
Validation loss: 3.057354793591098

Epoch: 34| Step: 0
Training loss: 2.6523342216668873
Validation loss: 3.0568427847678197

Epoch: 6| Step: 1
Training loss: 3.064823125866594
Validation loss: 3.057655172128818

Epoch: 6| Step: 2
Training loss: 3.359266980230987
Validation loss: 3.057114178690747

Epoch: 6| Step: 3
Training loss: 3.877260840669211
Validation loss: 3.0608816317875083

Epoch: 6| Step: 4
Training loss: 3.378246582553467
Validation loss: 3.062493105577783

Epoch: 6| Step: 5
Training loss: 3.2723366427174763
Validation loss: 3.0516414309125612

Epoch: 6| Step: 6
Training loss: 3.4897136758782685
Validation loss: 3.046816433789888

Epoch: 6| Step: 7
Training loss: 3.701909247952754
Validation loss: 3.049301901584244

Epoch: 6| Step: 8
Training loss: 2.7586761937641424
Validation loss: 3.0546786475983696

Epoch: 6| Step: 9
Training loss: 3.253478023198639
Validation loss: 3.075815563228308

Epoch: 6| Step: 10
Training loss: 3.294536611015765
Validation loss: 3.0484959045847764

Epoch: 6| Step: 11
Training loss: 3.587410551544391
Validation loss: 3.0451904823325036

Epoch: 6| Step: 12
Training loss: 2.8368278345867126
Validation loss: 3.0433477918916263

Epoch: 6| Step: 13
Training loss: 4.042648170034658
Validation loss: 3.0422667845351614

Epoch: 35| Step: 0
Training loss: 2.9386485674774394
Validation loss: 3.0516275761860823

Epoch: 6| Step: 1
Training loss: 3.124518395506325
Validation loss: 3.0610590146587615

Epoch: 6| Step: 2
Training loss: 3.7767519087793877
Validation loss: 3.0670371133029346

Epoch: 6| Step: 3
Training loss: 3.1503045010604698
Validation loss: 3.055051137979113

Epoch: 6| Step: 4
Training loss: 3.670208621838795
Validation loss: 3.042577350694986

Epoch: 6| Step: 5
Training loss: 3.001781888109824
Validation loss: 3.036234392728135

Epoch: 6| Step: 6
Training loss: 3.2396079958910176
Validation loss: 3.0340073357201924

Epoch: 6| Step: 7
Training loss: 3.593006355634632
Validation loss: 3.034418457709561

Epoch: 6| Step: 8
Training loss: 3.0281622192489004
Validation loss: 3.032437835086752

Epoch: 6| Step: 9
Training loss: 3.376819543970916
Validation loss: 3.0343715273954883

Epoch: 6| Step: 10
Training loss: 3.404662576052861
Validation loss: 3.031736163441793

Epoch: 6| Step: 11
Training loss: 3.437388192872748
Validation loss: 3.03077076577515

Epoch: 6| Step: 12
Training loss: 2.8809810289462074
Validation loss: 3.029673479417716

Epoch: 6| Step: 13
Training loss: 3.811437740237282
Validation loss: 3.027470756351521

Epoch: 36| Step: 0
Training loss: 3.0758224627945996
Validation loss: 3.025440392624105

Epoch: 6| Step: 1
Training loss: 3.0087289974428924
Validation loss: 3.0282702019370435

Epoch: 6| Step: 2
Training loss: 3.5560707838224572
Validation loss: 3.042913640349785

Epoch: 6| Step: 3
Training loss: 2.901578204102713
Validation loss: 3.0204726929288905

Epoch: 6| Step: 4
Training loss: 3.3368704784339096
Validation loss: 3.026054521377729

Epoch: 6| Step: 5
Training loss: 3.7046271388020724
Validation loss: 3.029207252367881

Epoch: 6| Step: 6
Training loss: 3.472618626325293
Validation loss: 3.049755905889888

Epoch: 6| Step: 7
Training loss: 2.5573429224247533
Validation loss: 3.059605826216955

Epoch: 6| Step: 8
Training loss: 3.378450960565261
Validation loss: 3.0571593141900752

Epoch: 6| Step: 9
Training loss: 3.3226120828132264
Validation loss: 3.0454087365460136

Epoch: 6| Step: 10
Training loss: 3.0655385727515863
Validation loss: 3.0296401720075044

Epoch: 6| Step: 11
Training loss: 3.6210275127521347
Validation loss: 3.0263540929743784

Epoch: 6| Step: 12
Training loss: 3.331193968568265
Validation loss: 3.025998001471231

Epoch: 6| Step: 13
Training loss: 4.218173065296049
Validation loss: 3.027814912362895

Epoch: 37| Step: 0
Training loss: 2.9812919309854227
Validation loss: 3.042018833470671

Epoch: 6| Step: 1
Training loss: 3.3651351869813726
Validation loss: 3.084206470514458

Epoch: 6| Step: 2
Training loss: 3.391489929418222
Validation loss: 3.053404712710049

Epoch: 6| Step: 3
Training loss: 3.112866152632346
Validation loss: 3.029709257271026

Epoch: 6| Step: 4
Training loss: 3.2180305343516444
Validation loss: 3.018594457132044

Epoch: 6| Step: 5
Training loss: 3.2215777077770595
Validation loss: 3.0149445388485288

Epoch: 6| Step: 6
Training loss: 3.88673298128676
Validation loss: 3.0129973286852874

Epoch: 6| Step: 7
Training loss: 3.5187361451006653
Validation loss: 3.0122934758687703

Epoch: 6| Step: 8
Training loss: 2.682808884810965
Validation loss: 3.011333738202632

Epoch: 6| Step: 9
Training loss: 3.64732667402653
Validation loss: 3.007423721584688

Epoch: 6| Step: 10
Training loss: 3.554612110721848
Validation loss: 3.0096525455950074

Epoch: 6| Step: 11
Training loss: 2.6293580345801577
Validation loss: 3.0089636536865503

Epoch: 6| Step: 12
Training loss: 2.947510726171492
Validation loss: 3.007031696701393

Epoch: 6| Step: 13
Training loss: 4.031701351004487
Validation loss: 3.004132944674181

Epoch: 38| Step: 0
Training loss: 4.121606297732808
Validation loss: 3.0050312613589476

Epoch: 6| Step: 1
Training loss: 3.32483707688506
Validation loss: 3.0040376949873626

Epoch: 6| Step: 2
Training loss: 2.5158484697302503
Validation loss: 3.005340978166444

Epoch: 6| Step: 3
Training loss: 3.5066727653663117
Validation loss: 3.0037750262844183

Epoch: 6| Step: 4
Training loss: 3.3347463156141206
Validation loss: 3.003769462489316

Epoch: 6| Step: 5
Training loss: 3.269788214681812
Validation loss: 3.002224997770073

Epoch: 6| Step: 6
Training loss: 3.2516272945813163
Validation loss: 3.001096453313618

Epoch: 6| Step: 7
Training loss: 3.547474545796794
Validation loss: 2.9978361974372603

Epoch: 6| Step: 8
Training loss: 3.411444945952183
Validation loss: 3.001167970696433

Epoch: 6| Step: 9
Training loss: 2.8635360375426853
Validation loss: 3.007029994161375

Epoch: 6| Step: 10
Training loss: 3.1703831965129914
Validation loss: 3.0221996079028997

Epoch: 6| Step: 11
Training loss: 2.582620758305735
Validation loss: 3.018106655018489

Epoch: 6| Step: 12
Training loss: 3.6779401319484224
Validation loss: 3.033204699593282

Epoch: 6| Step: 13
Training loss: 2.7513941785374367
Validation loss: 3.0021988277671423

Epoch: 39| Step: 0
Training loss: 3.7763705967546675
Validation loss: 2.9948677014101204

Epoch: 6| Step: 1
Training loss: 3.2304826249513097
Validation loss: 2.9945837335865035

Epoch: 6| Step: 2
Training loss: 3.446532986948907
Validation loss: 2.9938348282560145

Epoch: 6| Step: 3
Training loss: 2.807413036055986
Validation loss: 2.9942482087197875

Epoch: 6| Step: 4
Training loss: 3.7409966790073135
Validation loss: 2.993862284317993

Epoch: 6| Step: 5
Training loss: 4.023761743609572
Validation loss: 2.9925382649455545

Epoch: 6| Step: 6
Training loss: 3.3934837279002
Validation loss: 2.992649673799565

Epoch: 6| Step: 7
Training loss: 3.4645299586628857
Validation loss: 2.993203277885045

Epoch: 6| Step: 8
Training loss: 2.50307237662674
Validation loss: 2.9898816437548477

Epoch: 6| Step: 9
Training loss: 2.693397527234993
Validation loss: 2.9925185458745367

Epoch: 6| Step: 10
Training loss: 2.9623984403947623
Validation loss: 2.9927102637403675

Epoch: 6| Step: 11
Training loss: 2.874834802276621
Validation loss: 2.991138933494312

Epoch: 6| Step: 12
Training loss: 3.1272343086802303
Validation loss: 2.9886064425800885

Epoch: 6| Step: 13
Training loss: 3.371990133305026
Validation loss: 2.9891539085854615

Epoch: 40| Step: 0
Training loss: 3.2757804697746806
Validation loss: 2.984450251004178

Epoch: 6| Step: 1
Training loss: 3.976519091655881
Validation loss: 2.987459283497126

Epoch: 6| Step: 2
Training loss: 3.0169739547379084
Validation loss: 2.985622533320612

Epoch: 6| Step: 3
Training loss: 2.9771734296558914
Validation loss: 2.985355538463296

Epoch: 6| Step: 4
Training loss: 2.4479395006345825
Validation loss: 2.9863737500371594

Epoch: 6| Step: 5
Training loss: 4.020677052888362
Validation loss: 2.98986026258359

Epoch: 6| Step: 6
Training loss: 3.4010872168457835
Validation loss: 3.006895215068053

Epoch: 6| Step: 7
Training loss: 2.951764797630771
Validation loss: 3.0305370781773853

Epoch: 6| Step: 8
Training loss: 3.0404485763067948
Validation loss: 3.0368450884282394

Epoch: 6| Step: 9
Training loss: 2.870941946986018
Validation loss: 3.042515593387919

Epoch: 6| Step: 10
Training loss: 3.314684021909192
Validation loss: 3.040728151299965

Epoch: 6| Step: 11
Training loss: 3.5060002800723202
Validation loss: 3.0048801583234357

Epoch: 6| Step: 12
Training loss: 3.348298588735935
Validation loss: 2.9791223350741465

Epoch: 6| Step: 13
Training loss: 3.3410827836916086
Validation loss: 2.9820168822427355

Epoch: 41| Step: 0
Training loss: 3.018132091647388
Validation loss: 2.979436730632328

Epoch: 6| Step: 1
Training loss: 3.677551297388233
Validation loss: 2.988277051444029

Epoch: 6| Step: 2
Training loss: 3.008977491006178
Validation loss: 3.0057615470935692

Epoch: 6| Step: 3
Training loss: 3.1470850460560125
Validation loss: 3.0085182720304076

Epoch: 6| Step: 4
Training loss: 3.6008207339279945
Validation loss: 2.998351249062848

Epoch: 6| Step: 5
Training loss: 3.4665091209803336
Validation loss: 2.9811671366171635

Epoch: 6| Step: 6
Training loss: 2.555052938192822
Validation loss: 2.97623747646412

Epoch: 6| Step: 7
Training loss: 3.5693553083862195
Validation loss: 2.9736364816980823

Epoch: 6| Step: 8
Training loss: 3.1975360026655344
Validation loss: 2.9713896634542074

Epoch: 6| Step: 9
Training loss: 3.4265094187635032
Validation loss: 2.96719652170309

Epoch: 6| Step: 10
Training loss: 3.1027353216864033
Validation loss: 2.968168546063157

Epoch: 6| Step: 11
Training loss: 3.945675914380917
Validation loss: 2.967306856033199

Epoch: 6| Step: 12
Training loss: 3.0340280289282537
Validation loss: 2.967268860465107

Epoch: 6| Step: 13
Training loss: 2.0107401717677487
Validation loss: 2.9782066292794247

Epoch: 42| Step: 0
Training loss: 2.830100702441861
Validation loss: 2.9862950827253987

Epoch: 6| Step: 1
Training loss: 3.030743900797974
Validation loss: 3.001418256158446

Epoch: 6| Step: 2
Training loss: 3.4290160475539224
Validation loss: 3.0231018990926564

Epoch: 6| Step: 3
Training loss: 3.429624656848798
Validation loss: 3.0499377460672483

Epoch: 6| Step: 4
Training loss: 3.1438384815300577
Validation loss: 2.976530785941125

Epoch: 6| Step: 5
Training loss: 3.3605549004430206
Validation loss: 2.9654857614783894

Epoch: 6| Step: 6
Training loss: 3.5098786587947584
Validation loss: 2.9673434420103133

Epoch: 6| Step: 7
Training loss: 2.916175710138177
Validation loss: 2.97294509241384

Epoch: 6| Step: 8
Training loss: 2.66201031977074
Validation loss: 2.9691866179603266

Epoch: 6| Step: 9
Training loss: 3.9308491804234666
Validation loss: 2.9662122759602854

Epoch: 6| Step: 10
Training loss: 2.2821425690577204
Validation loss: 2.963208654736943

Epoch: 6| Step: 11
Training loss: 3.9938520630404724
Validation loss: 2.960513316233103

Epoch: 6| Step: 12
Training loss: 3.62953507443686
Validation loss: 2.958945877483761

Epoch: 6| Step: 13
Training loss: 2.828813837791705
Validation loss: 2.9592936313553486

Epoch: 43| Step: 0
Training loss: 3.535911791240637
Validation loss: 2.957225960311607

Epoch: 6| Step: 1
Training loss: 2.4005016676792295
Validation loss: 2.9579097410454454

Epoch: 6| Step: 2
Training loss: 3.5595851819391076
Validation loss: 2.959267179585851

Epoch: 6| Step: 3
Training loss: 2.992705855527322
Validation loss: 2.9549238537470544

Epoch: 6| Step: 4
Training loss: 3.275766204428243
Validation loss: 2.9545561371987428

Epoch: 6| Step: 5
Training loss: 3.050622445050533
Validation loss: 2.9527410581096656

Epoch: 6| Step: 6
Training loss: 2.8357167223699915
Validation loss: 2.9534431889872006

Epoch: 6| Step: 7
Training loss: 2.746610459922318
Validation loss: 2.9638898339205184

Epoch: 6| Step: 8
Training loss: 3.4912002840746545
Validation loss: 2.9775826284329527

Epoch: 6| Step: 9
Training loss: 4.202001031395242
Validation loss: 2.956084321309484

Epoch: 6| Step: 10
Training loss: 3.788960311927446
Validation loss: 2.9504599516298717

Epoch: 6| Step: 11
Training loss: 3.2918393697380233
Validation loss: 2.9515492478747625

Epoch: 6| Step: 12
Training loss: 2.6554378389880897
Validation loss: 2.9507980663182423

Epoch: 6| Step: 13
Training loss: 2.813344108220419
Validation loss: 2.949813071617333

Epoch: 44| Step: 0
Training loss: 3.7598921955156395
Validation loss: 2.9517060526891257

Epoch: 6| Step: 1
Training loss: 2.95246774938478
Validation loss: 2.961086715222913

Epoch: 6| Step: 2
Training loss: 3.375530483799266
Validation loss: 2.9662335181803496

Epoch: 6| Step: 3
Training loss: 3.160255232535123
Validation loss: 2.971831467163217

Epoch: 6| Step: 4
Training loss: 2.5324626890486144
Validation loss: 2.9614568879208294

Epoch: 6| Step: 5
Training loss: 2.712411353425068
Validation loss: 2.973163592003965

Epoch: 6| Step: 6
Training loss: 3.3443078262064607
Validation loss: 2.9596671570067437

Epoch: 6| Step: 7
Training loss: 2.9263737769919302
Validation loss: 2.9591137643630465

Epoch: 6| Step: 8
Training loss: 3.472844636868481
Validation loss: 2.9481099505000388

Epoch: 6| Step: 9
Training loss: 3.2041407021477935
Validation loss: 2.9449974560261336

Epoch: 6| Step: 10
Training loss: 3.613813965164352
Validation loss: 2.9443258686791762

Epoch: 6| Step: 11
Training loss: 3.266219819575841
Validation loss: 2.944117912489579

Epoch: 6| Step: 12
Training loss: 3.023655925421157
Validation loss: 2.9422782273631647

Epoch: 6| Step: 13
Training loss: 4.187386810139409
Validation loss: 2.9435475292533266

Epoch: 45| Step: 0
Training loss: 2.8904227521096435
Validation loss: 2.950669031699027

Epoch: 6| Step: 1
Training loss: 3.233451527142683
Validation loss: 2.950795598068661

Epoch: 6| Step: 2
Training loss: 3.39452113598896
Validation loss: 2.9526321747356605

Epoch: 6| Step: 3
Training loss: 3.1648322028686535
Validation loss: 2.9533523556258645

Epoch: 6| Step: 4
Training loss: 3.3938046501915973
Validation loss: 2.9481794349690764

Epoch: 6| Step: 5
Training loss: 4.072878682121202
Validation loss: 2.9413976179607806

Epoch: 6| Step: 6
Training loss: 3.073162900897722
Validation loss: 2.9418662145919208

Epoch: 6| Step: 7
Training loss: 3.6292763840521127
Validation loss: 2.939166582230708

Epoch: 6| Step: 8
Training loss: 2.9757562781998956
Validation loss: 2.9355463099687737

Epoch: 6| Step: 9
Training loss: 3.7134600287510615
Validation loss: 2.9343674153793833

Epoch: 6| Step: 10
Training loss: 2.6538547262693357
Validation loss: 2.9302797655426334

Epoch: 6| Step: 11
Training loss: 3.07949349437286
Validation loss: 2.9312503741843714

Epoch: 6| Step: 12
Training loss: 2.854862174800979
Validation loss: 2.9291193953133643

Epoch: 6| Step: 13
Training loss: 2.036611669935192
Validation loss: 2.9300427756973364

Epoch: 46| Step: 0
Training loss: 3.1574508346632144
Validation loss: 2.928645000310401

Epoch: 6| Step: 1
Training loss: 4.326264680508514
Validation loss: 2.927236457024811

Epoch: 6| Step: 2
Training loss: 3.625115754482667
Validation loss: 2.9268489955940837

Epoch: 6| Step: 3
Training loss: 3.594112742817211
Validation loss: 2.9265903356537173

Epoch: 6| Step: 4
Training loss: 3.1465928800735705
Validation loss: 2.9269819767960765

Epoch: 6| Step: 5
Training loss: 2.8707275157042313
Validation loss: 2.928002450348212

Epoch: 6| Step: 6
Training loss: 3.548882945366346
Validation loss: 2.939712052842432

Epoch: 6| Step: 7
Training loss: 2.7900162463244973
Validation loss: 2.9490013519982696

Epoch: 6| Step: 8
Training loss: 3.271785929432087
Validation loss: 2.929740190148386

Epoch: 6| Step: 9
Training loss: 3.3351864114390746
Validation loss: 2.9230874760302616

Epoch: 6| Step: 10
Training loss: 2.7285650818151073
Validation loss: 2.920921411798765

Epoch: 6| Step: 11
Training loss: 2.423716577119448
Validation loss: 2.9217047872905773

Epoch: 6| Step: 12
Training loss: 2.6130849995501997
Validation loss: 2.917004315803728

Epoch: 6| Step: 13
Training loss: 2.8666931890399243
Validation loss: 2.9193309434415804

Epoch: 47| Step: 0
Training loss: 3.5496629689300314
Validation loss: 2.9176050273474936

Epoch: 6| Step: 1
Training loss: 3.1807937384814338
Validation loss: 2.914056662866221

Epoch: 6| Step: 2
Training loss: 3.593156583139264
Validation loss: 2.915355936035841

Epoch: 6| Step: 3
Training loss: 3.539646395248197
Validation loss: 2.9141217688992955

Epoch: 6| Step: 4
Training loss: 2.815040966433738
Validation loss: 2.912288976026898

Epoch: 6| Step: 5
Training loss: 3.4060405701815495
Validation loss: 2.913194553891629

Epoch: 6| Step: 6
Training loss: 2.7421097703660253
Validation loss: 2.912301039410304

Epoch: 6| Step: 7
Training loss: 3.2405322158170327
Validation loss: 2.911354448028514

Epoch: 6| Step: 8
Training loss: 2.6908014999433103
Validation loss: 2.9101447556175

Epoch: 6| Step: 9
Training loss: 2.5349165181515945
Validation loss: 2.9112741084529734

Epoch: 6| Step: 10
Training loss: 3.764068915146697
Validation loss: 2.9120334985568803

Epoch: 6| Step: 11
Training loss: 2.8097392625763926
Validation loss: 2.9332854548328937

Epoch: 6| Step: 12
Training loss: 3.230381956399044
Validation loss: 2.9397384189497218

Epoch: 6| Step: 13
Training loss: 3.7219115850410516
Validation loss: 2.9824593147839513

Epoch: 48| Step: 0
Training loss: 3.47442355417607
Validation loss: 2.937077293100056

Epoch: 6| Step: 1
Training loss: 3.625789950885784
Validation loss: 2.906345099036559

Epoch: 6| Step: 2
Training loss: 2.7552692908963445
Validation loss: 2.905363427748103

Epoch: 6| Step: 3
Training loss: 2.9377124790694165
Validation loss: 2.907859516223803

Epoch: 6| Step: 4
Training loss: 2.794983975768857
Validation loss: 2.91049575251328

Epoch: 6| Step: 5
Training loss: 3.7757893374968345
Validation loss: 2.9099724753891887

Epoch: 6| Step: 6
Training loss: 3.223466990821834
Validation loss: 2.9110833874144015

Epoch: 6| Step: 7
Training loss: 3.165204480211396
Validation loss: 2.9139586579752135

Epoch: 6| Step: 8
Training loss: 3.4751588195075027
Validation loss: 2.9121148163642907

Epoch: 6| Step: 9
Training loss: 2.5476613147337823
Validation loss: 2.9099897258954797

Epoch: 6| Step: 10
Training loss: 3.0695049592540578
Validation loss: 2.9088283947528693

Epoch: 6| Step: 11
Training loss: 3.5019438658898787
Validation loss: 2.9053581766875776

Epoch: 6| Step: 12
Training loss: 2.670837557864208
Validation loss: 2.9040279196449053

Epoch: 6| Step: 13
Training loss: 3.7794410855480227
Validation loss: 2.90248638533462

Epoch: 49| Step: 0
Training loss: 3.169760163437193
Validation loss: 2.90163975213875

Epoch: 6| Step: 1
Training loss: 2.451059917917537
Validation loss: 2.8993241546278603

Epoch: 6| Step: 2
Training loss: 3.5346034508223734
Validation loss: 2.89979927257979

Epoch: 6| Step: 3
Training loss: 3.6405787649206696
Validation loss: 2.8986678882540873

Epoch: 6| Step: 4
Training loss: 2.8300174682940757
Validation loss: 2.8999015317556727

Epoch: 6| Step: 5
Training loss: 3.5667217737616963
Validation loss: 2.900382355267029

Epoch: 6| Step: 6
Training loss: 3.0058428768228196
Validation loss: 2.8992767821500696

Epoch: 6| Step: 7
Training loss: 3.203987117212806
Validation loss: 2.9032281113915084

Epoch: 6| Step: 8
Training loss: 3.226636243813383
Validation loss: 2.921476505312055

Epoch: 6| Step: 9
Training loss: 3.3090867505061707
Validation loss: 2.9420741565364756

Epoch: 6| Step: 10
Training loss: 3.2308377443811036
Validation loss: 2.910142281077499

Epoch: 6| Step: 11
Training loss: 3.294884826777488
Validation loss: 2.8997931070327576

Epoch: 6| Step: 12
Training loss: 3.0113029539298566
Validation loss: 2.89571745445812

Epoch: 6| Step: 13
Training loss: 2.8011232643447204
Validation loss: 2.8944116695327917

Epoch: 50| Step: 0
Training loss: 3.651784664344437
Validation loss: 2.8955621923668295

Epoch: 6| Step: 1
Training loss: 3.5936356236044937
Validation loss: 2.8917667811201695

Epoch: 6| Step: 2
Training loss: 3.5139051511553236
Validation loss: 2.8908684173236145

Epoch: 6| Step: 3
Training loss: 2.768990833839022
Validation loss: 2.8895890702992113

Epoch: 6| Step: 4
Training loss: 2.830211733658177
Validation loss: 2.889919978366409

Epoch: 6| Step: 5
Training loss: 3.245769094305663
Validation loss: 2.8894515476274263

Epoch: 6| Step: 6
Training loss: 3.416774065764298
Validation loss: 2.891123446276376

Epoch: 6| Step: 7
Training loss: 3.2790674125905794
Validation loss: 2.889827376328654

Epoch: 6| Step: 8
Training loss: 3.2469347657328758
Validation loss: 2.8899092719674866

Epoch: 6| Step: 9
Training loss: 2.7386200133432403
Validation loss: 2.8888636807306085

Epoch: 6| Step: 10
Training loss: 2.9451727796041425
Validation loss: 2.8865763257934844

Epoch: 6| Step: 11
Training loss: 3.1239762727468894
Validation loss: 2.8874765914112324

Epoch: 6| Step: 12
Training loss: 2.826602504904721
Validation loss: 2.8833999282066842

Epoch: 6| Step: 13
Training loss: 3.2517808290036228
Validation loss: 2.885425131517978

Epoch: 51| Step: 0
Training loss: 3.1318918145253076
Validation loss: 2.8819592127887166

Epoch: 6| Step: 1
Training loss: 3.0734375248236527
Validation loss: 2.880930118404796

Epoch: 6| Step: 2
Training loss: 3.1187850185714034
Validation loss: 2.8920892618074125

Epoch: 6| Step: 3
Training loss: 3.893320643478337
Validation loss: 2.9015892164394477

Epoch: 6| Step: 4
Training loss: 2.405450266921622
Validation loss: 2.9110257079019384

Epoch: 6| Step: 5
Training loss: 3.1828840155003966
Validation loss: 2.918721252090436

Epoch: 6| Step: 6
Training loss: 3.3286102371011643
Validation loss: 2.9343994401005724

Epoch: 6| Step: 7
Training loss: 3.1959186156298616
Validation loss: 2.928841301895065

Epoch: 6| Step: 8
Training loss: 3.449329067725498
Validation loss: 2.8943129808381793

Epoch: 6| Step: 9
Training loss: 2.8145320756839336
Validation loss: 2.8747082937239377

Epoch: 6| Step: 10
Training loss: 3.1482845297632616
Validation loss: 2.874692444760386

Epoch: 6| Step: 11
Training loss: 3.577550183896564
Validation loss: 2.8790885072949335

Epoch: 6| Step: 12
Training loss: 2.5935928113255313
Validation loss: 2.879186162295971

Epoch: 6| Step: 13
Training loss: 3.3738835218818792
Validation loss: 2.884964540825648

Epoch: 52| Step: 0
Training loss: 2.5715272577967268
Validation loss: 2.8901860545452207

Epoch: 6| Step: 1
Training loss: 3.045197010150155
Validation loss: 2.8843675504362114

Epoch: 6| Step: 2
Training loss: 3.4709858604765205
Validation loss: 2.8775429146682123

Epoch: 6| Step: 3
Training loss: 3.70555041756211
Validation loss: 2.8757345911646843

Epoch: 6| Step: 4
Training loss: 3.3982461108104975
Validation loss: 2.8765982153245306

Epoch: 6| Step: 5
Training loss: 3.461185213958818
Validation loss: 2.875998303622503

Epoch: 6| Step: 6
Training loss: 3.51691911402956
Validation loss: 2.872385138669311

Epoch: 6| Step: 7
Training loss: 3.620063314147627
Validation loss: 2.8726679406482654

Epoch: 6| Step: 8
Training loss: 2.3919576284043043
Validation loss: 2.870578429704718

Epoch: 6| Step: 9
Training loss: 2.8147198711476507
Validation loss: 2.86796857422601

Epoch: 6| Step: 10
Training loss: 2.9190287879603734
Validation loss: 2.8678668033531944

Epoch: 6| Step: 11
Training loss: 2.4130294218897874
Validation loss: 2.867582129656853

Epoch: 6| Step: 12
Training loss: 3.5892774531656397
Validation loss: 2.8663619795159696

Epoch: 6| Step: 13
Training loss: 3.030244798245264
Validation loss: 2.8651914217756804

Epoch: 53| Step: 0
Training loss: 3.1759324454226325
Validation loss: 2.8655390697627436

Epoch: 6| Step: 1
Training loss: 2.4819157742542237
Validation loss: 2.864419630338146

Epoch: 6| Step: 2
Training loss: 3.4806071210043417
Validation loss: 2.8644666458184234

Epoch: 6| Step: 3
Training loss: 3.2779885204549415
Validation loss: 2.863293464347073

Epoch: 6| Step: 4
Training loss: 3.445706091995095
Validation loss: 2.862343999367305

Epoch: 6| Step: 5
Training loss: 2.950061319004856
Validation loss: 2.8609572982288984

Epoch: 6| Step: 6
Training loss: 3.1236886897182052
Validation loss: 2.8614365146110825

Epoch: 6| Step: 7
Training loss: 2.753934300056615
Validation loss: 2.8612112981587168

Epoch: 6| Step: 8
Training loss: 2.9882509317293695
Validation loss: 2.8593184561192837

Epoch: 6| Step: 9
Training loss: 4.031751971078929
Validation loss: 2.8582290728220987

Epoch: 6| Step: 10
Training loss: 3.262237690286348
Validation loss: 2.86098782385612

Epoch: 6| Step: 11
Training loss: 3.194022890738653
Validation loss: 2.8582094783515832

Epoch: 6| Step: 12
Training loss: 3.1223328461814814
Validation loss: 2.8581102966619407

Epoch: 6| Step: 13
Training loss: 2.1410545419358633
Validation loss: 2.8648037435060507

Epoch: 54| Step: 0
Training loss: 2.797772652410341
Validation loss: 2.8934064126523875

Epoch: 6| Step: 1
Training loss: 3.5942308187180543
Validation loss: 2.935576722816412

Epoch: 6| Step: 2
Training loss: 3.1667785290151023
Validation loss: 2.947998604628035

Epoch: 6| Step: 3
Training loss: 3.432311980786022
Validation loss: 2.8946376594596686

Epoch: 6| Step: 4
Training loss: 2.6916566685194647
Validation loss: 2.8531990671620453

Epoch: 6| Step: 5
Training loss: 3.511640808802054
Validation loss: 2.855936275336886

Epoch: 6| Step: 6
Training loss: 2.6901394502308302
Validation loss: 2.858594469033356

Epoch: 6| Step: 7
Training loss: 2.980266679185764
Validation loss: 2.8636538926142845

Epoch: 6| Step: 8
Training loss: 2.6893580910950985
Validation loss: 2.863198142349563

Epoch: 6| Step: 9
Training loss: 3.2297043547538853
Validation loss: 2.8712930201242086

Epoch: 6| Step: 10
Training loss: 3.257556200808855
Validation loss: 2.875419719817039

Epoch: 6| Step: 11
Training loss: 3.0665340712809876
Validation loss: 2.866769492889573

Epoch: 6| Step: 12
Training loss: 3.7572852258474576
Validation loss: 2.863682341670042

Epoch: 6| Step: 13
Training loss: 3.4704874172381044
Validation loss: 2.8600895696684248

Epoch: 55| Step: 0
Training loss: 3.383881926260008
Validation loss: 2.860167524145789

Epoch: 6| Step: 1
Training loss: 3.1710465575487223
Validation loss: 2.8538229399790884

Epoch: 6| Step: 2
Training loss: 2.4926082052697387
Validation loss: 2.8488023935758418

Epoch: 6| Step: 3
Training loss: 3.2025664051803586
Validation loss: 2.8477076941858015

Epoch: 6| Step: 4
Training loss: 3.37790696025348
Validation loss: 2.8469308712252666

Epoch: 6| Step: 5
Training loss: 2.9774096627548117
Validation loss: 2.8439684376824403

Epoch: 6| Step: 6
Training loss: 3.954308856515237
Validation loss: 2.8480828546608246

Epoch: 6| Step: 7
Training loss: 3.08170292680478
Validation loss: 2.8401034401839427

Epoch: 6| Step: 8
Training loss: 2.870872187985905
Validation loss: 2.843338351614635

Epoch: 6| Step: 9
Training loss: 3.042606278305281
Validation loss: 2.8394876843013312

Epoch: 6| Step: 10
Training loss: 3.1834577472867087
Validation loss: 2.842206388843691

Epoch: 6| Step: 11
Training loss: 2.9772568741322725
Validation loss: 2.845787687666301

Epoch: 6| Step: 12
Training loss: 3.158714918236906
Validation loss: 2.84377802929998

Epoch: 6| Step: 13
Training loss: 2.919495291790871
Validation loss: 2.8394443750043155

Epoch: 56| Step: 0
Training loss: 3.2671811717194212
Validation loss: 2.839078979274599

Epoch: 6| Step: 1
Training loss: 2.953184096940928
Validation loss: 2.841667723722414

Epoch: 6| Step: 2
Training loss: 3.2189717633044967
Validation loss: 2.8471980583018586

Epoch: 6| Step: 3
Training loss: 2.832096241172375
Validation loss: 2.8597859482319596

Epoch: 6| Step: 4
Training loss: 3.3288017623607002
Validation loss: 2.8606772010297576

Epoch: 6| Step: 5
Training loss: 3.642032465832469
Validation loss: 2.8333551477199315

Epoch: 6| Step: 6
Training loss: 2.42541275051185
Validation loss: 2.833191526677785

Epoch: 6| Step: 7
Training loss: 3.722209955704501
Validation loss: 2.8346445631376067

Epoch: 6| Step: 8
Training loss: 3.221676283294276
Validation loss: 2.8349787357757825

Epoch: 6| Step: 9
Training loss: 2.9673712490210256
Validation loss: 2.8364317460556707

Epoch: 6| Step: 10
Training loss: 3.8421329725568576
Validation loss: 2.836451076115533

Epoch: 6| Step: 11
Training loss: 2.77012974307839
Validation loss: 2.836958179438305

Epoch: 6| Step: 12
Training loss: 2.888691683502063
Validation loss: 2.8364080078714204

Epoch: 6| Step: 13
Training loss: 1.8930726404212863
Validation loss: 2.8393558655724456

Epoch: 57| Step: 0
Training loss: 2.9576636259293427
Validation loss: 2.845760285342286

Epoch: 6| Step: 1
Training loss: 3.321779030447995
Validation loss: 2.8447720542341575

Epoch: 6| Step: 2
Training loss: 3.4991764734622404
Validation loss: 2.837421812211075

Epoch: 6| Step: 3
Training loss: 2.800275727728638
Validation loss: 2.831298589421906

Epoch: 6| Step: 4
Training loss: 3.431393557465512
Validation loss: 2.8305053483588045

Epoch: 6| Step: 5
Training loss: 2.750627792831976
Validation loss: 2.8285206166940173

Epoch: 6| Step: 6
Training loss: 2.9268001722618595
Validation loss: 2.8277481671980107

Epoch: 6| Step: 7
Training loss: 3.4218089476180613
Validation loss: 2.82702725823574

Epoch: 6| Step: 8
Training loss: 3.3505775409305314
Validation loss: 2.824062228643542

Epoch: 6| Step: 9
Training loss: 3.2759193353095672
Validation loss: 2.8238688765809123

Epoch: 6| Step: 10
Training loss: 2.925671726922031
Validation loss: 2.825251235375258

Epoch: 6| Step: 11
Training loss: 2.6494879425805355
Validation loss: 2.8267109300532147

Epoch: 6| Step: 12
Training loss: 3.0513420029224565
Validation loss: 2.832417015701593

Epoch: 6| Step: 13
Training loss: 3.6315504937908596
Validation loss: 2.831939099672219

Epoch: 58| Step: 0
Training loss: 2.30221414553986
Validation loss: 2.834428895424183

Epoch: 6| Step: 1
Training loss: 2.90129980357631
Validation loss: 2.8383614576127743

Epoch: 6| Step: 2
Training loss: 3.29402739136731
Validation loss: 2.8385668413743614

Epoch: 6| Step: 3
Training loss: 2.909691362563806
Validation loss: 2.82621678551677

Epoch: 6| Step: 4
Training loss: 3.818660074476949
Validation loss: 2.8250584302197947

Epoch: 6| Step: 5
Training loss: 3.044123419506587
Validation loss: 2.820318602963627

Epoch: 6| Step: 6
Training loss: 3.23755728770351
Validation loss: 2.818710221511792

Epoch: 6| Step: 7
Training loss: 3.093436793647005
Validation loss: 2.8151427109603016

Epoch: 6| Step: 8
Training loss: 2.881174009566392
Validation loss: 2.815294768114392

Epoch: 6| Step: 9
Training loss: 2.799521616532565
Validation loss: 2.815563983995215

Epoch: 6| Step: 10
Training loss: 3.5843920067913344
Validation loss: 2.8192577215028067

Epoch: 6| Step: 11
Training loss: 3.179004942720644
Validation loss: 2.8185148050381814

Epoch: 6| Step: 12
Training loss: 3.184242079546526
Validation loss: 2.8202990450728582

Epoch: 6| Step: 13
Training loss: 3.3669771982887537
Validation loss: 2.814477736981092

Epoch: 59| Step: 0
Training loss: 3.4241346449448256
Validation loss: 2.8113562898440527

Epoch: 6| Step: 1
Training loss: 3.1935331804765528
Validation loss: 2.809935952621065

Epoch: 6| Step: 2
Training loss: 2.907051878202141
Validation loss: 2.8091005734627674

Epoch: 6| Step: 3
Training loss: 2.904592061642334
Validation loss: 2.8103430084420595

Epoch: 6| Step: 4
Training loss: 3.2102391581112
Validation loss: 2.8113285099662537

Epoch: 6| Step: 5
Training loss: 3.203974764616189
Validation loss: 2.8100654520215684

Epoch: 6| Step: 6
Training loss: 3.6144121699340657
Validation loss: 2.805765141983079

Epoch: 6| Step: 7
Training loss: 3.0963754014211324
Validation loss: 2.809387021068298

Epoch: 6| Step: 8
Training loss: 2.7778082994267725
Validation loss: 2.808220379008898

Epoch: 6| Step: 9
Training loss: 2.680124853271947
Validation loss: 2.8068541214105225

Epoch: 6| Step: 10
Training loss: 2.786645263866508
Validation loss: 2.805264718887314

Epoch: 6| Step: 11
Training loss: 3.432574818595205
Validation loss: 2.803228675244849

Epoch: 6| Step: 12
Training loss: 2.8903922322350217
Validation loss: 2.824116966625938

Epoch: 6| Step: 13
Training loss: 3.521489655908062
Validation loss: 2.832878071391392

Epoch: 60| Step: 0
Training loss: 2.6708252389421165
Validation loss: 2.861779399696755

Epoch: 6| Step: 1
Training loss: 2.652835491367038
Validation loss: 2.898823194483852

Epoch: 6| Step: 2
Training loss: 3.4630594400652157
Validation loss: 2.940103829510437

Epoch: 6| Step: 3
Training loss: 3.104154719045974
Validation loss: 2.92827079531592

Epoch: 6| Step: 4
Training loss: 3.3400517627565396
Validation loss: 2.907529831628158

Epoch: 6| Step: 5
Training loss: 3.4109565346396855
Validation loss: 2.8613532494498854

Epoch: 6| Step: 6
Training loss: 3.4001348356550163
Validation loss: 2.8016645035629186

Epoch: 6| Step: 7
Training loss: 3.0819962841608124
Validation loss: 2.805217839827517

Epoch: 6| Step: 8
Training loss: 3.272961420295118
Validation loss: 2.812299056263764

Epoch: 6| Step: 9
Training loss: 2.8609781409251562
Validation loss: 2.8441591992739648

Epoch: 6| Step: 10
Training loss: 3.024165260592824
Validation loss: 2.8628355070808755

Epoch: 6| Step: 11
Training loss: 3.4822570111353874
Validation loss: 2.8795779350402366

Epoch: 6| Step: 12
Training loss: 3.466985855324551
Validation loss: 2.8227156392057844

Epoch: 6| Step: 13
Training loss: 2.159486635803149
Validation loss: 2.8053805163208954

Epoch: 61| Step: 0
Training loss: 3.195609752753695
Validation loss: 2.8041358935704155

Epoch: 6| Step: 1
Training loss: 3.227534187070826
Validation loss: 2.8103391287835566

Epoch: 6| Step: 2
Training loss: 2.751971145256827
Validation loss: 2.816100075414091

Epoch: 6| Step: 3
Training loss: 2.7183716609395985
Validation loss: 2.8301359297396407

Epoch: 6| Step: 4
Training loss: 3.0665342267780846
Validation loss: 2.838874620499521

Epoch: 6| Step: 5
Training loss: 2.7189679990164084
Validation loss: 2.836162763735358

Epoch: 6| Step: 6
Training loss: 2.6962197366359253
Validation loss: 2.834216726314439

Epoch: 6| Step: 7
Training loss: 3.0675126139063567
Validation loss: 2.8336280045803792

Epoch: 6| Step: 8
Training loss: 3.38767236925605
Validation loss: 2.81166028757897

Epoch: 6| Step: 9
Training loss: 3.9719755026454684
Validation loss: 2.7978088667715646

Epoch: 6| Step: 10
Training loss: 3.1271104933855147
Validation loss: 2.7794863003363677

Epoch: 6| Step: 11
Training loss: 3.0595375836104552
Validation loss: 2.7701917601471857

Epoch: 6| Step: 12
Training loss: 3.444246226592543
Validation loss: 2.7668078941235623

Epoch: 6| Step: 13
Training loss: 2.5598846673317692
Validation loss: 2.7755313293302786

Epoch: 62| Step: 0
Training loss: 3.331207423984782
Validation loss: 2.7830889665370036

Epoch: 6| Step: 1
Training loss: 3.6146570174359187
Validation loss: 2.785207881200683

Epoch: 6| Step: 2
Training loss: 2.582524285733121
Validation loss: 2.77780049167767

Epoch: 6| Step: 3
Training loss: 3.356014398300693
Validation loss: 2.77500166460139

Epoch: 6| Step: 4
Training loss: 3.2344913185322732
Validation loss: 2.7625258229651015

Epoch: 6| Step: 5
Training loss: 2.6904582221150153
Validation loss: 2.767219194757043

Epoch: 6| Step: 6
Training loss: 3.238274329239061
Validation loss: 2.7638610540870885

Epoch: 6| Step: 7
Training loss: 3.0161164036556
Validation loss: 2.7629479740634486

Epoch: 6| Step: 8
Training loss: 2.5747757860361657
Validation loss: 2.7615635655352

Epoch: 6| Step: 9
Training loss: 3.3874357491906792
Validation loss: 2.7612098828066953

Epoch: 6| Step: 10
Training loss: 2.918211246407996
Validation loss: 2.759912454934088

Epoch: 6| Step: 11
Training loss: 2.851374538967936
Validation loss: 2.758188144882907

Epoch: 6| Step: 12
Training loss: 2.927764179874558
Validation loss: 2.75705836571726

Epoch: 6| Step: 13
Training loss: 3.396988342696371
Validation loss: 2.754861049854984

Epoch: 63| Step: 0
Training loss: 3.351974070783307
Validation loss: 2.7539617028577386

Epoch: 6| Step: 1
Training loss: 3.724285589746267
Validation loss: 2.752841975784556

Epoch: 6| Step: 2
Training loss: 3.216695926381649
Validation loss: 2.7642945967333925

Epoch: 6| Step: 3
Training loss: 2.6765622078293587
Validation loss: 2.780705478739113

Epoch: 6| Step: 4
Training loss: 2.8007317063805823
Validation loss: 2.782548369768433

Epoch: 6| Step: 5
Training loss: 2.8303928450352194
Validation loss: 2.7893684072147926

Epoch: 6| Step: 6
Training loss: 3.1998801566570854
Validation loss: 2.7545094810540993

Epoch: 6| Step: 7
Training loss: 3.62969692720001
Validation loss: 2.7493199349367905

Epoch: 6| Step: 8
Training loss: 2.842364969527157
Validation loss: 2.7486307029631996

Epoch: 6| Step: 9
Training loss: 3.5681867218425656
Validation loss: 2.7507603163862666

Epoch: 6| Step: 10
Training loss: 2.963675890912661
Validation loss: 2.749482222631056

Epoch: 6| Step: 11
Training loss: 2.7521119244515204
Validation loss: 2.7533439430448143

Epoch: 6| Step: 12
Training loss: 2.393470516771523
Validation loss: 2.7522683581361798

Epoch: 6| Step: 13
Training loss: 2.5657711085023904
Validation loss: 2.753309914826196

Epoch: 64| Step: 0
Training loss: 3.4625007767108364
Validation loss: 2.7545672289427294

Epoch: 6| Step: 1
Training loss: 2.4082283705527403
Validation loss: 2.7532960319073

Epoch: 6| Step: 2
Training loss: 3.095950182373463
Validation loss: 2.754095380344337

Epoch: 6| Step: 3
Training loss: 2.7306935841300346
Validation loss: 2.753095625896822

Epoch: 6| Step: 4
Training loss: 2.604299211307918
Validation loss: 2.7533172799143744

Epoch: 6| Step: 5
Training loss: 3.381548145285931
Validation loss: 2.7519904453576043

Epoch: 6| Step: 6
Training loss: 3.5585799483901543
Validation loss: 2.7471031702986908

Epoch: 6| Step: 7
Training loss: 3.1330922446601863
Validation loss: 2.748560581880272

Epoch: 6| Step: 8
Training loss: 3.3464300520588734
Validation loss: 2.747900347723512

Epoch: 6| Step: 9
Training loss: 2.8727906071975964
Validation loss: 2.7463791260363473

Epoch: 6| Step: 10
Training loss: 2.562735942119906
Validation loss: 2.744089828930191

Epoch: 6| Step: 11
Training loss: 3.5797396685604843
Validation loss: 2.7427275583094985

Epoch: 6| Step: 12
Training loss: 3.3044385883929586
Validation loss: 2.743528100270582

Epoch: 6| Step: 13
Training loss: 2.330671108666442
Validation loss: 2.7463536750761572

Epoch: 65| Step: 0
Training loss: 3.1742932351508752
Validation loss: 2.741228201642813

Epoch: 6| Step: 1
Training loss: 2.850596643201034
Validation loss: 2.7441378223280948

Epoch: 6| Step: 2
Training loss: 3.0666443167438704
Validation loss: 2.740641650870764

Epoch: 6| Step: 3
Training loss: 3.5601075822669253
Validation loss: 2.7388487555124175

Epoch: 6| Step: 4
Training loss: 3.3738178019372866
Validation loss: 2.737496862158253

Epoch: 6| Step: 5
Training loss: 2.709707987209331
Validation loss: 2.7395882165282694

Epoch: 6| Step: 6
Training loss: 2.9760709742214675
Validation loss: 2.740014127089062

Epoch: 6| Step: 7
Training loss: 2.8509768367965034
Validation loss: 2.738469145290342

Epoch: 6| Step: 8
Training loss: 3.3765832931252557
Validation loss: 2.738443878261103

Epoch: 6| Step: 9
Training loss: 2.5381402321409854
Validation loss: 2.737124739102022

Epoch: 6| Step: 10
Training loss: 2.1308571372295764
Validation loss: 2.738076014837555

Epoch: 6| Step: 11
Training loss: 3.162485591569126
Validation loss: 2.7381257483825068

Epoch: 6| Step: 12
Training loss: 3.5634999795835816
Validation loss: 2.7369737052626872

Epoch: 6| Step: 13
Training loss: 3.3337572464007765
Validation loss: 2.738253660318888

Epoch: 66| Step: 0
Training loss: 3.3562036493322354
Validation loss: 2.7411900052824176

Epoch: 6| Step: 1
Training loss: 3.300340900730583
Validation loss: 2.749106952944141

Epoch: 6| Step: 2
Training loss: 3.4500605591697195
Validation loss: 2.7396210274422534

Epoch: 6| Step: 3
Training loss: 2.7552841743362255
Validation loss: 2.7319532657826917

Epoch: 6| Step: 4
Training loss: 2.116271323982685
Validation loss: 2.747198230701925

Epoch: 6| Step: 5
Training loss: 3.034345796014363
Validation loss: 2.731465548838152

Epoch: 6| Step: 6
Training loss: 2.8342451610498642
Validation loss: 2.7365636033063003

Epoch: 6| Step: 7
Training loss: 2.9610734168590445
Validation loss: 2.7476325262012726

Epoch: 6| Step: 8
Training loss: 3.1344175721887635
Validation loss: 2.736290057925273

Epoch: 6| Step: 9
Training loss: 2.590291670647512
Validation loss: 2.730482793110503

Epoch: 6| Step: 10
Training loss: 2.814072910863585
Validation loss: 2.7268242614413034

Epoch: 6| Step: 11
Training loss: 3.634105690107281
Validation loss: 2.725736109715562

Epoch: 6| Step: 12
Training loss: 3.130263359275908
Validation loss: 2.7232810643358936

Epoch: 6| Step: 13
Training loss: 3.3652185051134795
Validation loss: 2.725997567750659

Epoch: 67| Step: 0
Training loss: 3.5744352681601455
Validation loss: 2.7226145887922195

Epoch: 6| Step: 1
Training loss: 3.007464658762602
Validation loss: 2.7299776097522557

Epoch: 6| Step: 2
Training loss: 3.1381233842272342
Validation loss: 2.7322252449051696

Epoch: 6| Step: 3
Training loss: 3.285094415942299
Validation loss: 2.7344333334236546

Epoch: 6| Step: 4
Training loss: 3.248118809805501
Validation loss: 2.7392814351666837

Epoch: 6| Step: 5
Training loss: 3.3674970515520743
Validation loss: 2.7392858066619596

Epoch: 6| Step: 6
Training loss: 2.8489277412032
Validation loss: 2.7369562288216103

Epoch: 6| Step: 7
Training loss: 3.1763625697965727
Validation loss: 2.733431671606093

Epoch: 6| Step: 8
Training loss: 2.432261486533323
Validation loss: 2.7321506642336857

Epoch: 6| Step: 9
Training loss: 3.8898574500944973
Validation loss: 2.729229299250403

Epoch: 6| Step: 10
Training loss: 2.1843211373385945
Validation loss: 2.746939329078438

Epoch: 6| Step: 11
Training loss: 2.636334788305126
Validation loss: 2.757896593335064

Epoch: 6| Step: 12
Training loss: 2.6007741472508807
Validation loss: 2.761837091672179

Epoch: 6| Step: 13
Training loss: 3.116742324590775
Validation loss: 2.7708461895950602

Epoch: 68| Step: 0
Training loss: 2.927132675098933
Validation loss: 2.7881107086775976

Epoch: 6| Step: 1
Training loss: 2.9343498058273463
Validation loss: 2.812591983289112

Epoch: 6| Step: 2
Training loss: 2.9477978649845746
Validation loss: 2.8109141939127715

Epoch: 6| Step: 3
Training loss: 2.4593571508358503
Validation loss: 2.794660940198042

Epoch: 6| Step: 4
Training loss: 3.069981059659007
Validation loss: 2.76609895609045

Epoch: 6| Step: 5
Training loss: 3.4631694545897713
Validation loss: 2.777999549202838

Epoch: 6| Step: 6
Training loss: 2.7031038316548313
Validation loss: 2.791216508339394

Epoch: 6| Step: 7
Training loss: 2.8854792802721496
Validation loss: 2.7900915258562056

Epoch: 6| Step: 8
Training loss: 3.1830781671272215
Validation loss: 2.788330836989461

Epoch: 6| Step: 9
Training loss: 3.3354403194531588
Validation loss: 2.780043897791976

Epoch: 6| Step: 10
Training loss: 3.505463287165623
Validation loss: 2.7576288176446946

Epoch: 6| Step: 11
Training loss: 3.0295043323345467
Validation loss: 2.741539126515147

Epoch: 6| Step: 12
Training loss: 3.5749022783915128
Validation loss: 2.7269596076643836

Epoch: 6| Step: 13
Training loss: 2.904369935666868
Validation loss: 2.723628446942814

Epoch: 69| Step: 0
Training loss: 2.9398508607574114
Validation loss: 2.723251005926456

Epoch: 6| Step: 1
Training loss: 3.21821486089247
Validation loss: 2.7254995360290857

Epoch: 6| Step: 2
Training loss: 3.2286463328520765
Validation loss: 2.7283267529396644

Epoch: 6| Step: 3
Training loss: 2.9230422682001316
Validation loss: 2.728991713212135

Epoch: 6| Step: 4
Training loss: 2.651263774168788
Validation loss: 2.724972800098093

Epoch: 6| Step: 5
Training loss: 3.4388809204693986
Validation loss: 2.723235644284878

Epoch: 6| Step: 6
Training loss: 3.442315075796329
Validation loss: 2.7179495085973278

Epoch: 6| Step: 7
Training loss: 3.056450922627687
Validation loss: 2.7142767054833667

Epoch: 6| Step: 8
Training loss: 2.7359476852880977
Validation loss: 2.714431804388926

Epoch: 6| Step: 9
Training loss: 2.5895131448167925
Validation loss: 2.715313772085302

Epoch: 6| Step: 10
Training loss: 3.0063269972110747
Validation loss: 2.7119179118613803

Epoch: 6| Step: 11
Training loss: 3.1629558370415474
Validation loss: 2.7133847777954205

Epoch: 6| Step: 12
Training loss: 3.1771822721157474
Validation loss: 2.740647973341658

Epoch: 6| Step: 13
Training loss: 2.6681387136450505
Validation loss: 2.7435703045047335

Epoch: 70| Step: 0
Training loss: 2.6764720609743473
Validation loss: 2.7411627796931617

Epoch: 6| Step: 1
Training loss: 2.6402867568941013
Validation loss: 2.7489041114653543

Epoch: 6| Step: 2
Training loss: 2.9461739896632317
Validation loss: 2.7451966455442807

Epoch: 6| Step: 3
Training loss: 3.7950284258716467
Validation loss: 2.722676296492538

Epoch: 6| Step: 4
Training loss: 2.4532355994300743
Validation loss: 2.708788377446336

Epoch: 6| Step: 5
Training loss: 2.9307670537030557
Validation loss: 2.7074256991599506

Epoch: 6| Step: 6
Training loss: 2.8835889809526907
Validation loss: 2.705520540513832

Epoch: 6| Step: 7
Training loss: 2.8105827578440357
Validation loss: 2.705772609816528

Epoch: 6| Step: 8
Training loss: 3.2330068744618194
Validation loss: 2.7095879071427835

Epoch: 6| Step: 9
Training loss: 2.78236358294464
Validation loss: 2.7046262456136043

Epoch: 6| Step: 10
Training loss: 3.129461993940971
Validation loss: 2.7028510221401856

Epoch: 6| Step: 11
Training loss: 2.9593933427155608
Validation loss: 2.7069166474367026

Epoch: 6| Step: 12
Training loss: 3.642860086690958
Validation loss: 2.7018253583880987

Epoch: 6| Step: 13
Training loss: 3.7567289380314324
Validation loss: 2.7026888805958595

Epoch: 71| Step: 0
Training loss: 3.501350414793248
Validation loss: 2.7008856719175056

Epoch: 6| Step: 1
Training loss: 3.106780690350474
Validation loss: 2.700202418008695

Epoch: 6| Step: 2
Training loss: 2.6992152168482666
Validation loss: 2.6987860631277054

Epoch: 6| Step: 3
Training loss: 2.388919496216965
Validation loss: 2.7023126520914365

Epoch: 6| Step: 4
Training loss: 3.700094922884343
Validation loss: 2.7058778774634753

Epoch: 6| Step: 5
Training loss: 2.8898050330900285
Validation loss: 2.7056574934510915

Epoch: 6| Step: 6
Training loss: 2.6104267307908477
Validation loss: 2.7160916663651578

Epoch: 6| Step: 7
Training loss: 3.2567268593521597
Validation loss: 2.72729736151062

Epoch: 6| Step: 8
Training loss: 3.2543206471944126
Validation loss: 2.7219812881820413

Epoch: 6| Step: 9
Training loss: 2.8258647000428025
Validation loss: 2.7059931057198843

Epoch: 6| Step: 10
Training loss: 3.240533981590047
Validation loss: 2.698287300487866

Epoch: 6| Step: 11
Training loss: 3.088847736462627
Validation loss: 2.6944991335153343

Epoch: 6| Step: 12
Training loss: 2.5256747788826814
Validation loss: 2.690564899788806

Epoch: 6| Step: 13
Training loss: 3.1003829288855753
Validation loss: 2.697661022168053

Epoch: 72| Step: 0
Training loss: 2.577078867121789
Validation loss: 2.695722210504914

Epoch: 6| Step: 1
Training loss: 3.5265228228688446
Validation loss: 2.7009076578041977

Epoch: 6| Step: 2
Training loss: 2.7483660438708477
Validation loss: 2.7032471889459084

Epoch: 6| Step: 3
Training loss: 3.3030016050505195
Validation loss: 2.699894957586096

Epoch: 6| Step: 4
Training loss: 2.3791026768761245
Validation loss: 2.702128006272375

Epoch: 6| Step: 5
Training loss: 3.1009142604219617
Validation loss: 2.7028551196354083

Epoch: 6| Step: 6
Training loss: 3.106840548035571
Validation loss: 2.6991723390239932

Epoch: 6| Step: 7
Training loss: 3.1055625661438357
Validation loss: 2.703500234515201

Epoch: 6| Step: 8
Training loss: 3.2543385231137925
Validation loss: 2.700795576605693

Epoch: 6| Step: 9
Training loss: 2.607571646857216
Validation loss: 2.6983296897813065

Epoch: 6| Step: 10
Training loss: 3.6466645664671637
Validation loss: 2.696044965021608

Epoch: 6| Step: 11
Training loss: 2.95129337729697
Validation loss: 2.6941553571879244

Epoch: 6| Step: 12
Training loss: 3.056524246486579
Validation loss: 2.6957072221762193

Epoch: 6| Step: 13
Training loss: 2.8903399352682118
Validation loss: 2.694018357185512

Epoch: 73| Step: 0
Training loss: 2.7559480497394264
Validation loss: 2.68982786783914

Epoch: 6| Step: 1
Training loss: 3.6098833262855643
Validation loss: 2.691512782467424

Epoch: 6| Step: 2
Training loss: 3.1399322808610943
Validation loss: 2.6903949626397368

Epoch: 6| Step: 3
Training loss: 3.485335829109557
Validation loss: 2.6876320488119103

Epoch: 6| Step: 4
Training loss: 3.0879517753669967
Validation loss: 2.691648460381725

Epoch: 6| Step: 5
Training loss: 2.699585995899255
Validation loss: 2.697485876347764

Epoch: 6| Step: 6
Training loss: 3.186410455924963
Validation loss: 2.717709370571328

Epoch: 6| Step: 7
Training loss: 2.5436954426831355
Validation loss: 2.7453635593418135

Epoch: 6| Step: 8
Training loss: 3.041588055017204
Validation loss: 2.7588230547315864

Epoch: 6| Step: 9
Training loss: 2.9219499058225193
Validation loss: 2.776184935946589

Epoch: 6| Step: 10
Training loss: 2.5624129117727925
Validation loss: 2.7631462589604587

Epoch: 6| Step: 11
Training loss: 3.296527862352391
Validation loss: 2.7403744399446017

Epoch: 6| Step: 12
Training loss: 2.8969247165598775
Validation loss: 2.6885758154764305

Epoch: 6| Step: 13
Training loss: 3.319362369801348
Validation loss: 2.688705546926372

Epoch: 74| Step: 0
Training loss: 3.4214290519916526
Validation loss: 2.6934709332876414

Epoch: 6| Step: 1
Training loss: 2.972410976401863
Validation loss: 2.7064653629728737

Epoch: 6| Step: 2
Training loss: 3.0935372944161124
Validation loss: 2.7223769076242723

Epoch: 6| Step: 3
Training loss: 2.8331461638916764
Validation loss: 2.7200575095966957

Epoch: 6| Step: 4
Training loss: 2.957044472910495
Validation loss: 2.715613882058416

Epoch: 6| Step: 5
Training loss: 3.0706176606161812
Validation loss: 2.7092875933259584

Epoch: 6| Step: 6
Training loss: 3.4924704076541357
Validation loss: 2.7046920328469626

Epoch: 6| Step: 7
Training loss: 2.613308711114357
Validation loss: 2.6961518181519213

Epoch: 6| Step: 8
Training loss: 3.247220538113254
Validation loss: 2.691409665764337

Epoch: 6| Step: 9
Training loss: 2.5222699088948928
Validation loss: 2.6886549678808436

Epoch: 6| Step: 10
Training loss: 3.2822804604043134
Validation loss: 2.6889811138314066

Epoch: 6| Step: 11
Training loss: 3.1707382796113857
Validation loss: 2.687144941650582

Epoch: 6| Step: 12
Training loss: 2.9230670639211587
Validation loss: 2.6846735033024283

Epoch: 6| Step: 13
Training loss: 2.671664134845577
Validation loss: 2.6798771664600145

Epoch: 75| Step: 0
Training loss: 3.500601444338806
Validation loss: 2.6770788529236746

Epoch: 6| Step: 1
Training loss: 2.929214480042862
Validation loss: 2.6753805551677243

Epoch: 6| Step: 2
Training loss: 3.289946158759906
Validation loss: 2.675902315411026

Epoch: 6| Step: 3
Training loss: 3.0635255925806275
Validation loss: 2.6733246685576373

Epoch: 6| Step: 4
Training loss: 3.2198810256871413
Validation loss: 2.6733791154955044

Epoch: 6| Step: 5
Training loss: 2.662837219374246
Validation loss: 2.6747697895021947

Epoch: 6| Step: 6
Training loss: 3.1751655835805312
Validation loss: 2.673385504981022

Epoch: 6| Step: 7
Training loss: 3.141787489398358
Validation loss: 2.6737388812213645

Epoch: 6| Step: 8
Training loss: 3.1759929516039067
Validation loss: 2.6883558707192154

Epoch: 6| Step: 9
Training loss: 3.4017058693176425
Validation loss: 2.779966571896372

Epoch: 6| Step: 10
Training loss: 2.978826507853655
Validation loss: 2.755033260018361

Epoch: 6| Step: 11
Training loss: 2.8822995274782035
Validation loss: 2.669214827667561

Epoch: 6| Step: 12
Training loss: 1.9365524928480902
Validation loss: 2.678591283440433

Epoch: 6| Step: 13
Training loss: 2.3231432566157597
Validation loss: 2.679989481585289

Epoch: 76| Step: 0
Training loss: 2.974191597488187
Validation loss: 2.688951131538203

Epoch: 6| Step: 1
Training loss: 2.947386802978128
Validation loss: 2.7464074620635652

Epoch: 6| Step: 2
Training loss: 3.1396798756688056
Validation loss: 2.7818831501645254

Epoch: 6| Step: 3
Training loss: 3.116249191828813
Validation loss: 2.762421432377884

Epoch: 6| Step: 4
Training loss: 3.218960949549802
Validation loss: 2.7210990122395335

Epoch: 6| Step: 5
Training loss: 3.344653141301818
Validation loss: 2.698533825719941

Epoch: 6| Step: 6
Training loss: 3.0857499077673376
Validation loss: 2.6909500455300877

Epoch: 6| Step: 7
Training loss: 3.1460641098426056
Validation loss: 2.7033088806951375

Epoch: 6| Step: 8
Training loss: 2.964857098897403
Validation loss: 2.711622597413902

Epoch: 6| Step: 9
Training loss: 3.285337971527161
Validation loss: 2.724265832700374

Epoch: 6| Step: 10
Training loss: 3.1574006957372993
Validation loss: 2.7002996526049947

Epoch: 6| Step: 11
Training loss: 2.7092197923742427
Validation loss: 2.6860091588004797

Epoch: 6| Step: 12
Training loss: 2.6562348309252073
Validation loss: 2.6934627378172533

Epoch: 6| Step: 13
Training loss: 2.428013264602551
Validation loss: 2.6956844121394745

Epoch: 77| Step: 0
Training loss: 3.127168894560219
Validation loss: 2.695114271600522

Epoch: 6| Step: 1
Training loss: 3.419803358079901
Validation loss: 2.7065471113310964

Epoch: 6| Step: 2
Training loss: 2.4656024617565917
Validation loss: 2.7186263153754857

Epoch: 6| Step: 3
Training loss: 3.5528438943399734
Validation loss: 2.721287387351006

Epoch: 6| Step: 4
Training loss: 2.686437174869169
Validation loss: 2.707957508777311

Epoch: 6| Step: 5
Training loss: 2.4498569563543704
Validation loss: 2.69264976847325

Epoch: 6| Step: 6
Training loss: 3.2338235725966316
Validation loss: 2.668406246615372

Epoch: 6| Step: 7
Training loss: 3.6184050980357645
Validation loss: 2.6619163035515747

Epoch: 6| Step: 8
Training loss: 2.2585112338594286
Validation loss: 2.661430415732386

Epoch: 6| Step: 9
Training loss: 2.1638117345402716
Validation loss: 2.656182856618975

Epoch: 6| Step: 10
Training loss: 2.881821873112495
Validation loss: 2.658492853691086

Epoch: 6| Step: 11
Training loss: 3.580879583725156
Validation loss: 2.6598265657131264

Epoch: 6| Step: 12
Training loss: 2.818185611901289
Validation loss: 2.6640771212218843

Epoch: 6| Step: 13
Training loss: 3.6609994411723363
Validation loss: 2.6678368445383787

Epoch: 78| Step: 0
Training loss: 2.9986473848913975
Validation loss: 2.6718108860266425

Epoch: 6| Step: 1
Training loss: 3.3189137104123523
Validation loss: 2.6642026887515398

Epoch: 6| Step: 2
Training loss: 3.1202157591530417
Validation loss: 2.664752419428605

Epoch: 6| Step: 3
Training loss: 2.810486645083008
Validation loss: 2.6573925854420177

Epoch: 6| Step: 4
Training loss: 2.857401349091093
Validation loss: 2.6570058076699112

Epoch: 6| Step: 5
Training loss: 3.4282429287985736
Validation loss: 2.6572358205185034

Epoch: 6| Step: 6
Training loss: 2.939411920911375
Validation loss: 2.6558174142981077

Epoch: 6| Step: 7
Training loss: 2.490821009333491
Validation loss: 2.661698399514994

Epoch: 6| Step: 8
Training loss: 2.630214326052244
Validation loss: 2.660709319453524

Epoch: 6| Step: 9
Training loss: 2.6133760398015697
Validation loss: 2.6700885660447913

Epoch: 6| Step: 10
Training loss: 3.3854847280067437
Validation loss: 2.6728589162213923

Epoch: 6| Step: 11
Training loss: 3.3208277403538284
Validation loss: 2.6885363847695336

Epoch: 6| Step: 12
Training loss: 3.028221583917483
Validation loss: 2.6656102855541546

Epoch: 6| Step: 13
Training loss: 2.8139981835962002
Validation loss: 2.67670242768195

Epoch: 79| Step: 0
Training loss: 3.426879150120951
Validation loss: 2.680309452963891

Epoch: 6| Step: 1
Training loss: 2.9804405921015897
Validation loss: 2.6552284114800733

Epoch: 6| Step: 2
Training loss: 2.756707248258345
Validation loss: 2.6513342039684367

Epoch: 6| Step: 3
Training loss: 3.3735280535843053
Validation loss: 2.6569570084241247

Epoch: 6| Step: 4
Training loss: 2.843340833802372
Validation loss: 2.6582315050171474

Epoch: 6| Step: 5
Training loss: 2.869213417537283
Validation loss: 2.6548098767486596

Epoch: 6| Step: 6
Training loss: 2.8431434403662363
Validation loss: 2.658915304609739

Epoch: 6| Step: 7
Training loss: 3.3276811044017984
Validation loss: 2.6594050182103364

Epoch: 6| Step: 8
Training loss: 2.7471623084933556
Validation loss: 2.657942943843546

Epoch: 6| Step: 9
Training loss: 3.0296226931285895
Validation loss: 2.6593399924138064

Epoch: 6| Step: 10
Training loss: 3.6078255370223795
Validation loss: 2.659586969010667

Epoch: 6| Step: 11
Training loss: 2.646840922418895
Validation loss: 2.6557717478478304

Epoch: 6| Step: 12
Training loss: 2.6541187487657836
Validation loss: 2.6546768877100653

Epoch: 6| Step: 13
Training loss: 2.5093890312059077
Validation loss: 2.6528460287268034

Epoch: 80| Step: 0
Training loss: 3.041972593486254
Validation loss: 2.6480209066983154

Epoch: 6| Step: 1
Training loss: 3.4163006532210014
Validation loss: 2.647044299945938

Epoch: 6| Step: 2
Training loss: 3.2620131673821926
Validation loss: 2.654683126171372

Epoch: 6| Step: 3
Training loss: 2.451763188138873
Validation loss: 2.664584913026176

Epoch: 6| Step: 4
Training loss: 2.0216360431478733
Validation loss: 2.6647706200199166

Epoch: 6| Step: 5
Training loss: 3.1071151112036417
Validation loss: 2.67296042178998

Epoch: 6| Step: 6
Training loss: 2.340506381809504
Validation loss: 2.693591561007356

Epoch: 6| Step: 7
Training loss: 3.306509106584137
Validation loss: 2.7338533340421667

Epoch: 6| Step: 8
Training loss: 3.2213456141677765
Validation loss: 2.766708355572362

Epoch: 6| Step: 9
Training loss: 3.0019829872050825
Validation loss: 2.7493039412754054

Epoch: 6| Step: 10
Training loss: 3.265832191720815
Validation loss: 2.735613391030502

Epoch: 6| Step: 11
Training loss: 3.454029914041673
Validation loss: 2.6727198673234764

Epoch: 6| Step: 12
Training loss: 2.570405442432919
Validation loss: 2.6447613890860535

Epoch: 6| Step: 13
Training loss: 3.7506156416033942
Validation loss: 2.6507379495000234

Epoch: 81| Step: 0
Training loss: 2.4678694687859446
Validation loss: 2.654844039607419

Epoch: 6| Step: 1
Training loss: 2.9606000964691903
Validation loss: 2.659023853230692

Epoch: 6| Step: 2
Training loss: 3.1378687060614077
Validation loss: 2.6672196974836235

Epoch: 6| Step: 3
Training loss: 3.692453451825288
Validation loss: 2.670574743788097

Epoch: 6| Step: 4
Training loss: 2.54425625648865
Validation loss: 2.6737785148088635

Epoch: 6| Step: 5
Training loss: 2.9688360904458153
Validation loss: 2.667655851405887

Epoch: 6| Step: 6
Training loss: 3.5463727015612596
Validation loss: 2.6597648620471843

Epoch: 6| Step: 7
Training loss: 3.091844376411791
Validation loss: 2.6585342208138942

Epoch: 6| Step: 8
Training loss: 3.0721731202300533
Validation loss: 2.654938834458175

Epoch: 6| Step: 9
Training loss: 2.91572061363522
Validation loss: 2.653982281450289

Epoch: 6| Step: 10
Training loss: 3.2564550997817445
Validation loss: 2.653582559331744

Epoch: 6| Step: 11
Training loss: 2.8937881895639097
Validation loss: 2.651959107449152

Epoch: 6| Step: 12
Training loss: 2.477828607717332
Validation loss: 2.652912113369248

Epoch: 6| Step: 13
Training loss: 2.8394857440690706
Validation loss: 2.648438789352116

Epoch: 82| Step: 0
Training loss: 2.9620465539214025
Validation loss: 2.646387118972086

Epoch: 6| Step: 1
Training loss: 2.8110763337401155
Validation loss: 2.6470117080600435

Epoch: 6| Step: 2
Training loss: 2.9618214920726267
Validation loss: 2.6459192021932476

Epoch: 6| Step: 3
Training loss: 2.8495280494092556
Validation loss: 2.642762749546559

Epoch: 6| Step: 4
Training loss: 3.1587189941333693
Validation loss: 2.6419478523544537

Epoch: 6| Step: 5
Training loss: 2.0623351522515447
Validation loss: 2.6356907700823813

Epoch: 6| Step: 6
Training loss: 2.5247957807991543
Validation loss: 2.634197464929073

Epoch: 6| Step: 7
Training loss: 3.271409601524215
Validation loss: 2.638283556679785

Epoch: 6| Step: 8
Training loss: 3.745647192981089
Validation loss: 2.6641984606025564

Epoch: 6| Step: 9
Training loss: 2.8219541384392386
Validation loss: 2.694516997598648

Epoch: 6| Step: 10
Training loss: 3.640868346631732
Validation loss: 2.78223480840864

Epoch: 6| Step: 11
Training loss: 3.314895339625506
Validation loss: 2.682514042312329

Epoch: 6| Step: 12
Training loss: 2.9626762498665693
Validation loss: 2.6435847249924316

Epoch: 6| Step: 13
Training loss: 2.507236973211277
Validation loss: 2.637203939470051

Epoch: 83| Step: 0
Training loss: 2.947053834701101
Validation loss: 2.6350029244423903

Epoch: 6| Step: 1
Training loss: 3.13656733659305
Validation loss: 2.637666764007861

Epoch: 6| Step: 2
Training loss: 2.567813481672716
Validation loss: 2.642912238483472

Epoch: 6| Step: 3
Training loss: 3.247978755674743
Validation loss: 2.6401746715026517

Epoch: 6| Step: 4
Training loss: 2.277794193063941
Validation loss: 2.6402725340794486

Epoch: 6| Step: 5
Training loss: 3.5413068850412452
Validation loss: 2.636463962217552

Epoch: 6| Step: 6
Training loss: 2.850778801233019
Validation loss: 2.6375073239441984

Epoch: 6| Step: 7
Training loss: 3.5088430135620547
Validation loss: 2.63504618389401

Epoch: 6| Step: 8
Training loss: 2.9665741023792456
Validation loss: 2.633374942540633

Epoch: 6| Step: 9
Training loss: 2.5384872019521976
Validation loss: 2.634571793289736

Epoch: 6| Step: 10
Training loss: 2.7377503406899613
Validation loss: 2.6327579473529887

Epoch: 6| Step: 11
Training loss: 2.9561206619970934
Validation loss: 2.638520040318563

Epoch: 6| Step: 12
Training loss: 3.65048284602945
Validation loss: 2.6308620284257196

Epoch: 6| Step: 13
Training loss: 2.2866354303849357
Validation loss: 2.629382922473057

Epoch: 84| Step: 0
Training loss: 2.7166067861810803
Validation loss: 2.6286378733328197

Epoch: 6| Step: 1
Training loss: 2.743857198719593
Validation loss: 2.6290255383606267

Epoch: 6| Step: 2
Training loss: 3.328226150623239
Validation loss: 2.6296958662084045

Epoch: 6| Step: 3
Training loss: 2.7670133737310514
Validation loss: 2.626340513064987

Epoch: 6| Step: 4
Training loss: 2.4879782595527886
Validation loss: 2.629341051865667

Epoch: 6| Step: 5
Training loss: 2.831547978701487
Validation loss: 2.6290843068148315

Epoch: 6| Step: 6
Training loss: 2.9509030010707766
Validation loss: 2.6282231943542755

Epoch: 6| Step: 7
Training loss: 2.8791709167478543
Validation loss: 2.62923857117

Epoch: 6| Step: 8
Training loss: 3.385702330445744
Validation loss: 2.628147943938495

Epoch: 6| Step: 9
Training loss: 2.8992065067592976
Validation loss: 2.626975613517734

Epoch: 6| Step: 10
Training loss: 2.8796804725035487
Validation loss: 2.6518779911554553

Epoch: 6| Step: 11
Training loss: 3.5334538697129823
Validation loss: 2.6511687241389654

Epoch: 6| Step: 12
Training loss: 2.9039711169863613
Validation loss: 2.647580404641655

Epoch: 6| Step: 13
Training loss: 3.4544122980546446
Validation loss: 2.648521239793309

Epoch: 85| Step: 0
Training loss: 3.481020009304138
Validation loss: 2.655479372448089

Epoch: 6| Step: 1
Training loss: 2.580025267366392
Validation loss: 2.642638920320218

Epoch: 6| Step: 2
Training loss: 2.835082374465921
Validation loss: 2.6249162433034314

Epoch: 6| Step: 3
Training loss: 3.377238061377636
Validation loss: 2.6241891216973348

Epoch: 6| Step: 4
Training loss: 2.841184863490553
Validation loss: 2.6239784878296164

Epoch: 6| Step: 5
Training loss: 3.109788263356159
Validation loss: 2.6208119880141836

Epoch: 6| Step: 6
Training loss: 3.7538454048870347
Validation loss: 2.623274922892613

Epoch: 6| Step: 7
Training loss: 2.918798775438949
Validation loss: 2.6204296303984957

Epoch: 6| Step: 8
Training loss: 2.512916575955597
Validation loss: 2.622117313829873

Epoch: 6| Step: 9
Training loss: 2.4175024122129476
Validation loss: 2.6208821591775915

Epoch: 6| Step: 10
Training loss: 2.902666405138814
Validation loss: 2.620600253137115

Epoch: 6| Step: 11
Training loss: 3.2205033943052963
Validation loss: 2.622564042031031

Epoch: 6| Step: 12
Training loss: 2.8833238928609077
Validation loss: 2.6195578388318883

Epoch: 6| Step: 13
Training loss: 2.0844009969711483
Validation loss: 2.6176552063352836

Epoch: 86| Step: 0
Training loss: 2.7878777902272165
Validation loss: 2.6197112569409566

Epoch: 6| Step: 1
Training loss: 2.790111098863313
Validation loss: 2.619230202187801

Epoch: 6| Step: 2
Training loss: 2.6789188450350063
Validation loss: 2.619671906295897

Epoch: 6| Step: 3
Training loss: 3.2719841327702213
Validation loss: 2.614297575108515

Epoch: 6| Step: 4
Training loss: 2.9656386283665883
Validation loss: 2.6150829284170096

Epoch: 6| Step: 5
Training loss: 2.785515589492222
Validation loss: 2.615138076221977

Epoch: 6| Step: 6
Training loss: 2.927148802399557
Validation loss: 2.6165084944945014

Epoch: 6| Step: 7
Training loss: 2.547104339571231
Validation loss: 2.6162586829812065

Epoch: 6| Step: 8
Training loss: 3.469805170355686
Validation loss: 2.6158188389321935

Epoch: 6| Step: 9
Training loss: 3.274737771288432
Validation loss: 2.6155879037920116

Epoch: 6| Step: 10
Training loss: 2.4903695582180214
Validation loss: 2.615649524427269

Epoch: 6| Step: 11
Training loss: 3.4303244866009432
Validation loss: 2.6129009938240015

Epoch: 6| Step: 12
Training loss: 3.3151896371583733
Validation loss: 2.611180428124722

Epoch: 6| Step: 13
Training loss: 2.454617574704727
Validation loss: 2.6141296399672234

Epoch: 87| Step: 0
Training loss: 3.0768732149412257
Validation loss: 2.620629941345081

Epoch: 6| Step: 1
Training loss: 3.2524533915130656
Validation loss: 2.623780360303549

Epoch: 6| Step: 2
Training loss: 2.470108044998697
Validation loss: 2.639091965597869

Epoch: 6| Step: 3
Training loss: 1.7531595998467424
Validation loss: 2.659974219594889

Epoch: 6| Step: 4
Training loss: 3.293465971598781
Validation loss: 2.7000322737259417

Epoch: 6| Step: 5
Training loss: 3.3540114056843113
Validation loss: 2.714093354389984

Epoch: 6| Step: 6
Training loss: 3.407650440950474
Validation loss: 2.7230493659522854

Epoch: 6| Step: 7
Training loss: 3.821051091291602
Validation loss: 2.659400101855273

Epoch: 6| Step: 8
Training loss: 2.6992323525909967
Validation loss: 2.623956804086544

Epoch: 6| Step: 9
Training loss: 2.6703985049714967
Validation loss: 2.614686788791783

Epoch: 6| Step: 10
Training loss: 2.7808901093192917
Validation loss: 2.6079123734617324

Epoch: 6| Step: 11
Training loss: 3.097226434162129
Validation loss: 2.6114608408544977

Epoch: 6| Step: 12
Training loss: 2.651883834043772
Validation loss: 2.61353629381641

Epoch: 6| Step: 13
Training loss: 3.179541732108686
Validation loss: 2.6178426383879745

Epoch: 88| Step: 0
Training loss: 2.3517527962675406
Validation loss: 2.6173125030095683

Epoch: 6| Step: 1
Training loss: 3.185333862292934
Validation loss: 2.6184647253806563

Epoch: 6| Step: 2
Training loss: 3.077022761784203
Validation loss: 2.6211582898021044

Epoch: 6| Step: 3
Training loss: 3.083274290877022
Validation loss: 2.619360937021464

Epoch: 6| Step: 4
Training loss: 2.7138323100437423
Validation loss: 2.618573155287215

Epoch: 6| Step: 5
Training loss: 2.395610124445789
Validation loss: 2.618830219151938

Epoch: 6| Step: 6
Training loss: 3.3234730476949688
Validation loss: 2.615686025662425

Epoch: 6| Step: 7
Training loss: 2.7025852436239557
Validation loss: 2.615341063651281

Epoch: 6| Step: 8
Training loss: 3.237739029827536
Validation loss: 2.6127425190194247

Epoch: 6| Step: 9
Training loss: 3.303168342183268
Validation loss: 2.6086909941517553

Epoch: 6| Step: 10
Training loss: 3.3630237724468985
Validation loss: 2.6083483740532705

Epoch: 6| Step: 11
Training loss: 2.827397542727945
Validation loss: 2.6076861835765985

Epoch: 6| Step: 12
Training loss: 2.9378158724160586
Validation loss: 2.6077246336824134

Epoch: 6| Step: 13
Training loss: 2.889252867959079
Validation loss: 2.612838165304209

Epoch: 89| Step: 0
Training loss: 3.078541993685447
Validation loss: 2.610772719201823

Epoch: 6| Step: 1
Training loss: 2.529462772069042
Validation loss: 2.6106206327729407

Epoch: 6| Step: 2
Training loss: 2.9844481773791807
Validation loss: 2.614611169379023

Epoch: 6| Step: 3
Training loss: 2.561277330437984
Validation loss: 2.61884536015451

Epoch: 6| Step: 4
Training loss: 2.6073081231039246
Validation loss: 2.6092243334067873

Epoch: 6| Step: 5
Training loss: 2.9190224171189687
Validation loss: 2.611092310648464

Epoch: 6| Step: 6
Training loss: 2.5057011448058404
Validation loss: 2.6052394371899954

Epoch: 6| Step: 7
Training loss: 2.633019323177402
Validation loss: 2.6083259116797834

Epoch: 6| Step: 8
Training loss: 3.198733412896008
Validation loss: 2.603632021914423

Epoch: 6| Step: 9
Training loss: 2.904460397002153
Validation loss: 2.5997552146721543

Epoch: 6| Step: 10
Training loss: 3.5618555925024276
Validation loss: 2.599558354329453

Epoch: 6| Step: 11
Training loss: 3.2442682047084257
Validation loss: 2.597658723183422

Epoch: 6| Step: 12
Training loss: 3.454924929917046
Validation loss: 2.5991466494352116

Epoch: 6| Step: 13
Training loss: 2.9893339010958964
Validation loss: 2.596876082921067

Epoch: 90| Step: 0
Training loss: 2.422401420233044
Validation loss: 2.5969814250841092

Epoch: 6| Step: 1
Training loss: 3.085144713731122
Validation loss: 2.6016567934589436

Epoch: 6| Step: 2
Training loss: 2.694527243514164
Validation loss: 2.5995168751354156

Epoch: 6| Step: 3
Training loss: 3.2438041608989185
Validation loss: 2.601162990492207

Epoch: 6| Step: 4
Training loss: 3.034456425211736
Validation loss: 2.602999439802777

Epoch: 6| Step: 5
Training loss: 3.2039165728276457
Validation loss: 2.6031225182617295

Epoch: 6| Step: 6
Training loss: 3.300878038059503
Validation loss: 2.60369024500502

Epoch: 6| Step: 7
Training loss: 2.7957551728270413
Validation loss: 2.603640489805979

Epoch: 6| Step: 8
Training loss: 3.203119194211583
Validation loss: 2.607454399350631

Epoch: 6| Step: 9
Training loss: 3.073532473828084
Validation loss: 2.601600025638901

Epoch: 6| Step: 10
Training loss: 2.8155580637571984
Validation loss: 2.605178575044466

Epoch: 6| Step: 11
Training loss: 2.9217273042446403
Validation loss: 2.606681814752658

Epoch: 6| Step: 12
Training loss: 2.7369370147237033
Validation loss: 2.6024997900842695

Epoch: 6| Step: 13
Training loss: 2.503995753933655
Validation loss: 2.599057368408547

Epoch: 91| Step: 0
Training loss: 3.254144520181539
Validation loss: 2.6015388398759174

Epoch: 6| Step: 1
Training loss: 2.749746137519022
Validation loss: 2.603060025926317

Epoch: 6| Step: 2
Training loss: 3.234183190596871
Validation loss: 2.621394335041489

Epoch: 6| Step: 3
Training loss: 3.175810678868874
Validation loss: 2.605196264368357

Epoch: 6| Step: 4
Training loss: 2.843111406664031
Validation loss: 2.6099834817082255

Epoch: 6| Step: 5
Training loss: 2.6741444725890036
Validation loss: 2.5969041721143866

Epoch: 6| Step: 6
Training loss: 2.3029599714225095
Validation loss: 2.599529190757878

Epoch: 6| Step: 7
Training loss: 2.7124066068682744
Validation loss: 2.6119281455176897

Epoch: 6| Step: 8
Training loss: 3.120987414099077
Validation loss: 2.6159320414041534

Epoch: 6| Step: 9
Training loss: 2.7734781611510986
Validation loss: 2.612446022722323

Epoch: 6| Step: 10
Training loss: 3.090775109513452
Validation loss: 2.6083780788544044

Epoch: 6| Step: 11
Training loss: 3.2947535627302287
Validation loss: 2.60497823821735

Epoch: 6| Step: 12
Training loss: 3.0826686108240953
Validation loss: 2.599830478311628

Epoch: 6| Step: 13
Training loss: 2.8867569070444175
Validation loss: 2.6018844878730603

Epoch: 92| Step: 0
Training loss: 2.416885157825954
Validation loss: 2.601386355511758

Epoch: 6| Step: 1
Training loss: 2.7659225734816073
Validation loss: 2.6044289700884886

Epoch: 6| Step: 2
Training loss: 3.11182709432742
Validation loss: 2.6019145896444345

Epoch: 6| Step: 3
Training loss: 3.491314601826335
Validation loss: 2.6009814481820532

Epoch: 6| Step: 4
Training loss: 2.885426398489248
Validation loss: 2.598980059269764

Epoch: 6| Step: 5
Training loss: 3.23824811856355
Validation loss: 2.6079908136707664

Epoch: 6| Step: 6
Training loss: 3.185968068319052
Validation loss: 2.611232277119906

Epoch: 6| Step: 7
Training loss: 2.7635508372622812
Validation loss: 2.6042170146053873

Epoch: 6| Step: 8
Training loss: 2.9938717875068224
Validation loss: 2.5986365159474594

Epoch: 6| Step: 9
Training loss: 3.01346601770791
Validation loss: 2.590751449657876

Epoch: 6| Step: 10
Training loss: 3.1506806137846035
Validation loss: 2.5941975041103227

Epoch: 6| Step: 11
Training loss: 2.3349983087897046
Validation loss: 2.596985079554204

Epoch: 6| Step: 12
Training loss: 2.7284026399018866
Validation loss: 2.5966501736908616

Epoch: 6| Step: 13
Training loss: 3.2462365294637126
Validation loss: 2.5926430647203835

Epoch: 93| Step: 0
Training loss: 2.845720216468063
Validation loss: 2.590033653947467

Epoch: 6| Step: 1
Training loss: 3.0691678386198844
Validation loss: 2.5890523725667998

Epoch: 6| Step: 2
Training loss: 3.1718250890854547
Validation loss: 2.5911184572375343

Epoch: 6| Step: 3
Training loss: 2.691249715518892
Validation loss: 2.5898911154376507

Epoch: 6| Step: 4
Training loss: 2.319517879376881
Validation loss: 2.5908707057364264

Epoch: 6| Step: 5
Training loss: 2.5347412898305954
Validation loss: 2.5945194292667955

Epoch: 6| Step: 6
Training loss: 2.9016279978387645
Validation loss: 2.591045042070753

Epoch: 6| Step: 7
Training loss: 3.250015552190103
Validation loss: 2.58915708052517

Epoch: 6| Step: 8
Training loss: 3.1015106888678656
Validation loss: 2.5948651986911178

Epoch: 6| Step: 9
Training loss: 2.7876908378108136
Validation loss: 2.6051489931803182

Epoch: 6| Step: 10
Training loss: 2.983377819333419
Validation loss: 2.604804712374198

Epoch: 6| Step: 11
Training loss: 3.7951337173083872
Validation loss: 2.6180064047129803

Epoch: 6| Step: 12
Training loss: 2.741853959972592
Validation loss: 2.609880015967092

Epoch: 6| Step: 13
Training loss: 2.7172281675711987
Validation loss: 2.595164353597601

Epoch: 94| Step: 0
Training loss: 3.075142436876718
Validation loss: 2.5840532286877584

Epoch: 6| Step: 1
Training loss: 2.9804727496799015
Validation loss: 2.5829177562535572

Epoch: 6| Step: 2
Training loss: 3.508706027884397
Validation loss: 2.5833431978728725

Epoch: 6| Step: 3
Training loss: 3.082482366581065
Validation loss: 2.5842789098031598

Epoch: 6| Step: 4
Training loss: 2.2397038863508625
Validation loss: 2.5856277076528364

Epoch: 6| Step: 5
Training loss: 2.2178501937262407
Validation loss: 2.583320272957149

Epoch: 6| Step: 6
Training loss: 3.360455716200473
Validation loss: 2.584330641818962

Epoch: 6| Step: 7
Training loss: 3.080144539203518
Validation loss: 2.5808402173610534

Epoch: 6| Step: 8
Training loss: 2.757482838581597
Validation loss: 2.584070918772156

Epoch: 6| Step: 9
Training loss: 3.119689549137158
Validation loss: 2.5888821051648656

Epoch: 6| Step: 10
Training loss: 3.346668573989426
Validation loss: 2.5907583843136615

Epoch: 6| Step: 11
Training loss: 2.5805743055845274
Validation loss: 2.599490327512157

Epoch: 6| Step: 12
Training loss: 2.710503535206637
Validation loss: 2.609517374146459

Epoch: 6| Step: 13
Training loss: 2.7186182801357712
Validation loss: 2.6143666139868116

Epoch: 95| Step: 0
Training loss: 2.643002495027332
Validation loss: 2.620483607153451

Epoch: 6| Step: 1
Training loss: 2.51818224847763
Validation loss: 2.609545361161802

Epoch: 6| Step: 2
Training loss: 2.9657397618815238
Validation loss: 2.6049288560086152

Epoch: 6| Step: 3
Training loss: 2.8739592285449818
Validation loss: 2.6023481757410574

Epoch: 6| Step: 4
Training loss: 3.2198203075808984
Validation loss: 2.5945955764507285

Epoch: 6| Step: 5
Training loss: 2.8682651417539624
Validation loss: 2.609400022486336

Epoch: 6| Step: 6
Training loss: 3.15507742374172
Validation loss: 2.5927241204566314

Epoch: 6| Step: 7
Training loss: 3.2248560200569663
Validation loss: 2.5789498897287184

Epoch: 6| Step: 8
Training loss: 2.7852938967125986
Validation loss: 2.5770807651717837

Epoch: 6| Step: 9
Training loss: 2.7649949212743326
Validation loss: 2.573375792629937

Epoch: 6| Step: 10
Training loss: 2.6938024741458597
Validation loss: 2.5757842802876976

Epoch: 6| Step: 11
Training loss: 2.9061410534855163
Validation loss: 2.577585819626245

Epoch: 6| Step: 12
Training loss: 3.3524779023331868
Validation loss: 2.5746311830398176

Epoch: 6| Step: 13
Training loss: 3.0132004869204176
Validation loss: 2.5798022370865703

Epoch: 96| Step: 0
Training loss: 3.340984591336928
Validation loss: 2.576672663202583

Epoch: 6| Step: 1
Training loss: 3.055988785827992
Validation loss: 2.5760829401764975

Epoch: 6| Step: 2
Training loss: 2.607779740481493
Validation loss: 2.577373232202865

Epoch: 6| Step: 3
Training loss: 1.9854920614790403
Validation loss: 2.5790853720907725

Epoch: 6| Step: 4
Training loss: 3.0300180350292534
Validation loss: 2.5749676485037476

Epoch: 6| Step: 5
Training loss: 2.2902051137492494
Validation loss: 2.5741817772904803

Epoch: 6| Step: 6
Training loss: 3.469270959172716
Validation loss: 2.5790082207307425

Epoch: 6| Step: 7
Training loss: 3.2697876313569365
Validation loss: 2.578654121899613

Epoch: 6| Step: 8
Training loss: 2.857485788064693
Validation loss: 2.5864051321917056

Epoch: 6| Step: 9
Training loss: 3.7473279970279583
Validation loss: 2.6050068506938024

Epoch: 6| Step: 10
Training loss: 3.190273499438677
Validation loss: 2.614329760922317

Epoch: 6| Step: 11
Training loss: 2.990787507268822
Validation loss: 2.6169176011800412

Epoch: 6| Step: 12
Training loss: 2.290872840952349
Validation loss: 2.608756971888805

Epoch: 6| Step: 13
Training loss: 1.8649895152802074
Validation loss: 2.6099892288115876

Epoch: 97| Step: 0
Training loss: 2.023520213907266
Validation loss: 2.5925300537212843

Epoch: 6| Step: 1
Training loss: 3.0859600597474435
Validation loss: 2.5788794394674777

Epoch: 6| Step: 2
Training loss: 3.526259956007746
Validation loss: 2.5675617909953234

Epoch: 6| Step: 3
Training loss: 3.184380444642748
Validation loss: 2.569295127836625

Epoch: 6| Step: 4
Training loss: 3.18689602384274
Validation loss: 2.567589693166381

Epoch: 6| Step: 5
Training loss: 2.956460350892006
Validation loss: 2.566206895309507

Epoch: 6| Step: 6
Training loss: 2.6345752282485275
Validation loss: 2.567598574470148

Epoch: 6| Step: 7
Training loss: 3.208199700549128
Validation loss: 2.5668415574395906

Epoch: 6| Step: 8
Training loss: 2.731932502862271
Validation loss: 2.569014355746209

Epoch: 6| Step: 9
Training loss: 3.482424750463269
Validation loss: 2.5692395099069634

Epoch: 6| Step: 10
Training loss: 3.0320608096806163
Validation loss: 2.5641582454965013

Epoch: 6| Step: 11
Training loss: 2.5253733481681357
Validation loss: 2.564635286795991

Epoch: 6| Step: 12
Training loss: 2.37467030696315
Validation loss: 2.565843085676477

Epoch: 6| Step: 13
Training loss: 2.4126940555302117
Validation loss: 2.5632585352750925

Epoch: 98| Step: 0
Training loss: 3.1015572728033725
Validation loss: 2.567974582386729

Epoch: 6| Step: 1
Training loss: 3.0896208980554833
Validation loss: 2.5655417198696036

Epoch: 6| Step: 2
Training loss: 3.1915317543406716
Validation loss: 2.5660191563660653

Epoch: 6| Step: 3
Training loss: 2.3538628666295454
Validation loss: 2.5658639077034997

Epoch: 6| Step: 4
Training loss: 3.1367929338207787
Validation loss: 2.5652871689959325

Epoch: 6| Step: 5
Training loss: 3.4413614952130303
Validation loss: 2.561832376023993

Epoch: 6| Step: 6
Training loss: 3.0351817008464783
Validation loss: 2.569070269434187

Epoch: 6| Step: 7
Training loss: 2.9482908696605943
Validation loss: 2.5657631381136663

Epoch: 6| Step: 8
Training loss: 3.376695277804248
Validation loss: 2.5665905585456166

Epoch: 6| Step: 9
Training loss: 2.552373275375886
Validation loss: 2.585275091615125

Epoch: 6| Step: 10
Training loss: 2.7340737313107355
Validation loss: 2.5818133315051677

Epoch: 6| Step: 11
Training loss: 2.164705477056563
Validation loss: 2.5922169014776224

Epoch: 6| Step: 12
Training loss: 2.282794168491378
Validation loss: 2.6222989580867497

Epoch: 6| Step: 13
Training loss: 3.3076794654787967
Validation loss: 2.6104623711120603

Epoch: 99| Step: 0
Training loss: 2.3781679006709635
Validation loss: 2.622267172178855

Epoch: 6| Step: 1
Training loss: 2.8815035032019036
Validation loss: 2.6058788992351753

Epoch: 6| Step: 2
Training loss: 2.1047850225860336
Validation loss: 2.601862183507867

Epoch: 6| Step: 3
Training loss: 3.24242398422184
Validation loss: 2.5737410625336907

Epoch: 6| Step: 4
Training loss: 3.2726283564213228
Validation loss: 2.560901012907891

Epoch: 6| Step: 5
Training loss: 3.058241549854802
Validation loss: 2.5629122902867807

Epoch: 6| Step: 6
Training loss: 2.9364843032913632
Validation loss: 2.5720542274996965

Epoch: 6| Step: 7
Training loss: 3.033058649418601
Validation loss: 2.585836026541327

Epoch: 6| Step: 8
Training loss: 3.0657953710781514
Validation loss: 2.58357291412339

Epoch: 6| Step: 9
Training loss: 2.935559057640639
Validation loss: 2.585886054919384

Epoch: 6| Step: 10
Training loss: 2.9241433543851145
Validation loss: 2.5760043578614202

Epoch: 6| Step: 11
Training loss: 3.337186842953249
Validation loss: 2.572063818006748

Epoch: 6| Step: 12
Training loss: 2.7890643806344326
Validation loss: 2.571113965907829

Epoch: 6| Step: 13
Training loss: 3.3160265018798376
Validation loss: 2.563499549868131

Epoch: 100| Step: 0
Training loss: 2.594209928984092
Validation loss: 2.558359069256531

Epoch: 6| Step: 1
Training loss: 2.664518434769648
Validation loss: 2.560565878863122

Epoch: 6| Step: 2
Training loss: 2.733046901240424
Validation loss: 2.5719811443091314

Epoch: 6| Step: 3
Training loss: 2.7601118579256383
Validation loss: 2.61303649067117

Epoch: 6| Step: 4
Training loss: 3.112774548045986
Validation loss: 2.658741186587017

Epoch: 6| Step: 5
Training loss: 3.3494204631950915
Validation loss: 2.5968915444289795

Epoch: 6| Step: 6
Training loss: 3.0262614622848356
Validation loss: 2.579487976474237

Epoch: 6| Step: 7
Training loss: 3.0650424913258236
Validation loss: 2.5704150749968933

Epoch: 6| Step: 8
Training loss: 2.835127281278533
Validation loss: 2.5648428198763376

Epoch: 6| Step: 9
Training loss: 2.692711501178071
Validation loss: 2.563967868865647

Epoch: 6| Step: 10
Training loss: 3.075192056256215
Validation loss: 2.5597518613188854

Epoch: 6| Step: 11
Training loss: 2.466057963485948
Validation loss: 2.556973443155004

Epoch: 6| Step: 12
Training loss: 3.3074629291235986
Validation loss: 2.5599159860252194

Epoch: 6| Step: 13
Training loss: 3.1390124683940646
Validation loss: 2.5611882547756344

Epoch: 101| Step: 0
Training loss: 3.35942382777015
Validation loss: 2.559516658251042

Epoch: 6| Step: 1
Training loss: 2.582923261848699
Validation loss: 2.5620812164662863

Epoch: 6| Step: 2
Training loss: 3.0805666771303772
Validation loss: 2.5612347198030365

Epoch: 6| Step: 3
Training loss: 3.10277404951894
Validation loss: 2.560677698537765

Epoch: 6| Step: 4
Training loss: 2.9949240658006855
Validation loss: 2.565526923799028

Epoch: 6| Step: 5
Training loss: 2.864392157446432
Validation loss: 2.566540318363569

Epoch: 6| Step: 6
Training loss: 3.311390529025197
Validation loss: 2.5755429869087973

Epoch: 6| Step: 7
Training loss: 2.794759109843935
Validation loss: 2.5657917083004906

Epoch: 6| Step: 8
Training loss: 2.5756741983685276
Validation loss: 2.5865458012260554

Epoch: 6| Step: 9
Training loss: 3.104002946124694
Validation loss: 2.590813587786485

Epoch: 6| Step: 10
Training loss: 2.763406240684838
Validation loss: 2.6313521705218665

Epoch: 6| Step: 11
Training loss: 2.577781238179058
Validation loss: 2.6017514076812627

Epoch: 6| Step: 12
Training loss: 3.0290341487759234
Validation loss: 2.607137773573977

Epoch: 6| Step: 13
Training loss: 2.163898558208042
Validation loss: 2.6272340088159614

Epoch: 102| Step: 0
Training loss: 3.336271675756938
Validation loss: 2.676013485853175

Epoch: 6| Step: 1
Training loss: 2.932103495999908
Validation loss: 2.604460786679022

Epoch: 6| Step: 2
Training loss: 2.99369785844794
Validation loss: 2.577102767726879

Epoch: 6| Step: 3
Training loss: 2.050435936329565
Validation loss: 2.560073732357692

Epoch: 6| Step: 4
Training loss: 2.679350539839484
Validation loss: 2.556998140265163

Epoch: 6| Step: 5
Training loss: 3.0927831506892782
Validation loss: 2.5603822750793364

Epoch: 6| Step: 6
Training loss: 2.572429863184024
Validation loss: 2.564293432637263

Epoch: 6| Step: 7
Training loss: 2.4289883407997683
Validation loss: 2.5624988835029963

Epoch: 6| Step: 8
Training loss: 3.0542133870699546
Validation loss: 2.565541562985937

Epoch: 6| Step: 9
Training loss: 2.531240110024805
Validation loss: 2.562036702002425

Epoch: 6| Step: 10
Training loss: 3.392848678807765
Validation loss: 2.5640444379486054

Epoch: 6| Step: 11
Training loss: 3.28555872353447
Validation loss: 2.5643852496130703

Epoch: 6| Step: 12
Training loss: 3.4196689409785788
Validation loss: 2.566916548709836

Epoch: 6| Step: 13
Training loss: 2.8935627623389695
Validation loss: 2.568395294633248

Epoch: 103| Step: 0
Training loss: 2.982169249901587
Validation loss: 2.5750243742430667

Epoch: 6| Step: 1
Training loss: 2.6679815289259756
Validation loss: 2.572731234244556

Epoch: 6| Step: 2
Training loss: 2.725268212513983
Validation loss: 2.5843024551461413

Epoch: 6| Step: 3
Training loss: 2.970472458531149
Validation loss: 2.5895695816298065

Epoch: 6| Step: 4
Training loss: 2.989847488341176
Validation loss: 2.5848003995736506

Epoch: 6| Step: 5
Training loss: 2.578424424787987
Validation loss: 2.5865870116947747

Epoch: 6| Step: 6
Training loss: 3.4908252081492277
Validation loss: 2.5835942412167556

Epoch: 6| Step: 7
Training loss: 2.951247652950428
Validation loss: 2.5789364648626387

Epoch: 6| Step: 8
Training loss: 3.2807667694302727
Validation loss: 2.577497775041839

Epoch: 6| Step: 9
Training loss: 3.097146221952365
Validation loss: 2.5723952904805287

Epoch: 6| Step: 10
Training loss: 3.1077309100534682
Validation loss: 2.575261670556399

Epoch: 6| Step: 11
Training loss: 2.8812946572639078
Validation loss: 2.5691399773493764

Epoch: 6| Step: 12
Training loss: 2.474249014926794
Validation loss: 2.571550670663948

Epoch: 6| Step: 13
Training loss: 1.838645788023492
Validation loss: 2.5712986877656823

Epoch: 104| Step: 0
Training loss: 2.70903946889948
Validation loss: 2.5625005882616665

Epoch: 6| Step: 1
Training loss: 2.786439319201092
Validation loss: 2.5604623786386633

Epoch: 6| Step: 2
Training loss: 2.5733883897626937
Validation loss: 2.555202539964628

Epoch: 6| Step: 3
Training loss: 2.960925743864772
Validation loss: 2.5589695813280313

Epoch: 6| Step: 4
Training loss: 3.133030453375349
Validation loss: 2.5580221991098457

Epoch: 6| Step: 5
Training loss: 3.1628867896651442
Validation loss: 2.564646199038992

Epoch: 6| Step: 6
Training loss: 3.5409997349512476
Validation loss: 2.577751211624548

Epoch: 6| Step: 7
Training loss: 2.737658115506292
Validation loss: 2.585610844226603

Epoch: 6| Step: 8
Training loss: 2.8800112959852155
Validation loss: 2.587805274922691

Epoch: 6| Step: 9
Training loss: 3.1997782272737827
Validation loss: 2.5883660656255536

Epoch: 6| Step: 10
Training loss: 2.3403827129298653
Validation loss: 2.5855018400667205

Epoch: 6| Step: 11
Training loss: 2.789827471631923
Validation loss: 2.5972086617434185

Epoch: 6| Step: 12
Training loss: 2.6226200031938185
Validation loss: 2.5808286449746025

Epoch: 6| Step: 13
Training loss: 3.11901083182325
Validation loss: 2.5854731336968713

Epoch: 105| Step: 0
Training loss: 3.085146259321631
Validation loss: 2.580050602321511

Epoch: 6| Step: 1
Training loss: 2.5325603154824163
Validation loss: 2.5663353714827997

Epoch: 6| Step: 2
Training loss: 2.5830862685981875
Validation loss: 2.5611201497216527

Epoch: 6| Step: 3
Training loss: 2.867000397026532
Validation loss: 2.546759953037187

Epoch: 6| Step: 4
Training loss: 2.9762752524517846
Validation loss: 2.5460401865846545

Epoch: 6| Step: 5
Training loss: 3.1023028280479106
Validation loss: 2.5507560776100973

Epoch: 6| Step: 6
Training loss: 2.833207595129522
Validation loss: 2.5524541796787275

Epoch: 6| Step: 7
Training loss: 3.119356476368188
Validation loss: 2.5498802813649695

Epoch: 6| Step: 8
Training loss: 2.531292761924196
Validation loss: 2.5517208438788628

Epoch: 6| Step: 9
Training loss: 3.010094507704451
Validation loss: 2.5499697309254197

Epoch: 6| Step: 10
Training loss: 3.0097245913511244
Validation loss: 2.544699903637162

Epoch: 6| Step: 11
Training loss: 3.100569020623142
Validation loss: 2.556013879060876

Epoch: 6| Step: 12
Training loss: 2.922572414783476
Validation loss: 2.58119960402902

Epoch: 6| Step: 13
Training loss: 3.168853824276429
Validation loss: 2.601350952522625

Epoch: 106| Step: 0
Training loss: 2.5168792251691645
Validation loss: 2.654536174644664

Epoch: 6| Step: 1
Training loss: 2.715149611114659
Validation loss: 2.6960141769481427

Epoch: 6| Step: 2
Training loss: 3.353724922487366
Validation loss: 2.73117437177476

Epoch: 6| Step: 3
Training loss: 3.210716815427993
Validation loss: 2.6482466641250024

Epoch: 6| Step: 4
Training loss: 3.0149157386759446
Validation loss: 2.5724052105848676

Epoch: 6| Step: 5
Training loss: 2.3790142867888804
Validation loss: 2.539793535352884

Epoch: 6| Step: 6
Training loss: 2.176617720123229
Validation loss: 2.540770336510127

Epoch: 6| Step: 7
Training loss: 3.302814936092423
Validation loss: 2.5454886920281616

Epoch: 6| Step: 8
Training loss: 3.3981436766840356
Validation loss: 2.5541890839051984

Epoch: 6| Step: 9
Training loss: 2.8615021011528796
Validation loss: 2.5612948485272704

Epoch: 6| Step: 10
Training loss: 2.8861673161362975
Validation loss: 2.577535514771072

Epoch: 6| Step: 11
Training loss: 2.9951622421313764
Validation loss: 2.599358916778579

Epoch: 6| Step: 12
Training loss: 3.058238275559584
Validation loss: 2.6070181538637476

Epoch: 6| Step: 13
Training loss: 3.0049996041854623
Validation loss: 2.5896605182736527

Epoch: 107| Step: 0
Training loss: 2.9075819675374963
Validation loss: 2.5721944016311156

Epoch: 6| Step: 1
Training loss: 2.5942646113588297
Validation loss: 2.558400012279666

Epoch: 6| Step: 2
Training loss: 3.01176244800497
Validation loss: 2.5533946208023766

Epoch: 6| Step: 3
Training loss: 3.24479566709579
Validation loss: 2.5434315328738673

Epoch: 6| Step: 4
Training loss: 2.4130252720900205
Validation loss: 2.542629709733925

Epoch: 6| Step: 5
Training loss: 3.086913444617939
Validation loss: 2.541182540654226

Epoch: 6| Step: 6
Training loss: 3.112931101408166
Validation loss: 2.538431940149515

Epoch: 6| Step: 7
Training loss: 3.082890727949746
Validation loss: 2.5461694991070596

Epoch: 6| Step: 8
Training loss: 2.821242667794154
Validation loss: 2.547368214065237

Epoch: 6| Step: 9
Training loss: 2.7577001100283884
Validation loss: 2.5632521763194296

Epoch: 6| Step: 10
Training loss: 3.838267191886974
Validation loss: 2.5803830994321535

Epoch: 6| Step: 11
Training loss: 3.1368964538022994
Validation loss: 2.6016216148797846

Epoch: 6| Step: 12
Training loss: 2.120772476172519
Validation loss: 2.6097902337613688

Epoch: 6| Step: 13
Training loss: 1.7559441025163953
Validation loss: 2.6173492582458127

Epoch: 108| Step: 0
Training loss: 2.847704140007974
Validation loss: 2.6215169645116907

Epoch: 6| Step: 1
Training loss: 2.847999164881209
Validation loss: 2.609492427450004

Epoch: 6| Step: 2
Training loss: 3.5320394528130667
Validation loss: 2.592975154286796

Epoch: 6| Step: 3
Training loss: 2.7013141542201344
Validation loss: 2.557763673493711

Epoch: 6| Step: 4
Training loss: 2.994352110518664
Validation loss: 2.5415664813144856

Epoch: 6| Step: 5
Training loss: 2.5557525001415886
Validation loss: 2.548258083972508

Epoch: 6| Step: 6
Training loss: 3.1546566406675405
Validation loss: 2.5494110578644253

Epoch: 6| Step: 7
Training loss: 3.238929085530239
Validation loss: 2.5511157038252867

Epoch: 6| Step: 8
Training loss: 2.7964595720576897
Validation loss: 2.548517845452904

Epoch: 6| Step: 9
Training loss: 2.051058389012053
Validation loss: 2.5445427527557727

Epoch: 6| Step: 10
Training loss: 2.9696388921620267
Validation loss: 2.540317887274044

Epoch: 6| Step: 11
Training loss: 3.3251271962094444
Validation loss: 2.5409025162814514

Epoch: 6| Step: 12
Training loss: 3.267702746708263
Validation loss: 2.532002147767739

Epoch: 6| Step: 13
Training loss: 2.2036184204771945
Validation loss: 2.5350521512544915

Epoch: 109| Step: 0
Training loss: 3.251117807507291
Validation loss: 2.533148939090624

Epoch: 6| Step: 1
Training loss: 2.437710386146659
Validation loss: 2.531907758145726

Epoch: 6| Step: 2
Training loss: 2.5038624490367454
Validation loss: 2.5308426671422586

Epoch: 6| Step: 3
Training loss: 3.045018339556007
Validation loss: 2.530713060745039

Epoch: 6| Step: 4
Training loss: 3.0116171021878646
Validation loss: 2.535961497569488

Epoch: 6| Step: 5
Training loss: 3.639379198142999
Validation loss: 2.5617938615685807

Epoch: 6| Step: 6
Training loss: 2.920436892812009
Validation loss: 2.5797199584638557

Epoch: 6| Step: 7
Training loss: 2.7927572103565566
Validation loss: 2.624948633905348

Epoch: 6| Step: 8
Training loss: 1.6249353689398884
Validation loss: 2.644068201754212

Epoch: 6| Step: 9
Training loss: 2.9799964300556687
Validation loss: 2.6770532401329383

Epoch: 6| Step: 10
Training loss: 3.3300151203717223
Validation loss: 2.6929389174315768

Epoch: 6| Step: 11
Training loss: 3.144379606203767
Validation loss: 2.6621007136648944

Epoch: 6| Step: 12
Training loss: 2.878121712979936
Validation loss: 2.558136458973806

Epoch: 6| Step: 13
Training loss: 2.7742320467287302
Validation loss: 2.535421764357094

Epoch: 110| Step: 0
Training loss: 3.2388507632117634
Validation loss: 2.523478652017626

Epoch: 6| Step: 1
Training loss: 3.371482146024492
Validation loss: 2.5287455458463923

Epoch: 6| Step: 2
Training loss: 2.599282305037631
Validation loss: 2.5329126720659683

Epoch: 6| Step: 3
Training loss: 2.7924597643187905
Validation loss: 2.5339130170968405

Epoch: 6| Step: 4
Training loss: 2.8543359933639025
Validation loss: 2.5410590579427423

Epoch: 6| Step: 5
Training loss: 3.1473204948014226
Validation loss: 2.5367910387559194

Epoch: 6| Step: 6
Training loss: 2.4539297934067386
Validation loss: 2.5452075640780882

Epoch: 6| Step: 7
Training loss: 2.1915287520767777
Validation loss: 2.5423711798551962

Epoch: 6| Step: 8
Training loss: 3.2244168367904806
Validation loss: 2.5447620721981488

Epoch: 6| Step: 9
Training loss: 3.0461885119068457
Validation loss: 2.540525300830617

Epoch: 6| Step: 10
Training loss: 3.1577122388775596
Validation loss: 2.527944892699987

Epoch: 6| Step: 11
Training loss: 3.001111937131285
Validation loss: 2.517853911389944

Epoch: 6| Step: 12
Training loss: 2.821592848687753
Validation loss: 2.5169918673138167

Epoch: 6| Step: 13
Training loss: 2.6943642537701966
Validation loss: 2.526350447051543

Epoch: 111| Step: 0
Training loss: 3.1508716043446503
Validation loss: 2.5537053930186757

Epoch: 6| Step: 1
Training loss: 2.7888044991291148
Validation loss: 2.577243639115777

Epoch: 6| Step: 2
Training loss: 2.6641595101242985
Validation loss: 2.5910583923265063

Epoch: 6| Step: 3
Training loss: 3.269251220086805
Validation loss: 2.5913082034621318

Epoch: 6| Step: 4
Training loss: 2.7041393868393344
Validation loss: 2.5770253709826165

Epoch: 6| Step: 5
Training loss: 2.909835080851474
Validation loss: 2.573334284915118

Epoch: 6| Step: 6
Training loss: 3.415145318219367
Validation loss: 2.569334926745261

Epoch: 6| Step: 7
Training loss: 2.204098966408529
Validation loss: 2.558667698511471

Epoch: 6| Step: 8
Training loss: 3.4607842887221976
Validation loss: 2.550709227719946

Epoch: 6| Step: 9
Training loss: 3.0012963990704487
Validation loss: 2.5431643477382684

Epoch: 6| Step: 10
Training loss: 2.3252821597270663
Validation loss: 2.531304888913179

Epoch: 6| Step: 11
Training loss: 2.751944288100166
Validation loss: 2.5265932361145835

Epoch: 6| Step: 12
Training loss: 2.7799840038854775
Validation loss: 2.528944745521063

Epoch: 6| Step: 13
Training loss: 2.7233829705124375
Validation loss: 2.5314116614343076

Epoch: 112| Step: 0
Training loss: 2.2495857493211022
Validation loss: 2.530188622178764

Epoch: 6| Step: 1
Training loss: 2.724232899897382
Validation loss: 2.5374139883635842

Epoch: 6| Step: 2
Training loss: 3.192914963342238
Validation loss: 2.5496514237554653

Epoch: 6| Step: 3
Training loss: 3.7043739498285615
Validation loss: 2.554091172057053

Epoch: 6| Step: 4
Training loss: 2.756465766748137
Validation loss: 2.5644765214782397

Epoch: 6| Step: 5
Training loss: 2.6453994835817096
Validation loss: 2.5741098032221164

Epoch: 6| Step: 6
Training loss: 2.9610598898682747
Validation loss: 2.5638485593185156

Epoch: 6| Step: 7
Training loss: 2.3975597850676493
Validation loss: 2.5656704082100124

Epoch: 6| Step: 8
Training loss: 2.44942365212096
Validation loss: 2.559540701314955

Epoch: 6| Step: 9
Training loss: 2.721434397024321
Validation loss: 2.566156631132283

Epoch: 6| Step: 10
Training loss: 3.226137738290307
Validation loss: 2.5539909106264918

Epoch: 6| Step: 11
Training loss: 3.1016605851737094
Validation loss: 2.531520243177249

Epoch: 6| Step: 12
Training loss: 3.4917423382725086
Validation loss: 2.524399223402238

Epoch: 6| Step: 13
Training loss: 1.8492764552999725
Validation loss: 2.5222533719772033

Epoch: 113| Step: 0
Training loss: 2.6664836542589523
Validation loss: 2.5220834328575794

Epoch: 6| Step: 1
Training loss: 3.334100650844749
Validation loss: 2.518981379082524

Epoch: 6| Step: 2
Training loss: 1.9292411751361778
Validation loss: 2.5189207227159858

Epoch: 6| Step: 3
Training loss: 3.0724056185324944
Validation loss: 2.518241922928398

Epoch: 6| Step: 4
Training loss: 2.6489523778186674
Validation loss: 2.522086995608107

Epoch: 6| Step: 5
Training loss: 2.888556487775312
Validation loss: 2.5216235579325827

Epoch: 6| Step: 6
Training loss: 3.0494141000288217
Validation loss: 2.5169617898386862

Epoch: 6| Step: 7
Training loss: 2.9490092019926792
Validation loss: 2.513109042871136

Epoch: 6| Step: 8
Training loss: 2.4243511708389813
Validation loss: 2.5136928446403766

Epoch: 6| Step: 9
Training loss: 3.0588230714538716
Validation loss: 2.5121493141380298

Epoch: 6| Step: 10
Training loss: 2.7845168911350857
Validation loss: 2.511730512194915

Epoch: 6| Step: 11
Training loss: 2.7297904682445497
Validation loss: 2.513160638343694

Epoch: 6| Step: 12
Training loss: 3.3053661758783437
Validation loss: 2.514887335811162

Epoch: 6| Step: 13
Training loss: 3.3988275413745046
Validation loss: 2.520419893774653

Epoch: 114| Step: 0
Training loss: 2.467994864175606
Validation loss: 2.519737135143075

Epoch: 6| Step: 1
Training loss: 3.152929088604524
Validation loss: 2.528424841507773

Epoch: 6| Step: 2
Training loss: 3.0848464002657283
Validation loss: 2.5417681044562195

Epoch: 6| Step: 3
Training loss: 2.9396263705175505
Validation loss: 2.557585949914857

Epoch: 6| Step: 4
Training loss: 2.7714830846158467
Validation loss: 2.5465512825218877

Epoch: 6| Step: 5
Training loss: 3.1603083438368795
Validation loss: 2.5317308998844803

Epoch: 6| Step: 6
Training loss: 3.093944813152933
Validation loss: 2.5237443415408767

Epoch: 6| Step: 7
Training loss: 3.263993581260653
Validation loss: 2.5171987738981003

Epoch: 6| Step: 8
Training loss: 2.7705059192692687
Validation loss: 2.515501542738002

Epoch: 6| Step: 9
Training loss: 3.1128848408623635
Validation loss: 2.514283140502399

Epoch: 6| Step: 10
Training loss: 2.263747285602191
Validation loss: 2.51988408450547

Epoch: 6| Step: 11
Training loss: 2.743605548644917
Validation loss: 2.5230838994330376

Epoch: 6| Step: 12
Training loss: 2.627182915716345
Validation loss: 2.5334244764989573

Epoch: 6| Step: 13
Training loss: 2.5121348556960723
Validation loss: 2.5500609034922603

Epoch: 115| Step: 0
Training loss: 2.8983272726892415
Validation loss: 2.5483700905963618

Epoch: 6| Step: 1
Training loss: 2.946693481162204
Validation loss: 2.5733891289519613

Epoch: 6| Step: 2
Training loss: 3.223413145016753
Validation loss: 2.5419143802827544

Epoch: 6| Step: 3
Training loss: 2.8864081890624407
Validation loss: 2.521611092600307

Epoch: 6| Step: 4
Training loss: 3.041971496217752
Validation loss: 2.515846615156045

Epoch: 6| Step: 5
Training loss: 3.3208992473294168
Validation loss: 2.518970942249049

Epoch: 6| Step: 6
Training loss: 2.3320904441490176
Validation loss: 2.517035224894622

Epoch: 6| Step: 7
Training loss: 2.4183420315285264
Validation loss: 2.5223943530915602

Epoch: 6| Step: 8
Training loss: 3.2645995067657525
Validation loss: 2.5276186564787935

Epoch: 6| Step: 9
Training loss: 3.0658238337719474
Validation loss: 2.5211009859190927

Epoch: 6| Step: 10
Training loss: 2.8496731286241306
Validation loss: 2.5205635669530273

Epoch: 6| Step: 11
Training loss: 2.6169601113905756
Validation loss: 2.5145567557864057

Epoch: 6| Step: 12
Training loss: 2.1718412986720352
Validation loss: 2.513831630876514

Epoch: 6| Step: 13
Training loss: 3.217175737593845
Validation loss: 2.510642784479814

Epoch: 116| Step: 0
Training loss: 2.9809825849257923
Validation loss: 2.516765012865663

Epoch: 6| Step: 1
Training loss: 2.135778244544453
Validation loss: 2.519450608228705

Epoch: 6| Step: 2
Training loss: 2.631634819541893
Validation loss: 2.5204995087778213

Epoch: 6| Step: 3
Training loss: 2.8538646863097967
Validation loss: 2.527182617061863

Epoch: 6| Step: 4
Training loss: 2.89608529364661
Validation loss: 2.5323703200304353

Epoch: 6| Step: 5
Training loss: 3.029063744001134
Validation loss: 2.5407522844032955

Epoch: 6| Step: 6
Training loss: 3.275671585762003
Validation loss: 2.5438120613268476

Epoch: 6| Step: 7
Training loss: 2.274102077813338
Validation loss: 2.5388632863588

Epoch: 6| Step: 8
Training loss: 3.3419064582412785
Validation loss: 2.533161108807183

Epoch: 6| Step: 9
Training loss: 2.7894216781700503
Validation loss: 2.529594486674049

Epoch: 6| Step: 10
Training loss: 3.091798263038618
Validation loss: 2.5191580007923995

Epoch: 6| Step: 11
Training loss: 2.2195652283401013
Validation loss: 2.5148806343594696

Epoch: 6| Step: 12
Training loss: 2.906845359938199
Validation loss: 2.517146051254186

Epoch: 6| Step: 13
Training loss: 3.7833077372442734
Validation loss: 2.5230041586962626

Epoch: 117| Step: 0
Training loss: 2.9112646667451703
Validation loss: 2.5178743503490946

Epoch: 6| Step: 1
Training loss: 3.2734670705984628
Validation loss: 2.5289787667327954

Epoch: 6| Step: 2
Training loss: 3.01703385564909
Validation loss: 2.531163997953936

Epoch: 6| Step: 3
Training loss: 2.8098964932747044
Validation loss: 2.547678539035995

Epoch: 6| Step: 4
Training loss: 2.9160785808780867
Validation loss: 2.5561101747291604

Epoch: 6| Step: 5
Training loss: 3.170832420345648
Validation loss: 2.5810019333008754

Epoch: 6| Step: 6
Training loss: 2.696617805531835
Validation loss: 2.600436210877574

Epoch: 6| Step: 7
Training loss: 2.237212080518741
Validation loss: 2.6077082827977476

Epoch: 6| Step: 8
Training loss: 3.2776003931471274
Validation loss: 2.5787446720105094

Epoch: 6| Step: 9
Training loss: 2.307024272180863
Validation loss: 2.577899040693975

Epoch: 6| Step: 10
Training loss: 2.678740130970158
Validation loss: 2.5502555652346914

Epoch: 6| Step: 11
Training loss: 2.9384259327019113
Validation loss: 2.5389063916046184

Epoch: 6| Step: 12
Training loss: 2.950545541783862
Validation loss: 2.526423171860103

Epoch: 6| Step: 13
Training loss: 2.891216485620479
Validation loss: 2.514420936775809

Epoch: 118| Step: 0
Training loss: 2.6520472769572394
Validation loss: 2.509744942268131

Epoch: 6| Step: 1
Training loss: 3.5889310953068394
Validation loss: 2.5092852182200116

Epoch: 6| Step: 2
Training loss: 2.74743532752024
Validation loss: 2.5137664323035938

Epoch: 6| Step: 3
Training loss: 2.7984646163810902
Validation loss: 2.5179107498978817

Epoch: 6| Step: 4
Training loss: 2.429025541451586
Validation loss: 2.5207266897290115

Epoch: 6| Step: 5
Training loss: 2.103723938951097
Validation loss: 2.51547025503826

Epoch: 6| Step: 6
Training loss: 2.803244386850213
Validation loss: 2.51650021593486

Epoch: 6| Step: 7
Training loss: 3.5650419569288503
Validation loss: 2.5168784133614723

Epoch: 6| Step: 8
Training loss: 2.787510373220259
Validation loss: 2.5164836237834205

Epoch: 6| Step: 9
Training loss: 3.133316722447079
Validation loss: 2.5198782336353838

Epoch: 6| Step: 10
Training loss: 3.2920483878879727
Validation loss: 2.5196046905485274

Epoch: 6| Step: 11
Training loss: 2.40085025667076
Validation loss: 2.5187973272470194

Epoch: 6| Step: 12
Training loss: 2.975982208957612
Validation loss: 2.5237573408071583

Epoch: 6| Step: 13
Training loss: 2.428079250695135
Validation loss: 2.5234954145648185

Epoch: 119| Step: 0
Training loss: 2.8270322258606617
Validation loss: 2.5290134544962672

Epoch: 6| Step: 1
Training loss: 2.403637942173418
Validation loss: 2.52469074309259

Epoch: 6| Step: 2
Training loss: 2.7334508587606843
Validation loss: 2.534033681464286

Epoch: 6| Step: 3
Training loss: 2.835060341275274
Validation loss: 2.5384982402316907

Epoch: 6| Step: 4
Training loss: 3.152008379145682
Validation loss: 2.5336272990284057

Epoch: 6| Step: 5
Training loss: 2.4568136873942783
Validation loss: 2.530305542158832

Epoch: 6| Step: 6
Training loss: 2.567056094595101
Validation loss: 2.553921591768237

Epoch: 6| Step: 7
Training loss: 2.38373475284431
Validation loss: 2.561791950190966

Epoch: 6| Step: 8
Training loss: 3.0884293551339055
Validation loss: 2.589356870192321

Epoch: 6| Step: 9
Training loss: 3.0360205167295775
Validation loss: 2.593055641051619

Epoch: 6| Step: 10
Training loss: 3.245326276225575
Validation loss: 2.5827109484888804

Epoch: 6| Step: 11
Training loss: 3.2912975699887523
Validation loss: 2.5332230869255943

Epoch: 6| Step: 12
Training loss: 2.8030974149675663
Validation loss: 2.5220702684253133

Epoch: 6| Step: 13
Training loss: 3.0512744929773428
Validation loss: 2.51138675862108

Epoch: 120| Step: 0
Training loss: 2.9146291064325776
Validation loss: 2.5081059772248455

Epoch: 6| Step: 1
Training loss: 2.9373302004822404
Validation loss: 2.517513680271867

Epoch: 6| Step: 2
Training loss: 2.887962310904369
Validation loss: 2.523719641023584

Epoch: 6| Step: 3
Training loss: 2.8512711885660877
Validation loss: 2.529671839786599

Epoch: 6| Step: 4
Training loss: 2.9174412016839693
Validation loss: 2.5320217566910475

Epoch: 6| Step: 5
Training loss: 2.7654486131185507
Validation loss: 2.5369119906597275

Epoch: 6| Step: 6
Training loss: 2.6360693463883886
Validation loss: 2.5248164874675885

Epoch: 6| Step: 7
Training loss: 2.4042160553600067
Validation loss: 2.522076998547869

Epoch: 6| Step: 8
Training loss: 2.382123403496314
Validation loss: 2.516055808620236

Epoch: 6| Step: 9
Training loss: 2.460052524874292
Validation loss: 2.509316965135267

Epoch: 6| Step: 10
Training loss: 3.046988460677919
Validation loss: 2.5199585036204355

Epoch: 6| Step: 11
Training loss: 3.125456357058977
Validation loss: 2.5254227125516207

Epoch: 6| Step: 12
Training loss: 3.455464670867548
Validation loss: 2.5530001257850556

Epoch: 6| Step: 13
Training loss: 3.363160311732057
Validation loss: 2.6024213488803727

Epoch: 121| Step: 0
Training loss: 2.4526214082708218
Validation loss: 2.6415471418668965

Epoch: 6| Step: 1
Training loss: 3.172694509088142
Validation loss: 2.6863690357770524

Epoch: 6| Step: 2
Training loss: 2.8416992170719997
Validation loss: 2.6681501955966898

Epoch: 6| Step: 3
Training loss: 2.706265780290579
Validation loss: 2.7197476957273374

Epoch: 6| Step: 4
Training loss: 3.187643160129565
Validation loss: 2.6627447400670983

Epoch: 6| Step: 5
Training loss: 3.0367531128968923
Validation loss: 2.57041122915667

Epoch: 6| Step: 6
Training loss: 2.207611601828453
Validation loss: 2.5259888518613582

Epoch: 6| Step: 7
Training loss: 2.1366430963097933
Validation loss: 2.5138528617841605

Epoch: 6| Step: 8
Training loss: 3.262712411798578
Validation loss: 2.5152695071591955

Epoch: 6| Step: 9
Training loss: 2.9222183433800284
Validation loss: 2.509001153621656

Epoch: 6| Step: 10
Training loss: 3.125729132467832
Validation loss: 2.5091652446819124

Epoch: 6| Step: 11
Training loss: 2.7959537800419048
Validation loss: 2.5182461365425133

Epoch: 6| Step: 12
Training loss: 2.837126679586322
Validation loss: 2.5107432994437304

Epoch: 6| Step: 13
Training loss: 4.129732826956957
Validation loss: 2.5107922826801112

Epoch: 122| Step: 0
Training loss: 3.22006376546902
Validation loss: 2.512502019035823

Epoch: 6| Step: 1
Training loss: 2.922418717166872
Validation loss: 2.506089611914083

Epoch: 6| Step: 2
Training loss: 3.4769439145146093
Validation loss: 2.5013808200523666

Epoch: 6| Step: 3
Training loss: 3.0875998353454253
Validation loss: 2.505370388213614

Epoch: 6| Step: 4
Training loss: 2.4963437046272454
Validation loss: 2.504201778970846

Epoch: 6| Step: 5
Training loss: 3.174031543961942
Validation loss: 2.5083040130101333

Epoch: 6| Step: 6
Training loss: 2.618503706464171
Validation loss: 2.519961685840632

Epoch: 6| Step: 7
Training loss: 2.470229369567763
Validation loss: 2.5379695880737994

Epoch: 6| Step: 8
Training loss: 3.1605512563118503
Validation loss: 2.524460086302605

Epoch: 6| Step: 9
Training loss: 2.608158399019316
Validation loss: 2.5399966809738213

Epoch: 6| Step: 10
Training loss: 2.780271036396926
Validation loss: 2.521412313006696

Epoch: 6| Step: 11
Training loss: 1.9863400079152305
Validation loss: 2.5174611200295582

Epoch: 6| Step: 12
Training loss: 3.330933008624877
Validation loss: 2.510457699559111

Epoch: 6| Step: 13
Training loss: 2.0014903952649004
Validation loss: 2.5150398629141497

Epoch: 123| Step: 0
Training loss: 2.887481629944863
Validation loss: 2.5239097523874197

Epoch: 6| Step: 1
Training loss: 2.4473733718424766
Validation loss: 2.519153296156279

Epoch: 6| Step: 2
Training loss: 3.2231079524818975
Validation loss: 2.5385225495249917

Epoch: 6| Step: 3
Training loss: 3.6190256017120364
Validation loss: 2.5410518726416518

Epoch: 6| Step: 4
Training loss: 2.7024883777463775
Validation loss: 2.5407456985963215

Epoch: 6| Step: 5
Training loss: 1.952257131400598
Validation loss: 2.5340400378651613

Epoch: 6| Step: 6
Training loss: 2.7845059313746043
Validation loss: 2.5273926295876445

Epoch: 6| Step: 7
Training loss: 2.393756386372386
Validation loss: 2.5223225061429284

Epoch: 6| Step: 8
Training loss: 3.320930261924425
Validation loss: 2.5192086908320537

Epoch: 6| Step: 9
Training loss: 2.2493508780103664
Validation loss: 2.512190861795775

Epoch: 6| Step: 10
Training loss: 2.4504580244770815
Validation loss: 2.516317279050447

Epoch: 6| Step: 11
Training loss: 3.4083689127388643
Validation loss: 2.516553925996947

Epoch: 6| Step: 12
Training loss: 2.848530869201345
Validation loss: 2.517762570409168

Epoch: 6| Step: 13
Training loss: 3.2359261594064317
Validation loss: 2.5163529497634762

Epoch: 124| Step: 0
Training loss: 3.1028969918160816
Validation loss: 2.502454519762225

Epoch: 6| Step: 1
Training loss: 3.1648177387615988
Validation loss: 2.513344420565291

Epoch: 6| Step: 2
Training loss: 2.498867923001623
Validation loss: 2.5197876283649836

Epoch: 6| Step: 3
Training loss: 2.2734652907518016
Validation loss: 2.5272212790903548

Epoch: 6| Step: 4
Training loss: 2.5018429638853
Validation loss: 2.554231951590059

Epoch: 6| Step: 5
Training loss: 2.9013699814337777
Validation loss: 2.5685591335338733

Epoch: 6| Step: 6
Training loss: 3.490387932932854
Validation loss: 2.5335283284385945

Epoch: 6| Step: 7
Training loss: 2.983058459300864
Validation loss: 2.5155031488973636

Epoch: 6| Step: 8
Training loss: 2.6293934884950345
Validation loss: 2.4944251095600825

Epoch: 6| Step: 9
Training loss: 3.273968710393883
Validation loss: 2.496521917618816

Epoch: 6| Step: 10
Training loss: 2.812029057386531
Validation loss: 2.498969501461395

Epoch: 6| Step: 11
Training loss: 2.352092695822946
Validation loss: 2.49882318681074

Epoch: 6| Step: 12
Training loss: 2.7721801486631144
Validation loss: 2.4992350536024004

Epoch: 6| Step: 13
Training loss: 2.857997207971254
Validation loss: 2.5087700353245537

Epoch: 125| Step: 0
Training loss: 2.959663217561951
Validation loss: 2.5139836672854745

Epoch: 6| Step: 1
Training loss: 2.6848193261647886
Validation loss: 2.5095617892806903

Epoch: 6| Step: 2
Training loss: 3.338483995404687
Validation loss: 2.5246402392808602

Epoch: 6| Step: 3
Training loss: 3.326003137005527
Validation loss: 2.5195175543188135

Epoch: 6| Step: 4
Training loss: 2.8027926448918783
Validation loss: 2.506399190944209

Epoch: 6| Step: 5
Training loss: 2.3633651844599024
Validation loss: 2.5052621855384234

Epoch: 6| Step: 6
Training loss: 2.400432937038085
Validation loss: 2.5130277859383723

Epoch: 6| Step: 7
Training loss: 2.8325747053996513
Validation loss: 2.5065211522171165

Epoch: 6| Step: 8
Training loss: 2.912353996579331
Validation loss: 2.5269482021863285

Epoch: 6| Step: 9
Training loss: 2.744094055432247
Validation loss: 2.5217000626741446

Epoch: 6| Step: 10
Training loss: 2.81108998875814
Validation loss: 2.522966759607462

Epoch: 6| Step: 11
Training loss: 2.6406309590469927
Validation loss: 2.512693083197766

Epoch: 6| Step: 12
Training loss: 2.867750232158123
Validation loss: 2.4999876821891287

Epoch: 6| Step: 13
Training loss: 3.0702137239597858
Validation loss: 2.4955171611789506

Epoch: 126| Step: 0
Training loss: 2.5663776367078825
Validation loss: 2.500833740466701

Epoch: 6| Step: 1
Training loss: 3.0043065631548056
Validation loss: 2.4963531279778954

Epoch: 6| Step: 2
Training loss: 2.672116631183866
Validation loss: 2.494045745059699

Epoch: 6| Step: 3
Training loss: 2.997114383178342
Validation loss: 2.493527189438283

Epoch: 6| Step: 4
Training loss: 2.6400537719452246
Validation loss: 2.4893654379422703

Epoch: 6| Step: 5
Training loss: 3.149398316336606
Validation loss: 2.494199992766082

Epoch: 6| Step: 6
Training loss: 2.6545633683306855
Validation loss: 2.4935758940051604

Epoch: 6| Step: 7
Training loss: 2.2683843186604813
Validation loss: 2.4943146910004117

Epoch: 6| Step: 8
Training loss: 2.739508034332464
Validation loss: 2.501071254340997

Epoch: 6| Step: 9
Training loss: 3.0392300674802772
Validation loss: 2.508836595064579

Epoch: 6| Step: 10
Training loss: 3.1569063618366613
Validation loss: 2.546054613591404

Epoch: 6| Step: 11
Training loss: 2.6312256510643186
Validation loss: 2.581158169488942

Epoch: 6| Step: 12
Training loss: 3.0263370932171827
Validation loss: 2.6287664960708623

Epoch: 6| Step: 13
Training loss: 3.5046045804599495
Validation loss: 2.6193904552771614

Epoch: 127| Step: 0
Training loss: 2.7910430458382263
Validation loss: 2.574897407887788

Epoch: 6| Step: 1
Training loss: 2.5615651355975104
Validation loss: 2.5572896169229

Epoch: 6| Step: 2
Training loss: 3.0907636929549427
Validation loss: 2.5076144576018597

Epoch: 6| Step: 3
Training loss: 3.0124178420137557
Validation loss: 2.4991575287975856

Epoch: 6| Step: 4
Training loss: 2.923355461857499
Validation loss: 2.4924331643225504

Epoch: 6| Step: 5
Training loss: 3.2445500969195864
Validation loss: 2.4925506334439027

Epoch: 6| Step: 6
Training loss: 2.8034911938225044
Validation loss: 2.5106342816884757

Epoch: 6| Step: 7
Training loss: 2.606863492118551
Validation loss: 2.513670842882451

Epoch: 6| Step: 8
Training loss: 2.866845882343582
Validation loss: 2.5129789676756897

Epoch: 6| Step: 9
Training loss: 2.6517688425911774
Validation loss: 2.5147325658459665

Epoch: 6| Step: 10
Training loss: 3.1156555847687
Validation loss: 2.5116312411741086

Epoch: 6| Step: 11
Training loss: 2.7347473762904837
Validation loss: 2.5115140877688096

Epoch: 6| Step: 12
Training loss: 2.7192742730127275
Validation loss: 2.5095278383768327

Epoch: 6| Step: 13
Training loss: 3.1552574183282616
Validation loss: 2.5090101442247508

Epoch: 128| Step: 0
Training loss: 2.9964548462830187
Validation loss: 2.505538160093347

Epoch: 6| Step: 1
Training loss: 2.8535919910319585
Validation loss: 2.499887134711492

Epoch: 6| Step: 2
Training loss: 2.181534616871099
Validation loss: 2.4959438397776244

Epoch: 6| Step: 3
Training loss: 3.2795277753358363
Validation loss: 2.494488119999483

Epoch: 6| Step: 4
Training loss: 3.103235979967247
Validation loss: 2.505055858826086

Epoch: 6| Step: 5
Training loss: 3.100396463206753
Validation loss: 2.5220789181694747

Epoch: 6| Step: 6
Training loss: 2.695741304205435
Validation loss: 2.5510445401601247

Epoch: 6| Step: 7
Training loss: 3.1116591455266196
Validation loss: 2.6014698517959025

Epoch: 6| Step: 8
Training loss: 2.8985720703472375
Validation loss: 2.6096084231931096

Epoch: 6| Step: 9
Training loss: 2.126682737204043
Validation loss: 2.5683740559356467

Epoch: 6| Step: 10
Training loss: 2.921772674563956
Validation loss: 2.537823828363429

Epoch: 6| Step: 11
Training loss: 3.0004086216159758
Validation loss: 2.51083015614561

Epoch: 6| Step: 12
Training loss: 2.3134345151043867
Validation loss: 2.512835476034005

Epoch: 6| Step: 13
Training loss: 3.133290546882635
Validation loss: 2.5217177316740416

Epoch: 129| Step: 0
Training loss: 2.8953569601302545
Validation loss: 2.5188909919223454

Epoch: 6| Step: 1
Training loss: 3.0463500524345153
Validation loss: 2.516682260928552

Epoch: 6| Step: 2
Training loss: 2.8205243398302215
Validation loss: 2.5176911533584887

Epoch: 6| Step: 3
Training loss: 2.785643033454352
Validation loss: 2.509852980286538

Epoch: 6| Step: 4
Training loss: 3.2440594887505894
Validation loss: 2.507526347517029

Epoch: 6| Step: 5
Training loss: 3.0554115627538723
Validation loss: 2.5025257129328993

Epoch: 6| Step: 6
Training loss: 2.520373110624745
Validation loss: 2.498606700673261

Epoch: 6| Step: 7
Training loss: 2.648254568258267
Validation loss: 2.4929475903649845

Epoch: 6| Step: 8
Training loss: 2.9464510631941354
Validation loss: 2.4975754537897337

Epoch: 6| Step: 9
Training loss: 2.6762916690695184
Validation loss: 2.5012928060598387

Epoch: 6| Step: 10
Training loss: 2.888091425581872
Validation loss: 2.503524606056807

Epoch: 6| Step: 11
Training loss: 3.0080452172553414
Validation loss: 2.5177677836991816

Epoch: 6| Step: 12
Training loss: 2.6799838511137013
Validation loss: 2.552414598661252

Epoch: 6| Step: 13
Training loss: 1.821183614260571
Validation loss: 2.588024841902082

Epoch: 130| Step: 0
Training loss: 2.163846772937143
Validation loss: 2.619648593712817

Epoch: 6| Step: 1
Training loss: 2.6761930496877047
Validation loss: 2.615707142377433

Epoch: 6| Step: 2
Training loss: 3.1680941292332414
Validation loss: 2.6118514970851128

Epoch: 6| Step: 3
Training loss: 2.764678620739952
Validation loss: 2.5687162452912933

Epoch: 6| Step: 4
Training loss: 3.2440325898721842
Validation loss: 2.5613181177134794

Epoch: 6| Step: 5
Training loss: 2.725712597267517
Validation loss: 2.535587467958212

Epoch: 6| Step: 6
Training loss: 2.956879666070153
Validation loss: 2.5104522249827275

Epoch: 6| Step: 7
Training loss: 2.9369917084859694
Validation loss: 2.5074511729552773

Epoch: 6| Step: 8
Training loss: 2.055699436490475
Validation loss: 2.4977914006591666

Epoch: 6| Step: 9
Training loss: 2.7793840299493517
Validation loss: 2.507233813695587

Epoch: 6| Step: 10
Training loss: 3.07312147244648
Validation loss: 2.5177713393196943

Epoch: 6| Step: 11
Training loss: 2.5044578861070295
Validation loss: 2.5174076136470105

Epoch: 6| Step: 12
Training loss: 2.7505899143386627
Validation loss: 2.51517921390338

Epoch: 6| Step: 13
Training loss: 3.9474820960558694
Validation loss: 2.5188199518985277

Epoch: 131| Step: 0
Training loss: 2.981995117991984
Validation loss: 2.50928855700827

Epoch: 6| Step: 1
Training loss: 3.3250451680033906
Validation loss: 2.5212339764923906

Epoch: 6| Step: 2
Training loss: 3.3304365127438595
Validation loss: 2.5043599370394016

Epoch: 6| Step: 3
Training loss: 2.9139581001950563
Validation loss: 2.509945468101852

Epoch: 6| Step: 4
Training loss: 2.6725076740607907
Validation loss: 2.523097469068446

Epoch: 6| Step: 5
Training loss: 2.972774147372555
Validation loss: 2.529541054517316

Epoch: 6| Step: 6
Training loss: 2.583336296900208
Validation loss: 2.535361049326987

Epoch: 6| Step: 7
Training loss: 2.796784980220313
Validation loss: 2.5508966603077114

Epoch: 6| Step: 8
Training loss: 2.243409783967537
Validation loss: 2.528576836907177

Epoch: 6| Step: 9
Training loss: 2.636036966976349
Validation loss: 2.5149592065855413

Epoch: 6| Step: 10
Training loss: 2.8820912355677986
Validation loss: 2.505225214375689

Epoch: 6| Step: 11
Training loss: 2.478821599544708
Validation loss: 2.50604461744085

Epoch: 6| Step: 12
Training loss: 2.525307355246952
Validation loss: 2.494559734246306

Epoch: 6| Step: 13
Training loss: 3.156254532310329
Validation loss: 2.49337462231414

Epoch: 132| Step: 0
Training loss: 2.469816146679926
Validation loss: 2.487497978726994

Epoch: 6| Step: 1
Training loss: 2.7076434699569276
Validation loss: 2.495660492918167

Epoch: 6| Step: 2
Training loss: 2.4072669716435926
Validation loss: 2.51001490245638

Epoch: 6| Step: 3
Training loss: 2.9065628703713577
Validation loss: 2.5380748388431433

Epoch: 6| Step: 4
Training loss: 3.33952535260454
Validation loss: 2.523316048515126

Epoch: 6| Step: 5
Training loss: 3.122904876286341
Validation loss: 2.5049754561897655

Epoch: 6| Step: 6
Training loss: 2.7611259460903517
Validation loss: 2.490647461883645

Epoch: 6| Step: 7
Training loss: 3.569924364757995
Validation loss: 2.4905698179947917

Epoch: 6| Step: 8
Training loss: 2.465068824998848
Validation loss: 2.4895749721179885

Epoch: 6| Step: 9
Training loss: 2.5768929051626754
Validation loss: 2.506606822573681

Epoch: 6| Step: 10
Training loss: 3.041141691148989
Validation loss: 2.5326345787380307

Epoch: 6| Step: 11
Training loss: 2.9650159944099683
Validation loss: 2.5895718239497527

Epoch: 6| Step: 12
Training loss: 2.762407489453152
Validation loss: 2.6338494903127048

Epoch: 6| Step: 13
Training loss: 2.3618347280823606
Validation loss: 2.7238142395463267

Epoch: 133| Step: 0
Training loss: 3.042141254624107
Validation loss: 2.6407416212903074

Epoch: 6| Step: 1
Training loss: 2.830340113337181
Validation loss: 2.5745710322059465

Epoch: 6| Step: 2
Training loss: 2.959482605537743
Validation loss: 2.504099355195682

Epoch: 6| Step: 3
Training loss: 3.1925805684963273
Validation loss: 2.488496722868011

Epoch: 6| Step: 4
Training loss: 2.6427233783643005
Validation loss: 2.487980944802897

Epoch: 6| Step: 5
Training loss: 3.2295587773317016
Validation loss: 2.4872031356415114

Epoch: 6| Step: 6
Training loss: 3.117680484346981
Validation loss: 2.492391863830816

Epoch: 6| Step: 7
Training loss: 2.4948127336880166
Validation loss: 2.4959868347645338

Epoch: 6| Step: 8
Training loss: 2.677288349380993
Validation loss: 2.4861135531089023

Epoch: 6| Step: 9
Training loss: 2.25884352641861
Validation loss: 2.4963598843012407

Epoch: 6| Step: 10
Training loss: 3.1855140932268644
Validation loss: 2.4983816066501476

Epoch: 6| Step: 11
Training loss: 2.676034288902304
Validation loss: 2.4985637723156517

Epoch: 6| Step: 12
Training loss: 2.6795264548796496
Validation loss: 2.5050432414607355

Epoch: 6| Step: 13
Training loss: 2.8912633242632
Validation loss: 2.5206942972926525

Epoch: 134| Step: 0
Training loss: 3.24704064836074
Validation loss: 2.5575107316644727

Epoch: 6| Step: 1
Training loss: 2.979735277950066
Validation loss: 2.6008491487806773

Epoch: 6| Step: 2
Training loss: 2.966600141600901
Validation loss: 2.5998657087363797

Epoch: 6| Step: 3
Training loss: 2.547420326312227
Validation loss: 2.584075366324657

Epoch: 6| Step: 4
Training loss: 2.7013246571657885
Validation loss: 2.61952433195286

Epoch: 6| Step: 5
Training loss: 2.6441944984135857
Validation loss: 2.646101468967034

Epoch: 6| Step: 6
Training loss: 3.31641976541342
Validation loss: 2.673879201192321

Epoch: 6| Step: 7
Training loss: 2.5608792645743863
Validation loss: 2.6282529018000114

Epoch: 6| Step: 8
Training loss: 3.131025380131926
Validation loss: 2.5701674144790356

Epoch: 6| Step: 9
Training loss: 2.997896728732092
Validation loss: 2.5094372859149274

Epoch: 6| Step: 10
Training loss: 2.5818630977477244
Validation loss: 2.4895663911937462

Epoch: 6| Step: 11
Training loss: 2.9146502109259664
Validation loss: 2.482705754888097

Epoch: 6| Step: 12
Training loss: 2.4753482380952603
Validation loss: 2.4805769965443614

Epoch: 6| Step: 13
Training loss: 2.6122977511590153
Validation loss: 2.4891189599999692

Epoch: 135| Step: 0
Training loss: 2.695871930875405
Validation loss: 2.4879330611858617

Epoch: 6| Step: 1
Training loss: 3.1140690169431307
Validation loss: 2.4904021772919847

Epoch: 6| Step: 2
Training loss: 2.7154610570096986
Validation loss: 2.4869949189992777

Epoch: 6| Step: 3
Training loss: 2.606170239588831
Validation loss: 2.50573435516045

Epoch: 6| Step: 4
Training loss: 3.039546035701617
Validation loss: 2.4999949516737634

Epoch: 6| Step: 5
Training loss: 3.4212843851208965
Validation loss: 2.492307971932214

Epoch: 6| Step: 6
Training loss: 2.6098393010036056
Validation loss: 2.477152865736163

Epoch: 6| Step: 7
Training loss: 1.6957523460951216
Validation loss: 2.4816216098761714

Epoch: 6| Step: 8
Training loss: 3.390682940713177
Validation loss: 2.490533888657981

Epoch: 6| Step: 9
Training loss: 2.6588065914987715
Validation loss: 2.507901371811776

Epoch: 6| Step: 10
Training loss: 2.7124977568867634
Validation loss: 2.5458604060132397

Epoch: 6| Step: 11
Training loss: 3.146294179006796
Validation loss: 2.56121704315298

Epoch: 6| Step: 12
Training loss: 3.090522392583108
Validation loss: 2.583550820803517

Epoch: 6| Step: 13
Training loss: 2.339947680679085
Validation loss: 2.563993264498261

Epoch: 136| Step: 0
Training loss: 3.2098174357564684
Validation loss: 2.540196580817258

Epoch: 6| Step: 1
Training loss: 2.6676000114075977
Validation loss: 2.5298210778799537

Epoch: 6| Step: 2
Training loss: 2.778806148481726
Validation loss: 2.508619887249803

Epoch: 6| Step: 3
Training loss: 2.7977440192573084
Validation loss: 2.4957487794960347

Epoch: 6| Step: 4
Training loss: 2.7444354893293323
Validation loss: 2.485626237888195

Epoch: 6| Step: 5
Training loss: 2.5721870242356957
Validation loss: 2.48180438388313

Epoch: 6| Step: 6
Training loss: 1.9576656204256344
Validation loss: 2.47783703891872

Epoch: 6| Step: 7
Training loss: 2.8250467819796428
Validation loss: 2.479876175697537

Epoch: 6| Step: 8
Training loss: 3.0145157271060516
Validation loss: 2.481938759897606

Epoch: 6| Step: 9
Training loss: 2.7288336708427283
Validation loss: 2.4800240056344456

Epoch: 6| Step: 10
Training loss: 2.713363485410899
Validation loss: 2.4803690515567633

Epoch: 6| Step: 11
Training loss: 3.205932577679536
Validation loss: 2.485969549242042

Epoch: 6| Step: 12
Training loss: 3.0355624954357783
Validation loss: 2.48690988738047

Epoch: 6| Step: 13
Training loss: 3.214757424513071
Validation loss: 2.482567386317972

Epoch: 137| Step: 0
Training loss: 2.705616943460173
Validation loss: 2.4888798811427737

Epoch: 6| Step: 1
Training loss: 2.4089481039890424
Validation loss: 2.4938256579296847

Epoch: 6| Step: 2
Training loss: 2.789131227816548
Validation loss: 2.5157272592217583

Epoch: 6| Step: 3
Training loss: 2.585590350772066
Validation loss: 2.5482609209938496

Epoch: 6| Step: 4
Training loss: 3.1167086661325754
Validation loss: 2.5688783961298105

Epoch: 6| Step: 5
Training loss: 3.1515610111896892
Validation loss: 2.562078303692841

Epoch: 6| Step: 6
Training loss: 3.0690241238667344
Validation loss: 2.55405385478002

Epoch: 6| Step: 7
Training loss: 2.209496557622793
Validation loss: 2.5438960697164292

Epoch: 6| Step: 8
Training loss: 2.7181844013360736
Validation loss: 2.5220896221804514

Epoch: 6| Step: 9
Training loss: 2.716423178996626
Validation loss: 2.5177638034754177

Epoch: 6| Step: 10
Training loss: 3.17882554276888
Validation loss: 2.50391604931118

Epoch: 6| Step: 11
Training loss: 2.9492785719305377
Validation loss: 2.4896554406566396

Epoch: 6| Step: 12
Training loss: 3.1097686365058115
Validation loss: 2.486257106282694

Epoch: 6| Step: 13
Training loss: 2.5237364222863694
Validation loss: 2.479495103202811

Epoch: 138| Step: 0
Training loss: 2.486417686365623
Validation loss: 2.474992946653238

Epoch: 6| Step: 1
Training loss: 3.1489866170686627
Validation loss: 2.4729477322221207

Epoch: 6| Step: 2
Training loss: 2.681826169012369
Validation loss: 2.4759158841155204

Epoch: 6| Step: 3
Training loss: 2.795320558403089
Validation loss: 2.475105116397604

Epoch: 6| Step: 4
Training loss: 2.4172985522374795
Validation loss: 2.4722158730651853

Epoch: 6| Step: 5
Training loss: 2.8208110506050086
Validation loss: 2.471827042054543

Epoch: 6| Step: 6
Training loss: 2.302208242580547
Validation loss: 2.4707104557448543

Epoch: 6| Step: 7
Training loss: 3.008489359211248
Validation loss: 2.4748426247923057

Epoch: 6| Step: 8
Training loss: 2.8642186898005764
Validation loss: 2.4763778349051346

Epoch: 6| Step: 9
Training loss: 2.807725031896166
Validation loss: 2.470700707353969

Epoch: 6| Step: 10
Training loss: 2.630637065327773
Validation loss: 2.4837714311014194

Epoch: 6| Step: 11
Training loss: 3.6251854684672526
Validation loss: 2.4879055186723953

Epoch: 6| Step: 12
Training loss: 3.0609189058744835
Validation loss: 2.497130349791595

Epoch: 6| Step: 13
Training loss: 2.361268553128313
Validation loss: 2.4966200324883263

Epoch: 139| Step: 0
Training loss: 2.3812140434534115
Validation loss: 2.489417632623777

Epoch: 6| Step: 1
Training loss: 2.9415715995606493
Validation loss: 2.4888847058356762

Epoch: 6| Step: 2
Training loss: 2.5792476175039694
Validation loss: 2.508651248123752

Epoch: 6| Step: 3
Training loss: 3.5083593269406075
Validation loss: 2.5115238604584436

Epoch: 6| Step: 4
Training loss: 2.0706399910496707
Validation loss: 2.550139024110797

Epoch: 6| Step: 5
Training loss: 3.0223990931677682
Validation loss: 2.578087256967281

Epoch: 6| Step: 6
Training loss: 2.6056155230632783
Validation loss: 2.60414768105426

Epoch: 6| Step: 7
Training loss: 2.9858426784149463
Validation loss: 2.5898262171443456

Epoch: 6| Step: 8
Training loss: 3.2006826626261993
Validation loss: 2.543005211749589

Epoch: 6| Step: 9
Training loss: 3.021410516429216
Validation loss: 2.5199164934608724

Epoch: 6| Step: 10
Training loss: 2.4370367147867817
Validation loss: 2.494873472671615

Epoch: 6| Step: 11
Training loss: 2.5504912931603623
Validation loss: 2.5002048951959375

Epoch: 6| Step: 12
Training loss: 3.487034625105488
Validation loss: 2.513506688983358

Epoch: 6| Step: 13
Training loss: 1.975136163098056
Validation loss: 2.516568486388132

Epoch: 140| Step: 0
Training loss: 2.800012714493358
Validation loss: 2.5184973769567645

Epoch: 6| Step: 1
Training loss: 2.7556357289600952
Validation loss: 2.5290394859721315

Epoch: 6| Step: 2
Training loss: 2.5714592969663332
Validation loss: 2.5206606371946925

Epoch: 6| Step: 3
Training loss: 2.683050153333921
Validation loss: 2.5074522996497373

Epoch: 6| Step: 4
Training loss: 2.775228604359922
Validation loss: 2.4938455629199807

Epoch: 6| Step: 5
Training loss: 2.641962017632408
Validation loss: 2.4779154666507406

Epoch: 6| Step: 6
Training loss: 2.67061634422094
Validation loss: 2.477415038056676

Epoch: 6| Step: 7
Training loss: 2.4789021989396756
Validation loss: 2.479230523331893

Epoch: 6| Step: 8
Training loss: 2.8697146055164193
Validation loss: 2.4884810803150605

Epoch: 6| Step: 9
Training loss: 3.0367248487987863
Validation loss: 2.487932784000201

Epoch: 6| Step: 10
Training loss: 2.790603511167964
Validation loss: 2.498105270451217

Epoch: 6| Step: 11
Training loss: 3.119382157406385
Validation loss: 2.505378669428029

Epoch: 6| Step: 12
Training loss: 2.8616845647762803
Validation loss: 2.5245944117010874

Epoch: 6| Step: 13
Training loss: 3.4323467120945645
Validation loss: 2.539005572593512

Epoch: 141| Step: 0
Training loss: 3.1666570127908886
Validation loss: 2.5270778068941473

Epoch: 6| Step: 1
Training loss: 2.9026496489830134
Validation loss: 2.529963021470813

Epoch: 6| Step: 2
Training loss: 2.6423882911766876
Validation loss: 2.5300573863714337

Epoch: 6| Step: 3
Training loss: 2.702748090453122
Validation loss: 2.5231813685391837

Epoch: 6| Step: 4
Training loss: 2.6398164312524552
Validation loss: 2.49926449508291

Epoch: 6| Step: 5
Training loss: 3.3206979325921058
Validation loss: 2.508492578800153

Epoch: 6| Step: 6
Training loss: 3.308502520279647
Validation loss: 2.4933740557862953

Epoch: 6| Step: 7
Training loss: 2.9425573439670094
Validation loss: 2.488498435054019

Epoch: 6| Step: 8
Training loss: 2.9235596721490413
Validation loss: 2.4921520599798686

Epoch: 6| Step: 9
Training loss: 2.581290688551937
Validation loss: 2.488374890906972

Epoch: 6| Step: 10
Training loss: 2.5606320713980018
Validation loss: 2.4824383591827943

Epoch: 6| Step: 11
Training loss: 2.248158443012346
Validation loss: 2.480339389922815

Epoch: 6| Step: 12
Training loss: 2.3611912084220315
Validation loss: 2.4752466058415643

Epoch: 6| Step: 13
Training loss: 2.683344178345683
Validation loss: 2.4842923698116746

Epoch: 142| Step: 0
Training loss: 2.6713706092578837
Validation loss: 2.4843613261804083

Epoch: 6| Step: 1
Training loss: 2.975277120041096
Validation loss: 2.4855641703536633

Epoch: 6| Step: 2
Training loss: 2.707455204164263
Validation loss: 2.477769979604481

Epoch: 6| Step: 3
Training loss: 3.4040887257973442
Validation loss: 2.4851289093973645

Epoch: 6| Step: 4
Training loss: 2.584981136437658
Validation loss: 2.4785149526755563

Epoch: 6| Step: 5
Training loss: 2.9496680315379313
Validation loss: 2.4847265866580335

Epoch: 6| Step: 6
Training loss: 3.27374601162161
Validation loss: 2.496663779789598

Epoch: 6| Step: 7
Training loss: 2.660220779778996
Validation loss: 2.498572237178406

Epoch: 6| Step: 8
Training loss: 2.3892662824662874
Validation loss: 2.5220622880075094

Epoch: 6| Step: 9
Training loss: 2.9669620952595657
Validation loss: 2.5259500770891936

Epoch: 6| Step: 10
Training loss: 2.473095413428216
Validation loss: 2.53380727777783

Epoch: 6| Step: 11
Training loss: 2.794015968173359
Validation loss: 2.5644241330244353

Epoch: 6| Step: 12
Training loss: 2.5967595668068184
Validation loss: 2.5444507174854816

Epoch: 6| Step: 13
Training loss: 2.301393696174929
Validation loss: 2.5334063902630897

Epoch: 143| Step: 0
Training loss: 3.1952593736032777
Validation loss: 2.523184879953774

Epoch: 6| Step: 1
Training loss: 3.0553794135754857
Validation loss: 2.5017748244490323

Epoch: 6| Step: 2
Training loss: 3.1581336717394053
Validation loss: 2.486199033703314

Epoch: 6| Step: 3
Training loss: 2.318096297007462
Validation loss: 2.4767528981044267

Epoch: 6| Step: 4
Training loss: 3.269614670941447
Validation loss: 2.479812514850986

Epoch: 6| Step: 5
Training loss: 2.9348447446034958
Validation loss: 2.475387789966059

Epoch: 6| Step: 6
Training loss: 2.2278152956806587
Validation loss: 2.4808691756905508

Epoch: 6| Step: 7
Training loss: 3.05952932340681
Validation loss: 2.4763992756281943

Epoch: 6| Step: 8
Training loss: 2.8401807246664936
Validation loss: 2.47196611085838

Epoch: 6| Step: 9
Training loss: 2.5069063159676657
Validation loss: 2.4826224640180707

Epoch: 6| Step: 10
Training loss: 2.648325869928034
Validation loss: 2.4870054652820746

Epoch: 6| Step: 11
Training loss: 2.4051725278898424
Validation loss: 2.494339403146925

Epoch: 6| Step: 12
Training loss: 2.346257610359511
Validation loss: 2.5007204832651433

Epoch: 6| Step: 13
Training loss: 2.7622701696011136
Validation loss: 2.5181425482063973

Epoch: 144| Step: 0
Training loss: 2.17473616918193
Validation loss: 2.517987263597421

Epoch: 6| Step: 1
Training loss: 3.116451931932044
Validation loss: 2.510733844332573

Epoch: 6| Step: 2
Training loss: 3.3726932978677344
Validation loss: 2.511114813220231

Epoch: 6| Step: 3
Training loss: 2.6596900654689537
Validation loss: 2.490523112329259

Epoch: 6| Step: 4
Training loss: 2.559615116243933
Validation loss: 2.4993321726559303

Epoch: 6| Step: 5
Training loss: 2.5459720438510884
Validation loss: 2.4767032240542024

Epoch: 6| Step: 6
Training loss: 2.7968646001356054
Validation loss: 2.475428927798109

Epoch: 6| Step: 7
Training loss: 2.2257091292281856
Validation loss: 2.4806567689825756

Epoch: 6| Step: 8
Training loss: 3.135587077193767
Validation loss: 2.478316148680881

Epoch: 6| Step: 9
Training loss: 2.562271852338874
Validation loss: 2.4740406447978454

Epoch: 6| Step: 10
Training loss: 2.513851417229446
Validation loss: 2.4797129275248815

Epoch: 6| Step: 11
Training loss: 3.6711871862444325
Validation loss: 2.496021416124267

Epoch: 6| Step: 12
Training loss: 2.7579879921035557
Validation loss: 2.520225708628351

Epoch: 6| Step: 13
Training loss: 2.142343430022802
Validation loss: 2.5267022156715337

Epoch: 145| Step: 0
Training loss: 2.402924258177846
Validation loss: 2.553381173020818

Epoch: 6| Step: 1
Training loss: 2.7175556935882486
Validation loss: 2.524558828494464

Epoch: 6| Step: 2
Training loss: 3.1845174561026757
Validation loss: 2.4920445898619548

Epoch: 6| Step: 3
Training loss: 2.6300176167351346
Validation loss: 2.482422711501074

Epoch: 6| Step: 4
Training loss: 2.6008165911137975
Validation loss: 2.476521082866568

Epoch: 6| Step: 5
Training loss: 2.7218976270608906
Validation loss: 2.4769556508483497

Epoch: 6| Step: 6
Training loss: 3.058335723321658
Validation loss: 2.4809084308076415

Epoch: 6| Step: 7
Training loss: 2.297647670611798
Validation loss: 2.4745656242303484

Epoch: 6| Step: 8
Training loss: 2.25917429263372
Validation loss: 2.4787041024144107

Epoch: 6| Step: 9
Training loss: 2.957506915073904
Validation loss: 2.477707769071141

Epoch: 6| Step: 10
Training loss: 3.0921594403551764
Validation loss: 2.468872138943282

Epoch: 6| Step: 11
Training loss: 3.2407938340293443
Validation loss: 2.49035096112962

Epoch: 6| Step: 12
Training loss: 2.99100991126854
Validation loss: 2.4910150198157504

Epoch: 6| Step: 13
Training loss: 2.4683553645841965
Validation loss: 2.496023376839836

Epoch: 146| Step: 0
Training loss: 2.5932219553796934
Validation loss: 2.5123286896619854

Epoch: 6| Step: 1
Training loss: 2.8164482378111497
Validation loss: 2.517855354157423

Epoch: 6| Step: 2
Training loss: 2.879340999494438
Validation loss: 2.5217780472985885

Epoch: 6| Step: 3
Training loss: 2.3084444104219406
Validation loss: 2.5227236977457204

Epoch: 6| Step: 4
Training loss: 2.6043512100953095
Validation loss: 2.509591036061551

Epoch: 6| Step: 5
Training loss: 2.728134794971409
Validation loss: 2.5063085970461128

Epoch: 6| Step: 6
Training loss: 2.8230499761619017
Validation loss: 2.4967735215180578

Epoch: 6| Step: 7
Training loss: 3.013324868378804
Validation loss: 2.501576324562221

Epoch: 6| Step: 8
Training loss: 3.063043040183344
Validation loss: 2.4960806641810254

Epoch: 6| Step: 9
Training loss: 3.1339447182537077
Validation loss: 2.4937006932525088

Epoch: 6| Step: 10
Training loss: 2.6770248307739095
Validation loss: 2.492215336706426

Epoch: 6| Step: 11
Training loss: 2.78070611672078
Validation loss: 2.4895338198656494

Epoch: 6| Step: 12
Training loss: 2.7958471018361686
Validation loss: 2.4931780314806185

Epoch: 6| Step: 13
Training loss: 2.3625457880336245
Validation loss: 2.4869358874403975

Epoch: 147| Step: 0
Training loss: 2.9908826886392834
Validation loss: 2.488186274389327

Epoch: 6| Step: 1
Training loss: 2.720552570370029
Validation loss: 2.473030203447593

Epoch: 6| Step: 2
Training loss: 2.6313432618056876
Validation loss: 2.479839044192899

Epoch: 6| Step: 3
Training loss: 3.2091038426863863
Validation loss: 2.4746339016553502

Epoch: 6| Step: 4
Training loss: 2.503368206805626
Validation loss: 2.469866634960111

Epoch: 6| Step: 5
Training loss: 2.4068244149383355
Validation loss: 2.473105138903836

Epoch: 6| Step: 6
Training loss: 2.6329027833938303
Validation loss: 2.4745399293186705

Epoch: 6| Step: 7
Training loss: 3.0040014919069042
Validation loss: 2.4782777369530233

Epoch: 6| Step: 8
Training loss: 2.375291003418661
Validation loss: 2.4822986418869046

Epoch: 6| Step: 9
Training loss: 2.7151388982154825
Validation loss: 2.484227697290901

Epoch: 6| Step: 10
Training loss: 3.16041893922292
Validation loss: 2.4915605089954633

Epoch: 6| Step: 11
Training loss: 2.894215925701633
Validation loss: 2.4992212031030046

Epoch: 6| Step: 12
Training loss: 2.747056773206948
Validation loss: 2.4890971859648188

Epoch: 6| Step: 13
Training loss: 2.802418335431724
Validation loss: 2.490154839374951

Epoch: 148| Step: 0
Training loss: 2.886074133562571
Validation loss: 2.4882310148218454

Epoch: 6| Step: 1
Training loss: 2.8852146963959746
Validation loss: 2.4948611305772466

Epoch: 6| Step: 2
Training loss: 2.017983764167251
Validation loss: 2.49644088481703

Epoch: 6| Step: 3
Training loss: 3.08414888335774
Validation loss: 2.5024568411658468

Epoch: 6| Step: 4
Training loss: 2.80287456095405
Validation loss: 2.523337216386124

Epoch: 6| Step: 5
Training loss: 3.3988429737457224
Validation loss: 2.524380954699793

Epoch: 6| Step: 6
Training loss: 2.616771243571058
Validation loss: 2.5262654097054615

Epoch: 6| Step: 7
Training loss: 2.322243448958457
Validation loss: 2.5084011575511416

Epoch: 6| Step: 8
Training loss: 2.8998066015539754
Validation loss: 2.5076339219036714

Epoch: 6| Step: 9
Training loss: 2.9364362373255966
Validation loss: 2.506490291434226

Epoch: 6| Step: 10
Training loss: 2.4109149647498227
Validation loss: 2.4883953484365144

Epoch: 6| Step: 11
Training loss: 3.0334656473443316
Validation loss: 2.4836804262667314

Epoch: 6| Step: 12
Training loss: 2.5610552180607224
Validation loss: 2.486208270715251

Epoch: 6| Step: 13
Training loss: 2.527165449359234
Validation loss: 2.476001880363079

Epoch: 149| Step: 0
Training loss: 2.6488754225483895
Validation loss: 2.476059644391389

Epoch: 6| Step: 1
Training loss: 2.7226236743702223
Validation loss: 2.477745549176473

Epoch: 6| Step: 2
Training loss: 2.6048726053260314
Validation loss: 2.478741456736401

Epoch: 6| Step: 3
Training loss: 2.579670390875843
Validation loss: 2.482084183341503

Epoch: 6| Step: 4
Training loss: 2.7835097829963042
Validation loss: 2.4835133579451947

Epoch: 6| Step: 5
Training loss: 2.318841332952923
Validation loss: 2.482586433087285

Epoch: 6| Step: 6
Training loss: 2.9556818797268267
Validation loss: 2.480724471590849

Epoch: 6| Step: 7
Training loss: 3.2564622747601475
Validation loss: 2.483788197393763

Epoch: 6| Step: 8
Training loss: 2.413576737699095
Validation loss: 2.5155996011674597

Epoch: 6| Step: 9
Training loss: 2.748224552269568
Validation loss: 2.5613474341048987

Epoch: 6| Step: 10
Training loss: 2.8339867305943
Validation loss: 2.643422502573401

Epoch: 6| Step: 11
Training loss: 2.831345215937386
Validation loss: 2.728310254718429

Epoch: 6| Step: 12
Training loss: 2.864629534724485
Validation loss: 2.68788927315831

Epoch: 6| Step: 13
Training loss: 3.8940016712641645
Validation loss: 2.652131841375247

Epoch: 150| Step: 0
Training loss: 2.9119849277567393
Validation loss: 2.596228251655863

Epoch: 6| Step: 1
Training loss: 3.1549556079770227
Validation loss: 2.5345835771194216

Epoch: 6| Step: 2
Training loss: 2.3893836295221242
Validation loss: 2.5103886313020336

Epoch: 6| Step: 3
Training loss: 2.4329403019866733
Validation loss: 2.4993430146012465

Epoch: 6| Step: 4
Training loss: 3.0785577924841756
Validation loss: 2.493968849942595

Epoch: 6| Step: 5
Training loss: 3.479877117662105
Validation loss: 2.5126341258531157

Epoch: 6| Step: 6
Training loss: 2.807258723719749
Validation loss: 2.499003725580395

Epoch: 6| Step: 7
Training loss: 3.1452593416591177
Validation loss: 2.494654345431907

Epoch: 6| Step: 8
Training loss: 2.434192271591479
Validation loss: 2.495022342641113

Epoch: 6| Step: 9
Training loss: 2.479510168646646
Validation loss: 2.5095875332079993

Epoch: 6| Step: 10
Training loss: 2.6432889784386338
Validation loss: 2.50353509192344

Epoch: 6| Step: 11
Training loss: 2.5353339886774418
Validation loss: 2.523097166279923

Epoch: 6| Step: 12
Training loss: 2.704999681567951
Validation loss: 2.5221778547187705

Epoch: 6| Step: 13
Training loss: 2.5895289809481117
Validation loss: 2.5340317805098524

Epoch: 151| Step: 0
Training loss: 2.5378837783812718
Validation loss: 2.54885176347222

Epoch: 6| Step: 1
Training loss: 2.704788666259524
Validation loss: 2.5442579150287834

Epoch: 6| Step: 2
Training loss: 3.000245402153719
Validation loss: 2.5538281949894888

Epoch: 6| Step: 3
Training loss: 2.7614694183330495
Validation loss: 2.5790903600358823

Epoch: 6| Step: 4
Training loss: 2.6851001936760843
Validation loss: 2.5908791520092356

Epoch: 6| Step: 5
Training loss: 2.9084411892570885
Validation loss: 2.5871232707146103

Epoch: 6| Step: 6
Training loss: 2.725057891790712
Validation loss: 2.5460288980594257

Epoch: 6| Step: 7
Training loss: 3.1093194851160697
Validation loss: 2.5200460518690058

Epoch: 6| Step: 8
Training loss: 2.8793761078269555
Validation loss: 2.501923443108731

Epoch: 6| Step: 9
Training loss: 2.085006906328724
Validation loss: 2.479372504246156

Epoch: 6| Step: 10
Training loss: 3.153928148195049
Validation loss: 2.4802145483639535

Epoch: 6| Step: 11
Training loss: 2.9750730938306797
Validation loss: 2.4711091854085203

Epoch: 6| Step: 12
Training loss: 2.817057667817362
Validation loss: 2.468497258566019

Epoch: 6| Step: 13
Training loss: 2.1104946979382904
Validation loss: 2.4749702295207676

Epoch: 152| Step: 0
Training loss: 2.2854047591236224
Validation loss: 2.469697566108661

Epoch: 6| Step: 1
Training loss: 3.3467675969177066
Validation loss: 2.47637789080799

Epoch: 6| Step: 2
Training loss: 3.006848465638483
Validation loss: 2.477080392740478

Epoch: 6| Step: 3
Training loss: 2.30050683449466
Validation loss: 2.4861766628339423

Epoch: 6| Step: 4
Training loss: 2.4726921187416186
Validation loss: 2.4930222274141944

Epoch: 6| Step: 5
Training loss: 2.958469781728699
Validation loss: 2.4945243664678243

Epoch: 6| Step: 6
Training loss: 2.9431233251295104
Validation loss: 2.5021942804519264

Epoch: 6| Step: 7
Training loss: 2.5227696151991506
Validation loss: 2.527024135872329

Epoch: 6| Step: 8
Training loss: 2.794632422855595
Validation loss: 2.5275561615950033

Epoch: 6| Step: 9
Training loss: 2.8472252036805297
Validation loss: 2.5222833345155653

Epoch: 6| Step: 10
Training loss: 3.2847319520605036
Validation loss: 2.531455980207553

Epoch: 6| Step: 11
Training loss: 2.5230053983457483
Validation loss: 2.5323303218356075

Epoch: 6| Step: 12
Training loss: 2.75956441330696
Validation loss: 2.5475355980519443

Epoch: 6| Step: 13
Training loss: 2.2117738254040424
Validation loss: 2.560462471754101

Epoch: 153| Step: 0
Training loss: 2.7876574826765674
Validation loss: 2.5729898949918044

Epoch: 6| Step: 1
Training loss: 2.5882525727133876
Validation loss: 2.583775517875519

Epoch: 6| Step: 2
Training loss: 3.0022441100025365
Validation loss: 2.5840880794569983

Epoch: 6| Step: 3
Training loss: 3.1744105535304854
Validation loss: 2.579329012692593

Epoch: 6| Step: 4
Training loss: 3.0893578997367745
Validation loss: 2.5755853648083966

Epoch: 6| Step: 5
Training loss: 2.4856918971301525
Validation loss: 2.568636780387862

Epoch: 6| Step: 6
Training loss: 2.938764421759444
Validation loss: 2.5519554569903677

Epoch: 6| Step: 7
Training loss: 2.770645756694301
Validation loss: 2.539872732828042

Epoch: 6| Step: 8
Training loss: 2.826622579683622
Validation loss: 2.5143326961122185

Epoch: 6| Step: 9
Training loss: 2.8017923612914317
Validation loss: 2.518955617174245

Epoch: 6| Step: 10
Training loss: 3.24629866300999
Validation loss: 2.499768940697317

Epoch: 6| Step: 11
Training loss: 2.599854604617136
Validation loss: 2.487214203620439

Epoch: 6| Step: 12
Training loss: 1.74070423432135
Validation loss: 2.480017339190636

Epoch: 6| Step: 13
Training loss: 2.416779307228658
Validation loss: 2.48804564650152

Epoch: 154| Step: 0
Training loss: 2.9345979356021052
Validation loss: 2.4771438298839468

Epoch: 6| Step: 1
Training loss: 2.8382495041491214
Validation loss: 2.4819320118314128

Epoch: 6| Step: 2
Training loss: 2.6906967667457757
Validation loss: 2.481317629555931

Epoch: 6| Step: 3
Training loss: 2.9570073841094366
Validation loss: 2.4942792102857534

Epoch: 6| Step: 4
Training loss: 2.534276495170444
Validation loss: 2.499681210445288

Epoch: 6| Step: 5
Training loss: 2.838336696865428
Validation loss: 2.542859179135098

Epoch: 6| Step: 6
Training loss: 2.502584170851411
Validation loss: 2.5638495262399115

Epoch: 6| Step: 7
Training loss: 2.9176906059913272
Validation loss: 2.5711242798207463

Epoch: 6| Step: 8
Training loss: 2.822831484552247
Validation loss: 2.559719784460977

Epoch: 6| Step: 9
Training loss: 2.9393363245066824
Validation loss: 2.529665816975974

Epoch: 6| Step: 10
Training loss: 2.6462240055845485
Validation loss: 2.510393646982971

Epoch: 6| Step: 11
Training loss: 2.899005186520398
Validation loss: 2.4832281859571568

Epoch: 6| Step: 12
Training loss: 2.308467958382869
Validation loss: 2.4804579929890154

Epoch: 6| Step: 13
Training loss: 2.8600156306126427
Validation loss: 2.478028793669957

Epoch: 155| Step: 0
Training loss: 2.538558111710177
Validation loss: 2.4876776951838684

Epoch: 6| Step: 1
Training loss: 3.21910463620142
Validation loss: 2.4755082282005163

Epoch: 6| Step: 2
Training loss: 2.503498300060002
Validation loss: 2.484081868870809

Epoch: 6| Step: 3
Training loss: 2.2747885762997875
Validation loss: 2.480828242775603

Epoch: 6| Step: 4
Training loss: 2.806191553811345
Validation loss: 2.487808625419152

Epoch: 6| Step: 5
Training loss: 2.882495728329937
Validation loss: 2.4913360800572444

Epoch: 6| Step: 6
Training loss: 2.9278995195042943
Validation loss: 2.5050837889378763

Epoch: 6| Step: 7
Training loss: 3.1715377853863416
Validation loss: 2.507629244719038

Epoch: 6| Step: 8
Training loss: 3.2712138414261287
Validation loss: 2.509234758862303

Epoch: 6| Step: 9
Training loss: 2.6345351382055426
Validation loss: 2.5142881672774244

Epoch: 6| Step: 10
Training loss: 2.1946205867890916
Validation loss: 2.515568356470838

Epoch: 6| Step: 11
Training loss: 2.6927893286402336
Validation loss: 2.5079640712710995

Epoch: 6| Step: 12
Training loss: 2.5801660954438814
Validation loss: 2.4855772795652222

Epoch: 6| Step: 13
Training loss: 2.5645676621413545
Validation loss: 2.4877049176655537

Epoch: 156| Step: 0
Training loss: 2.168755575826991
Validation loss: 2.486174202490044

Epoch: 6| Step: 1
Training loss: 3.2481326093615768
Validation loss: 2.474626649871266

Epoch: 6| Step: 2
Training loss: 2.7665770880050515
Validation loss: 2.4852547873300455

Epoch: 6| Step: 3
Training loss: 2.6967612975232145
Validation loss: 2.489826098050725

Epoch: 6| Step: 4
Training loss: 1.9652378907965533
Validation loss: 2.4914596378871745

Epoch: 6| Step: 5
Training loss: 2.924789851537915
Validation loss: 2.5112648172280894

Epoch: 6| Step: 6
Training loss: 2.2690420756164853
Validation loss: 2.5317978392069262

Epoch: 6| Step: 7
Training loss: 2.587146027167282
Validation loss: 2.5429882985550067

Epoch: 6| Step: 8
Training loss: 3.000531467409409
Validation loss: 2.560155015161365

Epoch: 6| Step: 9
Training loss: 2.659998503949885
Validation loss: 2.5853559172567926

Epoch: 6| Step: 10
Training loss: 3.0858546764993093
Validation loss: 2.6029127492707276

Epoch: 6| Step: 11
Training loss: 2.983610045175536
Validation loss: 2.6001814083599375

Epoch: 6| Step: 12
Training loss: 3.21333731934655
Validation loss: 2.573483808176653

Epoch: 6| Step: 13
Training loss: 2.5090831734169887
Validation loss: 2.5225146741066347

Epoch: 157| Step: 0
Training loss: 2.5334312553888747
Validation loss: 2.4962542590734826

Epoch: 6| Step: 1
Training loss: 3.1131446262760307
Validation loss: 2.4788282309383387

Epoch: 6| Step: 2
Training loss: 2.472027401861763
Validation loss: 2.472716430103832

Epoch: 6| Step: 3
Training loss: 2.767535740346758
Validation loss: 2.4729278984954766

Epoch: 6| Step: 4
Training loss: 2.1948852123233866
Validation loss: 2.4826123524442862

Epoch: 6| Step: 5
Training loss: 3.4684709316408715
Validation loss: 2.4796003174565655

Epoch: 6| Step: 6
Training loss: 2.746046432152567
Validation loss: 2.4781036121127347

Epoch: 6| Step: 7
Training loss: 2.8344522585533287
Validation loss: 2.4803519200374637

Epoch: 6| Step: 8
Training loss: 2.268912830236847
Validation loss: 2.4751888000530156

Epoch: 6| Step: 9
Training loss: 2.6293281114666964
Validation loss: 2.482486156704305

Epoch: 6| Step: 10
Training loss: 3.111303756819592
Validation loss: 2.482484925736556

Epoch: 6| Step: 11
Training loss: 2.7253249893278477
Validation loss: 2.4905032116657484

Epoch: 6| Step: 12
Training loss: 2.6947349924783883
Validation loss: 2.5116986181876544

Epoch: 6| Step: 13
Training loss: 2.350059662731139
Validation loss: 2.5191116424940323

Epoch: 158| Step: 0
Training loss: 3.013908253347259
Validation loss: 2.525286247543468

Epoch: 6| Step: 1
Training loss: 1.7276099984552924
Validation loss: 2.51372586017433

Epoch: 6| Step: 2
Training loss: 2.622979794551325
Validation loss: 2.5237194551288256

Epoch: 6| Step: 3
Training loss: 2.733425127984641
Validation loss: 2.525203235260465

Epoch: 6| Step: 4
Training loss: 3.2301682098334075
Validation loss: 2.514801798706847

Epoch: 6| Step: 5
Training loss: 2.669286355074281
Validation loss: 2.5094384158040546

Epoch: 6| Step: 6
Training loss: 2.5628632078723252
Validation loss: 2.508478260755878

Epoch: 6| Step: 7
Training loss: 2.501472325698234
Validation loss: 2.5110177078115687

Epoch: 6| Step: 8
Training loss: 3.281744928726436
Validation loss: 2.506194107602217

Epoch: 6| Step: 9
Training loss: 2.4574332340519445
Validation loss: 2.491741244233397

Epoch: 6| Step: 10
Training loss: 3.216756406991581
Validation loss: 2.480847913103921

Epoch: 6| Step: 11
Training loss: 2.7237396930501316
Validation loss: 2.4863798730601174

Epoch: 6| Step: 12
Training loss: 2.4063288688119773
Validation loss: 2.488440448777644

Epoch: 6| Step: 13
Training loss: 2.4875105737816057
Validation loss: 2.485012057122799

Epoch: 159| Step: 0
Training loss: 1.840701411528053
Validation loss: 2.4797173058577062

Epoch: 6| Step: 1
Training loss: 2.993102090763431
Validation loss: 2.4805761067130896

Epoch: 6| Step: 2
Training loss: 2.891367883847729
Validation loss: 2.486591757904358

Epoch: 6| Step: 3
Training loss: 2.8863652365153745
Validation loss: 2.50439417450556

Epoch: 6| Step: 4
Training loss: 2.2887398033394133
Validation loss: 2.527799882498781

Epoch: 6| Step: 5
Training loss: 2.211514562777499
Validation loss: 2.546704266757596

Epoch: 6| Step: 6
Training loss: 3.0994184563819758
Validation loss: 2.5829619535341415

Epoch: 6| Step: 7
Training loss: 3.064915696893626
Validation loss: 2.5985229615469434

Epoch: 6| Step: 8
Training loss: 3.4217105634363114
Validation loss: 2.631189475502009

Epoch: 6| Step: 9
Training loss: 2.6364636559183348
Validation loss: 2.5373010515053194

Epoch: 6| Step: 10
Training loss: 2.39201175136295
Validation loss: 2.499647507377009

Epoch: 6| Step: 11
Training loss: 2.7532949648470555
Validation loss: 2.4689324362052725

Epoch: 6| Step: 12
Training loss: 3.3190134177400776
Validation loss: 2.4776589429620035

Epoch: 6| Step: 13
Training loss: 2.2228345212860527
Validation loss: 2.479841316469218

Epoch: 160| Step: 0
Training loss: 2.754768745146024
Validation loss: 2.481104083316936

Epoch: 6| Step: 1
Training loss: 3.4664126932816357
Validation loss: 2.495316987151099

Epoch: 6| Step: 2
Training loss: 3.055500049279571
Validation loss: 2.496352263282206

Epoch: 6| Step: 3
Training loss: 2.800870034740557
Validation loss: 2.4893406846570603

Epoch: 6| Step: 4
Training loss: 2.4657554330882947
Validation loss: 2.487204518883888

Epoch: 6| Step: 5
Training loss: 2.548625601837882
Validation loss: 2.484064445090544

Epoch: 6| Step: 6
Training loss: 2.8651391802096904
Validation loss: 2.491504947714939

Epoch: 6| Step: 7
Training loss: 2.839670461958488
Validation loss: 2.502373338943634

Epoch: 6| Step: 8
Training loss: 2.0962665294707508
Validation loss: 2.531030822404231

Epoch: 6| Step: 9
Training loss: 2.3337424691583935
Validation loss: 2.5577206855866046

Epoch: 6| Step: 10
Training loss: 2.5960938308169377
Validation loss: 2.573439514859492

Epoch: 6| Step: 11
Training loss: 3.2032939587203235
Validation loss: 2.5971092100241804

Epoch: 6| Step: 12
Training loss: 3.2333305994658037
Validation loss: 2.586370715571784

Epoch: 6| Step: 13
Training loss: 1.6434867967261506
Validation loss: 2.5987315538376325

Epoch: 161| Step: 0
Training loss: 2.6144298087915185
Validation loss: 2.5768137879238884

Epoch: 6| Step: 1
Training loss: 2.484576331084016
Validation loss: 2.584111532787361

Epoch: 6| Step: 2
Training loss: 3.1007206540615564
Validation loss: 2.5765902965824337

Epoch: 6| Step: 3
Training loss: 2.9098858803726295
Validation loss: 2.5762365052684357

Epoch: 6| Step: 4
Training loss: 2.286105697190755
Validation loss: 2.5700424505792703

Epoch: 6| Step: 5
Training loss: 2.7866918923484993
Validation loss: 2.5835838560268565

Epoch: 6| Step: 6
Training loss: 2.833208941552695
Validation loss: 2.5810210845347705

Epoch: 6| Step: 7
Training loss: 3.115129216730226
Validation loss: 2.5890789331510518

Epoch: 6| Step: 8
Training loss: 2.5065857926301724
Validation loss: 2.5893330371540495

Epoch: 6| Step: 9
Training loss: 2.2884999908787313
Validation loss: 2.601379394985501

Epoch: 6| Step: 10
Training loss: 3.2283908199088565
Validation loss: 2.607088245928177

Epoch: 6| Step: 11
Training loss: 2.5390243762161915
Validation loss: 2.5869955791734633

Epoch: 6| Step: 12
Training loss: 2.6449253797191004
Validation loss: 2.585976122793342

Epoch: 6| Step: 13
Training loss: 3.4417811697200125
Validation loss: 2.5673479461577213

Epoch: 162| Step: 0
Training loss: 2.803277981771468
Validation loss: 2.532837626466119

Epoch: 6| Step: 1
Training loss: 2.1182282201988243
Validation loss: 2.5379875029015553

Epoch: 6| Step: 2
Training loss: 2.764753818693179
Validation loss: 2.5121205318780397

Epoch: 6| Step: 3
Training loss: 2.3726854590714734
Validation loss: 2.4990426681409468

Epoch: 6| Step: 4
Training loss: 2.9653573979675136
Validation loss: 2.486238401613759

Epoch: 6| Step: 5
Training loss: 2.1848994464564013
Validation loss: 2.4671389173814773

Epoch: 6| Step: 6
Training loss: 3.3290269372777828
Validation loss: 2.4642951089120326

Epoch: 6| Step: 7
Training loss: 3.0067509350805746
Validation loss: 2.4703252503798954

Epoch: 6| Step: 8
Training loss: 2.8719901210221845
Validation loss: 2.4740782384306788

Epoch: 6| Step: 9
Training loss: 3.0024678887802843
Validation loss: 2.4932579991748343

Epoch: 6| Step: 10
Training loss: 2.862794925871858
Validation loss: 2.512734939675102

Epoch: 6| Step: 11
Training loss: 2.404543382912868
Validation loss: 2.5763246646016196

Epoch: 6| Step: 12
Training loss: 2.9137568172864396
Validation loss: 2.635839438502848

Epoch: 6| Step: 13
Training loss: 2.752175770857277
Validation loss: 2.6450693934644884

Epoch: 163| Step: 0
Training loss: 3.4520982967981713
Validation loss: 2.61765317415153

Epoch: 6| Step: 1
Training loss: 2.410701251120877
Validation loss: 2.5326528744509966

Epoch: 6| Step: 2
Training loss: 2.5669906159940123
Validation loss: 2.501121623170794

Epoch: 6| Step: 3
Training loss: 2.9650661701711907
Validation loss: 2.4932706977729064

Epoch: 6| Step: 4
Training loss: 2.572098039339599
Validation loss: 2.491849596779094

Epoch: 6| Step: 5
Training loss: 2.341477474927846
Validation loss: 2.478177220016853

Epoch: 6| Step: 6
Training loss: 2.9701826955173947
Validation loss: 2.4645575807139055

Epoch: 6| Step: 7
Training loss: 3.039617414242026
Validation loss: 2.469597053929935

Epoch: 6| Step: 8
Training loss: 3.062521175389165
Validation loss: 2.4705783189740034

Epoch: 6| Step: 9
Training loss: 2.975869405957438
Validation loss: 2.463446728314115

Epoch: 6| Step: 10
Training loss: 2.531211381782473
Validation loss: 2.4658875678674037

Epoch: 6| Step: 11
Training loss: 2.5151443496141037
Validation loss: 2.46013245326626

Epoch: 6| Step: 12
Training loss: 2.615494912397993
Validation loss: 2.457120198389203

Epoch: 6| Step: 13
Training loss: 2.6207402498325325
Validation loss: 2.4869090090928334

Epoch: 164| Step: 0
Training loss: 2.6182451075553077
Validation loss: 2.518731635319439

Epoch: 6| Step: 1
Training loss: 2.415234919903808
Validation loss: 2.5442169721481553

Epoch: 6| Step: 2
Training loss: 2.373889663548959
Validation loss: 2.562636824225702

Epoch: 6| Step: 3
Training loss: 2.5086909861862945
Validation loss: 2.570164016128652

Epoch: 6| Step: 4
Training loss: 3.1346685756978796
Validation loss: 2.603042810085009

Epoch: 6| Step: 5
Training loss: 2.245938237653096
Validation loss: 2.6055810069683214

Epoch: 6| Step: 6
Training loss: 3.102695363892202
Validation loss: 2.5668254305246823

Epoch: 6| Step: 7
Training loss: 3.151734700980749
Validation loss: 2.553195600660243

Epoch: 6| Step: 8
Training loss: 2.7455235373551514
Validation loss: 2.527362961937073

Epoch: 6| Step: 9
Training loss: 2.776125784357573
Validation loss: 2.5053119400503236

Epoch: 6| Step: 10
Training loss: 2.975131915076939
Validation loss: 2.4706590155579815

Epoch: 6| Step: 11
Training loss: 2.934891049444073
Validation loss: 2.4674078264236425

Epoch: 6| Step: 12
Training loss: 2.4473003071415165
Validation loss: 2.453796662626485

Epoch: 6| Step: 13
Training loss: 2.2716159930026745
Validation loss: 2.4606714415076985

Epoch: 165| Step: 0
Training loss: 3.211205241603023
Validation loss: 2.4531947268991843

Epoch: 6| Step: 1
Training loss: 3.0704260263978913
Validation loss: 2.464628058672727

Epoch: 6| Step: 2
Training loss: 2.8530065773060125
Validation loss: 2.4652219261564743

Epoch: 6| Step: 3
Training loss: 2.7363478164999
Validation loss: 2.453800544969798

Epoch: 6| Step: 4
Training loss: 3.0044993991860727
Validation loss: 2.4757702474648275

Epoch: 6| Step: 5
Training loss: 2.367848319801836
Validation loss: 2.46957997952224

Epoch: 6| Step: 6
Training loss: 2.145536371317949
Validation loss: 2.4872902541875153

Epoch: 6| Step: 7
Training loss: 2.1176610888533727
Validation loss: 2.4817128048724175

Epoch: 6| Step: 8
Training loss: 2.877466056351759
Validation loss: 2.499466428935011

Epoch: 6| Step: 9
Training loss: 2.680026552865878
Validation loss: 2.5226368298200983

Epoch: 6| Step: 10
Training loss: 2.678916976075102
Validation loss: 2.5459893571155128

Epoch: 6| Step: 11
Training loss: 2.4292922112382875
Validation loss: 2.55862774670185

Epoch: 6| Step: 12
Training loss: 2.4402059549429556
Validation loss: 2.5916646616779957

Epoch: 6| Step: 13
Training loss: 3.414149791727657
Validation loss: 2.6150808814900524

Epoch: 166| Step: 0
Training loss: 3.7265869395736204
Validation loss: 2.6210398210217303

Epoch: 6| Step: 1
Training loss: 2.5054429883497837
Validation loss: 2.5632047396926545

Epoch: 6| Step: 2
Training loss: 2.8217681763158966
Validation loss: 2.5418220582124302

Epoch: 6| Step: 3
Training loss: 2.043740354742686
Validation loss: 2.531704825199247

Epoch: 6| Step: 4
Training loss: 2.980371956109696
Validation loss: 2.5245001299841587

Epoch: 6| Step: 5
Training loss: 2.8849284359206036
Validation loss: 2.5308013147666126

Epoch: 6| Step: 6
Training loss: 2.587214866075995
Validation loss: 2.522291416889735

Epoch: 6| Step: 7
Training loss: 2.118376000627698
Validation loss: 2.5173107825540426

Epoch: 6| Step: 8
Training loss: 2.7477803375537984
Validation loss: 2.5144189664464194

Epoch: 6| Step: 9
Training loss: 2.7435446312584886
Validation loss: 2.508734586351269

Epoch: 6| Step: 10
Training loss: 2.65033988932187
Validation loss: 2.4845050528264156

Epoch: 6| Step: 11
Training loss: 2.903759945849539
Validation loss: 2.4830870181288853

Epoch: 6| Step: 12
Training loss: 2.9857829502577387
Validation loss: 2.488965547921581

Epoch: 6| Step: 13
Training loss: 2.572625137266079
Validation loss: 2.511005275079204

Epoch: 167| Step: 0
Training loss: 2.220621099106261
Validation loss: 2.526089752791675

Epoch: 6| Step: 1
Training loss: 3.014834285502765
Validation loss: 2.536108513658666

Epoch: 6| Step: 2
Training loss: 2.3848825936839613
Validation loss: 2.5336195826790973

Epoch: 6| Step: 3
Training loss: 2.952996952570742
Validation loss: 2.5339543095862256

Epoch: 6| Step: 4
Training loss: 2.4915723848738898
Validation loss: 2.5459077922242095

Epoch: 6| Step: 5
Training loss: 2.573857329818468
Validation loss: 2.533927206597032

Epoch: 6| Step: 6
Training loss: 2.1689482804389306
Validation loss: 2.5244990718284983

Epoch: 6| Step: 7
Training loss: 3.2347753894309816
Validation loss: 2.53009830608605

Epoch: 6| Step: 8
Training loss: 2.53337723627028
Validation loss: 2.515679748832113

Epoch: 6| Step: 9
Training loss: 2.702973730893196
Validation loss: 2.499392155615933

Epoch: 6| Step: 10
Training loss: 2.572367487275779
Validation loss: 2.494331782121363

Epoch: 6| Step: 11
Training loss: 2.6637965094714104
Validation loss: 2.4838119325892345

Epoch: 6| Step: 12
Training loss: 3.1984728268460034
Validation loss: 2.4886252283228862

Epoch: 6| Step: 13
Training loss: 2.9007483470477737
Validation loss: 2.497372816813527

Epoch: 168| Step: 0
Training loss: 2.241624927723047
Validation loss: 2.4911503181239545

Epoch: 6| Step: 1
Training loss: 2.5903739559077783
Validation loss: 2.489058068232902

Epoch: 6| Step: 2
Training loss: 2.0849315489366123
Validation loss: 2.4897775636471766

Epoch: 6| Step: 3
Training loss: 2.586100869910257
Validation loss: 2.4900186859733084

Epoch: 6| Step: 4
Training loss: 2.957122519128967
Validation loss: 2.486057695303929

Epoch: 6| Step: 5
Training loss: 2.5323350252754504
Validation loss: 2.483498960921935

Epoch: 6| Step: 6
Training loss: 2.355013422188707
Validation loss: 2.483589448032131

Epoch: 6| Step: 7
Training loss: 3.1484432551707635
Validation loss: 2.4953450242142314

Epoch: 6| Step: 8
Training loss: 3.0032709092212784
Validation loss: 2.5023863119467875

Epoch: 6| Step: 9
Training loss: 2.523919877281376
Validation loss: 2.5208335452044515

Epoch: 6| Step: 10
Training loss: 2.8678930594219794
Validation loss: 2.535468133337007

Epoch: 6| Step: 11
Training loss: 2.692945242420335
Validation loss: 2.5640128617277567

Epoch: 6| Step: 12
Training loss: 2.9490937667536072
Validation loss: 2.5839435804004776

Epoch: 6| Step: 13
Training loss: 2.877024228213764
Validation loss: 2.5630979423093874

Epoch: 169| Step: 0
Training loss: 2.4239309136960436
Validation loss: 2.53138180593006

Epoch: 6| Step: 1
Training loss: 2.071629058832073
Validation loss: 2.4967513008426967

Epoch: 6| Step: 2
Training loss: 2.9383227231040947
Validation loss: 2.475875140596716

Epoch: 6| Step: 3
Training loss: 2.739271651452342
Validation loss: 2.452656870738349

Epoch: 6| Step: 4
Training loss: 2.6251890931823136
Validation loss: 2.4648033060635566

Epoch: 6| Step: 5
Training loss: 1.9282287767573476
Validation loss: 2.458967346796037

Epoch: 6| Step: 6
Training loss: 1.978368604946038
Validation loss: 2.4656402152388566

Epoch: 6| Step: 7
Training loss: 2.7927987000243
Validation loss: 2.4663427830650444

Epoch: 6| Step: 8
Training loss: 2.977378753320218
Validation loss: 2.4842561422623484

Epoch: 6| Step: 9
Training loss: 2.8307952919927746
Validation loss: 2.508680076318524

Epoch: 6| Step: 10
Training loss: 2.7579739877250065
Validation loss: 2.542461669008908

Epoch: 6| Step: 11
Training loss: 2.969556036496709
Validation loss: 2.5548139926361735

Epoch: 6| Step: 12
Training loss: 3.0817580108006193
Validation loss: 2.547158261819766

Epoch: 6| Step: 13
Training loss: 2.5340322580248844
Validation loss: 2.546783348984612

Epoch: 170| Step: 0
Training loss: 2.2171972509792077
Validation loss: 2.57059896646699

Epoch: 6| Step: 1
Training loss: 2.598807952953944
Validation loss: 2.609173760143335

Epoch: 6| Step: 2
Training loss: 2.4483186324136765
Validation loss: 2.647833574741993

Epoch: 6| Step: 3
Training loss: 3.1212920506661592
Validation loss: 2.7103707430140167

Epoch: 6| Step: 4
Training loss: 3.1158499465285914
Validation loss: 2.7245321243372302

Epoch: 6| Step: 5
Training loss: 2.4073638319761383
Validation loss: 2.6901344337559827

Epoch: 6| Step: 6
Training loss: 3.138002733782519
Validation loss: 2.62046135446035

Epoch: 6| Step: 7
Training loss: 2.246511297805874
Validation loss: 2.5317746490588755

Epoch: 6| Step: 8
Training loss: 2.993926576253022
Validation loss: 2.4855759098569736

Epoch: 6| Step: 9
Training loss: 3.3012732505918443
Validation loss: 2.4765381394390236

Epoch: 6| Step: 10
Training loss: 2.4567557515521203
Validation loss: 2.4770389273435325

Epoch: 6| Step: 11
Training loss: 2.838159116579003
Validation loss: 2.474513057223753

Epoch: 6| Step: 12
Training loss: 2.4376832942026065
Validation loss: 2.472459779680151

Epoch: 6| Step: 13
Training loss: 2.4207811407961937
Validation loss: 2.476120730533671

Epoch: 171| Step: 0
Training loss: 3.043667714222768
Validation loss: 2.4799388187323133

Epoch: 6| Step: 1
Training loss: 2.6206068789153325
Validation loss: 2.4807572019853357

Epoch: 6| Step: 2
Training loss: 2.509466273641896
Validation loss: 2.463405028224346

Epoch: 6| Step: 3
Training loss: 2.088044548962533
Validation loss: 2.464935114346281

Epoch: 6| Step: 4
Training loss: 2.35925454343791
Validation loss: 2.461769510528446

Epoch: 6| Step: 5
Training loss: 2.977211388373693
Validation loss: 2.4805964911068585

Epoch: 6| Step: 6
Training loss: 2.392307263048064
Validation loss: 2.4903461336155064

Epoch: 6| Step: 7
Training loss: 2.7034361555470734
Validation loss: 2.5227686640349725

Epoch: 6| Step: 8
Training loss: 2.479183410673471
Validation loss: 2.5643715935431293

Epoch: 6| Step: 9
Training loss: 3.1490438554216964
Validation loss: 2.593662265915233

Epoch: 6| Step: 10
Training loss: 2.9744290292814073
Validation loss: 2.5934074285340025

Epoch: 6| Step: 11
Training loss: 2.602127609507437
Validation loss: 2.5975552106475237

Epoch: 6| Step: 12
Training loss: 2.347276298256178
Validation loss: 2.580498203136089

Epoch: 6| Step: 13
Training loss: 3.607112951842661
Validation loss: 2.553177730790796

Epoch: 172| Step: 0
Training loss: 3.157439357148033
Validation loss: 2.508676136859482

Epoch: 6| Step: 1
Training loss: 3.001840662540444
Validation loss: 2.4706877682382196

Epoch: 6| Step: 2
Training loss: 2.381414484866183
Validation loss: 2.455784686393799

Epoch: 6| Step: 3
Training loss: 3.126291237139314
Validation loss: 2.4587162200048476

Epoch: 6| Step: 4
Training loss: 2.5945482978846535
Validation loss: 2.4548490464750166

Epoch: 6| Step: 5
Training loss: 2.4643129481514725
Validation loss: 2.46048594425859

Epoch: 6| Step: 6
Training loss: 2.024224087919016
Validation loss: 2.4643676915893304

Epoch: 6| Step: 7
Training loss: 2.8314401996379823
Validation loss: 2.45194950003217

Epoch: 6| Step: 8
Training loss: 2.5477816600282908
Validation loss: 2.446991567674802

Epoch: 6| Step: 9
Training loss: 1.971324387950724
Validation loss: 2.4524115998696714

Epoch: 6| Step: 10
Training loss: 3.135912799975518
Validation loss: 2.4609397970209375

Epoch: 6| Step: 11
Training loss: 2.836021064809199
Validation loss: 2.4547962739580798

Epoch: 6| Step: 12
Training loss: 2.83052744961171
Validation loss: 2.4692376993212504

Epoch: 6| Step: 13
Training loss: 1.685234668588951
Validation loss: 2.50124912537186

Epoch: 173| Step: 0
Training loss: 2.857537017609192
Validation loss: 2.5163295235477015

Epoch: 6| Step: 1
Training loss: 2.4384542700222505
Validation loss: 2.5255059693652657

Epoch: 6| Step: 2
Training loss: 2.531928454239514
Validation loss: 2.5385352600286923

Epoch: 6| Step: 3
Training loss: 2.4470918172018816
Validation loss: 2.506203171696065

Epoch: 6| Step: 4
Training loss: 2.7221950758880165
Validation loss: 2.5276334006076704

Epoch: 6| Step: 5
Training loss: 3.0223475026674023
Validation loss: 2.52106781528922

Epoch: 6| Step: 6
Training loss: 2.6676047483147127
Validation loss: 2.525368922604228

Epoch: 6| Step: 7
Training loss: 2.3545946615506113
Validation loss: 2.5228936872237435

Epoch: 6| Step: 8
Training loss: 2.9759655451472082
Validation loss: 2.53398139002803

Epoch: 6| Step: 9
Training loss: 3.159066029881671
Validation loss: 2.525061443413417

Epoch: 6| Step: 10
Training loss: 2.6204065368556835
Validation loss: 2.522364008702662

Epoch: 6| Step: 11
Training loss: 2.477875466789737
Validation loss: 2.521206651599955

Epoch: 6| Step: 12
Training loss: 2.2443354615840154
Validation loss: 2.516680895925335

Epoch: 6| Step: 13
Training loss: 2.3644023159384253
Validation loss: 2.513347018533668

Epoch: 174| Step: 0
Training loss: 2.9512890149340527
Validation loss: 2.5007452274491877

Epoch: 6| Step: 1
Training loss: 2.671369895261525
Validation loss: 2.49499410775182

Epoch: 6| Step: 2
Training loss: 2.150125402297612
Validation loss: 2.503405500322962

Epoch: 6| Step: 3
Training loss: 2.6421997070030514
Validation loss: 2.500998901442193

Epoch: 6| Step: 4
Training loss: 3.03270599948648
Validation loss: 2.4805785271360805

Epoch: 6| Step: 5
Training loss: 2.3113932667588535
Validation loss: 2.4805714751413337

Epoch: 6| Step: 6
Training loss: 2.802356314331849
Validation loss: 2.488774759433733

Epoch: 6| Step: 7
Training loss: 2.243015893901104
Validation loss: 2.4980532562642073

Epoch: 6| Step: 8
Training loss: 2.627333375999349
Validation loss: 2.484437803048753

Epoch: 6| Step: 9
Training loss: 3.156555312091562
Validation loss: 2.4708393394492534

Epoch: 6| Step: 10
Training loss: 2.2357395513683462
Validation loss: 2.462034203959494

Epoch: 6| Step: 11
Training loss: 2.533743207383237
Validation loss: 2.4694719464851267

Epoch: 6| Step: 12
Training loss: 2.5118062670041703
Validation loss: 2.470452696182905

Epoch: 6| Step: 13
Training loss: 2.7801544946512666
Validation loss: 2.5025852946150704

Epoch: 175| Step: 0
Training loss: 2.719479254773747
Validation loss: 2.524304279344128

Epoch: 6| Step: 1
Training loss: 2.800037152180104
Validation loss: 2.5284661455536126

Epoch: 6| Step: 2
Training loss: 2.049830974030475
Validation loss: 2.524482322038652

Epoch: 6| Step: 3
Training loss: 2.9377051748492287
Validation loss: 2.531516685601162

Epoch: 6| Step: 4
Training loss: 2.577766347271507
Validation loss: 2.5027792412881813

Epoch: 6| Step: 5
Training loss: 3.1705566071620215
Validation loss: 2.4835757843388557

Epoch: 6| Step: 6
Training loss: 2.3630874428214996
Validation loss: 2.5064000214886244

Epoch: 6| Step: 7
Training loss: 2.560368093014853
Validation loss: 2.5039078984083876

Epoch: 6| Step: 8
Training loss: 2.76313255628283
Validation loss: 2.5114457054377204

Epoch: 6| Step: 9
Training loss: 2.818877216860094
Validation loss: 2.4887593184653642

Epoch: 6| Step: 10
Training loss: 2.8549637250048816
Validation loss: 2.476156872113156

Epoch: 6| Step: 11
Training loss: 2.2691334886351675
Validation loss: 2.466259045609848

Epoch: 6| Step: 12
Training loss: 1.9980645351431168
Validation loss: 2.4758120861712847

Epoch: 6| Step: 13
Training loss: 2.4388537437940316
Validation loss: 2.4764304803428656

Epoch: 176| Step: 0
Training loss: 2.119660906933484
Validation loss: 2.4769754233441583

Epoch: 6| Step: 1
Training loss: 2.049931348255901
Validation loss: 2.48396975100836

Epoch: 6| Step: 2
Training loss: 2.404864320952673
Validation loss: 2.48136314988971

Epoch: 6| Step: 3
Training loss: 1.9007339716251437
Validation loss: 2.4872840993774887

Epoch: 6| Step: 4
Training loss: 2.17291937218629
Validation loss: 2.4750718689799855

Epoch: 6| Step: 5
Training loss: 2.709009017777246
Validation loss: 2.480998941101395

Epoch: 6| Step: 6
Training loss: 2.7759924067742445
Validation loss: 2.485632780993726

Epoch: 6| Step: 7
Training loss: 3.0968319733033667
Validation loss: 2.4733138449037946

Epoch: 6| Step: 8
Training loss: 2.645534218127955
Validation loss: 2.4519668456780352

Epoch: 6| Step: 9
Training loss: 2.420321649345703
Validation loss: 2.4509782219888634

Epoch: 6| Step: 10
Training loss: 3.2664205503846406
Validation loss: 2.45940432119233

Epoch: 6| Step: 11
Training loss: 2.9108882521078967
Validation loss: 2.4568239281043858

Epoch: 6| Step: 12
Training loss: 2.7488779900188387
Validation loss: 2.486042402453875

Epoch: 6| Step: 13
Training loss: 2.509178003770987
Validation loss: 2.4852763980067762

Epoch: 177| Step: 0
Training loss: 2.9492970033078567
Validation loss: 2.517757360163032

Epoch: 6| Step: 1
Training loss: 2.290221666160585
Validation loss: 2.553673802396389

Epoch: 6| Step: 2
Training loss: 2.370138513243572
Validation loss: 2.5699101345786146

Epoch: 6| Step: 3
Training loss: 2.2350537529610977
Validation loss: 2.5309579838544844

Epoch: 6| Step: 4
Training loss: 2.6967456490448054
Validation loss: 2.5018049277249585

Epoch: 6| Step: 5
Training loss: 2.828569914664652
Validation loss: 2.496172458608689

Epoch: 6| Step: 6
Training loss: 2.429923778955464
Validation loss: 2.508587654264177

Epoch: 6| Step: 7
Training loss: 2.447558167090769
Validation loss: 2.5013065308094893

Epoch: 6| Step: 8
Training loss: 2.418994396390886
Validation loss: 2.5208304952756166

Epoch: 6| Step: 9
Training loss: 2.9855117630082364
Validation loss: 2.5204715826834194

Epoch: 6| Step: 10
Training loss: 2.561741972664163
Validation loss: 2.536348178325658

Epoch: 6| Step: 11
Training loss: 2.526935243683352
Validation loss: 2.51589174511789

Epoch: 6| Step: 12
Training loss: 2.522693347156051
Validation loss: 2.5344575657727515

Epoch: 6| Step: 13
Training loss: 2.422367365840766
Validation loss: 2.5220996527341883

Epoch: 178| Step: 0
Training loss: 2.747189125613384
Validation loss: 2.5341855458161384

Epoch: 6| Step: 1
Training loss: 2.1343468816421423
Validation loss: 2.513972405115809

Epoch: 6| Step: 2
Training loss: 1.643805626917889
Validation loss: 2.5252992459788923

Epoch: 6| Step: 3
Training loss: 2.467572764490032
Validation loss: 2.5243454446517646

Epoch: 6| Step: 4
Training loss: 2.8683057054529737
Validation loss: 2.5643389456439762

Epoch: 6| Step: 5
Training loss: 2.723621257594708
Validation loss: 2.577678748446194

Epoch: 6| Step: 6
Training loss: 1.9382735523223242
Validation loss: 2.563940303236034

Epoch: 6| Step: 7
Training loss: 2.6208883509195577
Validation loss: 2.5412949347895117

Epoch: 6| Step: 8
Training loss: 2.8872578573051477
Validation loss: 2.5367220836458717

Epoch: 6| Step: 9
Training loss: 2.6907540072218366
Validation loss: 2.511420678780568

Epoch: 6| Step: 10
Training loss: 3.1451777770917366
Validation loss: 2.504981556785754

Epoch: 6| Step: 11
Training loss: 1.7592799864025739
Validation loss: 2.5033508814188776

Epoch: 6| Step: 12
Training loss: 2.6356910793894075
Validation loss: 2.4936458458467183

Epoch: 6| Step: 13
Training loss: 2.9755433107383245
Validation loss: 2.472193298924958

Epoch: 179| Step: 0
Training loss: 2.4871192985853146
Validation loss: 2.499834002859666

Epoch: 6| Step: 1
Training loss: 2.798060501578836
Validation loss: 2.5024471785395987

Epoch: 6| Step: 2
Training loss: 2.7859541297198045
Validation loss: 2.5403592224883633

Epoch: 6| Step: 3
Training loss: 2.295107102731067
Validation loss: 2.5501943730125727

Epoch: 6| Step: 4
Training loss: 2.6634946872435488
Validation loss: 2.5465277263873274

Epoch: 6| Step: 5
Training loss: 2.326488867235633
Validation loss: 2.535633512395492

Epoch: 6| Step: 6
Training loss: 2.7790185784991714
Validation loss: 2.5304508282006277

Epoch: 6| Step: 7
Training loss: 2.4262197592657317
Validation loss: 2.5138061557942617

Epoch: 6| Step: 8
Training loss: 3.071110046700592
Validation loss: 2.4827956875097024

Epoch: 6| Step: 9
Training loss: 2.4128977116682497
Validation loss: 2.4633418585805584

Epoch: 6| Step: 10
Training loss: 2.2282369106699633
Validation loss: 2.475789514274391

Epoch: 6| Step: 11
Training loss: 2.269246121221583
Validation loss: 2.474041200209588

Epoch: 6| Step: 12
Training loss: 2.345820212002833
Validation loss: 2.4988098808569927

Epoch: 6| Step: 13
Training loss: 2.3469158915730066
Validation loss: 2.5232411188192563

Epoch: 180| Step: 0
Training loss: 2.2532487303559785
Validation loss: 2.551008842516128

Epoch: 6| Step: 1
Training loss: 3.1201832079282776
Validation loss: 2.5634047078943225

Epoch: 6| Step: 2
Training loss: 2.105046217494834
Validation loss: 2.5323333811984616

Epoch: 6| Step: 3
Training loss: 2.9200693354801066
Validation loss: 2.5096819961728185

Epoch: 6| Step: 4
Training loss: 2.1362103235657273
Validation loss: 2.4795224113848313

Epoch: 6| Step: 5
Training loss: 2.8460115934499055
Validation loss: 2.456768796392447

Epoch: 6| Step: 6
Training loss: 2.488249821965968
Validation loss: 2.456172701362904

Epoch: 6| Step: 7
Training loss: 2.2129259636962058
Validation loss: 2.4479262254712046

Epoch: 6| Step: 8
Training loss: 2.7731945522442465
Validation loss: 2.4588183207398853

Epoch: 6| Step: 9
Training loss: 2.1667265761480228
Validation loss: 2.4618927299236937

Epoch: 6| Step: 10
Training loss: 2.7387395412675417
Validation loss: 2.4874649412690135

Epoch: 6| Step: 11
Training loss: 2.369444825218481
Validation loss: 2.495699452720482

Epoch: 6| Step: 12
Training loss: 2.561205653360095
Validation loss: 2.5051086281776995

Epoch: 6| Step: 13
Training loss: 2.614292285622074
Validation loss: 2.554194413548825

Epoch: 181| Step: 0
Training loss: 2.229716533212562
Validation loss: 2.64631288203852

Epoch: 6| Step: 1
Training loss: 2.7097992280017906
Validation loss: 2.677470102705205

Epoch: 6| Step: 2
Training loss: 2.8199539590688905
Validation loss: 2.6530302160593022

Epoch: 6| Step: 3
Training loss: 2.8710090469010536
Validation loss: 2.561829785195247

Epoch: 6| Step: 4
Training loss: 2.384862999330094
Validation loss: 2.472040302853987

Epoch: 6| Step: 5
Training loss: 2.751049188393928
Validation loss: 2.455367214787908

Epoch: 6| Step: 6
Training loss: 2.3557588262642617
Validation loss: 2.4473084004085104

Epoch: 6| Step: 7
Training loss: 2.8053394293132636
Validation loss: 2.4576407361227024

Epoch: 6| Step: 8
Training loss: 2.5692068580092853
Validation loss: 2.460230268745634

Epoch: 6| Step: 9
Training loss: 1.9276005506202432
Validation loss: 2.4675750553343216

Epoch: 6| Step: 10
Training loss: 2.2859382008820694
Validation loss: 2.4881962654312306

Epoch: 6| Step: 11
Training loss: 3.1584303472778936
Validation loss: 2.486197399332257

Epoch: 6| Step: 12
Training loss: 2.4810542339284596
Validation loss: 2.515963262155397

Epoch: 6| Step: 13
Training loss: 2.5004097602730635
Validation loss: 2.515579304744752

Epoch: 182| Step: 0
Training loss: 2.4483251569008506
Validation loss: 2.54039999190706

Epoch: 6| Step: 1
Training loss: 2.5244289847842323
Validation loss: 2.5590015083014284

Epoch: 6| Step: 2
Training loss: 3.2174929043588594
Validation loss: 2.5745582825340345

Epoch: 6| Step: 3
Training loss: 2.388206105895352
Validation loss: 2.5577466824867425

Epoch: 6| Step: 4
Training loss: 2.712088920277674
Validation loss: 2.5658659759090505

Epoch: 6| Step: 5
Training loss: 2.6881929435737835
Validation loss: 2.5644400451120157

Epoch: 6| Step: 6
Training loss: 2.240949335392839
Validation loss: 2.5784895742616114

Epoch: 6| Step: 7
Training loss: 2.636452985014829
Validation loss: 2.601722791920008

Epoch: 6| Step: 8
Training loss: 2.7814215275023604
Validation loss: 2.644551974980423

Epoch: 6| Step: 9
Training loss: 2.8785411753344268
Validation loss: 2.594419493534797

Epoch: 6| Step: 10
Training loss: 2.5049170776165153
Validation loss: 2.5625423695012555

Epoch: 6| Step: 11
Training loss: 2.2874998415754084
Validation loss: 2.522139686118668

Epoch: 6| Step: 12
Training loss: 2.648512217500149
Validation loss: 2.5050421228932818

Epoch: 6| Step: 13
Training loss: 1.9477521313486836
Validation loss: 2.4823581451819723

Epoch: 183| Step: 0
Training loss: 2.623633982949843
Validation loss: 2.483326961291404

Epoch: 6| Step: 1
Training loss: 2.0253845038178957
Validation loss: 2.455584097490517

Epoch: 6| Step: 2
Training loss: 2.3449501525200818
Validation loss: 2.480007003014462

Epoch: 6| Step: 3
Training loss: 2.0737375394459456
Validation loss: 2.464564927658023

Epoch: 6| Step: 4
Training loss: 2.6660088284025085
Validation loss: 2.4306861732962504

Epoch: 6| Step: 5
Training loss: 2.4720465946559145
Validation loss: 2.4246964621899605

Epoch: 6| Step: 6
Training loss: 2.5724486776112934
Validation loss: 2.4378585499133387

Epoch: 6| Step: 7
Training loss: 2.5216498405599452
Validation loss: 2.4230745761832977

Epoch: 6| Step: 8
Training loss: 2.959858639924373
Validation loss: 2.429669725184054

Epoch: 6| Step: 9
Training loss: 2.503914057917331
Validation loss: 2.451566369400898

Epoch: 6| Step: 10
Training loss: 2.4217486933104815
Validation loss: 2.44732522271152

Epoch: 6| Step: 11
Training loss: 3.1136416199151866
Validation loss: 2.467384075772167

Epoch: 6| Step: 12
Training loss: 2.272641386663432
Validation loss: 2.4629416289256976

Epoch: 6| Step: 13
Training loss: 1.9432100631632334
Validation loss: 2.4812826552303067

Epoch: 184| Step: 0
Training loss: 2.667551748100941
Validation loss: 2.4776106860230636

Epoch: 6| Step: 1
Training loss: 2.4844897741520713
Validation loss: 2.513603603386527

Epoch: 6| Step: 2
Training loss: 2.279735741944795
Validation loss: 2.529386452457634

Epoch: 6| Step: 3
Training loss: 2.3505790402890083
Validation loss: 2.557916226671964

Epoch: 6| Step: 4
Training loss: 1.7569366307476462
Validation loss: 2.577356044215754

Epoch: 6| Step: 5
Training loss: 2.8964769668124246
Validation loss: 2.60684856770008

Epoch: 6| Step: 6
Training loss: 1.974858329617116
Validation loss: 2.5721228334244666

Epoch: 6| Step: 7
Training loss: 2.5153191421995498
Validation loss: 2.560176094735268

Epoch: 6| Step: 8
Training loss: 3.079736587853176
Validation loss: 2.533262351498334

Epoch: 6| Step: 9
Training loss: 2.706114951061195
Validation loss: 2.48560315123196

Epoch: 6| Step: 10
Training loss: 2.3449817726711983
Validation loss: 2.4577890012127397

Epoch: 6| Step: 11
Training loss: 2.12003059509081
Validation loss: 2.439166441489215

Epoch: 6| Step: 12
Training loss: 2.475039233272433
Validation loss: 2.4259255337780283

Epoch: 6| Step: 13
Training loss: 2.9430813623264713
Validation loss: 2.406033223166273

Epoch: 185| Step: 0
Training loss: 2.4329070810933935
Validation loss: 2.4055795565228544

Epoch: 6| Step: 1
Training loss: 2.2360705364750455
Validation loss: 2.3930226950090194

Epoch: 6| Step: 2
Training loss: 2.121481956518484
Validation loss: 2.4067955064628084

Epoch: 6| Step: 3
Training loss: 2.530088935464978
Validation loss: 2.4425145669789226

Epoch: 6| Step: 4
Training loss: 2.342907970488536
Validation loss: 2.486073277827339

Epoch: 6| Step: 5
Training loss: 2.576718403279133
Validation loss: 2.49147081146222

Epoch: 6| Step: 6
Training loss: 2.4069488303273014
Validation loss: 2.522274133058818

Epoch: 6| Step: 7
Training loss: 2.7383681431804323
Validation loss: 2.5568803694110462

Epoch: 6| Step: 8
Training loss: 2.421462485344782
Validation loss: 2.614982191829191

Epoch: 6| Step: 9
Training loss: 2.1974129724900324
Validation loss: 2.6326819861868875

Epoch: 6| Step: 10
Training loss: 2.5588991871005105
Validation loss: 2.6452813164098745

Epoch: 6| Step: 11
Training loss: 2.7376809326020646
Validation loss: 2.6879459677865736

Epoch: 6| Step: 12
Training loss: 2.9285261369984403
Validation loss: 2.658685137177477

Epoch: 6| Step: 13
Training loss: 2.8397377970369746
Validation loss: 2.5974385680665577

Epoch: 186| Step: 0
Training loss: 2.103134531620187
Validation loss: 2.5810693935638813

Epoch: 6| Step: 1
Training loss: 2.4329460837477144
Validation loss: 2.554312872295803

Epoch: 6| Step: 2
Training loss: 2.593244756184521
Validation loss: 2.516533834902567

Epoch: 6| Step: 3
Training loss: 3.0266570856836172
Validation loss: 2.4754796319644248

Epoch: 6| Step: 4
Training loss: 2.648508616705113
Validation loss: 2.455854145703181

Epoch: 6| Step: 5
Training loss: 2.5500820071927497
Validation loss: 2.4342972891950123

Epoch: 6| Step: 6
Training loss: 2.0996946521562845
Validation loss: 2.426499302609926

Epoch: 6| Step: 7
Training loss: 2.521553777305426
Validation loss: 2.424083459380065

Epoch: 6| Step: 8
Training loss: 2.479005012264009
Validation loss: 2.4177909551260535

Epoch: 6| Step: 9
Training loss: 2.3697315809296877
Validation loss: 2.4158861574551787

Epoch: 6| Step: 10
Training loss: 1.8936041697135113
Validation loss: 2.4163692147744196

Epoch: 6| Step: 11
Training loss: 2.507271966881907
Validation loss: 2.437681606270194

Epoch: 6| Step: 12
Training loss: 2.6372096982171525
Validation loss: 2.460172524862405

Epoch: 6| Step: 13
Training loss: 1.827063749665845
Validation loss: 2.4795876398320256

Epoch: 187| Step: 0
Training loss: 2.1316782412042015
Validation loss: 2.51202352249738

Epoch: 6| Step: 1
Training loss: 2.6073031852082655
Validation loss: 2.560958616818874

Epoch: 6| Step: 2
Training loss: 2.279824843789403
Validation loss: 2.583692706440607

Epoch: 6| Step: 3
Training loss: 2.6506286379288397
Validation loss: 2.5854300998211417

Epoch: 6| Step: 4
Training loss: 2.094548315187148
Validation loss: 2.557182829148789

Epoch: 6| Step: 5
Training loss: 2.2487685754421234
Validation loss: 2.533264433164537

Epoch: 6| Step: 6
Training loss: 2.854202010406926
Validation loss: 2.5206468174666683

Epoch: 6| Step: 7
Training loss: 2.25451461541571
Validation loss: 2.5104090192192654

Epoch: 6| Step: 8
Training loss: 2.2502354392741943
Validation loss: 2.520485578317192

Epoch: 6| Step: 9
Training loss: 2.664969371025611
Validation loss: 2.5271881664751126

Epoch: 6| Step: 10
Training loss: 2.390914101666271
Validation loss: 2.521655100712485

Epoch: 6| Step: 11
Training loss: 2.647115191626167
Validation loss: 2.5202090759012856

Epoch: 6| Step: 12
Training loss: 3.0222028236919734
Validation loss: 2.508475608689456

Epoch: 6| Step: 13
Training loss: 2.433305799859751
Validation loss: 2.4913783223549713

Epoch: 188| Step: 0
Training loss: 2.2974891101134927
Validation loss: 2.46630354870309

Epoch: 6| Step: 1
Training loss: 2.6976085668570353
Validation loss: 2.4822895142593056

Epoch: 6| Step: 2
Training loss: 1.2929945652162314
Validation loss: 2.4964335115333056

Epoch: 6| Step: 3
Training loss: 2.049328563800458
Validation loss: 2.521983077103538

Epoch: 6| Step: 4
Training loss: 2.9907972328074255
Validation loss: 2.540431134036389

Epoch: 6| Step: 5
Training loss: 2.121397218018401
Validation loss: 2.537574088223704

Epoch: 6| Step: 6
Training loss: 2.5209826170379905
Validation loss: 2.55678332567202

Epoch: 6| Step: 7
Training loss: 2.7422361885812907
Validation loss: 2.560950202001686

Epoch: 6| Step: 8
Training loss: 2.7513984245671237
Validation loss: 2.5620366329592277

Epoch: 6| Step: 9
Training loss: 2.590900648520068
Validation loss: 2.5528015378449385

Epoch: 6| Step: 10
Training loss: 2.305582060399835
Validation loss: 2.5262856091123194

Epoch: 6| Step: 11
Training loss: 2.20870103713786
Validation loss: 2.5141150130497683

Epoch: 6| Step: 12
Training loss: 2.4867885549840594
Validation loss: 2.486154097903842

Epoch: 6| Step: 13
Training loss: 2.4122314422238325
Validation loss: 2.4628577446032285

Epoch: 189| Step: 0
Training loss: 2.740334256799571
Validation loss: 2.4626235522402036

Epoch: 6| Step: 1
Training loss: 2.673331505052634
Validation loss: 2.4456757736236527

Epoch: 6| Step: 2
Training loss: 2.474056672935856
Validation loss: 2.4296291758325412

Epoch: 6| Step: 3
Training loss: 2.025605207827353
Validation loss: 2.4277034187285276

Epoch: 6| Step: 4
Training loss: 2.997866030528968
Validation loss: 2.43366629710107

Epoch: 6| Step: 5
Training loss: 2.5531396872426
Validation loss: 2.445696567354222

Epoch: 6| Step: 6
Training loss: 2.27998996581831
Validation loss: 2.447512183527928

Epoch: 6| Step: 7
Training loss: 2.710406512496267
Validation loss: 2.4305446792882663

Epoch: 6| Step: 8
Training loss: 2.202699985496149
Validation loss: 2.43910221526498

Epoch: 6| Step: 9
Training loss: 2.2605403274486133
Validation loss: 2.4445099559269905

Epoch: 6| Step: 10
Training loss: 1.7419345141736275
Validation loss: 2.4284820357071206

Epoch: 6| Step: 11
Training loss: 2.4907046124646604
Validation loss: 2.452644833604922

Epoch: 6| Step: 12
Training loss: 2.1723985658413674
Validation loss: 2.4505865254689376

Epoch: 6| Step: 13
Training loss: 1.7318307584179848
Validation loss: 2.4870282544187647

Epoch: 190| Step: 0
Training loss: 2.4605599249968964
Validation loss: 2.51806246874943

Epoch: 6| Step: 1
Training loss: 2.6139022933106375
Validation loss: 2.522525877812165

Epoch: 6| Step: 2
Training loss: 2.228484278064754
Validation loss: 2.5239867363158663

Epoch: 6| Step: 3
Training loss: 2.849868061960247
Validation loss: 2.5343746353978016

Epoch: 6| Step: 4
Training loss: 2.074970576066207
Validation loss: 2.521458534958614

Epoch: 6| Step: 5
Training loss: 2.0674526975818046
Validation loss: 2.5366400479480813

Epoch: 6| Step: 6
Training loss: 2.4948972123555966
Validation loss: 2.527569427281595

Epoch: 6| Step: 7
Training loss: 2.0057968531060606
Validation loss: 2.525380153745487

Epoch: 6| Step: 8
Training loss: 2.4791502324262167
Validation loss: 2.5093186804829952

Epoch: 6| Step: 9
Training loss: 2.4132237628524935
Validation loss: 2.514845404042873

Epoch: 6| Step: 10
Training loss: 2.1223919515437726
Validation loss: 2.5048347668590685

Epoch: 6| Step: 11
Training loss: 2.439092849259152
Validation loss: 2.5087689317030755

Epoch: 6| Step: 12
Training loss: 2.565741094269546
Validation loss: 2.512424912787501

Epoch: 6| Step: 13
Training loss: 2.4559633393487075
Validation loss: 2.5158182257341086

Epoch: 191| Step: 0
Training loss: 2.070108885918938
Validation loss: 2.5181765881017926

Epoch: 6| Step: 1
Training loss: 2.1460925812886447
Validation loss: 2.5075541100472796

Epoch: 6| Step: 2
Training loss: 2.6207679966806556
Validation loss: 2.5094646942663483

Epoch: 6| Step: 3
Training loss: 2.0819980411135557
Validation loss: 2.469536361805573

Epoch: 6| Step: 4
Training loss: 2.496574152652956
Validation loss: 2.4477696943878633

Epoch: 6| Step: 5
Training loss: 1.9212129274364225
Validation loss: 2.43863587461071

Epoch: 6| Step: 6
Training loss: 2.0982887834582304
Validation loss: 2.426942314125891

Epoch: 6| Step: 7
Training loss: 2.7455212795396484
Validation loss: 2.4359884263378686

Epoch: 6| Step: 8
Training loss: 2.043770568930802
Validation loss: 2.4297307220361346

Epoch: 6| Step: 9
Training loss: 2.7132677072966356
Validation loss: 2.421691318073676

Epoch: 6| Step: 10
Training loss: 2.8671033467512377
Validation loss: 2.4322564335790906

Epoch: 6| Step: 11
Training loss: 2.7306550798704268
Validation loss: 2.4512308997801138

Epoch: 6| Step: 12
Training loss: 2.031038596082821
Validation loss: 2.4564777258577952

Epoch: 6| Step: 13
Training loss: 2.5124745989222443
Validation loss: 2.45917444420554

Epoch: 192| Step: 0
Training loss: 2.2996737497558564
Validation loss: 2.458382875232866

Epoch: 6| Step: 1
Training loss: 1.9243055032122611
Validation loss: 2.4403054284850265

Epoch: 6| Step: 2
Training loss: 2.165209194410624
Validation loss: 2.4243661020480975

Epoch: 6| Step: 3
Training loss: 2.0977136472666986
Validation loss: 2.436341436589989

Epoch: 6| Step: 4
Training loss: 2.1538264711235215
Validation loss: 2.4571829729314887

Epoch: 6| Step: 5
Training loss: 2.520576390394315
Validation loss: 2.4713550715749157

Epoch: 6| Step: 6
Training loss: 2.335439367351295
Validation loss: 2.5136008231198903

Epoch: 6| Step: 7
Training loss: 2.6606321203285734
Validation loss: 2.501113243811267

Epoch: 6| Step: 8
Training loss: 2.405758795205119
Validation loss: 2.4984828755103066

Epoch: 6| Step: 9
Training loss: 2.125294160117326
Validation loss: 2.5470658117651426

Epoch: 6| Step: 10
Training loss: 2.579107201485931
Validation loss: 2.581406805484919

Epoch: 6| Step: 11
Training loss: 2.46655765198043
Validation loss: 2.624859702115688

Epoch: 6| Step: 12
Training loss: 2.379055275344251
Validation loss: 2.5916154323478446

Epoch: 6| Step: 13
Training loss: 2.9451854081395066
Validation loss: 2.5892547049899086

Epoch: 193| Step: 0
Training loss: 2.081295033560507
Validation loss: 2.569843534586816

Epoch: 6| Step: 1
Training loss: 2.053688996071272
Validation loss: 2.5488377556269026

Epoch: 6| Step: 2
Training loss: 2.515493069618913
Validation loss: 2.5304745350078086

Epoch: 6| Step: 3
Training loss: 2.0299253399278387
Validation loss: 2.514954104699848

Epoch: 6| Step: 4
Training loss: 2.5038895866803665
Validation loss: 2.4927517567225324

Epoch: 6| Step: 5
Training loss: 2.2266394886292207
Validation loss: 2.4799155468078844

Epoch: 6| Step: 6
Training loss: 2.3741670452888415
Validation loss: 2.4569658776472845

Epoch: 6| Step: 7
Training loss: 2.685898503258436
Validation loss: 2.437080327189271

Epoch: 6| Step: 8
Training loss: 3.0501315979630417
Validation loss: 2.458974502972283

Epoch: 6| Step: 9
Training loss: 2.030162344017445
Validation loss: 2.460322134726188

Epoch: 6| Step: 10
Training loss: 2.3850715309788386
Validation loss: 2.4754059925209577

Epoch: 6| Step: 11
Training loss: 2.286527825228557
Validation loss: 2.4780554817704004

Epoch: 6| Step: 12
Training loss: 1.4306543135066727
Validation loss: 2.4900531195977225

Epoch: 6| Step: 13
Training loss: 2.509616856303347
Validation loss: 2.4878278840123977

Epoch: 194| Step: 0
Training loss: 2.616432559318772
Validation loss: 2.4968992975325333

Epoch: 6| Step: 1
Training loss: 1.8301809113094087
Validation loss: 2.507433195873463

Epoch: 6| Step: 2
Training loss: 2.971540565004586
Validation loss: 2.504386965902569

Epoch: 6| Step: 3
Training loss: 1.517997457926837
Validation loss: 2.502092643359061

Epoch: 6| Step: 4
Training loss: 2.253741967413833
Validation loss: 2.5179997641775653

Epoch: 6| Step: 5
Training loss: 2.536735148798338
Validation loss: 2.5262291477877947

Epoch: 6| Step: 6
Training loss: 2.29986522943136
Validation loss: 2.562547685773239

Epoch: 6| Step: 7
Training loss: 2.0557779529762836
Validation loss: 2.565098015504196

Epoch: 6| Step: 8
Training loss: 2.77214067254644
Validation loss: 2.585480873769118

Epoch: 6| Step: 9
Training loss: 2.105130708129385
Validation loss: 2.587349395466873

Epoch: 6| Step: 10
Training loss: 2.16111383718511
Validation loss: 2.590490230771358

Epoch: 6| Step: 11
Training loss: 2.253513771409469
Validation loss: 2.544111674185799

Epoch: 6| Step: 12
Training loss: 2.3152328014931594
Validation loss: 2.518293166879395

Epoch: 6| Step: 13
Training loss: 1.8040566270614704
Validation loss: 2.476775923898686

Epoch: 195| Step: 0
Training loss: 2.238692161030165
Validation loss: 2.437342290769489

Epoch: 6| Step: 1
Training loss: 1.9111978074426477
Validation loss: 2.421792004102943

Epoch: 6| Step: 2
Training loss: 1.7970535853000993
Validation loss: 2.4174625506261154

Epoch: 6| Step: 3
Training loss: 1.9480074557057916
Validation loss: 2.4080261772783675

Epoch: 6| Step: 4
Training loss: 1.8989723613790739
Validation loss: 2.424657027611729

Epoch: 6| Step: 5
Training loss: 2.811383767615559
Validation loss: 2.433020022061086

Epoch: 6| Step: 6
Training loss: 2.5983293851472107
Validation loss: 2.455108706868211

Epoch: 6| Step: 7
Training loss: 2.888627635521619
Validation loss: 2.496381488187373

Epoch: 6| Step: 8
Training loss: 2.4017823594566736
Validation loss: 2.5329852550225067

Epoch: 6| Step: 9
Training loss: 2.5809016216614262
Validation loss: 2.545569164553562

Epoch: 6| Step: 10
Training loss: 2.165960918316975
Validation loss: 2.55644787846055

Epoch: 6| Step: 11
Training loss: 2.6591432858208988
Validation loss: 2.577786704024564

Epoch: 6| Step: 12
Training loss: 2.1075854587084426
Validation loss: 2.6165024158423544

Epoch: 6| Step: 13
Training loss: 2.218296165795025
Validation loss: 2.663765242801651

Epoch: 196| Step: 0
Training loss: 2.304121148301939
Validation loss: 2.691538049067078

Epoch: 6| Step: 1
Training loss: 2.2040937742164126
Validation loss: 2.673348721358222

Epoch: 6| Step: 2
Training loss: 2.588274311916495
Validation loss: 2.6356645868192183

Epoch: 6| Step: 3
Training loss: 2.2653014905748603
Validation loss: 2.552117092636728

Epoch: 6| Step: 4
Training loss: 2.7943867958278905
Validation loss: 2.4968425500512144

Epoch: 6| Step: 5
Training loss: 2.37172030822755
Validation loss: 2.467338640416303

Epoch: 6| Step: 6
Training loss: 2.315301383979465
Validation loss: 2.436363069178603

Epoch: 6| Step: 7
Training loss: 2.41230853413005
Validation loss: 2.407923083344498

Epoch: 6| Step: 8
Training loss: 2.020106574920156
Validation loss: 2.3993106711768872

Epoch: 6| Step: 9
Training loss: 2.16724907554495
Validation loss: 2.382463165664056

Epoch: 6| Step: 10
Training loss: 2.355354774463165
Validation loss: 2.3964475175288587

Epoch: 6| Step: 11
Training loss: 2.171410160954666
Validation loss: 2.408922788290552

Epoch: 6| Step: 12
Training loss: 2.137043093206232
Validation loss: 2.4283396140909144

Epoch: 6| Step: 13
Training loss: 2.63528462155819
Validation loss: 2.4415026421663315

Epoch: 197| Step: 0
Training loss: 2.614962505998103
Validation loss: 2.4476558744492842

Epoch: 6| Step: 1
Training loss: 1.992560497595586
Validation loss: 2.468504152405061

Epoch: 6| Step: 2
Training loss: 2.1523479593170047
Validation loss: 2.484476409491382

Epoch: 6| Step: 3
Training loss: 2.5328517602493426
Validation loss: 2.5154632595853204

Epoch: 6| Step: 4
Training loss: 2.1522533584694363
Validation loss: 2.5296212661764312

Epoch: 6| Step: 5
Training loss: 2.565592132989748
Validation loss: 2.550403548602226

Epoch: 6| Step: 6
Training loss: 2.2214080577423605
Validation loss: 2.5789454159408662

Epoch: 6| Step: 7
Training loss: 2.2935151938847227
Validation loss: 2.6141635302982347

Epoch: 6| Step: 8
Training loss: 2.0204705243659316
Validation loss: 2.6616319946041997

Epoch: 6| Step: 9
Training loss: 2.6863194911341552
Validation loss: 2.6572458483941928

Epoch: 6| Step: 10
Training loss: 2.198961585069713
Validation loss: 2.6385228891088586

Epoch: 6| Step: 11
Training loss: 2.3426441890019594
Validation loss: 2.5562975723433587

Epoch: 6| Step: 12
Training loss: 2.1257450817077728
Validation loss: 2.5067094026401238

Epoch: 6| Step: 13
Training loss: 1.8969153436081538
Validation loss: 2.4676982123562947

Epoch: 198| Step: 0
Training loss: 2.3561988319082583
Validation loss: 2.441134202332685

Epoch: 6| Step: 1
Training loss: 2.315258957816176
Validation loss: 2.4203975154796

Epoch: 6| Step: 2
Training loss: 2.1237993775499473
Validation loss: 2.4226072275601775

Epoch: 6| Step: 3
Training loss: 2.6282338703843124
Validation loss: 2.413597667764794

Epoch: 6| Step: 4
Training loss: 2.0632914556260284
Validation loss: 2.415528759546685

Epoch: 6| Step: 5
Training loss: 2.525159502184884
Validation loss: 2.40460443182718

Epoch: 6| Step: 6
Training loss: 2.7376509742387705
Validation loss: 2.4199747178473983

Epoch: 6| Step: 7
Training loss: 1.809423532312739
Validation loss: 2.4347781952389984

Epoch: 6| Step: 8
Training loss: 2.2312227434475664
Validation loss: 2.429894798184475

Epoch: 6| Step: 9
Training loss: 2.288663653625733
Validation loss: 2.461429193809819

Epoch: 6| Step: 10
Training loss: 2.422832275215452
Validation loss: 2.4869224637656573

Epoch: 6| Step: 11
Training loss: 1.8724071376779396
Validation loss: 2.501655793222495

Epoch: 6| Step: 12
Training loss: 2.1393196971185704
Validation loss: 2.499019263284464

Epoch: 6| Step: 13
Training loss: 2.0220228279704204
Validation loss: 2.5107796829102944

Epoch: 199| Step: 0
Training loss: 2.440358173471989
Validation loss: 2.5195996865900843

Epoch: 6| Step: 1
Training loss: 2.4290935612229525
Validation loss: 2.5309186612474406

Epoch: 6| Step: 2
Training loss: 2.606869894172243
Validation loss: 2.5258634743965502

Epoch: 6| Step: 3
Training loss: 2.397519013425914
Validation loss: 2.5586952337763633

Epoch: 6| Step: 4
Training loss: 1.861402223919386
Validation loss: 2.575115870325805

Epoch: 6| Step: 5
Training loss: 2.286278395353902
Validation loss: 2.5730846377268657

Epoch: 6| Step: 6
Training loss: 2.0036755404853617
Validation loss: 2.573497594207719

Epoch: 6| Step: 7
Training loss: 2.44150693151774
Validation loss: 2.5763474716585453

Epoch: 6| Step: 8
Training loss: 2.6587964586253
Validation loss: 2.5542184861358335

Epoch: 6| Step: 9
Training loss: 2.0366987653950974
Validation loss: 2.533112108769752

Epoch: 6| Step: 10
Training loss: 1.5838464942686923
Validation loss: 2.4972786242906153

Epoch: 6| Step: 11
Training loss: 1.796983466813713
Validation loss: 2.461487718500427

Epoch: 6| Step: 12
Training loss: 2.0285260055338097
Validation loss: 2.4615328525513522

Epoch: 6| Step: 13
Training loss: 2.730541834037336
Validation loss: 2.4446980317886218

Epoch: 200| Step: 0
Training loss: 2.2520007668556548
Validation loss: 2.437552948727126

Epoch: 6| Step: 1
Training loss: 2.621597991968666
Validation loss: 2.435500843601784

Epoch: 6| Step: 2
Training loss: 2.492589840355539
Validation loss: 2.463086148537603

Epoch: 6| Step: 3
Training loss: 2.1601149708561564
Validation loss: 2.4651656615279935

Epoch: 6| Step: 4
Training loss: 2.391763054725265
Validation loss: 2.4569205449222387

Epoch: 6| Step: 5
Training loss: 2.39342957585606
Validation loss: 2.4637549332581354

Epoch: 6| Step: 6
Training loss: 2.1773407584649904
Validation loss: 2.4730148554347964

Epoch: 6| Step: 7
Training loss: 2.080296923095
Validation loss: 2.4620299160087766

Epoch: 6| Step: 8
Training loss: 1.9460193008767321
Validation loss: 2.459207341532774

Epoch: 6| Step: 9
Training loss: 2.5506823580442517
Validation loss: 2.4796971628780717

Epoch: 6| Step: 10
Training loss: 1.9037898714094477
Validation loss: 2.482475274184715

Epoch: 6| Step: 11
Training loss: 1.6705134899801584
Validation loss: 2.5071389118493603

Epoch: 6| Step: 12
Training loss: 2.4301181423839466
Validation loss: 2.5012052717274194

Epoch: 6| Step: 13
Training loss: 1.8404326903521016
Validation loss: 2.5270920048470655

Epoch: 201| Step: 0
Training loss: 2.4641245716237603
Validation loss: 2.5536096893381774

Epoch: 6| Step: 1
Training loss: 1.7416925796454974
Validation loss: 2.573222587831325

Epoch: 6| Step: 2
Training loss: 2.579256214154696
Validation loss: 2.610254520815617

Epoch: 6| Step: 3
Training loss: 1.7838972397404889
Validation loss: 2.6267045342246775

Epoch: 6| Step: 4
Training loss: 2.047774139235938
Validation loss: 2.6616965117213094

Epoch: 6| Step: 5
Training loss: 2.4207938457514158
Validation loss: 2.663789614821156

Epoch: 6| Step: 6
Training loss: 2.181213282410002
Validation loss: 2.665128524492514

Epoch: 6| Step: 7
Training loss: 1.4675292765671788
Validation loss: 2.6566987895712884

Epoch: 6| Step: 8
Training loss: 2.5201666925187816
Validation loss: 2.671073288122893

Epoch: 6| Step: 9
Training loss: 2.400052797213603
Validation loss: 2.665832408902087

Epoch: 6| Step: 10
Training loss: 2.1611588481260458
Validation loss: 2.6474191717255278

Epoch: 6| Step: 11
Training loss: 2.5206243465166405
Validation loss: 2.622419570532081

Epoch: 6| Step: 12
Training loss: 1.8831294889045234
Validation loss: 2.5647352520620803

Epoch: 6| Step: 13
Training loss: 2.2108840127143217
Validation loss: 2.535583869579686

Epoch: 202| Step: 0
Training loss: 2.0870625751438117
Validation loss: 2.52127291098464

Epoch: 6| Step: 1
Training loss: 2.5560207795804346
Validation loss: 2.5131880535224345

Epoch: 6| Step: 2
Training loss: 2.587182888925855
Validation loss: 2.5061706672391146

Epoch: 6| Step: 3
Training loss: 1.8985892655105627
Validation loss: 2.5336676774329296

Epoch: 6| Step: 4
Training loss: 2.0362655925680624
Validation loss: 2.5550715886002173

Epoch: 6| Step: 5
Training loss: 2.5184217745560624
Validation loss: 2.565977598586134

Epoch: 6| Step: 6
Training loss: 2.09220122944641
Validation loss: 2.5609570211490262

Epoch: 6| Step: 7
Training loss: 1.8469130329792331
Validation loss: 2.567150152559129

Epoch: 6| Step: 8
Training loss: 2.402760043167591
Validation loss: 2.556499654203918

Epoch: 6| Step: 9
Training loss: 1.9872956296822142
Validation loss: 2.5454442066620713

Epoch: 6| Step: 10
Training loss: 2.086144140630815
Validation loss: 2.53028664334738

Epoch: 6| Step: 11
Training loss: 1.5659305297233583
Validation loss: 2.5134145923084397

Epoch: 6| Step: 12
Training loss: 2.4188748389070502
Validation loss: 2.507334361029032

Epoch: 6| Step: 13
Training loss: 1.565329697831095
Validation loss: 2.536843208611969

Epoch: 203| Step: 0
Training loss: 2.83408229876909
Validation loss: 2.5286556689076374

Epoch: 6| Step: 1
Training loss: 2.1614076049244493
Validation loss: 2.5195295049749236

Epoch: 6| Step: 2
Training loss: 1.8976905514980558
Validation loss: 2.513433648582151

Epoch: 6| Step: 3
Training loss: 2.453456200273434
Validation loss: 2.5226145859469566

Epoch: 6| Step: 4
Training loss: 2.1396779659432665
Validation loss: 2.540546321782048

Epoch: 6| Step: 5
Training loss: 1.4109348673072493
Validation loss: 2.5521775245654625

Epoch: 6| Step: 6
Training loss: 1.2707441434153028
Validation loss: 2.561178282216479

Epoch: 6| Step: 7
Training loss: 2.6078618396367914
Validation loss: 2.578452555412308

Epoch: 6| Step: 8
Training loss: 2.6053946282911573
Validation loss: 2.5936124458512766

Epoch: 6| Step: 9
Training loss: 2.23427362812273
Validation loss: 2.6060956184330326

Epoch: 6| Step: 10
Training loss: 1.3826471434612424
Validation loss: 2.5855704738795993

Epoch: 6| Step: 11
Training loss: 1.8945260903199714
Validation loss: 2.5554719019051055

Epoch: 6| Step: 12
Training loss: 2.341474420206152
Validation loss: 2.54489645526845

Epoch: 6| Step: 13
Training loss: 1.7688490876928247
Validation loss: 2.5527965457333814

Epoch: 204| Step: 0
Training loss: 1.5228148141487585
Validation loss: 2.530836288529461

Epoch: 6| Step: 1
Training loss: 1.909647868086491
Validation loss: 2.5352058971443214

Epoch: 6| Step: 2
Training loss: 2.60643451869955
Validation loss: 2.5452940393938452

Epoch: 6| Step: 3
Training loss: 2.015603117121705
Validation loss: 2.546323721489289

Epoch: 6| Step: 4
Training loss: 1.729850434690151
Validation loss: 2.54342893438877

Epoch: 6| Step: 5
Training loss: 1.6726342019378988
Validation loss: 2.5265166639194145

Epoch: 6| Step: 6
Training loss: 2.6965150665875197
Validation loss: 2.496181913416554

Epoch: 6| Step: 7
Training loss: 2.254127319707054
Validation loss: 2.4995701840809574

Epoch: 6| Step: 8
Training loss: 2.189858500294541
Validation loss: 2.507951913195959

Epoch: 6| Step: 9
Training loss: 2.3006392792971315
Validation loss: 2.522238279277114

Epoch: 6| Step: 10
Training loss: 1.8701034824277514
Validation loss: 2.534311031519861

Epoch: 6| Step: 11
Training loss: 1.679184523393643
Validation loss: 2.5434781448912607

Epoch: 6| Step: 12
Training loss: 2.3527079989091515
Validation loss: 2.5594380350689434

Epoch: 6| Step: 13
Training loss: 2.1920899329357746
Validation loss: 2.5878099835354194

Epoch: 205| Step: 0
Training loss: 1.6366613555531977
Validation loss: 2.5528305543628482

Epoch: 6| Step: 1
Training loss: 2.115353511368221
Validation loss: 2.56440668529742

Epoch: 6| Step: 2
Training loss: 2.062913564197989
Validation loss: 2.561190965367155

Epoch: 6| Step: 3
Training loss: 2.232012266426152
Validation loss: 2.5421180895779547

Epoch: 6| Step: 4
Training loss: 1.3247301582654551
Validation loss: 2.541409036808399

Epoch: 6| Step: 5
Training loss: 1.961280519188451
Validation loss: 2.525509408521088

Epoch: 6| Step: 6
Training loss: 2.0872317524408297
Validation loss: 2.5315051905353436

Epoch: 6| Step: 7
Training loss: 2.5796045854946223
Validation loss: 2.523719135146012

Epoch: 6| Step: 8
Training loss: 1.773711868102072
Validation loss: 2.5174475536184238

Epoch: 6| Step: 9
Training loss: 1.9176811422160513
Validation loss: 2.5060628213543397

Epoch: 6| Step: 10
Training loss: 2.3003906540199415
Validation loss: 2.487427646835659

Epoch: 6| Step: 11
Training loss: 2.2455754751917634
Validation loss: 2.495180554449521

Epoch: 6| Step: 12
Training loss: 2.4960952782663552
Validation loss: 2.4855927712430166

Epoch: 6| Step: 13
Training loss: 2.0557465235464916
Validation loss: 2.516369478593056

Epoch: 206| Step: 0
Training loss: 2.1584045040027067
Validation loss: 2.5372279514116594

Epoch: 6| Step: 1
Training loss: 2.1906667403354425
Validation loss: 2.5420857438213966

Epoch: 6| Step: 2
Training loss: 2.2547621663737396
Validation loss: 2.579931423420248

Epoch: 6| Step: 3
Training loss: 1.9131671913576718
Validation loss: 2.5759527367956774

Epoch: 6| Step: 4
Training loss: 1.989550352239284
Validation loss: 2.6063507319508568

Epoch: 6| Step: 5
Training loss: 2.1999878969726563
Validation loss: 2.5908512661431025

Epoch: 6| Step: 6
Training loss: 2.0202561042390363
Validation loss: 2.5923654968157757

Epoch: 6| Step: 7
Training loss: 1.6677160853392998
Validation loss: 2.584400326477911

Epoch: 6| Step: 8
Training loss: 1.8939242619574648
Validation loss: 2.5488901063741567

Epoch: 6| Step: 9
Training loss: 2.348220731942914
Validation loss: 2.538410885024584

Epoch: 6| Step: 10
Training loss: 2.0953332409269527
Validation loss: 2.5124962948452594

Epoch: 6| Step: 11
Training loss: 2.084648848678391
Validation loss: 2.521060046261939

Epoch: 6| Step: 12
Training loss: 2.1614981651466025
Validation loss: 2.5079773363241866

Epoch: 6| Step: 13
Training loss: 0.5343533360958678
Validation loss: 2.5417537287650447

Epoch: 207| Step: 0
Training loss: 2.2354166230565826
Validation loss: 2.536383918566278

Epoch: 6| Step: 1
Training loss: 1.9166727757011026
Validation loss: 2.5394616870067703

Epoch: 6| Step: 2
Training loss: 1.677066407996912
Validation loss: 2.5224670572948127

Epoch: 6| Step: 3
Training loss: 2.3102287273370847
Validation loss: 2.5254586662861147

Epoch: 6| Step: 4
Training loss: 1.4696895759465658
Validation loss: 2.500722373660962

Epoch: 6| Step: 5
Training loss: 1.7250974489412203
Validation loss: 2.5322658050661255

Epoch: 6| Step: 6
Training loss: 2.1475133399415824
Validation loss: 2.5425853901188997

Epoch: 6| Step: 7
Training loss: 2.1570418742027724
Validation loss: 2.513624742899512

Epoch: 6| Step: 8
Training loss: 1.611181485988539
Validation loss: 2.5216626838933656

Epoch: 6| Step: 9
Training loss: 1.72664217527736
Validation loss: 2.524487787515215

Epoch: 6| Step: 10
Training loss: 2.5826799325216623
Validation loss: 2.5622282797042137

Epoch: 6| Step: 11
Training loss: 1.7873410934560559
Validation loss: 2.588361284731174

Epoch: 6| Step: 12
Training loss: 2.46240035886607
Validation loss: 2.579988279494888

Epoch: 6| Step: 13
Training loss: 2.5341531564723914
Validation loss: 2.6033734140121476

Epoch: 208| Step: 0
Training loss: 1.9681463375733816
Validation loss: 2.6129839887332738

Epoch: 6| Step: 1
Training loss: 1.8857182916582171
Validation loss: 2.591970962105839

Epoch: 6| Step: 2
Training loss: 1.857022054903843
Validation loss: 2.5799893695437093

Epoch: 6| Step: 3
Training loss: 2.163581877401955
Validation loss: 2.555658487146649

Epoch: 6| Step: 4
Training loss: 2.41740132269515
Validation loss: 2.5048731848185435

Epoch: 6| Step: 5
Training loss: 1.9865103218891584
Validation loss: 2.4940789965179984

Epoch: 6| Step: 6
Training loss: 1.434954088785846
Validation loss: 2.4957014650501215

Epoch: 6| Step: 7
Training loss: 1.8867489514194444
Validation loss: 2.4711586741666003

Epoch: 6| Step: 8
Training loss: 2.088913983449061
Validation loss: 2.4724432445218216

Epoch: 6| Step: 9
Training loss: 2.448374236067948
Validation loss: 2.475473900871542

Epoch: 6| Step: 10
Training loss: 2.051719930263683
Validation loss: 2.4883192404655694

Epoch: 6| Step: 11
Training loss: 2.0778309320030166
Validation loss: 2.515032803065825

Epoch: 6| Step: 12
Training loss: 1.5228844837105402
Validation loss: 2.5450671717862465

Epoch: 6| Step: 13
Training loss: 2.3376673796593868
Validation loss: 2.5309718435072304

Epoch: 209| Step: 0
Training loss: 2.2102803578056154
Validation loss: 2.5674663172471304

Epoch: 6| Step: 1
Training loss: 1.607084403413089
Validation loss: 2.5672529298011857

Epoch: 6| Step: 2
Training loss: 1.918189943071224
Validation loss: 2.585097689565557

Epoch: 6| Step: 3
Training loss: 2.009952577249764
Validation loss: 2.596210021325169

Epoch: 6| Step: 4
Training loss: 2.1855572384067856
Validation loss: 2.601564963557402

Epoch: 6| Step: 5
Training loss: 2.0287203956648687
Validation loss: 2.590468690279367

Epoch: 6| Step: 6
Training loss: 1.9498960736286102
Validation loss: 2.5952615298316517

Epoch: 6| Step: 7
Training loss: 2.1613960226491655
Validation loss: 2.6023143699404794

Epoch: 6| Step: 8
Training loss: 1.9666166705980341
Validation loss: 2.571149385410905

Epoch: 6| Step: 9
Training loss: 1.6184201173204258
Validation loss: 2.5609721149047093

Epoch: 6| Step: 10
Training loss: 2.2382460985868726
Validation loss: 2.54959298620885

Epoch: 6| Step: 11
Training loss: 1.5705083468706342
Validation loss: 2.5356672012159502

Epoch: 6| Step: 12
Training loss: 2.4584196258744693
Validation loss: 2.5276394769447625

Epoch: 6| Step: 13
Training loss: 1.4776270021438427
Validation loss: 2.5165357154569943

Epoch: 210| Step: 0
Training loss: 2.2184385698990017
Validation loss: 2.5313095740029357

Epoch: 6| Step: 1
Training loss: 1.6495811508766813
Validation loss: 2.5508921740021555

Epoch: 6| Step: 2
Training loss: 1.7890367797601918
Validation loss: 2.5247752851627716

Epoch: 6| Step: 3
Training loss: 1.7194663202348917
Validation loss: 2.5429314106426166

Epoch: 6| Step: 4
Training loss: 2.2229830697702373
Validation loss: 2.520525019954787

Epoch: 6| Step: 5
Training loss: 2.3686186741480677
Validation loss: 2.5598743356741265

Epoch: 6| Step: 6
Training loss: 2.2891002040010218
Validation loss: 2.576518457455274

Epoch: 6| Step: 7
Training loss: 1.9865513678936857
Validation loss: 2.569978633147153

Epoch: 6| Step: 8
Training loss: 1.9446875246180686
Validation loss: 2.538424628239891

Epoch: 6| Step: 9
Training loss: 2.169105355559768
Validation loss: 2.5188881543902166

Epoch: 6| Step: 10
Training loss: 1.9726595132630806
Validation loss: 2.507164435248913

Epoch: 6| Step: 11
Training loss: 1.6508711798057512
Validation loss: 2.489809680283743

Epoch: 6| Step: 12
Training loss: 1.6880182247579165
Validation loss: 2.4990808191772214

Epoch: 6| Step: 13
Training loss: 1.9413011242287068
Validation loss: 2.509906489400982

Epoch: 211| Step: 0
Training loss: 1.8538479120244353
Validation loss: 2.500176374305056

Epoch: 6| Step: 1
Training loss: 2.111538152279109
Validation loss: 2.5206947274994795

Epoch: 6| Step: 2
Training loss: 1.8975431117210075
Validation loss: 2.5194956237761996

Epoch: 6| Step: 3
Training loss: 1.454855104290871
Validation loss: 2.5515894244684434

Epoch: 6| Step: 4
Training loss: 1.501418317368567
Validation loss: 2.5852462359643598

Epoch: 6| Step: 5
Training loss: 1.8988490031526155
Validation loss: 2.6015973739013556

Epoch: 6| Step: 6
Training loss: 2.194061139857071
Validation loss: 2.6007849911574406

Epoch: 6| Step: 7
Training loss: 2.1090324971502086
Validation loss: 2.5914910021277007

Epoch: 6| Step: 8
Training loss: 2.0150538381951972
Validation loss: 2.596549846050375

Epoch: 6| Step: 9
Training loss: 1.9890002316589375
Validation loss: 2.580054169485469

Epoch: 6| Step: 10
Training loss: 1.6619121286549303
Validation loss: 2.5709348468047897

Epoch: 6| Step: 11
Training loss: 2.1172631732325016
Validation loss: 2.60302915640055

Epoch: 6| Step: 12
Training loss: 1.7102866132252341
Validation loss: 2.6193487635802746

Epoch: 6| Step: 13
Training loss: 2.3362102030410212
Validation loss: 2.6578653557121688

Epoch: 212| Step: 0
Training loss: 2.1439056873786475
Validation loss: 2.6369925058100114

Epoch: 6| Step: 1
Training loss: 1.6142628341384386
Validation loss: 2.6068562669247854

Epoch: 6| Step: 2
Training loss: 1.5269512638091434
Validation loss: 2.565828150463968

Epoch: 6| Step: 3
Training loss: 2.4459076665947714
Validation loss: 2.5481816761156275

Epoch: 6| Step: 4
Training loss: 2.0324018293745265
Validation loss: 2.542020462106619

Epoch: 6| Step: 5
Training loss: 1.954621984907014
Validation loss: 2.5467367984678315

Epoch: 6| Step: 6
Training loss: 1.2405652663602538
Validation loss: 2.529678379429954

Epoch: 6| Step: 7
Training loss: 2.1476828619625445
Validation loss: 2.5359196665870885

Epoch: 6| Step: 8
Training loss: 2.292324931075463
Validation loss: 2.5351587113466243

Epoch: 6| Step: 9
Training loss: 1.6923207548444301
Validation loss: 2.5501850822658896

Epoch: 6| Step: 10
Training loss: 1.9247072641305862
Validation loss: 2.576895730555768

Epoch: 6| Step: 11
Training loss: 1.8018478577812673
Validation loss: 2.599670508546889

Epoch: 6| Step: 12
Training loss: 1.8758793993862906
Validation loss: 2.600734233084057

Epoch: 6| Step: 13
Training loss: 1.3563141838391293
Validation loss: 2.610751032810599

Epoch: 213| Step: 0
Training loss: 1.9124353460216668
Validation loss: 2.623563409511335

Epoch: 6| Step: 1
Training loss: 1.6766993712970026
Validation loss: 2.6292103013760943

Epoch: 6| Step: 2
Training loss: 1.9610693533897063
Validation loss: 2.6453830350989556

Epoch: 6| Step: 3
Training loss: 2.4005451695825375
Validation loss: 2.646230909187305

Epoch: 6| Step: 4
Training loss: 1.9862797523992586
Validation loss: 2.648717756704179

Epoch: 6| Step: 5
Training loss: 1.4631577211002187
Validation loss: 2.6886072055367616

Epoch: 6| Step: 6
Training loss: 2.0786786023217942
Validation loss: 2.682568717496651

Epoch: 6| Step: 7
Training loss: 1.8237100091933027
Validation loss: 2.656462402344751

Epoch: 6| Step: 8
Training loss: 1.987879264680646
Validation loss: 2.6396825557227976

Epoch: 6| Step: 9
Training loss: 1.6370705019450515
Validation loss: 2.644263124159712

Epoch: 6| Step: 10
Training loss: 1.836498548125439
Validation loss: 2.6078693422110795

Epoch: 6| Step: 11
Training loss: 2.125488898191531
Validation loss: 2.582260759311277

Epoch: 6| Step: 12
Training loss: 1.5499964344845032
Validation loss: 2.5299635514326746

Epoch: 6| Step: 13
Training loss: 1.6805058814379696
Validation loss: 2.53627710165987

Epoch: 214| Step: 0
Training loss: 2.514549641566526
Validation loss: 2.54936727346367

Epoch: 6| Step: 1
Training loss: 2.0412930386754553
Validation loss: 2.556422605427916

Epoch: 6| Step: 2
Training loss: 1.924787841599291
Validation loss: 2.5705030540020846

Epoch: 6| Step: 3
Training loss: 2.216992178896683
Validation loss: 2.5642920574870582

Epoch: 6| Step: 4
Training loss: 1.746323401861511
Validation loss: 2.5861022567595975

Epoch: 6| Step: 5
Training loss: 2.4355820176832603
Validation loss: 2.614577501054596

Epoch: 6| Step: 6
Training loss: 1.6880800168746688
Validation loss: 2.5974696984677643

Epoch: 6| Step: 7
Training loss: 1.3663321735069736
Validation loss: 2.5644893272708726

Epoch: 6| Step: 8
Training loss: 1.5175041269060858
Validation loss: 2.5830722300444733

Epoch: 6| Step: 9
Training loss: 1.809050928587222
Validation loss: 2.5857288224473973

Epoch: 6| Step: 10
Training loss: 1.7243721303055248
Validation loss: 2.614129739997205

Epoch: 6| Step: 11
Training loss: 1.3035766989644328
Validation loss: 2.613872694442698

Epoch: 6| Step: 12
Training loss: 1.879762830992583
Validation loss: 2.6368939828924027

Epoch: 6| Step: 13
Training loss: 1.830303166088698
Validation loss: 2.6496331499830506

Epoch: 215| Step: 0
Training loss: 1.620191355106132
Validation loss: 2.636162718706472

Epoch: 6| Step: 1
Training loss: 1.6671324158625354
Validation loss: 2.613787445397888

Epoch: 6| Step: 2
Training loss: 1.7871330551496358
Validation loss: 2.596839130215533

Epoch: 6| Step: 3
Training loss: 2.1152475626103793
Validation loss: 2.623589355906585

Epoch: 6| Step: 4
Training loss: 1.961265323790574
Validation loss: 2.600001774472561

Epoch: 6| Step: 5
Training loss: 1.1462738519680842
Validation loss: 2.5933570074840904

Epoch: 6| Step: 6
Training loss: 2.0501934844099097
Validation loss: 2.580984836028747

Epoch: 6| Step: 7
Training loss: 1.734026074751323
Validation loss: 2.568318404085315

Epoch: 6| Step: 8
Training loss: 1.9169313068409872
Validation loss: 2.577937134541353

Epoch: 6| Step: 9
Training loss: 2.0447212128073224
Validation loss: 2.5490986075576503

Epoch: 6| Step: 10
Training loss: 1.9634672466175846
Validation loss: 2.55546070771171

Epoch: 6| Step: 11
Training loss: 1.5283889511343987
Validation loss: 2.551490474412513

Epoch: 6| Step: 12
Training loss: 2.124936719961979
Validation loss: 2.597893248436205

Epoch: 6| Step: 13
Training loss: 1.9024023403411598
Validation loss: 2.598494261889859

Epoch: 216| Step: 0
Training loss: 1.6019913262121719
Validation loss: 2.6233618645202497

Epoch: 6| Step: 1
Training loss: 1.8388383390054874
Validation loss: 2.6438388692095773

Epoch: 6| Step: 2
Training loss: 1.1030980763378218
Validation loss: 2.649617174791113

Epoch: 6| Step: 3
Training loss: 2.0589750975427132
Validation loss: 2.647154336725951

Epoch: 6| Step: 4
Training loss: 1.5891292381713207
Validation loss: 2.630543513441796

Epoch: 6| Step: 5
Training loss: 2.048718270410471
Validation loss: 2.6369165713513216

Epoch: 6| Step: 6
Training loss: 2.066041506790699
Validation loss: 2.6251546430376216

Epoch: 6| Step: 7
Training loss: 1.9326345819786308
Validation loss: 2.604181227776621

Epoch: 6| Step: 8
Training loss: 2.153760938478258
Validation loss: 2.609767883012867

Epoch: 6| Step: 9
Training loss: 1.7001169220602261
Validation loss: 2.5772063417490414

Epoch: 6| Step: 10
Training loss: 1.9817571117378905
Validation loss: 2.5604693322499275

Epoch: 6| Step: 11
Training loss: 2.0691007702838236
Validation loss: 2.576707548628423

Epoch: 6| Step: 12
Training loss: 1.5257742932889122
Validation loss: 2.555218693080917

Epoch: 6| Step: 13
Training loss: 1.5912374999700816
Validation loss: 2.574518108307207

Epoch: 217| Step: 0
Training loss: 1.8656942230110634
Validation loss: 2.595050098485587

Epoch: 6| Step: 1
Training loss: 1.9217789168491706
Validation loss: 2.605640740057481

Epoch: 6| Step: 2
Training loss: 2.187170167307354
Validation loss: 2.578600546096555

Epoch: 6| Step: 3
Training loss: 2.047880668233196
Validation loss: 2.5655187517988383

Epoch: 6| Step: 4
Training loss: 1.7405384966793616
Validation loss: 2.5786742598861316

Epoch: 6| Step: 5
Training loss: 2.011797205311781
Validation loss: 2.5726830875193984

Epoch: 6| Step: 6
Training loss: 1.4981367141462996
Validation loss: 2.5652344982833553

Epoch: 6| Step: 7
Training loss: 2.028074158676359
Validation loss: 2.5801398306148076

Epoch: 6| Step: 8
Training loss: 2.0347089220927996
Validation loss: 2.5765060139320712

Epoch: 6| Step: 9
Training loss: 1.1407058373638381
Validation loss: 2.604987494939967

Epoch: 6| Step: 10
Training loss: 1.3913831037409259
Validation loss: 2.648133960138035

Epoch: 6| Step: 11
Training loss: 1.8027423102141173
Validation loss: 2.6257343798273336

Epoch: 6| Step: 12
Training loss: 1.7327491769322245
Validation loss: 2.6073345626131466

Epoch: 6| Step: 13
Training loss: 1.7378445537528444
Validation loss: 2.6489689038201556

Epoch: 218| Step: 0
Training loss: 1.8870172047358864
Validation loss: 2.6409346642920544

Epoch: 6| Step: 1
Training loss: 1.6769848749232759
Validation loss: 2.662255331206917

Epoch: 6| Step: 2
Training loss: 1.8876745358037619
Validation loss: 2.630905409559073

Epoch: 6| Step: 3
Training loss: 1.3947266941260135
Validation loss: 2.641291326092145

Epoch: 6| Step: 4
Training loss: 1.498769732449579
Validation loss: 2.6508141156927785

Epoch: 6| Step: 5
Training loss: 1.7516457448569513
Validation loss: 2.6398438426072866

Epoch: 6| Step: 6
Training loss: 1.5330277846842475
Validation loss: 2.620024089736928

Epoch: 6| Step: 7
Training loss: 1.9796232265766283
Validation loss: 2.628952500138636

Epoch: 6| Step: 8
Training loss: 1.9995927992184201
Validation loss: 2.6242670284979437

Epoch: 6| Step: 9
Training loss: 1.4094141648088638
Validation loss: 2.6273320143291983

Epoch: 6| Step: 10
Training loss: 2.1145956355396325
Validation loss: 2.6384768358796853

Epoch: 6| Step: 11
Training loss: 1.801265560403254
Validation loss: 2.635541951258761

Epoch: 6| Step: 12
Training loss: 1.8541130172454414
Validation loss: 2.639383930072314

Epoch: 6| Step: 13
Training loss: 2.0098939786060397
Validation loss: 2.6172290556878837

Epoch: 219| Step: 0
Training loss: 1.625755501231143
Validation loss: 2.6254728460759953

Epoch: 6| Step: 1
Training loss: 2.1583933474568977
Validation loss: 2.632641799148179

Epoch: 6| Step: 2
Training loss: 1.7927847042658551
Validation loss: 2.6446922256766334

Epoch: 6| Step: 3
Training loss: 2.0119932117082207
Validation loss: 2.6563174543797645

Epoch: 6| Step: 4
Training loss: 1.5439488641938117
Validation loss: 2.665253605796454

Epoch: 6| Step: 5
Training loss: 1.8453597460842863
Validation loss: 2.6622201671111125

Epoch: 6| Step: 6
Training loss: 1.9350362926105786
Validation loss: 2.647101955570451

Epoch: 6| Step: 7
Training loss: 2.1876083347197355
Validation loss: 2.636109415044101

Epoch: 6| Step: 8
Training loss: 1.03517242994799
Validation loss: 2.6464059433108584

Epoch: 6| Step: 9
Training loss: 1.4921104850667044
Validation loss: 2.6289149436605195

Epoch: 6| Step: 10
Training loss: 1.7226096079906636
Validation loss: 2.6574512774136534

Epoch: 6| Step: 11
Training loss: 1.3395064126687444
Validation loss: 2.625709527649576

Epoch: 6| Step: 12
Training loss: 1.6176681172943266
Validation loss: 2.6329365284772797

Epoch: 6| Step: 13
Training loss: 1.6029230061184165
Validation loss: 2.625690802929687

Epoch: 220| Step: 0
Training loss: 1.4718444367493428
Validation loss: 2.619474298619671

Epoch: 6| Step: 1
Training loss: 1.3877231882343795
Validation loss: 2.6044687513474054

Epoch: 6| Step: 2
Training loss: 2.0415650426783682
Validation loss: 2.5937369344189243

Epoch: 6| Step: 3
Training loss: 1.8461009409244207
Validation loss: 2.565610434992547

Epoch: 6| Step: 4
Training loss: 1.8916387441089568
Validation loss: 2.5839246006418466

Epoch: 6| Step: 5
Training loss: 1.7073415653120174
Validation loss: 2.6160178384386557

Epoch: 6| Step: 6
Training loss: 1.5909551161759408
Validation loss: 2.605214001790208

Epoch: 6| Step: 7
Training loss: 2.1474702634517824
Validation loss: 2.6148770562050485

Epoch: 6| Step: 8
Training loss: 2.095662510345902
Validation loss: 2.6229851417765113

Epoch: 6| Step: 9
Training loss: 1.6277687254051119
Validation loss: 2.6328338712736103

Epoch: 6| Step: 10
Training loss: 1.7353734072467937
Validation loss: 2.6338349650655957

Epoch: 6| Step: 11
Training loss: 1.4080087472037055
Validation loss: 2.667871947575693

Epoch: 6| Step: 12
Training loss: 1.115919286984678
Validation loss: 2.674572385985096

Epoch: 6| Step: 13
Training loss: 1.6762288525048865
Validation loss: 2.671001071438619

Epoch: 221| Step: 0
Training loss: 1.1064754256403897
Validation loss: 2.703388886685914

Epoch: 6| Step: 1
Training loss: 1.8787584782026494
Validation loss: 2.7411106433986587

Epoch: 6| Step: 2
Training loss: 1.635503641071424
Validation loss: 2.6862956737650054

Epoch: 6| Step: 3
Training loss: 2.054987780309576
Validation loss: 2.616706723418082

Epoch: 6| Step: 4
Training loss: 1.600695938510524
Validation loss: 2.578663092350137

Epoch: 6| Step: 5
Training loss: 1.8562782208387838
Validation loss: 2.5687715911177396

Epoch: 6| Step: 6
Training loss: 2.3440531216743885
Validation loss: 2.5450685769663295

Epoch: 6| Step: 7
Training loss: 1.657763671155903
Validation loss: 2.526137298779829

Epoch: 6| Step: 8
Training loss: 1.5754160528308743
Validation loss: 2.5353863755764

Epoch: 6| Step: 9
Training loss: 1.674929244411656
Validation loss: 2.550803589961339

Epoch: 6| Step: 10
Training loss: 1.5466326899468745
Validation loss: 2.5259821991453406

Epoch: 6| Step: 11
Training loss: 1.2536990746208598
Validation loss: 2.5492449223401796

Epoch: 6| Step: 12
Training loss: 1.858000752349307
Validation loss: 2.5563762815828004

Epoch: 6| Step: 13
Training loss: 1.6114561087903887
Validation loss: 2.5923140151363793

Epoch: 222| Step: 0
Training loss: 1.7812897527173917
Validation loss: 2.681719546178481

Epoch: 6| Step: 1
Training loss: 2.048883282816277
Validation loss: 2.7206447242788157

Epoch: 6| Step: 2
Training loss: 1.5414466786870942
Validation loss: 2.701866426420253

Epoch: 6| Step: 3
Training loss: 1.9146363935565547
Validation loss: 2.6495863929341277

Epoch: 6| Step: 4
Training loss: 1.8099139608303265
Validation loss: 2.6398421101046585

Epoch: 6| Step: 5
Training loss: 1.3199469156139414
Validation loss: 2.606330541247237

Epoch: 6| Step: 6
Training loss: 1.7123320309202887
Validation loss: 2.5832816531291076

Epoch: 6| Step: 7
Training loss: 1.8057073708638105
Validation loss: 2.5632544516631945

Epoch: 6| Step: 8
Training loss: 1.6930015036209558
Validation loss: 2.5236990157642176

Epoch: 6| Step: 9
Training loss: 1.7861799981593638
Validation loss: 2.5207446564186373

Epoch: 6| Step: 10
Training loss: 2.093539099248688
Validation loss: 2.531960027606986

Epoch: 6| Step: 11
Training loss: 1.3820031162673994
Validation loss: 2.5192072569807427

Epoch: 6| Step: 12
Training loss: 1.4542769101535098
Validation loss: 2.556360152829492

Epoch: 6| Step: 13
Training loss: 1.580231723934995
Validation loss: 2.5742839461580864

Epoch: 223| Step: 0
Training loss: 1.5490794801656762
Validation loss: 2.60569179117905

Epoch: 6| Step: 1
Training loss: 1.4092454161353727
Validation loss: 2.6212197833987374

Epoch: 6| Step: 2
Training loss: 1.3140516192227276
Validation loss: 2.6713924964165754

Epoch: 6| Step: 3
Training loss: 1.2953812602789232
Validation loss: 2.7100634405677

Epoch: 6| Step: 4
Training loss: 2.064185407561431
Validation loss: 2.7361591093650115

Epoch: 6| Step: 5
Training loss: 1.5308150627417862
Validation loss: 2.690885610537337

Epoch: 6| Step: 6
Training loss: 2.117967074965909
Validation loss: 2.712933514689945

Epoch: 6| Step: 7
Training loss: 2.1117564004300022
Validation loss: 2.6920987356717947

Epoch: 6| Step: 8
Training loss: 1.8360704089815485
Validation loss: 2.6741067675592034

Epoch: 6| Step: 9
Training loss: 1.1958398590618722
Validation loss: 2.6360404107237905

Epoch: 6| Step: 10
Training loss: 1.5217234823950634
Validation loss: 2.588850959137797

Epoch: 6| Step: 11
Training loss: 1.62770632817397
Validation loss: 2.58523619556222

Epoch: 6| Step: 12
Training loss: 1.5003307295813881
Validation loss: 2.5771853507386884

Epoch: 6| Step: 13
Training loss: 2.131423330110631
Validation loss: 2.5745538514008484

Epoch: 224| Step: 0
Training loss: 1.8730182347181434
Validation loss: 2.5712774072460696

Epoch: 6| Step: 1
Training loss: 1.5234966560029106
Validation loss: 2.5709323678568303

Epoch: 6| Step: 2
Training loss: 1.6767706095718709
Validation loss: 2.5882731282895333

Epoch: 6| Step: 3
Training loss: 1.8578628674377724
Validation loss: 2.565413834514086

Epoch: 6| Step: 4
Training loss: 1.6818288948036553
Validation loss: 2.5858471006404913

Epoch: 6| Step: 5
Training loss: 1.2521379783668376
Validation loss: 2.5575353348749847

Epoch: 6| Step: 6
Training loss: 1.2278669188050126
Validation loss: 2.5597697473877834

Epoch: 6| Step: 7
Training loss: 1.502442437718
Validation loss: 2.5721039378736568

Epoch: 6| Step: 8
Training loss: 1.6206529868372521
Validation loss: 2.6210599013502374

Epoch: 6| Step: 9
Training loss: 1.6421039999250426
Validation loss: 2.6300911107964358

Epoch: 6| Step: 10
Training loss: 1.926422940758256
Validation loss: 2.6586727156630405

Epoch: 6| Step: 11
Training loss: 1.8765787471731745
Validation loss: 2.6586886624779416

Epoch: 6| Step: 12
Training loss: 1.437777119337819
Validation loss: 2.6694290987402254

Epoch: 6| Step: 13
Training loss: 1.8721404841031608
Validation loss: 2.690871100685267

Epoch: 225| Step: 0
Training loss: 1.4422470163151477
Validation loss: 2.675764349229943

Epoch: 6| Step: 1
Training loss: 1.3286143579447125
Validation loss: 2.689516067289644

Epoch: 6| Step: 2
Training loss: 1.3059240637254852
Validation loss: 2.655772598285011

Epoch: 6| Step: 3
Training loss: 2.041734720250698
Validation loss: 2.6682452527284517

Epoch: 6| Step: 4
Training loss: 1.5722436370259862
Validation loss: 2.664202717138043

Epoch: 6| Step: 5
Training loss: 0.9787058692912046
Validation loss: 2.621037656484197

Epoch: 6| Step: 6
Training loss: 1.099425766354501
Validation loss: 2.632198198416802

Epoch: 6| Step: 7
Training loss: 1.8121740771627188
Validation loss: 2.6344410104706526

Epoch: 6| Step: 8
Training loss: 1.9105632325016
Validation loss: 2.6152168927734185

Epoch: 6| Step: 9
Training loss: 1.4346650405884027
Validation loss: 2.6020553010277405

Epoch: 6| Step: 10
Training loss: 2.298349335494661
Validation loss: 2.6074394104734213

Epoch: 6| Step: 11
Training loss: 1.7063179533565183
Validation loss: 2.626016888637005

Epoch: 6| Step: 12
Training loss: 1.6571783666846391
Validation loss: 2.6173124902761526

Epoch: 6| Step: 13
Training loss: 1.6498150606259443
Validation loss: 2.6304196547677594

Epoch: 226| Step: 0
Training loss: 1.4578493495916292
Validation loss: 2.6301764873833537

Epoch: 6| Step: 1
Training loss: 1.78522957081545
Validation loss: 2.6081456130170775

Epoch: 6| Step: 2
Training loss: 0.9847763999098306
Validation loss: 2.6376084006095253

Epoch: 6| Step: 3
Training loss: 1.0556484224782408
Validation loss: 2.6043559704958015

Epoch: 6| Step: 4
Training loss: 1.7820868283192104
Validation loss: 2.5904196470392655

Epoch: 6| Step: 5
Training loss: 1.4628484131614308
Validation loss: 2.600747990982598

Epoch: 6| Step: 6
Training loss: 1.7912810450310688
Validation loss: 2.6216965822000007

Epoch: 6| Step: 7
Training loss: 1.7706076609108927
Validation loss: 2.5906147743725

Epoch: 6| Step: 8
Training loss: 1.8598707163394967
Validation loss: 2.575639237235431

Epoch: 6| Step: 9
Training loss: 1.5774416057582057
Validation loss: 2.625276508993602

Epoch: 6| Step: 10
Training loss: 1.5338759968558309
Validation loss: 2.6270470838405844

Epoch: 6| Step: 11
Training loss: 1.7103037596719188
Validation loss: 2.645668643486112

Epoch: 6| Step: 12
Training loss: 1.7561047205449518
Validation loss: 2.6544691549937673

Epoch: 6| Step: 13
Training loss: 1.7177512995348987
Validation loss: 2.6261870771114455

Epoch: 227| Step: 0
Training loss: 1.1070777317968317
Validation loss: 2.6386441211347975

Epoch: 6| Step: 1
Training loss: 1.915845079832611
Validation loss: 2.6208676354259257

Epoch: 6| Step: 2
Training loss: 1.303807767208187
Validation loss: 2.614831834106223

Epoch: 6| Step: 3
Training loss: 1.8269809501377232
Validation loss: 2.5930328840624695

Epoch: 6| Step: 4
Training loss: 1.72766899452639
Validation loss: 2.587416972617154

Epoch: 6| Step: 5
Training loss: 1.5254040667421522
Validation loss: 2.6116225248259406

Epoch: 6| Step: 6
Training loss: 1.2099217246092395
Validation loss: 2.6170776422494053

Epoch: 6| Step: 7
Training loss: 1.760893973326228
Validation loss: 2.5923486000831573

Epoch: 6| Step: 8
Training loss: 1.2693751312511232
Validation loss: 2.6377210431030877

Epoch: 6| Step: 9
Training loss: 1.4314253620512014
Validation loss: 2.642341480634343

Epoch: 6| Step: 10
Training loss: 1.4475751332234552
Validation loss: 2.6655959285678104

Epoch: 6| Step: 11
Training loss: 1.6911984639798698
Validation loss: 2.674049564763962

Epoch: 6| Step: 12
Training loss: 1.9647224039939737
Validation loss: 2.6921084651325664

Epoch: 6| Step: 13
Training loss: 1.7018475422516175
Validation loss: 2.645669669651998

Epoch: 228| Step: 0
Training loss: 0.8700168949986016
Validation loss: 2.6460541263304096

Epoch: 6| Step: 1
Training loss: 0.8149170869063624
Validation loss: 2.6302369903949443

Epoch: 6| Step: 2
Training loss: 1.8820596669839909
Validation loss: 2.624879853819089

Epoch: 6| Step: 3
Training loss: 1.2732566751918937
Validation loss: 2.592007976796012

Epoch: 6| Step: 4
Training loss: 1.9845573762003337
Validation loss: 2.5853369597658586

Epoch: 6| Step: 5
Training loss: 1.6901844007572762
Validation loss: 2.5962113978371106

Epoch: 6| Step: 6
Training loss: 1.4519244741548722
Validation loss: 2.593527179294183

Epoch: 6| Step: 7
Training loss: 1.3611101498676115
Validation loss: 2.545907327006229

Epoch: 6| Step: 8
Training loss: 1.6507302922238403
Validation loss: 2.554522352928995

Epoch: 6| Step: 9
Training loss: 1.576750959733266
Validation loss: 2.556289018829168

Epoch: 6| Step: 10
Training loss: 1.6897947462139522
Validation loss: 2.5684092806559042

Epoch: 6| Step: 11
Training loss: 2.046370931977254
Validation loss: 2.592668378224111

Epoch: 6| Step: 12
Training loss: 1.3829122819837707
Validation loss: 2.5869952283692896

Epoch: 6| Step: 13
Training loss: 1.6774844604090795
Validation loss: 2.5990593608817267

Epoch: 229| Step: 0
Training loss: 1.0694139704690486
Validation loss: 2.6417508648326664

Epoch: 6| Step: 1
Training loss: 1.426570558890803
Validation loss: 2.6466125382173993

Epoch: 6| Step: 2
Training loss: 1.2566985890375484
Validation loss: 2.6324076535550502

Epoch: 6| Step: 3
Training loss: 0.869433612945601
Validation loss: 2.6487768731799153

Epoch: 6| Step: 4
Training loss: 1.6898729100491314
Validation loss: 2.647753127461984

Epoch: 6| Step: 5
Training loss: 1.4930692933310599
Validation loss: 2.6423967949511287

Epoch: 6| Step: 6
Training loss: 1.7891132730667239
Validation loss: 2.621798469838168

Epoch: 6| Step: 7
Training loss: 1.6866080434635669
Validation loss: 2.6180539901521414

Epoch: 6| Step: 8
Training loss: 1.6067815828710854
Validation loss: 2.580766729342236

Epoch: 6| Step: 9
Training loss: 1.5085321003877878
Validation loss: 2.5758660844862877

Epoch: 6| Step: 10
Training loss: 1.8400394149373402
Validation loss: 2.5521927716964297

Epoch: 6| Step: 11
Training loss: 1.6867124344467654
Validation loss: 2.5253619505107516

Epoch: 6| Step: 12
Training loss: 1.8183769446486033
Validation loss: 2.5343840427732256

Epoch: 6| Step: 13
Training loss: 1.6250988856819233
Validation loss: 2.5454262199312083

Epoch: 230| Step: 0
Training loss: 1.5361083672015927
Validation loss: 2.5789047717619824

Epoch: 6| Step: 1
Training loss: 1.63766634147191
Validation loss: 2.6187639000006095

Epoch: 6| Step: 2
Training loss: 1.5283507322751368
Validation loss: 2.622752853387045

Epoch: 6| Step: 3
Training loss: 1.8399568753786524
Validation loss: 2.661938024788606

Epoch: 6| Step: 4
Training loss: 1.6822664556198752
Validation loss: 2.6542923587027

Epoch: 6| Step: 5
Training loss: 1.3674442595117742
Validation loss: 2.6497471717995302

Epoch: 6| Step: 6
Training loss: 1.3994640652866677
Validation loss: 2.694230192249213

Epoch: 6| Step: 7
Training loss: 1.6082641323138154
Validation loss: 2.6680673341916252

Epoch: 6| Step: 8
Training loss: 1.6886520691662517
Validation loss: 2.681141743137111

Epoch: 6| Step: 9
Training loss: 2.0579821494230095
Validation loss: 2.617324792685906

Epoch: 6| Step: 10
Training loss: 0.8478429210813875
Validation loss: 2.5980819102970907

Epoch: 6| Step: 11
Training loss: 1.4358072680503913
Validation loss: 2.5805066803788104

Epoch: 6| Step: 12
Training loss: 1.2481892822399598
Validation loss: 2.5516265246010073

Epoch: 6| Step: 13
Training loss: 1.2932066914570244
Validation loss: 2.5248088528362485

Epoch: 231| Step: 0
Training loss: 1.7604966756783333
Validation loss: 2.538015740809352

Epoch: 6| Step: 1
Training loss: 1.5790328634271547
Validation loss: 2.5412607405106757

Epoch: 6| Step: 2
Training loss: 1.511402027948848
Validation loss: 2.57320404407405

Epoch: 6| Step: 3
Training loss: 1.763662479751588
Validation loss: 2.587044420757991

Epoch: 6| Step: 4
Training loss: 1.4199280876433036
Validation loss: 2.5893141919484592

Epoch: 6| Step: 5
Training loss: 1.5566673515830212
Validation loss: 2.641988890502726

Epoch: 6| Step: 6
Training loss: 1.7936895247310112
Validation loss: 2.6491222705705484

Epoch: 6| Step: 7
Training loss: 1.3993112402527819
Validation loss: 2.657105240499574

Epoch: 6| Step: 8
Training loss: 1.2707846220509493
Validation loss: 2.6475202698928855

Epoch: 6| Step: 9
Training loss: 0.996150355507128
Validation loss: 2.6447669501135715

Epoch: 6| Step: 10
Training loss: 1.4683275629825776
Validation loss: 2.6509165988299923

Epoch: 6| Step: 11
Training loss: 1.3991681965737597
Validation loss: 2.625532635327387

Epoch: 6| Step: 12
Training loss: 1.661429027271009
Validation loss: 2.6157674140750737

Epoch: 6| Step: 13
Training loss: 1.5370828512343886
Validation loss: 2.604889941444286

Epoch: 232| Step: 0
Training loss: 1.443622735429567
Validation loss: 2.564690203900834

Epoch: 6| Step: 1
Training loss: 1.5722807889408497
Validation loss: 2.5885845273295796

Epoch: 6| Step: 2
Training loss: 1.3976281237344281
Validation loss: 2.578483212104157

Epoch: 6| Step: 3
Training loss: 1.2892789716736741
Validation loss: 2.58943931881297

Epoch: 6| Step: 4
Training loss: 1.6842474498120774
Validation loss: 2.6142997834708406

Epoch: 6| Step: 5
Training loss: 1.0873805824572378
Validation loss: 2.610508337186298

Epoch: 6| Step: 6
Training loss: 1.6903636793871633
Validation loss: 2.608867317590599

Epoch: 6| Step: 7
Training loss: 1.7543790388179723
Validation loss: 2.6380348295491958

Epoch: 6| Step: 8
Training loss: 1.7777748339681625
Validation loss: 2.6081594566532256

Epoch: 6| Step: 9
Training loss: 0.9832006443069681
Validation loss: 2.657081142929827

Epoch: 6| Step: 10
Training loss: 1.3827178405431806
Validation loss: 2.6394459431335204

Epoch: 6| Step: 11
Training loss: 1.7036887819370774
Validation loss: 2.6504933053840705

Epoch: 6| Step: 12
Training loss: 1.4674174168239806
Validation loss: 2.6746819295649615

Epoch: 6| Step: 13
Training loss: 1.7497279091890454
Validation loss: 2.650894737962872

Epoch: 233| Step: 0
Training loss: 1.7454546072266308
Validation loss: 2.649916808497517

Epoch: 6| Step: 1
Training loss: 1.2213389457399468
Validation loss: 2.6089047185063743

Epoch: 6| Step: 2
Training loss: 1.3806533767733502
Validation loss: 2.6246361380196865

Epoch: 6| Step: 3
Training loss: 1.6825003558494338
Validation loss: 2.570487842675024

Epoch: 6| Step: 4
Training loss: 1.8092320677282503
Validation loss: 2.6083115165521695

Epoch: 6| Step: 5
Training loss: 1.5252111038678202
Validation loss: 2.55131263338131

Epoch: 6| Step: 6
Training loss: 1.4834511542229263
Validation loss: 2.5968375373423416

Epoch: 6| Step: 7
Training loss: 1.6927748290474696
Validation loss: 2.5799321378800766

Epoch: 6| Step: 8
Training loss: 1.6511669973784637
Validation loss: 2.5881017928243386

Epoch: 6| Step: 9
Training loss: 1.1958391114116376
Validation loss: 2.5847360092297067

Epoch: 6| Step: 10
Training loss: 1.0765729042735297
Validation loss: 2.6032009319363514

Epoch: 6| Step: 11
Training loss: 1.411298970402534
Validation loss: 2.596563287962589

Epoch: 6| Step: 12
Training loss: 1.2632739989875295
Validation loss: 2.5942606338688607

Epoch: 6| Step: 13
Training loss: 1.2629685486134175
Validation loss: 2.605615113764754

Epoch: 234| Step: 0
Training loss: 1.6999581668418935
Validation loss: 2.6152810933587496

Epoch: 6| Step: 1
Training loss: 1.2274007666230042
Validation loss: 2.5968707125379478

Epoch: 6| Step: 2
Training loss: 1.522609622685701
Validation loss: 2.591634839500882

Epoch: 6| Step: 3
Training loss: 1.3019715324723533
Validation loss: 2.5838643377439547

Epoch: 6| Step: 4
Training loss: 1.1375329945568367
Validation loss: 2.597610162102079

Epoch: 6| Step: 5
Training loss: 1.5785317982517935
Validation loss: 2.6307208776635256

Epoch: 6| Step: 6
Training loss: 1.5618945665419957
Validation loss: 2.6173949065021773

Epoch: 6| Step: 7
Training loss: 1.4117114929789565
Validation loss: 2.624309167622278

Epoch: 6| Step: 8
Training loss: 1.4337845761055252
Validation loss: 2.634354408699552

Epoch: 6| Step: 9
Training loss: 1.9873738494760307
Validation loss: 2.643357988474886

Epoch: 6| Step: 10
Training loss: 1.6543072516646224
Validation loss: 2.659870536581085

Epoch: 6| Step: 11
Training loss: 1.1149594156722438
Validation loss: 2.663484505791863

Epoch: 6| Step: 12
Training loss: 1.2576154471579528
Validation loss: 2.6435146046530043

Epoch: 6| Step: 13
Training loss: 1.0423732014485132
Validation loss: 2.634767637173971

Epoch: 235| Step: 0
Training loss: 1.121998704130951
Validation loss: 2.642431719806434

Epoch: 6| Step: 1
Training loss: 1.805748301594366
Validation loss: 2.6214232416699557

Epoch: 6| Step: 2
Training loss: 1.565936086970331
Validation loss: 2.628446300221976

Epoch: 6| Step: 3
Training loss: 1.2450463368322382
Validation loss: 2.625855103935416

Epoch: 6| Step: 4
Training loss: 1.1071615030766553
Validation loss: 2.6048665428242956

Epoch: 6| Step: 5
Training loss: 1.1589988818159132
Validation loss: 2.5998145481416817

Epoch: 6| Step: 6
Training loss: 1.4067362898203755
Validation loss: 2.6149167584169732

Epoch: 6| Step: 7
Training loss: 1.1576241240881682
Validation loss: 2.6121788432374022

Epoch: 6| Step: 8
Training loss: 1.0007878418704585
Validation loss: 2.637280778435323

Epoch: 6| Step: 9
Training loss: 1.7424054886131608
Validation loss: 2.63599017688546

Epoch: 6| Step: 10
Training loss: 1.3194317108789115
Validation loss: 2.6166193970433507

Epoch: 6| Step: 11
Training loss: 1.4311360176376018
Validation loss: 2.621019743473706

Epoch: 6| Step: 12
Training loss: 1.9403333558436078
Validation loss: 2.616006180101189

Epoch: 6| Step: 13
Training loss: 1.9831925120435079
Validation loss: 2.5946889473341113

Epoch: 236| Step: 0
Training loss: 1.089034788635682
Validation loss: 2.5828821408140294

Epoch: 6| Step: 1
Training loss: 1.5120513313602197
Validation loss: 2.59764560225725

Epoch: 6| Step: 2
Training loss: 1.5251167627879245
Validation loss: 2.5959277745496308

Epoch: 6| Step: 3
Training loss: 1.6691303005564293
Validation loss: 2.5994798559243972

Epoch: 6| Step: 4
Training loss: 1.6026480368617317
Validation loss: 2.577185279117092

Epoch: 6| Step: 5
Training loss: 1.0089276671857677
Validation loss: 2.5826050981987856

Epoch: 6| Step: 6
Training loss: 1.691073907000696
Validation loss: 2.600481557867511

Epoch: 6| Step: 7
Training loss: 1.55183739815186
Validation loss: 2.595944805007171

Epoch: 6| Step: 8
Training loss: 1.4913629780362259
Validation loss: 2.583505542055238

Epoch: 6| Step: 9
Training loss: 1.3605717619756312
Validation loss: 2.6138414023892462

Epoch: 6| Step: 10
Training loss: 1.2165315439796696
Validation loss: 2.606124625893008

Epoch: 6| Step: 11
Training loss: 1.382752153189746
Validation loss: 2.60818359929132

Epoch: 6| Step: 12
Training loss: 1.4516847918255205
Validation loss: 2.6555276070588003

Epoch: 6| Step: 13
Training loss: 1.1086903998387927
Validation loss: 2.651589206502545

Epoch: 237| Step: 0
Training loss: 1.6716329096272753
Validation loss: 2.664003852639194

Epoch: 6| Step: 1
Training loss: 1.3743115348786508
Validation loss: 2.6496858313443554

Epoch: 6| Step: 2
Training loss: 1.1951243931976556
Validation loss: 2.662224256845519

Epoch: 6| Step: 3
Training loss: 1.2531648149134642
Validation loss: 2.6798431371377665

Epoch: 6| Step: 4
Training loss: 1.3003447662362013
Validation loss: 2.6998400578511283

Epoch: 6| Step: 5
Training loss: 1.759172515329348
Validation loss: 2.666238081879821

Epoch: 6| Step: 6
Training loss: 1.1241977798382985
Validation loss: 2.6647623954479966

Epoch: 6| Step: 7
Training loss: 1.227867646953473
Validation loss: 2.615264353501854

Epoch: 6| Step: 8
Training loss: 1.8963931029304777
Validation loss: 2.6003054168100435

Epoch: 6| Step: 9
Training loss: 1.0127441041351513
Validation loss: 2.557897330408446

Epoch: 6| Step: 10
Training loss: 1.5796908928507394
Validation loss: 2.5804281845963404

Epoch: 6| Step: 11
Training loss: 1.2223976519906625
Validation loss: 2.549096874727738

Epoch: 6| Step: 12
Training loss: 1.33972363169882
Validation loss: 2.5676318388982406

Epoch: 6| Step: 13
Training loss: 1.6333700441918935
Validation loss: 2.5396245458351046

Epoch: 238| Step: 0
Training loss: 1.4388267365381766
Validation loss: 2.5610160542651053

Epoch: 6| Step: 1
Training loss: 1.2255040357967617
Validation loss: 2.5751196643404266

Epoch: 6| Step: 2
Training loss: 1.4261672242171584
Validation loss: 2.58136718574573

Epoch: 6| Step: 3
Training loss: 1.2825563330668674
Validation loss: 2.605538758787433

Epoch: 6| Step: 4
Training loss: 1.6647247286229105
Validation loss: 2.630058482330224

Epoch: 6| Step: 5
Training loss: 1.7738802857028912
Validation loss: 2.674403839643333

Epoch: 6| Step: 6
Training loss: 1.1539134568368377
Validation loss: 2.6398187639381727

Epoch: 6| Step: 7
Training loss: 1.468046141447601
Validation loss: 2.6950652805855206

Epoch: 6| Step: 8
Training loss: 1.3773406653496816
Validation loss: 2.681895020967015

Epoch: 6| Step: 9
Training loss: 1.1118832024909115
Validation loss: 2.677684737610435

Epoch: 6| Step: 10
Training loss: 1.114367681063132
Validation loss: 2.6972007430306775

Epoch: 6| Step: 11
Training loss: 1.834447572692498
Validation loss: 2.6511303123118455

Epoch: 6| Step: 12
Training loss: 1.0039368858561133
Validation loss: 2.6222256396282786

Epoch: 6| Step: 13
Training loss: 1.6689960255515544
Validation loss: 2.6091973117325904

Epoch: 239| Step: 0
Training loss: 1.1305952801443766
Validation loss: 2.582654330531199

Epoch: 6| Step: 1
Training loss: 1.4332035375570067
Validation loss: 2.5709183038204233

Epoch: 6| Step: 2
Training loss: 1.4180946819617006
Validation loss: 2.58840020612488

Epoch: 6| Step: 3
Training loss: 1.5244517544687601
Validation loss: 2.563903642259257

Epoch: 6| Step: 4
Training loss: 1.1004248080565706
Validation loss: 2.550016182211341

Epoch: 6| Step: 5
Training loss: 1.5512949671594622
Validation loss: 2.5906044658164395

Epoch: 6| Step: 6
Training loss: 1.1254736644929384
Validation loss: 2.6123055471810464

Epoch: 6| Step: 7
Training loss: 1.7458906290246923
Validation loss: 2.639870245651252

Epoch: 6| Step: 8
Training loss: 1.3146844578139478
Validation loss: 2.6309342019431408

Epoch: 6| Step: 9
Training loss: 0.9950342864450309
Validation loss: 2.636383986769844

Epoch: 6| Step: 10
Training loss: 1.4618056058946582
Validation loss: 2.679808876830627

Epoch: 6| Step: 11
Training loss: 1.7351498634189928
Validation loss: 2.6645699188821723

Epoch: 6| Step: 12
Training loss: 1.3403075724942757
Validation loss: 2.63763999969809

Epoch: 6| Step: 13
Training loss: 1.6625516955146955
Validation loss: 2.594600322143978

Epoch: 240| Step: 0
Training loss: 0.838708047570912
Validation loss: 2.5853443264106883

Epoch: 6| Step: 1
Training loss: 1.3124567660522566
Validation loss: 2.5927349060753815

Epoch: 6| Step: 2
Training loss: 1.5832106726800874
Validation loss: 2.5970565884636456

Epoch: 6| Step: 3
Training loss: 1.6732722353071263
Validation loss: 2.6045260319658463

Epoch: 6| Step: 4
Training loss: 1.3386270765473156
Validation loss: 2.570756821151892

Epoch: 6| Step: 5
Training loss: 1.5505080282673274
Validation loss: 2.562582397336726

Epoch: 6| Step: 6
Training loss: 1.6610837252998583
Validation loss: 2.5755383295276393

Epoch: 6| Step: 7
Training loss: 0.8264698185726477
Validation loss: 2.630542140276676

Epoch: 6| Step: 8
Training loss: 1.069373616987412
Validation loss: 2.647550788184717

Epoch: 6| Step: 9
Training loss: 1.5752499518286245
Validation loss: 2.611857983103289

Epoch: 6| Step: 10
Training loss: 1.2503041850955046
Validation loss: 2.593322095922809

Epoch: 6| Step: 11
Training loss: 1.3224536756395842
Validation loss: 2.609679745347169

Epoch: 6| Step: 12
Training loss: 1.5417562235345823
Validation loss: 2.57212431153349

Epoch: 6| Step: 13
Training loss: 1.531265959364576
Validation loss: 2.581903065344862

Epoch: 241| Step: 0
Training loss: 1.6912425889263754
Validation loss: 2.591332168710073

Epoch: 6| Step: 1
Training loss: 1.3650399916942215
Validation loss: 2.622828877306444

Epoch: 6| Step: 2
Training loss: 1.3413989325153273
Validation loss: 2.637287705448679

Epoch: 6| Step: 3
Training loss: 1.596290956358613
Validation loss: 2.6351262335077994

Epoch: 6| Step: 4
Training loss: 1.414269785151426
Validation loss: 2.6382365022830436

Epoch: 6| Step: 5
Training loss: 1.0945864612450915
Validation loss: 2.658930494066561

Epoch: 6| Step: 6
Training loss: 1.741597576079042
Validation loss: 2.664633945871254

Epoch: 6| Step: 7
Training loss: 1.677956829488711
Validation loss: 2.6561299827143157

Epoch: 6| Step: 8
Training loss: 1.0852444310127791
Validation loss: 2.6088292803456743

Epoch: 6| Step: 9
Training loss: 0.6103920152610024
Validation loss: 2.594012746637296

Epoch: 6| Step: 10
Training loss: 1.4572690713406398
Validation loss: 2.6096451543164156

Epoch: 6| Step: 11
Training loss: 1.194701593402232
Validation loss: 2.555671769468061

Epoch: 6| Step: 12
Training loss: 1.380365523498113
Validation loss: 2.5706296529927966

Epoch: 6| Step: 13
Training loss: 0.9753407579781701
Validation loss: 2.585573824218019

Epoch: 242| Step: 0
Training loss: 1.6051515140498858
Validation loss: 2.5611550047530116

Epoch: 6| Step: 1
Training loss: 1.2831340057012417
Validation loss: 2.570875628611701

Epoch: 6| Step: 2
Training loss: 1.6048740297123376
Validation loss: 2.5827006882915167

Epoch: 6| Step: 3
Training loss: 1.464253380381906
Validation loss: 2.575682152022255

Epoch: 6| Step: 4
Training loss: 1.1446018132144924
Validation loss: 2.577124244856693

Epoch: 6| Step: 5
Training loss: 1.4047777734588325
Validation loss: 2.5975521846765126

Epoch: 6| Step: 6
Training loss: 1.5540879210021659
Validation loss: 2.6077213884843222

Epoch: 6| Step: 7
Training loss: 1.2064740027335237
Validation loss: 2.585053990940084

Epoch: 6| Step: 8
Training loss: 1.4970296218428434
Validation loss: 2.5925764296954514

Epoch: 6| Step: 9
Training loss: 1.1948892679345322
Validation loss: 2.5769843766855627

Epoch: 6| Step: 10
Training loss: 1.066911179611238
Validation loss: 2.606545152543451

Epoch: 6| Step: 11
Training loss: 1.4473356366437182
Validation loss: 2.6291095288324104

Epoch: 6| Step: 12
Training loss: 1.3320412733310563
Validation loss: 2.6042560967297237

Epoch: 6| Step: 13
Training loss: 1.3059389884887305
Validation loss: 2.6505528233066378

Epoch: 243| Step: 0
Training loss: 1.4817372224970267
Validation loss: 2.6022562086710517

Epoch: 6| Step: 1
Training loss: 1.316569151265085
Validation loss: 2.650900321905994

Epoch: 6| Step: 2
Training loss: 1.4350397368986936
Validation loss: 2.651123503662414

Epoch: 6| Step: 3
Training loss: 1.5208607327157377
Validation loss: 2.6524594288500816

Epoch: 6| Step: 4
Training loss: 1.0529186533365853
Validation loss: 2.6383142877307875

Epoch: 6| Step: 5
Training loss: 1.2925676259513352
Validation loss: 2.635085096751788

Epoch: 6| Step: 6
Training loss: 1.2718632334321878
Validation loss: 2.60580179247813

Epoch: 6| Step: 7
Training loss: 1.5154393662493792
Validation loss: 2.6010572716509164

Epoch: 6| Step: 8
Training loss: 1.1641477515218384
Validation loss: 2.60139994735643

Epoch: 6| Step: 9
Training loss: 1.6384872314309489
Validation loss: 2.54858581349203

Epoch: 6| Step: 10
Training loss: 1.1673623746831954
Validation loss: 2.5510797388624646

Epoch: 6| Step: 11
Training loss: 1.1336583629783734
Validation loss: 2.522672640336479

Epoch: 6| Step: 12
Training loss: 1.4435614623781878
Validation loss: 2.5411224717326055

Epoch: 6| Step: 13
Training loss: 1.3139157153144865
Validation loss: 2.553249137225137

Epoch: 244| Step: 0
Training loss: 1.4786755010520392
Validation loss: 2.5642087018126274

Epoch: 6| Step: 1
Training loss: 1.7031868739656626
Validation loss: 2.5914263140568985

Epoch: 6| Step: 2
Training loss: 1.5800290094199285
Validation loss: 2.5885448847403416

Epoch: 6| Step: 3
Training loss: 1.1370788737864612
Validation loss: 2.5948416128527985

Epoch: 6| Step: 4
Training loss: 1.3403386128026025
Validation loss: 2.6024420782196334

Epoch: 6| Step: 5
Training loss: 1.49630576441717
Validation loss: 2.638974451499648

Epoch: 6| Step: 6
Training loss: 1.094020047229032
Validation loss: 2.6086378367257583

Epoch: 6| Step: 7
Training loss: 0.8559804283204159
Validation loss: 2.6129371341331713

Epoch: 6| Step: 8
Training loss: 1.0750946912534904
Validation loss: 2.6247044976593474

Epoch: 6| Step: 9
Training loss: 1.1361321577647676
Validation loss: 2.6116204987458795

Epoch: 6| Step: 10
Training loss: 1.3210722413390374
Validation loss: 2.625833870149311

Epoch: 6| Step: 11
Training loss: 1.5143911314076388
Validation loss: 2.576905438344059

Epoch: 6| Step: 12
Training loss: 1.2586592199629256
Validation loss: 2.579148883676437

Epoch: 6| Step: 13
Training loss: 0.9451075560301113
Validation loss: 2.5908864504533486

Epoch: 245| Step: 0
Training loss: 1.215399366684385
Validation loss: 2.576775131267933

Epoch: 6| Step: 1
Training loss: 1.3078454454435664
Validation loss: 2.5780150309576944

Epoch: 6| Step: 2
Training loss: 1.4023345691943558
Validation loss: 2.5470303512554313

Epoch: 6| Step: 3
Training loss: 0.84484065172923
Validation loss: 2.5681916542271748

Epoch: 6| Step: 4
Training loss: 1.461070743135295
Validation loss: 2.554276749609527

Epoch: 6| Step: 5
Training loss: 1.0558859338782474
Validation loss: 2.6033426673571305

Epoch: 6| Step: 6
Training loss: 1.3153334867761222
Validation loss: 2.610470386704613

Epoch: 6| Step: 7
Training loss: 0.9244954640559344
Validation loss: 2.6147916036195467

Epoch: 6| Step: 8
Training loss: 1.733517615291239
Validation loss: 2.6135415446157078

Epoch: 6| Step: 9
Training loss: 0.9794946216009137
Validation loss: 2.6058416467326873

Epoch: 6| Step: 10
Training loss: 1.5522253581699328
Validation loss: 2.6134019146903182

Epoch: 6| Step: 11
Training loss: 1.0557706004541831
Validation loss: 2.5873019171109757

Epoch: 6| Step: 12
Training loss: 1.684864104815809
Validation loss: 2.621185286953827

Epoch: 6| Step: 13
Training loss: 1.2958790735265542
Validation loss: 2.5688746088647543

Epoch: 246| Step: 0
Training loss: 1.3726552999077397
Validation loss: 2.6013559943539732

Epoch: 6| Step: 1
Training loss: 1.4323916683543803
Validation loss: 2.5904745885482208

Epoch: 6| Step: 2
Training loss: 0.925257764161668
Validation loss: 2.572453903152287

Epoch: 6| Step: 3
Training loss: 1.0138179254882307
Validation loss: 2.5822173859717323

Epoch: 6| Step: 4
Training loss: 1.5373013872090098
Validation loss: 2.582685318516035

Epoch: 6| Step: 5
Training loss: 1.3403350996805725
Validation loss: 2.5593306768276247

Epoch: 6| Step: 6
Training loss: 1.1147927714336245
Validation loss: 2.5627801273318283

Epoch: 6| Step: 7
Training loss: 1.4316561126912088
Validation loss: 2.595237229446445

Epoch: 6| Step: 8
Training loss: 1.0830510700967069
Validation loss: 2.614953833597403

Epoch: 6| Step: 9
Training loss: 1.5705780260292537
Validation loss: 2.60740470024875

Epoch: 6| Step: 10
Training loss: 1.0849604430656783
Validation loss: 2.628540545095801

Epoch: 6| Step: 11
Training loss: 1.6126282042171471
Validation loss: 2.641107524705036

Epoch: 6| Step: 12
Training loss: 1.0636119633730956
Validation loss: 2.657021561869649

Epoch: 6| Step: 13
Training loss: 1.1830705550171126
Validation loss: 2.6694890539896954

Epoch: 247| Step: 0
Training loss: 1.4331951366751943
Validation loss: 2.6223427169720175

Epoch: 6| Step: 1
Training loss: 1.471048545041562
Validation loss: 2.60518694934439

Epoch: 6| Step: 2
Training loss: 1.505317244059963
Validation loss: 2.5758898042620633

Epoch: 6| Step: 3
Training loss: 1.368914140587768
Validation loss: 2.553883459922626

Epoch: 6| Step: 4
Training loss: 1.0710532973070492
Validation loss: 2.5330438328119858

Epoch: 6| Step: 5
Training loss: 1.089646242901564
Validation loss: 2.527471616183613

Epoch: 6| Step: 6
Training loss: 1.0566938742936511
Validation loss: 2.5074577915111758

Epoch: 6| Step: 7
Training loss: 1.3012535910140002
Validation loss: 2.531937257115797

Epoch: 6| Step: 8
Training loss: 1.363660524616631
Validation loss: 2.51961818327918

Epoch: 6| Step: 9
Training loss: 1.2860708026231453
Validation loss: 2.56843380691712

Epoch: 6| Step: 10
Training loss: 1.1228341871460967
Validation loss: 2.6026305408558192

Epoch: 6| Step: 11
Training loss: 0.9564848605192647
Validation loss: 2.618374443491518

Epoch: 6| Step: 12
Training loss: 1.212899470642563
Validation loss: 2.64096938521746

Epoch: 6| Step: 13
Training loss: 1.6781050213809068
Validation loss: 2.677552734402904

Epoch: 248| Step: 0
Training loss: 1.2224179849241534
Validation loss: 2.6760230960868276

Epoch: 6| Step: 1
Training loss: 1.5873988892803077
Validation loss: 2.6222983490225937

Epoch: 6| Step: 2
Training loss: 1.158921223389802
Validation loss: 2.6356082839951447

Epoch: 6| Step: 3
Training loss: 0.701708022829607
Validation loss: 2.6210051784255533

Epoch: 6| Step: 4
Training loss: 0.9698875270604318
Validation loss: 2.5935804467565786

Epoch: 6| Step: 5
Training loss: 1.5648251590014837
Validation loss: 2.5489774071941835

Epoch: 6| Step: 6
Training loss: 1.8624325784858677
Validation loss: 2.568106825413278

Epoch: 6| Step: 7
Training loss: 1.2273472504836003
Validation loss: 2.54194547864549

Epoch: 6| Step: 8
Training loss: 1.0361921201768942
Validation loss: 2.546840963180878

Epoch: 6| Step: 9
Training loss: 1.1404959723248036
Validation loss: 2.542103326595704

Epoch: 6| Step: 10
Training loss: 1.0540714866782115
Validation loss: 2.5507993055039817

Epoch: 6| Step: 11
Training loss: 1.4501076000673436
Validation loss: 2.594840901510148

Epoch: 6| Step: 12
Training loss: 0.9155286132803698
Validation loss: 2.6145693249914066

Epoch: 6| Step: 13
Training loss: 1.5421208236797337
Validation loss: 2.606898524239339

Epoch: 249| Step: 0
Training loss: 1.0534201460285624
Validation loss: 2.6421350145924696

Epoch: 6| Step: 1
Training loss: 1.60029827556311
Validation loss: 2.6597631762557232

Epoch: 6| Step: 2
Training loss: 1.2387242051411556
Validation loss: 2.6644946524789344

Epoch: 6| Step: 3
Training loss: 1.492522995865885
Validation loss: 2.6966448724176484

Epoch: 6| Step: 4
Training loss: 1.294465780127824
Validation loss: 2.6710554716818233

Epoch: 6| Step: 5
Training loss: 1.2638396397917528
Validation loss: 2.6707609404263413

Epoch: 6| Step: 6
Training loss: 1.4980373257925763
Validation loss: 2.644323783791509

Epoch: 6| Step: 7
Training loss: 1.1595314475561687
Validation loss: 2.617795307645539

Epoch: 6| Step: 8
Training loss: 1.0154868985696897
Validation loss: 2.605538154660733

Epoch: 6| Step: 9
Training loss: 1.0468408379745555
Validation loss: 2.586704193160598

Epoch: 6| Step: 10
Training loss: 1.0465288871135427
Validation loss: 2.5887626688463374

Epoch: 6| Step: 11
Training loss: 1.288019208936622
Validation loss: 2.5690510884865048

Epoch: 6| Step: 12
Training loss: 1.491554085871415
Validation loss: 2.5670257278718975

Epoch: 6| Step: 13
Training loss: 0.5891238992601031
Validation loss: 2.5807464805320173

Epoch: 250| Step: 0
Training loss: 1.2317000268608946
Validation loss: 2.571526720449731

Epoch: 6| Step: 1
Training loss: 0.9702231988033557
Validation loss: 2.6019748335236836

Epoch: 6| Step: 2
Training loss: 1.1215592856585639
Validation loss: 2.6440485458323537

Epoch: 6| Step: 3
Training loss: 1.2425534650939345
Validation loss: 2.659362248508873

Epoch: 6| Step: 4
Training loss: 1.2931012319129278
Validation loss: 2.679059276464448

Epoch: 6| Step: 5
Training loss: 0.892912753961855
Validation loss: 2.659906664224012

Epoch: 6| Step: 6
Training loss: 1.619950077206014
Validation loss: 2.6229194320185467

Epoch: 6| Step: 7
Training loss: 1.6319687410895194
Validation loss: 2.5934598868958503

Epoch: 6| Step: 8
Training loss: 1.125285112492102
Validation loss: 2.583509330695367

Epoch: 6| Step: 9
Training loss: 1.2190748417593096
Validation loss: 2.5674921385843055

Epoch: 6| Step: 10
Training loss: 1.046064945932617
Validation loss: 2.569206753236767

Epoch: 6| Step: 11
Training loss: 1.4498593130590929
Validation loss: 2.6068302188876826

Epoch: 6| Step: 12
Training loss: 1.344658477987744
Validation loss: 2.6044900987828075

Epoch: 6| Step: 13
Training loss: 0.9636278715319744
Validation loss: 2.6062180372030936

Epoch: 251| Step: 0
Training loss: 0.8954583906307673
Validation loss: 2.578864898858593

Epoch: 6| Step: 1
Training loss: 1.0368195611942204
Validation loss: 2.6069522894618102

Epoch: 6| Step: 2
Training loss: 1.381471490146785
Validation loss: 2.6006419230659144

Epoch: 6| Step: 3
Training loss: 1.6295196329709167
Validation loss: 2.6086894011448614

Epoch: 6| Step: 4
Training loss: 0.6138968809776529
Validation loss: 2.585143968801787

Epoch: 6| Step: 5
Training loss: 1.2728026510185864
Validation loss: 2.653301285519356

Epoch: 6| Step: 6
Training loss: 0.9421189645414711
Validation loss: 2.6172870399721715

Epoch: 6| Step: 7
Training loss: 1.4962934156602745
Validation loss: 2.576498684702612

Epoch: 6| Step: 8
Training loss: 1.5657286284180603
Validation loss: 2.594161938778411

Epoch: 6| Step: 9
Training loss: 1.3820079467257895
Validation loss: 2.5706811171741735

Epoch: 6| Step: 10
Training loss: 1.3406029154774706
Validation loss: 2.5714264349791023

Epoch: 6| Step: 11
Training loss: 1.0377475764853517
Validation loss: 2.5542441673935383

Epoch: 6| Step: 12
Training loss: 1.2187509781271115
Validation loss: 2.544992658860506

Epoch: 6| Step: 13
Training loss: 1.1353628454955278
Validation loss: 2.5608690935987606

Epoch: 252| Step: 0
Training loss: 1.2902301470658097
Validation loss: 2.5822243380856333

Epoch: 6| Step: 1
Training loss: 1.529431255570232
Validation loss: 2.619700002076816

Epoch: 6| Step: 2
Training loss: 1.0542989509621443
Validation loss: 2.6548409553309704

Epoch: 6| Step: 3
Training loss: 0.845172424838667
Validation loss: 2.6880649603363156

Epoch: 6| Step: 4
Training loss: 1.2443769820315844
Validation loss: 2.6821240912870565

Epoch: 6| Step: 5
Training loss: 1.1651880340108418
Validation loss: 2.690274561802456

Epoch: 6| Step: 6
Training loss: 0.9693061401288415
Validation loss: 2.6811071829261226

Epoch: 6| Step: 7
Training loss: 1.2475313605454708
Validation loss: 2.629156596413445

Epoch: 6| Step: 8
Training loss: 1.7609380442797031
Validation loss: 2.6104513690279543

Epoch: 6| Step: 9
Training loss: 0.5679712445021976
Validation loss: 2.613033893707768

Epoch: 6| Step: 10
Training loss: 1.6334567464537897
Validation loss: 2.559936939882923

Epoch: 6| Step: 11
Training loss: 1.2134036147980978
Validation loss: 2.585316178554913

Epoch: 6| Step: 12
Training loss: 0.8539216147503694
Validation loss: 2.5816653179454687

Epoch: 6| Step: 13
Training loss: 1.1561064759951354
Validation loss: 2.5566255828834312

Epoch: 253| Step: 0
Training loss: 0.9515311250071118
Validation loss: 2.5693260694036546

Epoch: 6| Step: 1
Training loss: 1.1265635750986331
Validation loss: 2.5720577130581006

Epoch: 6| Step: 2
Training loss: 1.6430700338927264
Validation loss: 2.5605860059239296

Epoch: 6| Step: 3
Training loss: 1.256247453070189
Validation loss: 2.5769989746615827

Epoch: 6| Step: 4
Training loss: 0.8359432755030114
Validation loss: 2.5830143888104335

Epoch: 6| Step: 5
Training loss: 1.1778442938833404
Validation loss: 2.57213920520365

Epoch: 6| Step: 6
Training loss: 0.8039050696302225
Validation loss: 2.583003832563579

Epoch: 6| Step: 7
Training loss: 1.1327913479638916
Validation loss: 2.5888109720508696

Epoch: 6| Step: 8
Training loss: 1.6630462265425552
Validation loss: 2.6104793057655593

Epoch: 6| Step: 9
Training loss: 1.1205957881866722
Validation loss: 2.6089944555234945

Epoch: 6| Step: 10
Training loss: 1.274005458996753
Validation loss: 2.604326191271769

Epoch: 6| Step: 11
Training loss: 1.2837306408782851
Validation loss: 2.5906414268021636

Epoch: 6| Step: 12
Training loss: 0.7766482438275067
Validation loss: 2.5814007395152445

Epoch: 6| Step: 13
Training loss: 1.440522540704275
Validation loss: 2.60229361101467

Epoch: 254| Step: 0
Training loss: 1.1127925938082135
Validation loss: 2.5704597006847774

Epoch: 6| Step: 1
Training loss: 1.3090139141523507
Validation loss: 2.6085522691852545

Epoch: 6| Step: 2
Training loss: 0.9086383392072755
Validation loss: 2.6124704338779763

Epoch: 6| Step: 3
Training loss: 1.3971791919724885
Validation loss: 2.5809522363730455

Epoch: 6| Step: 4
Training loss: 1.7831749135655157
Validation loss: 2.595730948866375

Epoch: 6| Step: 5
Training loss: 1.4171988759115242
Validation loss: 2.5762992303157177

Epoch: 6| Step: 6
Training loss: 1.0499297027670773
Validation loss: 2.5934539697153194

Epoch: 6| Step: 7
Training loss: 1.0429644638144897
Validation loss: 2.603061321997173

Epoch: 6| Step: 8
Training loss: 0.988851450599555
Validation loss: 2.6306749948236985

Epoch: 6| Step: 9
Training loss: 1.2193426011951503
Validation loss: 2.569600886706229

Epoch: 6| Step: 10
Training loss: 1.1327432545511809
Validation loss: 2.582429192422099

Epoch: 6| Step: 11
Training loss: 1.1575148082634545
Validation loss: 2.5950151983410334

Epoch: 6| Step: 12
Training loss: 0.9190727575223248
Validation loss: 2.5789802760908547

Epoch: 6| Step: 13
Training loss: 0.8346201775757028
Validation loss: 2.564072599358189

Epoch: 255| Step: 0
Training loss: 1.2299089399606349
Validation loss: 2.5323685089387866

Epoch: 6| Step: 1
Training loss: 1.1645645492667525
Validation loss: 2.570481483651402

Epoch: 6| Step: 2
Training loss: 1.234045153621766
Validation loss: 2.5662326404088334

Epoch: 6| Step: 3
Training loss: 0.8600306350774006
Validation loss: 2.5688211454590983

Epoch: 6| Step: 4
Training loss: 1.1071295243000998
Validation loss: 2.6126757176088726

Epoch: 6| Step: 5
Training loss: 1.3081384122828907
Validation loss: 2.622858876521829

Epoch: 6| Step: 6
Training loss: 1.1586422272801868
Validation loss: 2.6486273271108094

Epoch: 6| Step: 7
Training loss: 1.12494087063848
Validation loss: 2.63808994263224

Epoch: 6| Step: 8
Training loss: 1.0102280640650212
Validation loss: 2.6458343423174995

Epoch: 6| Step: 9
Training loss: 1.4545043633357193
Validation loss: 2.6342758980824748

Epoch: 6| Step: 10
Training loss: 1.16827965110148
Validation loss: 2.597473098598366

Epoch: 6| Step: 11
Training loss: 0.8549777150177849
Validation loss: 2.580107407082614

Epoch: 6| Step: 12
Training loss: 1.4370640632721432
Validation loss: 2.564582477741141

Epoch: 6| Step: 13
Training loss: 1.392790618991647
Validation loss: 2.5264977940968665

Epoch: 256| Step: 0
Training loss: 1.5404663654235033
Validation loss: 2.5186513109658817

Epoch: 6| Step: 1
Training loss: 1.103544683833382
Validation loss: 2.5167929968949414

Epoch: 6| Step: 2
Training loss: 1.180562181391853
Validation loss: 2.505336509954165

Epoch: 6| Step: 3
Training loss: 1.5741746011227427
Validation loss: 2.5035281537458003

Epoch: 6| Step: 4
Training loss: 1.2077985873784336
Validation loss: 2.5393659573461935

Epoch: 6| Step: 5
Training loss: 1.035818212209023
Validation loss: 2.5277517972968764

Epoch: 6| Step: 6
Training loss: 0.9120010540374721
Validation loss: 2.5614679946126375

Epoch: 6| Step: 7
Training loss: 0.9940015774297958
Validation loss: 2.6263431813054843

Epoch: 6| Step: 8
Training loss: 1.0553616664956424
Validation loss: 2.65035086994678

Epoch: 6| Step: 9
Training loss: 1.0454199628802063
Validation loss: 2.670467812842043

Epoch: 6| Step: 10
Training loss: 0.9178165066053294
Validation loss: 2.6989414148652964

Epoch: 6| Step: 11
Training loss: 1.4196600797281993
Validation loss: 2.6457900684150206

Epoch: 6| Step: 12
Training loss: 1.1899924973644034
Validation loss: 2.602195029470333

Epoch: 6| Step: 13
Training loss: 1.1603701615845488
Validation loss: 2.5811861272988437

Epoch: 257| Step: 0
Training loss: 0.8168226941268187
Validation loss: 2.5573469503163087

Epoch: 6| Step: 1
Training loss: 1.142976870608995
Validation loss: 2.5338702174407444

Epoch: 6| Step: 2
Training loss: 0.6109267309464118
Validation loss: 2.5072087521533915

Epoch: 6| Step: 3
Training loss: 1.4061405563151856
Validation loss: 2.531454735581875

Epoch: 6| Step: 4
Training loss: 1.185790487834773
Validation loss: 2.5341080188940714

Epoch: 6| Step: 5
Training loss: 0.5023763334584531
Validation loss: 2.5252475076670935

Epoch: 6| Step: 6
Training loss: 1.0812945009456345
Validation loss: 2.567978482789959

Epoch: 6| Step: 7
Training loss: 1.7047661389919628
Validation loss: 2.5943241099280767

Epoch: 6| Step: 8
Training loss: 1.024192706139964
Validation loss: 2.5775954964698062

Epoch: 6| Step: 9
Training loss: 1.4094866063488747
Validation loss: 2.6082683464188827

Epoch: 6| Step: 10
Training loss: 1.25922608169521
Validation loss: 2.6050809322631725

Epoch: 6| Step: 11
Training loss: 1.5642156718399753
Validation loss: 2.593822728785652

Epoch: 6| Step: 12
Training loss: 0.7649468123577198
Validation loss: 2.5894665511214576

Epoch: 6| Step: 13
Training loss: 0.8335251627111873
Validation loss: 2.573979969139316

Epoch: 258| Step: 0
Training loss: 1.3300187914101629
Validation loss: 2.5634858270761924

Epoch: 6| Step: 1
Training loss: 1.046540676651437
Validation loss: 2.569042957633426

Epoch: 6| Step: 2
Training loss: 0.9796171707632898
Validation loss: 2.5624100403960868

Epoch: 6| Step: 3
Training loss: 0.9883767786710749
Validation loss: 2.570737848745531

Epoch: 6| Step: 4
Training loss: 1.2907569614586927
Validation loss: 2.5745445489836274

Epoch: 6| Step: 5
Training loss: 1.0243491851365456
Validation loss: 2.599763748440842

Epoch: 6| Step: 6
Training loss: 1.2305810301884803
Validation loss: 2.5925584733062075

Epoch: 6| Step: 7
Training loss: 0.9682123476523549
Validation loss: 2.5894715255050795

Epoch: 6| Step: 8
Training loss: 1.283877585960282
Validation loss: 2.6076389408125675

Epoch: 6| Step: 9
Training loss: 0.8893368758543778
Validation loss: 2.5943984253906285

Epoch: 6| Step: 10
Training loss: 1.6586259318610814
Validation loss: 2.596328468790899

Epoch: 6| Step: 11
Training loss: 0.7487321707588137
Validation loss: 2.5659486737902197

Epoch: 6| Step: 12
Training loss: 0.9581129228362026
Validation loss: 2.58147002856592

Epoch: 6| Step: 13
Training loss: 1.1973507027944998
Validation loss: 2.5604345980473346

Epoch: 259| Step: 0
Training loss: 1.2236255057954732
Validation loss: 2.568394778590276

Epoch: 6| Step: 1
Training loss: 1.2026145644941015
Validation loss: 2.555668927632875

Epoch: 6| Step: 2
Training loss: 1.0692124665624925
Validation loss: 2.5357899051766157

Epoch: 6| Step: 3
Training loss: 1.1626079099059594
Validation loss: 2.5281583864651225

Epoch: 6| Step: 4
Training loss: 0.9265803176170265
Validation loss: 2.549852400060311

Epoch: 6| Step: 5
Training loss: 1.3008718373141162
Validation loss: 2.541735313479663

Epoch: 6| Step: 6
Training loss: 0.7738635498441995
Validation loss: 2.550010896112952

Epoch: 6| Step: 7
Training loss: 1.203052369935124
Validation loss: 2.574068089230634

Epoch: 6| Step: 8
Training loss: 1.2451002411530605
Validation loss: 2.60841643718591

Epoch: 6| Step: 9
Training loss: 1.061520293089869
Validation loss: 2.5892463959940066

Epoch: 6| Step: 10
Training loss: 0.8651658971826311
Validation loss: 2.6085019285924016

Epoch: 6| Step: 11
Training loss: 0.9762193305733299
Validation loss: 2.6634131267358487

Epoch: 6| Step: 12
Training loss: 1.7525973799311003
Validation loss: 2.64482199270197

Epoch: 6| Step: 13
Training loss: 0.4505730655652135
Validation loss: 2.617342431262949

Epoch: 260| Step: 0
Training loss: 1.351744137945458
Validation loss: 2.618339301043029

Epoch: 6| Step: 1
Training loss: 1.275314959724894
Validation loss: 2.6021735848841216

Epoch: 6| Step: 2
Training loss: 1.2125769561256627
Validation loss: 2.5603931658983203

Epoch: 6| Step: 3
Training loss: 1.0304658393731994
Validation loss: 2.571010812537403

Epoch: 6| Step: 4
Training loss: 0.9425728877997473
Validation loss: 2.5547809988258083

Epoch: 6| Step: 5
Training loss: 0.8845515044696087
Validation loss: 2.5486618116601307

Epoch: 6| Step: 6
Training loss: 1.184898991283638
Validation loss: 2.555242901494873

Epoch: 6| Step: 7
Training loss: 1.1132464487090694
Validation loss: 2.5471798283866347

Epoch: 6| Step: 8
Training loss: 0.9560373867756806
Validation loss: 2.5377037993167746

Epoch: 6| Step: 9
Training loss: 1.6174845399663111
Validation loss: 2.5495860692978183

Epoch: 6| Step: 10
Training loss: 1.2562821834863727
Validation loss: 2.574871893791495

Epoch: 6| Step: 11
Training loss: 0.8845399143405828
Validation loss: 2.6005034292208684

Epoch: 6| Step: 12
Training loss: 1.091508038961712
Validation loss: 2.607491640610367

Epoch: 6| Step: 13
Training loss: 0.4021231037032334
Validation loss: 2.5952767263471537

Epoch: 261| Step: 0
Training loss: 1.1289589417512198
Validation loss: 2.600858692249627

Epoch: 6| Step: 1
Training loss: 1.13312515679604
Validation loss: 2.6097237890112144

Epoch: 6| Step: 2
Training loss: 0.789762167863131
Validation loss: 2.591782606668127

Epoch: 6| Step: 3
Training loss: 1.062668394320275
Validation loss: 2.5820190991370238

Epoch: 6| Step: 4
Training loss: 1.294574443531648
Validation loss: 2.579572938367917

Epoch: 6| Step: 5
Training loss: 1.102351508055814
Validation loss: 2.5877597129804712

Epoch: 6| Step: 6
Training loss: 0.9193056152218733
Validation loss: 2.5873585577172533

Epoch: 6| Step: 7
Training loss: 1.639058555110988
Validation loss: 2.5657544218152912

Epoch: 6| Step: 8
Training loss: 0.7105488815405114
Validation loss: 2.56347266824781

Epoch: 6| Step: 9
Training loss: 0.8733599142101414
Validation loss: 2.5381358646944965

Epoch: 6| Step: 10
Training loss: 1.2528744549369977
Validation loss: 2.5379437320336313

Epoch: 6| Step: 11
Training loss: 1.0662925575770077
Validation loss: 2.5411634170556785

Epoch: 6| Step: 12
Training loss: 1.0509556054884723
Validation loss: 2.5374456076412453

Epoch: 6| Step: 13
Training loss: 1.3480356760369543
Validation loss: 2.559123040343386

Epoch: 262| Step: 0
Training loss: 1.446262521648355
Validation loss: 2.586335616531137

Epoch: 6| Step: 1
Training loss: 1.5574778910088725
Validation loss: 2.590762107923257

Epoch: 6| Step: 2
Training loss: 0.7644345896739325
Validation loss: 2.6403751438331167

Epoch: 6| Step: 3
Training loss: 1.0490830891179355
Validation loss: 2.6000751122446677

Epoch: 6| Step: 4
Training loss: 0.693773731478758
Validation loss: 2.5950634671591084

Epoch: 6| Step: 5
Training loss: 1.0306546197617348
Validation loss: 2.5789180874446838

Epoch: 6| Step: 6
Training loss: 1.1263153016595493
Validation loss: 2.553345641580918

Epoch: 6| Step: 7
Training loss: 0.8278220720266948
Validation loss: 2.5296217181743788

Epoch: 6| Step: 8
Training loss: 0.6709189599242428
Validation loss: 2.560851724762542

Epoch: 6| Step: 9
Training loss: 1.0196955172158992
Validation loss: 2.506753972012849

Epoch: 6| Step: 10
Training loss: 1.5078705297184207
Validation loss: 2.5370336805160627

Epoch: 6| Step: 11
Training loss: 0.9889480090655447
Validation loss: 2.5262581924755643

Epoch: 6| Step: 12
Training loss: 1.0600852453394842
Validation loss: 2.539749036031999

Epoch: 6| Step: 13
Training loss: 1.1558111749921063
Validation loss: 2.5086606099144984

Epoch: 263| Step: 0
Training loss: 0.8371441412473676
Validation loss: 2.5533176520284893

Epoch: 6| Step: 1
Training loss: 0.949786608973215
Validation loss: 2.595394115047933

Epoch: 6| Step: 2
Training loss: 1.2406820135204248
Validation loss: 2.583576352388609

Epoch: 6| Step: 3
Training loss: 0.755544552555406
Validation loss: 2.608063451038074

Epoch: 6| Step: 4
Training loss: 0.9805343423613412
Validation loss: 2.603487106420727

Epoch: 6| Step: 5
Training loss: 1.0789233582705726
Validation loss: 2.58001654161917

Epoch: 6| Step: 6
Training loss: 1.0026054415343795
Validation loss: 2.544114912854857

Epoch: 6| Step: 7
Training loss: 1.3813328558465017
Validation loss: 2.557513257703222

Epoch: 6| Step: 8
Training loss: 0.6952570346612184
Validation loss: 2.510047644131245

Epoch: 6| Step: 9
Training loss: 1.2338018414583036
Validation loss: 2.508432786882017

Epoch: 6| Step: 10
Training loss: 1.2552840604402355
Validation loss: 2.498265968400238

Epoch: 6| Step: 11
Training loss: 1.1062836895139376
Validation loss: 2.527175216303598

Epoch: 6| Step: 12
Training loss: 1.3723663336558998
Validation loss: 2.5055832403992233

Epoch: 6| Step: 13
Training loss: 1.1323980691439903
Validation loss: 2.5152938371045406

Epoch: 264| Step: 0
Training loss: 1.138819899188131
Validation loss: 2.519262538532299

Epoch: 6| Step: 1
Training loss: 1.3186200371653467
Validation loss: 2.5227530917191645

Epoch: 6| Step: 2
Training loss: 1.2806856726911284
Validation loss: 2.53217536614422

Epoch: 6| Step: 3
Training loss: 1.0771500975664339
Validation loss: 2.5243040975547557

Epoch: 6| Step: 4
Training loss: 1.1415585916881976
Validation loss: 2.522305556916661

Epoch: 6| Step: 5
Training loss: 1.4179440330684094
Validation loss: 2.534870302919966

Epoch: 6| Step: 6
Training loss: 0.6807683703325098
Validation loss: 2.510137843158073

Epoch: 6| Step: 7
Training loss: 1.1319528409078299
Validation loss: 2.5008875194391913

Epoch: 6| Step: 8
Training loss: 0.9549588243984864
Validation loss: 2.579193327437259

Epoch: 6| Step: 9
Training loss: 1.0810043474863378
Validation loss: 2.576700677640738

Epoch: 6| Step: 10
Training loss: 0.9432223202677908
Validation loss: 2.555315803263114

Epoch: 6| Step: 11
Training loss: 0.7631227123654231
Validation loss: 2.568638830890924

Epoch: 6| Step: 12
Training loss: 0.9787062651508034
Validation loss: 2.5824795329890047

Epoch: 6| Step: 13
Training loss: 0.8485330362784075
Validation loss: 2.5651306637364195

Epoch: 265| Step: 0
Training loss: 0.593474223691517
Validation loss: 2.604101546591084

Epoch: 6| Step: 1
Training loss: 0.8192982534260748
Validation loss: 2.634113634743041

Epoch: 6| Step: 2
Training loss: 0.840892970261012
Validation loss: 2.5793174215988937

Epoch: 6| Step: 3
Training loss: 1.2109162851751782
Validation loss: 2.563329114823125

Epoch: 6| Step: 4
Training loss: 1.2788573929782054
Validation loss: 2.545387814778694

Epoch: 6| Step: 5
Training loss: 0.7576447920700886
Validation loss: 2.5379412501550767

Epoch: 6| Step: 6
Training loss: 0.9632210000308925
Validation loss: 2.5229363469092387

Epoch: 6| Step: 7
Training loss: 1.0937256946587934
Validation loss: 2.521712161580935

Epoch: 6| Step: 8
Training loss: 1.5485028265636884
Validation loss: 2.5486744042048466

Epoch: 6| Step: 9
Training loss: 1.4359349563127803
Validation loss: 2.5260199839037

Epoch: 6| Step: 10
Training loss: 1.266510877105474
Validation loss: 2.527839044703426

Epoch: 6| Step: 11
Training loss: 0.9995339022635961
Validation loss: 2.5363964123703964

Epoch: 6| Step: 12
Training loss: 0.8488356651817404
Validation loss: 2.541093446621407

Epoch: 6| Step: 13
Training loss: 0.6568841821771014
Validation loss: 2.5463257703279933

Epoch: 266| Step: 0
Training loss: 0.6818222634597908
Validation loss: 2.5350977488311757

Epoch: 6| Step: 1
Training loss: 1.2443862265401837
Validation loss: 2.5494956288839057

Epoch: 6| Step: 2
Training loss: 1.2162793866926835
Validation loss: 2.5558245789094274

Epoch: 6| Step: 3
Training loss: 0.9209855524891131
Validation loss: 2.555655384484326

Epoch: 6| Step: 4
Training loss: 1.181551137010467
Validation loss: 2.5473261144972756

Epoch: 6| Step: 5
Training loss: 0.7750294802811507
Validation loss: 2.554480133918003

Epoch: 6| Step: 6
Training loss: 1.2074051065061142
Validation loss: 2.533770670513855

Epoch: 6| Step: 7
Training loss: 0.9272369014692136
Validation loss: 2.5492758136190896

Epoch: 6| Step: 8
Training loss: 1.0181532276191014
Validation loss: 2.5469375180920206

Epoch: 6| Step: 9
Training loss: 0.8311794021571104
Validation loss: 2.5240283587863317

Epoch: 6| Step: 10
Training loss: 1.1507871297464671
Validation loss: 2.5263947013839787

Epoch: 6| Step: 11
Training loss: 1.064509567024239
Validation loss: 2.5284672456472363

Epoch: 6| Step: 12
Training loss: 1.3733562701510427
Validation loss: 2.5169217433583886

Epoch: 6| Step: 13
Training loss: 1.0202437793903796
Validation loss: 2.4871119718822943

Epoch: 267| Step: 0
Training loss: 1.1446146234864962
Validation loss: 2.5301202875949182

Epoch: 6| Step: 1
Training loss: 1.0415725792672683
Validation loss: 2.5288571353220632

Epoch: 6| Step: 2
Training loss: 1.1602814988880876
Validation loss: 2.5462580148109017

Epoch: 6| Step: 3
Training loss: 1.082437101743682
Validation loss: 2.583906360892987

Epoch: 6| Step: 4
Training loss: 0.7888478279807782
Validation loss: 2.569168599790744

Epoch: 6| Step: 5
Training loss: 1.1130081109388035
Validation loss: 2.589592035431233

Epoch: 6| Step: 6
Training loss: 1.116543617633373
Validation loss: 2.5973635302347917

Epoch: 6| Step: 7
Training loss: 0.8477649179584298
Validation loss: 2.545765536788688

Epoch: 6| Step: 8
Training loss: 1.324934999203109
Validation loss: 2.5545119448888522

Epoch: 6| Step: 9
Training loss: 0.6721917226491159
Validation loss: 2.535139533206678

Epoch: 6| Step: 10
Training loss: 1.113165598433644
Validation loss: 2.567645912948426

Epoch: 6| Step: 11
Training loss: 1.2258810106069626
Validation loss: 2.566622964551945

Epoch: 6| Step: 12
Training loss: 0.7944241401846098
Validation loss: 2.5725830932681664

Epoch: 6| Step: 13
Training loss: 0.9484874906986923
Validation loss: 2.5613892721880753

Epoch: 268| Step: 0
Training loss: 1.507662118320547
Validation loss: 2.565862000356903

Epoch: 6| Step: 1
Training loss: 1.012865043108181
Validation loss: 2.575026396263572

Epoch: 6| Step: 2
Training loss: 0.9704267695616126
Validation loss: 2.561226903455665

Epoch: 6| Step: 3
Training loss: 1.4243113007975432
Validation loss: 2.545506870678251

Epoch: 6| Step: 4
Training loss: 1.2015163020862751
Validation loss: 2.5721913747287997

Epoch: 6| Step: 5
Training loss: 1.0186325145916584
Validation loss: 2.5795325689347015

Epoch: 6| Step: 6
Training loss: 0.8801640982864585
Validation loss: 2.5971573629311306

Epoch: 6| Step: 7
Training loss: 1.0210041500085671
Validation loss: 2.5628129391354166

Epoch: 6| Step: 8
Training loss: 1.0079808648995283
Validation loss: 2.565739294743314

Epoch: 6| Step: 9
Training loss: 0.6800544011570104
Validation loss: 2.5262246410160207

Epoch: 6| Step: 10
Training loss: 0.6864843452360703
Validation loss: 2.484409307530749

Epoch: 6| Step: 11
Training loss: 0.8749163451395977
Validation loss: 2.530182800203315

Epoch: 6| Step: 12
Training loss: 0.5940119516859299
Validation loss: 2.495216012073296

Epoch: 6| Step: 13
Training loss: 1.2262711391512862
Validation loss: 2.5154268113708875

Epoch: 269| Step: 0
Training loss: 1.0073266447688005
Validation loss: 2.5165698799760423

Epoch: 6| Step: 1
Training loss: 0.7380925901243875
Validation loss: 2.5233103092331093

Epoch: 6| Step: 2
Training loss: 0.9048619986531636
Validation loss: 2.5569365439266063

Epoch: 6| Step: 3
Training loss: 1.0618184652653229
Validation loss: 2.5598840003545

Epoch: 6| Step: 4
Training loss: 0.6297111099776965
Validation loss: 2.52891819505393

Epoch: 6| Step: 5
Training loss: 1.113399887456078
Validation loss: 2.574006725091156

Epoch: 6| Step: 6
Training loss: 1.2296471168644032
Validation loss: 2.5590216015831984

Epoch: 6| Step: 7
Training loss: 1.3975733212666681
Validation loss: 2.575493724150324

Epoch: 6| Step: 8
Training loss: 1.0739047614622463
Validation loss: 2.5645876488361448

Epoch: 6| Step: 9
Training loss: 1.074409218288167
Validation loss: 2.575836571059567

Epoch: 6| Step: 10
Training loss: 0.8087766136495528
Validation loss: 2.553797040555303

Epoch: 6| Step: 11
Training loss: 1.0524642116415142
Validation loss: 2.5498321219165336

Epoch: 6| Step: 12
Training loss: 0.7768319903841369
Validation loss: 2.529918258039097

Epoch: 6| Step: 13
Training loss: 1.1542735347550375
Validation loss: 2.545509390500833

Epoch: 270| Step: 0
Training loss: 0.8605217997966481
Validation loss: 2.538173604880716

Epoch: 6| Step: 1
Training loss: 0.46056229466063453
Validation loss: 2.53341022751477

Epoch: 6| Step: 2
Training loss: 0.9194826344981102
Validation loss: 2.536353757717661

Epoch: 6| Step: 3
Training loss: 0.881907040928414
Validation loss: 2.513435143865727

Epoch: 6| Step: 4
Training loss: 1.1526819799570585
Validation loss: 2.530754146119159

Epoch: 6| Step: 5
Training loss: 0.3689288788463022
Validation loss: 2.516924687000607

Epoch: 6| Step: 6
Training loss: 1.5036911055018516
Validation loss: 2.4978422692565827

Epoch: 6| Step: 7
Training loss: 1.1239776204280691
Validation loss: 2.5052968834335974

Epoch: 6| Step: 8
Training loss: 1.098192945798033
Validation loss: 2.4770435008354483

Epoch: 6| Step: 9
Training loss: 1.1550830416531204
Validation loss: 2.4769806489946804

Epoch: 6| Step: 10
Training loss: 0.9464912001819891
Validation loss: 2.507712907244421

Epoch: 6| Step: 11
Training loss: 1.2664741681458125
Validation loss: 2.5097846773143524

Epoch: 6| Step: 12
Training loss: 1.013571967638741
Validation loss: 2.597178316895897

Epoch: 6| Step: 13
Training loss: 0.868526215855442
Validation loss: 2.6091856607476718

Epoch: 271| Step: 0
Training loss: 0.9475426966727263
Validation loss: 2.6068568500941556

Epoch: 6| Step: 1
Training loss: 1.0795865311177129
Validation loss: 2.619799828225623

Epoch: 6| Step: 2
Training loss: 0.8649318329736877
Validation loss: 2.612118083893009

Epoch: 6| Step: 3
Training loss: 0.4977192867245262
Validation loss: 2.6261890128827208

Epoch: 6| Step: 4
Training loss: 0.8465977401411254
Validation loss: 2.580809978059562

Epoch: 6| Step: 5
Training loss: 1.1135883108610767
Validation loss: 2.544591435959852

Epoch: 6| Step: 6
Training loss: 0.697509616081374
Validation loss: 2.551033762181354

Epoch: 6| Step: 7
Training loss: 1.0845581185898625
Validation loss: 2.52898749269792

Epoch: 6| Step: 8
Training loss: 1.135380169809766
Validation loss: 2.550988915251329

Epoch: 6| Step: 9
Training loss: 1.0977602872042884
Validation loss: 2.5581057318179776

Epoch: 6| Step: 10
Training loss: 0.9956600067631962
Validation loss: 2.5397610802486117

Epoch: 6| Step: 11
Training loss: 1.1645494505036946
Validation loss: 2.551381485552156

Epoch: 6| Step: 12
Training loss: 1.3596855773421213
Validation loss: 2.556844278987326

Epoch: 6| Step: 13
Training loss: 0.6290013969903179
Validation loss: 2.5752429921579143

Epoch: 272| Step: 0
Training loss: 0.6728780932241084
Validation loss: 2.555386449697727

Epoch: 6| Step: 1
Training loss: 0.9668357147738093
Validation loss: 2.5777776459904387

Epoch: 6| Step: 2
Training loss: 1.1388538666641053
Validation loss: 2.583309976972994

Epoch: 6| Step: 3
Training loss: 1.3486426682495367
Validation loss: 2.5674074014892354

Epoch: 6| Step: 4
Training loss: 0.7213518897799881
Validation loss: 2.5917473979249195

Epoch: 6| Step: 5
Training loss: 0.7546347621395606
Validation loss: 2.5746735908829965

Epoch: 6| Step: 6
Training loss: 1.1045310420884564
Validation loss: 2.5438542271129303

Epoch: 6| Step: 7
Training loss: 0.5411200026759222
Validation loss: 2.5126042053770385

Epoch: 6| Step: 8
Training loss: 1.5835669328463648
Validation loss: 2.5251899287171056

Epoch: 6| Step: 9
Training loss: 0.8061572605586166
Validation loss: 2.498326602906394

Epoch: 6| Step: 10
Training loss: 1.017871250685821
Validation loss: 2.47548455733831

Epoch: 6| Step: 11
Training loss: 0.7267404153859104
Validation loss: 2.543867278813906

Epoch: 6| Step: 12
Training loss: 1.1996529752906284
Validation loss: 2.5370184584878

Epoch: 6| Step: 13
Training loss: 0.4608230448718874
Validation loss: 2.516040773502924

Epoch: 273| Step: 0
Training loss: 0.7975641898029769
Validation loss: 2.5086931597745523

Epoch: 6| Step: 1
Training loss: 1.0913546900219853
Validation loss: 2.540299315247562

Epoch: 6| Step: 2
Training loss: 0.6811911295031018
Validation loss: 2.5505120867297357

Epoch: 6| Step: 3
Training loss: 1.0050178637269176
Validation loss: 2.551682656037922

Epoch: 6| Step: 4
Training loss: 1.0241981184195912
Validation loss: 2.5575147437546146

Epoch: 6| Step: 5
Training loss: 0.8978020452520707
Validation loss: 2.557627842512534

Epoch: 6| Step: 6
Training loss: 1.1519876220753393
Validation loss: 2.5591816950324877

Epoch: 6| Step: 7
Training loss: 0.6483783924785502
Validation loss: 2.5680189749547906

Epoch: 6| Step: 8
Training loss: 1.2785472741246726
Validation loss: 2.5180887335689155

Epoch: 6| Step: 9
Training loss: 1.0272678593791058
Validation loss: 2.51689729775367

Epoch: 6| Step: 10
Training loss: 0.877376394776995
Validation loss: 2.534367342128953

Epoch: 6| Step: 11
Training loss: 0.9288992545439552
Validation loss: 2.5261848925848045

Epoch: 6| Step: 12
Training loss: 0.9865379185917468
Validation loss: 2.5098860131347642

Epoch: 6| Step: 13
Training loss: 1.1015631493099816
Validation loss: 2.547666993121212

Epoch: 274| Step: 0
Training loss: 0.7905654191195399
Validation loss: 2.561947884895758

Epoch: 6| Step: 1
Training loss: 1.017922839097744
Validation loss: 2.5134498967386705

Epoch: 6| Step: 2
Training loss: 0.965388773445366
Validation loss: 2.5197288441425503

Epoch: 6| Step: 3
Training loss: 0.9998695169196695
Validation loss: 2.5194091863970116

Epoch: 6| Step: 4
Training loss: 0.8665702616429626
Validation loss: 2.51036700652035

Epoch: 6| Step: 5
Training loss: 0.8183531112249096
Validation loss: 2.5279235859393463

Epoch: 6| Step: 6
Training loss: 1.1775888128459324
Validation loss: 2.522287387902629

Epoch: 6| Step: 7
Training loss: 0.5604253763517083
Validation loss: 2.5473681536819606

Epoch: 6| Step: 8
Training loss: 1.2568087630457512
Validation loss: 2.5438627750725993

Epoch: 6| Step: 9
Training loss: 1.193720736319672
Validation loss: 2.5551631730882582

Epoch: 6| Step: 10
Training loss: 1.2674068105926692
Validation loss: 2.5562878023404187

Epoch: 6| Step: 11
Training loss: 0.7560095428414513
Validation loss: 2.5672392061018128

Epoch: 6| Step: 12
Training loss: 0.883802584549957
Validation loss: 2.5770051604220336

Epoch: 6| Step: 13
Training loss: 0.4385860790618781
Validation loss: 2.571464325624861

Epoch: 275| Step: 0
Training loss: 0.870409196176666
Validation loss: 2.5603580661957945

Epoch: 6| Step: 1
Training loss: 1.1910753134449448
Validation loss: 2.536417927929432

Epoch: 6| Step: 2
Training loss: 1.1796292928520755
Validation loss: 2.524161273075449

Epoch: 6| Step: 3
Training loss: 0.5445154787075608
Validation loss: 2.5474474839966907

Epoch: 6| Step: 4
Training loss: 1.0092182262069067
Validation loss: 2.540895519211641

Epoch: 6| Step: 5
Training loss: 0.9533464768532943
Validation loss: 2.5191638014348343

Epoch: 6| Step: 6
Training loss: 1.277736125257944
Validation loss: 2.525223494939599

Epoch: 6| Step: 7
Training loss: 0.5791683833922413
Validation loss: 2.54731037931327

Epoch: 6| Step: 8
Training loss: 0.7789708653071339
Validation loss: 2.566023777074852

Epoch: 6| Step: 9
Training loss: 0.8559542110242152
Validation loss: 2.537365088641553

Epoch: 6| Step: 10
Training loss: 0.6151158052054531
Validation loss: 2.556960897998452

Epoch: 6| Step: 11
Training loss: 1.1344629300930238
Validation loss: 2.550795081341583

Epoch: 6| Step: 12
Training loss: 0.9357223505454667
Validation loss: 2.5652241402022407

Epoch: 6| Step: 13
Training loss: 1.245311575282578
Validation loss: 2.528832379312768

Epoch: 276| Step: 0
Training loss: 1.0230199529915094
Validation loss: 2.508319968870459

Epoch: 6| Step: 1
Training loss: 0.9688009125651685
Validation loss: 2.492220266037209

Epoch: 6| Step: 2
Training loss: 1.2246734261683558
Validation loss: 2.5052453971841215

Epoch: 6| Step: 3
Training loss: 1.1800419357089553
Validation loss: 2.502702898763095

Epoch: 6| Step: 4
Training loss: 0.8752716868812895
Validation loss: 2.5191929560755635

Epoch: 6| Step: 5
Training loss: 0.8262296255141793
Validation loss: 2.5183655023798126

Epoch: 6| Step: 6
Training loss: 0.8417481233503938
Validation loss: 2.551792828062765

Epoch: 6| Step: 7
Training loss: 0.9486455560322659
Validation loss: 2.539060650265559

Epoch: 6| Step: 8
Training loss: 0.831862132476637
Validation loss: 2.560242175185692

Epoch: 6| Step: 9
Training loss: 1.0839722778745033
Validation loss: 2.540181224338899

Epoch: 6| Step: 10
Training loss: 1.028821687112636
Validation loss: 2.5453643888820268

Epoch: 6| Step: 11
Training loss: 0.8890620789753163
Validation loss: 2.543366135514304

Epoch: 6| Step: 12
Training loss: 0.783719964858832
Validation loss: 2.5202390057794215

Epoch: 6| Step: 13
Training loss: 0.49738334886418173
Validation loss: 2.531534395455049

Epoch: 277| Step: 0
Training loss: 0.6773653812320348
Validation loss: 2.5008412801716187

Epoch: 6| Step: 1
Training loss: 0.25902290575447207
Validation loss: 2.527203863625218

Epoch: 6| Step: 2
Training loss: 1.1570706934519541
Validation loss: 2.4860696222179826

Epoch: 6| Step: 3
Training loss: 1.3073903486031269
Validation loss: 2.4875474959594457

Epoch: 6| Step: 4
Training loss: 1.0891666838673417
Validation loss: 2.4938480670948766

Epoch: 6| Step: 5
Training loss: 0.750598906763075
Validation loss: 2.4774156579045923

Epoch: 6| Step: 6
Training loss: 0.85813460564846
Validation loss: 2.4960044331200963

Epoch: 6| Step: 7
Training loss: 0.9570839380825082
Validation loss: 2.541572803745803

Epoch: 6| Step: 8
Training loss: 0.7442467881614876
Validation loss: 2.5059918616605903

Epoch: 6| Step: 9
Training loss: 0.9729579472956735
Validation loss: 2.5345986155250344

Epoch: 6| Step: 10
Training loss: 1.254322208800917
Validation loss: 2.557061110650579

Epoch: 6| Step: 11
Training loss: 0.7842035539351481
Validation loss: 2.521056165806887

Epoch: 6| Step: 12
Training loss: 1.1634319056710198
Validation loss: 2.536881926028093

Epoch: 6| Step: 13
Training loss: 0.7807139274088783
Validation loss: 2.555990978831077

Epoch: 278| Step: 0
Training loss: 0.7305685372965928
Validation loss: 2.5721466076535497

Epoch: 6| Step: 1
Training loss: 0.7467250050875232
Validation loss: 2.524248528297027

Epoch: 6| Step: 2
Training loss: 1.1161482452114935
Validation loss: 2.520437226938051

Epoch: 6| Step: 3
Training loss: 1.0403793136578752
Validation loss: 2.5089454130026234

Epoch: 6| Step: 4
Training loss: 1.2802963894926107
Validation loss: 2.4805779463174567

Epoch: 6| Step: 5
Training loss: 1.2376167608336888
Validation loss: 2.5301414309634302

Epoch: 6| Step: 6
Training loss: 0.7674110366629132
Validation loss: 2.515693875068463

Epoch: 6| Step: 7
Training loss: 0.8400489733815781
Validation loss: 2.5407977418473093

Epoch: 6| Step: 8
Training loss: 0.845688747081157
Validation loss: 2.554966487140969

Epoch: 6| Step: 9
Training loss: 1.0829871186875513
Validation loss: 2.5596061631698657

Epoch: 6| Step: 10
Training loss: 0.7646773955219675
Validation loss: 2.573556566785382

Epoch: 6| Step: 11
Training loss: 0.8818309019162531
Validation loss: 2.559759704203723

Epoch: 6| Step: 12
Training loss: 0.9983509294830442
Validation loss: 2.565502666532399

Epoch: 6| Step: 13
Training loss: 0.6226701943093722
Validation loss: 2.5497883990395636

Epoch: 279| Step: 0
Training loss: 0.4852864856957081
Validation loss: 2.5156323241673246

Epoch: 6| Step: 1
Training loss: 0.9121250257435863
Validation loss: 2.532242967469015

Epoch: 6| Step: 2
Training loss: 0.9016495713842111
Validation loss: 2.5533012589663144

Epoch: 6| Step: 3
Training loss: 0.8743601230449146
Validation loss: 2.528470935266504

Epoch: 6| Step: 4
Training loss: 0.830199217098127
Validation loss: 2.5718162738944947

Epoch: 6| Step: 5
Training loss: 0.8650112854767128
Validation loss: 2.5328784901311945

Epoch: 6| Step: 6
Training loss: 0.6245586744466353
Validation loss: 2.5342654020853796

Epoch: 6| Step: 7
Training loss: 1.0999237207494368
Validation loss: 2.565141859204992

Epoch: 6| Step: 8
Training loss: 1.146557261345063
Validation loss: 2.5400501182584807

Epoch: 6| Step: 9
Training loss: 1.1699750120803936
Validation loss: 2.527475938156346

Epoch: 6| Step: 10
Training loss: 1.11249935064404
Validation loss: 2.5313492176578474

Epoch: 6| Step: 11
Training loss: 1.1083531576310142
Validation loss: 2.5194186674597963

Epoch: 6| Step: 12
Training loss: 0.8565396786488373
Validation loss: 2.5342776999700294

Epoch: 6| Step: 13
Training loss: 0.438252024092627
Validation loss: 2.5441760336468957

Epoch: 280| Step: 0
Training loss: 0.8499086050376913
Validation loss: 2.5424494858312534

Epoch: 6| Step: 1
Training loss: 0.9179877096612521
Validation loss: 2.5378537969833244

Epoch: 6| Step: 2
Training loss: 0.8559958519322615
Validation loss: 2.5446899037362267

Epoch: 6| Step: 3
Training loss: 0.546706909505004
Validation loss: 2.5582941536967807

Epoch: 6| Step: 4
Training loss: 1.0806681175300636
Validation loss: 2.524937734787507

Epoch: 6| Step: 5
Training loss: 1.0334163222264032
Validation loss: 2.5776757985974283

Epoch: 6| Step: 6
Training loss: 1.006426901105732
Validation loss: 2.547503168118862

Epoch: 6| Step: 7
Training loss: 1.1580361668896455
Validation loss: 2.580574665209067

Epoch: 6| Step: 8
Training loss: 0.879202017291864
Validation loss: 2.536398184199296

Epoch: 6| Step: 9
Training loss: 0.8765085703533612
Validation loss: 2.5352053743456224

Epoch: 6| Step: 10
Training loss: 0.8549667348581044
Validation loss: 2.5434300491775037

Epoch: 6| Step: 11
Training loss: 1.0455852363718894
Validation loss: 2.5343429343086123

Epoch: 6| Step: 12
Training loss: 0.9488870174494723
Validation loss: 2.5888916526431234

Epoch: 6| Step: 13
Training loss: 0.5133408034336394
Validation loss: 2.562903268707824

Epoch: 281| Step: 0
Training loss: 0.9709326551382188
Validation loss: 2.589289528818522

Epoch: 6| Step: 1
Training loss: 1.1010095818403214
Validation loss: 2.5911445820908914

Epoch: 6| Step: 2
Training loss: 1.004950429348631
Validation loss: 2.5498349627163335

Epoch: 6| Step: 3
Training loss: 0.6278642825032709
Validation loss: 2.5578759133384823

Epoch: 6| Step: 4
Training loss: 0.697717301280799
Validation loss: 2.5602882298238105

Epoch: 6| Step: 5
Training loss: 0.9976929636199091
Validation loss: 2.533731296449087

Epoch: 6| Step: 6
Training loss: 0.45072225981356573
Validation loss: 2.54766052883511

Epoch: 6| Step: 7
Training loss: 0.9154886710582155
Validation loss: 2.5012442394583694

Epoch: 6| Step: 8
Training loss: 1.2664989703415557
Validation loss: 2.513020435817576

Epoch: 6| Step: 9
Training loss: 0.913183980155784
Validation loss: 2.489340106912691

Epoch: 6| Step: 10
Training loss: 0.8366934664741413
Validation loss: 2.4828813721613376

Epoch: 6| Step: 11
Training loss: 1.0278415416721525
Validation loss: 2.487396403840356

Epoch: 6| Step: 12
Training loss: 0.7116360847712756
Validation loss: 2.5036314466872924

Epoch: 6| Step: 13
Training loss: 0.9446362054535526
Validation loss: 2.5057011013231096

Epoch: 282| Step: 0
Training loss: 0.9245813375975525
Validation loss: 2.539734515669775

Epoch: 6| Step: 1
Training loss: 0.5619797419938992
Validation loss: 2.5169598179334174

Epoch: 6| Step: 2
Training loss: 0.9831553275152904
Validation loss: 2.5347467261067527

Epoch: 6| Step: 3
Training loss: 1.2621973978114003
Validation loss: 2.53749546458984

Epoch: 6| Step: 4
Training loss: 0.8777339322437482
Validation loss: 2.5445213739045296

Epoch: 6| Step: 5
Training loss: 0.47479274331451016
Validation loss: 2.575364093724083

Epoch: 6| Step: 6
Training loss: 1.1623916411401873
Validation loss: 2.5810159443778073

Epoch: 6| Step: 7
Training loss: 0.8754210140429591
Validation loss: 2.579045931399115

Epoch: 6| Step: 8
Training loss: 1.2504775088917595
Validation loss: 2.5699053542646317

Epoch: 6| Step: 9
Training loss: 0.724797062588312
Validation loss: 2.5755402555881903

Epoch: 6| Step: 10
Training loss: 0.9905658595966683
Validation loss: 2.5380289790986197

Epoch: 6| Step: 11
Training loss: 0.3877287112822928
Validation loss: 2.5635838691218504

Epoch: 6| Step: 12
Training loss: 0.885194013687298
Validation loss: 2.562451907151044

Epoch: 6| Step: 13
Training loss: 0.6235808711967034
Validation loss: 2.5414771283865116

Epoch: 283| Step: 0
Training loss: 1.0095888200695549
Validation loss: 2.5391749334565406

Epoch: 6| Step: 1
Training loss: 1.0006599632697735
Validation loss: 2.5394468419528264

Epoch: 6| Step: 2
Training loss: 0.8244351649797502
Validation loss: 2.545181277940922

Epoch: 6| Step: 3
Training loss: 0.9673937255687445
Validation loss: 2.5568253988655316

Epoch: 6| Step: 4
Training loss: 0.6966733794786328
Validation loss: 2.540078638542334

Epoch: 6| Step: 5
Training loss: 1.0435840634683076
Validation loss: 2.582109976536

Epoch: 6| Step: 6
Training loss: 0.7664802212262867
Validation loss: 2.554255605291153

Epoch: 6| Step: 7
Training loss: 0.8306000269342607
Validation loss: 2.5723851620484144

Epoch: 6| Step: 8
Training loss: 0.7154499256251029
Validation loss: 2.561919545026536

Epoch: 6| Step: 9
Training loss: 1.0425928131246576
Validation loss: 2.57683893657532

Epoch: 6| Step: 10
Training loss: 0.6759920177439885
Validation loss: 2.528043807060281

Epoch: 6| Step: 11
Training loss: 1.0055082134099165
Validation loss: 2.5417688195572357

Epoch: 6| Step: 12
Training loss: 1.0161552805472005
Validation loss: 2.5177764571337895

Epoch: 6| Step: 13
Training loss: 0.8391906683013877
Validation loss: 2.518713450702908

Epoch: 284| Step: 0
Training loss: 0.5310961276094032
Validation loss: 2.4921842334535733

Epoch: 6| Step: 1
Training loss: 1.2585752082088768
Validation loss: 2.5038525399608

Epoch: 6| Step: 2
Training loss: 1.100951113025226
Validation loss: 2.4944503036494647

Epoch: 6| Step: 3
Training loss: 0.9890080670508922
Validation loss: 2.5169239149314584

Epoch: 6| Step: 4
Training loss: 0.8555754503569568
Validation loss: 2.5102047771873517

Epoch: 6| Step: 5
Training loss: 0.9811846790318122
Validation loss: 2.5120117167701275

Epoch: 6| Step: 6
Training loss: 1.0090521352170059
Validation loss: 2.5037701317483303

Epoch: 6| Step: 7
Training loss: 0.8677961601941643
Validation loss: 2.509239853986553

Epoch: 6| Step: 8
Training loss: 0.6755874223519093
Validation loss: 2.541056769786723

Epoch: 6| Step: 9
Training loss: 1.0953100794875625
Validation loss: 2.5275124286599078

Epoch: 6| Step: 10
Training loss: 0.6443720534263752
Validation loss: 2.4908658341811636

Epoch: 6| Step: 11
Training loss: 0.7141482195331953
Validation loss: 2.5347164557614215

Epoch: 6| Step: 12
Training loss: 0.6156970509613227
Validation loss: 2.5704798993784053

Epoch: 6| Step: 13
Training loss: 0.5920455460522537
Validation loss: 2.5532599108725584

Epoch: 285| Step: 0
Training loss: 0.7992148733930642
Validation loss: 2.562254262887144

Epoch: 6| Step: 1
Training loss: 0.8861878271852246
Validation loss: 2.5732561113136074

Epoch: 6| Step: 2
Training loss: 0.8741529315515526
Validation loss: 2.5462650001651856

Epoch: 6| Step: 3
Training loss: 0.8298998113854232
Validation loss: 2.533486921744663

Epoch: 6| Step: 4
Training loss: 0.8852252229650571
Validation loss: 2.5280254653146774

Epoch: 6| Step: 5
Training loss: 0.9363406960698206
Validation loss: 2.5074345229695028

Epoch: 6| Step: 6
Training loss: 0.7786870496849462
Validation loss: 2.5121691060875624

Epoch: 6| Step: 7
Training loss: 0.9278723684379203
Validation loss: 2.4951012443054146

Epoch: 6| Step: 8
Training loss: 1.0453112865948442
Validation loss: 2.50570268460558

Epoch: 6| Step: 9
Training loss: 0.7023756696769481
Validation loss: 2.5178752493988332

Epoch: 6| Step: 10
Training loss: 1.3195804168954814
Validation loss: 2.511805126953173

Epoch: 6| Step: 11
Training loss: 0.513001443202794
Validation loss: 2.527899095619331

Epoch: 6| Step: 12
Training loss: 0.745631529147139
Validation loss: 2.536655460731131

Epoch: 6| Step: 13
Training loss: 0.834045550851988
Validation loss: 2.534207428140919

Epoch: 286| Step: 0
Training loss: 0.9078042415696296
Validation loss: 2.5167561620144565

Epoch: 6| Step: 1
Training loss: 0.8446653840066052
Validation loss: 2.515679294329179

Epoch: 6| Step: 2
Training loss: 0.9776535653078524
Validation loss: 2.4836251279089927

Epoch: 6| Step: 3
Training loss: 0.5200115077872808
Validation loss: 2.4921238162313135

Epoch: 6| Step: 4
Training loss: 0.7154240571804668
Validation loss: 2.50879905835143

Epoch: 6| Step: 5
Training loss: 0.896005972410205
Validation loss: 2.4656671549219387

Epoch: 6| Step: 6
Training loss: 0.9807336760890133
Validation loss: 2.5115636510609463

Epoch: 6| Step: 7
Training loss: 0.9860837123688193
Validation loss: 2.4990798015502564

Epoch: 6| Step: 8
Training loss: 0.9244646456298868
Validation loss: 2.499462056477969

Epoch: 6| Step: 9
Training loss: 0.7928328750031115
Validation loss: 2.480256115713158

Epoch: 6| Step: 10
Training loss: 1.0769793740035665
Validation loss: 2.463525014501609

Epoch: 6| Step: 11
Training loss: 1.1476944576211037
Validation loss: 2.4949065754065156

Epoch: 6| Step: 12
Training loss: 0.6094531473766881
Validation loss: 2.487856826752428

Epoch: 6| Step: 13
Training loss: 0.7783127309317458
Validation loss: 2.4999702944067437

Epoch: 287| Step: 0
Training loss: 0.9384006941948881
Validation loss: 2.497434514911781

Epoch: 6| Step: 1
Training loss: 0.9342413535592043
Validation loss: 2.492131402861153

Epoch: 6| Step: 2
Training loss: 0.6973193278855828
Validation loss: 2.5194488020953583

Epoch: 6| Step: 3
Training loss: 0.7917321997840727
Validation loss: 2.555057390101986

Epoch: 6| Step: 4
Training loss: 1.0078489311789804
Validation loss: 2.5506629307728015

Epoch: 6| Step: 5
Training loss: 1.2994614512650904
Validation loss: 2.546386939737288

Epoch: 6| Step: 6
Training loss: 0.7935522028259542
Validation loss: 2.5229198102952717

Epoch: 6| Step: 7
Training loss: 0.6169702654618375
Validation loss: 2.5373703525879656

Epoch: 6| Step: 8
Training loss: 0.6843526496895556
Validation loss: 2.487642118776591

Epoch: 6| Step: 9
Training loss: 0.541550492397349
Validation loss: 2.5112845543872013

Epoch: 6| Step: 10
Training loss: 0.7561901068812367
Validation loss: 2.4799070306679516

Epoch: 6| Step: 11
Training loss: 0.8647327217433783
Validation loss: 2.470614834768054

Epoch: 6| Step: 12
Training loss: 0.9706672339453017
Validation loss: 2.478182413133149

Epoch: 6| Step: 13
Training loss: 1.0536301575703166
Validation loss: 2.469150917207019

Epoch: 288| Step: 0
Training loss: 0.7466728000587641
Validation loss: 2.4947276499724773

Epoch: 6| Step: 1
Training loss: 1.037622931677445
Validation loss: 2.522353179318198

Epoch: 6| Step: 2
Training loss: 0.8433895400758518
Validation loss: 2.5059582966622984

Epoch: 6| Step: 3
Training loss: 0.5107483434944347
Validation loss: 2.51617234556338

Epoch: 6| Step: 4
Training loss: 0.7398479328621362
Validation loss: 2.533823759524684

Epoch: 6| Step: 5
Training loss: 0.7161774830615769
Validation loss: 2.546853632170129

Epoch: 6| Step: 6
Training loss: 0.8045828297509926
Validation loss: 2.514052489936267

Epoch: 6| Step: 7
Training loss: 0.7687946802816616
Validation loss: 2.5484538290238627

Epoch: 6| Step: 8
Training loss: 1.1028793796355931
Validation loss: 2.5086724615583282

Epoch: 6| Step: 9
Training loss: 0.8766922934549267
Validation loss: 2.5160274470318185

Epoch: 6| Step: 10
Training loss: 0.8705049586190459
Validation loss: 2.5237280215107756

Epoch: 6| Step: 11
Training loss: 1.0044736334956126
Validation loss: 2.5021397944303554

Epoch: 6| Step: 12
Training loss: 0.956787452006589
Validation loss: 2.5270883573437137

Epoch: 6| Step: 13
Training loss: 1.0684850085380042
Validation loss: 2.513328439991679

Epoch: 289| Step: 0
Training loss: 0.7597477378798986
Validation loss: 2.514435292350319

Epoch: 6| Step: 1
Training loss: 1.0719242073530708
Validation loss: 2.530331216879401

Epoch: 6| Step: 2
Training loss: 0.8545473963749551
Validation loss: 2.4983049137383566

Epoch: 6| Step: 3
Training loss: 0.8658496744145469
Validation loss: 2.4779666020491593

Epoch: 6| Step: 4
Training loss: 0.7861347079994617
Validation loss: 2.4908212265021064

Epoch: 6| Step: 5
Training loss: 0.8747679879627711
Validation loss: 2.4711968645808575

Epoch: 6| Step: 6
Training loss: 0.991784502022104
Validation loss: 2.4995412590233643

Epoch: 6| Step: 7
Training loss: 0.9744546343136387
Validation loss: 2.510761752123988

Epoch: 6| Step: 8
Training loss: 0.936509881105449
Validation loss: 2.5687219035825124

Epoch: 6| Step: 9
Training loss: 0.8814891247265099
Validation loss: 2.55693391104008

Epoch: 6| Step: 10
Training loss: 0.7755152988855487
Validation loss: 2.599147406943728

Epoch: 6| Step: 11
Training loss: 0.7681859451463188
Validation loss: 2.5814052284136246

Epoch: 6| Step: 12
Training loss: 0.5491894655844766
Validation loss: 2.5949136313349705

Epoch: 6| Step: 13
Training loss: 0.7145664948980962
Validation loss: 2.5929873348811197

Epoch: 290| Step: 0
Training loss: 0.9981422154823597
Validation loss: 2.5558013098608874

Epoch: 6| Step: 1
Training loss: 0.6693676582881247
Validation loss: 2.4949015044433307

Epoch: 6| Step: 2
Training loss: 0.933720217003821
Validation loss: 2.5115583340473

Epoch: 6| Step: 3
Training loss: 0.9217258268020954
Validation loss: 2.501741739837242

Epoch: 6| Step: 4
Training loss: 0.8411508723404277
Validation loss: 2.4634863640790234

Epoch: 6| Step: 5
Training loss: 0.6454870823750317
Validation loss: 2.4464168749760016

Epoch: 6| Step: 6
Training loss: 0.974555952484755
Validation loss: 2.46366877382843

Epoch: 6| Step: 7
Training loss: 0.982049040834273
Validation loss: 2.452201397157468

Epoch: 6| Step: 8
Training loss: 0.7680851860684864
Validation loss: 2.482245515690378

Epoch: 6| Step: 9
Training loss: 0.7394477066188129
Validation loss: 2.474187859777635

Epoch: 6| Step: 10
Training loss: 0.8799296206811029
Validation loss: 2.4595880421074847

Epoch: 6| Step: 11
Training loss: 0.8259764095152007
Validation loss: 2.504320242858215

Epoch: 6| Step: 12
Training loss: 0.899652306629252
Validation loss: 2.5077735065470823

Epoch: 6| Step: 13
Training loss: 0.8224154809235943
Validation loss: 2.529042344552453

Epoch: 291| Step: 0
Training loss: 0.7581931269289643
Validation loss: 2.52013201217872

Epoch: 6| Step: 1
Training loss: 0.6944437493214837
Validation loss: 2.506606974963932

Epoch: 6| Step: 2
Training loss: 1.2221335369263369
Validation loss: 2.4859201367052366

Epoch: 6| Step: 3
Training loss: 0.9237764759424923
Validation loss: 2.494144183981109

Epoch: 6| Step: 4
Training loss: 0.7101059966147467
Validation loss: 2.470250448534529

Epoch: 6| Step: 5
Training loss: 0.574044129685635
Validation loss: 2.474387188167856

Epoch: 6| Step: 6
Training loss: 1.0432929631630194
Validation loss: 2.482097349148179

Epoch: 6| Step: 7
Training loss: 1.1173623221668556
Validation loss: 2.5205116490463775

Epoch: 6| Step: 8
Training loss: 1.1150319037555931
Validation loss: 2.5253403016723754

Epoch: 6| Step: 9
Training loss: 0.43710314257885596
Validation loss: 2.5467166424864174

Epoch: 6| Step: 10
Training loss: 0.4296633106705582
Validation loss: 2.5302664900658964

Epoch: 6| Step: 11
Training loss: 0.9378616271328379
Validation loss: 2.526961961582516

Epoch: 6| Step: 12
Training loss: 0.5936328119778858
Validation loss: 2.5212712454589723

Epoch: 6| Step: 13
Training loss: 0.7660100319058541
Validation loss: 2.542658880645093

Epoch: 292| Step: 0
Training loss: 0.7973555817381245
Validation loss: 2.5159630828201998

Epoch: 6| Step: 1
Training loss: 0.7647064693640704
Validation loss: 2.527554778121577

Epoch: 6| Step: 2
Training loss: 1.1576075960743142
Validation loss: 2.503255588624223

Epoch: 6| Step: 3
Training loss: 1.01879388445549
Validation loss: 2.5137917629725313

Epoch: 6| Step: 4
Training loss: 0.8988853996692717
Validation loss: 2.5028074559553426

Epoch: 6| Step: 5
Training loss: 0.3824763086873186
Validation loss: 2.525425875704933

Epoch: 6| Step: 6
Training loss: 0.7199271969280282
Validation loss: 2.5236702920873126

Epoch: 6| Step: 7
Training loss: 0.5921090942253295
Validation loss: 2.488736496765301

Epoch: 6| Step: 8
Training loss: 1.0771732828935647
Validation loss: 2.4996145140923725

Epoch: 6| Step: 9
Training loss: 0.594717717848782
Validation loss: 2.4981157103081753

Epoch: 6| Step: 10
Training loss: 0.5674745679189798
Validation loss: 2.5199480270883394

Epoch: 6| Step: 11
Training loss: 1.0060638516185891
Validation loss: 2.5217519154492596

Epoch: 6| Step: 12
Training loss: 0.9317347001215931
Validation loss: 2.5104264123116695

Epoch: 6| Step: 13
Training loss: 0.9158930584665831
Validation loss: 2.5247173268469263

Epoch: 293| Step: 0
Training loss: 1.106305456118494
Validation loss: 2.501182256097323

Epoch: 6| Step: 1
Training loss: 1.0099492450274088
Validation loss: 2.5024521112780795

Epoch: 6| Step: 2
Training loss: 0.8290223352255695
Validation loss: 2.488738918522771

Epoch: 6| Step: 3
Training loss: 0.8616740944048477
Validation loss: 2.4904947811396427

Epoch: 6| Step: 4
Training loss: 1.018193796361406
Validation loss: 2.5012972890832033

Epoch: 6| Step: 5
Training loss: 0.5367918428405285
Validation loss: 2.505632903614391

Epoch: 6| Step: 6
Training loss: 0.7928340026922677
Validation loss: 2.4762893007971476

Epoch: 6| Step: 7
Training loss: 0.6573491655239543
Validation loss: 2.469873545736276

Epoch: 6| Step: 8
Training loss: 0.6267381103309969
Validation loss: 2.4782843108387453

Epoch: 6| Step: 9
Training loss: 0.6728710509469051
Validation loss: 2.4825280897931044

Epoch: 6| Step: 10
Training loss: 1.0406582847060526
Validation loss: 2.4986600066240086

Epoch: 6| Step: 11
Training loss: 0.6765820383682134
Validation loss: 2.5191290502986865

Epoch: 6| Step: 12
Training loss: 0.7728959702002596
Validation loss: 2.493627154449479

Epoch: 6| Step: 13
Training loss: 0.8159802068946423
Validation loss: 2.482957012862768

Epoch: 294| Step: 0
Training loss: 0.9873717876690666
Validation loss: 2.4958876031478265

Epoch: 6| Step: 1
Training loss: 0.6232597441846865
Validation loss: 2.4903757573881973

Epoch: 6| Step: 2
Training loss: 0.8032870652367283
Validation loss: 2.468781807111623

Epoch: 6| Step: 3
Training loss: 0.6936509285028524
Validation loss: 2.500665947190883

Epoch: 6| Step: 4
Training loss: 1.0203254500263912
Validation loss: 2.527000722349884

Epoch: 6| Step: 5
Training loss: 0.8325858976250639
Validation loss: 2.547880481444273

Epoch: 6| Step: 6
Training loss: 1.0056904178676862
Validation loss: 2.552057652765936

Epoch: 6| Step: 7
Training loss: 0.7113552333436306
Validation loss: 2.523205037980021

Epoch: 6| Step: 8
Training loss: 0.735357803784312
Validation loss: 2.5493360293179275

Epoch: 6| Step: 9
Training loss: 0.8910602710581214
Validation loss: 2.532652374912828

Epoch: 6| Step: 10
Training loss: 0.7324289957336146
Validation loss: 2.5291092303549787

Epoch: 6| Step: 11
Training loss: 0.5202001123793414
Validation loss: 2.515256759604873

Epoch: 6| Step: 12
Training loss: 0.7688704233518633
Validation loss: 2.4978811832266774

Epoch: 6| Step: 13
Training loss: 0.9996507750118596
Validation loss: 2.5062346835135476

Epoch: 295| Step: 0
Training loss: 0.9197672655289747
Validation loss: 2.4865222798358984

Epoch: 6| Step: 1
Training loss: 0.8205248603239312
Validation loss: 2.5135764227315356

Epoch: 6| Step: 2
Training loss: 0.6459135779909554
Validation loss: 2.474886585606518

Epoch: 6| Step: 3
Training loss: 0.8168905181694986
Validation loss: 2.4904568084198915

Epoch: 6| Step: 4
Training loss: 0.8497861831673914
Validation loss: 2.520834953723191

Epoch: 6| Step: 5
Training loss: 0.5215897757207563
Validation loss: 2.525680609219563

Epoch: 6| Step: 6
Training loss: 0.48797016152145073
Validation loss: 2.5344582050498494

Epoch: 6| Step: 7
Training loss: 1.0329310846854856
Validation loss: 2.514027375528747

Epoch: 6| Step: 8
Training loss: 0.6972843883564991
Validation loss: 2.5358872933265446

Epoch: 6| Step: 9
Training loss: 0.7774968978844483
Validation loss: 2.5061984120535357

Epoch: 6| Step: 10
Training loss: 0.8454875010418722
Validation loss: 2.5206638358183246

Epoch: 6| Step: 11
Training loss: 0.8422504451067759
Validation loss: 2.5182480616293894

Epoch: 6| Step: 12
Training loss: 1.1333264467553739
Validation loss: 2.531944800388929

Epoch: 6| Step: 13
Training loss: 0.6021230983692223
Validation loss: 2.54728465683338

Epoch: 296| Step: 0
Training loss: 0.7803411156017658
Validation loss: 2.5174623074180156

Epoch: 6| Step: 1
Training loss: 0.7517501358904904
Validation loss: 2.526530440886067

Epoch: 6| Step: 2
Training loss: 0.9731716031655279
Validation loss: 2.5346921504221216

Epoch: 6| Step: 3
Training loss: 0.6583136853372464
Validation loss: 2.5405755817002706

Epoch: 6| Step: 4
Training loss: 1.0284831179919511
Validation loss: 2.520828758268816

Epoch: 6| Step: 5
Training loss: 0.7674977500708589
Validation loss: 2.508341656781004

Epoch: 6| Step: 6
Training loss: 0.4702455029341025
Validation loss: 2.52037894712287

Epoch: 6| Step: 7
Training loss: 0.5387851443853839
Validation loss: 2.543739055621994

Epoch: 6| Step: 8
Training loss: 0.9675658587531808
Validation loss: 2.5508144121288754

Epoch: 6| Step: 9
Training loss: 0.6484413606459809
Validation loss: 2.5633747129584656

Epoch: 6| Step: 10
Training loss: 0.8144720793423549
Validation loss: 2.5436391239029033

Epoch: 6| Step: 11
Training loss: 0.7093884706268497
Validation loss: 2.507479766504628

Epoch: 6| Step: 12
Training loss: 0.9760926604138909
Validation loss: 2.49496558278084

Epoch: 6| Step: 13
Training loss: 0.9944416781931028
Validation loss: 2.4860507563008865

Epoch: 297| Step: 0
Training loss: 0.9150912372773597
Validation loss: 2.446042134384652

Epoch: 6| Step: 1
Training loss: 0.7491984852903322
Validation loss: 2.4872341666748854

Epoch: 6| Step: 2
Training loss: 1.0530898815604581
Validation loss: 2.5025023877756953

Epoch: 6| Step: 3
Training loss: 1.0225296070317327
Validation loss: 2.5058150905001537

Epoch: 6| Step: 4
Training loss: 0.37733380954199036
Validation loss: 2.5102474737886498

Epoch: 6| Step: 5
Training loss: 0.5102612070537802
Validation loss: 2.505606012505773

Epoch: 6| Step: 6
Training loss: 0.470661430569981
Validation loss: 2.5062237496553945

Epoch: 6| Step: 7
Training loss: 0.6230344860794375
Validation loss: 2.5335130033860116

Epoch: 6| Step: 8
Training loss: 0.8817377891289883
Validation loss: 2.51050713257449

Epoch: 6| Step: 9
Training loss: 0.6805961717327534
Validation loss: 2.5327837667577415

Epoch: 6| Step: 10
Training loss: 1.0336753761082864
Validation loss: 2.5135079894139394

Epoch: 6| Step: 11
Training loss: 0.9037832692460981
Validation loss: 2.501835569632971

Epoch: 6| Step: 12
Training loss: 0.6482467370765796
Validation loss: 2.529832691054698

Epoch: 6| Step: 13
Training loss: 0.850905733835957
Validation loss: 2.5025456214571866

Epoch: 298| Step: 0
Training loss: 0.9267180326745552
Validation loss: 2.4725240585780948

Epoch: 6| Step: 1
Training loss: 0.7497724744271831
Validation loss: 2.5143141921483143

Epoch: 6| Step: 2
Training loss: 0.5774641383790126
Validation loss: 2.5144303535525405

Epoch: 6| Step: 3
Training loss: 0.5693783883288132
Validation loss: 2.526556894683744

Epoch: 6| Step: 4
Training loss: 1.2732000773207832
Validation loss: 2.519397634562878

Epoch: 6| Step: 5
Training loss: 0.9682446053628231
Validation loss: 2.503865249331634

Epoch: 6| Step: 6
Training loss: 0.5490340257273008
Validation loss: 2.530231791110985

Epoch: 6| Step: 7
Training loss: 0.7252378386037038
Validation loss: 2.560740098897779

Epoch: 6| Step: 8
Training loss: 0.5566590958592504
Validation loss: 2.514378926877635

Epoch: 6| Step: 9
Training loss: 0.4888289469790822
Validation loss: 2.534359993203677

Epoch: 6| Step: 10
Training loss: 0.8693656030142938
Validation loss: 2.528931559023261

Epoch: 6| Step: 11
Training loss: 0.6115710717225746
Validation loss: 2.5517922287931842

Epoch: 6| Step: 12
Training loss: 0.8642125004673621
Validation loss: 2.5043459475124727

Epoch: 6| Step: 13
Training loss: 0.6670923115993594
Validation loss: 2.521680441602832

Epoch: 299| Step: 0
Training loss: 0.8801647077655526
Validation loss: 2.4893741719745486

Epoch: 6| Step: 1
Training loss: 0.47444961747560005
Validation loss: 2.4820266307907244

Epoch: 6| Step: 2
Training loss: 0.8444945264766512
Validation loss: 2.486870533192458

Epoch: 6| Step: 3
Training loss: 0.7234800849393389
Validation loss: 2.518792388350886

Epoch: 6| Step: 4
Training loss: 0.8050420035782789
Validation loss: 2.5039174970381564

Epoch: 6| Step: 5
Training loss: 0.7075996432549854
Validation loss: 2.503784223811466

Epoch: 6| Step: 6
Training loss: 0.5364096227462614
Validation loss: 2.511136834310526

Epoch: 6| Step: 7
Training loss: 0.834215797637728
Validation loss: 2.498451085330652

Epoch: 6| Step: 8
Training loss: 0.5834789321482519
Validation loss: 2.513282889648232

Epoch: 6| Step: 9
Training loss: 0.8268850508444496
Validation loss: 2.495103549946094

Epoch: 6| Step: 10
Training loss: 0.8935763663908791
Validation loss: 2.53702516916619

Epoch: 6| Step: 11
Training loss: 1.026393552490523
Validation loss: 2.525628022017418

Epoch: 6| Step: 12
Training loss: 0.4483955802331289
Validation loss: 2.5591008736859227

Epoch: 6| Step: 13
Training loss: 1.1587038549886999
Validation loss: 2.5429946345894003

Epoch: 300| Step: 0
Training loss: 0.7108464444715172
Validation loss: 2.5212218445319263

Epoch: 6| Step: 1
Training loss: 1.0018998219252402
Validation loss: 2.518932852274195

Epoch: 6| Step: 2
Training loss: 0.5484861890258993
Validation loss: 2.525491421927957

Epoch: 6| Step: 3
Training loss: 1.042200155338619
Validation loss: 2.53770981062729

Epoch: 6| Step: 4
Training loss: 0.590626077802371
Validation loss: 2.5087977708078864

Epoch: 6| Step: 5
Training loss: 0.47782599131347064
Validation loss: 2.4936727749474685

Epoch: 6| Step: 6
Training loss: 0.924739718546849
Validation loss: 2.4995258148214288

Epoch: 6| Step: 7
Training loss: 0.657919440558563
Validation loss: 2.492486272912264

Epoch: 6| Step: 8
Training loss: 0.9438677379605128
Validation loss: 2.479889713496172

Epoch: 6| Step: 9
Training loss: 0.6943829355550386
Validation loss: 2.4810527211960967

Epoch: 6| Step: 10
Training loss: 0.7628898030719539
Validation loss: 2.5071293480487733

Epoch: 6| Step: 11
Training loss: 0.5867825835306723
Validation loss: 2.5039907331159235

Epoch: 6| Step: 12
Training loss: 0.6694392030844039
Validation loss: 2.50107809837036

Epoch: 6| Step: 13
Training loss: 0.686517034422098
Validation loss: 2.504129572830732

Epoch: 301| Step: 0
Training loss: 0.9574741506448815
Validation loss: 2.4928281232450287

Epoch: 6| Step: 1
Training loss: 0.7224848363532456
Validation loss: 2.512298574726706

Epoch: 6| Step: 2
Training loss: 0.7148996133290754
Validation loss: 2.459765231203922

Epoch: 6| Step: 3
Training loss: 0.8012664069580314
Validation loss: 2.466533560544156

Epoch: 6| Step: 4
Training loss: 0.40208595312908874
Validation loss: 2.5016200430906554

Epoch: 6| Step: 5
Training loss: 0.7829204629545832
Validation loss: 2.504200315028439

Epoch: 6| Step: 6
Training loss: 0.6371703623309347
Validation loss: 2.5177312171295183

Epoch: 6| Step: 7
Training loss: 0.8084762045520411
Validation loss: 2.517960310473885

Epoch: 6| Step: 8
Training loss: 0.7962280339874651
Validation loss: 2.52129732026573

Epoch: 6| Step: 9
Training loss: 0.7891122783407086
Validation loss: 2.5244504733685003

Epoch: 6| Step: 10
Training loss: 0.8890062310994877
Validation loss: 2.4982888569730144

Epoch: 6| Step: 11
Training loss: 0.5641486854965257
Validation loss: 2.511738180199779

Epoch: 6| Step: 12
Training loss: 0.7075800162314628
Validation loss: 2.4868007062215596

Epoch: 6| Step: 13
Training loss: 0.8140366035779483
Validation loss: 2.494177205430389

Epoch: 302| Step: 0
Training loss: 0.7128006551745965
Validation loss: 2.5265044454552346

Epoch: 6| Step: 1
Training loss: 0.5077341459420224
Validation loss: 2.500173881595519

Epoch: 6| Step: 2
Training loss: 0.7149717706162725
Validation loss: 2.506083930362968

Epoch: 6| Step: 3
Training loss: 0.6221775938555021
Validation loss: 2.5512649747581437

Epoch: 6| Step: 4
Training loss: 0.6683214383085444
Validation loss: 2.505630530926261

Epoch: 6| Step: 5
Training loss: 0.8584919640948693
Validation loss: 2.5418991486530036

Epoch: 6| Step: 6
Training loss: 0.908190950701753
Validation loss: 2.5243835819319704

Epoch: 6| Step: 7
Training loss: 0.6623836388155087
Validation loss: 2.518346454921734

Epoch: 6| Step: 8
Training loss: 0.6932995622652488
Validation loss: 2.4941749246296667

Epoch: 6| Step: 9
Training loss: 0.9796332336679446
Validation loss: 2.48897440489697

Epoch: 6| Step: 10
Training loss: 0.6267361844932487
Validation loss: 2.495929284379063

Epoch: 6| Step: 11
Training loss: 0.8842921053045579
Validation loss: 2.501077678114491

Epoch: 6| Step: 12
Training loss: 0.31609122759443825
Validation loss: 2.5213806919492043

Epoch: 6| Step: 13
Training loss: 1.0797360311330173
Validation loss: 2.4867136256799593

Epoch: 303| Step: 0
Training loss: 0.41213211792296955
Validation loss: 2.482892322079966

Epoch: 6| Step: 1
Training loss: 0.8013165801262542
Validation loss: 2.4906524097570326

Epoch: 6| Step: 2
Training loss: 0.6209611811199396
Validation loss: 2.5349347766626797

Epoch: 6| Step: 3
Training loss: 0.6038840690773534
Validation loss: 2.5411246609611235

Epoch: 6| Step: 4
Training loss: 0.7725258666093556
Validation loss: 2.5412529464588465

Epoch: 6| Step: 5
Training loss: 0.6155565175340819
Validation loss: 2.5304727934768394

Epoch: 6| Step: 6
Training loss: 0.642775206793799
Validation loss: 2.524153197196407

Epoch: 6| Step: 7
Training loss: 0.7941820981013175
Validation loss: 2.5224856899789807

Epoch: 6| Step: 8
Training loss: 0.9435605926423644
Validation loss: 2.506909852223891

Epoch: 6| Step: 9
Training loss: 0.4578474207244005
Validation loss: 2.5188985422052323

Epoch: 6| Step: 10
Training loss: 0.8226539256759514
Validation loss: 2.502414195531315

Epoch: 6| Step: 11
Training loss: 1.0989968472401708
Validation loss: 2.522007469346197

Epoch: 6| Step: 12
Training loss: 0.5934156178984472
Validation loss: 2.51221208207838

Epoch: 6| Step: 13
Training loss: 0.9131534000708779
Validation loss: 2.5026386569298347

Epoch: 304| Step: 0
Training loss: 0.9097752244245529
Validation loss: 2.5151151572164943

Epoch: 6| Step: 1
Training loss: 0.6945077761275856
Validation loss: 2.52218695996538

Epoch: 6| Step: 2
Training loss: 0.5421410983234985
Validation loss: 2.4903262809508298

Epoch: 6| Step: 3
Training loss: 0.44589506491389436
Validation loss: 2.4997901033662115

Epoch: 6| Step: 4
Training loss: 0.6524563994766843
Validation loss: 2.523037926733785

Epoch: 6| Step: 5
Training loss: 0.8776258169761803
Validation loss: 2.5199735062071285

Epoch: 6| Step: 6
Training loss: 0.5059199057636469
Validation loss: 2.4987020948389924

Epoch: 6| Step: 7
Training loss: 0.7210850311115886
Validation loss: 2.559279001430821

Epoch: 6| Step: 8
Training loss: 0.663737004111556
Validation loss: 2.5432029044078153

Epoch: 6| Step: 9
Training loss: 0.9310164369920662
Validation loss: 2.548398250176657

Epoch: 6| Step: 10
Training loss: 1.2095387902349424
Validation loss: 2.530837923449376

Epoch: 6| Step: 11
Training loss: 0.775789633837188
Validation loss: 2.499131991327872

Epoch: 6| Step: 12
Training loss: 0.2574573440312557
Validation loss: 2.5219394935271815

Epoch: 6| Step: 13
Training loss: 0.6047448291265759
Validation loss: 2.5011588466627117

Epoch: 305| Step: 0
Training loss: 0.9769918489770164
Validation loss: 2.481647262455509

Epoch: 6| Step: 1
Training loss: 0.6214444112246651
Validation loss: 2.445712694244886

Epoch: 6| Step: 2
Training loss: 0.7295929661682574
Validation loss: 2.453521451938207

Epoch: 6| Step: 3
Training loss: 0.8342375181280055
Validation loss: 2.460331053135741

Epoch: 6| Step: 4
Training loss: 0.6006669152725388
Validation loss: 2.4635624244153798

Epoch: 6| Step: 5
Training loss: 0.7105484621136154
Validation loss: 2.4683376033749043

Epoch: 6| Step: 6
Training loss: 0.5672253703776113
Validation loss: 2.5249825560556998

Epoch: 6| Step: 7
Training loss: 0.9484236412984012
Validation loss: 2.5131497795020006

Epoch: 6| Step: 8
Training loss: 0.6841114372778381
Validation loss: 2.5181064431799567

Epoch: 6| Step: 9
Training loss: 0.5572190341380737
Validation loss: 2.5267508859795353

Epoch: 6| Step: 10
Training loss: 0.9615979289959268
Validation loss: 2.5208454733501755

Epoch: 6| Step: 11
Training loss: 0.7407719816357462
Validation loss: 2.5050674148810868

Epoch: 6| Step: 12
Training loss: 0.6485737117501481
Validation loss: 2.5226715824305033

Epoch: 6| Step: 13
Training loss: 0.39922960867549834
Validation loss: 2.4516569057659647

Epoch: 306| Step: 0
Training loss: 0.7074351974572508
Validation loss: 2.4816041109707547

Epoch: 6| Step: 1
Training loss: 0.5345336466637668
Validation loss: 2.45062239712378

Epoch: 6| Step: 2
Training loss: 0.8824240243319019
Validation loss: 2.48587070152926

Epoch: 6| Step: 3
Training loss: 0.48769657988836185
Validation loss: 2.484622498500748

Epoch: 6| Step: 4
Training loss: 0.5267748554486796
Validation loss: 2.504419553905043

Epoch: 6| Step: 5
Training loss: 0.6142582976759312
Validation loss: 2.5298609019296614

Epoch: 6| Step: 6
Training loss: 0.9461673622883622
Validation loss: 2.517066819062487

Epoch: 6| Step: 7
Training loss: 0.42609999039056173
Validation loss: 2.555331090860482

Epoch: 6| Step: 8
Training loss: 0.8380712567876939
Validation loss: 2.5495385101245174

Epoch: 6| Step: 9
Training loss: 1.0106611578706497
Validation loss: 2.5827326623725066

Epoch: 6| Step: 10
Training loss: 0.7672507483365911
Validation loss: 2.597550021292598

Epoch: 6| Step: 11
Training loss: 0.9606461742402972
Validation loss: 2.5995796794663284

Epoch: 6| Step: 12
Training loss: 0.5322903376175127
Validation loss: 2.5930447485086368

Epoch: 6| Step: 13
Training loss: 0.8674243225596352
Validation loss: 2.5761440747387225

Epoch: 307| Step: 0
Training loss: 0.9649999700556142
Validation loss: 2.6060773863001025

Epoch: 6| Step: 1
Training loss: 0.5416281362425601
Validation loss: 2.566332084935303

Epoch: 6| Step: 2
Training loss: 0.6101728253915554
Validation loss: 2.5857289156444154

Epoch: 6| Step: 3
Training loss: 0.4532046248094362
Validation loss: 2.530074727478286

Epoch: 6| Step: 4
Training loss: 0.7491795502751093
Validation loss: 2.5413664713320827

Epoch: 6| Step: 5
Training loss: 0.7353575606183825
Validation loss: 2.541269538297902

Epoch: 6| Step: 6
Training loss: 0.9931625021112988
Validation loss: 2.4997933302331563

Epoch: 6| Step: 7
Training loss: 0.8702463724158825
Validation loss: 2.5275181249284686

Epoch: 6| Step: 8
Training loss: 0.7693872074921981
Validation loss: 2.5655620157387307

Epoch: 6| Step: 9
Training loss: 0.6293487177023459
Validation loss: 2.5595309301697085

Epoch: 6| Step: 10
Training loss: 0.5438929589107031
Validation loss: 2.5407925556311466

Epoch: 6| Step: 11
Training loss: 0.7431700376653888
Validation loss: 2.5591839359291

Epoch: 6| Step: 12
Training loss: 0.5411615553607564
Validation loss: 2.5631954230916243

Epoch: 6| Step: 13
Training loss: 0.7368920390429625
Validation loss: 2.5486193381442885

Epoch: 308| Step: 0
Training loss: 0.5618856306841951
Validation loss: 2.5349554460204002

Epoch: 6| Step: 1
Training loss: 0.9145099164363594
Validation loss: 2.544252266314763

Epoch: 6| Step: 2
Training loss: 0.6413084664191452
Validation loss: 2.5201658461662872

Epoch: 6| Step: 3
Training loss: 0.38945086448878113
Validation loss: 2.531563122057156

Epoch: 6| Step: 4
Training loss: 1.0065700353786275
Validation loss: 2.5140657957747266

Epoch: 6| Step: 5
Training loss: 0.8311859636809595
Validation loss: 2.5246483587892317

Epoch: 6| Step: 6
Training loss: 0.6116090561694627
Validation loss: 2.4924393362459574

Epoch: 6| Step: 7
Training loss: 0.5448436612565909
Validation loss: 2.4958390268927872

Epoch: 6| Step: 8
Training loss: 0.7547298932854688
Validation loss: 2.4737372293852387

Epoch: 6| Step: 9
Training loss: 0.4879263389105412
Validation loss: 2.4860855026822057

Epoch: 6| Step: 10
Training loss: 0.5317060532624753
Validation loss: 2.506755976491028

Epoch: 6| Step: 11
Training loss: 0.6966389423045017
Validation loss: 2.5130752760757735

Epoch: 6| Step: 12
Training loss: 1.1351007436162943
Validation loss: 2.511919544871948

Epoch: 6| Step: 13
Training loss: 0.3660072879391366
Validation loss: 2.515050748761853

Epoch: 309| Step: 0
Training loss: 0.672006860258076
Validation loss: 2.514693756157105

Epoch: 6| Step: 1
Training loss: 0.7790752659871426
Validation loss: 2.530052530252516

Epoch: 6| Step: 2
Training loss: 0.7425287767093512
Validation loss: 2.493475686354289

Epoch: 6| Step: 3
Training loss: 0.36039853500593455
Validation loss: 2.5340659337362084

Epoch: 6| Step: 4
Training loss: 0.7782986397400131
Validation loss: 2.507038921139859

Epoch: 6| Step: 5
Training loss: 0.4447050636399096
Validation loss: 2.521561537694689

Epoch: 6| Step: 6
Training loss: 0.7784781684803412
Validation loss: 2.525267584255831

Epoch: 6| Step: 7
Training loss: 0.5801690284067615
Validation loss: 2.5135950004605383

Epoch: 6| Step: 8
Training loss: 0.42519728835789733
Validation loss: 2.5274636949144726

Epoch: 6| Step: 9
Training loss: 0.951516968087202
Validation loss: 2.566845646331003

Epoch: 6| Step: 10
Training loss: 1.0520377888909007
Validation loss: 2.571412507239937

Epoch: 6| Step: 11
Training loss: 0.5608367701968824
Validation loss: 2.579726624644465

Epoch: 6| Step: 12
Training loss: 0.7760924806962713
Validation loss: 2.5710556048731914

Epoch: 6| Step: 13
Training loss: 0.6878196233426453
Validation loss: 2.545175821647365

Epoch: 310| Step: 0
Training loss: 0.7031581023159511
Validation loss: 2.5256994907300245

Epoch: 6| Step: 1
Training loss: 0.5278239571574012
Validation loss: 2.5212098103829295

Epoch: 6| Step: 2
Training loss: 0.7937781051105486
Validation loss: 2.514149879376871

Epoch: 6| Step: 3
Training loss: 1.1100815685475733
Validation loss: 2.5142283056872086

Epoch: 6| Step: 4
Training loss: 0.5078007329897944
Validation loss: 2.4902032166344763

Epoch: 6| Step: 5
Training loss: 0.5632563380474439
Validation loss: 2.512750866889107

Epoch: 6| Step: 6
Training loss: 0.4081398946897867
Validation loss: 2.484921293742324

Epoch: 6| Step: 7
Training loss: 0.8606209825631137
Validation loss: 2.4701355254562003

Epoch: 6| Step: 8
Training loss: 1.0662090971637865
Validation loss: 2.479138598994551

Epoch: 6| Step: 9
Training loss: 0.759793200151803
Validation loss: 2.4924229516354526

Epoch: 6| Step: 10
Training loss: 0.7956502515766679
Validation loss: 2.5318382984287537

Epoch: 6| Step: 11
Training loss: 0.5949864563482422
Validation loss: 2.5040367923934825

Epoch: 6| Step: 12
Training loss: 0.49072253478698746
Validation loss: 2.5327483178371395

Epoch: 6| Step: 13
Training loss: 0.5071778659998506
Validation loss: 2.543458878291134

Epoch: 311| Step: 0
Training loss: 0.8269360482421753
Validation loss: 2.5220869559655466

Epoch: 6| Step: 1
Training loss: 0.838654354571629
Validation loss: 2.474815725943268

Epoch: 6| Step: 2
Training loss: 0.7574171627816849
Validation loss: 2.494878067930849

Epoch: 6| Step: 3
Training loss: 0.5383376624855472
Validation loss: 2.505103259598855

Epoch: 6| Step: 4
Training loss: 0.8125187798310418
Validation loss: 2.5189930544436274

Epoch: 6| Step: 5
Training loss: 0.5336246152024391
Validation loss: 2.525134378953381

Epoch: 6| Step: 6
Training loss: 0.753065994927041
Validation loss: 2.5410177880890927

Epoch: 6| Step: 7
Training loss: 0.7506234438814142
Validation loss: 2.5568207464933455

Epoch: 6| Step: 8
Training loss: 0.8409419841214444
Validation loss: 2.538659423941796

Epoch: 6| Step: 9
Training loss: 0.8647282758500122
Validation loss: 2.5364858977845763

Epoch: 6| Step: 10
Training loss: 0.5422129413451239
Validation loss: 2.5615785794462766

Epoch: 6| Step: 11
Training loss: 0.6574361163822066
Validation loss: 2.55049956155702

Epoch: 6| Step: 12
Training loss: 0.7695449208240986
Validation loss: 2.5558072058834833

Epoch: 6| Step: 13
Training loss: 0.14927721301308527
Validation loss: 2.5529959303683505

Epoch: 312| Step: 0
Training loss: 1.074185568557133
Validation loss: 2.5386624231657637

Epoch: 6| Step: 1
Training loss: 0.6149637747384556
Validation loss: 2.5156097340310084

Epoch: 6| Step: 2
Training loss: 0.7237207356731293
Validation loss: 2.498002448921603

Epoch: 6| Step: 3
Training loss: 0.9375551843296106
Validation loss: 2.4703953956780773

Epoch: 6| Step: 4
Training loss: 0.735535496052928
Validation loss: 2.4915303992433846

Epoch: 6| Step: 5
Training loss: 0.44273890969394414
Validation loss: 2.5339876721999732

Epoch: 6| Step: 6
Training loss: 0.4861749461434235
Validation loss: 2.5285986876745503

Epoch: 6| Step: 7
Training loss: 0.35184043917820657
Validation loss: 2.5313744128912368

Epoch: 6| Step: 8
Training loss: 0.3993093637846902
Validation loss: 2.5417455670721574

Epoch: 6| Step: 9
Training loss: 0.7045781484202934
Validation loss: 2.5661381966578762

Epoch: 6| Step: 10
Training loss: 0.493284123979956
Validation loss: 2.5633505973435646

Epoch: 6| Step: 11
Training loss: 0.7782422341272675
Validation loss: 2.5498848257529674

Epoch: 6| Step: 12
Training loss: 0.7891667740918106
Validation loss: 2.574722762793818

Epoch: 6| Step: 13
Training loss: 0.855685063017123
Validation loss: 2.552648883877523

Epoch: 313| Step: 0
Training loss: 0.6028196649041543
Validation loss: 2.544330786950214

Epoch: 6| Step: 1
Training loss: 0.790391539229735
Validation loss: 2.4897338461964775

Epoch: 6| Step: 2
Training loss: 0.33537741479775623
Validation loss: 2.493180749176034

Epoch: 6| Step: 3
Training loss: 0.7554339017197691
Validation loss: 2.49722092915387

Epoch: 6| Step: 4
Training loss: 0.6502445732837695
Validation loss: 2.4772077869881355

Epoch: 6| Step: 5
Training loss: 0.9580134120392546
Validation loss: 2.5304701441996813

Epoch: 6| Step: 6
Training loss: 0.9901314405403501
Validation loss: 2.5230748817577613

Epoch: 6| Step: 7
Training loss: 0.5375153273237906
Validation loss: 2.586618007077058

Epoch: 6| Step: 8
Training loss: 0.47384058534193974
Validation loss: 2.5581977177654927

Epoch: 6| Step: 9
Training loss: 0.7391802849172738
Validation loss: 2.61669263059381

Epoch: 6| Step: 10
Training loss: 0.6745983641962281
Validation loss: 2.582230965535018

Epoch: 6| Step: 11
Training loss: 0.6969570898450611
Validation loss: 2.5927151452609514

Epoch: 6| Step: 12
Training loss: 0.4911915678600197
Validation loss: 2.603519528285144

Epoch: 6| Step: 13
Training loss: 0.8518235392710596
Validation loss: 2.576525812498462

Epoch: 314| Step: 0
Training loss: 0.7993174875073819
Validation loss: 2.5392478624051957

Epoch: 6| Step: 1
Training loss: 0.6222380168032217
Validation loss: 2.5263589213022417

Epoch: 6| Step: 2
Training loss: 0.45368219515290764
Validation loss: 2.4970404529603365

Epoch: 6| Step: 3
Training loss: 0.8615673191515523
Validation loss: 2.509441956664878

Epoch: 6| Step: 4
Training loss: 0.6677895467309627
Validation loss: 2.5066320660458437

Epoch: 6| Step: 5
Training loss: 1.10812145923236
Validation loss: 2.4892074590231292

Epoch: 6| Step: 6
Training loss: 0.6378181654637841
Validation loss: 2.528006991603579

Epoch: 6| Step: 7
Training loss: 0.5669043619780414
Validation loss: 2.5203772179421926

Epoch: 6| Step: 8
Training loss: 0.34476193038582453
Validation loss: 2.525057874706911

Epoch: 6| Step: 9
Training loss: 0.7405098274269144
Validation loss: 2.547059479819101

Epoch: 6| Step: 10
Training loss: 0.4349034093627127
Validation loss: 2.55106806363154

Epoch: 6| Step: 11
Training loss: 0.7366396298201018
Validation loss: 2.578093240243356

Epoch: 6| Step: 12
Training loss: 0.6192397751223898
Validation loss: 2.5858287019454727

Epoch: 6| Step: 13
Training loss: 0.41700583799652885
Validation loss: 2.5969808298255277

Epoch: 315| Step: 0
Training loss: 0.6853617013228616
Validation loss: 2.5888964979142175

Epoch: 6| Step: 1
Training loss: 0.5360028885969926
Validation loss: 2.572342576951627

Epoch: 6| Step: 2
Training loss: 0.8718387856020969
Validation loss: 2.5420513993254854

Epoch: 6| Step: 3
Training loss: 0.44498444905058265
Validation loss: 2.5458040465102028

Epoch: 6| Step: 4
Training loss: 0.6804789396764722
Validation loss: 2.5079768875807615

Epoch: 6| Step: 5
Training loss: 0.5623295048771985
Validation loss: 2.518828642829217

Epoch: 6| Step: 6
Training loss: 0.7800278450201669
Validation loss: 2.4923187816881978

Epoch: 6| Step: 7
Training loss: 0.6702268034390266
Validation loss: 2.5157139973281857

Epoch: 6| Step: 8
Training loss: 0.8777071763133704
Validation loss: 2.49597112822498

Epoch: 6| Step: 9
Training loss: 0.7452378481539954
Validation loss: 2.512068037387106

Epoch: 6| Step: 10
Training loss: 0.6351892554234394
Validation loss: 2.4820034479041415

Epoch: 6| Step: 11
Training loss: 0.5052343800964875
Validation loss: 2.4936504207507215

Epoch: 6| Step: 12
Training loss: 0.6276114741700618
Validation loss: 2.5013238396089994

Epoch: 6| Step: 13
Training loss: 0.7785606635388135
Validation loss: 2.526522147825765

Epoch: 316| Step: 0
Training loss: 0.8414621063649028
Validation loss: 2.5615122182099324

Epoch: 6| Step: 1
Training loss: 0.3666811759563343
Validation loss: 2.5613062799617947

Epoch: 6| Step: 2
Training loss: 0.533971630912685
Validation loss: 2.5971684785823537

Epoch: 6| Step: 3
Training loss: 0.8268234172829542
Validation loss: 2.618521981309075

Epoch: 6| Step: 4
Training loss: 0.7492187722756042
Validation loss: 2.6040306126319437

Epoch: 6| Step: 5
Training loss: 0.4092323797344153
Validation loss: 2.5441746682798976

Epoch: 6| Step: 6
Training loss: 0.7266589275073395
Validation loss: 2.5448053112443882

Epoch: 6| Step: 7
Training loss: 0.8073801340830835
Validation loss: 2.5165515177634896

Epoch: 6| Step: 8
Training loss: 0.784755395696343
Validation loss: 2.463271230380233

Epoch: 6| Step: 9
Training loss: 0.6358236093723322
Validation loss: 2.4555461539009613

Epoch: 6| Step: 10
Training loss: 0.8557637372331018
Validation loss: 2.4442419561468203

Epoch: 6| Step: 11
Training loss: 0.5922508387046405
Validation loss: 2.4228975622866655

Epoch: 6| Step: 12
Training loss: 0.6337948932585218
Validation loss: 2.4929634702064867

Epoch: 6| Step: 13
Training loss: 0.7161684529749262
Validation loss: 2.4473551530098994

Epoch: 317| Step: 0
Training loss: 0.820996099558032
Validation loss: 2.4531263052683014

Epoch: 6| Step: 1
Training loss: 0.3302156737361086
Validation loss: 2.461135739078308

Epoch: 6| Step: 2
Training loss: 0.5793080725587616
Validation loss: 2.4879461259723628

Epoch: 6| Step: 3
Training loss: 0.806261541594466
Validation loss: 2.5057007089553767

Epoch: 6| Step: 4
Training loss: 0.3975699647773251
Validation loss: 2.5088830170263763

Epoch: 6| Step: 5
Training loss: 0.7206872871126676
Validation loss: 2.5344383600737364

Epoch: 6| Step: 6
Training loss: 0.6903770674923715
Validation loss: 2.583016332123834

Epoch: 6| Step: 7
Training loss: 0.8931480608152578
Validation loss: 2.5560934906669583

Epoch: 6| Step: 8
Training loss: 0.42057710139630505
Validation loss: 2.5598713387695575

Epoch: 6| Step: 9
Training loss: 0.7753749432647552
Validation loss: 2.5348031564931066

Epoch: 6| Step: 10
Training loss: 0.5022938087994678
Validation loss: 2.5181268475109917

Epoch: 6| Step: 11
Training loss: 0.615483164060441
Validation loss: 2.517016596168145

Epoch: 6| Step: 12
Training loss: 0.5788821855040184
Validation loss: 2.494686675206143

Epoch: 6| Step: 13
Training loss: 1.1169207594622752
Validation loss: 2.5097322350923124

Epoch: 318| Step: 0
Training loss: 0.7341167320462695
Validation loss: 2.518187567794046

Epoch: 6| Step: 1
Training loss: 0.6122869461628689
Validation loss: 2.4839398635131746

Epoch: 6| Step: 2
Training loss: 0.46059527866744726
Validation loss: 2.490172142298361

Epoch: 6| Step: 3
Training loss: 0.5646057978403658
Validation loss: 2.5043544849617327

Epoch: 6| Step: 4
Training loss: 0.8434687251571917
Validation loss: 2.4804681484850524

Epoch: 6| Step: 5
Training loss: 0.4273292678527045
Validation loss: 2.479731401245516

Epoch: 6| Step: 6
Training loss: 0.7703341637712419
Validation loss: 2.4641690997410017

Epoch: 6| Step: 7
Training loss: 0.7228062654416848
Validation loss: 2.50725910300196

Epoch: 6| Step: 8
Training loss: 0.604107168709968
Validation loss: 2.538728235548039

Epoch: 6| Step: 9
Training loss: 0.5148431456682424
Validation loss: 2.5605584914922783

Epoch: 6| Step: 10
Training loss: 0.5164688314817609
Validation loss: 2.513610185854413

Epoch: 6| Step: 11
Training loss: 0.9068840373960625
Validation loss: 2.5649717401793457

Epoch: 6| Step: 12
Training loss: 0.5210224920733486
Validation loss: 2.547728350696372

Epoch: 6| Step: 13
Training loss: 1.029278981236037
Validation loss: 2.500114406511055

Epoch: 319| Step: 0
Training loss: 0.3344361668194622
Validation loss: 2.536825070957085

Epoch: 6| Step: 1
Training loss: 0.5753567894791349
Validation loss: 2.521728847424459

Epoch: 6| Step: 2
Training loss: 0.6913575839571814
Validation loss: 2.483768077622938

Epoch: 6| Step: 3
Training loss: 0.6422477266977481
Validation loss: 2.51504910918567

Epoch: 6| Step: 4
Training loss: 0.6773969266404475
Validation loss: 2.525830232334395

Epoch: 6| Step: 5
Training loss: 0.7639930225448148
Validation loss: 2.5133206031799844

Epoch: 6| Step: 6
Training loss: 0.6524999511470265
Validation loss: 2.5176290423578904

Epoch: 6| Step: 7
Training loss: 0.668551185502897
Validation loss: 2.489360840745656

Epoch: 6| Step: 8
Training loss: 1.0391739520195102
Validation loss: 2.4776202396016327

Epoch: 6| Step: 9
Training loss: 0.5111244769468031
Validation loss: 2.489665916460925

Epoch: 6| Step: 10
Training loss: 0.3581480560071037
Validation loss: 2.5186090469259454

Epoch: 6| Step: 11
Training loss: 0.5364919547004815
Validation loss: 2.493118439891308

Epoch: 6| Step: 12
Training loss: 0.7471888628875032
Validation loss: 2.5305642359089173

Epoch: 6| Step: 13
Training loss: 0.5977804516159742
Validation loss: 2.5149361333397326

Epoch: 320| Step: 0
Training loss: 0.7648965912782728
Validation loss: 2.4989277334698063

Epoch: 6| Step: 1
Training loss: 0.8068729832607037
Validation loss: 2.5372840790694307

Epoch: 6| Step: 2
Training loss: 0.2741735361324692
Validation loss: 2.5348438964385114

Epoch: 6| Step: 3
Training loss: 0.6687460498158379
Validation loss: 2.4885426486045787

Epoch: 6| Step: 4
Training loss: 0.6399351918666676
Validation loss: 2.5026399128133487

Epoch: 6| Step: 5
Training loss: 0.6938537554435922
Validation loss: 2.544349888757643

Epoch: 6| Step: 6
Training loss: 0.7669914663305115
Validation loss: 2.5286156200644583

Epoch: 6| Step: 7
Training loss: 0.39279610953963345
Validation loss: 2.4826156197097635

Epoch: 6| Step: 8
Training loss: 0.8183607588508213
Validation loss: 2.4873188378058897

Epoch: 6| Step: 9
Training loss: 0.5297662828309431
Validation loss: 2.509642342243676

Epoch: 6| Step: 10
Training loss: 0.5217147489738765
Validation loss: 2.5144295939719226

Epoch: 6| Step: 11
Training loss: 0.6265234499817826
Validation loss: 2.491668698605691

Epoch: 6| Step: 12
Training loss: 0.7526069473866414
Validation loss: 2.5327656961904315

Epoch: 6| Step: 13
Training loss: 0.4970077745109697
Validation loss: 2.484964482536898

Epoch: 321| Step: 0
Training loss: 0.7322308914410705
Validation loss: 2.500104046779142

Epoch: 6| Step: 1
Training loss: 0.6635295524469454
Validation loss: 2.495802941268161

Epoch: 6| Step: 2
Training loss: 0.6490670101429663
Validation loss: 2.495940395832755

Epoch: 6| Step: 3
Training loss: 0.6460544966336388
Validation loss: 2.5283893578359815

Epoch: 6| Step: 4
Training loss: 0.3490058655416715
Validation loss: 2.524929975637026

Epoch: 6| Step: 5
Training loss: 0.6093281214362117
Validation loss: 2.520221948956023

Epoch: 6| Step: 6
Training loss: 0.5205115627704806
Validation loss: 2.4993232077573926

Epoch: 6| Step: 7
Training loss: 0.6821425374443315
Validation loss: 2.5187445881907897

Epoch: 6| Step: 8
Training loss: 0.6133485744965083
Validation loss: 2.5300506136408885

Epoch: 6| Step: 9
Training loss: 0.9063627567519171
Validation loss: 2.542186500999943

Epoch: 6| Step: 10
Training loss: 0.4475057698522511
Validation loss: 2.5199390002259374

Epoch: 6| Step: 11
Training loss: 0.3755198293064926
Validation loss: 2.526702407434559

Epoch: 6| Step: 12
Training loss: 0.6020513010138799
Validation loss: 2.4962848469050716

Epoch: 6| Step: 13
Training loss: 1.0871147525721514
Validation loss: 2.4811317881250674

Epoch: 322| Step: 0
Training loss: 0.6501524205497281
Validation loss: 2.5072447329240144

Epoch: 6| Step: 1
Training loss: 0.5416920148591573
Validation loss: 2.4778233176385425

Epoch: 6| Step: 2
Training loss: 0.5848608679665105
Validation loss: 2.4758349006789717

Epoch: 6| Step: 3
Training loss: 0.6758484558909639
Validation loss: 2.4864941061728465

Epoch: 6| Step: 4
Training loss: 0.45458709027596556
Validation loss: 2.472870042651672

Epoch: 6| Step: 5
Training loss: 0.8394435550078516
Validation loss: 2.4895771026704985

Epoch: 6| Step: 6
Training loss: 0.4814050282305276
Validation loss: 2.5654117839315966

Epoch: 6| Step: 7
Training loss: 0.3400854588494919
Validation loss: 2.52052036770853

Epoch: 6| Step: 8
Training loss: 0.8806203445950458
Validation loss: 2.5853538021717184

Epoch: 6| Step: 9
Training loss: 0.7872530898284604
Validation loss: 2.547223637303747

Epoch: 6| Step: 10
Training loss: 0.7572015088619991
Validation loss: 2.5442769609571196

Epoch: 6| Step: 11
Training loss: 0.6041526518763752
Validation loss: 2.537227214822622

Epoch: 6| Step: 12
Training loss: 0.5093854165913624
Validation loss: 2.516742751219553

Epoch: 6| Step: 13
Training loss: 0.5334406452946602
Validation loss: 2.485282426268951

Epoch: 323| Step: 0
Training loss: 0.5572185527815499
Validation loss: 2.4839780757034204

Epoch: 6| Step: 1
Training loss: 0.6668292582447054
Validation loss: 2.480579471741167

Epoch: 6| Step: 2
Training loss: 0.6778534666408477
Validation loss: 2.480808384214489

Epoch: 6| Step: 3
Training loss: 0.36910092175626213
Validation loss: 2.4762222099211817

Epoch: 6| Step: 4
Training loss: 0.6532929419014355
Validation loss: 2.5086977665082726

Epoch: 6| Step: 5
Training loss: 0.7654094781955103
Validation loss: 2.5322442937115577

Epoch: 6| Step: 6
Training loss: 0.40066805276429973
Validation loss: 2.5074822038986944

Epoch: 6| Step: 7
Training loss: 0.7370163511638901
Validation loss: 2.5383048957533823

Epoch: 6| Step: 8
Training loss: 0.4371008755400439
Validation loss: 2.533463056934076

Epoch: 6| Step: 9
Training loss: 0.6307098636671215
Validation loss: 2.493252716127695

Epoch: 6| Step: 10
Training loss: 0.909300176419642
Validation loss: 2.537010745884517

Epoch: 6| Step: 11
Training loss: 0.6498712063616456
Validation loss: 2.5195908731685943

Epoch: 6| Step: 12
Training loss: 0.5128826852548529
Validation loss: 2.5333280967141234

Epoch: 6| Step: 13
Training loss: 0.6282901945238769
Validation loss: 2.507451966855737

Epoch: 324| Step: 0
Training loss: 0.6646974557293308
Validation loss: 2.497829946449977

Epoch: 6| Step: 1
Training loss: 0.6550214257266787
Validation loss: 2.4837659250568787

Epoch: 6| Step: 2
Training loss: 0.4268017359985183
Validation loss: 2.4934890819467554

Epoch: 6| Step: 3
Training loss: 0.5603945322404423
Validation loss: 2.466551973951822

Epoch: 6| Step: 4
Training loss: 0.49253342597344735
Validation loss: 2.486297415706319

Epoch: 6| Step: 5
Training loss: 0.7106652210028844
Validation loss: 2.491119724877039

Epoch: 6| Step: 6
Training loss: 0.854139156984041
Validation loss: 2.4796888543100772

Epoch: 6| Step: 7
Training loss: 0.5776836669623023
Validation loss: 2.5316305073287038

Epoch: 6| Step: 8
Training loss: 0.7648764473741967
Validation loss: 2.559917112661834

Epoch: 6| Step: 9
Training loss: 0.6554191870700549
Validation loss: 2.5559243466411155

Epoch: 6| Step: 10
Training loss: 0.7306457957758244
Validation loss: 2.5619905166907073

Epoch: 6| Step: 11
Training loss: 0.5707214143656708
Validation loss: 2.5832515654654853

Epoch: 6| Step: 12
Training loss: 0.7366649555456849
Validation loss: 2.6026173622527247

Epoch: 6| Step: 13
Training loss: 0.3606253103654871
Validation loss: 2.584948134939452

Epoch: 325| Step: 0
Training loss: 0.7218348603421447
Validation loss: 2.549821943572811

Epoch: 6| Step: 1
Training loss: 0.6814262687053543
Validation loss: 2.5455287221502565

Epoch: 6| Step: 2
Training loss: 0.5452656089056218
Validation loss: 2.463522440219108

Epoch: 6| Step: 3
Training loss: 0.6431362893287949
Validation loss: 2.463545068837659

Epoch: 6| Step: 4
Training loss: 0.35984609658606237
Validation loss: 2.4711264484381834

Epoch: 6| Step: 5
Training loss: 0.6311229237979217
Validation loss: 2.472785573467292

Epoch: 6| Step: 6
Training loss: 0.5200062924701264
Validation loss: 2.487687052430282

Epoch: 6| Step: 7
Training loss: 0.5968361507375194
Validation loss: 2.4800601740618133

Epoch: 6| Step: 8
Training loss: 0.9231155583047959
Validation loss: 2.4948715398241355

Epoch: 6| Step: 9
Training loss: 0.6435627915099337
Validation loss: 2.489403093647388

Epoch: 6| Step: 10
Training loss: 0.5715758036071016
Validation loss: 2.5370442501925297

Epoch: 6| Step: 11
Training loss: 0.5705022104439469
Validation loss: 2.549402912641137

Epoch: 6| Step: 12
Training loss: 0.5468119176176325
Validation loss: 2.5795978653326816

Epoch: 6| Step: 13
Training loss: 0.992991534676248
Validation loss: 2.559588068129339

Epoch: 326| Step: 0
Training loss: 0.5635013409592684
Validation loss: 2.567853861628119

Epoch: 6| Step: 1
Training loss: 0.5790335243744945
Validation loss: 2.5993245449386215

Epoch: 6| Step: 2
Training loss: 0.7440756221224561
Validation loss: 2.5320888320937205

Epoch: 6| Step: 3
Training loss: 0.8571481810983437
Validation loss: 2.547775136665721

Epoch: 6| Step: 4
Training loss: 0.7892524943730713
Validation loss: 2.5489970394091856

Epoch: 6| Step: 5
Training loss: 0.8074378629816951
Validation loss: 2.533781638280065

Epoch: 6| Step: 6
Training loss: 0.7160538816663397
Validation loss: 2.5334406662673334

Epoch: 6| Step: 7
Training loss: 0.46293649566899897
Validation loss: 2.557833127771825

Epoch: 6| Step: 8
Training loss: 0.5720752230062618
Validation loss: 2.5578399011067576

Epoch: 6| Step: 9
Training loss: 0.47275881009236714
Validation loss: 2.5543264817775486

Epoch: 6| Step: 10
Training loss: 0.7088969363264366
Validation loss: 2.527135927150637

Epoch: 6| Step: 11
Training loss: 0.8081654321833259
Validation loss: 2.5209584304684527

Epoch: 6| Step: 12
Training loss: 0.4185214443774211
Validation loss: 2.510617542531625

Epoch: 6| Step: 13
Training loss: 0.6969042570874974
Validation loss: 2.4771038775888914

Epoch: 327| Step: 0
Training loss: 0.6403071382520573
Validation loss: 2.462791223640867

Epoch: 6| Step: 1
Training loss: 0.5773995461557611
Validation loss: 2.43351566053319

Epoch: 6| Step: 2
Training loss: 0.5367378198159359
Validation loss: 2.4589721457317957

Epoch: 6| Step: 3
Training loss: 0.804665537414085
Validation loss: 2.469544910075039

Epoch: 6| Step: 4
Training loss: 0.4798531659369147
Validation loss: 2.4816829320338103

Epoch: 6| Step: 5
Training loss: 0.6742569153416577
Validation loss: 2.476496925830286

Epoch: 6| Step: 6
Training loss: 0.601113486227505
Validation loss: 2.5067726156434227

Epoch: 6| Step: 7
Training loss: 0.7338893583228687
Validation loss: 2.5226098653994895

Epoch: 6| Step: 8
Training loss: 0.5288765565095995
Validation loss: 2.4922324576540205

Epoch: 6| Step: 9
Training loss: 0.729351923887242
Validation loss: 2.512222856192549

Epoch: 6| Step: 10
Training loss: 0.46607916015952017
Validation loss: 2.4889856895381763

Epoch: 6| Step: 11
Training loss: 0.5925448635274293
Validation loss: 2.5120718796793797

Epoch: 6| Step: 12
Training loss: 0.8110202739712047
Validation loss: 2.490573806165538

Epoch: 6| Step: 13
Training loss: 0.3217058116725246
Validation loss: 2.486821816883935

Epoch: 328| Step: 0
Training loss: 0.5982753314813674
Validation loss: 2.4721234016751588

Epoch: 6| Step: 1
Training loss: 0.77273111163935
Validation loss: 2.4820198313191915

Epoch: 6| Step: 2
Training loss: 0.8157934416842824
Validation loss: 2.4930109322511504

Epoch: 6| Step: 3
Training loss: 0.45518122475198214
Validation loss: 2.4948678447005967

Epoch: 6| Step: 4
Training loss: 0.6203123251196473
Validation loss: 2.537932144862297

Epoch: 6| Step: 5
Training loss: 0.5105222735501082
Validation loss: 2.5128490714257516

Epoch: 6| Step: 6
Training loss: 0.597154094693952
Validation loss: 2.5394264110593596

Epoch: 6| Step: 7
Training loss: 0.7992987703627701
Validation loss: 2.547717134051135

Epoch: 6| Step: 8
Training loss: 0.47814720139662276
Validation loss: 2.5621705622569113

Epoch: 6| Step: 9
Training loss: 0.49504382250169543
Validation loss: 2.563759928974804

Epoch: 6| Step: 10
Training loss: 0.4589902674519951
Validation loss: 2.569844942180662

Epoch: 6| Step: 11
Training loss: 0.6858380126059604
Validation loss: 2.529652100156209

Epoch: 6| Step: 12
Training loss: 0.7778570119674274
Validation loss: 2.554798563466944

Epoch: 6| Step: 13
Training loss: 0.4059514636074782
Validation loss: 2.5119232557354128

Epoch: 329| Step: 0
Training loss: 0.40448104423082587
Validation loss: 2.5224293509311133

Epoch: 6| Step: 1
Training loss: 0.4203063978581823
Validation loss: 2.511166039266701

Epoch: 6| Step: 2
Training loss: 0.46930426571295486
Validation loss: 2.4992244307044835

Epoch: 6| Step: 3
Training loss: 0.7974920314881007
Validation loss: 2.5070392994933646

Epoch: 6| Step: 4
Training loss: 0.5815454029765779
Validation loss: 2.5197339526392892

Epoch: 6| Step: 5
Training loss: 0.6408428193999548
Validation loss: 2.5230192447826605

Epoch: 6| Step: 6
Training loss: 0.7260248799802957
Validation loss: 2.5466165014448117

Epoch: 6| Step: 7
Training loss: 0.4291277447275756
Validation loss: 2.539206091620239

Epoch: 6| Step: 8
Training loss: 0.462758170061413
Validation loss: 2.534564816411383

Epoch: 6| Step: 9
Training loss: 0.5688461369179013
Validation loss: 2.5683293101622517

Epoch: 6| Step: 10
Training loss: 0.6835986763912889
Validation loss: 2.5677400451537666

Epoch: 6| Step: 11
Training loss: 0.5740513460241704
Validation loss: 2.555121296267707

Epoch: 6| Step: 12
Training loss: 0.8801565813429304
Validation loss: 2.542998946309745

Epoch: 6| Step: 13
Training loss: 0.5696328437521287
Validation loss: 2.5536990755278177

Epoch: 330| Step: 0
Training loss: 0.6139216875527128
Validation loss: 2.54714497334998

Epoch: 6| Step: 1
Training loss: 0.5469597886977347
Validation loss: 2.5562754498823073

Epoch: 6| Step: 2
Training loss: 0.39816038929597747
Validation loss: 2.5521006004514475

Epoch: 6| Step: 3
Training loss: 0.6060653454467029
Validation loss: 2.518208544625143

Epoch: 6| Step: 4
Training loss: 0.4815960816315842
Validation loss: 2.5586707323947873

Epoch: 6| Step: 5
Training loss: 0.705401528705447
Validation loss: 2.5159614784828808

Epoch: 6| Step: 6
Training loss: 0.6243376082793175
Validation loss: 2.4909714913234766

Epoch: 6| Step: 7
Training loss: 0.36986772892216585
Validation loss: 2.4948371696205944

Epoch: 6| Step: 8
Training loss: 0.6476820256127847
Validation loss: 2.459363705455552

Epoch: 6| Step: 9
Training loss: 0.6824365466876567
Validation loss: 2.4845138689512622

Epoch: 6| Step: 10
Training loss: 0.6348930817800787
Validation loss: 2.47097087970379

Epoch: 6| Step: 11
Training loss: 0.5613964965635572
Validation loss: 2.4622892434176173

Epoch: 6| Step: 12
Training loss: 0.6695921061221415
Validation loss: 2.494746024839724

Epoch: 6| Step: 13
Training loss: 0.6256935801154896
Validation loss: 2.50708516983118

Epoch: 331| Step: 0
Training loss: 0.5718401476136141
Validation loss: 2.527676769370373

Epoch: 6| Step: 1
Training loss: 0.6284450000560097
Validation loss: 2.5179362068696127

Epoch: 6| Step: 2
Training loss: 0.5552114510463568
Validation loss: 2.5067274074121384

Epoch: 6| Step: 3
Training loss: 0.5037857621327294
Validation loss: 2.498406751606975

Epoch: 6| Step: 4
Training loss: 0.4609569771741052
Validation loss: 2.501900362870204

Epoch: 6| Step: 5
Training loss: 0.5119458633669276
Validation loss: 2.515948691128945

Epoch: 6| Step: 6
Training loss: 0.67269297642416
Validation loss: 2.533858555995041

Epoch: 6| Step: 7
Training loss: 0.5295181374996094
Validation loss: 2.4994237112508078

Epoch: 6| Step: 8
Training loss: 0.6898597620383451
Validation loss: 2.4957710881911006

Epoch: 6| Step: 9
Training loss: 0.5420169034254021
Validation loss: 2.500373455579441

Epoch: 6| Step: 10
Training loss: 0.7292963094356655
Validation loss: 2.528274585086956

Epoch: 6| Step: 11
Training loss: 0.6514897038252935
Validation loss: 2.4847419376465782

Epoch: 6| Step: 12
Training loss: 0.4932491115846285
Validation loss: 2.490710996071438

Epoch: 6| Step: 13
Training loss: 0.6062456868205063
Validation loss: 2.4772669199677457

Epoch: 332| Step: 0
Training loss: 0.30925478333510714
Validation loss: 2.48392802184125

Epoch: 6| Step: 1
Training loss: 0.6780576347255992
Validation loss: 2.5238483470013904

Epoch: 6| Step: 2
Training loss: 0.5540158140562652
Validation loss: 2.5376375345471907

Epoch: 6| Step: 3
Training loss: 0.7928801238044639
Validation loss: 2.5256019817710564

Epoch: 6| Step: 4
Training loss: 0.7314147535390855
Validation loss: 2.54629249033846

Epoch: 6| Step: 5
Training loss: 0.398522143629403
Validation loss: 2.5326163846240113

Epoch: 6| Step: 6
Training loss: 0.753639687963676
Validation loss: 2.531830634343195

Epoch: 6| Step: 7
Training loss: 0.7246665829184986
Validation loss: 2.549303252218682

Epoch: 6| Step: 8
Training loss: 0.4118663740340171
Validation loss: 2.5393913996286

Epoch: 6| Step: 9
Training loss: 0.8059658525678188
Validation loss: 2.53223997481535

Epoch: 6| Step: 10
Training loss: 0.4263839655470079
Validation loss: 2.5118023533712583

Epoch: 6| Step: 11
Training loss: 0.35252905538204027
Validation loss: 2.511784441622873

Epoch: 6| Step: 12
Training loss: 0.3025371524363854
Validation loss: 2.500437619761616

Epoch: 6| Step: 13
Training loss: 0.3414197203294224
Validation loss: 2.510866962076136

Epoch: 333| Step: 0
Training loss: 0.5750631494674937
Validation loss: 2.4950687010490777

Epoch: 6| Step: 1
Training loss: 0.511058381272913
Validation loss: 2.5003685566764675

Epoch: 6| Step: 2
Training loss: 0.7606399330296967
Validation loss: 2.4905012558685833

Epoch: 6| Step: 3
Training loss: 0.4387167971293324
Validation loss: 2.5250592209677674

Epoch: 6| Step: 4
Training loss: 0.5910868650313235
Validation loss: 2.5136067936520123

Epoch: 6| Step: 5
Training loss: 0.1928147825294556
Validation loss: 2.4928936205659076

Epoch: 6| Step: 6
Training loss: 0.47914107572247294
Validation loss: 2.531481510596004

Epoch: 6| Step: 7
Training loss: 0.4346014118853657
Validation loss: 2.5366091291206296

Epoch: 6| Step: 8
Training loss: 0.5909637277109454
Validation loss: 2.5283112110900055

Epoch: 6| Step: 9
Training loss: 0.6550152379367379
Validation loss: 2.513513917328975

Epoch: 6| Step: 10
Training loss: 0.592672021979319
Validation loss: 2.5195387347702343

Epoch: 6| Step: 11
Training loss: 0.6345498760075682
Validation loss: 2.518785807721114

Epoch: 6| Step: 12
Training loss: 0.62659936354112
Validation loss: 2.5388918967156004

Epoch: 6| Step: 13
Training loss: 0.6572319132571469
Validation loss: 2.5480462280245852

Epoch: 334| Step: 0
Training loss: 0.5187687835969468
Validation loss: 2.547590643763445

Epoch: 6| Step: 1
Training loss: 0.5100228256372206
Validation loss: 2.539200011663815

Epoch: 6| Step: 2
Training loss: 0.24555011527447723
Validation loss: 2.52505788993611

Epoch: 6| Step: 3
Training loss: 0.3869794101979588
Validation loss: 2.5489980250389443

Epoch: 6| Step: 4
Training loss: 0.6799916650107
Validation loss: 2.4880383730153106

Epoch: 6| Step: 5
Training loss: 0.5821280174971721
Validation loss: 2.525965971722281

Epoch: 6| Step: 6
Training loss: 0.7654226775358189
Validation loss: 2.5166174504719194

Epoch: 6| Step: 7
Training loss: 0.645413644359581
Validation loss: 2.5476644392069003

Epoch: 6| Step: 8
Training loss: 0.5792132522408533
Validation loss: 2.5038328358546083

Epoch: 6| Step: 9
Training loss: 0.5012321489442179
Validation loss: 2.530755131762848

Epoch: 6| Step: 10
Training loss: 0.7421950892010217
Validation loss: 2.5520011739625588

Epoch: 6| Step: 11
Training loss: 0.5784315379127629
Validation loss: 2.4958751407559117

Epoch: 6| Step: 12
Training loss: 0.4091880997769476
Validation loss: 2.522601698679072

Epoch: 6| Step: 13
Training loss: 0.4273399729448457
Validation loss: 2.5073100049714054

Epoch: 335| Step: 0
Training loss: 0.7965235215501739
Validation loss: 2.486013931515675

Epoch: 6| Step: 1
Training loss: 0.6780540525880845
Validation loss: 2.468165243108631

Epoch: 6| Step: 2
Training loss: 0.5092090184141287
Validation loss: 2.4820787845865917

Epoch: 6| Step: 3
Training loss: 0.49383126628246576
Validation loss: 2.474942811031972

Epoch: 6| Step: 4
Training loss: 0.6342994738940313
Validation loss: 2.4748869828595117

Epoch: 6| Step: 5
Training loss: 0.3849803306150089
Validation loss: 2.4429442295316566

Epoch: 6| Step: 6
Training loss: 0.37913618288360046
Validation loss: 2.4472786313844406

Epoch: 6| Step: 7
Training loss: 0.34575254011703677
Validation loss: 2.4598356890985076

Epoch: 6| Step: 8
Training loss: 0.555358695543648
Validation loss: 2.4934502788436

Epoch: 6| Step: 9
Training loss: 0.5520939975884149
Validation loss: 2.521928189628801

Epoch: 6| Step: 10
Training loss: 0.5322342898306586
Validation loss: 2.54382075555796

Epoch: 6| Step: 11
Training loss: 0.49686348140008973
Validation loss: 2.5548367478817444

Epoch: 6| Step: 12
Training loss: 0.7171216016093442
Validation loss: 2.551237921519209

Epoch: 6| Step: 13
Training loss: 0.5620150329863317
Validation loss: 2.576349011028107

Epoch: 336| Step: 0
Training loss: 0.1638980677246973
Validation loss: 2.549052433221929

Epoch: 6| Step: 1
Training loss: 0.652701137205559
Validation loss: 2.5243198603711727

Epoch: 6| Step: 2
Training loss: 0.7433093777318903
Validation loss: 2.5373512810864614

Epoch: 6| Step: 3
Training loss: 0.47832899541361024
Validation loss: 2.5116771930016433

Epoch: 6| Step: 4
Training loss: 0.5045168230788665
Validation loss: 2.4999769681464374

Epoch: 6| Step: 5
Training loss: 0.3734998698802451
Validation loss: 2.5022202425913154

Epoch: 6| Step: 6
Training loss: 0.6485035184780957
Validation loss: 2.5127446392594455

Epoch: 6| Step: 7
Training loss: 0.6082175584475761
Validation loss: 2.5107343441473855

Epoch: 6| Step: 8
Training loss: 0.8608302885619014
Validation loss: 2.5668143242978223

Epoch: 6| Step: 9
Training loss: 0.2856667143204255
Validation loss: 2.484639982338938

Epoch: 6| Step: 10
Training loss: 0.5113429371179765
Validation loss: 2.49953627336069

Epoch: 6| Step: 11
Training loss: 0.41590509155144206
Validation loss: 2.5480546170405285

Epoch: 6| Step: 12
Training loss: 0.5995674242882949
Validation loss: 2.525218634093341

Epoch: 6| Step: 13
Training loss: 0.41695741602273
Validation loss: 2.488645427290979

Epoch: 337| Step: 0
Training loss: 0.6218487930526608
Validation loss: 2.541050756809584

Epoch: 6| Step: 1
Training loss: 0.49316072368435837
Validation loss: 2.564590941117856

Epoch: 6| Step: 2
Training loss: 0.6831605901285809
Validation loss: 2.56139478001908

Epoch: 6| Step: 3
Training loss: 0.5216450532979767
Validation loss: 2.5138457358840727

Epoch: 6| Step: 4
Training loss: 0.2861019287107031
Validation loss: 2.518593992442454

Epoch: 6| Step: 5
Training loss: 0.32076205131579955
Validation loss: 2.5185985525659533

Epoch: 6| Step: 6
Training loss: 0.5187834326759804
Validation loss: 2.5091082213457088

Epoch: 6| Step: 7
Training loss: 0.5787503237136364
Validation loss: 2.535405483091928

Epoch: 6| Step: 8
Training loss: 0.5885549448141486
Validation loss: 2.497557811075153

Epoch: 6| Step: 9
Training loss: 0.46462096958500787
Validation loss: 2.533413735882989

Epoch: 6| Step: 10
Training loss: 0.5790436636943445
Validation loss: 2.5339506608319553

Epoch: 6| Step: 11
Training loss: 0.5830770224636374
Validation loss: 2.5675417800245275

Epoch: 6| Step: 12
Training loss: 0.23869422395898895
Validation loss: 2.529399436917107

Epoch: 6| Step: 13
Training loss: 1.0118247900811455
Validation loss: 2.5282429175296595

Epoch: 338| Step: 0
Training loss: 0.29606738161826257
Validation loss: 2.525690684383501

Epoch: 6| Step: 1
Training loss: 0.5454763510618905
Validation loss: 2.528623360808499

Epoch: 6| Step: 2
Training loss: 0.42281355477798516
Validation loss: 2.524143118942504

Epoch: 6| Step: 3
Training loss: 0.743779693139013
Validation loss: 2.515261112758736

Epoch: 6| Step: 4
Training loss: 0.33890008904083624
Validation loss: 2.550932941908478

Epoch: 6| Step: 5
Training loss: 0.6297002956708941
Validation loss: 2.565732445341253

Epoch: 6| Step: 6
Training loss: 0.6039013910529913
Validation loss: 2.5254329968459155

Epoch: 6| Step: 7
Training loss: 0.31582941055168323
Validation loss: 2.568400956126901

Epoch: 6| Step: 8
Training loss: 0.5907813697780517
Validation loss: 2.533122498472087

Epoch: 6| Step: 9
Training loss: 0.5609318544321549
Validation loss: 2.5496500753974236

Epoch: 6| Step: 10
Training loss: 0.6046009366473969
Validation loss: 2.5233859002916095

Epoch: 6| Step: 11
Training loss: 0.4361835667161853
Validation loss: 2.5313739834866746

Epoch: 6| Step: 12
Training loss: 0.8005361042208351
Validation loss: 2.55336178937591

Epoch: 6| Step: 13
Training loss: 0.3960106561243306
Validation loss: 2.565766530302943

Epoch: 339| Step: 0
Training loss: 0.37731817091654296
Validation loss: 2.5253371688669066

Epoch: 6| Step: 1
Training loss: 0.6672529880804086
Validation loss: 2.519116337540036

Epoch: 6| Step: 2
Training loss: 0.6178378770755668
Validation loss: 2.5040161749617362

Epoch: 6| Step: 3
Training loss: 0.6138029370135419
Validation loss: 2.538577350872932

Epoch: 6| Step: 4
Training loss: 0.8148381628940354
Validation loss: 2.502373430122679

Epoch: 6| Step: 5
Training loss: 0.5122828977417903
Validation loss: 2.48806105377501

Epoch: 6| Step: 6
Training loss: 0.32968133857357185
Validation loss: 2.522401073202268

Epoch: 6| Step: 7
Training loss: 0.48372303246828363
Validation loss: 2.526550444370134

Epoch: 6| Step: 8
Training loss: 0.4918569029759224
Validation loss: 2.4967619753344112

Epoch: 6| Step: 9
Training loss: 0.17524561335342614
Validation loss: 2.554396912697896

Epoch: 6| Step: 10
Training loss: 0.5390930167143385
Validation loss: 2.5484193555740613

Epoch: 6| Step: 11
Training loss: 0.378368152908058
Validation loss: 2.530439951362118

Epoch: 6| Step: 12
Training loss: 0.5319065917031739
Validation loss: 2.5421232267005203

Epoch: 6| Step: 13
Training loss: 0.7585118006905391
Validation loss: 2.530605224419942

Epoch: 340| Step: 0
Training loss: 0.5058739266088441
Validation loss: 2.536023800485101

Epoch: 6| Step: 1
Training loss: 0.5958703478628969
Validation loss: 2.518196635548299

Epoch: 6| Step: 2
Training loss: 0.5414334553190229
Validation loss: 2.545026192566076

Epoch: 6| Step: 3
Training loss: 0.5117660966474478
Validation loss: 2.517013907264582

Epoch: 6| Step: 4
Training loss: 0.45836542479555575
Validation loss: 2.527076302437029

Epoch: 6| Step: 5
Training loss: 0.355952572892765
Validation loss: 2.5164249763189694

Epoch: 6| Step: 6
Training loss: 0.687254948725529
Validation loss: 2.492145575138172

Epoch: 6| Step: 7
Training loss: 0.5183727282807093
Validation loss: 2.5069274679823472

Epoch: 6| Step: 8
Training loss: 0.555847379081856
Validation loss: 2.5011852449125556

Epoch: 6| Step: 9
Training loss: 0.5186929464563329
Validation loss: 2.5239175420992646

Epoch: 6| Step: 10
Training loss: 0.5650662850429437
Validation loss: 2.5203752619322666

Epoch: 6| Step: 11
Training loss: 0.2062813384638566
Validation loss: 2.540672460487423

Epoch: 6| Step: 12
Training loss: 0.5414453995987154
Validation loss: 2.570352723004247

Epoch: 6| Step: 13
Training loss: 0.7486104012908433
Validation loss: 2.5593732485451604

Epoch: 341| Step: 0
Training loss: 0.47318622732136184
Validation loss: 2.5837298079744473

Epoch: 6| Step: 1
Training loss: 0.9151704708099729
Validation loss: 2.614814379091412

Epoch: 6| Step: 2
Training loss: 0.5560559866661917
Validation loss: 2.5550896017464235

Epoch: 6| Step: 3
Training loss: 0.38762777590626485
Validation loss: 2.570761665699758

Epoch: 6| Step: 4
Training loss: 0.400421215842634
Validation loss: 2.5807638068638368

Epoch: 6| Step: 5
Training loss: 0.18112786017042637
Validation loss: 2.5794244155927557

Epoch: 6| Step: 6
Training loss: 0.6440838734996358
Validation loss: 2.557840959501362

Epoch: 6| Step: 7
Training loss: 0.539571521757402
Validation loss: 2.542013004200362

Epoch: 6| Step: 8
Training loss: 0.4237405009597566
Validation loss: 2.5544448822128567

Epoch: 6| Step: 9
Training loss: 0.5933397532188979
Validation loss: 2.546659277144624

Epoch: 6| Step: 10
Training loss: 0.3139338974955797
Validation loss: 2.5363217377030693

Epoch: 6| Step: 11
Training loss: 0.39161708734422657
Validation loss: 2.5151024129570585

Epoch: 6| Step: 12
Training loss: 0.526997092005544
Validation loss: 2.5046583490427685

Epoch: 6| Step: 13
Training loss: 0.48888306723395286
Validation loss: 2.5198741611125053

Epoch: 342| Step: 0
Training loss: 0.6095796388195598
Validation loss: 2.501034787044169

Epoch: 6| Step: 1
Training loss: 0.43883661045633326
Validation loss: 2.5202575649125305

Epoch: 6| Step: 2
Training loss: 0.26690424689633385
Validation loss: 2.5057597537251866

Epoch: 6| Step: 3
Training loss: 0.7720483577510447
Validation loss: 2.5217401140933173

Epoch: 6| Step: 4
Training loss: 0.5959508912172718
Validation loss: 2.542863256181324

Epoch: 6| Step: 5
Training loss: 0.5641449347620511
Validation loss: 2.5365714707673193

Epoch: 6| Step: 6
Training loss: 0.4826839522799779
Validation loss: 2.5306171429763253

Epoch: 6| Step: 7
Training loss: 0.645325697055015
Validation loss: 2.5643789314404097

Epoch: 6| Step: 8
Training loss: 0.5034496989272866
Validation loss: 2.5847662392979696

Epoch: 6| Step: 9
Training loss: 0.40622358969892536
Validation loss: 2.56553276099746

Epoch: 6| Step: 10
Training loss: 0.46837769664215145
Validation loss: 2.5701006046996686

Epoch: 6| Step: 11
Training loss: 0.36796738610146484
Validation loss: 2.5677185164889513

Epoch: 6| Step: 12
Training loss: 0.31179945625186806
Validation loss: 2.5452314718682394

Epoch: 6| Step: 13
Training loss: 0.4132793145233581
Validation loss: 2.536267781158683

Epoch: 343| Step: 0
Training loss: 0.6910952283380727
Validation loss: 2.5390374865692085

Epoch: 6| Step: 1
Training loss: 0.6490345240199099
Validation loss: 2.5194282532944072

Epoch: 6| Step: 2
Training loss: 0.4608030284703428
Validation loss: 2.505123914134928

Epoch: 6| Step: 3
Training loss: 0.358715841913453
Validation loss: 2.518327678105814

Epoch: 6| Step: 4
Training loss: 0.4420491153670651
Validation loss: 2.5281200424756793

Epoch: 6| Step: 5
Training loss: 0.5217834929229385
Validation loss: 2.5137392115953343

Epoch: 6| Step: 6
Training loss: 0.5062053778491947
Validation loss: 2.5053157307956586

Epoch: 6| Step: 7
Training loss: 0.3752403283902805
Validation loss: 2.563734528030944

Epoch: 6| Step: 8
Training loss: 0.6458672750434457
Validation loss: 2.5292152142325746

Epoch: 6| Step: 9
Training loss: 0.29418162735150144
Validation loss: 2.560373049837552

Epoch: 6| Step: 10
Training loss: 0.6610842846143443
Validation loss: 2.6072441657171574

Epoch: 6| Step: 11
Training loss: 0.5062681630490891
Validation loss: 2.5859749123390303

Epoch: 6| Step: 12
Training loss: 0.48125226404227234
Validation loss: 2.605833732991416

Epoch: 6| Step: 13
Training loss: 0.2423388485071579
Validation loss: 2.633756534841965

Epoch: 344| Step: 0
Training loss: 0.6160377706491161
Validation loss: 2.5910196053540147

Epoch: 6| Step: 1
Training loss: 0.21443101946189513
Validation loss: 2.6052179005626663

Epoch: 6| Step: 2
Training loss: 0.43366986543124164
Validation loss: 2.564795656559101

Epoch: 6| Step: 3
Training loss: 0.6818267218459536
Validation loss: 2.542579538049022

Epoch: 6| Step: 4
Training loss: 0.47557927935754996
Validation loss: 2.5287383215017782

Epoch: 6| Step: 5
Training loss: 0.3450597174417755
Validation loss: 2.493357615626831

Epoch: 6| Step: 6
Training loss: 0.5464834719058054
Validation loss: 2.5096949405898417

Epoch: 6| Step: 7
Training loss: 0.4826302175024935
Validation loss: 2.5407275807282463

Epoch: 6| Step: 8
Training loss: 0.5138556438151323
Validation loss: 2.5255193219528986

Epoch: 6| Step: 9
Training loss: 0.36711237524429813
Validation loss: 2.5383610258569416

Epoch: 6| Step: 10
Training loss: 0.5841921943695506
Validation loss: 2.551959066439845

Epoch: 6| Step: 11
Training loss: 0.49219113303160644
Validation loss: 2.5751581980113896

Epoch: 6| Step: 12
Training loss: 0.5236270049077943
Validation loss: 2.552606151303088

Epoch: 6| Step: 13
Training loss: 0.805933607845663
Validation loss: 2.582388907349139

Epoch: 345| Step: 0
Training loss: 0.9166065579271537
Validation loss: 2.592364057937591

Epoch: 6| Step: 1
Training loss: 0.6701066677031613
Validation loss: 2.539122875117392

Epoch: 6| Step: 2
Training loss: 0.5461176942042842
Validation loss: 2.5756865294575393

Epoch: 6| Step: 3
Training loss: 0.5017739061363529
Validation loss: 2.549397666500211

Epoch: 6| Step: 4
Training loss: 0.4146806672948408
Validation loss: 2.5355242928733857

Epoch: 6| Step: 5
Training loss: 0.4304151962116059
Validation loss: 2.501153678189994

Epoch: 6| Step: 6
Training loss: 0.5395876772594008
Validation loss: 2.4918229849142848

Epoch: 6| Step: 7
Training loss: 0.2755183471586747
Validation loss: 2.4950166173929795

Epoch: 6| Step: 8
Training loss: 0.6528963957437154
Validation loss: 2.482427167671799

Epoch: 6| Step: 9
Training loss: 0.24252583344000467
Validation loss: 2.535700387112557

Epoch: 6| Step: 10
Training loss: 0.5209582528670026
Validation loss: 2.4978270819134516

Epoch: 6| Step: 11
Training loss: 0.46951661999548877
Validation loss: 2.495889531099874

Epoch: 6| Step: 12
Training loss: 0.1944059408805044
Validation loss: 2.551056811423921

Epoch: 6| Step: 13
Training loss: 0.34331611864247863
Validation loss: 2.545656002213982

Epoch: 346| Step: 0
Training loss: 0.29503955135459004
Validation loss: 2.5677076237923884

Epoch: 6| Step: 1
Training loss: 0.6386679552990384
Validation loss: 2.576667233796711

Epoch: 6| Step: 2
Training loss: 0.4556850920663139
Validation loss: 2.56070310677752

Epoch: 6| Step: 3
Training loss: 0.4777611214238079
Validation loss: 2.5613488053311073

Epoch: 6| Step: 4
Training loss: 0.7165278207844192
Validation loss: 2.5145646937557657

Epoch: 6| Step: 5
Training loss: 0.6597034775151215
Validation loss: 2.503367688622846

Epoch: 6| Step: 6
Training loss: 0.5358232671149094
Validation loss: 2.5279157781480652

Epoch: 6| Step: 7
Training loss: 0.5547980883326115
Validation loss: 2.471533327197728

Epoch: 6| Step: 8
Training loss: 0.5304108331044364
Validation loss: 2.495501922188856

Epoch: 6| Step: 9
Training loss: 0.5254763565170831
Validation loss: 2.466360216143389

Epoch: 6| Step: 10
Training loss: 0.45824372614942926
Validation loss: 2.5080657116590643

Epoch: 6| Step: 11
Training loss: 0.5267169759760664
Validation loss: 2.5241502807734477

Epoch: 6| Step: 12
Training loss: 0.34507099915484307
Validation loss: 2.5312817018448786

Epoch: 6| Step: 13
Training loss: 0.21076968369870017
Validation loss: 2.550127500897004

Epoch: 347| Step: 0
Training loss: 0.5029763801898959
Validation loss: 2.5687025813074427

Epoch: 6| Step: 1
Training loss: 0.44546477742532864
Validation loss: 2.568678793167107

Epoch: 6| Step: 2
Training loss: 0.49151783754223244
Validation loss: 2.5749202275864747

Epoch: 6| Step: 3
Training loss: 0.5559756406037891
Validation loss: 2.575340713036707

Epoch: 6| Step: 4
Training loss: 0.5232613679987849
Validation loss: 2.5796429721710052

Epoch: 6| Step: 5
Training loss: 0.39185285234911144
Validation loss: 2.548426997938204

Epoch: 6| Step: 6
Training loss: 0.4781359976706671
Validation loss: 2.5387677360937015

Epoch: 6| Step: 7
Training loss: 0.5782381926377111
Validation loss: 2.5514732763460244

Epoch: 6| Step: 8
Training loss: 0.5666422385205014
Validation loss: 2.5328575305430663

Epoch: 6| Step: 9
Training loss: 0.6006865130313096
Validation loss: 2.5532937657345345

Epoch: 6| Step: 10
Training loss: 0.49995150927012433
Validation loss: 2.5383321964127594

Epoch: 6| Step: 11
Training loss: 0.4771186054162007
Validation loss: 2.5543309219054633

Epoch: 6| Step: 12
Training loss: 0.4507839301970088
Validation loss: 2.5536209875205143

Epoch: 6| Step: 13
Training loss: 0.5097074512012642
Validation loss: 2.57808919206191

Epoch: 348| Step: 0
Training loss: 0.41350134125253296
Validation loss: 2.609769957682766

Epoch: 6| Step: 1
Training loss: 0.44023892824243543
Validation loss: 2.599726824947365

Epoch: 6| Step: 2
Training loss: 0.41190557276666695
Validation loss: 2.590347356148706

Epoch: 6| Step: 3
Training loss: 0.4787895197281448
Validation loss: 2.5914984670212147

Epoch: 6| Step: 4
Training loss: 0.4318002776661855
Validation loss: 2.550775409698019

Epoch: 6| Step: 5
Training loss: 0.7867790267263832
Validation loss: 2.5704339600235113

Epoch: 6| Step: 6
Training loss: 0.5653125859097594
Validation loss: 2.5837635796110785

Epoch: 6| Step: 7
Training loss: 0.43064299032338815
Validation loss: 2.5645486749369195

Epoch: 6| Step: 8
Training loss: 0.4306556545137469
Validation loss: 2.56824610099417

Epoch: 6| Step: 9
Training loss: 0.5827701154335854
Validation loss: 2.5448446942930834

Epoch: 6| Step: 10
Training loss: 0.4932031597087285
Validation loss: 2.5435412383314113

Epoch: 6| Step: 11
Training loss: 0.5952945245947563
Validation loss: 2.550306766048895

Epoch: 6| Step: 12
Training loss: 0.2793170414826639
Validation loss: 2.5109214297383757

Epoch: 6| Step: 13
Training loss: 0.33475336700039554
Validation loss: 2.54629118047428

Epoch: 349| Step: 0
Training loss: 0.6044853345639672
Validation loss: 2.5167925517605743

Epoch: 6| Step: 1
Training loss: 0.4956436368028731
Validation loss: 2.542547417971474

Epoch: 6| Step: 2
Training loss: 0.4535197150204514
Validation loss: 2.5298354575361075

Epoch: 6| Step: 3
Training loss: 0.45736890530128854
Validation loss: 2.553750715261811

Epoch: 6| Step: 4
Training loss: 0.36706346080621155
Validation loss: 2.5717191512859037

Epoch: 6| Step: 5
Training loss: 0.3418172993688357
Validation loss: 2.5271792760464744

Epoch: 6| Step: 6
Training loss: 0.4484393947175834
Validation loss: 2.5348832774936576

Epoch: 6| Step: 7
Training loss: 0.5797286345495801
Validation loss: 2.538443508880627

Epoch: 6| Step: 8
Training loss: 0.6571992638914104
Validation loss: 2.5330961263975174

Epoch: 6| Step: 9
Training loss: 0.3669396233384325
Validation loss: 2.545056896320355

Epoch: 6| Step: 10
Training loss: 0.6396914868027899
Validation loss: 2.541478292449954

Epoch: 6| Step: 11
Training loss: 0.28791478132043763
Validation loss: 2.513231251802903

Epoch: 6| Step: 12
Training loss: 0.703668934979104
Validation loss: 2.5185607602931253

Epoch: 6| Step: 13
Training loss: 0.4208413105230627
Validation loss: 2.5012194715121985

Epoch: 350| Step: 0
Training loss: 0.4627470445677667
Validation loss: 2.500239495116605

Epoch: 6| Step: 1
Training loss: 0.4065880286128126
Validation loss: 2.496326117906135

Epoch: 6| Step: 2
Training loss: 0.353750940901243
Validation loss: 2.5307983801738483

Epoch: 6| Step: 3
Training loss: 0.6276289010351187
Validation loss: 2.5650562748931187

Epoch: 6| Step: 4
Training loss: 0.7770867617806765
Validation loss: 2.5749789674678296

Epoch: 6| Step: 5
Training loss: 0.5181960825367519
Validation loss: 2.5939809946150523

Epoch: 6| Step: 6
Training loss: 0.5693178779263448
Validation loss: 2.5620513531269884

Epoch: 6| Step: 7
Training loss: 0.5105048771624306
Validation loss: 2.5102980874235015

Epoch: 6| Step: 8
Training loss: 0.5132481092556606
Validation loss: 2.536074997493991

Epoch: 6| Step: 9
Training loss: 0.2262807607025137
Validation loss: 2.5190575641126505

Epoch: 6| Step: 10
Training loss: 0.44336203015578507
Validation loss: 2.4955688671369542

Epoch: 6| Step: 11
Training loss: 0.4754434172281016
Validation loss: 2.451543949160824

Epoch: 6| Step: 12
Training loss: 0.49334329803923566
Validation loss: 2.461094958165322

Epoch: 6| Step: 13
Training loss: 0.5266397934507973
Validation loss: 2.48061668104094

Epoch: 351| Step: 0
Training loss: 0.39387832094691355
Validation loss: 2.5017104399120074

Epoch: 6| Step: 1
Training loss: 0.5217947161476059
Validation loss: 2.5188645593929118

Epoch: 6| Step: 2
Training loss: 0.6080165295048006
Validation loss: 2.5268709980294912

Epoch: 6| Step: 3
Training loss: 0.306178869044419
Validation loss: 2.4995668492343746

Epoch: 6| Step: 4
Training loss: 0.3758713810425857
Validation loss: 2.5216210711743723

Epoch: 6| Step: 5
Training loss: 0.7630084734404935
Validation loss: 2.5012821488540724

Epoch: 6| Step: 6
Training loss: 0.5603689516121028
Validation loss: 2.5188439880144617

Epoch: 6| Step: 7
Training loss: 0.6643157700398845
Validation loss: 2.5061488367653157

Epoch: 6| Step: 8
Training loss: 0.26991371992629887
Validation loss: 2.5242304484235425

Epoch: 6| Step: 9
Training loss: 0.4294877368233222
Validation loss: 2.5182221496941026

Epoch: 6| Step: 10
Training loss: 0.300162794229475
Validation loss: 2.5005653849520124

Epoch: 6| Step: 11
Training loss: 0.5848642820259585
Validation loss: 2.5197508947455383

Epoch: 6| Step: 12
Training loss: 0.3971560384263698
Validation loss: 2.503875045987636

Epoch: 6| Step: 13
Training loss: 0.3589208054736057
Validation loss: 2.5285615847528224

Epoch: 352| Step: 0
Training loss: 0.6872009580646582
Validation loss: 2.5207984052038523

Epoch: 6| Step: 1
Training loss: 0.35151977279419605
Validation loss: 2.5164500041449087

Epoch: 6| Step: 2
Training loss: 0.14235791746165238
Validation loss: 2.5705246321503368

Epoch: 6| Step: 3
Training loss: 0.45227973300518914
Validation loss: 2.520212429717297

Epoch: 6| Step: 4
Training loss: 0.601292388516252
Validation loss: 2.489637035426202

Epoch: 6| Step: 5
Training loss: 0.5689251368068922
Validation loss: 2.524919341033761

Epoch: 6| Step: 6
Training loss: 0.6564496508667496
Validation loss: 2.4972386953861245

Epoch: 6| Step: 7
Training loss: 0.488225399637906
Validation loss: 2.512803248152743

Epoch: 6| Step: 8
Training loss: 0.3225380641815085
Validation loss: 2.4873333899958623

Epoch: 6| Step: 9
Training loss: 0.4110992309193341
Validation loss: 2.5255426395797604

Epoch: 6| Step: 10
Training loss: 0.5973451590116039
Validation loss: 2.5249187541696836

Epoch: 6| Step: 11
Training loss: 0.42915828366409897
Validation loss: 2.5211232619587216

Epoch: 6| Step: 12
Training loss: 0.5230946912838506
Validation loss: 2.5237835270604934

Epoch: 6| Step: 13
Training loss: 0.31550474425374603
Validation loss: 2.5373704657475384

Epoch: 353| Step: 0
Training loss: 0.3712861214992345
Validation loss: 2.5575739816207674

Epoch: 6| Step: 1
Training loss: 0.6718679028513238
Validation loss: 2.58352318627459

Epoch: 6| Step: 2
Training loss: 0.5415018148700033
Validation loss: 2.5868043397449707

Epoch: 6| Step: 3
Training loss: 0.4496584688985956
Validation loss: 2.6083900253512784

Epoch: 6| Step: 4
Training loss: 0.7863662657415639
Validation loss: 2.589104807278663

Epoch: 6| Step: 5
Training loss: 0.3992334904347578
Validation loss: 2.5695761216632778

Epoch: 6| Step: 6
Training loss: 0.5731126161192099
Validation loss: 2.4976622367225505

Epoch: 6| Step: 7
Training loss: 0.560011551601613
Validation loss: 2.508042135462914

Epoch: 6| Step: 8
Training loss: 0.3243678795578745
Validation loss: 2.525048567618447

Epoch: 6| Step: 9
Training loss: 0.4094402785343044
Validation loss: 2.4915766651974107

Epoch: 6| Step: 10
Training loss: 0.44329902473448274
Validation loss: 2.476163693378502

Epoch: 6| Step: 11
Training loss: 0.5983927558127672
Validation loss: 2.480762591215439

Epoch: 6| Step: 12
Training loss: 0.5794075837586745
Validation loss: 2.4610847550189567

Epoch: 6| Step: 13
Training loss: 0.41690523549802766
Validation loss: 2.488725044117661

Epoch: 354| Step: 0
Training loss: 0.570099307410745
Validation loss: 2.503991683222498

Epoch: 6| Step: 1
Training loss: 0.39818501419874586
Validation loss: 2.5041735216600123

Epoch: 6| Step: 2
Training loss: 0.6667829104247889
Validation loss: 2.527992385543206

Epoch: 6| Step: 3
Training loss: 0.5196075383441947
Validation loss: 2.537488009043958

Epoch: 6| Step: 4
Training loss: 0.586258584104049
Validation loss: 2.507888317958668

Epoch: 6| Step: 5
Training loss: 0.6265225937613657
Validation loss: 2.533199353721714

Epoch: 6| Step: 6
Training loss: 0.33151334874648714
Validation loss: 2.5193789887071403

Epoch: 6| Step: 7
Training loss: 0.26119120650389704
Validation loss: 2.547311974473863

Epoch: 6| Step: 8
Training loss: 0.4131654883727342
Validation loss: 2.5451397747635585

Epoch: 6| Step: 9
Training loss: 0.3721151249849964
Validation loss: 2.545496445918113

Epoch: 6| Step: 10
Training loss: 0.5929715424121348
Validation loss: 2.49976904427797

Epoch: 6| Step: 11
Training loss: 0.43652953073230066
Validation loss: 2.5172749945470203

Epoch: 6| Step: 12
Training loss: 0.3946678378416954
Validation loss: 2.4830562656533304

Epoch: 6| Step: 13
Training loss: 0.6843625132845582
Validation loss: 2.4864056868846536

Epoch: 355| Step: 0
Training loss: 0.5320343230350603
Validation loss: 2.4844234640087373

Epoch: 6| Step: 1
Training loss: 0.6000386543538258
Validation loss: 2.504237691359935

Epoch: 6| Step: 2
Training loss: 0.28482511968992696
Validation loss: 2.512383411346968

Epoch: 6| Step: 3
Training loss: 0.5885237519454962
Validation loss: 2.492939270941252

Epoch: 6| Step: 4
Training loss: 0.6351111542668375
Validation loss: 2.512881435936177

Epoch: 6| Step: 5
Training loss: 0.47751363050768814
Validation loss: 2.497880012188331

Epoch: 6| Step: 6
Training loss: 0.28800593412928377
Validation loss: 2.5411563268813904

Epoch: 6| Step: 7
Training loss: 0.4303969508558081
Validation loss: 2.550952774640504

Epoch: 6| Step: 8
Training loss: 0.4105046926618165
Validation loss: 2.5792648883042757

Epoch: 6| Step: 9
Training loss: 0.4769882582862773
Validation loss: 2.5788664178376366

Epoch: 6| Step: 10
Training loss: 0.6344708036795237
Validation loss: 2.574215669210129

Epoch: 6| Step: 11
Training loss: 0.5014904576550885
Validation loss: 2.5762393890977693

Epoch: 6| Step: 12
Training loss: 0.3687094940955879
Validation loss: 2.5318262590502325

Epoch: 6| Step: 13
Training loss: 0.6663981930244557
Validation loss: 2.5640719264714797

Epoch: 356| Step: 0
Training loss: 0.4784093154837918
Validation loss: 2.5189094011994886

Epoch: 6| Step: 1
Training loss: 0.717689727261509
Validation loss: 2.511932716575382

Epoch: 6| Step: 2
Training loss: 0.4213764635873712
Validation loss: 2.5054573104379654

Epoch: 6| Step: 3
Training loss: 0.45735751838668237
Validation loss: 2.4896134329955237

Epoch: 6| Step: 4
Training loss: 0.38749491703637456
Validation loss: 2.492447974650212

Epoch: 6| Step: 5
Training loss: 0.3838113482268072
Validation loss: 2.5018236184829794

Epoch: 6| Step: 6
Training loss: 0.26518572219227543
Validation loss: 2.486292607646042

Epoch: 6| Step: 7
Training loss: 0.5761525296341843
Validation loss: 2.4711225129137584

Epoch: 6| Step: 8
Training loss: 0.47632887069546176
Validation loss: 2.4886824006199904

Epoch: 6| Step: 9
Training loss: 0.4762253897858834
Validation loss: 2.50334167284202

Epoch: 6| Step: 10
Training loss: 0.5087715482717573
Validation loss: 2.5292857641293662

Epoch: 6| Step: 11
Training loss: 0.5608419777977203
Validation loss: 2.522716179743769

Epoch: 6| Step: 12
Training loss: 0.34875315237500565
Validation loss: 2.5925947023865916

Epoch: 6| Step: 13
Training loss: 0.5418575635170418
Validation loss: 2.5587163945092315

Epoch: 357| Step: 0
Training loss: 0.4446303010881389
Validation loss: 2.5566426164368368

Epoch: 6| Step: 1
Training loss: 0.3098379957364035
Validation loss: 2.566564931905525

Epoch: 6| Step: 2
Training loss: 0.4436260043434088
Validation loss: 2.5516729437168664

Epoch: 6| Step: 3
Training loss: 0.5176026536419515
Validation loss: 2.5580093599395624

Epoch: 6| Step: 4
Training loss: 0.48952253112918487
Validation loss: 2.562564591925047

Epoch: 6| Step: 5
Training loss: 0.6058561992746496
Validation loss: 2.52445170621462

Epoch: 6| Step: 6
Training loss: 0.5284232499396793
Validation loss: 2.5457638827553333

Epoch: 6| Step: 7
Training loss: 0.142039142490073
Validation loss: 2.504801855718207

Epoch: 6| Step: 8
Training loss: 0.46747864929444405
Validation loss: 2.486556945396282

Epoch: 6| Step: 9
Training loss: 0.2746233294917587
Validation loss: 2.5059227342556007

Epoch: 6| Step: 10
Training loss: 0.4923453002343549
Validation loss: 2.4768129486537522

Epoch: 6| Step: 11
Training loss: 0.6750758464021197
Validation loss: 2.4848641968861487

Epoch: 6| Step: 12
Training loss: 0.35878348390315545
Validation loss: 2.477065872427112

Epoch: 6| Step: 13
Training loss: 0.39076821562860736
Validation loss: 2.487828588856152

Epoch: 358| Step: 0
Training loss: 0.5746537721080444
Validation loss: 2.505896411488704

Epoch: 6| Step: 1
Training loss: 0.43049616579237965
Validation loss: 2.5639224742580935

Epoch: 6| Step: 2
Training loss: 0.3674104297890445
Validation loss: 2.583769168733936

Epoch: 6| Step: 3
Training loss: 0.4297911778994413
Validation loss: 2.605622031491507

Epoch: 6| Step: 4
Training loss: 0.6054098285184726
Validation loss: 2.5576305438468525

Epoch: 6| Step: 5
Training loss: 0.5781258763487076
Validation loss: 2.576960408328738

Epoch: 6| Step: 6
Training loss: 0.5818413802369661
Validation loss: 2.565421566154666

Epoch: 6| Step: 7
Training loss: 0.42427034643856926
Validation loss: 2.6038294977933987

Epoch: 6| Step: 8
Training loss: 0.3575850359278227
Validation loss: 2.5125530106926313

Epoch: 6| Step: 9
Training loss: 0.3852002356678548
Validation loss: 2.511253386673523

Epoch: 6| Step: 10
Training loss: 0.3576600787089922
Validation loss: 2.4966526125125656

Epoch: 6| Step: 11
Training loss: 0.5170473940448035
Validation loss: 2.482639875200724

Epoch: 6| Step: 12
Training loss: 0.25303559313760726
Validation loss: 2.516451108472765

Epoch: 6| Step: 13
Training loss: 0.5917980836157213
Validation loss: 2.5180196022814916

Epoch: 359| Step: 0
Training loss: 0.4565740727727528
Validation loss: 2.513526482993905

Epoch: 6| Step: 1
Training loss: 0.4196154163687777
Validation loss: 2.5403247446499235

Epoch: 6| Step: 2
Training loss: 0.5954377130304034
Validation loss: 2.564213962641505

Epoch: 6| Step: 3
Training loss: 0.3003360500291325
Validation loss: 2.559193721922648

Epoch: 6| Step: 4
Training loss: 0.3674490382742666
Validation loss: 2.565688921485206

Epoch: 6| Step: 5
Training loss: 0.4897771580163183
Validation loss: 2.5791048914216184

Epoch: 6| Step: 6
Training loss: 0.4333986410421587
Validation loss: 2.591830446072062

Epoch: 6| Step: 7
Training loss: 0.30464365227956
Validation loss: 2.5809541891854657

Epoch: 6| Step: 8
Training loss: 0.49423976702750394
Validation loss: 2.5494528504952414

Epoch: 6| Step: 9
Training loss: 0.5728146259874015
Validation loss: 2.5333810209450127

Epoch: 6| Step: 10
Training loss: 0.5094505008371946
Validation loss: 2.5226485106204795

Epoch: 6| Step: 11
Training loss: 0.40359633562690095
Validation loss: 2.475378045495994

Epoch: 6| Step: 12
Training loss: 0.36269107173151616
Validation loss: 2.5106346237612187

Epoch: 6| Step: 13
Training loss: 0.40950689229533055
Validation loss: 2.4860789999537305

Epoch: 360| Step: 0
Training loss: 0.5134727178975982
Validation loss: 2.522864589067471

Epoch: 6| Step: 1
Training loss: 0.38473772054265787
Validation loss: 2.496091363109009

Epoch: 6| Step: 2
Training loss: 0.4625385893368353
Validation loss: 2.500620644961565

Epoch: 6| Step: 3
Training loss: 0.5266309088124895
Validation loss: 2.4944155597065736

Epoch: 6| Step: 4
Training loss: 0.3191147484438314
Validation loss: 2.5334754052611412

Epoch: 6| Step: 5
Training loss: 0.4515867431363124
Validation loss: 2.486420365052643

Epoch: 6| Step: 6
Training loss: 0.34195275158302885
Validation loss: 2.5156889693133655

Epoch: 6| Step: 7
Training loss: 0.2539224179328803
Validation loss: 2.486453060679993

Epoch: 6| Step: 8
Training loss: 0.47053322159315514
Validation loss: 2.4852610570244877

Epoch: 6| Step: 9
Training loss: 0.3533593986489294
Validation loss: 2.4896364093535337

Epoch: 6| Step: 10
Training loss: 0.4481936160430855
Validation loss: 2.549280623566105

Epoch: 6| Step: 11
Training loss: 0.4930193698242612
Validation loss: 2.5056003845973622

Epoch: 6| Step: 12
Training loss: 0.49743048728603817
Validation loss: 2.5077184706072853

Epoch: 6| Step: 13
Training loss: 0.5995400354508688
Validation loss: 2.4817278940418204

Epoch: 361| Step: 0
Training loss: 0.4092282468983558
Validation loss: 2.5065960905436535

Epoch: 6| Step: 1
Training loss: 0.5214222503118464
Validation loss: 2.4937628168235264

Epoch: 6| Step: 2
Training loss: 0.40267704612073296
Validation loss: 2.4962622629461606

Epoch: 6| Step: 3
Training loss: 0.24408784677323891
Validation loss: 2.4951376411224637

Epoch: 6| Step: 4
Training loss: 0.4580921672905862
Validation loss: 2.5017140839386363

Epoch: 6| Step: 5
Training loss: 0.30496296290353797
Validation loss: 2.493362869148406

Epoch: 6| Step: 6
Training loss: 0.2292364521771053
Validation loss: 2.528825202863289

Epoch: 6| Step: 7
Training loss: 0.41027634088730514
Validation loss: 2.513722048456317

Epoch: 6| Step: 8
Training loss: 0.40895212623807414
Validation loss: 2.50201298877089

Epoch: 6| Step: 9
Training loss: 0.35581921498448393
Validation loss: 2.463552784061606

Epoch: 6| Step: 10
Training loss: 0.607211036520449
Validation loss: 2.500189509438486

Epoch: 6| Step: 11
Training loss: 0.7966855515818099
Validation loss: 2.5077193957886306

Epoch: 6| Step: 12
Training loss: 0.29938340798439195
Validation loss: 2.477674436553226

Epoch: 6| Step: 13
Training loss: 0.15669933916753187
Validation loss: 2.504882822734573

Epoch: 362| Step: 0
Training loss: 0.5609928178208486
Validation loss: 2.50292810502405

Epoch: 6| Step: 1
Training loss: 0.49247808809478444
Validation loss: 2.5025492150959256

Epoch: 6| Step: 2
Training loss: 0.50739828969692
Validation loss: 2.471243608209723

Epoch: 6| Step: 3
Training loss: 0.3778355996364432
Validation loss: 2.560877169316668

Epoch: 6| Step: 4
Training loss: 0.3928495768648316
Validation loss: 2.555138872616139

Epoch: 6| Step: 5
Training loss: 0.41441191918761566
Validation loss: 2.5667969807098525

Epoch: 6| Step: 6
Training loss: 0.4762382811508755
Validation loss: 2.5166217803891047

Epoch: 6| Step: 7
Training loss: 0.33793353210738625
Validation loss: 2.5406728590582692

Epoch: 6| Step: 8
Training loss: 0.37216701902830396
Validation loss: 2.533463314971519

Epoch: 6| Step: 9
Training loss: 0.5184282913907782
Validation loss: 2.4860326481856774

Epoch: 6| Step: 10
Training loss: 0.39023767341999216
Validation loss: 2.5002820194284263

Epoch: 6| Step: 11
Training loss: 0.39916831666582825
Validation loss: 2.5091585483819454

Epoch: 6| Step: 12
Training loss: 0.4797620615961165
Validation loss: 2.503451532478245

Epoch: 6| Step: 13
Training loss: 0.4940766153605357
Validation loss: 2.507288462530909

Epoch: 363| Step: 0
Training loss: 0.5606165719648021
Validation loss: 2.4917316460258756

Epoch: 6| Step: 1
Training loss: 0.28854289909586184
Validation loss: 2.4809718258695344

Epoch: 6| Step: 2
Training loss: 0.5591504983748472
Validation loss: 2.4860654994678923

Epoch: 6| Step: 3
Training loss: 0.538679567410743
Validation loss: 2.4926835086424686

Epoch: 6| Step: 4
Training loss: 0.4904807789941633
Validation loss: 2.474014704029141

Epoch: 6| Step: 5
Training loss: 0.3620129462016278
Validation loss: 2.4419691943801682

Epoch: 6| Step: 6
Training loss: 0.4976808137685267
Validation loss: 2.4677559016893693

Epoch: 6| Step: 7
Training loss: 0.4174428465549782
Validation loss: 2.476178205005407

Epoch: 6| Step: 8
Training loss: 0.35285676499417407
Validation loss: 2.4507870945275054

Epoch: 6| Step: 9
Training loss: 0.4286642201197108
Validation loss: 2.488552818496043

Epoch: 6| Step: 10
Training loss: 0.35552852253832934
Validation loss: 2.4800521592483045

Epoch: 6| Step: 11
Training loss: 0.45055694288366055
Validation loss: 2.484802961492393

Epoch: 6| Step: 12
Training loss: 0.26868174928277444
Validation loss: 2.4830143321921123

Epoch: 6| Step: 13
Training loss: 0.5656026730425016
Validation loss: 2.4528299309265607

Epoch: 364| Step: 0
Training loss: 0.42192253975218463
Validation loss: 2.4805040964985383

Epoch: 6| Step: 1
Training loss: 0.48022239075590867
Validation loss: 2.474077609457011

Epoch: 6| Step: 2
Training loss: 0.28631399882235925
Validation loss: 2.453018440109549

Epoch: 6| Step: 3
Training loss: 0.6059523097368431
Validation loss: 2.4690833457943757

Epoch: 6| Step: 4
Training loss: 0.3863308049216049
Validation loss: 2.4742095318881336

Epoch: 6| Step: 5
Training loss: 0.7177391407356728
Validation loss: 2.5070364587729492

Epoch: 6| Step: 6
Training loss: 0.28227703342774635
Validation loss: 2.5041479626569383

Epoch: 6| Step: 7
Training loss: 0.2864647459988536
Validation loss: 2.549636913535386

Epoch: 6| Step: 8
Training loss: 0.4004529950945709
Validation loss: 2.512324158975084

Epoch: 6| Step: 9
Training loss: 0.44516032111628406
Validation loss: 2.584691487200555

Epoch: 6| Step: 10
Training loss: 0.3900434743051962
Validation loss: 2.546554645437038

Epoch: 6| Step: 11
Training loss: 0.34185169325332904
Validation loss: 2.5720568688297756

Epoch: 6| Step: 12
Training loss: 0.5552014937942757
Validation loss: 2.5100007085109133

Epoch: 6| Step: 13
Training loss: 0.34134740431443916
Validation loss: 2.552157376897631

Epoch: 365| Step: 0
Training loss: 0.20906195582046733
Validation loss: 2.5244774150826865

Epoch: 6| Step: 1
Training loss: 0.5126031701984525
Validation loss: 2.476986807154546

Epoch: 6| Step: 2
Training loss: 0.4731515228416287
Validation loss: 2.4595875246030543

Epoch: 6| Step: 3
Training loss: 0.3254112351611844
Validation loss: 2.4406538575181584

Epoch: 6| Step: 4
Training loss: 0.5258568322552787
Validation loss: 2.4441769696501447

Epoch: 6| Step: 5
Training loss: 0.4779675049779613
Validation loss: 2.467049206629195

Epoch: 6| Step: 6
Training loss: 0.49000791813330513
Validation loss: 2.504548690763516

Epoch: 6| Step: 7
Training loss: 0.47688570163063054
Validation loss: 2.487146838467023

Epoch: 6| Step: 8
Training loss: 0.4731048787825973
Validation loss: 2.5030917134020942

Epoch: 6| Step: 9
Training loss: 0.5403994690691291
Validation loss: 2.476018063538263

Epoch: 6| Step: 10
Training loss: 0.4550813830344999
Validation loss: 2.4914641447776966

Epoch: 6| Step: 11
Training loss: 0.3016756063044721
Validation loss: 2.5194149666188204

Epoch: 6| Step: 12
Training loss: 0.4237009024519737
Validation loss: 2.5329090263657763

Epoch: 6| Step: 13
Training loss: 0.3060633455474746
Validation loss: 2.4991654633629774

Epoch: 366| Step: 0
Training loss: 0.2838403963837724
Validation loss: 2.517710219011337

Epoch: 6| Step: 1
Training loss: 0.37384265883363904
Validation loss: 2.5413835436075196

Epoch: 6| Step: 2
Training loss: 0.5680438079982032
Validation loss: 2.5208042427512654

Epoch: 6| Step: 3
Training loss: 0.4291432835711678
Validation loss: 2.5221154638878223

Epoch: 6| Step: 4
Training loss: 0.2594025304270524
Validation loss: 2.5129664252872117

Epoch: 6| Step: 5
Training loss: 0.4899293474915003
Validation loss: 2.467252112577117

Epoch: 6| Step: 6
Training loss: 0.5054980427244726
Validation loss: 2.4689409445122896

Epoch: 6| Step: 7
Training loss: 0.19225172233616133
Validation loss: 2.4888206635587458

Epoch: 6| Step: 8
Training loss: 0.3786231290822042
Validation loss: 2.505531327223754

Epoch: 6| Step: 9
Training loss: 0.36164223704181714
Validation loss: 2.480059826738259

Epoch: 6| Step: 10
Training loss: 0.6127596538348191
Validation loss: 2.5193356724799236

Epoch: 6| Step: 11
Training loss: 0.45764824391060116
Validation loss: 2.4914428388439624

Epoch: 6| Step: 12
Training loss: 0.5455777176408284
Validation loss: 2.5093995456912324

Epoch: 6| Step: 13
Training loss: 0.4198311108815176
Validation loss: 2.5238397698543773

Epoch: 367| Step: 0
Training loss: 0.22684557265440053
Validation loss: 2.535992263559391

Epoch: 6| Step: 1
Training loss: 0.41810108478503955
Validation loss: 2.5804091074487006

Epoch: 6| Step: 2
Training loss: 0.23271361241433083
Validation loss: 2.585889440539188

Epoch: 6| Step: 3
Training loss: 0.4336473758287354
Validation loss: 2.621615138277155

Epoch: 6| Step: 4
Training loss: 0.4751833047537381
Validation loss: 2.581069044437373

Epoch: 6| Step: 5
Training loss: 0.5129036035224822
Validation loss: 2.5774657081710037

Epoch: 6| Step: 6
Training loss: 0.3610028013796966
Validation loss: 2.5704137375308087

Epoch: 6| Step: 7
Training loss: 0.4674252705591768
Validation loss: 2.516937378235251

Epoch: 6| Step: 8
Training loss: 0.2524484305077805
Validation loss: 2.5056969847840045

Epoch: 6| Step: 9
Training loss: 0.5440724085694859
Validation loss: 2.480459658530423

Epoch: 6| Step: 10
Training loss: 0.34505721274348033
Validation loss: 2.500579652446611

Epoch: 6| Step: 11
Training loss: 0.7407225757817606
Validation loss: 2.4834673226875075

Epoch: 6| Step: 12
Training loss: 0.47588508174528604
Validation loss: 2.488358571741812

Epoch: 6| Step: 13
Training loss: 0.18342055612907687
Validation loss: 2.4740637471269156

Epoch: 368| Step: 0
Training loss: 0.2697279806465805
Validation loss: 2.5105955735591166

Epoch: 6| Step: 1
Training loss: 0.40561468625585556
Validation loss: 2.551580672311195

Epoch: 6| Step: 2
Training loss: 0.28428743554839875
Validation loss: 2.5399125587508906

Epoch: 6| Step: 3
Training loss: 0.1813556733051479
Validation loss: 2.575737024695989

Epoch: 6| Step: 4
Training loss: 0.479183680467271
Validation loss: 2.564102972060582

Epoch: 6| Step: 5
Training loss: 0.22615140581813645
Validation loss: 2.5678363503473016

Epoch: 6| Step: 6
Training loss: 0.5242890789763723
Validation loss: 2.568876992497181

Epoch: 6| Step: 7
Training loss: 0.5304010845281839
Validation loss: 2.540312708151691

Epoch: 6| Step: 8
Training loss: 0.4380276087154887
Validation loss: 2.5478592020393793

Epoch: 6| Step: 9
Training loss: 0.4517085693806111
Validation loss: 2.527317507312902

Epoch: 6| Step: 10
Training loss: 0.45201108753691194
Validation loss: 2.5003735468314146

Epoch: 6| Step: 11
Training loss: 0.43579219529449054
Validation loss: 2.533577135254754

Epoch: 6| Step: 12
Training loss: 0.3912272578933191
Validation loss: 2.4848878810520088

Epoch: 6| Step: 13
Training loss: 0.5518965285131723
Validation loss: 2.478983799615243

Epoch: 369| Step: 0
Training loss: 0.3417184358236912
Validation loss: 2.483466441117828

Epoch: 6| Step: 1
Training loss: 0.34520636174466385
Validation loss: 2.4999360783926563

Epoch: 6| Step: 2
Training loss: 0.2483927200554419
Validation loss: 2.4910009666641857

Epoch: 6| Step: 3
Training loss: 0.2615796473908675
Validation loss: 2.481594805168092

Epoch: 6| Step: 4
Training loss: 0.5870247988718271
Validation loss: 2.4891639977940443

Epoch: 6| Step: 5
Training loss: 0.5391187776683645
Validation loss: 2.49657245524717

Epoch: 6| Step: 6
Training loss: 0.5032268942253443
Validation loss: 2.5045891705023533

Epoch: 6| Step: 7
Training loss: 0.3577352307108008
Validation loss: 2.5196679005343348

Epoch: 6| Step: 8
Training loss: 0.49866707277323935
Validation loss: 2.552880834887223

Epoch: 6| Step: 9
Training loss: 0.4698913348667652
Validation loss: 2.553463040339391

Epoch: 6| Step: 10
Training loss: 0.3455111514760912
Validation loss: 2.566831026566646

Epoch: 6| Step: 11
Training loss: 0.5177411380508575
Validation loss: 2.5952255760468503

Epoch: 6| Step: 12
Training loss: 0.44299415636621603
Validation loss: 2.578855446971508

Epoch: 6| Step: 13
Training loss: 0.2857524179020909
Validation loss: 2.596091520067732

Epoch: 370| Step: 0
Training loss: 0.3274172120068317
Validation loss: 2.55542823689994

Epoch: 6| Step: 1
Training loss: 0.2823018432321887
Validation loss: 2.534378315405378

Epoch: 6| Step: 2
Training loss: 0.43789591926416455
Validation loss: 2.5470614364736357

Epoch: 6| Step: 3
Training loss: 0.27289999857567393
Validation loss: 2.469928952169631

Epoch: 6| Step: 4
Training loss: 0.39199181800448535
Validation loss: 2.4540458567009633

Epoch: 6| Step: 5
Training loss: 0.5434346567159617
Validation loss: 2.4544755739551114

Epoch: 6| Step: 6
Training loss: 0.3684968532029345
Validation loss: 2.482553368992029

Epoch: 6| Step: 7
Training loss: 0.4865300169277449
Validation loss: 2.474448460126005

Epoch: 6| Step: 8
Training loss: 0.489490446112411
Validation loss: 2.449556450187187

Epoch: 6| Step: 9
Training loss: 0.4833109766897784
Validation loss: 2.4788024100821433

Epoch: 6| Step: 10
Training loss: 0.5396506376770431
Validation loss: 2.516460492183733

Epoch: 6| Step: 11
Training loss: 0.39113914985212467
Validation loss: 2.526174654989286

Epoch: 6| Step: 12
Training loss: 0.4868036725704232
Validation loss: 2.524477276972861

Epoch: 6| Step: 13
Training loss: 0.31720206175578447
Validation loss: 2.5215669073251332

Epoch: 371| Step: 0
Training loss: 0.4105785557276846
Validation loss: 2.5362984807649025

Epoch: 6| Step: 1
Training loss: 0.3942405460605385
Validation loss: 2.5617046832760013

Epoch: 6| Step: 2
Training loss: 0.29561373418992076
Validation loss: 2.566612755408097

Epoch: 6| Step: 3
Training loss: 0.3080422386422289
Validation loss: 2.51696476297186

Epoch: 6| Step: 4
Training loss: 0.6222892148514798
Validation loss: 2.505395368889969

Epoch: 6| Step: 5
Training loss: 0.5661484493369475
Validation loss: 2.4798191477299727

Epoch: 6| Step: 6
Training loss: 0.44067690523293745
Validation loss: 2.4407388925340054

Epoch: 6| Step: 7
Training loss: 0.4765648763628636
Validation loss: 2.463150775611141

Epoch: 6| Step: 8
Training loss: 0.42251527730418836
Validation loss: 2.479385649813738

Epoch: 6| Step: 9
Training loss: 0.42492563564784674
Validation loss: 2.459322911837078

Epoch: 6| Step: 10
Training loss: 0.5097422393462508
Validation loss: 2.479750745313511

Epoch: 6| Step: 11
Training loss: 0.44808809378478176
Validation loss: 2.4783936209858246

Epoch: 6| Step: 12
Training loss: 0.20042790183307335
Validation loss: 2.510730491129091

Epoch: 6| Step: 13
Training loss: 0.22013602358116252
Validation loss: 2.4847923780046672

Epoch: 372| Step: 0
Training loss: 0.3183130686964778
Validation loss: 2.4732160099398404

Epoch: 6| Step: 1
Training loss: 0.3478701394297034
Validation loss: 2.476852704843894

Epoch: 6| Step: 2
Training loss: 0.229756296650087
Validation loss: 2.4885922769106075

Epoch: 6| Step: 3
Training loss: 0.2377119376669617
Validation loss: 2.5033728141217106

Epoch: 6| Step: 4
Training loss: 0.4999252352845278
Validation loss: 2.491151931750874

Epoch: 6| Step: 5
Training loss: 0.3162464633186013
Validation loss: 2.5284467072765953

Epoch: 6| Step: 6
Training loss: 0.34450638523468363
Validation loss: 2.507316007865393

Epoch: 6| Step: 7
Training loss: 0.41373225303689787
Validation loss: 2.4910203395124157

Epoch: 6| Step: 8
Training loss: 0.3491916078435468
Validation loss: 2.4847482844687527

Epoch: 6| Step: 9
Training loss: 0.5406724688467149
Validation loss: 2.498915696086955

Epoch: 6| Step: 10
Training loss: 0.5795147918725627
Validation loss: 2.4937271627430633

Epoch: 6| Step: 11
Training loss: 0.5136083991570147
Validation loss: 2.50264189805044

Epoch: 6| Step: 12
Training loss: 0.39046244099844896
Validation loss: 2.518449517755293

Epoch: 6| Step: 13
Training loss: 0.37110979145915346
Validation loss: 2.509529756360519

Epoch: 373| Step: 0
Training loss: 0.41902371542124717
Validation loss: 2.488620115201303

Epoch: 6| Step: 1
Training loss: 0.5113207018774587
Validation loss: 2.5448297950121654

Epoch: 6| Step: 2
Training loss: 0.3714338250168574
Validation loss: 2.5390086370391827

Epoch: 6| Step: 3
Training loss: 0.42522372920516843
Validation loss: 2.5147108463993946

Epoch: 6| Step: 4
Training loss: 0.45561924471575754
Validation loss: 2.5086956470848034

Epoch: 6| Step: 5
Training loss: 0.3179354038608113
Validation loss: 2.484161595838725

Epoch: 6| Step: 6
Training loss: 0.31005495324588295
Validation loss: 2.5158847763114527

Epoch: 6| Step: 7
Training loss: 0.27718112099585235
Validation loss: 2.461690133086296

Epoch: 6| Step: 8
Training loss: 0.4406644275962359
Validation loss: 2.4934391737718844

Epoch: 6| Step: 9
Training loss: 0.3219987399938466
Validation loss: 2.4846405395085065

Epoch: 6| Step: 10
Training loss: 0.29207694057991146
Validation loss: 2.498091712836676

Epoch: 6| Step: 11
Training loss: 0.5054853079912425
Validation loss: 2.4655902970268473

Epoch: 6| Step: 12
Training loss: 0.46320832693364133
Validation loss: 2.4828613895969562

Epoch: 6| Step: 13
Training loss: 0.13718670731839028
Validation loss: 2.4796960571727817

Epoch: 374| Step: 0
Training loss: 0.19295914969713995
Validation loss: 2.499157109244558

Epoch: 6| Step: 1
Training loss: 0.5631315606483409
Validation loss: 2.4657826979741126

Epoch: 6| Step: 2
Training loss: 0.31852921244290416
Validation loss: 2.5097589558386324

Epoch: 6| Step: 3
Training loss: 0.5441103125109706
Validation loss: 2.507086603457443

Epoch: 6| Step: 4
Training loss: 0.31883032899191527
Validation loss: 2.50284861940112

Epoch: 6| Step: 5
Training loss: 0.5370385695517197
Validation loss: 2.4997934297106346

Epoch: 6| Step: 6
Training loss: 0.41130194730137704
Validation loss: 2.4962770520963873

Epoch: 6| Step: 7
Training loss: 0.2670523915367482
Validation loss: 2.52121548835274

Epoch: 6| Step: 8
Training loss: 0.30182812312948115
Validation loss: 2.5376150958524883

Epoch: 6| Step: 9
Training loss: 0.5218758131923165
Validation loss: 2.4904978805708113

Epoch: 6| Step: 10
Training loss: 0.30497359024680154
Validation loss: 2.48738861415865

Epoch: 6| Step: 11
Training loss: 0.2953789434415934
Validation loss: 2.5073742206726095

Epoch: 6| Step: 12
Training loss: 0.32966731538498223
Validation loss: 2.5186170718755085

Epoch: 6| Step: 13
Training loss: 0.3162587964300889
Validation loss: 2.483502301860452

Epoch: 375| Step: 0
Training loss: 0.37304975099104076
Validation loss: 2.496764792834038

Epoch: 6| Step: 1
Training loss: 0.4104283474778407
Validation loss: 2.457814178655017

Epoch: 6| Step: 2
Training loss: 0.43532871547492025
Validation loss: 2.480927387495924

Epoch: 6| Step: 3
Training loss: 0.29133474531193443
Validation loss: 2.506200668614177

Epoch: 6| Step: 4
Training loss: 0.49116690345409386
Validation loss: 2.47980975252458

Epoch: 6| Step: 5
Training loss: 0.3739487297007967
Validation loss: 2.4846390119349735

Epoch: 6| Step: 6
Training loss: 0.44386999831501023
Validation loss: 2.535840657029285

Epoch: 6| Step: 7
Training loss: 0.2698214254327878
Validation loss: 2.5105000273021916

Epoch: 6| Step: 8
Training loss: 0.46600507674705793
Validation loss: 2.5286630374526

Epoch: 6| Step: 9
Training loss: 0.3308183845070162
Validation loss: 2.532825535156431

Epoch: 6| Step: 10
Training loss: 0.4672590704864634
Validation loss: 2.504865986805245

Epoch: 6| Step: 11
Training loss: 0.3320989651911694
Validation loss: 2.525080441233545

Epoch: 6| Step: 12
Training loss: 0.28574973231358974
Validation loss: 2.514115584081159

Epoch: 6| Step: 13
Training loss: 0.29953430608027115
Validation loss: 2.5161511841520103

Epoch: 376| Step: 0
Training loss: 0.3891004183878496
Validation loss: 2.5091586147933085

Epoch: 6| Step: 1
Training loss: 0.4155538978564137
Validation loss: 2.521874189434518

Epoch: 6| Step: 2
Training loss: 0.2939395080196081
Validation loss: 2.476717461842259

Epoch: 6| Step: 3
Training loss: 0.25661692691355054
Validation loss: 2.5139738720356415

Epoch: 6| Step: 4
Training loss: 0.4769491284552114
Validation loss: 2.510017637669575

Epoch: 6| Step: 5
Training loss: 0.4405194886677839
Validation loss: 2.493178298828766

Epoch: 6| Step: 6
Training loss: 0.318058573901936
Validation loss: 2.504387664038557

Epoch: 6| Step: 7
Training loss: 0.1645552694008572
Validation loss: 2.4744911795300957

Epoch: 6| Step: 8
Training loss: 0.4910195434705296
Validation loss: 2.4882531848587557

Epoch: 6| Step: 9
Training loss: 0.49997539757758974
Validation loss: 2.501969559399469

Epoch: 6| Step: 10
Training loss: 0.2910118486812256
Validation loss: 2.484781609790982

Epoch: 6| Step: 11
Training loss: 0.26646959441077933
Validation loss: 2.4909306925127725

Epoch: 6| Step: 12
Training loss: 0.4420084938078992
Validation loss: 2.503440708326171

Epoch: 6| Step: 13
Training loss: 0.4676241387566062
Validation loss: 2.5115604714697657

Epoch: 377| Step: 0
Training loss: 0.28308700285498306
Validation loss: 2.4794944239063987

Epoch: 6| Step: 1
Training loss: 0.2880708076254092
Validation loss: 2.4763835214613796

Epoch: 6| Step: 2
Training loss: 0.32354284404598543
Validation loss: 2.4773657405068175

Epoch: 6| Step: 3
Training loss: 0.3876902966691339
Validation loss: 2.4765016535307263

Epoch: 6| Step: 4
Training loss: 0.25826788189788286
Validation loss: 2.5306329156026184

Epoch: 6| Step: 5
Training loss: 0.5468472609978122
Validation loss: 2.4963038737357244

Epoch: 6| Step: 6
Training loss: 0.47253361206493616
Validation loss: 2.501427231773534

Epoch: 6| Step: 7
Training loss: 0.45561481312691515
Validation loss: 2.513222131451365

Epoch: 6| Step: 8
Training loss: 0.4610123007906135
Validation loss: 2.504094951924684

Epoch: 6| Step: 9
Training loss: 0.3597271272189061
Validation loss: 2.496170471307456

Epoch: 6| Step: 10
Training loss: 0.5444723483263783
Validation loss: 2.510358887796691

Epoch: 6| Step: 11
Training loss: 0.3062964165798019
Validation loss: 2.485456080670399

Epoch: 6| Step: 12
Training loss: 0.23715718712686265
Validation loss: 2.5400435477888657

Epoch: 6| Step: 13
Training loss: 0.17527510570584964
Validation loss: 2.505984578626118

Epoch: 378| Step: 0
Training loss: 0.27365162503624096
Validation loss: 2.4953242075725575

Epoch: 6| Step: 1
Training loss: 0.4023924492557015
Validation loss: 2.508429753557765

Epoch: 6| Step: 2
Training loss: 0.39432567490500775
Validation loss: 2.525040956025126

Epoch: 6| Step: 3
Training loss: 0.40497212066766575
Validation loss: 2.5029083408906283

Epoch: 6| Step: 4
Training loss: 0.2824559582923053
Validation loss: 2.49864771683513

Epoch: 6| Step: 5
Training loss: 0.5917701841070017
Validation loss: 2.4947844142184565

Epoch: 6| Step: 6
Training loss: 0.357731627607657
Validation loss: 2.5059253378722004

Epoch: 6| Step: 7
Training loss: 0.45335096447098316
Validation loss: 2.510363781500938

Epoch: 6| Step: 8
Training loss: 0.3954818905471304
Validation loss: 2.474985109128849

Epoch: 6| Step: 9
Training loss: 0.2866236152083113
Validation loss: 2.4450878700753016

Epoch: 6| Step: 10
Training loss: 0.1861219529049163
Validation loss: 2.446766483671446

Epoch: 6| Step: 11
Training loss: 0.4493539523791639
Validation loss: 2.449500941397982

Epoch: 6| Step: 12
Training loss: 0.40790842908439257
Validation loss: 2.4672772589132106

Epoch: 6| Step: 13
Training loss: 0.17782497192984856
Validation loss: 2.468376915496893

Epoch: 379| Step: 0
Training loss: 0.39745325179483615
Validation loss: 2.4260119018946487

Epoch: 6| Step: 1
Training loss: 0.4090899093572365
Validation loss: 2.476122301670079

Epoch: 6| Step: 2
Training loss: 0.45506435586293903
Validation loss: 2.5049657915094254

Epoch: 6| Step: 3
Training loss: 0.2107771953110768
Validation loss: 2.4857451719225345

Epoch: 6| Step: 4
Training loss: 0.3507949715970002
Validation loss: 2.496464187536572

Epoch: 6| Step: 5
Training loss: 0.3904463741062811
Validation loss: 2.505751495255363

Epoch: 6| Step: 6
Training loss: 0.14310227032462589
Validation loss: 2.4966109192264487

Epoch: 6| Step: 7
Training loss: 0.3933489997957731
Validation loss: 2.479597138234514

Epoch: 6| Step: 8
Training loss: 0.3516551425516048
Validation loss: 2.496663859882067

Epoch: 6| Step: 9
Training loss: 0.38107190193464036
Validation loss: 2.470056785313364

Epoch: 6| Step: 10
Training loss: 0.45749158580525945
Validation loss: 2.488866932502501

Epoch: 6| Step: 11
Training loss: 0.48287463853088325
Validation loss: 2.5017531226490415

Epoch: 6| Step: 12
Training loss: 0.15049725010092702
Validation loss: 2.476342401557866

Epoch: 6| Step: 13
Training loss: 0.4765405493511899
Validation loss: 2.4765418463838507

Epoch: 380| Step: 0
Training loss: 0.4245568966832016
Validation loss: 2.5063677712059143

Epoch: 6| Step: 1
Training loss: 0.14768870869875242
Validation loss: 2.469210284663366

Epoch: 6| Step: 2
Training loss: 0.40417616880527124
Validation loss: 2.4704342713778926

Epoch: 6| Step: 3
Training loss: 0.33415304910512145
Validation loss: 2.491007428242109

Epoch: 6| Step: 4
Training loss: 0.2825721551941108
Validation loss: 2.485670685079702

Epoch: 6| Step: 5
Training loss: 0.2887794810268685
Validation loss: 2.4759097574613373

Epoch: 6| Step: 6
Training loss: 0.33236292933911527
Validation loss: 2.5058991266442585

Epoch: 6| Step: 7
Training loss: 0.5075997713982779
Validation loss: 2.49612328193836

Epoch: 6| Step: 8
Training loss: 0.3054628776512679
Validation loss: 2.4732169801612667

Epoch: 6| Step: 9
Training loss: 0.6210883278280175
Validation loss: 2.4338842640697353

Epoch: 6| Step: 10
Training loss: 0.396344540746884
Validation loss: 2.4994770846515597

Epoch: 6| Step: 11
Training loss: 0.26706177949350673
Validation loss: 2.493907880764822

Epoch: 6| Step: 12
Training loss: 0.11157219467327775
Validation loss: 2.500143294175774

Epoch: 6| Step: 13
Training loss: 0.46978031413986726
Validation loss: 2.4854480832570465

Epoch: 381| Step: 0
Training loss: 0.34847728348174106
Validation loss: 2.5099639092840307

Epoch: 6| Step: 1
Training loss: 0.2786178203417589
Validation loss: 2.491375120861252

Epoch: 6| Step: 2
Training loss: 0.5263008259854657
Validation loss: 2.4948747191056917

Epoch: 6| Step: 3
Training loss: 0.3902483841192404
Validation loss: 2.497594214177472

Epoch: 6| Step: 4
Training loss: 0.29175501858988323
Validation loss: 2.4736957286756307

Epoch: 6| Step: 5
Training loss: 0.39579734094848407
Validation loss: 2.495263152846513

Epoch: 6| Step: 6
Training loss: 0.3874192492116635
Validation loss: 2.4616575678288566

Epoch: 6| Step: 7
Training loss: 0.4590178781821518
Validation loss: 2.480173580870967

Epoch: 6| Step: 8
Training loss: 0.3052342717385587
Validation loss: 2.4440943854607853

Epoch: 6| Step: 9
Training loss: 0.3171114186711889
Validation loss: 2.484156579309312

Epoch: 6| Step: 10
Training loss: 0.24642141417659275
Validation loss: 2.4366567566137065

Epoch: 6| Step: 11
Training loss: 0.27651927524004005
Validation loss: 2.470251075369249

Epoch: 6| Step: 12
Training loss: 0.3718179562838884
Validation loss: 2.483878243060405

Epoch: 6| Step: 13
Training loss: 0.49316315603645033
Validation loss: 2.487122988728635

Epoch: 382| Step: 0
Training loss: 0.514630051344143
Validation loss: 2.5173047464633185

Epoch: 6| Step: 1
Training loss: 0.37532825805336467
Validation loss: 2.5221953867107088

Epoch: 6| Step: 2
Training loss: 0.39894083431236405
Validation loss: 2.5036002034105174

Epoch: 6| Step: 3
Training loss: 0.3253348569489067
Validation loss: 2.526135166587232

Epoch: 6| Step: 4
Training loss: 0.3667260781113863
Validation loss: 2.5246761736954975

Epoch: 6| Step: 5
Training loss: 0.39494287150153495
Validation loss: 2.541628752744555

Epoch: 6| Step: 6
Training loss: 0.1873792517798686
Validation loss: 2.4828775611033653

Epoch: 6| Step: 7
Training loss: 0.4651728194581684
Validation loss: 2.4949322809724883

Epoch: 6| Step: 8
Training loss: 0.2041310375778398
Validation loss: 2.508330959385651

Epoch: 6| Step: 9
Training loss: 0.414401617274111
Validation loss: 2.5296484730659814

Epoch: 6| Step: 10
Training loss: 0.4853463431678305
Validation loss: 2.519572448520825

Epoch: 6| Step: 11
Training loss: 0.29641585230418305
Validation loss: 2.5576428757275367

Epoch: 6| Step: 12
Training loss: 0.3292998217612629
Validation loss: 2.506940212895167

Epoch: 6| Step: 13
Training loss: 0.4635402933021803
Validation loss: 2.506230408788829

Epoch: 383| Step: 0
Training loss: 0.20982705216712647
Validation loss: 2.524049881251905

Epoch: 6| Step: 1
Training loss: 0.30317622518797527
Validation loss: 2.4759946315501824

Epoch: 6| Step: 2
Training loss: 0.19204102571217277
Validation loss: 2.48712836622657

Epoch: 6| Step: 3
Training loss: 0.316276370577473
Validation loss: 2.475076985749243

Epoch: 6| Step: 4
Training loss: 0.4819591480657292
Validation loss: 2.460576699420117

Epoch: 6| Step: 5
Training loss: 0.3378813858092073
Validation loss: 2.4438401888026333

Epoch: 6| Step: 6
Training loss: 0.4337308855819606
Validation loss: 2.472575606675518

Epoch: 6| Step: 7
Training loss: 0.44065216941126334
Validation loss: 2.4423604139725916

Epoch: 6| Step: 8
Training loss: 0.40767865962657784
Validation loss: 2.491188818483254

Epoch: 6| Step: 9
Training loss: 0.38554183972132644
Validation loss: 2.4517998665236354

Epoch: 6| Step: 10
Training loss: 0.4637488766422701
Validation loss: 2.4901972208743968

Epoch: 6| Step: 11
Training loss: 0.37095364385245366
Validation loss: 2.49672150936401

Epoch: 6| Step: 12
Training loss: 0.4113502199446189
Validation loss: 2.507847357347865

Epoch: 6| Step: 13
Training loss: 0.19914487329129177
Validation loss: 2.519124619362073

Epoch: 384| Step: 0
Training loss: 0.29636953640297714
Validation loss: 2.5232270500762497

Epoch: 6| Step: 1
Training loss: 0.2812774565328289
Validation loss: 2.5306194532348396

Epoch: 6| Step: 2
Training loss: 0.460805405261413
Validation loss: 2.545017687799361

Epoch: 6| Step: 3
Training loss: 0.47305889161626596
Validation loss: 2.5309706026951067

Epoch: 6| Step: 4
Training loss: 0.3524772293940508
Validation loss: 2.5614011425850562

Epoch: 6| Step: 5
Training loss: 0.2203505831464898
Validation loss: 2.5373452239653727

Epoch: 6| Step: 6
Training loss: 0.5136659571085557
Validation loss: 2.5173723127837007

Epoch: 6| Step: 7
Training loss: 0.3121694962863272
Validation loss: 2.5171146923321173

Epoch: 6| Step: 8
Training loss: 0.3274435278200613
Validation loss: 2.4839185492887403

Epoch: 6| Step: 9
Training loss: 0.3025117363111135
Validation loss: 2.4563404300712146

Epoch: 6| Step: 10
Training loss: 0.43720973126683493
Validation loss: 2.4769318856602953

Epoch: 6| Step: 11
Training loss: 0.28597210742412293
Validation loss: 2.4352689607951037

Epoch: 6| Step: 12
Training loss: 0.427354060019027
Validation loss: 2.5054220550539688

Epoch: 6| Step: 13
Training loss: 0.3208214856206091
Validation loss: 2.445743935141531

Epoch: 385| Step: 0
Training loss: 0.30581658796068634
Validation loss: 2.4931702578065464

Epoch: 6| Step: 1
Training loss: 0.5299621848795133
Validation loss: 2.47078177658328

Epoch: 6| Step: 2
Training loss: 0.15696652155393054
Validation loss: 2.5383532632999795

Epoch: 6| Step: 3
Training loss: 0.35676942486264546
Validation loss: 2.5358107561109926

Epoch: 6| Step: 4
Training loss: 0.23737641023806536
Validation loss: 2.5573522042091237

Epoch: 6| Step: 5
Training loss: 0.5028195158645
Validation loss: 2.5535801746841114

Epoch: 6| Step: 6
Training loss: 0.32752081331699023
Validation loss: 2.532330950007534

Epoch: 6| Step: 7
Training loss: 0.37958634681356906
Validation loss: 2.539302549160687

Epoch: 6| Step: 8
Training loss: 0.33819982680847
Validation loss: 2.5257381749535535

Epoch: 6| Step: 9
Training loss: 0.30017733945137454
Validation loss: 2.5403077999849777

Epoch: 6| Step: 10
Training loss: 0.45363243235062417
Validation loss: 2.496218802846397

Epoch: 6| Step: 11
Training loss: 0.5076121008200916
Validation loss: 2.458723762700406

Epoch: 6| Step: 12
Training loss: 0.2960222067243452
Validation loss: 2.4585998412247623

Epoch: 6| Step: 13
Training loss: 0.15022792933260484
Validation loss: 2.476903944466857

Epoch: 386| Step: 0
Training loss: 0.29086750536592326
Validation loss: 2.470315649390137

Epoch: 6| Step: 1
Training loss: 0.40830829853399475
Validation loss: 2.4411747968664526

Epoch: 6| Step: 2
Training loss: 0.2975887953051257
Validation loss: 2.4662347776608464

Epoch: 6| Step: 3
Training loss: 0.5427697729623252
Validation loss: 2.4863391473817087

Epoch: 6| Step: 4
Training loss: 0.3528977363280338
Validation loss: 2.4769616900460503

Epoch: 6| Step: 5
Training loss: 0.3984709332968524
Validation loss: 2.4680342160352717

Epoch: 6| Step: 6
Training loss: 0.32423821356387605
Validation loss: 2.4955529109050922

Epoch: 6| Step: 7
Training loss: 0.28354781648430477
Validation loss: 2.4656500085911235

Epoch: 6| Step: 8
Training loss: 0.27173601467481706
Validation loss: 2.482131106672143

Epoch: 6| Step: 9
Training loss: 0.24072144142447885
Validation loss: 2.4919768923465

Epoch: 6| Step: 10
Training loss: 0.24500910591213956
Validation loss: 2.474610408905733

Epoch: 6| Step: 11
Training loss: 0.541280743472451
Validation loss: 2.477988023852628

Epoch: 6| Step: 12
Training loss: 0.39903747040976395
Validation loss: 2.5107621319586113

Epoch: 6| Step: 13
Training loss: 0.25501332650236513
Validation loss: 2.4683991028737124

Epoch: 387| Step: 0
Training loss: 0.42826799524582365
Validation loss: 2.481098225724739

Epoch: 6| Step: 1
Training loss: 0.4896516109769986
Validation loss: 2.459709681812572

Epoch: 6| Step: 2
Training loss: 0.32428875132995216
Validation loss: 2.4647603360592063

Epoch: 6| Step: 3
Training loss: 0.44776365712571337
Validation loss: 2.4560712359188592

Epoch: 6| Step: 4
Training loss: 0.31646574897356483
Validation loss: 2.4653161158900896

Epoch: 6| Step: 5
Training loss: 0.35689353457152884
Validation loss: 2.471180558540238

Epoch: 6| Step: 6
Training loss: 0.16935320219490385
Validation loss: 2.478335237949259

Epoch: 6| Step: 7
Training loss: 0.3405413647438004
Validation loss: 2.4445831843839465

Epoch: 6| Step: 8
Training loss: 0.4248734692542886
Validation loss: 2.4822607090311384

Epoch: 6| Step: 9
Training loss: 0.30449264359944694
Validation loss: 2.4904279494244674

Epoch: 6| Step: 10
Training loss: 0.42230028333123737
Validation loss: 2.4708290530717623

Epoch: 6| Step: 11
Training loss: 0.26896899083772596
Validation loss: 2.496297479783768

Epoch: 6| Step: 12
Training loss: 0.3537198314675492
Validation loss: 2.543843533556802

Epoch: 6| Step: 13
Training loss: 0.18074839917472554
Validation loss: 2.508348964399483

Epoch: 388| Step: 0
Training loss: 0.19766376465998542
Validation loss: 2.5003973491285367

Epoch: 6| Step: 1
Training loss: 0.29794255101968
Validation loss: 2.4986841173966625

Epoch: 6| Step: 2
Training loss: 0.273478504921039
Validation loss: 2.5082152875709665

Epoch: 6| Step: 3
Training loss: 0.49126165594585247
Validation loss: 2.5140523130140795

Epoch: 6| Step: 4
Training loss: 0.4260282237660989
Validation loss: 2.507725596028282

Epoch: 6| Step: 5
Training loss: 0.3929868439894133
Validation loss: 2.4819124125873273

Epoch: 6| Step: 6
Training loss: 0.34401708760556815
Validation loss: 2.494936606394859

Epoch: 6| Step: 7
Training loss: 0.28407178055781074
Validation loss: 2.4937507241827555

Epoch: 6| Step: 8
Training loss: 0.23259182334490436
Validation loss: 2.484036254903514

Epoch: 6| Step: 9
Training loss: 0.3921411084097157
Validation loss: 2.532391711870734

Epoch: 6| Step: 10
Training loss: 0.4284116008451373
Validation loss: 2.506721435323877

Epoch: 6| Step: 11
Training loss: 0.32889697680233576
Validation loss: 2.511495170044609

Epoch: 6| Step: 12
Training loss: 0.35419645137457784
Validation loss: 2.524172929555544

Epoch: 6| Step: 13
Training loss: 0.3195453388866786
Validation loss: 2.5047816084376757

Epoch: 389| Step: 0
Training loss: 0.22413156522335792
Validation loss: 2.5151303782808894

Epoch: 6| Step: 1
Training loss: 0.29678909414062715
Validation loss: 2.4868655169731784

Epoch: 6| Step: 2
Training loss: 0.31102687998349826
Validation loss: 2.4765782861532224

Epoch: 6| Step: 3
Training loss: 0.1502452680454347
Validation loss: 2.4706225102745947

Epoch: 6| Step: 4
Training loss: 0.37623933799185966
Validation loss: 2.4860256596141395

Epoch: 6| Step: 5
Training loss: 0.38283324671987756
Validation loss: 2.507939584863938

Epoch: 6| Step: 6
Training loss: 0.33788945633349876
Validation loss: 2.4861712234702207

Epoch: 6| Step: 7
Training loss: 0.3112898641550371
Validation loss: 2.514990228478094

Epoch: 6| Step: 8
Training loss: 0.35545411970611507
Validation loss: 2.49470725053596

Epoch: 6| Step: 9
Training loss: 0.27783554423546564
Validation loss: 2.4553863843272135

Epoch: 6| Step: 10
Training loss: 0.37147528459756396
Validation loss: 2.502547067928132

Epoch: 6| Step: 11
Training loss: 0.4490941413876096
Validation loss: 2.493062131301776

Epoch: 6| Step: 12
Training loss: 0.5392910016936603
Validation loss: 2.5077955273317856

Epoch: 6| Step: 13
Training loss: 0.3301635834709457
Validation loss: 2.4480289228398138

Epoch: 390| Step: 0
Training loss: 0.2774644911231155
Validation loss: 2.4860338887401476

Epoch: 6| Step: 1
Training loss: 0.3307812329356712
Validation loss: 2.478221826669046

Epoch: 6| Step: 2
Training loss: 0.22188453620242993
Validation loss: 2.4904900954429534

Epoch: 6| Step: 3
Training loss: 0.29352075072243194
Validation loss: 2.478168290314144

Epoch: 6| Step: 4
Training loss: 0.23693520623789577
Validation loss: 2.4887329784656376

Epoch: 6| Step: 5
Training loss: 0.271119593067345
Validation loss: 2.530905703827884

Epoch: 6| Step: 6
Training loss: 0.6007149906601422
Validation loss: 2.4777361657670443

Epoch: 6| Step: 7
Training loss: 0.33984348691732813
Validation loss: 2.493296403239047

Epoch: 6| Step: 8
Training loss: 0.47265900855402243
Validation loss: 2.4833493650581957

Epoch: 6| Step: 9
Training loss: 0.3546426417010271
Validation loss: 2.5043684365652727

Epoch: 6| Step: 10
Training loss: 0.18080473912919956
Validation loss: 2.4845213787295655

Epoch: 6| Step: 11
Training loss: 0.3846396225389598
Validation loss: 2.5061314405822475

Epoch: 6| Step: 12
Training loss: 0.29505391985912854
Validation loss: 2.5239044055169195

Epoch: 6| Step: 13
Training loss: 0.4197279193868667
Validation loss: 2.5516621302140257

Epoch: 391| Step: 0
Training loss: 0.28963177273552637
Validation loss: 2.530211216909611

Epoch: 6| Step: 1
Training loss: 0.45124593349854136
Validation loss: 2.5383895600689925

Epoch: 6| Step: 2
Training loss: 0.2433785714160259
Validation loss: 2.5215541458558297

Epoch: 6| Step: 3
Training loss: 0.35390095233110025
Validation loss: 2.5196310318812487

Epoch: 6| Step: 4
Training loss: 0.3940410779413665
Validation loss: 2.486048208179437

Epoch: 6| Step: 5
Training loss: 0.28652444278928135
Validation loss: 2.515489759448687

Epoch: 6| Step: 6
Training loss: 0.39445330539154505
Validation loss: 2.5093967372695674

Epoch: 6| Step: 7
Training loss: 0.23643315558610603
Validation loss: 2.5081457668557294

Epoch: 6| Step: 8
Training loss: 0.32258348683626475
Validation loss: 2.507418060998914

Epoch: 6| Step: 9
Training loss: 0.2347950191788745
Validation loss: 2.492544249405966

Epoch: 6| Step: 10
Training loss: 0.4809648542203644
Validation loss: 2.5287650735744136

Epoch: 6| Step: 11
Training loss: 0.3825421254329398
Validation loss: 2.5136408358172044

Epoch: 6| Step: 12
Training loss: 0.3736666977587734
Validation loss: 2.5100096648926975

Epoch: 6| Step: 13
Training loss: 0.16766911217341157
Validation loss: 2.4821444307697957

Epoch: 392| Step: 0
Training loss: 0.3515714432320603
Validation loss: 2.486325042023873

Epoch: 6| Step: 1
Training loss: 0.3758958407854147
Validation loss: 2.5001008249276047

Epoch: 6| Step: 2
Training loss: 0.33955335816312576
Validation loss: 2.492283974085781

Epoch: 6| Step: 3
Training loss: 0.3555948222518217
Validation loss: 2.4775569833200026

Epoch: 6| Step: 4
Training loss: 0.4391392922359996
Validation loss: 2.4915921864531168

Epoch: 6| Step: 5
Training loss: 0.35555243293107913
Validation loss: 2.4691274138201402

Epoch: 6| Step: 6
Training loss: 0.5012024784630417
Validation loss: 2.4408247585394798

Epoch: 6| Step: 7
Training loss: 0.1494679821185295
Validation loss: 2.5032452449645377

Epoch: 6| Step: 8
Training loss: 0.23389531957943052
Validation loss: 2.467703628028236

Epoch: 6| Step: 9
Training loss: 0.21221057521987302
Validation loss: 2.5002708985596787

Epoch: 6| Step: 10
Training loss: 0.4850405151119325
Validation loss: 2.5039140937521958

Epoch: 6| Step: 11
Training loss: 0.2688980958667607
Validation loss: 2.4752221339363287

Epoch: 6| Step: 12
Training loss: 0.24476211788856211
Validation loss: 2.4928537818550534

Epoch: 6| Step: 13
Training loss: 0.2513080589624942
Validation loss: 2.5056380301068817

Epoch: 393| Step: 0
Training loss: 0.1929585319006759
Validation loss: 2.49853111101519

Epoch: 6| Step: 1
Training loss: 0.6042311787418281
Validation loss: 2.4968007444251574

Epoch: 6| Step: 2
Training loss: 0.26126683062315215
Validation loss: 2.498019742643165

Epoch: 6| Step: 3
Training loss: 0.23059508530250433
Validation loss: 2.513835082944459

Epoch: 6| Step: 4
Training loss: 0.29115127115966266
Validation loss: 2.4716303450507064

Epoch: 6| Step: 5
Training loss: 0.46503108120685716
Validation loss: 2.489751243686939

Epoch: 6| Step: 6
Training loss: 0.30472266165490014
Validation loss: 2.470768148414613

Epoch: 6| Step: 7
Training loss: 0.17169194335068905
Validation loss: 2.499000937277575

Epoch: 6| Step: 8
Training loss: 0.19578540770187147
Validation loss: 2.455055366128881

Epoch: 6| Step: 9
Training loss: 0.216927514795162
Validation loss: 2.5090694809885106

Epoch: 6| Step: 10
Training loss: 0.20744067320619175
Validation loss: 2.4823279083171568

Epoch: 6| Step: 11
Training loss: 0.4894276702910898
Validation loss: 2.497692940743885

Epoch: 6| Step: 12
Training loss: 0.4229383137366606
Validation loss: 2.4679953731652318

Epoch: 6| Step: 13
Training loss: 0.4340665662175449
Validation loss: 2.4771099236697403

Epoch: 394| Step: 0
Training loss: 0.45279224279358904
Validation loss: 2.478567860948715

Epoch: 6| Step: 1
Training loss: 0.3510517224570439
Validation loss: 2.486309030077347

Epoch: 6| Step: 2
Training loss: 0.31575687316245893
Validation loss: 2.4736995072432655

Epoch: 6| Step: 3
Training loss: 0.3497194085038685
Validation loss: 2.4869809060116697

Epoch: 6| Step: 4
Training loss: 0.37999029526741024
Validation loss: 2.5044655868709182

Epoch: 6| Step: 5
Training loss: 0.21503783042894303
Validation loss: 2.4938533694404823

Epoch: 6| Step: 6
Training loss: 0.41216451267004034
Validation loss: 2.537110673437271

Epoch: 6| Step: 7
Training loss: 0.13361795997987394
Validation loss: 2.4863592246945556

Epoch: 6| Step: 8
Training loss: 0.3177791644179958
Validation loss: 2.511497492789099

Epoch: 6| Step: 9
Training loss: 0.28593824886786784
Validation loss: 2.4774126476567493

Epoch: 6| Step: 10
Training loss: 0.2658102567565965
Validation loss: 2.5172170906514513

Epoch: 6| Step: 11
Training loss: 0.23893463729552433
Validation loss: 2.508267460251997

Epoch: 6| Step: 12
Training loss: 0.4160799505084917
Validation loss: 2.4758009216585135

Epoch: 6| Step: 13
Training loss: 0.45844864117294837
Validation loss: 2.44843558154925

Epoch: 395| Step: 0
Training loss: 0.3203111508969064
Validation loss: 2.461895439981285

Epoch: 6| Step: 1
Training loss: 0.38271618624074794
Validation loss: 2.46424101823368

Epoch: 6| Step: 2
Training loss: 0.4286988762829457
Validation loss: 2.4495183902030515

Epoch: 6| Step: 3
Training loss: 0.39522557490290894
Validation loss: 2.481981164974337

Epoch: 6| Step: 4
Training loss: 0.3733985601257959
Validation loss: 2.4877660414393246

Epoch: 6| Step: 5
Training loss: 0.19257914985863772
Validation loss: 2.4636896581494168

Epoch: 6| Step: 6
Training loss: 0.27585690841069016
Validation loss: 2.4719824106801487

Epoch: 6| Step: 7
Training loss: 0.33283741638329245
Validation loss: 2.477486575139851

Epoch: 6| Step: 8
Training loss: 0.28435613129446435
Validation loss: 2.4957112051546217

Epoch: 6| Step: 9
Training loss: 0.16202438953373238
Validation loss: 2.495891423100382

Epoch: 6| Step: 10
Training loss: 0.3876692909713332
Validation loss: 2.488726934354106

Epoch: 6| Step: 11
Training loss: 0.30614324188087455
Validation loss: 2.5040593487218317

Epoch: 6| Step: 12
Training loss: 0.11391281143044604
Validation loss: 2.5144049293979243

Epoch: 6| Step: 13
Training loss: 0.5013069714064312
Validation loss: 2.501440408507368

Epoch: 396| Step: 0
Training loss: 0.29573676599509585
Validation loss: 2.509371178342557

Epoch: 6| Step: 1
Training loss: 0.5035636683613013
Validation loss: 2.49024672355381

Epoch: 6| Step: 2
Training loss: 0.2432967364062345
Validation loss: 2.5073055163391893

Epoch: 6| Step: 3
Training loss: 0.40950913015487983
Validation loss: 2.5198139240374395

Epoch: 6| Step: 4
Training loss: 0.506134164768187
Validation loss: 2.51902439914168

Epoch: 6| Step: 5
Training loss: 0.34246040244118875
Validation loss: 2.515278817817077

Epoch: 6| Step: 6
Training loss: 0.3405446246449766
Validation loss: 2.5034746542259003

Epoch: 6| Step: 7
Training loss: 0.18470020870110204
Validation loss: 2.4947954177357263

Epoch: 6| Step: 8
Training loss: 0.15851995743292166
Validation loss: 2.5154518368983174

Epoch: 6| Step: 9
Training loss: 0.31259717622462097
Validation loss: 2.510326153245028

Epoch: 6| Step: 10
Training loss: 0.1962502664211919
Validation loss: 2.482729691460917

Epoch: 6| Step: 11
Training loss: 0.2597700850025004
Validation loss: 2.5121906112679127

Epoch: 6| Step: 12
Training loss: 0.29286283485849024
Validation loss: 2.520031484103475

Epoch: 6| Step: 13
Training loss: 0.24543855125623698
Validation loss: 2.4788014074003284

Epoch: 397| Step: 0
Training loss: 0.35213227195259006
Validation loss: 2.4785621928502266

Epoch: 6| Step: 1
Training loss: 0.28202439033006865
Validation loss: 2.522722813634731

Epoch: 6| Step: 2
Training loss: 0.3144234589982925
Validation loss: 2.511314861149453

Epoch: 6| Step: 3
Training loss: 0.2935978936983519
Validation loss: 2.4916347842663704

Epoch: 6| Step: 4
Training loss: 0.23946026391593647
Validation loss: 2.544760204443385

Epoch: 6| Step: 5
Training loss: 0.45476062488149926
Validation loss: 2.506780488265973

Epoch: 6| Step: 6
Training loss: 0.3596988545605024
Validation loss: 2.534444383175448

Epoch: 6| Step: 7
Training loss: 0.2701229428597372
Validation loss: 2.523937653644709

Epoch: 6| Step: 8
Training loss: 0.12562012333205827
Validation loss: 2.5430043780386935

Epoch: 6| Step: 9
Training loss: 0.2133574835107826
Validation loss: 2.524909217101638

Epoch: 6| Step: 10
Training loss: 0.20276510928119934
Validation loss: 2.528404685046597

Epoch: 6| Step: 11
Training loss: 0.3146294046396017
Validation loss: 2.519065899048052

Epoch: 6| Step: 12
Training loss: 0.5154781421408168
Validation loss: 2.485016273436502

Epoch: 6| Step: 13
Training loss: 0.5583789118861822
Validation loss: 2.492314920258243

Epoch: 398| Step: 0
Training loss: 0.40862453191572273
Validation loss: 2.4815246365568835

Epoch: 6| Step: 1
Training loss: 0.5632274215734233
Validation loss: 2.4779088576447275

Epoch: 6| Step: 2
Training loss: 0.2684487567402113
Validation loss: 2.5089679068088544

Epoch: 6| Step: 3
Training loss: 0.31522928727781946
Validation loss: 2.46649766980248

Epoch: 6| Step: 4
Training loss: 0.24083051141704787
Validation loss: 2.482353937779096

Epoch: 6| Step: 5
Training loss: 0.2461905062158544
Validation loss: 2.512259076388755

Epoch: 6| Step: 6
Training loss: 0.3991725909875881
Validation loss: 2.5013734664545257

Epoch: 6| Step: 7
Training loss: 0.30954341591077905
Validation loss: 2.521018640196748

Epoch: 6| Step: 8
Training loss: 0.21761973477983296
Validation loss: 2.504329302473754

Epoch: 6| Step: 9
Training loss: 0.43333461681811675
Validation loss: 2.5171429693585976

Epoch: 6| Step: 10
Training loss: 0.4097153246383393
Validation loss: 2.5133502147348943

Epoch: 6| Step: 11
Training loss: 0.2043851770993515
Validation loss: 2.485470131651269

Epoch: 6| Step: 12
Training loss: 0.2836806250934887
Validation loss: 2.5145488371629257

Epoch: 6| Step: 13
Training loss: 0.23296146107662175
Validation loss: 2.482500282841679

Epoch: 399| Step: 0
Training loss: 0.1946260883684297
Validation loss: 2.4407782353386165

Epoch: 6| Step: 1
Training loss: 0.5092727207401928
Validation loss: 2.477880276698026

Epoch: 6| Step: 2
Training loss: 0.4305902188543402
Validation loss: 2.4942923995996606

Epoch: 6| Step: 3
Training loss: 0.2760962381342552
Validation loss: 2.512150691808493

Epoch: 6| Step: 4
Training loss: 0.48969488361101476
Validation loss: 2.488167981931235

Epoch: 6| Step: 5
Training loss: 0.24363115176463135
Validation loss: 2.4959842813801205

Epoch: 6| Step: 6
Training loss: 0.14740460311312556
Validation loss: 2.504894125771602

Epoch: 6| Step: 7
Training loss: 0.26565363673508957
Validation loss: 2.4826211525724062

Epoch: 6| Step: 8
Training loss: 0.19222155943733618
Validation loss: 2.4949206456056094

Epoch: 6| Step: 9
Training loss: 0.21800172071040297
Validation loss: 2.4550826495992477

Epoch: 6| Step: 10
Training loss: 0.31330669708783176
Validation loss: 2.4319360085702573

Epoch: 6| Step: 11
Training loss: 0.37067610679384555
Validation loss: 2.447667814621212

Epoch: 6| Step: 12
Training loss: 0.4005583993121811
Validation loss: 2.4431031779063566

Epoch: 6| Step: 13
Training loss: 0.574216466367164
Validation loss: 2.45310790290672

Epoch: 400| Step: 0
Training loss: 0.37018194110257563
Validation loss: 2.4589804507981428

Epoch: 6| Step: 1
Training loss: 0.26943398531269686
Validation loss: 2.479460531742036

Epoch: 6| Step: 2
Training loss: 0.2894398442978424
Validation loss: 2.461264624195577

Epoch: 6| Step: 3
Training loss: 0.32926447879814597
Validation loss: 2.4664694077235225

Epoch: 6| Step: 4
Training loss: 0.2072297260499561
Validation loss: 2.4819484424573974

Epoch: 6| Step: 5
Training loss: 0.27742271910925465
Validation loss: 2.4985542023690033

Epoch: 6| Step: 6
Training loss: 0.16693013694775163
Validation loss: 2.5435458021081683

Epoch: 6| Step: 7
Training loss: 0.3800710883278199
Validation loss: 2.549536131036479

Epoch: 6| Step: 8
Training loss: 0.43213338903483456
Validation loss: 2.5767316645955636

Epoch: 6| Step: 9
Training loss: 0.3899754655285613
Validation loss: 2.5374001800642443

Epoch: 6| Step: 10
Training loss: 0.23424688652477324
Validation loss: 2.5219645276188953

Epoch: 6| Step: 11
Training loss: 0.3638073587911187
Validation loss: 2.533433750792956

Epoch: 6| Step: 12
Training loss: 0.40555678424402314
Validation loss: 2.514480647474578

Epoch: 6| Step: 13
Training loss: 0.45686806920087386
Validation loss: 2.5317134435453093

Epoch: 401| Step: 0
Training loss: 0.48628988460349015
Validation loss: 2.504895057113379

Epoch: 6| Step: 1
Training loss: 0.5053593583518178
Validation loss: 2.4857207688254923

Epoch: 6| Step: 2
Training loss: 0.2770733119232706
Validation loss: 2.4685120219303895

Epoch: 6| Step: 3
Training loss: 0.39156765684003314
Validation loss: 2.4802027514409106

Epoch: 6| Step: 4
Training loss: 0.18288216771350227
Validation loss: 2.481880337335662

Epoch: 6| Step: 5
Training loss: 0.32720410456965504
Validation loss: 2.5232442521951164

Epoch: 6| Step: 6
Training loss: 0.22025543989029994
Validation loss: 2.5312067856385676

Epoch: 6| Step: 7
Training loss: 0.30473988645090067
Validation loss: 2.5415037443520254

Epoch: 6| Step: 8
Training loss: 0.3814828513367158
Validation loss: 2.5164624359553356

Epoch: 6| Step: 9
Training loss: 0.26540409046113334
Validation loss: 2.541282716258873

Epoch: 6| Step: 10
Training loss: 0.19594255865219817
Validation loss: 2.5690770874849065

Epoch: 6| Step: 11
Training loss: 0.2729850158692617
Validation loss: 2.4937616767479365

Epoch: 6| Step: 12
Training loss: 0.26514238102102267
Validation loss: 2.460508924838477

Epoch: 6| Step: 13
Training loss: 0.544813767514292
Validation loss: 2.4718915515708146

Epoch: 402| Step: 0
Training loss: 0.27113514674833006
Validation loss: 2.4785020005681333

Epoch: 6| Step: 1
Training loss: 0.42192584190598836
Validation loss: 2.4934480338772995

Epoch: 6| Step: 2
Training loss: 0.36876316047072166
Validation loss: 2.4738625770953186

Epoch: 6| Step: 3
Training loss: 0.29433286345053034
Validation loss: 2.496500389911158

Epoch: 6| Step: 4
Training loss: 0.3528237712198377
Validation loss: 2.4638138823822806

Epoch: 6| Step: 5
Training loss: 0.32966646787260084
Validation loss: 2.474861244670035

Epoch: 6| Step: 6
Training loss: 0.404993332731445
Validation loss: 2.490346379906969

Epoch: 6| Step: 7
Training loss: 0.2739742460573079
Validation loss: 2.4827424005400767

Epoch: 6| Step: 8
Training loss: 0.2173563379856121
Validation loss: 2.507203049620616

Epoch: 6| Step: 9
Training loss: 0.13424297239647678
Validation loss: 2.5168142165727803

Epoch: 6| Step: 10
Training loss: 0.35972441396859717
Validation loss: 2.5188584476388534

Epoch: 6| Step: 11
Training loss: 0.2816453248159613
Validation loss: 2.5102586924153973

Epoch: 6| Step: 12
Training loss: 0.39120899415164356
Validation loss: 2.49965956226046

Epoch: 6| Step: 13
Training loss: 0.3675951216981073
Validation loss: 2.5030791096924827

Epoch: 403| Step: 0
Training loss: 0.27782969817403813
Validation loss: 2.4879061853678373

Epoch: 6| Step: 1
Training loss: 0.40817930526229235
Validation loss: 2.5214185507472524

Epoch: 6| Step: 2
Training loss: 0.29356487660037867
Validation loss: 2.506710343534565

Epoch: 6| Step: 3
Training loss: 0.23979136084303146
Validation loss: 2.508921847116596

Epoch: 6| Step: 4
Training loss: 0.4494767318989689
Validation loss: 2.503448796235329

Epoch: 6| Step: 5
Training loss: 0.17981412820937404
Validation loss: 2.4811186347601586

Epoch: 6| Step: 6
Training loss: 0.22279637093770902
Validation loss: 2.4702091601172067

Epoch: 6| Step: 7
Training loss: 0.18253191828854376
Validation loss: 2.480900210514305

Epoch: 6| Step: 8
Training loss: 0.3059147181810408
Validation loss: 2.4877587336443123

Epoch: 6| Step: 9
Training loss: 0.34940180663720977
Validation loss: 2.4761943777103874

Epoch: 6| Step: 10
Training loss: 0.30855540749610383
Validation loss: 2.47315468412475

Epoch: 6| Step: 11
Training loss: 0.4352715139270364
Validation loss: 2.4870638365147446

Epoch: 6| Step: 12
Training loss: 0.34876754038122293
Validation loss: 2.4671718002108993

Epoch: 6| Step: 13
Training loss: 0.2623335889855835
Validation loss: 2.477214929797168

Epoch: 404| Step: 0
Training loss: 0.5121493966229859
Validation loss: 2.469013515213019

Epoch: 6| Step: 1
Training loss: 0.32543478273444515
Validation loss: 2.4576652902548743

Epoch: 6| Step: 2
Training loss: 0.11523024503128233
Validation loss: 2.478322812459745

Epoch: 6| Step: 3
Training loss: 0.4093511035729584
Validation loss: 2.469903591506931

Epoch: 6| Step: 4
Training loss: 0.22178978223703025
Validation loss: 2.446904798073828

Epoch: 6| Step: 5
Training loss: 0.17898629034741723
Validation loss: 2.450196992858063

Epoch: 6| Step: 6
Training loss: 0.35886570875470036
Validation loss: 2.4711121182646716

Epoch: 6| Step: 7
Training loss: 0.37529691227060213
Validation loss: 2.508921194691029

Epoch: 6| Step: 8
Training loss: 0.2953053185937019
Validation loss: 2.490537256701486

Epoch: 6| Step: 9
Training loss: 0.17083380430629597
Validation loss: 2.48105984260297

Epoch: 6| Step: 10
Training loss: 0.19457531089159916
Validation loss: 2.4978769044695315

Epoch: 6| Step: 11
Training loss: 0.1868118034310243
Validation loss: 2.4770659728173112

Epoch: 6| Step: 12
Training loss: 0.34949265561552667
Validation loss: 2.4926582586418946

Epoch: 6| Step: 13
Training loss: 0.42137444788812606
Validation loss: 2.524329941981736

Epoch: 405| Step: 0
Training loss: 0.39123500877520084
Validation loss: 2.50798314851537

Epoch: 6| Step: 1
Training loss: 0.16089924153874657
Validation loss: 2.5140592665055514

Epoch: 6| Step: 2
Training loss: 0.2242425078588529
Validation loss: 2.5168838087710474

Epoch: 6| Step: 3
Training loss: 0.30824123238843515
Validation loss: 2.519875258344211

Epoch: 6| Step: 4
Training loss: 0.4001637444023369
Validation loss: 2.507190662901727

Epoch: 6| Step: 5
Training loss: 0.29550050977317616
Validation loss: 2.522650617305099

Epoch: 6| Step: 6
Training loss: 0.48925581758438885
Validation loss: 2.466020893169727

Epoch: 6| Step: 7
Training loss: 0.24009950465036442
Validation loss: 2.5185686571416683

Epoch: 6| Step: 8
Training loss: 0.2874869115586841
Validation loss: 2.5013532580413886

Epoch: 6| Step: 9
Training loss: 0.29239632951762073
Validation loss: 2.517429976850329

Epoch: 6| Step: 10
Training loss: 0.10728496149400653
Validation loss: 2.498444068903801

Epoch: 6| Step: 11
Training loss: 0.2418457357805932
Validation loss: 2.547408201569575

Epoch: 6| Step: 12
Training loss: 0.15624588126476127
Validation loss: 2.522970901823142

Epoch: 6| Step: 13
Training loss: 0.4667653188852888
Validation loss: 2.527151839686236

Epoch: 406| Step: 0
Training loss: 0.3605982651874537
Validation loss: 2.534643578490483

Epoch: 6| Step: 1
Training loss: 0.3478513234655468
Validation loss: 2.517817072684514

Epoch: 6| Step: 2
Training loss: 0.26071076793173026
Validation loss: 2.533997218097106

Epoch: 6| Step: 3
Training loss: 0.43099215718986533
Validation loss: 2.49717116947976

Epoch: 6| Step: 4
Training loss: 0.191976456953338
Validation loss: 2.4854985221777057

Epoch: 6| Step: 5
Training loss: 0.38124229548439525
Validation loss: 2.513737875589551

Epoch: 6| Step: 6
Training loss: 0.20853266518099914
Validation loss: 2.5046349582792304

Epoch: 6| Step: 7
Training loss: 0.16997975426968295
Validation loss: 2.4805353622270823

Epoch: 6| Step: 8
Training loss: 0.23465783219941377
Validation loss: 2.5038870444265213

Epoch: 6| Step: 9
Training loss: 0.284781745695053
Validation loss: 2.4910333412807804

Epoch: 6| Step: 10
Training loss: 0.3104704036966178
Validation loss: 2.466484182706082

Epoch: 6| Step: 11
Training loss: 0.3511459001518253
Validation loss: 2.4749741646238714

Epoch: 6| Step: 12
Training loss: 0.38621654075461703
Validation loss: 2.488078650489481

Epoch: 6| Step: 13
Training loss: 0.10198466426988935
Validation loss: 2.488307628265433

Epoch: 407| Step: 0
Training loss: 0.2659524133895839
Validation loss: 2.5267523799771197

Epoch: 6| Step: 1
Training loss: 0.20070831814792864
Validation loss: 2.463445802115644

Epoch: 6| Step: 2
Training loss: 0.2641608049592745
Validation loss: 2.5116222456635375

Epoch: 6| Step: 3
Training loss: 0.2388970126405171
Validation loss: 2.473304108847073

Epoch: 6| Step: 4
Training loss: 0.24879859048378575
Validation loss: 2.4892663548376635

Epoch: 6| Step: 5
Training loss: 0.2128230258814469
Validation loss: 2.4861154216136936

Epoch: 6| Step: 6
Training loss: 0.4220257948770377
Validation loss: 2.4424391033888018

Epoch: 6| Step: 7
Training loss: 0.30800437175447193
Validation loss: 2.4928875181546273

Epoch: 6| Step: 8
Training loss: 0.41115676918817523
Validation loss: 2.4715406005051475

Epoch: 6| Step: 9
Training loss: 0.3052190521080949
Validation loss: 2.4697496309653317

Epoch: 6| Step: 10
Training loss: 0.19152551944354998
Validation loss: 2.454971834721283

Epoch: 6| Step: 11
Training loss: 0.4506862553510671
Validation loss: 2.448991188232341

Epoch: 6| Step: 12
Training loss: 0.35158225109991353
Validation loss: 2.4894872461422266

Epoch: 6| Step: 13
Training loss: 0.21551600099280646
Validation loss: 2.4603597535440533

Epoch: 408| Step: 0
Training loss: 0.1527032217952289
Validation loss: 2.4904548155283703

Epoch: 6| Step: 1
Training loss: 0.28443930915319193
Validation loss: 2.473282799881858

Epoch: 6| Step: 2
Training loss: 0.1663279792566409
Validation loss: 2.487452910767997

Epoch: 6| Step: 3
Training loss: 0.2516716708360501
Validation loss: 2.487258196752091

Epoch: 6| Step: 4
Training loss: 0.31638278403214803
Validation loss: 2.478221762532043

Epoch: 6| Step: 5
Training loss: 0.21036090458178747
Validation loss: 2.5065373971118503

Epoch: 6| Step: 6
Training loss: 0.333324237292081
Validation loss: 2.499694995835377

Epoch: 6| Step: 7
Training loss: 0.4521636465987434
Validation loss: 2.497765567995638

Epoch: 6| Step: 8
Training loss: 0.31160715825724555
Validation loss: 2.508404879751731

Epoch: 6| Step: 9
Training loss: 0.42471358100575474
Validation loss: 2.5018772460423766

Epoch: 6| Step: 10
Training loss: 0.18920213256242982
Validation loss: 2.5030382516675225

Epoch: 6| Step: 11
Training loss: 0.4047416415137867
Validation loss: 2.4818418640467725

Epoch: 6| Step: 12
Training loss: 0.2389234736978273
Validation loss: 2.5145359472992848

Epoch: 6| Step: 13
Training loss: 0.3363798356482984
Validation loss: 2.4655928777284077

Epoch: 409| Step: 0
Training loss: 0.1826977781464211
Validation loss: 2.483785852349093

Epoch: 6| Step: 1
Training loss: 0.3194355124051799
Validation loss: 2.4658066678266155

Epoch: 6| Step: 2
Training loss: 0.2806383741033758
Validation loss: 2.4825093652890406

Epoch: 6| Step: 3
Training loss: 0.35841787425874516
Validation loss: 2.4819853719762297

Epoch: 6| Step: 4
Training loss: 0.41530528786326526
Validation loss: 2.5114545801078982

Epoch: 6| Step: 5
Training loss: 0.13679518606558297
Validation loss: 2.4965841132081157

Epoch: 6| Step: 6
Training loss: 0.31323789263234514
Validation loss: 2.450867294751982

Epoch: 6| Step: 7
Training loss: 0.3165522697618315
Validation loss: 2.513803994785614

Epoch: 6| Step: 8
Training loss: 0.32111517424008357
Validation loss: 2.498440779241491

Epoch: 6| Step: 9
Training loss: 0.24255020146741976
Validation loss: 2.4995240927531532

Epoch: 6| Step: 10
Training loss: 0.21264016002968872
Validation loss: 2.514995784917045

Epoch: 6| Step: 11
Training loss: 0.4838895672542057
Validation loss: 2.5245551077706274

Epoch: 6| Step: 12
Training loss: 0.21706747230647352
Validation loss: 2.5107226145549415

Epoch: 6| Step: 13
Training loss: 0.28471450032770307
Validation loss: 2.5406247909633195

Epoch: 410| Step: 0
Training loss: 0.20868776788605814
Validation loss: 2.522611495488354

Epoch: 6| Step: 1
Training loss: 0.3547389325061399
Validation loss: 2.496542434694617

Epoch: 6| Step: 2
Training loss: 0.13908535469497466
Validation loss: 2.5302292905226054

Epoch: 6| Step: 3
Training loss: 0.42563980272854396
Validation loss: 2.5025943868894016

Epoch: 6| Step: 4
Training loss: 0.41439431768299395
Validation loss: 2.5002091904764634

Epoch: 6| Step: 5
Training loss: 0.31438297176302543
Validation loss: 2.535171864948767

Epoch: 6| Step: 6
Training loss: 0.2668914755664799
Validation loss: 2.5380261281147196

Epoch: 6| Step: 7
Training loss: 0.17711863913788192
Validation loss: 2.5300445116829113

Epoch: 6| Step: 8
Training loss: 0.3546904332716053
Validation loss: 2.5505867389410124

Epoch: 6| Step: 9
Training loss: 0.178441235007163
Validation loss: 2.5199543457710476

Epoch: 6| Step: 10
Training loss: 0.3360264239053788
Validation loss: 2.566172959055816

Epoch: 6| Step: 11
Training loss: 0.303999294757025
Validation loss: 2.5693022171901947

Epoch: 6| Step: 12
Training loss: 0.40007335839526215
Validation loss: 2.5611660244136676

Epoch: 6| Step: 13
Training loss: 0.22879470997985493
Validation loss: 2.545626148609036

Epoch: 411| Step: 0
Training loss: 0.33604458277683197
Validation loss: 2.513772112808362

Epoch: 6| Step: 1
Training loss: 0.2815396618657142
Validation loss: 2.5429968524497375

Epoch: 6| Step: 2
Training loss: 0.3408685447863617
Validation loss: 2.5266916199807854

Epoch: 6| Step: 3
Training loss: 0.16896354157992535
Validation loss: 2.4508202278700146

Epoch: 6| Step: 4
Training loss: 0.23096200723912932
Validation loss: 2.504574057849626

Epoch: 6| Step: 5
Training loss: 0.17973646243213962
Validation loss: 2.4761550789201485

Epoch: 6| Step: 6
Training loss: 0.4271445715039867
Validation loss: 2.4926514552600483

Epoch: 6| Step: 7
Training loss: 0.31278837726425635
Validation loss: 2.4450901641618037

Epoch: 6| Step: 8
Training loss: 0.3714727373837406
Validation loss: 2.4797762518353204

Epoch: 6| Step: 9
Training loss: 0.23087494825064137
Validation loss: 2.481809530156739

Epoch: 6| Step: 10
Training loss: 0.3121742219363662
Validation loss: 2.4962045838582028

Epoch: 6| Step: 11
Training loss: 0.3875208925952247
Validation loss: 2.4960155575914627

Epoch: 6| Step: 12
Training loss: 0.34542511143770593
Validation loss: 2.5301746346220697

Epoch: 6| Step: 13
Training loss: 0.3817120129009866
Validation loss: 2.525047122361696

Epoch: 412| Step: 0
Training loss: 0.3611491610682996
Validation loss: 2.5010860611807124

Epoch: 6| Step: 1
Training loss: 0.2087567953043059
Validation loss: 2.5008164446770316

Epoch: 6| Step: 2
Training loss: 0.4094325629379063
Validation loss: 2.5173725042390602

Epoch: 6| Step: 3
Training loss: 0.2628007414882831
Validation loss: 2.503546383637156

Epoch: 6| Step: 4
Training loss: 0.1240331691017762
Validation loss: 2.5127221445734143

Epoch: 6| Step: 5
Training loss: 0.27866568301556194
Validation loss: 2.4984489551627815

Epoch: 6| Step: 6
Training loss: 0.2951975790585191
Validation loss: 2.483802124147322

Epoch: 6| Step: 7
Training loss: 0.47951877310522245
Validation loss: 2.4776006207351324

Epoch: 6| Step: 8
Training loss: 0.3408716485565519
Validation loss: 2.4704196943593217

Epoch: 6| Step: 9
Training loss: 0.23834732577846493
Validation loss: 2.485723328627406

Epoch: 6| Step: 10
Training loss: 0.2962620329928074
Validation loss: 2.5028203877848885

Epoch: 6| Step: 11
Training loss: 0.33569614478602927
Validation loss: 2.500534812573643

Epoch: 6| Step: 12
Training loss: 0.46078740925260353
Validation loss: 2.55613276949967

Epoch: 6| Step: 13
Training loss: 0.22640984423767874
Validation loss: 2.556534159084522

Epoch: 413| Step: 0
Training loss: 0.35352588870497453
Validation loss: 2.5700296385409365

Epoch: 6| Step: 1
Training loss: 0.34792180581018695
Validation loss: 2.530311393233853

Epoch: 6| Step: 2
Training loss: 0.14585469010056698
Validation loss: 2.5574240689811187

Epoch: 6| Step: 3
Training loss: 0.24916850333881801
Validation loss: 2.5585562018061503

Epoch: 6| Step: 4
Training loss: 0.2346295325670113
Validation loss: 2.5796191368411834

Epoch: 6| Step: 5
Training loss: 0.2592960214442784
Validation loss: 2.5228033177834264

Epoch: 6| Step: 6
Training loss: 0.21101803478459505
Validation loss: 2.5394020670081474

Epoch: 6| Step: 7
Training loss: 0.2576414031822607
Validation loss: 2.5371243539744857

Epoch: 6| Step: 8
Training loss: 0.46896633877976046
Validation loss: 2.511477659819907

Epoch: 6| Step: 9
Training loss: 0.18094093139965614
Validation loss: 2.545296836409052

Epoch: 6| Step: 10
Training loss: 0.3653366843148782
Validation loss: 2.5448818383545198

Epoch: 6| Step: 11
Training loss: 0.18840578954288908
Validation loss: 2.5814325499451356

Epoch: 6| Step: 12
Training loss: 0.3926228360198733
Validation loss: 2.5474280169598833

Epoch: 6| Step: 13
Training loss: 0.4630421901393158
Validation loss: 2.5429651892857508

Epoch: 414| Step: 0
Training loss: 0.26588778960202464
Validation loss: 2.5296542496531607

Epoch: 6| Step: 1
Training loss: 0.42416867404954883
Validation loss: 2.515107067070645

Epoch: 6| Step: 2
Training loss: 0.3637543131058073
Validation loss: 2.494027576782968

Epoch: 6| Step: 3
Training loss: 0.24285164645155052
Validation loss: 2.5085482405706028

Epoch: 6| Step: 4
Training loss: 0.28181480280886434
Validation loss: 2.4509569134706624

Epoch: 6| Step: 5
Training loss: 0.4685169912410253
Validation loss: 2.459616905966197

Epoch: 6| Step: 6
Training loss: 0.39076156136486756
Validation loss: 2.4687167760322395

Epoch: 6| Step: 7
Training loss: 0.19561951349261109
Validation loss: 2.465065858952863

Epoch: 6| Step: 8
Training loss: 0.19854040218689797
Validation loss: 2.4774654966878344

Epoch: 6| Step: 9
Training loss: 0.3063105975747551
Validation loss: 2.5178129280991475

Epoch: 6| Step: 10
Training loss: 0.3988989607387421
Validation loss: 2.4762756496221474

Epoch: 6| Step: 11
Training loss: 0.25771027763689974
Validation loss: 2.472398903528874

Epoch: 6| Step: 12
Training loss: 0.2136897391709337
Validation loss: 2.4863333083094403

Epoch: 6| Step: 13
Training loss: 0.31931674677962313
Validation loss: 2.5031325270270615

Epoch: 415| Step: 0
Training loss: 0.3321869653318881
Validation loss: 2.4751795882053216

Epoch: 6| Step: 1
Training loss: 0.35408076011121914
Validation loss: 2.4771680468458026

Epoch: 6| Step: 2
Training loss: 0.35713551207210087
Validation loss: 2.4960031728707905

Epoch: 6| Step: 3
Training loss: 0.13794806799529485
Validation loss: 2.47730076038976

Epoch: 6| Step: 4
Training loss: 0.2993056651641594
Validation loss: 2.4882210790410917

Epoch: 6| Step: 5
Training loss: 0.20479581565929295
Validation loss: 2.492295492669456

Epoch: 6| Step: 6
Training loss: 0.18220898706002084
Validation loss: 2.509006841849905

Epoch: 6| Step: 7
Training loss: 0.2419461462820775
Validation loss: 2.4840822063437566

Epoch: 6| Step: 8
Training loss: 0.28364433909253883
Validation loss: 2.480522981347493

Epoch: 6| Step: 9
Training loss: 0.39149669660560626
Validation loss: 2.481819118187619

Epoch: 6| Step: 10
Training loss: 0.2938227857547348
Validation loss: 2.501325559413304

Epoch: 6| Step: 11
Training loss: 0.552017231948683
Validation loss: 2.5095138087029856

Epoch: 6| Step: 12
Training loss: 0.31744147125451894
Validation loss: 2.532182206592472

Epoch: 6| Step: 13
Training loss: 0.5081597827957245
Validation loss: 2.4426832366821882

Epoch: 416| Step: 0
Training loss: 0.3025385069180159
Validation loss: 2.4409215307627274

Epoch: 6| Step: 1
Training loss: 0.3968874568936663
Validation loss: 2.459633717046981

Epoch: 6| Step: 2
Training loss: 0.4423690019013891
Validation loss: 2.445255717501818

Epoch: 6| Step: 3
Training loss: 0.26817866964211223
Validation loss: 2.4473903544901088

Epoch: 6| Step: 4
Training loss: 0.4406338744926915
Validation loss: 2.422223885104022

Epoch: 6| Step: 5
Training loss: 0.40517830708843416
Validation loss: 2.448700261072074

Epoch: 6| Step: 6
Training loss: 0.28107815366843775
Validation loss: 2.4225033233801634

Epoch: 6| Step: 7
Training loss: 0.20754611574318554
Validation loss: 2.5030821802266425

Epoch: 6| Step: 8
Training loss: 0.33213576747466395
Validation loss: 2.484679396618765

Epoch: 6| Step: 9
Training loss: 0.24181243094598331
Validation loss: 2.5203962917566

Epoch: 6| Step: 10
Training loss: 0.33850148280395115
Validation loss: 2.524129937321931

Epoch: 6| Step: 11
Training loss: 0.24757076737607867
Validation loss: 2.494518599996097

Epoch: 6| Step: 12
Training loss: 0.3185999844527136
Validation loss: 2.5204636704371786

Epoch: 6| Step: 13
Training loss: 0.40329892007100043
Validation loss: 2.5376573605665693

Epoch: 417| Step: 0
Training loss: 0.22039604767217028
Validation loss: 2.462505007386289

Epoch: 6| Step: 1
Training loss: 0.2756707410420948
Validation loss: 2.497292005643352

Epoch: 6| Step: 2
Training loss: 0.34204079779782054
Validation loss: 2.5149582820288017

Epoch: 6| Step: 3
Training loss: 0.33294652559461435
Validation loss: 2.530893520227469

Epoch: 6| Step: 4
Training loss: 0.36599222391367636
Validation loss: 2.51034045870715

Epoch: 6| Step: 5
Training loss: 0.41026815068705713
Validation loss: 2.506360674656033

Epoch: 6| Step: 6
Training loss: 0.2726122528254863
Validation loss: 2.4724663825142605

Epoch: 6| Step: 7
Training loss: 0.21790956938007155
Validation loss: 2.5041607263229215

Epoch: 6| Step: 8
Training loss: 0.449020474670113
Validation loss: 2.461510946975988

Epoch: 6| Step: 9
Training loss: 0.38652083601806214
Validation loss: 2.444378925690274

Epoch: 6| Step: 10
Training loss: 0.3034873703775051
Validation loss: 2.404613033414776

Epoch: 6| Step: 11
Training loss: 0.2505923049605378
Validation loss: 2.4865380429673034

Epoch: 6| Step: 12
Training loss: 0.19547842607097343
Validation loss: 2.453681550341168

Epoch: 6| Step: 13
Training loss: 0.21018265838332678
Validation loss: 2.453311539729164

Epoch: 418| Step: 0
Training loss: 0.2998256862381565
Validation loss: 2.449970593463278

Epoch: 6| Step: 1
Training loss: 0.2605407451040089
Validation loss: 2.4296007085805895

Epoch: 6| Step: 2
Training loss: 0.29247906768921783
Validation loss: 2.439529361924564

Epoch: 6| Step: 3
Training loss: 0.4608752321760536
Validation loss: 2.4644725988096647

Epoch: 6| Step: 4
Training loss: 0.35618596505327854
Validation loss: 2.4396166355396143

Epoch: 6| Step: 5
Training loss: 0.3415913536155929
Validation loss: 2.4861036382545176

Epoch: 6| Step: 6
Training loss: 0.3846655003743752
Validation loss: 2.4810440265836275

Epoch: 6| Step: 7
Training loss: 0.20674294965155438
Validation loss: 2.472247297534592

Epoch: 6| Step: 8
Training loss: 0.24322871991646777
Validation loss: 2.4833391759219676

Epoch: 6| Step: 9
Training loss: 0.17843140174145475
Validation loss: 2.471461511991954

Epoch: 6| Step: 10
Training loss: 0.22517236557943401
Validation loss: 2.485948410717163

Epoch: 6| Step: 11
Training loss: 0.402698453083719
Validation loss: 2.5075805912581326

Epoch: 6| Step: 12
Training loss: 0.24786809801475568
Validation loss: 2.4835563926451125

Epoch: 6| Step: 13
Training loss: 0.3193558619638341
Validation loss: 2.4937444501320543

Epoch: 419| Step: 0
Training loss: 0.4865512412697417
Validation loss: 2.504001002028867

Epoch: 6| Step: 1
Training loss: 0.29792779666055036
Validation loss: 2.511197825699135

Epoch: 6| Step: 2
Training loss: 0.3408922376404397
Validation loss: 2.4994338214832275

Epoch: 6| Step: 3
Training loss: 0.4187747456939528
Validation loss: 2.498374297582986

Epoch: 6| Step: 4
Training loss: 0.23504234514548217
Validation loss: 2.501226636458897

Epoch: 6| Step: 5
Training loss: 0.33583511965957313
Validation loss: 2.5072956627919494

Epoch: 6| Step: 6
Training loss: 0.33418968092101703
Validation loss: 2.512546439739815

Epoch: 6| Step: 7
Training loss: 0.27556304403983745
Validation loss: 2.515614234342311

Epoch: 6| Step: 8
Training loss: 0.23685385810994575
Validation loss: 2.489413632817518

Epoch: 6| Step: 9
Training loss: 0.2377472193141183
Validation loss: 2.49185214205458

Epoch: 6| Step: 10
Training loss: 0.21716778617691337
Validation loss: 2.4751886819791786

Epoch: 6| Step: 11
Training loss: 0.25081387304675934
Validation loss: 2.431501533505877

Epoch: 6| Step: 12
Training loss: 0.25556355038578854
Validation loss: 2.4830321319307473

Epoch: 6| Step: 13
Training loss: 0.32887108313512703
Validation loss: 2.4731193103315534

Epoch: 420| Step: 0
Training loss: 0.32329971400872753
Validation loss: 2.453497022473199

Epoch: 6| Step: 1
Training loss: 0.2585272994623195
Validation loss: 2.468287045389344

Epoch: 6| Step: 2
Training loss: 0.3464835350774758
Validation loss: 2.42980300359191

Epoch: 6| Step: 3
Training loss: 0.3424340983843426
Validation loss: 2.4842985160386335

Epoch: 6| Step: 4
Training loss: 0.2856160076278407
Validation loss: 2.463600596266158

Epoch: 6| Step: 5
Training loss: 0.32877555570157335
Validation loss: 2.490480531015154

Epoch: 6| Step: 6
Training loss: 0.23869845340664808
Validation loss: 2.487698514236277

Epoch: 6| Step: 7
Training loss: 0.21280085569613907
Validation loss: 2.4600903541491723

Epoch: 6| Step: 8
Training loss: 0.32034374875485544
Validation loss: 2.459463209900671

Epoch: 6| Step: 9
Training loss: 0.17816563569394508
Validation loss: 2.502733981409148

Epoch: 6| Step: 10
Training loss: 0.4072847393386632
Validation loss: 2.484832159221491

Epoch: 6| Step: 11
Training loss: 0.1568545210530272
Validation loss: 2.476145267066826

Epoch: 6| Step: 12
Training loss: 0.28243124116638707
Validation loss: 2.49554934520109

Epoch: 6| Step: 13
Training loss: 0.2690255216559599
Validation loss: 2.481675548992794

Epoch: 421| Step: 0
Training loss: 0.36846676633396486
Validation loss: 2.486680398931605

Epoch: 6| Step: 1
Training loss: 0.24120900697746403
Validation loss: 2.499653016898762

Epoch: 6| Step: 2
Training loss: 0.27685238737245077
Validation loss: 2.482142730209708

Epoch: 6| Step: 3
Training loss: 0.4004109261180982
Validation loss: 2.463291978612841

Epoch: 6| Step: 4
Training loss: 0.32798305347614903
Validation loss: 2.4794869474978194

Epoch: 6| Step: 5
Training loss: 0.318701729672439
Validation loss: 2.4849987721286944

Epoch: 6| Step: 6
Training loss: 0.2561553815282694
Validation loss: 2.473338712979895

Epoch: 6| Step: 7
Training loss: 0.19906709545945367
Validation loss: 2.471652662953794

Epoch: 6| Step: 8
Training loss: 0.2910230238825197
Validation loss: 2.4626790869137056

Epoch: 6| Step: 9
Training loss: 0.2736767403455704
Validation loss: 2.4461770800157128

Epoch: 6| Step: 10
Training loss: 0.3213025354036014
Validation loss: 2.4742926314198557

Epoch: 6| Step: 11
Training loss: 0.42422649453753186
Validation loss: 2.486919387711418

Epoch: 6| Step: 12
Training loss: 0.20651282773688906
Validation loss: 2.499175782876401

Epoch: 6| Step: 13
Training loss: 0.18152349038202326
Validation loss: 2.4995265307255803

Epoch: 422| Step: 0
Training loss: 0.2908931833025522
Validation loss: 2.5007191069863772

Epoch: 6| Step: 1
Training loss: 0.17130081762780106
Validation loss: 2.5538999606711097

Epoch: 6| Step: 2
Training loss: 0.2346947078893235
Validation loss: 2.552336763644552

Epoch: 6| Step: 3
Training loss: 0.2697930930012787
Validation loss: 2.514052287011106

Epoch: 6| Step: 4
Training loss: 0.29730772805529265
Validation loss: 2.542450404424213

Epoch: 6| Step: 5
Training loss: 0.3753594027266218
Validation loss: 2.52076361786998

Epoch: 6| Step: 6
Training loss: 0.3172869493522475
Validation loss: 2.5475853692361836

Epoch: 6| Step: 7
Training loss: 0.2826209694820875
Validation loss: 2.523493867335582

Epoch: 6| Step: 8
Training loss: 0.3599653371044249
Validation loss: 2.526687775569508

Epoch: 6| Step: 9
Training loss: 0.3519310185372988
Validation loss: 2.5140020217401817

Epoch: 6| Step: 10
Training loss: 0.3051952386375308
Validation loss: 2.5017221712813593

Epoch: 6| Step: 11
Training loss: 0.30148920739881097
Validation loss: 2.4809302922119767

Epoch: 6| Step: 12
Training loss: 0.2007437659871665
Validation loss: 2.463006142174304

Epoch: 6| Step: 13
Training loss: 0.2863581944766688
Validation loss: 2.524613703456817

Epoch: 423| Step: 0
Training loss: 0.21123954552395333
Validation loss: 2.4679614212496612

Epoch: 6| Step: 1
Training loss: 0.3616485412219095
Validation loss: 2.4829420437055174

Epoch: 6| Step: 2
Training loss: 0.1988404646755996
Validation loss: 2.489557880263431

Epoch: 6| Step: 3
Training loss: 0.28024275874328797
Validation loss: 2.471606821677657

Epoch: 6| Step: 4
Training loss: 0.20746604678988195
Validation loss: 2.4895617161067696

Epoch: 6| Step: 5
Training loss: 0.2496249694012359
Validation loss: 2.4873416343781956

Epoch: 6| Step: 6
Training loss: 0.44154251155980623
Validation loss: 2.491361610486717

Epoch: 6| Step: 7
Training loss: 0.10075521114251093
Validation loss: 2.4738527380142625

Epoch: 6| Step: 8
Training loss: 0.18420183649307342
Validation loss: 2.463471154851932

Epoch: 6| Step: 9
Training loss: 0.3953322409423887
Validation loss: 2.5027871029128304

Epoch: 6| Step: 10
Training loss: 0.22768001529225093
Validation loss: 2.480746698378388

Epoch: 6| Step: 11
Training loss: 0.38119689462108375
Validation loss: 2.487614454527238

Epoch: 6| Step: 12
Training loss: 0.31270710519621064
Validation loss: 2.491548024959999

Epoch: 6| Step: 13
Training loss: 0.31221464957403583
Validation loss: 2.4974546056778846

Epoch: 424| Step: 0
Training loss: 0.39718624060766533
Validation loss: 2.505171937856998

Epoch: 6| Step: 1
Training loss: 0.2542214564511709
Validation loss: 2.477687429718266

Epoch: 6| Step: 2
Training loss: 0.18924994240725912
Validation loss: 2.509031219241044

Epoch: 6| Step: 3
Training loss: 0.253708410213766
Validation loss: 2.5324131561715495

Epoch: 6| Step: 4
Training loss: 0.40978713001881145
Validation loss: 2.516150946244956

Epoch: 6| Step: 5
Training loss: 0.18156850059691476
Validation loss: 2.5218244302830346

Epoch: 6| Step: 6
Training loss: 0.3153391138192826
Validation loss: 2.5053217512590162

Epoch: 6| Step: 7
Training loss: 0.27700438354652474
Validation loss: 2.5298442134804957

Epoch: 6| Step: 8
Training loss: 0.2151800298189128
Validation loss: 2.4991394776956986

Epoch: 6| Step: 9
Training loss: 0.15433130000974152
Validation loss: 2.5107740854882166

Epoch: 6| Step: 10
Training loss: 0.20988983902208638
Validation loss: 2.503634243656668

Epoch: 6| Step: 11
Training loss: 0.37264091812039724
Validation loss: 2.4820476333244934

Epoch: 6| Step: 12
Training loss: 0.2896916399045755
Validation loss: 2.5050210598576212

Epoch: 6| Step: 13
Training loss: 0.24777424465326423
Validation loss: 2.5166571890629377

Epoch: 425| Step: 0
Training loss: 0.21737888329203206
Validation loss: 2.504075905461717

Epoch: 6| Step: 1
Training loss: 0.3466504151786806
Validation loss: 2.508715088691504

Epoch: 6| Step: 2
Training loss: 0.19636825368488198
Validation loss: 2.504880719528918

Epoch: 6| Step: 3
Training loss: 0.23848681884755127
Validation loss: 2.5062964836185686

Epoch: 6| Step: 4
Training loss: 0.26718379291394323
Validation loss: 2.534495794664315

Epoch: 6| Step: 5
Training loss: 0.26039487588630483
Validation loss: 2.494527855531306

Epoch: 6| Step: 6
Training loss: 0.17025306368863632
Validation loss: 2.4968002526021764

Epoch: 6| Step: 7
Training loss: 0.4177664686195127
Validation loss: 2.4537592681160927

Epoch: 6| Step: 8
Training loss: 0.2713048327526306
Validation loss: 2.4638244402272016

Epoch: 6| Step: 9
Training loss: 0.35054787346816946
Validation loss: 2.474865345685754

Epoch: 6| Step: 10
Training loss: 0.24418095064912065
Validation loss: 2.4689114633213136

Epoch: 6| Step: 11
Training loss: 0.30743296117315094
Validation loss: 2.516700341039379

Epoch: 6| Step: 12
Training loss: 0.332539113906324
Validation loss: 2.545873971058249

Epoch: 6| Step: 13
Training loss: 0.3025244200126322
Validation loss: 2.5275328148723553

Epoch: 426| Step: 0
Training loss: 0.29543301832779567
Validation loss: 2.535830106599291

Epoch: 6| Step: 1
Training loss: 0.23659057861246247
Validation loss: 2.5306986415027595

Epoch: 6| Step: 2
Training loss: 0.32632691587480284
Validation loss: 2.574124503149714

Epoch: 6| Step: 3
Training loss: 0.20147511857755043
Validation loss: 2.541430359628786

Epoch: 6| Step: 4
Training loss: 0.21500078877592665
Validation loss: 2.53615432321943

Epoch: 6| Step: 5
Training loss: 0.20511154629082676
Validation loss: 2.5038983908653374

Epoch: 6| Step: 6
Training loss: 0.38246571150285824
Validation loss: 2.476380814318537

Epoch: 6| Step: 7
Training loss: 0.3220628505048245
Validation loss: 2.4953286859082655

Epoch: 6| Step: 8
Training loss: 0.43807422896107645
Validation loss: 2.447143139410164

Epoch: 6| Step: 9
Training loss: 0.3104037908896206
Validation loss: 2.461638959512002

Epoch: 6| Step: 10
Training loss: 0.3516043320245737
Validation loss: 2.4868133594450486

Epoch: 6| Step: 11
Training loss: 0.2789141827478313
Validation loss: 2.506772998127864

Epoch: 6| Step: 12
Training loss: 0.3667329653311839
Validation loss: 2.484640342435581

Epoch: 6| Step: 13
Training loss: 0.19318829298643417
Validation loss: 2.513369397466907

Epoch: 427| Step: 0
Training loss: 0.23170832887702236
Validation loss: 2.5206263928520545

Epoch: 6| Step: 1
Training loss: 0.3428766687472876
Validation loss: 2.5176630158812427

Epoch: 6| Step: 2
Training loss: 0.19224770153566625
Validation loss: 2.5285690919652315

Epoch: 6| Step: 3
Training loss: 0.30609317676282155
Validation loss: 2.5494820016588386

Epoch: 6| Step: 4
Training loss: 0.41206905655900483
Validation loss: 2.5410485332151054

Epoch: 6| Step: 5
Training loss: 0.3784715183885351
Validation loss: 2.5147447500114537

Epoch: 6| Step: 6
Training loss: 0.224923155165829
Validation loss: 2.534261678415355

Epoch: 6| Step: 7
Training loss: 0.30165369898145106
Validation loss: 2.477191683510672

Epoch: 6| Step: 8
Training loss: 0.1988130533767717
Validation loss: 2.4695159484038554

Epoch: 6| Step: 9
Training loss: 0.237577524833586
Validation loss: 2.4727652506489264

Epoch: 6| Step: 10
Training loss: 0.2834463587704526
Validation loss: 2.4501571944291634

Epoch: 6| Step: 11
Training loss: 0.24219006875429405
Validation loss: 2.462813011652887

Epoch: 6| Step: 12
Training loss: 0.33779056809590485
Validation loss: 2.4674618591093043

Epoch: 6| Step: 13
Training loss: 0.17988014260629104
Validation loss: 2.446993167990815

Epoch: 428| Step: 0
Training loss: 0.19008262503518616
Validation loss: 2.4488334951356157

Epoch: 6| Step: 1
Training loss: 0.14419972570134634
Validation loss: 2.4457518511716883

Epoch: 6| Step: 2
Training loss: 0.21484229347428863
Validation loss: 2.483487604897409

Epoch: 6| Step: 3
Training loss: 0.29523759325852034
Validation loss: 2.5021326157052024

Epoch: 6| Step: 4
Training loss: 0.38129474502391875
Validation loss: 2.464374602181821

Epoch: 6| Step: 5
Training loss: 0.392778051530397
Validation loss: 2.492091148710914

Epoch: 6| Step: 6
Training loss: 0.23972300245411737
Validation loss: 2.466415940567901

Epoch: 6| Step: 7
Training loss: 0.24885103578355777
Validation loss: 2.487973062153325

Epoch: 6| Step: 8
Training loss: 0.4014873463998948
Validation loss: 2.459714926425796

Epoch: 6| Step: 9
Training loss: 0.22585622275286046
Validation loss: 2.448609628996965

Epoch: 6| Step: 10
Training loss: 0.18664442003430873
Validation loss: 2.496369338399245

Epoch: 6| Step: 11
Training loss: 0.2679055153220277
Validation loss: 2.4643118477670876

Epoch: 6| Step: 12
Training loss: 0.2895236460947645
Validation loss: 2.4607460651986854

Epoch: 6| Step: 13
Training loss: 0.5287418340949731
Validation loss: 2.505705898231092

Epoch: 429| Step: 0
Training loss: 0.2658436100018739
Validation loss: 2.4534287012258877

Epoch: 6| Step: 1
Training loss: 0.3434322362328053
Validation loss: 2.490358010137845

Epoch: 6| Step: 2
Training loss: 0.2463617833084458
Validation loss: 2.47527057518984

Epoch: 6| Step: 3
Training loss: 0.37665498634530886
Validation loss: 2.4612153859506067

Epoch: 6| Step: 4
Training loss: 0.4027460364828073
Validation loss: 2.4888543000197703

Epoch: 6| Step: 5
Training loss: 0.4676983321068586
Validation loss: 2.4670538890464364

Epoch: 6| Step: 6
Training loss: 0.18403119870271128
Validation loss: 2.4919676551132013

Epoch: 6| Step: 7
Training loss: 0.20662447716657767
Validation loss: 2.483445035601556

Epoch: 6| Step: 8
Training loss: 0.16321938588462043
Validation loss: 2.498542464333569

Epoch: 6| Step: 9
Training loss: 0.24372225199997208
Validation loss: 2.4861280061424966

Epoch: 6| Step: 10
Training loss: 0.2800253191850844
Validation loss: 2.478733896867763

Epoch: 6| Step: 11
Training loss: 0.26179188802415193
Validation loss: 2.4497089364190274

Epoch: 6| Step: 12
Training loss: 0.35563735316966943
Validation loss: 2.443407799531812

Epoch: 6| Step: 13
Training loss: 0.2580704554502349
Validation loss: 2.4134347164875103

Epoch: 430| Step: 0
Training loss: 0.2888597086363212
Validation loss: 2.4437966980868024

Epoch: 6| Step: 1
Training loss: 0.3516254792493259
Validation loss: 2.4625751984635276

Epoch: 6| Step: 2
Training loss: 0.26441231360570705
Validation loss: 2.496545370019227

Epoch: 6| Step: 3
Training loss: 0.30434693351997527
Validation loss: 2.4768118183721075

Epoch: 6| Step: 4
Training loss: 0.3602449005978482
Validation loss: 2.473422337721892

Epoch: 6| Step: 5
Training loss: 0.2800213414386659
Validation loss: 2.4438264098678113

Epoch: 6| Step: 6
Training loss: 0.20717944832946283
Validation loss: 2.47937554003214

Epoch: 6| Step: 7
Training loss: 0.38018841451785435
Validation loss: 2.4797798619298104

Epoch: 6| Step: 8
Training loss: 0.3412157841181552
Validation loss: 2.462452340121597

Epoch: 6| Step: 9
Training loss: 0.25825777038265535
Validation loss: 2.4652014999070384

Epoch: 6| Step: 10
Training loss: 0.3347587531329247
Validation loss: 2.4863865152273474

Epoch: 6| Step: 11
Training loss: 0.1994404120601748
Validation loss: 2.536925797574124

Epoch: 6| Step: 12
Training loss: 0.34316613723744305
Validation loss: 2.500881622588562

Epoch: 6| Step: 13
Training loss: 0.18474574556730258
Validation loss: 2.5023125525154244

Epoch: 431| Step: 0
Training loss: 0.2850965933908312
Validation loss: 2.5214871262396445

Epoch: 6| Step: 1
Training loss: 0.23752848742945884
Validation loss: 2.533600750074089

Epoch: 6| Step: 2
Training loss: 0.30878790047491467
Validation loss: 2.52746070319493

Epoch: 6| Step: 3
Training loss: 0.3377410469393289
Validation loss: 2.5390930587911105

Epoch: 6| Step: 4
Training loss: 0.2774130774875327
Validation loss: 2.5398972348731435

Epoch: 6| Step: 5
Training loss: 0.3064347566205223
Validation loss: 2.4984653920902478

Epoch: 6| Step: 6
Training loss: 0.2742606171819218
Validation loss: 2.4891621933729513

Epoch: 6| Step: 7
Training loss: 0.3636154975174026
Validation loss: 2.4502086119898463

Epoch: 6| Step: 8
Training loss: 0.1805443650735186
Validation loss: 2.4522977193920608

Epoch: 6| Step: 9
Training loss: 0.39759187158502013
Validation loss: 2.438539863236692

Epoch: 6| Step: 10
Training loss: 0.3657233285324783
Validation loss: 2.465957268650159

Epoch: 6| Step: 11
Training loss: 0.28097735541284974
Validation loss: 2.4126774178535926

Epoch: 6| Step: 12
Training loss: 0.22627144237727045
Validation loss: 2.436593017663095

Epoch: 6| Step: 13
Training loss: 0.49070197673894655
Validation loss: 2.442474891077677

Epoch: 432| Step: 0
Training loss: 0.2739737429594088
Validation loss: 2.4688137893047335

Epoch: 6| Step: 1
Training loss: 0.28656777400963585
Validation loss: 2.4620727753960847

Epoch: 6| Step: 2
Training loss: 0.26757291802679206
Validation loss: 2.4679253248183506

Epoch: 6| Step: 3
Training loss: 0.281851945555954
Validation loss: 2.4661517766843715

Epoch: 6| Step: 4
Training loss: 0.27378403639292576
Validation loss: 2.470228547099385

Epoch: 6| Step: 5
Training loss: 0.2450180081030893
Validation loss: 2.4068914569795252

Epoch: 6| Step: 6
Training loss: 0.31178355344082226
Validation loss: 2.453669188594151

Epoch: 6| Step: 7
Training loss: 0.35333837628514503
Validation loss: 2.454764676219767

Epoch: 6| Step: 8
Training loss: 0.2068494052122526
Validation loss: 2.4875129616920586

Epoch: 6| Step: 9
Training loss: 0.2283767375942581
Validation loss: 2.443326234389875

Epoch: 6| Step: 10
Training loss: 0.1380711424804842
Validation loss: 2.4389557867721567

Epoch: 6| Step: 11
Training loss: 0.4342833696774646
Validation loss: 2.466533262764674

Epoch: 6| Step: 12
Training loss: 0.32826744121357937
Validation loss: 2.4654585578256887

Epoch: 6| Step: 13
Training loss: 0.5032940183794545
Validation loss: 2.4797511071539735

Epoch: 433| Step: 0
Training loss: 0.2757491084920491
Validation loss: 2.4924860682312944

Epoch: 6| Step: 1
Training loss: 0.3010111091486907
Validation loss: 2.490954555194797

Epoch: 6| Step: 2
Training loss: 0.2674421814350318
Validation loss: 2.4893973122232076

Epoch: 6| Step: 3
Training loss: 0.38039700734473547
Validation loss: 2.5216114270839696

Epoch: 6| Step: 4
Training loss: 0.2037027377474364
Validation loss: 2.517166270880733

Epoch: 6| Step: 5
Training loss: 0.27987128990716253
Validation loss: 2.495028175763577

Epoch: 6| Step: 6
Training loss: 0.2933539084015334
Validation loss: 2.5125263824122595

Epoch: 6| Step: 7
Training loss: 0.24433107195918372
Validation loss: 2.4981777728332193

Epoch: 6| Step: 8
Training loss: 0.21879645263090627
Validation loss: 2.5421581420175396

Epoch: 6| Step: 9
Training loss: 0.3049333021059119
Validation loss: 2.491342937453089

Epoch: 6| Step: 10
Training loss: 0.1666367188508692
Validation loss: 2.5007878405490063

Epoch: 6| Step: 11
Training loss: 0.3600080346495689
Validation loss: 2.505585407474909

Epoch: 6| Step: 12
Training loss: 0.15102073644995515
Validation loss: 2.494578914513831

Epoch: 6| Step: 13
Training loss: 0.32913538365658135
Validation loss: 2.4966439537440057

Epoch: 434| Step: 0
Training loss: 0.31886027429449854
Validation loss: 2.5095388124927163

Epoch: 6| Step: 1
Training loss: 0.19886159671319573
Validation loss: 2.461007451920298

Epoch: 6| Step: 2
Training loss: 0.22144489205522874
Validation loss: 2.4933187235944385

Epoch: 6| Step: 3
Training loss: 0.22545677880264892
Validation loss: 2.4881946612210597

Epoch: 6| Step: 4
Training loss: 0.2521531545610017
Validation loss: 2.4920790042380756

Epoch: 6| Step: 5
Training loss: 0.22614600275725336
Validation loss: 2.4641012335751364

Epoch: 6| Step: 6
Training loss: 0.3617341930149529
Validation loss: 2.505870300217488

Epoch: 6| Step: 7
Training loss: 0.21043903122603425
Validation loss: 2.501642959900616

Epoch: 6| Step: 8
Training loss: 0.21983687280934286
Validation loss: 2.5152846212901694

Epoch: 6| Step: 9
Training loss: 0.24694268318892582
Validation loss: 2.519404923341377

Epoch: 6| Step: 10
Training loss: 0.3286622168280506
Validation loss: 2.517158584019732

Epoch: 6| Step: 11
Training loss: 0.3545427522773065
Validation loss: 2.515852354141683

Epoch: 6| Step: 12
Training loss: 0.41141860705752514
Validation loss: 2.5176119810896624

Epoch: 6| Step: 13
Training loss: 0.14990284699097697
Validation loss: 2.5153265110834155

Epoch: 435| Step: 0
Training loss: 0.22153222645272502
Validation loss: 2.5126928128245916

Epoch: 6| Step: 1
Training loss: 0.28094577229746137
Validation loss: 2.512743478208827

Epoch: 6| Step: 2
Training loss: 0.2891901353048598
Validation loss: 2.496807816294994

Epoch: 6| Step: 3
Training loss: 0.327046483792729
Validation loss: 2.5383722040588554

Epoch: 6| Step: 4
Training loss: 0.3663910283096998
Validation loss: 2.55703723526377

Epoch: 6| Step: 5
Training loss: 0.23497331068227378
Validation loss: 2.529716542720441

Epoch: 6| Step: 6
Training loss: 0.21531103641638208
Validation loss: 2.518241088654363

Epoch: 6| Step: 7
Training loss: 0.2960619207299629
Validation loss: 2.4977665363789407

Epoch: 6| Step: 8
Training loss: 0.22468142804999316
Validation loss: 2.5369190421694205

Epoch: 6| Step: 9
Training loss: 0.2952090879554948
Validation loss: 2.5533193840020227

Epoch: 6| Step: 10
Training loss: 0.38557728006890457
Validation loss: 2.5429728994557284

Epoch: 6| Step: 11
Training loss: 0.35287719319277183
Validation loss: 2.5061222279010504

Epoch: 6| Step: 12
Training loss: 0.3072227977369236
Validation loss: 2.5128101296037366

Epoch: 6| Step: 13
Training loss: 0.35369299554001693
Validation loss: 2.494540760399103

Epoch: 436| Step: 0
Training loss: 0.3597095010824583
Validation loss: 2.5095981030460477

Epoch: 6| Step: 1
Training loss: 0.22215578653660434
Validation loss: 2.4992866780277128

Epoch: 6| Step: 2
Training loss: 0.30004175114181286
Validation loss: 2.4960292671940016

Epoch: 6| Step: 3
Training loss: 0.3451710933603754
Validation loss: 2.501038452555837

Epoch: 6| Step: 4
Training loss: 0.3673596688686745
Validation loss: 2.508297754409527

Epoch: 6| Step: 5
Training loss: 0.21545921081882402
Validation loss: 2.5093575089398694

Epoch: 6| Step: 6
Training loss: 0.34815613030456505
Validation loss: 2.4980379875897523

Epoch: 6| Step: 7
Training loss: 0.21907939123369033
Validation loss: 2.495200035605001

Epoch: 6| Step: 8
Training loss: 0.3006775912719926
Validation loss: 2.53295954748929

Epoch: 6| Step: 9
Training loss: 0.2165625568901747
Validation loss: 2.5333013695522992

Epoch: 6| Step: 10
Training loss: 0.21622131171144515
Validation loss: 2.5655454740828936

Epoch: 6| Step: 11
Training loss: 0.3253154589970086
Validation loss: 2.5466155320069714

Epoch: 6| Step: 12
Training loss: 0.21828758376645874
Validation loss: 2.531379176846399

Epoch: 6| Step: 13
Training loss: 0.24025813814812894
Validation loss: 2.544975531216443

Epoch: 437| Step: 0
Training loss: 0.3168856203680829
Validation loss: 2.5559955514713173

Epoch: 6| Step: 1
Training loss: 0.33336705047231996
Validation loss: 2.5091019867184174

Epoch: 6| Step: 2
Training loss: 0.2573754623320004
Validation loss: 2.5152623868014055

Epoch: 6| Step: 3
Training loss: 0.22168501456829887
Validation loss: 2.509779633347715

Epoch: 6| Step: 4
Training loss: 0.4305636057391665
Validation loss: 2.5053988929533757

Epoch: 6| Step: 5
Training loss: 0.13731413357014305
Validation loss: 2.5329476571608773

Epoch: 6| Step: 6
Training loss: 0.2954920757614113
Validation loss: 2.4914086621240457

Epoch: 6| Step: 7
Training loss: 0.3142889553876748
Validation loss: 2.48025533584726

Epoch: 6| Step: 8
Training loss: 0.18403169464845295
Validation loss: 2.487659330970194

Epoch: 6| Step: 9
Training loss: 0.29997402714513455
Validation loss: 2.489184682628245

Epoch: 6| Step: 10
Training loss: 0.20881403460562417
Validation loss: 2.5130728237039115

Epoch: 6| Step: 11
Training loss: 0.1654830693361001
Validation loss: 2.4955188849849685

Epoch: 6| Step: 12
Training loss: 0.31096201565197173
Validation loss: 2.509751034335072

Epoch: 6| Step: 13
Training loss: 0.1493815654744285
Validation loss: 2.4970524167363832

Epoch: 438| Step: 0
Training loss: 0.20528255446030158
Validation loss: 2.508121005734677

Epoch: 6| Step: 1
Training loss: 0.21137290628198255
Validation loss: 2.5300508953317182

Epoch: 6| Step: 2
Training loss: 0.2629395948035975
Validation loss: 2.5117817787582366

Epoch: 6| Step: 3
Training loss: 0.15407608024602856
Validation loss: 2.5080200872003315

Epoch: 6| Step: 4
Training loss: 0.45603447814208725
Validation loss: 2.5135846677312577

Epoch: 6| Step: 5
Training loss: 0.35126355494616396
Validation loss: 2.493671913434585

Epoch: 6| Step: 6
Training loss: 0.2517178938109354
Validation loss: 2.5067071311967624

Epoch: 6| Step: 7
Training loss: 0.13357876866536172
Validation loss: 2.529869291460332

Epoch: 6| Step: 8
Training loss: 0.27739349778715705
Validation loss: 2.4742962505512702

Epoch: 6| Step: 9
Training loss: 0.18912893263087088
Validation loss: 2.5031955338663248

Epoch: 6| Step: 10
Training loss: 0.20523746295024609
Validation loss: 2.4986299908891128

Epoch: 6| Step: 11
Training loss: 0.3125798957734505
Validation loss: 2.4951838627942253

Epoch: 6| Step: 12
Training loss: 0.3152649511282907
Validation loss: 2.4770806773501888

Epoch: 6| Step: 13
Training loss: 0.1881661007584469
Validation loss: 2.512632775995834

Epoch: 439| Step: 0
Training loss: 0.3260400699946071
Validation loss: 2.5118667379559474

Epoch: 6| Step: 1
Training loss: 0.29279698740967547
Validation loss: 2.516060571012608

Epoch: 6| Step: 2
Training loss: 0.22393090150338557
Validation loss: 2.491453750106042

Epoch: 6| Step: 3
Training loss: 0.3609461027829351
Validation loss: 2.4957800304108724

Epoch: 6| Step: 4
Training loss: 0.24540980225555353
Validation loss: 2.492837761452077

Epoch: 6| Step: 5
Training loss: 0.1795830008119424
Validation loss: 2.489145060576683

Epoch: 6| Step: 6
Training loss: 0.2737977923953851
Validation loss: 2.4919716909416953

Epoch: 6| Step: 7
Training loss: 0.1907397460312516
Validation loss: 2.5087581958932508

Epoch: 6| Step: 8
Training loss: 0.1775704770469885
Validation loss: 2.509345655934152

Epoch: 6| Step: 9
Training loss: 0.2178095458335252
Validation loss: 2.5117364177676693

Epoch: 6| Step: 10
Training loss: 0.28216911179965926
Validation loss: 2.513273186020938

Epoch: 6| Step: 11
Training loss: 0.2577862581711562
Validation loss: 2.5151265559503373

Epoch: 6| Step: 12
Training loss: 0.24625718275719244
Validation loss: 2.5094319592879044

Epoch: 6| Step: 13
Training loss: 0.28673274450424224
Validation loss: 2.539984647967526

Epoch: 440| Step: 0
Training loss: 0.36016578330705856
Validation loss: 2.5455669650479877

Epoch: 6| Step: 1
Training loss: 0.2399574327220687
Validation loss: 2.558562674635453

Epoch: 6| Step: 2
Training loss: 0.22398296579290877
Validation loss: 2.5432196115452026

Epoch: 6| Step: 3
Training loss: 0.34575066535924304
Validation loss: 2.520076959261391

Epoch: 6| Step: 4
Training loss: 0.3925528067400398
Validation loss: 2.545913046563378

Epoch: 6| Step: 5
Training loss: 0.27922924263253524
Validation loss: 2.500894064645207

Epoch: 6| Step: 6
Training loss: 0.24521247561825532
Validation loss: 2.5061504898362905

Epoch: 6| Step: 7
Training loss: 0.28369866786992964
Validation loss: 2.48474065259754

Epoch: 6| Step: 8
Training loss: 0.27302364638032905
Validation loss: 2.4720333348746677

Epoch: 6| Step: 9
Training loss: 0.3850382308741998
Validation loss: 2.4389149660989067

Epoch: 6| Step: 10
Training loss: 0.3532215391546909
Validation loss: 2.467521467461972

Epoch: 6| Step: 11
Training loss: 0.27784380359882976
Validation loss: 2.508473200365438

Epoch: 6| Step: 12
Training loss: 0.24025383537061332
Validation loss: 2.5050770960550963

Epoch: 6| Step: 13
Training loss: 0.3569214449587965
Validation loss: 2.5335768984780915

Epoch: 441| Step: 0
Training loss: 0.4935332927285983
Validation loss: 2.5365362799502997

Epoch: 6| Step: 1
Training loss: 0.2139315834815357
Validation loss: 2.4979921399552

Epoch: 6| Step: 2
Training loss: 0.2591474247092945
Validation loss: 2.490996951904532

Epoch: 6| Step: 3
Training loss: 0.2756971857907256
Validation loss: 2.4638486879558577

Epoch: 6| Step: 4
Training loss: 0.3343594658888624
Validation loss: 2.4932026201924713

Epoch: 6| Step: 5
Training loss: 0.3643831134697653
Validation loss: 2.4971202908046704

Epoch: 6| Step: 6
Training loss: 0.41269169023678043
Validation loss: 2.4863012390510675

Epoch: 6| Step: 7
Training loss: 0.29586152202108207
Validation loss: 2.5562487209523566

Epoch: 6| Step: 8
Training loss: 0.3091842217272542
Validation loss: 2.582795445046597

Epoch: 6| Step: 9
Training loss: 0.38022018004821245
Validation loss: 2.606682723495536

Epoch: 6| Step: 10
Training loss: 0.4693782569833207
Validation loss: 2.596510235718426

Epoch: 6| Step: 11
Training loss: 0.25934031093683063
Validation loss: 2.60522581420654

Epoch: 6| Step: 12
Training loss: 0.2763173493108844
Validation loss: 2.5560963826791707

Epoch: 6| Step: 13
Training loss: 0.22892303502902844
Validation loss: 2.5661629938798907

Epoch: 442| Step: 0
Training loss: 0.2750548757724246
Validation loss: 2.5190561970890197

Epoch: 6| Step: 1
Training loss: 0.2840888018963433
Validation loss: 2.5296439146199794

Epoch: 6| Step: 2
Training loss: 0.34197583554322886
Validation loss: 2.5164205976718246

Epoch: 6| Step: 3
Training loss: 0.41548244354762004
Validation loss: 2.4935611572034677

Epoch: 6| Step: 4
Training loss: 0.2968258566085213
Validation loss: 2.4588036258521897

Epoch: 6| Step: 5
Training loss: 0.3660314094453873
Validation loss: 2.449511283848907

Epoch: 6| Step: 6
Training loss: 0.284247020072549
Validation loss: 2.4238165708486297

Epoch: 6| Step: 7
Training loss: 0.267524574657245
Validation loss: 2.438141947843405

Epoch: 6| Step: 8
Training loss: 0.27131636655873576
Validation loss: 2.4361185724425543

Epoch: 6| Step: 9
Training loss: 0.37374869831203
Validation loss: 2.434948096779094

Epoch: 6| Step: 10
Training loss: 0.3281011799840221
Validation loss: 2.4278988468700358

Epoch: 6| Step: 11
Training loss: 0.28849916724691416
Validation loss: 2.412563163814149

Epoch: 6| Step: 12
Training loss: 0.35422709828329496
Validation loss: 2.4177321541697854

Epoch: 6| Step: 13
Training loss: 0.28597212045088366
Validation loss: 2.3828679893806712

Epoch: 443| Step: 0
Training loss: 0.38241603328618856
Validation loss: 2.3919156937640036

Epoch: 6| Step: 1
Training loss: 0.3776365222442092
Validation loss: 2.411825524495605

Epoch: 6| Step: 2
Training loss: 0.30177758902029395
Validation loss: 2.434172695018046

Epoch: 6| Step: 3
Training loss: 0.29941307112497934
Validation loss: 2.4364097961140327

Epoch: 6| Step: 4
Training loss: 0.251387752826915
Validation loss: 2.4502334812457645

Epoch: 6| Step: 5
Training loss: 0.3383868328008288
Validation loss: 2.43551904427074

Epoch: 6| Step: 6
Training loss: 0.48393975976659986
Validation loss: 2.45067736583304

Epoch: 6| Step: 7
Training loss: 0.32870377857484
Validation loss: 2.4532526851834517

Epoch: 6| Step: 8
Training loss: 0.3260465141196038
Validation loss: 2.445774461820639

Epoch: 6| Step: 9
Training loss: 0.19801535571885295
Validation loss: 2.48753315011053

Epoch: 6| Step: 10
Training loss: 0.31383147306510495
Validation loss: 2.513896391289392

Epoch: 6| Step: 11
Training loss: 0.3460109870067523
Validation loss: 2.5586761168274554

Epoch: 6| Step: 12
Training loss: 0.3084784062825469
Validation loss: 2.57553475212763

Epoch: 6| Step: 13
Training loss: 0.536451762507915
Validation loss: 2.560559650385299

Epoch: 444| Step: 0
Training loss: 0.2634803358844187
Validation loss: 2.5514527573783217

Epoch: 6| Step: 1
Training loss: 0.43659827425065645
Validation loss: 2.518290736894979

Epoch: 6| Step: 2
Training loss: 0.31347166633941653
Validation loss: 2.4645108002524676

Epoch: 6| Step: 3
Training loss: 0.30673177542796237
Validation loss: 2.4466384531752516

Epoch: 6| Step: 4
Training loss: 0.3445897141415117
Validation loss: 2.4259481506227565

Epoch: 6| Step: 5
Training loss: 0.3478355052739597
Validation loss: 2.4063476257166143

Epoch: 6| Step: 6
Training loss: 0.34319097405799204
Validation loss: 2.42252479963241

Epoch: 6| Step: 7
Training loss: 0.2912554424825194
Validation loss: 2.453106179082542

Epoch: 6| Step: 8
Training loss: 0.29393807589218823
Validation loss: 2.454319490866539

Epoch: 6| Step: 9
Training loss: 0.36284155539549645
Validation loss: 2.481726285650436

Epoch: 6| Step: 10
Training loss: 0.4352008146139017
Validation loss: 2.47034008843562

Epoch: 6| Step: 11
Training loss: 0.2829357331854662
Validation loss: 2.4694065235069385

Epoch: 6| Step: 12
Training loss: 0.29237057973057184
Validation loss: 2.4632835507051625

Epoch: 6| Step: 13
Training loss: 0.2907855769537022
Validation loss: 2.4837962130535005

Epoch: 445| Step: 0
Training loss: 0.2036278259790792
Validation loss: 2.4727036492765504

Epoch: 6| Step: 1
Training loss: 0.3656059048222757
Validation loss: 2.4415109657062395

Epoch: 6| Step: 2
Training loss: 0.1939956906936287
Validation loss: 2.4886010775258898

Epoch: 6| Step: 3
Training loss: 0.3668578067825472
Validation loss: 2.503055819394128

Epoch: 6| Step: 4
Training loss: 0.2674464994923536
Validation loss: 2.4682455023769863

Epoch: 6| Step: 5
Training loss: 0.31775670256624944
Validation loss: 2.490450971796109

Epoch: 6| Step: 6
Training loss: 0.4090302952561393
Validation loss: 2.4705932909247186

Epoch: 6| Step: 7
Training loss: 0.3045152764317155
Validation loss: 2.461557514706917

Epoch: 6| Step: 8
Training loss: 0.18891913085325146
Validation loss: 2.4646827483048526

Epoch: 6| Step: 9
Training loss: 0.2847579630591507
Validation loss: 2.451382010169038

Epoch: 6| Step: 10
Training loss: 0.30054085277516096
Validation loss: 2.479289031600198

Epoch: 6| Step: 11
Training loss: 0.4491127552536599
Validation loss: 2.5350153162233577

Epoch: 6| Step: 12
Training loss: 0.2692565347255736
Validation loss: 2.5257263511152948

Epoch: 6| Step: 13
Training loss: 0.24770821709037943
Validation loss: 2.5884947166031855

Epoch: 446| Step: 0
Training loss: 0.3444120036389541
Validation loss: 2.5458443989456256

Epoch: 6| Step: 1
Training loss: 0.22495944896165118
Validation loss: 2.570905499138403

Epoch: 6| Step: 2
Training loss: 0.25696386480112327
Validation loss: 2.5370992274624826

Epoch: 6| Step: 3
Training loss: 0.22555733371398065
Validation loss: 2.545887177548481

Epoch: 6| Step: 4
Training loss: 0.40545299183354055
Validation loss: 2.56073860120283

Epoch: 6| Step: 5
Training loss: 0.3527307491179499
Validation loss: 2.564991947607516

Epoch: 6| Step: 6
Training loss: 0.2554856694302847
Validation loss: 2.5535678211756387

Epoch: 6| Step: 7
Training loss: 0.31905817206396253
Validation loss: 2.5275958205064835

Epoch: 6| Step: 8
Training loss: 0.16792489743549757
Validation loss: 2.4797246223602647

Epoch: 6| Step: 9
Training loss: 0.2021600655422531
Validation loss: 2.51660529905767

Epoch: 6| Step: 10
Training loss: 0.37483370590587217
Validation loss: 2.501872032430412

Epoch: 6| Step: 11
Training loss: 0.3379160259599801
Validation loss: 2.510250470193273

Epoch: 6| Step: 12
Training loss: 0.26299722332630876
Validation loss: 2.5090260194728575

Epoch: 6| Step: 13
Training loss: 0.22492729575331852
Validation loss: 2.511079088516369

Epoch: 447| Step: 0
Training loss: 0.3122475558109692
Validation loss: 2.539004615395227

Epoch: 6| Step: 1
Training loss: 0.3066441359592307
Validation loss: 2.5153724932464554

Epoch: 6| Step: 2
Training loss: 0.32071569699214486
Validation loss: 2.5169578694531918

Epoch: 6| Step: 3
Training loss: 0.22792541872552818
Validation loss: 2.503743498627987

Epoch: 6| Step: 4
Training loss: 0.38411956611461817
Validation loss: 2.530032875161646

Epoch: 6| Step: 5
Training loss: 0.19029096783816715
Validation loss: 2.5206504956493987

Epoch: 6| Step: 6
Training loss: 0.17919053932395856
Validation loss: 2.494998274316408

Epoch: 6| Step: 7
Training loss: 0.18179591524127356
Validation loss: 2.4938258172689247

Epoch: 6| Step: 8
Training loss: 0.281665005733081
Validation loss: 2.5147461591370814

Epoch: 6| Step: 9
Training loss: 0.2771422365985568
Validation loss: 2.465461467508819

Epoch: 6| Step: 10
Training loss: 0.3012122744368678
Validation loss: 2.479869388937792

Epoch: 6| Step: 11
Training loss: 0.2593280002800323
Validation loss: 2.5077271713876375

Epoch: 6| Step: 12
Training loss: 0.35734671964691633
Validation loss: 2.4869143004618923

Epoch: 6| Step: 13
Training loss: 0.39102086036065936
Validation loss: 2.4939526598963284

Epoch: 448| Step: 0
Training loss: 0.185281644281903
Validation loss: 2.484983794121802

Epoch: 6| Step: 1
Training loss: 0.31373631776179395
Validation loss: 2.520342621873351

Epoch: 6| Step: 2
Training loss: 0.347482262697296
Validation loss: 2.4547299000658493

Epoch: 6| Step: 3
Training loss: 0.24881746338141328
Validation loss: 2.471018660422413

Epoch: 6| Step: 4
Training loss: 0.25462418804872594
Validation loss: 2.4960684533584727

Epoch: 6| Step: 5
Training loss: 0.4395134778435307
Validation loss: 2.474136439045082

Epoch: 6| Step: 6
Training loss: 0.2779185289514039
Validation loss: 2.473045935437636

Epoch: 6| Step: 7
Training loss: 0.1947706909071718
Validation loss: 2.4942247019376738

Epoch: 6| Step: 8
Training loss: 0.20264635178063134
Validation loss: 2.463682951669025

Epoch: 6| Step: 9
Training loss: 0.21261282828587844
Validation loss: 2.4418692983259667

Epoch: 6| Step: 10
Training loss: 0.32157233832075627
Validation loss: 2.4659787126492656

Epoch: 6| Step: 11
Training loss: 0.28857569040610626
Validation loss: 2.4723061240132855

Epoch: 6| Step: 12
Training loss: 0.2541591851639406
Validation loss: 2.4433920288500794

Epoch: 6| Step: 13
Training loss: 0.4219642120978405
Validation loss: 2.4425022799141938

Epoch: 449| Step: 0
Training loss: 0.3013493758232953
Validation loss: 2.4450286361842988

Epoch: 6| Step: 1
Training loss: 0.2998874562480221
Validation loss: 2.4568769612354586

Epoch: 6| Step: 2
Training loss: 0.14156377880200932
Validation loss: 2.4527697165139437

Epoch: 6| Step: 3
Training loss: 0.21992883484907405
Validation loss: 2.4627995324836296

Epoch: 6| Step: 4
Training loss: 0.3183681510230543
Validation loss: 2.466723988617224

Epoch: 6| Step: 5
Training loss: 0.4625381866361735
Validation loss: 2.4447327377715764

Epoch: 6| Step: 6
Training loss: 0.29858246223517115
Validation loss: 2.466497699944644

Epoch: 6| Step: 7
Training loss: 0.23372686892568206
Validation loss: 2.4668308398259224

Epoch: 6| Step: 8
Training loss: 0.21543599773997632
Validation loss: 2.4918160398462237

Epoch: 6| Step: 9
Training loss: 0.20320698110756147
Validation loss: 2.477565493051371

Epoch: 6| Step: 10
Training loss: 0.29104824011407726
Validation loss: 2.4375957978183855

Epoch: 6| Step: 11
Training loss: 0.13686749677254603
Validation loss: 2.48143079086697

Epoch: 6| Step: 12
Training loss: 0.1595436860728669
Validation loss: 2.499765483562373

Epoch: 6| Step: 13
Training loss: 0.13057720308022888
Validation loss: 2.5005432881929823

Epoch: 450| Step: 0
Training loss: 0.18716359756462297
Validation loss: 2.5086818544380884

Epoch: 6| Step: 1
Training loss: 0.3479167840675719
Validation loss: 2.5050362977379557

Epoch: 6| Step: 2
Training loss: 0.2618918060245152
Validation loss: 2.493812338161193

Epoch: 6| Step: 3
Training loss: 0.24510186744018997
Validation loss: 2.506281788369461

Epoch: 6| Step: 4
Training loss: 0.30746497369558895
Validation loss: 2.500501707454019

Epoch: 6| Step: 5
Training loss: 0.34698832568049065
Validation loss: 2.4774676531758932

Epoch: 6| Step: 6
Training loss: 0.23646806089135233
Validation loss: 2.495151546140485

Epoch: 6| Step: 7
Training loss: 0.14186449303981152
Validation loss: 2.4884471173815106

Epoch: 6| Step: 8
Training loss: 0.14241216746783383
Validation loss: 2.507507682141721

Epoch: 6| Step: 9
Training loss: 0.19943700316584528
Validation loss: 2.49482598851563

Epoch: 6| Step: 10
Training loss: 0.1976902423623806
Validation loss: 2.4989132053258145

Epoch: 6| Step: 11
Training loss: 0.19708544934819025
Validation loss: 2.499879276273087

Epoch: 6| Step: 12
Training loss: 0.20869854070082886
Validation loss: 2.4915052085544236

Epoch: 6| Step: 13
Training loss: 0.45965767032975186
Validation loss: 2.5012823579399077

Epoch: 451| Step: 0
Training loss: 0.13153203622859888
Validation loss: 2.489874906933252

Epoch: 6| Step: 1
Training loss: 0.20926510147123803
Validation loss: 2.5155764746872635

Epoch: 6| Step: 2
Training loss: 0.14470145153111466
Validation loss: 2.5299186998506915

Epoch: 6| Step: 3
Training loss: 0.42491390534305645
Validation loss: 2.4909834574893592

Epoch: 6| Step: 4
Training loss: 0.2553625743604624
Validation loss: 2.5086097741836526

Epoch: 6| Step: 5
Training loss: 0.24586539800228516
Validation loss: 2.434449113700211

Epoch: 6| Step: 6
Training loss: 0.22385363941003317
Validation loss: 2.4835843797675783

Epoch: 6| Step: 7
Training loss: 0.2557512593615896
Validation loss: 2.439812344071525

Epoch: 6| Step: 8
Training loss: 0.11479957227158905
Validation loss: 2.4580599648673567

Epoch: 6| Step: 9
Training loss: 0.3055886611319722
Validation loss: 2.4544377965370447

Epoch: 6| Step: 10
Training loss: 0.3520810329862459
Validation loss: 2.4561764087751152

Epoch: 6| Step: 11
Training loss: 0.2130190960378774
Validation loss: 2.4847761302307765

Epoch: 6| Step: 12
Training loss: 0.20459804655032346
Validation loss: 2.4445454511193025

Epoch: 6| Step: 13
Training loss: 0.3234270494956518
Validation loss: 2.438227867978367

Epoch: 452| Step: 0
Training loss: 0.3429559726985298
Validation loss: 2.4549381924564533

Epoch: 6| Step: 1
Training loss: 0.31474353577381886
Validation loss: 2.4623363045065214

Epoch: 6| Step: 2
Training loss: 0.164715924578733
Validation loss: 2.500731736430032

Epoch: 6| Step: 3
Training loss: 0.30637153432715436
Validation loss: 2.527858342121875

Epoch: 6| Step: 4
Training loss: 0.20404898043737432
Validation loss: 2.5214243604235995

Epoch: 6| Step: 5
Training loss: 0.31696545669753834
Validation loss: 2.5332044127893

Epoch: 6| Step: 6
Training loss: 0.3345467255713031
Validation loss: 2.543315348866076

Epoch: 6| Step: 7
Training loss: 0.20428594446937415
Validation loss: 2.5067254622280046

Epoch: 6| Step: 8
Training loss: 0.36040740368723834
Validation loss: 2.4998936158792167

Epoch: 6| Step: 9
Training loss: 0.21257750205804243
Validation loss: 2.4925009435569883

Epoch: 6| Step: 10
Training loss: 0.2780010466873238
Validation loss: 2.5018521759290673

Epoch: 6| Step: 11
Training loss: 0.277830583136192
Validation loss: 2.474939487542449

Epoch: 6| Step: 12
Training loss: 0.21422479943735612
Validation loss: 2.453673753404913

Epoch: 6| Step: 13
Training loss: 0.1931407154503672
Validation loss: 2.4648046405108275

Epoch: 453| Step: 0
Training loss: 0.22600315369456445
Validation loss: 2.438250781816151

Epoch: 6| Step: 1
Training loss: 0.4053453496534242
Validation loss: 2.4870028315503103

Epoch: 6| Step: 2
Training loss: 0.26024611928430186
Validation loss: 2.4808430107787416

Epoch: 6| Step: 3
Training loss: 0.33066524678900905
Validation loss: 2.4675424970945707

Epoch: 6| Step: 4
Training loss: 0.22376473879087605
Validation loss: 2.464620695273976

Epoch: 6| Step: 5
Training loss: 0.20808710010934925
Validation loss: 2.484806684995731

Epoch: 6| Step: 6
Training loss: 0.20361079299101612
Validation loss: 2.520235210524134

Epoch: 6| Step: 7
Training loss: 0.27385902611353374
Validation loss: 2.517646399826722

Epoch: 6| Step: 8
Training loss: 0.21855809956495903
Validation loss: 2.548830957363606

Epoch: 6| Step: 9
Training loss: 0.3858367610838182
Validation loss: 2.5268121726371318

Epoch: 6| Step: 10
Training loss: 0.1872816204867493
Validation loss: 2.4993676380537213

Epoch: 6| Step: 11
Training loss: 0.19641153111485601
Validation loss: 2.53870371919099

Epoch: 6| Step: 12
Training loss: 0.23246360051651035
Validation loss: 2.5207592190456496

Epoch: 6| Step: 13
Training loss: 0.19772023043764841
Validation loss: 2.480438194509806

Epoch: 454| Step: 0
Training loss: 0.29439241997591864
Validation loss: 2.500067507693761

Epoch: 6| Step: 1
Training loss: 0.17107233192125415
Validation loss: 2.494751999391305

Epoch: 6| Step: 2
Training loss: 0.3663214961693041
Validation loss: 2.4640792046556697

Epoch: 6| Step: 3
Training loss: 0.37957686629510823
Validation loss: 2.486137293945866

Epoch: 6| Step: 4
Training loss: 0.28522440997154724
Validation loss: 2.4823904368132874

Epoch: 6| Step: 5
Training loss: 0.2758287772487137
Validation loss: 2.486339724792313

Epoch: 6| Step: 6
Training loss: 0.3472349314218061
Validation loss: 2.473846493812291

Epoch: 6| Step: 7
Training loss: 0.17753109468178987
Validation loss: 2.512345154660413

Epoch: 6| Step: 8
Training loss: 0.20115515259802966
Validation loss: 2.493615361350733

Epoch: 6| Step: 9
Training loss: 0.291520557535016
Validation loss: 2.4885512330588497

Epoch: 6| Step: 10
Training loss: 0.21429386861363237
Validation loss: 2.4794875171986717

Epoch: 6| Step: 11
Training loss: 0.1524231899210622
Validation loss: 2.4729706177316113

Epoch: 6| Step: 12
Training loss: 0.1667022474625002
Validation loss: 2.4113600898765863

Epoch: 6| Step: 13
Training loss: 0.14240146823478406
Validation loss: 2.4398884731056287

Epoch: 455| Step: 0
Training loss: 0.22906268083375295
Validation loss: 2.437878405003671

Epoch: 6| Step: 1
Training loss: 0.24516268608052358
Validation loss: 2.4257935895264633

Epoch: 6| Step: 2
Training loss: 0.2736153160671446
Validation loss: 2.4400650665491157

Epoch: 6| Step: 3
Training loss: 0.18434705805392979
Validation loss: 2.4367582919141015

Epoch: 6| Step: 4
Training loss: 0.15681870794608513
Validation loss: 2.415612290082343

Epoch: 6| Step: 5
Training loss: 0.3036943290069814
Validation loss: 2.412441430583552

Epoch: 6| Step: 6
Training loss: 0.3286454523671759
Validation loss: 2.418237884719139

Epoch: 6| Step: 7
Training loss: 0.25231889301144905
Validation loss: 2.408782430754107

Epoch: 6| Step: 8
Training loss: 0.2006856820770535
Validation loss: 2.415124686255921

Epoch: 6| Step: 9
Training loss: 0.105844886604741
Validation loss: 2.430206270615555

Epoch: 6| Step: 10
Training loss: 0.12515430314386922
Validation loss: 2.4308444889061

Epoch: 6| Step: 11
Training loss: 0.3335741658235561
Validation loss: 2.4782248328305965

Epoch: 6| Step: 12
Training loss: 0.26017469449571956
Validation loss: 2.478640296658057

Epoch: 6| Step: 13
Training loss: 0.22096671340245538
Validation loss: 2.4827194347281276

Epoch: 456| Step: 0
Training loss: 0.16315510134099911
Validation loss: 2.466710803634229

Epoch: 6| Step: 1
Training loss: 0.15630301529800236
Validation loss: 2.435969725071282

Epoch: 6| Step: 2
Training loss: 0.2874808470939087
Validation loss: 2.4428136631301633

Epoch: 6| Step: 3
Training loss: 0.2807646112707658
Validation loss: 2.4421619934539223

Epoch: 6| Step: 4
Training loss: 0.23258490414489355
Validation loss: 2.415014199175431

Epoch: 6| Step: 5
Training loss: 0.25116399156411084
Validation loss: 2.4345474866992998

Epoch: 6| Step: 6
Training loss: 0.2930102255390922
Validation loss: 2.4777416795202574

Epoch: 6| Step: 7
Training loss: 0.28414747704505666
Validation loss: 2.4575808534290577

Epoch: 6| Step: 8
Training loss: 0.17834186486383705
Validation loss: 2.461153629342215

Epoch: 6| Step: 9
Training loss: 0.26652271376322423
Validation loss: 2.43988591460007

Epoch: 6| Step: 10
Training loss: 0.1995349133005125
Validation loss: 2.476458661869654

Epoch: 6| Step: 11
Training loss: 0.22467665286667493
Validation loss: 2.4236836856869775

Epoch: 6| Step: 12
Training loss: 0.39585499536904584
Validation loss: 2.430820245486478

Epoch: 6| Step: 13
Training loss: 0.4291144972020689
Validation loss: 2.4040457776830357

Epoch: 457| Step: 0
Training loss: 0.3109024579224001
Validation loss: 2.4380392188617512

Epoch: 6| Step: 1
Training loss: 0.23430458441576837
Validation loss: 2.40172117156128

Epoch: 6| Step: 2
Training loss: 0.1933510711119888
Validation loss: 2.4072160905595554

Epoch: 6| Step: 3
Training loss: 0.30178888401686965
Validation loss: 2.398418596791847

Epoch: 6| Step: 4
Training loss: 0.21028523794160597
Validation loss: 2.393228696764403

Epoch: 6| Step: 5
Training loss: 0.2869783738408615
Validation loss: 2.439138488096664

Epoch: 6| Step: 6
Training loss: 0.3673649825657516
Validation loss: 2.4104078200809838

Epoch: 6| Step: 7
Training loss: 0.20765189044988813
Validation loss: 2.445825802762325

Epoch: 6| Step: 8
Training loss: 0.2478467779997872
Validation loss: 2.4609288806832703

Epoch: 6| Step: 9
Training loss: 0.17926539724450716
Validation loss: 2.474727277872579

Epoch: 6| Step: 10
Training loss: 0.2529007884126036
Validation loss: 2.4844552943779328

Epoch: 6| Step: 11
Training loss: 0.21250585029066096
Validation loss: 2.486425932753152

Epoch: 6| Step: 12
Training loss: 0.13405178198396525
Validation loss: 2.47597174810658

Epoch: 6| Step: 13
Training loss: 0.1507160950256218
Validation loss: 2.4769384584604395

Epoch: 458| Step: 0
Training loss: 0.43682182064747455
Validation loss: 2.507721750143596

Epoch: 6| Step: 1
Training loss: 0.21757396406376145
Validation loss: 2.4338539000418815

Epoch: 6| Step: 2
Training loss: 0.23602694243413752
Validation loss: 2.4581463553052556

Epoch: 6| Step: 3
Training loss: 0.19679127684078124
Validation loss: 2.451796014472067

Epoch: 6| Step: 4
Training loss: 0.09185981114850594
Validation loss: 2.475379354565093

Epoch: 6| Step: 5
Training loss: 0.15124471077852858
Validation loss: 2.4888777592637705

Epoch: 6| Step: 6
Training loss: 0.3553766613403839
Validation loss: 2.452980707660473

Epoch: 6| Step: 7
Training loss: 0.18077370692995964
Validation loss: 2.4750237459725977

Epoch: 6| Step: 8
Training loss: 0.23717231355080337
Validation loss: 2.4729615365346738

Epoch: 6| Step: 9
Training loss: 0.21908822478614512
Validation loss: 2.4376587954053917

Epoch: 6| Step: 10
Training loss: 0.11905606974611581
Validation loss: 2.463141802881419

Epoch: 6| Step: 11
Training loss: 0.24347982625060574
Validation loss: 2.4480577967971797

Epoch: 6| Step: 12
Training loss: 0.14245087026594344
Validation loss: 2.4919258294305298

Epoch: 6| Step: 13
Training loss: 0.0927103631283153
Validation loss: 2.4548720751237214

Epoch: 459| Step: 0
Training loss: 0.2525631225642456
Validation loss: 2.474049703511536

Epoch: 6| Step: 1
Training loss: 0.17070253315349435
Validation loss: 2.484050913015063

Epoch: 6| Step: 2
Training loss: 0.23264928319272543
Validation loss: 2.4330186749223732

Epoch: 6| Step: 3
Training loss: 0.2988556992518229
Validation loss: 2.4713977381241197

Epoch: 6| Step: 4
Training loss: 0.2695197780213301
Validation loss: 2.4317039898261923

Epoch: 6| Step: 5
Training loss: 0.3235516406648882
Validation loss: 2.421360977779437

Epoch: 6| Step: 6
Training loss: 0.1292508749369627
Validation loss: 2.431372847335905

Epoch: 6| Step: 7
Training loss: 0.2821711713559373
Validation loss: 2.408455351474842

Epoch: 6| Step: 8
Training loss: 0.13551180657982706
Validation loss: 2.3910816026547623

Epoch: 6| Step: 9
Training loss: 0.21078563450918292
Validation loss: 2.4068918766387997

Epoch: 6| Step: 10
Training loss: 0.25516535273781954
Validation loss: 2.429315268455599

Epoch: 6| Step: 11
Training loss: 0.1952221470698009
Validation loss: 2.4639052922005478

Epoch: 6| Step: 12
Training loss: 0.22000637463795067
Validation loss: 2.445570890316223

Epoch: 6| Step: 13
Training loss: 0.2978757004259385
Validation loss: 2.479599636121191

Epoch: 460| Step: 0
Training loss: 0.1842552806622883
Validation loss: 2.4540897560056796

Epoch: 6| Step: 1
Training loss: 0.21272970819975615
Validation loss: 2.50129503117372

Epoch: 6| Step: 2
Training loss: 0.3641174291340267
Validation loss: 2.4815135328705487

Epoch: 6| Step: 3
Training loss: 0.28503108216916373
Validation loss: 2.491690073600604

Epoch: 6| Step: 4
Training loss: 0.147768905342255
Validation loss: 2.4920949631669806

Epoch: 6| Step: 5
Training loss: 0.12648507181061666
Validation loss: 2.4778745739190917

Epoch: 6| Step: 6
Training loss: 0.26659535830478437
Validation loss: 2.4812215866504057

Epoch: 6| Step: 7
Training loss: 0.2641766414328531
Validation loss: 2.4929998550440993

Epoch: 6| Step: 8
Training loss: 0.16618348218753015
Validation loss: 2.4606159808168595

Epoch: 6| Step: 9
Training loss: 0.2978716233798864
Validation loss: 2.5085725672328563

Epoch: 6| Step: 10
Training loss: 0.366646672736864
Validation loss: 2.4927388929868153

Epoch: 6| Step: 11
Training loss: 0.1437824479571164
Validation loss: 2.4926136069313394

Epoch: 6| Step: 12
Training loss: 0.14671382735325444
Validation loss: 2.4851371641877766

Epoch: 6| Step: 13
Training loss: 0.24377054011782037
Validation loss: 2.4914924839802315

Epoch: 461| Step: 0
Training loss: 0.21023747175722154
Validation loss: 2.469597627988405

Epoch: 6| Step: 1
Training loss: 0.1984098411417715
Validation loss: 2.4702110510305455

Epoch: 6| Step: 2
Training loss: 0.2834153794023203
Validation loss: 2.4623992833945914

Epoch: 6| Step: 3
Training loss: 0.15919117213283404
Validation loss: 2.4713799603983584

Epoch: 6| Step: 4
Training loss: 0.28713717942319805
Validation loss: 2.4614976564779267

Epoch: 6| Step: 5
Training loss: 0.17183157523988196
Validation loss: 2.478523602891363

Epoch: 6| Step: 6
Training loss: 0.20192267300841346
Validation loss: 2.433099765864786

Epoch: 6| Step: 7
Training loss: 0.24652147210404107
Validation loss: 2.507005196319663

Epoch: 6| Step: 8
Training loss: 0.19402046092272868
Validation loss: 2.4924646316637045

Epoch: 6| Step: 9
Training loss: 0.16924639427606875
Validation loss: 2.4879698807501005

Epoch: 6| Step: 10
Training loss: 0.34927675205012715
Validation loss: 2.5200294535618717

Epoch: 6| Step: 11
Training loss: 0.1833821457034219
Validation loss: 2.485511225866287

Epoch: 6| Step: 12
Training loss: 0.3174635094976974
Validation loss: 2.5095262820252118

Epoch: 6| Step: 13
Training loss: 0.12371729816048369
Validation loss: 2.5183740737398463

Epoch: 462| Step: 0
Training loss: 0.21225098226317707
Validation loss: 2.5034880188447795

Epoch: 6| Step: 1
Training loss: 0.22576065233514842
Validation loss: 2.476545607151863

Epoch: 6| Step: 2
Training loss: 0.17708289038845837
Validation loss: 2.4722099830066693

Epoch: 6| Step: 3
Training loss: 0.1763588950910314
Validation loss: 2.464346696501674

Epoch: 6| Step: 4
Training loss: 0.3046211268194803
Validation loss: 2.4690986336249474

Epoch: 6| Step: 5
Training loss: 0.2594662138254328
Validation loss: 2.468265127051832

Epoch: 6| Step: 6
Training loss: 0.32021566415898617
Validation loss: 2.4541211493299944

Epoch: 6| Step: 7
Training loss: 0.24056116223378318
Validation loss: 2.456284573611816

Epoch: 6| Step: 8
Training loss: 0.30432258663826606
Validation loss: 2.456879348659419

Epoch: 6| Step: 9
Training loss: 0.1872529945999898
Validation loss: 2.4745248108226483

Epoch: 6| Step: 10
Training loss: 0.28189098642695154
Validation loss: 2.4842736286788827

Epoch: 6| Step: 11
Training loss: 0.1395594306545078
Validation loss: 2.4882955281736647

Epoch: 6| Step: 12
Training loss: 0.19100007928102655
Validation loss: 2.487090686388815

Epoch: 6| Step: 13
Training loss: 0.14827069522326314
Validation loss: 2.504416021298033

Epoch: 463| Step: 0
Training loss: 0.16800434267726702
Validation loss: 2.4933169643365334

Epoch: 6| Step: 1
Training loss: 0.20992380745398995
Validation loss: 2.483229501211761

Epoch: 6| Step: 2
Training loss: 0.2934091436885563
Validation loss: 2.497648675676734

Epoch: 6| Step: 3
Training loss: 0.11599216785971588
Validation loss: 2.4684123749072215

Epoch: 6| Step: 4
Training loss: 0.2934958992351533
Validation loss: 2.494489658499032

Epoch: 6| Step: 5
Training loss: 0.2435635269139475
Validation loss: 2.5018370677496065

Epoch: 6| Step: 6
Training loss: 0.13594916227892115
Validation loss: 2.4717661702853357

Epoch: 6| Step: 7
Training loss: 0.18961447304566645
Validation loss: 2.4787036473371056

Epoch: 6| Step: 8
Training loss: 0.3327914343242822
Validation loss: 2.4851765839928706

Epoch: 6| Step: 9
Training loss: 0.22407798934346154
Validation loss: 2.463940295731694

Epoch: 6| Step: 10
Training loss: 0.21098351859632444
Validation loss: 2.495216073204923

Epoch: 6| Step: 11
Training loss: 0.16307242560234034
Validation loss: 2.4918537814616455

Epoch: 6| Step: 12
Training loss: 0.19982496291100224
Validation loss: 2.4773258218009726

Epoch: 6| Step: 13
Training loss: 0.1591648141664115
Validation loss: 2.485783271792725

Epoch: 464| Step: 0
Training loss: 0.20867412033215552
Validation loss: 2.535000301021351

Epoch: 6| Step: 1
Training loss: 0.189653585503555
Validation loss: 2.4924527512938264

Epoch: 6| Step: 2
Training loss: 0.13086824244730486
Validation loss: 2.5035127797078434

Epoch: 6| Step: 3
Training loss: 0.16298058813371544
Validation loss: 2.5365418958184955

Epoch: 6| Step: 4
Training loss: 0.1619959514871449
Validation loss: 2.520609941773578

Epoch: 6| Step: 5
Training loss: 0.13426165402388018
Validation loss: 2.5116150598473097

Epoch: 6| Step: 6
Training loss: 0.29657179004922857
Validation loss: 2.481320790042769

Epoch: 6| Step: 7
Training loss: 0.2661188107537259
Validation loss: 2.5127953076796454

Epoch: 6| Step: 8
Training loss: 0.25994284758188635
Validation loss: 2.4656682383256534

Epoch: 6| Step: 9
Training loss: 0.17193706432247116
Validation loss: 2.4515836884776974

Epoch: 6| Step: 10
Training loss: 0.17339525545985604
Validation loss: 2.468307222800701

Epoch: 6| Step: 11
Training loss: 0.2175856323590686
Validation loss: 2.474670659586047

Epoch: 6| Step: 12
Training loss: 0.2123617111452542
Validation loss: 2.4799587101001577

Epoch: 6| Step: 13
Training loss: 0.45057981211612363
Validation loss: 2.4868971130067345

Epoch: 465| Step: 0
Training loss: 0.3379405431312341
Validation loss: 2.4922917998983833

Epoch: 6| Step: 1
Training loss: 0.2502721259123097
Validation loss: 2.5359770140510167

Epoch: 6| Step: 2
Training loss: 0.15285005554579428
Validation loss: 2.481592834085519

Epoch: 6| Step: 3
Training loss: 0.1900294082871031
Validation loss: 2.479932738198152

Epoch: 6| Step: 4
Training loss: 0.2119029257524439
Validation loss: 2.5079961906308403

Epoch: 6| Step: 5
Training loss: 0.25174222295656856
Validation loss: 2.5155068300150774

Epoch: 6| Step: 6
Training loss: 0.26002740218115905
Validation loss: 2.5245424436610358

Epoch: 6| Step: 7
Training loss: 0.20648984473868331
Validation loss: 2.525191744449687

Epoch: 6| Step: 8
Training loss: 0.2405964131528096
Validation loss: 2.4818985625130057

Epoch: 6| Step: 9
Training loss: 0.24488717948316627
Validation loss: 2.439607599371255

Epoch: 6| Step: 10
Training loss: 0.15962722678487135
Validation loss: 2.481482968549909

Epoch: 6| Step: 11
Training loss: 0.27321154931868125
Validation loss: 2.458892406909799

Epoch: 6| Step: 12
Training loss: 0.19062308247961954
Validation loss: 2.462848761437603

Epoch: 6| Step: 13
Training loss: 0.20682277619558762
Validation loss: 2.4339945491794754

Epoch: 466| Step: 0
Training loss: 0.2034166333268714
Validation loss: 2.4540796417791233

Epoch: 6| Step: 1
Training loss: 0.22995971780449956
Validation loss: 2.4575168137588617

Epoch: 6| Step: 2
Training loss: 0.15624424208522322
Validation loss: 2.4855550382153124

Epoch: 6| Step: 3
Training loss: 0.1703626025286979
Validation loss: 2.4619277037557183

Epoch: 6| Step: 4
Training loss: 0.10182986920694916
Validation loss: 2.4871832352131733

Epoch: 6| Step: 5
Training loss: 0.22363063028262017
Validation loss: 2.484132648229629

Epoch: 6| Step: 6
Training loss: 0.1700983282293436
Validation loss: 2.509010793050981

Epoch: 6| Step: 7
Training loss: 0.18554728658530112
Validation loss: 2.5029048768250504

Epoch: 6| Step: 8
Training loss: 0.18176189599204073
Validation loss: 2.4819175870424415

Epoch: 6| Step: 9
Training loss: 0.27872848027816244
Validation loss: 2.4852853001067916

Epoch: 6| Step: 10
Training loss: 0.30666681651616234
Validation loss: 2.472363824035597

Epoch: 6| Step: 11
Training loss: 0.18058396703266807
Validation loss: 2.4529340931128227

Epoch: 6| Step: 12
Training loss: 0.31663449614433775
Validation loss: 2.4989512951183133

Epoch: 6| Step: 13
Training loss: 0.34518955898896814
Validation loss: 2.441691342351313

Epoch: 467| Step: 0
Training loss: 0.16740639385824627
Validation loss: 2.441307341116408

Epoch: 6| Step: 1
Training loss: 0.17649439156364113
Validation loss: 2.449412948211065

Epoch: 6| Step: 2
Training loss: 0.11946739270618932
Validation loss: 2.4530001226373077

Epoch: 6| Step: 3
Training loss: 0.1831165259519513
Validation loss: 2.4418791754649014

Epoch: 6| Step: 4
Training loss: 0.2782296819526207
Validation loss: 2.467433159749669

Epoch: 6| Step: 5
Training loss: 0.12203673854700903
Validation loss: 2.4363205156627363

Epoch: 6| Step: 6
Training loss: 0.23108073786636302
Validation loss: 2.4767702682605273

Epoch: 6| Step: 7
Training loss: 0.20455482565601216
Validation loss: 2.460209987577653

Epoch: 6| Step: 8
Training loss: 0.15319616916667342
Validation loss: 2.450838596153559

Epoch: 6| Step: 9
Training loss: 0.2788856920845481
Validation loss: 2.5050911244806042

Epoch: 6| Step: 10
Training loss: 0.3497810581560852
Validation loss: 2.451100195360522

Epoch: 6| Step: 11
Training loss: 0.2041133530418993
Validation loss: 2.463549411385753

Epoch: 6| Step: 12
Training loss: 0.2807388694421672
Validation loss: 2.453737757029372

Epoch: 6| Step: 13
Training loss: 0.215894919225808
Validation loss: 2.4666435889012877

Epoch: 468| Step: 0
Training loss: 0.1738521312895799
Validation loss: 2.4616131359173674

Epoch: 6| Step: 1
Training loss: 0.2114582521378936
Validation loss: 2.464949712878718

Epoch: 6| Step: 2
Training loss: 0.25275354622202917
Validation loss: 2.433905570907686

Epoch: 6| Step: 3
Training loss: 0.2760866851204975
Validation loss: 2.461678299461029

Epoch: 6| Step: 4
Training loss: 0.1356882564522713
Validation loss: 2.4932139710407037

Epoch: 6| Step: 5
Training loss: 0.11857913549185933
Validation loss: 2.4724472116426943

Epoch: 6| Step: 6
Training loss: 0.19154891711147767
Validation loss: 2.476187008328823

Epoch: 6| Step: 7
Training loss: 0.2829527570353559
Validation loss: 2.489594935807487

Epoch: 6| Step: 8
Training loss: 0.26210802933508104
Validation loss: 2.48972427525959

Epoch: 6| Step: 9
Training loss: 0.1597094467370428
Validation loss: 2.4794787126693327

Epoch: 6| Step: 10
Training loss: 0.30167009875064615
Validation loss: 2.500517909435241

Epoch: 6| Step: 11
Training loss: 0.2392736935697153
Validation loss: 2.4883918085345873

Epoch: 6| Step: 12
Training loss: 0.14506908815882
Validation loss: 2.511814354513131

Epoch: 6| Step: 13
Training loss: 0.20453898997338504
Validation loss: 2.462106609638218

Epoch: 469| Step: 0
Training loss: 0.1801728555912166
Validation loss: 2.4786820227946658

Epoch: 6| Step: 1
Training loss: 0.23967690644608688
Validation loss: 2.4722854970562267

Epoch: 6| Step: 2
Training loss: 0.12552259399107854
Validation loss: 2.4596954091539014

Epoch: 6| Step: 3
Training loss: 0.28957667886283067
Validation loss: 2.466998757332195

Epoch: 6| Step: 4
Training loss: 0.26265826903593475
Validation loss: 2.4466864492210045

Epoch: 6| Step: 5
Training loss: 0.2939472135057793
Validation loss: 2.4547876644084057

Epoch: 6| Step: 6
Training loss: 0.29917086474564397
Validation loss: 2.458630498156865

Epoch: 6| Step: 7
Training loss: 0.3215419852086427
Validation loss: 2.4387648692255155

Epoch: 6| Step: 8
Training loss: 0.19249662914978477
Validation loss: 2.434433088057538

Epoch: 6| Step: 9
Training loss: 0.24071568446093566
Validation loss: 2.449704042418263

Epoch: 6| Step: 10
Training loss: 0.1986559979045781
Validation loss: 2.457370230129192

Epoch: 6| Step: 11
Training loss: 0.15362853758388298
Validation loss: 2.4589449220989645

Epoch: 6| Step: 12
Training loss: 0.24361312336497198
Validation loss: 2.463467265895247

Epoch: 6| Step: 13
Training loss: 0.2601225702290522
Validation loss: 2.4851509915708183

Epoch: 470| Step: 0
Training loss: 0.23635947594886672
Validation loss: 2.5111140026117384

Epoch: 6| Step: 1
Training loss: 0.3402794642741824
Validation loss: 2.4980561800641214

Epoch: 6| Step: 2
Training loss: 0.11608113324288816
Validation loss: 2.4914580450389856

Epoch: 6| Step: 3
Training loss: 0.16633981018625063
Validation loss: 2.490937244326868

Epoch: 6| Step: 4
Training loss: 0.251706320362812
Validation loss: 2.47361467151723

Epoch: 6| Step: 5
Training loss: 0.14278497453617015
Validation loss: 2.462126730452249

Epoch: 6| Step: 6
Training loss: 0.12654745872034168
Validation loss: 2.438715476830117

Epoch: 6| Step: 7
Training loss: 0.30566286811960885
Validation loss: 2.4285603873123467

Epoch: 6| Step: 8
Training loss: 0.15599311931807702
Validation loss: 2.3692379176153477

Epoch: 6| Step: 9
Training loss: 0.16996007248823403
Validation loss: 2.3720054151678003

Epoch: 6| Step: 10
Training loss: 0.39767647037921333
Validation loss: 2.390399702140574

Epoch: 6| Step: 11
Training loss: 0.22979352930120467
Validation loss: 2.3926717720179678

Epoch: 6| Step: 12
Training loss: 0.137938811714234
Validation loss: 2.3804801943092926

Epoch: 6| Step: 13
Training loss: 0.13787951222019715
Validation loss: 2.3924223333503645

Epoch: 471| Step: 0
Training loss: 0.21118204634963736
Validation loss: 2.402791226905166

Epoch: 6| Step: 1
Training loss: 0.2840933914509606
Validation loss: 2.404889497085664

Epoch: 6| Step: 2
Training loss: 0.2550701753507946
Validation loss: 2.4208367553260897

Epoch: 6| Step: 3
Training loss: 0.1755707858361921
Validation loss: 2.4260289542939013

Epoch: 6| Step: 4
Training loss: 0.1725255834225501
Validation loss: 2.432867755628974

Epoch: 6| Step: 5
Training loss: 0.28742016948620097
Validation loss: 2.41976404354447

Epoch: 6| Step: 6
Training loss: 0.35537898848177624
Validation loss: 2.4120556950309786

Epoch: 6| Step: 7
Training loss: 0.22046151059415278
Validation loss: 2.431458630789188

Epoch: 6| Step: 8
Training loss: 0.37448559686112304
Validation loss: 2.4194467873687127

Epoch: 6| Step: 9
Training loss: 0.2569808841045395
Validation loss: 2.4172784125081823

Epoch: 6| Step: 10
Training loss: 0.32047984938648094
Validation loss: 2.446833173118027

Epoch: 6| Step: 11
Training loss: 0.15521697451284716
Validation loss: 2.4485730054294472

Epoch: 6| Step: 12
Training loss: 0.29384423732828724
Validation loss: 2.473000481779719

Epoch: 6| Step: 13
Training loss: 0.22598552405837968
Validation loss: 2.4496061577332995

Epoch: 472| Step: 0
Training loss: 0.1377660623690358
Validation loss: 2.4934948076178287

Epoch: 6| Step: 1
Training loss: 0.1408090975841796
Validation loss: 2.5239166756740343

Epoch: 6| Step: 2
Training loss: 0.2768044668648248
Validation loss: 2.4762502426656954

Epoch: 6| Step: 3
Training loss: 0.37394884924519645
Validation loss: 2.509236116677657

Epoch: 6| Step: 4
Training loss: 0.26366353904827916
Validation loss: 2.493047148780551

Epoch: 6| Step: 5
Training loss: 0.15752965725481574
Validation loss: 2.4619775426384574

Epoch: 6| Step: 6
Training loss: 0.2433701373517234
Validation loss: 2.4386471682719986

Epoch: 6| Step: 7
Training loss: 0.2471824888910209
Validation loss: 2.413830220926025

Epoch: 6| Step: 8
Training loss: 0.16923422172947294
Validation loss: 2.4629931272464676

Epoch: 6| Step: 9
Training loss: 0.2842035054191666
Validation loss: 2.4108666617013275

Epoch: 6| Step: 10
Training loss: 0.37180585298481583
Validation loss: 2.4317839243767425

Epoch: 6| Step: 11
Training loss: 0.32907342082972524
Validation loss: 2.428845716662617

Epoch: 6| Step: 12
Training loss: 0.19734262153502188
Validation loss: 2.442299822821981

Epoch: 6| Step: 13
Training loss: 0.10053066475709437
Validation loss: 2.4578834199850754

Epoch: 473| Step: 0
Training loss: 0.17778867374207857
Validation loss: 2.4597964322396875

Epoch: 6| Step: 1
Training loss: 0.23647706406441926
Validation loss: 2.45522686330752

Epoch: 6| Step: 2
Training loss: 0.3163864576954568
Validation loss: 2.4998303796795196

Epoch: 6| Step: 3
Training loss: 0.22759181544895785
Validation loss: 2.4365287130824274

Epoch: 6| Step: 4
Training loss: 0.2249271632556994
Validation loss: 2.450669832893435

Epoch: 6| Step: 5
Training loss: 0.1589654873775056
Validation loss: 2.433573898929472

Epoch: 6| Step: 6
Training loss: 0.25514193404169844
Validation loss: 2.4113344507833183

Epoch: 6| Step: 7
Training loss: 0.27135605832768867
Validation loss: 2.4046716029261455

Epoch: 6| Step: 8
Training loss: 0.26121190085332546
Validation loss: 2.3900844529336704

Epoch: 6| Step: 9
Training loss: 0.23545180754027484
Validation loss: 2.395704089544661

Epoch: 6| Step: 10
Training loss: 0.1716743566056457
Validation loss: 2.3992853328596047

Epoch: 6| Step: 11
Training loss: 0.19477180024359708
Validation loss: 2.408698271695822

Epoch: 6| Step: 12
Training loss: 0.20746448459943587
Validation loss: 2.442195240664278

Epoch: 6| Step: 13
Training loss: 0.3576218092748391
Validation loss: 2.413062204632102

Epoch: 474| Step: 0
Training loss: 0.23042148170015983
Validation loss: 2.477810549185532

Epoch: 6| Step: 1
Training loss: 0.18415718669319764
Validation loss: 2.4277968729410424

Epoch: 6| Step: 2
Training loss: 0.11592159795824412
Validation loss: 2.4816471643167164

Epoch: 6| Step: 3
Training loss: 0.2838444256058947
Validation loss: 2.484714169399608

Epoch: 6| Step: 4
Training loss: 0.27895911006995033
Validation loss: 2.4502812530714286

Epoch: 6| Step: 5
Training loss: 0.22279602816502586
Validation loss: 2.477981781277228

Epoch: 6| Step: 6
Training loss: 0.17009230540137127
Validation loss: 2.4880584108568575

Epoch: 6| Step: 7
Training loss: 0.17725703308143936
Validation loss: 2.4837368515562295

Epoch: 6| Step: 8
Training loss: 0.2974525906349156
Validation loss: 2.485506819060874

Epoch: 6| Step: 9
Training loss: 0.27603000790189036
Validation loss: 2.484664302674322

Epoch: 6| Step: 10
Training loss: 0.2191075655365954
Validation loss: 2.4925823199170374

Epoch: 6| Step: 11
Training loss: 0.1623877123620406
Validation loss: 2.4888570950548026

Epoch: 6| Step: 12
Training loss: 0.2250563941589197
Validation loss: 2.490413672667778

Epoch: 6| Step: 13
Training loss: 0.13989689206167494
Validation loss: 2.455955302003863

Epoch: 475| Step: 0
Training loss: 0.20290578420513017
Validation loss: 2.4302177640595155

Epoch: 6| Step: 1
Training loss: 0.1474279910033387
Validation loss: 2.473228335662589

Epoch: 6| Step: 2
Training loss: 0.18961124114323386
Validation loss: 2.443115829740052

Epoch: 6| Step: 3
Training loss: 0.2831506614760861
Validation loss: 2.4554319474036523

Epoch: 6| Step: 4
Training loss: 0.3091494711149388
Validation loss: 2.4342868231292942

Epoch: 6| Step: 5
Training loss: 0.20977407612461338
Validation loss: 2.4416629285852713

Epoch: 6| Step: 6
Training loss: 0.28759143867960785
Validation loss: 2.437251965797799

Epoch: 6| Step: 7
Training loss: 0.13023763962597315
Validation loss: 2.481950814544507

Epoch: 6| Step: 8
Training loss: 0.12675232779887777
Validation loss: 2.4997653502405495

Epoch: 6| Step: 9
Training loss: 0.23541626891521736
Validation loss: 2.486894390248523

Epoch: 6| Step: 10
Training loss: 0.16960151112941516
Validation loss: 2.499590724340392

Epoch: 6| Step: 11
Training loss: 0.1688849446042593
Validation loss: 2.487305703760357

Epoch: 6| Step: 12
Training loss: 0.25014433568522715
Validation loss: 2.4953936039216145

Epoch: 6| Step: 13
Training loss: 0.2935050759997565
Validation loss: 2.486649763578304

Epoch: 476| Step: 0
Training loss: 0.1131429938434632
Validation loss: 2.4657794915792963

Epoch: 6| Step: 1
Training loss: 0.13218092814132187
Validation loss: 2.4313695902907195

Epoch: 6| Step: 2
Training loss: 0.256066769708404
Validation loss: 2.4463258523024747

Epoch: 6| Step: 3
Training loss: 0.1442084186610282
Validation loss: 2.432585199443586

Epoch: 6| Step: 4
Training loss: 0.2495125996374418
Validation loss: 2.453534411576608

Epoch: 6| Step: 5
Training loss: 0.1628955712242114
Validation loss: 2.416146116943702

Epoch: 6| Step: 6
Training loss: 0.20493462401102874
Validation loss: 2.4179619697201264

Epoch: 6| Step: 7
Training loss: 0.21511734101605345
Validation loss: 2.44587516477071

Epoch: 6| Step: 8
Training loss: 0.19153497221210478
Validation loss: 2.4911640359776435

Epoch: 6| Step: 9
Training loss: 0.1948421632538452
Validation loss: 2.4606896935396305

Epoch: 6| Step: 10
Training loss: 0.4200840126889232
Validation loss: 2.479490586188354

Epoch: 6| Step: 11
Training loss: 0.23950517284783907
Validation loss: 2.472906574884864

Epoch: 6| Step: 12
Training loss: 0.10893770059314321
Validation loss: 2.4984229610171207

Epoch: 6| Step: 13
Training loss: 0.21925895950232127
Validation loss: 2.5170078001835465

Epoch: 477| Step: 0
Training loss: 0.20231054320757566
Validation loss: 2.5286369463399643

Epoch: 6| Step: 1
Training loss: 0.20831270215081615
Validation loss: 2.506320008726091

Epoch: 6| Step: 2
Training loss: 0.19426995503906308
Validation loss: 2.5220716599896584

Epoch: 6| Step: 3
Training loss: 0.27883100002064615
Validation loss: 2.5377415797703686

Epoch: 6| Step: 4
Training loss: 0.2245574393558175
Validation loss: 2.4906294190975187

Epoch: 6| Step: 5
Training loss: 0.30482364938262013
Validation loss: 2.5186968883990204

Epoch: 6| Step: 6
Training loss: 0.16001135389082788
Validation loss: 2.529035494091085

Epoch: 6| Step: 7
Training loss: 0.24135470256627933
Validation loss: 2.4994061615872307

Epoch: 6| Step: 8
Training loss: 0.13166975921482743
Validation loss: 2.468883245487897

Epoch: 6| Step: 9
Training loss: 0.2027735604286005
Validation loss: 2.487992069085213

Epoch: 6| Step: 10
Training loss: 0.24941709482236116
Validation loss: 2.479030006290992

Epoch: 6| Step: 11
Training loss: 0.1184557553794186
Validation loss: 2.483845150747746

Epoch: 6| Step: 12
Training loss: 0.2123216673124246
Validation loss: 2.481952096906352

Epoch: 6| Step: 13
Training loss: 0.11060407324774016
Validation loss: 2.506275101754545

Epoch: 478| Step: 0
Training loss: 0.15138175032918724
Validation loss: 2.480562596947534

Epoch: 6| Step: 1
Training loss: 0.215014701800807
Validation loss: 2.4664085372919446

Epoch: 6| Step: 2
Training loss: 0.2844969168472498
Validation loss: 2.4842451201841516

Epoch: 6| Step: 3
Training loss: 0.15396440878776055
Validation loss: 2.4959054127664695

Epoch: 6| Step: 4
Training loss: 0.19339696923278174
Validation loss: 2.4627622757135152

Epoch: 6| Step: 5
Training loss: 0.2641032046484367
Validation loss: 2.4510490009837946

Epoch: 6| Step: 6
Training loss: 0.1507768131255562
Validation loss: 2.457131429001672

Epoch: 6| Step: 7
Training loss: 0.20850318700083645
Validation loss: 2.455667174824394

Epoch: 6| Step: 8
Training loss: 0.24318273694744771
Validation loss: 2.4519035658898924

Epoch: 6| Step: 9
Training loss: 0.29112667806640485
Validation loss: 2.436093679587204

Epoch: 6| Step: 10
Training loss: 0.10805577597981067
Validation loss: 2.4224339353916013

Epoch: 6| Step: 11
Training loss: 0.4063531487902061
Validation loss: 2.424414767422963

Epoch: 6| Step: 12
Training loss: 0.14645134871429324
Validation loss: 2.484839172815701

Epoch: 6| Step: 13
Training loss: 0.08849270485994243
Validation loss: 2.4457554855454635

Epoch: 479| Step: 0
Training loss: 0.3109065917482222
Validation loss: 2.4700886949531324

Epoch: 6| Step: 1
Training loss: 0.19496321918158996
Validation loss: 2.5016055273798323

Epoch: 6| Step: 2
Training loss: 0.2939995370321132
Validation loss: 2.485954496131007

Epoch: 6| Step: 3
Training loss: 0.17455635332525649
Validation loss: 2.5375953159750333

Epoch: 6| Step: 4
Training loss: 0.2950075669247583
Validation loss: 2.5620381038791216

Epoch: 6| Step: 5
Training loss: 0.18335952427211516
Validation loss: 2.520349447137989

Epoch: 6| Step: 6
Training loss: 0.20021601314052465
Validation loss: 2.5312540096573777

Epoch: 6| Step: 7
Training loss: 0.21745860859668992
Validation loss: 2.5108897868322013

Epoch: 6| Step: 8
Training loss: 0.19696851583203948
Validation loss: 2.5055775126802438

Epoch: 6| Step: 9
Training loss: 0.2634456511760288
Validation loss: 2.481807592299844

Epoch: 6| Step: 10
Training loss: 0.18766175683650077
Validation loss: 2.458546379150164

Epoch: 6| Step: 11
Training loss: 0.19312275752521757
Validation loss: 2.471405432464257

Epoch: 6| Step: 12
Training loss: 0.2348343559741592
Validation loss: 2.4670575863416544

Epoch: 6| Step: 13
Training loss: 0.1459221094274389
Validation loss: 2.5053387826401874

Epoch: 480| Step: 0
Training loss: 0.29785104970418846
Validation loss: 2.492418091105811

Epoch: 6| Step: 1
Training loss: 0.16491044128192378
Validation loss: 2.4730022036579173

Epoch: 6| Step: 2
Training loss: 0.15703639382625076
Validation loss: 2.525320252056286

Epoch: 6| Step: 3
Training loss: 0.20320261792769004
Validation loss: 2.498178283882881

Epoch: 6| Step: 4
Training loss: 0.2841350087703438
Validation loss: 2.4971779061373685

Epoch: 6| Step: 5
Training loss: 0.2364000258348099
Validation loss: 2.5048126698943545

Epoch: 6| Step: 6
Training loss: 0.20670806202610847
Validation loss: 2.50425151564974

Epoch: 6| Step: 7
Training loss: 0.24127418831643369
Validation loss: 2.4931306199180034

Epoch: 6| Step: 8
Training loss: 0.20221548765236458
Validation loss: 2.5114604955164843

Epoch: 6| Step: 9
Training loss: 0.19754864436169384
Validation loss: 2.5110444853240734

Epoch: 6| Step: 10
Training loss: 0.19151972307076826
Validation loss: 2.4759462262064384

Epoch: 6| Step: 11
Training loss: 0.1444787239305368
Validation loss: 2.470975473764479

Epoch: 6| Step: 12
Training loss: 0.17958092638852938
Validation loss: 2.4342248346209314

Epoch: 6| Step: 13
Training loss: 0.32870482123448136
Validation loss: 2.446178703396971

Epoch: 481| Step: 0
Training loss: 0.17897533182437647
Validation loss: 2.4269874325302268

Epoch: 6| Step: 1
Training loss: 0.25522224070484545
Validation loss: 2.426767669272789

Epoch: 6| Step: 2
Training loss: 0.16997559016302424
Validation loss: 2.428541680571139

Epoch: 6| Step: 3
Training loss: 0.16084178884009884
Validation loss: 2.411543144825966

Epoch: 6| Step: 4
Training loss: 0.15498236599141285
Validation loss: 2.4275511997900137

Epoch: 6| Step: 5
Training loss: 0.25313493508986346
Validation loss: 2.4568156282698617

Epoch: 6| Step: 6
Training loss: 0.22211983966360999
Validation loss: 2.430734918854656

Epoch: 6| Step: 7
Training loss: 0.26494249849132984
Validation loss: 2.429882339163656

Epoch: 6| Step: 8
Training loss: 0.27735460287001695
Validation loss: 2.426799107045053

Epoch: 6| Step: 9
Training loss: 0.235993155805502
Validation loss: 2.455930992522556

Epoch: 6| Step: 10
Training loss: 0.20032050707401367
Validation loss: 2.4667127310063774

Epoch: 6| Step: 11
Training loss: 0.1763871083462784
Validation loss: 2.456196837017029

Epoch: 6| Step: 12
Training loss: 0.1223394022031408
Validation loss: 2.452554396949635

Epoch: 6| Step: 13
Training loss: 0.21627101184217928
Validation loss: 2.4841575163618623

Epoch: 482| Step: 0
Training loss: 0.15987395785128514
Validation loss: 2.4807271853612427

Epoch: 6| Step: 1
Training loss: 0.08683444512629683
Validation loss: 2.526759657685827

Epoch: 6| Step: 2
Training loss: 0.1571685257412709
Validation loss: 2.497165110373531

Epoch: 6| Step: 3
Training loss: 0.23772315032364555
Validation loss: 2.5055096287999676

Epoch: 6| Step: 4
Training loss: 0.31823126432702475
Validation loss: 2.520771551294628

Epoch: 6| Step: 5
Training loss: 0.2641520613524751
Validation loss: 2.50127121487044

Epoch: 6| Step: 6
Training loss: 0.2817512125786292
Validation loss: 2.5048913788230713

Epoch: 6| Step: 7
Training loss: 0.1863835194455136
Validation loss: 2.4851838204657195

Epoch: 6| Step: 8
Training loss: 0.10411049749023177
Validation loss: 2.4590045140638623

Epoch: 6| Step: 9
Training loss: 0.11206589895860461
Validation loss: 2.472643756055673

Epoch: 6| Step: 10
Training loss: 0.1543006896501112
Validation loss: 2.432032289610161

Epoch: 6| Step: 11
Training loss: 0.16026467630574728
Validation loss: 2.4148560666012417

Epoch: 6| Step: 12
Training loss: 0.3230233733958822
Validation loss: 2.4341870193812114

Epoch: 6| Step: 13
Training loss: 0.2803361270987778
Validation loss: 2.417434990176186

Epoch: 483| Step: 0
Training loss: 0.16364046719537195
Validation loss: 2.4358229056688563

Epoch: 6| Step: 1
Training loss: 0.13409969716340134
Validation loss: 2.435275127583278

Epoch: 6| Step: 2
Training loss: 0.32434938855208395
Validation loss: 2.4100204628697024

Epoch: 6| Step: 3
Training loss: 0.18759872896919375
Validation loss: 2.426994784406697

Epoch: 6| Step: 4
Training loss: 0.10290346336356614
Validation loss: 2.4316646594013585

Epoch: 6| Step: 5
Training loss: 0.1827645752517832
Validation loss: 2.475234057132841

Epoch: 6| Step: 6
Training loss: 0.25454094127754195
Validation loss: 2.4790838208259878

Epoch: 6| Step: 7
Training loss: 0.3462510588867302
Validation loss: 2.490169077464915

Epoch: 6| Step: 8
Training loss: 0.1904225763802724
Validation loss: 2.4526155474599487

Epoch: 6| Step: 9
Training loss: 0.13822453839167548
Validation loss: 2.480402930790355

Epoch: 6| Step: 10
Training loss: 0.2549193198999269
Validation loss: 2.441071917737053

Epoch: 6| Step: 11
Training loss: 0.2092987619210308
Validation loss: 2.474029393538342

Epoch: 6| Step: 12
Training loss: 0.18236240422296462
Validation loss: 2.4655004142474577

Epoch: 6| Step: 13
Training loss: 0.10886283578377402
Validation loss: 2.44371715752595

Epoch: 484| Step: 0
Training loss: 0.13390654953352232
Validation loss: 2.4991134373897608

Epoch: 6| Step: 1
Training loss: 0.17813345362028124
Validation loss: 2.474317220272639

Epoch: 6| Step: 2
Training loss: 0.19465031905607427
Validation loss: 2.4892792473319214

Epoch: 6| Step: 3
Training loss: 0.25059300365876785
Validation loss: 2.442939968414373

Epoch: 6| Step: 4
Training loss: 0.17812363473469384
Validation loss: 2.482720967096818

Epoch: 6| Step: 5
Training loss: 0.18007602359431027
Validation loss: 2.468238815026568

Epoch: 6| Step: 6
Training loss: 0.24905087188992364
Validation loss: 2.458870741591321

Epoch: 6| Step: 7
Training loss: 0.2601504666026394
Validation loss: 2.4481460596462354

Epoch: 6| Step: 8
Training loss: 0.3160811979825295
Validation loss: 2.523134120436249

Epoch: 6| Step: 9
Training loss: 0.09952509343765259
Validation loss: 2.4873387639468922

Epoch: 6| Step: 10
Training loss: 0.2135081129151895
Validation loss: 2.4996897545962558

Epoch: 6| Step: 11
Training loss: 0.14523853757740293
Validation loss: 2.4990419356845925

Epoch: 6| Step: 12
Training loss: 0.19581811309742045
Validation loss: 2.478060419611644

Epoch: 6| Step: 13
Training loss: 0.1384750836916194
Validation loss: 2.4180765857015936

Epoch: 485| Step: 0
Training loss: 0.24072271815177324
Validation loss: 2.478442728453003

Epoch: 6| Step: 1
Training loss: 0.13073070805110795
Validation loss: 2.4073805617508013

Epoch: 6| Step: 2
Training loss: 0.210866421627361
Validation loss: 2.4563043027200937

Epoch: 6| Step: 3
Training loss: 0.2012035011690283
Validation loss: 2.45601103625681

Epoch: 6| Step: 4
Training loss: 0.14616980154135767
Validation loss: 2.4397207965319176

Epoch: 6| Step: 5
Training loss: 0.2121889994123064
Validation loss: 2.4530279593512465

Epoch: 6| Step: 6
Training loss: 0.08506298239999997
Validation loss: 2.441051187008541

Epoch: 6| Step: 7
Training loss: 0.23099412680669265
Validation loss: 2.4500192943647856

Epoch: 6| Step: 8
Training loss: 0.181969949117277
Validation loss: 2.4341389969925444

Epoch: 6| Step: 9
Training loss: 0.3037693176092185
Validation loss: 2.455383738605582

Epoch: 6| Step: 10
Training loss: 0.3726704080959119
Validation loss: 2.455535797195308

Epoch: 6| Step: 11
Training loss: 0.16268516453925266
Validation loss: 2.4757107028441605

Epoch: 6| Step: 12
Training loss: 0.1290068161872292
Validation loss: 2.4826074907783404

Epoch: 6| Step: 13
Training loss: 0.13784267440121997
Validation loss: 2.4597934092886273

Epoch: 486| Step: 0
Training loss: 0.14519080891165978
Validation loss: 2.4881191251393986

Epoch: 6| Step: 1
Training loss: 0.19569930874269217
Validation loss: 2.496394599129831

Epoch: 6| Step: 2
Training loss: 0.1587898066692111
Validation loss: 2.506946102141748

Epoch: 6| Step: 3
Training loss: 0.17849518306227294
Validation loss: 2.4686431949929335

Epoch: 6| Step: 4
Training loss: 0.15851471674599232
Validation loss: 2.4527757839059956

Epoch: 6| Step: 5
Training loss: 0.16654174687923892
Validation loss: 2.4552452675377596

Epoch: 6| Step: 6
Training loss: 0.18057665385767382
Validation loss: 2.4914485692175665

Epoch: 6| Step: 7
Training loss: 0.21192371328853601
Validation loss: 2.4639493623163973

Epoch: 6| Step: 8
Training loss: 0.16994116662669148
Validation loss: 2.4476616622977927

Epoch: 6| Step: 9
Training loss: 0.24653199698564335
Validation loss: 2.4632074172296363

Epoch: 6| Step: 10
Training loss: 0.13943149147741213
Validation loss: 2.473129098945678

Epoch: 6| Step: 11
Training loss: 0.1544701231332661
Validation loss: 2.4624722696744628

Epoch: 6| Step: 12
Training loss: 0.315561084129888
Validation loss: 2.4966904976732605

Epoch: 6| Step: 13
Training loss: 0.3200720838479907
Validation loss: 2.467311494550472

Epoch: 487| Step: 0
Training loss: 0.21657618037688936
Validation loss: 2.4696247944003193

Epoch: 6| Step: 1
Training loss: 0.27473089315883875
Validation loss: 2.4516836226614593

Epoch: 6| Step: 2
Training loss: 0.1770364030658719
Validation loss: 2.4739940457230247

Epoch: 6| Step: 3
Training loss: 0.26139213336922335
Validation loss: 2.4829438939469757

Epoch: 6| Step: 4
Training loss: 0.2180785876577572
Validation loss: 2.480468152619176

Epoch: 6| Step: 5
Training loss: 0.26284361839903414
Validation loss: 2.4473117064260026

Epoch: 6| Step: 6
Training loss: 0.0902479863325218
Validation loss: 2.444464634468261

Epoch: 6| Step: 7
Training loss: 0.1270982866075513
Validation loss: 2.4472270516966095

Epoch: 6| Step: 8
Training loss: 0.19287248441943258
Validation loss: 2.450816989347433

Epoch: 6| Step: 9
Training loss: 0.11462178497241236
Validation loss: 2.4282515086440326

Epoch: 6| Step: 10
Training loss: 0.13008914419703785
Validation loss: 2.4913438738607208

Epoch: 6| Step: 11
Training loss: 0.15112521612185034
Validation loss: 2.459449256859718

Epoch: 6| Step: 12
Training loss: 0.26002409273173965
Validation loss: 2.4243238931224336

Epoch: 6| Step: 13
Training loss: 0.1628676226724412
Validation loss: 2.4496132146244047

Epoch: 488| Step: 0
Training loss: 0.13387426044311485
Validation loss: 2.4426744154653703

Epoch: 6| Step: 1
Training loss: 0.14116818109185655
Validation loss: 2.4537275420964217

Epoch: 6| Step: 2
Training loss: 0.13609603346694787
Validation loss: 2.4700626457372064

Epoch: 6| Step: 3
Training loss: 0.13310508895898204
Validation loss: 2.4477698273997035

Epoch: 6| Step: 4
Training loss: 0.2804884401598145
Validation loss: 2.4902427230202817

Epoch: 6| Step: 5
Training loss: 0.2366090948610424
Validation loss: 2.5029817621795063

Epoch: 6| Step: 6
Training loss: 0.10750463072373037
Validation loss: 2.482647031294597

Epoch: 6| Step: 7
Training loss: 0.20622494971709066
Validation loss: 2.476431768151325

Epoch: 6| Step: 8
Training loss: 0.2519418285114434
Validation loss: 2.4880660655232036

Epoch: 6| Step: 9
Training loss: 0.33501313806506283
Validation loss: 2.4857401745747265

Epoch: 6| Step: 10
Training loss: 0.19936550569200517
Validation loss: 2.4894848065765487

Epoch: 6| Step: 11
Training loss: 0.13011699731469892
Validation loss: 2.497088260494616

Epoch: 6| Step: 12
Training loss: 0.15817864546529384
Validation loss: 2.511020731883827

Epoch: 6| Step: 13
Training loss: 0.14217158060769713
Validation loss: 2.465794961044224

Epoch: 489| Step: 0
Training loss: 0.14552653275467212
Validation loss: 2.4786627996715795

Epoch: 6| Step: 1
Training loss: 0.2736661499975332
Validation loss: 2.5055291498693606

Epoch: 6| Step: 2
Training loss: 0.0868779895160039
Validation loss: 2.4679762704009973

Epoch: 6| Step: 3
Training loss: 0.2581408173007548
Validation loss: 2.4999640780093375

Epoch: 6| Step: 4
Training loss: 0.27208013140287424
Validation loss: 2.475783811856977

Epoch: 6| Step: 5
Training loss: 0.24820592992132448
Validation loss: 2.4608716896999154

Epoch: 6| Step: 6
Training loss: 0.10681624047898965
Validation loss: 2.4632525299179635

Epoch: 6| Step: 7
Training loss: 0.12605315844374165
Validation loss: 2.4696556144729485

Epoch: 6| Step: 8
Training loss: 0.18050672536166393
Validation loss: 2.453612038931371

Epoch: 6| Step: 9
Training loss: 0.09504726040592848
Validation loss: 2.458662444523578

Epoch: 6| Step: 10
Training loss: 0.13471034892829217
Validation loss: 2.4569365376218064

Epoch: 6| Step: 11
Training loss: 0.25368766178671975
Validation loss: 2.4632540215785967

Epoch: 6| Step: 12
Training loss: 0.13189784821551132
Validation loss: 2.442669549876347

Epoch: 6| Step: 13
Training loss: 0.10642982072702153
Validation loss: 2.4492530077842676

Epoch: 490| Step: 0
Training loss: 0.15551971002911047
Validation loss: 2.444224171799142

Epoch: 6| Step: 1
Training loss: 0.12447508852821071
Validation loss: 2.4472977888583123

Epoch: 6| Step: 2
Training loss: 0.17951521699792458
Validation loss: 2.41825423819163

Epoch: 6| Step: 3
Training loss: 0.3353162943580016
Validation loss: 2.46564297992309

Epoch: 6| Step: 4
Training loss: 0.15455726791184546
Validation loss: 2.466409553327272

Epoch: 6| Step: 5
Training loss: 0.106463198952644
Validation loss: 2.485638826956446

Epoch: 6| Step: 6
Training loss: 0.15130177591941538
Validation loss: 2.4401197257104954

Epoch: 6| Step: 7
Training loss: 0.121210292140756
Validation loss: 2.474832041181002

Epoch: 6| Step: 8
Training loss: 0.24883170881340447
Validation loss: 2.4713334491217984

Epoch: 6| Step: 9
Training loss: 0.13538338560944718
Validation loss: 2.4540600817788127

Epoch: 6| Step: 10
Training loss: 0.1692540319369605
Validation loss: 2.4612938782555758

Epoch: 6| Step: 11
Training loss: 0.15612088471624705
Validation loss: 2.4626383169841293

Epoch: 6| Step: 12
Training loss: 0.27456659442307024
Validation loss: 2.4894515071413417

Epoch: 6| Step: 13
Training loss: 0.20277209987504158
Validation loss: 2.4521141187552202

Epoch: 491| Step: 0
Training loss: 0.25189975794329644
Validation loss: 2.4506062523287677

Epoch: 6| Step: 1
Training loss: 0.1645865472246395
Validation loss: 2.455091950428241

Epoch: 6| Step: 2
Training loss: 0.1663415850330584
Validation loss: 2.4382834089284686

Epoch: 6| Step: 3
Training loss: 0.22808619031910082
Validation loss: 2.4585303583407168

Epoch: 6| Step: 4
Training loss: 0.17392568315163726
Validation loss: 2.457946411796362

Epoch: 6| Step: 5
Training loss: 0.3109093955292368
Validation loss: 2.466849983156843

Epoch: 6| Step: 6
Training loss: 0.1568523241653414
Validation loss: 2.4576800753979984

Epoch: 6| Step: 7
Training loss: 0.12523018236810832
Validation loss: 2.4510371782165628

Epoch: 6| Step: 8
Training loss: 0.13169776598895513
Validation loss: 2.4742601330817844

Epoch: 6| Step: 9
Training loss: 0.13411496140756987
Validation loss: 2.4666398795529454

Epoch: 6| Step: 10
Training loss: 0.1486824549259631
Validation loss: 2.4589950580969706

Epoch: 6| Step: 11
Training loss: 0.16997047255537948
Validation loss: 2.462417169683974

Epoch: 6| Step: 12
Training loss: 0.16214617345998825
Validation loss: 2.4292667598221804

Epoch: 6| Step: 13
Training loss: 0.2943090172134451
Validation loss: 2.4562661698628525

Epoch: 492| Step: 0
Training loss: 0.1840133741328092
Validation loss: 2.450287623763576

Epoch: 6| Step: 1
Training loss: 0.3357692896193719
Validation loss: 2.44457209052769

Epoch: 6| Step: 2
Training loss: 0.12120282736423658
Validation loss: 2.4353128922407623

Epoch: 6| Step: 3
Training loss: 0.12937010768495127
Validation loss: 2.4465696223774254

Epoch: 6| Step: 4
Training loss: 0.18300467196347928
Validation loss: 2.453452438594965

Epoch: 6| Step: 5
Training loss: 0.2513697620369671
Validation loss: 2.4347878505488993

Epoch: 6| Step: 6
Training loss: 0.10838455248733672
Validation loss: 2.453339162350244

Epoch: 6| Step: 7
Training loss: 0.2400896132451794
Validation loss: 2.492790869969755

Epoch: 6| Step: 8
Training loss: 0.19761728347441196
Validation loss: 2.4590818274791566

Epoch: 6| Step: 9
Training loss: 0.08534243587259473
Validation loss: 2.48957702440954

Epoch: 6| Step: 10
Training loss: 0.14789065218450154
Validation loss: 2.4623612928180583

Epoch: 6| Step: 11
Training loss: 0.17863315703198016
Validation loss: 2.4375842831588113

Epoch: 6| Step: 12
Training loss: 0.17765852598747112
Validation loss: 2.430624013855673

Epoch: 6| Step: 13
Training loss: 0.2886090846549449
Validation loss: 2.425294429055422

Epoch: 493| Step: 0
Training loss: 0.1604116659396454
Validation loss: 2.4278585963350667

Epoch: 6| Step: 1
Training loss: 0.25783277200702687
Validation loss: 2.434706648936621

Epoch: 6| Step: 2
Training loss: 0.11597494799427151
Validation loss: 2.4256882444538315

Epoch: 6| Step: 3
Training loss: 0.14186522830383577
Validation loss: 2.437072296207911

Epoch: 6| Step: 4
Training loss: 0.11299378407232688
Validation loss: 2.4378631558964776

Epoch: 6| Step: 5
Training loss: 0.14799079688477648
Validation loss: 2.445854931226399

Epoch: 6| Step: 6
Training loss: 0.31357457657814103
Validation loss: 2.426382026257485

Epoch: 6| Step: 7
Training loss: 0.22813636738399498
Validation loss: 2.4026782787598435

Epoch: 6| Step: 8
Training loss: 0.1919097311974164
Validation loss: 2.436810486658851

Epoch: 6| Step: 9
Training loss: 0.16232309845248732
Validation loss: 2.4500309227102592

Epoch: 6| Step: 10
Training loss: 0.2690686665358889
Validation loss: 2.4291201231289143

Epoch: 6| Step: 11
Training loss: 0.16281332999656703
Validation loss: 2.436085661138598

Epoch: 6| Step: 12
Training loss: 0.1515307926655683
Validation loss: 2.4194560249252115

Epoch: 6| Step: 13
Training loss: 0.10440571049782353
Validation loss: 2.4010165786704833

Epoch: 494| Step: 0
Training loss: 0.18473586473862083
Validation loss: 2.4242128286018754

Epoch: 6| Step: 1
Training loss: 0.2618043531797227
Validation loss: 2.43828154687696

Epoch: 6| Step: 2
Training loss: 0.14319971533179626
Validation loss: 2.407645578459688

Epoch: 6| Step: 3
Training loss: 0.15567661220453297
Validation loss: 2.460701541295647

Epoch: 6| Step: 4
Training loss: 0.3447637997148242
Validation loss: 2.474655483875018

Epoch: 6| Step: 5
Training loss: 0.19511582963106325
Validation loss: 2.4353652137564663

Epoch: 6| Step: 6
Training loss: 0.1589638821002966
Validation loss: 2.460352193982344

Epoch: 6| Step: 7
Training loss: 0.0967915254166071
Validation loss: 2.4962534477473026

Epoch: 6| Step: 8
Training loss: 0.15796370698216103
Validation loss: 2.4320295952918656

Epoch: 6| Step: 9
Training loss: 0.16303081494588278
Validation loss: 2.452791417954026

Epoch: 6| Step: 10
Training loss: 0.2376170124239561
Validation loss: 2.4344960500713313

Epoch: 6| Step: 11
Training loss: 0.18139605310319484
Validation loss: 2.4537050099583397

Epoch: 6| Step: 12
Training loss: 0.14202239542974948
Validation loss: 2.4213186518823293

Epoch: 6| Step: 13
Training loss: 0.14493579566294001
Validation loss: 2.449361520227565

Epoch: 495| Step: 0
Training loss: 0.11109326921163144
Validation loss: 2.453166985608062

Epoch: 6| Step: 1
Training loss: 0.1420427093457332
Validation loss: 2.4027070857946375

Epoch: 6| Step: 2
Training loss: 0.30111565516656286
Validation loss: 2.4359626489144723

Epoch: 6| Step: 3
Training loss: 0.1172566924864191
Validation loss: 2.4478523415252385

Epoch: 6| Step: 4
Training loss: 0.13431686513338945
Validation loss: 2.4544226085319254

Epoch: 6| Step: 5
Training loss: 0.2149549023326753
Validation loss: 2.4653984867762695

Epoch: 6| Step: 6
Training loss: 0.0902888272041357
Validation loss: 2.4696039613081675

Epoch: 6| Step: 7
Training loss: 0.0892629300576558
Validation loss: 2.447721025184502

Epoch: 6| Step: 8
Training loss: 0.15588722434325014
Validation loss: 2.4363378042197725

Epoch: 6| Step: 9
Training loss: 0.14298614489935946
Validation loss: 2.4292216299301885

Epoch: 6| Step: 10
Training loss: 0.29207319073791355
Validation loss: 2.4832245984263395

Epoch: 6| Step: 11
Training loss: 0.19637243673253074
Validation loss: 2.4677772833110025

Epoch: 6| Step: 12
Training loss: 0.18663229437112655
Validation loss: 2.44903499390658

Epoch: 6| Step: 13
Training loss: 0.29093299563124164
Validation loss: 2.448632894833576

Epoch: 496| Step: 0
Training loss: 0.10838792079737829
Validation loss: 2.4201362648179834

Epoch: 6| Step: 1
Training loss: 0.1281995184447458
Validation loss: 2.4358140232970955

Epoch: 6| Step: 2
Training loss: 0.10444318210467275
Validation loss: 2.442740998335166

Epoch: 6| Step: 3
Training loss: 0.2768489695598557
Validation loss: 2.4409044248620213

Epoch: 6| Step: 4
Training loss: 0.22493584168488762
Validation loss: 2.4819876980640747

Epoch: 6| Step: 5
Training loss: 0.10357635893634612
Validation loss: 2.4257697241745806

Epoch: 6| Step: 6
Training loss: 0.15818453903283186
Validation loss: 2.4393786292029556

Epoch: 6| Step: 7
Training loss: 0.24364018839939688
Validation loss: 2.450026013133894

Epoch: 6| Step: 8
Training loss: 0.2489636667363969
Validation loss: 2.453022845186738

Epoch: 6| Step: 9
Training loss: 0.11691976002512676
Validation loss: 2.460130467071973

Epoch: 6| Step: 10
Training loss: 0.1305994113357715
Validation loss: 2.404317268481087

Epoch: 6| Step: 11
Training loss: 0.23089451982236478
Validation loss: 2.4801812030217483

Epoch: 6| Step: 12
Training loss: 0.11835443908168977
Validation loss: 2.424073675505587

Epoch: 6| Step: 13
Training loss: 0.10327469931213341
Validation loss: 2.4346309643928126

Epoch: 497| Step: 0
Training loss: 0.24736382461409862
Validation loss: 2.441426075188323

Epoch: 6| Step: 1
Training loss: 0.28377034177420873
Validation loss: 2.4340483956904175

Epoch: 6| Step: 2
Training loss: 0.09208884375181968
Validation loss: 2.4467027340907603

Epoch: 6| Step: 3
Training loss: 0.1159942915597077
Validation loss: 2.4341283564670926

Epoch: 6| Step: 4
Training loss: 0.15589368246612537
Validation loss: 2.4490873949192067

Epoch: 6| Step: 5
Training loss: 0.28501328058838166
Validation loss: 2.4250383156693767

Epoch: 6| Step: 6
Training loss: 0.09444371497622062
Validation loss: 2.431247754265583

Epoch: 6| Step: 7
Training loss: 0.10638316991583087
Validation loss: 2.453497481180963

Epoch: 6| Step: 8
Training loss: 0.13843350675950383
Validation loss: 2.413115425042742

Epoch: 6| Step: 9
Training loss: 0.09529111692674226
Validation loss: 2.4251725447001897

Epoch: 6| Step: 10
Training loss: 0.18184054048245793
Validation loss: 2.413321120801422

Epoch: 6| Step: 11
Training loss: 0.15105939766519821
Validation loss: 2.4010671159981416

Epoch: 6| Step: 12
Training loss: 0.1609849713968039
Validation loss: 2.425415254523396

Epoch: 6| Step: 13
Training loss: 0.2507159442185937
Validation loss: 2.448029277849554

Epoch: 498| Step: 0
Training loss: 0.1443921786157522
Validation loss: 2.423779045918889

Epoch: 6| Step: 1
Training loss: 0.12043275319446675
Validation loss: 2.478045098098542

Epoch: 6| Step: 2
Training loss: 0.21820485784632696
Validation loss: 2.429015051615699

Epoch: 6| Step: 3
Training loss: 0.1816576877906555
Validation loss: 2.4311827620811033

Epoch: 6| Step: 4
Training loss: 0.2154852566333477
Validation loss: 2.454725409280604

Epoch: 6| Step: 5
Training loss: 0.10269866511290827
Validation loss: 2.448980452074483

Epoch: 6| Step: 6
Training loss: 0.1264556896181086
Validation loss: 2.417762049473567

Epoch: 6| Step: 7
Training loss: 0.08986353138136631
Validation loss: 2.4365420598130525

Epoch: 6| Step: 8
Training loss: 0.18185215600083185
Validation loss: 2.4162987084863246

Epoch: 6| Step: 9
Training loss: 0.1530293236308016
Validation loss: 2.407710500053971

Epoch: 6| Step: 10
Training loss: 0.1522570632398609
Validation loss: 2.4335471833719926

Epoch: 6| Step: 11
Training loss: 0.21424466617002963
Validation loss: 2.4067151254417904

Epoch: 6| Step: 12
Training loss: 0.39153608883061264
Validation loss: 2.380629040360333

Epoch: 6| Step: 13
Training loss: 0.15192956128833365
Validation loss: 2.445806281570881

Epoch: 499| Step: 0
Training loss: 0.16602316446574916
Validation loss: 2.4536037245749864

Epoch: 6| Step: 1
Training loss: 0.17125697536776394
Validation loss: 2.4755011560661124

Epoch: 6| Step: 2
Training loss: 0.2927239221560037
Validation loss: 2.443116682847157

Epoch: 6| Step: 3
Training loss: 0.20935144007205497
Validation loss: 2.4644068345395715

Epoch: 6| Step: 4
Training loss: 0.1696134706281201
Validation loss: 2.4859699349271858

Epoch: 6| Step: 5
Training loss: 0.24318347991261763
Validation loss: 2.4723591133088063

Epoch: 6| Step: 6
Training loss: 0.09476718817960243
Validation loss: 2.4961828069279366

Epoch: 6| Step: 7
Training loss: 0.16213123909453292
Validation loss: 2.4853236122976483

Epoch: 6| Step: 8
Training loss: 0.24193927903877496
Validation loss: 2.4866469335868624

Epoch: 6| Step: 9
Training loss: 0.1859642454354022
Validation loss: 2.4908457520245735

Epoch: 6| Step: 10
Training loss: 0.14305872457146382
Validation loss: 2.484548684290275

Epoch: 6| Step: 11
Training loss: 0.23574990083706532
Validation loss: 2.49541694826841

Epoch: 6| Step: 12
Training loss: 0.20007637957102437
Validation loss: 2.5223460169583207

Epoch: 6| Step: 13
Training loss: 0.23615993473358016
Validation loss: 2.498589872217037

Epoch: 500| Step: 0
Training loss: 0.16267205446471736
Validation loss: 2.4903383480132675

Epoch: 6| Step: 1
Training loss: 0.14502548436748303
Validation loss: 2.4943737668482355

Epoch: 6| Step: 2
Training loss: 0.17274898782977352
Validation loss: 2.501643090048026

Epoch: 6| Step: 3
Training loss: 0.2691191134555414
Validation loss: 2.4786818883388184

Epoch: 6| Step: 4
Training loss: 0.22400973343776404
Validation loss: 2.4581779001889013

Epoch: 6| Step: 5
Training loss: 0.22167154540851303
Validation loss: 2.487716528556953

Epoch: 6| Step: 6
Training loss: 0.2872203819910044
Validation loss: 2.4921118853733564

Epoch: 6| Step: 7
Training loss: 0.16439706884480734
Validation loss: 2.4674399978588983

Epoch: 6| Step: 8
Training loss: 0.17584103521282146
Validation loss: 2.5115671807596995

Epoch: 6| Step: 9
Training loss: 0.1615441706864864
Validation loss: 2.4900446762226265

Epoch: 6| Step: 10
Training loss: 0.29295165965776715
Validation loss: 2.5217846572258913

Epoch: 6| Step: 11
Training loss: 0.18190983337112873
Validation loss: 2.5137096296094716

Epoch: 6| Step: 12
Training loss: 0.23414127298850307
Validation loss: 2.5122185232857377

Epoch: 6| Step: 13
Training loss: 0.18762018405062922
Validation loss: 2.471281323750685

Testing loss: 2.6223649983769857
