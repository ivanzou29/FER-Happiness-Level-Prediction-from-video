Epoch: 1| Step: 0
Training loss: 5.746044622920514
Validation loss: 5.81077673104706

Epoch: 6| Step: 1
Training loss: 5.99901159410458
Validation loss: 5.7933503833987485

Epoch: 6| Step: 2
Training loss: 5.873728513091818
Validation loss: 5.774246128331201

Epoch: 6| Step: 3
Training loss: 5.759094344041797
Validation loss: 5.752839896338714

Epoch: 6| Step: 4
Training loss: 5.227697138086111
Validation loss: 5.728743205450548

Epoch: 6| Step: 5
Training loss: 5.822399610060983
Validation loss: 5.701196243413977

Epoch: 6| Step: 6
Training loss: 5.386410334376987
Validation loss: 5.670582901338228

Epoch: 6| Step: 7
Training loss: 6.228143240083207
Validation loss: 5.635744231773592

Epoch: 6| Step: 8
Training loss: 5.403821807814839
Validation loss: 5.596048214455968

Epoch: 6| Step: 9
Training loss: 5.7856995651353875
Validation loss: 5.551940017873246

Epoch: 6| Step: 10
Training loss: 6.5370717362413595
Validation loss: 5.502500927518534

Epoch: 6| Step: 11
Training loss: 4.705854770635666
Validation loss: 5.450993349364916

Epoch: 6| Step: 12
Training loss: 5.541445199465717
Validation loss: 5.3937774984887685

Epoch: 6| Step: 13
Training loss: 4.618500343771237
Validation loss: 5.336291188348944

Epoch: 2| Step: 0
Training loss: 4.933664884681157
Validation loss: 5.276305816613488

Epoch: 6| Step: 1
Training loss: 5.214260340141772
Validation loss: 5.214007335857801

Epoch: 6| Step: 2
Training loss: 5.436891368258533
Validation loss: 5.150104428937091

Epoch: 6| Step: 3
Training loss: 5.21032509929859
Validation loss: 5.082357975051041

Epoch: 6| Step: 4
Training loss: 4.411328142295006
Validation loss: 5.012760585831733

Epoch: 6| Step: 5
Training loss: 5.810333176217379
Validation loss: 4.943099388367686

Epoch: 6| Step: 6
Training loss: 6.290419532842775
Validation loss: 4.87407504536841

Epoch: 6| Step: 7
Training loss: 4.43559847641715
Validation loss: 4.808589049859363

Epoch: 6| Step: 8
Training loss: 3.96138217694671
Validation loss: 4.7459724008676

Epoch: 6| Step: 9
Training loss: 3.892333119171033
Validation loss: 4.68986871190095

Epoch: 6| Step: 10
Training loss: 4.322907646200428
Validation loss: 4.638823986346531

Epoch: 6| Step: 11
Training loss: 5.246182097985602
Validation loss: 4.593762183799321

Epoch: 6| Step: 12
Training loss: 4.060797231790187
Validation loss: 4.554543579531709

Epoch: 6| Step: 13
Training loss: 5.680651219605776
Validation loss: 4.51814148747397

Epoch: 3| Step: 0
Training loss: 5.015173395568898
Validation loss: 4.481072836650336

Epoch: 6| Step: 1
Training loss: 3.7666082720885923
Validation loss: 4.445569097000205

Epoch: 6| Step: 2
Training loss: 5.209851748065045
Validation loss: 4.409519427550573

Epoch: 6| Step: 3
Training loss: 3.4214669598326624
Validation loss: 4.369806287326143

Epoch: 6| Step: 4
Training loss: 5.953200292236304
Validation loss: 4.327576916458599

Epoch: 6| Step: 5
Training loss: 3.6201088892118944
Validation loss: 4.286937906838676

Epoch: 6| Step: 6
Training loss: 5.0727228627662715
Validation loss: 4.257896615332379

Epoch: 6| Step: 7
Training loss: 4.216907013889913
Validation loss: 4.224630483094305

Epoch: 6| Step: 8
Training loss: 4.462138159691691
Validation loss: 4.1939926003690555

Epoch: 6| Step: 9
Training loss: 4.5345955961319175
Validation loss: 4.1651975236132674

Epoch: 6| Step: 10
Training loss: 2.825027793139908
Validation loss: 4.1347618044301475

Epoch: 6| Step: 11
Training loss: 4.194342190223803
Validation loss: 4.1123004321197785

Epoch: 6| Step: 12
Training loss: 4.023423752251998
Validation loss: 4.0919464479488585

Epoch: 6| Step: 13
Training loss: 4.132731503592525
Validation loss: 4.073929037433675

Epoch: 4| Step: 0
Training loss: 4.020635543992057
Validation loss: 4.055987431369194

Epoch: 6| Step: 1
Training loss: 4.057824833924267
Validation loss: 4.0412506703028575

Epoch: 6| Step: 2
Training loss: 2.9875947051419782
Validation loss: 4.024727986205921

Epoch: 6| Step: 3
Training loss: 3.864191301037093
Validation loss: 4.009786527829819

Epoch: 6| Step: 4
Training loss: 3.942079575399789
Validation loss: 3.9942487881596933

Epoch: 6| Step: 5
Training loss: 4.07345044214836
Validation loss: 3.976213009795343

Epoch: 6| Step: 6
Training loss: 3.8740114981619023
Validation loss: 3.961190038807665

Epoch: 6| Step: 7
Training loss: 2.7188194529113727
Validation loss: 3.9419618410497077

Epoch: 6| Step: 8
Training loss: 4.370155922488949
Validation loss: 3.927952791782291

Epoch: 6| Step: 9
Training loss: 4.954998636717084
Validation loss: 3.9076108666225156

Epoch: 6| Step: 10
Training loss: 4.675325172253647
Validation loss: 3.8893314469153344

Epoch: 6| Step: 11
Training loss: 4.84538999296857
Validation loss: 3.872214876115396

Epoch: 6| Step: 12
Training loss: 3.530983703834959
Validation loss: 3.8575008804498605

Epoch: 6| Step: 13
Training loss: 5.2914505361238255
Validation loss: 3.8484591398289845

Epoch: 5| Step: 0
Training loss: 3.247131548999638
Validation loss: 3.833496925337331

Epoch: 6| Step: 1
Training loss: 2.9949482663993052
Validation loss: 3.8196717871719947

Epoch: 6| Step: 2
Training loss: 3.6088820612137615
Validation loss: 3.8096234063380945

Epoch: 6| Step: 3
Training loss: 4.387904508805263
Validation loss: 3.799490709561457

Epoch: 6| Step: 4
Training loss: 4.237864052767187
Validation loss: 3.7881108301559716

Epoch: 6| Step: 5
Training loss: 4.420684762100679
Validation loss: 3.775115023906547

Epoch: 6| Step: 6
Training loss: 4.349819854864727
Validation loss: 3.757077336018392

Epoch: 6| Step: 7
Training loss: 4.025443219725546
Validation loss: 3.746929013263555

Epoch: 6| Step: 8
Training loss: 3.8115649718304505
Validation loss: 3.737483538996996

Epoch: 6| Step: 9
Training loss: 4.113179929233467
Validation loss: 3.7273299854225153

Epoch: 6| Step: 10
Training loss: 3.487678091225963
Validation loss: 3.718489433294839

Epoch: 6| Step: 11
Training loss: 3.342550472543238
Validation loss: 3.70893381356006

Epoch: 6| Step: 12
Training loss: 5.2517918753137325
Validation loss: 3.6998939276126754

Epoch: 6| Step: 13
Training loss: 2.4265271205742422
Validation loss: 3.686671110152486

Epoch: 6| Step: 0
Training loss: 3.501689503114276
Validation loss: 3.680118294950634

Epoch: 6| Step: 1
Training loss: 3.373274468020158
Validation loss: 3.67467827403313

Epoch: 6| Step: 2
Training loss: 4.082686755831292
Validation loss: 3.666214567337353

Epoch: 6| Step: 3
Training loss: 3.6669084440337842
Validation loss: 3.6480808827279176

Epoch: 6| Step: 4
Training loss: 3.962056199500826
Validation loss: 3.643996368641967

Epoch: 6| Step: 5
Training loss: 2.244697893371695
Validation loss: 3.634906551894692

Epoch: 6| Step: 6
Training loss: 3.733921805618869
Validation loss: 3.644678677072665

Epoch: 6| Step: 7
Training loss: 3.296131791507631
Validation loss: 3.6170735613779166

Epoch: 6| Step: 8
Training loss: 3.3999407370395236
Validation loss: 3.611221716811603

Epoch: 6| Step: 9
Training loss: 4.339495874122744
Validation loss: 3.607231379706379

Epoch: 6| Step: 10
Training loss: 4.2004835486210785
Validation loss: 3.5993057856608353

Epoch: 6| Step: 11
Training loss: 4.677497058176312
Validation loss: 3.5925000599842667

Epoch: 6| Step: 12
Training loss: 4.288901515364522
Validation loss: 3.5865046272776993

Epoch: 6| Step: 13
Training loss: 4.296305448758643
Validation loss: 3.5855812158311724

Epoch: 7| Step: 0
Training loss: 4.100048083511872
Validation loss: 3.578510079389174

Epoch: 6| Step: 1
Training loss: 2.2088394184934934
Validation loss: 3.5751315191291884

Epoch: 6| Step: 2
Training loss: 2.618248932091437
Validation loss: 3.572228071551744

Epoch: 6| Step: 3
Training loss: 4.189029698881978
Validation loss: 3.5701947417524624

Epoch: 6| Step: 4
Training loss: 4.198569172142067
Validation loss: 3.5586122457157954

Epoch: 6| Step: 5
Training loss: 4.019392213186931
Validation loss: 3.5511455116430084

Epoch: 6| Step: 6
Training loss: 4.123308008147549
Validation loss: 3.547884299993301

Epoch: 6| Step: 7
Training loss: 4.536409374137835
Validation loss: 3.546146585638253

Epoch: 6| Step: 8
Training loss: 3.6506425945091143
Validation loss: 3.539066065416788

Epoch: 6| Step: 9
Training loss: 3.950272326196112
Validation loss: 3.531771670049887

Epoch: 6| Step: 10
Training loss: 3.078111677576658
Validation loss: 3.515912083944233

Epoch: 6| Step: 11
Training loss: 3.3817203159378884
Validation loss: 3.513359347909476

Epoch: 6| Step: 12
Training loss: 3.2413529022747523
Validation loss: 3.51076584825306

Epoch: 6| Step: 13
Training loss: 4.825118724568004
Validation loss: 3.5067698039889366

Epoch: 8| Step: 0
Training loss: 3.660915430371218
Validation loss: 3.502514303036386

Epoch: 6| Step: 1
Training loss: 2.766751248625586
Validation loss: 3.4994738017709053

Epoch: 6| Step: 2
Training loss: 3.847813760854365
Validation loss: 3.4979368609947317

Epoch: 6| Step: 3
Training loss: 3.2127134140908216
Validation loss: 3.5161441440639494

Epoch: 6| Step: 4
Training loss: 4.336853700358192
Validation loss: 3.5370233797707145

Epoch: 6| Step: 5
Training loss: 3.5703031510579186
Validation loss: 3.482576568018317

Epoch: 6| Step: 6
Training loss: 2.6596265088935103
Validation loss: 3.5092669668878487

Epoch: 6| Step: 7
Training loss: 4.7135982053397205
Validation loss: 3.5671981807267104

Epoch: 6| Step: 8
Training loss: 3.220128329071448
Validation loss: 3.6196968402011076

Epoch: 6| Step: 9
Training loss: 4.88863695584063
Validation loss: 3.652152964090442

Epoch: 6| Step: 10
Training loss: 3.9694662574172885
Validation loss: 3.5772743587809552

Epoch: 6| Step: 11
Training loss: 3.4337134573665002
Validation loss: 3.5175136029968095

Epoch: 6| Step: 12
Training loss: 3.548865612547944
Validation loss: 3.48975959054754

Epoch: 6| Step: 13
Training loss: 3.9638336247886192
Validation loss: 3.48466706198067

Epoch: 9| Step: 0
Training loss: 4.1147328538728045
Validation loss: 3.49215468671392

Epoch: 6| Step: 1
Training loss: 3.9771494254283506
Validation loss: 3.5005706682252256

Epoch: 6| Step: 2
Training loss: 3.3419869311457844
Validation loss: 3.5118038523019774

Epoch: 6| Step: 3
Training loss: 3.4470737652434686
Validation loss: 3.5075256945166413

Epoch: 6| Step: 4
Training loss: 4.11167280695879
Validation loss: 3.473836703175318

Epoch: 6| Step: 5
Training loss: 3.6325911915957168
Validation loss: 3.4639847533618884

Epoch: 6| Step: 6
Training loss: 3.3893012350089657
Validation loss: 3.4589171872411693

Epoch: 6| Step: 7
Training loss: 3.681418625186773
Validation loss: 3.4566287438174466

Epoch: 6| Step: 8
Training loss: 3.164261423145045
Validation loss: 3.4523194159909494

Epoch: 6| Step: 9
Training loss: 3.104513076467156
Validation loss: 3.4478221067786015

Epoch: 6| Step: 10
Training loss: 3.598871578747959
Validation loss: 3.4444322895687263

Epoch: 6| Step: 11
Training loss: 3.0782058627743147
Validation loss: 3.4422619320031056

Epoch: 6| Step: 12
Training loss: 4.69557003895402
Validation loss: 3.444303677629073

Epoch: 6| Step: 13
Training loss: 4.051739100304766
Validation loss: 3.438951811068838

Epoch: 10| Step: 0
Training loss: 3.2076531386891087
Validation loss: 3.4326792947537217

Epoch: 6| Step: 1
Training loss: 4.177158167954312
Validation loss: 3.424852606399262

Epoch: 6| Step: 2
Training loss: 4.428158666123345
Validation loss: 3.4202759545038903

Epoch: 6| Step: 3
Training loss: 3.0639473745144423
Validation loss: 3.415486325206616

Epoch: 6| Step: 4
Training loss: 3.445575453223659
Validation loss: 3.410932918098665

Epoch: 6| Step: 5
Training loss: 3.8531063924001354
Validation loss: 3.4082166449645377

Epoch: 6| Step: 6
Training loss: 3.5112825829313805
Validation loss: 3.403917850728418

Epoch: 6| Step: 7
Training loss: 3.7706516004294652
Validation loss: 3.396564582823457

Epoch: 6| Step: 8
Training loss: 4.254653626810397
Validation loss: 3.3658930227904165

Epoch: 6| Step: 9
Training loss: 3.266391207959864
Validation loss: 3.3632459259074263

Epoch: 6| Step: 10
Training loss: 3.3159015392783417
Validation loss: 3.3629888694943215

Epoch: 6| Step: 11
Training loss: 3.36218286316296
Validation loss: 3.3604284643186304

Epoch: 6| Step: 12
Training loss: 3.066231303478768
Validation loss: 3.356489510047849

Epoch: 6| Step: 13
Training loss: 3.772702352811273
Validation loss: 3.3542746912022383

Epoch: 11| Step: 0
Training loss: 4.220678044305977
Validation loss: 3.3516340427138056

Epoch: 6| Step: 1
Training loss: 2.9378145739350527
Validation loss: 3.3463482028312237

Epoch: 6| Step: 2
Training loss: 3.3482748058843996
Validation loss: 3.3427236916148493

Epoch: 6| Step: 3
Training loss: 3.8118545736330685
Validation loss: 3.338080574847761

Epoch: 6| Step: 4
Training loss: 3.4865622732995467
Validation loss: 3.3332033706268676

Epoch: 6| Step: 5
Training loss: 3.9740332333500317
Validation loss: 3.331102251110409

Epoch: 6| Step: 6
Training loss: 4.056302316854326
Validation loss: 3.328965972005721

Epoch: 6| Step: 7
Training loss: 3.5836080992872734
Validation loss: 3.3248360051149324

Epoch: 6| Step: 8
Training loss: 3.9186368545673678
Validation loss: 3.32207733600928

Epoch: 6| Step: 9
Training loss: 2.8698151316897893
Validation loss: 3.320889452536522

Epoch: 6| Step: 10
Training loss: 3.1103569282233936
Validation loss: 3.3187120226302413

Epoch: 6| Step: 11
Training loss: 3.014963660582626
Validation loss: 3.3168274189411417

Epoch: 6| Step: 12
Training loss: 3.849277398800965
Validation loss: 3.315694317071799

Epoch: 6| Step: 13
Training loss: 3.344852158910139
Validation loss: 3.315318640646823

Epoch: 12| Step: 0
Training loss: 3.8820043448139385
Validation loss: 3.312560745149734

Epoch: 6| Step: 1
Training loss: 3.996138496931471
Validation loss: 3.3112625454425784

Epoch: 6| Step: 2
Training loss: 2.841661965225522
Validation loss: 3.3092255632751337

Epoch: 6| Step: 3
Training loss: 3.6868729138986804
Validation loss: 3.3074159308974536

Epoch: 6| Step: 4
Training loss: 3.1772679676541684
Validation loss: 3.3087593615682005

Epoch: 6| Step: 5
Training loss: 4.079622541806798
Validation loss: 3.30488808498618

Epoch: 6| Step: 6
Training loss: 3.16449122408902
Validation loss: 3.3040775296721607

Epoch: 6| Step: 7
Training loss: 2.872745127232842
Validation loss: 3.3027291727853743

Epoch: 6| Step: 8
Training loss: 4.100564424694998
Validation loss: 3.3008783300814515

Epoch: 6| Step: 9
Training loss: 3.6246198257507762
Validation loss: 3.2997564241440394

Epoch: 6| Step: 10
Training loss: 3.469153303465319
Validation loss: 3.297936908507262

Epoch: 6| Step: 11
Training loss: 3.0830098231601775
Validation loss: 3.297152797323103

Epoch: 6| Step: 12
Training loss: 3.480565747280545
Validation loss: 3.296229179629192

Epoch: 6| Step: 13
Training loss: 4.103970414841408
Validation loss: 3.296500694800731

Epoch: 13| Step: 0
Training loss: 2.9424001526725196
Validation loss: 3.2959923992853866

Epoch: 6| Step: 1
Training loss: 3.7049045069611015
Validation loss: 3.2943134754356684

Epoch: 6| Step: 2
Training loss: 3.256335465669658
Validation loss: 3.2933369068978116

Epoch: 6| Step: 3
Training loss: 3.539185376592022
Validation loss: 3.2922893110256384

Epoch: 6| Step: 4
Training loss: 3.768234425162983
Validation loss: 3.2917953648816463

Epoch: 6| Step: 5
Training loss: 3.236301309201668
Validation loss: 3.2900639831902185

Epoch: 6| Step: 6
Training loss: 4.087792640966162
Validation loss: 3.2899192890747755

Epoch: 6| Step: 7
Training loss: 3.804890026052207
Validation loss: 3.2873603052792255

Epoch: 6| Step: 8
Training loss: 3.6631495918472914
Validation loss: 3.2864546259574805

Epoch: 6| Step: 9
Training loss: 3.7558492183300007
Validation loss: 3.2851951543849793

Epoch: 6| Step: 10
Training loss: 3.497786503169244
Validation loss: 3.2840162516980658

Epoch: 6| Step: 11
Training loss: 3.488730680384186
Validation loss: 3.2841955477541926

Epoch: 6| Step: 12
Training loss: 3.368417324986403
Validation loss: 3.2826662381486793

Epoch: 6| Step: 13
Training loss: 2.9519260132157785
Validation loss: 3.2812843301425505

Epoch: 14| Step: 0
Training loss: 3.8918607043972733
Validation loss: 3.279612803989549

Epoch: 6| Step: 1
Training loss: 3.5452815438235064
Validation loss: 3.279165166784753

Epoch: 6| Step: 2
Training loss: 3.8602906658253344
Validation loss: 3.2772810989374266

Epoch: 6| Step: 3
Training loss: 3.8049667224606845
Validation loss: 3.276366312704701

Epoch: 6| Step: 4
Training loss: 2.920445056598956
Validation loss: 3.275973089694966

Epoch: 6| Step: 5
Training loss: 4.1011006994490495
Validation loss: 3.2751442851233716

Epoch: 6| Step: 6
Training loss: 2.617218199592568
Validation loss: 3.2740920599849974

Epoch: 6| Step: 7
Training loss: 3.08422031188613
Validation loss: 3.271982789829433

Epoch: 6| Step: 8
Training loss: 3.119501082314843
Validation loss: 3.2712975501717314

Epoch: 6| Step: 9
Training loss: 3.941087329918105
Validation loss: 3.270972381723292

Epoch: 6| Step: 10
Training loss: 3.364419529630974
Validation loss: 3.269359149554946

Epoch: 6| Step: 11
Training loss: 3.4715983750147115
Validation loss: 3.267451356582747

Epoch: 6| Step: 12
Training loss: 3.7429164104906767
Validation loss: 3.2671465427282014

Epoch: 6| Step: 13
Training loss: 3.5208063218624925
Validation loss: 3.2661755197838196

Epoch: 15| Step: 0
Training loss: 2.3396415814163047
Validation loss: 3.264796616743774

Epoch: 6| Step: 1
Training loss: 3.8325064361577943
Validation loss: 3.2651077255701173

Epoch: 6| Step: 2
Training loss: 3.339458242553688
Validation loss: 3.2634423006175552

Epoch: 6| Step: 3
Training loss: 3.2976335132052728
Validation loss: 3.263270149297609

Epoch: 6| Step: 4
Training loss: 3.422934172282359
Validation loss: 3.2610734497368554

Epoch: 6| Step: 5
Training loss: 3.1607843442084533
Validation loss: 3.2608765691176984

Epoch: 6| Step: 6
Training loss: 4.2188078699734595
Validation loss: 3.259175369617272

Epoch: 6| Step: 7
Training loss: 4.017176465702222
Validation loss: 3.257840177463148

Epoch: 6| Step: 8
Training loss: 3.2458093474990948
Validation loss: 3.256279168521781

Epoch: 6| Step: 9
Training loss: 3.3923647587805488
Validation loss: 3.2552903535743787

Epoch: 6| Step: 10
Training loss: 3.7520208635624495
Validation loss: 3.2549391393124396

Epoch: 6| Step: 11
Training loss: 3.0360860100123763
Validation loss: 3.252170261715545

Epoch: 6| Step: 12
Training loss: 4.167861665388669
Validation loss: 3.2502070093605977

Epoch: 6| Step: 13
Training loss: 3.423342316147392
Validation loss: 3.250071456161507

Epoch: 16| Step: 0
Training loss: 3.3872359957700082
Validation loss: 3.2460813981029473

Epoch: 6| Step: 1
Training loss: 3.7572787534306586
Validation loss: 3.2440532141041465

Epoch: 6| Step: 2
Training loss: 3.5961924338614453
Validation loss: 3.2413331846576456

Epoch: 6| Step: 3
Training loss: 3.6784953719277595
Validation loss: 3.240046355929817

Epoch: 6| Step: 4
Training loss: 2.7137461247849175
Validation loss: 3.2393013186099737

Epoch: 6| Step: 5
Training loss: 3.583207165175077
Validation loss: 3.239146779523616

Epoch: 6| Step: 6
Training loss: 3.32756990630148
Validation loss: 3.2379084974390664

Epoch: 6| Step: 7
Training loss: 3.9841022472895835
Validation loss: 3.2361810869025263

Epoch: 6| Step: 8
Training loss: 2.385132907387108
Validation loss: 3.2338764364622707

Epoch: 6| Step: 9
Training loss: 3.9341413917906642
Validation loss: 3.233230138522511

Epoch: 6| Step: 10
Training loss: 3.7695913359443693
Validation loss: 3.232090647481566

Epoch: 6| Step: 11
Training loss: 3.323282076237247
Validation loss: 3.231136211751996

Epoch: 6| Step: 12
Training loss: 2.8378136684120006
Validation loss: 3.23051913569151

Epoch: 6| Step: 13
Training loss: 4.583834164161183
Validation loss: 3.2294983856530566

Epoch: 17| Step: 0
Training loss: 3.7457192465466758
Validation loss: 3.227840574975974

Epoch: 6| Step: 1
Training loss: 3.2968537388699075
Validation loss: 3.226616530018285

Epoch: 6| Step: 2
Training loss: 3.856438759213538
Validation loss: 3.225953442470138

Epoch: 6| Step: 3
Training loss: 3.364720549408279
Validation loss: 3.223731640091149

Epoch: 6| Step: 4
Training loss: 3.0459543255432933
Validation loss: 3.223337336736242

Epoch: 6| Step: 5
Training loss: 3.8046180671763836
Validation loss: 3.2227058159728905

Epoch: 6| Step: 6
Training loss: 2.5050263421354435
Validation loss: 3.222652689315604

Epoch: 6| Step: 7
Training loss: 4.129380876442556
Validation loss: 3.2210537966752706

Epoch: 6| Step: 8
Training loss: 3.4838530145203066
Validation loss: 3.2203548216717732

Epoch: 6| Step: 9
Training loss: 3.3432712390441526
Validation loss: 3.218327506596194

Epoch: 6| Step: 10
Training loss: 3.9624877544418435
Validation loss: 3.216936917572117

Epoch: 6| Step: 11
Training loss: 3.138763939125043
Validation loss: 3.2180572454816443

Epoch: 6| Step: 12
Training loss: 3.456437813207028
Validation loss: 3.215484654537041

Epoch: 6| Step: 13
Training loss: 3.073195019200311
Validation loss: 3.215144434101792

Epoch: 18| Step: 0
Training loss: 2.776393636657343
Validation loss: 3.2132899353180107

Epoch: 6| Step: 1
Training loss: 3.7628741208243897
Validation loss: 3.21232980505785

Epoch: 6| Step: 2
Training loss: 3.213347410063031
Validation loss: 3.211858413883626

Epoch: 6| Step: 3
Training loss: 3.6826647075378083
Validation loss: 3.210404109063195

Epoch: 6| Step: 4
Training loss: 3.33423322610382
Validation loss: 3.210606518557044

Epoch: 6| Step: 5
Training loss: 3.833788982898389
Validation loss: 3.2093214237590595

Epoch: 6| Step: 6
Training loss: 2.8207369244627527
Validation loss: 3.208331181738944

Epoch: 6| Step: 7
Training loss: 3.358862975378085
Validation loss: 3.2062276128805194

Epoch: 6| Step: 8
Training loss: 3.731594183557054
Validation loss: 3.2059814266438345

Epoch: 6| Step: 9
Training loss: 4.348549366374593
Validation loss: 3.2051651830914447

Epoch: 6| Step: 10
Training loss: 3.0528682354788588
Validation loss: 3.2051035319184007

Epoch: 6| Step: 11
Training loss: 2.3908444970784286
Validation loss: 3.203870717024108

Epoch: 6| Step: 12
Training loss: 3.662377333946634
Validation loss: 3.20388751414481

Epoch: 6| Step: 13
Training loss: 4.444900359505556
Validation loss: 3.2022825464312987

Epoch: 19| Step: 0
Training loss: 3.356708550695387
Validation loss: 3.204314980511481

Epoch: 6| Step: 1
Training loss: 2.883867768461175
Validation loss: 3.201357737585914

Epoch: 6| Step: 2
Training loss: 3.8127950335301795
Validation loss: 3.2000734293239708

Epoch: 6| Step: 3
Training loss: 3.336259098319278
Validation loss: 3.19859626498973

Epoch: 6| Step: 4
Training loss: 4.576223557913441
Validation loss: 3.1979219234116445

Epoch: 6| Step: 5
Training loss: 3.197018342892333
Validation loss: 3.1956611918614946

Epoch: 6| Step: 6
Training loss: 3.680141283308605
Validation loss: 3.1953067345738555

Epoch: 6| Step: 7
Training loss: 3.447525939622517
Validation loss: 3.1951930470065153

Epoch: 6| Step: 8
Training loss: 3.728105333632904
Validation loss: 3.192877316825345

Epoch: 6| Step: 9
Training loss: 2.7972214127301287
Validation loss: 3.192888274322376

Epoch: 6| Step: 10
Training loss: 2.6887540331127044
Validation loss: 3.1911593959370466

Epoch: 6| Step: 11
Training loss: 3.7862409960443553
Validation loss: 3.1914233729899633

Epoch: 6| Step: 12
Training loss: 3.1647960424770685
Validation loss: 3.1905534336077506

Epoch: 6| Step: 13
Training loss: 3.5580739417366978
Validation loss: 3.188577571576061

Epoch: 20| Step: 0
Training loss: 3.0043497341070498
Validation loss: 3.1885449094035887

Epoch: 6| Step: 1
Training loss: 4.142986502295551
Validation loss: 3.187022956637248

Epoch: 6| Step: 2
Training loss: 2.3295720870701127
Validation loss: 3.186566536465508

Epoch: 6| Step: 3
Training loss: 3.9743126760804084
Validation loss: 3.186045740185655

Epoch: 6| Step: 4
Training loss: 3.645327956276839
Validation loss: 3.1855238262312

Epoch: 6| Step: 5
Training loss: 3.627584391163719
Validation loss: 3.184309306489474

Epoch: 6| Step: 6
Training loss: 3.4493976343583514
Validation loss: 3.183758293855546

Epoch: 6| Step: 7
Training loss: 3.26405815244744
Validation loss: 3.1853162695451007

Epoch: 6| Step: 8
Training loss: 4.062579579674289
Validation loss: 3.180888099037648

Epoch: 6| Step: 9
Training loss: 2.6319564197260017
Validation loss: 3.181005024291244

Epoch: 6| Step: 10
Training loss: 3.634755654708249
Validation loss: 3.1815118570169743

Epoch: 6| Step: 11
Training loss: 3.2144801883297633
Validation loss: 3.1802132689764115

Epoch: 6| Step: 12
Training loss: 3.7326783990863532
Validation loss: 3.1789116343318047

Epoch: 6| Step: 13
Training loss: 2.6136110379948403
Validation loss: 3.179707691799421

Epoch: 21| Step: 0
Training loss: 2.655160119352393
Validation loss: 3.178285894784925

Epoch: 6| Step: 1
Training loss: 3.350677444511513
Validation loss: 3.180403098648771

Epoch: 6| Step: 2
Training loss: 3.135216758328537
Validation loss: 3.178422183324709

Epoch: 6| Step: 3
Training loss: 3.007842621095121
Validation loss: 3.177635893369769

Epoch: 6| Step: 4
Training loss: 3.3957624057469302
Validation loss: 3.17883605756149

Epoch: 6| Step: 5
Training loss: 3.4757773209196157
Validation loss: 3.179229754173822

Epoch: 6| Step: 6
Training loss: 3.584670697015624
Validation loss: 3.1745946267350336

Epoch: 6| Step: 7
Training loss: 3.637192577467002
Validation loss: 3.1730742891591714

Epoch: 6| Step: 8
Training loss: 4.225934727667924
Validation loss: 3.1693692200617347

Epoch: 6| Step: 9
Training loss: 3.9120377045045007
Validation loss: 3.169766303693821

Epoch: 6| Step: 10
Training loss: 3.2305958364229017
Validation loss: 3.1696127160630447

Epoch: 6| Step: 11
Training loss: 2.908859066231932
Validation loss: 3.1681847881344622

Epoch: 6| Step: 12
Training loss: 3.6235351233513846
Validation loss: 3.167069117021115

Epoch: 6| Step: 13
Training loss: 3.8465939057298657
Validation loss: 3.1660783773918295

Epoch: 22| Step: 0
Training loss: 3.9574946803372284
Validation loss: 3.165464367031538

Epoch: 6| Step: 1
Training loss: 3.378151587735405
Validation loss: 3.166056458164332

Epoch: 6| Step: 2
Training loss: 4.29348765630959
Validation loss: 3.1634187497979642

Epoch: 6| Step: 3
Training loss: 3.409723593061335
Validation loss: 3.162531332470134

Epoch: 6| Step: 4
Training loss: 3.659851908371558
Validation loss: 3.1623899498813692

Epoch: 6| Step: 5
Training loss: 3.10886674110365
Validation loss: 3.1594354082775262

Epoch: 6| Step: 6
Training loss: 2.9176531803611585
Validation loss: 3.161153220135029

Epoch: 6| Step: 7
Training loss: 3.203392352600172
Validation loss: 3.159171424904748

Epoch: 6| Step: 8
Training loss: 3.3801292719752114
Validation loss: 3.1595055242406156

Epoch: 6| Step: 9
Training loss: 2.9326485687111363
Validation loss: 3.157942574850578

Epoch: 6| Step: 10
Training loss: 3.275472004197374
Validation loss: 3.1575420467858692

Epoch: 6| Step: 11
Training loss: 3.1944981962095294
Validation loss: 3.1589712512102266

Epoch: 6| Step: 12
Training loss: 3.97731679421325
Validation loss: 3.1547938443617904

Epoch: 6| Step: 13
Training loss: 2.5477502173273106
Validation loss: 3.153909116289398

Epoch: 23| Step: 0
Training loss: 2.8944824873591664
Validation loss: 3.1536295639155894

Epoch: 6| Step: 1
Training loss: 3.7894334749129737
Validation loss: 3.1514314640059564

Epoch: 6| Step: 2
Training loss: 3.6971116313512704
Validation loss: 3.1522746068054417

Epoch: 6| Step: 3
Training loss: 3.274651277336135
Validation loss: 3.1510946390202395

Epoch: 6| Step: 4
Training loss: 3.039354325039245
Validation loss: 3.1508983791353056

Epoch: 6| Step: 5
Training loss: 3.1432887685076856
Validation loss: 3.1536194585220567

Epoch: 6| Step: 6
Training loss: 3.990771018084929
Validation loss: 3.155660779974044

Epoch: 6| Step: 7
Training loss: 3.701805942141804
Validation loss: 3.154218440831736

Epoch: 6| Step: 8
Training loss: 3.3903195291903927
Validation loss: 3.149838599663316

Epoch: 6| Step: 9
Training loss: 2.35361712858138
Validation loss: 3.1495201158740023

Epoch: 6| Step: 10
Training loss: 4.03417673251677
Validation loss: 3.1462404286093153

Epoch: 6| Step: 11
Training loss: 3.066682100948249
Validation loss: 3.1469646104765316

Epoch: 6| Step: 12
Training loss: 3.5997823755395433
Validation loss: 3.14437112371867

Epoch: 6| Step: 13
Training loss: 3.4638206579902797
Validation loss: 3.153003697602967

Epoch: 24| Step: 0
Training loss: 2.9433754133915224
Validation loss: 3.1813155081626188

Epoch: 6| Step: 1
Training loss: 3.839518629340625
Validation loss: 3.186861599605047

Epoch: 6| Step: 2
Training loss: 4.109364788782465
Validation loss: 3.1646553986025467

Epoch: 6| Step: 3
Training loss: 3.413410884030842
Validation loss: 3.142555665783479

Epoch: 6| Step: 4
Training loss: 3.705382612603742
Validation loss: 3.1526044636189967

Epoch: 6| Step: 5
Training loss: 4.305451313247217
Validation loss: 3.1595198065705965

Epoch: 6| Step: 6
Training loss: 3.0809545533946143
Validation loss: 3.179784591033806

Epoch: 6| Step: 7
Training loss: 3.417535268270905
Validation loss: 3.1404098872152066

Epoch: 6| Step: 8
Training loss: 3.0979542534777083
Validation loss: 3.1379728539363363

Epoch: 6| Step: 9
Training loss: 2.564887446560841
Validation loss: 3.1366413327419203

Epoch: 6| Step: 10
Training loss: 3.3352107165337608
Validation loss: 3.1386768525237003

Epoch: 6| Step: 11
Training loss: 3.092181800501632
Validation loss: 3.139138352457328

Epoch: 6| Step: 12
Training loss: 3.072698622042099
Validation loss: 3.1476291262093943

Epoch: 6| Step: 13
Training loss: 3.4956572702392554
Validation loss: 3.157205700749502

Epoch: 25| Step: 0
Training loss: 2.412764413208936
Validation loss: 3.1525688428013154

Epoch: 6| Step: 1
Training loss: 3.660414451521737
Validation loss: 3.1524147198213024

Epoch: 6| Step: 2
Training loss: 3.7970510685289183
Validation loss: 3.1521332139286744

Epoch: 6| Step: 3
Training loss: 4.320132812295143
Validation loss: 3.1427705395193954

Epoch: 6| Step: 4
Training loss: 3.315481319783892
Validation loss: 3.1351422183049364

Epoch: 6| Step: 5
Training loss: 3.615803859708085
Validation loss: 3.1337062356776624

Epoch: 6| Step: 6
Training loss: 3.0121050437250014
Validation loss: 3.1346725094801666

Epoch: 6| Step: 7
Training loss: 3.3574738556730894
Validation loss: 3.13484732063601

Epoch: 6| Step: 8
Training loss: 2.62652806810348
Validation loss: 3.129321446358143

Epoch: 6| Step: 9
Training loss: 3.5888682504250125
Validation loss: 3.1283845485888464

Epoch: 6| Step: 10
Training loss: 2.8250428154325555
Validation loss: 3.1263810811958352

Epoch: 6| Step: 11
Training loss: 3.4298831127925387
Validation loss: 3.126898645320441

Epoch: 6| Step: 12
Training loss: 3.384745620342644
Validation loss: 3.1242042151743727

Epoch: 6| Step: 13
Training loss: 4.076206267448942
Validation loss: 3.1247273611275106

Epoch: 26| Step: 0
Training loss: 3.5718333805092475
Validation loss: 3.1223949337369516

Epoch: 6| Step: 1
Training loss: 2.867666427984172
Validation loss: 3.122551342202423

Epoch: 6| Step: 2
Training loss: 2.255429181451172
Validation loss: 3.1197330035804693

Epoch: 6| Step: 3
Training loss: 3.8543741668655733
Validation loss: 3.120920763390592

Epoch: 6| Step: 4
Training loss: 3.7419288243222835
Validation loss: 3.126306504349304

Epoch: 6| Step: 5
Training loss: 4.316486230169644
Validation loss: 3.12038832640596

Epoch: 6| Step: 6
Training loss: 1.9766386115456402
Validation loss: 3.1137053677283717

Epoch: 6| Step: 7
Training loss: 3.3581349057879124
Validation loss: 3.1129005065396873

Epoch: 6| Step: 8
Training loss: 2.771182408728059
Validation loss: 3.112368713923154

Epoch: 6| Step: 9
Training loss: 2.9885285717710635
Validation loss: 3.110989044568875

Epoch: 6| Step: 10
Training loss: 3.8530322630675258
Validation loss: 3.109847959282523

Epoch: 6| Step: 11
Training loss: 3.4897531648369142
Validation loss: 3.108526626849922

Epoch: 6| Step: 12
Training loss: 3.9532095557054396
Validation loss: 3.1086299995388886

Epoch: 6| Step: 13
Training loss: 3.56009110773496
Validation loss: 3.1057784218328526

Epoch: 27| Step: 0
Training loss: 2.674791673765805
Validation loss: 3.1050594973146692

Epoch: 6| Step: 1
Training loss: 3.415742159803386
Validation loss: 3.1025825307470747

Epoch: 6| Step: 2
Training loss: 2.9297355139294723
Validation loss: 3.104117547886991

Epoch: 6| Step: 3
Training loss: 3.7668971528509045
Validation loss: 3.1020149381815316

Epoch: 6| Step: 4
Training loss: 3.501993701399755
Validation loss: 3.1009051414991498

Epoch: 6| Step: 5
Training loss: 3.3890246292889707
Validation loss: 3.1001496526643453

Epoch: 6| Step: 6
Training loss: 3.2681355294521044
Validation loss: 3.0978969036741653

Epoch: 6| Step: 7
Training loss: 3.9891013442769423
Validation loss: 3.099749065693428

Epoch: 6| Step: 8
Training loss: 4.01999909965543
Validation loss: 3.104468805331976

Epoch: 6| Step: 9
Training loss: 3.487168633363556
Validation loss: 3.1008055161406274

Epoch: 6| Step: 10
Training loss: 3.2539071292578345
Validation loss: 3.0939316334237317

Epoch: 6| Step: 11
Training loss: 3.6846115955230996
Validation loss: 3.0927450586984975

Epoch: 6| Step: 12
Training loss: 2.4757186462826826
Validation loss: 3.0953167390934877

Epoch: 6| Step: 13
Training loss: 2.4382132440364552
Validation loss: 3.0939897908554723

Epoch: 28| Step: 0
Training loss: 2.3581830986705565
Validation loss: 3.094940992114854

Epoch: 6| Step: 1
Training loss: 3.1611036995203263
Validation loss: 3.0949204742474072

Epoch: 6| Step: 2
Training loss: 3.0370732639533276
Validation loss: 3.0921897463152574

Epoch: 6| Step: 3
Training loss: 3.6525001533189725
Validation loss: 3.0929738588949904

Epoch: 6| Step: 4
Training loss: 2.9921973803484065
Validation loss: 3.092201156779641

Epoch: 6| Step: 5
Training loss: 3.2814480676361866
Validation loss: 3.092399376929203

Epoch: 6| Step: 6
Training loss: 3.2367975128262327
Validation loss: 3.090781950802064

Epoch: 6| Step: 7
Training loss: 3.6150170028518818
Validation loss: 3.0891995724899877

Epoch: 6| Step: 8
Training loss: 3.7708837741126695
Validation loss: 3.0875951059410265

Epoch: 6| Step: 9
Training loss: 3.932624583856653
Validation loss: 3.0865943102755637

Epoch: 6| Step: 10
Training loss: 3.460913251184803
Validation loss: 3.085424623332815

Epoch: 6| Step: 11
Training loss: 3.4131483866336207
Validation loss: 3.0838297247858693

Epoch: 6| Step: 12
Training loss: 3.868830784461107
Validation loss: 3.086457870761507

Epoch: 6| Step: 13
Training loss: 2.6748075398168436
Validation loss: 3.0900047771277417

Epoch: 29| Step: 0
Training loss: 3.428240286071764
Validation loss: 3.0925924091703254

Epoch: 6| Step: 1
Training loss: 3.1209296611864294
Validation loss: 3.101772949339514

Epoch: 6| Step: 2
Training loss: 3.518029776494335
Validation loss: 3.116961906675682

Epoch: 6| Step: 3
Training loss: 2.900727963336989
Validation loss: 3.086889965007968

Epoch: 6| Step: 4
Training loss: 3.1383540355170405
Validation loss: 3.0777847462609493

Epoch: 6| Step: 5
Training loss: 3.9261399138476856
Validation loss: 3.079802524962528

Epoch: 6| Step: 6
Training loss: 3.5311323838353057
Validation loss: 3.0798071964114984

Epoch: 6| Step: 7
Training loss: 2.6031044179553784
Validation loss: 3.0767391523365792

Epoch: 6| Step: 8
Training loss: 3.0781411107605035
Validation loss: 3.0763782946189693

Epoch: 6| Step: 9
Training loss: 3.317120047272938
Validation loss: 3.0765720012536435

Epoch: 6| Step: 10
Training loss: 3.1636331149137393
Validation loss: 3.0759054197408773

Epoch: 6| Step: 11
Training loss: 3.4561784457479243
Validation loss: 3.0749600287560015

Epoch: 6| Step: 12
Training loss: 3.970535477431106
Validation loss: 3.0747369376755564

Epoch: 6| Step: 13
Training loss: 3.5880554194598546
Validation loss: 3.0723707801211773

Epoch: 30| Step: 0
Training loss: 2.34534491631599
Validation loss: 3.0700842563701394

Epoch: 6| Step: 1
Training loss: 3.6147521288299784
Validation loss: 3.069751433465132

Epoch: 6| Step: 2
Training loss: 3.55821076895998
Validation loss: 3.068389165749904

Epoch: 6| Step: 3
Training loss: 3.650224987045961
Validation loss: 3.0671224568277693

Epoch: 6| Step: 4
Training loss: 3.8651475246053533
Validation loss: 3.0672096835924623

Epoch: 6| Step: 5
Training loss: 2.9514261839261775
Validation loss: 3.0633810733497375

Epoch: 6| Step: 6
Training loss: 2.968216215632982
Validation loss: 3.06397726840445

Epoch: 6| Step: 7
Training loss: 3.1293973882539814
Validation loss: 3.062588963106926

Epoch: 6| Step: 8
Training loss: 3.7503677187874587
Validation loss: 3.062127779452086

Epoch: 6| Step: 9
Training loss: 3.9903892453425773
Validation loss: 3.0602734181132365

Epoch: 6| Step: 10
Training loss: 3.1112459774152255
Validation loss: 3.0613751567160197

Epoch: 6| Step: 11
Training loss: 2.7876961403851324
Validation loss: 3.066455423851594

Epoch: 6| Step: 12
Training loss: 3.01443932502794
Validation loss: 3.0690965843415734

Epoch: 6| Step: 13
Training loss: 3.837011369542707
Validation loss: 3.0631818583617196

Epoch: 31| Step: 0
Training loss: 3.4442002626914605
Validation loss: 3.0693297466743816

Epoch: 6| Step: 1
Training loss: 3.399634420150765
Validation loss: 3.0616870778104484

Epoch: 6| Step: 2
Training loss: 3.0728808039927085
Validation loss: 3.0574025542457406

Epoch: 6| Step: 3
Training loss: 3.3075533225215343
Validation loss: 3.0556179484625074

Epoch: 6| Step: 4
Training loss: 3.2088925423370913
Validation loss: 3.0561121824839557

Epoch: 6| Step: 5
Training loss: 3.014150624744467
Validation loss: 3.0519117753501157

Epoch: 6| Step: 6
Training loss: 3.057470434487253
Validation loss: 3.0523750703042754

Epoch: 6| Step: 7
Training loss: 3.848380424395325
Validation loss: 3.052138716988153

Epoch: 6| Step: 8
Training loss: 3.9232222837960293
Validation loss: 3.051208357794691

Epoch: 6| Step: 9
Training loss: 2.6765183818719676
Validation loss: 3.0496429533603493

Epoch: 6| Step: 10
Training loss: 3.2628702472464655
Validation loss: 3.049362638702296

Epoch: 6| Step: 11
Training loss: 3.1044662296905505
Validation loss: 3.0487723392489725

Epoch: 6| Step: 12
Training loss: 3.936832795305246
Validation loss: 3.046658412575443

Epoch: 6| Step: 13
Training loss: 2.9490837419946834
Validation loss: 3.0455761636128003

Epoch: 32| Step: 0
Training loss: 2.7849686012347217
Validation loss: 3.0474664013710346

Epoch: 6| Step: 1
Training loss: 3.48641087196094
Validation loss: 3.0452965647911383

Epoch: 6| Step: 2
Training loss: 3.0070468473042324
Validation loss: 3.0447921764773054

Epoch: 6| Step: 3
Training loss: 3.3825353636658693
Validation loss: 3.043547537762377

Epoch: 6| Step: 4
Training loss: 3.10336136239489
Validation loss: 3.045065376874039

Epoch: 6| Step: 5
Training loss: 3.8406019267544558
Validation loss: 3.0445801916438424

Epoch: 6| Step: 6
Training loss: 2.596501832446813
Validation loss: 3.0418139177776182

Epoch: 6| Step: 7
Training loss: 2.09017525298617
Validation loss: 3.043732185528099

Epoch: 6| Step: 8
Training loss: 3.7226380610947305
Validation loss: 3.04205086428495

Epoch: 6| Step: 9
Training loss: 2.9370613582281644
Validation loss: 3.0406191376643483

Epoch: 6| Step: 10
Training loss: 4.21330667350479
Validation loss: 3.039607367537603

Epoch: 6| Step: 11
Training loss: 3.6491494637904367
Validation loss: 3.0400184818889606

Epoch: 6| Step: 12
Training loss: 3.6482362221981988
Validation loss: 3.037054024811773

Epoch: 6| Step: 13
Training loss: 3.492018727570225
Validation loss: 3.0391819832867197

Epoch: 33| Step: 0
Training loss: 3.1618478818877804
Validation loss: 3.0470453669580375

Epoch: 6| Step: 1
Training loss: 3.8223197671976585
Validation loss: 3.0494001174841734

Epoch: 6| Step: 2
Training loss: 3.9806534684047117
Validation loss: 3.0367527904107567

Epoch: 6| Step: 3
Training loss: 1.8303949983516794
Validation loss: 3.041283540509357

Epoch: 6| Step: 4
Training loss: 3.8401077505729893
Validation loss: 3.0468104824474564

Epoch: 6| Step: 5
Training loss: 3.203500567492582
Validation loss: 3.058400492302252

Epoch: 6| Step: 6
Training loss: 2.505631398558921
Validation loss: 3.069996454920193

Epoch: 6| Step: 7
Training loss: 4.082500113249553
Validation loss: 3.0767723214975864

Epoch: 6| Step: 8
Training loss: 3.1444417810447507
Validation loss: 3.053318505494544

Epoch: 6| Step: 9
Training loss: 3.399615344559851
Validation loss: 3.0390850753487677

Epoch: 6| Step: 10
Training loss: 3.813974314306591
Validation loss: 3.0354521362719664

Epoch: 6| Step: 11
Training loss: 3.0326632321949676
Validation loss: 3.032227262544722

Epoch: 6| Step: 12
Training loss: 3.1414144102729127
Validation loss: 3.0301937169600066

Epoch: 6| Step: 13
Training loss: 2.755834978132177
Validation loss: 3.0280971895494764

Epoch: 34| Step: 0
Training loss: 2.8316874117780833
Validation loss: 3.025353059781927

Epoch: 6| Step: 1
Training loss: 4.028781578704799
Validation loss: 3.032933352902187

Epoch: 6| Step: 2
Training loss: 3.6980661854492127
Validation loss: 3.054731039880367

Epoch: 6| Step: 3
Training loss: 3.90275172944764
Validation loss: 3.045203933628849

Epoch: 6| Step: 4
Training loss: 2.697234687379144
Validation loss: 3.022624256706618

Epoch: 6| Step: 5
Training loss: 2.987324001602732
Validation loss: 3.022269469747302

Epoch: 6| Step: 6
Training loss: 3.236783812262824
Validation loss: 3.0231787021337424

Epoch: 6| Step: 7
Training loss: 3.4029085060664177
Validation loss: 3.0226179837781277

Epoch: 6| Step: 8
Training loss: 2.4495676087274183
Validation loss: 3.025606440346875

Epoch: 6| Step: 9
Training loss: 2.5366381529894366
Validation loss: 3.0306718209552908

Epoch: 6| Step: 10
Training loss: 3.2164499898349694
Validation loss: 3.036500237795127

Epoch: 6| Step: 11
Training loss: 4.3348358679370005
Validation loss: 3.0312633626169934

Epoch: 6| Step: 12
Training loss: 3.3628220017554784
Validation loss: 3.023274983656818

Epoch: 6| Step: 13
Training loss: 2.9991108848370946
Validation loss: 3.0201797666602945

Epoch: 35| Step: 0
Training loss: 2.576741535173234
Validation loss: 3.0205354118609344

Epoch: 6| Step: 1
Training loss: 2.9532578857233927
Validation loss: 3.0214776389844635

Epoch: 6| Step: 2
Training loss: 3.1283171786211437
Validation loss: 3.022713638586239

Epoch: 6| Step: 3
Training loss: 2.59536536597529
Validation loss: 3.022273152847359

Epoch: 6| Step: 4
Training loss: 2.9786179221674813
Validation loss: 3.022855828577346

Epoch: 6| Step: 5
Training loss: 3.3496677404718245
Validation loss: 3.0245070777992944

Epoch: 6| Step: 6
Training loss: 3.989146169643419
Validation loss: 3.018704534927233

Epoch: 6| Step: 7
Training loss: 4.061699656364407
Validation loss: 3.0142185255917413

Epoch: 6| Step: 8
Training loss: 3.577194692618293
Validation loss: 3.012073828156557

Epoch: 6| Step: 9
Training loss: 4.145880591859588
Validation loss: 3.0094147510987224

Epoch: 6| Step: 10
Training loss: 2.9730344674594926
Validation loss: 3.0108017134264053

Epoch: 6| Step: 11
Training loss: 3.2447902297766347
Validation loss: 3.00964837344545

Epoch: 6| Step: 12
Training loss: 2.799836024523792
Validation loss: 3.008328589324669

Epoch: 6| Step: 13
Training loss: 3.521191204475287
Validation loss: 3.0077804114115376

Epoch: 36| Step: 0
Training loss: 3.3104317884217846
Validation loss: 3.0115808250770533

Epoch: 6| Step: 1
Training loss: 3.008225132765474
Validation loss: 3.0186816458025882

Epoch: 6| Step: 2
Training loss: 3.7491634707420642
Validation loss: 3.0290766118417363

Epoch: 6| Step: 3
Training loss: 3.1662102085870636
Validation loss: 3.010449404445695

Epoch: 6| Step: 4
Training loss: 3.8184017091243363
Validation loss: 3.0041521591194185

Epoch: 6| Step: 5
Training loss: 3.0998253557786324
Validation loss: 3.0019525733218315

Epoch: 6| Step: 6
Training loss: 3.220322308254714
Validation loss: 3.0016620673771697

Epoch: 6| Step: 7
Training loss: 3.16181048087449
Validation loss: 3.0011383241880667

Epoch: 6| Step: 8
Training loss: 3.1233010823780796
Validation loss: 3.000245909713003

Epoch: 6| Step: 9
Training loss: 2.794667656917736
Validation loss: 3.000397819886165

Epoch: 6| Step: 10
Training loss: 3.953606014614864
Validation loss: 2.9982680667463693

Epoch: 6| Step: 11
Training loss: 3.3198715814779467
Validation loss: 2.9995726790359445

Epoch: 6| Step: 12
Training loss: 3.1208636565490258
Validation loss: 2.9979012199576913

Epoch: 6| Step: 13
Training loss: 2.899424094532577
Validation loss: 2.9983167275615537

Epoch: 37| Step: 0
Training loss: 3.3179693593455113
Validation loss: 2.997121079004364

Epoch: 6| Step: 1
Training loss: 2.763313059883923
Validation loss: 2.9977854071257077

Epoch: 6| Step: 2
Training loss: 3.293121225757069
Validation loss: 3.0003108424141574

Epoch: 6| Step: 3
Training loss: 3.8345211234381993
Validation loss: 3.0005751813832315

Epoch: 6| Step: 4
Training loss: 3.7027173039187393
Validation loss: 2.995761370575783

Epoch: 6| Step: 5
Training loss: 3.1856916197093263
Validation loss: 2.995102948048144

Epoch: 6| Step: 6
Training loss: 3.885586214158828
Validation loss: 2.994827658645192

Epoch: 6| Step: 7
Training loss: 3.103057731521644
Validation loss: 2.992184328205899

Epoch: 6| Step: 8
Training loss: 3.625298586419916
Validation loss: 2.9917091962570224

Epoch: 6| Step: 9
Training loss: 3.3103285095755366
Validation loss: 2.991836597103252

Epoch: 6| Step: 10
Training loss: 2.5696874165711825
Validation loss: 2.9884024959864686

Epoch: 6| Step: 11
Training loss: 3.1946579092454472
Validation loss: 2.9872428585324333

Epoch: 6| Step: 12
Training loss: 3.113452327531769
Validation loss: 2.9883675610177134

Epoch: 6| Step: 13
Training loss: 2.3093227519937476
Validation loss: 2.988628119226099

Epoch: 38| Step: 0
Training loss: 3.102340331660481
Validation loss: 2.9917874615693756

Epoch: 6| Step: 1
Training loss: 3.326661697134257
Validation loss: 2.986569376608288

Epoch: 6| Step: 2
Training loss: 3.6031744736039975
Validation loss: 2.9821412593605303

Epoch: 6| Step: 3
Training loss: 3.2512591930407564
Validation loss: 2.9832091796549562

Epoch: 6| Step: 4
Training loss: 2.9662606493681962
Validation loss: 2.9843585840645743

Epoch: 6| Step: 5
Training loss: 2.9231244847833695
Validation loss: 2.9830632659215586

Epoch: 6| Step: 6
Training loss: 4.1101263831539345
Validation loss: 2.982616881473916

Epoch: 6| Step: 7
Training loss: 3.5017837338773017
Validation loss: 2.9819367261536756

Epoch: 6| Step: 8
Training loss: 2.638863602455747
Validation loss: 2.9806529980697496

Epoch: 6| Step: 9
Training loss: 3.708981032367504
Validation loss: 2.9826195898432086

Epoch: 6| Step: 10
Training loss: 3.067837481972586
Validation loss: 2.9791498187313215

Epoch: 6| Step: 11
Training loss: 2.8281593109915835
Validation loss: 2.980853547093798

Epoch: 6| Step: 12
Training loss: 3.175085387996571
Validation loss: 2.9814242586298083

Epoch: 6| Step: 13
Training loss: 3.5430577108198094
Validation loss: 2.9803683700390993

Epoch: 39| Step: 0
Training loss: 3.3252118036026457
Validation loss: 2.9817353480727555

Epoch: 6| Step: 1
Training loss: 3.101853671687548
Validation loss: 2.981902246749334

Epoch: 6| Step: 2
Training loss: 3.564125359502254
Validation loss: 2.979951189143381

Epoch: 6| Step: 3
Training loss: 2.9471476779642347
Validation loss: 2.9789389407011972

Epoch: 6| Step: 4
Training loss: 2.6371391808903843
Validation loss: 2.9794862888251026

Epoch: 6| Step: 5
Training loss: 4.060679805574239
Validation loss: 2.9836538489696753

Epoch: 6| Step: 6
Training loss: 3.7346220692899097
Validation loss: 2.9921773248863235

Epoch: 6| Step: 7
Training loss: 3.571404154557822
Validation loss: 3.015827666701745

Epoch: 6| Step: 8
Training loss: 3.4558041221157385
Validation loss: 3.0013529331472237

Epoch: 6| Step: 9
Training loss: 2.8619156686659486
Validation loss: 3.0159395157916102

Epoch: 6| Step: 10
Training loss: 3.3085680963992177
Validation loss: 3.0005202748072564

Epoch: 6| Step: 11
Training loss: 2.739444414878585
Validation loss: 2.9754037175184522

Epoch: 6| Step: 12
Training loss: 3.381588192313277
Validation loss: 2.9722891013752815

Epoch: 6| Step: 13
Training loss: 2.2955819986430233
Validation loss: 2.9710191570165287

Epoch: 40| Step: 0
Training loss: 3.400906352242536
Validation loss: 2.969799423183186

Epoch: 6| Step: 1
Training loss: 3.14672729387984
Validation loss: 2.970753106328666

Epoch: 6| Step: 2
Training loss: 3.4060307703425856
Validation loss: 2.970127454104007

Epoch: 6| Step: 3
Training loss: 3.380904930684918
Validation loss: 2.9727617843652254

Epoch: 6| Step: 4
Training loss: 3.122465097371267
Validation loss: 2.9694821640633315

Epoch: 6| Step: 5
Training loss: 3.019781854847581
Validation loss: 2.9673414428260108

Epoch: 6| Step: 6
Training loss: 3.735168117431733
Validation loss: 2.9682504748564393

Epoch: 6| Step: 7
Training loss: 3.2616269401375226
Validation loss: 2.9677562317586346

Epoch: 6| Step: 8
Training loss: 2.727416596085889
Validation loss: 2.9649735995876343

Epoch: 6| Step: 9
Training loss: 3.3653375274382187
Validation loss: 2.963400504871945

Epoch: 6| Step: 10
Training loss: 2.4559000440567007
Validation loss: 2.9640813882796677

Epoch: 6| Step: 11
Training loss: 3.58619426398114
Validation loss: 2.963070614861187

Epoch: 6| Step: 12
Training loss: 3.487763267069125
Validation loss: 2.9624379782334733

Epoch: 6| Step: 13
Training loss: 3.388250970122438
Validation loss: 2.961592634652213

Epoch: 41| Step: 0
Training loss: 2.8990530506871104
Validation loss: 2.961026794193672

Epoch: 6| Step: 1
Training loss: 3.2826047008170467
Validation loss: 2.96008558488541

Epoch: 6| Step: 2
Training loss: 2.7079120210473806
Validation loss: 2.9587079275627546

Epoch: 6| Step: 3
Training loss: 3.7739426805826346
Validation loss: 2.9575657493619563

Epoch: 6| Step: 4
Training loss: 3.75827486679264
Validation loss: 2.9586021223816577

Epoch: 6| Step: 5
Training loss: 3.035478925797371
Validation loss: 2.9534173549347367

Epoch: 6| Step: 6
Training loss: 3.445310423973652
Validation loss: 2.9533750557647367

Epoch: 6| Step: 7
Training loss: 2.987725259755857
Validation loss: 2.9523788592946323

Epoch: 6| Step: 8
Training loss: 2.933955874994717
Validation loss: 2.9568313611483505

Epoch: 6| Step: 9
Training loss: 4.098325312915435
Validation loss: 2.9647270375406416

Epoch: 6| Step: 10
Training loss: 2.8057528626795207
Validation loss: 2.98646619122366

Epoch: 6| Step: 11
Training loss: 3.394501188823308
Validation loss: 2.950365351749713

Epoch: 6| Step: 12
Training loss: 3.1122251703346047
Validation loss: 2.952019314272193

Epoch: 6| Step: 13
Training loss: 2.5998208571120256
Validation loss: 2.954102293207832

Epoch: 42| Step: 0
Training loss: 3.127630423701103
Validation loss: 2.956301115200664

Epoch: 6| Step: 1
Training loss: 3.2302629804289142
Validation loss: 2.9613561682478666

Epoch: 6| Step: 2
Training loss: 3.1815710838778344
Validation loss: 2.9724723428404296

Epoch: 6| Step: 3
Training loss: 2.8925435066083396
Validation loss: 2.979142414742674

Epoch: 6| Step: 4
Training loss: 3.7061537577337984
Validation loss: 2.9652572171244818

Epoch: 6| Step: 5
Training loss: 3.751832641382783
Validation loss: 2.9570500422592434

Epoch: 6| Step: 6
Training loss: 2.8451175964401263
Validation loss: 2.9494310245724944

Epoch: 6| Step: 7
Training loss: 3.090203458390014
Validation loss: 2.9482938469452287

Epoch: 6| Step: 8
Training loss: 3.116952069792428
Validation loss: 2.946674160008426

Epoch: 6| Step: 9
Training loss: 3.159078407138115
Validation loss: 2.948885639091711

Epoch: 6| Step: 10
Training loss: 3.458633654932711
Validation loss: 2.9490608036672397

Epoch: 6| Step: 11
Training loss: 3.091784845305877
Validation loss: 2.9486441994855124

Epoch: 6| Step: 12
Training loss: 3.1895775102046846
Validation loss: 2.9497984787616702

Epoch: 6| Step: 13
Training loss: 3.8726786151276347
Validation loss: 2.9483010414576616

Epoch: 43| Step: 0
Training loss: 3.616507612560292
Validation loss: 2.94812505346338

Epoch: 6| Step: 1
Training loss: 3.472366235077719
Validation loss: 2.946225888116017

Epoch: 6| Step: 2
Training loss: 3.0608340033130514
Validation loss: 2.9429077696492207

Epoch: 6| Step: 3
Training loss: 3.6420227772871385
Validation loss: 2.9476163832874858

Epoch: 6| Step: 4
Training loss: 3.483957308379557
Validation loss: 2.942282728554544

Epoch: 6| Step: 5
Training loss: 3.166457336600978
Validation loss: 2.944936206523016

Epoch: 6| Step: 6
Training loss: 2.8792259007795353
Validation loss: 2.943255995217938

Epoch: 6| Step: 7
Training loss: 2.8257031266199992
Validation loss: 2.9419327164128535

Epoch: 6| Step: 8
Training loss: 3.7414053017819584
Validation loss: 2.9372529541454457

Epoch: 6| Step: 9
Training loss: 3.0215670692061325
Validation loss: 2.936202978405324

Epoch: 6| Step: 10
Training loss: 3.574120291932835
Validation loss: 2.9344135416654464

Epoch: 6| Step: 11
Training loss: 2.7633105577635426
Validation loss: 2.9346596314994726

Epoch: 6| Step: 12
Training loss: 2.997510831048151
Validation loss: 2.9346939854465037

Epoch: 6| Step: 13
Training loss: 2.390967450515851
Validation loss: 2.9339390537508216

Epoch: 44| Step: 0
Training loss: 3.43730440450273
Validation loss: 2.9320733164242756

Epoch: 6| Step: 1
Training loss: 3.640686034644631
Validation loss: 2.931670412897672

Epoch: 6| Step: 2
Training loss: 2.8824914272740005
Validation loss: 2.931429454896153

Epoch: 6| Step: 3
Training loss: 2.7266031606533456
Validation loss: 2.9317745212513544

Epoch: 6| Step: 4
Training loss: 3.6487931072097237
Validation loss: 2.931282359495015

Epoch: 6| Step: 5
Training loss: 3.673842921371719
Validation loss: 2.930206243277033

Epoch: 6| Step: 6
Training loss: 2.9846689768493904
Validation loss: 2.930562742034893

Epoch: 6| Step: 7
Training loss: 3.4144233844589107
Validation loss: 2.9283399906358603

Epoch: 6| Step: 8
Training loss: 3.5742934589186643
Validation loss: 2.9285583218891538

Epoch: 6| Step: 9
Training loss: 2.809698871618812
Validation loss: 2.9281265092610917

Epoch: 6| Step: 10
Training loss: 2.928807485018733
Validation loss: 2.93121142146089

Epoch: 6| Step: 11
Training loss: 3.255961891944817
Validation loss: 2.9359252066715253

Epoch: 6| Step: 12
Training loss: 2.9558699833379745
Validation loss: 2.9329979651228655

Epoch: 6| Step: 13
Training loss: 2.752062977425093
Validation loss: 2.9366007423113145

Epoch: 45| Step: 0
Training loss: 3.2046862263260816
Validation loss: 2.931968539290745

Epoch: 6| Step: 1
Training loss: 3.1932721700631173
Validation loss: 2.931732880452188

Epoch: 6| Step: 2
Training loss: 3.53409832884214
Validation loss: 2.9384422248575097

Epoch: 6| Step: 3
Training loss: 2.4399317813154418
Validation loss: 2.9421133043996583

Epoch: 6| Step: 4
Training loss: 3.4329436189025833
Validation loss: 2.9330821331991612

Epoch: 6| Step: 5
Training loss: 4.083899374414335
Validation loss: 2.926168151926956

Epoch: 6| Step: 6
Training loss: 2.991628729137847
Validation loss: 2.920393044985208

Epoch: 6| Step: 7
Training loss: 2.8374792694813347
Validation loss: 2.920992748934204

Epoch: 6| Step: 8
Training loss: 2.866233396685857
Validation loss: 2.919568150377374

Epoch: 6| Step: 9
Training loss: 3.199396112204315
Validation loss: 2.918223494391338

Epoch: 6| Step: 10
Training loss: 3.5663896708609713
Validation loss: 2.9197446347827176

Epoch: 6| Step: 11
Training loss: 3.0303226900907934
Validation loss: 2.9183004318457866

Epoch: 6| Step: 12
Training loss: 3.10365635989118
Validation loss: 2.9192991854785326

Epoch: 6| Step: 13
Training loss: 3.332662149249095
Validation loss: 2.9170109881070014

Epoch: 46| Step: 0
Training loss: 2.328433944377916
Validation loss: 2.917418501385451

Epoch: 6| Step: 1
Training loss: 3.5705921556059583
Validation loss: 2.9168081140865607

Epoch: 6| Step: 2
Training loss: 3.2163823873446846
Validation loss: 2.9160906549586096

Epoch: 6| Step: 3
Training loss: 3.536895020855129
Validation loss: 2.916848635527205

Epoch: 6| Step: 4
Training loss: 3.7991928749215265
Validation loss: 2.914256828972308

Epoch: 6| Step: 5
Training loss: 3.022583518061532
Validation loss: 2.9147019169046393

Epoch: 6| Step: 6
Training loss: 3.0822958016805617
Validation loss: 2.914226368690401

Epoch: 6| Step: 7
Training loss: 2.6926819279235006
Validation loss: 2.9130403632411883

Epoch: 6| Step: 8
Training loss: 3.5844790083570777
Validation loss: 2.912152053475043

Epoch: 6| Step: 9
Training loss: 3.309820855124576
Validation loss: 2.91054677391817

Epoch: 6| Step: 10
Training loss: 2.589160489591759
Validation loss: 2.9109368209508255

Epoch: 6| Step: 11
Training loss: 3.5613849969665807
Validation loss: 2.9075983267167285

Epoch: 6| Step: 12
Training loss: 3.222104148966875
Validation loss: 2.9072125821460486

Epoch: 6| Step: 13
Training loss: 2.994560714883248
Validation loss: 2.906579665708709

Epoch: 47| Step: 0
Training loss: 3.310533767719259
Validation loss: 2.9054289129964506

Epoch: 6| Step: 1
Training loss: 1.760648753500574
Validation loss: 2.907793675749366

Epoch: 6| Step: 2
Training loss: 3.7598786255340158
Validation loss: 2.9095035688511266

Epoch: 6| Step: 3
Training loss: 2.8152247475705194
Validation loss: 2.9077062135249094

Epoch: 6| Step: 4
Training loss: 2.44901217573573
Validation loss: 2.91072675672752

Epoch: 6| Step: 5
Training loss: 3.4080078069033326
Validation loss: 2.915892228942735

Epoch: 6| Step: 6
Training loss: 2.626104758166875
Validation loss: 2.9023491328260507

Epoch: 6| Step: 7
Training loss: 2.5996051561878804
Validation loss: 2.9016427896598227

Epoch: 6| Step: 8
Training loss: 3.9063842750359377
Validation loss: 2.9023414613684397

Epoch: 6| Step: 9
Training loss: 3.4609140778517546
Validation loss: 2.9061603530110918

Epoch: 6| Step: 10
Training loss: 3.917472404767423
Validation loss: 2.9014669041761443

Epoch: 6| Step: 11
Training loss: 3.5236970590198466
Validation loss: 2.9055451274793893

Epoch: 6| Step: 12
Training loss: 3.4274295682230136
Validation loss: 2.9062861558189232

Epoch: 6| Step: 13
Training loss: 2.9811769296580324
Validation loss: 2.9146686440287475

Epoch: 48| Step: 0
Training loss: 2.797261131526991
Validation loss: 2.9203125651727095

Epoch: 6| Step: 1
Training loss: 2.984680479702638
Validation loss: 2.9232133712323187

Epoch: 6| Step: 2
Training loss: 3.1330627189273472
Validation loss: 2.9249289977391784

Epoch: 6| Step: 3
Training loss: 3.4092398304634792
Validation loss: 2.9125341511371525

Epoch: 6| Step: 4
Training loss: 3.339735526846733
Validation loss: 2.903743132437095

Epoch: 6| Step: 5
Training loss: 4.151748858638379
Validation loss: 2.901243887692502

Epoch: 6| Step: 6
Training loss: 3.273125462920801
Validation loss: 2.8996523178756126

Epoch: 6| Step: 7
Training loss: 2.976204117153333
Validation loss: 2.899204048526684

Epoch: 6| Step: 8
Training loss: 3.0055635045154667
Validation loss: 2.899006288379629

Epoch: 6| Step: 9
Training loss: 2.6648120888311277
Validation loss: 2.8965135048365185

Epoch: 6| Step: 10
Training loss: 3.324758053344822
Validation loss: 2.8967776062933392

Epoch: 6| Step: 11
Training loss: 3.1306274099677696
Validation loss: 2.8951426069063717

Epoch: 6| Step: 12
Training loss: 3.5466354221985044
Validation loss: 2.8968276108695563

Epoch: 6| Step: 13
Training loss: 2.5246144670815505
Validation loss: 2.902253515071663

Epoch: 49| Step: 0
Training loss: 2.685990109019982
Validation loss: 2.905694339244692

Epoch: 6| Step: 1
Training loss: 3.4928480372754587
Validation loss: 2.9049628154276808

Epoch: 6| Step: 2
Training loss: 2.8148769930428426
Validation loss: 2.9090533947023194

Epoch: 6| Step: 3
Training loss: 2.7451184902778394
Validation loss: 2.9039602469862986

Epoch: 6| Step: 4
Training loss: 2.7450565642207603
Validation loss: 2.8998506634160597

Epoch: 6| Step: 5
Training loss: 3.0309042192640367
Validation loss: 2.8863470783026335

Epoch: 6| Step: 6
Training loss: 3.606529137768032
Validation loss: 2.8906688612581584

Epoch: 6| Step: 7
Training loss: 2.740255343519426
Validation loss: 2.8929113089388063

Epoch: 6| Step: 8
Training loss: 3.7624457776797886
Validation loss: 2.9036101932215446

Epoch: 6| Step: 9
Training loss: 3.548372196350807
Validation loss: 2.9133188315473855

Epoch: 6| Step: 10
Training loss: 3.3380421916016276
Validation loss: 2.9306790323052088

Epoch: 6| Step: 11
Training loss: 3.1130375593243587
Validation loss: 2.93359595569959

Epoch: 6| Step: 12
Training loss: 3.2975175421235887
Validation loss: 2.9179047489671586

Epoch: 6| Step: 13
Training loss: 4.032916057429107
Validation loss: 2.909399211646176

Epoch: 50| Step: 0
Training loss: 3.425431584920176
Validation loss: 2.892127643174398

Epoch: 6| Step: 1
Training loss: 2.905200235422328
Validation loss: 2.884480997067823

Epoch: 6| Step: 2
Training loss: 2.8127734581143153
Validation loss: 2.8822202023176855

Epoch: 6| Step: 3
Training loss: 3.921686297128563
Validation loss: 2.879337722979809

Epoch: 6| Step: 4
Training loss: 3.5164193167334568
Validation loss: 2.880239932492478

Epoch: 6| Step: 5
Training loss: 2.9514468637394677
Validation loss: 2.8808527969443762

Epoch: 6| Step: 6
Training loss: 3.717238559829212
Validation loss: 2.8857757752409627

Epoch: 6| Step: 7
Training loss: 2.394000394389312
Validation loss: 2.875073636624746

Epoch: 6| Step: 8
Training loss: 2.2793139250312917
Validation loss: 2.875562235681647

Epoch: 6| Step: 9
Training loss: 2.982272540977265
Validation loss: 2.8732442581895237

Epoch: 6| Step: 10
Training loss: 3.4743576773472244
Validation loss: 2.875991120780284

Epoch: 6| Step: 11
Training loss: 3.0441321914381767
Validation loss: 2.8820328094803145

Epoch: 6| Step: 12
Training loss: 3.2411328174432494
Validation loss: 2.8834510618671456

Epoch: 6| Step: 13
Training loss: 3.7754671628784737
Validation loss: 2.890247830985964

Epoch: 51| Step: 0
Training loss: 2.370527573787822
Validation loss: 2.8716480980366335

Epoch: 6| Step: 1
Training loss: 3.1935618485123216
Validation loss: 2.8680209966604835

Epoch: 6| Step: 2
Training loss: 3.340322002947324
Validation loss: 2.8665183456304133

Epoch: 6| Step: 3
Training loss: 2.7781900439033946
Validation loss: 2.8673944534093883

Epoch: 6| Step: 4
Training loss: 3.0810178533852115
Validation loss: 2.867653450919858

Epoch: 6| Step: 5
Training loss: 3.7455097017662884
Validation loss: 2.8683465197275804

Epoch: 6| Step: 6
Training loss: 3.3618830345271973
Validation loss: 2.868483158635567

Epoch: 6| Step: 7
Training loss: 3.257421968686292
Validation loss: 2.865764402334691

Epoch: 6| Step: 8
Training loss: 3.3758718989145398
Validation loss: 2.8672699653913223

Epoch: 6| Step: 9
Training loss: 3.383375724439219
Validation loss: 2.8662132952308452

Epoch: 6| Step: 10
Training loss: 3.7011908135646734
Validation loss: 2.8661771947244783

Epoch: 6| Step: 11
Training loss: 2.7884866242836086
Validation loss: 2.864453328483628

Epoch: 6| Step: 12
Training loss: 3.0572307175513194
Validation loss: 2.8631400497260215

Epoch: 6| Step: 13
Training loss: 2.3052868080026134
Validation loss: 2.8609312813845733

Epoch: 52| Step: 0
Training loss: 2.381221452677061
Validation loss: 2.861670083321462

Epoch: 6| Step: 1
Training loss: 3.49566081685692
Validation loss: 2.862317842866473

Epoch: 6| Step: 2
Training loss: 3.3552018615666555
Validation loss: 2.860988085508066

Epoch: 6| Step: 3
Training loss: 2.6967323875513416
Validation loss: 2.8589438553755344

Epoch: 6| Step: 4
Training loss: 2.9487341476344207
Validation loss: 2.859162025313636

Epoch: 6| Step: 5
Training loss: 3.1773614647031225
Validation loss: 2.8688311673022415

Epoch: 6| Step: 6
Training loss: 3.2735387381328103
Validation loss: 2.8646324128153666

Epoch: 6| Step: 7
Training loss: 3.191436580667912
Validation loss: 2.8637169607150157

Epoch: 6| Step: 8
Training loss: 3.8743347089075186
Validation loss: 2.8576811824620956

Epoch: 6| Step: 9
Training loss: 3.180040944393644
Validation loss: 2.8565919259413826

Epoch: 6| Step: 10
Training loss: 2.834041918243333
Validation loss: 2.8547318454893857

Epoch: 6| Step: 11
Training loss: 3.1274803998959606
Validation loss: 2.855510623995702

Epoch: 6| Step: 12
Training loss: 3.36703512108083
Validation loss: 2.8540972353977776

Epoch: 6| Step: 13
Training loss: 3.1295438157387903
Validation loss: 2.8517325374911735

Epoch: 53| Step: 0
Training loss: 2.657189954612771
Validation loss: 2.8522648149735166

Epoch: 6| Step: 1
Training loss: 3.0916667050535573
Validation loss: 2.8518377643491126

Epoch: 6| Step: 2
Training loss: 3.659717187429621
Validation loss: 2.85083766911519

Epoch: 6| Step: 3
Training loss: 2.900002768942728
Validation loss: 2.8520138727040067

Epoch: 6| Step: 4
Training loss: 2.9824628046471116
Validation loss: 2.8508679811670015

Epoch: 6| Step: 5
Training loss: 3.4531621456305976
Validation loss: 2.8514662203378207

Epoch: 6| Step: 6
Training loss: 2.890575346649134
Validation loss: 2.851709678224221

Epoch: 6| Step: 7
Training loss: 3.436097569919947
Validation loss: 2.8485286732323174

Epoch: 6| Step: 8
Training loss: 3.674269264907307
Validation loss: 2.8483969605941133

Epoch: 6| Step: 9
Training loss: 2.788997446364707
Validation loss: 2.8483838633380727

Epoch: 6| Step: 10
Training loss: 3.7319846703152164
Validation loss: 2.846610693826419

Epoch: 6| Step: 11
Training loss: 2.4343552477210335
Validation loss: 2.8458803372414083

Epoch: 6| Step: 12
Training loss: 3.241113103233088
Validation loss: 2.8452398009826205

Epoch: 6| Step: 13
Training loss: 2.737726566223115
Validation loss: 2.845048081901659

Epoch: 54| Step: 0
Training loss: 3.5645545255268716
Validation loss: 2.8420332286231806

Epoch: 6| Step: 1
Training loss: 3.5349401587097877
Validation loss: 2.84882188311898

Epoch: 6| Step: 2
Training loss: 2.5172519516936847
Validation loss: 2.851214350901876

Epoch: 6| Step: 3
Training loss: 2.417448859951026
Validation loss: 2.86118233217706

Epoch: 6| Step: 4
Training loss: 3.1493855982240837
Validation loss: 2.8827706730867355

Epoch: 6| Step: 5
Training loss: 3.2995717377636944
Validation loss: 2.8771968881665795

Epoch: 6| Step: 6
Training loss: 2.7241346157549993
Validation loss: 2.847828188812635

Epoch: 6| Step: 7
Training loss: 3.514604072682971
Validation loss: 2.8380311222124135

Epoch: 6| Step: 8
Training loss: 3.297398530152276
Validation loss: 2.8356687908376013

Epoch: 6| Step: 9
Training loss: 2.9104918011246936
Validation loss: 2.835848089200982

Epoch: 6| Step: 10
Training loss: 3.0897684389526114
Validation loss: 2.8368935761751515

Epoch: 6| Step: 11
Training loss: 2.629263820958988
Validation loss: 2.839093548871225

Epoch: 6| Step: 12
Training loss: 3.6042356686611132
Validation loss: 2.837679810577658

Epoch: 6| Step: 13
Training loss: 3.8077136152511577
Validation loss: 2.836549356681398

Epoch: 55| Step: 0
Training loss: 3.6450489326614783
Validation loss: 2.8373037877830205

Epoch: 6| Step: 1
Training loss: 2.7586279681948302
Validation loss: 2.83622773254681

Epoch: 6| Step: 2
Training loss: 3.0450837959072126
Validation loss: 2.835626201628887

Epoch: 6| Step: 3
Training loss: 3.7149830179352588
Validation loss: 2.835229956981516

Epoch: 6| Step: 4
Training loss: 3.5013468739387457
Validation loss: 2.833268174490495

Epoch: 6| Step: 5
Training loss: 2.786108167280588
Validation loss: 2.8338057548210998

Epoch: 6| Step: 6
Training loss: 2.292326283170261
Validation loss: 2.8303843399890813

Epoch: 6| Step: 7
Training loss: 3.368794281337634
Validation loss: 2.8300711336018862

Epoch: 6| Step: 8
Training loss: 2.8469039697774785
Validation loss: 2.8302555764461457

Epoch: 6| Step: 9
Training loss: 3.1393296336488867
Validation loss: 2.831554323631391

Epoch: 6| Step: 10
Training loss: 2.893325945966346
Validation loss: 2.833460744916169

Epoch: 6| Step: 11
Training loss: 3.5209929450759914
Validation loss: 2.8406842192309596

Epoch: 6| Step: 12
Training loss: 3.426707578580577
Validation loss: 2.855418564319087

Epoch: 6| Step: 13
Training loss: 2.1623484299302635
Validation loss: 2.8710629478634453

Epoch: 56| Step: 0
Training loss: 3.550856183460563
Validation loss: 2.930310800840825

Epoch: 6| Step: 1
Training loss: 3.282158861991467
Validation loss: 2.9118877573137976

Epoch: 6| Step: 2
Training loss: 3.0816028137633884
Validation loss: 2.8725773687938707

Epoch: 6| Step: 3
Training loss: 2.253903499713985
Validation loss: 2.843610413722612

Epoch: 6| Step: 4
Training loss: 3.483118763084174
Validation loss: 2.8316496461623784

Epoch: 6| Step: 5
Training loss: 2.802340659955259
Validation loss: 2.823359862675819

Epoch: 6| Step: 6
Training loss: 2.9588138745225905
Validation loss: 2.8233223180045925

Epoch: 6| Step: 7
Training loss: 3.088589458299524
Validation loss: 2.823595114784875

Epoch: 6| Step: 8
Training loss: 4.035166649006445
Validation loss: 2.8251280028622445

Epoch: 6| Step: 9
Training loss: 3.019832857571905
Validation loss: 2.8265396957018565

Epoch: 6| Step: 10
Training loss: 2.9161063791449284
Validation loss: 2.8264619293884303

Epoch: 6| Step: 11
Training loss: 3.271097516772222
Validation loss: 2.826138107735661

Epoch: 6| Step: 12
Training loss: 2.9991701885802278
Validation loss: 2.825790823500483

Epoch: 6| Step: 13
Training loss: 3.041289859233009
Validation loss: 2.8272737064726714

Epoch: 57| Step: 0
Training loss: 3.217245250181729
Validation loss: 2.8263573278734864

Epoch: 6| Step: 1
Training loss: 3.6754675639099976
Validation loss: 2.82409386294947

Epoch: 6| Step: 2
Training loss: 3.329145248274164
Validation loss: 2.8233285942502286

Epoch: 6| Step: 3
Training loss: 2.4804313596775907
Validation loss: 2.821594075269436

Epoch: 6| Step: 4
Training loss: 3.134103713461148
Validation loss: 2.8201627732767944

Epoch: 6| Step: 5
Training loss: 2.9824867866012377
Validation loss: 2.8184501237596797

Epoch: 6| Step: 6
Training loss: 3.216166079479332
Validation loss: 2.822604264982341

Epoch: 6| Step: 7
Training loss: 2.9424450421771535
Validation loss: 2.823219838523586

Epoch: 6| Step: 8
Training loss: 2.8598185544377883
Validation loss: 2.8301168391694493

Epoch: 6| Step: 9
Training loss: 3.039454103946957
Validation loss: 2.8220725695367586

Epoch: 6| Step: 10
Training loss: 2.75137996728837
Validation loss: 2.818066914653944

Epoch: 6| Step: 11
Training loss: 3.2766397695384963
Validation loss: 2.8198349271422782

Epoch: 6| Step: 12
Training loss: 3.036638327618828
Validation loss: 2.8133431122314456

Epoch: 6| Step: 13
Training loss: 4.142453578028143
Validation loss: 2.8133239031528032

Epoch: 58| Step: 0
Training loss: 3.46131223281675
Validation loss: 2.8160285755077528

Epoch: 6| Step: 1
Training loss: 2.5496590031030606
Validation loss: 2.8169069016843338

Epoch: 6| Step: 2
Training loss: 3.275510582180221
Validation loss: 2.8165288173740755

Epoch: 6| Step: 3
Training loss: 3.7671284187205942
Validation loss: 2.8202071140790523

Epoch: 6| Step: 4
Training loss: 3.2228916521505133
Validation loss: 2.8169306403888448

Epoch: 6| Step: 5
Training loss: 2.813880581564742
Validation loss: 2.8140516560747275

Epoch: 6| Step: 6
Training loss: 2.904259440957475
Validation loss: 2.8123409066728042

Epoch: 6| Step: 7
Training loss: 2.877308623498
Validation loss: 2.8130670411115677

Epoch: 6| Step: 8
Training loss: 3.1567956433907565
Validation loss: 2.8108036399117284

Epoch: 6| Step: 9
Training loss: 3.2247437900229383
Validation loss: 2.8119222870297627

Epoch: 6| Step: 10
Training loss: 3.0773401179489546
Validation loss: 2.8098326601081847

Epoch: 6| Step: 11
Training loss: 3.4324571553200647
Validation loss: 2.80972570865913

Epoch: 6| Step: 12
Training loss: 3.2989333538574797
Validation loss: 2.8096513174290405

Epoch: 6| Step: 13
Training loss: 1.8256111793817684
Validation loss: 2.812074056112754

Epoch: 59| Step: 0
Training loss: 2.9421139457207452
Validation loss: 2.809237945840703

Epoch: 6| Step: 1
Training loss: 3.352699495961021
Validation loss: 2.8123315904300155

Epoch: 6| Step: 2
Training loss: 3.3578078762074086
Validation loss: 2.8115478508182226

Epoch: 6| Step: 3
Training loss: 3.111963469440449
Validation loss: 2.8114873624085335

Epoch: 6| Step: 4
Training loss: 3.8716898900842343
Validation loss: 2.8096746292836

Epoch: 6| Step: 5
Training loss: 3.2190299791952866
Validation loss: 2.8118943176371083

Epoch: 6| Step: 6
Training loss: 2.8037634047087034
Validation loss: 2.81676237376113

Epoch: 6| Step: 7
Training loss: 2.9215557719581717
Validation loss: 2.815433632078514

Epoch: 6| Step: 8
Training loss: 3.29252301114672
Validation loss: 2.82636607179884

Epoch: 6| Step: 9
Training loss: 3.495203819171184
Validation loss: 2.83313732687726

Epoch: 6| Step: 10
Training loss: 2.2507209682369718
Validation loss: 2.8453862313788796

Epoch: 6| Step: 11
Training loss: 2.8523384606159015
Validation loss: 2.8339384911785777

Epoch: 6| Step: 12
Training loss: 3.071052753230162
Validation loss: 2.81943974929899

Epoch: 6| Step: 13
Training loss: 2.7718761078532346
Validation loss: 2.813099930013504

Epoch: 60| Step: 0
Training loss: 3.7271556582113807
Validation loss: 2.8072484983934434

Epoch: 6| Step: 1
Training loss: 3.1978293209179656
Validation loss: 2.8043039707334914

Epoch: 6| Step: 2
Training loss: 3.2534592631726653
Validation loss: 2.8003909203634265

Epoch: 6| Step: 3
Training loss: 3.070781798083418
Validation loss: 2.800714965554032

Epoch: 6| Step: 4
Training loss: 2.6875875591829836
Validation loss: 2.8015264404572107

Epoch: 6| Step: 5
Training loss: 3.059977368289805
Validation loss: 2.801813922273727

Epoch: 6| Step: 6
Training loss: 2.969925818239359
Validation loss: 2.801935238593249

Epoch: 6| Step: 7
Training loss: 3.5573228394393137
Validation loss: 2.8016905510268466

Epoch: 6| Step: 8
Training loss: 2.461845012636144
Validation loss: 2.801405133888272

Epoch: 6| Step: 9
Training loss: 3.2142441701474933
Validation loss: 2.8019641308479635

Epoch: 6| Step: 10
Training loss: 2.739729603004082
Validation loss: 2.7998228722462097

Epoch: 6| Step: 11
Training loss: 3.638122484356683
Validation loss: 2.796253242708447

Epoch: 6| Step: 12
Training loss: 2.5229874436908575
Validation loss: 2.7955571429938835

Epoch: 6| Step: 13
Training loss: 3.3952869061463464
Validation loss: 2.7948642234411087

Epoch: 61| Step: 0
Training loss: 2.608736245558213
Validation loss: 2.79474676016771

Epoch: 6| Step: 1
Training loss: 4.042185301129451
Validation loss: 2.792672302315002

Epoch: 6| Step: 2
Training loss: 2.460166204777017
Validation loss: 2.793471633680215

Epoch: 6| Step: 3
Training loss: 1.9918940907746363
Validation loss: 2.791634945298172

Epoch: 6| Step: 4
Training loss: 3.0389223826451537
Validation loss: 2.7916074613985487

Epoch: 6| Step: 5
Training loss: 2.9817055152279903
Validation loss: 2.7900902541848587

Epoch: 6| Step: 6
Training loss: 3.270779424980382
Validation loss: 2.7898364908606816

Epoch: 6| Step: 7
Training loss: 3.265103239147651
Validation loss: 2.7879732129894936

Epoch: 6| Step: 8
Training loss: 2.8404021625802267
Validation loss: 2.7883829362243002

Epoch: 6| Step: 9
Training loss: 3.1039815928611434
Validation loss: 2.7873442550920506

Epoch: 6| Step: 10
Training loss: 3.5880221953795286
Validation loss: 2.787650093361368

Epoch: 6| Step: 11
Training loss: 3.0859864822556418
Validation loss: 2.7868605892151

Epoch: 6| Step: 12
Training loss: 3.5942956924776484
Validation loss: 2.785024155445562

Epoch: 6| Step: 13
Training loss: 3.118761014441112
Validation loss: 2.7855133953843496

Epoch: 62| Step: 0
Training loss: 2.8617373854071775
Validation loss: 2.7840832323131397

Epoch: 6| Step: 1
Training loss: 3.1540838683400523
Validation loss: 2.783366297896985

Epoch: 6| Step: 2
Training loss: 2.7620489416792906
Validation loss: 2.783964881355694

Epoch: 6| Step: 3
Training loss: 3.678590129005845
Validation loss: 2.783127029089654

Epoch: 6| Step: 4
Training loss: 3.093169495036509
Validation loss: 2.783007783538219

Epoch: 6| Step: 5
Training loss: 3.0786141718500892
Validation loss: 2.7824290699338357

Epoch: 6| Step: 6
Training loss: 3.047539271789314
Validation loss: 2.7814635659940494

Epoch: 6| Step: 7
Training loss: 2.91708160355296
Validation loss: 2.7818437380146257

Epoch: 6| Step: 8
Training loss: 2.5170839237472817
Validation loss: 2.782113748017373

Epoch: 6| Step: 9
Training loss: 3.34059264949768
Validation loss: 2.7823003205426526

Epoch: 6| Step: 10
Training loss: 3.4974785305234066
Validation loss: 2.780009473408419

Epoch: 6| Step: 11
Training loss: 2.7555198757705597
Validation loss: 2.7795121820919033

Epoch: 6| Step: 12
Training loss: 2.9951108192995552
Validation loss: 2.778551801151904

Epoch: 6| Step: 13
Training loss: 3.840840548867679
Validation loss: 2.7785837432336087

Epoch: 63| Step: 0
Training loss: 3.2140251962354203
Validation loss: 2.776356115233948

Epoch: 6| Step: 1
Training loss: 2.664630460185683
Validation loss: 2.7761739451401595

Epoch: 6| Step: 2
Training loss: 3.425296553421592
Validation loss: 2.7748524725005823

Epoch: 6| Step: 3
Training loss: 3.1725249728519302
Validation loss: 2.7733879726204465

Epoch: 6| Step: 4
Training loss: 2.8568891548869284
Validation loss: 2.7729630259252245

Epoch: 6| Step: 5
Training loss: 3.4160880707637435
Validation loss: 2.7703697642723437

Epoch: 6| Step: 6
Training loss: 3.3642556864561497
Validation loss: 2.7725925312105892

Epoch: 6| Step: 7
Training loss: 3.431346170714043
Validation loss: 2.7729712406741815

Epoch: 6| Step: 8
Training loss: 3.1113411519363976
Validation loss: 2.7688570903394565

Epoch: 6| Step: 9
Training loss: 3.177321695026571
Validation loss: 2.7723546878223893

Epoch: 6| Step: 10
Training loss: 2.5074474033304766
Validation loss: 2.771291127036887

Epoch: 6| Step: 11
Training loss: 2.99737354384066
Validation loss: 2.773805725620069

Epoch: 6| Step: 12
Training loss: 2.821055137520042
Validation loss: 2.7864176622530956

Epoch: 6| Step: 13
Training loss: 2.8702078977244256
Validation loss: 2.7918360834289393

Epoch: 64| Step: 0
Training loss: 3.0733174380583015
Validation loss: 2.764708575541144

Epoch: 6| Step: 1
Training loss: 3.0702604721359155
Validation loss: 2.769578069420187

Epoch: 6| Step: 2
Training loss: 2.7724391806065563
Validation loss: 2.7768836853544854

Epoch: 6| Step: 3
Training loss: 2.5628680453347283
Validation loss: 2.775998411392032

Epoch: 6| Step: 4
Training loss: 2.6161279156118313
Validation loss: 2.7769330756085258

Epoch: 6| Step: 5
Training loss: 3.103456778715624
Validation loss: 2.7774301225920546

Epoch: 6| Step: 6
Training loss: 3.790804558862302
Validation loss: 2.7768245329552808

Epoch: 6| Step: 7
Training loss: 3.2592524358247688
Validation loss: 2.7745405389367743

Epoch: 6| Step: 8
Training loss: 3.113375596515857
Validation loss: 2.7729463744698357

Epoch: 6| Step: 9
Training loss: 2.4855545410728666
Validation loss: 2.7729552054579076

Epoch: 6| Step: 10
Training loss: 3.421449957102977
Validation loss: 2.7710029043757487

Epoch: 6| Step: 11
Training loss: 3.2357055580938137
Validation loss: 2.7699313833414747

Epoch: 6| Step: 12
Training loss: 3.3602444255570614
Validation loss: 2.7659590027977985

Epoch: 6| Step: 13
Training loss: 3.321187844173988
Validation loss: 2.764298174687487

Epoch: 65| Step: 0
Training loss: 3.206594681384536
Validation loss: 2.765267698227295

Epoch: 6| Step: 1
Training loss: 3.467511892593991
Validation loss: 2.7653321206746218

Epoch: 6| Step: 2
Training loss: 3.3539209848467233
Validation loss: 2.7645759991615613

Epoch: 6| Step: 3
Training loss: 3.7430490286508125
Validation loss: 2.7652315750171517

Epoch: 6| Step: 4
Training loss: 2.7215123667508716
Validation loss: 2.7627370272090195

Epoch: 6| Step: 5
Training loss: 2.523523098937591
Validation loss: 2.762066405072261

Epoch: 6| Step: 6
Training loss: 2.66494029509635
Validation loss: 2.761507467876711

Epoch: 6| Step: 7
Training loss: 3.3014753164974433
Validation loss: 2.7585547964991712

Epoch: 6| Step: 8
Training loss: 3.0352033810288535
Validation loss: 2.7604555640766395

Epoch: 6| Step: 9
Training loss: 2.996775642792577
Validation loss: 2.7588511532972553

Epoch: 6| Step: 10
Training loss: 3.242315597761242
Validation loss: 2.7565573803611048

Epoch: 6| Step: 11
Training loss: 2.216295093092693
Validation loss: 2.7578725361208876

Epoch: 6| Step: 12
Training loss: 3.5364320254950843
Validation loss: 2.754972606485748

Epoch: 6| Step: 13
Training loss: 2.6292569293585277
Validation loss: 2.755713868756557

Epoch: 66| Step: 0
Training loss: 3.3452319132378143
Validation loss: 2.7538671477517855

Epoch: 6| Step: 1
Training loss: 3.2951330129724887
Validation loss: 2.7544154817887727

Epoch: 6| Step: 2
Training loss: 3.0834880137092275
Validation loss: 2.75330799394092

Epoch: 6| Step: 3
Training loss: 3.161706720908517
Validation loss: 2.7517031972837422

Epoch: 6| Step: 4
Training loss: 2.8772663637392477
Validation loss: 2.751710299287826

Epoch: 6| Step: 5
Training loss: 2.878494957953101
Validation loss: 2.750896917272214

Epoch: 6| Step: 6
Training loss: 3.0408635233116312
Validation loss: 2.747977623426719

Epoch: 6| Step: 7
Training loss: 2.9581395117079143
Validation loss: 2.7499562508914996

Epoch: 6| Step: 8
Training loss: 4.0140090243889555
Validation loss: 2.751621452577162

Epoch: 6| Step: 9
Training loss: 2.747195981728265
Validation loss: 2.7508643703909983

Epoch: 6| Step: 10
Training loss: 3.0157745798597615
Validation loss: 2.751140679530103

Epoch: 6| Step: 11
Training loss: 2.712025712558082
Validation loss: 2.748881743785484

Epoch: 6| Step: 12
Training loss: 2.887912942002147
Validation loss: 2.7475537712183593

Epoch: 6| Step: 13
Training loss: 2.65005506782176
Validation loss: 2.745696613275913

Epoch: 67| Step: 0
Training loss: 2.621998933356888
Validation loss: 2.7420064415698855

Epoch: 6| Step: 1
Training loss: 3.112498492504812
Validation loss: 2.742990920243076

Epoch: 6| Step: 2
Training loss: 3.080244390031307
Validation loss: 2.743957470911891

Epoch: 6| Step: 3
Training loss: 3.5751801078616867
Validation loss: 2.7413876924906067

Epoch: 6| Step: 4
Training loss: 3.3940999730525316
Validation loss: 2.741372353926326

Epoch: 6| Step: 5
Training loss: 2.0325840017454655
Validation loss: 2.739849892826375

Epoch: 6| Step: 6
Training loss: 3.0844608685291024
Validation loss: 2.7406527495616637

Epoch: 6| Step: 7
Training loss: 3.4911240701605544
Validation loss: 2.7375073639459777

Epoch: 6| Step: 8
Training loss: 3.018128615847389
Validation loss: 2.739005990691424

Epoch: 6| Step: 9
Training loss: 2.8545541616283834
Validation loss: 2.7390107117443407

Epoch: 6| Step: 10
Training loss: 3.2357802724470672
Validation loss: 2.736269989371639

Epoch: 6| Step: 11
Training loss: 3.1311950313288937
Validation loss: 2.7390963959431507

Epoch: 6| Step: 12
Training loss: 3.2788366252641103
Validation loss: 2.7375872245374544

Epoch: 6| Step: 13
Training loss: 2.411474426962839
Validation loss: 2.7442826036790886

Epoch: 68| Step: 0
Training loss: 3.1120681217945636
Validation loss: 2.7503364595812556

Epoch: 6| Step: 1
Training loss: 3.4769485773601736
Validation loss: 2.762719746219768

Epoch: 6| Step: 2
Training loss: 2.0132801699829757
Validation loss: 2.764224067987856

Epoch: 6| Step: 3
Training loss: 2.77771731840671
Validation loss: 2.7706169116681925

Epoch: 6| Step: 4
Training loss: 3.676546023324214
Validation loss: 2.7880246917955436

Epoch: 6| Step: 5
Training loss: 3.5946043906246006
Validation loss: 2.7334712706390576

Epoch: 6| Step: 6
Training loss: 3.12842905737119
Validation loss: 2.7383973166661586

Epoch: 6| Step: 7
Training loss: 2.68445769816545
Validation loss: 2.7410081046708457

Epoch: 6| Step: 8
Training loss: 2.6423660948866905
Validation loss: 2.743746985054177

Epoch: 6| Step: 9
Training loss: 3.1285705005273607
Validation loss: 2.748819250597194

Epoch: 6| Step: 10
Training loss: 3.5749546981822267
Validation loss: 2.762724972377949

Epoch: 6| Step: 11
Training loss: 3.156550327024902
Validation loss: 2.7729534562736426

Epoch: 6| Step: 12
Training loss: 2.9550694114420444
Validation loss: 2.7822176577389417

Epoch: 6| Step: 13
Training loss: 2.566913154045414
Validation loss: 2.7617643039011592

Epoch: 69| Step: 0
Training loss: 4.111766047045329
Validation loss: 2.746177625264276

Epoch: 6| Step: 1
Training loss: 3.2347249749325133
Validation loss: 2.741396823393743

Epoch: 6| Step: 2
Training loss: 2.9234213587500344
Validation loss: 2.7381107005179093

Epoch: 6| Step: 3
Training loss: 3.3605763261252344
Validation loss: 2.737363482952234

Epoch: 6| Step: 4
Training loss: 2.5665141043796615
Validation loss: 2.736776420504092

Epoch: 6| Step: 5
Training loss: 3.755226181065459
Validation loss: 2.7366130373960718

Epoch: 6| Step: 6
Training loss: 3.322246966346046
Validation loss: 2.7343339308131704

Epoch: 6| Step: 7
Training loss: 3.0954769978532033
Validation loss: 2.7327987876654123

Epoch: 6| Step: 8
Training loss: 2.768783231583161
Validation loss: 2.731984930668528

Epoch: 6| Step: 9
Training loss: 3.203495953177011
Validation loss: 2.7340080987793076

Epoch: 6| Step: 10
Training loss: 2.2961932357724337
Validation loss: 2.7325042635018977

Epoch: 6| Step: 11
Training loss: 2.8551791731801903
Validation loss: 2.731725058303129

Epoch: 6| Step: 12
Training loss: 2.4287200669875153
Validation loss: 2.733510864409088

Epoch: 6| Step: 13
Training loss: 1.8316492524272316
Validation loss: 2.741695841795375

Epoch: 70| Step: 0
Training loss: 3.033276539225451
Validation loss: 2.7500498618922062

Epoch: 6| Step: 1
Training loss: 3.0113084961437866
Validation loss: 2.7409970401541526

Epoch: 6| Step: 2
Training loss: 2.8763343368294514
Validation loss: 2.752445028020124

Epoch: 6| Step: 3
Training loss: 3.190294424598614
Validation loss: 2.7613793658433434

Epoch: 6| Step: 4
Training loss: 2.8959916069267426
Validation loss: 2.7557888201483567

Epoch: 6| Step: 5
Training loss: 3.5222298525444464
Validation loss: 2.7330149953914873

Epoch: 6| Step: 6
Training loss: 3.3100143319364213
Validation loss: 2.725684318857218

Epoch: 6| Step: 7
Training loss: 3.636511840834603
Validation loss: 2.725568546059162

Epoch: 6| Step: 8
Training loss: 2.8216329848894266
Validation loss: 2.727291418867921

Epoch: 6| Step: 9
Training loss: 2.8034842202504655
Validation loss: 2.7263832474102587

Epoch: 6| Step: 10
Training loss: 2.5776092938284614
Validation loss: 2.7292678752870856

Epoch: 6| Step: 11
Training loss: 2.777944250416637
Validation loss: 2.7275690510965274

Epoch: 6| Step: 12
Training loss: 3.0357930854379345
Validation loss: 2.728909970213013

Epoch: 6| Step: 13
Training loss: 3.4638722809290856
Validation loss: 2.727521587641423

Epoch: 71| Step: 0
Training loss: 2.9114363140076516
Validation loss: 2.726915302764028

Epoch: 6| Step: 1
Training loss: 2.193296871500624
Validation loss: 2.727413089122789

Epoch: 6| Step: 2
Training loss: 3.1114729508136527
Validation loss: 2.727110241009752

Epoch: 6| Step: 3
Training loss: 2.8445534042840923
Validation loss: 2.727566549083059

Epoch: 6| Step: 4
Training loss: 3.6664393672426923
Validation loss: 2.7265958258905223

Epoch: 6| Step: 5
Training loss: 2.6960579103991047
Validation loss: 2.7266488019727717

Epoch: 6| Step: 6
Training loss: 3.5380712472524865
Validation loss: 2.7246760167565744

Epoch: 6| Step: 7
Training loss: 3.0309693511349685
Validation loss: 2.7235327206005415

Epoch: 6| Step: 8
Training loss: 3.1128946444791468
Validation loss: 2.7223176660758046

Epoch: 6| Step: 9
Training loss: 2.2634159236365687
Validation loss: 2.7237318272559885

Epoch: 6| Step: 10
Training loss: 3.1091774729187573
Validation loss: 2.7225611472023346

Epoch: 6| Step: 11
Training loss: 3.4765168262010304
Validation loss: 2.7272768761645843

Epoch: 6| Step: 12
Training loss: 3.292554437857835
Validation loss: 2.7296553938711745

Epoch: 6| Step: 13
Training loss: 3.3291465373538744
Validation loss: 2.7245389546637586

Epoch: 72| Step: 0
Training loss: 3.4922838987149416
Validation loss: 2.719563718028937

Epoch: 6| Step: 1
Training loss: 2.794663391316414
Validation loss: 2.720240168421993

Epoch: 6| Step: 2
Training loss: 3.350558897624788
Validation loss: 2.7212925046652976

Epoch: 6| Step: 3
Training loss: 2.700592089123409
Validation loss: 2.7227495313179837

Epoch: 6| Step: 4
Training loss: 3.518388264087361
Validation loss: 2.7238344149299274

Epoch: 6| Step: 5
Training loss: 1.440649976534521
Validation loss: 2.7263979180599627

Epoch: 6| Step: 6
Training loss: 2.7906142761092765
Validation loss: 2.7292631542887933

Epoch: 6| Step: 7
Training loss: 3.3232136337573634
Validation loss: 2.7395309885552335

Epoch: 6| Step: 8
Training loss: 3.0193420587763002
Validation loss: 2.730352622341005

Epoch: 6| Step: 9
Training loss: 3.6095678765091748
Validation loss: 2.7265915901288724

Epoch: 6| Step: 10
Training loss: 3.6129890612434794
Validation loss: 2.7208523390009316

Epoch: 6| Step: 11
Training loss: 2.462889172933999
Validation loss: 2.718869417062277

Epoch: 6| Step: 12
Training loss: 3.0277260028328157
Validation loss: 2.716965903385319

Epoch: 6| Step: 13
Training loss: 2.733538603246838
Validation loss: 2.7144135018626714

Epoch: 73| Step: 0
Training loss: 3.893738140743314
Validation loss: 2.714164617190094

Epoch: 6| Step: 1
Training loss: 3.2130868219920825
Validation loss: 2.7136300429446347

Epoch: 6| Step: 2
Training loss: 3.065342887629016
Validation loss: 2.7173055862543083

Epoch: 6| Step: 3
Training loss: 2.8132148681876905
Validation loss: 2.7126299950990664

Epoch: 6| Step: 4
Training loss: 2.389459462989183
Validation loss: 2.7116449925911144

Epoch: 6| Step: 5
Training loss: 3.3298319706035637
Validation loss: 2.710365442390031

Epoch: 6| Step: 6
Training loss: 2.83790272278908
Validation loss: 2.7085883261112422

Epoch: 6| Step: 7
Training loss: 3.6867874232882754
Validation loss: 2.7084918187975293

Epoch: 6| Step: 8
Training loss: 2.6172381495798605
Validation loss: 2.7067673812377233

Epoch: 6| Step: 9
Training loss: 2.776038870652003
Validation loss: 2.7061935743657988

Epoch: 6| Step: 10
Training loss: 2.951296285535332
Validation loss: 2.705906775940289

Epoch: 6| Step: 11
Training loss: 2.882459169149913
Validation loss: 2.7047617424782895

Epoch: 6| Step: 12
Training loss: 2.790068971061692
Validation loss: 2.7054128122689742

Epoch: 6| Step: 13
Training loss: 3.101949595550347
Validation loss: 2.7065054408535274

Epoch: 74| Step: 0
Training loss: 2.6739044512937324
Validation loss: 2.7038119906794313

Epoch: 6| Step: 1
Training loss: 3.110584119789108
Validation loss: 2.70782540025392

Epoch: 6| Step: 2
Training loss: 3.6796320366374715
Validation loss: 2.7126421827676483

Epoch: 6| Step: 3
Training loss: 3.027866323344856
Validation loss: 2.7086200549719317

Epoch: 6| Step: 4
Training loss: 2.1133599962945233
Validation loss: 2.7071609559515597

Epoch: 6| Step: 5
Training loss: 3.1705653300837535
Validation loss: 2.706193347008161

Epoch: 6| Step: 6
Training loss: 2.91493240749191
Validation loss: 2.699108534382846

Epoch: 6| Step: 7
Training loss: 3.561652501003268
Validation loss: 2.7026372674978014

Epoch: 6| Step: 8
Training loss: 3.14901538779944
Validation loss: 2.7010876481228636

Epoch: 6| Step: 9
Training loss: 2.441060522395752
Validation loss: 2.6999555922137373

Epoch: 6| Step: 10
Training loss: 2.8235750638786676
Validation loss: 2.6993242295451503

Epoch: 6| Step: 11
Training loss: 3.388494850833623
Validation loss: 2.699675191463468

Epoch: 6| Step: 12
Training loss: 2.6946316508730312
Validation loss: 2.7020769621574177

Epoch: 6| Step: 13
Training loss: 3.736289200128854
Validation loss: 2.6994504481736645

Epoch: 75| Step: 0
Training loss: 2.812512207004759
Validation loss: 2.697947736466107

Epoch: 6| Step: 1
Training loss: 2.720287808870973
Validation loss: 2.7000298492144403

Epoch: 6| Step: 2
Training loss: 2.3600329561680318
Validation loss: 2.6982319965462334

Epoch: 6| Step: 3
Training loss: 3.4380299939882706
Validation loss: 2.7072897125369533

Epoch: 6| Step: 4
Training loss: 2.450473980889833
Validation loss: 2.70896616153447

Epoch: 6| Step: 5
Training loss: 2.71956946640099
Validation loss: 2.702384680908925

Epoch: 6| Step: 6
Training loss: 3.7187798763325213
Validation loss: 2.7000107184272926

Epoch: 6| Step: 7
Training loss: 3.32086277609249
Validation loss: 2.695471631845845

Epoch: 6| Step: 8
Training loss: 2.9519371590580703
Validation loss: 2.695776357709754

Epoch: 6| Step: 9
Training loss: 2.313585593607938
Validation loss: 2.69709469092159

Epoch: 6| Step: 10
Training loss: 3.1330115809173305
Validation loss: 2.6978534978218924

Epoch: 6| Step: 11
Training loss: 3.5555038017903873
Validation loss: 2.696896295983023

Epoch: 6| Step: 12
Training loss: 3.6213513131498236
Validation loss: 2.69837595088878

Epoch: 6| Step: 13
Training loss: 3.0001772192426888
Validation loss: 2.699796086552421

Epoch: 76| Step: 0
Training loss: 3.2537564796151686
Validation loss: 2.6970206387461566

Epoch: 6| Step: 1
Training loss: 3.1659211904195836
Validation loss: 2.69624902862833

Epoch: 6| Step: 2
Training loss: 2.4703925740476285
Validation loss: 2.6968183826612084

Epoch: 6| Step: 3
Training loss: 2.5715284630885598
Validation loss: 2.6957188529857805

Epoch: 6| Step: 4
Training loss: 3.0092096427891777
Validation loss: 2.6954911234482055

Epoch: 6| Step: 5
Training loss: 2.934354030871396
Validation loss: 2.6956305507760074

Epoch: 6| Step: 6
Training loss: 3.206538619051127
Validation loss: 2.694936928331143

Epoch: 6| Step: 7
Training loss: 3.115027728745684
Validation loss: 2.693595889587981

Epoch: 6| Step: 8
Training loss: 3.5188217887534257
Validation loss: 2.693260024169677

Epoch: 6| Step: 9
Training loss: 2.4714491370028218
Validation loss: 2.6912949142837443

Epoch: 6| Step: 10
Training loss: 3.004305293411525
Validation loss: 2.6916898370272095

Epoch: 6| Step: 11
Training loss: 3.308978530145499
Validation loss: 2.690931647121954

Epoch: 6| Step: 12
Training loss: 3.0781087342427944
Validation loss: 2.689148069658362

Epoch: 6| Step: 13
Training loss: 3.24961542641844
Validation loss: 2.6869335927477986

Epoch: 77| Step: 0
Training loss: 2.528979566546605
Validation loss: 2.6879097887726155

Epoch: 6| Step: 1
Training loss: 3.7857004252794404
Validation loss: 2.688872095589111

Epoch: 6| Step: 2
Training loss: 3.728154192392125
Validation loss: 2.6891054784313

Epoch: 6| Step: 3
Training loss: 3.2653087116007367
Validation loss: 2.6893344159812154

Epoch: 6| Step: 4
Training loss: 2.63668701152773
Validation loss: 2.708421754616313

Epoch: 6| Step: 5
Training loss: 3.074854938838166
Validation loss: 2.7347386384696724

Epoch: 6| Step: 6
Training loss: 2.711625685176025
Validation loss: 2.7320773970911527

Epoch: 6| Step: 7
Training loss: 2.6418357646583517
Validation loss: 2.726548714072106

Epoch: 6| Step: 8
Training loss: 3.0129126175174576
Validation loss: 2.7169799587299526

Epoch: 6| Step: 9
Training loss: 3.0456218000677384
Validation loss: 2.6975434279854684

Epoch: 6| Step: 10
Training loss: 2.3929246799397483
Validation loss: 2.6957165791331725

Epoch: 6| Step: 11
Training loss: 2.316650583591025
Validation loss: 2.698732314963962

Epoch: 6| Step: 12
Training loss: 3.2085694725691596
Validation loss: 2.691547476714062

Epoch: 6| Step: 13
Training loss: 3.797103435410542
Validation loss: 2.680745315717491

Epoch: 78| Step: 0
Training loss: 3.0084925291537012
Validation loss: 2.680128711942511

Epoch: 6| Step: 1
Training loss: 2.778151082280105
Validation loss: 2.6797067084309076

Epoch: 6| Step: 2
Training loss: 3.1538372826943513
Validation loss: 2.6866269554896633

Epoch: 6| Step: 3
Training loss: 3.870618989318586
Validation loss: 2.688233826962969

Epoch: 6| Step: 4
Training loss: 2.7886041857712836
Validation loss: 2.6909501903389317

Epoch: 6| Step: 5
Training loss: 2.678195905247554
Validation loss: 2.6878095488147795

Epoch: 6| Step: 6
Training loss: 3.7001614200331527
Validation loss: 2.6926839463260657

Epoch: 6| Step: 7
Training loss: 3.204298744075555
Validation loss: 2.6903763698570335

Epoch: 6| Step: 8
Training loss: 2.2700339727338275
Validation loss: 2.685035852222792

Epoch: 6| Step: 9
Training loss: 2.9768942500390447
Validation loss: 2.681169525613201

Epoch: 6| Step: 10
Training loss: 2.3930437405673968
Validation loss: 2.679018215745864

Epoch: 6| Step: 11
Training loss: 3.183610974598726
Validation loss: 2.6770120720332407

Epoch: 6| Step: 12
Training loss: 2.8572389722733615
Validation loss: 2.6741053582838625

Epoch: 6| Step: 13
Training loss: 2.915459919106588
Validation loss: 2.676447758465661

Epoch: 79| Step: 0
Training loss: 2.910234898266107
Validation loss: 2.677307699505443

Epoch: 6| Step: 1
Training loss: 3.195382488202413
Validation loss: 2.6784896371271483

Epoch: 6| Step: 2
Training loss: 2.6764768712587097
Validation loss: 2.6780473452863363

Epoch: 6| Step: 3
Training loss: 3.149324126622855
Validation loss: 2.6798325586103493

Epoch: 6| Step: 4
Training loss: 2.7174748905429102
Validation loss: 2.6788312522868916

Epoch: 6| Step: 5
Training loss: 3.290635120343679
Validation loss: 2.680957407301251

Epoch: 6| Step: 6
Training loss: 3.0367430634699266
Validation loss: 2.6795030129331523

Epoch: 6| Step: 7
Training loss: 3.051006313721292
Validation loss: 2.6786128885993357

Epoch: 6| Step: 8
Training loss: 2.8577574443571674
Validation loss: 2.6768720733482616

Epoch: 6| Step: 9
Training loss: 3.1783993522883423
Validation loss: 2.6788665691700624

Epoch: 6| Step: 10
Training loss: 2.866616007630788
Validation loss: 2.6777225157628894

Epoch: 6| Step: 11
Training loss: 2.6103952206529595
Validation loss: 2.6778467551077965

Epoch: 6| Step: 12
Training loss: 2.9059490745372174
Validation loss: 2.677241372465196

Epoch: 6| Step: 13
Training loss: 4.087290085934938
Validation loss: 2.676541193853165

Epoch: 80| Step: 0
Training loss: 2.937280687302209
Validation loss: 2.674732615651426

Epoch: 6| Step: 1
Training loss: 3.2501012346199802
Validation loss: 2.676207819213488

Epoch: 6| Step: 2
Training loss: 2.6487098936363287
Validation loss: 2.676902780867937

Epoch: 6| Step: 3
Training loss: 3.2796455456947644
Validation loss: 2.6803271103332027

Epoch: 6| Step: 4
Training loss: 2.9565597017099776
Validation loss: 2.6767998493367657

Epoch: 6| Step: 5
Training loss: 2.5009018225116884
Validation loss: 2.6774286796174183

Epoch: 6| Step: 6
Training loss: 2.766598546288728
Validation loss: 2.674290392659276

Epoch: 6| Step: 7
Training loss: 4.138529466786595
Validation loss: 2.6752221122320083

Epoch: 6| Step: 8
Training loss: 2.6443439907563038
Validation loss: 2.6712271247844144

Epoch: 6| Step: 9
Training loss: 3.3029770629437496
Validation loss: 2.672351283538534

Epoch: 6| Step: 10
Training loss: 2.2548120751071634
Validation loss: 2.6714671054535706

Epoch: 6| Step: 11
Training loss: 3.1258473582619675
Validation loss: 2.6704353714721076

Epoch: 6| Step: 12
Training loss: 3.0984676880936095
Validation loss: 2.671077699264543

Epoch: 6| Step: 13
Training loss: 2.6928756533987914
Validation loss: 2.669594325350525

Epoch: 81| Step: 0
Training loss: 2.8895261583307623
Validation loss: 2.6723260561754936

Epoch: 6| Step: 1
Training loss: 3.5030760190807997
Validation loss: 2.6721253502374482

Epoch: 6| Step: 2
Training loss: 2.683992803185901
Validation loss: 2.6703803864196156

Epoch: 6| Step: 3
Training loss: 2.7890003528669975
Validation loss: 2.6688932245472543

Epoch: 6| Step: 4
Training loss: 2.900799963223204
Validation loss: 2.6693730187634235

Epoch: 6| Step: 5
Training loss: 2.612503004300521
Validation loss: 2.668785455824646

Epoch: 6| Step: 6
Training loss: 3.176617464189534
Validation loss: 2.666184095844086

Epoch: 6| Step: 7
Training loss: 2.5732030876417475
Validation loss: 2.663303770365602

Epoch: 6| Step: 8
Training loss: 3.2602750769798066
Validation loss: 2.6660974645586073

Epoch: 6| Step: 9
Training loss: 3.13384338312807
Validation loss: 2.661947605421555

Epoch: 6| Step: 10
Training loss: 3.682468408266507
Validation loss: 2.6604980646195884

Epoch: 6| Step: 11
Training loss: 3.209133560325561
Validation loss: 2.6586029199822465

Epoch: 6| Step: 12
Training loss: 2.4328262318913896
Validation loss: 2.66078332911252

Epoch: 6| Step: 13
Training loss: 2.931999738581335
Validation loss: 2.6569704057280203

Epoch: 82| Step: 0
Training loss: 3.3962222541627645
Validation loss: 2.6615552918073364

Epoch: 6| Step: 1
Training loss: 2.5272468654452
Validation loss: 2.661126402265511

Epoch: 6| Step: 2
Training loss: 3.0867992887849325
Validation loss: 2.6599898540532476

Epoch: 6| Step: 3
Training loss: 3.145655309090365
Validation loss: 2.6587944376383996

Epoch: 6| Step: 4
Training loss: 3.215467390196105
Validation loss: 2.659726130019834

Epoch: 6| Step: 5
Training loss: 3.0025131507350493
Validation loss: 2.6597566595869746

Epoch: 6| Step: 6
Training loss: 2.9286505326277394
Validation loss: 2.6640241441716235

Epoch: 6| Step: 7
Training loss: 2.8250347979267567
Validation loss: 2.6629012047487977

Epoch: 6| Step: 8
Training loss: 2.7880383061550886
Validation loss: 2.6658248251924954

Epoch: 6| Step: 9
Training loss: 2.863222295927013
Validation loss: 2.6736328122698736

Epoch: 6| Step: 10
Training loss: 3.1519191224328567
Validation loss: 2.6786824059923338

Epoch: 6| Step: 11
Training loss: 2.9731816994130393
Validation loss: 2.6777570306210827

Epoch: 6| Step: 12
Training loss: 3.0417785275587987
Validation loss: 2.6727750277337137

Epoch: 6| Step: 13
Training loss: 2.8355045040594633
Validation loss: 2.671483692740281

Epoch: 83| Step: 0
Training loss: 2.938260081548897
Validation loss: 2.6679829568102855

Epoch: 6| Step: 1
Training loss: 3.566146590441369
Validation loss: 2.6647320863007864

Epoch: 6| Step: 2
Training loss: 2.928365750018489
Validation loss: 2.665251519488906

Epoch: 6| Step: 3
Training loss: 2.860239867441925
Validation loss: 2.6631979798551715

Epoch: 6| Step: 4
Training loss: 2.6136052910084757
Validation loss: 2.661616150666257

Epoch: 6| Step: 5
Training loss: 3.1758371045595624
Validation loss: 2.664894413644804

Epoch: 6| Step: 6
Training loss: 2.8462947316899556
Validation loss: 2.6599911214214775

Epoch: 6| Step: 7
Training loss: 3.359034463345076
Validation loss: 2.6610580803834636

Epoch: 6| Step: 8
Training loss: 2.572784997039436
Validation loss: 2.660391211434701

Epoch: 6| Step: 9
Training loss: 3.151937125261474
Validation loss: 2.6587015245780448

Epoch: 6| Step: 10
Training loss: 3.0999759488557146
Validation loss: 2.657241452882049

Epoch: 6| Step: 11
Training loss: 2.661347647578108
Validation loss: 2.6608368389343857

Epoch: 6| Step: 12
Training loss: 3.0196806363637005
Validation loss: 2.658959923994824

Epoch: 6| Step: 13
Training loss: 2.92092651639379
Validation loss: 2.6604641767212045

Epoch: 84| Step: 0
Training loss: 2.990167399029484
Validation loss: 2.6617625576989363

Epoch: 6| Step: 1
Training loss: 3.6540801301552235
Validation loss: 2.661072216188846

Epoch: 6| Step: 2
Training loss: 2.8346505936423823
Validation loss: 2.667047783576475

Epoch: 6| Step: 3
Training loss: 2.7419652604254274
Validation loss: 2.6612645820747574

Epoch: 6| Step: 4
Training loss: 3.319247014245422
Validation loss: 2.6537607515034294

Epoch: 6| Step: 5
Training loss: 3.2562632730693073
Validation loss: 2.6534649256541183

Epoch: 6| Step: 6
Training loss: 2.8334738378654856
Validation loss: 2.6512898396398135

Epoch: 6| Step: 7
Training loss: 2.6981699958391303
Validation loss: 2.6529884287671486

Epoch: 6| Step: 8
Training loss: 3.0799291909735738
Validation loss: 2.651669657285748

Epoch: 6| Step: 9
Training loss: 2.6937853038625152
Validation loss: 2.655430158012058

Epoch: 6| Step: 10
Training loss: 2.9011686469640887
Validation loss: 2.65203218727746

Epoch: 6| Step: 11
Training loss: 2.595327609923655
Validation loss: 2.6518017752791874

Epoch: 6| Step: 12
Training loss: 2.8282944433550385
Validation loss: 2.654572032046491

Epoch: 6| Step: 13
Training loss: 3.310852216744663
Validation loss: 2.6529403596185195

Epoch: 85| Step: 0
Training loss: 3.3688231564648348
Validation loss: 2.6486578229679187

Epoch: 6| Step: 1
Training loss: 2.9452822251117263
Validation loss: 2.6548571356718305

Epoch: 6| Step: 2
Training loss: 2.4273456437195904
Validation loss: 2.6649899890101127

Epoch: 6| Step: 3
Training loss: 3.416238959609001
Validation loss: 2.646575385394566

Epoch: 6| Step: 4
Training loss: 2.4843465935384645
Validation loss: 2.6497351737569113

Epoch: 6| Step: 5
Training loss: 2.499472276302272
Validation loss: 2.654044608319312

Epoch: 6| Step: 6
Training loss: 3.1557745244909796
Validation loss: 2.6688321377915645

Epoch: 6| Step: 7
Training loss: 3.267143954876676
Validation loss: 2.6821673840646687

Epoch: 6| Step: 8
Training loss: 2.6894495790190858
Validation loss: 2.684698312411507

Epoch: 6| Step: 9
Training loss: 3.433469038815252
Validation loss: 2.6744896938380673

Epoch: 6| Step: 10
Training loss: 3.172212930351347
Validation loss: 2.656973007990881

Epoch: 6| Step: 11
Training loss: 2.78173301017306
Validation loss: 2.6471689690194946

Epoch: 6| Step: 12
Training loss: 3.2264194410627964
Validation loss: 2.651134590312428

Epoch: 6| Step: 13
Training loss: 2.570995854496442
Validation loss: 2.645767568310785

Epoch: 86| Step: 0
Training loss: 2.970887709481567
Validation loss: 2.650870350867321

Epoch: 6| Step: 1
Training loss: 2.4431726032107495
Validation loss: 2.6470138542633745

Epoch: 6| Step: 2
Training loss: 3.560262814153917
Validation loss: 2.6469817675673055

Epoch: 6| Step: 3
Training loss: 3.0496731942614566
Validation loss: 2.646268678143983

Epoch: 6| Step: 4
Training loss: 2.8092821150415084
Validation loss: 2.6456572025331777

Epoch: 6| Step: 5
Training loss: 3.8376538074995534
Validation loss: 2.651421801068191

Epoch: 6| Step: 6
Training loss: 3.073568621942823
Validation loss: 2.649707098453836

Epoch: 6| Step: 7
Training loss: 2.1904616878653367
Validation loss: 2.6474234847735754

Epoch: 6| Step: 8
Training loss: 3.033321655865783
Validation loss: 2.651420802267746

Epoch: 6| Step: 9
Training loss: 3.1469867099303146
Validation loss: 2.6583035102236283

Epoch: 6| Step: 10
Training loss: 3.223702777518163
Validation loss: 2.6556102621707467

Epoch: 6| Step: 11
Training loss: 2.894755119284282
Validation loss: 2.6474841572077397

Epoch: 6| Step: 12
Training loss: 2.4165930462727783
Validation loss: 2.642099853912439

Epoch: 6| Step: 13
Training loss: 2.7005930602452266
Validation loss: 2.6471785043232594

Epoch: 87| Step: 0
Training loss: 3.03491964117562
Validation loss: 2.675588961031093

Epoch: 6| Step: 1
Training loss: 3.311544172468998
Validation loss: 2.699715422373558

Epoch: 6| Step: 2
Training loss: 3.112564214940226
Validation loss: 2.6442128623231578

Epoch: 6| Step: 3
Training loss: 2.807162242352393
Validation loss: 2.6402697221321447

Epoch: 6| Step: 4
Training loss: 2.948595883108563
Validation loss: 2.640998859981655

Epoch: 6| Step: 5
Training loss: 3.157546579677334
Validation loss: 2.6459894002655413

Epoch: 6| Step: 6
Training loss: 3.342626222382789
Validation loss: 2.6490375704006497

Epoch: 6| Step: 7
Training loss: 3.0999216500502387
Validation loss: 2.654498496278651

Epoch: 6| Step: 8
Training loss: 2.8089565419481346
Validation loss: 2.6536152907833253

Epoch: 6| Step: 9
Training loss: 2.2581622106979427
Validation loss: 2.6558887996150973

Epoch: 6| Step: 10
Training loss: 2.9875745947555044
Validation loss: 2.6628695338075854

Epoch: 6| Step: 11
Training loss: 2.3196460524582845
Validation loss: 2.662884639094185

Epoch: 6| Step: 12
Training loss: 3.3635517503373227
Validation loss: 2.6635216739660454

Epoch: 6| Step: 13
Training loss: 3.2407922155339017
Validation loss: 2.6752445466829617

Epoch: 88| Step: 0
Training loss: 2.942596721501787
Validation loss: 2.67008949833395

Epoch: 6| Step: 1
Training loss: 3.115128145230314
Validation loss: 2.6664502125870877

Epoch: 6| Step: 2
Training loss: 2.8581290109932835
Validation loss: 2.6539677166659503

Epoch: 6| Step: 3
Training loss: 3.1462944821171277
Validation loss: 2.6518670361885284

Epoch: 6| Step: 4
Training loss: 3.053069249467004
Validation loss: 2.647123455532273

Epoch: 6| Step: 5
Training loss: 2.781714239915529
Validation loss: 2.648814264185036

Epoch: 6| Step: 6
Training loss: 3.005811466581335
Validation loss: 2.646132983104719

Epoch: 6| Step: 7
Training loss: 2.8362619934231947
Validation loss: 2.652714176321452

Epoch: 6| Step: 8
Training loss: 3.1698782512979515
Validation loss: 2.6542401773331656

Epoch: 6| Step: 9
Training loss: 3.4341386486361674
Validation loss: 2.653949167170093

Epoch: 6| Step: 10
Training loss: 2.8984911314739947
Validation loss: 2.6386073195606894

Epoch: 6| Step: 11
Training loss: 2.610721902946138
Validation loss: 2.6346699963142113

Epoch: 6| Step: 12
Training loss: 2.8845133738942526
Validation loss: 2.6308179274217762

Epoch: 6| Step: 13
Training loss: 3.1586048670442657
Validation loss: 2.6303679929603403

Epoch: 89| Step: 0
Training loss: 2.8830275209868494
Validation loss: 2.6295642266767527

Epoch: 6| Step: 1
Training loss: 3.5977768603391724
Validation loss: 2.6273994788454083

Epoch: 6| Step: 2
Training loss: 2.9799973901314796
Validation loss: 2.6256451495150435

Epoch: 6| Step: 3
Training loss: 2.9322516448212848
Validation loss: 2.6235423633596477

Epoch: 6| Step: 4
Training loss: 2.7170668905909467
Validation loss: 2.6242672111778225

Epoch: 6| Step: 5
Training loss: 2.9461639549693337
Validation loss: 2.6232985711872523

Epoch: 6| Step: 6
Training loss: 3.783812734224333
Validation loss: 2.621355939723736

Epoch: 6| Step: 7
Training loss: 3.113262717312703
Validation loss: 2.6234946497854392

Epoch: 6| Step: 8
Training loss: 2.358702203683806
Validation loss: 2.621812097646365

Epoch: 6| Step: 9
Training loss: 3.114949658815231
Validation loss: 2.621741599350904

Epoch: 6| Step: 10
Training loss: 3.0154539069623745
Validation loss: 2.6217004124575145

Epoch: 6| Step: 11
Training loss: 3.09510634774203
Validation loss: 2.621260875152171

Epoch: 6| Step: 12
Training loss: 2.1125858312020265
Validation loss: 2.6197443704848027

Epoch: 6| Step: 13
Training loss: 2.1307329372862807
Validation loss: 2.6187873477217285

Epoch: 90| Step: 0
Training loss: 2.5393300076929686
Validation loss: 2.6198572438345376

Epoch: 6| Step: 1
Training loss: 2.646974953089416
Validation loss: 2.6184782569685856

Epoch: 6| Step: 2
Training loss: 3.232997287578017
Validation loss: 2.6182844923726583

Epoch: 6| Step: 3
Training loss: 3.3415445915876028
Validation loss: 2.617904446851873

Epoch: 6| Step: 4
Training loss: 2.7131850190676032
Validation loss: 2.619086644059447

Epoch: 6| Step: 5
Training loss: 3.6949448513514795
Validation loss: 2.6222504163052744

Epoch: 6| Step: 6
Training loss: 2.9821815618739507
Validation loss: 2.619341037457925

Epoch: 6| Step: 7
Training loss: 2.1530491387854247
Validation loss: 2.615269350865679

Epoch: 6| Step: 8
Training loss: 2.9920890134534286
Validation loss: 2.617780732491521

Epoch: 6| Step: 9
Training loss: 3.024953535999933
Validation loss: 2.6178193888382473

Epoch: 6| Step: 10
Training loss: 3.3818212735207633
Validation loss: 2.6187813047064696

Epoch: 6| Step: 11
Training loss: 3.1488957604035885
Validation loss: 2.6241163669974346

Epoch: 6| Step: 12
Training loss: 2.8757071247408272
Validation loss: 2.6257888977726527

Epoch: 6| Step: 13
Training loss: 1.653595434507168
Validation loss: 2.623538465435134

Epoch: 91| Step: 0
Training loss: 2.843635472936342
Validation loss: 2.6296804357460646

Epoch: 6| Step: 1
Training loss: 3.0736646528522527
Validation loss: 2.6327012610242

Epoch: 6| Step: 2
Training loss: 2.8354865101759255
Validation loss: 2.6269692994983878

Epoch: 6| Step: 3
Training loss: 3.3020002834012647
Validation loss: 2.624483257867218

Epoch: 6| Step: 4
Training loss: 2.433874515116684
Validation loss: 2.619915991908513

Epoch: 6| Step: 5
Training loss: 3.2095647323077974
Validation loss: 2.613403632349302

Epoch: 6| Step: 6
Training loss: 3.382253411235974
Validation loss: 2.6144938453414537

Epoch: 6| Step: 7
Training loss: 2.8916042009655305
Validation loss: 2.6116709814390635

Epoch: 6| Step: 8
Training loss: 2.6176132539077828
Validation loss: 2.61339100443939

Epoch: 6| Step: 9
Training loss: 2.5240417323947155
Validation loss: 2.6141999159701474

Epoch: 6| Step: 10
Training loss: 3.3723672558765454
Validation loss: 2.6165920647318894

Epoch: 6| Step: 11
Training loss: 3.083137574726029
Validation loss: 2.6130761982831623

Epoch: 6| Step: 12
Training loss: 2.200594483597056
Validation loss: 2.6155996928815806

Epoch: 6| Step: 13
Training loss: 3.5989380912745164
Validation loss: 2.6144761728380685

Epoch: 92| Step: 0
Training loss: 2.763325656731422
Validation loss: 2.610277739531733

Epoch: 6| Step: 1
Training loss: 2.957137031628417
Validation loss: 2.611915318096769

Epoch: 6| Step: 2
Training loss: 2.822187566502705
Validation loss: 2.6114098553916025

Epoch: 6| Step: 3
Training loss: 3.035260408595256
Validation loss: 2.6077251596381004

Epoch: 6| Step: 4
Training loss: 3.254241230037559
Validation loss: 2.6083505471552764

Epoch: 6| Step: 5
Training loss: 3.0655861699467284
Validation loss: 2.6094377370278683

Epoch: 6| Step: 6
Training loss: 3.212828884285197
Validation loss: 2.6096835991360505

Epoch: 6| Step: 7
Training loss: 2.620791558527597
Validation loss: 2.607877021710521

Epoch: 6| Step: 8
Training loss: 2.319749346379754
Validation loss: 2.609217388876992

Epoch: 6| Step: 9
Training loss: 3.4229124403912174
Validation loss: 2.609623570546209

Epoch: 6| Step: 10
Training loss: 2.655687339878771
Validation loss: 2.613583943967593

Epoch: 6| Step: 11
Training loss: 3.048824527794563
Validation loss: 2.6252984513543964

Epoch: 6| Step: 12
Training loss: 3.2994032291303825
Validation loss: 2.640210099599763

Epoch: 6| Step: 13
Training loss: 2.4952044268322684
Validation loss: 2.6199011340161573

Epoch: 93| Step: 0
Training loss: 2.8693345681451365
Validation loss: 2.61326772387511

Epoch: 6| Step: 1
Training loss: 3.448070987501718
Validation loss: 2.610096624925345

Epoch: 6| Step: 2
Training loss: 2.7538125745925206
Validation loss: 2.6117043294403564

Epoch: 6| Step: 3
Training loss: 2.641065391519626
Validation loss: 2.6056481368649704

Epoch: 6| Step: 4
Training loss: 3.10620323468318
Validation loss: 2.6049318537276758

Epoch: 6| Step: 5
Training loss: 2.7137796855271046
Validation loss: 2.6063709431537796

Epoch: 6| Step: 6
Training loss: 3.3519165990191024
Validation loss: 2.604403607490006

Epoch: 6| Step: 7
Training loss: 2.6860234839860686
Validation loss: 2.605029938058344

Epoch: 6| Step: 8
Training loss: 3.384697298745958
Validation loss: 2.6044687154195856

Epoch: 6| Step: 9
Training loss: 2.1778637766347178
Validation loss: 2.6061626917921514

Epoch: 6| Step: 10
Training loss: 3.107099304144531
Validation loss: 2.608910598678297

Epoch: 6| Step: 11
Training loss: 3.2766714941114046
Validation loss: 2.604718719706145

Epoch: 6| Step: 12
Training loss: 2.9759205203466723
Validation loss: 2.605048848681568

Epoch: 6| Step: 13
Training loss: 2.3809756343705124
Validation loss: 2.6015459152708527

Epoch: 94| Step: 0
Training loss: 2.6543425050115768
Validation loss: 2.602952604424446

Epoch: 6| Step: 1
Training loss: 3.0771645533733807
Validation loss: 2.6105605422574545

Epoch: 6| Step: 2
Training loss: 2.692514753239271
Validation loss: 2.6203602787179743

Epoch: 6| Step: 3
Training loss: 3.038056430164484
Validation loss: 2.6541713855256055

Epoch: 6| Step: 4
Training loss: 3.1863981848372283
Validation loss: 2.6913553006837354

Epoch: 6| Step: 5
Training loss: 3.4294194353526106
Validation loss: 2.732784290217723

Epoch: 6| Step: 6
Training loss: 3.115280600656255
Validation loss: 2.713755666106658

Epoch: 6| Step: 7
Training loss: 2.6241925223772613
Validation loss: 2.697723515423411

Epoch: 6| Step: 8
Training loss: 3.247307175336391
Validation loss: 2.638175628347568

Epoch: 6| Step: 9
Training loss: 3.153175594048688
Validation loss: 2.6124957809653613

Epoch: 6| Step: 10
Training loss: 2.1770529737287383
Validation loss: 2.6039754289529795

Epoch: 6| Step: 11
Training loss: 2.1752795423442266
Validation loss: 2.597566359139134

Epoch: 6| Step: 12
Training loss: 3.407725443333655
Validation loss: 2.6045401684753053

Epoch: 6| Step: 13
Training loss: 3.201344511580053
Validation loss: 2.6135640739856547

Epoch: 95| Step: 0
Training loss: 3.7205544589721753
Validation loss: 2.61740330831958

Epoch: 6| Step: 1
Training loss: 3.46142712438479
Validation loss: 2.6296987070102147

Epoch: 6| Step: 2
Training loss: 3.250142901286677
Validation loss: 2.652113047045074

Epoch: 6| Step: 3
Training loss: 2.869541958135394
Validation loss: 2.6416321996343255

Epoch: 6| Step: 4
Training loss: 2.9858901087474927
Validation loss: 2.6289281679161394

Epoch: 6| Step: 5
Training loss: 2.428633384555427
Validation loss: 2.6219866479895524

Epoch: 6| Step: 6
Training loss: 2.3047520515324353
Validation loss: 2.6099170369665416

Epoch: 6| Step: 7
Training loss: 3.0164281536533144
Validation loss: 2.6060082684971264

Epoch: 6| Step: 8
Training loss: 3.1903302959820534
Validation loss: 2.6060866105909164

Epoch: 6| Step: 9
Training loss: 2.7898537931792937
Validation loss: 2.6070214422217

Epoch: 6| Step: 10
Training loss: 2.7451115421222188
Validation loss: 2.602733645681497

Epoch: 6| Step: 11
Training loss: 2.6896394597192406
Validation loss: 2.597006612393107

Epoch: 6| Step: 12
Training loss: 3.1765967491543967
Validation loss: 2.599178531673054

Epoch: 6| Step: 13
Training loss: 2.1120503731485765
Validation loss: 2.6046458945735975

Epoch: 96| Step: 0
Training loss: 2.4804014662380403
Validation loss: 2.635135804119117

Epoch: 6| Step: 1
Training loss: 2.6329984967103948
Validation loss: 2.6654191720337916

Epoch: 6| Step: 2
Training loss: 3.186338624496156
Validation loss: 2.694146013839932

Epoch: 6| Step: 3
Training loss: 2.9066567085107198
Validation loss: 2.718484493346832

Epoch: 6| Step: 4
Training loss: 2.7601521107318416
Validation loss: 2.6350422378021854

Epoch: 6| Step: 5
Training loss: 2.8538658559025385
Validation loss: 2.608125081365738

Epoch: 6| Step: 6
Training loss: 2.724446784743271
Validation loss: 2.593980287977915

Epoch: 6| Step: 7
Training loss: 2.602287672544346
Validation loss: 2.585477860438596

Epoch: 6| Step: 8
Training loss: 3.3487292142638028
Validation loss: 2.584225387122221

Epoch: 6| Step: 9
Training loss: 2.7607330332908897
Validation loss: 2.5856179607288325

Epoch: 6| Step: 10
Training loss: 3.6073777258566695
Validation loss: 2.584107527764693

Epoch: 6| Step: 11
Training loss: 2.775302399663218
Validation loss: 2.585665645002334

Epoch: 6| Step: 12
Training loss: 3.5431722395394454
Validation loss: 2.5842789217073268

Epoch: 6| Step: 13
Training loss: 2.8120787411025474
Validation loss: 2.584250169016232

Epoch: 97| Step: 0
Training loss: 2.5694994350654676
Validation loss: 2.5840059923645216

Epoch: 6| Step: 1
Training loss: 1.9734780592084125
Validation loss: 2.5859913510731025

Epoch: 6| Step: 2
Training loss: 3.5099423745579195
Validation loss: 2.587740934581412

Epoch: 6| Step: 3
Training loss: 3.857643387627155
Validation loss: 2.5859492012039005

Epoch: 6| Step: 4
Training loss: 2.863476755667666
Validation loss: 2.5855328335850554

Epoch: 6| Step: 5
Training loss: 2.916755148135895
Validation loss: 2.5880656890567497

Epoch: 6| Step: 6
Training loss: 3.450439098997563
Validation loss: 2.5881233490534363

Epoch: 6| Step: 7
Training loss: 2.357879366726005
Validation loss: 2.5867483307013117

Epoch: 6| Step: 8
Training loss: 2.447032774300037
Validation loss: 2.592311974954256

Epoch: 6| Step: 9
Training loss: 2.913206736726002
Validation loss: 2.5941359540071964

Epoch: 6| Step: 10
Training loss: 3.178615829990395
Validation loss: 2.5907730639925197

Epoch: 6| Step: 11
Training loss: 3.1547745381365386
Validation loss: 2.590838289841481

Epoch: 6| Step: 12
Training loss: 2.995735634460616
Validation loss: 2.592287015969975

Epoch: 6| Step: 13
Training loss: 1.9586733326760624
Validation loss: 2.594830533668883

Epoch: 98| Step: 0
Training loss: 2.8799682480333315
Validation loss: 2.588657436892196

Epoch: 6| Step: 1
Training loss: 2.9918768898324632
Validation loss: 2.5879839931121147

Epoch: 6| Step: 2
Training loss: 3.0186241929275397
Validation loss: 2.584422851973383

Epoch: 6| Step: 3
Training loss: 3.0061442715458044
Validation loss: 2.590586464091573

Epoch: 6| Step: 4
Training loss: 3.016302319297004
Validation loss: 2.588230311334543

Epoch: 6| Step: 5
Training loss: 3.2902768899180965
Validation loss: 2.5872575779585256

Epoch: 6| Step: 6
Training loss: 2.9015980888324644
Validation loss: 2.5892584069993965

Epoch: 6| Step: 7
Training loss: 2.482217007398843
Validation loss: 2.587551619308254

Epoch: 6| Step: 8
Training loss: 2.6516061917483458
Validation loss: 2.5898635059967288

Epoch: 6| Step: 9
Training loss: 3.1884877787417576
Validation loss: 2.5887047566941592

Epoch: 6| Step: 10
Training loss: 2.998619397695601
Validation loss: 2.589392302520863

Epoch: 6| Step: 11
Training loss: 2.861162971182952
Validation loss: 2.586381493984181

Epoch: 6| Step: 12
Training loss: 3.0616885297393015
Validation loss: 2.5855798813888295

Epoch: 6| Step: 13
Training loss: 2.4968623498779987
Validation loss: 2.5810031351614424

Epoch: 99| Step: 0
Training loss: 3.1869623067282795
Validation loss: 2.587281702602351

Epoch: 6| Step: 1
Training loss: 3.3298954082937473
Validation loss: 2.587201494996313

Epoch: 6| Step: 2
Training loss: 3.3416170822105116
Validation loss: 2.5820059394436727

Epoch: 6| Step: 3
Training loss: 3.0492411498044305
Validation loss: 2.580961610057844

Epoch: 6| Step: 4
Training loss: 2.2599002465032627
Validation loss: 2.5820630357834355

Epoch: 6| Step: 5
Training loss: 2.8409769140297154
Validation loss: 2.5854951044948282

Epoch: 6| Step: 6
Training loss: 3.028453677579714
Validation loss: 2.588293544045429

Epoch: 6| Step: 7
Training loss: 3.311874042603714
Validation loss: 2.607465181063666

Epoch: 6| Step: 8
Training loss: 2.726971090137652
Validation loss: 2.6225745084467493

Epoch: 6| Step: 9
Training loss: 3.117615481564966
Validation loss: 2.652650853680778

Epoch: 6| Step: 10
Training loss: 2.0230817445238425
Validation loss: 2.658914362617589

Epoch: 6| Step: 11
Training loss: 2.9332112597582465
Validation loss: 2.633916275439465

Epoch: 6| Step: 12
Training loss: 3.0457976172597507
Validation loss: 2.607593810953429

Epoch: 6| Step: 13
Training loss: 2.63222173294221
Validation loss: 2.5930974153958135

Epoch: 100| Step: 0
Training loss: 3.1951290908070344
Validation loss: 2.5781187652184356

Epoch: 6| Step: 1
Training loss: 3.0652546852423845
Validation loss: 2.582967527518789

Epoch: 6| Step: 2
Training loss: 3.054536391323235
Validation loss: 2.577369937847548

Epoch: 6| Step: 3
Training loss: 2.5752482692696765
Validation loss: 2.5795183162470767

Epoch: 6| Step: 4
Training loss: 3.390131338720436
Validation loss: 2.580275870473805

Epoch: 6| Step: 5
Training loss: 3.110959976551934
Validation loss: 2.586599427534265

Epoch: 6| Step: 6
Training loss: 2.6878080856806794
Validation loss: 2.587625848896906

Epoch: 6| Step: 7
Training loss: 2.445647097964709
Validation loss: 2.5848006733142372

Epoch: 6| Step: 8
Training loss: 3.3801234880721
Validation loss: 2.5797431359881244

Epoch: 6| Step: 9
Training loss: 2.8919420695642954
Validation loss: 2.578059948709264

Epoch: 6| Step: 10
Training loss: 3.314362200432279
Validation loss: 2.5743271135791006

Epoch: 6| Step: 11
Training loss: 2.5274734581705487
Validation loss: 2.5794436207786493

Epoch: 6| Step: 12
Training loss: 2.8650494745320043
Validation loss: 2.574672544386514

Epoch: 6| Step: 13
Training loss: 2.19229907447264
Validation loss: 2.5754888626231676

Epoch: 101| Step: 0
Training loss: 3.159155386546799
Validation loss: 2.571818119508033

Epoch: 6| Step: 1
Training loss: 3.542759999578269
Validation loss: 2.580688517633136

Epoch: 6| Step: 2
Training loss: 3.1839845007993626
Validation loss: 2.5846814168713856

Epoch: 6| Step: 3
Training loss: 2.8694464077183213
Validation loss: 2.5835527448598588

Epoch: 6| Step: 4
Training loss: 2.8333526685466373
Validation loss: 2.5827022536529523

Epoch: 6| Step: 5
Training loss: 2.873254660866559
Validation loss: 2.5923216606131274

Epoch: 6| Step: 6
Training loss: 2.9050306818223284
Validation loss: 2.601370410232226

Epoch: 6| Step: 7
Training loss: 2.5539725233495396
Validation loss: 2.6114707558878227

Epoch: 6| Step: 8
Training loss: 2.9140229005142837
Validation loss: 2.5933828102620278

Epoch: 6| Step: 9
Training loss: 3.0945911227364022
Validation loss: 2.5825517949539654

Epoch: 6| Step: 10
Training loss: 3.1682649560968303
Validation loss: 2.576855219693801

Epoch: 6| Step: 11
Training loss: 2.6780708262996873
Validation loss: 2.5712361817203955

Epoch: 6| Step: 12
Training loss: 2.5221230121413196
Validation loss: 2.574649481527326

Epoch: 6| Step: 13
Training loss: 2.2300143071216025
Validation loss: 2.5734439608618973

Epoch: 102| Step: 0
Training loss: 3.1275243100472494
Validation loss: 2.574885147692161

Epoch: 6| Step: 1
Training loss: 3.194423262668725
Validation loss: 2.575547685091986

Epoch: 6| Step: 2
Training loss: 3.4992026374447636
Validation loss: 2.5771259140767944

Epoch: 6| Step: 3
Training loss: 2.4997417316546096
Validation loss: 2.5749386255723823

Epoch: 6| Step: 4
Training loss: 2.6783782162690852
Validation loss: 2.5739967434325943

Epoch: 6| Step: 5
Training loss: 2.9901744156300767
Validation loss: 2.5836765710959257

Epoch: 6| Step: 6
Training loss: 2.9506328098005494
Validation loss: 2.5715060230340665

Epoch: 6| Step: 7
Training loss: 3.1470617123381373
Validation loss: 2.571537659775632

Epoch: 6| Step: 8
Training loss: 3.014051273813496
Validation loss: 2.5698513436803005

Epoch: 6| Step: 9
Training loss: 2.9678579496028776
Validation loss: 2.5662872616014267

Epoch: 6| Step: 10
Training loss: 2.415783611188139
Validation loss: 2.564605842050984

Epoch: 6| Step: 11
Training loss: 2.9600824012112312
Validation loss: 2.5646614265209338

Epoch: 6| Step: 12
Training loss: 2.6844088497847594
Validation loss: 2.563487215159638

Epoch: 6| Step: 13
Training loss: 2.5762403593294794
Validation loss: 2.568485165379113

Epoch: 103| Step: 0
Training loss: 3.1828133030152093
Validation loss: 2.5685061007319465

Epoch: 6| Step: 1
Training loss: 2.6334968379320203
Validation loss: 2.569956570596678

Epoch: 6| Step: 2
Training loss: 2.638547000711448
Validation loss: 2.5743089382780044

Epoch: 6| Step: 3
Training loss: 3.2661135367417486
Validation loss: 2.5727993777040825

Epoch: 6| Step: 4
Training loss: 2.797183057133506
Validation loss: 2.5741354344235643

Epoch: 6| Step: 5
Training loss: 2.2764530697548735
Validation loss: 2.575028297817596

Epoch: 6| Step: 6
Training loss: 2.861828527862594
Validation loss: 2.573660028516994

Epoch: 6| Step: 7
Training loss: 3.104837451801916
Validation loss: 2.575784209622429

Epoch: 6| Step: 8
Training loss: 3.5376802486153087
Validation loss: 2.572479773584545

Epoch: 6| Step: 9
Training loss: 3.1464627038456845
Validation loss: 2.574915620851204

Epoch: 6| Step: 10
Training loss: 2.6071903425994707
Validation loss: 2.57545195692243

Epoch: 6| Step: 11
Training loss: 2.3781300047171388
Validation loss: 2.5797148683841185

Epoch: 6| Step: 12
Training loss: 2.971381697442207
Validation loss: 2.577355259414301

Epoch: 6| Step: 13
Training loss: 3.3690394289603023
Validation loss: 2.5824723527429434

Epoch: 104| Step: 0
Training loss: 2.7605504609318543
Validation loss: 2.5783329238152577

Epoch: 6| Step: 1
Training loss: 3.2596139295421978
Validation loss: 2.5736169674495133

Epoch: 6| Step: 2
Training loss: 2.6421782310138275
Validation loss: 2.5689485343712897

Epoch: 6| Step: 3
Training loss: 3.0137028868705737
Validation loss: 2.5634259137581576

Epoch: 6| Step: 4
Training loss: 2.55916844094539
Validation loss: 2.563890303592985

Epoch: 6| Step: 5
Training loss: 3.1136126754659554
Validation loss: 2.5632411586262833

Epoch: 6| Step: 6
Training loss: 3.5600020367905865
Validation loss: 2.5608419871507815

Epoch: 6| Step: 7
Training loss: 2.8363495834709376
Validation loss: 2.560770986658522

Epoch: 6| Step: 8
Training loss: 2.574531223625641
Validation loss: 2.561861274744775

Epoch: 6| Step: 9
Training loss: 2.8521492132394686
Validation loss: 2.5646062958800777

Epoch: 6| Step: 10
Training loss: 3.1338750316873516
Validation loss: 2.565040189724868

Epoch: 6| Step: 11
Training loss: 2.812608165780272
Validation loss: 2.5689562209450725

Epoch: 6| Step: 12
Training loss: 2.6674561126731042
Validation loss: 2.573466915979084

Epoch: 6| Step: 13
Training loss: 2.7843737258651338
Validation loss: 2.5705417511245834

Epoch: 105| Step: 0
Training loss: 2.7001664392952223
Validation loss: 2.577346849391329

Epoch: 6| Step: 1
Training loss: 3.479577563724174
Validation loss: 2.5846813028075486

Epoch: 6| Step: 2
Training loss: 3.353402439666805
Validation loss: 2.5693474688563733

Epoch: 6| Step: 3
Training loss: 3.083309551525332
Validation loss: 2.565485217146904

Epoch: 6| Step: 4
Training loss: 3.20063707447363
Validation loss: 2.5608181820529583

Epoch: 6| Step: 5
Training loss: 2.782745302257526
Validation loss: 2.563104614713175

Epoch: 6| Step: 6
Training loss: 2.9641429288948737
Validation loss: 2.563723804401265

Epoch: 6| Step: 7
Training loss: 2.2562064296076567
Validation loss: 2.565220679837297

Epoch: 6| Step: 8
Training loss: 2.9851100475786123
Validation loss: 2.5618253890862475

Epoch: 6| Step: 9
Training loss: 2.813251310240575
Validation loss: 2.5685719089915606

Epoch: 6| Step: 10
Training loss: 2.3862216263168734
Validation loss: 2.5648150087671273

Epoch: 6| Step: 11
Training loss: 2.8877450153716326
Validation loss: 2.568991525499684

Epoch: 6| Step: 12
Training loss: 2.9148960915525515
Validation loss: 2.5668722179739767

Epoch: 6| Step: 13
Training loss: 2.536267617410281
Validation loss: 2.5699060535556923

Epoch: 106| Step: 0
Training loss: 3.262214449374611
Validation loss: 2.568469485960673

Epoch: 6| Step: 1
Training loss: 3.285438988093132
Validation loss: 2.5685279671390213

Epoch: 6| Step: 2
Training loss: 2.2865201091603646
Validation loss: 2.5718413453172904

Epoch: 6| Step: 3
Training loss: 3.3402205048372267
Validation loss: 2.580596149207321

Epoch: 6| Step: 4
Training loss: 3.3754779335987966
Validation loss: 2.599246760951967

Epoch: 6| Step: 5
Training loss: 1.7763877896817588
Validation loss: 2.6025458416304765

Epoch: 6| Step: 6
Training loss: 2.7168872634474024
Validation loss: 2.608862398368746

Epoch: 6| Step: 7
Training loss: 2.6385706748728235
Validation loss: 2.644823514511245

Epoch: 6| Step: 8
Training loss: 2.952331274833477
Validation loss: 2.6316383089905813

Epoch: 6| Step: 9
Training loss: 2.6479172997482667
Validation loss: 2.598565633079117

Epoch: 6| Step: 10
Training loss: 2.9015282451721434
Validation loss: 2.573827657896152

Epoch: 6| Step: 11
Training loss: 3.0908710686492076
Validation loss: 2.5528258003120756

Epoch: 6| Step: 12
Training loss: 3.1068931911490774
Validation loss: 2.5501840609049595

Epoch: 6| Step: 13
Training loss: 2.8691444474851155
Validation loss: 2.5571398334822315

Epoch: 107| Step: 0
Training loss: 2.804976594524685
Validation loss: 2.5662885242975455

Epoch: 6| Step: 1
Training loss: 2.8964165482196758
Validation loss: 2.5712312293883652

Epoch: 6| Step: 2
Training loss: 3.0420678975831326
Validation loss: 2.562769758830584

Epoch: 6| Step: 3
Training loss: 2.9847609984341186
Validation loss: 2.568923795971638

Epoch: 6| Step: 4
Training loss: 2.3902687355809804
Validation loss: 2.5662384765015274

Epoch: 6| Step: 5
Training loss: 2.712196519460668
Validation loss: 2.5655113781901204

Epoch: 6| Step: 6
Training loss: 2.9996684209052136
Validation loss: 2.5665806978731047

Epoch: 6| Step: 7
Training loss: 3.428208434098918
Validation loss: 2.5645009394003853

Epoch: 6| Step: 8
Training loss: 2.6926893655390534
Validation loss: 2.5610103864563007

Epoch: 6| Step: 9
Training loss: 2.4435549138632897
Validation loss: 2.557398634679368

Epoch: 6| Step: 10
Training loss: 2.6892481596279842
Validation loss: 2.5568767859590547

Epoch: 6| Step: 11
Training loss: 3.447935044776518
Validation loss: 2.552642213268237

Epoch: 6| Step: 12
Training loss: 3.0277403344066305
Validation loss: 2.5538358442559606

Epoch: 6| Step: 13
Training loss: 3.6278455680860158
Validation loss: 2.5521811879433414

Epoch: 108| Step: 0
Training loss: 3.1325520623607965
Validation loss: 2.555507368168777

Epoch: 6| Step: 1
Training loss: 3.272224001046521
Validation loss: 2.5537886613680967

Epoch: 6| Step: 2
Training loss: 2.87613854462132
Validation loss: 2.553950108720535

Epoch: 6| Step: 3
Training loss: 3.0015189775829385
Validation loss: 2.5487027575716628

Epoch: 6| Step: 4
Training loss: 2.955298375848945
Validation loss: 2.5458380438218597

Epoch: 6| Step: 5
Training loss: 2.5855786400120424
Validation loss: 2.551640343323098

Epoch: 6| Step: 6
Training loss: 1.731786566258911
Validation loss: 2.557714113401714

Epoch: 6| Step: 7
Training loss: 2.552296584166139
Validation loss: 2.5529058326830554

Epoch: 6| Step: 8
Training loss: 3.1058145198622387
Validation loss: 2.567545117443736

Epoch: 6| Step: 9
Training loss: 3.410694547380669
Validation loss: 2.5739651707793776

Epoch: 6| Step: 10
Training loss: 2.877524552890945
Validation loss: 2.5662324326189143

Epoch: 6| Step: 11
Training loss: 2.7497775247921514
Validation loss: 2.5556994533717234

Epoch: 6| Step: 12
Training loss: 2.914847178829061
Validation loss: 2.554805132113986

Epoch: 6| Step: 13
Training loss: 3.332558414665556
Validation loss: 2.5538827542366995

Epoch: 109| Step: 0
Training loss: 3.249001716470074
Validation loss: 2.5518830157768724

Epoch: 6| Step: 1
Training loss: 3.3480385347288486
Validation loss: 2.551084189665902

Epoch: 6| Step: 2
Training loss: 2.478843817539324
Validation loss: 2.5524955438376913

Epoch: 6| Step: 3
Training loss: 2.4110342247399625
Validation loss: 2.548415946329854

Epoch: 6| Step: 4
Training loss: 3.0727889384647886
Validation loss: 2.545291762095435

Epoch: 6| Step: 5
Training loss: 2.9764210424576802
Validation loss: 2.5501490689932678

Epoch: 6| Step: 6
Training loss: 3.133463423307749
Validation loss: 2.546428372249661

Epoch: 6| Step: 7
Training loss: 2.7618722400880253
Validation loss: 2.547070007891115

Epoch: 6| Step: 8
Training loss: 3.279816668667003
Validation loss: 2.551552075626229

Epoch: 6| Step: 9
Training loss: 2.939049494713052
Validation loss: 2.549502993507984

Epoch: 6| Step: 10
Training loss: 3.31035342931315
Validation loss: 2.540992005440455

Epoch: 6| Step: 11
Training loss: 2.3051815214693674
Validation loss: 2.5452381538418987

Epoch: 6| Step: 12
Training loss: 2.4238582243422213
Validation loss: 2.5455857504160355

Epoch: 6| Step: 13
Training loss: 2.103402052339643
Validation loss: 2.542628651057069

Epoch: 110| Step: 0
Training loss: 2.826559740089431
Validation loss: 2.548810094759308

Epoch: 6| Step: 1
Training loss: 2.587742293803265
Validation loss: 2.5442632251712696

Epoch: 6| Step: 2
Training loss: 2.940243677433969
Validation loss: 2.5598662362623115

Epoch: 6| Step: 3
Training loss: 2.9296083973696
Validation loss: 2.556678417914833

Epoch: 6| Step: 4
Training loss: 3.007778573773764
Validation loss: 2.567899625009635

Epoch: 6| Step: 5
Training loss: 3.1126723705192374
Validation loss: 2.5703063739357384

Epoch: 6| Step: 6
Training loss: 3.0438035400193577
Validation loss: 2.581646091055571

Epoch: 6| Step: 7
Training loss: 2.1236470347159533
Validation loss: 2.5698943890366954

Epoch: 6| Step: 8
Training loss: 3.125725013553106
Validation loss: 2.56483939747894

Epoch: 6| Step: 9
Training loss: 3.069869225416162
Validation loss: 2.5568484610708553

Epoch: 6| Step: 10
Training loss: 3.2953778524054735
Validation loss: 2.5525054207572784

Epoch: 6| Step: 11
Training loss: 3.276864017844328
Validation loss: 2.549155867721469

Epoch: 6| Step: 12
Training loss: 2.4851228560045144
Validation loss: 2.5493825555026186

Epoch: 6| Step: 13
Training loss: 1.6404369428119707
Validation loss: 2.5512038489520896

Epoch: 111| Step: 0
Training loss: 2.099039484794897
Validation loss: 2.5513451656154844

Epoch: 6| Step: 1
Training loss: 2.861361287937086
Validation loss: 2.5485898391291757

Epoch: 6| Step: 2
Training loss: 2.999159377261376
Validation loss: 2.552313295559205

Epoch: 6| Step: 3
Training loss: 3.1255195185836486
Validation loss: 2.5485806863782425

Epoch: 6| Step: 4
Training loss: 2.172084661010516
Validation loss: 2.5470793029548533

Epoch: 6| Step: 5
Training loss: 2.9811818880821583
Validation loss: 2.5467720647600616

Epoch: 6| Step: 6
Training loss: 3.138378953350596
Validation loss: 2.543713867966118

Epoch: 6| Step: 7
Training loss: 3.077886272022314
Validation loss: 2.5415424341442336

Epoch: 6| Step: 8
Training loss: 2.5427542272226376
Validation loss: 2.5450327662890615

Epoch: 6| Step: 9
Training loss: 3.097901766308727
Validation loss: 2.5525149822700337

Epoch: 6| Step: 10
Training loss: 3.30100573617182
Validation loss: 2.556581287291914

Epoch: 6| Step: 11
Training loss: 2.213811832471279
Validation loss: 2.561048428204198

Epoch: 6| Step: 12
Training loss: 3.2069328190779274
Validation loss: 2.5598770511620703

Epoch: 6| Step: 13
Training loss: 3.292739226644749
Validation loss: 2.5573239296978034

Epoch: 112| Step: 0
Training loss: 3.082900781619331
Validation loss: 2.551881787141691

Epoch: 6| Step: 1
Training loss: 2.8443337983559043
Validation loss: 2.5506413243051274

Epoch: 6| Step: 2
Training loss: 2.3818008026121693
Validation loss: 2.540813279243612

Epoch: 6| Step: 3
Training loss: 2.967804768313149
Validation loss: 2.535706447151702

Epoch: 6| Step: 4
Training loss: 2.2921278287249454
Validation loss: 2.537290858761868

Epoch: 6| Step: 5
Training loss: 3.123808061259345
Validation loss: 2.534156226785879

Epoch: 6| Step: 6
Training loss: 2.4736796546714666
Validation loss: 2.5355538144771512

Epoch: 6| Step: 7
Training loss: 2.4824972673998467
Validation loss: 2.537128817134011

Epoch: 6| Step: 8
Training loss: 3.326689217923569
Validation loss: 2.5406713232988687

Epoch: 6| Step: 9
Training loss: 3.1064138449856227
Validation loss: 2.543202308658341

Epoch: 6| Step: 10
Training loss: 3.4713507173162874
Validation loss: 2.543605062933115

Epoch: 6| Step: 11
Training loss: 2.978046838108948
Validation loss: 2.547528744991197

Epoch: 6| Step: 12
Training loss: 2.499369541781342
Validation loss: 2.54367794146344

Epoch: 6| Step: 13
Training loss: 3.1342156899339
Validation loss: 2.5494285438614335

Epoch: 113| Step: 0
Training loss: 2.6876516077615733
Validation loss: 2.5466069640932525

Epoch: 6| Step: 1
Training loss: 2.5777835504240683
Validation loss: 2.5485331808699074

Epoch: 6| Step: 2
Training loss: 3.2999682627221043
Validation loss: 2.54675688080577

Epoch: 6| Step: 3
Training loss: 3.2822718890986597
Validation loss: 2.5525560792929345

Epoch: 6| Step: 4
Training loss: 2.9303898897596987
Validation loss: 2.5526957584262187

Epoch: 6| Step: 5
Training loss: 2.8004487291167504
Validation loss: 2.548709687944344

Epoch: 6| Step: 6
Training loss: 2.642301850915239
Validation loss: 2.531138172664682

Epoch: 6| Step: 7
Training loss: 2.9709143529030175
Validation loss: 2.5323980642943087

Epoch: 6| Step: 8
Training loss: 3.068987611479007
Validation loss: 2.5348912306954916

Epoch: 6| Step: 9
Training loss: 3.084470144116537
Validation loss: 2.537572190931745

Epoch: 6| Step: 10
Training loss: 3.0123412284324087
Validation loss: 2.5378896635022348

Epoch: 6| Step: 11
Training loss: 2.720002773648138
Validation loss: 2.5394763421850346

Epoch: 6| Step: 12
Training loss: 2.6243541467959646
Validation loss: 2.5406186609217234

Epoch: 6| Step: 13
Training loss: 2.3457245710601122
Validation loss: 2.5425282159081117

Epoch: 114| Step: 0
Training loss: 2.983123037360389
Validation loss: 2.538658973552975

Epoch: 6| Step: 1
Training loss: 3.3052183045097503
Validation loss: 2.5416195023018897

Epoch: 6| Step: 2
Training loss: 2.8734216089104834
Validation loss: 2.5343754365433915

Epoch: 6| Step: 3
Training loss: 2.5344240985822815
Validation loss: 2.5372616968622874

Epoch: 6| Step: 4
Training loss: 1.9499037156420462
Validation loss: 2.5462093805879826

Epoch: 6| Step: 5
Training loss: 2.957678619433987
Validation loss: 2.556803354166656

Epoch: 6| Step: 6
Training loss: 2.732843286112952
Validation loss: 2.5600828219883707

Epoch: 6| Step: 7
Training loss: 2.9668917009820976
Validation loss: 2.5630695691461054

Epoch: 6| Step: 8
Training loss: 3.1538791627927876
Validation loss: 2.5539038474361124

Epoch: 6| Step: 9
Training loss: 3.035954864970603
Validation loss: 2.5606186516140714

Epoch: 6| Step: 10
Training loss: 3.3539657690568165
Validation loss: 2.562166861632184

Epoch: 6| Step: 11
Training loss: 2.588842782531847
Validation loss: 2.551395821063486

Epoch: 6| Step: 12
Training loss: 2.8716645172990787
Validation loss: 2.5545826276036374

Epoch: 6| Step: 13
Training loss: 2.1569314515633464
Validation loss: 2.549346215132517

Epoch: 115| Step: 0
Training loss: 2.667505182119983
Validation loss: 2.538802677866903

Epoch: 6| Step: 1
Training loss: 2.9567961303281027
Validation loss: 2.5437987049869455

Epoch: 6| Step: 2
Training loss: 2.5179387227208196
Validation loss: 2.535947677317619

Epoch: 6| Step: 3
Training loss: 2.0117159056411933
Validation loss: 2.5371880015043646

Epoch: 6| Step: 4
Training loss: 3.334665096001431
Validation loss: 2.5331476244541262

Epoch: 6| Step: 5
Training loss: 3.2736583261956222
Validation loss: 2.5311341699137015

Epoch: 6| Step: 6
Training loss: 2.8361441376702126
Validation loss: 2.5278941892109015

Epoch: 6| Step: 7
Training loss: 2.2471632559005217
Validation loss: 2.5304415581707502

Epoch: 6| Step: 8
Training loss: 2.9905480258327253
Validation loss: 2.529049051053035

Epoch: 6| Step: 9
Training loss: 3.633105063194226
Validation loss: 2.5324149925395276

Epoch: 6| Step: 10
Training loss: 2.618790502849539
Validation loss: 2.537729272406275

Epoch: 6| Step: 11
Training loss: 2.6018441995689456
Validation loss: 2.5430318278514896

Epoch: 6| Step: 12
Training loss: 3.1003723167060544
Validation loss: 2.5444038079186577

Epoch: 6| Step: 13
Training loss: 2.7524454341126066
Validation loss: 2.544027103559984

Epoch: 116| Step: 0
Training loss: 2.749698969230399
Validation loss: 2.5432294428388422

Epoch: 6| Step: 1
Training loss: 2.5667284062213733
Validation loss: 2.557778533516177

Epoch: 6| Step: 2
Training loss: 3.2843180527182705
Validation loss: 2.5672370421384447

Epoch: 6| Step: 3
Training loss: 2.2332401194501736
Validation loss: 2.5661774576082705

Epoch: 6| Step: 4
Training loss: 2.604185139908436
Validation loss: 2.5619200723805187

Epoch: 6| Step: 5
Training loss: 3.161742313373555
Validation loss: 2.5635067152524527

Epoch: 6| Step: 6
Training loss: 3.336853044648078
Validation loss: 2.550515645954255

Epoch: 6| Step: 7
Training loss: 2.5122846140990416
Validation loss: 2.5507611822603904

Epoch: 6| Step: 8
Training loss: 3.465561647240279
Validation loss: 2.5467592322912243

Epoch: 6| Step: 9
Training loss: 2.475347852826482
Validation loss: 2.5396364927252884

Epoch: 6| Step: 10
Training loss: 2.5503365799419475
Validation loss: 2.535780399390586

Epoch: 6| Step: 11
Training loss: 2.5723989998107397
Validation loss: 2.5375628832696515

Epoch: 6| Step: 12
Training loss: 3.3828919998236278
Validation loss: 2.5479023920475563

Epoch: 6| Step: 13
Training loss: 2.786091737013199
Validation loss: 2.5335162697701294

Epoch: 117| Step: 0
Training loss: 2.8604120760605536
Validation loss: 2.5377923885602254

Epoch: 6| Step: 1
Training loss: 2.5286098887556654
Validation loss: 2.5294229731704134

Epoch: 6| Step: 2
Training loss: 2.4211491635367546
Validation loss: 2.5329882204810104

Epoch: 6| Step: 3
Training loss: 2.802863332725746
Validation loss: 2.5300019439862624

Epoch: 6| Step: 4
Training loss: 2.6248205214405402
Validation loss: 2.5234625039918646

Epoch: 6| Step: 5
Training loss: 3.102765136013007
Validation loss: 2.527156366107677

Epoch: 6| Step: 6
Training loss: 3.651293141424591
Validation loss: 2.532113478306555

Epoch: 6| Step: 7
Training loss: 3.393052177273104
Validation loss: 2.5281216396042403

Epoch: 6| Step: 8
Training loss: 2.4222390178172004
Validation loss: 2.533393428364426

Epoch: 6| Step: 9
Training loss: 2.624702981766256
Validation loss: 2.532539074883838

Epoch: 6| Step: 10
Training loss: 2.716891124634492
Validation loss: 2.53349869013829

Epoch: 6| Step: 11
Training loss: 2.891457597575005
Validation loss: 2.5382848899637276

Epoch: 6| Step: 12
Training loss: 2.835207338101468
Validation loss: 2.5344802660800156

Epoch: 6| Step: 13
Training loss: 2.9134491384900407
Validation loss: 2.5294326832553717

Epoch: 118| Step: 0
Training loss: 3.0366229388385815
Validation loss: 2.5249354807577644

Epoch: 6| Step: 1
Training loss: 3.4125867224772084
Validation loss: 2.516668933779646

Epoch: 6| Step: 2
Training loss: 2.505741678567584
Validation loss: 2.5129341006381516

Epoch: 6| Step: 3
Training loss: 2.657680619885172
Validation loss: 2.515361159836328

Epoch: 6| Step: 4
Training loss: 3.1993606405500428
Validation loss: 2.5110619944856474

Epoch: 6| Step: 5
Training loss: 2.94327610356245
Validation loss: 2.514944809149637

Epoch: 6| Step: 6
Training loss: 3.0630480217576985
Validation loss: 2.513142454220243

Epoch: 6| Step: 7
Training loss: 2.792675680510082
Validation loss: 2.5117740289793584

Epoch: 6| Step: 8
Training loss: 3.138770927380702
Validation loss: 2.509768882453445

Epoch: 6| Step: 9
Training loss: 2.545580201329624
Validation loss: 2.5114439221294966

Epoch: 6| Step: 10
Training loss: 2.5800242508628255
Validation loss: 2.5133597788340563

Epoch: 6| Step: 11
Training loss: 2.4915254006374257
Validation loss: 2.5176545398538965

Epoch: 6| Step: 12
Training loss: 2.7599752876999823
Validation loss: 2.526870601339843

Epoch: 6| Step: 13
Training loss: 2.4919155056131976
Validation loss: 2.525847492846652

Epoch: 119| Step: 0
Training loss: 2.7979768255663324
Validation loss: 2.5363251813977654

Epoch: 6| Step: 1
Training loss: 2.7978636629864857
Validation loss: 2.5383482346936184

Epoch: 6| Step: 2
Training loss: 3.2504316190067537
Validation loss: 2.538792669884542

Epoch: 6| Step: 3
Training loss: 3.1563933689301575
Validation loss: 2.5424769305433705

Epoch: 6| Step: 4
Training loss: 2.8706383168754432
Validation loss: 2.537137820223401

Epoch: 6| Step: 5
Training loss: 2.512680605190391
Validation loss: 2.5413377576931375

Epoch: 6| Step: 6
Training loss: 2.7015983371773555
Validation loss: 2.5376159384057733

Epoch: 6| Step: 7
Training loss: 2.6528087989187243
Validation loss: 2.528703107848757

Epoch: 6| Step: 8
Training loss: 2.3411861383676573
Validation loss: 2.5320945626152542

Epoch: 6| Step: 9
Training loss: 3.2347520986199805
Validation loss: 2.530826702853222

Epoch: 6| Step: 10
Training loss: 2.5266731233271065
Validation loss: 2.533147064797273

Epoch: 6| Step: 11
Training loss: 2.956891760817915
Validation loss: 2.541106476183136

Epoch: 6| Step: 12
Training loss: 2.6980125282567937
Validation loss: 2.5278783553810014

Epoch: 6| Step: 13
Training loss: 3.30502310417283
Validation loss: 2.5127092106499203

Epoch: 120| Step: 0
Training loss: 2.9528374103000457
Validation loss: 2.516992012964109

Epoch: 6| Step: 1
Training loss: 2.622746181224544
Validation loss: 2.515761542737153

Epoch: 6| Step: 2
Training loss: 2.5856382997874783
Validation loss: 2.511725952870952

Epoch: 6| Step: 3
Training loss: 2.9886195172106373
Validation loss: 2.512528947045011

Epoch: 6| Step: 4
Training loss: 2.850757223892058
Validation loss: 2.5091935474374574

Epoch: 6| Step: 5
Training loss: 2.0465145812960923
Validation loss: 2.5048484563375415

Epoch: 6| Step: 6
Training loss: 3.0295691795125177
Validation loss: 2.506061797355748

Epoch: 6| Step: 7
Training loss: 2.567759907316078
Validation loss: 2.5051438050812105

Epoch: 6| Step: 8
Training loss: 3.15401356844986
Validation loss: 2.512506709597228

Epoch: 6| Step: 9
Training loss: 2.4576515178985314
Validation loss: 2.5061639926029295

Epoch: 6| Step: 10
Training loss: 2.905651728260354
Validation loss: 2.5075192174403185

Epoch: 6| Step: 11
Training loss: 3.436383568924732
Validation loss: 2.511018000826157

Epoch: 6| Step: 12
Training loss: 3.2918269122428074
Validation loss: 2.5197501316817084

Epoch: 6| Step: 13
Training loss: 2.2461548904722015
Validation loss: 2.5243774926799647

Epoch: 121| Step: 0
Training loss: 2.712790875286617
Validation loss: 2.5110574359897395

Epoch: 6| Step: 1
Training loss: 1.979479299916422
Validation loss: 2.510806119890938

Epoch: 6| Step: 2
Training loss: 2.6103425202389685
Validation loss: 2.51244493470173

Epoch: 6| Step: 3
Training loss: 2.9530290860540225
Validation loss: 2.5089333506236273

Epoch: 6| Step: 4
Training loss: 3.610632210952613
Validation loss: 2.505463304469002

Epoch: 6| Step: 5
Training loss: 3.4184104067332677
Validation loss: 2.503779494895394

Epoch: 6| Step: 6
Training loss: 3.005001825722443
Validation loss: 2.506915361124387

Epoch: 6| Step: 7
Training loss: 2.539034893179245
Validation loss: 2.512983396186368

Epoch: 6| Step: 8
Training loss: 2.6559070141325556
Validation loss: 2.511329403937103

Epoch: 6| Step: 9
Training loss: 2.400843205941992
Validation loss: 2.5148231952337707

Epoch: 6| Step: 10
Training loss: 3.3112990883529165
Validation loss: 2.5177120386107994

Epoch: 6| Step: 11
Training loss: 2.502860245055748
Validation loss: 2.5149650678800057

Epoch: 6| Step: 12
Training loss: 2.5626367672033736
Validation loss: 2.5135078782399

Epoch: 6| Step: 13
Training loss: 3.0964927460523755
Validation loss: 2.5204998566315044

Epoch: 122| Step: 0
Training loss: 2.9450594441708144
Validation loss: 2.5101953537503636

Epoch: 6| Step: 1
Training loss: 2.733543749207795
Validation loss: 2.518376850772802

Epoch: 6| Step: 2
Training loss: 2.923221216810262
Validation loss: 2.525220974163562

Epoch: 6| Step: 3
Training loss: 2.9386730692540444
Validation loss: 2.5277225380244093

Epoch: 6| Step: 4
Training loss: 2.889830774018752
Validation loss: 2.5230590227640066

Epoch: 6| Step: 5
Training loss: 2.549430828525943
Validation loss: 2.5196206302978497

Epoch: 6| Step: 6
Training loss: 2.673707211131109
Validation loss: 2.508633953091728

Epoch: 6| Step: 7
Training loss: 2.308800392778169
Validation loss: 2.5076369914610854

Epoch: 6| Step: 8
Training loss: 3.2676554669007274
Validation loss: 2.5056176555496856

Epoch: 6| Step: 9
Training loss: 2.884833064546844
Validation loss: 2.5006432177515885

Epoch: 6| Step: 10
Training loss: 2.803594519717063
Validation loss: 2.506634140167981

Epoch: 6| Step: 11
Training loss: 2.984676166137865
Validation loss: 2.507414328131598

Epoch: 6| Step: 12
Training loss: 2.8079319626534525
Validation loss: 2.5065434795873713

Epoch: 6| Step: 13
Training loss: 2.869631191043097
Validation loss: 2.5087317393753863

Epoch: 123| Step: 0
Training loss: 1.8453736995203296
Validation loss: 2.505039492773879

Epoch: 6| Step: 1
Training loss: 1.7339031505531233
Validation loss: 2.50127740649565

Epoch: 6| Step: 2
Training loss: 2.4539060867732156
Validation loss: 2.497652502173655

Epoch: 6| Step: 3
Training loss: 3.2146749533260732
Validation loss: 2.504189158325952

Epoch: 6| Step: 4
Training loss: 2.8807133834830427
Validation loss: 2.5150243140969266

Epoch: 6| Step: 5
Training loss: 3.2609746940915336
Validation loss: 2.522956184809397

Epoch: 6| Step: 6
Training loss: 2.9112964419062943
Validation loss: 2.5278871606983158

Epoch: 6| Step: 7
Training loss: 3.103273164990129
Validation loss: 2.5279775299280436

Epoch: 6| Step: 8
Training loss: 2.716365601721233
Validation loss: 2.5477168694073433

Epoch: 6| Step: 9
Training loss: 2.9986287797960247
Validation loss: 2.535046997780252

Epoch: 6| Step: 10
Training loss: 3.027454635066034
Validation loss: 2.538768353079736

Epoch: 6| Step: 11
Training loss: 2.6749817036511043
Validation loss: 2.5426942150913745

Epoch: 6| Step: 12
Training loss: 3.3588795851088116
Validation loss: 2.539808466196784

Epoch: 6| Step: 13
Training loss: 2.8840524544780153
Validation loss: 2.5272545069130654

Epoch: 124| Step: 0
Training loss: 2.8430513634645878
Validation loss: 2.517738346796971

Epoch: 6| Step: 1
Training loss: 2.622411632521817
Validation loss: 2.5077056918245124

Epoch: 6| Step: 2
Training loss: 2.184685013018952
Validation loss: 2.5051668835796126

Epoch: 6| Step: 3
Training loss: 2.555141210367723
Validation loss: 2.5076379355856493

Epoch: 6| Step: 4
Training loss: 2.973970501146071
Validation loss: 2.508674950421967

Epoch: 6| Step: 5
Training loss: 3.1916497836816
Validation loss: 2.520115111290936

Epoch: 6| Step: 6
Training loss: 2.8037244583170584
Validation loss: 2.5295752065540262

Epoch: 6| Step: 7
Training loss: 3.181867971897699
Validation loss: 2.5255312411637503

Epoch: 6| Step: 8
Training loss: 2.2280485848997063
Validation loss: 2.519893375569724

Epoch: 6| Step: 9
Training loss: 2.6686796299682034
Validation loss: 2.52023095649493

Epoch: 6| Step: 10
Training loss: 3.382430903031389
Validation loss: 2.514282050516792

Epoch: 6| Step: 11
Training loss: 3.2289827520028553
Validation loss: 2.5101975158230805

Epoch: 6| Step: 12
Training loss: 2.9422805520211286
Validation loss: 2.502628006479627

Epoch: 6| Step: 13
Training loss: 2.5738467698804874
Validation loss: 2.496561505771226

Epoch: 125| Step: 0
Training loss: 2.7251324332717535
Validation loss: 2.500989920992054

Epoch: 6| Step: 1
Training loss: 3.0606749409828464
Validation loss: 2.497452152338347

Epoch: 6| Step: 2
Training loss: 2.9679696111434324
Validation loss: 2.5006769586590365

Epoch: 6| Step: 3
Training loss: 3.013690861897415
Validation loss: 2.503803515157212

Epoch: 6| Step: 4
Training loss: 2.776134544283668
Validation loss: 2.5124213047036332

Epoch: 6| Step: 5
Training loss: 3.0531112623735366
Validation loss: 2.512862399449637

Epoch: 6| Step: 6
Training loss: 2.81558533025606
Validation loss: 2.502494586722652

Epoch: 6| Step: 7
Training loss: 2.1560644539875273
Validation loss: 2.501729708308727

Epoch: 6| Step: 8
Training loss: 2.6986846616255606
Validation loss: 2.5004727849700363

Epoch: 6| Step: 9
Training loss: 2.6169143761988005
Validation loss: 2.4997101133719486

Epoch: 6| Step: 10
Training loss: 3.2787468944888256
Validation loss: 2.5014523153694763

Epoch: 6| Step: 11
Training loss: 2.833621926663224
Validation loss: 2.5052613730362405

Epoch: 6| Step: 12
Training loss: 2.8764762405483144
Validation loss: 2.4988775512499957

Epoch: 6| Step: 13
Training loss: 2.240065577432663
Validation loss: 2.502089143327773

Epoch: 126| Step: 0
Training loss: 3.195112972978454
Validation loss: 2.5123747460796677

Epoch: 6| Step: 1
Training loss: 1.348580217820614
Validation loss: 2.5128488449385133

Epoch: 6| Step: 2
Training loss: 2.9887407734918754
Validation loss: 2.52143530868874

Epoch: 6| Step: 3
Training loss: 3.1094789727238106
Validation loss: 2.5229896964126324

Epoch: 6| Step: 4
Training loss: 3.4263207109816722
Validation loss: 2.527441863242809

Epoch: 6| Step: 5
Training loss: 2.9526063170901575
Validation loss: 2.536074186776595

Epoch: 6| Step: 6
Training loss: 2.5445264976112743
Validation loss: 2.541108499971244

Epoch: 6| Step: 7
Training loss: 3.0349644191610765
Validation loss: 2.539730860583244

Epoch: 6| Step: 8
Training loss: 2.3107326042744605
Validation loss: 2.534551962596166

Epoch: 6| Step: 9
Training loss: 2.68260314515573
Validation loss: 2.523490345175928

Epoch: 6| Step: 10
Training loss: 2.969278870706476
Validation loss: 2.525034720126184

Epoch: 6| Step: 11
Training loss: 2.9660695071471315
Validation loss: 2.525994436881581

Epoch: 6| Step: 12
Training loss: 2.573552000443515
Validation loss: 2.5119142428999224

Epoch: 6| Step: 13
Training loss: 2.738230923830954
Validation loss: 2.5222409311022638

Epoch: 127| Step: 0
Training loss: 2.7708638889855597
Validation loss: 2.5243698232075715

Epoch: 6| Step: 1
Training loss: 3.008730899257278
Validation loss: 2.518333850191465

Epoch: 6| Step: 2
Training loss: 3.4354583225689694
Validation loss: 2.524018314567692

Epoch: 6| Step: 3
Training loss: 2.6173894548072103
Validation loss: 2.5396833328758803

Epoch: 6| Step: 4
Training loss: 2.47388137429984
Validation loss: 2.547433917266993

Epoch: 6| Step: 5
Training loss: 2.9914852742606244
Validation loss: 2.554972576236359

Epoch: 6| Step: 6
Training loss: 2.8738868880554285
Validation loss: 2.5525802547075367

Epoch: 6| Step: 7
Training loss: 2.598026840047825
Validation loss: 2.562199716809283

Epoch: 6| Step: 8
Training loss: 2.8939331919479425
Validation loss: 2.558222368984479

Epoch: 6| Step: 9
Training loss: 2.7245477703608936
Validation loss: 2.5299195439538216

Epoch: 6| Step: 10
Training loss: 2.5265110064881493
Validation loss: 2.5036980012185808

Epoch: 6| Step: 11
Training loss: 2.3301195650980207
Validation loss: 2.4990082157877787

Epoch: 6| Step: 12
Training loss: 3.072154805196953
Validation loss: 2.501042757680131

Epoch: 6| Step: 13
Training loss: 3.0742987848936916
Validation loss: 2.5021252059154846

Epoch: 128| Step: 0
Training loss: 2.651868550087994
Validation loss: 2.4988295599368593

Epoch: 6| Step: 1
Training loss: 3.2169866083238157
Validation loss: 2.497165557979984

Epoch: 6| Step: 2
Training loss: 3.2124245720108937
Validation loss: 2.4946138709646903

Epoch: 6| Step: 3
Training loss: 2.822238929912676
Validation loss: 2.4898502740323045

Epoch: 6| Step: 4
Training loss: 2.310663163909781
Validation loss: 2.4834813560165685

Epoch: 6| Step: 5
Training loss: 2.8019029826346022
Validation loss: 2.4874677146761837

Epoch: 6| Step: 6
Training loss: 3.1672540086520162
Validation loss: 2.4881507031932046

Epoch: 6| Step: 7
Training loss: 2.4508079714621007
Validation loss: 2.484134138446333

Epoch: 6| Step: 8
Training loss: 2.2889686539196443
Validation loss: 2.4983220632451415

Epoch: 6| Step: 9
Training loss: 2.5368327047953203
Validation loss: 2.503174425591968

Epoch: 6| Step: 10
Training loss: 3.008336247013897
Validation loss: 2.504484191237348

Epoch: 6| Step: 11
Training loss: 3.0427830532937477
Validation loss: 2.5014565152458603

Epoch: 6| Step: 12
Training loss: 2.9860475656613525
Validation loss: 2.5061777745563103

Epoch: 6| Step: 13
Training loss: 2.7243639982473504
Validation loss: 2.508353769019277

Epoch: 129| Step: 0
Training loss: 3.0642483450141365
Validation loss: 2.508747098291686

Epoch: 6| Step: 1
Training loss: 3.307115316820688
Validation loss: 2.499496582064393

Epoch: 6| Step: 2
Training loss: 3.0759449321048966
Validation loss: 2.498552537089885

Epoch: 6| Step: 3
Training loss: 2.049844582411612
Validation loss: 2.4957517152404844

Epoch: 6| Step: 4
Training loss: 3.218468070414227
Validation loss: 2.4930826994728705

Epoch: 6| Step: 5
Training loss: 2.6517418696754578
Validation loss: 2.4962504150282485

Epoch: 6| Step: 6
Training loss: 2.5701850465289224
Validation loss: 2.4952617843454554

Epoch: 6| Step: 7
Training loss: 2.579279230852683
Validation loss: 2.513636287097508

Epoch: 6| Step: 8
Training loss: 3.0301237865379633
Validation loss: 2.519595673648357

Epoch: 6| Step: 9
Training loss: 2.88881251242333
Validation loss: 2.5278374129147556

Epoch: 6| Step: 10
Training loss: 2.504001276412005
Validation loss: 2.5380405436059634

Epoch: 6| Step: 11
Training loss: 2.7735786509525955
Validation loss: 2.5522264307791374

Epoch: 6| Step: 12
Training loss: 2.7096443719943517
Validation loss: 2.542662459936802

Epoch: 6| Step: 13
Training loss: 2.5353786564916123
Validation loss: 2.5261616245241947

Epoch: 130| Step: 0
Training loss: 2.4384212220267183
Validation loss: 2.5224171548464196

Epoch: 6| Step: 1
Training loss: 2.5507858299693282
Validation loss: 2.516339664678752

Epoch: 6| Step: 2
Training loss: 2.2434506995044883
Validation loss: 2.514654674687562

Epoch: 6| Step: 3
Training loss: 3.3339310269146423
Validation loss: 2.5198317018971506

Epoch: 6| Step: 4
Training loss: 2.595489562056057
Validation loss: 2.5038346578599695

Epoch: 6| Step: 5
Training loss: 3.2577631738528234
Validation loss: 2.496829448648272

Epoch: 6| Step: 6
Training loss: 2.9177009020411897
Validation loss: 2.48610830747012

Epoch: 6| Step: 7
Training loss: 3.168908446675007
Validation loss: 2.4817997602849737

Epoch: 6| Step: 8
Training loss: 1.8906460595337298
Validation loss: 2.478713078797177

Epoch: 6| Step: 9
Training loss: 2.925082318052402
Validation loss: 2.483291408239699

Epoch: 6| Step: 10
Training loss: 3.142666736631375
Validation loss: 2.4837313160180985

Epoch: 6| Step: 11
Training loss: 2.7627175776210438
Validation loss: 2.488982538784156

Epoch: 6| Step: 12
Training loss: 2.8741923317261526
Validation loss: 2.494534404063787

Epoch: 6| Step: 13
Training loss: 2.8748644921254107
Validation loss: 2.495628375559945

Epoch: 131| Step: 0
Training loss: 3.2504354331952348
Validation loss: 2.509135092800317

Epoch: 6| Step: 1
Training loss: 3.2083798359725115
Validation loss: 2.5224510892895156

Epoch: 6| Step: 2
Training loss: 2.471115813637718
Validation loss: 2.5343409324300374

Epoch: 6| Step: 3
Training loss: 2.8960798602289493
Validation loss: 2.5344252456546377

Epoch: 6| Step: 4
Training loss: 2.595834285272594
Validation loss: 2.5233801723439715

Epoch: 6| Step: 5
Training loss: 2.7287933929110624
Validation loss: 2.5198957790833694

Epoch: 6| Step: 6
Training loss: 2.5080742149810447
Validation loss: 2.503956363177712

Epoch: 6| Step: 7
Training loss: 2.877633920000781
Validation loss: 2.4922364344206174

Epoch: 6| Step: 8
Training loss: 2.7106480512634987
Validation loss: 2.4904956030914596

Epoch: 6| Step: 9
Training loss: 2.709131876279058
Validation loss: 2.4923587102100933

Epoch: 6| Step: 10
Training loss: 2.780790826847763
Validation loss: 2.491218502212171

Epoch: 6| Step: 11
Training loss: 2.711699716670995
Validation loss: 2.4883972543769683

Epoch: 6| Step: 12
Training loss: 2.6817002814228785
Validation loss: 2.4972625634929426

Epoch: 6| Step: 13
Training loss: 3.031773630121371
Validation loss: 2.4989028604910053

Epoch: 132| Step: 0
Training loss: 2.7989080275252722
Validation loss: 2.4960192664222944

Epoch: 6| Step: 1
Training loss: 2.5611592949090314
Validation loss: 2.4961203692260203

Epoch: 6| Step: 2
Training loss: 2.212868861253855
Validation loss: 2.4963704043706825

Epoch: 6| Step: 3
Training loss: 2.802653220460518
Validation loss: 2.4979474224607725

Epoch: 6| Step: 4
Training loss: 2.9065879707299067
Validation loss: 2.4996715740109536

Epoch: 6| Step: 5
Training loss: 2.8555225205479373
Validation loss: 2.5044982270783467

Epoch: 6| Step: 6
Training loss: 3.2170233678612337
Validation loss: 2.5079841257308555

Epoch: 6| Step: 7
Training loss: 2.92998631288632
Validation loss: 2.515996552048916

Epoch: 6| Step: 8
Training loss: 2.541522433665057
Validation loss: 2.5269929167796925

Epoch: 6| Step: 9
Training loss: 1.9134937920670274
Validation loss: 2.5407984713472938

Epoch: 6| Step: 10
Training loss: 2.9936253850242878
Validation loss: 2.562665964470152

Epoch: 6| Step: 11
Training loss: 3.0924602864335937
Validation loss: 2.597140227895252

Epoch: 6| Step: 12
Training loss: 3.66196848687322
Validation loss: 2.6714254693268114

Epoch: 6| Step: 13
Training loss: 2.3631334495040255
Validation loss: 2.662202404090041

Epoch: 133| Step: 0
Training loss: 2.760017011009536
Validation loss: 2.6439237834360583

Epoch: 6| Step: 1
Training loss: 2.866320070856741
Validation loss: 2.622751883744794

Epoch: 6| Step: 2
Training loss: 3.5660148815330177
Validation loss: 2.6137017727893976

Epoch: 6| Step: 3
Training loss: 2.9861591857667698
Validation loss: 2.5871862193400545

Epoch: 6| Step: 4
Training loss: 2.927307627129007
Validation loss: 2.517730815945117

Epoch: 6| Step: 5
Training loss: 3.0111662955425795
Validation loss: 2.5027775798446057

Epoch: 6| Step: 6
Training loss: 2.234281738042168
Validation loss: 2.511390721389881

Epoch: 6| Step: 7
Training loss: 3.040566824722092
Validation loss: 2.5200533642044847

Epoch: 6| Step: 8
Training loss: 3.0327530113647394
Validation loss: 2.5460673207281292

Epoch: 6| Step: 9
Training loss: 2.8259380167368278
Validation loss: 2.610539329408542

Epoch: 6| Step: 10
Training loss: 3.2949841034987664
Validation loss: 2.6796338480700252

Epoch: 6| Step: 11
Training loss: 3.1183654548082096
Validation loss: 2.597438824683419

Epoch: 6| Step: 12
Training loss: 2.190998223001516
Validation loss: 2.5224400346528513

Epoch: 6| Step: 13
Training loss: 1.8658631548160225
Validation loss: 2.5016989544300174

Epoch: 134| Step: 0
Training loss: 2.5680003796455364
Validation loss: 2.496555484206453

Epoch: 6| Step: 1
Training loss: 2.4322002211268328
Validation loss: 2.5067206555099495

Epoch: 6| Step: 2
Training loss: 2.418829399599665
Validation loss: 2.546550739904718

Epoch: 6| Step: 3
Training loss: 2.337381280342346
Validation loss: 2.5958268935851647

Epoch: 6| Step: 4
Training loss: 3.2048650713770184
Validation loss: 2.6226853666035455

Epoch: 6| Step: 5
Training loss: 2.7279320367865947
Validation loss: 2.6378398803602487

Epoch: 6| Step: 6
Training loss: 2.4435912097747203
Validation loss: 2.6481966337539657

Epoch: 6| Step: 7
Training loss: 2.9269163326169143
Validation loss: 2.640194745152306

Epoch: 6| Step: 8
Training loss: 2.7626717526997817
Validation loss: 2.5919440701429863

Epoch: 6| Step: 9
Training loss: 3.255596916910997
Validation loss: 2.576215324249095

Epoch: 6| Step: 10
Training loss: 3.421731188116692
Validation loss: 2.548019716620895

Epoch: 6| Step: 11
Training loss: 2.881346290948774
Validation loss: 2.51770967119658

Epoch: 6| Step: 12
Training loss: 3.4927152025879753
Validation loss: 2.482583346497219

Epoch: 6| Step: 13
Training loss: 3.028287560791129
Validation loss: 2.476406644378086

Epoch: 135| Step: 0
Training loss: 2.6593048480919688
Validation loss: 2.4680470880415446

Epoch: 6| Step: 1
Training loss: 3.310119061129454
Validation loss: 2.472797598608391

Epoch: 6| Step: 2
Training loss: 2.8296464231428073
Validation loss: 2.4862523888835946

Epoch: 6| Step: 3
Training loss: 2.725875374417225
Validation loss: 2.504689705271171

Epoch: 6| Step: 4
Training loss: 3.096730347612655
Validation loss: 2.5243961188797166

Epoch: 6| Step: 5
Training loss: 3.141956863019788
Validation loss: 2.5326102341862624

Epoch: 6| Step: 6
Training loss: 2.626304302425831
Validation loss: 2.5240933623697375

Epoch: 6| Step: 7
Training loss: 3.095373787193768
Validation loss: 2.502043380173098

Epoch: 6| Step: 8
Training loss: 3.035577575426242
Validation loss: 2.492852205837822

Epoch: 6| Step: 9
Training loss: 2.585184592734051
Validation loss: 2.474753758136448

Epoch: 6| Step: 10
Training loss: 2.5960512179008246
Validation loss: 2.479781045650943

Epoch: 6| Step: 11
Training loss: 2.7377107164638517
Validation loss: 2.4899742453542486

Epoch: 6| Step: 12
Training loss: 1.9142650886290715
Validation loss: 2.506073036765937

Epoch: 6| Step: 13
Training loss: 2.862387982304753
Validation loss: 2.516404254594415

Epoch: 136| Step: 0
Training loss: 2.642764156134393
Validation loss: 2.5172972438481773

Epoch: 6| Step: 1
Training loss: 2.2750678754469336
Validation loss: 2.5288175144393867

Epoch: 6| Step: 2
Training loss: 2.6428516638268196
Validation loss: 2.516735044220203

Epoch: 6| Step: 3
Training loss: 2.605076887639813
Validation loss: 2.512089600071598

Epoch: 6| Step: 4
Training loss: 2.914001136931418
Validation loss: 2.4964002174972713

Epoch: 6| Step: 5
Training loss: 3.1684208746034748
Validation loss: 2.473753796311378

Epoch: 6| Step: 6
Training loss: 3.0679636893778293
Validation loss: 2.4734763597682505

Epoch: 6| Step: 7
Training loss: 2.257771633530731
Validation loss: 2.469246719461015

Epoch: 6| Step: 8
Training loss: 3.013169311628059
Validation loss: 2.4677643371778095

Epoch: 6| Step: 9
Training loss: 2.391428295134831
Validation loss: 2.4676535307911984

Epoch: 6| Step: 10
Training loss: 3.1802877473500453
Validation loss: 2.4713375227964707

Epoch: 6| Step: 11
Training loss: 2.679391827967597
Validation loss: 2.4715565598009244

Epoch: 6| Step: 12
Training loss: 3.187685792781493
Validation loss: 2.481838062755119

Epoch: 6| Step: 13
Training loss: 2.9162999785482238
Validation loss: 2.486608573740358

Epoch: 137| Step: 0
Training loss: 2.969100289007443
Validation loss: 2.491470340195402

Epoch: 6| Step: 1
Training loss: 2.6760921993708835
Validation loss: 2.4948677275581037

Epoch: 6| Step: 2
Training loss: 2.4128866449156203
Validation loss: 2.492747006362876

Epoch: 6| Step: 3
Training loss: 2.903580290506527
Validation loss: 2.482701622421597

Epoch: 6| Step: 4
Training loss: 2.9355416770579397
Validation loss: 2.479071967850722

Epoch: 6| Step: 5
Training loss: 2.787104926743998
Validation loss: 2.4860459147647784

Epoch: 6| Step: 6
Training loss: 2.841915335267247
Validation loss: 2.4856514004903

Epoch: 6| Step: 7
Training loss: 3.0017431281258857
Validation loss: 2.4946889637601055

Epoch: 6| Step: 8
Training loss: 2.5059618434634587
Validation loss: 2.48015003567806

Epoch: 6| Step: 9
Training loss: 2.98825827197048
Validation loss: 2.4808040171078107

Epoch: 6| Step: 10
Training loss: 2.2924340321608128
Validation loss: 2.485472088313032

Epoch: 6| Step: 11
Training loss: 2.878553433583458
Validation loss: 2.492728033630262

Epoch: 6| Step: 12
Training loss: 2.5420415216231715
Validation loss: 2.5005724917974237

Epoch: 6| Step: 13
Training loss: 3.4375589539067506
Validation loss: 2.498964725989524

Epoch: 138| Step: 0
Training loss: 3.1273523250998787
Validation loss: 2.4948240833761233

Epoch: 6| Step: 1
Training loss: 3.422061166097374
Validation loss: 2.4905352201268243

Epoch: 6| Step: 2
Training loss: 2.6650782463796765
Validation loss: 2.501868318954887

Epoch: 6| Step: 3
Training loss: 2.528723409440308
Validation loss: 2.5087635157758204

Epoch: 6| Step: 4
Training loss: 2.012738193608583
Validation loss: 2.5102749396758917

Epoch: 6| Step: 5
Training loss: 2.7855861166229556
Validation loss: 2.5178396190890395

Epoch: 6| Step: 6
Training loss: 2.316625472143919
Validation loss: 2.514610740824296

Epoch: 6| Step: 7
Training loss: 2.673628203982806
Validation loss: 2.5128757207715195

Epoch: 6| Step: 8
Training loss: 2.4957512992237234
Validation loss: 2.4996394461412437

Epoch: 6| Step: 9
Training loss: 3.224525085493605
Validation loss: 2.489715931679105

Epoch: 6| Step: 10
Training loss: 3.6110785621415116
Validation loss: 2.4934287534045434

Epoch: 6| Step: 11
Training loss: 2.2815739649834783
Validation loss: 2.4980324745059805

Epoch: 6| Step: 12
Training loss: 2.5540985455122884
Validation loss: 2.5282877922489706

Epoch: 6| Step: 13
Training loss: 3.0121658329798335
Validation loss: 2.534505634510072

Epoch: 139| Step: 0
Training loss: 2.632736974702621
Validation loss: 2.5395564722202284

Epoch: 6| Step: 1
Training loss: 2.4210190767957074
Validation loss: 2.5329049788429536

Epoch: 6| Step: 2
Training loss: 2.938626012681305
Validation loss: 2.520261419132462

Epoch: 6| Step: 3
Training loss: 2.911867352975276
Validation loss: 2.4899358806549095

Epoch: 6| Step: 4
Training loss: 2.150329755290578
Validation loss: 2.4859599741251026

Epoch: 6| Step: 5
Training loss: 2.30721999861506
Validation loss: 2.4920174970855813

Epoch: 6| Step: 6
Training loss: 2.6442243434587844
Validation loss: 2.4964326098962806

Epoch: 6| Step: 7
Training loss: 3.03303711112008
Validation loss: 2.499214676595939

Epoch: 6| Step: 8
Training loss: 2.536409183054713
Validation loss: 2.4944404188486127

Epoch: 6| Step: 9
Training loss: 3.2591194440333227
Validation loss: 2.489737561295795

Epoch: 6| Step: 10
Training loss: 3.1559472269304383
Validation loss: 2.4861214622779633

Epoch: 6| Step: 11
Training loss: 2.989382711628277
Validation loss: 2.4831327496781355

Epoch: 6| Step: 12
Training loss: 2.9888920178528977
Validation loss: 2.4803116938348184

Epoch: 6| Step: 13
Training loss: 2.5534237410207683
Validation loss: 2.4750828109813674

Epoch: 140| Step: 0
Training loss: 2.322333691804976
Validation loss: 2.4756160889502317

Epoch: 6| Step: 1
Training loss: 2.2516457578684532
Validation loss: 2.483547898279964

Epoch: 6| Step: 2
Training loss: 3.214784716670174
Validation loss: 2.486044718558451

Epoch: 6| Step: 3
Training loss: 2.77636323727955
Validation loss: 2.4786694532099616

Epoch: 6| Step: 4
Training loss: 2.733149749902007
Validation loss: 2.4790236960184147

Epoch: 6| Step: 5
Training loss: 2.7063024291142317
Validation loss: 2.4831864494902773

Epoch: 6| Step: 6
Training loss: 2.903887044470052
Validation loss: 2.4927257803001375

Epoch: 6| Step: 7
Training loss: 2.520764142392593
Validation loss: 2.4905066240134395

Epoch: 6| Step: 8
Training loss: 1.957506072715801
Validation loss: 2.488883436831105

Epoch: 6| Step: 9
Training loss: 3.334493069761519
Validation loss: 2.4897940861363987

Epoch: 6| Step: 10
Training loss: 2.6004480489401853
Validation loss: 2.4878725845195246

Epoch: 6| Step: 11
Training loss: 3.055102386007588
Validation loss: 2.5021882232636816

Epoch: 6| Step: 12
Training loss: 3.2286243270417843
Validation loss: 2.4939188706742152

Epoch: 6| Step: 13
Training loss: 2.6365057965219787
Validation loss: 2.487678010527768

Epoch: 141| Step: 0
Training loss: 2.9167062665885024
Validation loss: 2.489975962701773

Epoch: 6| Step: 1
Training loss: 2.5228191362130916
Validation loss: 2.494142605695673

Epoch: 6| Step: 2
Training loss: 2.8361397663212733
Validation loss: 2.490661539674427

Epoch: 6| Step: 3
Training loss: 3.0688995138443715
Validation loss: 2.487147017818498

Epoch: 6| Step: 4
Training loss: 2.3759679327704974
Validation loss: 2.4851047586652557

Epoch: 6| Step: 5
Training loss: 2.6773090094256777
Validation loss: 2.485188031330172

Epoch: 6| Step: 6
Training loss: 2.3794624167061538
Validation loss: 2.4818002778061072

Epoch: 6| Step: 7
Training loss: 3.2711360005742547
Validation loss: 2.482868440766673

Epoch: 6| Step: 8
Training loss: 2.8191488723877387
Validation loss: 2.4909563850761836

Epoch: 6| Step: 9
Training loss: 2.7790009052155713
Validation loss: 2.4843898810670213

Epoch: 6| Step: 10
Training loss: 2.92435354278317
Validation loss: 2.4907134272311495

Epoch: 6| Step: 11
Training loss: 2.359702586490911
Validation loss: 2.489511836295276

Epoch: 6| Step: 12
Training loss: 2.5369776220962397
Validation loss: 2.4855389460145525

Epoch: 6| Step: 13
Training loss: 2.827404457319645
Validation loss: 2.488489758729868

Epoch: 142| Step: 0
Training loss: 3.444306034123806
Validation loss: 2.4989853276484797

Epoch: 6| Step: 1
Training loss: 2.6229634332060434
Validation loss: 2.4931773271209368

Epoch: 6| Step: 2
Training loss: 2.93684363641287
Validation loss: 2.4846421284728875

Epoch: 6| Step: 3
Training loss: 3.0151127988044095
Validation loss: 2.4750747526018557

Epoch: 6| Step: 4
Training loss: 2.0125960427817846
Validation loss: 2.4763026030110855

Epoch: 6| Step: 5
Training loss: 2.327919970195341
Validation loss: 2.4775172570569826

Epoch: 6| Step: 6
Training loss: 3.125313399812233
Validation loss: 2.493112628007874

Epoch: 6| Step: 7
Training loss: 2.2386326272719415
Validation loss: 2.47362042557279

Epoch: 6| Step: 8
Training loss: 1.8992255188394906
Validation loss: 2.4654499436565436

Epoch: 6| Step: 9
Training loss: 3.2412989122589173
Validation loss: 2.460638849224236

Epoch: 6| Step: 10
Training loss: 2.8743759804906666
Validation loss: 2.469712105868173

Epoch: 6| Step: 11
Training loss: 3.2742222685124855
Validation loss: 2.4943949578183364

Epoch: 6| Step: 12
Training loss: 2.7439027296236707
Validation loss: 2.5236888534142725

Epoch: 6| Step: 13
Training loss: 2.2253499259528224
Validation loss: 2.547758754731166

Epoch: 143| Step: 0
Training loss: 3.439850159863719
Validation loss: 2.543221012705954

Epoch: 6| Step: 1
Training loss: 2.9287739461065576
Validation loss: 2.556605619177745

Epoch: 6| Step: 2
Training loss: 2.7386367284140674
Validation loss: 2.5061133067281216

Epoch: 6| Step: 3
Training loss: 2.9898685403458467
Validation loss: 2.486272270984585

Epoch: 6| Step: 4
Training loss: 2.319403987488539
Validation loss: 2.4746232073383254

Epoch: 6| Step: 5
Training loss: 2.079092273897464
Validation loss: 2.473096624709161

Epoch: 6| Step: 6
Training loss: 2.7252633133806174
Validation loss: 2.4643402154727734

Epoch: 6| Step: 7
Training loss: 3.324418847486422
Validation loss: 2.4611940801296504

Epoch: 6| Step: 8
Training loss: 3.1739260802191525
Validation loss: 2.450383763856638

Epoch: 6| Step: 9
Training loss: 2.233147664204681
Validation loss: 2.4556911212707138

Epoch: 6| Step: 10
Training loss: 2.88846734427412
Validation loss: 2.460859956315589

Epoch: 6| Step: 11
Training loss: 2.362075977521465
Validation loss: 2.4641063481557035

Epoch: 6| Step: 12
Training loss: 2.6096035977126535
Validation loss: 2.468036906364921

Epoch: 6| Step: 13
Training loss: 2.266575686180923
Validation loss: 2.4753399796594513

Epoch: 144| Step: 0
Training loss: 2.8983810707213298
Validation loss: 2.4734652272074222

Epoch: 6| Step: 1
Training loss: 3.471859749418013
Validation loss: 2.4778934938102815

Epoch: 6| Step: 2
Training loss: 2.9349488888502937
Validation loss: 2.4886873817585573

Epoch: 6| Step: 3
Training loss: 3.095636582486723
Validation loss: 2.512158771065179

Epoch: 6| Step: 4
Training loss: 2.314845673955864
Validation loss: 2.5133562547128063

Epoch: 6| Step: 5
Training loss: 2.458935604566245
Validation loss: 2.521432110027039

Epoch: 6| Step: 6
Training loss: 2.1512467207321184
Validation loss: 2.5330786440443243

Epoch: 6| Step: 7
Training loss: 2.423338318792967
Validation loss: 2.5462026971357097

Epoch: 6| Step: 8
Training loss: 3.016401596085506
Validation loss: 2.5534950582498297

Epoch: 6| Step: 9
Training loss: 2.2698537364337477
Validation loss: 2.548775424961725

Epoch: 6| Step: 10
Training loss: 3.0617880480244533
Validation loss: 2.5436488951192637

Epoch: 6| Step: 11
Training loss: 2.566905073347788
Validation loss: 2.5472559127857592

Epoch: 6| Step: 12
Training loss: 2.7035986865660573
Validation loss: 2.5389930633566613

Epoch: 6| Step: 13
Training loss: 3.4659814181789996
Validation loss: 2.5326094922051885

Epoch: 145| Step: 0
Training loss: 2.7958998018901666
Validation loss: 2.532532715727981

Epoch: 6| Step: 1
Training loss: 2.2379488873001474
Validation loss: 2.52611472596416

Epoch: 6| Step: 2
Training loss: 3.0871456050955137
Validation loss: 2.5196324593866044

Epoch: 6| Step: 3
Training loss: 2.82231597327495
Validation loss: 2.520956888800671

Epoch: 6| Step: 4
Training loss: 2.76875903470393
Validation loss: 2.5104307666931147

Epoch: 6| Step: 5
Training loss: 2.8390333024047263
Validation loss: 2.497905220694443

Epoch: 6| Step: 6
Training loss: 2.95064105164651
Validation loss: 2.492992048935931

Epoch: 6| Step: 7
Training loss: 3.111893290634324
Validation loss: 2.4812981344600176

Epoch: 6| Step: 8
Training loss: 2.3995736379196257
Validation loss: 2.4716954052675013

Epoch: 6| Step: 9
Training loss: 2.1877611276899165
Validation loss: 2.474888336730382

Epoch: 6| Step: 10
Training loss: 2.8163541876310174
Validation loss: 2.469342047699202

Epoch: 6| Step: 11
Training loss: 3.057106250727126
Validation loss: 2.4851252204194276

Epoch: 6| Step: 12
Training loss: 2.500337291852554
Validation loss: 2.4897897461169745

Epoch: 6| Step: 13
Training loss: 2.855489957759394
Validation loss: 2.503243926912951

Epoch: 146| Step: 0
Training loss: 2.6270752832308037
Validation loss: 2.510494916865036

Epoch: 6| Step: 1
Training loss: 2.7557553840120192
Validation loss: 2.512550908805867

Epoch: 6| Step: 2
Training loss: 2.6173376239593105
Validation loss: 2.518750751112243

Epoch: 6| Step: 3
Training loss: 2.004578951530396
Validation loss: 2.516996991550838

Epoch: 6| Step: 4
Training loss: 3.0251783145020874
Validation loss: 2.517848549622965

Epoch: 6| Step: 5
Training loss: 2.516261049976902
Validation loss: 2.5162327161728726

Epoch: 6| Step: 6
Training loss: 2.2122994800801696
Validation loss: 2.5164851590229995

Epoch: 6| Step: 7
Training loss: 3.5183356791575346
Validation loss: 2.514884197120084

Epoch: 6| Step: 8
Training loss: 2.8001779840303964
Validation loss: 2.5231838181984307

Epoch: 6| Step: 9
Training loss: 2.529582286623585
Validation loss: 2.5285277257261822

Epoch: 6| Step: 10
Training loss: 2.9123888706731793
Validation loss: 2.527227547127101

Epoch: 6| Step: 11
Training loss: 3.1356462329117476
Validation loss: 2.5283113135013293

Epoch: 6| Step: 12
Training loss: 2.6112412956826807
Validation loss: 2.519072423481905

Epoch: 6| Step: 13
Training loss: 2.558724203496842
Validation loss: 2.5373772755196744

Epoch: 147| Step: 0
Training loss: 3.119217978553197
Validation loss: 2.5264278446933557

Epoch: 6| Step: 1
Training loss: 2.459561499149172
Validation loss: 2.56102082013984

Epoch: 6| Step: 2
Training loss: 2.3599776957152967
Validation loss: 2.5751805151509592

Epoch: 6| Step: 3
Training loss: 2.8509156211909166
Validation loss: 2.590554177247743

Epoch: 6| Step: 4
Training loss: 3.123187951199163
Validation loss: 2.6131260377275782

Epoch: 6| Step: 5
Training loss: 3.0739029330711403
Validation loss: 2.5828928891196683

Epoch: 6| Step: 6
Training loss: 2.2340653211560073
Validation loss: 2.561987826958017

Epoch: 6| Step: 7
Training loss: 3.1259526135934372
Validation loss: 2.553433163555143

Epoch: 6| Step: 8
Training loss: 3.070630083815584
Validation loss: 2.539694695030394

Epoch: 6| Step: 9
Training loss: 2.5860463836888323
Validation loss: 2.548300703346252

Epoch: 6| Step: 10
Training loss: 2.6368552843700863
Validation loss: 2.549129084252892

Epoch: 6| Step: 11
Training loss: 2.349165090411757
Validation loss: 2.5267330487469355

Epoch: 6| Step: 12
Training loss: 2.733803825668325
Validation loss: 2.5046549764464285

Epoch: 6| Step: 13
Training loss: 2.2475662844582462
Validation loss: 2.4893740082310347

Epoch: 148| Step: 0
Training loss: 2.120268771930146
Validation loss: 2.4776160143231603

Epoch: 6| Step: 1
Training loss: 2.3868943569680003
Validation loss: 2.4713314594814606

Epoch: 6| Step: 2
Training loss: 2.3442656903371875
Validation loss: 2.471200130340661

Epoch: 6| Step: 3
Training loss: 2.7824527839980004
Validation loss: 2.4594558508436655

Epoch: 6| Step: 4
Training loss: 2.808301122539165
Validation loss: 2.4608351777826427

Epoch: 6| Step: 5
Training loss: 2.8904438683748186
Validation loss: 2.450093088899146

Epoch: 6| Step: 6
Training loss: 3.1241951478189183
Validation loss: 2.452917533980865

Epoch: 6| Step: 7
Training loss: 3.2579657429392235
Validation loss: 2.452755414968696

Epoch: 6| Step: 8
Training loss: 2.963349258442995
Validation loss: 2.464273907222057

Epoch: 6| Step: 9
Training loss: 2.1439075779067998
Validation loss: 2.461489275543149

Epoch: 6| Step: 10
Training loss: 2.1562533171255054
Validation loss: 2.4653486125436213

Epoch: 6| Step: 11
Training loss: 3.128117494069182
Validation loss: 2.4993898488028794

Epoch: 6| Step: 12
Training loss: 2.9436273180753925
Validation loss: 2.5011303704746926

Epoch: 6| Step: 13
Training loss: 3.051500770424988
Validation loss: 2.5285006101948455

Epoch: 149| Step: 0
Training loss: 3.053026767427196
Validation loss: 2.496374691871625

Epoch: 6| Step: 1
Training loss: 2.9743841415364187
Validation loss: 2.484437849483334

Epoch: 6| Step: 2
Training loss: 2.745926354028463
Validation loss: 2.4757228406274696

Epoch: 6| Step: 3
Training loss: 2.2267239696111463
Validation loss: 2.4918908311564283

Epoch: 6| Step: 4
Training loss: 2.2232227642622076
Validation loss: 2.5003538106950227

Epoch: 6| Step: 5
Training loss: 2.660271147768753
Validation loss: 2.5324762560085206

Epoch: 6| Step: 6
Training loss: 3.3385736917198554
Validation loss: 2.529192533061919

Epoch: 6| Step: 7
Training loss: 2.670161004230491
Validation loss: 2.5308979254951467

Epoch: 6| Step: 8
Training loss: 2.4823782712166755
Validation loss: 2.532831365227575

Epoch: 6| Step: 9
Training loss: 3.2096140563542948
Validation loss: 2.506426008593398

Epoch: 6| Step: 10
Training loss: 2.6367719178667284
Validation loss: 2.5088527186956204

Epoch: 6| Step: 11
Training loss: 2.2861693133699723
Validation loss: 2.4946116902473174

Epoch: 6| Step: 12
Training loss: 2.7995396712514444
Validation loss: 2.4868758215507785

Epoch: 6| Step: 13
Training loss: 2.7479781607880307
Validation loss: 2.4828419200455922

Epoch: 150| Step: 0
Training loss: 2.970376302083048
Validation loss: 2.4828798450542804

Epoch: 6| Step: 1
Training loss: 2.7467302477369357
Validation loss: 2.477180409824023

Epoch: 6| Step: 2
Training loss: 2.7727536500111043
Validation loss: 2.4763803205105175

Epoch: 6| Step: 3
Training loss: 2.7046153640162864
Validation loss: 2.4858277605224406

Epoch: 6| Step: 4
Training loss: 2.7958650097329314
Validation loss: 2.4800567716326993

Epoch: 6| Step: 5
Training loss: 1.8153418262678547
Validation loss: 2.4792297043666136

Epoch: 6| Step: 6
Training loss: 2.8565441355768573
Validation loss: 2.4687589222321162

Epoch: 6| Step: 7
Training loss: 2.367968741945212
Validation loss: 2.4956536042416513

Epoch: 6| Step: 8
Training loss: 2.0493047139922886
Validation loss: 2.5150517410693314

Epoch: 6| Step: 9
Training loss: 3.2920701145849343
Validation loss: 2.5429689707802496

Epoch: 6| Step: 10
Training loss: 3.0918092130991974
Validation loss: 2.5697027393839385

Epoch: 6| Step: 11
Training loss: 2.8582619757313394
Validation loss: 2.5854446144143957

Epoch: 6| Step: 12
Training loss: 3.105645017599693
Validation loss: 2.597349280638634

Epoch: 6| Step: 13
Training loss: 3.4985415280930288
Validation loss: 2.5801642473561563

Epoch: 151| Step: 0
Training loss: 3.7464752162152806
Validation loss: 2.5624363678985906

Epoch: 6| Step: 1
Training loss: 2.5733090820882762
Validation loss: 2.555783954732105

Epoch: 6| Step: 2
Training loss: 2.9865810369523214
Validation loss: 2.544261336897963

Epoch: 6| Step: 3
Training loss: 2.750849679249069
Validation loss: 2.532379034309088

Epoch: 6| Step: 4
Training loss: 3.008188516472125
Validation loss: 2.522578634360105

Epoch: 6| Step: 5
Training loss: 2.542756008736308
Validation loss: 2.4954823838059412

Epoch: 6| Step: 6
Training loss: 2.121352487312574
Validation loss: 2.4842849563437475

Epoch: 6| Step: 7
Training loss: 2.686836604367321
Validation loss: 2.46656459281478

Epoch: 6| Step: 8
Training loss: 2.6719326436924264
Validation loss: 2.4572628277359567

Epoch: 6| Step: 9
Training loss: 2.462498729724847
Validation loss: 2.4501947433124496

Epoch: 6| Step: 10
Training loss: 2.400510606490836
Validation loss: 2.440089637845386

Epoch: 6| Step: 11
Training loss: 2.7745933165979055
Validation loss: 2.4422867542335105

Epoch: 6| Step: 12
Training loss: 2.8321437208270206
Validation loss: 2.440453933679217

Epoch: 6| Step: 13
Training loss: 2.3685151962620625
Validation loss: 2.439391653467905

Epoch: 152| Step: 0
Training loss: 2.7925555583785364
Validation loss: 2.4500598081270613

Epoch: 6| Step: 1
Training loss: 2.803935255579285
Validation loss: 2.454550877424901

Epoch: 6| Step: 2
Training loss: 2.9172177656960536
Validation loss: 2.47179468087499

Epoch: 6| Step: 3
Training loss: 2.9459182561551573
Validation loss: 2.4568048219559877

Epoch: 6| Step: 4
Training loss: 2.5369708557138964
Validation loss: 2.4643753522238865

Epoch: 6| Step: 5
Training loss: 2.8288114778898588
Validation loss: 2.463570283190545

Epoch: 6| Step: 6
Training loss: 2.1587347558239287
Validation loss: 2.4698037624086724

Epoch: 6| Step: 7
Training loss: 2.8385421519614455
Validation loss: 2.471104176617486

Epoch: 6| Step: 8
Training loss: 3.1818900013534237
Validation loss: 2.4746792123930352

Epoch: 6| Step: 9
Training loss: 2.305038063413574
Validation loss: 2.489095236272516

Epoch: 6| Step: 10
Training loss: 2.7863208962649817
Validation loss: 2.501280603258237

Epoch: 6| Step: 11
Training loss: 2.4773855676793723
Validation loss: 2.497093591892716

Epoch: 6| Step: 12
Training loss: 3.1723476114189917
Validation loss: 2.509185590943578

Epoch: 6| Step: 13
Training loss: 2.0768320751087903
Validation loss: 2.495853805711397

Epoch: 153| Step: 0
Training loss: 3.223003946678877
Validation loss: 2.4948152286714143

Epoch: 6| Step: 1
Training loss: 2.6933515851500838
Validation loss: 2.5008354083272453

Epoch: 6| Step: 2
Training loss: 3.3635155998220942
Validation loss: 2.5055900045749615

Epoch: 6| Step: 3
Training loss: 2.375626732299462
Validation loss: 2.475161667780049

Epoch: 6| Step: 4
Training loss: 2.257244949549797
Validation loss: 2.461013807867382

Epoch: 6| Step: 5
Training loss: 2.282085109076425
Validation loss: 2.4676766991496053

Epoch: 6| Step: 6
Training loss: 2.50947491932626
Validation loss: 2.4636149982283673

Epoch: 6| Step: 7
Training loss: 3.1475328986983873
Validation loss: 2.4572428173296457

Epoch: 6| Step: 8
Training loss: 2.5062512442949587
Validation loss: 2.4704404240639106

Epoch: 6| Step: 9
Training loss: 2.8489782877798002
Validation loss: 2.477369151288512

Epoch: 6| Step: 10
Training loss: 2.628167285193464
Validation loss: 2.5023683794132463

Epoch: 6| Step: 11
Training loss: 3.2899284763156267
Validation loss: 2.5094672942081018

Epoch: 6| Step: 12
Training loss: 2.3712641797725147
Validation loss: 2.521943123572289

Epoch: 6| Step: 13
Training loss: 2.0277122794710967
Validation loss: 2.5216417195297995

Epoch: 154| Step: 0
Training loss: 1.9319505279004012
Validation loss: 2.511583280736817

Epoch: 6| Step: 1
Training loss: 3.1012654582648924
Validation loss: 2.5336072775525937

Epoch: 6| Step: 2
Training loss: 2.5194175043970786
Validation loss: 2.52236800250287

Epoch: 6| Step: 3
Training loss: 2.8800712309081837
Validation loss: 2.5097370615794516

Epoch: 6| Step: 4
Training loss: 2.603273029858194
Validation loss: 2.5053873161715976

Epoch: 6| Step: 5
Training loss: 3.0649074511844843
Validation loss: 2.494680130156302

Epoch: 6| Step: 6
Training loss: 3.2535872102653474
Validation loss: 2.497421076837769

Epoch: 6| Step: 7
Training loss: 2.5997929784078218
Validation loss: 2.5013924730265544

Epoch: 6| Step: 8
Training loss: 2.1090339667531914
Validation loss: 2.487086908581228

Epoch: 6| Step: 9
Training loss: 2.4017182318900496
Validation loss: 2.4866725229843545

Epoch: 6| Step: 10
Training loss: 2.0348910050879607
Validation loss: 2.4808417314604165

Epoch: 6| Step: 11
Training loss: 2.366264641782476
Validation loss: 2.467884459767483

Epoch: 6| Step: 12
Training loss: 3.3942012648423376
Validation loss: 2.4676387430709252

Epoch: 6| Step: 13
Training loss: 2.9818951754346217
Validation loss: 2.458457378082569

Epoch: 155| Step: 0
Training loss: 2.642014538536527
Validation loss: 2.453887363260119

Epoch: 6| Step: 1
Training loss: 2.96981374856604
Validation loss: 2.450647926458805

Epoch: 6| Step: 2
Training loss: 2.859489730450992
Validation loss: 2.452770723043586

Epoch: 6| Step: 3
Training loss: 2.378919078372636
Validation loss: 2.4456608173744123

Epoch: 6| Step: 4
Training loss: 2.6447100219705146
Validation loss: 2.4531901267113008

Epoch: 6| Step: 5
Training loss: 3.30109558414537
Validation loss: 2.449573156581485

Epoch: 6| Step: 6
Training loss: 2.2577979275454254
Validation loss: 2.4606646153234064

Epoch: 6| Step: 7
Training loss: 2.6879011342736168
Validation loss: 2.4616626125039063

Epoch: 6| Step: 8
Training loss: 2.4625588540726753
Validation loss: 2.4735090451167867

Epoch: 6| Step: 9
Training loss: 2.318378503040825
Validation loss: 2.47236270934759

Epoch: 6| Step: 10
Training loss: 2.536773400970673
Validation loss: 2.475024546649316

Epoch: 6| Step: 11
Training loss: 2.529163583903395
Validation loss: 2.4719401078725585

Epoch: 6| Step: 12
Training loss: 2.6054709461666157
Validation loss: 2.4715789354189273

Epoch: 6| Step: 13
Training loss: 3.15494291226689
Validation loss: 2.4670109831824316

Epoch: 156| Step: 0
Training loss: 2.2391475046424225
Validation loss: 2.475465632498763

Epoch: 6| Step: 1
Training loss: 2.746903843994073
Validation loss: 2.4847288699410917

Epoch: 6| Step: 2
Training loss: 2.685889182729678
Validation loss: 2.477120175686149

Epoch: 6| Step: 3
Training loss: 1.6836437386085894
Validation loss: 2.4826302872417525

Epoch: 6| Step: 4
Training loss: 2.7806922267573464
Validation loss: 2.492241511835068

Epoch: 6| Step: 5
Training loss: 2.6204077196648337
Validation loss: 2.4909350850912646

Epoch: 6| Step: 6
Training loss: 2.5726396872331634
Validation loss: 2.496931980691408

Epoch: 6| Step: 7
Training loss: 2.7207104860139117
Validation loss: 2.4898417712798553

Epoch: 6| Step: 8
Training loss: 3.133439835977145
Validation loss: 2.4874174218423604

Epoch: 6| Step: 9
Training loss: 3.0229433429644277
Validation loss: 2.4834353681674326

Epoch: 6| Step: 10
Training loss: 2.4257382006672255
Validation loss: 2.479398748782671

Epoch: 6| Step: 11
Training loss: 2.315489820892491
Validation loss: 2.4796249322514887

Epoch: 6| Step: 12
Training loss: 3.0483446538209886
Validation loss: 2.4870686358685474

Epoch: 6| Step: 13
Training loss: 2.9243735987608344
Validation loss: 2.4886215311357924

Epoch: 157| Step: 0
Training loss: 3.320852724893799
Validation loss: 2.484033615959507

Epoch: 6| Step: 1
Training loss: 2.6845170255488093
Validation loss: 2.4861970178069974

Epoch: 6| Step: 2
Training loss: 2.798371239777091
Validation loss: 2.4904624216538105

Epoch: 6| Step: 3
Training loss: 2.8652773114753263
Validation loss: 2.501071867301108

Epoch: 6| Step: 4
Training loss: 2.2487347542212555
Validation loss: 2.519015510431899

Epoch: 6| Step: 5
Training loss: 2.4068820668178437
Validation loss: 2.5444193353853124

Epoch: 6| Step: 6
Training loss: 2.7053055099603225
Validation loss: 2.5504495185510327

Epoch: 6| Step: 7
Training loss: 2.841151800711729
Validation loss: 2.5352491697390955

Epoch: 6| Step: 8
Training loss: 2.203070024386114
Validation loss: 2.5156593103858147

Epoch: 6| Step: 9
Training loss: 2.6542458546880896
Validation loss: 2.4981397065229314

Epoch: 6| Step: 10
Training loss: 2.8619229997024003
Validation loss: 2.4752735694001164

Epoch: 6| Step: 11
Training loss: 2.473337185163489
Validation loss: 2.467118415300926

Epoch: 6| Step: 12
Training loss: 2.260966701358536
Validation loss: 2.463763044270148

Epoch: 6| Step: 13
Training loss: 2.587750401566601
Validation loss: 2.4662478799505587

Epoch: 158| Step: 0
Training loss: 2.7519409959145413
Validation loss: 2.4575914414413953

Epoch: 6| Step: 1
Training loss: 2.715516985291384
Validation loss: 2.4581114695110955

Epoch: 6| Step: 2
Training loss: 2.3085639035123853
Validation loss: 2.4560415089124685

Epoch: 6| Step: 3
Training loss: 2.7588113591466246
Validation loss: 2.4451164044579077

Epoch: 6| Step: 4
Training loss: 2.359901318992402
Validation loss: 2.4562384977042417

Epoch: 6| Step: 5
Training loss: 2.3749068392501607
Validation loss: 2.4525950643019887

Epoch: 6| Step: 6
Training loss: 2.6067624290450238
Validation loss: 2.4644918785248087

Epoch: 6| Step: 7
Training loss: 2.735884418767804
Validation loss: 2.466579846367734

Epoch: 6| Step: 8
Training loss: 2.4812516065923838
Validation loss: 2.4738204598125697

Epoch: 6| Step: 9
Training loss: 2.3133309392156316
Validation loss: 2.4840302215530237

Epoch: 6| Step: 10
Training loss: 3.045789163237024
Validation loss: 2.502464637214324

Epoch: 6| Step: 11
Training loss: 2.7506605568745677
Validation loss: 2.512769090575181

Epoch: 6| Step: 12
Training loss: 2.791863581606519
Validation loss: 2.5496963163311155

Epoch: 6| Step: 13
Training loss: 2.5270195919676754
Validation loss: 2.5929067935942074

Epoch: 159| Step: 0
Training loss: 3.3976759484817136
Validation loss: 2.6255267045038284

Epoch: 6| Step: 1
Training loss: 3.219614005558368
Validation loss: 2.6398057632192726

Epoch: 6| Step: 2
Training loss: 2.557228061690445
Validation loss: 2.6369608591024307

Epoch: 6| Step: 3
Training loss: 2.8116749719008287
Validation loss: 2.6138664674470924

Epoch: 6| Step: 4
Training loss: 2.3294168254924252
Validation loss: 2.5844863008384187

Epoch: 6| Step: 5
Training loss: 2.5625517304944228
Validation loss: 2.5662579466976525

Epoch: 6| Step: 6
Training loss: 2.767515581564386
Validation loss: 2.5506005090204074

Epoch: 6| Step: 7
Training loss: 3.086644499708077
Validation loss: 2.5344271028183045

Epoch: 6| Step: 8
Training loss: 2.777928630123542
Validation loss: 2.513098352124914

Epoch: 6| Step: 9
Training loss: 2.087479839113383
Validation loss: 2.4979781157927285

Epoch: 6| Step: 10
Training loss: 2.628096615958961
Validation loss: 2.4839559180818123

Epoch: 6| Step: 11
Training loss: 2.2212794754571425
Validation loss: 2.4805578077427834

Epoch: 6| Step: 12
Training loss: 1.9371750466810593
Validation loss: 2.4626578275887225

Epoch: 6| Step: 13
Training loss: 2.5760952444298373
Validation loss: 2.4587187526598346

Epoch: 160| Step: 0
Training loss: 2.614078052426604
Validation loss: 2.4442208007717303

Epoch: 6| Step: 1
Training loss: 2.7156981077548696
Validation loss: 2.444283765006522

Epoch: 6| Step: 2
Training loss: 2.6380465406776374
Validation loss: 2.441234428807618

Epoch: 6| Step: 3
Training loss: 2.8217814416256584
Validation loss: 2.44391149708942

Epoch: 6| Step: 4
Training loss: 2.500381917391542
Validation loss: 2.460961054519772

Epoch: 6| Step: 5
Training loss: 3.2513114044011027
Validation loss: 2.473077755714629

Epoch: 6| Step: 6
Training loss: 1.8634352390468147
Validation loss: 2.4853866074722406

Epoch: 6| Step: 7
Training loss: 2.5827199043526963
Validation loss: 2.4807710083117085

Epoch: 6| Step: 8
Training loss: 2.608121285233639
Validation loss: 2.482903181088778

Epoch: 6| Step: 9
Training loss: 2.7975316475585754
Validation loss: 2.4918618066703173

Epoch: 6| Step: 10
Training loss: 2.5172972244983876
Validation loss: 2.4828835833157

Epoch: 6| Step: 11
Training loss: 2.5556579053350554
Validation loss: 2.483240844995712

Epoch: 6| Step: 12
Training loss: 2.810537289198168
Validation loss: 2.478232056499825

Epoch: 6| Step: 13
Training loss: 2.8188669827497654
Validation loss: 2.463018217143018

Epoch: 161| Step: 0
Training loss: 2.33847234972972
Validation loss: 2.4587945434209675

Epoch: 6| Step: 1
Training loss: 2.418734082704358
Validation loss: 2.452550035456134

Epoch: 6| Step: 2
Training loss: 2.9263157680963574
Validation loss: 2.4555098185850794

Epoch: 6| Step: 3
Training loss: 2.357380914845847
Validation loss: 2.4477852190202336

Epoch: 6| Step: 4
Training loss: 2.3921025515871115
Validation loss: 2.4610141068355618

Epoch: 6| Step: 5
Training loss: 2.3486669208801865
Validation loss: 2.4598647496302903

Epoch: 6| Step: 6
Training loss: 2.5307095739581396
Validation loss: 2.4729555860519286

Epoch: 6| Step: 7
Training loss: 2.7951331655208103
Validation loss: 2.47797829995349

Epoch: 6| Step: 8
Training loss: 2.7650961504975884
Validation loss: 2.47805520813529

Epoch: 6| Step: 9
Training loss: 2.9893155570623224
Validation loss: 2.4835451122374796

Epoch: 6| Step: 10
Training loss: 2.4882789504012135
Validation loss: 2.4795606042865335

Epoch: 6| Step: 11
Training loss: 2.4047966072855536
Validation loss: 2.480375394581586

Epoch: 6| Step: 12
Training loss: 3.1362390970927745
Validation loss: 2.4712403191660943

Epoch: 6| Step: 13
Training loss: 2.8564374666024728
Validation loss: 2.4761885105745827

Epoch: 162| Step: 0
Training loss: 2.6241995181315603
Validation loss: 2.465785307585493

Epoch: 6| Step: 1
Training loss: 2.7042904144170263
Validation loss: 2.4577520220939086

Epoch: 6| Step: 2
Training loss: 2.3714630492949165
Validation loss: 2.4688297672658828

Epoch: 6| Step: 3
Training loss: 2.6333396678156253
Validation loss: 2.475296447905598

Epoch: 6| Step: 4
Training loss: 2.8403974620305465
Validation loss: 2.47276883313772

Epoch: 6| Step: 5
Training loss: 2.2662368474411387
Validation loss: 2.4723778980949924

Epoch: 6| Step: 6
Training loss: 2.3998386130112492
Validation loss: 2.4850333985911215

Epoch: 6| Step: 7
Training loss: 3.2113737752008644
Validation loss: 2.485652580383905

Epoch: 6| Step: 8
Training loss: 2.8605916087606453
Validation loss: 2.490380895214156

Epoch: 6| Step: 9
Training loss: 2.6918739388638495
Validation loss: 2.4956230672267

Epoch: 6| Step: 10
Training loss: 2.258817350125509
Validation loss: 2.4996730200938266

Epoch: 6| Step: 11
Training loss: 2.314048248803496
Validation loss: 2.5068305623937057

Epoch: 6| Step: 12
Training loss: 2.452973184929645
Validation loss: 2.510846853043971

Epoch: 6| Step: 13
Training loss: 2.7493396312938723
Validation loss: 2.512346168444866

Epoch: 163| Step: 0
Training loss: 3.042180753836575
Validation loss: 2.529185875595698

Epoch: 6| Step: 1
Training loss: 2.7744242027819794
Validation loss: 2.550851075297252

Epoch: 6| Step: 2
Training loss: 2.4523665112049504
Validation loss: 2.562729495836947

Epoch: 6| Step: 3
Training loss: 2.165433043412548
Validation loss: 2.5593866903849487

Epoch: 6| Step: 4
Training loss: 2.2238789766850835
Validation loss: 2.572709936676677

Epoch: 6| Step: 5
Training loss: 3.1145575957154508
Validation loss: 2.562959348224319

Epoch: 6| Step: 6
Training loss: 2.3082924789871373
Validation loss: 2.5366045286078345

Epoch: 6| Step: 7
Training loss: 2.8246494244476987
Validation loss: 2.5217163221234444

Epoch: 6| Step: 8
Training loss: 2.7118439931474976
Validation loss: 2.4958802385010967

Epoch: 6| Step: 9
Training loss: 2.813817711603888
Validation loss: 2.486815592360158

Epoch: 6| Step: 10
Training loss: 2.1128303766079717
Validation loss: 2.48331814301756

Epoch: 6| Step: 11
Training loss: 2.681958095709613
Validation loss: 2.48169293169615

Epoch: 6| Step: 12
Training loss: 2.4565246739063586
Validation loss: 2.484146133419835

Epoch: 6| Step: 13
Training loss: 2.385892284791773
Validation loss: 2.4872471537060656

Epoch: 164| Step: 0
Training loss: 2.4815298619253894
Validation loss: 2.5056361909961726

Epoch: 6| Step: 1
Training loss: 3.1654669011394625
Validation loss: 2.49680603844677

Epoch: 6| Step: 2
Training loss: 2.395636398403759
Validation loss: 2.5002524904704653

Epoch: 6| Step: 3
Training loss: 2.6789975181644987
Validation loss: 2.5129242436568666

Epoch: 6| Step: 4
Training loss: 2.7338284191436344
Validation loss: 2.5092843273308394

Epoch: 6| Step: 5
Training loss: 2.561588125106526
Validation loss: 2.513056477217347

Epoch: 6| Step: 6
Training loss: 2.694101785935973
Validation loss: 2.516488272795686

Epoch: 6| Step: 7
Training loss: 2.1990291317219666
Validation loss: 2.5070329799597624

Epoch: 6| Step: 8
Training loss: 2.5502595470209752
Validation loss: 2.4899584236681878

Epoch: 6| Step: 9
Training loss: 2.684427412274133
Validation loss: 2.4848192751209943

Epoch: 6| Step: 10
Training loss: 2.1868064870947115
Validation loss: 2.475566163226482

Epoch: 6| Step: 11
Training loss: 2.2299609566593532
Validation loss: 2.4949957897911856

Epoch: 6| Step: 12
Training loss: 2.8524018189018547
Validation loss: 2.483342274992953

Epoch: 6| Step: 13
Training loss: 2.7456609132512013
Validation loss: 2.499221212847875

Epoch: 165| Step: 0
Training loss: 3.364780636760814
Validation loss: 2.498305240567754

Epoch: 6| Step: 1
Training loss: 2.675508582708615
Validation loss: 2.502952069441039

Epoch: 6| Step: 2
Training loss: 2.8540773772220853
Validation loss: 2.5279970321515837

Epoch: 6| Step: 3
Training loss: 2.6706708905298835
Validation loss: 2.5353307074453504

Epoch: 6| Step: 4
Training loss: 1.8330262172549308
Validation loss: 2.5448107753841467

Epoch: 6| Step: 5
Training loss: 2.6441979247500904
Validation loss: 2.5657373133645534

Epoch: 6| Step: 6
Training loss: 2.2510431838365133
Validation loss: 2.560181942631529

Epoch: 6| Step: 7
Training loss: 2.141287262654134
Validation loss: 2.5766434266571197

Epoch: 6| Step: 8
Training loss: 3.1337819109746228
Validation loss: 2.5654868339830537

Epoch: 6| Step: 9
Training loss: 2.0349243969194477
Validation loss: 2.567061371559334

Epoch: 6| Step: 10
Training loss: 2.396691994973136
Validation loss: 2.5506515420955513

Epoch: 6| Step: 11
Training loss: 3.0700459837809104
Validation loss: 2.5412152923576405

Epoch: 6| Step: 12
Training loss: 2.087324388621117
Validation loss: 2.5215585740482607

Epoch: 6| Step: 13
Training loss: 2.2774337829276434
Validation loss: 2.496383184696064

Epoch: 166| Step: 0
Training loss: 2.6327433138396503
Validation loss: 2.4789871215607575

Epoch: 6| Step: 1
Training loss: 2.588553681272157
Validation loss: 2.460320212246707

Epoch: 6| Step: 2
Training loss: 2.446913320112214
Validation loss: 2.448697441662808

Epoch: 6| Step: 3
Training loss: 3.1825581557121225
Validation loss: 2.432748591472825

Epoch: 6| Step: 4
Training loss: 1.902095269301179
Validation loss: 2.427856624919179

Epoch: 6| Step: 5
Training loss: 1.6974962646263496
Validation loss: 2.427492311036989

Epoch: 6| Step: 6
Training loss: 2.97554507351125
Validation loss: 2.4306226532596584

Epoch: 6| Step: 7
Training loss: 1.9549297082074286
Validation loss: 2.4358724793279176

Epoch: 6| Step: 8
Training loss: 3.0225126838260183
Validation loss: 2.4397843276780145

Epoch: 6| Step: 9
Training loss: 2.540658490287512
Validation loss: 2.4553979152133008

Epoch: 6| Step: 10
Training loss: 2.768825080490817
Validation loss: 2.4589215807632394

Epoch: 6| Step: 11
Training loss: 2.609922796985686
Validation loss: 2.4719979533317678

Epoch: 6| Step: 12
Training loss: 2.9619979368585154
Validation loss: 2.5035040653046434

Epoch: 6| Step: 13
Training loss: 2.2326058806699627
Validation loss: 2.5303412340125817

Epoch: 167| Step: 0
Training loss: 2.9599999224173046
Validation loss: 2.5493179342873864

Epoch: 6| Step: 1
Training loss: 2.479081374125039
Validation loss: 2.5451313267836446

Epoch: 6| Step: 2
Training loss: 2.444787502298816
Validation loss: 2.5419272523380996

Epoch: 6| Step: 3
Training loss: 2.411280439391353
Validation loss: 2.536224048840993

Epoch: 6| Step: 4
Training loss: 2.436086391476764
Validation loss: 2.5295337746761173

Epoch: 6| Step: 5
Training loss: 2.573863072924444
Validation loss: 2.540863471679418

Epoch: 6| Step: 6
Training loss: 2.5635855631588016
Validation loss: 2.5592779997263815

Epoch: 6| Step: 7
Training loss: 2.5794243514874373
Validation loss: 2.5853106294663672

Epoch: 6| Step: 8
Training loss: 3.011623752149614
Validation loss: 2.5892746377584066

Epoch: 6| Step: 9
Training loss: 2.5161567268196308
Validation loss: 2.591698165220474

Epoch: 6| Step: 10
Training loss: 2.591223347844706
Validation loss: 2.6005603865935303

Epoch: 6| Step: 11
Training loss: 2.2566022434176474
Validation loss: 2.6025976488922087

Epoch: 6| Step: 12
Training loss: 2.640555296209278
Validation loss: 2.605267172986285

Epoch: 6| Step: 13
Training loss: 2.68767334135068
Validation loss: 2.5941805353108185

Epoch: 168| Step: 0
Training loss: 2.93704057712599
Validation loss: 2.586690318941196

Epoch: 6| Step: 1
Training loss: 2.774854786827984
Validation loss: 2.581687882199318

Epoch: 6| Step: 2
Training loss: 2.63149429963147
Validation loss: 2.5738488725088313

Epoch: 6| Step: 3
Training loss: 2.602471453448745
Validation loss: 2.559437849765166

Epoch: 6| Step: 4
Training loss: 2.522814127452434
Validation loss: 2.555213480451351

Epoch: 6| Step: 5
Training loss: 2.560695198703915
Validation loss: 2.545280848963099

Epoch: 6| Step: 6
Training loss: 2.473493051778651
Validation loss: 2.531243024355869

Epoch: 6| Step: 7
Training loss: 2.2758913201462287
Validation loss: 2.522925349270275

Epoch: 6| Step: 8
Training loss: 2.771706828248661
Validation loss: 2.522425870987626

Epoch: 6| Step: 9
Training loss: 2.6460191155836688
Validation loss: 2.519995433608236

Epoch: 6| Step: 10
Training loss: 2.021836991815158
Validation loss: 2.510227287283105

Epoch: 6| Step: 11
Training loss: 2.336307151915874
Validation loss: 2.5367226162381025

Epoch: 6| Step: 12
Training loss: 2.3403757856494325
Validation loss: 2.532648914077299

Epoch: 6| Step: 13
Training loss: 2.6053906933760653
Validation loss: 2.5472237439869208

Epoch: 169| Step: 0
Training loss: 1.7064332940437121
Validation loss: 2.543046319305639

Epoch: 6| Step: 1
Training loss: 2.5362239993113023
Validation loss: 2.531815370906968

Epoch: 6| Step: 2
Training loss: 2.6073671942417143
Validation loss: 2.5369427279439165

Epoch: 6| Step: 3
Training loss: 2.403451257987964
Validation loss: 2.5352421338088575

Epoch: 6| Step: 4
Training loss: 2.6326819141275157
Validation loss: 2.540323440791211

Epoch: 6| Step: 5
Training loss: 2.1397468269182887
Validation loss: 2.522812557449328

Epoch: 6| Step: 6
Training loss: 2.9943884182770475
Validation loss: 2.4995440374926523

Epoch: 6| Step: 7
Training loss: 2.226753092856918
Validation loss: 2.5045149098914816

Epoch: 6| Step: 8
Training loss: 2.4399365693586987
Validation loss: 2.505982382484133

Epoch: 6| Step: 9
Training loss: 2.6714209455202043
Validation loss: 2.51723408228724

Epoch: 6| Step: 10
Training loss: 2.0823709808352957
Validation loss: 2.5132734083897748

Epoch: 6| Step: 11
Training loss: 3.317053346441267
Validation loss: 2.53719956378234

Epoch: 6| Step: 12
Training loss: 2.7222234526996902
Validation loss: 2.5311865677729086

Epoch: 6| Step: 13
Training loss: 2.3919927137767854
Validation loss: 2.51796089590535

Epoch: 170| Step: 0
Training loss: 2.44542988748292
Validation loss: 2.5230641031803414

Epoch: 6| Step: 1
Training loss: 2.2189982100793704
Validation loss: 2.5151330834681223

Epoch: 6| Step: 2
Training loss: 1.7522658257201777
Validation loss: 2.5203511173415127

Epoch: 6| Step: 3
Training loss: 2.5358797284195633
Validation loss: 2.5268610117798342

Epoch: 6| Step: 4
Training loss: 1.7541812264871914
Validation loss: 2.530482080615054

Epoch: 6| Step: 5
Training loss: 2.5201665033101954
Validation loss: 2.541609345537301

Epoch: 6| Step: 6
Training loss: 2.9723992656453775
Validation loss: 2.5342756262172386

Epoch: 6| Step: 7
Training loss: 2.247923846818159
Validation loss: 2.5448336427421876

Epoch: 6| Step: 8
Training loss: 2.6773290459546617
Validation loss: 2.5360222866771482

Epoch: 6| Step: 9
Training loss: 2.752353961199081
Validation loss: 2.519912031353572

Epoch: 6| Step: 10
Training loss: 2.226838104858875
Validation loss: 2.5066138785394156

Epoch: 6| Step: 11
Training loss: 2.7547322218235
Validation loss: 2.505091266729337

Epoch: 6| Step: 12
Training loss: 3.0276508790778793
Validation loss: 2.496919211388777

Epoch: 6| Step: 13
Training loss: 2.7614207235101724
Validation loss: 2.4986848591918704

Epoch: 171| Step: 0
Training loss: 2.3693101889868626
Validation loss: 2.514144152820024

Epoch: 6| Step: 1
Training loss: 2.27868131482792
Validation loss: 2.515113572214538

Epoch: 6| Step: 2
Training loss: 2.36598895358476
Validation loss: 2.52736123347733

Epoch: 6| Step: 3
Training loss: 2.4490962872468987
Validation loss: 2.5442450225209736

Epoch: 6| Step: 4
Training loss: 2.1972234153931867
Validation loss: 2.5583837159146565

Epoch: 6| Step: 5
Training loss: 2.210087481359607
Validation loss: 2.5641394622201146

Epoch: 6| Step: 6
Training loss: 2.3255254582397904
Validation loss: 2.555214289611079

Epoch: 6| Step: 7
Training loss: 2.352227912110707
Validation loss: 2.565747621912964

Epoch: 6| Step: 8
Training loss: 2.9855933773098156
Validation loss: 2.5701475180561792

Epoch: 6| Step: 9
Training loss: 2.467299216158856
Validation loss: 2.5797815553839167

Epoch: 6| Step: 10
Training loss: 2.6772343831673258
Validation loss: 2.5548099567373526

Epoch: 6| Step: 11
Training loss: 2.6277067670396828
Validation loss: 2.5368351503674447

Epoch: 6| Step: 12
Training loss: 2.6267492732824618
Validation loss: 2.5338868201872913

Epoch: 6| Step: 13
Training loss: 3.0634681572645293
Validation loss: 2.54644156680384

Epoch: 172| Step: 0
Training loss: 3.186269934177709
Validation loss: 2.519247120592513

Epoch: 6| Step: 1
Training loss: 1.8304876726241306
Validation loss: 2.521399496867039

Epoch: 6| Step: 2
Training loss: 2.0571127383169237
Validation loss: 2.5211672933304805

Epoch: 6| Step: 3
Training loss: 3.1186584214580866
Validation loss: 2.5200631383671306

Epoch: 6| Step: 4
Training loss: 2.3767778869578633
Validation loss: 2.5268401443169735

Epoch: 6| Step: 5
Training loss: 1.9945795993943969
Validation loss: 2.5365495057472893

Epoch: 6| Step: 6
Training loss: 1.9083950918385177
Validation loss: 2.535446388282827

Epoch: 6| Step: 7
Training loss: 2.8067058643252754
Validation loss: 2.5345488209471227

Epoch: 6| Step: 8
Training loss: 2.537235201093451
Validation loss: 2.5252532131054917

Epoch: 6| Step: 9
Training loss: 2.3769751918398456
Validation loss: 2.5313423288780577

Epoch: 6| Step: 10
Training loss: 2.498163502396228
Validation loss: 2.534947875298601

Epoch: 6| Step: 11
Training loss: 2.6147826120086433
Validation loss: 2.514475247927997

Epoch: 6| Step: 12
Training loss: 2.050399192462216
Validation loss: 2.5098722781006746

Epoch: 6| Step: 13
Training loss: 3.0616673485913153
Validation loss: 2.513938762091741

Epoch: 173| Step: 0
Training loss: 2.3245097515109254
Validation loss: 2.530171624323589

Epoch: 6| Step: 1
Training loss: 2.8765151965361353
Validation loss: 2.5258658524376605

Epoch: 6| Step: 2
Training loss: 2.7743232279821926
Validation loss: 2.5157379041489154

Epoch: 6| Step: 3
Training loss: 2.303422380189977
Validation loss: 2.511072690838741

Epoch: 6| Step: 4
Training loss: 2.590215825989703
Validation loss: 2.5187752611713443

Epoch: 6| Step: 5
Training loss: 2.570681559958125
Validation loss: 2.5176889743011697

Epoch: 6| Step: 6
Training loss: 2.1582532781927126
Validation loss: 2.493723854521875

Epoch: 6| Step: 7
Training loss: 1.5954461888892508
Validation loss: 2.482912115445412

Epoch: 6| Step: 8
Training loss: 2.568351391681984
Validation loss: 2.483462832253208

Epoch: 6| Step: 9
Training loss: 2.2296711953842805
Validation loss: 2.498266102828245

Epoch: 6| Step: 10
Training loss: 2.365960435757398
Validation loss: 2.49757298414566

Epoch: 6| Step: 11
Training loss: 2.6017542129765467
Validation loss: 2.516926722084114

Epoch: 6| Step: 12
Training loss: 2.6247638414510117
Validation loss: 2.5328897461722044

Epoch: 6| Step: 13
Training loss: 2.498423651584705
Validation loss: 2.537651541582801

Epoch: 174| Step: 0
Training loss: 2.5992698304385837
Validation loss: 2.5764928171249832

Epoch: 6| Step: 1
Training loss: 2.82815956389661
Validation loss: 2.593818224807647

Epoch: 6| Step: 2
Training loss: 2.230617110734639
Validation loss: 2.5998156959454906

Epoch: 6| Step: 3
Training loss: 2.393395109238293
Validation loss: 2.6124233708578144

Epoch: 6| Step: 4
Training loss: 2.0400162727978493
Validation loss: 2.593870833985198

Epoch: 6| Step: 5
Training loss: 2.6902665381283497
Validation loss: 2.6139632024285775

Epoch: 6| Step: 6
Training loss: 2.3806608898114474
Validation loss: 2.6212338024927617

Epoch: 6| Step: 7
Training loss: 3.033653329032827
Validation loss: 2.621969567664538

Epoch: 6| Step: 8
Training loss: 2.3756726968659376
Validation loss: 2.604687615904236

Epoch: 6| Step: 9
Training loss: 2.415083388474384
Validation loss: 2.5613588733118586

Epoch: 6| Step: 10
Training loss: 2.1194376231970233
Validation loss: 2.55334656127403

Epoch: 6| Step: 11
Training loss: 1.8022959662735132
Validation loss: 2.528136530878168

Epoch: 6| Step: 12
Training loss: 2.697225140841636
Validation loss: 2.4966329419444406

Epoch: 6| Step: 13
Training loss: 2.4427202518608877
Validation loss: 2.479186313296577

Epoch: 175| Step: 0
Training loss: 2.357430774889994
Validation loss: 2.47108885450914

Epoch: 6| Step: 1
Training loss: 1.9703408126551423
Validation loss: 2.4854694343902994

Epoch: 6| Step: 2
Training loss: 1.8151392958391817
Validation loss: 2.468863884804416

Epoch: 6| Step: 3
Training loss: 2.6894036581439367
Validation loss: 2.492772257521358

Epoch: 6| Step: 4
Training loss: 2.0787473047987945
Validation loss: 2.4787194715670666

Epoch: 6| Step: 5
Training loss: 2.6534275992180363
Validation loss: 2.507351934951963

Epoch: 6| Step: 6
Training loss: 2.731984515904437
Validation loss: 2.5179215301723388

Epoch: 6| Step: 7
Training loss: 2.263656708318475
Validation loss: 2.54458113237811

Epoch: 6| Step: 8
Training loss: 2.558827350231875
Validation loss: 2.5669798839953497

Epoch: 6| Step: 9
Training loss: 2.378638742624407
Validation loss: 2.5683676277962895

Epoch: 6| Step: 10
Training loss: 2.729871780123214
Validation loss: 2.557571430582667

Epoch: 6| Step: 11
Training loss: 2.264712340591233
Validation loss: 2.5645571399246525

Epoch: 6| Step: 12
Training loss: 2.436166251687141
Validation loss: 2.5875449564438915

Epoch: 6| Step: 13
Training loss: 3.2764591664622693
Validation loss: 2.577188190732319

Epoch: 176| Step: 0
Training loss: 2.1489995047957895
Validation loss: 2.5682017942064563

Epoch: 6| Step: 1
Training loss: 2.5010312814323465
Validation loss: 2.5555464157516496

Epoch: 6| Step: 2
Training loss: 2.3420247149250635
Validation loss: 2.554710157026191

Epoch: 6| Step: 3
Training loss: 2.2161351228687525
Validation loss: 2.56259362094512

Epoch: 6| Step: 4
Training loss: 2.2204394288798373
Validation loss: 2.5550174671262584

Epoch: 6| Step: 5
Training loss: 2.1501409262668383
Validation loss: 2.54732377963761

Epoch: 6| Step: 6
Training loss: 2.5414333132156863
Validation loss: 2.55142057568039

Epoch: 6| Step: 7
Training loss: 2.5981919274096157
Validation loss: 2.5484794375991546

Epoch: 6| Step: 8
Training loss: 2.52211554418851
Validation loss: 2.5489649639927374

Epoch: 6| Step: 9
Training loss: 2.944584359337557
Validation loss: 2.54142809803431

Epoch: 6| Step: 10
Training loss: 2.6321567884780075
Validation loss: 2.53085217476046

Epoch: 6| Step: 11
Training loss: 2.6830093658147303
Validation loss: 2.526443986957236

Epoch: 6| Step: 12
Training loss: 1.8535522843203611
Validation loss: 2.51040044415161

Epoch: 6| Step: 13
Training loss: 2.0038736500607306
Validation loss: 2.523936458129543

Epoch: 177| Step: 0
Training loss: 2.5702497944241345
Validation loss: 2.5282759144251576

Epoch: 6| Step: 1
Training loss: 1.637273289369072
Validation loss: 2.5261525681083983

Epoch: 6| Step: 2
Training loss: 2.263705578372912
Validation loss: 2.5272580892552723

Epoch: 6| Step: 3
Training loss: 2.3601323611108955
Validation loss: 2.54138729719276

Epoch: 6| Step: 4
Training loss: 2.6492304782275964
Validation loss: 2.5556239012266726

Epoch: 6| Step: 5
Training loss: 2.547354436577155
Validation loss: 2.53917857217954

Epoch: 6| Step: 6
Training loss: 2.540258882801198
Validation loss: 2.5274502648604282

Epoch: 6| Step: 7
Training loss: 2.6701749334284943
Validation loss: 2.531302012632423

Epoch: 6| Step: 8
Training loss: 2.574987548501733
Validation loss: 2.5306997345478193

Epoch: 6| Step: 9
Training loss: 2.244301254858312
Validation loss: 2.540023484033063

Epoch: 6| Step: 10
Training loss: 2.5583270450808837
Validation loss: 2.5458477824308123

Epoch: 6| Step: 11
Training loss: 2.128226803488623
Validation loss: 2.5568402623358084

Epoch: 6| Step: 12
Training loss: 2.563365883027344
Validation loss: 2.5523298079654095

Epoch: 6| Step: 13
Training loss: 2.0370067303583332
Validation loss: 2.5340763407728653

Epoch: 178| Step: 0
Training loss: 2.729279396893281
Validation loss: 2.5704984827344943

Epoch: 6| Step: 1
Training loss: 2.542421906208708
Validation loss: 2.562536840126503

Epoch: 6| Step: 2
Training loss: 2.394399418398923
Validation loss: 2.5470496884717706

Epoch: 6| Step: 3
Training loss: 2.489177165290787
Validation loss: 2.5536494506066885

Epoch: 6| Step: 4
Training loss: 1.6499824696389858
Validation loss: 2.5703225637892757

Epoch: 6| Step: 5
Training loss: 2.666587192622693
Validation loss: 2.5624662847774538

Epoch: 6| Step: 6
Training loss: 2.7697251094660706
Validation loss: 2.5736053077961962

Epoch: 6| Step: 7
Training loss: 2.470205915879424
Validation loss: 2.580520583870831

Epoch: 6| Step: 8
Training loss: 2.607856262827217
Validation loss: 2.579734214012481

Epoch: 6| Step: 9
Training loss: 1.4229192567115696
Validation loss: 2.5792821082982154

Epoch: 6| Step: 10
Training loss: 2.4031089990527117
Validation loss: 2.585476162897775

Epoch: 6| Step: 11
Training loss: 2.3262909699388095
Validation loss: 2.5483524172627186

Epoch: 6| Step: 12
Training loss: 1.6444841319240957
Validation loss: 2.5425183486288487

Epoch: 6| Step: 13
Training loss: 2.9240022962902983
Validation loss: 2.5318424762518563

Epoch: 179| Step: 0
Training loss: 2.9394686980484486
Validation loss: 2.5102679256599347

Epoch: 6| Step: 1
Training loss: 2.1326853955300984
Validation loss: 2.486258650906727

Epoch: 6| Step: 2
Training loss: 2.659669896057338
Validation loss: 2.482557667447418

Epoch: 6| Step: 3
Training loss: 2.2796610694069477
Validation loss: 2.5146230848758515

Epoch: 6| Step: 4
Training loss: 2.5066783396300294
Validation loss: 2.529879772507814

Epoch: 6| Step: 5
Training loss: 2.7178094047992825
Validation loss: 2.5539118548359645

Epoch: 6| Step: 6
Training loss: 2.223090747808542
Validation loss: 2.5479296673460894

Epoch: 6| Step: 7
Training loss: 2.7645596968659225
Validation loss: 2.5443887730572623

Epoch: 6| Step: 8
Training loss: 1.766934339770318
Validation loss: 2.534914885862212

Epoch: 6| Step: 9
Training loss: 2.7172047400078436
Validation loss: 2.549980953747829

Epoch: 6| Step: 10
Training loss: 1.8391846855236154
Validation loss: 2.5361863281636485

Epoch: 6| Step: 11
Training loss: 2.132071006351113
Validation loss: 2.5218134023803436

Epoch: 6| Step: 12
Training loss: 2.25253449848612
Validation loss: 2.5201296236407242

Epoch: 6| Step: 13
Training loss: 1.8115687115299377
Validation loss: 2.5570317561448546

Epoch: 180| Step: 0
Training loss: 2.2257461925355337
Validation loss: 2.57368841541624

Epoch: 6| Step: 1
Training loss: 2.6054063414916047
Validation loss: 2.6290366440882442

Epoch: 6| Step: 2
Training loss: 2.339223432387783
Validation loss: 2.648168952605776

Epoch: 6| Step: 3
Training loss: 2.6765405621717986
Validation loss: 2.6248630716498798

Epoch: 6| Step: 4
Training loss: 2.3118489354157865
Validation loss: 2.596757716707054

Epoch: 6| Step: 5
Training loss: 2.4692677787842867
Validation loss: 2.5791417150317435

Epoch: 6| Step: 6
Training loss: 2.617834939158074
Validation loss: 2.559159460263128

Epoch: 6| Step: 7
Training loss: 2.647288835729689
Validation loss: 2.5419737749506526

Epoch: 6| Step: 8
Training loss: 2.262798255946172
Validation loss: 2.5425008312401487

Epoch: 6| Step: 9
Training loss: 1.9628662715179226
Validation loss: 2.5297459294197426

Epoch: 6| Step: 10
Training loss: 2.767113753660265
Validation loss: 2.5356429838512455

Epoch: 6| Step: 11
Training loss: 2.1714582523669343
Validation loss: 2.51896411324928

Epoch: 6| Step: 12
Training loss: 1.7115609761820374
Validation loss: 2.504540695459196

Epoch: 6| Step: 13
Training loss: 2.4390345902345953
Validation loss: 2.5189059810208194

Epoch: 181| Step: 0
Training loss: 2.0208374757494862
Validation loss: 2.5174909491760777

Epoch: 6| Step: 1
Training loss: 2.5065673398906996
Validation loss: 2.5312704705560507

Epoch: 6| Step: 2
Training loss: 2.165460568745707
Validation loss: 2.5644939257444266

Epoch: 6| Step: 3
Training loss: 2.340206570269903
Validation loss: 2.550741315374325

Epoch: 6| Step: 4
Training loss: 2.722989777505538
Validation loss: 2.55110604361111

Epoch: 6| Step: 5
Training loss: 1.849399897184438
Validation loss: 2.5322380957996042

Epoch: 6| Step: 6
Training loss: 1.5448437850641938
Validation loss: 2.532743654640565

Epoch: 6| Step: 7
Training loss: 2.2119490934381085
Validation loss: 2.5196081367418635

Epoch: 6| Step: 8
Training loss: 2.8666958504307627
Validation loss: 2.5360888736604155

Epoch: 6| Step: 9
Training loss: 2.634147961880066
Validation loss: 2.514952301453458

Epoch: 6| Step: 10
Training loss: 2.5614690800322824
Validation loss: 2.522454286659075

Epoch: 6| Step: 11
Training loss: 2.638172703871773
Validation loss: 2.5028265981122315

Epoch: 6| Step: 12
Training loss: 2.4933901190113623
Validation loss: 2.4875945027691793

Epoch: 6| Step: 13
Training loss: 2.133463107075946
Validation loss: 2.4958549664016734

Epoch: 182| Step: 0
Training loss: 2.5306721722442798
Validation loss: 2.522759985661487

Epoch: 6| Step: 1
Training loss: 2.3092508946006425
Validation loss: 2.512988655096422

Epoch: 6| Step: 2
Training loss: 1.9756763265978685
Validation loss: 2.507241501843489

Epoch: 6| Step: 3
Training loss: 2.2647053924017975
Validation loss: 2.5106836540459305

Epoch: 6| Step: 4
Training loss: 1.9712403910033207
Validation loss: 2.4817184141245807

Epoch: 6| Step: 5
Training loss: 2.0400675784866737
Validation loss: 2.496985083944519

Epoch: 6| Step: 6
Training loss: 2.7881692262625206
Validation loss: 2.487220928079021

Epoch: 6| Step: 7
Training loss: 2.1684194835151334
Validation loss: 2.4958225151470015

Epoch: 6| Step: 8
Training loss: 2.1832585222468226
Validation loss: 2.5016556743482994

Epoch: 6| Step: 9
Training loss: 2.4602499349520652
Validation loss: 2.524307036650599

Epoch: 6| Step: 10
Training loss: 2.5062414459310847
Validation loss: 2.5531317999231566

Epoch: 6| Step: 11
Training loss: 2.7120511188978154
Validation loss: 2.5980255957375022

Epoch: 6| Step: 12
Training loss: 2.387780984851042
Validation loss: 2.6103773514810245

Epoch: 6| Step: 13
Training loss: 2.380294620165807
Validation loss: 2.6334998342832114

Epoch: 183| Step: 0
Training loss: 2.2405268138191032
Validation loss: 2.6442587090056016

Epoch: 6| Step: 1
Training loss: 2.505755855714452
Validation loss: 2.6356436810685477

Epoch: 6| Step: 2
Training loss: 1.4130156630709592
Validation loss: 2.6292716671040757

Epoch: 6| Step: 3
Training loss: 2.511826864380735
Validation loss: 2.6415910579251216

Epoch: 6| Step: 4
Training loss: 2.33033565559357
Validation loss: 2.6453598938594145

Epoch: 6| Step: 5
Training loss: 2.767904258362177
Validation loss: 2.6287622821172527

Epoch: 6| Step: 6
Training loss: 1.892926667265603
Validation loss: 2.6214120313186573

Epoch: 6| Step: 7
Training loss: 2.6627483090946975
Validation loss: 2.5958587045048094

Epoch: 6| Step: 8
Training loss: 2.4160383218795447
Validation loss: 2.5711102796510743

Epoch: 6| Step: 9
Training loss: 2.1459362659642447
Validation loss: 2.5306537300104974

Epoch: 6| Step: 10
Training loss: 2.3776240659607324
Validation loss: 2.5090343856892154

Epoch: 6| Step: 11
Training loss: 1.9448621603951812
Validation loss: 2.5006209443204552

Epoch: 6| Step: 12
Training loss: 2.7726913952957988
Validation loss: 2.4870446513764937

Epoch: 6| Step: 13
Training loss: 2.7900183826784355
Validation loss: 2.468882926705011

Epoch: 184| Step: 0
Training loss: 2.1419667960121385
Validation loss: 2.487491179782621

Epoch: 6| Step: 1
Training loss: 2.1248370837422548
Validation loss: 2.507168028402442

Epoch: 6| Step: 2
Training loss: 2.58938148020772
Validation loss: 2.5132402247235515

Epoch: 6| Step: 3
Training loss: 2.586649448085119
Validation loss: 2.544197127718168

Epoch: 6| Step: 4
Training loss: 2.4316938647221393
Validation loss: 2.5541339093957798

Epoch: 6| Step: 5
Training loss: 2.7979697530391783
Validation loss: 2.573903681676679

Epoch: 6| Step: 6
Training loss: 2.4753775183469293
Validation loss: 2.597765238570604

Epoch: 6| Step: 7
Training loss: 2.4352050149763205
Validation loss: 2.5787957267064683

Epoch: 6| Step: 8
Training loss: 2.411579422900636
Validation loss: 2.565619200242693

Epoch: 6| Step: 9
Training loss: 2.117202589818804
Validation loss: 2.557671789208961

Epoch: 6| Step: 10
Training loss: 2.1456472692714614
Validation loss: 2.5574311726970618

Epoch: 6| Step: 11
Training loss: 2.047843762093215
Validation loss: 2.564474996974857

Epoch: 6| Step: 12
Training loss: 1.7477677958961202
Validation loss: 2.543668648080383

Epoch: 6| Step: 13
Training loss: 1.8831250576319338
Validation loss: 2.548544176644082

Epoch: 185| Step: 0
Training loss: 1.8175616127705385
Validation loss: 2.523263791002006

Epoch: 6| Step: 1
Training loss: 2.5644585172853627
Validation loss: 2.5387807079158184

Epoch: 6| Step: 2
Training loss: 1.916366684976028
Validation loss: 2.5395291110290668

Epoch: 6| Step: 3
Training loss: 2.3324228849266677
Validation loss: 2.544895909276345

Epoch: 6| Step: 4
Training loss: 2.7118647416011554
Validation loss: 2.5595171725783583

Epoch: 6| Step: 5
Training loss: 2.4290990576869573
Validation loss: 2.559871690286365

Epoch: 6| Step: 6
Training loss: 2.6308272939650346
Validation loss: 2.5544612960365325

Epoch: 6| Step: 7
Training loss: 2.135973254604272
Validation loss: 2.562958448985188

Epoch: 6| Step: 8
Training loss: 2.153380322647359
Validation loss: 2.541269203375245

Epoch: 6| Step: 9
Training loss: 2.3609949070876763
Validation loss: 2.562770616121665

Epoch: 6| Step: 10
Training loss: 1.940174164672044
Validation loss: 2.56290955450807

Epoch: 6| Step: 11
Training loss: 1.7446992840198983
Validation loss: 2.567588128576014

Epoch: 6| Step: 12
Training loss: 2.5483252018195235
Validation loss: 2.5841833572564825

Epoch: 6| Step: 13
Training loss: 2.653664171768828
Validation loss: 2.565022284437275

Epoch: 186| Step: 0
Training loss: 1.8885481595662252
Validation loss: 2.538287585623797

Epoch: 6| Step: 1
Training loss: 2.387935946143812
Validation loss: 2.529282138540967

Epoch: 6| Step: 2
Training loss: 1.9859365491767247
Validation loss: 2.4877984473330663

Epoch: 6| Step: 3
Training loss: 2.149483498921029
Validation loss: 2.497032162573021

Epoch: 6| Step: 4
Training loss: 1.7893281431255497
Validation loss: 2.4703419543423197

Epoch: 6| Step: 5
Training loss: 2.362304586573737
Validation loss: 2.4754193429783835

Epoch: 6| Step: 6
Training loss: 2.9932171118361706
Validation loss: 2.484849426989082

Epoch: 6| Step: 7
Training loss: 2.396288477469822
Validation loss: 2.47550788230951

Epoch: 6| Step: 8
Training loss: 2.013719471203378
Validation loss: 2.497902699034226

Epoch: 6| Step: 9
Training loss: 2.2189522234675847
Validation loss: 2.5033631755125603

Epoch: 6| Step: 10
Training loss: 2.6027634972997404
Validation loss: 2.5105922114913533

Epoch: 6| Step: 11
Training loss: 2.179066340493555
Validation loss: 2.527103673677592

Epoch: 6| Step: 12
Training loss: 1.8159093689926442
Validation loss: 2.556381016996736

Epoch: 6| Step: 13
Training loss: 2.775358668337309
Validation loss: 2.5617202074521948

Epoch: 187| Step: 0
Training loss: 2.316540667540217
Validation loss: 2.5711133776226855

Epoch: 6| Step: 1
Training loss: 2.152001770876755
Validation loss: 2.558430830092556

Epoch: 6| Step: 2
Training loss: 2.5139225476882032
Validation loss: 2.5761449365354054

Epoch: 6| Step: 3
Training loss: 2.356093594244785
Validation loss: 2.565689676881552

Epoch: 6| Step: 4
Training loss: 2.346251310125604
Validation loss: 2.584047535016416

Epoch: 6| Step: 5
Training loss: 2.147340695708542
Validation loss: 2.5824552781110874

Epoch: 6| Step: 6
Training loss: 2.427043494250946
Validation loss: 2.556919847209203

Epoch: 6| Step: 7
Training loss: 1.2850242941226016
Validation loss: 2.545329718481592

Epoch: 6| Step: 8
Training loss: 2.3245110848848283
Validation loss: 2.5480872638133643

Epoch: 6| Step: 9
Training loss: 2.134601331917022
Validation loss: 2.5521812723205053

Epoch: 6| Step: 10
Training loss: 2.1708826226650673
Validation loss: 2.5439199364211595

Epoch: 6| Step: 11
Training loss: 2.5550906361966277
Validation loss: 2.5285083523048706

Epoch: 6| Step: 12
Training loss: 2.3502189371916766
Validation loss: 2.5228103421682038

Epoch: 6| Step: 13
Training loss: 1.9187793145441097
Validation loss: 2.5237339437049426

Epoch: 188| Step: 0
Training loss: 2.1836946358346996
Validation loss: 2.5198007874268926

Epoch: 6| Step: 1
Training loss: 2.0706653222355813
Validation loss: 2.5182750737720103

Epoch: 6| Step: 2
Training loss: 2.3068627388627547
Validation loss: 2.5075049040619466

Epoch: 6| Step: 3
Training loss: 2.498516310068531
Validation loss: 2.4872509209631364

Epoch: 6| Step: 4
Training loss: 1.8798572568271061
Validation loss: 2.499545971855198

Epoch: 6| Step: 5
Training loss: 2.6222470698104314
Validation loss: 2.5109676048770866

Epoch: 6| Step: 6
Training loss: 2.218609120369245
Validation loss: 2.505549220748715

Epoch: 6| Step: 7
Training loss: 2.023925368949747
Validation loss: 2.5033920748436107

Epoch: 6| Step: 8
Training loss: 1.9549556240304025
Validation loss: 2.5137942595155036

Epoch: 6| Step: 9
Training loss: 2.1812824716856274
Validation loss: 2.509784382112858

Epoch: 6| Step: 10
Training loss: 2.150557259488031
Validation loss: 2.508773000793936

Epoch: 6| Step: 11
Training loss: 2.0677303694184195
Validation loss: 2.5297140598641477

Epoch: 6| Step: 12
Training loss: 2.25665063233457
Validation loss: 2.511648834025525

Epoch: 6| Step: 13
Training loss: 2.725248440957522
Validation loss: 2.511221321224897

Epoch: 189| Step: 0
Training loss: 1.9108771151642439
Validation loss: 2.4959663952907265

Epoch: 6| Step: 1
Training loss: 2.669124414413446
Validation loss: 2.4764311822192635

Epoch: 6| Step: 2
Training loss: 2.258712325254284
Validation loss: 2.4857893472976573

Epoch: 6| Step: 3
Training loss: 2.1997082776945693
Validation loss: 2.490161538390977

Epoch: 6| Step: 4
Training loss: 1.9874590839516872
Validation loss: 2.4813282629922035

Epoch: 6| Step: 5
Training loss: 2.1990305411805724
Validation loss: 2.471405872806962

Epoch: 6| Step: 6
Training loss: 2.495890195662648
Validation loss: 2.503989346860641

Epoch: 6| Step: 7
Training loss: 1.8298419812252293
Validation loss: 2.520427449140386

Epoch: 6| Step: 8
Training loss: 1.841571231745603
Validation loss: 2.5112838081469633

Epoch: 6| Step: 9
Training loss: 2.015520433182742
Validation loss: 2.5158125274310588

Epoch: 6| Step: 10
Training loss: 2.2820181402543565
Validation loss: 2.5040018528212604

Epoch: 6| Step: 11
Training loss: 2.435485006982856
Validation loss: 2.5103968750276437

Epoch: 6| Step: 12
Training loss: 2.2742322863035405
Validation loss: 2.513481376860545

Epoch: 6| Step: 13
Training loss: 2.3139848839044372
Validation loss: 2.514563252158774

Epoch: 190| Step: 0
Training loss: 2.4263800282842123
Validation loss: 2.5060374064244484

Epoch: 6| Step: 1
Training loss: 1.907724279415013
Validation loss: 2.5159937163471326

Epoch: 6| Step: 2
Training loss: 1.9918874477240511
Validation loss: 2.5042911904463026

Epoch: 6| Step: 3
Training loss: 2.592550069091876
Validation loss: 2.5142906918770747

Epoch: 6| Step: 4
Training loss: 2.1521319442630786
Validation loss: 2.510682940302064

Epoch: 6| Step: 5
Training loss: 2.249274454755342
Validation loss: 2.5108122951504988

Epoch: 6| Step: 6
Training loss: 1.8871531489922764
Validation loss: 2.519840339486587

Epoch: 6| Step: 7
Training loss: 2.9193672393388606
Validation loss: 2.5345735069615065

Epoch: 6| Step: 8
Training loss: 2.339329632811701
Validation loss: 2.5393785243098383

Epoch: 6| Step: 9
Training loss: 2.50804274978586
Validation loss: 2.5575894521839584

Epoch: 6| Step: 10
Training loss: 1.8781963442741159
Validation loss: 2.5755615267657737

Epoch: 6| Step: 11
Training loss: 1.6626414647541496
Validation loss: 2.58556695795305

Epoch: 6| Step: 12
Training loss: 2.236951076581371
Validation loss: 2.596518657722258

Epoch: 6| Step: 13
Training loss: 1.9744778824217322
Validation loss: 2.606262459052224

Epoch: 191| Step: 0
Training loss: 2.8115670246165454
Validation loss: 2.594021662987493

Epoch: 6| Step: 1
Training loss: 1.8524987151518573
Validation loss: 2.567616759330513

Epoch: 6| Step: 2
Training loss: 2.2735444663141333
Validation loss: 2.549920817623061

Epoch: 6| Step: 3
Training loss: 2.5359993166155452
Validation loss: 2.5378080403234256

Epoch: 6| Step: 4
Training loss: 2.2875976041388735
Validation loss: 2.5269036085463275

Epoch: 6| Step: 5
Training loss: 2.2442186041581405
Validation loss: 2.516494057689172

Epoch: 6| Step: 6
Training loss: 1.898333511330203
Validation loss: 2.513218245014806

Epoch: 6| Step: 7
Training loss: 2.2968110575176937
Validation loss: 2.5087360169911963

Epoch: 6| Step: 8
Training loss: 1.9800312228582793
Validation loss: 2.5051868775413664

Epoch: 6| Step: 9
Training loss: 2.4116555470401613
Validation loss: 2.515572386028186

Epoch: 6| Step: 10
Training loss: 1.699584921483617
Validation loss: 2.509243171379917

Epoch: 6| Step: 11
Training loss: 2.406856311853328
Validation loss: 2.5324587329329047

Epoch: 6| Step: 12
Training loss: 2.0052541620211084
Validation loss: 2.5303929958297884

Epoch: 6| Step: 13
Training loss: 2.659906003051303
Validation loss: 2.538894631111307

Epoch: 192| Step: 0
Training loss: 2.0856364172193445
Validation loss: 2.5168208293505656

Epoch: 6| Step: 1
Training loss: 2.184167339621271
Validation loss: 2.521302707235949

Epoch: 6| Step: 2
Training loss: 2.7425327355405393
Validation loss: 2.5218699483356675

Epoch: 6| Step: 3
Training loss: 1.806567909220747
Validation loss: 2.542047108689076

Epoch: 6| Step: 4
Training loss: 2.29303529503098
Validation loss: 2.536481241459359

Epoch: 6| Step: 5
Training loss: 1.89608015472857
Validation loss: 2.543605754336534

Epoch: 6| Step: 6
Training loss: 1.6516982817615327
Validation loss: 2.5328417621544776

Epoch: 6| Step: 7
Training loss: 2.3748675861589272
Validation loss: 2.5190895043717387

Epoch: 6| Step: 8
Training loss: 1.6180656370941273
Validation loss: 2.517880036349654

Epoch: 6| Step: 9
Training loss: 2.482584662093454
Validation loss: 2.5364513485979465

Epoch: 6| Step: 10
Training loss: 2.8360615852889652
Validation loss: 2.5292019637666567

Epoch: 6| Step: 11
Training loss: 1.857509542776986
Validation loss: 2.5311099831157025

Epoch: 6| Step: 12
Training loss: 2.22632659197763
Validation loss: 2.550007102943548

Epoch: 6| Step: 13
Training loss: 2.072278280695921
Validation loss: 2.5487951744023247

Epoch: 193| Step: 0
Training loss: 2.2203010188321977
Validation loss: 2.538903238178126

Epoch: 6| Step: 1
Training loss: 1.6693278365933368
Validation loss: 2.5313664304105554

Epoch: 6| Step: 2
Training loss: 2.0427217936003434
Validation loss: 2.535079146146383

Epoch: 6| Step: 3
Training loss: 2.577532243499211
Validation loss: 2.5236204373045337

Epoch: 6| Step: 4
Training loss: 2.5862928993350933
Validation loss: 2.5401628672911567

Epoch: 6| Step: 5
Training loss: 2.2368796655436247
Validation loss: 2.535892527990382

Epoch: 6| Step: 6
Training loss: 2.6863633346968196
Validation loss: 2.543765649936105

Epoch: 6| Step: 7
Training loss: 2.0112928810076713
Validation loss: 2.553805588362013

Epoch: 6| Step: 8
Training loss: 1.9775198928469024
Validation loss: 2.5487401894070367

Epoch: 6| Step: 9
Training loss: 1.8191186485412938
Validation loss: 2.5716749840846327

Epoch: 6| Step: 10
Training loss: 2.1343955847444294
Validation loss: 2.5905396507087

Epoch: 6| Step: 11
Training loss: 2.4130767488632725
Validation loss: 2.593085253114184

Epoch: 6| Step: 12
Training loss: 1.3876599193894312
Validation loss: 2.591601136308321

Epoch: 6| Step: 13
Training loss: 2.1160379927961563
Validation loss: 2.5987849119209585

Epoch: 194| Step: 0
Training loss: 2.6204732282610634
Validation loss: 2.5755521822008327

Epoch: 6| Step: 1
Training loss: 1.821706082870715
Validation loss: 2.5832067379876644

Epoch: 6| Step: 2
Training loss: 1.5401895337079954
Validation loss: 2.5719328529646126

Epoch: 6| Step: 3
Training loss: 2.647775032663499
Validation loss: 2.5745166151422394

Epoch: 6| Step: 4
Training loss: 2.279143418978648
Validation loss: 2.5663314550964644

Epoch: 6| Step: 5
Training loss: 1.6572246922407685
Validation loss: 2.5512080141550246

Epoch: 6| Step: 6
Training loss: 1.5856125973286705
Validation loss: 2.542868591415917

Epoch: 6| Step: 7
Training loss: 2.347746125340019
Validation loss: 2.542523140102164

Epoch: 6| Step: 8
Training loss: 1.9994223475715445
Validation loss: 2.51573409395089

Epoch: 6| Step: 9
Training loss: 2.438671515222022
Validation loss: 2.5167937496505903

Epoch: 6| Step: 10
Training loss: 2.192045122065052
Validation loss: 2.5142710660049747

Epoch: 6| Step: 11
Training loss: 2.355733524453142
Validation loss: 2.49995272499424

Epoch: 6| Step: 12
Training loss: 2.129700566767393
Validation loss: 2.4991933280030043

Epoch: 6| Step: 13
Training loss: 1.9760820008302102
Validation loss: 2.502104437485822

Epoch: 195| Step: 0
Training loss: 2.0671034792247927
Validation loss: 2.488607754970682

Epoch: 6| Step: 1
Training loss: 2.4577090445908705
Validation loss: 2.47965802143769

Epoch: 6| Step: 2
Training loss: 1.7779655961654801
Validation loss: 2.503365251831044

Epoch: 6| Step: 3
Training loss: 2.3677713914141947
Validation loss: 2.4905897582699947

Epoch: 6| Step: 4
Training loss: 2.840018538562282
Validation loss: 2.4972633724381144

Epoch: 6| Step: 5
Training loss: 2.0701356056503277
Validation loss: 2.508173743306469

Epoch: 6| Step: 6
Training loss: 2.240780272483945
Validation loss: 2.5184090704426563

Epoch: 6| Step: 7
Training loss: 2.2554624794587776
Validation loss: 2.4860060209732784

Epoch: 6| Step: 8
Training loss: 1.810570841181051
Validation loss: 2.504506108897395

Epoch: 6| Step: 9
Training loss: 1.9205111494746256
Validation loss: 2.5021106526639527

Epoch: 6| Step: 10
Training loss: 2.0057457406042642
Validation loss: 2.5374352992908094

Epoch: 6| Step: 11
Training loss: 1.9003124632644839
Validation loss: 2.517831895083291

Epoch: 6| Step: 12
Training loss: 2.0428688506287283
Validation loss: 2.5440388060651125

Epoch: 6| Step: 13
Training loss: 1.424113596907126
Validation loss: 2.533653094898885

Epoch: 196| Step: 0
Training loss: 2.036534170574479
Validation loss: 2.5338804128148142

Epoch: 6| Step: 1
Training loss: 2.5020082037384905
Validation loss: 2.545034317548215

Epoch: 6| Step: 2
Training loss: 1.9125482914630796
Validation loss: 2.5551707260533227

Epoch: 6| Step: 3
Training loss: 2.2254951997532495
Validation loss: 2.5543702243286868

Epoch: 6| Step: 4
Training loss: 1.759508188196649
Validation loss: 2.5635321664556434

Epoch: 6| Step: 5
Training loss: 1.7104011984097427
Validation loss: 2.5667316233444986

Epoch: 6| Step: 6
Training loss: 1.5575267992729664
Validation loss: 2.5614869671213047

Epoch: 6| Step: 7
Training loss: 2.6044820263967985
Validation loss: 2.545958748182968

Epoch: 6| Step: 8
Training loss: 1.9767299777158274
Validation loss: 2.527409930146534

Epoch: 6| Step: 9
Training loss: 2.0582736090310707
Validation loss: 2.5244682226386805

Epoch: 6| Step: 10
Training loss: 2.5972211659837865
Validation loss: 2.5299697822761376

Epoch: 6| Step: 11
Training loss: 1.8704658999910089
Validation loss: 2.543078449211237

Epoch: 6| Step: 12
Training loss: 2.2390735016344228
Validation loss: 2.5160265401893356

Epoch: 6| Step: 13
Training loss: 2.5532183141009406
Validation loss: 2.482376286297887

Epoch: 197| Step: 0
Training loss: 2.106314466265268
Validation loss: 2.482543141994436

Epoch: 6| Step: 1
Training loss: 2.1218034600177074
Validation loss: 2.4599373838254244

Epoch: 6| Step: 2
Training loss: 2.83354216161338
Validation loss: 2.4624385070868433

Epoch: 6| Step: 3
Training loss: 1.87397725504097
Validation loss: 2.4636328267836047

Epoch: 6| Step: 4
Training loss: 2.3846844433612553
Validation loss: 2.4548732959185595

Epoch: 6| Step: 5
Training loss: 1.5778738898492701
Validation loss: 2.4451429569142484

Epoch: 6| Step: 6
Training loss: 1.6165681104343292
Validation loss: 2.461895778933523

Epoch: 6| Step: 7
Training loss: 2.206916090399886
Validation loss: 2.485149706217506

Epoch: 6| Step: 8
Training loss: 1.8224793990531538
Validation loss: 2.5028718368551477

Epoch: 6| Step: 9
Training loss: 2.5821631047318596
Validation loss: 2.5338193289907465

Epoch: 6| Step: 10
Training loss: 1.9882283081920487
Validation loss: 2.538874880387799

Epoch: 6| Step: 11
Training loss: 1.86836492851464
Validation loss: 2.570135495542828

Epoch: 6| Step: 12
Training loss: 1.9490998562500048
Validation loss: 2.5859919439045225

Epoch: 6| Step: 13
Training loss: 2.311322298956448
Validation loss: 2.5704597934380597

Epoch: 198| Step: 0
Training loss: 1.782716314878878
Validation loss: 2.5497440635964734

Epoch: 6| Step: 1
Training loss: 2.3006811460210512
Validation loss: 2.5345335910755553

Epoch: 6| Step: 2
Training loss: 2.8498993504469983
Validation loss: 2.508413231687483

Epoch: 6| Step: 3
Training loss: 2.243011748440877
Validation loss: 2.4913861456101007

Epoch: 6| Step: 4
Training loss: 2.2433097768777723
Validation loss: 2.4623364575543247

Epoch: 6| Step: 5
Training loss: 2.1215071301687707
Validation loss: 2.440008593760486

Epoch: 6| Step: 6
Training loss: 2.1338528621397406
Validation loss: 2.4299728362648465

Epoch: 6| Step: 7
Training loss: 1.839591233728652
Validation loss: 2.432578589530842

Epoch: 6| Step: 8
Training loss: 1.7516701085897373
Validation loss: 2.4492525043200404

Epoch: 6| Step: 9
Training loss: 1.4630324087457964
Validation loss: 2.4304466205176904

Epoch: 6| Step: 10
Training loss: 2.336261127214788
Validation loss: 2.4749113669237883

Epoch: 6| Step: 11
Training loss: 2.116040133566184
Validation loss: 2.477089847975041

Epoch: 6| Step: 12
Training loss: 2.0047628196784983
Validation loss: 2.4918029418509513

Epoch: 6| Step: 13
Training loss: 1.7827992310895282
Validation loss: 2.5211258351329158

Epoch: 199| Step: 0
Training loss: 2.4566489985161497
Validation loss: 2.544990539442941

Epoch: 6| Step: 1
Training loss: 1.8980286711365293
Validation loss: 2.5466075147519507

Epoch: 6| Step: 2
Training loss: 1.773785796392325
Validation loss: 2.586434614228962

Epoch: 6| Step: 3
Training loss: 1.912742751429251
Validation loss: 2.6286398131509263

Epoch: 6| Step: 4
Training loss: 2.1417126641980544
Validation loss: 2.64504424900314

Epoch: 6| Step: 5
Training loss: 2.5073283551116075
Validation loss: 2.6555639974813166

Epoch: 6| Step: 6
Training loss: 2.2842469060759347
Validation loss: 2.6824525126421235

Epoch: 6| Step: 7
Training loss: 1.6687108696053703
Validation loss: 2.6327959183505825

Epoch: 6| Step: 8
Training loss: 1.970073678822138
Validation loss: 2.630886168337813

Epoch: 6| Step: 9
Training loss: 1.970655094767463
Validation loss: 2.5968200082685726

Epoch: 6| Step: 10
Training loss: 2.5043324124223565
Validation loss: 2.5694450078725453

Epoch: 6| Step: 11
Training loss: 2.2421657016239496
Validation loss: 2.5471031307738192

Epoch: 6| Step: 12
Training loss: 2.0421101095045833
Validation loss: 2.5175566154341453

Epoch: 6| Step: 13
Training loss: 1.4946198137586875
Validation loss: 2.487915729294438

Epoch: 200| Step: 0
Training loss: 1.6828893617381144
Validation loss: 2.4829173172437007

Epoch: 6| Step: 1
Training loss: 2.224148160767655
Validation loss: 2.467885845527515

Epoch: 6| Step: 2
Training loss: 1.7620967620147887
Validation loss: 2.4663326421675054

Epoch: 6| Step: 3
Training loss: 2.066148709435493
Validation loss: 2.4713860702741846

Epoch: 6| Step: 4
Training loss: 2.510785488614355
Validation loss: 2.4932049090804216

Epoch: 6| Step: 5
Training loss: 2.2317833441996062
Validation loss: 2.528733092304294

Epoch: 6| Step: 6
Training loss: 2.1288545094773323
Validation loss: 2.541037355688703

Epoch: 6| Step: 7
Training loss: 1.689365486121053
Validation loss: 2.549019321588864

Epoch: 6| Step: 8
Training loss: 1.9760292751290383
Validation loss: 2.5388226391854007

Epoch: 6| Step: 9
Training loss: 2.263501033309994
Validation loss: 2.54142486602872

Epoch: 6| Step: 10
Training loss: 2.2294092016695295
Validation loss: 2.5192664197148686

Epoch: 6| Step: 11
Training loss: 1.8607192109243877
Validation loss: 2.5314337662308892

Epoch: 6| Step: 12
Training loss: 2.3842817935749743
Validation loss: 2.5372274239775554

Epoch: 6| Step: 13
Training loss: 1.9319302271412688
Validation loss: 2.538189659314089

Epoch: 201| Step: 0
Training loss: 2.1563746098434047
Validation loss: 2.5663864912392915

Epoch: 6| Step: 1
Training loss: 1.7411071438322545
Validation loss: 2.593076851595805

Epoch: 6| Step: 2
Training loss: 2.235707879155224
Validation loss: 2.6190379722632233

Epoch: 6| Step: 3
Training loss: 1.679974553619404
Validation loss: 2.6364352866222966

Epoch: 6| Step: 4
Training loss: 1.3520698256716703
Validation loss: 2.6801705615175226

Epoch: 6| Step: 5
Training loss: 2.2916187165763606
Validation loss: 2.7176273863199016

Epoch: 6| Step: 6
Training loss: 2.088225178192339
Validation loss: 2.7358093924749585

Epoch: 6| Step: 7
Training loss: 2.763867784437652
Validation loss: 2.7546824847035256

Epoch: 6| Step: 8
Training loss: 2.3621986116182527
Validation loss: 2.7179271908353804

Epoch: 6| Step: 9
Training loss: 2.29685527767096
Validation loss: 2.681406658405499

Epoch: 6| Step: 10
Training loss: 1.9730020050100512
Validation loss: 2.614367334725669

Epoch: 6| Step: 11
Training loss: 1.9702565317576892
Validation loss: 2.568547970925703

Epoch: 6| Step: 12
Training loss: 1.8331671408261807
Validation loss: 2.523135469755663

Epoch: 6| Step: 13
Training loss: 2.0974500615173373
Validation loss: 2.4855926165329967

Epoch: 202| Step: 0
Training loss: 2.314790673730499
Validation loss: 2.4491799614747594

Epoch: 6| Step: 1
Training loss: 1.9869887792138947
Validation loss: 2.461030872954603

Epoch: 6| Step: 2
Training loss: 2.123515452006047
Validation loss: 2.4534252289489658

Epoch: 6| Step: 3
Training loss: 1.9488681026784684
Validation loss: 2.4645957101067606

Epoch: 6| Step: 4
Training loss: 1.6625537031864577
Validation loss: 2.46250230945133

Epoch: 6| Step: 5
Training loss: 2.1461171329808915
Validation loss: 2.4566500629388175

Epoch: 6| Step: 6
Training loss: 2.0770579875699253
Validation loss: 2.469818793549057

Epoch: 6| Step: 7
Training loss: 1.7302241787614552
Validation loss: 2.4941502087977705

Epoch: 6| Step: 8
Training loss: 2.201639418547683
Validation loss: 2.5178277143763865

Epoch: 6| Step: 9
Training loss: 2.2545152499253573
Validation loss: 2.547228220650407

Epoch: 6| Step: 10
Training loss: 2.0145483172377254
Validation loss: 2.5482014047549995

Epoch: 6| Step: 11
Training loss: 2.396502879474708
Validation loss: 2.5869857853769207

Epoch: 6| Step: 12
Training loss: 2.037741865534734
Validation loss: 2.586700853206017

Epoch: 6| Step: 13
Training loss: 2.3496625455070754
Validation loss: 2.6133605404468887

Epoch: 203| Step: 0
Training loss: 2.663230609496277
Validation loss: 2.624839988788971

Epoch: 6| Step: 1
Training loss: 2.0879464637133904
Validation loss: 2.6126249275732576

Epoch: 6| Step: 2
Training loss: 1.3800082031641971
Validation loss: 2.592581552865151

Epoch: 6| Step: 3
Training loss: 1.952158574378071
Validation loss: 2.5858995269831593

Epoch: 6| Step: 4
Training loss: 2.1861408916137677
Validation loss: 2.594268871466167

Epoch: 6| Step: 5
Training loss: 2.323659416021427
Validation loss: 2.5992865056343195

Epoch: 6| Step: 6
Training loss: 1.6427604945998056
Validation loss: 2.5597317156809094

Epoch: 6| Step: 7
Training loss: 1.7487310168290522
Validation loss: 2.5558059244676845

Epoch: 6| Step: 8
Training loss: 1.9658207976278588
Validation loss: 2.527369667822224

Epoch: 6| Step: 9
Training loss: 2.213937079323808
Validation loss: 2.495329535548017

Epoch: 6| Step: 10
Training loss: 2.1398331785689493
Validation loss: 2.499896411390362

Epoch: 6| Step: 11
Training loss: 2.288086041700008
Validation loss: 2.4617525557417608

Epoch: 6| Step: 12
Training loss: 1.7904130926785282
Validation loss: 2.448648670498741

Epoch: 6| Step: 13
Training loss: 1.7180240832096276
Validation loss: 2.474011444057105

Epoch: 204| Step: 0
Training loss: 1.9079423490007752
Validation loss: 2.4647079208550453

Epoch: 6| Step: 1
Training loss: 1.5749511529523037
Validation loss: 2.516601025649519

Epoch: 6| Step: 2
Training loss: 1.893707473831347
Validation loss: 2.545105720782201

Epoch: 6| Step: 3
Training loss: 2.1814719931539996
Validation loss: 2.5652611625670105

Epoch: 6| Step: 4
Training loss: 1.8317537077174688
Validation loss: 2.574861768131811

Epoch: 6| Step: 5
Training loss: 2.025010370298605
Validation loss: 2.598586634387995

Epoch: 6| Step: 6
Training loss: 2.5612502423235592
Validation loss: 2.6002821908784193

Epoch: 6| Step: 7
Training loss: 1.998134159929831
Validation loss: 2.6024396351943633

Epoch: 6| Step: 8
Training loss: 2.179225968477292
Validation loss: 2.625367793672751

Epoch: 6| Step: 9
Training loss: 1.7203048608871887
Validation loss: 2.6390219667993287

Epoch: 6| Step: 10
Training loss: 1.824820049767931
Validation loss: 2.675329558425952

Epoch: 6| Step: 11
Training loss: 2.294333472607374
Validation loss: 2.656467688927921

Epoch: 6| Step: 12
Training loss: 2.237049342969086
Validation loss: 2.679745461628648

Epoch: 6| Step: 13
Training loss: 2.2372811364907874
Validation loss: 2.64693668670025

Epoch: 205| Step: 0
Training loss: 2.1142623231764817
Validation loss: 2.6103144425764633

Epoch: 6| Step: 1
Training loss: 1.660285208686185
Validation loss: 2.566933553923556

Epoch: 6| Step: 2
Training loss: 1.9355376365587418
Validation loss: 2.535753971551147

Epoch: 6| Step: 3
Training loss: 2.1746821204095785
Validation loss: 2.5148791654200755

Epoch: 6| Step: 4
Training loss: 1.5860715912755536
Validation loss: 2.4887232929436514

Epoch: 6| Step: 5
Training loss: 1.8581717308268082
Validation loss: 2.462454603455628

Epoch: 6| Step: 6
Training loss: 1.7875373036153417
Validation loss: 2.4727201064909923

Epoch: 6| Step: 7
Training loss: 1.9930921108897213
Validation loss: 2.4782719606085166

Epoch: 6| Step: 8
Training loss: 2.1873722584074677
Validation loss: 2.507574593086967

Epoch: 6| Step: 9
Training loss: 2.0927360698658766
Validation loss: 2.51323107635299

Epoch: 6| Step: 10
Training loss: 2.4359704133477917
Validation loss: 2.497806989011526

Epoch: 6| Step: 11
Training loss: 2.091535051417349
Validation loss: 2.5182775485641358

Epoch: 6| Step: 12
Training loss: 1.798389692027359
Validation loss: 2.507078793149794

Epoch: 6| Step: 13
Training loss: 2.5401436249984206
Validation loss: 2.5249658165803472

Epoch: 206| Step: 0
Training loss: 1.922155220258078
Validation loss: 2.5066089038759736

Epoch: 6| Step: 1
Training loss: 1.8514714600920534
Validation loss: 2.5590957871735474

Epoch: 6| Step: 2
Training loss: 2.1997182492256964
Validation loss: 2.5495835243444374

Epoch: 6| Step: 3
Training loss: 2.1159487545608213
Validation loss: 2.5662153528293956

Epoch: 6| Step: 4
Training loss: 2.0631088745263577
Validation loss: 2.5924998953951537

Epoch: 6| Step: 5
Training loss: 2.099421548648156
Validation loss: 2.595180894153865

Epoch: 6| Step: 6
Training loss: 1.5866729083592932
Validation loss: 2.6057334209911622

Epoch: 6| Step: 7
Training loss: 2.307638367609371
Validation loss: 2.592795279201357

Epoch: 6| Step: 8
Training loss: 2.479161388060349
Validation loss: 2.596971048019437

Epoch: 6| Step: 9
Training loss: 2.169554534226702
Validation loss: 2.5608670894312797

Epoch: 6| Step: 10
Training loss: 1.9200763504424299
Validation loss: 2.5510413906836713

Epoch: 6| Step: 11
Training loss: 1.590096643377808
Validation loss: 2.5298822298678787

Epoch: 6| Step: 12
Training loss: 1.6923619625086106
Validation loss: 2.541477545996855

Epoch: 6| Step: 13
Training loss: 1.5911141083879732
Validation loss: 2.520959069101005

Epoch: 207| Step: 0
Training loss: 2.074075180228761
Validation loss: 2.5350761780774445

Epoch: 6| Step: 1
Training loss: 1.9192636007503083
Validation loss: 2.522428038838499

Epoch: 6| Step: 2
Training loss: 2.475311444656384
Validation loss: 2.496827080942255

Epoch: 6| Step: 3
Training loss: 1.7814313561991002
Validation loss: 2.444955675471703

Epoch: 6| Step: 4
Training loss: 2.0953680590063066
Validation loss: 2.4103191984984513

Epoch: 6| Step: 5
Training loss: 2.3237111282585823
Validation loss: 2.4287832578491666

Epoch: 6| Step: 6
Training loss: 1.7230384731325703
Validation loss: 2.44690270056241

Epoch: 6| Step: 7
Training loss: 2.3191082330658017
Validation loss: 2.479143712540794

Epoch: 6| Step: 8
Training loss: 1.7433372091003476
Validation loss: 2.5185122060398397

Epoch: 6| Step: 9
Training loss: 1.9117616487280105
Validation loss: 2.522439102674741

Epoch: 6| Step: 10
Training loss: 2.28308763040598
Validation loss: 2.5496274830043717

Epoch: 6| Step: 11
Training loss: 1.644202845169425
Validation loss: 2.5751763698073087

Epoch: 6| Step: 12
Training loss: 2.1618145997608154
Validation loss: 2.601819962634975

Epoch: 6| Step: 13
Training loss: 1.213404204260297
Validation loss: 2.6075543315175445

Epoch: 208| Step: 0
Training loss: 1.7495499440903237
Validation loss: 2.5980730438975574

Epoch: 6| Step: 1
Training loss: 1.9738300721328585
Validation loss: 2.6148777983721345

Epoch: 6| Step: 2
Training loss: 1.4828191533959414
Validation loss: 2.585868917567649

Epoch: 6| Step: 3
Training loss: 2.1134184336249975
Validation loss: 2.577780252615071

Epoch: 6| Step: 4
Training loss: 1.984421256419843
Validation loss: 2.554246064345703

Epoch: 6| Step: 5
Training loss: 2.1348880268545773
Validation loss: 2.5401053448565456

Epoch: 6| Step: 6
Training loss: 2.123470653642834
Validation loss: 2.558684566175789

Epoch: 6| Step: 7
Training loss: 2.4259646433921436
Validation loss: 2.532413657275402

Epoch: 6| Step: 8
Training loss: 1.970386914535265
Validation loss: 2.526601985538356

Epoch: 6| Step: 9
Training loss: 1.5323060734130136
Validation loss: 2.53129515106918

Epoch: 6| Step: 10
Training loss: 2.45753131865902
Validation loss: 2.4969692317324603

Epoch: 6| Step: 11
Training loss: 2.116278534193822
Validation loss: 2.480986234457671

Epoch: 6| Step: 12
Training loss: 1.8173565747367162
Validation loss: 2.4546692883933368

Epoch: 6| Step: 13
Training loss: 1.4836327554196496
Validation loss: 2.4551185046388833

Epoch: 209| Step: 0
Training loss: 1.6548183659575157
Validation loss: 2.4600367483493453

Epoch: 6| Step: 1
Training loss: 2.2155097619394555
Validation loss: 2.4586111860338256

Epoch: 6| Step: 2
Training loss: 1.890264681695136
Validation loss: 2.4504703558681267

Epoch: 6| Step: 3
Training loss: 1.1971662520572057
Validation loss: 2.464504373746853

Epoch: 6| Step: 4
Training loss: 2.214784113435984
Validation loss: 2.4892042781676595

Epoch: 6| Step: 5
Training loss: 1.9062525014391887
Validation loss: 2.5121743223110533

Epoch: 6| Step: 6
Training loss: 2.1924865562174687
Validation loss: 2.5333657137224086

Epoch: 6| Step: 7
Training loss: 1.5853258278179536
Validation loss: 2.5083202259172457

Epoch: 6| Step: 8
Training loss: 1.5822088448013127
Validation loss: 2.5391083774255563

Epoch: 6| Step: 9
Training loss: 2.2333177319261672
Validation loss: 2.5259505053859628

Epoch: 6| Step: 10
Training loss: 2.2120852237860276
Validation loss: 2.5461540900484643

Epoch: 6| Step: 11
Training loss: 2.2499745685411714
Validation loss: 2.538774920790849

Epoch: 6| Step: 12
Training loss: 2.037974801938179
Validation loss: 2.5412327560612016

Epoch: 6| Step: 13
Training loss: 1.6784728870628147
Validation loss: 2.5583931662758466

Epoch: 210| Step: 0
Training loss: 1.86871020424613
Validation loss: 2.5685354229144686

Epoch: 6| Step: 1
Training loss: 1.3766515956281546
Validation loss: 2.5605707827399997

Epoch: 6| Step: 2
Training loss: 2.3086807053870118
Validation loss: 2.576444601389303

Epoch: 6| Step: 3
Training loss: 1.8928284218760731
Validation loss: 2.5723661298960563

Epoch: 6| Step: 4
Training loss: 2.347054758311613
Validation loss: 2.560329683696801

Epoch: 6| Step: 5
Training loss: 2.0529287955770585
Validation loss: 2.5808126183753477

Epoch: 6| Step: 6
Training loss: 1.748481023142775
Validation loss: 2.5801757819852575

Epoch: 6| Step: 7
Training loss: 1.8551460708317054
Validation loss: 2.581783683993929

Epoch: 6| Step: 8
Training loss: 2.2576716289990464
Validation loss: 2.556121890115271

Epoch: 6| Step: 9
Training loss: 1.7388218414142373
Validation loss: 2.560486243113416

Epoch: 6| Step: 10
Training loss: 1.918572791052096
Validation loss: 2.5213089604995145

Epoch: 6| Step: 11
Training loss: 1.7211312877355383
Validation loss: 2.503528301715401

Epoch: 6| Step: 12
Training loss: 1.5667327007959617
Validation loss: 2.508465472557733

Epoch: 6| Step: 13
Training loss: 2.303233266534682
Validation loss: 2.505207667490215

Epoch: 211| Step: 0
Training loss: 2.1870275804745463
Validation loss: 2.5071078480255817

Epoch: 6| Step: 1
Training loss: 1.9290580804089188
Validation loss: 2.525583482212521

Epoch: 6| Step: 2
Training loss: 2.087172467696934
Validation loss: 2.528688640647604

Epoch: 6| Step: 3
Training loss: 1.6953566585010735
Validation loss: 2.5353991928049173

Epoch: 6| Step: 4
Training loss: 1.7232983834776565
Validation loss: 2.543218299090331

Epoch: 6| Step: 5
Training loss: 2.0239232485471184
Validation loss: 2.5355064612456792

Epoch: 6| Step: 6
Training loss: 2.2166419962416017
Validation loss: 2.5338840788698795

Epoch: 6| Step: 7
Training loss: 1.6967368756415189
Validation loss: 2.5337652544029385

Epoch: 6| Step: 8
Training loss: 0.8238204427535476
Validation loss: 2.5221855135770954

Epoch: 6| Step: 9
Training loss: 1.8636842687670845
Validation loss: 2.513485051759648

Epoch: 6| Step: 10
Training loss: 1.2848885208043441
Validation loss: 2.544764000396612

Epoch: 6| Step: 11
Training loss: 2.316590994918619
Validation loss: 2.5512939153017156

Epoch: 6| Step: 12
Training loss: 2.672375191610244
Validation loss: 2.5206094871425586

Epoch: 6| Step: 13
Training loss: 1.233286123832797
Validation loss: 2.5407434928970796

Epoch: 212| Step: 0
Training loss: 2.337991889156373
Validation loss: 2.504110567582013

Epoch: 6| Step: 1
Training loss: 1.961241983430135
Validation loss: 2.5245055091044915

Epoch: 6| Step: 2
Training loss: 1.4644753768585694
Validation loss: 2.5359723193877506

Epoch: 6| Step: 3
Training loss: 1.7120439270168504
Validation loss: 2.5586612229420163

Epoch: 6| Step: 4
Training loss: 1.6878275376801073
Validation loss: 2.550110242367961

Epoch: 6| Step: 5
Training loss: 2.0271079453649885
Validation loss: 2.554886093867598

Epoch: 6| Step: 6
Training loss: 1.984873070874536
Validation loss: 2.541592774577034

Epoch: 6| Step: 7
Training loss: 1.4598013800248013
Validation loss: 2.517356297695003

Epoch: 6| Step: 8
Training loss: 1.6709072841853763
Validation loss: 2.547241144355328

Epoch: 6| Step: 9
Training loss: 2.2801638591176445
Validation loss: 2.512053705023787

Epoch: 6| Step: 10
Training loss: 1.7097654465101575
Validation loss: 2.5124818741127175

Epoch: 6| Step: 11
Training loss: 1.9832675877527817
Validation loss: 2.516895521363807

Epoch: 6| Step: 12
Training loss: 2.030711645530325
Validation loss: 2.5228338646961497

Epoch: 6| Step: 13
Training loss: 2.1061384448837486
Validation loss: 2.5226163796510517

Epoch: 213| Step: 0
Training loss: 1.6710990459827253
Validation loss: 2.5157347818046643

Epoch: 6| Step: 1
Training loss: 2.1225978513342487
Validation loss: 2.5274286841188474

Epoch: 6| Step: 2
Training loss: 2.0404779775562614
Validation loss: 2.5187558005235187

Epoch: 6| Step: 3
Training loss: 1.9733503574633626
Validation loss: 2.5649723288736137

Epoch: 6| Step: 4
Training loss: 1.4576596293378028
Validation loss: 2.54232829570463

Epoch: 6| Step: 5
Training loss: 1.9663401796064726
Validation loss: 2.585693761292628

Epoch: 6| Step: 6
Training loss: 1.8099359594786608
Validation loss: 2.5720620881897087

Epoch: 6| Step: 7
Training loss: 2.239359810490454
Validation loss: 2.5697914909815216

Epoch: 6| Step: 8
Training loss: 1.9495372320916375
Validation loss: 2.5840780479480854

Epoch: 6| Step: 9
Training loss: 2.100988486932496
Validation loss: 2.552023208408834

Epoch: 6| Step: 10
Training loss: 1.7314875856285517
Validation loss: 2.5342029992893638

Epoch: 6| Step: 11
Training loss: 1.934736680835385
Validation loss: 2.5405973433977214

Epoch: 6| Step: 12
Training loss: 1.218872210904239
Validation loss: 2.5397677049471623

Epoch: 6| Step: 13
Training loss: 2.0827637720381893
Validation loss: 2.518076064426682

Epoch: 214| Step: 0
Training loss: 1.127129552508143
Validation loss: 2.511055603400586

Epoch: 6| Step: 1
Training loss: 1.4804962880333794
Validation loss: 2.5121659216499967

Epoch: 6| Step: 2
Training loss: 1.8893404924104062
Validation loss: 2.5109505769618674

Epoch: 6| Step: 3
Training loss: 1.8486262994924558
Validation loss: 2.522986564752858

Epoch: 6| Step: 4
Training loss: 2.379127128882722
Validation loss: 2.524318886432853

Epoch: 6| Step: 5
Training loss: 1.6531067297345925
Validation loss: 2.5329939054475545

Epoch: 6| Step: 6
Training loss: 2.069129922791253
Validation loss: 2.5134482811074705

Epoch: 6| Step: 7
Training loss: 2.292713365516068
Validation loss: 2.528303298028219

Epoch: 6| Step: 8
Training loss: 2.4144525799197534
Validation loss: 2.520749599117312

Epoch: 6| Step: 9
Training loss: 1.6309473071120506
Validation loss: 2.502062798672861

Epoch: 6| Step: 10
Training loss: 1.7391449229269265
Validation loss: 2.5023811721335556

Epoch: 6| Step: 11
Training loss: 1.7536156632407807
Validation loss: 2.504884018132426

Epoch: 6| Step: 12
Training loss: 1.6451808344224808
Validation loss: 2.495844427725025

Epoch: 6| Step: 13
Training loss: 1.7228945612690547
Validation loss: 2.5130611871464037

Epoch: 215| Step: 0
Training loss: 1.5219244852969982
Validation loss: 2.5065364224006794

Epoch: 6| Step: 1
Training loss: 2.014062556820936
Validation loss: 2.501100464080807

Epoch: 6| Step: 2
Training loss: 2.181409586230415
Validation loss: 2.5190743682911605

Epoch: 6| Step: 3
Training loss: 1.6080450099320247
Validation loss: 2.5594388153479435

Epoch: 6| Step: 4
Training loss: 1.9388650576934383
Validation loss: 2.5407476883654496

Epoch: 6| Step: 5
Training loss: 1.746636427964595
Validation loss: 2.5252138189225026

Epoch: 6| Step: 6
Training loss: 1.754458538005792
Validation loss: 2.535053525579938

Epoch: 6| Step: 7
Training loss: 2.1263043383562814
Validation loss: 2.512574194756118

Epoch: 6| Step: 8
Training loss: 2.0603891610629375
Validation loss: 2.5533778657834136

Epoch: 6| Step: 9
Training loss: 2.143722631874774
Validation loss: 2.5802477179981262

Epoch: 6| Step: 10
Training loss: 1.8712914985534974
Validation loss: 2.587348919865232

Epoch: 6| Step: 11
Training loss: 1.255222141089676
Validation loss: 2.6059496289248165

Epoch: 6| Step: 12
Training loss: 1.6317362911863575
Validation loss: 2.5908364770724996

Epoch: 6| Step: 13
Training loss: 1.8394729661792921
Validation loss: 2.5786051840280977

Epoch: 216| Step: 0
Training loss: 1.6066953702132818
Validation loss: 2.5880047657786065

Epoch: 6| Step: 1
Training loss: 1.5606844463033607
Validation loss: 2.595304072738666

Epoch: 6| Step: 2
Training loss: 1.76797625868379
Validation loss: 2.593454293944739

Epoch: 6| Step: 3
Training loss: 1.9277941724475234
Validation loss: 2.5626459587861286

Epoch: 6| Step: 4
Training loss: 2.4273529121316866
Validation loss: 2.5451145173656973

Epoch: 6| Step: 5
Training loss: 1.8740787150076048
Validation loss: 2.4930482645033196

Epoch: 6| Step: 6
Training loss: 1.5221025144111782
Validation loss: 2.481359554496639

Epoch: 6| Step: 7
Training loss: 1.5205713943584453
Validation loss: 2.4570546854600512

Epoch: 6| Step: 8
Training loss: 2.5934683405523318
Validation loss: 2.457911823552892

Epoch: 6| Step: 9
Training loss: 1.5824650675939198
Validation loss: 2.4332392611871185

Epoch: 6| Step: 10
Training loss: 1.8060863407529875
Validation loss: 2.4324267937175654

Epoch: 6| Step: 11
Training loss: 2.0478676289158737
Validation loss: 2.4205841043189005

Epoch: 6| Step: 12
Training loss: 2.2182786467718887
Validation loss: 2.448021848814931

Epoch: 6| Step: 13
Training loss: 1.2964254312428438
Validation loss: 2.4439444131495405

Epoch: 217| Step: 0
Training loss: 1.7003360275943191
Validation loss: 2.4715420267430397

Epoch: 6| Step: 1
Training loss: 1.8699975356427443
Validation loss: 2.505620209348647

Epoch: 6| Step: 2
Training loss: 1.1195934504648242
Validation loss: 2.5104236121871537

Epoch: 6| Step: 3
Training loss: 1.9352785727103214
Validation loss: 2.510570097806042

Epoch: 6| Step: 4
Training loss: 2.291542974659632
Validation loss: 2.5385562595884474

Epoch: 6| Step: 5
Training loss: 2.0240151306235137
Validation loss: 2.527347673547907

Epoch: 6| Step: 6
Training loss: 1.8149338527847594
Validation loss: 2.5184011283033065

Epoch: 6| Step: 7
Training loss: 1.78224602675587
Validation loss: 2.5276786091793535

Epoch: 6| Step: 8
Training loss: 1.6491551577163417
Validation loss: 2.5438855264932894

Epoch: 6| Step: 9
Training loss: 1.5797920109468722
Validation loss: 2.5694403534065575

Epoch: 6| Step: 10
Training loss: 2.1183826409380657
Validation loss: 2.5833842718743654

Epoch: 6| Step: 11
Training loss: 1.8814464377818965
Validation loss: 2.6070471028749136

Epoch: 6| Step: 12
Training loss: 1.872200465366765
Validation loss: 2.613540125243204

Epoch: 6| Step: 13
Training loss: 2.071541245219547
Validation loss: 2.581229446457621

Epoch: 218| Step: 0
Training loss: 2.211851975535915
Validation loss: 2.6055469774548325

Epoch: 6| Step: 1
Training loss: 1.6721836411273525
Validation loss: 2.605082842386036

Epoch: 6| Step: 2
Training loss: 2.047479089017663
Validation loss: 2.578725506852997

Epoch: 6| Step: 3
Training loss: 1.763219088775752
Validation loss: 2.5631838440546115

Epoch: 6| Step: 4
Training loss: 1.8845862426780338
Validation loss: 2.5446170662784913

Epoch: 6| Step: 5
Training loss: 2.066437401924331
Validation loss: 2.4909847645324645

Epoch: 6| Step: 6
Training loss: 1.4846722756907782
Validation loss: 2.510109072558573

Epoch: 6| Step: 7
Training loss: 1.7524726293061712
Validation loss: 2.4944720833718708

Epoch: 6| Step: 8
Training loss: 2.1868466082635356
Validation loss: 2.4819442870387216

Epoch: 6| Step: 9
Training loss: 1.8464971217100228
Validation loss: 2.4847455936616236

Epoch: 6| Step: 10
Training loss: 1.8700526771673731
Validation loss: 2.4785639594779343

Epoch: 6| Step: 11
Training loss: 1.7410593528468516
Validation loss: 2.4692294682073164

Epoch: 6| Step: 12
Training loss: 1.4966329295229415
Validation loss: 2.4944109173463698

Epoch: 6| Step: 13
Training loss: 1.180155629627939
Validation loss: 2.511772016257951

Epoch: 219| Step: 0
Training loss: 1.6417134625240901
Validation loss: 2.5153999103073774

Epoch: 6| Step: 1
Training loss: 1.6204117776736977
Validation loss: 2.5028237567075715

Epoch: 6| Step: 2
Training loss: 2.2424826610494497
Validation loss: 2.4799455184671575

Epoch: 6| Step: 3
Training loss: 1.8821132516949692
Validation loss: 2.4623025109022123

Epoch: 6| Step: 4
Training loss: 2.1896273486658386
Validation loss: 2.4501602099123256

Epoch: 6| Step: 5
Training loss: 1.4435617101181333
Validation loss: 2.422546817514199

Epoch: 6| Step: 6
Training loss: 1.7556475383198626
Validation loss: 2.4760614293705485

Epoch: 6| Step: 7
Training loss: 1.6827075156897484
Validation loss: 2.502671895631197

Epoch: 6| Step: 8
Training loss: 1.356238242946592
Validation loss: 2.482845068266701

Epoch: 6| Step: 9
Training loss: 1.4331472257545161
Validation loss: 2.5238407769900975

Epoch: 6| Step: 10
Training loss: 1.5425304707836076
Validation loss: 2.546408094021596

Epoch: 6| Step: 11
Training loss: 1.9736073231360587
Validation loss: 2.569162524882837

Epoch: 6| Step: 12
Training loss: 2.0651794137670856
Validation loss: 2.590020245949512

Epoch: 6| Step: 13
Training loss: 2.487568655935583
Validation loss: 2.5760805776416724

Epoch: 220| Step: 0
Training loss: 1.839344386145103
Validation loss: 2.5745038029645597

Epoch: 6| Step: 1
Training loss: 1.7875062262153227
Validation loss: 2.564659699208134

Epoch: 6| Step: 2
Training loss: 2.0858085678201146
Validation loss: 2.5569604002013606

Epoch: 6| Step: 3
Training loss: 1.658312610835405
Validation loss: 2.5204815759400323

Epoch: 6| Step: 4
Training loss: 1.428254623707412
Validation loss: 2.4983439682659294

Epoch: 6| Step: 5
Training loss: 1.6136917441776328
Validation loss: 2.4681393060256687

Epoch: 6| Step: 6
Training loss: 2.220723308917729
Validation loss: 2.432717810184882

Epoch: 6| Step: 7
Training loss: 1.7798591671640047
Validation loss: 2.4196248250463857

Epoch: 6| Step: 8
Training loss: 2.4045215690725783
Validation loss: 2.3944032118226546

Epoch: 6| Step: 9
Training loss: 1.729586753219989
Validation loss: 2.407096473123916

Epoch: 6| Step: 10
Training loss: 1.2317263035323045
Validation loss: 2.4051982774351393

Epoch: 6| Step: 11
Training loss: 1.740316301294752
Validation loss: 2.414083383376068

Epoch: 6| Step: 12
Training loss: 1.4053678500739963
Validation loss: 2.4463018466680175

Epoch: 6| Step: 13
Training loss: 2.1466218801924564
Validation loss: 2.487680913544728

Epoch: 221| Step: 0
Training loss: 1.8762879081012365
Validation loss: 2.523783749519063

Epoch: 6| Step: 1
Training loss: 1.8308311061414397
Validation loss: 2.567244724349934

Epoch: 6| Step: 2
Training loss: 1.2995682751434563
Validation loss: 2.5701258479663456

Epoch: 6| Step: 3
Training loss: 1.3736587832211615
Validation loss: 2.5825445285456445

Epoch: 6| Step: 4
Training loss: 1.8665200161661544
Validation loss: 2.5757536730874646

Epoch: 6| Step: 5
Training loss: 1.8719004124618395
Validation loss: 2.564135374012328

Epoch: 6| Step: 6
Training loss: 1.7673253337017616
Validation loss: 2.538628522640049

Epoch: 6| Step: 7
Training loss: 2.149086815942077
Validation loss: 2.524660273988482

Epoch: 6| Step: 8
Training loss: 1.990516949510313
Validation loss: 2.518810599369175

Epoch: 6| Step: 9
Training loss: 1.801030470675574
Validation loss: 2.5126696932598915

Epoch: 6| Step: 10
Training loss: 1.430405233359524
Validation loss: 2.5298593373130602

Epoch: 6| Step: 11
Training loss: 1.9637628391946123
Validation loss: 2.529625869254895

Epoch: 6| Step: 12
Training loss: 1.9368584093563181
Validation loss: 2.562987490548673

Epoch: 6| Step: 13
Training loss: 2.436187390716393
Validation loss: 2.514717670638115

Epoch: 222| Step: 0
Training loss: 1.6042283364203942
Validation loss: 2.4406016703884474

Epoch: 6| Step: 1
Training loss: 2.1527130308634987
Validation loss: 2.388062343978487

Epoch: 6| Step: 2
Training loss: 1.5397112103714072
Validation loss: 2.4005000497187323

Epoch: 6| Step: 3
Training loss: 2.048506923404062
Validation loss: 2.3962629060638774

Epoch: 6| Step: 4
Training loss: 1.9035378846030084
Validation loss: 2.4218515236861595

Epoch: 6| Step: 5
Training loss: 2.532342274791857
Validation loss: 2.4628276617992113

Epoch: 6| Step: 6
Training loss: 1.726571959042422
Validation loss: 2.4714194201790476

Epoch: 6| Step: 7
Training loss: 1.5657761369497427
Validation loss: 2.4846067521071866

Epoch: 6| Step: 8
Training loss: 1.6184812521521883
Validation loss: 2.5013417468340213

Epoch: 6| Step: 9
Training loss: 1.752805368589522
Validation loss: 2.535970146940503

Epoch: 6| Step: 10
Training loss: 1.4318065677243348
Validation loss: 2.5333000438631603

Epoch: 6| Step: 11
Training loss: 2.077637923674004
Validation loss: 2.5727430812081775

Epoch: 6| Step: 12
Training loss: 1.541613019405039
Validation loss: 2.5814426677069227

Epoch: 6| Step: 13
Training loss: 1.9746688396129377
Validation loss: 2.580639917358075

Epoch: 223| Step: 0
Training loss: 1.7310907008287721
Validation loss: 2.604575839148216

Epoch: 6| Step: 1
Training loss: 2.104472474893176
Validation loss: 2.65701010322653

Epoch: 6| Step: 2
Training loss: 2.200727091194961
Validation loss: 2.705742197726736

Epoch: 6| Step: 3
Training loss: 1.6914806041276425
Validation loss: 2.674478750013873

Epoch: 6| Step: 4
Training loss: 1.2175389165748784
Validation loss: 2.6026825552514565

Epoch: 6| Step: 5
Training loss: 2.3271332747093103
Validation loss: 2.5454946250301154

Epoch: 6| Step: 6
Training loss: 1.3309208780985236
Validation loss: 2.522723158133188

Epoch: 6| Step: 7
Training loss: 2.018629924403678
Validation loss: 2.4870935457678773

Epoch: 6| Step: 8
Training loss: 2.1044734945152985
Validation loss: 2.465266971043536

Epoch: 6| Step: 9
Training loss: 1.2812319498418911
Validation loss: 2.4650766238523807

Epoch: 6| Step: 10
Training loss: 1.9959912656390368
Validation loss: 2.4758653902788654

Epoch: 6| Step: 11
Training loss: 1.3415908322118295
Validation loss: 2.4676536700035436

Epoch: 6| Step: 12
Training loss: 1.903203061261467
Validation loss: 2.47426878522123

Epoch: 6| Step: 13
Training loss: 1.4792188536701467
Validation loss: 2.503779393016515

Epoch: 224| Step: 0
Training loss: 1.3333097346522194
Validation loss: 2.5241630697430066

Epoch: 6| Step: 1
Training loss: 1.9543710014807405
Validation loss: 2.5594959218096887

Epoch: 6| Step: 2
Training loss: 2.3928492552051805
Validation loss: 2.595389155472871

Epoch: 6| Step: 3
Training loss: 2.0683056587542055
Validation loss: 2.695167188277788

Epoch: 6| Step: 4
Training loss: 1.4951634315799023
Validation loss: 2.680931975002492

Epoch: 6| Step: 5
Training loss: 1.7322967724964764
Validation loss: 2.682638305350152

Epoch: 6| Step: 6
Training loss: 1.5024875042438575
Validation loss: 2.6612820960781893

Epoch: 6| Step: 7
Training loss: 1.9320059373973653
Validation loss: 2.6066552466687947

Epoch: 6| Step: 8
Training loss: 2.0131174502724147
Validation loss: 2.549794348680627

Epoch: 6| Step: 9
Training loss: 1.5928343592253889
Validation loss: 2.505392364632233

Epoch: 6| Step: 10
Training loss: 1.4302397114904266
Validation loss: 2.5149975432812446

Epoch: 6| Step: 11
Training loss: 1.7511825653097046
Validation loss: 2.4725425015079323

Epoch: 6| Step: 12
Training loss: 1.8554456207439995
Validation loss: 2.5000117168357034

Epoch: 6| Step: 13
Training loss: 2.1057854522144597
Validation loss: 2.4879771096136367

Epoch: 225| Step: 0
Training loss: 2.0018964359351763
Validation loss: 2.497886675091564

Epoch: 6| Step: 1
Training loss: 1.764340363776357
Validation loss: 2.5246428489806205

Epoch: 6| Step: 2
Training loss: 2.0417437117176043
Validation loss: 2.540297859997453

Epoch: 6| Step: 3
Training loss: 1.4069352917354143
Validation loss: 2.5479492019874

Epoch: 6| Step: 4
Training loss: 1.3356965946471397
Validation loss: 2.5630219510966605

Epoch: 6| Step: 5
Training loss: 1.4694963547387847
Validation loss: 2.5778623862956356

Epoch: 6| Step: 6
Training loss: 1.7296740082556612
Validation loss: 2.6365202234320546

Epoch: 6| Step: 7
Training loss: 1.8165118443139414
Validation loss: 2.645149720774674

Epoch: 6| Step: 8
Training loss: 2.1371904650981497
Validation loss: 2.6016122013266534

Epoch: 6| Step: 9
Training loss: 1.6907283843013998
Validation loss: 2.545143602383238

Epoch: 6| Step: 10
Training loss: 2.1134732594581895
Validation loss: 2.5262364665813

Epoch: 6| Step: 11
Training loss: 1.3541214372955475
Validation loss: 2.5076694068825947

Epoch: 6| Step: 12
Training loss: 2.148517288113595
Validation loss: 2.5052506242420054

Epoch: 6| Step: 13
Training loss: 1.453118765212599
Validation loss: 2.4799104937776675

Epoch: 226| Step: 0
Training loss: 1.9132470086967943
Validation loss: 2.509662366948407

Epoch: 6| Step: 1
Training loss: 1.439162246941762
Validation loss: 2.519427652431901

Epoch: 6| Step: 2
Training loss: 1.575268643795439
Validation loss: 2.518778520204467

Epoch: 6| Step: 3
Training loss: 1.9886929848276813
Validation loss: 2.5315179747547023

Epoch: 6| Step: 4
Training loss: 1.7172971653999698
Validation loss: 2.569401874169262

Epoch: 6| Step: 5
Training loss: 1.9600251647735063
Validation loss: 2.548539267732373

Epoch: 6| Step: 6
Training loss: 1.709788663977779
Validation loss: 2.546470750426142

Epoch: 6| Step: 7
Training loss: 1.7689957976994863
Validation loss: 2.5430822769091868

Epoch: 6| Step: 8
Training loss: 1.27830464562592
Validation loss: 2.5467733471980907

Epoch: 6| Step: 9
Training loss: 1.769785949027211
Validation loss: 2.54558934774835

Epoch: 6| Step: 10
Training loss: 1.6646914301002875
Validation loss: 2.5490319043215863

Epoch: 6| Step: 11
Training loss: 1.665181245074834
Validation loss: 2.57011392509976

Epoch: 6| Step: 12
Training loss: 1.6011612552347414
Validation loss: 2.585751066695671

Epoch: 6| Step: 13
Training loss: 2.205180838991172
Validation loss: 2.6148267540407737

Epoch: 227| Step: 0
Training loss: 1.8667395784693301
Validation loss: 2.596005577498988

Epoch: 6| Step: 1
Training loss: 1.6715003333563534
Validation loss: 2.555309339264619

Epoch: 6| Step: 2
Training loss: 1.6818190423508677
Validation loss: 2.5343161207385587

Epoch: 6| Step: 3
Training loss: 1.896648490239869
Validation loss: 2.5342007256810875

Epoch: 6| Step: 4
Training loss: 1.9046032155440904
Validation loss: 2.5108107778840973

Epoch: 6| Step: 5
Training loss: 1.587163366835403
Validation loss: 2.5181690331091104

Epoch: 6| Step: 6
Training loss: 1.704876060791491
Validation loss: 2.4930015661940397

Epoch: 6| Step: 7
Training loss: 1.4747086447339446
Validation loss: 2.4979956847255496

Epoch: 6| Step: 8
Training loss: 1.088741059118758
Validation loss: 2.4974814259623086

Epoch: 6| Step: 9
Training loss: 2.1582362660068584
Validation loss: 2.513576746045369

Epoch: 6| Step: 10
Training loss: 1.325032752010129
Validation loss: 2.5032131998306895

Epoch: 6| Step: 11
Training loss: 1.870482534074649
Validation loss: 2.4944913449894313

Epoch: 6| Step: 12
Training loss: 1.5819682544363631
Validation loss: 2.4771137818936952

Epoch: 6| Step: 13
Training loss: 1.7050981203634994
Validation loss: 2.501344381866444

Epoch: 228| Step: 0
Training loss: 1.5203829930302448
Validation loss: 2.4880176343439637

Epoch: 6| Step: 1
Training loss: 2.2984667601755384
Validation loss: 2.5298945784460742

Epoch: 6| Step: 2
Training loss: 2.1075623812781923
Validation loss: 2.52178103305227

Epoch: 6| Step: 3
Training loss: 1.438221625936872
Validation loss: 2.532153861614609

Epoch: 6| Step: 4
Training loss: 1.5208436451740877
Validation loss: 2.529966663816394

Epoch: 6| Step: 5
Training loss: 1.6743535004047463
Validation loss: 2.533023198459951

Epoch: 6| Step: 6
Training loss: 1.7752285957888687
Validation loss: 2.5291517841880884

Epoch: 6| Step: 7
Training loss: 1.7673472554034906
Validation loss: 2.519608149969051

Epoch: 6| Step: 8
Training loss: 0.9083436918688781
Validation loss: 2.526615627598122

Epoch: 6| Step: 9
Training loss: 0.9910685319502243
Validation loss: 2.5194947222521056

Epoch: 6| Step: 10
Training loss: 1.908293957144386
Validation loss: 2.5392849500217274

Epoch: 6| Step: 11
Training loss: 1.5999467095798796
Validation loss: 2.5236905234394045

Epoch: 6| Step: 12
Training loss: 1.5775327420955239
Validation loss: 2.5317140966792575

Epoch: 6| Step: 13
Training loss: 1.6522856717916201
Validation loss: 2.530497014225361

Epoch: 229| Step: 0
Training loss: 1.480096372611188
Validation loss: 2.540524866918163

Epoch: 6| Step: 1
Training loss: 2.1178973932744523
Validation loss: 2.5376026464384314

Epoch: 6| Step: 2
Training loss: 1.2271661912871492
Validation loss: 2.536614046970643

Epoch: 6| Step: 3
Training loss: 1.7209454472976367
Validation loss: 2.5267125414302543

Epoch: 6| Step: 4
Training loss: 1.5288091395769148
Validation loss: 2.502049244059504

Epoch: 6| Step: 5
Training loss: 1.5403525275959526
Validation loss: 2.492607349559896

Epoch: 6| Step: 6
Training loss: 1.5264785540486505
Validation loss: 2.5088074886797327

Epoch: 6| Step: 7
Training loss: 1.9055718638417658
Validation loss: 2.4972483165704333

Epoch: 6| Step: 8
Training loss: 1.7809088530866253
Validation loss: 2.49870657532854

Epoch: 6| Step: 9
Training loss: 1.711849857743173
Validation loss: 2.5107410500290444

Epoch: 6| Step: 10
Training loss: 1.5091023042808485
Validation loss: 2.5432594959394494

Epoch: 6| Step: 11
Training loss: 1.5961501056956107
Validation loss: 2.5583138246451465

Epoch: 6| Step: 12
Training loss: 1.4023824702365768
Validation loss: 2.5590642290327144

Epoch: 6| Step: 13
Training loss: 1.9679813398236383
Validation loss: 2.588870880161083

Epoch: 230| Step: 0
Training loss: 1.8554941918485994
Validation loss: 2.6032680971108553

Epoch: 6| Step: 1
Training loss: 1.648461942807897
Validation loss: 2.5736486290438383

Epoch: 6| Step: 2
Training loss: 1.3603609828253105
Validation loss: 2.5673518694811555

Epoch: 6| Step: 3
Training loss: 1.8861031169593976
Validation loss: 2.532636482765664

Epoch: 6| Step: 4
Training loss: 2.0655171837998023
Validation loss: 2.5419843291285984

Epoch: 6| Step: 5
Training loss: 1.975938298872135
Validation loss: 2.5022288405695767

Epoch: 6| Step: 6
Training loss: 1.7358982854305836
Validation loss: 2.4759612293756788

Epoch: 6| Step: 7
Training loss: 1.4518382620463774
Validation loss: 2.4935550553977253

Epoch: 6| Step: 8
Training loss: 1.488792511839896
Validation loss: 2.4859138428913794

Epoch: 6| Step: 9
Training loss: 1.7751923336004478
Validation loss: 2.4706239878872847

Epoch: 6| Step: 10
Training loss: 1.393481717140648
Validation loss: 2.486120108337248

Epoch: 6| Step: 11
Training loss: 0.8742111601171937
Validation loss: 2.4944295889960992

Epoch: 6| Step: 12
Training loss: 1.6458563823132235
Validation loss: 2.493317911313035

Epoch: 6| Step: 13
Training loss: 1.0602767909541235
Validation loss: 2.50511863666797

Epoch: 231| Step: 0
Training loss: 1.6144450795037553
Validation loss: 2.500006228613529

Epoch: 6| Step: 1
Training loss: 1.378967024460763
Validation loss: 2.5069791589756125

Epoch: 6| Step: 2
Training loss: 1.5421687502817916
Validation loss: 2.528330506932588

Epoch: 6| Step: 3
Training loss: 1.1688239497488884
Validation loss: 2.5450869177689786

Epoch: 6| Step: 4
Training loss: 1.627604964192513
Validation loss: 2.510446528796381

Epoch: 6| Step: 5
Training loss: 2.0744387407615497
Validation loss: 2.5136811599593747

Epoch: 6| Step: 6
Training loss: 1.912509210103117
Validation loss: 2.5424332288992986

Epoch: 6| Step: 7
Training loss: 1.6843238893585508
Validation loss: 2.5330577518971324

Epoch: 6| Step: 8
Training loss: 1.9513858223465264
Validation loss: 2.5413713255028982

Epoch: 6| Step: 9
Training loss: 1.2106997841112426
Validation loss: 2.549770424353106

Epoch: 6| Step: 10
Training loss: 1.345770359435927
Validation loss: 2.572097773217517

Epoch: 6| Step: 11
Training loss: 1.5161248395543718
Validation loss: 2.5693354386082734

Epoch: 6| Step: 12
Training loss: 1.6020544273569832
Validation loss: 2.5689775606094902

Epoch: 6| Step: 13
Training loss: 1.5576856831285657
Validation loss: 2.5530843479696936

Epoch: 232| Step: 0
Training loss: 1.6472960945334587
Validation loss: 2.518254510812406

Epoch: 6| Step: 1
Training loss: 1.5597960918382934
Validation loss: 2.4966848830395003

Epoch: 6| Step: 2
Training loss: 0.8984611508117504
Validation loss: 2.4850702585386095

Epoch: 6| Step: 3
Training loss: 2.1126708102720793
Validation loss: 2.5073863738806597

Epoch: 6| Step: 4
Training loss: 1.2740647345105305
Validation loss: 2.5080952232450717

Epoch: 6| Step: 5
Training loss: 1.3588369773673334
Validation loss: 2.497187454666492

Epoch: 6| Step: 6
Training loss: 1.378781364340101
Validation loss: 2.504866323524941

Epoch: 6| Step: 7
Training loss: 1.1940977119419407
Validation loss: 2.523534471883713

Epoch: 6| Step: 8
Training loss: 1.3668828134265458
Validation loss: 2.5012149022528742

Epoch: 6| Step: 9
Training loss: 1.8033167269371644
Validation loss: 2.5026041588130163

Epoch: 6| Step: 10
Training loss: 1.5545566062841596
Validation loss: 2.4955257226686247

Epoch: 6| Step: 11
Training loss: 1.7795986752871047
Validation loss: 2.5101226091820346

Epoch: 6| Step: 12
Training loss: 1.877046231472264
Validation loss: 2.4837565716170285

Epoch: 6| Step: 13
Training loss: 2.385925960450412
Validation loss: 2.467560095719081

Epoch: 233| Step: 0
Training loss: 1.7684392191003404
Validation loss: 2.4432094095113364

Epoch: 6| Step: 1
Training loss: 1.4002458611951432
Validation loss: 2.43409611337933

Epoch: 6| Step: 2
Training loss: 2.021679678065525
Validation loss: 2.4371936227969777

Epoch: 6| Step: 3
Training loss: 1.8018291345555095
Validation loss: 2.4666156257441547

Epoch: 6| Step: 4
Training loss: 1.7882812659987302
Validation loss: 2.485302953609193

Epoch: 6| Step: 5
Training loss: 1.3472227864520976
Validation loss: 2.495017584788216

Epoch: 6| Step: 6
Training loss: 1.2506990862038967
Validation loss: 2.5047554215756618

Epoch: 6| Step: 7
Training loss: 2.3043270540435596
Validation loss: 2.526978499643516

Epoch: 6| Step: 8
Training loss: 1.5467353526572243
Validation loss: 2.557192502497688

Epoch: 6| Step: 9
Training loss: 1.663523555395068
Validation loss: 2.5736935313600107

Epoch: 6| Step: 10
Training loss: 1.3233164636239716
Validation loss: 2.5700641532923094

Epoch: 6| Step: 11
Training loss: 1.5734270627718314
Validation loss: 2.5707588714598018

Epoch: 6| Step: 12
Training loss: 1.5461191199381534
Validation loss: 2.539447214468332

Epoch: 6| Step: 13
Training loss: 1.1322991095716193
Validation loss: 2.508320843749274

Epoch: 234| Step: 0
Training loss: 2.0749859728971005
Validation loss: 2.514373872755018

Epoch: 6| Step: 1
Training loss: 1.473190574950604
Validation loss: 2.489202126182999

Epoch: 6| Step: 2
Training loss: 1.3169750942867362
Validation loss: 2.5054392197964357

Epoch: 6| Step: 3
Training loss: 1.7215757549590625
Validation loss: 2.519369805134916

Epoch: 6| Step: 4
Training loss: 1.8352339025367486
Validation loss: 2.5210859269953256

Epoch: 6| Step: 5
Training loss: 1.3154912649580184
Validation loss: 2.50398009353578

Epoch: 6| Step: 6
Training loss: 1.548166833773587
Validation loss: 2.4656327851996034

Epoch: 6| Step: 7
Training loss: 1.5462117169882754
Validation loss: 2.450347689923616

Epoch: 6| Step: 8
Training loss: 1.715987256547431
Validation loss: 2.434106677160947

Epoch: 6| Step: 9
Training loss: 1.9453935108398563
Validation loss: 2.4907807762049687

Epoch: 6| Step: 10
Training loss: 1.80038441156005
Validation loss: 2.5187200259236353

Epoch: 6| Step: 11
Training loss: 1.7317570353558245
Validation loss: 2.501639991103131

Epoch: 6| Step: 12
Training loss: 1.6943605624561406
Validation loss: 2.5068814342042525

Epoch: 6| Step: 13
Training loss: 1.5971389343365625
Validation loss: 2.4978484442360878

Epoch: 235| Step: 0
Training loss: 1.9884186642869914
Validation loss: 2.456052133309359

Epoch: 6| Step: 1
Training loss: 1.9140877235463338
Validation loss: 2.433259949425353

Epoch: 6| Step: 2
Training loss: 1.7630203074271817
Validation loss: 2.3916222973784356

Epoch: 6| Step: 3
Training loss: 1.6960727375825173
Validation loss: 2.3906333226689

Epoch: 6| Step: 4
Training loss: 1.3458227096154058
Validation loss: 2.367271850971816

Epoch: 6| Step: 5
Training loss: 1.4941363166298178
Validation loss: 2.4023107740351803

Epoch: 6| Step: 6
Training loss: 1.5498996794444997
Validation loss: 2.413188411429388

Epoch: 6| Step: 7
Training loss: 1.1872681843209876
Validation loss: 2.4211514125391136

Epoch: 6| Step: 8
Training loss: 1.8819566103020793
Validation loss: 2.4127670822891325

Epoch: 6| Step: 9
Training loss: 1.2995154376373432
Validation loss: 2.4382167868688414

Epoch: 6| Step: 10
Training loss: 1.9269244223018467
Validation loss: 2.487065589887987

Epoch: 6| Step: 11
Training loss: 1.5148658030785005
Validation loss: 2.526667799553144

Epoch: 6| Step: 12
Training loss: 1.4166244986747056
Validation loss: 2.54774943195918

Epoch: 6| Step: 13
Training loss: 1.3945349685234694
Validation loss: 2.5811495925811987

Epoch: 236| Step: 0
Training loss: 1.5009409814016268
Validation loss: 2.5704075987420514

Epoch: 6| Step: 1
Training loss: 1.1754123958296852
Validation loss: 2.563255555829287

Epoch: 6| Step: 2
Training loss: 1.7761124925856948
Validation loss: 2.5490963789149

Epoch: 6| Step: 3
Training loss: 1.6473223634156733
Validation loss: 2.490382740958301

Epoch: 6| Step: 4
Training loss: 1.878938099676456
Validation loss: 2.4443815329812937

Epoch: 6| Step: 5
Training loss: 1.552094256812791
Validation loss: 2.4270059473857457

Epoch: 6| Step: 6
Training loss: 1.4787337874155002
Validation loss: 2.3976377122561

Epoch: 6| Step: 7
Training loss: 1.3847714788531065
Validation loss: 2.3752794290266737

Epoch: 6| Step: 8
Training loss: 2.0343583019878033
Validation loss: 2.3628490845083134

Epoch: 6| Step: 9
Training loss: 1.6262283084487095
Validation loss: 2.367124834114176

Epoch: 6| Step: 10
Training loss: 1.5788534013075548
Validation loss: 2.368932725512096

Epoch: 6| Step: 11
Training loss: 1.753886675141322
Validation loss: 2.3676436916154446

Epoch: 6| Step: 12
Training loss: 1.5419866212692444
Validation loss: 2.385188964029535

Epoch: 6| Step: 13
Training loss: 1.1021378549936083
Validation loss: 2.4175236614183384

Epoch: 237| Step: 0
Training loss: 1.7769479164085773
Validation loss: 2.4565571485820015

Epoch: 6| Step: 1
Training loss: 1.7102125887872641
Validation loss: 2.4954632859905903

Epoch: 6| Step: 2
Training loss: 1.3441550952738888
Validation loss: 2.508210533024302

Epoch: 6| Step: 3
Training loss: 1.125723341353192
Validation loss: 2.5248184847133923

Epoch: 6| Step: 4
Training loss: 1.324741586641547
Validation loss: 2.541579002093721

Epoch: 6| Step: 5
Training loss: 2.0185003545542046
Validation loss: 2.56470667260556

Epoch: 6| Step: 6
Training loss: 1.7057623085898461
Validation loss: 2.594645490275243

Epoch: 6| Step: 7
Training loss: 1.2437700471268816
Validation loss: 2.577041598209114

Epoch: 6| Step: 8
Training loss: 1.827416763706226
Validation loss: 2.5528172361695445

Epoch: 6| Step: 9
Training loss: 1.529004844952249
Validation loss: 2.5155366843737452

Epoch: 6| Step: 10
Training loss: 1.4613959261275575
Validation loss: 2.5131206210612143

Epoch: 6| Step: 11
Training loss: 1.2940307128362718
Validation loss: 2.4924013350373553

Epoch: 6| Step: 12
Training loss: 1.5577950402967786
Validation loss: 2.4610892862836664

Epoch: 6| Step: 13
Training loss: 0.990712308195095
Validation loss: 2.4379679880332144

Epoch: 238| Step: 0
Training loss: 2.040287979593286
Validation loss: 2.429239249198222

Epoch: 6| Step: 1
Training loss: 1.4333818575311714
Validation loss: 2.434188756076817

Epoch: 6| Step: 2
Training loss: 1.4360138218036527
Validation loss: 2.4450251026980006

Epoch: 6| Step: 3
Training loss: 1.52212608819675
Validation loss: 2.433520560226578

Epoch: 6| Step: 4
Training loss: 1.23650437194076
Validation loss: 2.4647896526398747

Epoch: 6| Step: 5
Training loss: 1.4226984008376806
Validation loss: 2.4554829741848527

Epoch: 6| Step: 6
Training loss: 1.6555928060037535
Validation loss: 2.4560386065971076

Epoch: 6| Step: 7
Training loss: 1.568657757604234
Validation loss: 2.4810702859872555

Epoch: 6| Step: 8
Training loss: 1.5266808049131724
Validation loss: 2.484583963459974

Epoch: 6| Step: 9
Training loss: 1.4850336320196154
Validation loss: 2.5205437875212744

Epoch: 6| Step: 10
Training loss: 1.5090102740343132
Validation loss: 2.5126484661289004

Epoch: 6| Step: 11
Training loss: 1.8060450216492387
Validation loss: 2.5087362234120327

Epoch: 6| Step: 12
Training loss: 1.2587306302804915
Validation loss: 2.5264011571689258

Epoch: 6| Step: 13
Training loss: 1.35008745793221
Validation loss: 2.508046290572752

Epoch: 239| Step: 0
Training loss: 1.1425880888153963
Validation loss: 2.472782687175908

Epoch: 6| Step: 1
Training loss: 1.5415745097616036
Validation loss: 2.486722820574103

Epoch: 6| Step: 2
Training loss: 1.2752781302829364
Validation loss: 2.4706697135448596

Epoch: 6| Step: 3
Training loss: 1.4977446926470537
Validation loss: 2.489536759334804

Epoch: 6| Step: 4
Training loss: 1.2932445773577534
Validation loss: 2.458915835057415

Epoch: 6| Step: 5
Training loss: 1.4436649313961556
Validation loss: 2.479137489420839

Epoch: 6| Step: 6
Training loss: 1.7388036050219007
Validation loss: 2.460210037595639

Epoch: 6| Step: 7
Training loss: 1.0924155132351534
Validation loss: 2.474987855087816

Epoch: 6| Step: 8
Training loss: 1.9515153279036075
Validation loss: 2.4793541178089695

Epoch: 6| Step: 9
Training loss: 1.2013562564913816
Validation loss: 2.505678303479304

Epoch: 6| Step: 10
Training loss: 1.4836380584833764
Validation loss: 2.511955493886224

Epoch: 6| Step: 11
Training loss: 1.7288551816021598
Validation loss: 2.5096157969799315

Epoch: 6| Step: 12
Training loss: 1.8658561269444915
Validation loss: 2.532181265038492

Epoch: 6| Step: 13
Training loss: 1.4999898274394647
Validation loss: 2.546561668735855

Epoch: 240| Step: 0
Training loss: 1.4797670820319764
Validation loss: 2.500484704641855

Epoch: 6| Step: 1
Training loss: 1.4686676976296547
Validation loss: 2.4915120551952783

Epoch: 6| Step: 2
Training loss: 1.1214918964788814
Validation loss: 2.452106774234711

Epoch: 6| Step: 3
Training loss: 1.2449878341202953
Validation loss: 2.4644951947787264

Epoch: 6| Step: 4
Training loss: 1.7270497458780822
Validation loss: 2.4582165394342717

Epoch: 6| Step: 5
Training loss: 1.7085146536395437
Validation loss: 2.4695017804342694

Epoch: 6| Step: 6
Training loss: 0.9641238163718603
Validation loss: 2.4567048143404904

Epoch: 6| Step: 7
Training loss: 1.710196556707223
Validation loss: 2.4806546142334325

Epoch: 6| Step: 8
Training loss: 1.6083241707865308
Validation loss: 2.462544429276848

Epoch: 6| Step: 9
Training loss: 1.7456625591625765
Validation loss: 2.4607750009020477

Epoch: 6| Step: 10
Training loss: 1.5082749364237258
Validation loss: 2.496214938206339

Epoch: 6| Step: 11
Training loss: 1.1772566754922862
Validation loss: 2.5171718306639446

Epoch: 6| Step: 12
Training loss: 1.1875091351609461
Validation loss: 2.5401060866665635

Epoch: 6| Step: 13
Training loss: 2.1370898383057617
Validation loss: 2.5737545585754313

Epoch: 241| Step: 0
Training loss: 1.5205562635283905
Validation loss: 2.545443784666762

Epoch: 6| Step: 1
Training loss: 0.9527631917163852
Validation loss: 2.553964729444983

Epoch: 6| Step: 2
Training loss: 1.559233646445902
Validation loss: 2.4930033740062227

Epoch: 6| Step: 3
Training loss: 1.3083831162103017
Validation loss: 2.4898763175208547

Epoch: 6| Step: 4
Training loss: 1.6438980151933664
Validation loss: 2.4661385174338584

Epoch: 6| Step: 5
Training loss: 1.4035649414910982
Validation loss: 2.452611879611669

Epoch: 6| Step: 6
Training loss: 1.3740578805040273
Validation loss: 2.45728559850375

Epoch: 6| Step: 7
Training loss: 1.7488907977256283
Validation loss: 2.451950643865761

Epoch: 6| Step: 8
Training loss: 1.29464216936967
Validation loss: 2.475576110964026

Epoch: 6| Step: 9
Training loss: 1.1852264222586157
Validation loss: 2.4921504274554787

Epoch: 6| Step: 10
Training loss: 1.6942532653867188
Validation loss: 2.5230808481601548

Epoch: 6| Step: 11
Training loss: 1.9725096393151447
Validation loss: 2.5312722935739917

Epoch: 6| Step: 12
Training loss: 1.22844100264596
Validation loss: 2.5301944948017567

Epoch: 6| Step: 13
Training loss: 1.1876743590192975
Validation loss: 2.5481775353933953

Epoch: 242| Step: 0
Training loss: 1.762409624528687
Validation loss: 2.531226855473131

Epoch: 6| Step: 1
Training loss: 1.1603669768309506
Validation loss: 2.494004063187318

Epoch: 6| Step: 2
Training loss: 2.4092384705409655
Validation loss: 2.463914385966399

Epoch: 6| Step: 3
Training loss: 1.5352362303732079
Validation loss: 2.4675309117930535

Epoch: 6| Step: 4
Training loss: 0.8461200488116551
Validation loss: 2.4616800407143953

Epoch: 6| Step: 5
Training loss: 1.51509438891079
Validation loss: 2.4399582840728904

Epoch: 6| Step: 6
Training loss: 1.7103156087419502
Validation loss: 2.456802809071298

Epoch: 6| Step: 7
Training loss: 1.573323110989051
Validation loss: 2.438268060366587

Epoch: 6| Step: 8
Training loss: 1.5071717318904936
Validation loss: 2.4390843314284374

Epoch: 6| Step: 9
Training loss: 1.1309162975473055
Validation loss: 2.433452708445483

Epoch: 6| Step: 10
Training loss: 1.2667233916597926
Validation loss: 2.456519406827914

Epoch: 6| Step: 11
Training loss: 1.2013004885412855
Validation loss: 2.4683045400360517

Epoch: 6| Step: 12
Training loss: 1.5626736353717736
Validation loss: 2.4789880957283854

Epoch: 6| Step: 13
Training loss: 0.784995750610124
Validation loss: 2.5026327298886932

Epoch: 243| Step: 0
Training loss: 1.464026790415462
Validation loss: 2.5335718907476963

Epoch: 6| Step: 1
Training loss: 1.406722603961801
Validation loss: 2.563308620250808

Epoch: 6| Step: 2
Training loss: 1.5836300153677723
Validation loss: 2.547914171333779

Epoch: 6| Step: 3
Training loss: 1.511837976766414
Validation loss: 2.5496695676986865

Epoch: 6| Step: 4
Training loss: 1.6853523716806929
Validation loss: 2.5232672779178857

Epoch: 6| Step: 5
Training loss: 1.478821575402804
Validation loss: 2.5231645327827135

Epoch: 6| Step: 6
Training loss: 1.0662829429125806
Validation loss: 2.5314928194327115

Epoch: 6| Step: 7
Training loss: 1.6491372309225194
Validation loss: 2.506449090627989

Epoch: 6| Step: 8
Training loss: 1.7416541818539384
Validation loss: 2.4931802535541623

Epoch: 6| Step: 9
Training loss: 1.3060239696698188
Validation loss: 2.4713077019317318

Epoch: 6| Step: 10
Training loss: 1.1274927391106035
Validation loss: 2.4596201089294407

Epoch: 6| Step: 11
Training loss: 1.229807551920768
Validation loss: 2.475559876227454

Epoch: 6| Step: 12
Training loss: 1.687621218248259
Validation loss: 2.4535886944040075

Epoch: 6| Step: 13
Training loss: 0.9922075645040003
Validation loss: 2.4803610062172776

Epoch: 244| Step: 0
Training loss: 1.9926301352244082
Validation loss: 2.5026319247278566

Epoch: 6| Step: 1
Training loss: 1.3619116869147636
Validation loss: 2.5145898940426616

Epoch: 6| Step: 2
Training loss: 2.072745911995037
Validation loss: 2.5249095531790653

Epoch: 6| Step: 3
Training loss: 1.5813385377002738
Validation loss: 2.5184664644303814

Epoch: 6| Step: 4
Training loss: 1.4925626912201344
Validation loss: 2.4915101145953478

Epoch: 6| Step: 5
Training loss: 1.317371320285539
Validation loss: 2.4725269819795774

Epoch: 6| Step: 6
Training loss: 1.0523189369000712
Validation loss: 2.4807696752191752

Epoch: 6| Step: 7
Training loss: 1.0585293908631475
Validation loss: 2.4633625906076677

Epoch: 6| Step: 8
Training loss: 1.3739756756840789
Validation loss: 2.4583078247159573

Epoch: 6| Step: 9
Training loss: 1.1132892809126453
Validation loss: 2.4455558359350027

Epoch: 6| Step: 10
Training loss: 1.026574430585073
Validation loss: 2.4629455801245133

Epoch: 6| Step: 11
Training loss: 1.1234179074591097
Validation loss: 2.423873058109944

Epoch: 6| Step: 12
Training loss: 1.2348599507387619
Validation loss: 2.408863620800477

Epoch: 6| Step: 13
Training loss: 1.7990446177871577
Validation loss: 2.4281724671432188

Epoch: 245| Step: 0
Training loss: 1.6093895920767858
Validation loss: 2.4153952899972526

Epoch: 6| Step: 1
Training loss: 1.2360597050915811
Validation loss: 2.4160900877936267

Epoch: 6| Step: 2
Training loss: 1.2719385885702883
Validation loss: 2.4090410390980304

Epoch: 6| Step: 3
Training loss: 1.486874213136302
Validation loss: 2.447564792063075

Epoch: 6| Step: 4
Training loss: 0.8961908528963367
Validation loss: 2.484204372666622

Epoch: 6| Step: 5
Training loss: 1.283572766439558
Validation loss: 2.4854568454955164

Epoch: 6| Step: 6
Training loss: 1.8843583215383441
Validation loss: 2.5111010777608804

Epoch: 6| Step: 7
Training loss: 1.4838376327384377
Validation loss: 2.4736649050484782

Epoch: 6| Step: 8
Training loss: 1.0076806625364214
Validation loss: 2.4812830850380148

Epoch: 6| Step: 9
Training loss: 1.7801537068041717
Validation loss: 2.4490892021735875

Epoch: 6| Step: 10
Training loss: 1.7044673844000777
Validation loss: 2.4420553341625695

Epoch: 6| Step: 11
Training loss: 1.6204368639225368
Validation loss: 2.4334955907551574

Epoch: 6| Step: 12
Training loss: 0.972294721095228
Validation loss: 2.4306873482299003

Epoch: 6| Step: 13
Training loss: 0.9085997013018497
Validation loss: 2.4262701340506294

Epoch: 246| Step: 0
Training loss: 1.3461022304238996
Validation loss: 2.4429090416414856

Epoch: 6| Step: 1
Training loss: 1.2497316072334925
Validation loss: 2.4572025988412958

Epoch: 6| Step: 2
Training loss: 1.9532106914795595
Validation loss: 2.469578558379751

Epoch: 6| Step: 3
Training loss: 1.6077950138368244
Validation loss: 2.466704165127368

Epoch: 6| Step: 4
Training loss: 1.4328034012733357
Validation loss: 2.488243542287275

Epoch: 6| Step: 5
Training loss: 1.3051005183710442
Validation loss: 2.5064398647948467

Epoch: 6| Step: 6
Training loss: 0.8695234848457184
Validation loss: 2.518591452816524

Epoch: 6| Step: 7
Training loss: 1.4055473267503251
Validation loss: 2.5521738451104374

Epoch: 6| Step: 8
Training loss: 1.3012528581248912
Validation loss: 2.5738201128663913

Epoch: 6| Step: 9
Training loss: 1.6084228217309544
Validation loss: 2.535659707941346

Epoch: 6| Step: 10
Training loss: 1.3562768291860938
Validation loss: 2.4899590877547744

Epoch: 6| Step: 11
Training loss: 1.323369251639771
Validation loss: 2.4690059198475103

Epoch: 6| Step: 12
Training loss: 0.9495787703094943
Validation loss: 2.424984559021718

Epoch: 6| Step: 13
Training loss: 1.8170406423252663
Validation loss: 2.4375746299860666

Epoch: 247| Step: 0
Training loss: 1.1986509090833384
Validation loss: 2.444560859895247

Epoch: 6| Step: 1
Training loss: 1.2932456834987633
Validation loss: 2.4360310998384858

Epoch: 6| Step: 2
Training loss: 1.5983970808510382
Validation loss: 2.4558449865986307

Epoch: 6| Step: 3
Training loss: 1.2318502754041107
Validation loss: 2.465088370445451

Epoch: 6| Step: 4
Training loss: 1.369822899446636
Validation loss: 2.493271418043676

Epoch: 6| Step: 5
Training loss: 1.1615345791592964
Validation loss: 2.4928604221986053

Epoch: 6| Step: 6
Training loss: 1.4294030578821828
Validation loss: 2.4917938871051493

Epoch: 6| Step: 7
Training loss: 1.170253190904752
Validation loss: 2.5229468293226724

Epoch: 6| Step: 8
Training loss: 1.54845917625922
Validation loss: 2.5010485372978435

Epoch: 6| Step: 9
Training loss: 1.4485678637786668
Validation loss: 2.5615712135109283

Epoch: 6| Step: 10
Training loss: 1.5511756991068135
Validation loss: 2.5645691356081173

Epoch: 6| Step: 11
Training loss: 1.1965916589554937
Validation loss: 2.588953235334212

Epoch: 6| Step: 12
Training loss: 2.0557183410292477
Validation loss: 2.57795403473934

Epoch: 6| Step: 13
Training loss: 1.115980443243038
Validation loss: 2.5276527563934237

Epoch: 248| Step: 0
Training loss: 1.407922978781694
Validation loss: 2.5226422759212466

Epoch: 6| Step: 1
Training loss: 1.3950150022076024
Validation loss: 2.5165748380051363

Epoch: 6| Step: 2
Training loss: 1.4258889353597795
Validation loss: 2.5100135736605442

Epoch: 6| Step: 3
Training loss: 1.9234419846656758
Validation loss: 2.4749284490918146

Epoch: 6| Step: 4
Training loss: 1.6054149906411403
Validation loss: 2.4571771511706144

Epoch: 6| Step: 5
Training loss: 0.9142738815163505
Validation loss: 2.4155857775744147

Epoch: 6| Step: 6
Training loss: 1.676409765789702
Validation loss: 2.3707181893245624

Epoch: 6| Step: 7
Training loss: 1.1469122690906757
Validation loss: 2.389032429532759

Epoch: 6| Step: 8
Training loss: 1.473123734238558
Validation loss: 2.3711972537475026

Epoch: 6| Step: 9
Training loss: 1.2597909850887328
Validation loss: 2.365649937707561

Epoch: 6| Step: 10
Training loss: 1.6702888308668884
Validation loss: 2.373118794871129

Epoch: 6| Step: 11
Training loss: 1.1351658021927975
Validation loss: 2.385400047052693

Epoch: 6| Step: 12
Training loss: 1.4585291958025883
Validation loss: 2.4085688312535205

Epoch: 6| Step: 13
Training loss: 0.9039942851012541
Validation loss: 2.4083515818720946

Epoch: 249| Step: 0
Training loss: 1.3587301632188544
Validation loss: 2.4558483792501846

Epoch: 6| Step: 1
Training loss: 1.9840698608319576
Validation loss: 2.5197323217062833

Epoch: 6| Step: 2
Training loss: 1.278752428054369
Validation loss: 2.5185235659867558

Epoch: 6| Step: 3
Training loss: 1.6033954830905919
Validation loss: 2.520448994217537

Epoch: 6| Step: 4
Training loss: 0.9771711970165763
Validation loss: 2.493261265342695

Epoch: 6| Step: 5
Training loss: 1.3544201051306979
Validation loss: 2.4757944913236343

Epoch: 6| Step: 6
Training loss: 1.51295038563729
Validation loss: 2.4421785971707104

Epoch: 6| Step: 7
Training loss: 0.9864043253555507
Validation loss: 2.4031887742224605

Epoch: 6| Step: 8
Training loss: 1.495532535639071
Validation loss: 2.400006370253979

Epoch: 6| Step: 9
Training loss: 1.1589217377011318
Validation loss: 2.4032301377271663

Epoch: 6| Step: 10
Training loss: 1.3773507051514073
Validation loss: 2.379206424843056

Epoch: 6| Step: 11
Training loss: 1.684940870136131
Validation loss: 2.3848329485366055

Epoch: 6| Step: 12
Training loss: 1.010034816727266
Validation loss: 2.389749335370614

Epoch: 6| Step: 13
Training loss: 1.0715471372395873
Validation loss: 2.3802194489839072

Epoch: 250| Step: 0
Training loss: 1.3194263802792048
Validation loss: 2.4106385231863343

Epoch: 6| Step: 1
Training loss: 1.5710037759581315
Validation loss: 2.4338284573555335

Epoch: 6| Step: 2
Training loss: 1.2171096522223612
Validation loss: 2.46543958280171

Epoch: 6| Step: 3
Training loss: 1.2800256415123399
Validation loss: 2.4613292501431694

Epoch: 6| Step: 4
Training loss: 1.2051311462707759
Validation loss: 2.5060961200056004

Epoch: 6| Step: 5
Training loss: 0.8326360805514667
Validation loss: 2.511730609158285

Epoch: 6| Step: 6
Training loss: 1.313515860384475
Validation loss: 2.4955820105986186

Epoch: 6| Step: 7
Training loss: 1.4113744825768142
Validation loss: 2.4677073887602474

Epoch: 6| Step: 8
Training loss: 1.331639833637516
Validation loss: 2.4715924880658715

Epoch: 6| Step: 9
Training loss: 1.31443027062691
Validation loss: 2.447447244584514

Epoch: 6| Step: 10
Training loss: 1.093397138079046
Validation loss: 2.446148618267721

Epoch: 6| Step: 11
Training loss: 1.5986566000015117
Validation loss: 2.4017926661610947

Epoch: 6| Step: 12
Training loss: 1.235919854849573
Validation loss: 2.39708650583685

Epoch: 6| Step: 13
Training loss: 2.276136965178706
Validation loss: 2.3867293161704417

Epoch: 251| Step: 0
Training loss: 1.0476009641620325
Validation loss: 2.3785877309217045

Epoch: 6| Step: 1
Training loss: 1.1419936551821368
Validation loss: 2.367181683253008

Epoch: 6| Step: 2
Training loss: 1.3167358348077993
Validation loss: 2.397396584197994

Epoch: 6| Step: 3
Training loss: 1.4187727401188142
Validation loss: 2.4130217459232686

Epoch: 6| Step: 4
Training loss: 1.418332980537296
Validation loss: 2.427651404122902

Epoch: 6| Step: 5
Training loss: 1.8401490300404446
Validation loss: 2.4454931916898803

Epoch: 6| Step: 6
Training loss: 1.2581336517718718
Validation loss: 2.4629511426023023

Epoch: 6| Step: 7
Training loss: 0.9726632972063667
Validation loss: 2.472768830027473

Epoch: 6| Step: 8
Training loss: 1.4686722430485368
Validation loss: 2.4999273771587185

Epoch: 6| Step: 9
Training loss: 1.607489657450341
Validation loss: 2.538644722643905

Epoch: 6| Step: 10
Training loss: 1.1005772723150455
Validation loss: 2.5494868765777086

Epoch: 6| Step: 11
Training loss: 1.3694489005486803
Validation loss: 2.5288387802140764

Epoch: 6| Step: 12
Training loss: 1.340445558503207
Validation loss: 2.5170988650434962

Epoch: 6| Step: 13
Training loss: 0.9668912899270076
Validation loss: 2.508594855905944

Epoch: 252| Step: 0
Training loss: 1.0578878378699335
Validation loss: 2.5161142221939956

Epoch: 6| Step: 1
Training loss: 1.5721380146437567
Validation loss: 2.4775490499144928

Epoch: 6| Step: 2
Training loss: 1.3513508007976338
Validation loss: 2.438104523526142

Epoch: 6| Step: 3
Training loss: 1.2162252831765445
Validation loss: 2.4288528412604418

Epoch: 6| Step: 4
Training loss: 1.520133715445007
Validation loss: 2.4247271602810434

Epoch: 6| Step: 5
Training loss: 1.1981041416030085
Validation loss: 2.4319819762019987

Epoch: 6| Step: 6
Training loss: 0.9920576416100457
Validation loss: 2.4088378040098326

Epoch: 6| Step: 7
Training loss: 1.4608867452852219
Validation loss: 2.4318720272939554

Epoch: 6| Step: 8
Training loss: 0.7954161510862182
Validation loss: 2.4289540610667815

Epoch: 6| Step: 9
Training loss: 1.4994280042418793
Validation loss: 2.4258875648610396

Epoch: 6| Step: 10
Training loss: 0.7811799590185301
Validation loss: 2.432151944480427

Epoch: 6| Step: 11
Training loss: 0.9237882835394255
Validation loss: 2.4505962931978713

Epoch: 6| Step: 12
Training loss: 1.8693768422772288
Validation loss: 2.4422854295261014

Epoch: 6| Step: 13
Training loss: 1.4997460627185426
Validation loss: 2.465308786262962

Epoch: 253| Step: 0
Training loss: 0.9296814092869357
Validation loss: 2.461355073591555

Epoch: 6| Step: 1
Training loss: 1.9364841628408298
Validation loss: 2.461865124133457

Epoch: 6| Step: 2
Training loss: 1.8156312663352627
Validation loss: 2.4554418341961366

Epoch: 6| Step: 3
Training loss: 1.125912561111319
Validation loss: 2.473498794716259

Epoch: 6| Step: 4
Training loss: 0.7540155440253645
Validation loss: 2.428365689117544

Epoch: 6| Step: 5
Training loss: 0.7442275269395464
Validation loss: 2.422939301411871

Epoch: 6| Step: 6
Training loss: 1.2011959414668565
Validation loss: 2.398287114630822

Epoch: 6| Step: 7
Training loss: 1.0124073998762948
Validation loss: 2.3715773868005856

Epoch: 6| Step: 8
Training loss: 1.1885314276764352
Validation loss: 2.3886863466509523

Epoch: 6| Step: 9
Training loss: 1.0790114145037553
Validation loss: 2.3894076394220813

Epoch: 6| Step: 10
Training loss: 1.496222826616145
Validation loss: 2.3848486399246625

Epoch: 6| Step: 11
Training loss: 1.3723514798239953
Validation loss: 2.39991501769654

Epoch: 6| Step: 12
Training loss: 1.4612857179216716
Validation loss: 2.43406539073495

Epoch: 6| Step: 13
Training loss: 1.2362227794246259
Validation loss: 2.4745254904472853

Epoch: 254| Step: 0
Training loss: 1.5127566222343942
Validation loss: 2.493899345588048

Epoch: 6| Step: 1
Training loss: 1.1064567329645598
Validation loss: 2.4982248669545406

Epoch: 6| Step: 2
Training loss: 1.6850271827248386
Validation loss: 2.52278456448561

Epoch: 6| Step: 3
Training loss: 0.7301635920757293
Validation loss: 2.5333601687337164

Epoch: 6| Step: 4
Training loss: 1.0313541475360297
Validation loss: 2.5330973418790905

Epoch: 6| Step: 5
Training loss: 0.8826403154557895
Validation loss: 2.5422688175543517

Epoch: 6| Step: 6
Training loss: 1.4629382137202809
Validation loss: 2.5207917499765125

Epoch: 6| Step: 7
Training loss: 1.6216898729807798
Validation loss: 2.5057595158546264

Epoch: 6| Step: 8
Training loss: 1.1416600377987915
Validation loss: 2.5100779249744294

Epoch: 6| Step: 9
Training loss: 1.3855638449753254
Validation loss: 2.4694871976518105

Epoch: 6| Step: 10
Training loss: 1.447085720726275
Validation loss: 2.471942831286681

Epoch: 6| Step: 11
Training loss: 1.2328053405321755
Validation loss: 2.424694936500185

Epoch: 6| Step: 12
Training loss: 0.8495814527110684
Validation loss: 2.4099244082198443

Epoch: 6| Step: 13
Training loss: 1.1626742488748008
Validation loss: 2.389862054619706

Epoch: 255| Step: 0
Training loss: 0.8885221921181164
Validation loss: 2.380817119972417

Epoch: 6| Step: 1
Training loss: 1.644068999575812
Validation loss: 2.3897264676554677

Epoch: 6| Step: 2
Training loss: 1.1588198996060175
Validation loss: 2.4019168704261187

Epoch: 6| Step: 3
Training loss: 1.3161901189038143
Validation loss: 2.433543868136262

Epoch: 6| Step: 4
Training loss: 1.4260264564670837
Validation loss: 2.4494926282629357

Epoch: 6| Step: 5
Training loss: 1.27403797432014
Validation loss: 2.4848246452238514

Epoch: 6| Step: 6
Training loss: 1.12689356919242
Validation loss: 2.4587567447782317

Epoch: 6| Step: 7
Training loss: 1.0751264586477027
Validation loss: 2.4502543239235632

Epoch: 6| Step: 8
Training loss: 1.2759276773830042
Validation loss: 2.4813446418250518

Epoch: 6| Step: 9
Training loss: 1.2507896789991106
Validation loss: 2.4986101476122173

Epoch: 6| Step: 10
Training loss: 1.4101539675200105
Validation loss: 2.478562214571067

Epoch: 6| Step: 11
Training loss: 1.1384728390247805
Validation loss: 2.4687060176596662

Epoch: 6| Step: 12
Training loss: 1.3407563418626571
Validation loss: 2.460167113453113

Epoch: 6| Step: 13
Training loss: 1.2576988121448702
Validation loss: 2.4467498015958182

Epoch: 256| Step: 0
Training loss: 1.1880750769451618
Validation loss: 2.4378490650309224

Epoch: 6| Step: 1
Training loss: 1.076313154912946
Validation loss: 2.422025992204969

Epoch: 6| Step: 2
Training loss: 1.4250089042786924
Validation loss: 2.406294666861747

Epoch: 6| Step: 3
Training loss: 0.8805476480791483
Validation loss: 2.390605211427371

Epoch: 6| Step: 4
Training loss: 1.423584968306179
Validation loss: 2.397087887607069

Epoch: 6| Step: 5
Training loss: 1.5892971139440828
Validation loss: 2.4070135811315136

Epoch: 6| Step: 6
Training loss: 1.5061930127265575
Validation loss: 2.436574803973493

Epoch: 6| Step: 7
Training loss: 1.007348241995714
Validation loss: 2.437481231448915

Epoch: 6| Step: 8
Training loss: 1.0000187156833211
Validation loss: 2.4635582660808786

Epoch: 6| Step: 9
Training loss: 1.2624525646702938
Validation loss: 2.482100496247976

Epoch: 6| Step: 10
Training loss: 1.1268881741058858
Validation loss: 2.487063602525394

Epoch: 6| Step: 11
Training loss: 1.2785872726341623
Validation loss: 2.4598613197883794

Epoch: 6| Step: 12
Training loss: 1.4422575134938602
Validation loss: 2.4447683812554

Epoch: 6| Step: 13
Training loss: 0.7851617158158631
Validation loss: 2.3983828689474267

Epoch: 257| Step: 0
Training loss: 1.3727196945266031
Validation loss: 2.4267647646955464

Epoch: 6| Step: 1
Training loss: 1.3505535439049514
Validation loss: 2.4238352167509114

Epoch: 6| Step: 2
Training loss: 1.0214659942665405
Validation loss: 2.4109614081355

Epoch: 6| Step: 3
Training loss: 0.9353093938906579
Validation loss: 2.439775871104473

Epoch: 6| Step: 4
Training loss: 1.324178059270659
Validation loss: 2.43037296466803

Epoch: 6| Step: 5
Training loss: 1.352187612986268
Validation loss: 2.4286755866690726

Epoch: 6| Step: 6
Training loss: 1.071583515271545
Validation loss: 2.4157395060619224

Epoch: 6| Step: 7
Training loss: 1.0774863742754557
Validation loss: 2.411854488541101

Epoch: 6| Step: 8
Training loss: 1.0835284949843518
Validation loss: 2.4270621776825085

Epoch: 6| Step: 9
Training loss: 1.1589407156296025
Validation loss: 2.436433798200455

Epoch: 6| Step: 10
Training loss: 1.5207371964399325
Validation loss: 2.440680488984089

Epoch: 6| Step: 11
Training loss: 0.7715521674007023
Validation loss: 2.464218102628257

Epoch: 6| Step: 12
Training loss: 1.7128944527421242
Validation loss: 2.467942077226453

Epoch: 6| Step: 13
Training loss: 0.8029487490682194
Validation loss: 2.4718419436949066

Epoch: 258| Step: 0
Training loss: 1.299529518675766
Validation loss: 2.4662365136181825

Epoch: 6| Step: 1
Training loss: 1.7932380025311543
Validation loss: 2.4298422248817384

Epoch: 6| Step: 2
Training loss: 0.4793353785785994
Validation loss: 2.4547029218110086

Epoch: 6| Step: 3
Training loss: 1.2244539055705876
Validation loss: 2.4214226360122204

Epoch: 6| Step: 4
Training loss: 1.2402164007371248
Validation loss: 2.4307567474101184

Epoch: 6| Step: 5
Training loss: 1.2244750318804913
Validation loss: 2.412154961090014

Epoch: 6| Step: 6
Training loss: 1.2370413460077994
Validation loss: 2.3920564611754527

Epoch: 6| Step: 7
Training loss: 1.5375029897273078
Validation loss: 2.3938024611887725

Epoch: 6| Step: 8
Training loss: 0.8546600351331746
Validation loss: 2.385648363031516

Epoch: 6| Step: 9
Training loss: 1.3177021111905602
Validation loss: 2.3964738828629937

Epoch: 6| Step: 10
Training loss: 1.2235812749459332
Validation loss: 2.392494032426072

Epoch: 6| Step: 11
Training loss: 1.1075042209587864
Validation loss: 2.4067364368677104

Epoch: 6| Step: 12
Training loss: 1.0187660356441415
Validation loss: 2.4144252997363775

Epoch: 6| Step: 13
Training loss: 0.7480642451169469
Validation loss: 2.438915578913344

Epoch: 259| Step: 0
Training loss: 1.0495271253710636
Validation loss: 2.432567504818613

Epoch: 6| Step: 1
Training loss: 1.2792248421693193
Validation loss: 2.4714227520328413

Epoch: 6| Step: 2
Training loss: 1.1076970372470936
Validation loss: 2.4715372418413177

Epoch: 6| Step: 3
Training loss: 0.7103314174242584
Validation loss: 2.4552070315665238

Epoch: 6| Step: 4
Training loss: 0.9992667728721866
Validation loss: 2.472170346073631

Epoch: 6| Step: 5
Training loss: 1.26136089718308
Validation loss: 2.505844940882368

Epoch: 6| Step: 6
Training loss: 1.6518313648293104
Validation loss: 2.4863503274706935

Epoch: 6| Step: 7
Training loss: 1.6075905842272067
Validation loss: 2.5072433719852247

Epoch: 6| Step: 8
Training loss: 1.231177328840679
Validation loss: 2.494228931971191

Epoch: 6| Step: 9
Training loss: 0.9672706753120052
Validation loss: 2.482356331682736

Epoch: 6| Step: 10
Training loss: 1.3516454064844838
Validation loss: 2.4466978450787074

Epoch: 6| Step: 11
Training loss: 0.9452438960126739
Validation loss: 2.443726586586718

Epoch: 6| Step: 12
Training loss: 0.9332127771401346
Validation loss: 2.4230301107282783

Epoch: 6| Step: 13
Training loss: 1.0568624041600232
Validation loss: 2.4259651881472384

Epoch: 260| Step: 0
Training loss: 0.9435804909565576
Validation loss: 2.4395068762466554

Epoch: 6| Step: 1
Training loss: 0.9071698617616681
Validation loss: 2.4144217299567745

Epoch: 6| Step: 2
Training loss: 0.9964569626360816
Validation loss: 2.422074080643036

Epoch: 6| Step: 3
Training loss: 0.8423015028984414
Validation loss: 2.4009621504487995

Epoch: 6| Step: 4
Training loss: 1.7994345306587158
Validation loss: 2.40610838378657

Epoch: 6| Step: 5
Training loss: 1.3910375261818841
Validation loss: 2.442913496430587

Epoch: 6| Step: 6
Training loss: 1.1962619077753516
Validation loss: 2.4648834829081023

Epoch: 6| Step: 7
Training loss: 0.7356920809046974
Validation loss: 2.4466536612107883

Epoch: 6| Step: 8
Training loss: 1.0608063269806236
Validation loss: 2.4734930165395057

Epoch: 6| Step: 9
Training loss: 1.1131940841013188
Validation loss: 2.4729502839938733

Epoch: 6| Step: 10
Training loss: 1.1979658807790061
Validation loss: 2.4425331772011716

Epoch: 6| Step: 11
Training loss: 1.53737412224284
Validation loss: 2.4477903781658825

Epoch: 6| Step: 12
Training loss: 1.0904916457704934
Validation loss: 2.4472674980241846

Epoch: 6| Step: 13
Training loss: 1.0778612560593515
Validation loss: 2.418389745344519

Epoch: 261| Step: 0
Training loss: 1.047423432585801
Validation loss: 2.4298540816693417

Epoch: 6| Step: 1
Training loss: 1.6070366324787566
Validation loss: 2.430497957202458

Epoch: 6| Step: 2
Training loss: 1.2940022466837557
Validation loss: 2.436635119793665

Epoch: 6| Step: 3
Training loss: 1.084417198305511
Validation loss: 2.4461361492819975

Epoch: 6| Step: 4
Training loss: 1.0675854433871745
Validation loss: 2.435563103831412

Epoch: 6| Step: 5
Training loss: 1.3382452501753945
Validation loss: 2.4351237335777105

Epoch: 6| Step: 6
Training loss: 1.0789871086078797
Validation loss: 2.4441462667342146

Epoch: 6| Step: 7
Training loss: 1.0501024400603336
Validation loss: 2.423263379434214

Epoch: 6| Step: 8
Training loss: 0.9442883768501693
Validation loss: 2.4146021347236193

Epoch: 6| Step: 9
Training loss: 1.1889194237025187
Validation loss: 2.4225469529691632

Epoch: 6| Step: 10
Training loss: 1.1301459135524003
Validation loss: 2.4006247191903882

Epoch: 6| Step: 11
Training loss: 1.144352817622503
Validation loss: 2.370681347597924

Epoch: 6| Step: 12
Training loss: 1.3814743377643643
Validation loss: 2.3444070344925625

Epoch: 6| Step: 13
Training loss: 0.9309016401818386
Validation loss: 2.333870531098795

Epoch: 262| Step: 0
Training loss: 1.5851988928160266
Validation loss: 2.3322537014921183

Epoch: 6| Step: 1
Training loss: 1.1512616782988807
Validation loss: 2.340015335032759

Epoch: 6| Step: 2
Training loss: 1.30906541209786
Validation loss: 2.3536416503866757

Epoch: 6| Step: 3
Training loss: 1.11962054815554
Validation loss: 2.3490323028984994

Epoch: 6| Step: 4
Training loss: 0.7773922085633858
Validation loss: 2.3685400454811263

Epoch: 6| Step: 5
Training loss: 1.0389143185611316
Validation loss: 2.3759743052644526

Epoch: 6| Step: 6
Training loss: 1.2416467029238196
Validation loss: 2.4086728341657495

Epoch: 6| Step: 7
Training loss: 1.2053426640766196
Validation loss: 2.4254409963309485

Epoch: 6| Step: 8
Training loss: 1.3544107315004472
Validation loss: 2.4419450209869966

Epoch: 6| Step: 9
Training loss: 1.083111385693535
Validation loss: 2.4562656365246816

Epoch: 6| Step: 10
Training loss: 0.9434431840460663
Validation loss: 2.4612981133263845

Epoch: 6| Step: 11
Training loss: 0.9944426971351527
Validation loss: 2.4708473597643072

Epoch: 6| Step: 12
Training loss: 1.296783811741391
Validation loss: 2.498115666436853

Epoch: 6| Step: 13
Training loss: 1.159677117562596
Validation loss: 2.512056417606371

Epoch: 263| Step: 0
Training loss: 1.646911565675103
Validation loss: 2.504353336400109

Epoch: 6| Step: 1
Training loss: 1.1571860262052467
Validation loss: 2.491941565068032

Epoch: 6| Step: 2
Training loss: 1.241158929270964
Validation loss: 2.4432322168206686

Epoch: 6| Step: 3
Training loss: 1.1256225770609702
Validation loss: 2.420084960450898

Epoch: 6| Step: 4
Training loss: 1.2481580514595656
Validation loss: 2.387635543816359

Epoch: 6| Step: 5
Training loss: 1.2053834599442628
Validation loss: 2.4138896819350095

Epoch: 6| Step: 6
Training loss: 1.268233213738075
Validation loss: 2.3837340527117568

Epoch: 6| Step: 7
Training loss: 1.2994806242522459
Validation loss: 2.374946695106287

Epoch: 6| Step: 8
Training loss: 0.8598775607932004
Validation loss: 2.392879849215159

Epoch: 6| Step: 9
Training loss: 1.0814198443249075
Validation loss: 2.378713370461962

Epoch: 6| Step: 10
Training loss: 0.9475935220988899
Validation loss: 2.3843193896141552

Epoch: 6| Step: 11
Training loss: 0.8465302895423594
Validation loss: 2.407194682205974

Epoch: 6| Step: 12
Training loss: 0.7230825455582786
Validation loss: 2.402763393408913

Epoch: 6| Step: 13
Training loss: 1.0975962449366838
Validation loss: 2.435969257800881

Epoch: 264| Step: 0
Training loss: 1.0491350744175743
Validation loss: 2.4562524909024295

Epoch: 6| Step: 1
Training loss: 0.7193395435865355
Validation loss: 2.4399364317170336

Epoch: 6| Step: 2
Training loss: 1.268058979540006
Validation loss: 2.4486487050484667

Epoch: 6| Step: 3
Training loss: 0.7370520152469746
Validation loss: 2.4245714608192452

Epoch: 6| Step: 4
Training loss: 1.3196577897951625
Validation loss: 2.4411321187662893

Epoch: 6| Step: 5
Training loss: 1.6389395639519808
Validation loss: 2.443406361593157

Epoch: 6| Step: 6
Training loss: 1.0009193962334568
Validation loss: 2.424231522745419

Epoch: 6| Step: 7
Training loss: 1.2663157897307011
Validation loss: 2.4383720686917925

Epoch: 6| Step: 8
Training loss: 1.387785337509145
Validation loss: 2.423336903327307

Epoch: 6| Step: 9
Training loss: 1.1293709402428318
Validation loss: 2.4423735577418215

Epoch: 6| Step: 10
Training loss: 0.8413951649905255
Validation loss: 2.4464824804813623

Epoch: 6| Step: 11
Training loss: 1.1507126465941608
Validation loss: 2.431659780743894

Epoch: 6| Step: 12
Training loss: 1.0087133122500291
Validation loss: 2.432408577288287

Epoch: 6| Step: 13
Training loss: 1.0044754730086018
Validation loss: 2.426527133252315

Epoch: 265| Step: 0
Training loss: 1.1979804091149275
Validation loss: 2.4218509234906453

Epoch: 6| Step: 1
Training loss: 0.9949194474896463
Validation loss: 2.400906322201362

Epoch: 6| Step: 2
Training loss: 0.7492320579643656
Validation loss: 2.4235292234709305

Epoch: 6| Step: 3
Training loss: 1.664592103453614
Validation loss: 2.39633837526765

Epoch: 6| Step: 4
Training loss: 1.3468907047781107
Validation loss: 2.3946054880009893

Epoch: 6| Step: 5
Training loss: 1.1141151918681222
Validation loss: 2.4054598182734317

Epoch: 6| Step: 6
Training loss: 1.3709841518668642
Validation loss: 2.3984418551455002

Epoch: 6| Step: 7
Training loss: 0.7511114785546502
Validation loss: 2.411821877524636

Epoch: 6| Step: 8
Training loss: 0.8956945260022358
Validation loss: 2.406408894127904

Epoch: 6| Step: 9
Training loss: 1.0665296546043108
Validation loss: 2.420190730026923

Epoch: 6| Step: 10
Training loss: 0.9709736007790746
Validation loss: 2.4286043746632053

Epoch: 6| Step: 11
Training loss: 0.8515116475171619
Validation loss: 2.4379521937294073

Epoch: 6| Step: 12
Training loss: 1.4023803026116262
Validation loss: 2.4419226084704175

Epoch: 6| Step: 13
Training loss: 0.5700663466489495
Validation loss: 2.421755251270966

Epoch: 266| Step: 0
Training loss: 0.910092200125285
Validation loss: 2.460097813953904

Epoch: 6| Step: 1
Training loss: 1.255540584842548
Validation loss: 2.4483372519200732

Epoch: 6| Step: 2
Training loss: 0.9565352419608799
Validation loss: 2.443096945880918

Epoch: 6| Step: 3
Training loss: 0.8572198721085075
Validation loss: 2.444578985768567

Epoch: 6| Step: 4
Training loss: 0.883370383553259
Validation loss: 2.41616333128236

Epoch: 6| Step: 5
Training loss: 0.9201222584179214
Validation loss: 2.4251474152795782

Epoch: 6| Step: 6
Training loss: 0.6300565021775452
Validation loss: 2.3902708645568227

Epoch: 6| Step: 7
Training loss: 1.4262468805705266
Validation loss: 2.39449982165062

Epoch: 6| Step: 8
Training loss: 1.2131356745804982
Validation loss: 2.391482734517703

Epoch: 6| Step: 9
Training loss: 1.8223176971224324
Validation loss: 2.3978561654027772

Epoch: 6| Step: 10
Training loss: 1.007720706514889
Validation loss: 2.357251244866439

Epoch: 6| Step: 11
Training loss: 1.159960694962563
Validation loss: 2.362970363013563

Epoch: 6| Step: 12
Training loss: 1.0171041428123522
Validation loss: 2.3731297283933603

Epoch: 6| Step: 13
Training loss: 0.8742162055011772
Validation loss: 2.4384407361053384

Epoch: 267| Step: 0
Training loss: 0.9228972247094493
Validation loss: 2.4576728653830573

Epoch: 6| Step: 1
Training loss: 1.0164693403785008
Validation loss: 2.5232139444437482

Epoch: 6| Step: 2
Training loss: 0.6214258038094312
Validation loss: 2.514420837367248

Epoch: 6| Step: 3
Training loss: 1.2415003285371098
Validation loss: 2.4966606110008787

Epoch: 6| Step: 4
Training loss: 0.9399964472520934
Validation loss: 2.4791683877091204

Epoch: 6| Step: 5
Training loss: 0.9815290273007051
Validation loss: 2.448393914786899

Epoch: 6| Step: 6
Training loss: 0.5720017902339584
Validation loss: 2.4566235972889667

Epoch: 6| Step: 7
Training loss: 1.792798667935477
Validation loss: 2.451641669685475

Epoch: 6| Step: 8
Training loss: 1.046286915956182
Validation loss: 2.4134437263683797

Epoch: 6| Step: 9
Training loss: 1.4159653648138493
Validation loss: 2.388944750243435

Epoch: 6| Step: 10
Training loss: 1.0499075054119524
Validation loss: 2.3459094582839324

Epoch: 6| Step: 11
Training loss: 1.0722017529751324
Validation loss: 2.3431366815991566

Epoch: 6| Step: 12
Training loss: 1.4824611171107043
Validation loss: 2.3490510016460444

Epoch: 6| Step: 13
Training loss: 1.2570877830638194
Validation loss: 2.3682279035604195

Epoch: 268| Step: 0
Training loss: 0.8914348534183227
Validation loss: 2.445498017590873

Epoch: 6| Step: 1
Training loss: 1.2559446124966753
Validation loss: 2.481390286674075

Epoch: 6| Step: 2
Training loss: 1.339468678283725
Validation loss: 2.4736251452978517

Epoch: 6| Step: 3
Training loss: 0.863433099570505
Validation loss: 2.509492605062189

Epoch: 6| Step: 4
Training loss: 1.151754661893425
Validation loss: 2.5145986760559533

Epoch: 6| Step: 5
Training loss: 1.2179328918072305
Validation loss: 2.5124074962861633

Epoch: 6| Step: 6
Training loss: 1.170468058007295
Validation loss: 2.5026603469534576

Epoch: 6| Step: 7
Training loss: 0.7114899553352589
Validation loss: 2.5080082513840583

Epoch: 6| Step: 8
Training loss: 1.2232740992221236
Validation loss: 2.4829145769567185

Epoch: 6| Step: 9
Training loss: 0.8935685620507523
Validation loss: 2.4384982450087493

Epoch: 6| Step: 10
Training loss: 1.7255632780062888
Validation loss: 2.3954322850223497

Epoch: 6| Step: 11
Training loss: 0.8670108718388422
Validation loss: 2.3676273383109456

Epoch: 6| Step: 12
Training loss: 0.9710606122059631
Validation loss: 2.3215708031276043

Epoch: 6| Step: 13
Training loss: 1.3604979426050525
Validation loss: 2.323262761708

Epoch: 269| Step: 0
Training loss: 1.0264711336442716
Validation loss: 2.3179691209918634

Epoch: 6| Step: 1
Training loss: 0.7782557902281557
Validation loss: 2.3280680208239004

Epoch: 6| Step: 2
Training loss: 0.7453244222331215
Validation loss: 2.343400040070637

Epoch: 6| Step: 3
Training loss: 1.522048238493614
Validation loss: 2.365620156525383

Epoch: 6| Step: 4
Training loss: 1.0585946508875317
Validation loss: 2.3773074089167183

Epoch: 6| Step: 5
Training loss: 1.2264333280348443
Validation loss: 2.4619946380112943

Epoch: 6| Step: 6
Training loss: 1.040499618354225
Validation loss: 2.4612121683975454

Epoch: 6| Step: 7
Training loss: 0.7726479170208157
Validation loss: 2.4687487829518724

Epoch: 6| Step: 8
Training loss: 0.9186328190403152
Validation loss: 2.462135206051249

Epoch: 6| Step: 9
Training loss: 1.0057644993748884
Validation loss: 2.440170140281315

Epoch: 6| Step: 10
Training loss: 1.3075491764310054
Validation loss: 2.4312805897633902

Epoch: 6| Step: 11
Training loss: 1.1625148033922317
Validation loss: 2.4427613195919764

Epoch: 6| Step: 12
Training loss: 1.528496738768528
Validation loss: 2.418638868047861

Epoch: 6| Step: 13
Training loss: 1.2495031322975785
Validation loss: 2.404007054764632

Epoch: 270| Step: 0
Training loss: 1.0441629951840756
Validation loss: 2.3827147648195814

Epoch: 6| Step: 1
Training loss: 1.2935433393162334
Validation loss: 2.418580616634953

Epoch: 6| Step: 2
Training loss: 0.5218911174181272
Validation loss: 2.4032390045191216

Epoch: 6| Step: 3
Training loss: 1.190443656908269
Validation loss: 2.4063277000962224

Epoch: 6| Step: 4
Training loss: 0.9910036368240771
Validation loss: 2.4145895203498005

Epoch: 6| Step: 5
Training loss: 1.057241272625788
Validation loss: 2.4092127365104794

Epoch: 6| Step: 6
Training loss: 0.9396263169115365
Validation loss: 2.4255237965526275

Epoch: 6| Step: 7
Training loss: 1.6456390781285752
Validation loss: 2.432817146264745

Epoch: 6| Step: 8
Training loss: 0.8578210479366023
Validation loss: 2.4277727141884076

Epoch: 6| Step: 9
Training loss: 0.9142609079329341
Validation loss: 2.4680110686917502

Epoch: 6| Step: 10
Training loss: 1.3403386572724425
Validation loss: 2.4480685537567526

Epoch: 6| Step: 11
Training loss: 0.9714738023870563
Validation loss: 2.4335101424405425

Epoch: 6| Step: 12
Training loss: 0.9467017943845066
Validation loss: 2.434842887190023

Epoch: 6| Step: 13
Training loss: 1.1933373981456328
Validation loss: 2.415368651986527

Epoch: 271| Step: 0
Training loss: 0.9653691702892297
Validation loss: 2.4183399150740703

Epoch: 6| Step: 1
Training loss: 1.7480706751391295
Validation loss: 2.3905804693149784

Epoch: 6| Step: 2
Training loss: 0.6004254878885431
Validation loss: 2.382196423607084

Epoch: 6| Step: 3
Training loss: 0.9674992639701468
Validation loss: 2.3946953676957667

Epoch: 6| Step: 4
Training loss: 0.7004174767201505
Validation loss: 2.3774587002698913

Epoch: 6| Step: 5
Training loss: 1.1666887599124727
Validation loss: 2.3843675633097603

Epoch: 6| Step: 6
Training loss: 1.0455893407967143
Validation loss: 2.383098080724224

Epoch: 6| Step: 7
Training loss: 1.0006752714434783
Validation loss: 2.3893762981823095

Epoch: 6| Step: 8
Training loss: 1.036983906255927
Validation loss: 2.3796021528871627

Epoch: 6| Step: 9
Training loss: 0.7656420491714203
Validation loss: 2.396194502121035

Epoch: 6| Step: 10
Training loss: 1.3744000079493583
Validation loss: 2.385404638795737

Epoch: 6| Step: 11
Training loss: 0.972711676431645
Validation loss: 2.4192711166197465

Epoch: 6| Step: 12
Training loss: 0.9250299165372722
Validation loss: 2.445910910569437

Epoch: 6| Step: 13
Training loss: 1.0689341447812448
Validation loss: 2.463564827213572

Epoch: 272| Step: 0
Training loss: 1.1904915221680257
Validation loss: 2.4854182119918002

Epoch: 6| Step: 1
Training loss: 1.014901182034058
Validation loss: 2.4813001925641833

Epoch: 6| Step: 2
Training loss: 1.0241949758090962
Validation loss: 2.4744050323531437

Epoch: 6| Step: 3
Training loss: 1.2284542001672547
Validation loss: 2.4752864161885753

Epoch: 6| Step: 4
Training loss: 0.8487853866751061
Validation loss: 2.4799143290368137

Epoch: 6| Step: 5
Training loss: 0.9068059860038648
Validation loss: 2.446794872223728

Epoch: 6| Step: 6
Training loss: 1.080314348267245
Validation loss: 2.4026460756316825

Epoch: 6| Step: 7
Training loss: 0.9960179617978013
Validation loss: 2.3917158494439836

Epoch: 6| Step: 8
Training loss: 1.1295597072725732
Validation loss: 2.3709199624824233

Epoch: 6| Step: 9
Training loss: 0.7655633784817039
Validation loss: 2.385271142551854

Epoch: 6| Step: 10
Training loss: 0.6676100721577699
Validation loss: 2.378780863671083

Epoch: 6| Step: 11
Training loss: 1.728937922901675
Validation loss: 2.3547026183584934

Epoch: 6| Step: 12
Training loss: 0.8422807687838627
Validation loss: 2.348602179154671

Epoch: 6| Step: 13
Training loss: 0.9574861651982344
Validation loss: 2.3261295060335385

Epoch: 273| Step: 0
Training loss: 0.787285342554913
Validation loss: 2.3500635768168476

Epoch: 6| Step: 1
Training loss: 1.1272599514953237
Validation loss: 2.3781318815264703

Epoch: 6| Step: 2
Training loss: 1.227769003175553
Validation loss: 2.346931276102336

Epoch: 6| Step: 3
Training loss: 0.8752411782442022
Validation loss: 2.3579196169472953

Epoch: 6| Step: 4
Training loss: 0.7549226066888206
Validation loss: 2.3951516749763306

Epoch: 6| Step: 5
Training loss: 0.8900050632461367
Validation loss: 2.382839343267599

Epoch: 6| Step: 6
Training loss: 1.1023216066900827
Validation loss: 2.387130205323018

Epoch: 6| Step: 7
Training loss: 0.8683264186849848
Validation loss: 2.4078362005423943

Epoch: 6| Step: 8
Training loss: 0.8088337270328432
Validation loss: 2.4190932834064633

Epoch: 6| Step: 9
Training loss: 0.8971394989555652
Validation loss: 2.4259279247146

Epoch: 6| Step: 10
Training loss: 1.5136751827080794
Validation loss: 2.4376454553150224

Epoch: 6| Step: 11
Training loss: 1.161597387545777
Validation loss: 2.442205704330198

Epoch: 6| Step: 12
Training loss: 1.0044348249202195
Validation loss: 2.4383939697621564

Epoch: 6| Step: 13
Training loss: 1.3854708792421762
Validation loss: 2.4446394412541963

Epoch: 274| Step: 0
Training loss: 1.209522330996951
Validation loss: 2.414056967175967

Epoch: 6| Step: 1
Training loss: 1.1144817638762128
Validation loss: 2.404463453306732

Epoch: 6| Step: 2
Training loss: 0.8609564015828463
Validation loss: 2.3865701978175515

Epoch: 6| Step: 3
Training loss: 1.7370902449641987
Validation loss: 2.3835791355304443

Epoch: 6| Step: 4
Training loss: 0.9465505831079438
Validation loss: 2.3634725313093043

Epoch: 6| Step: 5
Training loss: 0.7516156913349651
Validation loss: 2.3729315668251725

Epoch: 6| Step: 6
Training loss: 0.8300266743590549
Validation loss: 2.346137349019864

Epoch: 6| Step: 7
Training loss: 0.8181219735319084
Validation loss: 2.3460386099402344

Epoch: 6| Step: 8
Training loss: 1.162766573705601
Validation loss: 2.330599677390779

Epoch: 6| Step: 9
Training loss: 0.7899350167359265
Validation loss: 2.3330616492507494

Epoch: 6| Step: 10
Training loss: 1.073622770576503
Validation loss: 2.3531072092772125

Epoch: 6| Step: 11
Training loss: 0.7550121359449756
Validation loss: 2.3665051991283717

Epoch: 6| Step: 12
Training loss: 0.7003310748951571
Validation loss: 2.383035401842681

Epoch: 6| Step: 13
Training loss: 1.3202938552533166
Validation loss: 2.408970271502178

Epoch: 275| Step: 0
Training loss: 0.7857125053137882
Validation loss: 2.428671278878123

Epoch: 6| Step: 1
Training loss: 1.0090096630393643
Validation loss: 2.4915924827810887

Epoch: 6| Step: 2
Training loss: 1.4105152719232772
Validation loss: 2.482194210238307

Epoch: 6| Step: 3
Training loss: 0.3964516198670145
Validation loss: 2.474955264884915

Epoch: 6| Step: 4
Training loss: 1.123290405405928
Validation loss: 2.474730732691875

Epoch: 6| Step: 5
Training loss: 1.1741040202300794
Validation loss: 2.485224474299953

Epoch: 6| Step: 6
Training loss: 1.14000779266371
Validation loss: 2.405886521418769

Epoch: 6| Step: 7
Training loss: 0.9251457640780533
Validation loss: 2.438620841019064

Epoch: 6| Step: 8
Training loss: 1.0030029032428442
Validation loss: 2.426490763814943

Epoch: 6| Step: 9
Training loss: 0.8313511320848282
Validation loss: 2.4270546908068042

Epoch: 6| Step: 10
Training loss: 0.7582281486866703
Validation loss: 2.4069257367233927

Epoch: 6| Step: 11
Training loss: 0.8729982639920342
Validation loss: 2.3897511354704415

Epoch: 6| Step: 12
Training loss: 1.352941482115855
Validation loss: 2.4148172537476937

Epoch: 6| Step: 13
Training loss: 1.3164125436694647
Validation loss: 2.360246626217429

Epoch: 276| Step: 0
Training loss: 1.5748931727435354
Validation loss: 2.3429310002788433

Epoch: 6| Step: 1
Training loss: 0.70764875054676
Validation loss: 2.345010546714707

Epoch: 6| Step: 2
Training loss: 1.0757936342588958
Validation loss: 2.330283511689732

Epoch: 6| Step: 3
Training loss: 1.1138231531302332
Validation loss: 2.3391707753280544

Epoch: 6| Step: 4
Training loss: 1.212912345851452
Validation loss: 2.3315391582674136

Epoch: 6| Step: 5
Training loss: 0.46900561039177796
Validation loss: 2.345673106962557

Epoch: 6| Step: 6
Training loss: 1.1693422540660048
Validation loss: 2.35331681731355

Epoch: 6| Step: 7
Training loss: 1.0667645757165272
Validation loss: 2.3909785811949766

Epoch: 6| Step: 8
Training loss: 0.9089385305924873
Validation loss: 2.3605107865486157

Epoch: 6| Step: 9
Training loss: 0.7387662233226917
Validation loss: 2.3803455209759847

Epoch: 6| Step: 10
Training loss: 1.002391934741881
Validation loss: 2.415823068574647

Epoch: 6| Step: 11
Training loss: 0.86891840119038
Validation loss: 2.4043284818364237

Epoch: 6| Step: 12
Training loss: 0.8069362144977033
Validation loss: 2.424574018038823

Epoch: 6| Step: 13
Training loss: 0.8554886419343797
Validation loss: 2.44142536902376

Epoch: 277| Step: 0
Training loss: 1.129797455012365
Validation loss: 2.4491106897136254

Epoch: 6| Step: 1
Training loss: 1.2754084774245853
Validation loss: 2.4439624911463507

Epoch: 6| Step: 2
Training loss: 1.642034452004904
Validation loss: 2.4396283723153704

Epoch: 6| Step: 3
Training loss: 1.045592818144028
Validation loss: 2.4016957668762786

Epoch: 6| Step: 4
Training loss: 0.6542419182770576
Validation loss: 2.413680763805066

Epoch: 6| Step: 5
Training loss: 1.1386052892463248
Validation loss: 2.400357795757237

Epoch: 6| Step: 6
Training loss: 0.7983418595874779
Validation loss: 2.396329156647243

Epoch: 6| Step: 7
Training loss: 0.9718233395305063
Validation loss: 2.409754265812946

Epoch: 6| Step: 8
Training loss: 0.6558496071211369
Validation loss: 2.3780515600927767

Epoch: 6| Step: 9
Training loss: 1.1320410897174156
Validation loss: 2.387164649633058

Epoch: 6| Step: 10
Training loss: 0.699305097480261
Validation loss: 2.383378956836582

Epoch: 6| Step: 11
Training loss: 0.769321161241065
Validation loss: 2.3772840176622294

Epoch: 6| Step: 12
Training loss: 0.7944952642492911
Validation loss: 2.398894522150798

Epoch: 6| Step: 13
Training loss: 0.5281761945932616
Validation loss: 2.400305654240912

Epoch: 278| Step: 0
Training loss: 0.7478466114469093
Validation loss: 2.396506697382134

Epoch: 6| Step: 1
Training loss: 1.2206687495159865
Validation loss: 2.4136206168076195

Epoch: 6| Step: 2
Training loss: 1.1439769040357253
Validation loss: 2.4179928630445766

Epoch: 6| Step: 3
Training loss: 1.0073512004838894
Validation loss: 2.404298152396605

Epoch: 6| Step: 4
Training loss: 1.5936811095663548
Validation loss: 2.417446074615576

Epoch: 6| Step: 5
Training loss: 0.8981596143790987
Validation loss: 2.4310639816990203

Epoch: 6| Step: 6
Training loss: 0.9643406347751504
Validation loss: 2.4456146445666156

Epoch: 6| Step: 7
Training loss: 0.9481814018276195
Validation loss: 2.408316751854422

Epoch: 6| Step: 8
Training loss: 0.5757072773883442
Validation loss: 2.417085162268324

Epoch: 6| Step: 9
Training loss: 1.159413417786294
Validation loss: 2.408570452308864

Epoch: 6| Step: 10
Training loss: 0.6639870993498498
Validation loss: 2.4078416177667377

Epoch: 6| Step: 11
Training loss: 0.7367969103358016
Validation loss: 2.394302511140943

Epoch: 6| Step: 12
Training loss: 0.9918656615675185
Validation loss: 2.3820982676421005

Epoch: 6| Step: 13
Training loss: 0.8282565965997154
Validation loss: 2.3649785389746296

Epoch: 279| Step: 0
Training loss: 0.676112430103746
Validation loss: 2.3813924344022332

Epoch: 6| Step: 1
Training loss: 1.1346233232735203
Validation loss: 2.358708275021738

Epoch: 6| Step: 2
Training loss: 0.6022048344712941
Validation loss: 2.351083438714524

Epoch: 6| Step: 3
Training loss: 0.951032906471399
Validation loss: 2.382134881139105

Epoch: 6| Step: 4
Training loss: 0.7389011908664728
Validation loss: 2.356661617286813

Epoch: 6| Step: 5
Training loss: 0.8764043165468844
Validation loss: 2.3674631829035846

Epoch: 6| Step: 6
Training loss: 0.7252896141507812
Validation loss: 2.359144250464905

Epoch: 6| Step: 7
Training loss: 1.5192549976582423
Validation loss: 2.366148782066055

Epoch: 6| Step: 8
Training loss: 1.2239638091702087
Validation loss: 2.3518259243439474

Epoch: 6| Step: 9
Training loss: 1.1746251198132331
Validation loss: 2.379317288211988

Epoch: 6| Step: 10
Training loss: 0.9966887847228061
Validation loss: 2.397761105334521

Epoch: 6| Step: 11
Training loss: 0.644222509246894
Validation loss: 2.3928564719812653

Epoch: 6| Step: 12
Training loss: 0.824472180495763
Validation loss: 2.4059244070642296

Epoch: 6| Step: 13
Training loss: 1.1055877405835328
Validation loss: 2.407207974321758

Epoch: 280| Step: 0
Training loss: 1.6521788169844802
Validation loss: 2.389547306850647

Epoch: 6| Step: 1
Training loss: 0.8956751277123117
Validation loss: 2.392000953448732

Epoch: 6| Step: 2
Training loss: 0.7289933997877152
Validation loss: 2.365673397398876

Epoch: 6| Step: 3
Training loss: 1.2122066614889069
Validation loss: 2.37630853296681

Epoch: 6| Step: 4
Training loss: 0.737114443455804
Validation loss: 2.3422702769671666

Epoch: 6| Step: 5
Training loss: 0.9045024333349659
Validation loss: 2.3581772771071012

Epoch: 6| Step: 6
Training loss: 0.783544756041318
Validation loss: 2.3615675123373543

Epoch: 6| Step: 7
Training loss: 1.0182554952172067
Validation loss: 2.355352175833243

Epoch: 6| Step: 8
Training loss: 1.0227861734248622
Validation loss: 2.390500170430969

Epoch: 6| Step: 9
Training loss: 0.8379393165507799
Validation loss: 2.3908554310324424

Epoch: 6| Step: 10
Training loss: 0.8642911225704787
Validation loss: 2.3898405015347417

Epoch: 6| Step: 11
Training loss: 0.8873869273191123
Validation loss: 2.4118239810973137

Epoch: 6| Step: 12
Training loss: 1.0378425721977962
Validation loss: 2.3819008080808044

Epoch: 6| Step: 13
Training loss: 0.48492800001182146
Validation loss: 2.4091350219858017

Epoch: 281| Step: 0
Training loss: 0.9283919082279107
Validation loss: 2.3594942650181863

Epoch: 6| Step: 1
Training loss: 1.03702373833556
Validation loss: 2.3631590897477968

Epoch: 6| Step: 2
Training loss: 1.1351643319836604
Validation loss: 2.3473119957823174

Epoch: 6| Step: 3
Training loss: 0.5980797308250396
Validation loss: 2.3386564137309622

Epoch: 6| Step: 4
Training loss: 1.6775523254602172
Validation loss: 2.3120195243842203

Epoch: 6| Step: 5
Training loss: 0.6251606734695434
Validation loss: 2.3250821485770006

Epoch: 6| Step: 6
Training loss: 0.961401695465107
Validation loss: 2.3127843498516727

Epoch: 6| Step: 7
Training loss: 1.074211259295616
Validation loss: 2.342576585399959

Epoch: 6| Step: 8
Training loss: 0.9244522341534763
Validation loss: 2.3504374521295475

Epoch: 6| Step: 9
Training loss: 0.7271821855679533
Validation loss: 2.3649697975691795

Epoch: 6| Step: 10
Training loss: 1.04593137658945
Validation loss: 2.362561666509947

Epoch: 6| Step: 11
Training loss: 0.8715313552100801
Validation loss: 2.387417293705887

Epoch: 6| Step: 12
Training loss: 0.5666728214556102
Validation loss: 2.393586784810267

Epoch: 6| Step: 13
Training loss: 0.772777815494343
Validation loss: 2.3932210258468527

Epoch: 282| Step: 0
Training loss: 0.8021343429660953
Validation loss: 2.430662315375704

Epoch: 6| Step: 1
Training loss: 0.895866363862733
Validation loss: 2.408502231864613

Epoch: 6| Step: 2
Training loss: 0.7735632591887989
Validation loss: 2.408893665543074

Epoch: 6| Step: 3
Training loss: 0.9460292022383516
Validation loss: 2.3847266513641436

Epoch: 6| Step: 4
Training loss: 0.8556666036540673
Validation loss: 2.420724902274091

Epoch: 6| Step: 5
Training loss: 0.8405065006274763
Validation loss: 2.4020981647183817

Epoch: 6| Step: 6
Training loss: 1.0247283831529197
Validation loss: 2.405801662851233

Epoch: 6| Step: 7
Training loss: 0.8648708432303466
Validation loss: 2.361509516273991

Epoch: 6| Step: 8
Training loss: 0.865038192931182
Validation loss: 2.3846242121870462

Epoch: 6| Step: 9
Training loss: 0.6051478612324751
Validation loss: 2.390508358408938

Epoch: 6| Step: 10
Training loss: 1.1226644113518751
Validation loss: 2.3938723128258794

Epoch: 6| Step: 11
Training loss: 0.8029169028268126
Validation loss: 2.393251315169529

Epoch: 6| Step: 12
Training loss: 1.4286775617683958
Validation loss: 2.3758580536555716

Epoch: 6| Step: 13
Training loss: 1.1950682346862167
Validation loss: 2.3720762788325556

Epoch: 283| Step: 0
Training loss: 0.8924667322278993
Validation loss: 2.352868841782015

Epoch: 6| Step: 1
Training loss: 0.46020781417559514
Validation loss: 2.355743467825263

Epoch: 6| Step: 2
Training loss: 0.41796042532072936
Validation loss: 2.3589378538168115

Epoch: 6| Step: 3
Training loss: 0.862387423148126
Validation loss: 2.3444071733687672

Epoch: 6| Step: 4
Training loss: 1.0386472173305437
Validation loss: 2.3954121219840756

Epoch: 6| Step: 5
Training loss: 1.153565254009312
Validation loss: 2.379514760153153

Epoch: 6| Step: 6
Training loss: 0.8020821030512371
Validation loss: 2.3799910053115263

Epoch: 6| Step: 7
Training loss: 0.9690528519293767
Validation loss: 2.3642996120485664

Epoch: 6| Step: 8
Training loss: 0.8096447808006474
Validation loss: 2.3914392671559304

Epoch: 6| Step: 9
Training loss: 1.069514401667479
Validation loss: 2.3695427847853257

Epoch: 6| Step: 10
Training loss: 0.9890084587869429
Validation loss: 2.356219956127126

Epoch: 6| Step: 11
Training loss: 0.8319088841393688
Validation loss: 2.361483042829557

Epoch: 6| Step: 12
Training loss: 1.3832584674906283
Validation loss: 2.3497262302588737

Epoch: 6| Step: 13
Training loss: 1.2869495066805696
Validation loss: 2.3542487648963184

Epoch: 284| Step: 0
Training loss: 0.8123059040930907
Validation loss: 2.3844936600389084

Epoch: 6| Step: 1
Training loss: 0.9398150153456545
Validation loss: 2.3748225964586154

Epoch: 6| Step: 2
Training loss: 1.0745000297578335
Validation loss: 2.3736921097533634

Epoch: 6| Step: 3
Training loss: 1.6068365577185582
Validation loss: 2.368249656044666

Epoch: 6| Step: 4
Training loss: 0.672789262121368
Validation loss: 2.382627263527283

Epoch: 6| Step: 5
Training loss: 0.7100390951380429
Validation loss: 2.3634578846627683

Epoch: 6| Step: 6
Training loss: 0.6107055858041786
Validation loss: 2.3291875882724087

Epoch: 6| Step: 7
Training loss: 0.9214812262118666
Validation loss: 2.3145795172964134

Epoch: 6| Step: 8
Training loss: 1.0309977367387382
Validation loss: 2.3283384238646736

Epoch: 6| Step: 9
Training loss: 1.003000110207853
Validation loss: 2.340527345349176

Epoch: 6| Step: 10
Training loss: 0.8354594922841446
Validation loss: 2.3550615721450137

Epoch: 6| Step: 11
Training loss: 0.8040655751175089
Validation loss: 2.3891682366891067

Epoch: 6| Step: 12
Training loss: 0.9588161717225133
Validation loss: 2.377466846358822

Epoch: 6| Step: 13
Training loss: 0.5802266608265115
Validation loss: 2.440911319960752

Epoch: 285| Step: 0
Training loss: 1.6114608432558712
Validation loss: 2.414562609606963

Epoch: 6| Step: 1
Training loss: 0.26960240682541403
Validation loss: 2.4013908704768108

Epoch: 6| Step: 2
Training loss: 0.7211755790859141
Validation loss: 2.3978056523474085

Epoch: 6| Step: 3
Training loss: 0.8927614787487317
Validation loss: 2.3874986691184774

Epoch: 6| Step: 4
Training loss: 0.6502445732837695
Validation loss: 2.362791724792192

Epoch: 6| Step: 5
Training loss: 0.8160668721776881
Validation loss: 2.351936327788768

Epoch: 6| Step: 6
Training loss: 0.7840336607840065
Validation loss: 2.3405434449441485

Epoch: 6| Step: 7
Training loss: 0.9949515881574073
Validation loss: 2.3422564554411966

Epoch: 6| Step: 8
Training loss: 0.7014656407838861
Validation loss: 2.338210178438376

Epoch: 6| Step: 9
Training loss: 0.8813956715192951
Validation loss: 2.3751679886201837

Epoch: 6| Step: 10
Training loss: 1.0685420185300998
Validation loss: 2.399712256432221

Epoch: 6| Step: 11
Training loss: 0.8418077791220252
Validation loss: 2.3875361146425127

Epoch: 6| Step: 12
Training loss: 1.164204121621783
Validation loss: 2.3921888666387567

Epoch: 6| Step: 13
Training loss: 0.7126430970098709
Validation loss: 2.4090055305175926

Epoch: 286| Step: 0
Training loss: 0.7356540012395738
Validation loss: 2.4166301629771683

Epoch: 6| Step: 1
Training loss: 1.128128047526885
Validation loss: 2.381659165322227

Epoch: 6| Step: 2
Training loss: 0.9283764675113887
Validation loss: 2.408423458706206

Epoch: 6| Step: 3
Training loss: 1.1090509183079553
Validation loss: 2.39745502204283

Epoch: 6| Step: 4
Training loss: 0.8111814657454629
Validation loss: 2.4105397705727674

Epoch: 6| Step: 5
Training loss: 0.9325378384212798
Validation loss: 2.3848661285467387

Epoch: 6| Step: 6
Training loss: 0.7640249699461614
Validation loss: 2.3902030710286195

Epoch: 6| Step: 7
Training loss: 0.6311771549080035
Validation loss: 2.3365915691292907

Epoch: 6| Step: 8
Training loss: 0.7202737247514672
Validation loss: 2.31831611350836

Epoch: 6| Step: 9
Training loss: 0.7657205950165951
Validation loss: 2.361689564950683

Epoch: 6| Step: 10
Training loss: 0.6727483529049809
Validation loss: 2.3579542987789526

Epoch: 6| Step: 11
Training loss: 1.5325145560190938
Validation loss: 2.394666364185076

Epoch: 6| Step: 12
Training loss: 0.7520427303678314
Validation loss: 2.346327759687909

Epoch: 6| Step: 13
Training loss: 1.0255107119041236
Validation loss: 2.3015014049532185

Epoch: 287| Step: 0
Training loss: 0.7234711871944601
Validation loss: 2.3396463040541975

Epoch: 6| Step: 1
Training loss: 1.1007225134660419
Validation loss: 2.337222249847742

Epoch: 6| Step: 2
Training loss: 1.4330737758686813
Validation loss: 2.359142124369749

Epoch: 6| Step: 3
Training loss: 1.0467932370268758
Validation loss: 2.3394119072636417

Epoch: 6| Step: 4
Training loss: 0.7239550903759964
Validation loss: 2.347767773311549

Epoch: 6| Step: 5
Training loss: 0.7697539805959502
Validation loss: 2.3291809755054165

Epoch: 6| Step: 6
Training loss: 1.221509060123804
Validation loss: 2.3405998361923426

Epoch: 6| Step: 7
Training loss: 0.9695699359758898
Validation loss: 2.335848683236667

Epoch: 6| Step: 8
Training loss: 0.6600140074124925
Validation loss: 2.3407489697067736

Epoch: 6| Step: 9
Training loss: 0.7401265491069295
Validation loss: 2.336292270223198

Epoch: 6| Step: 10
Training loss: 0.6729101590136155
Validation loss: 2.3439835129222457

Epoch: 6| Step: 11
Training loss: 0.7046085389552416
Validation loss: 2.3555834851147672

Epoch: 6| Step: 12
Training loss: 0.9767375636542942
Validation loss: 2.3470565114201283

Epoch: 6| Step: 13
Training loss: 0.7866029459057465
Validation loss: 2.3328443749572925

Epoch: 288| Step: 0
Training loss: 1.0135894918315576
Validation loss: 2.30793548966541

Epoch: 6| Step: 1
Training loss: 0.8953147022692906
Validation loss: 2.3381501595518643

Epoch: 6| Step: 2
Training loss: 0.6387105107651585
Validation loss: 2.356535893742425

Epoch: 6| Step: 3
Training loss: 0.8844720214356263
Validation loss: 2.3738511744420903

Epoch: 6| Step: 4
Training loss: 0.9933020871857013
Validation loss: 2.3854385405782126

Epoch: 6| Step: 5
Training loss: 0.9042797375367218
Validation loss: 2.3797830949605925

Epoch: 6| Step: 6
Training loss: 1.4625512660243782
Validation loss: 2.372268335280176

Epoch: 6| Step: 7
Training loss: 1.094228748720889
Validation loss: 2.3563978468519804

Epoch: 6| Step: 8
Training loss: 0.7991096727920269
Validation loss: 2.3302361479343143

Epoch: 6| Step: 9
Training loss: 0.7332244138314771
Validation loss: 2.3391098018226124

Epoch: 6| Step: 10
Training loss: 1.080779415325942
Validation loss: 2.3269502261199517

Epoch: 6| Step: 11
Training loss: 0.7648259878774962
Validation loss: 2.33962109754894

Epoch: 6| Step: 12
Training loss: 0.5182959994315347
Validation loss: 2.351840100582774

Epoch: 6| Step: 13
Training loss: 0.7636401079600053
Validation loss: 2.332260249487226

Epoch: 289| Step: 0
Training loss: 0.7058663017975944
Validation loss: 2.3346631535322304

Epoch: 6| Step: 1
Training loss: 1.0519384655814583
Validation loss: 2.381293978306659

Epoch: 6| Step: 2
Training loss: 0.8181395315070201
Validation loss: 2.3616743905399105

Epoch: 6| Step: 3
Training loss: 0.5758608738413045
Validation loss: 2.4067693916066504

Epoch: 6| Step: 4
Training loss: 0.8202074256086441
Validation loss: 2.381637097748108

Epoch: 6| Step: 5
Training loss: 0.9120631073483285
Validation loss: 2.3838412136183282

Epoch: 6| Step: 6
Training loss: 0.7958127590003162
Validation loss: 2.385059167797848

Epoch: 6| Step: 7
Training loss: 0.6847698231126104
Validation loss: 2.39875978612827

Epoch: 6| Step: 8
Training loss: 1.201359729498727
Validation loss: 2.3768178705329865

Epoch: 6| Step: 9
Training loss: 1.00653918358019
Validation loss: 2.3184899363878855

Epoch: 6| Step: 10
Training loss: 0.7790018541438866
Validation loss: 2.3526669506927633

Epoch: 6| Step: 11
Training loss: 0.9246887972282136
Validation loss: 2.3025170917385895

Epoch: 6| Step: 12
Training loss: 0.8602958600547794
Validation loss: 2.3539803591211754

Epoch: 6| Step: 13
Training loss: 1.1126706774654367
Validation loss: 2.355154011380079

Epoch: 290| Step: 0
Training loss: 1.2618873412694056
Validation loss: 2.3456125582339813

Epoch: 6| Step: 1
Training loss: 0.9104176092834015
Validation loss: 2.3455422804032415

Epoch: 6| Step: 2
Training loss: 0.4667566513543831
Validation loss: 2.3647468802703697

Epoch: 6| Step: 3
Training loss: 0.8611017392444954
Validation loss: 2.3194390352280347

Epoch: 6| Step: 4
Training loss: 0.8407634933005969
Validation loss: 2.3335779943686523

Epoch: 6| Step: 5
Training loss: 0.7189631767924106
Validation loss: 2.320314972694814

Epoch: 6| Step: 6
Training loss: 0.3787634669009079
Validation loss: 2.3477293309628187

Epoch: 6| Step: 7
Training loss: 0.8290708646269649
Validation loss: 2.354577142980664

Epoch: 6| Step: 8
Training loss: 0.9336530913962101
Validation loss: 2.369361092063503

Epoch: 6| Step: 9
Training loss: 1.1685450226251612
Validation loss: 2.3831287902356273

Epoch: 6| Step: 10
Training loss: 0.9080743841989553
Validation loss: 2.4057198595570823

Epoch: 6| Step: 11
Training loss: 1.0074624333347069
Validation loss: 2.402939063276834

Epoch: 6| Step: 12
Training loss: 0.6183528280483921
Validation loss: 2.366850901697157

Epoch: 6| Step: 13
Training loss: 0.7128379488779155
Validation loss: 2.360597827232218

Epoch: 291| Step: 0
Training loss: 1.1530380485026765
Validation loss: 2.349245476548605

Epoch: 6| Step: 1
Training loss: 0.6038624282472687
Validation loss: 2.3561200335825236

Epoch: 6| Step: 2
Training loss: 0.7502464445844057
Validation loss: 2.3276617532572375

Epoch: 6| Step: 3
Training loss: 0.5998054457187363
Validation loss: 2.322267980253621

Epoch: 6| Step: 4
Training loss: 0.9381039899065567
Validation loss: 2.356148080783174

Epoch: 6| Step: 5
Training loss: 0.6621650064778665
Validation loss: 2.3303787819603703

Epoch: 6| Step: 6
Training loss: 0.7809067925945102
Validation loss: 2.327200821295337

Epoch: 6| Step: 7
Training loss: 0.5710516542296334
Validation loss: 2.365244872397095

Epoch: 6| Step: 8
Training loss: 0.6022157961141641
Validation loss: 2.3597892392697597

Epoch: 6| Step: 9
Training loss: 1.0316950675699288
Validation loss: 2.378662543040968

Epoch: 6| Step: 10
Training loss: 1.3831134619492296
Validation loss: 2.3458646579822773

Epoch: 6| Step: 11
Training loss: 0.6994184709594838
Validation loss: 2.362140632135153

Epoch: 6| Step: 12
Training loss: 0.9878846831650219
Validation loss: 2.35966124547253

Epoch: 6| Step: 13
Training loss: 0.8535993521889014
Validation loss: 2.3648341542195994

Epoch: 292| Step: 0
Training loss: 0.7401082678799124
Validation loss: 2.366734566451831

Epoch: 6| Step: 1
Training loss: 1.008462976891015
Validation loss: 2.393137391861318

Epoch: 6| Step: 2
Training loss: 1.139176533332369
Validation loss: 2.3836234399404317

Epoch: 6| Step: 3
Training loss: 1.1901948867822632
Validation loss: 2.372455833404573

Epoch: 6| Step: 4
Training loss: 0.8199910942035966
Validation loss: 2.341939873322463

Epoch: 6| Step: 5
Training loss: 0.6596540538525933
Validation loss: 2.34093735570687

Epoch: 6| Step: 6
Training loss: 0.8553084828648642
Validation loss: 2.3405701848029876

Epoch: 6| Step: 7
Training loss: 0.7702121336511889
Validation loss: 2.3350315063515894

Epoch: 6| Step: 8
Training loss: 0.7089698726967832
Validation loss: 2.3262806857793463

Epoch: 6| Step: 9
Training loss: 0.6830157643030642
Validation loss: 2.3322075869055494

Epoch: 6| Step: 10
Training loss: 0.8884894215174638
Validation loss: 2.3152024354496366

Epoch: 6| Step: 11
Training loss: 0.6336061657536939
Validation loss: 2.325836323027186

Epoch: 6| Step: 12
Training loss: 0.6978407125753268
Validation loss: 2.3251499322628937

Epoch: 6| Step: 13
Training loss: 0.6135569639085379
Validation loss: 2.3274648599972436

Epoch: 293| Step: 0
Training loss: 0.7243458970603094
Validation loss: 2.342641615121506

Epoch: 6| Step: 1
Training loss: 0.9325091713871072
Validation loss: 2.379649188548991

Epoch: 6| Step: 2
Training loss: 0.5389742018766238
Validation loss: 2.370758569768662

Epoch: 6| Step: 3
Training loss: 0.8399920310482587
Validation loss: 2.390669292865623

Epoch: 6| Step: 4
Training loss: 0.7056079891847323
Validation loss: 2.362029173127727

Epoch: 6| Step: 5
Training loss: 1.1799276751643613
Validation loss: 2.364209293562398

Epoch: 6| Step: 6
Training loss: 0.8356926818006857
Validation loss: 2.3584611319835287

Epoch: 6| Step: 7
Training loss: 0.8893189474364471
Validation loss: 2.329310680490051

Epoch: 6| Step: 8
Training loss: 0.7908180272584449
Validation loss: 2.3442109647987586

Epoch: 6| Step: 9
Training loss: 0.8757102331791375
Validation loss: 2.284580169527899

Epoch: 6| Step: 10
Training loss: 0.8183396730805412
Validation loss: 2.294394032646576

Epoch: 6| Step: 11
Training loss: 0.8746107802522453
Validation loss: 2.3264239083339247

Epoch: 6| Step: 12
Training loss: 0.8154227433508586
Validation loss: 2.318913454773999

Epoch: 6| Step: 13
Training loss: 0.5906492631964309
Validation loss: 2.3234643153097676

Epoch: 294| Step: 0
Training loss: 0.44753194151529857
Validation loss: 2.324524854214106

Epoch: 6| Step: 1
Training loss: 0.9103058458760117
Validation loss: 2.368504469822027

Epoch: 6| Step: 2
Training loss: 0.5628399086843843
Validation loss: 2.361248518532385

Epoch: 6| Step: 3
Training loss: 0.6969401136692598
Validation loss: 2.3876335016091272

Epoch: 6| Step: 4
Training loss: 1.3624899680092035
Validation loss: 2.3992957720992303

Epoch: 6| Step: 5
Training loss: 0.6897604368193812
Validation loss: 2.393681360554012

Epoch: 6| Step: 6
Training loss: 0.7083271016987462
Validation loss: 2.375196285804424

Epoch: 6| Step: 7
Training loss: 0.7336604923847561
Validation loss: 2.3736137625558826

Epoch: 6| Step: 8
Training loss: 0.7688376306970109
Validation loss: 2.3503473361175

Epoch: 6| Step: 9
Training loss: 0.7406640730582675
Validation loss: 2.3303943713702173

Epoch: 6| Step: 10
Training loss: 0.9635227442077596
Validation loss: 2.352629996823955

Epoch: 6| Step: 11
Training loss: 0.6708244938198908
Validation loss: 2.350722654935202

Epoch: 6| Step: 12
Training loss: 0.8910757229349584
Validation loss: 2.3781307463857937

Epoch: 6| Step: 13
Training loss: 1.067653834495006
Validation loss: 2.363644544244294

Epoch: 295| Step: 0
Training loss: 0.6315017830694402
Validation loss: 2.3488228560596722

Epoch: 6| Step: 1
Training loss: 0.5043086729435144
Validation loss: 2.382366495470857

Epoch: 6| Step: 2
Training loss: 0.7834616065681647
Validation loss: 2.3961012142560283

Epoch: 6| Step: 3
Training loss: 0.6654128314078712
Validation loss: 2.364878502476752

Epoch: 6| Step: 4
Training loss: 1.0681705621830957
Validation loss: 2.3858830387036094

Epoch: 6| Step: 5
Training loss: 0.9699546952826605
Validation loss: 2.380076771872641

Epoch: 6| Step: 6
Training loss: 0.6018683659157211
Validation loss: 2.3697945310910473

Epoch: 6| Step: 7
Training loss: 0.8230441071219811
Validation loss: 2.365722046690786

Epoch: 6| Step: 8
Training loss: 0.8496495029137096
Validation loss: 2.3806435695176775

Epoch: 6| Step: 9
Training loss: 0.7891421136255728
Validation loss: 2.3881625638663975

Epoch: 6| Step: 10
Training loss: 0.8342988897464136
Validation loss: 2.3519497490777312

Epoch: 6| Step: 11
Training loss: 0.5239682709173048
Validation loss: 2.3525187399721084

Epoch: 6| Step: 12
Training loss: 1.1712910532397727
Validation loss: 2.334023304049672

Epoch: 6| Step: 13
Training loss: 0.8420141519412824
Validation loss: 2.3037102898323454

Epoch: 296| Step: 0
Training loss: 0.6599250478883871
Validation loss: 2.2936207711678342

Epoch: 6| Step: 1
Training loss: 1.0205772558796375
Validation loss: 2.274938664764008

Epoch: 6| Step: 2
Training loss: 0.7121097834633531
Validation loss: 2.2584669797714483

Epoch: 6| Step: 3
Training loss: 0.7417668807085971
Validation loss: 2.318434485214263

Epoch: 6| Step: 4
Training loss: 0.9346133613836228
Validation loss: 2.333378734967279

Epoch: 6| Step: 5
Training loss: 1.130279181350291
Validation loss: 2.362569074548191

Epoch: 6| Step: 6
Training loss: 0.6456302867130106
Validation loss: 2.353952918030412

Epoch: 6| Step: 7
Training loss: 0.6785023979518517
Validation loss: 2.396977519945016

Epoch: 6| Step: 8
Training loss: 0.7107854408045016
Validation loss: 2.4218905572461034

Epoch: 6| Step: 9
Training loss: 0.9491216978841869
Validation loss: 2.4198412509123295

Epoch: 6| Step: 10
Training loss: 1.004805877973135
Validation loss: 2.438481621488932

Epoch: 6| Step: 11
Training loss: 0.760482606685155
Validation loss: 2.390639785827042

Epoch: 6| Step: 12
Training loss: 0.8135205974773081
Validation loss: 2.389853733555739

Epoch: 6| Step: 13
Training loss: 0.3047589438380085
Validation loss: 2.379467750923862

Epoch: 297| Step: 0
Training loss: 0.5267151653718918
Validation loss: 2.338033252584824

Epoch: 6| Step: 1
Training loss: 0.7184494468223306
Validation loss: 2.3818421425323364

Epoch: 6| Step: 2
Training loss: 1.019335907093522
Validation loss: 2.3805129824100026

Epoch: 6| Step: 3
Training loss: 0.9409910687337939
Validation loss: 2.359121267562644

Epoch: 6| Step: 4
Training loss: 0.734124607659613
Validation loss: 2.3386197268394597

Epoch: 6| Step: 5
Training loss: 0.7899863622792027
Validation loss: 2.3614438103239577

Epoch: 6| Step: 6
Training loss: 0.9022498474142104
Validation loss: 2.336941937602933

Epoch: 6| Step: 7
Training loss: 1.2588236280952947
Validation loss: 2.3725961988891857

Epoch: 6| Step: 8
Training loss: 0.624490387099645
Validation loss: 2.3571160622403635

Epoch: 6| Step: 9
Training loss: 0.812441310230074
Validation loss: 2.3873991327680097

Epoch: 6| Step: 10
Training loss: 0.9664101800245032
Validation loss: 2.3852011884245368

Epoch: 6| Step: 11
Training loss: 0.924980912140488
Validation loss: 2.381449329414894

Epoch: 6| Step: 12
Training loss: 0.47301069478813784
Validation loss: 2.363942809305521

Epoch: 6| Step: 13
Training loss: 0.3546486501381114
Validation loss: 2.381948144913572

Epoch: 298| Step: 0
Training loss: 0.8113983829145559
Validation loss: 2.359875386975096

Epoch: 6| Step: 1
Training loss: 0.5235781124902427
Validation loss: 2.3516498855098247

Epoch: 6| Step: 2
Training loss: 1.1269423353713344
Validation loss: 2.356062753234931

Epoch: 6| Step: 3
Training loss: 0.6964364985828788
Validation loss: 2.3304976410137357

Epoch: 6| Step: 4
Training loss: 0.9899756339956814
Validation loss: 2.3003489514065327

Epoch: 6| Step: 5
Training loss: 0.6116107372739181
Validation loss: 2.312610511611357

Epoch: 6| Step: 6
Training loss: 0.9680327559792926
Validation loss: 2.3172474116046327

Epoch: 6| Step: 7
Training loss: 1.0594487414956084
Validation loss: 2.3395242640866516

Epoch: 6| Step: 8
Training loss: 0.48946487400478644
Validation loss: 2.3459944175015477

Epoch: 6| Step: 9
Training loss: 0.6215148553860524
Validation loss: 2.3330665423403865

Epoch: 6| Step: 10
Training loss: 0.6525930510779644
Validation loss: 2.361264619616495

Epoch: 6| Step: 11
Training loss: 0.8845156891327887
Validation loss: 2.3561569136726854

Epoch: 6| Step: 12
Training loss: 0.7539785083672558
Validation loss: 2.3572780953616137

Epoch: 6| Step: 13
Training loss: 0.47578523129956907
Validation loss: 2.360995921253286

Epoch: 299| Step: 0
Training loss: 0.3174689542805589
Validation loss: 2.360488470218994

Epoch: 6| Step: 1
Training loss: 0.7613096263315475
Validation loss: 2.3844940046180443

Epoch: 6| Step: 2
Training loss: 0.6208052294939173
Validation loss: 2.36778908737341

Epoch: 6| Step: 3
Training loss: 0.5607073883026377
Validation loss: 2.354855267278555

Epoch: 6| Step: 4
Training loss: 0.5163644343772497
Validation loss: 2.3517872420168198

Epoch: 6| Step: 5
Training loss: 0.6419717310195742
Validation loss: 2.360883855489524

Epoch: 6| Step: 6
Training loss: 0.9290682228751276
Validation loss: 2.344381833519416

Epoch: 6| Step: 7
Training loss: 1.2161722064647271
Validation loss: 2.335672890685419

Epoch: 6| Step: 8
Training loss: 0.6188836271316115
Validation loss: 2.332993377327852

Epoch: 6| Step: 9
Training loss: 0.5092229183151663
Validation loss: 2.298631903717468

Epoch: 6| Step: 10
Training loss: 1.1534426864056808
Validation loss: 2.328222599366404

Epoch: 6| Step: 11
Training loss: 0.9949280443962536
Validation loss: 2.321161223126849

Epoch: 6| Step: 12
Training loss: 0.5891923149205927
Validation loss: 2.3239425300638166

Epoch: 6| Step: 13
Training loss: 0.7006295744910789
Validation loss: 2.3080107436136306

Epoch: 300| Step: 0
Training loss: 0.8817005074598114
Validation loss: 2.342202874914105

Epoch: 6| Step: 1
Training loss: 0.6889876612636695
Validation loss: 2.34762945871902

Epoch: 6| Step: 2
Training loss: 0.9097439073367517
Validation loss: 2.3331368937915973

Epoch: 6| Step: 3
Training loss: 0.7182035027101192
Validation loss: 2.340393099430514

Epoch: 6| Step: 4
Training loss: 0.9878563551805554
Validation loss: 2.2973716432736717

Epoch: 6| Step: 5
Training loss: 0.7261473587436731
Validation loss: 2.3152518739796144

Epoch: 6| Step: 6
Training loss: 0.67656730403472
Validation loss: 2.3473443824761584

Epoch: 6| Step: 7
Training loss: 0.5704870871253502
Validation loss: 2.3513014470011275

Epoch: 6| Step: 8
Training loss: 0.7000062865588048
Validation loss: 2.38096846772105

Epoch: 6| Step: 9
Training loss: 0.3566932756348373
Validation loss: 2.369513183443515

Epoch: 6| Step: 10
Training loss: 0.7113358775286713
Validation loss: 2.3730418083122986

Epoch: 6| Step: 11
Training loss: 1.1443018764798827
Validation loss: 2.3766704685201083

Epoch: 6| Step: 12
Training loss: 0.6452452432899776
Validation loss: 2.3951819323918113

Epoch: 6| Step: 13
Training loss: 0.426501670803943
Validation loss: 2.3708341112093576

Epoch: 301| Step: 0
Training loss: 0.7484055896558448
Validation loss: 2.357773316823774

Epoch: 6| Step: 1
Training loss: 0.6541694858717053
Validation loss: 2.366851129698983

Epoch: 6| Step: 2
Training loss: 0.6311598260132922
Validation loss: 2.314098680240008

Epoch: 6| Step: 3
Training loss: 0.6699726319061132
Validation loss: 2.298593864214703

Epoch: 6| Step: 4
Training loss: 0.547253287133408
Validation loss: 2.3224913067267936

Epoch: 6| Step: 5
Training loss: 0.4839860523555036
Validation loss: 2.276194464938437

Epoch: 6| Step: 6
Training loss: 0.4842512526409784
Validation loss: 2.282776392581333

Epoch: 6| Step: 7
Training loss: 1.0051463738882382
Validation loss: 2.256223330298788

Epoch: 6| Step: 8
Training loss: 1.0891781760563273
Validation loss: 2.290173863428707

Epoch: 6| Step: 9
Training loss: 0.7662356141001672
Validation loss: 2.323822190056357

Epoch: 6| Step: 10
Training loss: 0.9091999449147964
Validation loss: 2.2888810661492998

Epoch: 6| Step: 11
Training loss: 1.0671944971260134
Validation loss: 2.310016843157896

Epoch: 6| Step: 12
Training loss: 0.5628153923422093
Validation loss: 2.3480853187444426

Epoch: 6| Step: 13
Training loss: 0.7799808111031238
Validation loss: 2.373510892358533

Epoch: 302| Step: 0
Training loss: 0.8863902891037684
Validation loss: 2.3462910517965376

Epoch: 6| Step: 1
Training loss: 0.7489668564892881
Validation loss: 2.3685610888575805

Epoch: 6| Step: 2
Training loss: 0.5363157200055915
Validation loss: 2.3432137114350096

Epoch: 6| Step: 3
Training loss: 0.6102008603012737
Validation loss: 2.353149108846015

Epoch: 6| Step: 4
Training loss: 0.8176052652183874
Validation loss: 2.3203628814653556

Epoch: 6| Step: 5
Training loss: 0.5860478360877124
Validation loss: 2.3104589534991424

Epoch: 6| Step: 6
Training loss: 0.4847427172170314
Validation loss: 2.2921362092890325

Epoch: 6| Step: 7
Training loss: 0.4540073091868059
Validation loss: 2.2975998220972764

Epoch: 6| Step: 8
Training loss: 1.1738388391091474
Validation loss: 2.3049842616992415

Epoch: 6| Step: 9
Training loss: 0.9163397437220993
Validation loss: 2.3041929553876765

Epoch: 6| Step: 10
Training loss: 0.4396564606621254
Validation loss: 2.312713520066887

Epoch: 6| Step: 11
Training loss: 0.648489800607538
Validation loss: 2.3521296014571837

Epoch: 6| Step: 12
Training loss: 0.9345681121704603
Validation loss: 2.3476501620920818

Epoch: 6| Step: 13
Training loss: 0.7417493229429976
Validation loss: 2.3612013494868207

Epoch: 303| Step: 0
Training loss: 0.8984246957944593
Validation loss: 2.3376336426758244

Epoch: 6| Step: 1
Training loss: 0.5231782071709291
Validation loss: 2.346190048592478

Epoch: 6| Step: 2
Training loss: 0.6477555055108264
Validation loss: 2.34296998255501

Epoch: 6| Step: 3
Training loss: 0.7372011225639569
Validation loss: 2.3409904647341886

Epoch: 6| Step: 4
Training loss: 0.4585238804791418
Validation loss: 2.3174977019609084

Epoch: 6| Step: 5
Training loss: 0.6007315606451601
Validation loss: 2.333813111103263

Epoch: 6| Step: 6
Training loss: 0.5177288195920865
Validation loss: 2.3162625009901237

Epoch: 6| Step: 7
Training loss: 0.47258370213143025
Validation loss: 2.3691749607801027

Epoch: 6| Step: 8
Training loss: 0.6179979049807596
Validation loss: 2.389088040567736

Epoch: 6| Step: 9
Training loss: 1.1190986558857197
Validation loss: 2.3875531540781987

Epoch: 6| Step: 10
Training loss: 0.9535179578853388
Validation loss: 2.3636879441102696

Epoch: 6| Step: 11
Training loss: 0.7255219833098364
Validation loss: 2.363042116011797

Epoch: 6| Step: 12
Training loss: 0.7210452707180921
Validation loss: 2.322700216335687

Epoch: 6| Step: 13
Training loss: 1.0403258022421586
Validation loss: 2.344486303036302

Epoch: 304| Step: 0
Training loss: 0.8918963610330547
Validation loss: 2.359724872228245

Epoch: 6| Step: 1
Training loss: 0.6552064409415648
Validation loss: 2.3399015851549216

Epoch: 6| Step: 2
Training loss: 1.1774631776336903
Validation loss: 2.3213807262117996

Epoch: 6| Step: 3
Training loss: 0.8135181063774743
Validation loss: 2.3099288581991626

Epoch: 6| Step: 4
Training loss: 0.5619617111799574
Validation loss: 2.289651386406229

Epoch: 6| Step: 5
Training loss: 0.732024021174057
Validation loss: 2.314618319709076

Epoch: 6| Step: 6
Training loss: 0.7679921749108741
Validation loss: 2.3198624367041427

Epoch: 6| Step: 7
Training loss: 0.6775701142379322
Validation loss: 2.3217330897862456

Epoch: 6| Step: 8
Training loss: 0.8265512736086327
Validation loss: 2.333317556269289

Epoch: 6| Step: 9
Training loss: 0.5276194946482633
Validation loss: 2.368330203284883

Epoch: 6| Step: 10
Training loss: 0.690218233482163
Validation loss: 2.3716084984385923

Epoch: 6| Step: 11
Training loss: 0.7291269064462564
Validation loss: 2.378171039775062

Epoch: 6| Step: 12
Training loss: 0.4843664476193373
Validation loss: 2.4536657124782693

Epoch: 6| Step: 13
Training loss: 0.43440831626080706
Validation loss: 2.4296448796858914

Epoch: 305| Step: 0
Training loss: 0.6660364097417188
Validation loss: 2.4069064112902407

Epoch: 6| Step: 1
Training loss: 0.8357951675885107
Validation loss: 2.3907692833730345

Epoch: 6| Step: 2
Training loss: 0.6813715974970871
Validation loss: 2.3415545347123947

Epoch: 6| Step: 3
Training loss: 0.419788783073776
Validation loss: 2.339536809818016

Epoch: 6| Step: 4
Training loss: 0.4390703187022344
Validation loss: 2.3241630737110786

Epoch: 6| Step: 5
Training loss: 1.0581357746510773
Validation loss: 2.321091608777323

Epoch: 6| Step: 6
Training loss: 0.6382251075136972
Validation loss: 2.312647764079618

Epoch: 6| Step: 7
Training loss: 0.5654016991838386
Validation loss: 2.3060602787208833

Epoch: 6| Step: 8
Training loss: 0.5124738232975425
Validation loss: 2.3156653593479564

Epoch: 6| Step: 9
Training loss: 0.6570032882637172
Validation loss: 2.3097178000526886

Epoch: 6| Step: 10
Training loss: 0.4967781512323427
Validation loss: 2.346945202269594

Epoch: 6| Step: 11
Training loss: 1.0660101186261346
Validation loss: 2.3555174582263074

Epoch: 6| Step: 12
Training loss: 1.0616584137536407
Validation loss: 2.349267721531748

Epoch: 6| Step: 13
Training loss: 0.8585389665615022
Validation loss: 2.3512880372760043

Epoch: 306| Step: 0
Training loss: 0.9924621502267585
Validation loss: 2.386030702130918

Epoch: 6| Step: 1
Training loss: 0.5861616341744805
Validation loss: 2.33785806896168

Epoch: 6| Step: 2
Training loss: 0.6413625332875876
Validation loss: 2.3799844926344154

Epoch: 6| Step: 3
Training loss: 0.6052844843882653
Validation loss: 2.3616374272689487

Epoch: 6| Step: 4
Training loss: 0.562021104616592
Validation loss: 2.3756942441364495

Epoch: 6| Step: 5
Training loss: 0.7205793072787395
Validation loss: 2.3809379435393048

Epoch: 6| Step: 6
Training loss: 0.7474239135854741
Validation loss: 2.3812244542565986

Epoch: 6| Step: 7
Training loss: 0.6974225121528635
Validation loss: 2.3554924634629795

Epoch: 6| Step: 8
Training loss: 0.45215140356157946
Validation loss: 2.3663928309246924

Epoch: 6| Step: 9
Training loss: 0.7276767267643435
Validation loss: 2.3693322891390567

Epoch: 6| Step: 10
Training loss: 0.9603387161087698
Validation loss: 2.3939445601387668

Epoch: 6| Step: 11
Training loss: 0.7212507033716538
Validation loss: 2.3520204687295876

Epoch: 6| Step: 12
Training loss: 0.6627892573488641
Validation loss: 2.382453246110739

Epoch: 6| Step: 13
Training loss: 0.6340997577999454
Validation loss: 2.371205616495611

Epoch: 307| Step: 0
Training loss: 1.1020163825214129
Validation loss: 2.3483471812179495

Epoch: 6| Step: 1
Training loss: 0.546237846867827
Validation loss: 2.383548678123656

Epoch: 6| Step: 2
Training loss: 0.5855391865149812
Validation loss: 2.375661279188342

Epoch: 6| Step: 3
Training loss: 0.7719663635422092
Validation loss: 2.353604764649739

Epoch: 6| Step: 4
Training loss: 0.559013049271917
Validation loss: 2.3619266156888017

Epoch: 6| Step: 5
Training loss: 0.6926448094967599
Validation loss: 2.3980890691479417

Epoch: 6| Step: 6
Training loss: 0.5931624466839821
Validation loss: 2.3917997753737232

Epoch: 6| Step: 7
Training loss: 1.0771780416340657
Validation loss: 2.3739416520109033

Epoch: 6| Step: 8
Training loss: 0.21870082915667394
Validation loss: 2.331910884919225

Epoch: 6| Step: 9
Training loss: 0.6574923245812377
Validation loss: 2.3232477622511047

Epoch: 6| Step: 10
Training loss: 0.49639634042946296
Validation loss: 2.3059799182923437

Epoch: 6| Step: 11
Training loss: 0.5784153338141566
Validation loss: 2.2997755262131396

Epoch: 6| Step: 12
Training loss: 0.6674961180341902
Validation loss: 2.323444204099199

Epoch: 6| Step: 13
Training loss: 0.8404717514855369
Validation loss: 2.3037422478964458

Epoch: 308| Step: 0
Training loss: 1.062146464602006
Validation loss: 2.307184090788536

Epoch: 6| Step: 1
Training loss: 0.5612284275148575
Validation loss: 2.306232613131918

Epoch: 6| Step: 2
Training loss: 0.28827030295493017
Validation loss: 2.315413539504909

Epoch: 6| Step: 3
Training loss: 0.9893277323378784
Validation loss: 2.335639951399153

Epoch: 6| Step: 4
Training loss: 0.6521071730288955
Validation loss: 2.3296269275982926

Epoch: 6| Step: 5
Training loss: 0.545500034996612
Validation loss: 2.3323279025998653

Epoch: 6| Step: 6
Training loss: 0.6172613751586571
Validation loss: 2.3376027050731243

Epoch: 6| Step: 7
Training loss: 0.23108712175882748
Validation loss: 2.3387084093185906

Epoch: 6| Step: 8
Training loss: 0.7107526937212972
Validation loss: 2.2908840741212733

Epoch: 6| Step: 9
Training loss: 0.7605478922519239
Validation loss: 2.3031497197245128

Epoch: 6| Step: 10
Training loss: 0.7215229117072653
Validation loss: 2.296087325140173

Epoch: 6| Step: 11
Training loss: 0.7444752819244057
Validation loss: 2.3052954860256585

Epoch: 6| Step: 12
Training loss: 0.7948207931547848
Validation loss: 2.301740869133285

Epoch: 6| Step: 13
Training loss: 0.28812276313889873
Validation loss: 2.3084036740145772

Epoch: 309| Step: 0
Training loss: 0.561153867428119
Validation loss: 2.3053276050469673

Epoch: 6| Step: 1
Training loss: 0.40974785590760027
Validation loss: 2.3356140666773832

Epoch: 6| Step: 2
Training loss: 0.6790821405090474
Validation loss: 2.3160825437234087

Epoch: 6| Step: 3
Training loss: 0.6878838334622901
Validation loss: 2.3294358440263707

Epoch: 6| Step: 4
Training loss: 0.9755042483903514
Validation loss: 2.337495765399239

Epoch: 6| Step: 5
Training loss: 0.40453514044207045
Validation loss: 2.3478046448346053

Epoch: 6| Step: 6
Training loss: 0.794896943172346
Validation loss: 2.34775068753695

Epoch: 6| Step: 7
Training loss: 0.38202434291719434
Validation loss: 2.391484402530346

Epoch: 6| Step: 8
Training loss: 0.7762319770968993
Validation loss: 2.3689800871824556

Epoch: 6| Step: 9
Training loss: 0.5386045141336891
Validation loss: 2.3830141716119244

Epoch: 6| Step: 10
Training loss: 0.9082872577378645
Validation loss: 2.380706513817006

Epoch: 6| Step: 11
Training loss: 0.6426791775446604
Validation loss: 2.404501618724369

Epoch: 6| Step: 12
Training loss: 0.7711142895715796
Validation loss: 2.4091418835071057

Epoch: 6| Step: 13
Training loss: 0.8721454242000378
Validation loss: 2.405207381056007

Epoch: 310| Step: 0
Training loss: 0.567763235488005
Validation loss: 2.368243382382198

Epoch: 6| Step: 1
Training loss: 0.7872428686182992
Validation loss: 2.3459834088750293

Epoch: 6| Step: 2
Training loss: 0.6796289177564696
Validation loss: 2.3294705405373732

Epoch: 6| Step: 3
Training loss: 0.7657620832764567
Validation loss: 2.315995184098189

Epoch: 6| Step: 4
Training loss: 0.8229485437198711
Validation loss: 2.343502233391356

Epoch: 6| Step: 5
Training loss: 0.6581081695433294
Validation loss: 2.3215361829054966

Epoch: 6| Step: 6
Training loss: 0.8612782989414857
Validation loss: 2.3283263848419566

Epoch: 6| Step: 7
Training loss: 0.5202344566673974
Validation loss: 2.3141072526551185

Epoch: 6| Step: 8
Training loss: 0.6807716098581775
Validation loss: 2.2861505796936514

Epoch: 6| Step: 9
Training loss: 0.4754453290623437
Validation loss: 2.2879155899112757

Epoch: 6| Step: 10
Training loss: 0.4905255733262863
Validation loss: 2.289544220280071

Epoch: 6| Step: 11
Training loss: 0.7513762403854568
Validation loss: 2.3305361387957984

Epoch: 6| Step: 12
Training loss: 0.6696880366207079
Validation loss: 2.338035076602737

Epoch: 6| Step: 13
Training loss: 0.26546884602976606
Validation loss: 2.358277713640531

Epoch: 311| Step: 0
Training loss: 0.725317472796669
Validation loss: 2.3762896824388275

Epoch: 6| Step: 1
Training loss: 0.7459760642980137
Validation loss: 2.379588402756737

Epoch: 6| Step: 2
Training loss: 0.667042117393326
Validation loss: 2.3680219982191617

Epoch: 6| Step: 3
Training loss: 0.5851708546587042
Validation loss: 2.400796107119295

Epoch: 6| Step: 4
Training loss: 0.7419447652509097
Validation loss: 2.3919648039278614

Epoch: 6| Step: 5
Training loss: 0.47743236387276405
Validation loss: 2.3518466463681733

Epoch: 6| Step: 6
Training loss: 0.518677231843857
Validation loss: 2.335494629928

Epoch: 6| Step: 7
Training loss: 0.6698419951479763
Validation loss: 2.3206256914591115

Epoch: 6| Step: 8
Training loss: 0.6795087338083471
Validation loss: 2.3009364884633228

Epoch: 6| Step: 9
Training loss: 0.847745864279853
Validation loss: 2.2922527111111877

Epoch: 6| Step: 10
Training loss: 0.8685672540358202
Validation loss: 2.2966910132224347

Epoch: 6| Step: 11
Training loss: 0.6760734852345075
Validation loss: 2.305677469608785

Epoch: 6| Step: 12
Training loss: 0.5594716143153099
Validation loss: 2.335436905181197

Epoch: 6| Step: 13
Training loss: 0.5719098231651776
Validation loss: 2.3038495197235025

Epoch: 312| Step: 0
Training loss: 0.7642317960752986
Validation loss: 2.31497069709245

Epoch: 6| Step: 1
Training loss: 0.8840557222993115
Validation loss: 2.34849820137889

Epoch: 6| Step: 2
Training loss: 0.47278664106615703
Validation loss: 2.314978537046178

Epoch: 6| Step: 3
Training loss: 0.5937897016402501
Validation loss: 2.3249739344760285

Epoch: 6| Step: 4
Training loss: 0.8538894009476583
Validation loss: 2.330711328288455

Epoch: 6| Step: 5
Training loss: 0.49666400484144124
Validation loss: 2.342894466218422

Epoch: 6| Step: 6
Training loss: 0.7520451873305745
Validation loss: 2.301128413420267

Epoch: 6| Step: 7
Training loss: 0.38681360487873356
Validation loss: 2.318918432441255

Epoch: 6| Step: 8
Training loss: 0.45020319007055126
Validation loss: 2.304576135123925

Epoch: 6| Step: 9
Training loss: 0.6381805816789453
Validation loss: 2.353479356009298

Epoch: 6| Step: 10
Training loss: 0.8855683514683524
Validation loss: 2.3517852820488003

Epoch: 6| Step: 11
Training loss: 0.8471094996258656
Validation loss: 2.3295436989909706

Epoch: 6| Step: 12
Training loss: 0.6196596875973356
Validation loss: 2.3206473471759628

Epoch: 6| Step: 13
Training loss: 0.36838830245703585
Validation loss: 2.2935366070563132

Epoch: 313| Step: 0
Training loss: 0.4754505787315862
Validation loss: 2.31361978098374

Epoch: 6| Step: 1
Training loss: 0.5212643905866988
Validation loss: 2.331250129773822

Epoch: 6| Step: 2
Training loss: 0.3781755618504481
Validation loss: 2.3417057444275367

Epoch: 6| Step: 3
Training loss: 0.7660856612741496
Validation loss: 2.35506279678177

Epoch: 6| Step: 4
Training loss: 0.9502873939677582
Validation loss: 2.337180051589001

Epoch: 6| Step: 5
Training loss: 0.6107468934544221
Validation loss: 2.3554677247475935

Epoch: 6| Step: 6
Training loss: 0.39963361306763107
Validation loss: 2.3108787063603

Epoch: 6| Step: 7
Training loss: 0.8186754149032699
Validation loss: 2.286216699712974

Epoch: 6| Step: 8
Training loss: 0.6323890210972705
Validation loss: 2.3143597911954767

Epoch: 6| Step: 9
Training loss: 0.7637716164784218
Validation loss: 2.3010037701410484

Epoch: 6| Step: 10
Training loss: 0.7517149709108201
Validation loss: 2.302692318489239

Epoch: 6| Step: 11
Training loss: 0.5367588355852297
Validation loss: 2.302399625047681

Epoch: 6| Step: 12
Training loss: 0.6216359201281756
Validation loss: 2.300070932122921

Epoch: 6| Step: 13
Training loss: 0.7203122037609757
Validation loss: 2.3373721242349865

Epoch: 314| Step: 0
Training loss: 0.7516819056074933
Validation loss: 2.3268690609371725

Epoch: 6| Step: 1
Training loss: 0.496213568087601
Validation loss: 2.331419368165687

Epoch: 6| Step: 2
Training loss: 0.7189669074453043
Validation loss: 2.3386378998963435

Epoch: 6| Step: 3
Training loss: 0.7975811540933042
Validation loss: 2.3535592568485995

Epoch: 6| Step: 4
Training loss: 0.6903044116201268
Validation loss: 2.3274692493646087

Epoch: 6| Step: 5
Training loss: 0.5331023962991354
Validation loss: 2.3536302211419144

Epoch: 6| Step: 6
Training loss: 0.784399512466462
Validation loss: 2.4125209832303063

Epoch: 6| Step: 7
Training loss: 0.6882833872663415
Validation loss: 2.411640611548023

Epoch: 6| Step: 8
Training loss: 0.6806649381831705
Validation loss: 2.3749283972472623

Epoch: 6| Step: 9
Training loss: 0.790496052717069
Validation loss: 2.339140073414794

Epoch: 6| Step: 10
Training loss: 0.6248087113427644
Validation loss: 2.3507247913717197

Epoch: 6| Step: 11
Training loss: 0.5177321294871411
Validation loss: 2.3225059136920594

Epoch: 6| Step: 12
Training loss: 0.8007164905693234
Validation loss: 2.3073470082335

Epoch: 6| Step: 13
Training loss: 0.4343206996047635
Validation loss: 2.3340273337217177

Epoch: 315| Step: 0
Training loss: 0.7947781969548084
Validation loss: 2.308118356861685

Epoch: 6| Step: 1
Training loss: 0.7274465207634382
Validation loss: 2.3322782143345746

Epoch: 6| Step: 2
Training loss: 0.44686563588715017
Validation loss: 2.3000352871949064

Epoch: 6| Step: 3
Training loss: 0.7284010728052023
Validation loss: 2.308461599435393

Epoch: 6| Step: 4
Training loss: 0.668267389652775
Validation loss: 2.3280138835885555

Epoch: 6| Step: 5
Training loss: 0.7957295431658953
Validation loss: 2.3146861672652226

Epoch: 6| Step: 6
Training loss: 0.6031895716596718
Validation loss: 2.2841878368419937

Epoch: 6| Step: 7
Training loss: 0.5876829724776897
Validation loss: 2.351777305899582

Epoch: 6| Step: 8
Training loss: 0.7512746152478926
Validation loss: 2.361932871939506

Epoch: 6| Step: 9
Training loss: 0.6253116307593333
Validation loss: 2.326564214160032

Epoch: 6| Step: 10
Training loss: 0.7317370251937914
Validation loss: 2.3481910670641386

Epoch: 6| Step: 11
Training loss: 0.4981303575148663
Validation loss: 2.331932456722935

Epoch: 6| Step: 12
Training loss: 0.5190527871065428
Validation loss: 2.3073772429457327

Epoch: 6| Step: 13
Training loss: 0.3435316692923346
Validation loss: 2.298523854136132

Epoch: 316| Step: 0
Training loss: 0.7291825338181293
Validation loss: 2.267842243124918

Epoch: 6| Step: 1
Training loss: 0.7890668056861563
Validation loss: 2.2358228807087785

Epoch: 6| Step: 2
Training loss: 0.5758894923419176
Validation loss: 2.248234777061083

Epoch: 6| Step: 3
Training loss: 0.5762980694694956
Validation loss: 2.27619419688291

Epoch: 6| Step: 4
Training loss: 0.9335731599843594
Validation loss: 2.277189375995552

Epoch: 6| Step: 5
Training loss: 0.26610964151395644
Validation loss: 2.311700026816048

Epoch: 6| Step: 6
Training loss: 0.7688879432041524
Validation loss: 2.3182035957908753

Epoch: 6| Step: 7
Training loss: 0.4603013319951355
Validation loss: 2.349734293015951

Epoch: 6| Step: 8
Training loss: 0.6973261873673521
Validation loss: 2.3473078553995146

Epoch: 6| Step: 9
Training loss: 0.4971866284212329
Validation loss: 2.3690997668184344

Epoch: 6| Step: 10
Training loss: 0.5892844422025285
Validation loss: 2.36334143500702

Epoch: 6| Step: 11
Training loss: 0.6439346789291124
Validation loss: 2.379193360964246

Epoch: 6| Step: 12
Training loss: 0.7904431944480843
Validation loss: 2.363286860476378

Epoch: 6| Step: 13
Training loss: 0.568698296974051
Validation loss: 2.3702330425159484

Epoch: 317| Step: 0
Training loss: 0.6594392844588065
Validation loss: 2.3422561084791296

Epoch: 6| Step: 1
Training loss: 0.5754154736034374
Validation loss: 2.3349286480395883

Epoch: 6| Step: 2
Training loss: 0.8580462500326712
Validation loss: 2.3166807950942694

Epoch: 6| Step: 3
Training loss: 0.5980694906691449
Validation loss: 2.2952378162398186

Epoch: 6| Step: 4
Training loss: 0.7853432427918833
Validation loss: 2.291555919143317

Epoch: 6| Step: 5
Training loss: 0.4814307653616462
Validation loss: 2.3168050419979247

Epoch: 6| Step: 6
Training loss: 0.7431199490541557
Validation loss: 2.317393175971949

Epoch: 6| Step: 7
Training loss: 0.5798176395722617
Validation loss: 2.3260909584644573

Epoch: 6| Step: 8
Training loss: 0.4335299264484386
Validation loss: 2.3501119089109754

Epoch: 6| Step: 9
Training loss: 0.8793272239433301
Validation loss: 2.352603667553422

Epoch: 6| Step: 10
Training loss: 0.6500397615008908
Validation loss: 2.320592843494689

Epoch: 6| Step: 11
Training loss: 0.266421777938298
Validation loss: 2.346543178070338

Epoch: 6| Step: 12
Training loss: 0.5510639520284
Validation loss: 2.33697890423761

Epoch: 6| Step: 13
Training loss: 0.2201483937087493
Validation loss: 2.320220584153006

Epoch: 318| Step: 0
Training loss: 0.3177536543846832
Validation loss: 2.318266420736416

Epoch: 6| Step: 1
Training loss: 0.5683795099526234
Validation loss: 2.3278950629085005

Epoch: 6| Step: 2
Training loss: 0.615120940877401
Validation loss: 2.3140757545789037

Epoch: 6| Step: 3
Training loss: 0.6257147278592848
Validation loss: 2.3173859498668095

Epoch: 6| Step: 4
Training loss: 0.6761214882661948
Validation loss: 2.3230345527014786

Epoch: 6| Step: 5
Training loss: 0.7570655523663945
Validation loss: 2.3338239178975426

Epoch: 6| Step: 6
Training loss: 0.8193497594092638
Validation loss: 2.3434477296017313

Epoch: 6| Step: 7
Training loss: 0.3957733205007725
Validation loss: 2.362476365513278

Epoch: 6| Step: 8
Training loss: 0.6025109431353294
Validation loss: 2.328585396173011

Epoch: 6| Step: 9
Training loss: 0.7397595495630582
Validation loss: 2.3654422115406177

Epoch: 6| Step: 10
Training loss: 0.5004809569776574
Validation loss: 2.335942554979421

Epoch: 6| Step: 11
Training loss: 0.5698054685670328
Validation loss: 2.3339099552432327

Epoch: 6| Step: 12
Training loss: 0.5573062597723055
Validation loss: 2.34182992473436

Epoch: 6| Step: 13
Training loss: 0.6058504193724411
Validation loss: 2.3230731129139026

Epoch: 319| Step: 0
Training loss: 0.6239441536219321
Validation loss: 2.288506676946829

Epoch: 6| Step: 1
Training loss: 0.7288228632258276
Validation loss: 2.288644327641087

Epoch: 6| Step: 2
Training loss: 0.605908117541005
Validation loss: 2.278821132872411

Epoch: 6| Step: 3
Training loss: 0.5244149717752825
Validation loss: 2.3155460611189453

Epoch: 6| Step: 4
Training loss: 0.562422614602494
Validation loss: 2.3176228784834687

Epoch: 6| Step: 5
Training loss: 0.7161876365714089
Validation loss: 2.345285503594463

Epoch: 6| Step: 6
Training loss: 0.6740257968380451
Validation loss: 2.385098080107637

Epoch: 6| Step: 7
Training loss: 0.693831699303285
Validation loss: 2.4268198945524406

Epoch: 6| Step: 8
Training loss: 0.8143549432282788
Validation loss: 2.453649227242476

Epoch: 6| Step: 9
Training loss: 0.4228693934110384
Validation loss: 2.4035004855021653

Epoch: 6| Step: 10
Training loss: 0.6786721417433236
Validation loss: 2.3817433250676077

Epoch: 6| Step: 11
Training loss: 0.49140538032103026
Validation loss: 2.3601855454679326

Epoch: 6| Step: 12
Training loss: 0.5048355877333628
Validation loss: 2.3121806874607738

Epoch: 6| Step: 13
Training loss: 0.6614687360611353
Validation loss: 2.276814789823499

Epoch: 320| Step: 0
Training loss: 0.79576216391118
Validation loss: 2.2926248439712498

Epoch: 6| Step: 1
Training loss: 0.6588860203778999
Validation loss: 2.287382579039942

Epoch: 6| Step: 2
Training loss: 0.6249937057178173
Validation loss: 2.305848380620735

Epoch: 6| Step: 3
Training loss: 0.6357168259960261
Validation loss: 2.3269701676631653

Epoch: 6| Step: 4
Training loss: 0.6633944573187823
Validation loss: 2.322677269615437

Epoch: 6| Step: 5
Training loss: 0.6501942243535432
Validation loss: 2.334005656887405

Epoch: 6| Step: 6
Training loss: 0.5844185532440119
Validation loss: 2.3642208570889243

Epoch: 6| Step: 7
Training loss: 0.49606769222999314
Validation loss: 2.370881884718785

Epoch: 6| Step: 8
Training loss: 0.5191428948690765
Validation loss: 2.357893812089763

Epoch: 6| Step: 9
Training loss: 0.7370994838097452
Validation loss: 2.3874056626679208

Epoch: 6| Step: 10
Training loss: 0.674878261325825
Validation loss: 2.3876780496763375

Epoch: 6| Step: 11
Training loss: 0.43634908723124843
Validation loss: 2.3872600779552156

Epoch: 6| Step: 12
Training loss: 0.7583712061832238
Validation loss: 2.3834422032074047

Epoch: 6| Step: 13
Training loss: 0.530922171476406
Validation loss: 2.359216981542971

Epoch: 321| Step: 0
Training loss: 0.5572107440509628
Validation loss: 2.3311139713321434

Epoch: 6| Step: 1
Training loss: 0.5008896125754427
Validation loss: 2.333091326291621

Epoch: 6| Step: 2
Training loss: 0.7216476412666725
Validation loss: 2.354648553472681

Epoch: 6| Step: 3
Training loss: 0.5131786865232046
Validation loss: 2.311854507699715

Epoch: 6| Step: 4
Training loss: 0.7230344452863827
Validation loss: 2.348583418434795

Epoch: 6| Step: 5
Training loss: 0.5278030938077699
Validation loss: 2.320330102701221

Epoch: 6| Step: 6
Training loss: 0.6003217410677498
Validation loss: 2.290703153307335

Epoch: 6| Step: 7
Training loss: 0.6196876780576541
Validation loss: 2.299798788388777

Epoch: 6| Step: 8
Training loss: 0.7124331744126551
Validation loss: 2.291368946936073

Epoch: 6| Step: 9
Training loss: 0.601195533093592
Validation loss: 2.315388618923278

Epoch: 6| Step: 10
Training loss: 0.4428257356441049
Validation loss: 2.3169915564239525

Epoch: 6| Step: 11
Training loss: 0.4787289980621862
Validation loss: 2.3292001632643684

Epoch: 6| Step: 12
Training loss: 0.8625993063327999
Validation loss: 2.37552249452422

Epoch: 6| Step: 13
Training loss: 0.5954604608283638
Validation loss: 2.358254178203463

Epoch: 322| Step: 0
Training loss: 0.48901620103369614
Validation loss: 2.391429269325844

Epoch: 6| Step: 1
Training loss: 0.5432220801101223
Validation loss: 2.4056417492570223

Epoch: 6| Step: 2
Training loss: 0.6692791405148634
Validation loss: 2.4082559152087626

Epoch: 6| Step: 3
Training loss: 0.8641066596834182
Validation loss: 2.351105565173385

Epoch: 6| Step: 4
Training loss: 0.5029476718094408
Validation loss: 2.342069305176446

Epoch: 6| Step: 5
Training loss: 0.7870063051652204
Validation loss: 2.3063977130377786

Epoch: 6| Step: 6
Training loss: 0.5598935031103096
Validation loss: 2.296129018624654

Epoch: 6| Step: 7
Training loss: 0.6439819538404606
Validation loss: 2.2880039082125982

Epoch: 6| Step: 8
Training loss: 0.4088234819046151
Validation loss: 2.2605869820127897

Epoch: 6| Step: 9
Training loss: 0.45648108078190536
Validation loss: 2.2646863068450673

Epoch: 6| Step: 10
Training loss: 0.44858277124398865
Validation loss: 2.261012641872521

Epoch: 6| Step: 11
Training loss: 0.6556756821671781
Validation loss: 2.3088302317672085

Epoch: 6| Step: 12
Training loss: 0.6254341524929817
Validation loss: 2.302871594388524

Epoch: 6| Step: 13
Training loss: 0.32432815130757153
Validation loss: 2.322749677391312

Epoch: 323| Step: 0
Training loss: 0.6773903712999265
Validation loss: 2.3775534695457403

Epoch: 6| Step: 1
Training loss: 0.3957933313669601
Validation loss: 2.404138975875595

Epoch: 6| Step: 2
Training loss: 0.7502644390584062
Validation loss: 2.4672759611312185

Epoch: 6| Step: 3
Training loss: 0.5560969056321011
Validation loss: 2.4629901711912137

Epoch: 6| Step: 4
Training loss: 0.5621198323160518
Validation loss: 2.4160956881144346

Epoch: 6| Step: 5
Training loss: 0.6021353483556119
Validation loss: 2.3884852983321854

Epoch: 6| Step: 6
Training loss: 0.5888796626298936
Validation loss: 2.3388734758376333

Epoch: 6| Step: 7
Training loss: 0.7838668864454863
Validation loss: 2.314547050940958

Epoch: 6| Step: 8
Training loss: 0.7186194591564071
Validation loss: 2.2996279795934425

Epoch: 6| Step: 9
Training loss: 0.6083764428928337
Validation loss: 2.3296689407937485

Epoch: 6| Step: 10
Training loss: 0.42460931253301165
Validation loss: 2.2885687550110383

Epoch: 6| Step: 11
Training loss: 0.4454272272994966
Validation loss: 2.307276443753077

Epoch: 6| Step: 12
Training loss: 0.4429926763191807
Validation loss: 2.3042039500555753

Epoch: 6| Step: 13
Training loss: 0.16815456935125644
Validation loss: 2.285565570148832

Epoch: 324| Step: 0
Training loss: 0.49031060222698525
Validation loss: 2.27750518535649

Epoch: 6| Step: 1
Training loss: 0.7452648411513996
Validation loss: 2.2881374979974574

Epoch: 6| Step: 2
Training loss: 0.6953647036725307
Validation loss: 2.3173577737047344

Epoch: 6| Step: 3
Training loss: 0.5754643379433808
Validation loss: 2.3146221253740995

Epoch: 6| Step: 4
Training loss: 0.5387782024427674
Validation loss: 2.3022803632120676

Epoch: 6| Step: 5
Training loss: 0.8657656861706433
Validation loss: 2.278995854415665

Epoch: 6| Step: 6
Training loss: 0.4046010149592757
Validation loss: 2.3159059476300334

Epoch: 6| Step: 7
Training loss: 0.32098973021018273
Validation loss: 2.309732718664174

Epoch: 6| Step: 8
Training loss: 0.6039458534510197
Validation loss: 2.308522114227809

Epoch: 6| Step: 9
Training loss: 0.33260565047267143
Validation loss: 2.3155433989920478

Epoch: 6| Step: 10
Training loss: 0.611160425944212
Validation loss: 2.329226824774399

Epoch: 6| Step: 11
Training loss: 0.1753739247091993
Validation loss: 2.3329631182843205

Epoch: 6| Step: 12
Training loss: 0.6919767536850739
Validation loss: 2.318605981158708

Epoch: 6| Step: 13
Training loss: 0.6563637271611221
Validation loss: 2.310768727660822

Epoch: 325| Step: 0
Training loss: 0.7073215710512583
Validation loss: 2.3098267544225477

Epoch: 6| Step: 1
Training loss: 0.5535046228407015
Validation loss: 2.324246632591514

Epoch: 6| Step: 2
Training loss: 0.6332565680418119
Validation loss: 2.315390751424729

Epoch: 6| Step: 3
Training loss: 0.5880365539107233
Validation loss: 2.3413808978085333

Epoch: 6| Step: 4
Training loss: 0.5999155163890594
Validation loss: 2.337185991266773

Epoch: 6| Step: 5
Training loss: 0.470047680384197
Validation loss: 2.33311709121262

Epoch: 6| Step: 6
Training loss: 0.5137342697946785
Validation loss: 2.3282360736706593

Epoch: 6| Step: 7
Training loss: 0.405930283256911
Validation loss: 2.3478776960647973

Epoch: 6| Step: 8
Training loss: 0.49840783894935153
Validation loss: 2.3645411336701168

Epoch: 6| Step: 9
Training loss: 0.40333693795655773
Validation loss: 2.3590300911689237

Epoch: 6| Step: 10
Training loss: 0.6533389922751689
Validation loss: 2.341424424028044

Epoch: 6| Step: 11
Training loss: 0.4802991055846598
Validation loss: 2.3547733037820233

Epoch: 6| Step: 12
Training loss: 0.730942108674706
Validation loss: 2.3552544190072626

Epoch: 6| Step: 13
Training loss: 0.3574791950894467
Validation loss: 2.357436961511715

Epoch: 326| Step: 0
Training loss: 0.5809188042762196
Validation loss: 2.3110164186421724

Epoch: 6| Step: 1
Training loss: 0.31506160837511554
Validation loss: 2.2908890170114873

Epoch: 6| Step: 2
Training loss: 0.5500957470696
Validation loss: 2.294681931036972

Epoch: 6| Step: 3
Training loss: 0.4139995347137877
Validation loss: 2.2937408587909074

Epoch: 6| Step: 4
Training loss: 0.2902302224438487
Validation loss: 2.2980749162908323

Epoch: 6| Step: 5
Training loss: 0.5333795500141729
Validation loss: 2.2929880741962116

Epoch: 6| Step: 6
Training loss: 0.20480959432203674
Validation loss: 2.329901697348254

Epoch: 6| Step: 7
Training loss: 0.6057598029731641
Validation loss: 2.321150592629762

Epoch: 6| Step: 8
Training loss: 0.396772834063061
Validation loss: 2.3260947938527616

Epoch: 6| Step: 9
Training loss: 0.6734300404996251
Validation loss: 2.318473644398326

Epoch: 6| Step: 10
Training loss: 0.5883737650919708
Validation loss: 2.322860418744444

Epoch: 6| Step: 11
Training loss: 0.3758691411324502
Validation loss: 2.3062875095397026

Epoch: 6| Step: 12
Training loss: 0.9599309472243438
Validation loss: 2.2747137090289353

Epoch: 6| Step: 13
Training loss: 0.9734007655479128
Validation loss: 2.2874898929463443

Epoch: 327| Step: 0
Training loss: 0.7164094797974709
Validation loss: 2.3028594934763444

Epoch: 6| Step: 1
Training loss: 0.45119818078179064
Validation loss: 2.314135885487875

Epoch: 6| Step: 2
Training loss: 0.5440531269385744
Validation loss: 2.2951154243854623

Epoch: 6| Step: 3
Training loss: 0.4636382973780654
Validation loss: 2.3191440358587885

Epoch: 6| Step: 4
Training loss: 0.3730686241320834
Validation loss: 2.322590362513973

Epoch: 6| Step: 5
Training loss: 0.4017666130975063
Validation loss: 2.3418016261332815

Epoch: 6| Step: 6
Training loss: 0.6519908978654758
Validation loss: 2.309233753648825

Epoch: 6| Step: 7
Training loss: 0.6949402316211555
Validation loss: 2.3168560950413575

Epoch: 6| Step: 8
Training loss: 0.46773632435912516
Validation loss: 2.315172571731898

Epoch: 6| Step: 9
Training loss: 0.5601568160858912
Validation loss: 2.2912106053650887

Epoch: 6| Step: 10
Training loss: 0.5366429193447381
Validation loss: 2.307844533847998

Epoch: 6| Step: 11
Training loss: 0.7156569228069404
Validation loss: 2.321423346396282

Epoch: 6| Step: 12
Training loss: 0.5052756104129507
Validation loss: 2.3248937040234043

Epoch: 6| Step: 13
Training loss: 0.5074086857844324
Validation loss: 2.2950222905064623

Epoch: 328| Step: 0
Training loss: 0.3806497045620797
Validation loss: 2.2845488388973076

Epoch: 6| Step: 1
Training loss: 0.7404969084505794
Validation loss: 2.32874027063392

Epoch: 6| Step: 2
Training loss: 0.4301775825107719
Validation loss: 2.3103284337197447

Epoch: 6| Step: 3
Training loss: 0.5049038556138907
Validation loss: 2.303286543727753

Epoch: 6| Step: 4
Training loss: 0.3882703192417623
Validation loss: 2.309194920984646

Epoch: 6| Step: 5
Training loss: 0.4956342265988811
Validation loss: 2.3021390712636673

Epoch: 6| Step: 6
Training loss: 0.30792009487015976
Validation loss: 2.30167765215029

Epoch: 6| Step: 7
Training loss: 0.586673325406924
Validation loss: 2.326471463201503

Epoch: 6| Step: 8
Training loss: 0.6443183316048183
Validation loss: 2.3113009878928836

Epoch: 6| Step: 9
Training loss: 0.7604556835737948
Validation loss: 2.302472316441064

Epoch: 6| Step: 10
Training loss: 0.5242648063246033
Validation loss: 2.3038384087489128

Epoch: 6| Step: 11
Training loss: 0.532559435979425
Validation loss: 2.3159478765431025

Epoch: 6| Step: 12
Training loss: 0.31427041663290906
Validation loss: 2.3088840293585737

Epoch: 6| Step: 13
Training loss: 0.6990426976720665
Validation loss: 2.316177445402448

Epoch: 329| Step: 0
Training loss: 0.24805448925917117
Validation loss: 2.341579153280717

Epoch: 6| Step: 1
Training loss: 0.5594167715065241
Validation loss: 2.366218676478306

Epoch: 6| Step: 2
Training loss: 0.5008294259403963
Validation loss: 2.327755718368316

Epoch: 6| Step: 3
Training loss: 0.5842717717023136
Validation loss: 2.363793111008575

Epoch: 6| Step: 4
Training loss: 0.5466915640404637
Validation loss: 2.348504155004188

Epoch: 6| Step: 5
Training loss: 0.6907851236368949
Validation loss: 2.3317271383158578

Epoch: 6| Step: 6
Training loss: 0.6148023269058301
Validation loss: 2.3351428723417547

Epoch: 6| Step: 7
Training loss: 0.4796938035283642
Validation loss: 2.3300916391848987

Epoch: 6| Step: 8
Training loss: 0.44159005988222366
Validation loss: 2.3422563328552357

Epoch: 6| Step: 9
Training loss: 0.5977643482459752
Validation loss: 2.321867880744549

Epoch: 6| Step: 10
Training loss: 0.5217085224438973
Validation loss: 2.298397009460627

Epoch: 6| Step: 11
Training loss: 0.5637347920517032
Validation loss: 2.3179815367537637

Epoch: 6| Step: 12
Training loss: 0.5514706024469112
Validation loss: 2.3077181448317026

Epoch: 6| Step: 13
Training loss: 0.34668703743033996
Validation loss: 2.2991750269338294

Epoch: 330| Step: 0
Training loss: 0.5710104760279562
Validation loss: 2.308573846832031

Epoch: 6| Step: 1
Training loss: 0.5475778422910744
Validation loss: 2.351230948868523

Epoch: 6| Step: 2
Training loss: 0.51014181119573
Validation loss: 2.336793169316489

Epoch: 6| Step: 3
Training loss: 0.6798194669447352
Validation loss: 2.3588778846708727

Epoch: 6| Step: 4
Training loss: 0.41567646224286153
Validation loss: 2.3285577579268226

Epoch: 6| Step: 5
Training loss: 0.4115556730545598
Validation loss: 2.356003660845411

Epoch: 6| Step: 6
Training loss: 0.7039765605465282
Validation loss: 2.3582000882043856

Epoch: 6| Step: 7
Training loss: 0.6349817934955547
Validation loss: 2.3469449007862613

Epoch: 6| Step: 8
Training loss: 0.574296465953878
Validation loss: 2.335226346005873

Epoch: 6| Step: 9
Training loss: 0.34911035908021376
Validation loss: 2.2848435654878245

Epoch: 6| Step: 10
Training loss: 0.522764998043405
Validation loss: 2.344458195054831

Epoch: 6| Step: 11
Training loss: 0.6439876460332795
Validation loss: 2.2850022405629247

Epoch: 6| Step: 12
Training loss: 0.5583851564848724
Validation loss: 2.2886763919064887

Epoch: 6| Step: 13
Training loss: 0.5366885114255788
Validation loss: 2.317121247813466

Epoch: 331| Step: 0
Training loss: 0.6775074339736794
Validation loss: 2.3262526013728855

Epoch: 6| Step: 1
Training loss: 0.5683461610496786
Validation loss: 2.3380794101622717

Epoch: 6| Step: 2
Training loss: 0.4579724133441635
Validation loss: 2.396508602589477

Epoch: 6| Step: 3
Training loss: 0.4014671368302629
Validation loss: 2.410576008445915

Epoch: 6| Step: 4
Training loss: 0.43565367342966366
Validation loss: 2.4040881773476217

Epoch: 6| Step: 5
Training loss: 0.7430114589413366
Validation loss: 2.380627591424163

Epoch: 6| Step: 6
Training loss: 0.6205584300393072
Validation loss: 2.354718228549481

Epoch: 6| Step: 7
Training loss: 0.680178059658334
Validation loss: 2.3433856541453753

Epoch: 6| Step: 8
Training loss: 0.5623446620924226
Validation loss: 2.3189243099995056

Epoch: 6| Step: 9
Training loss: 0.5354166441545098
Validation loss: 2.3361721109631133

Epoch: 6| Step: 10
Training loss: 0.5374470429614073
Validation loss: 2.310599028267001

Epoch: 6| Step: 11
Training loss: 0.4318829024788458
Validation loss: 2.318148438572705

Epoch: 6| Step: 12
Training loss: 0.6258960975670371
Validation loss: 2.327051561220787

Epoch: 6| Step: 13
Training loss: 0.1610679206805627
Validation loss: 2.3327176958146585

Epoch: 332| Step: 0
Training loss: 0.4860428122572214
Validation loss: 2.319011584431312

Epoch: 6| Step: 1
Training loss: 0.44055793062379367
Validation loss: 2.3189879583635054

Epoch: 6| Step: 2
Training loss: 0.3773739694061308
Validation loss: 2.3528014742179626

Epoch: 6| Step: 3
Training loss: 0.512065333284641
Validation loss: 2.3222479839805934

Epoch: 6| Step: 4
Training loss: 0.4756144489616844
Validation loss: 2.325716675702305

Epoch: 6| Step: 5
Training loss: 0.664999312278564
Validation loss: 2.2798524071259285

Epoch: 6| Step: 6
Training loss: 0.6007362239717017
Validation loss: 2.315330339754944

Epoch: 6| Step: 7
Training loss: 0.2952270318536632
Validation loss: 2.3169269077270838

Epoch: 6| Step: 8
Training loss: 0.7116301798642864
Validation loss: 2.311952674169731

Epoch: 6| Step: 9
Training loss: 0.6930921012562631
Validation loss: 2.2866220226209184

Epoch: 6| Step: 10
Training loss: 0.5487388456770715
Validation loss: 2.303748427075762

Epoch: 6| Step: 11
Training loss: 0.5804781321284624
Validation loss: 2.298418212630346

Epoch: 6| Step: 12
Training loss: 0.4550434639628046
Validation loss: 2.3343853300308375

Epoch: 6| Step: 13
Training loss: 0.4197083040990598
Validation loss: 2.2938459029223144

Epoch: 333| Step: 0
Training loss: 0.4748910923385291
Validation loss: 2.291587092862961

Epoch: 6| Step: 1
Training loss: 0.24945987528608
Validation loss: 2.3201899624069946

Epoch: 6| Step: 2
Training loss: 0.5033295162426713
Validation loss: 2.307074258216465

Epoch: 6| Step: 3
Training loss: 0.5153543166387196
Validation loss: 2.292970997267937

Epoch: 6| Step: 4
Training loss: 0.7387265270396172
Validation loss: 2.313077597860628

Epoch: 6| Step: 5
Training loss: 0.49699928960423195
Validation loss: 2.298279885736777

Epoch: 6| Step: 6
Training loss: 0.5873157567413665
Validation loss: 2.326082483115576

Epoch: 6| Step: 7
Training loss: 0.7567315011109024
Validation loss: 2.302258734052383

Epoch: 6| Step: 8
Training loss: 0.3824044018066614
Validation loss: 2.3104890329262173

Epoch: 6| Step: 9
Training loss: 0.5077576240819875
Validation loss: 2.3214048640886324

Epoch: 6| Step: 10
Training loss: 0.5126844423140804
Validation loss: 2.3427161886597774

Epoch: 6| Step: 11
Training loss: 0.5103343553412428
Validation loss: 2.3283101027739885

Epoch: 6| Step: 12
Training loss: 0.4817813837769137
Validation loss: 2.323411375017886

Epoch: 6| Step: 13
Training loss: 0.5641712422046846
Validation loss: 2.2956359481252284

Epoch: 334| Step: 0
Training loss: 0.7148781022953196
Validation loss: 2.3107681252391994

Epoch: 6| Step: 1
Training loss: 0.6170653693164226
Validation loss: 2.2991841110351925

Epoch: 6| Step: 2
Training loss: 0.4025001407113629
Validation loss: 2.298696219347856

Epoch: 6| Step: 3
Training loss: 0.4226914029830294
Validation loss: 2.328656892539242

Epoch: 6| Step: 4
Training loss: 0.5145789720244924
Validation loss: 2.3135736728399814

Epoch: 6| Step: 5
Training loss: 0.5842291022559607
Validation loss: 2.3045699061584677

Epoch: 6| Step: 6
Training loss: 0.37694940911077335
Validation loss: 2.3380738170474844

Epoch: 6| Step: 7
Training loss: 0.4793795824391403
Validation loss: 2.3410709746968705

Epoch: 6| Step: 8
Training loss: 0.6452906902774913
Validation loss: 2.349541380418937

Epoch: 6| Step: 9
Training loss: 0.6414273982214811
Validation loss: 2.3411514413746306

Epoch: 6| Step: 10
Training loss: 0.6327340819196473
Validation loss: 2.3450620166069656

Epoch: 6| Step: 11
Training loss: 0.5709064995962828
Validation loss: 2.338871399822163

Epoch: 6| Step: 12
Training loss: 0.5567673655997596
Validation loss: 2.315047916074251

Epoch: 6| Step: 13
Training loss: 0.21725052118184005
Validation loss: 2.2919048643260282

Epoch: 335| Step: 0
Training loss: 0.3282623003756301
Validation loss: 2.3028766685147457

Epoch: 6| Step: 1
Training loss: 0.5083756478734387
Validation loss: 2.321298927014451

Epoch: 6| Step: 2
Training loss: 0.6080562798935432
Validation loss: 2.31352795383162

Epoch: 6| Step: 3
Training loss: 0.48079512141278824
Validation loss: 2.3117235992808514

Epoch: 6| Step: 4
Training loss: 0.5680514153477587
Validation loss: 2.316712712005672

Epoch: 6| Step: 5
Training loss: 0.4115263806180353
Validation loss: 2.291903086648637

Epoch: 6| Step: 6
Training loss: 0.5266799988095345
Validation loss: 2.2994780320913675

Epoch: 6| Step: 7
Training loss: 0.6895856000588341
Validation loss: 2.3194325969353264

Epoch: 6| Step: 8
Training loss: 0.4890184254636656
Validation loss: 2.2917096675593487

Epoch: 6| Step: 9
Training loss: 0.5063258196721322
Validation loss: 2.310382205857005

Epoch: 6| Step: 10
Training loss: 0.5517298868589922
Validation loss: 2.355361162454753

Epoch: 6| Step: 11
Training loss: 0.6909053733944697
Validation loss: 2.349327524050835

Epoch: 6| Step: 12
Training loss: 0.45283318034691183
Validation loss: 2.353694423738939

Epoch: 6| Step: 13
Training loss: 0.7953844154084795
Validation loss: 2.3126758141658628

Epoch: 336| Step: 0
Training loss: 0.7114788132526917
Validation loss: 2.3198417792948907

Epoch: 6| Step: 1
Training loss: 0.39284927341704234
Validation loss: 2.3087521796719197

Epoch: 6| Step: 2
Training loss: 0.49329522532064923
Validation loss: 2.3052745034696533

Epoch: 6| Step: 3
Training loss: 0.6059696463625042
Validation loss: 2.306516967603044

Epoch: 6| Step: 4
Training loss: 0.42087262775918416
Validation loss: 2.309976849199578

Epoch: 6| Step: 5
Training loss: 0.45029443406789277
Validation loss: 2.345788937571512

Epoch: 6| Step: 6
Training loss: 0.2551775868377865
Validation loss: 2.3386725486775597

Epoch: 6| Step: 7
Training loss: 0.30071052116005864
Validation loss: 2.323137018395224

Epoch: 6| Step: 8
Training loss: 0.43400789363665926
Validation loss: 2.3394975681594254

Epoch: 6| Step: 9
Training loss: 0.6240429942330512
Validation loss: 2.3298129558398135

Epoch: 6| Step: 10
Training loss: 0.5844202615681834
Validation loss: 2.327426445244623

Epoch: 6| Step: 11
Training loss: 0.7899115121150554
Validation loss: 2.317672028671441

Epoch: 6| Step: 12
Training loss: 0.5040229543934748
Validation loss: 2.3378076774305003

Epoch: 6| Step: 13
Training loss: 0.5226368545559992
Validation loss: 2.3087532037389775

Epoch: 337| Step: 0
Training loss: 0.16947360487027602
Validation loss: 2.2973585001473236

Epoch: 6| Step: 1
Training loss: 0.5004799744451649
Validation loss: 2.3263186042595283

Epoch: 6| Step: 2
Training loss: 0.5165612361867113
Validation loss: 2.3051369894926363

Epoch: 6| Step: 3
Training loss: 0.609432902397314
Validation loss: 2.3164246172494014

Epoch: 6| Step: 4
Training loss: 0.6509670876066114
Validation loss: 2.3400971855089256

Epoch: 6| Step: 5
Training loss: 0.3475861210759662
Validation loss: 2.321323086725225

Epoch: 6| Step: 6
Training loss: 0.6126181546902734
Validation loss: 2.342707080760754

Epoch: 6| Step: 7
Training loss: 0.7291005013736879
Validation loss: 2.3254437960170002

Epoch: 6| Step: 8
Training loss: 0.5224169561109757
Validation loss: 2.3366977344745017

Epoch: 6| Step: 9
Training loss: 0.6420152512072789
Validation loss: 2.327543959313238

Epoch: 6| Step: 10
Training loss: 0.3267813829675444
Validation loss: 2.3259684618729883

Epoch: 6| Step: 11
Training loss: 0.4418574870900281
Validation loss: 2.3293076912570165

Epoch: 6| Step: 12
Training loss: 0.20898213786416223
Validation loss: 2.3420887644349593

Epoch: 6| Step: 13
Training loss: 0.7723846204942284
Validation loss: 2.3395428640489757

Epoch: 338| Step: 0
Training loss: 0.2615192848884395
Validation loss: 2.3445336621178967

Epoch: 6| Step: 1
Training loss: 0.4619089977156096
Validation loss: 2.379030325826059

Epoch: 6| Step: 2
Training loss: 0.39619717272895955
Validation loss: 2.3723587592092747

Epoch: 6| Step: 3
Training loss: 0.6992575778516475
Validation loss: 2.3731445216787934

Epoch: 6| Step: 4
Training loss: 0.7979370220831575
Validation loss: 2.3595752735647144

Epoch: 6| Step: 5
Training loss: 0.5983055925535387
Validation loss: 2.362183436136404

Epoch: 6| Step: 6
Training loss: 0.5516970710740952
Validation loss: 2.3578562665723166

Epoch: 6| Step: 7
Training loss: 0.43078839849242145
Validation loss: 2.338662823217267

Epoch: 6| Step: 8
Training loss: 0.16268238803959797
Validation loss: 2.315273098849714

Epoch: 6| Step: 9
Training loss: 0.2537592829335804
Validation loss: 2.3104249140868354

Epoch: 6| Step: 10
Training loss: 0.5771689112819096
Validation loss: 2.29291182518603

Epoch: 6| Step: 11
Training loss: 0.5972905255472996
Validation loss: 2.310843469991363

Epoch: 6| Step: 12
Training loss: 0.4754553582307853
Validation loss: 2.312210058179716

Epoch: 6| Step: 13
Training loss: 0.27873581773234973
Validation loss: 2.315361872803701

Epoch: 339| Step: 0
Training loss: 0.2792124854155156
Validation loss: 2.3414811044575816

Epoch: 6| Step: 1
Training loss: 0.697323943619059
Validation loss: 2.336668216242022

Epoch: 6| Step: 2
Training loss: 0.49137884648849833
Validation loss: 2.3451820106099914

Epoch: 6| Step: 3
Training loss: 0.5677356509247754
Validation loss: 2.339222614818917

Epoch: 6| Step: 4
Training loss: 0.45247162376917593
Validation loss: 2.3331043802022

Epoch: 6| Step: 5
Training loss: 0.5164548380698719
Validation loss: 2.3040804931772816

Epoch: 6| Step: 6
Training loss: 0.4988084094662862
Validation loss: 2.330457532109986

Epoch: 6| Step: 7
Training loss: 0.3011714089237867
Validation loss: 2.3058786002397205

Epoch: 6| Step: 8
Training loss: 0.26174232035158357
Validation loss: 2.287635856188038

Epoch: 6| Step: 9
Training loss: 0.591707480952615
Validation loss: 2.2954786983019844

Epoch: 6| Step: 10
Training loss: 0.4810510533792231
Validation loss: 2.3051956765012043

Epoch: 6| Step: 11
Training loss: 0.3736983796580921
Validation loss: 2.3061544931296245

Epoch: 6| Step: 12
Training loss: 0.6159919555219294
Validation loss: 2.280074558015882

Epoch: 6| Step: 13
Training loss: 0.546014845008746
Validation loss: 2.3188852634529966

Epoch: 340| Step: 0
Training loss: 0.28192629565209903
Validation loss: 2.3159236070704665

Epoch: 6| Step: 1
Training loss: 0.35076789065879166
Validation loss: 2.337175769307795

Epoch: 6| Step: 2
Training loss: 0.3651860863081927
Validation loss: 2.3216456095788978

Epoch: 6| Step: 3
Training loss: 0.567966548280502
Validation loss: 2.3358139338488653

Epoch: 6| Step: 4
Training loss: 0.559426014454683
Validation loss: 2.3504418474054916

Epoch: 6| Step: 5
Training loss: 0.6604943622850973
Validation loss: 2.3085874946736724

Epoch: 6| Step: 6
Training loss: 0.40757975824579806
Validation loss: 2.32701933304724

Epoch: 6| Step: 7
Training loss: 0.4359689557611837
Validation loss: 2.3004924745389155

Epoch: 6| Step: 8
Training loss: 0.4217212008122015
Validation loss: 2.287125614666572

Epoch: 6| Step: 9
Training loss: 0.6227339673331097
Validation loss: 2.2798952644612016

Epoch: 6| Step: 10
Training loss: 0.4581187425006504
Validation loss: 2.3042284536682613

Epoch: 6| Step: 11
Training loss: 0.48440379395578115
Validation loss: 2.333077040526821

Epoch: 6| Step: 12
Training loss: 0.6160433824051087
Validation loss: 2.3221841440076605

Epoch: 6| Step: 13
Training loss: 0.5346669375614342
Validation loss: 2.3124597053154554

Epoch: 341| Step: 0
Training loss: 0.48062752992140256
Validation loss: 2.3264365302211387

Epoch: 6| Step: 1
Training loss: 0.41503996007485666
Validation loss: 2.319631954108619

Epoch: 6| Step: 2
Training loss: 0.46586629452669137
Validation loss: 2.375750062177779

Epoch: 6| Step: 3
Training loss: 0.577280613566155
Validation loss: 2.352650887749555

Epoch: 6| Step: 4
Training loss: 0.4510992412807686
Validation loss: 2.349302336848148

Epoch: 6| Step: 5
Training loss: 0.45610333659024893
Validation loss: 2.3525858124201053

Epoch: 6| Step: 6
Training loss: 0.7044319086855595
Validation loss: 2.356382716696932

Epoch: 6| Step: 7
Training loss: 0.22933812753251875
Validation loss: 2.369424711527212

Epoch: 6| Step: 8
Training loss: 0.664458751262188
Validation loss: 2.326184948178728

Epoch: 6| Step: 9
Training loss: 0.5537265190071642
Validation loss: 2.340717123709272

Epoch: 6| Step: 10
Training loss: 0.45528865414019587
Validation loss: 2.2813706286749538

Epoch: 6| Step: 11
Training loss: 0.5359901280045596
Validation loss: 2.3079170059811003

Epoch: 6| Step: 12
Training loss: 0.5167147939580746
Validation loss: 2.329884304503385

Epoch: 6| Step: 13
Training loss: 0.6224506838157171
Validation loss: 2.3073028724920697

Epoch: 342| Step: 0
Training loss: 0.5771395816543105
Validation loss: 2.2898214979431906

Epoch: 6| Step: 1
Training loss: 0.41119366193248785
Validation loss: 2.268180356590085

Epoch: 6| Step: 2
Training loss: 0.5597506194356172
Validation loss: 2.3065228667598525

Epoch: 6| Step: 3
Training loss: 0.39204803661958687
Validation loss: 2.3229218927169484

Epoch: 6| Step: 4
Training loss: 0.7642466535760142
Validation loss: 2.3199866447127975

Epoch: 6| Step: 5
Training loss: 0.5009687991962904
Validation loss: 2.3502009365879424

Epoch: 6| Step: 6
Training loss: 0.44349745562188025
Validation loss: 2.3702578001775887

Epoch: 6| Step: 7
Training loss: 0.4237999093644305
Validation loss: 2.369646681919162

Epoch: 6| Step: 8
Training loss: 0.4559356566791256
Validation loss: 2.396758726794369

Epoch: 6| Step: 9
Training loss: 0.4982151719518574
Validation loss: 2.3906095309758695

Epoch: 6| Step: 10
Training loss: 0.41355335673889815
Validation loss: 2.4101669165828845

Epoch: 6| Step: 11
Training loss: 0.449532009862656
Validation loss: 2.417115974525404

Epoch: 6| Step: 12
Training loss: 0.4405651349462279
Validation loss: 2.3910301707496577

Epoch: 6| Step: 13
Training loss: 0.6805725255026837
Validation loss: 2.3503504807467612

Epoch: 343| Step: 0
Training loss: 0.6392317484837381
Validation loss: 2.3843588225622905

Epoch: 6| Step: 1
Training loss: 0.2460038157027585
Validation loss: 2.394054306257853

Epoch: 6| Step: 2
Training loss: 0.5735794452991954
Validation loss: 2.4134840569107117

Epoch: 6| Step: 3
Training loss: 0.5234575694777308
Validation loss: 2.407309743744548

Epoch: 6| Step: 4
Training loss: 0.27537226784849017
Validation loss: 2.3964083123846422

Epoch: 6| Step: 5
Training loss: 0.3906499282512162
Validation loss: 2.3587572940361254

Epoch: 6| Step: 6
Training loss: 0.5841333460816651
Validation loss: 2.3452806354513727

Epoch: 6| Step: 7
Training loss: 0.5621626955235709
Validation loss: 2.346100501558749

Epoch: 6| Step: 8
Training loss: 0.13890545608799967
Validation loss: 2.324161880223448

Epoch: 6| Step: 9
Training loss: 0.27570038817623627
Validation loss: 2.357998173571352

Epoch: 6| Step: 10
Training loss: 0.3182820770410234
Validation loss: 2.3287793313807557

Epoch: 6| Step: 11
Training loss: 0.6063408754018443
Validation loss: 2.305660610640538

Epoch: 6| Step: 12
Training loss: 0.5348141265787343
Validation loss: 2.3094606322631965

Epoch: 6| Step: 13
Training loss: 0.5911234432691217
Validation loss: 2.3322048652018927

Epoch: 344| Step: 0
Training loss: 0.5030176178442405
Validation loss: 2.3036072115383956

Epoch: 6| Step: 1
Training loss: 0.5345984008679519
Validation loss: 2.2916527853029813

Epoch: 6| Step: 2
Training loss: 0.41998088333357075
Validation loss: 2.329230320955312

Epoch: 6| Step: 3
Training loss: 0.3525573535517196
Validation loss: 2.310852352908524

Epoch: 6| Step: 4
Training loss: 0.5057056443793876
Validation loss: 2.322823705311734

Epoch: 6| Step: 5
Training loss: 0.44842532204497704
Validation loss: 2.326255371918404

Epoch: 6| Step: 6
Training loss: 0.4870729373130282
Validation loss: 2.351448453961892

Epoch: 6| Step: 7
Training loss: 0.3401946525291378
Validation loss: 2.333107461266064

Epoch: 6| Step: 8
Training loss: 0.4215062260377206
Validation loss: 2.314961971728169

Epoch: 6| Step: 9
Training loss: 0.4627610842203174
Validation loss: 2.316041952730737

Epoch: 6| Step: 10
Training loss: 0.5754347919571506
Validation loss: 2.334556584893215

Epoch: 6| Step: 11
Training loss: 0.3978237586214988
Validation loss: 2.3297595711034615

Epoch: 6| Step: 12
Training loss: 0.5879376921711726
Validation loss: 2.307011801061225

Epoch: 6| Step: 13
Training loss: 0.502000977131474
Validation loss: 2.3276510268904698

Epoch: 345| Step: 0
Training loss: 0.4314018383028516
Validation loss: 2.3285111616816354

Epoch: 6| Step: 1
Training loss: 0.43829132789272096
Validation loss: 2.2992694019384143

Epoch: 6| Step: 2
Training loss: 0.37126665604601
Validation loss: 2.3013992024299097

Epoch: 6| Step: 3
Training loss: 0.6488584737552593
Validation loss: 2.316417120294984

Epoch: 6| Step: 4
Training loss: 0.7485678429879101
Validation loss: 2.3242996192100085

Epoch: 6| Step: 5
Training loss: 0.27846159444354257
Validation loss: 2.311747398842566

Epoch: 6| Step: 6
Training loss: 0.24204828506520973
Validation loss: 2.2708078036567096

Epoch: 6| Step: 7
Training loss: 0.5393705179110027
Validation loss: 2.2799127277495495

Epoch: 6| Step: 8
Training loss: 0.41405577024353074
Validation loss: 2.2898163468851775

Epoch: 6| Step: 9
Training loss: 0.5862965310344322
Validation loss: 2.2675320241164774

Epoch: 6| Step: 10
Training loss: 0.37268678152222046
Validation loss: 2.2631551607646396

Epoch: 6| Step: 11
Training loss: 0.474860952755465
Validation loss: 2.2808837057132387

Epoch: 6| Step: 12
Training loss: 0.4446888957534514
Validation loss: 2.31252299227782

Epoch: 6| Step: 13
Training loss: 0.15340380612375443
Validation loss: 2.3122189835224685

Epoch: 346| Step: 0
Training loss: 0.5504012454045838
Validation loss: 2.3126414410128704

Epoch: 6| Step: 1
Training loss: 0.3490874907854714
Validation loss: 2.2998905773804688

Epoch: 6| Step: 2
Training loss: 0.5048223935246757
Validation loss: 2.326262799697188

Epoch: 6| Step: 3
Training loss: 0.37479782615054613
Validation loss: 2.3348358681160652

Epoch: 6| Step: 4
Training loss: 0.7456540714553593
Validation loss: 2.336818914677926

Epoch: 6| Step: 5
Training loss: 0.4966464230659675
Validation loss: 2.3089587905064275

Epoch: 6| Step: 6
Training loss: 0.2955675068610885
Validation loss: 2.3239035077118357

Epoch: 6| Step: 7
Training loss: 0.49374536681113984
Validation loss: 2.3000552107491843

Epoch: 6| Step: 8
Training loss: 0.5641208713582433
Validation loss: 2.288657702274872

Epoch: 6| Step: 9
Training loss: 0.4235100321566672
Validation loss: 2.3109920710341125

Epoch: 6| Step: 10
Training loss: 0.2967732405684855
Validation loss: 2.2884941886530124

Epoch: 6| Step: 11
Training loss: 0.44361681752896287
Validation loss: 2.2671720287339325

Epoch: 6| Step: 12
Training loss: 0.2665279971619852
Validation loss: 2.2723112858683336

Epoch: 6| Step: 13
Training loss: 0.18520369666238296
Validation loss: 2.286743234515882

Epoch: 347| Step: 0
Training loss: 0.27951244224874267
Validation loss: 2.285965930500422

Epoch: 6| Step: 1
Training loss: 0.49342792363987714
Validation loss: 2.3219120857667694

Epoch: 6| Step: 2
Training loss: 0.3853529306069405
Validation loss: 2.313546687996836

Epoch: 6| Step: 3
Training loss: 0.6555969985786146
Validation loss: 2.3222801406544544

Epoch: 6| Step: 4
Training loss: 0.657498466395631
Validation loss: 2.3386651076955687

Epoch: 6| Step: 5
Training loss: 0.4736795461349023
Validation loss: 2.3619139153620745

Epoch: 6| Step: 6
Training loss: 0.3532661168679952
Validation loss: 2.322536586585138

Epoch: 6| Step: 7
Training loss: 0.1906140535369731
Validation loss: 2.290826071299811

Epoch: 6| Step: 8
Training loss: 0.3388653845835279
Validation loss: 2.3375349414094364

Epoch: 6| Step: 9
Training loss: 0.5772315157561435
Validation loss: 2.329911732257569

Epoch: 6| Step: 10
Training loss: 0.2994128720532943
Validation loss: 2.3100631565771472

Epoch: 6| Step: 11
Training loss: 0.5666572277835039
Validation loss: 2.318669305459821

Epoch: 6| Step: 12
Training loss: 0.34901312378948907
Validation loss: 2.311661998853399

Epoch: 6| Step: 13
Training loss: 0.470390295013682
Validation loss: 2.308676694491093

Epoch: 348| Step: 0
Training loss: 0.30841538549992176
Validation loss: 2.3306464243753187

Epoch: 6| Step: 1
Training loss: 0.5026327200834849
Validation loss: 2.3025403560000135

Epoch: 6| Step: 2
Training loss: 0.5590102237080405
Validation loss: 2.331992769204689

Epoch: 6| Step: 3
Training loss: 0.34230976315585354
Validation loss: 2.3403585319875457

Epoch: 6| Step: 4
Training loss: 0.47780202478636064
Validation loss: 2.3336789106716753

Epoch: 6| Step: 5
Training loss: 0.58132881942726
Validation loss: 2.336954728664415

Epoch: 6| Step: 6
Training loss: 0.35808399761278303
Validation loss: 2.303250277393164

Epoch: 6| Step: 7
Training loss: 0.4339963916450572
Validation loss: 2.3206248474532

Epoch: 6| Step: 8
Training loss: 0.46989548911125256
Validation loss: 2.351819697890474

Epoch: 6| Step: 9
Training loss: 0.40623914263961963
Validation loss: 2.348719673937408

Epoch: 6| Step: 10
Training loss: 0.24591179584944714
Validation loss: 2.3499380424690983

Epoch: 6| Step: 11
Training loss: 0.47685175075327607
Validation loss: 2.3610398709067533

Epoch: 6| Step: 12
Training loss: 0.5873974984620015
Validation loss: 2.3524800559599646

Epoch: 6| Step: 13
Training loss: 0.45637109142417454
Validation loss: 2.3441986070306338

Epoch: 349| Step: 0
Training loss: 0.3468538196214555
Validation loss: 2.3365281397125357

Epoch: 6| Step: 1
Training loss: 0.5102965122668853
Validation loss: 2.329541785237261

Epoch: 6| Step: 2
Training loss: 0.6243977744728738
Validation loss: 2.3076970087799684

Epoch: 6| Step: 3
Training loss: 0.49410356224295343
Validation loss: 2.303497408746027

Epoch: 6| Step: 4
Training loss: 0.2800568198768991
Validation loss: 2.2966666323476668

Epoch: 6| Step: 5
Training loss: 0.5240622251233521
Validation loss: 2.2928097440531716

Epoch: 6| Step: 6
Training loss: 0.2530472971720411
Validation loss: 2.2715494976453936

Epoch: 6| Step: 7
Training loss: 0.27759003785174363
Validation loss: 2.2937946280479244

Epoch: 6| Step: 8
Training loss: 0.6953566890776369
Validation loss: 2.2794081753570996

Epoch: 6| Step: 9
Training loss: 0.43144642875944894
Validation loss: 2.2852102678027033

Epoch: 6| Step: 10
Training loss: 0.6769295126466911
Validation loss: 2.3004535419589978

Epoch: 6| Step: 11
Training loss: 0.336444726861745
Validation loss: 2.304454713706242

Epoch: 6| Step: 12
Training loss: 0.2660734934328956
Validation loss: 2.321359197712953

Epoch: 6| Step: 13
Training loss: 0.27668534960965624
Validation loss: 2.322655112956719

Epoch: 350| Step: 0
Training loss: 0.46034419135179416
Validation loss: 2.3278464005892334

Epoch: 6| Step: 1
Training loss: 0.44158724222158696
Validation loss: 2.369379726135599

Epoch: 6| Step: 2
Training loss: 0.3844274206004541
Validation loss: 2.3682179292524053

Epoch: 6| Step: 3
Training loss: 0.4482051194099894
Validation loss: 2.3630213853013147

Epoch: 6| Step: 4
Training loss: 0.4494409426293515
Validation loss: 2.359490764244153

Epoch: 6| Step: 5
Training loss: 0.6445066505130432
Validation loss: 2.3523309185517975

Epoch: 6| Step: 6
Training loss: 0.5005147191950097
Validation loss: 2.328633426533732

Epoch: 6| Step: 7
Training loss: 0.4901002647279711
Validation loss: 2.303466146217209

Epoch: 6| Step: 8
Training loss: 0.1738667766589331
Validation loss: 2.307938732625887

Epoch: 6| Step: 9
Training loss: 0.5154301246216233
Validation loss: 2.3053534155937756

Epoch: 6| Step: 10
Training loss: 0.2131932933101855
Validation loss: 2.269121709431002

Epoch: 6| Step: 11
Training loss: 0.5498496760498602
Validation loss: 2.28155238672727

Epoch: 6| Step: 12
Training loss: 0.351405776376774
Validation loss: 2.2927327846720056

Epoch: 6| Step: 13
Training loss: 0.25625966332986233
Validation loss: 2.283523051954575

Epoch: 351| Step: 0
Training loss: 0.31282453374743324
Validation loss: 2.2737541241835517

Epoch: 6| Step: 1
Training loss: 0.35303927832726456
Validation loss: 2.312984190816768

Epoch: 6| Step: 2
Training loss: 0.43604909910868533
Validation loss: 2.31220577067673

Epoch: 6| Step: 3
Training loss: 0.44573222006031066
Validation loss: 2.3105731265309775

Epoch: 6| Step: 4
Training loss: 0.7510307699216322
Validation loss: 2.326833191084423

Epoch: 6| Step: 5
Training loss: 0.15123660700195693
Validation loss: 2.351869778569999

Epoch: 6| Step: 6
Training loss: 0.46369426515762474
Validation loss: 2.309905905580858

Epoch: 6| Step: 7
Training loss: 0.47435979992182686
Validation loss: 2.3011411818531955

Epoch: 6| Step: 8
Training loss: 0.47588752411558743
Validation loss: 2.2896925678441535

Epoch: 6| Step: 9
Training loss: 0.4598552477141587
Validation loss: 2.2910328023856645

Epoch: 6| Step: 10
Training loss: 0.4892317561294263
Validation loss: 2.2885725513448336

Epoch: 6| Step: 11
Training loss: 0.50857416399439
Validation loss: 2.2990400345413002

Epoch: 6| Step: 12
Training loss: 0.3945677334374784
Validation loss: 2.277894950565455

Epoch: 6| Step: 13
Training loss: 0.2105173943144478
Validation loss: 2.3208369108584046

Epoch: 352| Step: 0
Training loss: 0.6636716702322282
Validation loss: 2.3131510653101723

Epoch: 6| Step: 1
Training loss: 0.3903988374216913
Validation loss: 2.3640575148648892

Epoch: 6| Step: 2
Training loss: 0.1522927565694374
Validation loss: 2.3711684071756918

Epoch: 6| Step: 3
Training loss: 0.3436609499635006
Validation loss: 2.3810617740649294

Epoch: 6| Step: 4
Training loss: 0.33924643322314263
Validation loss: 2.3741433995717856

Epoch: 6| Step: 5
Training loss: 0.2929253609634471
Validation loss: 2.36444060756035

Epoch: 6| Step: 6
Training loss: 0.4298170761324087
Validation loss: 2.3667064134433873

Epoch: 6| Step: 7
Training loss: 0.3199938840952199
Validation loss: 2.394845146845205

Epoch: 6| Step: 8
Training loss: 0.374781823268437
Validation loss: 2.3769368179482786

Epoch: 6| Step: 9
Training loss: 0.5329900182966674
Validation loss: 2.375497205725267

Epoch: 6| Step: 10
Training loss: 0.5801051483538717
Validation loss: 2.3496768253562155

Epoch: 6| Step: 11
Training loss: 0.5882920323735114
Validation loss: 2.3669141396801896

Epoch: 6| Step: 12
Training loss: 0.4731710011230074
Validation loss: 2.346591575845044

Epoch: 6| Step: 13
Training loss: 0.5064999269577681
Validation loss: 2.2966524325622553

Epoch: 353| Step: 0
Training loss: 0.32186404552151615
Validation loss: 2.300242336609103

Epoch: 6| Step: 1
Training loss: 0.43686161127162415
Validation loss: 2.3155037313333415

Epoch: 6| Step: 2
Training loss: 0.46638796465379934
Validation loss: 2.3004221126918543

Epoch: 6| Step: 3
Training loss: 0.3531669667718094
Validation loss: 2.2963438956812974

Epoch: 6| Step: 4
Training loss: 0.33855036455376203
Validation loss: 2.3000791912347323

Epoch: 6| Step: 5
Training loss: 0.5978340931495764
Validation loss: 2.3270981473081513

Epoch: 6| Step: 6
Training loss: 0.544355528841299
Validation loss: 2.2759828309050754

Epoch: 6| Step: 7
Training loss: 0.31732086750889893
Validation loss: 2.3186327877082453

Epoch: 6| Step: 8
Training loss: 0.5546973321607415
Validation loss: 2.3358011650763864

Epoch: 6| Step: 9
Training loss: 0.4576927842248373
Validation loss: 2.305479285130546

Epoch: 6| Step: 10
Training loss: 0.31480416553121277
Validation loss: 2.321370872536416

Epoch: 6| Step: 11
Training loss: 0.31968133661289516
Validation loss: 2.3599433233455724

Epoch: 6| Step: 12
Training loss: 0.11653207037210625
Validation loss: 2.375232419081948

Epoch: 6| Step: 13
Training loss: 0.6827493520556923
Validation loss: 2.337191588699988

Epoch: 354| Step: 0
Training loss: 0.4956195697751523
Validation loss: 2.356955488539322

Epoch: 6| Step: 1
Training loss: 0.5841373511163083
Validation loss: 2.372494995109488

Epoch: 6| Step: 2
Training loss: 0.4639576070900029
Validation loss: 2.3181748119287344

Epoch: 6| Step: 3
Training loss: 0.36378085739629695
Validation loss: 2.319256407362402

Epoch: 6| Step: 4
Training loss: 0.46340810444593467
Validation loss: 2.3138291314911643

Epoch: 6| Step: 5
Training loss: 0.3172103413217188
Validation loss: 2.29546153547892

Epoch: 6| Step: 6
Training loss: 0.42377698387607454
Validation loss: 2.3247583601341426

Epoch: 6| Step: 7
Training loss: 0.44574442211604254
Validation loss: 2.3160720133341974

Epoch: 6| Step: 8
Training loss: 0.5166036393064352
Validation loss: 2.290352683112864

Epoch: 6| Step: 9
Training loss: 0.3119790264547518
Validation loss: 2.3250702305195396

Epoch: 6| Step: 10
Training loss: 0.4251262105741148
Validation loss: 2.30964177146479

Epoch: 6| Step: 11
Training loss: 0.36148066007421326
Validation loss: 2.2895401165151092

Epoch: 6| Step: 12
Training loss: 0.5680087341758638
Validation loss: 2.3144808502634278

Epoch: 6| Step: 13
Training loss: 0.3264750824514329
Validation loss: 2.3141570735117227

Epoch: 355| Step: 0
Training loss: 0.6031251897465699
Validation loss: 2.356684424561767

Epoch: 6| Step: 1
Training loss: 0.408027611193223
Validation loss: 2.3523915940505113

Epoch: 6| Step: 2
Training loss: 0.3620917627687147
Validation loss: 2.346716394774427

Epoch: 6| Step: 3
Training loss: 0.3317010471761031
Validation loss: 2.319509719322469

Epoch: 6| Step: 4
Training loss: 0.31842633578764623
Validation loss: 2.3318660784293086

Epoch: 6| Step: 5
Training loss: 0.3696242499719621
Validation loss: 2.3076535529560185

Epoch: 6| Step: 6
Training loss: 0.35027168449608975
Validation loss: 2.3118428962646456

Epoch: 6| Step: 7
Training loss: 0.4125319027846045
Validation loss: 2.3265384383771948

Epoch: 6| Step: 8
Training loss: 0.6202432098893415
Validation loss: 2.320386504582093

Epoch: 6| Step: 9
Training loss: 0.496554153545087
Validation loss: 2.338947772741086

Epoch: 6| Step: 10
Training loss: 0.6158927664341749
Validation loss: 2.3239136964881446

Epoch: 6| Step: 11
Training loss: 0.41322360438969086
Validation loss: 2.3130233624723675

Epoch: 6| Step: 12
Training loss: 0.3722828735966831
Validation loss: 2.3304851604764463

Epoch: 6| Step: 13
Training loss: 0.6411304108422414
Validation loss: 2.315692302342518

Epoch: 356| Step: 0
Training loss: 0.2557111849681529
Validation loss: 2.3163189914018956

Epoch: 6| Step: 1
Training loss: 0.6422542231069359
Validation loss: 2.328546315658536

Epoch: 6| Step: 2
Training loss: 0.5024132604843662
Validation loss: 2.3424076953619988

Epoch: 6| Step: 3
Training loss: 0.36193598574316826
Validation loss: 2.296409934316838

Epoch: 6| Step: 4
Training loss: 0.36368155215588976
Validation loss: 2.3085122828474924

Epoch: 6| Step: 5
Training loss: 0.510632446636311
Validation loss: 2.3056292123251576

Epoch: 6| Step: 6
Training loss: 0.5869563082757583
Validation loss: 2.3218902795405056

Epoch: 6| Step: 7
Training loss: 0.32971799266512364
Validation loss: 2.3280428992858524

Epoch: 6| Step: 8
Training loss: 0.5413940978785065
Validation loss: 2.335518736642924

Epoch: 6| Step: 9
Training loss: 0.23749926717544734
Validation loss: 2.376610793108008

Epoch: 6| Step: 10
Training loss: 0.6527251995727043
Validation loss: 2.4012234277581985

Epoch: 6| Step: 11
Training loss: 0.3765396063718959
Validation loss: 2.403518297588502

Epoch: 6| Step: 12
Training loss: 0.4536144638456732
Validation loss: 2.418253744175476

Epoch: 6| Step: 13
Training loss: 0.5773049802241883
Validation loss: 2.417619439591187

Epoch: 357| Step: 0
Training loss: 0.5599691623899324
Validation loss: 2.367156461300145

Epoch: 6| Step: 1
Training loss: 0.33262493686754274
Validation loss: 2.3571991881944387

Epoch: 6| Step: 2
Training loss: 0.615679383175307
Validation loss: 2.3579168618622113

Epoch: 6| Step: 3
Training loss: 0.3515925924349733
Validation loss: 2.313379521777513

Epoch: 6| Step: 4
Training loss: 0.594847943927719
Validation loss: 2.3217848567975445

Epoch: 6| Step: 5
Training loss: 0.3400417606042945
Validation loss: 2.313964047724028

Epoch: 6| Step: 6
Training loss: 0.34597854634362574
Validation loss: 2.324549739161051

Epoch: 6| Step: 7
Training loss: 0.4063786706362641
Validation loss: 2.3187920770900745

Epoch: 6| Step: 8
Training loss: 0.34358295803634004
Validation loss: 2.3474303174314817

Epoch: 6| Step: 9
Training loss: 0.5660511350582763
Validation loss: 2.349293449814539

Epoch: 6| Step: 10
Training loss: 0.5859716278309849
Validation loss: 2.3544086423051485

Epoch: 6| Step: 11
Training loss: 0.44651972112643346
Validation loss: 2.381167975910444

Epoch: 6| Step: 12
Training loss: 0.2221347490563745
Validation loss: 2.346109939944459

Epoch: 6| Step: 13
Training loss: 0.4410655808516196
Validation loss: 2.3290855395640753

Epoch: 358| Step: 0
Training loss: 0.6228924503105898
Validation loss: 2.308142630655745

Epoch: 6| Step: 1
Training loss: 0.3490098896182977
Validation loss: 2.3200139077016892

Epoch: 6| Step: 2
Training loss: 0.38776687230700685
Validation loss: 2.298742898996774

Epoch: 6| Step: 3
Training loss: 0.4435795476775682
Validation loss: 2.2971256775881623

Epoch: 6| Step: 4
Training loss: 0.33261332260457904
Validation loss: 2.2752087059780775

Epoch: 6| Step: 5
Training loss: 0.34867758156262535
Validation loss: 2.320445829513258

Epoch: 6| Step: 6
Training loss: 0.36533815266105857
Validation loss: 2.3262474393771275

Epoch: 6| Step: 7
Training loss: 0.5581211678607264
Validation loss: 2.3132522698609184

Epoch: 6| Step: 8
Training loss: 0.2299999949595202
Validation loss: 2.2879829205854305

Epoch: 6| Step: 9
Training loss: 0.41558439443613554
Validation loss: 2.317283823962193

Epoch: 6| Step: 10
Training loss: 0.19155904937922077
Validation loss: 2.30964853923941

Epoch: 6| Step: 11
Training loss: 0.5736701057008861
Validation loss: 2.3340359990719675

Epoch: 6| Step: 12
Training loss: 0.5701748930166571
Validation loss: 2.3602985350311045

Epoch: 6| Step: 13
Training loss: 0.15237637317256225
Validation loss: 2.3314544799416517

Epoch: 359| Step: 0
Training loss: 0.36601337444382964
Validation loss: 2.3468340222027853

Epoch: 6| Step: 1
Training loss: 0.3611113645581228
Validation loss: 2.3434847199631506

Epoch: 6| Step: 2
Training loss: 0.5006433758357529
Validation loss: 2.3061726096467345

Epoch: 6| Step: 3
Training loss: 0.322523175985177
Validation loss: 2.3345906880897607

Epoch: 6| Step: 4
Training loss: 0.5987812001455419
Validation loss: 2.3274456314966505

Epoch: 6| Step: 5
Training loss: 0.34544774768468894
Validation loss: 2.2993763695680816

Epoch: 6| Step: 6
Training loss: 0.3284155830525781
Validation loss: 2.319151641172809

Epoch: 6| Step: 7
Training loss: 0.332147017099842
Validation loss: 2.34492179809915

Epoch: 6| Step: 8
Training loss: 0.4445534142464454
Validation loss: 2.325694647758923

Epoch: 6| Step: 9
Training loss: 0.33149833547309476
Validation loss: 2.3028507372522626

Epoch: 6| Step: 10
Training loss: 0.525018695089718
Validation loss: 2.2967213421693344

Epoch: 6| Step: 11
Training loss: 0.5397617117656688
Validation loss: 2.2951531853283145

Epoch: 6| Step: 12
Training loss: 0.2765799333713583
Validation loss: 2.2920349570943013

Epoch: 6| Step: 13
Training loss: 0.4046490006563061
Validation loss: 2.3154525897909113

Epoch: 360| Step: 0
Training loss: 0.2889222371829051
Validation loss: 2.340836238684125

Epoch: 6| Step: 1
Training loss: 0.4098633219691873
Validation loss: 2.3734074030961185

Epoch: 6| Step: 2
Training loss: 0.4047571409536833
Validation loss: 2.374294764587187

Epoch: 6| Step: 3
Training loss: 0.3860322465311678
Validation loss: 2.3530620317747526

Epoch: 6| Step: 4
Training loss: 0.3884803645205398
Validation loss: 2.331587177259728

Epoch: 6| Step: 5
Training loss: 0.5814933083035231
Validation loss: 2.307471332755271

Epoch: 6| Step: 6
Training loss: 0.5075505094339059
Validation loss: 2.30817805986281

Epoch: 6| Step: 7
Training loss: 0.412532101451341
Validation loss: 2.301001040496115

Epoch: 6| Step: 8
Training loss: 0.3774730081887298
Validation loss: 2.325593725066495

Epoch: 6| Step: 9
Training loss: 0.6416421119731235
Validation loss: 2.3031682845219494

Epoch: 6| Step: 10
Training loss: 0.4170991461128909
Validation loss: 2.2744234867096456

Epoch: 6| Step: 11
Training loss: 0.3747412862025476
Validation loss: 2.3039524102550852

Epoch: 6| Step: 12
Training loss: 0.4265301269431501
Validation loss: 2.3203124723782826

Epoch: 6| Step: 13
Training loss: 0.635189982664539
Validation loss: 2.375153256508721

Epoch: 361| Step: 0
Training loss: 0.5265741454514824
Validation loss: 2.3173649207991422

Epoch: 6| Step: 1
Training loss: 0.42878350619079836
Validation loss: 2.34847864949738

Epoch: 6| Step: 2
Training loss: 0.45988484783883826
Validation loss: 2.330629099786888

Epoch: 6| Step: 3
Training loss: 0.47199182074842827
Validation loss: 2.2916935666501415

Epoch: 6| Step: 4
Training loss: 0.4378608850049403
Validation loss: 2.288620237420946

Epoch: 6| Step: 5
Training loss: 0.21277877949381202
Validation loss: 2.262847173996458

Epoch: 6| Step: 6
Training loss: 0.3243490899309187
Validation loss: 2.284474160965778

Epoch: 6| Step: 7
Training loss: 0.42965991191731
Validation loss: 2.2769470662987272

Epoch: 6| Step: 8
Training loss: 0.5806604410283763
Validation loss: 2.3029867051717274

Epoch: 6| Step: 9
Training loss: 0.504647737005465
Validation loss: 2.31744150135368

Epoch: 6| Step: 10
Training loss: 0.41327837706867104
Validation loss: 2.3362402395164583

Epoch: 6| Step: 11
Training loss: 0.48126864335250025
Validation loss: 2.3672916651112725

Epoch: 6| Step: 12
Training loss: 0.43253923320878856
Validation loss: 2.3824006131963675

Epoch: 6| Step: 13
Training loss: 0.4009266312657992
Validation loss: 2.377224689265436

Epoch: 362| Step: 0
Training loss: 0.7115089718701352
Validation loss: 2.3877656122833693

Epoch: 6| Step: 1
Training loss: 0.29291668747205013
Validation loss: 2.389056970915902

Epoch: 6| Step: 2
Training loss: 0.5052714816344236
Validation loss: 2.390600780879387

Epoch: 6| Step: 3
Training loss: 0.33694279866058174
Validation loss: 2.3677189264053795

Epoch: 6| Step: 4
Training loss: 0.5332313222730402
Validation loss: 2.3456201006797786

Epoch: 6| Step: 5
Training loss: 0.4277363955654687
Validation loss: 2.364208899941736

Epoch: 6| Step: 6
Training loss: 0.4544569696109986
Validation loss: 2.324059545755753

Epoch: 6| Step: 7
Training loss: 0.526852131321247
Validation loss: 2.3253591057483396

Epoch: 6| Step: 8
Training loss: 0.19700179066606646
Validation loss: 2.3093613307914174

Epoch: 6| Step: 9
Training loss: 0.5214992906816145
Validation loss: 2.343493781629295

Epoch: 6| Step: 10
Training loss: 0.5191673208796919
Validation loss: 2.3367298157240075

Epoch: 6| Step: 11
Training loss: 0.3162867002338899
Validation loss: 2.3689221957581053

Epoch: 6| Step: 12
Training loss: 0.3075255242275877
Validation loss: 2.3126250817710874

Epoch: 6| Step: 13
Training loss: 0.1519862712511606
Validation loss: 2.3319524562517877

Epoch: 363| Step: 0
Training loss: 0.2630748913548039
Validation loss: 2.354055495871962

Epoch: 6| Step: 1
Training loss: 0.30765522312982935
Validation loss: 2.3451111147987875

Epoch: 6| Step: 2
Training loss: 0.4576298306941396
Validation loss: 2.355050253205542

Epoch: 6| Step: 3
Training loss: 0.3217727822890719
Validation loss: 2.3236092450488575

Epoch: 6| Step: 4
Training loss: 0.2827157924814068
Validation loss: 2.3432003347457453

Epoch: 6| Step: 5
Training loss: 0.4419829727945186
Validation loss: 2.3262018399646953

Epoch: 6| Step: 6
Training loss: 0.46770111990324154
Validation loss: 2.3472247261949355

Epoch: 6| Step: 7
Training loss: 0.48719743607172133
Validation loss: 2.3287475352646645

Epoch: 6| Step: 8
Training loss: 0.6876502306396701
Validation loss: 2.3234922061272028

Epoch: 6| Step: 9
Training loss: 0.35357056501690437
Validation loss: 2.3625229158086043

Epoch: 6| Step: 10
Training loss: 0.2069127355399422
Validation loss: 2.314579038810857

Epoch: 6| Step: 11
Training loss: 0.4357698836131673
Validation loss: 2.302579389127651

Epoch: 6| Step: 12
Training loss: 0.5941429092995335
Validation loss: 2.3262925764213582

Epoch: 6| Step: 13
Training loss: 0.23019964056446804
Validation loss: 2.3166685903627817

Epoch: 364| Step: 0
Training loss: 0.1511312430135871
Validation loss: 2.3081288707796186

Epoch: 6| Step: 1
Training loss: 0.4640065997585422
Validation loss: 2.3030223127680256

Epoch: 6| Step: 2
Training loss: 0.3468697577587286
Validation loss: 2.3026064986026453

Epoch: 6| Step: 3
Training loss: 0.5214207928361009
Validation loss: 2.308200498764257

Epoch: 6| Step: 4
Training loss: 0.3959880973864636
Validation loss: 2.3307629192633192

Epoch: 6| Step: 5
Training loss: 0.39740555960908786
Validation loss: 2.3319529179803093

Epoch: 6| Step: 6
Training loss: 0.2790163538756065
Validation loss: 2.349084431145577

Epoch: 6| Step: 7
Training loss: 0.40037183019673706
Validation loss: 2.352173283538768

Epoch: 6| Step: 8
Training loss: 0.25457430763967137
Validation loss: 2.36852899552301

Epoch: 6| Step: 9
Training loss: 0.5712233546363754
Validation loss: 2.4014802581584465

Epoch: 6| Step: 10
Training loss: 0.5931039105797268
Validation loss: 2.378959348710929

Epoch: 6| Step: 11
Training loss: 0.19070599390893533
Validation loss: 2.3763182046871303

Epoch: 6| Step: 12
Training loss: 0.41901322461268686
Validation loss: 2.36596225178948

Epoch: 6| Step: 13
Training loss: 0.3831808108988929
Validation loss: 2.391565138418457

Epoch: 365| Step: 0
Training loss: 0.23555673069365268
Validation loss: 2.3812964081343138

Epoch: 6| Step: 1
Training loss: 0.5063057185934855
Validation loss: 2.387929892217662

Epoch: 6| Step: 2
Training loss: 0.2750143632605732
Validation loss: 2.382396312122563

Epoch: 6| Step: 3
Training loss: 0.16815695642394884
Validation loss: 2.3887282113426997

Epoch: 6| Step: 4
Training loss: 0.6108729950395985
Validation loss: 2.3561319137241594

Epoch: 6| Step: 5
Training loss: 0.46048109443823776
Validation loss: 2.392703600454732

Epoch: 6| Step: 6
Training loss: 0.385048312215124
Validation loss: 2.3425751047197125

Epoch: 6| Step: 7
Training loss: 0.29398518035316096
Validation loss: 2.3604603529506663

Epoch: 6| Step: 8
Training loss: 0.33457304847075164
Validation loss: 2.3440507210487267

Epoch: 6| Step: 9
Training loss: 0.544707115813744
Validation loss: 2.3087768476526516

Epoch: 6| Step: 10
Training loss: 0.2345872077288809
Validation loss: 2.3237269080287364

Epoch: 6| Step: 11
Training loss: 0.5427650783206726
Validation loss: 2.3198082963966002

Epoch: 6| Step: 12
Training loss: 0.2953391628238106
Validation loss: 2.363206623539526

Epoch: 6| Step: 13
Training loss: 0.30943950211862137
Validation loss: 2.3742937936233677

Epoch: 366| Step: 0
Training loss: 0.2647099581787216
Validation loss: 2.3457891375665794

Epoch: 6| Step: 1
Training loss: 0.3495484837191542
Validation loss: 2.3638602347313227

Epoch: 6| Step: 2
Training loss: 0.23016324241774097
Validation loss: 2.345945996206074

Epoch: 6| Step: 3
Training loss: 0.43642216132714123
Validation loss: 2.352528030012138

Epoch: 6| Step: 4
Training loss: 0.5850636896692453
Validation loss: 2.3233430551014305

Epoch: 6| Step: 5
Training loss: 0.3351654007024835
Validation loss: 2.3271187573793237

Epoch: 6| Step: 6
Training loss: 0.17628688145680269
Validation loss: 2.312770405873457

Epoch: 6| Step: 7
Training loss: 0.37144409506840287
Validation loss: 2.3046209343442388

Epoch: 6| Step: 8
Training loss: 0.4620308274804803
Validation loss: 2.330636501526807

Epoch: 6| Step: 9
Training loss: 0.3643827045273911
Validation loss: 2.316514117047613

Epoch: 6| Step: 10
Training loss: 0.33035785627103975
Validation loss: 2.334505855247032

Epoch: 6| Step: 11
Training loss: 0.45152212972259365
Validation loss: 2.345866694477535

Epoch: 6| Step: 12
Training loss: 0.5440682181595211
Validation loss: 2.3289718700859114

Epoch: 6| Step: 13
Training loss: 0.11791532914278714
Validation loss: 2.3487615950181957

Epoch: 367| Step: 0
Training loss: 0.46741935692322023
Validation loss: 2.3490985906430977

Epoch: 6| Step: 1
Training loss: 0.4072456080970907
Validation loss: 2.349280337450119

Epoch: 6| Step: 2
Training loss: 0.5574855348395403
Validation loss: 2.3587282078338085

Epoch: 6| Step: 3
Training loss: 0.3889294255034722
Validation loss: 2.3208200073640204

Epoch: 6| Step: 4
Training loss: 0.33750917148490883
Validation loss: 2.337665925479648

Epoch: 6| Step: 5
Training loss: 0.4786478599474996
Validation loss: 2.3306263616651504

Epoch: 6| Step: 6
Training loss: 0.354438672610842
Validation loss: 2.365881454350047

Epoch: 6| Step: 7
Training loss: 0.2737822675195114
Validation loss: 2.314207264403274

Epoch: 6| Step: 8
Training loss: 0.3559740059864508
Validation loss: 2.316527652538663

Epoch: 6| Step: 9
Training loss: 0.40600343704647956
Validation loss: 2.3506196172808744

Epoch: 6| Step: 10
Training loss: 0.4610966229971378
Validation loss: 2.3309589719312322

Epoch: 6| Step: 11
Training loss: 0.30070839036596797
Validation loss: 2.3169357944296416

Epoch: 6| Step: 12
Training loss: 0.3623165735315495
Validation loss: 2.3349505015829344

Epoch: 6| Step: 13
Training loss: 0.24130582294548344
Validation loss: 2.2975256358776965

Epoch: 368| Step: 0
Training loss: 0.44909953318397283
Validation loss: 2.324467786788413

Epoch: 6| Step: 1
Training loss: 0.5204653266329198
Validation loss: 2.3199699317189784

Epoch: 6| Step: 2
Training loss: 0.5487315408560752
Validation loss: 2.3355015420488785

Epoch: 6| Step: 3
Training loss: 0.299559116748732
Validation loss: 2.355596672313109

Epoch: 6| Step: 4
Training loss: 0.34143215884228234
Validation loss: 2.3504547735974635

Epoch: 6| Step: 5
Training loss: 0.3281688887898847
Validation loss: 2.361156953064618

Epoch: 6| Step: 6
Training loss: 0.4103021634638232
Validation loss: 2.3513529427313347

Epoch: 6| Step: 7
Training loss: 0.34507368727894966
Validation loss: 2.3303894451675795

Epoch: 6| Step: 8
Training loss: 0.37953289557736664
Validation loss: 2.3208820374212356

Epoch: 6| Step: 9
Training loss: 0.3101418691227055
Validation loss: 2.3040210714890623

Epoch: 6| Step: 10
Training loss: 0.37506698963724555
Validation loss: 2.3024464825045183

Epoch: 6| Step: 11
Training loss: 0.49314103780951396
Validation loss: 2.3111905057315423

Epoch: 6| Step: 12
Training loss: 0.3559739641261974
Validation loss: 2.2796345917922336

Epoch: 6| Step: 13
Training loss: 0.3805992020318992
Validation loss: 2.265716752856002

Epoch: 369| Step: 0
Training loss: 0.42960932627398596
Validation loss: 2.282066511503755

Epoch: 6| Step: 1
Training loss: 0.3911505787337648
Validation loss: 2.295439037383846

Epoch: 6| Step: 2
Training loss: 0.5531856460514363
Validation loss: 2.291381327259571

Epoch: 6| Step: 3
Training loss: 0.5610548103946965
Validation loss: 2.3082635887490235

Epoch: 6| Step: 4
Training loss: 0.36588178974494373
Validation loss: 2.324954363396767

Epoch: 6| Step: 5
Training loss: 0.23843675760776042
Validation loss: 2.3551224200373597

Epoch: 6| Step: 6
Training loss: 0.48474805063856125
Validation loss: 2.33374374672577

Epoch: 6| Step: 7
Training loss: 0.5813137214351692
Validation loss: 2.366517456662679

Epoch: 6| Step: 8
Training loss: 0.2546771304822112
Validation loss: 2.3395388994882826

Epoch: 6| Step: 9
Training loss: 0.35279684601377354
Validation loss: 2.3199604809149426

Epoch: 6| Step: 10
Training loss: 0.4983542746536897
Validation loss: 2.317320845316267

Epoch: 6| Step: 11
Training loss: 0.32371855839011904
Validation loss: 2.29816269747916

Epoch: 6| Step: 12
Training loss: 0.26721782512234843
Validation loss: 2.342185521425446

Epoch: 6| Step: 13
Training loss: 0.5439066299573037
Validation loss: 2.342921595590663

Epoch: 370| Step: 0
Training loss: 0.43957089011794137
Validation loss: 2.329707077579161

Epoch: 6| Step: 1
Training loss: 0.18555619065841644
Validation loss: 2.2716736591077322

Epoch: 6| Step: 2
Training loss: 0.38142962679862397
Validation loss: 2.2665903186999468

Epoch: 6| Step: 3
Training loss: 0.47695996953628544
Validation loss: 2.280979216840794

Epoch: 6| Step: 4
Training loss: 0.27414172631360767
Validation loss: 2.2829510503235984

Epoch: 6| Step: 5
Training loss: 0.4784650036252384
Validation loss: 2.2820537205995755

Epoch: 6| Step: 6
Training loss: 0.43741598344348454
Validation loss: 2.2810298449900688

Epoch: 6| Step: 7
Training loss: 0.4563111884747864
Validation loss: 2.2610586007280737

Epoch: 6| Step: 8
Training loss: 0.3380057959990735
Validation loss: 2.293166154584221

Epoch: 6| Step: 9
Training loss: 0.4786798779151855
Validation loss: 2.3069293342906745

Epoch: 6| Step: 10
Training loss: 0.3499483457834155
Validation loss: 2.3540075366133335

Epoch: 6| Step: 11
Training loss: 0.4366498759762811
Validation loss: 2.3773659954989035

Epoch: 6| Step: 12
Training loss: 0.43358816538470524
Validation loss: 2.3795716930577746

Epoch: 6| Step: 13
Training loss: 0.2728302752765799
Validation loss: 2.3929578848823185

Epoch: 371| Step: 0
Training loss: 0.48416142215722535
Validation loss: 2.37872386603472

Epoch: 6| Step: 1
Training loss: 0.40371040525064505
Validation loss: 2.3586480554837346

Epoch: 6| Step: 2
Training loss: 0.3748861577166066
Validation loss: 2.4056747493632353

Epoch: 6| Step: 3
Training loss: 0.5134599197610009
Validation loss: 2.362006708339057

Epoch: 6| Step: 4
Training loss: 0.34973748486481776
Validation loss: 2.3677419389989227

Epoch: 6| Step: 5
Training loss: 0.5700942889244838
Validation loss: 2.3454716878638866

Epoch: 6| Step: 6
Training loss: 0.4930789987456194
Validation loss: 2.3389122325378677

Epoch: 6| Step: 7
Training loss: 0.42483262595021404
Validation loss: 2.320734392215073

Epoch: 6| Step: 8
Training loss: 0.2568824058820231
Validation loss: 2.343453632608345

Epoch: 6| Step: 9
Training loss: 0.3694266366769925
Validation loss: 2.285178720878943

Epoch: 6| Step: 10
Training loss: 0.24130552962243873
Validation loss: 2.314686014422723

Epoch: 6| Step: 11
Training loss: 0.2175188843432426
Validation loss: 2.298126765822832

Epoch: 6| Step: 12
Training loss: 0.4423756883060202
Validation loss: 2.2952324850837713

Epoch: 6| Step: 13
Training loss: 0.33987862857426315
Validation loss: 2.292112181493382

Epoch: 372| Step: 0
Training loss: 0.3571266664513524
Validation loss: 2.3301838004693094

Epoch: 6| Step: 1
Training loss: 0.46178029484445793
Validation loss: 2.3181738741359124

Epoch: 6| Step: 2
Training loss: 0.4217954489974766
Validation loss: 2.3068952277945627

Epoch: 6| Step: 3
Training loss: 0.40572378116635904
Validation loss: 2.3384053551203667

Epoch: 6| Step: 4
Training loss: 0.3372946538355032
Validation loss: 2.3630024786827106

Epoch: 6| Step: 5
Training loss: 0.4525960762023672
Validation loss: 2.363786154724984

Epoch: 6| Step: 6
Training loss: 0.45538766508896006
Validation loss: 2.359622069050385

Epoch: 6| Step: 7
Training loss: 0.3877140684419355
Validation loss: 2.3565615829246522

Epoch: 6| Step: 8
Training loss: 0.41680855917887333
Validation loss: 2.350634668925502

Epoch: 6| Step: 9
Training loss: 0.3722163036612894
Validation loss: 2.3484572078465287

Epoch: 6| Step: 10
Training loss: 0.2743397405035704
Validation loss: 2.344012051497423

Epoch: 6| Step: 11
Training loss: 0.23388522153626015
Validation loss: 2.317708887863139

Epoch: 6| Step: 12
Training loss: 0.2923523076006322
Validation loss: 2.3015675573636853

Epoch: 6| Step: 13
Training loss: 0.5535140183559406
Validation loss: 2.306126422640914

Epoch: 373| Step: 0
Training loss: 0.38806747523156776
Validation loss: 2.2947686918927306

Epoch: 6| Step: 1
Training loss: 0.2996171743877301
Validation loss: 2.3123487663094204

Epoch: 6| Step: 2
Training loss: 0.3862872751082549
Validation loss: 2.305139696445703

Epoch: 6| Step: 3
Training loss: 0.3800473482034676
Validation loss: 2.315715404628547

Epoch: 6| Step: 4
Training loss: 0.37130811422673327
Validation loss: 2.330244824907275

Epoch: 6| Step: 5
Training loss: 0.24150047993957818
Validation loss: 2.34520856421728

Epoch: 6| Step: 6
Training loss: 0.41217579238610896
Validation loss: 2.3293649097500997

Epoch: 6| Step: 7
Training loss: 0.2768320817168862
Validation loss: 2.377416423081125

Epoch: 6| Step: 8
Training loss: 0.41399904880552624
Validation loss: 2.366543373853512

Epoch: 6| Step: 9
Training loss: 0.3455438624196145
Validation loss: 2.3938891186810034

Epoch: 6| Step: 10
Training loss: 0.3121623480080224
Validation loss: 2.3917128127962424

Epoch: 6| Step: 11
Training loss: 0.4617796817341676
Validation loss: 2.384469332411048

Epoch: 6| Step: 12
Training loss: 0.5284978036067944
Validation loss: 2.3585894626419677

Epoch: 6| Step: 13
Training loss: 0.3017334542427595
Validation loss: 2.3449603274705404

Epoch: 374| Step: 0
Training loss: 0.4184748357592811
Validation loss: 2.330840339880502

Epoch: 6| Step: 1
Training loss: 0.4291774496865758
Validation loss: 2.318374258184135

Epoch: 6| Step: 2
Training loss: 0.39660700888694955
Validation loss: 2.3138903128305834

Epoch: 6| Step: 3
Training loss: 0.6412543485170568
Validation loss: 2.2988850984692273

Epoch: 6| Step: 4
Training loss: 0.24021692910465134
Validation loss: 2.2907285908880204

Epoch: 6| Step: 5
Training loss: 0.3757190169037042
Validation loss: 2.319918004034262

Epoch: 6| Step: 6
Training loss: 0.2505951443390897
Validation loss: 2.297933465612884

Epoch: 6| Step: 7
Training loss: 0.338169886558837
Validation loss: 2.3392460266561113

Epoch: 6| Step: 8
Training loss: 0.2756374957048283
Validation loss: 2.331287811548011

Epoch: 6| Step: 9
Training loss: 0.27058470146257046
Validation loss: 2.3531758536264804

Epoch: 6| Step: 10
Training loss: 0.3228553924056452
Validation loss: 2.3756995873544846

Epoch: 6| Step: 11
Training loss: 0.3297284548302607
Validation loss: 2.3434720799551507

Epoch: 6| Step: 12
Training loss: 0.4304279017236121
Validation loss: 2.3819345294078698

Epoch: 6| Step: 13
Training loss: 0.39939609850939234
Validation loss: 2.362858497221203

Epoch: 375| Step: 0
Training loss: 0.37123384341009963
Validation loss: 2.3539347093763037

Epoch: 6| Step: 1
Training loss: 0.3093472227477167
Validation loss: 2.3788712862985055

Epoch: 6| Step: 2
Training loss: 0.4577079555936472
Validation loss: 2.3101275523497584

Epoch: 6| Step: 3
Training loss: 0.5482075396584684
Validation loss: 2.319723306997623

Epoch: 6| Step: 4
Training loss: 0.45569482038135495
Validation loss: 2.3610252450011324

Epoch: 6| Step: 5
Training loss: 0.37389273887290825
Validation loss: 2.3873269977156597

Epoch: 6| Step: 6
Training loss: 0.319852300677777
Validation loss: 2.3606225029544365

Epoch: 6| Step: 7
Training loss: 0.3674414547848364
Validation loss: 2.3768034069747452

Epoch: 6| Step: 8
Training loss: 0.16604446272867043
Validation loss: 2.376744978027787

Epoch: 6| Step: 9
Training loss: 0.2516840895617559
Validation loss: 2.375328686718368

Epoch: 6| Step: 10
Training loss: 0.3635423603798151
Validation loss: 2.3967102753577105

Epoch: 6| Step: 11
Training loss: 0.3040310561730097
Validation loss: 2.389931468992818

Epoch: 6| Step: 12
Training loss: 0.3768899894377834
Validation loss: 2.354426519274934

Epoch: 6| Step: 13
Training loss: 0.2734053865376157
Validation loss: 2.335820905389183

Epoch: 376| Step: 0
Training loss: 0.27381919378280506
Validation loss: 2.3386880882831065

Epoch: 6| Step: 1
Training loss: 0.5041934533004757
Validation loss: 2.351196288892132

Epoch: 6| Step: 2
Training loss: 0.44779370712383787
Validation loss: 2.3376166286900437

Epoch: 6| Step: 3
Training loss: 0.27895296704631783
Validation loss: 2.3444544596914083

Epoch: 6| Step: 4
Training loss: 0.39508325843123715
Validation loss: 2.305471364224622

Epoch: 6| Step: 5
Training loss: 0.39674720133279295
Validation loss: 2.3005994861485553

Epoch: 6| Step: 6
Training loss: 0.21881252485164532
Validation loss: 2.350550729228953

Epoch: 6| Step: 7
Training loss: 0.3506750986955351
Validation loss: 2.3496112102164877

Epoch: 6| Step: 8
Training loss: 0.4617050214039969
Validation loss: 2.393012475874747

Epoch: 6| Step: 9
Training loss: 0.3746367125336507
Validation loss: 2.361351082623203

Epoch: 6| Step: 10
Training loss: 0.27142828766773924
Validation loss: 2.3580966567597663

Epoch: 6| Step: 11
Training loss: 0.30630732603126387
Validation loss: 2.319131997468994

Epoch: 6| Step: 12
Training loss: 0.2125842663635939
Validation loss: 2.288699924831197

Epoch: 6| Step: 13
Training loss: 0.49446430084574083
Validation loss: 2.2675153275565654

Epoch: 377| Step: 0
Training loss: 0.46418077008561653
Validation loss: 2.276512633603726

Epoch: 6| Step: 1
Training loss: 0.39306564804856997
Validation loss: 2.2765090817987623

Epoch: 6| Step: 2
Training loss: 0.22185836850546597
Validation loss: 2.2667298324290144

Epoch: 6| Step: 3
Training loss: 0.3575852234502329
Validation loss: 2.2689017973185637

Epoch: 6| Step: 4
Training loss: 0.31317305801412537
Validation loss: 2.303899048313442

Epoch: 6| Step: 5
Training loss: 0.29976959520165974
Validation loss: 2.3125718218407196

Epoch: 6| Step: 6
Training loss: 0.28270414394759447
Validation loss: 2.336541616591576

Epoch: 6| Step: 7
Training loss: 0.39375952981588097
Validation loss: 2.353845196669934

Epoch: 6| Step: 8
Training loss: 0.3903584715415859
Validation loss: 2.352784382502613

Epoch: 6| Step: 9
Training loss: 0.24267541282825403
Validation loss: 2.341830476471578

Epoch: 6| Step: 10
Training loss: 0.2778968802395023
Validation loss: 2.3256273963976

Epoch: 6| Step: 11
Training loss: 0.33995605673886614
Validation loss: 2.337259114702818

Epoch: 6| Step: 12
Training loss: 0.48572717634994894
Validation loss: 2.3346836347803794

Epoch: 6| Step: 13
Training loss: 0.5758583379561998
Validation loss: 2.326130202013197

Epoch: 378| Step: 0
Training loss: 0.37692675720653346
Validation loss: 2.3502956416488017

Epoch: 6| Step: 1
Training loss: 0.3204193169732645
Validation loss: 2.3056975979157412

Epoch: 6| Step: 2
Training loss: 0.20953638490078527
Validation loss: 2.306812817146505

Epoch: 6| Step: 3
Training loss: 0.267307395135327
Validation loss: 2.2890701295218108

Epoch: 6| Step: 4
Training loss: 0.4104115009789604
Validation loss: 2.2817773028338078

Epoch: 6| Step: 5
Training loss: 0.23430216770229675
Validation loss: 2.313915458046094

Epoch: 6| Step: 6
Training loss: 0.3239741839224258
Validation loss: 2.319544573153592

Epoch: 6| Step: 7
Training loss: 0.40085217924616495
Validation loss: 2.301039455215575

Epoch: 6| Step: 8
Training loss: 0.23596172461030937
Validation loss: 2.3231617416460373

Epoch: 6| Step: 9
Training loss: 0.4208558275644378
Validation loss: 2.289738675441103

Epoch: 6| Step: 10
Training loss: 0.15699213333109965
Validation loss: 2.3024748595126727

Epoch: 6| Step: 11
Training loss: 0.622257198604756
Validation loss: 2.2976232809202033

Epoch: 6| Step: 12
Training loss: 0.25718001608545266
Validation loss: 2.2957862582372894

Epoch: 6| Step: 13
Training loss: 0.38176371484064
Validation loss: 2.3195226490662573

Epoch: 379| Step: 0
Training loss: 0.4046298144257084
Validation loss: 2.3021842892831215

Epoch: 6| Step: 1
Training loss: 0.4881880404198678
Validation loss: 2.302557520058238

Epoch: 6| Step: 2
Training loss: 0.33813196725066097
Validation loss: 2.344086293257148

Epoch: 6| Step: 3
Training loss: 0.39433701143312194
Validation loss: 2.328052331043992

Epoch: 6| Step: 4
Training loss: 0.3501900480505505
Validation loss: 2.3488671535414642

Epoch: 6| Step: 5
Training loss: 0.43233613471082166
Validation loss: 2.3123251126316084

Epoch: 6| Step: 6
Training loss: 0.25670677099065675
Validation loss: 2.341167072934064

Epoch: 6| Step: 7
Training loss: 0.3496528683678818
Validation loss: 2.3186228969241847

Epoch: 6| Step: 8
Training loss: 0.4150518437829772
Validation loss: 2.290281747822732

Epoch: 6| Step: 9
Training loss: 0.33141940346621274
Validation loss: 2.328356763050174

Epoch: 6| Step: 10
Training loss: 0.22818750478848462
Validation loss: 2.3124057802685365

Epoch: 6| Step: 11
Training loss: 0.19844751107502137
Validation loss: 2.296183210928202

Epoch: 6| Step: 12
Training loss: 0.19297320403236773
Validation loss: 2.3206271342224323

Epoch: 6| Step: 13
Training loss: 0.3072236465344822
Validation loss: 2.30488769651747

Epoch: 380| Step: 0
Training loss: 0.3587124148229058
Validation loss: 2.2962069326377605

Epoch: 6| Step: 1
Training loss: 0.4290370178990823
Validation loss: 2.315242873406655

Epoch: 6| Step: 2
Training loss: 0.266150823622251
Validation loss: 2.3045531264131354

Epoch: 6| Step: 3
Training loss: 0.5140925088489148
Validation loss: 2.3269737377437885

Epoch: 6| Step: 4
Training loss: 0.3820096569550764
Validation loss: 2.315429037020699

Epoch: 6| Step: 5
Training loss: 0.16177512950641493
Validation loss: 2.3001769875639706

Epoch: 6| Step: 6
Training loss: 0.34993602900358556
Validation loss: 2.3229797551895985

Epoch: 6| Step: 7
Training loss: 0.29676226935053324
Validation loss: 2.3264018689044836

Epoch: 6| Step: 8
Training loss: 0.3490730305912901
Validation loss: 2.337541163140591

Epoch: 6| Step: 9
Training loss: 0.25982007194627427
Validation loss: 2.337892153606103

Epoch: 6| Step: 10
Training loss: 0.42334450759870595
Validation loss: 2.293641679263783

Epoch: 6| Step: 11
Training loss: 0.34728671375687226
Validation loss: 2.291453946962542

Epoch: 6| Step: 12
Training loss: 0.20315497433975294
Validation loss: 2.2718091717397346

Epoch: 6| Step: 13
Training loss: 0.2411143692628609
Validation loss: 2.3033419689101295

Epoch: 381| Step: 0
Training loss: 0.14441579640724825
Validation loss: 2.279069785529702

Epoch: 6| Step: 1
Training loss: 0.35472194067493185
Validation loss: 2.2634035143734264

Epoch: 6| Step: 2
Training loss: 0.3621909073413471
Validation loss: 2.2993783563701116

Epoch: 6| Step: 3
Training loss: 0.2740121117206915
Validation loss: 2.3016007598349475

Epoch: 6| Step: 4
Training loss: 0.25915100410383923
Validation loss: 2.289524487429658

Epoch: 6| Step: 5
Training loss: 0.38148072249777004
Validation loss: 2.2725773929255446

Epoch: 6| Step: 6
Training loss: 0.5466692946339841
Validation loss: 2.303528630785482

Epoch: 6| Step: 7
Training loss: 0.5388443823451567
Validation loss: 2.2867626348632144

Epoch: 6| Step: 8
Training loss: 0.3804300088760643
Validation loss: 2.292067933586609

Epoch: 6| Step: 9
Training loss: 0.3422105737858443
Validation loss: 2.3090555046325454

Epoch: 6| Step: 10
Training loss: 0.17866181912832566
Validation loss: 2.3074079400132668

Epoch: 6| Step: 11
Training loss: 0.2558928314931904
Validation loss: 2.3366703402945426

Epoch: 6| Step: 12
Training loss: 0.2876265791385874
Validation loss: 2.320453954236528

Epoch: 6| Step: 13
Training loss: 0.18499704510030085
Validation loss: 2.3522121916629124

Epoch: 382| Step: 0
Training loss: 0.3350475855380697
Validation loss: 2.336298128213891

Epoch: 6| Step: 1
Training loss: 0.39460721559298095
Validation loss: 2.330059054495668

Epoch: 6| Step: 2
Training loss: 0.21380896624979326
Validation loss: 2.3470263239101383

Epoch: 6| Step: 3
Training loss: 0.3801816926619565
Validation loss: 2.327016408624462

Epoch: 6| Step: 4
Training loss: 0.19689880862914513
Validation loss: 2.300754617092971

Epoch: 6| Step: 5
Training loss: 0.2953667474805429
Validation loss: 2.3014406855053977

Epoch: 6| Step: 6
Training loss: 0.3971503916767662
Validation loss: 2.3231773452762963

Epoch: 6| Step: 7
Training loss: 0.39971188957715786
Validation loss: 2.327310139147007

Epoch: 6| Step: 8
Training loss: 0.25717866896326796
Validation loss: 2.3285809863401976

Epoch: 6| Step: 9
Training loss: 0.2881934789592907
Validation loss: 2.3224014922369802

Epoch: 6| Step: 10
Training loss: 0.6069380621158674
Validation loss: 2.3189489347226977

Epoch: 6| Step: 11
Training loss: 0.3658406330906812
Validation loss: 2.3032960123047825

Epoch: 6| Step: 12
Training loss: 0.14308991743504873
Validation loss: 2.2949471267431516

Epoch: 6| Step: 13
Training loss: 0.4661751281512255
Validation loss: 2.3043408416277877

Epoch: 383| Step: 0
Training loss: 0.15016154392052064
Validation loss: 2.3432421499799694

Epoch: 6| Step: 1
Training loss: 0.39365012855067383
Validation loss: 2.333047834156181

Epoch: 6| Step: 2
Training loss: 0.4485524751229438
Validation loss: 2.3089535987303167

Epoch: 6| Step: 3
Training loss: 0.22297977901413746
Validation loss: 2.319044899193417

Epoch: 6| Step: 4
Training loss: 0.4005427745998346
Validation loss: 2.341283411163478

Epoch: 6| Step: 5
Training loss: 0.3369993019082624
Validation loss: 2.3432620792387655

Epoch: 6| Step: 6
Training loss: 0.24691471281420127
Validation loss: 2.3662937583136436

Epoch: 6| Step: 7
Training loss: 0.2939860546987591
Validation loss: 2.369785811236609

Epoch: 6| Step: 8
Training loss: 0.41667574236840244
Validation loss: 2.364471069319239

Epoch: 6| Step: 9
Training loss: 0.10194256625546191
Validation loss: 2.338860821321897

Epoch: 6| Step: 10
Training loss: 0.2977667140489388
Validation loss: 2.3306300666673114

Epoch: 6| Step: 11
Training loss: 0.38063375196745963
Validation loss: 2.266655646423439

Epoch: 6| Step: 12
Training loss: 0.40789889447258093
Validation loss: 2.3317492653923746

Epoch: 6| Step: 13
Training loss: 0.5846591483031109
Validation loss: 2.309132266393793

Epoch: 384| Step: 0
Training loss: 0.3173977892349785
Validation loss: 2.259296263092671

Epoch: 6| Step: 1
Training loss: 0.3659887835289995
Validation loss: 2.2811722561676384

Epoch: 6| Step: 2
Training loss: 0.4256831239792677
Validation loss: 2.2699422204578386

Epoch: 6| Step: 3
Training loss: 0.38923359061990526
Validation loss: 2.280433398497687

Epoch: 6| Step: 4
Training loss: 0.30218866446664194
Validation loss: 2.3065576195172817

Epoch: 6| Step: 5
Training loss: 0.3904912338103235
Validation loss: 2.2933596442239086

Epoch: 6| Step: 6
Training loss: 0.29443384679780277
Validation loss: 2.3190913042586745

Epoch: 6| Step: 7
Training loss: 0.2077842908370821
Validation loss: 2.3445879307248676

Epoch: 6| Step: 8
Training loss: 0.14623145839742996
Validation loss: 2.3372739230573765

Epoch: 6| Step: 9
Training loss: 0.2318963914448165
Validation loss: 2.3595790778851566

Epoch: 6| Step: 10
Training loss: 0.5345755440592221
Validation loss: 2.391711763420783

Epoch: 6| Step: 11
Training loss: 0.3728174432776925
Validation loss: 2.3873303486747015

Epoch: 6| Step: 12
Training loss: 0.27435583128042623
Validation loss: 2.400824108112106

Epoch: 6| Step: 13
Training loss: 0.3002217526230605
Validation loss: 2.3838022356233575

Epoch: 385| Step: 0
Training loss: 0.19837292461535533
Validation loss: 2.3811786571483733

Epoch: 6| Step: 1
Training loss: 0.27308986909262756
Validation loss: 2.4023755666121724

Epoch: 6| Step: 2
Training loss: 0.31495881734818315
Validation loss: 2.3730099927233077

Epoch: 6| Step: 3
Training loss: 0.3699211869842673
Validation loss: 2.361395813845849

Epoch: 6| Step: 4
Training loss: 0.3244048698909658
Validation loss: 2.346901394205285

Epoch: 6| Step: 5
Training loss: 0.32362416911396086
Validation loss: 2.361963984709766

Epoch: 6| Step: 6
Training loss: 0.4186516646318954
Validation loss: 2.389270329752418

Epoch: 6| Step: 7
Training loss: 0.4658022383216386
Validation loss: 2.3642951121456317

Epoch: 6| Step: 8
Training loss: 0.20707786683006257
Validation loss: 2.3721492867008696

Epoch: 6| Step: 9
Training loss: 0.339006994248427
Validation loss: 2.3833427593659504

Epoch: 6| Step: 10
Training loss: 0.4152713260376277
Validation loss: 2.403800336427947

Epoch: 6| Step: 11
Training loss: 0.2781624731257625
Validation loss: 2.415167619065196

Epoch: 6| Step: 12
Training loss: 0.47335700430357464
Validation loss: 2.4137907129077663

Epoch: 6| Step: 13
Training loss: 0.2424071607878741
Validation loss: 2.3793762923768598

Epoch: 386| Step: 0
Training loss: 0.3066417305312911
Validation loss: 2.3866206715360674

Epoch: 6| Step: 1
Training loss: 0.21612303203748015
Validation loss: 2.3632114129903607

Epoch: 6| Step: 2
Training loss: 0.4414505725314642
Validation loss: 2.334911183942568

Epoch: 6| Step: 3
Training loss: 0.30386414910467285
Validation loss: 2.3575886352377817

Epoch: 6| Step: 4
Training loss: 0.39155285311153737
Validation loss: 2.325268917473767

Epoch: 6| Step: 5
Training loss: 0.342965118632285
Validation loss: 2.341629821653299

Epoch: 6| Step: 6
Training loss: 0.20038194098441653
Validation loss: 2.361265361696855

Epoch: 6| Step: 7
Training loss: 0.44365166595427363
Validation loss: 2.3646460701857475

Epoch: 6| Step: 8
Training loss: 0.3557007839260734
Validation loss: 2.3536676587099343

Epoch: 6| Step: 9
Training loss: 0.38571361967122636
Validation loss: 2.372556697944643

Epoch: 6| Step: 10
Training loss: 0.37676987616336827
Validation loss: 2.3505813055517133

Epoch: 6| Step: 11
Training loss: 0.3737389700356042
Validation loss: 2.3448419465100203

Epoch: 6| Step: 12
Training loss: 0.44129257088646207
Validation loss: 2.30528887089181

Epoch: 6| Step: 13
Training loss: 0.12722449276686779
Validation loss: 2.2971590586515704

Epoch: 387| Step: 0
Training loss: 0.4822785477333591
Validation loss: 2.3329867693044672

Epoch: 6| Step: 1
Training loss: 0.43957568684777953
Validation loss: 2.3089475570026803

Epoch: 6| Step: 2
Training loss: 0.37537361447856327
Validation loss: 2.268602720333599

Epoch: 6| Step: 3
Training loss: 0.25871401004386513
Validation loss: 2.299993170183696

Epoch: 6| Step: 4
Training loss: 0.2588131587488321
Validation loss: 2.319434237181895

Epoch: 6| Step: 5
Training loss: 0.40731232469597967
Validation loss: 2.301636701859896

Epoch: 6| Step: 6
Training loss: 0.2684172677530094
Validation loss: 2.3362488667565513

Epoch: 6| Step: 7
Training loss: 0.2988616575488086
Validation loss: 2.3750139180991567

Epoch: 6| Step: 8
Training loss: 0.3942300761164858
Validation loss: 2.3885045946390138

Epoch: 6| Step: 9
Training loss: 0.19054159153193628
Validation loss: 2.3624350676083132

Epoch: 6| Step: 10
Training loss: 0.46980089959533067
Validation loss: 2.3857188671256178

Epoch: 6| Step: 11
Training loss: 0.33171911714868624
Validation loss: 2.3852590813452954

Epoch: 6| Step: 12
Training loss: 0.27911891469544636
Validation loss: 2.381152191362561

Epoch: 6| Step: 13
Training loss: 0.35226112462678105
Validation loss: 2.383050809227086

Epoch: 388| Step: 0
Training loss: 0.3775452228010006
Validation loss: 2.3750935068165093

Epoch: 6| Step: 1
Training loss: 0.3731383366333905
Validation loss: 2.3545678245508728

Epoch: 6| Step: 2
Training loss: 0.3087777060266842
Validation loss: 2.3491366902846416

Epoch: 6| Step: 3
Training loss: 0.3658639102828195
Validation loss: 2.3373842323786573

Epoch: 6| Step: 4
Training loss: 0.32844358826936876
Validation loss: 2.306103996908531

Epoch: 6| Step: 5
Training loss: 0.29824806462400993
Validation loss: 2.336786275963903

Epoch: 6| Step: 6
Training loss: 0.3120917395239263
Validation loss: 2.333765096168236

Epoch: 6| Step: 7
Training loss: 0.34015711225716644
Validation loss: 2.3754346446578047

Epoch: 6| Step: 8
Training loss: 0.38473783673474
Validation loss: 2.3721016154495955

Epoch: 6| Step: 9
Training loss: 0.4368770114705027
Validation loss: 2.3478002192341574

Epoch: 6| Step: 10
Training loss: 0.35112205041588285
Validation loss: 2.397945015590937

Epoch: 6| Step: 11
Training loss: 0.3727046535254136
Validation loss: 2.422737814717676

Epoch: 6| Step: 12
Training loss: 0.1914277064694936
Validation loss: 2.3890093022408356

Epoch: 6| Step: 13
Training loss: 0.3556257048132269
Validation loss: 2.385194517600318

Epoch: 389| Step: 0
Training loss: 0.41621122105130975
Validation loss: 2.3936007854776298

Epoch: 6| Step: 1
Training loss: 0.31645610793266493
Validation loss: 2.41758569534662

Epoch: 6| Step: 2
Training loss: 0.15116476244298385
Validation loss: 2.367475652049627

Epoch: 6| Step: 3
Training loss: 0.20600641055687774
Validation loss: 2.384842709576789

Epoch: 6| Step: 4
Training loss: 0.26838943946044874
Validation loss: 2.3845435740387884

Epoch: 6| Step: 5
Training loss: 0.23349514158941032
Validation loss: 2.416500054692086

Epoch: 6| Step: 6
Training loss: 0.324514139575636
Validation loss: 2.410902461876352

Epoch: 6| Step: 7
Training loss: 0.29000941680549136
Validation loss: 2.3761868466316773

Epoch: 6| Step: 8
Training loss: 0.594412033018428
Validation loss: 2.4331869455835493

Epoch: 6| Step: 9
Training loss: 0.3171663455767734
Validation loss: 2.4323063249816705

Epoch: 6| Step: 10
Training loss: 0.40192387718209466
Validation loss: 2.3835592153247713

Epoch: 6| Step: 11
Training loss: 0.4594904605282046
Validation loss: 2.399922643717163

Epoch: 6| Step: 12
Training loss: 0.24080794179658177
Validation loss: 2.384089283877184

Epoch: 6| Step: 13
Training loss: 0.6581155282884971
Validation loss: 2.3683986185768786

Epoch: 390| Step: 0
Training loss: 0.3436727436988641
Validation loss: 2.3496737065564126

Epoch: 6| Step: 1
Training loss: 0.4950841708338602
Validation loss: 2.3584157689803185

Epoch: 6| Step: 2
Training loss: 0.19757450584635577
Validation loss: 2.3207155210977306

Epoch: 6| Step: 3
Training loss: 0.37588769432175245
Validation loss: 2.322839355359418

Epoch: 6| Step: 4
Training loss: 0.46513537066943267
Validation loss: 2.316695151534225

Epoch: 6| Step: 5
Training loss: 0.33772560455914247
Validation loss: 2.328749678651161

Epoch: 6| Step: 6
Training loss: 0.5229652893845461
Validation loss: 2.2854887784993965

Epoch: 6| Step: 7
Training loss: 0.2709686127896468
Validation loss: 2.2959010235849378

Epoch: 6| Step: 8
Training loss: 0.49953617994389254
Validation loss: 2.287521498774261

Epoch: 6| Step: 9
Training loss: 0.4227044992882483
Validation loss: 2.34739066712864

Epoch: 6| Step: 10
Training loss: 0.3658401239491926
Validation loss: 2.303531458710766

Epoch: 6| Step: 11
Training loss: 0.45240796017216506
Validation loss: 2.32731195229205

Epoch: 6| Step: 12
Training loss: 0.36147255974878606
Validation loss: 2.3379968947370284

Epoch: 6| Step: 13
Training loss: 0.37021011756047695
Validation loss: 2.356470889526519

Epoch: 391| Step: 0
Training loss: 0.2933935010949569
Validation loss: 2.370597766262036

Epoch: 6| Step: 1
Training loss: 0.4720484395892214
Validation loss: 2.409194773389893

Epoch: 6| Step: 2
Training loss: 0.37329400948920016
Validation loss: 2.3638908004896004

Epoch: 6| Step: 3
Training loss: 0.5008137756354262
Validation loss: 2.392120872402333

Epoch: 6| Step: 4
Training loss: 0.2431397406735606
Validation loss: 2.3765942706634315

Epoch: 6| Step: 5
Training loss: 0.34748814837053127
Validation loss: 2.3927859617750227

Epoch: 6| Step: 6
Training loss: 0.3386900821002382
Validation loss: 2.3553086288997584

Epoch: 6| Step: 7
Training loss: 0.2825748182487696
Validation loss: 2.3163041583750394

Epoch: 6| Step: 8
Training loss: 0.40877835569107274
Validation loss: 2.311407656594867

Epoch: 6| Step: 9
Training loss: 0.44707451614663435
Validation loss: 2.29342206209115

Epoch: 6| Step: 10
Training loss: 0.17796345504439637
Validation loss: 2.269399301537634

Epoch: 6| Step: 11
Training loss: 0.4761538864380514
Validation loss: 2.3170790784671698

Epoch: 6| Step: 12
Training loss: 0.2596811286199753
Validation loss: 2.3017380618406618

Epoch: 6| Step: 13
Training loss: 0.3704548003017126
Validation loss: 2.308384204554354

Epoch: 392| Step: 0
Training loss: 0.3925104415014948
Validation loss: 2.329982536557142

Epoch: 6| Step: 1
Training loss: 0.4266708948936665
Validation loss: 2.3474387015074076

Epoch: 6| Step: 2
Training loss: 0.3634613575079052
Validation loss: 2.3309786894618605

Epoch: 6| Step: 3
Training loss: 0.41508357987354744
Validation loss: 2.354760612777173

Epoch: 6| Step: 4
Training loss: 0.18129946346156225
Validation loss: 2.376766179585398

Epoch: 6| Step: 5
Training loss: 0.4082948864463628
Validation loss: 2.3500466097318045

Epoch: 6| Step: 6
Training loss: 0.3974770207630665
Validation loss: 2.316666905000394

Epoch: 6| Step: 7
Training loss: 0.3795156003411829
Validation loss: 2.2939506589406675

Epoch: 6| Step: 8
Training loss: 0.26954684005099344
Validation loss: 2.28569212194928

Epoch: 6| Step: 9
Training loss: 0.45273451587059327
Validation loss: 2.2787137580744385

Epoch: 6| Step: 10
Training loss: 0.47280693804790647
Validation loss: 2.313557708023158

Epoch: 6| Step: 11
Training loss: 0.4012733591119481
Validation loss: 2.324378173026285

Epoch: 6| Step: 12
Training loss: 0.4511970083659162
Validation loss: 2.349094180030705

Epoch: 6| Step: 13
Training loss: 0.28322130342216595
Validation loss: 2.3295173938187954

Epoch: 393| Step: 0
Training loss: 0.3337660070038263
Validation loss: 2.389911492319969

Epoch: 6| Step: 1
Training loss: 0.3825634516028136
Validation loss: 2.3767909878426843

Epoch: 6| Step: 2
Training loss: 0.39082211289570196
Validation loss: 2.377533961974019

Epoch: 6| Step: 3
Training loss: 0.4769902732685127
Validation loss: 2.430795647462414

Epoch: 6| Step: 4
Training loss: 0.47759737934155533
Validation loss: 2.4275225571514887

Epoch: 6| Step: 5
Training loss: 0.36790943194080755
Validation loss: 2.3821710474594413

Epoch: 6| Step: 6
Training loss: 0.43112099556239725
Validation loss: 2.3488431824600906

Epoch: 6| Step: 7
Training loss: 0.2139707166665777
Validation loss: 2.3186565185627708

Epoch: 6| Step: 8
Training loss: 0.4241168185973154
Validation loss: 2.3282856802843566

Epoch: 6| Step: 9
Training loss: 0.17074404690824652
Validation loss: 2.32893459142672

Epoch: 6| Step: 10
Training loss: 0.5004841725250556
Validation loss: 2.2954596955005213

Epoch: 6| Step: 11
Training loss: 0.347865802317071
Validation loss: 2.2680563056887175

Epoch: 6| Step: 12
Training loss: 0.4276806871695765
Validation loss: 2.270012786212685

Epoch: 6| Step: 13
Training loss: 0.27208641590623245
Validation loss: 2.3001783718229767

Epoch: 394| Step: 0
Training loss: 0.23306057629158342
Validation loss: 2.290181547037399

Epoch: 6| Step: 1
Training loss: 0.4821178698498357
Validation loss: 2.3028153118047316

Epoch: 6| Step: 2
Training loss: 0.3398715369604753
Validation loss: 2.3459371707681695

Epoch: 6| Step: 3
Training loss: 0.29179491759924214
Validation loss: 2.3205030919654104

Epoch: 6| Step: 4
Training loss: 0.39763273982790065
Validation loss: 2.3532423040858164

Epoch: 6| Step: 5
Training loss: 0.33290290858200444
Validation loss: 2.3551076855386777

Epoch: 6| Step: 6
Training loss: 0.2085188556190765
Validation loss: 2.3964239638166793

Epoch: 6| Step: 7
Training loss: 0.3926508821848397
Validation loss: 2.3921117446992968

Epoch: 6| Step: 8
Training loss: 0.29728821807702105
Validation loss: 2.3884744361752186

Epoch: 6| Step: 9
Training loss: 0.21574810598068067
Validation loss: 2.363146950941446

Epoch: 6| Step: 10
Training loss: 0.36191721141287286
Validation loss: 2.391034137316362

Epoch: 6| Step: 11
Training loss: 0.34483458903925873
Validation loss: 2.3541519064027177

Epoch: 6| Step: 12
Training loss: 0.3448480278617481
Validation loss: 2.3398285407394916

Epoch: 6| Step: 13
Training loss: 0.530671000514273
Validation loss: 2.340917322330625

Epoch: 395| Step: 0
Training loss: 0.22172624880453765
Validation loss: 2.3522320994169217

Epoch: 6| Step: 1
Training loss: 0.291687235220492
Validation loss: 2.3693547823919543

Epoch: 6| Step: 2
Training loss: 0.40310862899776895
Validation loss: 2.3600054200671403

Epoch: 6| Step: 3
Training loss: 0.15343657416590734
Validation loss: 2.413296257571014

Epoch: 6| Step: 4
Training loss: 0.24536538191905413
Validation loss: 2.3673947373297666

Epoch: 6| Step: 5
Training loss: 0.3775787301101114
Validation loss: 2.4133532962102024

Epoch: 6| Step: 6
Training loss: 0.37411390360885927
Validation loss: 2.4033420743082554

Epoch: 6| Step: 7
Training loss: 0.24600667775499427
Validation loss: 2.4026490259047493

Epoch: 6| Step: 8
Training loss: 0.31856457702516433
Validation loss: 2.400879926525575

Epoch: 6| Step: 9
Training loss: 0.4914421311031344
Validation loss: 2.372845658684488

Epoch: 6| Step: 10
Training loss: 0.4057047008569745
Validation loss: 2.381583521593692

Epoch: 6| Step: 11
Training loss: 0.4112037724308901
Validation loss: 2.337767445011954

Epoch: 6| Step: 12
Training loss: 0.2613846083470843
Validation loss: 2.356451493005558

Epoch: 6| Step: 13
Training loss: 0.33510501976880896
Validation loss: 2.3250702933681846

Epoch: 396| Step: 0
Training loss: 0.3130825216258106
Validation loss: 2.338528557964552

Epoch: 6| Step: 1
Training loss: 0.3143327849997885
Validation loss: 2.312549947494684

Epoch: 6| Step: 2
Training loss: 0.14304148486246493
Validation loss: 2.376782994758323

Epoch: 6| Step: 3
Training loss: 0.28499895486723686
Validation loss: 2.359569746614448

Epoch: 6| Step: 4
Training loss: 0.4548704467507812
Validation loss: 2.343784919943504

Epoch: 6| Step: 5
Training loss: 0.29344186093032154
Validation loss: 2.3478456988967937

Epoch: 6| Step: 6
Training loss: 0.2560314880848628
Validation loss: 2.325201610248581

Epoch: 6| Step: 7
Training loss: 0.29798818487868506
Validation loss: 2.349732882853736

Epoch: 6| Step: 8
Training loss: 0.3655639833905129
Validation loss: 2.3424768179611224

Epoch: 6| Step: 9
Training loss: 0.31174289064935345
Validation loss: 2.3512171145966954

Epoch: 6| Step: 10
Training loss: 0.388912088358771
Validation loss: 2.33223621736474

Epoch: 6| Step: 11
Training loss: 0.22830403957673795
Validation loss: 2.336888853949611

Epoch: 6| Step: 12
Training loss: 0.31107736058653557
Validation loss: 2.3104531681381912

Epoch: 6| Step: 13
Training loss: 0.44929815502777065
Validation loss: 2.298567781468642

Epoch: 397| Step: 0
Training loss: 0.1339876900198865
Validation loss: 2.30965266083191

Epoch: 6| Step: 1
Training loss: 0.26604470585576
Validation loss: 2.291623591878663

Epoch: 6| Step: 2
Training loss: 0.3841120013996138
Validation loss: 2.326287617012475

Epoch: 6| Step: 3
Training loss: 0.42212464752046996
Validation loss: 2.3251298455552853

Epoch: 6| Step: 4
Training loss: 0.416267963228023
Validation loss: 2.3448277293287605

Epoch: 6| Step: 5
Training loss: 0.2490228540750289
Validation loss: 2.3775954186663455

Epoch: 6| Step: 6
Training loss: 0.2717821148896664
Validation loss: 2.369416447174207

Epoch: 6| Step: 7
Training loss: 0.23274760301843062
Validation loss: 2.3739642403571715

Epoch: 6| Step: 8
Training loss: 0.413117752473311
Validation loss: 2.3888588389961174

Epoch: 6| Step: 9
Training loss: 0.3521527104427937
Validation loss: 2.3823855685507707

Epoch: 6| Step: 10
Training loss: 0.31165560845316964
Validation loss: 2.379317512325531

Epoch: 6| Step: 11
Training loss: 0.17587177806518023
Validation loss: 2.3775818245992233

Epoch: 6| Step: 12
Training loss: 0.16533211078855942
Validation loss: 2.3523406325945744

Epoch: 6| Step: 13
Training loss: 0.224962851981038
Validation loss: 2.346218223239677

Epoch: 398| Step: 0
Training loss: 0.3123704641805864
Validation loss: 2.3826706743051314

Epoch: 6| Step: 1
Training loss: 0.1821028458101103
Validation loss: 2.3497710463999137

Epoch: 6| Step: 2
Training loss: 0.2629714280489067
Validation loss: 2.349938356659703

Epoch: 6| Step: 3
Training loss: 0.27716540929163497
Validation loss: 2.3410515710405257

Epoch: 6| Step: 4
Training loss: 0.3100139796081318
Validation loss: 2.3595638969639725

Epoch: 6| Step: 5
Training loss: 0.4461019612106092
Validation loss: 2.340205267200583

Epoch: 6| Step: 6
Training loss: 0.19442872367519135
Validation loss: 2.3234458690982236

Epoch: 6| Step: 7
Training loss: 0.2606685691660002
Validation loss: 2.3183434094118582

Epoch: 6| Step: 8
Training loss: 0.3587261852972988
Validation loss: 2.304509214162457

Epoch: 6| Step: 9
Training loss: 0.27893690106453467
Validation loss: 2.325517506672779

Epoch: 6| Step: 10
Training loss: 0.2735327827108215
Validation loss: 2.291621028374856

Epoch: 6| Step: 11
Training loss: 0.32547659636959475
Validation loss: 2.3049214225786803

Epoch: 6| Step: 12
Training loss: 0.37800090818573573
Validation loss: 2.298768185856187

Epoch: 6| Step: 13
Training loss: 0.2625535206502206
Validation loss: 2.331832106893206

Epoch: 399| Step: 0
Training loss: 0.2194789848016083
Validation loss: 2.3544290868051894

Epoch: 6| Step: 1
Training loss: 0.2222557648950575
Validation loss: 2.3474130883181035

Epoch: 6| Step: 2
Training loss: 0.20804593806927837
Validation loss: 2.3696458023617835

Epoch: 6| Step: 3
Training loss: 0.28075399636968074
Validation loss: 2.3771875083755525

Epoch: 6| Step: 4
Training loss: 0.33835365013999325
Validation loss: 2.356320523961339

Epoch: 6| Step: 5
Training loss: 0.25727390615397344
Validation loss: 2.3875010142458155

Epoch: 6| Step: 6
Training loss: 0.2444558054654224
Validation loss: 2.366886697714897

Epoch: 6| Step: 7
Training loss: 0.4135176114341465
Validation loss: 2.373738017821335

Epoch: 6| Step: 8
Training loss: 0.4366134618997838
Validation loss: 2.3489333859192922

Epoch: 6| Step: 9
Training loss: 0.29197172265436544
Validation loss: 2.3683725512024703

Epoch: 6| Step: 10
Training loss: 0.2650056518545778
Validation loss: 2.331490791371351

Epoch: 6| Step: 11
Training loss: 0.4366299288100462
Validation loss: 2.3442413859561224

Epoch: 6| Step: 12
Training loss: 0.24812213627005836
Validation loss: 2.3235391247927426

Epoch: 6| Step: 13
Training loss: 0.23695731149579133
Validation loss: 2.303936711472866

Epoch: 400| Step: 0
Training loss: 0.398495763370867
Validation loss: 2.3061236390294164

Epoch: 6| Step: 1
Training loss: 0.3722147023135675
Validation loss: 2.31348523251943

Epoch: 6| Step: 2
Training loss: 0.23453894285512386
Validation loss: 2.356704713343403

Epoch: 6| Step: 3
Training loss: 0.18882286790467054
Validation loss: 2.369685947927325

Epoch: 6| Step: 4
Training loss: 0.2832593664689626
Validation loss: 2.3648354111959167

Epoch: 6| Step: 5
Training loss: 0.32311302670148817
Validation loss: 2.396066436199443

Epoch: 6| Step: 6
Training loss: 0.30873618882675125
Validation loss: 2.3971613919288535

Epoch: 6| Step: 7
Training loss: 0.12972176397925878
Validation loss: 2.382864624615278

Epoch: 6| Step: 8
Training loss: 0.3862568958370585
Validation loss: 2.3871559164424982

Epoch: 6| Step: 9
Training loss: 0.4635366768157647
Validation loss: 2.3692549133584664

Epoch: 6| Step: 10
Training loss: 0.16720412006836036
Validation loss: 2.3476658868802605

Epoch: 6| Step: 11
Training loss: 0.3531662283941637
Validation loss: 2.3545282383699324

Epoch: 6| Step: 12
Training loss: 0.3418686927548344
Validation loss: 2.3579219240839455

Epoch: 6| Step: 13
Training loss: 0.1645217156704368
Validation loss: 2.3207205252783174

Epoch: 401| Step: 0
Training loss: 0.4144439919172827
Validation loss: 2.313323847812801

Epoch: 6| Step: 1
Training loss: 0.2564857910005615
Validation loss: 2.318973727774159

Epoch: 6| Step: 2
Training loss: 0.18711759393913938
Validation loss: 2.2830188157206814

Epoch: 6| Step: 3
Training loss: 0.2179892629453143
Validation loss: 2.321827370466416

Epoch: 6| Step: 4
Training loss: 0.44998774842962447
Validation loss: 2.315164233585108

Epoch: 6| Step: 5
Training loss: 0.33731589196552814
Validation loss: 2.317784663168613

Epoch: 6| Step: 6
Training loss: 0.35663060636957183
Validation loss: 2.314545570051371

Epoch: 6| Step: 7
Training loss: 0.14945063423916807
Validation loss: 2.2976202928611325

Epoch: 6| Step: 8
Training loss: 0.21186615362800942
Validation loss: 2.3238491410760242

Epoch: 6| Step: 9
Training loss: 0.3239657322487411
Validation loss: 2.342167283404584

Epoch: 6| Step: 10
Training loss: 0.39728000281018205
Validation loss: 2.3340069315647547

Epoch: 6| Step: 11
Training loss: 0.1551528378348653
Validation loss: 2.350926801812327

Epoch: 6| Step: 12
Training loss: 0.2448488187356544
Validation loss: 2.3471035521301826

Epoch: 6| Step: 13
Training loss: 0.1476747718174135
Validation loss: 2.3403618543488087

Epoch: 402| Step: 0
Training loss: 0.4542767258667004
Validation loss: 2.3055507738769117

Epoch: 6| Step: 1
Training loss: 0.3948499317840096
Validation loss: 2.3853604668821737

Epoch: 6| Step: 2
Training loss: 0.2923478604450293
Validation loss: 2.372980051109627

Epoch: 6| Step: 3
Training loss: 0.1899881967216169
Validation loss: 2.3665673376184757

Epoch: 6| Step: 4
Training loss: 0.3430029489241695
Validation loss: 2.3500635468176094

Epoch: 6| Step: 5
Training loss: 0.2127095686213174
Validation loss: 2.373560298000558

Epoch: 6| Step: 6
Training loss: 0.27460238419339594
Validation loss: 2.3607665686627217

Epoch: 6| Step: 7
Training loss: 0.2768760552396966
Validation loss: 2.3742559246449244

Epoch: 6| Step: 8
Training loss: 0.16705035707903151
Validation loss: 2.377570122802812

Epoch: 6| Step: 9
Training loss: 0.27634718320448703
Validation loss: 2.362440932937957

Epoch: 6| Step: 10
Training loss: 0.39902570726642556
Validation loss: 2.374224025985799

Epoch: 6| Step: 11
Training loss: 0.41657876239806685
Validation loss: 2.3623082665812487

Epoch: 6| Step: 12
Training loss: 0.27280698014712895
Validation loss: 2.3356695111645713

Epoch: 6| Step: 13
Training loss: 0.23482574194609496
Validation loss: 2.3280213327362844

Epoch: 403| Step: 0
Training loss: 0.37688795326835467
Validation loss: 2.3631683260255447

Epoch: 6| Step: 1
Training loss: 0.22679486362197426
Validation loss: 2.362408929004782

Epoch: 6| Step: 2
Training loss: 0.2119529266581467
Validation loss: 2.320601949809205

Epoch: 6| Step: 3
Training loss: 0.20396637888681993
Validation loss: 2.3742842434968523

Epoch: 6| Step: 4
Training loss: 0.4044333333623321
Validation loss: 2.3521982105773946

Epoch: 6| Step: 5
Training loss: 0.4036588748752923
Validation loss: 2.362982698554626

Epoch: 6| Step: 6
Training loss: 0.19189332762673178
Validation loss: 2.3765090828399953

Epoch: 6| Step: 7
Training loss: 0.28192881945804826
Validation loss: 2.3678894345164525

Epoch: 6| Step: 8
Training loss: 0.22591218022974124
Validation loss: 2.3885149758115674

Epoch: 6| Step: 9
Training loss: 0.33777636321499066
Validation loss: 2.3739614628563737

Epoch: 6| Step: 10
Training loss: 0.22724547703703968
Validation loss: 2.3659215326780942

Epoch: 6| Step: 11
Training loss: 0.2167440470347702
Validation loss: 2.3961209446004874

Epoch: 6| Step: 12
Training loss: 0.3779653290889075
Validation loss: 2.354014385662137

Epoch: 6| Step: 13
Training loss: 0.19415387774236523
Validation loss: 2.37061525782179

Epoch: 404| Step: 0
Training loss: 0.2048651906772892
Validation loss: 2.3957092677482974

Epoch: 6| Step: 1
Training loss: 0.22294967123312365
Validation loss: 2.352113719587573

Epoch: 6| Step: 2
Training loss: 0.37998833453317254
Validation loss: 2.3957023292311006

Epoch: 6| Step: 3
Training loss: 0.2567841220122687
Validation loss: 2.378811216427079

Epoch: 6| Step: 4
Training loss: 0.34943348173336164
Validation loss: 2.3550192385101223

Epoch: 6| Step: 5
Training loss: 0.2874312121571787
Validation loss: 2.339587011246637

Epoch: 6| Step: 6
Training loss: 0.27270342519834645
Validation loss: 2.345624129828865

Epoch: 6| Step: 7
Training loss: 0.27075056345714577
Validation loss: 2.350052393074164

Epoch: 6| Step: 8
Training loss: 0.33009488441310636
Validation loss: 2.336327882102817

Epoch: 6| Step: 9
Training loss: 0.307779541768479
Validation loss: 2.350881413380623

Epoch: 6| Step: 10
Training loss: 0.2849107495482224
Validation loss: 2.342925817036519

Epoch: 6| Step: 11
Training loss: 0.27328884988798713
Validation loss: 2.3498612052409182

Epoch: 6| Step: 12
Training loss: 0.24574451795305835
Validation loss: 2.348031425763372

Epoch: 6| Step: 13
Training loss: 0.34677057283796014
Validation loss: 2.3826766781129076

Epoch: 405| Step: 0
Training loss: 0.19442390482896846
Validation loss: 2.381781305609529

Epoch: 6| Step: 1
Training loss: 0.16043011580067082
Validation loss: 2.3615831542257992

Epoch: 6| Step: 2
Training loss: 0.45375034327008
Validation loss: 2.349833395023873

Epoch: 6| Step: 3
Training loss: 0.2509190682783286
Validation loss: 2.382603398344953

Epoch: 6| Step: 4
Training loss: 0.31257871590091046
Validation loss: 2.345901777980749

Epoch: 6| Step: 5
Training loss: 0.3202683371826248
Validation loss: 2.36908439422943

Epoch: 6| Step: 6
Training loss: 0.211613771939504
Validation loss: 2.322432474486177

Epoch: 6| Step: 7
Training loss: 0.15118512925981542
Validation loss: 2.3204367402630166

Epoch: 6| Step: 8
Training loss: 0.24800693010109234
Validation loss: 2.3094420536637266

Epoch: 6| Step: 9
Training loss: 0.3907076938837224
Validation loss: 2.396777423821741

Epoch: 6| Step: 10
Training loss: 0.19621693059178302
Validation loss: 2.3660090108849365

Epoch: 6| Step: 11
Training loss: 0.35153414294001745
Validation loss: 2.3576280460711123

Epoch: 6| Step: 12
Training loss: 0.2804260901520468
Validation loss: 2.4081322593246655

Epoch: 6| Step: 13
Training loss: 0.43552258342521155
Validation loss: 2.4021507198305287

Epoch: 406| Step: 0
Training loss: 0.36961560244283975
Validation loss: 2.395557051284693

Epoch: 6| Step: 1
Training loss: 0.10724919919235192
Validation loss: 2.4064367184844313

Epoch: 6| Step: 2
Training loss: 0.1922977569310645
Validation loss: 2.399261143994503

Epoch: 6| Step: 3
Training loss: 0.3582237503952689
Validation loss: 2.3742342039743

Epoch: 6| Step: 4
Training loss: 0.22776490165562616
Validation loss: 2.4032418399228317

Epoch: 6| Step: 5
Training loss: 0.4021094667839626
Validation loss: 2.383272150557907

Epoch: 6| Step: 6
Training loss: 0.16352295143310716
Validation loss: 2.361698036265429

Epoch: 6| Step: 7
Training loss: 0.13316564032508638
Validation loss: 2.3883025574327643

Epoch: 6| Step: 8
Training loss: 0.25572949672970313
Validation loss: 2.384810098177937

Epoch: 6| Step: 9
Training loss: 0.33603416205483333
Validation loss: 2.337237021416574

Epoch: 6| Step: 10
Training loss: 0.352409053510911
Validation loss: 2.3689727635815045

Epoch: 6| Step: 11
Training loss: 0.21635330633623895
Validation loss: 2.3506395586988837

Epoch: 6| Step: 12
Training loss: 0.24321210915072908
Validation loss: 2.361476078655507

Epoch: 6| Step: 13
Training loss: 0.36045957771077364
Validation loss: 2.345709239546039

Epoch: 407| Step: 0
Training loss: 0.3349801994991238
Validation loss: 2.3498575864729174

Epoch: 6| Step: 1
Training loss: 0.3974385923060767
Validation loss: 2.331260972367095

Epoch: 6| Step: 2
Training loss: 0.2702188428797231
Validation loss: 2.3738952640723774

Epoch: 6| Step: 3
Training loss: 0.12184187686578099
Validation loss: 2.3464482082028786

Epoch: 6| Step: 4
Training loss: 0.3353416348089267
Validation loss: 2.355743357367764

Epoch: 6| Step: 5
Training loss: 0.233343596779086
Validation loss: 2.3792063187074106

Epoch: 6| Step: 6
Training loss: 0.20953467813598955
Validation loss: 2.3754985363131467

Epoch: 6| Step: 7
Training loss: 0.294148701104774
Validation loss: 2.387073253471647

Epoch: 6| Step: 8
Training loss: 0.3116571743220002
Validation loss: 2.368509920180146

Epoch: 6| Step: 9
Training loss: 0.30390625833545665
Validation loss: 2.3587254911903917

Epoch: 6| Step: 10
Training loss: 0.1994737321015407
Validation loss: 2.322124830918231

Epoch: 6| Step: 11
Training loss: 0.32313554278058365
Validation loss: 2.3246318005803506

Epoch: 6| Step: 12
Training loss: 0.28411389929773284
Validation loss: 2.304742131768453

Epoch: 6| Step: 13
Training loss: 0.4925736925498959
Validation loss: 2.321413104172449

Epoch: 408| Step: 0
Training loss: 0.1503332635552212
Validation loss: 2.272251101641423

Epoch: 6| Step: 1
Training loss: 0.33680210188223386
Validation loss: 2.338131868125193

Epoch: 6| Step: 2
Training loss: 0.4301758851690957
Validation loss: 2.329800123918038

Epoch: 6| Step: 3
Training loss: 0.24488515624267856
Validation loss: 2.3249357806980484

Epoch: 6| Step: 4
Training loss: 0.2551582280752172
Validation loss: 2.2992986973079397

Epoch: 6| Step: 5
Training loss: 0.22339957789079817
Validation loss: 2.3491894196973417

Epoch: 6| Step: 6
Training loss: 0.16697337507503046
Validation loss: 2.337312477042959

Epoch: 6| Step: 7
Training loss: 0.26383389334208546
Validation loss: 2.322413048674197

Epoch: 6| Step: 8
Training loss: 0.40181742194871595
Validation loss: 2.316816507951274

Epoch: 6| Step: 9
Training loss: 0.3973419048703008
Validation loss: 2.3040832550569865

Epoch: 6| Step: 10
Training loss: 0.22273119284271056
Validation loss: 2.308989812124691

Epoch: 6| Step: 11
Training loss: 0.25112121213464866
Validation loss: 2.3293262121133487

Epoch: 6| Step: 12
Training loss: 0.1743709094326592
Validation loss: 2.3377375027299143

Epoch: 6| Step: 13
Training loss: 0.12104376022563172
Validation loss: 2.3281478544860033

Epoch: 409| Step: 0
Training loss: 0.2686438672507915
Validation loss: 2.325380225686549

Epoch: 6| Step: 1
Training loss: 0.18681805495767478
Validation loss: 2.3509942667129606

Epoch: 6| Step: 2
Training loss: 0.3680910194853378
Validation loss: 2.3421954440531536

Epoch: 6| Step: 3
Training loss: 0.12719690685258228
Validation loss: 2.3784447856251063

Epoch: 6| Step: 4
Training loss: 0.11373984068131554
Validation loss: 2.396276626844238

Epoch: 6| Step: 5
Training loss: 0.37075269988653103
Validation loss: 2.3628365741297217

Epoch: 6| Step: 6
Training loss: 0.26939665156395476
Validation loss: 2.370641132375966

Epoch: 6| Step: 7
Training loss: 0.29611495251596276
Validation loss: 2.3520980226276804

Epoch: 6| Step: 8
Training loss: 0.21473443111098903
Validation loss: 2.3490445872180916

Epoch: 6| Step: 9
Training loss: 0.20791252174303937
Validation loss: 2.381739668630815

Epoch: 6| Step: 10
Training loss: 0.17935732900657375
Validation loss: 2.35024493103316

Epoch: 6| Step: 11
Training loss: 0.32736878447296414
Validation loss: 2.376139413365292

Epoch: 6| Step: 12
Training loss: 0.3671916393290206
Validation loss: 2.370903220884762

Epoch: 6| Step: 13
Training loss: 0.42982307376033907
Validation loss: 2.3500157389989753

Epoch: 410| Step: 0
Training loss: 0.12410071736216985
Validation loss: 2.339399322507552

Epoch: 6| Step: 1
Training loss: 0.3387107048082262
Validation loss: 2.3499888633441453

Epoch: 6| Step: 2
Training loss: 0.24489956195923746
Validation loss: 2.3632005068054722

Epoch: 6| Step: 3
Training loss: 0.24562002180602047
Validation loss: 2.329947727187742

Epoch: 6| Step: 4
Training loss: 0.45598371390489
Validation loss: 2.3131563961756885

Epoch: 6| Step: 5
Training loss: 0.22800599024771365
Validation loss: 2.3338507973568783

Epoch: 6| Step: 6
Training loss: 0.34913766461506746
Validation loss: 2.335379553337111

Epoch: 6| Step: 7
Training loss: 0.3916656175389679
Validation loss: 2.3635181242865295

Epoch: 6| Step: 8
Training loss: 0.19874218430536533
Validation loss: 2.3526613219736023

Epoch: 6| Step: 9
Training loss: 0.14299709997871154
Validation loss: 2.3709144468402674

Epoch: 6| Step: 10
Training loss: 0.21580954995225646
Validation loss: 2.3420180806624575

Epoch: 6| Step: 11
Training loss: 0.202323008913985
Validation loss: 2.3813639309441936

Epoch: 6| Step: 12
Training loss: 0.38148997993109407
Validation loss: 2.3652069509399305

Epoch: 6| Step: 13
Training loss: 0.2869286130327843
Validation loss: 2.3815404020970834

Epoch: 411| Step: 0
Training loss: 0.2428050550770227
Validation loss: 2.3443542073558956

Epoch: 6| Step: 1
Training loss: 0.1265944475895352
Validation loss: 2.3351767951647973

Epoch: 6| Step: 2
Training loss: 0.2159420205345587
Validation loss: 2.318142432421375

Epoch: 6| Step: 3
Training loss: 0.40075176048725025
Validation loss: 2.3379881993841436

Epoch: 6| Step: 4
Training loss: 0.42207049326118296
Validation loss: 2.3177508756893297

Epoch: 6| Step: 5
Training loss: 0.2842973288637015
Validation loss: 2.2789024926183177

Epoch: 6| Step: 6
Training loss: 0.22918419156834724
Validation loss: 2.295182509221852

Epoch: 6| Step: 7
Training loss: 0.2490784004740672
Validation loss: 2.2937539969399925

Epoch: 6| Step: 8
Training loss: 0.18807845491952555
Validation loss: 2.2470356682295396

Epoch: 6| Step: 9
Training loss: 0.28746791432505225
Validation loss: 2.2943116176823564

Epoch: 6| Step: 10
Training loss: 0.24736463785081886
Validation loss: 2.2537881234433965

Epoch: 6| Step: 11
Training loss: 0.33833393056743194
Validation loss: 2.317303086446547

Epoch: 6| Step: 12
Training loss: 0.4142378669624104
Validation loss: 2.294778621813148

Epoch: 6| Step: 13
Training loss: 0.1647564539339861
Validation loss: 2.325603551479466

Epoch: 412| Step: 0
Training loss: 0.3330610685749043
Validation loss: 2.3256910029621256

Epoch: 6| Step: 1
Training loss: 0.23389069269105286
Validation loss: 2.3159655915644186

Epoch: 6| Step: 2
Training loss: 0.331770895813717
Validation loss: 2.3343461396004206

Epoch: 6| Step: 3
Training loss: 0.22110545359931025
Validation loss: 2.365709826214523

Epoch: 6| Step: 4
Training loss: 0.30585886686046576
Validation loss: 2.3634336664619275

Epoch: 6| Step: 5
Training loss: 0.4236415153372782
Validation loss: 2.3809024422252976

Epoch: 6| Step: 6
Training loss: 0.1489166569650626
Validation loss: 2.345655974235389

Epoch: 6| Step: 7
Training loss: 0.15760790148753723
Validation loss: 2.3475333869565187

Epoch: 6| Step: 8
Training loss: 0.21456496617649728
Validation loss: 2.399580595424185

Epoch: 6| Step: 9
Training loss: 0.30439710227411665
Validation loss: 2.401081968850167

Epoch: 6| Step: 10
Training loss: 0.3209613879933039
Validation loss: 2.3585502455910214

Epoch: 6| Step: 11
Training loss: 0.18655511077867346
Validation loss: 2.3531583686165187

Epoch: 6| Step: 12
Training loss: 0.33320610653257726
Validation loss: 2.3492718322704844

Epoch: 6| Step: 13
Training loss: 0.2610028282209605
Validation loss: 2.3782099268082644

Epoch: 413| Step: 0
Training loss: 0.17891781199046775
Validation loss: 2.348563107524313

Epoch: 6| Step: 1
Training loss: 0.21846297711741916
Validation loss: 2.337697038806688

Epoch: 6| Step: 2
Training loss: 0.3256316250769621
Validation loss: 2.332840251755476

Epoch: 6| Step: 3
Training loss: 0.2502784370552927
Validation loss: 2.363836908878962

Epoch: 6| Step: 4
Training loss: 0.26754412469852135
Validation loss: 2.3385809378856606

Epoch: 6| Step: 5
Training loss: 0.13560149222005824
Validation loss: 2.3594713360490416

Epoch: 6| Step: 6
Training loss: 0.3987688668789159
Validation loss: 2.3469459057305526

Epoch: 6| Step: 7
Training loss: 0.2818705943919988
Validation loss: 2.385982809677385

Epoch: 6| Step: 8
Training loss: 0.38788283110718447
Validation loss: 2.3601067412104126

Epoch: 6| Step: 9
Training loss: 0.2793641176173764
Validation loss: 2.380310388860111

Epoch: 6| Step: 10
Training loss: 0.436628034720371
Validation loss: 2.3717515006800904

Epoch: 6| Step: 11
Training loss: 0.3037985279815426
Validation loss: 2.3626619589809232

Epoch: 6| Step: 12
Training loss: 0.2656722868173736
Validation loss: 2.3720045256771503

Epoch: 6| Step: 13
Training loss: 0.25557468679304984
Validation loss: 2.3552674371580906

Epoch: 414| Step: 0
Training loss: 0.22575642802400764
Validation loss: 2.3420020845223064

Epoch: 6| Step: 1
Training loss: 0.31759863924442433
Validation loss: 2.349929738221648

Epoch: 6| Step: 2
Training loss: 0.2844222171066566
Validation loss: 2.330414077726754

Epoch: 6| Step: 3
Training loss: 0.28784732311790506
Validation loss: 2.3360561859668243

Epoch: 6| Step: 4
Training loss: 0.2560236163459268
Validation loss: 2.3730599457079387

Epoch: 6| Step: 5
Training loss: 0.30133496135051047
Validation loss: 2.3590194172333163

Epoch: 6| Step: 6
Training loss: 0.22826004407641612
Validation loss: 2.3442142937297596

Epoch: 6| Step: 7
Training loss: 0.4327170986425853
Validation loss: 2.3738438458899074

Epoch: 6| Step: 8
Training loss: 0.2907825407012877
Validation loss: 2.3397855978616082

Epoch: 6| Step: 9
Training loss: 0.2908580020336255
Validation loss: 2.363860807354895

Epoch: 6| Step: 10
Training loss: 0.4495710732777332
Validation loss: 2.3759289480785717

Epoch: 6| Step: 11
Training loss: 0.32786688416239035
Validation loss: 2.382526860296343

Epoch: 6| Step: 12
Training loss: 0.26043637519009466
Validation loss: 2.3535379366437703

Epoch: 6| Step: 13
Training loss: 0.2705568757991598
Validation loss: 2.3402090569995897

Epoch: 415| Step: 0
Training loss: 0.29126552118848287
Validation loss: 2.3164931091160916

Epoch: 6| Step: 1
Training loss: 0.22390236913082284
Validation loss: 2.3147024670845777

Epoch: 6| Step: 2
Training loss: 0.40759291967324796
Validation loss: 2.316244686966592

Epoch: 6| Step: 3
Training loss: 0.31951956179630453
Validation loss: 2.230039146547312

Epoch: 6| Step: 4
Training loss: 0.2666409082687845
Validation loss: 2.251632633044776

Epoch: 6| Step: 5
Training loss: 0.34497013078494965
Validation loss: 2.278286293084219

Epoch: 6| Step: 6
Training loss: 0.23242593809791742
Validation loss: 2.272930285880502

Epoch: 6| Step: 7
Training loss: 0.22352200890670837
Validation loss: 2.32121991308683

Epoch: 6| Step: 8
Training loss: 0.358843514054103
Validation loss: 2.3487505960870028

Epoch: 6| Step: 9
Training loss: 0.35322120166296606
Validation loss: 2.373509967788598

Epoch: 6| Step: 10
Training loss: 0.37932616492972304
Validation loss: 2.4117774469624296

Epoch: 6| Step: 11
Training loss: 0.20994826877431666
Validation loss: 2.36157306989297

Epoch: 6| Step: 12
Training loss: 0.23980124901572733
Validation loss: 2.3779551757503032

Epoch: 6| Step: 13
Training loss: 0.25240622299248977
Validation loss: 2.3820677493279856

Epoch: 416| Step: 0
Training loss: 0.3437335162111953
Validation loss: 2.3330818962242463

Epoch: 6| Step: 1
Training loss: 0.3725842908243873
Validation loss: 2.3191171152786993

Epoch: 6| Step: 2
Training loss: 0.3570337533341341
Validation loss: 2.3525672798901227

Epoch: 6| Step: 3
Training loss: 0.18568369188002176
Validation loss: 2.3756638685525777

Epoch: 6| Step: 4
Training loss: 0.23727024283639742
Validation loss: 2.353140899818457

Epoch: 6| Step: 5
Training loss: 0.38683463778119026
Validation loss: 2.3313700162666953

Epoch: 6| Step: 6
Training loss: 0.24196009573226998
Validation loss: 2.377095999303848

Epoch: 6| Step: 7
Training loss: 0.23649343903596554
Validation loss: 2.3389741033813216

Epoch: 6| Step: 8
Training loss: 0.3950867471928976
Validation loss: 2.3715429290582324

Epoch: 6| Step: 9
Training loss: 0.27932080253063235
Validation loss: 2.35599281922718

Epoch: 6| Step: 10
Training loss: 0.32481571759128947
Validation loss: 2.3692271928242747

Epoch: 6| Step: 11
Training loss: 0.35423408128484685
Validation loss: 2.3618653830084253

Epoch: 6| Step: 12
Training loss: 0.2661236682229608
Validation loss: 2.337969733987783

Epoch: 6| Step: 13
Training loss: 0.16417771222280703
Validation loss: 2.3275576159777494

Epoch: 417| Step: 0
Training loss: 0.14925996151385143
Validation loss: 2.348267758610781

Epoch: 6| Step: 1
Training loss: 0.2926150411991291
Validation loss: 2.36513564299343

Epoch: 6| Step: 2
Training loss: 0.4188646714642687
Validation loss: 2.3529796985655356

Epoch: 6| Step: 3
Training loss: 0.3679813974073834
Validation loss: 2.3482278096664713

Epoch: 6| Step: 4
Training loss: 0.18345123197376326
Validation loss: 2.3556629456551867

Epoch: 6| Step: 5
Training loss: 0.2557584694637394
Validation loss: 2.3744152193270662

Epoch: 6| Step: 6
Training loss: 0.2619335232757981
Validation loss: 2.4088566845207504

Epoch: 6| Step: 7
Training loss: 0.20096362547761273
Validation loss: 2.4226475219567223

Epoch: 6| Step: 8
Training loss: 0.3034139205029024
Validation loss: 2.418184814150992

Epoch: 6| Step: 9
Training loss: 0.41273730922322444
Validation loss: 2.390183982569096

Epoch: 6| Step: 10
Training loss: 0.3101331005537617
Validation loss: 2.393569306353023

Epoch: 6| Step: 11
Training loss: 0.3626447659851509
Validation loss: 2.3930943573502432

Epoch: 6| Step: 12
Training loss: 0.23836791698062504
Validation loss: 2.3898612061020694

Epoch: 6| Step: 13
Training loss: 0.3479650604641693
Validation loss: 2.367918328612118

Epoch: 418| Step: 0
Training loss: 0.32892516754547974
Validation loss: 2.3391679521300515

Epoch: 6| Step: 1
Training loss: 0.28750246088384523
Validation loss: 2.3200290021013585

Epoch: 6| Step: 2
Training loss: 0.3514530011360304
Validation loss: 2.2983343597245387

Epoch: 6| Step: 3
Training loss: 0.36534649357113474
Validation loss: 2.3076112761428793

Epoch: 6| Step: 4
Training loss: 0.2792723718311732
Validation loss: 2.316814082976584

Epoch: 6| Step: 5
Training loss: 0.22072856047581424
Validation loss: 2.3142115925093822

Epoch: 6| Step: 6
Training loss: 0.20073753986965168
Validation loss: 2.3204175164974816

Epoch: 6| Step: 7
Training loss: 0.3647301605298808
Validation loss: 2.3106176258561417

Epoch: 6| Step: 8
Training loss: 0.2211103311797971
Validation loss: 2.326780844461608

Epoch: 6| Step: 9
Training loss: 0.4051448020391651
Validation loss: 2.32361124036804

Epoch: 6| Step: 10
Training loss: 0.3160587215390087
Validation loss: 2.3063911249633704

Epoch: 6| Step: 11
Training loss: 0.2935857506393617
Validation loss: 2.3212872634253907

Epoch: 6| Step: 12
Training loss: 0.2533217230811217
Validation loss: 2.342262457767372

Epoch: 6| Step: 13
Training loss: 0.1761031065234692
Validation loss: 2.3579884701966822

Epoch: 419| Step: 0
Training loss: 0.2352562390786211
Validation loss: 2.3947696905324913

Epoch: 6| Step: 1
Training loss: 0.19049639389362064
Validation loss: 2.3990416198025364

Epoch: 6| Step: 2
Training loss: 0.3430326302371945
Validation loss: 2.392562034808985

Epoch: 6| Step: 3
Training loss: 0.3343337612925865
Validation loss: 2.4032218128123537

Epoch: 6| Step: 4
Training loss: 0.32123588423386235
Validation loss: 2.397679015953662

Epoch: 6| Step: 5
Training loss: 0.3008227133967796
Validation loss: 2.411943678694547

Epoch: 6| Step: 6
Training loss: 0.38138206023911314
Validation loss: 2.3645390145960197

Epoch: 6| Step: 7
Training loss: 0.11702377485179147
Validation loss: 2.3640673050242182

Epoch: 6| Step: 8
Training loss: 0.16385576869931598
Validation loss: 2.3283711537484084

Epoch: 6| Step: 9
Training loss: 0.29788528001393544
Validation loss: 2.316084365657967

Epoch: 6| Step: 10
Training loss: 0.4952507666495723
Validation loss: 2.305407590669209

Epoch: 6| Step: 11
Training loss: 0.23573160155642028
Validation loss: 2.2877614670324538

Epoch: 6| Step: 12
Training loss: 0.2190089226096074
Validation loss: 2.281490644190684

Epoch: 6| Step: 13
Training loss: 0.2015683701865429
Validation loss: 2.3115282475303407

Epoch: 420| Step: 0
Training loss: 0.2679521494358336
Validation loss: 2.315452583701379

Epoch: 6| Step: 1
Training loss: 0.19290286418144037
Validation loss: 2.3589103897021744

Epoch: 6| Step: 2
Training loss: 0.24239206903504923
Validation loss: 2.3630972185570758

Epoch: 6| Step: 3
Training loss: 0.3174943933217179
Validation loss: 2.385181925045392

Epoch: 6| Step: 4
Training loss: 0.2694408569241852
Validation loss: 2.3721577757792227

Epoch: 6| Step: 5
Training loss: 0.26259355807839296
Validation loss: 2.3769090101198067

Epoch: 6| Step: 6
Training loss: 0.20638840214842483
Validation loss: 2.3859595776124007

Epoch: 6| Step: 7
Training loss: 0.21255803157301267
Validation loss: 2.3831591045576754

Epoch: 6| Step: 8
Training loss: 0.26335995909728777
Validation loss: 2.3473415516343854

Epoch: 6| Step: 9
Training loss: 0.2474826041523801
Validation loss: 2.365459025385941

Epoch: 6| Step: 10
Training loss: 0.1731771108201849
Validation loss: 2.376762333203713

Epoch: 6| Step: 11
Training loss: 0.22040354389620936
Validation loss: 2.357770962787146

Epoch: 6| Step: 12
Training loss: 0.42724996510522834
Validation loss: 2.3438791284572953

Epoch: 6| Step: 13
Training loss: 0.4867496272498586
Validation loss: 2.3753605241346882

Epoch: 421| Step: 0
Training loss: 0.3200163518929886
Validation loss: 2.3463936286229994

Epoch: 6| Step: 1
Training loss: 0.31559883519110016
Validation loss: 2.3448420101953635

Epoch: 6| Step: 2
Training loss: 0.22535256704132006
Validation loss: 2.334695950674961

Epoch: 6| Step: 3
Training loss: 0.22660506604975855
Validation loss: 2.3962092525115493

Epoch: 6| Step: 4
Training loss: 0.2408656301190399
Validation loss: 2.3852804103578737

Epoch: 6| Step: 5
Training loss: 0.35816858805284113
Validation loss: 2.369834163536698

Epoch: 6| Step: 6
Training loss: 0.26111780036452825
Validation loss: 2.373307642485988

Epoch: 6| Step: 7
Training loss: 0.23541604737535113
Validation loss: 2.3644580031755837

Epoch: 6| Step: 8
Training loss: 0.36648244329922103
Validation loss: 2.4170372572370087

Epoch: 6| Step: 9
Training loss: 0.3612033319193383
Validation loss: 2.39410304488316

Epoch: 6| Step: 10
Training loss: 0.20633907489833048
Validation loss: 2.3550024274187336

Epoch: 6| Step: 11
Training loss: 0.28676515822101606
Validation loss: 2.394847664619523

Epoch: 6| Step: 12
Training loss: 0.1352838696503513
Validation loss: 2.3814525071191426

Epoch: 6| Step: 13
Training loss: 0.16209751683262336
Validation loss: 2.3480637534026894

Epoch: 422| Step: 0
Training loss: 0.25821310765623856
Validation loss: 2.340234516796752

Epoch: 6| Step: 1
Training loss: 0.32707499348684826
Validation loss: 2.3334352043286453

Epoch: 6| Step: 2
Training loss: 0.1914916529180904
Validation loss: 2.3375737181089957

Epoch: 6| Step: 3
Training loss: 0.1417214905201525
Validation loss: 2.316826026906783

Epoch: 6| Step: 4
Training loss: 0.2449411542809184
Validation loss: 2.2772214906627304

Epoch: 6| Step: 5
Training loss: 0.16811817198753654
Validation loss: 2.2928536008445337

Epoch: 6| Step: 6
Training loss: 0.22208892757665266
Validation loss: 2.342646564804919

Epoch: 6| Step: 7
Training loss: 0.22067350847147085
Validation loss: 2.3222365823793587

Epoch: 6| Step: 8
Training loss: 0.3036487429802773
Validation loss: 2.3474899871118837

Epoch: 6| Step: 9
Training loss: 0.29585732907821033
Validation loss: 2.350067058907684

Epoch: 6| Step: 10
Training loss: 0.2666221303306987
Validation loss: 2.3603603063460596

Epoch: 6| Step: 11
Training loss: 0.4135307820646904
Validation loss: 2.357174093531976

Epoch: 6| Step: 12
Training loss: 0.38361581867078604
Validation loss: 2.372456401252022

Epoch: 6| Step: 13
Training loss: 0.2290322015846399
Validation loss: 2.36481313784518

Epoch: 423| Step: 0
Training loss: 0.24563453608485358
Validation loss: 2.3786962456099245

Epoch: 6| Step: 1
Training loss: 0.3697403169180376
Validation loss: 2.3617212247601316

Epoch: 6| Step: 2
Training loss: 0.3290089326895204
Validation loss: 2.3853271131895886

Epoch: 6| Step: 3
Training loss: 0.27148978138761654
Validation loss: 2.3783119022677677

Epoch: 6| Step: 4
Training loss: 0.36810561305551437
Validation loss: 2.3799644810773444

Epoch: 6| Step: 5
Training loss: 0.22101604592427165
Validation loss: 2.390461072047306

Epoch: 6| Step: 6
Training loss: 0.2575645699606465
Validation loss: 2.4051472603875723

Epoch: 6| Step: 7
Training loss: 0.4358742001424703
Validation loss: 2.4150576031423263

Epoch: 6| Step: 8
Training loss: 0.20580737924909814
Validation loss: 2.414064709940182

Epoch: 6| Step: 9
Training loss: 0.1828349645782953
Validation loss: 2.3785670171420765

Epoch: 6| Step: 10
Training loss: 0.3369908010468196
Validation loss: 2.3542693828360903

Epoch: 6| Step: 11
Training loss: 0.25251007621791177
Validation loss: 2.3640071441903934

Epoch: 6| Step: 12
Training loss: 0.37394990521906796
Validation loss: 2.3291113543010624

Epoch: 6| Step: 13
Training loss: 0.4128287666921926
Validation loss: 2.32331945818436

Epoch: 424| Step: 0
Training loss: 0.2759179551837513
Validation loss: 2.310153339231052

Epoch: 6| Step: 1
Training loss: 0.34592928196933176
Validation loss: 2.320086105779901

Epoch: 6| Step: 2
Training loss: 0.23091601759654048
Validation loss: 2.3058732347603326

Epoch: 6| Step: 3
Training loss: 0.33201735972352936
Validation loss: 2.3561104682758955

Epoch: 6| Step: 4
Training loss: 0.24427685560734455
Validation loss: 2.335881562509279

Epoch: 6| Step: 5
Training loss: 0.2784276119664208
Validation loss: 2.384817253820352

Epoch: 6| Step: 6
Training loss: 0.15056763796315523
Validation loss: 2.364398063444023

Epoch: 6| Step: 7
Training loss: 0.48465500706087705
Validation loss: 2.3661440906556748

Epoch: 6| Step: 8
Training loss: 0.24641216205671862
Validation loss: 2.344675083057135

Epoch: 6| Step: 9
Training loss: 0.25263781995205226
Validation loss: 2.3769614168062714

Epoch: 6| Step: 10
Training loss: 0.21861436589869224
Validation loss: 2.398920548006861

Epoch: 6| Step: 11
Training loss: 0.2695075591359533
Validation loss: 2.3971998147663416

Epoch: 6| Step: 12
Training loss: 0.3366326967812107
Validation loss: 2.3984000365504046

Epoch: 6| Step: 13
Training loss: 0.33841853714756115
Validation loss: 2.4278252694768305

Epoch: 425| Step: 0
Training loss: 0.15477844127445647
Validation loss: 2.3960246515772794

Epoch: 6| Step: 1
Training loss: 0.34690390844425095
Validation loss: 2.416290857764213

Epoch: 6| Step: 2
Training loss: 0.25760118899004364
Validation loss: 2.3849495054474454

Epoch: 6| Step: 3
Training loss: 0.2478862753173005
Validation loss: 2.3857433061243385

Epoch: 6| Step: 4
Training loss: 0.13892553528144908
Validation loss: 2.350047227720496

Epoch: 6| Step: 5
Training loss: 0.17125005245207936
Validation loss: 2.35630870189013

Epoch: 6| Step: 6
Training loss: 0.4041121793507383
Validation loss: 2.351108942133341

Epoch: 6| Step: 7
Training loss: 0.4073161660100098
Validation loss: 2.3438692660049343

Epoch: 6| Step: 8
Training loss: 0.3356823062811002
Validation loss: 2.3680264347444524

Epoch: 6| Step: 9
Training loss: 0.2695705689209428
Validation loss: 2.4038985052726556

Epoch: 6| Step: 10
Training loss: 0.1897618344659821
Validation loss: 2.430337302570172

Epoch: 6| Step: 11
Training loss: 0.2234104666995631
Validation loss: 2.412448950589821

Epoch: 6| Step: 12
Training loss: 0.3512216080869113
Validation loss: 2.4111530545975297

Epoch: 6| Step: 13
Training loss: 0.20246498460090037
Validation loss: 2.4206386748905966

Epoch: 426| Step: 0
Training loss: 0.20356324493569392
Validation loss: 2.427185253226974

Epoch: 6| Step: 1
Training loss: 0.2706527872334234
Validation loss: 2.408866523017

Epoch: 6| Step: 2
Training loss: 0.2785210671769263
Validation loss: 2.379046602364065

Epoch: 6| Step: 3
Training loss: 0.30975609388276115
Validation loss: 2.347257996578767

Epoch: 6| Step: 4
Training loss: 0.3237335181919736
Validation loss: 2.332539079519871

Epoch: 6| Step: 5
Training loss: 0.31125460657671067
Validation loss: 2.3544234432436935

Epoch: 6| Step: 6
Training loss: 0.1838228439921335
Validation loss: 2.3788019048267297

Epoch: 6| Step: 7
Training loss: 0.43742908175473294
Validation loss: 2.3423493617149953

Epoch: 6| Step: 8
Training loss: 0.2014915833176651
Validation loss: 2.354043957554727

Epoch: 6| Step: 9
Training loss: 0.23884590659240376
Validation loss: 2.356583801546005

Epoch: 6| Step: 10
Training loss: 0.28456628203565065
Validation loss: 2.3848412054208645

Epoch: 6| Step: 11
Training loss: 0.13707496694955423
Validation loss: 2.3438366923825935

Epoch: 6| Step: 12
Training loss: 0.08495554687674474
Validation loss: 2.347268644268925

Epoch: 6| Step: 13
Training loss: 0.1801817461385866
Validation loss: 2.3450961430338344

Epoch: 427| Step: 0
Training loss: 0.31544814631539786
Validation loss: 2.323759648255265

Epoch: 6| Step: 1
Training loss: 0.10089552558717038
Validation loss: 2.332228311761284

Epoch: 6| Step: 2
Training loss: 0.1712410190674158
Validation loss: 2.3456301257232504

Epoch: 6| Step: 3
Training loss: 0.18594997187868353
Validation loss: 2.3345887471770643

Epoch: 6| Step: 4
Training loss: 0.28140479702232873
Validation loss: 2.3531770520086486

Epoch: 6| Step: 5
Training loss: 0.29056759082685807
Validation loss: 2.3774642260698426

Epoch: 6| Step: 6
Training loss: 0.3503305253930508
Validation loss: 2.35387166017318

Epoch: 6| Step: 7
Training loss: 0.11353358167405952
Validation loss: 2.392531452272031

Epoch: 6| Step: 8
Training loss: 0.207840516417544
Validation loss: 2.370895677774033

Epoch: 6| Step: 9
Training loss: 0.14608693565959135
Validation loss: 2.389226292614608

Epoch: 6| Step: 10
Training loss: 0.3225395425684598
Validation loss: 2.370901264825239

Epoch: 6| Step: 11
Training loss: 0.28378297047071993
Validation loss: 2.362559458308906

Epoch: 6| Step: 12
Training loss: 0.24071026783726496
Validation loss: 2.369912304129554

Epoch: 6| Step: 13
Training loss: 0.32167424357752156
Validation loss: 2.3800173722551987

Epoch: 428| Step: 0
Training loss: 0.3358949479055909
Validation loss: 2.3537607070747026

Epoch: 6| Step: 1
Training loss: 0.23440851130918564
Validation loss: 2.341092076633947

Epoch: 6| Step: 2
Training loss: 0.24210527008505917
Validation loss: 2.3237942314906186

Epoch: 6| Step: 3
Training loss: 0.20776015748257814
Validation loss: 2.349902573570831

Epoch: 6| Step: 4
Training loss: 0.23595408324515718
Validation loss: 2.339963939288273

Epoch: 6| Step: 5
Training loss: 0.40636310470100956
Validation loss: 2.3387072873801698

Epoch: 6| Step: 6
Training loss: 0.21098647608682308
Validation loss: 2.356196741780813

Epoch: 6| Step: 7
Training loss: 0.29721940291534255
Validation loss: 2.3125771629100007

Epoch: 6| Step: 8
Training loss: 0.3575065179043927
Validation loss: 2.3812136031195745

Epoch: 6| Step: 9
Training loss: 0.22769294905078086
Validation loss: 2.351312336417961

Epoch: 6| Step: 10
Training loss: 0.15705433884542924
Validation loss: 2.390269700859935

Epoch: 6| Step: 11
Training loss: 0.25955254556373575
Validation loss: 2.3898322533412535

Epoch: 6| Step: 12
Training loss: 0.20070724162345394
Validation loss: 2.341615882486049

Epoch: 6| Step: 13
Training loss: 0.2023843319527893
Validation loss: 2.3449446217102876

Epoch: 429| Step: 0
Training loss: 0.2668925224197893
Validation loss: 2.320085885337078

Epoch: 6| Step: 1
Training loss: 0.2537280704624852
Validation loss: 2.32599281500849

Epoch: 6| Step: 2
Training loss: 0.17402090676604992
Validation loss: 2.308942229188393

Epoch: 6| Step: 3
Training loss: 0.3295272880811634
Validation loss: 2.331083162480603

Epoch: 6| Step: 4
Training loss: 0.21437119619592657
Validation loss: 2.350626849738476

Epoch: 6| Step: 5
Training loss: 0.1965121429722075
Validation loss: 2.3515928325959607

Epoch: 6| Step: 6
Training loss: 0.1297274140327439
Validation loss: 2.363696024860503

Epoch: 6| Step: 7
Training loss: 0.2015057358173869
Validation loss: 2.346341911237385

Epoch: 6| Step: 8
Training loss: 0.25437051436384733
Validation loss: 2.369083933786062

Epoch: 6| Step: 9
Training loss: 0.300384929191253
Validation loss: 2.346994842719861

Epoch: 6| Step: 10
Training loss: 0.49467433408277
Validation loss: 2.377958203014398

Epoch: 6| Step: 11
Training loss: 0.15786519870325577
Validation loss: 2.38516665933166

Epoch: 6| Step: 12
Training loss: 0.14961443660928703
Validation loss: 2.386047622311176

Epoch: 6| Step: 13
Training loss: 0.392659971141374
Validation loss: 2.400654330962768

Epoch: 430| Step: 0
Training loss: 0.20360661228153673
Validation loss: 2.3665926563023274

Epoch: 6| Step: 1
Training loss: 0.12404549770453116
Validation loss: 2.382427842030837

Epoch: 6| Step: 2
Training loss: 0.193220310102467
Validation loss: 2.379405859633768

Epoch: 6| Step: 3
Training loss: 0.14107300998804181
Validation loss: 2.35478657444779

Epoch: 6| Step: 4
Training loss: 0.190579370212326
Validation loss: 2.370979963319527

Epoch: 6| Step: 5
Training loss: 0.17554890854272664
Validation loss: 2.3813555801856143

Epoch: 6| Step: 6
Training loss: 0.206953249938858
Validation loss: 2.3125504929147063

Epoch: 6| Step: 7
Training loss: 0.30877347131078453
Validation loss: 2.3637991519180046

Epoch: 6| Step: 8
Training loss: 0.40284582865812524
Validation loss: 2.318734259375497

Epoch: 6| Step: 9
Training loss: 0.14545384628784191
Validation loss: 2.314484335489579

Epoch: 6| Step: 10
Training loss: 0.28130117586570186
Validation loss: 2.300758717568989

Epoch: 6| Step: 11
Training loss: 0.30806181729922705
Validation loss: 2.326832522308468

Epoch: 6| Step: 12
Training loss: 0.19964073405128852
Validation loss: 2.310496115276691

Epoch: 6| Step: 13
Training loss: 0.4588489738571766
Validation loss: 2.324692537917452

Epoch: 431| Step: 0
Training loss: 0.2758182019989129
Validation loss: 2.3313164879418795

Epoch: 6| Step: 1
Training loss: 0.19604905481601967
Validation loss: 2.318802466602023

Epoch: 6| Step: 2
Training loss: 0.17299205113937777
Validation loss: 2.3327242254729814

Epoch: 6| Step: 3
Training loss: 0.4182370118212575
Validation loss: 2.3276572954164907

Epoch: 6| Step: 4
Training loss: 0.14878823854714512
Validation loss: 2.35619066342724

Epoch: 6| Step: 5
Training loss: 0.30261601010693406
Validation loss: 2.3524112710211633

Epoch: 6| Step: 6
Training loss: 0.1644932903976626
Validation loss: 2.3988360477704767

Epoch: 6| Step: 7
Training loss: 0.19880537079000238
Validation loss: 2.3679829319708383

Epoch: 6| Step: 8
Training loss: 0.2540548623263694
Validation loss: 2.4129768976047585

Epoch: 6| Step: 9
Training loss: 0.1973170034144165
Validation loss: 2.4194742392743005

Epoch: 6| Step: 10
Training loss: 0.34249417702047785
Validation loss: 2.388510679308176

Epoch: 6| Step: 11
Training loss: 0.1224096692834545
Validation loss: 2.4132351414451185

Epoch: 6| Step: 12
Training loss: 0.16269803313949183
Validation loss: 2.406331791131567

Epoch: 6| Step: 13
Training loss: 0.18223970331073774
Validation loss: 2.366084359412314

Epoch: 432| Step: 0
Training loss: 0.23196431809757284
Validation loss: 2.3582984931164046

Epoch: 6| Step: 1
Training loss: 0.2780835667297585
Validation loss: 2.3896271474749713

Epoch: 6| Step: 2
Training loss: 0.26166700449443886
Validation loss: 2.350234136479088

Epoch: 6| Step: 3
Training loss: 0.3635118634414438
Validation loss: 2.3712526170779493

Epoch: 6| Step: 4
Training loss: 0.2551600968584253
Validation loss: 2.336697314277042

Epoch: 6| Step: 5
Training loss: 0.1557762354480825
Validation loss: 2.36845600324208

Epoch: 6| Step: 6
Training loss: 0.22907143026380858
Validation loss: 2.3364256248920254

Epoch: 6| Step: 7
Training loss: 0.28477315120929086
Validation loss: 2.342870705670235

Epoch: 6| Step: 8
Training loss: 0.25921171690428946
Validation loss: 2.333507261810914

Epoch: 6| Step: 9
Training loss: 0.23910866584565482
Validation loss: 2.3706455491303067

Epoch: 6| Step: 10
Training loss: 0.12113583125830964
Validation loss: 2.352530924356117

Epoch: 6| Step: 11
Training loss: 0.20116486583461757
Validation loss: 2.3493580502751685

Epoch: 6| Step: 12
Training loss: 0.18666358994888857
Validation loss: 2.366671742337492

Epoch: 6| Step: 13
Training loss: 0.37637316110618463
Validation loss: 2.3657309283593806

Epoch: 433| Step: 0
Training loss: 0.12852603296264753
Validation loss: 2.3416269357313584

Epoch: 6| Step: 1
Training loss: 0.21221630674788938
Validation loss: 2.3773414585196746

Epoch: 6| Step: 2
Training loss: 0.2894206019777564
Validation loss: 2.366940050902823

Epoch: 6| Step: 3
Training loss: 0.3488290058393987
Validation loss: 2.3357986039599727

Epoch: 6| Step: 4
Training loss: 0.27113594364435173
Validation loss: 2.325346214520929

Epoch: 6| Step: 5
Training loss: 0.256709600785919
Validation loss: 2.338148200213318

Epoch: 6| Step: 6
Training loss: 0.13448871275672936
Validation loss: 2.343349934003364

Epoch: 6| Step: 7
Training loss: 0.1389746785118473
Validation loss: 2.3729142408914874

Epoch: 6| Step: 8
Training loss: 0.23463812204481424
Validation loss: 2.3612104965210685

Epoch: 6| Step: 9
Training loss: 0.22876186634511866
Validation loss: 2.3805443383028746

Epoch: 6| Step: 10
Training loss: 0.20715129718680517
Validation loss: 2.3913463491077844

Epoch: 6| Step: 11
Training loss: 0.2713858885476124
Validation loss: 2.391944010123124

Epoch: 6| Step: 12
Training loss: 0.3583036292132658
Validation loss: 2.3690001662320195

Epoch: 6| Step: 13
Training loss: 0.23957395880782506
Validation loss: 2.3622795263406497

Epoch: 434| Step: 0
Training loss: 0.36045695265309785
Validation loss: 2.3419384655822877

Epoch: 6| Step: 1
Training loss: 0.09969986750678572
Validation loss: 2.316723739103681

Epoch: 6| Step: 2
Training loss: 0.17933841672864975
Validation loss: 2.3087324949549934

Epoch: 6| Step: 3
Training loss: 0.27519163423006315
Validation loss: 2.3417603248880896

Epoch: 6| Step: 4
Training loss: 0.23348125281368767
Validation loss: 2.3369876483222223

Epoch: 6| Step: 5
Training loss: 0.1521180388183031
Validation loss: 2.336471665005639

Epoch: 6| Step: 6
Training loss: 0.4205972075951918
Validation loss: 2.351606994977623

Epoch: 6| Step: 7
Training loss: 0.2315563708046322
Validation loss: 2.354968966806544

Epoch: 6| Step: 8
Training loss: 0.1603019447086439
Validation loss: 2.3818093041121267

Epoch: 6| Step: 9
Training loss: 0.3107072308225657
Validation loss: 2.4059017820651234

Epoch: 6| Step: 10
Training loss: 0.17858116983342406
Validation loss: 2.3987380650420325

Epoch: 6| Step: 11
Training loss: 0.263650907459864
Validation loss: 2.3797755541418857

Epoch: 6| Step: 12
Training loss: 0.37643804590856045
Validation loss: 2.400425320114596

Epoch: 6| Step: 13
Training loss: 0.10515284026854278
Validation loss: 2.392718016649379

Epoch: 435| Step: 0
Training loss: 0.3170665867544169
Validation loss: 2.370283547222433

Epoch: 6| Step: 1
Training loss: 0.22149699408965098
Validation loss: 2.4040342745502947

Epoch: 6| Step: 2
Training loss: 0.3217841279352284
Validation loss: 2.3706616418134723

Epoch: 6| Step: 3
Training loss: 0.28296406620389436
Validation loss: 2.3516006823662656

Epoch: 6| Step: 4
Training loss: 0.171520354943234
Validation loss: 2.3729053769264454

Epoch: 6| Step: 5
Training loss: 0.2527792052140181
Validation loss: 2.3584611667674387

Epoch: 6| Step: 6
Training loss: 0.3782557379696454
Validation loss: 2.3600030981298654

Epoch: 6| Step: 7
Training loss: 0.23359419781185847
Validation loss: 2.33511860694788

Epoch: 6| Step: 8
Training loss: 0.32667662346678
Validation loss: 2.3593627412158775

Epoch: 6| Step: 9
Training loss: 0.2557068872684911
Validation loss: 2.3583498893280437

Epoch: 6| Step: 10
Training loss: 0.3526462804004552
Validation loss: 2.384751392934889

Epoch: 6| Step: 11
Training loss: 0.2824033295806599
Validation loss: 2.3564160296731416

Epoch: 6| Step: 12
Training loss: 0.3261531436132981
Validation loss: 2.3324291488715367

Epoch: 6| Step: 13
Training loss: 0.1589912164701664
Validation loss: 2.3413321391166213

Epoch: 436| Step: 0
Training loss: 0.2974847504770548
Validation loss: 2.3421112938456266

Epoch: 6| Step: 1
Training loss: 0.22553782755111185
Validation loss: 2.3492321868582815

Epoch: 6| Step: 2
Training loss: 0.29262838301236876
Validation loss: 2.3425906157016994

Epoch: 6| Step: 3
Training loss: 0.32039112196137054
Validation loss: 2.338303599607066

Epoch: 6| Step: 4
Training loss: 0.23202181292779187
Validation loss: 2.3435227544403396

Epoch: 6| Step: 5
Training loss: 0.2023058752749485
Validation loss: 2.358098320937317

Epoch: 6| Step: 6
Training loss: 0.13318891337587715
Validation loss: 2.3301721406459834

Epoch: 6| Step: 7
Training loss: 0.19768038666404059
Validation loss: 2.3350443814373287

Epoch: 6| Step: 8
Training loss: 0.2760354467207033
Validation loss: 2.3551001723892795

Epoch: 6| Step: 9
Training loss: 0.3048099125198319
Validation loss: 2.363721830365118

Epoch: 6| Step: 10
Training loss: 0.2574553616961328
Validation loss: 2.3783417476536797

Epoch: 6| Step: 11
Training loss: 0.32961396305700286
Validation loss: 2.408785822108606

Epoch: 6| Step: 12
Training loss: 0.39344956577212586
Validation loss: 2.4027101904379644

Epoch: 6| Step: 13
Training loss: 0.2609471148015828
Validation loss: 2.4007541885768373

Epoch: 437| Step: 0
Training loss: 0.20820082185484087
Validation loss: 2.422817537184445

Epoch: 6| Step: 1
Training loss: 0.24939727398104128
Validation loss: 2.376403642620219

Epoch: 6| Step: 2
Training loss: 0.2768591825044403
Validation loss: 2.4036201464390454

Epoch: 6| Step: 3
Training loss: 0.18259983694300624
Validation loss: 2.334925983307466

Epoch: 6| Step: 4
Training loss: 0.28463912477488995
Validation loss: 2.335828275311967

Epoch: 6| Step: 5
Training loss: 0.19690334933393078
Validation loss: 2.3495633500949316

Epoch: 6| Step: 6
Training loss: 0.21054154780341933
Validation loss: 2.3651518785778776

Epoch: 6| Step: 7
Training loss: 0.289595421989293
Validation loss: 2.3289961857621715

Epoch: 6| Step: 8
Training loss: 0.23298371950663263
Validation loss: 2.339590602617974

Epoch: 6| Step: 9
Training loss: 0.1555864370301177
Validation loss: 2.308627053525108

Epoch: 6| Step: 10
Training loss: 0.41501439638330445
Validation loss: 2.342431687702148

Epoch: 6| Step: 11
Training loss: 0.3089096046385233
Validation loss: 2.3352172552774517

Epoch: 6| Step: 12
Training loss: 0.2618335642842958
Validation loss: 2.2930991124954287

Epoch: 6| Step: 13
Training loss: 0.15826111778456828
Validation loss: 2.3305719131562754

Epoch: 438| Step: 0
Training loss: 0.24191384082490217
Validation loss: 2.3109216600120797

Epoch: 6| Step: 1
Training loss: 0.2434356429111225
Validation loss: 2.3382509930983497

Epoch: 6| Step: 2
Training loss: 0.310104534920775
Validation loss: 2.3674526877625017

Epoch: 6| Step: 3
Training loss: 0.27626523674937137
Validation loss: 2.338271361787778

Epoch: 6| Step: 4
Training loss: 0.2972311343261191
Validation loss: 2.351433004135325

Epoch: 6| Step: 5
Training loss: 0.12709508441574377
Validation loss: 2.3393575700889273

Epoch: 6| Step: 6
Training loss: 0.1587264506452335
Validation loss: 2.35164476836109

Epoch: 6| Step: 7
Training loss: 0.24652583926667002
Validation loss: 2.343229642139161

Epoch: 6| Step: 8
Training loss: 0.16444433147995557
Validation loss: 2.3581097192853178

Epoch: 6| Step: 9
Training loss: 0.10600117234209282
Validation loss: 2.3151615804314383

Epoch: 6| Step: 10
Training loss: 0.23484202584187677
Validation loss: 2.3923246939305027

Epoch: 6| Step: 11
Training loss: 0.31708446858804784
Validation loss: 2.344912626063992

Epoch: 6| Step: 12
Training loss: 0.1798196700419809
Validation loss: 2.3419122985377605

Epoch: 6| Step: 13
Training loss: 0.23092505977712852
Validation loss: 2.3460629935030703

Epoch: 439| Step: 0
Training loss: 0.1447895294027139
Validation loss: 2.372302506918974

Epoch: 6| Step: 1
Training loss: 0.2486153643674635
Validation loss: 2.4004832816031856

Epoch: 6| Step: 2
Training loss: 0.2855586648325746
Validation loss: 2.3762286569688804

Epoch: 6| Step: 3
Training loss: 0.10540991042544766
Validation loss: 2.387448303087312

Epoch: 6| Step: 4
Training loss: 0.08060063299782134
Validation loss: 2.3752837926352

Epoch: 6| Step: 5
Training loss: 0.15483119051411712
Validation loss: 2.402329329674066

Epoch: 6| Step: 6
Training loss: 0.19862865492409051
Validation loss: 2.4082451518059917

Epoch: 6| Step: 7
Training loss: 0.32869804388769247
Validation loss: 2.395171111307608

Epoch: 6| Step: 8
Training loss: 0.13662552379872464
Validation loss: 2.3875560854201154

Epoch: 6| Step: 9
Training loss: 0.27988356212827037
Validation loss: 2.417760107997197

Epoch: 6| Step: 10
Training loss: 0.300891496840002
Validation loss: 2.4034970818901797

Epoch: 6| Step: 11
Training loss: 0.2213317813025942
Validation loss: 2.367758351062009

Epoch: 6| Step: 12
Training loss: 0.22851366873661846
Validation loss: 2.3914170282586276

Epoch: 6| Step: 13
Training loss: 0.09928527163968501
Validation loss: 2.371828298354712

Epoch: 440| Step: 0
Training loss: 0.14308523112837893
Validation loss: 2.3509238095309954

Epoch: 6| Step: 1
Training loss: 0.3599873591561411
Validation loss: 2.3221935818979813

Epoch: 6| Step: 2
Training loss: 0.2963767136420074
Validation loss: 2.3243643424419704

Epoch: 6| Step: 3
Training loss: 0.12197568659076075
Validation loss: 2.3241267812651163

Epoch: 6| Step: 4
Training loss: 0.18693039722079113
Validation loss: 2.3215341101591584

Epoch: 6| Step: 5
Training loss: 0.20748274533217606
Validation loss: 2.3211799859734663

Epoch: 6| Step: 6
Training loss: 0.15218215098762344
Validation loss: 2.283876532868866

Epoch: 6| Step: 7
Training loss: 0.2508759946494539
Validation loss: 2.317286891765413

Epoch: 6| Step: 8
Training loss: 0.2843764629955177
Validation loss: 2.3206886441551324

Epoch: 6| Step: 9
Training loss: 0.17633321779237698
Validation loss: 2.3233545163746774

Epoch: 6| Step: 10
Training loss: 0.24611279247420975
Validation loss: 2.365682596768098

Epoch: 6| Step: 11
Training loss: 0.18088577687492793
Validation loss: 2.3534582932466184

Epoch: 6| Step: 12
Training loss: 0.21359498629878465
Validation loss: 2.348915970830517

Epoch: 6| Step: 13
Training loss: 0.25597355748122286
Validation loss: 2.354687216557614

Epoch: 441| Step: 0
Training loss: 0.17643978424397594
Validation loss: 2.3489964863626076

Epoch: 6| Step: 1
Training loss: 0.19239342364950335
Validation loss: 2.3562369630801703

Epoch: 6| Step: 2
Training loss: 0.24894955604967203
Validation loss: 2.3600161677554614

Epoch: 6| Step: 3
Training loss: 0.24037306744090736
Validation loss: 2.3478943086730792

Epoch: 6| Step: 4
Training loss: 0.24234522021577534
Validation loss: 2.343811826266469

Epoch: 6| Step: 5
Training loss: 0.21065445736420976
Validation loss: 2.3350025423642182

Epoch: 6| Step: 6
Training loss: 0.15604677096686462
Validation loss: 2.3279058002647277

Epoch: 6| Step: 7
Training loss: 0.17640891864606287
Validation loss: 2.3508299929276775

Epoch: 6| Step: 8
Training loss: 0.2745368112816066
Validation loss: 2.3724412384358224

Epoch: 6| Step: 9
Training loss: 0.14476882893968965
Validation loss: 2.3793188483865984

Epoch: 6| Step: 10
Training loss: 0.3535120421170086
Validation loss: 2.3579587836019074

Epoch: 6| Step: 11
Training loss: 0.1808736564814371
Validation loss: 2.347838613469846

Epoch: 6| Step: 12
Training loss: 0.1466174919546831
Validation loss: 2.3576513072170027

Epoch: 6| Step: 13
Training loss: 0.2493885953323603
Validation loss: 2.3813319498669783

Epoch: 442| Step: 0
Training loss: 0.20007335390526548
Validation loss: 2.369660825113702

Epoch: 6| Step: 1
Training loss: 0.21489942869549356
Validation loss: 2.342537348698783

Epoch: 6| Step: 2
Training loss: 0.2861444256089093
Validation loss: 2.3680066930633292

Epoch: 6| Step: 3
Training loss: 0.23840782055804374
Validation loss: 2.3890536722767943

Epoch: 6| Step: 4
Training loss: 0.18642432890176933
Validation loss: 2.392516224344807

Epoch: 6| Step: 5
Training loss: 0.12054644232899121
Validation loss: 2.3590144752782325

Epoch: 6| Step: 6
Training loss: 0.15063530351490206
Validation loss: 2.334810210002637

Epoch: 6| Step: 7
Training loss: 0.1979654758065189
Validation loss: 2.328230710164759

Epoch: 6| Step: 8
Training loss: 0.1395601713893399
Validation loss: 2.332152353617024

Epoch: 6| Step: 9
Training loss: 0.2809391423093595
Validation loss: 2.3312096508448867

Epoch: 6| Step: 10
Training loss: 0.27628522001118855
Validation loss: 2.321456909254639

Epoch: 6| Step: 11
Training loss: 0.240407137274236
Validation loss: 2.344270858587671

Epoch: 6| Step: 12
Training loss: 0.3053422153579958
Validation loss: 2.3373028484777185

Epoch: 6| Step: 13
Training loss: 0.2695084714248121
Validation loss: 2.3307686643862295

Epoch: 443| Step: 0
Training loss: 0.15729155293096342
Validation loss: 2.4020099276232596

Epoch: 6| Step: 1
Training loss: 0.2881820906183332
Validation loss: 2.450128476003645

Epoch: 6| Step: 2
Training loss: 0.30184446405487636
Validation loss: 2.4820497579438836

Epoch: 6| Step: 3
Training loss: 0.4163680039353172
Validation loss: 2.488318924172663

Epoch: 6| Step: 4
Training loss: 0.37011064508538816
Validation loss: 2.489543157778434

Epoch: 6| Step: 5
Training loss: 0.2104214076807956
Validation loss: 2.4165956644470175

Epoch: 6| Step: 6
Training loss: 0.23864077975781947
Validation loss: 2.361380866620241

Epoch: 6| Step: 7
Training loss: 0.25462930868751515
Validation loss: 2.3195919010215715

Epoch: 6| Step: 8
Training loss: 0.3272340349407731
Validation loss: 2.279373607852986

Epoch: 6| Step: 9
Training loss: 0.30538090030452386
Validation loss: 2.2881892377142146

Epoch: 6| Step: 10
Training loss: 0.22399658700724934
Validation loss: 2.3311375410370188

Epoch: 6| Step: 11
Training loss: 0.241488031157871
Validation loss: 2.3553763818919085

Epoch: 6| Step: 12
Training loss: 0.1695847180866094
Validation loss: 2.423672098056766

Epoch: 6| Step: 13
Training loss: 0.4264309676831685
Validation loss: 2.4530488814873515

Epoch: 444| Step: 0
Training loss: 0.3731434083036664
Validation loss: 2.4673974717121476

Epoch: 6| Step: 1
Training loss: 0.16775420259606535
Validation loss: 2.467444729146128

Epoch: 6| Step: 2
Training loss: 0.28672930154952225
Validation loss: 2.4405658016593854

Epoch: 6| Step: 3
Training loss: 0.2781812889487343
Validation loss: 2.4169377605251188

Epoch: 6| Step: 4
Training loss: 0.18676822637308355
Validation loss: 2.3924570148981945

Epoch: 6| Step: 5
Training loss: 0.3738186626771425
Validation loss: 2.3588345365057286

Epoch: 6| Step: 6
Training loss: 0.17768442059752496
Validation loss: 2.3475503388985537

Epoch: 6| Step: 7
Training loss: 0.2686807648612555
Validation loss: 2.2838772939205416

Epoch: 6| Step: 8
Training loss: 0.2993446573239116
Validation loss: 2.283544224271872

Epoch: 6| Step: 9
Training loss: 0.1570008001648807
Validation loss: 2.247382860311795

Epoch: 6| Step: 10
Training loss: 0.3319350832630484
Validation loss: 2.2728189654459867

Epoch: 6| Step: 11
Training loss: 0.3293254102332672
Validation loss: 2.261184740706562

Epoch: 6| Step: 12
Training loss: 0.3405554652328451
Validation loss: 2.2683416360144375

Epoch: 6| Step: 13
Training loss: 0.445888364446671
Validation loss: 2.273733406415175

Epoch: 445| Step: 0
Training loss: 0.18221365871719178
Validation loss: 2.306879945218062

Epoch: 6| Step: 1
Training loss: 0.2534305223946116
Validation loss: 2.336073967436027

Epoch: 6| Step: 2
Training loss: 0.2993305445656576
Validation loss: 2.3592503039407546

Epoch: 6| Step: 3
Training loss: 0.26305213433523517
Validation loss: 2.372088591337175

Epoch: 6| Step: 4
Training loss: 0.20663417669089187
Validation loss: 2.371697905507993

Epoch: 6| Step: 5
Training loss: 0.21777801337801775
Validation loss: 2.4338232454403683

Epoch: 6| Step: 6
Training loss: 0.356116469772811
Validation loss: 2.3867663741972223

Epoch: 6| Step: 7
Training loss: 0.31675265623302157
Validation loss: 2.3903914643224007

Epoch: 6| Step: 8
Training loss: 0.19528889513426334
Validation loss: 2.375509999627031

Epoch: 6| Step: 9
Training loss: 0.20220015044044026
Validation loss: 2.368801665158653

Epoch: 6| Step: 10
Training loss: 0.20620900743769605
Validation loss: 2.354080884326887

Epoch: 6| Step: 11
Training loss: 0.33206683697445
Validation loss: 2.3529576578266527

Epoch: 6| Step: 12
Training loss: 0.21672299990787722
Validation loss: 2.3250884675814825

Epoch: 6| Step: 13
Training loss: 0.2003380615421679
Validation loss: 2.3005912929791443

Epoch: 446| Step: 0
Training loss: 0.24807571633939107
Validation loss: 2.3110244963682423

Epoch: 6| Step: 1
Training loss: 0.3366435748130615
Validation loss: 2.3088585258745433

Epoch: 6| Step: 2
Training loss: 0.39488329147081896
Validation loss: 2.3035243644067855

Epoch: 6| Step: 3
Training loss: 0.15591172316795104
Validation loss: 2.3510905023681636

Epoch: 6| Step: 4
Training loss: 0.1736459044851269
Validation loss: 2.374730201167572

Epoch: 6| Step: 5
Training loss: 0.15376465184869284
Validation loss: 2.3611563352692997

Epoch: 6| Step: 6
Training loss: 0.2225608286592653
Validation loss: 2.364599839236428

Epoch: 6| Step: 7
Training loss: 0.2710484634522636
Validation loss: 2.384758102086521

Epoch: 6| Step: 8
Training loss: 0.23540436085183883
Validation loss: 2.3711095701524676

Epoch: 6| Step: 9
Training loss: 0.11031120541328943
Validation loss: 2.359668400784191

Epoch: 6| Step: 10
Training loss: 0.4549747726237797
Validation loss: 2.3224852825548736

Epoch: 6| Step: 11
Training loss: 0.2894894565530158
Validation loss: 2.3512963917868763

Epoch: 6| Step: 12
Training loss: 0.31501811667978585
Validation loss: 2.360157299132825

Epoch: 6| Step: 13
Training loss: 0.4786843138769404
Validation loss: 2.366505490536685

Epoch: 447| Step: 0
Training loss: 0.3656384278138449
Validation loss: 2.3649589330975425

Epoch: 6| Step: 1
Training loss: 0.24574371451414456
Validation loss: 2.3155467641546497

Epoch: 6| Step: 2
Training loss: 0.3399226436900007
Validation loss: 2.3465463420003028

Epoch: 6| Step: 3
Training loss: 0.30528699145549426
Validation loss: 2.320096658281522

Epoch: 6| Step: 4
Training loss: 0.23458081586383583
Validation loss: 2.354630253025673

Epoch: 6| Step: 5
Training loss: 0.3769696879330566
Validation loss: 2.3674218038723525

Epoch: 6| Step: 6
Training loss: 0.32510362082796845
Validation loss: 2.3646894684744924

Epoch: 6| Step: 7
Training loss: 0.24455061247830234
Validation loss: 2.3436968900617603

Epoch: 6| Step: 8
Training loss: 0.27310977096786443
Validation loss: 2.3822821484335455

Epoch: 6| Step: 9
Training loss: 0.20121666492982032
Validation loss: 2.382852466771895

Epoch: 6| Step: 10
Training loss: 0.19992597185940714
Validation loss: 2.4036779892932474

Epoch: 6| Step: 11
Training loss: 0.2226250609923102
Validation loss: 2.41644639746509

Epoch: 6| Step: 12
Training loss: 0.34794977205731953
Validation loss: 2.41882639699087

Epoch: 6| Step: 13
Training loss: 0.30380534578338814
Validation loss: 2.4308388824884966

Epoch: 448| Step: 0
Training loss: 0.1793813066171375
Validation loss: 2.427410194737543

Epoch: 6| Step: 1
Training loss: 0.2666145293607146
Validation loss: 2.372857573390295

Epoch: 6| Step: 2
Training loss: 0.3391794640218422
Validation loss: 2.3852761902486503

Epoch: 6| Step: 3
Training loss: 0.32138123972698696
Validation loss: 2.3818180057805693

Epoch: 6| Step: 4
Training loss: 0.26242420146668377
Validation loss: 2.3831826382315953

Epoch: 6| Step: 5
Training loss: 0.20294217905583908
Validation loss: 2.383821868808532

Epoch: 6| Step: 6
Training loss: 0.28667142773757237
Validation loss: 2.381602563537937

Epoch: 6| Step: 7
Training loss: 0.3323419687808951
Validation loss: 2.3904737949776638

Epoch: 6| Step: 8
Training loss: 0.23573708516867264
Validation loss: 2.3641225815765092

Epoch: 6| Step: 9
Training loss: 0.20420815454211994
Validation loss: 2.380878053675492

Epoch: 6| Step: 10
Training loss: 0.2695873036355081
Validation loss: 2.3595613817401877

Epoch: 6| Step: 11
Training loss: 0.14484724735000556
Validation loss: 2.3625939901050286

Epoch: 6| Step: 12
Training loss: 0.2619380743638925
Validation loss: 2.3767912855401994

Epoch: 6| Step: 13
Training loss: 0.3956752658086043
Validation loss: 2.361189282317815

Epoch: 449| Step: 0
Training loss: 0.34221084593471274
Validation loss: 2.3535672215125674

Epoch: 6| Step: 1
Training loss: 0.29196115794575045
Validation loss: 2.32950873559618

Epoch: 6| Step: 2
Training loss: 0.3552495259463686
Validation loss: 2.274096007187317

Epoch: 6| Step: 3
Training loss: 0.23205446005182293
Validation loss: 2.2574388442012205

Epoch: 6| Step: 4
Training loss: 0.24510174584858363
Validation loss: 2.269139051141411

Epoch: 6| Step: 5
Training loss: 0.24588040534964012
Validation loss: 2.267980451138514

Epoch: 6| Step: 6
Training loss: 0.2870761566667676
Validation loss: 2.2872750880516057

Epoch: 6| Step: 7
Training loss: 0.27032646407733973
Validation loss: 2.3286341685541347

Epoch: 6| Step: 8
Training loss: 0.23456737252837948
Validation loss: 2.3254504050796645

Epoch: 6| Step: 9
Training loss: 0.22612102839607534
Validation loss: 2.3726846492511173

Epoch: 6| Step: 10
Training loss: 0.32186960104701273
Validation loss: 2.3877561812639683

Epoch: 6| Step: 11
Training loss: 0.2554314799055562
Validation loss: 2.4434394035415195

Epoch: 6| Step: 12
Training loss: 0.2599344780322749
Validation loss: 2.4544896262939253

Epoch: 6| Step: 13
Training loss: 0.16599856457283543
Validation loss: 2.505540149684771

Epoch: 450| Step: 0
Training loss: 0.31952855078716
Validation loss: 2.4853739273867244

Epoch: 6| Step: 1
Training loss: 0.29869954453246184
Validation loss: 2.436408182007061

Epoch: 6| Step: 2
Training loss: 0.2521348933357829
Validation loss: 2.422306241778798

Epoch: 6| Step: 3
Training loss: 0.23014139105437326
Validation loss: 2.4107956111294753

Epoch: 6| Step: 4
Training loss: 0.3622611706040084
Validation loss: 2.385095974460803

Epoch: 6| Step: 5
Training loss: 0.1525278202070643
Validation loss: 2.396266264319057

Epoch: 6| Step: 6
Training loss: 0.2580948352968727
Validation loss: 2.3765663709114992

Epoch: 6| Step: 7
Training loss: 0.19503339852823023
Validation loss: 2.3568894500515265

Epoch: 6| Step: 8
Training loss: 0.3051318571905597
Validation loss: 2.330840536758704

Epoch: 6| Step: 9
Training loss: 0.22725349319142188
Validation loss: 2.3410776037041847

Epoch: 6| Step: 10
Training loss: 0.19465489307334194
Validation loss: 2.3725693683140587

Epoch: 6| Step: 11
Training loss: 0.1812508307635243
Validation loss: 2.372028089501217

Epoch: 6| Step: 12
Training loss: 0.18528432842611198
Validation loss: 2.388029300701837

Epoch: 6| Step: 13
Training loss: 0.1961371180083253
Validation loss: 2.3679050227343126

Epoch: 451| Step: 0
Training loss: 0.22052632905373415
Validation loss: 2.37468973711952

Epoch: 6| Step: 1
Training loss: 0.18956114452240924
Validation loss: 2.3954041305673246

Epoch: 6| Step: 2
Training loss: 0.3804290883973862
Validation loss: 2.424164944393346

Epoch: 6| Step: 3
Training loss: 0.3322967029157995
Validation loss: 2.379395910365157

Epoch: 6| Step: 4
Training loss: 0.19302360202953522
Validation loss: 2.4129009931163945

Epoch: 6| Step: 5
Training loss: 0.2923410048118895
Validation loss: 2.4065301202317904

Epoch: 6| Step: 6
Training loss: 0.3135426888285522
Validation loss: 2.3870788198420554

Epoch: 6| Step: 7
Training loss: 0.24769051552437765
Validation loss: 2.4028786879438218

Epoch: 6| Step: 8
Training loss: 0.2025250138475013
Validation loss: 2.395610898157613

Epoch: 6| Step: 9
Training loss: 0.15419023788419634
Validation loss: 2.3641196840736347

Epoch: 6| Step: 10
Training loss: 0.17883943409488814
Validation loss: 2.358524142738714

Epoch: 6| Step: 11
Training loss: 0.3275477235907999
Validation loss: 2.3488357254013708

Epoch: 6| Step: 12
Training loss: 0.22518975283268475
Validation loss: 2.365756307467763

Epoch: 6| Step: 13
Training loss: 0.07884750362888898
Validation loss: 2.377763273247016

Epoch: 452| Step: 0
Training loss: 0.18315104616677633
Validation loss: 2.3812242701569586

Epoch: 6| Step: 1
Training loss: 0.2623526596773868
Validation loss: 2.4117934326093993

Epoch: 6| Step: 2
Training loss: 0.2960659849490442
Validation loss: 2.4319471915615267

Epoch: 6| Step: 3
Training loss: 0.2428412995509954
Validation loss: 2.4147185117154133

Epoch: 6| Step: 4
Training loss: 0.3005144248600861
Validation loss: 2.407993515480421

Epoch: 6| Step: 5
Training loss: 0.28704251918775947
Validation loss: 2.391291884106463

Epoch: 6| Step: 6
Training loss: 0.2064293984276606
Validation loss: 2.322523084733936

Epoch: 6| Step: 7
Training loss: 0.2549112822903548
Validation loss: 2.3435170900843065

Epoch: 6| Step: 8
Training loss: 0.2671093419296186
Validation loss: 2.2996470895301666

Epoch: 6| Step: 9
Training loss: 0.23436567764815713
Validation loss: 2.2824998292751175

Epoch: 6| Step: 10
Training loss: 0.2447830597737428
Validation loss: 2.3076077049914967

Epoch: 6| Step: 11
Training loss: 0.280081493830937
Validation loss: 2.3004658577906922

Epoch: 6| Step: 12
Training loss: 0.2379557309061547
Validation loss: 2.259721435185145

Epoch: 6| Step: 13
Training loss: 0.2187214475117364
Validation loss: 2.2683211976971314

Epoch: 453| Step: 0
Training loss: 0.2021358412351788
Validation loss: 2.3165481463881785

Epoch: 6| Step: 1
Training loss: 0.2138111093236707
Validation loss: 2.2988070627813224

Epoch: 6| Step: 2
Training loss: 0.35427547167274925
Validation loss: 2.3270097577385562

Epoch: 6| Step: 3
Training loss: 0.29329050832939585
Validation loss: 2.3108551885122073

Epoch: 6| Step: 4
Training loss: 0.14714606564450478
Validation loss: 2.333956309698274

Epoch: 6| Step: 5
Training loss: 0.2454852953457681
Validation loss: 2.3441627910072156

Epoch: 6| Step: 6
Training loss: 0.17797897610912222
Validation loss: 2.3608525786309973

Epoch: 6| Step: 7
Training loss: 0.263469137733309
Validation loss: 2.383756311932892

Epoch: 6| Step: 8
Training loss: 0.14667600812500517
Validation loss: 2.3980350218817206

Epoch: 6| Step: 9
Training loss: 0.2344685367856282
Validation loss: 2.358698894113314

Epoch: 6| Step: 10
Training loss: 0.3081902872368389
Validation loss: 2.3811991000493227

Epoch: 6| Step: 11
Training loss: 0.29850513480752433
Validation loss: 2.353742016879121

Epoch: 6| Step: 12
Training loss: 0.29450274362403284
Validation loss: 2.375116023763163

Epoch: 6| Step: 13
Training loss: 0.13649339495431517
Validation loss: 2.354933753577036

Epoch: 454| Step: 0
Training loss: 0.27638138104443416
Validation loss: 2.328439909394143

Epoch: 6| Step: 1
Training loss: 0.20337624783593247
Validation loss: 2.3520284881979854

Epoch: 6| Step: 2
Training loss: 0.20714401377069605
Validation loss: 2.3497342384642366

Epoch: 6| Step: 3
Training loss: 0.2997552290389559
Validation loss: 2.307203154807242

Epoch: 6| Step: 4
Training loss: 0.35779427061328756
Validation loss: 2.32641753455239

Epoch: 6| Step: 5
Training loss: 0.28742944950575944
Validation loss: 2.279230345028248

Epoch: 6| Step: 6
Training loss: 0.22285385732447116
Validation loss: 2.30145363600304

Epoch: 6| Step: 7
Training loss: 0.20895734950930941
Validation loss: 2.314071358639971

Epoch: 6| Step: 8
Training loss: 0.21242326655323163
Validation loss: 2.2986414360793233

Epoch: 6| Step: 9
Training loss: 0.251198192066092
Validation loss: 2.3295588493939774

Epoch: 6| Step: 10
Training loss: 0.3406136659608886
Validation loss: 2.349417010285321

Epoch: 6| Step: 11
Training loss: 0.1588607295561914
Validation loss: 2.3379502229011657

Epoch: 6| Step: 12
Training loss: 0.19070686317915106
Validation loss: 2.3617620890160005

Epoch: 6| Step: 13
Training loss: 0.1695501327985622
Validation loss: 2.3611051901594893

Epoch: 455| Step: 0
Training loss: 0.1734981297720608
Validation loss: 2.3319106650445485

Epoch: 6| Step: 1
Training loss: 0.16163632300963698
Validation loss: 2.3252671887317793

Epoch: 6| Step: 2
Training loss: 0.2807391082947243
Validation loss: 2.3511100608797415

Epoch: 6| Step: 3
Training loss: 0.1905362149142758
Validation loss: 2.3119017867408993

Epoch: 6| Step: 4
Training loss: 0.2144259986328037
Validation loss: 2.3435311010813864

Epoch: 6| Step: 5
Training loss: 0.13607704930587167
Validation loss: 2.318435690496355

Epoch: 6| Step: 6
Training loss: 0.1773516968278396
Validation loss: 2.307059022385762

Epoch: 6| Step: 7
Training loss: 0.27208035047297124
Validation loss: 2.345359074888867

Epoch: 6| Step: 8
Training loss: 0.4123396569063682
Validation loss: 2.339398429934114

Epoch: 6| Step: 9
Training loss: 0.17886711550475998
Validation loss: 2.3470976779638817

Epoch: 6| Step: 10
Training loss: 0.16309359526786765
Validation loss: 2.3226622387837357

Epoch: 6| Step: 11
Training loss: 0.30659693509975616
Validation loss: 2.346153580579412

Epoch: 6| Step: 12
Training loss: 0.2634538384797752
Validation loss: 2.3398926273568286

Epoch: 6| Step: 13
Training loss: 0.157350260487166
Validation loss: 2.359117514121937

Epoch: 456| Step: 0
Training loss: 0.20820672638660878
Validation loss: 2.3416740307739388

Epoch: 6| Step: 1
Training loss: 0.17576894717078437
Validation loss: 2.363708863115284

Epoch: 6| Step: 2
Training loss: 0.3007470396329011
Validation loss: 2.3932967195130477

Epoch: 6| Step: 3
Training loss: 0.15923754102950582
Validation loss: 2.3344156694768854

Epoch: 6| Step: 4
Training loss: 0.20868949050273922
Validation loss: 2.3652374814106434

Epoch: 6| Step: 5
Training loss: 0.15850615031737603
Validation loss: 2.366351533117962

Epoch: 6| Step: 6
Training loss: 0.17728413155303613
Validation loss: 2.379282395199815

Epoch: 6| Step: 7
Training loss: 0.24183977452140806
Validation loss: 2.3582804726523676

Epoch: 6| Step: 8
Training loss: 0.32508404864557094
Validation loss: 2.3546610523725024

Epoch: 6| Step: 9
Training loss: 0.14689800990230661
Validation loss: 2.389479981493719

Epoch: 6| Step: 10
Training loss: 0.1972989724554459
Validation loss: 2.3642535418541724

Epoch: 6| Step: 11
Training loss: 0.2793333123187358
Validation loss: 2.3645406755946543

Epoch: 6| Step: 12
Training loss: 0.29104817611625505
Validation loss: 2.3545756015253634

Epoch: 6| Step: 13
Training loss: 0.40461397865565213
Validation loss: 2.350863184480277

Epoch: 457| Step: 0
Training loss: 0.21420508738325716
Validation loss: 2.3722160367308764

Epoch: 6| Step: 1
Training loss: 0.25132267460769436
Validation loss: 2.3469532287029162

Epoch: 6| Step: 2
Training loss: 0.19970871940962542
Validation loss: 2.3577653130896516

Epoch: 6| Step: 3
Training loss: 0.18094785927483623
Validation loss: 2.3340600873519586

Epoch: 6| Step: 4
Training loss: 0.20628947400436864
Validation loss: 2.319810502192779

Epoch: 6| Step: 5
Training loss: 0.26857545252196124
Validation loss: 2.29693534123892

Epoch: 6| Step: 6
Training loss: 0.141554647105763
Validation loss: 2.304737120146857

Epoch: 6| Step: 7
Training loss: 0.17448466325518988
Validation loss: 2.29031670000707

Epoch: 6| Step: 8
Training loss: 0.24854148152214717
Validation loss: 2.2718923477083997

Epoch: 6| Step: 9
Training loss: 0.13855318577879924
Validation loss: 2.2838304708104227

Epoch: 6| Step: 10
Training loss: 0.35654299716954574
Validation loss: 2.330103381928015

Epoch: 6| Step: 11
Training loss: 0.27812791833525174
Validation loss: 2.325846483496144

Epoch: 6| Step: 12
Training loss: 0.23938718139788978
Validation loss: 2.3283909361338555

Epoch: 6| Step: 13
Training loss: 0.18385856887006552
Validation loss: 2.3533565379819312

Epoch: 458| Step: 0
Training loss: 0.14489584763616203
Validation loss: 2.3799892667681926

Epoch: 6| Step: 1
Training loss: 0.22961110219860692
Validation loss: 2.3934622382435027

Epoch: 6| Step: 2
Training loss: 0.220910439135729
Validation loss: 2.3940621137137437

Epoch: 6| Step: 3
Training loss: 0.29290829352615594
Validation loss: 2.3810791882170794

Epoch: 6| Step: 4
Training loss: 0.26952088377547817
Validation loss: 2.382664442379696

Epoch: 6| Step: 5
Training loss: 0.29145268129145135
Validation loss: 2.3740745591539385

Epoch: 6| Step: 6
Training loss: 0.2456912882368954
Validation loss: 2.3461882380169983

Epoch: 6| Step: 7
Training loss: 0.2620704053400148
Validation loss: 2.350441630627697

Epoch: 6| Step: 8
Training loss: 0.20853846206610038
Validation loss: 2.306820451446121

Epoch: 6| Step: 9
Training loss: 0.26794390493718895
Validation loss: 2.2893658100050875

Epoch: 6| Step: 10
Training loss: 0.23150498791835145
Validation loss: 2.2903772929393007

Epoch: 6| Step: 11
Training loss: 0.18347433955027825
Validation loss: 2.289453782344484

Epoch: 6| Step: 12
Training loss: 0.2658655816182388
Validation loss: 2.274230882870129

Epoch: 6| Step: 13
Training loss: 0.1287380045330422
Validation loss: 2.2627828579502016

Epoch: 459| Step: 0
Training loss: 0.18456318755753257
Validation loss: 2.2455542759632405

Epoch: 6| Step: 1
Training loss: 0.3986958619738988
Validation loss: 2.28476827837502

Epoch: 6| Step: 2
Training loss: 0.3556556838932464
Validation loss: 2.286816919086496

Epoch: 6| Step: 3
Training loss: 0.18870953012335262
Validation loss: 2.3125855026246858

Epoch: 6| Step: 4
Training loss: 0.25983169977320175
Validation loss: 2.318294454814041

Epoch: 6| Step: 5
Training loss: 0.22978877929217675
Validation loss: 2.3553917546970586

Epoch: 6| Step: 6
Training loss: 0.18707224610899167
Validation loss: 2.346113268093236

Epoch: 6| Step: 7
Training loss: 0.15257551219322293
Validation loss: 2.3190289571179994

Epoch: 6| Step: 8
Training loss: 0.24116823073174132
Validation loss: 2.349337116428555

Epoch: 6| Step: 9
Training loss: 0.24900077267894585
Validation loss: 2.3650811152841267

Epoch: 6| Step: 10
Training loss: 0.35573758449992426
Validation loss: 2.36739136140126

Epoch: 6| Step: 11
Training loss: 0.2709435076855977
Validation loss: 2.3525767942199862

Epoch: 6| Step: 12
Training loss: 0.276916308841212
Validation loss: 2.3469091310432395

Epoch: 6| Step: 13
Training loss: 0.22925826792331322
Validation loss: 2.352944984812221

Epoch: 460| Step: 0
Training loss: 0.23674821166709512
Validation loss: 2.341739376491549

Epoch: 6| Step: 1
Training loss: 0.31361061866220585
Validation loss: 2.3480108829763244

Epoch: 6| Step: 2
Training loss: 0.2631817536298583
Validation loss: 2.3724458028513506

Epoch: 6| Step: 3
Training loss: 0.1585962039306662
Validation loss: 2.358520297585732

Epoch: 6| Step: 4
Training loss: 0.1217295123693343
Validation loss: 2.3765632652855415

Epoch: 6| Step: 5
Training loss: 0.18209488783677757
Validation loss: 2.32818850639671

Epoch: 6| Step: 6
Training loss: 0.15159949657327032
Validation loss: 2.365186542155927

Epoch: 6| Step: 7
Training loss: 0.3123581802904803
Validation loss: 2.3223575024069625

Epoch: 6| Step: 8
Training loss: 0.3121081995554001
Validation loss: 2.3143334275354794

Epoch: 6| Step: 9
Training loss: 0.16887812298203142
Validation loss: 2.30059262628643

Epoch: 6| Step: 10
Training loss: 0.1923564950979793
Validation loss: 2.3166266673009286

Epoch: 6| Step: 11
Training loss: 0.24160838876885726
Validation loss: 2.3201737497558415

Epoch: 6| Step: 12
Training loss: 0.2594488550080026
Validation loss: 2.308188071484952

Epoch: 6| Step: 13
Training loss: 0.1659687424826544
Validation loss: 2.300325695908919

Epoch: 461| Step: 0
Training loss: 0.16193876135617177
Validation loss: 2.35620712222111

Epoch: 6| Step: 1
Training loss: 0.18274376302400927
Validation loss: 2.3599710660251927

Epoch: 6| Step: 2
Training loss: 0.16738445098680374
Validation loss: 2.370910100059718

Epoch: 6| Step: 3
Training loss: 0.2100192144379647
Validation loss: 2.3831067314293377

Epoch: 6| Step: 4
Training loss: 0.18927946685271035
Validation loss: 2.3585405488354976

Epoch: 6| Step: 5
Training loss: 0.3043002210440445
Validation loss: 2.3696389646845715

Epoch: 6| Step: 6
Training loss: 0.1550033487546555
Validation loss: 2.3676525687824026

Epoch: 6| Step: 7
Training loss: 0.16736328429499114
Validation loss: 2.3668396851716516

Epoch: 6| Step: 8
Training loss: 0.21151910180379704
Validation loss: 2.347070411995111

Epoch: 6| Step: 9
Training loss: 0.28435991739791167
Validation loss: 2.3413120582027385

Epoch: 6| Step: 10
Training loss: 0.21113261276645018
Validation loss: 2.375288395839562

Epoch: 6| Step: 11
Training loss: 0.18991188663279918
Validation loss: 2.3623490490586416

Epoch: 6| Step: 12
Training loss: 0.33071679620310757
Validation loss: 2.3684872590473662

Epoch: 6| Step: 13
Training loss: 0.050943006966715325
Validation loss: 2.372325183816055

Epoch: 462| Step: 0
Training loss: 0.11796148132516185
Validation loss: 2.3509192949302338

Epoch: 6| Step: 1
Training loss: 0.17094527011590302
Validation loss: 2.321032436484925

Epoch: 6| Step: 2
Training loss: 0.2088501044343665
Validation loss: 2.353865038335103

Epoch: 6| Step: 3
Training loss: 0.15485488813049073
Validation loss: 2.364998428966243

Epoch: 6| Step: 4
Training loss: 0.2888863258650579
Validation loss: 2.381013363904689

Epoch: 6| Step: 5
Training loss: 0.35085887432381196
Validation loss: 2.3573013969368

Epoch: 6| Step: 6
Training loss: 0.18310946650909266
Validation loss: 2.3571117085035636

Epoch: 6| Step: 7
Training loss: 0.16463460400300436
Validation loss: 2.3637389362670382

Epoch: 6| Step: 8
Training loss: 0.20575029932605204
Validation loss: 2.3596282999039717

Epoch: 6| Step: 9
Training loss: 0.20297318066818693
Validation loss: 2.333345644635655

Epoch: 6| Step: 10
Training loss: 0.18876452017505715
Validation loss: 2.3472871124195116

Epoch: 6| Step: 11
Training loss: 0.1682647935051697
Validation loss: 2.339133389597553

Epoch: 6| Step: 12
Training loss: 0.10862294994879104
Validation loss: 2.3198962962014114

Epoch: 6| Step: 13
Training loss: 0.11437276616546793
Validation loss: 2.33251468757094

Epoch: 463| Step: 0
Training loss: 0.2423352744356183
Validation loss: 2.3438220170964694

Epoch: 6| Step: 1
Training loss: 0.18231081634936727
Validation loss: 2.3889127654850406

Epoch: 6| Step: 2
Training loss: 0.12094170500224125
Validation loss: 2.362601674740446

Epoch: 6| Step: 3
Training loss: 0.17006730838596557
Validation loss: 2.368629790792323

Epoch: 6| Step: 4
Training loss: 0.18891005991019472
Validation loss: 2.374263582332488

Epoch: 6| Step: 5
Training loss: 0.14170169578401026
Validation loss: 2.3668863153707744

Epoch: 6| Step: 6
Training loss: 0.3390734701535412
Validation loss: 2.3663490218587246

Epoch: 6| Step: 7
Training loss: 0.2629296487806215
Validation loss: 2.3895008013005405

Epoch: 6| Step: 8
Training loss: 0.19857033691334058
Validation loss: 2.365049197482569

Epoch: 6| Step: 9
Training loss: 0.23696025923174419
Validation loss: 2.3436547323574226

Epoch: 6| Step: 10
Training loss: 0.1654410685978332
Validation loss: 2.381890663928554

Epoch: 6| Step: 11
Training loss: 0.14954990868465196
Validation loss: 2.345934162287259

Epoch: 6| Step: 12
Training loss: 0.18004055169073763
Validation loss: 2.3170522201964756

Epoch: 6| Step: 13
Training loss: 0.13235816660862956
Validation loss: 2.308963260576335

Epoch: 464| Step: 0
Training loss: 0.23029754227781563
Validation loss: 2.319626174495443

Epoch: 6| Step: 1
Training loss: 0.2974597793125741
Validation loss: 2.3485826063073874

Epoch: 6| Step: 2
Training loss: 0.19564954286858735
Validation loss: 2.346869559324252

Epoch: 6| Step: 3
Training loss: 0.18905403930081285
Validation loss: 2.298331330203388

Epoch: 6| Step: 4
Training loss: 0.20175834463664188
Validation loss: 2.324629490731549

Epoch: 6| Step: 5
Training loss: 0.15385993221829397
Validation loss: 2.335821369645616

Epoch: 6| Step: 6
Training loss: 0.27674988847694115
Validation loss: 2.3396596651779213

Epoch: 6| Step: 7
Training loss: 0.14266744193706848
Validation loss: 2.3426006416717793

Epoch: 6| Step: 8
Training loss: 0.13368240337278234
Validation loss: 2.3525099228456385

Epoch: 6| Step: 9
Training loss: 0.22774489756331975
Validation loss: 2.372711371016005

Epoch: 6| Step: 10
Training loss: 0.19531419753290627
Validation loss: 2.3818299248459165

Epoch: 6| Step: 11
Training loss: 0.12477960006063453
Validation loss: 2.3652331209454194

Epoch: 6| Step: 12
Training loss: 0.12070677822720181
Validation loss: 2.4009070167923907

Epoch: 6| Step: 13
Training loss: 0.3657899802240369
Validation loss: 2.3952169303974977

Epoch: 465| Step: 0
Training loss: 0.16750154835248676
Validation loss: 2.4012568414346624

Epoch: 6| Step: 1
Training loss: 0.27612350558268983
Validation loss: 2.4044468279816202

Epoch: 6| Step: 2
Training loss: 0.13296698253053085
Validation loss: 2.377400070142881

Epoch: 6| Step: 3
Training loss: 0.18278311264998642
Validation loss: 2.3948296569084078

Epoch: 6| Step: 4
Training loss: 0.27325948642726566
Validation loss: 2.39170568475163

Epoch: 6| Step: 5
Training loss: 0.3028393963186031
Validation loss: 2.368222317779904

Epoch: 6| Step: 6
Training loss: 0.2058308999709903
Validation loss: 2.391920813985903

Epoch: 6| Step: 7
Training loss: 0.17179246568073792
Validation loss: 2.3436483250375466

Epoch: 6| Step: 8
Training loss: 0.1865698671723391
Validation loss: 2.372863979086525

Epoch: 6| Step: 9
Training loss: 0.23511824379927843
Validation loss: 2.3637871394947814

Epoch: 6| Step: 10
Training loss: 0.16830766662665278
Validation loss: 2.3601588138605596

Epoch: 6| Step: 11
Training loss: 0.16255634229760743
Validation loss: 2.336103375755405

Epoch: 6| Step: 12
Training loss: 0.24527133790691188
Validation loss: 2.3503072226371655

Epoch: 6| Step: 13
Training loss: 0.17856841318956504
Validation loss: 2.352433997312171

Epoch: 466| Step: 0
Training loss: 0.27216207869513803
Validation loss: 2.3418636598326183

Epoch: 6| Step: 1
Training loss: 0.3721150849405021
Validation loss: 2.3204324171392803

Epoch: 6| Step: 2
Training loss: 0.3046448628841598
Validation loss: 2.31252118527487

Epoch: 6| Step: 3
Training loss: 0.22776035468182584
Validation loss: 2.3380844309061417

Epoch: 6| Step: 4
Training loss: 0.18350462068942872
Validation loss: 2.343579088767975

Epoch: 6| Step: 5
Training loss: 0.19600241878474314
Validation loss: 2.3576956959840527

Epoch: 6| Step: 6
Training loss: 0.1334330772118088
Validation loss: 2.345806496089868

Epoch: 6| Step: 7
Training loss: 0.1554871473976619
Validation loss: 2.3630795948651286

Epoch: 6| Step: 8
Training loss: 0.1868195106260381
Validation loss: 2.337914772254061

Epoch: 6| Step: 9
Training loss: 0.1889201956745233
Validation loss: 2.367597781237455

Epoch: 6| Step: 10
Training loss: 0.23145393162383807
Validation loss: 2.386676596561705

Epoch: 6| Step: 11
Training loss: 0.18164293226191813
Validation loss: 2.386975346379699

Epoch: 6| Step: 12
Training loss: 0.17930120949087253
Validation loss: 2.3618113583455633

Epoch: 6| Step: 13
Training loss: 0.13257417613382597
Validation loss: 2.369754968841571

Epoch: 467| Step: 0
Training loss: 0.16163071664243003
Validation loss: 2.365695473007359

Epoch: 6| Step: 1
Training loss: 0.38700002979431236
Validation loss: 2.3798189943162846

Epoch: 6| Step: 2
Training loss: 0.18184145213286487
Validation loss: 2.3273312055801445

Epoch: 6| Step: 3
Training loss: 0.2187527503113193
Validation loss: 2.3490898136090426

Epoch: 6| Step: 4
Training loss: 0.23775190433557822
Validation loss: 2.3203381328120556

Epoch: 6| Step: 5
Training loss: 0.1405677480184384
Validation loss: 2.320698669191699

Epoch: 6| Step: 6
Training loss: 0.23812385739029818
Validation loss: 2.296591138400463

Epoch: 6| Step: 7
Training loss: 0.20131456999319997
Validation loss: 2.30175847185479

Epoch: 6| Step: 8
Training loss: 0.2420192795706039
Validation loss: 2.278021178991432

Epoch: 6| Step: 9
Training loss: 0.2814362227317499
Validation loss: 2.2821933359660505

Epoch: 6| Step: 10
Training loss: 0.2180994783461715
Validation loss: 2.264651952013114

Epoch: 6| Step: 11
Training loss: 0.1846720904329578
Validation loss: 2.2717962581969258

Epoch: 6| Step: 12
Training loss: 0.23432451340187216
Validation loss: 2.313973231088429

Epoch: 6| Step: 13
Training loss: 0.333678121863329
Validation loss: 2.3231614100401687

Epoch: 468| Step: 0
Training loss: 0.15344538112918718
Validation loss: 2.3190277631990575

Epoch: 6| Step: 1
Training loss: 0.20358191964476727
Validation loss: 2.315722795362977

Epoch: 6| Step: 2
Training loss: 0.26872569794893814
Validation loss: 2.3574746670378235

Epoch: 6| Step: 3
Training loss: 0.13051482289407
Validation loss: 2.357216325388344

Epoch: 6| Step: 4
Training loss: 0.32117319771641134
Validation loss: 2.3898257847809887

Epoch: 6| Step: 5
Training loss: 0.16561143702628653
Validation loss: 2.373756578114665

Epoch: 6| Step: 6
Training loss: 0.20501613588329803
Validation loss: 2.4359167156193005

Epoch: 6| Step: 7
Training loss: 0.18381823349785092
Validation loss: 2.393514659511732

Epoch: 6| Step: 8
Training loss: 0.2932512574262401
Validation loss: 2.379371296810449

Epoch: 6| Step: 9
Training loss: 0.2435190986995013
Validation loss: 2.382030741970958

Epoch: 6| Step: 10
Training loss: 0.14145243454274492
Validation loss: 2.3512108887116767

Epoch: 6| Step: 11
Training loss: 0.13203023791630647
Validation loss: 2.3531198770601063

Epoch: 6| Step: 12
Training loss: 0.22843158839517813
Validation loss: 2.3562073109955297

Epoch: 6| Step: 13
Training loss: 0.1587248429505062
Validation loss: 2.3085201619475533

Epoch: 469| Step: 0
Training loss: 0.18229071866651808
Validation loss: 2.315354773227108

Epoch: 6| Step: 1
Training loss: 0.29788297893997046
Validation loss: 2.3447641777616512

Epoch: 6| Step: 2
Training loss: 0.2506002729779741
Validation loss: 2.3791350316588975

Epoch: 6| Step: 3
Training loss: 0.21436411464347105
Validation loss: 2.37724116311363

Epoch: 6| Step: 4
Training loss: 0.31622611911230947
Validation loss: 2.382160786077861

Epoch: 6| Step: 5
Training loss: 0.20972480803033108
Validation loss: 2.3431549399741702

Epoch: 6| Step: 6
Training loss: 0.19489059655966054
Validation loss: 2.3532217016591033

Epoch: 6| Step: 7
Training loss: 0.19890083864496966
Validation loss: 2.3835129252907987

Epoch: 6| Step: 8
Training loss: 0.23197459611357013
Validation loss: 2.333470859810903

Epoch: 6| Step: 9
Training loss: 0.14623612030305141
Validation loss: 2.363958921319303

Epoch: 6| Step: 10
Training loss: 0.33626190313379356
Validation loss: 2.3481895899241736

Epoch: 6| Step: 11
Training loss: 0.1858403545138085
Validation loss: 2.3832168894936556

Epoch: 6| Step: 12
Training loss: 0.14500809955172883
Validation loss: 2.388521175835876

Epoch: 6| Step: 13
Training loss: 0.14518760805417463
Validation loss: 2.3643427402019266

Epoch: 470| Step: 0
Training loss: 0.18576668217797998
Validation loss: 2.3572067319030876

Epoch: 6| Step: 1
Training loss: 0.3262398700310704
Validation loss: 2.3558614215071394

Epoch: 6| Step: 2
Training loss: 0.23892522778926784
Validation loss: 2.3423006844750143

Epoch: 6| Step: 3
Training loss: 0.26630698337494685
Validation loss: 2.3711073747774476

Epoch: 6| Step: 4
Training loss: 0.21030571596446893
Validation loss: 2.333551116161385

Epoch: 6| Step: 5
Training loss: 0.28889398560144347
Validation loss: 2.3254036241976834

Epoch: 6| Step: 6
Training loss: 0.14990308929158555
Validation loss: 2.363018539608306

Epoch: 6| Step: 7
Training loss: 0.1712540768047592
Validation loss: 2.364040730091096

Epoch: 6| Step: 8
Training loss: 0.14822673264710204
Validation loss: 2.366967727280238

Epoch: 6| Step: 9
Training loss: 0.1718570526462785
Validation loss: 2.39176425306701

Epoch: 6| Step: 10
Training loss: 0.12396032875389032
Validation loss: 2.375038084600212

Epoch: 6| Step: 11
Training loss: 0.08047283692305154
Validation loss: 2.3601248563532797

Epoch: 6| Step: 12
Training loss: 0.20187968204371592
Validation loss: 2.383128881674013

Epoch: 6| Step: 13
Training loss: 0.17578670175363398
Validation loss: 2.4004379069287918

Epoch: 471| Step: 0
Training loss: 0.22836407094454048
Validation loss: 2.3514517677407705

Epoch: 6| Step: 1
Training loss: 0.2701880979105581
Validation loss: 2.3308163365635304

Epoch: 6| Step: 2
Training loss: 0.3389535293734954
Validation loss: 2.315805114217384

Epoch: 6| Step: 3
Training loss: 0.15380007402347884
Validation loss: 2.3937027955180783

Epoch: 6| Step: 4
Training loss: 0.19668290969951813
Validation loss: 2.357545276416253

Epoch: 6| Step: 5
Training loss: 0.13647120408397287
Validation loss: 2.4157696478179043

Epoch: 6| Step: 6
Training loss: 0.3629605097662558
Validation loss: 2.4005838223283056

Epoch: 6| Step: 7
Training loss: 0.1484950355653641
Validation loss: 2.3990142899379054

Epoch: 6| Step: 8
Training loss: 0.28208159317050835
Validation loss: 2.362952429170135

Epoch: 6| Step: 9
Training loss: 0.3242386616486951
Validation loss: 2.359009670242599

Epoch: 6| Step: 10
Training loss: 0.24485873848975565
Validation loss: 2.328863020749766

Epoch: 6| Step: 11
Training loss: 0.16155521629118194
Validation loss: 2.3340007207326168

Epoch: 6| Step: 12
Training loss: 0.18912412647895258
Validation loss: 2.333793819565861

Epoch: 6| Step: 13
Training loss: 0.13235309328022957
Validation loss: 2.3752800841620787

Epoch: 472| Step: 0
Training loss: 0.3164703398421915
Validation loss: 2.330167301989206

Epoch: 6| Step: 1
Training loss: 0.3942610126752131
Validation loss: 2.3743643198713884

Epoch: 6| Step: 2
Training loss: 0.16871445930587126
Validation loss: 2.3418238129223132

Epoch: 6| Step: 3
Training loss: 0.20435355113282863
Validation loss: 2.324832901367757

Epoch: 6| Step: 4
Training loss: 0.28681551888016565
Validation loss: 2.3354216534999304

Epoch: 6| Step: 5
Training loss: 0.1406788789000655
Validation loss: 2.3296122519355085

Epoch: 6| Step: 6
Training loss: 0.25194367679357266
Validation loss: 2.3162752734333822

Epoch: 6| Step: 7
Training loss: 0.2787468435981189
Validation loss: 2.3074835644681286

Epoch: 6| Step: 8
Training loss: 0.29267307620091976
Validation loss: 2.350445036899863

Epoch: 6| Step: 9
Training loss: 0.3481907111700979
Validation loss: 2.353730950819248

Epoch: 6| Step: 10
Training loss: 0.20507038646811326
Validation loss: 2.369270348681333

Epoch: 6| Step: 11
Training loss: 0.3204426617281974
Validation loss: 2.3695113030533896

Epoch: 6| Step: 12
Training loss: 0.25307366239086276
Validation loss: 2.367270522731411

Epoch: 6| Step: 13
Training loss: 0.3778047182529634
Validation loss: 2.3365306149963176

Epoch: 473| Step: 0
Training loss: 0.272088729771779
Validation loss: 2.3523756164117993

Epoch: 6| Step: 1
Training loss: 0.25647614664850876
Validation loss: 2.342143019091617

Epoch: 6| Step: 2
Training loss: 0.2420553492891719
Validation loss: 2.3233523172534634

Epoch: 6| Step: 3
Training loss: 0.24271869088176246
Validation loss: 2.3394074575672597

Epoch: 6| Step: 4
Training loss: 0.22292231674401905
Validation loss: 2.3583844050384393

Epoch: 6| Step: 5
Training loss: 0.23072889968793475
Validation loss: 2.3136876040818923

Epoch: 6| Step: 6
Training loss: 0.24343548988129396
Validation loss: 2.328482482117083

Epoch: 6| Step: 7
Training loss: 0.38842853999219173
Validation loss: 2.3187354915894596

Epoch: 6| Step: 8
Training loss: 0.18102091008136165
Validation loss: 2.3478815406310205

Epoch: 6| Step: 9
Training loss: 0.23101635709304064
Validation loss: 2.3429842911575407

Epoch: 6| Step: 10
Training loss: 0.23420465159721926
Validation loss: 2.339796161224165

Epoch: 6| Step: 11
Training loss: 0.3271891782074511
Validation loss: 2.3402449499643736

Epoch: 6| Step: 12
Training loss: 0.2713550973364941
Validation loss: 2.3225074060632975

Epoch: 6| Step: 13
Training loss: 0.21520594497369674
Validation loss: 2.3126012840362353

Epoch: 474| Step: 0
Training loss: 0.26976771279020667
Validation loss: 2.2641204828597816

Epoch: 6| Step: 1
Training loss: 0.3390447607541881
Validation loss: 2.285652793700416

Epoch: 6| Step: 2
Training loss: 0.19561453354048045
Validation loss: 2.2349422855380707

Epoch: 6| Step: 3
Training loss: 0.21532571657917013
Validation loss: 2.2390245155873925

Epoch: 6| Step: 4
Training loss: 0.347093201216881
Validation loss: 2.2376992724055995

Epoch: 6| Step: 5
Training loss: 0.17458436176601053
Validation loss: 2.269931828954801

Epoch: 6| Step: 6
Training loss: 0.2198068006029885
Validation loss: 2.3153783084835724

Epoch: 6| Step: 7
Training loss: 0.21096079309212254
Validation loss: 2.3514421311127434

Epoch: 6| Step: 8
Training loss: 0.17127834055976324
Validation loss: 2.3418065633606493

Epoch: 6| Step: 9
Training loss: 0.17553939075075112
Validation loss: 2.388734873908493

Epoch: 6| Step: 10
Training loss: 0.20133437843069926
Validation loss: 2.398278007189284

Epoch: 6| Step: 11
Training loss: 0.23913338987664673
Validation loss: 2.41804469366684

Epoch: 6| Step: 12
Training loss: 0.35997874919105416
Validation loss: 2.4331366023163996

Epoch: 6| Step: 13
Training loss: 0.24820891666829423
Validation loss: 2.3778730813041125

Epoch: 475| Step: 0
Training loss: 0.15093404879484507
Validation loss: 2.305151312730395

Epoch: 6| Step: 1
Training loss: 0.2536502427821668
Validation loss: 2.286707866154883

Epoch: 6| Step: 2
Training loss: 0.26966788104537937
Validation loss: 2.278440861121716

Epoch: 6| Step: 3
Training loss: 0.25638495764233216
Validation loss: 2.273409733435153

Epoch: 6| Step: 4
Training loss: 0.3286887049735411
Validation loss: 2.291102887235049

Epoch: 6| Step: 5
Training loss: 0.27569315910973924
Validation loss: 2.299197125533973

Epoch: 6| Step: 6
Training loss: 0.18661623538733335
Validation loss: 2.3519285538048322

Epoch: 6| Step: 7
Training loss: 0.15464226176819992
Validation loss: 2.378917489916941

Epoch: 6| Step: 8
Training loss: 0.23078441015932508
Validation loss: 2.4113481708578064

Epoch: 6| Step: 9
Training loss: 0.28859683495211563
Validation loss: 2.445506294510436

Epoch: 6| Step: 10
Training loss: 0.2689396543884156
Validation loss: 2.4601857381129535

Epoch: 6| Step: 11
Training loss: 0.3808900478433935
Validation loss: 2.4260276534675187

Epoch: 6| Step: 12
Training loss: 0.2818684004753275
Validation loss: 2.4512408908458605

Epoch: 6| Step: 13
Training loss: 0.17172887941462403
Validation loss: 2.392895037866588

Epoch: 476| Step: 0
Training loss: 0.23937978165783416
Validation loss: 2.3777037328125123

Epoch: 6| Step: 1
Training loss: 0.18070171067030297
Validation loss: 2.345374350486362

Epoch: 6| Step: 2
Training loss: 0.18121807622940525
Validation loss: 2.3383178830423725

Epoch: 6| Step: 3
Training loss: 0.34235999449680443
Validation loss: 2.301359182361172

Epoch: 6| Step: 4
Training loss: 0.2893501603112404
Validation loss: 2.294377312563755

Epoch: 6| Step: 5
Training loss: 0.22337081921224045
Validation loss: 2.303741330379685

Epoch: 6| Step: 6
Training loss: 0.2944036819674797
Validation loss: 2.2826154294206895

Epoch: 6| Step: 7
Training loss: 0.28636642918026467
Validation loss: 2.3467451027599067

Epoch: 6| Step: 8
Training loss: 0.28246097003913895
Validation loss: 2.329071694830937

Epoch: 6| Step: 9
Training loss: 0.22240946293919836
Validation loss: 2.359915909496953

Epoch: 6| Step: 10
Training loss: 0.2976157709066211
Validation loss: 2.3586789591514483

Epoch: 6| Step: 11
Training loss: 0.15680802359336105
Validation loss: 2.36682230272862

Epoch: 6| Step: 12
Training loss: 0.18069447441851777
Validation loss: 2.386190818016157

Epoch: 6| Step: 13
Training loss: 0.2548366519447018
Validation loss: 2.342115453266142

Epoch: 477| Step: 0
Training loss: 0.2488188108560417
Validation loss: 2.3965138913772166

Epoch: 6| Step: 1
Training loss: 0.19951880055470436
Validation loss: 2.341342425050354

Epoch: 6| Step: 2
Training loss: 0.2173762784046138
Validation loss: 2.3998051972145484

Epoch: 6| Step: 3
Training loss: 0.1795285185032578
Validation loss: 2.3581000430051575

Epoch: 6| Step: 4
Training loss: 0.309637212895134
Validation loss: 2.2877173753473037

Epoch: 6| Step: 5
Training loss: 0.3133452428590254
Validation loss: 2.2830823663236934

Epoch: 6| Step: 6
Training loss: 0.2630956782496781
Validation loss: 2.283976428274405

Epoch: 6| Step: 7
Training loss: 0.3073936619106131
Validation loss: 2.274313562220397

Epoch: 6| Step: 8
Training loss: 0.30314785192811705
Validation loss: 2.303331328518292

Epoch: 6| Step: 9
Training loss: 0.2748424132695745
Validation loss: 2.345848299293235

Epoch: 6| Step: 10
Training loss: 0.2386420676165863
Validation loss: 2.3488333367582133

Epoch: 6| Step: 11
Training loss: 0.18982881479422925
Validation loss: 2.3588864552007234

Epoch: 6| Step: 12
Training loss: 0.1423002238991136
Validation loss: 2.3955071125977865

Epoch: 6| Step: 13
Training loss: 0.18170971735631522
Validation loss: 2.3748716936065337

Epoch: 478| Step: 0
Training loss: 0.1444095666385216
Validation loss: 2.3960516410620376

Epoch: 6| Step: 1
Training loss: 0.18030026898477752
Validation loss: 2.3707513765590305

Epoch: 6| Step: 2
Training loss: 0.18707629849185767
Validation loss: 2.3723698513038762

Epoch: 6| Step: 3
Training loss: 0.1975993553270314
Validation loss: 2.354166112194237

Epoch: 6| Step: 4
Training loss: 0.17230360819068413
Validation loss: 2.348967244917813

Epoch: 6| Step: 5
Training loss: 0.18198974447254332
Validation loss: 2.3434767215792336

Epoch: 6| Step: 6
Training loss: 0.32436764986240507
Validation loss: 2.328807988024905

Epoch: 6| Step: 7
Training loss: 0.27912115691631856
Validation loss: 2.3664528522967276

Epoch: 6| Step: 8
Training loss: 0.26199434487959106
Validation loss: 2.3330127419647364

Epoch: 6| Step: 9
Training loss: 0.23329087496228743
Validation loss: 2.354352126102076

Epoch: 6| Step: 10
Training loss: 0.19741772934516377
Validation loss: 2.3873280592200983

Epoch: 6| Step: 11
Training loss: 0.19132228878243113
Validation loss: 2.3753266231374197

Epoch: 6| Step: 12
Training loss: 0.15250698538712695
Validation loss: 2.3886013400086012

Epoch: 6| Step: 13
Training loss: 0.3079453912447406
Validation loss: 2.3884979164042854

Epoch: 479| Step: 0
Training loss: 0.31204032468326803
Validation loss: 2.353440307071029

Epoch: 6| Step: 1
Training loss: 0.24935758275321918
Validation loss: 2.368059926561311

Epoch: 6| Step: 2
Training loss: 0.13541558995796965
Validation loss: 2.360856398810428

Epoch: 6| Step: 3
Training loss: 0.13504956229706372
Validation loss: 2.341576810334634

Epoch: 6| Step: 4
Training loss: 0.20618070572663852
Validation loss: 2.3168116203770563

Epoch: 6| Step: 5
Training loss: 0.1955321316832542
Validation loss: 2.313790806680239

Epoch: 6| Step: 6
Training loss: 0.19306847817713418
Validation loss: 2.3252476146081533

Epoch: 6| Step: 7
Training loss: 0.3164047665031412
Validation loss: 2.330198262397838

Epoch: 6| Step: 8
Training loss: 0.10103420257855698
Validation loss: 2.3379157492799805

Epoch: 6| Step: 9
Training loss: 0.16985020276948326
Validation loss: 2.3088615260377927

Epoch: 6| Step: 10
Training loss: 0.1610757206430142
Validation loss: 2.3441596747138957

Epoch: 6| Step: 11
Training loss: 0.1844143688067652
Validation loss: 2.3234413827561804

Epoch: 6| Step: 12
Training loss: 0.2641380991867149
Validation loss: 2.3271065115477803

Epoch: 6| Step: 13
Training loss: 0.07555765009552452
Validation loss: 2.325258310166102

Epoch: 480| Step: 0
Training loss: 0.24533416445855236
Validation loss: 2.31061604703071

Epoch: 6| Step: 1
Training loss: 0.25337024746555853
Validation loss: 2.338700104111458

Epoch: 6| Step: 2
Training loss: 0.09659842727083781
Validation loss: 2.3251600935261068

Epoch: 6| Step: 3
Training loss: 0.12495422270114874
Validation loss: 2.3546531450296304

Epoch: 6| Step: 4
Training loss: 0.21528791118344018
Validation loss: 2.3588376421064736

Epoch: 6| Step: 5
Training loss: 0.18000144070472596
Validation loss: 2.39905070297307

Epoch: 6| Step: 6
Training loss: 0.13310061786681596
Validation loss: 2.3728241120166143

Epoch: 6| Step: 7
Training loss: 0.2188600025158474
Validation loss: 2.3901408015665466

Epoch: 6| Step: 8
Training loss: 0.2597636889622182
Validation loss: 2.4138418048232997

Epoch: 6| Step: 9
Training loss: 0.15991542900075972
Validation loss: 2.3940552410978992

Epoch: 6| Step: 10
Training loss: 0.22207564227603827
Validation loss: 2.3937689091887058

Epoch: 6| Step: 11
Training loss: 0.26344368561963843
Validation loss: 2.3882886910129657

Epoch: 6| Step: 12
Training loss: 0.11714097529981365
Validation loss: 2.3792907155229566

Epoch: 6| Step: 13
Training loss: 0.19587634714158733
Validation loss: 2.3538787209053322

Epoch: 481| Step: 0
Training loss: 0.19099400364802682
Validation loss: 2.3970583964792085

Epoch: 6| Step: 1
Training loss: 0.1955461820741783
Validation loss: 2.3627698922224156

Epoch: 6| Step: 2
Training loss: 0.16654549915408587
Validation loss: 2.3775141156603974

Epoch: 6| Step: 3
Training loss: 0.2540365325025603
Validation loss: 2.3769724329568023

Epoch: 6| Step: 4
Training loss: 0.18116741683232035
Validation loss: 2.3825126826473606

Epoch: 6| Step: 5
Training loss: 0.09901931310186698
Validation loss: 2.365687118956392

Epoch: 6| Step: 6
Training loss: 0.1874415684093439
Validation loss: 2.357645247293052

Epoch: 6| Step: 7
Training loss: 0.15138421731948554
Validation loss: 2.349609846351815

Epoch: 6| Step: 8
Training loss: 0.154012956032853
Validation loss: 2.354481415684762

Epoch: 6| Step: 9
Training loss: 0.2645118614342299
Validation loss: 2.35530631267254

Epoch: 6| Step: 10
Training loss: 0.23949763676198155
Validation loss: 2.346820704928804

Epoch: 6| Step: 11
Training loss: 0.24121007262781435
Validation loss: 2.3389127307072854

Epoch: 6| Step: 12
Training loss: 0.1623205280492552
Validation loss: 2.3188777457095124

Epoch: 6| Step: 13
Training loss: 0.1765430684495052
Validation loss: 2.3327526155093246

Epoch: 482| Step: 0
Training loss: 0.26866328037954235
Validation loss: 2.3345446789652002

Epoch: 6| Step: 1
Training loss: 0.2785529787072437
Validation loss: 2.305532897102844

Epoch: 6| Step: 2
Training loss: 0.13445556604052447
Validation loss: 2.3372051752808174

Epoch: 6| Step: 3
Training loss: 0.12311544475656966
Validation loss: 2.3119361548122033

Epoch: 6| Step: 4
Training loss: 0.16564372424682605
Validation loss: 2.3606583583939313

Epoch: 6| Step: 5
Training loss: 0.13799689793123623
Validation loss: 2.336155876992451

Epoch: 6| Step: 6
Training loss: 0.11411135407864982
Validation loss: 2.3496349773407177

Epoch: 6| Step: 7
Training loss: 0.14910828710896887
Validation loss: 2.3445902772225096

Epoch: 6| Step: 8
Training loss: 0.1946885442016912
Validation loss: 2.347898135195957

Epoch: 6| Step: 9
Training loss: 0.13578923185480718
Validation loss: 2.34765293796165

Epoch: 6| Step: 10
Training loss: 0.257497942369999
Validation loss: 2.325776535406874

Epoch: 6| Step: 11
Training loss: 0.24112681416154874
Validation loss: 2.337029154578967

Epoch: 6| Step: 12
Training loss: 0.17747648624029452
Validation loss: 2.3278986783745945

Epoch: 6| Step: 13
Training loss: 0.08199216558684211
Validation loss: 2.3357598367546144

Epoch: 483| Step: 0
Training loss: 0.11148162348532259
Validation loss: 2.3384814905664055

Epoch: 6| Step: 1
Training loss: 0.17200606940547503
Validation loss: 2.3591851783740436

Epoch: 6| Step: 2
Training loss: 0.3253560857312988
Validation loss: 2.339715667110943

Epoch: 6| Step: 3
Training loss: 0.21172927675435446
Validation loss: 2.3465635064645176

Epoch: 6| Step: 4
Training loss: 0.10186899228899517
Validation loss: 2.365836372327447

Epoch: 6| Step: 5
Training loss: 0.14035425348672234
Validation loss: 2.3353083847778806

Epoch: 6| Step: 6
Training loss: 0.10273419840692348
Validation loss: 2.347383314941368

Epoch: 6| Step: 7
Training loss: 0.1281045417618338
Validation loss: 2.337012963858815

Epoch: 6| Step: 8
Training loss: 0.23560371978244693
Validation loss: 2.3189399863634046

Epoch: 6| Step: 9
Training loss: 0.26414282384057075
Validation loss: 2.323029115385801

Epoch: 6| Step: 10
Training loss: 0.1630139677493116
Validation loss: 2.3579087993601178

Epoch: 6| Step: 11
Training loss: 0.15395159053512056
Validation loss: 2.315568334514892

Epoch: 6| Step: 12
Training loss: 0.20898584561409864
Validation loss: 2.300478865038247

Epoch: 6| Step: 13
Training loss: 0.2810914731953956
Validation loss: 2.3453346446567394

Epoch: 484| Step: 0
Training loss: 0.24585919328361028
Validation loss: 2.290399713154771

Epoch: 6| Step: 1
Training loss: 0.22534315247298442
Validation loss: 2.2843112939647523

Epoch: 6| Step: 2
Training loss: 0.3223233720307959
Validation loss: 2.2436937116174

Epoch: 6| Step: 3
Training loss: 0.43978164261465846
Validation loss: 2.2715926199710115

Epoch: 6| Step: 4
Training loss: 0.3243856115571611
Validation loss: 2.2709800384569396

Epoch: 6| Step: 5
Training loss: 0.21875867656121467
Validation loss: 2.3234643462041253

Epoch: 6| Step: 6
Training loss: 0.40688272867318903
Validation loss: 2.3492390896604425

Epoch: 6| Step: 7
Training loss: 0.3169884447028419
Validation loss: 2.3914395330137554

Epoch: 6| Step: 8
Training loss: 0.28976926232032596
Validation loss: 2.3790762580388676

Epoch: 6| Step: 9
Training loss: 0.23250362016566653
Validation loss: 2.4404799380978788

Epoch: 6| Step: 10
Training loss: 0.3613734655027689
Validation loss: 2.41701721556313

Epoch: 6| Step: 11
Training loss: 0.2697628656992469
Validation loss: 2.4022894233478858

Epoch: 6| Step: 12
Training loss: 0.30638793690222205
Validation loss: 2.3869773816319446

Epoch: 6| Step: 13
Training loss: 0.2838864993424908
Validation loss: 2.360224986255758

Epoch: 485| Step: 0
Training loss: 0.28773672630639896
Validation loss: 2.35137644312336

Epoch: 6| Step: 1
Training loss: 0.2217729095190386
Validation loss: 2.3525863918743095

Epoch: 6| Step: 2
Training loss: 0.1793539330442596
Validation loss: 2.3228095826535133

Epoch: 6| Step: 3
Training loss: 0.1518106486422372
Validation loss: 2.3038618046044874

Epoch: 6| Step: 4
Training loss: 0.3195050343063137
Validation loss: 2.284342650859821

Epoch: 6| Step: 5
Training loss: 0.2654011568591152
Validation loss: 2.275306107667254

Epoch: 6| Step: 6
Training loss: 0.22233897743544898
Validation loss: 2.2898017467698497

Epoch: 6| Step: 7
Training loss: 0.2437972515107939
Validation loss: 2.313024627654135

Epoch: 6| Step: 8
Training loss: 0.21511965288724022
Validation loss: 2.315879783116568

Epoch: 6| Step: 9
Training loss: 0.18739165712452588
Validation loss: 2.3407102105614066

Epoch: 6| Step: 10
Training loss: 0.22318058014885903
Validation loss: 2.3804490467703543

Epoch: 6| Step: 11
Training loss: 0.3742567485081111
Validation loss: 2.3872752014170637

Epoch: 6| Step: 12
Training loss: 0.30600590222718904
Validation loss: 2.418690195669422

Epoch: 6| Step: 13
Training loss: 0.17954001386216187
Validation loss: 2.425963643705463

Epoch: 486| Step: 0
Training loss: 0.275028369263892
Validation loss: 2.4780610310218485

Epoch: 6| Step: 1
Training loss: 0.3454826535584916
Validation loss: 2.47526102497091

Epoch: 6| Step: 2
Training loss: 0.2848236678928473
Validation loss: 2.4022503610342354

Epoch: 6| Step: 3
Training loss: 0.26815260871715074
Validation loss: 2.4394096475005593

Epoch: 6| Step: 4
Training loss: 0.18426840173710204
Validation loss: 2.3545482593757616

Epoch: 6| Step: 5
Training loss: 0.20976996497241188
Validation loss: 2.3274546036050703

Epoch: 6| Step: 6
Training loss: 0.1693734603720363
Validation loss: 2.307720254426998

Epoch: 6| Step: 7
Training loss: 0.24060126720159764
Validation loss: 2.2644011046401453

Epoch: 6| Step: 8
Training loss: 0.30991671462459114
Validation loss: 2.275664392147213

Epoch: 6| Step: 9
Training loss: 0.233202848322463
Validation loss: 2.3400289441108257

Epoch: 6| Step: 10
Training loss: 0.2528858220419445
Validation loss: 2.3770662116141517

Epoch: 6| Step: 11
Training loss: 0.20096137320282143
Validation loss: 2.4095778160811347

Epoch: 6| Step: 12
Training loss: 0.3085545502887039
Validation loss: 2.4835806038521513

Epoch: 6| Step: 13
Training loss: 0.38042092149965734
Validation loss: 2.4457693497840873

Epoch: 487| Step: 0
Training loss: 0.1554647862106405
Validation loss: 2.422125568851433

Epoch: 6| Step: 1
Training loss: 0.17443383159285938
Validation loss: 2.3929165762953817

Epoch: 6| Step: 2
Training loss: 0.30309338355600246
Validation loss: 2.376224763325646

Epoch: 6| Step: 3
Training loss: 0.183812457550625
Validation loss: 2.3540689856667525

Epoch: 6| Step: 4
Training loss: 0.20358223987226617
Validation loss: 2.3418427887165167

Epoch: 6| Step: 5
Training loss: 0.18985354982992605
Validation loss: 2.347695442645012

Epoch: 6| Step: 6
Training loss: 0.33148183806826614
Validation loss: 2.324147973620692

Epoch: 6| Step: 7
Training loss: 0.30884327035673886
Validation loss: 2.3572410055128454

Epoch: 6| Step: 8
Training loss: 0.2512114942992631
Validation loss: 2.3478387406779615

Epoch: 6| Step: 9
Training loss: 0.22906205470001528
Validation loss: 2.372033592286455

Epoch: 6| Step: 10
Training loss: 0.22987696268292365
Validation loss: 2.385724490384846

Epoch: 6| Step: 11
Training loss: 0.2019547534338341
Validation loss: 2.3872640695790706

Epoch: 6| Step: 12
Training loss: 0.2086183872746255
Validation loss: 2.4070495184927543

Epoch: 6| Step: 13
Training loss: 0.16922791499347675
Validation loss: 2.426148932451042

Epoch: 488| Step: 0
Training loss: 0.2318984637508937
Validation loss: 2.4347705933665122

Epoch: 6| Step: 1
Training loss: 0.16888635632028398
Validation loss: 2.409954215813782

Epoch: 6| Step: 2
Training loss: 0.1485899782053068
Validation loss: 2.411576346418617

Epoch: 6| Step: 3
Training loss: 0.11666946750142727
Validation loss: 2.407860351175604

Epoch: 6| Step: 4
Training loss: 0.2593758749659844
Validation loss: 2.3946210661050804

Epoch: 6| Step: 5
Training loss: 0.2132177202394709
Validation loss: 2.414615585665404

Epoch: 6| Step: 6
Training loss: 0.14117438897288923
Validation loss: 2.3854135960277354

Epoch: 6| Step: 7
Training loss: 0.12613949109138026
Validation loss: 2.3783514062552213

Epoch: 6| Step: 8
Training loss: 0.29888715971202684
Validation loss: 2.3822041709190778

Epoch: 6| Step: 9
Training loss: 0.2998395023571865
Validation loss: 2.393480821779788

Epoch: 6| Step: 10
Training loss: 0.1667785449084718
Validation loss: 2.399725600676331

Epoch: 6| Step: 11
Training loss: 0.2433979946739149
Validation loss: 2.3903058722627

Epoch: 6| Step: 12
Training loss: 0.2569264589636301
Validation loss: 2.389846940018966

Epoch: 6| Step: 13
Training loss: 0.16195124071628778
Validation loss: 2.4028895031242836

Epoch: 489| Step: 0
Training loss: 0.28175023415529526
Validation loss: 2.402811175450613

Epoch: 6| Step: 1
Training loss: 0.16626963537108294
Validation loss: 2.416948831003007

Epoch: 6| Step: 2
Training loss: 0.14297030349054202
Validation loss: 2.3993583958984814

Epoch: 6| Step: 3
Training loss: 0.13020170830720737
Validation loss: 2.396797702658111

Epoch: 6| Step: 4
Training loss: 0.10201712788091094
Validation loss: 2.402167832091038

Epoch: 6| Step: 5
Training loss: 0.14357222884564472
Validation loss: 2.387728633111694

Epoch: 6| Step: 6
Training loss: 0.10768081494125627
Validation loss: 2.3685624266566965

Epoch: 6| Step: 7
Training loss: 0.21037298180240493
Validation loss: 2.349982785842813

Epoch: 6| Step: 8
Training loss: 0.17131611600606375
Validation loss: 2.4044457980243945

Epoch: 6| Step: 9
Training loss: 0.16869158241410293
Validation loss: 2.381117646082164

Epoch: 6| Step: 10
Training loss: 0.2394499338257866
Validation loss: 2.3897695118589235

Epoch: 6| Step: 11
Training loss: 0.1744785142763002
Validation loss: 2.3424243418388655

Epoch: 6| Step: 12
Training loss: 0.2774321321241843
Validation loss: 2.370048975416204

Epoch: 6| Step: 13
Training loss: 0.2791985825661146
Validation loss: 2.368427414454688

Epoch: 490| Step: 0
Training loss: 0.1457924970150015
Validation loss: 2.3820178948400406

Epoch: 6| Step: 1
Training loss: 0.09881706779051347
Validation loss: 2.3758166387449977

Epoch: 6| Step: 2
Training loss: 0.1585081186392659
Validation loss: 2.417707169029757

Epoch: 6| Step: 3
Training loss: 0.14703823920247924
Validation loss: 2.4000497753867784

Epoch: 6| Step: 4
Training loss: 0.18138311447221603
Validation loss: 2.4050923623052203

Epoch: 6| Step: 5
Training loss: 0.18957306319669404
Validation loss: 2.3814919123179665

Epoch: 6| Step: 6
Training loss: 0.13558074214766155
Validation loss: 2.371764735797753

Epoch: 6| Step: 7
Training loss: 0.22945694348408643
Validation loss: 2.3409829292743605

Epoch: 6| Step: 8
Training loss: 0.16291740983987005
Validation loss: 2.364968571558465

Epoch: 6| Step: 9
Training loss: 0.2738140918874365
Validation loss: 2.3525009128001724

Epoch: 6| Step: 10
Training loss: 0.12290668827573303
Validation loss: 2.34177880692136

Epoch: 6| Step: 11
Training loss: 0.2928996704039798
Validation loss: 2.3528346352347884

Epoch: 6| Step: 12
Training loss: 0.18204850372929568
Validation loss: 2.3414125902495444

Epoch: 6| Step: 13
Training loss: 0.16949501902968414
Validation loss: 2.3545006564008983

Epoch: 491| Step: 0
Training loss: 0.17845315528844655
Validation loss: 2.320661252109879

Epoch: 6| Step: 1
Training loss: 0.19211565628735303
Validation loss: 2.3565814582876534

Epoch: 6| Step: 2
Training loss: 0.13365588555722233
Validation loss: 2.367603158428226

Epoch: 6| Step: 3
Training loss: 0.17812338376566808
Validation loss: 2.413918796978205

Epoch: 6| Step: 4
Training loss: 0.2585875248231727
Validation loss: 2.411889507689896

Epoch: 6| Step: 5
Training loss: 0.14470829944979074
Validation loss: 2.419516613330213

Epoch: 6| Step: 6
Training loss: 0.1573336337378464
Validation loss: 2.42914474286884

Epoch: 6| Step: 7
Training loss: 0.19891916450353986
Validation loss: 2.4532941764213034

Epoch: 6| Step: 8
Training loss: 0.33136373627599075
Validation loss: 2.438945167261189

Epoch: 6| Step: 9
Training loss: 0.18911625712634644
Validation loss: 2.432793357189436

Epoch: 6| Step: 10
Training loss: 0.291947109353366
Validation loss: 2.3989328392172795

Epoch: 6| Step: 11
Training loss: 0.1721548381608346
Validation loss: 2.376140082289414

Epoch: 6| Step: 12
Training loss: 0.1504885738501158
Validation loss: 2.3688529471204904

Epoch: 6| Step: 13
Training loss: 0.15385957508765652
Validation loss: 2.3482358950361197

Epoch: 492| Step: 0
Training loss: 0.2736780879311602
Validation loss: 2.330174051681602

Epoch: 6| Step: 1
Training loss: 0.18759123251549276
Validation loss: 2.31028091968899

Epoch: 6| Step: 2
Training loss: 0.18539719818718228
Validation loss: 2.3483507903050116

Epoch: 6| Step: 3
Training loss: 0.0753576149593579
Validation loss: 2.3441281588528238

Epoch: 6| Step: 4
Training loss: 0.19658086921359813
Validation loss: 2.3372790453447263

Epoch: 6| Step: 5
Training loss: 0.14300362573292033
Validation loss: 2.3228245407929666

Epoch: 6| Step: 6
Training loss: 0.2655892067523013
Validation loss: 2.3451745716981653

Epoch: 6| Step: 7
Training loss: 0.23338041674902263
Validation loss: 2.383496949223124

Epoch: 6| Step: 8
Training loss: 0.2832272486442298
Validation loss: 2.3886715777099004

Epoch: 6| Step: 9
Training loss: 0.17473592950968078
Validation loss: 2.414923692474018

Epoch: 6| Step: 10
Training loss: 0.14455177831492752
Validation loss: 2.3855580135184495

Epoch: 6| Step: 11
Training loss: 0.15319957352625882
Validation loss: 2.436984028356274

Epoch: 6| Step: 12
Training loss: 0.19489330128184199
Validation loss: 2.444415327353503

Epoch: 6| Step: 13
Training loss: 0.21506517444035214
Validation loss: 2.4378615732480013

Epoch: 493| Step: 0
Training loss: 0.19810731180095859
Validation loss: 2.4485552923250995

Epoch: 6| Step: 1
Training loss: 0.16224278854543137
Validation loss: 2.41409253419896

Epoch: 6| Step: 2
Training loss: 0.1732193165146512
Validation loss: 2.359715348694623

Epoch: 6| Step: 3
Training loss: 0.14787172107011745
Validation loss: 2.3697076583588896

Epoch: 6| Step: 4
Training loss: 0.1843820146260791
Validation loss: 2.3403025462594407

Epoch: 6| Step: 5
Training loss: 0.1992553041618453
Validation loss: 2.3387174352305746

Epoch: 6| Step: 6
Training loss: 0.12045344914837955
Validation loss: 2.320207802490452

Epoch: 6| Step: 7
Training loss: 0.21251083760113654
Validation loss: 2.301702167621277

Epoch: 6| Step: 8
Training loss: 0.19342780588106043
Validation loss: 2.304270939404549

Epoch: 6| Step: 9
Training loss: 0.10111029068796443
Validation loss: 2.289826783478977

Epoch: 6| Step: 10
Training loss: 0.24674174358058762
Validation loss: 2.2831386612255717

Epoch: 6| Step: 11
Training loss: 0.11034635514657623
Validation loss: 2.346035649670598

Epoch: 6| Step: 12
Training loss: 0.2775372246742472
Validation loss: 2.323685051630847

Epoch: 6| Step: 13
Training loss: 0.17456235017712013
Validation loss: 2.3356143756602763

Epoch: 494| Step: 0
Training loss: 0.16526674895884003
Validation loss: 2.358040575491161

Epoch: 6| Step: 1
Training loss: 0.15071376540499212
Validation loss: 2.3355394041260724

Epoch: 6| Step: 2
Training loss: 0.17007211642149966
Validation loss: 2.3344637912807453

Epoch: 6| Step: 3
Training loss: 0.2671040421361067
Validation loss: 2.3345833521450654

Epoch: 6| Step: 4
Training loss: 0.18847178912665483
Validation loss: 2.3573905532968755

Epoch: 6| Step: 5
Training loss: 0.1285276560963787
Validation loss: 2.3437913875959038

Epoch: 6| Step: 6
Training loss: 0.18785921099872246
Validation loss: 2.3597266142941486

Epoch: 6| Step: 7
Training loss: 0.1107603115476044
Validation loss: 2.356757043365199

Epoch: 6| Step: 8
Training loss: 0.09059623537177616
Validation loss: 2.3353499306228063

Epoch: 6| Step: 9
Training loss: 0.19054563855860573
Validation loss: 2.3809445019267867

Epoch: 6| Step: 10
Training loss: 0.28022616848442927
Validation loss: 2.342299809971897

Epoch: 6| Step: 11
Training loss: 0.211970326210403
Validation loss: 2.384266421026133

Epoch: 6| Step: 12
Training loss: 0.24717176563326354
Validation loss: 2.3419697618768387

Epoch: 6| Step: 13
Training loss: 0.08792181521220976
Validation loss: 2.346088421462363

Epoch: 495| Step: 0
Training loss: 0.1556961914275811
Validation loss: 2.361908904027286

Epoch: 6| Step: 1
Training loss: 0.11156164740656054
Validation loss: 2.3477394796730016

Epoch: 6| Step: 2
Training loss: 0.12430746116729985
Validation loss: 2.3784568156377204

Epoch: 6| Step: 3
Training loss: 0.18462628318208982
Validation loss: 2.380784024594396

Epoch: 6| Step: 4
Training loss: 0.2587245212901415
Validation loss: 2.372564127720894

Epoch: 6| Step: 5
Training loss: 0.13968093200578097
Validation loss: 2.4025113451243807

Epoch: 6| Step: 6
Training loss: 0.10233056806163417
Validation loss: 2.3621156689263434

Epoch: 6| Step: 7
Training loss: 0.12457195769545701
Validation loss: 2.364891459519036

Epoch: 6| Step: 8
Training loss: 0.21633622485998572
Validation loss: 2.357715348124064

Epoch: 6| Step: 9
Training loss: 0.1190648737055033
Validation loss: 2.341103038177468

Epoch: 6| Step: 10
Training loss: 0.2263279885030591
Validation loss: 2.3666567764381763

Epoch: 6| Step: 11
Training loss: 0.21256488412531183
Validation loss: 2.3552874638534775

Epoch: 6| Step: 12
Training loss: 0.21421549578253227
Validation loss: 2.3336521341443324

Epoch: 6| Step: 13
Training loss: 0.15041209352516507
Validation loss: 2.3353327460379405

Epoch: 496| Step: 0
Training loss: 0.1391698867340611
Validation loss: 2.3399380361151447

Epoch: 6| Step: 1
Training loss: 0.3065737997727587
Validation loss: 2.333453692424492

Epoch: 6| Step: 2
Training loss: 0.13946933865791558
Validation loss: 2.306009128967828

Epoch: 6| Step: 3
Training loss: 0.17355063610340865
Validation loss: 2.3204449279920336

Epoch: 6| Step: 4
Training loss: 0.2645206213143553
Validation loss: 2.3004597391658144

Epoch: 6| Step: 5
Training loss: 0.19455458451310342
Validation loss: 2.288642229026254

Epoch: 6| Step: 6
Training loss: 0.206388790220939
Validation loss: 2.31091707059132

Epoch: 6| Step: 7
Training loss: 0.12477706609495089
Validation loss: 2.3088455724972734

Epoch: 6| Step: 8
Training loss: 0.1458707928798592
Validation loss: 2.327307958909823

Epoch: 6| Step: 9
Training loss: 0.16705810628936676
Validation loss: 2.355868125877497

Epoch: 6| Step: 10
Training loss: 0.16891466535306543
Validation loss: 2.3509179372768596

Epoch: 6| Step: 11
Training loss: 0.08488030005105954
Validation loss: 2.3370361992815614

Epoch: 6| Step: 12
Training loss: 0.17545355876271423
Validation loss: 2.3846785402874997

Epoch: 6| Step: 13
Training loss: 0.18674178599865152
Validation loss: 2.3673908096652534

Epoch: 497| Step: 0
Training loss: 0.1506641489117201
Validation loss: 2.395380726596957

Epoch: 6| Step: 1
Training loss: 0.11974479356021617
Validation loss: 2.4148992993090417

Epoch: 6| Step: 2
Training loss: 0.19574104977141765
Validation loss: 2.3866988613693074

Epoch: 6| Step: 3
Training loss: 0.12729665054885855
Validation loss: 2.3487320046436038

Epoch: 6| Step: 4
Training loss: 0.22436232871082484
Validation loss: 2.3821231731895542

Epoch: 6| Step: 5
Training loss: 0.1568250148765433
Validation loss: 2.3618353598110047

Epoch: 6| Step: 6
Training loss: 0.1499392808766285
Validation loss: 2.3632732974631954

Epoch: 6| Step: 7
Training loss: 0.17095862282511465
Validation loss: 2.3480798859390593

Epoch: 6| Step: 8
Training loss: 0.37071449575882875
Validation loss: 2.334213380566658

Epoch: 6| Step: 9
Training loss: 0.11522974797027324
Validation loss: 2.320412615516607

Epoch: 6| Step: 10
Training loss: 0.19000106894355537
Validation loss: 2.322163997422378

Epoch: 6| Step: 11
Training loss: 0.179192784581064
Validation loss: 2.310815809253908

Epoch: 6| Step: 12
Training loss: 0.15960440113983373
Validation loss: 2.3397939578340443

Epoch: 6| Step: 13
Training loss: 0.41745228811709084
Validation loss: 2.331478448099725

Epoch: 498| Step: 0
Training loss: 0.2880623759316831
Validation loss: 2.307437260379794

Epoch: 6| Step: 1
Training loss: 0.18227967268223577
Validation loss: 2.3178677972179504

Epoch: 6| Step: 2
Training loss: 0.23464555224516084
Validation loss: 2.3125292576061764

Epoch: 6| Step: 3
Training loss: 0.16598605846336667
Validation loss: 2.3521578733502686

Epoch: 6| Step: 4
Training loss: 0.1422999162944794
Validation loss: 2.3614458735519195

Epoch: 6| Step: 5
Training loss: 0.2128571300229995
Validation loss: 2.373345975139921

Epoch: 6| Step: 6
Training loss: 0.2844136641491339
Validation loss: 2.3720812627432655

Epoch: 6| Step: 7
Training loss: 0.19124501112745235
Validation loss: 2.3809395241866347

Epoch: 6| Step: 8
Training loss: 0.09824737929471955
Validation loss: 2.376084527499478

Epoch: 6| Step: 9
Training loss: 0.10470712250099126
Validation loss: 2.3834511758814214

Epoch: 6| Step: 10
Training loss: 0.13799390815120396
Validation loss: 2.387105331610651

Epoch: 6| Step: 11
Training loss: 0.23115622900343497
Validation loss: 2.3774673315972055

Epoch: 6| Step: 12
Training loss: 0.14270753082922213
Validation loss: 2.371669769800762

Epoch: 6| Step: 13
Training loss: 0.1649582004523298
Validation loss: 2.37752360671649

Epoch: 499| Step: 0
Training loss: 0.10281983037806156
Validation loss: 2.3967356719180466

Epoch: 6| Step: 1
Training loss: 0.26228203579828
Validation loss: 2.3752830274123204

Epoch: 6| Step: 2
Training loss: 0.14408341179458192
Validation loss: 2.3881127389258685

Epoch: 6| Step: 3
Training loss: 0.13383807377487839
Validation loss: 2.346214438230151

Epoch: 6| Step: 4
Training loss: 0.24133969164069688
Validation loss: 2.338267693287862

Epoch: 6| Step: 5
Training loss: 0.15350537763372318
Validation loss: 2.338870926854284

Epoch: 6| Step: 6
Training loss: 0.2340857946724353
Validation loss: 2.3480872108338806

Epoch: 6| Step: 7
Training loss: 0.2619769971592122
Validation loss: 2.361501587081875

Epoch: 6| Step: 8
Training loss: 0.2187895739044876
Validation loss: 2.360957464092455

Epoch: 6| Step: 9
Training loss: 0.16851515941882733
Validation loss: 2.3595338825095724

Epoch: 6| Step: 10
Training loss: 0.2198392875587215
Validation loss: 2.324664942715367

Epoch: 6| Step: 11
Training loss: 0.23405460870221262
Validation loss: 2.3429278478797166

Epoch: 6| Step: 12
Training loss: 0.1603971565187627
Validation loss: 2.342538426668979

Epoch: 6| Step: 13
Training loss: 0.1545285646265058
Validation loss: 2.3618694620525815

Epoch: 500| Step: 0
Training loss: 0.1611951476235712
Validation loss: 2.3891649457148154

Epoch: 6| Step: 1
Training loss: 0.19958255311405954
Validation loss: 2.3980898655787253

Epoch: 6| Step: 2
Training loss: 0.24483294172842113
Validation loss: 2.423810787934995

Epoch: 6| Step: 3
Training loss: 0.19093570480501698
Validation loss: 2.4118503335309525

Epoch: 6| Step: 4
Training loss: 0.16613425336042972
Validation loss: 2.406194112251472

Epoch: 6| Step: 5
Training loss: 0.37797626927857353
Validation loss: 2.417804219206843

Epoch: 6| Step: 6
Training loss: 0.31152194270908395
Validation loss: 2.383664909576156

Epoch: 6| Step: 7
Training loss: 0.11371471246751946
Validation loss: 2.3784159288680082

Epoch: 6| Step: 8
Training loss: 0.18547320660231711
Validation loss: 2.31511301311899

Epoch: 6| Step: 9
Training loss: 0.2927452251947303
Validation loss: 2.3076178929513045

Epoch: 6| Step: 10
Training loss: 0.4568180826064959
Validation loss: 2.272963560412097

Epoch: 6| Step: 11
Training loss: 0.28924149049277675
Validation loss: 2.295763443394708

Epoch: 6| Step: 12
Training loss: 0.1840873332992859
Validation loss: 2.3202374572098443

Epoch: 6| Step: 13
Training loss: 0.08495270754974865
Validation loss: 2.33560851266175

Epoch: 501| Step: 0
Training loss: 0.1834046627852813
Validation loss: 2.3618781902390884

Epoch: 6| Step: 1
Training loss: 0.26108354376175535
Validation loss: 2.3831751388278466

Epoch: 6| Step: 2
Training loss: 0.29846895361713555
Validation loss: 2.4061407153111785

Epoch: 6| Step: 3
Training loss: 0.24622913451312495
Validation loss: 2.4048402276465595

Epoch: 6| Step: 4
Training loss: 0.16695009225242707
Validation loss: 2.3891420665044634

Epoch: 6| Step: 5
Training loss: 0.18940923123325668
Validation loss: 2.3667906559129204

Epoch: 6| Step: 6
Training loss: 0.1861391252565995
Validation loss: 2.334211602436259

Epoch: 6| Step: 7
Training loss: 0.1390548374443761
Validation loss: 2.336519650654222

Epoch: 6| Step: 8
Training loss: 0.10072443047914242
Validation loss: 2.3310790243410815

Epoch: 6| Step: 9
Training loss: 0.1890298302853017
Validation loss: 2.3000959771472105

Epoch: 6| Step: 10
Training loss: 0.2150849808702869
Validation loss: 2.290087713231228

Epoch: 6| Step: 11
Training loss: 0.3005262383757818
Validation loss: 2.3035110738658817

Epoch: 6| Step: 12
Training loss: 0.2862978774847804
Validation loss: 2.3317150321307674

Epoch: 6| Step: 13
Training loss: 0.2800438103078483
Validation loss: 2.3479950895288675

Epoch: 502| Step: 0
Training loss: 0.1767099853217433
Validation loss: 2.3415847434968073

Epoch: 6| Step: 1
Training loss: 0.10120101936061594
Validation loss: 2.3792806405151574

Epoch: 6| Step: 2
Training loss: 0.22135877697949286
Validation loss: 2.333512342928605

Epoch: 6| Step: 3
Training loss: 0.14816648437548144
Validation loss: 2.353439102287011

Epoch: 6| Step: 4
Training loss: 0.26072382773006786
Validation loss: 2.3278840254053104

Epoch: 6| Step: 5
Training loss: 0.1536318535560226
Validation loss: 2.339367220333576

Epoch: 6| Step: 6
Training loss: 0.18975132156057606
Validation loss: 2.3351653227527276

Epoch: 6| Step: 7
Training loss: 0.1304365201076117
Validation loss: 2.35613732850713

Epoch: 6| Step: 8
Training loss: 0.14497787185474828
Validation loss: 2.3293793635558857

Epoch: 6| Step: 9
Training loss: 0.2075648718275989
Validation loss: 2.350091793385644

Epoch: 6| Step: 10
Training loss: 0.1381066920480241
Validation loss: 2.361656022414287

Epoch: 6| Step: 11
Training loss: 0.18955200603704556
Validation loss: 2.3681283231388925

Epoch: 6| Step: 12
Training loss: 0.31743065106716334
Validation loss: 2.405885806021566

Epoch: 6| Step: 13
Training loss: 0.22041378635160283
Validation loss: 2.4164834161671873

Epoch: 503| Step: 0
Training loss: 0.17009496094726242
Validation loss: 2.3571673167445484

Epoch: 6| Step: 1
Training loss: 0.16448014891304785
Validation loss: 2.384635120908804

Epoch: 6| Step: 2
Training loss: 0.1399538528433678
Validation loss: 2.357496492642958

Epoch: 6| Step: 3
Training loss: 0.21914392152642514
Validation loss: 2.3957349477918095

Epoch: 6| Step: 4
Training loss: 0.1811761557668376
Validation loss: 2.36809230176858

Epoch: 6| Step: 5
Training loss: 0.3104510609349219
Validation loss: 2.380096865558165

Epoch: 6| Step: 6
Training loss: 0.19487287635575923
Validation loss: 2.38656513674469

Epoch: 6| Step: 7
Training loss: 0.14988712767870593
Validation loss: 2.3595540840449467

Epoch: 6| Step: 8
Training loss: 0.21433485622838921
Validation loss: 2.3802246215619145

Epoch: 6| Step: 9
Training loss: 0.13576327647222533
Validation loss: 2.3837702324105936

Epoch: 6| Step: 10
Training loss: 0.15560645254328567
Validation loss: 2.3739072361458082

Epoch: 6| Step: 11
Training loss: 0.18252696904375765
Validation loss: 2.374269742369209

Epoch: 6| Step: 12
Training loss: 0.1521381678316702
Validation loss: 2.3667557082034856

Epoch: 6| Step: 13
Training loss: 0.09732245619538803
Validation loss: 2.3904655441433276

Epoch: 504| Step: 0
Training loss: 0.1692937884293632
Validation loss: 2.3759514673581856

Epoch: 6| Step: 1
Training loss: 0.2764203994260496
Validation loss: 2.4032534471218776

Epoch: 6| Step: 2
Training loss: 0.07290376679663148
Validation loss: 2.400994080398128

Epoch: 6| Step: 3
Training loss: 0.2236378431795487
Validation loss: 2.4232398155377726

Epoch: 6| Step: 4
Training loss: 0.16306295632722168
Validation loss: 2.4196000565230773

Epoch: 6| Step: 5
Training loss: 0.2435849771271792
Validation loss: 2.425587786214521

Epoch: 6| Step: 6
Training loss: 0.17435118384409248
Validation loss: 2.4127657456243394

Epoch: 6| Step: 7
Training loss: 0.15819579566649308
Validation loss: 2.4214263563979714

Epoch: 6| Step: 8
Training loss: 0.1942591107967707
Validation loss: 2.3992508541966115

Epoch: 6| Step: 9
Training loss: 0.16784977025741307
Validation loss: 2.3945141692170386

Epoch: 6| Step: 10
Training loss: 0.17440236000024903
Validation loss: 2.3704325263222734

Epoch: 6| Step: 11
Training loss: 0.1428320987283429
Validation loss: 2.3692215406888977

Epoch: 6| Step: 12
Training loss: 0.22326752759971893
Validation loss: 2.3823778444264496

Epoch: 6| Step: 13
Training loss: 0.11713470620824291
Validation loss: 2.3642522390264435

Epoch: 505| Step: 0
Training loss: 0.11158814932784997
Validation loss: 2.339042703812731

Epoch: 6| Step: 1
Training loss: 0.33282810407423313
Validation loss: 2.2874909699600954

Epoch: 6| Step: 2
Training loss: 0.18150281292729623
Validation loss: 2.3000976414929735

Epoch: 6| Step: 3
Training loss: 0.16321415343943302
Validation loss: 2.307630274419796

Epoch: 6| Step: 4
Training loss: 0.2729128026810079
Validation loss: 2.325016622211564

Epoch: 6| Step: 5
Training loss: 0.20752676558506927
Validation loss: 2.3324937981967544

Epoch: 6| Step: 6
Training loss: 0.14371687621495785
Validation loss: 2.343574682535543

Epoch: 6| Step: 7
Training loss: 0.11532012529153167
Validation loss: 2.3562701954284457

Epoch: 6| Step: 8
Training loss: 0.3375983876294067
Validation loss: 2.3804243854103126

Epoch: 6| Step: 9
Training loss: 0.15744872420349218
Validation loss: 2.374504640016824

Epoch: 6| Step: 10
Training loss: 0.2046278324228278
Validation loss: 2.4136446830090446

Epoch: 6| Step: 11
Training loss: 0.2203953546600043
Validation loss: 2.4504492260172688

Epoch: 6| Step: 12
Training loss: 0.12421399593252878
Validation loss: 2.4194730080352453

Epoch: 6| Step: 13
Training loss: 0.21116627543565455
Validation loss: 2.3839927919972856

Epoch: 506| Step: 0
Training loss: 0.10383889266612005
Validation loss: 2.3744789851678756

Epoch: 6| Step: 1
Training loss: 0.14323221694703792
Validation loss: 2.325534019400219

Epoch: 6| Step: 2
Training loss: 0.15530759207840186
Validation loss: 2.3349833902092048

Epoch: 6| Step: 3
Training loss: 0.20330029039986092
Validation loss: 2.29639164142316

Epoch: 6| Step: 4
Training loss: 0.21017440767090168
Validation loss: 2.3178051683015344

Epoch: 6| Step: 5
Training loss: 0.14768825466723548
Validation loss: 2.32304382711923

Epoch: 6| Step: 6
Training loss: 0.15467889790747927
Validation loss: 2.318010703468174

Epoch: 6| Step: 7
Training loss: 0.24023707318535267
Validation loss: 2.3098732114957397

Epoch: 6| Step: 8
Training loss: 0.2542521687952449
Validation loss: 2.323164846379547

Epoch: 6| Step: 9
Training loss: 0.13691388917876632
Validation loss: 2.3314055076021574

Epoch: 6| Step: 10
Training loss: 0.20674415691749343
Validation loss: 2.3501977781233476

Epoch: 6| Step: 11
Training loss: 0.18646313156759514
Validation loss: 2.3482989066889433

Epoch: 6| Step: 12
Training loss: 0.13964474946600708
Validation loss: 2.347248860977203

Epoch: 6| Step: 13
Training loss: 0.07298170819082757
Validation loss: 2.362224549604372

Epoch: 507| Step: 0
Training loss: 0.2099164516428439
Validation loss: 2.3359696119933235

Epoch: 6| Step: 1
Training loss: 0.2397974429331068
Validation loss: 2.341075892658831

Epoch: 6| Step: 2
Training loss: 0.10221659499870345
Validation loss: 2.364468782667994

Epoch: 6| Step: 3
Training loss: 0.12158705612890655
Validation loss: 2.3450483525599473

Epoch: 6| Step: 4
Training loss: 0.21057897581361795
Validation loss: 2.369040177731279

Epoch: 6| Step: 5
Training loss: 0.11498421655284499
Validation loss: 2.36525955783603

Epoch: 6| Step: 6
Training loss: 0.24472907294152538
Validation loss: 2.3740220790210604

Epoch: 6| Step: 7
Training loss: 0.1079303239299001
Validation loss: 2.371328539543511

Epoch: 6| Step: 8
Training loss: 0.16125634977495
Validation loss: 2.3768523844695006

Epoch: 6| Step: 9
Training loss: 0.2534859626709482
Validation loss: 2.389477384570715

Epoch: 6| Step: 10
Training loss: 0.13116207981400407
Validation loss: 2.4008824465136254

Epoch: 6| Step: 11
Training loss: 0.16650313995274488
Validation loss: 2.4145160443735474

Epoch: 6| Step: 12
Training loss: 0.13680969347064
Validation loss: 2.4027562576026673

Epoch: 6| Step: 13
Training loss: 0.1536020254193445
Validation loss: 2.411470615743098

Epoch: 508| Step: 0
Training loss: 0.1519349678194166
Validation loss: 2.4159602714144532

Epoch: 6| Step: 1
Training loss: 0.16636574794041675
Validation loss: 2.395060816946249

Epoch: 6| Step: 2
Training loss: 0.238943415009537
Validation loss: 2.440524418615058

Epoch: 6| Step: 3
Training loss: 0.26075215981376226
Validation loss: 2.414307691196356

Epoch: 6| Step: 4
Training loss: 0.1466510015747895
Validation loss: 2.417687609412483

Epoch: 6| Step: 5
Training loss: 0.22620294255426301
Validation loss: 2.393644462063938

Epoch: 6| Step: 6
Training loss: 0.1672480892306033
Validation loss: 2.389728504319386

Epoch: 6| Step: 7
Training loss: 0.13933748023545559
Validation loss: 2.352658061658136

Epoch: 6| Step: 8
Training loss: 0.1637959187767285
Validation loss: 2.3524863297047394

Epoch: 6| Step: 9
Training loss: 0.21380570803941043
Validation loss: 2.3157077105345403

Epoch: 6| Step: 10
Training loss: 0.21979251295683103
Validation loss: 2.3174785572472456

Epoch: 6| Step: 11
Training loss: 0.25033609329074497
Validation loss: 2.3343195980621996

Epoch: 6| Step: 12
Training loss: 0.19497042263516207
Validation loss: 2.341303709673201

Epoch: 6| Step: 13
Training loss: 0.04314106019780495
Validation loss: 2.386664421884153

Epoch: 509| Step: 0
Training loss: 0.20140340129770187
Validation loss: 2.364552579564755

Epoch: 6| Step: 1
Training loss: 0.12858327227302793
Validation loss: 2.3510157081246486

Epoch: 6| Step: 2
Training loss: 0.19877311005378148
Validation loss: 2.3952065884402396

Epoch: 6| Step: 3
Training loss: 0.2280734258644452
Validation loss: 2.3992429161697255

Epoch: 6| Step: 4
Training loss: 0.2253642127893051
Validation loss: 2.389320108021366

Epoch: 6| Step: 5
Training loss: 0.25385797481839845
Validation loss: 2.4057934235588414

Epoch: 6| Step: 6
Training loss: 0.105832439775368
Validation loss: 2.384051568073712

Epoch: 6| Step: 7
Training loss: 0.16885440784235523
Validation loss: 2.3967095809877654

Epoch: 6| Step: 8
Training loss: 0.28755042525379226
Validation loss: 2.431863283875957

Epoch: 6| Step: 9
Training loss: 0.21620773478464536
Validation loss: 2.394911449493571

Epoch: 6| Step: 10
Training loss: 0.20598224975674817
Validation loss: 2.386869282096766

Epoch: 6| Step: 11
Training loss: 0.1414891553183916
Validation loss: 2.382767378959664

Epoch: 6| Step: 12
Training loss: 0.12137766594861234
Validation loss: 2.373671865187265

Epoch: 6| Step: 13
Training loss: 0.12902802437538127
Validation loss: 2.382335891814247

Epoch: 510| Step: 0
Training loss: 0.12394798040899983
Validation loss: 2.366144361522578

Epoch: 6| Step: 1
Training loss: 0.1685774883880885
Validation loss: 2.3863626748228555

Epoch: 6| Step: 2
Training loss: 0.25336690987373006
Validation loss: 2.369022995940873

Epoch: 6| Step: 3
Training loss: 0.1743047854613162
Validation loss: 2.3534306813088053

Epoch: 6| Step: 4
Training loss: 0.0760975621931087
Validation loss: 2.3429084037968906

Epoch: 6| Step: 5
Training loss: 0.16018653211178427
Validation loss: 2.334178356969316

Epoch: 6| Step: 6
Training loss: 0.1306729269513349
Validation loss: 2.3394888345517137

Epoch: 6| Step: 7
Training loss: 0.20082837008309418
Validation loss: 2.3313256733305443

Epoch: 6| Step: 8
Training loss: 0.12227426656829854
Validation loss: 2.313496199094474

Epoch: 6| Step: 9
Training loss: 0.1389577564890478
Validation loss: 2.3206550922797264

Epoch: 6| Step: 10
Training loss: 0.1975830281751484
Validation loss: 2.321779524487912

Epoch: 6| Step: 11
Training loss: 0.14808959721958811
Validation loss: 2.35705861032197

Epoch: 6| Step: 12
Training loss: 0.24157844377337157
Validation loss: 2.331123183912666

Epoch: 6| Step: 13
Training loss: 0.1396736108992309
Validation loss: 2.329076261686733

Epoch: 511| Step: 0
Training loss: 0.1734404473440942
Validation loss: 2.3501647811592092

Epoch: 6| Step: 1
Training loss: 0.25032767041510756
Validation loss: 2.3848032650111963

Epoch: 6| Step: 2
Training loss: 0.24064093202633652
Validation loss: 2.3885545874270324

Epoch: 6| Step: 3
Training loss: 0.228523604750894
Validation loss: 2.3813117998560616

Epoch: 6| Step: 4
Training loss: 0.24427342427038015
Validation loss: 2.382021216944476

Epoch: 6| Step: 5
Training loss: 0.11959965017266168
Validation loss: 2.353389059088094

Epoch: 6| Step: 6
Training loss: 0.1525845702763742
Validation loss: 2.344692370558057

Epoch: 6| Step: 7
Training loss: 0.14937531211852342
Validation loss: 2.357465284482953

Epoch: 6| Step: 8
Training loss: 0.1632428699085717
Validation loss: 2.3580472706760083

Epoch: 6| Step: 9
Training loss: 0.14582385233872677
Validation loss: 2.341801759690345

Epoch: 6| Step: 10
Training loss: 0.2118939245121958
Validation loss: 2.3329539107717343

Epoch: 6| Step: 11
Training loss: 0.15495471512014286
Validation loss: 2.3424348112192748

Epoch: 6| Step: 12
Training loss: 0.22496806818819964
Validation loss: 2.3153507893940257

Epoch: 6| Step: 13
Training loss: 0.2917127516078228
Validation loss: 2.36044462650984

Epoch: 512| Step: 0
Training loss: 0.17497576435048612
Validation loss: 2.378298677175475

Epoch: 6| Step: 1
Training loss: 0.13216249499987096
Validation loss: 2.3630699307989973

Epoch: 6| Step: 2
Training loss: 0.10681613149239669
Validation loss: 2.3892536341164474

Epoch: 6| Step: 3
Training loss: 0.21007004497817053
Validation loss: 2.4104698988761646

Epoch: 6| Step: 4
Training loss: 0.22778483039626324
Validation loss: 2.399749996916371

Epoch: 6| Step: 5
Training loss: 0.17166996235041102
Validation loss: 2.40567189764506

Epoch: 6| Step: 6
Training loss: 0.2351373829671029
Validation loss: 2.4024307151198436

Epoch: 6| Step: 7
Training loss: 0.14671565553288282
Validation loss: 2.4164641379957255

Epoch: 6| Step: 8
Training loss: 0.22783303814472153
Validation loss: 2.3883175658790887

Epoch: 6| Step: 9
Training loss: 0.16392285784684074
Validation loss: 2.378737933704677

Epoch: 6| Step: 10
Training loss: 0.16280633405845588
Validation loss: 2.3821398585338134

Epoch: 6| Step: 11
Training loss: 0.13302030854755184
Validation loss: 2.3476609161113817

Epoch: 6| Step: 12
Training loss: 0.22495443955721162
Validation loss: 2.339331983487862

Epoch: 6| Step: 13
Training loss: 0.3164688684171913
Validation loss: 2.365884554493141

Epoch: 513| Step: 0
Training loss: 0.27536731648385965
Validation loss: 2.3419196273976883

Epoch: 6| Step: 1
Training loss: 0.1954529352750596
Validation loss: 2.352115328324537

Epoch: 6| Step: 2
Training loss: 0.1090981735334146
Validation loss: 2.340510126759908

Epoch: 6| Step: 3
Training loss: 0.17854630855578277
Validation loss: 2.3576794253647857

Epoch: 6| Step: 4
Training loss: 0.2530933866657212
Validation loss: 2.365526715239849

Epoch: 6| Step: 5
Training loss: 0.14254602959359286
Validation loss: 2.3571702608592138

Epoch: 6| Step: 6
Training loss: 0.11146024343229449
Validation loss: 2.3549956247873296

Epoch: 6| Step: 7
Training loss: 0.2876542947175368
Validation loss: 2.325996234489915

Epoch: 6| Step: 8
Training loss: 0.14626543849985746
Validation loss: 2.3192146996512157

Epoch: 6| Step: 9
Training loss: 0.19386048358591962
Validation loss: 2.3407007016640184

Epoch: 6| Step: 10
Training loss: 0.22075854930544803
Validation loss: 2.294493888022238

Epoch: 6| Step: 11
Training loss: 0.18471781573820042
Validation loss: 2.313671251129159

Epoch: 6| Step: 12
Training loss: 0.1332718325191302
Validation loss: 2.3201555547237325

Epoch: 6| Step: 13
Training loss: 0.23147969855619732
Validation loss: 2.3457615140427106

Epoch: 514| Step: 0
Training loss: 0.16418778653876748
Validation loss: 2.345833236062522

Epoch: 6| Step: 1
Training loss: 0.22431749369349802
Validation loss: 2.3623808714905095

Epoch: 6| Step: 2
Training loss: 0.199563868163425
Validation loss: 2.380189445117108

Epoch: 6| Step: 3
Training loss: 0.1950324243859493
Validation loss: 2.407539234315543

Epoch: 6| Step: 4
Training loss: 0.1972093501884535
Validation loss: 2.3942926583050723

Epoch: 6| Step: 5
Training loss: 0.1126140149186003
Validation loss: 2.421427434186515

Epoch: 6| Step: 6
Training loss: 0.08869297116933395
Validation loss: 2.4439764319032147

Epoch: 6| Step: 7
Training loss: 0.15762056420359635
Validation loss: 2.4397439180634146

Epoch: 6| Step: 8
Training loss: 0.14171102173624658
Validation loss: 2.417281366133537

Epoch: 6| Step: 9
Training loss: 0.14836664767566593
Validation loss: 2.4276649094840232

Epoch: 6| Step: 10
Training loss: 0.16022666685701847
Validation loss: 2.393012666566613

Epoch: 6| Step: 11
Training loss: 0.123751078442007
Validation loss: 2.4291726698455003

Epoch: 6| Step: 12
Training loss: 0.18478799527258083
Validation loss: 2.3941487414626224

Epoch: 6| Step: 13
Training loss: 0.13353050614401338
Validation loss: 2.376021005434268

Epoch: 515| Step: 0
Training loss: 0.12126974421915752
Validation loss: 2.3668646050553135

Epoch: 6| Step: 1
Training loss: 0.1014459518967706
Validation loss: 2.3464856267944474

Epoch: 6| Step: 2
Training loss: 0.2142098525277313
Validation loss: 2.317316567822416

Epoch: 6| Step: 3
Training loss: 0.17427138273361928
Validation loss: 2.296128337556209

Epoch: 6| Step: 4
Training loss: 0.2625646017826318
Validation loss: 2.3133821068826785

Epoch: 6| Step: 5
Training loss: 0.19070096378437937
Validation loss: 2.2983510242503415

Epoch: 6| Step: 6
Training loss: 0.11829646235696223
Validation loss: 2.3151835939850347

Epoch: 6| Step: 7
Training loss: 0.11140570530751574
Validation loss: 2.322706851416512

Epoch: 6| Step: 8
Training loss: 0.16857766517507855
Validation loss: 2.3055498176058857

Epoch: 6| Step: 9
Training loss: 0.0868094489760928
Validation loss: 2.361725933640195

Epoch: 6| Step: 10
Training loss: 0.06458562900067623
Validation loss: 2.367435759755568

Epoch: 6| Step: 11
Training loss: 0.22020866909801493
Validation loss: 2.3724337553255515

Epoch: 6| Step: 12
Training loss: 0.08720424515223983
Validation loss: 2.3915009657470025

Epoch: 6| Step: 13
Training loss: 0.1327183473867009
Validation loss: 2.3722612968621437

Epoch: 516| Step: 0
Training loss: 0.1206507038120233
Validation loss: 2.372360738381205

Epoch: 6| Step: 1
Training loss: 0.24273074657821048
Validation loss: 2.394349389183716

Epoch: 6| Step: 2
Training loss: 0.17838885775029278
Validation loss: 2.3961992941088788

Epoch: 6| Step: 3
Training loss: 0.14876187795009427
Validation loss: 2.3947244532865186

Epoch: 6| Step: 4
Training loss: 0.15483194841281187
Validation loss: 2.371726580259318

Epoch: 6| Step: 5
Training loss: 0.0841030956204759
Validation loss: 2.3559841386061358

Epoch: 6| Step: 6
Training loss: 0.10561391765251632
Validation loss: 2.3898674707511

Epoch: 6| Step: 7
Training loss: 0.233921152021129
Validation loss: 2.3636972851535325

Epoch: 6| Step: 8
Training loss: 0.07883730652478298
Validation loss: 2.37316854355684

Epoch: 6| Step: 9
Training loss: 0.1709081755997152
Validation loss: 2.3650899494978974

Epoch: 6| Step: 10
Training loss: 0.15029579739948218
Validation loss: 2.3430702793461338

Epoch: 6| Step: 11
Training loss: 0.2480219730883454
Validation loss: 2.353793440699528

Epoch: 6| Step: 12
Training loss: 0.14487178738943035
Validation loss: 2.3664322603406416

Epoch: 6| Step: 13
Training loss: 0.1282089548569583
Validation loss: 2.351168921346119

Epoch: 517| Step: 0
Training loss: 0.14882472627618765
Validation loss: 2.352005191607504

Epoch: 6| Step: 1
Training loss: 0.1352768200355864
Validation loss: 2.369685458931858

Epoch: 6| Step: 2
Training loss: 0.1979826369680074
Validation loss: 2.3834047632795583

Epoch: 6| Step: 3
Training loss: 0.19031098407461067
Validation loss: 2.3720853955499295

Epoch: 6| Step: 4
Training loss: 0.15951357968738247
Validation loss: 2.356197742779092

Epoch: 6| Step: 5
Training loss: 0.1741764832018184
Validation loss: 2.391569631496842

Epoch: 6| Step: 6
Training loss: 0.20444393189766663
Validation loss: 2.3574158655977975

Epoch: 6| Step: 7
Training loss: 0.2013293918100513
Validation loss: 2.3860159672508505

Epoch: 6| Step: 8
Training loss: 0.144504248184568
Validation loss: 2.374477331121305

Epoch: 6| Step: 9
Training loss: 0.2293347569485445
Validation loss: 2.390652866510759

Epoch: 6| Step: 10
Training loss: 0.2361614254132864
Validation loss: 2.3863175972752586

Epoch: 6| Step: 11
Training loss: 0.1911287436957548
Validation loss: 2.380377081279518

Epoch: 6| Step: 12
Training loss: 0.18573133434914138
Validation loss: 2.3946934155474193

Epoch: 6| Step: 13
Training loss: 0.11489098511712963
Validation loss: 2.379432193197124

Epoch: 518| Step: 0
Training loss: 0.23021213339924357
Validation loss: 2.3874230482648593

Epoch: 6| Step: 1
Training loss: 0.1700795253490997
Validation loss: 2.3296421610937794

Epoch: 6| Step: 2
Training loss: 0.16776888067343212
Validation loss: 2.368636716616066

Epoch: 6| Step: 3
Training loss: 0.12716332420242135
Validation loss: 2.351588065814108

Epoch: 6| Step: 4
Training loss: 0.2481161831723411
Validation loss: 2.3595440586747007

Epoch: 6| Step: 5
Training loss: 0.1707106675897477
Validation loss: 2.35445613172268

Epoch: 6| Step: 6
Training loss: 0.19605295965265954
Validation loss: 2.344745825315507

Epoch: 6| Step: 7
Training loss: 0.11288502062181612
Validation loss: 2.331980371974014

Epoch: 6| Step: 8
Training loss: 0.10828466716895488
Validation loss: 2.3776544181195516

Epoch: 6| Step: 9
Training loss: 0.21334620384480305
Validation loss: 2.3357311024114633

Epoch: 6| Step: 10
Training loss: 0.12152068953808333
Validation loss: 2.3355030925257805

Epoch: 6| Step: 11
Training loss: 0.1748389471568831
Validation loss: 2.3290672650052806

Epoch: 6| Step: 12
Training loss: 0.1927965044097962
Validation loss: 2.2974454118316747

Epoch: 6| Step: 13
Training loss: 0.13005257747980464
Validation loss: 2.3084534846999984

Epoch: 519| Step: 0
Training loss: 0.19385193212295043
Validation loss: 2.301534372792511

Epoch: 6| Step: 1
Training loss: 0.19738232588203156
Validation loss: 2.3524122435247246

Epoch: 6| Step: 2
Training loss: 0.14286901246938766
Validation loss: 2.3511639443536283

Epoch: 6| Step: 3
Training loss: 0.277893354623948
Validation loss: 2.3827684753105833

Epoch: 6| Step: 4
Training loss: 0.15009058089944352
Validation loss: 2.4291999437711675

Epoch: 6| Step: 5
Training loss: 0.21671035689842033
Validation loss: 2.4622463805100288

Epoch: 6| Step: 6
Training loss: 0.149957100127782
Validation loss: 2.468077274266347

Epoch: 6| Step: 7
Training loss: 0.09094925924840182
Validation loss: 2.435161585856583

Epoch: 6| Step: 8
Training loss: 0.3308284177563105
Validation loss: 2.4852048025073588

Epoch: 6| Step: 9
Training loss: 0.17742948266352165
Validation loss: 2.4637022344418638

Epoch: 6| Step: 10
Training loss: 0.21274145832520266
Validation loss: 2.4596126450701323

Epoch: 6| Step: 11
Training loss: 0.15576485179273372
Validation loss: 2.4317507635908684

Epoch: 6| Step: 12
Training loss: 0.15302653017296416
Validation loss: 2.4045916056173837

Epoch: 6| Step: 13
Training loss: 0.18035635647878834
Validation loss: 2.406612712497451

Epoch: 520| Step: 0
Training loss: 0.24698115613616892
Validation loss: 2.383239806761303

Epoch: 6| Step: 1
Training loss: 0.15981057707517723
Validation loss: 2.4056520053248223

Epoch: 6| Step: 2
Training loss: 0.08513252426494945
Validation loss: 2.392454589976174

Epoch: 6| Step: 3
Training loss: 0.27871945855334723
Validation loss: 2.4111269837481046

Epoch: 6| Step: 4
Training loss: 0.20892630866680348
Validation loss: 2.4018487748024

Epoch: 6| Step: 5
Training loss: 0.21380353877555278
Validation loss: 2.3919109446405447

Epoch: 6| Step: 6
Training loss: 0.15864772488883022
Validation loss: 2.3797514729159825

Epoch: 6| Step: 7
Training loss: 0.0979788316135868
Validation loss: 2.371067419245659

Epoch: 6| Step: 8
Training loss: 0.2216510754240353
Validation loss: 2.3413844710993366

Epoch: 6| Step: 9
Training loss: 0.1835934963630385
Validation loss: 2.3248974906630937

Epoch: 6| Step: 10
Training loss: 0.29595936566534015
Validation loss: 2.2872088702903612

Epoch: 6| Step: 11
Training loss: 0.2874632749735901
Validation loss: 2.2948524075346715

Epoch: 6| Step: 12
Training loss: 0.24558509757345937
Validation loss: 2.296544836279783

Epoch: 6| Step: 13
Training loss: 0.1491800857302896
Validation loss: 2.272733634015053

Epoch: 521| Step: 0
Training loss: 0.138136326554164
Validation loss: 2.2841060401927833

Epoch: 6| Step: 1
Training loss: 0.1993319806710355
Validation loss: 2.282382440709073

Epoch: 6| Step: 2
Training loss: 0.3122780727093903
Validation loss: 2.3338727499672167

Epoch: 6| Step: 3
Training loss: 0.1541728535315007
Validation loss: 2.3504927078316387

Epoch: 6| Step: 4
Training loss: 0.19620834892641748
Validation loss: 2.3115650061681445

Epoch: 6| Step: 5
Training loss: 0.14402281410034773
Validation loss: 2.3143147667566377

Epoch: 6| Step: 6
Training loss: 0.18287873535422042
Validation loss: 2.308158082581751

Epoch: 6| Step: 7
Training loss: 0.12292043305003816
Validation loss: 2.3211132468933693

Epoch: 6| Step: 8
Training loss: 0.1240155037272205
Validation loss: 2.3336135685720842

Epoch: 6| Step: 9
Training loss: 0.18658984335325296
Validation loss: 2.334057388677354

Epoch: 6| Step: 10
Training loss: 0.15363115035767277
Validation loss: 2.3672513825582326

Epoch: 6| Step: 11
Training loss: 0.176489024993916
Validation loss: 2.3668043807416144

Epoch: 6| Step: 12
Training loss: 0.24282173204238722
Validation loss: 2.350030398515862

Epoch: 6| Step: 13
Training loss: 0.16698578493214278
Validation loss: 2.3632332894836745

Epoch: 522| Step: 0
Training loss: 0.11590869853641571
Validation loss: 2.3935890018736683

Epoch: 6| Step: 1
Training loss: 0.21522984923989083
Validation loss: 2.4120637062096755

Epoch: 6| Step: 2
Training loss: 0.23600211395563536
Validation loss: 2.4164005538964375

Epoch: 6| Step: 3
Training loss: 0.19321659866411223
Validation loss: 2.377977695786091

Epoch: 6| Step: 4
Training loss: 0.14725129591544828
Validation loss: 2.359990547679884

Epoch: 6| Step: 5
Training loss: 0.18949508202393925
Validation loss: 2.38466161361819

Epoch: 6| Step: 6
Training loss: 0.13572345576954542
Validation loss: 2.3536205770948224

Epoch: 6| Step: 7
Training loss: 0.13876584052829521
Validation loss: 2.339772339081293

Epoch: 6| Step: 8
Training loss: 0.13399673966499892
Validation loss: 2.3574097430821515

Epoch: 6| Step: 9
Training loss: 0.10184005719460597
Validation loss: 2.3191557334404687

Epoch: 6| Step: 10
Training loss: 0.1931643899696899
Validation loss: 2.318113106453476

Epoch: 6| Step: 11
Training loss: 0.15778112642574627
Validation loss: 2.2922638768455474

Epoch: 6| Step: 12
Training loss: 0.26528354745158295
Validation loss: 2.288712385119455

Epoch: 6| Step: 13
Training loss: 0.1975323695956889
Validation loss: 2.3163246680365717

Epoch: 523| Step: 0
Training loss: 0.17075894793876303
Validation loss: 2.299008316652028

Epoch: 6| Step: 1
Training loss: 0.16012389158539764
Validation loss: 2.312930826099342

Epoch: 6| Step: 2
Training loss: 0.1083889089297005
Validation loss: 2.326282321197372

Epoch: 6| Step: 3
Training loss: 0.11358728259879056
Validation loss: 2.315237489766172

Epoch: 6| Step: 4
Training loss: 0.22883581894181942
Validation loss: 2.3092056784043686

Epoch: 6| Step: 5
Training loss: 0.1979022941055448
Validation loss: 2.291747623329957

Epoch: 6| Step: 6
Training loss: 0.27241414533128827
Validation loss: 2.2839731069537192

Epoch: 6| Step: 7
Training loss: 0.13140552337980826
Validation loss: 2.3086049413617116

Epoch: 6| Step: 8
Training loss: 0.15976994142554077
Validation loss: 2.3023272331176443

Epoch: 6| Step: 9
Training loss: 0.09303914218162118
Validation loss: 2.315664793903727

Epoch: 6| Step: 10
Training loss: 0.11973971470442185
Validation loss: 2.3417754791808685

Epoch: 6| Step: 11
Training loss: 0.14154229074607644
Validation loss: 2.316628367078725

Epoch: 6| Step: 12
Training loss: 0.1837336331980326
Validation loss: 2.3302062530011747

Epoch: 6| Step: 13
Training loss: 0.12218941028496842
Validation loss: 2.3258179507408565

Epoch: 524| Step: 0
Training loss: 0.22841296376016487
Validation loss: 2.3270653229541964

Epoch: 6| Step: 1
Training loss: 0.171768513116922
Validation loss: 2.328340470734578

Epoch: 6| Step: 2
Training loss: 0.22736133133853564
Validation loss: 2.321166411896213

Epoch: 6| Step: 3
Training loss: 0.13294554105524828
Validation loss: 2.3079291353602267

Epoch: 6| Step: 4
Training loss: 0.09947342102907264
Validation loss: 2.323518254025585

Epoch: 6| Step: 5
Training loss: 0.19371612468035285
Validation loss: 2.3226767762419063

Epoch: 6| Step: 6
Training loss: 0.10218625909302667
Validation loss: 2.306353628046533

Epoch: 6| Step: 7
Training loss: 0.1068441461063171
Validation loss: 2.3185795015848423

Epoch: 6| Step: 8
Training loss: 0.1484347016924056
Validation loss: 2.329484343281402

Epoch: 6| Step: 9
Training loss: 0.13812835047399608
Validation loss: 2.341587733479606

Epoch: 6| Step: 10
Training loss: 0.11280026763155483
Validation loss: 2.338361085846565

Epoch: 6| Step: 11
Training loss: 0.13336519634232374
Validation loss: 2.402360260756052

Epoch: 6| Step: 12
Training loss: 0.1557277295568322
Validation loss: 2.341084953793266

Epoch: 6| Step: 13
Training loss: 0.17400905750942347
Validation loss: 2.3237147160336757

Epoch: 525| Step: 0
Training loss: 0.10672117062974842
Validation loss: 2.335449827428851

Epoch: 6| Step: 1
Training loss: 0.10468339805253073
Validation loss: 2.34644608945066

Epoch: 6| Step: 2
Training loss: 0.2278386382818081
Validation loss: 2.3176367512334757

Epoch: 6| Step: 3
Training loss: 0.08252440951673318
Validation loss: 2.3521282733853823

Epoch: 6| Step: 4
Training loss: 0.16287103073131706
Validation loss: 2.3461696109713555

Epoch: 6| Step: 5
Training loss: 0.19858410668539347
Validation loss: 2.355121730448332

Epoch: 6| Step: 6
Training loss: 0.12746646240166176
Validation loss: 2.311724956109755

Epoch: 6| Step: 7
Training loss: 0.15912579870473043
Validation loss: 2.342888888428264

Epoch: 6| Step: 8
Training loss: 0.12494522623194994
Validation loss: 2.337380364513864

Epoch: 6| Step: 9
Training loss: 0.12766150399535467
Validation loss: 2.324191357644305

Epoch: 6| Step: 10
Training loss: 0.13500955867923928
Validation loss: 2.3309830172219477

Epoch: 6| Step: 11
Training loss: 0.10389456575710576
Validation loss: 2.3294796473641917

Epoch: 6| Step: 12
Training loss: 0.23124049173602812
Validation loss: 2.360112373354333

Epoch: 6| Step: 13
Training loss: 0.09838409507840565
Validation loss: 2.32591428679106

Epoch: 526| Step: 0
Training loss: 0.11158861253380797
Validation loss: 2.3126946921346496

Epoch: 6| Step: 1
Training loss: 0.07126874503540702
Validation loss: 2.345945160216908

Epoch: 6| Step: 2
Training loss: 0.20555155467118427
Validation loss: 2.3304273275960155

Epoch: 6| Step: 3
Training loss: 0.1486360577142567
Validation loss: 2.3245276808592767

Epoch: 6| Step: 4
Training loss: 0.1819208096626435
Validation loss: 2.3145479591898988

Epoch: 6| Step: 5
Training loss: 0.24150536209327844
Validation loss: 2.329109952015531

Epoch: 6| Step: 6
Training loss: 0.06619815618655264
Validation loss: 2.288836846503519

Epoch: 6| Step: 7
Training loss: 0.12247045927127634
Validation loss: 2.3254631176884213

Epoch: 6| Step: 8
Training loss: 0.1092716478051353
Validation loss: 2.315339883089958

Epoch: 6| Step: 9
Training loss: 0.14248864749811493
Validation loss: 2.29430153992069

Epoch: 6| Step: 10
Training loss: 0.10024290478925192
Validation loss: 2.28775652074668

Epoch: 6| Step: 11
Training loss: 0.10143386507425876
Validation loss: 2.284068763321189

Epoch: 6| Step: 12
Training loss: 0.16771633566449032
Validation loss: 2.3073732961701183

Epoch: 6| Step: 13
Training loss: 0.06869852539474379
Validation loss: 2.323618115572768

Epoch: 527| Step: 0
Training loss: 0.22794689417518219
Validation loss: 2.332374358843109

Epoch: 6| Step: 1
Training loss: 0.15140713810537224
Validation loss: 2.3085184073370413

Epoch: 6| Step: 2
Training loss: 0.1612174649831599
Validation loss: 2.328256358203912

Epoch: 6| Step: 3
Training loss: 0.19189421093164166
Validation loss: 2.3335335604579024

Epoch: 6| Step: 4
Training loss: 0.26651435515655925
Validation loss: 2.3807186648515577

Epoch: 6| Step: 5
Training loss: 0.10326150074851552
Validation loss: 2.3600908918399326

Epoch: 6| Step: 6
Training loss: 0.08647664776924596
Validation loss: 2.3795730397496593

Epoch: 6| Step: 7
Training loss: 0.10319099265437091
Validation loss: 2.386644893987359

Epoch: 6| Step: 8
Training loss: 0.15659708573795225
Validation loss: 2.3605243491438244

Epoch: 6| Step: 9
Training loss: 0.1948945054923623
Validation loss: 2.386720442824598

Epoch: 6| Step: 10
Training loss: 0.13976712951575368
Validation loss: 2.3562140502868107

Epoch: 6| Step: 11
Training loss: 0.11716966095885296
Validation loss: 2.359483557870329

Epoch: 6| Step: 12
Training loss: 0.11573655411203665
Validation loss: 2.347663107750012

Epoch: 6| Step: 13
Training loss: 0.16959354315323918
Validation loss: 2.3619323970772

Epoch: 528| Step: 0
Training loss: 0.16801844460558552
Validation loss: 2.362981586514207

Epoch: 6| Step: 1
Training loss: 0.18872670389877488
Validation loss: 2.3345777775584002

Epoch: 6| Step: 2
Training loss: 0.1349958719620229
Validation loss: 2.3476862339446476

Epoch: 6| Step: 3
Training loss: 0.10320295039298616
Validation loss: 2.366723478817677

Epoch: 6| Step: 4
Training loss: 0.1541631457102856
Validation loss: 2.347938690823272

Epoch: 6| Step: 5
Training loss: 0.13844913404718448
Validation loss: 2.3369332240635834

Epoch: 6| Step: 6
Training loss: 0.1049786234848728
Validation loss: 2.34613707037957

Epoch: 6| Step: 7
Training loss: 0.26217078556894113
Validation loss: 2.354878124163431

Epoch: 6| Step: 8
Training loss: 0.22591631918010022
Validation loss: 2.3622372032227323

Epoch: 6| Step: 9
Training loss: 0.11529127025694068
Validation loss: 2.3450560553359825

Epoch: 6| Step: 10
Training loss: 0.0863606994543563
Validation loss: 2.329184232911876

Epoch: 6| Step: 11
Training loss: 0.0909493360485475
Validation loss: 2.304536922785479

Epoch: 6| Step: 12
Training loss: 0.10595108050674824
Validation loss: 2.3340393469085288

Epoch: 6| Step: 13
Training loss: 0.19401674558996856
Validation loss: 2.325247297632564

Epoch: 529| Step: 0
Training loss: 0.20073130427972471
Validation loss: 2.3347584086975757

Epoch: 6| Step: 1
Training loss: 0.11718000546968017
Validation loss: 2.290791517455651

Epoch: 6| Step: 2
Training loss: 0.1457458699297175
Validation loss: 2.2867046281197942

Epoch: 6| Step: 3
Training loss: 0.1709166326373612
Validation loss: 2.3068354349150746

Epoch: 6| Step: 4
Training loss: 0.14952497168169007
Validation loss: 2.3054599230224633

Epoch: 6| Step: 5
Training loss: 0.1069514682061861
Validation loss: 2.315504799745631

Epoch: 6| Step: 6
Training loss: 0.11906488543846659
Validation loss: 2.330073409925024

Epoch: 6| Step: 7
Training loss: 0.19411674675035706
Validation loss: 2.3157711777428243

Epoch: 6| Step: 8
Training loss: 0.14539283972134104
Validation loss: 2.336492837557451

Epoch: 6| Step: 9
Training loss: 0.20340755873701713
Validation loss: 2.34380328182787

Epoch: 6| Step: 10
Training loss: 0.21364527995352373
Validation loss: 2.3331360894730535

Epoch: 6| Step: 11
Training loss: 0.15069562155680855
Validation loss: 2.343630273967241

Epoch: 6| Step: 12
Training loss: 0.20624817897975298
Validation loss: 2.3331049153230707

Epoch: 6| Step: 13
Training loss: 0.15721888553050173
Validation loss: 2.336965356381631

Epoch: 530| Step: 0
Training loss: 0.13271351238871346
Validation loss: 2.3282919983020003

Epoch: 6| Step: 1
Training loss: 0.20115574522075103
Validation loss: 2.335151562370931

Epoch: 6| Step: 2
Training loss: 0.18914591076353474
Validation loss: 2.3527036816910685

Epoch: 6| Step: 3
Training loss: 0.15903228534624572
Validation loss: 2.3223346643469216

Epoch: 6| Step: 4
Training loss: 0.1501733523264317
Validation loss: 2.365449311432772

Epoch: 6| Step: 5
Training loss: 0.1430179266438612
Validation loss: 2.3718122603352714

Epoch: 6| Step: 6
Training loss: 0.15805047523746285
Validation loss: 2.366607831133792

Epoch: 6| Step: 7
Training loss: 0.13400843657261155
Validation loss: 2.3707019729363688

Epoch: 6| Step: 8
Training loss: 0.23557481426076643
Validation loss: 2.3690892226571916

Epoch: 6| Step: 9
Training loss: 0.20358422527151676
Validation loss: 2.385364310952863

Epoch: 6| Step: 10
Training loss: 0.19286627461653932
Validation loss: 2.3899548362212575

Epoch: 6| Step: 11
Training loss: 0.1440854801873347
Validation loss: 2.375813028218855

Epoch: 6| Step: 12
Training loss: 0.1225242718667759
Validation loss: 2.3643718478723423

Epoch: 6| Step: 13
Training loss: 0.20800973774909992
Validation loss: 2.3779303262728284

Epoch: 531| Step: 0
Training loss: 0.19000194143884488
Validation loss: 2.3870852410739882

Epoch: 6| Step: 1
Training loss: 0.15574833683898562
Validation loss: 2.3543448903882624

Epoch: 6| Step: 2
Training loss: 0.20112568593545405
Validation loss: 2.381993590896608

Epoch: 6| Step: 3
Training loss: 0.07539932022945613
Validation loss: 2.3757835033832415

Epoch: 6| Step: 4
Training loss: 0.22730400976908294
Validation loss: 2.376984661859489

Epoch: 6| Step: 5
Training loss: 0.1356710892693765
Validation loss: 2.361515132045237

Epoch: 6| Step: 6
Training loss: 0.1593924603995538
Validation loss: 2.3591704518631085

Epoch: 6| Step: 7
Training loss: 0.16571449569904068
Validation loss: 2.349607326473363

Epoch: 6| Step: 8
Training loss: 0.23188834301070096
Validation loss: 2.3636388229014833

Epoch: 6| Step: 9
Training loss: 0.11760913180228173
Validation loss: 2.351016322042065

Epoch: 6| Step: 10
Training loss: 0.11658126264572177
Validation loss: 2.365717410784636

Epoch: 6| Step: 11
Training loss: 0.15990435748930776
Validation loss: 2.349720886212233

Epoch: 6| Step: 12
Training loss: 0.160337293456969
Validation loss: 2.346935749765593

Epoch: 6| Step: 13
Training loss: 0.0752097493717096
Validation loss: 2.368445206447595

Epoch: 532| Step: 0
Training loss: 0.08996406046208491
Validation loss: 2.3430467990416015

Epoch: 6| Step: 1
Training loss: 0.21147093610054968
Validation loss: 2.3784985822999296

Epoch: 6| Step: 2
Training loss: 0.24255910175324658
Validation loss: 2.348047777977264

Epoch: 6| Step: 3
Training loss: 0.12140867981387778
Validation loss: 2.390197769349499

Epoch: 6| Step: 4
Training loss: 0.10457124126137302
Validation loss: 2.3826137126951954

Epoch: 6| Step: 5
Training loss: 0.10988637045786483
Validation loss: 2.3585516445031396

Epoch: 6| Step: 6
Training loss: 0.13943502484992643
Validation loss: 2.39806489601152

Epoch: 6| Step: 7
Training loss: 0.22621382816702823
Validation loss: 2.393651400120208

Epoch: 6| Step: 8
Training loss: 0.14690655587453996
Validation loss: 2.3660315899073456

Epoch: 6| Step: 9
Training loss: 0.10467081755476824
Validation loss: 2.332021958008033

Epoch: 6| Step: 10
Training loss: 0.15974651236338766
Validation loss: 2.3349242397563303

Epoch: 6| Step: 11
Training loss: 0.14930065688209426
Validation loss: 2.330821002290521

Epoch: 6| Step: 12
Training loss: 0.26060585143735837
Validation loss: 2.328468224226749

Epoch: 6| Step: 13
Training loss: 0.11605301713592046
Validation loss: 2.331036863343899

Epoch: 533| Step: 0
Training loss: 0.14448403540945012
Validation loss: 2.3351263600444714

Epoch: 6| Step: 1
Training loss: 0.17530053953860533
Validation loss: 2.3055612283396285

Epoch: 6| Step: 2
Training loss: 0.294111338014815
Validation loss: 2.323102018720973

Epoch: 6| Step: 3
Training loss: 0.2043594483341074
Validation loss: 2.3266236867885977

Epoch: 6| Step: 4
Training loss: 0.22579474920288845
Validation loss: 2.3183455494240888

Epoch: 6| Step: 5
Training loss: 0.22475822326491085
Validation loss: 2.324132006432752

Epoch: 6| Step: 6
Training loss: 0.17063291904216812
Validation loss: 2.3266671183063523

Epoch: 6| Step: 7
Training loss: 0.17282102067163463
Validation loss: 2.3587658348438647

Epoch: 6| Step: 8
Training loss: 0.12331887865124101
Validation loss: 2.351934328704495

Epoch: 6| Step: 9
Training loss: 0.15405911826857863
Validation loss: 2.323687565970664

Epoch: 6| Step: 10
Training loss: 0.21552833380599232
Validation loss: 2.337352193015746

Epoch: 6| Step: 11
Training loss: 0.21393815696385865
Validation loss: 2.3550646941510607

Epoch: 6| Step: 12
Training loss: 0.23437659739903638
Validation loss: 2.3655592968889114

Epoch: 6| Step: 13
Training loss: 0.3455911659801575
Validation loss: 2.3737025848674516

Epoch: 534| Step: 0
Training loss: 0.1857525338260652
Validation loss: 2.370418395302717

Epoch: 6| Step: 1
Training loss: 0.14337946779561783
Validation loss: 2.388521417868871

Epoch: 6| Step: 2
Training loss: 0.16489928155387443
Validation loss: 2.3960014227227893

Epoch: 6| Step: 3
Training loss: 0.22149100655344536
Validation loss: 2.417475545560786

Epoch: 6| Step: 4
Training loss: 0.23536553875590727
Validation loss: 2.4190588523261294

Epoch: 6| Step: 5
Training loss: 0.15339769852326438
Validation loss: 2.4083179717651424

Epoch: 6| Step: 6
Training loss: 0.09676599984609968
Validation loss: 2.4029227058616143

Epoch: 6| Step: 7
Training loss: 0.11074794202651295
Validation loss: 2.361823098600812

Epoch: 6| Step: 8
Training loss: 0.24968463407884106
Validation loss: 2.386308314159782

Epoch: 6| Step: 9
Training loss: 0.15715446359154236
Validation loss: 2.353479338580528

Epoch: 6| Step: 10
Training loss: 0.23075787948275253
Validation loss: 2.3654157560991984

Epoch: 6| Step: 11
Training loss: 0.25719951235412003
Validation loss: 2.3611395787311036

Epoch: 6| Step: 12
Training loss: 0.31086830682378763
Validation loss: 2.320497706166682

Epoch: 6| Step: 13
Training loss: 0.2077629008654264
Validation loss: 2.379991031702044

Epoch: 535| Step: 0
Training loss: 0.10590148383880481
Validation loss: 2.4190770622473954

Epoch: 6| Step: 1
Training loss: 0.1418251311572568
Validation loss: 2.4583239762879154

Epoch: 6| Step: 2
Training loss: 0.1552823082171376
Validation loss: 2.4794709549799117

Epoch: 6| Step: 3
Training loss: 0.13513642590178565
Validation loss: 2.4453975900277096

Epoch: 6| Step: 4
Training loss: 0.19029056651311993
Validation loss: 2.4966404866342473

Epoch: 6| Step: 5
Training loss: 0.2273261584525197
Validation loss: 2.5089497597364185

Epoch: 6| Step: 6
Training loss: 0.1877109711592586
Validation loss: 2.48945645224273

Epoch: 6| Step: 7
Training loss: 0.15427722081422043
Validation loss: 2.449446314698679

Epoch: 6| Step: 8
Training loss: 0.12139120791812445
Validation loss: 2.4202433037808277

Epoch: 6| Step: 9
Training loss: 0.11477620967357559
Validation loss: 2.387918203018725

Epoch: 6| Step: 10
Training loss: 0.24429290599910944
Validation loss: 2.3695262000732535

Epoch: 6| Step: 11
Training loss: 0.27160351012283385
Validation loss: 2.3557344168227163

Epoch: 6| Step: 12
Training loss: 0.27942265166044755
Validation loss: 2.3612658193220084

Epoch: 6| Step: 13
Training loss: 0.19491423054843499
Validation loss: 2.357117518015913

Epoch: 536| Step: 0
Training loss: 0.08663926455441795
Validation loss: 2.3961485396343174

Epoch: 6| Step: 1
Training loss: 0.22027649619083897
Validation loss: 2.3795388502388315

Epoch: 6| Step: 2
Training loss: 0.16108323692849094
Validation loss: 2.38816335877693

Epoch: 6| Step: 3
Training loss: 0.1705612507439248
Validation loss: 2.3811383489783675

Epoch: 6| Step: 4
Training loss: 0.18356255002422125
Validation loss: 2.3987468672142422

Epoch: 6| Step: 5
Training loss: 0.26206034103621445
Validation loss: 2.3943622429565856

Epoch: 6| Step: 6
Training loss: 0.188000051947343
Validation loss: 2.4043781855918445

Epoch: 6| Step: 7
Training loss: 0.17795015169246003
Validation loss: 2.3534428718646074

Epoch: 6| Step: 8
Training loss: 0.14563317626912603
Validation loss: 2.355069915990837

Epoch: 6| Step: 9
Training loss: 0.20490341010255733
Validation loss: 2.362592275110615

Epoch: 6| Step: 10
Training loss: 0.13409007104606632
Validation loss: 2.3613475846019614

Epoch: 6| Step: 11
Training loss: 0.17911055447668367
Validation loss: 2.3289865613418534

Epoch: 6| Step: 12
Training loss: 0.14517808203873625
Validation loss: 2.305656408804958

Epoch: 6| Step: 13
Training loss: 0.242962581396759
Validation loss: 2.332194263608236

Epoch: 537| Step: 0
Training loss: 0.11454844395170914
Validation loss: 2.324242572726103

Epoch: 6| Step: 1
Training loss: 0.14519483073074838
Validation loss: 2.3148290658794695

Epoch: 6| Step: 2
Training loss: 0.18863409505231546
Validation loss: 2.365515869040508

Epoch: 6| Step: 3
Training loss: 0.19675624346187948
Validation loss: 2.374858816383678

Epoch: 6| Step: 4
Training loss: 0.21969398256995892
Validation loss: 2.348828811044971

Epoch: 6| Step: 5
Training loss: 0.1340683437620989
Validation loss: 2.351608724524431

Epoch: 6| Step: 6
Training loss: 0.23147519236648414
Validation loss: 2.345973331248465

Epoch: 6| Step: 7
Training loss: 0.1944279572662842
Validation loss: 2.3273927823169642

Epoch: 6| Step: 8
Training loss: 0.25642844244152607
Validation loss: 2.336576595987937

Epoch: 6| Step: 9
Training loss: 0.16827590714299256
Validation loss: 2.334147474614489

Epoch: 6| Step: 10
Training loss: 0.18826217515171617
Validation loss: 2.323347798731441

Epoch: 6| Step: 11
Training loss: 0.23654352570585432
Validation loss: 2.3125290479445884

Epoch: 6| Step: 12
Training loss: 0.2937758961889579
Validation loss: 2.3170672166097734

Epoch: 6| Step: 13
Training loss: 0.2259625515431234
Validation loss: 2.2774562410744044

Epoch: 538| Step: 0
Training loss: 0.2999608754434781
Validation loss: 2.29612065905377

Epoch: 6| Step: 1
Training loss: 0.346792637867232
Validation loss: 2.309885820049234

Epoch: 6| Step: 2
Training loss: 0.24494490325088583
Validation loss: 2.3753798277686524

Epoch: 6| Step: 3
Training loss: 0.20753694349054758
Validation loss: 2.401644095266189

Epoch: 6| Step: 4
Training loss: 0.18873537902223897
Validation loss: 2.458765433747375

Epoch: 6| Step: 5
Training loss: 0.19081855585701182
Validation loss: 2.4760532633909835

Epoch: 6| Step: 6
Training loss: 0.10818386319580242
Validation loss: 2.4512313275361968

Epoch: 6| Step: 7
Training loss: 0.1980776926475116
Validation loss: 2.487944609187041

Epoch: 6| Step: 8
Training loss: 0.21602286245628155
Validation loss: 2.465623484622132

Epoch: 6| Step: 9
Training loss: 0.25049955405882773
Validation loss: 2.4247852328442008

Epoch: 6| Step: 10
Training loss: 0.2565598690302297
Validation loss: 2.381947736465678

Epoch: 6| Step: 11
Training loss: 0.17695840234023832
Validation loss: 2.3620924615120233

Epoch: 6| Step: 12
Training loss: 0.17249086969164987
Validation loss: 2.318341308377389

Epoch: 6| Step: 13
Training loss: 0.17487353029512875
Validation loss: 2.335732161571334

Epoch: 539| Step: 0
Training loss: 0.17925996296553467
Validation loss: 2.2911135228759965

Epoch: 6| Step: 1
Training loss: 0.3285529547493606
Validation loss: 2.3061092417902795

Epoch: 6| Step: 2
Training loss: 0.19873593297096206
Validation loss: 2.2818203228762415

Epoch: 6| Step: 3
Training loss: 0.152743865593884
Validation loss: 2.3333221878790518

Epoch: 6| Step: 4
Training loss: 0.15128788254935413
Validation loss: 2.355418830464643

Epoch: 6| Step: 5
Training loss: 0.24455800808886347
Validation loss: 2.3644914788576235

Epoch: 6| Step: 6
Training loss: 0.13304173097281372
Validation loss: 2.3787711286788444

Epoch: 6| Step: 7
Training loss: 0.2406928332195319
Validation loss: 2.410659202262797

Epoch: 6| Step: 8
Training loss: 0.30910039910432935
Validation loss: 2.430358764975336

Epoch: 6| Step: 9
Training loss: 0.3668463522271789
Validation loss: 2.3810896222198994

Epoch: 6| Step: 10
Training loss: 0.23661562873552855
Validation loss: 2.374694326361492

Epoch: 6| Step: 11
Training loss: 0.17566095050399008
Validation loss: 2.3352131738656348

Epoch: 6| Step: 12
Training loss: 0.39738904223091065
Validation loss: 2.320175079544449

Epoch: 6| Step: 13
Training loss: 0.32139433785387317
Validation loss: 2.3109028380040777

Epoch: 540| Step: 0
Training loss: 0.10854459909244374
Validation loss: 2.3047751055308177

Epoch: 6| Step: 1
Training loss: 0.15768408696869105
Validation loss: 2.3238409399678814

Epoch: 6| Step: 2
Training loss: 0.3045227510138263
Validation loss: 2.285923285110646

Epoch: 6| Step: 3
Training loss: 0.3124212284944737
Validation loss: 2.315966303881778

Epoch: 6| Step: 4
Training loss: 0.30305672987756926
Validation loss: 2.321211284106266

Epoch: 6| Step: 5
Training loss: 0.5644392388031592
Validation loss: 2.354055172429578

Epoch: 6| Step: 6
Training loss: 0.17929120522304584
Validation loss: 2.425503100990008

Epoch: 6| Step: 7
Training loss: 0.36538960223231176
Validation loss: 2.503242862844381

Epoch: 6| Step: 8
Training loss: 0.576655763355807
Validation loss: 2.5474290464703633

Epoch: 6| Step: 9
Training loss: 0.4118321828916149
Validation loss: 2.540345095405935

Epoch: 6| Step: 10
Training loss: 0.4778077475471742
Validation loss: 2.5273658711025635

Epoch: 6| Step: 11
Training loss: 0.36219751052911936
Validation loss: 2.5031039378439046

Epoch: 6| Step: 12
Training loss: 0.2506008675959822
Validation loss: 2.4470257451947166

Epoch: 6| Step: 13
Training loss: 0.32747787286176966
Validation loss: 2.3772476270943637

Epoch: 541| Step: 0
Training loss: 0.37933573027832856
Validation loss: 2.3000760391777453

Epoch: 6| Step: 1
Training loss: 0.29973847593118946
Validation loss: 2.2464478892048425

Epoch: 6| Step: 2
Training loss: 0.5498178863296241
Validation loss: 2.2707194640040758

Epoch: 6| Step: 3
Training loss: 0.49069133297982015
Validation loss: 2.2777239983818895

Epoch: 6| Step: 4
Training loss: 0.2877435751196876
Validation loss: 2.2921782525720276

Epoch: 6| Step: 5
Training loss: 0.28610640784804103
Validation loss: 2.309419090101777

Epoch: 6| Step: 6
Training loss: 0.20076711916643994
Validation loss: 2.3521471431608068

Epoch: 6| Step: 7
Training loss: 0.2950581115932847
Validation loss: 2.37737203103506

Epoch: 6| Step: 8
Training loss: 0.4798232138191495
Validation loss: 2.4320023188404543

Epoch: 6| Step: 9
Training loss: 0.5112094820190893
Validation loss: 2.4317069596659797

Epoch: 6| Step: 10
Training loss: 0.33770623440397135
Validation loss: 2.394600150033412

Epoch: 6| Step: 11
Training loss: 0.2911310159168935
Validation loss: 2.385818445638914

Epoch: 6| Step: 12
Training loss: 0.5636571531957386
Validation loss: 2.386970119156614

Epoch: 6| Step: 13
Training loss: 0.3932639247698847
Validation loss: 2.378865943199609

Epoch: 542| Step: 0
Training loss: 0.44226453265156473
Validation loss: 2.381425922865117

Epoch: 6| Step: 1
Training loss: 0.4529670900575633
Validation loss: 2.3664306510448583

Epoch: 6| Step: 2
Training loss: 0.4974486704086309
Validation loss: 2.384779640904973

Epoch: 6| Step: 3
Training loss: 0.39768793620616655
Validation loss: 2.3786178778601017

Epoch: 6| Step: 4
Training loss: 0.4871928482300421
Validation loss: 2.357775365866675

Epoch: 6| Step: 5
Training loss: 0.2984265140688378
Validation loss: 2.3804461680632585

Epoch: 6| Step: 6
Training loss: 0.6011975159608357
Validation loss: 2.343476336509662

Epoch: 6| Step: 7
Training loss: 0.4408791864010889
Validation loss: 2.2932003411808246

Epoch: 6| Step: 8
Training loss: 0.31598508142613896
Validation loss: 2.296583149722892

Epoch: 6| Step: 9
Training loss: 0.25468856893209796
Validation loss: 2.317029452105307

Epoch: 6| Step: 10
Training loss: 0.5210773150870606
Validation loss: 2.3394586359615057

Epoch: 6| Step: 11
Training loss: 0.3623030423438053
Validation loss: 2.330899972867529

Epoch: 6| Step: 12
Training loss: 0.24229860833496913
Validation loss: 2.3275069441617466

Epoch: 6| Step: 13
Training loss: 0.4183324318979944
Validation loss: 2.297125948781264

Epoch: 543| Step: 0
Training loss: 0.24341332249437567
Validation loss: 2.2883335526259105

Epoch: 6| Step: 1
Training loss: 0.36109145377934027
Validation loss: 2.2807620261717094

Epoch: 6| Step: 2
Training loss: 0.33376693339734503
Validation loss: 2.2781373040464152

Epoch: 6| Step: 3
Training loss: 0.3813928438148906
Validation loss: 2.2656000222939228

Epoch: 6| Step: 4
Training loss: 0.27811899768053044
Validation loss: 2.2740658736450277

Epoch: 6| Step: 5
Training loss: 0.3509513735555304
Validation loss: 2.303710541332178

Epoch: 6| Step: 6
Training loss: 0.2663641770552584
Validation loss: 2.3220725390671206

Epoch: 6| Step: 7
Training loss: 0.3135587756768522
Validation loss: 2.2901259443975133

Epoch: 6| Step: 8
Training loss: 0.30133570310693264
Validation loss: 2.3258903037300764

Epoch: 6| Step: 9
Training loss: 0.36081991798814594
Validation loss: 2.3652958388468317

Epoch: 6| Step: 10
Training loss: 0.4663088334167823
Validation loss: 2.386407119849511

Epoch: 6| Step: 11
Training loss: 0.38876954964793664
Validation loss: 2.3332599106090437

Epoch: 6| Step: 12
Training loss: 0.4535092500407803
Validation loss: 2.320656918357336

Epoch: 6| Step: 13
Training loss: 0.233931917350702
Validation loss: 2.2994135064272254

Epoch: 544| Step: 0
Training loss: 0.28296343427159143
Validation loss: 2.244877207598279

Epoch: 6| Step: 1
Training loss: 0.3399154324404327
Validation loss: 2.2561179449124094

Epoch: 6| Step: 2
Training loss: 0.4529591618628784
Validation loss: 2.294011167621348

Epoch: 6| Step: 3
Training loss: 0.3436797677165939
Validation loss: 2.338402163182413

Epoch: 6| Step: 4
Training loss: 0.284059138472237
Validation loss: 2.3816744981884974

Epoch: 6| Step: 5
Training loss: 0.41740000880816697
Validation loss: 2.4240345821808735

Epoch: 6| Step: 6
Training loss: 0.2519609021309846
Validation loss: 2.3996277856774966

Epoch: 6| Step: 7
Training loss: 0.41476742101507874
Validation loss: 2.4218617132261056

Epoch: 6| Step: 8
Training loss: 0.5272021068093862
Validation loss: 2.4177102854265926

Epoch: 6| Step: 9
Training loss: 0.5109260184488282
Validation loss: 2.419645971381764

Epoch: 6| Step: 10
Training loss: 0.5371462167762345
Validation loss: 2.404523641715765

Epoch: 6| Step: 11
Training loss: 0.43875551589802464
Validation loss: 2.393040613473739

Epoch: 6| Step: 12
Training loss: 0.3375857306137664
Validation loss: 2.433685041349552

Epoch: 6| Step: 13
Training loss: 0.3019730871000227
Validation loss: 2.433248451123173

Epoch: 545| Step: 0
Training loss: 0.4053598334821514
Validation loss: 2.478789182819956

Epoch: 6| Step: 1
Training loss: 0.3644184239130915
Validation loss: 2.4489649789857086

Epoch: 6| Step: 2
Training loss: 0.33130531613906034
Validation loss: 2.461803152120194

Epoch: 6| Step: 3
Training loss: 0.20344091570751044
Validation loss: 2.4783864567482494

Epoch: 6| Step: 4
Training loss: 0.3955873574221714
Validation loss: 2.455324173615267

Epoch: 6| Step: 5
Training loss: 0.20593835159033066
Validation loss: 2.416962916964611

Epoch: 6| Step: 6
Training loss: 0.33015729868804
Validation loss: 2.3620210134132718

Epoch: 6| Step: 7
Training loss: 0.3066930786754213
Validation loss: 2.3264420995216955

Epoch: 6| Step: 8
Training loss: 0.23054202579787694
Validation loss: 2.328348943369506

Epoch: 6| Step: 9
Training loss: 0.2454873895154726
Validation loss: 2.2982309153797353

Epoch: 6| Step: 10
Training loss: 0.2936418176863358
Validation loss: 2.318857787640649

Epoch: 6| Step: 11
Training loss: 0.3280777783701563
Validation loss: 2.288678213255295

Epoch: 6| Step: 12
Training loss: 0.294538893461337
Validation loss: 2.300740363424914

Epoch: 6| Step: 13
Training loss: 0.5764131461124176
Validation loss: 2.2693674873763188

Epoch: 546| Step: 0
Training loss: 0.3651202630464152
Validation loss: 2.367527900468422

Epoch: 6| Step: 1
Training loss: 0.3714421293383233
Validation loss: 2.445982536853056

Epoch: 6| Step: 2
Training loss: 0.25951755122365
Validation loss: 2.489872437888211

Epoch: 6| Step: 3
Training loss: 0.3478471039235159
Validation loss: 2.5531181569618413

Epoch: 6| Step: 4
Training loss: 0.4960297971339011
Validation loss: 2.576380799251731

Epoch: 6| Step: 5
Training loss: 0.4523939944809689
Validation loss: 2.5012318683278316

Epoch: 6| Step: 6
Training loss: 0.25710071216456426
Validation loss: 2.420029608310537

Epoch: 6| Step: 7
Training loss: 0.3392849965643641
Validation loss: 2.338676424819083

Epoch: 6| Step: 8
Training loss: 0.39616019991351215
Validation loss: 2.293394067153369

Epoch: 6| Step: 9
Training loss: 0.5032231631980636
Validation loss: 2.269759010302488

Epoch: 6| Step: 10
Training loss: 0.6342980173690099
Validation loss: 2.272223571332796

Epoch: 6| Step: 11
Training loss: 0.44312986239414043
Validation loss: 2.3344596791754944

Epoch: 6| Step: 12
Training loss: 0.33245672005223986
Validation loss: 2.3946373977932485

Epoch: 6| Step: 13
Training loss: 0.36526919520238565
Validation loss: 2.4370973947119117

Epoch: 547| Step: 0
Training loss: 0.38640421782382256
Validation loss: 2.470875068559289

Epoch: 6| Step: 1
Training loss: 0.6804192210762896
Validation loss: 2.575691342836181

Epoch: 6| Step: 2
Training loss: 0.5547659375246664
Validation loss: 2.494963251581384

Epoch: 6| Step: 3
Training loss: 0.5143783410706595
Validation loss: 2.4500215325613692

Epoch: 6| Step: 4
Training loss: 0.3886829930541187
Validation loss: 2.350832133083483

Epoch: 6| Step: 5
Training loss: 0.40630824331774473
Validation loss: 2.3489672432807276

Epoch: 6| Step: 6
Training loss: 0.4529128564600044
Validation loss: 2.333953854750934

Epoch: 6| Step: 7
Training loss: 0.3260250103548217
Validation loss: 2.31424725033429

Epoch: 6| Step: 8
Training loss: 0.42360210105124585
Validation loss: 2.305817245582692

Epoch: 6| Step: 9
Training loss: 0.33878516707923784
Validation loss: 2.3105375060381976

Epoch: 6| Step: 10
Training loss: 0.33523871689924817
Validation loss: 2.3478165490360112

Epoch: 6| Step: 11
Training loss: 0.5662447468932906
Validation loss: 2.3187194329542744

Epoch: 6| Step: 12
Training loss: 0.3928779102694637
Validation loss: 2.3413477880836795

Epoch: 6| Step: 13
Training loss: 0.3976236333754606
Validation loss: 2.3039486704195182

Epoch: 548| Step: 0
Training loss: 0.4702891511919407
Validation loss: 2.3473489563753276

Epoch: 6| Step: 1
Training loss: 0.3202006912477741
Validation loss: 2.3516418162386894

Epoch: 6| Step: 2
Training loss: 0.21838228791319586
Validation loss: 2.313110800808515

Epoch: 6| Step: 3
Training loss: 0.31926934250716377
Validation loss: 2.2881449285111843

Epoch: 6| Step: 4
Training loss: 0.32127688770358526
Validation loss: 2.291277177961191

Epoch: 6| Step: 5
Training loss: 0.2947673392732557
Validation loss: 2.247171412850057

Epoch: 6| Step: 6
Training loss: 0.4405022368975078
Validation loss: 2.267939353037027

Epoch: 6| Step: 7
Training loss: 0.32815117958626405
Validation loss: 2.265677820140889

Epoch: 6| Step: 8
Training loss: 0.3291899904707693
Validation loss: 2.325016650880028

Epoch: 6| Step: 9
Training loss: 0.2869711692489578
Validation loss: 2.3327753158603874

Epoch: 6| Step: 10
Training loss: 0.22478667186199924
Validation loss: 2.3380718225577164

Epoch: 6| Step: 11
Training loss: 0.3315983811647269
Validation loss: 2.383909083751643

Epoch: 6| Step: 12
Training loss: 0.33553159943205635
Validation loss: 2.400621690608132

Epoch: 6| Step: 13
Training loss: 0.3291447212150872
Validation loss: 2.401478520226831

Epoch: 549| Step: 0
Training loss: 0.3463175104099258
Validation loss: 2.3660047829489264

Epoch: 6| Step: 1
Training loss: 0.27027795162916285
Validation loss: 2.318927909602733

Epoch: 6| Step: 2
Training loss: 0.36988900027476007
Validation loss: 2.3040432677005094

Epoch: 6| Step: 3
Training loss: 0.33186389969187846
Validation loss: 2.3059745569397845

Epoch: 6| Step: 4
Training loss: 0.19346665768115057
Validation loss: 2.303675928687806

Epoch: 6| Step: 5
Training loss: 0.24887084773827886
Validation loss: 2.2848398782459656

Epoch: 6| Step: 6
Training loss: 0.4988363254861834
Validation loss: 2.288755593477428

Epoch: 6| Step: 7
Training loss: 0.4227245043009498
Validation loss: 2.3143754616459042

Epoch: 6| Step: 8
Training loss: 0.18223394887986072
Validation loss: 2.341772380784471

Epoch: 6| Step: 9
Training loss: 0.2646192696464008
Validation loss: 2.359462065741521

Epoch: 6| Step: 10
Training loss: 0.18467814207170705
Validation loss: 2.374009165873215

Epoch: 6| Step: 11
Training loss: 0.2804532421361963
Validation loss: 2.3821130558131456

Epoch: 6| Step: 12
Training loss: 0.20516143196691164
Validation loss: 2.405156148891037

Epoch: 6| Step: 13
Training loss: 0.42912465425361285
Validation loss: 2.4226290129457166

Epoch: 550| Step: 0
Training loss: 0.3048131512487704
Validation loss: 2.389944049394654

Epoch: 6| Step: 1
Training loss: 0.1841554773464336
Validation loss: 2.406715532349376

Epoch: 6| Step: 2
Training loss: 0.2872675764750535
Validation loss: 2.3922956188134923

Epoch: 6| Step: 3
Training loss: 0.3071567540969461
Validation loss: 2.3937151183399767

Epoch: 6| Step: 4
Training loss: 0.2332213699769209
Validation loss: 2.3767974401043865

Epoch: 6| Step: 5
Training loss: 0.33797096664400184
Validation loss: 2.3882879804077697

Epoch: 6| Step: 6
Training loss: 0.2242820178631749
Validation loss: 2.3519607736506574

Epoch: 6| Step: 7
Training loss: 0.22752354122809582
Validation loss: 2.3356524839687496

Epoch: 6| Step: 8
Training loss: 0.23072672807482617
Validation loss: 2.3241069350073205

Epoch: 6| Step: 9
Training loss: 0.275002971004563
Validation loss: 2.3431525745335597

Epoch: 6| Step: 10
Training loss: 0.2698503899212929
Validation loss: 2.2900026121159107

Epoch: 6| Step: 11
Training loss: 0.1756593334417353
Validation loss: 2.2863579827385005

Epoch: 6| Step: 12
Training loss: 0.28192060048864376
Validation loss: 2.282224924156432

Epoch: 6| Step: 13
Training loss: 0.2238764289675102
Validation loss: 2.29165870426469

Epoch: 551| Step: 0
Training loss: 0.19310429634918205
Validation loss: 2.30495212399062

Epoch: 6| Step: 1
Training loss: 0.2857081024637597
Validation loss: 2.3200441953000075

Epoch: 6| Step: 2
Training loss: 0.2654134946126541
Validation loss: 2.3261390408816385

Epoch: 6| Step: 3
Training loss: 0.16644285990285188
Validation loss: 2.3306892722042742

Epoch: 6| Step: 4
Training loss: 0.1859247676112364
Validation loss: 2.317545868084425

Epoch: 6| Step: 5
Training loss: 0.27463528007640414
Validation loss: 2.3341614924293603

Epoch: 6| Step: 6
Training loss: 0.20138159255443228
Validation loss: 2.3693999960137035

Epoch: 6| Step: 7
Training loss: 0.1905930820696689
Validation loss: 2.3511240298993807

Epoch: 6| Step: 8
Training loss: 0.17199029090142337
Validation loss: 2.3525350266685066

Epoch: 6| Step: 9
Training loss: 0.2114547198711897
Validation loss: 2.338765017456198

Epoch: 6| Step: 10
Training loss: 0.21342438097579497
Validation loss: 2.3696576766293127

Epoch: 6| Step: 11
Training loss: 0.20567119763523684
Validation loss: 2.367403022547213

Epoch: 6| Step: 12
Training loss: 0.2803092827288035
Validation loss: 2.370857442829882

Epoch: 6| Step: 13
Training loss: 0.25541071101262086
Validation loss: 2.392533547088901

Epoch: 552| Step: 0
Training loss: 0.2580868532797627
Validation loss: 2.4152594688943854

Epoch: 6| Step: 1
Training loss: 0.2700576893228571
Validation loss: 2.433228946502731

Epoch: 6| Step: 2
Training loss: 0.26496999989145165
Validation loss: 2.4424018309862037

Epoch: 6| Step: 3
Training loss: 0.2026590174160298
Validation loss: 2.418575969689854

Epoch: 6| Step: 4
Training loss: 0.18238379103381125
Validation loss: 2.4209766469702867

Epoch: 6| Step: 5
Training loss: 0.21761426539899473
Validation loss: 2.4510692883994185

Epoch: 6| Step: 6
Training loss: 0.2526084892978031
Validation loss: 2.422906021691396

Epoch: 6| Step: 7
Training loss: 0.29597736476846354
Validation loss: 2.3823539207885966

Epoch: 6| Step: 8
Training loss: 0.22151260128838005
Validation loss: 2.4047013437022056

Epoch: 6| Step: 9
Training loss: 0.24018169228597103
Validation loss: 2.348106323799577

Epoch: 6| Step: 10
Training loss: 0.14495865028774693
Validation loss: 2.360527340115657

Epoch: 6| Step: 11
Training loss: 0.23595505421747015
Validation loss: 2.328014627182945

Epoch: 6| Step: 12
Training loss: 0.2205989220311863
Validation loss: 2.3167166143760607

Epoch: 6| Step: 13
Training loss: 0.2636545246208428
Validation loss: 2.3135377594654227

Epoch: 553| Step: 0
Training loss: 0.21434248622082913
Validation loss: 2.260798430032798

Epoch: 6| Step: 1
Training loss: 0.21524025135360925
Validation loss: 2.2914265444369017

Epoch: 6| Step: 2
Training loss: 0.22009612475999865
Validation loss: 2.296314126655512

Epoch: 6| Step: 3
Training loss: 0.2623582968390665
Validation loss: 2.334712970572135

Epoch: 6| Step: 4
Training loss: 0.2334116369369682
Validation loss: 2.3310282333107915

Epoch: 6| Step: 5
Training loss: 0.21425049107716743
Validation loss: 2.345131162088893

Epoch: 6| Step: 6
Training loss: 0.20917968892472352
Validation loss: 2.350899235385534

Epoch: 6| Step: 7
Training loss: 0.15407976738534385
Validation loss: 2.38059953702465

Epoch: 6| Step: 8
Training loss: 0.28046584752103143
Validation loss: 2.3813580777727887

Epoch: 6| Step: 9
Training loss: 0.1705705276108406
Validation loss: 2.376527200785546

Epoch: 6| Step: 10
Training loss: 0.19389819199927594
Validation loss: 2.4215702299122137

Epoch: 6| Step: 11
Training loss: 0.29022134004589123
Validation loss: 2.3957616559007424

Epoch: 6| Step: 12
Training loss: 0.31689173340113364
Validation loss: 2.4240790778589956

Epoch: 6| Step: 13
Training loss: 0.21899410660317112
Validation loss: 2.428268345251424

Epoch: 554| Step: 0
Training loss: 0.13941755081477084
Validation loss: 2.392524006281517

Epoch: 6| Step: 1
Training loss: 0.1899264214496011
Validation loss: 2.380301599287981

Epoch: 6| Step: 2
Training loss: 0.22051113352542745
Validation loss: 2.38252173091532

Epoch: 6| Step: 3
Training loss: 0.24114519837352846
Validation loss: 2.381971205692748

Epoch: 6| Step: 4
Training loss: 0.30885166544595666
Validation loss: 2.3458307547483974

Epoch: 6| Step: 5
Training loss: 0.11151467972021133
Validation loss: 2.3482084422216962

Epoch: 6| Step: 6
Training loss: 0.16483843758687347
Validation loss: 2.3300903541139433

Epoch: 6| Step: 7
Training loss: 0.18231032593914803
Validation loss: 2.3520259905302634

Epoch: 6| Step: 8
Training loss: 0.21880270118750245
Validation loss: 2.329502669043525

Epoch: 6| Step: 9
Training loss: 0.17532068421305005
Validation loss: 2.3254237206672705

Epoch: 6| Step: 10
Training loss: 0.146690325598855
Validation loss: 2.326239793342721

Epoch: 6| Step: 11
Training loss: 0.24629519558560078
Validation loss: 2.3339999211053133

Epoch: 6| Step: 12
Training loss: 0.24130611626817158
Validation loss: 2.324690000403254

Epoch: 6| Step: 13
Training loss: 0.10263214427796961
Validation loss: 2.3315798599029645

Epoch: 555| Step: 0
Training loss: 0.1519305604690013
Validation loss: 2.3448123222512716

Epoch: 6| Step: 1
Training loss: 0.16272594786281622
Validation loss: 2.3470860011305548

Epoch: 6| Step: 2
Training loss: 0.22350285847967302
Validation loss: 2.3216303865553987

Epoch: 6| Step: 3
Training loss: 0.15442873957637296
Validation loss: 2.3128417504480936

Epoch: 6| Step: 4
Training loss: 0.2561101194390328
Validation loss: 2.3358634069697577

Epoch: 6| Step: 5
Training loss: 0.17607864018885425
Validation loss: 2.326286306146453

Epoch: 6| Step: 6
Training loss: 0.15387806610132945
Validation loss: 2.335386845615631

Epoch: 6| Step: 7
Training loss: 0.2493145755471996
Validation loss: 2.380414936075262

Epoch: 6| Step: 8
Training loss: 0.18337951497537494
Validation loss: 2.3348651163525047

Epoch: 6| Step: 9
Training loss: 0.16739162835815957
Validation loss: 2.3147369170623615

Epoch: 6| Step: 10
Training loss: 0.20254238644615694
Validation loss: 2.314453697663162

Epoch: 6| Step: 11
Training loss: 0.21770935655350376
Validation loss: 2.3287285188154874

Epoch: 6| Step: 12
Training loss: 0.20605780612700803
Validation loss: 2.342346044361745

Epoch: 6| Step: 13
Training loss: 0.1500829112368492
Validation loss: 2.3419513716599893

Epoch: 556| Step: 0
Training loss: 0.22691742457024988
Validation loss: 2.381424093865495

Epoch: 6| Step: 1
Training loss: 0.1710449081538503
Validation loss: 2.3776325516654686

Epoch: 6| Step: 2
Training loss: 0.1531829279202124
Validation loss: 2.372727363521225

Epoch: 6| Step: 3
Training loss: 0.19932562635254683
Validation loss: 2.393354111333117

Epoch: 6| Step: 4
Training loss: 0.12287048912718183
Validation loss: 2.4020970152892427

Epoch: 6| Step: 5
Training loss: 0.10828718714104665
Validation loss: 2.403380618338172

Epoch: 6| Step: 6
Training loss: 0.16928238951532076
Validation loss: 2.4401049274084388

Epoch: 6| Step: 7
Training loss: 0.12397626295034904
Validation loss: 2.3952117484536806

Epoch: 6| Step: 8
Training loss: 0.13351176406429663
Validation loss: 2.3748350118507893

Epoch: 6| Step: 9
Training loss: 0.2167602198775236
Validation loss: 2.3809975971742245

Epoch: 6| Step: 10
Training loss: 0.1428026495610259
Validation loss: 2.3965569409692313

Epoch: 6| Step: 11
Training loss: 0.24768404819663958
Validation loss: 2.3611587456473084

Epoch: 6| Step: 12
Training loss: 0.18091734581211746
Validation loss: 2.345964588965241

Epoch: 6| Step: 13
Training loss: 0.16861892881626797
Validation loss: 2.368582161270593

Epoch: 557| Step: 0
Training loss: 0.14638313609721293
Validation loss: 2.3737502120870237

Epoch: 6| Step: 1
Training loss: 0.168976323363163
Validation loss: 2.3847793184046338

Epoch: 6| Step: 2
Training loss: 0.1555437218745489
Validation loss: 2.392962518367548

Epoch: 6| Step: 3
Training loss: 0.13960651622122977
Validation loss: 2.391893522532757

Epoch: 6| Step: 4
Training loss: 0.21904043943634496
Validation loss: 2.3919803970862437

Epoch: 6| Step: 5
Training loss: 0.16132550133518322
Validation loss: 2.393258507702579

Epoch: 6| Step: 6
Training loss: 0.137999685184752
Validation loss: 2.381251981837381

Epoch: 6| Step: 7
Training loss: 0.17306762596727746
Validation loss: 2.3905753266510734

Epoch: 6| Step: 8
Training loss: 0.18500650926041304
Validation loss: 2.3845431009914497

Epoch: 6| Step: 9
Training loss: 0.2235273837316876
Validation loss: 2.3940037279759565

Epoch: 6| Step: 10
Training loss: 0.11975736532949662
Validation loss: 2.3859896077696123

Epoch: 6| Step: 11
Training loss: 0.23559856511882915
Validation loss: 2.3793999208382655

Epoch: 6| Step: 12
Training loss: 0.22240151506770228
Validation loss: 2.3812442938700973

Epoch: 6| Step: 13
Training loss: 0.15874130638227593
Validation loss: 2.37581694627611

Epoch: 558| Step: 0
Training loss: 0.1787906323114596
Validation loss: 2.3815861615704623

Epoch: 6| Step: 1
Training loss: 0.16642707998796213
Validation loss: 2.371509357789378

Epoch: 6| Step: 2
Training loss: 0.1913260077612084
Validation loss: 2.3549582279254895

Epoch: 6| Step: 3
Training loss: 0.13938837578443375
Validation loss: 2.370477238666548

Epoch: 6| Step: 4
Training loss: 0.1951064835248073
Validation loss: 2.3514082510578427

Epoch: 6| Step: 5
Training loss: 0.2620880737972669
Validation loss: 2.3791564123406355

Epoch: 6| Step: 6
Training loss: 0.26402475267837017
Validation loss: 2.3543688514592795

Epoch: 6| Step: 7
Training loss: 0.1900688273534799
Validation loss: 2.3534085971353553

Epoch: 6| Step: 8
Training loss: 0.2021522705894138
Validation loss: 2.327951412001944

Epoch: 6| Step: 9
Training loss: 0.16780838408119952
Validation loss: 2.320523129236475

Epoch: 6| Step: 10
Training loss: 0.2165662552699254
Validation loss: 2.3140774119166165

Epoch: 6| Step: 11
Training loss: 0.16774491988120602
Validation loss: 2.323445243482428

Epoch: 6| Step: 12
Training loss: 0.20748306851651144
Validation loss: 2.351517864088889

Epoch: 6| Step: 13
Training loss: 0.16456510555053297
Validation loss: 2.34351853762503

Epoch: 559| Step: 0
Training loss: 0.12503863274102092
Validation loss: 2.3589947176785047

Epoch: 6| Step: 1
Training loss: 0.12517658813711716
Validation loss: 2.3678664244390544

Epoch: 6| Step: 2
Training loss: 0.2010295697922822
Validation loss: 2.35904815263597

Epoch: 6| Step: 3
Training loss: 0.1791645193156114
Validation loss: 2.3392007737883045

Epoch: 6| Step: 4
Training loss: 0.13431221942552787
Validation loss: 2.356700927770893

Epoch: 6| Step: 5
Training loss: 0.14516634846433277
Validation loss: 2.3606739506500682

Epoch: 6| Step: 6
Training loss: 0.20746604678988195
Validation loss: 2.3549165728287296

Epoch: 6| Step: 7
Training loss: 0.25942333874045104
Validation loss: 2.3470721123898213

Epoch: 6| Step: 8
Training loss: 0.19596644596892132
Validation loss: 2.344497152211488

Epoch: 6| Step: 9
Training loss: 0.23475662791805002
Validation loss: 2.355036533898706

Epoch: 6| Step: 10
Training loss: 0.16694599204206498
Validation loss: 2.342409364392793

Epoch: 6| Step: 11
Training loss: 0.2750240077029704
Validation loss: 2.3476814999073174

Epoch: 6| Step: 12
Training loss: 0.19264656228167226
Validation loss: 2.366488606128157

Epoch: 6| Step: 13
Training loss: 0.08305126062872678
Validation loss: 2.3740479094254776

Epoch: 560| Step: 0
Training loss: 0.09910753467444314
Validation loss: 2.3740447195153265

Epoch: 6| Step: 1
Training loss: 0.1092472692973272
Validation loss: 2.353863161781221

Epoch: 6| Step: 2
Training loss: 0.11113467055713372
Validation loss: 2.4074466810273742

Epoch: 6| Step: 3
Training loss: 0.15538444389757705
Validation loss: 2.360847828916627

Epoch: 6| Step: 4
Training loss: 0.1509598820244786
Validation loss: 2.353193463246314

Epoch: 6| Step: 5
Training loss: 0.22383521636328
Validation loss: 2.3686195811452406

Epoch: 6| Step: 6
Training loss: 0.2519757608107564
Validation loss: 2.3986392895444966

Epoch: 6| Step: 7
Training loss: 0.21289580452594015
Validation loss: 2.3657394989862492

Epoch: 6| Step: 8
Training loss: 0.1719607767727656
Validation loss: 2.357501458441494

Epoch: 6| Step: 9
Training loss: 0.20477079342021418
Validation loss: 2.3140068222375576

Epoch: 6| Step: 10
Training loss: 0.15219118352736496
Validation loss: 2.3132019097407936

Epoch: 6| Step: 11
Training loss: 0.178268740195868
Validation loss: 2.2898508290980826

Epoch: 6| Step: 12
Training loss: 0.24451392816245746
Validation loss: 2.3007541479891347

Epoch: 6| Step: 13
Training loss: 0.2514502956293067
Validation loss: 2.299461201253259

Epoch: 561| Step: 0
Training loss: 0.23743803100496436
Validation loss: 2.3097655168500015

Epoch: 6| Step: 1
Training loss: 0.15658172322847613
Validation loss: 2.3097737973471073

Epoch: 6| Step: 2
Training loss: 0.2108228866592457
Validation loss: 2.328570134846112

Epoch: 6| Step: 3
Training loss: 0.15791316598679153
Validation loss: 2.333622832255259

Epoch: 6| Step: 4
Training loss: 0.30242500494734414
Validation loss: 2.3377677498720684

Epoch: 6| Step: 5
Training loss: 0.2861359371496412
Validation loss: 2.353740971813979

Epoch: 6| Step: 6
Training loss: 0.17734241233018708
Validation loss: 2.3896027106480644

Epoch: 6| Step: 7
Training loss: 0.11645580987280543
Validation loss: 2.4045062118397253

Epoch: 6| Step: 8
Training loss: 0.15282495622437692
Validation loss: 2.380995113206144

Epoch: 6| Step: 9
Training loss: 0.14990956292180485
Validation loss: 2.3923538222740346

Epoch: 6| Step: 10
Training loss: 0.16032700623583945
Validation loss: 2.4107502848631763

Epoch: 6| Step: 11
Training loss: 0.13639434747229878
Validation loss: 2.405701828262306

Epoch: 6| Step: 12
Training loss: 0.3463061402182152
Validation loss: 2.417591056791596

Epoch: 6| Step: 13
Training loss: 0.16991572533364352
Validation loss: 2.3896519981563697

Epoch: 562| Step: 0
Training loss: 0.2129650948141536
Validation loss: 2.367424448541686

Epoch: 6| Step: 1
Training loss: 0.3030097201475282
Validation loss: 2.3639553984184882

Epoch: 6| Step: 2
Training loss: 0.23635108300292396
Validation loss: 2.3525212518281924

Epoch: 6| Step: 3
Training loss: 0.18823589514708064
Validation loss: 2.3596963895127536

Epoch: 6| Step: 4
Training loss: 0.14024204190688508
Validation loss: 2.3468371376758737

Epoch: 6| Step: 5
Training loss: 0.21949019540295842
Validation loss: 2.3251919701217787

Epoch: 6| Step: 6
Training loss: 0.21686016911522663
Validation loss: 2.3048588851183545

Epoch: 6| Step: 7
Training loss: 0.23673629192155035
Validation loss: 2.3130228437642684

Epoch: 6| Step: 8
Training loss: 0.1891218612420526
Validation loss: 2.334749006226261

Epoch: 6| Step: 9
Training loss: 0.1308462791152887
Validation loss: 2.323669142838326

Epoch: 6| Step: 10
Training loss: 0.18368986332928317
Validation loss: 2.363977771487747

Epoch: 6| Step: 11
Training loss: 0.14699310337929883
Validation loss: 2.355489962393925

Epoch: 6| Step: 12
Training loss: 0.1104758963168602
Validation loss: 2.351329995428629

Epoch: 6| Step: 13
Training loss: 0.3106671826025938
Validation loss: 2.3298985735337805

Epoch: 563| Step: 0
Training loss: 0.13125588000841054
Validation loss: 2.3287154007437123

Epoch: 6| Step: 1
Training loss: 0.1481097643899734
Validation loss: 2.316450231107237

Epoch: 6| Step: 2
Training loss: 0.15627515709534545
Validation loss: 2.3076059724617153

Epoch: 6| Step: 3
Training loss: 0.20126096363887366
Validation loss: 2.328643428376396

Epoch: 6| Step: 4
Training loss: 0.18325404941773688
Validation loss: 2.3474191626434266

Epoch: 6| Step: 5
Training loss: 0.21011573939933403
Validation loss: 2.356486462981975

Epoch: 6| Step: 6
Training loss: 0.18164811067640782
Validation loss: 2.3355156801647596

Epoch: 6| Step: 7
Training loss: 0.16292360644263298
Validation loss: 2.3348003762209513

Epoch: 6| Step: 8
Training loss: 0.23565264394227142
Validation loss: 2.317757255330076

Epoch: 6| Step: 9
Training loss: 0.13769239057322008
Validation loss: 2.313510417943738

Epoch: 6| Step: 10
Training loss: 0.17996914186814217
Validation loss: 2.3312744807948094

Epoch: 6| Step: 11
Training loss: 0.16440421802053212
Validation loss: 2.3430168000389684

Epoch: 6| Step: 12
Training loss: 0.2491127826256857
Validation loss: 2.3670963732927195

Epoch: 6| Step: 13
Training loss: 0.3090402656287003
Validation loss: 2.3604969501884496

Epoch: 564| Step: 0
Training loss: 0.11677061873443761
Validation loss: 2.356482572619512

Epoch: 6| Step: 1
Training loss: 0.23076258532877583
Validation loss: 2.402280683779302

Epoch: 6| Step: 2
Training loss: 0.14068541288755412
Validation loss: 2.4022719644552164

Epoch: 6| Step: 3
Training loss: 0.22343340149701804
Validation loss: 2.4049296896595505

Epoch: 6| Step: 4
Training loss: 0.18397810453513583
Validation loss: 2.3672146230610065

Epoch: 6| Step: 5
Training loss: 0.14014157675586744
Validation loss: 2.3470742445033688

Epoch: 6| Step: 6
Training loss: 0.11950477855497305
Validation loss: 2.32722415413348

Epoch: 6| Step: 7
Training loss: 0.18113266254457508
Validation loss: 2.346545337431151

Epoch: 6| Step: 8
Training loss: 0.1934701621438927
Validation loss: 2.351593773959285

Epoch: 6| Step: 9
Training loss: 0.15241813066537932
Validation loss: 2.379515476071783

Epoch: 6| Step: 10
Training loss: 0.2465191751570104
Validation loss: 2.384904537707244

Epoch: 6| Step: 11
Training loss: 0.2152197928084202
Validation loss: 2.4107363455104305

Epoch: 6| Step: 12
Training loss: 0.1826089867367162
Validation loss: 2.411393307810431

Epoch: 6| Step: 13
Training loss: 0.2706402753831332
Validation loss: 2.391835187826224

Epoch: 565| Step: 0
Training loss: 0.2065053594450248
Validation loss: 2.411777055258936

Epoch: 6| Step: 1
Training loss: 0.16901621681237428
Validation loss: 2.424108684963721

Epoch: 6| Step: 2
Training loss: 0.07352963942341763
Validation loss: 2.4085553795387904

Epoch: 6| Step: 3
Training loss: 0.15397442551843396
Validation loss: 2.4187207765566114

Epoch: 6| Step: 4
Training loss: 0.16834828280487152
Validation loss: 2.358234825158272

Epoch: 6| Step: 5
Training loss: 0.11418264312781692
Validation loss: 2.3934813851746575

Epoch: 6| Step: 6
Training loss: 0.15133003886503912
Validation loss: 2.4044040779886218

Epoch: 6| Step: 7
Training loss: 0.1650335660843077
Validation loss: 2.368088954440251

Epoch: 6| Step: 8
Training loss: 0.13401847160832397
Validation loss: 2.3611522235061795

Epoch: 6| Step: 9
Training loss: 0.18061320645858622
Validation loss: 2.3521089680304756

Epoch: 6| Step: 10
Training loss: 0.13312509158404429
Validation loss: 2.387729107675274

Epoch: 6| Step: 11
Training loss: 0.21096439543320838
Validation loss: 2.3951351562719934

Epoch: 6| Step: 12
Training loss: 0.14317952003662787
Validation loss: 2.365455796798769

Epoch: 6| Step: 13
Training loss: 0.1690314519827749
Validation loss: 2.38088806970088

Epoch: 566| Step: 0
Training loss: 0.17686303310552545
Validation loss: 2.4068105013132337

Epoch: 6| Step: 1
Training loss: 0.13285140561613595
Validation loss: 2.3623299471461086

Epoch: 6| Step: 2
Training loss: 0.08933374526482828
Validation loss: 2.3628283586141623

Epoch: 6| Step: 3
Training loss: 0.13061268171151205
Validation loss: 2.360216214753659

Epoch: 6| Step: 4
Training loss: 0.15376992723570723
Validation loss: 2.3972511886285006

Epoch: 6| Step: 5
Training loss: 0.14220288293019623
Validation loss: 2.405423107389016

Epoch: 6| Step: 6
Training loss: 0.12438461697840518
Validation loss: 2.4192867616079

Epoch: 6| Step: 7
Training loss: 0.19425312750739895
Validation loss: 2.4002606201264354

Epoch: 6| Step: 8
Training loss: 0.10070073881792162
Validation loss: 2.39341702180844

Epoch: 6| Step: 9
Training loss: 0.16756661649013568
Validation loss: 2.3824644590713375

Epoch: 6| Step: 10
Training loss: 0.17327434215587267
Validation loss: 2.3902242057664984

Epoch: 6| Step: 11
Training loss: 0.19538797827464366
Validation loss: 2.3709622987446553

Epoch: 6| Step: 12
Training loss: 0.164623340716722
Validation loss: 2.340983175674753

Epoch: 6| Step: 13
Training loss: 0.1536540390237281
Validation loss: 2.3405644492259374

Epoch: 567| Step: 0
Training loss: 0.11321132244549831
Validation loss: 2.3369323590705258

Epoch: 6| Step: 1
Training loss: 0.11352055857229536
Validation loss: 2.338950939273006

Epoch: 6| Step: 2
Training loss: 0.15139692076018715
Validation loss: 2.352388261434192

Epoch: 6| Step: 3
Training loss: 0.19407434924895062
Validation loss: 2.3102510997143213

Epoch: 6| Step: 4
Training loss: 0.12000669654400337
Validation loss: 2.3202214073126433

Epoch: 6| Step: 5
Training loss: 0.17065538834426083
Validation loss: 2.342196828653424

Epoch: 6| Step: 6
Training loss: 0.11904019672524152
Validation loss: 2.325119817572588

Epoch: 6| Step: 7
Training loss: 0.19355577070162142
Validation loss: 2.353921863555354

Epoch: 6| Step: 8
Training loss: 0.16103372706235372
Validation loss: 2.3555256410137337

Epoch: 6| Step: 9
Training loss: 0.154100830743597
Validation loss: 2.3580969728530286

Epoch: 6| Step: 10
Training loss: 0.14374072806890828
Validation loss: 2.332767048874398

Epoch: 6| Step: 11
Training loss: 0.15695517675825543
Validation loss: 2.347892659373737

Epoch: 6| Step: 12
Training loss: 0.118086986783155
Validation loss: 2.3575790742585436

Epoch: 6| Step: 13
Training loss: 0.16179390165469454
Validation loss: 2.3537000429077306

Epoch: 568| Step: 0
Training loss: 0.21722153150017617
Validation loss: 2.343426512130316

Epoch: 6| Step: 1
Training loss: 0.2024256054627611
Validation loss: 2.3784313155172705

Epoch: 6| Step: 2
Training loss: 0.15475973287512942
Validation loss: 2.3969334516735237

Epoch: 6| Step: 3
Training loss: 0.22554488035508577
Validation loss: 2.3823414778623704

Epoch: 6| Step: 4
Training loss: 0.18856217609121023
Validation loss: 2.4109746741680738

Epoch: 6| Step: 5
Training loss: 0.22466065194665558
Validation loss: 2.4267381146805285

Epoch: 6| Step: 6
Training loss: 0.1637210130333065
Validation loss: 2.4322126008159612

Epoch: 6| Step: 7
Training loss: 0.12913295289204552
Validation loss: 2.426871886838099

Epoch: 6| Step: 8
Training loss: 0.2152959053720358
Validation loss: 2.4085696210258596

Epoch: 6| Step: 9
Training loss: 0.12514697315538847
Validation loss: 2.365681717904237

Epoch: 6| Step: 10
Training loss: 0.1769033854727204
Validation loss: 2.3910596692180452

Epoch: 6| Step: 11
Training loss: 0.16072509507885363
Validation loss: 2.352016287041472

Epoch: 6| Step: 12
Training loss: 0.1576358313801962
Validation loss: 2.3531823864360484

Epoch: 6| Step: 13
Training loss: 0.19522400758654446
Validation loss: 2.361995827524673

Epoch: 569| Step: 0
Training loss: 0.126067653517569
Validation loss: 2.3503102950567922

Epoch: 6| Step: 1
Training loss: 0.1081532807657633
Validation loss: 2.3296923253918562

Epoch: 6| Step: 2
Training loss: 0.13153097413791576
Validation loss: 2.3397570904597114

Epoch: 6| Step: 3
Training loss: 0.1858650290682269
Validation loss: 2.311211528307591

Epoch: 6| Step: 4
Training loss: 0.13348875660466034
Validation loss: 2.3117666985868124

Epoch: 6| Step: 5
Training loss: 0.10112440549489457
Validation loss: 2.325402254541277

Epoch: 6| Step: 6
Training loss: 0.13819379061222622
Validation loss: 2.3077273997085843

Epoch: 6| Step: 7
Training loss: 0.18515391650117713
Validation loss: 2.305515055772883

Epoch: 6| Step: 8
Training loss: 0.11793894643912417
Validation loss: 2.329378829780293

Epoch: 6| Step: 9
Training loss: 0.11792625583989252
Validation loss: 2.3300357841540467

Epoch: 6| Step: 10
Training loss: 0.16625590046830507
Validation loss: 2.3170628683901455

Epoch: 6| Step: 11
Training loss: 0.17104288808368712
Validation loss: 2.340795887741499

Epoch: 6| Step: 12
Training loss: 0.10776462494014315
Validation loss: 2.3328582582912785

Epoch: 6| Step: 13
Training loss: 0.07639042056991273
Validation loss: 2.309868305900235

Epoch: 570| Step: 0
Training loss: 0.1404224698966823
Validation loss: 2.322106517588136

Epoch: 6| Step: 1
Training loss: 0.14338878854758402
Validation loss: 2.3187997819559327

Epoch: 6| Step: 2
Training loss: 0.14548880177677573
Validation loss: 2.326092083181712

Epoch: 6| Step: 3
Training loss: 0.14746209958862774
Validation loss: 2.340983650953659

Epoch: 6| Step: 4
Training loss: 0.2113793478495474
Validation loss: 2.333225242979481

Epoch: 6| Step: 5
Training loss: 0.15733846390376566
Validation loss: 2.3500578627731485

Epoch: 6| Step: 6
Training loss: 0.12142270921094882
Validation loss: 2.3297467163295624

Epoch: 6| Step: 7
Training loss: 0.13262883277068388
Validation loss: 2.359986237266293

Epoch: 6| Step: 8
Training loss: 0.19806896590623455
Validation loss: 2.3700181667333773

Epoch: 6| Step: 9
Training loss: 0.13021553417003892
Validation loss: 2.3617957225817023

Epoch: 6| Step: 10
Training loss: 0.09266571516835921
Validation loss: 2.3608376084197378

Epoch: 6| Step: 11
Training loss: 0.17272515712730338
Validation loss: 2.359235242607758

Epoch: 6| Step: 12
Training loss: 0.09912410975786462
Validation loss: 2.384383741591317

Epoch: 6| Step: 13
Training loss: 0.16191875211690887
Validation loss: 2.3799474341674016

Epoch: 571| Step: 0
Training loss: 0.0998221303773243
Validation loss: 2.391065916788802

Epoch: 6| Step: 1
Training loss: 0.12821770779778585
Validation loss: 2.3981497350356773

Epoch: 6| Step: 2
Training loss: 0.11105887999186939
Validation loss: 2.358196394176154

Epoch: 6| Step: 3
Training loss: 0.15702542180305473
Validation loss: 2.380791658054274

Epoch: 6| Step: 4
Training loss: 0.13061904188649476
Validation loss: 2.366800176972928

Epoch: 6| Step: 5
Training loss: 0.19636674548938451
Validation loss: 2.3529197606089927

Epoch: 6| Step: 6
Training loss: 0.08776885445109868
Validation loss: 2.3480707382499055

Epoch: 6| Step: 7
Training loss: 0.16310988610139418
Validation loss: 2.3203533444262914

Epoch: 6| Step: 8
Training loss: 0.17694986563537596
Validation loss: 2.345137446748149

Epoch: 6| Step: 9
Training loss: 0.1436728296253378
Validation loss: 2.3069094589916794

Epoch: 6| Step: 10
Training loss: 0.16567033313737817
Validation loss: 2.3123847768647114

Epoch: 6| Step: 11
Training loss: 0.12807092804959497
Validation loss: 2.320492782154732

Epoch: 6| Step: 12
Training loss: 0.14617075726496143
Validation loss: 2.315902692026145

Epoch: 6| Step: 13
Training loss: 0.12878066505589944
Validation loss: 2.307401273716525

Epoch: 572| Step: 0
Training loss: 0.13533407376300963
Validation loss: 2.302594762596158

Epoch: 6| Step: 1
Training loss: 0.12599845814234564
Validation loss: 2.32675949456373

Epoch: 6| Step: 2
Training loss: 0.1275495019586351
Validation loss: 2.3388436748644863

Epoch: 6| Step: 3
Training loss: 0.1811306984197872
Validation loss: 2.358348739230484

Epoch: 6| Step: 4
Training loss: 0.1529804885888012
Validation loss: 2.35191991649922

Epoch: 6| Step: 5
Training loss: 0.15678175801542146
Validation loss: 2.3799354822454024

Epoch: 6| Step: 6
Training loss: 0.14557427929995126
Validation loss: 2.3490482006904205

Epoch: 6| Step: 7
Training loss: 0.13923115843031708
Validation loss: 2.3482318905654065

Epoch: 6| Step: 8
Training loss: 0.20437939911812064
Validation loss: 2.3783210867056193

Epoch: 6| Step: 9
Training loss: 0.2144413560928088
Validation loss: 2.3845592974338605

Epoch: 6| Step: 10
Training loss: 0.16043262941548475
Validation loss: 2.3784588721914424

Epoch: 6| Step: 11
Training loss: 0.21191232214709652
Validation loss: 2.3483084394041054

Epoch: 6| Step: 12
Training loss: 0.10688402167802417
Validation loss: 2.318312922109256

Epoch: 6| Step: 13
Training loss: 0.09355172409429253
Validation loss: 2.3378568179729635

Epoch: 573| Step: 0
Training loss: 0.1464650204905812
Validation loss: 2.317561690938667

Epoch: 6| Step: 1
Training loss: 0.07769555435603316
Validation loss: 2.315759153093262

Epoch: 6| Step: 2
Training loss: 0.11039521189593496
Validation loss: 2.3438656073603403

Epoch: 6| Step: 3
Training loss: 0.12283520430440865
Validation loss: 2.324463482190723

Epoch: 6| Step: 4
Training loss: 0.15947222595717434
Validation loss: 2.3364190018877906

Epoch: 6| Step: 5
Training loss: 0.12499079819426988
Validation loss: 2.3268448654356972

Epoch: 6| Step: 6
Training loss: 0.15282886245903743
Validation loss: 2.3348228557282362

Epoch: 6| Step: 7
Training loss: 0.21671671717212213
Validation loss: 2.31585429412844

Epoch: 6| Step: 8
Training loss: 0.12689556871189417
Validation loss: 2.346120917927608

Epoch: 6| Step: 9
Training loss: 0.11415399007729744
Validation loss: 2.3618158629807255

Epoch: 6| Step: 10
Training loss: 0.15946246696853683
Validation loss: 2.380598991042039

Epoch: 6| Step: 11
Training loss: 0.13665573166383202
Validation loss: 2.4003384321302024

Epoch: 6| Step: 12
Training loss: 0.15287253723593738
Validation loss: 2.3900319880725602

Epoch: 6| Step: 13
Training loss: 0.12639432583268256
Validation loss: 2.380814118417734

Epoch: 574| Step: 0
Training loss: 0.1225066587891158
Validation loss: 2.3761000835326325

Epoch: 6| Step: 1
Training loss: 0.17047967012150725
Validation loss: 2.368192700474116

Epoch: 6| Step: 2
Training loss: 0.09464585907274004
Validation loss: 2.3633551728156936

Epoch: 6| Step: 3
Training loss: 0.22268099396393343
Validation loss: 2.3473424646686016

Epoch: 6| Step: 4
Training loss: 0.15165229526443635
Validation loss: 2.368697692538586

Epoch: 6| Step: 5
Training loss: 0.13174202717855749
Validation loss: 2.3651568770798366

Epoch: 6| Step: 6
Training loss: 0.15152976626430703
Validation loss: 2.363772300662348

Epoch: 6| Step: 7
Training loss: 0.1674542976595329
Validation loss: 2.34229455090684

Epoch: 6| Step: 8
Training loss: 0.1208381493269124
Validation loss: 2.3552352660853213

Epoch: 6| Step: 9
Training loss: 0.15010572050690313
Validation loss: 2.336680478888468

Epoch: 6| Step: 10
Training loss: 0.14246638374179285
Validation loss: 2.3603940997222326

Epoch: 6| Step: 11
Training loss: 0.1882194089040381
Validation loss: 2.361118712424055

Epoch: 6| Step: 12
Training loss: 0.12647940945789196
Validation loss: 2.3490538473436917

Epoch: 6| Step: 13
Training loss: 0.1266395143204873
Validation loss: 2.377771111283713

Epoch: 575| Step: 0
Training loss: 0.13324835728049642
Validation loss: 2.3645232616139533

Epoch: 6| Step: 1
Training loss: 0.16036974238164425
Validation loss: 2.356593554218804

Epoch: 6| Step: 2
Training loss: 0.21579595575074015
Validation loss: 2.352775995683452

Epoch: 6| Step: 3
Training loss: 0.11440309433543172
Validation loss: 2.3746166362407544

Epoch: 6| Step: 4
Training loss: 0.09094068794463289
Validation loss: 2.3710244101682867

Epoch: 6| Step: 5
Training loss: 0.09665569335198779
Validation loss: 2.359562174877999

Epoch: 6| Step: 6
Training loss: 0.20183296281155544
Validation loss: 2.3364954900790504

Epoch: 6| Step: 7
Training loss: 0.13984785979641232
Validation loss: 2.3383878287344833

Epoch: 6| Step: 8
Training loss: 0.20522326828171028
Validation loss: 2.3486220945858576

Epoch: 6| Step: 9
Training loss: 0.1787673986077047
Validation loss: 2.351599413409964

Epoch: 6| Step: 10
Training loss: 0.14318704563736476
Validation loss: 2.3390074516658577

Epoch: 6| Step: 11
Training loss: 0.1628195305604116
Validation loss: 2.3777957484106382

Epoch: 6| Step: 12
Training loss: 0.11396179407610747
Validation loss: 2.4074439075471

Epoch: 6| Step: 13
Training loss: 0.06705501546360645
Validation loss: 2.360482374136065

Epoch: 576| Step: 0
Training loss: 0.11802178084592714
Validation loss: 2.3522406178700668

Epoch: 6| Step: 1
Training loss: 0.18350600113852325
Validation loss: 2.36793187801134

Epoch: 6| Step: 2
Training loss: 0.20362564890964774
Validation loss: 2.3708133442844153

Epoch: 6| Step: 3
Training loss: 0.16372127470285888
Validation loss: 2.365301005312883

Epoch: 6| Step: 4
Training loss: 0.08801949907265955
Validation loss: 2.3484007361817283

Epoch: 6| Step: 5
Training loss: 0.09993874100319562
Validation loss: 2.32419456523812

Epoch: 6| Step: 6
Training loss: 0.14367599292639036
Validation loss: 2.304988112188208

Epoch: 6| Step: 7
Training loss: 0.08988704881959352
Validation loss: 2.3118716918734283

Epoch: 6| Step: 8
Training loss: 0.13280317329868863
Validation loss: 2.2888254534780295

Epoch: 6| Step: 9
Training loss: 0.11740117857663751
Validation loss: 2.3223382525926537

Epoch: 6| Step: 10
Training loss: 0.1341044335706606
Validation loss: 2.2996973039167865

Epoch: 6| Step: 11
Training loss: 0.20369853149265355
Validation loss: 2.28817605304862

Epoch: 6| Step: 12
Training loss: 0.11898062077020402
Validation loss: 2.263389704514245

Epoch: 6| Step: 13
Training loss: 0.0939656548870427
Validation loss: 2.285240375830839

Epoch: 577| Step: 0
Training loss: 0.10235374143473827
Validation loss: 2.2929179972149827

Epoch: 6| Step: 1
Training loss: 0.15138929882368335
Validation loss: 2.2686026779566224

Epoch: 6| Step: 2
Training loss: 0.11528616081040277
Validation loss: 2.3007230158830803

Epoch: 6| Step: 3
Training loss: 0.16622223619547788
Validation loss: 2.302265236239657

Epoch: 6| Step: 4
Training loss: 0.1121502436270217
Validation loss: 2.3117396815612707

Epoch: 6| Step: 5
Training loss: 0.10733381476643548
Validation loss: 2.314527787118491

Epoch: 6| Step: 6
Training loss: 0.15983362383011396
Validation loss: 2.3582504309923387

Epoch: 6| Step: 7
Training loss: 0.1517365594167898
Validation loss: 2.35538608949698

Epoch: 6| Step: 8
Training loss: 0.15897544676434025
Validation loss: 2.3579242540504772

Epoch: 6| Step: 9
Training loss: 0.13292387892200289
Validation loss: 2.362299288481489

Epoch: 6| Step: 10
Training loss: 0.16005680439328798
Validation loss: 2.372154459044269

Epoch: 6| Step: 11
Training loss: 0.17023371987394031
Validation loss: 2.3862392413180333

Epoch: 6| Step: 12
Training loss: 0.19466786815249942
Validation loss: 2.3622389738231293

Epoch: 6| Step: 13
Training loss: 0.15123006701154335
Validation loss: 2.3283480526157057

Epoch: 578| Step: 0
Training loss: 0.1564576081052989
Validation loss: 2.323461236905652

Epoch: 6| Step: 1
Training loss: 0.1210580319363901
Validation loss: 2.33004871160018

Epoch: 6| Step: 2
Training loss: 0.17668604052244133
Validation loss: 2.312230609145516

Epoch: 6| Step: 3
Training loss: 0.10393345376326184
Validation loss: 2.3281213078039764

Epoch: 6| Step: 4
Training loss: 0.15038038813442045
Validation loss: 2.3029577528263068

Epoch: 6| Step: 5
Training loss: 0.11764865578437961
Validation loss: 2.327995016418861

Epoch: 6| Step: 6
Training loss: 0.10039287390212366
Validation loss: 2.3172012506264146

Epoch: 6| Step: 7
Training loss: 0.12397902737378207
Validation loss: 2.3008151852832404

Epoch: 6| Step: 8
Training loss: 0.18900543092438105
Validation loss: 2.2851157900812518

Epoch: 6| Step: 9
Training loss: 0.12492965044821759
Validation loss: 2.271308230231551

Epoch: 6| Step: 10
Training loss: 0.16341556997306475
Validation loss: 2.2880631396425573

Epoch: 6| Step: 11
Training loss: 0.12509991705561632
Validation loss: 2.312277935377609

Epoch: 6| Step: 12
Training loss: 0.2172025373453794
Validation loss: 2.307309678515561

Epoch: 6| Step: 13
Training loss: 0.1463647990137488
Validation loss: 2.30800998913136

Epoch: 579| Step: 0
Training loss: 0.2043140983979957
Validation loss: 2.324415247652432

Epoch: 6| Step: 1
Training loss: 0.16342893382903947
Validation loss: 2.3047651013295996

Epoch: 6| Step: 2
Training loss: 0.06523908067052075
Validation loss: 2.292478805304278

Epoch: 6| Step: 3
Training loss: 0.11463573505667055
Validation loss: 2.2904554140803723

Epoch: 6| Step: 4
Training loss: 0.12782371295765585
Validation loss: 2.333482215309526

Epoch: 6| Step: 5
Training loss: 0.13180526800515635
Validation loss: 2.3224509072215693

Epoch: 6| Step: 6
Training loss: 0.11589866644589523
Validation loss: 2.330896563879562

Epoch: 6| Step: 7
Training loss: 0.11820247120496787
Validation loss: 2.3115639958235845

Epoch: 6| Step: 8
Training loss: 0.1271176958789592
Validation loss: 2.321573346259669

Epoch: 6| Step: 9
Training loss: 0.10505123414761967
Validation loss: 2.3410657982870937

Epoch: 6| Step: 10
Training loss: 0.1881402825487928
Validation loss: 2.3453774449441185

Epoch: 6| Step: 11
Training loss: 0.13450274882202054
Validation loss: 2.340905523223688

Epoch: 6| Step: 12
Training loss: 0.15639356931410628
Validation loss: 2.3180350525605307

Epoch: 6| Step: 13
Training loss: 0.1619573132736604
Validation loss: 2.3096054764410634

Epoch: 580| Step: 0
Training loss: 0.07628491767878422
Validation loss: 2.294849396317983

Epoch: 6| Step: 1
Training loss: 0.10156475119663384
Validation loss: 2.318022076086923

Epoch: 6| Step: 2
Training loss: 0.23069092176685474
Validation loss: 2.2657115994693133

Epoch: 6| Step: 3
Training loss: 0.11613190391716315
Validation loss: 2.279459962508266

Epoch: 6| Step: 4
Training loss: 0.14821338046982582
Validation loss: 2.2825517310396526

Epoch: 6| Step: 5
Training loss: 0.08701157189901614
Validation loss: 2.3005590649296126

Epoch: 6| Step: 6
Training loss: 0.1519513333565573
Validation loss: 2.2676511288201517

Epoch: 6| Step: 7
Training loss: 0.12253217678405462
Validation loss: 2.2936236649598256

Epoch: 6| Step: 8
Training loss: 0.1659149594003162
Validation loss: 2.2903671368637273

Epoch: 6| Step: 9
Training loss: 0.09122200292247885
Validation loss: 2.2859221176390165

Epoch: 6| Step: 10
Training loss: 0.13587060521080216
Validation loss: 2.2876817446914033

Epoch: 6| Step: 11
Training loss: 0.09320891218452607
Validation loss: 2.3084194218236043

Epoch: 6| Step: 12
Training loss: 0.16905400743148943
Validation loss: 2.2912430191737054

Epoch: 6| Step: 13
Training loss: 0.0977213308913347
Validation loss: 2.318495841570032

Epoch: 581| Step: 0
Training loss: 0.1679954673898574
Validation loss: 2.328957961933321

Epoch: 6| Step: 1
Training loss: 0.1210505616173347
Validation loss: 2.3059896542988425

Epoch: 6| Step: 2
Training loss: 0.20430529159509686
Validation loss: 2.358935937827262

Epoch: 6| Step: 3
Training loss: 0.21639048660100912
Validation loss: 2.3409188522457414

Epoch: 6| Step: 4
Training loss: 0.15291312385005543
Validation loss: 2.3659409956750936

Epoch: 6| Step: 5
Training loss: 0.09789637131657147
Validation loss: 2.3548965533212867

Epoch: 6| Step: 6
Training loss: 0.0884875899089039
Validation loss: 2.3406026576632297

Epoch: 6| Step: 7
Training loss: 0.1861962849649991
Validation loss: 2.3413793944735883

Epoch: 6| Step: 8
Training loss: 0.14292697817394484
Validation loss: 2.356715764352045

Epoch: 6| Step: 9
Training loss: 0.10996249487470237
Validation loss: 2.32445831842761

Epoch: 6| Step: 10
Training loss: 0.10370493618255873
Validation loss: 2.3480611898302612

Epoch: 6| Step: 11
Training loss: 0.14250373205936215
Validation loss: 2.316780183412585

Epoch: 6| Step: 12
Training loss: 0.10177981986176302
Validation loss: 2.3288860113725813

Epoch: 6| Step: 13
Training loss: 0.15356429544267913
Validation loss: 2.288856186543375

Epoch: 582| Step: 0
Training loss: 0.08037313050833077
Validation loss: 2.2854296998587995

Epoch: 6| Step: 1
Training loss: 0.1567110352885044
Validation loss: 2.297514854734039

Epoch: 6| Step: 2
Training loss: 0.161547843030307
Validation loss: 2.3101411094470254

Epoch: 6| Step: 3
Training loss: 0.07843181445120576
Validation loss: 2.3009503749129503

Epoch: 6| Step: 4
Training loss: 0.058634376349360445
Validation loss: 2.28967957545786

Epoch: 6| Step: 5
Training loss: 0.20833779966017313
Validation loss: 2.317040680172396

Epoch: 6| Step: 6
Training loss: 0.14235204251669387
Validation loss: 2.3074704244984265

Epoch: 6| Step: 7
Training loss: 0.1319625529054357
Validation loss: 2.2747869850038396

Epoch: 6| Step: 8
Training loss: 0.1125856037422153
Validation loss: 2.3098740816274286

Epoch: 6| Step: 9
Training loss: 0.13664413868577907
Validation loss: 2.315793300632271

Epoch: 6| Step: 10
Training loss: 0.17509631652659907
Validation loss: 2.32320137179284

Epoch: 6| Step: 11
Training loss: 0.09806906232520958
Validation loss: 2.297530401568937

Epoch: 6| Step: 12
Training loss: 0.1042662343367978
Validation loss: 2.312942371665568

Epoch: 6| Step: 13
Training loss: 0.09954549573698138
Validation loss: 2.3107720470788067

Epoch: 583| Step: 0
Training loss: 0.0893854445326754
Validation loss: 2.32647157835462

Epoch: 6| Step: 1
Training loss: 0.10026806073546622
Validation loss: 2.325845165216932

Epoch: 6| Step: 2
Training loss: 0.13009800687409648
Validation loss: 2.300667829026665

Epoch: 6| Step: 3
Training loss: 0.16598485773751243
Validation loss: 2.2977052568832192

Epoch: 6| Step: 4
Training loss: 0.17611310151873535
Validation loss: 2.309354072893491

Epoch: 6| Step: 5
Training loss: 0.08786074607328152
Validation loss: 2.311274779568433

Epoch: 6| Step: 6
Training loss: 0.19116433094823812
Validation loss: 2.299400817036508

Epoch: 6| Step: 7
Training loss: 0.13750179706829652
Validation loss: 2.2929215071105458

Epoch: 6| Step: 8
Training loss: 0.14931562085440978
Validation loss: 2.3394903084187897

Epoch: 6| Step: 9
Training loss: 0.10497168127142394
Validation loss: 2.3481706020969586

Epoch: 6| Step: 10
Training loss: 0.13730176865580443
Validation loss: 2.3283660713206906

Epoch: 6| Step: 11
Training loss: 0.06947300351849434
Validation loss: 2.3521463769503828

Epoch: 6| Step: 12
Training loss: 0.08963268303660231
Validation loss: 2.3399931551992084

Epoch: 6| Step: 13
Training loss: 0.12464163491178394
Validation loss: 2.3706789393322154

Epoch: 584| Step: 0
Training loss: 0.1096375328895703
Validation loss: 2.359126615716323

Epoch: 6| Step: 1
Training loss: 0.12224372372064543
Validation loss: 2.366142129036637

Epoch: 6| Step: 2
Training loss: 0.14316692661683497
Validation loss: 2.336991833316642

Epoch: 6| Step: 3
Training loss: 0.1283135733148434
Validation loss: 2.360270297108256

Epoch: 6| Step: 4
Training loss: 0.08241443882974797
Validation loss: 2.335949100316461

Epoch: 6| Step: 5
Training loss: 0.1307659456169582
Validation loss: 2.3489876276391497

Epoch: 6| Step: 6
Training loss: 0.1094579467283178
Validation loss: 2.360091151452848

Epoch: 6| Step: 7
Training loss: 0.1895356834094372
Validation loss: 2.35451870906046

Epoch: 6| Step: 8
Training loss: 0.18627476717939867
Validation loss: 2.358781800444188

Epoch: 6| Step: 9
Training loss: 0.10901579882392076
Validation loss: 2.3439167469280484

Epoch: 6| Step: 10
Training loss: 0.10881277747012043
Validation loss: 2.341798021184418

Epoch: 6| Step: 11
Training loss: 0.09661443993933937
Validation loss: 2.3295389619249347

Epoch: 6| Step: 12
Training loss: 0.10396302901896279
Validation loss: 2.3612251028218827

Epoch: 6| Step: 13
Training loss: 0.11711017521208823
Validation loss: 2.351785740973605

Epoch: 585| Step: 0
Training loss: 0.13529972994059178
Validation loss: 2.3373311143490243

Epoch: 6| Step: 1
Training loss: 0.08462662253785937
Validation loss: 2.3424427983860348

Epoch: 6| Step: 2
Training loss: 0.19457182633386014
Validation loss: 2.3227130996221814

Epoch: 6| Step: 3
Training loss: 0.12270587263597686
Validation loss: 2.2890548708727434

Epoch: 6| Step: 4
Training loss: 0.15742673038160485
Validation loss: 2.347187129066981

Epoch: 6| Step: 5
Training loss: 0.09823973389096508
Validation loss: 2.339872762528364

Epoch: 6| Step: 6
Training loss: 0.16131994767050553
Validation loss: 2.3397446768447483

Epoch: 6| Step: 7
Training loss: 0.1280392476126538
Validation loss: 2.347003675103638

Epoch: 6| Step: 8
Training loss: 0.12646583055972832
Validation loss: 2.3566104279336053

Epoch: 6| Step: 9
Training loss: 0.1159962586573379
Validation loss: 2.3725974123142506

Epoch: 6| Step: 10
Training loss: 0.10336827641316416
Validation loss: 2.3605466846829137

Epoch: 6| Step: 11
Training loss: 0.08231975140560935
Validation loss: 2.3570900647763326

Epoch: 6| Step: 12
Training loss: 0.09524552755637729
Validation loss: 2.3732340529003477

Epoch: 6| Step: 13
Training loss: 0.17961404169631448
Validation loss: 2.3729975883091665

Epoch: 586| Step: 0
Training loss: 0.13735591372373998
Validation loss: 2.33473544543077

Epoch: 6| Step: 1
Training loss: 0.11326740443362864
Validation loss: 2.367370372060121

Epoch: 6| Step: 2
Training loss: 0.10018123765805304
Validation loss: 2.367087400898804

Epoch: 6| Step: 3
Training loss: 0.09626859385459118
Validation loss: 2.360343355713085

Epoch: 6| Step: 4
Training loss: 0.13664175317733665
Validation loss: 2.35363838952304

Epoch: 6| Step: 5
Training loss: 0.11216662669653461
Validation loss: 2.3357333041463657

Epoch: 6| Step: 6
Training loss: 0.10894362497920534
Validation loss: 2.358151288081025

Epoch: 6| Step: 7
Training loss: 0.1610166998304005
Validation loss: 2.339326956654427

Epoch: 6| Step: 8
Training loss: 0.22384055870366293
Validation loss: 2.345314827288552

Epoch: 6| Step: 9
Training loss: 0.1513903815434546
Validation loss: 2.356347282792649

Epoch: 6| Step: 10
Training loss: 0.13585773188434805
Validation loss: 2.323004946931948

Epoch: 6| Step: 11
Training loss: 0.08673898873129753
Validation loss: 2.3124518473987723

Epoch: 6| Step: 12
Training loss: 0.11699984148108511
Validation loss: 2.3195417050683487

Epoch: 6| Step: 13
Training loss: 0.078660453243806
Validation loss: 2.312412506417229

Epoch: 587| Step: 0
Training loss: 0.06879981049052221
Validation loss: 2.3072102414107425

Epoch: 6| Step: 1
Training loss: 0.13907868526865744
Validation loss: 2.3022474205312444

Epoch: 6| Step: 2
Training loss: 0.09845000974699662
Validation loss: 2.330803545362392

Epoch: 6| Step: 3
Training loss: 0.18300829534151428
Validation loss: 2.3276723193244857

Epoch: 6| Step: 4
Training loss: 0.10772617328924002
Validation loss: 2.3078020816853058

Epoch: 6| Step: 5
Training loss: 0.12290399824204351
Validation loss: 2.3180577142810757

Epoch: 6| Step: 6
Training loss: 0.08129785726156559
Validation loss: 2.3293171360536804

Epoch: 6| Step: 7
Training loss: 0.09728172486891189
Validation loss: 2.3233830010406424

Epoch: 6| Step: 8
Training loss: 0.15863704630657843
Validation loss: 2.3057326227300807

Epoch: 6| Step: 9
Training loss: 0.15771419418720847
Validation loss: 2.3041728517654465

Epoch: 6| Step: 10
Training loss: 0.08078325162137999
Validation loss: 2.291121695669539

Epoch: 6| Step: 11
Training loss: 0.14682064876945172
Validation loss: 2.3044824001791704

Epoch: 6| Step: 12
Training loss: 0.11725983771238023
Validation loss: 2.2902720469033393

Epoch: 6| Step: 13
Training loss: 0.09519000096113268
Validation loss: 2.3183120872137555

Epoch: 588| Step: 0
Training loss: 0.10267458089410202
Validation loss: 2.345371341283504

Epoch: 6| Step: 1
Training loss: 0.0886677295707301
Validation loss: 2.3113532630653286

Epoch: 6| Step: 2
Training loss: 0.18996180250789457
Validation loss: 2.3103122844684765

Epoch: 6| Step: 3
Training loss: 0.08406684951094606
Validation loss: 2.3140007344319007

Epoch: 6| Step: 4
Training loss: 0.15395702284610932
Validation loss: 2.3543822357427966

Epoch: 6| Step: 5
Training loss: 0.12257268148361695
Validation loss: 2.3342133278487904

Epoch: 6| Step: 6
Training loss: 0.12154634940257743
Validation loss: 2.3429576669328616

Epoch: 6| Step: 7
Training loss: 0.10845958428492515
Validation loss: 2.345973060784566

Epoch: 6| Step: 8
Training loss: 0.12511543070226422
Validation loss: 2.3634590496293124

Epoch: 6| Step: 9
Training loss: 0.09811725047513695
Validation loss: 2.3753125287884327

Epoch: 6| Step: 10
Training loss: 0.10208778075663846
Validation loss: 2.359445548162399

Epoch: 6| Step: 11
Training loss: 0.16323743852990585
Validation loss: 2.3513720122525013

Epoch: 6| Step: 12
Training loss: 0.12030740733329442
Validation loss: 2.3779351027788107

Epoch: 6| Step: 13
Training loss: 0.0971238692768905
Validation loss: 2.3600004003346116

Epoch: 589| Step: 0
Training loss: 0.12324057198627875
Validation loss: 2.3625011241602207

Epoch: 6| Step: 1
Training loss: 0.14475154841209226
Validation loss: 2.379377074061111

Epoch: 6| Step: 2
Training loss: 0.21313277305903855
Validation loss: 2.357818879201827

Epoch: 6| Step: 3
Training loss: 0.10720445130493389
Validation loss: 2.3511541309954715

Epoch: 6| Step: 4
Training loss: 0.09341797545742271
Validation loss: 2.333477930636777

Epoch: 6| Step: 5
Training loss: 0.12180650816107166
Validation loss: 2.348932669410964

Epoch: 6| Step: 6
Training loss: 0.07861334048440727
Validation loss: 2.325438926575493

Epoch: 6| Step: 7
Training loss: 0.21121028639712616
Validation loss: 2.3293507216451084

Epoch: 6| Step: 8
Training loss: 0.16879394674263903
Validation loss: 2.335475863806329

Epoch: 6| Step: 9
Training loss: 0.1419170416916428
Validation loss: 2.3137654126809273

Epoch: 6| Step: 10
Training loss: 0.12076146542989762
Validation loss: 2.3306566139231046

Epoch: 6| Step: 11
Training loss: 0.14477387889053492
Validation loss: 2.282676369974168

Epoch: 6| Step: 12
Training loss: 0.11019783368044278
Validation loss: 2.296326679038642

Epoch: 6| Step: 13
Training loss: 0.17495849704765054
Validation loss: 2.3087323000779554

Epoch: 590| Step: 0
Training loss: 0.09141263287421268
Validation loss: 2.2822430795435387

Epoch: 6| Step: 1
Training loss: 0.15166471834315548
Validation loss: 2.289333982718984

Epoch: 6| Step: 2
Training loss: 0.14000520948739714
Validation loss: 2.3140321061245297

Epoch: 6| Step: 3
Training loss: 0.14570034653415262
Validation loss: 2.323296120338341

Epoch: 6| Step: 4
Training loss: 0.12257312217408378
Validation loss: 2.316022496562999

Epoch: 6| Step: 5
Training loss: 0.08728454152588797
Validation loss: 2.3344921052541343

Epoch: 6| Step: 6
Training loss: 0.14270199006896045
Validation loss: 2.3364596448489965

Epoch: 6| Step: 7
Training loss: 0.17703926482411478
Validation loss: 2.33125972148097

Epoch: 6| Step: 8
Training loss: 0.17761490547923997
Validation loss: 2.3604172809338895

Epoch: 6| Step: 9
Training loss: 0.1250334337344606
Validation loss: 2.371783712543667

Epoch: 6| Step: 10
Training loss: 0.15911192124341142
Validation loss: 2.3335566816653426

Epoch: 6| Step: 11
Training loss: 0.11078017052688119
Validation loss: 2.361126870913653

Epoch: 6| Step: 12
Training loss: 0.10559208158059487
Validation loss: 2.3422604942072196

Epoch: 6| Step: 13
Training loss: 0.09087368207156873
Validation loss: 2.357890963470165

Epoch: 591| Step: 0
Training loss: 0.1746411544247067
Validation loss: 2.3963539667122724

Epoch: 6| Step: 1
Training loss: 0.16052201419666626
Validation loss: 2.353704572869471

Epoch: 6| Step: 2
Training loss: 0.10768490147762633
Validation loss: 2.345259994784074

Epoch: 6| Step: 3
Training loss: 0.1768652341896467
Validation loss: 2.3608728826291845

Epoch: 6| Step: 4
Training loss: 0.08587401385900222
Validation loss: 2.342890881005733

Epoch: 6| Step: 5
Training loss: 0.12401736612552797
Validation loss: 2.3591101539268613

Epoch: 6| Step: 6
Training loss: 0.14097241693385645
Validation loss: 2.3263502407235945

Epoch: 6| Step: 7
Training loss: 0.11874903753794086
Validation loss: 2.3242964294087693

Epoch: 6| Step: 8
Training loss: 0.07027457459501499
Validation loss: 2.317285175875977

Epoch: 6| Step: 9
Training loss: 0.10323192749684526
Validation loss: 2.3033119497453294

Epoch: 6| Step: 10
Training loss: 0.12207962763530558
Validation loss: 2.318570842874934

Epoch: 6| Step: 11
Training loss: 0.11464275008071607
Validation loss: 2.2903050247126426

Epoch: 6| Step: 12
Training loss: 0.1494369738596258
Validation loss: 2.2908391478295846

Epoch: 6| Step: 13
Training loss: 0.12340747129985985
Validation loss: 2.2465621418483983

Epoch: 592| Step: 0
Training loss: 0.13927378783543318
Validation loss: 2.25096741268893

Epoch: 6| Step: 1
Training loss: 0.15633074938865107
Validation loss: 2.254857617454216

Epoch: 6| Step: 2
Training loss: 0.08916215883911978
Validation loss: 2.272538129891692

Epoch: 6| Step: 3
Training loss: 0.16355587870708646
Validation loss: 2.277274031134678

Epoch: 6| Step: 4
Training loss: 0.1531301704331784
Validation loss: 2.2959127614260706

Epoch: 6| Step: 5
Training loss: 0.11405972483929934
Validation loss: 2.314722106569721

Epoch: 6| Step: 6
Training loss: 0.09084022467760339
Validation loss: 2.2958729045005035

Epoch: 6| Step: 7
Training loss: 0.10813230200460221
Validation loss: 2.296232009479517

Epoch: 6| Step: 8
Training loss: 0.12528408818873046
Validation loss: 2.319019808145674

Epoch: 6| Step: 9
Training loss: 0.17001567641198653
Validation loss: 2.3127621361052575

Epoch: 6| Step: 10
Training loss: 0.11555856426349405
Validation loss: 2.3188049008295555

Epoch: 6| Step: 11
Training loss: 0.11837017589173329
Validation loss: 2.3176006779285534

Epoch: 6| Step: 12
Training loss: 0.20103284976250949
Validation loss: 2.344188176968961

Epoch: 6| Step: 13
Training loss: 0.1559667702478328
Validation loss: 2.3447453442390582

Epoch: 593| Step: 0
Training loss: 0.1471207718326701
Validation loss: 2.3846368227380035

Epoch: 6| Step: 1
Training loss: 0.1826464787619716
Validation loss: 2.3413428717877767

Epoch: 6| Step: 2
Training loss: 0.0932311062726476
Validation loss: 2.362028666266796

Epoch: 6| Step: 3
Training loss: 0.2402562232278317
Validation loss: 2.351288180107043

Epoch: 6| Step: 4
Training loss: 0.13596731494732806
Validation loss: 2.336608088078293

Epoch: 6| Step: 5
Training loss: 0.06665204992778961
Validation loss: 2.311647148697879

Epoch: 6| Step: 6
Training loss: 0.08923400899571227
Validation loss: 2.358087107896645

Epoch: 6| Step: 7
Training loss: 0.12921575035386754
Validation loss: 2.3300401323698154

Epoch: 6| Step: 8
Training loss: 0.0863421676831083
Validation loss: 2.2949029072449174

Epoch: 6| Step: 9
Training loss: 0.12441156884872803
Validation loss: 2.2917210907127594

Epoch: 6| Step: 10
Training loss: 0.1067910136558719
Validation loss: 2.2714314997086915

Epoch: 6| Step: 11
Training loss: 0.10285895267801451
Validation loss: 2.272660564467201

Epoch: 6| Step: 12
Training loss: 0.16414553380286775
Validation loss: 2.28641489805096

Epoch: 6| Step: 13
Training loss: 0.15302825250702679
Validation loss: 2.2641343881856217

Epoch: 594| Step: 0
Training loss: 0.11257244615308522
Validation loss: 2.2699668753818525

Epoch: 6| Step: 1
Training loss: 0.15246400610620928
Validation loss: 2.254295324781123

Epoch: 6| Step: 2
Training loss: 0.12643762980570897
Validation loss: 2.3106551700736317

Epoch: 6| Step: 3
Training loss: 0.19478695735406604
Validation loss: 2.3233145578078624

Epoch: 6| Step: 4
Training loss: 0.11612082040628621
Validation loss: 2.3313943377203525

Epoch: 6| Step: 5
Training loss: 0.16373571138794898
Validation loss: 2.323009959423729

Epoch: 6| Step: 6
Training loss: 0.1212402426711597
Validation loss: 2.3467842641943566

Epoch: 6| Step: 7
Training loss: 0.10078842651335666
Validation loss: 2.3595322397164686

Epoch: 6| Step: 8
Training loss: 0.17338214411864752
Validation loss: 2.346661813238666

Epoch: 6| Step: 9
Training loss: 0.12504219296751495
Validation loss: 2.335101184892791

Epoch: 6| Step: 10
Training loss: 0.11596792923223882
Validation loss: 2.334222093276205

Epoch: 6| Step: 11
Training loss: 0.1643546319170731
Validation loss: 2.3163680762895744

Epoch: 6| Step: 12
Training loss: 0.1785394126852934
Validation loss: 2.34224429969851

Epoch: 6| Step: 13
Training loss: 0.09578866444526701
Validation loss: 2.352025812864948

Epoch: 595| Step: 0
Training loss: 0.09967454012871624
Validation loss: 2.364193376271289

Epoch: 6| Step: 1
Training loss: 0.0996055181541995
Validation loss: 2.3715556697035725

Epoch: 6| Step: 2
Training loss: 0.1055249576556544
Validation loss: 2.3708318285325722

Epoch: 6| Step: 3
Training loss: 0.13379962907260035
Validation loss: 2.3512959027830447

Epoch: 6| Step: 4
Training loss: 0.25633918384901705
Validation loss: 2.365056752736264

Epoch: 6| Step: 5
Training loss: 0.08152777707330797
Validation loss: 2.3616898911467965

Epoch: 6| Step: 6
Training loss: 0.1309832584365822
Validation loss: 2.3547121273266005

Epoch: 6| Step: 7
Training loss: 0.0976038506118369
Validation loss: 2.3607669107324343

Epoch: 6| Step: 8
Training loss: 0.1119281302260084
Validation loss: 2.356629512023633

Epoch: 6| Step: 9
Training loss: 0.08020560654220307
Validation loss: 2.3388800096842224

Epoch: 6| Step: 10
Training loss: 0.13671474450919605
Validation loss: 2.319808687052539

Epoch: 6| Step: 11
Training loss: 0.12855489849628485
Validation loss: 2.3120526848684757

Epoch: 6| Step: 12
Training loss: 0.09721897454268036
Validation loss: 2.3242233341123923

Epoch: 6| Step: 13
Training loss: 0.11152116870075503
Validation loss: 2.301192317263175

Epoch: 596| Step: 0
Training loss: 0.11074571351588884
Validation loss: 2.315051991233633

Epoch: 6| Step: 1
Training loss: 0.15049970064893842
Validation loss: 2.3116347565829063

Epoch: 6| Step: 2
Training loss: 0.2401066417249322
Validation loss: 2.3161866971928955

Epoch: 6| Step: 3
Training loss: 0.12124049232384798
Validation loss: 2.3373587760841734

Epoch: 6| Step: 4
Training loss: 0.0908628897179834
Validation loss: 2.296789617948691

Epoch: 6| Step: 5
Training loss: 0.08846785353014701
Validation loss: 2.3053156985699026

Epoch: 6| Step: 6
Training loss: 0.17097550425595265
Validation loss: 2.3241025723817987

Epoch: 6| Step: 7
Training loss: 0.10147157597167776
Validation loss: 2.3608022750435986

Epoch: 6| Step: 8
Training loss: 0.15822655304170524
Validation loss: 2.33670147126634

Epoch: 6| Step: 9
Training loss: 0.11489263875808121
Validation loss: 2.3352294753182616

Epoch: 6| Step: 10
Training loss: 0.1733954004793892
Validation loss: 2.354058929585841

Epoch: 6| Step: 11
Training loss: 0.12472741386870893
Validation loss: 2.3301956280121416

Epoch: 6| Step: 12
Training loss: 0.07487172317777674
Validation loss: 2.3141431693776227

Epoch: 6| Step: 13
Training loss: 0.13690555616828592
Validation loss: 2.2900420699666224

Epoch: 597| Step: 0
Training loss: 0.11365309065202807
Validation loss: 2.3158125744074964

Epoch: 6| Step: 1
Training loss: 0.08699086364266345
Validation loss: 2.3235181503112177

Epoch: 6| Step: 2
Training loss: 0.07965437490456956
Validation loss: 2.2945990191817573

Epoch: 6| Step: 3
Training loss: 0.07349496138037681
Validation loss: 2.309143617236626

Epoch: 6| Step: 4
Training loss: 0.21191227819860584
Validation loss: 2.3106191885926908

Epoch: 6| Step: 5
Training loss: 0.10061843125008314
Validation loss: 2.3302612139235013

Epoch: 6| Step: 6
Training loss: 0.09430203233282987
Validation loss: 2.3497043897584424

Epoch: 6| Step: 7
Training loss: 0.07935653612572423
Validation loss: 2.3597676407422834

Epoch: 6| Step: 8
Training loss: 0.1644215288413251
Validation loss: 2.3717977727374215

Epoch: 6| Step: 9
Training loss: 0.17275967283743338
Validation loss: 2.3959465643906217

Epoch: 6| Step: 10
Training loss: 0.11842181333995018
Validation loss: 2.3610027880333835

Epoch: 6| Step: 11
Training loss: 0.09372916089349935
Validation loss: 2.3684649969703013

Epoch: 6| Step: 12
Training loss: 0.10698016559096692
Validation loss: 2.373092243519312

Epoch: 6| Step: 13
Training loss: 0.0888784055650888
Validation loss: 2.387705596264851

Epoch: 598| Step: 0
Training loss: 0.0810658378285205
Validation loss: 2.351305042831157

Epoch: 6| Step: 1
Training loss: 0.10358578625443636
Validation loss: 2.3466116140380326

Epoch: 6| Step: 2
Training loss: 0.15544562119817903
Validation loss: 2.3108726552438497

Epoch: 6| Step: 3
Training loss: 0.14913042110508362
Validation loss: 2.3143788863841115

Epoch: 6| Step: 4
Training loss: 0.12179897669899048
Validation loss: 2.3251514416807777

Epoch: 6| Step: 5
Training loss: 0.16584891195082654
Validation loss: 2.335411218543875

Epoch: 6| Step: 6
Training loss: 0.10092689539648779
Validation loss: 2.3191522458384206

Epoch: 6| Step: 7
Training loss: 0.18944561343688485
Validation loss: 2.2733108975220517

Epoch: 6| Step: 8
Training loss: 0.1339574019304271
Validation loss: 2.335976923281578

Epoch: 6| Step: 9
Training loss: 0.17580733105770124
Validation loss: 2.295200076794558

Epoch: 6| Step: 10
Training loss: 0.13465175793888765
Validation loss: 2.332997995296001

Epoch: 6| Step: 11
Training loss: 0.15467881963438126
Validation loss: 2.3198940131320485

Epoch: 6| Step: 12
Training loss: 0.22577815103219087
Validation loss: 2.3015735207225396

Epoch: 6| Step: 13
Training loss: 0.10312906549849699
Validation loss: 2.315516455925605

Epoch: 599| Step: 0
Training loss: 0.08729548555135187
Validation loss: 2.332577650217958

Epoch: 6| Step: 1
Training loss: 0.11949280372977007
Validation loss: 2.327057260423116

Epoch: 6| Step: 2
Training loss: 0.24894009111651993
Validation loss: 2.383804086189166

Epoch: 6| Step: 3
Training loss: 0.10301622900285995
Validation loss: 2.364020004342178

Epoch: 6| Step: 4
Training loss: 0.1657688663146712
Validation loss: 2.3700975019031216

Epoch: 6| Step: 5
Training loss: 0.10594730947871413
Validation loss: 2.337012419211548

Epoch: 6| Step: 6
Training loss: 0.10832948467711423
Validation loss: 2.364528589959803

Epoch: 6| Step: 7
Training loss: 0.13348021674463817
Validation loss: 2.3486420142143363

Epoch: 6| Step: 8
Training loss: 0.08737547690612024
Validation loss: 2.328118342370601

Epoch: 6| Step: 9
Training loss: 0.1580338809054806
Validation loss: 2.3542764979108233

Epoch: 6| Step: 10
Training loss: 0.12710571655419975
Validation loss: 2.3184745500033026

Epoch: 6| Step: 11
Training loss: 0.18063956429657033
Validation loss: 2.3601338014480993

Epoch: 6| Step: 12
Training loss: 0.13706892672186397
Validation loss: 2.3081153190790986

Epoch: 6| Step: 13
Training loss: 0.10983945800188229
Validation loss: 2.3461689821270566

Epoch: 600| Step: 0
Training loss: 0.12606726936789767
Validation loss: 2.332411260477645

Epoch: 6| Step: 1
Training loss: 0.16789228339993742
Validation loss: 2.3376344377015648

Epoch: 6| Step: 2
Training loss: 0.1321183887702504
Validation loss: 2.309853545211289

Epoch: 6| Step: 3
Training loss: 0.15085364565447412
Validation loss: 2.350943913575405

Epoch: 6| Step: 4
Training loss: 0.11869640474150227
Validation loss: 2.3327743344835894

Epoch: 6| Step: 5
Training loss: 0.10129192880796382
Validation loss: 2.36358421727501

Epoch: 6| Step: 6
Training loss: 0.10787003405601478
Validation loss: 2.3428653833269304

Epoch: 6| Step: 7
Training loss: 0.11703447045910598
Validation loss: 2.34395483181543

Epoch: 6| Step: 8
Training loss: 0.09182886824178059
Validation loss: 2.364040398254982

Epoch: 6| Step: 9
Training loss: 0.08425463672236214
Validation loss: 2.3643633297548856

Epoch: 6| Step: 10
Training loss: 0.19908223430122074
Validation loss: 2.3339963793461957

Epoch: 6| Step: 11
Training loss: 0.08250611100177545
Validation loss: 2.3702634060377195

Epoch: 6| Step: 12
Training loss: 0.12597351661962494
Validation loss: 2.368668520595882

Epoch: 6| Step: 13
Training loss: 0.08883419053061933
Validation loss: 2.362660910265844

Epoch: 601| Step: 0
Training loss: 0.12963920348897148
Validation loss: 2.3604581710218695

Epoch: 6| Step: 1
Training loss: 0.0974026199728547
Validation loss: 2.380313803009385

Epoch: 6| Step: 2
Training loss: 0.08697139263627202
Validation loss: 2.3353500914438188

Epoch: 6| Step: 3
Training loss: 0.1444318274750436
Validation loss: 2.357116802907752

Epoch: 6| Step: 4
Training loss: 0.16486844153587776
Validation loss: 2.307822440291905

Epoch: 6| Step: 5
Training loss: 0.11490367863340233
Validation loss: 2.3286324555215123

Epoch: 6| Step: 6
Training loss: 0.09760401282337378
Validation loss: 2.3468924115108045

Epoch: 6| Step: 7
Training loss: 0.09327458996855179
Validation loss: 2.3266410880312502

Epoch: 6| Step: 8
Training loss: 0.09986633927281159
Validation loss: 2.3652409314076333

Epoch: 6| Step: 9
Training loss: 0.1967900937022433
Validation loss: 2.3509823873255717

Epoch: 6| Step: 10
Training loss: 0.12777270083330233
Validation loss: 2.3446363571054953

Epoch: 6| Step: 11
Training loss: 0.14383039144277068
Validation loss: 2.3357171941709516

Epoch: 6| Step: 12
Training loss: 0.15386768598589562
Validation loss: 2.330944596109743

Epoch: 6| Step: 13
Training loss: 0.10125154337324821
Validation loss: 2.331483288433708

Epoch: 602| Step: 0
Training loss: 0.13004823060516818
Validation loss: 2.345550455910754

Epoch: 6| Step: 1
Training loss: 0.08609631612885772
Validation loss: 2.31483982978713

Epoch: 6| Step: 2
Training loss: 0.08328473796393239
Validation loss: 2.3217569810798993

Epoch: 6| Step: 3
Training loss: 0.16582615081609772
Validation loss: 2.3255737799882032

Epoch: 6| Step: 4
Training loss: 0.08287430292443371
Validation loss: 2.3150138317361066

Epoch: 6| Step: 5
Training loss: 0.07941754829779901
Validation loss: 2.332241722251876

Epoch: 6| Step: 6
Training loss: 0.15194962946149002
Validation loss: 2.3429105779969452

Epoch: 6| Step: 7
Training loss: 0.14255326197978654
Validation loss: 2.3204181937512383

Epoch: 6| Step: 8
Training loss: 0.10301551931784585
Validation loss: 2.3329785549893884

Epoch: 6| Step: 9
Training loss: 0.18072151095494204
Validation loss: 2.3093373490023947

Epoch: 6| Step: 10
Training loss: 0.11268731738444387
Validation loss: 2.332600916633018

Epoch: 6| Step: 11
Training loss: 0.1336110246097219
Validation loss: 2.3479298281087586

Epoch: 6| Step: 12
Training loss: 0.13268056094083097
Validation loss: 2.326936625383769

Epoch: 6| Step: 13
Training loss: 0.09536328115968357
Validation loss: 2.3179360186043425

Epoch: 603| Step: 0
Training loss: 0.08955415929415408
Validation loss: 2.3445513754654437

Epoch: 6| Step: 1
Training loss: 0.16999369232663147
Validation loss: 2.32575783637285

Epoch: 6| Step: 2
Training loss: 0.181877945125632
Validation loss: 2.3160613854902032

Epoch: 6| Step: 3
Training loss: 0.12930601439199407
Validation loss: 2.3524398881223365

Epoch: 6| Step: 4
Training loss: 0.14802094411096403
Validation loss: 2.3326103002869316

Epoch: 6| Step: 5
Training loss: 0.12057164138657811
Validation loss: 2.3436578329142046

Epoch: 6| Step: 6
Training loss: 0.117254087285884
Validation loss: 2.337282324918955

Epoch: 6| Step: 7
Training loss: 0.12768057964867327
Validation loss: 2.3337194838112403

Epoch: 6| Step: 8
Training loss: 0.12616449576609437
Validation loss: 2.345160954219748

Epoch: 6| Step: 9
Training loss: 0.08891521455591406
Validation loss: 2.3367386775820744

Epoch: 6| Step: 10
Training loss: 0.10519868659732313
Validation loss: 2.375876943755634

Epoch: 6| Step: 11
Training loss: 0.19376989577799053
Validation loss: 2.3568084797186333

Epoch: 6| Step: 12
Training loss: 0.12660763018320417
Validation loss: 2.3566808064806994

Epoch: 6| Step: 13
Training loss: 0.10145246064858505
Validation loss: 2.32830709849291

Epoch: 604| Step: 0
Training loss: 0.11811164213397464
Validation loss: 2.33449860798629

Epoch: 6| Step: 1
Training loss: 0.09962592267981644
Validation loss: 2.3495899993035128

Epoch: 6| Step: 2
Training loss: 0.1713854471795277
Validation loss: 2.2987725948886393

Epoch: 6| Step: 3
Training loss: 0.11015903929297012
Validation loss: 2.317276930517206

Epoch: 6| Step: 4
Training loss: 0.17523733334673872
Validation loss: 2.2818756245810237

Epoch: 6| Step: 5
Training loss: 0.08937805182241673
Validation loss: 2.2925870223744544

Epoch: 6| Step: 6
Training loss: 0.1864078623021658
Validation loss: 2.2805912669827713

Epoch: 6| Step: 7
Training loss: 0.11642431256629063
Validation loss: 2.2530394406319036

Epoch: 6| Step: 8
Training loss: 0.1712560128110061
Validation loss: 2.2711123765156156

Epoch: 6| Step: 9
Training loss: 0.177524327253118
Validation loss: 2.2770906098467023

Epoch: 6| Step: 10
Training loss: 0.14847222975962926
Validation loss: 2.2553635359360364

Epoch: 6| Step: 11
Training loss: 0.08932121850318897
Validation loss: 2.256292255208069

Epoch: 6| Step: 12
Training loss: 0.09512915056261723
Validation loss: 2.299271787995528

Epoch: 6| Step: 13
Training loss: 0.12812371137017514
Validation loss: 2.2965639785694125

Epoch: 605| Step: 0
Training loss: 0.16310506126070606
Validation loss: 2.336817489865216

Epoch: 6| Step: 1
Training loss: 0.1869661360284887
Validation loss: 2.3248880957274314

Epoch: 6| Step: 2
Training loss: 0.1330289199370552
Validation loss: 2.3510182161343978

Epoch: 6| Step: 3
Training loss: 0.06782239772489905
Validation loss: 2.3745265514697493

Epoch: 6| Step: 4
Training loss: 0.23844060103373488
Validation loss: 2.342107258106082

Epoch: 6| Step: 5
Training loss: 0.07680105515218695
Validation loss: 2.33387738981199

Epoch: 6| Step: 6
Training loss: 0.10283320336611221
Validation loss: 2.337111778762834

Epoch: 6| Step: 7
Training loss: 0.12579898738781412
Validation loss: 2.3454635787560885

Epoch: 6| Step: 8
Training loss: 0.15008901100850003
Validation loss: 2.3487251876713855

Epoch: 6| Step: 9
Training loss: 0.06968648704511073
Validation loss: 2.364789775860378

Epoch: 6| Step: 10
Training loss: 0.14490959547309518
Validation loss: 2.3658153523944763

Epoch: 6| Step: 11
Training loss: 0.1686328247119792
Validation loss: 2.339868612268788

Epoch: 6| Step: 12
Training loss: 0.15284545522607054
Validation loss: 2.368035185436026

Epoch: 6| Step: 13
Training loss: 0.06755033690722746
Validation loss: 2.363943693153776

Epoch: 606| Step: 0
Training loss: 0.16898046249149426
Validation loss: 2.3748087220380305

Epoch: 6| Step: 1
Training loss: 0.13469548404201004
Validation loss: 2.375862404331978

Epoch: 6| Step: 2
Training loss: 0.09934532003461029
Validation loss: 2.3577364783276176

Epoch: 6| Step: 3
Training loss: 0.0924585066581773
Validation loss: 2.325193732547443

Epoch: 6| Step: 4
Training loss: 0.10736496891931917
Validation loss: 2.3431249768205857

Epoch: 6| Step: 5
Training loss: 0.13147869451427271
Validation loss: 2.329491192348272

Epoch: 6| Step: 6
Training loss: 0.13885338415548765
Validation loss: 2.321716301580351

Epoch: 6| Step: 7
Training loss: 0.1808679615726065
Validation loss: 2.31419342925372

Epoch: 6| Step: 8
Training loss: 0.1416161759826998
Validation loss: 2.3137860002454502

Epoch: 6| Step: 9
Training loss: 0.07344513432408399
Validation loss: 2.3078432563843285

Epoch: 6| Step: 10
Training loss: 0.14948699766729046
Validation loss: 2.2868113227881635

Epoch: 6| Step: 11
Training loss: 0.14977158052545764
Validation loss: 2.282921677403593

Epoch: 6| Step: 12
Training loss: 0.11117546590446226
Validation loss: 2.3012757663637076

Epoch: 6| Step: 13
Training loss: 0.05827707906287428
Validation loss: 2.2972036426124145

Epoch: 607| Step: 0
Training loss: 0.07672038718980316
Validation loss: 2.289497320470553

Epoch: 6| Step: 1
Training loss: 0.09605726580671259
Validation loss: 2.3041099017827165

Epoch: 6| Step: 2
Training loss: 0.17969893336202417
Validation loss: 2.3111550672419052

Epoch: 6| Step: 3
Training loss: 0.16415025997797783
Validation loss: 2.3097947778772774

Epoch: 6| Step: 4
Training loss: 0.09067990103471595
Validation loss: 2.324523781124735

Epoch: 6| Step: 5
Training loss: 0.16351293298261405
Validation loss: 2.3162056406269906

Epoch: 6| Step: 6
Training loss: 0.10775428406132477
Validation loss: 2.312870402272764

Epoch: 6| Step: 7
Training loss: 0.1412589367533317
Validation loss: 2.3433420221332217

Epoch: 6| Step: 8
Training loss: 0.103569907225102
Validation loss: 2.3428181535657915

Epoch: 6| Step: 9
Training loss: 0.12840696657574538
Validation loss: 2.324921911804751

Epoch: 6| Step: 10
Training loss: 0.10722324473905974
Validation loss: 2.336662070083304

Epoch: 6| Step: 11
Training loss: 0.15457859154992032
Validation loss: 2.339112254646644

Epoch: 6| Step: 12
Training loss: 0.08339922567347996
Validation loss: 2.339861050187667

Epoch: 6| Step: 13
Training loss: 0.09848652746495284
Validation loss: 2.333113912367701

Epoch: 608| Step: 0
Training loss: 0.09507119517904437
Validation loss: 2.3430604504164405

Epoch: 6| Step: 1
Training loss: 0.10692246261562312
Validation loss: 2.332520357213329

Epoch: 6| Step: 2
Training loss: 0.1116042894611724
Validation loss: 2.31997818684463

Epoch: 6| Step: 3
Training loss: 0.1918643024892015
Validation loss: 2.312490216572339

Epoch: 6| Step: 4
Training loss: 0.09876344547000226
Validation loss: 2.3367669552145722

Epoch: 6| Step: 5
Training loss: 0.09917335823600314
Validation loss: 2.3030878905290657

Epoch: 6| Step: 6
Training loss: 0.09923056021559525
Validation loss: 2.3167809900897622

Epoch: 6| Step: 7
Training loss: 0.1438038149942073
Validation loss: 2.3329235264915966

Epoch: 6| Step: 8
Training loss: 0.10684625551377151
Validation loss: 2.3196420925730132

Epoch: 6| Step: 9
Training loss: 0.09803527710242893
Validation loss: 2.297715523895645

Epoch: 6| Step: 10
Training loss: 0.12889541956168885
Validation loss: 2.282752835651443

Epoch: 6| Step: 11
Training loss: 0.08223023010011969
Validation loss: 2.2998943182414733

Epoch: 6| Step: 12
Training loss: 0.12004590439220979
Validation loss: 2.3110334551316285

Epoch: 6| Step: 13
Training loss: 0.12011571433551815
Validation loss: 2.278440093753452

Epoch: 609| Step: 0
Training loss: 0.11672724303531053
Validation loss: 2.322681633814322

Epoch: 6| Step: 1
Training loss: 0.13281600610929623
Validation loss: 2.3207149483227303

Epoch: 6| Step: 2
Training loss: 0.07404752480333868
Validation loss: 2.3079825057594077

Epoch: 6| Step: 3
Training loss: 0.06450362105887805
Validation loss: 2.3075807548130163

Epoch: 6| Step: 4
Training loss: 0.11704835578267965
Validation loss: 2.3270821171878002

Epoch: 6| Step: 5
Training loss: 0.07599518530544584
Validation loss: 2.2938453114235657

Epoch: 6| Step: 6
Training loss: 0.15103669542046072
Validation loss: 2.3352095963462824

Epoch: 6| Step: 7
Training loss: 0.07956223506314021
Validation loss: 2.332171664778378

Epoch: 6| Step: 8
Training loss: 0.10926665747296682
Validation loss: 2.3215629070326353

Epoch: 6| Step: 9
Training loss: 0.047629248677370194
Validation loss: 2.323534367209959

Epoch: 6| Step: 10
Training loss: 0.07659844326008138
Validation loss: 2.3251780873207704

Epoch: 6| Step: 11
Training loss: 0.07539739948926201
Validation loss: 2.31689293401867

Epoch: 6| Step: 12
Training loss: 0.15832343060076895
Validation loss: 2.296331003446289

Epoch: 6| Step: 13
Training loss: 0.08385298120458393
Validation loss: 2.3245940978979323

Epoch: 610| Step: 0
Training loss: 0.051009234923460364
Validation loss: 2.300867924038821

Epoch: 6| Step: 1
Training loss: 0.13895145627890781
Validation loss: 2.305408222291872

Epoch: 6| Step: 2
Training loss: 0.08329699016857182
Validation loss: 2.302184010334116

Epoch: 6| Step: 3
Training loss: 0.08910371930807813
Validation loss: 2.3157098936671208

Epoch: 6| Step: 4
Training loss: 0.14229197724696158
Validation loss: 2.3053290279150986

Epoch: 6| Step: 5
Training loss: 0.07923863743492073
Validation loss: 2.314802219434081

Epoch: 6| Step: 6
Training loss: 0.14770182456224212
Validation loss: 2.3372464577534378

Epoch: 6| Step: 7
Training loss: 0.11532067445659824
Validation loss: 2.2980205019726343

Epoch: 6| Step: 8
Training loss: 0.08591219139229628
Validation loss: 2.298396072521289

Epoch: 6| Step: 9
Training loss: 0.1607597714582995
Validation loss: 2.309398745570514

Epoch: 6| Step: 10
Training loss: 0.08975209868787885
Validation loss: 2.286213063184033

Epoch: 6| Step: 11
Training loss: 0.0849517510369495
Validation loss: 2.2912402213965732

Epoch: 6| Step: 12
Training loss: 0.08975352027226671
Validation loss: 2.2991330407924537

Epoch: 6| Step: 13
Training loss: 0.09096942473960366
Validation loss: 2.2689241020737865

Epoch: 611| Step: 0
Training loss: 0.10887292594965227
Validation loss: 2.2698791778286695

Epoch: 6| Step: 1
Training loss: 0.14547055042558094
Validation loss: 2.288790337670089

Epoch: 6| Step: 2
Training loss: 0.06519968615284336
Validation loss: 2.2852767756892587

Epoch: 6| Step: 3
Training loss: 0.0788626654331312
Validation loss: 2.2823006725867

Epoch: 6| Step: 4
Training loss: 0.15392555149672563
Validation loss: 2.2903797962732124

Epoch: 6| Step: 5
Training loss: 0.10809126280751633
Validation loss: 2.269093177992807

Epoch: 6| Step: 6
Training loss: 0.09524021788707013
Validation loss: 2.282360607258143

Epoch: 6| Step: 7
Training loss: 0.10495271981356895
Validation loss: 2.276578909110259

Epoch: 6| Step: 8
Training loss: 0.0888594215269522
Validation loss: 2.309786865943393

Epoch: 6| Step: 9
Training loss: 0.12665806741396468
Validation loss: 2.282443902470467

Epoch: 6| Step: 10
Training loss: 0.14094285672489898
Validation loss: 2.300661257973588

Epoch: 6| Step: 11
Training loss: 0.07876122515296281
Validation loss: 2.297356340864408

Epoch: 6| Step: 12
Training loss: 0.10029951072387648
Validation loss: 2.298328192480843

Epoch: 6| Step: 13
Training loss: 0.06840041155011611
Validation loss: 2.3481428690251254

Epoch: 612| Step: 0
Training loss: 0.10925036379395676
Validation loss: 2.3228601693179995

Epoch: 6| Step: 1
Training loss: 0.13700157611960104
Validation loss: 2.326160450752132

Epoch: 6| Step: 2
Training loss: 0.06763166968909284
Validation loss: 2.327732132179647

Epoch: 6| Step: 3
Training loss: 0.10639567486479992
Validation loss: 2.3150981779021165

Epoch: 6| Step: 4
Training loss: 0.10280943601471904
Validation loss: 2.293340910036707

Epoch: 6| Step: 5
Training loss: 0.12110761593833215
Validation loss: 2.3145288327210656

Epoch: 6| Step: 6
Training loss: 0.09127964233972996
Validation loss: 2.329939376173616

Epoch: 6| Step: 7
Training loss: 0.0703436795615204
Validation loss: 2.31327563700098

Epoch: 6| Step: 8
Training loss: 0.21529332719212563
Validation loss: 2.2868274244404727

Epoch: 6| Step: 9
Training loss: 0.10502618193607184
Validation loss: 2.2978032256532814

Epoch: 6| Step: 10
Training loss: 0.1420541829982053
Validation loss: 2.2890275709435635

Epoch: 6| Step: 11
Training loss: 0.10943319271244965
Validation loss: 2.3324528481717195

Epoch: 6| Step: 12
Training loss: 0.09112047512524576
Validation loss: 2.3273219989185567

Epoch: 6| Step: 13
Training loss: 0.0692347742222851
Validation loss: 2.3128353364653367

Epoch: 613| Step: 0
Training loss: 0.07252524432263943
Validation loss: 2.330611975267143

Epoch: 6| Step: 1
Training loss: 0.17056419384228164
Validation loss: 2.3220175438595017

Epoch: 6| Step: 2
Training loss: 0.09622169637365828
Validation loss: 2.315777000188108

Epoch: 6| Step: 3
Training loss: 0.15169754893775186
Validation loss: 2.3595885498178464

Epoch: 6| Step: 4
Training loss: 0.049929816938103264
Validation loss: 2.3478110271625305

Epoch: 6| Step: 5
Training loss: 0.046927085390277894
Validation loss: 2.336937937913593

Epoch: 6| Step: 6
Training loss: 0.10395292814727222
Validation loss: 2.3497757563164603

Epoch: 6| Step: 7
Training loss: 0.09091681306557242
Validation loss: 2.378134056941752

Epoch: 6| Step: 8
Training loss: 0.08477214137752766
Validation loss: 2.3322056214752793

Epoch: 6| Step: 9
Training loss: 0.1663906013939395
Validation loss: 2.350827934559428

Epoch: 6| Step: 10
Training loss: 0.12347564470045978
Validation loss: 2.3086398321213393

Epoch: 6| Step: 11
Training loss: 0.07222873158393082
Validation loss: 2.3283823161124593

Epoch: 6| Step: 12
Training loss: 0.1068467785009127
Validation loss: 2.3046078158744674

Epoch: 6| Step: 13
Training loss: 0.06255640896695898
Validation loss: 2.314013897144993

Epoch: 614| Step: 0
Training loss: 0.13410645447944014
Validation loss: 2.325004984991115

Epoch: 6| Step: 1
Training loss: 0.1526239398334464
Validation loss: 2.317379241472243

Epoch: 6| Step: 2
Training loss: 0.09118322445622624
Validation loss: 2.336967026008287

Epoch: 6| Step: 3
Training loss: 0.1048774435491256
Validation loss: 2.3189299161358905

Epoch: 6| Step: 4
Training loss: 0.14367087197381478
Validation loss: 2.332641688763576

Epoch: 6| Step: 5
Training loss: 0.131028450444467
Validation loss: 2.3160370834463113

Epoch: 6| Step: 6
Training loss: 0.07658170220854785
Validation loss: 2.3094587185183917

Epoch: 6| Step: 7
Training loss: 0.14740452097731305
Validation loss: 2.3087575329087393

Epoch: 6| Step: 8
Training loss: 0.12894106163684493
Validation loss: 2.3199399967659016

Epoch: 6| Step: 9
Training loss: 0.12653825904500207
Validation loss: 2.317255872802037

Epoch: 6| Step: 10
Training loss: 0.10479307082577172
Validation loss: 2.3239642833878573

Epoch: 6| Step: 11
Training loss: 0.051797577139754504
Validation loss: 2.335351607442033

Epoch: 6| Step: 12
Training loss: 0.11223543768688603
Validation loss: 2.3164394561452104

Epoch: 6| Step: 13
Training loss: 0.11779819547770999
Validation loss: 2.35992420304672

Epoch: 615| Step: 0
Training loss: 0.11119195490704582
Validation loss: 2.2950979924396573

Epoch: 6| Step: 1
Training loss: 0.1715099076747051
Validation loss: 2.3288392254734487

Epoch: 6| Step: 2
Training loss: 0.08025307849634473
Validation loss: 2.3262600236502964

Epoch: 6| Step: 3
Training loss: 0.13648120134023217
Validation loss: 2.3048735918708885

Epoch: 6| Step: 4
Training loss: 0.07678278451301401
Validation loss: 2.3271957170336837

Epoch: 6| Step: 5
Training loss: 0.058749512425641595
Validation loss: 2.2938636631809626

Epoch: 6| Step: 6
Training loss: 0.14367524100048296
Validation loss: 2.3077176538145117

Epoch: 6| Step: 7
Training loss: 0.14045589266184874
Validation loss: 2.3172038107239255

Epoch: 6| Step: 8
Training loss: 0.11800163707466368
Validation loss: 2.2883494374318496

Epoch: 6| Step: 9
Training loss: 0.10100789128295366
Validation loss: 2.3276145955329497

Epoch: 6| Step: 10
Training loss: 0.14241941319115067
Validation loss: 2.3171300236852646

Epoch: 6| Step: 11
Training loss: 0.14109639789466585
Validation loss: 2.3190634080475947

Epoch: 6| Step: 12
Training loss: 0.08416416916893142
Validation loss: 2.3391955274829757

Epoch: 6| Step: 13
Training loss: 0.11394031541817384
Validation loss: 2.325719602861702

Epoch: 616| Step: 0
Training loss: 0.08673620241693737
Validation loss: 2.3655880617640714

Epoch: 6| Step: 1
Training loss: 0.1655778160902286
Validation loss: 2.3482578758341677

Epoch: 6| Step: 2
Training loss: 0.07743348806339663
Validation loss: 2.3418810354107653

Epoch: 6| Step: 3
Training loss: 0.14318882128323607
Validation loss: 2.355691973392577

Epoch: 6| Step: 4
Training loss: 0.15124555438381057
Validation loss: 2.336833855823295

Epoch: 6| Step: 5
Training loss: 0.13935289253574934
Validation loss: 2.3308617384639145

Epoch: 6| Step: 6
Training loss: 0.1453826673360294
Validation loss: 2.2866242873378098

Epoch: 6| Step: 7
Training loss: 0.09472133681050743
Validation loss: 2.2847472498047683

Epoch: 6| Step: 8
Training loss: 0.13496934309756453
Validation loss: 2.30994478650077

Epoch: 6| Step: 9
Training loss: 0.10741480457272372
Validation loss: 2.287043230906668

Epoch: 6| Step: 10
Training loss: 0.13503834178843688
Validation loss: 2.300799431110861

Epoch: 6| Step: 11
Training loss: 0.09797384118049189
Validation loss: 2.280289000702038

Epoch: 6| Step: 12
Training loss: 0.13162439823601765
Validation loss: 2.250197352364676

Epoch: 6| Step: 13
Training loss: 0.07861153973848028
Validation loss: 2.285080108762378

Epoch: 617| Step: 0
Training loss: 0.1063143992551509
Validation loss: 2.287989096666547

Epoch: 6| Step: 1
Training loss: 0.1187486924551202
Validation loss: 2.257719658888235

Epoch: 6| Step: 2
Training loss: 0.09295772519177023
Validation loss: 2.242696066911148

Epoch: 6| Step: 3
Training loss: 0.07427886673948032
Validation loss: 2.289522326357004

Epoch: 6| Step: 4
Training loss: 0.1010367374676208
Validation loss: 2.3042798398706896

Epoch: 6| Step: 5
Training loss: 0.14587689001866028
Validation loss: 2.3092311802747374

Epoch: 6| Step: 6
Training loss: 0.09719959300322939
Validation loss: 2.3126873238700414

Epoch: 6| Step: 7
Training loss: 0.09983771462623392
Validation loss: 2.304647154374081

Epoch: 6| Step: 8
Training loss: 0.16946657063248619
Validation loss: 2.320940433998068

Epoch: 6| Step: 9
Training loss: 0.09970208136127849
Validation loss: 2.3280466455649385

Epoch: 6| Step: 10
Training loss: 0.11842259978246097
Validation loss: 2.3271515336098556

Epoch: 6| Step: 11
Training loss: 0.148038314833553
Validation loss: 2.3500841949302282

Epoch: 6| Step: 12
Training loss: 0.1482298301803454
Validation loss: 2.3353953848964277

Epoch: 6| Step: 13
Training loss: 0.13299196403738764
Validation loss: 2.3268997388396024

Epoch: 618| Step: 0
Training loss: 0.09153643653764461
Validation loss: 2.3560124213718594

Epoch: 6| Step: 1
Training loss: 0.14617494963200933
Validation loss: 2.3284436310874956

Epoch: 6| Step: 2
Training loss: 0.1734145903277056
Validation loss: 2.303196633158105

Epoch: 6| Step: 3
Training loss: 0.08173008824149433
Validation loss: 2.316801812001401

Epoch: 6| Step: 4
Training loss: 0.08750899164372439
Validation loss: 2.3107712460699568

Epoch: 6| Step: 5
Training loss: 0.1264578916781829
Validation loss: 2.310405076071068

Epoch: 6| Step: 6
Training loss: 0.10468441225594002
Validation loss: 2.306267762101154

Epoch: 6| Step: 7
Training loss: 0.13567980698275867
Validation loss: 2.287798502203481

Epoch: 6| Step: 8
Training loss: 0.10048041780954929
Validation loss: 2.3178505408109475

Epoch: 6| Step: 9
Training loss: 0.11179087068253861
Validation loss: 2.3483658996124523

Epoch: 6| Step: 10
Training loss: 0.1489503808888716
Validation loss: 2.328321945340277

Epoch: 6| Step: 11
Training loss: 0.16498816568749147
Validation loss: 2.306852435880697

Epoch: 6| Step: 12
Training loss: 0.06989507481229285
Validation loss: 2.3274919753607484

Epoch: 6| Step: 13
Training loss: 0.11541585452075775
Validation loss: 2.3159592299573974

Epoch: 619| Step: 0
Training loss: 0.11371599828897891
Validation loss: 2.3116806061892934

Epoch: 6| Step: 1
Training loss: 0.09437558938151862
Validation loss: 2.3252699725790555

Epoch: 6| Step: 2
Training loss: 0.1400005263612423
Validation loss: 2.30956702798513

Epoch: 6| Step: 3
Training loss: 0.08878936608930142
Validation loss: 2.2910200875574724

Epoch: 6| Step: 4
Training loss: 0.16767576636445963
Validation loss: 2.34308460703053

Epoch: 6| Step: 5
Training loss: 0.09537124015832804
Validation loss: 2.3242737609579627

Epoch: 6| Step: 6
Training loss: 0.11658568026493772
Validation loss: 2.355825337172163

Epoch: 6| Step: 7
Training loss: 0.129276351221784
Validation loss: 2.326243724364126

Epoch: 6| Step: 8
Training loss: 0.15940816548214978
Validation loss: 2.333273682696141

Epoch: 6| Step: 9
Training loss: 0.12287967160173892
Validation loss: 2.313771665088574

Epoch: 6| Step: 10
Training loss: 0.09157244152317848
Validation loss: 2.3459547560432568

Epoch: 6| Step: 11
Training loss: 0.15590767315237766
Validation loss: 2.3446711195206835

Epoch: 6| Step: 12
Training loss: 0.1405094917415486
Validation loss: 2.38732821224422

Epoch: 6| Step: 13
Training loss: 0.19290462154193597
Validation loss: 2.381949368642418

Epoch: 620| Step: 0
Training loss: 0.18841566574541402
Validation loss: 2.3803765427848096

Epoch: 6| Step: 1
Training loss: 0.07489835636512132
Validation loss: 2.350387042343183

Epoch: 6| Step: 2
Training loss: 0.13886516156442363
Validation loss: 2.3411910506126246

Epoch: 6| Step: 3
Training loss: 0.1276187904567833
Validation loss: 2.3446820173163787

Epoch: 6| Step: 4
Training loss: 0.08316186746125662
Validation loss: 2.340040882390826

Epoch: 6| Step: 5
Training loss: 0.130849553209343
Validation loss: 2.3021243267189266

Epoch: 6| Step: 6
Training loss: 0.1893204293137927
Validation loss: 2.3473946435471285

Epoch: 6| Step: 7
Training loss: 0.21254269577704038
Validation loss: 2.3164314899896628

Epoch: 6| Step: 8
Training loss: 0.16527863331369844
Validation loss: 2.3133693201281105

Epoch: 6| Step: 9
Training loss: 0.06546646479485389
Validation loss: 2.335421857127107

Epoch: 6| Step: 10
Training loss: 0.11481976680362492
Validation loss: 2.34113488440066

Epoch: 6| Step: 11
Training loss: 0.09705584013296763
Validation loss: 2.3229003762942635

Epoch: 6| Step: 12
Training loss: 0.08900788456302747
Validation loss: 2.3386129193062235

Epoch: 6| Step: 13
Training loss: 0.06950605369907523
Validation loss: 2.3231835911130685

Epoch: 621| Step: 0
Training loss: 0.11627504840297015
Validation loss: 2.3414740753179686

Epoch: 6| Step: 1
Training loss: 0.10351094199330065
Validation loss: 2.3300879424035257

Epoch: 6| Step: 2
Training loss: 0.1382062104928207
Validation loss: 2.309791823877217

Epoch: 6| Step: 3
Training loss: 0.1355110505883636
Validation loss: 2.317668459195433

Epoch: 6| Step: 4
Training loss: 0.08399717100380726
Validation loss: 2.30716006025575

Epoch: 6| Step: 5
Training loss: 0.11547310395091247
Validation loss: 2.2970460168556293

Epoch: 6| Step: 6
Training loss: 0.14440263360891378
Validation loss: 2.2827334152641052

Epoch: 6| Step: 7
Training loss: 0.24257043589815797
Validation loss: 2.307063445020749

Epoch: 6| Step: 8
Training loss: 0.11823954417636064
Validation loss: 2.281017461868798

Epoch: 6| Step: 9
Training loss: 0.1408641688694247
Validation loss: 2.294395205863531

Epoch: 6| Step: 10
Training loss: 0.21371097172140865
Validation loss: 2.2832716020645596

Epoch: 6| Step: 11
Training loss: 0.17624619242261824
Validation loss: 2.306087071578207

Epoch: 6| Step: 12
Training loss: 0.4193988648004499
Validation loss: 2.2783757790481074

Epoch: 6| Step: 13
Training loss: 0.11307976743768536
Validation loss: 2.269381452901962

Epoch: 622| Step: 0
Training loss: 0.18970559198867834
Validation loss: 2.2388419738364815

Epoch: 6| Step: 1
Training loss: 0.16315196179868513
Validation loss: 2.2289904169285637

Epoch: 6| Step: 2
Training loss: 0.1878285509699196
Validation loss: 2.263417898963892

Epoch: 6| Step: 3
Training loss: 0.16356577495587682
Validation loss: 2.299346142538255

Epoch: 6| Step: 4
Training loss: 0.21428044772488203
Validation loss: 2.26732633004831

Epoch: 6| Step: 5
Training loss: 0.17256648591262488
Validation loss: 2.310654795067176

Epoch: 6| Step: 6
Training loss: 0.2421509961335974
Validation loss: 2.333534799688363

Epoch: 6| Step: 7
Training loss: 0.15083894539920822
Validation loss: 2.3639283455969995

Epoch: 6| Step: 8
Training loss: 0.256601756271914
Validation loss: 2.4283923624430868

Epoch: 6| Step: 9
Training loss: 0.2396226164844035
Validation loss: 2.457456530061328

Epoch: 6| Step: 10
Training loss: 0.27095276082320563
Validation loss: 2.443856924832607

Epoch: 6| Step: 11
Training loss: 0.21924901991204285
Validation loss: 2.4061349309355387

Epoch: 6| Step: 12
Training loss: 0.14632690867067671
Validation loss: 2.362461211348427

Epoch: 6| Step: 13
Training loss: 0.10867125314908943
Validation loss: 2.3535113876918032

Epoch: 623| Step: 0
Training loss: 0.19514827499709694
Validation loss: 2.276899195420953

Epoch: 6| Step: 1
Training loss: 0.19208884653473537
Validation loss: 2.2786770058651644

Epoch: 6| Step: 2
Training loss: 0.2093579794242689
Validation loss: 2.271142402502365

Epoch: 6| Step: 3
Training loss: 0.16464071334875596
Validation loss: 2.2365761815950953

Epoch: 6| Step: 4
Training loss: 0.14641865845638824
Validation loss: 2.2278597345921094

Epoch: 6| Step: 5
Training loss: 0.14652776711234386
Validation loss: 2.2407240389105194

Epoch: 6| Step: 6
Training loss: 0.1756497580073916
Validation loss: 2.1847981210808958

Epoch: 6| Step: 7
Training loss: 0.21261377444340868
Validation loss: 2.203934438107968

Epoch: 6| Step: 8
Training loss: 0.21017292764848317
Validation loss: 2.211396791762634

Epoch: 6| Step: 9
Training loss: 0.1953758613807839
Validation loss: 2.233850422279711

Epoch: 6| Step: 10
Training loss: 0.1290490630916164
Validation loss: 2.234220534272688

Epoch: 6| Step: 11
Training loss: 0.1761789062517863
Validation loss: 2.2954480848956815

Epoch: 6| Step: 12
Training loss: 0.10864739996678784
Validation loss: 2.291025396064871

Epoch: 6| Step: 13
Training loss: 0.10266282015580676
Validation loss: 2.34541451144308

Epoch: 624| Step: 0
Training loss: 0.22023313831199992
Validation loss: 2.364780581148635

Epoch: 6| Step: 1
Training loss: 0.284074783626146
Validation loss: 2.3678639819126532

Epoch: 6| Step: 2
Training loss: 0.16387758733509483
Validation loss: 2.3301647511834926

Epoch: 6| Step: 3
Training loss: 0.10523584929795009
Validation loss: 2.3168177196077657

Epoch: 6| Step: 4
Training loss: 0.1208882819056259
Validation loss: 2.277702723564732

Epoch: 6| Step: 5
Training loss: 0.08480277631689155
Validation loss: 2.268013844069248

Epoch: 6| Step: 6
Training loss: 0.12455080204329871
Validation loss: 2.2305865967015053

Epoch: 6| Step: 7
Training loss: 0.21321146525518644
Validation loss: 2.2631375981868174

Epoch: 6| Step: 8
Training loss: 0.17555117384973912
Validation loss: 2.22871705641522

Epoch: 6| Step: 9
Training loss: 0.22782648948865683
Validation loss: 2.230741109494242

Epoch: 6| Step: 10
Training loss: 0.12201140317453188
Validation loss: 2.2369900769215914

Epoch: 6| Step: 11
Training loss: 0.1508799185610887
Validation loss: 2.234009829712366

Epoch: 6| Step: 12
Training loss: 0.18572900767452377
Validation loss: 2.2678202634707336

Epoch: 6| Step: 13
Training loss: 0.15029532026071107
Validation loss: 2.270560875840546

Epoch: 625| Step: 0
Training loss: 0.10387431385316324
Validation loss: 2.320911927638733

Epoch: 6| Step: 1
Training loss: 0.1593748779857393
Validation loss: 2.344159639170958

Epoch: 6| Step: 2
Training loss: 0.19259525323491902
Validation loss: 2.3976212673495194

Epoch: 6| Step: 3
Training loss: 0.24220065111939804
Validation loss: 2.397058738717406

Epoch: 6| Step: 4
Training loss: 0.18239938527898245
Validation loss: 2.4527896672549794

Epoch: 6| Step: 5
Training loss: 0.2015551924304943
Validation loss: 2.47993944311818

Epoch: 6| Step: 6
Training loss: 0.3066534416290161
Validation loss: 2.468417947914496

Epoch: 6| Step: 7
Training loss: 0.13121163227502664
Validation loss: 2.411191741432299

Epoch: 6| Step: 8
Training loss: 0.19062855435794232
Validation loss: 2.320603831165132

Epoch: 6| Step: 9
Training loss: 0.18516175306166058
Validation loss: 2.2649470926467608

Epoch: 6| Step: 10
Training loss: 0.2308077420426803
Validation loss: 2.251429093129994

Epoch: 6| Step: 11
Training loss: 0.24836548295239644
Validation loss: 2.243235156340318

Epoch: 6| Step: 12
Training loss: 0.2947904407601539
Validation loss: 2.2094284239018194

Epoch: 6| Step: 13
Training loss: 0.2597309749123474
Validation loss: 2.204025490634184

Epoch: 626| Step: 0
Training loss: 0.31964905579455993
Validation loss: 2.218933971357016

Epoch: 6| Step: 1
Training loss: 0.1961227395563805
Validation loss: 2.2213296656046064

Epoch: 6| Step: 2
Training loss: 0.21977065597617668
Validation loss: 2.2373846923902865

Epoch: 6| Step: 3
Training loss: 0.2174390269459144
Validation loss: 2.245762528675018

Epoch: 6| Step: 4
Training loss: 0.18843632599637303
Validation loss: 2.3162220260467743

Epoch: 6| Step: 5
Training loss: 0.10060256987157187
Validation loss: 2.347430393878838

Epoch: 6| Step: 6
Training loss: 0.18082462083979034
Validation loss: 2.360573105639022

Epoch: 6| Step: 7
Training loss: 0.2311674776268174
Validation loss: 2.3711654069217905

Epoch: 6| Step: 8
Training loss: 0.24340059656867027
Validation loss: 2.400743614722339

Epoch: 6| Step: 9
Training loss: 0.3228627077776273
Validation loss: 2.4029053806641536

Epoch: 6| Step: 10
Training loss: 0.4165208998653524
Validation loss: 2.416005016072192

Epoch: 6| Step: 11
Training loss: 0.29299700282878127
Validation loss: 2.3810052094919945

Epoch: 6| Step: 12
Training loss: 0.2408610907291523
Validation loss: 2.3412504369334557

Epoch: 6| Step: 13
Training loss: 0.20322647677729808
Validation loss: 2.307736672322584

Epoch: 627| Step: 0
Training loss: 0.1842168319479346
Validation loss: 2.302932153099401

Epoch: 6| Step: 1
Training loss: 0.2309600797617335
Validation loss: 2.270969589614629

Epoch: 6| Step: 2
Training loss: 0.22779509256781405
Validation loss: 2.2434999274313188

Epoch: 6| Step: 3
Training loss: 0.17233686271698231
Validation loss: 2.195834605786022

Epoch: 6| Step: 4
Training loss: 0.2418922501211215
Validation loss: 2.2179368461656623

Epoch: 6| Step: 5
Training loss: 0.23234431791973675
Validation loss: 2.2078984397883588

Epoch: 6| Step: 6
Training loss: 0.41974849226489397
Validation loss: 2.2478385573540502

Epoch: 6| Step: 7
Training loss: 0.26684355320461406
Validation loss: 2.255432306676784

Epoch: 6| Step: 8
Training loss: 0.14917967369556986
Validation loss: 2.3064571493564103

Epoch: 6| Step: 9
Training loss: 0.18260370296528927
Validation loss: 2.3698866915162835

Epoch: 6| Step: 10
Training loss: 0.24491690245817432
Validation loss: 2.3965878433249213

Epoch: 6| Step: 11
Training loss: 0.20100331883691502
Validation loss: 2.4110410042993493

Epoch: 6| Step: 12
Training loss: 0.21813886286888137
Validation loss: 2.4263597652978586

Epoch: 6| Step: 13
Training loss: 0.23742437287924928
Validation loss: 2.4433057955938073

Epoch: 628| Step: 0
Training loss: 0.22698549542058957
Validation loss: 2.439777571773363

Epoch: 6| Step: 1
Training loss: 0.1825505609398966
Validation loss: 2.4396705886179726

Epoch: 6| Step: 2
Training loss: 0.3320805008207844
Validation loss: 2.4499005979556205

Epoch: 6| Step: 3
Training loss: 0.2143130857933006
Validation loss: 2.4329391481617484

Epoch: 6| Step: 4
Training loss: 0.1521155041369386
Validation loss: 2.4102786660914424

Epoch: 6| Step: 5
Training loss: 0.3215115597101719
Validation loss: 2.382622161261773

Epoch: 6| Step: 6
Training loss: 0.2681683344823715
Validation loss: 2.3384856597320307

Epoch: 6| Step: 7
Training loss: 0.24624482316418672
Validation loss: 2.332140714078738

Epoch: 6| Step: 8
Training loss: 0.251312090949518
Validation loss: 2.3750682873885305

Epoch: 6| Step: 9
Training loss: 0.22037190928160771
Validation loss: 2.388825188048448

Epoch: 6| Step: 10
Training loss: 0.33850379389661056
Validation loss: 2.385764187015713

Epoch: 6| Step: 11
Training loss: 0.22190074569801196
Validation loss: 2.3869739276091657

Epoch: 6| Step: 12
Training loss: 0.13643651167790766
Validation loss: 2.390015132301543

Epoch: 6| Step: 13
Training loss: 0.2794969548979077
Validation loss: 2.3382581865178698

Epoch: 629| Step: 0
Training loss: 0.2549265973714366
Validation loss: 2.3887383328975487

Epoch: 6| Step: 1
Training loss: 0.1818780372962472
Validation loss: 2.3869915682047984

Epoch: 6| Step: 2
Training loss: 0.17539918492080514
Validation loss: 2.3838614046230053

Epoch: 6| Step: 3
Training loss: 0.22839510421186518
Validation loss: 2.4026591549702063

Epoch: 6| Step: 4
Training loss: 0.28243265250128174
Validation loss: 2.3830725334483334

Epoch: 6| Step: 5
Training loss: 0.15624333605860816
Validation loss: 2.414608474268309

Epoch: 6| Step: 6
Training loss: 0.2815038012710362
Validation loss: 2.3931386934257564

Epoch: 6| Step: 7
Training loss: 0.29939072450184534
Validation loss: 2.383234000149241

Epoch: 6| Step: 8
Training loss: 0.27951894614710465
Validation loss: 2.366977242754096

Epoch: 6| Step: 9
Training loss: 0.5451314106271028
Validation loss: 2.3559442557604267

Epoch: 6| Step: 10
Training loss: 0.19677397391413176
Validation loss: 2.3659974701837485

Epoch: 6| Step: 11
Training loss: 0.14329260952679904
Validation loss: 2.3494921603976615

Epoch: 6| Step: 12
Training loss: 0.23473083187492325
Validation loss: 2.326914406820975

Epoch: 6| Step: 13
Training loss: 0.2954705294873712
Validation loss: 2.328789957877762

Epoch: 630| Step: 0
Training loss: 0.39221470651068835
Validation loss: 2.3326167989232274

Epoch: 6| Step: 1
Training loss: 0.2693252467301366
Validation loss: 2.3030818829482818

Epoch: 6| Step: 2
Training loss: 0.2910415970650446
Validation loss: 2.3071363072673505

Epoch: 6| Step: 3
Training loss: 0.23062382346269256
Validation loss: 2.2913144203557456

Epoch: 6| Step: 4
Training loss: 0.20931188820720759
Validation loss: 2.3268152122926176

Epoch: 6| Step: 5
Training loss: 0.2343845524430711
Validation loss: 2.3246681513099237

Epoch: 6| Step: 6
Training loss: 0.2365772022405428
Validation loss: 2.285350351615414

Epoch: 6| Step: 7
Training loss: 0.1500678872424799
Validation loss: 2.3114172111347364

Epoch: 6| Step: 8
Training loss: 0.144667284327727
Validation loss: 2.285899702853151

Epoch: 6| Step: 9
Training loss: 0.3966596432105465
Validation loss: 2.29798934119941

Epoch: 6| Step: 10
Training loss: 0.189148362815678
Validation loss: 2.2969538982257363

Epoch: 6| Step: 11
Training loss: 0.26423731327549255
Validation loss: 2.323440713003932

Epoch: 6| Step: 12
Training loss: 0.23451610132504908
Validation loss: 2.3490991319424768

Epoch: 6| Step: 13
Training loss: 0.19857088096877373
Validation loss: 2.3861221500437613

Epoch: 631| Step: 0
Training loss: 0.2883365381665443
Validation loss: 2.3868618136094124

Epoch: 6| Step: 1
Training loss: 0.3539493071445711
Validation loss: 2.413356213741904

Epoch: 6| Step: 2
Training loss: 0.16276769367480642
Validation loss: 2.370806364264372

Epoch: 6| Step: 3
Training loss: 0.20078655488245914
Validation loss: 2.3639554195656687

Epoch: 6| Step: 4
Training loss: 0.205355629041672
Validation loss: 2.3451642468211196

Epoch: 6| Step: 5
Training loss: 0.2046909128152091
Validation loss: 2.3203877270799875

Epoch: 6| Step: 6
Training loss: 0.20800132920454875
Validation loss: 2.332300585698966

Epoch: 6| Step: 7
Training loss: 0.22690445481506855
Validation loss: 2.2962134522410356

Epoch: 6| Step: 8
Training loss: 0.20299833273026785
Validation loss: 2.3077966840194857

Epoch: 6| Step: 9
Training loss: 0.15151312161344774
Validation loss: 2.294157954664031

Epoch: 6| Step: 10
Training loss: 0.2862364155032184
Validation loss: 2.284116078759756

Epoch: 6| Step: 11
Training loss: 0.23236527274622576
Validation loss: 2.2678706574767196

Epoch: 6| Step: 12
Training loss: 0.2053652161660934
Validation loss: 2.297400281593199

Epoch: 6| Step: 13
Training loss: 0.2300065141252951
Validation loss: 2.3365303834871742

Epoch: 632| Step: 0
Training loss: 0.23365278231700723
Validation loss: 2.394570541547943

Epoch: 6| Step: 1
Training loss: 0.14196116070422538
Validation loss: 2.4320622557941265

Epoch: 6| Step: 2
Training loss: 0.23050894629169397
Validation loss: 2.4248229885417976

Epoch: 6| Step: 3
Training loss: 0.18992915763685353
Validation loss: 2.4484059675838536

Epoch: 6| Step: 4
Training loss: 0.18877441707786813
Validation loss: 2.4772309787922357

Epoch: 6| Step: 5
Training loss: 0.17976205771701972
Validation loss: 2.485891203386271

Epoch: 6| Step: 6
Training loss: 0.18956530091354265
Validation loss: 2.4462253303454924

Epoch: 6| Step: 7
Training loss: 0.2282424500304094
Validation loss: 2.437480351127224

Epoch: 6| Step: 8
Training loss: 0.15921664832752414
Validation loss: 2.4146469093260037

Epoch: 6| Step: 9
Training loss: 0.13466695960803007
Validation loss: 2.3635657050901777

Epoch: 6| Step: 10
Training loss: 0.13427920253507486
Validation loss: 2.309164446953888

Epoch: 6| Step: 11
Training loss: 0.24839977631775756
Validation loss: 2.298104926334354

Epoch: 6| Step: 12
Training loss: 0.22444404654063022
Validation loss: 2.3041422259202324

Epoch: 6| Step: 13
Training loss: 0.32909401225589513
Validation loss: 2.2883551868104184

Epoch: 633| Step: 0
Training loss: 0.2019722119724783
Validation loss: 2.27478350488531

Epoch: 6| Step: 1
Training loss: 0.2768760821491389
Validation loss: 2.291468007789161

Epoch: 6| Step: 2
Training loss: 0.18589591274482797
Validation loss: 2.3315924225424323

Epoch: 6| Step: 3
Training loss: 0.1754522211199494
Validation loss: 2.3448464665251527

Epoch: 6| Step: 4
Training loss: 0.20310045974384527
Validation loss: 2.3690721954258076

Epoch: 6| Step: 5
Training loss: 0.25837344497836506
Validation loss: 2.4081401659201895

Epoch: 6| Step: 6
Training loss: 0.24956020772422416
Validation loss: 2.3994056954969327

Epoch: 6| Step: 7
Training loss: 0.30428064520945114
Validation loss: 2.3931828594261364

Epoch: 6| Step: 8
Training loss: 0.20356372074572826
Validation loss: 2.3990198050922613

Epoch: 6| Step: 9
Training loss: 0.19932409381012162
Validation loss: 2.3703448447218376

Epoch: 6| Step: 10
Training loss: 0.17278698075729845
Validation loss: 2.348228768208913

Epoch: 6| Step: 11
Training loss: 0.16390484091968532
Validation loss: 2.3611769184068025

Epoch: 6| Step: 12
Training loss: 0.13590671667596474
Validation loss: 2.3478725652351424

Epoch: 6| Step: 13
Training loss: 0.19543315975101905
Validation loss: 2.334994208604997

Epoch: 634| Step: 0
Training loss: 0.2635206283243635
Validation loss: 2.327527439917958

Epoch: 6| Step: 1
Training loss: 0.1470204399221284
Validation loss: 2.354936140386956

Epoch: 6| Step: 2
Training loss: 0.19972006048776228
Validation loss: 2.3112959028678333

Epoch: 6| Step: 3
Training loss: 0.2466885931320848
Validation loss: 2.3208802844242458

Epoch: 6| Step: 4
Training loss: 0.1712528423174386
Validation loss: 2.341215006145529

Epoch: 6| Step: 5
Training loss: 0.12262830233623428
Validation loss: 2.3793526617952656

Epoch: 6| Step: 6
Training loss: 0.1324472313069522
Validation loss: 2.3515281011079385

Epoch: 6| Step: 7
Training loss: 0.24706900826211697
Validation loss: 2.3532333769162688

Epoch: 6| Step: 8
Training loss: 0.12940945089444428
Validation loss: 2.3381552289352743

Epoch: 6| Step: 9
Training loss: 0.14802088748448577
Validation loss: 2.3381216919666796

Epoch: 6| Step: 10
Training loss: 0.1421097548124786
Validation loss: 2.3397879250705658

Epoch: 6| Step: 11
Training loss: 0.18811998583996264
Validation loss: 2.342309357662143

Epoch: 6| Step: 12
Training loss: 0.18851672125196045
Validation loss: 2.31697930907108

Epoch: 6| Step: 13
Training loss: 0.053803494206591015
Validation loss: 2.3479398143558385

Epoch: 635| Step: 0
Training loss: 0.20700476135085355
Validation loss: 2.3219448179081152

Epoch: 6| Step: 1
Training loss: 0.1734565771625504
Validation loss: 2.325025827527032

Epoch: 6| Step: 2
Training loss: 0.1867394918628556
Validation loss: 2.3321807566607147

Epoch: 6| Step: 3
Training loss: 0.1653863987587671
Validation loss: 2.3388424516003035

Epoch: 6| Step: 4
Training loss: 0.1410967147236853
Validation loss: 2.3467066035111577

Epoch: 6| Step: 5
Training loss: 0.16960517923796084
Validation loss: 2.3571251731943987

Epoch: 6| Step: 6
Training loss: 0.15486600791906444
Validation loss: 2.369810543280363

Epoch: 6| Step: 7
Training loss: 0.09940854096583378
Validation loss: 2.3972367729594892

Epoch: 6| Step: 8
Training loss: 0.1422756199727202
Validation loss: 2.409415156862117

Epoch: 6| Step: 9
Training loss: 0.2527613134634848
Validation loss: 2.4188948964549204

Epoch: 6| Step: 10
Training loss: 0.12207520284393679
Validation loss: 2.4044121258568274

Epoch: 6| Step: 11
Training loss: 0.09449640806312289
Validation loss: 2.389101715636298

Epoch: 6| Step: 12
Training loss: 0.07703557087945431
Validation loss: 2.3511910235578215

Epoch: 6| Step: 13
Training loss: 0.2741260306603799
Validation loss: 2.363330205622

Epoch: 636| Step: 0
Training loss: 0.17490038037329633
Validation loss: 2.3172707229695955

Epoch: 6| Step: 1
Training loss: 0.1691520065988917
Validation loss: 2.30760901535862

Epoch: 6| Step: 2
Training loss: 0.08011798913109192
Validation loss: 2.3030854143657886

Epoch: 6| Step: 3
Training loss: 0.12045673125486639
Validation loss: 2.294725542015703

Epoch: 6| Step: 4
Training loss: 0.15105625950814328
Validation loss: 2.2920509258602833

Epoch: 6| Step: 5
Training loss: 0.198885854572905
Validation loss: 2.304174782139132

Epoch: 6| Step: 6
Training loss: 0.30105397629347586
Validation loss: 2.3251509085884523

Epoch: 6| Step: 7
Training loss: 0.20902800772968655
Validation loss: 2.2766448972310407

Epoch: 6| Step: 8
Training loss: 0.11418980832551562
Validation loss: 2.3073954318026457

Epoch: 6| Step: 9
Training loss: 0.1180509269985853
Validation loss: 2.307424136256487

Epoch: 6| Step: 10
Training loss: 0.11208924484957039
Validation loss: 2.3219284568635694

Epoch: 6| Step: 11
Training loss: 0.16733658284601133
Validation loss: 2.3049510640336424

Epoch: 6| Step: 12
Training loss: 0.19073098628872195
Validation loss: 2.3539943764515447

Epoch: 6| Step: 13
Training loss: 0.13880276882605938
Validation loss: 2.3228280891015896

Epoch: 637| Step: 0
Training loss: 0.16027733249752124
Validation loss: 2.351371781659461

Epoch: 6| Step: 1
Training loss: 0.13584717457212567
Validation loss: 2.327551389588423

Epoch: 6| Step: 2
Training loss: 0.2536431049354231
Validation loss: 2.3275640956785146

Epoch: 6| Step: 3
Training loss: 0.2386433554684031
Validation loss: 2.369930819203566

Epoch: 6| Step: 4
Training loss: 0.12177405073765638
Validation loss: 2.3334278208049386

Epoch: 6| Step: 5
Training loss: 0.18332424064506533
Validation loss: 2.327708908098767

Epoch: 6| Step: 6
Training loss: 0.16575162878214345
Validation loss: 2.364960734722532

Epoch: 6| Step: 7
Training loss: 0.08818814993543815
Validation loss: 2.3410696496597057

Epoch: 6| Step: 8
Training loss: 0.154438756342895
Validation loss: 2.352329465808055

Epoch: 6| Step: 9
Training loss: 0.18825472490554046
Validation loss: 2.351086422069437

Epoch: 6| Step: 10
Training loss: 0.16913480550432342
Validation loss: 2.3354248072493022

Epoch: 6| Step: 11
Training loss: 0.1612707356956238
Validation loss: 2.343458101423885

Epoch: 6| Step: 12
Training loss: 0.11364612517099412
Validation loss: 2.3805694151814913

Epoch: 6| Step: 13
Training loss: 0.11005192984416685
Validation loss: 2.3781595047329267

Epoch: 638| Step: 0
Training loss: 0.12421215147810445
Validation loss: 2.3732061590154427

Epoch: 6| Step: 1
Training loss: 0.1601186684965503
Validation loss: 2.3607466307995497

Epoch: 6| Step: 2
Training loss: 0.21277028803685624
Validation loss: 2.3688115233727447

Epoch: 6| Step: 3
Training loss: 0.18549956672288825
Validation loss: 2.39628342782882

Epoch: 6| Step: 4
Training loss: 0.22229739600654305
Validation loss: 2.403367301587996

Epoch: 6| Step: 5
Training loss: 0.11184685305063628
Validation loss: 2.3916021284814395

Epoch: 6| Step: 6
Training loss: 0.1724663499218299
Validation loss: 2.4085352172596046

Epoch: 6| Step: 7
Training loss: 0.11093385633341307
Validation loss: 2.4028317325110895

Epoch: 6| Step: 8
Training loss: 0.1659368945414243
Validation loss: 2.3970397765086306

Epoch: 6| Step: 9
Training loss: 0.31176637128030293
Validation loss: 2.3901562275032178

Epoch: 6| Step: 10
Training loss: 0.13410806562888294
Validation loss: 2.357226711670616

Epoch: 6| Step: 11
Training loss: 0.1487235149679075
Validation loss: 2.367686447019951

Epoch: 6| Step: 12
Training loss: 0.12069720281498113
Validation loss: 2.377023152536153

Epoch: 6| Step: 13
Training loss: 0.13053372415613818
Validation loss: 2.355921972346428

Epoch: 639| Step: 0
Training loss: 0.12697714064934762
Validation loss: 2.3642745339261606

Epoch: 6| Step: 1
Training loss: 0.25227604362212197
Validation loss: 2.3600103072623897

Epoch: 6| Step: 2
Training loss: 0.1704960691203053
Validation loss: 2.337320909477153

Epoch: 6| Step: 3
Training loss: 0.10378247180898365
Validation loss: 2.3089003967863793

Epoch: 6| Step: 4
Training loss: 0.12096797656445411
Validation loss: 2.325767464784823

Epoch: 6| Step: 5
Training loss: 0.21365751151950702
Validation loss: 2.306532241469858

Epoch: 6| Step: 6
Training loss: 0.1041014934346326
Validation loss: 2.2866469085972483

Epoch: 6| Step: 7
Training loss: 0.13987548084534332
Validation loss: 2.3332525391661476

Epoch: 6| Step: 8
Training loss: 0.10813914896885465
Validation loss: 2.3356121831431267

Epoch: 6| Step: 9
Training loss: 0.12486151758001866
Validation loss: 2.329603992982947

Epoch: 6| Step: 10
Training loss: 0.1335578786642223
Validation loss: 2.3180818469464404

Epoch: 6| Step: 11
Training loss: 0.14516935732806382
Validation loss: 2.3170459044468887

Epoch: 6| Step: 12
Training loss: 0.15706404585481742
Validation loss: 2.3115070930818544

Epoch: 6| Step: 13
Training loss: 0.11604006811615532
Validation loss: 2.3609838332178184

Epoch: 640| Step: 0
Training loss: 0.2599978448705119
Validation loss: 2.3548897770558614

Epoch: 6| Step: 1
Training loss: 0.1684254215825073
Validation loss: 2.3810043319771137

Epoch: 6| Step: 2
Training loss: 0.14036155899719985
Validation loss: 2.3770282355431833

Epoch: 6| Step: 3
Training loss: 0.18982665609001317
Validation loss: 2.3943289257921063

Epoch: 6| Step: 4
Training loss: 0.12592543814001453
Validation loss: 2.3536700582404797

Epoch: 6| Step: 5
Training loss: 0.1678586477000965
Validation loss: 2.3696469437307663

Epoch: 6| Step: 6
Training loss: 0.19400752895348175
Validation loss: 2.3642751650028946

Epoch: 6| Step: 7
Training loss: 0.10389432372578661
Validation loss: 2.3676787204185468

Epoch: 6| Step: 8
Training loss: 0.10066983048415802
Validation loss: 2.3512874621356645

Epoch: 6| Step: 9
Training loss: 0.1346546075180284
Validation loss: 2.3504388209675304

Epoch: 6| Step: 10
Training loss: 0.11723073718027001
Validation loss: 2.337585166637379

Epoch: 6| Step: 11
Training loss: 0.1651086773291315
Validation loss: 2.354363814264594

Epoch: 6| Step: 12
Training loss: 0.18787773151531306
Validation loss: 2.318890218517067

Epoch: 6| Step: 13
Training loss: 0.2196777204694572
Validation loss: 2.298395092080787

Epoch: 641| Step: 0
Training loss: 0.11499248591524977
Validation loss: 2.308470007323967

Epoch: 6| Step: 1
Training loss: 0.17444629264602998
Validation loss: 2.3176236848673355

Epoch: 6| Step: 2
Training loss: 0.16258268888851057
Validation loss: 2.3520801424019577

Epoch: 6| Step: 3
Training loss: 0.11871451644548581
Validation loss: 2.3055733995784498

Epoch: 6| Step: 4
Training loss: 0.15021809676718528
Validation loss: 2.3335646014446754

Epoch: 6| Step: 5
Training loss: 0.12889434297073152
Validation loss: 2.2875826526792067

Epoch: 6| Step: 6
Training loss: 0.18444756558872946
Validation loss: 2.3499666712790317

Epoch: 6| Step: 7
Training loss: 0.206463737712175
Validation loss: 2.337327898459128

Epoch: 6| Step: 8
Training loss: 0.19105448805307831
Validation loss: 2.3388293573721137

Epoch: 6| Step: 9
Training loss: 0.13892888711787685
Validation loss: 2.3332506163683

Epoch: 6| Step: 10
Training loss: 0.1285694737075265
Validation loss: 2.3660597000205077

Epoch: 6| Step: 11
Training loss: 0.11135409704723032
Validation loss: 2.3459085862188997

Epoch: 6| Step: 12
Training loss: 0.1503754831097834
Validation loss: 2.3194210430564794

Epoch: 6| Step: 13
Training loss: 0.16358782014237602
Validation loss: 2.335254546442685

Epoch: 642| Step: 0
Training loss: 0.17870284932495425
Validation loss: 2.3417870015887403

Epoch: 6| Step: 1
Training loss: 0.21185627162496704
Validation loss: 2.3594303891996287

Epoch: 6| Step: 2
Training loss: 0.14953293154656916
Validation loss: 2.378914909213

Epoch: 6| Step: 3
Training loss: 0.1424027108520079
Validation loss: 2.410258877205412

Epoch: 6| Step: 4
Training loss: 0.18320628124844923
Validation loss: 2.4031433327516174

Epoch: 6| Step: 5
Training loss: 0.16467954199273419
Validation loss: 2.3843868502021612

Epoch: 6| Step: 6
Training loss: 0.13575509922450799
Validation loss: 2.3936334112560353

Epoch: 6| Step: 7
Training loss: 0.21122041908515612
Validation loss: 2.40019277551271

Epoch: 6| Step: 8
Training loss: 0.18357931242644904
Validation loss: 2.3859340330393484

Epoch: 6| Step: 9
Training loss: 0.14346255375546269
Validation loss: 2.3828206250963184

Epoch: 6| Step: 10
Training loss: 0.14989635443138472
Validation loss: 2.3363066603233515

Epoch: 6| Step: 11
Training loss: 0.254362869488958
Validation loss: 2.3063665231687334

Epoch: 6| Step: 12
Training loss: 0.14965029348657852
Validation loss: 2.2805223775318653

Epoch: 6| Step: 13
Training loss: 0.13123515959127155
Validation loss: 2.287362482339637

Epoch: 643| Step: 0
Training loss: 0.15949266475220225
Validation loss: 2.260041230413948

Epoch: 6| Step: 1
Training loss: 0.22448703917279703
Validation loss: 2.2529119746582604

Epoch: 6| Step: 2
Training loss: 0.26916097002132694
Validation loss: 2.2821285664800586

Epoch: 6| Step: 3
Training loss: 0.16777388780242566
Validation loss: 2.2722138841410535

Epoch: 6| Step: 4
Training loss: 0.09366063985187836
Validation loss: 2.276308271086337

Epoch: 6| Step: 5
Training loss: 0.10668698707366758
Validation loss: 2.300160332923518

Epoch: 6| Step: 6
Training loss: 0.10942109873549564
Validation loss: 2.3293074909474494

Epoch: 6| Step: 7
Training loss: 0.27919293850549837
Validation loss: 2.3053812341689093

Epoch: 6| Step: 8
Training loss: 0.1764455851277662
Validation loss: 2.371570136620128

Epoch: 6| Step: 9
Training loss: 0.1960569974189756
Validation loss: 2.357148028189013

Epoch: 6| Step: 10
Training loss: 0.20237706105347272
Validation loss: 2.3498926556676545

Epoch: 6| Step: 11
Training loss: 0.10344194092970158
Validation loss: 2.3614325181764544

Epoch: 6| Step: 12
Training loss: 0.11605956533087664
Validation loss: 2.3849927266947044

Epoch: 6| Step: 13
Training loss: 0.158981545116161
Validation loss: 2.3523456361140185

Epoch: 644| Step: 0
Training loss: 0.09745971931200748
Validation loss: 2.364077820074313

Epoch: 6| Step: 1
Training loss: 0.10066452474787742
Validation loss: 2.3429948614351934

Epoch: 6| Step: 2
Training loss: 0.21754124155869442
Validation loss: 2.3709474237232877

Epoch: 6| Step: 3
Training loss: 0.13122667888807207
Validation loss: 2.328374965011395

Epoch: 6| Step: 4
Training loss: 0.1385631605256459
Validation loss: 2.3118842850920247

Epoch: 6| Step: 5
Training loss: 0.19347603486495735
Validation loss: 2.3546469627978315

Epoch: 6| Step: 6
Training loss: 0.18761413795713858
Validation loss: 2.3229170008826094

Epoch: 6| Step: 7
Training loss: 0.1755556884610787
Validation loss: 2.2856481815821805

Epoch: 6| Step: 8
Training loss: 0.22272752992835437
Validation loss: 2.289887424640723

Epoch: 6| Step: 9
Training loss: 0.16359423045258167
Validation loss: 2.3107041045654766

Epoch: 6| Step: 10
Training loss: 0.14023463055260627
Validation loss: 2.3282934076866577

Epoch: 6| Step: 11
Training loss: 0.141134544275356
Validation loss: 2.3254416771442266

Epoch: 6| Step: 12
Training loss: 0.23578060187976863
Validation loss: 2.351175760672869

Epoch: 6| Step: 13
Training loss: 0.1566989290742789
Validation loss: 2.3266105642868746

Epoch: 645| Step: 0
Training loss: 0.20195025251990914
Validation loss: 2.353221515913431

Epoch: 6| Step: 1
Training loss: 0.13346934577292677
Validation loss: 2.3542163887911265

Epoch: 6| Step: 2
Training loss: 0.1332768219595727
Validation loss: 2.309901881274491

Epoch: 6| Step: 3
Training loss: 0.15678763875096757
Validation loss: 2.3359639150550167

Epoch: 6| Step: 4
Training loss: 0.2051817677499204
Validation loss: 2.326832192878397

Epoch: 6| Step: 5
Training loss: 0.20850677820206648
Validation loss: 2.3054793638029385

Epoch: 6| Step: 6
Training loss: 0.1385008872637233
Validation loss: 2.325873073777836

Epoch: 6| Step: 7
Training loss: 0.18229253746006382
Validation loss: 2.3433116937795586

Epoch: 6| Step: 8
Training loss: 0.1520952680283538
Validation loss: 2.344049385665461

Epoch: 6| Step: 9
Training loss: 0.09003666193941595
Validation loss: 2.3465861502332093

Epoch: 6| Step: 10
Training loss: 0.14050837820245182
Validation loss: 2.3424639667634035

Epoch: 6| Step: 11
Training loss: 0.15664739142284514
Validation loss: 2.3482099892213233

Epoch: 6| Step: 12
Training loss: 0.1758757231412118
Validation loss: 2.356369837439006

Epoch: 6| Step: 13
Training loss: 0.18144769574623523
Validation loss: 2.3495199637424107

Epoch: 646| Step: 0
Training loss: 0.08688338413364337
Validation loss: 2.3377419495734446

Epoch: 6| Step: 1
Training loss: 0.06827011411500669
Validation loss: 2.3346227142889044

Epoch: 6| Step: 2
Training loss: 0.12768623979136123
Validation loss: 2.284617800503521

Epoch: 6| Step: 3
Training loss: 0.1342327806912939
Validation loss: 2.2575256537871504

Epoch: 6| Step: 4
Training loss: 0.1299542897240916
Validation loss: 2.2691703736662308

Epoch: 6| Step: 5
Training loss: 0.20320630280423577
Validation loss: 2.282281950963281

Epoch: 6| Step: 6
Training loss: 0.14195141160904018
Validation loss: 2.282922879537072

Epoch: 6| Step: 7
Training loss: 0.11411684665222932
Validation loss: 2.2621066748514815

Epoch: 6| Step: 8
Training loss: 0.23856978847592142
Validation loss: 2.2568382695930946

Epoch: 6| Step: 9
Training loss: 0.21656978157319376
Validation loss: 2.2621357312884944

Epoch: 6| Step: 10
Training loss: 0.20999759087997213
Validation loss: 2.2497532211009683

Epoch: 6| Step: 11
Training loss: 0.09805626482284165
Validation loss: 2.250685737736804

Epoch: 6| Step: 12
Training loss: 0.09333078712831919
Validation loss: 2.2382684390976313

Epoch: 6| Step: 13
Training loss: 0.1340500659444996
Validation loss: 2.242757723232215

Epoch: 647| Step: 0
Training loss: 0.1352154232873968
Validation loss: 2.267715565677758

Epoch: 6| Step: 1
Training loss: 0.10402697096985573
Validation loss: 2.2751233694546453

Epoch: 6| Step: 2
Training loss: 0.13947232351996597
Validation loss: 2.284630376191902

Epoch: 6| Step: 3
Training loss: 0.09470571701513081
Validation loss: 2.2787359614442115

Epoch: 6| Step: 4
Training loss: 0.1079694360705714
Validation loss: 2.280432714990008

Epoch: 6| Step: 5
Training loss: 0.10706631162754003
Validation loss: 2.302999789183657

Epoch: 6| Step: 6
Training loss: 0.10114239038440959
Validation loss: 2.2974665621326125

Epoch: 6| Step: 7
Training loss: 0.10217528528302479
Validation loss: 2.3431226496436772

Epoch: 6| Step: 8
Training loss: 0.12701862552827994
Validation loss: 2.352918616573668

Epoch: 6| Step: 9
Training loss: 0.12377925173064543
Validation loss: 2.3615123409879706

Epoch: 6| Step: 10
Training loss: 0.14291651949467138
Validation loss: 2.3566362011547906

Epoch: 6| Step: 11
Training loss: 0.16727287283013664
Validation loss: 2.3600639364773714

Epoch: 6| Step: 12
Training loss: 0.1660985403007108
Validation loss: 2.34392954121583

Epoch: 6| Step: 13
Training loss: 0.1657104098774844
Validation loss: 2.3416022125623663

Epoch: 648| Step: 0
Training loss: 0.08609061797099525
Validation loss: 2.3455122909112465

Epoch: 6| Step: 1
Training loss: 0.15899839784606723
Validation loss: 2.3128345871593563

Epoch: 6| Step: 2
Training loss: 0.18436580004611108
Validation loss: 2.3280505925310253

Epoch: 6| Step: 3
Training loss: 0.10048470912475034
Validation loss: 2.3464041433895693

Epoch: 6| Step: 4
Training loss: 0.15948725164634645
Validation loss: 2.3223489736925425

Epoch: 6| Step: 5
Training loss: 0.12448625117123796
Validation loss: 2.2824164844359913

Epoch: 6| Step: 6
Training loss: 0.09791576236280217
Validation loss: 2.300054491832325

Epoch: 6| Step: 7
Training loss: 0.07514352067602093
Validation loss: 2.2757310601633844

Epoch: 6| Step: 8
Training loss: 0.11553263454623983
Validation loss: 2.286470509087283

Epoch: 6| Step: 9
Training loss: 0.11452629465049215
Validation loss: 2.2940758564125803

Epoch: 6| Step: 10
Training loss: 0.12633220978586818
Validation loss: 2.2530002052138776

Epoch: 6| Step: 11
Training loss: 0.08251457086585762
Validation loss: 2.256974123771986

Epoch: 6| Step: 12
Training loss: 0.11298731372389328
Validation loss: 2.261636960255596

Epoch: 6| Step: 13
Training loss: 0.061400436257800055
Validation loss: 2.262310013346111

Epoch: 649| Step: 0
Training loss: 0.13325844955403882
Validation loss: 2.267135502442216

Epoch: 6| Step: 1
Training loss: 0.1662556091774927
Validation loss: 2.2393945637785735

Epoch: 6| Step: 2
Training loss: 0.1544312362905866
Validation loss: 2.2548888643625244

Epoch: 6| Step: 3
Training loss: 0.09781168964769373
Validation loss: 2.256035845301214

Epoch: 6| Step: 4
Training loss: 0.14086896212085542
Validation loss: 2.225299539620966

Epoch: 6| Step: 5
Training loss: 0.14830936372385123
Validation loss: 2.274720263397188

Epoch: 6| Step: 6
Training loss: 0.0715633888480945
Validation loss: 2.302520773497098

Epoch: 6| Step: 7
Training loss: 0.1621264483182005
Validation loss: 2.2947275898210298

Epoch: 6| Step: 8
Training loss: 0.06554501603619717
Validation loss: 2.2882545672388273

Epoch: 6| Step: 9
Training loss: 0.10218538870511491
Validation loss: 2.285206632476797

Epoch: 6| Step: 10
Training loss: 0.09672422057720445
Validation loss: 2.2864920992327997

Epoch: 6| Step: 11
Training loss: 0.10994457204397666
Validation loss: 2.303671643107031

Epoch: 6| Step: 12
Training loss: 0.055508282670855925
Validation loss: 2.3116648062933844

Epoch: 6| Step: 13
Training loss: 0.15553347687471236
Validation loss: 2.3044142305057624

Epoch: 650| Step: 0
Training loss: 0.13054441154068724
Validation loss: 2.2827983663643256

Epoch: 6| Step: 1
Training loss: 0.10790981102797578
Validation loss: 2.3052017386272405

Epoch: 6| Step: 2
Training loss: 0.17227226101815812
Validation loss: 2.308406337156543

Epoch: 6| Step: 3
Training loss: 0.13629766058266304
Validation loss: 2.32648829698395

Epoch: 6| Step: 4
Training loss: 0.10899640020388854
Validation loss: 2.279742562234055

Epoch: 6| Step: 5
Training loss: 0.0906572416107322
Validation loss: 2.3166353955249437

Epoch: 6| Step: 6
Training loss: 0.14227131924867661
Validation loss: 2.2746763522701183

Epoch: 6| Step: 7
Training loss: 0.19928229010557147
Validation loss: 2.3053847081311294

Epoch: 6| Step: 8
Training loss: 0.09210335014544058
Validation loss: 2.2917969279776527

Epoch: 6| Step: 9
Training loss: 0.11207538082699273
Validation loss: 2.3122642937963165

Epoch: 6| Step: 10
Training loss: 0.12845560979904938
Validation loss: 2.32810652464612

Epoch: 6| Step: 11
Training loss: 0.10560686287260461
Validation loss: 2.3312060339155436

Epoch: 6| Step: 12
Training loss: 0.12918038551734892
Validation loss: 2.3166893789801506

Epoch: 6| Step: 13
Training loss: 0.15270478310714788
Validation loss: 2.352032765781601

Epoch: 651| Step: 0
Training loss: 0.17175050041036988
Validation loss: 2.347939237849399

Epoch: 6| Step: 1
Training loss: 0.13439230419343293
Validation loss: 2.34756314204929

Epoch: 6| Step: 2
Training loss: 0.18187962467173543
Validation loss: 2.3441802189885217

Epoch: 6| Step: 3
Training loss: 0.1169321377333671
Validation loss: 2.3552088070187875

Epoch: 6| Step: 4
Training loss: 0.1635492448103883
Validation loss: 2.3282383298409752

Epoch: 6| Step: 5
Training loss: 0.0934936923883504
Validation loss: 2.3060247372112435

Epoch: 6| Step: 6
Training loss: 0.10239974048251463
Validation loss: 2.3038759070997363

Epoch: 6| Step: 7
Training loss: 0.1539626545830883
Validation loss: 2.2986905895157506

Epoch: 6| Step: 8
Training loss: 0.08227399830531504
Validation loss: 2.294865430959457

Epoch: 6| Step: 9
Training loss: 0.08035701939028382
Validation loss: 2.3100996694125366

Epoch: 6| Step: 10
Training loss: 0.1389701885125775
Validation loss: 2.2918517081840637

Epoch: 6| Step: 11
Training loss: 0.115601423798277
Validation loss: 2.295791129714487

Epoch: 6| Step: 12
Training loss: 0.15335382714830142
Validation loss: 2.274722999784523

Epoch: 6| Step: 13
Training loss: 0.16644779501592083
Validation loss: 2.2810928441181573

Epoch: 652| Step: 0
Training loss: 0.15125349143230896
Validation loss: 2.300330622690471

Epoch: 6| Step: 1
Training loss: 0.14069679864516554
Validation loss: 2.2966676615245194

Epoch: 6| Step: 2
Training loss: 0.08571696431802936
Validation loss: 2.3245175157287012

Epoch: 6| Step: 3
Training loss: 0.10738412020189891
Validation loss: 2.3156116905193596

Epoch: 6| Step: 4
Training loss: 0.09635414357657629
Validation loss: 2.306757992142161

Epoch: 6| Step: 5
Training loss: 0.1344828680035346
Validation loss: 2.2955814363484857

Epoch: 6| Step: 6
Training loss: 0.16943165890691003
Validation loss: 2.3208221392933117

Epoch: 6| Step: 7
Training loss: 0.14475301534265983
Validation loss: 2.3268271875187625

Epoch: 6| Step: 8
Training loss: 0.15021246724077178
Validation loss: 2.3188984647726882

Epoch: 6| Step: 9
Training loss: 0.1311600632430192
Validation loss: 2.30534524321192

Epoch: 6| Step: 10
Training loss: 0.11220330762536204
Validation loss: 2.339880354701429

Epoch: 6| Step: 11
Training loss: 0.08920491151328708
Validation loss: 2.3214348712598114

Epoch: 6| Step: 12
Training loss: 0.1588074421304278
Validation loss: 2.3207215073336824

Epoch: 6| Step: 13
Training loss: 0.0871867819554831
Validation loss: 2.315280646013848

Epoch: 653| Step: 0
Training loss: 0.07443412475276415
Validation loss: 2.3043374350686165

Epoch: 6| Step: 1
Training loss: 0.15538901100452046
Validation loss: 2.305425774771808

Epoch: 6| Step: 2
Training loss: 0.09083001279813203
Validation loss: 2.310717965044774

Epoch: 6| Step: 3
Training loss: 0.1046249223968601
Validation loss: 2.3077909158681025

Epoch: 6| Step: 4
Training loss: 0.15453790598267303
Validation loss: 2.3197517937041607

Epoch: 6| Step: 5
Training loss: 0.14374276899726765
Validation loss: 2.3312674021861084

Epoch: 6| Step: 6
Training loss: 0.16717634030111872
Validation loss: 2.324890071203264

Epoch: 6| Step: 7
Training loss: 0.12283164455712645
Validation loss: 2.299760175144039

Epoch: 6| Step: 8
Training loss: 0.1326978834036243
Validation loss: 2.2936325050302444

Epoch: 6| Step: 9
Training loss: 0.07150349960482434
Validation loss: 2.2930953717288323

Epoch: 6| Step: 10
Training loss: 0.11718565621515023
Validation loss: 2.2952227174087287

Epoch: 6| Step: 11
Training loss: 0.1173863392964952
Validation loss: 2.2718230212593182

Epoch: 6| Step: 12
Training loss: 0.1391330224069377
Validation loss: 2.301121342345042

Epoch: 6| Step: 13
Training loss: 0.09198384824238785
Validation loss: 2.2790522747244863

Epoch: 654| Step: 0
Training loss: 0.11444463698384195
Validation loss: 2.2734274932164102

Epoch: 6| Step: 1
Training loss: 0.10922843189602927
Validation loss: 2.2835839365723536

Epoch: 6| Step: 2
Training loss: 0.08260301452615333
Validation loss: 2.298174887263974

Epoch: 6| Step: 3
Training loss: 0.11211582972722665
Validation loss: 2.2806849502616817

Epoch: 6| Step: 4
Training loss: 0.08747125285364395
Validation loss: 2.2870043075789774

Epoch: 6| Step: 5
Training loss: 0.1766222333718398
Validation loss: 2.292442030264829

Epoch: 6| Step: 6
Training loss: 0.08147412666325034
Validation loss: 2.2828495128619055

Epoch: 6| Step: 7
Training loss: 0.08126774328236529
Validation loss: 2.267465496616339

Epoch: 6| Step: 8
Training loss: 0.12980262891323466
Validation loss: 2.2628118637854944

Epoch: 6| Step: 9
Training loss: 0.15907858346630036
Validation loss: 2.2604389041196002

Epoch: 6| Step: 10
Training loss: 0.1352106293667995
Validation loss: 2.26087192150843

Epoch: 6| Step: 11
Training loss: 0.08850163952809335
Validation loss: 2.2578031370327416

Epoch: 6| Step: 12
Training loss: 0.08244487387335256
Validation loss: 2.2570421224765065

Epoch: 6| Step: 13
Training loss: 0.09898758809264818
Validation loss: 2.2327680384608506

Epoch: 655| Step: 0
Training loss: 0.15520496178065019
Validation loss: 2.270985497664419

Epoch: 6| Step: 1
Training loss: 0.1367275371452474
Validation loss: 2.2506631263677264

Epoch: 6| Step: 2
Training loss: 0.1309682478570835
Validation loss: 2.2842299237294235

Epoch: 6| Step: 3
Training loss: 0.09942834429276859
Validation loss: 2.285286372171402

Epoch: 6| Step: 4
Training loss: 0.1425821290695019
Validation loss: 2.2593370878011356

Epoch: 6| Step: 5
Training loss: 0.11801868749120013
Validation loss: 2.282930186653343

Epoch: 6| Step: 6
Training loss: 0.08614448254215056
Validation loss: 2.2673774614836355

Epoch: 6| Step: 7
Training loss: 0.07068820751213027
Validation loss: 2.2674553232795356

Epoch: 6| Step: 8
Training loss: 0.1695244625156727
Validation loss: 2.2799464772090814

Epoch: 6| Step: 9
Training loss: 0.06804129302805458
Validation loss: 2.2599004353815766

Epoch: 6| Step: 10
Training loss: 0.12350232362757224
Validation loss: 2.277350643869882

Epoch: 6| Step: 11
Training loss: 0.07477780337088555
Validation loss: 2.2672074463042646

Epoch: 6| Step: 12
Training loss: 0.11423747378876087
Validation loss: 2.2783846490246833

Epoch: 6| Step: 13
Training loss: 0.14482025943624868
Validation loss: 2.293901149127123

Epoch: 656| Step: 0
Training loss: 0.08320493293194899
Validation loss: 2.2901885069273047

Epoch: 6| Step: 1
Training loss: 0.11791125358486705
Validation loss: 2.289354499958321

Epoch: 6| Step: 2
Training loss: 0.10229961047660058
Validation loss: 2.3244400008725377

Epoch: 6| Step: 3
Training loss: 0.09642580200405257
Validation loss: 2.316301083736337

Epoch: 6| Step: 4
Training loss: 0.20147486896136688
Validation loss: 2.3722068907963636

Epoch: 6| Step: 5
Training loss: 0.07115681020878876
Validation loss: 2.354506542584839

Epoch: 6| Step: 6
Training loss: 0.19062067871198657
Validation loss: 2.358261237772157

Epoch: 6| Step: 7
Training loss: 0.11506781421160898
Validation loss: 2.3735462482474876

Epoch: 6| Step: 8
Training loss: 0.1954094932045428
Validation loss: 2.3875321288422877

Epoch: 6| Step: 9
Training loss: 0.08817600965362563
Validation loss: 2.341350429082918

Epoch: 6| Step: 10
Training loss: 0.09961849526184231
Validation loss: 2.3376480552256593

Epoch: 6| Step: 11
Training loss: 0.1305985912521949
Validation loss: 2.340225211914403

Epoch: 6| Step: 12
Training loss: 0.07615408017081032
Validation loss: 2.3262771284105606

Epoch: 6| Step: 13
Training loss: 0.08396605912913069
Validation loss: 2.315648779569083

Epoch: 657| Step: 0
Training loss: 0.10491432057649404
Validation loss: 2.3204545176851425

Epoch: 6| Step: 1
Training loss: 0.11486047765653748
Validation loss: 2.2656962801109657

Epoch: 6| Step: 2
Training loss: 0.15815198330719538
Validation loss: 2.275784379652317

Epoch: 6| Step: 3
Training loss: 0.12412954282178733
Validation loss: 2.2454153714833422

Epoch: 6| Step: 4
Training loss: 0.19804458917807244
Validation loss: 2.2686378550951325

Epoch: 6| Step: 5
Training loss: 0.17932018801647806
Validation loss: 2.262125552115036

Epoch: 6| Step: 6
Training loss: 0.10586443603917264
Validation loss: 2.2799286003857255

Epoch: 6| Step: 7
Training loss: 0.08929267094111593
Validation loss: 2.3016948076054407

Epoch: 6| Step: 8
Training loss: 0.1474155773097344
Validation loss: 2.281139285122902

Epoch: 6| Step: 9
Training loss: 0.09493546212051479
Validation loss: 2.299997520579196

Epoch: 6| Step: 10
Training loss: 0.08580424532984353
Validation loss: 2.347215432094147

Epoch: 6| Step: 11
Training loss: 0.10190145162312594
Validation loss: 2.303394578581262

Epoch: 6| Step: 12
Training loss: 0.16548161170294076
Validation loss: 2.338292519688424

Epoch: 6| Step: 13
Training loss: 0.06465998241106442
Validation loss: 2.3554128872424993

Epoch: 658| Step: 0
Training loss: 0.16761394109095776
Validation loss: 2.3596442501623094

Epoch: 6| Step: 1
Training loss: 0.10127862817707026
Validation loss: 2.3715683897416655

Epoch: 6| Step: 2
Training loss: 0.1274340543416767
Validation loss: 2.3627566463228855

Epoch: 6| Step: 3
Training loss: 0.05927737902179907
Validation loss: 2.378176524573377

Epoch: 6| Step: 4
Training loss: 0.178504626730386
Validation loss: 2.386110860261498

Epoch: 6| Step: 5
Training loss: 0.0827489434699538
Validation loss: 2.345547948612415

Epoch: 6| Step: 6
Training loss: 0.06889328222585762
Validation loss: 2.3703310046583383

Epoch: 6| Step: 7
Training loss: 0.18569924974390115
Validation loss: 2.3638217688590446

Epoch: 6| Step: 8
Training loss: 0.12260146360150875
Validation loss: 2.34107103821103

Epoch: 6| Step: 9
Training loss: 0.1312596547458573
Validation loss: 2.308986265866308

Epoch: 6| Step: 10
Training loss: 0.17754834258918137
Validation loss: 2.313945890003653

Epoch: 6| Step: 11
Training loss: 0.14833504503937683
Validation loss: 2.322574268167667

Epoch: 6| Step: 12
Training loss: 0.11560624137990164
Validation loss: 2.3024902776592353

Epoch: 6| Step: 13
Training loss: 0.22123096440750492
Validation loss: 2.3060582932289218

Epoch: 659| Step: 0
Training loss: 0.13652862544428293
Validation loss: 2.3103373413647477

Epoch: 6| Step: 1
Training loss: 0.2079883530518394
Validation loss: 2.3349366383748897

Epoch: 6| Step: 2
Training loss: 0.1554716812029989
Validation loss: 2.3098442756845956

Epoch: 6| Step: 3
Training loss: 0.11611622468956898
Validation loss: 2.330201555238247

Epoch: 6| Step: 4
Training loss: 0.11698248732256346
Validation loss: 2.3179646439575405

Epoch: 6| Step: 5
Training loss: 0.08981294725886761
Validation loss: 2.3288154852709355

Epoch: 6| Step: 6
Training loss: 0.12435714252029127
Validation loss: 2.3338084744261356

Epoch: 6| Step: 7
Training loss: 0.12686613477073636
Validation loss: 2.2990912401005117

Epoch: 6| Step: 8
Training loss: 0.14020217802169418
Validation loss: 2.315282281450955

Epoch: 6| Step: 9
Training loss: 0.10480431259833244
Validation loss: 2.3036674142737317

Epoch: 6| Step: 10
Training loss: 0.14135168983024893
Validation loss: 2.299247000197799

Epoch: 6| Step: 11
Training loss: 0.11991879897257526
Validation loss: 2.2845148533178996

Epoch: 6| Step: 12
Training loss: 0.09248719981430066
Validation loss: 2.2616630744432498

Epoch: 6| Step: 13
Training loss: 0.16514773994723284
Validation loss: 2.277233211435266

Epoch: 660| Step: 0
Training loss: 0.14825980944931152
Validation loss: 2.2776725870893224

Epoch: 6| Step: 1
Training loss: 0.1270763532748859
Validation loss: 2.2891932820446845

Epoch: 6| Step: 2
Training loss: 0.10220821229036185
Validation loss: 2.252445108115137

Epoch: 6| Step: 3
Training loss: 0.1022390153651786
Validation loss: 2.2976339572302114

Epoch: 6| Step: 4
Training loss: 0.1439132558979052
Validation loss: 2.2710540781226514

Epoch: 6| Step: 5
Training loss: 0.09451531914390181
Validation loss: 2.287597067338168

Epoch: 6| Step: 6
Training loss: 0.0864422103654467
Validation loss: 2.271305858253351

Epoch: 6| Step: 7
Training loss: 0.07680779108833725
Validation loss: 2.3233496607608113

Epoch: 6| Step: 8
Training loss: 0.07296653373546445
Validation loss: 2.290545010262329

Epoch: 6| Step: 9
Training loss: 0.08277905582822839
Validation loss: 2.312866770519282

Epoch: 6| Step: 10
Training loss: 0.10841784432386359
Validation loss: 2.294767894235111

Epoch: 6| Step: 11
Training loss: 0.06286218871054546
Validation loss: 2.302160316805602

Epoch: 6| Step: 12
Training loss: 0.10483365105485808
Validation loss: 2.317835775099831

Epoch: 6| Step: 13
Training loss: 0.06631104924033383
Validation loss: 2.3000935980752844

Epoch: 661| Step: 0
Training loss: 0.14939532442963308
Validation loss: 2.306429200372242

Epoch: 6| Step: 1
Training loss: 0.09665841533259355
Validation loss: 2.2790077305081273

Epoch: 6| Step: 2
Training loss: 0.060155039007209754
Validation loss: 2.274075944695814

Epoch: 6| Step: 3
Training loss: 0.1289583375483478
Validation loss: 2.2885590171452175

Epoch: 6| Step: 4
Training loss: 0.1705857932105654
Validation loss: 2.283499428069075

Epoch: 6| Step: 5
Training loss: 0.16449629110645278
Validation loss: 2.263598101820202

Epoch: 6| Step: 6
Training loss: 0.1414253058686977
Validation loss: 2.2900765953781312

Epoch: 6| Step: 7
Training loss: 0.1313577669357658
Validation loss: 2.3008116384032498

Epoch: 6| Step: 8
Training loss: 0.10480397491838424
Validation loss: 2.2944555620384652

Epoch: 6| Step: 9
Training loss: 0.061596735932713434
Validation loss: 2.293984358887621

Epoch: 6| Step: 10
Training loss: 0.17809079661667376
Validation loss: 2.2873260464630105

Epoch: 6| Step: 11
Training loss: 0.1631259526484358
Validation loss: 2.279934233818156

Epoch: 6| Step: 12
Training loss: 0.08868411353597062
Validation loss: 2.2935560885429984

Epoch: 6| Step: 13
Training loss: 0.10334442034089562
Validation loss: 2.2674118257576117

Epoch: 662| Step: 0
Training loss: 0.06863671310708751
Validation loss: 2.278999138556541

Epoch: 6| Step: 1
Training loss: 0.059618293481255254
Validation loss: 2.30303705601629

Epoch: 6| Step: 2
Training loss: 0.1256516354469408
Validation loss: 2.321512335720053

Epoch: 6| Step: 3
Training loss: 0.09990432025076645
Validation loss: 2.2961161720766463

Epoch: 6| Step: 4
Training loss: 0.09244790435396927
Validation loss: 2.3044030265792887

Epoch: 6| Step: 5
Training loss: 0.13126718261052528
Validation loss: 2.3123709224960556

Epoch: 6| Step: 6
Training loss: 0.08944070638217944
Validation loss: 2.297366288613723

Epoch: 6| Step: 7
Training loss: 0.08760289673030294
Validation loss: 2.317523358162461

Epoch: 6| Step: 8
Training loss: 0.09947071522201408
Validation loss: 2.336691683843219

Epoch: 6| Step: 9
Training loss: 0.0786199566867929
Validation loss: 2.320795227132368

Epoch: 6| Step: 10
Training loss: 0.1299270468512269
Validation loss: 2.3149589113644713

Epoch: 6| Step: 11
Training loss: 0.12256521989760255
Validation loss: 2.328004396613743

Epoch: 6| Step: 12
Training loss: 0.0779033706083584
Validation loss: 2.3515758427492246

Epoch: 6| Step: 13
Training loss: 0.07096870502737578
Validation loss: 2.318110594776425

Epoch: 663| Step: 0
Training loss: 0.07724009272321022
Validation loss: 2.3358430809391337

Epoch: 6| Step: 1
Training loss: 0.11074169367389138
Validation loss: 2.316990405713275

Epoch: 6| Step: 2
Training loss: 0.14184915009871923
Validation loss: 2.3205827031079886

Epoch: 6| Step: 3
Training loss: 0.09740573699682684
Validation loss: 2.3259489388407997

Epoch: 6| Step: 4
Training loss: 0.14124123998712712
Validation loss: 2.3491935382120923

Epoch: 6| Step: 5
Training loss: 0.09422649547029563
Validation loss: 2.3399892092045698

Epoch: 6| Step: 6
Training loss: 0.055012689773797384
Validation loss: 2.3116961974876995

Epoch: 6| Step: 7
Training loss: 0.14316226885245764
Validation loss: 2.3421813276509567

Epoch: 6| Step: 8
Training loss: 0.10299646900256358
Validation loss: 2.3091067345650234

Epoch: 6| Step: 9
Training loss: 0.15147343260112636
Validation loss: 2.2981817052604665

Epoch: 6| Step: 10
Training loss: 0.1261403032490362
Validation loss: 2.292733074275263

Epoch: 6| Step: 11
Training loss: 0.07680657247939242
Validation loss: 2.289385567738863

Epoch: 6| Step: 12
Training loss: 0.14618927158384754
Validation loss: 2.299405800709271

Epoch: 6| Step: 13
Training loss: 0.1244924642597494
Validation loss: 2.2971250470361766

Epoch: 664| Step: 0
Training loss: 0.10118849371138824
Validation loss: 2.274104046113115

Epoch: 6| Step: 1
Training loss: 0.10225463656613404
Validation loss: 2.2921431324864865

Epoch: 6| Step: 2
Training loss: 0.1196780940548096
Validation loss: 2.3136874639158

Epoch: 6| Step: 3
Training loss: 0.1417891082528188
Validation loss: 2.31218623898766

Epoch: 6| Step: 4
Training loss: 0.09541270897846282
Validation loss: 2.300666652322593

Epoch: 6| Step: 5
Training loss: 0.14131498605733817
Validation loss: 2.282667071369183

Epoch: 6| Step: 6
Training loss: 0.15438675978499117
Validation loss: 2.3467148249414325

Epoch: 6| Step: 7
Training loss: 0.11252833777729633
Validation loss: 2.323949233301807

Epoch: 6| Step: 8
Training loss: 0.14723462302110038
Validation loss: 2.3314372561979853

Epoch: 6| Step: 9
Training loss: 0.15494346345117394
Validation loss: 2.3277433641015364

Epoch: 6| Step: 10
Training loss: 0.10736922794644024
Validation loss: 2.308707158026047

Epoch: 6| Step: 11
Training loss: 0.2674887570576464
Validation loss: 2.3443742999387625

Epoch: 6| Step: 12
Training loss: 0.20109178745168715
Validation loss: 2.3358055321932047

Epoch: 6| Step: 13
Training loss: 0.13666639688027124
Validation loss: 2.3401761393860157

Epoch: 665| Step: 0
Training loss: 0.12210079194068074
Validation loss: 2.36748895655062

Epoch: 6| Step: 1
Training loss: 0.08911020983686689
Validation loss: 2.323856885437289

Epoch: 6| Step: 2
Training loss: 0.12640836920217252
Validation loss: 2.339995838263602

Epoch: 6| Step: 3
Training loss: 0.1120873255097001
Validation loss: 2.313172621437126

Epoch: 6| Step: 4
Training loss: 0.13072906952609928
Validation loss: 2.3113401636732553

Epoch: 6| Step: 5
Training loss: 0.1279215992125132
Validation loss: 2.291681821741313

Epoch: 6| Step: 6
Training loss: 0.12617158210649537
Validation loss: 2.2985520219306146

Epoch: 6| Step: 7
Training loss: 0.15747641619587374
Validation loss: 2.3124319868609464

Epoch: 6| Step: 8
Training loss: 0.13717765765195786
Validation loss: 2.29686780086726

Epoch: 6| Step: 9
Training loss: 0.23566940814986148
Validation loss: 2.3110495566355302

Epoch: 6| Step: 10
Training loss: 0.13289749707456655
Validation loss: 2.3318728748759225

Epoch: 6| Step: 11
Training loss: 0.18040423912263742
Validation loss: 2.2956215225226044

Epoch: 6| Step: 12
Training loss: 0.19203915375661235
Validation loss: 2.3132487761290363

Epoch: 6| Step: 13
Training loss: 0.07073151389959544
Validation loss: 2.320350872324794

Epoch: 666| Step: 0
Training loss: 0.13249285885622597
Validation loss: 2.3715659564329505

Epoch: 6| Step: 1
Training loss: 0.14311581302084633
Validation loss: 2.3509202272941447

Epoch: 6| Step: 2
Training loss: 0.13663962663184362
Validation loss: 2.3728518115981583

Epoch: 6| Step: 3
Training loss: 0.09393519249890972
Validation loss: 2.3606137302144035

Epoch: 6| Step: 4
Training loss: 0.11746072706350208
Validation loss: 2.3745763834824953

Epoch: 6| Step: 5
Training loss: 0.16179374623646595
Validation loss: 2.3776204948393413

Epoch: 6| Step: 6
Training loss: 0.1308328758282873
Validation loss: 2.36152081782361

Epoch: 6| Step: 7
Training loss: 0.10000042263329127
Validation loss: 2.3177455349285085

Epoch: 6| Step: 8
Training loss: 0.09431412466373912
Validation loss: 2.3472685263134467

Epoch: 6| Step: 9
Training loss: 0.1287577669800828
Validation loss: 2.330432672845539

Epoch: 6| Step: 10
Training loss: 0.14244176274826065
Validation loss: 2.319643844019056

Epoch: 6| Step: 11
Training loss: 0.14621905776927213
Validation loss: 2.297763627172246

Epoch: 6| Step: 12
Training loss: 0.14370127090414395
Validation loss: 2.3015782916769636

Epoch: 6| Step: 13
Training loss: 0.1462671958766448
Validation loss: 2.3152866784125603

Epoch: 667| Step: 0
Training loss: 0.09454371315002227
Validation loss: 2.278406163328407

Epoch: 6| Step: 1
Training loss: 0.08442197778901334
Validation loss: 2.3086818058281677

Epoch: 6| Step: 2
Training loss: 0.08867329625742588
Validation loss: 2.2830515238127074

Epoch: 6| Step: 3
Training loss: 0.1193532960756709
Validation loss: 2.295213481360782

Epoch: 6| Step: 4
Training loss: 0.06724235851141554
Validation loss: 2.333879847036653

Epoch: 6| Step: 5
Training loss: 0.14573240548430091
Validation loss: 2.3115117367849134

Epoch: 6| Step: 6
Training loss: 0.08189204871147043
Validation loss: 2.3070859703248274

Epoch: 6| Step: 7
Training loss: 0.1228695795587134
Validation loss: 2.31935969542515

Epoch: 6| Step: 8
Training loss: 0.17411673086266283
Validation loss: 2.3366837955080104

Epoch: 6| Step: 9
Training loss: 0.10284908294586474
Validation loss: 2.3164291503827874

Epoch: 6| Step: 10
Training loss: 0.09729818503859551
Validation loss: 2.32812437949565

Epoch: 6| Step: 11
Training loss: 0.08623701159321927
Validation loss: 2.3322283403411004

Epoch: 6| Step: 12
Training loss: 0.09404829372648459
Validation loss: 2.3093892775928238

Epoch: 6| Step: 13
Training loss: 0.07715963330697806
Validation loss: 2.3095291308503114

Epoch: 668| Step: 0
Training loss: 0.10810743397319478
Validation loss: 2.3241695088269836

Epoch: 6| Step: 1
Training loss: 0.0937288478990182
Validation loss: 2.3284095947539707

Epoch: 6| Step: 2
Training loss: 0.15018315061382342
Validation loss: 2.3220130321245827

Epoch: 6| Step: 3
Training loss: 0.10127382333722162
Validation loss: 2.336615106072788

Epoch: 6| Step: 4
Training loss: 0.14591879696228655
Validation loss: 2.3393281188434965

Epoch: 6| Step: 5
Training loss: 0.10690551110363262
Validation loss: 2.330851686197096

Epoch: 6| Step: 6
Training loss: 0.14346498164822255
Validation loss: 2.3429838058897805

Epoch: 6| Step: 7
Training loss: 0.10359427774878893
Validation loss: 2.320458245280961

Epoch: 6| Step: 8
Training loss: 0.08093124204362051
Validation loss: 2.3255546412664105

Epoch: 6| Step: 9
Training loss: 0.15455504439620826
Validation loss: 2.3368664963411203

Epoch: 6| Step: 10
Training loss: 0.06347340429225483
Validation loss: 2.338585729535826

Epoch: 6| Step: 11
Training loss: 0.18071283249234385
Validation loss: 2.3303471226293824

Epoch: 6| Step: 12
Training loss: 0.12916959969461714
Validation loss: 2.3134347627766885

Epoch: 6| Step: 13
Training loss: 0.12504063631191684
Validation loss: 2.3318782074670845

Epoch: 669| Step: 0
Training loss: 0.11672208075258468
Validation loss: 2.283506368470342

Epoch: 6| Step: 1
Training loss: 0.1611304889858222
Validation loss: 2.286980085744319

Epoch: 6| Step: 2
Training loss: 0.11415687406209044
Validation loss: 2.28413608505218

Epoch: 6| Step: 3
Training loss: 0.179806296842551
Validation loss: 2.263196751269047

Epoch: 6| Step: 4
Training loss: 0.12373211203961447
Validation loss: 2.266916753024878

Epoch: 6| Step: 5
Training loss: 0.12441073043409512
Validation loss: 2.270489540128015

Epoch: 6| Step: 6
Training loss: 0.16803751691107172
Validation loss: 2.268752175615986

Epoch: 6| Step: 7
Training loss: 0.11814749814415368
Validation loss: 2.275495100908247

Epoch: 6| Step: 8
Training loss: 0.0665876421546278
Validation loss: 2.303256847738226

Epoch: 6| Step: 9
Training loss: 0.14064764794126622
Validation loss: 2.3134158038562824

Epoch: 6| Step: 10
Training loss: 0.139377825306366
Validation loss: 2.3046554004233717

Epoch: 6| Step: 11
Training loss: 0.14879768991532596
Validation loss: 2.301304845699397

Epoch: 6| Step: 12
Training loss: 0.2239610686615678
Validation loss: 2.329294076770851

Epoch: 6| Step: 13
Training loss: 0.22147816476071094
Validation loss: 2.3592320272362373

Epoch: 670| Step: 0
Training loss: 0.08290491458242918
Validation loss: 2.3359196066458296

Epoch: 6| Step: 1
Training loss: 0.08501698848358029
Validation loss: 2.3158325531852717

Epoch: 6| Step: 2
Training loss: 0.09533897524667967
Validation loss: 2.337151129584968

Epoch: 6| Step: 3
Training loss: 0.11744049102360604
Validation loss: 2.29362096900541

Epoch: 6| Step: 4
Training loss: 0.13623370231701226
Validation loss: 2.288940532273592

Epoch: 6| Step: 5
Training loss: 0.23373424043415
Validation loss: 2.307876649607719

Epoch: 6| Step: 6
Training loss: 0.13004537318997728
Validation loss: 2.3320077904660264

Epoch: 6| Step: 7
Training loss: 0.09616986628990432
Validation loss: 2.3291438531874618

Epoch: 6| Step: 8
Training loss: 0.11965315047623513
Validation loss: 2.385840413827553

Epoch: 6| Step: 9
Training loss: 0.1281817333871695
Validation loss: 2.383884233426193

Epoch: 6| Step: 10
Training loss: 0.12972859857437985
Validation loss: 2.4161678810081804

Epoch: 6| Step: 11
Training loss: 0.18804411616280695
Validation loss: 2.399118898319075

Epoch: 6| Step: 12
Training loss: 0.12433542224514808
Validation loss: 2.3828282445007174

Epoch: 6| Step: 13
Training loss: 0.16077972798790208
Validation loss: 2.3635751583350055

Epoch: 671| Step: 0
Training loss: 0.1587989618704209
Validation loss: 2.387945534268898

Epoch: 6| Step: 1
Training loss: 0.1051873718718226
Validation loss: 2.371059442546874

Epoch: 6| Step: 2
Training loss: 0.1839567410719477
Validation loss: 2.343798499477196

Epoch: 6| Step: 3
Training loss: 0.16167356901165225
Validation loss: 2.3723626035452696

Epoch: 6| Step: 4
Training loss: 0.08396741784589694
Validation loss: 2.360826347578798

Epoch: 6| Step: 5
Training loss: 0.12042188378464314
Validation loss: 2.3208902738383266

Epoch: 6| Step: 6
Training loss: 0.13776423034965796
Validation loss: 2.327443424675413

Epoch: 6| Step: 7
Training loss: 0.1412457369165279
Validation loss: 2.314411947156559

Epoch: 6| Step: 8
Training loss: 0.1285897038542828
Validation loss: 2.341199083769887

Epoch: 6| Step: 9
Training loss: 0.1142436736072235
Validation loss: 2.32583422380131

Epoch: 6| Step: 10
Training loss: 0.08576966825063317
Validation loss: 2.3314397668507225

Epoch: 6| Step: 11
Training loss: 0.07685183597689381
Validation loss: 2.3497155129680385

Epoch: 6| Step: 12
Training loss: 0.190948561927033
Validation loss: 2.3632429840697142

Epoch: 6| Step: 13
Training loss: 0.14756812059207572
Validation loss: 2.361063929075725

Epoch: 672| Step: 0
Training loss: 0.14269565284619495
Validation loss: 2.3899585768981413

Epoch: 6| Step: 1
Training loss: 0.1444643935661294
Validation loss: 2.3743307658205297

Epoch: 6| Step: 2
Training loss: 0.08390887881446223
Validation loss: 2.342508585863104

Epoch: 6| Step: 3
Training loss: 0.0986251780888481
Validation loss: 2.36533351907957

Epoch: 6| Step: 4
Training loss: 0.1305677880361705
Validation loss: 2.3159995323852414

Epoch: 6| Step: 5
Training loss: 0.24657409957366283
Validation loss: 2.337260791523411

Epoch: 6| Step: 6
Training loss: 0.09520335984056297
Validation loss: 2.332079359994875

Epoch: 6| Step: 7
Training loss: 0.08231531640334516
Validation loss: 2.3096146058191582

Epoch: 6| Step: 8
Training loss: 0.1697543238948006
Validation loss: 2.299447061648596

Epoch: 6| Step: 9
Training loss: 0.09355871733426002
Validation loss: 2.294714175154712

Epoch: 6| Step: 10
Training loss: 0.11904047446262551
Validation loss: 2.2833963215565682

Epoch: 6| Step: 11
Training loss: 0.09012830804535293
Validation loss: 2.277867545303942

Epoch: 6| Step: 12
Training loss: 0.1682381299576691
Validation loss: 2.2891067533643756

Epoch: 6| Step: 13
Training loss: 0.10606947000234555
Validation loss: 2.240036093945503

Epoch: 673| Step: 0
Training loss: 0.12072964889179368
Validation loss: 2.3003396779888137

Epoch: 6| Step: 1
Training loss: 0.1137431445649748
Validation loss: 2.259314920728986

Epoch: 6| Step: 2
Training loss: 0.09470486146561882
Validation loss: 2.249050698957939

Epoch: 6| Step: 3
Training loss: 0.17518399817634214
Validation loss: 2.2558823263521393

Epoch: 6| Step: 4
Training loss: 0.15922669728728558
Validation loss: 2.2805273625528786

Epoch: 6| Step: 5
Training loss: 0.12012282412569913
Validation loss: 2.280211167327261

Epoch: 6| Step: 6
Training loss: 0.12047818451859332
Validation loss: 2.2796541634062266

Epoch: 6| Step: 7
Training loss: 0.06501991144666726
Validation loss: 2.277852543483293

Epoch: 6| Step: 8
Training loss: 0.17452525602411262
Validation loss: 2.290681785834624

Epoch: 6| Step: 9
Training loss: 0.13351056425839394
Validation loss: 2.3297398427047424

Epoch: 6| Step: 10
Training loss: 0.10432652684156431
Validation loss: 2.315319142147417

Epoch: 6| Step: 11
Training loss: 0.09655314168673411
Validation loss: 2.327250729776006

Epoch: 6| Step: 12
Training loss: 0.07518335346392227
Validation loss: 2.332862320470935

Epoch: 6| Step: 13
Training loss: 0.06901226925912392
Validation loss: 2.3174793033923717

Epoch: 674| Step: 0
Training loss: 0.09019413810583302
Validation loss: 2.310132882424176

Epoch: 6| Step: 1
Training loss: 0.1393694725565658
Validation loss: 2.31881484445803

Epoch: 6| Step: 2
Training loss: 0.12467671102679151
Validation loss: 2.305138825082974

Epoch: 6| Step: 3
Training loss: 0.14220964814701656
Validation loss: 2.3209482758778845

Epoch: 6| Step: 4
Training loss: 0.0924590455551846
Validation loss: 2.2805204670445454

Epoch: 6| Step: 5
Training loss: 0.10663595102009293
Validation loss: 2.28781899791539

Epoch: 6| Step: 6
Training loss: 0.17499009215032313
Validation loss: 2.2859177920448897

Epoch: 6| Step: 7
Training loss: 0.08189484062836914
Validation loss: 2.289834552220404

Epoch: 6| Step: 8
Training loss: 0.12279208613012195
Validation loss: 2.296651757230285

Epoch: 6| Step: 9
Training loss: 0.14907086918686294
Validation loss: 2.290704902258467

Epoch: 6| Step: 10
Training loss: 0.08236713557805701
Validation loss: 2.277798166893669

Epoch: 6| Step: 11
Training loss: 0.1545660531973355
Validation loss: 2.2882960443737534

Epoch: 6| Step: 12
Training loss: 0.12859370170212275
Validation loss: 2.3109814802867295

Epoch: 6| Step: 13
Training loss: 0.11575436057204772
Validation loss: 2.314056384356384

Epoch: 675| Step: 0
Training loss: 0.1165903173867685
Validation loss: 2.309387964350503

Epoch: 6| Step: 1
Training loss: 0.16303599615136846
Validation loss: 2.3605806893371324

Epoch: 6| Step: 2
Training loss: 0.11602278311639097
Validation loss: 2.3474261150072726

Epoch: 6| Step: 3
Training loss: 0.0965474650258008
Validation loss: 2.3427698428007373

Epoch: 6| Step: 4
Training loss: 0.13016560966204588
Validation loss: 2.343993243102279

Epoch: 6| Step: 5
Training loss: 0.08716447791584968
Validation loss: 2.3304316926823643

Epoch: 6| Step: 6
Training loss: 0.07102407234717177
Validation loss: 2.33265102499542

Epoch: 6| Step: 7
Training loss: 0.1066581627813677
Validation loss: 2.3404799279291457

Epoch: 6| Step: 8
Training loss: 0.14086776547611943
Validation loss: 2.3193366659149253

Epoch: 6| Step: 9
Training loss: 0.12948000981533825
Validation loss: 2.338435372718359

Epoch: 6| Step: 10
Training loss: 0.12945077501465033
Validation loss: 2.3573693884551172

Epoch: 6| Step: 11
Training loss: 0.09470705932723762
Validation loss: 2.3656273349938948

Epoch: 6| Step: 12
Training loss: 0.07876353979084272
Validation loss: 2.3844065562546035

Epoch: 6| Step: 13
Training loss: 0.11509837190647337
Validation loss: 2.389359059305908

Epoch: 676| Step: 0
Training loss: 0.10419420285651936
Validation loss: 2.3955050578378128

Epoch: 6| Step: 1
Training loss: 0.10733767157007047
Validation loss: 2.4090309831577814

Epoch: 6| Step: 2
Training loss: 0.15797363519897026
Validation loss: 2.377086631644131

Epoch: 6| Step: 3
Training loss: 0.12784509555627932
Validation loss: 2.381697321581788

Epoch: 6| Step: 4
Training loss: 0.18650368391162156
Validation loss: 2.3905972647996707

Epoch: 6| Step: 5
Training loss: 0.0728567312058714
Validation loss: 2.3371211497900304

Epoch: 6| Step: 6
Training loss: 0.16460063077371523
Validation loss: 2.3182127999602975

Epoch: 6| Step: 7
Training loss: 0.09632280737252338
Validation loss: 2.2880989456579037

Epoch: 6| Step: 8
Training loss: 0.09352460230136307
Validation loss: 2.2541288527998704

Epoch: 6| Step: 9
Training loss: 0.11560353856409637
Validation loss: 2.2670374641734368

Epoch: 6| Step: 10
Training loss: 0.10625366141518013
Validation loss: 2.2674768135236714

Epoch: 6| Step: 11
Training loss: 0.192049968170366
Validation loss: 2.2478387096096526

Epoch: 6| Step: 12
Training loss: 0.22110823358064988
Validation loss: 2.268461124266236

Epoch: 6| Step: 13
Training loss: 0.21102926236333247
Validation loss: 2.2714538738642243

Epoch: 677| Step: 0
Training loss: 0.10405682395083897
Validation loss: 2.267769983652605

Epoch: 6| Step: 1
Training loss: 0.12775560721691095
Validation loss: 2.317133439096885

Epoch: 6| Step: 2
Training loss: 0.08177991806982
Validation loss: 2.343685741569132

Epoch: 6| Step: 3
Training loss: 0.21265186254836888
Validation loss: 2.3783068656602726

Epoch: 6| Step: 4
Training loss: 0.11958295757149376
Validation loss: 2.3684287999559004

Epoch: 6| Step: 5
Training loss: 0.1803059508325981
Validation loss: 2.3937284928032003

Epoch: 6| Step: 6
Training loss: 0.0609288166657438
Validation loss: 2.3700940714146492

Epoch: 6| Step: 7
Training loss: 0.09828882854546923
Validation loss: 2.4091468003156797

Epoch: 6| Step: 8
Training loss: 0.16663064915180387
Validation loss: 2.4192519830559043

Epoch: 6| Step: 9
Training loss: 0.10243642756725226
Validation loss: 2.39790452846974

Epoch: 6| Step: 10
Training loss: 0.14166766629731226
Validation loss: 2.3895756660266394

Epoch: 6| Step: 11
Training loss: 0.1281106411633695
Validation loss: 2.4014678299981873

Epoch: 6| Step: 12
Training loss: 0.13835074623466384
Validation loss: 2.3764672100138853

Epoch: 6| Step: 13
Training loss: 0.13679488650651714
Validation loss: 2.3590940739995623

Epoch: 678| Step: 0
Training loss: 0.10301581765736462
Validation loss: 2.3619212516244303

Epoch: 6| Step: 1
Training loss: 0.06504948306301606
Validation loss: 2.363372597572671

Epoch: 6| Step: 2
Training loss: 0.14068448609928777
Validation loss: 2.3306722724218534

Epoch: 6| Step: 3
Training loss: 0.10208254415667659
Validation loss: 2.297312020436776

Epoch: 6| Step: 4
Training loss: 0.10912135208670108
Validation loss: 2.3126025455689807

Epoch: 6| Step: 5
Training loss: 0.10710757398725843
Validation loss: 2.313518965943857

Epoch: 6| Step: 6
Training loss: 0.1385060043673095
Validation loss: 2.2882411168655397

Epoch: 6| Step: 7
Training loss: 0.0915934866169657
Validation loss: 2.2950342785902196

Epoch: 6| Step: 8
Training loss: 0.1516255911047437
Validation loss: 2.296124970172209

Epoch: 6| Step: 9
Training loss: 0.13502784456197753
Validation loss: 2.259822781241183

Epoch: 6| Step: 10
Training loss: 0.14582491251497998
Validation loss: 2.2619365496803123

Epoch: 6| Step: 11
Training loss: 0.08893804554828914
Validation loss: 2.2361103635894697

Epoch: 6| Step: 12
Training loss: 0.11285915332061025
Validation loss: 2.244960667677422

Epoch: 6| Step: 13
Training loss: 0.15599125060929572
Validation loss: 2.241902873590056

Epoch: 679| Step: 0
Training loss: 0.1863349641388492
Validation loss: 2.242193655873331

Epoch: 6| Step: 1
Training loss: 0.13876065246612207
Validation loss: 2.265574977550258

Epoch: 6| Step: 2
Training loss: 0.129514199826967
Validation loss: 2.2773003836577335

Epoch: 6| Step: 3
Training loss: 0.11392980754505648
Validation loss: 2.2850558283858655

Epoch: 6| Step: 4
Training loss: 0.08938855460225897
Validation loss: 2.2941403992257063

Epoch: 6| Step: 5
Training loss: 0.10876684475617443
Validation loss: 2.297773679708253

Epoch: 6| Step: 6
Training loss: 0.1593398183905048
Validation loss: 2.311638426869453

Epoch: 6| Step: 7
Training loss: 0.0658875359821348
Validation loss: 2.3088057581173276

Epoch: 6| Step: 8
Training loss: 0.09625247043374542
Validation loss: 2.30037221669906

Epoch: 6| Step: 9
Training loss: 0.1052068088990738
Validation loss: 2.3223656309292777

Epoch: 6| Step: 10
Training loss: 0.10579919265644552
Validation loss: 2.3441875597596056

Epoch: 6| Step: 11
Training loss: 0.12991262394948636
Validation loss: 2.326550408967466

Epoch: 6| Step: 12
Training loss: 0.11064842264414626
Validation loss: 2.304625849996838

Epoch: 6| Step: 13
Training loss: 0.11945154315632123
Validation loss: 2.3211719485587774

Epoch: 680| Step: 0
Training loss: 0.09826612768592068
Validation loss: 2.3215075353331702

Epoch: 6| Step: 1
Training loss: 0.10312784635343712
Validation loss: 2.311098913174889

Epoch: 6| Step: 2
Training loss: 0.15303767935606744
Validation loss: 2.3131009257576474

Epoch: 6| Step: 3
Training loss: 0.16596429816775493
Validation loss: 2.3003116920117677

Epoch: 6| Step: 4
Training loss: 0.12976791204128593
Validation loss: 2.335044586744252

Epoch: 6| Step: 5
Training loss: 0.1721143356626519
Validation loss: 2.353299592896064

Epoch: 6| Step: 6
Training loss: 0.15113661648125531
Validation loss: 2.345100983683567

Epoch: 6| Step: 7
Training loss: 0.15248931141823507
Validation loss: 2.3421909728285093

Epoch: 6| Step: 8
Training loss: 0.08434117564197893
Validation loss: 2.3469962091964476

Epoch: 6| Step: 9
Training loss: 0.15970376106413964
Validation loss: 2.3662112159433097

Epoch: 6| Step: 10
Training loss: 0.18752906494571261
Validation loss: 2.3702362343111374

Epoch: 6| Step: 11
Training loss: 0.2085065906035334
Validation loss: 2.3508940577160877

Epoch: 6| Step: 12
Training loss: 0.07426940607232821
Validation loss: 2.361721969410762

Epoch: 6| Step: 13
Training loss: 0.12214032644870007
Validation loss: 2.3455133237942873

Epoch: 681| Step: 0
Training loss: 0.12275972238750825
Validation loss: 2.3179455501053825

Epoch: 6| Step: 1
Training loss: 0.12829991995826806
Validation loss: 2.2830489558772427

Epoch: 6| Step: 2
Training loss: 0.11065750837189592
Validation loss: 2.2841072410014394

Epoch: 6| Step: 3
Training loss: 0.24921442823339968
Validation loss: 2.2503393799157427

Epoch: 6| Step: 4
Training loss: 0.12649723507145672
Validation loss: 2.246557659448257

Epoch: 6| Step: 5
Training loss: 0.08740789779406206
Validation loss: 2.263467647421846

Epoch: 6| Step: 6
Training loss: 0.07861719654829612
Validation loss: 2.251220899421851

Epoch: 6| Step: 7
Training loss: 0.09887184789217082
Validation loss: 2.241018721204385

Epoch: 6| Step: 8
Training loss: 0.11836136353587998
Validation loss: 2.264644628795731

Epoch: 6| Step: 9
Training loss: 0.1429744268551448
Validation loss: 2.2736247790793067

Epoch: 6| Step: 10
Training loss: 0.1150881113819826
Validation loss: 2.26748825078429

Epoch: 6| Step: 11
Training loss: 0.09839139324050056
Validation loss: 2.2759220282108332

Epoch: 6| Step: 12
Training loss: 0.19362373775590375
Validation loss: 2.3037493209424347

Epoch: 6| Step: 13
Training loss: 0.16911742093069296
Validation loss: 2.281903754650739

Epoch: 682| Step: 0
Training loss: 0.1401562427916254
Validation loss: 2.321364019941766

Epoch: 6| Step: 1
Training loss: 0.1134074470089463
Validation loss: 2.3159058230957967

Epoch: 6| Step: 2
Training loss: 0.06110942708642096
Validation loss: 2.3496009866676255

Epoch: 6| Step: 3
Training loss: 0.1328545672046896
Validation loss: 2.3055420406614417

Epoch: 6| Step: 4
Training loss: 0.11248174062209508
Validation loss: 2.31444212695987

Epoch: 6| Step: 5
Training loss: 0.09482092925316896
Validation loss: 2.3327816876562495

Epoch: 6| Step: 6
Training loss: 0.10166041990716844
Validation loss: 2.31490814594633

Epoch: 6| Step: 7
Training loss: 0.10509809070349196
Validation loss: 2.3491441412042726

Epoch: 6| Step: 8
Training loss: 0.16697437347517885
Validation loss: 2.340326680129452

Epoch: 6| Step: 9
Training loss: 0.13735414403831997
Validation loss: 2.306785557061839

Epoch: 6| Step: 10
Training loss: 0.08420928514407634
Validation loss: 2.311478259103737

Epoch: 6| Step: 11
Training loss: 0.1427594429807733
Validation loss: 2.338511825653599

Epoch: 6| Step: 12
Training loss: 0.0870192298687016
Validation loss: 2.329304749346091

Epoch: 6| Step: 13
Training loss: 0.23308511876109025
Validation loss: 2.3171652042859456

Epoch: 683| Step: 0
Training loss: 0.1550695412131497
Validation loss: 2.3141945702772704

Epoch: 6| Step: 1
Training loss: 0.1513835590491988
Validation loss: 2.3244768183665228

Epoch: 6| Step: 2
Training loss: 0.11861002524530224
Validation loss: 2.324556486416393

Epoch: 6| Step: 3
Training loss: 0.13111278565095918
Validation loss: 2.308889485550846

Epoch: 6| Step: 4
Training loss: 0.10845216072779404
Validation loss: 2.3008386441925546

Epoch: 6| Step: 5
Training loss: 0.16286557551554368
Validation loss: 2.313392085732759

Epoch: 6| Step: 6
Training loss: 0.09079224142416692
Validation loss: 2.289056844234287

Epoch: 6| Step: 7
Training loss: 0.11518664098772226
Validation loss: 2.306992197339435

Epoch: 6| Step: 8
Training loss: 0.14902892371362014
Validation loss: 2.2951092881456425

Epoch: 6| Step: 9
Training loss: 0.10475784471994833
Validation loss: 2.3113087548879574

Epoch: 6| Step: 10
Training loss: 0.09202052831937489
Validation loss: 2.2977914193703954

Epoch: 6| Step: 11
Training loss: 0.1466993725059373
Validation loss: 2.2820604935192117

Epoch: 6| Step: 12
Training loss: 0.08706968818978107
Validation loss: 2.2923617029609353

Epoch: 6| Step: 13
Training loss: 0.06945204415891004
Validation loss: 2.3379232946257664

Epoch: 684| Step: 0
Training loss: 0.14041051136820415
Validation loss: 2.3109339472343953

Epoch: 6| Step: 1
Training loss: 0.185447867229372
Validation loss: 2.311504100788674

Epoch: 6| Step: 2
Training loss: 0.18988198966621203
Validation loss: 2.2986617386403485

Epoch: 6| Step: 3
Training loss: 0.15174246996448848
Validation loss: 2.2834650401016567

Epoch: 6| Step: 4
Training loss: 0.09244079181814321
Validation loss: 2.2964588061945603

Epoch: 6| Step: 5
Training loss: 0.11990723442894391
Validation loss: 2.2939602252833424

Epoch: 6| Step: 6
Training loss: 0.144531037356246
Validation loss: 2.280354148464179

Epoch: 6| Step: 7
Training loss: 0.22427486720948142
Validation loss: 2.271631431564838

Epoch: 6| Step: 8
Training loss: 0.07677448761333332
Validation loss: 2.2624852218920335

Epoch: 6| Step: 9
Training loss: 0.12207696515075146
Validation loss: 2.243637351962423

Epoch: 6| Step: 10
Training loss: 0.1609893449125208
Validation loss: 2.2537792743944247

Epoch: 6| Step: 11
Training loss: 0.20648971845140707
Validation loss: 2.2534498704304777

Epoch: 6| Step: 12
Training loss: 0.3236069594689044
Validation loss: 2.2790094403453742

Epoch: 6| Step: 13
Training loss: 0.12932979475830517
Validation loss: 2.2880588699865894

Epoch: 685| Step: 0
Training loss: 0.11197455437350745
Validation loss: 2.3014147146701665

Epoch: 6| Step: 1
Training loss: 0.2718208615342968
Validation loss: 2.3167263268400506

Epoch: 6| Step: 2
Training loss: 0.16522007106976538
Validation loss: 2.3526951583765814

Epoch: 6| Step: 3
Training loss: 0.3723459299258228
Validation loss: 2.337122412347419

Epoch: 6| Step: 4
Training loss: 0.1572353407974097
Validation loss: 2.3200203244910598

Epoch: 6| Step: 5
Training loss: 0.08896629340689753
Validation loss: 2.2924372707700518

Epoch: 6| Step: 6
Training loss: 0.15779220526097745
Validation loss: 2.3002101828016146

Epoch: 6| Step: 7
Training loss: 0.1608581224534494
Validation loss: 2.288534027618137

Epoch: 6| Step: 8
Training loss: 0.2135493472896748
Validation loss: 2.2755619930072783

Epoch: 6| Step: 9
Training loss: 0.18484898878204784
Validation loss: 2.3008395032560816

Epoch: 6| Step: 10
Training loss: 0.21119059284617672
Validation loss: 2.3015642146457584

Epoch: 6| Step: 11
Training loss: 0.19539099069810495
Validation loss: 2.319202917804057

Epoch: 6| Step: 12
Training loss: 0.219428322036498
Validation loss: 2.3422716719210497

Epoch: 6| Step: 13
Training loss: 0.29109366221894983
Validation loss: 2.3385906899960847

Epoch: 686| Step: 0
Training loss: 0.1509511706675168
Validation loss: 2.359429435479598

Epoch: 6| Step: 1
Training loss: 0.1829894448490791
Validation loss: 2.376363471914513

Epoch: 6| Step: 2
Training loss: 0.13253187938667566
Validation loss: 2.353780269538283

Epoch: 6| Step: 3
Training loss: 0.16578379319889153
Validation loss: 2.3488339332029646

Epoch: 6| Step: 4
Training loss: 0.14717288651378468
Validation loss: 2.310114922365842

Epoch: 6| Step: 5
Training loss: 0.29689968157112284
Validation loss: 2.334166361247187

Epoch: 6| Step: 6
Training loss: 0.20372787288152627
Validation loss: 2.3219078940187194

Epoch: 6| Step: 7
Training loss: 0.1999511066664891
Validation loss: 2.3116012451943235

Epoch: 6| Step: 8
Training loss: 0.18413430642902515
Validation loss: 2.349747119179805

Epoch: 6| Step: 9
Training loss: 0.13482516811610767
Validation loss: 2.3696332910825175

Epoch: 6| Step: 10
Training loss: 0.22183345721417136
Validation loss: 2.392622431532546

Epoch: 6| Step: 11
Training loss: 0.13762329463742354
Validation loss: 2.395808877771087

Epoch: 6| Step: 12
Training loss: 0.20300965518786745
Validation loss: 2.3912574300964735

Epoch: 6| Step: 13
Training loss: 0.18432531293454155
Validation loss: 2.394979806589208

Epoch: 687| Step: 0
Training loss: 0.15523331801616672
Validation loss: 2.3518534766387273

Epoch: 6| Step: 1
Training loss: 0.11522924686594735
Validation loss: 2.3586811712571425

Epoch: 6| Step: 2
Training loss: 0.1470850011372588
Validation loss: 2.3072663892861662

Epoch: 6| Step: 3
Training loss: 0.1039089431987302
Validation loss: 2.285744283074229

Epoch: 6| Step: 4
Training loss: 0.16932039024496628
Validation loss: 2.279128246145139

Epoch: 6| Step: 5
Training loss: 0.16750496776886123
Validation loss: 2.280541677916835

Epoch: 6| Step: 6
Training loss: 0.12631144849395234
Validation loss: 2.27308027542722

Epoch: 6| Step: 7
Training loss: 0.12908489679522958
Validation loss: 2.263635988736789

Epoch: 6| Step: 8
Training loss: 0.1918957348657188
Validation loss: 2.2636120548073784

Epoch: 6| Step: 9
Training loss: 0.1461427009905736
Validation loss: 2.2412498903080915

Epoch: 6| Step: 10
Training loss: 0.14130316897236633
Validation loss: 2.237278198469813

Epoch: 6| Step: 11
Training loss: 0.12274463181522959
Validation loss: 2.253095984106039

Epoch: 6| Step: 12
Training loss: 0.1326637486898405
Validation loss: 2.2429699122377444

Epoch: 6| Step: 13
Training loss: 0.11279841818588135
Validation loss: 2.2593435614654065

Epoch: 688| Step: 0
Training loss: 0.16763002596715806
Validation loss: 2.276781689805841

Epoch: 6| Step: 1
Training loss: 0.10244749158416487
Validation loss: 2.310851018309811

Epoch: 6| Step: 2
Training loss: 0.1443089115304641
Validation loss: 2.330953060378925

Epoch: 6| Step: 3
Training loss: 0.14337933788538582
Validation loss: 2.36514163928462

Epoch: 6| Step: 4
Training loss: 0.1657562361208647
Validation loss: 2.3911619206101293

Epoch: 6| Step: 5
Training loss: 0.14027295153158423
Validation loss: 2.3840133016338343

Epoch: 6| Step: 6
Training loss: 0.09251047310306451
Validation loss: 2.39213021226671

Epoch: 6| Step: 7
Training loss: 0.12075958366672164
Validation loss: 2.397805833035635

Epoch: 6| Step: 8
Training loss: 0.13043062229741192
Validation loss: 2.391980398693891

Epoch: 6| Step: 9
Training loss: 0.26252881698016806
Validation loss: 2.389300012502471

Epoch: 6| Step: 10
Training loss: 0.08252037770215256
Validation loss: 2.334099921271428

Epoch: 6| Step: 11
Training loss: 0.16222837974803603
Validation loss: 2.3216662454171497

Epoch: 6| Step: 12
Training loss: 0.12714806774923587
Validation loss: 2.291767007881436

Epoch: 6| Step: 13
Training loss: 0.14310191888728901
Validation loss: 2.2879554171016

Epoch: 689| Step: 0
Training loss: 0.14575512242026425
Validation loss: 2.27172097315636

Epoch: 6| Step: 1
Training loss: 0.10224224454963138
Validation loss: 2.247254308024162

Epoch: 6| Step: 2
Training loss: 0.2492985346567635
Validation loss: 2.260221811372481

Epoch: 6| Step: 3
Training loss: 0.1502836020006591
Validation loss: 2.2870414144209787

Epoch: 6| Step: 4
Training loss: 0.16061322217279117
Validation loss: 2.286342683142871

Epoch: 6| Step: 5
Training loss: 0.12435670066284418
Validation loss: 2.3020055205832928

Epoch: 6| Step: 6
Training loss: 0.16022880585439342
Validation loss: 2.3415311574528492

Epoch: 6| Step: 7
Training loss: 0.12180697073823299
Validation loss: 2.389644516373334

Epoch: 6| Step: 8
Training loss: 0.1733577826445288
Validation loss: 2.4086617873823117

Epoch: 6| Step: 9
Training loss: 0.22129885693092002
Validation loss: 2.433192175719467

Epoch: 6| Step: 10
Training loss: 0.1607768085225869
Validation loss: 2.4274874641254707

Epoch: 6| Step: 11
Training loss: 0.20749532221783887
Validation loss: 2.4458295667370233

Epoch: 6| Step: 12
Training loss: 0.2149779160934506
Validation loss: 2.4309611218178797

Epoch: 6| Step: 13
Training loss: 0.11086414927712718
Validation loss: 2.3956303007994055

Epoch: 690| Step: 0
Training loss: 0.17709545954156314
Validation loss: 2.3744860969072015

Epoch: 6| Step: 1
Training loss: 0.101528015150937
Validation loss: 2.3532523070074216

Epoch: 6| Step: 2
Training loss: 0.08869288191484441
Validation loss: 2.3436916636655205

Epoch: 6| Step: 3
Training loss: 0.11504803154636173
Validation loss: 2.3182478612849966

Epoch: 6| Step: 4
Training loss: 0.13531569161075938
Validation loss: 2.3111033302974957

Epoch: 6| Step: 5
Training loss: 0.17223339752491598
Validation loss: 2.2964006550397817

Epoch: 6| Step: 6
Training loss: 0.16267914205105313
Validation loss: 2.2671180159304334

Epoch: 6| Step: 7
Training loss: 0.13024367488615637
Validation loss: 2.2604484750562364

Epoch: 6| Step: 8
Training loss: 0.27065878831170626
Validation loss: 2.267195657658733

Epoch: 6| Step: 9
Training loss: 0.11142873400721724
Validation loss: 2.3081003466955408

Epoch: 6| Step: 10
Training loss: 0.1941695723261644
Validation loss: 2.2950980940872965

Epoch: 6| Step: 11
Training loss: 0.11657499541047038
Validation loss: 2.3389912565549174

Epoch: 6| Step: 12
Training loss: 0.1003676146917367
Validation loss: 2.359504113769415

Epoch: 6| Step: 13
Training loss: 0.1812793461292432
Validation loss: 2.3840597365303324

Epoch: 691| Step: 0
Training loss: 0.2037527580893661
Validation loss: 2.3854685509647293

Epoch: 6| Step: 1
Training loss: 0.1373263074802565
Validation loss: 2.40046876252692

Epoch: 6| Step: 2
Training loss: 0.15279278235976962
Validation loss: 2.3474113540418258

Epoch: 6| Step: 3
Training loss: 0.13346295395388336
Validation loss: 2.3607846841721343

Epoch: 6| Step: 4
Training loss: 0.16817440151814397
Validation loss: 2.316024255450673

Epoch: 6| Step: 5
Training loss: 0.09843274873287325
Validation loss: 2.3135575390387366

Epoch: 6| Step: 6
Training loss: 0.14597750389116101
Validation loss: 2.314188664366526

Epoch: 6| Step: 7
Training loss: 0.24749735539400952
Validation loss: 2.2823115065033432

Epoch: 6| Step: 8
Training loss: 0.21420318303492475
Validation loss: 2.31563471168418

Epoch: 6| Step: 9
Training loss: 0.1381470662287164
Validation loss: 2.3090532330495064

Epoch: 6| Step: 10
Training loss: 0.2083971025304393
Validation loss: 2.3157029612177094

Epoch: 6| Step: 11
Training loss: 0.16273252375333103
Validation loss: 2.291352735105905

Epoch: 6| Step: 12
Training loss: 0.1882829412803824
Validation loss: 2.2921372684613064

Epoch: 6| Step: 13
Training loss: 0.08746164324170301
Validation loss: 2.2966730005115714

Epoch: 692| Step: 0
Training loss: 0.14096782539925323
Validation loss: 2.2660316348480123

Epoch: 6| Step: 1
Training loss: 0.1036183189727803
Validation loss: 2.281291622468227

Epoch: 6| Step: 2
Training loss: 0.17037246418421118
Validation loss: 2.2828096252280905

Epoch: 6| Step: 3
Training loss: 0.11030290594336688
Validation loss: 2.2670358363388385

Epoch: 6| Step: 4
Training loss: 0.10221329666723868
Validation loss: 2.2869727646644837

Epoch: 6| Step: 5
Training loss: 0.16494916126366665
Validation loss: 2.2890716236726023

Epoch: 6| Step: 6
Training loss: 0.11294107085511208
Validation loss: 2.281207229363897

Epoch: 6| Step: 7
Training loss: 0.12774056731680336
Validation loss: 2.3021140921753966

Epoch: 6| Step: 8
Training loss: 0.15048163001371404
Validation loss: 2.2861209055770924

Epoch: 6| Step: 9
Training loss: 0.12939530858220225
Validation loss: 2.311602088613296

Epoch: 6| Step: 10
Training loss: 0.13655564933676875
Validation loss: 2.3121808116412694

Epoch: 6| Step: 11
Training loss: 0.1885958476925726
Validation loss: 2.317304247511834

Epoch: 6| Step: 12
Training loss: 0.13144155783200828
Validation loss: 2.3466622474925716

Epoch: 6| Step: 13
Training loss: 0.11835199181974085
Validation loss: 2.338602707969213

Epoch: 693| Step: 0
Training loss: 0.16829202282779662
Validation loss: 2.348304627196043

Epoch: 6| Step: 1
Training loss: 0.09291878908542307
Validation loss: 2.345375239145966

Epoch: 6| Step: 2
Training loss: 0.13814600780447087
Validation loss: 2.354482420678807

Epoch: 6| Step: 3
Training loss: 0.18668138098163128
Validation loss: 2.3368892444927853

Epoch: 6| Step: 4
Training loss: 0.21618660959665315
Validation loss: 2.340802430185855

Epoch: 6| Step: 5
Training loss: 0.11542262444614973
Validation loss: 2.340391582590236

Epoch: 6| Step: 6
Training loss: 0.09977275875160276
Validation loss: 2.3012390199448

Epoch: 6| Step: 7
Training loss: 0.08749920257136873
Validation loss: 2.302315387677585

Epoch: 6| Step: 8
Training loss: 0.09157823843168748
Validation loss: 2.289098415186099

Epoch: 6| Step: 9
Training loss: 0.09050997142497114
Validation loss: 2.294899419091261

Epoch: 6| Step: 10
Training loss: 0.2149870914504142
Validation loss: 2.2888684085309734

Epoch: 6| Step: 11
Training loss: 0.08444040708210578
Validation loss: 2.288558676604814

Epoch: 6| Step: 12
Training loss: 0.14146340964197526
Validation loss: 2.299119964045471

Epoch: 6| Step: 13
Training loss: 0.1293245810244027
Validation loss: 2.2777920962701583

Epoch: 694| Step: 0
Training loss: 0.16103937156254144
Validation loss: 2.320532276700836

Epoch: 6| Step: 1
Training loss: 0.09705893950739092
Validation loss: 2.3044108552048805

Epoch: 6| Step: 2
Training loss: 0.10199179153628503
Validation loss: 2.3243701141338455

Epoch: 6| Step: 3
Training loss: 0.1794658413252279
Validation loss: 2.3001575186864094

Epoch: 6| Step: 4
Training loss: 0.12019342623703674
Validation loss: 2.3146749244541414

Epoch: 6| Step: 5
Training loss: 0.1281004414049587
Validation loss: 2.316845299836441

Epoch: 6| Step: 6
Training loss: 0.14295039502079607
Validation loss: 2.358253232432723

Epoch: 6| Step: 7
Training loss: 0.1990066970508203
Validation loss: 2.373509783900668

Epoch: 6| Step: 8
Training loss: 0.13512960292552875
Validation loss: 2.331766407396722

Epoch: 6| Step: 9
Training loss: 0.11119365099542883
Validation loss: 2.2922512177757204

Epoch: 6| Step: 10
Training loss: 0.09959902429095592
Validation loss: 2.2667474070414544

Epoch: 6| Step: 11
Training loss: 0.10786574299844516
Validation loss: 2.2461054045743536

Epoch: 6| Step: 12
Training loss: 0.15535408300935774
Validation loss: 2.2610068419582094

Epoch: 6| Step: 13
Training loss: 0.23587212035650637
Validation loss: 2.232117192608654

Epoch: 695| Step: 0
Training loss: 0.08365024591630381
Validation loss: 2.256049959829044

Epoch: 6| Step: 1
Training loss: 0.09510586688843242
Validation loss: 2.2509365457003843

Epoch: 6| Step: 2
Training loss: 0.09999343284262409
Validation loss: 2.25634165431602

Epoch: 6| Step: 3
Training loss: 0.0966452672162586
Validation loss: 2.2629066082651654

Epoch: 6| Step: 4
Training loss: 0.09546095511897332
Validation loss: 2.2852035754554736

Epoch: 6| Step: 5
Training loss: 0.08439954725127544
Validation loss: 2.295427478049464

Epoch: 6| Step: 6
Training loss: 0.08931960235522937
Validation loss: 2.288169662357403

Epoch: 6| Step: 7
Training loss: 0.16458225798154968
Validation loss: 2.324483693216873

Epoch: 6| Step: 8
Training loss: 0.12557409002208658
Validation loss: 2.3446277683816983

Epoch: 6| Step: 9
Training loss: 0.19030806741422648
Validation loss: 2.366609957563123

Epoch: 6| Step: 10
Training loss: 0.1609745867135148
Validation loss: 2.393463050205132

Epoch: 6| Step: 11
Training loss: 0.12086971770715363
Validation loss: 2.4066692754640275

Epoch: 6| Step: 12
Training loss: 0.14774589289929002
Validation loss: 2.367552565141734

Epoch: 6| Step: 13
Training loss: 0.06147524672004388
Validation loss: 2.379885270698731

Epoch: 696| Step: 0
Training loss: 0.16991277648419467
Validation loss: 2.3732214368507307

Epoch: 6| Step: 1
Training loss: 0.1771850796186045
Validation loss: 2.3858886142978437

Epoch: 6| Step: 2
Training loss: 0.10240240072670413
Validation loss: 2.356999758258504

Epoch: 6| Step: 3
Training loss: 0.16715408864801787
Validation loss: 2.3905307516079386

Epoch: 6| Step: 4
Training loss: 0.1562238075237391
Validation loss: 2.338321701116591

Epoch: 6| Step: 5
Training loss: 0.1590279927042888
Validation loss: 2.2871952484398057

Epoch: 6| Step: 6
Training loss: 0.1321660465389887
Validation loss: 2.2595475445838282

Epoch: 6| Step: 7
Training loss: 0.13391490225063787
Validation loss: 2.2415054700046126

Epoch: 6| Step: 8
Training loss: 0.22423972520179766
Validation loss: 2.258885905629853

Epoch: 6| Step: 9
Training loss: 0.18845617352034577
Validation loss: 2.250954807097974

Epoch: 6| Step: 10
Training loss: 0.20988801088894013
Validation loss: 2.2648235200425875

Epoch: 6| Step: 11
Training loss: 0.20346391354031335
Validation loss: 2.24516300357939

Epoch: 6| Step: 12
Training loss: 0.25318333342171767
Validation loss: 2.3026073837273575

Epoch: 6| Step: 13
Training loss: 0.04617599256344685
Validation loss: 2.2902819845665157

Epoch: 697| Step: 0
Training loss: 0.18634432036513907
Validation loss: 2.3123578136247662

Epoch: 6| Step: 1
Training loss: 0.26950465637813015
Validation loss: 2.3549179755323384

Epoch: 6| Step: 2
Training loss: 0.2745115439605428
Validation loss: 2.3404941819265903

Epoch: 6| Step: 3
Training loss: 0.2911955514037489
Validation loss: 2.3505299434281413

Epoch: 6| Step: 4
Training loss: 0.12208462440515437
Validation loss: 2.369665494415724

Epoch: 6| Step: 5
Training loss: 0.15118799986092363
Validation loss: 2.371851471036788

Epoch: 6| Step: 6
Training loss: 0.11594418757036691
Validation loss: 2.3593640081699268

Epoch: 6| Step: 7
Training loss: 0.18527791456378417
Validation loss: 2.366728882908456

Epoch: 6| Step: 8
Training loss: 0.31713627556650964
Validation loss: 2.3430459368525947

Epoch: 6| Step: 9
Training loss: 0.20699612301499104
Validation loss: 2.350273119245861

Epoch: 6| Step: 10
Training loss: 0.09169273353532255
Validation loss: 2.37649205051837

Epoch: 6| Step: 11
Training loss: 0.224543653077894
Validation loss: 2.404551345021892

Epoch: 6| Step: 12
Training loss: 0.22852618038219852
Validation loss: 2.3982248883094526

Epoch: 6| Step: 13
Training loss: 0.19522769994418485
Validation loss: 2.4280911963343863

Epoch: 698| Step: 0
Training loss: 0.22683009425711198
Validation loss: 2.4454519979104097

Epoch: 6| Step: 1
Training loss: 0.11577072432906849
Validation loss: 2.4381911941394674

Epoch: 6| Step: 2
Training loss: 0.2044606130684202
Validation loss: 2.4663770394694797

Epoch: 6| Step: 3
Training loss: 0.21756835655323012
Validation loss: 2.4588285671764103

Epoch: 6| Step: 4
Training loss: 0.2312162851552053
Validation loss: 2.469648007587438

Epoch: 6| Step: 5
Training loss: 0.2739563787170613
Validation loss: 2.4376619325692594

Epoch: 6| Step: 6
Training loss: 0.1490412217773784
Validation loss: 2.40789544172152

Epoch: 6| Step: 7
Training loss: 0.208964364707049
Validation loss: 2.3990323228747292

Epoch: 6| Step: 8
Training loss: 0.11869964520168186
Validation loss: 2.365444445229029

Epoch: 6| Step: 9
Training loss: 0.247577245186482
Validation loss: 2.336970123919501

Epoch: 6| Step: 10
Training loss: 0.3484372998566331
Validation loss: 2.3243858679230995

Epoch: 6| Step: 11
Training loss: 0.12686211184638566
Validation loss: 2.346907828964499

Epoch: 6| Step: 12
Training loss: 0.1356924432405813
Validation loss: 2.310576060115489

Epoch: 6| Step: 13
Training loss: 0.289944398889615
Validation loss: 2.3317934545989196

Epoch: 699| Step: 0
Training loss: 0.5490448818951702
Validation loss: 2.344088122407936

Epoch: 6| Step: 1
Training loss: 0.14804427866810535
Validation loss: 2.330446882415083

Epoch: 6| Step: 2
Training loss: 0.28889009128273463
Validation loss: 2.3962257766498527

Epoch: 6| Step: 3
Training loss: 0.41581011786983346
Validation loss: 2.383832514495744

Epoch: 6| Step: 4
Training loss: 0.6964396010388312
Validation loss: 2.3292644476538755

Epoch: 6| Step: 5
Training loss: 0.6623876656356017
Validation loss: 2.23765140052615

Epoch: 6| Step: 6
Training loss: 0.22751117093306
Validation loss: 2.1654985235344837

Epoch: 6| Step: 7
Training loss: 0.7265333764586865
Validation loss: 2.163359909468252

Epoch: 6| Step: 8
Training loss: 0.5306714497916556
Validation loss: 2.24211704125866

Epoch: 6| Step: 9
Training loss: 0.7384598934670308
Validation loss: 2.29010785542178

Epoch: 6| Step: 10
Training loss: 0.3637569962972452
Validation loss: 2.232820417099552

Epoch: 6| Step: 11
Training loss: 0.3435545712590631
Validation loss: 2.296075698169779

Epoch: 6| Step: 12
Training loss: 0.2988714174313575
Validation loss: 2.3211997266558946

Epoch: 6| Step: 13
Training loss: 0.296646406606131
Validation loss: 2.3894299377917023

Epoch: 700| Step: 0
Training loss: 0.5120854701697781
Validation loss: 2.4362243888377266

Epoch: 6| Step: 1
Training loss: 0.7831896545317202
Validation loss: 2.465583688775706

Epoch: 6| Step: 2
Training loss: 0.4368907228186444
Validation loss: 2.3979564239193047

Epoch: 6| Step: 3
Training loss: 0.5640704431793475
Validation loss: 2.3269596755275233

Epoch: 6| Step: 4
Training loss: 0.5568492297750625
Validation loss: 2.3087907979839066

Epoch: 6| Step: 5
Training loss: 0.3049990455034048
Validation loss: 2.2414832246617147

Epoch: 6| Step: 6
Training loss: 0.6430004784135833
Validation loss: 2.203100692625403

Epoch: 6| Step: 7
Training loss: 0.9782765414300286
Validation loss: 2.2169693545494344

Epoch: 6| Step: 8
Training loss: 0.5105063366137073
Validation loss: 2.225238187880227

Epoch: 6| Step: 9
Training loss: 0.5689261844770694
Validation loss: 2.2351522656318723

Epoch: 6| Step: 10
Training loss: 0.586091262987027
Validation loss: 2.3058878291463625

Epoch: 6| Step: 11
Training loss: 0.6212250672677437
Validation loss: 2.3887280117230123

Epoch: 6| Step: 12
Training loss: 0.5154414861845722
Validation loss: 2.5329106862632385

Epoch: 6| Step: 13
Training loss: 0.3491882046306131
Validation loss: 2.624469272736751

Epoch: 701| Step: 0
Training loss: 0.8748814298129415
Validation loss: 2.707582698825521

Epoch: 6| Step: 1
Training loss: 0.428053627886892
Validation loss: 2.566435250550639

Epoch: 6| Step: 2
Training loss: 0.6803252856166261
Validation loss: 2.4554492313848177

Epoch: 6| Step: 3
Training loss: 0.5875247818204425
Validation loss: 2.415438390467123

Epoch: 6| Step: 4
Training loss: 0.6388845060608211
Validation loss: 2.4023966849693057

Epoch: 6| Step: 5
Training loss: 0.7032762152935066
Validation loss: 2.4151345448623696

Epoch: 6| Step: 6
Training loss: 0.46428460865098703
Validation loss: 2.424237466982267

Epoch: 6| Step: 7
Training loss: 0.5735965393879776
Validation loss: 2.511738702014174

Epoch: 6| Step: 8
Training loss: 0.5741377273799974
Validation loss: 2.545579685697023

Epoch: 6| Step: 9
Training loss: 0.5457191787138728
Validation loss: 2.5185003961195545

Epoch: 6| Step: 10
Training loss: 0.3437166197782142
Validation loss: 2.5610854703915344

Epoch: 6| Step: 11
Training loss: 0.4805925721438655
Validation loss: 2.5775992704239754

Epoch: 6| Step: 12
Training loss: 0.5000451484800321
Validation loss: 2.5302994499342204

Epoch: 6| Step: 13
Training loss: 0.7154093938141984
Validation loss: 2.501235508439413

Epoch: 702| Step: 0
Training loss: 0.31681756964469276
Validation loss: 2.384403959719424

Epoch: 6| Step: 1
Training loss: 0.5600365631905568
Validation loss: 2.343090638964925

Epoch: 6| Step: 2
Training loss: 0.5349130843766075
Validation loss: 2.315875713288269

Epoch: 6| Step: 3
Training loss: 0.6475751266934723
Validation loss: 2.285045949894361

Epoch: 6| Step: 4
Training loss: 0.568011724848017
Validation loss: 2.286652358429591

Epoch: 6| Step: 5
Training loss: 0.5309885728148879
Validation loss: 2.289444115428951

Epoch: 6| Step: 6
Training loss: 0.5981046203999908
Validation loss: 2.2739781008046247

Epoch: 6| Step: 7
Training loss: 0.5128736204072535
Validation loss: 2.3381040039193435

Epoch: 6| Step: 8
Training loss: 0.42858391272436286
Validation loss: 2.355131372158208

Epoch: 6| Step: 9
Training loss: 0.4124996813859576
Validation loss: 2.356478422239725

Epoch: 6| Step: 10
Training loss: 0.3538969312371494
Validation loss: 2.3659435257879298

Epoch: 6| Step: 11
Training loss: 0.2815168095350077
Validation loss: 2.4208438664299448

Epoch: 6| Step: 12
Training loss: 0.45360288413033256
Validation loss: 2.4254401882702306

Epoch: 6| Step: 13
Training loss: 0.44589043642235177
Validation loss: 2.447555579942565

Epoch: 703| Step: 0
Training loss: 0.5372953335756582
Validation loss: 2.454650701251946

Epoch: 6| Step: 1
Training loss: 0.28984466614282806
Validation loss: 2.4399566197788007

Epoch: 6| Step: 2
Training loss: 0.48532431389749303
Validation loss: 2.4183738189357142

Epoch: 6| Step: 3
Training loss: 0.3962914509557921
Validation loss: 2.3865758743917582

Epoch: 6| Step: 4
Training loss: 0.2706383345492541
Validation loss: 2.3599005020692214

Epoch: 6| Step: 5
Training loss: 0.5302473030183613
Validation loss: 2.3997029097551184

Epoch: 6| Step: 6
Training loss: 0.4542039981279731
Validation loss: 2.3816431138491456

Epoch: 6| Step: 7
Training loss: 0.34783329902352345
Validation loss: 2.3735613413598995

Epoch: 6| Step: 8
Training loss: 0.5938304043587952
Validation loss: 2.3805515256135656

Epoch: 6| Step: 9
Training loss: 0.39345837117315163
Validation loss: 2.360970264032459

Epoch: 6| Step: 10
Training loss: 0.6039176515438106
Validation loss: 2.3312624288925554

Epoch: 6| Step: 11
Training loss: 0.37926947497667934
Validation loss: 2.3093959536922783

Epoch: 6| Step: 12
Training loss: 0.4750724699552331
Validation loss: 2.3258495262272074

Epoch: 6| Step: 13
Training loss: 0.5336629540623834
Validation loss: 2.294261505550113

Epoch: 704| Step: 0
Training loss: 0.3390383219558445
Validation loss: 2.3312982995999114

Epoch: 6| Step: 1
Training loss: 0.38884708155218267
Validation loss: 2.3581800449334605

Epoch: 6| Step: 2
Training loss: 0.41510949827413435
Validation loss: 2.387862821332878

Epoch: 6| Step: 3
Training loss: 0.36036008085608384
Validation loss: 2.3584326122656805

Epoch: 6| Step: 4
Training loss: 0.39685452851490527
Validation loss: 2.3612760466510494

Epoch: 6| Step: 5
Training loss: 0.2917074646117925
Validation loss: 2.3659772405022346

Epoch: 6| Step: 6
Training loss: 0.4300557725799026
Validation loss: 2.357520669072639

Epoch: 6| Step: 7
Training loss: 0.28110936410401494
Validation loss: 2.342285539873645

Epoch: 6| Step: 8
Training loss: 0.41100553957368624
Validation loss: 2.312662133361882

Epoch: 6| Step: 9
Training loss: 0.26303055087478505
Validation loss: 2.3160556539721533

Epoch: 6| Step: 10
Training loss: 0.5296848747165854
Validation loss: 2.2924805487071924

Epoch: 6| Step: 11
Training loss: 0.42949214309060707
Validation loss: 2.287339847982734

Epoch: 6| Step: 12
Training loss: 0.30569733264952365
Validation loss: 2.263408146901123

Epoch: 6| Step: 13
Training loss: 0.44645395717650765
Validation loss: 2.2277821506121853

Epoch: 705| Step: 0
Training loss: 0.368210787046904
Validation loss: 2.267205623537507

Epoch: 6| Step: 1
Training loss: 0.3439439963077834
Validation loss: 2.270948577203918

Epoch: 6| Step: 2
Training loss: 0.40209075232399577
Validation loss: 2.2712917770155587

Epoch: 6| Step: 3
Training loss: 0.4367676804757252
Validation loss: 2.2884726239772313

Epoch: 6| Step: 4
Training loss: 0.27870561130837074
Validation loss: 2.273068275319411

Epoch: 6| Step: 5
Training loss: 0.35262077842735745
Validation loss: 2.2963572958034764

Epoch: 6| Step: 6
Training loss: 0.3521792406266207
Validation loss: 2.2925808407881503

Epoch: 6| Step: 7
Training loss: 0.26879376953243433
Validation loss: 2.2902289645415923

Epoch: 6| Step: 8
Training loss: 0.28701865131718796
Validation loss: 2.288757429324527

Epoch: 6| Step: 9
Training loss: 0.33969413270063537
Validation loss: 2.2929878438810154

Epoch: 6| Step: 10
Training loss: 0.20940147204086645
Validation loss: 2.3014479850680365

Epoch: 6| Step: 11
Training loss: 0.2915610891514504
Validation loss: 2.333359239876841

Epoch: 6| Step: 12
Training loss: 0.3931778080560848
Validation loss: 2.3353981808207633

Epoch: 6| Step: 13
Training loss: 0.2763866242492225
Validation loss: 2.3536165806964355

Epoch: 706| Step: 0
Training loss: 0.3799038564938123
Validation loss: 2.3799598836857077

Epoch: 6| Step: 1
Training loss: 0.45006206799658444
Validation loss: 2.3785692595223793

Epoch: 6| Step: 2
Training loss: 0.2900565042613758
Validation loss: 2.4262438885748008

Epoch: 6| Step: 3
Training loss: 0.2837384524705478
Validation loss: 2.404009429643218

Epoch: 6| Step: 4
Training loss: 0.23355450061229802
Validation loss: 2.390366741581392

Epoch: 6| Step: 5
Training loss: 0.2031586417436016
Validation loss: 2.3852575820197766

Epoch: 6| Step: 6
Training loss: 0.3384691038372003
Validation loss: 2.3885368821701025

Epoch: 6| Step: 7
Training loss: 0.23815907019334523
Validation loss: 2.3596711065640963

Epoch: 6| Step: 8
Training loss: 0.2592490372947983
Validation loss: 2.3750429802607043

Epoch: 6| Step: 9
Training loss: 0.1949746261190544
Validation loss: 2.3662213493072968

Epoch: 6| Step: 10
Training loss: 0.24402888983651208
Validation loss: 2.3589928680270242

Epoch: 6| Step: 11
Training loss: 0.21972295122357896
Validation loss: 2.349613229825841

Epoch: 6| Step: 12
Training loss: 0.23194221882091795
Validation loss: 2.350540213106925

Epoch: 6| Step: 13
Training loss: 0.23762618370654298
Validation loss: 2.3585124963896646

Epoch: 707| Step: 0
Training loss: 0.17971926905875948
Validation loss: 2.369147616420235

Epoch: 6| Step: 1
Training loss: 0.2574470125697367
Validation loss: 2.3662809785028145

Epoch: 6| Step: 2
Training loss: 0.17855204621779316
Validation loss: 2.3593106368696333

Epoch: 6| Step: 3
Training loss: 0.1920842695954675
Validation loss: 2.3796112553155986

Epoch: 6| Step: 4
Training loss: 0.2609377923838182
Validation loss: 2.364514659473247

Epoch: 6| Step: 5
Training loss: 0.20190678771395656
Validation loss: 2.347903295996575

Epoch: 6| Step: 6
Training loss: 0.2553759076629357
Validation loss: 2.379220499357392

Epoch: 6| Step: 7
Training loss: 0.24390150949000092
Validation loss: 2.352467225080875

Epoch: 6| Step: 8
Training loss: 0.1401542958258373
Validation loss: 2.3466963058580443

Epoch: 6| Step: 9
Training loss: 0.2460560088509004
Validation loss: 2.3339670131286625

Epoch: 6| Step: 10
Training loss: 0.25327713127011414
Validation loss: 2.342431243361251

Epoch: 6| Step: 11
Training loss: 0.22532670289774528
Validation loss: 2.3810542572144455

Epoch: 6| Step: 12
Training loss: 0.2468313184554395
Validation loss: 2.372199507452126

Epoch: 6| Step: 13
Training loss: 0.1707908346116405
Validation loss: 2.378160311610971

Epoch: 708| Step: 0
Training loss: 0.19351299040767778
Validation loss: 2.3622306221992657

Epoch: 6| Step: 1
Training loss: 0.1851001582107919
Validation loss: 2.3652392790298724

Epoch: 6| Step: 2
Training loss: 0.20278350844751783
Validation loss: 2.3777061021562673

Epoch: 6| Step: 3
Training loss: 0.19941270026359098
Validation loss: 2.3393974321582474

Epoch: 6| Step: 4
Training loss: 0.21297397206901686
Validation loss: 2.3598540358388185

Epoch: 6| Step: 5
Training loss: 0.1703736503870176
Validation loss: 2.3678984552979028

Epoch: 6| Step: 6
Training loss: 0.1542729347102199
Validation loss: 2.2986844572433602

Epoch: 6| Step: 7
Training loss: 0.2397917336959038
Validation loss: 2.3397510518488054

Epoch: 6| Step: 8
Training loss: 0.15640638393354445
Validation loss: 2.348527726611072

Epoch: 6| Step: 9
Training loss: 0.2931777971215752
Validation loss: 2.335347334432234

Epoch: 6| Step: 10
Training loss: 0.18508258754620618
Validation loss: 2.315086676307991

Epoch: 6| Step: 11
Training loss: 0.23396873230779314
Validation loss: 2.359967478511025

Epoch: 6| Step: 12
Training loss: 0.22652443204247996
Validation loss: 2.3445764890550054

Epoch: 6| Step: 13
Training loss: 0.08601579026007997
Validation loss: 2.3694475274079427

Epoch: 709| Step: 0
Training loss: 0.1452218644703155
Validation loss: 2.3685772365619595

Epoch: 6| Step: 1
Training loss: 0.16563656109820207
Validation loss: 2.3894214124424096

Epoch: 6| Step: 2
Training loss: 0.20678044368084558
Validation loss: 2.394443767782804

Epoch: 6| Step: 3
Training loss: 0.20937672443533797
Validation loss: 2.3749545642973344

Epoch: 6| Step: 4
Training loss: 0.14738579913605637
Validation loss: 2.3949002525268774

Epoch: 6| Step: 5
Training loss: 0.23762601125834087
Validation loss: 2.4166354353106247

Epoch: 6| Step: 6
Training loss: 0.18519736046856589
Validation loss: 2.4041881434563894

Epoch: 6| Step: 7
Training loss: 0.14810982098247155
Validation loss: 2.3889240602691335

Epoch: 6| Step: 8
Training loss: 0.17932215119759035
Validation loss: 2.3690065919626764

Epoch: 6| Step: 9
Training loss: 0.24222316786933132
Validation loss: 2.397217881671496

Epoch: 6| Step: 10
Training loss: 0.19104823865752474
Validation loss: 2.3596476214210105

Epoch: 6| Step: 11
Training loss: 0.12323869407043216
Validation loss: 2.3699647908944135

Epoch: 6| Step: 12
Training loss: 0.2208887349366472
Validation loss: 2.3421372627383286

Epoch: 6| Step: 13
Training loss: 0.22106804681462122
Validation loss: 2.3284962411737267

Epoch: 710| Step: 0
Training loss: 0.1642807802705542
Validation loss: 2.3031097406483547

Epoch: 6| Step: 1
Training loss: 0.1656584094197706
Validation loss: 2.2928301284417083

Epoch: 6| Step: 2
Training loss: 0.17288203428828414
Validation loss: 2.2630166388003516

Epoch: 6| Step: 3
Training loss: 0.25928671150023264
Validation loss: 2.2538769469971776

Epoch: 6| Step: 4
Training loss: 0.1890279482173019
Validation loss: 2.262709275019709

Epoch: 6| Step: 5
Training loss: 0.2246882921982171
Validation loss: 2.276537891349274

Epoch: 6| Step: 6
Training loss: 0.16930631974742094
Validation loss: 2.288830158599739

Epoch: 6| Step: 7
Training loss: 0.1021766889756195
Validation loss: 2.292115993209096

Epoch: 6| Step: 8
Training loss: 0.19031661173257666
Validation loss: 2.302187112735125

Epoch: 6| Step: 9
Training loss: 0.17545649410970443
Validation loss: 2.3118406240937066

Epoch: 6| Step: 10
Training loss: 0.15720569874960263
Validation loss: 2.3382098747323585

Epoch: 6| Step: 11
Training loss: 0.14678528714084696
Validation loss: 2.340578725436169

Epoch: 6| Step: 12
Training loss: 0.1135941574031655
Validation loss: 2.3577358509373827

Epoch: 6| Step: 13
Training loss: 0.17726781412507098
Validation loss: 2.374189978105202

Epoch: 711| Step: 0
Training loss: 0.15555631912584267
Validation loss: 2.3602244871537645

Epoch: 6| Step: 1
Training loss: 0.24211358665257116
Validation loss: 2.415830795597241

Epoch: 6| Step: 2
Training loss: 0.14722044071982995
Validation loss: 2.369522152602579

Epoch: 6| Step: 3
Training loss: 0.16724812264165698
Validation loss: 2.3957534682207227

Epoch: 6| Step: 4
Training loss: 0.15199220885289144
Validation loss: 2.3601583869779046

Epoch: 6| Step: 5
Training loss: 0.14444026144962477
Validation loss: 2.34920690532906

Epoch: 6| Step: 6
Training loss: 0.1763515651369794
Validation loss: 2.33426062078889

Epoch: 6| Step: 7
Training loss: 0.17646972615718642
Validation loss: 2.3215227508800518

Epoch: 6| Step: 8
Training loss: 0.14619150129887223
Validation loss: 2.3255442208757544

Epoch: 6| Step: 9
Training loss: 0.21353649020705154
Validation loss: 2.2854375502898034

Epoch: 6| Step: 10
Training loss: 0.15912172514271747
Validation loss: 2.3200590469574656

Epoch: 6| Step: 11
Training loss: 0.1742526132662679
Validation loss: 2.327418697339944

Epoch: 6| Step: 12
Training loss: 0.1906819555526174
Validation loss: 2.309043508295096

Epoch: 6| Step: 13
Training loss: 0.13937767830229703
Validation loss: 2.3152941790273642

Epoch: 712| Step: 0
Training loss: 0.10380493975835717
Validation loss: 2.28930610296522

Epoch: 6| Step: 1
Training loss: 0.176704150953594
Validation loss: 2.300444594370917

Epoch: 6| Step: 2
Training loss: 0.1289585036516477
Validation loss: 2.3100956282425114

Epoch: 6| Step: 3
Training loss: 0.09407312616734596
Validation loss: 2.320720792609515

Epoch: 6| Step: 4
Training loss: 0.11722712641538738
Validation loss: 2.3149318922804896

Epoch: 6| Step: 5
Training loss: 0.1060479385027006
Validation loss: 2.341427716956789

Epoch: 6| Step: 6
Training loss: 0.14985557845589217
Validation loss: 2.333862674969485

Epoch: 6| Step: 7
Training loss: 0.08365099742624515
Validation loss: 2.337773349202202

Epoch: 6| Step: 8
Training loss: 0.13793232992229065
Validation loss: 2.3609953197032874

Epoch: 6| Step: 9
Training loss: 0.19797561838328265
Validation loss: 2.3320438157043983

Epoch: 6| Step: 10
Training loss: 0.114501461036129
Validation loss: 2.3453705280438566

Epoch: 6| Step: 11
Training loss: 0.12855066760862408
Validation loss: 2.320762771234392

Epoch: 6| Step: 12
Training loss: 0.16268364748861258
Validation loss: 2.3128763439709936

Epoch: 6| Step: 13
Training loss: 0.09104244692404061
Validation loss: 2.3302159477456876

Epoch: 713| Step: 0
Training loss: 0.1647416714005186
Validation loss: 2.3063745029690375

Epoch: 6| Step: 1
Training loss: 0.14401083118960809
Validation loss: 2.3304572130928722

Epoch: 6| Step: 2
Training loss: 0.13629761275162075
Validation loss: 2.30129046621518

Epoch: 6| Step: 3
Training loss: 0.15634585658889613
Validation loss: 2.3214692713009297

Epoch: 6| Step: 4
Training loss: 0.14153996805110972
Validation loss: 2.3349358648699057

Epoch: 6| Step: 5
Training loss: 0.09289204895557943
Validation loss: 2.3307997727173255

Epoch: 6| Step: 6
Training loss: 0.18295474142953144
Validation loss: 2.3411918346436362

Epoch: 6| Step: 7
Training loss: 0.14075952294506638
Validation loss: 2.338212887669736

Epoch: 6| Step: 8
Training loss: 0.13659205015517245
Validation loss: 2.3352356378722505

Epoch: 6| Step: 9
Training loss: 0.07643604016196626
Validation loss: 2.3873714317697066

Epoch: 6| Step: 10
Training loss: 0.10400112578207965
Validation loss: 2.4112964860107065

Epoch: 6| Step: 11
Training loss: 0.20307649436754474
Validation loss: 2.4071941944400534

Epoch: 6| Step: 12
Training loss: 0.13140088105545028
Validation loss: 2.4053714428415787

Epoch: 6| Step: 13
Training loss: 0.09095485524922273
Validation loss: 2.3791096352496974

Epoch: 714| Step: 0
Training loss: 0.13656864100076502
Validation loss: 2.4020988498931497

Epoch: 6| Step: 1
Training loss: 0.11106911025181802
Validation loss: 2.3907497951710033

Epoch: 6| Step: 2
Training loss: 0.18947329856198225
Validation loss: 2.396033083884636

Epoch: 6| Step: 3
Training loss: 0.11842939836024009
Validation loss: 2.3650946603424505

Epoch: 6| Step: 4
Training loss: 0.18125735629708178
Validation loss: 2.3663772154116804

Epoch: 6| Step: 5
Training loss: 0.10638865879335593
Validation loss: 2.365773561204855

Epoch: 6| Step: 6
Training loss: 0.16474257591485064
Validation loss: 2.336941367159452

Epoch: 6| Step: 7
Training loss: 0.09121108841321987
Validation loss: 2.3254869001067306

Epoch: 6| Step: 8
Training loss: 0.1414377382953236
Validation loss: 2.3143314114785305

Epoch: 6| Step: 9
Training loss: 0.14086247631685167
Validation loss: 2.3093330073205895

Epoch: 6| Step: 10
Training loss: 0.12422429738163673
Validation loss: 2.3043686713143052

Epoch: 6| Step: 11
Training loss: 0.12978989999338225
Validation loss: 2.29861879456419

Epoch: 6| Step: 12
Training loss: 0.19932336491385771
Validation loss: 2.3032536722036423

Epoch: 6| Step: 13
Training loss: 0.22126540573547804
Validation loss: 2.2870773145466634

Epoch: 715| Step: 0
Training loss: 0.14835379775352805
Validation loss: 2.303030557956138

Epoch: 6| Step: 1
Training loss: 0.16355548011144944
Validation loss: 2.2964007331859193

Epoch: 6| Step: 2
Training loss: 0.12764228686071433
Validation loss: 2.311858747616608

Epoch: 6| Step: 3
Training loss: 0.12419381791147938
Validation loss: 2.2843987317793553

Epoch: 6| Step: 4
Training loss: 0.13753870587247177
Validation loss: 2.290700023601976

Epoch: 6| Step: 5
Training loss: 0.1681640509805886
Validation loss: 2.2939903377686335

Epoch: 6| Step: 6
Training loss: 0.13798952797274533
Validation loss: 2.2612924444837925

Epoch: 6| Step: 7
Training loss: 0.10831473959705666
Validation loss: 2.2878730665835607

Epoch: 6| Step: 8
Training loss: 0.13202391750808934
Validation loss: 2.2808737315980814

Epoch: 6| Step: 9
Training loss: 0.10710965646919646
Validation loss: 2.285274920218894

Epoch: 6| Step: 10
Training loss: 0.11959692858490723
Validation loss: 2.2801577737113696

Epoch: 6| Step: 11
Training loss: 0.15581627491243005
Validation loss: 2.3080908667273974

Epoch: 6| Step: 12
Training loss: 0.13905564784195182
Validation loss: 2.2933933886262383

Epoch: 6| Step: 13
Training loss: 0.07885568870789271
Validation loss: 2.3056480067786693

Epoch: 716| Step: 0
Training loss: 0.11739286865218734
Validation loss: 2.324516954367803

Epoch: 6| Step: 1
Training loss: 0.19819243986071997
Validation loss: 2.346758393152467

Epoch: 6| Step: 2
Training loss: 0.1334723810819789
Validation loss: 2.3356667753845324

Epoch: 6| Step: 3
Training loss: 0.19504055163966552
Validation loss: 2.3191660381408243

Epoch: 6| Step: 4
Training loss: 0.1442991532464473
Validation loss: 2.332188257079706

Epoch: 6| Step: 5
Training loss: 0.12875287728659277
Validation loss: 2.3103075684463636

Epoch: 6| Step: 6
Training loss: 0.13446569930332108
Validation loss: 2.3131061126583092

Epoch: 6| Step: 7
Training loss: 0.09883307908197275
Validation loss: 2.321496206292427

Epoch: 6| Step: 8
Training loss: 0.09964988856976907
Validation loss: 2.2988054390425825

Epoch: 6| Step: 9
Training loss: 0.1359897113153193
Validation loss: 2.298639590978729

Epoch: 6| Step: 10
Training loss: 0.13615654748039677
Validation loss: 2.3428583616231964

Epoch: 6| Step: 11
Training loss: 0.11795450181368486
Validation loss: 2.314962337731228

Epoch: 6| Step: 12
Training loss: 0.16585644776451497
Validation loss: 2.312275920854617

Epoch: 6| Step: 13
Training loss: 0.0864411383524754
Validation loss: 2.309867890810907

Epoch: 717| Step: 0
Training loss: 0.11740260250943255
Validation loss: 2.3260867593682866

Epoch: 6| Step: 1
Training loss: 0.09466203477763566
Validation loss: 2.318747020414704

Epoch: 6| Step: 2
Training loss: 0.12816159144527559
Validation loss: 2.289554191334548

Epoch: 6| Step: 3
Training loss: 0.1028204236629602
Validation loss: 2.32416502567422

Epoch: 6| Step: 4
Training loss: 0.1234605586569886
Validation loss: 2.2997270949194872

Epoch: 6| Step: 5
Training loss: 0.14809245864730164
Validation loss: 2.301654675724917

Epoch: 6| Step: 6
Training loss: 0.12349464294990734
Validation loss: 2.2969237816218957

Epoch: 6| Step: 7
Training loss: 0.13934846150692215
Validation loss: 2.3151196245433443

Epoch: 6| Step: 8
Training loss: 0.1051729699540993
Validation loss: 2.32613420099917

Epoch: 6| Step: 9
Training loss: 0.09479050591914416
Validation loss: 2.2920860674911916

Epoch: 6| Step: 10
Training loss: 0.10546638786355149
Validation loss: 2.3454362645520765

Epoch: 6| Step: 11
Training loss: 0.14637781081729997
Validation loss: 2.38120123175103

Epoch: 6| Step: 12
Training loss: 0.10905505113932529
Validation loss: 2.3418180634474504

Epoch: 6| Step: 13
Training loss: 0.06877290780256604
Validation loss: 2.3768978146334194

Epoch: 718| Step: 0
Training loss: 0.19056272505699673
Validation loss: 2.349693136660842

Epoch: 6| Step: 1
Training loss: 0.12607196034625553
Validation loss: 2.3678347742552472

Epoch: 6| Step: 2
Training loss: 0.11697824391872697
Validation loss: 2.3383296930137147

Epoch: 6| Step: 3
Training loss: 0.05175433507069787
Validation loss: 2.3534455199878965

Epoch: 6| Step: 4
Training loss: 0.1069163913912189
Validation loss: 2.3683022787044026

Epoch: 6| Step: 5
Training loss: 0.1327125369468667
Validation loss: 2.3610648693773917

Epoch: 6| Step: 6
Training loss: 0.18372179192757887
Validation loss: 2.3485738377149548

Epoch: 6| Step: 7
Training loss: 0.097859476344327
Validation loss: 2.311767095037479

Epoch: 6| Step: 8
Training loss: 0.1193455980951415
Validation loss: 2.310161161964221

Epoch: 6| Step: 9
Training loss: 0.09644358637652925
Validation loss: 2.2940194496675392

Epoch: 6| Step: 10
Training loss: 0.10944944215551124
Validation loss: 2.3010371492586508

Epoch: 6| Step: 11
Training loss: 0.16162588798119704
Validation loss: 2.286714763185168

Epoch: 6| Step: 12
Training loss: 0.06286770716988427
Validation loss: 2.306133034260587

Epoch: 6| Step: 13
Training loss: 0.09133162182590158
Validation loss: 2.2781244348145813

Epoch: 719| Step: 0
Training loss: 0.147645348696476
Validation loss: 2.2892177531517635

Epoch: 6| Step: 1
Training loss: 0.15282764976972812
Validation loss: 2.30471944896313

Epoch: 6| Step: 2
Training loss: 0.11178777569701945
Validation loss: 2.3033478077486125

Epoch: 6| Step: 3
Training loss: 0.11894195439150583
Validation loss: 2.306711712387364

Epoch: 6| Step: 4
Training loss: 0.09956745125635497
Validation loss: 2.2997577539218383

Epoch: 6| Step: 5
Training loss: 0.10145336027395703
Validation loss: 2.313683974719193

Epoch: 6| Step: 6
Training loss: 0.17619127560048176
Validation loss: 2.3218826257825604

Epoch: 6| Step: 7
Training loss: 0.14797783250738522
Validation loss: 2.3330611509308046

Epoch: 6| Step: 8
Training loss: 0.1795308632842332
Validation loss: 2.315772610799686

Epoch: 6| Step: 9
Training loss: 0.1389490366542005
Validation loss: 2.300108973390222

Epoch: 6| Step: 10
Training loss: 0.10585364118580885
Validation loss: 2.293143668066852

Epoch: 6| Step: 11
Training loss: 0.09045458032890598
Validation loss: 2.292929843405431

Epoch: 6| Step: 12
Training loss: 0.14058408539345127
Validation loss: 2.293441019737185

Epoch: 6| Step: 13
Training loss: 0.11122926706363262
Validation loss: 2.2709216474836333

Epoch: 720| Step: 0
Training loss: 0.10530734957996496
Validation loss: 2.3072751304192964

Epoch: 6| Step: 1
Training loss: 0.13925941006251033
Validation loss: 2.301586750329568

Epoch: 6| Step: 2
Training loss: 0.14808881110339225
Validation loss: 2.28145529328559

Epoch: 6| Step: 3
Training loss: 0.11783230924897586
Validation loss: 2.272666223811696

Epoch: 6| Step: 4
Training loss: 0.10153815087630261
Validation loss: 2.2729999851539557

Epoch: 6| Step: 5
Training loss: 0.10600173464235203
Validation loss: 2.278858112672465

Epoch: 6| Step: 6
Training loss: 0.11667895440406746
Validation loss: 2.2936184597083407

Epoch: 6| Step: 7
Training loss: 0.14156147619639317
Validation loss: 2.299617977526149

Epoch: 6| Step: 8
Training loss: 0.14791031127583062
Validation loss: 2.288155818786257

Epoch: 6| Step: 9
Training loss: 0.1370371381001355
Validation loss: 2.292300487546741

Epoch: 6| Step: 10
Training loss: 0.11370749685572255
Validation loss: 2.3389397648707244

Epoch: 6| Step: 11
Training loss: 0.1035940529961276
Validation loss: 2.3025823573907918

Epoch: 6| Step: 12
Training loss: 0.0826860643512342
Validation loss: 2.3425013365484384

Epoch: 6| Step: 13
Training loss: 0.1703905897739519
Validation loss: 2.3589923420389116

Epoch: 721| Step: 0
Training loss: 0.14236818167785165
Validation loss: 2.33376876515489

Epoch: 6| Step: 1
Training loss: 0.10396900397287759
Validation loss: 2.3349389127745037

Epoch: 6| Step: 2
Training loss: 0.1157635725094017
Validation loss: 2.3580590848463325

Epoch: 6| Step: 3
Training loss: 0.09691115327686853
Validation loss: 2.3266398858979813

Epoch: 6| Step: 4
Training loss: 0.05695012639371211
Validation loss: 2.3173771251821305

Epoch: 6| Step: 5
Training loss: 0.11502984856848013
Validation loss: 2.3082348558615955

Epoch: 6| Step: 6
Training loss: 0.1286774034476325
Validation loss: 2.2805185824110317

Epoch: 6| Step: 7
Training loss: 0.13414953912033067
Validation loss: 2.301574941177581

Epoch: 6| Step: 8
Training loss: 0.18944850404747288
Validation loss: 2.2946043389612196

Epoch: 6| Step: 9
Training loss: 0.1805396295873927
Validation loss: 2.2910719697450843

Epoch: 6| Step: 10
Training loss: 0.09125450898813968
Validation loss: 2.2908740103772653

Epoch: 6| Step: 11
Training loss: 0.12429603145991673
Validation loss: 2.2960185165346787

Epoch: 6| Step: 12
Training loss: 0.16356658917753614
Validation loss: 2.294002681594145

Epoch: 6| Step: 13
Training loss: 0.09029497469077233
Validation loss: 2.3070243164912636

Epoch: 722| Step: 0
Training loss: 0.11474029851036312
Validation loss: 2.2962673539526746

Epoch: 6| Step: 1
Training loss: 0.10053366626922369
Validation loss: 2.3127946397099035

Epoch: 6| Step: 2
Training loss: 0.10386520862308234
Validation loss: 2.3361158312160435

Epoch: 6| Step: 3
Training loss: 0.1432868639013632
Validation loss: 2.327576022994872

Epoch: 6| Step: 4
Training loss: 0.08973467466745053
Validation loss: 2.3318292792077595

Epoch: 6| Step: 5
Training loss: 0.12044048994616033
Validation loss: 2.3009536995818407

Epoch: 6| Step: 6
Training loss: 0.14390836989573705
Validation loss: 2.302981402528773

Epoch: 6| Step: 7
Training loss: 0.09281151140855327
Validation loss: 2.3160208516863436

Epoch: 6| Step: 8
Training loss: 0.0915339539656942
Validation loss: 2.3398906738598573

Epoch: 6| Step: 9
Training loss: 0.10444418080681445
Validation loss: 2.3263083918535954

Epoch: 6| Step: 10
Training loss: 0.07844197818997242
Validation loss: 2.312963128379332

Epoch: 6| Step: 11
Training loss: 0.08571337333039983
Validation loss: 2.2835064711953077

Epoch: 6| Step: 12
Training loss: 0.10144171960701424
Validation loss: 2.314433158129669

Epoch: 6| Step: 13
Training loss: 0.12338499509815333
Validation loss: 2.3063894476524047

Epoch: 723| Step: 0
Training loss: 0.07617008989638806
Validation loss: 2.3090867597672804

Epoch: 6| Step: 1
Training loss: 0.08554413292465994
Validation loss: 2.3015967939645385

Epoch: 6| Step: 2
Training loss: 0.08911626619217407
Validation loss: 2.30478969685963

Epoch: 6| Step: 3
Training loss: 0.12586385283268298
Validation loss: 2.308138748220899

Epoch: 6| Step: 4
Training loss: 0.11062197341658092
Validation loss: 2.3010340756671055

Epoch: 6| Step: 5
Training loss: 0.13115915435581954
Validation loss: 2.3124984302199474

Epoch: 6| Step: 6
Training loss: 0.11776853601811484
Validation loss: 2.318248243909996

Epoch: 6| Step: 7
Training loss: 0.14517454731105175
Validation loss: 2.272448929609097

Epoch: 6| Step: 8
Training loss: 0.09701412808502487
Validation loss: 2.3103327208229376

Epoch: 6| Step: 9
Training loss: 0.08913111009893745
Validation loss: 2.2819877866538394

Epoch: 6| Step: 10
Training loss: 0.12291881542900401
Validation loss: 2.299928498460834

Epoch: 6| Step: 11
Training loss: 0.08625438095106573
Validation loss: 2.3029440955551914

Epoch: 6| Step: 12
Training loss: 0.0913078287673973
Validation loss: 2.299090728284729

Epoch: 6| Step: 13
Training loss: 0.13766544099189765
Validation loss: 2.315217995280001

Epoch: 724| Step: 0
Training loss: 0.10331251352942414
Validation loss: 2.312276358794547

Epoch: 6| Step: 1
Training loss: 0.11308799076357538
Validation loss: 2.3404567340884825

Epoch: 6| Step: 2
Training loss: 0.08691033880422137
Validation loss: 2.330806025900693

Epoch: 6| Step: 3
Training loss: 0.11185104133552218
Validation loss: 2.314470612762014

Epoch: 6| Step: 4
Training loss: 0.10031521577367482
Validation loss: 2.311448895722679

Epoch: 6| Step: 5
Training loss: 0.08479844646691741
Validation loss: 2.333454146165435

Epoch: 6| Step: 6
Training loss: 0.14642734689067585
Validation loss: 2.3096551688033333

Epoch: 6| Step: 7
Training loss: 0.11920592207157757
Validation loss: 2.326771549406355

Epoch: 6| Step: 8
Training loss: 0.09335079732299244
Validation loss: 2.3085672011145952

Epoch: 6| Step: 9
Training loss: 0.09900890540909914
Validation loss: 2.293804899990812

Epoch: 6| Step: 10
Training loss: 0.0854368773131084
Validation loss: 2.336069131675554

Epoch: 6| Step: 11
Training loss: 0.06458754322279607
Validation loss: 2.312657407720796

Epoch: 6| Step: 12
Training loss: 0.08777190773704212
Validation loss: 2.323260836159656

Epoch: 6| Step: 13
Training loss: 0.10574050172716923
Validation loss: 2.329047670534382

Epoch: 725| Step: 0
Training loss: 0.06930298089153772
Validation loss: 2.3240707922553985

Epoch: 6| Step: 1
Training loss: 0.1467653377493191
Validation loss: 2.3480644259578543

Epoch: 6| Step: 2
Training loss: 0.12348204062648435
Validation loss: 2.326429392813498

Epoch: 6| Step: 3
Training loss: 0.10826906439787234
Validation loss: 2.3570314875876996

Epoch: 6| Step: 4
Training loss: 0.12799883567990178
Validation loss: 2.3414316230266934

Epoch: 6| Step: 5
Training loss: 0.1322094465303648
Validation loss: 2.3499310702633163

Epoch: 6| Step: 6
Training loss: 0.12141011811259461
Validation loss: 2.3523278956340925

Epoch: 6| Step: 7
Training loss: 0.12929358233267035
Validation loss: 2.3424548141067034

Epoch: 6| Step: 8
Training loss: 0.14975402527423884
Validation loss: 2.3710366821827744

Epoch: 6| Step: 9
Training loss: 0.11187486910945545
Validation loss: 2.3731953273886934

Epoch: 6| Step: 10
Training loss: 0.16359548288172637
Validation loss: 2.3549118089645242

Epoch: 6| Step: 11
Training loss: 0.12308200834147504
Validation loss: 2.371776162505168

Epoch: 6| Step: 12
Training loss: 0.07083784317229154
Validation loss: 2.352198317386751

Epoch: 6| Step: 13
Training loss: 0.06932903980814804
Validation loss: 2.3629136100156445

Epoch: 726| Step: 0
Training loss: 0.06791883957286428
Validation loss: 2.3388656891259623

Epoch: 6| Step: 1
Training loss: 0.08808877912873277
Validation loss: 2.3714718175743794

Epoch: 6| Step: 2
Training loss: 0.12839076983399686
Validation loss: 2.3504252552571048

Epoch: 6| Step: 3
Training loss: 0.08440625883269731
Validation loss: 2.34298256399776

Epoch: 6| Step: 4
Training loss: 0.1371265120814124
Validation loss: 2.3531204245159683

Epoch: 6| Step: 5
Training loss: 0.08154134977184013
Validation loss: 2.3190590342759663

Epoch: 6| Step: 6
Training loss: 0.0975194640630196
Validation loss: 2.3081438762989555

Epoch: 6| Step: 7
Training loss: 0.1255103362773864
Validation loss: 2.314775132624174

Epoch: 6| Step: 8
Training loss: 0.12726034990668883
Validation loss: 2.32475055950261

Epoch: 6| Step: 9
Training loss: 0.10539682461267458
Validation loss: 2.319626898398446

Epoch: 6| Step: 10
Training loss: 0.12698107191736963
Validation loss: 2.308829334038208

Epoch: 6| Step: 11
Training loss: 0.07074957014958347
Validation loss: 2.3081083271657783

Epoch: 6| Step: 12
Training loss: 0.07109017258331245
Validation loss: 2.3028235477146675

Epoch: 6| Step: 13
Training loss: 0.1018261833553101
Validation loss: 2.3269720300990575

Epoch: 727| Step: 0
Training loss: 0.10898584720341874
Validation loss: 2.3221423492254374

Epoch: 6| Step: 1
Training loss: 0.12728501000717166
Validation loss: 2.3237216278910497

Epoch: 6| Step: 2
Training loss: 0.04645249070665714
Validation loss: 2.3063667110205968

Epoch: 6| Step: 3
Training loss: 0.1213437737126687
Validation loss: 2.3205908063620573

Epoch: 6| Step: 4
Training loss: 0.12870182097685445
Validation loss: 2.311965347339405

Epoch: 6| Step: 5
Training loss: 0.12840890308479175
Validation loss: 2.308750328632778

Epoch: 6| Step: 6
Training loss: 0.07464111761338245
Validation loss: 2.2951689179403356

Epoch: 6| Step: 7
Training loss: 0.07420013219316807
Validation loss: 2.335890096140294

Epoch: 6| Step: 8
Training loss: 0.08539151014129256
Validation loss: 2.3104587437883826

Epoch: 6| Step: 9
Training loss: 0.07246249999240778
Validation loss: 2.3165399852795057

Epoch: 6| Step: 10
Training loss: 0.11838224854099272
Validation loss: 2.3549437536684783

Epoch: 6| Step: 11
Training loss: 0.10817995907927179
Validation loss: 2.3479826738829486

Epoch: 6| Step: 12
Training loss: 0.09657460580482928
Validation loss: 2.3315785228748145

Epoch: 6| Step: 13
Training loss: 0.07081271103947867
Validation loss: 2.3394856029990154

Epoch: 728| Step: 0
Training loss: 0.1168378142624148
Validation loss: 2.356997995142912

Epoch: 6| Step: 1
Training loss: 0.05855718504915136
Validation loss: 2.3267897081278055

Epoch: 6| Step: 2
Training loss: 0.12638158524577583
Validation loss: 2.328249818768054

Epoch: 6| Step: 3
Training loss: 0.09239405811569126
Validation loss: 2.326218406794779

Epoch: 6| Step: 4
Training loss: 0.09669218078963887
Validation loss: 2.33630859048179

Epoch: 6| Step: 5
Training loss: 0.1372941171801753
Validation loss: 2.3467260759342383

Epoch: 6| Step: 6
Training loss: 0.09436478302137191
Validation loss: 2.327514591540731

Epoch: 6| Step: 7
Training loss: 0.09371383784148088
Validation loss: 2.3146687719519012

Epoch: 6| Step: 8
Training loss: 0.12490673609236483
Validation loss: 2.315414837150419

Epoch: 6| Step: 9
Training loss: 0.11382555912244122
Validation loss: 2.323256932091698

Epoch: 6| Step: 10
Training loss: 0.05757272346268724
Validation loss: 2.334794157068322

Epoch: 6| Step: 11
Training loss: 0.08340743862775848
Validation loss: 2.3586893082884406

Epoch: 6| Step: 12
Training loss: 0.09538948475486604
Validation loss: 2.3404474695226845

Epoch: 6| Step: 13
Training loss: 0.15686234053601295
Validation loss: 2.3688400967021015

Epoch: 729| Step: 0
Training loss: 0.0756228233745333
Validation loss: 2.3636548426264534

Epoch: 6| Step: 1
Training loss: 0.07678272386641541
Validation loss: 2.3602546562947806

Epoch: 6| Step: 2
Training loss: 0.10131204424560847
Validation loss: 2.3403802340524584

Epoch: 6| Step: 3
Training loss: 0.12464735086242948
Validation loss: 2.362382616549021

Epoch: 6| Step: 4
Training loss: 0.0827075435970463
Validation loss: 2.360668173238551

Epoch: 6| Step: 5
Training loss: 0.12719916197668307
Validation loss: 2.341127974676496

Epoch: 6| Step: 6
Training loss: 0.06829320566142494
Validation loss: 2.3450815587123466

Epoch: 6| Step: 7
Training loss: 0.09005255897967054
Validation loss: 2.3441102104530307

Epoch: 6| Step: 8
Training loss: 0.1260933445636797
Validation loss: 2.3513248056241713

Epoch: 6| Step: 9
Training loss: 0.09178549107515951
Validation loss: 2.3253074720551843

Epoch: 6| Step: 10
Training loss: 0.10045610771017227
Validation loss: 2.3206929369749902

Epoch: 6| Step: 11
Training loss: 0.16529162116427124
Validation loss: 2.307979376159261

Epoch: 6| Step: 12
Training loss: 0.09020479881786035
Validation loss: 2.3277660532802353

Epoch: 6| Step: 13
Training loss: 0.07759542086569436
Validation loss: 2.3449082726282295

Epoch: 730| Step: 0
Training loss: 0.08301329314146352
Validation loss: 2.318693100067743

Epoch: 6| Step: 1
Training loss: 0.10069987408708023
Validation loss: 2.326010721352395

Epoch: 6| Step: 2
Training loss: 0.08971980086454906
Validation loss: 2.325978951866782

Epoch: 6| Step: 3
Training loss: 0.11103309891135936
Validation loss: 2.330596318013268

Epoch: 6| Step: 4
Training loss: 0.12426704976207473
Validation loss: 2.3106075326717326

Epoch: 6| Step: 5
Training loss: 0.1410008546908156
Validation loss: 2.3042160995364984

Epoch: 6| Step: 6
Training loss: 0.11044431687328779
Validation loss: 2.2827409408592825

Epoch: 6| Step: 7
Training loss: 0.11806556442629541
Validation loss: 2.2688440274294366

Epoch: 6| Step: 8
Training loss: 0.09700776316544811
Validation loss: 2.2892136135253938

Epoch: 6| Step: 9
Training loss: 0.14070519836058878
Validation loss: 2.275565528124157

Epoch: 6| Step: 10
Training loss: 0.1692685524468927
Validation loss: 2.279172275091861

Epoch: 6| Step: 11
Training loss: 0.1403485468289101
Validation loss: 2.289961792818385

Epoch: 6| Step: 12
Training loss: 0.14453485845236805
Validation loss: 2.327588146301999

Epoch: 6| Step: 13
Training loss: 0.07389470622677229
Validation loss: 2.3391205534584767

Epoch: 731| Step: 0
Training loss: 0.09524017388304908
Validation loss: 2.346784905436447

Epoch: 6| Step: 1
Training loss: 0.1570014823388778
Validation loss: 2.3653895886562397

Epoch: 6| Step: 2
Training loss: 0.13746626721928284
Validation loss: 2.364949579151272

Epoch: 6| Step: 3
Training loss: 0.10882075411446583
Validation loss: 2.357065340653382

Epoch: 6| Step: 4
Training loss: 0.18624162605521377
Validation loss: 2.364578643515181

Epoch: 6| Step: 5
Training loss: 0.12179355911062373
Validation loss: 2.361044062129524

Epoch: 6| Step: 6
Training loss: 0.14105244417395357
Validation loss: 2.335186467626894

Epoch: 6| Step: 7
Training loss: 0.10834709876281828
Validation loss: 2.3271703641042505

Epoch: 6| Step: 8
Training loss: 0.10185325707935672
Validation loss: 2.3387941063940665

Epoch: 6| Step: 9
Training loss: 0.10830493709202767
Validation loss: 2.322402499522577

Epoch: 6| Step: 10
Training loss: 0.11988372133668103
Validation loss: 2.330836232381492

Epoch: 6| Step: 11
Training loss: 0.11420061032638203
Validation loss: 2.3195498605893086

Epoch: 6| Step: 12
Training loss: 0.09617716301356585
Validation loss: 2.3267777271997723

Epoch: 6| Step: 13
Training loss: 0.12245103211930737
Validation loss: 2.3397819388577217

Epoch: 732| Step: 0
Training loss: 0.14369897662503844
Validation loss: 2.309230385392429

Epoch: 6| Step: 1
Training loss: 0.14124213015313944
Validation loss: 2.3310619735121034

Epoch: 6| Step: 2
Training loss: 0.11031805221698288
Validation loss: 2.3054785654031247

Epoch: 6| Step: 3
Training loss: 0.07578874174918611
Validation loss: 2.307807204957176

Epoch: 6| Step: 4
Training loss: 0.16274128547130234
Validation loss: 2.3218977544067037

Epoch: 6| Step: 5
Training loss: 0.09064811872054575
Validation loss: 2.3292724854854225

Epoch: 6| Step: 6
Training loss: 0.09069846809122901
Validation loss: 2.3246606937607073

Epoch: 6| Step: 7
Training loss: 0.117232298235603
Validation loss: 2.341363386579137

Epoch: 6| Step: 8
Training loss: 0.18741748901679792
Validation loss: 2.3384317439428166

Epoch: 6| Step: 9
Training loss: 0.1371588707293474
Validation loss: 2.3256354401854376

Epoch: 6| Step: 10
Training loss: 0.10492335695539519
Validation loss: 2.3414997425242166

Epoch: 6| Step: 11
Training loss: 0.08730505744804497
Validation loss: 2.3416344099991075

Epoch: 6| Step: 12
Training loss: 0.14715680597062153
Validation loss: 2.351500860072815

Epoch: 6| Step: 13
Training loss: 0.09513623342623234
Validation loss: 2.32500227608174

Epoch: 733| Step: 0
Training loss: 0.11885449570822854
Validation loss: 2.3225322243213253

Epoch: 6| Step: 1
Training loss: 0.13539534104372142
Validation loss: 2.30534605833853

Epoch: 6| Step: 2
Training loss: 0.09234625695951748
Validation loss: 2.301533814458453

Epoch: 6| Step: 3
Training loss: 0.07589960343765552
Validation loss: 2.303136187146789

Epoch: 6| Step: 4
Training loss: 0.07838007889228546
Validation loss: 2.31173661471385

Epoch: 6| Step: 5
Training loss: 0.07285184796254374
Validation loss: 2.299506935157565

Epoch: 6| Step: 6
Training loss: 0.09592582132971109
Validation loss: 2.2909469365500117

Epoch: 6| Step: 7
Training loss: 0.09477496631022242
Validation loss: 2.292391557981046

Epoch: 6| Step: 8
Training loss: 0.11430609734303043
Validation loss: 2.272370195351459

Epoch: 6| Step: 9
Training loss: 0.10053377743461865
Validation loss: 2.306414970935787

Epoch: 6| Step: 10
Training loss: 0.12108741251451174
Validation loss: 2.2985129337947816

Epoch: 6| Step: 11
Training loss: 0.13516470656647483
Validation loss: 2.28157383688987

Epoch: 6| Step: 12
Training loss: 0.09520838788960992
Validation loss: 2.2810105251336235

Epoch: 6| Step: 13
Training loss: 0.07798842174308154
Validation loss: 2.2922978247056642

Epoch: 734| Step: 0
Training loss: 0.11889910450267083
Validation loss: 2.309607749978428

Epoch: 6| Step: 1
Training loss: 0.09276932155112066
Validation loss: 2.292382406143549

Epoch: 6| Step: 2
Training loss: 0.10051570681196975
Validation loss: 2.2986329035745245

Epoch: 6| Step: 3
Training loss: 0.11441254938101206
Validation loss: 2.320620708063742

Epoch: 6| Step: 4
Training loss: 0.12211926051106874
Validation loss: 2.303065971744213

Epoch: 6| Step: 5
Training loss: 0.08033711142583262
Validation loss: 2.2836320447999965

Epoch: 6| Step: 6
Training loss: 0.12954193931621244
Validation loss: 2.2724732363844895

Epoch: 6| Step: 7
Training loss: 0.11279847598151765
Validation loss: 2.2856360085512946

Epoch: 6| Step: 8
Training loss: 0.08151414784472673
Validation loss: 2.283692490106794

Epoch: 6| Step: 9
Training loss: 0.12479538860512876
Validation loss: 2.2854565197632244

Epoch: 6| Step: 10
Training loss: 0.05913806457154793
Validation loss: 2.2806413046055574

Epoch: 6| Step: 11
Training loss: 0.13441381282057074
Validation loss: 2.2772398564935674

Epoch: 6| Step: 12
Training loss: 0.09076590087364066
Validation loss: 2.2743148494997

Epoch: 6| Step: 13
Training loss: 0.1322469943445065
Validation loss: 2.297935512790725

Epoch: 735| Step: 0
Training loss: 0.09658022301256916
Validation loss: 2.3083307579262793

Epoch: 6| Step: 1
Training loss: 0.087955850664173
Validation loss: 2.2974267887938153

Epoch: 6| Step: 2
Training loss: 0.10906993522275496
Validation loss: 2.286230629034269

Epoch: 6| Step: 3
Training loss: 0.1238699924977853
Validation loss: 2.326041098943155

Epoch: 6| Step: 4
Training loss: 0.08862835366410012
Validation loss: 2.3029911684659115

Epoch: 6| Step: 5
Training loss: 0.12301932132361333
Validation loss: 2.306066319675274

Epoch: 6| Step: 6
Training loss: 0.09170684051526334
Validation loss: 2.328893705960617

Epoch: 6| Step: 7
Training loss: 0.08244790687589092
Validation loss: 2.345475570257372

Epoch: 6| Step: 8
Training loss: 0.07656136300254784
Validation loss: 2.3264565411826656

Epoch: 6| Step: 9
Training loss: 0.11976847000749245
Validation loss: 2.316553728395099

Epoch: 6| Step: 10
Training loss: 0.09136282998107764
Validation loss: 2.343586281147952

Epoch: 6| Step: 11
Training loss: 0.07365409103461497
Validation loss: 2.3038371123723227

Epoch: 6| Step: 12
Training loss: 0.12482344183503208
Validation loss: 2.3226829682376855

Epoch: 6| Step: 13
Training loss: 0.11878527349558901
Validation loss: 2.3446947399121436

Epoch: 736| Step: 0
Training loss: 0.09998706663210435
Validation loss: 2.3258091602537516

Epoch: 6| Step: 1
Training loss: 0.08119785636973431
Validation loss: 2.325058139290664

Epoch: 6| Step: 2
Training loss: 0.13346586380465839
Validation loss: 2.2991601881158736

Epoch: 6| Step: 3
Training loss: 0.142578125
Validation loss: 2.3090371009707726

Epoch: 6| Step: 4
Training loss: 0.12417761163455435
Validation loss: 2.304640313234309

Epoch: 6| Step: 5
Training loss: 0.15462947561552634
Validation loss: 2.2853319275678756

Epoch: 6| Step: 6
Training loss: 0.06861699470789147
Validation loss: 2.2799188244921007

Epoch: 6| Step: 7
Training loss: 0.06391563415413506
Validation loss: 2.2974620752733776

Epoch: 6| Step: 8
Training loss: 0.11893737371851942
Validation loss: 2.3096858747217195

Epoch: 6| Step: 9
Training loss: 0.10106264038848799
Validation loss: 2.301711531336221

Epoch: 6| Step: 10
Training loss: 0.11212293180713334
Validation loss: 2.333029278561601

Epoch: 6| Step: 11
Training loss: 0.10479071567715653
Validation loss: 2.3195979791266024

Epoch: 6| Step: 12
Training loss: 0.08900483443793501
Validation loss: 2.3029308723541706

Epoch: 6| Step: 13
Training loss: 0.13126928267294358
Validation loss: 2.3122471352691583

Epoch: 737| Step: 0
Training loss: 0.09328090011109334
Validation loss: 2.293300621905245

Epoch: 6| Step: 1
Training loss: 0.09668814015284453
Validation loss: 2.299213098076794

Epoch: 6| Step: 2
Training loss: 0.10990224359296591
Validation loss: 2.2700936711308346

Epoch: 6| Step: 3
Training loss: 0.1372814519656246
Validation loss: 2.2805252991860483

Epoch: 6| Step: 4
Training loss: 0.13038948015152682
Validation loss: 2.305942468053067

Epoch: 6| Step: 5
Training loss: 0.11435116516276723
Validation loss: 2.328334496379835

Epoch: 6| Step: 6
Training loss: 0.12040421841746764
Validation loss: 2.3236628405915742

Epoch: 6| Step: 7
Training loss: 0.09935438017176632
Validation loss: 2.3090632292194386

Epoch: 6| Step: 8
Training loss: 0.07915785046581042
Validation loss: 2.3076188805827678

Epoch: 6| Step: 9
Training loss: 0.06087913025443679
Validation loss: 2.2967345319159653

Epoch: 6| Step: 10
Training loss: 0.13219835129741728
Validation loss: 2.3308052117036766

Epoch: 6| Step: 11
Training loss: 0.08843433370246517
Validation loss: 2.3420463730906467

Epoch: 6| Step: 12
Training loss: 0.12358029487012921
Validation loss: 2.3392748663200504

Epoch: 6| Step: 13
Training loss: 0.09486624653583682
Validation loss: 2.344773713367215

Epoch: 738| Step: 0
Training loss: 0.08809044164573351
Validation loss: 2.330255432619598

Epoch: 6| Step: 1
Training loss: 0.06613302471331883
Validation loss: 2.3633947139260103

Epoch: 6| Step: 2
Training loss: 0.07675079587844487
Validation loss: 2.3750852020127287

Epoch: 6| Step: 3
Training loss: 0.14115827166613035
Validation loss: 2.3847907241401196

Epoch: 6| Step: 4
Training loss: 0.12109212720460406
Validation loss: 2.364671869659151

Epoch: 6| Step: 5
Training loss: 0.1417529579334179
Validation loss: 2.381600028800995

Epoch: 6| Step: 6
Training loss: 0.06462142385709659
Validation loss: 2.346531950236097

Epoch: 6| Step: 7
Training loss: 0.09797315675841778
Validation loss: 2.3585099354786556

Epoch: 6| Step: 8
Training loss: 0.1484475571588304
Validation loss: 2.348671242243871

Epoch: 6| Step: 9
Training loss: 0.12805102323570508
Validation loss: 2.352068600389154

Epoch: 6| Step: 10
Training loss: 0.09791630927064615
Validation loss: 2.3270638907924868

Epoch: 6| Step: 11
Training loss: 0.1342395590592721
Validation loss: 2.335639315878199

Epoch: 6| Step: 12
Training loss: 0.09187564108423789
Validation loss: 2.3171421607098726

Epoch: 6| Step: 13
Training loss: 0.10709875233601998
Validation loss: 2.321414824188935

Epoch: 739| Step: 0
Training loss: 0.07087250069596392
Validation loss: 2.327346841289697

Epoch: 6| Step: 1
Training loss: 0.10933176105586773
Validation loss: 2.307417771099242

Epoch: 6| Step: 2
Training loss: 0.10249389380200623
Validation loss: 2.3350594577244603

Epoch: 6| Step: 3
Training loss: 0.0826511095851693
Validation loss: 2.3431313040604573

Epoch: 6| Step: 4
Training loss: 0.06846151895002991
Validation loss: 2.327812405082148

Epoch: 6| Step: 5
Training loss: 0.0940055047633831
Validation loss: 2.3160701310642824

Epoch: 6| Step: 6
Training loss: 0.13545624371651246
Validation loss: 2.3036330647312107

Epoch: 6| Step: 7
Training loss: 0.0569163836252639
Validation loss: 2.3213090940910526

Epoch: 6| Step: 8
Training loss: 0.12727115117972787
Validation loss: 2.3188988948286524

Epoch: 6| Step: 9
Training loss: 0.05782798820593836
Validation loss: 2.2854270637860434

Epoch: 6| Step: 10
Training loss: 0.09079327744929293
Validation loss: 2.3157623895257515

Epoch: 6| Step: 11
Training loss: 0.09490047299899795
Validation loss: 2.294394003595482

Epoch: 6| Step: 12
Training loss: 0.14393786458968494
Validation loss: 2.288316353577767

Epoch: 6| Step: 13
Training loss: 0.15321653948330477
Validation loss: 2.304565662287191

Epoch: 740| Step: 0
Training loss: 0.10108203212742312
Validation loss: 2.3114100789231817

Epoch: 6| Step: 1
Training loss: 0.08837709372332075
Validation loss: 2.2925974778053937

Epoch: 6| Step: 2
Training loss: 0.0770103873288459
Validation loss: 2.319614672696346

Epoch: 6| Step: 3
Training loss: 0.07615990422403726
Validation loss: 2.312188217554386

Epoch: 6| Step: 4
Training loss: 0.09003130885601933
Validation loss: 2.298160198160912

Epoch: 6| Step: 5
Training loss: 0.11669176069872454
Validation loss: 2.2962861412981717

Epoch: 6| Step: 6
Training loss: 0.10570864856128782
Validation loss: 2.3067045822974497

Epoch: 6| Step: 7
Training loss: 0.11707869087661843
Validation loss: 2.278772547045011

Epoch: 6| Step: 8
Training loss: 0.1069105985816938
Validation loss: 2.307923617469801

Epoch: 6| Step: 9
Training loss: 0.11528047350794925
Validation loss: 2.309195375329066

Epoch: 6| Step: 10
Training loss: 0.09838987401791086
Validation loss: 2.27066665331973

Epoch: 6| Step: 11
Training loss: 0.08072108823082627
Validation loss: 2.3261143652558727

Epoch: 6| Step: 12
Training loss: 0.15374036214052997
Validation loss: 2.3004389069676265

Epoch: 6| Step: 13
Training loss: 0.16268774063057384
Validation loss: 2.2949894201374543

Epoch: 741| Step: 0
Training loss: 0.09649633109574622
Validation loss: 2.2922190726621188

Epoch: 6| Step: 1
Training loss: 0.055309700696364386
Validation loss: 2.264922502493938

Epoch: 6| Step: 2
Training loss: 0.0587855101934745
Validation loss: 2.2984818901184054

Epoch: 6| Step: 3
Training loss: 0.09605000360772853
Validation loss: 2.2946296025780275

Epoch: 6| Step: 4
Training loss: 0.08595838076332388
Validation loss: 2.298163221214552

Epoch: 6| Step: 5
Training loss: 0.0668035535931395
Validation loss: 2.333895927130076

Epoch: 6| Step: 6
Training loss: 0.13971793172882943
Validation loss: 2.3038893351854752

Epoch: 6| Step: 7
Training loss: 0.08254023579992535
Validation loss: 2.2930973813016045

Epoch: 6| Step: 8
Training loss: 0.1325393068854937
Validation loss: 2.3055331862102015

Epoch: 6| Step: 9
Training loss: 0.12346303289448493
Validation loss: 2.3128609945064986

Epoch: 6| Step: 10
Training loss: 0.08286053550939067
Validation loss: 2.2830231144534507

Epoch: 6| Step: 11
Training loss: 0.11177839857580565
Validation loss: 2.3032180364616788

Epoch: 6| Step: 12
Training loss: 0.11579954433954766
Validation loss: 2.309183663372703

Epoch: 6| Step: 13
Training loss: 0.12456144947904824
Validation loss: 2.2902754854370615

Epoch: 742| Step: 0
Training loss: 0.07634628331747258
Validation loss: 2.2792781672268974

Epoch: 6| Step: 1
Training loss: 0.07038436303456409
Validation loss: 2.299906047963748

Epoch: 6| Step: 2
Training loss: 0.10248492037666841
Validation loss: 2.2882344031329125

Epoch: 6| Step: 3
Training loss: 0.08629842847226714
Validation loss: 2.295427172033444

Epoch: 6| Step: 4
Training loss: 0.09374469503652093
Validation loss: 2.3284300654989365

Epoch: 6| Step: 5
Training loss: 0.05566748809312498
Validation loss: 2.3280168326368074

Epoch: 6| Step: 6
Training loss: 0.06220491606321636
Validation loss: 2.3080873857310786

Epoch: 6| Step: 7
Training loss: 0.10636735388679393
Validation loss: 2.3206941985278497

Epoch: 6| Step: 8
Training loss: 0.08268768062701576
Validation loss: 2.3140239023522025

Epoch: 6| Step: 9
Training loss: 0.06882897928554259
Validation loss: 2.3220775784122685

Epoch: 6| Step: 10
Training loss: 0.10333741340382095
Validation loss: 2.3249769116385597

Epoch: 6| Step: 11
Training loss: 0.08365932481784262
Validation loss: 2.338250246455001

Epoch: 6| Step: 12
Training loss: 0.11129431462104244
Validation loss: 2.31365866597493

Epoch: 6| Step: 13
Training loss: 0.0551508239408624
Validation loss: 2.313122900182056

Epoch: 743| Step: 0
Training loss: 0.060312617800898964
Validation loss: 2.3282722415021135

Epoch: 6| Step: 1
Training loss: 0.1073026993049705
Validation loss: 2.318954654944044

Epoch: 6| Step: 2
Training loss: 0.1032651804630029
Validation loss: 2.32511232770529

Epoch: 6| Step: 3
Training loss: 0.070127960270092
Validation loss: 2.3318441822368507

Epoch: 6| Step: 4
Training loss: 0.04780668713803917
Validation loss: 2.3210183523552415

Epoch: 6| Step: 5
Training loss: 0.12174479379160942
Validation loss: 2.3390830507490237

Epoch: 6| Step: 6
Training loss: 0.08044034748291086
Validation loss: 2.3348939810315006

Epoch: 6| Step: 7
Training loss: 0.09290057555723315
Validation loss: 2.3008024083557497

Epoch: 6| Step: 8
Training loss: 0.12648924662095376
Validation loss: 2.3308364023129777

Epoch: 6| Step: 9
Training loss: 0.1357110076881277
Validation loss: 2.323657368337897

Epoch: 6| Step: 10
Training loss: 0.07507410436615879
Validation loss: 2.3030604956331264

Epoch: 6| Step: 11
Training loss: 0.13772522486446592
Validation loss: 2.3311672013331943

Epoch: 6| Step: 12
Training loss: 0.08133685451291453
Validation loss: 2.323836788656076

Epoch: 6| Step: 13
Training loss: 0.07265199012984096
Validation loss: 2.312452991498912

Epoch: 744| Step: 0
Training loss: 0.11345875743170768
Validation loss: 2.321108264544777

Epoch: 6| Step: 1
Training loss: 0.056016124443131365
Validation loss: 2.316954675862384

Epoch: 6| Step: 2
Training loss: 0.10642689361803023
Validation loss: 2.3333177089900516

Epoch: 6| Step: 3
Training loss: 0.08851977444659061
Validation loss: 2.311145659703316

Epoch: 6| Step: 4
Training loss: 0.07803410368319921
Validation loss: 2.2896081706000637

Epoch: 6| Step: 5
Training loss: 0.11684015773394185
Validation loss: 2.3172138386672305

Epoch: 6| Step: 6
Training loss: 0.10142873244433508
Validation loss: 2.333698619502317

Epoch: 6| Step: 7
Training loss: 0.060339661538970205
Validation loss: 2.290887258968669

Epoch: 6| Step: 8
Training loss: 0.08386798767202062
Validation loss: 2.287973002349163

Epoch: 6| Step: 9
Training loss: 0.07843578927104689
Validation loss: 2.326054637684982

Epoch: 6| Step: 10
Training loss: 0.09314044337102148
Validation loss: 2.337016476638668

Epoch: 6| Step: 11
Training loss: 0.13336872283720394
Validation loss: 2.312971165224245

Epoch: 6| Step: 12
Training loss: 0.07632361483646147
Validation loss: 2.3310777211184237

Epoch: 6| Step: 13
Training loss: 0.05852093344331915
Validation loss: 2.321522191831803

Epoch: 745| Step: 0
Training loss: 0.06884862344481793
Validation loss: 2.3373900744711085

Epoch: 6| Step: 1
Training loss: 0.0649778400126768
Validation loss: 2.3161210503263407

Epoch: 6| Step: 2
Training loss: 0.11883852523169068
Validation loss: 2.3455150567414784

Epoch: 6| Step: 3
Training loss: 0.1517772411738309
Validation loss: 2.3359693178731735

Epoch: 6| Step: 4
Training loss: 0.06390971071810664
Validation loss: 2.3448024407640986

Epoch: 6| Step: 5
Training loss: 0.07019843346116889
Validation loss: 2.339785541982269

Epoch: 6| Step: 6
Training loss: 0.099407191872894
Validation loss: 2.3465212194485217

Epoch: 6| Step: 7
Training loss: 0.08894375238068093
Validation loss: 2.3697371534162484

Epoch: 6| Step: 8
Training loss: 0.08445758354352595
Validation loss: 2.330520514033304

Epoch: 6| Step: 9
Training loss: 0.07365280444077751
Validation loss: 2.3427638699522393

Epoch: 6| Step: 10
Training loss: 0.04549836748365968
Validation loss: 2.364080552255459

Epoch: 6| Step: 11
Training loss: 0.09471229563765664
Validation loss: 2.369834380433699

Epoch: 6| Step: 12
Training loss: 0.10319358286323942
Validation loss: 2.3370551031566515

Epoch: 6| Step: 13
Training loss: 0.10059984351761216
Validation loss: 2.340977925698113

Epoch: 746| Step: 0
Training loss: 0.05205101510544681
Validation loss: 2.369236468746142

Epoch: 6| Step: 1
Training loss: 0.0956419243047337
Validation loss: 2.366459266663114

Epoch: 6| Step: 2
Training loss: 0.06534182285552904
Validation loss: 2.356114892411851

Epoch: 6| Step: 3
Training loss: 0.09796452027183834
Validation loss: 2.3516459092006037

Epoch: 6| Step: 4
Training loss: 0.052894965885372035
Validation loss: 2.340665836471693

Epoch: 6| Step: 5
Training loss: 0.08750612075719286
Validation loss: 2.3811604540120435

Epoch: 6| Step: 6
Training loss: 0.055269254991246845
Validation loss: 2.3514553747884053

Epoch: 6| Step: 7
Training loss: 0.05840490625908894
Validation loss: 2.360001334542296

Epoch: 6| Step: 8
Training loss: 0.11305170809439435
Validation loss: 2.318817205427817

Epoch: 6| Step: 9
Training loss: 0.09459369720889768
Validation loss: 2.3471848190242306

Epoch: 6| Step: 10
Training loss: 0.11622516160353916
Validation loss: 2.3384645408528106

Epoch: 6| Step: 11
Training loss: 0.050677087215496616
Validation loss: 2.3302742072279132

Epoch: 6| Step: 12
Training loss: 0.05887786211877147
Validation loss: 2.3232841368426254

Epoch: 6| Step: 13
Training loss: 0.08621893121901489
Validation loss: 2.310788371179282

Epoch: 747| Step: 0
Training loss: 0.05038681348535498
Validation loss: 2.311171594400821

Epoch: 6| Step: 1
Training loss: 0.0808472938772768
Validation loss: 2.315360166283164

Epoch: 6| Step: 2
Training loss: 0.10639266365687478
Validation loss: 2.28855144010926

Epoch: 6| Step: 3
Training loss: 0.0706003344187249
Validation loss: 2.3260290370084484

Epoch: 6| Step: 4
Training loss: 0.11976308110117743
Validation loss: 2.309535706088304

Epoch: 6| Step: 5
Training loss: 0.06040541019721781
Validation loss: 2.2941975114575386

Epoch: 6| Step: 6
Training loss: 0.10586375424522318
Validation loss: 2.2961621171910958

Epoch: 6| Step: 7
Training loss: 0.1389004609797211
Validation loss: 2.266414910571986

Epoch: 6| Step: 8
Training loss: 0.14427716887388453
Validation loss: 2.3186451965993875

Epoch: 6| Step: 9
Training loss: 0.0885120358627459
Validation loss: 2.300726987716758

Epoch: 6| Step: 10
Training loss: 0.11305452134425502
Validation loss: 2.2861566380743894

Epoch: 6| Step: 11
Training loss: 0.13728527132583856
Validation loss: 2.3060306084448223

Epoch: 6| Step: 12
Training loss: 0.07175215129812987
Validation loss: 2.281053277542258

Epoch: 6| Step: 13
Training loss: 0.10458944375810261
Validation loss: 2.303633425300571

Epoch: 748| Step: 0
Training loss: 0.08219021199832113
Validation loss: 2.2986287262547314

Epoch: 6| Step: 1
Training loss: 0.13823052812287678
Validation loss: 2.2940024463518824

Epoch: 6| Step: 2
Training loss: 0.10080684089297072
Validation loss: 2.3101871235273115

Epoch: 6| Step: 3
Training loss: 0.11170853904930822
Validation loss: 2.3151819274733354

Epoch: 6| Step: 4
Training loss: 0.11764817685727182
Validation loss: 2.3272243865683944

Epoch: 6| Step: 5
Training loss: 0.08805221961114033
Validation loss: 2.348946774161906

Epoch: 6| Step: 6
Training loss: 0.06660304990768763
Validation loss: 2.3418074369532325

Epoch: 6| Step: 7
Training loss: 0.050515220803892376
Validation loss: 2.3479144299225854

Epoch: 6| Step: 8
Training loss: 0.08396445914262708
Validation loss: 2.3375417707263524

Epoch: 6| Step: 9
Training loss: 0.09743803439382219
Validation loss: 2.333239261940017

Epoch: 6| Step: 10
Training loss: 0.09431506769174836
Validation loss: 2.350837519724338

Epoch: 6| Step: 11
Training loss: 0.07097206443679707
Validation loss: 2.330319171940142

Epoch: 6| Step: 12
Training loss: 0.09000813952369109
Validation loss: 2.339252587408152

Epoch: 6| Step: 13
Training loss: 0.07275060031727573
Validation loss: 2.3170651929737147

Epoch: 749| Step: 0
Training loss: 0.09606177895280935
Validation loss: 2.310344282146858

Epoch: 6| Step: 1
Training loss: 0.16159007763087785
Validation loss: 2.2875306885506177

Epoch: 6| Step: 2
Training loss: 0.06370381244693639
Validation loss: 2.3133263573451672

Epoch: 6| Step: 3
Training loss: 0.07428989325951563
Validation loss: 2.271423629650923

Epoch: 6| Step: 4
Training loss: 0.1913625803585782
Validation loss: 2.298064492473812

Epoch: 6| Step: 5
Training loss: 0.08023910507589672
Validation loss: 2.2870541135369384

Epoch: 6| Step: 6
Training loss: 0.12602842727070968
Validation loss: 2.2985318048392016

Epoch: 6| Step: 7
Training loss: 0.06044691817877623
Validation loss: 2.3162357815636687

Epoch: 6| Step: 8
Training loss: 0.07788889194787355
Validation loss: 2.3071076564588258

Epoch: 6| Step: 9
Training loss: 0.10842632673810537
Validation loss: 2.333194758399186

Epoch: 6| Step: 10
Training loss: 0.10604211581696504
Validation loss: 2.3107819331914867

Epoch: 6| Step: 11
Training loss: 0.0823914476249049
Validation loss: 2.3351427400506175

Epoch: 6| Step: 12
Training loss: 0.06355511133560256
Validation loss: 2.292973732139733

Epoch: 6| Step: 13
Training loss: 0.10769146123343197
Validation loss: 2.313874142112917

Epoch: 750| Step: 0
Training loss: 0.13946881780295803
Validation loss: 2.315392674660335

Epoch: 6| Step: 1
Training loss: 0.1003041904638297
Validation loss: 2.309030108517874

Epoch: 6| Step: 2
Training loss: 0.12593844672526386
Validation loss: 2.2846583707924255

Epoch: 6| Step: 3
Training loss: 0.06624378990024035
Validation loss: 2.317293010765043

Epoch: 6| Step: 4
Training loss: 0.09020358051453972
Validation loss: 2.3149775189168134

Epoch: 6| Step: 5
Training loss: 0.0707249761768222
Validation loss: 2.320148627823033

Epoch: 6| Step: 6
Training loss: 0.11178268523837201
Validation loss: 2.3018285417037254

Epoch: 6| Step: 7
Training loss: 0.12842030396169457
Validation loss: 2.2826020429684917

Epoch: 6| Step: 8
Training loss: 0.07680444441442481
Validation loss: 2.304240896739784

Epoch: 6| Step: 9
Training loss: 0.12419390039984386
Validation loss: 2.3060621752754384

Epoch: 6| Step: 10
Training loss: 0.0709511147417813
Validation loss: 2.2909806610984713

Epoch: 6| Step: 11
Training loss: 0.12624022519163317
Validation loss: 2.306236848933465

Epoch: 6| Step: 12
Training loss: 0.10396086558890398
Validation loss: 2.308328254624226

Epoch: 6| Step: 13
Training loss: 0.085829941131729
Validation loss: 2.310044362532211

Epoch: 751| Step: 0
Training loss: 0.08590868445111222
Validation loss: 2.305295369814763

Epoch: 6| Step: 1
Training loss: 0.06075639773165359
Validation loss: 2.300364907036075

Epoch: 6| Step: 2
Training loss: 0.1151669191674217
Validation loss: 2.2698713995189337

Epoch: 6| Step: 3
Training loss: 0.10362458792070746
Validation loss: 2.289080958978113

Epoch: 6| Step: 4
Training loss: 0.05533704989423434
Validation loss: 2.3175785507214175

Epoch: 6| Step: 5
Training loss: 0.07636331685006023
Validation loss: 2.278892602077826

Epoch: 6| Step: 6
Training loss: 0.12350661434311727
Validation loss: 2.313481668773045

Epoch: 6| Step: 7
Training loss: 0.08347834850269649
Validation loss: 2.310190897097328

Epoch: 6| Step: 8
Training loss: 0.05695096449423559
Validation loss: 2.3040845108224275

Epoch: 6| Step: 9
Training loss: 0.05945996319723522
Validation loss: 2.3107783408685973

Epoch: 6| Step: 10
Training loss: 0.0918136337890629
Validation loss: 2.3130866908142593

Epoch: 6| Step: 11
Training loss: 0.08298732841413342
Validation loss: 2.3081977531953934

Epoch: 6| Step: 12
Training loss: 0.09621324630116793
Validation loss: 2.297307864149733

Epoch: 6| Step: 13
Training loss: 0.10660330395308773
Validation loss: 2.3236931484793555

Epoch: 752| Step: 0
Training loss: 0.07351565805428356
Validation loss: 2.298084868738527

Epoch: 6| Step: 1
Training loss: 0.0594367401933642
Validation loss: 2.322007408038485

Epoch: 6| Step: 2
Training loss: 0.12884790371646568
Validation loss: 2.306074142098499

Epoch: 6| Step: 3
Training loss: 0.0741664237728767
Validation loss: 2.3102362310572224

Epoch: 6| Step: 4
Training loss: 0.09546034048536721
Validation loss: 2.3211064332998

Epoch: 6| Step: 5
Training loss: 0.09800096706112728
Validation loss: 2.335909199156533

Epoch: 6| Step: 6
Training loss: 0.11532197467522717
Validation loss: 2.3394551210955497

Epoch: 6| Step: 7
Training loss: 0.10371089906566074
Validation loss: 2.3490675393847287

Epoch: 6| Step: 8
Training loss: 0.1340451261293136
Validation loss: 2.3179409132086644

Epoch: 6| Step: 9
Training loss: 0.07823029515355777
Validation loss: 2.3327365882536673

Epoch: 6| Step: 10
Training loss: 0.14566720642518874
Validation loss: 2.324843980924439

Epoch: 6| Step: 11
Training loss: 0.11263641623292174
Validation loss: 2.3281330032249614

Epoch: 6| Step: 12
Training loss: 0.06284868681275681
Validation loss: 2.3127994326865178

Epoch: 6| Step: 13
Training loss: 0.1197254803159012
Validation loss: 2.3031322790192723

Epoch: 753| Step: 0
Training loss: 0.15801974842082164
Validation loss: 2.308933755845422

Epoch: 6| Step: 1
Training loss: 0.11868345378669984
Validation loss: 2.3026307525667207

Epoch: 6| Step: 2
Training loss: 0.13677506649350052
Validation loss: 2.302196386506181

Epoch: 6| Step: 3
Training loss: 0.111326966363332
Validation loss: 2.2755575187240793

Epoch: 6| Step: 4
Training loss: 0.12502495695360155
Validation loss: 2.286858916671186

Epoch: 6| Step: 5
Training loss: 0.1497308638701508
Validation loss: 2.2754054487008624

Epoch: 6| Step: 6
Training loss: 0.1579196533102708
Validation loss: 2.292533626248278

Epoch: 6| Step: 7
Training loss: 0.09876850915930263
Validation loss: 2.3025418357036376

Epoch: 6| Step: 8
Training loss: 0.11664768501679283
Validation loss: 2.315315373060181

Epoch: 6| Step: 9
Training loss: 0.1314709024899171
Validation loss: 2.282737835613719

Epoch: 6| Step: 10
Training loss: 0.1063219808335054
Validation loss: 2.3077251579233042

Epoch: 6| Step: 11
Training loss: 0.07093662515596547
Validation loss: 2.290599192537023

Epoch: 6| Step: 12
Training loss: 0.1022427227699701
Validation loss: 2.3200166105567543

Epoch: 6| Step: 13
Training loss: 0.08931830941580675
Validation loss: 2.321248716067009

Epoch: 754| Step: 0
Training loss: 0.12010191998719805
Validation loss: 2.327987705390794

Epoch: 6| Step: 1
Training loss: 0.0779865677557189
Validation loss: 2.3153965028577144

Epoch: 6| Step: 2
Training loss: 0.09672127416888197
Validation loss: 2.3472561185654244

Epoch: 6| Step: 3
Training loss: 0.13151116811581695
Validation loss: 2.3643620101812464

Epoch: 6| Step: 4
Training loss: 0.10566525344036454
Validation loss: 2.337130462094537

Epoch: 6| Step: 5
Training loss: 0.06890698169786873
Validation loss: 2.323525986801286

Epoch: 6| Step: 6
Training loss: 0.10719311805799274
Validation loss: 2.3266954797798314

Epoch: 6| Step: 7
Training loss: 0.1127057254152259
Validation loss: 2.3266568446243667

Epoch: 6| Step: 8
Training loss: 0.10289727267005051
Validation loss: 2.327852420248259

Epoch: 6| Step: 9
Training loss: 0.08364927729353146
Validation loss: 2.318519176318762

Epoch: 6| Step: 10
Training loss: 0.11226211238401695
Validation loss: 2.3183558629781307

Epoch: 6| Step: 11
Training loss: 0.127152565040922
Validation loss: 2.308599756563155

Epoch: 6| Step: 12
Training loss: 0.06589785374923865
Validation loss: 2.3133920547038906

Epoch: 6| Step: 13
Training loss: 0.10780888979851909
Validation loss: 2.3110545737036694

Epoch: 755| Step: 0
Training loss: 0.13139923671191536
Validation loss: 2.3125225704591594

Epoch: 6| Step: 1
Training loss: 0.08039664097696027
Validation loss: 2.3293505881995804

Epoch: 6| Step: 2
Training loss: 0.1157195416767752
Validation loss: 2.311593044994345

Epoch: 6| Step: 3
Training loss: 0.131856097340092
Validation loss: 2.328104579428826

Epoch: 6| Step: 4
Training loss: 0.09788154363559537
Validation loss: 2.3425808446759824

Epoch: 6| Step: 5
Training loss: 0.05995787921835001
Validation loss: 2.3433901395003693

Epoch: 6| Step: 6
Training loss: 0.09664346035473144
Validation loss: 2.3345677330563217

Epoch: 6| Step: 7
Training loss: 0.07210340851290835
Validation loss: 2.327660712865706

Epoch: 6| Step: 8
Training loss: 0.11059811991562499
Validation loss: 2.3422496519106537

Epoch: 6| Step: 9
Training loss: 0.04825075928601433
Validation loss: 2.3424708419030287

Epoch: 6| Step: 10
Training loss: 0.05358430934283961
Validation loss: 2.36447300847149

Epoch: 6| Step: 11
Training loss: 0.10972349811048873
Validation loss: 2.3365964921306253

Epoch: 6| Step: 12
Training loss: 0.09975149263672989
Validation loss: 2.3262167509436282

Epoch: 6| Step: 13
Training loss: 0.08401554106030094
Validation loss: 2.3334667498011195

Epoch: 756| Step: 0
Training loss: 0.12339774318450226
Validation loss: 2.3555045965487955

Epoch: 6| Step: 1
Training loss: 0.054559878039148135
Validation loss: 2.3309111665653375

Epoch: 6| Step: 2
Training loss: 0.0802542505746614
Validation loss: 2.3229628921192234

Epoch: 6| Step: 3
Training loss: 0.10983964029901942
Validation loss: 2.326599989816632

Epoch: 6| Step: 4
Training loss: 0.0943055530448647
Validation loss: 2.321743866681592

Epoch: 6| Step: 5
Training loss: 0.0809755743530458
Validation loss: 2.3084530490888238

Epoch: 6| Step: 6
Training loss: 0.09797208258635538
Validation loss: 2.301173691962241

Epoch: 6| Step: 7
Training loss: 0.09003234846523467
Validation loss: 2.297679338107225

Epoch: 6| Step: 8
Training loss: 0.09913334512398382
Validation loss: 2.316142757569455

Epoch: 6| Step: 9
Training loss: 0.1083680144567139
Validation loss: 2.3067092995731837

Epoch: 6| Step: 10
Training loss: 0.06987165960164976
Validation loss: 2.287467940415332

Epoch: 6| Step: 11
Training loss: 0.04907338297696336
Validation loss: 2.2970338880441226

Epoch: 6| Step: 12
Training loss: 0.0909849284966083
Validation loss: 2.276183062414091

Epoch: 6| Step: 13
Training loss: 0.08363764181006762
Validation loss: 2.295471372497744

Epoch: 757| Step: 0
Training loss: 0.09126593363304311
Validation loss: 2.2745531820053078

Epoch: 6| Step: 1
Training loss: 0.10360207636413558
Validation loss: 2.273082233333535

Epoch: 6| Step: 2
Training loss: 0.09939442611152063
Validation loss: 2.2792057931222454

Epoch: 6| Step: 3
Training loss: 0.08467093938788224
Validation loss: 2.2844902128815514

Epoch: 6| Step: 4
Training loss: 0.11901788173387474
Validation loss: 2.296246363701779

Epoch: 6| Step: 5
Training loss: 0.09097991783208191
Validation loss: 2.296559690321932

Epoch: 6| Step: 6
Training loss: 0.11827043206697446
Validation loss: 2.3071551894490896

Epoch: 6| Step: 7
Training loss: 0.061401549200618646
Validation loss: 2.323603130546118

Epoch: 6| Step: 8
Training loss: 0.07007117382072674
Validation loss: 2.2734073690059793

Epoch: 6| Step: 9
Training loss: 0.049396141198718733
Validation loss: 2.2839201728235525

Epoch: 6| Step: 10
Training loss: 0.08746284649747454
Validation loss: 2.29101182208402

Epoch: 6| Step: 11
Training loss: 0.1048887073558056
Validation loss: 2.3297859252589337

Epoch: 6| Step: 12
Training loss: 0.09053611898019409
Validation loss: 2.329985321372251

Epoch: 6| Step: 13
Training loss: 0.06005837277627627
Validation loss: 2.2941421413659144

Epoch: 758| Step: 0
Training loss: 0.10170709422347239
Validation loss: 2.3210981341413053

Epoch: 6| Step: 1
Training loss: 0.06547700537434056
Validation loss: 2.2987641944672954

Epoch: 6| Step: 2
Training loss: 0.08955671754586272
Validation loss: 2.2976634419315176

Epoch: 6| Step: 3
Training loss: 0.07172443749641678
Validation loss: 2.314128835325454

Epoch: 6| Step: 4
Training loss: 0.07511167705397408
Validation loss: 2.3131094963289036

Epoch: 6| Step: 5
Training loss: 0.11419269956141416
Validation loss: 2.323582161055615

Epoch: 6| Step: 6
Training loss: 0.07044976135078793
Validation loss: 2.330694666350666

Epoch: 6| Step: 7
Training loss: 0.08803177995677973
Validation loss: 2.3255863050719965

Epoch: 6| Step: 8
Training loss: 0.05861270518466321
Validation loss: 2.294517486418252

Epoch: 6| Step: 9
Training loss: 0.09328376050187422
Validation loss: 2.276843337097379

Epoch: 6| Step: 10
Training loss: 0.0701420260508486
Validation loss: 2.2950068171622853

Epoch: 6| Step: 11
Training loss: 0.09430270883328226
Validation loss: 2.2936815165613225

Epoch: 6| Step: 12
Training loss: 0.11955587532347292
Validation loss: 2.3081612644194696

Epoch: 6| Step: 13
Training loss: 0.08076273953255123
Validation loss: 2.293325034093375

Epoch: 759| Step: 0
Training loss: 0.0903293403018478
Validation loss: 2.2758984797474384

Epoch: 6| Step: 1
Training loss: 0.06340483868190622
Validation loss: 2.2775361997796124

Epoch: 6| Step: 2
Training loss: 0.08413468815465022
Validation loss: 2.3020277416577515

Epoch: 6| Step: 3
Training loss: 0.13024047852134563
Validation loss: 2.299198656449866

Epoch: 6| Step: 4
Training loss: 0.10072518866822654
Validation loss: 2.310741364469409

Epoch: 6| Step: 5
Training loss: 0.07914839641452122
Validation loss: 2.3088682236494553

Epoch: 6| Step: 6
Training loss: 0.07445464792125049
Validation loss: 2.3337281126803493

Epoch: 6| Step: 7
Training loss: 0.061718135012809996
Validation loss: 2.3357966135639407

Epoch: 6| Step: 8
Training loss: 0.11222021408926564
Validation loss: 2.328386830369565

Epoch: 6| Step: 9
Training loss: 0.07572143285578256
Validation loss: 2.315176682106091

Epoch: 6| Step: 10
Training loss: 0.10405994750091399
Validation loss: 2.330582381054851

Epoch: 6| Step: 11
Training loss: 0.09994845552019244
Validation loss: 2.344474559069468

Epoch: 6| Step: 12
Training loss: 0.04443764144151312
Validation loss: 2.3311745997149993

Epoch: 6| Step: 13
Training loss: 0.05294335424633088
Validation loss: 2.314972559769079

Epoch: 760| Step: 0
Training loss: 0.062648525933221
Validation loss: 2.293908149699246

Epoch: 6| Step: 1
Training loss: 0.07105524768052786
Validation loss: 2.340174044259573

Epoch: 6| Step: 2
Training loss: 0.09928658486868673
Validation loss: 2.32562521100025

Epoch: 6| Step: 3
Training loss: 0.13927709116984377
Validation loss: 2.3191664062439483

Epoch: 6| Step: 4
Training loss: 0.06168594544827909
Validation loss: 2.3265374753059027

Epoch: 6| Step: 5
Training loss: 0.06725997024342394
Validation loss: 2.3062004072240323

Epoch: 6| Step: 6
Training loss: 0.09637602405678154
Validation loss: 2.3120471352385454

Epoch: 6| Step: 7
Training loss: 0.06020789855266012
Validation loss: 2.3117032328894362

Epoch: 6| Step: 8
Training loss: 0.13085979490070443
Validation loss: 2.2957200263385147

Epoch: 6| Step: 9
Training loss: 0.06627511301433024
Validation loss: 2.3325137885161746

Epoch: 6| Step: 10
Training loss: 0.07169678767319138
Validation loss: 2.3124069343692826

Epoch: 6| Step: 11
Training loss: 0.07505900550389864
Validation loss: 2.3289266740654164

Epoch: 6| Step: 12
Training loss: 0.09743270082748608
Validation loss: 2.3212101277563755

Epoch: 6| Step: 13
Training loss: 0.09189683970066283
Validation loss: 2.3345303175371845

Epoch: 761| Step: 0
Training loss: 0.04935217023242501
Validation loss: 2.31027511363075

Epoch: 6| Step: 1
Training loss: 0.1183078655359433
Validation loss: 2.3366596805156252

Epoch: 6| Step: 2
Training loss: 0.06949522968664423
Validation loss: 2.3297653800471014

Epoch: 6| Step: 3
Training loss: 0.059962463204173956
Validation loss: 2.328706011303056

Epoch: 6| Step: 4
Training loss: 0.07838353651691993
Validation loss: 2.3394302067633594

Epoch: 6| Step: 5
Training loss: 0.05961022642322497
Validation loss: 2.338697329125427

Epoch: 6| Step: 6
Training loss: 0.07987350687141012
Validation loss: 2.354924617815186

Epoch: 6| Step: 7
Training loss: 0.07438954665374553
Validation loss: 2.3669931234537667

Epoch: 6| Step: 8
Training loss: 0.11826957767875106
Validation loss: 2.336936697196721

Epoch: 6| Step: 9
Training loss: 0.1609759173788776
Validation loss: 2.3426402428218434

Epoch: 6| Step: 10
Training loss: 0.12199342213401981
Validation loss: 2.3804957442333476

Epoch: 6| Step: 11
Training loss: 0.07313171956986027
Validation loss: 2.3534241126961293

Epoch: 6| Step: 12
Training loss: 0.0938869161982689
Validation loss: 2.338616056693568

Epoch: 6| Step: 13
Training loss: 0.12296371071558662
Validation loss: 2.3169621921003025

Epoch: 762| Step: 0
Training loss: 0.09285031195453608
Validation loss: 2.3122846707678226

Epoch: 6| Step: 1
Training loss: 0.1339103538747856
Validation loss: 2.322073447684657

Epoch: 6| Step: 2
Training loss: 0.06859342833510905
Validation loss: 2.295797825815214

Epoch: 6| Step: 3
Training loss: 0.1033892489891271
Validation loss: 2.2873302500287345

Epoch: 6| Step: 4
Training loss: 0.07938607289301616
Validation loss: 2.293135797621883

Epoch: 6| Step: 5
Training loss: 0.06930271548223162
Validation loss: 2.2708989057042093

Epoch: 6| Step: 6
Training loss: 0.06961274969438394
Validation loss: 2.2861265245915967

Epoch: 6| Step: 7
Training loss: 0.11443931069834873
Validation loss: 2.267938914448287

Epoch: 6| Step: 8
Training loss: 0.04625667865721683
Validation loss: 2.2792690082888014

Epoch: 6| Step: 9
Training loss: 0.06960452470139755
Validation loss: 2.2957629498206487

Epoch: 6| Step: 10
Training loss: 0.0996443088832137
Validation loss: 2.2785516564849666

Epoch: 6| Step: 11
Training loss: 0.09994892607953286
Validation loss: 2.296367245089631

Epoch: 6| Step: 12
Training loss: 0.060687121886353224
Validation loss: 2.2912133992622317

Epoch: 6| Step: 13
Training loss: 0.09456154617621466
Validation loss: 2.2908719031738505

Epoch: 763| Step: 0
Training loss: 0.08424841604243657
Validation loss: 2.2689645021552156

Epoch: 6| Step: 1
Training loss: 0.07082155514829903
Validation loss: 2.2935604533837823

Epoch: 6| Step: 2
Training loss: 0.07631693074163838
Validation loss: 2.2985618869902456

Epoch: 6| Step: 3
Training loss: 0.10879128811681017
Validation loss: 2.3101000384054657

Epoch: 6| Step: 4
Training loss: 0.05957024996394643
Validation loss: 2.2936546469713552

Epoch: 6| Step: 5
Training loss: 0.09187504301264787
Validation loss: 2.3371043196484265

Epoch: 6| Step: 6
Training loss: 0.07342676746286307
Validation loss: 2.325025933930717

Epoch: 6| Step: 7
Training loss: 0.10958981280954427
Validation loss: 2.304783421198047

Epoch: 6| Step: 8
Training loss: 0.08304011333531745
Validation loss: 2.3297361486663446

Epoch: 6| Step: 9
Training loss: 0.07436172617341182
Validation loss: 2.316158642307728

Epoch: 6| Step: 10
Training loss: 0.06404226291659593
Validation loss: 2.326312034030057

Epoch: 6| Step: 11
Training loss: 0.11288167099603576
Validation loss: 2.31239834012973

Epoch: 6| Step: 12
Training loss: 0.06650035865496957
Validation loss: 2.3351145646123164

Epoch: 6| Step: 13
Training loss: 0.042326212755927836
Validation loss: 2.3086046182144013

Epoch: 764| Step: 0
Training loss: 0.04936179819797545
Validation loss: 2.312584928944624

Epoch: 6| Step: 1
Training loss: 0.06319641133618246
Validation loss: 2.3188204729706583

Epoch: 6| Step: 2
Training loss: 0.062355574989813825
Validation loss: 2.307367546403992

Epoch: 6| Step: 3
Training loss: 0.0772841804544981
Validation loss: 2.3365599917843882

Epoch: 6| Step: 4
Training loss: 0.114248063413288
Validation loss: 2.3371566163141937

Epoch: 6| Step: 5
Training loss: 0.0728799125592506
Validation loss: 2.302059788366126

Epoch: 6| Step: 6
Training loss: 0.09790598408613917
Validation loss: 2.3225958532864626

Epoch: 6| Step: 7
Training loss: 0.07529032884415321
Validation loss: 2.3126884811558215

Epoch: 6| Step: 8
Training loss: 0.09181194993276955
Validation loss: 2.2658550775045625

Epoch: 6| Step: 9
Training loss: 0.09277993229668773
Validation loss: 2.304066949098262

Epoch: 6| Step: 10
Training loss: 0.0467954298028702
Validation loss: 2.2761692653283103

Epoch: 6| Step: 11
Training loss: 0.08990158417202868
Validation loss: 2.319101308011373

Epoch: 6| Step: 12
Training loss: 0.09818930102990574
Validation loss: 2.3036945109450357

Epoch: 6| Step: 13
Training loss: 0.07622078401315663
Validation loss: 2.3174667920168384

Epoch: 765| Step: 0
Training loss: 0.1754981940881622
Validation loss: 2.289879047601775

Epoch: 6| Step: 1
Training loss: 0.07646043845162243
Validation loss: 2.2998655270540196

Epoch: 6| Step: 2
Training loss: 0.08602681179044115
Validation loss: 2.3003302161889034

Epoch: 6| Step: 3
Training loss: 0.12317832858106093
Validation loss: 2.3142474345001087

Epoch: 6| Step: 4
Training loss: 0.08621890961534437
Validation loss: 2.297701967680664

Epoch: 6| Step: 5
Training loss: 0.08825058341137396
Validation loss: 2.307335325782787

Epoch: 6| Step: 6
Training loss: 0.11372147719962088
Validation loss: 2.298946553939668

Epoch: 6| Step: 7
Training loss: 0.07236313362981692
Validation loss: 2.3295007299443604

Epoch: 6| Step: 8
Training loss: 0.06551548328880161
Validation loss: 2.3395316102895105

Epoch: 6| Step: 9
Training loss: 0.11656043447142224
Validation loss: 2.309127869925592

Epoch: 6| Step: 10
Training loss: 0.05396813886166109
Validation loss: 2.317518593761046

Epoch: 6| Step: 11
Training loss: 0.08558082527429813
Validation loss: 2.340564582853597

Epoch: 6| Step: 12
Training loss: 0.08606615514791768
Validation loss: 2.3241707817291846

Epoch: 6| Step: 13
Training loss: 0.07256592396486913
Validation loss: 2.314194600187589

Epoch: 766| Step: 0
Training loss: 0.08834775881633344
Validation loss: 2.313432626809993

Epoch: 6| Step: 1
Training loss: 0.06731660672595527
Validation loss: 2.319653320150867

Epoch: 6| Step: 2
Training loss: 0.10226237796789689
Validation loss: 2.3178472204697242

Epoch: 6| Step: 3
Training loss: 0.12794255053666215
Validation loss: 2.308674297055792

Epoch: 6| Step: 4
Training loss: 0.10628875979121408
Validation loss: 2.318416948841827

Epoch: 6| Step: 5
Training loss: 0.07042450064306716
Validation loss: 2.316322664780456

Epoch: 6| Step: 6
Training loss: 0.09235891795283274
Validation loss: 2.311552672392762

Epoch: 6| Step: 7
Training loss: 0.11846044115660553
Validation loss: 2.325569982323611

Epoch: 6| Step: 8
Training loss: 0.08520324726924941
Validation loss: 2.3168764327343934

Epoch: 6| Step: 9
Training loss: 0.06765994840428922
Validation loss: 2.291161396635872

Epoch: 6| Step: 10
Training loss: 0.1038073576443591
Validation loss: 2.320318316021502

Epoch: 6| Step: 11
Training loss: 0.11573130740249626
Validation loss: 2.3070353297523964

Epoch: 6| Step: 12
Training loss: 0.08386041675202738
Validation loss: 2.3084077758960553

Epoch: 6| Step: 13
Training loss: 0.11295764016358888
Validation loss: 2.2953895362193286

Epoch: 767| Step: 0
Training loss: 0.10861367687749399
Validation loss: 2.2953037811508863

Epoch: 6| Step: 1
Training loss: 0.04128556742667776
Validation loss: 2.29627890905917

Epoch: 6| Step: 2
Training loss: 0.13046618362004175
Validation loss: 2.284265474112514

Epoch: 6| Step: 3
Training loss: 0.08027367440998545
Validation loss: 2.2664640746281037

Epoch: 6| Step: 4
Training loss: 0.07287223205658877
Validation loss: 2.2815540581392746

Epoch: 6| Step: 5
Training loss: 0.13283962786131395
Validation loss: 2.269888163454303

Epoch: 6| Step: 6
Training loss: 0.07232820533357363
Validation loss: 2.2865709094942748

Epoch: 6| Step: 7
Training loss: 0.10034931460988977
Validation loss: 2.2836624439016706

Epoch: 6| Step: 8
Training loss: 0.05908120564601137
Validation loss: 2.260642468322202

Epoch: 6| Step: 9
Training loss: 0.05041152674006614
Validation loss: 2.303327032279206

Epoch: 6| Step: 10
Training loss: 0.1328376437677029
Validation loss: 2.2910345524838815

Epoch: 6| Step: 11
Training loss: 0.07442205591398039
Validation loss: 2.3180165263709642

Epoch: 6| Step: 12
Training loss: 0.04976441119883126
Validation loss: 2.2847652937009904

Epoch: 6| Step: 13
Training loss: 0.07572014141555809
Validation loss: 2.3115871460226516

Epoch: 768| Step: 0
Training loss: 0.05581405158064827
Validation loss: 2.316041055583285

Epoch: 6| Step: 1
Training loss: 0.12282263668465583
Validation loss: 2.3090955245408438

Epoch: 6| Step: 2
Training loss: 0.09254942501431516
Validation loss: 2.3224921953115256

Epoch: 6| Step: 3
Training loss: 0.10344563223169481
Validation loss: 2.315320681226516

Epoch: 6| Step: 4
Training loss: 0.10598511038143646
Validation loss: 2.3307801812623037

Epoch: 6| Step: 5
Training loss: 0.08345320643064079
Validation loss: 2.31531659768203

Epoch: 6| Step: 6
Training loss: 0.09613665363429998
Validation loss: 2.311816707945249

Epoch: 6| Step: 7
Training loss: 0.09575466792154966
Validation loss: 2.318320394134147

Epoch: 6| Step: 8
Training loss: 0.10612591236304185
Validation loss: 2.322818447401811

Epoch: 6| Step: 9
Training loss: 0.10195652017019162
Validation loss: 2.3252743021440185

Epoch: 6| Step: 10
Training loss: 0.0684240920397366
Validation loss: 2.327742131699943

Epoch: 6| Step: 11
Training loss: 0.09659603622924873
Validation loss: 2.3248845362278057

Epoch: 6| Step: 12
Training loss: 0.06214138052080377
Validation loss: 2.348222153111777

Epoch: 6| Step: 13
Training loss: 0.06888279119791725
Validation loss: 2.335381237270376

Epoch: 769| Step: 0
Training loss: 0.058413048099823485
Validation loss: 2.3396911313843423

Epoch: 6| Step: 1
Training loss: 0.0915616603314824
Validation loss: 2.340314295825954

Epoch: 6| Step: 2
Training loss: 0.10224163880065794
Validation loss: 2.3310529586497095

Epoch: 6| Step: 3
Training loss: 0.08803763280999607
Validation loss: 2.321415804294068

Epoch: 6| Step: 4
Training loss: 0.09675750105572482
Validation loss: 2.299529472050452

Epoch: 6| Step: 5
Training loss: 0.13153027315336685
Validation loss: 2.3458855878454963

Epoch: 6| Step: 6
Training loss: 0.04497811953165513
Validation loss: 2.3178601854793324

Epoch: 6| Step: 7
Training loss: 0.09338670613837734
Validation loss: 2.2940759603405185

Epoch: 6| Step: 8
Training loss: 0.07333491177998244
Validation loss: 2.2947781743895206

Epoch: 6| Step: 9
Training loss: 0.12136888396026237
Validation loss: 2.2928465590371063

Epoch: 6| Step: 10
Training loss: 0.0884339282490647
Validation loss: 2.2964770014319718

Epoch: 6| Step: 11
Training loss: 0.10697221711663946
Validation loss: 2.2574699486325205

Epoch: 6| Step: 12
Training loss: 0.09692664346521686
Validation loss: 2.2641543086339984

Epoch: 6| Step: 13
Training loss: 0.1321894180776439
Validation loss: 2.2659169236380503

Epoch: 770| Step: 0
Training loss: 0.08680764659376379
Validation loss: 2.264050125804673

Epoch: 6| Step: 1
Training loss: 0.08512231146106994
Validation loss: 2.2647323824551817

Epoch: 6| Step: 2
Training loss: 0.0716793728127705
Validation loss: 2.2888973705280486

Epoch: 6| Step: 3
Training loss: 0.10875028778728685
Validation loss: 2.2820445975158252

Epoch: 6| Step: 4
Training loss: 0.07921756668260407
Validation loss: 2.2827998425807867

Epoch: 6| Step: 5
Training loss: 0.11827192427860724
Validation loss: 2.2843502901133363

Epoch: 6| Step: 6
Training loss: 0.0936112469826793
Validation loss: 2.277459830800255

Epoch: 6| Step: 7
Training loss: 0.13573252691567722
Validation loss: 2.2932130553792303

Epoch: 6| Step: 8
Training loss: 0.06858882543139334
Validation loss: 2.2916149845802556

Epoch: 6| Step: 9
Training loss: 0.07531275804562504
Validation loss: 2.265899288559876

Epoch: 6| Step: 10
Training loss: 0.05225976871958521
Validation loss: 2.298737180199304

Epoch: 6| Step: 11
Training loss: 0.10927790351022051
Validation loss: 2.278384141840286

Epoch: 6| Step: 12
Training loss: 0.12018525900712908
Validation loss: 2.2812424571246495

Epoch: 6| Step: 13
Training loss: 0.0887487376653865
Validation loss: 2.2796960545410365

Epoch: 771| Step: 0
Training loss: 0.06192777050206265
Validation loss: 2.282170059468101

Epoch: 6| Step: 1
Training loss: 0.07619785208231096
Validation loss: 2.270700501253023

Epoch: 6| Step: 2
Training loss: 0.17478720082029142
Validation loss: 2.2635072699617576

Epoch: 6| Step: 3
Training loss: 0.10676432847545358
Validation loss: 2.2870833596836544

Epoch: 6| Step: 4
Training loss: 0.1060503535500406
Validation loss: 2.268868540052975

Epoch: 6| Step: 5
Training loss: 0.07131992612598907
Validation loss: 2.28623425544323

Epoch: 6| Step: 6
Training loss: 0.111560424410054
Validation loss: 2.2590269358220296

Epoch: 6| Step: 7
Training loss: 0.1045357533127769
Validation loss: 2.268632774451178

Epoch: 6| Step: 8
Training loss: 0.06933562856256135
Validation loss: 2.2848539295649113

Epoch: 6| Step: 9
Training loss: 0.10937060619793143
Validation loss: 2.2900397420210004

Epoch: 6| Step: 10
Training loss: 0.06755700263636323
Validation loss: 2.2744558202099685

Epoch: 6| Step: 11
Training loss: 0.09825936047903587
Validation loss: 2.271730698561886

Epoch: 6| Step: 12
Training loss: 0.134548343808582
Validation loss: 2.2775614180338044

Epoch: 6| Step: 13
Training loss: 0.08593457661338069
Validation loss: 2.2772789174461576

Epoch: 772| Step: 0
Training loss: 0.0937191594576946
Validation loss: 2.2597171632435744

Epoch: 6| Step: 1
Training loss: 0.08196818959226002
Validation loss: 2.289429025418749

Epoch: 6| Step: 2
Training loss: 0.07213520511648967
Validation loss: 2.25337814946299

Epoch: 6| Step: 3
Training loss: 0.06445572948973406
Validation loss: 2.2780734208064226

Epoch: 6| Step: 4
Training loss: 0.14113342906902746
Validation loss: 2.290261871891522

Epoch: 6| Step: 5
Training loss: 0.0906156417931254
Validation loss: 2.2776903409263722

Epoch: 6| Step: 6
Training loss: 0.1247988736823766
Validation loss: 2.311767642860106

Epoch: 6| Step: 7
Training loss: 0.124411127184581
Validation loss: 2.269767817947175

Epoch: 6| Step: 8
Training loss: 0.09593215124460075
Validation loss: 2.280167321467647

Epoch: 6| Step: 9
Training loss: 0.0805984606699249
Validation loss: 2.2945487870742562

Epoch: 6| Step: 10
Training loss: 0.14103827413491715
Validation loss: 2.283890895150855

Epoch: 6| Step: 11
Training loss: 0.11207360667336484
Validation loss: 2.2920845083367114

Epoch: 6| Step: 12
Training loss: 0.09233121882936306
Validation loss: 2.288994230054286

Epoch: 6| Step: 13
Training loss: 0.16779905441166088
Validation loss: 2.2743393922081983

Epoch: 773| Step: 0
Training loss: 0.060627685347914906
Validation loss: 2.2986686243396712

Epoch: 6| Step: 1
Training loss: 0.06539259756068656
Validation loss: 2.2906908801150165

Epoch: 6| Step: 2
Training loss: 0.11037330919538915
Validation loss: 2.2845428201576654

Epoch: 6| Step: 3
Training loss: 0.13546286461265292
Validation loss: 2.3111174180002876

Epoch: 6| Step: 4
Training loss: 0.15707648560432996
Validation loss: 2.2719901770491036

Epoch: 6| Step: 5
Training loss: 0.14002841658940385
Validation loss: 2.2930548713349332

Epoch: 6| Step: 6
Training loss: 0.17426399703981135
Validation loss: 2.3166959582410103

Epoch: 6| Step: 7
Training loss: 0.26997882888054164
Validation loss: 2.311206093126202

Epoch: 6| Step: 8
Training loss: 0.21160090288098504
Validation loss: 2.313286304794935

Epoch: 6| Step: 9
Training loss: 0.16112809607799125
Validation loss: 2.3301132465346504

Epoch: 6| Step: 10
Training loss: 0.15722325126051803
Validation loss: 2.335914622953535

Epoch: 6| Step: 11
Training loss: 0.21395093767322163
Validation loss: 2.3354318941136616

Epoch: 6| Step: 12
Training loss: 0.10347568893207881
Validation loss: 2.3475581710628575

Epoch: 6| Step: 13
Training loss: 0.23870069295467367
Validation loss: 2.3599936267746915

Epoch: 774| Step: 0
Training loss: 0.0914630603310945
Validation loss: 2.349471753683313

Epoch: 6| Step: 1
Training loss: 0.1429344453981486
Validation loss: 2.333016438507027

Epoch: 6| Step: 2
Training loss: 0.14511974481354775
Validation loss: 2.336847603007859

Epoch: 6| Step: 3
Training loss: 0.1289698342803897
Validation loss: 2.3533245681922033

Epoch: 6| Step: 4
Training loss: 0.11769984620506801
Validation loss: 2.3279142304312446

Epoch: 6| Step: 5
Training loss: 0.09934314979115115
Validation loss: 2.331214146430605

Epoch: 6| Step: 6
Training loss: 0.18335407927203695
Validation loss: 2.284845881336345

Epoch: 6| Step: 7
Training loss: 0.12044282904610298
Validation loss: 2.3097318107416096

Epoch: 6| Step: 8
Training loss: 0.16520157549358813
Validation loss: 2.297083152049029

Epoch: 6| Step: 9
Training loss: 0.13998628310716876
Validation loss: 2.303772496255322

Epoch: 6| Step: 10
Training loss: 0.1459617063921371
Validation loss: 2.296046710598345

Epoch: 6| Step: 11
Training loss: 0.23425711210094308
Validation loss: 2.322553870815949

Epoch: 6| Step: 12
Training loss: 0.18242270777836944
Validation loss: 2.301550452198301

Epoch: 6| Step: 13
Training loss: 0.16840786976724592
Validation loss: 2.3281773970591244

Epoch: 775| Step: 0
Training loss: 0.1526105451932497
Validation loss: 2.3010162919278785

Epoch: 6| Step: 1
Training loss: 0.11131305341593718
Validation loss: 2.3060259581511304

Epoch: 6| Step: 2
Training loss: 0.13057683932977057
Validation loss: 2.3129458736189914

Epoch: 6| Step: 3
Training loss: 0.12244650665992825
Validation loss: 2.320511492681692

Epoch: 6| Step: 4
Training loss: 0.08094866264169547
Validation loss: 2.3090929790461923

Epoch: 6| Step: 5
Training loss: 0.13468258828856855
Validation loss: 2.28396155076295

Epoch: 6| Step: 6
Training loss: 0.15588311992074472
Validation loss: 2.315789407222746

Epoch: 6| Step: 7
Training loss: 0.11034410164516945
Validation loss: 2.272758175750751

Epoch: 6| Step: 8
Training loss: 0.2251028527841231
Validation loss: 2.2972330703424984

Epoch: 6| Step: 9
Training loss: 0.15710027136242
Validation loss: 2.298423678609482

Epoch: 6| Step: 10
Training loss: 0.2178179947640263
Validation loss: 2.285861300626633

Epoch: 6| Step: 11
Training loss: 0.17790229955066705
Validation loss: 2.2793255553986875

Epoch: 6| Step: 12
Training loss: 0.1826006937993324
Validation loss: 2.2658900053959647

Epoch: 6| Step: 13
Training loss: 0.11740734618322252
Validation loss: 2.3118204295080433

Epoch: 776| Step: 0
Training loss: 0.09777852985869205
Validation loss: 2.3201375689373473

Epoch: 6| Step: 1
Training loss: 0.07962259543147715
Validation loss: 2.38083241034471

Epoch: 6| Step: 2
Training loss: 0.12201334577745439
Validation loss: 2.3838886748440324

Epoch: 6| Step: 3
Training loss: 0.20267467832637417
Validation loss: 2.3760168643676227

Epoch: 6| Step: 4
Training loss: 0.1169193816639852
Validation loss: 2.3732106333799905

Epoch: 6| Step: 5
Training loss: 0.1670796795355943
Validation loss: 2.3589840343454114

Epoch: 6| Step: 6
Training loss: 0.09580292655572628
Validation loss: 2.3101051221787365

Epoch: 6| Step: 7
Training loss: 0.11713028941785718
Validation loss: 2.3365508681173734

Epoch: 6| Step: 8
Training loss: 0.128410650994847
Validation loss: 2.3446807653899815

Epoch: 6| Step: 9
Training loss: 0.14624972304701053
Validation loss: 2.339265990507637

Epoch: 6| Step: 10
Training loss: 0.2063900446829116
Validation loss: 2.313577112893147

Epoch: 6| Step: 11
Training loss: 0.20514837605807296
Validation loss: 2.313671880495878

Epoch: 6| Step: 12
Training loss: 0.1672969234979883
Validation loss: 2.2986916138830185

Epoch: 6| Step: 13
Training loss: 0.1953761855246269
Validation loss: 2.2804147615981614

Epoch: 777| Step: 0
Training loss: 0.14668008446163502
Validation loss: 2.2998737194648675

Epoch: 6| Step: 1
Training loss: 0.13208479529117248
Validation loss: 2.2879465192403394

Epoch: 6| Step: 2
Training loss: 0.19853161134571376
Validation loss: 2.307393001371014

Epoch: 6| Step: 3
Training loss: 0.19063262885102705
Validation loss: 2.3312671525594655

Epoch: 6| Step: 4
Training loss: 0.12084540157506453
Validation loss: 2.320526028146958

Epoch: 6| Step: 5
Training loss: 0.1424153587704612
Validation loss: 2.312267776265511

Epoch: 6| Step: 6
Training loss: 0.1508312582190261
Validation loss: 2.3101540317008937

Epoch: 6| Step: 7
Training loss: 0.1463491005942706
Validation loss: 2.3385051723807866

Epoch: 6| Step: 8
Training loss: 0.11952259244295317
Validation loss: 2.3333789107563527

Epoch: 6| Step: 9
Training loss: 0.14117669789193563
Validation loss: 2.3127931155767296

Epoch: 6| Step: 10
Training loss: 0.21911803858427806
Validation loss: 2.338123949562398

Epoch: 6| Step: 11
Training loss: 0.2882052675510347
Validation loss: 2.2992511262197786

Epoch: 6| Step: 12
Training loss: 0.15727026551170625
Validation loss: 2.3033893113798487

Epoch: 6| Step: 13
Training loss: 0.24857897269195361
Validation loss: 2.3060983443066903

Epoch: 778| Step: 0
Training loss: 0.12080227859420217
Validation loss: 2.2974689031962003

Epoch: 6| Step: 1
Training loss: 0.10004624698077791
Validation loss: 2.2928465355569245

Epoch: 6| Step: 2
Training loss: 0.11828723509346764
Validation loss: 2.319192466249068

Epoch: 6| Step: 3
Training loss: 0.10334705176239571
Validation loss: 2.286082868161072

Epoch: 6| Step: 4
Training loss: 0.13572720232244984
Validation loss: 2.3333082468761552

Epoch: 6| Step: 5
Training loss: 0.27311878703577663
Validation loss: 2.298861975924252

Epoch: 6| Step: 6
Training loss: 0.12546481198773318
Validation loss: 2.2973762006111844

Epoch: 6| Step: 7
Training loss: 0.12186015539974714
Validation loss: 2.2764576627763256

Epoch: 6| Step: 8
Training loss: 0.14082799935491347
Validation loss: 2.3210555665244343

Epoch: 6| Step: 9
Training loss: 0.08544268446870328
Validation loss: 2.3129987281426354

Epoch: 6| Step: 10
Training loss: 0.12509396865495892
Validation loss: 2.3222102463211556

Epoch: 6| Step: 11
Training loss: 0.15619402121095646
Validation loss: 2.3663658595951

Epoch: 6| Step: 12
Training loss: 0.14676103533043275
Validation loss: 2.3971277104814273

Epoch: 6| Step: 13
Training loss: 0.1035312244969091
Validation loss: 2.4011832852504873

Epoch: 779| Step: 0
Training loss: 0.2158750059120076
Validation loss: 2.4072334465007135

Epoch: 6| Step: 1
Training loss: 0.1406345496643879
Validation loss: 2.3740776048644223

Epoch: 6| Step: 2
Training loss: 0.1746182859737042
Validation loss: 2.382111743919578

Epoch: 6| Step: 3
Training loss: 0.1292936183484736
Validation loss: 2.3775882730973867

Epoch: 6| Step: 4
Training loss: 0.1729281896798183
Validation loss: 2.3668600092969614

Epoch: 6| Step: 5
Training loss: 0.15651210021278755
Validation loss: 2.3485187147965263

Epoch: 6| Step: 6
Training loss: 0.24594123595137576
Validation loss: 2.341791359184904

Epoch: 6| Step: 7
Training loss: 0.13748392829384576
Validation loss: 2.3333797516596833

Epoch: 6| Step: 8
Training loss: 0.08702563239875052
Validation loss: 2.2944008417659467

Epoch: 6| Step: 9
Training loss: 0.1379144358946741
Validation loss: 2.281190672229558

Epoch: 6| Step: 10
Training loss: 0.16545464598763282
Validation loss: 2.2938088622890493

Epoch: 6| Step: 11
Training loss: 0.1408534975142717
Validation loss: 2.276051683733086

Epoch: 6| Step: 12
Training loss: 0.16515497504890764
Validation loss: 2.2703412792833593

Epoch: 6| Step: 13
Training loss: 0.08299604220246658
Validation loss: 2.27353789805541

Epoch: 780| Step: 0
Training loss: 0.1333052246694602
Validation loss: 2.2674022635796094

Epoch: 6| Step: 1
Training loss: 0.10600592104972827
Validation loss: 2.262923898759906

Epoch: 6| Step: 2
Training loss: 0.16389122605902304
Validation loss: 2.2613433810337544

Epoch: 6| Step: 3
Training loss: 0.15048822728477268
Validation loss: 2.2462618891419015

Epoch: 6| Step: 4
Training loss: 0.1777520432965085
Validation loss: 2.285115308791878

Epoch: 6| Step: 5
Training loss: 0.08409444117040547
Validation loss: 2.2754774003583034

Epoch: 6| Step: 6
Training loss: 0.11628599708061178
Validation loss: 2.297226910743962

Epoch: 6| Step: 7
Training loss: 0.08719489983976338
Validation loss: 2.2862978310422033

Epoch: 6| Step: 8
Training loss: 0.22448197773871925
Validation loss: 2.3055246580838937

Epoch: 6| Step: 9
Training loss: 0.09607430897192956
Validation loss: 2.313446935255865

Epoch: 6| Step: 10
Training loss: 0.1521932151629948
Validation loss: 2.3193535597714092

Epoch: 6| Step: 11
Training loss: 0.11453989860177985
Validation loss: 2.346573110687307

Epoch: 6| Step: 12
Training loss: 0.13258761411886555
Validation loss: 2.384023709353335

Epoch: 6| Step: 13
Training loss: 0.10982889272997029
Validation loss: 2.368309110227921

Epoch: 781| Step: 0
Training loss: 0.08191979022595629
Validation loss: 2.3990824438424356

Epoch: 6| Step: 1
Training loss: 0.09744464359651776
Validation loss: 2.3902240910033923

Epoch: 6| Step: 2
Training loss: 0.15904202974049986
Validation loss: 2.388552022233655

Epoch: 6| Step: 3
Training loss: 0.1654587550111865
Validation loss: 2.3819056428169985

Epoch: 6| Step: 4
Training loss: 0.10230816775851517
Validation loss: 2.346795580944488

Epoch: 6| Step: 5
Training loss: 0.13826582116729447
Validation loss: 2.3426564433480896

Epoch: 6| Step: 6
Training loss: 0.10093780194228513
Validation loss: 2.330006327859256

Epoch: 6| Step: 7
Training loss: 0.10447214059065955
Validation loss: 2.3156555284036555

Epoch: 6| Step: 8
Training loss: 0.11119882704595159
Validation loss: 2.3044583598293293

Epoch: 6| Step: 9
Training loss: 0.11025878922467658
Validation loss: 2.2844032658997144

Epoch: 6| Step: 10
Training loss: 0.10929593566425441
Validation loss: 2.2987477947378143

Epoch: 6| Step: 11
Training loss: 0.10516703683529306
Validation loss: 2.2858071888581764

Epoch: 6| Step: 12
Training loss: 0.1189948229482543
Validation loss: 2.273896060906962

Epoch: 6| Step: 13
Training loss: 0.10298464554710775
Validation loss: 2.2583639087051934

Epoch: 782| Step: 0
Training loss: 0.1156866846632911
Validation loss: 2.284293473746151

Epoch: 6| Step: 1
Training loss: 0.10407998432158848
Validation loss: 2.259846311739973

Epoch: 6| Step: 2
Training loss: 0.13768825107080437
Validation loss: 2.288728318541422

Epoch: 6| Step: 3
Training loss: 0.11674109310180163
Validation loss: 2.2650351022663653

Epoch: 6| Step: 4
Training loss: 0.09952689477203992
Validation loss: 2.2593807019153656

Epoch: 6| Step: 5
Training loss: 0.11747571153910316
Validation loss: 2.2493862029285587

Epoch: 6| Step: 6
Training loss: 0.10271821493247935
Validation loss: 2.2808887096139463

Epoch: 6| Step: 7
Training loss: 0.08490220868222989
Validation loss: 2.274380402840395

Epoch: 6| Step: 8
Training loss: 0.1574325870248604
Validation loss: 2.2948909670690916

Epoch: 6| Step: 9
Training loss: 0.09753883933155225
Validation loss: 2.296850228191745

Epoch: 6| Step: 10
Training loss: 0.1779757108323447
Validation loss: 2.3118692007222927

Epoch: 6| Step: 11
Training loss: 0.07929308100019238
Validation loss: 2.33804103329695

Epoch: 6| Step: 12
Training loss: 0.1408611275494597
Validation loss: 2.3252309421847817

Epoch: 6| Step: 13
Training loss: 0.09227930282517505
Validation loss: 2.329704820630405

Epoch: 783| Step: 0
Training loss: 0.11892687274083026
Validation loss: 2.3243736187228645

Epoch: 6| Step: 1
Training loss: 0.07644145286262725
Validation loss: 2.3447364902280614

Epoch: 6| Step: 2
Training loss: 0.1306851779087454
Validation loss: 2.3432617674351324

Epoch: 6| Step: 3
Training loss: 0.10041493166104618
Validation loss: 2.338154852857246

Epoch: 6| Step: 4
Training loss: 0.15664370526640878
Validation loss: 2.3277283764459207

Epoch: 6| Step: 5
Training loss: 0.1507289598152026
Validation loss: 2.3250746685118093

Epoch: 6| Step: 6
Training loss: 0.13712563594889723
Validation loss: 2.3425651940967156

Epoch: 6| Step: 7
Training loss: 0.09820462754525677
Validation loss: 2.3164421880720734

Epoch: 6| Step: 8
Training loss: 0.14511694670666192
Validation loss: 2.2947010086379263

Epoch: 6| Step: 9
Training loss: 0.10267587344996518
Validation loss: 2.3155663084617863

Epoch: 6| Step: 10
Training loss: 0.13996053379947104
Validation loss: 2.2888184247591834

Epoch: 6| Step: 11
Training loss: 0.08300621087268172
Validation loss: 2.2984424884830377

Epoch: 6| Step: 12
Training loss: 0.06966091279086586
Validation loss: 2.2768420974121257

Epoch: 6| Step: 13
Training loss: 0.12492325035898329
Validation loss: 2.3262618684710294

Epoch: 784| Step: 0
Training loss: 0.09569046364934426
Validation loss: 2.299398644062609

Epoch: 6| Step: 1
Training loss: 0.09502382435367455
Validation loss: 2.2973287900217074

Epoch: 6| Step: 2
Training loss: 0.18085389345237268
Validation loss: 2.2975173653547065

Epoch: 6| Step: 3
Training loss: 0.07508419546222628
Validation loss: 2.2743497658274756

Epoch: 6| Step: 4
Training loss: 0.0830801648482682
Validation loss: 2.2729561253845394

Epoch: 6| Step: 5
Training loss: 0.08528744233512578
Validation loss: 2.2461777058694166

Epoch: 6| Step: 6
Training loss: 0.13380047129972486
Validation loss: 2.2714313653998888

Epoch: 6| Step: 7
Training loss: 0.21764834621726992
Validation loss: 2.2731801310103035

Epoch: 6| Step: 8
Training loss: 0.09838923035266726
Validation loss: 2.268111125221239

Epoch: 6| Step: 9
Training loss: 0.11475303710058814
Validation loss: 2.2993436930064632

Epoch: 6| Step: 10
Training loss: 0.12802987143482228
Validation loss: 2.2947005107156673

Epoch: 6| Step: 11
Training loss: 0.10389846059097756
Validation loss: 2.3041144713831687

Epoch: 6| Step: 12
Training loss: 0.12429892363859074
Validation loss: 2.322323690385174

Epoch: 6| Step: 13
Training loss: 0.12116690318042654
Validation loss: 2.350277027522173

Epoch: 785| Step: 0
Training loss: 0.10280371074008124
Validation loss: 2.3390702779021897

Epoch: 6| Step: 1
Training loss: 0.08926130242067204
Validation loss: 2.3452507896382877

Epoch: 6| Step: 2
Training loss: 0.12642758973241205
Validation loss: 2.3583141795154954

Epoch: 6| Step: 3
Training loss: 0.13148395032808444
Validation loss: 2.342795555448289

Epoch: 6| Step: 4
Training loss: 0.10333928346887576
Validation loss: 2.3577461968746163

Epoch: 6| Step: 5
Training loss: 0.12180153056674234
Validation loss: 2.349442626179557

Epoch: 6| Step: 6
Training loss: 0.10835045534399325
Validation loss: 2.338144630748192

Epoch: 6| Step: 7
Training loss: 0.07940584104530987
Validation loss: 2.3071578429204926

Epoch: 6| Step: 8
Training loss: 0.14154025756757588
Validation loss: 2.324723247023318

Epoch: 6| Step: 9
Training loss: 0.09493993049766349
Validation loss: 2.3075126027913955

Epoch: 6| Step: 10
Training loss: 0.11208718010382525
Validation loss: 2.3177681945024133

Epoch: 6| Step: 11
Training loss: 0.10593563514238374
Validation loss: 2.3004300367746744

Epoch: 6| Step: 12
Training loss: 0.11635911934687361
Validation loss: 2.3134311335714037

Epoch: 6| Step: 13
Training loss: 0.09332560802458872
Validation loss: 2.3034611457313554

Epoch: 786| Step: 0
Training loss: 0.06992627401739288
Validation loss: 2.279963440861935

Epoch: 6| Step: 1
Training loss: 0.09575195429216897
Validation loss: 2.3080091685587174

Epoch: 6| Step: 2
Training loss: 0.12876348103156107
Validation loss: 2.296026649537606

Epoch: 6| Step: 3
Training loss: 0.17912369885607635
Validation loss: 2.289685629399529

Epoch: 6| Step: 4
Training loss: 0.08855738453571418
Validation loss: 2.2919076660457054

Epoch: 6| Step: 5
Training loss: 0.07611797027103177
Validation loss: 2.2899085543468303

Epoch: 6| Step: 6
Training loss: 0.10739576282446489
Validation loss: 2.2883879721079947

Epoch: 6| Step: 7
Training loss: 0.1330812483964405
Validation loss: 2.2946752557000245

Epoch: 6| Step: 8
Training loss: 0.13470512912021781
Validation loss: 2.273157904669346

Epoch: 6| Step: 9
Training loss: 0.06630180363447512
Validation loss: 2.2918412851459253

Epoch: 6| Step: 10
Training loss: 0.07690920132938303
Validation loss: 2.283407812121662

Epoch: 6| Step: 11
Training loss: 0.05766280841226006
Validation loss: 2.284806849325799

Epoch: 6| Step: 12
Training loss: 0.04254269974504158
Validation loss: 2.2876189483086997

Epoch: 6| Step: 13
Training loss: 0.15755833397963637
Validation loss: 2.29384638265926

Epoch: 787| Step: 0
Training loss: 0.08848878973877632
Validation loss: 2.2986616895682355

Epoch: 6| Step: 1
Training loss: 0.11771768797214877
Validation loss: 2.2767828473265266

Epoch: 6| Step: 2
Training loss: 0.13477825713731953
Validation loss: 2.3062328921470345

Epoch: 6| Step: 3
Training loss: 0.09323273453021226
Validation loss: 2.2639176931217415

Epoch: 6| Step: 4
Training loss: 0.06890067297992822
Validation loss: 2.29227201981482

Epoch: 6| Step: 5
Training loss: 0.1445841821193058
Validation loss: 2.2891321762071506

Epoch: 6| Step: 6
Training loss: 0.09969060054429701
Validation loss: 2.29460530035237

Epoch: 6| Step: 7
Training loss: 0.08086665876265633
Validation loss: 2.2756250562002966

Epoch: 6| Step: 8
Training loss: 0.07441031053551027
Validation loss: 2.2975104962900446

Epoch: 6| Step: 9
Training loss: 0.07941526444891073
Validation loss: 2.3170890231400594

Epoch: 6| Step: 10
Training loss: 0.10458177665423275
Validation loss: 2.2848232646861506

Epoch: 6| Step: 11
Training loss: 0.09068194996455001
Validation loss: 2.2809410307403435

Epoch: 6| Step: 12
Training loss: 0.10871912370619179
Validation loss: 2.2832442548816374

Epoch: 6| Step: 13
Training loss: 0.12230555945554364
Validation loss: 2.2594661885265976

Epoch: 788| Step: 0
Training loss: 0.09293303565030558
Validation loss: 2.2646206800553657

Epoch: 6| Step: 1
Training loss: 0.08064063727303544
Validation loss: 2.2865524700548754

Epoch: 6| Step: 2
Training loss: 0.09458127629077999
Validation loss: 2.284688121131687

Epoch: 6| Step: 3
Training loss: 0.08205805635696235
Validation loss: 2.302109717382748

Epoch: 6| Step: 4
Training loss: 0.11148841511757872
Validation loss: 2.290617040363948

Epoch: 6| Step: 5
Training loss: 0.08134027518574889
Validation loss: 2.3022319467512884

Epoch: 6| Step: 6
Training loss: 0.10216281982906468
Validation loss: 2.2893854428818083

Epoch: 6| Step: 7
Training loss: 0.11318733169663216
Validation loss: 2.2856812468543812

Epoch: 6| Step: 8
Training loss: 0.11536628237162772
Validation loss: 2.272918930707522

Epoch: 6| Step: 9
Training loss: 0.10266331002447554
Validation loss: 2.2749606029705682

Epoch: 6| Step: 10
Training loss: 0.09218494585507642
Validation loss: 2.2777573565169518

Epoch: 6| Step: 11
Training loss: 0.1250802244597537
Validation loss: 2.269805526772026

Epoch: 6| Step: 12
Training loss: 0.10982330442641934
Validation loss: 2.277414984148232

Epoch: 6| Step: 13
Training loss: 0.17748591064895677
Validation loss: 2.302817508829545

Epoch: 789| Step: 0
Training loss: 0.0988541565035194
Validation loss: 2.2763147646224278

Epoch: 6| Step: 1
Training loss: 0.10853032517197023
Validation loss: 2.296278981627288

Epoch: 6| Step: 2
Training loss: 0.12306037329249932
Validation loss: 2.285632124900001

Epoch: 6| Step: 3
Training loss: 0.08167747437093588
Validation loss: 2.3013549036058563

Epoch: 6| Step: 4
Training loss: 0.11795411492823077
Validation loss: 2.3114214385443534

Epoch: 6| Step: 5
Training loss: 0.1114560321060782
Validation loss: 2.2890770167746837

Epoch: 6| Step: 6
Training loss: 0.12427925774447664
Validation loss: 2.304601930170258

Epoch: 6| Step: 7
Training loss: 0.09319369846391433
Validation loss: 2.3096016822121834

Epoch: 6| Step: 8
Training loss: 0.08954195459559783
Validation loss: 2.307181972647108

Epoch: 6| Step: 9
Training loss: 0.1579088016374057
Validation loss: 2.3245321165787924

Epoch: 6| Step: 10
Training loss: 0.08267429049017723
Validation loss: 2.323854555512512

Epoch: 6| Step: 11
Training loss: 0.09304650425136445
Validation loss: 2.3307351066516873

Epoch: 6| Step: 12
Training loss: 0.10622082232501646
Validation loss: 2.3375127193957477

Epoch: 6| Step: 13
Training loss: 0.08929032937537193
Validation loss: 2.307466222625411

Epoch: 790| Step: 0
Training loss: 0.08781401421218836
Validation loss: 2.3204860832942353

Epoch: 6| Step: 1
Training loss: 0.1184913893621394
Validation loss: 2.311569960288153

Epoch: 6| Step: 2
Training loss: 0.06913265799294871
Validation loss: 2.32491841300429

Epoch: 6| Step: 3
Training loss: 0.068442301178964
Validation loss: 2.293269307007875

Epoch: 6| Step: 4
Training loss: 0.07743457352752003
Validation loss: 2.303199242353783

Epoch: 6| Step: 5
Training loss: 0.08867940345599702
Validation loss: 2.3233642518471496

Epoch: 6| Step: 6
Training loss: 0.09715096406369955
Validation loss: 2.3120840167425194

Epoch: 6| Step: 7
Training loss: 0.06473101329522622
Validation loss: 2.2978864603460827

Epoch: 6| Step: 8
Training loss: 0.1129116738307648
Validation loss: 2.3051169080055147

Epoch: 6| Step: 9
Training loss: 0.1034217039519799
Validation loss: 2.2849504892670387

Epoch: 6| Step: 10
Training loss: 0.09986999021391879
Validation loss: 2.281160815028606

Epoch: 6| Step: 11
Training loss: 0.07951213401305555
Validation loss: 2.276109662083011

Epoch: 6| Step: 12
Training loss: 0.12820373186319997
Validation loss: 2.273219417916004

Epoch: 6| Step: 13
Training loss: 0.06142460362529099
Validation loss: 2.2830892889037937

Epoch: 791| Step: 0
Training loss: 0.10813064833314302
Validation loss: 2.2866285230250645

Epoch: 6| Step: 1
Training loss: 0.0953621336419012
Validation loss: 2.3009180722289524

Epoch: 6| Step: 2
Training loss: 0.07216654248305847
Validation loss: 2.293962830316709

Epoch: 6| Step: 3
Training loss: 0.08903260607705953
Validation loss: 2.304009552985814

Epoch: 6| Step: 4
Training loss: 0.10212976419946045
Validation loss: 2.3100391609883006

Epoch: 6| Step: 5
Training loss: 0.09379948859550684
Validation loss: 2.3093553162180958

Epoch: 6| Step: 6
Training loss: 0.06448734343235785
Validation loss: 2.3036799727730766

Epoch: 6| Step: 7
Training loss: 0.10143784520865534
Validation loss: 2.2969795160300013

Epoch: 6| Step: 8
Training loss: 0.10621416297467996
Validation loss: 2.3069296471155103

Epoch: 6| Step: 9
Training loss: 0.10287421267945168
Validation loss: 2.2841932302515597

Epoch: 6| Step: 10
Training loss: 0.11732751508603265
Validation loss: 2.2412148620941434

Epoch: 6| Step: 11
Training loss: 0.0690579078515536
Validation loss: 2.279523838942882

Epoch: 6| Step: 12
Training loss: 0.11085133345957543
Validation loss: 2.2636886689913838

Epoch: 6| Step: 13
Training loss: 0.19196177656016644
Validation loss: 2.2454981082852914

Epoch: 792| Step: 0
Training loss: 0.11362961527580799
Validation loss: 2.2410339838956603

Epoch: 6| Step: 1
Training loss: 0.11808073242456486
Validation loss: 2.2322714142702793

Epoch: 6| Step: 2
Training loss: 0.11582584046267418
Validation loss: 2.2609999801763387

Epoch: 6| Step: 3
Training loss: 0.08527410001493028
Validation loss: 2.2575307571568395

Epoch: 6| Step: 4
Training loss: 0.08635304779515474
Validation loss: 2.2604879310669816

Epoch: 6| Step: 5
Training loss: 0.10306288571658576
Validation loss: 2.247367259734057

Epoch: 6| Step: 6
Training loss: 0.1067692220574041
Validation loss: 2.2682433899240113

Epoch: 6| Step: 7
Training loss: 0.09519124839099952
Validation loss: 2.2889596233568255

Epoch: 6| Step: 8
Training loss: 0.13228326424124717
Validation loss: 2.27748221777441

Epoch: 6| Step: 9
Training loss: 0.11108499044444822
Validation loss: 2.28237201261709

Epoch: 6| Step: 10
Training loss: 0.07649594839904593
Validation loss: 2.279960431344955

Epoch: 6| Step: 11
Training loss: 0.15285673947222972
Validation loss: 2.2986664752096218

Epoch: 6| Step: 12
Training loss: 0.18581149656318027
Validation loss: 2.2761121873036596

Epoch: 6| Step: 13
Training loss: 0.09337559084341489
Validation loss: 2.311778515005396

Epoch: 793| Step: 0
Training loss: 0.07907139532555603
Validation loss: 2.2991321102858215

Epoch: 6| Step: 1
Training loss: 0.12774295865537058
Validation loss: 2.298468515767087

Epoch: 6| Step: 2
Training loss: 0.10866137566982571
Validation loss: 2.304547193847316

Epoch: 6| Step: 3
Training loss: 0.15699078669591057
Validation loss: 2.326100043254721

Epoch: 6| Step: 4
Training loss: 0.08888110376743942
Validation loss: 2.3035088808413575

Epoch: 6| Step: 5
Training loss: 0.09381856497214645
Validation loss: 2.2964746278206905

Epoch: 6| Step: 6
Training loss: 0.10184526511239049
Validation loss: 2.2815695963132154

Epoch: 6| Step: 7
Training loss: 0.12709591977790652
Validation loss: 2.272042388849783

Epoch: 6| Step: 8
Training loss: 0.11290052990871391
Validation loss: 2.2901886216659637

Epoch: 6| Step: 9
Training loss: 0.10973053860140171
Validation loss: 2.286885197980132

Epoch: 6| Step: 10
Training loss: 0.05601594363538279
Validation loss: 2.3106021404500545

Epoch: 6| Step: 11
Training loss: 0.1708827202245184
Validation loss: 2.3242029928719576

Epoch: 6| Step: 12
Training loss: 0.09148557106754257
Validation loss: 2.29984425083827

Epoch: 6| Step: 13
Training loss: 0.03945656285792988
Validation loss: 2.323738954332218

Epoch: 794| Step: 0
Training loss: 0.09451356517472531
Validation loss: 2.3165352221756055

Epoch: 6| Step: 1
Training loss: 0.07696085772414851
Validation loss: 2.3083879588601164

Epoch: 6| Step: 2
Training loss: 0.09820788032835649
Validation loss: 2.3385387586627666

Epoch: 6| Step: 3
Training loss: 0.09754424347597775
Validation loss: 2.335060344820176

Epoch: 6| Step: 4
Training loss: 0.07909248441243548
Validation loss: 2.3028608605375025

Epoch: 6| Step: 5
Training loss: 0.05613899901668721
Validation loss: 2.302723805278925

Epoch: 6| Step: 6
Training loss: 0.11234805057767194
Validation loss: 2.3212849739932544

Epoch: 6| Step: 7
Training loss: 0.09480657344587912
Validation loss: 2.284023375787382

Epoch: 6| Step: 8
Training loss: 0.06755841221251502
Validation loss: 2.294782982094266

Epoch: 6| Step: 9
Training loss: 0.0867018681065745
Validation loss: 2.2824732992290797

Epoch: 6| Step: 10
Training loss: 0.10579700515343567
Validation loss: 2.2534662138727253

Epoch: 6| Step: 11
Training loss: 0.09750614551133673
Validation loss: 2.290145186795809

Epoch: 6| Step: 12
Training loss: 0.11990552178754033
Validation loss: 2.286275928457284

Epoch: 6| Step: 13
Training loss: 0.10516471662913751
Validation loss: 2.302833943310215

Epoch: 795| Step: 0
Training loss: 0.07512165152526303
Validation loss: 2.281409030641132

Epoch: 6| Step: 1
Training loss: 0.07228006076968288
Validation loss: 2.2875984199860517

Epoch: 6| Step: 2
Training loss: 0.0965058854870397
Validation loss: 2.2647015741713195

Epoch: 6| Step: 3
Training loss: 0.07324479734221426
Validation loss: 2.2910800845006265

Epoch: 6| Step: 4
Training loss: 0.12884683395662277
Validation loss: 2.281362362514935

Epoch: 6| Step: 5
Training loss: 0.10060526375147041
Validation loss: 2.2814946489439927

Epoch: 6| Step: 6
Training loss: 0.10226273314756369
Validation loss: 2.305072188491423

Epoch: 6| Step: 7
Training loss: 0.07339324315111387
Validation loss: 2.3165927179620884

Epoch: 6| Step: 8
Training loss: 0.11935976854986795
Validation loss: 2.3154950904616376

Epoch: 6| Step: 9
Training loss: 0.10482185268699254
Validation loss: 2.3133563313350667

Epoch: 6| Step: 10
Training loss: 0.097036704341649
Validation loss: 2.3234811157111137

Epoch: 6| Step: 11
Training loss: 0.09537795352112341
Validation loss: 2.292862655204074

Epoch: 6| Step: 12
Training loss: 0.11243280897723779
Validation loss: 2.282257799201955

Epoch: 6| Step: 13
Training loss: 0.0630619446330195
Validation loss: 2.3065910180159337

Epoch: 796| Step: 0
Training loss: 0.06601756307476993
Validation loss: 2.2535202945087796

Epoch: 6| Step: 1
Training loss: 0.09020780836951789
Validation loss: 2.2696962816706074

Epoch: 6| Step: 2
Training loss: 0.07804548568271816
Validation loss: 2.2741189617624333

Epoch: 6| Step: 3
Training loss: 0.11931480901201379
Validation loss: 2.2888821940303075

Epoch: 6| Step: 4
Training loss: 0.08160050013002648
Validation loss: 2.24839739085135

Epoch: 6| Step: 5
Training loss: 0.07711194479060389
Validation loss: 2.2585715546447807

Epoch: 6| Step: 6
Training loss: 0.07395798587661488
Validation loss: 2.2347685127976624

Epoch: 6| Step: 7
Training loss: 0.06763632396127837
Validation loss: 2.247340664583145

Epoch: 6| Step: 8
Training loss: 0.10110587393745038
Validation loss: 2.2602892365726857

Epoch: 6| Step: 9
Training loss: 0.0610365867447112
Validation loss: 2.2729128027818137

Epoch: 6| Step: 10
Training loss: 0.14245340692957312
Validation loss: 2.2639483943057286

Epoch: 6| Step: 11
Training loss: 0.10378023731009833
Validation loss: 2.246479299304268

Epoch: 6| Step: 12
Training loss: 0.08458609764050139
Validation loss: 2.289099956495644

Epoch: 6| Step: 13
Training loss: 0.13764929171456872
Validation loss: 2.299453227285045

Epoch: 797| Step: 0
Training loss: 0.08376891198421882
Validation loss: 2.2750654020287495

Epoch: 6| Step: 1
Training loss: 0.10021330967384884
Validation loss: 2.2798109956508505

Epoch: 6| Step: 2
Training loss: 0.05581275004446229
Validation loss: 2.2876341937021776

Epoch: 6| Step: 3
Training loss: 0.14306391951447098
Validation loss: 2.2879938491675436

Epoch: 6| Step: 4
Training loss: 0.08770220480938555
Validation loss: 2.309692118193718

Epoch: 6| Step: 5
Training loss: 0.13092427281370236
Validation loss: 2.265715226331191

Epoch: 6| Step: 6
Training loss: 0.09609771173730726
Validation loss: 2.2739937442952485

Epoch: 6| Step: 7
Training loss: 0.09082172761860595
Validation loss: 2.2811778528141295

Epoch: 6| Step: 8
Training loss: 0.1640485803057865
Validation loss: 2.2952102567214294

Epoch: 6| Step: 9
Training loss: 0.10249343947023862
Validation loss: 2.3101762982687264

Epoch: 6| Step: 10
Training loss: 0.10293345218266678
Validation loss: 2.3132861596175163

Epoch: 6| Step: 11
Training loss: 0.120639471905527
Validation loss: 2.326434410599587

Epoch: 6| Step: 12
Training loss: 0.07941197488745677
Validation loss: 2.350124628292042

Epoch: 6| Step: 13
Training loss: 0.06793185814103475
Validation loss: 2.307357003462273

Epoch: 798| Step: 0
Training loss: 0.11460844265117164
Validation loss: 2.3044410658631054

Epoch: 6| Step: 1
Training loss: 0.07272075691535691
Validation loss: 2.302401566929244

Epoch: 6| Step: 2
Training loss: 0.1171073003359934
Validation loss: 2.3355656864769023

Epoch: 6| Step: 3
Training loss: 0.09614285342601846
Validation loss: 2.319194656602648

Epoch: 6| Step: 4
Training loss: 0.10088114334388192
Validation loss: 2.310689801324617

Epoch: 6| Step: 5
Training loss: 0.09681402371637682
Validation loss: 2.296818116748896

Epoch: 6| Step: 6
Training loss: 0.08852129472787516
Validation loss: 2.298741174980811

Epoch: 6| Step: 7
Training loss: 0.092493639192451
Validation loss: 2.2948011705103832

Epoch: 6| Step: 8
Training loss: 0.08380520082769774
Validation loss: 2.2696525692810767

Epoch: 6| Step: 9
Training loss: 0.09115246566983365
Validation loss: 2.2979619228947854

Epoch: 6| Step: 10
Training loss: 0.08599447940660133
Validation loss: 2.3040155976480268

Epoch: 6| Step: 11
Training loss: 0.09541988791712187
Validation loss: 2.3161179914941723

Epoch: 6| Step: 12
Training loss: 0.09193474987073803
Validation loss: 2.310635861045267

Epoch: 6| Step: 13
Training loss: 0.054217868036467845
Validation loss: 2.303695963199212

Epoch: 799| Step: 0
Training loss: 0.08943574457525148
Validation loss: 2.325171951584743

Epoch: 6| Step: 1
Training loss: 0.0772004555725364
Validation loss: 2.316106157920861

Epoch: 6| Step: 2
Training loss: 0.12420677166292099
Validation loss: 2.3294544007316396

Epoch: 6| Step: 3
Training loss: 0.0800401667439148
Validation loss: 2.316742139799584

Epoch: 6| Step: 4
Training loss: 0.10211887551833505
Validation loss: 2.304217165394497

Epoch: 6| Step: 5
Training loss: 0.11121219320764081
Validation loss: 2.2975139620682516

Epoch: 6| Step: 6
Training loss: 0.133706826323178
Validation loss: 2.2784568238982406

Epoch: 6| Step: 7
Training loss: 0.06208940018336133
Validation loss: 2.2689115003462175

Epoch: 6| Step: 8
Training loss: 0.07828582066005177
Validation loss: 2.2683368299071125

Epoch: 6| Step: 9
Training loss: 0.08471064586460791
Validation loss: 2.2683310772573257

Epoch: 6| Step: 10
Training loss: 0.12619565792741402
Validation loss: 2.239476290694297

Epoch: 6| Step: 11
Training loss: 0.1068970082025838
Validation loss: 2.2671070347753592

Epoch: 6| Step: 12
Training loss: 0.09840358403411448
Validation loss: 2.2489966983577148

Epoch: 6| Step: 13
Training loss: 0.12285689416665946
Validation loss: 2.2654562944253036

Epoch: 800| Step: 0
Training loss: 0.10322154756381889
Validation loss: 2.2644802620192332

Epoch: 6| Step: 1
Training loss: 0.07915536204780155
Validation loss: 2.25772209964413

Epoch: 6| Step: 2
Training loss: 0.07343613377274211
Validation loss: 2.2751094149485205

Epoch: 6| Step: 3
Training loss: 0.10485166143906262
Validation loss: 2.248333424274046

Epoch: 6| Step: 4
Training loss: 0.12875022259711494
Validation loss: 2.244869378060526

Epoch: 6| Step: 5
Training loss: 0.07676585618793158
Validation loss: 2.2780129018027457

Epoch: 6| Step: 6
Training loss: 0.08234064474530153
Validation loss: 2.2983569926086016

Epoch: 6| Step: 7
Training loss: 0.08685005702973285
Validation loss: 2.318511064718568

Epoch: 6| Step: 8
Training loss: 0.08805001429264434
Validation loss: 2.3239991498366708

Epoch: 6| Step: 9
Training loss: 0.0788232534451451
Validation loss: 2.3140366151402834

Epoch: 6| Step: 10
Training loss: 0.10662660995723608
Validation loss: 2.298577720071497

Epoch: 6| Step: 11
Training loss: 0.10310626058388245
Validation loss: 2.3337369809934208

Epoch: 6| Step: 12
Training loss: 0.08923592935670203
Validation loss: 2.313055506630656

Epoch: 6| Step: 13
Training loss: 0.12724981851461767
Validation loss: 2.317472940409471

Testing loss: 2.4739610360114073
