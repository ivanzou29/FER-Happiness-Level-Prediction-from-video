Epoch: 1| Step: 0
Training loss: 6.507243009014581
Validation loss: 5.80267905623464

Epoch: 6| Step: 1
Training loss: 4.879442587113563
Validation loss: 5.784551639199611

Epoch: 6| Step: 2
Training loss: 5.131525305031317
Validation loss: 5.765610376586208

Epoch: 6| Step: 3
Training loss: 4.713747518129588
Validation loss: 5.745361765132406

Epoch: 6| Step: 4
Training loss: 7.000928544720425
Validation loss: 5.723653984904428

Epoch: 6| Step: 5
Training loss: 6.179175740306294
Validation loss: 5.69953562182101

Epoch: 6| Step: 6
Training loss: 5.056201360254017
Validation loss: 5.67282752695488

Epoch: 6| Step: 7
Training loss: 5.324632859445863
Validation loss: 5.642865072465574

Epoch: 6| Step: 8
Training loss: 5.284636365494123
Validation loss: 5.609973060365262

Epoch: 6| Step: 9
Training loss: 5.634591296588408
Validation loss: 5.574168222185441

Epoch: 6| Step: 10
Training loss: 5.318842613409032
Validation loss: 5.534095176549298

Epoch: 6| Step: 11
Training loss: 6.012490305426826
Validation loss: 5.491773133525966

Epoch: 6| Step: 12
Training loss: 5.7034624391825375
Validation loss: 5.447408856199228

Epoch: 6| Step: 13
Training loss: 6.6299618547587915
Validation loss: 5.399258364859282

Epoch: 2| Step: 0
Training loss: 5.439305849666914
Validation loss: 5.35117410667021

Epoch: 6| Step: 1
Training loss: 6.755179501964383
Validation loss: 5.3019514118421185

Epoch: 6| Step: 2
Training loss: 6.007540097652478
Validation loss: 5.253066745933887

Epoch: 6| Step: 3
Training loss: 5.286229421485794
Validation loss: 5.206440630506759

Epoch: 6| Step: 4
Training loss: 4.353157887878839
Validation loss: 5.159795758716564

Epoch: 6| Step: 5
Training loss: 4.449860671358917
Validation loss: 5.117243185321964

Epoch: 6| Step: 6
Training loss: 5.441646179036026
Validation loss: 5.0785846925573415

Epoch: 6| Step: 7
Training loss: 3.657220695297363
Validation loss: 5.042688005782974

Epoch: 6| Step: 8
Training loss: 5.2376815145353275
Validation loss: 5.010939120858851

Epoch: 6| Step: 9
Training loss: 4.680892763653033
Validation loss: 4.980733522555011

Epoch: 6| Step: 10
Training loss: 5.603180676857544
Validation loss: 4.949715998558904

Epoch: 6| Step: 11
Training loss: 5.400167582701916
Validation loss: 4.917927825149383

Epoch: 6| Step: 12
Training loss: 4.057957853667122
Validation loss: 4.875618046954386

Epoch: 6| Step: 13
Training loss: 4.966634239927254
Validation loss: 4.836928778894933

Epoch: 3| Step: 0
Training loss: 4.502612732996237
Validation loss: 4.807718753713563

Epoch: 6| Step: 1
Training loss: 4.919816037592259
Validation loss: 4.782605567705587

Epoch: 6| Step: 2
Training loss: 4.447592420470096
Validation loss: 4.749501530863342

Epoch: 6| Step: 3
Training loss: 5.2154742713390885
Validation loss: 4.719586598177201

Epoch: 6| Step: 4
Training loss: 4.275743939546926
Validation loss: 4.68574766595796

Epoch: 6| Step: 5
Training loss: 4.513133064308247
Validation loss: 4.656634443508092

Epoch: 6| Step: 6
Training loss: 5.081512917336011
Validation loss: 4.641179814213256

Epoch: 6| Step: 7
Training loss: 4.231098328975351
Validation loss: 4.619669204803334

Epoch: 6| Step: 8
Training loss: 5.509394858027528
Validation loss: 4.600303501765527

Epoch: 6| Step: 9
Training loss: 4.387173093262237
Validation loss: 4.582954450740971

Epoch: 6| Step: 10
Training loss: 5.402655315999807
Validation loss: 4.559885916604213

Epoch: 6| Step: 11
Training loss: 4.24521524699115
Validation loss: 4.532997244266396

Epoch: 6| Step: 12
Training loss: 4.959694533940081
Validation loss: 4.506005173584901

Epoch: 6| Step: 13
Training loss: 4.038909968257457
Validation loss: 4.4897283136617

Epoch: 4| Step: 0
Training loss: 5.7288342558632595
Validation loss: 4.45739910575611

Epoch: 6| Step: 1
Training loss: 5.151905610931764
Validation loss: 4.431945719414706

Epoch: 6| Step: 2
Training loss: 4.210963318131659
Validation loss: 4.423818488942334

Epoch: 6| Step: 3
Training loss: 3.839349724625695
Validation loss: 4.412633695299346

Epoch: 6| Step: 4
Training loss: 4.577200005210097
Validation loss: 4.392791791437432

Epoch: 6| Step: 5
Training loss: 4.621806098677175
Validation loss: 4.377486194930302

Epoch: 6| Step: 6
Training loss: 4.2753357515608315
Validation loss: 4.358572551540308

Epoch: 6| Step: 7
Training loss: 4.3502116272409355
Validation loss: 4.340579535688593

Epoch: 6| Step: 8
Training loss: 3.817327850797098
Validation loss: 4.330718057440226

Epoch: 6| Step: 9
Training loss: 3.796649439512784
Validation loss: 4.3152462307528925

Epoch: 6| Step: 10
Training loss: 4.499331106699622
Validation loss: 4.295224745915535

Epoch: 6| Step: 11
Training loss: 4.763952943737635
Validation loss: 4.285425803441243

Epoch: 6| Step: 12
Training loss: 4.027645421685263
Validation loss: 4.276666180027142

Epoch: 6| Step: 13
Training loss: 4.800629479140844
Validation loss: 4.266408963714291

Epoch: 5| Step: 0
Training loss: 4.926743004344694
Validation loss: 4.255399055387443

Epoch: 6| Step: 1
Training loss: 4.571403281959337
Validation loss: 4.242397347501378

Epoch: 6| Step: 2
Training loss: 4.210141589758063
Validation loss: 4.23190076826988

Epoch: 6| Step: 3
Training loss: 4.842000140701034
Validation loss: 4.21876116059535

Epoch: 6| Step: 4
Training loss: 4.809607491131683
Validation loss: 4.207509880844704

Epoch: 6| Step: 5
Training loss: 3.696160959016928
Validation loss: 4.1963493132472465

Epoch: 6| Step: 6
Training loss: 3.5378566818234805
Validation loss: 4.189367235231071

Epoch: 6| Step: 7
Training loss: 4.402442748235264
Validation loss: 4.177966894105258

Epoch: 6| Step: 8
Training loss: 3.554365541738339
Validation loss: 4.16504742486736

Epoch: 6| Step: 9
Training loss: 4.195048119652061
Validation loss: 4.1553330367153976

Epoch: 6| Step: 10
Training loss: 4.10464820683277
Validation loss: 4.148039073306803

Epoch: 6| Step: 11
Training loss: 5.024781042993744
Validation loss: 4.139310225995438

Epoch: 6| Step: 12
Training loss: 4.015083959326312
Validation loss: 4.127953899588933

Epoch: 6| Step: 13
Training loss: 4.236933874612267
Validation loss: 4.118641939855244

Epoch: 6| Step: 0
Training loss: 4.345343208410235
Validation loss: 4.112633181333992

Epoch: 6| Step: 1
Training loss: 4.091862600158297
Validation loss: 4.106031153100405

Epoch: 6| Step: 2
Training loss: 5.455992373821936
Validation loss: 4.096296074607771

Epoch: 6| Step: 3
Training loss: 3.5433222921300516
Validation loss: 4.087451125923349

Epoch: 6| Step: 4
Training loss: 4.342915406768439
Validation loss: 4.077426899525522

Epoch: 6| Step: 5
Training loss: 3.8684930620549123
Validation loss: 4.065856135437574

Epoch: 6| Step: 6
Training loss: 3.986688876988559
Validation loss: 4.058324934252547

Epoch: 6| Step: 7
Training loss: 3.9081967805108424
Validation loss: 4.050537722272807

Epoch: 6| Step: 8
Training loss: 4.177773181651228
Validation loss: 4.038349610035597

Epoch: 6| Step: 9
Training loss: 3.3487969928675096
Validation loss: 4.0276086871946175

Epoch: 6| Step: 10
Training loss: 4.2508429644969805
Validation loss: 4.020043377704235

Epoch: 6| Step: 11
Training loss: 4.238749029125124
Validation loss: 4.012041400080627

Epoch: 6| Step: 12
Training loss: 4.298554359325717
Validation loss: 4.0024648142765935

Epoch: 6| Step: 13
Training loss: 4.936281077909457
Validation loss: 3.9947109492079793

Epoch: 7| Step: 0
Training loss: 2.280983478183606
Validation loss: 3.9846465334939354

Epoch: 6| Step: 1
Training loss: 3.855250080868316
Validation loss: 3.9775160798063176

Epoch: 6| Step: 2
Training loss: 4.033675063187522
Validation loss: 3.969917462194219

Epoch: 6| Step: 3
Training loss: 4.907296038842755
Validation loss: 3.9625373540186244

Epoch: 6| Step: 4
Training loss: 4.019076871259708
Validation loss: 3.9534679249348263

Epoch: 6| Step: 5
Training loss: 3.2521727708292563
Validation loss: 3.946477057990236

Epoch: 6| Step: 6
Training loss: 3.8552213858083104
Validation loss: 3.942306960866801

Epoch: 6| Step: 7
Training loss: 4.1629153849139335
Validation loss: 3.9346954337455324

Epoch: 6| Step: 8
Training loss: 4.653961643403552
Validation loss: 3.9247426013609052

Epoch: 6| Step: 9
Training loss: 3.9971615734069217
Validation loss: 3.9120101376723064

Epoch: 6| Step: 10
Training loss: 4.043482474155023
Validation loss: 3.9178331654473193

Epoch: 6| Step: 11
Training loss: 3.8033572775655125
Validation loss: 3.902952106945821

Epoch: 6| Step: 12
Training loss: 5.3265007877103985
Validation loss: 3.8913792594267482

Epoch: 6| Step: 13
Training loss: 4.462710053444898
Validation loss: 3.8871567167979775

Epoch: 8| Step: 0
Training loss: 4.959053222370646
Validation loss: 3.8844780680508406

Epoch: 6| Step: 1
Training loss: 4.559631281886487
Validation loss: 3.8735845073072674

Epoch: 6| Step: 2
Training loss: 3.4789837238997925
Validation loss: 3.8631579673295264

Epoch: 6| Step: 3
Training loss: 4.07851410978925
Validation loss: 3.85686243571954

Epoch: 6| Step: 4
Training loss: 2.890665414888503
Validation loss: 3.847015146551737

Epoch: 6| Step: 5
Training loss: 3.8494840201876
Validation loss: 3.8418135548569268

Epoch: 6| Step: 6
Training loss: 4.042630005434561
Validation loss: 3.836214205317542

Epoch: 6| Step: 7
Training loss: 3.903189230543863
Validation loss: 3.82621313507516

Epoch: 6| Step: 8
Training loss: 3.4897384077697122
Validation loss: 3.8154654183755587

Epoch: 6| Step: 9
Training loss: 4.357868330725408
Validation loss: 3.8108807034371988

Epoch: 6| Step: 10
Training loss: 4.189955489620968
Validation loss: 3.810284063879367

Epoch: 6| Step: 11
Training loss: 4.225035104097879
Validation loss: 3.7994013003537654

Epoch: 6| Step: 12
Training loss: 3.808972712516437
Validation loss: 3.7940803417121036

Epoch: 6| Step: 13
Training loss: 3.6587779117480084
Validation loss: 3.786460234051992

Epoch: 9| Step: 0
Training loss: 4.2189934554319395
Validation loss: 3.7812978615541577

Epoch: 6| Step: 1
Training loss: 3.862024054477559
Validation loss: 3.773797329243351

Epoch: 6| Step: 2
Training loss: 3.343023203357044
Validation loss: 3.7679677429325102

Epoch: 6| Step: 3
Training loss: 3.683769407968749
Validation loss: 3.763408526151313

Epoch: 6| Step: 4
Training loss: 3.9540731024383287
Validation loss: 3.756333955734899

Epoch: 6| Step: 5
Training loss: 4.263452444751463
Validation loss: 3.7486432044469873

Epoch: 6| Step: 6
Training loss: 3.8098215168475247
Validation loss: 3.745713404343326

Epoch: 6| Step: 7
Training loss: 4.500997009032264
Validation loss: 3.7406057869885725

Epoch: 6| Step: 8
Training loss: 3.2332049478689586
Validation loss: 3.7354729922194636

Epoch: 6| Step: 9
Training loss: 4.148294047660963
Validation loss: 3.7297632814078923

Epoch: 6| Step: 10
Training loss: 3.5130220398595653
Validation loss: 3.729193327059063

Epoch: 6| Step: 11
Training loss: 3.919546340265512
Validation loss: 3.7160598622257255

Epoch: 6| Step: 12
Training loss: 4.05641399222495
Validation loss: 3.7119596024280357

Epoch: 6| Step: 13
Training loss: 4.435678672428176
Validation loss: 3.708793162731184

Epoch: 10| Step: 0
Training loss: 3.1219189523346516
Validation loss: 3.703131819061471

Epoch: 6| Step: 1
Training loss: 3.9953256952204375
Validation loss: 3.6976932017313127

Epoch: 6| Step: 2
Training loss: 4.2852267987156365
Validation loss: 3.690737006228297

Epoch: 6| Step: 3
Training loss: 4.04437626465654
Validation loss: 3.6874228014546513

Epoch: 6| Step: 4
Training loss: 3.9579504664455345
Validation loss: 3.6942606624865295

Epoch: 6| Step: 5
Training loss: 4.538126391006212
Validation loss: 3.678647215123689

Epoch: 6| Step: 6
Training loss: 3.980005119358777
Validation loss: 3.679448114233833

Epoch: 6| Step: 7
Training loss: 4.050892371306136
Validation loss: 3.6789774447706813

Epoch: 6| Step: 8
Training loss: 3.453713759550747
Validation loss: 3.6758388219107108

Epoch: 6| Step: 9
Training loss: 3.8694594365985973
Validation loss: 3.6659014403013686

Epoch: 6| Step: 10
Training loss: 4.059556099814247
Validation loss: 3.658238066337938

Epoch: 6| Step: 11
Training loss: 2.9577969525992103
Validation loss: 3.6548012120018223

Epoch: 6| Step: 12
Training loss: 3.8443908157234166
Validation loss: 3.6548413779027578

Epoch: 6| Step: 13
Training loss: 3.5720213425394896
Validation loss: 3.661518646351698

Epoch: 11| Step: 0
Training loss: 3.2387926091373065
Validation loss: 3.6371253040481606

Epoch: 6| Step: 1
Training loss: 3.6132820418073455
Validation loss: 3.6344282068340417

Epoch: 6| Step: 2
Training loss: 4.336572878911001
Validation loss: 3.638405061910395

Epoch: 6| Step: 3
Training loss: 4.658506115670165
Validation loss: 3.6361883921430627

Epoch: 6| Step: 4
Training loss: 3.8062046793727866
Validation loss: 3.6326449511391683

Epoch: 6| Step: 5
Training loss: 3.3422779871750175
Validation loss: 3.6275224562142436

Epoch: 6| Step: 6
Training loss: 4.814746877131209
Validation loss: 3.6190935374248316

Epoch: 6| Step: 7
Training loss: 3.3091854570697947
Validation loss: 3.620352759452466

Epoch: 6| Step: 8
Training loss: 3.6351854019422642
Validation loss: 3.61942508966325

Epoch: 6| Step: 9
Training loss: 3.487843792558529
Validation loss: 3.6062742993285823

Epoch: 6| Step: 10
Training loss: 2.7375972399576742
Validation loss: 3.6061368331801393

Epoch: 6| Step: 11
Training loss: 3.7117787903281734
Validation loss: 3.608181862810095

Epoch: 6| Step: 12
Training loss: 3.7311686393519126
Validation loss: 3.609248515257073

Epoch: 6| Step: 13
Training loss: 4.899954480329563
Validation loss: 3.606221105662019

Epoch: 12| Step: 0
Training loss: 4.106267297902826
Validation loss: 3.5964798512798106

Epoch: 6| Step: 1
Training loss: 3.651073867430925
Validation loss: 3.588287680769948

Epoch: 6| Step: 2
Training loss: 3.4163292663958935
Validation loss: 3.5836430897703626

Epoch: 6| Step: 3
Training loss: 3.816910240918883
Validation loss: 3.5757509917851436

Epoch: 6| Step: 4
Training loss: 3.4709276117081114
Validation loss: 3.572618087729382

Epoch: 6| Step: 5
Training loss: 3.831491788170104
Validation loss: 3.569079003669774

Epoch: 6| Step: 6
Training loss: 3.9393594377958667
Validation loss: 3.568116638565687

Epoch: 6| Step: 7
Training loss: 3.986823552552153
Validation loss: 3.562100107186229

Epoch: 6| Step: 8
Training loss: 3.4713251675965844
Validation loss: 3.5581854610827763

Epoch: 6| Step: 9
Training loss: 3.8450715809125464
Validation loss: 3.5587724384813715

Epoch: 6| Step: 10
Training loss: 3.9408118231682363
Validation loss: 3.554748289428463

Epoch: 6| Step: 11
Training loss: 3.774360370130717
Validation loss: 3.548132497103368

Epoch: 6| Step: 12
Training loss: 3.6257101218429306
Validation loss: 3.5449561336385935

Epoch: 6| Step: 13
Training loss: 3.9655276455664086
Validation loss: 3.541361543853665

Epoch: 13| Step: 0
Training loss: 2.962098067819313
Validation loss: 3.5412481235603583

Epoch: 6| Step: 1
Training loss: 3.998003222847308
Validation loss: 3.5375284754213867

Epoch: 6| Step: 2
Training loss: 3.9861954662747188
Validation loss: 3.5330073537304907

Epoch: 6| Step: 3
Training loss: 4.040023364764342
Validation loss: 3.531439034624576

Epoch: 6| Step: 4
Training loss: 3.5915969369821075
Validation loss: 3.529858591556193

Epoch: 6| Step: 5
Training loss: 3.7982428955541967
Validation loss: 3.5299513165045298

Epoch: 6| Step: 6
Training loss: 3.7861698395790677
Validation loss: 3.5275550071946316

Epoch: 6| Step: 7
Training loss: 3.719239146655817
Validation loss: 3.524886514522279

Epoch: 6| Step: 8
Training loss: 3.6328495146803808
Validation loss: 3.517733091040918

Epoch: 6| Step: 9
Training loss: 3.769831923120268
Validation loss: 3.515207588090795

Epoch: 6| Step: 10
Training loss: 4.636664039141205
Validation loss: 3.5118794247111205

Epoch: 6| Step: 11
Training loss: 3.941582758025854
Validation loss: 3.5076043995654405

Epoch: 6| Step: 12
Training loss: 3.00234671043391
Validation loss: 3.506737273364888

Epoch: 6| Step: 13
Training loss: 2.4096882024068185
Validation loss: 3.5034746305767186

Epoch: 14| Step: 0
Training loss: 3.2338315350516833
Validation loss: 3.500996207635229

Epoch: 6| Step: 1
Training loss: 4.277779836502791
Validation loss: 3.498169711944471

Epoch: 6| Step: 2
Training loss: 4.612290730678386
Validation loss: 3.4957541174239712

Epoch: 6| Step: 3
Training loss: 2.9546422542373727
Validation loss: 3.4940662420023085

Epoch: 6| Step: 4
Training loss: 3.0165634671538384
Validation loss: 3.4942958982568233

Epoch: 6| Step: 5
Training loss: 3.380293474266394
Validation loss: 3.4934595923968175

Epoch: 6| Step: 6
Training loss: 4.35474699737342
Validation loss: 3.5032179230409977

Epoch: 6| Step: 7
Training loss: 3.5410180488994736
Validation loss: 3.4877668128935384

Epoch: 6| Step: 8
Training loss: 3.8528195200514332
Validation loss: 3.4967028209852398

Epoch: 6| Step: 9
Training loss: 3.268108682830632
Validation loss: 3.5095201098824154

Epoch: 6| Step: 10
Training loss: 3.1750864392626466
Validation loss: 3.5085949912407095

Epoch: 6| Step: 11
Training loss: 3.923011888566237
Validation loss: 3.5069853605465564

Epoch: 6| Step: 12
Training loss: 3.7083496064818435
Validation loss: 3.4901048035861955

Epoch: 6| Step: 13
Training loss: 4.491086184632605
Validation loss: 3.4825743596176704

Epoch: 15| Step: 0
Training loss: 3.5048289365286593
Validation loss: 3.478999536125462

Epoch: 6| Step: 1
Training loss: 3.721247243268341
Validation loss: 3.475886444655197

Epoch: 6| Step: 2
Training loss: 3.6051765893866587
Validation loss: 3.4778353702309404

Epoch: 6| Step: 3
Training loss: 3.0225809939302146
Validation loss: 3.4779699024767528

Epoch: 6| Step: 4
Training loss: 3.9249324962861247
Validation loss: 3.4804925149078385

Epoch: 6| Step: 5
Training loss: 4.515065511606302
Validation loss: 3.474888034485465

Epoch: 6| Step: 6
Training loss: 3.588368242315169
Validation loss: 3.4665649917007624

Epoch: 6| Step: 7
Training loss: 4.107052222726791
Validation loss: 3.4630462615396316

Epoch: 6| Step: 8
Training loss: 3.475144549320485
Validation loss: 3.4602002099935687

Epoch: 6| Step: 9
Training loss: 4.492115318713568
Validation loss: 3.4579470987478436

Epoch: 6| Step: 10
Training loss: 3.4716347735755027
Validation loss: 3.454385131350146

Epoch: 6| Step: 11
Training loss: 3.092282496260995
Validation loss: 3.4530573700801583

Epoch: 6| Step: 12
Training loss: 3.268274282116189
Validation loss: 3.4508778094842425

Epoch: 6| Step: 13
Training loss: 3.2485211749215326
Validation loss: 3.450215211112114

Epoch: 16| Step: 0
Training loss: 4.09377702310976
Validation loss: 3.4470919073806416

Epoch: 6| Step: 1
Training loss: 3.1972374375952812
Validation loss: 3.443446110173421

Epoch: 6| Step: 2
Training loss: 3.2531247889274066
Validation loss: 3.4408258333206074

Epoch: 6| Step: 3
Training loss: 3.6487724591537902
Validation loss: 3.439353581839629

Epoch: 6| Step: 4
Training loss: 3.972812525733378
Validation loss: 3.4370700645624512

Epoch: 6| Step: 5
Training loss: 3.197880764406612
Validation loss: 3.4343189052074283

Epoch: 6| Step: 6
Training loss: 3.995207776907737
Validation loss: 3.4312401776018437

Epoch: 6| Step: 7
Training loss: 3.517551284340268
Validation loss: 3.428901278954566

Epoch: 6| Step: 8
Training loss: 2.95943620209616
Validation loss: 3.426159394010887

Epoch: 6| Step: 9
Training loss: 3.5741668530641486
Validation loss: 3.426437830801608

Epoch: 6| Step: 10
Training loss: 4.280764809841547
Validation loss: 3.425068996612625

Epoch: 6| Step: 11
Training loss: 3.694247263631474
Validation loss: 3.4216261079393537

Epoch: 6| Step: 12
Training loss: 3.6667977800913714
Validation loss: 3.4210233866206443

Epoch: 6| Step: 13
Training loss: 4.0553022738117095
Validation loss: 3.4194150600810924

Epoch: 17| Step: 0
Training loss: 3.420855505279416
Validation loss: 3.418872624341813

Epoch: 6| Step: 1
Training loss: 3.3575914483245732
Validation loss: 3.4178025158188405

Epoch: 6| Step: 2
Training loss: 3.8400471537396954
Validation loss: 3.4171377758111827

Epoch: 6| Step: 3
Training loss: 3.6399863014382627
Validation loss: 3.415435368558812

Epoch: 6| Step: 4
Training loss: 4.002350116808815
Validation loss: 3.4124044013768464

Epoch: 6| Step: 5
Training loss: 2.6045325568967845
Validation loss: 3.412191205028704

Epoch: 6| Step: 6
Training loss: 3.3012281848861225
Validation loss: 3.410291766719414

Epoch: 6| Step: 7
Training loss: 3.2997756419352777
Validation loss: 3.4096878102707366

Epoch: 6| Step: 8
Training loss: 4.210881107214579
Validation loss: 3.408320115221716

Epoch: 6| Step: 9
Training loss: 2.4263332555873665
Validation loss: 3.407044312729113

Epoch: 6| Step: 10
Training loss: 4.537410783547412
Validation loss: 3.405182069586508

Epoch: 6| Step: 11
Training loss: 4.217774907204826
Validation loss: 3.403111656092971

Epoch: 6| Step: 12
Training loss: 3.846483452685352
Validation loss: 3.4022479729686057

Epoch: 6| Step: 13
Training loss: 3.5611328714161816
Validation loss: 3.4016800557536278

Epoch: 18| Step: 0
Training loss: 3.398689909583024
Validation loss: 3.3994016115941594

Epoch: 6| Step: 1
Training loss: 3.263524306115468
Validation loss: 3.398444643768659

Epoch: 6| Step: 2
Training loss: 2.37396659453493
Validation loss: 3.398055407947167

Epoch: 6| Step: 3
Training loss: 3.2501693094608366
Validation loss: 3.3977903254113526

Epoch: 6| Step: 4
Training loss: 4.013372004461012
Validation loss: 3.3972316897421417

Epoch: 6| Step: 5
Training loss: 3.17089076815172
Validation loss: 3.3954226327704924

Epoch: 6| Step: 6
Training loss: 3.721439190643615
Validation loss: 3.3945840278524417

Epoch: 6| Step: 7
Training loss: 4.0334826060854345
Validation loss: 3.3938834181574244

Epoch: 6| Step: 8
Training loss: 3.0476569321667557
Validation loss: 3.3924766079167843

Epoch: 6| Step: 9
Training loss: 4.474198867436615
Validation loss: 3.391095531741449

Epoch: 6| Step: 10
Training loss: 3.519402538659932
Validation loss: 3.3885056834155103

Epoch: 6| Step: 11
Training loss: 5.017772179307528
Validation loss: 3.3875269827570085

Epoch: 6| Step: 12
Training loss: 3.964851206504688
Validation loss: 3.3863832447822935

Epoch: 6| Step: 13
Training loss: 1.2091263547487694
Validation loss: 3.3843093027754922

Epoch: 19| Step: 0
Training loss: 3.719758866606248
Validation loss: 3.3827439114854823

Epoch: 6| Step: 1
Training loss: 3.962052107567008
Validation loss: 3.3814045121725385

Epoch: 6| Step: 2
Training loss: 3.758292121971397
Validation loss: 3.3803935735012227

Epoch: 6| Step: 3
Training loss: 3.7735124347583486
Validation loss: 3.377183588363796

Epoch: 6| Step: 4
Training loss: 3.981483517300449
Validation loss: 3.375879881728848

Epoch: 6| Step: 5
Training loss: 2.6009488685155038
Validation loss: 3.373863546163173

Epoch: 6| Step: 6
Training loss: 4.0432503864767195
Validation loss: 3.371801850444858

Epoch: 6| Step: 7
Training loss: 3.3338015863227035
Validation loss: 3.3699608985188214

Epoch: 6| Step: 8
Training loss: 3.8156736328624823
Validation loss: 3.3678246687948867

Epoch: 6| Step: 9
Training loss: 3.4891964522400025
Validation loss: 3.3684272022896518

Epoch: 6| Step: 10
Training loss: 3.714328220669166
Validation loss: 3.3651823420308546

Epoch: 6| Step: 11
Training loss: 3.1646263844565037
Validation loss: 3.3627907011255247

Epoch: 6| Step: 12
Training loss: 3.858920545500938
Validation loss: 3.360172147579468

Epoch: 6| Step: 13
Training loss: 2.306659643496955
Validation loss: 3.3591706992448396

Epoch: 20| Step: 0
Training loss: 4.061950646450449
Validation loss: 3.357164386387621

Epoch: 6| Step: 1
Training loss: 4.661006060206973
Validation loss: 3.3565856021517635

Epoch: 6| Step: 2
Training loss: 3.7757810024748393
Validation loss: 3.3541127310556247

Epoch: 6| Step: 3
Training loss: 3.4370019725342176
Validation loss: 3.3547505185408735

Epoch: 6| Step: 4
Training loss: 3.581232179394334
Validation loss: 3.3545601966217333

Epoch: 6| Step: 5
Training loss: 3.230561297750431
Validation loss: 3.352443322410276

Epoch: 6| Step: 6
Training loss: 3.9235205370746042
Validation loss: 3.356196452317248

Epoch: 6| Step: 7
Training loss: 3.4673978902445652
Validation loss: 3.3538220462357007

Epoch: 6| Step: 8
Training loss: 3.096802255832774
Validation loss: 3.355601576593862

Epoch: 6| Step: 9
Training loss: 2.578788348313593
Validation loss: 3.354658135282552

Epoch: 6| Step: 10
Training loss: 3.5311056462042822
Validation loss: 3.354654884360369

Epoch: 6| Step: 11
Training loss: 3.2661801099106547
Validation loss: 3.3518515650388387

Epoch: 6| Step: 12
Training loss: 3.898538653145037
Validation loss: 3.3504119067596436

Epoch: 6| Step: 13
Training loss: 3.0568902154488047
Validation loss: 3.346109664192784

Epoch: 21| Step: 0
Training loss: 3.6817981150002157
Validation loss: 3.344203279976569

Epoch: 6| Step: 1
Training loss: 3.50518251648569
Validation loss: 3.341914322738145

Epoch: 6| Step: 2
Training loss: 4.058777262528863
Validation loss: 3.342172440104974

Epoch: 6| Step: 3
Training loss: 2.5945325842822053
Validation loss: 3.340776108706218

Epoch: 6| Step: 4
Training loss: 3.493874229993084
Validation loss: 3.3413044179540545

Epoch: 6| Step: 5
Training loss: 3.7431146353213305
Validation loss: 3.3385701287315874

Epoch: 6| Step: 6
Training loss: 3.1364745998731465
Validation loss: 3.335938216234287

Epoch: 6| Step: 7
Training loss: 3.1228157039012445
Validation loss: 3.3337749470667606

Epoch: 6| Step: 8
Training loss: 3.976698597675636
Validation loss: 3.3330736110367627

Epoch: 6| Step: 9
Training loss: 4.282026011730513
Validation loss: 3.3310940270765657

Epoch: 6| Step: 10
Training loss: 2.982170529069913
Validation loss: 3.329869912643617

Epoch: 6| Step: 11
Training loss: 3.239732221675746
Validation loss: 3.3287809346517547

Epoch: 6| Step: 12
Training loss: 3.8852798942376574
Validation loss: 3.3278440551094364

Epoch: 6| Step: 13
Training loss: 4.181711779812644
Validation loss: 3.326980323873303

Epoch: 22| Step: 0
Training loss: 3.497123217189182
Validation loss: 3.32639425228481

Epoch: 6| Step: 1
Training loss: 4.061571924865358
Validation loss: 3.3254088301033153

Epoch: 6| Step: 2
Training loss: 3.626606815302405
Validation loss: 3.3240740032284077

Epoch: 6| Step: 3
Training loss: 3.2837851766931894
Validation loss: 3.3231058873394725

Epoch: 6| Step: 4
Training loss: 3.3612966319885804
Validation loss: 3.3209070426917044

Epoch: 6| Step: 5
Training loss: 4.2082787437801175
Validation loss: 3.320660789024524

Epoch: 6| Step: 6
Training loss: 3.463290067248885
Validation loss: 3.319461485967629

Epoch: 6| Step: 7
Training loss: 3.4386855421885616
Validation loss: 3.3176202375833608

Epoch: 6| Step: 8
Training loss: 3.8641819227053342
Validation loss: 3.3170617258532813

Epoch: 6| Step: 9
Training loss: 3.396681198024145
Validation loss: 3.316780489255028

Epoch: 6| Step: 10
Training loss: 3.5628431723761382
Validation loss: 3.315259666589356

Epoch: 6| Step: 11
Training loss: 3.2589036317233093
Validation loss: 3.313652596499797

Epoch: 6| Step: 12
Training loss: 3.2787058821984765
Validation loss: 3.3129896149202005

Epoch: 6| Step: 13
Training loss: 3.2713752022362326
Validation loss: 3.311570612772421

Epoch: 23| Step: 0
Training loss: 2.951743796956486
Validation loss: 3.3114609608537866

Epoch: 6| Step: 1
Training loss: 2.546925269256826
Validation loss: 3.3096068415616267

Epoch: 6| Step: 2
Training loss: 4.180381531893622
Validation loss: 3.3092276379078047

Epoch: 6| Step: 3
Training loss: 3.7231996986179205
Validation loss: 3.3084629353229524

Epoch: 6| Step: 4
Training loss: 3.884444632485349
Validation loss: 3.307454247903759

Epoch: 6| Step: 5
Training loss: 2.9292795939990666
Validation loss: 3.305995626694105

Epoch: 6| Step: 6
Training loss: 4.685852168044942
Validation loss: 3.3038732826540915

Epoch: 6| Step: 7
Training loss: 3.55753891152221
Validation loss: 3.304048994973965

Epoch: 6| Step: 8
Training loss: 3.1036182576248805
Validation loss: 3.3028456051127755

Epoch: 6| Step: 9
Training loss: 2.8810085038202287
Validation loss: 3.30275665858043

Epoch: 6| Step: 10
Training loss: 3.611384241257151
Validation loss: 3.3028761481064937

Epoch: 6| Step: 11
Training loss: 3.1535726843786525
Validation loss: 3.2997069224332143

Epoch: 6| Step: 12
Training loss: 3.914071758815147
Validation loss: 3.299984213342876

Epoch: 6| Step: 13
Training loss: 4.174119438462183
Validation loss: 3.2992023619610227

Epoch: 24| Step: 0
Training loss: 3.455329985034853
Validation loss: 3.298162856819712

Epoch: 6| Step: 1
Training loss: 3.293144248548497
Validation loss: 3.2977224859744423

Epoch: 6| Step: 2
Training loss: 3.7222102119163467
Validation loss: 3.294480404828209

Epoch: 6| Step: 3
Training loss: 3.518463751903935
Validation loss: 3.2960232857924883

Epoch: 6| Step: 4
Training loss: 4.034492076117619
Validation loss: 3.2934594797193575

Epoch: 6| Step: 5
Training loss: 3.4283414036926714
Validation loss: 3.2926693582439097

Epoch: 6| Step: 6
Training loss: 3.155832244118045
Validation loss: 3.2918398463554337

Epoch: 6| Step: 7
Training loss: 3.513192517850462
Validation loss: 3.296643538525226

Epoch: 6| Step: 8
Training loss: 3.235756988869162
Validation loss: 3.3070998889658814

Epoch: 6| Step: 9
Training loss: 3.575613414716964
Validation loss: 3.2900934324048983

Epoch: 6| Step: 10
Training loss: 3.291750862557782
Validation loss: 3.2898362520852062

Epoch: 6| Step: 11
Training loss: 3.861151776606585
Validation loss: 3.287844639295049

Epoch: 6| Step: 12
Training loss: 3.6025462100091743
Validation loss: 3.2863775439388903

Epoch: 6| Step: 13
Training loss: 3.8411613369213957
Validation loss: 3.284527477695967

Epoch: 25| Step: 0
Training loss: 3.6324381317519863
Validation loss: 3.2851301964308126

Epoch: 6| Step: 1
Training loss: 3.840576102036285
Validation loss: 3.2853840573652984

Epoch: 6| Step: 2
Training loss: 3.5970507515027808
Validation loss: 3.284943895606153

Epoch: 6| Step: 3
Training loss: 2.9532903392868435
Validation loss: 3.2803469194983466

Epoch: 6| Step: 4
Training loss: 3.7773807369973667
Validation loss: 3.2803169404423005

Epoch: 6| Step: 5
Training loss: 3.3209843931856584
Validation loss: 3.2789870483232515

Epoch: 6| Step: 6
Training loss: 3.311184171927373
Validation loss: 3.2766927109412887

Epoch: 6| Step: 7
Training loss: 4.218419719059195
Validation loss: 3.2791069568100646

Epoch: 6| Step: 8
Training loss: 2.819912192553548
Validation loss: 3.2772374993740665

Epoch: 6| Step: 9
Training loss: 2.8989458075383103
Validation loss: 3.2758431980575966

Epoch: 6| Step: 10
Training loss: 3.0083131051550236
Validation loss: 3.2770716513044333

Epoch: 6| Step: 11
Training loss: 3.179220629259517
Validation loss: 3.273787995986677

Epoch: 6| Step: 12
Training loss: 4.6182767096445945
Validation loss: 3.2794303743497

Epoch: 6| Step: 13
Training loss: 3.8235945070343997
Validation loss: 3.2755463374362748

Epoch: 26| Step: 0
Training loss: 3.9301929793406325
Validation loss: 3.27109383326303

Epoch: 6| Step: 1
Training loss: 3.4531490273308587
Validation loss: 3.270274422111416

Epoch: 6| Step: 2
Training loss: 3.1749024623997433
Validation loss: 3.27142410764004

Epoch: 6| Step: 3
Training loss: 4.237276666658042
Validation loss: 3.268251931291337

Epoch: 6| Step: 4
Training loss: 3.7063710596599426
Validation loss: 3.268457750145463

Epoch: 6| Step: 5
Training loss: 3.6962235277380606
Validation loss: 3.2684130649708174

Epoch: 6| Step: 6
Training loss: 2.64177574951353
Validation loss: 3.2665487526395065

Epoch: 6| Step: 7
Training loss: 2.956562766049015
Validation loss: 3.2681308071486272

Epoch: 6| Step: 8
Training loss: 3.2202531582372846
Validation loss: 3.2692456807227206

Epoch: 6| Step: 9
Training loss: 3.3672570312118446
Validation loss: 3.269238287570415

Epoch: 6| Step: 10
Training loss: 2.426688646524397
Validation loss: 3.273836283527134

Epoch: 6| Step: 11
Training loss: 4.00521415376013
Validation loss: 3.272765395822475

Epoch: 6| Step: 12
Training loss: 4.470569800259163
Validation loss: 3.2619345316728774

Epoch: 6| Step: 13
Training loss: 3.0837740883816096
Validation loss: 3.260396069935979

Epoch: 27| Step: 0
Training loss: 3.6505732360524186
Validation loss: 3.2615383000767237

Epoch: 6| Step: 1
Training loss: 3.623211649723406
Validation loss: 3.2612713466714722

Epoch: 6| Step: 2
Training loss: 3.069655486418281
Validation loss: 3.264226019617565

Epoch: 6| Step: 3
Training loss: 3.514700941926872
Validation loss: 3.2718246950506664

Epoch: 6| Step: 4
Training loss: 3.0165381753719878
Validation loss: 3.2931026736638156

Epoch: 6| Step: 5
Training loss: 4.01758382200617
Validation loss: 3.3438261980067683

Epoch: 6| Step: 6
Training loss: 4.32771888783164
Validation loss: 3.274086253191705

Epoch: 6| Step: 7
Training loss: 2.5836559729960364
Validation loss: 3.258103466735185

Epoch: 6| Step: 8
Training loss: 3.837071392962975
Validation loss: 3.2610147297170213

Epoch: 6| Step: 9
Training loss: 3.550715715498096
Validation loss: 3.2926568634020343

Epoch: 6| Step: 10
Training loss: 3.07499248844873
Validation loss: 3.2671206955078613

Epoch: 6| Step: 11
Training loss: 4.032501263083197
Validation loss: 3.2505254738749727

Epoch: 6| Step: 12
Training loss: 2.842652496836966
Validation loss: 3.247298147772988

Epoch: 6| Step: 13
Training loss: 3.6116475138899427
Validation loss: 3.250179331574946

Epoch: 28| Step: 0
Training loss: 3.3292589718304693
Validation loss: 3.2649895360379126

Epoch: 6| Step: 1
Training loss: 3.4994883844559186
Validation loss: 3.2632090522417334

Epoch: 6| Step: 2
Training loss: 4.303803230197995
Validation loss: 3.2572214278895903

Epoch: 6| Step: 3
Training loss: 2.9917514572949675
Validation loss: 3.2767673435187272

Epoch: 6| Step: 4
Training loss: 2.835633821227773
Validation loss: 3.3324654454265596

Epoch: 6| Step: 5
Training loss: 3.5347812516921686
Validation loss: 3.414766889969305

Epoch: 6| Step: 6
Training loss: 3.1058708650330638
Validation loss: 3.3237522363235024

Epoch: 6| Step: 7
Training loss: 4.1722912527153895
Validation loss: 3.2530214827582573

Epoch: 6| Step: 8
Training loss: 3.813632734278172
Validation loss: 3.2432433374945657

Epoch: 6| Step: 9
Training loss: 2.5785951127963664
Validation loss: 3.245289914692253

Epoch: 6| Step: 10
Training loss: 3.6570071227140173
Validation loss: 3.3555228084666884

Epoch: 6| Step: 11
Training loss: 4.2370851296756085
Validation loss: 3.375935763938015

Epoch: 6| Step: 12
Training loss: 3.875440510968106
Validation loss: 3.3471176275675676

Epoch: 6| Step: 13
Training loss: 2.7230889785131707
Validation loss: 3.3365952480037673

Epoch: 29| Step: 0
Training loss: 3.760941121028715
Validation loss: 3.3184557183489933

Epoch: 6| Step: 1
Training loss: 3.108558125757957
Validation loss: 3.238653339063398

Epoch: 6| Step: 2
Training loss: 3.3437066476453663
Validation loss: 3.2843721114396947

Epoch: 6| Step: 3
Training loss: 4.06870441557726
Validation loss: 3.2368879898972964

Epoch: 6| Step: 4
Training loss: 2.8408369297919798
Validation loss: 3.2272240460287307

Epoch: 6| Step: 5
Training loss: 3.5759221254868496
Validation loss: 3.2284378584239692

Epoch: 6| Step: 6
Training loss: 2.770676132752614
Validation loss: 3.254361831299757

Epoch: 6| Step: 7
Training loss: 3.2666128024376877
Validation loss: 3.283647944500547

Epoch: 6| Step: 8
Training loss: 4.469985471014865
Validation loss: 3.3265519523319487

Epoch: 6| Step: 9
Training loss: 3.3790775674596727
Validation loss: 3.257699644149935

Epoch: 6| Step: 10
Training loss: 3.096209232584012
Validation loss: 3.2235117916530918

Epoch: 6| Step: 11
Training loss: 3.7010122461041637
Validation loss: 3.219993546225362

Epoch: 6| Step: 12
Training loss: 3.088505316397643
Validation loss: 3.2239606706438266

Epoch: 6| Step: 13
Training loss: 4.400131197620636
Validation loss: 3.230704473233903

Epoch: 30| Step: 0
Training loss: 3.742294405562945
Validation loss: 3.2419577422153654

Epoch: 6| Step: 1
Training loss: 4.253312783226506
Validation loss: 3.2335545832581944

Epoch: 6| Step: 2
Training loss: 3.9855640507094012
Validation loss: 3.223934423116885

Epoch: 6| Step: 3
Training loss: 3.3340839176703936
Validation loss: 3.2163938856708314

Epoch: 6| Step: 4
Training loss: 3.159907572879407
Validation loss: 3.212968316267013

Epoch: 6| Step: 5
Training loss: 3.947339313466686
Validation loss: 3.2118354804985825

Epoch: 6| Step: 6
Training loss: 3.551866153704011
Validation loss: 3.212077446119653

Epoch: 6| Step: 7
Training loss: 2.1367390577616994
Validation loss: 3.211216351313766

Epoch: 6| Step: 8
Training loss: 2.855744939511563
Validation loss: 3.219014521799462

Epoch: 6| Step: 9
Training loss: 3.5794411450004957
Validation loss: 3.215861302487405

Epoch: 6| Step: 10
Training loss: 3.3409631827368766
Validation loss: 3.2193096824001155

Epoch: 6| Step: 11
Training loss: 3.359813714767087
Validation loss: 3.219237285414082

Epoch: 6| Step: 12
Training loss: 3.1057153375959476
Validation loss: 3.220597767913637

Epoch: 6| Step: 13
Training loss: 3.922588268329899
Validation loss: 3.214600383248199

Epoch: 31| Step: 0
Training loss: 3.822698865848253
Validation loss: 3.212678863511669

Epoch: 6| Step: 1
Training loss: 4.076027985077118
Validation loss: 3.210821102667266

Epoch: 6| Step: 2
Training loss: 3.7473437756529364
Validation loss: 3.2035683121784695

Epoch: 6| Step: 3
Training loss: 3.1559100581746757
Validation loss: 3.2025289913938018

Epoch: 6| Step: 4
Training loss: 3.2540536689107276
Validation loss: 3.202307391120579

Epoch: 6| Step: 5
Training loss: 3.150674560011787
Validation loss: 3.2001248207154065

Epoch: 6| Step: 6
Training loss: 3.0403605927380575
Validation loss: 3.201633168192005

Epoch: 6| Step: 7
Training loss: 3.708835882073874
Validation loss: 3.1995460578914527

Epoch: 6| Step: 8
Training loss: 2.6446223053124895
Validation loss: 3.199482288063839

Epoch: 6| Step: 9
Training loss: 3.312822722063072
Validation loss: 3.198099020858363

Epoch: 6| Step: 10
Training loss: 3.4038615120711615
Validation loss: 3.1949024596747106

Epoch: 6| Step: 11
Training loss: 3.0887886107319016
Validation loss: 3.1945049999454613

Epoch: 6| Step: 12
Training loss: 3.7472478304070354
Validation loss: 3.192709795804247

Epoch: 6| Step: 13
Training loss: 4.269265434457492
Validation loss: 3.1936378891663835

Epoch: 32| Step: 0
Training loss: 3.966335493309082
Validation loss: 3.1913284129799346

Epoch: 6| Step: 1
Training loss: 3.989059506813776
Validation loss: 3.1910891030212

Epoch: 6| Step: 2
Training loss: 2.678336022341442
Validation loss: 3.1887474217001266

Epoch: 6| Step: 3
Training loss: 3.585306481916839
Validation loss: 3.1904897017957787

Epoch: 6| Step: 4
Training loss: 3.504824174723682
Validation loss: 3.194294611903667

Epoch: 6| Step: 5
Training loss: 3.180638876262731
Validation loss: 3.1900693128170614

Epoch: 6| Step: 6
Training loss: 3.1543420747051787
Validation loss: 3.189913256593475

Epoch: 6| Step: 7
Training loss: 3.5295297939536154
Validation loss: 3.1877536065562393

Epoch: 6| Step: 8
Training loss: 3.582806452377146
Validation loss: 3.187067630275952

Epoch: 6| Step: 9
Training loss: 4.287585394984817
Validation loss: 3.183114171377447

Epoch: 6| Step: 10
Training loss: 3.132761662325203
Validation loss: 3.1839787776640867

Epoch: 6| Step: 11
Training loss: 3.20604070683062
Validation loss: 3.181191716997078

Epoch: 6| Step: 12
Training loss: 2.8949651354335817
Validation loss: 3.1819455601525894

Epoch: 6| Step: 13
Training loss: 2.8927304410015244
Validation loss: 3.1799446577030452

Epoch: 33| Step: 0
Training loss: 2.858308520269619
Validation loss: 3.1807717771953747

Epoch: 6| Step: 1
Training loss: 3.105861499830269
Validation loss: 3.1795673398551996

Epoch: 6| Step: 2
Training loss: 3.3321898088372968
Validation loss: 3.1813859380557816

Epoch: 6| Step: 3
Training loss: 3.2768417537733585
Validation loss: 3.179386679087583

Epoch: 6| Step: 4
Training loss: 3.9277655753438183
Validation loss: 3.178937584248367

Epoch: 6| Step: 5
Training loss: 3.9472546320124633
Validation loss: 3.1809940919460535

Epoch: 6| Step: 6
Training loss: 3.4579936094296713
Validation loss: 3.1780980440307154

Epoch: 6| Step: 7
Training loss: 3.879505983147701
Validation loss: 3.177407924156185

Epoch: 6| Step: 8
Training loss: 3.395003484575284
Validation loss: 3.176291757325686

Epoch: 6| Step: 9
Training loss: 3.9634871543848393
Validation loss: 3.174734492751425

Epoch: 6| Step: 10
Training loss: 3.171448025834005
Validation loss: 3.174791144155863

Epoch: 6| Step: 11
Training loss: 2.600407707819527
Validation loss: 3.1747417684387966

Epoch: 6| Step: 12
Training loss: 3.44597053731322
Validation loss: 3.1737633125748985

Epoch: 6| Step: 13
Training loss: 3.3599234199879606
Validation loss: 3.1733483404933724

Epoch: 34| Step: 0
Training loss: 3.629958608932542
Validation loss: 3.1754785864801303

Epoch: 6| Step: 1
Training loss: 3.1399406332733357
Validation loss: 3.1835562855720347

Epoch: 6| Step: 2
Training loss: 3.7932614057411276
Validation loss: 3.201861354222826

Epoch: 6| Step: 3
Training loss: 3.0698394022633297
Validation loss: 3.194448205399644

Epoch: 6| Step: 4
Training loss: 2.4344028456617077
Validation loss: 3.1695066604211033

Epoch: 6| Step: 5
Training loss: 3.9611250552704353
Validation loss: 3.1704319447057427

Epoch: 6| Step: 6
Training loss: 3.296902769432813
Validation loss: 3.1711134045506437

Epoch: 6| Step: 7
Training loss: 2.896902824523364
Validation loss: 3.1694845578367663

Epoch: 6| Step: 8
Training loss: 3.022371799220706
Validation loss: 3.1725811271580158

Epoch: 6| Step: 9
Training loss: 3.655539158246781
Validation loss: 3.1738475309903516

Epoch: 6| Step: 10
Training loss: 3.1920780889476905
Validation loss: 3.174103132148293

Epoch: 6| Step: 11
Training loss: 3.213311795628126
Validation loss: 3.17457768754255

Epoch: 6| Step: 12
Training loss: 4.180970752554462
Validation loss: 3.181492011880032

Epoch: 6| Step: 13
Training loss: 4.431965344882257
Validation loss: 3.1700886973685924

Epoch: 35| Step: 0
Training loss: 3.2488166415346527
Validation loss: 3.1634473503733127

Epoch: 6| Step: 1
Training loss: 3.314314147517193
Validation loss: 3.1618143525096225

Epoch: 6| Step: 2
Training loss: 3.7397724553618636
Validation loss: 3.1608606299804625

Epoch: 6| Step: 3
Training loss: 3.4587491869330957
Validation loss: 3.159920678631392

Epoch: 6| Step: 4
Training loss: 3.165105803108807
Validation loss: 3.159333201323255

Epoch: 6| Step: 5
Training loss: 2.694100635481225
Validation loss: 3.1598933701874645

Epoch: 6| Step: 6
Training loss: 4.293879460100283
Validation loss: 3.167984298660412

Epoch: 6| Step: 7
Training loss: 2.93869627273494
Validation loss: 3.188135154991594

Epoch: 6| Step: 8
Training loss: 4.546376204250609
Validation loss: 3.1625729726031064

Epoch: 6| Step: 9
Training loss: 3.4180235765692006
Validation loss: 3.1530201591544884

Epoch: 6| Step: 10
Training loss: 3.1538605662834267
Validation loss: 3.1539780432036286

Epoch: 6| Step: 11
Training loss: 3.3288848439378644
Validation loss: 3.152724810604942

Epoch: 6| Step: 12
Training loss: 2.757675383619932
Validation loss: 3.150976980561192

Epoch: 6| Step: 13
Training loss: 3.2385115409293235
Validation loss: 3.1500100291415256

Epoch: 36| Step: 0
Training loss: 2.9859209300748706
Validation loss: 3.149116408920219

Epoch: 6| Step: 1
Training loss: 3.2208559128404515
Validation loss: 3.148859066919447

Epoch: 6| Step: 2
Training loss: 3.8059823028185082
Validation loss: 3.150259328058327

Epoch: 6| Step: 3
Training loss: 3.6601867348817194
Validation loss: 3.1490678094466715

Epoch: 6| Step: 4
Training loss: 2.4403097146880914
Validation loss: 3.149641877329485

Epoch: 6| Step: 5
Training loss: 3.4794893096132498
Validation loss: 3.1499998950453643

Epoch: 6| Step: 6
Training loss: 3.259571359924408
Validation loss: 3.148007000012204

Epoch: 6| Step: 7
Training loss: 3.2471184794359798
Validation loss: 3.148229208339026

Epoch: 6| Step: 8
Training loss: 3.317208452558357
Validation loss: 3.1467471301476904

Epoch: 6| Step: 9
Training loss: 3.3073343269220032
Validation loss: 3.1445464906123815

Epoch: 6| Step: 10
Training loss: 4.002019372469002
Validation loss: 3.143407062982972

Epoch: 6| Step: 11
Training loss: 3.5599021139510403
Validation loss: 3.146473049766909

Epoch: 6| Step: 12
Training loss: 3.304719532479949
Validation loss: 3.1445315940437393

Epoch: 6| Step: 13
Training loss: 4.033721639263365
Validation loss: 3.1480316753089297

Epoch: 37| Step: 0
Training loss: 3.0369346249464657
Validation loss: 3.144491902398634

Epoch: 6| Step: 1
Training loss: 3.5767505121372696
Validation loss: 3.14416732358567

Epoch: 6| Step: 2
Training loss: 3.4691924766614655
Validation loss: 3.1424435304553584

Epoch: 6| Step: 3
Training loss: 2.619877676692658
Validation loss: 3.14303216305709

Epoch: 6| Step: 4
Training loss: 3.625433271099917
Validation loss: 3.1381050260259085

Epoch: 6| Step: 5
Training loss: 3.0582069356994235
Validation loss: 3.1353763529626133

Epoch: 6| Step: 6
Training loss: 2.7777266741396294
Validation loss: 3.1332904437901448

Epoch: 6| Step: 7
Training loss: 3.6017452036426576
Validation loss: 3.133709278955435

Epoch: 6| Step: 8
Training loss: 4.104735798110524
Validation loss: 3.1334673422400314

Epoch: 6| Step: 9
Training loss: 3.618558487905855
Validation loss: 3.132957147673329

Epoch: 6| Step: 10
Training loss: 3.808907989840821
Validation loss: 3.1322731779475323

Epoch: 6| Step: 11
Training loss: 2.65498429604464
Validation loss: 3.131409192154258

Epoch: 6| Step: 12
Training loss: 3.8603427924498788
Validation loss: 3.1303193446313076

Epoch: 6| Step: 13
Training loss: 3.2138602141655586
Validation loss: 3.1292340379858277

Epoch: 38| Step: 0
Training loss: 3.0211052783147316
Validation loss: 3.128489597280153

Epoch: 6| Step: 1
Training loss: 4.3642926661801935
Validation loss: 3.127292440299789

Epoch: 6| Step: 2
Training loss: 3.1920399964582615
Validation loss: 3.1249542799035455

Epoch: 6| Step: 3
Training loss: 3.0674718863917416
Validation loss: 3.123967989257956

Epoch: 6| Step: 4
Training loss: 3.3710600850180286
Validation loss: 3.123591100102468

Epoch: 6| Step: 5
Training loss: 3.796158962470772
Validation loss: 3.135101505839656

Epoch: 6| Step: 6
Training loss: 3.7663921666905726
Validation loss: 3.1214676259495153

Epoch: 6| Step: 7
Training loss: 3.2629449241355415
Validation loss: 3.1197377713703998

Epoch: 6| Step: 8
Training loss: 3.28471264469255
Validation loss: 3.1185367516008347

Epoch: 6| Step: 9
Training loss: 3.0150171171243345
Validation loss: 3.1176402905033003

Epoch: 6| Step: 10
Training loss: 2.889530448915526
Validation loss: 3.118273668120941

Epoch: 6| Step: 11
Training loss: 3.0899187505712566
Validation loss: 3.1178725705433536

Epoch: 6| Step: 12
Training loss: 3.2380269391339427
Validation loss: 3.118867268429993

Epoch: 6| Step: 13
Training loss: 3.8647728365408445
Validation loss: 3.119269193117935

Epoch: 39| Step: 0
Training loss: 3.211445937543652
Validation loss: 3.118701821218795

Epoch: 6| Step: 1
Training loss: 3.5383631539462
Validation loss: 3.117879682503155

Epoch: 6| Step: 2
Training loss: 2.645160639595474
Validation loss: 3.117871450651795

Epoch: 6| Step: 3
Training loss: 4.082979199889281
Validation loss: 3.1160390916165897

Epoch: 6| Step: 4
Training loss: 3.3668776367358455
Validation loss: 3.1153687436721538

Epoch: 6| Step: 5
Training loss: 3.883259369523706
Validation loss: 3.114513919254497

Epoch: 6| Step: 6
Training loss: 3.514497432024532
Validation loss: 3.114713618289395

Epoch: 6| Step: 7
Training loss: 2.751933545164111
Validation loss: 3.113141745709861

Epoch: 6| Step: 8
Training loss: 3.144748997701553
Validation loss: 3.111348860956688

Epoch: 6| Step: 9
Training loss: 3.2265820075454483
Validation loss: 3.110783332694125

Epoch: 6| Step: 10
Training loss: 3.7614197102143705
Validation loss: 3.1102750657295104

Epoch: 6| Step: 11
Training loss: 2.603425696179898
Validation loss: 3.109080151785144

Epoch: 6| Step: 12
Training loss: 3.8149021273116297
Validation loss: 3.108556621497312

Epoch: 6| Step: 13
Training loss: 3.2301481334625084
Validation loss: 3.1074580347876983

Epoch: 40| Step: 0
Training loss: 3.086558605414484
Validation loss: 3.107372024458127

Epoch: 6| Step: 1
Training loss: 3.4292596710929706
Validation loss: 3.1054664583430545

Epoch: 6| Step: 2
Training loss: 2.6681010044544236
Validation loss: 3.1055616531411516

Epoch: 6| Step: 3
Training loss: 3.408683397616738
Validation loss: 3.1051950220694127

Epoch: 6| Step: 4
Training loss: 3.191781553054951
Validation loss: 3.104077849872824

Epoch: 6| Step: 5
Training loss: 3.18198351244728
Validation loss: 3.1013536995396174

Epoch: 6| Step: 6
Training loss: 3.268973208331936
Validation loss: 3.1025458547119698

Epoch: 6| Step: 7
Training loss: 3.6598010954459723
Validation loss: 3.1014744853648617

Epoch: 6| Step: 8
Training loss: 4.018116219054534
Validation loss: 3.098859247098998

Epoch: 6| Step: 9
Training loss: 4.093961986847931
Validation loss: 3.09830871098916

Epoch: 6| Step: 10
Training loss: 3.535832225599497
Validation loss: 3.096380183650338

Epoch: 6| Step: 11
Training loss: 3.2157163675597693
Validation loss: 3.0938631022356566

Epoch: 6| Step: 12
Training loss: 2.732865619961058
Validation loss: 3.093682101206783

Epoch: 6| Step: 13
Training loss: 3.1933640039626234
Validation loss: 3.0942754687663414

Epoch: 41| Step: 0
Training loss: 3.1371805461552262
Validation loss: 3.0930528166968325

Epoch: 6| Step: 1
Training loss: 2.9893074218461853
Validation loss: 3.091554328485733

Epoch: 6| Step: 2
Training loss: 3.068381442373702
Validation loss: 3.09315894098973

Epoch: 6| Step: 3
Training loss: 3.250409320584528
Validation loss: 3.093644190992822

Epoch: 6| Step: 4
Training loss: 3.164351386551563
Validation loss: 3.0891541167394

Epoch: 6| Step: 5
Training loss: 3.811738985746399
Validation loss: 3.0880090359058228

Epoch: 6| Step: 6
Training loss: 3.1229119000304126
Validation loss: 3.0887656666091803

Epoch: 6| Step: 7
Training loss: 3.4809394629435504
Validation loss: 3.0887188200310747

Epoch: 6| Step: 8
Training loss: 3.220857985493885
Validation loss: 3.0870625540775674

Epoch: 6| Step: 9
Training loss: 3.578050904152298
Validation loss: 3.089234697458158

Epoch: 6| Step: 10
Training loss: 4.141433579290486
Validation loss: 3.0881174039573045

Epoch: 6| Step: 11
Training loss: 3.3908716630648197
Validation loss: 3.086254110588788

Epoch: 6| Step: 12
Training loss: 2.982363517305197
Validation loss: 3.0860803905680343

Epoch: 6| Step: 13
Training loss: 3.5118390530526735
Validation loss: 3.084469512446593

Epoch: 42| Step: 0
Training loss: 4.273088904743476
Validation loss: 3.0836221869498077

Epoch: 6| Step: 1
Training loss: 3.3130721551767803
Validation loss: 3.083243571346475

Epoch: 6| Step: 2
Training loss: 2.996983919362104
Validation loss: 3.0823663441289093

Epoch: 6| Step: 3
Training loss: 3.153154422558464
Validation loss: 3.080675531665097

Epoch: 6| Step: 4
Training loss: 3.257669203280236
Validation loss: 3.08190776314976

Epoch: 6| Step: 5
Training loss: 4.478427039300505
Validation loss: 3.0799545681653364

Epoch: 6| Step: 6
Training loss: 3.2016319703011455
Validation loss: 3.078939703691097

Epoch: 6| Step: 7
Training loss: 3.436323901034334
Validation loss: 3.0786637735797653

Epoch: 6| Step: 8
Training loss: 3.7243015940282347
Validation loss: 3.077925851410676

Epoch: 6| Step: 9
Training loss: 3.539742848598483
Validation loss: 3.076634160685801

Epoch: 6| Step: 10
Training loss: 2.688530657771698
Validation loss: 3.0757604628265858

Epoch: 6| Step: 11
Training loss: 2.9321495188831053
Validation loss: 3.0757564620328948

Epoch: 6| Step: 12
Training loss: 2.3302555448353384
Validation loss: 3.0747713465682662

Epoch: 6| Step: 13
Training loss: 2.4193888054791106
Validation loss: 3.0739462775080466

Epoch: 43| Step: 0
Training loss: 3.1865358577466343
Validation loss: 3.0716477839063483

Epoch: 6| Step: 1
Training loss: 3.821255994498181
Validation loss: 3.0733710908064116

Epoch: 6| Step: 2
Training loss: 2.3265574253454773
Validation loss: 3.070913147154521

Epoch: 6| Step: 3
Training loss: 3.6232921918295586
Validation loss: 3.0690495244040727

Epoch: 6| Step: 4
Training loss: 2.9598699169958653
Validation loss: 3.069672737348362

Epoch: 6| Step: 5
Training loss: 3.7727960076813285
Validation loss: 3.0697815155251518

Epoch: 6| Step: 6
Training loss: 3.1675118941254614
Validation loss: 3.06797640408994

Epoch: 6| Step: 7
Training loss: 2.92875701369432
Validation loss: 3.06603767265297

Epoch: 6| Step: 8
Training loss: 3.7082319495811653
Validation loss: 3.067457065159617

Epoch: 6| Step: 9
Training loss: 3.1299780297041484
Validation loss: 3.0667883152216584

Epoch: 6| Step: 10
Training loss: 3.688890227415871
Validation loss: 3.0662098510457914

Epoch: 6| Step: 11
Training loss: 3.140164469645394
Validation loss: 3.065598961420586

Epoch: 6| Step: 12
Training loss: 3.844344302498139
Validation loss: 3.0671307693004306

Epoch: 6| Step: 13
Training loss: 2.7644049760615004
Validation loss: 3.064003845340519

Epoch: 44| Step: 0
Training loss: 3.5503422263228694
Validation loss: 3.0666432099116254

Epoch: 6| Step: 1
Training loss: 3.6578958833455055
Validation loss: 3.061478441705902

Epoch: 6| Step: 2
Training loss: 3.6079693323595574
Validation loss: 3.0625472133162233

Epoch: 6| Step: 3
Training loss: 3.1159181998292804
Validation loss: 3.060327238393027

Epoch: 6| Step: 4
Training loss: 3.460271560287582
Validation loss: 3.0590915903664024

Epoch: 6| Step: 5
Training loss: 3.954831444853516
Validation loss: 3.06057775700572

Epoch: 6| Step: 6
Training loss: 2.911720623469179
Validation loss: 3.057143007323592

Epoch: 6| Step: 7
Training loss: 3.3070709074739457
Validation loss: 3.0568131012205786

Epoch: 6| Step: 8
Training loss: 3.002081784511134
Validation loss: 3.0557832943148435

Epoch: 6| Step: 9
Training loss: 2.7280193470075877
Validation loss: 3.0560675482627966

Epoch: 6| Step: 10
Training loss: 3.0976273101185976
Validation loss: 3.056759026171226

Epoch: 6| Step: 11
Training loss: 2.6585378331019065
Validation loss: 3.054747608034982

Epoch: 6| Step: 12
Training loss: 3.5946903491197526
Validation loss: 3.056358975948132

Epoch: 6| Step: 13
Training loss: 3.9431213941934002
Validation loss: 3.055929295313475

Epoch: 45| Step: 0
Training loss: 2.545961461898513
Validation loss: 3.0546741475337806

Epoch: 6| Step: 1
Training loss: 3.8619189816100516
Validation loss: 3.054817549632686

Epoch: 6| Step: 2
Training loss: 4.080039324103442
Validation loss: 3.053568219722655

Epoch: 6| Step: 3
Training loss: 3.005256180847885
Validation loss: 3.0519467213036555

Epoch: 6| Step: 4
Training loss: 3.750076293169226
Validation loss: 3.0489051199869173

Epoch: 6| Step: 5
Training loss: 3.2592211269145235
Validation loss: 3.0498801431248976

Epoch: 6| Step: 6
Training loss: 3.258307769232822
Validation loss: 3.0486582898937935

Epoch: 6| Step: 7
Training loss: 2.7461083358876506
Validation loss: 3.0482342040318495

Epoch: 6| Step: 8
Training loss: 3.3710201958227026
Validation loss: 3.0470646557549217

Epoch: 6| Step: 9
Training loss: 3.466520125397393
Validation loss: 3.047753702134748

Epoch: 6| Step: 10
Training loss: 3.6707586661173313
Validation loss: 3.047326614906943

Epoch: 6| Step: 11
Training loss: 2.7627205980693788
Validation loss: 3.04378517893472

Epoch: 6| Step: 12
Training loss: 2.997928062843221
Validation loss: 3.0437317610245973

Epoch: 6| Step: 13
Training loss: 3.324261352409515
Validation loss: 3.0436242258108583

Epoch: 46| Step: 0
Training loss: 3.4258104799387263
Validation loss: 3.04113242671597

Epoch: 6| Step: 1
Training loss: 3.7380123539981214
Validation loss: 3.0499958051749836

Epoch: 6| Step: 2
Training loss: 4.154446088499175
Validation loss: 3.0794050163028706

Epoch: 6| Step: 3
Training loss: 3.7912058008713463
Validation loss: 3.0431731827253783

Epoch: 6| Step: 4
Training loss: 3.5931597681067045
Validation loss: 3.0413824772676104

Epoch: 6| Step: 5
Training loss: 2.8965041300742365
Validation loss: 3.0448412135817375

Epoch: 6| Step: 6
Training loss: 2.5386423555633923
Validation loss: 3.0661399276806596

Epoch: 6| Step: 7
Training loss: 3.2808589157284027
Validation loss: 3.129782327154901

Epoch: 6| Step: 8
Training loss: 2.889772196572508
Validation loss: 3.077280024669657

Epoch: 6| Step: 9
Training loss: 3.816211582244111
Validation loss: 3.0571724537077336

Epoch: 6| Step: 10
Training loss: 3.664614507742451
Validation loss: 3.0474036882108573

Epoch: 6| Step: 11
Training loss: 2.7518124243218947
Validation loss: 3.060321949979058

Epoch: 6| Step: 12
Training loss: 2.690981982360422
Validation loss: 3.090669474876954

Epoch: 6| Step: 13
Training loss: 2.255320298819783
Validation loss: 3.1365736856804967

Epoch: 47| Step: 0
Training loss: 2.9518088985604414
Validation loss: 3.243619759967797

Epoch: 6| Step: 1
Training loss: 3.025473212437963
Validation loss: 3.214466729204989

Epoch: 6| Step: 2
Training loss: 4.310221194368657
Validation loss: 3.115785400877454

Epoch: 6| Step: 3
Training loss: 2.9639725642819985
Validation loss: 3.0464643724937726

Epoch: 6| Step: 4
Training loss: 3.3517815933997723
Validation loss: 3.0358186086362124

Epoch: 6| Step: 5
Training loss: 3.5405943799357225
Validation loss: 3.037871660203208

Epoch: 6| Step: 6
Training loss: 4.1331078580659195
Validation loss: 3.056433172654914

Epoch: 6| Step: 7
Training loss: 3.8501159551423894
Validation loss: 3.0919938110543055

Epoch: 6| Step: 8
Training loss: 3.0493939282204545
Validation loss: 3.034244575011159

Epoch: 6| Step: 9
Training loss: 3.0140629809405395
Validation loss: 3.032536417949371

Epoch: 6| Step: 10
Training loss: 1.7762800785661552
Validation loss: 3.0340315625603735

Epoch: 6| Step: 11
Training loss: 2.3613755794833593
Validation loss: 3.0469925951607695

Epoch: 6| Step: 12
Training loss: 4.265390690107743
Validation loss: 3.073725210903044

Epoch: 6| Step: 13
Training loss: 3.166478419146175
Validation loss: 3.072287664316213

Epoch: 48| Step: 0
Training loss: 3.0472167777058514
Validation loss: 3.066991108410816

Epoch: 6| Step: 1
Training loss: 3.7067943051086263
Validation loss: 3.0534842386496654

Epoch: 6| Step: 2
Training loss: 3.5944024861982395
Validation loss: 3.0384241375252476

Epoch: 6| Step: 3
Training loss: 3.190215655603905
Validation loss: 3.0268781838425265

Epoch: 6| Step: 4
Training loss: 3.302923791508028
Validation loss: 3.0271642797267253

Epoch: 6| Step: 5
Training loss: 3.9564600209299217
Validation loss: 3.0278450376785706

Epoch: 6| Step: 6
Training loss: 3.504758052991642
Validation loss: 3.0395502857363192

Epoch: 6| Step: 7
Training loss: 3.3486540296699516
Validation loss: 3.025129334083221

Epoch: 6| Step: 8
Training loss: 2.790285926715384
Validation loss: 3.029490653931668

Epoch: 6| Step: 9
Training loss: 3.6246174577585273
Validation loss: 3.0500590971102026

Epoch: 6| Step: 10
Training loss: 2.565896272431465
Validation loss: 3.039084307712056

Epoch: 6| Step: 11
Training loss: 3.2501332182357228
Validation loss: 3.032790205127585

Epoch: 6| Step: 12
Training loss: 3.1956048286110237
Validation loss: 3.0329089237216613

Epoch: 6| Step: 13
Training loss: 2.4909138549095924
Validation loss: 3.027517321133067

Epoch: 49| Step: 0
Training loss: 2.8318938544257577
Validation loss: 3.0317006665743844

Epoch: 6| Step: 1
Training loss: 3.53574159950176
Validation loss: 3.0336337656662726

Epoch: 6| Step: 2
Training loss: 3.0514432650396532
Validation loss: 3.0298309962866465

Epoch: 6| Step: 3
Training loss: 3.864797512538949
Validation loss: 3.022614043259604

Epoch: 6| Step: 4
Training loss: 3.3988830975829627
Validation loss: 3.0165442042857418

Epoch: 6| Step: 5
Training loss: 3.6471892678278826
Validation loss: 3.0132984365999342

Epoch: 6| Step: 6
Training loss: 3.5902809980924433
Validation loss: 3.012309527657078

Epoch: 6| Step: 7
Training loss: 3.211217566386151
Validation loss: 3.012509094259956

Epoch: 6| Step: 8
Training loss: 3.512094309989517
Validation loss: 3.011280052814831

Epoch: 6| Step: 9
Training loss: 3.248123801141062
Validation loss: 3.008180053056077

Epoch: 6| Step: 10
Training loss: 2.9522976801301812
Validation loss: 3.005239822672853

Epoch: 6| Step: 11
Training loss: 3.1611307006866594
Validation loss: 3.0025410367459133

Epoch: 6| Step: 12
Training loss: 2.59451411378572
Validation loss: 3.0018320129841607

Epoch: 6| Step: 13
Training loss: 3.1835285952401033
Validation loss: 2.9986836765497573

Epoch: 50| Step: 0
Training loss: 2.7582433434257996
Validation loss: 2.9998713605912695

Epoch: 6| Step: 1
Training loss: 2.985999019993125
Validation loss: 2.9972008033480884

Epoch: 6| Step: 2
Training loss: 3.0932046428855227
Validation loss: 2.9965444988548686

Epoch: 6| Step: 3
Training loss: 3.881243690080167
Validation loss: 2.995878933733749

Epoch: 6| Step: 4
Training loss: 3.073380429892418
Validation loss: 2.993660410211185

Epoch: 6| Step: 5
Training loss: 3.8503080418203863
Validation loss: 2.992359695442676

Epoch: 6| Step: 6
Training loss: 3.4371240583666074
Validation loss: 2.9916587423872674

Epoch: 6| Step: 7
Training loss: 2.912790793117105
Validation loss: 2.9905069762413783

Epoch: 6| Step: 8
Training loss: 3.385995684283549
Validation loss: 2.988217177197775

Epoch: 6| Step: 9
Training loss: 3.6125899359783733
Validation loss: 2.9899260553269373

Epoch: 6| Step: 10
Training loss: 2.9695476865727533
Validation loss: 2.9897057633000816

Epoch: 6| Step: 11
Training loss: 2.912654096595333
Validation loss: 2.9872457738236906

Epoch: 6| Step: 12
Training loss: 3.4638849456392133
Validation loss: 2.9855088846650126

Epoch: 6| Step: 13
Training loss: 3.252132449776028
Validation loss: 2.984140144740673

Testing loss: 3.188567500989628
