Epoch: 1| Step: 0
Training loss: 3.3630274589386264
Validation loss: 3.636061442002538

Epoch: 5| Step: 1
Training loss: 3.949833038278129
Validation loss: 3.6341197170333985

Epoch: 5| Step: 2
Training loss: 3.7420516656421197
Validation loss: 3.627330951392858

Epoch: 5| Step: 3
Training loss: 4.2678480678354695
Validation loss: 3.6201719537416017

Epoch: 5| Step: 4
Training loss: 3.8363551516523304
Validation loss: 3.616552241442228

Epoch: 5| Step: 5
Training loss: 3.082866134989031
Validation loss: 3.611228411252067

Epoch: 5| Step: 6
Training loss: 4.814286532044189
Validation loss: 3.605347338912591

Epoch: 5| Step: 7
Training loss: 3.6043456075418123
Validation loss: 3.600521645585971

Epoch: 5| Step: 8
Training loss: 3.5848505371518993
Validation loss: 3.597880817420964

Epoch: 5| Step: 9
Training loss: 3.805000057345777
Validation loss: 3.590854513057387

Epoch: 5| Step: 10
Training loss: 3.5443251262526605
Validation loss: 3.584647801564314

Epoch: 2| Step: 0
Training loss: 4.010269571884734
Validation loss: 3.5806113925332945

Epoch: 5| Step: 1
Training loss: 3.5394443196523016
Validation loss: 3.575074486760013

Epoch: 5| Step: 2
Training loss: 4.241305489642278
Validation loss: 3.570246246923024

Epoch: 5| Step: 3
Training loss: 3.9229537878375256
Validation loss: 3.56767652458644

Epoch: 5| Step: 4
Training loss: 4.065473202122692
Validation loss: 3.5614215849953927

Epoch: 5| Step: 5
Training loss: 3.745123171646132
Validation loss: 3.553548990015999

Epoch: 5| Step: 6
Training loss: 3.2660160104390696
Validation loss: 3.5482137911808396

Epoch: 5| Step: 7
Training loss: 3.636832689247956
Validation loss: 3.5461407573152295

Epoch: 5| Step: 8
Training loss: 3.819538311045708
Validation loss: 3.538443439352437

Epoch: 5| Step: 9
Training loss: 3.29329961198333
Validation loss: 3.53537275301428

Epoch: 5| Step: 10
Training loss: 3.70095594274462
Validation loss: 3.529080205548032

Epoch: 3| Step: 0
Training loss: 3.9359944205050734
Validation loss: 3.5259490405458864

Epoch: 5| Step: 1
Training loss: 4.0230565751867475
Validation loss: 3.5208458290720563

Epoch: 5| Step: 2
Training loss: 4.226465023136578
Validation loss: 3.51621094409099

Epoch: 5| Step: 3
Training loss: 3.9370442686801685
Validation loss: 3.50747836421958

Epoch: 5| Step: 4
Training loss: 2.794113756773517
Validation loss: 3.502607574747903

Epoch: 5| Step: 5
Training loss: 3.2387715556326593
Validation loss: 3.4997724160241708

Epoch: 5| Step: 6
Training loss: 3.5406196991492753
Validation loss: 3.491489017999308

Epoch: 5| Step: 7
Training loss: 3.182226568493755
Validation loss: 3.489205967067103

Epoch: 5| Step: 8
Training loss: 3.7132545706193625
Validation loss: 3.482019987616391

Epoch: 5| Step: 9
Training loss: 3.423669074760538
Validation loss: 3.477916638619953

Epoch: 5| Step: 10
Training loss: 4.579162688364945
Validation loss: 3.47084390619715

Epoch: 4| Step: 0
Training loss: 4.092215446968097
Validation loss: 3.4655465164114645

Epoch: 5| Step: 1
Training loss: 3.169289874372537
Validation loss: 3.45878112380731

Epoch: 5| Step: 2
Training loss: 3.2886619052085635
Validation loss: 3.452151868410943

Epoch: 5| Step: 3
Training loss: 3.5272522298741062
Validation loss: 3.4470994381913704

Epoch: 5| Step: 4
Training loss: 3.1994606457600145
Validation loss: 3.4409733620685707

Epoch: 5| Step: 5
Training loss: 3.5041294260726112
Validation loss: 3.436430289398107

Epoch: 5| Step: 6
Training loss: 4.178841136197588
Validation loss: 3.431143795785851

Epoch: 5| Step: 7
Training loss: 4.3786699433757805
Validation loss: 3.4249094470935155

Epoch: 5| Step: 8
Training loss: 3.950896830091103
Validation loss: 3.4189424181404426

Epoch: 5| Step: 9
Training loss: 3.27146280310052
Validation loss: 3.413947935325297

Epoch: 5| Step: 10
Training loss: 3.3241418634616013
Validation loss: 3.4065343356742894

Epoch: 5| Step: 0
Training loss: 3.7670048761581807
Validation loss: 3.4014924305053253

Epoch: 5| Step: 1
Training loss: 3.4464817960682574
Validation loss: 3.395735699183495

Epoch: 5| Step: 2
Training loss: 3.322919185880625
Validation loss: 3.39093765126106

Epoch: 5| Step: 3
Training loss: 3.8343675434565463
Validation loss: 3.3828453053469514

Epoch: 5| Step: 4
Training loss: 3.8181766710205394
Validation loss: 3.3774109147688383

Epoch: 5| Step: 5
Training loss: 3.8028725558324092
Validation loss: 3.374133644128304

Epoch: 5| Step: 6
Training loss: 3.2764019709871195
Validation loss: 3.3629382075030736

Epoch: 5| Step: 7
Training loss: 3.459119745639467
Validation loss: 3.3600099040421147

Epoch: 5| Step: 8
Training loss: 3.9655563841550765
Validation loss: 3.3557377746235004

Epoch: 5| Step: 9
Training loss: 3.2783720928849336
Validation loss: 3.345012666750115

Epoch: 5| Step: 10
Training loss: 3.488277422485302
Validation loss: 3.341337308583617

Epoch: 6| Step: 0
Training loss: 3.5278514610732246
Validation loss: 3.335306498558731

Epoch: 5| Step: 1
Training loss: 3.6722614490788406
Validation loss: 3.330911967964838

Epoch: 5| Step: 2
Training loss: 3.617291640560132
Validation loss: 3.3219890680125275

Epoch: 5| Step: 3
Training loss: 3.6104972382785707
Validation loss: 3.315417699082202

Epoch: 5| Step: 4
Training loss: 3.2139179291801105
Validation loss: 3.311071609919759

Epoch: 5| Step: 5
Training loss: 4.402005146209052
Validation loss: 3.305488457749465

Epoch: 5| Step: 6
Training loss: 3.5936682650351983
Validation loss: 3.299569510990912

Epoch: 5| Step: 7
Training loss: 3.085393852923988
Validation loss: 3.29493757150661

Epoch: 5| Step: 8
Training loss: 3.5065181527640865
Validation loss: 3.2860216392399915

Epoch: 5| Step: 9
Training loss: 3.2061767926698135
Validation loss: 3.2810331539570234

Epoch: 5| Step: 10
Training loss: 3.2720810440025025
Validation loss: 3.273065616622

Epoch: 7| Step: 0
Training loss: 3.2344183435161913
Validation loss: 3.2698744248772105

Epoch: 5| Step: 1
Training loss: 3.9053228880261885
Validation loss: 3.2598389999007966

Epoch: 5| Step: 2
Training loss: 3.6083606434082984
Validation loss: 3.256720053359194

Epoch: 5| Step: 3
Training loss: 3.8758055557199347
Validation loss: 3.250523234008843

Epoch: 5| Step: 4
Training loss: 3.700982999385861
Validation loss: 3.2425345159887993

Epoch: 5| Step: 5
Training loss: 3.4159561596989723
Validation loss: 3.2355237088790254

Epoch: 5| Step: 6
Training loss: 3.4497038175077916
Validation loss: 3.229046478310653

Epoch: 5| Step: 7
Training loss: 3.324247725435557
Validation loss: 3.2211762278326366

Epoch: 5| Step: 8
Training loss: 3.6405823013355776
Validation loss: 3.2155850894812326

Epoch: 5| Step: 9
Training loss: 2.7511374982045336
Validation loss: 3.206621499367605

Epoch: 5| Step: 10
Training loss: 3.1447464199966175
Validation loss: 3.2017473853470695

Epoch: 8| Step: 0
Training loss: 3.4793994087142868
Validation loss: 3.191310706270897

Epoch: 5| Step: 1
Training loss: 4.19247892079886
Validation loss: 3.18908459635232

Epoch: 5| Step: 2
Training loss: 3.006162988747781
Validation loss: 3.1828113344612743

Epoch: 5| Step: 3
Training loss: 2.5860038817952606
Validation loss: 3.174122228735367

Epoch: 5| Step: 4
Training loss: 4.046674686614567
Validation loss: 3.1694286883906653

Epoch: 5| Step: 5
Training loss: 2.9620933994092304
Validation loss: 3.1653724437094026

Epoch: 5| Step: 6
Training loss: 3.0607914732547568
Validation loss: 3.156721507336083

Epoch: 5| Step: 7
Training loss: 3.186870288355371
Validation loss: 3.1470387710941052

Epoch: 5| Step: 8
Training loss: 3.3789412480123904
Validation loss: 3.1443559507427525

Epoch: 5| Step: 9
Training loss: 3.885058361778658
Validation loss: 3.137391613333914

Epoch: 5| Step: 10
Training loss: 3.433899120513129
Validation loss: 3.133897773165668

Epoch: 9| Step: 0
Training loss: 3.675826263962887
Validation loss: 3.1242979643431146

Epoch: 5| Step: 1
Training loss: 3.653042029881742
Validation loss: 3.1147377671948413

Epoch: 5| Step: 2
Training loss: 3.4806142449071524
Validation loss: 3.108847276659519

Epoch: 5| Step: 3
Training loss: 3.504194062829321
Validation loss: 3.1034141917406566

Epoch: 5| Step: 4
Training loss: 3.3042739356877524
Validation loss: 3.0912449467650633

Epoch: 5| Step: 5
Training loss: 3.690012318453606
Validation loss: 3.0888448929955445

Epoch: 5| Step: 6
Training loss: 3.0999310331979157
Validation loss: 3.078651904078336

Epoch: 5| Step: 7
Training loss: 3.409930838949086
Validation loss: 3.071591934359649

Epoch: 5| Step: 8
Training loss: 3.0358105203457435
Validation loss: 3.064593587510643

Epoch: 5| Step: 9
Training loss: 2.9039433667569248
Validation loss: 3.0595689165437587

Epoch: 5| Step: 10
Training loss: 2.9367338764179634
Validation loss: 3.0527065359992442

Epoch: 10| Step: 0
Training loss: 2.8807536063740695
Validation loss: 3.0393513888770185

Epoch: 5| Step: 1
Training loss: 3.37805080279402
Validation loss: 3.039046698337076

Epoch: 5| Step: 2
Training loss: 3.7733578880868053
Validation loss: 3.0312884934804623

Epoch: 5| Step: 3
Training loss: 3.0692587250171255
Validation loss: 3.024343222821222

Epoch: 5| Step: 4
Training loss: 3.1107348051766173
Validation loss: 3.015678247594509

Epoch: 5| Step: 5
Training loss: 3.661421680221762
Validation loss: 3.0123227921687774

Epoch: 5| Step: 6
Training loss: 3.2102837187023563
Validation loss: 3.0030786576075426

Epoch: 5| Step: 7
Training loss: 3.0902116366010235
Validation loss: 2.9940726952244288

Epoch: 5| Step: 8
Training loss: 2.8536341000922794
Validation loss: 2.9884209434205564

Epoch: 5| Step: 9
Training loss: 3.3975701288504028
Validation loss: 2.981159828793139

Epoch: 5| Step: 10
Training loss: 3.597094099462535
Validation loss: 2.978336035715425

Epoch: 11| Step: 0
Training loss: 3.4982829650577556
Validation loss: 2.966203211368285

Epoch: 5| Step: 1
Training loss: 3.520661268976898
Validation loss: 2.961819146398219

Epoch: 5| Step: 2
Training loss: 3.293164809647549
Validation loss: 2.9541102598206854

Epoch: 5| Step: 3
Training loss: 2.9335583152611924
Validation loss: 2.9421440449579346

Epoch: 5| Step: 4
Training loss: 2.9515353975520826
Validation loss: 2.9394947209725015

Epoch: 5| Step: 5
Training loss: 3.441497559045128
Validation loss: 2.9286461304096183

Epoch: 5| Step: 6
Training loss: 2.762432518734665
Validation loss: 2.9208208557773334

Epoch: 5| Step: 7
Training loss: 2.545524098480233
Validation loss: 2.9168692475970333

Epoch: 5| Step: 8
Training loss: 3.876710206692314
Validation loss: 2.9085541781611624

Epoch: 5| Step: 9
Training loss: 3.0574277016801195
Validation loss: 2.9063477082399873

Epoch: 5| Step: 10
Training loss: 3.305665504984914
Validation loss: 2.887249938864999

Epoch: 12| Step: 0
Training loss: 2.9034196751307797
Validation loss: 2.886960473804407

Epoch: 5| Step: 1
Training loss: 3.1507976006599834
Validation loss: 2.8796743716017117

Epoch: 5| Step: 2
Training loss: 3.105975108580568
Validation loss: 2.8716231225800812

Epoch: 5| Step: 3
Training loss: 3.228289790715721
Validation loss: 2.86366550691042

Epoch: 5| Step: 4
Training loss: 3.167680042813304
Validation loss: 2.858013606987847

Epoch: 5| Step: 5
Training loss: 2.679043706402837
Validation loss: 2.84379142362347

Epoch: 5| Step: 6
Training loss: 3.1564229785616953
Validation loss: 2.841448636402995

Epoch: 5| Step: 7
Training loss: 3.0738315750473078
Validation loss: 2.835568409360561

Epoch: 5| Step: 8
Training loss: 3.6309422426581013
Validation loss: 2.8271885193148036

Epoch: 5| Step: 9
Training loss: 3.1987837983671685
Validation loss: 2.821380128644687

Epoch: 5| Step: 10
Training loss: 3.258864125549567
Validation loss: 2.8152580401691005

Epoch: 13| Step: 0
Training loss: 3.1432544841025924
Validation loss: 2.808078609377776

Epoch: 5| Step: 1
Training loss: 3.1831021356426215
Validation loss: 2.8018973656643738

Epoch: 5| Step: 2
Training loss: 3.369539859724466
Validation loss: 2.784325249307122

Epoch: 5| Step: 3
Training loss: 2.9593512883590884
Validation loss: 2.7831540698492416

Epoch: 5| Step: 4
Training loss: 2.6597790779785346
Validation loss: 2.773512608367448

Epoch: 5| Step: 5
Training loss: 2.7633901068266353
Validation loss: 2.76878246122697

Epoch: 5| Step: 6
Training loss: 3.1247555446378708
Validation loss: 2.763138567507146

Epoch: 5| Step: 7
Training loss: 3.1189201721366855
Validation loss: 2.752187028894528

Epoch: 5| Step: 8
Training loss: 3.140474078599359
Validation loss: 2.7386149087484646

Epoch: 5| Step: 9
Training loss: 3.7426272076206266
Validation loss: 2.7394564055783763

Epoch: 5| Step: 10
Training loss: 2.5472961264838756
Validation loss: 2.730247359366956

Epoch: 14| Step: 0
Training loss: 2.8523509986469797
Validation loss: 2.72023113991108

Epoch: 5| Step: 1
Training loss: 3.1838386301046078
Validation loss: 2.7122426054885818

Epoch: 5| Step: 2
Training loss: 2.8553931021421954
Validation loss: 2.706503713134107

Epoch: 5| Step: 3
Training loss: 3.230347267828052
Validation loss: 2.701020694879342

Epoch: 5| Step: 4
Training loss: 3.0724503157892014
Validation loss: 2.696080683044323

Epoch: 5| Step: 5
Training loss: 3.4549250679336914
Validation loss: 2.685179524912149

Epoch: 5| Step: 6
Training loss: 2.9307306085726155
Validation loss: 2.67661833113235

Epoch: 5| Step: 7
Training loss: 2.8104376118876044
Validation loss: 2.6703894509910606

Epoch: 5| Step: 8
Training loss: 2.1920714431243966
Validation loss: 2.6671391447973676

Epoch: 5| Step: 9
Training loss: 3.166874895444017
Validation loss: 2.6601114001105803

Epoch: 5| Step: 10
Training loss: 3.41381248414143
Validation loss: 2.6599767051927046

Epoch: 15| Step: 0
Training loss: 2.734340645710528
Validation loss: 2.647363234128868

Epoch: 5| Step: 1
Training loss: 2.5960409319197253
Validation loss: 2.639544051258184

Epoch: 5| Step: 2
Training loss: 2.794717137417279
Validation loss: 2.6379069638893604

Epoch: 5| Step: 3
Training loss: 3.0062251670906197
Validation loss: 2.6374716058479986

Epoch: 5| Step: 4
Training loss: 2.8033277355354413
Validation loss: 2.633976604950622

Epoch: 5| Step: 5
Training loss: 3.4796893855938986
Validation loss: 2.63279359599602

Epoch: 5| Step: 6
Training loss: 2.700606391063971
Validation loss: 2.6184958060249754

Epoch: 5| Step: 7
Training loss: 3.2076318807984876
Validation loss: 2.616690003948283

Epoch: 5| Step: 8
Training loss: 3.0491986144307788
Validation loss: 2.6140131789357284

Epoch: 5| Step: 9
Training loss: 3.352245768011043
Validation loss: 2.606904757061512

Epoch: 5| Step: 10
Training loss: 2.784145776494641
Validation loss: 2.600030800618816

Epoch: 16| Step: 0
Training loss: 3.2589058264966972
Validation loss: 2.593183929866232

Epoch: 5| Step: 1
Training loss: 2.896501989947702
Validation loss: 2.5814263320901114

Epoch: 5| Step: 2
Training loss: 2.6814857432626416
Validation loss: 2.588581380941597

Epoch: 5| Step: 3
Training loss: 3.004846790235417
Validation loss: 2.5735333126249156

Epoch: 5| Step: 4
Training loss: 2.835008032785705
Validation loss: 2.570816033106805

Epoch: 5| Step: 5
Training loss: 2.481832198631549
Validation loss: 2.574779811548229

Epoch: 5| Step: 6
Training loss: 3.3692872477153366
Validation loss: 2.5610141312957033

Epoch: 5| Step: 7
Training loss: 3.3888421359424323
Validation loss: 2.559022430075799

Epoch: 5| Step: 8
Training loss: 2.845053237926444
Validation loss: 2.560150833472376

Epoch: 5| Step: 9
Training loss: 2.6795438944870655
Validation loss: 2.5540612393842457

Epoch: 5| Step: 10
Training loss: 2.6698751717579934
Validation loss: 2.549072799031125

Epoch: 17| Step: 0
Training loss: 2.767851972794868
Validation loss: 2.5498880922781866

Epoch: 5| Step: 1
Training loss: 3.081651555449464
Validation loss: 2.5377029421444575

Epoch: 5| Step: 2
Training loss: 3.1330301489817667
Validation loss: 2.531041724051296

Epoch: 5| Step: 3
Training loss: 2.597598059439867
Validation loss: 2.530499825063292

Epoch: 5| Step: 4
Training loss: 3.0630623437388373
Validation loss: 2.524766938613683

Epoch: 5| Step: 5
Training loss: 3.156113725496374
Validation loss: 2.5275609337610927

Epoch: 5| Step: 6
Training loss: 3.470605714683596
Validation loss: 2.5235704271233317

Epoch: 5| Step: 7
Training loss: 2.717774139305515
Validation loss: 2.515274941692975

Epoch: 5| Step: 8
Training loss: 2.761830803784495
Validation loss: 2.509524202120915

Epoch: 5| Step: 9
Training loss: 2.8003519279838285
Validation loss: 2.5120858118941327

Epoch: 5| Step: 10
Training loss: 2.029551573585591
Validation loss: 2.5090027016139156

Epoch: 18| Step: 0
Training loss: 2.9322095264338084
Validation loss: 2.4967893605978397

Epoch: 5| Step: 1
Training loss: 2.488165979994149
Validation loss: 2.4982624866097294

Epoch: 5| Step: 2
Training loss: 3.068600708851474
Validation loss: 2.4994139353546396

Epoch: 5| Step: 3
Training loss: 2.328689199607088
Validation loss: 2.4896531031978575

Epoch: 5| Step: 4
Training loss: 3.255494388472956
Validation loss: 2.4894901635259874

Epoch: 5| Step: 5
Training loss: 2.832925168725196
Validation loss: 2.4916496641598442

Epoch: 5| Step: 6
Training loss: 2.799988872642205
Validation loss: 2.4830227096488007

Epoch: 5| Step: 7
Training loss: 2.955571851310964
Validation loss: 2.480622601778225

Epoch: 5| Step: 8
Training loss: 3.082093444892896
Validation loss: 2.4845170011238538

Epoch: 5| Step: 9
Training loss: 3.254388633774195
Validation loss: 2.479642798709291

Epoch: 5| Step: 10
Training loss: 2.496354114880804
Validation loss: 2.4758855426882027

Epoch: 19| Step: 0
Training loss: 3.16613535857608
Validation loss: 2.4699517800204935

Epoch: 5| Step: 1
Training loss: 3.050721542809618
Validation loss: 2.4734954190189415

Epoch: 5| Step: 2
Training loss: 2.768435068927115
Validation loss: 2.466615804509816

Epoch: 5| Step: 3
Training loss: 3.138258616617724
Validation loss: 2.4765740306302835

Epoch: 5| Step: 4
Training loss: 2.5254350910564707
Validation loss: 2.4664648406093526

Epoch: 5| Step: 5
Training loss: 2.6398082124520057
Validation loss: 2.472699295330484

Epoch: 5| Step: 6
Training loss: 2.624961216957966
Validation loss: 2.468294210897547

Epoch: 5| Step: 7
Training loss: 2.7383102437224394
Validation loss: 2.465758832897938

Epoch: 5| Step: 8
Training loss: 2.693046169866879
Validation loss: 2.471870004335075

Epoch: 5| Step: 9
Training loss: 3.524997949261441
Validation loss: 2.4623354070423424

Epoch: 5| Step: 10
Training loss: 2.395946090919673
Validation loss: 2.4599691120866067

Epoch: 20| Step: 0
Training loss: 2.7975447721196813
Validation loss: 2.461041727380204

Epoch: 5| Step: 1
Training loss: 2.664978227937951
Validation loss: 2.4543212185389685

Epoch: 5| Step: 2
Training loss: 2.8864660087895477
Validation loss: 2.4553590488945827

Epoch: 5| Step: 3
Training loss: 2.7560808402331727
Validation loss: 2.4609304214117906

Epoch: 5| Step: 4
Training loss: 3.1138261535961407
Validation loss: 2.463549306282235

Epoch: 5| Step: 5
Training loss: 2.8502575540448354
Validation loss: 2.4549097158446336

Epoch: 5| Step: 6
Training loss: 2.692385911853267
Validation loss: 2.4540490293277326

Epoch: 5| Step: 7
Training loss: 2.303968931776757
Validation loss: 2.453504400448042

Epoch: 5| Step: 8
Training loss: 3.3715636101619326
Validation loss: 2.446707651383427

Epoch: 5| Step: 9
Training loss: 2.8345907076649475
Validation loss: 2.4461238735964765

Epoch: 5| Step: 10
Training loss: 3.0797361233616387
Validation loss: 2.4534933413141626

Epoch: 21| Step: 0
Training loss: 2.876829808966088
Validation loss: 2.445096531079359

Epoch: 5| Step: 1
Training loss: 2.5771855347663912
Validation loss: 2.4458708034204872

Epoch: 5| Step: 2
Training loss: 3.309926887004372
Validation loss: 2.445633078677888

Epoch: 5| Step: 3
Training loss: 2.850778801233019
Validation loss: 2.4512996242694824

Epoch: 5| Step: 4
Training loss: 2.768539789284209
Validation loss: 2.441250969524223

Epoch: 5| Step: 5
Training loss: 3.1043771420665927
Validation loss: 2.447148583286139

Epoch: 5| Step: 6
Training loss: 2.9909163282316857
Validation loss: 2.4417069728265184

Epoch: 5| Step: 7
Training loss: 2.1875677915695326
Validation loss: 2.4485190270716437

Epoch: 5| Step: 8
Training loss: 2.7307441365172855
Validation loss: 2.4435811685473507

Epoch: 5| Step: 9
Training loss: 2.9426312371791443
Validation loss: 2.441450278920862

Epoch: 5| Step: 10
Training loss: 2.940313898832816
Validation loss: 2.439152015514424

Epoch: 22| Step: 0
Training loss: 2.9199700495085312
Validation loss: 2.4387841471888763

Epoch: 5| Step: 1
Training loss: 2.871305662885231
Validation loss: 2.4410326747114306

Epoch: 5| Step: 2
Training loss: 2.976976901466115
Validation loss: 2.4335512286487497

Epoch: 5| Step: 3
Training loss: 2.497455159988576
Validation loss: 2.4497589433058056

Epoch: 5| Step: 4
Training loss: 2.8194069716328456
Validation loss: 2.4420413005548918

Epoch: 5| Step: 5
Training loss: 2.8181229225839695
Validation loss: 2.4376397977569173

Epoch: 5| Step: 6
Training loss: 2.625901839334082
Validation loss: 2.443693482429133

Epoch: 5| Step: 7
Training loss: 2.4730382446466255
Validation loss: 2.4551591175111276

Epoch: 5| Step: 8
Training loss: 3.1897971159894034
Validation loss: 2.440582363714267

Epoch: 5| Step: 9
Training loss: 3.415758074151384
Validation loss: 2.443214543692795

Epoch: 5| Step: 10
Training loss: 2.534243755963963
Validation loss: 2.4423231750083194

Epoch: 23| Step: 0
Training loss: 2.5572050329840574
Validation loss: 2.434532761672396

Epoch: 5| Step: 1
Training loss: 2.753915686625011
Validation loss: 2.440473307023702

Epoch: 5| Step: 2
Training loss: 3.0583887336002578
Validation loss: 2.4385171434539634

Epoch: 5| Step: 3
Training loss: 3.0614231318297134
Validation loss: 2.4326523440523946

Epoch: 5| Step: 4
Training loss: 2.7514718191875867
Validation loss: 2.4429570060178083

Epoch: 5| Step: 5
Training loss: 2.860493592304267
Validation loss: 2.4447409328669654

Epoch: 5| Step: 6
Training loss: 2.7055641591507316
Validation loss: 2.4369063936393487

Epoch: 5| Step: 7
Training loss: 2.3661994508723465
Validation loss: 2.4414690873129814

Epoch: 5| Step: 8
Training loss: 2.8981395475751746
Validation loss: 2.435603132311247

Epoch: 5| Step: 9
Training loss: 3.1359061094650733
Validation loss: 2.432086111049701

Epoch: 5| Step: 10
Training loss: 3.0594015211878745
Validation loss: 2.4417440941479223

Epoch: 24| Step: 0
Training loss: 3.3537940219146827
Validation loss: 2.437224688888432

Epoch: 5| Step: 1
Training loss: 2.7625006144941517
Validation loss: 2.4397817533017467

Epoch: 5| Step: 2
Training loss: 2.6452591540866184
Validation loss: 2.435922149327996

Epoch: 5| Step: 3
Training loss: 2.7235936831908214
Validation loss: 2.429022087061493

Epoch: 5| Step: 4
Training loss: 2.7514385448915077
Validation loss: 2.437770528744636

Epoch: 5| Step: 5
Training loss: 3.1574109652206976
Validation loss: 2.4342282531924377

Epoch: 5| Step: 6
Training loss: 2.9740912323678415
Validation loss: 2.4386004447848664

Epoch: 5| Step: 7
Training loss: 3.066504682188069
Validation loss: 2.4315296031614975

Epoch: 5| Step: 8
Training loss: 2.586419098139492
Validation loss: 2.4329791629120625

Epoch: 5| Step: 9
Training loss: 2.6166673741268816
Validation loss: 2.4419474251091677

Epoch: 5| Step: 10
Training loss: 2.303019084591289
Validation loss: 2.432841776011109

Epoch: 25| Step: 0
Training loss: 3.070089783489487
Validation loss: 2.436079908402434

Epoch: 5| Step: 1
Training loss: 3.0624341373757185
Validation loss: 2.433789937583936

Epoch: 5| Step: 2
Training loss: 2.582950491891161
Validation loss: 2.432341325822157

Epoch: 5| Step: 3
Training loss: 3.046923984231644
Validation loss: 2.4272190619207454

Epoch: 5| Step: 4
Training loss: 2.90301300588356
Validation loss: 2.429675771126189

Epoch: 5| Step: 5
Training loss: 2.489643293055062
Validation loss: 2.4328799251234616

Epoch: 5| Step: 6
Training loss: 2.6466838240687918
Validation loss: 2.4338833081884848

Epoch: 5| Step: 7
Training loss: 3.139568853482018
Validation loss: 2.436388975735589

Epoch: 5| Step: 8
Training loss: 2.603376243162781
Validation loss: 2.4341052184560446

Epoch: 5| Step: 9
Training loss: 2.8946579301837856
Validation loss: 2.4296604610410895

Epoch: 5| Step: 10
Training loss: 2.6077264386439176
Validation loss: 2.4380861329102395

Epoch: 26| Step: 0
Training loss: 2.8145604533393325
Validation loss: 2.4267696294246974

Epoch: 5| Step: 1
Training loss: 2.700035313975784
Validation loss: 2.4305285118774433

Epoch: 5| Step: 2
Training loss: 3.562066704349849
Validation loss: 2.4314134820082676

Epoch: 5| Step: 3
Training loss: 2.3643083342456723
Validation loss: 2.430523463758582

Epoch: 5| Step: 4
Training loss: 3.0761101804329254
Validation loss: 2.4198405294437078

Epoch: 5| Step: 5
Training loss: 2.4386652582052233
Validation loss: 2.4262095309698135

Epoch: 5| Step: 6
Training loss: 2.4648779913553667
Validation loss: 2.4267248524202594

Epoch: 5| Step: 7
Training loss: 3.172455532522869
Validation loss: 2.4245751282635597

Epoch: 5| Step: 8
Training loss: 2.5167826956302615
Validation loss: 2.415527423879445

Epoch: 5| Step: 9
Training loss: 2.914723993651454
Validation loss: 2.4317367021425613

Epoch: 5| Step: 10
Training loss: 2.8435694039817685
Validation loss: 2.423412554470706

Epoch: 27| Step: 0
Training loss: 2.6729865188173045
Validation loss: 2.4316055255123756

Epoch: 5| Step: 1
Training loss: 3.385598108368978
Validation loss: 2.4213329924680815

Epoch: 5| Step: 2
Training loss: 3.0196405270087228
Validation loss: 2.4386286965960653

Epoch: 5| Step: 3
Training loss: 3.284431295883342
Validation loss: 2.423606769441014

Epoch: 5| Step: 4
Training loss: 3.140135314115395
Validation loss: 2.4278113051427774

Epoch: 5| Step: 5
Training loss: 2.0716279079568993
Validation loss: 2.4234695652588196

Epoch: 5| Step: 6
Training loss: 2.724205419203116
Validation loss: 2.4240874162791446

Epoch: 5| Step: 7
Training loss: 2.88341898340746
Validation loss: 2.430791921378193

Epoch: 5| Step: 8
Training loss: 2.438340946775776
Validation loss: 2.4230941747080594

Epoch: 5| Step: 9
Training loss: 2.7385520202588034
Validation loss: 2.4352775846092447

Epoch: 5| Step: 10
Training loss: 2.2955805446060222
Validation loss: 2.426333250304414

Epoch: 28| Step: 0
Training loss: 2.761632591533073
Validation loss: 2.4295462865474433

Epoch: 5| Step: 1
Training loss: 2.953939012831565
Validation loss: 2.41845239837789

Epoch: 5| Step: 2
Training loss: 2.788954703334164
Validation loss: 2.4314769718960085

Epoch: 5| Step: 3
Training loss: 2.6648361559345584
Validation loss: 2.4263047570613936

Epoch: 5| Step: 4
Training loss: 2.8821205197719824
Validation loss: 2.4360049711034883

Epoch: 5| Step: 5
Training loss: 2.7172864285009375
Validation loss: 2.41995848723573

Epoch: 5| Step: 6
Training loss: 2.8579786883254332
Validation loss: 2.4315423257582434

Epoch: 5| Step: 7
Training loss: 2.7994803968323363
Validation loss: 2.4281062486641702

Epoch: 5| Step: 8
Training loss: 2.539680194546169
Validation loss: 2.4260367000612493

Epoch: 5| Step: 9
Training loss: 3.298367131005279
Validation loss: 2.4165859109909826

Epoch: 5| Step: 10
Training loss: 2.639508434538707
Validation loss: 2.417998171635337

Epoch: 29| Step: 0
Training loss: 2.279751010817998
Validation loss: 2.42382250446858

Epoch: 5| Step: 1
Training loss: 3.208978877001909
Validation loss: 2.417616575452463

Epoch: 5| Step: 2
Training loss: 2.8038722476507805
Validation loss: 2.4296112064395547

Epoch: 5| Step: 3
Training loss: 2.8791116255611566
Validation loss: 2.4252512283780003

Epoch: 5| Step: 4
Training loss: 2.8745149949685125
Validation loss: 2.4285308350077655

Epoch: 5| Step: 5
Training loss: 2.508634343467791
Validation loss: 2.418362955334713

Epoch: 5| Step: 6
Training loss: 2.928333020225628
Validation loss: 2.4292724996714115

Epoch: 5| Step: 7
Training loss: 2.9376350534113747
Validation loss: 2.4296194620362535

Epoch: 5| Step: 8
Training loss: 1.9504778814403816
Validation loss: 2.4234897021984736

Epoch: 5| Step: 9
Training loss: 3.12349557903692
Validation loss: 2.419385695482865

Epoch: 5| Step: 10
Training loss: 3.270279774727642
Validation loss: 2.418081905240609

Epoch: 30| Step: 0
Training loss: 2.835306060524709
Validation loss: 2.417244737742366

Epoch: 5| Step: 1
Training loss: 3.166093188776523
Validation loss: 2.4238589837487203

Epoch: 5| Step: 2
Training loss: 2.516685215037458
Validation loss: 2.422430972174291

Epoch: 5| Step: 3
Training loss: 2.2361291788554634
Validation loss: 2.4276906992455345

Epoch: 5| Step: 4
Training loss: 3.4267821638579767
Validation loss: 2.4256629613149694

Epoch: 5| Step: 5
Training loss: 2.4488134702875928
Validation loss: 2.4210886869316814

Epoch: 5| Step: 6
Training loss: 2.744181372723492
Validation loss: 2.425053826722

Epoch: 5| Step: 7
Training loss: 2.8781803618666033
Validation loss: 2.4298645193505695

Epoch: 5| Step: 8
Training loss: 2.9374748391230447
Validation loss: 2.4229102762476407

Epoch: 5| Step: 9
Training loss: 2.618084927323028
Validation loss: 2.4288117431262704

Epoch: 5| Step: 10
Training loss: 2.987775054144793
Validation loss: 2.420758309410008

Epoch: 31| Step: 0
Training loss: 2.557625670417156
Validation loss: 2.421724568966946

Epoch: 5| Step: 1
Training loss: 3.1311435582387155
Validation loss: 2.423183701258591

Epoch: 5| Step: 2
Training loss: 2.5311638146315705
Validation loss: 2.42671025265213

Epoch: 5| Step: 3
Training loss: 2.7657273268223292
Validation loss: 2.4180569756646033

Epoch: 5| Step: 4
Training loss: 2.3157760509074583
Validation loss: 2.4209322276982514

Epoch: 5| Step: 5
Training loss: 2.912580261434331
Validation loss: 2.4190394796934953

Epoch: 5| Step: 6
Training loss: 3.052144038059957
Validation loss: 2.416464709823843

Epoch: 5| Step: 7
Training loss: 2.69769677011045
Validation loss: 2.4149899863271567

Epoch: 5| Step: 8
Training loss: 3.149752283195554
Validation loss: 2.428678904327906

Epoch: 5| Step: 9
Training loss: 3.00734035204564
Validation loss: 2.4196603250594944

Epoch: 5| Step: 10
Training loss: 2.653172404266767
Validation loss: 2.410768878694287

Epoch: 32| Step: 0
Training loss: 2.688248463580128
Validation loss: 2.4228705448980747

Epoch: 5| Step: 1
Training loss: 2.759967858638755
Validation loss: 2.411611373326972

Epoch: 5| Step: 2
Training loss: 2.5040462175071014
Validation loss: 2.4144512080872023

Epoch: 5| Step: 3
Training loss: 3.1406690300279587
Validation loss: 2.421653020227893

Epoch: 5| Step: 4
Training loss: 3.1133486406602104
Validation loss: 2.422768870941808

Epoch: 5| Step: 5
Training loss: 2.2572448439260877
Validation loss: 2.418544973574461

Epoch: 5| Step: 6
Training loss: 2.8306788931660583
Validation loss: 2.4151098486456375

Epoch: 5| Step: 7
Training loss: 2.679584556804321
Validation loss: 2.4214726119404046

Epoch: 5| Step: 8
Training loss: 2.5717490219836723
Validation loss: 2.4217547833751

Epoch: 5| Step: 9
Training loss: 3.228097915166506
Validation loss: 2.411543303223481

Epoch: 5| Step: 10
Training loss: 2.9539490211132517
Validation loss: 2.4228549399810357

Epoch: 33| Step: 0
Training loss: 2.958426263630112
Validation loss: 2.4220560133892763

Epoch: 5| Step: 1
Training loss: 2.6236537024067386
Validation loss: 2.4105854267579843

Epoch: 5| Step: 2
Training loss: 3.14496036231651
Validation loss: 2.417136092274707

Epoch: 5| Step: 3
Training loss: 2.5343091398776285
Validation loss: 2.424163272957815

Epoch: 5| Step: 4
Training loss: 2.727365894604715
Validation loss: 2.4139105232630236

Epoch: 5| Step: 5
Training loss: 2.677648630584919
Validation loss: 2.422316734208606

Epoch: 5| Step: 6
Training loss: 3.0109870308730073
Validation loss: 2.418872144770909

Epoch: 5| Step: 7
Training loss: 3.111873830292086
Validation loss: 2.4219789851184133

Epoch: 5| Step: 8
Training loss: 2.665233544857338
Validation loss: 2.4158478588427696

Epoch: 5| Step: 9
Training loss: 2.6237188573463848
Validation loss: 2.4255068832902067

Epoch: 5| Step: 10
Training loss: 2.5359230703905844
Validation loss: 2.419092896066821

Epoch: 34| Step: 0
Training loss: 3.0948029855071555
Validation loss: 2.4116326462687385

Epoch: 5| Step: 1
Training loss: 2.633679798930515
Validation loss: 2.4194374830220235

Epoch: 5| Step: 2
Training loss: 2.3795377647896365
Validation loss: 2.423646536320775

Epoch: 5| Step: 3
Training loss: 3.1780370229361443
Validation loss: 2.412354353441606

Epoch: 5| Step: 4
Training loss: 2.809238322734199
Validation loss: 2.4203104449450734

Epoch: 5| Step: 5
Training loss: 3.0774818949162963
Validation loss: 2.4264008627009424

Epoch: 5| Step: 6
Training loss: 2.7494782039474206
Validation loss: 2.4195459520405183

Epoch: 5| Step: 7
Training loss: 2.71909040753487
Validation loss: 2.420086174429531

Epoch: 5| Step: 8
Training loss: 3.0606165173852964
Validation loss: 2.4049593720794893

Epoch: 5| Step: 9
Training loss: 2.413720856722257
Validation loss: 2.423149100305492

Epoch: 5| Step: 10
Training loss: 2.4022447022899596
Validation loss: 2.4227053232136826

Epoch: 35| Step: 0
Training loss: 2.404592265027286
Validation loss: 2.426532129464358

Epoch: 5| Step: 1
Training loss: 2.5481921575480824
Validation loss: 2.417307124563184

Epoch: 5| Step: 2
Training loss: 2.8122889121631998
Validation loss: 2.4161540058031026

Epoch: 5| Step: 3
Training loss: 2.920128938101316
Validation loss: 2.4117022270321917

Epoch: 5| Step: 4
Training loss: 2.9822650261125556
Validation loss: 2.4108535646826685

Epoch: 5| Step: 5
Training loss: 2.970839397607921
Validation loss: 2.4229781873074128

Epoch: 5| Step: 6
Training loss: 3.1605266641591303
Validation loss: 2.417113062062162

Epoch: 5| Step: 7
Training loss: 2.368807499572673
Validation loss: 2.4147221957167475

Epoch: 5| Step: 8
Training loss: 2.817344054380287
Validation loss: 2.422054925825104

Epoch: 5| Step: 9
Training loss: 2.829392628548462
Validation loss: 2.4216448983855923

Epoch: 5| Step: 10
Training loss: 2.8428356670984263
Validation loss: 2.4199595889842382

Epoch: 36| Step: 0
Training loss: 3.0056755103874195
Validation loss: 2.4084756352348062

Epoch: 5| Step: 1
Training loss: 2.1486827363586927
Validation loss: 2.4223142354607847

Epoch: 5| Step: 2
Training loss: 2.558812442198405
Validation loss: 2.4201387282095497

Epoch: 5| Step: 3
Training loss: 2.7183208784624586
Validation loss: 2.411246822265371

Epoch: 5| Step: 4
Training loss: 2.8649785734377358
Validation loss: 2.4098624749444624

Epoch: 5| Step: 5
Training loss: 2.771109966341401
Validation loss: 2.403451349719839

Epoch: 5| Step: 6
Training loss: 2.8680408673427316
Validation loss: 2.4132936185548926

Epoch: 5| Step: 7
Training loss: 2.2342642376529205
Validation loss: 2.4139864496388275

Epoch: 5| Step: 8
Training loss: 3.257850848001969
Validation loss: 2.408272953882516

Epoch: 5| Step: 9
Training loss: 2.768578455585806
Validation loss: 2.408958241687429

Epoch: 5| Step: 10
Training loss: 3.3567349728172426
Validation loss: 2.418250886088621

Epoch: 37| Step: 0
Training loss: 2.9465992997813055
Validation loss: 2.418852358358105

Epoch: 5| Step: 1
Training loss: 2.917267619393048
Validation loss: 2.418916033273931

Epoch: 5| Step: 2
Training loss: 2.453572226413368
Validation loss: 2.4196064264134947

Epoch: 5| Step: 3
Training loss: 2.701309299903722
Validation loss: 2.4142976704657872

Epoch: 5| Step: 4
Training loss: 3.020464714623423
Validation loss: 2.417598806264231

Epoch: 5| Step: 5
Training loss: 2.9497926671504904
Validation loss: 2.418708201681554

Epoch: 5| Step: 6
Training loss: 2.4209781093497993
Validation loss: 2.418555140475528

Epoch: 5| Step: 7
Training loss: 3.008606327875552
Validation loss: 2.4082287761401058

Epoch: 5| Step: 8
Training loss: 3.185608695416771
Validation loss: 2.4149573083102474

Epoch: 5| Step: 9
Training loss: 2.367410277909217
Validation loss: 2.424715671208202

Epoch: 5| Step: 10
Training loss: 2.528432526056086
Validation loss: 2.4161343621240454

Epoch: 38| Step: 0
Training loss: 2.6123269566807816
Validation loss: 2.4150835487627305

Epoch: 5| Step: 1
Training loss: 2.445643198485191
Validation loss: 2.4089981854640357

Epoch: 5| Step: 2
Training loss: 2.7897138930164354
Validation loss: 2.416746497471119

Epoch: 5| Step: 3
Training loss: 2.82375406792674
Validation loss: 2.408967091652528

Epoch: 5| Step: 4
Training loss: 2.578009400521504
Validation loss: 2.4186530183630732

Epoch: 5| Step: 5
Training loss: 2.5486562853651717
Validation loss: 2.415347793521189

Epoch: 5| Step: 6
Training loss: 3.0369361950725757
Validation loss: 2.4211439327981408

Epoch: 5| Step: 7
Training loss: 2.3069440753509554
Validation loss: 2.414613696868487

Epoch: 5| Step: 8
Training loss: 2.7512446967857653
Validation loss: 2.413610884256306

Epoch: 5| Step: 9
Training loss: 3.032911179758517
Validation loss: 2.4098668727392853

Epoch: 5| Step: 10
Training loss: 3.550256268559881
Validation loss: 2.4124299770477227

Epoch: 39| Step: 0
Training loss: 2.7658234433461555
Validation loss: 2.4137238152319758

Epoch: 5| Step: 1
Training loss: 2.6366999420625503
Validation loss: 2.408031417348263

Epoch: 5| Step: 2
Training loss: 2.3983772593335644
Validation loss: 2.40349347134697

Epoch: 5| Step: 3
Training loss: 3.1006389943787256
Validation loss: 2.4138251771818573

Epoch: 5| Step: 4
Training loss: 3.322459381750782
Validation loss: 2.410372994249982

Epoch: 5| Step: 5
Training loss: 2.4745039702911806
Validation loss: 2.4119227895469137

Epoch: 5| Step: 6
Training loss: 2.1213636138828034
Validation loss: 2.4112250222883946

Epoch: 5| Step: 7
Training loss: 2.7232273110428853
Validation loss: 2.404248930551846

Epoch: 5| Step: 8
Training loss: 2.792340572112668
Validation loss: 2.412089259964804

Epoch: 5| Step: 9
Training loss: 3.321645096783643
Validation loss: 2.4033468627116505

Epoch: 5| Step: 10
Training loss: 2.5341523097328937
Validation loss: 2.415432437312573

Epoch: 40| Step: 0
Training loss: 2.765185218801989
Validation loss: 2.411857165005858

Epoch: 5| Step: 1
Training loss: 2.8324154507710557
Validation loss: 2.408772563710613

Epoch: 5| Step: 2
Training loss: 3.14795584579582
Validation loss: 2.4046754206573553

Epoch: 5| Step: 3
Training loss: 2.349105717559712
Validation loss: 2.4101427996993023

Epoch: 5| Step: 4
Training loss: 2.4537700606782926
Validation loss: 2.4063248363673426

Epoch: 5| Step: 5
Training loss: 2.892517954672542
Validation loss: 2.4100654140712954

Epoch: 5| Step: 6
Training loss: 2.925141003462349
Validation loss: 2.406706535627916

Epoch: 5| Step: 7
Training loss: 3.250082161671792
Validation loss: 2.4145187624819435

Epoch: 5| Step: 8
Training loss: 2.803530483623715
Validation loss: 2.4074650352205964

Epoch: 5| Step: 9
Training loss: 2.587279372092502
Validation loss: 2.4180688372300545

Epoch: 5| Step: 10
Training loss: 2.2836737102926477
Validation loss: 2.4109933715366614

Epoch: 41| Step: 0
Training loss: 2.17755427278665
Validation loss: 2.413819106407371

Epoch: 5| Step: 1
Training loss: 2.940763567944358
Validation loss: 2.4126361653137622

Epoch: 5| Step: 2
Training loss: 3.349413914441072
Validation loss: 2.41036217010393

Epoch: 5| Step: 3
Training loss: 1.9505582499427383
Validation loss: 2.409726077619432

Epoch: 5| Step: 4
Training loss: 3.0059390091587397
Validation loss: 2.419841942716842

Epoch: 5| Step: 5
Training loss: 2.792037616585636
Validation loss: 2.404008540263726

Epoch: 5| Step: 6
Training loss: 2.531488666350076
Validation loss: 2.413273922379248

Epoch: 5| Step: 7
Training loss: 3.0728524066650147
Validation loss: 2.402533311665752

Epoch: 5| Step: 8
Training loss: 2.8499629302709284
Validation loss: 2.4072021222214968

Epoch: 5| Step: 9
Training loss: 3.018718496596583
Validation loss: 2.402465443730712

Epoch: 5| Step: 10
Training loss: 2.474322825568522
Validation loss: 2.4128719258222286

Epoch: 42| Step: 0
Training loss: 2.7512401038845034
Validation loss: 2.4103368192680112

Epoch: 5| Step: 1
Training loss: 2.5549848191021183
Validation loss: 2.4198213050331754

Epoch: 5| Step: 2
Training loss: 2.624834146255554
Validation loss: 2.4086195826471877

Epoch: 5| Step: 3
Training loss: 3.2291460754394308
Validation loss: 2.4115751313453355

Epoch: 5| Step: 4
Training loss: 2.870306080835398
Validation loss: 2.4159092757662317

Epoch: 5| Step: 5
Training loss: 2.9524286650099874
Validation loss: 2.4197854111476493

Epoch: 5| Step: 6
Training loss: 2.9930826546331493
Validation loss: 2.4061892496065074

Epoch: 5| Step: 7
Training loss: 2.6843180782513554
Validation loss: 2.399985518740817

Epoch: 5| Step: 8
Training loss: 2.716863745189353
Validation loss: 2.4174823706837407

Epoch: 5| Step: 9
Training loss: 2.4491521652880923
Validation loss: 2.409372693996497

Epoch: 5| Step: 10
Training loss: 2.564484269940111
Validation loss: 2.4044785080135944

Epoch: 43| Step: 0
Training loss: 3.0139841942629033
Validation loss: 2.403674687254915

Epoch: 5| Step: 1
Training loss: 2.4885117739934843
Validation loss: 2.403426714252357

Epoch: 5| Step: 2
Training loss: 2.5621600972345746
Validation loss: 2.4123262689583513

Epoch: 5| Step: 3
Training loss: 2.9099612586729635
Validation loss: 2.400778317549712

Epoch: 5| Step: 4
Training loss: 2.577899899915032
Validation loss: 2.416860437598614

Epoch: 5| Step: 5
Training loss: 2.6385436573967325
Validation loss: 2.413885014277009

Epoch: 5| Step: 6
Training loss: 2.580106771167147
Validation loss: 2.4157401926737245

Epoch: 5| Step: 7
Training loss: 2.964762690344472
Validation loss: 2.4076401118137323

Epoch: 5| Step: 8
Training loss: 2.838887511483406
Validation loss: 2.4133529886820786

Epoch: 5| Step: 9
Training loss: 2.8300555473780222
Validation loss: 2.40783112933647

Epoch: 5| Step: 10
Training loss: 3.048510459758076
Validation loss: 2.407882640494946

Epoch: 44| Step: 0
Training loss: 2.560008722081823
Validation loss: 2.418581324699709

Epoch: 5| Step: 1
Training loss: 2.9939022081263325
Validation loss: 2.4145346145140913

Epoch: 5| Step: 2
Training loss: 2.9726501544985138
Validation loss: 2.4169025440399325

Epoch: 5| Step: 3
Training loss: 2.5412500905169666
Validation loss: 2.411457062210205

Epoch: 5| Step: 4
Training loss: 2.7250522048569192
Validation loss: 2.4003583826365595

Epoch: 5| Step: 5
Training loss: 2.906753004290888
Validation loss: 2.409166356249156

Epoch: 5| Step: 6
Training loss: 2.8384569814572664
Validation loss: 2.41028441925013

Epoch: 5| Step: 7
Training loss: 2.8461432813658494
Validation loss: 2.3983932789792393

Epoch: 5| Step: 8
Training loss: 2.3939347636577164
Validation loss: 2.4131682958273393

Epoch: 5| Step: 9
Training loss: 2.6084586721739904
Validation loss: 2.4195006037454383

Epoch: 5| Step: 10
Training loss: 2.9715068665344404
Validation loss: 2.402681393310065

Epoch: 45| Step: 0
Training loss: 2.9485994408735356
Validation loss: 2.404948106767483

Epoch: 5| Step: 1
Training loss: 3.0310075800595446
Validation loss: 2.404096797310949

Epoch: 5| Step: 2
Training loss: 2.2841475387861596
Validation loss: 2.41153125169422

Epoch: 5| Step: 3
Training loss: 2.7127769891325997
Validation loss: 2.415444792559547

Epoch: 5| Step: 4
Training loss: 3.2630327513229247
Validation loss: 2.402455511260539

Epoch: 5| Step: 5
Training loss: 2.8015727224339
Validation loss: 2.4131978036105557

Epoch: 5| Step: 6
Training loss: 2.6963013535067106
Validation loss: 2.391995547506916

Epoch: 5| Step: 7
Training loss: 2.085524042993758
Validation loss: 2.4028403463125856

Epoch: 5| Step: 8
Training loss: 3.14007077617211
Validation loss: 2.409678143315863

Epoch: 5| Step: 9
Training loss: 2.860494925884033
Validation loss: 2.412892472604183

Epoch: 5| Step: 10
Training loss: 2.249197074889049
Validation loss: 2.4108277633530792

Epoch: 46| Step: 0
Training loss: 2.4910846051611335
Validation loss: 2.4135865181857787

Epoch: 5| Step: 1
Training loss: 2.475566290602512
Validation loss: 2.4128367408380824

Epoch: 5| Step: 2
Training loss: 3.1506527663333364
Validation loss: 2.405607726165371

Epoch: 5| Step: 3
Training loss: 2.857434891353641
Validation loss: 2.4082548027833486

Epoch: 5| Step: 4
Training loss: 2.900192510857964
Validation loss: 2.3984354295795476

Epoch: 5| Step: 5
Training loss: 2.735666024743881
Validation loss: 2.4134472030559295

Epoch: 5| Step: 6
Training loss: 2.812564679567691
Validation loss: 2.4047339817197004

Epoch: 5| Step: 7
Training loss: 3.0735811883552278
Validation loss: 2.414160729409667

Epoch: 5| Step: 8
Training loss: 2.4738271149754176
Validation loss: 2.405956449103446

Epoch: 5| Step: 9
Training loss: 2.6192959164090808
Validation loss: 2.4087262622474532

Epoch: 5| Step: 10
Training loss: 2.586208179517406
Validation loss: 2.407449168052179

Epoch: 47| Step: 0
Training loss: 3.363595130442736
Validation loss: 2.3984449789380835

Epoch: 5| Step: 1
Training loss: 2.6212261865759325
Validation loss: 2.4071968771513927

Epoch: 5| Step: 2
Training loss: 2.4672968970041502
Validation loss: 2.4070160755267693

Epoch: 5| Step: 3
Training loss: 2.7525686925203985
Validation loss: 2.4123725236422007

Epoch: 5| Step: 4
Training loss: 2.720925874484808
Validation loss: 2.409698983833251

Epoch: 5| Step: 5
Training loss: 2.9353253045539414
Validation loss: 2.424991350588794

Epoch: 5| Step: 6
Training loss: 2.62651472439679
Validation loss: 2.410754113172984

Epoch: 5| Step: 7
Training loss: 2.4922148604370964
Validation loss: 2.408017118914476

Epoch: 5| Step: 8
Training loss: 3.153777409818834
Validation loss: 2.4178089286033706

Epoch: 5| Step: 9
Training loss: 2.6286252737453752
Validation loss: 2.41066913496261

Epoch: 5| Step: 10
Training loss: 2.4831580294321385
Validation loss: 2.40963551113498

Epoch: 48| Step: 0
Training loss: 3.10490318282539
Validation loss: 2.397755217347481

Epoch: 5| Step: 1
Training loss: 2.6791894744645792
Validation loss: 2.4204192646178964

Epoch: 5| Step: 2
Training loss: 2.6875246623482325
Validation loss: 2.410031106651342

Epoch: 5| Step: 3
Training loss: 2.8687985750627782
Validation loss: 2.4042477128416873

Epoch: 5| Step: 4
Training loss: 2.4528801668290865
Validation loss: 2.412754717580273

Epoch: 5| Step: 5
Training loss: 2.8203299144090996
Validation loss: 2.4092230465427122

Epoch: 5| Step: 6
Training loss: 2.649582066958319
Validation loss: 2.3958775463188937

Epoch: 5| Step: 7
Training loss: 2.4903634310921166
Validation loss: 2.406610986794226

Epoch: 5| Step: 8
Training loss: 3.041681019648998
Validation loss: 2.408114334986061

Epoch: 5| Step: 9
Training loss: 2.935027360154995
Validation loss: 2.4161018359317654

Epoch: 5| Step: 10
Training loss: 2.4598724482583316
Validation loss: 2.417647835842591

Epoch: 49| Step: 0
Training loss: 2.971061689919551
Validation loss: 2.4126844488745

Epoch: 5| Step: 1
Training loss: 2.9722933854786864
Validation loss: 2.4070405847930565

Epoch: 5| Step: 2
Training loss: 2.749346568764255
Validation loss: 2.405853607466147

Epoch: 5| Step: 3
Training loss: 2.6645891222817593
Validation loss: 2.4044777280925334

Epoch: 5| Step: 4
Training loss: 2.6520119460917093
Validation loss: 2.405593616341401

Epoch: 5| Step: 5
Training loss: 2.9853641807980793
Validation loss: 2.406942269303802

Epoch: 5| Step: 6
Training loss: 2.6038289779427743
Validation loss: 2.4027876851861576

Epoch: 5| Step: 7
Training loss: 2.619399681621275
Validation loss: 2.4112839011238756

Epoch: 5| Step: 8
Training loss: 3.0465381925221444
Validation loss: 2.4183723412005067

Epoch: 5| Step: 9
Training loss: 2.5321053837484646
Validation loss: 2.400034776750987

Epoch: 5| Step: 10
Training loss: 2.3609579472947084
Validation loss: 2.3991623088222624

Epoch: 50| Step: 0
Training loss: 2.9529862951573627
Validation loss: 2.4024634866915995

Epoch: 5| Step: 1
Training loss: 1.9840339307460042
Validation loss: 2.403776924086137

Epoch: 5| Step: 2
Training loss: 2.2783629032868067
Validation loss: 2.4083549658497145

Epoch: 5| Step: 3
Training loss: 2.8258566848688504
Validation loss: 2.404251602687739

Epoch: 5| Step: 4
Training loss: 2.7258574440415657
Validation loss: 2.4075567103827256

Epoch: 5| Step: 5
Training loss: 3.2405548764976615
Validation loss: 2.4015689582547592

Epoch: 5| Step: 6
Training loss: 2.6079014254996853
Validation loss: 2.399185422657978

Epoch: 5| Step: 7
Training loss: 2.674551175691735
Validation loss: 2.409912332106041

Epoch: 5| Step: 8
Training loss: 3.1433756914517654
Validation loss: 2.400978380278141

Epoch: 5| Step: 9
Training loss: 2.9319636340416593
Validation loss: 2.412039842118612

Epoch: 5| Step: 10
Training loss: 2.708217080384452
Validation loss: 2.4108080353341843

Epoch: 51| Step: 0
Training loss: 2.387205782831669
Validation loss: 2.4048216380797043

Epoch: 5| Step: 1
Training loss: 2.96535514673036
Validation loss: 2.4023737364880966

Epoch: 5| Step: 2
Training loss: 2.9640964375404586
Validation loss: 2.4005497371618967

Epoch: 5| Step: 3
Training loss: 2.532158865062344
Validation loss: 2.408300839733731

Epoch: 5| Step: 4
Training loss: 2.7834397171917917
Validation loss: 2.411975147594016

Epoch: 5| Step: 5
Training loss: 2.6333570511470112
Validation loss: 2.4073682598934383

Epoch: 5| Step: 6
Training loss: 2.6656777415810127
Validation loss: 2.395279955701232

Epoch: 5| Step: 7
Training loss: 2.9720158332002486
Validation loss: 2.402776285392694

Epoch: 5| Step: 8
Training loss: 2.2877112035753893
Validation loss: 2.4020343337482

Epoch: 5| Step: 9
Training loss: 3.188517389430422
Validation loss: 2.3972618388434204

Epoch: 5| Step: 10
Training loss: 2.6749743950589866
Validation loss: 2.4028460938087135

Epoch: 52| Step: 0
Training loss: 2.494695949642872
Validation loss: 2.3942002568183405

Epoch: 5| Step: 1
Training loss: 2.6835835330329982
Validation loss: 2.399179860868194

Epoch: 5| Step: 2
Training loss: 3.006859725060177
Validation loss: 2.4133285615820927

Epoch: 5| Step: 3
Training loss: 2.7738891233853327
Validation loss: 2.4070905451349436

Epoch: 5| Step: 4
Training loss: 2.678433939720336
Validation loss: 2.4045682297660176

Epoch: 5| Step: 5
Training loss: 2.5536579075516888
Validation loss: 2.4023067012304105

Epoch: 5| Step: 6
Training loss: 2.4507710041662523
Validation loss: 2.4072637384258866

Epoch: 5| Step: 7
Training loss: 2.8334253707597523
Validation loss: 2.3981542270020064

Epoch: 5| Step: 8
Training loss: 3.260773335571131
Validation loss: 2.4054112532735634

Epoch: 5| Step: 9
Training loss: 2.747357399236252
Validation loss: 2.400182813343807

Epoch: 5| Step: 10
Training loss: 2.548215267705542
Validation loss: 2.4119703412449476

Epoch: 53| Step: 0
Training loss: 2.417275867190799
Validation loss: 2.405864466814643

Epoch: 5| Step: 1
Training loss: 2.5928529773875364
Validation loss: 2.3948308451517515

Epoch: 5| Step: 2
Training loss: 2.51001507302428
Validation loss: 2.3937916402944226

Epoch: 5| Step: 3
Training loss: 2.602011610335089
Validation loss: 2.398180273185433

Epoch: 5| Step: 4
Training loss: 3.024708562005735
Validation loss: 2.4140142429401723

Epoch: 5| Step: 5
Training loss: 3.170342136054649
Validation loss: 2.4027573234937325

Epoch: 5| Step: 6
Training loss: 2.868240869758097
Validation loss: 2.4095592556167937

Epoch: 5| Step: 7
Training loss: 3.0606004701752743
Validation loss: 2.4011373488598355

Epoch: 5| Step: 8
Training loss: 2.251401570675517
Validation loss: 2.3954131654575774

Epoch: 5| Step: 9
Training loss: 2.5140749497754395
Validation loss: 2.3999248004483937

Epoch: 5| Step: 10
Training loss: 3.0432711684809206
Validation loss: 2.4002279445114825

Epoch: 54| Step: 0
Training loss: 2.508604596024562
Validation loss: 2.4107795425665732

Epoch: 5| Step: 1
Training loss: 2.7750698390111124
Validation loss: 2.4044668715437707

Epoch: 5| Step: 2
Training loss: 3.0151653038245194
Validation loss: 2.402585815644999

Epoch: 5| Step: 3
Training loss: 2.7110060097780107
Validation loss: 2.4150464496881305

Epoch: 5| Step: 4
Training loss: 2.669938484369058
Validation loss: 2.4058963295715534

Epoch: 5| Step: 5
Training loss: 2.7465482202780014
Validation loss: 2.409911047047381

Epoch: 5| Step: 6
Training loss: 2.617841132231579
Validation loss: 2.3996625730148464

Epoch: 5| Step: 7
Training loss: 2.621565797598858
Validation loss: 2.3992019797253077

Epoch: 5| Step: 8
Training loss: 2.721769213016743
Validation loss: 2.4018528152955256

Epoch: 5| Step: 9
Training loss: 2.838829058642724
Validation loss: 2.3990567363165125

Epoch: 5| Step: 10
Training loss: 2.8759400862500084
Validation loss: 2.399523578762017

Epoch: 55| Step: 0
Training loss: 3.0876975919068537
Validation loss: 2.407081427335411

Epoch: 5| Step: 1
Training loss: 2.7637534840534665
Validation loss: 2.4042135580597024

Epoch: 5| Step: 2
Training loss: 3.091211992609364
Validation loss: 2.407007806309008

Epoch: 5| Step: 3
Training loss: 2.0327755407892325
Validation loss: 2.4000392507689874

Epoch: 5| Step: 4
Training loss: 2.584932990764353
Validation loss: 2.3923701640817554

Epoch: 5| Step: 5
Training loss: 2.825882164606257
Validation loss: 2.410442549688788

Epoch: 5| Step: 6
Training loss: 2.9224640767522234
Validation loss: 2.404775889522325

Epoch: 5| Step: 7
Training loss: 2.6195086306702646
Validation loss: 2.4078510489037814

Epoch: 5| Step: 8
Training loss: 2.4615040929164795
Validation loss: 2.3985134747503487

Epoch: 5| Step: 9
Training loss: 2.355969731588177
Validation loss: 2.3926301166911754

Epoch: 5| Step: 10
Training loss: 3.1533644676956527
Validation loss: 2.4029857888384556

Epoch: 56| Step: 0
Training loss: 2.7551448552703994
Validation loss: 2.396545226456326

Epoch: 5| Step: 1
Training loss: 2.6684066837513574
Validation loss: 2.4001237978333965

Epoch: 5| Step: 2
Training loss: 2.8090247830213992
Validation loss: 2.403662835715635

Epoch: 5| Step: 3
Training loss: 2.727498066147102
Validation loss: 2.409835791200166

Epoch: 5| Step: 4
Training loss: 2.7992058104488295
Validation loss: 2.3975582094966286

Epoch: 5| Step: 5
Training loss: 2.6422670213676422
Validation loss: 2.395675832342884

Epoch: 5| Step: 6
Training loss: 2.6300965741778293
Validation loss: 2.40103446096828

Epoch: 5| Step: 7
Training loss: 2.8039504759056975
Validation loss: 2.4021340966418276

Epoch: 5| Step: 8
Training loss: 3.3982253435933063
Validation loss: 2.3941303376516188

Epoch: 5| Step: 9
Training loss: 2.498600568095901
Validation loss: 2.4089417016582773

Epoch: 5| Step: 10
Training loss: 2.077610611891645
Validation loss: 2.399011745546396

Epoch: 57| Step: 0
Training loss: 3.0671256806823344
Validation loss: 2.4006969234753037

Epoch: 5| Step: 1
Training loss: 2.506175995683043
Validation loss: 2.4109021609474026

Epoch: 5| Step: 2
Training loss: 2.5395206918310946
Validation loss: 2.405161014157623

Epoch: 5| Step: 3
Training loss: 2.4721733212248247
Validation loss: 2.4060239777608814

Epoch: 5| Step: 4
Training loss: 2.7833917493648155
Validation loss: 2.4005053542755763

Epoch: 5| Step: 5
Training loss: 3.205922761097352
Validation loss: 2.408949684348988

Epoch: 5| Step: 6
Training loss: 2.5792112894054897
Validation loss: 2.395268073328625

Epoch: 5| Step: 7
Training loss: 3.2539257401595916
Validation loss: 2.3992542841341455

Epoch: 5| Step: 8
Training loss: 2.2580744713462733
Validation loss: 2.404153333096537

Epoch: 5| Step: 9
Training loss: 2.289466587893363
Validation loss: 2.402136756188993

Epoch: 5| Step: 10
Training loss: 2.935287941320564
Validation loss: 2.3953642811789937

Epoch: 58| Step: 0
Training loss: 2.757559529662297
Validation loss: 2.4056865307811734

Epoch: 5| Step: 1
Training loss: 2.7691626041125024
Validation loss: 2.4002708735536378

Epoch: 5| Step: 2
Training loss: 2.910620735530666
Validation loss: 2.394870032230505

Epoch: 5| Step: 3
Training loss: 2.507865548686876
Validation loss: 2.4104031871598464

Epoch: 5| Step: 4
Training loss: 2.590694972290857
Validation loss: 2.4060094910544585

Epoch: 5| Step: 5
Training loss: 2.4829679139207697
Validation loss: 2.395701413225478

Epoch: 5| Step: 6
Training loss: 2.9445644410191556
Validation loss: 2.3957897697721933

Epoch: 5| Step: 7
Training loss: 2.5312520721803824
Validation loss: 2.405428930245551

Epoch: 5| Step: 8
Training loss: 2.5742234735054823
Validation loss: 2.390420793313851

Epoch: 5| Step: 9
Training loss: 2.67086344526895
Validation loss: 2.3977339650902145

Epoch: 5| Step: 10
Training loss: 3.1542091947953055
Validation loss: 2.410204788527378

Epoch: 59| Step: 0
Training loss: 2.9443273541023314
Validation loss: 2.3886617359914837

Epoch: 5| Step: 1
Training loss: 2.604942806296977
Validation loss: 2.3905634278645578

Epoch: 5| Step: 2
Training loss: 2.795384100247016
Validation loss: 2.4096096988907103

Epoch: 5| Step: 3
Training loss: 2.9319075247530595
Validation loss: 2.4033624252234693

Epoch: 5| Step: 4
Training loss: 2.8776385597256513
Validation loss: 2.4039506307131333

Epoch: 5| Step: 5
Training loss: 2.2197845625946444
Validation loss: 2.3954354689260944

Epoch: 5| Step: 6
Training loss: 2.6670615579361496
Validation loss: 2.3934482828233237

Epoch: 5| Step: 7
Training loss: 2.5927475060497027
Validation loss: 2.408300831217716

Epoch: 5| Step: 8
Training loss: 2.7768620369707575
Validation loss: 2.3987599229264585

Epoch: 5| Step: 9
Training loss: 2.801584551544123
Validation loss: 2.3976298426659834

Epoch: 5| Step: 10
Training loss: 2.675370545436539
Validation loss: 2.3954223084064714

Epoch: 60| Step: 0
Training loss: 2.9087620205173876
Validation loss: 2.3912840793987202

Epoch: 5| Step: 1
Training loss: 2.7239454766305
Validation loss: 2.40947375221723

Epoch: 5| Step: 2
Training loss: 2.0365242195365694
Validation loss: 2.402890831946739

Epoch: 5| Step: 3
Training loss: 2.527958743519274
Validation loss: 2.4078369362549847

Epoch: 5| Step: 4
Training loss: 3.326355512996218
Validation loss: 2.405272010870514

Epoch: 5| Step: 5
Training loss: 2.462445865558897
Validation loss: 2.402216663962546

Epoch: 5| Step: 6
Training loss: 2.5193853291683297
Validation loss: 2.3990465824237344

Epoch: 5| Step: 7
Training loss: 3.0396294935214954
Validation loss: 2.408772199722258

Epoch: 5| Step: 8
Training loss: 2.499244957393265
Validation loss: 2.40717148126556

Epoch: 5| Step: 9
Training loss: 2.9433780054465952
Validation loss: 2.3912642458921747

Epoch: 5| Step: 10
Training loss: 2.78550557517961
Validation loss: 2.3920542619827967

Epoch: 61| Step: 0
Training loss: 3.181567786631713
Validation loss: 2.405923845517587

Epoch: 5| Step: 1
Training loss: 2.8356378570392966
Validation loss: 2.3946158898306185

Epoch: 5| Step: 2
Training loss: 2.054724863387113
Validation loss: 2.3948654688052273

Epoch: 5| Step: 3
Training loss: 2.228134510506855
Validation loss: 2.405980410827089

Epoch: 5| Step: 4
Training loss: 3.338033334930162
Validation loss: 2.4066758777101382

Epoch: 5| Step: 5
Training loss: 3.0723994105287455
Validation loss: 2.4021453879574186

Epoch: 5| Step: 6
Training loss: 2.7470650182972003
Validation loss: 2.400893116925239

Epoch: 5| Step: 7
Training loss: 3.210225344202348
Validation loss: 2.4018141589558697

Epoch: 5| Step: 8
Training loss: 2.170605075523961
Validation loss: 2.404705236279269

Epoch: 5| Step: 9
Training loss: 2.3990885195824854
Validation loss: 2.4030799402669865

Epoch: 5| Step: 10
Training loss: 2.0801316518567754
Validation loss: 2.3873268285836495

Epoch: 62| Step: 0
Training loss: 2.0216102155502043
Validation loss: 2.4161563252395815

Epoch: 5| Step: 1
Training loss: 2.9210167914733622
Validation loss: 2.399698798338077

Epoch: 5| Step: 2
Training loss: 3.2918403837181174
Validation loss: 2.400889549448759

Epoch: 5| Step: 3
Training loss: 2.5440783914328136
Validation loss: 2.3922840302469446

Epoch: 5| Step: 4
Training loss: 2.2050414711648587
Validation loss: 2.3953262270378297

Epoch: 5| Step: 5
Training loss: 2.7176198254569295
Validation loss: 2.411456045878211

Epoch: 5| Step: 6
Training loss: 3.0248974175832566
Validation loss: 2.397796738734379

Epoch: 5| Step: 7
Training loss: 2.4231511845230416
Validation loss: 2.3941410777761205

Epoch: 5| Step: 8
Training loss: 2.600631776492369
Validation loss: 2.403358249665143

Epoch: 5| Step: 9
Training loss: 2.6203717802253865
Validation loss: 2.405297892046752

Epoch: 5| Step: 10
Training loss: 3.3587235639729287
Validation loss: 2.3910997479532923

Epoch: 63| Step: 0
Training loss: 2.634811502768433
Validation loss: 2.400456608940611

Epoch: 5| Step: 1
Training loss: 2.3735443472905002
Validation loss: 2.4030320867572477

Epoch: 5| Step: 2
Training loss: 2.8297473616774362
Validation loss: 2.400650567706824

Epoch: 5| Step: 3
Training loss: 2.903069673633112
Validation loss: 2.40077593840703

Epoch: 5| Step: 4
Training loss: 2.6005984974642717
Validation loss: 2.4042444936907574

Epoch: 5| Step: 5
Training loss: 2.6881753826940975
Validation loss: 2.3929236750207714

Epoch: 5| Step: 6
Training loss: 2.6445336841927034
Validation loss: 2.3926171593226564

Epoch: 5| Step: 7
Training loss: 2.815838929918035
Validation loss: 2.4004396707115343

Epoch: 5| Step: 8
Training loss: 2.790532000146487
Validation loss: 2.3969660962622115

Epoch: 5| Step: 9
Training loss: 2.8098814748562755
Validation loss: 2.405808191820392

Epoch: 5| Step: 10
Training loss: 2.821378638462024
Validation loss: 2.41370526275111

Epoch: 64| Step: 0
Training loss: 2.5362321777620007
Validation loss: 2.3984387163845433

Epoch: 5| Step: 1
Training loss: 2.8843255763091946
Validation loss: 2.3925003073256836

Epoch: 5| Step: 2
Training loss: 2.655959618347616
Validation loss: 2.4021060612923697

Epoch: 5| Step: 3
Training loss: 3.0320354899037927
Validation loss: 2.3977431916744063

Epoch: 5| Step: 4
Training loss: 2.558308779156511
Validation loss: 2.397984678836079

Epoch: 5| Step: 5
Training loss: 2.8570724138022756
Validation loss: 2.393307812580061

Epoch: 5| Step: 6
Training loss: 2.8910832222327976
Validation loss: 2.387734896913887

Epoch: 5| Step: 7
Training loss: 2.1628308699078094
Validation loss: 2.396118952421896

Epoch: 5| Step: 8
Training loss: 2.689822856501731
Validation loss: 2.394936774141586

Epoch: 5| Step: 9
Training loss: 2.7080414443570593
Validation loss: 2.410496034263077

Epoch: 5| Step: 10
Training loss: 2.610008117253919
Validation loss: 2.3884438265228765

Epoch: 65| Step: 0
Training loss: 2.646219680893546
Validation loss: 2.400614271846949

Epoch: 5| Step: 1
Training loss: 2.465227825631799
Validation loss: 2.3977935622427067

Epoch: 5| Step: 2
Training loss: 3.3265166358778324
Validation loss: 2.4030558098676185

Epoch: 5| Step: 3
Training loss: 2.2417028880354146
Validation loss: 2.395456293157558

Epoch: 5| Step: 4
Training loss: 2.2626452615377706
Validation loss: 2.3728883592523893

Epoch: 5| Step: 5
Training loss: 2.3707233874991407
Validation loss: 2.392598244819149

Epoch: 5| Step: 6
Training loss: 2.519158292860154
Validation loss: 2.4033789497817124

Epoch: 5| Step: 7
Training loss: 2.585992357300265
Validation loss: 2.3939868982954615

Epoch: 5| Step: 8
Training loss: 3.1743645880750533
Validation loss: 2.4004738161793173

Epoch: 5| Step: 9
Training loss: 2.972556474692997
Validation loss: 2.3936492484466805

Epoch: 5| Step: 10
Training loss: 2.9574424225981812
Validation loss: 2.4023052109439056

Epoch: 66| Step: 0
Training loss: 2.602944863121234
Validation loss: 2.3979213584514096

Epoch: 5| Step: 1
Training loss: 2.6684066837513574
Validation loss: 2.3936095583448895

Epoch: 5| Step: 2
Training loss: 2.6628671240780313
Validation loss: 2.4052288507983888

Epoch: 5| Step: 3
Training loss: 2.746427122367634
Validation loss: 2.406038370083084

Epoch: 5| Step: 4
Training loss: 2.9995442680072024
Validation loss: 2.4038109736238638

Epoch: 5| Step: 5
Training loss: 2.3745408869243625
Validation loss: 2.3913421702568485

Epoch: 5| Step: 6
Training loss: 2.4663945804062504
Validation loss: 2.4049089410627014

Epoch: 5| Step: 7
Training loss: 2.5974276105029332
Validation loss: 2.4044971940575928

Epoch: 5| Step: 8
Training loss: 2.579952909793927
Validation loss: 2.4113341552240937

Epoch: 5| Step: 9
Training loss: 3.158565163135076
Validation loss: 2.3893554037940703

Epoch: 5| Step: 10
Training loss: 2.829282070796903
Validation loss: 2.399574319007569

Epoch: 67| Step: 0
Training loss: 2.408077685329176
Validation loss: 2.3983250528457276

Epoch: 5| Step: 1
Training loss: 2.816390250447576
Validation loss: 2.392115840756323

Epoch: 5| Step: 2
Training loss: 2.7500514979308974
Validation loss: 2.3906874445106143

Epoch: 5| Step: 3
Training loss: 2.7169382482256808
Validation loss: 2.3946754007882944

Epoch: 5| Step: 4
Training loss: 2.69630179562821
Validation loss: 2.3972141664921054

Epoch: 5| Step: 5
Training loss: 2.8023493379356923
Validation loss: 2.386267934711911

Epoch: 5| Step: 6
Training loss: 2.91166346901549
Validation loss: 2.3987484756698554

Epoch: 5| Step: 7
Training loss: 3.09415964824587
Validation loss: 2.407568338307424

Epoch: 5| Step: 8
Training loss: 2.441452538623688
Validation loss: 2.3982794973059116

Epoch: 5| Step: 9
Training loss: 2.921501258161706
Validation loss: 2.3917845904855284

Epoch: 5| Step: 10
Training loss: 1.926248056657072
Validation loss: 2.397112636345738

Epoch: 68| Step: 0
Training loss: 3.2580216521309975
Validation loss: 2.412442339170307

Epoch: 5| Step: 1
Training loss: 2.741048375206273
Validation loss: 2.3989907079950985

Epoch: 5| Step: 2
Training loss: 2.963457549945602
Validation loss: 2.3898425879831287

Epoch: 5| Step: 3
Training loss: 2.622507728732551
Validation loss: 2.394114066753074

Epoch: 5| Step: 4
Training loss: 2.8887608471233057
Validation loss: 2.399207982769317

Epoch: 5| Step: 5
Training loss: 2.665695987306265
Validation loss: 2.40826896620921

Epoch: 5| Step: 6
Training loss: 2.9718764055411206
Validation loss: 2.4083926587171756

Epoch: 5| Step: 7
Training loss: 2.5233730626810527
Validation loss: 2.4127361528661804

Epoch: 5| Step: 8
Training loss: 1.9909962402262267
Validation loss: 2.3909609474990092

Epoch: 5| Step: 9
Training loss: 2.400106340277679
Validation loss: 2.3962780101513017

Epoch: 5| Step: 10
Training loss: 2.3888518296060672
Validation loss: 2.399299551370586

Epoch: 69| Step: 0
Training loss: 3.0968960265707417
Validation loss: 2.3927429991572295

Epoch: 5| Step: 1
Training loss: 3.1701962392818275
Validation loss: 2.3994574687315606

Epoch: 5| Step: 2
Training loss: 2.575103283634798
Validation loss: 2.4031686346583623

Epoch: 5| Step: 3
Training loss: 2.673929863186117
Validation loss: 2.399900779330954

Epoch: 5| Step: 4
Training loss: 2.7698514723636496
Validation loss: 2.3920939532409533

Epoch: 5| Step: 5
Training loss: 2.290199908563727
Validation loss: 2.4042232732044155

Epoch: 5| Step: 6
Training loss: 2.8876226556001483
Validation loss: 2.388054128290324

Epoch: 5| Step: 7
Training loss: 2.555401436908429
Validation loss: 2.4136996037779417

Epoch: 5| Step: 8
Training loss: 2.746767658657753
Validation loss: 2.3823685061440742

Epoch: 5| Step: 9
Training loss: 2.400433433653822
Validation loss: 2.397126156550431

Epoch: 5| Step: 10
Training loss: 2.417771536282979
Validation loss: 2.4152108185982883

Epoch: 70| Step: 0
Training loss: 2.895191112264972
Validation loss: 2.39513218925102

Epoch: 5| Step: 1
Training loss: 3.0326608736870795
Validation loss: 2.390500599402351

Epoch: 5| Step: 2
Training loss: 2.616334873067625
Validation loss: 2.3936913251479717

Epoch: 5| Step: 3
Training loss: 2.766440492217167
Validation loss: 2.390758448750114

Epoch: 5| Step: 4
Training loss: 2.970617249179956
Validation loss: 2.3924538120289514

Epoch: 5| Step: 5
Training loss: 2.454800173518557
Validation loss: 2.3901143642270357

Epoch: 5| Step: 6
Training loss: 2.3606804274156428
Validation loss: 2.3988220156735247

Epoch: 5| Step: 7
Training loss: 2.3434831594517664
Validation loss: 2.4000899988052424

Epoch: 5| Step: 8
Training loss: 2.19289735053377
Validation loss: 2.3896680666384627

Epoch: 5| Step: 9
Training loss: 3.0621937189896444
Validation loss: 2.3903558466830104

Epoch: 5| Step: 10
Training loss: 2.837620427605163
Validation loss: 2.3962299796149913

Epoch: 71| Step: 0
Training loss: 2.6082161711520357
Validation loss: 2.3908179281231083

Epoch: 5| Step: 1
Training loss: 2.7452654396500464
Validation loss: 2.3918399456747244

Epoch: 5| Step: 2
Training loss: 2.8070297449300603
Validation loss: 2.392894004008559

Epoch: 5| Step: 3
Training loss: 2.666646112919116
Validation loss: 2.385581091522019

Epoch: 5| Step: 4
Training loss: 2.7446240851090686
Validation loss: 2.404860883026098

Epoch: 5| Step: 5
Training loss: 2.780328576546447
Validation loss: 2.388343534712375

Epoch: 5| Step: 6
Training loss: 2.908682184875533
Validation loss: 2.39999958462609

Epoch: 5| Step: 7
Training loss: 2.67546598707325
Validation loss: 2.390627494337258

Epoch: 5| Step: 8
Training loss: 2.801185908539749
Validation loss: 2.392232334311626

Epoch: 5| Step: 9
Training loss: 2.15922904508121
Validation loss: 2.3950605953762443

Epoch: 5| Step: 10
Training loss: 2.6447742975923445
Validation loss: 2.392009120213158

Epoch: 72| Step: 0
Training loss: 3.0257263194366795
Validation loss: 2.407502161142868

Epoch: 5| Step: 1
Training loss: 3.3024612034057266
Validation loss: 2.4007861618696995

Epoch: 5| Step: 2
Training loss: 3.156188208853298
Validation loss: 2.3909737186996805

Epoch: 5| Step: 3
Training loss: 2.6141630546715926
Validation loss: 2.400171618538139

Epoch: 5| Step: 4
Training loss: 2.095783896902801
Validation loss: 2.3947012460774775

Epoch: 5| Step: 5
Training loss: 2.605353631674891
Validation loss: 2.3935427076641447

Epoch: 5| Step: 6
Training loss: 2.6233324476318933
Validation loss: 2.3934491536336404

Epoch: 5| Step: 7
Training loss: 2.5343310595747246
Validation loss: 2.3922669677112056

Epoch: 5| Step: 8
Training loss: 2.5607003195823177
Validation loss: 2.382328550623015

Epoch: 5| Step: 9
Training loss: 2.6101827684623604
Validation loss: 2.393930138479633

Epoch: 5| Step: 10
Training loss: 2.288577396170053
Validation loss: 2.3968778686446375

Epoch: 73| Step: 0
Training loss: 3.022666970966303
Validation loss: 2.398720293875178

Epoch: 5| Step: 1
Training loss: 2.5125314397410543
Validation loss: 2.3882879444481353

Epoch: 5| Step: 2
Training loss: 2.729865142509619
Validation loss: 2.398152955953844

Epoch: 5| Step: 3
Training loss: 2.8770709664320466
Validation loss: 2.3808784746896627

Epoch: 5| Step: 4
Training loss: 2.7008853520420835
Validation loss: 2.391631458571134

Epoch: 5| Step: 5
Training loss: 2.5346787389454044
Validation loss: 2.401465957548608

Epoch: 5| Step: 6
Training loss: 2.759132652829625
Validation loss: 2.3934924131205353

Epoch: 5| Step: 7
Training loss: 2.157361393760576
Validation loss: 2.403508475598359

Epoch: 5| Step: 8
Training loss: 2.6717653307799263
Validation loss: 2.3885572277487195

Epoch: 5| Step: 9
Training loss: 2.6625250801731934
Validation loss: 2.396993420602655

Epoch: 5| Step: 10
Training loss: 2.743444953245247
Validation loss: 2.4004697087525866

Epoch: 74| Step: 0
Training loss: 2.8422797458101097
Validation loss: 2.389201703075673

Epoch: 5| Step: 1
Training loss: 2.6262837858355437
Validation loss: 2.3870013115573467

Epoch: 5| Step: 2
Training loss: 2.6225361841721995
Validation loss: 2.4010539553826535

Epoch: 5| Step: 3
Training loss: 2.5096157162792863
Validation loss: 2.3956091859319404

Epoch: 5| Step: 4
Training loss: 2.3644576746507524
Validation loss: 2.395917561581102

Epoch: 5| Step: 5
Training loss: 2.3877719983851
Validation loss: 2.3873105832639787

Epoch: 5| Step: 6
Training loss: 2.717080052836001
Validation loss: 2.3967244642201346

Epoch: 5| Step: 7
Training loss: 2.654169861348943
Validation loss: 2.389866791724011

Epoch: 5| Step: 8
Training loss: 2.78003263083868
Validation loss: 2.407993394111722

Epoch: 5| Step: 9
Training loss: 2.9422473287551636
Validation loss: 2.394863507696502

Epoch: 5| Step: 10
Training loss: 2.9929387914820618
Validation loss: 2.4062007339136833

Epoch: 75| Step: 0
Training loss: 2.723546061975615
Validation loss: 2.4009625690089345

Epoch: 5| Step: 1
Training loss: 2.9802285993825435
Validation loss: 2.3932005453084875

Epoch: 5| Step: 2
Training loss: 2.279895746290307
Validation loss: 2.3917924107096296

Epoch: 5| Step: 3
Training loss: 2.8460050591579997
Validation loss: 2.403342922866514

Epoch: 5| Step: 4
Training loss: 2.5054173901119823
Validation loss: 2.3922824935306495

Epoch: 5| Step: 5
Training loss: 2.3291778232077522
Validation loss: 2.387097808553033

Epoch: 5| Step: 6
Training loss: 2.4634905454292766
Validation loss: 2.399762582999497

Epoch: 5| Step: 7
Training loss: 2.940893283001264
Validation loss: 2.389836342577947

Epoch: 5| Step: 8
Training loss: 3.0236217038524864
Validation loss: 2.4097989007003666

Epoch: 5| Step: 9
Training loss: 2.5763816719148314
Validation loss: 2.4029692871812816

Epoch: 5| Step: 10
Training loss: 2.666862649471059
Validation loss: 2.384144436009365

Epoch: 76| Step: 0
Training loss: 2.6096620687315197
Validation loss: 2.4013563088816094

Epoch: 5| Step: 1
Training loss: 2.5302171837086673
Validation loss: 2.3940240517242137

Epoch: 5| Step: 2
Training loss: 2.667553803778103
Validation loss: 2.4062385500212113

Epoch: 5| Step: 3
Training loss: 2.636898594127053
Validation loss: 2.3982111359163802

Epoch: 5| Step: 4
Training loss: 2.7677453312945155
Validation loss: 2.4021347935459243

Epoch: 5| Step: 5
Training loss: 2.9612586015904054
Validation loss: 2.4001904791013304

Epoch: 5| Step: 6
Training loss: 2.4270959507255414
Validation loss: 2.390860595075323

Epoch: 5| Step: 7
Training loss: 2.7466585492813502
Validation loss: 2.3922267617145834

Epoch: 5| Step: 8
Training loss: 2.748745718931409
Validation loss: 2.3879531555716325

Epoch: 5| Step: 9
Training loss: 2.4045367396279183
Validation loss: 2.3777797495632194

Epoch: 5| Step: 10
Training loss: 2.9590456109587726
Validation loss: 2.3865347856581787

Epoch: 77| Step: 0
Training loss: 3.062401283385866
Validation loss: 2.4005983609991075

Epoch: 5| Step: 1
Training loss: 2.3768718771421233
Validation loss: 2.384780038655331

Epoch: 5| Step: 2
Training loss: 2.466257309668372
Validation loss: 2.389402411082522

Epoch: 5| Step: 3
Training loss: 2.7071755110708464
Validation loss: 2.400735081495967

Epoch: 5| Step: 4
Training loss: 2.905794989950359
Validation loss: 2.3984450174176244

Epoch: 5| Step: 5
Training loss: 2.394654113704062
Validation loss: 2.4026548229406957

Epoch: 5| Step: 6
Training loss: 2.6097594566140994
Validation loss: 2.398476958430422

Epoch: 5| Step: 7
Training loss: 2.4842500475284326
Validation loss: 2.3981167901287628

Epoch: 5| Step: 8
Training loss: 2.316770682526922
Validation loss: 2.395628577886273

Epoch: 5| Step: 9
Training loss: 2.591643247672327
Validation loss: 2.397569051350373

Epoch: 5| Step: 10
Training loss: 3.373260756328806
Validation loss: 2.3976416855339053

Epoch: 78| Step: 0
Training loss: 2.7029408298441666
Validation loss: 2.3937298829377074

Epoch: 5| Step: 1
Training loss: 2.934326730479422
Validation loss: 2.394247809294237

Epoch: 5| Step: 2
Training loss: 2.092875511538925
Validation loss: 2.3863741551732827

Epoch: 5| Step: 3
Training loss: 2.7211814618711845
Validation loss: 2.4044646954302356

Epoch: 5| Step: 4
Training loss: 2.721979174717175
Validation loss: 2.392333453259972

Epoch: 5| Step: 5
Training loss: 2.4369462191126443
Validation loss: 2.3949201843757897

Epoch: 5| Step: 6
Training loss: 2.452547041726687
Validation loss: 2.4071798532258244

Epoch: 5| Step: 7
Training loss: 3.225800726793193
Validation loss: 2.399113183568357

Epoch: 5| Step: 8
Training loss: 2.7250235950253394
Validation loss: 2.3755122238487254

Epoch: 5| Step: 9
Training loss: 2.0604798798720814
Validation loss: 2.390961157654488

Epoch: 5| Step: 10
Training loss: 3.141119163693874
Validation loss: 2.390906123093647

Epoch: 79| Step: 0
Training loss: 2.4603497484513435
Validation loss: 2.3837916252906624

Epoch: 5| Step: 1
Training loss: 2.988585373106921
Validation loss: 2.392440817272579

Epoch: 5| Step: 2
Training loss: 2.966369959820486
Validation loss: 2.389116848364773

Epoch: 5| Step: 3
Training loss: 2.436251002429425
Validation loss: 2.396048355797299

Epoch: 5| Step: 4
Training loss: 2.0071179565374524
Validation loss: 2.397071584378912

Epoch: 5| Step: 5
Training loss: 3.152263730154995
Validation loss: 2.3961376683501885

Epoch: 5| Step: 6
Training loss: 2.5668194349659172
Validation loss: 2.387842761325985

Epoch: 5| Step: 7
Training loss: 2.8398825368633034
Validation loss: 2.4051148115817162

Epoch: 5| Step: 8
Training loss: 2.6977749840098535
Validation loss: 2.395365729763068

Epoch: 5| Step: 9
Training loss: 2.6535884313143168
Validation loss: 2.3934731559546667

Epoch: 5| Step: 10
Training loss: 2.4470053958373446
Validation loss: 2.398734765822247

Epoch: 80| Step: 0
Training loss: 3.271017340730461
Validation loss: 2.401014144241807

Epoch: 5| Step: 1
Training loss: 2.9113755507235877
Validation loss: 2.375093178683404

Epoch: 5| Step: 2
Training loss: 2.695586171285149
Validation loss: 2.3956283146335977

Epoch: 5| Step: 3
Training loss: 2.844660518886639
Validation loss: 2.3914148220458262

Epoch: 5| Step: 4
Training loss: 2.539140436003404
Validation loss: 2.3870128871068195

Epoch: 5| Step: 5
Training loss: 2.2320463410355695
Validation loss: 2.4092159516831764

Epoch: 5| Step: 6
Training loss: 2.4283413116840666
Validation loss: 2.405514280077248

Epoch: 5| Step: 7
Training loss: 2.3449202604096038
Validation loss: 2.394176762912597

Epoch: 5| Step: 8
Training loss: 2.324922445500923
Validation loss: 2.3916084100088795

Epoch: 5| Step: 9
Training loss: 2.721614162065549
Validation loss: 2.3997060078690615

Epoch: 5| Step: 10
Training loss: 2.878744589253491
Validation loss: 2.3883427178571663

Epoch: 81| Step: 0
Training loss: 2.3013985652511684
Validation loss: 2.391300479976255

Epoch: 5| Step: 1
Training loss: 2.3936471224756657
Validation loss: 2.393581043998874

Epoch: 5| Step: 2
Training loss: 2.7796500243672924
Validation loss: 2.3907969787793943

Epoch: 5| Step: 3
Training loss: 2.805919238607927
Validation loss: 2.402693309441642

Epoch: 5| Step: 4
Training loss: 2.1368848886007235
Validation loss: 2.3934573882916745

Epoch: 5| Step: 5
Training loss: 2.8746792158207968
Validation loss: 2.391317611587674

Epoch: 5| Step: 6
Training loss: 2.874415628503175
Validation loss: 2.3908030683372936

Epoch: 5| Step: 7
Training loss: 3.0291026266500647
Validation loss: 2.3994666635805317

Epoch: 5| Step: 8
Training loss: 2.3645971244600292
Validation loss: 2.397065077601685

Epoch: 5| Step: 9
Training loss: 2.6436067258280884
Validation loss: 2.3924104019587213

Epoch: 5| Step: 10
Training loss: 3.0174679831739692
Validation loss: 2.3929329496141083

Epoch: 82| Step: 0
Training loss: 2.8785381935902827
Validation loss: 2.3964792808421542

Epoch: 5| Step: 1
Training loss: 2.7960895309139286
Validation loss: 2.3947706101060486

Epoch: 5| Step: 2
Training loss: 2.2392475911508978
Validation loss: 2.389638100945653

Epoch: 5| Step: 3
Training loss: 2.269074228201532
Validation loss: 2.388393158947346

Epoch: 5| Step: 4
Training loss: 2.9635614931932808
Validation loss: 2.3882023917253417

Epoch: 5| Step: 5
Training loss: 2.813990473527108
Validation loss: 2.38897807810999

Epoch: 5| Step: 6
Training loss: 2.8310306017753457
Validation loss: 2.3880752788260384

Epoch: 5| Step: 7
Training loss: 2.4589596505471167
Validation loss: 2.3924660373438704

Epoch: 5| Step: 8
Training loss: 2.508122220031886
Validation loss: 2.3902403712211466

Epoch: 5| Step: 9
Training loss: 2.812320788289906
Validation loss: 2.3940664837790915

Epoch: 5| Step: 10
Training loss: 2.5772253142841737
Validation loss: 2.3894115416249635

Epoch: 83| Step: 0
Training loss: 2.621256475044952
Validation loss: 2.400013000442816

Epoch: 5| Step: 1
Training loss: 2.468078715164994
Validation loss: 2.380714314435113

Epoch: 5| Step: 2
Training loss: 2.8168269463556563
Validation loss: 2.399826695524053

Epoch: 5| Step: 3
Training loss: 2.0627266730391685
Validation loss: 2.3952988697652566

Epoch: 5| Step: 4
Training loss: 2.3294590961494785
Validation loss: 2.403776387100699

Epoch: 5| Step: 5
Training loss: 3.1122527487723763
Validation loss: 2.411440001915303

Epoch: 5| Step: 6
Training loss: 2.5908127664915552
Validation loss: 2.373422606186128

Epoch: 5| Step: 7
Training loss: 2.5874898348253867
Validation loss: 2.3951799983005273

Epoch: 5| Step: 8
Training loss: 2.5122800588420025
Validation loss: 2.4007088473212366

Epoch: 5| Step: 9
Training loss: 3.432916394321008
Validation loss: 2.3848309695030756

Epoch: 5| Step: 10
Training loss: 2.370892536606309
Validation loss: 2.3947739940052366

Epoch: 84| Step: 0
Training loss: 2.2548527837433157
Validation loss: 2.382893227928272

Epoch: 5| Step: 1
Training loss: 2.3362722507843894
Validation loss: 2.3947059928789125

Epoch: 5| Step: 2
Training loss: 2.748982848279392
Validation loss: 2.3826493929442094

Epoch: 5| Step: 3
Training loss: 3.6910577195748915
Validation loss: 2.3931862316444366

Epoch: 5| Step: 4
Training loss: 2.4862585065493814
Validation loss: 2.399846554408995

Epoch: 5| Step: 5
Training loss: 2.2556211403559776
Validation loss: 2.3884286267387522

Epoch: 5| Step: 6
Training loss: 2.7916046439345794
Validation loss: 2.3877847887893404

Epoch: 5| Step: 7
Training loss: 2.8478181685683563
Validation loss: 2.3950264712100973

Epoch: 5| Step: 8
Training loss: 2.426342197496179
Validation loss: 2.384266600589946

Epoch: 5| Step: 9
Training loss: 2.6758097626218103
Validation loss: 2.389182855556303

Epoch: 5| Step: 10
Training loss: 2.3898191402748195
Validation loss: 2.389618812719128

Epoch: 85| Step: 0
Training loss: 2.9538079334959133
Validation loss: 2.3872422857771776

Epoch: 5| Step: 1
Training loss: 2.665793564040607
Validation loss: 2.389517778447099

Epoch: 5| Step: 2
Training loss: 2.7957432337729107
Validation loss: 2.3845874256570676

Epoch: 5| Step: 3
Training loss: 2.9943962212027357
Validation loss: 2.3906489373802944

Epoch: 5| Step: 4
Training loss: 2.6503098432673537
Validation loss: 2.3888461439523647

Epoch: 5| Step: 5
Training loss: 2.8137708547760703
Validation loss: 2.3972617051679563

Epoch: 5| Step: 6
Training loss: 2.6694650768532835
Validation loss: 2.3862091014949396

Epoch: 5| Step: 7
Training loss: 2.369048844058963
Validation loss: 2.393399490161678

Epoch: 5| Step: 8
Training loss: 2.2546379184360203
Validation loss: 2.3907130487441606

Epoch: 5| Step: 9
Training loss: 2.556349094400811
Validation loss: 2.396199391467764

Epoch: 5| Step: 10
Training loss: 2.4076724121216735
Validation loss: 2.3950829834765797

Epoch: 86| Step: 0
Training loss: 2.430879355766398
Validation loss: 2.393741770268347

Epoch: 5| Step: 1
Training loss: 2.6301957435432497
Validation loss: 2.388372776012737

Epoch: 5| Step: 2
Training loss: 2.2106873064047794
Validation loss: 2.386029865144033

Epoch: 5| Step: 3
Training loss: 1.8661033643283058
Validation loss: 2.3965162961457755

Epoch: 5| Step: 4
Training loss: 2.5125536443193157
Validation loss: 2.3890795708709063

Epoch: 5| Step: 5
Training loss: 2.583770858466373
Validation loss: 2.388411643997092

Epoch: 5| Step: 6
Training loss: 2.6516586115451206
Validation loss: 2.4076977111537063

Epoch: 5| Step: 7
Training loss: 2.3852107751825873
Validation loss: 2.392957424747284

Epoch: 5| Step: 8
Training loss: 3.3743228939560277
Validation loss: 2.39165141873385

Epoch: 5| Step: 9
Training loss: 3.073416114348735
Validation loss: 2.3921550680241643

Epoch: 5| Step: 10
Training loss: 3.209140395343645
Validation loss: 2.3942568067888566

Epoch: 87| Step: 0
Training loss: 2.7722440488980027
Validation loss: 2.3765002306650183

Epoch: 5| Step: 1
Training loss: 2.91341902350042
Validation loss: 2.393699034185217

Epoch: 5| Step: 2
Training loss: 2.207725753213883
Validation loss: 2.3981558550971966

Epoch: 5| Step: 3
Training loss: 2.832888138145781
Validation loss: 2.3962408970192026

Epoch: 5| Step: 4
Training loss: 2.411143887302431
Validation loss: 2.397244328363591

Epoch: 5| Step: 5
Training loss: 2.961968959421612
Validation loss: 2.399511889416364

Epoch: 5| Step: 6
Training loss: 2.709782247064802
Validation loss: 2.403772691656448

Epoch: 5| Step: 7
Training loss: 2.217711837094467
Validation loss: 2.394925156607628

Epoch: 5| Step: 8
Training loss: 2.678493756575907
Validation loss: 2.400649703780322

Epoch: 5| Step: 9
Training loss: 2.91347303385814
Validation loss: 2.391244307155836

Epoch: 5| Step: 10
Training loss: 2.281947094737819
Validation loss: 2.4010502728317835

Epoch: 88| Step: 0
Training loss: 2.7170918988020345
Validation loss: 2.3825501301375205

Epoch: 5| Step: 1
Training loss: 2.3620835477118183
Validation loss: 2.376742840171992

Epoch: 5| Step: 2
Training loss: 3.026020691230462
Validation loss: 2.3820458109204004

Epoch: 5| Step: 3
Training loss: 3.0181188203894918
Validation loss: 2.385891403701825

Epoch: 5| Step: 4
Training loss: 2.75763388425429
Validation loss: 2.386837328600196

Epoch: 5| Step: 5
Training loss: 2.6559854712318693
Validation loss: 2.3783683325620504

Epoch: 5| Step: 6
Training loss: 2.923403416673979
Validation loss: 2.3953523863816177

Epoch: 5| Step: 7
Training loss: 2.395172979045217
Validation loss: 2.383456970132823

Epoch: 5| Step: 8
Training loss: 2.042584997717449
Validation loss: 2.389652832801777

Epoch: 5| Step: 9
Training loss: 2.735109241542536
Validation loss: 2.4003618077874505

Epoch: 5| Step: 10
Training loss: 2.225775757043393
Validation loss: 2.398322958277265

Epoch: 89| Step: 0
Training loss: 3.195734196749538
Validation loss: 2.3897068116407065

Epoch: 5| Step: 1
Training loss: 2.4179692430141357
Validation loss: 2.4018124468829227

Epoch: 5| Step: 2
Training loss: 2.445002819597924
Validation loss: 2.4000357781583905

Epoch: 5| Step: 3
Training loss: 2.511094272279498
Validation loss: 2.4000365098531358

Epoch: 5| Step: 4
Training loss: 2.708907892953111
Validation loss: 2.392296278933588

Epoch: 5| Step: 5
Training loss: 2.8877048898640636
Validation loss: 2.392339782160964

Epoch: 5| Step: 6
Training loss: 2.622218793078334
Validation loss: 2.3905101364887256

Epoch: 5| Step: 7
Training loss: 2.1492492252076456
Validation loss: 2.3862622343069977

Epoch: 5| Step: 8
Training loss: 2.5459767261169532
Validation loss: 2.380779456782324

Epoch: 5| Step: 9
Training loss: 3.0167120520899253
Validation loss: 2.382003313795243

Epoch: 5| Step: 10
Training loss: 2.36207577564939
Validation loss: 2.392499288834302

Epoch: 90| Step: 0
Training loss: 2.6850747099131045
Validation loss: 2.388697100520493

Epoch: 5| Step: 1
Training loss: 2.1100008565891932
Validation loss: 2.388021338255862

Epoch: 5| Step: 2
Training loss: 3.186312136248119
Validation loss: 2.4001057634840235

Epoch: 5| Step: 3
Training loss: 2.7945412217309684
Validation loss: 2.383875642001468

Epoch: 5| Step: 4
Training loss: 2.767791589057338
Validation loss: 2.380143497226902

Epoch: 5| Step: 5
Training loss: 2.5296416647836653
Validation loss: 2.3943402346428475

Epoch: 5| Step: 6
Training loss: 2.9889606177299863
Validation loss: 2.394633095145599

Epoch: 5| Step: 7
Training loss: 2.2806151042210243
Validation loss: 2.3940429510811145

Epoch: 5| Step: 8
Training loss: 2.2859366364128686
Validation loss: 2.3902122843171822

Epoch: 5| Step: 9
Training loss: 2.5620751377615067
Validation loss: 2.3864402930126047

Epoch: 5| Step: 10
Training loss: 2.841739656586766
Validation loss: 2.385515746073042

Epoch: 91| Step: 0
Training loss: 2.630977002114754
Validation loss: 2.4011563278223917

Epoch: 5| Step: 1
Training loss: 2.6567822091485302
Validation loss: 2.4002905696235737

Epoch: 5| Step: 2
Training loss: 2.9813859760616097
Validation loss: 2.396000736339347

Epoch: 5| Step: 3
Training loss: 2.5831651837988936
Validation loss: 2.394182928465617

Epoch: 5| Step: 4
Training loss: 2.4672435558442505
Validation loss: 2.3917347648964227

Epoch: 5| Step: 5
Training loss: 2.11827155368536
Validation loss: 2.3810047195910884

Epoch: 5| Step: 6
Training loss: 2.248373715448312
Validation loss: 2.382581722569808

Epoch: 5| Step: 7
Training loss: 2.6150508528482153
Validation loss: 2.3754823202495063

Epoch: 5| Step: 8
Training loss: 3.010012765648218
Validation loss: 2.4025045393612503

Epoch: 5| Step: 9
Training loss: 2.6821444177795364
Validation loss: 2.4005005746215478

Epoch: 5| Step: 10
Training loss: 2.9282789582740754
Validation loss: 2.3887018270562206

Epoch: 92| Step: 0
Training loss: 2.35697501687302
Validation loss: 2.412087318173758

Epoch: 5| Step: 1
Training loss: 2.9545849617404096
Validation loss: 2.3841198247027524

Epoch: 5| Step: 2
Training loss: 2.6363214037989406
Validation loss: 2.3920731811895593

Epoch: 5| Step: 3
Training loss: 3.3756591718300517
Validation loss: 2.380413418620993

Epoch: 5| Step: 4
Training loss: 2.6266236506326877
Validation loss: 2.392010303427109

Epoch: 5| Step: 5
Training loss: 2.6991869514679063
Validation loss: 2.402083480372905

Epoch: 5| Step: 6
Training loss: 2.2542565666882357
Validation loss: 2.3852774810558044

Epoch: 5| Step: 7
Training loss: 3.1171159090698204
Validation loss: 2.3802950703628856

Epoch: 5| Step: 8
Training loss: 2.0438554929052364
Validation loss: 2.3931352279419196

Epoch: 5| Step: 9
Training loss: 2.2149739975619327
Validation loss: 2.3829495470432596

Epoch: 5| Step: 10
Training loss: 2.285216241032789
Validation loss: 2.3818251671830293

Epoch: 93| Step: 0
Training loss: 2.685955224636107
Validation loss: 2.381463516623868

Epoch: 5| Step: 1
Training loss: 2.7056022274039746
Validation loss: 2.375763675898391

Epoch: 5| Step: 2
Training loss: 2.270021369262135
Validation loss: 2.3992641235398895

Epoch: 5| Step: 3
Training loss: 2.5553559061744138
Validation loss: 2.3893528362416134

Epoch: 5| Step: 4
Training loss: 2.162697371808545
Validation loss: 2.3849668385418923

Epoch: 5| Step: 5
Training loss: 2.305177694658044
Validation loss: 2.38472670726544

Epoch: 5| Step: 6
Training loss: 2.8949952776776473
Validation loss: 2.393201287662775

Epoch: 5| Step: 7
Training loss: 2.460267184564677
Validation loss: 2.3812231967804096

Epoch: 5| Step: 8
Training loss: 2.81732332110608
Validation loss: 2.394721881855762

Epoch: 5| Step: 9
Training loss: 3.3247275047215306
Validation loss: 2.3791644809604318

Epoch: 5| Step: 10
Training loss: 2.5940176584411847
Validation loss: 2.3952042075093187

Epoch: 94| Step: 0
Training loss: 2.3595119209222837
Validation loss: 2.369888942650757

Epoch: 5| Step: 1
Training loss: 3.050057651412661
Validation loss: 2.395615360640023

Epoch: 5| Step: 2
Training loss: 2.7728512426425733
Validation loss: 2.3935785077554255

Epoch: 5| Step: 3
Training loss: 3.0336385538435873
Validation loss: 2.4066577726207234

Epoch: 5| Step: 4
Training loss: 2.483573160389154
Validation loss: 2.3876649999381465

Epoch: 5| Step: 5
Training loss: 2.493105058760038
Validation loss: 2.384572813557683

Epoch: 5| Step: 6
Training loss: 2.650371644212847
Validation loss: 2.387949511864077

Epoch: 5| Step: 7
Training loss: 2.8658528976756155
Validation loss: 2.3899239934481167

Epoch: 5| Step: 8
Training loss: 2.5348505855671064
Validation loss: 2.3809923094523233

Epoch: 5| Step: 9
Training loss: 2.2187222761114525
Validation loss: 2.388840477602255

Epoch: 5| Step: 10
Training loss: 2.197172307046169
Validation loss: 2.38319848032844

Epoch: 95| Step: 0
Training loss: 2.9407048700007774
Validation loss: 2.3851222288095535

Epoch: 5| Step: 1
Training loss: 2.72783886784319
Validation loss: 2.385855637622251

Epoch: 5| Step: 2
Training loss: 2.865949067040551
Validation loss: 2.3904615487495464

Epoch: 5| Step: 3
Training loss: 1.995896898928485
Validation loss: 2.386947161985236

Epoch: 5| Step: 4
Training loss: 2.364901707483753
Validation loss: 2.3931964511079786

Epoch: 5| Step: 5
Training loss: 2.491909477965544
Validation loss: 2.384200065357555

Epoch: 5| Step: 6
Training loss: 2.404645012969111
Validation loss: 2.393613711816672

Epoch: 5| Step: 7
Training loss: 2.619017095305357
Validation loss: 2.374421072338217

Epoch: 5| Step: 8
Training loss: 2.8467384816505636
Validation loss: 2.3755432192027364

Epoch: 5| Step: 9
Training loss: 2.975127106844325
Validation loss: 2.3788992888762004

Epoch: 5| Step: 10
Training loss: 2.3910055418632354
Validation loss: 2.391632387926696

Epoch: 96| Step: 0
Training loss: 2.8247025155943812
Validation loss: 2.4090324064970248

Epoch: 5| Step: 1
Training loss: 2.081825575412222
Validation loss: 2.3710145373676195

Epoch: 5| Step: 2
Training loss: 2.8579601685596043
Validation loss: 2.384954828467589

Epoch: 5| Step: 3
Training loss: 2.6234320544515213
Validation loss: 2.3848736629440013

Epoch: 5| Step: 4
Training loss: 2.897353799997232
Validation loss: 2.3923495208773655

Epoch: 5| Step: 5
Training loss: 2.8685944558653946
Validation loss: 2.3732534029966583

Epoch: 5| Step: 6
Training loss: 2.581608124428972
Validation loss: 2.3825148615948017

Epoch: 5| Step: 7
Training loss: 2.131292563094507
Validation loss: 2.401649529659959

Epoch: 5| Step: 8
Training loss: 2.5787495174583173
Validation loss: 2.3997821272722386

Epoch: 5| Step: 9
Training loss: 2.4652156398147715
Validation loss: 2.381303069961883

Epoch: 5| Step: 10
Training loss: 2.991782377621064
Validation loss: 2.3817648545530443

Epoch: 97| Step: 0
Training loss: 2.52842620828229
Validation loss: 2.381143550782877

Epoch: 5| Step: 1
Training loss: 2.6780613004749467
Validation loss: 2.385446575052708

Epoch: 5| Step: 2
Training loss: 2.582325420848929
Validation loss: 2.3949064975719274

Epoch: 5| Step: 3
Training loss: 2.2527146387666104
Validation loss: 2.3965570805674554

Epoch: 5| Step: 4
Training loss: 2.6206437249018477
Validation loss: 2.371709270924648

Epoch: 5| Step: 5
Training loss: 2.6636625196608974
Validation loss: 2.3863012371162884

Epoch: 5| Step: 6
Training loss: 2.6614039963601996
Validation loss: 2.394239336435177

Epoch: 5| Step: 7
Training loss: 3.095788457518707
Validation loss: 2.382685280316501

Epoch: 5| Step: 8
Training loss: 2.772527755034258
Validation loss: 2.3763195089908518

Epoch: 5| Step: 9
Training loss: 2.697561459128438
Validation loss: 2.3979832772700536

Epoch: 5| Step: 10
Training loss: 2.058649572668772
Validation loss: 2.386849199239853

Epoch: 98| Step: 0
Training loss: 2.8151366696288416
Validation loss: 2.3787012792374598

Epoch: 5| Step: 1
Training loss: 2.366045786674961
Validation loss: 2.378709847857799

Epoch: 5| Step: 2
Training loss: 3.03753309820533
Validation loss: 2.381067184912105

Epoch: 5| Step: 3
Training loss: 2.4294804426569154
Validation loss: 2.3963353990382696

Epoch: 5| Step: 4
Training loss: 2.9669633809842617
Validation loss: 2.390363669972601

Epoch: 5| Step: 5
Training loss: 2.243560051913692
Validation loss: 2.398441166253825

Epoch: 5| Step: 6
Training loss: 2.230875542685132
Validation loss: 2.392932228603347

Epoch: 5| Step: 7
Training loss: 2.391083517545637
Validation loss: 2.3850582219076

Epoch: 5| Step: 8
Training loss: 2.7684798511435376
Validation loss: 2.379894252474258

Epoch: 5| Step: 9
Training loss: 2.461099673785904
Validation loss: 2.398916114649111

Epoch: 5| Step: 10
Training loss: 2.9732484165034436
Validation loss: 2.3797067204441866

Epoch: 99| Step: 0
Training loss: 3.462186910748184
Validation loss: 2.3873863955997257

Epoch: 5| Step: 1
Training loss: 2.1858157622309426
Validation loss: 2.3978045885318338

Epoch: 5| Step: 2
Training loss: 2.652000169031935
Validation loss: 2.3818016604593986

Epoch: 5| Step: 3
Training loss: 2.2609848386584352
Validation loss: 2.3870142951142497

Epoch: 5| Step: 4
Training loss: 2.356163415911653
Validation loss: 2.38221545661658

Epoch: 5| Step: 5
Training loss: 2.8642926062815954
Validation loss: 2.374750962987652

Epoch: 5| Step: 6
Training loss: 2.873637996314481
Validation loss: 2.3867837115514616

Epoch: 5| Step: 7
Training loss: 2.533582766282948
Validation loss: 2.3893809632903587

Epoch: 5| Step: 8
Training loss: 2.576620969461705
Validation loss: 2.396685124550304

Epoch: 5| Step: 9
Training loss: 2.3228683010477478
Validation loss: 2.3869054733455277

Epoch: 5| Step: 10
Training loss: 2.382408733240982
Validation loss: 2.3821834805141555

Epoch: 100| Step: 0
Training loss: 2.397982774801485
Validation loss: 2.400274463310872

Epoch: 5| Step: 1
Training loss: 2.79223981828564
Validation loss: 2.392585401526062

Epoch: 5| Step: 2
Training loss: 2.6238790571032293
Validation loss: 2.383562021436924

Epoch: 5| Step: 3
Training loss: 3.03069843111232
Validation loss: 2.391299391825327

Epoch: 5| Step: 4
Training loss: 2.446237309987754
Validation loss: 2.3864145838514124

Epoch: 5| Step: 5
Training loss: 2.309825691153067
Validation loss: 2.3895668670847683

Epoch: 5| Step: 6
Training loss: 2.3617990937543847
Validation loss: 2.3840473613815627

Epoch: 5| Step: 7
Training loss: 2.2438973211096593
Validation loss: 2.3840019448711764

Epoch: 5| Step: 8
Training loss: 2.4720136099628975
Validation loss: 2.3831707417986085

Epoch: 5| Step: 9
Training loss: 3.019920649717608
Validation loss: 2.3813433053678152

Epoch: 5| Step: 10
Training loss: 2.923975877717133
Validation loss: 2.3875948561049376

Epoch: 101| Step: 0
Training loss: 2.468701905373594
Validation loss: 2.3783125107560625

Epoch: 5| Step: 1
Training loss: 2.505237243443235
Validation loss: 2.384307671962393

Epoch: 5| Step: 2
Training loss: 2.7469190331446063
Validation loss: 2.3801525631181644

Epoch: 5| Step: 3
Training loss: 2.8522687481579903
Validation loss: 2.3844626525509374

Epoch: 5| Step: 4
Training loss: 2.63006049518124
Validation loss: 2.3827381022226595

Epoch: 5| Step: 5
Training loss: 2.698715052552879
Validation loss: 2.390693888756461

Epoch: 5| Step: 6
Training loss: 2.9400865246243746
Validation loss: 2.4026128029161193

Epoch: 5| Step: 7
Training loss: 2.288752303734312
Validation loss: 2.3740837216500075

Epoch: 5| Step: 8
Training loss: 2.2129506358050577
Validation loss: 2.3770604643373634

Epoch: 5| Step: 9
Training loss: 2.56460949667242
Validation loss: 2.3802022482636547

Epoch: 5| Step: 10
Training loss: 2.700272306203381
Validation loss: 2.3745596800797872

Epoch: 102| Step: 0
Training loss: 2.8117244922847466
Validation loss: 2.385336650003042

Epoch: 5| Step: 1
Training loss: 2.8908005119858506
Validation loss: 2.393523310056693

Epoch: 5| Step: 2
Training loss: 2.6480337189604874
Validation loss: 2.364646177516997

Epoch: 5| Step: 3
Training loss: 2.8577167309314624
Validation loss: 2.381601568104354

Epoch: 5| Step: 4
Training loss: 2.67609059571324
Validation loss: 2.394116452515962

Epoch: 5| Step: 5
Training loss: 2.55008032429164
Validation loss: 2.389179244841771

Epoch: 5| Step: 6
Training loss: 2.117508754779683
Validation loss: 2.3736071407107837

Epoch: 5| Step: 7
Training loss: 2.5809152935720294
Validation loss: 2.380055860472417

Epoch: 5| Step: 8
Training loss: 2.26950498687203
Validation loss: 2.3905286861360793

Epoch: 5| Step: 9
Training loss: 2.6784148016050064
Validation loss: 2.3987499879377703

Epoch: 5| Step: 10
Training loss: 2.364600451795368
Validation loss: 2.3759921246349047

Epoch: 103| Step: 0
Training loss: 3.104674193263035
Validation loss: 2.386027693704288

Epoch: 5| Step: 1
Training loss: 2.6921148377817556
Validation loss: 2.3825861997713917

Epoch: 5| Step: 2
Training loss: 2.4240033057980295
Validation loss: 2.3837904960714487

Epoch: 5| Step: 3
Training loss: 2.865237370588925
Validation loss: 2.3773399380252416

Epoch: 5| Step: 4
Training loss: 2.234301159045379
Validation loss: 2.3726888669048747

Epoch: 5| Step: 5
Training loss: 2.7833904645009393
Validation loss: 2.380635449913549

Epoch: 5| Step: 6
Training loss: 2.306297955104879
Validation loss: 2.3756044068869895

Epoch: 5| Step: 7
Training loss: 2.5231295654618426
Validation loss: 2.390824773587246

Epoch: 5| Step: 8
Training loss: 2.6866754553330066
Validation loss: 2.393120297915997

Epoch: 5| Step: 9
Training loss: 2.635151624859286
Validation loss: 2.377500444030496

Epoch: 5| Step: 10
Training loss: 2.161928853370275
Validation loss: 2.3979002252697192

Epoch: 104| Step: 0
Training loss: 1.794172427316865
Validation loss: 2.3790137038038344

Epoch: 5| Step: 1
Training loss: 2.2125628532490635
Validation loss: 2.3917421243786614

Epoch: 5| Step: 2
Training loss: 2.5680639757048476
Validation loss: 2.398179713032443

Epoch: 5| Step: 3
Training loss: 2.4852448865858814
Validation loss: 2.3858098767601725

Epoch: 5| Step: 4
Training loss: 2.755147364806561
Validation loss: 2.38668088669951

Epoch: 5| Step: 5
Training loss: 2.7689104985202966
Validation loss: 2.382219958181968

Epoch: 5| Step: 6
Training loss: 2.292638179728898
Validation loss: 2.404352343029982

Epoch: 5| Step: 7
Training loss: 2.469222204704067
Validation loss: 2.385543476948211

Epoch: 5| Step: 8
Training loss: 2.9343416807255362
Validation loss: 2.382280438465465

Epoch: 5| Step: 9
Training loss: 3.0184200951674445
Validation loss: 2.394771545201731

Epoch: 5| Step: 10
Training loss: 3.090530415660404
Validation loss: 2.4019013892719254

Epoch: 105| Step: 0
Training loss: 2.503385349788101
Validation loss: 2.3929323475219273

Epoch: 5| Step: 1
Training loss: 2.3602032754930136
Validation loss: 2.3982597216511774

Epoch: 5| Step: 2
Training loss: 2.513948818028714
Validation loss: 2.392537899587449

Epoch: 5| Step: 3
Training loss: 3.0204258786474667
Validation loss: 2.3884830454046773

Epoch: 5| Step: 4
Training loss: 2.5252900778453955
Validation loss: 2.3813647620352336

Epoch: 5| Step: 5
Training loss: 2.3319518109310575
Validation loss: 2.3849984140103415

Epoch: 5| Step: 6
Training loss: 2.1603251110113297
Validation loss: 2.3807915816013483

Epoch: 5| Step: 7
Training loss: 2.9959751787061486
Validation loss: 2.3773167918821128

Epoch: 5| Step: 8
Training loss: 2.8694314517128827
Validation loss: 2.3682810803972014

Epoch: 5| Step: 9
Training loss: 2.4673518797101734
Validation loss: 2.3940266688801626

Epoch: 5| Step: 10
Training loss: 2.7197685526101014
Validation loss: 2.3941931554533395

Epoch: 106| Step: 0
Training loss: 2.1686484980947407
Validation loss: 2.3752091795463395

Epoch: 5| Step: 1
Training loss: 2.3728027218150336
Validation loss: 2.39439981829866

Epoch: 5| Step: 2
Training loss: 2.93070213549911
Validation loss: 2.392872250032146

Epoch: 5| Step: 3
Training loss: 2.522417458732913
Validation loss: 2.402726346308631

Epoch: 5| Step: 4
Training loss: 3.4878094771698245
Validation loss: 2.389376085205103

Epoch: 5| Step: 5
Training loss: 2.615024048236969
Validation loss: 2.390714021350047

Epoch: 5| Step: 6
Training loss: 2.134672478740404
Validation loss: 2.3808741665590416

Epoch: 5| Step: 7
Training loss: 2.2442424010727873
Validation loss: 2.3861331625796764

Epoch: 5| Step: 8
Training loss: 2.0220982895533903
Validation loss: 2.3742319299653776

Epoch: 5| Step: 9
Training loss: 2.7741801382486186
Validation loss: 2.3953273112189097

Epoch: 5| Step: 10
Training loss: 3.0009155465852113
Validation loss: 2.377551508174819

Epoch: 107| Step: 0
Training loss: 2.3449125331353877
Validation loss: 2.3896951043138284

Epoch: 5| Step: 1
Training loss: 2.5208329970514582
Validation loss: 2.3895108981253816

Epoch: 5| Step: 2
Training loss: 1.893916897611237
Validation loss: 2.398504122332891

Epoch: 5| Step: 3
Training loss: 2.575646150868248
Validation loss: 2.3927480037702993

Epoch: 5| Step: 4
Training loss: 2.5733047275073297
Validation loss: 2.3808872147547544

Epoch: 5| Step: 5
Training loss: 2.8452003888453175
Validation loss: 2.4066528688359714

Epoch: 5| Step: 6
Training loss: 2.6897993675202256
Validation loss: 2.370838941480273

Epoch: 5| Step: 7
Training loss: 2.3443686113954416
Validation loss: 2.377688827726258

Epoch: 5| Step: 8
Training loss: 3.1308937951359668
Validation loss: 2.3909090127961203

Epoch: 5| Step: 9
Training loss: 2.7191696720026797
Validation loss: 2.3769479738841395

Epoch: 5| Step: 10
Training loss: 2.7282991753523422
Validation loss: 2.3923977509431005

Epoch: 108| Step: 0
Training loss: 2.503370778260481
Validation loss: 2.375021579819259

Epoch: 5| Step: 1
Training loss: 3.059662730759875
Validation loss: 2.3640464341947958

Epoch: 5| Step: 2
Training loss: 2.1527479176518427
Validation loss: 2.3705498821257565

Epoch: 5| Step: 3
Training loss: 2.563198552633203
Validation loss: 2.3720232027491903

Epoch: 5| Step: 4
Training loss: 2.6467281440429877
Validation loss: 2.3774995652220356

Epoch: 5| Step: 5
Training loss: 2.9382414186511876
Validation loss: 2.3844749145363533

Epoch: 5| Step: 6
Training loss: 2.1626370689743695
Validation loss: 2.383921386222989

Epoch: 5| Step: 7
Training loss: 2.633282899574809
Validation loss: 2.3974570483986564

Epoch: 5| Step: 8
Training loss: 2.539753230114916
Validation loss: 2.371845356600895

Epoch: 5| Step: 9
Training loss: 2.9008939877811333
Validation loss: 2.4027244673710104

Epoch: 5| Step: 10
Training loss: 2.230450685230863
Validation loss: 2.4045065242309573

Epoch: 109| Step: 0
Training loss: 3.0175863420195568
Validation loss: 2.386239745185085

Epoch: 5| Step: 1
Training loss: 2.3799175749859085
Validation loss: 2.3782942042987405

Epoch: 5| Step: 2
Training loss: 2.5190709366330006
Validation loss: 2.3912737075673975

Epoch: 5| Step: 3
Training loss: 2.7157953803691965
Validation loss: 2.3948544680563995

Epoch: 5| Step: 4
Training loss: 2.4763158440729915
Validation loss: 2.3816733878789513

Epoch: 5| Step: 5
Training loss: 2.92354499297133
Validation loss: 2.384942595822802

Epoch: 5| Step: 6
Training loss: 2.2252227500255892
Validation loss: 2.3722245190862195

Epoch: 5| Step: 7
Training loss: 2.6115528087064126
Validation loss: 2.386452488975709

Epoch: 5| Step: 8
Training loss: 2.534817665660497
Validation loss: 2.387481825796478

Epoch: 5| Step: 9
Training loss: 2.6448959932989147
Validation loss: 2.3810672990398802

Epoch: 5| Step: 10
Training loss: 2.372207103693976
Validation loss: 2.3726471676101033

Epoch: 110| Step: 0
Training loss: 2.5381516921070726
Validation loss: 2.386080334713405

Epoch: 5| Step: 1
Training loss: 2.7667390982403695
Validation loss: 2.3812620910297944

Epoch: 5| Step: 2
Training loss: 2.8882055106020705
Validation loss: 2.381689110847242

Epoch: 5| Step: 3
Training loss: 2.232846464161728
Validation loss: 2.376226019131476

Epoch: 5| Step: 4
Training loss: 2.550140160093285
Validation loss: 2.3633672997051614

Epoch: 5| Step: 5
Training loss: 2.3513990579880795
Validation loss: 2.3861971675066855

Epoch: 5| Step: 6
Training loss: 3.0434723463060234
Validation loss: 2.377845138337384

Epoch: 5| Step: 7
Training loss: 2.4929556783813425
Validation loss: 2.371575123215985

Epoch: 5| Step: 8
Training loss: 2.2474945742124723
Validation loss: 2.383861007794787

Epoch: 5| Step: 9
Training loss: 2.5043645906434335
Validation loss: 2.37240397393367

Epoch: 5| Step: 10
Training loss: 2.711327956166253
Validation loss: 2.3985744494805536

Epoch: 111| Step: 0
Training loss: 2.9707575384871157
Validation loss: 2.3810191150987494

Epoch: 5| Step: 1
Training loss: 2.7803955480077556
Validation loss: 2.3955193362428244

Epoch: 5| Step: 2
Training loss: 2.5720492817264202
Validation loss: 2.3740901585928045

Epoch: 5| Step: 3
Training loss: 2.07416185204006
Validation loss: 2.3824641029001845

Epoch: 5| Step: 4
Training loss: 2.5024054399092197
Validation loss: 2.3698961449685987

Epoch: 5| Step: 5
Training loss: 2.531404655347258
Validation loss: 2.381002734683859

Epoch: 5| Step: 6
Training loss: 2.487589741530538
Validation loss: 2.3823174473242226

Epoch: 5| Step: 7
Training loss: 2.3305641044830714
Validation loss: 2.40102152546466

Epoch: 5| Step: 8
Training loss: 3.030186574750045
Validation loss: 2.385041347377519

Epoch: 5| Step: 9
Training loss: 2.6431737032679052
Validation loss: 2.3831687710662965

Epoch: 5| Step: 10
Training loss: 2.1953323743470374
Validation loss: 2.3705699084062073

Epoch: 112| Step: 0
Training loss: 2.208378797339039
Validation loss: 2.3852723575898214

Epoch: 5| Step: 1
Training loss: 2.462818214265632
Validation loss: 2.3734719909833237

Epoch: 5| Step: 2
Training loss: 2.5380438536574537
Validation loss: 2.3915001188828406

Epoch: 5| Step: 3
Training loss: 2.408212926246022
Validation loss: 2.387181222417413

Epoch: 5| Step: 4
Training loss: 3.0014141246655215
Validation loss: 2.3937359982347735

Epoch: 5| Step: 5
Training loss: 2.745501653834373
Validation loss: 2.3869697271412718

Epoch: 5| Step: 6
Training loss: 2.658146887751234
Validation loss: 2.378006390761328

Epoch: 5| Step: 7
Training loss: 3.0556328522894765
Validation loss: 2.384559981197612

Epoch: 5| Step: 8
Training loss: 2.4422971030917813
Validation loss: 2.3932451643556334

Epoch: 5| Step: 9
Training loss: 2.3659356461299654
Validation loss: 2.382846841038496

Epoch: 5| Step: 10
Training loss: 2.372351826421194
Validation loss: 2.3859215432402454

Epoch: 113| Step: 0
Training loss: 2.625195632184156
Validation loss: 2.3859108348831413

Epoch: 5| Step: 1
Training loss: 2.9571834711480536
Validation loss: 2.383470263944488

Epoch: 5| Step: 2
Training loss: 2.6425393292722226
Validation loss: 2.382175902094517

Epoch: 5| Step: 3
Training loss: 2.613242293040393
Validation loss: 2.395043197250152

Epoch: 5| Step: 4
Training loss: 2.5084387451868326
Validation loss: 2.38939467638067

Epoch: 5| Step: 5
Training loss: 2.1722062770760187
Validation loss: 2.3712275400538734

Epoch: 5| Step: 6
Training loss: 3.055951025445577
Validation loss: 2.397695035453042

Epoch: 5| Step: 7
Training loss: 2.451765327499835
Validation loss: 2.3914426332568555

Epoch: 5| Step: 8
Training loss: 2.5170096620503823
Validation loss: 2.3788463908901023

Epoch: 5| Step: 9
Training loss: 2.477122150327683
Validation loss: 2.3767492936430363

Epoch: 5| Step: 10
Training loss: 2.134435909178494
Validation loss: 2.3726247839069363

Epoch: 114| Step: 0
Training loss: 2.615332284680008
Validation loss: 2.3624863391035698

Epoch: 5| Step: 1
Training loss: 2.5717618154879363
Validation loss: 2.3872470522425124

Epoch: 5| Step: 2
Training loss: 2.4692786894032763
Validation loss: 2.373309026218395

Epoch: 5| Step: 3
Training loss: 2.018926474590456
Validation loss: 2.375122568004204

Epoch: 5| Step: 4
Training loss: 2.4749144837989694
Validation loss: 2.375370936309418

Epoch: 5| Step: 5
Training loss: 2.2643223668003274
Validation loss: 2.3849511264330285

Epoch: 5| Step: 6
Training loss: 2.9658159715044787
Validation loss: 2.381303289582255

Epoch: 5| Step: 7
Training loss: 1.849878631940857
Validation loss: 2.38968243892338

Epoch: 5| Step: 8
Training loss: 3.277914040816869
Validation loss: 2.3671166546007543

Epoch: 5| Step: 9
Training loss: 2.1323776081198282
Validation loss: 2.366280106361631

Epoch: 5| Step: 10
Training loss: 3.300257678519801
Validation loss: 2.3703221245437787

Epoch: 115| Step: 0
Training loss: 2.2464727728777407
Validation loss: 2.379589954134827

Epoch: 5| Step: 1
Training loss: 2.1188144415223715
Validation loss: 2.3922279051696886

Epoch: 5| Step: 2
Training loss: 2.436766587473029
Validation loss: 2.3727067163517988

Epoch: 5| Step: 3
Training loss: 2.669286444393501
Validation loss: 2.3751623587171764

Epoch: 5| Step: 4
Training loss: 2.3980936307150365
Validation loss: 2.3730883847010045

Epoch: 5| Step: 5
Training loss: 2.96031661556944
Validation loss: 2.393017445642635

Epoch: 5| Step: 6
Training loss: 3.277935424792393
Validation loss: 2.3788146583233085

Epoch: 5| Step: 7
Training loss: 2.5760628515951725
Validation loss: 2.362607782173968

Epoch: 5| Step: 8
Training loss: 2.5880286298698243
Validation loss: 2.3731048300076445

Epoch: 5| Step: 9
Training loss: 2.5408854821411597
Validation loss: 2.3820888357092054

Epoch: 5| Step: 10
Training loss: 2.217547991038709
Validation loss: 2.3716783962533756

Epoch: 116| Step: 0
Training loss: 2.7815583304611926
Validation loss: 2.389249147949133

Epoch: 5| Step: 1
Training loss: 2.1991578224103545
Validation loss: 2.384787499149755

Epoch: 5| Step: 2
Training loss: 2.342834090242383
Validation loss: 2.3678892959348086

Epoch: 5| Step: 3
Training loss: 2.819184730314801
Validation loss: 2.364394065745344

Epoch: 5| Step: 4
Training loss: 2.34239992039894
Validation loss: 2.378296156433711

Epoch: 5| Step: 5
Training loss: 2.4446215156038416
Validation loss: 2.384342300048242

Epoch: 5| Step: 6
Training loss: 2.679576459980721
Validation loss: 2.3703925221025446

Epoch: 5| Step: 7
Training loss: 2.836318145511641
Validation loss: 2.3756513118093174

Epoch: 5| Step: 8
Training loss: 2.3695203912311977
Validation loss: 2.3827253869410927

Epoch: 5| Step: 9
Training loss: 2.383850571941732
Validation loss: 2.3702750903684366

Epoch: 5| Step: 10
Training loss: 2.814287846601092
Validation loss: 2.377888380904207

Epoch: 117| Step: 0
Training loss: 2.532666410531338
Validation loss: 2.386136951954672

Epoch: 5| Step: 1
Training loss: 2.601039891260835
Validation loss: 2.376852339708165

Epoch: 5| Step: 2
Training loss: 2.565411100403736
Validation loss: 2.3797200352058425

Epoch: 5| Step: 3
Training loss: 2.919495945105307
Validation loss: 2.386471648103079

Epoch: 5| Step: 4
Training loss: 2.4924723782247575
Validation loss: 2.388759716701009

Epoch: 5| Step: 5
Training loss: 1.884402098705991
Validation loss: 2.361876783799774

Epoch: 5| Step: 6
Training loss: 2.2680058039030864
Validation loss: 2.3827084281057527

Epoch: 5| Step: 7
Training loss: 2.014576483961084
Validation loss: 2.364141385438032

Epoch: 5| Step: 8
Training loss: 3.086368887964894
Validation loss: 2.393037438167878

Epoch: 5| Step: 9
Training loss: 2.6978676004747086
Validation loss: 2.3868268499083127

Epoch: 5| Step: 10
Training loss: 2.9891686412193965
Validation loss: 2.375294263967804

Epoch: 118| Step: 0
Training loss: 2.522115071532525
Validation loss: 2.3833425840351308

Epoch: 5| Step: 1
Training loss: 2.3175258150278095
Validation loss: 2.3759076333063796

Epoch: 5| Step: 2
Training loss: 2.5771245691510285
Validation loss: 2.3826368418123196

Epoch: 5| Step: 3
Training loss: 1.8831555065946683
Validation loss: 2.3992437015322854

Epoch: 5| Step: 4
Training loss: 3.1580587812948133
Validation loss: 2.3751251628129117

Epoch: 5| Step: 5
Training loss: 2.317886780002088
Validation loss: 2.3783527945984937

Epoch: 5| Step: 6
Training loss: 2.727764924747031
Validation loss: 2.3789023704382

Epoch: 5| Step: 7
Training loss: 2.519390628646037
Validation loss: 2.3671545086425794

Epoch: 5| Step: 8
Training loss: 2.677939954527534
Validation loss: 2.390169607937117

Epoch: 5| Step: 9
Training loss: 2.5373085889359777
Validation loss: 2.3694627185782644

Epoch: 5| Step: 10
Training loss: 2.7845193741998258
Validation loss: 2.378593252482066

Epoch: 119| Step: 0
Training loss: 2.592451207024584
Validation loss: 2.38180191286232

Epoch: 5| Step: 1
Training loss: 2.37172030822755
Validation loss: 2.372094628412864

Epoch: 5| Step: 2
Training loss: 2.506459093765686
Validation loss: 2.396038681867496

Epoch: 5| Step: 3
Training loss: 2.2672250293698837
Validation loss: 2.366653901536143

Epoch: 5| Step: 4
Training loss: 2.3687067475811303
Validation loss: 2.371336046682272

Epoch: 5| Step: 5
Training loss: 3.041836842692829
Validation loss: 2.3846619404346634

Epoch: 5| Step: 6
Training loss: 2.389612120433064
Validation loss: 2.3765243432175267

Epoch: 5| Step: 7
Training loss: 3.1888233504462993
Validation loss: 2.394643443326659

Epoch: 5| Step: 8
Training loss: 2.256677256361636
Validation loss: 2.3828783778957408

Epoch: 5| Step: 9
Training loss: 2.5814168548227614
Validation loss: 2.3787549143804836

Epoch: 5| Step: 10
Training loss: 2.525220306152414
Validation loss: 2.385306357981111

Epoch: 120| Step: 0
Training loss: 2.404549728720158
Validation loss: 2.3876771177079315

Epoch: 5| Step: 1
Training loss: 2.466792912302587
Validation loss: 2.3678696129282826

Epoch: 5| Step: 2
Training loss: 2.7812724594752396
Validation loss: 2.3882209217264516

Epoch: 5| Step: 3
Training loss: 2.1750017889607407
Validation loss: 2.362868503917559

Epoch: 5| Step: 4
Training loss: 2.828972958060314
Validation loss: 2.377485479441615

Epoch: 5| Step: 5
Training loss: 2.3580485271931746
Validation loss: 2.3738010901513773

Epoch: 5| Step: 6
Training loss: 3.1912182830776437
Validation loss: 2.3969970633967046

Epoch: 5| Step: 7
Training loss: 2.388091795909382
Validation loss: 2.3878246669682435

Epoch: 5| Step: 8
Training loss: 2.377037579705982
Validation loss: 2.3810413746675274

Epoch: 5| Step: 9
Training loss: 2.7696115673132153
Validation loss: 2.391942062963826

Epoch: 5| Step: 10
Training loss: 2.230636029225555
Validation loss: 2.397753700175425

Epoch: 121| Step: 0
Training loss: 2.37462010607873
Validation loss: 2.378944388988638

Epoch: 5| Step: 1
Training loss: 2.434776447381641
Validation loss: 2.3616721641409444

Epoch: 5| Step: 2
Training loss: 2.8434659375853277
Validation loss: 2.3667808152776555

Epoch: 5| Step: 3
Training loss: 2.1849795398583507
Validation loss: 2.369419861061748

Epoch: 5| Step: 4
Training loss: 2.2794448817559996
Validation loss: 2.3730622964615593

Epoch: 5| Step: 5
Training loss: 3.103222150712837
Validation loss: 2.3778958942860404

Epoch: 5| Step: 6
Training loss: 2.0325742659660633
Validation loss: 2.3658640865386333

Epoch: 5| Step: 7
Training loss: 2.6968219455703077
Validation loss: 2.3767703268968705

Epoch: 5| Step: 8
Training loss: 2.46569306602371
Validation loss: 2.3770135030974013

Epoch: 5| Step: 9
Training loss: 2.7283545783102627
Validation loss: 2.389063864348701

Epoch: 5| Step: 10
Training loss: 2.879569030411204
Validation loss: 2.3806623500343838

Epoch: 122| Step: 0
Training loss: 2.6020446880352988
Validation loss: 2.3864832229989634

Epoch: 5| Step: 1
Training loss: 2.6909821595586143
Validation loss: 2.3648673476016375

Epoch: 5| Step: 2
Training loss: 2.6057107747234745
Validation loss: 2.3764896146997776

Epoch: 5| Step: 3
Training loss: 1.9948282130572985
Validation loss: 2.3793555536773288

Epoch: 5| Step: 4
Training loss: 2.3588674643600696
Validation loss: 2.3609675190223283

Epoch: 5| Step: 5
Training loss: 2.890322282766127
Validation loss: 2.39302309085363

Epoch: 5| Step: 6
Training loss: 2.638536428593676
Validation loss: 2.3541019393410627

Epoch: 5| Step: 7
Training loss: 2.7100663338175703
Validation loss: 2.3695377473901105

Epoch: 5| Step: 8
Training loss: 2.245028194938615
Validation loss: 2.3751852409085665

Epoch: 5| Step: 9
Training loss: 2.4309372217757086
Validation loss: 2.360417140827454

Epoch: 5| Step: 10
Training loss: 2.8573434418704036
Validation loss: 2.3757274627545266

Epoch: 123| Step: 0
Training loss: 2.8242050740397615
Validation loss: 2.3735794866664057

Epoch: 5| Step: 1
Training loss: 2.5129769171532437
Validation loss: 2.361065417705558

Epoch: 5| Step: 2
Training loss: 2.775895869355052
Validation loss: 2.389755491963876

Epoch: 5| Step: 3
Training loss: 2.244048831347193
Validation loss: 2.3869748802583604

Epoch: 5| Step: 4
Training loss: 2.253411461850708
Validation loss: 2.3792004392162958

Epoch: 5| Step: 5
Training loss: 2.2320824445996044
Validation loss: 2.3689228342542843

Epoch: 5| Step: 6
Training loss: 2.6598522219802807
Validation loss: 2.380324192978642

Epoch: 5| Step: 7
Training loss: 2.446067230460982
Validation loss: 2.3811016189517966

Epoch: 5| Step: 8
Training loss: 3.2278525519085894
Validation loss: 2.381809324024448

Epoch: 5| Step: 9
Training loss: 2.462541717330841
Validation loss: 2.3772794560657977

Epoch: 5| Step: 10
Training loss: 2.1700466885795877
Validation loss: 2.3669562378266424

Epoch: 124| Step: 0
Training loss: 2.5961452592669687
Validation loss: 2.372991530303341

Epoch: 5| Step: 1
Training loss: 2.876162749968548
Validation loss: 2.3836907312067015

Epoch: 5| Step: 2
Training loss: 2.04892587201292
Validation loss: 2.3737008665587833

Epoch: 5| Step: 3
Training loss: 3.248569320345397
Validation loss: 2.384736552323327

Epoch: 5| Step: 4
Training loss: 2.4377465734722774
Validation loss: 2.3733092346963534

Epoch: 5| Step: 5
Training loss: 2.34420293881854
Validation loss: 2.3781291865097347

Epoch: 5| Step: 6
Training loss: 2.395607337796981
Validation loss: 2.3922017572046856

Epoch: 5| Step: 7
Training loss: 2.3590295804034045
Validation loss: 2.3727221616334906

Epoch: 5| Step: 8
Training loss: 2.5179558611903006
Validation loss: 2.3798402298902896

Epoch: 5| Step: 9
Training loss: 2.3505741716573
Validation loss: 2.3854460570470093

Epoch: 5| Step: 10
Training loss: 2.774644186216932
Validation loss: 2.371891692758612

Epoch: 125| Step: 0
Training loss: 2.932171310384989
Validation loss: 2.376017540879004

Epoch: 5| Step: 1
Training loss: 3.0359793667500496
Validation loss: 2.375553927889694

Epoch: 5| Step: 2
Training loss: 2.8119195975018454
Validation loss: 2.374897555790198

Epoch: 5| Step: 3
Training loss: 2.72083544494952
Validation loss: 2.356822042407993

Epoch: 5| Step: 4
Training loss: 2.1220707619074535
Validation loss: 2.3652332661860016

Epoch: 5| Step: 5
Training loss: 2.1084455915075
Validation loss: 2.38188599276063

Epoch: 5| Step: 6
Training loss: 2.0210368522594826
Validation loss: 2.3654210667195326

Epoch: 5| Step: 7
Training loss: 2.4098491751300535
Validation loss: 2.386060760402425

Epoch: 5| Step: 8
Training loss: 2.5114929192618076
Validation loss: 2.361908597941516

Epoch: 5| Step: 9
Training loss: 2.5547830639618407
Validation loss: 2.3690513557027293

Epoch: 5| Step: 10
Training loss: 2.5902552213075896
Validation loss: 2.3575093369288234

Epoch: 126| Step: 0
Training loss: 2.3777842013053445
Validation loss: 2.380534697752573

Epoch: 5| Step: 1
Training loss: 2.64453584791767
Validation loss: 2.3848249571439895

Epoch: 5| Step: 2
Training loss: 2.6717860335323023
Validation loss: 2.3911771405441393

Epoch: 5| Step: 3
Training loss: 1.933174596496222
Validation loss: 2.3807902539043715

Epoch: 5| Step: 4
Training loss: 2.132571922958707
Validation loss: 2.3661431112006945

Epoch: 5| Step: 5
Training loss: 2.97367370276689
Validation loss: 2.3970090420110353

Epoch: 5| Step: 6
Training loss: 2.484482960784392
Validation loss: 2.3667032705067728

Epoch: 5| Step: 7
Training loss: 2.557843979331288
Validation loss: 2.370077992454842

Epoch: 5| Step: 8
Training loss: 2.7485911488484116
Validation loss: 2.3870247482815063

Epoch: 5| Step: 9
Training loss: 2.7616560738666767
Validation loss: 2.3831424085998667

Epoch: 5| Step: 10
Training loss: 2.512380557281423
Validation loss: 2.378425562916164

Epoch: 127| Step: 0
Training loss: 3.2059251408776115
Validation loss: 2.373517942192444

Epoch: 5| Step: 1
Training loss: 2.1584596231204127
Validation loss: 2.3732114424807427

Epoch: 5| Step: 2
Training loss: 2.8221239522994614
Validation loss: 2.3815538879900453

Epoch: 5| Step: 3
Training loss: 2.761629224564461
Validation loss: 2.3788832548826986

Epoch: 5| Step: 4
Training loss: 2.4226366383663844
Validation loss: 2.3576084872626475

Epoch: 5| Step: 5
Training loss: 2.6554229346304656
Validation loss: 2.365924225347004

Epoch: 5| Step: 6
Training loss: 2.460229971766268
Validation loss: 2.377743589766075

Epoch: 5| Step: 7
Training loss: 2.3297168998475026
Validation loss: 2.371949207998112

Epoch: 5| Step: 8
Training loss: 2.178691786985815
Validation loss: 2.3600525426794667

Epoch: 5| Step: 9
Training loss: 2.4734646167341054
Validation loss: 2.3764398050061715

Epoch: 5| Step: 10
Training loss: 2.3050985713246512
Validation loss: 2.3883092158189245

Epoch: 128| Step: 0
Training loss: 2.8800056666742315
Validation loss: 2.3842335358899662

Epoch: 5| Step: 1
Training loss: 2.8916670287147612
Validation loss: 2.3615251368348438

Epoch: 5| Step: 2
Training loss: 2.3217367303065903
Validation loss: 2.377499159783913

Epoch: 5| Step: 3
Training loss: 2.2770042100883368
Validation loss: 2.3621907140418177

Epoch: 5| Step: 4
Training loss: 2.293759159412858
Validation loss: 2.374645729174574

Epoch: 5| Step: 5
Training loss: 1.8644391506717555
Validation loss: 2.3788011881544944

Epoch: 5| Step: 6
Training loss: 2.328450532210407
Validation loss: 2.3726453880291496

Epoch: 5| Step: 7
Training loss: 2.8630554193428592
Validation loss: 2.3840711900653715

Epoch: 5| Step: 8
Training loss: 2.8162680921384022
Validation loss: 2.353627967527491

Epoch: 5| Step: 9
Training loss: 2.6622832053308985
Validation loss: 2.3765642016122386

Epoch: 5| Step: 10
Training loss: 2.2619036399628194
Validation loss: 2.368766108580484

Epoch: 129| Step: 0
Training loss: 2.161351237267419
Validation loss: 2.3882049336781574

Epoch: 5| Step: 1
Training loss: 3.139860601064355
Validation loss: 2.3731626248012607

Epoch: 5| Step: 2
Training loss: 2.1573649302048175
Validation loss: 2.363175818948331

Epoch: 5| Step: 3
Training loss: 2.270725795987698
Validation loss: 2.377621057679482

Epoch: 5| Step: 4
Training loss: 1.8748400937876168
Validation loss: 2.3775934492431534

Epoch: 5| Step: 5
Training loss: 2.5327853973840067
Validation loss: 2.3812522994324707

Epoch: 5| Step: 6
Training loss: 2.440202926108228
Validation loss: 2.377763237397757

Epoch: 5| Step: 7
Training loss: 2.8003331122476807
Validation loss: 2.3839650196949007

Epoch: 5| Step: 8
Training loss: 2.8540143902849566
Validation loss: 2.3810030140891265

Epoch: 5| Step: 9
Training loss: 2.798047209018984
Validation loss: 2.3620054558269166

Epoch: 5| Step: 10
Training loss: 2.509247271373725
Validation loss: 2.3631420219575037

Epoch: 130| Step: 0
Training loss: 2.9832016800400782
Validation loss: 2.3586393971344153

Epoch: 5| Step: 1
Training loss: 2.1690812839034916
Validation loss: 2.380348680902376

Epoch: 5| Step: 2
Training loss: 2.7417492638603744
Validation loss: 2.3670209871226398

Epoch: 5| Step: 3
Training loss: 2.3583706366438535
Validation loss: 2.3734336182391766

Epoch: 5| Step: 4
Training loss: 2.4707807083915725
Validation loss: 2.3697836508756773

Epoch: 5| Step: 5
Training loss: 2.4472603641827932
Validation loss: 2.380506312717493

Epoch: 5| Step: 6
Training loss: 2.0125711653548244
Validation loss: 2.356055400906654

Epoch: 5| Step: 7
Training loss: 2.6527332137948885
Validation loss: 2.3728255079155813

Epoch: 5| Step: 8
Training loss: 2.7869421327987065
Validation loss: 2.3644322273906293

Epoch: 5| Step: 9
Training loss: 2.38622072708455
Validation loss: 2.3817656499842603

Epoch: 5| Step: 10
Training loss: 2.5674226510376665
Validation loss: 2.367843309117108

Epoch: 131| Step: 0
Training loss: 2.438211483921345
Validation loss: 2.3698631837464155

Epoch: 5| Step: 1
Training loss: 2.239017491976385
Validation loss: 2.3641902695731147

Epoch: 5| Step: 2
Training loss: 2.763593024217462
Validation loss: 2.3519281423236147

Epoch: 5| Step: 3
Training loss: 2.800455965654534
Validation loss: 2.3778074787459005

Epoch: 5| Step: 4
Training loss: 2.644391054750707
Validation loss: 2.36600243493507

Epoch: 5| Step: 5
Training loss: 2.095579344550485
Validation loss: 2.3776591709198494

Epoch: 5| Step: 6
Training loss: 2.562125853229475
Validation loss: 2.3666581792244497

Epoch: 5| Step: 7
Training loss: 2.585382961040166
Validation loss: 2.370380094257159

Epoch: 5| Step: 8
Training loss: 2.5959314571671683
Validation loss: 2.3579122236572414

Epoch: 5| Step: 9
Training loss: 2.219522690882388
Validation loss: 2.381930542844535

Epoch: 5| Step: 10
Training loss: 2.7795811478938783
Validation loss: 2.361536641856259

Epoch: 132| Step: 0
Training loss: 2.1926419451185843
Validation loss: 2.369254127793604

Epoch: 5| Step: 1
Training loss: 2.444969372547749
Validation loss: 2.3665106178005058

Epoch: 5| Step: 2
Training loss: 2.4920002738438143
Validation loss: 2.366580866587574

Epoch: 5| Step: 3
Training loss: 2.6360165261371398
Validation loss: 2.3619203984961126

Epoch: 5| Step: 4
Training loss: 2.818660939368087
Validation loss: 2.3823380504774327

Epoch: 5| Step: 5
Training loss: 1.8213797784462096
Validation loss: 2.3651581975649014

Epoch: 5| Step: 6
Training loss: 2.4543657991699717
Validation loss: 2.3575133756628444

Epoch: 5| Step: 7
Training loss: 2.5532433397188856
Validation loss: 2.371775069179777

Epoch: 5| Step: 8
Training loss: 2.862506090182693
Validation loss: 2.3607444111272415

Epoch: 5| Step: 9
Training loss: 2.8028885961761776
Validation loss: 2.364872913121221

Epoch: 5| Step: 10
Training loss: 2.5135294081737722
Validation loss: 2.365856762502576

Epoch: 133| Step: 0
Training loss: 2.827823686091759
Validation loss: 2.3815599462830015

Epoch: 5| Step: 1
Training loss: 2.3885185585506794
Validation loss: 2.3676766027991367

Epoch: 5| Step: 2
Training loss: 2.8770961583482615
Validation loss: 2.3513340982008106

Epoch: 5| Step: 3
Training loss: 2.879207848909008
Validation loss: 2.3761396269894677

Epoch: 5| Step: 4
Training loss: 2.1073699463959574
Validation loss: 2.3552204735140023

Epoch: 5| Step: 5
Training loss: 2.5037187574535125
Validation loss: 2.3765510973197985

Epoch: 5| Step: 6
Training loss: 1.8951301807790433
Validation loss: 2.382617995084953

Epoch: 5| Step: 7
Training loss: 1.8976685650403522
Validation loss: 2.376066760611269

Epoch: 5| Step: 8
Training loss: 2.5667415963006825
Validation loss: 2.3834395916387816

Epoch: 5| Step: 9
Training loss: 2.5954397741042263
Validation loss: 2.3565925860244246

Epoch: 5| Step: 10
Training loss: 2.9366651931510748
Validation loss: 2.369518802966447

Epoch: 134| Step: 0
Training loss: 2.215418934352485
Validation loss: 2.3834794075312864

Epoch: 5| Step: 1
Training loss: 2.681288705115177
Validation loss: 2.357401702226614

Epoch: 5| Step: 2
Training loss: 2.5098377261956033
Validation loss: 2.3721153625058684

Epoch: 5| Step: 3
Training loss: 2.814904181440231
Validation loss: 2.3605044858017257

Epoch: 5| Step: 4
Training loss: 1.895220570170601
Validation loss: 2.3784661272417615

Epoch: 5| Step: 5
Training loss: 2.599567278285422
Validation loss: 2.3711326752565705

Epoch: 5| Step: 6
Training loss: 2.761473303521291
Validation loss: 2.3527484977774615

Epoch: 5| Step: 7
Training loss: 2.8067146987006613
Validation loss: 2.3592600700399617

Epoch: 5| Step: 8
Training loss: 2.1816692572399328
Validation loss: 2.372319004141292

Epoch: 5| Step: 9
Training loss: 2.4957519679321125
Validation loss: 2.3702284846552524

Epoch: 5| Step: 10
Training loss: 2.448597903861249
Validation loss: 2.3797632194654925

Epoch: 135| Step: 0
Training loss: 2.484688217283886
Validation loss: 2.3663909193461627

Epoch: 5| Step: 1
Training loss: 2.0508818102205226
Validation loss: 2.362742021279242

Epoch: 5| Step: 2
Training loss: 2.5531395004775836
Validation loss: 2.364703075403212

Epoch: 5| Step: 3
Training loss: 3.113540696039407
Validation loss: 2.3633670545537564

Epoch: 5| Step: 4
Training loss: 2.4525589988525827
Validation loss: 2.3631151534714

Epoch: 5| Step: 5
Training loss: 2.5006097050098703
Validation loss: 2.3418799089714595

Epoch: 5| Step: 6
Training loss: 2.416370461387293
Validation loss: 2.378769708248217

Epoch: 5| Step: 7
Training loss: 2.071440882246896
Validation loss: 2.3751241061087094

Epoch: 5| Step: 8
Training loss: 2.45609720545951
Validation loss: 2.384964566166949

Epoch: 5| Step: 9
Training loss: 2.790502865501235
Validation loss: 2.3820728517047924

Epoch: 5| Step: 10
Training loss: 2.5237593785074375
Validation loss: 2.3575816688027764

Epoch: 136| Step: 0
Training loss: 2.8499687862360057
Validation loss: 2.3564313325957307

Epoch: 5| Step: 1
Training loss: 2.555477475157548
Validation loss: 2.3775555710898084

Epoch: 5| Step: 2
Training loss: 2.5131321277911036
Validation loss: 2.375556881592397

Epoch: 5| Step: 3
Training loss: 2.8418569447044724
Validation loss: 2.3743938391404806

Epoch: 5| Step: 4
Training loss: 2.4814317651083853
Validation loss: 2.3780646032931463

Epoch: 5| Step: 5
Training loss: 2.5999750099448353
Validation loss: 2.3619536637598184

Epoch: 5| Step: 6
Training loss: 2.4196343670637264
Validation loss: 2.367630166553901

Epoch: 5| Step: 7
Training loss: 2.498840826233939
Validation loss: 2.3538423573093943

Epoch: 5| Step: 8
Training loss: 2.4034369733723295
Validation loss: 2.36440100072361

Epoch: 5| Step: 9
Training loss: 1.7676595932537662
Validation loss: 2.3669557634305836

Epoch: 5| Step: 10
Training loss: 2.4945460910755863
Validation loss: 2.3588508545850964

Epoch: 137| Step: 0
Training loss: 2.1570598905735086
Validation loss: 2.3610548702380583

Epoch: 5| Step: 1
Training loss: 2.745403783732
Validation loss: 2.3569342784581098

Epoch: 5| Step: 2
Training loss: 2.0032348697899804
Validation loss: 2.3715012496116072

Epoch: 5| Step: 3
Training loss: 2.4666880434845484
Validation loss: 2.373487860630936

Epoch: 5| Step: 4
Training loss: 2.6506247701647045
Validation loss: 2.354558113027778

Epoch: 5| Step: 5
Training loss: 2.82168976607747
Validation loss: 2.3453462487754613

Epoch: 5| Step: 6
Training loss: 2.5763381777077146
Validation loss: 2.3620702154778797

Epoch: 5| Step: 7
Training loss: 2.4537584009478537
Validation loss: 2.376513724663147

Epoch: 5| Step: 8
Training loss: 2.3732579518073145
Validation loss: 2.3630729424161214

Epoch: 5| Step: 9
Training loss: 2.28615200160144
Validation loss: 2.376926904452951

Epoch: 5| Step: 10
Training loss: 3.014757416994806
Validation loss: 2.366561388812363

Epoch: 138| Step: 0
Training loss: 2.5152915591442757
Validation loss: 2.363533989180275

Epoch: 5| Step: 1
Training loss: 2.258620701579239
Validation loss: 2.350329209969205

Epoch: 5| Step: 2
Training loss: 2.2089094694003073
Validation loss: 2.3576003426951204

Epoch: 5| Step: 3
Training loss: 2.7111621071061576
Validation loss: 2.3566137844949844

Epoch: 5| Step: 4
Training loss: 2.538141359353059
Validation loss: 2.356335599028867

Epoch: 5| Step: 5
Training loss: 2.7671062576025225
Validation loss: 2.3764722607684883

Epoch: 5| Step: 6
Training loss: 2.389471037359295
Validation loss: 2.3681210180137766

Epoch: 5| Step: 7
Training loss: 2.635597453996752
Validation loss: 2.377585157484581

Epoch: 5| Step: 8
Training loss: 2.284579003614207
Validation loss: 2.3526276114883076

Epoch: 5| Step: 9
Training loss: 2.3952454439993227
Validation loss: 2.3595408611080035

Epoch: 5| Step: 10
Training loss: 2.8089834481414044
Validation loss: 2.374021477532124

Epoch: 139| Step: 0
Training loss: 2.634541020529948
Validation loss: 2.364169898640586

Epoch: 5| Step: 1
Training loss: 2.4254657337455274
Validation loss: 2.3600290836007694

Epoch: 5| Step: 2
Training loss: 2.8632392828182955
Validation loss: 2.3667050079776764

Epoch: 5| Step: 3
Training loss: 1.834570452855512
Validation loss: 2.3586967442486153

Epoch: 5| Step: 4
Training loss: 2.706091603495715
Validation loss: 2.3767974325541075

Epoch: 5| Step: 5
Training loss: 2.429908668779722
Validation loss: 2.3561627924547786

Epoch: 5| Step: 6
Training loss: 2.4966105372388583
Validation loss: 2.3697604125372402

Epoch: 5| Step: 7
Training loss: 2.5836283812668945
Validation loss: 2.349688812812324

Epoch: 5| Step: 8
Training loss: 2.216841615737935
Validation loss: 2.3611471986113983

Epoch: 5| Step: 9
Training loss: 2.3315069225780345
Validation loss: 2.3580637075419077

Epoch: 5| Step: 10
Training loss: 2.8440149204812415
Validation loss: 2.3577100321077746

Epoch: 140| Step: 0
Training loss: 2.280334916194788
Validation loss: 2.36275723820178

Epoch: 5| Step: 1
Training loss: 2.532639863651182
Validation loss: 2.3532386022750353

Epoch: 5| Step: 2
Training loss: 2.1918781608774123
Validation loss: 2.3786471061543537

Epoch: 5| Step: 3
Training loss: 3.0559463443739294
Validation loss: 2.3752029129331533

Epoch: 5| Step: 4
Training loss: 2.592787230718961
Validation loss: 2.3457481130848223

Epoch: 5| Step: 5
Training loss: 3.070485971612259
Validation loss: 2.368370160073161

Epoch: 5| Step: 6
Training loss: 3.1112816873594302
Validation loss: 2.3753573856334724

Epoch: 5| Step: 7
Training loss: 2.420374448511697
Validation loss: 2.3661801893562875

Epoch: 5| Step: 8
Training loss: 2.0271700452062222
Validation loss: 2.369049292064552

Epoch: 5| Step: 9
Training loss: 1.8741332912003417
Validation loss: 2.375755386386299

Epoch: 5| Step: 10
Training loss: 1.6705776421670142
Validation loss: 2.371584441301104

Epoch: 141| Step: 0
Training loss: 2.121387215505253
Validation loss: 2.3509862704328266

Epoch: 5| Step: 1
Training loss: 2.608288841558725
Validation loss: 2.378374059432069

Epoch: 5| Step: 2
Training loss: 2.395425203363116
Validation loss: 2.372338206629585

Epoch: 5| Step: 3
Training loss: 2.4674929545107727
Validation loss: 2.3511729028234893

Epoch: 5| Step: 4
Training loss: 2.875773284411934
Validation loss: 2.3581480353558457

Epoch: 5| Step: 5
Training loss: 2.636868304497066
Validation loss: 2.3744217827746708

Epoch: 5| Step: 6
Training loss: 2.465437683029646
Validation loss: 2.3496632852507804

Epoch: 5| Step: 7
Training loss: 2.935144981949525
Validation loss: 2.3636427622237433

Epoch: 5| Step: 8
Training loss: 2.288905844682195
Validation loss: 2.3583747271677074

Epoch: 5| Step: 9
Training loss: 2.411065077110278
Validation loss: 2.351412089851598

Epoch: 5| Step: 10
Training loss: 1.569186513893078
Validation loss: 2.362426974406146

Epoch: 142| Step: 0
Training loss: 2.165866031417027
Validation loss: 2.3673717181124507

Epoch: 5| Step: 1
Training loss: 1.9384143271653163
Validation loss: 2.359757468800525

Epoch: 5| Step: 2
Training loss: 2.993863823942812
Validation loss: 2.3768018580922665

Epoch: 5| Step: 3
Training loss: 2.6657678062762256
Validation loss: 2.3644292717175257

Epoch: 5| Step: 4
Training loss: 2.830060433595066
Validation loss: 2.354605198760671

Epoch: 5| Step: 5
Training loss: 2.6625418252301416
Validation loss: 2.369013027144765

Epoch: 5| Step: 6
Training loss: 2.2667001212213047
Validation loss: 2.3670332912652317

Epoch: 5| Step: 7
Training loss: 1.9322018940954122
Validation loss: 2.3627604341282438

Epoch: 5| Step: 8
Training loss: 2.723981800063359
Validation loss: 2.3728230424030734

Epoch: 5| Step: 9
Training loss: 2.1737350073764055
Validation loss: 2.3764828854412836

Epoch: 5| Step: 10
Training loss: 2.634257387045004
Validation loss: 2.3809303972259217

Epoch: 143| Step: 0
Training loss: 2.7424038098000554
Validation loss: 2.3806971345198136

Epoch: 5| Step: 1
Training loss: 2.8651787896150496
Validation loss: 2.3791541182529006

Epoch: 5| Step: 2
Training loss: 2.399493652812292
Validation loss: 2.3692607958892715

Epoch: 5| Step: 3
Training loss: 2.73889884568632
Validation loss: 2.361823342827026

Epoch: 5| Step: 4
Training loss: 2.650299228112772
Validation loss: 2.375848588317179

Epoch: 5| Step: 5
Training loss: 2.23194507703579
Validation loss: 2.3734357590757305

Epoch: 5| Step: 6
Training loss: 2.063182140022474
Validation loss: 2.3416329084691316

Epoch: 5| Step: 7
Training loss: 1.9053614687465112
Validation loss: 2.3358071741128725

Epoch: 5| Step: 8
Training loss: 2.344030643191228
Validation loss: 2.3616891057793716

Epoch: 5| Step: 9
Training loss: 2.779841034001118
Validation loss: 2.3558250188697296

Epoch: 5| Step: 10
Training loss: 2.2115767670187796
Validation loss: 2.3699618486115224

Epoch: 144| Step: 0
Training loss: 2.5968666195877677
Validation loss: 2.372875625762639

Epoch: 5| Step: 1
Training loss: 2.1560272986359377
Validation loss: 2.3742604877313225

Epoch: 5| Step: 2
Training loss: 3.0427296144202045
Validation loss: 2.3583268090020204

Epoch: 5| Step: 3
Training loss: 1.8612905300382536
Validation loss: 2.370562244734841

Epoch: 5| Step: 4
Training loss: 1.970492122004262
Validation loss: 2.352307822762584

Epoch: 5| Step: 5
Training loss: 2.3347036107421015
Validation loss: 2.363957659539054

Epoch: 5| Step: 6
Training loss: 2.338394964724172
Validation loss: 2.3820538579145287

Epoch: 5| Step: 7
Training loss: 2.8077943218578922
Validation loss: 2.3458985727471835

Epoch: 5| Step: 8
Training loss: 2.9293787272181158
Validation loss: 2.3595582874136856

Epoch: 5| Step: 9
Training loss: 2.584164290965773
Validation loss: 2.3524978233535605

Epoch: 5| Step: 10
Training loss: 2.256576569400674
Validation loss: 2.372838671677837

Epoch: 145| Step: 0
Training loss: 2.7775375792178374
Validation loss: 2.358249972238493

Epoch: 5| Step: 1
Training loss: 2.550255994475774
Validation loss: 2.3788510475507367

Epoch: 5| Step: 2
Training loss: 1.9591152037180481
Validation loss: 2.3638653308593356

Epoch: 5| Step: 3
Training loss: 1.8099545988426964
Validation loss: 2.3803864370671413

Epoch: 5| Step: 4
Training loss: 2.0298103512651795
Validation loss: 2.35891726418341

Epoch: 5| Step: 5
Training loss: 2.1422750976816047
Validation loss: 2.3530897776863626

Epoch: 5| Step: 6
Training loss: 2.8292119587646996
Validation loss: 2.3407549189471304

Epoch: 5| Step: 7
Training loss: 2.3820397296478086
Validation loss: 2.372442943609128

Epoch: 5| Step: 8
Training loss: 2.1746865057555835
Validation loss: 2.3705709898508176

Epoch: 5| Step: 9
Training loss: 3.2690785230166064
Validation loss: 2.3579493018607125

Epoch: 5| Step: 10
Training loss: 2.889573024372908
Validation loss: 2.3578685810286415

Epoch: 146| Step: 0
Training loss: 2.287125428597053
Validation loss: 2.363054725111563

Epoch: 5| Step: 1
Training loss: 2.62177159829554
Validation loss: 2.3590785894812876

Epoch: 5| Step: 2
Training loss: 2.302601947163534
Validation loss: 2.374147093623203

Epoch: 5| Step: 3
Training loss: 2.339520924098965
Validation loss: 2.3649131050198977

Epoch: 5| Step: 4
Training loss: 2.4421893275395035
Validation loss: 2.3609610897357123

Epoch: 5| Step: 5
Training loss: 2.128157121637169
Validation loss: 2.367905287986472

Epoch: 5| Step: 6
Training loss: 2.6699723278711898
Validation loss: 2.331265812052939

Epoch: 5| Step: 7
Training loss: 2.649228138345942
Validation loss: 2.355992750130542

Epoch: 5| Step: 8
Training loss: 2.4789683692763815
Validation loss: 2.3741504021753377

Epoch: 5| Step: 9
Training loss: 2.6889301309584126
Validation loss: 2.3510888209631857

Epoch: 5| Step: 10
Training loss: 2.3427874813954848
Validation loss: 2.360353096110272

Epoch: 147| Step: 0
Training loss: 2.237196841027935
Validation loss: 2.342669962669335

Epoch: 5| Step: 1
Training loss: 2.5242710685443894
Validation loss: 2.354848773947154

Epoch: 5| Step: 2
Training loss: 2.2942943997567373
Validation loss: 2.3674962013622087

Epoch: 5| Step: 3
Training loss: 2.368203225352724
Validation loss: 2.3652711996857407

Epoch: 5| Step: 4
Training loss: 2.1986365081140655
Validation loss: 2.3644783640363594

Epoch: 5| Step: 5
Training loss: 1.873429530797303
Validation loss: 2.3632097076649248

Epoch: 5| Step: 6
Training loss: 2.6194786860615906
Validation loss: 2.364404159189615

Epoch: 5| Step: 7
Training loss: 3.0696245738052212
Validation loss: 2.3617360515132457

Epoch: 5| Step: 8
Training loss: 2.8127246343126515
Validation loss: 2.351735233635717

Epoch: 5| Step: 9
Training loss: 2.415313988881461
Validation loss: 2.343402107698264

Epoch: 5| Step: 10
Training loss: 2.353861955035392
Validation loss: 2.349855224506474

Epoch: 148| Step: 0
Training loss: 2.651381125510096
Validation loss: 2.3557241784939227

Epoch: 5| Step: 1
Training loss: 1.8104250639562323
Validation loss: 2.350040263474895

Epoch: 5| Step: 2
Training loss: 2.1661984475721323
Validation loss: 2.3659931847996667

Epoch: 5| Step: 3
Training loss: 2.7253731918269475
Validation loss: 2.352991648494006

Epoch: 5| Step: 4
Training loss: 2.6035461195056295
Validation loss: 2.343697684192944

Epoch: 5| Step: 5
Training loss: 2.4600233529695936
Validation loss: 2.3543868332635136

Epoch: 5| Step: 6
Training loss: 2.4494892561132433
Validation loss: 2.364167739654111

Epoch: 5| Step: 7
Training loss: 2.2828801222752464
Validation loss: 2.3677325603167283

Epoch: 5| Step: 8
Training loss: 2.068723363791301
Validation loss: 2.3375936781470488

Epoch: 5| Step: 9
Training loss: 2.888206666288336
Validation loss: 2.3636257244993

Epoch: 5| Step: 10
Training loss: 2.7310669861675985
Validation loss: 2.3699707376480386

Epoch: 149| Step: 0
Training loss: 3.4196259933220916
Validation loss: 2.358182121344661

Epoch: 5| Step: 1
Training loss: 2.424362086915422
Validation loss: 2.3665881959655493

Epoch: 5| Step: 2
Training loss: 2.5977335294543336
Validation loss: 2.3629880461055843

Epoch: 5| Step: 3
Training loss: 2.4385627972712434
Validation loss: 2.3545218372304015

Epoch: 5| Step: 4
Training loss: 1.6930174168807874
Validation loss: 2.349224122377929

Epoch: 5| Step: 5
Training loss: 2.262801732971596
Validation loss: 2.3513996347365156

Epoch: 5| Step: 6
Training loss: 2.7571697404625213
Validation loss: 2.371720544949085

Epoch: 5| Step: 7
Training loss: 2.533818672352379
Validation loss: 2.3607112235738206

Epoch: 5| Step: 8
Training loss: 2.2799052625348346
Validation loss: 2.350525220844141

Epoch: 5| Step: 9
Training loss: 2.0848488699389796
Validation loss: 2.366672345694361

Epoch: 5| Step: 10
Training loss: 2.188497697284717
Validation loss: 2.353148111998144

Epoch: 150| Step: 0
Training loss: 2.4571141166843815
Validation loss: 2.360068846362837

Epoch: 5| Step: 1
Training loss: 2.580387671568653
Validation loss: 2.3414136731172173

Epoch: 5| Step: 2
Training loss: 2.5032683942205276
Validation loss: 2.3540007572442416

Epoch: 5| Step: 3
Training loss: 2.1541337395026274
Validation loss: 2.3468328041958775

Epoch: 5| Step: 4
Training loss: 2.4969621320854274
Validation loss: 2.359887630603293

Epoch: 5| Step: 5
Training loss: 2.7718681085924497
Validation loss: 2.3370132276808597

Epoch: 5| Step: 6
Training loss: 2.203426800340603
Validation loss: 2.364517463249796

Epoch: 5| Step: 7
Training loss: 2.4727694468930568
Validation loss: 2.360697238253431

Epoch: 5| Step: 8
Training loss: 2.6549712749586787
Validation loss: 2.35171632948693

Epoch: 5| Step: 9
Training loss: 2.208170207014616
Validation loss: 2.3623752512660974

Epoch: 5| Step: 10
Training loss: 2.4107549532734898
Validation loss: 2.346680933990181

Epoch: 151| Step: 0
Training loss: 2.686486075116194
Validation loss: 2.345834542562694

Epoch: 5| Step: 1
Training loss: 1.828008990397142
Validation loss: 2.361706994940802

Epoch: 5| Step: 2
Training loss: 2.5696673757624944
Validation loss: 2.387073948328936

Epoch: 5| Step: 3
Training loss: 2.4393567569411156
Validation loss: 2.369634561741201

Epoch: 5| Step: 4
Training loss: 2.501525985384561
Validation loss: 2.3498426684057434

Epoch: 5| Step: 5
Training loss: 2.511070060910201
Validation loss: 2.3338758091462104

Epoch: 5| Step: 6
Training loss: 2.3142225705973503
Validation loss: 2.376907370706984

Epoch: 5| Step: 7
Training loss: 2.396418613318126
Validation loss: 2.3478269190290826

Epoch: 5| Step: 8
Training loss: 2.6666062368062655
Validation loss: 2.371014074595974

Epoch: 5| Step: 9
Training loss: 2.06179462277352
Validation loss: 2.3662714445196373

Epoch: 5| Step: 10
Training loss: 2.9040691437804833
Validation loss: 2.3194375839886807

Epoch: 152| Step: 0
Training loss: 2.163061688633833
Validation loss: 2.342123743625945

Epoch: 5| Step: 1
Training loss: 1.7888629252298347
Validation loss: 2.3392246050396786

Epoch: 5| Step: 2
Training loss: 2.480924020873064
Validation loss: 2.36857821122214

Epoch: 5| Step: 3
Training loss: 2.892800002568169
Validation loss: 2.3671262328325096

Epoch: 5| Step: 4
Training loss: 2.673866645084111
Validation loss: 2.3561044598812

Epoch: 5| Step: 5
Training loss: 2.398164416743078
Validation loss: 2.3581851142001016

Epoch: 5| Step: 6
Training loss: 2.50806670519691
Validation loss: 2.3543785338187972

Epoch: 5| Step: 7
Training loss: 2.5812471846964633
Validation loss: 2.3536551420087815

Epoch: 5| Step: 8
Training loss: 2.4225610561176114
Validation loss: 2.345606192876127

Epoch: 5| Step: 9
Training loss: 2.3833633536557777
Validation loss: 2.3417364816728483

Epoch: 5| Step: 10
Training loss: 2.32058652550539
Validation loss: 2.3532681163738136

Epoch: 153| Step: 0
Training loss: 2.2915331946142614
Validation loss: 2.3222806738538146

Epoch: 5| Step: 1
Training loss: 2.7193100451087666
Validation loss: 2.3618067104214333

Epoch: 5| Step: 2
Training loss: 2.7204376770351804
Validation loss: 2.3358747502886237

Epoch: 5| Step: 3
Training loss: 1.8755465028957656
Validation loss: 2.3591861020379143

Epoch: 5| Step: 4
Training loss: 2.445047284938665
Validation loss: 2.3441243146926025

Epoch: 5| Step: 5
Training loss: 2.6308421564140505
Validation loss: 2.3557359697626215

Epoch: 5| Step: 6
Training loss: 2.520099711791787
Validation loss: 2.3536996377267894

Epoch: 5| Step: 7
Training loss: 2.424501828020492
Validation loss: 2.3548697110527828

Epoch: 5| Step: 8
Training loss: 2.4212814095842297
Validation loss: 2.3584756857440707

Epoch: 5| Step: 9
Training loss: 2.0683405859997053
Validation loss: 2.3579565080309868

Epoch: 5| Step: 10
Training loss: 2.4776447230006737
Validation loss: 2.3502859610124194

Epoch: 154| Step: 0
Training loss: 1.9732912759981533
Validation loss: 2.3572395345877117

Epoch: 5| Step: 1
Training loss: 2.8304182839376124
Validation loss: 2.3310221096741905

Epoch: 5| Step: 2
Training loss: 2.5433920231151643
Validation loss: 2.3557068380936315

Epoch: 5| Step: 3
Training loss: 2.198612651341115
Validation loss: 2.36164291138658

Epoch: 5| Step: 4
Training loss: 1.999169773397805
Validation loss: 2.3630131037067406

Epoch: 5| Step: 5
Training loss: 2.860273209706982
Validation loss: 2.354105756318141

Epoch: 5| Step: 6
Training loss: 2.2481908942654547
Validation loss: 2.3662453038741664

Epoch: 5| Step: 7
Training loss: 2.817094398690831
Validation loss: 2.3560352022877717

Epoch: 5| Step: 8
Training loss: 2.5938091041541056
Validation loss: 2.3501834627152327

Epoch: 5| Step: 9
Training loss: 2.1254776810448113
Validation loss: 2.336247418277866

Epoch: 5| Step: 10
Training loss: 2.4325800417740524
Validation loss: 2.3521612237315463

Epoch: 155| Step: 0
Training loss: 2.4314447163175026
Validation loss: 2.3328952934813794

Epoch: 5| Step: 1
Training loss: 2.124639143878136
Validation loss: 2.3274504829712703

Epoch: 5| Step: 2
Training loss: 2.5600340538442143
Validation loss: 2.361674210343875

Epoch: 5| Step: 3
Training loss: 2.4880139074028857
Validation loss: 2.3468270527914905

Epoch: 5| Step: 4
Training loss: 2.42200602515406
Validation loss: 2.334619703306825

Epoch: 5| Step: 5
Training loss: 2.602170947523763
Validation loss: 2.3629557219338024

Epoch: 5| Step: 6
Training loss: 2.3935120546488817
Validation loss: 2.345176823597549

Epoch: 5| Step: 7
Training loss: 2.3719689954947514
Validation loss: 2.3568932565317837

Epoch: 5| Step: 8
Training loss: 2.7181194933574346
Validation loss: 2.349115095307101

Epoch: 5| Step: 9
Training loss: 2.2974155334951756
Validation loss: 2.345611784424231

Epoch: 5| Step: 10
Training loss: 2.185964972191837
Validation loss: 2.3659160032159927

Epoch: 156| Step: 0
Training loss: 2.1888994372652117
Validation loss: 2.315357915556426

Epoch: 5| Step: 1
Training loss: 2.550472223276808
Validation loss: 2.3281029766742662

Epoch: 5| Step: 2
Training loss: 2.917380563469877
Validation loss: 2.3414290948941763

Epoch: 5| Step: 3
Training loss: 2.5402808450140726
Validation loss: 2.353543105229017

Epoch: 5| Step: 4
Training loss: 2.292476256735348
Validation loss: 2.3398799493186857

Epoch: 5| Step: 5
Training loss: 2.846273120355666
Validation loss: 2.3585375520832366

Epoch: 5| Step: 6
Training loss: 2.306201708941926
Validation loss: 2.3566841003923726

Epoch: 5| Step: 7
Training loss: 2.4287428414734533
Validation loss: 2.347901484012545

Epoch: 5| Step: 8
Training loss: 2.0201399750887106
Validation loss: 2.3470218979343644

Epoch: 5| Step: 9
Training loss: 2.488899764915197
Validation loss: 2.3502678823853858

Epoch: 5| Step: 10
Training loss: 2.004616773135207
Validation loss: 2.370406100619896

Epoch: 157| Step: 0
Training loss: 2.457259078144595
Validation loss: 2.3559220441655633

Epoch: 5| Step: 1
Training loss: 2.244673782640233
Validation loss: 2.3456359035606766

Epoch: 5| Step: 2
Training loss: 2.3586632874060114
Validation loss: 2.351912908747772

Epoch: 5| Step: 3
Training loss: 2.724505766399216
Validation loss: 2.3405034704049035

Epoch: 5| Step: 4
Training loss: 2.38133789460976
Validation loss: 2.3391906326925094

Epoch: 5| Step: 5
Training loss: 2.235236795328174
Validation loss: 2.3608539750929842

Epoch: 5| Step: 6
Training loss: 2.2547235709389426
Validation loss: 2.3445735356867745

Epoch: 5| Step: 7
Training loss: 2.4225705040276666
Validation loss: 2.3524438658139473

Epoch: 5| Step: 8
Training loss: 2.572176179366214
Validation loss: 2.3524693283298226

Epoch: 5| Step: 9
Training loss: 2.365739335354645
Validation loss: 2.3271587167230843

Epoch: 5| Step: 10
Training loss: 2.4798564004854815
Validation loss: 2.3404933637062744

Epoch: 158| Step: 0
Training loss: 2.5684546159266093
Validation loss: 2.3525529336768765

Epoch: 5| Step: 1
Training loss: 1.9358316437211247
Validation loss: 2.3511939086441

Epoch: 5| Step: 2
Training loss: 2.1607043931502656
Validation loss: 2.3438401159100755

Epoch: 5| Step: 3
Training loss: 2.624273472107793
Validation loss: 2.348383246730746

Epoch: 5| Step: 4
Training loss: 2.102289577482211
Validation loss: 2.362018395526045

Epoch: 5| Step: 5
Training loss: 2.0013316013109277
Validation loss: 2.344383109389607

Epoch: 5| Step: 6
Training loss: 2.2586777029199463
Validation loss: 2.3395476789320595

Epoch: 5| Step: 7
Training loss: 2.8770427910012812
Validation loss: 2.3684168375333723

Epoch: 5| Step: 8
Training loss: 2.5166628574401457
Validation loss: 2.345815736758582

Epoch: 5| Step: 9
Training loss: 2.4413890624394994
Validation loss: 2.340943950048366

Epoch: 5| Step: 10
Training loss: 2.8113534073662136
Validation loss: 2.358840203748525

Epoch: 159| Step: 0
Training loss: 2.763608207912848
Validation loss: 2.344742927921765

Epoch: 5| Step: 1
Training loss: 2.657889006341638
Validation loss: 2.343303808036982

Epoch: 5| Step: 2
Training loss: 2.1761721905290563
Validation loss: 2.344329543567948

Epoch: 5| Step: 3
Training loss: 2.6310400727314756
Validation loss: 2.3455668789764923

Epoch: 5| Step: 4
Training loss: 2.180025354815384
Validation loss: 2.3299688407417882

Epoch: 5| Step: 5
Training loss: 2.4816182514264735
Validation loss: 2.333103622022523

Epoch: 5| Step: 6
Training loss: 2.335072334851852
Validation loss: 2.3484514560538177

Epoch: 5| Step: 7
Training loss: 2.124830688014523
Validation loss: 2.3347051513173627

Epoch: 5| Step: 8
Training loss: 1.9721697216776997
Validation loss: 2.3471871530957826

Epoch: 5| Step: 9
Training loss: 2.557543356967016
Validation loss: 2.348920752311989

Epoch: 5| Step: 10
Training loss: 2.357411559176373
Validation loss: 2.337045971001419

Epoch: 160| Step: 0
Training loss: 2.576716460190574
Validation loss: 2.3330475720834034

Epoch: 5| Step: 1
Training loss: 1.7477917362468696
Validation loss: 2.3557520551997624

Epoch: 5| Step: 2
Training loss: 2.4564495520059624
Validation loss: 2.3357723313640677

Epoch: 5| Step: 3
Training loss: 2.244921887744421
Validation loss: 2.326124277638124

Epoch: 5| Step: 4
Training loss: 2.574400552399163
Validation loss: 2.339943028767827

Epoch: 5| Step: 5
Training loss: 2.2230964318628486
Validation loss: 2.3401296002975314

Epoch: 5| Step: 6
Training loss: 2.673207625511763
Validation loss: 2.3424744135311943

Epoch: 5| Step: 7
Training loss: 2.267453632995216
Validation loss: 2.345994579232027

Epoch: 5| Step: 8
Training loss: 2.7959439736621015
Validation loss: 2.34359035043909

Epoch: 5| Step: 9
Training loss: 2.603391079166552
Validation loss: 2.3497714489852277

Epoch: 5| Step: 10
Training loss: 1.876399026908126
Validation loss: 2.341729863836187

Epoch: 161| Step: 0
Training loss: 2.3432049944133153
Validation loss: 2.339182881285209

Epoch: 5| Step: 1
Training loss: 2.884252173225303
Validation loss: 2.345485268561894

Epoch: 5| Step: 2
Training loss: 2.9191872377475754
Validation loss: 2.350279919184332

Epoch: 5| Step: 3
Training loss: 1.5614981682064613
Validation loss: 2.353237199115101

Epoch: 5| Step: 4
Training loss: 2.369321157396609
Validation loss: 2.3595542315364613

Epoch: 5| Step: 5
Training loss: 2.0773863662876115
Validation loss: 2.3324264796351106

Epoch: 5| Step: 6
Training loss: 2.461682791100727
Validation loss: 2.340079670150962

Epoch: 5| Step: 7
Training loss: 2.355810441116317
Validation loss: 2.3377797073755455

Epoch: 5| Step: 8
Training loss: 2.6277013230800508
Validation loss: 2.3670596381937137

Epoch: 5| Step: 9
Training loss: 2.2943987310975316
Validation loss: 2.320625782046115

Epoch: 5| Step: 10
Training loss: 2.2988244950388186
Validation loss: 2.3554571805122357

Epoch: 162| Step: 0
Training loss: 2.4527210461843207
Validation loss: 2.3546089327193798

Epoch: 5| Step: 1
Training loss: 3.005950589249152
Validation loss: 2.322259373382483

Epoch: 5| Step: 2
Training loss: 2.429199758558357
Validation loss: 2.348021800209846

Epoch: 5| Step: 3
Training loss: 2.573914389786441
Validation loss: 2.351657073918532

Epoch: 5| Step: 4
Training loss: 2.6088587084549353
Validation loss: 2.3598272092212715

Epoch: 5| Step: 5
Training loss: 2.6885664842049626
Validation loss: 2.3373555064885267

Epoch: 5| Step: 6
Training loss: 1.93986446939527
Validation loss: 2.3340324392444245

Epoch: 5| Step: 7
Training loss: 2.7214599783493645
Validation loss: 2.349389784600815

Epoch: 5| Step: 8
Training loss: 1.766374749531673
Validation loss: 2.364127267238875

Epoch: 5| Step: 9
Training loss: 2.1767167386560566
Validation loss: 2.3575268978681505

Epoch: 5| Step: 10
Training loss: 1.8405155324200189
Validation loss: 2.36775905916667

Epoch: 163| Step: 0
Training loss: 2.2266258899967695
Validation loss: 2.359070530406227

Epoch: 5| Step: 1
Training loss: 2.177865418738038
Validation loss: 2.3439574655023505

Epoch: 5| Step: 2
Training loss: 2.0862160257415314
Validation loss: 2.3350387448220196

Epoch: 5| Step: 3
Training loss: 2.459554325919071
Validation loss: 2.361882943037173

Epoch: 5| Step: 4
Training loss: 2.3807121650680143
Validation loss: 2.326047075330887

Epoch: 5| Step: 5
Training loss: 2.3805727578838276
Validation loss: 2.315462011939098

Epoch: 5| Step: 6
Training loss: 2.5567632518994454
Validation loss: 2.3484180180897702

Epoch: 5| Step: 7
Training loss: 2.7825148203164636
Validation loss: 2.354467828079615

Epoch: 5| Step: 8
Training loss: 2.7319071941446755
Validation loss: 2.3413716538709872

Epoch: 5| Step: 9
Training loss: 2.1549706464569454
Validation loss: 2.341157748762486

Epoch: 5| Step: 10
Training loss: 2.2694007717844977
Validation loss: 2.339165096049722

Epoch: 164| Step: 0
Training loss: 2.6858676122390794
Validation loss: 2.355474635941486

Epoch: 5| Step: 1
Training loss: 2.2272545525370187
Validation loss: 2.3345220507261994

Epoch: 5| Step: 2
Training loss: 2.3484314005373426
Validation loss: 2.3505833237822453

Epoch: 5| Step: 3
Training loss: 2.128985426244133
Validation loss: 2.360465403201219

Epoch: 5| Step: 4
Training loss: 2.4860252801249647
Validation loss: 2.340160469985761

Epoch: 5| Step: 5
Training loss: 2.370564183230221
Validation loss: 2.3396170454606384

Epoch: 5| Step: 6
Training loss: 2.5654409326278573
Validation loss: 2.3450220616993858

Epoch: 5| Step: 7
Training loss: 2.550495312774485
Validation loss: 2.3481686653124854

Epoch: 5| Step: 8
Training loss: 2.1031562972892996
Validation loss: 2.3320824797889017

Epoch: 5| Step: 9
Training loss: 2.1282014852662914
Validation loss: 2.34688086637802

Epoch: 5| Step: 10
Training loss: 2.583302425896941
Validation loss: 2.342155619753219

Epoch: 165| Step: 0
Training loss: 2.8726272743388397
Validation loss: 2.3453704919727367

Epoch: 5| Step: 1
Training loss: 2.611494197429278
Validation loss: 2.3421039956866476

Epoch: 5| Step: 2
Training loss: 2.5971332224274946
Validation loss: 2.3410081167358645

Epoch: 5| Step: 3
Training loss: 2.0260038266084615
Validation loss: 2.358404051983079

Epoch: 5| Step: 4
Training loss: 2.3964227918750507
Validation loss: 2.34135997256943

Epoch: 5| Step: 5
Training loss: 2.3790543734031986
Validation loss: 2.3467413317092825

Epoch: 5| Step: 6
Training loss: 1.9190007247883678
Validation loss: 2.365633800365217

Epoch: 5| Step: 7
Training loss: 2.4171600715052564
Validation loss: 2.3373831251598274

Epoch: 5| Step: 8
Training loss: 1.9544163821590539
Validation loss: 2.337724850838069

Epoch: 5| Step: 9
Training loss: 2.050129407194257
Validation loss: 2.3440226428422113

Epoch: 5| Step: 10
Training loss: 2.739201237439384
Validation loss: 2.333729265024681

Epoch: 166| Step: 0
Training loss: 2.6284968381865963
Validation loss: 2.3449850064889874

Epoch: 5| Step: 1
Training loss: 2.1226898426575036
Validation loss: 2.3563562008849335

Epoch: 5| Step: 2
Training loss: 2.39676889037963
Validation loss: 2.325297293795995

Epoch: 5| Step: 3
Training loss: 2.622531456772302
Validation loss: 2.346549362806527

Epoch: 5| Step: 4
Training loss: 2.633945481659407
Validation loss: 2.345104313537542

Epoch: 5| Step: 5
Training loss: 2.3240376890806513
Validation loss: 2.3150833902068424

Epoch: 5| Step: 6
Training loss: 2.722779718606911
Validation loss: 2.36782868084526

Epoch: 5| Step: 7
Training loss: 2.2159449078704094
Validation loss: 2.3561151100277677

Epoch: 5| Step: 8
Training loss: 2.12250147519549
Validation loss: 2.355005597401244

Epoch: 5| Step: 9
Training loss: 2.3413858315433833
Validation loss: 2.3286823520345563

Epoch: 5| Step: 10
Training loss: 1.841125171622779
Validation loss: 2.344908992006168

Epoch: 167| Step: 0
Training loss: 2.7772469161652893
Validation loss: 2.330154737717549

Epoch: 5| Step: 1
Training loss: 2.6594783238422104
Validation loss: 2.346523908158914

Epoch: 5| Step: 2
Training loss: 2.326345493297806
Validation loss: 2.3382346759814125

Epoch: 5| Step: 3
Training loss: 2.0019097746830847
Validation loss: 2.340149475544061

Epoch: 5| Step: 4
Training loss: 1.757070562822688
Validation loss: 2.337901025861819

Epoch: 5| Step: 5
Training loss: 2.1841992134231845
Validation loss: 2.337363088740742

Epoch: 5| Step: 6
Training loss: 2.430737333009509
Validation loss: 2.356705401925335

Epoch: 5| Step: 7
Training loss: 1.9902190412804794
Validation loss: 2.332414773318386

Epoch: 5| Step: 8
Training loss: 2.6655844538870728
Validation loss: 2.342052582289745

Epoch: 5| Step: 9
Training loss: 2.662136063753323
Validation loss: 2.3396272918174663

Epoch: 5| Step: 10
Training loss: 2.616681041394575
Validation loss: 2.349192776494752

Epoch: 168| Step: 0
Training loss: 2.8144892968865274
Validation loss: 2.349710986226319

Epoch: 5| Step: 1
Training loss: 2.5651267010365406
Validation loss: 2.3419765875661147

Epoch: 5| Step: 2
Training loss: 2.9193744261048327
Validation loss: 2.3347297894028314

Epoch: 5| Step: 3
Training loss: 2.204530740919412
Validation loss: 2.3328096385123636

Epoch: 5| Step: 4
Training loss: 2.304965244949699
Validation loss: 2.3384037846413928

Epoch: 5| Step: 5
Training loss: 1.4886578261173715
Validation loss: 2.340520806243361

Epoch: 5| Step: 6
Training loss: 2.188009802132082
Validation loss: 2.3531088216928415

Epoch: 5| Step: 7
Training loss: 2.368781229985886
Validation loss: 2.322171463679612

Epoch: 5| Step: 8
Training loss: 1.652067625813738
Validation loss: 2.336786867838291

Epoch: 5| Step: 9
Training loss: 2.687084964375694
Validation loss: 2.352638283912329

Epoch: 5| Step: 10
Training loss: 2.4351342286823616
Validation loss: 2.3337365360955746

Epoch: 169| Step: 0
Training loss: 2.183998466204709
Validation loss: 2.347069088979585

Epoch: 5| Step: 1
Training loss: 2.3133813364213514
Validation loss: 2.336334590954113

Epoch: 5| Step: 2
Training loss: 1.6481636145259342
Validation loss: 2.3528505988605226

Epoch: 5| Step: 3
Training loss: 2.360787076468855
Validation loss: 2.3338477796120007

Epoch: 5| Step: 4
Training loss: 1.9042422868778512
Validation loss: 2.3383084093673996

Epoch: 5| Step: 5
Training loss: 2.9433439845421283
Validation loss: 2.335414550138635

Epoch: 5| Step: 6
Training loss: 2.5719116245410656
Validation loss: 2.338556997027547

Epoch: 5| Step: 7
Training loss: 2.2845379897808025
Validation loss: 2.3201231741305772

Epoch: 5| Step: 8
Training loss: 2.6367006654472407
Validation loss: 2.340146687487412

Epoch: 5| Step: 9
Training loss: 2.5700149131965624
Validation loss: 2.3441271800416446

Epoch: 5| Step: 10
Training loss: 2.3302040801494757
Validation loss: 2.3468141713423427

Epoch: 170| Step: 0
Training loss: 2.266623651806948
Validation loss: 2.3565833740157553

Epoch: 5| Step: 1
Training loss: 2.5227814285064105
Validation loss: 2.3477866311800613

Epoch: 5| Step: 2
Training loss: 2.86037940223094
Validation loss: 2.358640716648905

Epoch: 5| Step: 3
Training loss: 1.66248271617653
Validation loss: 2.34701442553135

Epoch: 5| Step: 4
Training loss: 2.619302106028253
Validation loss: 2.3578394572247476

Epoch: 5| Step: 5
Training loss: 2.1905655225659846
Validation loss: 2.3268022222591576

Epoch: 5| Step: 6
Training loss: 2.463197572534845
Validation loss: 2.3388907273014565

Epoch: 5| Step: 7
Training loss: 2.2970001809398695
Validation loss: 2.334034407529871

Epoch: 5| Step: 8
Training loss: 2.419778125301925
Validation loss: 2.3294645745835485

Epoch: 5| Step: 9
Training loss: 2.2064788397097015
Validation loss: 2.3157375136591405

Epoch: 5| Step: 10
Training loss: 2.4037052917290183
Validation loss: 2.3377801942718603

Epoch: 171| Step: 0
Training loss: 2.3749022212731012
Validation loss: 2.3234155800526577

Epoch: 5| Step: 1
Training loss: 2.3958543417189198
Validation loss: 2.3199617262905616

Epoch: 5| Step: 2
Training loss: 2.498654575710837
Validation loss: 2.342835154945079

Epoch: 5| Step: 3
Training loss: 2.195514710368579
Validation loss: 2.330462495570624

Epoch: 5| Step: 4
Training loss: 2.4363457318713038
Validation loss: 2.333991624406679

Epoch: 5| Step: 5
Training loss: 2.3650163318481434
Validation loss: 2.3331494463991675

Epoch: 5| Step: 6
Training loss: 2.4506118438608837
Validation loss: 2.3488668533962564

Epoch: 5| Step: 7
Training loss: 2.3409445693449484
Validation loss: 2.3329387626366898

Epoch: 5| Step: 8
Training loss: 2.2360669112592357
Validation loss: 2.323126886906719

Epoch: 5| Step: 9
Training loss: 1.988105871113933
Validation loss: 2.3594426014541137

Epoch: 5| Step: 10
Training loss: 2.540421530070464
Validation loss: 2.332520045072864

Epoch: 172| Step: 0
Training loss: 2.4149715353984336
Validation loss: 2.3381197271220073

Epoch: 5| Step: 1
Training loss: 2.2441156583481194
Validation loss: 2.336971658612664

Epoch: 5| Step: 2
Training loss: 2.5312856977794818
Validation loss: 2.3248857602199275

Epoch: 5| Step: 3
Training loss: 2.168634425884714
Validation loss: 2.331769928905021

Epoch: 5| Step: 4
Training loss: 1.6523221783323345
Validation loss: 2.338902275703756

Epoch: 5| Step: 5
Training loss: 2.4650356502160244
Validation loss: 2.3508682455333663

Epoch: 5| Step: 6
Training loss: 2.4367705989995114
Validation loss: 2.3347499538319405

Epoch: 5| Step: 7
Training loss: 2.367642399856839
Validation loss: 2.3390415502500232

Epoch: 5| Step: 8
Training loss: 2.588579102110519
Validation loss: 2.3297594792210203

Epoch: 5| Step: 9
Training loss: 2.4930822984352603
Validation loss: 2.324291858676265

Epoch: 5| Step: 10
Training loss: 2.345856292323163
Validation loss: 2.357765619713304

Epoch: 173| Step: 0
Training loss: 2.3198295116263816
Validation loss: 2.3372548410671325

Epoch: 5| Step: 1
Training loss: 2.2142971649401226
Validation loss: 2.3362988935866955

Epoch: 5| Step: 2
Training loss: 2.4639070547706017
Validation loss: 2.2984563927889567

Epoch: 5| Step: 3
Training loss: 2.357253883273658
Validation loss: 2.34289792559058

Epoch: 5| Step: 4
Training loss: 1.9221035581073642
Validation loss: 2.325619552106826

Epoch: 5| Step: 5
Training loss: 2.164630360929271
Validation loss: 2.3201901010753345

Epoch: 5| Step: 6
Training loss: 2.7988540211642174
Validation loss: 2.33067570428698

Epoch: 5| Step: 7
Training loss: 2.272516017979067
Validation loss: 2.335217908752785

Epoch: 5| Step: 8
Training loss: 2.5782196952306062
Validation loss: 2.3255296385064557

Epoch: 5| Step: 9
Training loss: 2.507800045754949
Validation loss: 2.3510836698810484

Epoch: 5| Step: 10
Training loss: 2.0955020918329383
Validation loss: 2.3383254051633964

Epoch: 174| Step: 0
Training loss: 2.3228273474337966
Validation loss: 2.32036268701268

Epoch: 5| Step: 1
Training loss: 2.3652233876383426
Validation loss: 2.3406203777589

Epoch: 5| Step: 2
Training loss: 1.7244264671993375
Validation loss: 2.3546638853020716

Epoch: 5| Step: 3
Training loss: 2.1301374602400247
Validation loss: 2.3291795919730633

Epoch: 5| Step: 4
Training loss: 2.5308132030233703
Validation loss: 2.3371469492634325

Epoch: 5| Step: 5
Training loss: 2.512385586842732
Validation loss: 2.3272885344127174

Epoch: 5| Step: 6
Training loss: 2.5948452762643606
Validation loss: 2.3144941703009416

Epoch: 5| Step: 7
Training loss: 2.6416851375989037
Validation loss: 2.333302975235908

Epoch: 5| Step: 8
Training loss: 2.275666602429406
Validation loss: 2.33919123245216

Epoch: 5| Step: 9
Training loss: 2.254734885285537
Validation loss: 2.3183848021671416

Epoch: 5| Step: 10
Training loss: 2.277887557519231
Validation loss: 2.3438146176198247

Epoch: 175| Step: 0
Training loss: 2.1968231976453287
Validation loss: 2.3259518155582586

Epoch: 5| Step: 1
Training loss: 2.633361396961928
Validation loss: 2.3129038287682144

Epoch: 5| Step: 2
Training loss: 2.116559825914114
Validation loss: 2.332843606802709

Epoch: 5| Step: 3
Training loss: 2.1390267970335795
Validation loss: 2.323941509104865

Epoch: 5| Step: 4
Training loss: 2.594552433027375
Validation loss: 2.32483805547713

Epoch: 5| Step: 5
Training loss: 2.217377143905707
Validation loss: 2.3342942945003284

Epoch: 5| Step: 6
Training loss: 2.3504032560075365
Validation loss: 2.326262998064842

Epoch: 5| Step: 7
Training loss: 2.041876827504228
Validation loss: 2.3202072248942094

Epoch: 5| Step: 8
Training loss: 2.4206319264481007
Validation loss: 2.347155872849003

Epoch: 5| Step: 9
Training loss: 2.382880138000062
Validation loss: 2.33592698723204

Epoch: 5| Step: 10
Training loss: 2.423307721065181
Validation loss: 2.346682738177031

Epoch: 176| Step: 0
Training loss: 2.0688441413595644
Validation loss: 2.323006982223425

Epoch: 5| Step: 1
Training loss: 2.422142949202138
Validation loss: 2.350760015575258

Epoch: 5| Step: 2
Training loss: 2.2926405715692275
Validation loss: 2.3180817463066363

Epoch: 5| Step: 3
Training loss: 2.5392835315451996
Validation loss: 2.3258783688714217

Epoch: 5| Step: 4
Training loss: 2.806978527904288
Validation loss: 2.3368894189207547

Epoch: 5| Step: 5
Training loss: 2.1251629037684876
Validation loss: 2.3328023535629074

Epoch: 5| Step: 6
Training loss: 2.322575143475152
Validation loss: 2.313920571660007

Epoch: 5| Step: 7
Training loss: 2.1154505512658703
Validation loss: 2.3238727414400313

Epoch: 5| Step: 8
Training loss: 1.978753726109884
Validation loss: 2.3355918016905957

Epoch: 5| Step: 9
Training loss: 2.465483133661016
Validation loss: 2.3280064349675995

Epoch: 5| Step: 10
Training loss: 2.408262228878577
Validation loss: 2.3240188878073584

Epoch: 177| Step: 0
Training loss: 2.660679881896626
Validation loss: 2.3256813466756454

Epoch: 5| Step: 1
Training loss: 2.767959643808449
Validation loss: 2.3360441746466085

Epoch: 5| Step: 2
Training loss: 2.085953273070632
Validation loss: 2.335665817723561

Epoch: 5| Step: 3
Training loss: 1.999399750756968
Validation loss: 2.3378870732349015

Epoch: 5| Step: 4
Training loss: 2.483913738687935
Validation loss: 2.3362331529095015

Epoch: 5| Step: 5
Training loss: 2.426121686306682
Validation loss: 2.3272726598227584

Epoch: 5| Step: 6
Training loss: 2.3971822728197147
Validation loss: 2.362264472926284

Epoch: 5| Step: 7
Training loss: 2.438206496921633
Validation loss: 2.3029396010000753

Epoch: 5| Step: 8
Training loss: 1.857866460659789
Validation loss: 2.3148028872557496

Epoch: 5| Step: 9
Training loss: 2.0775381995039104
Validation loss: 2.3306022172705614

Epoch: 5| Step: 10
Training loss: 2.1507831876935173
Validation loss: 2.3321336699780524

Epoch: 178| Step: 0
Training loss: 2.7877094823017057
Validation loss: 2.334146910077989

Epoch: 5| Step: 1
Training loss: 1.635296770629232
Validation loss: 2.3305985608987903

Epoch: 5| Step: 2
Training loss: 1.9116482826530707
Validation loss: 2.3088577974849502

Epoch: 5| Step: 3
Training loss: 2.672756651927437
Validation loss: 2.356150093157256

Epoch: 5| Step: 4
Training loss: 2.1003493881221424
Validation loss: 2.338660398423077

Epoch: 5| Step: 5
Training loss: 2.5695566845914044
Validation loss: 2.3209732875364217

Epoch: 5| Step: 6
Training loss: 2.702017231889805
Validation loss: 2.311148130003974

Epoch: 5| Step: 7
Training loss: 1.7634353563592116
Validation loss: 2.3280523112224736

Epoch: 5| Step: 8
Training loss: 2.097006698997905
Validation loss: 2.326761357719157

Epoch: 5| Step: 9
Training loss: 2.490599888922679
Validation loss: 2.3414973671999406

Epoch: 5| Step: 10
Training loss: 2.493772953090345
Validation loss: 2.308312251307663

Epoch: 179| Step: 0
Training loss: 1.4745552912008664
Validation loss: 2.3206405156437855

Epoch: 5| Step: 1
Training loss: 2.0917605157393853
Validation loss: 2.309523655078615

Epoch: 5| Step: 2
Training loss: 2.339082266011174
Validation loss: 2.336099597402984

Epoch: 5| Step: 3
Training loss: 2.4472264608672902
Validation loss: 2.310534094191061

Epoch: 5| Step: 4
Training loss: 2.4336470449621745
Validation loss: 2.3389469320584744

Epoch: 5| Step: 5
Training loss: 2.3398349870062325
Validation loss: 2.325927970108297

Epoch: 5| Step: 6
Training loss: 2.2822771242259643
Validation loss: 2.303563224497966

Epoch: 5| Step: 7
Training loss: 2.3433202731047564
Validation loss: 2.3221795492459107

Epoch: 5| Step: 8
Training loss: 2.276407091731164
Validation loss: 2.3305521253582677

Epoch: 5| Step: 9
Training loss: 2.560992472013814
Validation loss: 2.318408513997374

Epoch: 5| Step: 10
Training loss: 2.5640112909553427
Validation loss: 2.3378732488233553

Epoch: 180| Step: 0
Training loss: 2.424760145929759
Validation loss: 2.309670358649508

Epoch: 5| Step: 1
Training loss: 2.121815820242303
Validation loss: 2.325860190910293

Epoch: 5| Step: 2
Training loss: 2.085095639310879
Validation loss: 2.32360158371339

Epoch: 5| Step: 3
Training loss: 2.6003255566935186
Validation loss: 2.331083886399944

Epoch: 5| Step: 4
Training loss: 2.270608301707702
Validation loss: 2.3170422988772255

Epoch: 5| Step: 5
Training loss: 2.449500254830174
Validation loss: 2.3368822311611885

Epoch: 5| Step: 6
Training loss: 2.1928859345794565
Validation loss: 2.3365863592067306

Epoch: 5| Step: 7
Training loss: 1.957022661201681
Validation loss: 2.3566497599403786

Epoch: 5| Step: 8
Training loss: 2.3655563122794057
Validation loss: 2.3311873454414425

Epoch: 5| Step: 9
Training loss: 2.5457088866672755
Validation loss: 2.3461310397213313

Epoch: 5| Step: 10
Training loss: 2.2706202719124944
Validation loss: 2.3491897754569826

Epoch: 181| Step: 0
Training loss: 2.246361545686537
Validation loss: 2.317764515672261

Epoch: 5| Step: 1
Training loss: 2.7430961820488444
Validation loss: 2.3398973681135895

Epoch: 5| Step: 2
Training loss: 2.470864175364928
Validation loss: 2.310878241530393

Epoch: 5| Step: 3
Training loss: 2.4532116917156004
Validation loss: 2.3200768979924167

Epoch: 5| Step: 4
Training loss: 2.247193811795279
Validation loss: 2.332462781153653

Epoch: 5| Step: 5
Training loss: 2.111276631252256
Validation loss: 2.3400879589587933

Epoch: 5| Step: 6
Training loss: 2.2505524275037163
Validation loss: 2.352020940688186

Epoch: 5| Step: 7
Training loss: 2.3120107390936413
Validation loss: 2.3170617066506956

Epoch: 5| Step: 8
Training loss: 2.4295081167452506
Validation loss: 2.3268676344388854

Epoch: 5| Step: 9
Training loss: 2.0316939822398163
Validation loss: 2.3115724717246073

Epoch: 5| Step: 10
Training loss: 1.6717102825272312
Validation loss: 2.3297058242080837

Epoch: 182| Step: 0
Training loss: 2.020497546531738
Validation loss: 2.308428057529969

Epoch: 5| Step: 1
Training loss: 2.1091289235444077
Validation loss: 2.3224870956032198

Epoch: 5| Step: 2
Training loss: 2.4442308855209687
Validation loss: 2.3172545407850387

Epoch: 5| Step: 3
Training loss: 2.4972456063814206
Validation loss: 2.3181363289347665

Epoch: 5| Step: 4
Training loss: 2.583014550587856
Validation loss: 2.3232619539710093

Epoch: 5| Step: 5
Training loss: 2.681100989693834
Validation loss: 2.3282224743898574

Epoch: 5| Step: 6
Training loss: 2.0080141196343413
Validation loss: 2.3241850301341045

Epoch: 5| Step: 7
Training loss: 2.1982998867927344
Validation loss: 2.316199222677496

Epoch: 5| Step: 8
Training loss: 2.660729255524435
Validation loss: 2.349005106041993

Epoch: 5| Step: 9
Training loss: 2.125280025207708
Validation loss: 2.318198560741965

Epoch: 5| Step: 10
Training loss: 1.7735448460292949
Validation loss: 2.319695821771204

Epoch: 183| Step: 0
Training loss: 2.5400037693386195
Validation loss: 2.329305284239263

Epoch: 5| Step: 1
Training loss: 2.0692960727194807
Validation loss: 2.346441192577312

Epoch: 5| Step: 2
Training loss: 1.9313973947715035
Validation loss: 2.3330459776693515

Epoch: 5| Step: 3
Training loss: 2.8834543728275333
Validation loss: 2.319170312776205

Epoch: 5| Step: 4
Training loss: 2.236350086887249
Validation loss: 2.3376332928342545

Epoch: 5| Step: 5
Training loss: 1.899668855420309
Validation loss: 2.324551066997746

Epoch: 5| Step: 6
Training loss: 2.388006933429052
Validation loss: 2.3256898786020637

Epoch: 5| Step: 7
Training loss: 2.2499594154936235
Validation loss: 2.3079818337426974

Epoch: 5| Step: 8
Training loss: 2.1610277842474748
Validation loss: 2.324368915789291

Epoch: 5| Step: 9
Training loss: 2.029120517443531
Validation loss: 2.3354989701758964

Epoch: 5| Step: 10
Training loss: 2.951338454669547
Validation loss: 2.3220550290655617

Epoch: 184| Step: 0
Training loss: 2.3080029449708555
Validation loss: 2.3132281754713646

Epoch: 5| Step: 1
Training loss: 2.4981456555125057
Validation loss: 2.324440419977076

Epoch: 5| Step: 2
Training loss: 2.4027793923472407
Validation loss: 2.3519092582558176

Epoch: 5| Step: 3
Training loss: 1.9246618642708553
Validation loss: 2.3070830867514833

Epoch: 5| Step: 4
Training loss: 2.0817063527209454
Validation loss: 2.3068870864346036

Epoch: 5| Step: 5
Training loss: 2.494936870471953
Validation loss: 2.3116802391121483

Epoch: 5| Step: 6
Training loss: 2.2146839979038293
Validation loss: 2.3369041251264164

Epoch: 5| Step: 7
Training loss: 2.166844751913261
Validation loss: 2.3292832709724793

Epoch: 5| Step: 8
Training loss: 2.3724161447994794
Validation loss: 2.334377603026588

Epoch: 5| Step: 9
Training loss: 2.3697397303217356
Validation loss: 2.3249402465137017

Epoch: 5| Step: 10
Training loss: 2.323765301748932
Validation loss: 2.3304518623993276

Epoch: 185| Step: 0
Training loss: 2.1719780767117682
Validation loss: 2.311213011333436

Epoch: 5| Step: 1
Training loss: 2.1293771205541088
Validation loss: 2.2955479569606454

Epoch: 5| Step: 2
Training loss: 2.387315940752388
Validation loss: 2.3198140711356108

Epoch: 5| Step: 3
Training loss: 2.403526151631883
Validation loss: 2.316197551362387

Epoch: 5| Step: 4
Training loss: 1.899831315131741
Validation loss: 2.320513865734912

Epoch: 5| Step: 5
Training loss: 2.0434894080656414
Validation loss: 2.327319881204993

Epoch: 5| Step: 6
Training loss: 2.6621915002750955
Validation loss: 2.3532641357178314

Epoch: 5| Step: 7
Training loss: 1.8191492514214285
Validation loss: 2.3269844705376617

Epoch: 5| Step: 8
Training loss: 2.2162592702328547
Validation loss: 2.3269060512555835

Epoch: 5| Step: 9
Training loss: 2.4182678925037546
Validation loss: 2.3026829988424

Epoch: 5| Step: 10
Training loss: 2.668479144536119
Validation loss: 2.3281214707760687

Epoch: 186| Step: 0
Training loss: 2.0240364513808924
Validation loss: 2.346659932563275

Epoch: 5| Step: 1
Training loss: 2.183056377967263
Validation loss: 2.3391337951096784

Epoch: 5| Step: 2
Training loss: 2.526675954145743
Validation loss: 2.327463187409283

Epoch: 5| Step: 3
Training loss: 2.1442765326088704
Validation loss: 2.340522799741542

Epoch: 5| Step: 4
Training loss: 2.218245972886692
Validation loss: 2.3280039594301067

Epoch: 5| Step: 5
Training loss: 2.0319908551663652
Validation loss: 2.3376499612463704

Epoch: 5| Step: 6
Training loss: 2.3250248897409764
Validation loss: 2.3341967013427563

Epoch: 5| Step: 7
Training loss: 2.9643234178308697
Validation loss: 2.3272889485980572

Epoch: 5| Step: 8
Training loss: 2.3120019737288025
Validation loss: 2.3395237468710226

Epoch: 5| Step: 9
Training loss: 2.419223441380761
Validation loss: 2.342436289799336

Epoch: 5| Step: 10
Training loss: 1.6282467318841323
Validation loss: 2.3375034727735717

Epoch: 187| Step: 0
Training loss: 1.8415534949879528
Validation loss: 2.302243881147097

Epoch: 5| Step: 1
Training loss: 2.7959765477649943
Validation loss: 2.3167627285759074

Epoch: 5| Step: 2
Training loss: 2.4651136054116147
Validation loss: 2.3284938179033454

Epoch: 5| Step: 3
Training loss: 2.193280783355157
Validation loss: 2.320933280240944

Epoch: 5| Step: 4
Training loss: 2.273545200379294
Validation loss: 2.3095167706620447

Epoch: 5| Step: 5
Training loss: 2.357089723260652
Validation loss: 2.306833008338741

Epoch: 5| Step: 6
Training loss: 2.081726968083763
Validation loss: 2.3095863870193454

Epoch: 5| Step: 7
Training loss: 1.9604835136710788
Validation loss: 2.2937772005939587

Epoch: 5| Step: 8
Training loss: 2.4729019211734142
Validation loss: 2.3166848131579987

Epoch: 5| Step: 9
Training loss: 2.296771403980186
Validation loss: 2.3134788020365056

Epoch: 5| Step: 10
Training loss: 2.1937762006189465
Validation loss: 2.320684604301709

Epoch: 188| Step: 0
Training loss: 1.6277536389698803
Validation loss: 2.3098729007343426

Epoch: 5| Step: 1
Training loss: 2.3406039676306998
Validation loss: 2.307423402414415

Epoch: 5| Step: 2
Training loss: 2.6459216205755234
Validation loss: 2.307616277634141

Epoch: 5| Step: 3
Training loss: 2.203654124251039
Validation loss: 2.3031834965580296

Epoch: 5| Step: 4
Training loss: 2.5131560346901876
Validation loss: 2.3284776938978573

Epoch: 5| Step: 5
Training loss: 2.436414623697472
Validation loss: 2.329510711555634

Epoch: 5| Step: 6
Training loss: 2.0875509929710447
Validation loss: 2.315082810501573

Epoch: 5| Step: 7
Training loss: 2.2411822148894798
Validation loss: 2.3153567441036413

Epoch: 5| Step: 8
Training loss: 2.264386594965343
Validation loss: 2.294091946189353

Epoch: 5| Step: 9
Training loss: 2.3261407166259143
Validation loss: 2.3219447086030076

Epoch: 5| Step: 10
Training loss: 2.4249523669411723
Validation loss: 2.317876905390202

Epoch: 189| Step: 0
Training loss: 2.1116502711927394
Validation loss: 2.329016080617829

Epoch: 5| Step: 1
Training loss: 1.988249712920627
Validation loss: 2.3461419842782547

Epoch: 5| Step: 2
Training loss: 2.485059727770328
Validation loss: 2.314344644312569

Epoch: 5| Step: 3
Training loss: 2.4238601916064777
Validation loss: 2.3162210310154685

Epoch: 5| Step: 4
Training loss: 1.952728597468761
Validation loss: 2.3094070362633863

Epoch: 5| Step: 5
Training loss: 2.6163205660996414
Validation loss: 2.3272066476418316

Epoch: 5| Step: 6
Training loss: 2.614062638633346
Validation loss: 2.3168225783992584

Epoch: 5| Step: 7
Training loss: 2.3718628492282847
Validation loss: 2.3326109377321855

Epoch: 5| Step: 8
Training loss: 2.167387903432169
Validation loss: 2.333127432043196

Epoch: 5| Step: 9
Training loss: 2.034088733414261
Validation loss: 2.3028358503146706

Epoch: 5| Step: 10
Training loss: 1.8329207288392528
Validation loss: 2.339546090043653

Epoch: 190| Step: 0
Training loss: 2.2373737406137555
Validation loss: 2.3234751106559854

Epoch: 5| Step: 1
Training loss: 2.385710408033837
Validation loss: 2.2849777316022624

Epoch: 5| Step: 2
Training loss: 2.2224988831387473
Validation loss: 2.319496009747487

Epoch: 5| Step: 3
Training loss: 3.0314692781714068
Validation loss: 2.325503844642014

Epoch: 5| Step: 4
Training loss: 1.3446549318249468
Validation loss: 2.322019495280123

Epoch: 5| Step: 5
Training loss: 2.179983030130674
Validation loss: 2.3317531085150422

Epoch: 5| Step: 6
Training loss: 1.8678998665611128
Validation loss: 2.3314330070776936

Epoch: 5| Step: 7
Training loss: 2.2133894086344976
Validation loss: 2.3331592651634776

Epoch: 5| Step: 8
Training loss: 2.2773758900698917
Validation loss: 2.327199593563628

Epoch: 5| Step: 9
Training loss: 2.452249261324539
Validation loss: 2.3178051406499365

Epoch: 5| Step: 10
Training loss: 2.4245551261653038
Validation loss: 2.3347097483308006

Epoch: 191| Step: 0
Training loss: 1.8277660571762528
Validation loss: 2.3385467114492227

Epoch: 5| Step: 1
Training loss: 2.572767111772785
Validation loss: 2.321751072598259

Epoch: 5| Step: 2
Training loss: 2.438307212781812
Validation loss: 2.3344293622651646

Epoch: 5| Step: 3
Training loss: 2.3684624489852943
Validation loss: 2.3200517761158737

Epoch: 5| Step: 4
Training loss: 2.8031435996706904
Validation loss: 2.3048104502462365

Epoch: 5| Step: 5
Training loss: 1.819600174656103
Validation loss: 2.3468376729425726

Epoch: 5| Step: 6
Training loss: 1.9803404757097949
Validation loss: 2.2953950189039234

Epoch: 5| Step: 7
Training loss: 2.294914083264698
Validation loss: 2.3187100572116845

Epoch: 5| Step: 8
Training loss: 2.22405779316136
Validation loss: 2.342396912847186

Epoch: 5| Step: 9
Training loss: 2.2540500006625988
Validation loss: 2.3193977182101317

Epoch: 5| Step: 10
Training loss: 2.3081308278336383
Validation loss: 2.3071330504003926

Epoch: 192| Step: 0
Training loss: 2.304617360227721
Validation loss: 2.315877494980608

Epoch: 5| Step: 1
Training loss: 2.1112665807909705
Validation loss: 2.305416869833691

Epoch: 5| Step: 2
Training loss: 2.0011942397384503
Validation loss: 2.3054598296155837

Epoch: 5| Step: 3
Training loss: 2.3928988743866237
Validation loss: 2.311520227850022

Epoch: 5| Step: 4
Training loss: 2.2841133019959803
Validation loss: 2.3260916351684857

Epoch: 5| Step: 5
Training loss: 2.0584819842984774
Validation loss: 2.3004032571543167

Epoch: 5| Step: 6
Training loss: 2.5095834153823633
Validation loss: 2.337402443009536

Epoch: 5| Step: 7
Training loss: 2.21057546502402
Validation loss: 2.3676985522668565

Epoch: 5| Step: 8
Training loss: 2.2685811718212974
Validation loss: 2.340192908546151

Epoch: 5| Step: 9
Training loss: 2.205438792193808
Validation loss: 2.3292795762099976

Epoch: 5| Step: 10
Training loss: 2.5467468416698624
Validation loss: 2.355791570213319

Epoch: 193| Step: 0
Training loss: 1.8431500250720492
Validation loss: 2.3377490486043957

Epoch: 5| Step: 1
Training loss: 2.11841708017995
Validation loss: 2.3300309045044716

Epoch: 5| Step: 2
Training loss: 2.2787278747321493
Validation loss: 2.3507973232755877

Epoch: 5| Step: 3
Training loss: 2.165818916655414
Validation loss: 2.2965886022090434

Epoch: 5| Step: 4
Training loss: 1.946962629522885
Validation loss: 2.3099839309007755

Epoch: 5| Step: 5
Training loss: 2.2464484689330795
Validation loss: 2.3134525236373893

Epoch: 5| Step: 6
Training loss: 2.7673242381176246
Validation loss: 2.3166801333469444

Epoch: 5| Step: 7
Training loss: 2.624606148373891
Validation loss: 2.2937674401336587

Epoch: 5| Step: 8
Training loss: 1.7990364674746622
Validation loss: 2.304148667995883

Epoch: 5| Step: 9
Training loss: 2.5341540972937233
Validation loss: 2.3136356029868916

Epoch: 5| Step: 10
Training loss: 2.189856758310398
Validation loss: 2.311042960190745

Epoch: 194| Step: 0
Training loss: 2.3233526074537227
Validation loss: 2.301668384642813

Epoch: 5| Step: 1
Training loss: 2.2190005738514196
Validation loss: 2.3047674327550673

Epoch: 5| Step: 2
Training loss: 2.0314603256493835
Validation loss: 2.32975757609826

Epoch: 5| Step: 3
Training loss: 2.5521954155008992
Validation loss: 2.309124872328838

Epoch: 5| Step: 4
Training loss: 1.6847366029790047
Validation loss: 2.321016917014572

Epoch: 5| Step: 5
Training loss: 1.9898043870870448
Validation loss: 2.3022425610450568

Epoch: 5| Step: 6
Training loss: 2.2913808702220226
Validation loss: 2.2932128407375845

Epoch: 5| Step: 7
Training loss: 1.845489715671538
Validation loss: 2.323856703963592

Epoch: 5| Step: 8
Training loss: 2.9175554465391693
Validation loss: 2.3079527357868765

Epoch: 5| Step: 9
Training loss: 2.3319876968687394
Validation loss: 2.3264152027842435

Epoch: 5| Step: 10
Training loss: 2.276489202174253
Validation loss: 2.3169575781311447

Epoch: 195| Step: 0
Training loss: 2.4666517008078266
Validation loss: 2.306698826974599

Epoch: 5| Step: 1
Training loss: 2.045462433963553
Validation loss: 2.3285110152514954

Epoch: 5| Step: 2
Training loss: 2.2421074298026227
Validation loss: 2.3228585855698194

Epoch: 5| Step: 3
Training loss: 2.313791275356956
Validation loss: 2.2903707735129255

Epoch: 5| Step: 4
Training loss: 1.9328067295293623
Validation loss: 2.297978162843973

Epoch: 5| Step: 5
Training loss: 2.329249372930341
Validation loss: 2.3301230728669893

Epoch: 5| Step: 6
Training loss: 2.148517288113595
Validation loss: 2.315067781301112

Epoch: 5| Step: 7
Training loss: 2.26735983889591
Validation loss: 2.339479183712901

Epoch: 5| Step: 8
Training loss: 2.4345444587225313
Validation loss: 2.327376565866862

Epoch: 5| Step: 9
Training loss: 1.979946571746681
Validation loss: 2.2926699879820625

Epoch: 5| Step: 10
Training loss: 2.4327716449107464
Validation loss: 2.318385857640947

Epoch: 196| Step: 0
Training loss: 2.1077166785084738
Validation loss: 2.3280061651693793

Epoch: 5| Step: 1
Training loss: 2.136650572531199
Validation loss: 2.322420484878322

Epoch: 5| Step: 2
Training loss: 2.0811197600982942
Validation loss: 2.3268582364402803

Epoch: 5| Step: 3
Training loss: 2.2837124428586626
Validation loss: 2.3196658003925252

Epoch: 5| Step: 4
Training loss: 2.3208954460922824
Validation loss: 2.336242776556028

Epoch: 5| Step: 5
Training loss: 2.4487520348159255
Validation loss: 2.3180089084849342

Epoch: 5| Step: 6
Training loss: 2.1315339556500983
Validation loss: 2.3212404571765917

Epoch: 5| Step: 7
Training loss: 2.7747152474510344
Validation loss: 2.319344309283844

Epoch: 5| Step: 8
Training loss: 2.003400772322157
Validation loss: 2.2997753902154465

Epoch: 5| Step: 9
Training loss: 1.9841408178361892
Validation loss: 2.31741972828541

Epoch: 5| Step: 10
Training loss: 2.158922833193122
Validation loss: 2.3271911982628644

Epoch: 197| Step: 0
Training loss: 2.3237722785460417
Validation loss: 2.33571621814615

Epoch: 5| Step: 1
Training loss: 2.5827349513251234
Validation loss: 2.3494713521378023

Epoch: 5| Step: 2
Training loss: 2.2727140868411326
Validation loss: 2.314031140617926

Epoch: 5| Step: 3
Training loss: 2.1554513087851133
Validation loss: 2.3275264464154506

Epoch: 5| Step: 4
Training loss: 2.1379345323907413
Validation loss: 2.3391568445225337

Epoch: 5| Step: 5
Training loss: 1.9803670221269292
Validation loss: 2.3137106815098725

Epoch: 5| Step: 6
Training loss: 2.287697655315009
Validation loss: 2.31279898043568

Epoch: 5| Step: 7
Training loss: 2.3536252324710314
Validation loss: 2.2935967097440235

Epoch: 5| Step: 8
Training loss: 2.2221768202382215
Validation loss: 2.3426083152881754

Epoch: 5| Step: 9
Training loss: 1.9158352486013315
Validation loss: 2.3320436513574485

Epoch: 5| Step: 10
Training loss: 2.1040009033578304
Validation loss: 2.318770748994541

Epoch: 198| Step: 0
Training loss: 2.5009388114585427
Validation loss: 2.335234686621325

Epoch: 5| Step: 1
Training loss: 1.907569178655443
Validation loss: 2.3460033520010364

Epoch: 5| Step: 2
Training loss: 2.339408311782503
Validation loss: 2.287995258164822

Epoch: 5| Step: 3
Training loss: 1.9461010173599127
Validation loss: 2.3219014708526395

Epoch: 5| Step: 4
Training loss: 2.564934016488855
Validation loss: 2.3109975411078403

Epoch: 5| Step: 5
Training loss: 1.9882689589924314
Validation loss: 2.2775150312687242

Epoch: 5| Step: 6
Training loss: 1.956417025422254
Validation loss: 2.300266835614035

Epoch: 5| Step: 7
Training loss: 2.3808978283400024
Validation loss: 2.3184629064837834

Epoch: 5| Step: 8
Training loss: 2.3918673210728496
Validation loss: 2.333916014733735

Epoch: 5| Step: 9
Training loss: 2.325430315455308
Validation loss: 2.319194264737877

Epoch: 5| Step: 10
Training loss: 1.8946163197717651
Validation loss: 2.2853202666305417

Epoch: 199| Step: 0
Training loss: 2.665466654502939
Validation loss: 2.3201565928178525

Epoch: 5| Step: 1
Training loss: 2.169525961891793
Validation loss: 2.316553804754736

Epoch: 5| Step: 2
Training loss: 2.381576167318813
Validation loss: 2.29784520541202

Epoch: 5| Step: 3
Training loss: 2.260999601469549
Validation loss: 2.313901524207926

Epoch: 5| Step: 4
Training loss: 1.5145776807145215
Validation loss: 2.327452246440411

Epoch: 5| Step: 5
Training loss: 2.1999430302266183
Validation loss: 2.312041189746106

Epoch: 5| Step: 6
Training loss: 2.0011848278024833
Validation loss: 2.302913569700163

Epoch: 5| Step: 7
Training loss: 2.444993945935327
Validation loss: 2.3273911911888177

Epoch: 5| Step: 8
Training loss: 2.178672198571443
Validation loss: 2.293637625303268

Epoch: 5| Step: 9
Training loss: 2.138779450241114
Validation loss: 2.3220456281495943

Epoch: 5| Step: 10
Training loss: 2.2556919580733528
Validation loss: 2.311054744812374

Epoch: 200| Step: 0
Training loss: 2.147895217428278
Validation loss: 2.298099032342086

Epoch: 5| Step: 1
Training loss: 2.211206642187275
Validation loss: 2.3412851587387213

Epoch: 5| Step: 2
Training loss: 1.5798525277860596
Validation loss: 2.307207852174152

Epoch: 5| Step: 3
Training loss: 2.124857505059829
Validation loss: 2.297120575134205

Epoch: 5| Step: 4
Training loss: 1.997363080714005
Validation loss: 2.3191862306664346

Epoch: 5| Step: 5
Training loss: 2.7258347029076586
Validation loss: 2.2896352391123607

Epoch: 5| Step: 6
Training loss: 2.624475517555562
Validation loss: 2.305858417923048

Epoch: 5| Step: 7
Training loss: 2.4068914772169028
Validation loss: 2.306840052459967

Epoch: 5| Step: 8
Training loss: 2.2229387744017535
Validation loss: 2.3159267109912967

Epoch: 5| Step: 9
Training loss: 2.3133246523706146
Validation loss: 2.3134600861599575

Epoch: 5| Step: 10
Training loss: 1.7972727459752158
Validation loss: 2.3128638431655366

Epoch: 201| Step: 0
Training loss: 2.0301700949227994
Validation loss: 2.3331625648127985

Epoch: 5| Step: 1
Training loss: 2.4692937517715143
Validation loss: 2.335600209603274

Epoch: 5| Step: 2
Training loss: 2.2527544327966296
Validation loss: 2.340397242187688

Epoch: 5| Step: 3
Training loss: 2.4296874018727372
Validation loss: 2.3127504327891706

Epoch: 5| Step: 4
Training loss: 1.519055211046377
Validation loss: 2.3389808441003264

Epoch: 5| Step: 5
Training loss: 2.005318722018992
Validation loss: 2.290625026905286

Epoch: 5| Step: 6
Training loss: 1.9045836873354263
Validation loss: 2.317021358524976

Epoch: 5| Step: 7
Training loss: 2.4514552951808075
Validation loss: 2.313534553164039

Epoch: 5| Step: 8
Training loss: 2.4453465273503596
Validation loss: 2.336531781319283

Epoch: 5| Step: 9
Training loss: 2.256198187151251
Validation loss: 2.3147996478204838

Epoch: 5| Step: 10
Training loss: 2.3524317354681816
Validation loss: 2.3310822851439497

Epoch: 202| Step: 0
Training loss: 2.0750915645021824
Validation loss: 2.321313122918125

Epoch: 5| Step: 1
Training loss: 2.490743188674314
Validation loss: 2.2941585413329477

Epoch: 5| Step: 2
Training loss: 2.156323970686881
Validation loss: 2.3374455804759644

Epoch: 5| Step: 3
Training loss: 2.131701393093129
Validation loss: 2.321716795710086

Epoch: 5| Step: 4
Training loss: 1.7975225194122575
Validation loss: 2.31330884929676

Epoch: 5| Step: 5
Training loss: 2.2479469681454316
Validation loss: 2.317152295685223

Epoch: 5| Step: 6
Training loss: 2.1121325517514786
Validation loss: 2.3117920441233593

Epoch: 5| Step: 7
Training loss: 2.515687361234519
Validation loss: 2.3156458252871297

Epoch: 5| Step: 8
Training loss: 2.0441144425814612
Validation loss: 2.310861529779215

Epoch: 5| Step: 9
Training loss: 1.9305119780174058
Validation loss: 2.290160455111586

Epoch: 5| Step: 10
Training loss: 2.6592057780520926
Validation loss: 2.3116265032688332

Epoch: 203| Step: 0
Training loss: 2.3849538717867347
Validation loss: 2.3195200677653

Epoch: 5| Step: 1
Training loss: 2.1329439562853723
Validation loss: 2.310742072295261

Epoch: 5| Step: 2
Training loss: 2.425252614185736
Validation loss: 2.3220699523204735

Epoch: 5| Step: 3
Training loss: 2.213919633497387
Validation loss: 2.305754470579795

Epoch: 5| Step: 4
Training loss: 2.464129215902359
Validation loss: 2.2811704350069184

Epoch: 5| Step: 5
Training loss: 2.2211460554181284
Validation loss: 2.290528584422757

Epoch: 5| Step: 6
Training loss: 1.7238654565907277
Validation loss: 2.33095155196834

Epoch: 5| Step: 7
Training loss: 1.9190802373844433
Validation loss: 2.3065633990887475

Epoch: 5| Step: 8
Training loss: 1.9770430029831245
Validation loss: 2.3235202124609025

Epoch: 5| Step: 9
Training loss: 2.4094398460122455
Validation loss: 2.295186475005913

Epoch: 5| Step: 10
Training loss: 2.3552603305192874
Validation loss: 2.288587849195586

Epoch: 204| Step: 0
Training loss: 2.0384034008710388
Validation loss: 2.2865437478057147

Epoch: 5| Step: 1
Training loss: 2.286405929161857
Validation loss: 2.3010362872050703

Epoch: 5| Step: 2
Training loss: 2.145569819100001
Validation loss: 2.2981301598352903

Epoch: 5| Step: 3
Training loss: 2.277969614598263
Validation loss: 2.3146018077465675

Epoch: 5| Step: 4
Training loss: 2.0875338614452854
Validation loss: 2.305152330334164

Epoch: 5| Step: 5
Training loss: 2.4001683255613204
Validation loss: 2.2656973855884788

Epoch: 5| Step: 6
Training loss: 1.8986204710646497
Validation loss: 2.30616675128069

Epoch: 5| Step: 7
Training loss: 2.1324875133367964
Validation loss: 2.314486621679888

Epoch: 5| Step: 8
Training loss: 2.038135069184989
Validation loss: 2.3254321752659393

Epoch: 5| Step: 9
Training loss: 2.001131929516046
Validation loss: 2.3235461811571536

Epoch: 5| Step: 10
Training loss: 2.729368498427341
Validation loss: 2.328888539361283

Epoch: 205| Step: 0
Training loss: 2.3639126021015997
Validation loss: 2.311031559883504

Epoch: 5| Step: 1
Training loss: 2.0028927863342574
Validation loss: 2.3261767263759583

Epoch: 5| Step: 2
Training loss: 2.2201819298919734
Validation loss: 2.3061674310520104

Epoch: 5| Step: 3
Training loss: 1.7964913663585012
Validation loss: 2.3457351207928943

Epoch: 5| Step: 4
Training loss: 2.118660952516936
Validation loss: 2.3283249204239356

Epoch: 5| Step: 5
Training loss: 2.310508695465942
Validation loss: 2.321788780179319

Epoch: 5| Step: 6
Training loss: 2.1013748482235584
Validation loss: 2.3158421929738484

Epoch: 5| Step: 7
Training loss: 2.6701024293718403
Validation loss: 2.323324405998286

Epoch: 5| Step: 8
Training loss: 2.2642369721071454
Validation loss: 2.296263913087505

Epoch: 5| Step: 9
Training loss: 2.023377877907189
Validation loss: 2.3062273790911014

Epoch: 5| Step: 10
Training loss: 2.1924375123674533
Validation loss: 2.293204584844439

Epoch: 206| Step: 0
Training loss: 1.862346742712254
Validation loss: 2.3276318478384517

Epoch: 5| Step: 1
Training loss: 2.413818149483688
Validation loss: 2.3177164812948354

Epoch: 5| Step: 2
Training loss: 2.0737181093455272
Validation loss: 2.3584199583443666

Epoch: 5| Step: 3
Training loss: 1.4971403042132951
Validation loss: 2.2981058672968

Epoch: 5| Step: 4
Training loss: 2.3026053640838064
Validation loss: 2.3134407783796873

Epoch: 5| Step: 5
Training loss: 1.5671368272220507
Validation loss: 2.336075983384957

Epoch: 5| Step: 6
Training loss: 2.2085237840784253
Validation loss: 2.3133162299884478

Epoch: 5| Step: 7
Training loss: 2.270004459494357
Validation loss: 2.3276853011981173

Epoch: 5| Step: 8
Training loss: 2.338750669886026
Validation loss: 2.326870082539676

Epoch: 5| Step: 9
Training loss: 2.3902409064210994
Validation loss: 2.2850349460684223

Epoch: 5| Step: 10
Training loss: 2.6377031763292162
Validation loss: 2.3170297137769817

Epoch: 207| Step: 0
Training loss: 2.0132955649077573
Validation loss: 2.2933549660012713

Epoch: 5| Step: 1
Training loss: 2.0646128380672395
Validation loss: 2.323525693312659

Epoch: 5| Step: 2
Training loss: 1.7685242202131326
Validation loss: 2.325778882144867

Epoch: 5| Step: 3
Training loss: 2.040757917716637
Validation loss: 2.3142477258420953

Epoch: 5| Step: 4
Training loss: 2.4077272710748288
Validation loss: 2.3331494815604383

Epoch: 5| Step: 5
Training loss: 2.1826971461863907
Validation loss: 2.3234075054081855

Epoch: 5| Step: 6
Training loss: 2.3073902898395833
Validation loss: 2.31891273507042

Epoch: 5| Step: 7
Training loss: 2.095794590414328
Validation loss: 2.3025798879208246

Epoch: 5| Step: 8
Training loss: 2.486928431341265
Validation loss: 2.3152622331489896

Epoch: 5| Step: 9
Training loss: 2.412706605435048
Validation loss: 2.3196932362422937

Epoch: 5| Step: 10
Training loss: 2.3255304818346585
Validation loss: 2.2848527974513835

Epoch: 208| Step: 0
Training loss: 3.049580942350964
Validation loss: 2.3338056722033915

Epoch: 5| Step: 1
Training loss: 2.314469813033191
Validation loss: 2.3163895891984163

Epoch: 5| Step: 2
Training loss: 2.019616248815717
Validation loss: 2.2861477459678423

Epoch: 5| Step: 3
Training loss: 1.9137164990403728
Validation loss: 2.312840964011521

Epoch: 5| Step: 4
Training loss: 2.1595219651818844
Validation loss: 2.319596883311589

Epoch: 5| Step: 5
Training loss: 2.2959603285469092
Validation loss: 2.296524057873855

Epoch: 5| Step: 6
Training loss: 2.1290045759260274
Validation loss: 2.3187709181518428

Epoch: 5| Step: 7
Training loss: 2.1826708213138986
Validation loss: 2.315805161265698

Epoch: 5| Step: 8
Training loss: 1.2372421574015475
Validation loss: 2.3134796009997713

Epoch: 5| Step: 9
Training loss: 1.954145851376854
Validation loss: 2.2946723364210437

Epoch: 5| Step: 10
Training loss: 1.8921442154486174
Validation loss: 2.3213892109962146

Epoch: 209| Step: 0
Training loss: 1.9996181361905767
Validation loss: 2.288305099401616

Epoch: 5| Step: 1
Training loss: 2.5200175917480667
Validation loss: 2.328965474657639

Epoch: 5| Step: 2
Training loss: 2.0703938018381773
Validation loss: 2.300897706012904

Epoch: 5| Step: 3
Training loss: 2.5066322092298727
Validation loss: 2.337073911993128

Epoch: 5| Step: 4
Training loss: 2.4481274669596806
Validation loss: 2.2921711057939875

Epoch: 5| Step: 5
Training loss: 1.8291053425698394
Validation loss: 2.325000226548636

Epoch: 5| Step: 6
Training loss: 2.254579017234125
Validation loss: 2.3271115008836505

Epoch: 5| Step: 7
Training loss: 1.938521946296506
Validation loss: 2.295555725325507

Epoch: 5| Step: 8
Training loss: 2.0178286312900573
Validation loss: 2.2847347151543382

Epoch: 5| Step: 9
Training loss: 2.0602026195320233
Validation loss: 2.2956115370601173

Epoch: 5| Step: 10
Training loss: 2.20869348096398
Validation loss: 2.332468438007665

Epoch: 210| Step: 0
Training loss: 1.9510917150701128
Validation loss: 2.3299259141955067

Epoch: 5| Step: 1
Training loss: 1.8955665512456734
Validation loss: 2.322579940551676

Epoch: 5| Step: 2
Training loss: 2.5628021806393573
Validation loss: 2.2723022677988025

Epoch: 5| Step: 3
Training loss: 2.2714617031865116
Validation loss: 2.295295170340973

Epoch: 5| Step: 4
Training loss: 2.021123085354666
Validation loss: 2.309578854547809

Epoch: 5| Step: 5
Training loss: 2.4150548580407425
Validation loss: 2.3387108888718435

Epoch: 5| Step: 6
Training loss: 1.7180886816999363
Validation loss: 2.2761933623064654

Epoch: 5| Step: 7
Training loss: 2.5466211110512598
Validation loss: 2.316016587841823

Epoch: 5| Step: 8
Training loss: 1.9548880592357343
Validation loss: 2.2939730637889464

Epoch: 5| Step: 9
Training loss: 2.4316894526347674
Validation loss: 2.27403488122409

Epoch: 5| Step: 10
Training loss: 1.5681149112867971
Validation loss: 2.2873216293762924

Epoch: 211| Step: 0
Training loss: 2.1825299068468698
Validation loss: 2.3067236286072146

Epoch: 5| Step: 1
Training loss: 1.930998507423555
Validation loss: 2.317722769500213

Epoch: 5| Step: 2
Training loss: 2.3219466186814253
Validation loss: 2.3051170531413607

Epoch: 5| Step: 3
Training loss: 2.5216291343213717
Validation loss: 2.3025443642243344

Epoch: 5| Step: 4
Training loss: 2.177353131917691
Validation loss: 2.301948788056209

Epoch: 5| Step: 5
Training loss: 2.165264580750094
Validation loss: 2.303664711154905

Epoch: 5| Step: 6
Training loss: 2.5621854077267936
Validation loss: 2.3151637297519025

Epoch: 5| Step: 7
Training loss: 1.7825936051839397
Validation loss: 2.291503500699824

Epoch: 5| Step: 8
Training loss: 1.6209830004996768
Validation loss: 2.334180456928248

Epoch: 5| Step: 9
Training loss: 2.3498236732074207
Validation loss: 2.3233029010274566

Epoch: 5| Step: 10
Training loss: 1.9762981976899707
Validation loss: 2.3302460757881214

Epoch: 212| Step: 0
Training loss: 1.863022952300301
Validation loss: 2.292001162492278

Epoch: 5| Step: 1
Training loss: 1.6169887549599695
Validation loss: 2.2948113002595116

Epoch: 5| Step: 2
Training loss: 2.1507132389554546
Validation loss: 2.2895937056197657

Epoch: 5| Step: 3
Training loss: 1.8814462477005423
Validation loss: 2.3153110132461254

Epoch: 5| Step: 4
Training loss: 2.3411820648976738
Validation loss: 2.2933658516572777

Epoch: 5| Step: 5
Training loss: 2.696275268209915
Validation loss: 2.3183426176538293

Epoch: 5| Step: 6
Training loss: 2.3656756417058222
Validation loss: 2.3067577887631074

Epoch: 5| Step: 7
Training loss: 1.768875640612393
Validation loss: 2.3232375848994877

Epoch: 5| Step: 8
Training loss: 2.4237699908985832
Validation loss: 2.2849211563553196

Epoch: 5| Step: 9
Training loss: 2.3110576977528123
Validation loss: 2.3324276397668626

Epoch: 5| Step: 10
Training loss: 1.7620272144333318
Validation loss: 2.303090652207693

Epoch: 213| Step: 0
Training loss: 1.983544243355903
Validation loss: 2.3091235911325936

Epoch: 5| Step: 1
Training loss: 1.9781892738928515
Validation loss: 2.323981762457308

Epoch: 5| Step: 2
Training loss: 2.647667516896579
Validation loss: 2.323417039841223

Epoch: 5| Step: 3
Training loss: 1.9265508448734725
Validation loss: 2.3297849052101114

Epoch: 5| Step: 4
Training loss: 2.5723870436296883
Validation loss: 2.3260015215879632

Epoch: 5| Step: 5
Training loss: 2.3856793277062143
Validation loss: 2.3053198095600265

Epoch: 5| Step: 6
Training loss: 1.834862576985568
Validation loss: 2.294248609435325

Epoch: 5| Step: 7
Training loss: 1.729750645698728
Validation loss: 2.2975788211456414

Epoch: 5| Step: 8
Training loss: 2.431703277148444
Validation loss: 2.337219252086468

Epoch: 5| Step: 9
Training loss: 1.859125841901675
Validation loss: 2.3248450593795873

Epoch: 5| Step: 10
Training loss: 1.8094156263992023
Validation loss: 2.3481822915508417

Epoch: 214| Step: 0
Training loss: 2.051413476765479
Validation loss: 2.3041298023431693

Epoch: 5| Step: 1
Training loss: 1.7436583600865823
Validation loss: 2.2994175167573805

Epoch: 5| Step: 2
Training loss: 1.7018106971385694
Validation loss: 2.304398008101459

Epoch: 5| Step: 3
Training loss: 2.566013346749588
Validation loss: 2.340491371278364

Epoch: 5| Step: 4
Training loss: 2.287331613482002
Validation loss: 2.297851984222659

Epoch: 5| Step: 5
Training loss: 1.9615967390916986
Validation loss: 2.316342026565634

Epoch: 5| Step: 6
Training loss: 2.3184208721177
Validation loss: 2.310405442241205

Epoch: 5| Step: 7
Training loss: 2.506938175840516
Validation loss: 2.3287738821585724

Epoch: 5| Step: 8
Training loss: 2.0800021305440115
Validation loss: 2.316023001316301

Epoch: 5| Step: 9
Training loss: 1.9653624196990693
Validation loss: 2.2858809837899323

Epoch: 5| Step: 10
Training loss: 1.9041552055676183
Validation loss: 2.297589731979342

Epoch: 215| Step: 0
Training loss: 2.4747525409331295
Validation loss: 2.3160164472632228

Epoch: 5| Step: 1
Training loss: 1.7228115989202493
Validation loss: 2.2753608421049996

Epoch: 5| Step: 2
Training loss: 1.8046149036949177
Validation loss: 2.3498318643668523

Epoch: 5| Step: 3
Training loss: 2.2551086497722967
Validation loss: 2.3218471578152275

Epoch: 5| Step: 4
Training loss: 2.0000563851991346
Validation loss: 2.3087971460312815

Epoch: 5| Step: 5
Training loss: 2.125365618499223
Validation loss: 2.336222065366113

Epoch: 5| Step: 6
Training loss: 1.926177194990657
Validation loss: 2.305511470810896

Epoch: 5| Step: 7
Training loss: 2.4534307398670756
Validation loss: 2.2940115392021205

Epoch: 5| Step: 8
Training loss: 2.379814888944022
Validation loss: 2.329359241782286

Epoch: 5| Step: 9
Training loss: 2.177698136785095
Validation loss: 2.316547081223751

Epoch: 5| Step: 10
Training loss: 1.707548713380173
Validation loss: 2.3261297699878436

Epoch: 216| Step: 0
Training loss: 2.2330091876991087
Validation loss: 2.2946678239882474

Epoch: 5| Step: 1
Training loss: 2.275576918674729
Validation loss: 2.3220363663056744

Epoch: 5| Step: 2
Training loss: 1.7291700600586957
Validation loss: 2.298663436088712

Epoch: 5| Step: 3
Training loss: 1.5964473263646795
Validation loss: 2.3523217181895535

Epoch: 5| Step: 4
Training loss: 2.1599160693781165
Validation loss: 2.323612367388872

Epoch: 5| Step: 5
Training loss: 2.054416653147312
Validation loss: 2.3018055127675447

Epoch: 5| Step: 6
Training loss: 2.6140837983736165
Validation loss: 2.2812540776599373

Epoch: 5| Step: 7
Training loss: 2.0817589214926775
Validation loss: 2.3402233189458173

Epoch: 5| Step: 8
Training loss: 2.462070168097221
Validation loss: 2.3118678035030316

Epoch: 5| Step: 9
Training loss: 2.035668365419507
Validation loss: 2.3083813137180975

Epoch: 5| Step: 10
Training loss: 2.097232484546785
Validation loss: 2.3487442839848405

Epoch: 217| Step: 0
Training loss: 1.293748879547371
Validation loss: 2.3223871324363947

Epoch: 5| Step: 1
Training loss: 1.8427179972077323
Validation loss: 2.2891986530223827

Epoch: 5| Step: 2
Training loss: 2.0840194970901087
Validation loss: 2.281727147431951

Epoch: 5| Step: 3
Training loss: 2.0122128963037857
Validation loss: 2.3144680795480213

Epoch: 5| Step: 4
Training loss: 2.1146624946496964
Validation loss: 2.320083924555256

Epoch: 5| Step: 5
Training loss: 2.045145017150206
Validation loss: 2.3079116852296315

Epoch: 5| Step: 6
Training loss: 2.0582990924082423
Validation loss: 2.3349373020847817

Epoch: 5| Step: 7
Training loss: 1.8972069790725656
Validation loss: 2.3151972659795783

Epoch: 5| Step: 8
Training loss: 2.2425568705038113
Validation loss: 2.3261975325144437

Epoch: 5| Step: 9
Training loss: 2.9444339160211137
Validation loss: 2.3318179860223576

Epoch: 5| Step: 10
Training loss: 2.6926209209920025
Validation loss: 2.2879974374869354

Epoch: 218| Step: 0
Training loss: 1.6808730089191857
Validation loss: 2.3255128016429225

Epoch: 5| Step: 1
Training loss: 2.1251845560151343
Validation loss: 2.2966011246269527

Epoch: 5| Step: 2
Training loss: 2.146768483458294
Validation loss: 2.31634837328685

Epoch: 5| Step: 3
Training loss: 2.193336004334807
Validation loss: 2.2739417582471093

Epoch: 5| Step: 4
Training loss: 1.839626550508802
Validation loss: 2.3317736483068563

Epoch: 5| Step: 5
Training loss: 2.1519641022152065
Validation loss: 2.35886801863308

Epoch: 5| Step: 6
Training loss: 2.244598262329571
Validation loss: 2.3118628799617613

Epoch: 5| Step: 7
Training loss: 2.4442878501999328
Validation loss: 2.287793442819861

Epoch: 5| Step: 8
Training loss: 2.213360540421956
Validation loss: 2.3016895025431108

Epoch: 5| Step: 9
Training loss: 2.221563892071618
Validation loss: 2.26625534075359

Epoch: 5| Step: 10
Training loss: 1.7637275019561882
Validation loss: 2.2805042022631756

Epoch: 219| Step: 0
Training loss: 2.057918430576571
Validation loss: 2.3092300612224705

Epoch: 5| Step: 1
Training loss: 2.1921817271019965
Validation loss: 2.3065538083265587

Epoch: 5| Step: 2
Training loss: 2.5177046431068666
Validation loss: 2.313184557571141

Epoch: 5| Step: 3
Training loss: 2.551090800034278
Validation loss: 2.2976484907007766

Epoch: 5| Step: 4
Training loss: 1.7080335664197948
Validation loss: 2.303532015169484

Epoch: 5| Step: 5
Training loss: 1.7776809540184046
Validation loss: 2.308923760225271

Epoch: 5| Step: 6
Training loss: 2.2744185700296145
Validation loss: 2.3021548390970357

Epoch: 5| Step: 7
Training loss: 1.9258611016422247
Validation loss: 2.3103635109449394

Epoch: 5| Step: 8
Training loss: 2.322708588134613
Validation loss: 2.309648935221181

Epoch: 5| Step: 9
Training loss: 1.7474697076575916
Validation loss: 2.2793664195210726

Epoch: 5| Step: 10
Training loss: 2.1370163175096466
Validation loss: 2.302781299121767

Epoch: 220| Step: 0
Training loss: 2.6500871859909196
Validation loss: 2.3207741875326113

Epoch: 5| Step: 1
Training loss: 1.9324914738120325
Validation loss: 2.3260579937024963

Epoch: 5| Step: 2
Training loss: 1.5886867352726972
Validation loss: 2.296263479350566

Epoch: 5| Step: 3
Training loss: 2.40030897853669
Validation loss: 2.3035175099161584

Epoch: 5| Step: 4
Training loss: 1.9964862594341832
Validation loss: 2.29839624987055

Epoch: 5| Step: 5
Training loss: 2.3176764210993563
Validation loss: 2.298300108948285

Epoch: 5| Step: 6
Training loss: 2.148680960992429
Validation loss: 2.2936843711573336

Epoch: 5| Step: 7
Training loss: 1.8797974564631796
Validation loss: 2.278357211396224

Epoch: 5| Step: 8
Training loss: 1.8547761608293885
Validation loss: 2.3316806317950527

Epoch: 5| Step: 9
Training loss: 1.8741367896200307
Validation loss: 2.3195519041623

Epoch: 5| Step: 10
Training loss: 2.2997837462555073
Validation loss: 2.2979473484550894

Epoch: 221| Step: 0
Training loss: 2.509944211788195
Validation loss: 2.322005372698905

Epoch: 5| Step: 1
Training loss: 2.0538813528914885
Validation loss: 2.2969582259169483

Epoch: 5| Step: 2
Training loss: 1.9501311282549478
Validation loss: 2.296050163512725

Epoch: 5| Step: 3
Training loss: 1.8850106351840776
Validation loss: 2.272087662553447

Epoch: 5| Step: 4
Training loss: 2.35505725815286
Validation loss: 2.309727470911221

Epoch: 5| Step: 5
Training loss: 2.066821916450488
Validation loss: 2.3113794957327762

Epoch: 5| Step: 6
Training loss: 2.226563142475236
Validation loss: 2.3344085603089937

Epoch: 5| Step: 7
Training loss: 1.761567508946867
Validation loss: 2.339649431289913

Epoch: 5| Step: 8
Training loss: 2.1569838449919256
Validation loss: 2.3105568519483466

Epoch: 5| Step: 9
Training loss: 2.1413718820991994
Validation loss: 2.32108339019445

Epoch: 5| Step: 10
Training loss: 2.1961036424064595
Validation loss: 2.3038197007956143

Epoch: 222| Step: 0
Training loss: 2.1054505186406285
Validation loss: 2.294402165821108

Epoch: 5| Step: 1
Training loss: 2.2289082267423543
Validation loss: 2.3268250115116014

Epoch: 5| Step: 2
Training loss: 2.0291665763254425
Validation loss: 2.3022892240490993

Epoch: 5| Step: 3
Training loss: 2.1162645643874334
Validation loss: 2.318788199771658

Epoch: 5| Step: 4
Training loss: 2.263245694688035
Validation loss: 2.308734353226095

Epoch: 5| Step: 5
Training loss: 2.110643697604431
Validation loss: 2.278286177183512

Epoch: 5| Step: 6
Training loss: 1.7123935025924817
Validation loss: 2.2850951399834427

Epoch: 5| Step: 7
Training loss: 2.2985078366510923
Validation loss: 2.3130577144331466

Epoch: 5| Step: 8
Training loss: 2.0271667520805896
Validation loss: 2.3372055509632164

Epoch: 5| Step: 9
Training loss: 1.9111235807933649
Validation loss: 2.286714410037991

Epoch: 5| Step: 10
Training loss: 2.0808353961918566
Validation loss: 2.308677844903813

Epoch: 223| Step: 0
Training loss: 2.0078546541887468
Validation loss: 2.324815087403024

Epoch: 5| Step: 1
Training loss: 2.140921801853494
Validation loss: 2.333189865029054

Epoch: 5| Step: 2
Training loss: 1.9747428509343399
Validation loss: 2.290928614582225

Epoch: 5| Step: 3
Training loss: 2.5546777940851557
Validation loss: 2.299058576212585

Epoch: 5| Step: 4
Training loss: 2.1725399179599427
Validation loss: 2.3102534233841556

Epoch: 5| Step: 5
Training loss: 1.8061999304144463
Validation loss: 2.287895505736562

Epoch: 5| Step: 6
Training loss: 1.9654218608158658
Validation loss: 2.296237299239128

Epoch: 5| Step: 7
Training loss: 2.1985666721030155
Validation loss: 2.3497277882606387

Epoch: 5| Step: 8
Training loss: 2.124799606747763
Validation loss: 2.2969705766731274

Epoch: 5| Step: 9
Training loss: 2.3409410046912904
Validation loss: 2.3261602821321934

Epoch: 5| Step: 10
Training loss: 1.7861577069282446
Validation loss: 2.3067620730557716

Epoch: 224| Step: 0
Training loss: 1.976163258395211
Validation loss: 2.3433472886935593

Epoch: 5| Step: 1
Training loss: 2.1802714122888225
Validation loss: 2.3173878316210983

Epoch: 5| Step: 2
Training loss: 2.7200708797980777
Validation loss: 2.29079915366898

Epoch: 5| Step: 3
Training loss: 1.6826459513556395
Validation loss: 2.299223197795648

Epoch: 5| Step: 4
Training loss: 1.837938881705739
Validation loss: 2.2967983057531773

Epoch: 5| Step: 5
Training loss: 2.178286084823108
Validation loss: 2.3256864283565193

Epoch: 5| Step: 6
Training loss: 1.6483659773944372
Validation loss: 2.3098367489097678

Epoch: 5| Step: 7
Training loss: 2.161959180293055
Validation loss: 2.309248769751218

Epoch: 5| Step: 8
Training loss: 1.9614183056826362
Validation loss: 2.3299907270508684

Epoch: 5| Step: 9
Training loss: 2.2011869306481007
Validation loss: 2.3053227854152136

Epoch: 5| Step: 10
Training loss: 2.235509197764799
Validation loss: 2.3283228983143793

Epoch: 225| Step: 0
Training loss: 1.8188972046522913
Validation loss: 2.3143621794180773

Epoch: 5| Step: 1
Training loss: 2.102148718773209
Validation loss: 2.2875953190928247

Epoch: 5| Step: 2
Training loss: 2.030389104486846
Validation loss: 2.3399776253560907

Epoch: 5| Step: 3
Training loss: 1.7238068144289487
Validation loss: 2.3157077802796797

Epoch: 5| Step: 4
Training loss: 2.1561228396749725
Validation loss: 2.3218603124830124

Epoch: 5| Step: 5
Training loss: 2.151177341224953
Validation loss: 2.30107244805606

Epoch: 5| Step: 6
Training loss: 2.306488264641552
Validation loss: 2.3197739001817776

Epoch: 5| Step: 7
Training loss: 2.3340282994690034
Validation loss: 2.309710680907494

Epoch: 5| Step: 8
Training loss: 2.219567376674925
Validation loss: 2.324480555503947

Epoch: 5| Step: 9
Training loss: 2.149567906629419
Validation loss: 2.334232540137807

Epoch: 5| Step: 10
Training loss: 2.253110854359743
Validation loss: 2.322839103723378

Epoch: 226| Step: 0
Training loss: 1.8881919274690024
Validation loss: 2.2775989533639804

Epoch: 5| Step: 1
Training loss: 2.2975867589399006
Validation loss: 2.297558687545052

Epoch: 5| Step: 2
Training loss: 1.8158483817585869
Validation loss: 2.344595196549878

Epoch: 5| Step: 3
Training loss: 2.174100325851518
Validation loss: 2.303264800468611

Epoch: 5| Step: 4
Training loss: 2.57555830375072
Validation loss: 2.3054149149238405

Epoch: 5| Step: 5
Training loss: 2.0068901110388793
Validation loss: 2.2931346315863324

Epoch: 5| Step: 6
Training loss: 1.9513906484153238
Validation loss: 2.27564735082195

Epoch: 5| Step: 7
Training loss: 2.1440849465153042
Validation loss: 2.295095734967301

Epoch: 5| Step: 8
Training loss: 2.0396399137177657
Validation loss: 2.3211245612360445

Epoch: 5| Step: 9
Training loss: 1.962590163279658
Validation loss: 2.3306448712174714

Epoch: 5| Step: 10
Training loss: 2.014501095670893
Validation loss: 2.3298875284668457

Epoch: 227| Step: 0
Training loss: 2.7458017554852763
Validation loss: 2.3077304935464373

Epoch: 5| Step: 1
Training loss: 1.9649605991208607
Validation loss: 2.2798370062426834

Epoch: 5| Step: 2
Training loss: 1.8724249641653048
Validation loss: 2.3103924686869015

Epoch: 5| Step: 3
Training loss: 2.298917212822139
Validation loss: 2.3295636056779916

Epoch: 5| Step: 4
Training loss: 2.2595517544442223
Validation loss: 2.3072877037262267

Epoch: 5| Step: 5
Training loss: 2.3877328569389746
Validation loss: 2.3451663642718166

Epoch: 5| Step: 6
Training loss: 2.375148065870494
Validation loss: 2.3595048683551463

Epoch: 5| Step: 7
Training loss: 1.8166659261836138
Validation loss: 2.3396235618901784

Epoch: 5| Step: 8
Training loss: 1.5450287406988814
Validation loss: 2.3154985232315584

Epoch: 5| Step: 9
Training loss: 1.8120017846795529
Validation loss: 2.333794725816917

Epoch: 5| Step: 10
Training loss: 1.866004345536155
Validation loss: 2.3172206017514454

Epoch: 228| Step: 0
Training loss: 1.9672675227825698
Validation loss: 2.2887420373979745

Epoch: 5| Step: 1
Training loss: 1.7602820109796926
Validation loss: 2.306421534766456

Epoch: 5| Step: 2
Training loss: 1.834668049320173
Validation loss: 2.3210416363397437

Epoch: 5| Step: 3
Training loss: 2.463957275001628
Validation loss: 2.280204033634772

Epoch: 5| Step: 4
Training loss: 2.3177759967885296
Validation loss: 2.2664464811344955

Epoch: 5| Step: 5
Training loss: 2.4105513139163675
Validation loss: 2.3023436616332975

Epoch: 5| Step: 6
Training loss: 2.038866640235761
Validation loss: 2.298716483506572

Epoch: 5| Step: 7
Training loss: 1.973107254291686
Validation loss: 2.3244090746092527

Epoch: 5| Step: 8
Training loss: 1.6262500063333944
Validation loss: 2.276190733557609

Epoch: 5| Step: 9
Training loss: 2.117526206763006
Validation loss: 2.3258765160309283

Epoch: 5| Step: 10
Training loss: 2.3359742432833466
Validation loss: 2.3167807543939904

Epoch: 229| Step: 0
Training loss: 1.852251142087778
Validation loss: 2.3130130287432555

Epoch: 5| Step: 1
Training loss: 2.2227528958351632
Validation loss: 2.2999211450303596

Epoch: 5| Step: 2
Training loss: 2.4738412822672866
Validation loss: 2.2981185275827536

Epoch: 5| Step: 3
Training loss: 1.7065287184222617
Validation loss: 2.302984408121954

Epoch: 5| Step: 4
Training loss: 2.3708934416523073
Validation loss: 2.2670947881973875

Epoch: 5| Step: 5
Training loss: 1.8532991916041144
Validation loss: 2.323111751940976

Epoch: 5| Step: 6
Training loss: 1.9848645424926805
Validation loss: 2.296425432813996

Epoch: 5| Step: 7
Training loss: 1.7960957039734913
Validation loss: 2.335483544366984

Epoch: 5| Step: 8
Training loss: 2.0480037227015635
Validation loss: 2.3396403136439066

Epoch: 5| Step: 9
Training loss: 2.1389965908242727
Validation loss: 2.2953765984166825

Epoch: 5| Step: 10
Training loss: 2.188981889415424
Validation loss: 2.3411102556852437

Epoch: 230| Step: 0
Training loss: 2.311782416278847
Validation loss: 2.3044826916432335

Epoch: 5| Step: 1
Training loss: 2.163218640116789
Validation loss: 2.3216967074572397

Epoch: 5| Step: 2
Training loss: 2.3574641491782318
Validation loss: 2.3172534576909185

Epoch: 5| Step: 3
Training loss: 2.0216821546136887
Validation loss: 2.2780367564551867

Epoch: 5| Step: 4
Training loss: 2.258354781871259
Validation loss: 2.330279809712034

Epoch: 5| Step: 5
Training loss: 1.8680705771458743
Validation loss: 2.3138788841040556

Epoch: 5| Step: 6
Training loss: 1.6351533746671296
Validation loss: 2.3122494852054962

Epoch: 5| Step: 7
Training loss: 1.9280456477178745
Validation loss: 2.2916315732340338

Epoch: 5| Step: 8
Training loss: 2.3735843253913798
Validation loss: 2.3439177706705143

Epoch: 5| Step: 9
Training loss: 1.7578917760986368
Validation loss: 2.30199434947993

Epoch: 5| Step: 10
Training loss: 2.074387940369023
Validation loss: 2.3134101067858666

Epoch: 231| Step: 0
Training loss: 1.990535874220517
Validation loss: 2.2858336011419667

Epoch: 5| Step: 1
Training loss: 2.1317187288839743
Validation loss: 2.2949350047123196

Epoch: 5| Step: 2
Training loss: 1.7045416583394635
Validation loss: 2.303705972043329

Epoch: 5| Step: 3
Training loss: 1.9567778341415
Validation loss: 2.2893697886646898

Epoch: 5| Step: 4
Training loss: 1.670016102056483
Validation loss: 2.327878440832748

Epoch: 5| Step: 5
Training loss: 2.2038912691826233
Validation loss: 2.3108910986467732

Epoch: 5| Step: 6
Training loss: 1.7810613298046511
Validation loss: 2.303243770473585

Epoch: 5| Step: 7
Training loss: 2.626869081195096
Validation loss: 2.3106763378689306

Epoch: 5| Step: 8
Training loss: 1.8308431518434947
Validation loss: 2.2936526898603864

Epoch: 5| Step: 9
Training loss: 2.2761418882836293
Validation loss: 2.340973404510421

Epoch: 5| Step: 10
Training loss: 2.479227839978737
Validation loss: 2.274742351629169

Epoch: 232| Step: 0
Training loss: 1.800438705600191
Validation loss: 2.30495652397471

Epoch: 5| Step: 1
Training loss: 2.0321653211129216
Validation loss: 2.315839084511727

Epoch: 5| Step: 2
Training loss: 2.424500352962922
Validation loss: 2.319628788281558

Epoch: 5| Step: 3
Training loss: 2.1273393656853234
Validation loss: 2.2977115976223486

Epoch: 5| Step: 4
Training loss: 1.3229494115826934
Validation loss: 2.2923119675884593

Epoch: 5| Step: 5
Training loss: 1.8744223022597821
Validation loss: 2.2788732871639144

Epoch: 5| Step: 6
Training loss: 2.118739836451817
Validation loss: 2.28863366932378

Epoch: 5| Step: 7
Training loss: 1.9724638287959055
Validation loss: 2.32010421682661

Epoch: 5| Step: 8
Training loss: 2.295392758373096
Validation loss: 2.298980406465496

Epoch: 5| Step: 9
Training loss: 1.694305964927618
Validation loss: 2.2873699630041897

Epoch: 5| Step: 10
Training loss: 2.7335140943845926
Validation loss: 2.350038849678155

Epoch: 233| Step: 0
Training loss: 1.788767494633265
Validation loss: 2.3281335185665175

Epoch: 5| Step: 1
Training loss: 2.082074077230138
Validation loss: 2.288333151555259

Epoch: 5| Step: 2
Training loss: 2.5177828614506357
Validation loss: 2.3207865065443625

Epoch: 5| Step: 3
Training loss: 1.913761224196774
Validation loss: 2.322463164354932

Epoch: 5| Step: 4
Training loss: 1.8538195538735627
Validation loss: 2.292401453465578

Epoch: 5| Step: 5
Training loss: 2.154112488921876
Validation loss: 2.307344828299019

Epoch: 5| Step: 6
Training loss: 2.194007567150103
Validation loss: 2.3354489898779294

Epoch: 5| Step: 7
Training loss: 1.628839651525613
Validation loss: 2.2725837992616693

Epoch: 5| Step: 8
Training loss: 1.5965561938576618
Validation loss: 2.293123742037783

Epoch: 5| Step: 9
Training loss: 1.9561548764437762
Validation loss: 2.2874775941081933

Epoch: 5| Step: 10
Training loss: 2.597057485767518
Validation loss: 2.284871634894764

Epoch: 234| Step: 0
Training loss: 1.518959231936431
Validation loss: 2.2885358849269632

Epoch: 5| Step: 1
Training loss: 2.1984864230158574
Validation loss: 2.2708479478254207

Epoch: 5| Step: 2
Training loss: 2.2102996660979337
Validation loss: 2.3169250986263905

Epoch: 5| Step: 3
Training loss: 2.3315725722106238
Validation loss: 2.2962155506349666

Epoch: 5| Step: 4
Training loss: 1.3652975043243618
Validation loss: 2.3080100760481748

Epoch: 5| Step: 5
Training loss: 1.921754538629839
Validation loss: 2.3031106895841145

Epoch: 5| Step: 6
Training loss: 2.0750669767302115
Validation loss: 2.3614231567753357

Epoch: 5| Step: 7
Training loss: 1.8338904473542956
Validation loss: 2.352217573508573

Epoch: 5| Step: 8
Training loss: 2.1405132849284825
Validation loss: 2.3141226193331956

Epoch: 5| Step: 9
Training loss: 2.3813335894634
Validation loss: 2.316374386416762

Epoch: 5| Step: 10
Training loss: 1.9710793414895245
Validation loss: 2.3058915991902382

Epoch: 235| Step: 0
Training loss: 2.0422624639923916
Validation loss: 2.319324833289066

Epoch: 5| Step: 1
Training loss: 2.32858804283935
Validation loss: 2.296949611822315

Epoch: 5| Step: 2
Training loss: 2.0738764191229992
Validation loss: 2.302657412204355

Epoch: 5| Step: 3
Training loss: 2.105979843246058
Validation loss: 2.2966338781627424

Epoch: 5| Step: 4
Training loss: 1.6979775291097265
Validation loss: 2.29822698998693

Epoch: 5| Step: 5
Training loss: 2.0023715740269563
Validation loss: 2.2947151353826523

Epoch: 5| Step: 6
Training loss: 2.003992863320684
Validation loss: 2.339157270853978

Epoch: 5| Step: 7
Training loss: 2.4985028552393453
Validation loss: 2.3203153527692075

Epoch: 5| Step: 8
Training loss: 1.5705787091429577
Validation loss: 2.3282065637746374

Epoch: 5| Step: 9
Training loss: 2.1083405395304244
Validation loss: 2.2754932521079616

Epoch: 5| Step: 10
Training loss: 2.0998910830272584
Validation loss: 2.316485534914759

Epoch: 236| Step: 0
Training loss: 1.9267864582853775
Validation loss: 2.326525688669405

Epoch: 5| Step: 1
Training loss: 1.6395124750526515
Validation loss: 2.3208042072767516

Epoch: 5| Step: 2
Training loss: 2.4039496783926024
Validation loss: 2.3216718366509252

Epoch: 5| Step: 3
Training loss: 2.1701472154245645
Validation loss: 2.2956908734685624

Epoch: 5| Step: 4
Training loss: 1.9680580255203823
Validation loss: 2.2900640837407953

Epoch: 5| Step: 5
Training loss: 2.1410385066582545
Validation loss: 2.3070542758222223

Epoch: 5| Step: 6
Training loss: 1.851691261675243
Validation loss: 2.293951176373541

Epoch: 5| Step: 7
Training loss: 2.328649372213893
Validation loss: 2.3127891095957285

Epoch: 5| Step: 8
Training loss: 1.8999503430352478
Validation loss: 2.288844831416135

Epoch: 5| Step: 9
Training loss: 1.9362507145722108
Validation loss: 2.3076269615919363

Epoch: 5| Step: 10
Training loss: 1.5987755322002086
Validation loss: 2.320789418381559

Epoch: 237| Step: 0
Training loss: 2.368751034698663
Validation loss: 2.316106750099056

Epoch: 5| Step: 1
Training loss: 2.012676359232691
Validation loss: 2.3225468244064174

Epoch: 5| Step: 2
Training loss: 1.4950510081389383
Validation loss: 2.2763586199310493

Epoch: 5| Step: 3
Training loss: 2.165485231147033
Validation loss: 2.3284282449669345

Epoch: 5| Step: 4
Training loss: 2.195813213548166
Validation loss: 2.272568775534557

Epoch: 5| Step: 5
Training loss: 1.8936400529526418
Validation loss: 2.291550847219022

Epoch: 5| Step: 6
Training loss: 1.8617640942403362
Validation loss: 2.3225791894224237

Epoch: 5| Step: 7
Training loss: 2.1222375978486507
Validation loss: 2.300576420950977

Epoch: 5| Step: 8
Training loss: 2.0523669697145404
Validation loss: 2.28968351662385

Epoch: 5| Step: 9
Training loss: 1.7680793515215818
Validation loss: 2.2770048380495678

Epoch: 5| Step: 10
Training loss: 2.1895904361840732
Validation loss: 2.3248143210063565

Epoch: 238| Step: 0
Training loss: 2.3376613622445936
Validation loss: 2.290958712642447

Epoch: 5| Step: 1
Training loss: 2.1718834526940394
Validation loss: 2.2970271492298004

Epoch: 5| Step: 2
Training loss: 1.7524849415130797
Validation loss: 2.2921952638272955

Epoch: 5| Step: 3
Training loss: 1.9006688070219404
Validation loss: 2.3334465863683778

Epoch: 5| Step: 4
Training loss: 1.8202819821660567
Validation loss: 2.311237178863585

Epoch: 5| Step: 5
Training loss: 1.877999830597371
Validation loss: 2.297396319072684

Epoch: 5| Step: 6
Training loss: 2.0601343401834917
Validation loss: 2.310575138100486

Epoch: 5| Step: 7
Training loss: 2.265921948145048
Validation loss: 2.3318803881036234

Epoch: 5| Step: 8
Training loss: 1.8167476866384413
Validation loss: 2.320634216564439

Epoch: 5| Step: 9
Training loss: 1.9382488280309635
Validation loss: 2.327401306867996

Epoch: 5| Step: 10
Training loss: 2.4506566938682317
Validation loss: 2.291616408970673

Epoch: 239| Step: 0
Training loss: 1.6981526154317967
Validation loss: 2.305259584364712

Epoch: 5| Step: 1
Training loss: 1.908464989708577
Validation loss: 2.291045136689092

Epoch: 5| Step: 2
Training loss: 1.7828584068332285
Validation loss: 2.2842580943896142

Epoch: 5| Step: 3
Training loss: 1.4582314955258158
Validation loss: 2.3318156673504795

Epoch: 5| Step: 4
Training loss: 2.6352069052547273
Validation loss: 2.314598348448916

Epoch: 5| Step: 5
Training loss: 2.218552701532587
Validation loss: 2.3121585244617746

Epoch: 5| Step: 6
Training loss: 2.031942865604747
Validation loss: 2.3103885678404503

Epoch: 5| Step: 7
Training loss: 2.3111648829432103
Validation loss: 2.331796551687497

Epoch: 5| Step: 8
Training loss: 1.7015855463602267
Validation loss: 2.2902699626526752

Epoch: 5| Step: 9
Training loss: 2.068301163125307
Validation loss: 2.2988703035019715

Epoch: 5| Step: 10
Training loss: 1.6872246129009207
Validation loss: 2.3487269630003764

Epoch: 240| Step: 0
Training loss: 2.2128880392195835
Validation loss: 2.3131811817682686

Epoch: 5| Step: 1
Training loss: 1.5284286509374487
Validation loss: 2.3069991481856653

Epoch: 5| Step: 2
Training loss: 1.9055602905256623
Validation loss: 2.3021753818289223

Epoch: 5| Step: 3
Training loss: 1.855509739473234
Validation loss: 2.2869122053985826

Epoch: 5| Step: 4
Training loss: 2.2982503704600648
Validation loss: 2.301792437281202

Epoch: 5| Step: 5
Training loss: 2.441944276653495
Validation loss: 2.3087131509691123

Epoch: 5| Step: 6
Training loss: 1.7059183573937222
Validation loss: 2.3135546424776168

Epoch: 5| Step: 7
Training loss: 2.1051138329251353
Validation loss: 2.2772434859622854

Epoch: 5| Step: 8
Training loss: 2.107961901890491
Validation loss: 2.3092968137398624

Epoch: 5| Step: 9
Training loss: 1.9026322978234196
Validation loss: 2.2992300160285435

Epoch: 5| Step: 10
Training loss: 1.795590414211412
Validation loss: 2.3129698723038308

Epoch: 241| Step: 0
Training loss: 1.8493364690677505
Validation loss: 2.314930208976028

Epoch: 5| Step: 1
Training loss: 2.73421612959231
Validation loss: 2.3229946989901675

Epoch: 5| Step: 2
Training loss: 1.8529528455874373
Validation loss: 2.307752010324121

Epoch: 5| Step: 3
Training loss: 2.5205441353688465
Validation loss: 2.3273841993545967

Epoch: 5| Step: 4
Training loss: 1.6288679745062804
Validation loss: 2.2885202512237073

Epoch: 5| Step: 5
Training loss: 1.927033363587954
Validation loss: 2.315110526562996

Epoch: 5| Step: 6
Training loss: 2.12895586148472
Validation loss: 2.326432803388508

Epoch: 5| Step: 7
Training loss: 1.954048487730313
Validation loss: 2.294447148604927

Epoch: 5| Step: 8
Training loss: 1.9499363619861798
Validation loss: 2.2727325297040353

Epoch: 5| Step: 9
Training loss: 1.538081287195351
Validation loss: 2.273027440643395

Epoch: 5| Step: 10
Training loss: 1.886651837601812
Validation loss: 2.325104312980291

Epoch: 242| Step: 0
Training loss: 1.7416593837433665
Validation loss: 2.3168883354026106

Epoch: 5| Step: 1
Training loss: 1.8720153577655507
Validation loss: 2.3022304334420953

Epoch: 5| Step: 2
Training loss: 1.786319946030095
Validation loss: 2.3085959076561173

Epoch: 5| Step: 3
Training loss: 2.0424166748531656
Validation loss: 2.2909402313064624

Epoch: 5| Step: 4
Training loss: 2.1249174214193745
Validation loss: 2.3370861785440593

Epoch: 5| Step: 5
Training loss: 2.1968382830963313
Validation loss: 2.345181219167739

Epoch: 5| Step: 6
Training loss: 1.5284701435391375
Validation loss: 2.3566138644519055

Epoch: 5| Step: 7
Training loss: 2.279316749257291
Validation loss: 2.3208386064480084

Epoch: 5| Step: 8
Training loss: 1.795870359117267
Validation loss: 2.345412701361958

Epoch: 5| Step: 9
Training loss: 1.9220556158777882
Validation loss: 2.314984239669758

Epoch: 5| Step: 10
Training loss: 2.8486304690168627
Validation loss: 2.3163250310573837

Epoch: 243| Step: 0
Training loss: 1.9672640687859013
Validation loss: 2.2931542148679425

Epoch: 5| Step: 1
Training loss: 2.0709632858344964
Validation loss: 2.305892168976634

Epoch: 5| Step: 2
Training loss: 2.0579763568821288
Validation loss: 2.3152832979238083

Epoch: 5| Step: 3
Training loss: 2.096223878464564
Validation loss: 2.3116174652905217

Epoch: 5| Step: 4
Training loss: 2.1736638228985705
Validation loss: 2.3184905434375445

Epoch: 5| Step: 5
Training loss: 1.9748526554433548
Validation loss: 2.3146640902799245

Epoch: 5| Step: 6
Training loss: 2.0746564098062117
Validation loss: 2.3238862288306685

Epoch: 5| Step: 7
Training loss: 2.161525630286285
Validation loss: 2.309636347019037

Epoch: 5| Step: 8
Training loss: 2.3237370865469695
Validation loss: 2.2767653076722527

Epoch: 5| Step: 9
Training loss: 1.118390589260789
Validation loss: 2.2912338179929836

Epoch: 5| Step: 10
Training loss: 1.8443103520675832
Validation loss: 2.2928714892638005

Epoch: 244| Step: 0
Training loss: 2.0954039005424923
Validation loss: 2.31905679736468

Epoch: 5| Step: 1
Training loss: 2.6293802500047403
Validation loss: 2.286977086021286

Epoch: 5| Step: 2
Training loss: 2.1234465137820897
Validation loss: 2.3320865493659575

Epoch: 5| Step: 3
Training loss: 1.4969659160487407
Validation loss: 2.275164248768842

Epoch: 5| Step: 4
Training loss: 2.0354291912254467
Validation loss: 2.312636254178555

Epoch: 5| Step: 5
Training loss: 1.4336481317916872
Validation loss: 2.288812566776944

Epoch: 5| Step: 6
Training loss: 2.132112828445112
Validation loss: 2.349389034950242

Epoch: 5| Step: 7
Training loss: 2.097546679371774
Validation loss: 2.273276187400527

Epoch: 5| Step: 8
Training loss: 1.8826590194510815
Validation loss: 2.3280811480493853

Epoch: 5| Step: 9
Training loss: 1.8849848328240753
Validation loss: 2.291897417758497

Epoch: 5| Step: 10
Training loss: 1.82345833133151
Validation loss: 2.2905058666299287

Epoch: 245| Step: 0
Training loss: 1.7600263429967753
Validation loss: 2.3481461563534443

Epoch: 5| Step: 1
Training loss: 1.5783317354966924
Validation loss: 2.3044519647870505

Epoch: 5| Step: 2
Training loss: 1.1332143136714428
Validation loss: 2.316695945515185

Epoch: 5| Step: 3
Training loss: 2.1701619369978338
Validation loss: 2.279443796441842

Epoch: 5| Step: 4
Training loss: 2.697240609751171
Validation loss: 2.3103903737373295

Epoch: 5| Step: 5
Training loss: 2.2501715488733587
Validation loss: 2.2941508621043263

Epoch: 5| Step: 6
Training loss: 2.2376861580069356
Validation loss: 2.333205369181348

Epoch: 5| Step: 7
Training loss: 2.0555412346395454
Validation loss: 2.2921665727790903

Epoch: 5| Step: 8
Training loss: 1.463184525795605
Validation loss: 2.315616911651925

Epoch: 5| Step: 9
Training loss: 1.7119470692143925
Validation loss: 2.29483420947043

Epoch: 5| Step: 10
Training loss: 2.3128533995431533
Validation loss: 2.3129501237275205

Epoch: 246| Step: 0
Training loss: 2.2353026058490553
Validation loss: 2.3174034907223056

Epoch: 5| Step: 1
Training loss: 2.0776730382952073
Validation loss: 2.2953360466891453

Epoch: 5| Step: 2
Training loss: 1.5718399134942351
Validation loss: 2.287317278969047

Epoch: 5| Step: 3
Training loss: 1.9857467955979224
Validation loss: 2.304564426390312

Epoch: 5| Step: 4
Training loss: 2.0704558700726303
Validation loss: 2.280396204365123

Epoch: 5| Step: 5
Training loss: 2.916894268056439
Validation loss: 2.3059557896062315

Epoch: 5| Step: 6
Training loss: 1.5862605324974925
Validation loss: 2.323084412193501

Epoch: 5| Step: 7
Training loss: 1.8531986524281006
Validation loss: 2.305451470796512

Epoch: 5| Step: 8
Training loss: 1.79294680912331
Validation loss: 2.297549888244788

Epoch: 5| Step: 9
Training loss: 1.6794727276844625
Validation loss: 2.322284070651004

Epoch: 5| Step: 10
Training loss: 1.605095961604624
Validation loss: 2.307532480116798

Epoch: 247| Step: 0
Training loss: 2.2152172493579556
Validation loss: 2.3046018356162024

Epoch: 5| Step: 1
Training loss: 1.9727595840432068
Validation loss: 2.299377656195406

Epoch: 5| Step: 2
Training loss: 1.7425277446141632
Validation loss: 2.273922490345569

Epoch: 5| Step: 3
Training loss: 1.7391228513707806
Validation loss: 2.272561339215401

Epoch: 5| Step: 4
Training loss: 2.0172482836701016
Validation loss: 2.2990672994886467

Epoch: 5| Step: 5
Training loss: 1.9009380434265313
Validation loss: 2.3156523997633025

Epoch: 5| Step: 6
Training loss: 1.9957353901042225
Validation loss: 2.305648749525031

Epoch: 5| Step: 7
Training loss: 1.752790474211743
Validation loss: 2.282450417020266

Epoch: 5| Step: 8
Training loss: 1.8545087077372713
Validation loss: 2.3453364722873857

Epoch: 5| Step: 9
Training loss: 1.958159344296173
Validation loss: 2.318404720076603

Epoch: 5| Step: 10
Training loss: 2.3489908242921347
Validation loss: 2.2942546971346243

Epoch: 248| Step: 0
Training loss: 1.3449358475995519
Validation loss: 2.291258213600531

Epoch: 5| Step: 1
Training loss: 1.7492907994413427
Validation loss: 2.284380496169571

Epoch: 5| Step: 2
Training loss: 1.7131684968499867
Validation loss: 2.3432442232171957

Epoch: 5| Step: 3
Training loss: 2.0033255585293746
Validation loss: 2.3026667141413837

Epoch: 5| Step: 4
Training loss: 2.0144126854004
Validation loss: 2.300779303686688

Epoch: 5| Step: 5
Training loss: 2.277790110898421
Validation loss: 2.3352379932183753

Epoch: 5| Step: 6
Training loss: 2.0579411378826524
Validation loss: 2.3341259738049778

Epoch: 5| Step: 7
Training loss: 1.9460754736704848
Validation loss: 2.313349654474736

Epoch: 5| Step: 8
Training loss: 1.962594718834102
Validation loss: 2.309422688979304

Epoch: 5| Step: 9
Training loss: 2.365644600508607
Validation loss: 2.316987819931524

Epoch: 5| Step: 10
Training loss: 2.009959812996175
Validation loss: 2.30016100276717

Epoch: 249| Step: 0
Training loss: 1.6407247603830772
Validation loss: 2.295424228023226

Epoch: 5| Step: 1
Training loss: 1.7709205007603892
Validation loss: 2.2789049427478516

Epoch: 5| Step: 2
Training loss: 2.303275396646135
Validation loss: 2.271383272180229

Epoch: 5| Step: 3
Training loss: 1.6299318154238565
Validation loss: 2.3157388255147695

Epoch: 5| Step: 4
Training loss: 2.3130931609012855
Validation loss: 2.3028405760719712

Epoch: 5| Step: 5
Training loss: 1.9706964710074113
Validation loss: 2.302517390966933

Epoch: 5| Step: 6
Training loss: 1.5744857372365983
Validation loss: 2.2927239064694547

Epoch: 5| Step: 7
Training loss: 2.3863784872146168
Validation loss: 2.2909595423995164

Epoch: 5| Step: 8
Training loss: 1.5610718112778894
Validation loss: 2.2734146108554443

Epoch: 5| Step: 9
Training loss: 2.134520018357933
Validation loss: 2.337113076426924

Epoch: 5| Step: 10
Training loss: 2.0124821964210926
Validation loss: 2.3070618848761084

Epoch: 250| Step: 0
Training loss: 2.0123538894214237
Validation loss: 2.3185233548432835

Epoch: 5| Step: 1
Training loss: 1.6668285609135245
Validation loss: 2.3027692422665296

Epoch: 5| Step: 2
Training loss: 2.087687583307331
Validation loss: 2.3224762217072703

Epoch: 5| Step: 3
Training loss: 1.606240933760056
Validation loss: 2.3500511189182847

Epoch: 5| Step: 4
Training loss: 1.7190312935653138
Validation loss: 2.3071112417185167

Epoch: 5| Step: 5
Training loss: 1.5163533142063688
Validation loss: 2.294962598255634

Epoch: 5| Step: 6
Training loss: 1.9349721600010807
Validation loss: 2.325674172778408

Epoch: 5| Step: 7
Training loss: 2.1890590016938165
Validation loss: 2.3044875580864312

Epoch: 5| Step: 8
Training loss: 2.5057093277307536
Validation loss: 2.308834452254716

Epoch: 5| Step: 9
Training loss: 1.7431107884234966
Validation loss: 2.3011925233622015

Epoch: 5| Step: 10
Training loss: 2.3727574050236324
Validation loss: 2.3046964016383202

Epoch: 251| Step: 0
Training loss: 2.1545197552288506
Validation loss: 2.300787222360898

Epoch: 5| Step: 1
Training loss: 1.7699839031974627
Validation loss: 2.2896383114904686

Epoch: 5| Step: 2
Training loss: 1.9344430002514739
Validation loss: 2.319669802786555

Epoch: 5| Step: 3
Training loss: 1.7283899638733204
Validation loss: 2.310150513863169

Epoch: 5| Step: 4
Training loss: 1.6365789021399755
Validation loss: 2.33711630961475

Epoch: 5| Step: 5
Training loss: 1.7964650889018998
Validation loss: 2.335829685637057

Epoch: 5| Step: 6
Training loss: 2.4185232287812117
Validation loss: 2.33986494955999

Epoch: 5| Step: 7
Training loss: 2.2958583528109644
Validation loss: 2.3060014830884255

Epoch: 5| Step: 8
Training loss: 2.168576047225764
Validation loss: 2.28829085725226

Epoch: 5| Step: 9
Training loss: 1.722293184042164
Validation loss: 2.3122722460364167

Epoch: 5| Step: 10
Training loss: 2.0900607272730056
Validation loss: 2.275669955024599

Epoch: 252| Step: 0
Training loss: 1.4477329915226227
Validation loss: 2.2979148802784115

Epoch: 5| Step: 1
Training loss: 2.285671286944847
Validation loss: 2.329212413497598

Epoch: 5| Step: 2
Training loss: 2.1096713387762107
Validation loss: 2.310297651175279

Epoch: 5| Step: 3
Training loss: 1.5203812680662918
Validation loss: 2.308160586068363

Epoch: 5| Step: 4
Training loss: 1.0785583509736867
Validation loss: 2.313502231159542

Epoch: 5| Step: 5
Training loss: 2.2237463558997006
Validation loss: 2.328491287834622

Epoch: 5| Step: 6
Training loss: 2.485396648964818
Validation loss: 2.3159868491897475

Epoch: 5| Step: 7
Training loss: 1.8768635707612666
Validation loss: 2.293781331984345

Epoch: 5| Step: 8
Training loss: 2.2832533518387446
Validation loss: 2.2764459850982433

Epoch: 5| Step: 9
Training loss: 2.1126559137897494
Validation loss: 2.290254793571436

Epoch: 5| Step: 10
Training loss: 1.3178580680279766
Validation loss: 2.302537988917596

Epoch: 253| Step: 0
Training loss: 1.6435828294344992
Validation loss: 2.2925697545946955

Epoch: 5| Step: 1
Training loss: 2.212669637610056
Validation loss: 2.3329170298086286

Epoch: 5| Step: 2
Training loss: 1.7732608387883524
Validation loss: 2.3028560479887994

Epoch: 5| Step: 3
Training loss: 2.353968710439411
Validation loss: 2.310245175677284

Epoch: 5| Step: 4
Training loss: 2.0858243418657354
Validation loss: 2.301416505329925

Epoch: 5| Step: 5
Training loss: 2.0030114628220512
Validation loss: 2.346216001295593

Epoch: 5| Step: 6
Training loss: 2.175745636735863
Validation loss: 2.3276761801921513

Epoch: 5| Step: 7
Training loss: 1.9223489564609475
Validation loss: 2.2889711425541592

Epoch: 5| Step: 8
Training loss: 1.7200495575263754
Validation loss: 2.320786528637223

Epoch: 5| Step: 9
Training loss: 1.6861815777039795
Validation loss: 2.31011222790115

Epoch: 5| Step: 10
Training loss: 1.6158158386972696
Validation loss: 2.334524704937965

Epoch: 254| Step: 0
Training loss: 2.421904040747005
Validation loss: 2.319413406848535

Epoch: 5| Step: 1
Training loss: 2.282310866242203
Validation loss: 2.3411774017513585

Epoch: 5| Step: 2
Training loss: 1.3685800054883253
Validation loss: 2.2829649420191287

Epoch: 5| Step: 3
Training loss: 1.4091766420835077
Validation loss: 2.2701669029127554

Epoch: 5| Step: 4
Training loss: 1.8650035775280713
Validation loss: 2.3124417782953692

Epoch: 5| Step: 5
Training loss: 1.8316151486002148
Validation loss: 2.3116931522078614

Epoch: 5| Step: 6
Training loss: 1.721120829115942
Validation loss: 2.331583978736509

Epoch: 5| Step: 7
Training loss: 1.984048951764098
Validation loss: 2.33242431159957

Epoch: 5| Step: 8
Training loss: 2.036569759770967
Validation loss: 2.2640228943561658

Epoch: 5| Step: 9
Training loss: 2.163560609423881
Validation loss: 2.330693456408638

Epoch: 5| Step: 10
Training loss: 1.9074414391483996
Validation loss: 2.3224827575308464

Epoch: 255| Step: 0
Training loss: 1.9945546167889834
Validation loss: 2.303186917067874

Epoch: 5| Step: 1
Training loss: 1.6999646884392356
Validation loss: 2.2776673555141493

Epoch: 5| Step: 2
Training loss: 1.8892723478091153
Validation loss: 2.2731660207825555

Epoch: 5| Step: 3
Training loss: 1.6513468302910668
Validation loss: 2.3619154512141205

Epoch: 5| Step: 4
Training loss: 1.964042909899287
Validation loss: 2.302066417790264

Epoch: 5| Step: 5
Training loss: 2.0849101647799206
Validation loss: 2.281505001266143

Epoch: 5| Step: 6
Training loss: 1.8089942571064903
Validation loss: 2.3162327190091636

Epoch: 5| Step: 7
Training loss: 2.1075717706553045
Validation loss: 2.289379442456502

Epoch: 5| Step: 8
Training loss: 1.831504892570257
Validation loss: 2.308628768631705

Epoch: 5| Step: 9
Training loss: 1.5930321516634625
Validation loss: 2.275689545527457

Epoch: 5| Step: 10
Training loss: 2.6011535506398595
Validation loss: 2.2995250260066586

Epoch: 256| Step: 0
Training loss: 1.7699651123100013
Validation loss: 2.314886640311718

Epoch: 5| Step: 1
Training loss: 2.2635680233268953
Validation loss: 2.3159585491858183

Epoch: 5| Step: 2
Training loss: 2.076743103853502
Validation loss: 2.2700740052324764

Epoch: 5| Step: 3
Training loss: 2.305348240163046
Validation loss: 2.3333591585737103

Epoch: 5| Step: 4
Training loss: 1.528584944266752
Validation loss: 2.262282547908178

Epoch: 5| Step: 5
Training loss: 1.5134377181537226
Validation loss: 2.2969128168411235

Epoch: 5| Step: 6
Training loss: 1.959364666827879
Validation loss: 2.2683323509788798

Epoch: 5| Step: 7
Training loss: 2.077480933403723
Validation loss: 2.2928224263149963

Epoch: 5| Step: 8
Training loss: 1.9022581484606682
Validation loss: 2.3137092266774943

Epoch: 5| Step: 9
Training loss: 1.7071302721297308
Validation loss: 2.2984849746514837

Epoch: 5| Step: 10
Training loss: 2.157176827530459
Validation loss: 2.2965906025856073

Epoch: 257| Step: 0
Training loss: 1.8961872846357521
Validation loss: 2.2663172325238032

Epoch: 5| Step: 1
Training loss: 2.096101152461712
Validation loss: 2.3087944067238415

Epoch: 5| Step: 2
Training loss: 1.9463255668773078
Validation loss: 2.326075879430757

Epoch: 5| Step: 3
Training loss: 1.7764810669284927
Validation loss: 2.3235503743630055

Epoch: 5| Step: 4
Training loss: 1.7634922751464899
Validation loss: 2.2771047120800634

Epoch: 5| Step: 5
Training loss: 1.9536612423036819
Validation loss: 2.318829219194463

Epoch: 5| Step: 6
Training loss: 1.75746653225154
Validation loss: 2.3350481593014076

Epoch: 5| Step: 7
Training loss: 2.271289872872899
Validation loss: 2.3023227100775046

Epoch: 5| Step: 8
Training loss: 2.02934375227828
Validation loss: 2.2700380541656644

Epoch: 5| Step: 9
Training loss: 1.8423580799284742
Validation loss: 2.321340538746052

Epoch: 5| Step: 10
Training loss: 1.6265608553919324
Validation loss: 2.260362929473857

Epoch: 258| Step: 0
Training loss: 1.668681579787372
Validation loss: 2.29255323367395

Epoch: 5| Step: 1
Training loss: 1.7688769884657005
Validation loss: 2.307371585130102

Epoch: 5| Step: 2
Training loss: 1.922413014104593
Validation loss: 2.3390903747735896

Epoch: 5| Step: 3
Training loss: 2.064366738524899
Validation loss: 2.31719780212413

Epoch: 5| Step: 4
Training loss: 2.1130324691465874
Validation loss: 2.309685791475312

Epoch: 5| Step: 5
Training loss: 2.134948443431274
Validation loss: 2.300860429320571

Epoch: 5| Step: 6
Training loss: 1.564292032660796
Validation loss: 2.260132338249838

Epoch: 5| Step: 7
Training loss: 1.5538069948897013
Validation loss: 2.2934916785112476

Epoch: 5| Step: 8
Training loss: 1.4610598099859988
Validation loss: 2.2882692941613447

Epoch: 5| Step: 9
Training loss: 2.3692490064669807
Validation loss: 2.317558908064396

Epoch: 5| Step: 10
Training loss: 2.3469414916187805
Validation loss: 2.3250532778623896

Epoch: 259| Step: 0
Training loss: 1.4353448219571878
Validation loss: 2.311851035697117

Epoch: 5| Step: 1
Training loss: 2.0893382949640356
Validation loss: 2.3063086151572034

Epoch: 5| Step: 2
Training loss: 1.8472285027584427
Validation loss: 2.3301657485120026

Epoch: 5| Step: 3
Training loss: 1.6921857134667826
Validation loss: 2.3266661486772153

Epoch: 5| Step: 4
Training loss: 1.8403602733555295
Validation loss: 2.312274842080714

Epoch: 5| Step: 5
Training loss: 1.6257590941753028
Validation loss: 2.31018570420619

Epoch: 5| Step: 6
Training loss: 2.6747683201936248
Validation loss: 2.3239133611285268

Epoch: 5| Step: 7
Training loss: 2.0546825104279365
Validation loss: 2.292413091802453

Epoch: 5| Step: 8
Training loss: 1.7292563710058808
Validation loss: 2.302487346020324

Epoch: 5| Step: 9
Training loss: 2.142280439702123
Validation loss: 2.336247097856702

Epoch: 5| Step: 10
Training loss: 1.7904689541074312
Validation loss: 2.3391428139003794

Epoch: 260| Step: 0
Training loss: 1.7152459231296089
Validation loss: 2.3010452987825025

Epoch: 5| Step: 1
Training loss: 2.2967473208693225
Validation loss: 2.3315638699416414

Epoch: 5| Step: 2
Training loss: 1.421254452284899
Validation loss: 2.325831854523097

Epoch: 5| Step: 3
Training loss: 2.067035312485673
Validation loss: 2.3088488491556336

Epoch: 5| Step: 4
Training loss: 1.2961505567025224
Validation loss: 2.348499603003806

Epoch: 5| Step: 5
Training loss: 2.342445519138457
Validation loss: 2.349487941475129

Epoch: 5| Step: 6
Training loss: 2.157874117668275
Validation loss: 2.342389102825762

Epoch: 5| Step: 7
Training loss: 2.0901450251953517
Validation loss: 2.315457241081782

Epoch: 5| Step: 8
Training loss: 2.1697616724024913
Validation loss: 2.333222463130133

Epoch: 5| Step: 9
Training loss: 1.571553285715486
Validation loss: 2.3510801358657982

Epoch: 5| Step: 10
Training loss: 1.6771419664957556
Validation loss: 2.334594064779856

Epoch: 261| Step: 0
Training loss: 2.1523570425519662
Validation loss: 2.3255797823801143

Epoch: 5| Step: 1
Training loss: 1.5690684538642625
Validation loss: 2.3713342488198395

Epoch: 5| Step: 2
Training loss: 2.0292932328603626
Validation loss: 2.3095369859459076

Epoch: 5| Step: 3
Training loss: 1.8957803600022765
Validation loss: 2.3056534372719977

Epoch: 5| Step: 4
Training loss: 1.6491774213664143
Validation loss: 2.2739065515452532

Epoch: 5| Step: 5
Training loss: 2.232855006374616
Validation loss: 2.286284784603767

Epoch: 5| Step: 6
Training loss: 2.00232180294254
Validation loss: 2.2949902140876355

Epoch: 5| Step: 7
Training loss: 2.0199047458964783
Validation loss: 2.2699439376883817

Epoch: 5| Step: 8
Training loss: 1.8808095574837493
Validation loss: 2.2726068095801284

Epoch: 5| Step: 9
Training loss: 1.6992376216848957
Validation loss: 2.329661390172105

Epoch: 5| Step: 10
Training loss: 1.8502038405213903
Validation loss: 2.3307825004143345

Epoch: 262| Step: 0
Training loss: 1.9936030127415312
Validation loss: 2.316702187800613

Epoch: 5| Step: 1
Training loss: 1.6654145385153412
Validation loss: 2.3167219392502747

Epoch: 5| Step: 2
Training loss: 2.267931060530413
Validation loss: 2.320389638440068

Epoch: 5| Step: 3
Training loss: 1.8699309174123988
Validation loss: 2.3128838767876236

Epoch: 5| Step: 4
Training loss: 1.4907140997082882
Validation loss: 2.355210706447446

Epoch: 5| Step: 5
Training loss: 1.980727319936387
Validation loss: 2.328515701011406

Epoch: 5| Step: 6
Training loss: 1.96794608520686
Validation loss: 2.324154933274963

Epoch: 5| Step: 7
Training loss: 1.8177384936026628
Validation loss: 2.3137412405345446

Epoch: 5| Step: 8
Training loss: 2.1491057865098466
Validation loss: 2.342630079134045

Epoch: 5| Step: 9
Training loss: 1.9271870215761604
Validation loss: 2.2933236479334105

Epoch: 5| Step: 10
Training loss: 1.874320415682746
Validation loss: 2.330723111906773

Epoch: 263| Step: 0
Training loss: 1.9130019383198817
Validation loss: 2.296557914294143

Epoch: 5| Step: 1
Training loss: 1.4917427718427096
Validation loss: 2.302552809864157

Epoch: 5| Step: 2
Training loss: 1.328407302473742
Validation loss: 2.342431115312258

Epoch: 5| Step: 3
Training loss: 1.8292487187617634
Validation loss: 2.3051992319272685

Epoch: 5| Step: 4
Training loss: 2.286200077936356
Validation loss: 2.338264757168121

Epoch: 5| Step: 5
Training loss: 1.995838245977781
Validation loss: 2.2774989414479405

Epoch: 5| Step: 6
Training loss: 1.4207083139018006
Validation loss: 2.298157741787461

Epoch: 5| Step: 7
Training loss: 2.6666847367469173
Validation loss: 2.3076348348272955

Epoch: 5| Step: 8
Training loss: 1.8950666477289702
Validation loss: 2.314934209590715

Epoch: 5| Step: 9
Training loss: 1.8913873443856166
Validation loss: 2.32883998421583

Epoch: 5| Step: 10
Training loss: 1.6731645121021739
Validation loss: 2.336304454739557

Epoch: 264| Step: 0
Training loss: 1.7786975441635042
Validation loss: 2.3086543168508675

Epoch: 5| Step: 1
Training loss: 1.8854701489473153
Validation loss: 2.301595651707941

Epoch: 5| Step: 2
Training loss: 1.908521143515568
Validation loss: 2.2605063069670734

Epoch: 5| Step: 3
Training loss: 1.6084105926035845
Validation loss: 2.318903863682843

Epoch: 5| Step: 4
Training loss: 1.3557752103408336
Validation loss: 2.314010515350801

Epoch: 5| Step: 5
Training loss: 2.2572908953947173
Validation loss: 2.3312991160989576

Epoch: 5| Step: 6
Training loss: 2.2774562906034292
Validation loss: 2.3553321861508643

Epoch: 5| Step: 7
Training loss: 1.5585553539776358
Validation loss: 2.3519133998033643

Epoch: 5| Step: 8
Training loss: 2.167968859973252
Validation loss: 2.3244418013671577

Epoch: 5| Step: 9
Training loss: 1.683114747059754
Validation loss: 2.282036903922761

Epoch: 5| Step: 10
Training loss: 2.0552515916353
Validation loss: 2.3026823943054104

Epoch: 265| Step: 0
Training loss: 1.7828654944177091
Validation loss: 2.3098237799304937

Epoch: 5| Step: 1
Training loss: 1.8982310241691247
Validation loss: 2.2779046586149825

Epoch: 5| Step: 2
Training loss: 3.0137914904567
Validation loss: 2.300754804288774

Epoch: 5| Step: 3
Training loss: 1.5728637315882619
Validation loss: 2.3392202421140897

Epoch: 5| Step: 4
Training loss: 1.4960085692695757
Validation loss: 2.2571895049407393

Epoch: 5| Step: 5
Training loss: 1.573546613984033
Validation loss: 2.2971069774631516

Epoch: 5| Step: 6
Training loss: 1.8331078332876911
Validation loss: 2.3229780644736664

Epoch: 5| Step: 7
Training loss: 2.0050734305312883
Validation loss: 2.3023675603823426

Epoch: 5| Step: 8
Training loss: 1.9901396754142864
Validation loss: 2.352121071157746

Epoch: 5| Step: 9
Training loss: 1.479000117995107
Validation loss: 2.302506993942182

Epoch: 5| Step: 10
Training loss: 1.8570066483295926
Validation loss: 2.2944114744101283

Epoch: 266| Step: 0
Training loss: 2.1678963863908405
Validation loss: 2.3269405915847914

Epoch: 5| Step: 1
Training loss: 1.9123908391977655
Validation loss: 2.3297263292301675

Epoch: 5| Step: 2
Training loss: 2.3993832590488147
Validation loss: 2.275342935450288

Epoch: 5| Step: 3
Training loss: 1.4045539800986162
Validation loss: 2.3550709163794994

Epoch: 5| Step: 4
Training loss: 1.4159877590199916
Validation loss: 2.308642643791677

Epoch: 5| Step: 5
Training loss: 2.036841809264833
Validation loss: 2.326871913104808

Epoch: 5| Step: 6
Training loss: 1.85737957991491
Validation loss: 2.3055448355386194

Epoch: 5| Step: 7
Training loss: 1.7449332867743022
Validation loss: 2.3280741522307724

Epoch: 5| Step: 8
Training loss: 1.947955071653769
Validation loss: 2.3416325269281857

Epoch: 5| Step: 9
Training loss: 2.0955089184028095
Validation loss: 2.333797027143775

Epoch: 5| Step: 10
Training loss: 1.5410796757720338
Validation loss: 2.3007174807099684

Epoch: 267| Step: 0
Training loss: 2.013100395916837
Validation loss: 2.323639768776599

Epoch: 5| Step: 1
Training loss: 1.905291894992445
Validation loss: 2.2824992188308784

Epoch: 5| Step: 2
Training loss: 1.9139291522228281
Validation loss: 2.300060649988838

Epoch: 5| Step: 3
Training loss: 1.7386223961897513
Validation loss: 2.3528674645515233

Epoch: 5| Step: 4
Training loss: 1.6338405019593851
Validation loss: 2.2950815290929674

Epoch: 5| Step: 5
Training loss: 2.468079874375298
Validation loss: 2.3504451482880424

Epoch: 5| Step: 6
Training loss: 2.3387525048540687
Validation loss: 2.331894946150211

Epoch: 5| Step: 7
Training loss: 1.4010458547914817
Validation loss: 2.3606789977287272

Epoch: 5| Step: 8
Training loss: 1.8189493076670127
Validation loss: 2.3026903389998505

Epoch: 5| Step: 9
Training loss: 1.6200764233023355
Validation loss: 2.3011888770777804

Epoch: 5| Step: 10
Training loss: 1.812322410565081
Validation loss: 2.2802749094486545

Epoch: 268| Step: 0
Training loss: 1.9745694089442705
Validation loss: 2.3290214015878212

Epoch: 5| Step: 1
Training loss: 1.7460877420548206
Validation loss: 2.3194758884452704

Epoch: 5| Step: 2
Training loss: 1.1487159650905787
Validation loss: 2.324295003261778

Epoch: 5| Step: 3
Training loss: 1.5661311110107003
Validation loss: 2.2962790061888043

Epoch: 5| Step: 4
Training loss: 1.4705515424975235
Validation loss: 2.3375106235271734

Epoch: 5| Step: 5
Training loss: 2.7100294719655946
Validation loss: 2.3029120223291595

Epoch: 5| Step: 6
Training loss: 2.3024330621488804
Validation loss: 2.3086867417056083

Epoch: 5| Step: 7
Training loss: 1.6216681140816094
Validation loss: 2.278192966350449

Epoch: 5| Step: 8
Training loss: 1.7997510366986598
Validation loss: 2.326221887109029

Epoch: 5| Step: 9
Training loss: 1.5588408539578822
Validation loss: 2.299587777083498

Epoch: 5| Step: 10
Training loss: 2.1602564645323277
Validation loss: 2.3172296029400608

Epoch: 269| Step: 0
Training loss: 1.7387615783218149
Validation loss: 2.305708237394511

Epoch: 5| Step: 1
Training loss: 1.9487033078397218
Validation loss: 2.308550960697452

Epoch: 5| Step: 2
Training loss: 1.776027049193726
Validation loss: 2.29555009784243

Epoch: 5| Step: 3
Training loss: 1.9627314412871328
Validation loss: 2.3035979846237677

Epoch: 5| Step: 4
Training loss: 1.7737458754982822
Validation loss: 2.309798762968875

Epoch: 5| Step: 5
Training loss: 2.032975857480154
Validation loss: 2.335552436670198

Epoch: 5| Step: 6
Training loss: 1.9089502689444213
Validation loss: 2.3073209988809125

Epoch: 5| Step: 7
Training loss: 1.5499046788592532
Validation loss: 2.2967867649797107

Epoch: 5| Step: 8
Training loss: 1.4172512792937138
Validation loss: 2.3193804300786893

Epoch: 5| Step: 9
Training loss: 2.1196937507178424
Validation loss: 2.3808536067300783

Epoch: 5| Step: 10
Training loss: 2.080685178620379
Validation loss: 2.310795193008228

Epoch: 270| Step: 0
Training loss: 1.9507645037584997
Validation loss: 2.3027387057438333

Epoch: 5| Step: 1
Training loss: 1.973654677521449
Validation loss: 2.3277701436195293

Epoch: 5| Step: 2
Training loss: 1.7490808252816448
Validation loss: 2.317892866449457

Epoch: 5| Step: 3
Training loss: 1.5703379311091765
Validation loss: 2.2968414819853007

Epoch: 5| Step: 4
Training loss: 1.7491974352704622
Validation loss: 2.32579210192939

Epoch: 5| Step: 5
Training loss: 1.726647698557196
Validation loss: 2.323269637392243

Epoch: 5| Step: 6
Training loss: 1.3750516708375524
Validation loss: 2.3143595020830188

Epoch: 5| Step: 7
Training loss: 2.319615937046034
Validation loss: 2.3243816569231326

Epoch: 5| Step: 8
Training loss: 1.8404223267348228
Validation loss: 2.3275624964067743

Epoch: 5| Step: 9
Training loss: 1.8833550902041094
Validation loss: 2.315071728524311

Epoch: 5| Step: 10
Training loss: 2.3123111132211798
Validation loss: 2.3154599160403553

Epoch: 271| Step: 0
Training loss: 1.7346445509937292
Validation loss: 2.2791080102940606

Epoch: 5| Step: 1
Training loss: 1.7083384661093417
Validation loss: 2.3298671954158117

Epoch: 5| Step: 2
Training loss: 2.216743421540287
Validation loss: 2.3022493210619213

Epoch: 5| Step: 3
Training loss: 1.8719448630616815
Validation loss: 2.298802629280426

Epoch: 5| Step: 4
Training loss: 1.5817892760791707
Validation loss: 2.263604177948972

Epoch: 5| Step: 5
Training loss: 1.9340877017636515
Validation loss: 2.3027639508123463

Epoch: 5| Step: 6
Training loss: 1.735808664892278
Validation loss: 2.297067282159939

Epoch: 5| Step: 7
Training loss: 2.533901003763762
Validation loss: 2.304436079730056

Epoch: 5| Step: 8
Training loss: 1.6299824989877116
Validation loss: 2.3038759721956796

Epoch: 5| Step: 9
Training loss: 1.6360227429644205
Validation loss: 2.329772375188841

Epoch: 5| Step: 10
Training loss: 1.8755180279061832
Validation loss: 2.3361605320554317

Epoch: 272| Step: 0
Training loss: 1.5997844222988922
Validation loss: 2.323477507163081

Epoch: 5| Step: 1
Training loss: 1.9736385505815583
Validation loss: 2.3681598340812764

Epoch: 5| Step: 2
Training loss: 1.6637063518390305
Validation loss: 2.3140833477460907

Epoch: 5| Step: 3
Training loss: 1.7200415873490045
Validation loss: 2.30414621689392

Epoch: 5| Step: 4
Training loss: 2.0424492432580545
Validation loss: 2.271912075727061

Epoch: 5| Step: 5
Training loss: 1.5584137700310647
Validation loss: 2.2999778094208763

Epoch: 5| Step: 6
Training loss: 1.6192666661587314
Validation loss: 2.29987352216516

Epoch: 5| Step: 7
Training loss: 1.9754989235270894
Validation loss: 2.3178703875481754

Epoch: 5| Step: 8
Training loss: 2.198154984942961
Validation loss: 2.310772226806516

Epoch: 5| Step: 9
Training loss: 2.367022417311242
Validation loss: 2.34298904207132

Epoch: 5| Step: 10
Training loss: 1.592890788327184
Validation loss: 2.324297850040014

Epoch: 273| Step: 0
Training loss: 1.7921583550768136
Validation loss: 2.2988473664865325

Epoch: 5| Step: 1
Training loss: 1.6509199207878393
Validation loss: 2.288568724205707

Epoch: 5| Step: 2
Training loss: 1.3028594132887028
Validation loss: 2.294852652185381

Epoch: 5| Step: 3
Training loss: 1.8107757917455716
Validation loss: 2.2910063580039

Epoch: 5| Step: 4
Training loss: 1.8429669155808683
Validation loss: 2.3340543852037197

Epoch: 5| Step: 5
Training loss: 1.8876494013792566
Validation loss: 2.2855557056380444

Epoch: 5| Step: 6
Training loss: 2.037689799262287
Validation loss: 2.276896797178009

Epoch: 5| Step: 7
Training loss: 2.032332146764635
Validation loss: 2.2485608873098313

Epoch: 5| Step: 8
Training loss: 1.7189925976250442
Validation loss: 2.3099091163641137

Epoch: 5| Step: 9
Training loss: 1.981679753045628
Validation loss: 2.2882094918477143

Epoch: 5| Step: 10
Training loss: 2.215983640754992
Validation loss: 2.34103504511779

Epoch: 274| Step: 0
Training loss: 1.1799997585910615
Validation loss: 2.2692695568322256

Epoch: 5| Step: 1
Training loss: 2.144904654813581
Validation loss: 2.332938217587705

Epoch: 5| Step: 2
Training loss: 1.754042452343039
Validation loss: 2.3652397543121477

Epoch: 5| Step: 3
Training loss: 1.6756743283607267
Validation loss: 2.325222314858857

Epoch: 5| Step: 4
Training loss: 1.4864139406792625
Validation loss: 2.306856078769699

Epoch: 5| Step: 5
Training loss: 1.9014363406105421
Validation loss: 2.321258664688713

Epoch: 5| Step: 6
Training loss: 2.0844935301975163
Validation loss: 2.3359537914593

Epoch: 5| Step: 7
Training loss: 1.8898549679205994
Validation loss: 2.282880791574339

Epoch: 5| Step: 8
Training loss: 1.4406545276056875
Validation loss: 2.342795638065342

Epoch: 5| Step: 9
Training loss: 2.462433665974816
Validation loss: 2.3087386904816576

Epoch: 5| Step: 10
Training loss: 1.7056982217170555
Validation loss: 2.2970163149651

Epoch: 275| Step: 0
Training loss: 2.26821593416882
Validation loss: 2.3007195554960953

Epoch: 5| Step: 1
Training loss: 1.740394319490225
Validation loss: 2.3152169405766143

Epoch: 5| Step: 2
Training loss: 1.4405157548439425
Validation loss: 2.2893107194723137

Epoch: 5| Step: 3
Training loss: 1.8943023858017944
Validation loss: 2.305081152593913

Epoch: 5| Step: 4
Training loss: 1.9872323437769113
Validation loss: 2.2845641260992857

Epoch: 5| Step: 5
Training loss: 2.001983374390369
Validation loss: 2.298565926689274

Epoch: 5| Step: 6
Training loss: 2.1411813722960003
Validation loss: 2.295895477344797

Epoch: 5| Step: 7
Training loss: 2.0887313591737686
Validation loss: 2.305012083617392

Epoch: 5| Step: 8
Training loss: 1.813793378609616
Validation loss: 2.330673699616378

Epoch: 5| Step: 9
Training loss: 1.557680938277092
Validation loss: 2.2901400721475276

Epoch: 5| Step: 10
Training loss: 1.581202386433243
Validation loss: 2.313726451922787

Epoch: 276| Step: 0
Training loss: 1.7739936527925673
Validation loss: 2.2895533873814

Epoch: 5| Step: 1
Training loss: 2.5901491839477084
Validation loss: 2.3053536980514138

Epoch: 5| Step: 2
Training loss: 1.5927242643342558
Validation loss: 2.326479440709439

Epoch: 5| Step: 3
Training loss: 1.4477386731123127
Validation loss: 2.271248201434125

Epoch: 5| Step: 4
Training loss: 2.0773941705329793
Validation loss: 2.3326039879209475

Epoch: 5| Step: 5
Training loss: 1.73993828477701
Validation loss: 2.34239795804847

Epoch: 5| Step: 6
Training loss: 1.9485256514687619
Validation loss: 2.339685828105387

Epoch: 5| Step: 7
Training loss: 2.043364098189198
Validation loss: 2.3258514060940207

Epoch: 5| Step: 8
Training loss: 1.6066735566388521
Validation loss: 2.3224136718083748

Epoch: 5| Step: 9
Training loss: 1.6853254930931525
Validation loss: 2.371084263480147

Epoch: 5| Step: 10
Training loss: 2.034694509422381
Validation loss: 2.3228199649567993

Epoch: 277| Step: 0
Training loss: 1.646375333494466
Validation loss: 2.3038093786407168

Epoch: 5| Step: 1
Training loss: 2.3446168440918798
Validation loss: 2.30965386681187

Epoch: 5| Step: 2
Training loss: 1.9767652565919884
Validation loss: 2.3381477775354247

Epoch: 5| Step: 3
Training loss: 1.7936168820633918
Validation loss: 2.3242214457592008

Epoch: 5| Step: 4
Training loss: 1.64812520761673
Validation loss: 2.3071618675685293

Epoch: 5| Step: 5
Training loss: 1.647457391885448
Validation loss: 2.337840451294386

Epoch: 5| Step: 6
Training loss: 2.033613854219859
Validation loss: 2.343144825018293

Epoch: 5| Step: 7
Training loss: 2.0525901155749904
Validation loss: 2.344899544960065

Epoch: 5| Step: 8
Training loss: 2.1398526768465107
Validation loss: 2.3385792014444675

Epoch: 5| Step: 9
Training loss: 1.3573926305021973
Validation loss: 2.316912956038755

Epoch: 5| Step: 10
Training loss: 1.6818364790265574
Validation loss: 2.310782637676636

Epoch: 278| Step: 0
Training loss: 1.7075635835082783
Validation loss: 2.297907787042514

Epoch: 5| Step: 1
Training loss: 2.3282972438512006
Validation loss: 2.3591078381719712

Epoch: 5| Step: 2
Training loss: 1.779247429806599
Validation loss: 2.324642120156119

Epoch: 5| Step: 3
Training loss: 1.8028071792796454
Validation loss: 2.319039369060053

Epoch: 5| Step: 4
Training loss: 1.9775122972725752
Validation loss: 2.385576916542338

Epoch: 5| Step: 5
Training loss: 1.3756330939977266
Validation loss: 2.31094092172381

Epoch: 5| Step: 6
Training loss: 1.559514282978154
Validation loss: 2.2761438255354496

Epoch: 5| Step: 7
Training loss: 2.257821053353446
Validation loss: 2.283697083723043

Epoch: 5| Step: 8
Training loss: 1.8588671591801593
Validation loss: 2.3168459117431075

Epoch: 5| Step: 9
Training loss: 1.5954996864129658
Validation loss: 2.286687329653159

Epoch: 5| Step: 10
Training loss: 1.6546816327762777
Validation loss: 2.31935698019865

Epoch: 279| Step: 0
Training loss: 1.7030786630469055
Validation loss: 2.291324013368647

Epoch: 5| Step: 1
Training loss: 2.695614916656336
Validation loss: 2.336961050670065

Epoch: 5| Step: 2
Training loss: 1.892888692248455
Validation loss: 2.3126033348580113

Epoch: 5| Step: 3
Training loss: 1.7738226249725484
Validation loss: 2.2993819397449657

Epoch: 5| Step: 4
Training loss: 1.860834462526659
Validation loss: 2.2712092167999867

Epoch: 5| Step: 5
Training loss: 1.436083717912969
Validation loss: 2.3569175626042327

Epoch: 5| Step: 6
Training loss: 1.3997912114994207
Validation loss: 2.325610516147744

Epoch: 5| Step: 7
Training loss: 1.6256763077925125
Validation loss: 2.3387656049932946

Epoch: 5| Step: 8
Training loss: 2.186373393271865
Validation loss: 2.317049802660236

Epoch: 5| Step: 9
Training loss: 1.6027537311944295
Validation loss: 2.2898272968056217

Epoch: 5| Step: 10
Training loss: 1.28653997350119
Validation loss: 2.3081606227209863

Epoch: 280| Step: 0
Training loss: 1.949992116276381
Validation loss: 2.315121250128084

Epoch: 5| Step: 1
Training loss: 1.719336808341041
Validation loss: 2.2981238598525535

Epoch: 5| Step: 2
Training loss: 1.935103688086411
Validation loss: 2.339969212356062

Epoch: 5| Step: 3
Training loss: 1.630163133216
Validation loss: 2.3347304625049135

Epoch: 5| Step: 4
Training loss: 1.6815686714471707
Validation loss: 2.3098689607201472

Epoch: 5| Step: 5
Training loss: 2.0061525838142713
Validation loss: 2.297990337431442

Epoch: 5| Step: 6
Training loss: 1.3536001732251213
Validation loss: 2.2649323827305783

Epoch: 5| Step: 7
Training loss: 1.4632481544283553
Validation loss: 2.3164910396041596

Epoch: 5| Step: 8
Training loss: 1.583985428627501
Validation loss: 2.2767316732027787

Epoch: 5| Step: 9
Training loss: 2.303680717266812
Validation loss: 2.29604995751038

Epoch: 5| Step: 10
Training loss: 2.145377348317728
Validation loss: 2.3170808409784356

Epoch: 281| Step: 0
Training loss: 1.7828376119652114
Validation loss: 2.3330603570250497

Epoch: 5| Step: 1
Training loss: 1.0859082444455974
Validation loss: 2.322222168016964

Epoch: 5| Step: 2
Training loss: 1.8497842869133612
Validation loss: 2.302766128403632

Epoch: 5| Step: 3
Training loss: 1.8187434429037392
Validation loss: 2.274130806253425

Epoch: 5| Step: 4
Training loss: 2.3584403908988447
Validation loss: 2.303313071672879

Epoch: 5| Step: 5
Training loss: 1.6828853240765722
Validation loss: 2.3422213715151043

Epoch: 5| Step: 6
Training loss: 1.4309351745573244
Validation loss: 2.333101570815618

Epoch: 5| Step: 7
Training loss: 2.372575023819551
Validation loss: 2.3194794153502443

Epoch: 5| Step: 8
Training loss: 1.985551020054878
Validation loss: 2.3345404742100198

Epoch: 5| Step: 9
Training loss: 1.529355726412919
Validation loss: 2.331792569558652

Epoch: 5| Step: 10
Training loss: 1.7457231303221308
Validation loss: 2.2982811874789166

Epoch: 282| Step: 0
Training loss: 1.8031466292698823
Validation loss: 2.3003869953201095

Epoch: 5| Step: 1
Training loss: 1.723308621357884
Validation loss: 2.3102919855311925

Epoch: 5| Step: 2
Training loss: 2.0175112392864065
Validation loss: 2.361144195395626

Epoch: 5| Step: 3
Training loss: 1.6253520877581225
Validation loss: 2.3052409235317763

Epoch: 5| Step: 4
Training loss: 1.622181869611704
Validation loss: 2.2797917183172007

Epoch: 5| Step: 5
Training loss: 1.7307242383570094
Validation loss: 2.283546938858832

Epoch: 5| Step: 6
Training loss: 1.9738546527081724
Validation loss: 2.335023229238003

Epoch: 5| Step: 7
Training loss: 1.464400811938655
Validation loss: 2.320936125619691

Epoch: 5| Step: 8
Training loss: 2.253999863503561
Validation loss: 2.348226062891084

Epoch: 5| Step: 9
Training loss: 1.237213685408269
Validation loss: 2.316195015056393

Epoch: 5| Step: 10
Training loss: 2.0864723462837076
Validation loss: 2.29012880566433

Epoch: 283| Step: 0
Training loss: 1.6581655976594962
Validation loss: 2.3117357957412503

Epoch: 5| Step: 1
Training loss: 1.4954276332557626
Validation loss: 2.2796579520941176

Epoch: 5| Step: 2
Training loss: 1.4849525532704664
Validation loss: 2.3345810850858677

Epoch: 5| Step: 3
Training loss: 2.09350482017558
Validation loss: 2.2549582532685455

Epoch: 5| Step: 4
Training loss: 2.0890363327818444
Validation loss: 2.3021560272898562

Epoch: 5| Step: 5
Training loss: 1.758467895396969
Validation loss: 2.2668570094141076

Epoch: 5| Step: 6
Training loss: 1.9525232227228992
Validation loss: 2.297311978031415

Epoch: 5| Step: 7
Training loss: 1.6674991277094766
Validation loss: 2.290767133105229

Epoch: 5| Step: 8
Training loss: 2.134344535822465
Validation loss: 2.284675917177124

Epoch: 5| Step: 9
Training loss: 2.1652183338047997
Validation loss: 2.3001421044078216

Epoch: 5| Step: 10
Training loss: 1.2602050015029254
Validation loss: 2.337729211071335

Epoch: 284| Step: 0
Training loss: 1.6333402665957741
Validation loss: 2.3514975305549837

Epoch: 5| Step: 1
Training loss: 1.8885826239656993
Validation loss: 2.3396373189808806

Epoch: 5| Step: 2
Training loss: 1.8452720178981314
Validation loss: 2.277617833917872

Epoch: 5| Step: 3
Training loss: 2.1500508856850704
Validation loss: 2.3238332937378097

Epoch: 5| Step: 4
Training loss: 1.5779773907510322
Validation loss: 2.38199817682928

Epoch: 5| Step: 5
Training loss: 1.5107499204411818
Validation loss: 2.318127708382273

Epoch: 5| Step: 6
Training loss: 1.6008108468621896
Validation loss: 2.3292360090482878

Epoch: 5| Step: 7
Training loss: 1.4570761666009397
Validation loss: 2.3117548066986386

Epoch: 5| Step: 8
Training loss: 1.7667318604994042
Validation loss: 2.3856740052280068

Epoch: 5| Step: 9
Training loss: 1.261846482746815
Validation loss: 2.308953599840621

Epoch: 5| Step: 10
Training loss: 2.761774691132511
Validation loss: 2.3221883700323054

Epoch: 285| Step: 0
Training loss: 1.791533650036713
Validation loss: 2.308534317052506

Epoch: 5| Step: 1
Training loss: 1.3631653832108022
Validation loss: 2.3341608323429677

Epoch: 5| Step: 2
Training loss: 1.7447223099165963
Validation loss: 2.2956192354127363

Epoch: 5| Step: 3
Training loss: 1.746242508322634
Validation loss: 2.2719133293864746

Epoch: 5| Step: 4
Training loss: 2.3068554008682765
Validation loss: 2.275937604835504

Epoch: 5| Step: 5
Training loss: 2.121557364194202
Validation loss: 2.326331884618056

Epoch: 5| Step: 6
Training loss: 1.4252544945453782
Validation loss: 2.3463840632720165

Epoch: 5| Step: 7
Training loss: 1.9714951525673807
Validation loss: 2.33370261595523

Epoch: 5| Step: 8
Training loss: 1.9261015031871591
Validation loss: 2.2938400111185713

Epoch: 5| Step: 9
Training loss: 1.694465249703396
Validation loss: 2.309756906122645

Epoch: 5| Step: 10
Training loss: 1.7066432765137691
Validation loss: 2.3830307942386777

Epoch: 286| Step: 0
Training loss: 1.0388983116357229
Validation loss: 2.2960437768731548

Epoch: 5| Step: 1
Training loss: 1.833069594515217
Validation loss: 2.322578639734734

Epoch: 5| Step: 2
Training loss: 1.7195037576157937
Validation loss: 2.300203121163456

Epoch: 5| Step: 3
Training loss: 1.5085559652566023
Validation loss: 2.3084825874492867

Epoch: 5| Step: 4
Training loss: 1.6362475169769868
Validation loss: 2.3601807770319168

Epoch: 5| Step: 5
Training loss: 1.6686840087186576
Validation loss: 2.308187599449161

Epoch: 5| Step: 6
Training loss: 2.478302738314679
Validation loss: 2.366382699378385

Epoch: 5| Step: 7
Training loss: 1.9052700588210048
Validation loss: 2.344121852895647

Epoch: 5| Step: 8
Training loss: 1.9695667207664378
Validation loss: 2.301528596743561

Epoch: 5| Step: 9
Training loss: 1.9948010822070612
Validation loss: 2.2943253302502655

Epoch: 5| Step: 10
Training loss: 1.8100196045925578
Validation loss: 2.261355596406913

Epoch: 287| Step: 0
Training loss: 2.529281321591899
Validation loss: 2.311266074636517

Epoch: 5| Step: 1
Training loss: 1.7349127545806071
Validation loss: 2.325653892179081

Epoch: 5| Step: 2
Training loss: 1.6714108972697908
Validation loss: 2.3005663316303187

Epoch: 5| Step: 3
Training loss: 1.941867950004301
Validation loss: 2.3300166406855403

Epoch: 5| Step: 4
Training loss: 1.7304305853843835
Validation loss: 2.279995675558722

Epoch: 5| Step: 5
Training loss: 1.4948787685984428
Validation loss: 2.309762828637199

Epoch: 5| Step: 6
Training loss: 1.5030254212067815
Validation loss: 2.3258044954952513

Epoch: 5| Step: 7
Training loss: 1.7192410547851102
Validation loss: 2.3368665396742783

Epoch: 5| Step: 8
Training loss: 1.6498954075116852
Validation loss: 2.306241209227548

Epoch: 5| Step: 9
Training loss: 1.80810982015747
Validation loss: 2.323306153985691

Epoch: 5| Step: 10
Training loss: 1.5710560570761656
Validation loss: 2.3904016803173582

Epoch: 288| Step: 0
Training loss: 1.692897077943609
Validation loss: 2.3062924894468475

Epoch: 5| Step: 1
Training loss: 1.8021390020632615
Validation loss: 2.289022179124949

Epoch: 5| Step: 2
Training loss: 1.5126745076038632
Validation loss: 2.304850174585665

Epoch: 5| Step: 3
Training loss: 1.8536982712630956
Validation loss: 2.31640081261991

Epoch: 5| Step: 4
Training loss: 1.7494981591148755
Validation loss: 2.327157164542378

Epoch: 5| Step: 5
Training loss: 2.2015471523554044
Validation loss: 2.310645839273625

Epoch: 5| Step: 6
Training loss: 1.9889647502508632
Validation loss: 2.310639678262194

Epoch: 5| Step: 7
Training loss: 1.8718090243167955
Validation loss: 2.3442955853262606

Epoch: 5| Step: 8
Training loss: 1.6249785055059416
Validation loss: 2.2749393194959437

Epoch: 5| Step: 9
Training loss: 1.5430489434757635
Validation loss: 2.3241638987835

Epoch: 5| Step: 10
Training loss: 1.624463359547531
Validation loss: 2.3154728761487418

Epoch: 289| Step: 0
Training loss: 1.5087977535651789
Validation loss: 2.265190048249075

Epoch: 5| Step: 1
Training loss: 1.5954825763665543
Validation loss: 2.300028882641166

Epoch: 5| Step: 2
Training loss: 1.7820099665045186
Validation loss: 2.3039043037784857

Epoch: 5| Step: 3
Training loss: 1.6879469668116218
Validation loss: 2.2780257997991185

Epoch: 5| Step: 4
Training loss: 1.7177816263928603
Validation loss: 2.3248944891396537

Epoch: 5| Step: 5
Training loss: 2.01882302355894
Validation loss: 2.3076039271972477

Epoch: 5| Step: 6
Training loss: 1.4740216226997491
Validation loss: 2.325320283566907

Epoch: 5| Step: 7
Training loss: 2.0855609682546152
Validation loss: 2.350317520285522

Epoch: 5| Step: 8
Training loss: 2.1504853077900803
Validation loss: 2.326540435040891

Epoch: 5| Step: 9
Training loss: 1.652353201043265
Validation loss: 2.3123692922061885

Epoch: 5| Step: 10
Training loss: 1.6385698070724775
Validation loss: 2.26979971854807

Epoch: 290| Step: 0
Training loss: 1.47736026264486
Validation loss: 2.321444782640859

Epoch: 5| Step: 1
Training loss: 1.4570088320891843
Validation loss: 2.2970598961329234

Epoch: 5| Step: 2
Training loss: 1.5187160786423695
Validation loss: 2.2853949640280655

Epoch: 5| Step: 3
Training loss: 2.0185060241473254
Validation loss: 2.310248045871519

Epoch: 5| Step: 4
Training loss: 2.276453802882126
Validation loss: 2.3249534647264296

Epoch: 5| Step: 5
Training loss: 2.6847660441559946
Validation loss: 2.3446838050005128

Epoch: 5| Step: 6
Training loss: 1.3809726350298082
Validation loss: 2.28156538044859

Epoch: 5| Step: 7
Training loss: 1.8090237792156576
Validation loss: 2.304636195192089

Epoch: 5| Step: 8
Training loss: 1.5992674223365437
Validation loss: 2.3286490870773786

Epoch: 5| Step: 9
Training loss: 1.549337719356831
Validation loss: 2.3425779183396913

Epoch: 5| Step: 10
Training loss: 1.1931580219125257
Validation loss: 2.338962131158847

Epoch: 291| Step: 0
Training loss: 1.636744824477194
Validation loss: 2.287549784675752

Epoch: 5| Step: 1
Training loss: 1.3921141634034058
Validation loss: 2.3680536069272464

Epoch: 5| Step: 2
Training loss: 1.5500655744894425
Validation loss: 2.3138028936340658

Epoch: 5| Step: 3
Training loss: 1.340386372560756
Validation loss: 2.3216753110821933

Epoch: 5| Step: 4
Training loss: 2.599221674255616
Validation loss: 2.332580039021635

Epoch: 5| Step: 5
Training loss: 1.795573883019497
Validation loss: 2.3271806344176205

Epoch: 5| Step: 6
Training loss: 1.4735494075604003
Validation loss: 2.3164988351250324

Epoch: 5| Step: 7
Training loss: 1.536877780708568
Validation loss: 2.311736275924272

Epoch: 5| Step: 8
Training loss: 1.9146304163852763
Validation loss: 2.3394851591943797

Epoch: 5| Step: 9
Training loss: 1.998461727803747
Validation loss: 2.3129325856755103

Epoch: 5| Step: 10
Training loss: 1.8406920856368065
Validation loss: 2.3336451852367612

Epoch: 292| Step: 0
Training loss: 1.6407122634205247
Validation loss: 2.306946040077696

Epoch: 5| Step: 1
Training loss: 2.0046353268691264
Validation loss: 2.2888468172794023

Epoch: 5| Step: 2
Training loss: 2.344156662311309
Validation loss: 2.260041215667612

Epoch: 5| Step: 3
Training loss: 1.7381907235908114
Validation loss: 2.2916781480190207

Epoch: 5| Step: 4
Training loss: 1.6260906374210506
Validation loss: 2.2873124432432315

Epoch: 5| Step: 5
Training loss: 1.404602569286914
Validation loss: 2.365486319180759

Epoch: 5| Step: 6
Training loss: 1.65343264509666
Validation loss: 2.3100638013538917

Epoch: 5| Step: 7
Training loss: 1.3743408530565657
Validation loss: 2.338550692491379

Epoch: 5| Step: 8
Training loss: 2.2660759838727955
Validation loss: 2.345633241155943

Epoch: 5| Step: 9
Training loss: 1.2571444425479998
Validation loss: 2.3120294883247787

Epoch: 5| Step: 10
Training loss: 2.063959356787567
Validation loss: 2.30062743575222

Epoch: 293| Step: 0
Training loss: 1.716064713625007
Validation loss: 2.313019026601088

Epoch: 5| Step: 1
Training loss: 1.9592050140967798
Validation loss: 2.3170059662606657

Epoch: 5| Step: 2
Training loss: 1.7378890720256743
Validation loss: 2.3367405667909242

Epoch: 5| Step: 3
Training loss: 2.0759001560346553
Validation loss: 2.327323522900051

Epoch: 5| Step: 4
Training loss: 1.8104695753202815
Validation loss: 2.2996844594655443

Epoch: 5| Step: 5
Training loss: 1.5338883539177635
Validation loss: 2.3300207765858714

Epoch: 5| Step: 6
Training loss: 1.4069277931316748
Validation loss: 2.329139342598954

Epoch: 5| Step: 7
Training loss: 1.487507456271934
Validation loss: 2.3355864934941066

Epoch: 5| Step: 8
Training loss: 1.512217673441928
Validation loss: 2.3106259227158383

Epoch: 5| Step: 9
Training loss: 2.2866849562503897
Validation loss: 2.2974087054137375

Epoch: 5| Step: 10
Training loss: 1.5910968013353186
Validation loss: 2.3578670425405712

Epoch: 294| Step: 0
Training loss: 1.507321687973661
Validation loss: 2.350374650512598

Epoch: 5| Step: 1
Training loss: 1.6811586546634016
Validation loss: 2.3497279344596307

Epoch: 5| Step: 2
Training loss: 1.8121405935753963
Validation loss: 2.358391283770443

Epoch: 5| Step: 3
Training loss: 1.8697503668882538
Validation loss: 2.3407132772328145

Epoch: 5| Step: 4
Training loss: 1.429798392909453
Validation loss: 2.325480579428872

Epoch: 5| Step: 5
Training loss: 1.3544507340054042
Validation loss: 2.321274012187404

Epoch: 5| Step: 6
Training loss: 1.9372891342103322
Validation loss: 2.3175766442330907

Epoch: 5| Step: 7
Training loss: 1.5776119342393178
Validation loss: 2.294756439885805

Epoch: 5| Step: 8
Training loss: 1.4485766692723772
Validation loss: 2.359365774950338

Epoch: 5| Step: 9
Training loss: 1.7914103465110365
Validation loss: 2.305999950574324

Epoch: 5| Step: 10
Training loss: 2.8767729558422457
Validation loss: 2.2901344095278717

Epoch: 295| Step: 0
Training loss: 1.7708805825904863
Validation loss: 2.3048268605056847

Epoch: 5| Step: 1
Training loss: 1.5030323214123524
Validation loss: 2.308361252125414

Epoch: 5| Step: 2
Training loss: 1.8231599336611353
Validation loss: 2.3455616447242473

Epoch: 5| Step: 3
Training loss: 1.8260472545839308
Validation loss: 2.3207413184720593

Epoch: 5| Step: 4
Training loss: 1.722458462594959
Validation loss: 2.3805450447581085

Epoch: 5| Step: 5
Training loss: 1.3561883165246373
Validation loss: 2.3435376022518453

Epoch: 5| Step: 6
Training loss: 1.688810122511726
Validation loss: 2.3028473847078406

Epoch: 5| Step: 7
Training loss: 1.3570189831782666
Validation loss: 2.323847928672971

Epoch: 5| Step: 8
Training loss: 2.2075044647897433
Validation loss: 2.325103260005013

Epoch: 5| Step: 9
Training loss: 1.8320687296272826
Validation loss: 2.3253348501606115

Epoch: 5| Step: 10
Training loss: 2.0791172727579883
Validation loss: 2.322163019289014

Epoch: 296| Step: 0
Training loss: 1.6431492596123531
Validation loss: 2.3206566167729297

Epoch: 5| Step: 1
Training loss: 1.8090326093957787
Validation loss: 2.3862647944415336

Epoch: 5| Step: 2
Training loss: 1.8043145789404966
Validation loss: 2.330741588517951

Epoch: 5| Step: 3
Training loss: 1.6221078665081952
Validation loss: 2.3097453401937558

Epoch: 5| Step: 4
Training loss: 1.8113968221418588
Validation loss: 2.34845963562499

Epoch: 5| Step: 5
Training loss: 1.7276583684822198
Validation loss: 2.3064646475627484

Epoch: 5| Step: 6
Training loss: 1.505946769107965
Validation loss: 2.3342483465283315

Epoch: 5| Step: 7
Training loss: 1.5824113554029273
Validation loss: 2.294070476738471

Epoch: 5| Step: 8
Training loss: 1.8917826741591592
Validation loss: 2.3222841711086937

Epoch: 5| Step: 9
Training loss: 1.5127778200092015
Validation loss: 2.2958979082231896

Epoch: 5| Step: 10
Training loss: 2.078515152410501
Validation loss: 2.328607871272818

Epoch: 297| Step: 0
Training loss: 1.7073085393841896
Validation loss: 2.291030616159751

Epoch: 5| Step: 1
Training loss: 1.7860764149917605
Validation loss: 2.3216902334652003

Epoch: 5| Step: 2
Training loss: 2.176923852460536
Validation loss: 2.325360702125586

Epoch: 5| Step: 3
Training loss: 1.6403114382507296
Validation loss: 2.2502442618150793

Epoch: 5| Step: 4
Training loss: 1.6333119481821172
Validation loss: 2.3389587257008677

Epoch: 5| Step: 5
Training loss: 2.0984760295088765
Validation loss: 2.3728518007941095

Epoch: 5| Step: 6
Training loss: 2.2552018962060507
Validation loss: 2.34940633032104

Epoch: 5| Step: 7
Training loss: 1.1987134633149694
Validation loss: 2.340790340271006

Epoch: 5| Step: 8
Training loss: 1.6012124027838204
Validation loss: 2.336818155235032

Epoch: 5| Step: 9
Training loss: 1.6320649402404266
Validation loss: 2.3606931300345515

Epoch: 5| Step: 10
Training loss: 1.0663267112944474
Validation loss: 2.289671806470518

Epoch: 298| Step: 0
Training loss: 1.1222879781332538
Validation loss: 2.3029780974849285

Epoch: 5| Step: 1
Training loss: 1.821204102198997
Validation loss: 2.33275645972645

Epoch: 5| Step: 2
Training loss: 2.12364579976255
Validation loss: 2.3042326931539945

Epoch: 5| Step: 3
Training loss: 1.541427885929391
Validation loss: 2.3237408916199978

Epoch: 5| Step: 4
Training loss: 1.9110287660901963
Validation loss: 2.3887175681557937

Epoch: 5| Step: 5
Training loss: 1.8969439373027162
Validation loss: 2.313036164993738

Epoch: 5| Step: 6
Training loss: 1.4414873798147387
Validation loss: 2.2965347085955403

Epoch: 5| Step: 7
Training loss: 1.9465449462138333
Validation loss: 2.3631060580177063

Epoch: 5| Step: 8
Training loss: 1.8213163563010173
Validation loss: 2.28172706765971

Epoch: 5| Step: 9
Training loss: 1.6458988257145473
Validation loss: 2.307723138315077

Epoch: 5| Step: 10
Training loss: 2.115128194833262
Validation loss: 2.372284074114525

Epoch: 299| Step: 0
Training loss: 1.7625695181048444
Validation loss: 2.2762272350519486

Epoch: 5| Step: 1
Training loss: 1.6134556267366766
Validation loss: 2.3373392779950777

Epoch: 5| Step: 2
Training loss: 1.7794268463267104
Validation loss: 2.3177317421922257

Epoch: 5| Step: 3
Training loss: 1.7302349268434885
Validation loss: 2.329028293293608

Epoch: 5| Step: 4
Training loss: 1.3766315057542424
Validation loss: 2.3263290634711464

Epoch: 5| Step: 5
Training loss: 1.9467930808673877
Validation loss: 2.277097734153699

Epoch: 5| Step: 6
Training loss: 1.207223327563262
Validation loss: 2.3363489138592195

Epoch: 5| Step: 7
Training loss: 2.3432963631627075
Validation loss: 2.3325540890200345

Epoch: 5| Step: 8
Training loss: 1.4632957315212067
Validation loss: 2.3151027241526365

Epoch: 5| Step: 9
Training loss: 1.9529319972999266
Validation loss: 2.3541351680697464

Epoch: 5| Step: 10
Training loss: 1.699881729050945
Validation loss: 2.311186751541329

Epoch: 300| Step: 0
Training loss: 1.3812738252544088
Validation loss: 2.3510712555522577

Epoch: 5| Step: 1
Training loss: 2.256404873506977
Validation loss: 2.293983186019321

Epoch: 5| Step: 2
Training loss: 1.5460936759806072
Validation loss: 2.2842454021756455

Epoch: 5| Step: 3
Training loss: 1.483461359835462
Validation loss: 2.2799666617659557

Epoch: 5| Step: 4
Training loss: 1.7817114516726564
Validation loss: 2.237295459001322

Epoch: 5| Step: 5
Training loss: 1.3004157208593357
Validation loss: 2.330484697907101

Epoch: 5| Step: 6
Training loss: 1.4517671537310464
Validation loss: 2.297191790840427

Epoch: 5| Step: 7
Training loss: 1.8713827208681466
Validation loss: 2.3056011910371264

Epoch: 5| Step: 8
Training loss: 1.8835062988435167
Validation loss: 2.3166655803910112

Epoch: 5| Step: 9
Training loss: 2.1377070231877155
Validation loss: 2.323213409786436

Epoch: 5| Step: 10
Training loss: 1.5297451020131356
Validation loss: 2.29134155905764

Epoch: 301| Step: 0
Training loss: 1.4523283712917965
Validation loss: 2.2895758979628336

Epoch: 5| Step: 1
Training loss: 1.377237623327029
Validation loss: 2.2983804807907764

Epoch: 5| Step: 2
Training loss: 1.6185522540463033
Validation loss: 2.34868557505549

Epoch: 5| Step: 3
Training loss: 1.7057772641765658
Validation loss: 2.341345119160403

Epoch: 5| Step: 4
Training loss: 1.651819745747891
Validation loss: 2.362620019780407

Epoch: 5| Step: 5
Training loss: 1.9323226912510703
Validation loss: 2.3459207918214275

Epoch: 5| Step: 6
Training loss: 1.7507240977187146
Validation loss: 2.249093402895649

Epoch: 5| Step: 7
Training loss: 2.7477746108796524
Validation loss: 2.351174653951755

Epoch: 5| Step: 8
Training loss: 1.1246340474333694
Validation loss: 2.3399685407609283

Epoch: 5| Step: 9
Training loss: 1.1349705102425254
Validation loss: 2.3159647846032287

Epoch: 5| Step: 10
Training loss: 1.8713078704834816
Validation loss: 2.334493912821118

Epoch: 302| Step: 0
Training loss: 1.228465020088134
Validation loss: 2.364340226809071

Epoch: 5| Step: 1
Training loss: 1.4910693547974354
Validation loss: 2.3103488776987913

Epoch: 5| Step: 2
Training loss: 2.101662332085121
Validation loss: 2.33693320212337

Epoch: 5| Step: 3
Training loss: 1.8676769301467055
Validation loss: 2.3317839368252797

Epoch: 5| Step: 4
Training loss: 1.3504092638110425
Validation loss: 2.316619950067877

Epoch: 5| Step: 5
Training loss: 1.4354048678167433
Validation loss: 2.3207557641252587

Epoch: 5| Step: 6
Training loss: 1.6403886170621833
Validation loss: 2.3583152285329185

Epoch: 5| Step: 7
Training loss: 1.7163320699852458
Validation loss: 2.301260672056794

Epoch: 5| Step: 8
Training loss: 1.4140253220196823
Validation loss: 2.2811433331989823

Epoch: 5| Step: 9
Training loss: 2.3008732672070504
Validation loss: 2.283997213638336

Epoch: 5| Step: 10
Training loss: 1.935568615957773
Validation loss: 2.316484516756058

Epoch: 303| Step: 0
Training loss: 1.511127681656906
Validation loss: 2.3099141117701842

Epoch: 5| Step: 1
Training loss: 2.3907236315756917
Validation loss: 2.312610184589562

Epoch: 5| Step: 2
Training loss: 1.5478094341910837
Validation loss: 2.338209652708981

Epoch: 5| Step: 3
Training loss: 1.3273993360927268
Validation loss: 2.307412110327611

Epoch: 5| Step: 4
Training loss: 2.102266555327182
Validation loss: 2.3024291472606317

Epoch: 5| Step: 5
Training loss: 1.8123583244989427
Validation loss: 2.325163329552757

Epoch: 5| Step: 6
Training loss: 1.848768935554723
Validation loss: 2.3010586041223795

Epoch: 5| Step: 7
Training loss: 1.6372754008474613
Validation loss: 2.2934637464612995

Epoch: 5| Step: 8
Training loss: 1.4584664238643943
Validation loss: 2.314530684677009

Epoch: 5| Step: 9
Training loss: 1.7191213726759054
Validation loss: 2.289616373679875

Epoch: 5| Step: 10
Training loss: 1.1009225271410343
Validation loss: 2.3161694171925618

Epoch: 304| Step: 0
Training loss: 1.4837135849093914
Validation loss: 2.333764059184136

Epoch: 5| Step: 1
Training loss: 1.6577295856073158
Validation loss: 2.311291527707541

Epoch: 5| Step: 2
Training loss: 1.6891704344868177
Validation loss: 2.335495177673437

Epoch: 5| Step: 3
Training loss: 1.4922874377272985
Validation loss: 2.3036694029392004

Epoch: 5| Step: 4
Training loss: 1.577388024806973
Validation loss: 2.324906790729854

Epoch: 5| Step: 5
Training loss: 2.51034066703852
Validation loss: 2.319568179184071

Epoch: 5| Step: 6
Training loss: 1.454984152402797
Validation loss: 2.3024076943119938

Epoch: 5| Step: 7
Training loss: 1.6154923700018455
Validation loss: 2.3487090819433534

Epoch: 5| Step: 8
Training loss: 1.6345567649583461
Validation loss: 2.296136705193775

Epoch: 5| Step: 9
Training loss: 1.7712003738892255
Validation loss: 2.313684477766599

Epoch: 5| Step: 10
Training loss: 1.4531141711416067
Validation loss: 2.33333233827432

Epoch: 305| Step: 0
Training loss: 2.0211236751716495
Validation loss: 2.2982682804555066

Epoch: 5| Step: 1
Training loss: 1.8199125841128347
Validation loss: 2.309971847270291

Epoch: 5| Step: 2
Training loss: 1.5425637015322615
Validation loss: 2.295811329624077

Epoch: 5| Step: 3
Training loss: 2.1614312105124003
Validation loss: 2.347906857177142

Epoch: 5| Step: 4
Training loss: 1.4531168783637705
Validation loss: 2.3463904194178116

Epoch: 5| Step: 5
Training loss: 2.1320828597551778
Validation loss: 2.345896106255229

Epoch: 5| Step: 6
Training loss: 1.9626342606024443
Validation loss: 2.3624822600393616

Epoch: 5| Step: 7
Training loss: 1.308185206165538
Validation loss: 2.280849840301518

Epoch: 5| Step: 8
Training loss: 1.3930407340234383
Validation loss: 2.2843340340833853

Epoch: 5| Step: 9
Training loss: 1.2774756593867542
Validation loss: 2.303348060957533

Epoch: 5| Step: 10
Training loss: 1.5775877538536514
Validation loss: 2.324094293849919

Epoch: 306| Step: 0
Training loss: 1.185946351672927
Validation loss: 2.29767884159747

Epoch: 5| Step: 1
Training loss: 1.8965244780051238
Validation loss: 2.317544745303681

Epoch: 5| Step: 2
Training loss: 2.223291611325257
Validation loss: 2.368424376090989

Epoch: 5| Step: 3
Training loss: 1.642013688693679
Validation loss: 2.3486404795062414

Epoch: 5| Step: 4
Training loss: 1.4820535275037237
Validation loss: 2.3166707759096865

Epoch: 5| Step: 5
Training loss: 1.3684457275254795
Validation loss: 2.295228690830033

Epoch: 5| Step: 6
Training loss: 1.6936671275454993
Validation loss: 2.2764887269440344

Epoch: 5| Step: 7
Training loss: 1.4328846022041142
Validation loss: 2.380090018321316

Epoch: 5| Step: 8
Training loss: 1.8456247787397946
Validation loss: 2.29077548227605

Epoch: 5| Step: 9
Training loss: 1.8305521445788473
Validation loss: 2.3753160159576843

Epoch: 5| Step: 10
Training loss: 1.3802640891659337
Validation loss: 2.305734556245334

Epoch: 307| Step: 0
Training loss: 1.497374462030462
Validation loss: 2.3264450285232474

Epoch: 5| Step: 1
Training loss: 2.17962657337424
Validation loss: 2.34266195876783

Epoch: 5| Step: 2
Training loss: 1.835339517808594
Validation loss: 2.3053026627321542

Epoch: 5| Step: 3
Training loss: 1.9020372962463843
Validation loss: 2.38886367306474

Epoch: 5| Step: 4
Training loss: 1.1934490763264363
Validation loss: 2.316154499087045

Epoch: 5| Step: 5
Training loss: 1.3613818471370531
Validation loss: 2.3235378625778513

Epoch: 5| Step: 6
Training loss: 2.064630159783052
Validation loss: 2.335729591049863

Epoch: 5| Step: 7
Training loss: 2.0254959770620338
Validation loss: 2.3371012422083317

Epoch: 5| Step: 8
Training loss: 1.5749288240123602
Validation loss: 2.3274357142778226

Epoch: 5| Step: 9
Training loss: 1.2469503872293255
Validation loss: 2.334451470317738

Epoch: 5| Step: 10
Training loss: 1.4863382306551165
Validation loss: 2.3213323635632626

Epoch: 308| Step: 0
Training loss: 1.7724922786915718
Validation loss: 2.3225268818615663

Epoch: 5| Step: 1
Training loss: 1.5657560373622632
Validation loss: 2.3744268303223808

Epoch: 5| Step: 2
Training loss: 1.3169374384695165
Validation loss: 2.3034923471165345

Epoch: 5| Step: 3
Training loss: 2.1113893286544196
Validation loss: 2.311891277783442

Epoch: 5| Step: 4
Training loss: 1.6486421430938576
Validation loss: 2.37011133792187

Epoch: 5| Step: 5
Training loss: 1.885374233829166
Validation loss: 2.3697112327501193

Epoch: 5| Step: 6
Training loss: 1.63476008296925
Validation loss: 2.369364145455929

Epoch: 5| Step: 7
Training loss: 1.3672864169713093
Validation loss: 2.357660077931671

Epoch: 5| Step: 8
Training loss: 1.8916878353172417
Validation loss: 2.328160638805522

Epoch: 5| Step: 9
Training loss: 1.806046143746013
Validation loss: 2.386324900411435

Epoch: 5| Step: 10
Training loss: 1.531533273458122
Validation loss: 2.318972506189104

Epoch: 309| Step: 0
Training loss: 1.4717874164804858
Validation loss: 2.299007055465484

Epoch: 5| Step: 1
Training loss: 1.5003733964927526
Validation loss: 2.3035618489504066

Epoch: 5| Step: 2
Training loss: 1.832443093408981
Validation loss: 2.296765882165761

Epoch: 5| Step: 3
Training loss: 1.7857778456139213
Validation loss: 2.3437316062506275

Epoch: 5| Step: 4
Training loss: 1.6505155798203592
Validation loss: 2.332954929434958

Epoch: 5| Step: 5
Training loss: 1.4558101988629992
Validation loss: 2.28382782054407

Epoch: 5| Step: 6
Training loss: 1.9719020497058248
Validation loss: 2.3005071242336483

Epoch: 5| Step: 7
Training loss: 1.5227138267658427
Validation loss: 2.29510475814138

Epoch: 5| Step: 8
Training loss: 1.975583403166627
Validation loss: 2.3330122661608588

Epoch: 5| Step: 9
Training loss: 1.597544398041566
Validation loss: 2.271672869140058

Epoch: 5| Step: 10
Training loss: 2.056369107863634
Validation loss: 2.355102855659673

Epoch: 310| Step: 0
Training loss: 1.5943002685833774
Validation loss: 2.3525710274357077

Epoch: 5| Step: 1
Training loss: 1.6139314463496384
Validation loss: 2.3551407727192997

Epoch: 5| Step: 2
Training loss: 1.6785352436328025
Validation loss: 2.383332107188521

Epoch: 5| Step: 3
Training loss: 1.67966202117758
Validation loss: 2.3231082299987866

Epoch: 5| Step: 4
Training loss: 2.0830168547257446
Validation loss: 2.347823727342928

Epoch: 5| Step: 5
Training loss: 1.7852887995485713
Validation loss: 2.287003342992586

Epoch: 5| Step: 6
Training loss: 1.5656007136671246
Validation loss: 2.3180956611005024

Epoch: 5| Step: 7
Training loss: 1.2828945212679332
Validation loss: 2.3540055534456967

Epoch: 5| Step: 8
Training loss: 1.411576884265886
Validation loss: 2.3179105306604177

Epoch: 5| Step: 9
Training loss: 1.8167701930840785
Validation loss: 2.291466850973933

Epoch: 5| Step: 10
Training loss: 1.601982471017745
Validation loss: 2.255334026800568

Epoch: 311| Step: 0
Training loss: 1.3772696056954357
Validation loss: 2.3452082286233615

Epoch: 5| Step: 1
Training loss: 1.252876881224746
Validation loss: 2.3440995752107954

Epoch: 5| Step: 2
Training loss: 2.1300414252394444
Validation loss: 2.3285063206743097

Epoch: 5| Step: 3
Training loss: 1.36192521036417
Validation loss: 2.329047759693093

Epoch: 5| Step: 4
Training loss: 1.6820679585747402
Validation loss: 2.3190652519604718

Epoch: 5| Step: 5
Training loss: 1.4704310759547015
Validation loss: 2.3293392012783114

Epoch: 5| Step: 6
Training loss: 1.0660062605690113
Validation loss: 2.3372090538559043

Epoch: 5| Step: 7
Training loss: 1.3890754124113138
Validation loss: 2.315366208716565

Epoch: 5| Step: 8
Training loss: 1.6243044758568808
Validation loss: 2.3566545768585843

Epoch: 5| Step: 9
Training loss: 2.048336759253488
Validation loss: 2.347527306920426

Epoch: 5| Step: 10
Training loss: 2.506761942872203
Validation loss: 2.332057928062347

Epoch: 312| Step: 0
Training loss: 1.7283716174121746
Validation loss: 2.344245737896371

Epoch: 5| Step: 1
Training loss: 2.1062044404759397
Validation loss: 2.305535581908044

Epoch: 5| Step: 2
Training loss: 1.5722307473810115
Validation loss: 2.3496666435533453

Epoch: 5| Step: 3
Training loss: 1.6881027558042943
Validation loss: 2.3150914794887245

Epoch: 5| Step: 4
Training loss: 0.9165447797080029
Validation loss: 2.304530853348453

Epoch: 5| Step: 5
Training loss: 1.3530648762161694
Validation loss: 2.344976555698144

Epoch: 5| Step: 6
Training loss: 1.5542389495785662
Validation loss: 2.2970453974423766

Epoch: 5| Step: 7
Training loss: 1.8092708103047348
Validation loss: 2.3208375117710833

Epoch: 5| Step: 8
Training loss: 1.5807402441232616
Validation loss: 2.3189614444583975

Epoch: 5| Step: 9
Training loss: 1.8699019106469954
Validation loss: 2.3342982690666814

Epoch: 5| Step: 10
Training loss: 1.5872359198845345
Validation loss: 2.2921687962279322

Epoch: 313| Step: 0
Training loss: 1.5747122547151737
Validation loss: 2.3230130064219234

Epoch: 5| Step: 1
Training loss: 1.5215824668515918
Validation loss: 2.363078209482233

Epoch: 5| Step: 2
Training loss: 2.3999096456049904
Validation loss: 2.3343863804665497

Epoch: 5| Step: 3
Training loss: 2.0139297335052637
Validation loss: 2.306997412420751

Epoch: 5| Step: 4
Training loss: 1.4403652991435216
Validation loss: 2.312418139426983

Epoch: 5| Step: 5
Training loss: 1.376859404708915
Validation loss: 2.274052646551036

Epoch: 5| Step: 6
Training loss: 1.6555039506944011
Validation loss: 2.3545754074483662

Epoch: 5| Step: 7
Training loss: 1.215011879427256
Validation loss: 2.363887009072989

Epoch: 5| Step: 8
Training loss: 1.3113232287240797
Validation loss: 2.307850058592517

Epoch: 5| Step: 9
Training loss: 1.603737893538297
Validation loss: 2.331604211053719

Epoch: 5| Step: 10
Training loss: 1.6759913030548963
Validation loss: 2.345423645445258

Epoch: 314| Step: 0
Training loss: 1.6167193486127873
Validation loss: 2.3685792286348937

Epoch: 5| Step: 1
Training loss: 1.7087448213801573
Validation loss: 2.3227064215137374

Epoch: 5| Step: 2
Training loss: 1.4758004134283431
Validation loss: 2.3346925093464788

Epoch: 5| Step: 3
Training loss: 1.3935802219460078
Validation loss: 2.345029702248063

Epoch: 5| Step: 4
Training loss: 1.294071614561061
Validation loss: 2.346961022443899

Epoch: 5| Step: 5
Training loss: 1.5373700901135776
Validation loss: 2.355048620347695

Epoch: 5| Step: 6
Training loss: 1.7770326446900713
Validation loss: 2.362683363951507

Epoch: 5| Step: 7
Training loss: 1.3802879694390537
Validation loss: 2.3540992652754027

Epoch: 5| Step: 8
Training loss: 1.6854980744583143
Validation loss: 2.322073774477755

Epoch: 5| Step: 9
Training loss: 2.098106407012691
Validation loss: 2.331145878136208

Epoch: 5| Step: 10
Training loss: 2.147764343228034
Validation loss: 2.3564069246807895

Epoch: 315| Step: 0
Training loss: 0.9495757573656738
Validation loss: 2.2840501964914868

Epoch: 5| Step: 1
Training loss: 1.5543155704513827
Validation loss: 2.339439763562383

Epoch: 5| Step: 2
Training loss: 1.6087478600927199
Validation loss: 2.305858018788799

Epoch: 5| Step: 3
Training loss: 1.775013496455071
Validation loss: 2.308193841420522

Epoch: 5| Step: 4
Training loss: 1.7125474853614775
Validation loss: 2.3465048030621625

Epoch: 5| Step: 5
Training loss: 1.7822104424570637
Validation loss: 2.3396171418868343

Epoch: 5| Step: 6
Training loss: 1.4268996777198808
Validation loss: 2.3509594113252286

Epoch: 5| Step: 7
Training loss: 1.6262693582565737
Validation loss: 2.3345917713763997

Epoch: 5| Step: 8
Training loss: 1.3659240988704762
Validation loss: 2.291369675290968

Epoch: 5| Step: 9
Training loss: 2.541551326782027
Validation loss: 2.302486157441768

Epoch: 5| Step: 10
Training loss: 1.2119921613760793
Validation loss: 2.3226956998562867

Epoch: 316| Step: 0
Training loss: 1.8060552525057918
Validation loss: 2.3428515105997842

Epoch: 5| Step: 1
Training loss: 1.6934140030476226
Validation loss: 2.308887957174315

Epoch: 5| Step: 2
Training loss: 1.973841305554152
Validation loss: 2.3742782810930656

Epoch: 5| Step: 3
Training loss: 1.6920157869382575
Validation loss: 2.318188698516957

Epoch: 5| Step: 4
Training loss: 1.338880097864678
Validation loss: 2.347232950452268

Epoch: 5| Step: 5
Training loss: 1.504810012155593
Validation loss: 2.273271224257546

Epoch: 5| Step: 6
Training loss: 1.378761219037807
Validation loss: 2.320209424510313

Epoch: 5| Step: 7
Training loss: 1.780131273143819
Validation loss: 2.33238230352098

Epoch: 5| Step: 8
Training loss: 1.1450347834305332
Validation loss: 2.354885811116228

Epoch: 5| Step: 9
Training loss: 1.5638659800599497
Validation loss: 2.3348921199737207

Epoch: 5| Step: 10
Training loss: 1.7889396925176002
Validation loss: 2.3234480648207585

Epoch: 317| Step: 0
Training loss: 1.6174065630426198
Validation loss: 2.320417007176011

Epoch: 5| Step: 1
Training loss: 1.3217796886523345
Validation loss: 2.342001098254739

Epoch: 5| Step: 2
Training loss: 1.9872946699110232
Validation loss: 2.3258130148451026

Epoch: 5| Step: 3
Training loss: 2.1636440271864026
Validation loss: 2.3098707709077853

Epoch: 5| Step: 4
Training loss: 1.4826858546818695
Validation loss: 2.3286714740407146

Epoch: 5| Step: 5
Training loss: 1.711998318885263
Validation loss: 2.315680798717454

Epoch: 5| Step: 6
Training loss: 1.5001346209833963
Validation loss: 2.3084404157737253

Epoch: 5| Step: 7
Training loss: 1.2504534852453357
Validation loss: 2.3492607102339247

Epoch: 5| Step: 8
Training loss: 1.7078044196633095
Validation loss: 2.3013196949179067

Epoch: 5| Step: 9
Training loss: 1.6251015264633397
Validation loss: 2.3148503729802083

Epoch: 5| Step: 10
Training loss: 1.7385110424613737
Validation loss: 2.320094230105427

Epoch: 318| Step: 0
Training loss: 1.8476317970641725
Validation loss: 2.3077199122705463

Epoch: 5| Step: 1
Training loss: 1.1970428209700357
Validation loss: 2.3564970939956362

Epoch: 5| Step: 2
Training loss: 1.6955230160284112
Validation loss: 2.3077335673841035

Epoch: 5| Step: 3
Training loss: 1.3477838870433592
Validation loss: 2.3214277405609445

Epoch: 5| Step: 4
Training loss: 1.459983065128091
Validation loss: 2.3358633136811444

Epoch: 5| Step: 5
Training loss: 1.3345392952397244
Validation loss: 2.383230354605095

Epoch: 5| Step: 6
Training loss: 1.3177235970599435
Validation loss: 2.3860675614958273

Epoch: 5| Step: 7
Training loss: 2.217793540577921
Validation loss: 2.3680275011115417

Epoch: 5| Step: 8
Training loss: 1.97718300710511
Validation loss: 2.347314758945886

Epoch: 5| Step: 9
Training loss: 1.7470188634385735
Validation loss: 2.324445996817511

Epoch: 5| Step: 10
Training loss: 1.5578792148335037
Validation loss: 2.3562156899532463

Epoch: 319| Step: 0
Training loss: 1.5081404097173323
Validation loss: 2.3327735267431384

Epoch: 5| Step: 1
Training loss: 1.4940067405803958
Validation loss: 2.326278447547018

Epoch: 5| Step: 2
Training loss: 1.5529890895148297
Validation loss: 2.33900555990381

Epoch: 5| Step: 3
Training loss: 1.3625051480817216
Validation loss: 2.3154832597943624

Epoch: 5| Step: 4
Training loss: 1.9339549334185682
Validation loss: 2.3355137147741916

Epoch: 5| Step: 5
Training loss: 2.281570621063781
Validation loss: 2.31296120534031

Epoch: 5| Step: 6
Training loss: 1.2642449283871526
Validation loss: 2.3233719503778754

Epoch: 5| Step: 7
Training loss: 1.6238264100829891
Validation loss: 2.3141262108958993

Epoch: 5| Step: 8
Training loss: 1.2690924722513328
Validation loss: 2.340320114720515

Epoch: 5| Step: 9
Training loss: 1.7967313626141346
Validation loss: 2.344786587439216

Epoch: 5| Step: 10
Training loss: 1.505802692776432
Validation loss: 2.316928376029789

Epoch: 320| Step: 0
Training loss: 1.7251202527576475
Validation loss: 2.282062870608152

Epoch: 5| Step: 1
Training loss: 1.3251475899747014
Validation loss: 2.3186445945657046

Epoch: 5| Step: 2
Training loss: 1.6891514503284204
Validation loss: 2.3274403096778618

Epoch: 5| Step: 3
Training loss: 1.6887012727090296
Validation loss: 2.2753216197787967

Epoch: 5| Step: 4
Training loss: 1.5699679627764023
Validation loss: 2.3500305556049956

Epoch: 5| Step: 5
Training loss: 1.4543725677719073
Validation loss: 2.3344978392778684

Epoch: 5| Step: 6
Training loss: 1.5925491895519517
Validation loss: 2.343797695535991

Epoch: 5| Step: 7
Training loss: 1.4899626117854208
Validation loss: 2.3349790555905234

Epoch: 5| Step: 8
Training loss: 1.2341442133844152
Validation loss: 2.291519472050581

Epoch: 5| Step: 9
Training loss: 1.674478731605232
Validation loss: 2.338801881834653

Epoch: 5| Step: 10
Training loss: 2.286071594018283
Validation loss: 2.313983454725939

Epoch: 321| Step: 0
Training loss: 2.259968187226402
Validation loss: 2.303824828472445

Epoch: 5| Step: 1
Training loss: 1.2519513158442954
Validation loss: 2.364762039301726

Epoch: 5| Step: 2
Training loss: 1.695441948655387
Validation loss: 2.3728233632871865

Epoch: 5| Step: 3
Training loss: 1.7768421848740872
Validation loss: 2.325884081695133

Epoch: 5| Step: 4
Training loss: 1.7017241149879418
Validation loss: 2.331794414399973

Epoch: 5| Step: 5
Training loss: 1.514804578710445
Validation loss: 2.342045848769687

Epoch: 5| Step: 6
Training loss: 1.3384936679096089
Validation loss: 2.2907438603513657

Epoch: 5| Step: 7
Training loss: 1.4978552425914826
Validation loss: 2.3272826553963637

Epoch: 5| Step: 8
Training loss: 1.5463546494247318
Validation loss: 2.3975271036526085

Epoch: 5| Step: 9
Training loss: 1.475872706199137
Validation loss: 2.3411609823872053

Epoch: 5| Step: 10
Training loss: 1.439704034642865
Validation loss: 2.3345084029566534

Epoch: 322| Step: 0
Training loss: 1.8101726585569762
Validation loss: 2.3160272352623634

Epoch: 5| Step: 1
Training loss: 1.881458222788351
Validation loss: 2.338215152852267

Epoch: 5| Step: 2
Training loss: 1.3678320972763494
Validation loss: 2.2849811759994267

Epoch: 5| Step: 3
Training loss: 1.2224295409010908
Validation loss: 2.323690843765436

Epoch: 5| Step: 4
Training loss: 1.9572529619608428
Validation loss: 2.328136533532566

Epoch: 5| Step: 5
Training loss: 1.8042580229760683
Validation loss: 2.3386467134163293

Epoch: 5| Step: 6
Training loss: 1.8049156408066462
Validation loss: 2.286551795664023

Epoch: 5| Step: 7
Training loss: 1.3842379878940276
Validation loss: 2.2786207664036806

Epoch: 5| Step: 8
Training loss: 0.9988830408090846
Validation loss: 2.3325727335720026

Epoch: 5| Step: 9
Training loss: 1.308365622605926
Validation loss: 2.3119255423309877

Epoch: 5| Step: 10
Training loss: 2.107467806424275
Validation loss: 2.346395140490635

Epoch: 323| Step: 0
Training loss: 1.4014894226143233
Validation loss: 2.331971988387744

Epoch: 5| Step: 1
Training loss: 1.7670116549562487
Validation loss: 2.309462410579163

Epoch: 5| Step: 2
Training loss: 1.8944725420792619
Validation loss: 2.3273948272647638

Epoch: 5| Step: 3
Training loss: 1.2958873067002663
Validation loss: 2.379215079461637

Epoch: 5| Step: 4
Training loss: 1.5550335829564308
Validation loss: 2.3352445548016467

Epoch: 5| Step: 5
Training loss: 2.0189245851214244
Validation loss: 2.300866262200108

Epoch: 5| Step: 6
Training loss: 1.2277433700304834
Validation loss: 2.3347488382266044

Epoch: 5| Step: 7
Training loss: 1.9867595852920292
Validation loss: 2.3434100401511384

Epoch: 5| Step: 8
Training loss: 1.4557705658932798
Validation loss: 2.2794309312121603

Epoch: 5| Step: 9
Training loss: 1.3920304129500918
Validation loss: 2.313986453783987

Epoch: 5| Step: 10
Training loss: 1.271845518703089
Validation loss: 2.367514792721817

Epoch: 324| Step: 0
Training loss: 1.8766728250437503
Validation loss: 2.3269823938307406

Epoch: 5| Step: 1
Training loss: 1.661529762701755
Validation loss: 2.324128164496197

Epoch: 5| Step: 2
Training loss: 1.3486933601372644
Validation loss: 2.3034770647787375

Epoch: 5| Step: 3
Training loss: 1.5216929301362707
Validation loss: 2.2827196330621873

Epoch: 5| Step: 4
Training loss: 1.250051783442771
Validation loss: 2.336775065977301

Epoch: 5| Step: 5
Training loss: 1.3471181043830853
Validation loss: 2.3386743212238446

Epoch: 5| Step: 6
Training loss: 1.5036629616273056
Validation loss: 2.3565156687809865

Epoch: 5| Step: 7
Training loss: 1.3830190385789263
Validation loss: 2.2838693539389996

Epoch: 5| Step: 8
Training loss: 2.0317194469544293
Validation loss: 2.2941275951809392

Epoch: 5| Step: 9
Training loss: 1.6428143380198175
Validation loss: 2.315048910502392

Epoch: 5| Step: 10
Training loss: 1.7285426595696585
Validation loss: 2.3575344402563285

Epoch: 325| Step: 0
Training loss: 1.6551053392244988
Validation loss: 2.3589007770234898

Epoch: 5| Step: 1
Training loss: 1.307073638283393
Validation loss: 2.3333638895322277

Epoch: 5| Step: 2
Training loss: 1.3971961281684284
Validation loss: 2.346727243744655

Epoch: 5| Step: 3
Training loss: 2.2103423810503395
Validation loss: 2.343102178702548

Epoch: 5| Step: 4
Training loss: 1.5255814553828506
Validation loss: 2.3464228494238584

Epoch: 5| Step: 5
Training loss: 2.0435640769639973
Validation loss: 2.335235370555959

Epoch: 5| Step: 6
Training loss: 1.549677458398082
Validation loss: 2.334546949903214

Epoch: 5| Step: 7
Training loss: 1.4640486123190712
Validation loss: 2.3713931191870246

Epoch: 5| Step: 8
Training loss: 1.6406600948394845
Validation loss: 2.3703768258668445

Epoch: 5| Step: 9
Training loss: 1.493492554382012
Validation loss: 2.33020925208328

Epoch: 5| Step: 10
Training loss: 1.1402599325318274
Validation loss: 2.3094222627090937

Epoch: 326| Step: 0
Training loss: 1.4037396382520948
Validation loss: 2.3637716824660213

Epoch: 5| Step: 1
Training loss: 1.4821770708399622
Validation loss: 2.2988989655281666

Epoch: 5| Step: 2
Training loss: 1.344351567304013
Validation loss: 2.3272261524120332

Epoch: 5| Step: 3
Training loss: 1.5712460452130907
Validation loss: 2.32472085180043

Epoch: 5| Step: 4
Training loss: 1.55147446673642
Validation loss: 2.3595762709567585

Epoch: 5| Step: 5
Training loss: 1.271052367715516
Validation loss: 2.3597154372378055

Epoch: 5| Step: 6
Training loss: 1.7988364750671426
Validation loss: 2.340375697469972

Epoch: 5| Step: 7
Training loss: 1.6301685446209113
Validation loss: 2.294391889568724

Epoch: 5| Step: 8
Training loss: 1.3763770230719863
Validation loss: 2.3717422994491715

Epoch: 5| Step: 9
Training loss: 2.301940729433791
Validation loss: 2.378535639224301

Epoch: 5| Step: 10
Training loss: 1.570560872187726
Validation loss: 2.306608593726764

Epoch: 327| Step: 0
Training loss: 1.3712304202049377
Validation loss: 2.3277814806720767

Epoch: 5| Step: 1
Training loss: 1.3300964085334763
Validation loss: 2.344357890389309

Epoch: 5| Step: 2
Training loss: 1.8469622157331278
Validation loss: 2.3424632915058448

Epoch: 5| Step: 3
Training loss: 1.8077004782902546
Validation loss: 2.31781730953322

Epoch: 5| Step: 4
Training loss: 2.1788717951739813
Validation loss: 2.342668352917756

Epoch: 5| Step: 5
Training loss: 1.2985811615389864
Validation loss: 2.3604636285552667

Epoch: 5| Step: 6
Training loss: 1.5118561122892473
Validation loss: 2.3399362437096958

Epoch: 5| Step: 7
Training loss: 1.4030630663008623
Validation loss: 2.3113756958201903

Epoch: 5| Step: 8
Training loss: 1.6735979275779949
Validation loss: 2.381567007813266

Epoch: 5| Step: 9
Training loss: 1.242451957526026
Validation loss: 2.2968555126210375

Epoch: 5| Step: 10
Training loss: 1.586380769766764
Validation loss: 2.371921729173169

Epoch: 328| Step: 0
Training loss: 1.545302622641074
Validation loss: 2.344358536669219

Epoch: 5| Step: 1
Training loss: 1.1799796039628958
Validation loss: 2.3194201972305954

Epoch: 5| Step: 2
Training loss: 1.5823523678247817
Validation loss: 2.3339837269458825

Epoch: 5| Step: 3
Training loss: 1.555640613788673
Validation loss: 2.3710718652096685

Epoch: 5| Step: 4
Training loss: 1.2973606165584697
Validation loss: 2.3869761304084745

Epoch: 5| Step: 5
Training loss: 1.3641428151470019
Validation loss: 2.343322193110111

Epoch: 5| Step: 6
Training loss: 1.9460803741644717
Validation loss: 2.3849059641585137

Epoch: 5| Step: 7
Training loss: 1.4996292927744077
Validation loss: 2.3520879262393253

Epoch: 5| Step: 8
Training loss: 2.0573298068474744
Validation loss: 2.371586534081776

Epoch: 5| Step: 9
Training loss: 1.3454737585450975
Validation loss: 2.3479892186848472

Epoch: 5| Step: 10
Training loss: 2.1112988776087676
Validation loss: 2.3644261403914393

Epoch: 329| Step: 0
Training loss: 1.1848670480885686
Validation loss: 2.3651380655749437

Epoch: 5| Step: 1
Training loss: 1.3375454868175625
Validation loss: 2.3295238427568328

Epoch: 5| Step: 2
Training loss: 1.6727455938461078
Validation loss: 2.3092112065534565

Epoch: 5| Step: 3
Training loss: 1.7083005746941509
Validation loss: 2.336726501912553

Epoch: 5| Step: 4
Training loss: 1.6334135418615128
Validation loss: 2.3651603456210135

Epoch: 5| Step: 5
Training loss: 1.0854946303724602
Validation loss: 2.3323092593882677

Epoch: 5| Step: 6
Training loss: 1.769496892128161
Validation loss: 2.3674706979677684

Epoch: 5| Step: 7
Training loss: 2.2044734210157406
Validation loss: 2.3190626121135263

Epoch: 5| Step: 8
Training loss: 1.8582528198089412
Validation loss: 2.363549690726663

Epoch: 5| Step: 9
Training loss: 1.3539343512381863
Validation loss: 2.3187322559898917

Epoch: 5| Step: 10
Training loss: 1.200371551610412
Validation loss: 2.3417734771700616

Epoch: 330| Step: 0
Training loss: 1.1830691443395822
Validation loss: 2.3512232423343287

Epoch: 5| Step: 1
Training loss: 1.2478803783271422
Validation loss: 2.3734424294650327

Epoch: 5| Step: 2
Training loss: 1.823325091429964
Validation loss: 2.328903976379712

Epoch: 5| Step: 3
Training loss: 1.1728597953564606
Validation loss: 2.3738839825571643

Epoch: 5| Step: 4
Training loss: 1.5817126294697532
Validation loss: 2.3977805675574237

Epoch: 5| Step: 5
Training loss: 1.9121255221284188
Validation loss: 2.4399903919081902

Epoch: 5| Step: 6
Training loss: 1.5045087127788235
Validation loss: 2.390312567432737

Epoch: 5| Step: 7
Training loss: 1.652728241179013
Validation loss: 2.327152385714087

Epoch: 5| Step: 8
Training loss: 1.6845605468466938
Validation loss: 2.2939628370220677

Epoch: 5| Step: 9
Training loss: 1.4108211397536736
Validation loss: 2.306510928384679

Epoch: 5| Step: 10
Training loss: 2.054874658219433
Validation loss: 2.3588863095693577

Epoch: 331| Step: 0
Training loss: 1.7030962320400422
Validation loss: 2.299164895782498

Epoch: 5| Step: 1
Training loss: 1.1582738330479578
Validation loss: 2.3348017676772232

Epoch: 5| Step: 2
Training loss: 1.5105813649148716
Validation loss: 2.3718447869858594

Epoch: 5| Step: 3
Training loss: 1.2384044212911722
Validation loss: 2.38347447165518

Epoch: 5| Step: 4
Training loss: 1.3975059773926353
Validation loss: 2.313031365857592

Epoch: 5| Step: 5
Training loss: 2.331702638920773
Validation loss: 2.3548346713429433

Epoch: 5| Step: 6
Training loss: 1.4162090721849356
Validation loss: 2.3541146404308386

Epoch: 5| Step: 7
Training loss: 1.4512166443769263
Validation loss: 2.2715796735971345

Epoch: 5| Step: 8
Training loss: 1.227190816518772
Validation loss: 2.347842843545464

Epoch: 5| Step: 9
Training loss: 1.8745112735860048
Validation loss: 2.2902076603679644

Epoch: 5| Step: 10
Training loss: 1.5646340102493788
Validation loss: 2.304822075976387

Epoch: 332| Step: 0
Training loss: 1.77322715822656
Validation loss: 2.3311681058560496

Epoch: 5| Step: 1
Training loss: 1.4244832858828649
Validation loss: 2.3283629663658894

Epoch: 5| Step: 2
Training loss: 1.608102758545114
Validation loss: 2.3858265416940143

Epoch: 5| Step: 3
Training loss: 1.056139702088582
Validation loss: 2.367023519871801

Epoch: 5| Step: 4
Training loss: 1.3581359302486435
Validation loss: 2.317842510930278

Epoch: 5| Step: 5
Training loss: 1.429115222564806
Validation loss: 2.34766875063677

Epoch: 5| Step: 6
Training loss: 1.7968877377265915
Validation loss: 2.3346074122663922

Epoch: 5| Step: 7
Training loss: 2.121850316124605
Validation loss: 2.3470479184451825

Epoch: 5| Step: 8
Training loss: 1.590730237196275
Validation loss: 2.4116303756331243

Epoch: 5| Step: 9
Training loss: 1.5101314757752708
Validation loss: 2.3552004527799975

Epoch: 5| Step: 10
Training loss: 1.2959592872482597
Validation loss: 2.310386365809443

Epoch: 333| Step: 0
Training loss: 1.242372894847225
Validation loss: 2.3318253411113505

Epoch: 5| Step: 1
Training loss: 0.9531735267167734
Validation loss: 2.3762101219184917

Epoch: 5| Step: 2
Training loss: 1.5867278286154374
Validation loss: 2.340163448642371

Epoch: 5| Step: 3
Training loss: 2.1440117767921514
Validation loss: 2.3379471970151386

Epoch: 5| Step: 4
Training loss: 1.4505940207115822
Validation loss: 2.3585090039411516

Epoch: 5| Step: 5
Training loss: 1.266043134777094
Validation loss: 2.3842840031623975

Epoch: 5| Step: 6
Training loss: 1.0719071363964405
Validation loss: 2.3440572874923102

Epoch: 5| Step: 7
Training loss: 1.9195799731730332
Validation loss: 2.3581348656867185

Epoch: 5| Step: 8
Training loss: 1.7511581947937656
Validation loss: 2.3166070445153855

Epoch: 5| Step: 9
Training loss: 1.715912991725431
Validation loss: 2.3170404489287564

Epoch: 5| Step: 10
Training loss: 1.600844952873597
Validation loss: 2.3041148557988635

Epoch: 334| Step: 0
Training loss: 1.426282569854387
Validation loss: 2.345944607808218

Epoch: 5| Step: 1
Training loss: 1.4201832023159051
Validation loss: 2.340770382301402

Epoch: 5| Step: 2
Training loss: 1.5066391723087775
Validation loss: 2.320886701579746

Epoch: 5| Step: 3
Training loss: 1.3604829153819848
Validation loss: 2.343072050753785

Epoch: 5| Step: 4
Training loss: 1.2016330732992828
Validation loss: 2.283477331922841

Epoch: 5| Step: 5
Training loss: 1.6643680775491632
Validation loss: 2.375844983234808

Epoch: 5| Step: 6
Training loss: 1.3189843173016575
Validation loss: 2.3854038639229254

Epoch: 5| Step: 7
Training loss: 2.1839717203482194
Validation loss: 2.3431639421934727

Epoch: 5| Step: 8
Training loss: 1.321668526687051
Validation loss: 2.344609201104372

Epoch: 5| Step: 9
Training loss: 1.8841903520141725
Validation loss: 2.3347721834747777

Epoch: 5| Step: 10
Training loss: 1.5209367621102394
Validation loss: 2.330836207634187

Epoch: 335| Step: 0
Training loss: 1.4548193784730505
Validation loss: 2.3290281535003854

Epoch: 5| Step: 1
Training loss: 1.3870504063259654
Validation loss: 2.33209042546111

Epoch: 5| Step: 2
Training loss: 1.8384007588135138
Validation loss: 2.3855753730875753

Epoch: 5| Step: 3
Training loss: 1.750870283893795
Validation loss: 2.258639853145955

Epoch: 5| Step: 4
Training loss: 1.1242368016705684
Validation loss: 2.3410713185493672

Epoch: 5| Step: 5
Training loss: 1.5565752999300795
Validation loss: 2.376959852927229

Epoch: 5| Step: 6
Training loss: 1.7520150436295483
Validation loss: 2.3000164167826793

Epoch: 5| Step: 7
Training loss: 1.248764715174825
Validation loss: 2.319151329443858

Epoch: 5| Step: 8
Training loss: 1.1300845217531972
Validation loss: 2.31231951265587

Epoch: 5| Step: 9
Training loss: 2.1484632455843764
Validation loss: 2.415762998262412

Epoch: 5| Step: 10
Training loss: 1.334324627177869
Validation loss: 2.312656521454169

Epoch: 336| Step: 0
Training loss: 1.5473313092064154
Validation loss: 2.3181516878432173

Epoch: 5| Step: 1
Training loss: 2.0185911842446225
Validation loss: 2.3644544739707998

Epoch: 5| Step: 2
Training loss: 1.8524965915828757
Validation loss: 2.3383250006074374

Epoch: 5| Step: 3
Training loss: 1.7840705090688949
Validation loss: 2.317956398803768

Epoch: 5| Step: 4
Training loss: 1.5496328411243936
Validation loss: 2.353582530976267

Epoch: 5| Step: 5
Training loss: 0.9415439172652493
Validation loss: 2.333004763171415

Epoch: 5| Step: 6
Training loss: 1.741183346515309
Validation loss: 2.291257278776959

Epoch: 5| Step: 7
Training loss: 1.1694499546252441
Validation loss: 2.3153608674376587

Epoch: 5| Step: 8
Training loss: 1.0102139626853106
Validation loss: 2.331916900682329

Epoch: 5| Step: 9
Training loss: 1.1430940946527723
Validation loss: 2.330057797463057

Epoch: 5| Step: 10
Training loss: 1.8531716352130219
Validation loss: 2.3613377831666105

Epoch: 337| Step: 0
Training loss: 1.7274444536920517
Validation loss: 2.3355540041270197

Epoch: 5| Step: 1
Training loss: 2.017642645159666
Validation loss: 2.387747515730495

Epoch: 5| Step: 2
Training loss: 1.5994949020395128
Validation loss: 2.4033766617481165

Epoch: 5| Step: 3
Training loss: 1.3544271903199037
Validation loss: 2.3315850485764926

Epoch: 5| Step: 4
Training loss: 1.6746341362687092
Validation loss: 2.357766727689929

Epoch: 5| Step: 5
Training loss: 1.1152208531189616
Validation loss: 2.359720044194785

Epoch: 5| Step: 6
Training loss: 1.6551663434428403
Validation loss: 2.3162668883433923

Epoch: 5| Step: 7
Training loss: 1.4552608912849583
Validation loss: 2.3633671435024994

Epoch: 5| Step: 8
Training loss: 1.380157076285724
Validation loss: 2.3232802151585044

Epoch: 5| Step: 9
Training loss: 1.2062988528305882
Validation loss: 2.3674616300761095

Epoch: 5| Step: 10
Training loss: 1.4889069290792099
Validation loss: 2.3854275817950947

Epoch: 338| Step: 0
Training loss: 1.7565577797316452
Validation loss: 2.3740951485342707

Epoch: 5| Step: 1
Training loss: 1.3685538739299574
Validation loss: 2.366411713705866

Epoch: 5| Step: 2
Training loss: 1.5191153224290594
Validation loss: 2.303057087736709

Epoch: 5| Step: 3
Training loss: 1.3675991201655104
Validation loss: 2.39900837403648

Epoch: 5| Step: 4
Training loss: 1.3682327198824167
Validation loss: 2.3360766846318906

Epoch: 5| Step: 5
Training loss: 1.4789425675678087
Validation loss: 2.336777616698297

Epoch: 5| Step: 6
Training loss: 2.278147848299881
Validation loss: 2.3543646331089083

Epoch: 5| Step: 7
Training loss: 1.1645464819103029
Validation loss: 2.2886128174117983

Epoch: 5| Step: 8
Training loss: 1.5425343348609306
Validation loss: 2.365448319768456

Epoch: 5| Step: 9
Training loss: 1.5213782845213208
Validation loss: 2.364441065113075

Epoch: 5| Step: 10
Training loss: 0.9379406211456918
Validation loss: 2.296540956564302

Epoch: 339| Step: 0
Training loss: 1.6307632509330936
Validation loss: 2.3456128981418565

Epoch: 5| Step: 1
Training loss: 1.1661462247415386
Validation loss: 2.3340505475177595

Epoch: 5| Step: 2
Training loss: 1.5721981436896688
Validation loss: 2.3414880273730576

Epoch: 5| Step: 3
Training loss: 1.5156120221083786
Validation loss: 2.345855519686649

Epoch: 5| Step: 4
Training loss: 1.4404912592772645
Validation loss: 2.3431153737818278

Epoch: 5| Step: 5
Training loss: 1.691678630930618
Validation loss: 2.3728700077070863

Epoch: 5| Step: 6
Training loss: 1.4358951068385941
Validation loss: 2.3093523089255603

Epoch: 5| Step: 7
Training loss: 1.2810586926059895
Validation loss: 2.299795793123753

Epoch: 5| Step: 8
Training loss: 1.4949124206610824
Validation loss: 2.3633533694243827

Epoch: 5| Step: 9
Training loss: 1.892102066492779
Validation loss: 2.3740011110484

Epoch: 5| Step: 10
Training loss: 1.5172944460418287
Validation loss: 2.334880790546614

Epoch: 340| Step: 0
Training loss: 1.7107867866919166
Validation loss: 2.3170221407765577

Epoch: 5| Step: 1
Training loss: 1.4986999759168311
Validation loss: 2.271999257853194

Epoch: 5| Step: 2
Training loss: 1.528931321926318
Validation loss: 2.342715233333331

Epoch: 5| Step: 3
Training loss: 1.8689322519897467
Validation loss: 2.373588298970874

Epoch: 5| Step: 4
Training loss: 1.2897219733845668
Validation loss: 2.2912110629960516

Epoch: 5| Step: 5
Training loss: 1.707992806649527
Validation loss: 2.3433656526395685

Epoch: 5| Step: 6
Training loss: 1.3581776223518858
Validation loss: 2.3533906015929067

Epoch: 5| Step: 7
Training loss: 1.0297917546241306
Validation loss: 2.388927150899086

Epoch: 5| Step: 8
Training loss: 1.400560993807111
Validation loss: 2.294877065737329

Epoch: 5| Step: 9
Training loss: 1.5359358421774656
Validation loss: 2.335152317689986

Epoch: 5| Step: 10
Training loss: 1.9630052219929663
Validation loss: 2.3032784819945444

Epoch: 341| Step: 0
Training loss: 1.436426342263768
Validation loss: 2.381206502859784

Epoch: 5| Step: 1
Training loss: 1.2406864333616832
Validation loss: 2.3091186384253484

Epoch: 5| Step: 2
Training loss: 1.1282785115712617
Validation loss: 2.2969151607013467

Epoch: 5| Step: 3
Training loss: 1.521012239079638
Validation loss: 2.2969814329173412

Epoch: 5| Step: 4
Training loss: 1.2267743553354429
Validation loss: 2.3254671905812407

Epoch: 5| Step: 5
Training loss: 2.0776912838934933
Validation loss: 2.356476109338145

Epoch: 5| Step: 6
Training loss: 1.20959191163679
Validation loss: 2.3386569771788976

Epoch: 5| Step: 7
Training loss: 2.2776781101699517
Validation loss: 2.3595076856903794

Epoch: 5| Step: 8
Training loss: 1.4071722609177464
Validation loss: 2.3359239581764317

Epoch: 5| Step: 9
Training loss: 1.4606491049008674
Validation loss: 2.3835060195684212

Epoch: 5| Step: 10
Training loss: 1.6579954918223754
Validation loss: 2.3311149644054248

Epoch: 342| Step: 0
Training loss: 1.272168515990709
Validation loss: 2.3424711253570947

Epoch: 5| Step: 1
Training loss: 1.206384874620658
Validation loss: 2.335461060242002

Epoch: 5| Step: 2
Training loss: 1.8941976037151367
Validation loss: 2.285387342849323

Epoch: 5| Step: 3
Training loss: 1.6491200268000412
Validation loss: 2.317591525530255

Epoch: 5| Step: 4
Training loss: 1.3170475062938463
Validation loss: 2.3834639356928076

Epoch: 5| Step: 5
Training loss: 1.3715907225939472
Validation loss: 2.354838653698745

Epoch: 5| Step: 6
Training loss: 1.6886599051205495
Validation loss: 2.334582754221456

Epoch: 5| Step: 7
Training loss: 1.0278243184649751
Validation loss: 2.311892070641981

Epoch: 5| Step: 8
Training loss: 1.8124423182286735
Validation loss: 2.3478108841199563

Epoch: 5| Step: 9
Training loss: 1.5006670263491357
Validation loss: 2.332030600853465

Epoch: 5| Step: 10
Training loss: 1.7107533394974521
Validation loss: 2.3509053394156902

Epoch: 343| Step: 0
Training loss: 1.9532534137472868
Validation loss: 2.2924085357813917

Epoch: 5| Step: 1
Training loss: 1.7487498313789205
Validation loss: 2.3654030127293653

Epoch: 5| Step: 2
Training loss: 1.9202838296511475
Validation loss: 2.315304752261968

Epoch: 5| Step: 3
Training loss: 1.1886124670330944
Validation loss: 2.3576345399032568

Epoch: 5| Step: 4
Training loss: 1.1420598346213773
Validation loss: 2.379981283886556

Epoch: 5| Step: 5
Training loss: 1.3383828698551534
Validation loss: 2.3330905779970585

Epoch: 5| Step: 6
Training loss: 1.81841863910539
Validation loss: 2.3335993837777655

Epoch: 5| Step: 7
Training loss: 1.532538903070868
Validation loss: 2.369425394789617

Epoch: 5| Step: 8
Training loss: 1.392755911715082
Validation loss: 2.385661628512854

Epoch: 5| Step: 9
Training loss: 1.291966352254921
Validation loss: 2.3426032998626205

Epoch: 5| Step: 10
Training loss: 0.863917500365218
Validation loss: 2.354878391971584

Epoch: 344| Step: 0
Training loss: 1.685231202447823
Validation loss: 2.3272322524386246

Epoch: 5| Step: 1
Training loss: 1.4274496272029722
Validation loss: 2.3087858734327718

Epoch: 5| Step: 2
Training loss: 1.6023700445985192
Validation loss: 2.3546711494318027

Epoch: 5| Step: 3
Training loss: 1.5315312497060887
Validation loss: 2.328344470879121

Epoch: 5| Step: 4
Training loss: 1.3054852359627946
Validation loss: 2.3364198314102245

Epoch: 5| Step: 5
Training loss: 1.4616425796635184
Validation loss: 2.3287467079631856

Epoch: 5| Step: 6
Training loss: 1.0840440888324574
Validation loss: 2.3383558595841882

Epoch: 5| Step: 7
Training loss: 1.476830352224557
Validation loss: 2.337388064042744

Epoch: 5| Step: 8
Training loss: 1.3024972588332724
Validation loss: 2.3540349664492557

Epoch: 5| Step: 9
Training loss: 1.9795266342741593
Validation loss: 2.4170145909512093

Epoch: 5| Step: 10
Training loss: 1.6903784891239357
Validation loss: 2.313771109984485

Epoch: 345| Step: 0
Training loss: 1.1569044992899349
Validation loss: 2.3153211617733054

Epoch: 5| Step: 1
Training loss: 1.1922123917647105
Validation loss: 2.330057846974201

Epoch: 5| Step: 2
Training loss: 1.2530599334643326
Validation loss: 2.3477138304541043

Epoch: 5| Step: 3
Training loss: 1.4879822117706167
Validation loss: 2.318847498706747

Epoch: 5| Step: 4
Training loss: 1.683039385873621
Validation loss: 2.3881979143179195

Epoch: 5| Step: 5
Training loss: 1.4612578178568636
Validation loss: 2.325485050812772

Epoch: 5| Step: 6
Training loss: 1.1448781395910876
Validation loss: 2.331679364641827

Epoch: 5| Step: 7
Training loss: 1.6039726172985176
Validation loss: 2.3476673949255917

Epoch: 5| Step: 8
Training loss: 2.3429268981105955
Validation loss: 2.3429634639438257

Epoch: 5| Step: 9
Training loss: 1.4754936749882799
Validation loss: 2.3016180350444078

Epoch: 5| Step: 10
Training loss: 1.5434946443584072
Validation loss: 2.3025206688369235

Epoch: 346| Step: 0
Training loss: 1.2727988109981083
Validation loss: 2.3287754189506042

Epoch: 5| Step: 1
Training loss: 1.0233081998027023
Validation loss: 2.3686254170901035

Epoch: 5| Step: 2
Training loss: 1.3669220584954596
Validation loss: 2.3969116701848794

Epoch: 5| Step: 3
Training loss: 1.3462895194002653
Validation loss: 2.3255090512819403

Epoch: 5| Step: 4
Training loss: 1.5314881275848897
Validation loss: 2.364258641471744

Epoch: 5| Step: 5
Training loss: 1.2748068719339336
Validation loss: 2.383201632169194

Epoch: 5| Step: 6
Training loss: 1.822302258809152
Validation loss: 2.2953738464437308

Epoch: 5| Step: 7
Training loss: 1.6654526898717141
Validation loss: 2.315445135637699

Epoch: 5| Step: 8
Training loss: 2.2190056237196347
Validation loss: 2.3669394216197084

Epoch: 5| Step: 9
Training loss: 1.1048589851193233
Validation loss: 2.3218652159287445

Epoch: 5| Step: 10
Training loss: 1.575167840764202
Validation loss: 2.3435569114859756

Epoch: 347| Step: 0
Training loss: 1.385356050852732
Validation loss: 2.32252897359056

Epoch: 5| Step: 1
Training loss: 1.6480530204576993
Validation loss: 2.330670133553355

Epoch: 5| Step: 2
Training loss: 1.6933805646967548
Validation loss: 2.3393982496660186

Epoch: 5| Step: 3
Training loss: 1.0498154182772788
Validation loss: 2.3457807377590743

Epoch: 5| Step: 4
Training loss: 1.3938355834412437
Validation loss: 2.3159532668343408

Epoch: 5| Step: 5
Training loss: 1.5367728304789128
Validation loss: 2.3349788184379014

Epoch: 5| Step: 6
Training loss: 2.1106196369603425
Validation loss: 2.302621251750113

Epoch: 5| Step: 7
Training loss: 1.3923521139351525
Validation loss: 2.307946615350174

Epoch: 5| Step: 8
Training loss: 1.25310122117767
Validation loss: 2.3149890989872035

Epoch: 5| Step: 9
Training loss: 1.532579584342206
Validation loss: 2.3362978538866597

Epoch: 5| Step: 10
Training loss: 1.2968225583423596
Validation loss: 2.3803153668388997

Epoch: 348| Step: 0
Training loss: 1.021268044899465
Validation loss: 2.34910326207446

Epoch: 5| Step: 1
Training loss: 1.603672479910111
Validation loss: 2.322934856993794

Epoch: 5| Step: 2
Training loss: 1.7094508989350208
Validation loss: 2.3603645601413272

Epoch: 5| Step: 3
Training loss: 1.503675963370025
Validation loss: 2.396949186309541

Epoch: 5| Step: 4
Training loss: 1.3669426399034206
Validation loss: 2.34257969778022

Epoch: 5| Step: 5
Training loss: 1.196708512243122
Validation loss: 2.2934109397222677

Epoch: 5| Step: 6
Training loss: 1.6127490627538594
Validation loss: 2.338668285024084

Epoch: 5| Step: 7
Training loss: 2.1552973315111856
Validation loss: 2.3528129652376752

Epoch: 5| Step: 8
Training loss: 1.3510854242905845
Validation loss: 2.312657385550278

Epoch: 5| Step: 9
Training loss: 1.3606683125433778
Validation loss: 2.337474581093447

Epoch: 5| Step: 10
Training loss: 1.4855446473675942
Validation loss: 2.3161036906945633

Epoch: 349| Step: 0
Training loss: 1.2090802131591714
Validation loss: 2.3568308988776203

Epoch: 5| Step: 1
Training loss: 1.3313655140508125
Validation loss: 2.3266915770676695

Epoch: 5| Step: 2
Training loss: 1.3789914026524885
Validation loss: 2.367005012382511

Epoch: 5| Step: 3
Training loss: 1.421686264758664
Validation loss: 2.320609232736107

Epoch: 5| Step: 4
Training loss: 1.2470407743846652
Validation loss: 2.280057286548677

Epoch: 5| Step: 5
Training loss: 1.6894219368056942
Validation loss: 2.348079432294874

Epoch: 5| Step: 6
Training loss: 1.6732880512255706
Validation loss: 2.34365123144158

Epoch: 5| Step: 7
Training loss: 1.4531868542047999
Validation loss: 2.3445037187715507

Epoch: 5| Step: 8
Training loss: 1.943075893563183
Validation loss: 2.3573703846054603

Epoch: 5| Step: 9
Training loss: 1.6942758511049643
Validation loss: 2.315163145083782

Epoch: 5| Step: 10
Training loss: 1.5215785495666074
Validation loss: 2.319910901824806

Epoch: 350| Step: 0
Training loss: 0.9404398282812547
Validation loss: 2.3738838254266024

Epoch: 5| Step: 1
Training loss: 2.0326180179579953
Validation loss: 2.341836212779399

Epoch: 5| Step: 2
Training loss: 1.6972632369714933
Validation loss: 2.2931095778892256

Epoch: 5| Step: 3
Training loss: 1.7296926165800566
Validation loss: 2.337304836494239

Epoch: 5| Step: 4
Training loss: 1.4126322557765785
Validation loss: 2.3120675166187574

Epoch: 5| Step: 5
Training loss: 1.1422755696671494
Validation loss: 2.2927104532434845

Epoch: 5| Step: 6
Training loss: 1.4732697926422815
Validation loss: 2.3388323727998186

Epoch: 5| Step: 7
Training loss: 1.6133462001481866
Validation loss: 2.3450402496407907

Epoch: 5| Step: 8
Training loss: 1.2909589746370183
Validation loss: 2.350654007655317

Epoch: 5| Step: 9
Training loss: 1.3659364916837657
Validation loss: 2.4058824047185317

Epoch: 5| Step: 10
Training loss: 1.3905821375724086
Validation loss: 2.2786700721307063

Epoch: 351| Step: 0
Training loss: 1.4799124042260505
Validation loss: 2.3650123427824576

Epoch: 5| Step: 1
Training loss: 1.5559517019174955
Validation loss: 2.286639344284668

Epoch: 5| Step: 2
Training loss: 1.3852010238821029
Validation loss: 2.368668771421897

Epoch: 5| Step: 3
Training loss: 1.1263395387746342
Validation loss: 2.3362899856193065

Epoch: 5| Step: 4
Training loss: 1.6513900710132767
Validation loss: 2.359829149473623

Epoch: 5| Step: 5
Training loss: 1.294818764748535
Validation loss: 2.314470765618738

Epoch: 5| Step: 6
Training loss: 1.4970359126429384
Validation loss: 2.3895640143817896

Epoch: 5| Step: 7
Training loss: 2.092835183774707
Validation loss: 2.3320687506852282

Epoch: 5| Step: 8
Training loss: 1.044707488411653
Validation loss: 2.4196289857774276

Epoch: 5| Step: 9
Training loss: 0.9906383044194815
Validation loss: 2.3729793445629266

Epoch: 5| Step: 10
Training loss: 1.8060230416130238
Validation loss: 2.376658308114606

Epoch: 352| Step: 0
Training loss: 1.3587756096076753
Validation loss: 2.354984977198231

Epoch: 5| Step: 1
Training loss: 1.7292188000767337
Validation loss: 2.348803322161183

Epoch: 5| Step: 2
Training loss: 1.2152510079962546
Validation loss: 2.327994050646474

Epoch: 5| Step: 3
Training loss: 1.6237621728031153
Validation loss: 2.307682107002835

Epoch: 5| Step: 4
Training loss: 0.9761169332648951
Validation loss: 2.349792871006696

Epoch: 5| Step: 5
Training loss: 1.4930817485946475
Validation loss: 2.346129882541252

Epoch: 5| Step: 6
Training loss: 1.6964724742973534
Validation loss: 2.3465378050607137

Epoch: 5| Step: 7
Training loss: 1.1351018463350964
Validation loss: 2.3427253304466427

Epoch: 5| Step: 8
Training loss: 1.1194135456275034
Validation loss: 2.3394733002650057

Epoch: 5| Step: 9
Training loss: 2.178891272371994
Validation loss: 2.382150149062609

Epoch: 5| Step: 10
Training loss: 1.5948499735765629
Validation loss: 2.364760077078298

Epoch: 353| Step: 0
Training loss: 1.3931258784240446
Validation loss: 2.3382098056584213

Epoch: 5| Step: 1
Training loss: 1.1956715761276566
Validation loss: 2.368778290020802

Epoch: 5| Step: 2
Training loss: 1.4826151805990238
Validation loss: 2.401816107985058

Epoch: 5| Step: 3
Training loss: 1.6008795794125652
Validation loss: 2.330398186474886

Epoch: 5| Step: 4
Training loss: 1.323494412077841
Validation loss: 2.319706594869405

Epoch: 5| Step: 5
Training loss: 1.4350801916012548
Validation loss: 2.3604632006416613

Epoch: 5| Step: 6
Training loss: 1.4740645659033746
Validation loss: 2.359574096902316

Epoch: 5| Step: 7
Training loss: 2.2234015262827396
Validation loss: 2.4002796925340593

Epoch: 5| Step: 8
Training loss: 1.2489581057453134
Validation loss: 2.3638497040723383

Epoch: 5| Step: 9
Training loss: 1.103013996450481
Validation loss: 2.374076000751127

Epoch: 5| Step: 10
Training loss: 1.338938682645019
Validation loss: 2.36080815637493

Epoch: 354| Step: 0
Training loss: 1.7074324705920525
Validation loss: 2.342815010863131

Epoch: 5| Step: 1
Training loss: 1.433970056356853
Validation loss: 2.315537139189812

Epoch: 5| Step: 2
Training loss: 1.4268080267141146
Validation loss: 2.274734844652197

Epoch: 5| Step: 3
Training loss: 1.3557433803818097
Validation loss: 2.4117148889292226

Epoch: 5| Step: 4
Training loss: 1.0608216662088727
Validation loss: 2.2943045144237484

Epoch: 5| Step: 5
Training loss: 1.540214765609147
Validation loss: 2.310711882997258

Epoch: 5| Step: 6
Training loss: 1.1520648166118106
Validation loss: 2.390487820311866

Epoch: 5| Step: 7
Training loss: 1.4833421828331015
Validation loss: 2.2908823127174744

Epoch: 5| Step: 8
Training loss: 1.430873024948542
Validation loss: 2.4247134577593497

Epoch: 5| Step: 9
Training loss: 1.5013842553321997
Validation loss: 2.3886112399328043

Epoch: 5| Step: 10
Training loss: 2.2100610512288323
Validation loss: 2.4021761111663578

Epoch: 355| Step: 0
Training loss: 1.3805902156704724
Validation loss: 2.3610012157553264

Epoch: 5| Step: 1
Training loss: 1.2951487807008897
Validation loss: 2.3525829249543615

Epoch: 5| Step: 2
Training loss: 1.7750079893550255
Validation loss: 2.3638338835940527

Epoch: 5| Step: 3
Training loss: 1.5338703234544289
Validation loss: 2.34219625839523

Epoch: 5| Step: 4
Training loss: 1.0088002886521412
Validation loss: 2.397201673437308

Epoch: 5| Step: 5
Training loss: 1.392518201397434
Validation loss: 2.406053880024694

Epoch: 5| Step: 6
Training loss: 1.4888146913759812
Validation loss: 2.3469008100703896

Epoch: 5| Step: 7
Training loss: 2.011984442785345
Validation loss: 2.3487921651619703

Epoch: 5| Step: 8
Training loss: 1.7161345956653438
Validation loss: 2.3068984883311567

Epoch: 5| Step: 9
Training loss: 1.2552172500905676
Validation loss: 2.361391919629349

Epoch: 5| Step: 10
Training loss: 0.8371213213432636
Validation loss: 2.3271865886008514

Epoch: 356| Step: 0
Training loss: 1.3425226150682172
Validation loss: 2.329447054114319

Epoch: 5| Step: 1
Training loss: 1.4950785965177968
Validation loss: 2.341069279525223

Epoch: 5| Step: 2
Training loss: 1.5764079809316403
Validation loss: 2.3399095727516097

Epoch: 5| Step: 3
Training loss: 1.284891582472189
Validation loss: 2.3773954375986834

Epoch: 5| Step: 4
Training loss: 2.0984733027445315
Validation loss: 2.34809252243284

Epoch: 5| Step: 5
Training loss: 1.410939091779755
Validation loss: 2.300311617899157

Epoch: 5| Step: 6
Training loss: 1.5313587539355384
Validation loss: 2.3354074182148232

Epoch: 5| Step: 7
Training loss: 1.4246881344495308
Validation loss: 2.318914453072142

Epoch: 5| Step: 8
Training loss: 1.476593905321812
Validation loss: 2.374270200187251

Epoch: 5| Step: 9
Training loss: 1.2001223064718582
Validation loss: 2.350534520944501

Epoch: 5| Step: 10
Training loss: 1.2934945411758636
Validation loss: 2.3529479974036183

Epoch: 357| Step: 0
Training loss: 1.8985527223384926
Validation loss: 2.420608426957851

Epoch: 5| Step: 1
Training loss: 1.623770762392293
Validation loss: 2.3348464769301085

Epoch: 5| Step: 2
Training loss: 1.340702148920845
Validation loss: 2.3727130765354114

Epoch: 5| Step: 3
Training loss: 1.3163228447184643
Validation loss: 2.4432308858055447

Epoch: 5| Step: 4
Training loss: 1.5606053882080049
Validation loss: 2.3959517993145942

Epoch: 5| Step: 5
Training loss: 1.3039285428179685
Validation loss: 2.3499340708998693

Epoch: 5| Step: 6
Training loss: 1.43897892712399
Validation loss: 2.3747137163776957

Epoch: 5| Step: 7
Training loss: 0.9765505370361014
Validation loss: 2.416890227005889

Epoch: 5| Step: 8
Training loss: 1.3150641054403172
Validation loss: 2.3147713709574917

Epoch: 5| Step: 9
Training loss: 1.5339820001135487
Validation loss: 2.3719359506721087

Epoch: 5| Step: 10
Training loss: 1.3938827930362927
Validation loss: 2.4434900129621986

Epoch: 358| Step: 0
Training loss: 1.3719937666314885
Validation loss: 2.445006140266642

Epoch: 5| Step: 1
Training loss: 1.3372735375461489
Validation loss: 2.3830416198885938

Epoch: 5| Step: 2
Training loss: 1.8023204390229957
Validation loss: 2.362928214468301

Epoch: 5| Step: 3
Training loss: 1.254818070815946
Validation loss: 2.283964420313519

Epoch: 5| Step: 4
Training loss: 1.5238829132768288
Validation loss: 2.367332938937061

Epoch: 5| Step: 5
Training loss: 1.5976491615492583
Validation loss: 2.374175580062838

Epoch: 5| Step: 6
Training loss: 1.6810778164527311
Validation loss: 2.294298914600079

Epoch: 5| Step: 7
Training loss: 1.5987800805287091
Validation loss: 2.323270517955052

Epoch: 5| Step: 8
Training loss: 1.2404770501076883
Validation loss: 2.356610228856893

Epoch: 5| Step: 9
Training loss: 1.0304662442701067
Validation loss: 2.3203428146366916

Epoch: 5| Step: 10
Training loss: 1.4651545080528714
Validation loss: 2.333517402062903

Epoch: 359| Step: 0
Training loss: 1.4709958700800219
Validation loss: 2.320125337638998

Epoch: 5| Step: 1
Training loss: 1.4828591889084577
Validation loss: 2.377932015381418

Epoch: 5| Step: 2
Training loss: 1.325183348295983
Validation loss: 2.3733445763065286

Epoch: 5| Step: 3
Training loss: 1.4565131772326232
Validation loss: 2.3872651778253493

Epoch: 5| Step: 4
Training loss: 1.2584098203204337
Validation loss: 2.3962245730502305

Epoch: 5| Step: 5
Training loss: 1.964006795525691
Validation loss: 2.3896158603054

Epoch: 5| Step: 6
Training loss: 1.3431693308434196
Validation loss: 2.3455156311112675

Epoch: 5| Step: 7
Training loss: 2.280388656417236
Validation loss: 2.385936784783441

Epoch: 5| Step: 8
Training loss: 1.1402380299942492
Validation loss: 2.352762834081197

Epoch: 5| Step: 9
Training loss: 0.9550939453312521
Validation loss: 2.3934533893233385

Epoch: 5| Step: 10
Training loss: 1.3030855772060874
Validation loss: 2.272772056710748

Epoch: 360| Step: 0
Training loss: 0.7349431701020999
Validation loss: 2.3837661553523986

Epoch: 5| Step: 1
Training loss: 1.0927191644985748
Validation loss: 2.2995380909739542

Epoch: 5| Step: 2
Training loss: 2.159289443091836
Validation loss: 2.321880256888574

Epoch: 5| Step: 3
Training loss: 1.544105748256283
Validation loss: 2.2930537443883314

Epoch: 5| Step: 4
Training loss: 1.2267335420153265
Validation loss: 2.4200076819365477

Epoch: 5| Step: 5
Training loss: 1.2267688164644888
Validation loss: 2.296997738393038

Epoch: 5| Step: 6
Training loss: 1.032743008998312
Validation loss: 2.3416911630754544

Epoch: 5| Step: 7
Training loss: 1.7232042336329572
Validation loss: 2.3735241387274972

Epoch: 5| Step: 8
Training loss: 1.537915959729687
Validation loss: 2.3944283609029564

Epoch: 5| Step: 9
Training loss: 1.5264601236802064
Validation loss: 2.3249367052879935

Epoch: 5| Step: 10
Training loss: 1.4421359233788034
Validation loss: 2.450239683087651

Epoch: 361| Step: 0
Training loss: 1.0878787904708629
Validation loss: 2.3075926598794485

Epoch: 5| Step: 1
Training loss: 1.0792912795439182
Validation loss: 2.3648518401781162

Epoch: 5| Step: 2
Training loss: 1.5569450817774204
Validation loss: 2.4199196418051976

Epoch: 5| Step: 3
Training loss: 1.0311924889451518
Validation loss: 2.392204531209812

Epoch: 5| Step: 4
Training loss: 1.9123824862610341
Validation loss: 2.4078986746233433

Epoch: 5| Step: 5
Training loss: 1.2378227275453788
Validation loss: 2.3905861100930266

Epoch: 5| Step: 6
Training loss: 1.6221821635597033
Validation loss: 2.3967449435262207

Epoch: 5| Step: 7
Training loss: 2.0015194604610387
Validation loss: 2.3875575317622184

Epoch: 5| Step: 8
Training loss: 1.1938878963374224
Validation loss: 2.3195964268599987

Epoch: 5| Step: 9
Training loss: 1.354997272559092
Validation loss: 2.372275313159951

Epoch: 5| Step: 10
Training loss: 1.1059921158031873
Validation loss: 2.3993826323980185

Epoch: 362| Step: 0
Training loss: 1.1538964107768033
Validation loss: 2.3620638781905066

Epoch: 5| Step: 1
Training loss: 1.8378000105310386
Validation loss: 2.3126184077879857

Epoch: 5| Step: 2
Training loss: 1.8223688519546373
Validation loss: 2.3664277395762956

Epoch: 5| Step: 3
Training loss: 0.9947919529353557
Validation loss: 2.3225891748409015

Epoch: 5| Step: 4
Training loss: 1.41704384139786
Validation loss: 2.339395515506871

Epoch: 5| Step: 5
Training loss: 1.6012660798956142
Validation loss: 2.3396318775160445

Epoch: 5| Step: 6
Training loss: 1.0822793283698526
Validation loss: 2.378979807449836

Epoch: 5| Step: 7
Training loss: 1.313489994703623
Validation loss: 2.3538414413507756

Epoch: 5| Step: 8
Training loss: 1.3987308386341626
Validation loss: 2.403326385260099

Epoch: 5| Step: 9
Training loss: 1.3482443148427508
Validation loss: 2.2878687838968057

Epoch: 5| Step: 10
Training loss: 1.1589504873414869
Validation loss: 2.3206112107496977

Epoch: 363| Step: 0
Training loss: 1.368001553824585
Validation loss: 2.3347965386631557

Epoch: 5| Step: 1
Training loss: 1.1931086649908027
Validation loss: 2.36313032025785

Epoch: 5| Step: 2
Training loss: 1.5103221819910833
Validation loss: 2.341157502380467

Epoch: 5| Step: 3
Training loss: 1.353867434183514
Validation loss: 2.33514151045629

Epoch: 5| Step: 4
Training loss: 1.3005859869953953
Validation loss: 2.3261639587053287

Epoch: 5| Step: 5
Training loss: 1.746969187044986
Validation loss: 2.2416960343520396

Epoch: 5| Step: 6
Training loss: 1.336553777238568
Validation loss: 2.3253004044981123

Epoch: 5| Step: 7
Training loss: 0.9419650876526722
Validation loss: 2.4050208106999715

Epoch: 5| Step: 8
Training loss: 2.0956463552786815
Validation loss: 2.337340468044553

Epoch: 5| Step: 9
Training loss: 1.4957015915486964
Validation loss: 2.401735363910326

Epoch: 5| Step: 10
Training loss: 1.3247071212391694
Validation loss: 2.320491424376209

Epoch: 364| Step: 0
Training loss: 1.2376899631234752
Validation loss: 2.308982187773463

Epoch: 5| Step: 1
Training loss: 1.6055562164909531
Validation loss: 2.405532920774994

Epoch: 5| Step: 2
Training loss: 1.4162296107172088
Validation loss: 2.3673893704945743

Epoch: 5| Step: 3
Training loss: 1.2733357862795094
Validation loss: 2.3267058855111498

Epoch: 5| Step: 4
Training loss: 1.9411637521265923
Validation loss: 2.3027628870649344

Epoch: 5| Step: 5
Training loss: 1.2298573746215498
Validation loss: 2.332901826488789

Epoch: 5| Step: 6
Training loss: 1.0929042270857539
Validation loss: 2.3672739123691255

Epoch: 5| Step: 7
Training loss: 1.5334568081081952
Validation loss: 2.30881873503572

Epoch: 5| Step: 8
Training loss: 1.9784562157526122
Validation loss: 2.3477792420147723

Epoch: 5| Step: 9
Training loss: 1.154252362885679
Validation loss: 2.3944643393995766

Epoch: 5| Step: 10
Training loss: 1.2424833317335167
Validation loss: 2.371693797428018

Epoch: 365| Step: 0
Training loss: 1.3482429885696094
Validation loss: 2.3378267355809172

Epoch: 5| Step: 1
Training loss: 1.8082336990168084
Validation loss: 2.314712987644953

Epoch: 5| Step: 2
Training loss: 1.3953983378732455
Validation loss: 2.383179325545149

Epoch: 5| Step: 3
Training loss: 0.9172992943602472
Validation loss: 2.3553017944990744

Epoch: 5| Step: 4
Training loss: 1.7170711293936594
Validation loss: 2.368747081143849

Epoch: 5| Step: 5
Training loss: 1.3568218853718281
Validation loss: 2.3462006377539772

Epoch: 5| Step: 6
Training loss: 1.1279594384435394
Validation loss: 2.3130066795202486

Epoch: 5| Step: 7
Training loss: 1.085364430660006
Validation loss: 2.3520648008152505

Epoch: 5| Step: 8
Training loss: 2.1492916004698146
Validation loss: 2.2847688999946096

Epoch: 5| Step: 9
Training loss: 1.262676147409903
Validation loss: 2.3419960207763433

Epoch: 5| Step: 10
Training loss: 0.8018841847156118
Validation loss: 2.302798429099223

Epoch: 366| Step: 0
Training loss: 0.9938473371902737
Validation loss: 2.3319057002688357

Epoch: 5| Step: 1
Training loss: 1.5291052609344244
Validation loss: 2.33314640494723

Epoch: 5| Step: 2
Training loss: 0.9996205444427446
Validation loss: 2.3308649693244257

Epoch: 5| Step: 3
Training loss: 1.4682501896163582
Validation loss: 2.3412662200342225

Epoch: 5| Step: 4
Training loss: 1.555625517535861
Validation loss: 2.3684329900097123

Epoch: 5| Step: 5
Training loss: 1.5373728815888088
Validation loss: 2.3420897643480525

Epoch: 5| Step: 6
Training loss: 1.5554455773137759
Validation loss: 2.344797704457851

Epoch: 5| Step: 7
Training loss: 1.4235767618806345
Validation loss: 2.3477237597456138

Epoch: 5| Step: 8
Training loss: 2.0120763960757104
Validation loss: 2.3686306566566895

Epoch: 5| Step: 9
Training loss: 1.09973425689619
Validation loss: 2.375267816802578

Epoch: 5| Step: 10
Training loss: 1.167272098442374
Validation loss: 2.3212644833094314

Epoch: 367| Step: 0
Training loss: 1.9906288781719668
Validation loss: 2.2889718380721424

Epoch: 5| Step: 1
Training loss: 1.533012621275822
Validation loss: 2.389317748585089

Epoch: 5| Step: 2
Training loss: 1.2732697358817966
Validation loss: 2.3895843528243796

Epoch: 5| Step: 3
Training loss: 1.1723725851977496
Validation loss: 2.3427541562783687

Epoch: 5| Step: 4
Training loss: 1.314063321905979
Validation loss: 2.301252272362703

Epoch: 5| Step: 5
Training loss: 1.6512588293978714
Validation loss: 2.3267581162023685

Epoch: 5| Step: 6
Training loss: 0.9266612381455936
Validation loss: 2.4072965198147607

Epoch: 5| Step: 7
Training loss: 0.9105817594191381
Validation loss: 2.3637366521612497

Epoch: 5| Step: 8
Training loss: 1.804343318733752
Validation loss: 2.3913008905788904

Epoch: 5| Step: 9
Training loss: 1.2677005185607586
Validation loss: 2.3186925748885203

Epoch: 5| Step: 10
Training loss: 1.2736116535948736
Validation loss: 2.389713929555842

Epoch: 368| Step: 0
Training loss: 1.7532113446682593
Validation loss: 2.3728403030976533

Epoch: 5| Step: 1
Training loss: 1.5275240350258934
Validation loss: 2.326142533988779

Epoch: 5| Step: 2
Training loss: 1.086390887782348
Validation loss: 2.3523397505169537

Epoch: 5| Step: 3
Training loss: 1.1974065053673582
Validation loss: 2.3301112655850407

Epoch: 5| Step: 4
Training loss: 1.35402468401611
Validation loss: 2.3489334956056207

Epoch: 5| Step: 5
Training loss: 1.1065593502470628
Validation loss: 2.2955637293047615

Epoch: 5| Step: 6
Training loss: 1.9463185845493682
Validation loss: 2.345788034041672

Epoch: 5| Step: 7
Training loss: 1.326734600428458
Validation loss: 2.350583543546233

Epoch: 5| Step: 8
Training loss: 1.2244315132312922
Validation loss: 2.3214500315144297

Epoch: 5| Step: 9
Training loss: 1.0436454035265053
Validation loss: 2.337145332417044

Epoch: 5| Step: 10
Training loss: 1.8010834214897324
Validation loss: 2.37585243725721

Epoch: 369| Step: 0
Training loss: 1.9695023204308482
Validation loss: 2.277190459569694

Epoch: 5| Step: 1
Training loss: 1.5228430737597272
Validation loss: 2.393492704991956

Epoch: 5| Step: 2
Training loss: 1.5487424579033389
Validation loss: 2.322705107522864

Epoch: 5| Step: 3
Training loss: 1.023895568838515
Validation loss: 2.4089079433426006

Epoch: 5| Step: 4
Training loss: 1.3922625126522146
Validation loss: 2.3518578237587784

Epoch: 5| Step: 5
Training loss: 1.591082790726237
Validation loss: 2.403504183498192

Epoch: 5| Step: 6
Training loss: 1.3284131803330224
Validation loss: 2.312379808969168

Epoch: 5| Step: 7
Training loss: 1.7244948352350375
Validation loss: 2.317803104385369

Epoch: 5| Step: 8
Training loss: 1.0511005015898545
Validation loss: 2.413920370366825

Epoch: 5| Step: 9
Training loss: 1.299582997711683
Validation loss: 2.3602955557170064

Epoch: 5| Step: 10
Training loss: 1.2900756553525081
Validation loss: 2.3504469030942716

Epoch: 370| Step: 0
Training loss: 1.4031732597632671
Validation loss: 2.312265963519546

Epoch: 5| Step: 1
Training loss: 1.279484579278846
Validation loss: 2.349833683044755

Epoch: 5| Step: 2
Training loss: 1.3007099945438687
Validation loss: 2.386516376842486

Epoch: 5| Step: 3
Training loss: 1.4353058697036367
Validation loss: 2.3665634199551646

Epoch: 5| Step: 4
Training loss: 1.9761423259938107
Validation loss: 2.3406915837320064

Epoch: 5| Step: 5
Training loss: 1.3075186341163179
Validation loss: 2.4018859411056406

Epoch: 5| Step: 6
Training loss: 0.9901780332529202
Validation loss: 2.3627738698838416

Epoch: 5| Step: 7
Training loss: 1.2794210825020462
Validation loss: 2.3761047563647035

Epoch: 5| Step: 8
Training loss: 1.331881114743399
Validation loss: 2.35245069870959

Epoch: 5| Step: 9
Training loss: 1.4907969441600828
Validation loss: 2.313488091491106

Epoch: 5| Step: 10
Training loss: 1.520443365535696
Validation loss: 2.388006921620021

Epoch: 371| Step: 0
Training loss: 1.604894976403261
Validation loss: 2.3541244882748553

Epoch: 5| Step: 1
Training loss: 1.459572710453587
Validation loss: 2.327772155195977

Epoch: 5| Step: 2
Training loss: 1.0862033436262448
Validation loss: 2.362191001641258

Epoch: 5| Step: 3
Training loss: 1.1671993821852986
Validation loss: 2.4272980932771917

Epoch: 5| Step: 4
Training loss: 1.0988419939746423
Validation loss: 2.355067274048332

Epoch: 5| Step: 5
Training loss: 1.2910625316507036
Validation loss: 2.342848687460206

Epoch: 5| Step: 6
Training loss: 1.0427096041361368
Validation loss: 2.3062542522658114

Epoch: 5| Step: 7
Training loss: 1.5183356516569482
Validation loss: 2.3689446496173887

Epoch: 5| Step: 8
Training loss: 1.7629999547386055
Validation loss: 2.3360751515455984

Epoch: 5| Step: 9
Training loss: 0.8101007543701834
Validation loss: 2.3652084082389506

Epoch: 5| Step: 10
Training loss: 2.0500981237606943
Validation loss: 2.354132730898428

Epoch: 372| Step: 0
Training loss: 1.1916122508573972
Validation loss: 2.300554848204555

Epoch: 5| Step: 1
Training loss: 1.0965465216832793
Validation loss: 2.326020514041177

Epoch: 5| Step: 2
Training loss: 1.0566059325440667
Validation loss: 2.405084744149291

Epoch: 5| Step: 3
Training loss: 1.265513756655012
Validation loss: 2.2753852484692927

Epoch: 5| Step: 4
Training loss: 1.3635300024051933
Validation loss: 2.3472436386671447

Epoch: 5| Step: 5
Training loss: 1.2239247527148993
Validation loss: 2.3814666158595

Epoch: 5| Step: 6
Training loss: 1.1283902371612677
Validation loss: 2.3733298774342138

Epoch: 5| Step: 7
Training loss: 1.4224494360600601
Validation loss: 2.4279073363648513

Epoch: 5| Step: 8
Training loss: 1.4558987140586168
Validation loss: 2.3888133486917145

Epoch: 5| Step: 9
Training loss: 2.1915622594450577
Validation loss: 2.437588275986369

Epoch: 5| Step: 10
Training loss: 1.393573677986845
Validation loss: 2.346655221855361

Epoch: 373| Step: 0
Training loss: 1.0370031040148873
Validation loss: 2.3739093819548627

Epoch: 5| Step: 1
Training loss: 2.2397960709658724
Validation loss: 2.3653228741312127

Epoch: 5| Step: 2
Training loss: 1.391461752845312
Validation loss: 2.36998086521366

Epoch: 5| Step: 3
Training loss: 1.3258298002939646
Validation loss: 2.2984245530757064

Epoch: 5| Step: 4
Training loss: 1.0690389699835863
Validation loss: 2.4057661885113117

Epoch: 5| Step: 5
Training loss: 1.15596793574773
Validation loss: 2.3326609238881235

Epoch: 5| Step: 6
Training loss: 1.0608486919285158
Validation loss: 2.3663586465323796

Epoch: 5| Step: 7
Training loss: 1.7200259934168975
Validation loss: 2.3683376441552566

Epoch: 5| Step: 8
Training loss: 1.2145241074601725
Validation loss: 2.3484864829322394

Epoch: 5| Step: 9
Training loss: 1.4929521608653669
Validation loss: 2.344007193287118

Epoch: 5| Step: 10
Training loss: 1.4363307343875027
Validation loss: 2.344730609038286

Epoch: 374| Step: 0
Training loss: 1.5332982902392431
Validation loss: 2.3474976775079592

Epoch: 5| Step: 1
Training loss: 0.7096883678221005
Validation loss: 2.3326342725047517

Epoch: 5| Step: 2
Training loss: 1.2541212331372515
Validation loss: 2.3939064073952747

Epoch: 5| Step: 3
Training loss: 1.4720081957505988
Validation loss: 2.380934146428198

Epoch: 5| Step: 4
Training loss: 1.0151355444317403
Validation loss: 2.3413747563561977

Epoch: 5| Step: 5
Training loss: 1.5979385686150087
Validation loss: 2.3631990916609675

Epoch: 5| Step: 6
Training loss: 1.3241310203096324
Validation loss: 2.4094044332184272

Epoch: 5| Step: 7
Training loss: 1.3887998626574876
Validation loss: 2.350444377023636

Epoch: 5| Step: 8
Training loss: 1.3440149179181333
Validation loss: 2.4318266927417

Epoch: 5| Step: 9
Training loss: 1.7492826217568846
Validation loss: 2.3862287159514803

Epoch: 5| Step: 10
Training loss: 2.0872735591668667
Validation loss: 2.3735569508229286

Epoch: 375| Step: 0
Training loss: 1.3654237542168774
Validation loss: 2.41783621991375

Epoch: 5| Step: 1
Training loss: 1.5433029392344706
Validation loss: 2.3627024944730763

Epoch: 5| Step: 2
Training loss: 0.986116413018625
Validation loss: 2.366022100427236

Epoch: 5| Step: 3
Training loss: 1.0210558720095873
Validation loss: 2.3123999909091295

Epoch: 5| Step: 4
Training loss: 0.9801183431560095
Validation loss: 2.394640368906648

Epoch: 5| Step: 5
Training loss: 1.4280461128867674
Validation loss: 2.3374618315375826

Epoch: 5| Step: 6
Training loss: 1.6946793178028103
Validation loss: 2.445378306016881

Epoch: 5| Step: 7
Training loss: 1.418349790212425
Validation loss: 2.357457753835578

Epoch: 5| Step: 8
Training loss: 1.7290328636642456
Validation loss: 2.351090161071401

Epoch: 5| Step: 9
Training loss: 1.3584611824732051
Validation loss: 2.3481932079874497

Epoch: 5| Step: 10
Training loss: 1.4262927666286067
Validation loss: 2.355406406876605

Epoch: 376| Step: 0
Training loss: 1.5732320338844443
Validation loss: 2.345617539354904

Epoch: 5| Step: 1
Training loss: 1.7262300887675592
Validation loss: 2.372913992404894

Epoch: 5| Step: 2
Training loss: 1.2723025547625877
Validation loss: 2.3496187245510924

Epoch: 5| Step: 3
Training loss: 2.072098332446753
Validation loss: 2.33834112687734

Epoch: 5| Step: 4
Training loss: 1.2002713929685087
Validation loss: 2.409381456253286

Epoch: 5| Step: 5
Training loss: 1.5113375081993385
Validation loss: 2.3262966993816967

Epoch: 5| Step: 6
Training loss: 1.1615103580244541
Validation loss: 2.3419090155951587

Epoch: 5| Step: 7
Training loss: 1.1726552781540047
Validation loss: 2.3997709711922424

Epoch: 5| Step: 8
Training loss: 1.068303917486301
Validation loss: 2.424352160616029

Epoch: 5| Step: 9
Training loss: 1.0979182246352162
Validation loss: 2.3948907286412533

Epoch: 5| Step: 10
Training loss: 1.2596445897827568
Validation loss: 2.3841147729447236

Epoch: 377| Step: 0
Training loss: 1.5121244925963004
Validation loss: 2.382506344858044

Epoch: 5| Step: 1
Training loss: 0.9518160352271159
Validation loss: 2.3597539608121516

Epoch: 5| Step: 2
Training loss: 1.4189300221238277
Validation loss: 2.309418566143816

Epoch: 5| Step: 3
Training loss: 1.0835522039324412
Validation loss: 2.3685403507099165

Epoch: 5| Step: 4
Training loss: 1.0492255170182119
Validation loss: 2.3437897490818984

Epoch: 5| Step: 5
Training loss: 1.4132409000910153
Validation loss: 2.371070732095119

Epoch: 5| Step: 6
Training loss: 1.3974507009583153
Validation loss: 2.3497927329942976

Epoch: 5| Step: 7
Training loss: 2.2814163774409657
Validation loss: 2.40407501567516

Epoch: 5| Step: 8
Training loss: 1.1840371286589144
Validation loss: 2.338591790613907

Epoch: 5| Step: 9
Training loss: 1.38262601985123
Validation loss: 2.3582396067694087

Epoch: 5| Step: 10
Training loss: 1.1678220216578825
Validation loss: 2.3106743752045213

Epoch: 378| Step: 0
Training loss: 1.624989949708817
Validation loss: 2.3152359235031335

Epoch: 5| Step: 1
Training loss: 1.405382100477623
Validation loss: 2.357675639726271

Epoch: 5| Step: 2
Training loss: 1.3029817863825002
Validation loss: 2.3804664099420054

Epoch: 5| Step: 3
Training loss: 1.3755846947844868
Validation loss: 2.3403562612117037

Epoch: 5| Step: 4
Training loss: 2.051650438944365
Validation loss: 2.3378120736970294

Epoch: 5| Step: 5
Training loss: 1.058650504417265
Validation loss: 2.3111229432404343

Epoch: 5| Step: 6
Training loss: 1.2504427125873334
Validation loss: 2.3767137534928504

Epoch: 5| Step: 7
Training loss: 0.8615242525009075
Validation loss: 2.3802215072458623

Epoch: 5| Step: 8
Training loss: 1.4517127937553551
Validation loss: 2.36514780790454

Epoch: 5| Step: 9
Training loss: 1.2871296118388482
Validation loss: 2.4155158809667476

Epoch: 5| Step: 10
Training loss: 1.3246355329229593
Validation loss: 2.3931179240150815

Epoch: 379| Step: 0
Training loss: 1.0651873654776907
Validation loss: 2.3755033927805864

Epoch: 5| Step: 1
Training loss: 1.3145861622114419
Validation loss: 2.411783750350464

Epoch: 5| Step: 2
Training loss: 1.1891839986677326
Validation loss: 2.392443846566945

Epoch: 5| Step: 3
Training loss: 1.4771773254160336
Validation loss: 2.339272445448021

Epoch: 5| Step: 4
Training loss: 1.1500445688982104
Validation loss: 2.3871215600700526

Epoch: 5| Step: 5
Training loss: 1.2324045122619305
Validation loss: 2.3795434834583387

Epoch: 5| Step: 6
Training loss: 1.3004756259152066
Validation loss: 2.355105333191813

Epoch: 5| Step: 7
Training loss: 1.5415343751938115
Validation loss: 2.2929782690093914

Epoch: 5| Step: 8
Training loss: 1.318770642593595
Validation loss: 2.3449593528331127

Epoch: 5| Step: 9
Training loss: 2.056911990384553
Validation loss: 2.323230017237778

Epoch: 5| Step: 10
Training loss: 1.1761504952708814
Validation loss: 2.324201621267119

Epoch: 380| Step: 0
Training loss: 1.2410764703912835
Validation loss: 2.4044240032903694

Epoch: 5| Step: 1
Training loss: 1.3068158726426782
Validation loss: 2.328939146442827

Epoch: 5| Step: 2
Training loss: 1.2230213339279072
Validation loss: 2.3557771029809036

Epoch: 5| Step: 3
Training loss: 1.2922352441826055
Validation loss: 2.3410405276721153

Epoch: 5| Step: 4
Training loss: 1.0885518391451772
Validation loss: 2.3673283419220468

Epoch: 5| Step: 5
Training loss: 1.2100799969955387
Validation loss: 2.340934846752998

Epoch: 5| Step: 6
Training loss: 1.193380102798582
Validation loss: 2.39654837946413

Epoch: 5| Step: 7
Training loss: 1.500721360639497
Validation loss: 2.308636491870295

Epoch: 5| Step: 8
Training loss: 1.947226322125617
Validation loss: 2.351516628884323

Epoch: 5| Step: 9
Training loss: 1.386280044147537
Validation loss: 2.336556593248647

Epoch: 5| Step: 10
Training loss: 1.4407596119777322
Validation loss: 2.373784941263008

Epoch: 381| Step: 0
Training loss: 1.0145921590579152
Validation loss: 2.3970524575692074

Epoch: 5| Step: 1
Training loss: 1.2758162578351198
Validation loss: 2.332190880145836

Epoch: 5| Step: 2
Training loss: 1.3802081653906761
Validation loss: 2.31300022221456

Epoch: 5| Step: 3
Training loss: 1.880987271944714
Validation loss: 2.343395530666913

Epoch: 5| Step: 4
Training loss: 1.39904183909941
Validation loss: 2.3811528491887253

Epoch: 5| Step: 5
Training loss: 1.563982069937133
Validation loss: 2.4181928394794507

Epoch: 5| Step: 6
Training loss: 1.0329715923638938
Validation loss: 2.270612220652665

Epoch: 5| Step: 7
Training loss: 1.376884296401437
Validation loss: 2.378111003691008

Epoch: 5| Step: 8
Training loss: 1.3997912114994207
Validation loss: 2.4029324528972915

Epoch: 5| Step: 9
Training loss: 1.5326759549761444
Validation loss: 2.3333541111819383

Epoch: 5| Step: 10
Training loss: 0.9966268272368798
Validation loss: 2.3079978887793193

Epoch: 382| Step: 0
Training loss: 1.3775802158324053
Validation loss: 2.3106926715213003

Epoch: 5| Step: 1
Training loss: 1.2203250879476144
Validation loss: 2.3747045487554477

Epoch: 5| Step: 2
Training loss: 1.857315589920443
Validation loss: 2.3480904305486408

Epoch: 5| Step: 3
Training loss: 1.7168499935121817
Validation loss: 2.377873004757349

Epoch: 5| Step: 4
Training loss: 1.2709901379428503
Validation loss: 2.3746326056583817

Epoch: 5| Step: 5
Training loss: 1.0090699741799094
Validation loss: 2.390020095966652

Epoch: 5| Step: 6
Training loss: 1.4683284560406522
Validation loss: 2.397238566367544

Epoch: 5| Step: 7
Training loss: 1.2057041909890327
Validation loss: 2.3122879486506296

Epoch: 5| Step: 8
Training loss: 1.0315798029796175
Validation loss: 2.3402796067203857

Epoch: 5| Step: 9
Training loss: 1.4281836766849583
Validation loss: 2.372566288791643

Epoch: 5| Step: 10
Training loss: 1.1938503522783976
Validation loss: 2.3750230262387086

Epoch: 383| Step: 0
Training loss: 0.9312150090959598
Validation loss: 2.35594721010875

Epoch: 5| Step: 1
Training loss: 1.4599836366859968
Validation loss: 2.388313794991669

Epoch: 5| Step: 2
Training loss: 0.7649411241776058
Validation loss: 2.3944160278329782

Epoch: 5| Step: 3
Training loss: 2.1369309677377193
Validation loss: 2.4306985353838813

Epoch: 5| Step: 4
Training loss: 1.620431199319649
Validation loss: 2.405019077991741

Epoch: 5| Step: 5
Training loss: 1.3891523042534022
Validation loss: 2.419553951663251

Epoch: 5| Step: 6
Training loss: 1.314571290280917
Validation loss: 2.3581387381032535

Epoch: 5| Step: 7
Training loss: 1.51416936759029
Validation loss: 2.3945102656939374

Epoch: 5| Step: 8
Training loss: 1.3498654157169543
Validation loss: 2.359201875987678

Epoch: 5| Step: 9
Training loss: 1.2515826220091388
Validation loss: 2.3819889640572085

Epoch: 5| Step: 10
Training loss: 1.3235894792614178
Validation loss: 2.382488306276782

Epoch: 384| Step: 0
Training loss: 0.9008419205017811
Validation loss: 2.313426972999135

Epoch: 5| Step: 1
Training loss: 1.088172095439229
Validation loss: 2.3623814900507885

Epoch: 5| Step: 2
Training loss: 1.2432213565542207
Validation loss: 2.355965828402812

Epoch: 5| Step: 3
Training loss: 1.2582136189858966
Validation loss: 2.33654417415058

Epoch: 5| Step: 4
Training loss: 1.1183739610920647
Validation loss: 2.3478174487824073

Epoch: 5| Step: 5
Training loss: 1.3458257212389138
Validation loss: 2.3853315116176153

Epoch: 5| Step: 6
Training loss: 1.1485112484458746
Validation loss: 2.2967683277496516

Epoch: 5| Step: 7
Training loss: 1.4994627467275912
Validation loss: 2.2975276588707603

Epoch: 5| Step: 8
Training loss: 1.2787067012970155
Validation loss: 2.3739151206616445

Epoch: 5| Step: 9
Training loss: 2.1428130168004587
Validation loss: 2.394637629037591

Epoch: 5| Step: 10
Training loss: 1.7226463542489652
Validation loss: 2.3750888525032288

Epoch: 385| Step: 0
Training loss: 1.2665289017564403
Validation loss: 2.381508391095354

Epoch: 5| Step: 1
Training loss: 1.484960340233587
Validation loss: 2.362605130214012

Epoch: 5| Step: 2
Training loss: 2.121881552954374
Validation loss: 2.370871987535857

Epoch: 5| Step: 3
Training loss: 1.1964475939281585
Validation loss: 2.414462766707672

Epoch: 5| Step: 4
Training loss: 0.9138033572898603
Validation loss: 2.392676306412119

Epoch: 5| Step: 5
Training loss: 1.5464387528988288
Validation loss: 2.4261562152791543

Epoch: 5| Step: 6
Training loss: 1.3801034803568988
Validation loss: 2.3108400674711493

Epoch: 5| Step: 7
Training loss: 1.352836097023302
Validation loss: 2.3436406170878294

Epoch: 5| Step: 8
Training loss: 0.8702365780490942
Validation loss: 2.367828914031081

Epoch: 5| Step: 9
Training loss: 0.9764166761242421
Validation loss: 2.2955972123712494

Epoch: 5| Step: 10
Training loss: 1.0858364469864634
Validation loss: 2.3385132639595514

Epoch: 386| Step: 0
Training loss: 1.2399556965758192
Validation loss: 2.35009777024545

Epoch: 5| Step: 1
Training loss: 1.4775912621676055
Validation loss: 2.4089962433097933

Epoch: 5| Step: 2
Training loss: 1.342587611431562
Validation loss: 2.4082270531917325

Epoch: 5| Step: 3
Training loss: 1.106713662260372
Validation loss: 2.378845963050193

Epoch: 5| Step: 4
Training loss: 1.464395357805327
Validation loss: 2.4644262588450245

Epoch: 5| Step: 5
Training loss: 1.3002973693246038
Validation loss: 2.358559483613036

Epoch: 5| Step: 6
Training loss: 1.0051060494414403
Validation loss: 2.363325791738801

Epoch: 5| Step: 7
Training loss: 0.9935889371469536
Validation loss: 2.33421228996553

Epoch: 5| Step: 8
Training loss: 1.6591842857867416
Validation loss: 2.430356526075535

Epoch: 5| Step: 9
Training loss: 1.962473112274445
Validation loss: 2.310548370657368

Epoch: 5| Step: 10
Training loss: 0.8774391985203688
Validation loss: 2.3580929449030434

Epoch: 387| Step: 0
Training loss: 1.074923142191835
Validation loss: 2.3940069962356456

Epoch: 5| Step: 1
Training loss: 1.4072474439078988
Validation loss: 2.3480165168385456

Epoch: 5| Step: 2
Training loss: 1.5734542618496066
Validation loss: 2.3351563983847847

Epoch: 5| Step: 3
Training loss: 1.4696505606127765
Validation loss: 2.3900878214789674

Epoch: 5| Step: 4
Training loss: 1.839926165053011
Validation loss: 2.35133578488185

Epoch: 5| Step: 5
Training loss: 1.2234497420476773
Validation loss: 2.328952090983829

Epoch: 5| Step: 6
Training loss: 1.2335819642444337
Validation loss: 2.3930570491494825

Epoch: 5| Step: 7
Training loss: 1.0439080284319333
Validation loss: 2.297910315084117

Epoch: 5| Step: 8
Training loss: 1.131713228592761
Validation loss: 2.25459282761812

Epoch: 5| Step: 9
Training loss: 1.0354533219069533
Validation loss: 2.433117105755322

Epoch: 5| Step: 10
Training loss: 1.3249218179921047
Validation loss: 2.3544730327328907

Epoch: 388| Step: 0
Training loss: 1.0539860406056163
Validation loss: 2.4332010997973015

Epoch: 5| Step: 1
Training loss: 1.4372483738140065
Validation loss: 2.3998784724951845

Epoch: 5| Step: 2
Training loss: 1.3633251893578293
Validation loss: 2.348673821523332

Epoch: 5| Step: 3
Training loss: 1.3770010432569753
Validation loss: 2.343374645844441

Epoch: 5| Step: 4
Training loss: 1.1161746255303129
Validation loss: 2.3225716179597655

Epoch: 5| Step: 5
Training loss: 1.8646497519258618
Validation loss: 2.370405510110126

Epoch: 5| Step: 6
Training loss: 1.095546881267605
Validation loss: 2.4582339044746435

Epoch: 5| Step: 7
Training loss: 1.3535841887311522
Validation loss: 2.334666151281362

Epoch: 5| Step: 8
Training loss: 1.3017882152535591
Validation loss: 2.357914490572906

Epoch: 5| Step: 9
Training loss: 1.21395817213885
Validation loss: 2.3855292299111595

Epoch: 5| Step: 10
Training loss: 1.2722294231601543
Validation loss: 2.3681217779730117

Epoch: 389| Step: 0
Training loss: 2.115119515327073
Validation loss: 2.391282554904756

Epoch: 5| Step: 1
Training loss: 1.2724063653727342
Validation loss: 2.3430024232494056

Epoch: 5| Step: 2
Training loss: 1.4038619215414414
Validation loss: 2.37871453388477

Epoch: 5| Step: 3
Training loss: 1.1553320462732763
Validation loss: 2.2962977699940756

Epoch: 5| Step: 4
Training loss: 1.2858482747045268
Validation loss: 2.320271154892774

Epoch: 5| Step: 5
Training loss: 1.4256365977028356
Validation loss: 2.3029200497224007

Epoch: 5| Step: 6
Training loss: 1.3335430705492142
Validation loss: 2.3554260100920876

Epoch: 5| Step: 7
Training loss: 0.8611927228797336
Validation loss: 2.3977146190320324

Epoch: 5| Step: 8
Training loss: 0.9513612593902923
Validation loss: 2.3078873051451496

Epoch: 5| Step: 9
Training loss: 1.1728580674777975
Validation loss: 2.3968924372813754

Epoch: 5| Step: 10
Training loss: 1.0017063959931065
Validation loss: 2.4057855572034317

Epoch: 390| Step: 0
Training loss: 1.0662565580392205
Validation loss: 2.338961898246285

Epoch: 5| Step: 1
Training loss: 1.209462602779169
Validation loss: 2.3941641736991928

Epoch: 5| Step: 2
Training loss: 1.2983010965212938
Validation loss: 2.298164305497029

Epoch: 5| Step: 3
Training loss: 1.2607749976063267
Validation loss: 2.354754983619085

Epoch: 5| Step: 4
Training loss: 1.41404753619122
Validation loss: 2.3685527113604987

Epoch: 5| Step: 5
Training loss: 1.2226281696056578
Validation loss: 2.3403495491009108

Epoch: 5| Step: 6
Training loss: 1.2520532910153945
Validation loss: 2.340787189917417

Epoch: 5| Step: 7
Training loss: 1.2894594910564747
Validation loss: 2.390628889492087

Epoch: 5| Step: 8
Training loss: 1.1743982742545054
Validation loss: 2.4155658857060653

Epoch: 5| Step: 9
Training loss: 1.3272539311600648
Validation loss: 2.3312734251080647

Epoch: 5| Step: 10
Training loss: 2.0550659759400203
Validation loss: 2.3367113486118822

Epoch: 391| Step: 0
Training loss: 1.3531012623314809
Validation loss: 2.331441476721071

Epoch: 5| Step: 1
Training loss: 0.8191533572945155
Validation loss: 2.364790692998797

Epoch: 5| Step: 2
Training loss: 1.0455835261901238
Validation loss: 2.3201475159701213

Epoch: 5| Step: 3
Training loss: 1.96104497728994
Validation loss: 2.334614281991955

Epoch: 5| Step: 4
Training loss: 1.031701769275263
Validation loss: 2.35007853820757

Epoch: 5| Step: 5
Training loss: 1.2733992120334445
Validation loss: 2.3308677349374656

Epoch: 5| Step: 6
Training loss: 1.5976951986102836
Validation loss: 2.307843960655691

Epoch: 5| Step: 7
Training loss: 1.0886718574800411
Validation loss: 2.405780605819284

Epoch: 5| Step: 8
Training loss: 1.343731414311535
Validation loss: 2.3699717247157506

Epoch: 5| Step: 9
Training loss: 1.3045945734063529
Validation loss: 2.361121201016098

Epoch: 5| Step: 10
Training loss: 1.3902520526170454
Validation loss: 2.36668127362488

Epoch: 392| Step: 0
Training loss: 1.4029916950613546
Validation loss: 2.3209203169339943

Epoch: 5| Step: 1
Training loss: 1.9037360827913499
Validation loss: 2.368872953115681

Epoch: 5| Step: 2
Training loss: 1.0746012613537241
Validation loss: 2.378360151295245

Epoch: 5| Step: 3
Training loss: 1.2019983937067098
Validation loss: 2.2910639534305006

Epoch: 5| Step: 4
Training loss: 1.362705054295478
Validation loss: 2.3316831474082678

Epoch: 5| Step: 5
Training loss: 1.1020076204095295
Validation loss: 2.331392081305363

Epoch: 5| Step: 6
Training loss: 1.1464874423504272
Validation loss: 2.3541384056486554

Epoch: 5| Step: 7
Training loss: 1.0373086683957928
Validation loss: 2.320244922484588

Epoch: 5| Step: 8
Training loss: 1.2473905984002833
Validation loss: 2.4100255071302628

Epoch: 5| Step: 9
Training loss: 1.4264198022943033
Validation loss: 2.305840283094202

Epoch: 5| Step: 10
Training loss: 1.5852616096026948
Validation loss: 2.3836429971612967

Epoch: 393| Step: 0
Training loss: 1.3193498973545552
Validation loss: 2.434369589965863

Epoch: 5| Step: 1
Training loss: 1.6215597562974384
Validation loss: 2.408777380697526

Epoch: 5| Step: 2
Training loss: 1.0143361643692042
Validation loss: 2.331684022594746

Epoch: 5| Step: 3
Training loss: 0.9959978543664426
Validation loss: 2.4200933587129527

Epoch: 5| Step: 4
Training loss: 1.4589288131572258
Validation loss: 2.4271604460665572

Epoch: 5| Step: 5
Training loss: 0.8678536820384727
Validation loss: 2.41493215114825

Epoch: 5| Step: 6
Training loss: 1.315562444726487
Validation loss: 2.3617434735387897

Epoch: 5| Step: 7
Training loss: 1.8751748321403339
Validation loss: 2.2907859370222057

Epoch: 5| Step: 8
Training loss: 1.2949804232380597
Validation loss: 2.3284002167419855

Epoch: 5| Step: 9
Training loss: 1.287528032164352
Validation loss: 2.359194844226876

Epoch: 5| Step: 10
Training loss: 0.973371618010016
Validation loss: 2.3367790988579067

Epoch: 394| Step: 0
Training loss: 1.208514638430946
Validation loss: 2.3672421373031645

Epoch: 5| Step: 1
Training loss: 1.630559726986305
Validation loss: 2.3783479116795148

Epoch: 5| Step: 2
Training loss: 1.5264472379090734
Validation loss: 2.3104373898074213

Epoch: 5| Step: 3
Training loss: 0.7871471613671591
Validation loss: 2.4134952207718054

Epoch: 5| Step: 4
Training loss: 1.180708285655966
Validation loss: 2.322034155999639

Epoch: 5| Step: 5
Training loss: 0.8624881536250717
Validation loss: 2.349814412842552

Epoch: 5| Step: 6
Training loss: 1.4590715538033225
Validation loss: 2.31444552861529

Epoch: 5| Step: 7
Training loss: 1.339306693139844
Validation loss: 2.428315542556805

Epoch: 5| Step: 8
Training loss: 1.0284333923127988
Validation loss: 2.371526878839333

Epoch: 5| Step: 9
Training loss: 0.5941316231491464
Validation loss: 2.3900317424383015

Epoch: 5| Step: 10
Training loss: 2.262683405739874
Validation loss: 2.3448002420783394

Epoch: 395| Step: 0
Training loss: 1.4942914101305316
Validation loss: 2.405218725093596

Epoch: 5| Step: 1
Training loss: 0.8729786686208343
Validation loss: 2.3251654795509378

Epoch: 5| Step: 2
Training loss: 1.1636490055435174
Validation loss: 2.3548111450412668

Epoch: 5| Step: 3
Training loss: 1.1387820574941108
Validation loss: 2.3430761843978076

Epoch: 5| Step: 4
Training loss: 1.1344968178655281
Validation loss: 2.361377654170311

Epoch: 5| Step: 5
Training loss: 1.2974256702219886
Validation loss: 2.409777865298817

Epoch: 5| Step: 6
Training loss: 1.4221591875061506
Validation loss: 2.3752391977541762

Epoch: 5| Step: 7
Training loss: 1.3735665739163672
Validation loss: 2.3649804657867755

Epoch: 5| Step: 8
Training loss: 1.6289208866623581
Validation loss: 2.40317585671543

Epoch: 5| Step: 9
Training loss: 1.2524926128664529
Validation loss: 2.3459467404001

Epoch: 5| Step: 10
Training loss: 1.9015007266038966
Validation loss: 2.3213003254594935

Epoch: 396| Step: 0
Training loss: 0.9941542049297352
Validation loss: 2.382180867027516

Epoch: 5| Step: 1
Training loss: 1.2689554640046987
Validation loss: 2.3887146897542535

Epoch: 5| Step: 2
Training loss: 1.3172608270292492
Validation loss: 2.4050710896076604

Epoch: 5| Step: 3
Training loss: 1.2487267685448522
Validation loss: 2.385711433184514

Epoch: 5| Step: 4
Training loss: 1.1254022197132718
Validation loss: 2.4533129044615607

Epoch: 5| Step: 5
Training loss: 1.4095992998840203
Validation loss: 2.388088857710462

Epoch: 5| Step: 6
Training loss: 0.9170193896661685
Validation loss: 2.3524820589395308

Epoch: 5| Step: 7
Training loss: 1.0663077060874993
Validation loss: 2.4173263318499276

Epoch: 5| Step: 8
Training loss: 2.032141621843327
Validation loss: 2.335906216172563

Epoch: 5| Step: 9
Training loss: 1.1806948573385208
Validation loss: 2.3331368586301364

Epoch: 5| Step: 10
Training loss: 1.2711418381910347
Validation loss: 2.3105638015020697

Epoch: 397| Step: 0
Training loss: 0.9220860773026471
Validation loss: 2.3250212367271375

Epoch: 5| Step: 1
Training loss: 0.9335670307757153
Validation loss: 2.387966493598063

Epoch: 5| Step: 2
Training loss: 1.4065185290491533
Validation loss: 2.314286532709983

Epoch: 5| Step: 3
Training loss: 1.8028102209930112
Validation loss: 2.3953112100626446

Epoch: 5| Step: 4
Training loss: 1.09459490158731
Validation loss: 2.369697654848964

Epoch: 5| Step: 5
Training loss: 1.51494055955566
Validation loss: 2.3351406848711638

Epoch: 5| Step: 6
Training loss: 1.1887631975759043
Validation loss: 2.3506432744181693

Epoch: 5| Step: 7
Training loss: 1.0287866938595203
Validation loss: 2.397155172008355

Epoch: 5| Step: 8
Training loss: 1.2075174087154061
Validation loss: 2.328046862500962

Epoch: 5| Step: 9
Training loss: 1.292472628925269
Validation loss: 2.3556853615686566

Epoch: 5| Step: 10
Training loss: 1.4455128298928681
Validation loss: 2.3745073175543125

Epoch: 398| Step: 0
Training loss: 0.9938186393880665
Validation loss: 2.35636786387527

Epoch: 5| Step: 1
Training loss: 0.9073902717437117
Validation loss: 2.3146246191002753

Epoch: 5| Step: 2
Training loss: 1.4305688194886295
Validation loss: 2.339548417490855

Epoch: 5| Step: 3
Training loss: 1.3755705689992557
Validation loss: 2.3900861878879387

Epoch: 5| Step: 4
Training loss: 1.1957289026541835
Validation loss: 2.3715002183181606

Epoch: 5| Step: 5
Training loss: 1.1756736731504775
Validation loss: 2.368485521463239

Epoch: 5| Step: 6
Training loss: 0.8883479607459116
Validation loss: 2.3449063910930943

Epoch: 5| Step: 7
Training loss: 1.2206995605416708
Validation loss: 2.3902958855116645

Epoch: 5| Step: 8
Training loss: 1.8384477052821961
Validation loss: 2.320020997440734

Epoch: 5| Step: 9
Training loss: 1.4639094513943525
Validation loss: 2.342590859470678

Epoch: 5| Step: 10
Training loss: 1.1988000791270268
Validation loss: 2.4127174195945633

Epoch: 399| Step: 0
Training loss: 1.8597961718128406
Validation loss: 2.351544170085393

Epoch: 5| Step: 1
Training loss: 1.1540637095465933
Validation loss: 2.3514633607514686

Epoch: 5| Step: 2
Training loss: 1.195770076359058
Validation loss: 2.411513492415213

Epoch: 5| Step: 3
Training loss: 0.9107085422794237
Validation loss: 2.33821622623664

Epoch: 5| Step: 4
Training loss: 1.204453069733035
Validation loss: 2.3342846188905044

Epoch: 5| Step: 5
Training loss: 1.3912124678766546
Validation loss: 2.3350870607354595

Epoch: 5| Step: 6
Training loss: 1.6366597531412845
Validation loss: 2.393151373732957

Epoch: 5| Step: 7
Training loss: 1.5838884166997957
Validation loss: 2.4144078006517686

Epoch: 5| Step: 8
Training loss: 0.6710216736640261
Validation loss: 2.397388348099627

Epoch: 5| Step: 9
Training loss: 1.2042519876860849
Validation loss: 2.3614180542912804

Epoch: 5| Step: 10
Training loss: 0.764503319076309
Validation loss: 2.293443758938922

Epoch: 400| Step: 0
Training loss: 1.1746095921852715
Validation loss: 2.372724768791444

Epoch: 5| Step: 1
Training loss: 1.238014360902285
Validation loss: 2.376413411583556

Epoch: 5| Step: 2
Training loss: 1.4763632342188109
Validation loss: 2.3721991421748383

Epoch: 5| Step: 3
Training loss: 1.760805421900775
Validation loss: 2.435803168014968

Epoch: 5| Step: 4
Training loss: 1.5462669179202106
Validation loss: 2.394300980003059

Epoch: 5| Step: 5
Training loss: 1.4795258672424756
Validation loss: 2.3339346368725984

Epoch: 5| Step: 6
Training loss: 0.953371954021137
Validation loss: 2.301612221891587

Epoch: 5| Step: 7
Training loss: 1.37031650520879
Validation loss: 2.3410900704797664

Epoch: 5| Step: 8
Training loss: 0.9355999766273545
Validation loss: 2.328089601806868

Epoch: 5| Step: 9
Training loss: 1.1651899778813126
Validation loss: 2.3731095821971477

Epoch: 5| Step: 10
Training loss: 0.9124555563881319
Validation loss: 2.372995282865705

Epoch: 401| Step: 0
Training loss: 1.9093239185848803
Validation loss: 2.3852774219430857

Epoch: 5| Step: 1
Training loss: 1.3792980815284743
Validation loss: 2.375411137830078

Epoch: 5| Step: 2
Training loss: 0.9452391982229404
Validation loss: 2.4194510691998716

Epoch: 5| Step: 3
Training loss: 1.4219875081582658
Validation loss: 2.3668406448416945

Epoch: 5| Step: 4
Training loss: 1.3940114994806192
Validation loss: 2.3653898780343665

Epoch: 5| Step: 5
Training loss: 1.2000966788129717
Validation loss: 2.374912614947259

Epoch: 5| Step: 6
Training loss: 1.0617155096076207
Validation loss: 2.3529356838886213

Epoch: 5| Step: 7
Training loss: 1.1583970214752768
Validation loss: 2.3514980707570348

Epoch: 5| Step: 8
Training loss: 0.9427788253197151
Validation loss: 2.355359857429425

Epoch: 5| Step: 9
Training loss: 1.385832812495926
Validation loss: 2.29886044311138

Epoch: 5| Step: 10
Training loss: 1.487523404105576
Validation loss: 2.3940257179662208

Epoch: 402| Step: 0
Training loss: 1.1464451745787145
Validation loss: 2.3962375194709766

Epoch: 5| Step: 1
Training loss: 1.2289852342486796
Validation loss: 2.3214613928058467

Epoch: 5| Step: 2
Training loss: 2.0645101750484103
Validation loss: 2.4322539323944823

Epoch: 5| Step: 3
Training loss: 1.0587456513262619
Validation loss: 2.414012420577689

Epoch: 5| Step: 4
Training loss: 0.9455178723413755
Validation loss: 2.431844404353138

Epoch: 5| Step: 5
Training loss: 1.5661154308186596
Validation loss: 2.4555533054312852

Epoch: 5| Step: 6
Training loss: 1.05756229388504
Validation loss: 2.3980493948007644

Epoch: 5| Step: 7
Training loss: 1.3074821191589854
Validation loss: 2.4235531606023195

Epoch: 5| Step: 8
Training loss: 1.6003433425395377
Validation loss: 2.4186041564970435

Epoch: 5| Step: 9
Training loss: 1.1483443864715828
Validation loss: 2.376153090668324

Epoch: 5| Step: 10
Training loss: 0.9465083920166738
Validation loss: 2.3218190054274435

Epoch: 403| Step: 0
Training loss: 1.1717395449872494
Validation loss: 2.3553612517058333

Epoch: 5| Step: 1
Training loss: 1.1297039131038025
Validation loss: 2.3274137042566285

Epoch: 5| Step: 2
Training loss: 1.1740679250007489
Validation loss: 2.3128630850013727

Epoch: 5| Step: 3
Training loss: 1.3422573582118402
Validation loss: 2.3843403845818147

Epoch: 5| Step: 4
Training loss: 1.5668411222005338
Validation loss: 2.2882970168176837

Epoch: 5| Step: 5
Training loss: 0.834711548442022
Validation loss: 2.413480040669842

Epoch: 5| Step: 6
Training loss: 1.892727778042173
Validation loss: 2.3635515688094526

Epoch: 5| Step: 7
Training loss: 1.1564460278924225
Validation loss: 2.4129046825488767

Epoch: 5| Step: 8
Training loss: 1.4711496756807634
Validation loss: 2.3431738393431316

Epoch: 5| Step: 9
Training loss: 1.323451086918108
Validation loss: 2.316732563510738

Epoch: 5| Step: 10
Training loss: 1.0093137811100712
Validation loss: 2.330514310410328

Epoch: 404| Step: 0
Training loss: 1.4059968932512235
Validation loss: 2.3521343943895974

Epoch: 5| Step: 1
Training loss: 1.5853918480486553
Validation loss: 2.4000884617461913

Epoch: 5| Step: 2
Training loss: 1.1329487685752548
Validation loss: 2.3782694774764077

Epoch: 5| Step: 3
Training loss: 0.6404303743545465
Validation loss: 2.3305866215510203

Epoch: 5| Step: 4
Training loss: 1.0861500045000188
Validation loss: 2.367142219750708

Epoch: 5| Step: 5
Training loss: 1.9101734121600886
Validation loss: 2.3799966690331087

Epoch: 5| Step: 6
Training loss: 0.9334665634795267
Validation loss: 2.3494901657806335

Epoch: 5| Step: 7
Training loss: 1.2325499841331125
Validation loss: 2.3484768428695513

Epoch: 5| Step: 8
Training loss: 1.0969326036765736
Validation loss: 2.3991816859487605

Epoch: 5| Step: 9
Training loss: 1.4472989839114712
Validation loss: 2.375623910339197

Epoch: 5| Step: 10
Training loss: 1.1039053169781088
Validation loss: 2.416465102358836

Epoch: 405| Step: 0
Training loss: 1.0495473430945021
Validation loss: 2.3479204202411914

Epoch: 5| Step: 1
Training loss: 1.0526364197745193
Validation loss: 2.3673921589546523

Epoch: 5| Step: 2
Training loss: 1.1214378971791592
Validation loss: 2.384710171174803

Epoch: 5| Step: 3
Training loss: 0.9385411838667147
Validation loss: 2.331711978912596

Epoch: 5| Step: 4
Training loss: 1.897136666413792
Validation loss: 2.36145447710081

Epoch: 5| Step: 5
Training loss: 1.3516516683634587
Validation loss: 2.3390530880435296

Epoch: 5| Step: 6
Training loss: 1.3188495996115588
Validation loss: 2.3846389459913024

Epoch: 5| Step: 7
Training loss: 0.971332491853603
Validation loss: 2.2853071192589836

Epoch: 5| Step: 8
Training loss: 1.432994748571108
Validation loss: 2.3743893313753253

Epoch: 5| Step: 9
Training loss: 1.364652496021744
Validation loss: 2.3400018337893953

Epoch: 5| Step: 10
Training loss: 1.2074499792791595
Validation loss: 2.3849375081850153

Epoch: 406| Step: 0
Training loss: 1.7813738060472704
Validation loss: 2.3377408496521457

Epoch: 5| Step: 1
Training loss: 1.356557579145841
Validation loss: 2.337414303671177

Epoch: 5| Step: 2
Training loss: 1.1836698904191418
Validation loss: 2.486942253919075

Epoch: 5| Step: 3
Training loss: 1.6131268074058034
Validation loss: 2.3390430386472154

Epoch: 5| Step: 4
Training loss: 1.1794675912580748
Validation loss: 2.379841884518444

Epoch: 5| Step: 5
Training loss: 0.9289747118284907
Validation loss: 2.3893480755864855

Epoch: 5| Step: 6
Training loss: 1.0643345198042753
Validation loss: 2.3644932626780357

Epoch: 5| Step: 7
Training loss: 1.1274047687008064
Validation loss: 2.30478948996996

Epoch: 5| Step: 8
Training loss: 1.1437342866745819
Validation loss: 2.4247647355604016

Epoch: 5| Step: 9
Training loss: 1.2583488126564768
Validation loss: 2.3333001921830117

Epoch: 5| Step: 10
Training loss: 0.8653757225296992
Validation loss: 2.3470937720392895

Epoch: 407| Step: 0
Training loss: 1.298256471502819
Validation loss: 2.3820496966630347

Epoch: 5| Step: 1
Training loss: 0.9114804110805003
Validation loss: 2.2989520755344786

Epoch: 5| Step: 2
Training loss: 1.423767004807413
Validation loss: 2.3176835312621806

Epoch: 5| Step: 3
Training loss: 1.1543987506763205
Validation loss: 2.3914975509530336

Epoch: 5| Step: 4
Training loss: 1.2805540008746952
Validation loss: 2.3604227114094822

Epoch: 5| Step: 5
Training loss: 1.2867360246491204
Validation loss: 2.327274860747324

Epoch: 5| Step: 6
Training loss: 0.8042214164148644
Validation loss: 2.294676210358189

Epoch: 5| Step: 7
Training loss: 1.1528415445260802
Validation loss: 2.3969380983298323

Epoch: 5| Step: 8
Training loss: 0.7478488829418526
Validation loss: 2.2863778707422724

Epoch: 5| Step: 9
Training loss: 2.18871404473419
Validation loss: 2.402485043912364

Epoch: 5| Step: 10
Training loss: 1.2910840453515235
Validation loss: 2.376018536763828

Epoch: 408| Step: 0
Training loss: 1.182794433213887
Validation loss: 2.3382781111109034

Epoch: 5| Step: 1
Training loss: 1.1734882186311255
Validation loss: 2.391561073040844

Epoch: 5| Step: 2
Training loss: 1.8824128165960199
Validation loss: 2.3280251269526375

Epoch: 5| Step: 3
Training loss: 1.21458785621669
Validation loss: 2.3333184599585484

Epoch: 5| Step: 4
Training loss: 1.2155063208380754
Validation loss: 2.3685058947853

Epoch: 5| Step: 5
Training loss: 1.1995897247384453
Validation loss: 2.350752705552208

Epoch: 5| Step: 6
Training loss: 1.026217463322564
Validation loss: 2.3786897596996677

Epoch: 5| Step: 7
Training loss: 0.9749765564472015
Validation loss: 2.3599652412681653

Epoch: 5| Step: 8
Training loss: 1.1693182456323798
Validation loss: 2.323689081854785

Epoch: 5| Step: 9
Training loss: 1.2357982204968343
Validation loss: 2.3702821898447795

Epoch: 5| Step: 10
Training loss: 1.0305770643571097
Validation loss: 2.34780830498441

Epoch: 409| Step: 0
Training loss: 0.7935822842846162
Validation loss: 2.310539553144061

Epoch: 5| Step: 1
Training loss: 1.2035666806870005
Validation loss: 2.336114004053507

Epoch: 5| Step: 2
Training loss: 2.101438270499045
Validation loss: 2.373270819892831

Epoch: 5| Step: 3
Training loss: 0.9245684119475012
Validation loss: 2.3426265676585762

Epoch: 5| Step: 4
Training loss: 0.9791974644518262
Validation loss: 2.388598389557079

Epoch: 5| Step: 5
Training loss: 1.4516127726510375
Validation loss: 2.31878249931684

Epoch: 5| Step: 6
Training loss: 1.1968847169805357
Validation loss: 2.3826976299923897

Epoch: 5| Step: 7
Training loss: 1.2542787277919019
Validation loss: 2.367986524122227

Epoch: 5| Step: 8
Training loss: 1.1466186548779198
Validation loss: 2.3659576401921605

Epoch: 5| Step: 9
Training loss: 1.2529596576391695
Validation loss: 2.2720686119284794

Epoch: 5| Step: 10
Training loss: 1.5188871847603749
Validation loss: 2.4010562135982103

Epoch: 410| Step: 0
Training loss: 1.5269141019732209
Validation loss: 2.4216203776035017

Epoch: 5| Step: 1
Training loss: 1.386155263829929
Validation loss: 2.3793064111375015

Epoch: 5| Step: 2
Training loss: 0.9142714041628835
Validation loss: 2.364126430088122

Epoch: 5| Step: 3
Training loss: 0.9915797858019408
Validation loss: 2.437173561216734

Epoch: 5| Step: 4
Training loss: 0.9331351394766749
Validation loss: 2.4272877871435945

Epoch: 5| Step: 5
Training loss: 0.8554295570069987
Validation loss: 2.374194070528186

Epoch: 5| Step: 6
Training loss: 0.9858066502235928
Validation loss: 2.313186647773602

Epoch: 5| Step: 7
Training loss: 1.4696624843278052
Validation loss: 2.424189699059376

Epoch: 5| Step: 8
Training loss: 1.304120288832689
Validation loss: 2.4301856252145075

Epoch: 5| Step: 9
Training loss: 1.589870143362
Validation loss: 2.3534539316538736

Epoch: 5| Step: 10
Training loss: 1.922539448823221
Validation loss: 2.3988467807196203

Epoch: 411| Step: 0
Training loss: 1.2866255410857672
Validation loss: 2.386984805186376

Epoch: 5| Step: 1
Training loss: 0.9595691273264804
Validation loss: 2.426080283014727

Epoch: 5| Step: 2
Training loss: 1.357241040815575
Validation loss: 2.3988086653341814

Epoch: 5| Step: 3
Training loss: 1.4596676943429026
Validation loss: 2.32937796693454

Epoch: 5| Step: 4
Training loss: 1.0639978957764893
Validation loss: 2.395184332075672

Epoch: 5| Step: 5
Training loss: 1.1867011043198525
Validation loss: 2.353419094176545

Epoch: 5| Step: 6
Training loss: 0.8037454590735893
Validation loss: 2.3419044234086397

Epoch: 5| Step: 7
Training loss: 1.7969326507608012
Validation loss: 2.3392112581440956

Epoch: 5| Step: 8
Training loss: 1.4182584272269094
Validation loss: 2.351976979191271

Epoch: 5| Step: 9
Training loss: 1.2591551728463515
Validation loss: 2.386988076612322

Epoch: 5| Step: 10
Training loss: 1.1381560477348267
Validation loss: 2.3956730875049104

Epoch: 412| Step: 0
Training loss: 0.9869182973861804
Validation loss: 2.379618227823334

Epoch: 5| Step: 1
Training loss: 1.2629640651674041
Validation loss: 2.435968793687623

Epoch: 5| Step: 2
Training loss: 1.264462443338917
Validation loss: 2.359341358275561

Epoch: 5| Step: 3
Training loss: 0.7459724687195396
Validation loss: 2.348478671329732

Epoch: 5| Step: 4
Training loss: 0.8752940228877327
Validation loss: 2.4533110151534157

Epoch: 5| Step: 5
Training loss: 1.0346734990561264
Validation loss: 2.3577929558128075

Epoch: 5| Step: 6
Training loss: 1.6460036982312842
Validation loss: 2.4433394931011096

Epoch: 5| Step: 7
Training loss: 1.46293984344356
Validation loss: 2.3418416294174733

Epoch: 5| Step: 8
Training loss: 1.0693615775322196
Validation loss: 2.4055469680774695

Epoch: 5| Step: 9
Training loss: 2.049270974765206
Validation loss: 2.299082020708561

Epoch: 5| Step: 10
Training loss: 0.5717660331096011
Validation loss: 2.3931445097497135

Epoch: 413| Step: 0
Training loss: 1.2034981879556261
Validation loss: 2.4230953787150473

Epoch: 5| Step: 1
Training loss: 1.1108911389255631
Validation loss: 2.4173483615534663

Epoch: 5| Step: 2
Training loss: 0.9427486361885979
Validation loss: 2.3638080343043693

Epoch: 5| Step: 3
Training loss: 1.425361048819413
Validation loss: 2.368932485265405

Epoch: 5| Step: 4
Training loss: 1.4880437386093617
Validation loss: 2.340050136515312

Epoch: 5| Step: 5
Training loss: 1.2455058370152516
Validation loss: 2.3608578810557566

Epoch: 5| Step: 6
Training loss: 0.9495101606981425
Validation loss: 2.387626061281518

Epoch: 5| Step: 7
Training loss: 1.115201558767677
Validation loss: 2.328011764852554

Epoch: 5| Step: 8
Training loss: 0.7889225901836009
Validation loss: 2.365982361326021

Epoch: 5| Step: 9
Training loss: 2.138244418968857
Validation loss: 2.4051092368557203

Epoch: 5| Step: 10
Training loss: 1.1446881495918348
Validation loss: 2.445643446919959

Epoch: 414| Step: 0
Training loss: 1.496110482782162
Validation loss: 2.3676322238494873

Epoch: 5| Step: 1
Training loss: 1.3510565720409722
Validation loss: 2.4516078395074743

Epoch: 5| Step: 2
Training loss: 0.994786889961851
Validation loss: 2.3937644261286626

Epoch: 5| Step: 3
Training loss: 2.0679659230580767
Validation loss: 2.3849404180184774

Epoch: 5| Step: 4
Training loss: 0.9229275788178034
Validation loss: 2.3431495548186723

Epoch: 5| Step: 5
Training loss: 0.9799219559714548
Validation loss: 2.4285231668675435

Epoch: 5| Step: 6
Training loss: 1.009189286286936
Validation loss: 2.4045428362365655

Epoch: 5| Step: 7
Training loss: 1.1547035494916247
Validation loss: 2.325968051861238

Epoch: 5| Step: 8
Training loss: 1.0255309381305209
Validation loss: 2.3802292782188306

Epoch: 5| Step: 9
Training loss: 1.2442905688992763
Validation loss: 2.338436526031944

Epoch: 5| Step: 10
Training loss: 1.0839569913137441
Validation loss: 2.3332544784435147

Epoch: 415| Step: 0
Training loss: 1.0069829794573233
Validation loss: 2.393504636879375

Epoch: 5| Step: 1
Training loss: 1.0323653691705503
Validation loss: 2.37263794878284

Epoch: 5| Step: 2
Training loss: 1.3875008969690672
Validation loss: 2.4263513623109763

Epoch: 5| Step: 3
Training loss: 1.0994491324877103
Validation loss: 2.335472656338764

Epoch: 5| Step: 4
Training loss: 1.142535608266776
Validation loss: 2.3703197418705124

Epoch: 5| Step: 5
Training loss: 1.1182637399280921
Validation loss: 2.38759285895975

Epoch: 5| Step: 6
Training loss: 1.7936945092526746
Validation loss: 2.299583487228392

Epoch: 5| Step: 7
Training loss: 0.9961196596852399
Validation loss: 2.3705185803147226

Epoch: 5| Step: 8
Training loss: 1.4979629194664044
Validation loss: 2.320867202628594

Epoch: 5| Step: 9
Training loss: 0.814655781879486
Validation loss: 2.3827968463084295

Epoch: 5| Step: 10
Training loss: 1.3765493247260068
Validation loss: 2.396962543262227

Epoch: 416| Step: 0
Training loss: 1.9950393310532353
Validation loss: 2.3761812768633273

Epoch: 5| Step: 1
Training loss: 1.6057942378391272
Validation loss: 2.3651165657547573

Epoch: 5| Step: 2
Training loss: 1.2418879501673548
Validation loss: 2.449378628818163

Epoch: 5| Step: 3
Training loss: 1.2444432727395702
Validation loss: 2.309940787788222

Epoch: 5| Step: 4
Training loss: 1.325928655914509
Validation loss: 2.3669408616055216

Epoch: 5| Step: 5
Training loss: 0.9411899428946088
Validation loss: 2.347462863030132

Epoch: 5| Step: 6
Training loss: 1.2364423316406477
Validation loss: 2.3507396242294

Epoch: 5| Step: 7
Training loss: 0.927895558058192
Validation loss: 2.364890196610277

Epoch: 5| Step: 8
Training loss: 0.8682457592589032
Validation loss: 2.355414377267004

Epoch: 5| Step: 9
Training loss: 1.0428040906677374
Validation loss: 2.4027571271734915

Epoch: 5| Step: 10
Training loss: 0.9254619192515056
Validation loss: 2.3710211448286227

Epoch: 417| Step: 0
Training loss: 0.9958660987560584
Validation loss: 2.3078303195254497

Epoch: 5| Step: 1
Training loss: 1.8953902037590085
Validation loss: 2.3053635640303605

Epoch: 5| Step: 2
Training loss: 0.793581345429862
Validation loss: 2.3850002811151643

Epoch: 5| Step: 3
Training loss: 1.3495179958295518
Validation loss: 2.3193544937712693

Epoch: 5| Step: 4
Training loss: 1.114142583293356
Validation loss: 2.3273784725888715

Epoch: 5| Step: 5
Training loss: 1.2984228434005165
Validation loss: 2.300030025118558

Epoch: 5| Step: 6
Training loss: 1.00273348812336
Validation loss: 2.2716214687386307

Epoch: 5| Step: 7
Training loss: 1.571709462240878
Validation loss: 2.386440028746353

Epoch: 5| Step: 8
Training loss: 0.9609526966413019
Validation loss: 2.3706118161868734

Epoch: 5| Step: 9
Training loss: 1.0960012971981754
Validation loss: 2.375033588851945

Epoch: 5| Step: 10
Training loss: 1.329407017102122
Validation loss: 2.32446450567765

Epoch: 418| Step: 0
Training loss: 0.965484591649049
Validation loss: 2.3752873111462542

Epoch: 5| Step: 1
Training loss: 1.0458273698755791
Validation loss: 2.3648022363370487

Epoch: 5| Step: 2
Training loss: 1.1415537880461448
Validation loss: 2.365398156184659

Epoch: 5| Step: 3
Training loss: 1.7912813112300128
Validation loss: 2.4300271759512175

Epoch: 5| Step: 4
Training loss: 1.324210828009121
Validation loss: 2.383127322917991

Epoch: 5| Step: 5
Training loss: 1.3758096045410453
Validation loss: 2.375065018433676

Epoch: 5| Step: 6
Training loss: 1.2546083380214264
Validation loss: 2.4694875942161842

Epoch: 5| Step: 7
Training loss: 1.0295012703619553
Validation loss: 2.4146686741629124

Epoch: 5| Step: 8
Training loss: 1.2476599724892614
Validation loss: 2.309693653252782

Epoch: 5| Step: 9
Training loss: 1.0210162926549915
Validation loss: 2.351881950783038

Epoch: 5| Step: 10
Training loss: 1.253208287008886
Validation loss: 2.327158256797397

Epoch: 419| Step: 0
Training loss: 1.2838864531980643
Validation loss: 2.347287663420087

Epoch: 5| Step: 1
Training loss: 0.7404913544288594
Validation loss: 2.3640301145656504

Epoch: 5| Step: 2
Training loss: 0.8781462032161101
Validation loss: 2.351913289165987

Epoch: 5| Step: 3
Training loss: 1.1088420501137775
Validation loss: 2.37122194025709

Epoch: 5| Step: 4
Training loss: 1.271321697932667
Validation loss: 2.3356609695931674

Epoch: 5| Step: 5
Training loss: 1.583099230809953
Validation loss: 2.390441914597883

Epoch: 5| Step: 6
Training loss: 1.330383310581821
Validation loss: 2.340621794506439

Epoch: 5| Step: 7
Training loss: 1.3065581473875867
Validation loss: 2.348131268900877

Epoch: 5| Step: 8
Training loss: 1.8799395030007287
Validation loss: 2.331421779598432

Epoch: 5| Step: 9
Training loss: 0.986873000313857
Validation loss: 2.3561943295908216

Epoch: 5| Step: 10
Training loss: 0.7627288771898798
Validation loss: 2.3727567232609417

Epoch: 420| Step: 0
Training loss: 1.1655993461342615
Validation loss: 2.3546021414720935

Epoch: 5| Step: 1
Training loss: 1.4069168205264913
Validation loss: 2.3556867442254936

Epoch: 5| Step: 2
Training loss: 1.029347138019092
Validation loss: 2.3600926819736006

Epoch: 5| Step: 3
Training loss: 0.6991812839806318
Validation loss: 2.394911953676977

Epoch: 5| Step: 4
Training loss: 1.1147343839213322
Validation loss: 2.2916038456096968

Epoch: 5| Step: 5
Training loss: 0.9704469154615103
Validation loss: 2.336519491559517

Epoch: 5| Step: 6
Training loss: 0.9668504488194569
Validation loss: 2.354165367331561

Epoch: 5| Step: 7
Training loss: 1.2624400058504095
Validation loss: 2.3187452812822342

Epoch: 5| Step: 8
Training loss: 1.262534807688485
Validation loss: 2.279068913760928

Epoch: 5| Step: 9
Training loss: 2.0211239110983947
Validation loss: 2.3739507199883256

Epoch: 5| Step: 10
Training loss: 1.2766324083663663
Validation loss: 2.4395083979273355

Epoch: 421| Step: 0
Training loss: 0.9031877080140901
Validation loss: 2.3583502524022046

Epoch: 5| Step: 1
Training loss: 1.0680050445394642
Validation loss: 2.411348427610103

Epoch: 5| Step: 2
Training loss: 1.1065334948207475
Validation loss: 2.4844637103142775

Epoch: 5| Step: 3
Training loss: 1.050547407145453
Validation loss: 2.3510932709046086

Epoch: 5| Step: 4
Training loss: 1.3176259353065483
Validation loss: 2.413705542088218

Epoch: 5| Step: 5
Training loss: 1.3740295540159035
Validation loss: 2.3946394083335902

Epoch: 5| Step: 6
Training loss: 1.942504449394953
Validation loss: 2.3406226499214293

Epoch: 5| Step: 7
Training loss: 1.0625181757550384
Validation loss: 2.3439568978599463

Epoch: 5| Step: 8
Training loss: 1.1268404105955878
Validation loss: 2.3847074835923543

Epoch: 5| Step: 9
Training loss: 1.1415725325783952
Validation loss: 2.385306552513329

Epoch: 5| Step: 10
Training loss: 1.3114193145708415
Validation loss: 2.2975043658891328

Epoch: 422| Step: 0
Training loss: 1.019916914566583
Validation loss: 2.358701605896376

Epoch: 5| Step: 1
Training loss: 0.9806491640224598
Validation loss: 2.3529668682319587

Epoch: 5| Step: 2
Training loss: 1.0223228849613621
Validation loss: 2.421060080609607

Epoch: 5| Step: 3
Training loss: 1.8003111120085225
Validation loss: 2.410611504527849

Epoch: 5| Step: 4
Training loss: 1.153567579154164
Validation loss: 2.2956143054994635

Epoch: 5| Step: 5
Training loss: 1.1318977608964673
Validation loss: 2.422418722407125

Epoch: 5| Step: 6
Training loss: 1.4265439018716828
Validation loss: 2.4224937270509845

Epoch: 5| Step: 7
Training loss: 1.4571593691053273
Validation loss: 2.3874532844376875

Epoch: 5| Step: 8
Training loss: 1.0343273947095843
Validation loss: 2.4206398843552326

Epoch: 5| Step: 9
Training loss: 1.255392411954955
Validation loss: 2.4473943135119813

Epoch: 5| Step: 10
Training loss: 1.23791859608109
Validation loss: 2.359692075302538

Epoch: 423| Step: 0
Training loss: 1.0900814111737023
Validation loss: 2.3922965559482168

Epoch: 5| Step: 1
Training loss: 0.8996536648142825
Validation loss: 2.4219555426260224

Epoch: 5| Step: 2
Training loss: 0.9630147300734501
Validation loss: 2.373059805807776

Epoch: 5| Step: 3
Training loss: 1.250417925588162
Validation loss: 2.3298496383618366

Epoch: 5| Step: 4
Training loss: 1.3867763883405464
Validation loss: 2.3988674460267334

Epoch: 5| Step: 5
Training loss: 0.9744272921993195
Validation loss: 2.382501212204765

Epoch: 5| Step: 6
Training loss: 1.6196693873068901
Validation loss: 2.3898536177021232

Epoch: 5| Step: 7
Training loss: 0.9107421168180664
Validation loss: 2.3881811285275716

Epoch: 5| Step: 8
Training loss: 1.807903050798304
Validation loss: 2.4115781259736564

Epoch: 5| Step: 9
Training loss: 0.9833980132237479
Validation loss: 2.3169030396556285

Epoch: 5| Step: 10
Training loss: 1.2058567394330355
Validation loss: 2.3475574298367707

Epoch: 424| Step: 0
Training loss: 0.5288581296591839
Validation loss: 2.400658302451505

Epoch: 5| Step: 1
Training loss: 0.9360074241641263
Validation loss: 2.3365037630743344

Epoch: 5| Step: 2
Training loss: 1.1780461899683103
Validation loss: 2.338178022659461

Epoch: 5| Step: 3
Training loss: 1.1508724842046107
Validation loss: 2.391697493369467

Epoch: 5| Step: 4
Training loss: 1.1436905100208674
Validation loss: 2.4006602502833214

Epoch: 5| Step: 5
Training loss: 2.1401404507617756
Validation loss: 2.39561398123088

Epoch: 5| Step: 6
Training loss: 1.1175040483508076
Validation loss: 2.3555988576566653

Epoch: 5| Step: 7
Training loss: 1.2896084640757615
Validation loss: 2.4302232938474715

Epoch: 5| Step: 8
Training loss: 0.7946892475284468
Validation loss: 2.3612364464472697

Epoch: 5| Step: 9
Training loss: 0.8653077725177655
Validation loss: 2.3889028303234476

Epoch: 5| Step: 10
Training loss: 1.3721741334997808
Validation loss: 2.355152888023494

Epoch: 425| Step: 0
Training loss: 1.5417048818989625
Validation loss: 2.3034255588308836

Epoch: 5| Step: 1
Training loss: 1.0779278339937521
Validation loss: 2.3084560722675507

Epoch: 5| Step: 2
Training loss: 0.8320066063325201
Validation loss: 2.4216270200736654

Epoch: 5| Step: 3
Training loss: 1.7151646064081416
Validation loss: 2.346889029576001

Epoch: 5| Step: 4
Training loss: 1.0729298575371278
Validation loss: 2.3889313887042807

Epoch: 5| Step: 5
Training loss: 1.005358524994286
Validation loss: 2.401334600606118

Epoch: 5| Step: 6
Training loss: 1.196731224089679
Validation loss: 2.3930742785272483

Epoch: 5| Step: 7
Training loss: 1.0149399427676653
Validation loss: 2.3717049191152615

Epoch: 5| Step: 8
Training loss: 1.1651140622142369
Validation loss: 2.381157849092287

Epoch: 5| Step: 9
Training loss: 1.0190380555104364
Validation loss: 2.3849561530399703

Epoch: 5| Step: 10
Training loss: 1.3150622924584066
Validation loss: 2.426111544245635

Epoch: 426| Step: 0
Training loss: 1.1970242479460884
Validation loss: 2.3554263877661157

Epoch: 5| Step: 1
Training loss: 1.5353947810869564
Validation loss: 2.401825672187788

Epoch: 5| Step: 2
Training loss: 0.9015634969775209
Validation loss: 2.3578487967022377

Epoch: 5| Step: 3
Training loss: 2.0290762200325694
Validation loss: 2.3915818559718076

Epoch: 5| Step: 4
Training loss: 1.1808704230586384
Validation loss: 2.4216331564951674

Epoch: 5| Step: 5
Training loss: 0.8810591037768944
Validation loss: 2.4082545025880773

Epoch: 5| Step: 6
Training loss: 1.2049844417913065
Validation loss: 2.383862686517502

Epoch: 5| Step: 7
Training loss: 1.1299740714077615
Validation loss: 2.363740422127644

Epoch: 5| Step: 8
Training loss: 0.9356728550579804
Validation loss: 2.317042223640116

Epoch: 5| Step: 9
Training loss: 1.2474806191997256
Validation loss: 2.3694844072524845

Epoch: 5| Step: 10
Training loss: 1.3123731097690912
Validation loss: 2.3848426469596324

Epoch: 427| Step: 0
Training loss: 1.2382210316742057
Validation loss: 2.361664199672656

Epoch: 5| Step: 1
Training loss: 1.3747182904277149
Validation loss: 2.401890720137538

Epoch: 5| Step: 2
Training loss: 1.2905061902648187
Validation loss: 2.3576356946987276

Epoch: 5| Step: 3
Training loss: 1.2301315087672535
Validation loss: 2.3155296808801777

Epoch: 5| Step: 4
Training loss: 1.914929874620252
Validation loss: 2.390801656127414

Epoch: 5| Step: 5
Training loss: 0.9277468710609905
Validation loss: 2.364701706149248

Epoch: 5| Step: 6
Training loss: 1.0454068493423292
Validation loss: 2.351405054965617

Epoch: 5| Step: 7
Training loss: 0.7863168062777877
Validation loss: 2.403800726765024

Epoch: 5| Step: 8
Training loss: 0.9257591663414663
Validation loss: 2.3616677569286098

Epoch: 5| Step: 9
Training loss: 0.8054097462011606
Validation loss: 2.3624143250597767

Epoch: 5| Step: 10
Training loss: 1.435622440347478
Validation loss: 2.3806287732952414

Epoch: 428| Step: 0
Training loss: 0.8911194683539492
Validation loss: 2.399519815869467

Epoch: 5| Step: 1
Training loss: 1.2097575684113795
Validation loss: 2.408165081054242

Epoch: 5| Step: 2
Training loss: 1.1000124258726716
Validation loss: 2.3876888317083367

Epoch: 5| Step: 3
Training loss: 0.9859326466774923
Validation loss: 2.3672230196429265

Epoch: 5| Step: 4
Training loss: 1.2422400409455123
Validation loss: 2.406501402105208

Epoch: 5| Step: 5
Training loss: 1.3564955809844972
Validation loss: 2.4029807420692166

Epoch: 5| Step: 6
Training loss: 1.1276206117389638
Validation loss: 2.4264166381626495

Epoch: 5| Step: 7
Training loss: 0.8943124695144127
Validation loss: 2.3813133135081537

Epoch: 5| Step: 8
Training loss: 1.0407398423985046
Validation loss: 2.354113416389845

Epoch: 5| Step: 9
Training loss: 2.0507095179047057
Validation loss: 2.3636180155353377

Epoch: 5| Step: 10
Training loss: 1.321723815713445
Validation loss: 2.340695876009771

Epoch: 429| Step: 0
Training loss: 2.0308525283442727
Validation loss: 2.318067872763697

Epoch: 5| Step: 1
Training loss: 1.1823903125271884
Validation loss: 2.4025936324562496

Epoch: 5| Step: 2
Training loss: 1.0618946370447147
Validation loss: 2.3903809788226886

Epoch: 5| Step: 3
Training loss: 1.4484640865910494
Validation loss: 2.335303256384169

Epoch: 5| Step: 4
Training loss: 0.7062128715545624
Validation loss: 2.3212205972853113

Epoch: 5| Step: 5
Training loss: 1.1976504430860273
Validation loss: 2.3436926109370306

Epoch: 5| Step: 6
Training loss: 0.8728493076516418
Validation loss: 2.367557329558631

Epoch: 5| Step: 7
Training loss: 0.8965220391499983
Validation loss: 2.394071719066185

Epoch: 5| Step: 8
Training loss: 1.235300513860027
Validation loss: 2.307643187959585

Epoch: 5| Step: 9
Training loss: 1.156263299813976
Validation loss: 2.4199553980997366

Epoch: 5| Step: 10
Training loss: 1.2708370594324405
Validation loss: 2.3427648353809425

Epoch: 430| Step: 0
Training loss: 1.2441593569987748
Validation loss: 2.3693237087862107

Epoch: 5| Step: 1
Training loss: 1.057858708103509
Validation loss: 2.370697502488164

Epoch: 5| Step: 2
Training loss: 1.2247727572586322
Validation loss: 2.3574494978260043

Epoch: 5| Step: 3
Training loss: 1.061684576050169
Validation loss: 2.320583236697368

Epoch: 5| Step: 4
Training loss: 1.463587188917766
Validation loss: 2.3510193676371083

Epoch: 5| Step: 5
Training loss: 1.7669950587878738
Validation loss: 2.382250003195782

Epoch: 5| Step: 6
Training loss: 0.9077113635246288
Validation loss: 2.3493139431935797

Epoch: 5| Step: 7
Training loss: 0.9799981982837386
Validation loss: 2.365012113519375

Epoch: 5| Step: 8
Training loss: 1.119014180281911
Validation loss: 2.3244447648734896

Epoch: 5| Step: 9
Training loss: 1.4463254111369657
Validation loss: 2.3403351635942116

Epoch: 5| Step: 10
Training loss: 1.2438111160828038
Validation loss: 2.4149083801600617

Epoch: 431| Step: 0
Training loss: 1.1964890417991239
Validation loss: 2.378768608437729

Epoch: 5| Step: 1
Training loss: 1.0851950543072635
Validation loss: 2.3412045641606825

Epoch: 5| Step: 2
Training loss: 0.9700425354489831
Validation loss: 2.4003615856387412

Epoch: 5| Step: 3
Training loss: 1.4389682403410455
Validation loss: 2.399117736776791

Epoch: 5| Step: 4
Training loss: 1.1281661409183434
Validation loss: 2.3569218449109934

Epoch: 5| Step: 5
Training loss: 1.7289223402595855
Validation loss: 2.3271421411642623

Epoch: 5| Step: 6
Training loss: 0.8827059183514598
Validation loss: 2.3713121013780185

Epoch: 5| Step: 7
Training loss: 1.2928535894181
Validation loss: 2.35819526031053

Epoch: 5| Step: 8
Training loss: 1.1538075089096413
Validation loss: 2.3659995993287053

Epoch: 5| Step: 9
Training loss: 0.8304113100845393
Validation loss: 2.3424413471708596

Epoch: 5| Step: 10
Training loss: 1.0335601593579762
Validation loss: 2.3959605828332813

Epoch: 432| Step: 0
Training loss: 1.1733920132980467
Validation loss: 2.40878035964683

Epoch: 5| Step: 1
Training loss: 0.808554459506428
Validation loss: 2.3303951986368117

Epoch: 5| Step: 2
Training loss: 1.179571941854776
Validation loss: 2.385925562891087

Epoch: 5| Step: 3
Training loss: 1.0004934643098724
Validation loss: 2.3150443115455035

Epoch: 5| Step: 4
Training loss: 0.9041303312380995
Validation loss: 2.3508991754083834

Epoch: 5| Step: 5
Training loss: 1.207247865862608
Validation loss: 2.345266082337779

Epoch: 5| Step: 6
Training loss: 1.793950495663103
Validation loss: 2.3673013449725704

Epoch: 5| Step: 7
Training loss: 1.2412840718858897
Validation loss: 2.3666051110780018

Epoch: 5| Step: 8
Training loss: 1.268982848049251
Validation loss: 2.3957001205440505

Epoch: 5| Step: 9
Training loss: 1.5895215207035303
Validation loss: 2.372929798261197

Epoch: 5| Step: 10
Training loss: 1.037550205716487
Validation loss: 2.3394130447539334

Epoch: 433| Step: 0
Training loss: 1.2001211144998591
Validation loss: 2.383978532735847

Epoch: 5| Step: 1
Training loss: 1.1145554595504144
Validation loss: 2.37638293137894

Epoch: 5| Step: 2
Training loss: 1.1308808267037858
Validation loss: 2.369128388612314

Epoch: 5| Step: 3
Training loss: 1.0852833705675868
Validation loss: 2.3945508326883123

Epoch: 5| Step: 4
Training loss: 1.244144122299956
Validation loss: 2.3563213127501013

Epoch: 5| Step: 5
Training loss: 1.7997491158378454
Validation loss: 2.307055263139357

Epoch: 5| Step: 6
Training loss: 0.8128827367323781
Validation loss: 2.367279296793242

Epoch: 5| Step: 7
Training loss: 0.8318542148850858
Validation loss: 2.353472395384025

Epoch: 5| Step: 8
Training loss: 1.0031617962989983
Validation loss: 2.3194083434775394

Epoch: 5| Step: 9
Training loss: 1.1139623867170676
Validation loss: 2.3589944644654324

Epoch: 5| Step: 10
Training loss: 1.1518438774453865
Validation loss: 2.3833303947467903

Epoch: 434| Step: 0
Training loss: 1.027298552820699
Validation loss: 2.3073913375654844

Epoch: 5| Step: 1
Training loss: 0.7587240576669002
Validation loss: 2.3787236472539357

Epoch: 5| Step: 2
Training loss: 1.2402325487498858
Validation loss: 2.373339263972668

Epoch: 5| Step: 3
Training loss: 1.1837903353657981
Validation loss: 2.39708331770918

Epoch: 5| Step: 4
Training loss: 0.9531441983650176
Validation loss: 2.4162745228331297

Epoch: 5| Step: 5
Training loss: 1.352616885593894
Validation loss: 2.3332339428976607

Epoch: 5| Step: 6
Training loss: 0.9296283222245301
Validation loss: 2.3826256823856493

Epoch: 5| Step: 7
Training loss: 1.032880130463773
Validation loss: 2.409892735950811

Epoch: 5| Step: 8
Training loss: 0.8206280056156803
Validation loss: 2.373321894567083

Epoch: 5| Step: 9
Training loss: 2.0994433528110727
Validation loss: 2.4071961849077845

Epoch: 5| Step: 10
Training loss: 1.3731624288757867
Validation loss: 2.3218900272495504

Epoch: 435| Step: 0
Training loss: 0.7596462518814854
Validation loss: 2.4042502271672395

Epoch: 5| Step: 1
Training loss: 1.0843582195995407
Validation loss: 2.4209287935283963

Epoch: 5| Step: 2
Training loss: 0.9434247675438013
Validation loss: 2.36104441610292

Epoch: 5| Step: 3
Training loss: 1.374914209984019
Validation loss: 2.336199940599803

Epoch: 5| Step: 4
Training loss: 1.2065705342928084
Validation loss: 2.3488218541013515

Epoch: 5| Step: 5
Training loss: 0.8153280046303957
Validation loss: 2.360957873457067

Epoch: 5| Step: 6
Training loss: 1.07355270544904
Validation loss: 2.3988424054696385

Epoch: 5| Step: 7
Training loss: 1.021813538362448
Validation loss: 2.442711506342181

Epoch: 5| Step: 8
Training loss: 1.8107113398283177
Validation loss: 2.3536630153989853

Epoch: 5| Step: 9
Training loss: 1.3072002221860195
Validation loss: 2.3946441750631986

Epoch: 5| Step: 10
Training loss: 1.1234409337528475
Validation loss: 2.294808399027964

Epoch: 436| Step: 0
Training loss: 0.9828106696713723
Validation loss: 2.3796212012598503

Epoch: 5| Step: 1
Training loss: 1.3302899834714654
Validation loss: 2.3480144358049664

Epoch: 5| Step: 2
Training loss: 1.4783438780593825
Validation loss: 2.3546626833216098

Epoch: 5| Step: 3
Training loss: 1.2376039981491418
Validation loss: 2.2951895963596516

Epoch: 5| Step: 4
Training loss: 1.291627401349881
Validation loss: 2.3722935885264156

Epoch: 5| Step: 5
Training loss: 1.1482656960206714
Validation loss: 2.3779626156114624

Epoch: 5| Step: 6
Training loss: 1.0900349329678989
Validation loss: 2.3365986370945326

Epoch: 5| Step: 7
Training loss: 0.988425805899773
Validation loss: 2.3539394986332787

Epoch: 5| Step: 8
Training loss: 1.702285279613043
Validation loss: 2.3898556429941467

Epoch: 5| Step: 9
Training loss: 0.8418042742410635
Validation loss: 2.4348564737448832

Epoch: 5| Step: 10
Training loss: 0.9459250176031183
Validation loss: 2.4098735055859155

Epoch: 437| Step: 0
Training loss: 1.120109790887332
Validation loss: 2.342967657959615

Epoch: 5| Step: 1
Training loss: 1.080601818747281
Validation loss: 2.341466958566333

Epoch: 5| Step: 2
Training loss: 1.023232825393502
Validation loss: 2.4311291441981266

Epoch: 5| Step: 3
Training loss: 1.0711673747439665
Validation loss: 2.4266614537158855

Epoch: 5| Step: 4
Training loss: 1.1683053644744292
Validation loss: 2.3654105191655934

Epoch: 5| Step: 5
Training loss: 0.7564068765525375
Validation loss: 2.3631657929414533

Epoch: 5| Step: 6
Training loss: 1.271881697728473
Validation loss: 2.35864674249482

Epoch: 5| Step: 7
Training loss: 2.123039350873569
Validation loss: 2.4264207787949386

Epoch: 5| Step: 8
Training loss: 1.1404425592703817
Validation loss: 2.4097972411092834

Epoch: 5| Step: 9
Training loss: 0.6941969849177292
Validation loss: 2.3988663987123537

Epoch: 5| Step: 10
Training loss: 0.880454975010264
Validation loss: 2.4166332012005083

Epoch: 438| Step: 0
Training loss: 1.1009135397589296
Validation loss: 2.326369301959358

Epoch: 5| Step: 1
Training loss: 1.1389198622071297
Validation loss: 2.328817866374932

Epoch: 5| Step: 2
Training loss: 1.0389440942286632
Validation loss: 2.4104049495002724

Epoch: 5| Step: 3
Training loss: 0.9677908671606223
Validation loss: 2.4001280650029666

Epoch: 5| Step: 4
Training loss: 0.89789395683465
Validation loss: 2.409818147618083

Epoch: 5| Step: 5
Training loss: 1.3279318276337733
Validation loss: 2.3596360267914434

Epoch: 5| Step: 6
Training loss: 1.1186723778078367
Validation loss: 2.3598065540171396

Epoch: 5| Step: 7
Training loss: 0.9063508207867864
Validation loss: 2.327068630142716

Epoch: 5| Step: 8
Training loss: 0.9345810270741602
Validation loss: 2.402465339956459

Epoch: 5| Step: 9
Training loss: 1.0800947908905774
Validation loss: 2.3549890725142433

Epoch: 5| Step: 10
Training loss: 2.1025103732294292
Validation loss: 2.3970352332566383

Epoch: 439| Step: 0
Training loss: 1.1002736769860912
Validation loss: 2.400502470785289

Epoch: 5| Step: 1
Training loss: 0.8152146472746512
Validation loss: 2.4457191376338683

Epoch: 5| Step: 2
Training loss: 1.2135818158276683
Validation loss: 2.380343445589191

Epoch: 5| Step: 3
Training loss: 0.8480407967650526
Validation loss: 2.3890066141293245

Epoch: 5| Step: 4
Training loss: 0.889543679996648
Validation loss: 2.3853805230452814

Epoch: 5| Step: 5
Training loss: 1.1102943372113228
Validation loss: 2.3083079654497203

Epoch: 5| Step: 6
Training loss: 1.257755349323966
Validation loss: 2.3710042720333084

Epoch: 5| Step: 7
Training loss: 1.8800597268620494
Validation loss: 2.3924655572906106

Epoch: 5| Step: 8
Training loss: 1.0751805109569568
Validation loss: 2.4041778779448673

Epoch: 5| Step: 9
Training loss: 1.3501523991501057
Validation loss: 2.2520186405448985

Epoch: 5| Step: 10
Training loss: 1.2100376846813488
Validation loss: 2.320084702459316

Epoch: 440| Step: 0
Training loss: 1.0179294558104361
Validation loss: 2.3770362046150773

Epoch: 5| Step: 1
Training loss: 1.1040082793927373
Validation loss: 2.362620703383082

Epoch: 5| Step: 2
Training loss: 0.8442730518635887
Validation loss: 2.3787278288733242

Epoch: 5| Step: 3
Training loss: 1.4597506674719118
Validation loss: 2.385496598075205

Epoch: 5| Step: 4
Training loss: 1.0949900545687583
Validation loss: 2.3642617236826444

Epoch: 5| Step: 5
Training loss: 1.8263105859961515
Validation loss: 2.466222007422169

Epoch: 5| Step: 6
Training loss: 0.8824347641583188
Validation loss: 2.4165067255589188

Epoch: 5| Step: 7
Training loss: 1.088008415378955
Validation loss: 2.357361241974011

Epoch: 5| Step: 8
Training loss: 1.1849101586226962
Validation loss: 2.3219705431085824

Epoch: 5| Step: 9
Training loss: 1.3634170858047059
Validation loss: 2.355535592881819

Epoch: 5| Step: 10
Training loss: 0.9992728569884846
Validation loss: 2.404854557228358

Epoch: 441| Step: 0
Training loss: 1.0587583181691747
Validation loss: 2.339101752859197

Epoch: 5| Step: 1
Training loss: 1.038801633742777
Validation loss: 2.29106018696145

Epoch: 5| Step: 2
Training loss: 1.0568432851552527
Validation loss: 2.3369024219955543

Epoch: 5| Step: 3
Training loss: 0.9303844628324974
Validation loss: 2.372687362877547

Epoch: 5| Step: 4
Training loss: 0.9019603492708531
Validation loss: 2.266402930033281

Epoch: 5| Step: 5
Training loss: 1.2960675954910335
Validation loss: 2.3325240105725684

Epoch: 5| Step: 6
Training loss: 1.1348738758238313
Validation loss: 2.3365229077044765

Epoch: 5| Step: 7
Training loss: 1.717906051123061
Validation loss: 2.3545459462113643

Epoch: 5| Step: 8
Training loss: 1.0551909198937164
Validation loss: 2.3552378283799933

Epoch: 5| Step: 9
Training loss: 0.8551861718698649
Validation loss: 2.3514521018985066

Epoch: 5| Step: 10
Training loss: 1.1587993251668212
Validation loss: 2.350132729361952

Epoch: 442| Step: 0
Training loss: 1.215704707888736
Validation loss: 2.3871227532242187

Epoch: 5| Step: 1
Training loss: 1.8639369746469252
Validation loss: 2.3976011997060356

Epoch: 5| Step: 2
Training loss: 1.0174836977090884
Validation loss: 2.3997284541192685

Epoch: 5| Step: 3
Training loss: 0.7052127360925391
Validation loss: 2.3614950932990464

Epoch: 5| Step: 4
Training loss: 1.1747409616184739
Validation loss: 2.336210711114089

Epoch: 5| Step: 5
Training loss: 1.222366201103632
Validation loss: 2.3203332614946963

Epoch: 5| Step: 6
Training loss: 0.7079564990160441
Validation loss: 2.3297192536204223

Epoch: 5| Step: 7
Training loss: 1.0363529413719397
Validation loss: 2.4003176008573424

Epoch: 5| Step: 8
Training loss: 1.1754119394435614
Validation loss: 2.377688754947287

Epoch: 5| Step: 9
Training loss: 1.5080686361543825
Validation loss: 2.326405932990973

Epoch: 5| Step: 10
Training loss: 1.0368561803801044
Validation loss: 2.359843000612882

Epoch: 443| Step: 0
Training loss: 1.0898287645629132
Validation loss: 2.377982406973458

Epoch: 5| Step: 1
Training loss: 1.8666653082479348
Validation loss: 2.4305790304602186

Epoch: 5| Step: 2
Training loss: 1.0549859648941577
Validation loss: 2.363514818747968

Epoch: 5| Step: 3
Training loss: 0.8234321492725228
Validation loss: 2.347457504138558

Epoch: 5| Step: 4
Training loss: 1.0046373369618258
Validation loss: 2.3856499384086707

Epoch: 5| Step: 5
Training loss: 1.1536280829425323
Validation loss: 2.3805694604113867

Epoch: 5| Step: 6
Training loss: 1.3023976773067918
Validation loss: 2.3763845226076183

Epoch: 5| Step: 7
Training loss: 1.1071380843661751
Validation loss: 2.4452955894143655

Epoch: 5| Step: 8
Training loss: 0.9752827002199712
Validation loss: 2.3681406837749686

Epoch: 5| Step: 9
Training loss: 1.1301430655530094
Validation loss: 2.3609150713965965

Epoch: 5| Step: 10
Training loss: 0.8681210827996548
Validation loss: 2.3572129234631123

Epoch: 444| Step: 0
Training loss: 0.9535639643185643
Validation loss: 2.3921720584838715

Epoch: 5| Step: 1
Training loss: 1.075394309716887
Validation loss: 2.367400928234105

Epoch: 5| Step: 2
Training loss: 1.27951872554551
Validation loss: 2.3335714621556343

Epoch: 5| Step: 3
Training loss: 1.0778877439527446
Validation loss: 2.397668911291313

Epoch: 5| Step: 4
Training loss: 0.9139185735087187
Validation loss: 2.4158667806043317

Epoch: 5| Step: 5
Training loss: 1.9057342582051486
Validation loss: 2.3297793945179195

Epoch: 5| Step: 6
Training loss: 0.9914765100856271
Validation loss: 2.322309282083044

Epoch: 5| Step: 7
Training loss: 0.9122172257172598
Validation loss: 2.311614936158537

Epoch: 5| Step: 8
Training loss: 1.1143672531637432
Validation loss: 2.3721316046258374

Epoch: 5| Step: 9
Training loss: 0.79683030695029
Validation loss: 2.3317939680320636

Epoch: 5| Step: 10
Training loss: 1.3254084011676794
Validation loss: 2.391432218696766

Epoch: 445| Step: 0
Training loss: 1.1618607968451846
Validation loss: 2.3638986576822987

Epoch: 5| Step: 1
Training loss: 1.860086064654798
Validation loss: 2.3426407757644716

Epoch: 5| Step: 2
Training loss: 1.03463605369755
Validation loss: 2.295429851347504

Epoch: 5| Step: 3
Training loss: 1.1657446158143867
Validation loss: 2.368593854977278

Epoch: 5| Step: 4
Training loss: 0.8099381700511945
Validation loss: 2.350694793836702

Epoch: 5| Step: 5
Training loss: 0.7097862479993315
Validation loss: 2.2843959275837125

Epoch: 5| Step: 6
Training loss: 0.9226918238695043
Validation loss: 2.3095092657143783

Epoch: 5| Step: 7
Training loss: 1.3963748915643832
Validation loss: 2.382072378166802

Epoch: 5| Step: 8
Training loss: 0.9387342275927563
Validation loss: 2.3609240077966587

Epoch: 5| Step: 9
Training loss: 1.229006816146734
Validation loss: 2.325682425844812

Epoch: 5| Step: 10
Training loss: 1.2711086860815524
Validation loss: 2.3681770529864856

Epoch: 446| Step: 0
Training loss: 0.698096840409212
Validation loss: 2.3185267162335697

Epoch: 5| Step: 1
Training loss: 1.0939819634919115
Validation loss: 2.3895091997675415

Epoch: 5| Step: 2
Training loss: 1.9829060681978914
Validation loss: 2.273485564987556

Epoch: 5| Step: 3
Training loss: 1.1391602085733217
Validation loss: 2.3360038141828987

Epoch: 5| Step: 4
Training loss: 1.1265514590162788
Validation loss: 2.3496843973070267

Epoch: 5| Step: 5
Training loss: 0.977199499277993
Validation loss: 2.391489213068006

Epoch: 5| Step: 6
Training loss: 0.9501613755943386
Validation loss: 2.3441659548691205

Epoch: 5| Step: 7
Training loss: 1.0396306485179385
Validation loss: 2.376601528169718

Epoch: 5| Step: 8
Training loss: 1.0042672899622442
Validation loss: 2.30114876979596

Epoch: 5| Step: 9
Training loss: 1.4353287096393514
Validation loss: 2.3448121735591423

Epoch: 5| Step: 10
Training loss: 0.8319793470070533
Validation loss: 2.359216983716269

Epoch: 447| Step: 0
Training loss: 0.9062047486681964
Validation loss: 2.29831081139468

Epoch: 5| Step: 1
Training loss: 1.1982243294850246
Validation loss: 2.32782474026036

Epoch: 5| Step: 2
Training loss: 1.1786521258532483
Validation loss: 2.378855397872243

Epoch: 5| Step: 3
Training loss: 0.7592673347034218
Validation loss: 2.357419762032423

Epoch: 5| Step: 4
Training loss: 1.077479957341054
Validation loss: 2.33448137842443

Epoch: 5| Step: 5
Training loss: 1.2443271658807828
Validation loss: 2.3756582225586635

Epoch: 5| Step: 6
Training loss: 2.081713224531235
Validation loss: 2.3460645856270452

Epoch: 5| Step: 7
Training loss: 1.278634122443971
Validation loss: 2.4029755064550042

Epoch: 5| Step: 8
Training loss: 0.7730432912195069
Validation loss: 2.369000600449258

Epoch: 5| Step: 9
Training loss: 1.1355856265190023
Validation loss: 2.3596838265671414

Epoch: 5| Step: 10
Training loss: 0.6960796667316249
Validation loss: 2.4230155257289563

Epoch: 448| Step: 0
Training loss: 0.9763325840189689
Validation loss: 2.3833596949984246

Epoch: 5| Step: 1
Training loss: 1.7746014913307853
Validation loss: 2.343391941297873

Epoch: 5| Step: 2
Training loss: 1.164811373490308
Validation loss: 2.3446394350427755

Epoch: 5| Step: 3
Training loss: 0.900341967676766
Validation loss: 2.2764415536573983

Epoch: 5| Step: 4
Training loss: 0.9649757572943647
Validation loss: 2.433870399804917

Epoch: 5| Step: 5
Training loss: 1.479804300050846
Validation loss: 2.37368458954552

Epoch: 5| Step: 6
Training loss: 1.2453825065817692
Validation loss: 2.326313312372032

Epoch: 5| Step: 7
Training loss: 1.0753739128102864
Validation loss: 2.3338726994385532

Epoch: 5| Step: 8
Training loss: 1.0154530893231384
Validation loss: 2.390160093893205

Epoch: 5| Step: 9
Training loss: 1.0067909445269387
Validation loss: 2.31848174507203

Epoch: 5| Step: 10
Training loss: 1.1059584324977325
Validation loss: 2.4100527025547502

Epoch: 449| Step: 0
Training loss: 0.7192312785401418
Validation loss: 2.3339330480074336

Epoch: 5| Step: 1
Training loss: 0.9837160781285532
Validation loss: 2.355724565914487

Epoch: 5| Step: 2
Training loss: 1.183051107671487
Validation loss: 2.319142381036431

Epoch: 5| Step: 3
Training loss: 0.6982374071077618
Validation loss: 2.3439049837012793

Epoch: 5| Step: 4
Training loss: 1.185727151301932
Validation loss: 2.3548716091219735

Epoch: 5| Step: 5
Training loss: 0.7545476369209942
Validation loss: 2.386421982300034

Epoch: 5| Step: 6
Training loss: 0.9268467240448062
Validation loss: 2.3699084650136637

Epoch: 5| Step: 7
Training loss: 1.8793296416238388
Validation loss: 2.3861719273761537

Epoch: 5| Step: 8
Training loss: 1.0051132842406891
Validation loss: 2.391127563901097

Epoch: 5| Step: 9
Training loss: 1.4490400754284727
Validation loss: 2.3689032334253275

Epoch: 5| Step: 10
Training loss: 1.2408741179595977
Validation loss: 2.340421211322549

Epoch: 450| Step: 0
Training loss: 1.3251943679615048
Validation loss: 2.4081542235636197

Epoch: 5| Step: 1
Training loss: 0.9581829070467057
Validation loss: 2.328516286730732

Epoch: 5| Step: 2
Training loss: 0.9428312035394325
Validation loss: 2.3297319643932557

Epoch: 5| Step: 3
Training loss: 0.826163866802389
Validation loss: 2.383372302962651

Epoch: 5| Step: 4
Training loss: 0.8702257561729877
Validation loss: 2.40557980909517

Epoch: 5| Step: 5
Training loss: 1.874393110604351
Validation loss: 2.373650114871127

Epoch: 5| Step: 6
Training loss: 1.2115040591994928
Validation loss: 2.3655846128152027

Epoch: 5| Step: 7
Training loss: 1.0255364595885286
Validation loss: 2.372280647328325

Epoch: 5| Step: 8
Training loss: 1.1947892483612215
Validation loss: 2.3225956242515844

Epoch: 5| Step: 9
Training loss: 0.820894670534533
Validation loss: 2.3698673993900607

Epoch: 5| Step: 10
Training loss: 0.933932606001441
Validation loss: 2.432491629355453

Epoch: 451| Step: 0
Training loss: 1.667610362231222
Validation loss: 2.305546129287063

Epoch: 5| Step: 1
Training loss: 0.7924381604420925
Validation loss: 2.4128278646912222

Epoch: 5| Step: 2
Training loss: 0.9910869050996136
Validation loss: 2.378917638632648

Epoch: 5| Step: 3
Training loss: 1.2380535024596868
Validation loss: 2.4271787515264953

Epoch: 5| Step: 4
Training loss: 0.7782582027298344
Validation loss: 2.3837755580640785

Epoch: 5| Step: 5
Training loss: 1.1459876679028234
Validation loss: 2.3466061903843833

Epoch: 5| Step: 6
Training loss: 1.1580388948203808
Validation loss: 2.4107951171800126

Epoch: 5| Step: 7
Training loss: 0.7911834915436872
Validation loss: 2.3502930074288786

Epoch: 5| Step: 8
Training loss: 1.047188726075541
Validation loss: 2.359251345478824

Epoch: 5| Step: 9
Training loss: 1.0978235409140982
Validation loss: 2.307819904223842

Epoch: 5| Step: 10
Training loss: 1.3252964192039767
Validation loss: 2.3553459026471644

Epoch: 452| Step: 0
Training loss: 0.8683007457741814
Validation loss: 2.337033337305133

Epoch: 5| Step: 1
Training loss: 1.175854753496966
Validation loss: 2.3425812463082396

Epoch: 5| Step: 2
Training loss: 1.1473531469484717
Validation loss: 2.3264193423322777

Epoch: 5| Step: 3
Training loss: 1.8875290293703295
Validation loss: 2.3151263062651477

Epoch: 5| Step: 4
Training loss: 1.1017478624586712
Validation loss: 2.333446349060008

Epoch: 5| Step: 5
Training loss: 1.2830159182850678
Validation loss: 2.3652861927776616

Epoch: 5| Step: 6
Training loss: 0.778673309725954
Validation loss: 2.368004061494358

Epoch: 5| Step: 7
Training loss: 1.2203170287845602
Validation loss: 2.3261251152402034

Epoch: 5| Step: 8
Training loss: 0.8962024253657459
Validation loss: 2.3500509825573834

Epoch: 5| Step: 9
Training loss: 0.8246534385455423
Validation loss: 2.3606380131832965

Epoch: 5| Step: 10
Training loss: 0.887502114199417
Validation loss: 2.347115107090125

Epoch: 453| Step: 0
Training loss: 0.8808927339382129
Validation loss: 2.3863398563008285

Epoch: 5| Step: 1
Training loss: 1.0181719608611555
Validation loss: 2.455033267005699

Epoch: 5| Step: 2
Training loss: 1.1337153552901533
Validation loss: 2.390282732087668

Epoch: 5| Step: 3
Training loss: 0.719757617710051
Validation loss: 2.3104168256650865

Epoch: 5| Step: 4
Training loss: 1.1488397633346643
Validation loss: 2.3026952097876103

Epoch: 5| Step: 5
Training loss: 1.274857273715029
Validation loss: 2.360090084758593

Epoch: 5| Step: 6
Training loss: 1.0379597828558247
Validation loss: 2.334849778586991

Epoch: 5| Step: 7
Training loss: 0.675865035844166
Validation loss: 2.4428040384932372

Epoch: 5| Step: 8
Training loss: 1.9807011394605885
Validation loss: 2.3637644766709482

Epoch: 5| Step: 9
Training loss: 0.6910858920756948
Validation loss: 2.3492709690923337

Epoch: 5| Step: 10
Training loss: 1.0493299253506154
Validation loss: 2.315791118685345

Epoch: 454| Step: 0
Training loss: 1.0317195632471499
Validation loss: 2.2701945897211218

Epoch: 5| Step: 1
Training loss: 1.3576897885059587
Validation loss: 2.410536192912028

Epoch: 5| Step: 2
Training loss: 0.9448928216675869
Validation loss: 2.369481323179694

Epoch: 5| Step: 3
Training loss: 0.8523396087182241
Validation loss: 2.3732205413344274

Epoch: 5| Step: 4
Training loss: 0.9238279314424017
Validation loss: 2.3288844746535275

Epoch: 5| Step: 5
Training loss: 1.118460510136583
Validation loss: 2.4078438131871263

Epoch: 5| Step: 6
Training loss: 1.7665060765075258
Validation loss: 2.3734203886473426

Epoch: 5| Step: 7
Training loss: 0.8932455559979513
Validation loss: 2.4514332634750313

Epoch: 5| Step: 8
Training loss: 1.0734208906685017
Validation loss: 2.3522448836242895

Epoch: 5| Step: 9
Training loss: 1.2851073652901053
Validation loss: 2.403618606837853

Epoch: 5| Step: 10
Training loss: 1.3656248481104436
Validation loss: 2.3823050477902603

Epoch: 455| Step: 0
Training loss: 0.8125625732975811
Validation loss: 2.3323885752688733

Epoch: 5| Step: 1
Training loss: 0.9506323692342125
Validation loss: 2.357516861974263

Epoch: 5| Step: 2
Training loss: 0.9896263046304232
Validation loss: 2.3550751857156746

Epoch: 5| Step: 3
Training loss: 0.7976397416426886
Validation loss: 2.3844497679908256

Epoch: 5| Step: 4
Training loss: 1.1126804269789652
Validation loss: 2.406343771219804

Epoch: 5| Step: 5
Training loss: 1.336922711719876
Validation loss: 2.28089936590769

Epoch: 5| Step: 6
Training loss: 1.1192369669244258
Validation loss: 2.3062359979942957

Epoch: 5| Step: 7
Training loss: 1.730085894596709
Validation loss: 2.3642162247452534

Epoch: 5| Step: 8
Training loss: 1.228707739723227
Validation loss: 2.3332845370365978

Epoch: 5| Step: 9
Training loss: 1.2750072516440818
Validation loss: 2.3621681976101665

Epoch: 5| Step: 10
Training loss: 0.8778208494349503
Validation loss: 2.3642982122001617

Epoch: 456| Step: 0
Training loss: 1.0214333749442854
Validation loss: 2.363091451409562

Epoch: 5| Step: 1
Training loss: 1.1934439321675736
Validation loss: 2.4479090082855617

Epoch: 5| Step: 2
Training loss: 1.1912416938580221
Validation loss: 2.3694524908810566

Epoch: 5| Step: 3
Training loss: 1.1852545841388284
Validation loss: 2.383496671185788

Epoch: 5| Step: 4
Training loss: 1.143561932469978
Validation loss: 2.390304393799316

Epoch: 5| Step: 5
Training loss: 1.9743174592774928
Validation loss: 2.3751952043070688

Epoch: 5| Step: 6
Training loss: 0.8247178722366947
Validation loss: 2.3405834834233628

Epoch: 5| Step: 7
Training loss: 0.8752272174640945
Validation loss: 2.337651327153812

Epoch: 5| Step: 8
Training loss: 1.094561956656979
Validation loss: 2.3484513971057837

Epoch: 5| Step: 9
Training loss: 0.9937056693499735
Validation loss: 2.3880154810048246

Epoch: 5| Step: 10
Training loss: 1.0437013717561943
Validation loss: 2.326200143325079

Epoch: 457| Step: 0
Training loss: 0.8961608568920404
Validation loss: 2.3497968182669604

Epoch: 5| Step: 1
Training loss: 0.9507671333211627
Validation loss: 2.376171148212868

Epoch: 5| Step: 2
Training loss: 0.8573538160141619
Validation loss: 2.424623344304739

Epoch: 5| Step: 3
Training loss: 1.0179028715889717
Validation loss: 2.416994593107307

Epoch: 5| Step: 4
Training loss: 0.9164761359712923
Validation loss: 2.370641484916371

Epoch: 5| Step: 5
Training loss: 1.1998050014688564
Validation loss: 2.3745641330004594

Epoch: 5| Step: 6
Training loss: 1.9074501262059285
Validation loss: 2.333096870916098

Epoch: 5| Step: 7
Training loss: 1.3349791541597253
Validation loss: 2.3701977659165396

Epoch: 5| Step: 8
Training loss: 0.8288279015476682
Validation loss: 2.3830205032095684

Epoch: 5| Step: 9
Training loss: 0.9001028465741335
Validation loss: 2.301385723054265

Epoch: 5| Step: 10
Training loss: 1.0130503371517787
Validation loss: 2.4023904135089036

Epoch: 458| Step: 0
Training loss: 1.3566244953140167
Validation loss: 2.3221206185780563

Epoch: 5| Step: 1
Training loss: 0.646391132925787
Validation loss: 2.376665484525005

Epoch: 5| Step: 2
Training loss: 1.7921412600843722
Validation loss: 2.468567809940374

Epoch: 5| Step: 3
Training loss: 0.8925786258353867
Validation loss: 2.4024210919671725

Epoch: 5| Step: 4
Training loss: 1.1718343091893835
Validation loss: 2.341605817812681

Epoch: 5| Step: 5
Training loss: 1.2864081595619918
Validation loss: 2.3320467690006272

Epoch: 5| Step: 6
Training loss: 0.7136138591768716
Validation loss: 2.374941346956008

Epoch: 5| Step: 7
Training loss: 1.0856859203896119
Validation loss: 2.395106840980444

Epoch: 5| Step: 8
Training loss: 0.8702646937501014
Validation loss: 2.304967083457368

Epoch: 5| Step: 9
Training loss: 1.0114887226435876
Validation loss: 2.3897151053239583

Epoch: 5| Step: 10
Training loss: 1.1992894751354208
Validation loss: 2.3391367937052685

Epoch: 459| Step: 0
Training loss: 1.3316043382189537
Validation loss: 2.4408250337226147

Epoch: 5| Step: 1
Training loss: 0.7669362109191074
Validation loss: 2.324736569578513

Epoch: 5| Step: 2
Training loss: 1.0840579995935868
Validation loss: 2.39122762744645

Epoch: 5| Step: 3
Training loss: 0.9594732774727632
Validation loss: 2.3326626614378436

Epoch: 5| Step: 4
Training loss: 0.9562361236263563
Validation loss: 2.351653616529977

Epoch: 5| Step: 5
Training loss: 0.8033936848928551
Validation loss: 2.376524212151187

Epoch: 5| Step: 6
Training loss: 1.9466180671652213
Validation loss: 2.3424399183906366

Epoch: 5| Step: 7
Training loss: 0.8773758512961027
Validation loss: 2.3664990462338698

Epoch: 5| Step: 8
Training loss: 1.2161593657672585
Validation loss: 2.3712309964716987

Epoch: 5| Step: 9
Training loss: 1.1091088526442547
Validation loss: 2.3122818080907908

Epoch: 5| Step: 10
Training loss: 0.7566680131247664
Validation loss: 2.362212848243552

Epoch: 460| Step: 0
Training loss: 1.2262440164713644
Validation loss: 2.3855314845536277

Epoch: 5| Step: 1
Training loss: 1.1718591307519262
Validation loss: 2.426381841357859

Epoch: 5| Step: 2
Training loss: 0.7921833226321381
Validation loss: 2.3491645273015984

Epoch: 5| Step: 3
Training loss: 0.8850423956807972
Validation loss: 2.399070550115321

Epoch: 5| Step: 4
Training loss: 0.9929370001662408
Validation loss: 2.38356038928892

Epoch: 5| Step: 5
Training loss: 1.1602286884542758
Validation loss: 2.3917946594480655

Epoch: 5| Step: 6
Training loss: 0.8940193010631946
Validation loss: 2.3915386090920543

Epoch: 5| Step: 7
Training loss: 0.7780880072812395
Validation loss: 2.336171646227698

Epoch: 5| Step: 8
Training loss: 1.830763974317835
Validation loss: 2.387333360829031

Epoch: 5| Step: 9
Training loss: 1.3372570458906012
Validation loss: 2.3739056286776146

Epoch: 5| Step: 10
Training loss: 1.0675224080291181
Validation loss: 2.3430878204899845

Epoch: 461| Step: 0
Training loss: 1.0440735412580158
Validation loss: 2.404374729377201

Epoch: 5| Step: 1
Training loss: 1.0292773018700536
Validation loss: 2.361887606007169

Epoch: 5| Step: 2
Training loss: 0.8910168237607017
Validation loss: 2.3268305236918656

Epoch: 5| Step: 3
Training loss: 1.9612027175095568
Validation loss: 2.3499332712396024

Epoch: 5| Step: 4
Training loss: 0.662241379623787
Validation loss: 2.3700519760017174

Epoch: 5| Step: 5
Training loss: 1.1068170096544472
Validation loss: 2.3411550440340108

Epoch: 5| Step: 6
Training loss: 1.0648944464836854
Validation loss: 2.4193256723019974

Epoch: 5| Step: 7
Training loss: 0.9224631163090601
Validation loss: 2.337544214228506

Epoch: 5| Step: 8
Training loss: 0.7955168201171644
Validation loss: 2.361389927464257

Epoch: 5| Step: 9
Training loss: 0.8486576054751831
Validation loss: 2.3695527881376326

Epoch: 5| Step: 10
Training loss: 1.0176037219556782
Validation loss: 2.364623134795397

Epoch: 462| Step: 0
Training loss: 1.0190512744106304
Validation loss: 2.316569953654668

Epoch: 5| Step: 1
Training loss: 0.9673586667746462
Validation loss: 2.347398585011045

Epoch: 5| Step: 2
Training loss: 1.3606461030149761
Validation loss: 2.346256753721

Epoch: 5| Step: 3
Training loss: 0.824848458792789
Validation loss: 2.3602344849232053

Epoch: 5| Step: 4
Training loss: 1.270095418138997
Validation loss: 2.3583785089664677

Epoch: 5| Step: 5
Training loss: 0.9499420424399881
Validation loss: 2.3315511400178055

Epoch: 5| Step: 6
Training loss: 0.7040941129546965
Validation loss: 2.350790445224051

Epoch: 5| Step: 7
Training loss: 0.9848050585867076
Validation loss: 2.366825245664922

Epoch: 5| Step: 8
Training loss: 0.7706457287799655
Validation loss: 2.3637221145245304

Epoch: 5| Step: 9
Training loss: 0.9696772967191154
Validation loss: 2.34927679963087

Epoch: 5| Step: 10
Training loss: 1.898623861576859
Validation loss: 2.333754817482394

Epoch: 463| Step: 0
Training loss: 0.7466579520903389
Validation loss: 2.425600807375014

Epoch: 5| Step: 1
Training loss: 1.1485050207517404
Validation loss: 2.33715996763322

Epoch: 5| Step: 2
Training loss: 1.2128283105344055
Validation loss: 2.329684478281763

Epoch: 5| Step: 3
Training loss: 1.102532412945653
Validation loss: 2.4598922106002004

Epoch: 5| Step: 4
Training loss: 1.0237464729592998
Validation loss: 2.370795213491031

Epoch: 5| Step: 5
Training loss: 0.8997258113059169
Validation loss: 2.3400174231801305

Epoch: 5| Step: 6
Training loss: 1.7714044958777053
Validation loss: 2.331428138599496

Epoch: 5| Step: 7
Training loss: 1.1497547095381269
Validation loss: 2.424212187747899

Epoch: 5| Step: 8
Training loss: 0.7543118033371529
Validation loss: 2.3370455294758927

Epoch: 5| Step: 9
Training loss: 1.1607196608618056
Validation loss: 2.3708430386063175

Epoch: 5| Step: 10
Training loss: 0.8522600239471675
Validation loss: 2.4427233321483315

Epoch: 464| Step: 0
Training loss: 1.006471910352865
Validation loss: 2.314994409009076

Epoch: 5| Step: 1
Training loss: 1.108215854747809
Validation loss: 2.372813561176306

Epoch: 5| Step: 2
Training loss: 1.8525680193852463
Validation loss: 2.3530528266446695

Epoch: 5| Step: 3
Training loss: 0.9063003131448794
Validation loss: 2.3711831359346456

Epoch: 5| Step: 4
Training loss: 0.9859769894872651
Validation loss: 2.3020868438247004

Epoch: 5| Step: 5
Training loss: 0.9397873947992458
Validation loss: 2.359974196744682

Epoch: 5| Step: 6
Training loss: 1.0004940600621604
Validation loss: 2.2738434096860853

Epoch: 5| Step: 7
Training loss: 1.0228961357236885
Validation loss: 2.3442812792595107

Epoch: 5| Step: 8
Training loss: 1.0311726627828053
Validation loss: 2.306113027591429

Epoch: 5| Step: 9
Training loss: 1.2476801803673023
Validation loss: 2.3360759120530976

Epoch: 5| Step: 10
Training loss: 0.6018713121311104
Validation loss: 2.3350976859742523

Epoch: 465| Step: 0
Training loss: 1.7022157394226527
Validation loss: 2.3162293459886283

Epoch: 5| Step: 1
Training loss: 0.731941818588086
Validation loss: 2.3382426550192243

Epoch: 5| Step: 2
Training loss: 1.0039944739854572
Validation loss: 2.3795183709881083

Epoch: 5| Step: 3
Training loss: 0.9822864477046592
Validation loss: 2.3360282835585977

Epoch: 5| Step: 4
Training loss: 0.9058678248687028
Validation loss: 2.3454413936066194

Epoch: 5| Step: 5
Training loss: 1.0329394517862693
Validation loss: 2.303238891384896

Epoch: 5| Step: 6
Training loss: 1.1512932078219225
Validation loss: 2.3497062101715813

Epoch: 5| Step: 7
Training loss: 1.4493221441437694
Validation loss: 2.3694552715034125

Epoch: 5| Step: 8
Training loss: 0.8795630819307504
Validation loss: 2.3610299976160363

Epoch: 5| Step: 9
Training loss: 0.6908960992701615
Validation loss: 2.4025018578127217

Epoch: 5| Step: 10
Training loss: 0.9516057272427246
Validation loss: 2.3780423805432207

Epoch: 466| Step: 0
Training loss: 1.8824686709934189
Validation loss: 2.3541964406461005

Epoch: 5| Step: 1
Training loss: 1.1034008945474598
Validation loss: 2.368616386089217

Epoch: 5| Step: 2
Training loss: 1.0861246510339493
Validation loss: 2.3908019113332095

Epoch: 5| Step: 3
Training loss: 0.9634615925001531
Validation loss: 2.363596492126705

Epoch: 5| Step: 4
Training loss: 1.0864325842483633
Validation loss: 2.3019014928053965

Epoch: 5| Step: 5
Training loss: 0.8559918480868196
Validation loss: 2.3178528148327056

Epoch: 5| Step: 6
Training loss: 0.7567755299733326
Validation loss: 2.4123553555798756

Epoch: 5| Step: 7
Training loss: 0.647220872012173
Validation loss: 2.4163682143008147

Epoch: 5| Step: 8
Training loss: 1.2602982215819765
Validation loss: 2.4317727806952845

Epoch: 5| Step: 9
Training loss: 1.0875406849584155
Validation loss: 2.3613267972161376

Epoch: 5| Step: 10
Training loss: 1.1618311444768414
Validation loss: 2.3047254786934745

Epoch: 467| Step: 0
Training loss: 1.0632901339191343
Validation loss: 2.4104058896982585

Epoch: 5| Step: 1
Training loss: 1.748320591131323
Validation loss: 2.3578205155776533

Epoch: 5| Step: 2
Training loss: 1.0738396547877347
Validation loss: 2.4192161517231794

Epoch: 5| Step: 3
Training loss: 0.898040949340226
Validation loss: 2.3128661863789404

Epoch: 5| Step: 4
Training loss: 1.0560190907725053
Validation loss: 2.368267741917606

Epoch: 5| Step: 5
Training loss: 1.22618451945921
Validation loss: 2.2665108244264

Epoch: 5| Step: 6
Training loss: 0.7240809650067044
Validation loss: 2.345701243555977

Epoch: 5| Step: 7
Training loss: 0.971220250993533
Validation loss: 2.3259475533859497

Epoch: 5| Step: 8
Training loss: 1.0172375129088915
Validation loss: 2.29488874011358

Epoch: 5| Step: 9
Training loss: 1.184526132890331
Validation loss: 2.3072336033529766

Epoch: 5| Step: 10
Training loss: 0.7385167952108277
Validation loss: 2.4111721035766505

Epoch: 468| Step: 0
Training loss: 1.0745372508121223
Validation loss: 2.3936976156514

Epoch: 5| Step: 1
Training loss: 0.6981214085403722
Validation loss: 2.3363654509830414

Epoch: 5| Step: 2
Training loss: 1.810703637045308
Validation loss: 2.360093205815553

Epoch: 5| Step: 3
Training loss: 0.6438195663196193
Validation loss: 2.4398500122323243

Epoch: 5| Step: 4
Training loss: 1.2728726122902205
Validation loss: 2.3040726203137805

Epoch: 5| Step: 5
Training loss: 1.1587177439194813
Validation loss: 2.3506908698961166

Epoch: 5| Step: 6
Training loss: 1.0202121141948026
Validation loss: 2.4379949264439253

Epoch: 5| Step: 7
Training loss: 0.5351830635871447
Validation loss: 2.339971908594942

Epoch: 5| Step: 8
Training loss: 1.0739886783095458
Validation loss: 2.3657224373505312

Epoch: 5| Step: 9
Training loss: 1.407557155471777
Validation loss: 2.3494179372439157

Epoch: 5| Step: 10
Training loss: 0.7140882074248571
Validation loss: 2.3886961056286067

Epoch: 469| Step: 0
Training loss: 0.8123910170603638
Validation loss: 2.342063555209628

Epoch: 5| Step: 1
Training loss: 0.8905186505985733
Validation loss: 2.415469130332627

Epoch: 5| Step: 2
Training loss: 1.7399965202910608
Validation loss: 2.361483808181805

Epoch: 5| Step: 3
Training loss: 0.8230857836303307
Validation loss: 2.330709051413304

Epoch: 5| Step: 4
Training loss: 1.3930653793700212
Validation loss: 2.3939995987397737

Epoch: 5| Step: 5
Training loss: 0.7357460372252946
Validation loss: 2.3957334742839644

Epoch: 5| Step: 6
Training loss: 1.0386427985371998
Validation loss: 2.316955032145668

Epoch: 5| Step: 7
Training loss: 1.0742102050441393
Validation loss: 2.44175254075512

Epoch: 5| Step: 8
Training loss: 1.1598459464577464
Validation loss: 2.3474059196766275

Epoch: 5| Step: 9
Training loss: 0.9096264258915172
Validation loss: 2.376375060445007

Epoch: 5| Step: 10
Training loss: 1.1748327440572528
Validation loss: 2.3847662732293595

Epoch: 470| Step: 0
Training loss: 0.8788455518320125
Validation loss: 2.368308552752093

Epoch: 5| Step: 1
Training loss: 0.6638345888264658
Validation loss: 2.397941525514688

Epoch: 5| Step: 2
Training loss: 0.6434447870494955
Validation loss: 2.3713714328348625

Epoch: 5| Step: 3
Training loss: 1.3128777823122237
Validation loss: 2.436152510377899

Epoch: 5| Step: 4
Training loss: 1.1494703254768766
Validation loss: 2.4405449369027057

Epoch: 5| Step: 5
Training loss: 0.913362349016808
Validation loss: 2.420905624667746

Epoch: 5| Step: 6
Training loss: 0.9738375985013376
Validation loss: 2.381013055429692

Epoch: 5| Step: 7
Training loss: 1.744443108962426
Validation loss: 2.421153638244665

Epoch: 5| Step: 8
Training loss: 1.0970793052876597
Validation loss: 2.37025909591877

Epoch: 5| Step: 9
Training loss: 1.3146197594595042
Validation loss: 2.3635960918961763

Epoch: 5| Step: 10
Training loss: 1.1261939494827262
Validation loss: 2.384403114635315

Epoch: 471| Step: 0
Training loss: 1.1209797552017902
Validation loss: 2.2927782072099605

Epoch: 5| Step: 1
Training loss: 1.373812639649741
Validation loss: 2.392205801131889

Epoch: 5| Step: 2
Training loss: 1.1485880020033064
Validation loss: 2.344159202813002

Epoch: 5| Step: 3
Training loss: 1.057471493366096
Validation loss: 2.364402784341217

Epoch: 5| Step: 4
Training loss: 0.8307374377820493
Validation loss: 2.373765621419344

Epoch: 5| Step: 5
Training loss: 1.062016601551275
Validation loss: 2.406077242774324

Epoch: 5| Step: 6
Training loss: 1.2945490742056607
Validation loss: 2.3459753900514246

Epoch: 5| Step: 7
Training loss: 0.8117487442011587
Validation loss: 2.351362492502583

Epoch: 5| Step: 8
Training loss: 1.017594994461896
Validation loss: 2.3458134384796456

Epoch: 5| Step: 9
Training loss: 1.6842715144879048
Validation loss: 2.386517323229016

Epoch: 5| Step: 10
Training loss: 1.061299711934497
Validation loss: 2.332683309166326

Epoch: 472| Step: 0
Training loss: 1.4462958212726107
Validation loss: 2.374045171977454

Epoch: 5| Step: 1
Training loss: 1.7559530638415568
Validation loss: 2.3900813214318823

Epoch: 5| Step: 2
Training loss: 1.0562527944313418
Validation loss: 2.3492943086194753

Epoch: 5| Step: 3
Training loss: 0.9631378908674738
Validation loss: 2.376515442016754

Epoch: 5| Step: 4
Training loss: 1.069654610585424
Validation loss: 2.340917523289468

Epoch: 5| Step: 5
Training loss: 0.9562231583661492
Validation loss: 2.323161547427631

Epoch: 5| Step: 6
Training loss: 0.8381226402892391
Validation loss: 2.397845314690356

Epoch: 5| Step: 7
Training loss: 0.7638624104813994
Validation loss: 2.328948387164965

Epoch: 5| Step: 8
Training loss: 0.778402403136383
Validation loss: 2.3983393844764973

Epoch: 5| Step: 9
Training loss: 1.0435056982976953
Validation loss: 2.394489575630491

Epoch: 5| Step: 10
Training loss: 0.689233242341762
Validation loss: 2.401395161016363

Epoch: 473| Step: 0
Training loss: 1.0129828490888766
Validation loss: 2.4314479458484883

Epoch: 5| Step: 1
Training loss: 0.7244749124394301
Validation loss: 2.3200462958973374

Epoch: 5| Step: 2
Training loss: 0.8625931910603645
Validation loss: 2.4340905297228987

Epoch: 5| Step: 3
Training loss: 1.2377632573942747
Validation loss: 2.3191969320699717

Epoch: 5| Step: 4
Training loss: 1.7404853477135247
Validation loss: 2.3496154512850156

Epoch: 5| Step: 5
Training loss: 0.8322669756445188
Validation loss: 2.368192594927398

Epoch: 5| Step: 6
Training loss: 0.9024713599397349
Validation loss: 2.3589879537285596

Epoch: 5| Step: 7
Training loss: 1.2420545302903994
Validation loss: 2.4490827587534474

Epoch: 5| Step: 8
Training loss: 1.1047008529784106
Validation loss: 2.3698650530396734

Epoch: 5| Step: 9
Training loss: 1.0031082009308159
Validation loss: 2.3029018296924564

Epoch: 5| Step: 10
Training loss: 1.063196402814476
Validation loss: 2.2957124327360923

Epoch: 474| Step: 0
Training loss: 1.0485422323705302
Validation loss: 2.345932135139392

Epoch: 5| Step: 1
Training loss: 0.5326390339225208
Validation loss: 2.3924772574898325

Epoch: 5| Step: 2
Training loss: 0.8477518405719959
Validation loss: 2.368388510765149

Epoch: 5| Step: 3
Training loss: 1.0536743949655791
Validation loss: 2.3721673909341425

Epoch: 5| Step: 4
Training loss: 0.9027514176718082
Validation loss: 2.328724372913915

Epoch: 5| Step: 5
Training loss: 0.7172856548351739
Validation loss: 2.334304534568563

Epoch: 5| Step: 6
Training loss: 1.1329026811154346
Validation loss: 2.3204563483397944

Epoch: 5| Step: 7
Training loss: 1.2108113869246608
Validation loss: 2.4301798906867447

Epoch: 5| Step: 8
Training loss: 1.9053587784417299
Validation loss: 2.293001440823203

Epoch: 5| Step: 9
Training loss: 0.7673859100784152
Validation loss: 2.3494878219943467

Epoch: 5| Step: 10
Training loss: 0.889076023635852
Validation loss: 2.2913200341863997

Epoch: 475| Step: 0
Training loss: 1.373006155351704
Validation loss: 2.398574901590717

Epoch: 5| Step: 1
Training loss: 1.0127345107906185
Validation loss: 2.3990411955642013

Epoch: 5| Step: 2
Training loss: 1.1899733134090325
Validation loss: 2.4040688712262046

Epoch: 5| Step: 3
Training loss: 0.9190017082916587
Validation loss: 2.3890628213212297

Epoch: 5| Step: 4
Training loss: 1.0963349450148738
Validation loss: 2.4127604807729

Epoch: 5| Step: 5
Training loss: 1.834703071020056
Validation loss: 2.378041082574693

Epoch: 5| Step: 6
Training loss: 0.6577439560143105
Validation loss: 2.415808875153501

Epoch: 5| Step: 7
Training loss: 1.0588350478493225
Validation loss: 2.4163812660458825

Epoch: 5| Step: 8
Training loss: 0.8690793133658931
Validation loss: 2.4121671216280745

Epoch: 5| Step: 9
Training loss: 0.7472009482264373
Validation loss: 2.3588957082080113

Epoch: 5| Step: 10
Training loss: 0.8446750514912195
Validation loss: 2.387468912430886

Epoch: 476| Step: 0
Training loss: 0.8881502402126333
Validation loss: 2.3656204296196925

Epoch: 5| Step: 1
Training loss: 0.9958737597912066
Validation loss: 2.3533560246233463

Epoch: 5| Step: 2
Training loss: 1.9067756053285159
Validation loss: 2.331366616213263

Epoch: 5| Step: 3
Training loss: 0.6099342567552284
Validation loss: 2.358981959183445

Epoch: 5| Step: 4
Training loss: 0.7435352335920837
Validation loss: 2.397203084015751

Epoch: 5| Step: 5
Training loss: 1.0310332908657578
Validation loss: 2.3436633254674586

Epoch: 5| Step: 6
Training loss: 1.2365145429750144
Validation loss: 2.3337464133570553

Epoch: 5| Step: 7
Training loss: 1.0781039913176143
Validation loss: 2.3548278518968107

Epoch: 5| Step: 8
Training loss: 0.7111429190185994
Validation loss: 2.443648796009579

Epoch: 5| Step: 9
Training loss: 0.7425922695460278
Validation loss: 2.3859240038132032

Epoch: 5| Step: 10
Training loss: 0.953565808280151
Validation loss: 2.3788566816560683

Epoch: 477| Step: 0
Training loss: 0.7612549372295259
Validation loss: 2.4207841859884613

Epoch: 5| Step: 1
Training loss: 1.23467564844822
Validation loss: 2.378856449955366

Epoch: 5| Step: 2
Training loss: 0.8205203565016865
Validation loss: 2.2748011116608833

Epoch: 5| Step: 3
Training loss: 0.6346303472889102
Validation loss: 2.384340302329082

Epoch: 5| Step: 4
Training loss: 0.7886909516565307
Validation loss: 2.452539925332803

Epoch: 5| Step: 5
Training loss: 1.1747212241594436
Validation loss: 2.409343885259123

Epoch: 5| Step: 6
Training loss: 0.7749804125125597
Validation loss: 2.3958067804677956

Epoch: 5| Step: 7
Training loss: 1.7236487196061305
Validation loss: 2.3520061595103066

Epoch: 5| Step: 8
Training loss: 1.1753404367621358
Validation loss: 2.449719037295924

Epoch: 5| Step: 9
Training loss: 0.9746335319017416
Validation loss: 2.356637828561288

Epoch: 5| Step: 10
Training loss: 1.219812663500529
Validation loss: 2.365045400877178

Epoch: 478| Step: 0
Training loss: 0.8766748883281272
Validation loss: 2.3121250639070228

Epoch: 5| Step: 1
Training loss: 1.2613747898517842
Validation loss: 2.3491793863802584

Epoch: 5| Step: 2
Training loss: 0.9778878335775013
Validation loss: 2.324611020129702

Epoch: 5| Step: 3
Training loss: 0.9709352641698401
Validation loss: 2.329126482200552

Epoch: 5| Step: 4
Training loss: 0.942012955422616
Validation loss: 2.311160843081137

Epoch: 5| Step: 5
Training loss: 0.6956661053874456
Validation loss: 2.318595583855775

Epoch: 5| Step: 6
Training loss: 1.6924900168458314
Validation loss: 2.3508377634560493

Epoch: 5| Step: 7
Training loss: 0.7733216632450272
Validation loss: 2.391005383177352

Epoch: 5| Step: 8
Training loss: 1.1021547821960134
Validation loss: 2.390293341492382

Epoch: 5| Step: 9
Training loss: 0.6238293651933948
Validation loss: 2.430132251175504

Epoch: 5| Step: 10
Training loss: 1.0078158711221779
Validation loss: 2.4344477868340784

Epoch: 479| Step: 0
Training loss: 0.7145315436974278
Validation loss: 2.3198738742854186

Epoch: 5| Step: 1
Training loss: 0.8837985717936274
Validation loss: 2.365282658305434

Epoch: 5| Step: 2
Training loss: 1.183882020398038
Validation loss: 2.3952368301777267

Epoch: 5| Step: 3
Training loss: 0.8728456201220893
Validation loss: 2.37903473858976

Epoch: 5| Step: 4
Training loss: 1.2092894629852566
Validation loss: 2.3874369948786964

Epoch: 5| Step: 5
Training loss: 0.9186439790341845
Validation loss: 2.4272482267310775

Epoch: 5| Step: 6
Training loss: 1.0113346151215141
Validation loss: 2.419005451097919

Epoch: 5| Step: 7
Training loss: 0.8176960954337558
Validation loss: 2.363087996375912

Epoch: 5| Step: 8
Training loss: 1.7699397880743892
Validation loss: 2.375272464289358

Epoch: 5| Step: 9
Training loss: 0.9854809436978172
Validation loss: 2.364896634185778

Epoch: 5| Step: 10
Training loss: 0.9517984382762469
Validation loss: 2.4088874854943323

Epoch: 480| Step: 0
Training loss: 0.9026894835960264
Validation loss: 2.429399856144792

Epoch: 5| Step: 1
Training loss: 1.0252735470735288
Validation loss: 2.3704575241555994

Epoch: 5| Step: 2
Training loss: 0.9586687675788188
Validation loss: 2.351359235292464

Epoch: 5| Step: 3
Training loss: 0.7255290074560046
Validation loss: 2.326077772615734

Epoch: 5| Step: 4
Training loss: 1.0555458249653042
Validation loss: 2.392689568822816

Epoch: 5| Step: 5
Training loss: 0.8263972991672116
Validation loss: 2.3615609810122358

Epoch: 5| Step: 6
Training loss: 1.7512225921250528
Validation loss: 2.3821914667777753

Epoch: 5| Step: 7
Training loss: 1.0724863405402638
Validation loss: 2.3527672884838444

Epoch: 5| Step: 8
Training loss: 1.2130168167294537
Validation loss: 2.374259738914977

Epoch: 5| Step: 9
Training loss: 1.11791920208913
Validation loss: 2.3967637529718395

Epoch: 5| Step: 10
Training loss: 1.2496399837846024
Validation loss: 2.367781958226111

Epoch: 481| Step: 0
Training loss: 0.8154224509643343
Validation loss: 2.3266398947128932

Epoch: 5| Step: 1
Training loss: 0.8980011253434842
Validation loss: 2.4023478104698532

Epoch: 5| Step: 2
Training loss: 0.6167991237104131
Validation loss: 2.389467144909604

Epoch: 5| Step: 3
Training loss: 0.9658640050310393
Validation loss: 2.2743992120485377

Epoch: 5| Step: 4
Training loss: 0.9403274496404442
Validation loss: 2.3595950806270145

Epoch: 5| Step: 5
Training loss: 0.9872976240590247
Validation loss: 2.353973490370119

Epoch: 5| Step: 6
Training loss: 1.1091635059184592
Validation loss: 2.3281852217204952

Epoch: 5| Step: 7
Training loss: 1.064128861339531
Validation loss: 2.2930697317734414

Epoch: 5| Step: 8
Training loss: 1.8460926754916467
Validation loss: 2.399952627341709

Epoch: 5| Step: 9
Training loss: 0.9869277189160345
Validation loss: 2.387565626215195

Epoch: 5| Step: 10
Training loss: 0.7159993987214105
Validation loss: 2.354200526444189

Epoch: 482| Step: 0
Training loss: 0.7608906474954097
Validation loss: 2.32795443271005

Epoch: 5| Step: 1
Training loss: 0.8211034322325677
Validation loss: 2.3229889691283643

Epoch: 5| Step: 2
Training loss: 1.009284017141248
Validation loss: 2.397918393808782

Epoch: 5| Step: 3
Training loss: 1.1571570266885445
Validation loss: 2.3643129132778413

Epoch: 5| Step: 4
Training loss: 0.8678492864738687
Validation loss: 2.387156719742718

Epoch: 5| Step: 5
Training loss: 1.01348545954944
Validation loss: 2.3948179026343244

Epoch: 5| Step: 6
Training loss: 0.6838413335134012
Validation loss: 2.3502531938075717

Epoch: 5| Step: 7
Training loss: 0.9879644436480707
Validation loss: 2.468809613855067

Epoch: 5| Step: 8
Training loss: 0.7699852393333256
Validation loss: 2.282404496910174

Epoch: 5| Step: 9
Training loss: 0.9380281550100307
Validation loss: 2.358000513247427

Epoch: 5| Step: 10
Training loss: 1.8917338374755512
Validation loss: 2.3757024113830747

Epoch: 483| Step: 0
Training loss: 0.9208276909587713
Validation loss: 2.374779898823882

Epoch: 5| Step: 1
Training loss: 0.7900224643845122
Validation loss: 2.3708873561033914

Epoch: 5| Step: 2
Training loss: 1.7758408448758425
Validation loss: 2.393334123595495

Epoch: 5| Step: 3
Training loss: 0.799376730719416
Validation loss: 2.3356495171211185

Epoch: 5| Step: 4
Training loss: 1.3663655453306764
Validation loss: 2.403848162912897

Epoch: 5| Step: 5
Training loss: 1.0228486441832294
Validation loss: 2.3717270693744115

Epoch: 5| Step: 6
Training loss: 0.6817888683462234
Validation loss: 2.363852390425128

Epoch: 5| Step: 7
Training loss: 1.1095592721834013
Validation loss: 2.2922390704439315

Epoch: 5| Step: 8
Training loss: 0.8718497241878713
Validation loss: 2.3693977790380436

Epoch: 5| Step: 9
Training loss: 1.0204319975949883
Validation loss: 2.3257959050181802

Epoch: 5| Step: 10
Training loss: 0.9663198199591069
Validation loss: 2.3027570372803536

Epoch: 484| Step: 0
Training loss: 1.192428000653777
Validation loss: 2.3486292616983393

Epoch: 5| Step: 1
Training loss: 0.9924005294746884
Validation loss: 2.29517712432285

Epoch: 5| Step: 2
Training loss: 0.64276598007712
Validation loss: 2.4125024602861425

Epoch: 5| Step: 3
Training loss: 0.947560058139714
Validation loss: 2.2695866300335963

Epoch: 5| Step: 4
Training loss: 0.766543790742124
Validation loss: 2.37681755261501

Epoch: 5| Step: 5
Training loss: 1.7537716004610926
Validation loss: 2.3591804475793614

Epoch: 5| Step: 6
Training loss: 1.0227267294217603
Validation loss: 2.322179065702459

Epoch: 5| Step: 7
Training loss: 1.008953542677629
Validation loss: 2.2849795458016766

Epoch: 5| Step: 8
Training loss: 0.7545741389020041
Validation loss: 2.3433691753150128

Epoch: 5| Step: 9
Training loss: 0.9580865452384568
Validation loss: 2.341758632404955

Epoch: 5| Step: 10
Training loss: 1.1443238054092388
Validation loss: 2.393623256848804

Epoch: 485| Step: 0
Training loss: 1.7045638979289697
Validation loss: 2.317733124815495

Epoch: 5| Step: 1
Training loss: 1.1168613624700765
Validation loss: 2.420734815912285

Epoch: 5| Step: 2
Training loss: 0.6510359166209292
Validation loss: 2.3318157492571356

Epoch: 5| Step: 3
Training loss: 1.0096307365591723
Validation loss: 2.3263824960735775

Epoch: 5| Step: 4
Training loss: 0.8910991678034754
Validation loss: 2.4055005240640783

Epoch: 5| Step: 5
Training loss: 1.0812604341389387
Validation loss: 2.3622972015811783

Epoch: 5| Step: 6
Training loss: 1.3012574386750506
Validation loss: 2.379872093129583

Epoch: 5| Step: 7
Training loss: 0.801186510209986
Validation loss: 2.4271899395367846

Epoch: 5| Step: 8
Training loss: 0.850423278321864
Validation loss: 2.3223052146910454

Epoch: 5| Step: 9
Training loss: 0.992301333648176
Validation loss: 2.352379327209266

Epoch: 5| Step: 10
Training loss: 0.9166613419696018
Validation loss: 2.3631500801655996

Epoch: 486| Step: 0
Training loss: 1.104460940943538
Validation loss: 2.2829619650939774

Epoch: 5| Step: 1
Training loss: 0.9665482634893597
Validation loss: 2.4214795824861652

Epoch: 5| Step: 2
Training loss: 0.9092311496285722
Validation loss: 2.334517270501867

Epoch: 5| Step: 3
Training loss: 0.830661200889109
Validation loss: 2.404243722757318

Epoch: 5| Step: 4
Training loss: 0.9325978541741993
Validation loss: 2.3743361509772036

Epoch: 5| Step: 5
Training loss: 0.8155712256115727
Validation loss: 2.3913949531746934

Epoch: 5| Step: 6
Training loss: 0.9450514882305616
Validation loss: 2.428476032186361

Epoch: 5| Step: 7
Training loss: 1.1221649687759048
Validation loss: 2.342367192818648

Epoch: 5| Step: 8
Training loss: 0.9421419300300782
Validation loss: 2.314588856605807

Epoch: 5| Step: 9
Training loss: 1.8563762172340255
Validation loss: 2.382693852362659

Epoch: 5| Step: 10
Training loss: 0.9628014513549991
Validation loss: 2.367275790204671

Epoch: 487| Step: 0
Training loss: 1.4745563421755032
Validation loss: 2.3755425544272697

Epoch: 5| Step: 1
Training loss: 0.9912297590000304
Validation loss: 2.4693018508191815

Epoch: 5| Step: 2
Training loss: 0.7623208038635931
Validation loss: 2.2531263480379344

Epoch: 5| Step: 3
Training loss: 0.8996887119042574
Validation loss: 2.355613963462058

Epoch: 5| Step: 4
Training loss: 0.7388763048021402
Validation loss: 2.3621649178575277

Epoch: 5| Step: 5
Training loss: 1.6848084919935569
Validation loss: 2.393602821522573

Epoch: 5| Step: 6
Training loss: 0.9688489924889674
Validation loss: 2.3235719531724346

Epoch: 5| Step: 7
Training loss: 1.0312054942381979
Validation loss: 2.399983279279346

Epoch: 5| Step: 8
Training loss: 0.873993430874577
Validation loss: 2.4067355293224555

Epoch: 5| Step: 9
Training loss: 0.8191684192458919
Validation loss: 2.3613325187324463

Epoch: 5| Step: 10
Training loss: 0.971145651819794
Validation loss: 2.2870473060842165

Epoch: 488| Step: 0
Training loss: 1.6819425128044014
Validation loss: 2.3613394057043267

Epoch: 5| Step: 1
Training loss: 1.007969629621144
Validation loss: 2.372629816908992

Epoch: 5| Step: 2
Training loss: 0.7462889331137638
Validation loss: 2.402580671202055

Epoch: 5| Step: 3
Training loss: 0.7895037861782171
Validation loss: 2.4337313714897606

Epoch: 5| Step: 4
Training loss: 0.9948928175757917
Validation loss: 2.372582401673093

Epoch: 5| Step: 5
Training loss: 0.7709834923418023
Validation loss: 2.3929341998655373

Epoch: 5| Step: 6
Training loss: 0.9028183650812959
Validation loss: 2.360970351985658

Epoch: 5| Step: 7
Training loss: 0.826608673132901
Validation loss: 2.353000647944203

Epoch: 5| Step: 8
Training loss: 0.7327378062102714
Validation loss: 2.3644648295426074

Epoch: 5| Step: 9
Training loss: 0.8965328427844811
Validation loss: 2.4025929124773255

Epoch: 5| Step: 10
Training loss: 1.5457237660666527
Validation loss: 2.4245759841936168

Epoch: 489| Step: 0
Training loss: 1.832333798020815
Validation loss: 2.356802696638558

Epoch: 5| Step: 1
Training loss: 1.0020631726008769
Validation loss: 2.261854146128461

Epoch: 5| Step: 2
Training loss: 0.8824376686172222
Validation loss: 2.378592463534542

Epoch: 5| Step: 3
Training loss: 0.9364209004616194
Validation loss: 2.340171747012894

Epoch: 5| Step: 4
Training loss: 0.6830818003111828
Validation loss: 2.271485853490531

Epoch: 5| Step: 5
Training loss: 1.3153768527402068
Validation loss: 2.36033859682801

Epoch: 5| Step: 6
Training loss: 0.8298691071285146
Validation loss: 2.328580730370367

Epoch: 5| Step: 7
Training loss: 0.7437736828022675
Validation loss: 2.3867848616420777

Epoch: 5| Step: 8
Training loss: 0.9127100206394501
Validation loss: 2.323542417140246

Epoch: 5| Step: 9
Training loss: 0.993931176806015
Validation loss: 2.372422981766495

Epoch: 5| Step: 10
Training loss: 0.8645847542685969
Validation loss: 2.396244354534537

Epoch: 490| Step: 0
Training loss: 0.9030648524968994
Validation loss: 2.373578601005856

Epoch: 5| Step: 1
Training loss: 1.076143129383698
Validation loss: 2.3543761818322926

Epoch: 5| Step: 2
Training loss: 1.071777621814457
Validation loss: 2.3628609975430486

Epoch: 5| Step: 3
Training loss: 0.8215971923212775
Validation loss: 2.4118037031755484

Epoch: 5| Step: 4
Training loss: 1.8381010901884791
Validation loss: 2.3621192775974653

Epoch: 5| Step: 5
Training loss: 0.9823121147953527
Validation loss: 2.3419371432252714

Epoch: 5| Step: 6
Training loss: 0.7907001007356937
Validation loss: 2.355991306717635

Epoch: 5| Step: 7
Training loss: 0.6369183701337652
Validation loss: 2.314404889250491

Epoch: 5| Step: 8
Training loss: 0.881995743204947
Validation loss: 2.395351975403219

Epoch: 5| Step: 9
Training loss: 0.8957147556752615
Validation loss: 2.3285692227083796

Epoch: 5| Step: 10
Training loss: 0.9676115668581204
Validation loss: 2.401970582197101

Epoch: 491| Step: 0
Training loss: 0.8936789504400647
Validation loss: 2.3430454805925476

Epoch: 5| Step: 1
Training loss: 0.9980463972295823
Validation loss: 2.367925436237119

Epoch: 5| Step: 2
Training loss: 0.765390983161714
Validation loss: 2.373672710311846

Epoch: 5| Step: 3
Training loss: 0.8580060632775997
Validation loss: 2.4037888619826653

Epoch: 5| Step: 4
Training loss: 0.9468693799144784
Validation loss: 2.298713375306264

Epoch: 5| Step: 5
Training loss: 1.715519661092762
Validation loss: 2.322036074836867

Epoch: 5| Step: 6
Training loss: 1.2439482583603887
Validation loss: 2.3879036580024575

Epoch: 5| Step: 7
Training loss: 1.0995114758887066
Validation loss: 2.4075044670851957

Epoch: 5| Step: 8
Training loss: 0.9741033490316757
Validation loss: 2.3414880000011404

Epoch: 5| Step: 9
Training loss: 1.0694383267369412
Validation loss: 2.3656389728662925

Epoch: 5| Step: 10
Training loss: 0.6700670401995162
Validation loss: 2.412923281027589

Epoch: 492| Step: 0
Training loss: 1.6864296379577621
Validation loss: 2.3203567904485207

Epoch: 5| Step: 1
Training loss: 0.6578138428445551
Validation loss: 2.424790712642667

Epoch: 5| Step: 2
Training loss: 0.9901417344678599
Validation loss: 2.4028934293097444

Epoch: 5| Step: 3
Training loss: 0.8156769337690615
Validation loss: 2.326688167973823

Epoch: 5| Step: 4
Training loss: 0.9634408056033551
Validation loss: 2.318247944223947

Epoch: 5| Step: 5
Training loss: 0.8596588359617618
Validation loss: 2.4189012523047406

Epoch: 5| Step: 6
Training loss: 1.1239636203946741
Validation loss: 2.3951528780447546

Epoch: 5| Step: 7
Training loss: 0.830022401622284
Validation loss: 2.3256654952873954

Epoch: 5| Step: 8
Training loss: 0.7806561310961475
Validation loss: 2.3176012099921723

Epoch: 5| Step: 9
Training loss: 0.8828012246281124
Validation loss: 2.3222035805662364

Epoch: 5| Step: 10
Training loss: 1.176564662166397
Validation loss: 2.3204180131134287

Epoch: 493| Step: 0
Training loss: 0.8072695370173897
Validation loss: 2.36699882694111

Epoch: 5| Step: 1
Training loss: 1.3992488787552684
Validation loss: 2.3417200662287776

Epoch: 5| Step: 2
Training loss: 0.8220167349668818
Validation loss: 2.326971291955463

Epoch: 5| Step: 3
Training loss: 0.9090929491930525
Validation loss: 2.345719396176433

Epoch: 5| Step: 4
Training loss: 0.8787680962382781
Validation loss: 2.329719131475182

Epoch: 5| Step: 5
Training loss: 0.9437230832638244
Validation loss: 2.3343003881370787

Epoch: 5| Step: 6
Training loss: 1.0550136485731059
Validation loss: 2.3515239212697607

Epoch: 5| Step: 7
Training loss: 0.728981053478984
Validation loss: 2.3027480440912518

Epoch: 5| Step: 8
Training loss: 0.8499914954264914
Validation loss: 2.34478981605952

Epoch: 5| Step: 9
Training loss: 1.7822109106761346
Validation loss: 2.3138967185570856

Epoch: 5| Step: 10
Training loss: 0.6955310606612796
Validation loss: 2.408929834527113

Epoch: 494| Step: 0
Training loss: 0.7618477736529994
Validation loss: 2.340961505482408

Epoch: 5| Step: 1
Training loss: 0.9628115731804091
Validation loss: 2.357190705333878

Epoch: 5| Step: 2
Training loss: 1.008654988953923
Validation loss: 2.384855832537786

Epoch: 5| Step: 3
Training loss: 0.6251401267323949
Validation loss: 2.3396850205595827

Epoch: 5| Step: 4
Training loss: 0.690744374172566
Validation loss: 2.3788023078874114

Epoch: 5| Step: 5
Training loss: 0.9805977725059516
Validation loss: 2.3773986591373

Epoch: 5| Step: 6
Training loss: 1.9029079595368958
Validation loss: 2.3958260541879324

Epoch: 5| Step: 7
Training loss: 1.0110149513067288
Validation loss: 2.3736335772180364

Epoch: 5| Step: 8
Training loss: 0.8127800018841876
Validation loss: 2.3771248052193448

Epoch: 5| Step: 9
Training loss: 0.8543267836565879
Validation loss: 2.4032139305720963

Epoch: 5| Step: 10
Training loss: 1.190292388033041
Validation loss: 2.3772016212646165

Epoch: 495| Step: 0
Training loss: 1.0051925671120105
Validation loss: 2.4169700256770166

Epoch: 5| Step: 1
Training loss: 0.5186561729420522
Validation loss: 2.3454431096649855

Epoch: 5| Step: 2
Training loss: 0.6550069343767666
Validation loss: 2.2910119586019313

Epoch: 5| Step: 3
Training loss: 1.1491735266650627
Validation loss: 2.3146206439787522

Epoch: 5| Step: 4
Training loss: 1.0286692491916354
Validation loss: 2.3159770511578226

Epoch: 5| Step: 5
Training loss: 0.5604292051574201
Validation loss: 2.3078105141937364

Epoch: 5| Step: 6
Training loss: 0.7949405077500888
Validation loss: 2.445362835820467

Epoch: 5| Step: 7
Training loss: 1.800284625438356
Validation loss: 2.3176023150469907

Epoch: 5| Step: 8
Training loss: 1.1852154590600126
Validation loss: 2.325946152499578

Epoch: 5| Step: 9
Training loss: 1.010452833544322
Validation loss: 2.3675268154681124

Epoch: 5| Step: 10
Training loss: 1.1021119499217025
Validation loss: 2.3511780970521112

Epoch: 496| Step: 0
Training loss: 1.5139933976819342
Validation loss: 2.3766351952444

Epoch: 5| Step: 1
Training loss: 1.1901730017367687
Validation loss: 2.384947518986157

Epoch: 5| Step: 2
Training loss: 0.5624359412275024
Validation loss: 2.4135092663440494

Epoch: 5| Step: 3
Training loss: 1.070408169445515
Validation loss: 2.342693917305495

Epoch: 5| Step: 4
Training loss: 0.7035662220367364
Validation loss: 2.371684141439357

Epoch: 5| Step: 5
Training loss: 1.0140065135107066
Validation loss: 2.404157223095292

Epoch: 5| Step: 6
Training loss: 0.9625215267895226
Validation loss: 2.383791156395892

Epoch: 5| Step: 7
Training loss: 0.7435044500375549
Validation loss: 2.3345613112289127

Epoch: 5| Step: 8
Training loss: 0.6542006692330725
Validation loss: 2.375748643178156

Epoch: 5| Step: 9
Training loss: 1.047172959470645
Validation loss: 2.365088455813519

Epoch: 5| Step: 10
Training loss: 0.898840341232155
Validation loss: 2.3779795209680255

Epoch: 497| Step: 0
Training loss: 0.9356529796853171
Validation loss: 2.398717415720359

Epoch: 5| Step: 1
Training loss: 0.7498708454823937
Validation loss: 2.3238822651389244

Epoch: 5| Step: 2
Training loss: 0.7811313920585917
Validation loss: 2.4637482373608757

Epoch: 5| Step: 3
Training loss: 1.6547212563044187
Validation loss: 2.328688968419276

Epoch: 5| Step: 4
Training loss: 0.98025878238611
Validation loss: 2.428223283904205

Epoch: 5| Step: 5
Training loss: 0.9825027462869947
Validation loss: 2.328112080041218

Epoch: 5| Step: 6
Training loss: 0.7431176229997873
Validation loss: 2.3723399977876656

Epoch: 5| Step: 7
Training loss: 1.4262217220140943
Validation loss: 2.2787989666136363

Epoch: 5| Step: 8
Training loss: 0.7701846219713047
Validation loss: 2.3777260368962962

Epoch: 5| Step: 9
Training loss: 0.9397337052377916
Validation loss: 2.3298969813660744

Epoch: 5| Step: 10
Training loss: 0.856061895271818
Validation loss: 2.3155390407144774

Epoch: 498| Step: 0
Training loss: 0.7609180252120998
Validation loss: 2.303333872867506

Epoch: 5| Step: 1
Training loss: 1.1174870336236915
Validation loss: 2.3571291065445354

Epoch: 5| Step: 2
Training loss: 0.8046528336548254
Validation loss: 2.4445318208837854

Epoch: 5| Step: 3
Training loss: 0.9452012682331116
Validation loss: 2.3362495514916177

Epoch: 5| Step: 4
Training loss: 1.0503592512354445
Validation loss: 2.3972570564653872

Epoch: 5| Step: 5
Training loss: 0.6575568900861144
Validation loss: 2.34014212662491

Epoch: 5| Step: 6
Training loss: 0.705676556605159
Validation loss: 2.389852291821458

Epoch: 5| Step: 7
Training loss: 1.1062697888344715
Validation loss: 2.375540757590053

Epoch: 5| Step: 8
Training loss: 1.7644587353069707
Validation loss: 2.3672018181688554

Epoch: 5| Step: 9
Training loss: 0.7469845392192401
Validation loss: 2.3229661036165394

Epoch: 5| Step: 10
Training loss: 0.7116058477802598
Validation loss: 2.3993481172024014

Epoch: 499| Step: 0
Training loss: 0.6688889305690141
Validation loss: 2.3258313535518886

Epoch: 5| Step: 1
Training loss: 1.220609908550235
Validation loss: 2.3910843463305183

Epoch: 5| Step: 2
Training loss: 0.7288210640179956
Validation loss: 2.41452535706737

Epoch: 5| Step: 3
Training loss: 0.6368633410329064
Validation loss: 2.409124716764533

Epoch: 5| Step: 4
Training loss: 1.623083818843794
Validation loss: 2.3145057108377602

Epoch: 5| Step: 5
Training loss: 0.8030965688697461
Validation loss: 2.356380972702873

Epoch: 5| Step: 6
Training loss: 0.9365486404162244
Validation loss: 2.3645642389897397

Epoch: 5| Step: 7
Training loss: 1.0302876692959573
Validation loss: 2.2224056188301127

Epoch: 5| Step: 8
Training loss: 0.8791642891066765
Validation loss: 2.369834815309423

Epoch: 5| Step: 9
Training loss: 1.0425585107827073
Validation loss: 2.401871852112046

Epoch: 5| Step: 10
Training loss: 0.7848130420203865
Validation loss: 2.3139022432543053

Epoch: 500| Step: 0
Training loss: 1.237171819307606
Validation loss: 2.2549135826926645

Epoch: 5| Step: 1
Training loss: 0.562290788527099
Validation loss: 2.354216083338642

Epoch: 5| Step: 2
Training loss: 0.7878891936834344
Validation loss: 2.3631823590995

Epoch: 5| Step: 3
Training loss: 1.701909952971029
Validation loss: 2.3196753333510096

Epoch: 5| Step: 4
Training loss: 1.0954296294313906
Validation loss: 2.2883594024893834

Epoch: 5| Step: 5
Training loss: 1.213896207086621
Validation loss: 2.3496743431912375

Epoch: 5| Step: 6
Training loss: 0.8078540606847676
Validation loss: 2.34854940380976

Epoch: 5| Step: 7
Training loss: 0.9343665208718862
Validation loss: 2.3566610059278412

Epoch: 5| Step: 8
Training loss: 0.8468236041925049
Validation loss: 2.33274738986954

Epoch: 5| Step: 9
Training loss: 0.8735900827520882
Validation loss: 2.3463371736682506

Epoch: 5| Step: 10
Training loss: 0.7301440817898406
Validation loss: 2.360087770236788

Epoch: 501| Step: 0
Training loss: 1.8097566034202077
Validation loss: 2.3618209103328094

Epoch: 5| Step: 1
Training loss: 0.898200592650611
Validation loss: 2.3292224326656132

Epoch: 5| Step: 2
Training loss: 0.9018848788221988
Validation loss: 2.3153096518752037

Epoch: 5| Step: 3
Training loss: 0.6713297205919011
Validation loss: 2.426781412487202

Epoch: 5| Step: 4
Training loss: 0.9367854256081789
Validation loss: 2.3971136218623648

Epoch: 5| Step: 5
Training loss: 0.8531140532856748
Validation loss: 2.3171049771795538

Epoch: 5| Step: 6
Training loss: 0.8635984157479699
Validation loss: 2.3991156167202425

Epoch: 5| Step: 7
Training loss: 0.9128137192918783
Validation loss: 2.3075107029849606

Epoch: 5| Step: 8
Training loss: 1.3060047558264138
Validation loss: 2.355279284048198

Epoch: 5| Step: 9
Training loss: 0.9376778433915981
Validation loss: 2.3456106078613166

Epoch: 5| Step: 10
Training loss: 0.8077572167256277
Validation loss: 2.3422075234315716

Epoch: 502| Step: 0
Training loss: 1.6624830029988307
Validation loss: 2.3618011061980875

Epoch: 5| Step: 1
Training loss: 0.8054779022614427
Validation loss: 2.3362968130888517

Epoch: 5| Step: 2
Training loss: 0.8038200591716426
Validation loss: 2.3237958984452733

Epoch: 5| Step: 3
Training loss: 1.151521344012321
Validation loss: 2.395887318805893

Epoch: 5| Step: 4
Training loss: 0.5130276429423107
Validation loss: 2.3462896663344557

Epoch: 5| Step: 5
Training loss: 0.8839380633957853
Validation loss: 2.4075465662503523

Epoch: 5| Step: 6
Training loss: 0.8998145786650094
Validation loss: 2.3754550754754957

Epoch: 5| Step: 7
Training loss: 0.8687172190567184
Validation loss: 2.376841763605578

Epoch: 5| Step: 8
Training loss: 0.880897436567256
Validation loss: 2.3698057163222765

Epoch: 5| Step: 9
Training loss: 0.6767656290062556
Validation loss: 2.322747122026735

Epoch: 5| Step: 10
Training loss: 1.140966494925028
Validation loss: 2.3106312754948397

Epoch: 503| Step: 0
Training loss: 1.0393344838680663
Validation loss: 2.3613708058508354

Epoch: 5| Step: 1
Training loss: 1.7021524995021096
Validation loss: 2.4215815530092795

Epoch: 5| Step: 2
Training loss: 0.7800001064324917
Validation loss: 2.329789514682846

Epoch: 5| Step: 3
Training loss: 0.8029773279530971
Validation loss: 2.390518508888862

Epoch: 5| Step: 4
Training loss: 0.5818334665851045
Validation loss: 2.4028347940496975

Epoch: 5| Step: 5
Training loss: 0.8281469881989294
Validation loss: 2.3185252378858765

Epoch: 5| Step: 6
Training loss: 0.8063700593966427
Validation loss: 2.337705061900525

Epoch: 5| Step: 7
Training loss: 0.983157843485579
Validation loss: 2.3681683959177042

Epoch: 5| Step: 8
Training loss: 0.9555033105945575
Validation loss: 2.416260135249264

Epoch: 5| Step: 9
Training loss: 1.1284608589317537
Validation loss: 2.3593523018580522

Epoch: 5| Step: 10
Training loss: 1.0798555941643526
Validation loss: 2.382712846968843

Epoch: 504| Step: 0
Training loss: 0.9901767390405087
Validation loss: 2.315764957302646

Epoch: 5| Step: 1
Training loss: 0.9133658077100586
Validation loss: 2.3470074162405914

Epoch: 5| Step: 2
Training loss: 1.0381556404088785
Validation loss: 2.3220554287278516

Epoch: 5| Step: 3
Training loss: 1.0714789390078396
Validation loss: 2.4217249982297115

Epoch: 5| Step: 4
Training loss: 0.8678888457538698
Validation loss: 2.292014047763712

Epoch: 5| Step: 5
Training loss: 1.8289471595226718
Validation loss: 2.3540938743911806

Epoch: 5| Step: 6
Training loss: 0.7319716226726349
Validation loss: 2.4250730804808347

Epoch: 5| Step: 7
Training loss: 0.6884622342397554
Validation loss: 2.3594922136651926

Epoch: 5| Step: 8
Training loss: 0.7090048038282262
Validation loss: 2.393941743708115

Epoch: 5| Step: 9
Training loss: 0.7137363381756838
Validation loss: 2.361741129429549

Epoch: 5| Step: 10
Training loss: 0.8127064075918166
Validation loss: 2.4094540178999897

Epoch: 505| Step: 0
Training loss: 1.0100670960300935
Validation loss: 2.363363556262134

Epoch: 5| Step: 1
Training loss: 0.9754721085409469
Validation loss: 2.287014997029752

Epoch: 5| Step: 2
Training loss: 0.950232949055495
Validation loss: 2.378871217866395

Epoch: 5| Step: 3
Training loss: 0.7354745141494978
Validation loss: 2.3477086610471805

Epoch: 5| Step: 4
Training loss: 0.7717711096898828
Validation loss: 2.305018135938424

Epoch: 5| Step: 5
Training loss: 1.0348684810613267
Validation loss: 2.3809572471768155

Epoch: 5| Step: 6
Training loss: 1.6423524027892156
Validation loss: 2.3281899998052062

Epoch: 5| Step: 7
Training loss: 0.8100417068128503
Validation loss: 2.367486321428314

Epoch: 5| Step: 8
Training loss: 0.8121969318025712
Validation loss: 2.393974366981587

Epoch: 5| Step: 9
Training loss: 1.0551941961387683
Validation loss: 2.311112965962706

Epoch: 5| Step: 10
Training loss: 1.1267368895938314
Validation loss: 2.3113594951011804

Epoch: 506| Step: 0
Training loss: 1.0325735441898396
Validation loss: 2.354713443053821

Epoch: 5| Step: 1
Training loss: 0.9887134074542394
Validation loss: 2.361637173796458

Epoch: 5| Step: 2
Training loss: 0.7336695915237815
Validation loss: 2.2963680042344707

Epoch: 5| Step: 3
Training loss: 0.7991878007581101
Validation loss: 2.2879462738511553

Epoch: 5| Step: 4
Training loss: 0.7954508453134458
Validation loss: 2.3180460211119898

Epoch: 5| Step: 5
Training loss: 0.7904363324164337
Validation loss: 2.3529157592068213

Epoch: 5| Step: 6
Training loss: 1.773862006513431
Validation loss: 2.2975284555702427

Epoch: 5| Step: 7
Training loss: 0.7283408029363831
Validation loss: 2.3569892755325754

Epoch: 5| Step: 8
Training loss: 0.8818551332870589
Validation loss: 2.3816163625888422

Epoch: 5| Step: 9
Training loss: 1.073499237461823
Validation loss: 2.3014076361200173

Epoch: 5| Step: 10
Training loss: 0.7642990619807892
Validation loss: 2.310303780086569

Epoch: 507| Step: 0
Training loss: 1.1568851788287866
Validation loss: 2.331525639278087

Epoch: 5| Step: 1
Training loss: 1.164977872253622
Validation loss: 2.3680259935822923

Epoch: 5| Step: 2
Training loss: 1.663048950429132
Validation loss: 2.363799084676369

Epoch: 5| Step: 3
Training loss: 0.8521858173909098
Validation loss: 2.3063892725850863

Epoch: 5| Step: 4
Training loss: 0.8278179679162961
Validation loss: 2.3771033652825113

Epoch: 5| Step: 5
Training loss: 0.5552131687213785
Validation loss: 2.3627834646353323

Epoch: 5| Step: 6
Training loss: 0.7354861436468334
Validation loss: 2.3792091638953194

Epoch: 5| Step: 7
Training loss: 0.7408272575698546
Validation loss: 2.389897684579518

Epoch: 5| Step: 8
Training loss: 1.0616856988810852
Validation loss: 2.445475833672922

Epoch: 5| Step: 9
Training loss: 0.6725305862987153
Validation loss: 2.4141387858372254

Epoch: 5| Step: 10
Training loss: 0.9190724981102044
Validation loss: 2.3705473282707765

Epoch: 508| Step: 0
Training loss: 1.0443500986560623
Validation loss: 2.356347964951199

Epoch: 5| Step: 1
Training loss: 1.7468520870992144
Validation loss: 2.3891192214125603

Epoch: 5| Step: 2
Training loss: 0.8791180503805928
Validation loss: 2.3796725231582183

Epoch: 5| Step: 3
Training loss: 0.8735048599064297
Validation loss: 2.3193075324555177

Epoch: 5| Step: 4
Training loss: 0.5483929140492222
Validation loss: 2.41478090488097

Epoch: 5| Step: 5
Training loss: 0.9157573929721797
Validation loss: 2.427247506407893

Epoch: 5| Step: 6
Training loss: 0.8488622427700637
Validation loss: 2.332534569452018

Epoch: 5| Step: 7
Training loss: 0.9172187175994417
Validation loss: 2.3523741920307173

Epoch: 5| Step: 8
Training loss: 0.8174832190094923
Validation loss: 2.330592074234755

Epoch: 5| Step: 9
Training loss: 1.092661343059019
Validation loss: 2.3435707838661757

Epoch: 5| Step: 10
Training loss: 0.7157835905431933
Validation loss: 2.309332352348706

Epoch: 509| Step: 0
Training loss: 0.8078757521401395
Validation loss: 2.3642656549188965

Epoch: 5| Step: 1
Training loss: 0.8876477051444346
Validation loss: 2.385754864137227

Epoch: 5| Step: 2
Training loss: 0.875703801074768
Validation loss: 2.3140743099466676

Epoch: 5| Step: 3
Training loss: 1.0767854855484529
Validation loss: 2.2693824893692964

Epoch: 5| Step: 4
Training loss: 0.6619929883721004
Validation loss: 2.40566968532325

Epoch: 5| Step: 5
Training loss: 0.936583866083142
Validation loss: 2.3163355697038486

Epoch: 5| Step: 6
Training loss: 0.5668239500281779
Validation loss: 2.311106066868215

Epoch: 5| Step: 7
Training loss: 1.0034890699603898
Validation loss: 2.2919747206146726

Epoch: 5| Step: 8
Training loss: 1.1252553438111879
Validation loss: 2.3267563141947365

Epoch: 5| Step: 9
Training loss: 1.6704404862189097
Validation loss: 2.34006451555764

Epoch: 5| Step: 10
Training loss: 0.9248026895149022
Validation loss: 2.3234833858771995

Epoch: 510| Step: 0
Training loss: 0.6973879624013525
Validation loss: 2.3107179572785794

Epoch: 5| Step: 1
Training loss: 1.1659945641026144
Validation loss: 2.2930724865116177

Epoch: 5| Step: 2
Training loss: 1.1076005525774282
Validation loss: 2.348954397033212

Epoch: 5| Step: 3
Training loss: 1.0329717654702217
Validation loss: 2.317039942184241

Epoch: 5| Step: 4
Training loss: 0.914859456905588
Validation loss: 2.305430491884182

Epoch: 5| Step: 5
Training loss: 0.9826709287532457
Validation loss: 2.387224018265689

Epoch: 5| Step: 6
Training loss: 0.5743693718618909
Validation loss: 2.3897191368310446

Epoch: 5| Step: 7
Training loss: 0.9789262469685531
Validation loss: 2.399374009121531

Epoch: 5| Step: 8
Training loss: 1.6678434588436042
Validation loss: 2.3353786844753714

Epoch: 5| Step: 9
Training loss: 0.4876271558868932
Validation loss: 2.3638525476802426

Epoch: 5| Step: 10
Training loss: 0.9141933966918724
Validation loss: 2.3309588344534418

Epoch: 511| Step: 0
Training loss: 0.799133652736744
Validation loss: 2.352850075857642

Epoch: 5| Step: 1
Training loss: 0.9176511174413562
Validation loss: 2.4102327913656647

Epoch: 5| Step: 2
Training loss: 1.0443847416549539
Validation loss: 2.3559390271533016

Epoch: 5| Step: 3
Training loss: 1.2090320978313296
Validation loss: 2.4025854347138482

Epoch: 5| Step: 4
Training loss: 0.9438306054056731
Validation loss: 2.3790387952001106

Epoch: 5| Step: 5
Training loss: 0.7365462893165641
Validation loss: 2.417171443234651

Epoch: 5| Step: 6
Training loss: 0.9569064311939296
Validation loss: 2.3891696198197594

Epoch: 5| Step: 7
Training loss: 0.9990941355460126
Validation loss: 2.3763787564213423

Epoch: 5| Step: 8
Training loss: 0.9174437624667375
Validation loss: 2.399708517338423

Epoch: 5| Step: 9
Training loss: 0.759581359641698
Validation loss: 2.379095759968619

Epoch: 5| Step: 10
Training loss: 1.7834271961834927
Validation loss: 2.326223359463332

Epoch: 512| Step: 0
Training loss: 0.8816428073354069
Validation loss: 2.396485461866379

Epoch: 5| Step: 1
Training loss: 0.7483198499491454
Validation loss: 2.290476527074339

Epoch: 5| Step: 2
Training loss: 0.9565661798984015
Validation loss: 2.4038687724271206

Epoch: 5| Step: 3
Training loss: 0.9804479893162008
Validation loss: 2.3852182354045555

Epoch: 5| Step: 4
Training loss: 1.7267186020928826
Validation loss: 2.350313316479117

Epoch: 5| Step: 5
Training loss: 0.8064365821637439
Validation loss: 2.4152155081074795

Epoch: 5| Step: 6
Training loss: 1.2640266686867434
Validation loss: 2.3756677253457528

Epoch: 5| Step: 7
Training loss: 0.5964572073414743
Validation loss: 2.3434277948109576

Epoch: 5| Step: 8
Training loss: 0.7253954548795646
Validation loss: 2.3367590687790996

Epoch: 5| Step: 9
Training loss: 0.937078190324804
Validation loss: 2.3496138757513187

Epoch: 5| Step: 10
Training loss: 0.8799729380456296
Validation loss: 2.3835236680833765

Epoch: 513| Step: 0
Training loss: 0.7563684607169376
Validation loss: 2.3871890915501033

Epoch: 5| Step: 1
Training loss: 1.0205310581607874
Validation loss: 2.3121503561749885

Epoch: 5| Step: 2
Training loss: 0.776982554189554
Validation loss: 2.3895273591521207

Epoch: 5| Step: 3
Training loss: 0.8100830957387322
Validation loss: 2.322414709445075

Epoch: 5| Step: 4
Training loss: 0.9156887553024619
Validation loss: 2.293134814373344

Epoch: 5| Step: 5
Training loss: 0.9638145610197806
Validation loss: 2.359901753525894

Epoch: 5| Step: 6
Training loss: 1.9105479457043424
Validation loss: 2.2792967985169548

Epoch: 5| Step: 7
Training loss: 0.5428908587235801
Validation loss: 2.3364280418559678

Epoch: 5| Step: 8
Training loss: 0.6438367396314024
Validation loss: 2.289693083440176

Epoch: 5| Step: 9
Training loss: 0.7560282279577686
Validation loss: 2.319280152837906

Epoch: 5| Step: 10
Training loss: 1.0037627952586745
Validation loss: 2.3495251602613645

Epoch: 514| Step: 0
Training loss: 0.9677996434610163
Validation loss: 2.3868299185500903

Epoch: 5| Step: 1
Training loss: 0.7425231977493106
Validation loss: 2.3533671665220113

Epoch: 5| Step: 2
Training loss: 1.1662941349260498
Validation loss: 2.4205652882750908

Epoch: 5| Step: 3
Training loss: 0.9826935530885347
Validation loss: 2.30080753941434

Epoch: 5| Step: 4
Training loss: 0.8321952120989067
Validation loss: 2.3750991109775406

Epoch: 5| Step: 5
Training loss: 0.8316790771195464
Validation loss: 2.380831240957734

Epoch: 5| Step: 6
Training loss: 0.7808256141039484
Validation loss: 2.42342404919249

Epoch: 5| Step: 7
Training loss: 0.9658756066704631
Validation loss: 2.4182011759334587

Epoch: 5| Step: 8
Training loss: 0.6235857459854312
Validation loss: 2.345726406037243

Epoch: 5| Step: 9
Training loss: 1.2755371757302576
Validation loss: 2.4015933170885058

Epoch: 5| Step: 10
Training loss: 1.8671661758801303
Validation loss: 2.3486553157035077

Epoch: 515| Step: 0
Training loss: 0.9988134914932978
Validation loss: 2.3514256427822118

Epoch: 5| Step: 1
Training loss: 1.0146906736539854
Validation loss: 2.3473685542528484

Epoch: 5| Step: 2
Training loss: 0.8829189000109704
Validation loss: 2.3278700716577565

Epoch: 5| Step: 3
Training loss: 0.8620968111243618
Validation loss: 2.379198871421379

Epoch: 5| Step: 4
Training loss: 1.0133632417916356
Validation loss: 2.3643160588498566

Epoch: 5| Step: 5
Training loss: 0.8812340998737012
Validation loss: 2.406921398526514

Epoch: 5| Step: 6
Training loss: 0.761548536796434
Validation loss: 2.3340982726590798

Epoch: 5| Step: 7
Training loss: 0.8029013504153797
Validation loss: 2.3606102832288958

Epoch: 5| Step: 8
Training loss: 1.6465425854367504
Validation loss: 2.354997731221142

Epoch: 5| Step: 9
Training loss: 0.7481435210342269
Validation loss: 2.3753801429111014

Epoch: 5| Step: 10
Training loss: 1.0470947490474136
Validation loss: 2.257703500665648

Epoch: 516| Step: 0
Training loss: 1.02174604576322
Validation loss: 2.3713975775132115

Epoch: 5| Step: 1
Training loss: 0.7991853022731241
Validation loss: 2.366647135103539

Epoch: 5| Step: 2
Training loss: 0.9112863360199888
Validation loss: 2.3778512626814976

Epoch: 5| Step: 3
Training loss: 1.0225524569908253
Validation loss: 2.346151506088663

Epoch: 5| Step: 4
Training loss: 0.7052373310101958
Validation loss: 2.280404350926956

Epoch: 5| Step: 5
Training loss: 1.0578145330006659
Validation loss: 2.35529915227244

Epoch: 5| Step: 6
Training loss: 1.053535001277426
Validation loss: 2.3714414111483384

Epoch: 5| Step: 7
Training loss: 1.6049984431036413
Validation loss: 2.334185361950486

Epoch: 5| Step: 8
Training loss: 1.0742862194720997
Validation loss: 2.410032050186383

Epoch: 5| Step: 9
Training loss: 0.7198120232080615
Validation loss: 2.367892444875869

Epoch: 5| Step: 10
Training loss: 0.8039801738771223
Validation loss: 2.362084483266275

Epoch: 517| Step: 0
Training loss: 0.8267164667444417
Validation loss: 2.3236682731145346

Epoch: 5| Step: 1
Training loss: 0.7832570806549132
Validation loss: 2.3117396061515834

Epoch: 5| Step: 2
Training loss: 1.0656803441148874
Validation loss: 2.406338981322406

Epoch: 5| Step: 3
Training loss: 0.7686898525867957
Validation loss: 2.2689846974067285

Epoch: 5| Step: 4
Training loss: 0.8368498199982355
Validation loss: 2.305683064590822

Epoch: 5| Step: 5
Training loss: 0.8449502814072742
Validation loss: 2.3386067360537486

Epoch: 5| Step: 6
Training loss: 1.1963759534770437
Validation loss: 2.274353902637353

Epoch: 5| Step: 7
Training loss: 0.7753109062206119
Validation loss: 2.3266828890471554

Epoch: 5| Step: 8
Training loss: 1.675113286984184
Validation loss: 2.391474586323536

Epoch: 5| Step: 9
Training loss: 0.8215566011132177
Validation loss: 2.367089895670687

Epoch: 5| Step: 10
Training loss: 0.7627291116295506
Validation loss: 2.3454137627080027

Epoch: 518| Step: 0
Training loss: 0.9112093812552521
Validation loss: 2.3585865539939475

Epoch: 5| Step: 1
Training loss: 0.974622768394163
Validation loss: 2.331940387515288

Epoch: 5| Step: 2
Training loss: 0.8333416501265996
Validation loss: 2.343545162314819

Epoch: 5| Step: 3
Training loss: 0.9716284656921712
Validation loss: 2.300014270026625

Epoch: 5| Step: 4
Training loss: 0.6796637125347059
Validation loss: 2.3977232945192313

Epoch: 5| Step: 5
Training loss: 0.7446076537054233
Validation loss: 2.329358830166222

Epoch: 5| Step: 6
Training loss: 1.7513146911696693
Validation loss: 2.273415721319188

Epoch: 5| Step: 7
Training loss: 0.9079403733030567
Validation loss: 2.342575156155036

Epoch: 5| Step: 8
Training loss: 0.9425007642545561
Validation loss: 2.3240486372995615

Epoch: 5| Step: 9
Training loss: 1.0055023448580995
Validation loss: 2.2965079404840747

Epoch: 5| Step: 10
Training loss: 0.7463021112263154
Validation loss: 2.338635113326273

Epoch: 519| Step: 0
Training loss: 1.143242380446738
Validation loss: 2.427381872292057

Epoch: 5| Step: 1
Training loss: 0.8075330844986891
Validation loss: 2.4441908787664475

Epoch: 5| Step: 2
Training loss: 0.5973474041155726
Validation loss: 2.407085915414395

Epoch: 5| Step: 3
Training loss: 1.7380396985874538
Validation loss: 2.41172565544907

Epoch: 5| Step: 4
Training loss: 0.943543852465734
Validation loss: 2.3264110020693782

Epoch: 5| Step: 5
Training loss: 0.9816152852465548
Validation loss: 2.3547471612389694

Epoch: 5| Step: 6
Training loss: 1.0251147089714803
Validation loss: 2.3844639674516466

Epoch: 5| Step: 7
Training loss: 0.910191351086826
Validation loss: 2.361221975932409

Epoch: 5| Step: 8
Training loss: 0.7241321236200587
Validation loss: 2.408723739822393

Epoch: 5| Step: 9
Training loss: 1.1441798793717939
Validation loss: 2.2658240785641204

Epoch: 5| Step: 10
Training loss: 0.7728074715555233
Validation loss: 2.321242352372551

Epoch: 520| Step: 0
Training loss: 0.7332721301750664
Validation loss: 2.3430134910163156

Epoch: 5| Step: 1
Training loss: 0.9099156794415307
Validation loss: 2.323967111266417

Epoch: 5| Step: 2
Training loss: 0.6263820150420651
Validation loss: 2.2796902484628845

Epoch: 5| Step: 3
Training loss: 0.5866061146962079
Validation loss: 2.380597485550877

Epoch: 5| Step: 4
Training loss: 0.977564000622366
Validation loss: 2.3389526546130144

Epoch: 5| Step: 5
Training loss: 0.832058256901957
Validation loss: 2.3347366686506965

Epoch: 5| Step: 6
Training loss: 0.9455039090661266
Validation loss: 2.4221915788052164

Epoch: 5| Step: 7
Training loss: 0.9467728424358732
Validation loss: 2.3525312022391054

Epoch: 5| Step: 8
Training loss: 1.648174970069656
Validation loss: 2.353808289072347

Epoch: 5| Step: 9
Training loss: 1.1676966627741845
Validation loss: 2.396278828580859

Epoch: 5| Step: 10
Training loss: 0.7192227426004154
Validation loss: 2.3616282566494924

Epoch: 521| Step: 0
Training loss: 0.8609659899862978
Validation loss: 2.328976615460324

Epoch: 5| Step: 1
Training loss: 0.6059312592096988
Validation loss: 2.3255737998308468

Epoch: 5| Step: 2
Training loss: 0.7515766737269581
Validation loss: 2.3560439779305122

Epoch: 5| Step: 3
Training loss: 0.7901278564951879
Validation loss: 2.337275932487071

Epoch: 5| Step: 4
Training loss: 0.6400410386428382
Validation loss: 2.32183014077165

Epoch: 5| Step: 5
Training loss: 0.961200523045652
Validation loss: 2.436475474840114

Epoch: 5| Step: 6
Training loss: 1.742205974669071
Validation loss: 2.3423277665476046

Epoch: 5| Step: 7
Training loss: 0.9107906439102536
Validation loss: 2.315243526706479

Epoch: 5| Step: 8
Training loss: 0.7437173435510925
Validation loss: 2.2960924304485144

Epoch: 5| Step: 9
Training loss: 0.9180350746381309
Validation loss: 2.34044434225792

Epoch: 5| Step: 10
Training loss: 1.096390669963292
Validation loss: 2.351898983654734

Epoch: 522| Step: 0
Training loss: 0.9188085083269855
Validation loss: 2.3527730700418275

Epoch: 5| Step: 1
Training loss: 0.7284762292595565
Validation loss: 2.3457524671477143

Epoch: 5| Step: 2
Training loss: 0.8653334997845075
Validation loss: 2.271399813897693

Epoch: 5| Step: 3
Training loss: 1.21064971457459
Validation loss: 2.3791340715602747

Epoch: 5| Step: 4
Training loss: 0.7540957356039854
Validation loss: 2.408966413220207

Epoch: 5| Step: 5
Training loss: 1.0957843933974212
Validation loss: 2.283011428037797

Epoch: 5| Step: 6
Training loss: 0.8256584718605819
Validation loss: 2.3040187242871455

Epoch: 5| Step: 7
Training loss: 1.7748637241113077
Validation loss: 2.3840192861990754

Epoch: 5| Step: 8
Training loss: 0.7171258405388262
Validation loss: 2.294820316731985

Epoch: 5| Step: 9
Training loss: 0.8169652311988141
Validation loss: 2.3838622681812023

Epoch: 5| Step: 10
Training loss: 0.5950065667727676
Validation loss: 2.42524106682081

Epoch: 523| Step: 0
Training loss: 1.7280438312693593
Validation loss: 2.330501077536176

Epoch: 5| Step: 1
Training loss: 0.9268470777445876
Validation loss: 2.3678662263086823

Epoch: 5| Step: 2
Training loss: 0.8322659730028739
Validation loss: 2.3833586337433776

Epoch: 5| Step: 3
Training loss: 0.7661152262811909
Validation loss: 2.378180348186103

Epoch: 5| Step: 4
Training loss: 0.8308071032152037
Validation loss: 2.3406456613983453

Epoch: 5| Step: 5
Training loss: 0.7690816040022376
Validation loss: 2.343189799858563

Epoch: 5| Step: 6
Training loss: 1.1013108094450672
Validation loss: 2.3720260581742445

Epoch: 5| Step: 7
Training loss: 0.8418745814876748
Validation loss: 2.3412575171137826

Epoch: 5| Step: 8
Training loss: 0.8470591186600058
Validation loss: 2.3311224910733293

Epoch: 5| Step: 9
Training loss: 0.8356541304835512
Validation loss: 2.347183052904906

Epoch: 5| Step: 10
Training loss: 1.1854338489934204
Validation loss: 2.387811216491421

Epoch: 524| Step: 0
Training loss: 0.9976120092848402
Validation loss: 2.323196180947497

Epoch: 5| Step: 1
Training loss: 0.8638092083656763
Validation loss: 2.383217774261652

Epoch: 5| Step: 2
Training loss: 0.7168176216636338
Validation loss: 2.353941529231731

Epoch: 5| Step: 3
Training loss: 1.0795867519601816
Validation loss: 2.3410967821100153

Epoch: 5| Step: 4
Training loss: 0.751450328426453
Validation loss: 2.374547615208509

Epoch: 5| Step: 5
Training loss: 0.597455483418237
Validation loss: 2.337160751645381

Epoch: 5| Step: 6
Training loss: 1.7291846063748035
Validation loss: 2.3054062812748453

Epoch: 5| Step: 7
Training loss: 0.7168852208547148
Validation loss: 2.3788784544164674

Epoch: 5| Step: 8
Training loss: 0.5697377587945476
Validation loss: 2.330433159076725

Epoch: 5| Step: 9
Training loss: 1.0484060223056768
Validation loss: 2.3663712840031215

Epoch: 5| Step: 10
Training loss: 0.742781190834234
Validation loss: 2.3916883854885507

Epoch: 525| Step: 0
Training loss: 0.9522768217732489
Validation loss: 2.4396835424963284

Epoch: 5| Step: 1
Training loss: 0.8546136213936933
Validation loss: 2.4031894076148275

Epoch: 5| Step: 2
Training loss: 0.6952879826370066
Validation loss: 2.3438080592467174

Epoch: 5| Step: 3
Training loss: 0.9476903218986664
Validation loss: 2.3903566440816473

Epoch: 5| Step: 4
Training loss: 1.2211594361975002
Validation loss: 2.3294706703993233

Epoch: 5| Step: 5
Training loss: 0.6698194820349472
Validation loss: 2.4100729196850645

Epoch: 5| Step: 6
Training loss: 0.6281886775444394
Validation loss: 2.406940712123196

Epoch: 5| Step: 7
Training loss: 1.7415270729643912
Validation loss: 2.358987939600752

Epoch: 5| Step: 8
Training loss: 0.7896125689070449
Validation loss: 2.3668451843140175

Epoch: 5| Step: 9
Training loss: 0.7257975992223495
Validation loss: 2.360642693816296

Epoch: 5| Step: 10
Training loss: 0.6897115466234418
Validation loss: 2.3288714080973967

Epoch: 526| Step: 0
Training loss: 1.2151905803581537
Validation loss: 2.3547834161460774

Epoch: 5| Step: 1
Training loss: 0.5572351593413392
Validation loss: 2.347760234489539

Epoch: 5| Step: 2
Training loss: 0.7732998503912388
Validation loss: 2.3283233106641155

Epoch: 5| Step: 3
Training loss: 0.8500885763017559
Validation loss: 2.3821992141058894

Epoch: 5| Step: 4
Training loss: 0.621777380177452
Validation loss: 2.381602306539039

Epoch: 5| Step: 5
Training loss: 0.71185390390916
Validation loss: 2.3329111177234925

Epoch: 5| Step: 6
Training loss: 0.7142967674558196
Validation loss: 2.3229096048951234

Epoch: 5| Step: 7
Training loss: 0.8418875731709551
Validation loss: 2.319961375441686

Epoch: 5| Step: 8
Training loss: 0.707830914727302
Validation loss: 2.339012077488916

Epoch: 5| Step: 9
Training loss: 1.1155465085068872
Validation loss: 2.3771165625139954

Epoch: 5| Step: 10
Training loss: 1.7942860403832928
Validation loss: 2.3247464018200965

Epoch: 527| Step: 0
Training loss: 0.6931760088809343
Validation loss: 2.406727668176701

Epoch: 5| Step: 1
Training loss: 0.5097862619483251
Validation loss: 2.3854892531773286

Epoch: 5| Step: 2
Training loss: 1.0736631864151622
Validation loss: 2.325162861514428

Epoch: 5| Step: 3
Training loss: 0.6103274165145705
Validation loss: 2.360694256184609

Epoch: 5| Step: 4
Training loss: 0.8124559830700181
Validation loss: 2.3509327503777877

Epoch: 5| Step: 5
Training loss: 0.8451057420964562
Validation loss: 2.3751724538922785

Epoch: 5| Step: 6
Training loss: 1.0240943489791172
Validation loss: 2.356631770382608

Epoch: 5| Step: 7
Training loss: 1.7285016937556532
Validation loss: 2.381016486875311

Epoch: 5| Step: 8
Training loss: 0.6673932635946166
Validation loss: 2.307930781005316

Epoch: 5| Step: 9
Training loss: 0.8911029135741063
Validation loss: 2.2503687016417024

Epoch: 5| Step: 10
Training loss: 0.859664001421022
Validation loss: 2.4030179351388186

Epoch: 528| Step: 0
Training loss: 0.721411793377461
Validation loss: 2.269765301480752

Epoch: 5| Step: 1
Training loss: 0.812641718315896
Validation loss: 2.336602307117726

Epoch: 5| Step: 2
Training loss: 1.244898207612777
Validation loss: 2.3804223165540903

Epoch: 5| Step: 3
Training loss: 0.8940844023607443
Validation loss: 2.299857035318226

Epoch: 5| Step: 4
Training loss: 0.8050196804578942
Validation loss: 2.441270986046257

Epoch: 5| Step: 5
Training loss: 0.8935150637987194
Validation loss: 2.4057093879847455

Epoch: 5| Step: 6
Training loss: 1.7190860766507086
Validation loss: 2.333566065870341

Epoch: 5| Step: 7
Training loss: 0.6619290806880789
Validation loss: 2.3931110926092813

Epoch: 5| Step: 8
Training loss: 0.5419668380720297
Validation loss: 2.3634490497721026

Epoch: 5| Step: 9
Training loss: 0.7472659185302285
Validation loss: 2.379085512262175

Epoch: 5| Step: 10
Training loss: 0.8369780864285278
Validation loss: 2.359169921567907

Epoch: 529| Step: 0
Training loss: 0.9000193726256004
Validation loss: 2.387542122321819

Epoch: 5| Step: 1
Training loss: 0.9154564425670999
Validation loss: 2.3588830062345867

Epoch: 5| Step: 2
Training loss: 0.8913089401530326
Validation loss: 2.375989039837923

Epoch: 5| Step: 3
Training loss: 0.8333235899037734
Validation loss: 2.387478374651063

Epoch: 5| Step: 4
Training loss: 0.5458803668639501
Validation loss: 2.4147911120474865

Epoch: 5| Step: 5
Training loss: 0.8882474787188069
Validation loss: 2.35586060155078

Epoch: 5| Step: 6
Training loss: 1.0479973427651474
Validation loss: 2.270863935752269

Epoch: 5| Step: 7
Training loss: 0.9234909184168884
Validation loss: 2.33270822302446

Epoch: 5| Step: 8
Training loss: 1.568087391529683
Validation loss: 2.360798594860393

Epoch: 5| Step: 9
Training loss: 0.634255353797507
Validation loss: 2.337856484407843

Epoch: 5| Step: 10
Training loss: 0.7475453979204587
Validation loss: 2.326728867424173

Epoch: 530| Step: 0
Training loss: 0.784421890498599
Validation loss: 2.2938662571479216

Epoch: 5| Step: 1
Training loss: 0.5756140643477899
Validation loss: 2.3870463227630045

Epoch: 5| Step: 2
Training loss: 0.7654033651495751
Validation loss: 2.352675291589656

Epoch: 5| Step: 3
Training loss: 0.694498056620494
Validation loss: 2.332574881136974

Epoch: 5| Step: 4
Training loss: 0.7773024198193356
Validation loss: 2.3633026867861

Epoch: 5| Step: 5
Training loss: 0.7842033259153189
Validation loss: 2.364224723874467

Epoch: 5| Step: 6
Training loss: 0.6934931881149943
Validation loss: 2.330836415511539

Epoch: 5| Step: 7
Training loss: 1.6774261866559366
Validation loss: 2.2991070661911306

Epoch: 5| Step: 8
Training loss: 1.1202938402821907
Validation loss: 2.339767644089835

Epoch: 5| Step: 9
Training loss: 1.0657481863465919
Validation loss: 2.3695679986483227

Epoch: 5| Step: 10
Training loss: 0.5933578852822524
Validation loss: 2.318845957269828

Epoch: 531| Step: 0
Training loss: 0.730328755554879
Validation loss: 2.3957684230348777

Epoch: 5| Step: 1
Training loss: 0.8656284304664476
Validation loss: 2.326399336560667

Epoch: 5| Step: 2
Training loss: 0.934369933711067
Validation loss: 2.35051519541035

Epoch: 5| Step: 3
Training loss: 0.5467924328190409
Validation loss: 2.390570430627436

Epoch: 5| Step: 4
Training loss: 0.7976952613310118
Validation loss: 2.3422694971279334

Epoch: 5| Step: 5
Training loss: 1.5956865400855536
Validation loss: 2.3577093253344055

Epoch: 5| Step: 6
Training loss: 0.9794145973638324
Validation loss: 2.2728783443121214

Epoch: 5| Step: 7
Training loss: 0.7611332526045406
Validation loss: 2.329209974462588

Epoch: 5| Step: 8
Training loss: 0.8434550158224952
Validation loss: 2.3569793980543263

Epoch: 5| Step: 9
Training loss: 0.9982525936353824
Validation loss: 2.313348667073506

Epoch: 5| Step: 10
Training loss: 0.9512156450982957
Validation loss: 2.383086923995308

Epoch: 532| Step: 0
Training loss: 0.9234319567312274
Validation loss: 2.3699204355922934

Epoch: 5| Step: 1
Training loss: 0.6863212233377131
Validation loss: 2.3411345953095983

Epoch: 5| Step: 2
Training loss: 0.7649310723586454
Validation loss: 2.313556489118857

Epoch: 5| Step: 3
Training loss: 0.7349026995760992
Validation loss: 2.3443385598670647

Epoch: 5| Step: 4
Training loss: 0.8078559052189362
Validation loss: 2.3645075486429876

Epoch: 5| Step: 5
Training loss: 0.765481546158366
Validation loss: 2.318695115649213

Epoch: 5| Step: 6
Training loss: 1.1357164716228276
Validation loss: 2.438743901547371

Epoch: 5| Step: 7
Training loss: 1.6298540683083633
Validation loss: 2.3397155821937217

Epoch: 5| Step: 8
Training loss: 1.0887705122792468
Validation loss: 2.375377669257605

Epoch: 5| Step: 9
Training loss: 1.0836030306483992
Validation loss: 2.322579548706174

Epoch: 5| Step: 10
Training loss: 0.6651974796047279
Validation loss: 2.350987842865897

Epoch: 533| Step: 0
Training loss: 0.9566463708607653
Validation loss: 2.3513718759682014

Epoch: 5| Step: 1
Training loss: 1.6757741363303267
Validation loss: 2.402983435885635

Epoch: 5| Step: 2
Training loss: 0.6660401012588002
Validation loss: 2.356003954640765

Epoch: 5| Step: 3
Training loss: 0.9938258364069098
Validation loss: 2.322287008208688

Epoch: 5| Step: 4
Training loss: 0.7439038157688658
Validation loss: 2.3933119387251245

Epoch: 5| Step: 5
Training loss: 0.8371417204446018
Validation loss: 2.3115104680023912

Epoch: 5| Step: 6
Training loss: 0.6432539334078697
Validation loss: 2.4183782712171085

Epoch: 5| Step: 7
Training loss: 1.0062154491487352
Validation loss: 2.3925115133810793

Epoch: 5| Step: 8
Training loss: 0.8152339860360461
Validation loss: 2.3363635526926436

Epoch: 5| Step: 9
Training loss: 0.6185648072658283
Validation loss: 2.330918490420668

Epoch: 5| Step: 10
Training loss: 0.8725366317469926
Validation loss: 2.3238219958931494

Epoch: 534| Step: 0
Training loss: 0.7441337364859151
Validation loss: 2.3549831287518295

Epoch: 5| Step: 1
Training loss: 1.1324713883985686
Validation loss: 2.2771776176349916

Epoch: 5| Step: 2
Training loss: 0.8761906697081022
Validation loss: 2.321299880110749

Epoch: 5| Step: 3
Training loss: 0.7246975909308198
Validation loss: 2.3499081319857784

Epoch: 5| Step: 4
Training loss: 0.8245416885417869
Validation loss: 2.3358798718029123

Epoch: 5| Step: 5
Training loss: 1.6008985678417675
Validation loss: 2.3511901741685564

Epoch: 5| Step: 6
Training loss: 0.7940078466733931
Validation loss: 2.3208500602061806

Epoch: 5| Step: 7
Training loss: 0.630287549003035
Validation loss: 2.371950444451284

Epoch: 5| Step: 8
Training loss: 0.9214262435837212
Validation loss: 2.303857043108119

Epoch: 5| Step: 9
Training loss: 0.7608485410729591
Validation loss: 2.403128351823444

Epoch: 5| Step: 10
Training loss: 0.9641972279190509
Validation loss: 2.3045618733879096

Epoch: 535| Step: 0
Training loss: 0.5566310145569087
Validation loss: 2.3672402626898212

Epoch: 5| Step: 1
Training loss: 0.7501118099792843
Validation loss: 2.3878105808986874

Epoch: 5| Step: 2
Training loss: 0.7243884384712403
Validation loss: 2.317501932106567

Epoch: 5| Step: 3
Training loss: 0.9381394430798496
Validation loss: 2.3502518837643516

Epoch: 5| Step: 4
Training loss: 1.0953746174001193
Validation loss: 2.3158149544898032

Epoch: 5| Step: 5
Training loss: 0.8084167434157034
Validation loss: 2.415999151324853

Epoch: 5| Step: 6
Training loss: 0.6291210684347442
Validation loss: 2.34884714414081

Epoch: 5| Step: 7
Training loss: 1.120914617708488
Validation loss: 2.3663454608062207

Epoch: 5| Step: 8
Training loss: 0.9416589041758484
Validation loss: 2.4096460007545564

Epoch: 5| Step: 9
Training loss: 0.6612105668971101
Validation loss: 2.3340163260416653

Epoch: 5| Step: 10
Training loss: 1.8995850160053975
Validation loss: 2.305166662373627

Epoch: 536| Step: 0
Training loss: 1.5470358254415393
Validation loss: 2.4325813064263597

Epoch: 5| Step: 1
Training loss: 0.9079546844963221
Validation loss: 2.315864056149027

Epoch: 5| Step: 2
Training loss: 0.8347254013773936
Validation loss: 2.388668180872739

Epoch: 5| Step: 3
Training loss: 0.9071061266896061
Validation loss: 2.329555674497462

Epoch: 5| Step: 4
Training loss: 1.0005900311242022
Validation loss: 2.3868792482779777

Epoch: 5| Step: 5
Training loss: 0.783656457614913
Validation loss: 2.324489355978392

Epoch: 5| Step: 6
Training loss: 0.5652993271000931
Validation loss: 2.332289829553965

Epoch: 5| Step: 7
Training loss: 0.7963356736112718
Validation loss: 2.334420974295638

Epoch: 5| Step: 8
Training loss: 1.0586881701037558
Validation loss: 2.347252780296067

Epoch: 5| Step: 9
Training loss: 0.6444143940735768
Validation loss: 2.3228330666575836

Epoch: 5| Step: 10
Training loss: 0.6992519733058784
Validation loss: 2.3964140330508013

Epoch: 537| Step: 0
Training loss: 0.9493545623447863
Validation loss: 2.3760450003888933

Epoch: 5| Step: 1
Training loss: 1.007646591369742
Validation loss: 2.3766231576291275

Epoch: 5| Step: 2
Training loss: 1.6773098462911042
Validation loss: 2.3719162796295463

Epoch: 5| Step: 3
Training loss: 0.755293918013306
Validation loss: 2.3660126818801417

Epoch: 5| Step: 4
Training loss: 0.7897040903019074
Validation loss: 2.3651699632087397

Epoch: 5| Step: 5
Training loss: 0.6298910214384538
Validation loss: 2.3014343049134456

Epoch: 5| Step: 6
Training loss: 0.7876529756949787
Validation loss: 2.3611891802581337

Epoch: 5| Step: 7
Training loss: 0.807365553561292
Validation loss: 2.358069850103145

Epoch: 5| Step: 8
Training loss: 0.9011163331481646
Validation loss: 2.3402502234944436

Epoch: 5| Step: 9
Training loss: 0.9972669387013815
Validation loss: 2.2927804826180607

Epoch: 5| Step: 10
Training loss: 0.5865028705477895
Validation loss: 2.3209181177154834

Epoch: 538| Step: 0
Training loss: 1.676654508115596
Validation loss: 2.297313916401975

Epoch: 5| Step: 1
Training loss: 0.7724006716130171
Validation loss: 2.3068729562282737

Epoch: 5| Step: 2
Training loss: 0.7467724574096177
Validation loss: 2.355571594044695

Epoch: 5| Step: 3
Training loss: 0.6107250322226591
Validation loss: 2.4169059330165

Epoch: 5| Step: 4
Training loss: 0.7650976895308544
Validation loss: 2.4078752276023487

Epoch: 5| Step: 5
Training loss: 0.6614341105634075
Validation loss: 2.3729220282320753

Epoch: 5| Step: 6
Training loss: 0.8517882371632611
Validation loss: 2.3591353749693633

Epoch: 5| Step: 7
Training loss: 1.0575929535038058
Validation loss: 2.3909717790598783

Epoch: 5| Step: 8
Training loss: 0.9527390120590119
Validation loss: 2.349588814367233

Epoch: 5| Step: 9
Training loss: 0.9599990914757721
Validation loss: 2.25945687779714

Epoch: 5| Step: 10
Training loss: 0.9849844665561188
Validation loss: 2.315898390326943

Epoch: 539| Step: 0
Training loss: 0.7924566635533308
Validation loss: 2.33047253576553

Epoch: 5| Step: 1
Training loss: 0.6683547260026866
Validation loss: 2.386569537724926

Epoch: 5| Step: 2
Training loss: 0.6322938182695745
Validation loss: 2.338326566205719

Epoch: 5| Step: 3
Training loss: 0.9667104663188768
Validation loss: 2.3640689023735715

Epoch: 5| Step: 4
Training loss: 0.8245711816050072
Validation loss: 2.2498255699662386

Epoch: 5| Step: 5
Training loss: 0.8352671636115576
Validation loss: 2.282769828425024

Epoch: 5| Step: 6
Training loss: 0.9958103150669559
Validation loss: 2.3787543173214583

Epoch: 5| Step: 7
Training loss: 1.695835929262516
Validation loss: 2.2699154792667433

Epoch: 5| Step: 8
Training loss: 0.6389036545452372
Validation loss: 2.3538358127173376

Epoch: 5| Step: 9
Training loss: 0.5924018310955167
Validation loss: 2.320713249328744

Epoch: 5| Step: 10
Training loss: 1.2467840309707725
Validation loss: 2.3324226156393113

Epoch: 540| Step: 0
Training loss: 1.064456260746528
Validation loss: 2.3756325817861543

Epoch: 5| Step: 1
Training loss: 0.7927145715001026
Validation loss: 2.2900043087060906

Epoch: 5| Step: 2
Training loss: 1.5787891463427342
Validation loss: 2.3235038398908614

Epoch: 5| Step: 3
Training loss: 0.9276473155080541
Validation loss: 2.448973009176112

Epoch: 5| Step: 4
Training loss: 0.6861279842251349
Validation loss: 2.3271852699791626

Epoch: 5| Step: 5
Training loss: 0.7610870872273272
Validation loss: 2.3667680835904275

Epoch: 5| Step: 6
Training loss: 0.7369443707738288
Validation loss: 2.352964929947731

Epoch: 5| Step: 7
Training loss: 0.8397230549515604
Validation loss: 2.296108085167958

Epoch: 5| Step: 8
Training loss: 0.6203399978807861
Validation loss: 2.3880955381626188

Epoch: 5| Step: 9
Training loss: 0.6445260018799711
Validation loss: 2.3316925358551237

Epoch: 5| Step: 10
Training loss: 1.0209597230377743
Validation loss: 2.3681054994196495

Epoch: 541| Step: 0
Training loss: 0.7288612180089518
Validation loss: 2.417236901228725

Epoch: 5| Step: 1
Training loss: 0.6704202249747475
Validation loss: 2.361093915393744

Epoch: 5| Step: 2
Training loss: 0.7841191060571255
Validation loss: 2.3935433620849786

Epoch: 5| Step: 3
Training loss: 0.7744929500773674
Validation loss: 2.362245266145275

Epoch: 5| Step: 4
Training loss: 1.8245058671015928
Validation loss: 2.364944030072372

Epoch: 5| Step: 5
Training loss: 1.1800327427410817
Validation loss: 2.3500988403842853

Epoch: 5| Step: 6
Training loss: 0.7884524035774524
Validation loss: 2.4172505957556947

Epoch: 5| Step: 7
Training loss: 0.7150610921676003
Validation loss: 2.3400784179534115

Epoch: 5| Step: 8
Training loss: 0.8103755172311243
Validation loss: 2.3358910838905684

Epoch: 5| Step: 9
Training loss: 0.9395323658474543
Validation loss: 2.28464980570195

Epoch: 5| Step: 10
Training loss: 0.6769149399700573
Validation loss: 2.356613441278508

Epoch: 542| Step: 0
Training loss: 0.5228245120769175
Validation loss: 2.3697860265153317

Epoch: 5| Step: 1
Training loss: 1.5791592372159227
Validation loss: 2.353694454781098

Epoch: 5| Step: 2
Training loss: 0.859956613876768
Validation loss: 2.3801469810880964

Epoch: 5| Step: 3
Training loss: 0.933382976154084
Validation loss: 2.368008998221158

Epoch: 5| Step: 4
Training loss: 0.9297706823241105
Validation loss: 2.3300105451978728

Epoch: 5| Step: 5
Training loss: 0.6992149352923285
Validation loss: 2.3663572858199746

Epoch: 5| Step: 6
Training loss: 0.8474203739625978
Validation loss: 2.4076247073903136

Epoch: 5| Step: 7
Training loss: 0.9081004751297668
Validation loss: 2.33281782622332

Epoch: 5| Step: 8
Training loss: 0.9783864192976124
Validation loss: 2.3714324200598447

Epoch: 5| Step: 9
Training loss: 0.8860537013792704
Validation loss: 2.3809506952848194

Epoch: 5| Step: 10
Training loss: 0.9344516786478492
Validation loss: 2.3230897737867298

Epoch: 543| Step: 0
Training loss: 0.6673680554757605
Validation loss: 2.413144574393073

Epoch: 5| Step: 1
Training loss: 0.7745748307320769
Validation loss: 2.3661246266205795

Epoch: 5| Step: 2
Training loss: 0.5569707059125466
Validation loss: 2.31808588138246

Epoch: 5| Step: 3
Training loss: 0.6716786918399815
Validation loss: 2.393306762832778

Epoch: 5| Step: 4
Training loss: 0.8109122682148378
Validation loss: 2.339216915939529

Epoch: 5| Step: 5
Training loss: 0.9327820637144837
Validation loss: 2.405714178070049

Epoch: 5| Step: 6
Training loss: 0.6595511738963146
Validation loss: 2.3482705910652975

Epoch: 5| Step: 7
Training loss: 1.0501221926297102
Validation loss: 2.3781916982537545

Epoch: 5| Step: 8
Training loss: 1.8146094182004975
Validation loss: 2.3524486515674194

Epoch: 5| Step: 9
Training loss: 0.9029783519228411
Validation loss: 2.3761363190493237

Epoch: 5| Step: 10
Training loss: 0.9866493230876244
Validation loss: 2.3557743614416378

Epoch: 544| Step: 0
Training loss: 0.6769958121636489
Validation loss: 2.357949949851578

Epoch: 5| Step: 1
Training loss: 1.6269659474612885
Validation loss: 2.358563361854111

Epoch: 5| Step: 2
Training loss: 1.1123205490254056
Validation loss: 2.3709825129241047

Epoch: 5| Step: 3
Training loss: 0.7463703541532024
Validation loss: 2.343371333771605

Epoch: 5| Step: 4
Training loss: 1.024981375269201
Validation loss: 2.318059672906014

Epoch: 5| Step: 5
Training loss: 0.46354707614728313
Validation loss: 2.3609526972154904

Epoch: 5| Step: 6
Training loss: 0.6864859298075456
Validation loss: 2.353718738337958

Epoch: 5| Step: 7
Training loss: 0.5038665341835036
Validation loss: 2.331699488932752

Epoch: 5| Step: 8
Training loss: 0.7018170164823965
Validation loss: 2.2681094557710213

Epoch: 5| Step: 9
Training loss: 0.8258079286306025
Validation loss: 2.3302636229792526

Epoch: 5| Step: 10
Training loss: 0.812323330965424
Validation loss: 2.3467014185030317

Epoch: 545| Step: 0
Training loss: 0.6463918475639033
Validation loss: 2.359544109740121

Epoch: 5| Step: 1
Training loss: 1.072405918858837
Validation loss: 2.3417859823884672

Epoch: 5| Step: 2
Training loss: 0.9864814261472975
Validation loss: 2.3232097001290493

Epoch: 5| Step: 3
Training loss: 0.7104548817831643
Validation loss: 2.391102916182918

Epoch: 5| Step: 4
Training loss: 0.6213078879436648
Validation loss: 2.314591603454339

Epoch: 5| Step: 5
Training loss: 0.7221487376739196
Validation loss: 2.3560142918613622

Epoch: 5| Step: 6
Training loss: 1.1414454396626605
Validation loss: 2.336578283447223

Epoch: 5| Step: 7
Training loss: 0.6178871004392602
Validation loss: 2.375916872356734

Epoch: 5| Step: 8
Training loss: 1.0190625044920079
Validation loss: 2.3139442106905284

Epoch: 5| Step: 9
Training loss: 1.6154821129779446
Validation loss: 2.309313662259185

Epoch: 5| Step: 10
Training loss: 0.7536266777031289
Validation loss: 2.3636584391862074

Epoch: 546| Step: 0
Training loss: 1.6473076731557592
Validation loss: 2.3188323700823275

Epoch: 5| Step: 1
Training loss: 0.6730839254727659
Validation loss: 2.2965879084396437

Epoch: 5| Step: 2
Training loss: 1.0426996005235967
Validation loss: 2.358153439530141

Epoch: 5| Step: 3
Training loss: 0.916476721302007
Validation loss: 2.3372645131559233

Epoch: 5| Step: 4
Training loss: 0.7127680006774746
Validation loss: 2.41893953648759

Epoch: 5| Step: 5
Training loss: 1.0566209942868006
Validation loss: 2.313969662554125

Epoch: 5| Step: 6
Training loss: 0.9053021439791858
Validation loss: 2.3371561501291844

Epoch: 5| Step: 7
Training loss: 0.7252709589431118
Validation loss: 2.409166473302286

Epoch: 5| Step: 8
Training loss: 0.7117552612855214
Validation loss: 2.4228469660708765

Epoch: 5| Step: 9
Training loss: 0.9927545263878396
Validation loss: 2.3011196422534463

Epoch: 5| Step: 10
Training loss: 0.7922648044164764
Validation loss: 2.369377010343946

Epoch: 547| Step: 0
Training loss: 0.680570007568675
Validation loss: 2.4007072700793874

Epoch: 5| Step: 1
Training loss: 1.8016667040608156
Validation loss: 2.355493066418307

Epoch: 5| Step: 2
Training loss: 0.7107484167821361
Validation loss: 2.336633649648988

Epoch: 5| Step: 3
Training loss: 0.6165515182143555
Validation loss: 2.311352525756839

Epoch: 5| Step: 4
Training loss: 0.5805489527049519
Validation loss: 2.36753028703422

Epoch: 5| Step: 5
Training loss: 1.1025977714592168
Validation loss: 2.3912794448054058

Epoch: 5| Step: 6
Training loss: 0.6786070160927221
Validation loss: 2.294097980105923

Epoch: 5| Step: 7
Training loss: 1.0166225522794095
Validation loss: 2.3249537640994697

Epoch: 5| Step: 8
Training loss: 0.8373304508588869
Validation loss: 2.372509184537244

Epoch: 5| Step: 9
Training loss: 0.6502342150604443
Validation loss: 2.3901952927974035

Epoch: 5| Step: 10
Training loss: 1.018270363262913
Validation loss: 2.3613368440592932

Epoch: 548| Step: 0
Training loss: 0.931943000650843
Validation loss: 2.304777502572804

Epoch: 5| Step: 1
Training loss: 0.6710381286095151
Validation loss: 2.3607006655645835

Epoch: 5| Step: 2
Training loss: 0.7627406772305099
Validation loss: 2.334493016175824

Epoch: 5| Step: 3
Training loss: 0.89772496371307
Validation loss: 2.431356215166247

Epoch: 5| Step: 4
Training loss: 0.8033744320770246
Validation loss: 2.3856009174712263

Epoch: 5| Step: 5
Training loss: 0.8770812350963101
Validation loss: 2.4033896741768164

Epoch: 5| Step: 6
Training loss: 0.7464065295580843
Validation loss: 2.3564031593008647

Epoch: 5| Step: 7
Training loss: 1.595038472850626
Validation loss: 2.381058103123008

Epoch: 5| Step: 8
Training loss: 1.096149210977986
Validation loss: 2.359027342814433

Epoch: 5| Step: 9
Training loss: 0.9291488946546499
Validation loss: 2.3770052955971526

Epoch: 5| Step: 10
Training loss: 0.6200191870919909
Validation loss: 2.3308774461782615

Epoch: 549| Step: 0
Training loss: 0.8560926348460858
Validation loss: 2.345585382931826

Epoch: 5| Step: 1
Training loss: 0.9280045928944188
Validation loss: 2.3279329066378542

Epoch: 5| Step: 2
Training loss: 0.7358960976263004
Validation loss: 2.276322830062309

Epoch: 5| Step: 3
Training loss: 0.9880978862751039
Validation loss: 2.3600306141617735

Epoch: 5| Step: 4
Training loss: 0.814829311809836
Validation loss: 2.3301104233646326

Epoch: 5| Step: 5
Training loss: 0.7688980208144338
Validation loss: 2.3186409044109264

Epoch: 5| Step: 6
Training loss: 0.6963170756179503
Validation loss: 2.3637767972223434

Epoch: 5| Step: 7
Training loss: 0.7858015606451811
Validation loss: 2.353221277330993

Epoch: 5| Step: 8
Training loss: 0.9093529098816562
Validation loss: 2.30500188636449

Epoch: 5| Step: 9
Training loss: 0.8850801426759036
Validation loss: 2.31139354404188

Epoch: 5| Step: 10
Training loss: 1.6209543191167004
Validation loss: 2.3085225950792907

Epoch: 550| Step: 0
Training loss: 0.6065663878735362
Validation loss: 2.4288023976025097

Epoch: 5| Step: 1
Training loss: 0.7368220688669915
Validation loss: 2.3468702431453012

Epoch: 5| Step: 2
Training loss: 0.993317778778115
Validation loss: 2.3282379763854477

Epoch: 5| Step: 3
Training loss: 0.9618876032409481
Validation loss: 2.393395155296943

Epoch: 5| Step: 4
Training loss: 0.8054637683081654
Validation loss: 2.298743831473213

Epoch: 5| Step: 5
Training loss: 1.1778919626961981
Validation loss: 2.2594672584751363

Epoch: 5| Step: 6
Training loss: 1.6427299438422605
Validation loss: 2.28907685326269

Epoch: 5| Step: 7
Training loss: 0.5522455540931824
Validation loss: 2.344095467978772

Epoch: 5| Step: 8
Training loss: 0.6681864422772034
Validation loss: 2.361964269623351

Epoch: 5| Step: 9
Training loss: 0.7301979174848339
Validation loss: 2.370455123232978

Epoch: 5| Step: 10
Training loss: 0.5652779225602564
Validation loss: 2.2842439810450785

Epoch: 551| Step: 0
Training loss: 0.8197139554511952
Validation loss: 2.3756379078766745

Epoch: 5| Step: 1
Training loss: 0.8316106673507406
Validation loss: 2.3152359151984485

Epoch: 5| Step: 2
Training loss: 0.6378234220520005
Validation loss: 2.3632438234318123

Epoch: 5| Step: 3
Training loss: 1.5981135751422535
Validation loss: 2.3304496842763154

Epoch: 5| Step: 4
Training loss: 0.7373497551287294
Validation loss: 2.293829390913406

Epoch: 5| Step: 5
Training loss: 0.8011074611263512
Validation loss: 2.340976045384467

Epoch: 5| Step: 6
Training loss: 1.1088269451497654
Validation loss: 2.3332237140627496

Epoch: 5| Step: 7
Training loss: 0.7904992195767357
Validation loss: 2.2984841844180375

Epoch: 5| Step: 8
Training loss: 0.8197030846426383
Validation loss: 2.292486774176825

Epoch: 5| Step: 9
Training loss: 0.8555527737257128
Validation loss: 2.26888279282295

Epoch: 5| Step: 10
Training loss: 0.5544244921760936
Validation loss: 2.3181717851125665

Epoch: 552| Step: 0
Training loss: 0.6217394177802092
Validation loss: 2.332102181224762

Epoch: 5| Step: 1
Training loss: 1.6072627159110497
Validation loss: 2.3490721197508004

Epoch: 5| Step: 2
Training loss: 0.8881855398935866
Validation loss: 2.2974394048395514

Epoch: 5| Step: 3
Training loss: 0.7981316251188535
Validation loss: 2.3525193970869958

Epoch: 5| Step: 4
Training loss: 0.8580330167455504
Validation loss: 2.377619502321106

Epoch: 5| Step: 5
Training loss: 0.6184749695239311
Validation loss: 2.287217181451192

Epoch: 5| Step: 6
Training loss: 0.8092440510278669
Validation loss: 2.369621644157573

Epoch: 5| Step: 7
Training loss: 0.8880774889163024
Validation loss: 2.365861010207859

Epoch: 5| Step: 8
Training loss: 0.5375567705647203
Validation loss: 2.3485205039265744

Epoch: 5| Step: 9
Training loss: 0.7997849756590121
Validation loss: 2.424647018462439

Epoch: 5| Step: 10
Training loss: 1.065434386805058
Validation loss: 2.369925282869766

Epoch: 553| Step: 0
Training loss: 0.5921943261550784
Validation loss: 2.294849438210285

Epoch: 5| Step: 1
Training loss: 0.49694303970406095
Validation loss: 2.3804998958165027

Epoch: 5| Step: 2
Training loss: 0.8733308744092594
Validation loss: 2.269105839720726

Epoch: 5| Step: 3
Training loss: 0.6397974437683426
Validation loss: 2.30864563313095

Epoch: 5| Step: 4
Training loss: 0.7889778167303968
Validation loss: 2.3972706410889613

Epoch: 5| Step: 5
Training loss: 0.6483945257814759
Validation loss: 2.337194245913003

Epoch: 5| Step: 6
Training loss: 1.5943992638620226
Validation loss: 2.3764539018389943

Epoch: 5| Step: 7
Training loss: 0.9509084912606883
Validation loss: 2.39190106694801

Epoch: 5| Step: 8
Training loss: 1.0682569381449274
Validation loss: 2.340261133113134

Epoch: 5| Step: 9
Training loss: 0.7907345873005719
Validation loss: 2.3424008780428838

Epoch: 5| Step: 10
Training loss: 0.9216243597142499
Validation loss: 2.2772539184011076

Epoch: 554| Step: 0
Training loss: 0.7879093166057581
Validation loss: 2.2250782534259326

Epoch: 5| Step: 1
Training loss: 1.0173754938792066
Validation loss: 2.383880868482083

Epoch: 5| Step: 2
Training loss: 1.5668190581016967
Validation loss: 2.295219238118213

Epoch: 5| Step: 3
Training loss: 0.6052765325791485
Validation loss: 2.3902869031380622

Epoch: 5| Step: 4
Training loss: 0.843567475250466
Validation loss: 2.3394787070325362

Epoch: 5| Step: 5
Training loss: 0.751544236815806
Validation loss: 2.3333146721522904

Epoch: 5| Step: 6
Training loss: 0.47438803955169667
Validation loss: 2.3655274868700418

Epoch: 5| Step: 7
Training loss: 1.012021641699639
Validation loss: 2.3652971484157614

Epoch: 5| Step: 8
Training loss: 0.6464187266044978
Validation loss: 2.4207039109828847

Epoch: 5| Step: 9
Training loss: 0.6879786212532656
Validation loss: 2.3566164111056347

Epoch: 5| Step: 10
Training loss: 0.8490407158756644
Validation loss: 2.346175323557889

Epoch: 555| Step: 0
Training loss: 0.7242654976679568
Validation loss: 2.3420229624285303

Epoch: 5| Step: 1
Training loss: 0.6578759532053958
Validation loss: 2.3956157640822675

Epoch: 5| Step: 2
Training loss: 0.5103103533464309
Validation loss: 2.343307668859603

Epoch: 5| Step: 3
Training loss: 1.6113843503448
Validation loss: 2.3652758039504955

Epoch: 5| Step: 4
Training loss: 0.8268471341328604
Validation loss: 2.3506359231339857

Epoch: 5| Step: 5
Training loss: 0.7303748248908156
Validation loss: 2.3964013684029393

Epoch: 5| Step: 6
Training loss: 0.6578046005390864
Validation loss: 2.3444106901051915

Epoch: 5| Step: 7
Training loss: 0.9104079524713609
Validation loss: 2.424699467045325

Epoch: 5| Step: 8
Training loss: 0.5771169637757158
Validation loss: 2.2705142258046203

Epoch: 5| Step: 9
Training loss: 0.8667977290516755
Validation loss: 2.3237876213031

Epoch: 5| Step: 10
Training loss: 1.2323782016856883
Validation loss: 2.361572724140551

Epoch: 556| Step: 0
Training loss: 0.8434274551454919
Validation loss: 2.316923869875542

Epoch: 5| Step: 1
Training loss: 0.7721547751012947
Validation loss: 2.3586167109345912

Epoch: 5| Step: 2
Training loss: 0.6462639378090577
Validation loss: 2.3536067492443227

Epoch: 5| Step: 3
Training loss: 1.7629341618820764
Validation loss: 2.3942452341393095

Epoch: 5| Step: 4
Training loss: 0.6220951764034873
Validation loss: 2.386609968464199

Epoch: 5| Step: 5
Training loss: 0.7557721937897638
Validation loss: 2.3389024012057265

Epoch: 5| Step: 6
Training loss: 0.8049124986468438
Validation loss: 2.275886184729287

Epoch: 5| Step: 7
Training loss: 0.8362377019870297
Validation loss: 2.3882492209750827

Epoch: 5| Step: 8
Training loss: 0.7062640163414873
Validation loss: 2.383215075314847

Epoch: 5| Step: 9
Training loss: 0.9039667239521018
Validation loss: 2.2783862490599125

Epoch: 5| Step: 10
Training loss: 0.7308989701180686
Validation loss: 2.3328299129487244

Epoch: 557| Step: 0
Training loss: 0.7782016792969438
Validation loss: 2.3230904259833944

Epoch: 5| Step: 1
Training loss: 0.6159330246141981
Validation loss: 2.364588033622597

Epoch: 5| Step: 2
Training loss: 0.9562371209467833
Validation loss: 2.3496177551192647

Epoch: 5| Step: 3
Training loss: 0.5618683659519382
Validation loss: 2.293835250612797

Epoch: 5| Step: 4
Training loss: 1.092167881692573
Validation loss: 2.269129656389765

Epoch: 5| Step: 5
Training loss: 0.5943588347698671
Validation loss: 2.4187488313081578

Epoch: 5| Step: 6
Training loss: 0.7336180824087538
Validation loss: 2.3712876131110217

Epoch: 5| Step: 7
Training loss: 1.0004058848643036
Validation loss: 2.288536441671233

Epoch: 5| Step: 8
Training loss: 0.8692378643374744
Validation loss: 2.3437089124790256

Epoch: 5| Step: 9
Training loss: 0.7349519289606604
Validation loss: 2.367678136807916

Epoch: 5| Step: 10
Training loss: 1.6560754504084887
Validation loss: 2.3930308748915827

Epoch: 558| Step: 0
Training loss: 0.7171289573827543
Validation loss: 2.267016956990776

Epoch: 5| Step: 1
Training loss: 0.8171793731226996
Validation loss: 2.307579723837595

Epoch: 5| Step: 2
Training loss: 1.0111957509091893
Validation loss: 2.3349979058531414

Epoch: 5| Step: 3
Training loss: 0.5910757726304703
Validation loss: 2.3193754782725264

Epoch: 5| Step: 4
Training loss: 1.7184151756833028
Validation loss: 2.3628879985719764

Epoch: 5| Step: 5
Training loss: 0.84720532777406
Validation loss: 2.33499073422943

Epoch: 5| Step: 6
Training loss: 0.6098410462601249
Validation loss: 2.3156096645041884

Epoch: 5| Step: 7
Training loss: 0.778157752086957
Validation loss: 2.300334269499472

Epoch: 5| Step: 8
Training loss: 0.7840601163655337
Validation loss: 2.381525474734913

Epoch: 5| Step: 9
Training loss: 0.7451814196337825
Validation loss: 2.3749500619142627

Epoch: 5| Step: 10
Training loss: 0.8743223563564568
Validation loss: 2.3216638912094263

Epoch: 559| Step: 0
Training loss: 0.6425908559912026
Validation loss: 2.354728997103968

Epoch: 5| Step: 1
Training loss: 0.8410137809028022
Validation loss: 2.3555966287803485

Epoch: 5| Step: 2
Training loss: 0.8521436055947197
Validation loss: 2.327436278239198

Epoch: 5| Step: 3
Training loss: 1.1416606120949095
Validation loss: 2.377753000121037

Epoch: 5| Step: 4
Training loss: 0.544400338153678
Validation loss: 2.373991439607139

Epoch: 5| Step: 5
Training loss: 0.7644022695148378
Validation loss: 2.295236498251418

Epoch: 5| Step: 6
Training loss: 0.6502799091669013
Validation loss: 2.384909434075599

Epoch: 5| Step: 7
Training loss: 0.7936061308229806
Validation loss: 2.367666464565079

Epoch: 5| Step: 8
Training loss: 0.8825706555770614
Validation loss: 2.317776450280394

Epoch: 5| Step: 9
Training loss: 1.5338882762007038
Validation loss: 2.4059572637079394

Epoch: 5| Step: 10
Training loss: 0.6122043411796981
Validation loss: 2.3009149268920766

Epoch: 560| Step: 0
Training loss: 1.0299220927875632
Validation loss: 2.3118023561413286

Epoch: 5| Step: 1
Training loss: 0.6418724707430119
Validation loss: 2.2770473996816243

Epoch: 5| Step: 2
Training loss: 0.7769531342059058
Validation loss: 2.3751647430086336

Epoch: 5| Step: 3
Training loss: 0.775969320590381
Validation loss: 2.309717358852794

Epoch: 5| Step: 4
Training loss: 1.5838878145901474
Validation loss: 2.3564563766922886

Epoch: 5| Step: 5
Training loss: 0.8367276601735475
Validation loss: 2.342913097965596

Epoch: 5| Step: 6
Training loss: 0.6385120343483432
Validation loss: 2.3253990578463513

Epoch: 5| Step: 7
Training loss: 0.5308253329985153
Validation loss: 2.3687871770051507

Epoch: 5| Step: 8
Training loss: 0.6552351870792733
Validation loss: 2.336240433744931

Epoch: 5| Step: 9
Training loss: 0.6165532100111019
Validation loss: 2.324344178907921

Epoch: 5| Step: 10
Training loss: 0.9509455981553795
Validation loss: 2.3601516524321617

Epoch: 561| Step: 0
Training loss: 0.6429245081868556
Validation loss: 2.3654642990606454

Epoch: 5| Step: 1
Training loss: 0.7693335574506216
Validation loss: 2.362555389136963

Epoch: 5| Step: 2
Training loss: 0.9074269905882157
Validation loss: 2.337806137803151

Epoch: 5| Step: 3
Training loss: 0.6783458139253983
Validation loss: 2.3605673562174005

Epoch: 5| Step: 4
Training loss: 0.6738728162899592
Validation loss: 2.3607082803458246

Epoch: 5| Step: 5
Training loss: 0.8051637888073709
Validation loss: 2.337243617971773

Epoch: 5| Step: 6
Training loss: 0.682481591287311
Validation loss: 2.352515045740717

Epoch: 5| Step: 7
Training loss: 0.7367423837537963
Validation loss: 2.306028064847618

Epoch: 5| Step: 8
Training loss: 1.05045957498602
Validation loss: 2.2918035608014278

Epoch: 5| Step: 9
Training loss: 0.7424623883800627
Validation loss: 2.390671057957491

Epoch: 5| Step: 10
Training loss: 1.750836785391894
Validation loss: 2.361530807933741

Epoch: 562| Step: 0
Training loss: 0.5887916984693973
Validation loss: 2.3994356161330592

Epoch: 5| Step: 1
Training loss: 1.010514415194578
Validation loss: 2.3282307119540646

Epoch: 5| Step: 2
Training loss: 0.8386392872222066
Validation loss: 2.354057071700044

Epoch: 5| Step: 3
Training loss: 1.5630386949802668
Validation loss: 2.3706641057889506

Epoch: 5| Step: 4
Training loss: 0.7728670887499763
Validation loss: 2.3836688373127477

Epoch: 5| Step: 5
Training loss: 0.8907650954503519
Validation loss: 2.3811192933627265

Epoch: 5| Step: 6
Training loss: 0.6970683013639032
Validation loss: 2.3316113601083392

Epoch: 5| Step: 7
Training loss: 0.8526321133131047
Validation loss: 2.266633686931733

Epoch: 5| Step: 8
Training loss: 0.876449304299484
Validation loss: 2.329803669305369

Epoch: 5| Step: 9
Training loss: 0.8676109998194764
Validation loss: 2.3798507544260596

Epoch: 5| Step: 10
Training loss: 0.7841712884702565
Validation loss: 2.3407949280719356

Epoch: 563| Step: 0
Training loss: 0.6282785730843294
Validation loss: 2.354207404333485

Epoch: 5| Step: 1
Training loss: 0.6570498043166547
Validation loss: 2.415269599738315

Epoch: 5| Step: 2
Training loss: 0.7170610486752946
Validation loss: 2.379631644348842

Epoch: 5| Step: 3
Training loss: 0.6332216706051625
Validation loss: 2.358271103087217

Epoch: 5| Step: 4
Training loss: 0.7984563433370158
Validation loss: 2.3575596091050124

Epoch: 5| Step: 5
Training loss: 1.0478759649018146
Validation loss: 2.4182973815264464

Epoch: 5| Step: 6
Training loss: 0.6880395246147553
Validation loss: 2.3900190037466835

Epoch: 5| Step: 7
Training loss: 0.8177946413660844
Validation loss: 2.3741748382384307

Epoch: 5| Step: 8
Training loss: 1.6479081302748055
Validation loss: 2.345320809490272

Epoch: 5| Step: 9
Training loss: 0.9207382305510634
Validation loss: 2.360513006983635

Epoch: 5| Step: 10
Training loss: 0.8454867255704519
Validation loss: 2.3275507441489163

Epoch: 564| Step: 0
Training loss: 0.7643710007020968
Validation loss: 2.3764674570501887

Epoch: 5| Step: 1
Training loss: 0.6222871794622385
Validation loss: 2.332283966442029

Epoch: 5| Step: 2
Training loss: 0.8237011264895672
Validation loss: 2.3342834201444522

Epoch: 5| Step: 3
Training loss: 1.0427078320746244
Validation loss: 2.2892376650251602

Epoch: 5| Step: 4
Training loss: 0.9018304859577725
Validation loss: 2.3591557412887343

Epoch: 5| Step: 5
Training loss: 0.6779472390564922
Validation loss: 2.2647142185683933

Epoch: 5| Step: 6
Training loss: 0.7897933747690604
Validation loss: 2.3729893766420824

Epoch: 5| Step: 7
Training loss: 0.840260211683905
Validation loss: 2.3947981136492715

Epoch: 5| Step: 8
Training loss: 1.51916766290986
Validation loss: 2.3559265404743543

Epoch: 5| Step: 9
Training loss: 0.48636149096643727
Validation loss: 2.297378898854256

Epoch: 5| Step: 10
Training loss: 0.6711435550420318
Validation loss: 2.2641280289928924

Epoch: 565| Step: 0
Training loss: 0.7384316023866739
Validation loss: 2.3522568416452216

Epoch: 5| Step: 1
Training loss: 0.8215352346046577
Validation loss: 2.3108772907920816

Epoch: 5| Step: 2
Training loss: 0.6980853778315391
Validation loss: 2.3729039200329294

Epoch: 5| Step: 3
Training loss: 0.5823880836309168
Validation loss: 2.3478989235386027

Epoch: 5| Step: 4
Training loss: 0.8723139748196982
Validation loss: 2.418862560532136

Epoch: 5| Step: 5
Training loss: 0.7153515289045002
Validation loss: 2.2931796593569236

Epoch: 5| Step: 6
Training loss: 0.6660990732666175
Validation loss: 2.3763748374024685

Epoch: 5| Step: 7
Training loss: 0.5948497726019311
Validation loss: 2.327964739759481

Epoch: 5| Step: 8
Training loss: 0.8163711321272872
Validation loss: 2.3425344989152865

Epoch: 5| Step: 9
Training loss: 1.55656067225271
Validation loss: 2.3149918852275193

Epoch: 5| Step: 10
Training loss: 0.9961182535186942
Validation loss: 2.3234407207276

Epoch: 566| Step: 0
Training loss: 0.8432337629834249
Validation loss: 2.35074663875019

Epoch: 5| Step: 1
Training loss: 0.5586610233371613
Validation loss: 2.3137057569041204

Epoch: 5| Step: 2
Training loss: 0.658191533651644
Validation loss: 2.2734690412650624

Epoch: 5| Step: 3
Training loss: 1.026195566218271
Validation loss: 2.3471379825536434

Epoch: 5| Step: 4
Training loss: 0.7857117087767812
Validation loss: 2.3276786368042304

Epoch: 5| Step: 5
Training loss: 0.739189840238077
Validation loss: 2.353651593882501

Epoch: 5| Step: 6
Training loss: 0.8835294394863976
Validation loss: 2.3543934198788876

Epoch: 5| Step: 7
Training loss: 0.8890318424456597
Validation loss: 2.3083690739905527

Epoch: 5| Step: 8
Training loss: 0.613748797398028
Validation loss: 2.3123469369968253

Epoch: 5| Step: 9
Training loss: 1.5454484931806893
Validation loss: 2.3479435026834574

Epoch: 5| Step: 10
Training loss: 0.5918124357387239
Validation loss: 2.3182978220653623

Epoch: 567| Step: 0
Training loss: 0.6943190045444817
Validation loss: 2.330903387349753

Epoch: 5| Step: 1
Training loss: 0.7889170748715385
Validation loss: 2.38104757961713

Epoch: 5| Step: 2
Training loss: 0.8220511041102371
Validation loss: 2.4315829275506013

Epoch: 5| Step: 3
Training loss: 0.64906060488061
Validation loss: 2.3506772821924335

Epoch: 5| Step: 4
Training loss: 0.7501779186295103
Validation loss: 2.3114615051084804

Epoch: 5| Step: 5
Training loss: 1.5542624961347002
Validation loss: 2.2676112898322325

Epoch: 5| Step: 6
Training loss: 0.8771436522545901
Validation loss: 2.351321289416112

Epoch: 5| Step: 7
Training loss: 0.9357415556183944
Validation loss: 2.3147706555036343

Epoch: 5| Step: 8
Training loss: 0.633205197782142
Validation loss: 2.3205006404618573

Epoch: 5| Step: 9
Training loss: 0.46218431885651723
Validation loss: 2.3694932520978083

Epoch: 5| Step: 10
Training loss: 0.5555360777407439
Validation loss: 2.2736655184619896

Epoch: 568| Step: 0
Training loss: 1.5758328551815013
Validation loss: 2.2307752379967614

Epoch: 5| Step: 1
Training loss: 0.6543818859842003
Validation loss: 2.3750676510841493

Epoch: 5| Step: 2
Training loss: 0.6678502384816817
Validation loss: 2.2591857571744187

Epoch: 5| Step: 3
Training loss: 0.7166174890220058
Validation loss: 2.3080335229195112

Epoch: 5| Step: 4
Training loss: 0.5469343425706238
Validation loss: 2.3366457972765535

Epoch: 5| Step: 5
Training loss: 0.7754285212175518
Validation loss: 2.27197188387613

Epoch: 5| Step: 6
Training loss: 0.8423621454850153
Validation loss: 2.2961179674268033

Epoch: 5| Step: 7
Training loss: 0.9590728781080513
Validation loss: 2.335579803349213

Epoch: 5| Step: 8
Training loss: 0.8485240098324537
Validation loss: 2.324735921151967

Epoch: 5| Step: 9
Training loss: 0.5043626241571916
Validation loss: 2.3086288930032577

Epoch: 5| Step: 10
Training loss: 0.6969530275736256
Validation loss: 2.362095693610984

Epoch: 569| Step: 0
Training loss: 0.6190792739267116
Validation loss: 2.352806372018643

Epoch: 5| Step: 1
Training loss: 0.7502311509283677
Validation loss: 2.323291448327197

Epoch: 5| Step: 2
Training loss: 0.7573811197948118
Validation loss: 2.3487286220831267

Epoch: 5| Step: 3
Training loss: 0.9414766530663641
Validation loss: 2.3604334322177185

Epoch: 5| Step: 4
Training loss: 0.6345519190289064
Validation loss: 2.3444705962874965

Epoch: 5| Step: 5
Training loss: 1.6239111994015776
Validation loss: 2.370587331770629

Epoch: 5| Step: 6
Training loss: 0.8641495286596472
Validation loss: 2.3092376092639095

Epoch: 5| Step: 7
Training loss: 0.6403117926143613
Validation loss: 2.359609380222001

Epoch: 5| Step: 8
Training loss: 0.6017780908463143
Validation loss: 2.3177075074376323

Epoch: 5| Step: 9
Training loss: 0.5346563189905202
Validation loss: 2.3457032299192853

Epoch: 5| Step: 10
Training loss: 0.7934047083108918
Validation loss: 2.3265118215404565

Epoch: 570| Step: 0
Training loss: 0.6465267156006523
Validation loss: 2.3576077021667095

Epoch: 5| Step: 1
Training loss: 0.7994862575817121
Validation loss: 2.353756555162959

Epoch: 5| Step: 2
Training loss: 0.6970297149867053
Validation loss: 2.4036341771893612

Epoch: 5| Step: 3
Training loss: 1.6715720071484799
Validation loss: 2.353955860447699

Epoch: 5| Step: 4
Training loss: 0.8305410014578083
Validation loss: 2.3405078479161308

Epoch: 5| Step: 5
Training loss: 1.1191506909621758
Validation loss: 2.403632624265041

Epoch: 5| Step: 6
Training loss: 0.6207336245438237
Validation loss: 2.341545882679205

Epoch: 5| Step: 7
Training loss: 0.756048213425483
Validation loss: 2.3616357935378574

Epoch: 5| Step: 8
Training loss: 0.716727604234391
Validation loss: 2.306768061049929

Epoch: 5| Step: 9
Training loss: 0.67686976708162
Validation loss: 2.378677986832833

Epoch: 5| Step: 10
Training loss: 0.6325552146544101
Validation loss: 2.351049323956404

Epoch: 571| Step: 0
Training loss: 0.6433411447968221
Validation loss: 2.346095258662503

Epoch: 5| Step: 1
Training loss: 0.7629681244612643
Validation loss: 2.3708575688029248

Epoch: 5| Step: 2
Training loss: 0.7505453034717335
Validation loss: 2.2846587287458546

Epoch: 5| Step: 3
Training loss: 0.8584889091926151
Validation loss: 2.3155486440821464

Epoch: 5| Step: 4
Training loss: 0.7386991740910887
Validation loss: 2.347427781562056

Epoch: 5| Step: 5
Training loss: 0.9387162584216947
Validation loss: 2.2780183857952947

Epoch: 5| Step: 6
Training loss: 0.7893511178216372
Validation loss: 2.2706551507784347

Epoch: 5| Step: 7
Training loss: 0.6789075168821677
Validation loss: 2.3745458931927996

Epoch: 5| Step: 8
Training loss: 1.5258411714084104
Validation loss: 2.3362088489105335

Epoch: 5| Step: 9
Training loss: 0.6798829860845934
Validation loss: 2.3191125520253455

Epoch: 5| Step: 10
Training loss: 0.8626308148459936
Validation loss: 2.3730846403881043

Epoch: 572| Step: 0
Training loss: 0.591296245468067
Validation loss: 2.313412357745388

Epoch: 5| Step: 1
Training loss: 0.8762942687428228
Validation loss: 2.3208315092650236

Epoch: 5| Step: 2
Training loss: 0.8630100704635472
Validation loss: 2.310436195054956

Epoch: 5| Step: 3
Training loss: 0.6170251125668976
Validation loss: 2.3951314747892516

Epoch: 5| Step: 4
Training loss: 1.5550682330110368
Validation loss: 2.3870242091384815

Epoch: 5| Step: 5
Training loss: 0.8594725813517252
Validation loss: 2.3304531626717915

Epoch: 5| Step: 6
Training loss: 0.885761130402714
Validation loss: 2.322551564695551

Epoch: 5| Step: 7
Training loss: 1.0298462185362012
Validation loss: 2.3129731802500766

Epoch: 5| Step: 8
Training loss: 0.7355886130461288
Validation loss: 2.3043184875210465

Epoch: 5| Step: 9
Training loss: 0.5674317120541432
Validation loss: 2.396438076815884

Epoch: 5| Step: 10
Training loss: 0.6182121029185877
Validation loss: 2.2866126655044776

Epoch: 573| Step: 0
Training loss: 0.8019694747038574
Validation loss: 2.34174777355295

Epoch: 5| Step: 1
Training loss: 0.7622291615491245
Validation loss: 2.343787081298634

Epoch: 5| Step: 2
Training loss: 0.6553055006389257
Validation loss: 2.385532422733589

Epoch: 5| Step: 3
Training loss: 0.7914938905471719
Validation loss: 2.3672908799778662

Epoch: 5| Step: 4
Training loss: 0.8356015965473413
Validation loss: 2.383577615788423

Epoch: 5| Step: 5
Training loss: 0.6491707252706928
Validation loss: 2.3335318125705578

Epoch: 5| Step: 6
Training loss: 0.6882160965633162
Validation loss: 2.3250359038792614

Epoch: 5| Step: 7
Training loss: 0.9316772197837692
Validation loss: 2.358041815975835

Epoch: 5| Step: 8
Training loss: 1.5624372088213336
Validation loss: 2.3534955276736116

Epoch: 5| Step: 9
Training loss: 0.683189752272283
Validation loss: 2.3798867831036996

Epoch: 5| Step: 10
Training loss: 1.0243497088267808
Validation loss: 2.281339706835004

Epoch: 574| Step: 0
Training loss: 0.6347452952724052
Validation loss: 2.3194711811074615

Epoch: 5| Step: 1
Training loss: 0.6416963132804981
Validation loss: 2.3043418985278787

Epoch: 5| Step: 2
Training loss: 0.8354419772594001
Validation loss: 2.422553261140781

Epoch: 5| Step: 3
Training loss: 0.8984739213278332
Validation loss: 2.3636429032235924

Epoch: 5| Step: 4
Training loss: 0.9680837062650978
Validation loss: 2.2973510324791238

Epoch: 5| Step: 5
Training loss: 0.9719224789420113
Validation loss: 2.3371779159338577

Epoch: 5| Step: 6
Training loss: 0.8062803558430996
Validation loss: 2.3288231547728815

Epoch: 5| Step: 7
Training loss: 1.4745113112829757
Validation loss: 2.3691289404847145

Epoch: 5| Step: 8
Training loss: 0.5895084160518642
Validation loss: 2.355934384510422

Epoch: 5| Step: 9
Training loss: 0.632792013331215
Validation loss: 2.2831424197091015

Epoch: 5| Step: 10
Training loss: 1.0270799653550666
Validation loss: 2.359058346110478

Epoch: 575| Step: 0
Training loss: 0.6885352143539842
Validation loss: 2.2544926178337463

Epoch: 5| Step: 1
Training loss: 0.9486936521822616
Validation loss: 2.3807604079854516

Epoch: 5| Step: 2
Training loss: 1.5984298213651251
Validation loss: 2.426163350944881

Epoch: 5| Step: 3
Training loss: 0.9290290231636642
Validation loss: 2.3084026778343287

Epoch: 5| Step: 4
Training loss: 0.7823525088067359
Validation loss: 2.3561607882519815

Epoch: 5| Step: 5
Training loss: 0.6929069869978123
Validation loss: 2.342596654927041

Epoch: 5| Step: 6
Training loss: 0.8363688416705406
Validation loss: 2.303264939599409

Epoch: 5| Step: 7
Training loss: 0.5609356797807749
Validation loss: 2.3932102258902557

Epoch: 5| Step: 8
Training loss: 0.6607036014377896
Validation loss: 2.4052504839573894

Epoch: 5| Step: 9
Training loss: 0.7422223133154043
Validation loss: 2.2851050311640546

Epoch: 5| Step: 10
Training loss: 0.6947877167947373
Validation loss: 2.315010519507678

Epoch: 576| Step: 0
Training loss: 0.7510380713543876
Validation loss: 2.227580658537499

Epoch: 5| Step: 1
Training loss: 0.5527395241433497
Validation loss: 2.3380547317172002

Epoch: 5| Step: 2
Training loss: 0.6277925570003929
Validation loss: 2.3116332483202395

Epoch: 5| Step: 3
Training loss: 1.6845421476359281
Validation loss: 2.337067847526972

Epoch: 5| Step: 4
Training loss: 0.6775433273818998
Validation loss: 2.3294328942983578

Epoch: 5| Step: 5
Training loss: 0.860794905746198
Validation loss: 2.33076823184576

Epoch: 5| Step: 6
Training loss: 0.856691575176821
Validation loss: 2.3318768513706845

Epoch: 5| Step: 7
Training loss: 0.8125545410043445
Validation loss: 2.276739007508608

Epoch: 5| Step: 8
Training loss: 0.5996102199486362
Validation loss: 2.316439523654886

Epoch: 5| Step: 9
Training loss: 0.6689920450858082
Validation loss: 2.3145707107095936

Epoch: 5| Step: 10
Training loss: 0.7344382644349386
Validation loss: 2.311502807602209

Epoch: 577| Step: 0
Training loss: 1.111907593376442
Validation loss: 2.3126501751322484

Epoch: 5| Step: 1
Training loss: 0.8725661761483295
Validation loss: 2.336987396015635

Epoch: 5| Step: 2
Training loss: 0.6751433652934185
Validation loss: 2.2937156261805596

Epoch: 5| Step: 3
Training loss: 0.744277941432047
Validation loss: 2.3596143671059235

Epoch: 5| Step: 4
Training loss: 0.6658443107543538
Validation loss: 2.4005687378570153

Epoch: 5| Step: 5
Training loss: 1.7573554228873807
Validation loss: 2.359514431852745

Epoch: 5| Step: 6
Training loss: 0.6714731167775423
Validation loss: 2.2866442223554206

Epoch: 5| Step: 7
Training loss: 0.5073846041270142
Validation loss: 2.3166384340314226

Epoch: 5| Step: 8
Training loss: 0.789702731711339
Validation loss: 2.3044833541119885

Epoch: 5| Step: 9
Training loss: 0.6812585235202478
Validation loss: 2.3377798214233403

Epoch: 5| Step: 10
Training loss: 0.751428158306431
Validation loss: 2.3322871986299503

Epoch: 578| Step: 0
Training loss: 1.7479569225502758
Validation loss: 2.3500589263848553

Epoch: 5| Step: 1
Training loss: 0.8736293138535886
Validation loss: 2.349159853809463

Epoch: 5| Step: 2
Training loss: 0.4672047895721639
Validation loss: 2.374372930595878

Epoch: 5| Step: 3
Training loss: 0.505123796632915
Validation loss: 2.3406792413359856

Epoch: 5| Step: 4
Training loss: 0.7823776880167215
Validation loss: 2.3400088678992508

Epoch: 5| Step: 5
Training loss: 0.6968928818054941
Validation loss: 2.3564376687120356

Epoch: 5| Step: 6
Training loss: 0.645026554182055
Validation loss: 2.3179035152053586

Epoch: 5| Step: 7
Training loss: 0.7332925326383439
Validation loss: 2.266535766080329

Epoch: 5| Step: 8
Training loss: 0.7499735350707915
Validation loss: 2.3368451653596116

Epoch: 5| Step: 9
Training loss: 0.8797799409095023
Validation loss: 2.3297930661383712

Epoch: 5| Step: 10
Training loss: 0.6193734101430003
Validation loss: 2.2734469181090255

Epoch: 579| Step: 0
Training loss: 0.5394326473385099
Validation loss: 2.339677075477383

Epoch: 5| Step: 1
Training loss: 0.6879223913150565
Validation loss: 2.3181990882448567

Epoch: 5| Step: 2
Training loss: 0.7649180983040191
Validation loss: 2.307660359611631

Epoch: 5| Step: 3
Training loss: 0.49752329812536783
Validation loss: 2.395905300377427

Epoch: 5| Step: 4
Training loss: 0.7288629353400907
Validation loss: 2.450285406735292

Epoch: 5| Step: 5
Training loss: 0.703596211530127
Validation loss: 2.302233512396102

Epoch: 5| Step: 6
Training loss: 1.5926566768208923
Validation loss: 2.2612730203333804

Epoch: 5| Step: 7
Training loss: 0.97868202606781
Validation loss: 2.345255087782344

Epoch: 5| Step: 8
Training loss: 0.5842934240429782
Validation loss: 2.328499419716742

Epoch: 5| Step: 9
Training loss: 0.8279606278153031
Validation loss: 2.3127612471075727

Epoch: 5| Step: 10
Training loss: 0.8127848052660223
Validation loss: 2.3073677441739635

Epoch: 580| Step: 0
Training loss: 0.6558503796140632
Validation loss: 2.3846884790729104

Epoch: 5| Step: 1
Training loss: 1.6299114099077099
Validation loss: 2.283511980165649

Epoch: 5| Step: 2
Training loss: 0.7096570399545084
Validation loss: 2.3360802314676166

Epoch: 5| Step: 3
Training loss: 0.7866510992880569
Validation loss: 2.3599096641941197

Epoch: 5| Step: 4
Training loss: 0.6701055558522967
Validation loss: 2.3091300404052575

Epoch: 5| Step: 5
Training loss: 0.6987999029202058
Validation loss: 2.2818980322709397

Epoch: 5| Step: 6
Training loss: 0.8686049964699594
Validation loss: 2.4164072876328686

Epoch: 5| Step: 7
Training loss: 0.719838313584596
Validation loss: 2.342772784217165

Epoch: 5| Step: 8
Training loss: 0.7970583835598108
Validation loss: 2.344611799066869

Epoch: 5| Step: 9
Training loss: 0.8263329603643936
Validation loss: 2.261547648542942

Epoch: 5| Step: 10
Training loss: 0.5763180822009627
Validation loss: 2.376390065469095

Epoch: 581| Step: 0
Training loss: 1.0387641076737761
Validation loss: 2.3284264585650836

Epoch: 5| Step: 1
Training loss: 1.543486921002305
Validation loss: 2.366638172922129

Epoch: 5| Step: 2
Training loss: 0.8219059318262517
Validation loss: 2.3161557952105745

Epoch: 5| Step: 3
Training loss: 0.5674507244916556
Validation loss: 2.382284560035278

Epoch: 5| Step: 4
Training loss: 0.619911267791361
Validation loss: 2.2896214872586573

Epoch: 5| Step: 5
Training loss: 0.7236253581004164
Validation loss: 2.3187911119070543

Epoch: 5| Step: 6
Training loss: 0.683832377609371
Validation loss: 2.3973611993579422

Epoch: 5| Step: 7
Training loss: 0.6958568028434273
Validation loss: 2.3650054215207317

Epoch: 5| Step: 8
Training loss: 0.6367276899026103
Validation loss: 2.334381843217846

Epoch: 5| Step: 9
Training loss: 0.884780176308321
Validation loss: 2.3378754660859506

Epoch: 5| Step: 10
Training loss: 0.6364784957597351
Validation loss: 2.3625393001050163

Epoch: 582| Step: 0
Training loss: 0.6819353095148717
Validation loss: 2.4001817302878927

Epoch: 5| Step: 1
Training loss: 0.6517109800070826
Validation loss: 2.349794819544515

Epoch: 5| Step: 2
Training loss: 0.6479403186868149
Validation loss: 2.367929332429966

Epoch: 5| Step: 3
Training loss: 0.6631939087999277
Validation loss: 2.3638086980417903

Epoch: 5| Step: 4
Training loss: 1.5802751755413134
Validation loss: 2.3189925588962006

Epoch: 5| Step: 5
Training loss: 0.85164781895465
Validation loss: 2.29932214771774

Epoch: 5| Step: 6
Training loss: 0.7325494273698441
Validation loss: 2.337987506386154

Epoch: 5| Step: 7
Training loss: 0.9063387531360715
Validation loss: 2.403195207880999

Epoch: 5| Step: 8
Training loss: 0.6168717651127771
Validation loss: 2.426402573272674

Epoch: 5| Step: 9
Training loss: 0.8021442258105207
Validation loss: 2.3181577250738843

Epoch: 5| Step: 10
Training loss: 0.5289606807316601
Validation loss: 2.367313242641249

Epoch: 583| Step: 0
Training loss: 0.7320931065499934
Validation loss: 2.3033811286903934

Epoch: 5| Step: 1
Training loss: 0.9229841833340288
Validation loss: 2.263691700707485

Epoch: 5| Step: 2
Training loss: 0.6089810296065254
Validation loss: 2.3507427159867125

Epoch: 5| Step: 3
Training loss: 0.5630112285188806
Validation loss: 2.3455930314821827

Epoch: 5| Step: 4
Training loss: 0.7770847675081848
Validation loss: 2.340928820215097

Epoch: 5| Step: 5
Training loss: 1.6562507197540446
Validation loss: 2.4046585345336617

Epoch: 5| Step: 6
Training loss: 0.684376404817437
Validation loss: 2.3091861785146506

Epoch: 5| Step: 7
Training loss: 0.6936205304968205
Validation loss: 2.328411567242086

Epoch: 5| Step: 8
Training loss: 0.6743752069269664
Validation loss: 2.3440692632206335

Epoch: 5| Step: 9
Training loss: 0.7879412398867972
Validation loss: 2.387293591494906

Epoch: 5| Step: 10
Training loss: 0.8354449024010905
Validation loss: 2.3512100044384043

Epoch: 584| Step: 0
Training loss: 0.7855990475515781
Validation loss: 2.3636987634482005

Epoch: 5| Step: 1
Training loss: 0.7051493009110321
Validation loss: 2.3832347714247595

Epoch: 5| Step: 2
Training loss: 0.8556372419976477
Validation loss: 2.332234751004833

Epoch: 5| Step: 3
Training loss: 0.6249134480627959
Validation loss: 2.3581779174254285

Epoch: 5| Step: 4
Training loss: 0.7025700392374982
Validation loss: 2.3256556481918755

Epoch: 5| Step: 5
Training loss: 0.7987566032196424
Validation loss: 2.320199726902963

Epoch: 5| Step: 6
Training loss: 0.8048782492908403
Validation loss: 2.3999726913464006

Epoch: 5| Step: 7
Training loss: 0.8574846110061306
Validation loss: 2.2729590477412636

Epoch: 5| Step: 8
Training loss: 1.507347470058763
Validation loss: 2.295154148165034

Epoch: 5| Step: 9
Training loss: 0.9478643039591375
Validation loss: 2.340988299701927

Epoch: 5| Step: 10
Training loss: 0.685092830006391
Validation loss: 2.2570717052574905

Epoch: 585| Step: 0
Training loss: 0.5648195601859224
Validation loss: 2.3753785143149138

Epoch: 5| Step: 1
Training loss: 0.9379179340852782
Validation loss: 2.4108928767923468

Epoch: 5| Step: 2
Training loss: 0.5906322589811679
Validation loss: 2.293503974720332

Epoch: 5| Step: 3
Training loss: 0.5406167939285449
Validation loss: 2.3338745635061273

Epoch: 5| Step: 4
Training loss: 0.6727160135939078
Validation loss: 2.326569685086092

Epoch: 5| Step: 5
Training loss: 0.7391877437225711
Validation loss: 2.3085483632417656

Epoch: 5| Step: 6
Training loss: 0.6878328384657678
Validation loss: 2.336959295473265

Epoch: 5| Step: 7
Training loss: 0.4551330336815378
Validation loss: 2.2987175323977618

Epoch: 5| Step: 8
Training loss: 0.5714701047772703
Validation loss: 2.330246428939057

Epoch: 5| Step: 9
Training loss: 1.8030799873326764
Validation loss: 2.2740881553693657

Epoch: 5| Step: 10
Training loss: 0.9150718267838448
Validation loss: 2.393826674690405

Epoch: 586| Step: 0
Training loss: 0.6441581339680184
Validation loss: 2.3493652020480322

Epoch: 5| Step: 1
Training loss: 0.8718289749412373
Validation loss: 2.4497841190349723

Epoch: 5| Step: 2
Training loss: 0.7787573531463432
Validation loss: 2.335298943491435

Epoch: 5| Step: 3
Training loss: 0.7876682616416915
Validation loss: 2.3221492878428425

Epoch: 5| Step: 4
Training loss: 0.529856199783666
Validation loss: 2.3004196893802944

Epoch: 5| Step: 5
Training loss: 1.5850766857140117
Validation loss: 2.33420719005309

Epoch: 5| Step: 6
Training loss: 0.885515581477462
Validation loss: 2.294809424569608

Epoch: 5| Step: 7
Training loss: 0.7188835434622367
Validation loss: 2.3438789720496462

Epoch: 5| Step: 8
Training loss: 0.7956361677849866
Validation loss: 2.348885746098016

Epoch: 5| Step: 9
Training loss: 0.7648223250508442
Validation loss: 2.3695724311971524

Epoch: 5| Step: 10
Training loss: 0.597248761255218
Validation loss: 2.3776564786019723

Epoch: 587| Step: 0
Training loss: 0.8443376825699784
Validation loss: 2.3468359273172545

Epoch: 5| Step: 1
Training loss: 0.7432094966118467
Validation loss: 2.314563155692487

Epoch: 5| Step: 2
Training loss: 0.6505051703866996
Validation loss: 2.30681828268303

Epoch: 5| Step: 3
Training loss: 0.8229937014356135
Validation loss: 2.2014395722841296

Epoch: 5| Step: 4
Training loss: 0.6231888755727302
Validation loss: 2.370634842873303

Epoch: 5| Step: 5
Training loss: 0.5411729824781203
Validation loss: 2.263612510656361

Epoch: 5| Step: 6
Training loss: 0.7533607288108307
Validation loss: 2.3413687298556645

Epoch: 5| Step: 7
Training loss: 0.6304004523475351
Validation loss: 2.2887881154195813

Epoch: 5| Step: 8
Training loss: 1.5173623264209914
Validation loss: 2.366678772464533

Epoch: 5| Step: 9
Training loss: 0.8422071691703901
Validation loss: 2.3662956737625573

Epoch: 5| Step: 10
Training loss: 0.6698970734478942
Validation loss: 2.31067917923599

Epoch: 588| Step: 0
Training loss: 0.6803439467122627
Validation loss: 2.349607817465263

Epoch: 5| Step: 1
Training loss: 0.8043501433805308
Validation loss: 2.349513169242442

Epoch: 5| Step: 2
Training loss: 0.7640456043707856
Validation loss: 2.2981603576800778

Epoch: 5| Step: 3
Training loss: 0.6306838508873127
Validation loss: 2.352071718738251

Epoch: 5| Step: 4
Training loss: 0.7484652392636456
Validation loss: 2.272677251427536

Epoch: 5| Step: 5
Training loss: 0.7240381997236877
Validation loss: 2.316018809425345

Epoch: 5| Step: 6
Training loss: 1.6117002115371508
Validation loss: 2.2890291968584355

Epoch: 5| Step: 7
Training loss: 0.7071489267790593
Validation loss: 2.3520945585301933

Epoch: 5| Step: 8
Training loss: 0.5870506140465039
Validation loss: 2.3291330984243124

Epoch: 5| Step: 9
Training loss: 0.6109099008711693
Validation loss: 2.330947317085283

Epoch: 5| Step: 10
Training loss: 0.7131348492061745
Validation loss: 2.3996902597938865

Epoch: 589| Step: 0
Training loss: 0.962372925036317
Validation loss: 2.344982591511892

Epoch: 5| Step: 1
Training loss: 0.9526281468852882
Validation loss: 2.3632543256028153

Epoch: 5| Step: 2
Training loss: 0.6398544562146228
Validation loss: 2.3704367214862847

Epoch: 5| Step: 3
Training loss: 0.6918535671343148
Validation loss: 2.327964857041206

Epoch: 5| Step: 4
Training loss: 1.5344458724860905
Validation loss: 2.329015052801838

Epoch: 5| Step: 5
Training loss: 0.5633277895003811
Validation loss: 2.336956258431189

Epoch: 5| Step: 6
Training loss: 0.5759576431535576
Validation loss: 2.404008938565014

Epoch: 5| Step: 7
Training loss: 0.9394461776254454
Validation loss: 2.3438606947049623

Epoch: 5| Step: 8
Training loss: 0.5824240057002493
Validation loss: 2.347337646115594

Epoch: 5| Step: 9
Training loss: 0.5714611087842466
Validation loss: 2.284538042522805

Epoch: 5| Step: 10
Training loss: 0.8204534500372209
Validation loss: 2.350765316772741

Epoch: 590| Step: 0
Training loss: 0.5691360724796609
Validation loss: 2.2904388328579133

Epoch: 5| Step: 1
Training loss: 1.6154130424017399
Validation loss: 2.358948640059058

Epoch: 5| Step: 2
Training loss: 0.6290516655600541
Validation loss: 2.316291861179225

Epoch: 5| Step: 3
Training loss: 0.7850468497661905
Validation loss: 2.349323167338276

Epoch: 5| Step: 4
Training loss: 0.720425725548621
Validation loss: 2.358809194596498

Epoch: 5| Step: 5
Training loss: 0.82100259726807
Validation loss: 2.2976067684421086

Epoch: 5| Step: 6
Training loss: 0.6791839049400271
Validation loss: 2.3490397099492837

Epoch: 5| Step: 7
Training loss: 0.8283801855221714
Validation loss: 2.413799680038829

Epoch: 5| Step: 8
Training loss: 0.7948655617002557
Validation loss: 2.3358386672477174

Epoch: 5| Step: 9
Training loss: 0.36345391630848595
Validation loss: 2.3584426105655933

Epoch: 5| Step: 10
Training loss: 0.6051391196491855
Validation loss: 2.306617107286924

Epoch: 591| Step: 0
Training loss: 1.5563629170706197
Validation loss: 2.4247832726740404

Epoch: 5| Step: 1
Training loss: 0.4910773215002231
Validation loss: 2.3924312278750652

Epoch: 5| Step: 2
Training loss: 0.704024523622189
Validation loss: 2.4233283565630543

Epoch: 5| Step: 3
Training loss: 0.5240922220863024
Validation loss: 2.3420004759536237

Epoch: 5| Step: 4
Training loss: 0.8097052927539371
Validation loss: 2.3912190967132445

Epoch: 5| Step: 5
Training loss: 0.7485228137487404
Validation loss: 2.35064907265169

Epoch: 5| Step: 6
Training loss: 0.5969399042441561
Validation loss: 2.3299498238077545

Epoch: 5| Step: 7
Training loss: 0.7810458107186556
Validation loss: 2.4001597950961435

Epoch: 5| Step: 8
Training loss: 0.9464963325755893
Validation loss: 2.3303433602465313

Epoch: 5| Step: 9
Training loss: 0.665188407093746
Validation loss: 2.309500605744829

Epoch: 5| Step: 10
Training loss: 0.7810089502395662
Validation loss: 2.2937525518031596

Epoch: 592| Step: 0
Training loss: 0.8067017317341331
Validation loss: 2.28903964894076

Epoch: 5| Step: 1
Training loss: 0.6497057266944714
Validation loss: 2.330412550265938

Epoch: 5| Step: 2
Training loss: 0.6544257421412742
Validation loss: 2.352943081375451

Epoch: 5| Step: 3
Training loss: 1.446015635420395
Validation loss: 2.3298539286067816

Epoch: 5| Step: 4
Training loss: 0.685893414064738
Validation loss: 2.227901761332183

Epoch: 5| Step: 5
Training loss: 0.6343180795323242
Validation loss: 2.2993466531822415

Epoch: 5| Step: 6
Training loss: 0.8510404614020178
Validation loss: 2.3534658356022096

Epoch: 5| Step: 7
Training loss: 0.8103889771138303
Validation loss: 2.3857795851053676

Epoch: 5| Step: 8
Training loss: 0.9582188302894028
Validation loss: 2.3136692754927317

Epoch: 5| Step: 9
Training loss: 0.5381785899735915
Validation loss: 2.348634953020633

Epoch: 5| Step: 10
Training loss: 0.5749047521816457
Validation loss: 2.3210077548921904

Epoch: 593| Step: 0
Training loss: 0.6702639760058181
Validation loss: 2.323614111704912

Epoch: 5| Step: 1
Training loss: 0.8750913776640313
Validation loss: 2.340656926504307

Epoch: 5| Step: 2
Training loss: 0.46463867279862836
Validation loss: 2.3502516950569836

Epoch: 5| Step: 3
Training loss: 0.8434248050329339
Validation loss: 2.393278859738514

Epoch: 5| Step: 4
Training loss: 0.7090536877087483
Validation loss: 2.3590412051818888

Epoch: 5| Step: 5
Training loss: 0.6365877964647165
Validation loss: 2.315554235694929

Epoch: 5| Step: 6
Training loss: 0.73497232534247
Validation loss: 2.395018346846688

Epoch: 5| Step: 7
Training loss: 0.46413725369687736
Validation loss: 2.231383492096397

Epoch: 5| Step: 8
Training loss: 0.5122722515115685
Validation loss: 2.369936175956589

Epoch: 5| Step: 9
Training loss: 1.642572101305282
Validation loss: 2.3280815951291616

Epoch: 5| Step: 10
Training loss: 0.7766564939785008
Validation loss: 2.346144408988979

Epoch: 594| Step: 0
Training loss: 0.870840780022524
Validation loss: 2.323509386430476

Epoch: 5| Step: 1
Training loss: 0.6864748811439754
Validation loss: 2.346039310394777

Epoch: 5| Step: 2
Training loss: 0.655263840993091
Validation loss: 2.2689572178553985

Epoch: 5| Step: 3
Training loss: 0.6673491431795169
Validation loss: 2.3715554637739507

Epoch: 5| Step: 4
Training loss: 0.4099364282006898
Validation loss: 2.3395239671259973

Epoch: 5| Step: 5
Training loss: 0.6357254518336515
Validation loss: 2.3463379428683178

Epoch: 5| Step: 6
Training loss: 0.6763715205768405
Validation loss: 2.305124812057017

Epoch: 5| Step: 7
Training loss: 1.540333566705394
Validation loss: 2.3099503189850696

Epoch: 5| Step: 8
Training loss: 0.7166638991575995
Validation loss: 2.382676285391177

Epoch: 5| Step: 9
Training loss: 0.9599531761313596
Validation loss: 2.2133936107325836

Epoch: 5| Step: 10
Training loss: 0.6837783782132985
Validation loss: 2.3653572084292223

Epoch: 595| Step: 0
Training loss: 0.5325279012722173
Validation loss: 2.3631910856914304

Epoch: 5| Step: 1
Training loss: 0.722624494525051
Validation loss: 2.3134467513033585

Epoch: 5| Step: 2
Training loss: 0.7251668261278919
Validation loss: 2.3452478852165446

Epoch: 5| Step: 3
Training loss: 0.7824397374064852
Validation loss: 2.328806743527064

Epoch: 5| Step: 4
Training loss: 0.624024058358088
Validation loss: 2.367339733189784

Epoch: 5| Step: 5
Training loss: 0.7996218219602688
Validation loss: 2.355087527776573

Epoch: 5| Step: 6
Training loss: 1.5523645116438047
Validation loss: 2.2777750382238935

Epoch: 5| Step: 7
Training loss: 0.6195450914720011
Validation loss: 2.3929081394339407

Epoch: 5| Step: 8
Training loss: 0.6240669915845186
Validation loss: 2.3149070362830644

Epoch: 5| Step: 9
Training loss: 0.8390201167194492
Validation loss: 2.4059450605947426

Epoch: 5| Step: 10
Training loss: 0.8192531830344878
Validation loss: 2.3408169656000517

Epoch: 596| Step: 0
Training loss: 0.939697931635822
Validation loss: 2.3584408186359638

Epoch: 5| Step: 1
Training loss: 0.5086620853298172
Validation loss: 2.257659386312334

Epoch: 5| Step: 2
Training loss: 0.7206783962400912
Validation loss: 2.3847193530086286

Epoch: 5| Step: 3
Training loss: 0.781512635908034
Validation loss: 2.3235798816078552

Epoch: 5| Step: 4
Training loss: 0.4972728324182021
Validation loss: 2.352889842267984

Epoch: 5| Step: 5
Training loss: 0.714786423015642
Validation loss: 2.2899671776667248

Epoch: 5| Step: 6
Training loss: 0.5377447912672418
Validation loss: 2.325997133859537

Epoch: 5| Step: 7
Training loss: 1.4950114585922147
Validation loss: 2.361108288973385

Epoch: 5| Step: 8
Training loss: 0.6690910681763939
Validation loss: 2.310140380906965

Epoch: 5| Step: 9
Training loss: 0.7865937771070677
Validation loss: 2.304682369236895

Epoch: 5| Step: 10
Training loss: 0.5588558355794152
Validation loss: 2.3618586981041028

Epoch: 597| Step: 0
Training loss: 0.5025665157097429
Validation loss: 2.3291100774948044

Epoch: 5| Step: 1
Training loss: 0.5816851361256301
Validation loss: 2.353221617229254

Epoch: 5| Step: 2
Training loss: 0.645161268787999
Validation loss: 2.3698200100178854

Epoch: 5| Step: 3
Training loss: 0.5681819311055157
Validation loss: 2.288077574593538

Epoch: 5| Step: 4
Training loss: 0.8555979870585714
Validation loss: 2.3308475792680183

Epoch: 5| Step: 5
Training loss: 0.6976267843655963
Validation loss: 2.349374412897059

Epoch: 5| Step: 6
Training loss: 0.7724706984336086
Validation loss: 2.362862528439605

Epoch: 5| Step: 7
Training loss: 0.679985770188834
Validation loss: 2.350693211392301

Epoch: 5| Step: 8
Training loss: 1.0585136805584145
Validation loss: 2.329186872844129

Epoch: 5| Step: 9
Training loss: 0.6615994270408714
Validation loss: 2.2826834751632576

Epoch: 5| Step: 10
Training loss: 1.7001686685699493
Validation loss: 2.398035683094547

Epoch: 598| Step: 0
Training loss: 0.7161617115456853
Validation loss: 2.359096763865954

Epoch: 5| Step: 1
Training loss: 0.754217804883859
Validation loss: 2.3083582846296746

Epoch: 5| Step: 2
Training loss: 0.6707092196010451
Validation loss: 2.321563405059977

Epoch: 5| Step: 3
Training loss: 0.6681146741163696
Validation loss: 2.2962269000156765

Epoch: 5| Step: 4
Training loss: 0.7614885813858233
Validation loss: 2.3734883202199666

Epoch: 5| Step: 5
Training loss: 0.8764414154576801
Validation loss: 2.362010938547377

Epoch: 5| Step: 6
Training loss: 0.5575375475021345
Validation loss: 2.3258694849232064

Epoch: 5| Step: 7
Training loss: 1.5269656286462032
Validation loss: 2.3538711074464542

Epoch: 5| Step: 8
Training loss: 0.5434485312291526
Validation loss: 2.3400600073950204

Epoch: 5| Step: 9
Training loss: 0.6574751453270837
Validation loss: 2.357204378388214

Epoch: 5| Step: 10
Training loss: 0.9442582044197033
Validation loss: 2.3265788517508903

Epoch: 599| Step: 0
Training loss: 0.5029211247280011
Validation loss: 2.289806634337634

Epoch: 5| Step: 1
Training loss: 0.6388259141978678
Validation loss: 2.3826284982050323

Epoch: 5| Step: 2
Training loss: 0.7601987491657591
Validation loss: 2.230289783139874

Epoch: 5| Step: 3
Training loss: 0.6378215997729915
Validation loss: 2.4056315517580624

Epoch: 5| Step: 4
Training loss: 1.6171378160298941
Validation loss: 2.298190073788067

Epoch: 5| Step: 5
Training loss: 0.7250704879037945
Validation loss: 2.3750286413601933

Epoch: 5| Step: 6
Training loss: 0.7505680952648984
Validation loss: 2.337430407707899

Epoch: 5| Step: 7
Training loss: 0.6003886325185124
Validation loss: 2.282146538966633

Epoch: 5| Step: 8
Training loss: 0.7559708308567009
Validation loss: 2.2834098639019578

Epoch: 5| Step: 9
Training loss: 0.6095685895891173
Validation loss: 2.292940141304042

Epoch: 5| Step: 10
Training loss: 0.9452042635910696
Validation loss: 2.302454795447545

Epoch: 600| Step: 0
Training loss: 0.4555014086574878
Validation loss: 2.2917006209497224

Epoch: 5| Step: 1
Training loss: 0.5511728612511109
Validation loss: 2.311438969207324

Epoch: 5| Step: 2
Training loss: 0.5478498761428201
Validation loss: 2.336933718815334

Epoch: 5| Step: 3
Training loss: 0.7943452810615411
Validation loss: 2.338544789715584

Epoch: 5| Step: 4
Training loss: 0.842010010822887
Validation loss: 2.3055362329547644

Epoch: 5| Step: 5
Training loss: 0.5043514857430167
Validation loss: 2.334696852183594

Epoch: 5| Step: 6
Training loss: 0.6940920330292752
Validation loss: 2.3253994426020363

Epoch: 5| Step: 7
Training loss: 0.6412937349050606
Validation loss: 2.381793656743509

Epoch: 5| Step: 8
Training loss: 0.9854830001108011
Validation loss: 2.31087626683428

Epoch: 5| Step: 9
Training loss: 1.4887890687775907
Validation loss: 2.429316918934087

Epoch: 5| Step: 10
Training loss: 0.6267111718407481
Validation loss: 2.413835137212313

Testing loss: 2.994032169176864
