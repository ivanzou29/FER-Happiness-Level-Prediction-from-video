Epoch: 1| Step: 0
Training loss: 7.974329293008902
Validation loss: 8.643938978521344

Epoch: 5| Step: 1
Training loss: 9.160506473182302
Validation loss: 8.637160849747898

Epoch: 5| Step: 2
Training loss: 9.287465695385839
Validation loss: 8.632764063732532

Epoch: 5| Step: 3
Training loss: 7.610279319339033
Validation loss: 8.629353869347126

Epoch: 5| Step: 4
Training loss: 8.711796219585375
Validation loss: 8.623282398408778

Epoch: 5| Step: 5
Training loss: 8.8572502481305
Validation loss: 8.618147453574

Epoch: 5| Step: 6
Training loss: 8.013924401562873
Validation loss: 8.613378110416386

Epoch: 5| Step: 7
Training loss: 8.595685595230364
Validation loss: 8.609090781565376

Epoch: 5| Step: 8
Training loss: 8.116622126755388
Validation loss: 8.606396400771578

Epoch: 5| Step: 9
Training loss: 9.455876326757537
Validation loss: 8.598242220965332

Epoch: 5| Step: 10
Training loss: 8.269349497589351
Validation loss: 8.59604556988425

Epoch: 2| Step: 0
Training loss: 9.34156595176378
Validation loss: 8.590780111555263

Epoch: 5| Step: 1
Training loss: 8.34846780390579
Validation loss: 8.583696040100214

Epoch: 5| Step: 2
Training loss: 6.654687832476072
Validation loss: 8.581983287078558

Epoch: 5| Step: 3
Training loss: 8.743504756517611
Validation loss: 8.576745891731292

Epoch: 5| Step: 4
Training loss: 9.079635520711436
Validation loss: 8.575668715194192

Epoch: 5| Step: 5
Training loss: 8.891937427158162
Validation loss: 8.568439227128488

Epoch: 5| Step: 6
Training loss: 9.269464993310404
Validation loss: 8.566697448366172

Epoch: 5| Step: 7
Training loss: 7.944074896314357
Validation loss: 8.562999821233506

Epoch: 5| Step: 8
Training loss: 8.724671680645558
Validation loss: 8.558297420793448

Epoch: 5| Step: 9
Training loss: 7.894035946702551
Validation loss: 8.55210969049115

Epoch: 5| Step: 10
Training loss: 8.525417695761718
Validation loss: 8.548378681063404

Epoch: 3| Step: 0
Training loss: 7.718870586735188
Validation loss: 8.54616601205765

Epoch: 5| Step: 1
Training loss: 8.303359893588917
Validation loss: 8.541727218193207

Epoch: 5| Step: 2
Training loss: 7.480036041254534
Validation loss: 8.536329846489219

Epoch: 5| Step: 3
Training loss: 8.107957072870319
Validation loss: 8.53136284782211

Epoch: 5| Step: 4
Training loss: 8.589222440155153
Validation loss: 8.528170391333173

Epoch: 5| Step: 5
Training loss: 8.24641849342792
Validation loss: 8.523669878340813

Epoch: 5| Step: 6
Training loss: 8.303920362322188
Validation loss: 8.520706420919282

Epoch: 5| Step: 7
Training loss: 9.290127705167476
Validation loss: 8.516878408622107

Epoch: 5| Step: 8
Training loss: 8.746061474091853
Validation loss: 8.510543880329456

Epoch: 5| Step: 9
Training loss: 9.461056444726085
Validation loss: 8.50824922128749

Epoch: 5| Step: 10
Training loss: 8.829746117749153
Validation loss: 8.50195010723224

Epoch: 4| Step: 0
Training loss: 8.33349802490255
Validation loss: 8.498301274166634

Epoch: 5| Step: 1
Training loss: 8.170655139443522
Validation loss: 8.49318128650657

Epoch: 5| Step: 2
Training loss: 8.149727153306413
Validation loss: 8.488996550962092

Epoch: 5| Step: 3
Training loss: 8.323571654811019
Validation loss: 8.483800426507896

Epoch: 5| Step: 4
Training loss: 8.236306588260318
Validation loss: 8.480647109608615

Epoch: 5| Step: 5
Training loss: 8.732986913124552
Validation loss: 8.475810366883984

Epoch: 5| Step: 6
Training loss: 8.880323076299259
Validation loss: 8.470778241879326

Epoch: 5| Step: 7
Training loss: 9.178058366075787
Validation loss: 8.467503764782293

Epoch: 5| Step: 8
Training loss: 6.909236762683869
Validation loss: 8.460293337300994

Epoch: 5| Step: 9
Training loss: 8.732577608136609
Validation loss: 8.456843443516442

Epoch: 5| Step: 10
Training loss: 8.899936512924237
Validation loss: 8.45210817876171

Epoch: 5| Step: 0
Training loss: 8.194125457704535
Validation loss: 8.44641975776529

Epoch: 5| Step: 1
Training loss: 8.298108485139993
Validation loss: 8.441120686172175

Epoch: 5| Step: 2
Training loss: 8.490159565534807
Validation loss: 8.434956567782802

Epoch: 5| Step: 3
Training loss: 7.829085422464497
Validation loss: 8.429758926650553

Epoch: 5| Step: 4
Training loss: 8.885303802190816
Validation loss: 8.425499109695199

Epoch: 5| Step: 5
Training loss: 9.033642514651525
Validation loss: 8.421469995997986

Epoch: 5| Step: 6
Training loss: 9.2066417768705
Validation loss: 8.417357398652168

Epoch: 5| Step: 7
Training loss: 7.858760013370678
Validation loss: 8.410444869650531

Epoch: 5| Step: 8
Training loss: 7.880634048436147
Validation loss: 8.406144890153051

Epoch: 5| Step: 9
Training loss: 8.31648514523404
Validation loss: 8.40050659058444

Epoch: 5| Step: 10
Training loss: 7.876279696681141
Validation loss: 8.395155525700044

Epoch: 6| Step: 0
Training loss: 6.961695911265982
Validation loss: 8.392179742480756

Epoch: 5| Step: 1
Training loss: 8.774850923407607
Validation loss: 8.386893787089

Epoch: 5| Step: 2
Training loss: 8.721811283525325
Validation loss: 8.382591204957365

Epoch: 5| Step: 3
Training loss: 7.664270054051187
Validation loss: 8.375580582799548

Epoch: 5| Step: 4
Training loss: 8.496720971819023
Validation loss: 8.370501938055895

Epoch: 5| Step: 5
Training loss: 8.093119357368776
Validation loss: 8.366597220814045

Epoch: 5| Step: 6
Training loss: 8.77113710241357
Validation loss: 8.361738627180497

Epoch: 5| Step: 7
Training loss: 8.486150791084462
Validation loss: 8.3551980403512

Epoch: 5| Step: 8
Training loss: 8.393820496900068
Validation loss: 8.349026865822436

Epoch: 5| Step: 9
Training loss: 8.77839413288365
Validation loss: 8.34389456979784

Epoch: 5| Step: 10
Training loss: 8.116846776866069
Validation loss: 8.340491783511695

Epoch: 7| Step: 0
Training loss: 7.722719229874073
Validation loss: 8.334214798443739

Epoch: 5| Step: 1
Training loss: 7.900895669116735
Validation loss: 8.329649703798054

Epoch: 5| Step: 2
Training loss: 8.42378351954629
Validation loss: 8.321660499617376

Epoch: 5| Step: 3
Training loss: 7.48429217521695
Validation loss: 8.315249078295654

Epoch: 5| Step: 4
Training loss: 8.85700949115811
Validation loss: 8.311081582619913

Epoch: 5| Step: 5
Training loss: 8.161705793967654
Validation loss: 8.30442319348361

Epoch: 5| Step: 6
Training loss: 8.590290496852392
Validation loss: 8.30011976530999

Epoch: 5| Step: 7
Training loss: 7.9827496988899105
Validation loss: 8.29702989335443

Epoch: 5| Step: 8
Training loss: 7.8656701421219015
Validation loss: 8.287481119655334

Epoch: 5| Step: 9
Training loss: 8.995082783511586
Validation loss: 8.283841289221373

Epoch: 5| Step: 10
Training loss: 8.767798060910964
Validation loss: 8.275989647204783

Epoch: 8| Step: 0
Training loss: 8.375331131950796
Validation loss: 8.271932445260191

Epoch: 5| Step: 1
Training loss: 7.37233880085087
Validation loss: 8.263736970968381

Epoch: 5| Step: 2
Training loss: 8.571235600070393
Validation loss: 8.256788457062768

Epoch: 5| Step: 3
Training loss: 8.42090879995086
Validation loss: 8.25601326169711

Epoch: 5| Step: 4
Training loss: 8.576336227715208
Validation loss: 8.243664498690311

Epoch: 5| Step: 5
Training loss: 7.637640809105011
Validation loss: 8.235980011774389

Epoch: 5| Step: 6
Training loss: 8.008544650218964
Validation loss: 8.23320739242578

Epoch: 5| Step: 7
Training loss: 8.403006569626116
Validation loss: 8.226783776499351

Epoch: 5| Step: 8
Training loss: 8.170434303273087
Validation loss: 8.217287900906452

Epoch: 5| Step: 9
Training loss: 8.412730842132534
Validation loss: 8.211646824227431

Epoch: 5| Step: 10
Training loss: 8.018215898430752
Validation loss: 8.206094407636076

Epoch: 9| Step: 0
Training loss: 7.510496296947682
Validation loss: 8.197298968381391

Epoch: 5| Step: 1
Training loss: 8.716121810699143
Validation loss: 8.190788479729843

Epoch: 5| Step: 2
Training loss: 7.65626594386095
Validation loss: 8.185766524263915

Epoch: 5| Step: 3
Training loss: 8.621534452940624
Validation loss: 8.176868967998566

Epoch: 5| Step: 4
Training loss: 8.794052402960515
Validation loss: 8.170748579726071

Epoch: 5| Step: 5
Training loss: 7.979681199285866
Validation loss: 8.16222080096873

Epoch: 5| Step: 6
Training loss: 8.12384024926068
Validation loss: 8.154291281346675

Epoch: 5| Step: 7
Training loss: 7.946728485472885
Validation loss: 8.144505955176387

Epoch: 5| Step: 8
Training loss: 8.325399614886878
Validation loss: 8.139358671116067

Epoch: 5| Step: 9
Training loss: 7.159129533759837
Validation loss: 8.129564778448131

Epoch: 5| Step: 10
Training loss: 8.271005418910596
Validation loss: 8.121589524173334

Epoch: 10| Step: 0
Training loss: 8.188864557835966
Validation loss: 8.112782708073286

Epoch: 5| Step: 1
Training loss: 7.9477727301193575
Validation loss: 8.106263229864444

Epoch: 5| Step: 2
Training loss: 8.297339359945546
Validation loss: 8.096035950195631

Epoch: 5| Step: 3
Training loss: 7.80825934712612
Validation loss: 8.09001741231668

Epoch: 5| Step: 4
Training loss: 8.286419100921295
Validation loss: 8.079401203069876

Epoch: 5| Step: 5
Training loss: 7.781895867318896
Validation loss: 8.069400043702036

Epoch: 5| Step: 6
Training loss: 7.210307679615122
Validation loss: 8.06076115252441

Epoch: 5| Step: 7
Training loss: 7.631937591793403
Validation loss: 8.052415836429237

Epoch: 5| Step: 8
Training loss: 7.00466327650284
Validation loss: 8.038114730416195

Epoch: 5| Step: 9
Training loss: 9.590516381069708
Validation loss: 8.030904568470028

Epoch: 5| Step: 10
Training loss: 8.198576678052017
Validation loss: 8.023183994741885

Epoch: 11| Step: 0
Training loss: 6.779995147343252
Validation loss: 8.012935586158244

Epoch: 5| Step: 1
Training loss: 8.86354550757448
Validation loss: 8.005414932414606

Epoch: 5| Step: 2
Training loss: 8.53833384428284
Validation loss: 7.997724917145745

Epoch: 5| Step: 3
Training loss: 7.426662210204033
Validation loss: 7.983989093545126

Epoch: 5| Step: 4
Training loss: 7.66365235268488
Validation loss: 7.976637187094392

Epoch: 5| Step: 5
Training loss: 7.560112190019643
Validation loss: 7.967214025736647

Epoch: 5| Step: 6
Training loss: 8.162432085254169
Validation loss: 7.952163942192033

Epoch: 5| Step: 7
Training loss: 8.667574859375089
Validation loss: 7.943938300594599

Epoch: 5| Step: 8
Training loss: 7.912903168879207
Validation loss: 7.933611310557914

Epoch: 5| Step: 9
Training loss: 7.349668544639578
Validation loss: 7.925676343503532

Epoch: 5| Step: 10
Training loss: 7.904101415300135
Validation loss: 7.913726196652368

Epoch: 12| Step: 0
Training loss: 7.167035766086513
Validation loss: 7.90457869379482

Epoch: 5| Step: 1
Training loss: 8.168905094136651
Validation loss: 7.896553219941999

Epoch: 5| Step: 2
Training loss: 7.741062055561038
Validation loss: 7.882614613444258

Epoch: 5| Step: 3
Training loss: 7.249852672263848
Validation loss: 7.871002297213784

Epoch: 5| Step: 4
Training loss: 7.1892453935453675
Validation loss: 7.8597000939785024

Epoch: 5| Step: 5
Training loss: 8.579144637857853
Validation loss: 7.848783389281617

Epoch: 5| Step: 6
Training loss: 8.401602328835526
Validation loss: 7.838744144742875

Epoch: 5| Step: 7
Training loss: 7.195694208116319
Validation loss: 7.8257865718272575

Epoch: 5| Step: 8
Training loss: 8.273468392146055
Validation loss: 7.814128510754525

Epoch: 5| Step: 9
Training loss: 7.661291338883285
Validation loss: 7.8022302712603375

Epoch: 5| Step: 10
Training loss: 7.956602164578237
Validation loss: 7.787221818555419

Epoch: 13| Step: 0
Training loss: 7.361161519323851
Validation loss: 7.777974450378405

Epoch: 5| Step: 1
Training loss: 8.13446057538784
Validation loss: 7.76447064842904

Epoch: 5| Step: 2
Training loss: 8.503441057987065
Validation loss: 7.7562756066630385

Epoch: 5| Step: 3
Training loss: 7.622428585529937
Validation loss: 7.745358832249732

Epoch: 5| Step: 4
Training loss: 7.7826348110425165
Validation loss: 7.730841148770352

Epoch: 5| Step: 5
Training loss: 6.435374973993994
Validation loss: 7.720776894989919

Epoch: 5| Step: 6
Training loss: 8.020759350984559
Validation loss: 7.703638078124152

Epoch: 5| Step: 7
Training loss: 8.024897456479536
Validation loss: 7.696975658707263

Epoch: 5| Step: 8
Training loss: 7.795503484237173
Validation loss: 7.677755731590237

Epoch: 5| Step: 9
Training loss: 7.339466940001767
Validation loss: 7.665949399583817

Epoch: 5| Step: 10
Training loss: 7.005220646238792
Validation loss: 7.655840489625996

Epoch: 14| Step: 0
Training loss: 6.907367046345478
Validation loss: 7.642139024355765

Epoch: 5| Step: 1
Training loss: 7.098555361495383
Validation loss: 7.624172930391292

Epoch: 5| Step: 2
Training loss: 8.116979308115729
Validation loss: 7.619493744646699

Epoch: 5| Step: 3
Training loss: 7.918662237992241
Validation loss: 7.603077893787497

Epoch: 5| Step: 4
Training loss: 8.231393813699533
Validation loss: 7.589608999873921

Epoch: 5| Step: 5
Training loss: 7.949158284475195
Validation loss: 7.57049965401443

Epoch: 5| Step: 6
Training loss: 7.727235400267831
Validation loss: 7.556070155611668

Epoch: 5| Step: 7
Training loss: 6.960629782848456
Validation loss: 7.544830874969475

Epoch: 5| Step: 8
Training loss: 7.030934780260541
Validation loss: 7.531147704895362

Epoch: 5| Step: 9
Training loss: 6.98896055294317
Validation loss: 7.514189362616028

Epoch: 5| Step: 10
Training loss: 7.666285076872814
Validation loss: 7.503082497851912

Epoch: 15| Step: 0
Training loss: 7.333333651224765
Validation loss: 7.489664206509672

Epoch: 5| Step: 1
Training loss: 7.2527160818527046
Validation loss: 7.475389890605886

Epoch: 5| Step: 2
Training loss: 8.152376036861076
Validation loss: 7.4583791333917295

Epoch: 5| Step: 3
Training loss: 7.80220806461823
Validation loss: 7.445225254660663

Epoch: 5| Step: 4
Training loss: 6.075238245935138
Validation loss: 7.428858182187239

Epoch: 5| Step: 5
Training loss: 6.782833353997831
Validation loss: 7.418315322141973

Epoch: 5| Step: 6
Training loss: 7.378614929813772
Validation loss: 7.403489952299934

Epoch: 5| Step: 7
Training loss: 7.824257997670535
Validation loss: 7.380448014505981

Epoch: 5| Step: 8
Training loss: 7.760616045615883
Validation loss: 7.368985501194569

Epoch: 5| Step: 9
Training loss: 7.044674684202954
Validation loss: 7.3515595595880585

Epoch: 5| Step: 10
Training loss: 7.360189793668919
Validation loss: 7.338999467528343

Epoch: 16| Step: 0
Training loss: 7.8768506978680195
Validation loss: 7.330624061273522

Epoch: 5| Step: 1
Training loss: 7.127680759392391
Validation loss: 7.305226352714387

Epoch: 5| Step: 2
Training loss: 7.6684746752672295
Validation loss: 7.294702203818528

Epoch: 5| Step: 3
Training loss: 7.954060018019959
Validation loss: 7.274429655607707

Epoch: 5| Step: 4
Training loss: 7.042823861949087
Validation loss: 7.2562297947704675

Epoch: 5| Step: 5
Training loss: 7.249701132040289
Validation loss: 7.244033814060458

Epoch: 5| Step: 6
Training loss: 7.2070534806567705
Validation loss: 7.22650298364859

Epoch: 5| Step: 7
Training loss: 7.173135750518132
Validation loss: 7.20733593379149

Epoch: 5| Step: 8
Training loss: 7.044773778159893
Validation loss: 7.19510836962658

Epoch: 5| Step: 9
Training loss: 6.149010753930515
Validation loss: 7.172171889490236

Epoch: 5| Step: 10
Training loss: 6.350062945196605
Validation loss: 7.152861819829034

Epoch: 17| Step: 0
Training loss: 7.444057362806385
Validation loss: 7.139927722480859

Epoch: 5| Step: 1
Training loss: 7.410976012658864
Validation loss: 7.121090714423836

Epoch: 5| Step: 2
Training loss: 6.869213929271931
Validation loss: 7.109513642136716

Epoch: 5| Step: 3
Training loss: 6.834364216276644
Validation loss: 7.086830704153152

Epoch: 5| Step: 4
Training loss: 7.15246695261857
Validation loss: 7.070816552000391

Epoch: 5| Step: 5
Training loss: 7.127089344666269
Validation loss: 7.055811653897089

Epoch: 5| Step: 6
Training loss: 6.948904749791847
Validation loss: 7.031030888396372

Epoch: 5| Step: 7
Training loss: 6.411623008796883
Validation loss: 7.013360155140783

Epoch: 5| Step: 8
Training loss: 7.115564892045477
Validation loss: 7.004331968156884

Epoch: 5| Step: 9
Training loss: 6.960594708257833
Validation loss: 6.977325985252938

Epoch: 5| Step: 10
Training loss: 6.645487936804407
Validation loss: 6.964400937954502

Epoch: 18| Step: 0
Training loss: 5.884343286267766
Validation loss: 6.939068931037969

Epoch: 5| Step: 1
Training loss: 6.53861153892274
Validation loss: 6.923016673193052

Epoch: 5| Step: 2
Training loss: 6.145993126122715
Validation loss: 6.903564055548088

Epoch: 5| Step: 3
Training loss: 7.035841057557159
Validation loss: 6.889486708135683

Epoch: 5| Step: 4
Training loss: 6.330668976493827
Validation loss: 6.863358376016686

Epoch: 5| Step: 5
Training loss: 6.391416169604055
Validation loss: 6.85746258554502

Epoch: 5| Step: 6
Training loss: 7.476773473300159
Validation loss: 6.830731873901917

Epoch: 5| Step: 7
Training loss: 7.46006774626133
Validation loss: 6.810414288797259

Epoch: 5| Step: 8
Training loss: 7.29286152087078
Validation loss: 6.789487476930393

Epoch: 5| Step: 9
Training loss: 6.897226367706283
Validation loss: 6.772384307901211

Epoch: 5| Step: 10
Training loss: 7.0860346710709186
Validation loss: 6.753290623839759

Epoch: 19| Step: 0
Training loss: 7.5299174922561765
Validation loss: 6.7308397675822755

Epoch: 5| Step: 1
Training loss: 5.460044340295969
Validation loss: 6.713342056228829

Epoch: 5| Step: 2
Training loss: 6.947505300107337
Validation loss: 6.688968871663702

Epoch: 5| Step: 3
Training loss: 6.02795098559343
Validation loss: 6.669964381830973

Epoch: 5| Step: 4
Training loss: 6.791441119920835
Validation loss: 6.645239856333978

Epoch: 5| Step: 5
Training loss: 5.840261795237784
Validation loss: 6.629967524958866

Epoch: 5| Step: 6
Training loss: 6.8435426445470755
Validation loss: 6.6027827082305794

Epoch: 5| Step: 7
Training loss: 6.546775653240107
Validation loss: 6.588717760168535

Epoch: 5| Step: 8
Training loss: 7.339016041924356
Validation loss: 6.566149706261902

Epoch: 5| Step: 9
Training loss: 6.440239480819987
Validation loss: 6.538892903165253

Epoch: 5| Step: 10
Training loss: 6.200764319776559
Validation loss: 6.525345287460214

Epoch: 20| Step: 0
Training loss: 6.341753264883162
Validation loss: 6.498450799028201

Epoch: 5| Step: 1
Training loss: 6.232431974196612
Validation loss: 6.460955330167316

Epoch: 5| Step: 2
Training loss: 6.4784034532985775
Validation loss: 6.4406740587389555

Epoch: 5| Step: 3
Training loss: 5.901470531244932
Validation loss: 6.431137574347667

Epoch: 5| Step: 4
Training loss: 6.638250092330815
Validation loss: 6.41164306167646

Epoch: 5| Step: 5
Training loss: 6.711093247974417
Validation loss: 6.379815956156541

Epoch: 5| Step: 6
Training loss: 6.027650697992686
Validation loss: 6.350828808733576

Epoch: 5| Step: 7
Training loss: 6.156318470530557
Validation loss: 6.331561364739442

Epoch: 5| Step: 8
Training loss: 6.500747050857946
Validation loss: 6.301397911337622

Epoch: 5| Step: 9
Training loss: 6.585290191443167
Validation loss: 6.291741260764665

Epoch: 5| Step: 10
Training loss: 5.8998669237549395
Validation loss: 6.2631674819064305

Epoch: 21| Step: 0
Training loss: 6.040697357644264
Validation loss: 6.240285017941767

Epoch: 5| Step: 1
Training loss: 4.856469171750409
Validation loss: 6.209542517281428

Epoch: 5| Step: 2
Training loss: 5.043263752506283
Validation loss: 6.197403197830877

Epoch: 5| Step: 3
Training loss: 6.5014916689094076
Validation loss: 6.168089237218415

Epoch: 5| Step: 4
Training loss: 6.777133799882064
Validation loss: 6.145574806689452

Epoch: 5| Step: 5
Training loss: 6.3796313049547155
Validation loss: 6.118300392890682

Epoch: 5| Step: 6
Training loss: 6.639933327949112
Validation loss: 6.0973024895196595

Epoch: 5| Step: 7
Training loss: 6.097859254007873
Validation loss: 6.070443729953295

Epoch: 5| Step: 8
Training loss: 5.488540328348976
Validation loss: 6.040992827668665

Epoch: 5| Step: 9
Training loss: 6.123787584783205
Validation loss: 6.013839890226443

Epoch: 5| Step: 10
Training loss: 6.507586526782756
Validation loss: 5.982591110665704

Epoch: 22| Step: 0
Training loss: 6.22635388952221
Validation loss: 5.963362159791168

Epoch: 5| Step: 1
Training loss: 6.032796552746178
Validation loss: 5.931104011891068

Epoch: 5| Step: 2
Training loss: 5.4653524253408134
Validation loss: 5.9173264621602915

Epoch: 5| Step: 3
Training loss: 5.910790368431367
Validation loss: 5.886816331581147

Epoch: 5| Step: 4
Training loss: 5.559741589969916
Validation loss: 5.860620758307033

Epoch: 5| Step: 5
Training loss: 6.16822293550816
Validation loss: 5.824301680773521

Epoch: 5| Step: 6
Training loss: 6.329520064686388
Validation loss: 5.793765917784899

Epoch: 5| Step: 7
Training loss: 5.689710250476293
Validation loss: 5.777423221578161

Epoch: 5| Step: 8
Training loss: 5.158173543317297
Validation loss: 5.748624880639422

Epoch: 5| Step: 9
Training loss: 5.8521381089972015
Validation loss: 5.715870882529704

Epoch: 5| Step: 10
Training loss: 5.035007187536086
Validation loss: 5.691696164225242

Epoch: 23| Step: 0
Training loss: 5.70703125
Validation loss: 5.674734417854231

Epoch: 5| Step: 1
Training loss: 4.394706159713595
Validation loss: 5.64031386356001

Epoch: 5| Step: 2
Training loss: 5.640275178242965
Validation loss: 5.593731440471347

Epoch: 5| Step: 3
Training loss: 5.775754553971681
Validation loss: 5.581910746323044

Epoch: 5| Step: 4
Training loss: 5.384401659863537
Validation loss: 5.550741560125841

Epoch: 5| Step: 5
Training loss: 5.710335967272929
Validation loss: 5.5282553298193085

Epoch: 5| Step: 6
Training loss: 5.9803995418717575
Validation loss: 5.4872987270245295

Epoch: 5| Step: 7
Training loss: 5.4606144145082745
Validation loss: 5.458262269848228

Epoch: 5| Step: 8
Training loss: 5.2708390227074755
Validation loss: 5.4329615591775475

Epoch: 5| Step: 9
Training loss: 5.343272048367117
Validation loss: 5.411580996013546

Epoch: 5| Step: 10
Training loss: 5.264366656082463
Validation loss: 5.370037259394839

Epoch: 24| Step: 0
Training loss: 3.907334078086787
Validation loss: 5.3439665988369285

Epoch: 5| Step: 1
Training loss: 5.664258145866728
Validation loss: 5.331020808827347

Epoch: 5| Step: 2
Training loss: 4.366226991450301
Validation loss: 5.277355062888065

Epoch: 5| Step: 3
Training loss: 5.1540113733571
Validation loss: 5.25706323809571

Epoch: 5| Step: 4
Training loss: 5.268773617584039
Validation loss: 5.220449623665456

Epoch: 5| Step: 5
Training loss: 5.56172191878597
Validation loss: 5.18767764650552

Epoch: 5| Step: 6
Training loss: 4.771252520717708
Validation loss: 5.156270333079411

Epoch: 5| Step: 7
Training loss: 5.816783352239838
Validation loss: 5.149096506451452

Epoch: 5| Step: 8
Training loss: 5.62961185858712
Validation loss: 5.112013660161348

Epoch: 5| Step: 9
Training loss: 4.929872826721445
Validation loss: 5.083040749803873

Epoch: 5| Step: 10
Training loss: 5.142000611443559
Validation loss: 5.038286057934504

Epoch: 25| Step: 0
Training loss: 5.116549339978801
Validation loss: 5.025085573871263

Epoch: 5| Step: 1
Training loss: 5.012092082865112
Validation loss: 4.973437919466036

Epoch: 5| Step: 2
Training loss: 3.798473508311881
Validation loss: 4.959580943959001

Epoch: 5| Step: 3
Training loss: 5.343289182547589
Validation loss: 4.909508523820894

Epoch: 5| Step: 4
Training loss: 4.967428931470383
Validation loss: 4.856097811861916

Epoch: 5| Step: 5
Training loss: 4.688028331228323
Validation loss: 4.841599183846637

Epoch: 5| Step: 6
Training loss: 4.775936590083666
Validation loss: 4.808011835957264

Epoch: 5| Step: 7
Training loss: 4.168888008544149
Validation loss: 4.766261528456472

Epoch: 5| Step: 8
Training loss: 5.415497736858085
Validation loss: 4.760233078004571

Epoch: 5| Step: 9
Training loss: 4.896603376283788
Validation loss: 4.716402189749991

Epoch: 5| Step: 10
Training loss: 4.342367048144427
Validation loss: 4.671775920806544

Epoch: 26| Step: 0
Training loss: 4.93401899641978
Validation loss: 4.645943647204616

Epoch: 5| Step: 1
Training loss: 4.924326646346876
Validation loss: 4.614978052387798

Epoch: 5| Step: 2
Training loss: 4.937251217525896
Validation loss: 4.575971129836566

Epoch: 5| Step: 3
Training loss: 4.63581964119912
Validation loss: 4.5347648026930125

Epoch: 5| Step: 4
Training loss: 3.837418963542789
Validation loss: 4.52708699721107

Epoch: 5| Step: 5
Training loss: 4.071401380864034
Validation loss: 4.470611361304699

Epoch: 5| Step: 6
Training loss: 4.570593357422646
Validation loss: 4.460260847257103

Epoch: 5| Step: 7
Training loss: 4.569000003513295
Validation loss: 4.41887208682015

Epoch: 5| Step: 8
Training loss: 4.450744420910794
Validation loss: 4.3876908824902285

Epoch: 5| Step: 9
Training loss: 4.134006493624684
Validation loss: 4.347624516721193

Epoch: 5| Step: 10
Training loss: 3.643298824899578
Validation loss: 4.326436974476548

Epoch: 27| Step: 0
Training loss: 3.7882694633616776
Validation loss: 4.299417746677787

Epoch: 5| Step: 1
Training loss: 4.119228834181769
Validation loss: 4.2630716012466054

Epoch: 5| Step: 2
Training loss: 3.7470471518374655
Validation loss: 4.226578873301299

Epoch: 5| Step: 3
Training loss: 3.9309670884747163
Validation loss: 4.205728870014544

Epoch: 5| Step: 4
Training loss: 4.685431469048231
Validation loss: 4.164536032698199

Epoch: 5| Step: 5
Training loss: 4.608327972979242
Validation loss: 4.153123206036041

Epoch: 5| Step: 6
Training loss: 4.258714604836678
Validation loss: 4.1102285101955385

Epoch: 5| Step: 7
Training loss: 4.203934035025955
Validation loss: 4.073711683478902

Epoch: 5| Step: 8
Training loss: 3.2989191886298688
Validation loss: 4.050762718094135

Epoch: 5| Step: 9
Training loss: 4.0011092078558015
Validation loss: 4.021425259198823

Epoch: 5| Step: 10
Training loss: 4.254121016588421
Validation loss: 3.9906040889504877

Epoch: 28| Step: 0
Training loss: 3.549565979121492
Validation loss: 3.951221954012282

Epoch: 5| Step: 1
Training loss: 4.364755461704414
Validation loss: 3.930239651991708

Epoch: 5| Step: 2
Training loss: 3.4330214022317356
Validation loss: 3.893397557456119

Epoch: 5| Step: 3
Training loss: 3.32467572918377
Validation loss: 3.843289743675447

Epoch: 5| Step: 4
Training loss: 4.1728109959925535
Validation loss: 3.8234059743593445

Epoch: 5| Step: 5
Training loss: 4.136594026610687
Validation loss: 3.788822663014024

Epoch: 5| Step: 6
Training loss: 3.2797763966893037
Validation loss: 3.766320967394122

Epoch: 5| Step: 7
Training loss: 3.071414351826446
Validation loss: 3.7573521177516525

Epoch: 5| Step: 8
Training loss: 3.8717073787585496
Validation loss: 3.7177886823372446

Epoch: 5| Step: 9
Training loss: 3.640680533710031
Validation loss: 3.7009663844426632

Epoch: 5| Step: 10
Training loss: 4.51264195100051
Validation loss: 3.6543021449753814

Epoch: 29| Step: 0
Training loss: 3.1577483293826236
Validation loss: 3.6362721902455624

Epoch: 5| Step: 1
Training loss: 3.1396663588135487
Validation loss: 3.6201528845101585

Epoch: 5| Step: 2
Training loss: 4.258272982553527
Validation loss: 3.5930932870336605

Epoch: 5| Step: 3
Training loss: 3.2639418649545116
Validation loss: 3.5619739690298164

Epoch: 5| Step: 4
Training loss: 2.8421022441171298
Validation loss: 3.5412695549272306

Epoch: 5| Step: 5
Training loss: 3.2783843106093156
Validation loss: 3.532340227470307

Epoch: 5| Step: 6
Training loss: 3.574142438563771
Validation loss: 3.499849837754517

Epoch: 5| Step: 7
Training loss: 3.6389439184737205
Validation loss: 3.46402716585172

Epoch: 5| Step: 8
Training loss: 4.3889208978915555
Validation loss: 3.4716476344567644

Epoch: 5| Step: 9
Training loss: 2.991983989438145
Validation loss: 3.4352093504635954

Epoch: 5| Step: 10
Training loss: 3.6677580134067824
Validation loss: 3.410872454739395

Epoch: 30| Step: 0
Training loss: 3.1377694732326784
Validation loss: 3.400842351578379

Epoch: 5| Step: 1
Training loss: 2.92201420253511
Validation loss: 3.383640655808365

Epoch: 5| Step: 2
Training loss: 2.7075840329191267
Validation loss: 3.345925969516244

Epoch: 5| Step: 3
Training loss: 3.387973011958735
Validation loss: 3.3168775377554254

Epoch: 5| Step: 4
Training loss: 4.013006997089764
Validation loss: 3.315438998907598

Epoch: 5| Step: 5
Training loss: 3.0312863377231603
Validation loss: 3.295272200374989

Epoch: 5| Step: 6
Training loss: 3.8741594448885226
Validation loss: 3.2846630333367735

Epoch: 5| Step: 7
Training loss: 2.9832149467918345
Validation loss: 3.267288152676611

Epoch: 5| Step: 8
Training loss: 3.1791717335938507
Validation loss: 3.2363547916541413

Epoch: 5| Step: 9
Training loss: 3.5028647551568306
Validation loss: 3.226927816260058

Epoch: 5| Step: 10
Training loss: 3.3020804291881865
Validation loss: 3.219871966611992

Epoch: 31| Step: 0
Training loss: 3.681762369505644
Validation loss: 3.19648931812691

Epoch: 5| Step: 1
Training loss: 3.4193066577918296
Validation loss: 3.185425797890161

Epoch: 5| Step: 2
Training loss: 2.6495538119991906
Validation loss: 3.1647665419662774

Epoch: 5| Step: 3
Training loss: 3.257518874001736
Validation loss: 3.1654270160377163

Epoch: 5| Step: 4
Training loss: 3.819920681634247
Validation loss: 3.162282866443216

Epoch: 5| Step: 5
Training loss: 3.100497045969867
Validation loss: 3.1482884221035334

Epoch: 5| Step: 6
Training loss: 2.856979784398965
Validation loss: 3.1538561313273314

Epoch: 5| Step: 7
Training loss: 2.3411160736964796
Validation loss: 3.1186623178928286

Epoch: 5| Step: 8
Training loss: 2.800480484608245
Validation loss: 3.0773717844540265

Epoch: 5| Step: 9
Training loss: 3.2241166198690183
Validation loss: 3.1172019992494966

Epoch: 5| Step: 10
Training loss: 3.4044776995417734
Validation loss: 3.0898792575994514

Epoch: 32| Step: 0
Training loss: 2.7511483309105444
Validation loss: 3.089008319217398

Epoch: 5| Step: 1
Training loss: 3.5218472497450977
Validation loss: 3.0824448974811185

Epoch: 5| Step: 2
Training loss: 2.681726241776692
Validation loss: 3.0771052164836536

Epoch: 5| Step: 3
Training loss: 3.403093327706797
Validation loss: 3.0651249237128586

Epoch: 5| Step: 4
Training loss: 3.7213061867733717
Validation loss: 3.0550853196502987

Epoch: 5| Step: 5
Training loss: 2.080160764386873
Validation loss: 3.073289126513629

Epoch: 5| Step: 6
Training loss: 2.910813225444541
Validation loss: 3.057458149830635

Epoch: 5| Step: 7
Training loss: 2.968960885036622
Validation loss: 3.071914659376242

Epoch: 5| Step: 8
Training loss: 2.486349796461425
Validation loss: 3.0578876391118834

Epoch: 5| Step: 9
Training loss: 4.259659728667105
Validation loss: 3.043443207916942

Epoch: 5| Step: 10
Training loss: 2.2931876134966758
Validation loss: 3.049359649123276

Epoch: 33| Step: 0
Training loss: 2.57677651020276
Validation loss: 3.0451685381887907

Epoch: 5| Step: 1
Training loss: 2.412417941106143
Validation loss: 3.0354921633841525

Epoch: 5| Step: 2
Training loss: 3.4076072018861256
Validation loss: 3.0312069263026022

Epoch: 5| Step: 3
Training loss: 2.104900559457348
Validation loss: 3.0406369095518384

Epoch: 5| Step: 4
Training loss: 2.40912644505669
Validation loss: 3.0227014170725077

Epoch: 5| Step: 5
Training loss: 3.177955249315256
Validation loss: 3.053100714277995

Epoch: 5| Step: 6
Training loss: 3.3075221824911316
Validation loss: 3.015484886903624

Epoch: 5| Step: 7
Training loss: 4.0530576866519095
Validation loss: 3.012973807829212

Epoch: 5| Step: 8
Training loss: 2.8993117666780766
Validation loss: 3.0264547426599377

Epoch: 5| Step: 9
Training loss: 3.5233649607970867
Validation loss: 3.042794306123941

Epoch: 5| Step: 10
Training loss: 3.0693910880843007
Validation loss: 3.000226714683931

Epoch: 34| Step: 0
Training loss: 3.1609561695220716
Validation loss: 3.019491164131572

Epoch: 5| Step: 1
Training loss: 2.3701236254805433
Validation loss: 2.9968275725702234

Epoch: 5| Step: 2
Training loss: 3.8125672881645283
Validation loss: 3.009548448820651

Epoch: 5| Step: 3
Training loss: 2.8501578437863877
Validation loss: 3.016173866901243

Epoch: 5| Step: 4
Training loss: 2.019560409719065
Validation loss: 2.9994005788806244

Epoch: 5| Step: 5
Training loss: 2.829783253811112
Validation loss: 3.012634407135566

Epoch: 5| Step: 6
Training loss: 3.1239648248838874
Validation loss: 2.9983358125501343

Epoch: 5| Step: 7
Training loss: 2.628043907629023
Validation loss: 3.0195821669626657

Epoch: 5| Step: 8
Training loss: 3.8151846016833675
Validation loss: 3.0197089980187335

Epoch: 5| Step: 9
Training loss: 3.809890354210787
Validation loss: 3.0112124688211677

Epoch: 5| Step: 10
Training loss: 2.203402454409687
Validation loss: 3.026144577941422

Epoch: 35| Step: 0
Training loss: 2.2312989301685877
Validation loss: 2.975572037086605

Epoch: 5| Step: 1
Training loss: 3.6091654663036965
Validation loss: 3.003800428944924

Epoch: 5| Step: 2
Training loss: 3.4007033237719337
Validation loss: 3.0087156506256756

Epoch: 5| Step: 3
Training loss: 2.854528102590087
Validation loss: 2.9887176548894674

Epoch: 5| Step: 4
Training loss: 3.2340642070258925
Validation loss: 2.992967131591364

Epoch: 5| Step: 5
Training loss: 1.927590099064528
Validation loss: 3.0137640215820505

Epoch: 5| Step: 6
Training loss: 3.6142256208881154
Validation loss: 3.018584441522263

Epoch: 5| Step: 7
Training loss: 2.886913329136552
Validation loss: 3.004754201256734

Epoch: 5| Step: 8
Training loss: 2.803436765482518
Validation loss: 2.9995263505110765

Epoch: 5| Step: 9
Training loss: 3.3621200346841444
Validation loss: 2.9882900430130523

Epoch: 5| Step: 10
Training loss: 2.946866624644282
Validation loss: 3.0281100394854494

Epoch: 36| Step: 0
Training loss: 3.102715957588861
Validation loss: 2.9884894271509532

Epoch: 5| Step: 1
Training loss: 3.2194304996861742
Validation loss: 3.0212324713984997

Epoch: 5| Step: 2
Training loss: 3.2663785074256126
Validation loss: 2.9913004344208476

Epoch: 5| Step: 3
Training loss: 3.147164743034563
Validation loss: 3.0156243003518384

Epoch: 5| Step: 4
Training loss: 2.952301717975309
Validation loss: 2.992048087821919

Epoch: 5| Step: 5
Training loss: 3.187219046384134
Validation loss: 2.979462440609956

Epoch: 5| Step: 6
Training loss: 3.5661178422114115
Validation loss: 3.0125827796144677

Epoch: 5| Step: 7
Training loss: 2.8078894229428997
Validation loss: 3.0058503634448406

Epoch: 5| Step: 8
Training loss: 2.382997099182694
Validation loss: 3.000867263651284

Epoch: 5| Step: 9
Training loss: 2.6030987393633382
Validation loss: 3.0336494451019274

Epoch: 5| Step: 10
Training loss: 2.844488194827874
Validation loss: 2.987056191581848

Epoch: 37| Step: 0
Training loss: 2.9341040928011703
Validation loss: 3.0061714382283364

Epoch: 5| Step: 1
Training loss: 2.2260657040683562
Validation loss: 2.984775635939971

Epoch: 5| Step: 2
Training loss: 1.9309489339578554
Validation loss: 3.0139010597856424

Epoch: 5| Step: 3
Training loss: 2.90649823184889
Validation loss: 3.0115381289388248

Epoch: 5| Step: 4
Training loss: 2.6702457390615417
Validation loss: 2.999836105395453

Epoch: 5| Step: 5
Training loss: 3.686630663796567
Validation loss: 2.990711683670485

Epoch: 5| Step: 6
Training loss: 3.3684232705510517
Validation loss: 3.0101515906638405

Epoch: 5| Step: 7
Training loss: 3.8756559493562843
Validation loss: 2.994139595824367

Epoch: 5| Step: 8
Training loss: 3.760128964789392
Validation loss: 2.9996612590022433

Epoch: 5| Step: 9
Training loss: 2.8683790178962782
Validation loss: 3.0004702766873055

Epoch: 5| Step: 10
Training loss: 2.4753033538791938
Validation loss: 3.0043892881624275

Epoch: 38| Step: 0
Training loss: 3.4535897749116096
Validation loss: 2.9924840453261745

Epoch: 5| Step: 1
Training loss: 3.4665296166790482
Validation loss: 2.9972279262144097

Epoch: 5| Step: 2
Training loss: 2.50024660801512
Validation loss: 3.0057603555796644

Epoch: 5| Step: 3
Training loss: 3.227212835725706
Validation loss: 2.9949273305646127

Epoch: 5| Step: 4
Training loss: 2.957248614245187
Validation loss: 2.992956195078533

Epoch: 5| Step: 5
Training loss: 2.4496502412536114
Validation loss: 2.996162467348514

Epoch: 5| Step: 6
Training loss: 3.219929895526375
Validation loss: 2.9723851157332635

Epoch: 5| Step: 7
Training loss: 2.6686044943672673
Validation loss: 2.993345175626793

Epoch: 5| Step: 8
Training loss: 3.078710200261204
Validation loss: 2.9870569451251527

Epoch: 5| Step: 9
Training loss: 2.9015446791258235
Validation loss: 3.0300111200014945

Epoch: 5| Step: 10
Training loss: 3.1515154689897584
Validation loss: 2.9739798196352227

Epoch: 39| Step: 0
Training loss: 2.257739108783674
Validation loss: 2.9953162109061697

Epoch: 5| Step: 1
Training loss: 1.8824648081009119
Validation loss: 3.0149563955623986

Epoch: 5| Step: 2
Training loss: 2.898519262924003
Validation loss: 3.002007687690395

Epoch: 5| Step: 3
Training loss: 3.711142700946644
Validation loss: 3.005273772440505

Epoch: 5| Step: 4
Training loss: 3.32558835209249
Validation loss: 2.962425366128704

Epoch: 5| Step: 5
Training loss: 2.508451006168528
Validation loss: 2.9832096290984484

Epoch: 5| Step: 6
Training loss: 3.675949757652922
Validation loss: 2.997969349451384

Epoch: 5| Step: 7
Training loss: 3.3422166392378925
Validation loss: 2.9783297594574183

Epoch: 5| Step: 8
Training loss: 3.0997173672704434
Validation loss: 2.985650033562047

Epoch: 5| Step: 9
Training loss: 3.3592715225251353
Validation loss: 2.985944765772104

Epoch: 5| Step: 10
Training loss: 2.191073740927857
Validation loss: 2.953649228343452

Epoch: 40| Step: 0
Training loss: 3.259509918258658
Validation loss: 2.9947372869589852

Epoch: 5| Step: 1
Training loss: 2.7819085359491016
Validation loss: 3.0055399335867508

Epoch: 5| Step: 2
Training loss: 2.7634377316340335
Validation loss: 2.964763601741807

Epoch: 5| Step: 3
Training loss: 2.919865371004293
Validation loss: 2.989593079368024

Epoch: 5| Step: 4
Training loss: 2.6148706914028406
Validation loss: 2.987281688227846

Epoch: 5| Step: 5
Training loss: 3.080262347356153
Validation loss: 3.0079717024248254

Epoch: 5| Step: 6
Training loss: 2.909288028519305
Validation loss: 2.9778618382121302

Epoch: 5| Step: 7
Training loss: 3.1966054674110516
Validation loss: 2.978452646123242

Epoch: 5| Step: 8
Training loss: 3.5218867845854303
Validation loss: 2.9788165435671

Epoch: 5| Step: 9
Training loss: 2.78008460156264
Validation loss: 2.985707617785139

Epoch: 5| Step: 10
Training loss: 3.1503506662065988
Validation loss: 2.976452634518917

Epoch: 41| Step: 0
Training loss: 2.3292523413262836
Validation loss: 2.9739423868891004

Epoch: 5| Step: 1
Training loss: 3.0859736573237773
Validation loss: 2.984066389358857

Epoch: 5| Step: 2
Training loss: 2.5003928829469575
Validation loss: 2.9642007250885856

Epoch: 5| Step: 3
Training loss: 3.026566653034628
Validation loss: 2.985274348758082

Epoch: 5| Step: 4
Training loss: 2.3126732013896345
Validation loss: 2.9838293206241557

Epoch: 5| Step: 5
Training loss: 3.066680701541574
Validation loss: 2.9737112578651734

Epoch: 5| Step: 6
Training loss: 3.018207136352992
Validation loss: 2.9925713907734157

Epoch: 5| Step: 7
Training loss: 3.123340929226373
Validation loss: 2.99779504667853

Epoch: 5| Step: 8
Training loss: 3.4045352644408444
Validation loss: 2.97487671385449

Epoch: 5| Step: 9
Training loss: 4.106054320528393
Validation loss: 3.0049070557477324

Epoch: 5| Step: 10
Training loss: 2.5410658225189247
Validation loss: 3.000720356351312

Epoch: 42| Step: 0
Training loss: 2.756640133743491
Validation loss: 2.996571432601991

Epoch: 5| Step: 1
Training loss: 3.7490460771978564
Validation loss: 3.0033850099283477

Epoch: 5| Step: 2
Training loss: 2.9736228704677807
Validation loss: 2.980401522748951

Epoch: 5| Step: 3
Training loss: 3.3356301659695395
Validation loss: 2.9620313990406313

Epoch: 5| Step: 4
Training loss: 2.5726900090963256
Validation loss: 2.9862420151573192

Epoch: 5| Step: 5
Training loss: 2.9398240980089074
Validation loss: 2.9836966296535645

Epoch: 5| Step: 6
Training loss: 3.635724875311321
Validation loss: 2.9876540469833452

Epoch: 5| Step: 7
Training loss: 2.734056726733657
Validation loss: 2.9700400416022603

Epoch: 5| Step: 8
Training loss: 3.186660955362775
Validation loss: 2.971220093136473

Epoch: 5| Step: 9
Training loss: 2.787407734117975
Validation loss: 2.993186381055624

Epoch: 5| Step: 10
Training loss: 1.7755977564342715
Validation loss: 2.9994888656416636

Epoch: 43| Step: 0
Training loss: 3.1700145357683174
Validation loss: 3.000441247012768

Epoch: 5| Step: 1
Training loss: 2.4416629747833705
Validation loss: 2.9945356790174635

Epoch: 5| Step: 2
Training loss: 3.658346895324548
Validation loss: 2.97928587450347

Epoch: 5| Step: 3
Training loss: 2.643481633699216
Validation loss: 2.967594020544971

Epoch: 5| Step: 4
Training loss: 2.708747968967805
Validation loss: 2.9757589592145073

Epoch: 5| Step: 5
Training loss: 3.0235327575029447
Validation loss: 2.9597964914030697

Epoch: 5| Step: 6
Training loss: 3.0219235437038607
Validation loss: 2.9821397463508266

Epoch: 5| Step: 7
Training loss: 3.367269634475351
Validation loss: 2.978528851513853

Epoch: 5| Step: 8
Training loss: 3.262328313643643
Validation loss: 2.9752509258362396

Epoch: 5| Step: 9
Training loss: 2.441703302240941
Validation loss: 2.9825613185331137

Epoch: 5| Step: 10
Training loss: 3.0502744832584776
Validation loss: 2.9651469829031223

Epoch: 44| Step: 0
Training loss: 2.979292611258749
Validation loss: 2.9894258888521494

Epoch: 5| Step: 1
Training loss: 2.7248746790635274
Validation loss: 2.951391373274785

Epoch: 5| Step: 2
Training loss: 2.416141639328118
Validation loss: 2.982884721361827

Epoch: 5| Step: 3
Training loss: 3.0690278527669914
Validation loss: 2.964283458881192

Epoch: 5| Step: 4
Training loss: 3.604186982261129
Validation loss: 2.9900711145853127

Epoch: 5| Step: 5
Training loss: 2.9222336819242334
Validation loss: 2.979826142469441

Epoch: 5| Step: 6
Training loss: 3.1894462477918815
Validation loss: 2.950805852454924

Epoch: 5| Step: 7
Training loss: 3.300880060466297
Validation loss: 2.9831690345391126

Epoch: 5| Step: 8
Training loss: 2.8601516752771734
Validation loss: 2.96864900012398

Epoch: 5| Step: 9
Training loss: 3.42093216958105
Validation loss: 2.979745287344283

Epoch: 5| Step: 10
Training loss: 2.41549709124539
Validation loss: 2.9903563185120707

Epoch: 45| Step: 0
Training loss: 2.2131185927644386
Validation loss: 2.9673537497970237

Epoch: 5| Step: 1
Training loss: 3.2005336793290478
Validation loss: 2.9777936731082715

Epoch: 5| Step: 2
Training loss: 3.0201423293167915
Validation loss: 2.955984075100818

Epoch: 5| Step: 3
Training loss: 3.256825688702015
Validation loss: 2.9625208019258187

Epoch: 5| Step: 4
Training loss: 3.0583450781434713
Validation loss: 2.986576405095551

Epoch: 5| Step: 5
Training loss: 2.8953082113959905
Validation loss: 2.9588645644116363

Epoch: 5| Step: 6
Training loss: 2.681729797969972
Validation loss: 2.9601780866198566

Epoch: 5| Step: 7
Training loss: 2.6771633170878992
Validation loss: 2.960087539604231

Epoch: 5| Step: 8
Training loss: 2.762863590944723
Validation loss: 2.961648313120947

Epoch: 5| Step: 9
Training loss: 3.5467096365809
Validation loss: 2.992162073289141

Epoch: 5| Step: 10
Training loss: 3.606329884297192
Validation loss: 2.949324062558516

Epoch: 46| Step: 0
Training loss: 2.449879242392802
Validation loss: 2.9534652243995074

Epoch: 5| Step: 1
Training loss: 4.015813800811498
Validation loss: 2.9559052720306838

Epoch: 5| Step: 2
Training loss: 3.0624514206127875
Validation loss: 2.970692746852188

Epoch: 5| Step: 3
Training loss: 2.926906394814557
Validation loss: 2.943773585869632

Epoch: 5| Step: 4
Training loss: 2.6699318763528845
Validation loss: 2.97815827602234

Epoch: 5| Step: 5
Training loss: 3.3004465147856052
Validation loss: 2.9512882539955356

Epoch: 5| Step: 6
Training loss: 2.6458909836943802
Validation loss: 2.969090034773568

Epoch: 5| Step: 7
Training loss: 2.4909324236095323
Validation loss: 2.981766355068471

Epoch: 5| Step: 8
Training loss: 3.5405919557462036
Validation loss: 2.9450130894182363

Epoch: 5| Step: 9
Training loss: 2.6825638617515684
Validation loss: 2.958957343443546

Epoch: 5| Step: 10
Training loss: 2.4925287186509126
Validation loss: 2.9678983009595004

Epoch: 47| Step: 0
Training loss: 2.5430555665744032
Validation loss: 2.9566015807352564

Epoch: 5| Step: 1
Training loss: 2.7366373348948665
Validation loss: 2.9500833727257216

Epoch: 5| Step: 2
Training loss: 2.5986223532413524
Validation loss: 2.956492377362564

Epoch: 5| Step: 3
Training loss: 2.6302447829537874
Validation loss: 2.9483603776903298

Epoch: 5| Step: 4
Training loss: 2.939639833927015
Validation loss: 2.9429247556672693

Epoch: 5| Step: 5
Training loss: 3.1024691315989616
Validation loss: 2.9582351386345387

Epoch: 5| Step: 6
Training loss: 2.8885545068385072
Validation loss: 2.944681986576475

Epoch: 5| Step: 7
Training loss: 2.8028944654300454
Validation loss: 2.948377149698237

Epoch: 5| Step: 8
Training loss: 4.1444148156064635
Validation loss: 2.94781253296975

Epoch: 5| Step: 9
Training loss: 3.2238240663407445
Validation loss: 2.9596171201245745

Epoch: 5| Step: 10
Training loss: 3.1507910930953678
Validation loss: 2.986356730438031

Epoch: 48| Step: 0
Training loss: 2.862676829910656
Validation loss: 2.9713021759212483

Epoch: 5| Step: 1
Training loss: 3.0349461938151436
Validation loss: 2.9628070095367307

Epoch: 5| Step: 2
Training loss: 3.0708406493998264
Validation loss: 2.967081078598031

Epoch: 5| Step: 3
Training loss: 2.7725806403579316
Validation loss: 2.968131140219614

Epoch: 5| Step: 4
Training loss: 2.4315341420585854
Validation loss: 2.980089108635918

Epoch: 5| Step: 5
Training loss: 3.005223019110609
Validation loss: 2.9544096300796063

Epoch: 5| Step: 6
Training loss: 3.19872864263276
Validation loss: 2.963318315680148

Epoch: 5| Step: 7
Training loss: 2.7369951174507454
Validation loss: 2.9629492520185443

Epoch: 5| Step: 8
Training loss: 3.3749016641490135
Validation loss: 2.9500095101876362

Epoch: 5| Step: 9
Training loss: 2.344207312155493
Validation loss: 2.96549877638663

Epoch: 5| Step: 10
Training loss: 3.6457085869655326
Validation loss: 2.944754089670328

Epoch: 49| Step: 0
Training loss: 3.1070210349970377
Validation loss: 2.950845191157642

Epoch: 5| Step: 1
Training loss: 3.5315074995561577
Validation loss: 2.9635417335646204

Epoch: 5| Step: 2
Training loss: 2.3326715711680346
Validation loss: 2.9898385948707493

Epoch: 5| Step: 3
Training loss: 3.6413277533074164
Validation loss: 2.9471214999262267

Epoch: 5| Step: 4
Training loss: 3.2125489583719222
Validation loss: 2.9614482554596306

Epoch: 5| Step: 5
Training loss: 3.2163846111334133
Validation loss: 2.9527943978372

Epoch: 5| Step: 6
Training loss: 2.7831925883846607
Validation loss: 2.9552892226966687

Epoch: 5| Step: 7
Training loss: 2.17671049536392
Validation loss: 2.9580464015247068

Epoch: 5| Step: 8
Training loss: 3.3445529152004285
Validation loss: 2.9803461490357868

Epoch: 5| Step: 9
Training loss: 2.276064898083551
Validation loss: 2.961035159488062

Epoch: 5| Step: 10
Training loss: 2.774192427926864
Validation loss: 2.958870748962275

Epoch: 50| Step: 0
Training loss: 2.3678280810311336
Validation loss: 2.9676061761542805

Epoch: 5| Step: 1
Training loss: 3.4268964042043826
Validation loss: 2.9499133832704154

Epoch: 5| Step: 2
Training loss: 2.9749732392974786
Validation loss: 2.955738785810143

Epoch: 5| Step: 3
Training loss: 2.891125939754947
Validation loss: 2.9513635590294944

Epoch: 5| Step: 4
Training loss: 3.11129701339004
Validation loss: 2.961725855430068

Epoch: 5| Step: 5
Training loss: 2.5414586425033905
Validation loss: 2.986235487238751

Epoch: 5| Step: 6
Training loss: 3.088400946376395
Validation loss: 2.957528868199841

Epoch: 5| Step: 7
Training loss: 2.433853943754894
Validation loss: 2.9546977261639475

Epoch: 5| Step: 8
Training loss: 3.541004313447184
Validation loss: 2.9723020709683516

Epoch: 5| Step: 9
Training loss: 3.0993121460750923
Validation loss: 2.9636955285447875

Epoch: 5| Step: 10
Training loss: 2.7781247356745076
Validation loss: 2.939013529113413

Epoch: 51| Step: 0
Training loss: 2.6546534508581026
Validation loss: 2.9604711158522297

Epoch: 5| Step: 1
Training loss: 2.885060330822874
Validation loss: 2.948124900416696

Epoch: 5| Step: 2
Training loss: 3.0808403315390267
Validation loss: 2.947785545942651

Epoch: 5| Step: 3
Training loss: 2.721300879630554
Validation loss: 2.960415607489238

Epoch: 5| Step: 4
Training loss: 3.5552503203133097
Validation loss: 2.931852148895084

Epoch: 5| Step: 5
Training loss: 3.539494704913864
Validation loss: 2.966479556617078

Epoch: 5| Step: 6
Training loss: 2.8883777027570647
Validation loss: 2.9711665285265663

Epoch: 5| Step: 7
Training loss: 2.2589631102219236
Validation loss: 2.958638922578561

Epoch: 5| Step: 8
Training loss: 3.5982327574019486
Validation loss: 2.954839626756463

Epoch: 5| Step: 9
Training loss: 2.3622036581525125
Validation loss: 2.945654161119255

Epoch: 5| Step: 10
Training loss: 2.76122904405633
Validation loss: 2.960598411389837

Epoch: 52| Step: 0
Training loss: 2.8515253770057893
Validation loss: 2.9434582726673995

Epoch: 5| Step: 1
Training loss: 3.20538295154071
Validation loss: 2.9329720663638805

Epoch: 5| Step: 2
Training loss: 3.0902429604920396
Validation loss: 2.938884148056708

Epoch: 5| Step: 3
Training loss: 3.073187881828744
Validation loss: 2.9498517326455285

Epoch: 5| Step: 4
Training loss: 3.4635270120793513
Validation loss: 2.9495223289711077

Epoch: 5| Step: 5
Training loss: 3.334522384918485
Validation loss: 2.9330503174153417

Epoch: 5| Step: 6
Training loss: 2.532090224226911
Validation loss: 2.9070806040800994

Epoch: 5| Step: 7
Training loss: 3.081073413918923
Validation loss: 2.9237690046366587

Epoch: 5| Step: 8
Training loss: 2.114400232465012
Validation loss: 2.9438372343711543

Epoch: 5| Step: 9
Training loss: 3.025951355698843
Validation loss: 2.956041209525417

Epoch: 5| Step: 10
Training loss: 2.23169552925634
Validation loss: 2.9280087552460574

Epoch: 53| Step: 0
Training loss: 3.7276282236110823
Validation loss: 2.9615893798851753

Epoch: 5| Step: 1
Training loss: 2.641791994348959
Validation loss: 2.9523949724257386

Epoch: 5| Step: 2
Training loss: 2.6831186643072926
Validation loss: 2.930956200009364

Epoch: 5| Step: 3
Training loss: 3.1641170544100907
Validation loss: 2.953666706342614

Epoch: 5| Step: 4
Training loss: 3.231935917492838
Validation loss: 2.9215871965181845

Epoch: 5| Step: 5
Training loss: 2.4220764076409074
Validation loss: 2.947976981864627

Epoch: 5| Step: 6
Training loss: 2.5951492028534315
Validation loss: 2.9338758266461755

Epoch: 5| Step: 7
Training loss: 3.1480658148510474
Validation loss: 2.93110631876642

Epoch: 5| Step: 8
Training loss: 2.777301428535453
Validation loss: 2.9313409120345852

Epoch: 5| Step: 9
Training loss: 2.6979329073109053
Validation loss: 2.9297909087932763

Epoch: 5| Step: 10
Training loss: 2.963969024969972
Validation loss: 2.9385537443921796

Epoch: 54| Step: 0
Training loss: 2.1701861065284227
Validation loss: 2.9447564794083076

Epoch: 5| Step: 1
Training loss: 2.284748060498394
Validation loss: 2.9522174309374085

Epoch: 5| Step: 2
Training loss: 3.375180133674856
Validation loss: 2.9270211373275004

Epoch: 5| Step: 3
Training loss: 2.679249185465014
Validation loss: 2.9300622782657166

Epoch: 5| Step: 4
Training loss: 2.318766480256198
Validation loss: 2.921674665262702

Epoch: 5| Step: 5
Training loss: 3.0174682992251323
Validation loss: 2.931695049946726

Epoch: 5| Step: 6
Training loss: 3.165020380903675
Validation loss: 2.941981527378006

Epoch: 5| Step: 7
Training loss: 3.766840821575216
Validation loss: 2.954319452087548

Epoch: 5| Step: 8
Training loss: 3.0197182186616662
Validation loss: 2.9247913503889733

Epoch: 5| Step: 9
Training loss: 2.7987888543727415
Validation loss: 2.936546579395387

Epoch: 5| Step: 10
Training loss: 3.4566611571407524
Validation loss: 2.949586064625806

Epoch: 55| Step: 0
Training loss: 2.3043259159216887
Validation loss: 2.9385942486325245

Epoch: 5| Step: 1
Training loss: 3.1951362542603055
Validation loss: 2.922168288142646

Epoch: 5| Step: 2
Training loss: 2.5456180396149932
Validation loss: 2.9673511156170687

Epoch: 5| Step: 3
Training loss: 3.476251138181476
Validation loss: 2.892017393435368

Epoch: 5| Step: 4
Training loss: 1.960331735855608
Validation loss: 2.934776516788937

Epoch: 5| Step: 5
Training loss: 1.9221750660932768
Validation loss: 2.9446082458188427

Epoch: 5| Step: 6
Training loss: 3.1831692465256016
Validation loss: 2.9456884930200546

Epoch: 5| Step: 7
Training loss: 3.1440307977153186
Validation loss: 2.908384880911107

Epoch: 5| Step: 8
Training loss: 4.020292308295582
Validation loss: 2.9440558522734945

Epoch: 5| Step: 9
Training loss: 2.4125181523564168
Validation loss: 2.9201291909423674

Epoch: 5| Step: 10
Training loss: 3.3308688749113236
Validation loss: 2.895654081573411

Epoch: 56| Step: 0
Training loss: 2.515175441591231
Validation loss: 2.914097778560716

Epoch: 5| Step: 1
Training loss: 2.7910099870372553
Validation loss: 2.911424036590977

Epoch: 5| Step: 2
Training loss: 2.5688142903025795
Validation loss: 2.939248213464779

Epoch: 5| Step: 3
Training loss: 3.417263599136222
Validation loss: 2.9184149373414496

Epoch: 5| Step: 4
Training loss: 3.3023565201414287
Validation loss: 2.9415318962942107

Epoch: 5| Step: 5
Training loss: 3.2504503965068237
Validation loss: 2.8999100609999267

Epoch: 5| Step: 6
Training loss: 3.001392518154643
Validation loss: 2.922499056522549

Epoch: 5| Step: 7
Training loss: 2.9893843067302663
Validation loss: 2.9304081066267487

Epoch: 5| Step: 8
Training loss: 2.9044881422917497
Validation loss: 2.939008913007784

Epoch: 5| Step: 9
Training loss: 2.448431591228861
Validation loss: 2.946232150535378

Epoch: 5| Step: 10
Training loss: 2.9063615674989847
Validation loss: 2.9086010267056

Epoch: 57| Step: 0
Training loss: 2.523534436327463
Validation loss: 2.9344469619550613

Epoch: 5| Step: 1
Training loss: 3.267382865037883
Validation loss: 2.9240164664089767

Epoch: 5| Step: 2
Training loss: 2.7360112117682616
Validation loss: 2.936859795933347

Epoch: 5| Step: 3
Training loss: 2.340809006836747
Validation loss: 2.9329456551630693

Epoch: 5| Step: 4
Training loss: 2.3638908167571073
Validation loss: 2.904831211719508

Epoch: 5| Step: 5
Training loss: 3.0500881369941784
Validation loss: 2.9239862165154658

Epoch: 5| Step: 6
Training loss: 2.4331091433502503
Validation loss: 2.903116039339695

Epoch: 5| Step: 7
Training loss: 4.068541275038199
Validation loss: 2.947036563665967

Epoch: 5| Step: 8
Training loss: 3.6303223309708472
Validation loss: 2.9319311595118274

Epoch: 5| Step: 9
Training loss: 2.656102613960204
Validation loss: 2.9126659102586405

Epoch: 5| Step: 10
Training loss: 2.5729202908839186
Validation loss: 2.90770023755182

Epoch: 58| Step: 0
Training loss: 2.9115057562080513
Validation loss: 2.8985091693847784

Epoch: 5| Step: 1
Training loss: 2.6770903788868456
Validation loss: 2.9247802816625836

Epoch: 5| Step: 2
Training loss: 2.8597593622408715
Validation loss: 2.9066341436043053

Epoch: 5| Step: 3
Training loss: 3.0114277304474713
Validation loss: 2.9232320634230233

Epoch: 5| Step: 4
Training loss: 2.9792580401584274
Validation loss: 2.91332187713083

Epoch: 5| Step: 5
Training loss: 2.657452479428357
Validation loss: 2.9052441219464984

Epoch: 5| Step: 6
Training loss: 3.115160136997484
Validation loss: 2.9143847303550525

Epoch: 5| Step: 7
Training loss: 3.117335265823344
Validation loss: 2.8994018075638186

Epoch: 5| Step: 8
Training loss: 3.3870767758331346
Validation loss: 2.9401174267579986

Epoch: 5| Step: 9
Training loss: 3.079024904641617
Validation loss: 2.9175660286407776

Epoch: 5| Step: 10
Training loss: 2.299951892847244
Validation loss: 2.930337209543783

Epoch: 59| Step: 0
Training loss: 2.714333114353555
Validation loss: 2.927420774092421

Epoch: 5| Step: 1
Training loss: 3.632402950704817
Validation loss: 2.935860238360831

Epoch: 5| Step: 2
Training loss: 3.0162150541985278
Validation loss: 2.9206919959797952

Epoch: 5| Step: 3
Training loss: 2.6139968781748126
Validation loss: 2.895787217829523

Epoch: 5| Step: 4
Training loss: 2.7941646976465906
Validation loss: 2.917549056663995

Epoch: 5| Step: 5
Training loss: 2.9400102968100503
Validation loss: 2.9094373858074167

Epoch: 5| Step: 6
Training loss: 2.7447601162124418
Validation loss: 2.905389305252231

Epoch: 5| Step: 7
Training loss: 2.888588017503237
Validation loss: 2.9278682012202966

Epoch: 5| Step: 8
Training loss: 3.1503931980867517
Validation loss: 2.9134218164359407

Epoch: 5| Step: 9
Training loss: 2.6327608822253636
Validation loss: 2.918423487146152

Epoch: 5| Step: 10
Training loss: 2.882697043652593
Validation loss: 2.919154291754966

Epoch: 60| Step: 0
Training loss: 2.762020369789536
Validation loss: 2.939433129175516

Epoch: 5| Step: 1
Training loss: 2.2902623700092146
Validation loss: 2.8963060970622734

Epoch: 5| Step: 2
Training loss: 2.777775512270533
Validation loss: 2.9210257944291786

Epoch: 5| Step: 3
Training loss: 2.05156676734312
Validation loss: 2.9395946861746656

Epoch: 5| Step: 4
Training loss: 3.4341461466381604
Validation loss: 2.89542153748067

Epoch: 5| Step: 5
Training loss: 2.760158675511512
Validation loss: 2.9043661719002007

Epoch: 5| Step: 6
Training loss: 3.713278840953287
Validation loss: 2.8845327667984564

Epoch: 5| Step: 7
Training loss: 2.475864829581355
Validation loss: 2.91769392027248

Epoch: 5| Step: 8
Training loss: 3.372336431542281
Validation loss: 2.9382724640848963

Epoch: 5| Step: 9
Training loss: 2.8754149427760245
Validation loss: 2.930251755278276

Epoch: 5| Step: 10
Training loss: 2.8829535886566307
Validation loss: 2.888062846368086

Epoch: 61| Step: 0
Training loss: 3.0950279293741367
Validation loss: 2.882976212638294

Epoch: 5| Step: 1
Training loss: 3.410688256083805
Validation loss: 2.922638006534104

Epoch: 5| Step: 2
Training loss: 2.1917942947919116
Validation loss: 2.875882964154811

Epoch: 5| Step: 3
Training loss: 2.7190455133599998
Validation loss: 2.9061614345146745

Epoch: 5| Step: 4
Training loss: 3.2635139322101843
Validation loss: 2.90310702764573

Epoch: 5| Step: 5
Training loss: 2.514151005108734
Validation loss: 2.919385221149067

Epoch: 5| Step: 6
Training loss: 2.6563462183859983
Validation loss: 2.8949206467569164

Epoch: 5| Step: 7
Training loss: 2.7287095150497778
Validation loss: 2.8972796987969724

Epoch: 5| Step: 8
Training loss: 3.612573436795808
Validation loss: 2.894554393721675

Epoch: 5| Step: 9
Training loss: 2.8712297679834333
Validation loss: 2.9377216193547353

Epoch: 5| Step: 10
Training loss: 2.3351452354664013
Validation loss: 2.9206800462517655

Epoch: 62| Step: 0
Training loss: 2.983505681634233
Validation loss: 2.915146696798574

Epoch: 5| Step: 1
Training loss: 3.083476415527569
Validation loss: 2.8789184577177602

Epoch: 5| Step: 2
Training loss: 3.186890188488823
Validation loss: 2.8939549115596477

Epoch: 5| Step: 3
Training loss: 3.3410987682204047
Validation loss: 2.905828180044722

Epoch: 5| Step: 4
Training loss: 2.6842676285574045
Validation loss: 2.9044465781002633

Epoch: 5| Step: 5
Training loss: 2.9136209843767578
Validation loss: 2.8987805329062657

Epoch: 5| Step: 6
Training loss: 2.2382712372294584
Validation loss: 2.8942015795617095

Epoch: 5| Step: 7
Training loss: 2.0844040852909465
Validation loss: 2.908798615747974

Epoch: 5| Step: 8
Training loss: 3.4494890083373417
Validation loss: 2.88129777139781

Epoch: 5| Step: 9
Training loss: 2.748334033226478
Validation loss: 2.9018566733321434

Epoch: 5| Step: 10
Training loss: 2.8291671266026372
Validation loss: 2.9007330159723734

Epoch: 63| Step: 0
Training loss: 3.2319775232723233
Validation loss: 2.906548808325104

Epoch: 5| Step: 1
Training loss: 3.0913594575685366
Validation loss: 2.8991406979152803

Epoch: 5| Step: 2
Training loss: 3.1496394965344656
Validation loss: 2.894880508241381

Epoch: 5| Step: 3
Training loss: 3.2886859741706176
Validation loss: 2.9114153262242346

Epoch: 5| Step: 4
Training loss: 2.5546783540427835
Validation loss: 2.956855815429399

Epoch: 5| Step: 5
Training loss: 2.5379814781072243
Validation loss: 2.8978646534898966

Epoch: 5| Step: 6
Training loss: 2.865136350945497
Validation loss: 2.9229204773911857

Epoch: 5| Step: 7
Training loss: 3.045273580052893
Validation loss: 2.8946524462619427

Epoch: 5| Step: 8
Training loss: 2.5415729964042004
Validation loss: 2.901972373612215

Epoch: 5| Step: 9
Training loss: 3.1934755450008625
Validation loss: 2.9143252160980633

Epoch: 5| Step: 10
Training loss: 2.52422658198283
Validation loss: 2.9250503560946473

Epoch: 64| Step: 0
Training loss: 2.5609503922012853
Validation loss: 2.884170356058818

Epoch: 5| Step: 1
Training loss: 3.015297669350414
Validation loss: 2.8996053247480593

Epoch: 5| Step: 2
Training loss: 2.6293301970280685
Validation loss: 2.9139276851788143

Epoch: 5| Step: 3
Training loss: 2.727988058981393
Validation loss: 2.9351679390665883

Epoch: 5| Step: 4
Training loss: 2.7878344313827137
Validation loss: 2.9172071832099293

Epoch: 5| Step: 5
Training loss: 3.3589356600887315
Validation loss: 2.8995263156588797

Epoch: 5| Step: 6
Training loss: 3.2910985013674576
Validation loss: 2.899791478562311

Epoch: 5| Step: 7
Training loss: 2.715999395727166
Validation loss: 2.9127191882110246

Epoch: 5| Step: 8
Training loss: 2.8032859764529174
Validation loss: 2.877529171410143

Epoch: 5| Step: 9
Training loss: 3.1709400922637414
Validation loss: 2.8750065281362724

Epoch: 5| Step: 10
Training loss: 2.551740620756286
Validation loss: 2.892848288435764

Epoch: 65| Step: 0
Training loss: 2.6875122424889217
Validation loss: 2.9000337339906666

Epoch: 5| Step: 1
Training loss: 3.0578047902863332
Validation loss: 2.8699938868107058

Epoch: 5| Step: 2
Training loss: 3.0153487479219114
Validation loss: 2.8840941952465053

Epoch: 5| Step: 3
Training loss: 2.359415824486416
Validation loss: 2.8663212961863733

Epoch: 5| Step: 4
Training loss: 3.429086549981021
Validation loss: 2.8795889567284996

Epoch: 5| Step: 5
Training loss: 2.3520614753655837
Validation loss: 2.9049026289296025

Epoch: 5| Step: 6
Training loss: 3.0776651881343278
Validation loss: 2.904587274326948

Epoch: 5| Step: 7
Training loss: 3.2879493261270314
Validation loss: 2.9119495003445364

Epoch: 5| Step: 8
Training loss: 2.620410904148353
Validation loss: 2.918122049459224

Epoch: 5| Step: 9
Training loss: 2.754100430183132
Validation loss: 2.8831801352511226

Epoch: 5| Step: 10
Training loss: 3.08576319721351
Validation loss: 2.895382812847596

Epoch: 66| Step: 0
Training loss: 2.8757305046481267
Validation loss: 2.864173311812163

Epoch: 5| Step: 1
Training loss: 2.612050677633034
Validation loss: 2.913844984747708

Epoch: 5| Step: 2
Training loss: 1.7030264449695505
Validation loss: 2.8948875388314974

Epoch: 5| Step: 3
Training loss: 3.1227063726392337
Validation loss: 2.9229806016138946

Epoch: 5| Step: 4
Training loss: 2.9969043654672793
Validation loss: 2.8990106834319445

Epoch: 5| Step: 5
Training loss: 2.0940731425513723
Validation loss: 2.8879705380849927

Epoch: 5| Step: 6
Training loss: 2.908771364586847
Validation loss: 2.89550912198486

Epoch: 5| Step: 7
Training loss: 2.8422691765489856
Validation loss: 2.9146567795518075

Epoch: 5| Step: 8
Training loss: 3.3312993201635996
Validation loss: 2.877464115890576

Epoch: 5| Step: 9
Training loss: 3.288958405140915
Validation loss: 2.8693680057556583

Epoch: 5| Step: 10
Training loss: 3.539241828332925
Validation loss: 2.9011616536869265

Epoch: 67| Step: 0
Training loss: 2.2147789462934724
Validation loss: 2.89858355932355

Epoch: 5| Step: 1
Training loss: 3.3236740508768556
Validation loss: 2.9049212024293785

Epoch: 5| Step: 2
Training loss: 2.421811798255478
Validation loss: 2.8778021097022326

Epoch: 5| Step: 3
Training loss: 3.0195134052573454
Validation loss: 2.871354679843397

Epoch: 5| Step: 4
Training loss: 2.644175473148538
Validation loss: 2.8986323467232356

Epoch: 5| Step: 5
Training loss: 2.490149355166303
Validation loss: 2.8934111334085535

Epoch: 5| Step: 6
Training loss: 2.7661191854388667
Validation loss: 2.8824324516434077

Epoch: 5| Step: 7
Training loss: 2.6116380757233792
Validation loss: 2.8699910507199826

Epoch: 5| Step: 8
Training loss: 3.1212301785439687
Validation loss: 2.900073759635302

Epoch: 5| Step: 9
Training loss: 3.4134828263070496
Validation loss: 2.8881909916992017

Epoch: 5| Step: 10
Training loss: 3.4928881733814565
Validation loss: 2.8854434945506817

Epoch: 68| Step: 0
Training loss: 3.2119771569034743
Validation loss: 2.917699030514091

Epoch: 5| Step: 1
Training loss: 2.4499704281326267
Validation loss: 2.9209773152294503

Epoch: 5| Step: 2
Training loss: 3.3990165129504826
Validation loss: 2.8873733337175667

Epoch: 5| Step: 3
Training loss: 2.286564736870233
Validation loss: 2.9180079568141277

Epoch: 5| Step: 4
Training loss: 2.48270182377882
Validation loss: 2.9063033567557124

Epoch: 5| Step: 5
Training loss: 3.677003955074338
Validation loss: 2.9000511488118423

Epoch: 5| Step: 6
Training loss: 2.120880059987202
Validation loss: 2.909733102937215

Epoch: 5| Step: 7
Training loss: 3.1282245021851898
Validation loss: 2.8770854585828385

Epoch: 5| Step: 8
Training loss: 2.6221128662748074
Validation loss: 2.9068896661123436

Epoch: 5| Step: 9
Training loss: 2.973223077015622
Validation loss: 2.9106755041922945

Epoch: 5| Step: 10
Training loss: 2.7422646188352386
Validation loss: 2.8943138754465574

Epoch: 69| Step: 0
Training loss: 2.8993160427815
Validation loss: 2.936908096761665

Epoch: 5| Step: 1
Training loss: 2.611091916935852
Validation loss: 2.92533879512216

Epoch: 5| Step: 2
Training loss: 2.4746864505557977
Validation loss: 2.8704612880799103

Epoch: 5| Step: 3
Training loss: 3.017677833860362
Validation loss: 2.896803406507501

Epoch: 5| Step: 4
Training loss: 3.1484739997205797
Validation loss: 2.8905789855824415

Epoch: 5| Step: 5
Training loss: 2.2796227909392655
Validation loss: 2.9237043405348198

Epoch: 5| Step: 6
Training loss: 3.2369820964837825
Validation loss: 2.918807924010353

Epoch: 5| Step: 7
Training loss: 3.0172421561554907
Validation loss: 2.8735819721826363

Epoch: 5| Step: 8
Training loss: 3.062789280521904
Validation loss: 2.8736358168553924

Epoch: 5| Step: 9
Training loss: 2.608359316207936
Validation loss: 2.878206046431927

Epoch: 5| Step: 10
Training loss: 2.812275517300017
Validation loss: 2.8729661093484666

Epoch: 70| Step: 0
Training loss: 2.3541024010812723
Validation loss: 2.868335491484516

Epoch: 5| Step: 1
Training loss: 2.842441467380357
Validation loss: 2.8662012695310444

Epoch: 5| Step: 2
Training loss: 3.0648156578299277
Validation loss: 2.890922306273106

Epoch: 5| Step: 3
Training loss: 1.9132022092107404
Validation loss: 2.8495839598776493

Epoch: 5| Step: 4
Training loss: 3.4825190917270166
Validation loss: 2.8613524278600306

Epoch: 5| Step: 5
Training loss: 2.6690127562771533
Validation loss: 2.878399902460729

Epoch: 5| Step: 6
Training loss: 2.761659872460703
Validation loss: 2.864635596968513

Epoch: 5| Step: 7
Training loss: 3.454446807164683
Validation loss: 2.8832876838324855

Epoch: 5| Step: 8
Training loss: 3.0873341936694962
Validation loss: 2.8894494306690017

Epoch: 5| Step: 9
Training loss: 3.4569378683980356
Validation loss: 2.8684390546601675

Epoch: 5| Step: 10
Training loss: 2.3653441450129247
Validation loss: 2.8600224430389165

Epoch: 71| Step: 0
Training loss: 3.0380834262485603
Validation loss: 2.880528175444145

Epoch: 5| Step: 1
Training loss: 3.392058320047939
Validation loss: 2.8761071948463366

Epoch: 5| Step: 2
Training loss: 3.0020003007943283
Validation loss: 2.8977368280189135

Epoch: 5| Step: 3
Training loss: 2.4321276808902
Validation loss: 2.9042195524451233

Epoch: 5| Step: 4
Training loss: 2.784327743591643
Validation loss: 2.883499148659072

Epoch: 5| Step: 5
Training loss: 2.465497735707302
Validation loss: 2.8683690873186833

Epoch: 5| Step: 6
Training loss: 2.4601641696331225
Validation loss: 2.880090721150237

Epoch: 5| Step: 7
Training loss: 2.248425462596448
Validation loss: 2.885834739401177

Epoch: 5| Step: 8
Training loss: 2.862448286230725
Validation loss: 2.861726724966936

Epoch: 5| Step: 9
Training loss: 2.9369077694224157
Validation loss: 2.87009843700429

Epoch: 5| Step: 10
Training loss: 3.4524415319354946
Validation loss: 2.847698829438664

Epoch: 72| Step: 0
Training loss: 2.780679622841595
Validation loss: 2.869639184901167

Epoch: 5| Step: 1
Training loss: 3.285320119138664
Validation loss: 2.8933197081452824

Epoch: 5| Step: 2
Training loss: 3.1040751467191465
Validation loss: 2.8937486032175044

Epoch: 5| Step: 3
Training loss: 2.72534729730546
Validation loss: 2.8787264114693056

Epoch: 5| Step: 4
Training loss: 2.6788202333699815
Validation loss: 2.8695157019661415

Epoch: 5| Step: 5
Training loss: 2.7993659323332327
Validation loss: 2.894957501969834

Epoch: 5| Step: 6
Training loss: 2.3718189217794814
Validation loss: 2.8697996827084262

Epoch: 5| Step: 7
Training loss: 2.7467686134541682
Validation loss: 2.895700490765055

Epoch: 5| Step: 8
Training loss: 3.3701180364386065
Validation loss: 2.9024666992418466

Epoch: 5| Step: 9
Training loss: 2.6870516913225915
Validation loss: 2.8791368134234885

Epoch: 5| Step: 10
Training loss: 2.6359612627207656
Validation loss: 2.8620502117828415

Epoch: 73| Step: 0
Training loss: 2.613107809517973
Validation loss: 2.879623770029611

Epoch: 5| Step: 1
Training loss: 2.980964509421926
Validation loss: 2.871761324047592

Epoch: 5| Step: 2
Training loss: 2.4731694513027564
Validation loss: 2.8751324965953517

Epoch: 5| Step: 3
Training loss: 3.647839384859807
Validation loss: 2.8973004164609435

Epoch: 5| Step: 4
Training loss: 2.4846864900909584
Validation loss: 2.8945487200684035

Epoch: 5| Step: 5
Training loss: 3.0106173825697207
Validation loss: 2.8937690626684307

Epoch: 5| Step: 6
Training loss: 2.588014995537403
Validation loss: 2.8912300370194166

Epoch: 5| Step: 7
Training loss: 2.8418745626730715
Validation loss: 2.8624368170112082

Epoch: 5| Step: 8
Training loss: 2.4380323366707217
Validation loss: 2.8847404911729466

Epoch: 5| Step: 9
Training loss: 3.631590409991857
Validation loss: 2.8851909917178045

Epoch: 5| Step: 10
Training loss: 2.00924738216194
Validation loss: 2.8861542494922654

Epoch: 74| Step: 0
Training loss: 2.49867232354147
Validation loss: 2.8596199406366027

Epoch: 5| Step: 1
Training loss: 2.446146277488401
Validation loss: 2.8797976112293835

Epoch: 5| Step: 2
Training loss: 2.868050676597733
Validation loss: 2.9070318508748625

Epoch: 5| Step: 3
Training loss: 2.7259823419638525
Validation loss: 2.908932105732673

Epoch: 5| Step: 4
Training loss: 3.888297859571843
Validation loss: 2.8610515604878186

Epoch: 5| Step: 5
Training loss: 2.4309619370073374
Validation loss: 2.8490460309521026

Epoch: 5| Step: 6
Training loss: 2.856130124170439
Validation loss: 2.9243689893521423

Epoch: 5| Step: 7
Training loss: 2.9026018441245323
Validation loss: 2.8961934358351287

Epoch: 5| Step: 8
Training loss: 2.8701253282782644
Validation loss: 2.863493456349054

Epoch: 5| Step: 9
Training loss: 2.8424401253304996
Validation loss: 2.8754778960148855

Epoch: 5| Step: 10
Training loss: 2.7043265610393052
Validation loss: 2.8660202876123195

Epoch: 75| Step: 0
Training loss: 1.9439565076633076
Validation loss: 2.8837309926299866

Epoch: 5| Step: 1
Training loss: 2.810898897288696
Validation loss: 2.8791761256376995

Epoch: 5| Step: 2
Training loss: 2.6747865039086203
Validation loss: 2.8649457306645156

Epoch: 5| Step: 3
Training loss: 2.426221724615174
Validation loss: 2.856274711871957

Epoch: 5| Step: 4
Training loss: 3.5003905759593654
Validation loss: 2.849506677620448

Epoch: 5| Step: 5
Training loss: 3.017505118959094
Validation loss: 2.8712029441978246

Epoch: 5| Step: 6
Training loss: 2.2369001298352447
Validation loss: 2.8167997473932274

Epoch: 5| Step: 7
Training loss: 3.846968505119625
Validation loss: 2.9025013759291416

Epoch: 5| Step: 8
Training loss: 2.762119722731333
Validation loss: 2.8851752785311975

Epoch: 5| Step: 9
Training loss: 2.5217134709961533
Validation loss: 2.882952344608153

Epoch: 5| Step: 10
Training loss: 3.192860154259914
Validation loss: 2.8804999804299443

Epoch: 76| Step: 0
Training loss: 3.3052011365759055
Validation loss: 2.869610657767825

Epoch: 5| Step: 1
Training loss: 3.463603144891212
Validation loss: 2.8722523734226377

Epoch: 5| Step: 2
Training loss: 3.1220217436400457
Validation loss: 2.8612909620560187

Epoch: 5| Step: 3
Training loss: 3.280094197479081
Validation loss: 2.8979393793293533

Epoch: 5| Step: 4
Training loss: 2.7144896351786256
Validation loss: 2.8724409987201667

Epoch: 5| Step: 5
Training loss: 2.24539157672436
Validation loss: 2.886675311845798

Epoch: 5| Step: 6
Training loss: 2.7118716870226365
Validation loss: 2.8530882422354904

Epoch: 5| Step: 7
Training loss: 3.2148037023819405
Validation loss: 2.8816143740543834

Epoch: 5| Step: 8
Training loss: 2.449701045734042
Validation loss: 2.8507093707850615

Epoch: 5| Step: 9
Training loss: 2.064478301126644
Validation loss: 2.856677189339477

Epoch: 5| Step: 10
Training loss: 2.2508432079872063
Validation loss: 2.8853894535207587

Epoch: 77| Step: 0
Training loss: 2.73302936685852
Validation loss: 2.83986665513044

Epoch: 5| Step: 1
Training loss: 3.795364644621717
Validation loss: 2.8437588761551837

Epoch: 5| Step: 2
Training loss: 2.282168268872015
Validation loss: 2.872106531735197

Epoch: 5| Step: 3
Training loss: 2.342956713893257
Validation loss: 2.854883462497057

Epoch: 5| Step: 4
Training loss: 1.974546708830354
Validation loss: 2.8955802467526053

Epoch: 5| Step: 5
Training loss: 3.108120919368174
Validation loss: 2.8869447205201593

Epoch: 5| Step: 6
Training loss: 2.523728675695514
Validation loss: 2.8833733670098334

Epoch: 5| Step: 7
Training loss: 2.1060845601566025
Validation loss: 2.8618425023882796

Epoch: 5| Step: 8
Training loss: 2.971407534058476
Validation loss: 2.851324437669811

Epoch: 5| Step: 9
Training loss: 3.564261419288273
Validation loss: 2.859089419819173

Epoch: 5| Step: 10
Training loss: 3.137145435010579
Validation loss: 2.8571824202164247

Epoch: 78| Step: 0
Training loss: 3.3126851156080166
Validation loss: 2.8889012521508675

Epoch: 5| Step: 1
Training loss: 2.479025208954782
Validation loss: 2.866448625651079

Epoch: 5| Step: 2
Training loss: 2.6551415318411307
Validation loss: 2.874810649955039

Epoch: 5| Step: 3
Training loss: 2.7988671395243956
Validation loss: 2.885649741016436

Epoch: 5| Step: 4
Training loss: 3.3912805723337143
Validation loss: 2.855082689534617

Epoch: 5| Step: 5
Training loss: 2.4513309016827325
Validation loss: 2.8830467191445615

Epoch: 5| Step: 6
Training loss: 2.075073066252281
Validation loss: 2.8579979139148866

Epoch: 5| Step: 7
Training loss: 2.635103943455772
Validation loss: 2.861912909668872

Epoch: 5| Step: 8
Training loss: 2.981888778996899
Validation loss: 2.8698429126689025

Epoch: 5| Step: 9
Training loss: 2.7965323808399183
Validation loss: 2.838856835812428

Epoch: 5| Step: 10
Training loss: 3.3635408343403386
Validation loss: 2.8810100521438455

Epoch: 79| Step: 0
Training loss: 2.2626843540681985
Validation loss: 2.879339731626176

Epoch: 5| Step: 1
Training loss: 2.8363880818876352
Validation loss: 2.854134527938206

Epoch: 5| Step: 2
Training loss: 2.581445670851199
Validation loss: 2.866072705430754

Epoch: 5| Step: 3
Training loss: 3.534334304264977
Validation loss: 2.9039260953407124

Epoch: 5| Step: 4
Training loss: 3.2349028962786583
Validation loss: 2.877373803704451

Epoch: 5| Step: 5
Training loss: 2.9940707104626787
Validation loss: 2.8884257057546834

Epoch: 5| Step: 6
Training loss: 2.881448728116833
Validation loss: 2.865709359512821

Epoch: 5| Step: 7
Training loss: 2.2963891585976035
Validation loss: 2.9035418318495716

Epoch: 5| Step: 8
Training loss: 2.572694735408599
Validation loss: 2.8439964269698663

Epoch: 5| Step: 9
Training loss: 2.8895984373314434
Validation loss: 2.866804790949092

Epoch: 5| Step: 10
Training loss: 2.741901350170827
Validation loss: 2.8793844539170768

Epoch: 80| Step: 0
Training loss: 3.164033564682508
Validation loss: 2.882612037619768

Epoch: 5| Step: 1
Training loss: 2.988850697632255
Validation loss: 2.8825298057001096

Epoch: 5| Step: 2
Training loss: 2.9934866452904423
Validation loss: 2.8445163880926856

Epoch: 5| Step: 3
Training loss: 2.990805842274226
Validation loss: 2.8783104105565798

Epoch: 5| Step: 4
Training loss: 2.5670069625813565
Validation loss: 2.891529498036036

Epoch: 5| Step: 5
Training loss: 2.6802194139706446
Validation loss: 2.8809725895975435

Epoch: 5| Step: 6
Training loss: 2.9600356849890663
Validation loss: 2.892177573912123

Epoch: 5| Step: 7
Training loss: 3.2655219102859525
Validation loss: 2.862292167991742

Epoch: 5| Step: 8
Training loss: 2.2952033986233653
Validation loss: 2.8344282731524606

Epoch: 5| Step: 9
Training loss: 2.870414061766408
Validation loss: 2.8617303333960287

Epoch: 5| Step: 10
Training loss: 2.361835838491875
Validation loss: 2.8296127979085393

Epoch: 81| Step: 0
Training loss: 3.0671951736921645
Validation loss: 2.8569737166779117

Epoch: 5| Step: 1
Training loss: 2.759404314691132
Validation loss: 2.8341318428257325

Epoch: 5| Step: 2
Training loss: 3.0310574499894782
Validation loss: 2.8599012941652293

Epoch: 5| Step: 3
Training loss: 1.9115705188672205
Validation loss: 2.8646604266191855

Epoch: 5| Step: 4
Training loss: 2.4337469698706338
Validation loss: 2.849334100513053

Epoch: 5| Step: 5
Training loss: 2.9616257162130686
Validation loss: 2.8662900545891614

Epoch: 5| Step: 6
Training loss: 2.7284640701218335
Validation loss: 2.8597488835793854

Epoch: 5| Step: 7
Training loss: 2.5900617366782375
Validation loss: 2.8651227629223666

Epoch: 5| Step: 8
Training loss: 3.1678257544214734
Validation loss: 2.9020246950528095

Epoch: 5| Step: 9
Training loss: 3.676019285888224
Validation loss: 2.8902442546125724

Epoch: 5| Step: 10
Training loss: 1.896753765423749
Validation loss: 2.828268214880288

Epoch: 82| Step: 0
Training loss: 2.2540205954598287
Validation loss: 2.852984700513051

Epoch: 5| Step: 1
Training loss: 3.01176086475499
Validation loss: 2.863075942771845

Epoch: 5| Step: 2
Training loss: 2.6144753138707584
Validation loss: 2.887280950115802

Epoch: 5| Step: 3
Training loss: 2.678382043955374
Validation loss: 2.8273748811367794

Epoch: 5| Step: 4
Training loss: 3.359667672116608
Validation loss: 2.8293263547619194

Epoch: 5| Step: 5
Training loss: 2.49149009010875
Validation loss: 2.8542509438545487

Epoch: 5| Step: 6
Training loss: 3.0403673366667583
Validation loss: 2.8783739265994726

Epoch: 5| Step: 7
Training loss: 2.6334195215470024
Validation loss: 2.8572254803828945

Epoch: 5| Step: 8
Training loss: 3.0463791663859943
Validation loss: 2.879373815185419

Epoch: 5| Step: 9
Training loss: 2.921499952429556
Validation loss: 2.852323752850993

Epoch: 5| Step: 10
Training loss: 3.1306845270499797
Validation loss: 2.8730871445452237

Epoch: 83| Step: 0
Training loss: 3.4804903965200875
Validation loss: 2.8811148752769595

Epoch: 5| Step: 1
Training loss: 3.5204185527432705
Validation loss: 2.8546870701592395

Epoch: 5| Step: 2
Training loss: 2.129427280887089
Validation loss: 2.804948361197681

Epoch: 5| Step: 3
Training loss: 3.2979627505223594
Validation loss: 2.853126694498005

Epoch: 5| Step: 4
Training loss: 2.8588431442158524
Validation loss: 2.850211477070552

Epoch: 5| Step: 5
Training loss: 2.934435930523391
Validation loss: 2.838543096660349

Epoch: 5| Step: 6
Training loss: 2.4087592578783275
Validation loss: 2.849634816884829

Epoch: 5| Step: 7
Training loss: 2.4116807564528355
Validation loss: 2.841357124431733

Epoch: 5| Step: 8
Training loss: 2.302900028498798
Validation loss: 2.839647085788229

Epoch: 5| Step: 9
Training loss: 3.1989936796020384
Validation loss: 2.801225345988107

Epoch: 5| Step: 10
Training loss: 2.013428903715595
Validation loss: 2.8207629094141193

Epoch: 84| Step: 0
Training loss: 2.6963292070196014
Validation loss: 2.8938475680681663

Epoch: 5| Step: 1
Training loss: 3.2826176290942466
Validation loss: 2.8651094325312463

Epoch: 5| Step: 2
Training loss: 2.6957797764956686
Validation loss: 2.888241918935348

Epoch: 5| Step: 3
Training loss: 2.8587148769474484
Validation loss: 2.881526244440854

Epoch: 5| Step: 4
Training loss: 1.9093143035181872
Validation loss: 2.8308586234925794

Epoch: 5| Step: 5
Training loss: 2.5161144657084105
Validation loss: 2.8754368789399707

Epoch: 5| Step: 6
Training loss: 3.6039201214794416
Validation loss: 2.8830982707673884

Epoch: 5| Step: 7
Training loss: 2.1204297904039913
Validation loss: 2.846453973540383

Epoch: 5| Step: 8
Training loss: 2.6373689881098095
Validation loss: 2.8571284413340265

Epoch: 5| Step: 9
Training loss: 2.6739007063628586
Validation loss: 2.851952175969785

Epoch: 5| Step: 10
Training loss: 3.4570214567746174
Validation loss: 2.8918905763062046

Epoch: 85| Step: 0
Training loss: 3.740180574433555
Validation loss: 2.841427814659255

Epoch: 5| Step: 1
Training loss: 2.414206392511989
Validation loss: 2.8715334471523657

Epoch: 5| Step: 2
Training loss: 2.85622428364936
Validation loss: 2.8608470059377664

Epoch: 5| Step: 3
Training loss: 2.9200866448598353
Validation loss: 2.878788432043554

Epoch: 5| Step: 4
Training loss: 2.834360235779318
Validation loss: 2.8891837906514044

Epoch: 5| Step: 5
Training loss: 2.8566524697852
Validation loss: 2.8506411491319885

Epoch: 5| Step: 6
Training loss: 2.7508883341926595
Validation loss: 2.832409259828584

Epoch: 5| Step: 7
Training loss: 2.447487153593333
Validation loss: 2.8801946297931713

Epoch: 5| Step: 8
Training loss: 2.1573918954015374
Validation loss: 2.8799611498663173

Epoch: 5| Step: 9
Training loss: 3.0657521321633716
Validation loss: 2.831599661218469

Epoch: 5| Step: 10
Training loss: 2.5694003356263493
Validation loss: 2.841368942198294

Epoch: 86| Step: 0
Training loss: 2.724252153721844
Validation loss: 2.8452384863825118

Epoch: 5| Step: 1
Training loss: 2.550801906531263
Validation loss: 2.8515742413094647

Epoch: 5| Step: 2
Training loss: 2.395333832349052
Validation loss: 2.887046332132634

Epoch: 5| Step: 3
Training loss: 2.7418586555517273
Validation loss: 2.862568474725414

Epoch: 5| Step: 4
Training loss: 3.4235254775233477
Validation loss: 2.841870146914957

Epoch: 5| Step: 5
Training loss: 2.281184574390894
Validation loss: 2.8416133319397803

Epoch: 5| Step: 6
Training loss: 2.8063580736449523
Validation loss: 2.8545933700819197

Epoch: 5| Step: 7
Training loss: 3.0232693726469297
Validation loss: 2.862671956379677

Epoch: 5| Step: 8
Training loss: 2.648948507607003
Validation loss: 2.8200246240004336

Epoch: 5| Step: 9
Training loss: 2.570806670295368
Validation loss: 2.86230545059889

Epoch: 5| Step: 10
Training loss: 3.519964904826947
Validation loss: 2.8649896978205844

Epoch: 87| Step: 0
Training loss: 3.2448645880002465
Validation loss: 2.854287944277266

Epoch: 5| Step: 1
Training loss: 2.5506042138626537
Validation loss: 2.8733216782223034

Epoch: 5| Step: 2
Training loss: 3.0406927526596075
Validation loss: 2.9100281530767034

Epoch: 5| Step: 3
Training loss: 3.3225452052041367
Validation loss: 2.8529802363542918

Epoch: 5| Step: 4
Training loss: 2.086191911934377
Validation loss: 2.826212418769103

Epoch: 5| Step: 5
Training loss: 2.4582483524785244
Validation loss: 2.8690923502738914

Epoch: 5| Step: 6
Training loss: 2.293572367512543
Validation loss: 2.8477900052906753

Epoch: 5| Step: 7
Training loss: 3.2262784449532744
Validation loss: 2.849652300402008

Epoch: 5| Step: 8
Training loss: 3.1099488002082913
Validation loss: 2.8193188433943384

Epoch: 5| Step: 9
Training loss: 2.4847486682799618
Validation loss: 2.8642308043792375

Epoch: 5| Step: 10
Training loss: 2.385817836915896
Validation loss: 2.854498601776041

Epoch: 88| Step: 0
Training loss: 3.14075693640975
Validation loss: 2.8647643741142215

Epoch: 5| Step: 1
Training loss: 3.1598749778255915
Validation loss: 2.8609861715056075

Epoch: 5| Step: 2
Training loss: 2.588039684681219
Validation loss: 2.861619073795248

Epoch: 5| Step: 3
Training loss: 2.5022717644481176
Validation loss: 2.857493894850042

Epoch: 5| Step: 4
Training loss: 2.610106771046389
Validation loss: 2.863956778608809

Epoch: 5| Step: 5
Training loss: 3.078425358868477
Validation loss: 2.848260086254374

Epoch: 5| Step: 6
Training loss: 2.4497211920465984
Validation loss: 2.8465386039627685

Epoch: 5| Step: 7
Training loss: 2.857187904275271
Validation loss: 2.8750509308400702

Epoch: 5| Step: 8
Training loss: 3.02972656980272
Validation loss: 2.7882131398497583

Epoch: 5| Step: 9
Training loss: 2.817855652479461
Validation loss: 2.884172939990788

Epoch: 5| Step: 10
Training loss: 2.3771439963871197
Validation loss: 2.837688332605306

Epoch: 89| Step: 0
Training loss: 2.52191607549369
Validation loss: 2.855961418495272

Epoch: 5| Step: 1
Training loss: 3.379002211426358
Validation loss: 2.842690250651535

Epoch: 5| Step: 2
Training loss: 3.4469453916858273
Validation loss: 2.8689757261138538

Epoch: 5| Step: 3
Training loss: 2.0164825034845038
Validation loss: 2.8791032448437974

Epoch: 5| Step: 4
Training loss: 3.0646802965112396
Validation loss: 2.864101467081527

Epoch: 5| Step: 5
Training loss: 2.493523027612418
Validation loss: 2.8785954776273517

Epoch: 5| Step: 6
Training loss: 3.0448236847241463
Validation loss: 2.8457947071158833

Epoch: 5| Step: 7
Training loss: 2.904236783276281
Validation loss: 2.843708220576924

Epoch: 5| Step: 8
Training loss: 2.1536218963977967
Validation loss: 2.862209909394302

Epoch: 5| Step: 9
Training loss: 3.1251559409334067
Validation loss: 2.8655332232507136

Epoch: 5| Step: 10
Training loss: 2.284837906010924
Validation loss: 2.853757070048481

Epoch: 90| Step: 0
Training loss: 3.326640769714996
Validation loss: 2.8229070904782776

Epoch: 5| Step: 1
Training loss: 2.3587602231239297
Validation loss: 2.8490407381810976

Epoch: 5| Step: 2
Training loss: 2.5880112184461215
Validation loss: 2.85462552639551

Epoch: 5| Step: 3
Training loss: 2.3111241345874114
Validation loss: 2.827967490972101

Epoch: 5| Step: 4
Training loss: 2.828097095667975
Validation loss: 2.856482034998818

Epoch: 5| Step: 5
Training loss: 2.675825622636189
Validation loss: 2.8563488500823526

Epoch: 5| Step: 6
Training loss: 2.138267611263934
Validation loss: 2.8408647351573153

Epoch: 5| Step: 7
Training loss: 3.044682892822614
Validation loss: 2.876768416312745

Epoch: 5| Step: 8
Training loss: 3.59097886429263
Validation loss: 2.8262257094807355

Epoch: 5| Step: 9
Training loss: 2.8601098288942337
Validation loss: 2.8888886659836137

Epoch: 5| Step: 10
Training loss: 2.8060353050430766
Validation loss: 2.8511580740782043

Epoch: 91| Step: 0
Training loss: 3.3548618962478183
Validation loss: 2.879212138842916

Epoch: 5| Step: 1
Training loss: 2.882808695638157
Validation loss: 2.856595536369482

Epoch: 5| Step: 2
Training loss: 3.046667003868079
Validation loss: 2.85323703992771

Epoch: 5| Step: 3
Training loss: 2.393099931140784
Validation loss: 2.844641726763379

Epoch: 5| Step: 4
Training loss: 2.616628285347233
Validation loss: 2.854659557485853

Epoch: 5| Step: 5
Training loss: 2.5124356921112687
Validation loss: 2.8625975395221297

Epoch: 5| Step: 6
Training loss: 2.0799366790963356
Validation loss: 2.856467124646036

Epoch: 5| Step: 7
Training loss: 2.0146006265533813
Validation loss: 2.877248705872512

Epoch: 5| Step: 8
Training loss: 3.1325091360191837
Validation loss: 2.8394588524398143

Epoch: 5| Step: 9
Training loss: 3.0748764943697235
Validation loss: 2.832675308807687

Epoch: 5| Step: 10
Training loss: 3.210852109047428
Validation loss: 2.8683775878809232

Epoch: 92| Step: 0
Training loss: 3.2009695849178788
Validation loss: 2.8397912010165953

Epoch: 5| Step: 1
Training loss: 2.309339477100672
Validation loss: 2.881543065600166

Epoch: 5| Step: 2
Training loss: 2.8389785477061884
Validation loss: 2.8498333043683988

Epoch: 5| Step: 3
Training loss: 3.3973393913296874
Validation loss: 2.8351972199032276

Epoch: 5| Step: 4
Training loss: 3.0659712756280144
Validation loss: 2.8791118446063533

Epoch: 5| Step: 5
Training loss: 2.140630123382897
Validation loss: 2.844085257104206

Epoch: 5| Step: 6
Training loss: 2.7469916795202556
Validation loss: 2.8403797094427796

Epoch: 5| Step: 7
Training loss: 2.2130661277837143
Validation loss: 2.8704034514132033

Epoch: 5| Step: 8
Training loss: 3.287985292304342
Validation loss: 2.8627448220563676

Epoch: 5| Step: 9
Training loss: 2.298859860987926
Validation loss: 2.8537205783957162

Epoch: 5| Step: 10
Training loss: 2.7117264448851857
Validation loss: 2.8435054494953427

Epoch: 93| Step: 0
Training loss: 2.5082799172865724
Validation loss: 2.8341384958524047

Epoch: 5| Step: 1
Training loss: 2.8070196374981586
Validation loss: 2.8332661322768242

Epoch: 5| Step: 2
Training loss: 3.2184285123695693
Validation loss: 2.8780486576195754

Epoch: 5| Step: 3
Training loss: 2.5240948178214357
Validation loss: 2.795308440488012

Epoch: 5| Step: 4
Training loss: 1.9773340340281038
Validation loss: 2.831909143561594

Epoch: 5| Step: 5
Training loss: 2.561768031831449
Validation loss: 2.8391123596584977

Epoch: 5| Step: 6
Training loss: 3.3817514777480286
Validation loss: 2.9073753308535997

Epoch: 5| Step: 7
Training loss: 2.6396982948260432
Validation loss: 2.8587843963438995

Epoch: 5| Step: 8
Training loss: 3.0064502355941305
Validation loss: 2.8254154187737495

Epoch: 5| Step: 9
Training loss: 2.118879142133814
Validation loss: 2.8575040130476523

Epoch: 5| Step: 10
Training loss: 3.8455399478141397
Validation loss: 2.8572516556869436

Epoch: 94| Step: 0
Training loss: 2.1108616993902363
Validation loss: 2.85021931492187

Epoch: 5| Step: 1
Training loss: 2.4499863877210237
Validation loss: 2.8076499841030937

Epoch: 5| Step: 2
Training loss: 2.427967505336555
Validation loss: 2.8362295367126116

Epoch: 5| Step: 3
Training loss: 3.6827606521213117
Validation loss: 2.828690605733605

Epoch: 5| Step: 4
Training loss: 3.228946128615568
Validation loss: 2.8569107002729126

Epoch: 5| Step: 5
Training loss: 1.7701746295193987
Validation loss: 2.873409798955159

Epoch: 5| Step: 6
Training loss: 3.44536066346012
Validation loss: 2.864524025997628

Epoch: 5| Step: 7
Training loss: 2.366753063057682
Validation loss: 2.841477676336506

Epoch: 5| Step: 8
Training loss: 2.9558357835717732
Validation loss: 2.8529983373605585

Epoch: 5| Step: 9
Training loss: 2.972238839678395
Validation loss: 2.808413408129258

Epoch: 5| Step: 10
Training loss: 2.534635846017673
Validation loss: 2.888929518691859

Epoch: 95| Step: 0
Training loss: 3.0656899168274823
Validation loss: 2.8644472237895022

Epoch: 5| Step: 1
Training loss: 2.4624847876374187
Validation loss: 2.861746664437038

Epoch: 5| Step: 2
Training loss: 3.083079731452491
Validation loss: 2.805843745065022

Epoch: 5| Step: 3
Training loss: 2.691404123955982
Validation loss: 2.828889034616342

Epoch: 5| Step: 4
Training loss: 2.0661472093292135
Validation loss: 2.889956789127638

Epoch: 5| Step: 5
Training loss: 1.721124777079151
Validation loss: 2.855888661613395

Epoch: 5| Step: 6
Training loss: 2.6481851553189792
Validation loss: 2.8835711448748613

Epoch: 5| Step: 7
Training loss: 2.9150531302005613
Validation loss: 2.8201330434229397

Epoch: 5| Step: 8
Training loss: 3.281286039608627
Validation loss: 2.8067519348488776

Epoch: 5| Step: 9
Training loss: 3.3943975178634194
Validation loss: 2.8866403771028213

Epoch: 5| Step: 10
Training loss: 2.781542216176543
Validation loss: 2.8074727949809284

Epoch: 96| Step: 0
Training loss: 2.161845369425425
Validation loss: 2.8396615567734607

Epoch: 5| Step: 1
Training loss: 2.621118218525181
Validation loss: 2.829501739565494

Epoch: 5| Step: 2
Training loss: 2.4251169471463485
Validation loss: 2.8347266340595128

Epoch: 5| Step: 3
Training loss: 2.7917523916566815
Validation loss: 2.8885759722399325

Epoch: 5| Step: 4
Training loss: 2.7037188809209325
Validation loss: 2.8616150334156134

Epoch: 5| Step: 5
Training loss: 2.4516281128874637
Validation loss: 2.8535760575784126

Epoch: 5| Step: 6
Training loss: 2.516488252930307
Validation loss: 2.8659243916783192

Epoch: 5| Step: 7
Training loss: 2.9152680631365357
Validation loss: 2.8525427400695227

Epoch: 5| Step: 8
Training loss: 3.852985730403928
Validation loss: 2.8203162504972337

Epoch: 5| Step: 9
Training loss: 2.910112009416241
Validation loss: 2.871066798148587

Epoch: 5| Step: 10
Training loss: 2.8553516870134863
Validation loss: 2.837900765212758

Epoch: 97| Step: 0
Training loss: 3.1684399876376435
Validation loss: 2.8019547297812513

Epoch: 5| Step: 1
Training loss: 2.6968465226704317
Validation loss: 2.8081202761922843

Epoch: 5| Step: 2
Training loss: 2.2955574876104845
Validation loss: 2.8223684643102533

Epoch: 5| Step: 3
Training loss: 3.0969705484164343
Validation loss: 2.882840190409532

Epoch: 5| Step: 4
Training loss: 2.2651474021796183
Validation loss: 2.86111576701058

Epoch: 5| Step: 5
Training loss: 3.2570775069705626
Validation loss: 2.81917802426601

Epoch: 5| Step: 6
Training loss: 3.004339576291743
Validation loss: 2.824646390352503

Epoch: 5| Step: 7
Training loss: 3.027346585180124
Validation loss: 2.8796893589829975

Epoch: 5| Step: 8
Training loss: 2.2845913180565907
Validation loss: 2.8541943828930756

Epoch: 5| Step: 9
Training loss: 2.3530295222189803
Validation loss: 2.809649308233571

Epoch: 5| Step: 10
Training loss: 2.673821883267459
Validation loss: 2.8435854083811787

Epoch: 98| Step: 0
Training loss: 3.230626094358159
Validation loss: 2.849596867189529

Epoch: 5| Step: 1
Training loss: 3.1406052622008813
Validation loss: 2.826936071114266

Epoch: 5| Step: 2
Training loss: 2.4329017892278
Validation loss: 2.8637744337974187

Epoch: 5| Step: 3
Training loss: 2.5876285060355557
Validation loss: 2.8709816442081357

Epoch: 5| Step: 4
Training loss: 2.6536855548035816
Validation loss: 2.854137304334789

Epoch: 5| Step: 5
Training loss: 2.591164920806869
Validation loss: 2.8146764212037616

Epoch: 5| Step: 6
Training loss: 2.6692571475290667
Validation loss: 2.8305925097279885

Epoch: 5| Step: 7
Training loss: 2.809055677688501
Validation loss: 2.8764979368972656

Epoch: 5| Step: 8
Training loss: 2.4566248328668356
Validation loss: 2.8355732725164304

Epoch: 5| Step: 9
Training loss: 3.09751785950519
Validation loss: 2.8395712466527363

Epoch: 5| Step: 10
Training loss: 2.415386343118516
Validation loss: 2.8461429890750733

Epoch: 99| Step: 0
Training loss: 2.942760707873012
Validation loss: 2.835343868759924

Epoch: 5| Step: 1
Training loss: 2.423206578559799
Validation loss: 2.871363411738299

Epoch: 5| Step: 2
Training loss: 3.176207491527567
Validation loss: 2.85542699120816

Epoch: 5| Step: 3
Training loss: 2.6360135413995684
Validation loss: 2.8554404431147513

Epoch: 5| Step: 4
Training loss: 2.2969441306162333
Validation loss: 2.8437426635835066

Epoch: 5| Step: 5
Training loss: 3.1286386287312653
Validation loss: 2.8267420685583375

Epoch: 5| Step: 6
Training loss: 2.387108204435106
Validation loss: 2.825067791155795

Epoch: 5| Step: 7
Training loss: 2.960236076271334
Validation loss: 2.829189251222045

Epoch: 5| Step: 8
Training loss: 2.4007197651808876
Validation loss: 2.840156860756963

Epoch: 5| Step: 9
Training loss: 2.7410595957064405
Validation loss: 2.830284618001627

Epoch: 5| Step: 10
Training loss: 3.239734576620919
Validation loss: 2.847081968099648

Epoch: 100| Step: 0
Training loss: 2.8302230218687052
Validation loss: 2.8412565442083126

Epoch: 5| Step: 1
Training loss: 2.5453967151327213
Validation loss: 2.7832667592662355

Epoch: 5| Step: 2
Training loss: 2.5872168934324216
Validation loss: 2.826919507233014

Epoch: 5| Step: 3
Training loss: 2.720987999235955
Validation loss: 2.8409272682600304

Epoch: 5| Step: 4
Training loss: 1.999679897441144
Validation loss: 2.8022387822427297

Epoch: 5| Step: 5
Training loss: 3.0853490340817804
Validation loss: 2.8382451035258356

Epoch: 5| Step: 6
Training loss: 3.0767800738042026
Validation loss: 2.839439501324046

Epoch: 5| Step: 7
Training loss: 2.68805759766722
Validation loss: 2.830279344493235

Epoch: 5| Step: 8
Training loss: 2.366213758768438
Validation loss: 2.8194659098731094

Epoch: 5| Step: 9
Training loss: 3.6141669100379525
Validation loss: 2.8320558106033165

Epoch: 5| Step: 10
Training loss: 2.865390474296728
Validation loss: 2.8382789534648096

Epoch: 101| Step: 0
Training loss: 3.642309887702335
Validation loss: 2.8593618651640402

Epoch: 5| Step: 1
Training loss: 2.441381347529247
Validation loss: 2.8511288090435003

Epoch: 5| Step: 2
Training loss: 2.9611832408537446
Validation loss: 2.834212533804027

Epoch: 5| Step: 3
Training loss: 2.7521406858379853
Validation loss: 2.8365318954341934

Epoch: 5| Step: 4
Training loss: 2.91130807087342
Validation loss: 2.8610926834369477

Epoch: 5| Step: 5
Training loss: 2.6570177651623688
Validation loss: 2.827846451968151

Epoch: 5| Step: 6
Training loss: 2.363951835386943
Validation loss: 2.8621081935129222

Epoch: 5| Step: 7
Training loss: 2.2410471073018514
Validation loss: 2.8712186606343986

Epoch: 5| Step: 8
Training loss: 2.6102193962343994
Validation loss: 2.818517219039811

Epoch: 5| Step: 9
Training loss: 2.2058711691180184
Validation loss: 2.8636621014516637

Epoch: 5| Step: 10
Training loss: 3.29828573841865
Validation loss: 2.8511919208692738

Epoch: 102| Step: 0
Training loss: 2.62363052975781
Validation loss: 2.8313629645064933

Epoch: 5| Step: 1
Training loss: 2.7680573193287743
Validation loss: 2.835628467259266

Epoch: 5| Step: 2
Training loss: 2.4593723709111783
Validation loss: 2.7924505543435583

Epoch: 5| Step: 3
Training loss: 2.2544480966636904
Validation loss: 2.874769972042935

Epoch: 5| Step: 4
Training loss: 2.673786305113746
Validation loss: 2.8746545743729404

Epoch: 5| Step: 5
Training loss: 2.9499105084309702
Validation loss: 2.8511949851605713

Epoch: 5| Step: 6
Training loss: 2.7955186847791706
Validation loss: 2.8572479509803506

Epoch: 5| Step: 7
Training loss: 2.8051959668687356
Validation loss: 2.7901113276522285

Epoch: 5| Step: 8
Training loss: 2.9605802859021506
Validation loss: 2.8152893399522205

Epoch: 5| Step: 9
Training loss: 3.008475094428875
Validation loss: 2.8299844498821125

Epoch: 5| Step: 10
Training loss: 3.3908519756798112
Validation loss: 2.8516286103140773

Epoch: 103| Step: 0
Training loss: 2.9942938260911824
Validation loss: 2.8089925436742478

Epoch: 5| Step: 1
Training loss: 2.0597402431082394
Validation loss: 2.8656003290400567

Epoch: 5| Step: 2
Training loss: 1.945993817373493
Validation loss: 2.8759085381994063

Epoch: 5| Step: 3
Training loss: 3.1494488854663967
Validation loss: 2.7982805397929456

Epoch: 5| Step: 4
Training loss: 2.8469096645418035
Validation loss: 2.8410359741842397

Epoch: 5| Step: 5
Training loss: 1.8423737384075678
Validation loss: 2.834075058539734

Epoch: 5| Step: 6
Training loss: 2.259269165261699
Validation loss: 2.787969024501666

Epoch: 5| Step: 7
Training loss: 3.312250235876063
Validation loss: 2.817807584529465

Epoch: 5| Step: 8
Training loss: 2.8864891363560954
Validation loss: 2.804918889143444

Epoch: 5| Step: 9
Training loss: 3.3513822351452784
Validation loss: 2.8551744861835817

Epoch: 5| Step: 10
Training loss: 3.0258681509637197
Validation loss: 2.7926672708163296

Epoch: 104| Step: 0
Training loss: 2.728435670832168
Validation loss: 2.869956753898635

Epoch: 5| Step: 1
Training loss: 2.367281568817282
Validation loss: 2.8047302738250264

Epoch: 5| Step: 2
Training loss: 2.3532121011488027
Validation loss: 2.8265151297958977

Epoch: 5| Step: 3
Training loss: 2.571478767510596
Validation loss: 2.81320508643702

Epoch: 5| Step: 4
Training loss: 2.7133457359605364
Validation loss: 2.814631227723211

Epoch: 5| Step: 5
Training loss: 2.7941777526957137
Validation loss: 2.7964857129222955

Epoch: 5| Step: 6
Training loss: 2.778073414858928
Validation loss: 2.816581888652925

Epoch: 5| Step: 7
Training loss: 2.6113315944605784
Validation loss: 2.8364018762581895

Epoch: 5| Step: 8
Training loss: 3.2179481470495466
Validation loss: 2.827899151295255

Epoch: 5| Step: 9
Training loss: 3.6673433950906
Validation loss: 2.8196503331693954

Epoch: 5| Step: 10
Training loss: 1.8933211089576845
Validation loss: 2.8176022880156855

Epoch: 105| Step: 0
Training loss: 2.186609904533333
Validation loss: 2.8455976352537298

Epoch: 5| Step: 1
Training loss: 2.5532089761209575
Validation loss: 2.8497553136910256

Epoch: 5| Step: 2
Training loss: 2.853813892105427
Validation loss: 2.8516348503307882

Epoch: 5| Step: 3
Training loss: 2.6574840596134552
Validation loss: 2.838847377210497

Epoch: 5| Step: 4
Training loss: 3.113803948877234
Validation loss: 2.8306283857111834

Epoch: 5| Step: 5
Training loss: 3.000353792309887
Validation loss: 2.8652173525154176

Epoch: 5| Step: 6
Training loss: 2.287674727306962
Validation loss: 2.7932650937174817

Epoch: 5| Step: 7
Training loss: 2.735675175681426
Validation loss: 2.82494611199582

Epoch: 5| Step: 8
Training loss: 2.7540393986539806
Validation loss: 2.8443561364584338

Epoch: 5| Step: 9
Training loss: 3.591313340464657
Validation loss: 2.830033523968021

Epoch: 5| Step: 10
Training loss: 2.029771824495399
Validation loss: 2.842302773819234

Epoch: 106| Step: 0
Training loss: 2.830005505290254
Validation loss: 2.868959366523863

Epoch: 5| Step: 1
Training loss: 2.8669847629808833
Validation loss: 2.760344606102489

Epoch: 5| Step: 2
Training loss: 3.2983075685990286
Validation loss: 2.8234318433892285

Epoch: 5| Step: 3
Training loss: 2.719355811663127
Validation loss: 2.8463023524518314

Epoch: 5| Step: 4
Training loss: 2.838403895589828
Validation loss: 2.8063666515057046

Epoch: 5| Step: 5
Training loss: 2.9357507245318626
Validation loss: 2.8454114434352564

Epoch: 5| Step: 6
Training loss: 2.296364863829263
Validation loss: 2.8496378234744575

Epoch: 5| Step: 7
Training loss: 3.0621930961195707
Validation loss: 2.8271644913316085

Epoch: 5| Step: 8
Training loss: 2.7178001059821635
Validation loss: 2.817035198792165

Epoch: 5| Step: 9
Training loss: 2.03930615836464
Validation loss: 2.8369428605824614

Epoch: 5| Step: 10
Training loss: 2.6002770533035067
Validation loss: 2.839601323260932

Epoch: 107| Step: 0
Training loss: 2.6880230062045163
Validation loss: 2.797516690139112

Epoch: 5| Step: 1
Training loss: 3.1570797575481078
Validation loss: 2.8282117071725192

Epoch: 5| Step: 2
Training loss: 2.705154450920043
Validation loss: 2.807624546178704

Epoch: 5| Step: 3
Training loss: 2.936708221863195
Validation loss: 2.8504664885038493

Epoch: 5| Step: 4
Training loss: 2.988126464026355
Validation loss: 2.8239219923884136

Epoch: 5| Step: 5
Training loss: 2.3472643126777513
Validation loss: 2.8417659609976984

Epoch: 5| Step: 6
Training loss: 2.3863770885005806
Validation loss: 2.833226027860534

Epoch: 5| Step: 7
Training loss: 2.9597001119720927
Validation loss: 2.8207810444798596

Epoch: 5| Step: 8
Training loss: 2.7639371387438407
Validation loss: 2.847817963319969

Epoch: 5| Step: 9
Training loss: 2.2793130882229162
Validation loss: 2.8338767320211975

Epoch: 5| Step: 10
Training loss: 2.779758267630252
Validation loss: 2.8245892737872103

Epoch: 108| Step: 0
Training loss: 1.9022432962641143
Validation loss: 2.854469104249564

Epoch: 5| Step: 1
Training loss: 3.135039263514391
Validation loss: 2.833052378471205

Epoch: 5| Step: 2
Training loss: 3.2980928747865446
Validation loss: 2.8208283147065787

Epoch: 5| Step: 3
Training loss: 2.6950509207025095
Validation loss: 2.8602269642395552

Epoch: 5| Step: 4
Training loss: 2.3962381325011477
Validation loss: 2.816152797011337

Epoch: 5| Step: 5
Training loss: 2.8679451006499055
Validation loss: 2.8612085868663897

Epoch: 5| Step: 6
Training loss: 2.516431501487467
Validation loss: 2.8272069450432626

Epoch: 5| Step: 7
Training loss: 2.7255825260022095
Validation loss: 2.8351096051044515

Epoch: 5| Step: 8
Training loss: 2.413407023799428
Validation loss: 2.8686785063902187

Epoch: 5| Step: 9
Training loss: 3.1401649251984027
Validation loss: 2.8149719459183298

Epoch: 5| Step: 10
Training loss: 3.1517213871194842
Validation loss: 2.86909189546344

Epoch: 109| Step: 0
Training loss: 3.3816383914382713
Validation loss: 2.8357065761554217

Epoch: 5| Step: 1
Training loss: 2.343489467127566
Validation loss: 2.793766848594622

Epoch: 5| Step: 2
Training loss: 3.4987760856176604
Validation loss: 2.8085290291873117

Epoch: 5| Step: 3
Training loss: 2.9137918382387773
Validation loss: 2.831571931461707

Epoch: 5| Step: 4
Training loss: 2.243121122248995
Validation loss: 2.822353218866158

Epoch: 5| Step: 5
Training loss: 1.9744424419229534
Validation loss: 2.8351587270174634

Epoch: 5| Step: 6
Training loss: 2.4364181465225934
Validation loss: 2.8160341378905174

Epoch: 5| Step: 7
Training loss: 2.383884376455032
Validation loss: 2.7730314473709026

Epoch: 5| Step: 8
Training loss: 2.975594270479799
Validation loss: 2.787865151668638

Epoch: 5| Step: 9
Training loss: 2.3754795995634006
Validation loss: 2.8488416379959896

Epoch: 5| Step: 10
Training loss: 3.04721709067153
Validation loss: 2.864391196212651

Epoch: 110| Step: 0
Training loss: 2.0980562933250715
Validation loss: 2.777989878777591

Epoch: 5| Step: 1
Training loss: 2.792808944291823
Validation loss: 2.8601532976345725

Epoch: 5| Step: 2
Training loss: 3.4405961398405003
Validation loss: 2.8192719616024813

Epoch: 5| Step: 3
Training loss: 2.5408649326593626
Validation loss: 2.8117856794629157

Epoch: 5| Step: 4
Training loss: 2.516834797411411
Validation loss: 2.8133025506681966

Epoch: 5| Step: 5
Training loss: 2.7587181095687803
Validation loss: 2.8232232900408807

Epoch: 5| Step: 6
Training loss: 2.866087325645808
Validation loss: 2.8240564142762072

Epoch: 5| Step: 7
Training loss: 3.213459444565572
Validation loss: 2.8211093113656394

Epoch: 5| Step: 8
Training loss: 2.288471653428314
Validation loss: 2.7969118584359194

Epoch: 5| Step: 9
Training loss: 1.8732607085969233
Validation loss: 2.8135131943352376

Epoch: 5| Step: 10
Training loss: 3.3092971288292383
Validation loss: 2.8128605163746334

Epoch: 111| Step: 0
Training loss: 2.5857820492952457
Validation loss: 2.8356803303525813

Epoch: 5| Step: 1
Training loss: 2.7347183447942136
Validation loss: 2.7958929854342607

Epoch: 5| Step: 2
Training loss: 2.46639999374355
Validation loss: 2.8461077738968816

Epoch: 5| Step: 3
Training loss: 2.9830619759638597
Validation loss: 2.7830704430827704

Epoch: 5| Step: 4
Training loss: 2.160422117348407
Validation loss: 2.832296852044584

Epoch: 5| Step: 5
Training loss: 2.49178432922506
Validation loss: 2.82455072165371

Epoch: 5| Step: 6
Training loss: 2.7026914568615545
Validation loss: 2.8390293301149208

Epoch: 5| Step: 7
Training loss: 3.986858476555816
Validation loss: 2.83425705821916

Epoch: 5| Step: 8
Training loss: 2.0928668536663513
Validation loss: 2.8225757956280044

Epoch: 5| Step: 9
Training loss: 2.7939296963310962
Validation loss: 2.8886668864664875

Epoch: 5| Step: 10
Training loss: 2.2350269780248246
Validation loss: 2.912680246429418

Epoch: 112| Step: 0
Training loss: 2.9035451463881627
Validation loss: 2.806242979786219

Epoch: 5| Step: 1
Training loss: 2.312606602866467
Validation loss: 2.7807699325866455

Epoch: 5| Step: 2
Training loss: 2.5819251519131585
Validation loss: 2.803637507727178

Epoch: 5| Step: 3
Training loss: 2.607609682784497
Validation loss: 2.784099445150715

Epoch: 5| Step: 4
Training loss: 3.243087459809349
Validation loss: 2.8256273296745156

Epoch: 5| Step: 5
Training loss: 2.4349630798736763
Validation loss: 2.848208938274064

Epoch: 5| Step: 6
Training loss: 3.068152679921514
Validation loss: 2.7973928718553434

Epoch: 5| Step: 7
Training loss: 2.5765814582122615
Validation loss: 2.8581198242667623

Epoch: 5| Step: 8
Training loss: 2.832583290754229
Validation loss: 2.850821106519959

Epoch: 5| Step: 9
Training loss: 2.843035765442712
Validation loss: 2.830462572769322

Epoch: 5| Step: 10
Training loss: 2.8215974960666466
Validation loss: 2.7736575542977544

Epoch: 113| Step: 0
Training loss: 2.4385969188046563
Validation loss: 2.8501573994465854

Epoch: 5| Step: 1
Training loss: 2.596844585070741
Validation loss: 2.8094668103563816

Epoch: 5| Step: 2
Training loss: 2.8020285751116436
Validation loss: 2.8643160542988535

Epoch: 5| Step: 3
Training loss: 3.0437519989947073
Validation loss: 2.814309873897156

Epoch: 5| Step: 4
Training loss: 3.2055611627075353
Validation loss: 2.850087674117735

Epoch: 5| Step: 5
Training loss: 3.0749130919045684
Validation loss: 2.8271760193120468

Epoch: 5| Step: 6
Training loss: 2.5641518827732663
Validation loss: 2.788051386212997

Epoch: 5| Step: 7
Training loss: 2.420180287699551
Validation loss: 2.783155875259179

Epoch: 5| Step: 8
Training loss: 2.4585016699446443
Validation loss: 2.8640003697769805

Epoch: 5| Step: 9
Training loss: 2.4615388650160237
Validation loss: 2.855271300732035

Epoch: 5| Step: 10
Training loss: 2.8125007629393495
Validation loss: 2.8029190179305603

Epoch: 114| Step: 0
Training loss: 2.783079081665609
Validation loss: 2.8084914834221206

Epoch: 5| Step: 1
Training loss: 3.104543948874482
Validation loss: 2.7997180986522308

Epoch: 5| Step: 2
Training loss: 3.090171825483292
Validation loss: 2.829197149350984

Epoch: 5| Step: 3
Training loss: 2.769707032558428
Validation loss: 2.811101121201213

Epoch: 5| Step: 4
Training loss: 2.558502335407741
Validation loss: 2.785361789297126

Epoch: 5| Step: 5
Training loss: 2.87093530334475
Validation loss: 2.788975544550008

Epoch: 5| Step: 6
Training loss: 3.033125621544841
Validation loss: 2.829068450936156

Epoch: 5| Step: 7
Training loss: 2.293609269733677
Validation loss: 2.840556882860147

Epoch: 5| Step: 8
Training loss: 2.691277532724597
Validation loss: 2.811615613215203

Epoch: 5| Step: 9
Training loss: 2.010646378697273
Validation loss: 2.8226867786206764

Epoch: 5| Step: 10
Training loss: 2.8305741132835607
Validation loss: 2.8226225834908316

Epoch: 115| Step: 0
Training loss: 3.088004586073084
Validation loss: 2.82997749720573

Epoch: 5| Step: 1
Training loss: 3.44036205094245
Validation loss: 2.830482257880991

Epoch: 5| Step: 2
Training loss: 2.585699249079338
Validation loss: 2.8103809791880656

Epoch: 5| Step: 3
Training loss: 2.2979039592743176
Validation loss: 2.791130095776587

Epoch: 5| Step: 4
Training loss: 2.813974883872315
Validation loss: 2.847854062502878

Epoch: 5| Step: 5
Training loss: 2.276051699502046
Validation loss: 2.8084276511831074

Epoch: 5| Step: 6
Training loss: 2.0743938020162678
Validation loss: 2.7970662567490483

Epoch: 5| Step: 7
Training loss: 3.034860093287273
Validation loss: 2.823899292012158

Epoch: 5| Step: 8
Training loss: 2.8036468190269335
Validation loss: 2.859332792581494

Epoch: 5| Step: 9
Training loss: 2.1792287036047284
Validation loss: 2.8090211287909903

Epoch: 5| Step: 10
Training loss: 3.0297833856889467
Validation loss: 2.8314395404926467

Epoch: 116| Step: 0
Training loss: 2.752679906192253
Validation loss: 2.8107350981693004

Epoch: 5| Step: 1
Training loss: 3.054498925205578
Validation loss: 2.824040980953658

Epoch: 5| Step: 2
Training loss: 3.065774995982055
Validation loss: 2.823952634202579

Epoch: 5| Step: 3
Training loss: 2.5345597469100505
Validation loss: 2.806293153279144

Epoch: 5| Step: 4
Training loss: 2.782223648921342
Validation loss: 2.8399516398281235

Epoch: 5| Step: 5
Training loss: 2.087472757858417
Validation loss: 2.7869982676543175

Epoch: 5| Step: 6
Training loss: 2.381076668265575
Validation loss: 2.8385769854934804

Epoch: 5| Step: 7
Training loss: 3.160522288848105
Validation loss: 2.8721548102470673

Epoch: 5| Step: 8
Training loss: 2.791514625014951
Validation loss: 2.8391073707305647

Epoch: 5| Step: 9
Training loss: 3.2814192955303065
Validation loss: 2.8369661713805234

Epoch: 5| Step: 10
Training loss: 2.142946418537376
Validation loss: 2.781655663953719

Epoch: 117| Step: 0
Training loss: 2.5441353695799207
Validation loss: 2.8123346168449515

Epoch: 5| Step: 1
Training loss: 3.2661599629106215
Validation loss: 2.8119665189103578

Epoch: 5| Step: 2
Training loss: 3.3596583047328705
Validation loss: 2.8159882164957506

Epoch: 5| Step: 3
Training loss: 2.8720877451336806
Validation loss: 2.809942269714446

Epoch: 5| Step: 4
Training loss: 2.12920591712601
Validation loss: 2.8193474329299737

Epoch: 5| Step: 5
Training loss: 2.0392226817620944
Validation loss: 2.774394711405242

Epoch: 5| Step: 6
Training loss: 2.743269399899916
Validation loss: 2.8267215919508115

Epoch: 5| Step: 7
Training loss: 2.6905275192058533
Validation loss: 2.765384883107785

Epoch: 5| Step: 8
Training loss: 2.628350889316224
Validation loss: 2.8114743384965295

Epoch: 5| Step: 9
Training loss: 2.813535118354334
Validation loss: 2.846854589461673

Epoch: 5| Step: 10
Training loss: 2.509899376299853
Validation loss: 2.8525279812317894

Epoch: 118| Step: 0
Training loss: 2.808242627347704
Validation loss: 2.8162477983572147

Epoch: 5| Step: 1
Training loss: 2.7952723679878804
Validation loss: 2.8245783860122615

Epoch: 5| Step: 2
Training loss: 2.52959293709456
Validation loss: 2.8198965492697297

Epoch: 5| Step: 3
Training loss: 1.785458729032232
Validation loss: 2.852954853057939

Epoch: 5| Step: 4
Training loss: 2.162708285670134
Validation loss: 2.8005412986328744

Epoch: 5| Step: 5
Training loss: 3.103536213253768
Validation loss: 2.8329254067256437

Epoch: 5| Step: 6
Training loss: 3.0271144066353646
Validation loss: 2.760737221312823

Epoch: 5| Step: 7
Training loss: 2.7429332099596073
Validation loss: 2.832731750100103

Epoch: 5| Step: 8
Training loss: 2.8063477089232736
Validation loss: 2.8373967902786634

Epoch: 5| Step: 9
Training loss: 2.916072040070907
Validation loss: 2.7775800641429202

Epoch: 5| Step: 10
Training loss: 2.7536724018344585
Validation loss: 2.8080599814459037

Epoch: 119| Step: 0
Training loss: 2.6549372402323854
Validation loss: 2.838676301477036

Epoch: 5| Step: 1
Training loss: 2.3748096590564995
Validation loss: 2.8014617430539706

Epoch: 5| Step: 2
Training loss: 2.8198124238795526
Validation loss: 2.7826369006417018

Epoch: 5| Step: 3
Training loss: 2.2067447442631436
Validation loss: 2.808664787462409

Epoch: 5| Step: 4
Training loss: 2.2436670612105707
Validation loss: 2.7724145199984322

Epoch: 5| Step: 5
Training loss: 3.203650305867917
Validation loss: 2.835162674890687

Epoch: 5| Step: 6
Training loss: 3.410617373337204
Validation loss: 2.8528715110845924

Epoch: 5| Step: 7
Training loss: 2.1492024117739357
Validation loss: 2.8023728669652264

Epoch: 5| Step: 8
Training loss: 3.503152381320357
Validation loss: 2.8604731807487416

Epoch: 5| Step: 9
Training loss: 2.4249368325097866
Validation loss: 2.831865861396495

Epoch: 5| Step: 10
Training loss: 2.60067633121862
Validation loss: 2.8509952005025037

Epoch: 120| Step: 0
Training loss: 2.991419760911885
Validation loss: 2.819197313036298

Epoch: 5| Step: 1
Training loss: 3.125989680931549
Validation loss: 2.779559147902216

Epoch: 5| Step: 2
Training loss: 3.1681033104707033
Validation loss: 2.826012489062965

Epoch: 5| Step: 3
Training loss: 1.9485446169362621
Validation loss: 2.8238876326357962

Epoch: 5| Step: 4
Training loss: 2.6933371561640183
Validation loss: 2.86421943180321

Epoch: 5| Step: 5
Training loss: 2.254038682878165
Validation loss: 2.775553400041129

Epoch: 5| Step: 6
Training loss: 2.2928064344101546
Validation loss: 2.778979549156046

Epoch: 5| Step: 7
Training loss: 2.9553482325538525
Validation loss: 2.797630640162918

Epoch: 5| Step: 8
Training loss: 2.140379954325155
Validation loss: 2.7751424080521354

Epoch: 5| Step: 9
Training loss: 2.545814621061076
Validation loss: 2.8373027008143676

Epoch: 5| Step: 10
Training loss: 3.5190942897365156
Validation loss: 2.834179370692442

Epoch: 121| Step: 0
Training loss: 3.0986471238934397
Validation loss: 2.7910292743706266

Epoch: 5| Step: 1
Training loss: 2.38081290971886
Validation loss: 2.812845399856204

Epoch: 5| Step: 2
Training loss: 3.1626277731915744
Validation loss: 2.7820396910708105

Epoch: 5| Step: 3
Training loss: 2.435954068306788
Validation loss: 2.818060479315426

Epoch: 5| Step: 4
Training loss: 2.3387087710572927
Validation loss: 2.836625648056307

Epoch: 5| Step: 5
Training loss: 2.6551796944651227
Validation loss: 2.789378746796908

Epoch: 5| Step: 6
Training loss: 3.4006483581783997
Validation loss: 2.8440396804689407

Epoch: 5| Step: 7
Training loss: 2.8822507233371866
Validation loss: 2.8225929063392985

Epoch: 5| Step: 8
Training loss: 2.4258201706569698
Validation loss: 2.834824938236542

Epoch: 5| Step: 9
Training loss: 3.1204973971199093
Validation loss: 2.812293222134193

Epoch: 5| Step: 10
Training loss: 1.5957895580028045
Validation loss: 2.8285242212611013

Epoch: 122| Step: 0
Training loss: 2.1531679545022517
Validation loss: 2.779291369613215

Epoch: 5| Step: 1
Training loss: 2.842905275412507
Validation loss: 2.8193234217768612

Epoch: 5| Step: 2
Training loss: 2.52134792865837
Validation loss: 2.8513991163699677

Epoch: 5| Step: 3
Training loss: 2.532292940010515
Validation loss: 2.807768566585809

Epoch: 5| Step: 4
Training loss: 2.836775558688691
Validation loss: 2.8344090812486384

Epoch: 5| Step: 5
Training loss: 2.9407963215361823
Validation loss: 2.7909058801645403

Epoch: 5| Step: 6
Training loss: 2.7070361821293454
Validation loss: 2.7916331343518728

Epoch: 5| Step: 7
Training loss: 2.8301074419418373
Validation loss: 2.8480837934947276

Epoch: 5| Step: 8
Training loss: 2.115537556541412
Validation loss: 2.8275130049444863

Epoch: 5| Step: 9
Training loss: 2.991417848091825
Validation loss: 2.820999588573747

Epoch: 5| Step: 10
Training loss: 3.0237992733129766
Validation loss: 2.7784780727752176

Epoch: 123| Step: 0
Training loss: 2.553606463715014
Validation loss: 2.833500725677157

Epoch: 5| Step: 1
Training loss: 2.522901921080872
Validation loss: 2.8053496277859296

Epoch: 5| Step: 2
Training loss: 2.5704015467097987
Validation loss: 2.799134324114897

Epoch: 5| Step: 3
Training loss: 1.8214267054850106
Validation loss: 2.7511501964612872

Epoch: 5| Step: 4
Training loss: 2.725089563420276
Validation loss: 2.773417495038384

Epoch: 5| Step: 5
Training loss: 3.660383056648433
Validation loss: 2.838805283611455

Epoch: 5| Step: 6
Training loss: 2.985466083579925
Validation loss: 2.8091940643236764

Epoch: 5| Step: 7
Training loss: 2.4161145028902626
Validation loss: 2.8222269139525253

Epoch: 5| Step: 8
Training loss: 2.7244268322026706
Validation loss: 2.804916945106651

Epoch: 5| Step: 9
Training loss: 2.673135917236354
Validation loss: 2.766923663818254

Epoch: 5| Step: 10
Training loss: 2.3639958081668153
Validation loss: 2.784651494540663

Epoch: 124| Step: 0
Training loss: 2.635552132684516
Validation loss: 2.8216474455935714

Epoch: 5| Step: 1
Training loss: 2.654212259792298
Validation loss: 2.784235438843848

Epoch: 5| Step: 2
Training loss: 2.7000324000074682
Validation loss: 2.810572415086979

Epoch: 5| Step: 3
Training loss: 2.331271509475272
Validation loss: 2.796295148071791

Epoch: 5| Step: 4
Training loss: 3.0336875946202717
Validation loss: 2.816493015745712

Epoch: 5| Step: 5
Training loss: 2.872787951453026
Validation loss: 2.8538265494186983

Epoch: 5| Step: 6
Training loss: 2.4969807512903364
Validation loss: 2.8059739413083697

Epoch: 5| Step: 7
Training loss: 2.383579418398102
Validation loss: 2.8139845563558916

Epoch: 5| Step: 8
Training loss: 3.6978709616545373
Validation loss: 2.7346465137413163

Epoch: 5| Step: 9
Training loss: 2.4745230475273696
Validation loss: 2.806184389619186

Epoch: 5| Step: 10
Training loss: 2.4180937751652984
Validation loss: 2.8059873516350926

Epoch: 125| Step: 0
Training loss: 2.781480929613611
Validation loss: 2.8094664772935793

Epoch: 5| Step: 1
Training loss: 2.169769254273544
Validation loss: 2.7884360292582806

Epoch: 5| Step: 2
Training loss: 2.560888015985846
Validation loss: 2.8060516422888373

Epoch: 5| Step: 3
Training loss: 2.417346683283682
Validation loss: 2.7667384588912367

Epoch: 5| Step: 4
Training loss: 2.4740542637479646
Validation loss: 2.806140565413613

Epoch: 5| Step: 5
Training loss: 2.569239708473296
Validation loss: 2.8213162699771797

Epoch: 5| Step: 6
Training loss: 3.2370888938730022
Validation loss: 2.783277380340793

Epoch: 5| Step: 7
Training loss: 2.9296129547807737
Validation loss: 2.805444494651291

Epoch: 5| Step: 8
Training loss: 2.5427542272226376
Validation loss: 2.783382128068651

Epoch: 5| Step: 9
Training loss: 2.855846458325495
Validation loss: 2.8053769277085285

Epoch: 5| Step: 10
Training loss: 3.3511736450830942
Validation loss: 2.787588755311427

Epoch: 126| Step: 0
Training loss: 2.6327825255909163
Validation loss: 2.812832880772811

Epoch: 5| Step: 1
Training loss: 2.2993314932512305
Validation loss: 2.7764685916500986

Epoch: 5| Step: 2
Training loss: 3.2304426236001405
Validation loss: 2.8061629718461263

Epoch: 5| Step: 3
Training loss: 2.933654540710852
Validation loss: 2.782642804319527

Epoch: 5| Step: 4
Training loss: 2.5695381273483235
Validation loss: 2.822900179400976

Epoch: 5| Step: 5
Training loss: 2.7777077051437296
Validation loss: 2.8804297284323854

Epoch: 5| Step: 6
Training loss: 2.5613415588426873
Validation loss: 2.8512439962899685

Epoch: 5| Step: 7
Training loss: 2.3338728235633113
Validation loss: 2.7796598439609084

Epoch: 5| Step: 8
Training loss: 2.476070415333674
Validation loss: 2.760639248722316

Epoch: 5| Step: 9
Training loss: 3.251885967305796
Validation loss: 2.8569374518604906

Epoch: 5| Step: 10
Training loss: 2.1981080199435348
Validation loss: 2.8079101930076473

Epoch: 127| Step: 0
Training loss: 2.6777944745888225
Validation loss: 2.7900072736200934

Epoch: 5| Step: 1
Training loss: 3.2770178249736928
Validation loss: 2.8193318888096774

Epoch: 5| Step: 2
Training loss: 2.16773438432674
Validation loss: 2.7957289398521024

Epoch: 5| Step: 3
Training loss: 3.3369289238218967
Validation loss: 2.7922781573172717

Epoch: 5| Step: 4
Training loss: 2.3807555278508405
Validation loss: 2.7892033547228756

Epoch: 5| Step: 5
Training loss: 2.5471081773230764
Validation loss: 2.816979133743101

Epoch: 5| Step: 6
Training loss: 2.54069677723072
Validation loss: 2.7916974405922903

Epoch: 5| Step: 7
Training loss: 2.8427984301439158
Validation loss: 2.8103512644433453

Epoch: 5| Step: 8
Training loss: 2.6805810800851373
Validation loss: 2.834217232852494

Epoch: 5| Step: 9
Training loss: 2.9353397623731476
Validation loss: 2.8499984490779506

Epoch: 5| Step: 10
Training loss: 2.1425478575801953
Validation loss: 2.7763686722938914

Epoch: 128| Step: 0
Training loss: 3.0973206539127163
Validation loss: 2.7972065929598022

Epoch: 5| Step: 1
Training loss: 3.111693778046767
Validation loss: 2.810060209904229

Epoch: 5| Step: 2
Training loss: 3.5062219628829734
Validation loss: 2.8174722906359655

Epoch: 5| Step: 3
Training loss: 2.196233047307024
Validation loss: 2.754636993307209

Epoch: 5| Step: 4
Training loss: 2.4712880282835896
Validation loss: 2.7652247464684736

Epoch: 5| Step: 5
Training loss: 2.546648542013465
Validation loss: 2.7865646702361775

Epoch: 5| Step: 6
Training loss: 2.2283215450792015
Validation loss: 2.8178962558571197

Epoch: 5| Step: 7
Training loss: 1.8308783769282753
Validation loss: 2.809135052024959

Epoch: 5| Step: 8
Training loss: 2.746663757464649
Validation loss: 2.7191135096058656

Epoch: 5| Step: 9
Training loss: 2.3493152919528315
Validation loss: 2.7762068537120452

Epoch: 5| Step: 10
Training loss: 3.0326119735436117
Validation loss: 2.849677568276017

Epoch: 129| Step: 0
Training loss: 2.5841635528745797
Validation loss: 2.758258822390499

Epoch: 5| Step: 1
Training loss: 2.203777676482653
Validation loss: 2.768103526034229

Epoch: 5| Step: 2
Training loss: 3.2293427614168384
Validation loss: 2.799615947399106

Epoch: 5| Step: 3
Training loss: 2.1024819103646633
Validation loss: 2.817748516071393

Epoch: 5| Step: 4
Training loss: 2.9476003488375566
Validation loss: 2.797532069099688

Epoch: 5| Step: 5
Training loss: 2.828519509129359
Validation loss: 2.811133039979289

Epoch: 5| Step: 6
Training loss: 2.7270329897444476
Validation loss: 2.829521330792026

Epoch: 5| Step: 7
Training loss: 3.0398873825294768
Validation loss: 2.7802479399662112

Epoch: 5| Step: 8
Training loss: 3.09988165598752
Validation loss: 2.819399478216406

Epoch: 5| Step: 9
Training loss: 2.2153070089815925
Validation loss: 2.786770166830247

Epoch: 5| Step: 10
Training loss: 2.6275811901669544
Validation loss: 2.771255359866773

Epoch: 130| Step: 0
Training loss: 2.1090482105444233
Validation loss: 2.8319376603087645

Epoch: 5| Step: 1
Training loss: 1.7784966722295867
Validation loss: 2.7920547941627536

Epoch: 5| Step: 2
Training loss: 2.7893679155092665
Validation loss: 2.819537386259901

Epoch: 5| Step: 3
Training loss: 3.8062205897605934
Validation loss: 2.8017729833496965

Epoch: 5| Step: 4
Training loss: 2.4355030193525504
Validation loss: 2.801159554364974

Epoch: 5| Step: 5
Training loss: 2.134354365906734
Validation loss: 2.8083266383192576

Epoch: 5| Step: 6
Training loss: 2.202245442015363
Validation loss: 2.768456053504617

Epoch: 5| Step: 7
Training loss: 2.891996316139756
Validation loss: 2.801322368606908

Epoch: 5| Step: 8
Training loss: 3.8270948619942304
Validation loss: 2.7863339006580627

Epoch: 5| Step: 9
Training loss: 1.932830598294662
Validation loss: 2.815684884970429

Epoch: 5| Step: 10
Training loss: 2.8537006044060407
Validation loss: 2.811862137630527

Epoch: 131| Step: 0
Training loss: 2.5605483647974308
Validation loss: 2.7875245704121654

Epoch: 5| Step: 1
Training loss: 2.718330701744479
Validation loss: 2.7251514370908976

Epoch: 5| Step: 2
Training loss: 2.692542734471103
Validation loss: 2.829624649322609

Epoch: 5| Step: 3
Training loss: 3.3652994124138305
Validation loss: 2.79082808544098

Epoch: 5| Step: 4
Training loss: 2.877444679132811
Validation loss: 2.7505581802952026

Epoch: 5| Step: 5
Training loss: 3.1122394192246334
Validation loss: 2.8193547509897545

Epoch: 5| Step: 6
Training loss: 2.5892265125140113
Validation loss: 2.789484938061051

Epoch: 5| Step: 7
Training loss: 1.5922236145535795
Validation loss: 2.828070025039168

Epoch: 5| Step: 8
Training loss: 1.6825978460102449
Validation loss: 2.769857608764376

Epoch: 5| Step: 9
Training loss: 3.439250985595402
Validation loss: 2.8120367892434555

Epoch: 5| Step: 10
Training loss: 2.6606339125229694
Validation loss: 2.7940448514823175

Epoch: 132| Step: 0
Training loss: 2.843796446703885
Validation loss: 2.8025490411576675

Epoch: 5| Step: 1
Training loss: 2.8567070526449414
Validation loss: 2.765640366274442

Epoch: 5| Step: 2
Training loss: 2.4766516443809263
Validation loss: 2.7632582854736563

Epoch: 5| Step: 3
Training loss: 2.7628522864062504
Validation loss: 2.835251772749756

Epoch: 5| Step: 4
Training loss: 2.2996174535646703
Validation loss: 2.832451520887836

Epoch: 5| Step: 5
Training loss: 2.1563597941433836
Validation loss: 2.8110995024535255

Epoch: 5| Step: 6
Training loss: 2.5616116728512526
Validation loss: 2.7918622051430395

Epoch: 5| Step: 7
Training loss: 2.75017243624971
Validation loss: 2.7798700461456667

Epoch: 5| Step: 8
Training loss: 2.403920222388403
Validation loss: 2.7766181165523487

Epoch: 5| Step: 9
Training loss: 3.187446144995409
Validation loss: 2.790377067553418

Epoch: 5| Step: 10
Training loss: 2.9843422453515847
Validation loss: 2.809335868006543

Epoch: 133| Step: 0
Training loss: 2.493823336715597
Validation loss: 2.772349175585053

Epoch: 5| Step: 1
Training loss: 3.4489080995530452
Validation loss: 2.800569710952469

Epoch: 5| Step: 2
Training loss: 3.372258803874284
Validation loss: 2.8103069820537274

Epoch: 5| Step: 3
Training loss: 2.4867555740798664
Validation loss: 2.7996994425638344

Epoch: 5| Step: 4
Training loss: 2.7336327117472043
Validation loss: 2.7996463726654666

Epoch: 5| Step: 5
Training loss: 2.4992280722012272
Validation loss: 2.823771510136858

Epoch: 5| Step: 6
Training loss: 2.444879658083601
Validation loss: 2.790122450997509

Epoch: 5| Step: 7
Training loss: 2.591865038460528
Validation loss: 2.8105589869591108

Epoch: 5| Step: 8
Training loss: 2.4226998185930384
Validation loss: 2.8521589746816574

Epoch: 5| Step: 9
Training loss: 1.6819128155151624
Validation loss: 2.8069030838583675

Epoch: 5| Step: 10
Training loss: 2.7630139110213614
Validation loss: 2.786177620343903

Epoch: 134| Step: 0
Training loss: 2.4587841482656527
Validation loss: 2.7766807831819738

Epoch: 5| Step: 1
Training loss: 2.946335996684507
Validation loss: 2.764264420429318

Epoch: 5| Step: 2
Training loss: 2.833378249167669
Validation loss: 2.8178449970664112

Epoch: 5| Step: 3
Training loss: 3.2813969170513166
Validation loss: 2.7791781938410995

Epoch: 5| Step: 4
Training loss: 2.0124408499987405
Validation loss: 2.790522156339694

Epoch: 5| Step: 5
Training loss: 2.562489300217038
Validation loss: 2.776669465189294

Epoch: 5| Step: 6
Training loss: 2.686691073724082
Validation loss: 2.8001048452257855

Epoch: 5| Step: 7
Training loss: 2.2069822052764128
Validation loss: 2.794547236031201

Epoch: 5| Step: 8
Training loss: 2.4447320121136933
Validation loss: 2.7701160906781936

Epoch: 5| Step: 9
Training loss: 3.223046407490346
Validation loss: 2.7914254168934596

Epoch: 5| Step: 10
Training loss: 2.5822881204371217
Validation loss: 2.786694095648014

Epoch: 135| Step: 0
Training loss: 2.510154130010484
Validation loss: 2.7551662862820425

Epoch: 5| Step: 1
Training loss: 3.162384718652152
Validation loss: 2.7645749883849344

Epoch: 5| Step: 2
Training loss: 2.4919645873442176
Validation loss: 2.8037990296589768

Epoch: 5| Step: 3
Training loss: 3.028963465392512
Validation loss: 2.7902708394957245

Epoch: 5| Step: 4
Training loss: 2.3904276249008074
Validation loss: 2.784092457997441

Epoch: 5| Step: 5
Training loss: 2.82022077670164
Validation loss: 2.7844386545879076

Epoch: 5| Step: 6
Training loss: 3.136841273973005
Validation loss: 2.7475763531151505

Epoch: 5| Step: 7
Training loss: 2.3203771306037213
Validation loss: 2.76844783230301

Epoch: 5| Step: 8
Training loss: 2.560591102992122
Validation loss: 2.809327383166088

Epoch: 5| Step: 9
Training loss: 2.6932533248814274
Validation loss: 2.7836532570157466

Epoch: 5| Step: 10
Training loss: 2.060226111733789
Validation loss: 2.777934145132482

Epoch: 136| Step: 0
Training loss: 2.5175602263412915
Validation loss: 2.813728384208058

Epoch: 5| Step: 1
Training loss: 2.885971860572637
Validation loss: 2.779811218286759

Epoch: 5| Step: 2
Training loss: 2.240387409972913
Validation loss: 2.787337495891841

Epoch: 5| Step: 3
Training loss: 3.226720625949015
Validation loss: 2.8324661218594085

Epoch: 5| Step: 4
Training loss: 2.005860801332258
Validation loss: 2.7598982104494385

Epoch: 5| Step: 5
Training loss: 3.1512997019811593
Validation loss: 2.795726983923074

Epoch: 5| Step: 6
Training loss: 2.3999028901480814
Validation loss: 2.834503547141386

Epoch: 5| Step: 7
Training loss: 2.665521037857191
Validation loss: 2.76960244797337

Epoch: 5| Step: 8
Training loss: 2.4194857717790588
Validation loss: 2.7850369302443276

Epoch: 5| Step: 9
Training loss: 2.816020203691312
Validation loss: 2.7851265721886542

Epoch: 5| Step: 10
Training loss: 3.032863226991566
Validation loss: 2.8193103876887786

Epoch: 137| Step: 0
Training loss: 2.571018666944837
Validation loss: 2.8086017240734305

Epoch: 5| Step: 1
Training loss: 2.6562767476249807
Validation loss: 2.7823274752979894

Epoch: 5| Step: 2
Training loss: 2.4689692146418354
Validation loss: 2.781619546196078

Epoch: 5| Step: 3
Training loss: 3.1241679800591635
Validation loss: 2.837557648161734

Epoch: 5| Step: 4
Training loss: 2.4768841170615565
Validation loss: 2.8279130042986695

Epoch: 5| Step: 5
Training loss: 3.0345560508953184
Validation loss: 2.767746592854859

Epoch: 5| Step: 6
Training loss: 2.673727363822319
Validation loss: 2.758456013118159

Epoch: 5| Step: 7
Training loss: 2.1968494614572323
Validation loss: 2.755277884520228

Epoch: 5| Step: 8
Training loss: 2.69464315313128
Validation loss: 2.7996211522986707

Epoch: 5| Step: 9
Training loss: 2.2231970264948906
Validation loss: 2.8087368399183985

Epoch: 5| Step: 10
Training loss: 3.0654313985838644
Validation loss: 2.797570234802257

Epoch: 138| Step: 0
Training loss: 3.230135290424505
Validation loss: 2.727597024240348

Epoch: 5| Step: 1
Training loss: 2.251802464231963
Validation loss: 2.7382617596497347

Epoch: 5| Step: 2
Training loss: 2.425525891412943
Validation loss: 2.7761718230654813

Epoch: 5| Step: 3
Training loss: 2.9505641268555767
Validation loss: 2.7359421418658147

Epoch: 5| Step: 4
Training loss: 3.0346881991607453
Validation loss: 2.8263481176971332

Epoch: 5| Step: 5
Training loss: 2.3144075928406256
Validation loss: 2.7690742183033294

Epoch: 5| Step: 6
Training loss: 3.0675126139063567
Validation loss: 2.7822291876667724

Epoch: 5| Step: 7
Training loss: 2.714461704514521
Validation loss: 2.8003110070521116

Epoch: 5| Step: 8
Training loss: 2.556326337574537
Validation loss: 2.7996909193620243

Epoch: 5| Step: 9
Training loss: 2.1795399386865646
Validation loss: 2.7926448699344415

Epoch: 5| Step: 10
Training loss: 2.3027778601969158
Validation loss: 2.7694485726354556

Epoch: 139| Step: 0
Training loss: 2.389059514105598
Validation loss: 2.765991261769066

Epoch: 5| Step: 1
Training loss: 2.3914294915003
Validation loss: 2.787487132600405

Epoch: 5| Step: 2
Training loss: 3.043633874326823
Validation loss: 2.870454237852787

Epoch: 5| Step: 3
Training loss: 2.522984703232293
Validation loss: 2.816216374044925

Epoch: 5| Step: 4
Training loss: 2.49061491807455
Validation loss: 2.800585166518129

Epoch: 5| Step: 5
Training loss: 2.4479583953114443
Validation loss: 2.8300394302300353

Epoch: 5| Step: 6
Training loss: 3.354721323597026
Validation loss: 2.759584291089428

Epoch: 5| Step: 7
Training loss: 2.531424245606152
Validation loss: 2.792848879135443

Epoch: 5| Step: 8
Training loss: 2.6071138921573196
Validation loss: 2.8196338260467733

Epoch: 5| Step: 9
Training loss: 2.5457154425146995
Validation loss: 2.8316598404113855

Epoch: 5| Step: 10
Training loss: 2.825584999211412
Validation loss: 2.837509166787108

Epoch: 140| Step: 0
Training loss: 3.2214240660468256
Validation loss: 2.8012339404813384

Epoch: 5| Step: 1
Training loss: 2.687529807701704
Validation loss: 2.811760930859861

Epoch: 5| Step: 2
Training loss: 2.749571073200031
Validation loss: 2.8059189069513373

Epoch: 5| Step: 3
Training loss: 2.3787102078243194
Validation loss: 2.803893407713049

Epoch: 5| Step: 4
Training loss: 3.2138232700774796
Validation loss: 2.755581745312304

Epoch: 5| Step: 5
Training loss: 2.763025991499122
Validation loss: 2.792957562723149

Epoch: 5| Step: 6
Training loss: 2.1831235430538145
Validation loss: 2.7193479360167

Epoch: 5| Step: 7
Training loss: 2.881120883257992
Validation loss: 2.7595394667056703

Epoch: 5| Step: 8
Training loss: 2.110637145906925
Validation loss: 2.793412031350524

Epoch: 5| Step: 9
Training loss: 2.449746496359029
Validation loss: 2.77290092291152

Epoch: 5| Step: 10
Training loss: 2.5113106450932046
Validation loss: 2.7848123814679204

Epoch: 141| Step: 0
Training loss: 2.712902049843204
Validation loss: 2.8334388357374003

Epoch: 5| Step: 1
Training loss: 3.1956846584732617
Validation loss: 2.7582155918616196

Epoch: 5| Step: 2
Training loss: 2.5566577837945967
Validation loss: 2.7796373068952076

Epoch: 5| Step: 3
Training loss: 2.6198438230951226
Validation loss: 2.7993886219367043

Epoch: 5| Step: 4
Training loss: 2.586546673433065
Validation loss: 2.803446388365559

Epoch: 5| Step: 5
Training loss: 1.9985702888090533
Validation loss: 2.809318928414117

Epoch: 5| Step: 6
Training loss: 2.857899436233205
Validation loss: 2.823467632395115

Epoch: 5| Step: 7
Training loss: 2.293789510360656
Validation loss: 2.768025709595166

Epoch: 5| Step: 8
Training loss: 2.8336072864109227
Validation loss: 2.7904779014994237

Epoch: 5| Step: 9
Training loss: 3.034594706036908
Validation loss: 2.7636944930952927

Epoch: 5| Step: 10
Training loss: 2.24364485215357
Validation loss: 2.768139137127851

Epoch: 142| Step: 0
Training loss: 2.0219257849516374
Validation loss: 2.788773617286956

Epoch: 5| Step: 1
Training loss: 2.657568301510078
Validation loss: 2.7882797674674165

Epoch: 5| Step: 2
Training loss: 2.573460931908682
Validation loss: 2.7867999945641984

Epoch: 5| Step: 3
Training loss: 2.833303526179283
Validation loss: 2.8475569672239214

Epoch: 5| Step: 4
Training loss: 2.867523090565577
Validation loss: 2.7820409940669615

Epoch: 5| Step: 5
Training loss: 2.6478584129074365
Validation loss: 2.7632676521232105

Epoch: 5| Step: 6
Training loss: 2.9913046707277537
Validation loss: 2.7955371853584463

Epoch: 5| Step: 7
Training loss: 2.5846294310121705
Validation loss: 2.778053639841317

Epoch: 5| Step: 8
Training loss: 2.867395377873752
Validation loss: 2.8390159666013233

Epoch: 5| Step: 9
Training loss: 2.153454834764898
Validation loss: 2.7640359247206865

Epoch: 5| Step: 10
Training loss: 2.713093540630544
Validation loss: 2.772589577919596

Epoch: 143| Step: 0
Training loss: 2.9065776353144024
Validation loss: 2.803719824287691

Epoch: 5| Step: 1
Training loss: 3.015834030259505
Validation loss: 2.8518263621286803

Epoch: 5| Step: 2
Training loss: 2.332311565478411
Validation loss: 2.7632068100835396

Epoch: 5| Step: 3
Training loss: 2.0856718544273893
Validation loss: 2.727173242940582

Epoch: 5| Step: 4
Training loss: 3.522657219198622
Validation loss: 2.746148657659359

Epoch: 5| Step: 5
Training loss: 2.2771405346925757
Validation loss: 2.8209120321950554

Epoch: 5| Step: 6
Training loss: 2.1801492618942824
Validation loss: 2.7815046314844354

Epoch: 5| Step: 7
Training loss: 2.431515806127527
Validation loss: 2.8176955404626765

Epoch: 5| Step: 8
Training loss: 2.5321713878124164
Validation loss: 2.8438427538227167

Epoch: 5| Step: 9
Training loss: 2.8691582416281833
Validation loss: 2.769501847221675

Epoch: 5| Step: 10
Training loss: 2.8543177840794476
Validation loss: 2.811659012897801

Epoch: 144| Step: 0
Training loss: 2.671799597317568
Validation loss: 2.823515695691624

Epoch: 5| Step: 1
Training loss: 2.9367304666482816
Validation loss: 2.8139837482670322

Epoch: 5| Step: 2
Training loss: 2.078362702277155
Validation loss: 2.83133542257665

Epoch: 5| Step: 3
Training loss: 2.118422032181762
Validation loss: 2.8018199740320955

Epoch: 5| Step: 4
Training loss: 2.2176963560952467
Validation loss: 2.8059098946481744

Epoch: 5| Step: 5
Training loss: 3.0158713442734855
Validation loss: 2.7928627985959666

Epoch: 5| Step: 6
Training loss: 2.9223051519516314
Validation loss: 2.8032003383463

Epoch: 5| Step: 7
Training loss: 2.3404515771320504
Validation loss: 2.781411038979378

Epoch: 5| Step: 8
Training loss: 2.985103658029672
Validation loss: 2.7966434238294275

Epoch: 5| Step: 9
Training loss: 2.0165817001140476
Validation loss: 2.770705304706528

Epoch: 5| Step: 10
Training loss: 3.456601011584023
Validation loss: 2.730479737000807

Epoch: 145| Step: 0
Training loss: 3.087372651350281
Validation loss: 2.829391239535845

Epoch: 5| Step: 1
Training loss: 2.6814511559352074
Validation loss: 2.7625892848568734

Epoch: 5| Step: 2
Training loss: 2.4292506962981584
Validation loss: 2.830660776228984

Epoch: 5| Step: 3
Training loss: 3.174047167922105
Validation loss: 2.7952379403822176

Epoch: 5| Step: 4
Training loss: 1.8232148571448514
Validation loss: 2.7626203879455407

Epoch: 5| Step: 5
Training loss: 3.281443417615964
Validation loss: 2.7642885583457226

Epoch: 5| Step: 6
Training loss: 2.937755005501833
Validation loss: 2.784912192569374

Epoch: 5| Step: 7
Training loss: 2.549652457395599
Validation loss: 2.754396222879638

Epoch: 5| Step: 8
Training loss: 2.628300363176223
Validation loss: 2.7981514084249617

Epoch: 5| Step: 9
Training loss: 2.055596444293182
Validation loss: 2.8026123276415693

Epoch: 5| Step: 10
Training loss: 1.946454367960401
Validation loss: 2.8007378675727086

Epoch: 146| Step: 0
Training loss: 2.111516360097345
Validation loss: 2.8134216074743157

Epoch: 5| Step: 1
Training loss: 3.096323195490519
Validation loss: 2.7725583379368848

Epoch: 5| Step: 2
Training loss: 1.9186995409565295
Validation loss: 2.7954810321365153

Epoch: 5| Step: 3
Training loss: 2.5078983470448133
Validation loss: 2.793160421075148

Epoch: 5| Step: 4
Training loss: 2.8751791193353013
Validation loss: 2.803591528673625

Epoch: 5| Step: 5
Training loss: 2.621565251928166
Validation loss: 2.7539520494918417

Epoch: 5| Step: 6
Training loss: 3.150892791173595
Validation loss: 2.754095992841407

Epoch: 5| Step: 7
Training loss: 2.3422173129799773
Validation loss: 2.719322714751312

Epoch: 5| Step: 8
Training loss: 2.675635563580717
Validation loss: 2.7491229393587786

Epoch: 5| Step: 9
Training loss: 2.715645782777476
Validation loss: 2.8226090451172707

Epoch: 5| Step: 10
Training loss: 2.968120789355217
Validation loss: 2.7872876139774574

Epoch: 147| Step: 0
Training loss: 3.2199835034060396
Validation loss: 2.7499321959965846

Epoch: 5| Step: 1
Training loss: 3.251429023551095
Validation loss: 2.7506874237693215

Epoch: 5| Step: 2
Training loss: 1.8668510101891862
Validation loss: 2.7655552375049584

Epoch: 5| Step: 3
Training loss: 2.418949156455111
Validation loss: 2.748076033427873

Epoch: 5| Step: 4
Training loss: 3.492708922508517
Validation loss: 2.829499055874914

Epoch: 5| Step: 5
Training loss: 3.280175169244804
Validation loss: 2.770659294525476

Epoch: 5| Step: 6
Training loss: 2.3322144505092286
Validation loss: 2.815258010118519

Epoch: 5| Step: 7
Training loss: 1.6448856071653706
Validation loss: 2.796559619245509

Epoch: 5| Step: 8
Training loss: 2.718038707072983
Validation loss: 2.7826949363466422

Epoch: 5| Step: 9
Training loss: 1.8932846529952796
Validation loss: 2.795813385530831

Epoch: 5| Step: 10
Training loss: 2.087884801244509
Validation loss: 2.749998499104527

Epoch: 148| Step: 0
Training loss: 2.230887512339518
Validation loss: 2.8151779023234664

Epoch: 5| Step: 1
Training loss: 2.772670156143584
Validation loss: 2.7609748528276516

Epoch: 5| Step: 2
Training loss: 2.825153707863163
Validation loss: 2.752308669767341

Epoch: 5| Step: 3
Training loss: 2.8144133946872603
Validation loss: 2.810916399202651

Epoch: 5| Step: 4
Training loss: 2.600143641392064
Validation loss: 2.810412539443184

Epoch: 5| Step: 5
Training loss: 2.892076777271365
Validation loss: 2.740734651179029

Epoch: 5| Step: 6
Training loss: 2.342380886733918
Validation loss: 2.7742490055801707

Epoch: 5| Step: 7
Training loss: 2.568206202359802
Validation loss: 2.8004494211887243

Epoch: 5| Step: 8
Training loss: 3.1013852316214177
Validation loss: 2.76983118604802

Epoch: 5| Step: 9
Training loss: 3.000536234932609
Validation loss: 2.70960456855933

Epoch: 5| Step: 10
Training loss: 1.814421654501201
Validation loss: 2.7754048444696813

Epoch: 149| Step: 0
Training loss: 2.3410015012205867
Validation loss: 2.821584241703655

Epoch: 5| Step: 1
Training loss: 2.208792788615159
Validation loss: 2.7792671327757366

Epoch: 5| Step: 2
Training loss: 2.68571572622591
Validation loss: 2.7933143806308927

Epoch: 5| Step: 3
Training loss: 2.600501133234019
Validation loss: 2.7530740148765482

Epoch: 5| Step: 4
Training loss: 3.1365718973446017
Validation loss: 2.8012129909574943

Epoch: 5| Step: 5
Training loss: 2.654673209328718
Validation loss: 2.778813689551164

Epoch: 5| Step: 6
Training loss: 2.80479630708163
Validation loss: 2.77370157840515

Epoch: 5| Step: 7
Training loss: 2.5627257084880934
Validation loss: 2.797478289104763

Epoch: 5| Step: 8
Training loss: 2.515592586711309
Validation loss: 2.74766131954781

Epoch: 5| Step: 9
Training loss: 3.047389060450666
Validation loss: 2.7737583268897055

Epoch: 5| Step: 10
Training loss: 2.3989194702587198
Validation loss: 2.828945222492995

Epoch: 150| Step: 0
Training loss: 2.5429299347196075
Validation loss: 2.8146758546787343

Epoch: 5| Step: 1
Training loss: 2.099334216163202
Validation loss: 2.7304563761918432

Epoch: 5| Step: 2
Training loss: 2.9017083562244017
Validation loss: 2.732136904626123

Epoch: 5| Step: 3
Training loss: 2.1285153651329214
Validation loss: 2.7857657303887238

Epoch: 5| Step: 4
Training loss: 2.0640163049719207
Validation loss: 2.838161009844588

Epoch: 5| Step: 5
Training loss: 3.219000797315477
Validation loss: 2.721019229255533

Epoch: 5| Step: 6
Training loss: 2.9395095769080894
Validation loss: 2.790689540427626

Epoch: 5| Step: 7
Training loss: 2.8996556439331815
Validation loss: 2.764476697402205

Epoch: 5| Step: 8
Training loss: 3.1990819210093857
Validation loss: 2.7653422358544972

Epoch: 5| Step: 9
Training loss: 2.784924940265464
Validation loss: 2.772819694030907

Epoch: 5| Step: 10
Training loss: 2.367832108660981
Validation loss: 2.827110845206873

Epoch: 151| Step: 0
Training loss: 2.816041877868679
Validation loss: 2.7500249203385296

Epoch: 5| Step: 1
Training loss: 2.185750097894999
Validation loss: 2.756767256837181

Epoch: 5| Step: 2
Training loss: 2.406123963064822
Validation loss: 2.7358519687852323

Epoch: 5| Step: 3
Training loss: 2.583995447113467
Validation loss: 2.8354046131464417

Epoch: 5| Step: 4
Training loss: 2.4895535604274146
Validation loss: 2.7741467426512525

Epoch: 5| Step: 5
Training loss: 2.788791931876693
Validation loss: 2.833983521051352

Epoch: 5| Step: 6
Training loss: 2.6937429972334113
Validation loss: 2.7245974083476416

Epoch: 5| Step: 7
Training loss: 2.97283525968076
Validation loss: 2.8169208260368768

Epoch: 5| Step: 8
Training loss: 2.670843449502514
Validation loss: 2.8068848518214784

Epoch: 5| Step: 9
Training loss: 2.848190194765631
Validation loss: 2.7612861779205518

Epoch: 5| Step: 10
Training loss: 2.8520858493419516
Validation loss: 2.7728323845246

Epoch: 152| Step: 0
Training loss: 2.5887822756373886
Validation loss: 2.806155602939643

Epoch: 5| Step: 1
Training loss: 2.340083700623042
Validation loss: 2.7517731432596024

Epoch: 5| Step: 2
Training loss: 2.087619631874177
Validation loss: 2.7832369977512204

Epoch: 5| Step: 3
Training loss: 2.6130150173265223
Validation loss: 2.775090676418612

Epoch: 5| Step: 4
Training loss: 2.2717864343310197
Validation loss: 2.7677470235636545

Epoch: 5| Step: 5
Training loss: 3.4999208441366454
Validation loss: 2.7803690788307045

Epoch: 5| Step: 6
Training loss: 2.9343270554855825
Validation loss: 2.757849410135803

Epoch: 5| Step: 7
Training loss: 2.352289334633511
Validation loss: 2.772649296846576

Epoch: 5| Step: 8
Training loss: 2.427609158859789
Validation loss: 2.7547112006385146

Epoch: 5| Step: 9
Training loss: 2.9618036216221695
Validation loss: 2.7735500758269223

Epoch: 5| Step: 10
Training loss: 2.656309329099601
Validation loss: 2.837343985452652

Epoch: 153| Step: 0
Training loss: 2.7744603809436574
Validation loss: 2.8078205726722008

Epoch: 5| Step: 1
Training loss: 2.8327831033232376
Validation loss: 2.740327398485491

Epoch: 5| Step: 2
Training loss: 2.5832306215930347
Validation loss: 2.7994144726218013

Epoch: 5| Step: 3
Training loss: 3.3844548350716175
Validation loss: 2.8287484753046477

Epoch: 5| Step: 4
Training loss: 2.173791273272542
Validation loss: 2.766683376092288

Epoch: 5| Step: 5
Training loss: 3.35891791494317
Validation loss: 2.758326986798961

Epoch: 5| Step: 6
Training loss: 2.754236339509246
Validation loss: 2.7165816036379953

Epoch: 5| Step: 7
Training loss: 2.2318559865534233
Validation loss: 2.813542211891947

Epoch: 5| Step: 8
Training loss: 1.536971477444929
Validation loss: 2.7551653604494084

Epoch: 5| Step: 9
Training loss: 2.3627253107079254
Validation loss: 2.782288327438176

Epoch: 5| Step: 10
Training loss: 2.1435303289119974
Validation loss: 2.810717695456827

Epoch: 154| Step: 0
Training loss: 2.482533858299818
Validation loss: 2.8053771369758387

Epoch: 5| Step: 1
Training loss: 2.4953348501562465
Validation loss: 2.705745672612851

Epoch: 5| Step: 2
Training loss: 2.6343664456519345
Validation loss: 2.756935112759518

Epoch: 5| Step: 3
Training loss: 2.463324463982761
Validation loss: 2.7589008552216834

Epoch: 5| Step: 4
Training loss: 2.5242535006965543
Validation loss: 2.756719169451018

Epoch: 5| Step: 5
Training loss: 1.9348342769341302
Validation loss: 2.8044933332204214

Epoch: 5| Step: 6
Training loss: 3.0807279628171957
Validation loss: 2.7859425747189968

Epoch: 5| Step: 7
Training loss: 2.7099500281311943
Validation loss: 2.7536922895645524

Epoch: 5| Step: 8
Training loss: 2.954712294823004
Validation loss: 2.7850872565637284

Epoch: 5| Step: 9
Training loss: 3.015882411900721
Validation loss: 2.7887713678282244

Epoch: 5| Step: 10
Training loss: 2.239984367009516
Validation loss: 2.7566699638584558

Epoch: 155| Step: 0
Training loss: 2.9777450014875817
Validation loss: 2.787123146520096

Epoch: 5| Step: 1
Training loss: 2.5926170172625698
Validation loss: 2.770188387849175

Epoch: 5| Step: 2
Training loss: 2.222602937457889
Validation loss: 2.7996652900807057

Epoch: 5| Step: 3
Training loss: 2.718046426170255
Validation loss: 2.762962864388726

Epoch: 5| Step: 4
Training loss: 3.0726818620015384
Validation loss: 2.7905846269463255

Epoch: 5| Step: 5
Training loss: 2.801958717118313
Validation loss: 2.759747009096118

Epoch: 5| Step: 6
Training loss: 2.574244497630624
Validation loss: 2.8182255510181657

Epoch: 5| Step: 7
Training loss: 2.304914146529079
Validation loss: 2.8002748662469683

Epoch: 5| Step: 8
Training loss: 2.3410703472206866
Validation loss: 2.8138560080922206

Epoch: 5| Step: 9
Training loss: 2.4214798143432814
Validation loss: 2.8405009625797706

Epoch: 5| Step: 10
Training loss: 2.834284192768251
Validation loss: 2.724459839821153

Epoch: 156| Step: 0
Training loss: 2.7748388913787245
Validation loss: 2.783512747726251

Epoch: 5| Step: 1
Training loss: 2.2937807793072307
Validation loss: 2.7723581481073643

Epoch: 5| Step: 2
Training loss: 2.8914223061100066
Validation loss: 2.7850718567494828

Epoch: 5| Step: 3
Training loss: 2.936092445300569
Validation loss: 2.729429765081026

Epoch: 5| Step: 4
Training loss: 1.9199026888784163
Validation loss: 2.7738036128244

Epoch: 5| Step: 5
Training loss: 2.8171186035668607
Validation loss: 2.755407222021541

Epoch: 5| Step: 6
Training loss: 2.3369991479887613
Validation loss: 2.8319945046513086

Epoch: 5| Step: 7
Training loss: 2.9978658714701023
Validation loss: 2.7830429842231186

Epoch: 5| Step: 8
Training loss: 2.4906274582528845
Validation loss: 2.775504138564352

Epoch: 5| Step: 9
Training loss: 2.6538096269115976
Validation loss: 2.6971977081400875

Epoch: 5| Step: 10
Training loss: 2.949061752081555
Validation loss: 2.7449438938586104

Epoch: 157| Step: 0
Training loss: 2.641823942233898
Validation loss: 2.806955284076926

Epoch: 5| Step: 1
Training loss: 3.550581688303676
Validation loss: 2.74741220512619

Epoch: 5| Step: 2
Training loss: 2.0576913437337145
Validation loss: 2.8056725227833152

Epoch: 5| Step: 3
Training loss: 3.11526376357611
Validation loss: 2.773987689885729

Epoch: 5| Step: 4
Training loss: 2.20489701235988
Validation loss: 2.7931485163626677

Epoch: 5| Step: 5
Training loss: 2.2378687719848545
Validation loss: 2.8117131124843397

Epoch: 5| Step: 6
Training loss: 2.648040921837192
Validation loss: 2.7797284187489257

Epoch: 5| Step: 7
Training loss: 3.248703037581552
Validation loss: 2.755273116904571

Epoch: 5| Step: 8
Training loss: 2.2410368941137064
Validation loss: 2.7589306116448595

Epoch: 5| Step: 9
Training loss: 2.364777197151814
Validation loss: 2.801117514019181

Epoch: 5| Step: 10
Training loss: 2.3186435027227676
Validation loss: 2.7899954900676827

Epoch: 158| Step: 0
Training loss: 2.4703485649125563
Validation loss: 2.793192513662032

Epoch: 5| Step: 1
Training loss: 2.9532830735946667
Validation loss: 2.814364634860933

Epoch: 5| Step: 2
Training loss: 2.7649662935985906
Validation loss: 2.789791735350655

Epoch: 5| Step: 3
Training loss: 2.023083747959368
Validation loss: 2.775858652439238

Epoch: 5| Step: 4
Training loss: 2.380289411659443
Validation loss: 2.7270863643829224

Epoch: 5| Step: 5
Training loss: 3.381601870238611
Validation loss: 2.724276551114504

Epoch: 5| Step: 6
Training loss: 2.5051447383768637
Validation loss: 2.7557581730080165

Epoch: 5| Step: 7
Training loss: 2.125848825005231
Validation loss: 2.8025131990695424

Epoch: 5| Step: 8
Training loss: 2.801394513822788
Validation loss: 2.7543997587777933

Epoch: 5| Step: 9
Training loss: 2.2351928494605975
Validation loss: 2.735342543566257

Epoch: 5| Step: 10
Training loss: 2.571874914713936
Validation loss: 2.796760870692013

Epoch: 159| Step: 0
Training loss: 2.2131705178656937
Validation loss: 2.7738296261624193

Epoch: 5| Step: 1
Training loss: 2.773606673977692
Validation loss: 2.7604677764810788

Epoch: 5| Step: 2
Training loss: 2.7813616098019294
Validation loss: 2.7445487059853506

Epoch: 5| Step: 3
Training loss: 2.8726425456907267
Validation loss: 2.7894455322214857

Epoch: 5| Step: 4
Training loss: 2.919765424842961
Validation loss: 2.773028039697615

Epoch: 5| Step: 5
Training loss: 2.5114555161622643
Validation loss: 2.729230331571332

Epoch: 5| Step: 6
Training loss: 2.1010132252614184
Validation loss: 2.755848894773549

Epoch: 5| Step: 7
Training loss: 2.6271198432517093
Validation loss: 2.8122581669648765

Epoch: 5| Step: 8
Training loss: 2.9533644483260493
Validation loss: 2.76469448373184

Epoch: 5| Step: 9
Training loss: 2.9493220633290873
Validation loss: 2.751101383285276

Epoch: 5| Step: 10
Training loss: 1.7950895644133602
Validation loss: 2.7802255035659384

Epoch: 160| Step: 0
Training loss: 2.8856432076405008
Validation loss: 2.7120039633246646

Epoch: 5| Step: 1
Training loss: 2.3403183291802363
Validation loss: 2.7484734829975954

Epoch: 5| Step: 2
Training loss: 2.1068572665961693
Validation loss: 2.815267833909739

Epoch: 5| Step: 3
Training loss: 3.3262565991760185
Validation loss: 2.7545308313847716

Epoch: 5| Step: 4
Training loss: 2.4712149953027223
Validation loss: 2.7409966342361227

Epoch: 5| Step: 5
Training loss: 2.981691122308369
Validation loss: 2.766635594957652

Epoch: 5| Step: 6
Training loss: 2.328114247137238
Validation loss: 2.8519197378164143

Epoch: 5| Step: 7
Training loss: 2.652493052711701
Validation loss: 2.8063224482937095

Epoch: 5| Step: 8
Training loss: 2.7975407665783396
Validation loss: 2.821634215996492

Epoch: 5| Step: 9
Training loss: 2.4990332641646873
Validation loss: 2.7828080450966377

Epoch: 5| Step: 10
Training loss: 1.8569641511997323
Validation loss: 2.78364969012518

Epoch: 161| Step: 0
Training loss: 2.2147193079844634
Validation loss: 2.776991225900544

Epoch: 5| Step: 1
Training loss: 3.052519123789175
Validation loss: 2.8084338858625366

Epoch: 5| Step: 2
Training loss: 2.647372861696602
Validation loss: 2.7761068626012415

Epoch: 5| Step: 3
Training loss: 2.7228220994478685
Validation loss: 2.7951311394691407

Epoch: 5| Step: 4
Training loss: 2.652005742914072
Validation loss: 2.74389151047244

Epoch: 5| Step: 5
Training loss: 2.073641076978268
Validation loss: 2.762057277527891

Epoch: 5| Step: 6
Training loss: 2.772768525585623
Validation loss: 2.7952186518231112

Epoch: 5| Step: 7
Training loss: 2.7241033706320983
Validation loss: 2.7839602825793253

Epoch: 5| Step: 8
Training loss: 2.7328362195058125
Validation loss: 2.737791044000671

Epoch: 5| Step: 9
Training loss: 2.572610123837983
Validation loss: 2.728140658721398

Epoch: 5| Step: 10
Training loss: 2.33590779875688
Validation loss: 2.761006654705889

Epoch: 162| Step: 0
Training loss: 2.6375695784372044
Validation loss: 2.77010587076869

Epoch: 5| Step: 1
Training loss: 2.3800004218606015
Validation loss: 2.786227282901475

Epoch: 5| Step: 2
Training loss: 3.2298865387537465
Validation loss: 2.7729742162091737

Epoch: 5| Step: 3
Training loss: 2.9564955111410978
Validation loss: 2.730586927887011

Epoch: 5| Step: 4
Training loss: 2.3783804276349754
Validation loss: 2.7916868377774735

Epoch: 5| Step: 5
Training loss: 2.788429679992169
Validation loss: 2.7461794587176116

Epoch: 5| Step: 6
Training loss: 2.469459914492865
Validation loss: 2.8172951842119796

Epoch: 5| Step: 7
Training loss: 2.8513693548137184
Validation loss: 2.775849607188584

Epoch: 5| Step: 8
Training loss: 2.326513154868855
Validation loss: 2.7843240946984698

Epoch: 5| Step: 9
Training loss: 2.042522315997168
Validation loss: 2.7990790691867

Epoch: 5| Step: 10
Training loss: 2.175336973899034
Validation loss: 2.7794496351026874

Epoch: 163| Step: 0
Training loss: 2.2499993642170324
Validation loss: 2.7693696974843545

Epoch: 5| Step: 1
Training loss: 2.4315893451231956
Validation loss: 2.788908807620496

Epoch: 5| Step: 2
Training loss: 2.4913424311754095
Validation loss: 2.7746216268903963

Epoch: 5| Step: 3
Training loss: 2.3309120035471156
Validation loss: 2.7455195483597548

Epoch: 5| Step: 4
Training loss: 2.165453191990739
Validation loss: 2.7299978560308142

Epoch: 5| Step: 5
Training loss: 2.9256515168583737
Validation loss: 2.72236838247298

Epoch: 5| Step: 6
Training loss: 2.8124866909136053
Validation loss: 2.780490274192177

Epoch: 5| Step: 7
Training loss: 2.683755794780074
Validation loss: 2.7804198750495224

Epoch: 5| Step: 8
Training loss: 2.4559268379683807
Validation loss: 2.7453610978245684

Epoch: 5| Step: 9
Training loss: 3.103585225039659
Validation loss: 2.7408711708841884

Epoch: 5| Step: 10
Training loss: 2.7492487488150883
Validation loss: 2.713880003466285

Epoch: 164| Step: 0
Training loss: 2.596352799446157
Validation loss: 2.7548690417331385

Epoch: 5| Step: 1
Training loss: 2.572484637808645
Validation loss: 2.7878971130232792

Epoch: 5| Step: 2
Training loss: 2.9650898103798076
Validation loss: 2.7572340211134705

Epoch: 5| Step: 3
Training loss: 2.347134295690823
Validation loss: 2.7755106855059117

Epoch: 5| Step: 4
Training loss: 3.273536116177498
Validation loss: 2.756207630556472

Epoch: 5| Step: 5
Training loss: 2.3540390002537293
Validation loss: 2.757962717987617

Epoch: 5| Step: 6
Training loss: 2.488694951566118
Validation loss: 2.7844383562801647

Epoch: 5| Step: 7
Training loss: 2.5370126754269675
Validation loss: 2.7537957989610238

Epoch: 5| Step: 8
Training loss: 2.9099853465442145
Validation loss: 2.7795938296529092

Epoch: 5| Step: 9
Training loss: 2.7565349613202725
Validation loss: 2.76511549805829

Epoch: 5| Step: 10
Training loss: 2.009055617417535
Validation loss: 2.777056519244493

Epoch: 165| Step: 0
Training loss: 2.737761052195472
Validation loss: 2.7508619026126806

Epoch: 5| Step: 1
Training loss: 2.175639450958924
Validation loss: 2.764637402684856

Epoch: 5| Step: 2
Training loss: 2.309421655495924
Validation loss: 2.77301584747794

Epoch: 5| Step: 3
Training loss: 2.65201536232827
Validation loss: 2.7939555911011755

Epoch: 5| Step: 4
Training loss: 2.8219423947149163
Validation loss: 2.8153014383379227

Epoch: 5| Step: 5
Training loss: 2.6885816482197984
Validation loss: 2.724743483911704

Epoch: 5| Step: 6
Training loss: 3.2185408144631684
Validation loss: 2.7613963962012082

Epoch: 5| Step: 7
Training loss: 2.793753560381846
Validation loss: 2.7968470451207725

Epoch: 5| Step: 8
Training loss: 2.0847324505218383
Validation loss: 2.7113870615181823

Epoch: 5| Step: 9
Training loss: 2.760124123864393
Validation loss: 2.690541310568028

Epoch: 5| Step: 10
Training loss: 1.9991281516449162
Validation loss: 2.76644835612155

Epoch: 166| Step: 0
Training loss: 2.764424553810159
Validation loss: 2.736428717115811

Epoch: 5| Step: 1
Training loss: 2.0405330105620942
Validation loss: 2.722336079318479

Epoch: 5| Step: 2
Training loss: 2.3740548712761114
Validation loss: 2.7890165012723758

Epoch: 5| Step: 3
Training loss: 2.6054475202939433
Validation loss: 2.766656039064734

Epoch: 5| Step: 4
Training loss: 2.426743665074456
Validation loss: 2.8048955743228214

Epoch: 5| Step: 5
Training loss: 2.515813405818386
Validation loss: 2.725811041769673

Epoch: 5| Step: 6
Training loss: 2.739144574168998
Validation loss: 2.8266768418212327

Epoch: 5| Step: 7
Training loss: 3.4054978966477525
Validation loss: 2.762038729047054

Epoch: 5| Step: 8
Training loss: 2.4247987880012807
Validation loss: 2.7609751313858397

Epoch: 5| Step: 9
Training loss: 2.6226284576752494
Validation loss: 2.7821061688977333

Epoch: 5| Step: 10
Training loss: 2.673757770914036
Validation loss: 2.769944363798638

Epoch: 167| Step: 0
Training loss: 2.9380374173351878
Validation loss: 2.7892223576720485

Epoch: 5| Step: 1
Training loss: 2.1377760591762205
Validation loss: 2.7646603661783598

Epoch: 5| Step: 2
Training loss: 3.0341900597263978
Validation loss: 2.793248529330706

Epoch: 5| Step: 3
Training loss: 2.1970162618918163
Validation loss: 2.7590324350408273

Epoch: 5| Step: 4
Training loss: 3.364025498827661
Validation loss: 2.7552728787096616

Epoch: 5| Step: 5
Training loss: 2.5347585028108734
Validation loss: 2.792493827743158

Epoch: 5| Step: 6
Training loss: 1.9195363772443734
Validation loss: 2.7597462176387393

Epoch: 5| Step: 7
Training loss: 2.176499855909073
Validation loss: 2.731780996143115

Epoch: 5| Step: 8
Training loss: 2.560803386721268
Validation loss: 2.7467312604135823

Epoch: 5| Step: 9
Training loss: 2.428757566242929
Validation loss: 2.7765186259235928

Epoch: 5| Step: 10
Training loss: 3.002251257205026
Validation loss: 2.7473580272324316

Epoch: 168| Step: 0
Training loss: 2.680558310613276
Validation loss: 2.767091940826245

Epoch: 5| Step: 1
Training loss: 2.6338040892809187
Validation loss: 2.7748291295598726

Epoch: 5| Step: 2
Training loss: 2.705136471336011
Validation loss: 2.754774137148286

Epoch: 5| Step: 3
Training loss: 2.8818672098332887
Validation loss: 2.758151183511446

Epoch: 5| Step: 4
Training loss: 2.1497357139498665
Validation loss: 2.7241637892157

Epoch: 5| Step: 5
Training loss: 3.010713837595604
Validation loss: 2.779501957070209

Epoch: 5| Step: 6
Training loss: 2.3724817678476544
Validation loss: 2.77043693668379

Epoch: 5| Step: 7
Training loss: 3.3152324994287437
Validation loss: 2.7579380994374807

Epoch: 5| Step: 8
Training loss: 1.9262328324490494
Validation loss: 2.795087932581718

Epoch: 5| Step: 9
Training loss: 2.8430213413893353
Validation loss: 2.717887237046862

Epoch: 5| Step: 10
Training loss: 2.1886306020782755
Validation loss: 2.782131287265033

Epoch: 169| Step: 0
Training loss: 2.395455261475155
Validation loss: 2.754788699410249

Epoch: 5| Step: 1
Training loss: 2.6489413972033944
Validation loss: 2.7962342169454564

Epoch: 5| Step: 2
Training loss: 2.142589475172193
Validation loss: 2.793758689028325

Epoch: 5| Step: 3
Training loss: 2.63264061794047
Validation loss: 2.773942784024322

Epoch: 5| Step: 4
Training loss: 2.5354205024667236
Validation loss: 2.7568557326650085

Epoch: 5| Step: 5
Training loss: 3.5608848792184893
Validation loss: 2.771589009742699

Epoch: 5| Step: 6
Training loss: 2.2388783136227945
Validation loss: 2.7351993210121304

Epoch: 5| Step: 7
Training loss: 2.799463363721143
Validation loss: 2.7387861176374884

Epoch: 5| Step: 8
Training loss: 2.989123815295463
Validation loss: 2.7970270869535274

Epoch: 5| Step: 9
Training loss: 2.687836648127148
Validation loss: 2.7149721375103484

Epoch: 5| Step: 10
Training loss: 1.961790651547993
Validation loss: 2.7835194867418487

Epoch: 170| Step: 0
Training loss: 2.8955458537235472
Validation loss: 2.769860170684517

Epoch: 5| Step: 1
Training loss: 2.5719688203740096
Validation loss: 2.751559855488552

Epoch: 5| Step: 2
Training loss: 2.96741431455626
Validation loss: 2.709096886758813

Epoch: 5| Step: 3
Training loss: 1.370611904932341
Validation loss: 2.75879884669291

Epoch: 5| Step: 4
Training loss: 2.502707255314621
Validation loss: 2.796748067863181

Epoch: 5| Step: 5
Training loss: 2.414776940163594
Validation loss: 2.7933403517732587

Epoch: 5| Step: 6
Training loss: 2.8181572707497082
Validation loss: 2.7681733127520007

Epoch: 5| Step: 7
Training loss: 2.2468873852639133
Validation loss: 2.717380656438638

Epoch: 5| Step: 8
Training loss: 2.4607571005927578
Validation loss: 2.784719852505182

Epoch: 5| Step: 9
Training loss: 3.0020678069546847
Validation loss: 2.751181668353914

Epoch: 5| Step: 10
Training loss: 2.756875459804596
Validation loss: 2.792088173892534

Epoch: 171| Step: 0
Training loss: 2.441293942729373
Validation loss: 2.7952112953364967

Epoch: 5| Step: 1
Training loss: 2.9110713876759373
Validation loss: 2.731327071322339

Epoch: 5| Step: 2
Training loss: 2.246915292179639
Validation loss: 2.7279191571483277

Epoch: 5| Step: 3
Training loss: 2.7589465179071295
Validation loss: 2.762697470908769

Epoch: 5| Step: 4
Training loss: 3.1900081864015775
Validation loss: 2.7324043450513047

Epoch: 5| Step: 5
Training loss: 2.1815898073129665
Validation loss: 2.737755473116006

Epoch: 5| Step: 6
Training loss: 2.7410849938782547
Validation loss: 2.795931509103151

Epoch: 5| Step: 7
Training loss: 2.0934879651430944
Validation loss: 2.743864896571208

Epoch: 5| Step: 8
Training loss: 2.2550743950119636
Validation loss: 2.708768650279595

Epoch: 5| Step: 9
Training loss: 2.621557976308083
Validation loss: 2.7570673814926487

Epoch: 5| Step: 10
Training loss: 2.683584332623123
Validation loss: 2.77669077346381

Epoch: 172| Step: 0
Training loss: 2.431131308043785
Validation loss: 2.765536218396221

Epoch: 5| Step: 1
Training loss: 2.477572935938126
Validation loss: 2.75859955138473

Epoch: 5| Step: 2
Training loss: 2.1924904709786155
Validation loss: 2.785502437703984

Epoch: 5| Step: 3
Training loss: 3.0100829435561076
Validation loss: 2.7366940538247224

Epoch: 5| Step: 4
Training loss: 2.600249546253072
Validation loss: 2.8094183944732016

Epoch: 5| Step: 5
Training loss: 2.789906435529039
Validation loss: 2.7813053602603826

Epoch: 5| Step: 6
Training loss: 3.319368259578951
Validation loss: 2.7905891298287377

Epoch: 5| Step: 7
Training loss: 2.0921917710890985
Validation loss: 2.7958894735867577

Epoch: 5| Step: 8
Training loss: 2.696041550375535
Validation loss: 2.7612842950787724

Epoch: 5| Step: 9
Training loss: 1.8409985848068608
Validation loss: 2.7723739597607944

Epoch: 5| Step: 10
Training loss: 2.5237736433791236
Validation loss: 2.7856727545390916

Epoch: 173| Step: 0
Training loss: 2.5434421737333617
Validation loss: 2.769384075616325

Epoch: 5| Step: 1
Training loss: 2.1569347676408555
Validation loss: 2.7476487292603

Epoch: 5| Step: 2
Training loss: 3.1748129481686593
Validation loss: 2.79718479299911

Epoch: 5| Step: 3
Training loss: 2.62824647965146
Validation loss: 2.7140574285243146

Epoch: 5| Step: 4
Training loss: 3.4462274906390507
Validation loss: 2.708669855178882

Epoch: 5| Step: 5
Training loss: 2.088955071710729
Validation loss: 2.7689687645188172

Epoch: 5| Step: 6
Training loss: 2.692564517127499
Validation loss: 2.777319243708508

Epoch: 5| Step: 7
Training loss: 2.599271573217048
Validation loss: 2.7551237013808536

Epoch: 5| Step: 8
Training loss: 2.9185867165875354
Validation loss: 2.7454553323930195

Epoch: 5| Step: 9
Training loss: 1.6088580440113507
Validation loss: 2.769701717758531

Epoch: 5| Step: 10
Training loss: 2.116498095891156
Validation loss: 2.753637047273749

Epoch: 174| Step: 0
Training loss: 2.017091675838099
Validation loss: 2.8037677104124095

Epoch: 5| Step: 1
Training loss: 2.205474898910464
Validation loss: 2.8022231853031383

Epoch: 5| Step: 2
Training loss: 2.531915553626744
Validation loss: 2.7786165420734106

Epoch: 5| Step: 3
Training loss: 3.5653781975962286
Validation loss: 2.7369646794975333

Epoch: 5| Step: 4
Training loss: 2.5006326828514176
Validation loss: 2.832208626142534

Epoch: 5| Step: 5
Training loss: 2.293238453380926
Validation loss: 2.7560795975175703

Epoch: 5| Step: 6
Training loss: 2.481863419739435
Validation loss: 2.77793318535929

Epoch: 5| Step: 7
Training loss: 2.160931356756452
Validation loss: 2.766452898753278

Epoch: 5| Step: 8
Training loss: 2.598462339685091
Validation loss: 2.786494872611028

Epoch: 5| Step: 9
Training loss: 2.8576177815404176
Validation loss: 2.7292900909217077

Epoch: 5| Step: 10
Training loss: 2.6412209284166854
Validation loss: 2.783157276293329

Epoch: 175| Step: 0
Training loss: 2.0045705069865885
Validation loss: 2.7695817868001

Epoch: 5| Step: 1
Training loss: 2.056101149531139
Validation loss: 2.7733567194459456

Epoch: 5| Step: 2
Training loss: 2.460781419436595
Validation loss: 2.7115372334857875

Epoch: 5| Step: 3
Training loss: 3.0164581887161077
Validation loss: 2.753078695043813

Epoch: 5| Step: 4
Training loss: 3.094490348008217
Validation loss: 2.755839819196412

Epoch: 5| Step: 5
Training loss: 2.7929812984584803
Validation loss: 2.7866154832354635

Epoch: 5| Step: 6
Training loss: 2.0422803254983095
Validation loss: 2.764970656936885

Epoch: 5| Step: 7
Training loss: 2.2603184082426586
Validation loss: 2.827321196387316

Epoch: 5| Step: 8
Training loss: 3.1810951959683615
Validation loss: 2.8056605592280066

Epoch: 5| Step: 9
Training loss: 2.6766350713490588
Validation loss: 2.8106277888470492

Epoch: 5| Step: 10
Training loss: 2.525932849755632
Validation loss: 2.7897959679676134

Testing loss: 2.542818194241244
