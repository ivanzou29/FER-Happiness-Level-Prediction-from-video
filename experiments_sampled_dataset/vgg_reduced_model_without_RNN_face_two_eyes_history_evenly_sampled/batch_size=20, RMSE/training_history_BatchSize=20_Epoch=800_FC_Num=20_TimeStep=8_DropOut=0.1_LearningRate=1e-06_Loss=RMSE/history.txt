Epoch: 1| Step: 0
Training loss: 3.7255960486838546
Validation loss: 3.2732568330193845

Epoch: 5| Step: 1
Training loss: 3.983915175289425
Validation loss: 3.268222845339654

Epoch: 5| Step: 2
Training loss: 3.267090974875103
Validation loss: 3.265551770808119

Epoch: 5| Step: 3
Training loss: 3.073041717226271
Validation loss: 3.2610664594260528

Epoch: 5| Step: 4
Training loss: 3.5934860796007917
Validation loss: 3.253728759535438

Epoch: 5| Step: 5
Training loss: 3.665079524698377
Validation loss: 3.2514937291428403

Epoch: 5| Step: 6
Training loss: 2.8469361282971413
Validation loss: 3.249081066015316

Epoch: 5| Step: 7
Training loss: 3.5178905731670835
Validation loss: 3.2410412818737457

Epoch: 5| Step: 8
Training loss: 3.670086364145684
Validation loss: 3.241980623044148

Epoch: 5| Step: 9
Training loss: 3.990077347543514
Validation loss: 3.232826020919231

Epoch: 5| Step: 10
Training loss: 2.87420776066464
Validation loss: 3.2317226179872227

Epoch: 2| Step: 0
Training loss: 3.0400864315294447
Validation loss: 3.225082904799047

Epoch: 5| Step: 1
Training loss: 3.9156858690649985
Validation loss: 3.222491644579882

Epoch: 5| Step: 2
Training loss: 3.346782984390307
Validation loss: 3.21907565409598

Epoch: 5| Step: 3
Training loss: 3.3462854202670163
Validation loss: 3.215696564498122

Epoch: 5| Step: 4
Training loss: 3.43811764803518
Validation loss: 3.2118786827985324

Epoch: 5| Step: 5
Training loss: 3.7791778940008096
Validation loss: 3.207236035344268

Epoch: 5| Step: 6
Training loss: 3.9804093316222673
Validation loss: 3.202491026416193

Epoch: 5| Step: 7
Training loss: 3.3838144276646704
Validation loss: 3.1983408137418583

Epoch: 5| Step: 8
Training loss: 3.5757014300068084
Validation loss: 3.195516670091161

Epoch: 5| Step: 9
Training loss: 3.020307788953743
Validation loss: 3.1938168118819616

Epoch: 5| Step: 10
Training loss: 3.0663829243738627
Validation loss: 3.1850858590798055

Epoch: 3| Step: 0
Training loss: 3.0239804591097537
Validation loss: 3.183528611345758

Epoch: 5| Step: 1
Training loss: 4.22893509755425
Validation loss: 3.1796509086884126

Epoch: 5| Step: 2
Training loss: 2.796731955850173
Validation loss: 3.173441183957786

Epoch: 5| Step: 3
Training loss: 3.023338138810628
Validation loss: 3.174208761229694

Epoch: 5| Step: 4
Training loss: 3.7580188210804275
Validation loss: 3.1699504152840574

Epoch: 5| Step: 5
Training loss: 3.3494725680425903
Validation loss: 3.163513670751019

Epoch: 5| Step: 6
Training loss: 3.679878634856447
Validation loss: 3.1568698004427427

Epoch: 5| Step: 7
Training loss: 3.775481687218204
Validation loss: 3.1554399439954777

Epoch: 5| Step: 8
Training loss: 3.265909866976783
Validation loss: 3.149456925300399

Epoch: 5| Step: 9
Training loss: 3.144759611758436
Validation loss: 3.1475154880674094

Epoch: 5| Step: 10
Training loss: 3.386745501173904
Validation loss: 3.1442839608636266

Epoch: 4| Step: 0
Training loss: 3.8651393822808005
Validation loss: 3.1412788338648516

Epoch: 5| Step: 1
Training loss: 3.405963570687249
Validation loss: 3.137033264013293

Epoch: 5| Step: 2
Training loss: 3.455292586705388
Validation loss: 3.1316306224946713

Epoch: 5| Step: 3
Training loss: 3.3577583148857038
Validation loss: 3.1266154603153837

Epoch: 5| Step: 4
Training loss: 2.669077161260279
Validation loss: 3.1210134628528134

Epoch: 5| Step: 5
Training loss: 3.722404159224167
Validation loss: 3.119996655861782

Epoch: 5| Step: 6
Training loss: 2.5440843891926024
Validation loss: 3.114911638725492

Epoch: 5| Step: 7
Training loss: 3.4233047076560337
Validation loss: 3.110047684252397

Epoch: 5| Step: 8
Training loss: 3.911662509971808
Validation loss: 3.1061691789323334

Epoch: 5| Step: 9
Training loss: 3.108714584682639
Validation loss: 3.1011972677008

Epoch: 5| Step: 10
Training loss: 3.537058281700624
Validation loss: 3.0988188670414627

Epoch: 5| Step: 0
Training loss: 3.8264378157801318
Validation loss: 3.097196624459765

Epoch: 5| Step: 1
Training loss: 3.7340488690456235
Validation loss: 3.0903206209355543

Epoch: 5| Step: 2
Training loss: 3.8464210967600874
Validation loss: 3.0864908457748768

Epoch: 5| Step: 3
Training loss: 2.9974896736380754
Validation loss: 3.080981022158403

Epoch: 5| Step: 4
Training loss: 3.2164265663259566
Validation loss: 3.0723542168846976

Epoch: 5| Step: 5
Training loss: 3.0440450975684104
Validation loss: 3.0734101302661574

Epoch: 5| Step: 6
Training loss: 3.0109076885970665
Validation loss: 3.0687453339741766

Epoch: 5| Step: 7
Training loss: 3.7638683733003684
Validation loss: 3.064578743992799

Epoch: 5| Step: 8
Training loss: 2.888843379110533
Validation loss: 3.06045230718041

Epoch: 5| Step: 9
Training loss: 3.189248297445464
Validation loss: 3.059573317239184

Epoch: 5| Step: 10
Training loss: 3.0329236001876465
Validation loss: 3.052573640952018

Epoch: 6| Step: 0
Training loss: 3.183728249171904
Validation loss: 3.0488254342436445

Epoch: 5| Step: 1
Training loss: 3.6833735508398893
Validation loss: 3.0416942049590014

Epoch: 5| Step: 2
Training loss: 3.11227619025234
Validation loss: 3.0383852796649062

Epoch: 5| Step: 3
Training loss: 4.110717554127802
Validation loss: 3.037229323395029

Epoch: 5| Step: 4
Training loss: 3.5932616855742117
Validation loss: 3.030470314475206

Epoch: 5| Step: 5
Training loss: 3.2043752323788195
Validation loss: 3.0244204368114747

Epoch: 5| Step: 6
Training loss: 2.9480256149235062
Validation loss: 3.0214328333658274

Epoch: 5| Step: 7
Training loss: 3.2276802990088505
Validation loss: 3.0159098427802387

Epoch: 5| Step: 8
Training loss: 3.262335183376142
Validation loss: 3.0108163912211467

Epoch: 5| Step: 9
Training loss: 3.3035793024506868
Validation loss: 3.005764548478327

Epoch: 5| Step: 10
Training loss: 2.3017659953914262
Validation loss: 3.0001276888044615

Epoch: 7| Step: 0
Training loss: 3.492292364197369
Validation loss: 2.9992093049191957

Epoch: 5| Step: 1
Training loss: 2.8865443113736253
Validation loss: 2.992845121425764

Epoch: 5| Step: 2
Training loss: 3.413308905002481
Validation loss: 2.9906560936778943

Epoch: 5| Step: 3
Training loss: 3.137742119068093
Validation loss: 2.9857151557545625

Epoch: 5| Step: 4
Training loss: 3.2807520897336926
Validation loss: 2.9773257730900142

Epoch: 5| Step: 5
Training loss: 3.781732197430952
Validation loss: 2.9745315118079927

Epoch: 5| Step: 6
Training loss: 3.2585154262175817
Validation loss: 2.972661403741929

Epoch: 5| Step: 7
Training loss: 3.4622867614967205
Validation loss: 2.9665581185462786

Epoch: 5| Step: 8
Training loss: 3.127732265029106
Validation loss: 2.959254583422034

Epoch: 5| Step: 9
Training loss: 3.370622692591894
Validation loss: 2.954306790572341

Epoch: 5| Step: 10
Training loss: 2.3287136690558397
Validation loss: 2.9502761363273358

Epoch: 8| Step: 0
Training loss: 3.5238930012353205
Validation loss: 2.9455775926114733

Epoch: 5| Step: 1
Training loss: 3.238981790084505
Validation loss: 2.94147372789723

Epoch: 5| Step: 2
Training loss: 3.1271885646842272
Validation loss: 2.936807568726833

Epoch: 5| Step: 3
Training loss: 3.6048829500663677
Validation loss: 2.9329809583260475

Epoch: 5| Step: 4
Training loss: 3.348816927489882
Validation loss: 2.9278936582964636

Epoch: 5| Step: 5
Training loss: 2.830654804243812
Validation loss: 2.923052466465696

Epoch: 5| Step: 6
Training loss: 2.80924748862245
Validation loss: 2.9154502078105593

Epoch: 5| Step: 7
Training loss: 2.774537891711469
Validation loss: 2.910363803533505

Epoch: 5| Step: 8
Training loss: 3.178933693951793
Validation loss: 2.907258602247703

Epoch: 5| Step: 9
Training loss: 3.4474779447274675
Validation loss: 2.9019701323921185

Epoch: 5| Step: 10
Training loss: 3.374702581793537
Validation loss: 2.896270570806361

Epoch: 9| Step: 0
Training loss: 3.420455289729437
Validation loss: 2.8933041091034877

Epoch: 5| Step: 1
Training loss: 3.2986578437216383
Validation loss: 2.8869447631447196

Epoch: 5| Step: 2
Training loss: 3.0596019500937666
Validation loss: 2.8820364076072558

Epoch: 5| Step: 3
Training loss: 2.5481952451521
Validation loss: 2.876499810276277

Epoch: 5| Step: 4
Training loss: 3.4167252202172698
Validation loss: 2.8704475394957996

Epoch: 5| Step: 5
Training loss: 3.7400384199239616
Validation loss: 2.8659325524170627

Epoch: 5| Step: 6
Training loss: 2.622812176825627
Validation loss: 2.8615795029135627

Epoch: 5| Step: 7
Training loss: 3.170161644216879
Validation loss: 2.8571353548584284

Epoch: 5| Step: 8
Training loss: 3.0223733769122196
Validation loss: 2.850130541045685

Epoch: 5| Step: 9
Training loss: 3.345039190453371
Validation loss: 2.8474251124014187

Epoch: 5| Step: 10
Training loss: 2.9955525810963963
Validation loss: 2.838462120552946

Epoch: 10| Step: 0
Training loss: 3.0051359083064075
Validation loss: 2.835758731633372

Epoch: 5| Step: 1
Training loss: 2.5202459696663793
Validation loss: 2.8313610485863205

Epoch: 5| Step: 2
Training loss: 3.3961229883396022
Validation loss: 2.824793481678669

Epoch: 5| Step: 3
Training loss: 3.1629299067625216
Validation loss: 2.8193574807084816

Epoch: 5| Step: 4
Training loss: 3.1395945210669907
Validation loss: 2.8166553696111363

Epoch: 5| Step: 5
Training loss: 3.0407934285294345
Validation loss: 2.809138846648701

Epoch: 5| Step: 6
Training loss: 3.4743840282286516
Validation loss: 2.8021348377536524

Epoch: 5| Step: 7
Training loss: 3.1127062258134437
Validation loss: 2.797725221718896

Epoch: 5| Step: 8
Training loss: 3.15185951569502
Validation loss: 2.7931968631952104

Epoch: 5| Step: 9
Training loss: 3.0061249197398725
Validation loss: 2.7864401840402455

Epoch: 5| Step: 10
Training loss: 3.250665303137944
Validation loss: 2.7828476785029777

Epoch: 11| Step: 0
Training loss: 3.0484475797000674
Validation loss: 2.7785349728231585

Epoch: 5| Step: 1
Training loss: 3.2099952521838673
Validation loss: 2.7736650206344504

Epoch: 5| Step: 2
Training loss: 2.9691492715676295
Validation loss: 2.767623746412867

Epoch: 5| Step: 3
Training loss: 2.8548324439590242
Validation loss: 2.760805224242392

Epoch: 5| Step: 4
Training loss: 3.0104203449653584
Validation loss: 2.755506018871915

Epoch: 5| Step: 5
Training loss: 3.448430110506922
Validation loss: 2.7515274459574575

Epoch: 5| Step: 6
Training loss: 2.419421620729078
Validation loss: 2.7455065093839943

Epoch: 5| Step: 7
Training loss: 2.760212229709801
Validation loss: 2.737373090862651

Epoch: 5| Step: 8
Training loss: 3.2040896568088773
Validation loss: 2.7377379791915697

Epoch: 5| Step: 9
Training loss: 3.365019274992245
Validation loss: 2.7310177699124427

Epoch: 5| Step: 10
Training loss: 3.397751592060205
Validation loss: 2.7272834448776266

Epoch: 12| Step: 0
Training loss: 3.6034261718233176
Validation loss: 2.7190653205923696

Epoch: 5| Step: 1
Training loss: 3.162679940031266
Validation loss: 2.7136175668460054

Epoch: 5| Step: 2
Training loss: 2.376280389277401
Validation loss: 2.7103220854694023

Epoch: 5| Step: 3
Training loss: 2.541497761685055
Validation loss: 2.701267430943946

Epoch: 5| Step: 4
Training loss: 3.5241936593334833
Validation loss: 2.6978060551242526

Epoch: 5| Step: 5
Training loss: 3.1278554459168597
Validation loss: 2.6904045200728492

Epoch: 5| Step: 6
Training loss: 3.1320419315147427
Validation loss: 2.6845267481088815

Epoch: 5| Step: 7
Training loss: 2.9009212740578207
Validation loss: 2.6784055670206266

Epoch: 5| Step: 8
Training loss: 2.8462185049345794
Validation loss: 2.6734913210026185

Epoch: 5| Step: 9
Training loss: 2.4787141616700525
Validation loss: 2.673517361066975

Epoch: 5| Step: 10
Training loss: 3.412417506523867
Validation loss: 2.6618628905513506

Epoch: 13| Step: 0
Training loss: 2.952870191449958
Validation loss: 2.6611390994086976

Epoch: 5| Step: 1
Training loss: 2.833452970185482
Validation loss: 2.6534016247945393

Epoch: 5| Step: 2
Training loss: 3.200961838651764
Validation loss: 2.652050198216525

Epoch: 5| Step: 3
Training loss: 2.977859174586984
Validation loss: 2.6461801799781277

Epoch: 5| Step: 4
Training loss: 3.4012153585030442
Validation loss: 2.6384136797171025

Epoch: 5| Step: 5
Training loss: 3.5922958749266654
Validation loss: 2.6318057600709683

Epoch: 5| Step: 6
Training loss: 3.1065983475252605
Validation loss: 2.626327993236351

Epoch: 5| Step: 7
Training loss: 2.408652060338358
Validation loss: 2.619965231559153

Epoch: 5| Step: 8
Training loss: 2.6523273900107562
Validation loss: 2.6156533194346836

Epoch: 5| Step: 9
Training loss: 2.4590586438223316
Validation loss: 2.615853717799549

Epoch: 5| Step: 10
Training loss: 3.0220511952171942
Validation loss: 2.608501950214043

Epoch: 14| Step: 0
Training loss: 2.7582131762038484
Validation loss: 2.6063672743029103

Epoch: 5| Step: 1
Training loss: 2.7662258034400726
Validation loss: 2.597213317773647

Epoch: 5| Step: 2
Training loss: 3.2799085508949615
Validation loss: 2.6014877210539127

Epoch: 5| Step: 3
Training loss: 3.207327119326342
Validation loss: 2.5891589835829363

Epoch: 5| Step: 4
Training loss: 3.220996554155233
Validation loss: 2.5872654167336506

Epoch: 5| Step: 5
Training loss: 2.606249187661463
Validation loss: 2.5817568299014084

Epoch: 5| Step: 6
Training loss: 2.6377072438178875
Validation loss: 2.5745017058500124

Epoch: 5| Step: 7
Training loss: 2.9092023066844734
Validation loss: 2.5746481044404748

Epoch: 5| Step: 8
Training loss: 2.9753093334269693
Validation loss: 2.5669080775206337

Epoch: 5| Step: 9
Training loss: 3.032366989250331
Validation loss: 2.568406913058794

Epoch: 5| Step: 10
Training loss: 2.82570017349497
Validation loss: 2.5566909338745503

Epoch: 15| Step: 0
Training loss: 2.6107746870230195
Validation loss: 2.5527674504966766

Epoch: 5| Step: 1
Training loss: 2.8384724366497918
Validation loss: 2.5546015759831557

Epoch: 5| Step: 2
Training loss: 2.868579162962837
Validation loss: 2.5510919436322985

Epoch: 5| Step: 3
Training loss: 2.883047533662923
Validation loss: 2.5480665576070964

Epoch: 5| Step: 4
Training loss: 3.2030425270442024
Validation loss: 2.538641255839656

Epoch: 5| Step: 5
Training loss: 2.662413145269441
Validation loss: 2.5438998064934966

Epoch: 5| Step: 6
Training loss: 2.8900041893001407
Validation loss: 2.535622713396424

Epoch: 5| Step: 7
Training loss: 3.5106040534803267
Validation loss: 2.5348776523884853

Epoch: 5| Step: 8
Training loss: 2.656361745839968
Validation loss: 2.5323935128223987

Epoch: 5| Step: 9
Training loss: 3.198506370291211
Validation loss: 2.527479448676048

Epoch: 5| Step: 10
Training loss: 2.401248340993345
Validation loss: 2.5213781876665147

Epoch: 16| Step: 0
Training loss: 2.8753638659220497
Validation loss: 2.5223791230103267

Epoch: 5| Step: 1
Training loss: 3.0056934372853843
Validation loss: 2.523118318714221

Epoch: 5| Step: 2
Training loss: 3.158992671000452
Validation loss: 2.5159198320958667

Epoch: 5| Step: 3
Training loss: 2.9737530763857927
Validation loss: 2.5060275274312818

Epoch: 5| Step: 4
Training loss: 2.6404911887670717
Validation loss: 2.5070515284614516

Epoch: 5| Step: 5
Training loss: 3.082060026897499
Validation loss: 2.502906535111329

Epoch: 5| Step: 6
Training loss: 2.8152926673321863
Validation loss: 2.5004182609231234

Epoch: 5| Step: 7
Training loss: 2.663628148442926
Validation loss: 2.502450848129152

Epoch: 5| Step: 8
Training loss: 2.8382568963137667
Validation loss: 2.487210500212969

Epoch: 5| Step: 9
Training loss: 2.717214391837438
Validation loss: 2.4935787284700073

Epoch: 5| Step: 10
Training loss: 2.865377993322469
Validation loss: 2.4899078321047057

Epoch: 17| Step: 0
Training loss: 2.5310655691515063
Validation loss: 2.484821925611252

Epoch: 5| Step: 1
Training loss: 2.829277688845792
Validation loss: 2.4882491862715694

Epoch: 5| Step: 2
Training loss: 2.5812064511225463
Validation loss: 2.4816124694278345

Epoch: 5| Step: 3
Training loss: 2.4514335097543603
Validation loss: 2.4769564860904514

Epoch: 5| Step: 4
Training loss: 3.0740161717522465
Validation loss: 2.478284208429015

Epoch: 5| Step: 5
Training loss: 3.005568740010405
Validation loss: 2.4748978055188817

Epoch: 5| Step: 6
Training loss: 2.6683855080333543
Validation loss: 2.478850124132986

Epoch: 5| Step: 7
Training loss: 3.394544735301177
Validation loss: 2.4745628244489772

Epoch: 5| Step: 8
Training loss: 2.7923217877765625
Validation loss: 2.4696237895494426

Epoch: 5| Step: 9
Training loss: 3.2239592536263495
Validation loss: 2.464967022685437

Epoch: 5| Step: 10
Training loss: 2.682035168479059
Validation loss: 2.4670687779519236

Epoch: 18| Step: 0
Training loss: 2.3498350369606236
Validation loss: 2.4607745091713937

Epoch: 5| Step: 1
Training loss: 2.779285894655049
Validation loss: 2.457010269434128

Epoch: 5| Step: 2
Training loss: 2.901720023616852
Validation loss: 2.456496156199462

Epoch: 5| Step: 3
Training loss: 3.218093508834696
Validation loss: 2.4521281302620146

Epoch: 5| Step: 4
Training loss: 3.115294988634453
Validation loss: 2.454552264445978

Epoch: 5| Step: 5
Training loss: 2.808450029327605
Validation loss: 2.454495700923586

Epoch: 5| Step: 6
Training loss: 2.675456184634396
Validation loss: 2.4517995131054753

Epoch: 5| Step: 7
Training loss: 2.7491539607390876
Validation loss: 2.4470711180905744

Epoch: 5| Step: 8
Training loss: 2.8148612388980188
Validation loss: 2.4537302026637535

Epoch: 5| Step: 9
Training loss: 2.932314739960889
Validation loss: 2.447198206697995

Epoch: 5| Step: 10
Training loss: 2.7272461304668196
Validation loss: 2.4463602745166457

Epoch: 19| Step: 0
Training loss: 2.453340557371091
Validation loss: 2.4481034580476213

Epoch: 5| Step: 1
Training loss: 3.0986565109005526
Validation loss: 2.4457620166082195

Epoch: 5| Step: 2
Training loss: 2.859084317800282
Validation loss: 2.4477566832813316

Epoch: 5| Step: 3
Training loss: 2.897870689555735
Validation loss: 2.435348948867936

Epoch: 5| Step: 4
Training loss: 3.1653210809444263
Validation loss: 2.443753207646039

Epoch: 5| Step: 5
Training loss: 2.7803818279934207
Validation loss: 2.436196705805867

Epoch: 5| Step: 6
Training loss: 2.7865404538801943
Validation loss: 2.440628679518087

Epoch: 5| Step: 7
Training loss: 2.6881874447248046
Validation loss: 2.4351949217992046

Epoch: 5| Step: 8
Training loss: 3.033240382548464
Validation loss: 2.431375228170966

Epoch: 5| Step: 9
Training loss: 2.7579800390084133
Validation loss: 2.4278397257962654

Epoch: 5| Step: 10
Training loss: 2.424137559884076
Validation loss: 2.42908529645115

Epoch: 20| Step: 0
Training loss: 2.4541444057454544
Validation loss: 2.433076739243212

Epoch: 5| Step: 1
Training loss: 3.2456475971507035
Validation loss: 2.429130919624802

Epoch: 5| Step: 2
Training loss: 3.054729646748085
Validation loss: 2.4345686297804128

Epoch: 5| Step: 3
Training loss: 2.5592494910536754
Validation loss: 2.4317168838806476

Epoch: 5| Step: 4
Training loss: 2.4188076160281358
Validation loss: 2.4254856374357994

Epoch: 5| Step: 5
Training loss: 3.1926350836676933
Validation loss: 2.4329489182492012

Epoch: 5| Step: 6
Training loss: 2.9461636312689614
Validation loss: 2.426173852053757

Epoch: 5| Step: 7
Training loss: 2.61958499242375
Validation loss: 2.428818060359087

Epoch: 5| Step: 8
Training loss: 2.7296207622892252
Validation loss: 2.4337758984508078

Epoch: 5| Step: 9
Training loss: 2.712258492542902
Validation loss: 2.4271532393958766

Epoch: 5| Step: 10
Training loss: 2.9377394233690466
Validation loss: 2.432811180840072

Epoch: 21| Step: 0
Training loss: 2.2431910591676507
Validation loss: 2.4359379062779722

Epoch: 5| Step: 1
Training loss: 3.3427734375
Validation loss: 2.4266474578579014

Epoch: 5| Step: 2
Training loss: 2.757854861185369
Validation loss: 2.4241375281576505

Epoch: 5| Step: 3
Training loss: 2.9074961954027967
Validation loss: 2.428366455560101

Epoch: 5| Step: 4
Training loss: 2.690423572900266
Validation loss: 2.4224890558642036

Epoch: 5| Step: 5
Training loss: 3.0773066483348295
Validation loss: 2.4258832415513623

Epoch: 5| Step: 6
Training loss: 2.4266978818681326
Validation loss: 2.424655772571455

Epoch: 5| Step: 7
Training loss: 2.581124150715864
Validation loss: 2.4262681190793147

Epoch: 5| Step: 8
Training loss: 2.979507551275531
Validation loss: 2.422057780481555

Epoch: 5| Step: 9
Training loss: 2.8704888154160626
Validation loss: 2.4193676796780883

Epoch: 5| Step: 10
Training loss: 2.920119630374873
Validation loss: 2.4239383393587266

Epoch: 22| Step: 0
Training loss: 2.8493883179229744
Validation loss: 2.428934217989708

Epoch: 5| Step: 1
Training loss: 3.0252336396084765
Validation loss: 2.4254301495863495

Epoch: 5| Step: 2
Training loss: 2.7467252132817785
Validation loss: 2.429546114550951

Epoch: 5| Step: 3
Training loss: 2.5332221366504206
Validation loss: 2.4179914274859757

Epoch: 5| Step: 4
Training loss: 2.671444239107819
Validation loss: 2.414884166250792

Epoch: 5| Step: 5
Training loss: 2.598441236244401
Validation loss: 2.4130405453578

Epoch: 5| Step: 6
Training loss: 2.7037202036463968
Validation loss: 2.42218613017062

Epoch: 5| Step: 7
Training loss: 3.2315092060300907
Validation loss: 2.424115617260297

Epoch: 5| Step: 8
Training loss: 3.0617472443613782
Validation loss: 2.4228028794816745

Epoch: 5| Step: 9
Training loss: 2.903905763951903
Validation loss: 2.418527076587176

Epoch: 5| Step: 10
Training loss: 2.4653480364558944
Validation loss: 2.4182928718505416

Epoch: 23| Step: 0
Training loss: 3.3133781276824403
Validation loss: 2.4210070888490747

Epoch: 5| Step: 1
Training loss: 2.3044230681191946
Validation loss: 2.4155506199152867

Epoch: 5| Step: 2
Training loss: 3.1903918742498227
Validation loss: 2.4181387766630094

Epoch: 5| Step: 3
Training loss: 3.2558368208389474
Validation loss: 2.4172643845944335

Epoch: 5| Step: 4
Training loss: 2.640953088727233
Validation loss: 2.4210936355989197

Epoch: 5| Step: 5
Training loss: 2.9803084384106158
Validation loss: 2.4226238880484816

Epoch: 5| Step: 6
Training loss: 2.8962035091193696
Validation loss: 2.430138590294076

Epoch: 5| Step: 7
Training loss: 2.7373202783124944
Validation loss: 2.4288798533235867

Epoch: 5| Step: 8
Training loss: 2.33854330922319
Validation loss: 2.423222395975609

Epoch: 5| Step: 9
Training loss: 2.612155278291567
Validation loss: 2.4248468758983135

Epoch: 5| Step: 10
Training loss: 2.315033118091425
Validation loss: 2.4153418173232706

Epoch: 24| Step: 0
Training loss: 3.028391798172711
Validation loss: 2.4140626762855475

Epoch: 5| Step: 1
Training loss: 2.47383713810187
Validation loss: 2.4149223888504046

Epoch: 5| Step: 2
Training loss: 2.9909075596540102
Validation loss: 2.413914980590546

Epoch: 5| Step: 3
Training loss: 2.8514009612849263
Validation loss: 2.4200519026040825

Epoch: 5| Step: 4
Training loss: 2.8934244982102544
Validation loss: 2.422211298780424

Epoch: 5| Step: 5
Training loss: 2.957116391607815
Validation loss: 2.429349584775215

Epoch: 5| Step: 6
Training loss: 2.546558664721359
Validation loss: 2.413753819127019

Epoch: 5| Step: 7
Training loss: 2.6021802930479003
Validation loss: 2.413518895209506

Epoch: 5| Step: 8
Training loss: 3.180096274304093
Validation loss: 2.4221066973072505

Epoch: 5| Step: 9
Training loss: 2.64987980552017
Validation loss: 2.415943875089945

Epoch: 5| Step: 10
Training loss: 2.5606101906264147
Validation loss: 2.418812869836973

Epoch: 25| Step: 0
Training loss: 2.7428060415452027
Validation loss: 2.412797565058121

Epoch: 5| Step: 1
Training loss: 2.690437131341789
Validation loss: 2.4298411149534735

Epoch: 5| Step: 2
Training loss: 3.11681009938329
Validation loss: 2.4135941997913197

Epoch: 5| Step: 3
Training loss: 2.882288112346377
Validation loss: 2.4097311427097554

Epoch: 5| Step: 4
Training loss: 2.21143974288
Validation loss: 2.423979971722764

Epoch: 5| Step: 5
Training loss: 2.836013162407508
Validation loss: 2.4167564178819028

Epoch: 5| Step: 6
Training loss: 2.59423694865449
Validation loss: 2.416608101796761

Epoch: 5| Step: 7
Training loss: 3.153401515242391
Validation loss: 2.414076866167953

Epoch: 5| Step: 8
Training loss: 3.0755837111326643
Validation loss: 2.417429753323115

Epoch: 5| Step: 9
Training loss: 2.8605906086096833
Validation loss: 2.414899357696666

Epoch: 5| Step: 10
Training loss: 2.493826874047629
Validation loss: 2.4141347823668093

Epoch: 26| Step: 0
Training loss: 2.8373982684346273
Validation loss: 2.4130654991365574

Epoch: 5| Step: 1
Training loss: 2.857502642185595
Validation loss: 2.415530155708195

Epoch: 5| Step: 2
Training loss: 2.4959330857795377
Validation loss: 2.4259019444865615

Epoch: 5| Step: 3
Training loss: 2.7969673184124506
Validation loss: 2.4139134024192934

Epoch: 5| Step: 4
Training loss: 3.1460651708062186
Validation loss: 2.4101613982170185

Epoch: 5| Step: 5
Training loss: 2.8157937154911514
Validation loss: 2.4140205277438254

Epoch: 5| Step: 6
Training loss: 2.988841125298873
Validation loss: 2.4089966764369297

Epoch: 5| Step: 7
Training loss: 2.1170101302620354
Validation loss: 2.4201921515697298

Epoch: 5| Step: 8
Training loss: 2.7864803895641868
Validation loss: 2.4149840182670226

Epoch: 5| Step: 9
Training loss: 2.360494588007396
Validation loss: 2.4135600604333365

Epoch: 5| Step: 10
Training loss: 3.427370857460259
Validation loss: 2.417524564913699

Epoch: 27| Step: 0
Training loss: 3.333663701534208
Validation loss: 2.4095714888354345

Epoch: 5| Step: 1
Training loss: 2.160937093981569
Validation loss: 2.413712851574745

Epoch: 5| Step: 2
Training loss: 2.8555938234086358
Validation loss: 2.4218094842354083

Epoch: 5| Step: 3
Training loss: 2.5080436053401947
Validation loss: 2.414898054059916

Epoch: 5| Step: 4
Training loss: 2.532798199433815
Validation loss: 2.407631700991595

Epoch: 5| Step: 5
Training loss: 2.865764046293896
Validation loss: 2.41443939139513

Epoch: 5| Step: 6
Training loss: 2.6965925190291697
Validation loss: 2.41092840595766

Epoch: 5| Step: 7
Training loss: 3.0258479797742814
Validation loss: 2.4118461731989607

Epoch: 5| Step: 8
Training loss: 2.684228813622836
Validation loss: 2.414963384716023

Epoch: 5| Step: 9
Training loss: 3.016646928529464
Validation loss: 2.415366855057844

Epoch: 5| Step: 10
Training loss: 2.9411882013199184
Validation loss: 2.4150760268756133

Epoch: 28| Step: 0
Training loss: 2.6005312046847866
Validation loss: 2.417953770804307

Epoch: 5| Step: 1
Training loss: 2.574175774963737
Validation loss: 2.410222383542043

Epoch: 5| Step: 2
Training loss: 2.5975171962605725
Validation loss: 2.4187088535331407

Epoch: 5| Step: 3
Training loss: 2.3299827588143374
Validation loss: 2.4185855709639403

Epoch: 5| Step: 4
Training loss: 3.0531370320859064
Validation loss: 2.411262397050182

Epoch: 5| Step: 5
Training loss: 2.9072311549972123
Validation loss: 2.4200115549253542

Epoch: 5| Step: 6
Training loss: 2.917081440089185
Validation loss: 2.4187125250971686

Epoch: 5| Step: 7
Training loss: 3.0889366544907557
Validation loss: 2.4104972902945154

Epoch: 5| Step: 8
Training loss: 2.822091933452802
Validation loss: 2.4137407552988446

Epoch: 5| Step: 9
Training loss: 2.8360052599837964
Validation loss: 2.410940478577075

Epoch: 5| Step: 10
Training loss: 2.888706044581122
Validation loss: 2.4120229820432426

Epoch: 29| Step: 0
Training loss: 2.304914560286022
Validation loss: 2.411011806123959

Epoch: 5| Step: 1
Training loss: 2.6937434397748117
Validation loss: 2.4165060847830695

Epoch: 5| Step: 2
Training loss: 3.1502510697352624
Validation loss: 2.4154444529264225

Epoch: 5| Step: 3
Training loss: 2.56511108604053
Validation loss: 2.414975587375011

Epoch: 5| Step: 4
Training loss: 2.4488143465351526
Validation loss: 2.4085699360832162

Epoch: 5| Step: 5
Training loss: 2.8786293010445148
Validation loss: 2.4096501957384766

Epoch: 5| Step: 6
Training loss: 2.623468769879993
Validation loss: 2.4142563521662295

Epoch: 5| Step: 7
Training loss: 3.036474228954204
Validation loss: 2.4154301978443247

Epoch: 5| Step: 8
Training loss: 2.8505767372560507
Validation loss: 2.406879811938038

Epoch: 5| Step: 9
Training loss: 3.1006306898837255
Validation loss: 2.4119177800785696

Epoch: 5| Step: 10
Training loss: 2.853055547430872
Validation loss: 2.4085953278676575

Epoch: 30| Step: 0
Training loss: 2.4317370047101936
Validation loss: 2.422338336998436

Epoch: 5| Step: 1
Training loss: 2.6756529394418385
Validation loss: 2.406329794621958

Epoch: 5| Step: 2
Training loss: 2.8794017763840722
Validation loss: 2.418606651658117

Epoch: 5| Step: 3
Training loss: 2.9362150587891143
Validation loss: 2.416199344759114

Epoch: 5| Step: 4
Training loss: 2.6344816536994897
Validation loss: 2.416334204317541

Epoch: 5| Step: 5
Training loss: 2.970662354359445
Validation loss: 2.4056393349612213

Epoch: 5| Step: 6
Training loss: 3.092962453767824
Validation loss: 2.409687256609362

Epoch: 5| Step: 7
Training loss: 2.6328368596158414
Validation loss: 2.4128301347311703

Epoch: 5| Step: 8
Training loss: 2.838056293017964
Validation loss: 2.4157356156117666

Epoch: 5| Step: 9
Training loss: 2.239525041634805
Validation loss: 2.4081024989090865

Epoch: 5| Step: 10
Training loss: 3.22989362511985
Validation loss: 2.422211893065506

Epoch: 31| Step: 0
Training loss: 2.7631558532994123
Validation loss: 2.4140212913070607

Epoch: 5| Step: 1
Training loss: 2.7647416595297307
Validation loss: 2.411071996935658

Epoch: 5| Step: 2
Training loss: 2.444072665013054
Validation loss: 2.4167101940638194

Epoch: 5| Step: 3
Training loss: 3.2012113483781204
Validation loss: 2.4050192773252026

Epoch: 5| Step: 4
Training loss: 2.6886172966195625
Validation loss: 2.415623111398039

Epoch: 5| Step: 5
Training loss: 2.8963026219947783
Validation loss: 2.412483454753868

Epoch: 5| Step: 6
Training loss: 2.867520097364457
Validation loss: 2.408052349301608

Epoch: 5| Step: 7
Training loss: 2.5813675343353486
Validation loss: 2.4166824200986246

Epoch: 5| Step: 8
Training loss: 2.566444617322844
Validation loss: 2.411772715158714

Epoch: 5| Step: 9
Training loss: 2.7788523937172545
Validation loss: 2.408208816050934

Epoch: 5| Step: 10
Training loss: 2.943524614845802
Validation loss: 2.404410174667089

Epoch: 32| Step: 0
Training loss: 3.207170267379392
Validation loss: 2.410405279207753

Epoch: 5| Step: 1
Training loss: 2.684406274118198
Validation loss: 2.4081649703398087

Epoch: 5| Step: 2
Training loss: 2.636951215880814
Validation loss: 2.408339687349959

Epoch: 5| Step: 3
Training loss: 3.082702022222145
Validation loss: 2.4173084746248223

Epoch: 5| Step: 4
Training loss: 2.5144070348327467
Validation loss: 2.4134237594837833

Epoch: 5| Step: 5
Training loss: 2.686674745403982
Validation loss: 2.4226169610072374

Epoch: 5| Step: 6
Training loss: 2.3757594048932997
Validation loss: 2.4136650527399297

Epoch: 5| Step: 7
Training loss: 3.2054232656183768
Validation loss: 2.418260029622407

Epoch: 5| Step: 8
Training loss: 2.243334965055797
Validation loss: 2.4033453458693708

Epoch: 5| Step: 9
Training loss: 2.7772714683258557
Validation loss: 2.41028480428263

Epoch: 5| Step: 10
Training loss: 2.9510810681553963
Validation loss: 2.4125917805632193

Epoch: 33| Step: 0
Training loss: 2.612749852548496
Validation loss: 2.3944293716144434

Epoch: 5| Step: 1
Training loss: 2.6061601765108575
Validation loss: 2.4046321779137023

Epoch: 5| Step: 2
Training loss: 2.8278857388108913
Validation loss: 2.4106671611874044

Epoch: 5| Step: 3
Training loss: 2.793919029498886
Validation loss: 2.4088131810597986

Epoch: 5| Step: 4
Training loss: 2.818671343397425
Validation loss: 2.4155687167227757

Epoch: 5| Step: 5
Training loss: 2.77345924906195
Validation loss: 2.4100387208728473

Epoch: 5| Step: 6
Training loss: 2.657535017757145
Validation loss: 2.411813913906953

Epoch: 5| Step: 7
Training loss: 2.8914467133373454
Validation loss: 2.4171423063853745

Epoch: 5| Step: 8
Training loss: 2.942480045792198
Validation loss: 2.415339152680395

Epoch: 5| Step: 9
Training loss: 2.611149167624465
Validation loss: 2.4196380976156813

Epoch: 5| Step: 10
Training loss: 3.036891289145432
Validation loss: 2.418490735246719

Epoch: 34| Step: 0
Training loss: 2.4732617063338806
Validation loss: 2.4149920414935075

Epoch: 5| Step: 1
Training loss: 2.84367823248211
Validation loss: 2.4123955842331126

Epoch: 5| Step: 2
Training loss: 2.8346293981882784
Validation loss: 2.42081286864173

Epoch: 5| Step: 3
Training loss: 3.2963646950294683
Validation loss: 2.4106389719704375

Epoch: 5| Step: 4
Training loss: 2.375154791355281
Validation loss: 2.422720659262098

Epoch: 5| Step: 5
Training loss: 3.2994527998876606
Validation loss: 2.412123842076843

Epoch: 5| Step: 6
Training loss: 2.8920251702866087
Validation loss: 2.414262000277532

Epoch: 5| Step: 7
Training loss: 2.192309079703897
Validation loss: 2.4025084288284293

Epoch: 5| Step: 8
Training loss: 2.5466418949473586
Validation loss: 2.401808706789148

Epoch: 5| Step: 9
Training loss: 2.68211730587845
Validation loss: 2.4095593045583037

Epoch: 5| Step: 10
Training loss: 2.841001586795459
Validation loss: 2.411674160998595

Epoch: 35| Step: 0
Training loss: 2.9462092726704157
Validation loss: 2.40967403881169

Epoch: 5| Step: 1
Training loss: 2.7217502920179157
Validation loss: 2.410104803390946

Epoch: 5| Step: 2
Training loss: 2.5838535359330663
Validation loss: 2.414488791982456

Epoch: 5| Step: 3
Training loss: 2.5548726519296663
Validation loss: 2.416588770516569

Epoch: 5| Step: 4
Training loss: 2.8230783526485537
Validation loss: 2.400632523431993

Epoch: 5| Step: 5
Training loss: 2.703753359753289
Validation loss: 2.4133295866860625

Epoch: 5| Step: 6
Training loss: 2.7307004816611493
Validation loss: 2.4072449588403426

Epoch: 5| Step: 7
Training loss: 2.909079210301198
Validation loss: 2.4202195854875144

Epoch: 5| Step: 8
Training loss: 2.691731249228368
Validation loss: 2.4247897029566334

Epoch: 5| Step: 9
Training loss: 3.195178786933331
Validation loss: 2.407013548114309

Epoch: 5| Step: 10
Training loss: 2.422791732055503
Validation loss: 2.412668165500389

Epoch: 36| Step: 0
Training loss: 3.2923683352202167
Validation loss: 2.4174418353638574

Epoch: 5| Step: 1
Training loss: 2.579092225791269
Validation loss: 2.420426309691087

Epoch: 5| Step: 2
Training loss: 2.3946470447315513
Validation loss: 2.405518085813736

Epoch: 5| Step: 3
Training loss: 2.918860201011154
Validation loss: 2.4180279120388097

Epoch: 5| Step: 4
Training loss: 2.891312141195957
Validation loss: 2.410319718603895

Epoch: 5| Step: 5
Training loss: 2.3724297117346977
Validation loss: 2.4128962178296045

Epoch: 5| Step: 6
Training loss: 3.185707036803733
Validation loss: 2.4062065277199918

Epoch: 5| Step: 7
Training loss: 2.9505085329010945
Validation loss: 2.420305757893121

Epoch: 5| Step: 8
Training loss: 2.5670604597757896
Validation loss: 2.395290058133255

Epoch: 5| Step: 9
Training loss: 2.606648008112296
Validation loss: 2.4062497389747572

Epoch: 5| Step: 10
Training loss: 2.369970416918551
Validation loss: 2.4094397300363948

Epoch: 37| Step: 0
Training loss: 2.9371912367856123
Validation loss: 2.410506369648795

Epoch: 5| Step: 1
Training loss: 2.7375188574293867
Validation loss: 2.41192230752023

Epoch: 5| Step: 2
Training loss: 1.8952044677135838
Validation loss: 2.4110324703025743

Epoch: 5| Step: 3
Training loss: 2.6485476850696665
Validation loss: 2.413074023818598

Epoch: 5| Step: 4
Training loss: 2.927700009440154
Validation loss: 2.4024821990788454

Epoch: 5| Step: 5
Training loss: 2.943823804962778
Validation loss: 2.41545094203354

Epoch: 5| Step: 6
Training loss: 2.707533136166788
Validation loss: 2.412063603114079

Epoch: 5| Step: 7
Training loss: 2.5177947928487905
Validation loss: 2.4167071421468855

Epoch: 5| Step: 8
Training loss: 3.2767144236636803
Validation loss: 2.4113007886937052

Epoch: 5| Step: 9
Training loss: 3.0511926039095507
Validation loss: 2.410062790930359

Epoch: 5| Step: 10
Training loss: 2.4703068713245293
Validation loss: 2.4083210577319987

Epoch: 38| Step: 0
Training loss: 2.974912491481088
Validation loss: 2.4220670181352393

Epoch: 5| Step: 1
Training loss: 2.615622345662109
Validation loss: 2.404795048715564

Epoch: 5| Step: 2
Training loss: 2.8495185110706127
Validation loss: 2.4087068554711863

Epoch: 5| Step: 3
Training loss: 2.7896732975814156
Validation loss: 2.4174682792651385

Epoch: 5| Step: 4
Training loss: 2.498210743531838
Validation loss: 2.4195823400447334

Epoch: 5| Step: 5
Training loss: 2.6559834066010533
Validation loss: 2.4083968580131057

Epoch: 5| Step: 6
Training loss: 2.543943625539268
Validation loss: 2.4114786868043856

Epoch: 5| Step: 7
Training loss: 2.595726179561603
Validation loss: 2.4096248794368376

Epoch: 5| Step: 8
Training loss: 3.0876685586856465
Validation loss: 2.4161823736527923

Epoch: 5| Step: 9
Training loss: 2.899549738689404
Validation loss: 2.410265490891499

Epoch: 5| Step: 10
Training loss: 2.849849322167335
Validation loss: 2.409700090272548

Epoch: 39| Step: 0
Training loss: 2.9024367388157057
Validation loss: 2.414580274792655

Epoch: 5| Step: 1
Training loss: 2.525619649864898
Validation loss: 2.4043094367479863

Epoch: 5| Step: 2
Training loss: 2.854301245270878
Validation loss: 2.406374856314218

Epoch: 5| Step: 3
Training loss: 2.4851881891600827
Validation loss: 2.411606108612994

Epoch: 5| Step: 4
Training loss: 2.5431151926559825
Validation loss: 2.403144665167467

Epoch: 5| Step: 5
Training loss: 2.901208914975783
Validation loss: 2.411239378781931

Epoch: 5| Step: 6
Training loss: 2.7243533215816536
Validation loss: 2.4185402237413616

Epoch: 5| Step: 7
Training loss: 2.3616522100414885
Validation loss: 2.4165797580400166

Epoch: 5| Step: 8
Training loss: 3.0808898591508833
Validation loss: 2.4160871740937337

Epoch: 5| Step: 9
Training loss: 2.9572399070826147
Validation loss: 2.406245329241993

Epoch: 5| Step: 10
Training loss: 2.8935670469382515
Validation loss: 2.4114784635535806

Epoch: 40| Step: 0
Training loss: 3.034411168300312
Validation loss: 2.4098327784493203

Epoch: 5| Step: 1
Training loss: 2.8268541041193767
Validation loss: 2.4134591223307744

Epoch: 5| Step: 2
Training loss: 2.98162011622139
Validation loss: 2.409206726472366

Epoch: 5| Step: 3
Training loss: 3.1253983815891595
Validation loss: 2.396772821243238

Epoch: 5| Step: 4
Training loss: 2.6405348903472405
Validation loss: 2.408978052963939

Epoch: 5| Step: 5
Training loss: 1.7361020948387837
Validation loss: 2.4032513243132643

Epoch: 5| Step: 6
Training loss: 3.05607709961145
Validation loss: 2.414509822442028

Epoch: 5| Step: 7
Training loss: 2.706553495449604
Validation loss: 2.4092886513226324

Epoch: 5| Step: 8
Training loss: 2.854976919585296
Validation loss: 2.4119609549129035

Epoch: 5| Step: 9
Training loss: 2.435786892368497
Validation loss: 2.41939303761068

Epoch: 5| Step: 10
Training loss: 2.5430970049742467
Validation loss: 2.408599079242693

Epoch: 41| Step: 0
Training loss: 2.927175192336191
Validation loss: 2.4175056593089232

Epoch: 5| Step: 1
Training loss: 2.7386362931270583
Validation loss: 2.409038303103205

Epoch: 5| Step: 2
Training loss: 2.522468309912281
Validation loss: 2.398537597405969

Epoch: 5| Step: 3
Training loss: 2.750009189937148
Validation loss: 2.4220801709479485

Epoch: 5| Step: 4
Training loss: 2.3850291463482503
Validation loss: 2.4163818050044137

Epoch: 5| Step: 5
Training loss: 2.7435745252662076
Validation loss: 2.4019152128603096

Epoch: 5| Step: 6
Training loss: 2.7000620693560444
Validation loss: 2.4125904448639117

Epoch: 5| Step: 7
Training loss: 3.3703969011982022
Validation loss: 2.4070927870369094

Epoch: 5| Step: 8
Training loss: 2.670281453674799
Validation loss: 2.4177807134394045

Epoch: 5| Step: 9
Training loss: 2.716865939065318
Validation loss: 2.4034443556876495

Epoch: 5| Step: 10
Training loss: 2.6004865557897547
Validation loss: 2.4056067840920896

Epoch: 42| Step: 0
Training loss: 2.500996867748741
Validation loss: 2.409161791172644

Epoch: 5| Step: 1
Training loss: 2.410683745740772
Validation loss: 2.4038665851074983

Epoch: 5| Step: 2
Training loss: 2.5665435522037976
Validation loss: 2.4148056118932506

Epoch: 5| Step: 3
Training loss: 2.760182775029328
Validation loss: 2.4092824861199538

Epoch: 5| Step: 4
Training loss: 3.0163823100861378
Validation loss: 2.405700857453263

Epoch: 5| Step: 5
Training loss: 2.4165389805528172
Validation loss: 2.413655169543864

Epoch: 5| Step: 6
Training loss: 3.1323202226811024
Validation loss: 2.40809176143545

Epoch: 5| Step: 7
Training loss: 2.936916536864273
Validation loss: 2.4246194543638597

Epoch: 5| Step: 8
Training loss: 2.7052257511330744
Validation loss: 2.4104671294061735

Epoch: 5| Step: 9
Training loss: 2.6113432810307184
Validation loss: 2.4167248675035733

Epoch: 5| Step: 10
Training loss: 3.1152276400789267
Validation loss: 2.408567989326119

Epoch: 43| Step: 0
Training loss: 2.8207337970912345
Validation loss: 2.4146440490933396

Epoch: 5| Step: 1
Training loss: 2.697165916196515
Validation loss: 2.409075721367517

Epoch: 5| Step: 2
Training loss: 2.991882468031565
Validation loss: 2.403255737406254

Epoch: 5| Step: 3
Training loss: 2.9962118391615498
Validation loss: 2.4151575456441314

Epoch: 5| Step: 4
Training loss: 2.963049143182501
Validation loss: 2.410804863225524

Epoch: 5| Step: 5
Training loss: 2.586264782619496
Validation loss: 2.4038607739302913

Epoch: 5| Step: 6
Training loss: 2.7180101988533
Validation loss: 2.4204505142307826

Epoch: 5| Step: 7
Training loss: 2.398618511116626
Validation loss: 2.4039457517993736

Epoch: 5| Step: 8
Training loss: 2.5664535355530185
Validation loss: 2.4019518914396816

Epoch: 5| Step: 9
Training loss: 2.7021717309033964
Validation loss: 2.4113621832206045

Epoch: 5| Step: 10
Training loss: 2.5553414443985636
Validation loss: 2.4161399851547642

Epoch: 44| Step: 0
Training loss: 3.0637956330890366
Validation loss: 2.404900145454184

Epoch: 5| Step: 1
Training loss: 2.4869343751931483
Validation loss: 2.4023508101975763

Epoch: 5| Step: 2
Training loss: 2.9404750935758566
Validation loss: 2.416776782600993

Epoch: 5| Step: 3
Training loss: 2.3439019726119854
Validation loss: 2.4126213761548176

Epoch: 5| Step: 4
Training loss: 2.6033710230672726
Validation loss: 2.4093524614141804

Epoch: 5| Step: 5
Training loss: 2.7671308135780506
Validation loss: 2.413961451217901

Epoch: 5| Step: 6
Training loss: 3.135177214509865
Validation loss: 2.4147081975434532

Epoch: 5| Step: 7
Training loss: 2.675681631642429
Validation loss: 2.3984573276324572

Epoch: 5| Step: 8
Training loss: 2.711697254848543
Validation loss: 2.4114257013669853

Epoch: 5| Step: 9
Training loss: 2.6656036841198762
Validation loss: 2.408230860496144

Epoch: 5| Step: 10
Training loss: 2.631735018067409
Validation loss: 2.414575610062254

Epoch: 45| Step: 0
Training loss: 3.04356274665236
Validation loss: 2.4037441165619504

Epoch: 5| Step: 1
Training loss: 2.941677288724257
Validation loss: 2.4144701461029707

Epoch: 5| Step: 2
Training loss: 3.231037869306181
Validation loss: 2.4227771085862067

Epoch: 5| Step: 3
Training loss: 2.14129817429669
Validation loss: 2.4069892483938595

Epoch: 5| Step: 4
Training loss: 2.2601356038621794
Validation loss: 2.411348650341369

Epoch: 5| Step: 5
Training loss: 2.550792653173688
Validation loss: 2.4121498235046475

Epoch: 5| Step: 6
Training loss: 2.8252430769056875
Validation loss: 2.404644655818816

Epoch: 5| Step: 7
Training loss: 2.9679394067095464
Validation loss: 2.4088789385469993

Epoch: 5| Step: 8
Training loss: 2.4515023666018743
Validation loss: 2.402633293918566

Epoch: 5| Step: 9
Training loss: 2.6539672018064127
Validation loss: 2.4102977453806367

Epoch: 5| Step: 10
Training loss: 2.8874647856707742
Validation loss: 2.4135675477443446

Epoch: 46| Step: 0
Training loss: 2.7173250344529984
Validation loss: 2.413519297783408

Epoch: 5| Step: 1
Training loss: 2.695527087528903
Validation loss: 2.409507848395474

Epoch: 5| Step: 2
Training loss: 2.672047302758222
Validation loss: 2.4088247507699942

Epoch: 5| Step: 3
Training loss: 2.956941751917166
Validation loss: 2.4090596264345217

Epoch: 5| Step: 4
Training loss: 2.51369663039602
Validation loss: 2.4025976490223746

Epoch: 5| Step: 5
Training loss: 2.7936162451486948
Validation loss: 2.4088032066500067

Epoch: 5| Step: 6
Training loss: 2.6445043835761397
Validation loss: 2.405898797420477

Epoch: 5| Step: 7
Training loss: 2.7571445769326517
Validation loss: 2.4056360638556296

Epoch: 5| Step: 8
Training loss: 2.2292298518938023
Validation loss: 2.4140379271554373

Epoch: 5| Step: 9
Training loss: 2.9601057590458364
Validation loss: 2.4123385699746276

Epoch: 5| Step: 10
Training loss: 3.0744714112043696
Validation loss: 2.410047826420486

Epoch: 47| Step: 0
Training loss: 3.115062017665357
Validation loss: 2.4019268819712063

Epoch: 5| Step: 1
Training loss: 2.3309963875852633
Validation loss: 2.411674141332857

Epoch: 5| Step: 2
Training loss: 2.3201379164447236
Validation loss: 2.4138397985944064

Epoch: 5| Step: 3
Training loss: 2.7160409167695105
Validation loss: 2.406252235759948

Epoch: 5| Step: 4
Training loss: 2.7948370813373473
Validation loss: 2.407059871872205

Epoch: 5| Step: 5
Training loss: 2.576884485671862
Validation loss: 2.410021221317821

Epoch: 5| Step: 6
Training loss: 2.17598078307614
Validation loss: 2.4036943298367164

Epoch: 5| Step: 7
Training loss: 2.9699389837400147
Validation loss: 2.4179400060418508

Epoch: 5| Step: 8
Training loss: 3.071206154485102
Validation loss: 2.4016868047224404

Epoch: 5| Step: 9
Training loss: 2.9710827145407896
Validation loss: 2.4124866448458393

Epoch: 5| Step: 10
Training loss: 2.793759363487306
Validation loss: 2.416162919599657

Epoch: 48| Step: 0
Training loss: 2.9942906411170984
Validation loss: 2.397312247329465

Epoch: 5| Step: 1
Training loss: 2.4505588205591025
Validation loss: 2.4169476520424826

Epoch: 5| Step: 2
Training loss: 2.758626844650012
Validation loss: 2.404028635467806

Epoch: 5| Step: 3
Training loss: 2.831225639726879
Validation loss: 2.4104809341827487

Epoch: 5| Step: 4
Training loss: 3.0710362947456384
Validation loss: 2.40049279611609

Epoch: 5| Step: 5
Training loss: 2.487851763059547
Validation loss: 2.4038927421630354

Epoch: 5| Step: 6
Training loss: 2.4999917983874256
Validation loss: 2.4059196003485965

Epoch: 5| Step: 7
Training loss: 2.3363295006122122
Validation loss: 2.3991241418152858

Epoch: 5| Step: 8
Training loss: 2.9588467506155047
Validation loss: 2.413755342173604

Epoch: 5| Step: 9
Training loss: 2.44308448178235
Validation loss: 2.4122386095156845

Epoch: 5| Step: 10
Training loss: 3.0652663523703976
Validation loss: 2.4164623503689198

Epoch: 49| Step: 0
Training loss: 2.308036517490691
Validation loss: 2.40535504334825

Epoch: 5| Step: 1
Training loss: 3.363618663207024
Validation loss: 2.3934353941509228

Epoch: 5| Step: 2
Training loss: 2.861029307935642
Validation loss: 2.408823766319767

Epoch: 5| Step: 3
Training loss: 2.5505923424676933
Validation loss: 2.3979397545489514

Epoch: 5| Step: 4
Training loss: 2.6918441792661807
Validation loss: 2.407064670985564

Epoch: 5| Step: 5
Training loss: 1.8854597167550038
Validation loss: 2.4154926092427056

Epoch: 5| Step: 6
Training loss: 2.6194017750876393
Validation loss: 2.417945517787643

Epoch: 5| Step: 7
Training loss: 2.2640213124785142
Validation loss: 2.4184509588519263

Epoch: 5| Step: 8
Training loss: 2.5085543191924042
Validation loss: 2.397931451893472

Epoch: 5| Step: 9
Training loss: 3.151294103341806
Validation loss: 2.4161654056103763

Epoch: 5| Step: 10
Training loss: 3.385196119118149
Validation loss: 2.4206657298981726

Epoch: 50| Step: 0
Training loss: 2.6528610152078307
Validation loss: 2.4062346974805062

Epoch: 5| Step: 1
Training loss: 2.825928651879576
Validation loss: 2.4142804295512503

Epoch: 5| Step: 2
Training loss: 2.7896133861864927
Validation loss: 2.4071469317965724

Epoch: 5| Step: 3
Training loss: 3.2741509072136563
Validation loss: 2.4040651058506444

Epoch: 5| Step: 4
Training loss: 3.18608196355703
Validation loss: 2.402973738665826

Epoch: 5| Step: 5
Training loss: 2.6745151615165934
Validation loss: 2.4057506388850736

Epoch: 5| Step: 6
Training loss: 2.474485278311052
Validation loss: 2.418969191130809

Epoch: 5| Step: 7
Training loss: 2.262941441754743
Validation loss: 2.4167316454198726

Epoch: 5| Step: 8
Training loss: 2.2190218476865553
Validation loss: 2.4090106928998454

Epoch: 5| Step: 9
Training loss: 2.655377592546224
Validation loss: 2.4132337604218925

Epoch: 5| Step: 10
Training loss: 2.624103665589454
Validation loss: 2.4052095682221672

Epoch: 51| Step: 0
Training loss: 2.5300481321257116
Validation loss: 2.409423668923145

Epoch: 5| Step: 1
Training loss: 2.426061346865005
Validation loss: 2.4135523627863558

Epoch: 5| Step: 2
Training loss: 3.147689541176486
Validation loss: 2.41033857421175

Epoch: 5| Step: 3
Training loss: 2.4339165389296613
Validation loss: 2.4013949693887957

Epoch: 5| Step: 4
Training loss: 2.2457160433100567
Validation loss: 2.4103363608552244

Epoch: 5| Step: 5
Training loss: 2.9754793694508024
Validation loss: 2.394111236601287

Epoch: 5| Step: 6
Training loss: 3.2609185430746153
Validation loss: 2.414127930788773

Epoch: 5| Step: 7
Training loss: 2.4354182425810125
Validation loss: 2.416332542849269

Epoch: 5| Step: 8
Training loss: 2.5575713233287503
Validation loss: 2.4076285342812294

Epoch: 5| Step: 9
Training loss: 2.9237354903495114
Validation loss: 2.4091544795833597

Epoch: 5| Step: 10
Training loss: 2.839735278297198
Validation loss: 2.4124844122069646

Epoch: 52| Step: 0
Training loss: 3.4282537778662334
Validation loss: 2.420344784605909

Epoch: 5| Step: 1
Training loss: 2.8509761677805954
Validation loss: 2.411512646200456

Epoch: 5| Step: 2
Training loss: 2.3786294209182954
Validation loss: 2.4041835465343993

Epoch: 5| Step: 3
Training loss: 2.3064380269303384
Validation loss: 2.4049303127329664

Epoch: 5| Step: 4
Training loss: 2.6069644598197312
Validation loss: 2.414277460043086

Epoch: 5| Step: 5
Training loss: 2.4340019557258565
Validation loss: 2.416611315086626

Epoch: 5| Step: 6
Training loss: 2.540963831380292
Validation loss: 2.402667699502069

Epoch: 5| Step: 7
Training loss: 3.1770306859057897
Validation loss: 2.419865849579431

Epoch: 5| Step: 8
Training loss: 2.486036788520917
Validation loss: 2.397959701759026

Epoch: 5| Step: 9
Training loss: 2.5215180363022314
Validation loss: 2.4028710585019444

Epoch: 5| Step: 10
Training loss: 2.9309943374376055
Validation loss: 2.421280714485216

Epoch: 53| Step: 0
Training loss: 2.9226378398724324
Validation loss: 2.4078204822181055

Epoch: 5| Step: 1
Training loss: 2.7954666598410647
Validation loss: 2.417775255924929

Epoch: 5| Step: 2
Training loss: 2.684110588933602
Validation loss: 2.4111047424963945

Epoch: 5| Step: 3
Training loss: 2.318619132654609
Validation loss: 2.397717572165411

Epoch: 5| Step: 4
Training loss: 3.0326339865675145
Validation loss: 2.4011010571552287

Epoch: 5| Step: 5
Training loss: 2.7713862180633777
Validation loss: 2.402194458672723

Epoch: 5| Step: 6
Training loss: 2.5040659265888685
Validation loss: 2.405042461719436

Epoch: 5| Step: 7
Training loss: 2.753624781299686
Validation loss: 2.4007125677711625

Epoch: 5| Step: 8
Training loss: 2.6039468189264388
Validation loss: 2.4040292678390993

Epoch: 5| Step: 9
Training loss: 2.6598545525158985
Validation loss: 2.4013008026063014

Epoch: 5| Step: 10
Training loss: 2.746725647286897
Validation loss: 2.415776934079686

Epoch: 54| Step: 0
Training loss: 2.524144690657126
Validation loss: 2.409662920017337

Epoch: 5| Step: 1
Training loss: 2.824117022907501
Validation loss: 2.4140267169531953

Epoch: 5| Step: 2
Training loss: 2.9460909596351312
Validation loss: 2.3965512826880038

Epoch: 5| Step: 3
Training loss: 2.883465948711788
Validation loss: 2.4158938736644266

Epoch: 5| Step: 4
Training loss: 2.2083597961375716
Validation loss: 2.4058054969044713

Epoch: 5| Step: 5
Training loss: 2.555224440957105
Validation loss: 2.3970450790974054

Epoch: 5| Step: 6
Training loss: 3.263786272821148
Validation loss: 2.41429510183058

Epoch: 5| Step: 7
Training loss: 2.92726804392573
Validation loss: 2.4098695216248927

Epoch: 5| Step: 8
Training loss: 2.179188989217392
Validation loss: 2.4155897107174846

Epoch: 5| Step: 9
Training loss: 2.5705959546400363
Validation loss: 2.410183672638355

Epoch: 5| Step: 10
Training loss: 2.792074591216843
Validation loss: 2.4183343734846963

Epoch: 55| Step: 0
Training loss: 2.3861251067803466
Validation loss: 2.4016690297562153

Epoch: 5| Step: 1
Training loss: 2.4260432643947905
Validation loss: 2.4062284711821023

Epoch: 5| Step: 2
Training loss: 2.6317340215366607
Validation loss: 2.4187722582443585

Epoch: 5| Step: 3
Training loss: 2.84796936239415
Validation loss: 2.4207099856722207

Epoch: 5| Step: 4
Training loss: 2.9811935643386525
Validation loss: 2.4077619704050073

Epoch: 5| Step: 5
Training loss: 3.251373294309682
Validation loss: 2.401192258892529

Epoch: 5| Step: 6
Training loss: 2.882233352172324
Validation loss: 2.4056950880048293

Epoch: 5| Step: 7
Training loss: 2.456968952596063
Validation loss: 2.4015841084984486

Epoch: 5| Step: 8
Training loss: 2.4547548164641326
Validation loss: 2.411811094958568

Epoch: 5| Step: 9
Training loss: 2.841472342401354
Validation loss: 2.4032964149252964

Epoch: 5| Step: 10
Training loss: 2.4980094614575123
Validation loss: 2.421202172305526

Epoch: 56| Step: 0
Training loss: 2.3408685901232444
Validation loss: 2.402981757184946

Epoch: 5| Step: 1
Training loss: 3.0415082568022545
Validation loss: 2.410285357899695

Epoch: 5| Step: 2
Training loss: 2.5502082216108897
Validation loss: 2.4190143225935983

Epoch: 5| Step: 3
Training loss: 2.3591526760421746
Validation loss: 2.417995527413635

Epoch: 5| Step: 4
Training loss: 2.5977669369627554
Validation loss: 2.4135482330050957

Epoch: 5| Step: 5
Training loss: 3.453030269928711
Validation loss: 2.4114479396584296

Epoch: 5| Step: 6
Training loss: 2.61443272697668
Validation loss: 2.402974144073236

Epoch: 5| Step: 7
Training loss: 2.563417317023711
Validation loss: 2.422888638349775

Epoch: 5| Step: 8
Training loss: 2.6249982743030507
Validation loss: 2.4104419785591484

Epoch: 5| Step: 9
Training loss: 2.974911690050418
Validation loss: 2.4080646684240485

Epoch: 5| Step: 10
Training loss: 2.4449083280637534
Validation loss: 2.4078778525940714

Epoch: 57| Step: 0
Training loss: 2.299073704490928
Validation loss: 2.4024127012892906

Epoch: 5| Step: 1
Training loss: 2.7341655541994885
Validation loss: 2.3893718535532997

Epoch: 5| Step: 2
Training loss: 2.9681460117504854
Validation loss: 2.4159818498658647

Epoch: 5| Step: 3
Training loss: 2.922096611227404
Validation loss: 2.4131909132525107

Epoch: 5| Step: 4
Training loss: 2.4499773374793894
Validation loss: 2.405975739545724

Epoch: 5| Step: 5
Training loss: 3.0125086993966392
Validation loss: 2.4086100959793275

Epoch: 5| Step: 6
Training loss: 2.86024220141313
Validation loss: 2.4221327550239824

Epoch: 5| Step: 7
Training loss: 2.317897786030345
Validation loss: 2.4115350931157447

Epoch: 5| Step: 8
Training loss: 3.0409389478832716
Validation loss: 2.402877227351943

Epoch: 5| Step: 9
Training loss: 2.913443573787143
Validation loss: 2.406839552871085

Epoch: 5| Step: 10
Training loss: 2.0225803518660608
Validation loss: 2.4245027352597557

Epoch: 58| Step: 0
Training loss: 2.8577425940354826
Validation loss: 2.410431567384517

Epoch: 5| Step: 1
Training loss: 3.2124852814689726
Validation loss: 2.412653449324426

Epoch: 5| Step: 2
Training loss: 2.5941973380891774
Validation loss: 2.4231176019527645

Epoch: 5| Step: 3
Training loss: 2.709359889004817
Validation loss: 2.4131169527417606

Epoch: 5| Step: 4
Training loss: 2.8482144702137444
Validation loss: 2.4070200972277673

Epoch: 5| Step: 5
Training loss: 2.3021310884749697
Validation loss: 2.4200140338044336

Epoch: 5| Step: 6
Training loss: 2.7099387668012005
Validation loss: 2.4113501738439407

Epoch: 5| Step: 7
Training loss: 2.6630497682728986
Validation loss: 2.4096628295858262

Epoch: 5| Step: 8
Training loss: 2.8922076867057025
Validation loss: 2.4141242628715225

Epoch: 5| Step: 9
Training loss: 1.9704673179891687
Validation loss: 2.4061182542970982

Epoch: 5| Step: 10
Training loss: 2.8858433119971925
Validation loss: 2.415179240068199

Epoch: 59| Step: 0
Training loss: 2.4779982391301902
Validation loss: 2.400286132921961

Epoch: 5| Step: 1
Training loss: 2.583719183706206
Validation loss: 2.4235597263736546

Epoch: 5| Step: 2
Training loss: 3.2703331404908096
Validation loss: 2.406169078687719

Epoch: 5| Step: 3
Training loss: 2.660802463010335
Validation loss: 2.4086216954027537

Epoch: 5| Step: 4
Training loss: 2.7711852478804206
Validation loss: 2.4151008672720735

Epoch: 5| Step: 5
Training loss: 2.7787373368922377
Validation loss: 2.410184256593244

Epoch: 5| Step: 6
Training loss: 2.758563493267233
Validation loss: 2.4165923445209754

Epoch: 5| Step: 7
Training loss: 2.3868056560870636
Validation loss: 2.4029220603964943

Epoch: 5| Step: 8
Training loss: 2.385368602107423
Validation loss: 2.415697676496321

Epoch: 5| Step: 9
Training loss: 2.802965320814933
Validation loss: 2.4155710361906015

Epoch: 5| Step: 10
Training loss: 2.835923039843472
Validation loss: 2.4011087979225705

Epoch: 60| Step: 0
Training loss: 2.874521630336339
Validation loss: 2.4122034397377643

Epoch: 5| Step: 1
Training loss: 2.8128922083028716
Validation loss: 2.414899175102636

Epoch: 5| Step: 2
Training loss: 2.3379420224613408
Validation loss: 2.427337726807719

Epoch: 5| Step: 3
Training loss: 2.6042154434722344
Validation loss: 2.4076064395990486

Epoch: 5| Step: 4
Training loss: 2.563077535908371
Validation loss: 2.409059704650761

Epoch: 5| Step: 5
Training loss: 2.613897003024303
Validation loss: 2.4057943240002135

Epoch: 5| Step: 6
Training loss: 2.891156946672977
Validation loss: 2.392540275135384

Epoch: 5| Step: 7
Training loss: 2.734989467788864
Validation loss: 2.4171749097878537

Epoch: 5| Step: 8
Training loss: 2.9923932276187784
Validation loss: 2.405948198620158

Epoch: 5| Step: 9
Training loss: 2.7700036510897927
Validation loss: 2.4218708044909585

Epoch: 5| Step: 10
Training loss: 2.3685688482984064
Validation loss: 2.4089945139930538

Epoch: 61| Step: 0
Training loss: 2.9286922137510016
Validation loss: 2.4137495356861085

Epoch: 5| Step: 1
Training loss: 3.042503781719882
Validation loss: 2.4158791071009293

Epoch: 5| Step: 2
Training loss: 2.447843661470932
Validation loss: 2.4100667341504676

Epoch: 5| Step: 3
Training loss: 2.3257907712188595
Validation loss: 2.4231163175493355

Epoch: 5| Step: 4
Training loss: 3.2312819577081107
Validation loss: 2.412815752108709

Epoch: 5| Step: 5
Training loss: 2.3900790120874658
Validation loss: 2.405726591752849

Epoch: 5| Step: 6
Training loss: 2.2822181006141267
Validation loss: 2.404690664869085

Epoch: 5| Step: 7
Training loss: 2.799020721985765
Validation loss: 2.4143243994005195

Epoch: 5| Step: 8
Training loss: 2.694279304066814
Validation loss: 2.410419459777445

Epoch: 5| Step: 9
Training loss: 2.529375111905325
Validation loss: 2.4042645560003253

Epoch: 5| Step: 10
Training loss: 2.787473680175237
Validation loss: 2.391673194533621

Epoch: 62| Step: 0
Training loss: 2.7825095078682036
Validation loss: 2.418675533622806

Epoch: 5| Step: 1
Training loss: 2.3469466725464505
Validation loss: 2.4098780618675777

Epoch: 5| Step: 2
Training loss: 2.7459442401845373
Validation loss: 2.4243941887567964

Epoch: 5| Step: 3
Training loss: 2.538394593643216
Validation loss: 2.4174311457355233

Epoch: 5| Step: 4
Training loss: 2.577883529914595
Validation loss: 2.4037695102636722

Epoch: 5| Step: 5
Training loss: 2.5360168030961345
Validation loss: 2.410822240119559

Epoch: 5| Step: 6
Training loss: 2.1687852576300353
Validation loss: 2.420589198584561

Epoch: 5| Step: 7
Training loss: 3.243381804221344
Validation loss: 2.4109510587504883

Epoch: 5| Step: 8
Training loss: 3.1640603901420437
Validation loss: 2.4163120979961015

Epoch: 5| Step: 9
Training loss: 2.9215020742440028
Validation loss: 2.408184116409165

Epoch: 5| Step: 10
Training loss: 2.3111794283848255
Validation loss: 2.4022496161404185

Epoch: 63| Step: 0
Training loss: 2.6367647746272493
Validation loss: 2.4162209725345485

Epoch: 5| Step: 1
Training loss: 2.2851702306596904
Validation loss: 2.406291672583204

Epoch: 5| Step: 2
Training loss: 2.9081955827009316
Validation loss: 2.4130681933812945

Epoch: 5| Step: 3
Training loss: 2.74286158609598
Validation loss: 2.4000873455352143

Epoch: 5| Step: 4
Training loss: 2.243952358970897
Validation loss: 2.4073064003628395

Epoch: 5| Step: 5
Training loss: 2.9275877892339754
Validation loss: 2.4327331052442016

Epoch: 5| Step: 6
Training loss: 2.6750522038009468
Validation loss: 2.409555194531959

Epoch: 5| Step: 7
Training loss: 3.0357236589559533
Validation loss: 2.410375396891118

Epoch: 5| Step: 8
Training loss: 2.5809190810479667
Validation loss: 2.4200432462496893

Epoch: 5| Step: 9
Training loss: 2.9530368367916173
Validation loss: 2.427851465651813

Epoch: 5| Step: 10
Training loss: 2.435433220677913
Validation loss: 2.414149200138852

Epoch: 64| Step: 0
Training loss: 2.7948370813373473
Validation loss: 2.4220072985030283

Epoch: 5| Step: 1
Training loss: 2.914215329332713
Validation loss: 2.4120456282763016

Epoch: 5| Step: 2
Training loss: 2.4545732827326985
Validation loss: 2.4160297662739256

Epoch: 5| Step: 3
Training loss: 2.5945953462305353
Validation loss: 2.4048915875339394

Epoch: 5| Step: 4
Training loss: 2.618561159303603
Validation loss: 2.410943897200999

Epoch: 5| Step: 5
Training loss: 2.3568741637000574
Validation loss: 2.406587440408818

Epoch: 5| Step: 6
Training loss: 2.855418318317477
Validation loss: 2.4253760303495424

Epoch: 5| Step: 7
Training loss: 3.2718647749922307
Validation loss: 2.4146166925060815

Epoch: 5| Step: 8
Training loss: 2.3237726889452195
Validation loss: 2.408654830830969

Epoch: 5| Step: 9
Training loss: 2.3362046921420276
Validation loss: 2.422112077587071

Epoch: 5| Step: 10
Training loss: 2.9480867550220973
Validation loss: 2.399134377125338

Epoch: 65| Step: 0
Training loss: 2.601202037686238
Validation loss: 2.417863178514609

Epoch: 5| Step: 1
Training loss: 2.7164945345057765
Validation loss: 2.424932825722515

Epoch: 5| Step: 2
Training loss: 2.8724747223567717
Validation loss: 2.4073202328490324

Epoch: 5| Step: 3
Training loss: 2.89648651513955
Validation loss: 2.425205586658979

Epoch: 5| Step: 4
Training loss: 2.1915398487295037
Validation loss: 2.4017248413418835

Epoch: 5| Step: 5
Training loss: 2.1476097038056916
Validation loss: 2.3970986251751265

Epoch: 5| Step: 6
Training loss: 2.5970472955756008
Validation loss: 2.4181310490641508

Epoch: 5| Step: 7
Training loss: 2.803995966332945
Validation loss: 2.410874979624374

Epoch: 5| Step: 8
Training loss: 3.392072939772279
Validation loss: 2.420609325595008

Epoch: 5| Step: 9
Training loss: 2.3611873714124174
Validation loss: 2.416055691904666

Epoch: 5| Step: 10
Training loss: 2.7660035989535205
Validation loss: 2.407215289693324

Epoch: 66| Step: 0
Training loss: 2.470624477657588
Validation loss: 2.420042088394395

Epoch: 5| Step: 1
Training loss: 2.277111846475408
Validation loss: 2.4116160480431774

Epoch: 5| Step: 2
Training loss: 2.6924891625543106
Validation loss: 2.3982245013407453

Epoch: 5| Step: 3
Training loss: 2.3187174339783736
Validation loss: 2.404794131909216

Epoch: 5| Step: 4
Training loss: 2.518612811041697
Validation loss: 2.4089986260401774

Epoch: 5| Step: 5
Training loss: 2.8498059859242466
Validation loss: 2.411249078377368

Epoch: 5| Step: 6
Training loss: 2.4878934501144365
Validation loss: 2.4218948135862197

Epoch: 5| Step: 7
Training loss: 2.8384558055152596
Validation loss: 2.412974820535722

Epoch: 5| Step: 8
Training loss: 2.820201163590799
Validation loss: 2.413023465448133

Epoch: 5| Step: 9
Training loss: 2.790848189738034
Validation loss: 2.4026589351679117

Epoch: 5| Step: 10
Training loss: 3.403139846811407
Validation loss: 2.4190929024253385

Epoch: 67| Step: 0
Training loss: 2.9693827707634193
Validation loss: 2.4213462927309184

Epoch: 5| Step: 1
Training loss: 2.1038242351016225
Validation loss: 2.417511904283012

Epoch: 5| Step: 2
Training loss: 2.769168975336255
Validation loss: 2.4066948140616042

Epoch: 5| Step: 3
Training loss: 2.704898142421719
Validation loss: 2.405548790458776

Epoch: 5| Step: 4
Training loss: 2.6772452477400406
Validation loss: 2.419230068708481

Epoch: 5| Step: 5
Training loss: 2.1059223316357905
Validation loss: 2.4119242887715195

Epoch: 5| Step: 6
Training loss: 2.599958778934898
Validation loss: 2.4142237831508346

Epoch: 5| Step: 7
Training loss: 2.7032308392393802
Validation loss: 2.414156627217105

Epoch: 5| Step: 8
Training loss: 3.0152383665178757
Validation loss: 2.4094611280183575

Epoch: 5| Step: 9
Training loss: 3.1102540580282114
Validation loss: 2.4092568195966173

Epoch: 5| Step: 10
Training loss: 2.5800901379475256
Validation loss: 2.402737581492704

Epoch: 68| Step: 0
Training loss: 2.9352973633981727
Validation loss: 2.4137097045259357

Epoch: 5| Step: 1
Training loss: 2.6151538748171106
Validation loss: 2.40211147969959

Epoch: 5| Step: 2
Training loss: 2.7654975818657257
Validation loss: 2.407165712146878

Epoch: 5| Step: 3
Training loss: 3.1441860980995417
Validation loss: 2.408422048312687

Epoch: 5| Step: 4
Training loss: 2.6473169347421197
Validation loss: 2.4156709144695747

Epoch: 5| Step: 5
Training loss: 2.7831432456552037
Validation loss: 2.400638992774507

Epoch: 5| Step: 6
Training loss: 2.6468389407317225
Validation loss: 2.4149903323935136

Epoch: 5| Step: 7
Training loss: 2.8375054850924406
Validation loss: 2.4151047215921335

Epoch: 5| Step: 8
Training loss: 2.776745523872453
Validation loss: 2.399624951345163

Epoch: 5| Step: 9
Training loss: 1.9538901089287943
Validation loss: 2.4313437594165666

Epoch: 5| Step: 10
Training loss: 1.9485165969224012
Validation loss: 2.429772735220141

Epoch: 69| Step: 0
Training loss: 2.9263087613260788
Validation loss: 2.4144243212860093

Epoch: 5| Step: 1
Training loss: 2.4329014952349297
Validation loss: 2.4220597645557755

Epoch: 5| Step: 2
Training loss: 2.76795077187527
Validation loss: 2.419108595194872

Epoch: 5| Step: 3
Training loss: 2.8853548412837595
Validation loss: 2.4055350511617024

Epoch: 5| Step: 4
Training loss: 2.831243829109928
Validation loss: 2.4040153417690324

Epoch: 5| Step: 5
Training loss: 2.2567537458664875
Validation loss: 2.4202773769376558

Epoch: 5| Step: 6
Training loss: 2.707803899417873
Validation loss: 2.4123567360432574

Epoch: 5| Step: 7
Training loss: 2.5759243907731415
Validation loss: 2.4260767927299374

Epoch: 5| Step: 8
Training loss: 2.7731893938870593
Validation loss: 2.41603675995058

Epoch: 5| Step: 9
Training loss: 2.395515077986587
Validation loss: 2.4055576444414046

Epoch: 5| Step: 10
Training loss: 2.8375874913376844
Validation loss: 2.4081623855821697

Epoch: 70| Step: 0
Training loss: 3.207197029391764
Validation loss: 2.4138408277294996

Epoch: 5| Step: 1
Training loss: 2.6222985308619875
Validation loss: 2.407344405697259

Epoch: 5| Step: 2
Training loss: 2.7257115476251212
Validation loss: 2.4170412166557664

Epoch: 5| Step: 3
Training loss: 2.509875343388465
Validation loss: 2.428623056642836

Epoch: 5| Step: 4
Training loss: 2.3638168862903957
Validation loss: 2.407877313861467

Epoch: 5| Step: 5
Training loss: 2.7373202783124944
Validation loss: 2.4182577959530547

Epoch: 5| Step: 6
Training loss: 2.3440617671874375
Validation loss: 2.4024809260521027

Epoch: 5| Step: 7
Training loss: 2.517728695979783
Validation loss: 2.404669637021421

Epoch: 5| Step: 8
Training loss: 2.352301801385406
Validation loss: 2.421904339250415

Epoch: 5| Step: 9
Training loss: 3.094572632206421
Validation loss: 2.4258161642719163

Epoch: 5| Step: 10
Training loss: 2.778493994461442
Validation loss: 2.409854062304429

Epoch: 71| Step: 0
Training loss: 2.4701752230619984
Validation loss: 2.4252359072746423

Epoch: 5| Step: 1
Training loss: 2.7356075451725226
Validation loss: 2.402995181423359

Epoch: 5| Step: 2
Training loss: 2.7036880171430595
Validation loss: 2.415471305022931

Epoch: 5| Step: 3
Training loss: 2.7378205307685
Validation loss: 2.4062424590226072

Epoch: 5| Step: 4
Training loss: 2.416528127799022
Validation loss: 2.423172984061602

Epoch: 5| Step: 5
Training loss: 2.9572561926806324
Validation loss: 2.4006719393768012

Epoch: 5| Step: 6
Training loss: 2.333514637942244
Validation loss: 2.4056092117417203

Epoch: 5| Step: 7
Training loss: 3.0660582132306207
Validation loss: 2.4132606923568725

Epoch: 5| Step: 8
Training loss: 2.323238493061375
Validation loss: 2.4147383542959795

Epoch: 5| Step: 9
Training loss: 2.6630879070972733
Validation loss: 2.3969550682549974

Epoch: 5| Step: 10
Training loss: 2.871164167928964
Validation loss: 2.4134298386884074

Epoch: 72| Step: 0
Training loss: 2.653518978202697
Validation loss: 2.416135605674942

Epoch: 5| Step: 1
Training loss: 3.084140225241887
Validation loss: 2.4150657853523567

Epoch: 5| Step: 2
Training loss: 2.4638602203379496
Validation loss: 2.410261158705799

Epoch: 5| Step: 3
Training loss: 2.4987059104888307
Validation loss: 2.4100534918408263

Epoch: 5| Step: 4
Training loss: 2.4003059986862305
Validation loss: 2.415104920093165

Epoch: 5| Step: 5
Training loss: 2.997956215547004
Validation loss: 2.405939510168969

Epoch: 5| Step: 6
Training loss: 2.599898897552814
Validation loss: 2.400661565923216

Epoch: 5| Step: 7
Training loss: 2.384707638397186
Validation loss: 2.4132858605690797

Epoch: 5| Step: 8
Training loss: 2.973298774085037
Validation loss: 2.4133110072729727

Epoch: 5| Step: 9
Training loss: 2.663720788603083
Validation loss: 2.420026038323094

Epoch: 5| Step: 10
Training loss: 2.492207685526355
Validation loss: 2.4060717110331424

Epoch: 73| Step: 0
Training loss: 2.1613905072581683
Validation loss: 2.4075895644493115

Epoch: 5| Step: 1
Training loss: 3.2958041074464126
Validation loss: 2.416779209638058

Epoch: 5| Step: 2
Training loss: 2.73057588686337
Validation loss: 2.418133792793943

Epoch: 5| Step: 3
Training loss: 2.955719953122112
Validation loss: 2.417960231972154

Epoch: 5| Step: 4
Training loss: 2.1491807796295435
Validation loss: 2.4053035153636086

Epoch: 5| Step: 5
Training loss: 2.669199356734834
Validation loss: 2.4131061292177125

Epoch: 5| Step: 6
Training loss: 2.36218690361725
Validation loss: 2.420883023192934

Epoch: 5| Step: 7
Training loss: 2.240134119718865
Validation loss: 2.411198314283614

Epoch: 5| Step: 8
Training loss: 2.8856299880366585
Validation loss: 2.4214811281998525

Epoch: 5| Step: 9
Training loss: 2.7954684508796164
Validation loss: 2.415551281640073

Epoch: 5| Step: 10
Training loss: 2.838729618861054
Validation loss: 2.4013811428056218

Epoch: 74| Step: 0
Training loss: 2.3647351545308872
Validation loss: 2.4021941598545236

Epoch: 5| Step: 1
Training loss: 2.6939534617187153
Validation loss: 2.404827479982237

Epoch: 5| Step: 2
Training loss: 2.7589755537077583
Validation loss: 2.4073859565725066

Epoch: 5| Step: 3
Training loss: 2.477237741733935
Validation loss: 2.4088392865298682

Epoch: 5| Step: 4
Training loss: 1.9742635392005792
Validation loss: 2.41692944251843

Epoch: 5| Step: 5
Training loss: 2.7064520145984887
Validation loss: 2.4051584496213527

Epoch: 5| Step: 6
Training loss: 2.770631988399546
Validation loss: 2.4206630817064636

Epoch: 5| Step: 7
Training loss: 2.2551734575096014
Validation loss: 2.40835220459246

Epoch: 5| Step: 8
Training loss: 2.9894241840033837
Validation loss: 2.4190509051144744

Epoch: 5| Step: 9
Training loss: 3.1900480968711995
Validation loss: 2.406594311856758

Epoch: 5| Step: 10
Training loss: 3.004430677970532
Validation loss: 2.4136236545707015

Epoch: 75| Step: 0
Training loss: 2.6328211934203654
Validation loss: 2.4160192476018065

Epoch: 5| Step: 1
Training loss: 2.451433120727129
Validation loss: 2.403003400438459

Epoch: 5| Step: 2
Training loss: 2.6958455761057123
Validation loss: 2.410269427398195

Epoch: 5| Step: 3
Training loss: 2.5294721034559493
Validation loss: 2.414975251922139

Epoch: 5| Step: 4
Training loss: 2.70450111597609
Validation loss: 2.4141146098721613

Epoch: 5| Step: 5
Training loss: 2.592099779333683
Validation loss: 2.4114282177763506

Epoch: 5| Step: 6
Training loss: 3.0006512888619086
Validation loss: 2.419048878830969

Epoch: 5| Step: 7
Training loss: 3.2651599023519884
Validation loss: 2.4021497614602936

Epoch: 5| Step: 8
Training loss: 2.578104469911155
Validation loss: 2.401608097300775

Epoch: 5| Step: 9
Training loss: 2.330957008747617
Validation loss: 2.4076957551732114

Epoch: 5| Step: 10
Training loss: 2.3890470395732484
Validation loss: 2.4138748069961746

Epoch: 76| Step: 0
Training loss: 2.3151021184293583
Validation loss: 2.4138702179007985

Epoch: 5| Step: 1
Training loss: 2.79916134944985
Validation loss: 2.4157181626314315

Epoch: 5| Step: 2
Training loss: 2.947229060305821
Validation loss: 2.4166906180236247

Epoch: 5| Step: 3
Training loss: 2.7114118441390636
Validation loss: 2.4083408327351727

Epoch: 5| Step: 4
Training loss: 2.43933378833281
Validation loss: 2.413721919895616

Epoch: 5| Step: 5
Training loss: 2.795091966402353
Validation loss: 2.4095102870102174

Epoch: 5| Step: 6
Training loss: 2.9861344348873873
Validation loss: 2.4121815447842225

Epoch: 5| Step: 7
Training loss: 2.814394672959552
Validation loss: 2.4089041631820898

Epoch: 5| Step: 8
Training loss: 2.1297950499169818
Validation loss: 2.4148521322632637

Epoch: 5| Step: 9
Training loss: 2.6640820991936223
Validation loss: 2.403986014538904

Epoch: 5| Step: 10
Training loss: 2.5128957977550037
Validation loss: 2.4154893249472744

Epoch: 77| Step: 0
Training loss: 2.2905608081019793
Validation loss: 2.4009543056360374

Epoch: 5| Step: 1
Training loss: 2.579051643070474
Validation loss: 2.412647521175615

Epoch: 5| Step: 2
Training loss: 2.2750170486985137
Validation loss: 2.412143236241203

Epoch: 5| Step: 3
Training loss: 3.0913116402039362
Validation loss: 2.41188044310864

Epoch: 5| Step: 4
Training loss: 2.7752978465755764
Validation loss: 2.4161444999100263

Epoch: 5| Step: 5
Training loss: 2.498020437427293
Validation loss: 2.4245321251872425

Epoch: 5| Step: 6
Training loss: 2.9753497198657795
Validation loss: 2.418907869916856

Epoch: 5| Step: 7
Training loss: 2.4851754296626085
Validation loss: 2.4101588475108704

Epoch: 5| Step: 8
Training loss: 2.8185497914873716
Validation loss: 2.4033026552201493

Epoch: 5| Step: 9
Training loss: 2.7290570671458165
Validation loss: 2.411524112597781

Epoch: 5| Step: 10
Training loss: 2.5096128662168695
Validation loss: 2.413333004050243

Epoch: 78| Step: 0
Training loss: 2.9233143571029676
Validation loss: 2.409050749673015

Epoch: 5| Step: 1
Training loss: 2.7690268246834755
Validation loss: 2.409348375507886

Epoch: 5| Step: 2
Training loss: 2.5980446431917943
Validation loss: 2.416848146868412

Epoch: 5| Step: 3
Training loss: 2.7589965526231586
Validation loss: 2.420828696402799

Epoch: 5| Step: 4
Training loss: 2.9488193671010166
Validation loss: 2.423246422359698

Epoch: 5| Step: 5
Training loss: 2.8428514339501976
Validation loss: 2.4160546477967264

Epoch: 5| Step: 6
Training loss: 2.3702650554538134
Validation loss: 2.420731338041913

Epoch: 5| Step: 7
Training loss: 2.2217205739713024
Validation loss: 2.393397144387073

Epoch: 5| Step: 8
Training loss: 2.4654360390549375
Validation loss: 2.4145335973540014

Epoch: 5| Step: 9
Training loss: 2.615066078474423
Validation loss: 2.396348462539516

Epoch: 5| Step: 10
Training loss: 2.6459026077292838
Validation loss: 2.4216418675086304

Epoch: 79| Step: 0
Training loss: 2.9724377665890866
Validation loss: 2.416781804273763

Epoch: 5| Step: 1
Training loss: 2.370371575018568
Validation loss: 2.418602909975509

Epoch: 5| Step: 2
Training loss: 2.640175685238727
Validation loss: 2.4196061043169763

Epoch: 5| Step: 3
Training loss: 2.689296654143614
Validation loss: 2.4236696557093818

Epoch: 5| Step: 4
Training loss: 2.342506485709186
Validation loss: 2.4286268694464255

Epoch: 5| Step: 5
Training loss: 2.524298175682627
Validation loss: 2.406330426921205

Epoch: 5| Step: 6
Training loss: 2.723576875798179
Validation loss: 2.402821319836471

Epoch: 5| Step: 7
Training loss: 3.3657182289181855
Validation loss: 2.4216647667858284

Epoch: 5| Step: 8
Training loss: 2.55044343122168
Validation loss: 2.4118461870171424

Epoch: 5| Step: 9
Training loss: 2.0918422377054946
Validation loss: 2.422808888595019

Epoch: 5| Step: 10
Training loss: 2.721259438844852
Validation loss: 2.4136587149658717

Epoch: 80| Step: 0
Training loss: 2.352858075609832
Validation loss: 2.4105426229132267

Epoch: 5| Step: 1
Training loss: 2.826998238534989
Validation loss: 2.418588042824758

Epoch: 5| Step: 2
Training loss: 2.6432793272674058
Validation loss: 2.420236446721813

Epoch: 5| Step: 3
Training loss: 2.5065252975748744
Validation loss: 2.4083091087697

Epoch: 5| Step: 4
Training loss: 2.9898669455021976
Validation loss: 2.4092854921104587

Epoch: 5| Step: 5
Training loss: 2.6796673031593565
Validation loss: 2.410996748616438

Epoch: 5| Step: 6
Training loss: 2.6425566520861694
Validation loss: 2.409023506755295

Epoch: 5| Step: 7
Training loss: 2.825342485040686
Validation loss: 2.4164998191745046

Epoch: 5| Step: 8
Training loss: 2.5461669124779527
Validation loss: 2.399261039280271

Epoch: 5| Step: 9
Training loss: 2.2559186655154795
Validation loss: 2.4156985509598443

Epoch: 5| Step: 10
Training loss: 2.753372811672508
Validation loss: 2.4154027838251584

Epoch: 81| Step: 0
Training loss: 2.487325200212334
Validation loss: 2.42047290685533

Epoch: 5| Step: 1
Training loss: 2.7768114655631924
Validation loss: 2.4005561869706957

Epoch: 5| Step: 2
Training loss: 2.3743551282259485
Validation loss: 2.412505756617628

Epoch: 5| Step: 3
Training loss: 2.6389164560673897
Validation loss: 2.399348314870049

Epoch: 5| Step: 4
Training loss: 2.4912896048560214
Validation loss: 2.414998872573641

Epoch: 5| Step: 5
Training loss: 2.7202651088208416
Validation loss: 2.4031294506200394

Epoch: 5| Step: 6
Training loss: 2.9348861752847317
Validation loss: 2.410842983549705

Epoch: 5| Step: 7
Training loss: 2.846119323330756
Validation loss: 2.3973826810871817

Epoch: 5| Step: 8
Training loss: 2.566900707902855
Validation loss: 2.4211061467291044

Epoch: 5| Step: 9
Training loss: 2.80997065084206
Validation loss: 2.4023313065646885

Epoch: 5| Step: 10
Training loss: 2.274784383931296
Validation loss: 2.4176669396866353

Epoch: 82| Step: 0
Training loss: 2.531037309917967
Validation loss: 2.4029854815838085

Epoch: 5| Step: 1
Training loss: 2.702623265619746
Validation loss: 2.4068850225498646

Epoch: 5| Step: 2
Training loss: 2.152049631283868
Validation loss: 2.411520554469752

Epoch: 5| Step: 3
Training loss: 2.965523341600129
Validation loss: 2.4148544709975943

Epoch: 5| Step: 4
Training loss: 2.2722771164103657
Validation loss: 2.4340849207762436

Epoch: 5| Step: 5
Training loss: 2.9067334829169407
Validation loss: 2.42138825340611

Epoch: 5| Step: 6
Training loss: 2.5695566845914044
Validation loss: 2.417363546527933

Epoch: 5| Step: 7
Training loss: 2.8172044191788634
Validation loss: 2.4187883060363586

Epoch: 5| Step: 8
Training loss: 2.9627383751876524
Validation loss: 2.418719034054226

Epoch: 5| Step: 9
Training loss: 2.577705302900445
Validation loss: 2.419119728860633

Epoch: 5| Step: 10
Training loss: 2.4060879937663
Validation loss: 2.410110060215539

Epoch: 83| Step: 0
Training loss: 2.6748397173055336
Validation loss: 2.4168736171548475

Epoch: 5| Step: 1
Training loss: 2.677188252769196
Validation loss: 2.4023443217209732

Epoch: 5| Step: 2
Training loss: 2.3774882884093116
Validation loss: 2.419786681427361

Epoch: 5| Step: 3
Training loss: 3.0303064824575934
Validation loss: 2.409295309170493

Epoch: 5| Step: 4
Training loss: 2.5898523114783543
Validation loss: 2.428940043589024

Epoch: 5| Step: 5
Training loss: 2.7383478567427457
Validation loss: 2.4230999270629354

Epoch: 5| Step: 6
Training loss: 2.2980439202449983
Validation loss: 2.4023624441114975

Epoch: 5| Step: 7
Training loss: 3.177459911270626
Validation loss: 2.423456716712195

Epoch: 5| Step: 8
Training loss: 2.432060040071623
Validation loss: 2.398893907662107

Epoch: 5| Step: 9
Training loss: 2.4660972152692384
Validation loss: 2.42109770697799

Epoch: 5| Step: 10
Training loss: 2.4329596071351394
Validation loss: 2.4356200838778665

Epoch: 84| Step: 0
Training loss: 3.4781645437564945
Validation loss: 2.405744789633564

Epoch: 5| Step: 1
Training loss: 2.7271949887033546
Validation loss: 2.4088378529660006

Epoch: 5| Step: 2
Training loss: 3.0134231355952363
Validation loss: 2.413148893965802

Epoch: 5| Step: 3
Training loss: 2.261798231345769
Validation loss: 2.411241289359718

Epoch: 5| Step: 4
Training loss: 2.6989143520134897
Validation loss: 2.4109450030689756

Epoch: 5| Step: 5
Training loss: 2.6789257868746628
Validation loss: 2.392289870617165

Epoch: 5| Step: 6
Training loss: 2.3655764696996338
Validation loss: 2.4025725331696615

Epoch: 5| Step: 7
Training loss: 2.1404091385088977
Validation loss: 2.4138674459597675

Epoch: 5| Step: 8
Training loss: 2.4485356840057713
Validation loss: 2.4167616156856666

Epoch: 5| Step: 9
Training loss: 2.5168201142913285
Validation loss: 2.4172488622688446

Epoch: 5| Step: 10
Training loss: 2.434553860127923
Validation loss: 2.4254118087322505

Epoch: 85| Step: 0
Training loss: 2.5488889255798983
Validation loss: 2.396129941480916

Epoch: 5| Step: 1
Training loss: 2.4944339779825633
Validation loss: 2.399034891822521

Epoch: 5| Step: 2
Training loss: 2.6337676989771315
Validation loss: 2.4097216944618927

Epoch: 5| Step: 3
Training loss: 2.7052703458611225
Validation loss: 2.4257841171805974

Epoch: 5| Step: 4
Training loss: 3.0366976836121298
Validation loss: 2.4235363160964876

Epoch: 5| Step: 5
Training loss: 2.5172357555762654
Validation loss: 2.4227725395275574

Epoch: 5| Step: 6
Training loss: 2.405433615378051
Validation loss: 2.409819338577237

Epoch: 5| Step: 7
Training loss: 2.9829460837504276
Validation loss: 2.4109667768681198

Epoch: 5| Step: 8
Training loss: 2.378113161877155
Validation loss: 2.3971630998374867

Epoch: 5| Step: 9
Training loss: 3.0147452380595663
Validation loss: 2.4206281407669663

Epoch: 5| Step: 10
Training loss: 2.2508974404817157
Validation loss: 2.399427182961959

Epoch: 86| Step: 0
Training loss: 2.5357201746943225
Validation loss: 2.426147658369939

Epoch: 5| Step: 1
Training loss: 2.7037142954676465
Validation loss: 2.420930060031321

Epoch: 5| Step: 2
Training loss: 2.358053481500929
Validation loss: 2.415929936786931

Epoch: 5| Step: 3
Training loss: 2.8193920884389336
Validation loss: 2.4138680863740123

Epoch: 5| Step: 4
Training loss: 2.536744171475735
Validation loss: 2.427684452999309

Epoch: 5| Step: 5
Training loss: 2.698822478204127
Validation loss: 2.412658879640465

Epoch: 5| Step: 6
Training loss: 2.684480789817815
Validation loss: 2.411666583299552

Epoch: 5| Step: 7
Training loss: 2.3800380876843388
Validation loss: 2.4186381345611

Epoch: 5| Step: 8
Training loss: 3.158338705442451
Validation loss: 2.420048393561259

Epoch: 5| Step: 9
Training loss: 2.489977391764637
Validation loss: 2.426392036173903

Epoch: 5| Step: 10
Training loss: 2.5785498991423346
Validation loss: 2.4164987561624316

Epoch: 87| Step: 0
Training loss: 2.5744916803044418
Validation loss: 2.4207487728820096

Epoch: 5| Step: 1
Training loss: 3.1346235486689813
Validation loss: 2.423895169509916

Epoch: 5| Step: 2
Training loss: 2.701608750767609
Validation loss: 2.3937005014484543

Epoch: 5| Step: 3
Training loss: 2.273391880482208
Validation loss: 2.422416666133442

Epoch: 5| Step: 4
Training loss: 3.072282697723542
Validation loss: 2.4209085632781453

Epoch: 5| Step: 5
Training loss: 2.700603565995295
Validation loss: 2.401048966480473

Epoch: 5| Step: 6
Training loss: 2.4923272646754047
Validation loss: 2.411465080161605

Epoch: 5| Step: 7
Training loss: 2.703225723771448
Validation loss: 2.4102080390729483

Epoch: 5| Step: 8
Training loss: 2.187763743168547
Validation loss: 2.414329504750549

Epoch: 5| Step: 9
Training loss: 2.2584317424020393
Validation loss: 2.4027671522887593

Epoch: 5| Step: 10
Training loss: 2.8012900854576452
Validation loss: 2.4020906085724616

Epoch: 88| Step: 0
Training loss: 2.6860641369749745
Validation loss: 2.4232620834708265

Epoch: 5| Step: 1
Training loss: 2.3753507254784
Validation loss: 2.4223620107339654

Epoch: 5| Step: 2
Training loss: 1.937190246432395
Validation loss: 2.424779317439134

Epoch: 5| Step: 3
Training loss: 2.650251279469521
Validation loss: 2.419016952454331

Epoch: 5| Step: 4
Training loss: 2.8504715178089977
Validation loss: 2.4102714334080506

Epoch: 5| Step: 5
Training loss: 2.9811678125340846
Validation loss: 2.434898368479223

Epoch: 5| Step: 6
Training loss: 2.8326157801938345
Validation loss: 2.4223924711855926

Epoch: 5| Step: 7
Training loss: 2.468289972251129
Validation loss: 2.4197273918147792

Epoch: 5| Step: 8
Training loss: 2.707926196282938
Validation loss: 2.4167977984547546

Epoch: 5| Step: 9
Training loss: 2.657742249436713
Validation loss: 2.4217459272114126

Epoch: 5| Step: 10
Training loss: 2.5372213877794483
Validation loss: 2.416930782714378

Epoch: 89| Step: 0
Training loss: 2.5693277716280347
Validation loss: 2.413059067358764

Epoch: 5| Step: 1
Training loss: 1.9320638133265342
Validation loss: 2.417489823577227

Epoch: 5| Step: 2
Training loss: 3.038183560790898
Validation loss: 2.4007472283332754

Epoch: 5| Step: 3
Training loss: 2.72616285657942
Validation loss: 2.4102027611888173

Epoch: 5| Step: 4
Training loss: 2.055449833886199
Validation loss: 2.407436271807687

Epoch: 5| Step: 5
Training loss: 2.7020487324056393
Validation loss: 2.4209201779022855

Epoch: 5| Step: 6
Training loss: 3.090698895472606
Validation loss: 2.422255713647526

Epoch: 5| Step: 7
Training loss: 3.0855215057825287
Validation loss: 2.399498686081854

Epoch: 5| Step: 8
Training loss: 2.5334357726148977
Validation loss: 2.4179240496339367

Epoch: 5| Step: 9
Training loss: 2.6600912705158004
Validation loss: 2.4154627856173687

Epoch: 5| Step: 10
Training loss: 2.142213440897308
Validation loss: 2.4154611309791174

Epoch: 90| Step: 0
Training loss: 2.6201295628434913
Validation loss: 2.4119586133729003

Epoch: 5| Step: 1
Training loss: 2.1664329794037127
Validation loss: 2.4046507294988584

Epoch: 5| Step: 2
Training loss: 2.6062024411772375
Validation loss: 2.4096600645077615

Epoch: 5| Step: 3
Training loss: 2.8456089525212254
Validation loss: 2.41426049984993

Epoch: 5| Step: 4
Training loss: 2.929125759947895
Validation loss: 2.418132864082043

Epoch: 5| Step: 5
Training loss: 2.9445490568598776
Validation loss: 2.4180638998658055

Epoch: 5| Step: 6
Training loss: 2.260110602921672
Validation loss: 2.408634068556204

Epoch: 5| Step: 7
Training loss: 2.7360700312680994
Validation loss: 2.412098823289467

Epoch: 5| Step: 8
Training loss: 2.674173091818498
Validation loss: 2.4205827444341126

Epoch: 5| Step: 9
Training loss: 2.4232020526291675
Validation loss: 2.401200985874051

Epoch: 5| Step: 10
Training loss: 2.367514911834257
Validation loss: 2.4137456685810537

Epoch: 91| Step: 0
Training loss: 2.5179276442005722
Validation loss: 2.4130136747110993

Epoch: 5| Step: 1
Training loss: 2.758809803572475
Validation loss: 2.408095593971689

Epoch: 5| Step: 2
Training loss: 2.623249923788942
Validation loss: 2.4256940059816614

Epoch: 5| Step: 3
Training loss: 2.899497277982315
Validation loss: 2.4199875997122073

Epoch: 5| Step: 4
Training loss: 2.5318010460367235
Validation loss: 2.4173066059611443

Epoch: 5| Step: 5
Training loss: 2.7500138715914346
Validation loss: 2.415795915823922

Epoch: 5| Step: 6
Training loss: 2.6934530284773426
Validation loss: 2.418487482053193

Epoch: 5| Step: 7
Training loss: 2.7248895535266118
Validation loss: 2.4133691659891565

Epoch: 5| Step: 8
Training loss: 2.2818321634836227
Validation loss: 2.3972392261959303

Epoch: 5| Step: 9
Training loss: 2.545335081783605
Validation loss: 2.4011088075317835

Epoch: 5| Step: 10
Training loss: 2.4286261199755392
Validation loss: 2.412596996902915

Epoch: 92| Step: 0
Training loss: 2.9886109014455626
Validation loss: 2.4307003895333996

Epoch: 5| Step: 1
Training loss: 2.758011159684783
Validation loss: 2.4099338125898484

Epoch: 5| Step: 2
Training loss: 2.6869650019931477
Validation loss: 2.4193343492378636

Epoch: 5| Step: 3
Training loss: 2.0146697390415302
Validation loss: 2.415014578146137

Epoch: 5| Step: 4
Training loss: 2.3902624516054574
Validation loss: 2.415887678096316

Epoch: 5| Step: 5
Training loss: 2.695164065489295
Validation loss: 2.420917721130127

Epoch: 5| Step: 6
Training loss: 2.89362867854901
Validation loss: 2.4017821203611

Epoch: 5| Step: 7
Training loss: 1.9442485672821734
Validation loss: 2.410580658050826

Epoch: 5| Step: 8
Training loss: 2.6692859977973717
Validation loss: 2.4153654338593156

Epoch: 5| Step: 9
Training loss: 2.5284760899770142
Validation loss: 2.3996300810248434

Epoch: 5| Step: 10
Training loss: 3.0844203648037998
Validation loss: 2.420160112631062

Epoch: 93| Step: 0
Training loss: 2.887960659784156
Validation loss: 2.422890539741503

Epoch: 5| Step: 1
Training loss: 2.6263368926092143
Validation loss: 2.4155757759426826

Epoch: 5| Step: 2
Training loss: 2.4449956036549616
Validation loss: 2.4201376238943544

Epoch: 5| Step: 3
Training loss: 2.694327088604534
Validation loss: 2.414898547700951

Epoch: 5| Step: 4
Training loss: 2.534125872501819
Validation loss: 2.4179467900942067

Epoch: 5| Step: 5
Training loss: 2.4810787382043475
Validation loss: 2.4095223970578665

Epoch: 5| Step: 6
Training loss: 2.5696151390311424
Validation loss: 2.4147670933678183

Epoch: 5| Step: 7
Training loss: 2.28884584618912
Validation loss: 2.398346745070432

Epoch: 5| Step: 8
Training loss: 2.794268880359338
Validation loss: 2.420991620169856

Epoch: 5| Step: 9
Training loss: 2.7824520985060923
Validation loss: 2.421585825772451

Epoch: 5| Step: 10
Training loss: 2.6808131219941744
Validation loss: 2.4302979542471927

Epoch: 94| Step: 0
Training loss: 2.710684728793368
Validation loss: 2.399801500462303

Epoch: 5| Step: 1
Training loss: 2.4515213310718793
Validation loss: 2.413848505339584

Epoch: 5| Step: 2
Training loss: 2.6747889997029914
Validation loss: 2.4113007876305277

Epoch: 5| Step: 3
Training loss: 2.5261120868318643
Validation loss: 2.4146672939595684

Epoch: 5| Step: 4
Training loss: 2.7385811852328885
Validation loss: 2.425854992955624

Epoch: 5| Step: 5
Training loss: 2.9917084233195474
Validation loss: 2.4092253151908016

Epoch: 5| Step: 6
Training loss: 2.394507552709515
Validation loss: 2.430868973064395

Epoch: 5| Step: 7
Training loss: 2.423209038301162
Validation loss: 2.409662974276242

Epoch: 5| Step: 8
Training loss: 2.8756386420745708
Validation loss: 2.4160875719954196

Epoch: 5| Step: 9
Training loss: 2.4328527899255907
Validation loss: 2.4010421528352053

Epoch: 5| Step: 10
Training loss: 2.5252660969937843
Validation loss: 2.4210728603408564

Epoch: 95| Step: 0
Training loss: 3.277052165030942
Validation loss: 2.4124096595868325

Epoch: 5| Step: 1
Training loss: 2.0924428019117896
Validation loss: 2.3972404314249447

Epoch: 5| Step: 2
Training loss: 2.633115847173502
Validation loss: 2.399889688964717

Epoch: 5| Step: 3
Training loss: 2.9794712222201585
Validation loss: 2.4071324933840805

Epoch: 5| Step: 4
Training loss: 2.6835399994332767
Validation loss: 2.4143605146355567

Epoch: 5| Step: 5
Training loss: 2.7267634364197786
Validation loss: 2.409332169607398

Epoch: 5| Step: 6
Training loss: 2.590957793244991
Validation loss: 2.4189358642083074

Epoch: 5| Step: 7
Training loss: 2.4861358544262657
Validation loss: 2.4034801629551863

Epoch: 5| Step: 8
Training loss: 2.336411648092703
Validation loss: 2.4084230307982217

Epoch: 5| Step: 9
Training loss: 2.1266924905953006
Validation loss: 2.4229011661342432

Epoch: 5| Step: 10
Training loss: 2.632681370760839
Validation loss: 2.4069266654991206

Epoch: 96| Step: 0
Training loss: 2.0112873096218014
Validation loss: 2.424551385203728

Epoch: 5| Step: 1
Training loss: 2.7008299152557047
Validation loss: 2.404663561256911

Epoch: 5| Step: 2
Training loss: 2.60573026382715
Validation loss: 2.4167370469478215

Epoch: 5| Step: 3
Training loss: 2.342317982933275
Validation loss: 2.4034838097839883

Epoch: 5| Step: 4
Training loss: 3.089074966336046
Validation loss: 2.427014620101959

Epoch: 5| Step: 5
Training loss: 2.463751936495178
Validation loss: 2.4095441188112567

Epoch: 5| Step: 6
Training loss: 2.698080570932312
Validation loss: 2.4148491608040765

Epoch: 5| Step: 7
Training loss: 2.706637883745816
Validation loss: 2.4295687420094123

Epoch: 5| Step: 8
Training loss: 2.7080301750902294
Validation loss: 2.42058305898697

Epoch: 5| Step: 9
Training loss: 3.006793753763856
Validation loss: 2.4000544699517365

Epoch: 5| Step: 10
Training loss: 1.9913285741252154
Validation loss: 2.417594121378024

Epoch: 97| Step: 0
Training loss: 2.8145513894625873
Validation loss: 2.413288326172916

Epoch: 5| Step: 1
Training loss: 2.214453284343849
Validation loss: 2.4222164160835202

Epoch: 5| Step: 2
Training loss: 2.634856293901844
Validation loss: 2.4066301143343947

Epoch: 5| Step: 3
Training loss: 3.452482690236027
Validation loss: 2.4137378812471577

Epoch: 5| Step: 4
Training loss: 2.658046877583271
Validation loss: 2.4206972241471854

Epoch: 5| Step: 5
Training loss: 2.6222539798336504
Validation loss: 2.412529555529743

Epoch: 5| Step: 6
Training loss: 1.508759275469519
Validation loss: 2.4051107866947987

Epoch: 5| Step: 7
Training loss: 2.9728150494501513
Validation loss: 2.423121791600073

Epoch: 5| Step: 8
Training loss: 2.16984298384098
Validation loss: 2.4231326476196613

Epoch: 5| Step: 9
Training loss: 2.424660735633413
Validation loss: 2.411954789100681

Epoch: 5| Step: 10
Training loss: 2.8027886468504137
Validation loss: 2.4266851143289028

Epoch: 98| Step: 0
Training loss: 2.4040385401107125
Validation loss: 2.4231485792508245

Epoch: 5| Step: 1
Training loss: 2.826038750266063
Validation loss: 2.418079340625253

Epoch: 5| Step: 2
Training loss: 2.663769926858565
Validation loss: 2.4176834348692537

Epoch: 5| Step: 3
Training loss: 2.6466887785742967
Validation loss: 2.3868262086830536

Epoch: 5| Step: 4
Training loss: 2.6416718704541413
Validation loss: 2.4134555171307794

Epoch: 5| Step: 5
Training loss: 2.5255039127722085
Validation loss: 2.4226752624570977

Epoch: 5| Step: 6
Training loss: 2.145855159710244
Validation loss: 2.4120254935780467

Epoch: 5| Step: 7
Training loss: 2.576202785720071
Validation loss: 2.4194861140236283

Epoch: 5| Step: 8
Training loss: 2.971402077897354
Validation loss: 2.4171698677198417

Epoch: 5| Step: 9
Training loss: 2.7501174728271818
Validation loss: 2.41457397923598

Epoch: 5| Step: 10
Training loss: 2.4902588846833056
Validation loss: 2.396572959411249

Epoch: 99| Step: 0
Training loss: 2.634932844258085
Validation loss: 2.421576945700207

Epoch: 5| Step: 1
Training loss: 2.4767722633649574
Validation loss: 2.424666610092428

Epoch: 5| Step: 2
Training loss: 2.731136649636341
Validation loss: 2.4241399806091133

Epoch: 5| Step: 3
Training loss: 2.0872873803320093
Validation loss: 2.4042036530715043

Epoch: 5| Step: 4
Training loss: 2.3804646916694465
Validation loss: 2.4210728952841007

Epoch: 5| Step: 5
Training loss: 2.9147208853259805
Validation loss: 2.4111695805205806

Epoch: 5| Step: 6
Training loss: 2.478675109686108
Validation loss: 2.418661631465719

Epoch: 5| Step: 7
Training loss: 2.4897887545527557
Validation loss: 2.420588966642137

Epoch: 5| Step: 8
Training loss: 2.7539863304236643
Validation loss: 2.410188045382728

Epoch: 5| Step: 9
Training loss: 2.696367582499392
Validation loss: 2.4101754153521697

Epoch: 5| Step: 10
Training loss: 2.949894182279342
Validation loss: 2.4266670549945233

Epoch: 100| Step: 0
Training loss: 3.420397156303365
Validation loss: 2.4243106298160253

Epoch: 5| Step: 1
Training loss: 2.8308931576352876
Validation loss: 2.4169837524757436

Epoch: 5| Step: 2
Training loss: 2.5532864803202044
Validation loss: 2.4084781547264393

Epoch: 5| Step: 3
Training loss: 2.5642418872444206
Validation loss: 2.4191316805913883

Epoch: 5| Step: 4
Training loss: 2.422716056235614
Validation loss: 2.421913160432979

Epoch: 5| Step: 5
Training loss: 2.7235194497573882
Validation loss: 2.4199327093555874

Epoch: 5| Step: 6
Training loss: 2.500410427735596
Validation loss: 2.4283054212716744

Epoch: 5| Step: 7
Training loss: 2.290166074569459
Validation loss: 2.413766637010357

Epoch: 5| Step: 8
Training loss: 2.562511909271106
Validation loss: 2.4209135001355873

Epoch: 5| Step: 9
Training loss: 2.367172392239847
Validation loss: 2.414329566337484

Epoch: 5| Step: 10
Training loss: 1.986958901504893
Validation loss: 2.39625276707886

Epoch: 101| Step: 0
Training loss: 2.9592633106460533
Validation loss: 2.428369670182239

Epoch: 5| Step: 1
Training loss: 2.4779128956791436
Validation loss: 2.410574287706965

Epoch: 5| Step: 2
Training loss: 2.4771988589653295
Validation loss: 2.413075858576111

Epoch: 5| Step: 3
Training loss: 2.340801673404359
Validation loss: 2.4202329321206606

Epoch: 5| Step: 4
Training loss: 2.7805974816375194
Validation loss: 2.4030162436601166

Epoch: 5| Step: 5
Training loss: 2.4151713469633727
Validation loss: 2.4165099570186417

Epoch: 5| Step: 6
Training loss: 2.5428119851353634
Validation loss: 2.4157613714213597

Epoch: 5| Step: 7
Training loss: 2.6484850313765755
Validation loss: 2.412289403260494

Epoch: 5| Step: 8
Training loss: 2.58125161824395
Validation loss: 2.4282777725392535

Epoch: 5| Step: 9
Training loss: 2.7866626319977725
Validation loss: 2.426402615535086

Epoch: 5| Step: 10
Training loss: 2.544029471676535
Validation loss: 2.406934930735224

Epoch: 102| Step: 0
Training loss: 3.0444993367625903
Validation loss: 2.3968004087718304

Epoch: 5| Step: 1
Training loss: 2.651213324984237
Validation loss: 2.404369361385669

Epoch: 5| Step: 2
Training loss: 2.599434563701182
Validation loss: 2.408003349518612

Epoch: 5| Step: 3
Training loss: 2.6898628316175306
Validation loss: 2.4151573959754935

Epoch: 5| Step: 4
Training loss: 2.919514237850154
Validation loss: 2.410602157571201

Epoch: 5| Step: 5
Training loss: 2.4465920510031873
Validation loss: 2.417230465702246

Epoch: 5| Step: 6
Training loss: 2.208036858672561
Validation loss: 2.411471761767408

Epoch: 5| Step: 7
Training loss: 2.9815804544277498
Validation loss: 2.417594727932386

Epoch: 5| Step: 8
Training loss: 2.1697717815580075
Validation loss: 2.4189575978735585

Epoch: 5| Step: 9
Training loss: 2.110480802816073
Validation loss: 2.400245320009089

Epoch: 5| Step: 10
Training loss: 2.471259374914298
Validation loss: 2.411498207349635

Epoch: 103| Step: 0
Training loss: 2.2675419557300573
Validation loss: 2.414633545618934

Epoch: 5| Step: 1
Training loss: 2.6117962779212474
Validation loss: 2.404153908919118

Epoch: 5| Step: 2
Training loss: 2.3704421830833726
Validation loss: 2.4267822280242863

Epoch: 5| Step: 3
Training loss: 2.6617595305592405
Validation loss: 2.4235072504803967

Epoch: 5| Step: 4
Training loss: 2.7509568023784463
Validation loss: 2.430785498536337

Epoch: 5| Step: 5
Training loss: 2.3017847434253964
Validation loss: 2.4207289869817665

Epoch: 5| Step: 6
Training loss: 2.4306043262735417
Validation loss: 2.407881540673328

Epoch: 5| Step: 7
Training loss: 2.680866927233962
Validation loss: 2.4100208234783045

Epoch: 5| Step: 8
Training loss: 3.0689437960403243
Validation loss: 2.414586906370651

Epoch: 5| Step: 9
Training loss: 2.6397077784499423
Validation loss: 2.4200958226778493

Epoch: 5| Step: 10
Training loss: 2.461756687967593
Validation loss: 2.398078479265967

Epoch: 104| Step: 0
Training loss: 2.1835127322430883
Validation loss: 2.4051251130657625

Epoch: 5| Step: 1
Training loss: 3.0112193444363395
Validation loss: 2.4083344889335474

Epoch: 5| Step: 2
Training loss: 2.6872113982201635
Validation loss: 2.4146373008843622

Epoch: 5| Step: 3
Training loss: 2.4692335983029796
Validation loss: 2.407797429980818

Epoch: 5| Step: 4
Training loss: 2.61911313400235
Validation loss: 2.4223209257702663

Epoch: 5| Step: 5
Training loss: 2.5822358620232855
Validation loss: 2.4210626314785784

Epoch: 5| Step: 6
Training loss: 2.3311350776225024
Validation loss: 2.415148464668479

Epoch: 5| Step: 7
Training loss: 2.8535558970571078
Validation loss: 2.4198075567208654

Epoch: 5| Step: 8
Training loss: 2.5430770358749037
Validation loss: 2.4046654386793787

Epoch: 5| Step: 9
Training loss: 2.1413420429923544
Validation loss: 2.4187643614960517

Epoch: 5| Step: 10
Training loss: 2.944909996639229
Validation loss: 2.416513173621665

Epoch: 105| Step: 0
Training loss: 2.0454373734649245
Validation loss: 2.41726130368163

Epoch: 5| Step: 1
Training loss: 2.837923221702848
Validation loss: 2.4209108739235297

Epoch: 5| Step: 2
Training loss: 2.319515104099508
Validation loss: 2.4184612920428625

Epoch: 5| Step: 3
Training loss: 2.3952182698984497
Validation loss: 2.3998962564503534

Epoch: 5| Step: 4
Training loss: 2.824608655846913
Validation loss: 2.4145229617410484

Epoch: 5| Step: 5
Training loss: 2.343410111259752
Validation loss: 2.4341921673267373

Epoch: 5| Step: 6
Training loss: 2.8967489171907195
Validation loss: 2.425299361213307

Epoch: 5| Step: 7
Training loss: 2.6282253432197233
Validation loss: 2.4092514640788685

Epoch: 5| Step: 8
Training loss: 2.793962891252372
Validation loss: 2.4274266659560406

Epoch: 5| Step: 9
Training loss: 2.930956105544222
Validation loss: 2.4335277290786164

Epoch: 5| Step: 10
Training loss: 2.291925300106509
Validation loss: 2.4004100263870463

Epoch: 106| Step: 0
Training loss: 2.9271610199923903
Validation loss: 2.4126298567146574

Epoch: 5| Step: 1
Training loss: 2.6324102167974335
Validation loss: 2.4250361648872003

Epoch: 5| Step: 2
Training loss: 3.226997253832906
Validation loss: 2.4150669742544655

Epoch: 5| Step: 3
Training loss: 2.093967711104086
Validation loss: 2.4221831920517727

Epoch: 5| Step: 4
Training loss: 2.4952511506968014
Validation loss: 2.397218121222301

Epoch: 5| Step: 5
Training loss: 1.9707332491580787
Validation loss: 2.4168987169833724

Epoch: 5| Step: 6
Training loss: 2.5919070763002465
Validation loss: 2.41466840343078

Epoch: 5| Step: 7
Training loss: 2.638669164332897
Validation loss: 2.425570821609087

Epoch: 5| Step: 8
Training loss: 2.0296295745078208
Validation loss: 2.431663992045875

Epoch: 5| Step: 9
Training loss: 2.9553972816951983
Validation loss: 2.413369745986464

Epoch: 5| Step: 10
Training loss: 2.5494883416659846
Validation loss: 2.399819783867129

Epoch: 107| Step: 0
Training loss: 2.2124408692470294
Validation loss: 2.411908426492173

Epoch: 5| Step: 1
Training loss: 2.1529203497597553
Validation loss: 2.4143668834840186

Epoch: 5| Step: 2
Training loss: 2.5505748624391034
Validation loss: 2.3969136552872543

Epoch: 5| Step: 3
Training loss: 2.693107963927754
Validation loss: 2.4080512341206246

Epoch: 5| Step: 4
Training loss: 2.868466790873947
Validation loss: 2.4180448712523877

Epoch: 5| Step: 5
Training loss: 2.8714388477762425
Validation loss: 2.3990753620047434

Epoch: 5| Step: 6
Training loss: 2.2814477286151704
Validation loss: 2.412666390468365

Epoch: 5| Step: 7
Training loss: 1.934818997061896
Validation loss: 2.429876649287273

Epoch: 5| Step: 8
Training loss: 2.331140191404194
Validation loss: 2.4203435347440094

Epoch: 5| Step: 9
Training loss: 2.9436169507195524
Validation loss: 2.4128708256185853

Epoch: 5| Step: 10
Training loss: 3.192890919146757
Validation loss: 2.4100851545512807

Epoch: 108| Step: 0
Training loss: 3.0802538331203544
Validation loss: 2.408590394499907

Epoch: 5| Step: 1
Training loss: 2.5318871155474616
Validation loss: 2.4107236151995712

Epoch: 5| Step: 2
Training loss: 2.499109777261193
Validation loss: 2.415306978782888

Epoch: 5| Step: 3
Training loss: 2.6640011061588775
Validation loss: 2.417544190403901

Epoch: 5| Step: 4
Training loss: 2.4345344696895226
Validation loss: 2.4053976357563616

Epoch: 5| Step: 5
Training loss: 2.4586891197033047
Validation loss: 2.40813937387786

Epoch: 5| Step: 6
Training loss: 2.9242863624088042
Validation loss: 2.4074924011948804

Epoch: 5| Step: 7
Training loss: 2.369931283268473
Validation loss: 2.4230073386230377

Epoch: 5| Step: 8
Training loss: 1.8412460522890988
Validation loss: 2.4061557680474444

Epoch: 5| Step: 9
Training loss: 2.9602238341061735
Validation loss: 2.431562929328461

Epoch: 5| Step: 10
Training loss: 2.45736134166076
Validation loss: 2.4230982755237847

Epoch: 109| Step: 0
Training loss: 2.847725238147533
Validation loss: 2.4309161762984663

Epoch: 5| Step: 1
Training loss: 2.5673111201477465
Validation loss: 2.4160316677580362

Epoch: 5| Step: 2
Training loss: 2.731166068387115
Validation loss: 2.4091332821273403

Epoch: 5| Step: 3
Training loss: 2.4369263585312333
Validation loss: 2.429787493841711

Epoch: 5| Step: 4
Training loss: 2.498904560417463
Validation loss: 2.418888808728512

Epoch: 5| Step: 5
Training loss: 2.9091514952267743
Validation loss: 2.3928226345841526

Epoch: 5| Step: 6
Training loss: 2.5488406593920723
Validation loss: 2.4138329706064985

Epoch: 5| Step: 7
Training loss: 2.2617301347673306
Validation loss: 2.4163126560675607

Epoch: 5| Step: 8
Training loss: 2.3140007510501364
Validation loss: 2.4211364466809098

Epoch: 5| Step: 9
Training loss: 2.9619924633643726
Validation loss: 2.4054208442140124

Epoch: 5| Step: 10
Training loss: 1.879393960383292
Validation loss: 2.4084510351930035

Epoch: 110| Step: 0
Training loss: 2.540867747666693
Validation loss: 2.4132227350477446

Epoch: 5| Step: 1
Training loss: 2.818924157964473
Validation loss: 2.417368042029888

Epoch: 5| Step: 2
Training loss: 2.390725526379067
Validation loss: 2.429770382357545

Epoch: 5| Step: 3
Training loss: 2.682315971980419
Validation loss: 2.401033393244661

Epoch: 5| Step: 4
Training loss: 2.406380984221564
Validation loss: 2.4086675247126665

Epoch: 5| Step: 5
Training loss: 2.6331647416562567
Validation loss: 2.4169294658538627

Epoch: 5| Step: 6
Training loss: 2.607929948889857
Validation loss: 2.420300670445441

Epoch: 5| Step: 7
Training loss: 3.4232719740031765
Validation loss: 2.4156969781987656

Epoch: 5| Step: 8
Training loss: 2.3916763287746723
Validation loss: 2.411513244716703

Epoch: 5| Step: 9
Training loss: 2.289133324682909
Validation loss: 2.426550336127601

Epoch: 5| Step: 10
Training loss: 1.7892806407420354
Validation loss: 2.426819750884945

Epoch: 111| Step: 0
Training loss: 2.6906043465028757
Validation loss: 2.4078052791161833

Epoch: 5| Step: 1
Training loss: 2.7290110264629113
Validation loss: 2.4275533013492545

Epoch: 5| Step: 2
Training loss: 1.9701339459266667
Validation loss: 2.391012207733027

Epoch: 5| Step: 3
Training loss: 2.9179154765259074
Validation loss: 2.394703404299594

Epoch: 5| Step: 4
Training loss: 2.240162323622004
Validation loss: 2.395928417813961

Epoch: 5| Step: 5
Training loss: 2.2322870916360342
Validation loss: 2.42171974703349

Epoch: 5| Step: 6
Training loss: 2.553778903851761
Validation loss: 2.407522618517159

Epoch: 5| Step: 7
Training loss: 3.2868383865943036
Validation loss: 2.4062877364942494

Epoch: 5| Step: 8
Training loss: 2.6262041690536804
Validation loss: 2.4195887343511124

Epoch: 5| Step: 9
Training loss: 2.4933657357291477
Validation loss: 2.438202800037337

Epoch: 5| Step: 10
Training loss: 2.0964335993216543
Validation loss: 2.418809301233343

Epoch: 112| Step: 0
Training loss: 2.1403864149802785
Validation loss: 2.4089541976810103

Epoch: 5| Step: 1
Training loss: 2.401262042895594
Validation loss: 2.4099658938691255

Epoch: 5| Step: 2
Training loss: 3.090227684348401
Validation loss: 2.4213132219296334

Epoch: 5| Step: 3
Training loss: 2.655756646509336
Validation loss: 2.4244209893130235

Epoch: 5| Step: 4
Training loss: 2.78003726193272
Validation loss: 2.406784263592346

Epoch: 5| Step: 5
Training loss: 2.540124195847197
Validation loss: 2.4246086885313676

Epoch: 5| Step: 6
Training loss: 2.530874907405744
Validation loss: 2.410251520016727

Epoch: 5| Step: 7
Training loss: 2.146547686239306
Validation loss: 2.408105183802309

Epoch: 5| Step: 8
Training loss: 2.5586136911794477
Validation loss: 2.404109522190736

Epoch: 5| Step: 9
Training loss: 2.07824557535395
Validation loss: 2.4190654483118146

Epoch: 5| Step: 10
Training loss: 3.1813060942914895
Validation loss: 2.4229826522892153

Epoch: 113| Step: 0
Training loss: 2.1737971959137314
Validation loss: 2.425420852338085

Epoch: 5| Step: 1
Training loss: 3.417190341049988
Validation loss: 2.4053938916450233

Epoch: 5| Step: 2
Training loss: 3.208728188001074
Validation loss: 2.421775397172159

Epoch: 5| Step: 3
Training loss: 2.0822454918427753
Validation loss: 2.430491814155974

Epoch: 5| Step: 4
Training loss: 2.2627170184678556
Validation loss: 2.4120035029454088

Epoch: 5| Step: 5
Training loss: 2.284728963958574
Validation loss: 2.41693707213213

Epoch: 5| Step: 6
Training loss: 2.14597137402216
Validation loss: 2.419585360787102

Epoch: 5| Step: 7
Training loss: 2.5511833212856643
Validation loss: 2.4156208593712476

Epoch: 5| Step: 8
Training loss: 2.5512923799066574
Validation loss: 2.421308617286325

Epoch: 5| Step: 9
Training loss: 2.305541937250365
Validation loss: 2.413049270922943

Epoch: 5| Step: 10
Training loss: 2.825162653333742
Validation loss: 2.4189684641030538

Epoch: 114| Step: 0
Training loss: 2.3974034568593034
Validation loss: 2.4117887707268215

Epoch: 5| Step: 1
Training loss: 2.157447703447092
Validation loss: 2.427563048758527

Epoch: 5| Step: 2
Training loss: 2.256493100413368
Validation loss: 2.418190277102043

Epoch: 5| Step: 3
Training loss: 2.950180604223101
Validation loss: 2.417835626143618

Epoch: 5| Step: 4
Training loss: 2.387700804409584
Validation loss: 2.414975363385915

Epoch: 5| Step: 5
Training loss: 2.452732516435532
Validation loss: 2.405892594760834

Epoch: 5| Step: 6
Training loss: 2.830636442619943
Validation loss: 2.4093611120210485

Epoch: 5| Step: 7
Training loss: 2.164987965257422
Validation loss: 2.4124518447737917

Epoch: 5| Step: 8
Training loss: 2.7043445460079507
Validation loss: 2.429234692293977

Epoch: 5| Step: 9
Training loss: 3.1193029735262034
Validation loss: 2.4051453497654083

Epoch: 5| Step: 10
Training loss: 2.5251476055852016
Validation loss: 2.4192921033881225

Epoch: 115| Step: 0
Training loss: 3.0729346495711014
Validation loss: 2.4239840165727813

Epoch: 5| Step: 1
Training loss: 2.524074603929363
Validation loss: 2.4071261980515

Epoch: 5| Step: 2
Training loss: 2.5399247334059307
Validation loss: 2.416928179222638

Epoch: 5| Step: 3
Training loss: 2.341082771874862
Validation loss: 2.4132088731855874

Epoch: 5| Step: 4
Training loss: 2.8647433889352536
Validation loss: 2.3957240917523306

Epoch: 5| Step: 5
Training loss: 2.33634144023908
Validation loss: 2.4098659940320113

Epoch: 5| Step: 6
Training loss: 2.746360711569137
Validation loss: 2.4241970842723046

Epoch: 5| Step: 7
Training loss: 2.6942956747909133
Validation loss: 2.4232525038995547

Epoch: 5| Step: 8
Training loss: 1.9788489705804508
Validation loss: 2.4262319179907452

Epoch: 5| Step: 9
Training loss: 2.339762742004687
Validation loss: 2.4201993906205175

Epoch: 5| Step: 10
Training loss: 2.4934766538332918
Validation loss: 2.4232635264863425

Epoch: 116| Step: 0
Training loss: 2.328565619843415
Validation loss: 2.398236578583286

Epoch: 5| Step: 1
Training loss: 2.479443339662588
Validation loss: 2.415999065374949

Epoch: 5| Step: 2
Training loss: 2.416250675396694
Validation loss: 2.414041598389778

Epoch: 5| Step: 3
Training loss: 2.6474653502187957
Validation loss: 2.418641543894714

Epoch: 5| Step: 4
Training loss: 2.421002729292241
Validation loss: 2.4267713957256807

Epoch: 5| Step: 5
Training loss: 2.0247997279091257
Validation loss: 2.423812102114568

Epoch: 5| Step: 6
Training loss: 2.2608210704380434
Validation loss: 2.422855435175228

Epoch: 5| Step: 7
Training loss: 2.6412472866349517
Validation loss: 2.412059145553861

Epoch: 5| Step: 8
Training loss: 2.7938877967799804
Validation loss: 2.4131884942923607

Epoch: 5| Step: 9
Training loss: 2.835707137574819
Validation loss: 2.4068018937319517

Epoch: 5| Step: 10
Training loss: 2.9497289759389997
Validation loss: 2.4236159255597802

Epoch: 117| Step: 0
Training loss: 2.3519682169862284
Validation loss: 2.436913298998263

Epoch: 5| Step: 1
Training loss: 2.5043401238088636
Validation loss: 2.4146061586535965

Epoch: 5| Step: 2
Training loss: 2.5403228917978686
Validation loss: 2.40760676010649

Epoch: 5| Step: 3
Training loss: 2.3859274593559197
Validation loss: 2.4133646545401377

Epoch: 5| Step: 4
Training loss: 2.5941467900857043
Validation loss: 2.4063797569367806

Epoch: 5| Step: 5
Training loss: 2.536743795531484
Validation loss: 2.4115245250723967

Epoch: 5| Step: 6
Training loss: 2.441566108047669
Validation loss: 2.41129165385571

Epoch: 5| Step: 7
Training loss: 2.192586271704812
Validation loss: 2.4164496953124934

Epoch: 5| Step: 8
Training loss: 2.6119912560215823
Validation loss: 2.419894535172092

Epoch: 5| Step: 9
Training loss: 2.914996041087477
Validation loss: 2.40185575907147

Epoch: 5| Step: 10
Training loss: 2.884802154950243
Validation loss: 2.4226681683689013

Epoch: 118| Step: 0
Training loss: 2.5016380665580393
Validation loss: 2.3971926324546318

Epoch: 5| Step: 1
Training loss: 2.821810506799739
Validation loss: 2.4207318082536684

Epoch: 5| Step: 2
Training loss: 2.877156816925718
Validation loss: 2.4080829710647085

Epoch: 5| Step: 3
Training loss: 2.4957651510037646
Validation loss: 2.422553747930728

Epoch: 5| Step: 4
Training loss: 2.575463973530804
Validation loss: 2.4148577970284903

Epoch: 5| Step: 5
Training loss: 2.3360411962247123
Validation loss: 2.423421769505545

Epoch: 5| Step: 6
Training loss: 2.3348020517878414
Validation loss: 2.416662630608922

Epoch: 5| Step: 7
Training loss: 2.4668789304011414
Validation loss: 2.414875782782333

Epoch: 5| Step: 8
Training loss: 2.73469750818499
Validation loss: 2.427436831037358

Epoch: 5| Step: 9
Training loss: 2.4245370324615263
Validation loss: 2.4021786884914693

Epoch: 5| Step: 10
Training loss: 2.2313900729965237
Validation loss: 2.418200854179838

Epoch: 119| Step: 0
Training loss: 2.119604778877453
Validation loss: 2.4292079174067185

Epoch: 5| Step: 1
Training loss: 2.3602716624160136
Validation loss: 2.399023717307031

Epoch: 5| Step: 2
Training loss: 2.6776799725794302
Validation loss: 2.410233783749566

Epoch: 5| Step: 3
Training loss: 1.945220699978477
Validation loss: 2.4100585182148553

Epoch: 5| Step: 4
Training loss: 2.6448541666653846
Validation loss: 2.3931938994598485

Epoch: 5| Step: 5
Training loss: 2.6291204538127837
Validation loss: 2.4111842626922697

Epoch: 5| Step: 6
Training loss: 2.7153224166318495
Validation loss: 2.417872579574068

Epoch: 5| Step: 7
Training loss: 2.835836277355901
Validation loss: 2.410348341248012

Epoch: 5| Step: 8
Training loss: 2.3930187333454143
Validation loss: 2.39503780941428

Epoch: 5| Step: 9
Training loss: 2.5630309322483535
Validation loss: 2.410939418430506

Epoch: 5| Step: 10
Training loss: 3.007202403628116
Validation loss: 2.418419954774023

Epoch: 120| Step: 0
Training loss: 2.13949153991724
Validation loss: 2.423176384369907

Epoch: 5| Step: 1
Training loss: 2.0659400688112717
Validation loss: 2.3974428831197208

Epoch: 5| Step: 2
Training loss: 2.1895413274634508
Validation loss: 2.405780447575159

Epoch: 5| Step: 3
Training loss: 2.747315483665968
Validation loss: 2.428588767531396

Epoch: 5| Step: 4
Training loss: 2.1390737217008997
Validation loss: 2.41715224214135

Epoch: 5| Step: 5
Training loss: 2.79453379924467
Validation loss: 2.4108969675245615

Epoch: 5| Step: 6
Training loss: 2.707836036998064
Validation loss: 2.4171018390760355

Epoch: 5| Step: 7
Training loss: 2.9395780315031437
Validation loss: 2.4070209365013864

Epoch: 5| Step: 8
Training loss: 2.5831621379937713
Validation loss: 2.4079540894950067

Epoch: 5| Step: 9
Training loss: 2.651553321332449
Validation loss: 2.4246122845488927

Epoch: 5| Step: 10
Training loss: 2.6042800776899897
Validation loss: 2.3958234630736297

Epoch: 121| Step: 0
Training loss: 2.2993980615179486
Validation loss: 2.41527333384766

Epoch: 5| Step: 1
Training loss: 2.225412814816635
Validation loss: 2.418423710520291

Epoch: 5| Step: 2
Training loss: 2.9675619860299762
Validation loss: 2.438514657101464

Epoch: 5| Step: 3
Training loss: 2.823101746144778
Validation loss: 2.421850115819904

Epoch: 5| Step: 4
Training loss: 2.424135002732853
Validation loss: 2.413113412898052

Epoch: 5| Step: 5
Training loss: 2.2322125407649778
Validation loss: 2.4209611399748985

Epoch: 5| Step: 6
Training loss: 2.226201292487189
Validation loss: 2.421865963265678

Epoch: 5| Step: 7
Training loss: 2.2781925353621744
Validation loss: 2.4092849047455296

Epoch: 5| Step: 8
Training loss: 2.99646964568714
Validation loss: 2.4182480990266364

Epoch: 5| Step: 9
Training loss: 2.5895918641649343
Validation loss: 2.4278813176587666

Epoch: 5| Step: 10
Training loss: 2.690106480841489
Validation loss: 2.424689836058374

Epoch: 122| Step: 0
Training loss: 2.6479633098088793
Validation loss: 2.4124898221817506

Epoch: 5| Step: 1
Training loss: 2.203089504091268
Validation loss: 2.4216060101359917

Epoch: 5| Step: 2
Training loss: 2.256770966212391
Validation loss: 2.4124575061425313

Epoch: 5| Step: 3
Training loss: 2.994591924668215
Validation loss: 2.410285979588638

Epoch: 5| Step: 4
Training loss: 2.8629365013507724
Validation loss: 2.4250403861059584

Epoch: 5| Step: 5
Training loss: 2.1328417877310306
Validation loss: 2.4064840568640125

Epoch: 5| Step: 6
Training loss: 2.6918755331187256
Validation loss: 2.3916176339625315

Epoch: 5| Step: 7
Training loss: 2.154445943923139
Validation loss: 2.4340960333345483

Epoch: 5| Step: 8
Training loss: 2.563585935166766
Validation loss: 2.4106776457862193

Epoch: 5| Step: 9
Training loss: 2.9356800691256733
Validation loss: 2.4145347992591977

Epoch: 5| Step: 10
Training loss: 2.0528391367623864
Validation loss: 2.4143759875740045

Epoch: 123| Step: 0
Training loss: 2.663910713234574
Validation loss: 2.4128131723332804

Epoch: 5| Step: 1
Training loss: 1.7581721637256702
Validation loss: 2.4161704831970936

Epoch: 5| Step: 2
Training loss: 2.705029737129273
Validation loss: 2.4160027145292937

Epoch: 5| Step: 3
Training loss: 2.9303441646883304
Validation loss: 2.4326065782571282

Epoch: 5| Step: 4
Training loss: 2.7704806186980524
Validation loss: 2.413304938391953

Epoch: 5| Step: 5
Training loss: 2.131164920484673
Validation loss: 2.4196324239111253

Epoch: 5| Step: 6
Training loss: 2.446790449647473
Validation loss: 2.411063384365705

Epoch: 5| Step: 7
Training loss: 2.4188546328128475
Validation loss: 2.3995854743992826

Epoch: 5| Step: 8
Training loss: 2.6098907326520506
Validation loss: 2.4062970149786596

Epoch: 5| Step: 9
Training loss: 2.4898924589105644
Validation loss: 2.4102988419724993

Epoch: 5| Step: 10
Training loss: 2.701982819141851
Validation loss: 2.4061285754579673

Epoch: 124| Step: 0
Training loss: 1.93722039943228
Validation loss: 2.414182198109595

Epoch: 5| Step: 1
Training loss: 2.597933509198993
Validation loss: 2.416997114325447

Epoch: 5| Step: 2
Training loss: 2.202475918866596
Validation loss: 2.4186987312651116

Epoch: 5| Step: 3
Training loss: 2.2914634845711697
Validation loss: 2.4132729716132366

Epoch: 5| Step: 4
Training loss: 2.085305793347829
Validation loss: 2.4194398321583703

Epoch: 5| Step: 5
Training loss: 2.540018412305524
Validation loss: 2.412122066112855

Epoch: 5| Step: 6
Training loss: 2.274778933840706
Validation loss: 2.4117670442102104

Epoch: 5| Step: 7
Training loss: 3.03107821577512
Validation loss: 2.4114160016846453

Epoch: 5| Step: 8
Training loss: 2.8484257415846854
Validation loss: 2.4264912878497498

Epoch: 5| Step: 9
Training loss: 2.5423009320762637
Validation loss: 2.4132084971183247

Epoch: 5| Step: 10
Training loss: 3.15693430516907
Validation loss: 2.409285843252468

Epoch: 125| Step: 0
Training loss: 2.5523856989481564
Validation loss: 2.4167842790402188

Epoch: 5| Step: 1
Training loss: 2.2840750981425892
Validation loss: 2.408412025447106

Epoch: 5| Step: 2
Training loss: 2.751057074861277
Validation loss: 2.405028179093071

Epoch: 5| Step: 3
Training loss: 2.6116326895594986
Validation loss: 2.4287393212375648

Epoch: 5| Step: 4
Training loss: 3.212371431739191
Validation loss: 2.4194124211872854

Epoch: 5| Step: 5
Training loss: 2.145128510900358
Validation loss: 2.4107451022790882

Epoch: 5| Step: 6
Training loss: 2.513704882140517
Validation loss: 2.413486233389681

Epoch: 5| Step: 7
Training loss: 2.140599828418952
Validation loss: 2.4116540481800013

Epoch: 5| Step: 8
Training loss: 2.3652916294164448
Validation loss: 2.4105902145985443

Epoch: 5| Step: 9
Training loss: 2.6316859158308614
Validation loss: 2.4037128124029223

Epoch: 5| Step: 10
Training loss: 2.2247474098417683
Validation loss: 2.410441695653169

Epoch: 126| Step: 0
Training loss: 2.447216718448373
Validation loss: 2.4140931501286964

Epoch: 5| Step: 1
Training loss: 2.811138586513993
Validation loss: 2.4141788775193813

Epoch: 5| Step: 2
Training loss: 2.1415217393853396
Validation loss: 2.3900837037119174

Epoch: 5| Step: 3
Training loss: 2.1439103580922305
Validation loss: 2.4087030973458985

Epoch: 5| Step: 4
Training loss: 2.9867070059379524
Validation loss: 2.4441281261139354

Epoch: 5| Step: 5
Training loss: 2.5776427771671795
Validation loss: 2.422325811594821

Epoch: 5| Step: 6
Training loss: 2.6705237647111404
Validation loss: 2.4053624634746984

Epoch: 5| Step: 7
Training loss: 2.586206243558779
Validation loss: 2.4323737186470487

Epoch: 5| Step: 8
Training loss: 2.487882046138942
Validation loss: 2.4250145956449516

Epoch: 5| Step: 9
Training loss: 2.64071646086176
Validation loss: 2.401167290624625

Epoch: 5| Step: 10
Training loss: 1.885900979687955
Validation loss: 2.4416647565594043

Epoch: 127| Step: 0
Training loss: 2.5571637299668377
Validation loss: 2.4123060675247743

Epoch: 5| Step: 1
Training loss: 2.066243329322972
Validation loss: 2.40562589936882

Epoch: 5| Step: 2
Training loss: 2.7945611002465975
Validation loss: 2.4171722354991987

Epoch: 5| Step: 3
Training loss: 2.2927514254310077
Validation loss: 2.414510768473946

Epoch: 5| Step: 4
Training loss: 2.87761751519929
Validation loss: 2.397220517798458

Epoch: 5| Step: 5
Training loss: 2.11829957928641
Validation loss: 2.423628673832043

Epoch: 5| Step: 6
Training loss: 2.4815766511078166
Validation loss: 2.4314183506161253

Epoch: 5| Step: 7
Training loss: 2.3870879292012437
Validation loss: 2.418305857022934

Epoch: 5| Step: 8
Training loss: 2.4102740637673308
Validation loss: 2.4123364551607436

Epoch: 5| Step: 9
Training loss: 2.0067301998451867
Validation loss: 2.423147609612754

Epoch: 5| Step: 10
Training loss: 3.3840410147000823
Validation loss: 2.4382618128286646

Epoch: 128| Step: 0
Training loss: 2.3576727783384226
Validation loss: 2.4170323082196052

Epoch: 5| Step: 1
Training loss: 2.2518951064458066
Validation loss: 2.403393808613551

Epoch: 5| Step: 2
Training loss: 2.291958692035285
Validation loss: 2.4119078323256304

Epoch: 5| Step: 3
Training loss: 2.2983352275321445
Validation loss: 2.4088264764836644

Epoch: 5| Step: 4
Training loss: 2.4743769776677733
Validation loss: 2.423469055380365

Epoch: 5| Step: 5
Training loss: 2.4366302894907084
Validation loss: 2.4080593762606903

Epoch: 5| Step: 6
Training loss: 2.727407155191841
Validation loss: 2.394459202400557

Epoch: 5| Step: 7
Training loss: 2.181963426278205
Validation loss: 2.4015064337331107

Epoch: 5| Step: 8
Training loss: 2.651170878580878
Validation loss: 2.412381397213644

Epoch: 5| Step: 9
Training loss: 3.129386264970456
Validation loss: 2.4265045873081252

Epoch: 5| Step: 10
Training loss: 2.734359828361928
Validation loss: 2.4091226655050653

Epoch: 129| Step: 0
Training loss: 2.596144524581998
Validation loss: 2.4039861883641285

Epoch: 5| Step: 1
Training loss: 2.2651891881149533
Validation loss: 2.4210373249181605

Epoch: 5| Step: 2
Training loss: 2.161695818129745
Validation loss: 2.393672148836907

Epoch: 5| Step: 3
Training loss: 2.3561393327298825
Validation loss: 2.4106513251986343

Epoch: 5| Step: 4
Training loss: 1.7835272570666896
Validation loss: 2.400729452283665

Epoch: 5| Step: 5
Training loss: 2.683331206026675
Validation loss: 2.394697338577129

Epoch: 5| Step: 6
Training loss: 2.552741379790265
Validation loss: 2.4177576967895287

Epoch: 5| Step: 7
Training loss: 2.9636665590559614
Validation loss: 2.4108036770068155

Epoch: 5| Step: 8
Training loss: 2.8912969684537835
Validation loss: 2.4081462520754724

Epoch: 5| Step: 9
Training loss: 2.3414052806059265
Validation loss: 2.405583402652837

Epoch: 5| Step: 10
Training loss: 2.680639514914928
Validation loss: 2.427138791134407

Epoch: 130| Step: 0
Training loss: 2.784865611616109
Validation loss: 2.3984532787470285

Epoch: 5| Step: 1
Training loss: 2.419147555382754
Validation loss: 2.4157376775723542

Epoch: 5| Step: 2
Training loss: 2.5700619468199486
Validation loss: 2.4012472520122525

Epoch: 5| Step: 3
Training loss: 2.626429123359882
Validation loss: 2.3984342965660495

Epoch: 5| Step: 4
Training loss: 2.404154670284319
Validation loss: 2.4353114921565937

Epoch: 5| Step: 5
Training loss: 2.1668986660897556
Validation loss: 2.4226419060937054

Epoch: 5| Step: 6
Training loss: 2.4690918504664907
Validation loss: 2.409748958742605

Epoch: 5| Step: 7
Training loss: 2.2376391703197083
Validation loss: 2.399495036401559

Epoch: 5| Step: 8
Training loss: 2.849685845711855
Validation loss: 2.418940481846895

Epoch: 5| Step: 9
Training loss: 2.3395059434065604
Validation loss: 2.392271303548615

Epoch: 5| Step: 10
Training loss: 2.601467188100153
Validation loss: 2.415233836167541

Epoch: 131| Step: 0
Training loss: 2.21011854984388
Validation loss: 2.4156703620867583

Epoch: 5| Step: 1
Training loss: 2.6479462924823634
Validation loss: 2.388929975924529

Epoch: 5| Step: 2
Training loss: 2.314179815580793
Validation loss: 2.393622521051563

Epoch: 5| Step: 3
Training loss: 2.309141658820543
Validation loss: 2.4268749682265427

Epoch: 5| Step: 4
Training loss: 2.697290374841192
Validation loss: 2.3971583498806877

Epoch: 5| Step: 5
Training loss: 2.757812067739653
Validation loss: 2.413621046980596

Epoch: 5| Step: 6
Training loss: 2.538754488529236
Validation loss: 2.4207409604201393

Epoch: 5| Step: 7
Training loss: 2.579675381664923
Validation loss: 2.4152288027846947

Epoch: 5| Step: 8
Training loss: 2.2461720859301533
Validation loss: 2.40590543268221

Epoch: 5| Step: 9
Training loss: 3.0497372998779095
Validation loss: 2.3946386000494706

Epoch: 5| Step: 10
Training loss: 1.8438130384110598
Validation loss: 2.4206366848857335

Epoch: 132| Step: 0
Training loss: 2.044070120189129
Validation loss: 2.4307645851605177

Epoch: 5| Step: 1
Training loss: 2.707128305608159
Validation loss: 2.4108054608540925

Epoch: 5| Step: 2
Training loss: 2.583831574989004
Validation loss: 2.4212478529619537

Epoch: 5| Step: 3
Training loss: 2.5189874579710647
Validation loss: 2.398624758237596

Epoch: 5| Step: 4
Training loss: 1.9871562780503136
Validation loss: 2.3936345658204417

Epoch: 5| Step: 5
Training loss: 2.320462925206059
Validation loss: 2.407184256986647

Epoch: 5| Step: 6
Training loss: 2.5092748258555426
Validation loss: 2.410840544687941

Epoch: 5| Step: 7
Training loss: 2.5707337750200443
Validation loss: 2.4043344336955075

Epoch: 5| Step: 8
Training loss: 2.739917652535525
Validation loss: 2.4284423437882343

Epoch: 5| Step: 9
Training loss: 2.5481726962002877
Validation loss: 2.3951679987651358

Epoch: 5| Step: 10
Training loss: 2.866406409699505
Validation loss: 2.4149467711664325

Epoch: 133| Step: 0
Training loss: 2.6129158346152215
Validation loss: 2.391908266220786

Epoch: 5| Step: 1
Training loss: 2.4678835736701434
Validation loss: 2.4264028384692957

Epoch: 5| Step: 2
Training loss: 2.3140206363453477
Validation loss: 2.396742651298788

Epoch: 5| Step: 3
Training loss: 2.5114929192618076
Validation loss: 2.4104448331424373

Epoch: 5| Step: 4
Training loss: 2.75743709959363
Validation loss: 2.408836590747962

Epoch: 5| Step: 5
Training loss: 2.4428675314316672
Validation loss: 2.391187378243224

Epoch: 5| Step: 6
Training loss: 2.108395723568193
Validation loss: 2.4157404144694583

Epoch: 5| Step: 7
Training loss: 2.345349592491178
Validation loss: 2.4060038970910793

Epoch: 5| Step: 8
Training loss: 2.8839486217181403
Validation loss: 2.416445938089495

Epoch: 5| Step: 9
Training loss: 2.689275997537288
Validation loss: 2.4368468693495577

Epoch: 5| Step: 10
Training loss: 2.0279410774052913
Validation loss: 2.40913441436565

Epoch: 134| Step: 0
Training loss: 2.9331920770388056
Validation loss: 2.4074929314947453

Epoch: 5| Step: 1
Training loss: 2.745612806418592
Validation loss: 2.4093729334028438

Epoch: 5| Step: 2
Training loss: 2.200916346532692
Validation loss: 2.4009570679270533

Epoch: 5| Step: 3
Training loss: 2.336131110189529
Validation loss: 2.425539479423613

Epoch: 5| Step: 4
Training loss: 2.2683765408756695
Validation loss: 2.390897789579608

Epoch: 5| Step: 5
Training loss: 2.486288713141335
Validation loss: 2.4072534849649916

Epoch: 5| Step: 6
Training loss: 2.2481429595696527
Validation loss: 2.4321602209666326

Epoch: 5| Step: 7
Training loss: 2.774752968454977
Validation loss: 2.3993921913424527

Epoch: 5| Step: 8
Training loss: 2.4150483423927045
Validation loss: 2.39004934544783

Epoch: 5| Step: 9
Training loss: 2.437291747758193
Validation loss: 2.3881942672266723

Epoch: 5| Step: 10
Training loss: 2.424740185534564
Validation loss: 2.3869929268206076

Epoch: 135| Step: 0
Training loss: 2.3502018943256338
Validation loss: 2.3935001677839853

Epoch: 5| Step: 1
Training loss: 2.7285135278714203
Validation loss: 2.4123288311881663

Epoch: 5| Step: 2
Training loss: 2.1184439784140987
Validation loss: 2.395517183036545

Epoch: 5| Step: 3
Training loss: 2.7761327407717316
Validation loss: 2.3970153628450053

Epoch: 5| Step: 4
Training loss: 2.8279055515526323
Validation loss: 2.4142149705077753

Epoch: 5| Step: 5
Training loss: 2.3125023712970845
Validation loss: 2.389834695942292

Epoch: 5| Step: 6
Training loss: 2.824374583734531
Validation loss: 2.4087773067292844

Epoch: 5| Step: 7
Training loss: 2.0065740781104555
Validation loss: 2.396537719392804

Epoch: 5| Step: 8
Training loss: 2.1496864711239407
Validation loss: 2.397173863804722

Epoch: 5| Step: 9
Training loss: 2.3945063578819354
Validation loss: 2.403208920018327

Epoch: 5| Step: 10
Training loss: 2.636965139674331
Validation loss: 2.400895633162197

Epoch: 136| Step: 0
Training loss: 2.464921711264594
Validation loss: 2.417273077944088

Epoch: 5| Step: 1
Training loss: 2.8081830272202124
Validation loss: 2.4268951677559225

Epoch: 5| Step: 2
Training loss: 2.5201648004322834
Validation loss: 2.39644783417989

Epoch: 5| Step: 3
Training loss: 2.3384787728759493
Validation loss: 2.368109631586806

Epoch: 5| Step: 4
Training loss: 2.3213098097384774
Validation loss: 2.417192561715709

Epoch: 5| Step: 5
Training loss: 2.4470536245964025
Validation loss: 2.39702539914003

Epoch: 5| Step: 6
Training loss: 2.0719872952001777
Validation loss: 2.412529473706773

Epoch: 5| Step: 7
Training loss: 2.8575395206578653
Validation loss: 2.386965408524155

Epoch: 5| Step: 8
Training loss: 2.3923495187341666
Validation loss: 2.4164604492237083

Epoch: 5| Step: 9
Training loss: 2.969447967397156
Validation loss: 2.393745221486893

Epoch: 5| Step: 10
Training loss: 1.6287755387734637
Validation loss: 2.3870204050621204

Epoch: 137| Step: 0
Training loss: 2.55022888278361
Validation loss: 2.409690207836642

Epoch: 5| Step: 1
Training loss: 2.369935508526592
Validation loss: 2.4191840945601015

Epoch: 5| Step: 2
Training loss: 1.9675467310860926
Validation loss: 2.436794397641719

Epoch: 5| Step: 3
Training loss: 2.699631655257095
Validation loss: 2.389654304695025

Epoch: 5| Step: 4
Training loss: 1.898209734781657
Validation loss: 2.3941309008936424

Epoch: 5| Step: 5
Training loss: 2.6814123002306314
Validation loss: 2.422218832378205

Epoch: 5| Step: 6
Training loss: 2.026325536093018
Validation loss: 2.4051505897163477

Epoch: 5| Step: 7
Training loss: 3.130148347014308
Validation loss: 2.393773534678311

Epoch: 5| Step: 8
Training loss: 2.6370288807774176
Validation loss: 2.3971199172881

Epoch: 5| Step: 9
Training loss: 2.266004859387136
Validation loss: 2.402873143237873

Epoch: 5| Step: 10
Training loss: 2.72934718420741
Validation loss: 2.4194385224912973

Epoch: 138| Step: 0
Training loss: 3.1885837881568486
Validation loss: 2.421967989498907

Epoch: 5| Step: 1
Training loss: 2.8483723392870064
Validation loss: 2.396048524313675

Epoch: 5| Step: 2
Training loss: 2.160428959496697
Validation loss: 2.4006008748752286

Epoch: 5| Step: 3
Training loss: 2.1825142855356945
Validation loss: 2.402664643619039

Epoch: 5| Step: 4
Training loss: 2.675037497854787
Validation loss: 2.4125639921271906

Epoch: 5| Step: 5
Training loss: 2.220035878828018
Validation loss: 2.4139114132423476

Epoch: 5| Step: 6
Training loss: 2.8990951573418977
Validation loss: 2.4065171631344615

Epoch: 5| Step: 7
Training loss: 1.8641469292014305
Validation loss: 2.3932204902421397

Epoch: 5| Step: 8
Training loss: 2.293028848565583
Validation loss: 2.4071216770319013

Epoch: 5| Step: 9
Training loss: 2.290951102698627
Validation loss: 2.397193127602779

Epoch: 5| Step: 10
Training loss: 2.251430162912654
Validation loss: 2.4009275880209846

Epoch: 139| Step: 0
Training loss: 2.345830375529492
Validation loss: 2.3968635095573125

Epoch: 5| Step: 1
Training loss: 1.9348721064211938
Validation loss: 2.415048889079392

Epoch: 5| Step: 2
Training loss: 2.465652067280038
Validation loss: 2.403805780877898

Epoch: 5| Step: 3
Training loss: 2.500544679434394
Validation loss: 2.3941172363477743

Epoch: 5| Step: 4
Training loss: 2.2824093733612782
Validation loss: 2.420951772617215

Epoch: 5| Step: 5
Training loss: 2.6120588924960004
Validation loss: 2.406636055175113

Epoch: 5| Step: 6
Training loss: 2.8129461994145535
Validation loss: 2.397499430922396

Epoch: 5| Step: 7
Training loss: 2.8220085475746224
Validation loss: 2.4032879104973772

Epoch: 5| Step: 8
Training loss: 2.444869711277239
Validation loss: 2.393783011602819

Epoch: 5| Step: 9
Training loss: 2.4989568441327457
Validation loss: 2.40465778398914

Epoch: 5| Step: 10
Training loss: 2.235360841744338
Validation loss: 2.4010933259722065

Epoch: 140| Step: 0
Training loss: 2.317302768384254
Validation loss: 2.395709277914216

Epoch: 5| Step: 1
Training loss: 3.0155411940872745
Validation loss: 2.398211030621811

Epoch: 5| Step: 2
Training loss: 2.118400198268593
Validation loss: 2.401427326474299

Epoch: 5| Step: 3
Training loss: 2.482049009111297
Validation loss: 2.4075412346139657

Epoch: 5| Step: 4
Training loss: 2.675377318251283
Validation loss: 2.4211826823498144

Epoch: 5| Step: 5
Training loss: 2.458267458879026
Validation loss: 2.4275850082715014

Epoch: 5| Step: 6
Training loss: 2.0296627004986347
Validation loss: 2.422116521409235

Epoch: 5| Step: 7
Training loss: 2.502554542030971
Validation loss: 2.390952286074997

Epoch: 5| Step: 8
Training loss: 2.747843069884568
Validation loss: 2.430539985602962

Epoch: 5| Step: 9
Training loss: 2.799645357152219
Validation loss: 2.4273616152925164

Epoch: 5| Step: 10
Training loss: 1.6400717392792
Validation loss: 2.41975123253312

Epoch: 141| Step: 0
Training loss: 2.4339010617123176
Validation loss: 2.393359598826947

Epoch: 5| Step: 1
Training loss: 2.292162257850586
Validation loss: 2.4072711590587526

Epoch: 5| Step: 2
Training loss: 2.5077762779400747
Validation loss: 2.3855722880556804

Epoch: 5| Step: 3
Training loss: 2.355424010704365
Validation loss: 2.407237576465703

Epoch: 5| Step: 4
Training loss: 2.576767072543147
Validation loss: 2.400118131939073

Epoch: 5| Step: 5
Training loss: 2.516810357073834
Validation loss: 2.406025255306049

Epoch: 5| Step: 6
Training loss: 2.45664162268052
Validation loss: 2.4015962649186897

Epoch: 5| Step: 7
Training loss: 2.2681584367261025
Validation loss: 2.3663597412769426

Epoch: 5| Step: 8
Training loss: 2.3316065211397454
Validation loss: 2.4082907056550487

Epoch: 5| Step: 9
Training loss: 2.432057001092137
Validation loss: 2.3955598968509872

Epoch: 5| Step: 10
Training loss: 2.6682400432848743
Validation loss: 2.393019331130662

Epoch: 142| Step: 0
Training loss: 2.2249134046869585
Validation loss: 2.4079968009500674

Epoch: 5| Step: 1
Training loss: 1.9504460998261466
Validation loss: 2.3932448451384585

Epoch: 5| Step: 2
Training loss: 2.2375743874912595
Validation loss: 2.396672406247127

Epoch: 5| Step: 3
Training loss: 2.5216416148142926
Validation loss: 2.372412947292259

Epoch: 5| Step: 4
Training loss: 2.784425444311921
Validation loss: 2.3855365118183416

Epoch: 5| Step: 5
Training loss: 2.525811841020188
Validation loss: 2.3921850418401087

Epoch: 5| Step: 6
Training loss: 2.5705705414616364
Validation loss: 2.3882203549437038

Epoch: 5| Step: 7
Training loss: 2.4537340124992073
Validation loss: 2.4058115250297396

Epoch: 5| Step: 8
Training loss: 2.7180944946008756
Validation loss: 2.401529965886302

Epoch: 5| Step: 9
Training loss: 2.5051710055948173
Validation loss: 2.4046007472507456

Epoch: 5| Step: 10
Training loss: 2.327227220950578
Validation loss: 2.3849522121057802

Epoch: 143| Step: 0
Training loss: 2.484579977540454
Validation loss: 2.406335275963741

Epoch: 5| Step: 1
Training loss: 2.5354100645465723
Validation loss: 2.394631671276921

Epoch: 5| Step: 2
Training loss: 2.361413542383429
Validation loss: 2.3856730284181786

Epoch: 5| Step: 3
Training loss: 3.2316791891321337
Validation loss: 2.4052414332595267

Epoch: 5| Step: 4
Training loss: 1.9009915349612325
Validation loss: 2.3979638583869067

Epoch: 5| Step: 5
Training loss: 2.702940653429956
Validation loss: 2.3841735148310463

Epoch: 5| Step: 6
Training loss: 2.426448613507593
Validation loss: 2.396028906787987

Epoch: 5| Step: 7
Training loss: 2.617737851708248
Validation loss: 2.4094898731113097

Epoch: 5| Step: 8
Training loss: 2.2607286885396123
Validation loss: 2.3952157214745013

Epoch: 5| Step: 9
Training loss: 2.075897399616106
Validation loss: 2.4127304576184807

Epoch: 5| Step: 10
Training loss: 1.992400034618856
Validation loss: 2.4149756521301486

Epoch: 144| Step: 0
Training loss: 2.4217680876729695
Validation loss: 2.3821179224046296

Epoch: 5| Step: 1
Training loss: 2.380275188372469
Validation loss: 2.394739921422679

Epoch: 5| Step: 2
Training loss: 2.152252915364348
Validation loss: 2.3921710596788053

Epoch: 5| Step: 3
Training loss: 2.2775969847077326
Validation loss: 2.402072785899385

Epoch: 5| Step: 4
Training loss: 2.512184871060547
Validation loss: 2.390355274507765

Epoch: 5| Step: 5
Training loss: 2.868508016648576
Validation loss: 2.4052038551523762

Epoch: 5| Step: 6
Training loss: 2.2284801055725443
Validation loss: 2.3974173988803344

Epoch: 5| Step: 7
Training loss: 2.9063999588537697
Validation loss: 2.3888021542640954

Epoch: 5| Step: 8
Training loss: 2.1876970474867017
Validation loss: 2.4000399215772226

Epoch: 5| Step: 9
Training loss: 1.9174644910565855
Validation loss: 2.4029663607724494

Epoch: 5| Step: 10
Training loss: 2.7617215125516594
Validation loss: 2.4016052162019674

Epoch: 145| Step: 0
Training loss: 2.225139390672495
Validation loss: 2.396047605230566

Epoch: 5| Step: 1
Training loss: 2.638877606507214
Validation loss: 2.3765419594386064

Epoch: 5| Step: 2
Training loss: 2.612314179305186
Validation loss: 2.385845658569035

Epoch: 5| Step: 3
Training loss: 1.6856232556202158
Validation loss: 2.403971044194202

Epoch: 5| Step: 4
Training loss: 2.1342927037203236
Validation loss: 2.3775207039798847

Epoch: 5| Step: 5
Training loss: 2.193749791332789
Validation loss: 2.3972123554202716

Epoch: 5| Step: 6
Training loss: 2.5805889031215457
Validation loss: 2.384647012186476

Epoch: 5| Step: 7
Training loss: 2.825215144109232
Validation loss: 2.3879885853456297

Epoch: 5| Step: 8
Training loss: 2.762469371781214
Validation loss: 2.3966515583526995

Epoch: 5| Step: 9
Training loss: 2.5933325557985425
Validation loss: 2.3822215670348545

Epoch: 5| Step: 10
Training loss: 2.110539884695126
Validation loss: 2.377414036734535

Epoch: 146| Step: 0
Training loss: 2.537544900280813
Validation loss: 2.389585127950839

Epoch: 5| Step: 1
Training loss: 2.095390474261068
Validation loss: 2.4026677976658446

Epoch: 5| Step: 2
Training loss: 2.532543746555339
Validation loss: 2.3853319146497105

Epoch: 5| Step: 3
Training loss: 2.386417650874787
Validation loss: 2.393930287333617

Epoch: 5| Step: 4
Training loss: 2.509579045229086
Validation loss: 2.376129829388206

Epoch: 5| Step: 5
Training loss: 1.9256605377434295
Validation loss: 2.412011166209412

Epoch: 5| Step: 6
Training loss: 2.7851892926796067
Validation loss: 2.3914956465775092

Epoch: 5| Step: 7
Training loss: 2.317933786692309
Validation loss: 2.413211077533478

Epoch: 5| Step: 8
Training loss: 2.7163613887019453
Validation loss: 2.3644187913002854

Epoch: 5| Step: 9
Training loss: 2.638685789713959
Validation loss: 2.372847251204851

Epoch: 5| Step: 10
Training loss: 2.17110083524983
Validation loss: 2.3852826249314956

Epoch: 147| Step: 0
Training loss: 1.8480511942869229
Validation loss: 2.389524384631633

Epoch: 5| Step: 1
Training loss: 2.5234759537450797
Validation loss: 2.3908017697905026

Epoch: 5| Step: 2
Training loss: 2.338969224842328
Validation loss: 2.375682357146303

Epoch: 5| Step: 3
Training loss: 2.39433011428395
Validation loss: 2.3615526161349103

Epoch: 5| Step: 4
Training loss: 2.504465501909808
Validation loss: 2.379772272262396

Epoch: 5| Step: 5
Training loss: 2.3134136972384147
Validation loss: 2.3922064527034608

Epoch: 5| Step: 6
Training loss: 2.113708340117557
Validation loss: 2.3624203689522916

Epoch: 5| Step: 7
Training loss: 2.593343312196075
Validation loss: 2.384336366021792

Epoch: 5| Step: 8
Training loss: 2.625500767489953
Validation loss: 2.411285307717089

Epoch: 5| Step: 9
Training loss: 2.6040437796526494
Validation loss: 2.4030926683976275

Epoch: 5| Step: 10
Training loss: 2.6342621839085334
Validation loss: 2.368384092237197

Epoch: 148| Step: 0
Training loss: 2.228066455130772
Validation loss: 2.3801744177304727

Epoch: 5| Step: 1
Training loss: 2.2315641208798245
Validation loss: 2.394814178646883

Epoch: 5| Step: 2
Training loss: 2.834302362522769
Validation loss: 2.366191349960212

Epoch: 5| Step: 3
Training loss: 2.0757658912282877
Validation loss: 2.3977906669379805

Epoch: 5| Step: 4
Training loss: 2.7193064503850897
Validation loss: 2.3882007439630972

Epoch: 5| Step: 5
Training loss: 2.267742456597924
Validation loss: 2.3775388471038013

Epoch: 5| Step: 6
Training loss: 1.9957773215358927
Validation loss: 2.4056519946680828

Epoch: 5| Step: 7
Training loss: 2.5455898482726282
Validation loss: 2.3985689322333474

Epoch: 5| Step: 8
Training loss: 2.335508377311707
Validation loss: 2.376347155961783

Epoch: 5| Step: 9
Training loss: 2.492252360967788
Validation loss: 2.4106867776336403

Epoch: 5| Step: 10
Training loss: 2.716510859118951
Validation loss: 2.4175914173313777

Epoch: 149| Step: 0
Training loss: 2.4201948675404004
Validation loss: 2.3731122186373454

Epoch: 5| Step: 1
Training loss: 2.6612805470746665
Validation loss: 2.402553754261951

Epoch: 5| Step: 2
Training loss: 2.5519794261306346
Validation loss: 2.385669928199519

Epoch: 5| Step: 3
Training loss: 2.2567557531528366
Validation loss: 2.404522254622966

Epoch: 5| Step: 4
Training loss: 2.2995364800147664
Validation loss: 2.382232387752962

Epoch: 5| Step: 5
Training loss: 2.273518773884187
Validation loss: 2.3882385842411087

Epoch: 5| Step: 6
Training loss: 2.614038012857888
Validation loss: 2.3855568400000333

Epoch: 5| Step: 7
Training loss: 2.0253355336950594
Validation loss: 2.3684585036080295

Epoch: 5| Step: 8
Training loss: 2.6029126212321327
Validation loss: 2.3727017877785266

Epoch: 5| Step: 9
Training loss: 2.3563511146280676
Validation loss: 2.3914630066423856

Epoch: 5| Step: 10
Training loss: 2.3701968562784415
Validation loss: 2.3810967373631806

Epoch: 150| Step: 0
Training loss: 2.0010140947477484
Validation loss: 2.3715925670305986

Epoch: 5| Step: 1
Training loss: 2.491575064192647
Validation loss: 2.3714741061213345

Epoch: 5| Step: 2
Training loss: 2.566298483991203
Validation loss: 2.379293325180605

Epoch: 5| Step: 3
Training loss: 2.1219753730416304
Validation loss: 2.379766157171076

Epoch: 5| Step: 4
Training loss: 2.2975012515856434
Validation loss: 2.4016764228430616

Epoch: 5| Step: 5
Training loss: 2.2597814508277945
Validation loss: 2.3898986500083392

Epoch: 5| Step: 6
Training loss: 2.8269623110417545
Validation loss: 2.3807393604490454

Epoch: 5| Step: 7
Training loss: 2.394938448312109
Validation loss: 2.3753312035939604

Epoch: 5| Step: 8
Training loss: 2.53896061619506
Validation loss: 2.3751324517924224

Epoch: 5| Step: 9
Training loss: 2.7524034227826424
Validation loss: 2.357461061886095

Epoch: 5| Step: 10
Training loss: 2.0587204490629945
Validation loss: 2.363700515058074

Epoch: 151| Step: 0
Training loss: 2.561510779014662
Validation loss: 2.387348202479413

Epoch: 5| Step: 1
Training loss: 1.5008460678726692
Validation loss: 2.364690951569561

Epoch: 5| Step: 2
Training loss: 3.3357430966481725
Validation loss: 2.3861382272547416

Epoch: 5| Step: 3
Training loss: 2.7011546632958963
Validation loss: 2.411334335961753

Epoch: 5| Step: 4
Training loss: 2.162229567359889
Validation loss: 2.3708477618085535

Epoch: 5| Step: 5
Training loss: 2.3458516171580204
Validation loss: 2.3678379757794064

Epoch: 5| Step: 6
Training loss: 2.5042800505279295
Validation loss: 2.4018269140743844

Epoch: 5| Step: 7
Training loss: 2.137138590458719
Validation loss: 2.3746522023794445

Epoch: 5| Step: 8
Training loss: 2.2844421836064224
Validation loss: 2.3642619828375735

Epoch: 5| Step: 9
Training loss: 2.2366649923683113
Validation loss: 2.372568866946471

Epoch: 5| Step: 10
Training loss: 2.0453611410373536
Validation loss: 2.377406582216633

Epoch: 152| Step: 0
Training loss: 2.4183279334581353
Validation loss: 2.391102368310007

Epoch: 5| Step: 1
Training loss: 2.5103464604819097
Validation loss: 2.385338143905116

Epoch: 5| Step: 2
Training loss: 2.428326977119514
Validation loss: 2.38022002736539

Epoch: 5| Step: 3
Training loss: 2.559986835982332
Validation loss: 2.3714973363154375

Epoch: 5| Step: 4
Training loss: 2.1679529137935125
Validation loss: 2.3918186215648505

Epoch: 5| Step: 5
Training loss: 2.6149388004530327
Validation loss: 2.412660906509037

Epoch: 5| Step: 6
Training loss: 2.0271412301755487
Validation loss: 2.4002666931512104

Epoch: 5| Step: 7
Training loss: 2.0364133499783916
Validation loss: 2.3598699422038347

Epoch: 5| Step: 8
Training loss: 1.9970793259843966
Validation loss: 2.3749237955040563

Epoch: 5| Step: 9
Training loss: 2.640479360322443
Validation loss: 2.374471790272833

Epoch: 5| Step: 10
Training loss: 2.735862719582993
Validation loss: 2.3923905520717197

Epoch: 153| Step: 0
Training loss: 2.3513331507369166
Validation loss: 2.395280195445848

Epoch: 5| Step: 1
Training loss: 2.541361357898974
Validation loss: 2.3628578223671206

Epoch: 5| Step: 2
Training loss: 2.440631713076455
Validation loss: 2.3773985270408233

Epoch: 5| Step: 3
Training loss: 2.32133158386854
Validation loss: 2.3570222968722936

Epoch: 5| Step: 4
Training loss: 2.15679769885396
Validation loss: 2.365612780799691

Epoch: 5| Step: 5
Training loss: 2.402212644891804
Validation loss: 2.3512020983009405

Epoch: 5| Step: 6
Training loss: 2.1835297658755093
Validation loss: 2.385441403588279

Epoch: 5| Step: 7
Training loss: 2.8410331407686535
Validation loss: 2.3807222442476417

Epoch: 5| Step: 8
Training loss: 2.7799277430687566
Validation loss: 2.370888667179349

Epoch: 5| Step: 9
Training loss: 1.9518879749600957
Validation loss: 2.379684825446991

Epoch: 5| Step: 10
Training loss: 1.8842912620550354
Validation loss: 2.3794603534779593

Epoch: 154| Step: 0
Training loss: 2.865719286782927
Validation loss: 2.379249116848783

Epoch: 5| Step: 1
Training loss: 1.7072027543636508
Validation loss: 2.361713322330812

Epoch: 5| Step: 2
Training loss: 2.4207403663034635
Validation loss: 2.3473003123699723

Epoch: 5| Step: 3
Training loss: 2.2023076915461672
Validation loss: 2.4105031992702153

Epoch: 5| Step: 4
Training loss: 2.9932816300319973
Validation loss: 2.382502075179947

Epoch: 5| Step: 5
Training loss: 2.386065854240554
Validation loss: 2.405745944779278

Epoch: 5| Step: 6
Training loss: 2.3564066624860804
Validation loss: 2.3744607927515773

Epoch: 5| Step: 7
Training loss: 2.2069597350830468
Validation loss: 2.3919238109812864

Epoch: 5| Step: 8
Training loss: 2.405608946384176
Validation loss: 2.3707929664611167

Epoch: 5| Step: 9
Training loss: 1.9171847665980222
Validation loss: 2.389134394269215

Epoch: 5| Step: 10
Training loss: 2.606789958831615
Validation loss: 2.3918491237188837

Epoch: 155| Step: 0
Training loss: 2.7815595304573786
Validation loss: 2.3948094952193135

Epoch: 5| Step: 1
Training loss: 2.3136410346770107
Validation loss: 2.374352136317707

Epoch: 5| Step: 2
Training loss: 2.2953766587277413
Validation loss: 2.3677311354294126

Epoch: 5| Step: 3
Training loss: 1.8875445025926085
Validation loss: 2.390250833875852

Epoch: 5| Step: 4
Training loss: 2.5240794212734747
Validation loss: 2.378190876833638

Epoch: 5| Step: 5
Training loss: 2.5944065963449527
Validation loss: 2.3723508743837147

Epoch: 5| Step: 6
Training loss: 2.3405605740205013
Validation loss: 2.3752588310240768

Epoch: 5| Step: 7
Training loss: 2.041338005341296
Validation loss: 2.37161453997929

Epoch: 5| Step: 8
Training loss: 2.5620702057450067
Validation loss: 2.393564966440556

Epoch: 5| Step: 9
Training loss: 2.111549217653185
Validation loss: 2.362580191444963

Epoch: 5| Step: 10
Training loss: 2.4950038578103
Validation loss: 2.373392557441283

Epoch: 156| Step: 0
Training loss: 2.0508291475061355
Validation loss: 2.3698081541428797

Epoch: 5| Step: 1
Training loss: 2.0862468818654962
Validation loss: 2.3763277706432877

Epoch: 5| Step: 2
Training loss: 2.2852337685503
Validation loss: 2.377921332227792

Epoch: 5| Step: 3
Training loss: 2.600509934670238
Validation loss: 2.3844271784494397

Epoch: 5| Step: 4
Training loss: 2.714460387023267
Validation loss: 2.3894132572188798

Epoch: 5| Step: 5
Training loss: 2.1556216443910303
Validation loss: 2.373123554594636

Epoch: 5| Step: 6
Training loss: 2.8216742189610087
Validation loss: 2.3767147253556744

Epoch: 5| Step: 7
Training loss: 2.3013180687745476
Validation loss: 2.3561926180986354

Epoch: 5| Step: 8
Training loss: 2.4088073615948282
Validation loss: 2.369141803403649

Epoch: 5| Step: 9
Training loss: 2.2653305388521887
Validation loss: 2.3719281244268586

Epoch: 5| Step: 10
Training loss: 2.278108288529669
Validation loss: 2.3706716745086696

Epoch: 157| Step: 0
Training loss: 2.899334462847226
Validation loss: 2.3559122582440923

Epoch: 5| Step: 1
Training loss: 2.4724103615521926
Validation loss: 2.360598447888737

Epoch: 5| Step: 2
Training loss: 2.064498280127916
Validation loss: 2.393311394571406

Epoch: 5| Step: 3
Training loss: 2.306746878506401
Validation loss: 2.3779627050923344

Epoch: 5| Step: 4
Training loss: 2.6923259608728367
Validation loss: 2.3688235839095295

Epoch: 5| Step: 5
Training loss: 2.177903405715898
Validation loss: 2.3603536511205423

Epoch: 5| Step: 6
Training loss: 1.6678496056914724
Validation loss: 2.3485836050930704

Epoch: 5| Step: 7
Training loss: 2.190124245520201
Validation loss: 2.370148021936626

Epoch: 5| Step: 8
Training loss: 2.739779988665423
Validation loss: 2.385320971498082

Epoch: 5| Step: 9
Training loss: 2.1850535199836343
Validation loss: 2.3752817041913574

Epoch: 5| Step: 10
Training loss: 2.2565373710582377
Validation loss: 2.3591599839441795

Epoch: 158| Step: 0
Training loss: 2.4483371346454788
Validation loss: 2.323851335314336

Epoch: 5| Step: 1
Training loss: 2.58466116302248
Validation loss: 2.3955713432918646

Epoch: 5| Step: 2
Training loss: 2.3443665774261984
Validation loss: 2.3645874329864305

Epoch: 5| Step: 3
Training loss: 2.6542819642356204
Validation loss: 2.372849952760864

Epoch: 5| Step: 4
Training loss: 2.0899977582709597
Validation loss: 2.375888408952903

Epoch: 5| Step: 5
Training loss: 1.7420277885822106
Validation loss: 2.3830594821572286

Epoch: 5| Step: 6
Training loss: 2.205025793084731
Validation loss: 2.358421781269783

Epoch: 5| Step: 7
Training loss: 2.60479590379735
Validation loss: 2.3797049493743585

Epoch: 5| Step: 8
Training loss: 2.317498038248921
Validation loss: 2.3663964969910687

Epoch: 5| Step: 9
Training loss: 2.4547881301853978
Validation loss: 2.377785672998353

Epoch: 5| Step: 10
Training loss: 2.3766530959538628
Validation loss: 2.3513257847100064

Epoch: 159| Step: 0
Training loss: 1.6730788700554513
Validation loss: 2.358644029561768

Epoch: 5| Step: 1
Training loss: 2.0031786930785302
Validation loss: 2.360468110782711

Epoch: 5| Step: 2
Training loss: 2.41539710229471
Validation loss: 2.3962130569784814

Epoch: 5| Step: 3
Training loss: 2.000742297703852
Validation loss: 2.392702061865023

Epoch: 5| Step: 4
Training loss: 2.0867465732537642
Validation loss: 2.373877099580828

Epoch: 5| Step: 5
Training loss: 2.4147946133361256
Validation loss: 2.37904124726658

Epoch: 5| Step: 6
Training loss: 2.668535342729552
Validation loss: 2.390152471315042

Epoch: 5| Step: 7
Training loss: 2.273217678913011
Validation loss: 2.3665824676567078

Epoch: 5| Step: 8
Training loss: 2.7041279249741947
Validation loss: 2.388366735001096

Epoch: 5| Step: 9
Training loss: 2.199462877075182
Validation loss: 2.3999122809116935

Epoch: 5| Step: 10
Training loss: 3.04632140779135
Validation loss: 2.3732098285999297

Epoch: 160| Step: 0
Training loss: 2.0210407452144894
Validation loss: 2.4042112814835095

Epoch: 5| Step: 1
Training loss: 2.5043485967864125
Validation loss: 2.376018085756451

Epoch: 5| Step: 2
Training loss: 2.3795842549700703
Validation loss: 2.3894070573635027

Epoch: 5| Step: 3
Training loss: 2.4243366159939352
Validation loss: 2.3757331463521982

Epoch: 5| Step: 4
Training loss: 2.2983295220815343
Validation loss: 2.393552755307016

Epoch: 5| Step: 5
Training loss: 2.4670752144037666
Validation loss: 2.407667275619068

Epoch: 5| Step: 6
Training loss: 2.113682171203092
Validation loss: 2.3795588531203964

Epoch: 5| Step: 7
Training loss: 2.3185591832534227
Validation loss: 2.3879187065315044

Epoch: 5| Step: 8
Training loss: 2.5540968652576863
Validation loss: 2.372890055461292

Epoch: 5| Step: 9
Training loss: 2.4291798346431386
Validation loss: 2.3841986357957925

Epoch: 5| Step: 10
Training loss: 2.2815337331243914
Validation loss: 2.3921295006592787

Epoch: 161| Step: 0
Training loss: 2.2381022916023703
Validation loss: 2.357934714408482

Epoch: 5| Step: 1
Training loss: 2.3859184659087482
Validation loss: 2.3575466965856533

Epoch: 5| Step: 2
Training loss: 2.0517116797452264
Validation loss: 2.3679972994610776

Epoch: 5| Step: 3
Training loss: 2.3594941368086766
Validation loss: 2.357919758289379

Epoch: 5| Step: 4
Training loss: 2.512339181640237
Validation loss: 2.380277858341724

Epoch: 5| Step: 5
Training loss: 2.7419515220201993
Validation loss: 2.388248590866115

Epoch: 5| Step: 6
Training loss: 2.348271903305545
Validation loss: 2.3675151002484673

Epoch: 5| Step: 7
Training loss: 2.3771839139511886
Validation loss: 2.352046836137447

Epoch: 5| Step: 8
Training loss: 2.1869655501203784
Validation loss: 2.357860883141883

Epoch: 5| Step: 9
Training loss: 2.1502901724238423
Validation loss: 2.4046423210140855

Epoch: 5| Step: 10
Training loss: 2.2520359153119607
Validation loss: 2.349924170039292

Epoch: 162| Step: 0
Training loss: 2.5229857427169264
Validation loss: 2.359802739742817

Epoch: 5| Step: 1
Training loss: 1.967868365324271
Validation loss: 2.3749266172167585

Epoch: 5| Step: 2
Training loss: 2.295434201456834
Validation loss: 2.3607651254537694

Epoch: 5| Step: 3
Training loss: 2.1286374543612108
Validation loss: 2.3661758598815514

Epoch: 5| Step: 4
Training loss: 2.0350031291740787
Validation loss: 2.3647937219380473

Epoch: 5| Step: 5
Training loss: 2.5896763812222656
Validation loss: 2.3528766867504536

Epoch: 5| Step: 6
Training loss: 2.4671055592319244
Validation loss: 2.347688080492345

Epoch: 5| Step: 7
Training loss: 2.313689673331318
Validation loss: 2.3644144678164687

Epoch: 5| Step: 8
Training loss: 2.7093600650010528
Validation loss: 2.3728353926286556

Epoch: 5| Step: 9
Training loss: 2.1143845588452224
Validation loss: 2.3539958902441747

Epoch: 5| Step: 10
Training loss: 2.524802863102004
Validation loss: 2.3747454843115987

Epoch: 163| Step: 0
Training loss: 2.4624271788697776
Validation loss: 2.3443501022102904

Epoch: 5| Step: 1
Training loss: 2.3481347331133953
Validation loss: 2.3709035301344885

Epoch: 5| Step: 2
Training loss: 2.312281624045593
Validation loss: 2.367192103786453

Epoch: 5| Step: 3
Training loss: 2.3362392881259098
Validation loss: 2.3634014270274473

Epoch: 5| Step: 4
Training loss: 2.3921689302507323
Validation loss: 2.3671413056893997

Epoch: 5| Step: 5
Training loss: 2.13874467002967
Validation loss: 2.396378874941831

Epoch: 5| Step: 6
Training loss: 2.6713566862944673
Validation loss: 2.356606674845216

Epoch: 5| Step: 7
Training loss: 2.3604174199542207
Validation loss: 2.369794967596781

Epoch: 5| Step: 8
Training loss: 2.37551944473071
Validation loss: 2.372040526545029

Epoch: 5| Step: 9
Training loss: 2.172431380545754
Validation loss: 2.3727946877446646

Epoch: 5| Step: 10
Training loss: 1.7778679043388799
Validation loss: 2.3758023784296416

Epoch: 164| Step: 0
Training loss: 2.253353798263585
Validation loss: 2.38397499532894

Epoch: 5| Step: 1
Training loss: 1.9695717443882883
Validation loss: 2.4051194664147277

Epoch: 5| Step: 2
Training loss: 2.7940379837064726
Validation loss: 2.363423520603174

Epoch: 5| Step: 3
Training loss: 1.910824337070392
Validation loss: 2.33363729319491

Epoch: 5| Step: 4
Training loss: 2.412665002744125
Validation loss: 2.3776116985579177

Epoch: 5| Step: 5
Training loss: 2.1993894900348443
Validation loss: 2.360950775260096

Epoch: 5| Step: 6
Training loss: 1.8121244107161434
Validation loss: 2.366673373675458

Epoch: 5| Step: 7
Training loss: 2.0778518153013987
Validation loss: 2.3482572459115088

Epoch: 5| Step: 8
Training loss: 2.921587435193322
Validation loss: 2.3612185656638562

Epoch: 5| Step: 9
Training loss: 2.285988263331177
Validation loss: 2.390909106081448

Epoch: 5| Step: 10
Training loss: 2.552664326040145
Validation loss: 2.364319462482012

Epoch: 165| Step: 0
Training loss: 2.741910654205299
Validation loss: 2.3634460592436186

Epoch: 5| Step: 1
Training loss: 2.2177707499089285
Validation loss: 2.395368606058736

Epoch: 5| Step: 2
Training loss: 2.515285303151513
Validation loss: 2.359083620955668

Epoch: 5| Step: 3
Training loss: 2.1730793419935504
Validation loss: 2.3343619864049545

Epoch: 5| Step: 4
Training loss: 2.2410629589287687
Validation loss: 2.378351260737828

Epoch: 5| Step: 5
Training loss: 2.440746590568664
Validation loss: 2.3775036303823724

Epoch: 5| Step: 6
Training loss: 2.355975601044044
Validation loss: 2.3548184108940897

Epoch: 5| Step: 7
Training loss: 2.2211507783881923
Validation loss: 2.3767722058584897

Epoch: 5| Step: 8
Training loss: 2.2199091502665174
Validation loss: 2.388885932512577

Epoch: 5| Step: 9
Training loss: 2.009123733971047
Validation loss: 2.3755629972669543

Epoch: 5| Step: 10
Training loss: 2.3005982408778323
Validation loss: 2.3792212945617344

Epoch: 166| Step: 0
Training loss: 2.215499861482837
Validation loss: 2.3909295365527874

Epoch: 5| Step: 1
Training loss: 2.314203614253745
Validation loss: 2.3728546800713346

Epoch: 5| Step: 2
Training loss: 2.5575101698209908
Validation loss: 2.3711763743179866

Epoch: 5| Step: 3
Training loss: 1.5973423880371926
Validation loss: 2.356647065377278

Epoch: 5| Step: 4
Training loss: 2.2121175575542864
Validation loss: 2.354328280284806

Epoch: 5| Step: 5
Training loss: 2.2219457043693223
Validation loss: 2.3409275619009375

Epoch: 5| Step: 6
Training loss: 2.0604538449082206
Validation loss: 2.358748473058081

Epoch: 5| Step: 7
Training loss: 2.7651916854113154
Validation loss: 2.3654956276539956

Epoch: 5| Step: 8
Training loss: 2.47680075669659
Validation loss: 2.373945600694385

Epoch: 5| Step: 9
Training loss: 2.3187285388868486
Validation loss: 2.3448926102508016

Epoch: 5| Step: 10
Training loss: 2.300138477634855
Validation loss: 2.383316867274393

Epoch: 167| Step: 0
Training loss: 2.035398033262436
Validation loss: 2.350441892397107

Epoch: 5| Step: 1
Training loss: 2.099847143150465
Validation loss: 2.3759342745837357

Epoch: 5| Step: 2
Training loss: 2.2045380950633287
Validation loss: 2.345460700830379

Epoch: 5| Step: 3
Training loss: 2.462283005811478
Validation loss: 2.3461405353512266

Epoch: 5| Step: 4
Training loss: 2.1650162671118967
Validation loss: 2.362518359350194

Epoch: 5| Step: 5
Training loss: 2.1703861539905938
Validation loss: 2.363001604246584

Epoch: 5| Step: 6
Training loss: 2.0412878995648587
Validation loss: 2.3880393167920757

Epoch: 5| Step: 7
Training loss: 2.317247003368778
Validation loss: 2.3746559917223395

Epoch: 5| Step: 8
Training loss: 2.5148025021069293
Validation loss: 2.394834412019221

Epoch: 5| Step: 9
Training loss: 2.802396130504327
Validation loss: 2.369890880074245

Epoch: 5| Step: 10
Training loss: 2.3597907906276365
Validation loss: 2.376032378764386

Epoch: 168| Step: 0
Training loss: 2.345859747874019
Validation loss: 2.384321240047382

Epoch: 5| Step: 1
Training loss: 1.9601674790743029
Validation loss: 2.3629974349393623

Epoch: 5| Step: 2
Training loss: 2.6952636714327083
Validation loss: 2.3657788758983576

Epoch: 5| Step: 3
Training loss: 2.249929321026658
Validation loss: 2.393052172665628

Epoch: 5| Step: 4
Training loss: 3.041859572751404
Validation loss: 2.3783917961498044

Epoch: 5| Step: 5
Training loss: 1.7538694110221518
Validation loss: 2.4051506195614385

Epoch: 5| Step: 6
Training loss: 1.977347960480812
Validation loss: 2.3698521415803824

Epoch: 5| Step: 7
Training loss: 2.1688283504877455
Validation loss: 2.372179635421419

Epoch: 5| Step: 8
Training loss: 1.3617596811083839
Validation loss: 2.3558322119501134

Epoch: 5| Step: 9
Training loss: 2.5768788418219604
Validation loss: 2.397102490260063

Epoch: 5| Step: 10
Training loss: 2.6015104454720896
Validation loss: 2.3975819274248362

Epoch: 169| Step: 0
Training loss: 2.508969144197358
Validation loss: 2.373760747964215

Epoch: 5| Step: 1
Training loss: 2.394450001170513
Validation loss: 2.3771784861767644

Epoch: 5| Step: 2
Training loss: 2.680746864471409
Validation loss: 2.37386567164696

Epoch: 5| Step: 3
Training loss: 2.205532408987065
Validation loss: 2.4049103503185236

Epoch: 5| Step: 4
Training loss: 1.7079084922568228
Validation loss: 2.361731927733507

Epoch: 5| Step: 5
Training loss: 2.4223161849288104
Validation loss: 2.3548722073373263

Epoch: 5| Step: 6
Training loss: 2.3872069813132795
Validation loss: 2.3759783741134033

Epoch: 5| Step: 7
Training loss: 1.923634599740419
Validation loss: 2.3558681052018184

Epoch: 5| Step: 8
Training loss: 2.182845695532639
Validation loss: 2.3774850912538796

Epoch: 5| Step: 9
Training loss: 2.4815604143046266
Validation loss: 2.373821580387082

Epoch: 5| Step: 10
Training loss: 2.238271663305713
Validation loss: 2.381883611968293

Epoch: 170| Step: 0
Training loss: 2.3199410189333145
Validation loss: 2.3380223402459532

Epoch: 5| Step: 1
Training loss: 2.082962944166319
Validation loss: 2.3727878378030436

Epoch: 5| Step: 2
Training loss: 2.434633280968424
Validation loss: 2.34844868221973

Epoch: 5| Step: 3
Training loss: 2.6344443677500613
Validation loss: 2.3311243875830554

Epoch: 5| Step: 4
Training loss: 2.9324656424172337
Validation loss: 2.336431828729526

Epoch: 5| Step: 5
Training loss: 2.044253585321511
Validation loss: 2.3543039365911778

Epoch: 5| Step: 6
Training loss: 2.28384116389112
Validation loss: 2.369422166738182

Epoch: 5| Step: 7
Training loss: 2.3594694813385315
Validation loss: 2.38173808205626

Epoch: 5| Step: 8
Training loss: 2.2132444174651
Validation loss: 2.4046294401008423

Epoch: 5| Step: 9
Training loss: 1.8585616825347107
Validation loss: 2.3886120846013674

Epoch: 5| Step: 10
Training loss: 1.8441155281451973
Validation loss: 2.379052362622991

Epoch: 171| Step: 0
Training loss: 2.0361589242555307
Validation loss: 2.380734695636804

Epoch: 5| Step: 1
Training loss: 2.7909340442776602
Validation loss: 2.354764103164154

Epoch: 5| Step: 2
Training loss: 2.0607602266619938
Validation loss: 2.3497465496629566

Epoch: 5| Step: 3
Training loss: 2.1981898013041032
Validation loss: 2.393100238593392

Epoch: 5| Step: 4
Training loss: 2.7471583162783437
Validation loss: 2.358912297018161

Epoch: 5| Step: 5
Training loss: 2.0113022456427667
Validation loss: 2.3537683965876033

Epoch: 5| Step: 6
Training loss: 1.7967993015432318
Validation loss: 2.370534421609057

Epoch: 5| Step: 7
Training loss: 2.3531856574641266
Validation loss: 2.359192472592116

Epoch: 5| Step: 8
Training loss: 2.5033485874705153
Validation loss: 2.355862237654527

Epoch: 5| Step: 9
Training loss: 2.245128444064321
Validation loss: 2.343097499136267

Epoch: 5| Step: 10
Training loss: 1.9835602296608952
Validation loss: 2.339074885516898

Epoch: 172| Step: 0
Training loss: 2.0912079823634206
Validation loss: 2.34992041827262

Epoch: 5| Step: 1
Training loss: 2.561902046219056
Validation loss: 2.3416526023568798

Epoch: 5| Step: 2
Training loss: 2.4692846757401163
Validation loss: 2.352915442689899

Epoch: 5| Step: 3
Training loss: 2.115050190720101
Validation loss: 2.378826817943757

Epoch: 5| Step: 4
Training loss: 1.8902259594705721
Validation loss: 2.3732461212087066

Epoch: 5| Step: 5
Training loss: 2.318189066775272
Validation loss: 2.3666813245363016

Epoch: 5| Step: 6
Training loss: 2.3964126439384508
Validation loss: 2.348125652782488

Epoch: 5| Step: 7
Training loss: 2.3105538917106054
Validation loss: 2.3703306012387166

Epoch: 5| Step: 8
Training loss: 2.4464699440362545
Validation loss: 2.3788819498293066

Epoch: 5| Step: 9
Training loss: 2.1283221362164686
Validation loss: 2.364773480874858

Epoch: 5| Step: 10
Training loss: 2.313216433507576
Validation loss: 2.3731282149229282

Epoch: 173| Step: 0
Training loss: 2.4695690100250043
Validation loss: 2.374100668665046

Epoch: 5| Step: 1
Training loss: 2.038911192676997
Validation loss: 2.3687095388195605

Epoch: 5| Step: 2
Training loss: 2.36285648784803
Validation loss: 2.3879240041451326

Epoch: 5| Step: 3
Training loss: 1.8240306683772913
Validation loss: 2.378970774806291

Epoch: 5| Step: 4
Training loss: 2.1537249610937628
Validation loss: 2.3696980710879916

Epoch: 5| Step: 5
Training loss: 2.1235577794157354
Validation loss: 2.348825049888491

Epoch: 5| Step: 6
Training loss: 2.577852454373558
Validation loss: 2.368524218989747

Epoch: 5| Step: 7
Training loss: 2.394338677832064
Validation loss: 2.3494300984266845

Epoch: 5| Step: 8
Training loss: 2.0469913595191467
Validation loss: 2.398668447015319

Epoch: 5| Step: 9
Training loss: 2.2553008473885354
Validation loss: 2.3775389732619696

Epoch: 5| Step: 10
Training loss: 2.6166815880837984
Validation loss: 2.343639996862859

Epoch: 174| Step: 0
Training loss: 1.8254460325348278
Validation loss: 2.3526705678637123

Epoch: 5| Step: 1
Training loss: 1.7732782502451099
Validation loss: 2.3398578114795554

Epoch: 5| Step: 2
Training loss: 2.6045904094539103
Validation loss: 2.3599179572226716

Epoch: 5| Step: 3
Training loss: 2.0640866505598274
Validation loss: 2.353424070212505

Epoch: 5| Step: 4
Training loss: 2.568275641755318
Validation loss: 2.3495033080715544

Epoch: 5| Step: 5
Training loss: 1.8880333279601829
Validation loss: 2.361057592344795

Epoch: 5| Step: 6
Training loss: 2.6363036782672458
Validation loss: 2.388750447368906

Epoch: 5| Step: 7
Training loss: 2.2499694822149117
Validation loss: 2.3883256014024155

Epoch: 5| Step: 8
Training loss: 2.4957633359473084
Validation loss: 2.3515987898332487

Epoch: 5| Step: 9
Training loss: 2.0562335677490386
Validation loss: 2.3868521915940977

Epoch: 5| Step: 10
Training loss: 2.4191171017609854
Validation loss: 2.3922142297537357

Epoch: 175| Step: 0
Training loss: 1.9282672304095556
Validation loss: 2.402539548607397

Epoch: 5| Step: 1
Training loss: 2.463557129717977
Validation loss: 2.347793591191236

Epoch: 5| Step: 2
Training loss: 2.175107019356587
Validation loss: 2.3454815534153792

Epoch: 5| Step: 3
Training loss: 2.551651483445329
Validation loss: 2.3824813351742957

Epoch: 5| Step: 4
Training loss: 2.5778256329208724
Validation loss: 2.365178156499835

Epoch: 5| Step: 5
Training loss: 1.7765435398133476
Validation loss: 2.374109276026449

Epoch: 5| Step: 6
Training loss: 2.2141833523413648
Validation loss: 2.333187743301889

Epoch: 5| Step: 7
Training loss: 2.31003893237313
Validation loss: 2.3684183339895712

Epoch: 5| Step: 8
Training loss: 2.0972731824778856
Validation loss: 2.370042049392673

Epoch: 5| Step: 9
Training loss: 2.2229263329288305
Validation loss: 2.3684696166744454

Epoch: 5| Step: 10
Training loss: 2.3632830659213067
Validation loss: 2.3736675693576665

Epoch: 176| Step: 0
Training loss: 2.4220225627613683
Validation loss: 2.3560369008369215

Epoch: 5| Step: 1
Training loss: 2.525584438407016
Validation loss: 2.3509765610169775

Epoch: 5| Step: 2
Training loss: 2.098406382292372
Validation loss: 2.344870627425808

Epoch: 5| Step: 3
Training loss: 2.1225327024422995
Validation loss: 2.370783559838756

Epoch: 5| Step: 4
Training loss: 2.45193792888119
Validation loss: 2.353849055450171

Epoch: 5| Step: 5
Training loss: 2.0692072383217903
Validation loss: 2.3549099430425082

Epoch: 5| Step: 6
Training loss: 2.6610475187019023
Validation loss: 2.367024284515659

Epoch: 5| Step: 7
Training loss: 2.1818006110206314
Validation loss: 2.3786248457352643

Epoch: 5| Step: 8
Training loss: 1.5658167160124203
Validation loss: 2.3416898909387722

Epoch: 5| Step: 9
Training loss: 2.144933443970918
Validation loss: 2.361628817873321

Epoch: 5| Step: 10
Training loss: 2.260064397924022
Validation loss: 2.35743057262014

Epoch: 177| Step: 0
Training loss: 2.3182458375736887
Validation loss: 2.3766098729801137

Epoch: 5| Step: 1
Training loss: 1.8509376211840982
Validation loss: 2.3888700615968563

Epoch: 5| Step: 2
Training loss: 2.243055009661419
Validation loss: 2.3678677696680555

Epoch: 5| Step: 3
Training loss: 2.195676508689417
Validation loss: 2.3449720373003253

Epoch: 5| Step: 4
Training loss: 2.18892078580815
Validation loss: 2.3657285535241

Epoch: 5| Step: 5
Training loss: 1.8884365562425245
Validation loss: 2.386121518298696

Epoch: 5| Step: 6
Training loss: 2.8628272390095493
Validation loss: 2.355439654208179

Epoch: 5| Step: 7
Training loss: 2.147623025658683
Validation loss: 2.358867734975732

Epoch: 5| Step: 8
Training loss: 2.3955786749353853
Validation loss: 2.3959438032779286

Epoch: 5| Step: 9
Training loss: 2.2341826029285876
Validation loss: 2.371806693804991

Epoch: 5| Step: 10
Training loss: 2.2494802934402807
Validation loss: 2.380677641400718

Epoch: 178| Step: 0
Training loss: 2.353149588204403
Validation loss: 2.384366983783981

Epoch: 5| Step: 1
Training loss: 2.1845066844011063
Validation loss: 2.366094169355947

Epoch: 5| Step: 2
Training loss: 2.596017420952744
Validation loss: 2.379492855309206

Epoch: 5| Step: 3
Training loss: 1.9214963462411694
Validation loss: 2.3624933675783684

Epoch: 5| Step: 4
Training loss: 2.4812924436691297
Validation loss: 2.374568081728438

Epoch: 5| Step: 5
Training loss: 2.001997903462626
Validation loss: 2.3854199148083355

Epoch: 5| Step: 6
Training loss: 2.4024835809470106
Validation loss: 2.3546330702052143

Epoch: 5| Step: 7
Training loss: 2.23128931347489
Validation loss: 2.3818191531563357

Epoch: 5| Step: 8
Training loss: 2.2548172562471276
Validation loss: 2.3801576916808975

Epoch: 5| Step: 9
Training loss: 1.9247079454300116
Validation loss: 2.371454602592875

Epoch: 5| Step: 10
Training loss: 2.2606207994206358
Validation loss: 2.3840279913610196

Epoch: 179| Step: 0
Training loss: 2.5621372059123155
Validation loss: 2.366355724683203

Epoch: 5| Step: 1
Training loss: 1.691050855552024
Validation loss: 2.375644604996343

Epoch: 5| Step: 2
Training loss: 1.9421804561471914
Validation loss: 2.390273216617098

Epoch: 5| Step: 3
Training loss: 2.116885455781193
Validation loss: 2.3617259781454707

Epoch: 5| Step: 4
Training loss: 1.9681559075030142
Validation loss: 2.3706557638401238

Epoch: 5| Step: 5
Training loss: 2.074061845782477
Validation loss: 2.3686463525581214

Epoch: 5| Step: 6
Training loss: 2.2459221019670847
Validation loss: 2.353716052400462

Epoch: 5| Step: 7
Training loss: 2.5154162966003533
Validation loss: 2.3517976936985687

Epoch: 5| Step: 8
Training loss: 2.0045766917263843
Validation loss: 2.3551529620431304

Epoch: 5| Step: 9
Training loss: 2.7411214381040905
Validation loss: 2.395369300650177

Epoch: 5| Step: 10
Training loss: 2.4972212607448236
Validation loss: 2.3714495027745235

Epoch: 180| Step: 0
Training loss: 2.337111468332518
Validation loss: 2.3890776237914175

Epoch: 5| Step: 1
Training loss: 2.163137410328603
Validation loss: 2.3774730024090998

Epoch: 5| Step: 2
Training loss: 2.4175698686225453
Validation loss: 2.353671324446602

Epoch: 5| Step: 3
Training loss: 2.0908767571418236
Validation loss: 2.372082914137587

Epoch: 5| Step: 4
Training loss: 1.8207780627395702
Validation loss: 2.366951096364743

Epoch: 5| Step: 5
Training loss: 2.326552096536407
Validation loss: 2.3789293526595006

Epoch: 5| Step: 6
Training loss: 2.439651517840902
Validation loss: 2.3671920247283276

Epoch: 5| Step: 7
Training loss: 2.0164551910408486
Validation loss: 2.3851925302682684

Epoch: 5| Step: 8
Training loss: 2.029687133507112
Validation loss: 2.374334572412242

Epoch: 5| Step: 9
Training loss: 2.233487252961849
Validation loss: 2.366858003862492

Epoch: 5| Step: 10
Training loss: 2.6193081135858156
Validation loss: 2.3609810507620863

Epoch: 181| Step: 0
Training loss: 2.274628317516759
Validation loss: 2.3655357948836704

Epoch: 5| Step: 1
Training loss: 2.2843505482336934
Validation loss: 2.391408438167872

Epoch: 5| Step: 2
Training loss: 2.817032869975294
Validation loss: 2.370766373922257

Epoch: 5| Step: 3
Training loss: 2.0600750857622327
Validation loss: 2.366935879868249

Epoch: 5| Step: 4
Training loss: 2.0100448607187977
Validation loss: 2.3697334319357046

Epoch: 5| Step: 5
Training loss: 2.181792196747623
Validation loss: 2.398807265318306

Epoch: 5| Step: 6
Training loss: 2.1390362712179947
Validation loss: 2.3683054422510583

Epoch: 5| Step: 7
Training loss: 2.5574057580135
Validation loss: 2.350978976379676

Epoch: 5| Step: 8
Training loss: 1.8529423589907452
Validation loss: 2.3465692639773814

Epoch: 5| Step: 9
Training loss: 2.227427103924144
Validation loss: 2.3584410800610267

Epoch: 5| Step: 10
Training loss: 1.6675581058060986
Validation loss: 2.3556742377084614

Epoch: 182| Step: 0
Training loss: 2.445581000946389
Validation loss: 2.3510078656699434

Epoch: 5| Step: 1
Training loss: 2.103691072505666
Validation loss: 2.3527888096240184

Epoch: 5| Step: 2
Training loss: 2.272392216173246
Validation loss: 2.3446272085554525

Epoch: 5| Step: 3
Training loss: 1.7589949636121587
Validation loss: 2.3826745046932016

Epoch: 5| Step: 4
Training loss: 2.5932157954504444
Validation loss: 2.3668874483223004

Epoch: 5| Step: 5
Training loss: 1.8638734656104972
Validation loss: 2.3449969654538956

Epoch: 5| Step: 6
Training loss: 2.38967597424878
Validation loss: 2.3376053766241998

Epoch: 5| Step: 7
Training loss: 2.2620553143430655
Validation loss: 2.3830750948580204

Epoch: 5| Step: 8
Training loss: 2.1436401072103317
Validation loss: 2.378241922919545

Epoch: 5| Step: 9
Training loss: 1.8732727360116297
Validation loss: 2.3861375160091254

Epoch: 5| Step: 10
Training loss: 2.400463031766209
Validation loss: 2.363369294542417

Epoch: 183| Step: 0
Training loss: 1.5079024688285605
Validation loss: 2.3534663955045927

Epoch: 5| Step: 1
Training loss: 2.4241285114907107
Validation loss: 2.378564659433999

Epoch: 5| Step: 2
Training loss: 2.2481943938824167
Validation loss: 2.368936472058702

Epoch: 5| Step: 3
Training loss: 2.0779581791742037
Validation loss: 2.363197431889024

Epoch: 5| Step: 4
Training loss: 1.9588417313159139
Validation loss: 2.383907571747724

Epoch: 5| Step: 5
Training loss: 1.8606823084023543
Validation loss: 2.3930192432840935

Epoch: 5| Step: 6
Training loss: 2.839911248875439
Validation loss: 2.355223684565708

Epoch: 5| Step: 7
Training loss: 2.235319884789469
Validation loss: 2.366832241758285

Epoch: 5| Step: 8
Training loss: 2.394026785602681
Validation loss: 2.3743619245188428

Epoch: 5| Step: 9
Training loss: 2.183481175996018
Validation loss: 2.382906514664416

Epoch: 5| Step: 10
Training loss: 2.269153346838531
Validation loss: 2.352351327708322

Epoch: 184| Step: 0
Training loss: 2.279252314193269
Validation loss: 2.384261628710268

Epoch: 5| Step: 1
Training loss: 2.1218075051900467
Validation loss: 2.3678589138788686

Epoch: 5| Step: 2
Training loss: 2.061881695170198
Validation loss: 2.380785145548353

Epoch: 5| Step: 3
Training loss: 2.2823445032974705
Validation loss: 2.406807845332861

Epoch: 5| Step: 4
Training loss: 2.449184192371084
Validation loss: 2.3627615896734993

Epoch: 5| Step: 5
Training loss: 2.1312543046745613
Validation loss: 2.3692701820474693

Epoch: 5| Step: 6
Training loss: 1.8121493427846418
Validation loss: 2.370766258757921

Epoch: 5| Step: 7
Training loss: 2.1599467557066756
Validation loss: 2.3601524106126264

Epoch: 5| Step: 8
Training loss: 2.03891750711746
Validation loss: 2.373932547281801

Epoch: 5| Step: 9
Training loss: 2.238630284229398
Validation loss: 2.3494198249865974

Epoch: 5| Step: 10
Training loss: 2.522081229133764
Validation loss: 2.373118323867558

Epoch: 185| Step: 0
Training loss: 1.5098121310198602
Validation loss: 2.3668541278397175

Epoch: 5| Step: 1
Training loss: 2.2011815149592038
Validation loss: 2.3665722925081187

Epoch: 5| Step: 2
Training loss: 2.811450253720362
Validation loss: 2.3705604143827963

Epoch: 5| Step: 3
Training loss: 1.9559513851318353
Validation loss: 2.3787644802371384

Epoch: 5| Step: 4
Training loss: 1.9752693016809653
Validation loss: 2.3749467587939463

Epoch: 5| Step: 5
Training loss: 2.782376350609871
Validation loss: 2.367644784141661

Epoch: 5| Step: 6
Training loss: 2.122720280911079
Validation loss: 2.3628827169773476

Epoch: 5| Step: 7
Training loss: 1.5830792758632155
Validation loss: 2.3823739070288372

Epoch: 5| Step: 8
Training loss: 2.395938130173775
Validation loss: 2.3777738099408037

Epoch: 5| Step: 9
Training loss: 2.5731647284356916
Validation loss: 2.387901058291553

Epoch: 5| Step: 10
Training loss: 1.7911541967334443
Validation loss: 2.339745687072992

Epoch: 186| Step: 0
Training loss: 2.0044940287233945
Validation loss: 2.363910883996984

Epoch: 5| Step: 1
Training loss: 2.4630184034557514
Validation loss: 2.3476507572335517

Epoch: 5| Step: 2
Training loss: 2.6487101636756045
Validation loss: 2.3858298028883533

Epoch: 5| Step: 3
Training loss: 2.182036197491482
Validation loss: 2.375588523859959

Epoch: 5| Step: 4
Training loss: 2.5469793754674175
Validation loss: 2.3702093413282967

Epoch: 5| Step: 5
Training loss: 1.786381007116018
Validation loss: 2.3597279869781627

Epoch: 5| Step: 6
Training loss: 2.5579766148026923
Validation loss: 2.3827488280661546

Epoch: 5| Step: 7
Training loss: 1.8471899109438898
Validation loss: 2.3857871163492663

Epoch: 5| Step: 8
Training loss: 1.5225871525015868
Validation loss: 2.3577596949109156

Epoch: 5| Step: 9
Training loss: 1.6832811813333233
Validation loss: 2.3568107743460223

Epoch: 5| Step: 10
Training loss: 2.290758981988723
Validation loss: 2.380414433129206

Epoch: 187| Step: 0
Training loss: 1.8136622550030583
Validation loss: 2.3519524561074445

Epoch: 5| Step: 1
Training loss: 1.9742828612339494
Validation loss: 2.3492423672703335

Epoch: 5| Step: 2
Training loss: 2.3054402819187603
Validation loss: 2.367597863530438

Epoch: 5| Step: 3
Training loss: 2.3325320525588924
Validation loss: 2.3748603578974783

Epoch: 5| Step: 4
Training loss: 1.9656793777876813
Validation loss: 2.364961634450503

Epoch: 5| Step: 5
Training loss: 2.4184648685801995
Validation loss: 2.3336752536277166

Epoch: 5| Step: 6
Training loss: 2.138416236683648
Validation loss: 2.365500105765456

Epoch: 5| Step: 7
Training loss: 2.5210866459290404
Validation loss: 2.3914342019155135

Epoch: 5| Step: 8
Training loss: 2.5072686387005536
Validation loss: 2.397013509377144

Epoch: 5| Step: 9
Training loss: 1.7743306200712734
Validation loss: 2.375003912921957

Epoch: 5| Step: 10
Training loss: 2.121131292471049
Validation loss: 2.3838682356501586

Epoch: 188| Step: 0
Training loss: 2.264627381720788
Validation loss: 2.3495407797551815

Epoch: 5| Step: 1
Training loss: 1.6653820411735425
Validation loss: 2.3595302655383223

Epoch: 5| Step: 2
Training loss: 1.9927902207513262
Validation loss: 2.3554429030547395

Epoch: 5| Step: 3
Training loss: 1.5268512526924523
Validation loss: 2.3600119518952787

Epoch: 5| Step: 4
Training loss: 2.5086837633604477
Validation loss: 2.406868784618698

Epoch: 5| Step: 5
Training loss: 2.4804731714404493
Validation loss: 2.35872092630943

Epoch: 5| Step: 6
Training loss: 2.432847497941905
Validation loss: 2.3631788163277587

Epoch: 5| Step: 7
Training loss: 1.742129269298187
Validation loss: 2.388774576319407

Epoch: 5| Step: 8
Training loss: 1.943371275285486
Validation loss: 2.3658945402637377

Epoch: 5| Step: 9
Training loss: 2.7632559419507845
Validation loss: 2.3819499245401423

Epoch: 5| Step: 10
Training loss: 2.2813342353214074
Validation loss: 2.361027442693106

Epoch: 189| Step: 0
Training loss: 2.080459889225815
Validation loss: 2.3561623561436744

Epoch: 5| Step: 1
Training loss: 2.174166232375012
Validation loss: 2.3873803923607784

Epoch: 5| Step: 2
Training loss: 1.977861060783325
Validation loss: 2.3596567209706834

Epoch: 5| Step: 3
Training loss: 2.8711530406824397
Validation loss: 2.349163321416018

Epoch: 5| Step: 4
Training loss: 2.336832136733877
Validation loss: 2.3656572147015558

Epoch: 5| Step: 5
Training loss: 2.037986617691083
Validation loss: 2.3543288116705514

Epoch: 5| Step: 6
Training loss: 1.6064376691734963
Validation loss: 2.343379163493302

Epoch: 5| Step: 7
Training loss: 2.2435296590675424
Validation loss: 2.368535993078141

Epoch: 5| Step: 8
Training loss: 1.52969951371647
Validation loss: 2.3494271582523765

Epoch: 5| Step: 9
Training loss: 2.226050495373562
Validation loss: 2.353566448139649

Epoch: 5| Step: 10
Training loss: 2.656200632870753
Validation loss: 2.362441387079895

Epoch: 190| Step: 0
Training loss: 2.1488076740755595
Validation loss: 2.3538138894538765

Epoch: 5| Step: 1
Training loss: 2.6111778381515136
Validation loss: 2.3663079768013104

Epoch: 5| Step: 2
Training loss: 1.6466574074540197
Validation loss: 2.3570655712332385

Epoch: 5| Step: 3
Training loss: 2.43194475225387
Validation loss: 2.374609684673936

Epoch: 5| Step: 4
Training loss: 2.499066464648883
Validation loss: 2.3686676330990895

Epoch: 5| Step: 5
Training loss: 1.7676997190350616
Validation loss: 2.3739950172674806

Epoch: 5| Step: 6
Training loss: 1.8248608131110695
Validation loss: 2.3495128691797613

Epoch: 5| Step: 7
Training loss: 2.3369777238769247
Validation loss: 2.3992717489580926

Epoch: 5| Step: 8
Training loss: 1.9961660114503943
Validation loss: 2.348450709378612

Epoch: 5| Step: 9
Training loss: 2.0400010795216414
Validation loss: 2.3525326864606284

Epoch: 5| Step: 10
Training loss: 2.3030504522590545
Validation loss: 2.378452513899315

Epoch: 191| Step: 0
Training loss: 2.3362716384791833
Validation loss: 2.3995371676482447

Epoch: 5| Step: 1
Training loss: 1.411253357064754
Validation loss: 2.356197409838407

Epoch: 5| Step: 2
Training loss: 2.421872046684187
Validation loss: 2.376886350530142

Epoch: 5| Step: 3
Training loss: 2.1534770882554364
Validation loss: 2.391467128466441

Epoch: 5| Step: 4
Training loss: 2.356123648172416
Validation loss: 2.3721514697640225

Epoch: 5| Step: 5
Training loss: 2.3661379863909224
Validation loss: 2.373128733996943

Epoch: 5| Step: 6
Training loss: 2.1565941798524557
Validation loss: 2.3916030835748154

Epoch: 5| Step: 7
Training loss: 2.2559407537404894
Validation loss: 2.3810101171091334

Epoch: 5| Step: 8
Training loss: 2.0602055126747834
Validation loss: 2.374199373390853

Epoch: 5| Step: 9
Training loss: 1.8201361312887367
Validation loss: 2.3560738181356307

Epoch: 5| Step: 10
Training loss: 2.1693333085960256
Validation loss: 2.3787095719552793

Epoch: 192| Step: 0
Training loss: 2.4416671735569904
Validation loss: 2.3848820228829735

Epoch: 5| Step: 1
Training loss: 2.856693866055716
Validation loss: 2.3696251321284674

Epoch: 5| Step: 2
Training loss: 1.799726926434982
Validation loss: 2.3741017269046125

Epoch: 5| Step: 3
Training loss: 1.9761700146272931
Validation loss: 2.358890370942205

Epoch: 5| Step: 4
Training loss: 2.3542492494755107
Validation loss: 2.382538471573071

Epoch: 5| Step: 5
Training loss: 1.8847538606741008
Validation loss: 2.3645247751711427

Epoch: 5| Step: 6
Training loss: 1.8406250544031522
Validation loss: 2.3340063351410576

Epoch: 5| Step: 7
Training loss: 2.0346766985016407
Validation loss: 2.3448264042278635

Epoch: 5| Step: 8
Training loss: 2.284678143427467
Validation loss: 2.3360383626598993

Epoch: 5| Step: 9
Training loss: 2.454400769538709
Validation loss: 2.3642847352283867

Epoch: 5| Step: 10
Training loss: 1.3698245529269037
Validation loss: 2.343993829328887

Epoch: 193| Step: 0
Training loss: 2.3349816653657034
Validation loss: 2.345279370180688

Epoch: 5| Step: 1
Training loss: 2.1949815602494716
Validation loss: 2.3464441654460853

Epoch: 5| Step: 2
Training loss: 1.9941876711325701
Validation loss: 2.3555602209625173

Epoch: 5| Step: 3
Training loss: 1.8751654234074449
Validation loss: 2.375760985209242

Epoch: 5| Step: 4
Training loss: 1.7835045984806188
Validation loss: 2.390412935356012

Epoch: 5| Step: 5
Training loss: 2.273964417735295
Validation loss: 2.3806268866087392

Epoch: 5| Step: 6
Training loss: 1.694023943492024
Validation loss: 2.3934614167086257

Epoch: 5| Step: 7
Training loss: 2.102842373725756
Validation loss: 2.3411277600476534

Epoch: 5| Step: 8
Training loss: 1.9532429773938529
Validation loss: 2.3606964313793912

Epoch: 5| Step: 9
Training loss: 2.233843440069154
Validation loss: 2.3699836289904064

Epoch: 5| Step: 10
Training loss: 3.0959146036302734
Validation loss: 2.3265430179189805

Epoch: 194| Step: 0
Training loss: 2.3379042903083285
Validation loss: 2.3500640775313553

Epoch: 5| Step: 1
Training loss: 1.7325447666830405
Validation loss: 2.3616206774009005

Epoch: 5| Step: 2
Training loss: 2.0274934511278833
Validation loss: 2.352617393419657

Epoch: 5| Step: 3
Training loss: 2.234379908416265
Validation loss: 2.387777330144242

Epoch: 5| Step: 4
Training loss: 2.308707245749432
Validation loss: 2.3846567592057206

Epoch: 5| Step: 5
Training loss: 2.7027738486410944
Validation loss: 2.381463766909632

Epoch: 5| Step: 6
Training loss: 2.227578878151396
Validation loss: 2.361212108831809

Epoch: 5| Step: 7
Training loss: 1.7975076639704406
Validation loss: 2.374072635943143

Epoch: 5| Step: 8
Training loss: 2.053306666774904
Validation loss: 2.359043028713972

Epoch: 5| Step: 9
Training loss: 1.7337905998949406
Validation loss: 2.3907717625474647

Epoch: 5| Step: 10
Training loss: 2.3188704302583747
Validation loss: 2.3679606936392803

Epoch: 195| Step: 0
Training loss: 2.2776081854273538
Validation loss: 2.366414441567363

Epoch: 5| Step: 1
Training loss: 1.8888764926403905
Validation loss: 2.37244548731912

Epoch: 5| Step: 2
Training loss: 2.2940049697569385
Validation loss: 2.405247657316669

Epoch: 5| Step: 3
Training loss: 2.259124796878179
Validation loss: 2.3955678781166756

Epoch: 5| Step: 4
Training loss: 1.997124333105712
Validation loss: 2.3927478119859193

Epoch: 5| Step: 5
Training loss: 1.914296972743928
Validation loss: 2.4102430130066423

Epoch: 5| Step: 6
Training loss: 1.6013154374270586
Validation loss: 2.3862809362252784

Epoch: 5| Step: 7
Training loss: 2.33507978838048
Validation loss: 2.373277362200594

Epoch: 5| Step: 8
Training loss: 2.3097346499408125
Validation loss: 2.3912200004985356

Epoch: 5| Step: 9
Training loss: 2.122337580780497
Validation loss: 2.3887536627161525

Epoch: 5| Step: 10
Training loss: 2.3716913566814344
Validation loss: 2.3418030684396918

Epoch: 196| Step: 0
Training loss: 1.7011440550744408
Validation loss: 2.3622038014088114

Epoch: 5| Step: 1
Training loss: 1.8386200481993622
Validation loss: 2.369061169592458

Epoch: 5| Step: 2
Training loss: 2.4200955652646092
Validation loss: 2.337505283495609

Epoch: 5| Step: 3
Training loss: 2.6609242320779942
Validation loss: 2.3480465322126896

Epoch: 5| Step: 4
Training loss: 2.153519158902755
Validation loss: 2.3970507613462173

Epoch: 5| Step: 5
Training loss: 1.8709185364939152
Validation loss: 2.338396405842815

Epoch: 5| Step: 6
Training loss: 2.1483378439245033
Validation loss: 2.328128464250175

Epoch: 5| Step: 7
Training loss: 2.0373890758814324
Validation loss: 2.3517415464309597

Epoch: 5| Step: 8
Training loss: 1.6631796200630706
Validation loss: 2.3705086340301484

Epoch: 5| Step: 9
Training loss: 2.6502419235355443
Validation loss: 2.3366024009254183

Epoch: 5| Step: 10
Training loss: 2.096838424067994
Validation loss: 2.3345687674871973

Epoch: 197| Step: 0
Training loss: 2.184963826942869
Validation loss: 2.355757280957138

Epoch: 5| Step: 1
Training loss: 2.3256664223430485
Validation loss: 2.3568589109692635

Epoch: 5| Step: 2
Training loss: 2.2845547919746156
Validation loss: 2.364136002000094

Epoch: 5| Step: 3
Training loss: 2.015225393027934
Validation loss: 2.371265424150776

Epoch: 5| Step: 4
Training loss: 2.0528865217015495
Validation loss: 2.346208145529033

Epoch: 5| Step: 5
Training loss: 2.539467647213466
Validation loss: 2.366352109472165

Epoch: 5| Step: 6
Training loss: 2.0851555548073963
Validation loss: 2.3607791448502673

Epoch: 5| Step: 7
Training loss: 1.9599769336939104
Validation loss: 2.36991704973984

Epoch: 5| Step: 8
Training loss: 2.473058972097891
Validation loss: 2.3841633830369195

Epoch: 5| Step: 9
Training loss: 1.5273425011983386
Validation loss: 2.3538050096517726

Epoch: 5| Step: 10
Training loss: 1.5939397511936204
Validation loss: 2.377410074941008

Epoch: 198| Step: 0
Training loss: 2.594237500073405
Validation loss: 2.3788226639795496

Epoch: 5| Step: 1
Training loss: 1.793291781711057
Validation loss: 2.386668185978732

Epoch: 5| Step: 2
Training loss: 2.225860056581634
Validation loss: 2.386016588279425

Epoch: 5| Step: 3
Training loss: 1.7945946861151856
Validation loss: 2.3959539622951715

Epoch: 5| Step: 4
Training loss: 1.7493181262595867
Validation loss: 2.399011704938698

Epoch: 5| Step: 5
Training loss: 2.5173495050506225
Validation loss: 2.353192241994452

Epoch: 5| Step: 6
Training loss: 2.1861852782207705
Validation loss: 2.3654165526930084

Epoch: 5| Step: 7
Training loss: 1.7782271317312495
Validation loss: 2.355071318058832

Epoch: 5| Step: 8
Training loss: 2.1980722260830925
Validation loss: 2.382439807812874

Epoch: 5| Step: 9
Training loss: 1.8951196130530443
Validation loss: 2.3253579536660136

Epoch: 5| Step: 10
Training loss: 2.46475330797448
Validation loss: 2.3748088326882724

Epoch: 199| Step: 0
Training loss: 2.2339504879047047
Validation loss: 2.348000964725567

Epoch: 5| Step: 1
Training loss: 2.274755665999392
Validation loss: 2.3572161350633727

Epoch: 5| Step: 2
Training loss: 1.8038937362957175
Validation loss: 2.390133279482469

Epoch: 5| Step: 3
Training loss: 2.250119841880856
Validation loss: 2.385335736465342

Epoch: 5| Step: 4
Training loss: 2.473884940146271
Validation loss: 2.3724271409928352

Epoch: 5| Step: 5
Training loss: 2.4976141035039765
Validation loss: 2.389471020193048

Epoch: 5| Step: 6
Training loss: 1.9526675489681322
Validation loss: 2.381095605250937

Epoch: 5| Step: 7
Training loss: 1.8292813678599809
Validation loss: 2.345554902150737

Epoch: 5| Step: 8
Training loss: 1.7672054003172355
Validation loss: 2.3696133158489836

Epoch: 5| Step: 9
Training loss: 2.027191920833551
Validation loss: 2.349139950030785

Epoch: 5| Step: 10
Training loss: 1.8785891195870141
Validation loss: 2.365212478266044

Epoch: 200| Step: 0
Training loss: 2.400594927642378
Validation loss: 2.3545419954802838

Epoch: 5| Step: 1
Training loss: 2.3183254377649796
Validation loss: 2.366873569087171

Epoch: 5| Step: 2
Training loss: 1.4409135839743943
Validation loss: 2.3637442441472745

Epoch: 5| Step: 3
Training loss: 2.5454631238644203
Validation loss: 2.3847806299057406

Epoch: 5| Step: 4
Training loss: 1.985682920020025
Validation loss: 2.374140443030731

Epoch: 5| Step: 5
Training loss: 2.164380983129037
Validation loss: 2.3525647691729046

Epoch: 5| Step: 6
Training loss: 1.932321334021606
Validation loss: 2.3526937581615193

Epoch: 5| Step: 7
Training loss: 2.2728669279712848
Validation loss: 2.3340040472012262

Epoch: 5| Step: 8
Training loss: 2.3761275776928334
Validation loss: 2.3607260281640374

Epoch: 5| Step: 9
Training loss: 1.419438716746646
Validation loss: 2.3795536990263653

Epoch: 5| Step: 10
Training loss: 1.9865795115207123
Validation loss: 2.338556610051638

Epoch: 201| Step: 0
Training loss: 2.941548905073227
Validation loss: 2.3653247117877356

Epoch: 5| Step: 1
Training loss: 1.8966554668656759
Validation loss: 2.382729751976438

Epoch: 5| Step: 2
Training loss: 2.2322458646712278
Validation loss: 2.3629837606883517

Epoch: 5| Step: 3
Training loss: 1.9028584060231077
Validation loss: 2.3468660408105606

Epoch: 5| Step: 4
Training loss: 1.824998056071043
Validation loss: 2.3617355478458775

Epoch: 5| Step: 5
Training loss: 1.90178181771302
Validation loss: 2.3518293798441015

Epoch: 5| Step: 6
Training loss: 2.2623306000239953
Validation loss: 2.3644074824594528

Epoch: 5| Step: 7
Training loss: 2.1600261186857304
Validation loss: 2.369285731966154

Epoch: 5| Step: 8
Training loss: 1.7686824152135454
Validation loss: 2.3463962319847123

Epoch: 5| Step: 9
Training loss: 2.3948094267073907
Validation loss: 2.390055504486174

Epoch: 5| Step: 10
Training loss: 1.7192098522571415
Validation loss: 2.344276530964581

Epoch: 202| Step: 0
Training loss: 2.1229855582078008
Validation loss: 2.3709005403583396

Epoch: 5| Step: 1
Training loss: 1.48195169302683
Validation loss: 2.362841777708794

Epoch: 5| Step: 2
Training loss: 2.0157379591879208
Validation loss: 2.3856579872156893

Epoch: 5| Step: 3
Training loss: 2.051123250872798
Validation loss: 2.4007163223869994

Epoch: 5| Step: 4
Training loss: 2.6633512828478274
Validation loss: 2.3337032662844686

Epoch: 5| Step: 5
Training loss: 2.006706437807748
Validation loss: 2.3664898454344065

Epoch: 5| Step: 6
Training loss: 1.966628975695633
Validation loss: 2.374453272818902

Epoch: 5| Step: 7
Training loss: 2.3759970328957882
Validation loss: 2.374291667867164

Epoch: 5| Step: 8
Training loss: 2.149423823665932
Validation loss: 2.360257790982786

Epoch: 5| Step: 9
Training loss: 1.6009908260628258
Validation loss: 2.364128104931527

Epoch: 5| Step: 10
Training loss: 2.341259154115002
Validation loss: 2.3886749316123104

Epoch: 203| Step: 0
Training loss: 2.104086455777188
Validation loss: 2.3608161096143054

Epoch: 5| Step: 1
Training loss: 2.4239357333460987
Validation loss: 2.3426373247672965

Epoch: 5| Step: 2
Training loss: 2.104218800216791
Validation loss: 2.3561168019908387

Epoch: 5| Step: 3
Training loss: 2.0685227053149706
Validation loss: 2.3388951631836856

Epoch: 5| Step: 4
Training loss: 1.7860722101357873
Validation loss: 2.3209578502365313

Epoch: 5| Step: 5
Training loss: 1.7207966496557787
Validation loss: 2.3302254158151636

Epoch: 5| Step: 6
Training loss: 2.088899374094591
Validation loss: 2.3554200989958773

Epoch: 5| Step: 7
Training loss: 2.1068624720940754
Validation loss: 2.354471724493197

Epoch: 5| Step: 8
Training loss: 2.3537158928343302
Validation loss: 2.3608679972195388

Epoch: 5| Step: 9
Training loss: 2.236108600886208
Validation loss: 2.3670867667811994

Epoch: 5| Step: 10
Training loss: 2.100761970156335
Validation loss: 2.364271023965377

Epoch: 204| Step: 0
Training loss: 2.1356600242826214
Validation loss: 2.3725793934825035

Epoch: 5| Step: 1
Training loss: 1.9956230907628179
Validation loss: 2.359230637420695

Epoch: 5| Step: 2
Training loss: 2.1986798834016956
Validation loss: 2.3857175539911317

Epoch: 5| Step: 3
Training loss: 2.586712124792133
Validation loss: 2.392581674867415

Epoch: 5| Step: 4
Training loss: 2.0819569300686527
Validation loss: 2.3709043529980764

Epoch: 5| Step: 5
Training loss: 2.0139149353564583
Validation loss: 2.392643282925787

Epoch: 5| Step: 6
Training loss: 2.0586574479441873
Validation loss: 2.3942796617507955

Epoch: 5| Step: 7
Training loss: 2.3223169576170566
Validation loss: 2.381738280109044

Epoch: 5| Step: 8
Training loss: 2.0789626878304857
Validation loss: 2.3896609700428217

Epoch: 5| Step: 9
Training loss: 1.661959972009742
Validation loss: 2.3933320176965918

Epoch: 5| Step: 10
Training loss: 1.6587249689577965
Validation loss: 2.3625828651349288

Epoch: 205| Step: 0
Training loss: 1.6990500180008896
Validation loss: 2.3595330062447424

Epoch: 5| Step: 1
Training loss: 2.248170956949752
Validation loss: 2.394948206433634

Epoch: 5| Step: 2
Training loss: 1.4924450397435993
Validation loss: 2.3556982277005853

Epoch: 5| Step: 3
Training loss: 2.018520198060457
Validation loss: 2.3391079386391

Epoch: 5| Step: 4
Training loss: 1.8979645442123085
Validation loss: 2.3762398210842948

Epoch: 5| Step: 5
Training loss: 2.1564837342888636
Validation loss: 2.357568636245581

Epoch: 5| Step: 6
Training loss: 2.111406153702393
Validation loss: 2.3234332695829174

Epoch: 5| Step: 7
Training loss: 2.2795142271983106
Validation loss: 2.3510115938924265

Epoch: 5| Step: 8
Training loss: 2.7276941262872625
Validation loss: 2.3529925070386817

Epoch: 5| Step: 9
Training loss: 2.005845111621634
Validation loss: 2.3700138918644877

Epoch: 5| Step: 10
Training loss: 2.068978279173066
Validation loss: 2.3189347307028596

Epoch: 206| Step: 0
Training loss: 1.5325302688571534
Validation loss: 2.3484844383383976

Epoch: 5| Step: 1
Training loss: 2.63815661749638
Validation loss: 2.334984292704787

Epoch: 5| Step: 2
Training loss: 2.2441803585880877
Validation loss: 2.3760141076087287

Epoch: 5| Step: 3
Training loss: 1.654754539334828
Validation loss: 2.3542855762968107

Epoch: 5| Step: 4
Training loss: 1.915792251927428
Validation loss: 2.3650988768980707

Epoch: 5| Step: 5
Training loss: 1.9757295444129026
Validation loss: 2.368768512297314

Epoch: 5| Step: 6
Training loss: 2.3464224265976763
Validation loss: 2.340301382911122

Epoch: 5| Step: 7
Training loss: 2.07145653550764
Validation loss: 2.3692822954331714

Epoch: 5| Step: 8
Training loss: 1.9352918162350106
Validation loss: 2.3703067068856756

Epoch: 5| Step: 9
Training loss: 2.074296795369935
Validation loss: 2.3650986579408686

Epoch: 5| Step: 10
Training loss: 2.287313997804946
Validation loss: 2.3660702620165286

Epoch: 207| Step: 0
Training loss: 2.383514200919283
Validation loss: 2.3755375642886056

Epoch: 5| Step: 1
Training loss: 2.439002136617415
Validation loss: 2.37397837294795

Epoch: 5| Step: 2
Training loss: 2.0553659689596455
Validation loss: 2.347789648752548

Epoch: 5| Step: 3
Training loss: 2.5462303984107115
Validation loss: 2.3744298102599486

Epoch: 5| Step: 4
Training loss: 1.783381608802773
Validation loss: 2.3866140041423582

Epoch: 5| Step: 5
Training loss: 1.4758668905988335
Validation loss: 2.3985870871566637

Epoch: 5| Step: 6
Training loss: 1.7589564691202593
Validation loss: 2.3660953276070447

Epoch: 5| Step: 7
Training loss: 2.054055932744118
Validation loss: 2.368233521803113

Epoch: 5| Step: 8
Training loss: 1.5414784634471816
Validation loss: 2.395961675287185

Epoch: 5| Step: 9
Training loss: 2.534660584790463
Validation loss: 2.36198263155305

Epoch: 5| Step: 10
Training loss: 1.9655551115629362
Validation loss: 2.3383544167960415

Epoch: 208| Step: 0
Training loss: 1.7412366111005109
Validation loss: 2.361465128088071

Epoch: 5| Step: 1
Training loss: 2.193196101238731
Validation loss: 2.334265286221036

Epoch: 5| Step: 2
Training loss: 2.240857836597751
Validation loss: 2.3270151152451235

Epoch: 5| Step: 3
Training loss: 2.1387194763181467
Validation loss: 2.37453544339169

Epoch: 5| Step: 4
Training loss: 1.7617571841359103
Validation loss: 2.3610537258013413

Epoch: 5| Step: 5
Training loss: 2.3190713253657784
Validation loss: 2.3567491226587736

Epoch: 5| Step: 6
Training loss: 2.511510481438703
Validation loss: 2.366987555879423

Epoch: 5| Step: 7
Training loss: 1.8564087103095415
Validation loss: 2.3440727930412115

Epoch: 5| Step: 8
Training loss: 1.966777115753836
Validation loss: 2.3696388448674974

Epoch: 5| Step: 9
Training loss: 2.1870199494186773
Validation loss: 2.3578483120473557

Epoch: 5| Step: 10
Training loss: 1.70518753731952
Validation loss: 2.3604632467998585

Epoch: 209| Step: 0
Training loss: 1.967841529141378
Validation loss: 2.361433044706669

Epoch: 5| Step: 1
Training loss: 1.7453181445133799
Validation loss: 2.3250138573570442

Epoch: 5| Step: 2
Training loss: 1.9062930242967429
Validation loss: 2.3535161838012573

Epoch: 5| Step: 3
Training loss: 1.8938722073746717
Validation loss: 2.3209996961709263

Epoch: 5| Step: 4
Training loss: 2.148640571013626
Validation loss: 2.3312529754817626

Epoch: 5| Step: 5
Training loss: 2.3441216746312623
Validation loss: 2.3383751299298856

Epoch: 5| Step: 6
Training loss: 1.6728543416816888
Validation loss: 2.319373652291336

Epoch: 5| Step: 7
Training loss: 1.6827939428299796
Validation loss: 2.3495490684650027

Epoch: 5| Step: 8
Training loss: 2.3224793665434404
Validation loss: 2.347695557303096

Epoch: 5| Step: 9
Training loss: 2.1607091378935435
Validation loss: 2.3313255127817416

Epoch: 5| Step: 10
Training loss: 2.7943989966378977
Validation loss: 2.3455091359699147

Epoch: 210| Step: 0
Training loss: 1.9887204387776731
Validation loss: 2.342811421698948

Epoch: 5| Step: 1
Training loss: 2.10863849356387
Validation loss: 2.3365864387518083

Epoch: 5| Step: 2
Training loss: 2.112605580958794
Validation loss: 2.3638368579062785

Epoch: 5| Step: 3
Training loss: 1.8633276335822992
Validation loss: 2.336795980710205

Epoch: 5| Step: 4
Training loss: 2.156017125035148
Validation loss: 2.3456783868687534

Epoch: 5| Step: 5
Training loss: 2.5052212551574122
Validation loss: 2.380602648153944

Epoch: 5| Step: 6
Training loss: 2.230838137101236
Validation loss: 2.370148586551258

Epoch: 5| Step: 7
Training loss: 1.4251631559696676
Validation loss: 2.332053268107986

Epoch: 5| Step: 8
Training loss: 1.9139505158966428
Validation loss: 2.3706689293771563

Epoch: 5| Step: 9
Training loss: 2.113701572325911
Validation loss: 2.3497168189461326

Epoch: 5| Step: 10
Training loss: 1.826503262566786
Validation loss: 2.379987488907045

Epoch: 211| Step: 0
Training loss: 1.1992943954218491
Validation loss: 2.334382036502734

Epoch: 5| Step: 1
Training loss: 2.6227634529610153
Validation loss: 2.3375170789279713

Epoch: 5| Step: 2
Training loss: 2.1753003669381767
Validation loss: 2.3665470228957894

Epoch: 5| Step: 3
Training loss: 1.7428439148193189
Validation loss: 2.3457558042735287

Epoch: 5| Step: 4
Training loss: 2.0947324810522447
Validation loss: 2.356851407209495

Epoch: 5| Step: 5
Training loss: 1.748677298811773
Validation loss: 2.333406133731939

Epoch: 5| Step: 6
Training loss: 2.080213830667133
Validation loss: 2.339133036692348

Epoch: 5| Step: 7
Training loss: 2.113060677064735
Validation loss: 2.339647460058076

Epoch: 5| Step: 8
Training loss: 1.8890330650743554
Validation loss: 2.358948761777581

Epoch: 5| Step: 9
Training loss: 2.470890710517224
Validation loss: 2.3289591507616403

Epoch: 5| Step: 10
Training loss: 2.102014088947326
Validation loss: 2.3789533365992948

Epoch: 212| Step: 0
Training loss: 1.9544867079295751
Validation loss: 2.3498309108423032

Epoch: 5| Step: 1
Training loss: 2.065171909704391
Validation loss: 2.364230921995363

Epoch: 5| Step: 2
Training loss: 2.2316670046809164
Validation loss: 2.356027723651614

Epoch: 5| Step: 3
Training loss: 2.1104353888516885
Validation loss: 2.350956300224485

Epoch: 5| Step: 4
Training loss: 1.9593198874965023
Validation loss: 2.3638197646428365

Epoch: 5| Step: 5
Training loss: 1.65176807232129
Validation loss: 2.349534316472517

Epoch: 5| Step: 6
Training loss: 2.164688625718137
Validation loss: 2.3332807118185213

Epoch: 5| Step: 7
Training loss: 1.9820250767065495
Validation loss: 2.3551806386929495

Epoch: 5| Step: 8
Training loss: 1.9685502934967456
Validation loss: 2.3327347922380595

Epoch: 5| Step: 9
Training loss: 1.8952380562775666
Validation loss: 2.3630393338098905

Epoch: 5| Step: 10
Training loss: 2.5772600052228887
Validation loss: 2.367537422894918

Epoch: 213| Step: 0
Training loss: 2.1536158075665077
Validation loss: 2.3553485007397907

Epoch: 5| Step: 1
Training loss: 1.9980672796108039
Validation loss: 2.3846335324979537

Epoch: 5| Step: 2
Training loss: 2.1822817004817616
Validation loss: 2.3697235591656876

Epoch: 5| Step: 3
Training loss: 1.6368979126097487
Validation loss: 2.3598638141052715

Epoch: 5| Step: 4
Training loss: 2.3501044026984768
Validation loss: 2.34720230320618

Epoch: 5| Step: 5
Training loss: 2.1079499128496884
Validation loss: 2.3519020962335655

Epoch: 5| Step: 6
Training loss: 1.7655010348662414
Validation loss: 2.38014913635104

Epoch: 5| Step: 7
Training loss: 1.8578708880130743
Validation loss: 2.347062308137841

Epoch: 5| Step: 8
Training loss: 2.4632445163570913
Validation loss: 2.3456581633755924

Epoch: 5| Step: 9
Training loss: 2.213221795400815
Validation loss: 2.4127592280447003

Epoch: 5| Step: 10
Training loss: 1.3058730352647485
Validation loss: 2.4072532980636323

Epoch: 214| Step: 0
Training loss: 2.1654866624384863
Validation loss: 2.3929447193073474

Epoch: 5| Step: 1
Training loss: 1.891330051581075
Validation loss: 2.379736495550353

Epoch: 5| Step: 2
Training loss: 1.8598107220110205
Validation loss: 2.3663813971811996

Epoch: 5| Step: 3
Training loss: 2.2087701209576127
Validation loss: 2.379915536927864

Epoch: 5| Step: 4
Training loss: 1.7527780281277636
Validation loss: 2.351860367932132

Epoch: 5| Step: 5
Training loss: 2.322901248167953
Validation loss: 2.3293272004458503

Epoch: 5| Step: 6
Training loss: 1.5683985191011334
Validation loss: 2.3809862292574837

Epoch: 5| Step: 7
Training loss: 2.1804330295984147
Validation loss: 2.3570281463045406

Epoch: 5| Step: 8
Training loss: 1.7711323953054552
Validation loss: 2.3515496434007557

Epoch: 5| Step: 9
Training loss: 2.428897937896631
Validation loss: 2.355755032642287

Epoch: 5| Step: 10
Training loss: 2.013292130665507
Validation loss: 2.353011710356798

Epoch: 215| Step: 0
Training loss: 2.115195262543802
Validation loss: 2.356702482249536

Epoch: 5| Step: 1
Training loss: 1.6169650159742237
Validation loss: 2.3768911048662575

Epoch: 5| Step: 2
Training loss: 2.6951607924073717
Validation loss: 2.376830017178972

Epoch: 5| Step: 3
Training loss: 2.242036076659555
Validation loss: 2.340563421826139

Epoch: 5| Step: 4
Training loss: 1.9439112507455547
Validation loss: 2.344512323258283

Epoch: 5| Step: 5
Training loss: 2.0472005337734203
Validation loss: 2.328308012384944

Epoch: 5| Step: 6
Training loss: 1.736144529232949
Validation loss: 2.379391684128876

Epoch: 5| Step: 7
Training loss: 2.243499478351353
Validation loss: 2.327347439420006

Epoch: 5| Step: 8
Training loss: 1.7935151242122822
Validation loss: 2.362529764043808

Epoch: 5| Step: 9
Training loss: 1.9759007729624243
Validation loss: 2.3646113694121618

Epoch: 5| Step: 10
Training loss: 1.6335838722576186
Validation loss: 2.36858040028255

Epoch: 216| Step: 0
Training loss: 2.381375238924864
Validation loss: 2.376116478864194

Epoch: 5| Step: 1
Training loss: 2.2006092181692116
Validation loss: 2.3838687217363574

Epoch: 5| Step: 2
Training loss: 2.141652995064684
Validation loss: 2.380251777815928

Epoch: 5| Step: 3
Training loss: 1.6973465350392551
Validation loss: 2.3768768450651065

Epoch: 5| Step: 4
Training loss: 2.1903302003850356
Validation loss: 2.4095663106315763

Epoch: 5| Step: 5
Training loss: 1.870248113685557
Validation loss: 2.4030189785101395

Epoch: 5| Step: 6
Training loss: 1.7290500310451338
Validation loss: 2.4019377451975514

Epoch: 5| Step: 7
Training loss: 1.5716180640695412
Validation loss: 2.4059698524822735

Epoch: 5| Step: 8
Training loss: 2.0320611361220164
Validation loss: 2.3768632280130486

Epoch: 5| Step: 9
Training loss: 2.3116969183290257
Validation loss: 2.4046610399007515

Epoch: 5| Step: 10
Training loss: 1.9321155176477303
Validation loss: 2.4073475940798446

Epoch: 217| Step: 0
Training loss: 1.349362650289558
Validation loss: 2.3793475142580465

Epoch: 5| Step: 1
Training loss: 1.7310396032182962
Validation loss: 2.3465131997314668

Epoch: 5| Step: 2
Training loss: 2.107609780236439
Validation loss: 2.342016615774897

Epoch: 5| Step: 3
Training loss: 1.5341123958328788
Validation loss: 2.3837510741556667

Epoch: 5| Step: 4
Training loss: 1.797271618400916
Validation loss: 2.3367267059745758

Epoch: 5| Step: 5
Training loss: 2.042450760769634
Validation loss: 2.354485109008548

Epoch: 5| Step: 6
Training loss: 2.095571380484465
Validation loss: 2.363412524280604

Epoch: 5| Step: 7
Training loss: 2.1730263491848665
Validation loss: 2.309468450404879

Epoch: 5| Step: 8
Training loss: 2.337721127745129
Validation loss: 2.36014495479874

Epoch: 5| Step: 9
Training loss: 2.459002700022316
Validation loss: 2.343484063049792

Epoch: 5| Step: 10
Training loss: 2.4792751534284108
Validation loss: 2.3413897305661666

Epoch: 218| Step: 0
Training loss: 2.1444867794797156
Validation loss: 2.368938062878259

Epoch: 5| Step: 1
Training loss: 1.8471613215045277
Validation loss: 2.3883408909342556

Epoch: 5| Step: 2
Training loss: 2.159767488398432
Validation loss: 2.3559921788590485

Epoch: 5| Step: 3
Training loss: 1.478572143925717
Validation loss: 2.3347687751994877

Epoch: 5| Step: 4
Training loss: 1.9822836841844156
Validation loss: 2.3953368387199925

Epoch: 5| Step: 5
Training loss: 2.3614729086739232
Validation loss: 2.3532256077618996

Epoch: 5| Step: 6
Training loss: 1.867326803078628
Validation loss: 2.329046448729484

Epoch: 5| Step: 7
Training loss: 2.111683804091975
Validation loss: 2.3744169576329353

Epoch: 5| Step: 8
Training loss: 1.8807260182798984
Validation loss: 2.3622481909081414

Epoch: 5| Step: 9
Training loss: 2.4917455777672224
Validation loss: 2.3661074913763063

Epoch: 5| Step: 10
Training loss: 1.8547984629139507
Validation loss: 2.3281178292280145

Epoch: 219| Step: 0
Training loss: 2.4639058935970835
Validation loss: 2.3507192599710858

Epoch: 5| Step: 1
Training loss: 2.3270672949292623
Validation loss: 2.3467648154679113

Epoch: 5| Step: 2
Training loss: 1.9185197897122293
Validation loss: 2.335726927231502

Epoch: 5| Step: 3
Training loss: 1.8718495922879812
Validation loss: 2.3555381298178437

Epoch: 5| Step: 4
Training loss: 1.6837231792078116
Validation loss: 2.3579422609283527

Epoch: 5| Step: 5
Training loss: 1.5781997814023137
Validation loss: 2.3436723167097004

Epoch: 5| Step: 6
Training loss: 2.004157513487198
Validation loss: 2.328531396476852

Epoch: 5| Step: 7
Training loss: 1.7585370414331707
Validation loss: 2.330789615142602

Epoch: 5| Step: 8
Training loss: 2.018060321923292
Validation loss: 2.3295378405225975

Epoch: 5| Step: 9
Training loss: 2.2768562541046524
Validation loss: 2.361683459484661

Epoch: 5| Step: 10
Training loss: 2.1340074929317647
Validation loss: 2.345836322811443

Epoch: 220| Step: 0
Training loss: 1.964322394486817
Validation loss: 2.340946207660139

Epoch: 5| Step: 1
Training loss: 2.18165767324919
Validation loss: 2.34980350721055

Epoch: 5| Step: 2
Training loss: 1.7616753752585514
Validation loss: 2.3442926250427427

Epoch: 5| Step: 3
Training loss: 2.0354994705937894
Validation loss: 2.3604220488921293

Epoch: 5| Step: 4
Training loss: 2.0865244521813735
Validation loss: 2.3049156119179175

Epoch: 5| Step: 5
Training loss: 1.5896724824250417
Validation loss: 2.3734014703541164

Epoch: 5| Step: 6
Training loss: 1.8009566678813185
Validation loss: 2.2794474010324675

Epoch: 5| Step: 7
Training loss: 2.42131892557661
Validation loss: 2.354112987321944

Epoch: 5| Step: 8
Training loss: 1.7639449236655849
Validation loss: 2.3336343534464405

Epoch: 5| Step: 9
Training loss: 2.017076900886671
Validation loss: 2.358703686195978

Epoch: 5| Step: 10
Training loss: 2.3356149508183766
Validation loss: 2.3916988793250025

Epoch: 221| Step: 0
Training loss: 2.565740072106827
Validation loss: 2.34842059328077

Epoch: 5| Step: 1
Training loss: 1.8762733586107063
Validation loss: 2.355487967958148

Epoch: 5| Step: 2
Training loss: 2.250576369319785
Validation loss: 2.3437746244934927

Epoch: 5| Step: 3
Training loss: 2.0658193522794877
Validation loss: 2.3674466182751344

Epoch: 5| Step: 4
Training loss: 2.069790410843116
Validation loss: 2.3703660094311565

Epoch: 5| Step: 5
Training loss: 2.1040811300989737
Validation loss: 2.3667723199115196

Epoch: 5| Step: 6
Training loss: 1.6567399361959387
Validation loss: 2.3698389293163618

Epoch: 5| Step: 7
Training loss: 1.3257469429068627
Validation loss: 2.31131298748721

Epoch: 5| Step: 8
Training loss: 2.051824046631426
Validation loss: 2.3288980023697423

Epoch: 5| Step: 9
Training loss: 2.012606704442062
Validation loss: 2.373346511989274

Epoch: 5| Step: 10
Training loss: 1.9036633185867813
Validation loss: 2.3378807065810254

Epoch: 222| Step: 0
Training loss: 1.856049585280199
Validation loss: 2.3528220623459464

Epoch: 5| Step: 1
Training loss: 2.4078923355125674
Validation loss: 2.357204259842347

Epoch: 5| Step: 2
Training loss: 2.1707625799186894
Validation loss: 2.3854684988422346

Epoch: 5| Step: 3
Training loss: 2.0673268796682063
Validation loss: 2.385008897510884

Epoch: 5| Step: 4
Training loss: 2.3181633549055287
Validation loss: 2.413614302284364

Epoch: 5| Step: 5
Training loss: 2.0837724858599964
Validation loss: 2.374103370414515

Epoch: 5| Step: 6
Training loss: 1.4422224674965902
Validation loss: 2.384742716482798

Epoch: 5| Step: 7
Training loss: 1.45599361012702
Validation loss: 2.3697662651452247

Epoch: 5| Step: 8
Training loss: 2.0988659203365736
Validation loss: 2.365245113018351

Epoch: 5| Step: 9
Training loss: 1.8506277436941745
Validation loss: 2.3833546624698236

Epoch: 5| Step: 10
Training loss: 2.1487283405767936
Validation loss: 2.3561884247743183

Epoch: 223| Step: 0
Training loss: 1.9195019096768442
Validation loss: 2.3601526278562672

Epoch: 5| Step: 1
Training loss: 1.4768561015814785
Validation loss: 2.374756935000037

Epoch: 5| Step: 2
Training loss: 1.832918907777538
Validation loss: 2.348776676033237

Epoch: 5| Step: 3
Training loss: 1.8496881325216834
Validation loss: 2.3144600069175536

Epoch: 5| Step: 4
Training loss: 1.6689298839983173
Validation loss: 2.3397583724127546

Epoch: 5| Step: 5
Training loss: 2.7400003171489002
Validation loss: 2.3262358424776775

Epoch: 5| Step: 6
Training loss: 1.9888419988753452
Validation loss: 2.348497862980226

Epoch: 5| Step: 7
Training loss: 1.6703511361202568
Validation loss: 2.3058326953027395

Epoch: 5| Step: 8
Training loss: 1.7811695549183182
Validation loss: 2.33005501768569

Epoch: 5| Step: 9
Training loss: 2.463684389739748
Validation loss: 2.370375308475633

Epoch: 5| Step: 10
Training loss: 2.098987348811901
Validation loss: 2.3235109123609736

Epoch: 224| Step: 0
Training loss: 2.0741371382985356
Validation loss: 2.3838300055205064

Epoch: 5| Step: 1
Training loss: 2.4045957353221747
Validation loss: 2.335194516362697

Epoch: 5| Step: 2
Training loss: 2.156571737418065
Validation loss: 2.3481978402793966

Epoch: 5| Step: 3
Training loss: 1.5714772777316508
Validation loss: 2.329266798031833

Epoch: 5| Step: 4
Training loss: 2.174064027062752
Validation loss: 2.335837629537882

Epoch: 5| Step: 5
Training loss: 1.5157769510451806
Validation loss: 2.3242552494758617

Epoch: 5| Step: 6
Training loss: 2.0912403609469234
Validation loss: 2.3451061129248196

Epoch: 5| Step: 7
Training loss: 1.8910436245603206
Validation loss: 2.29647923968516

Epoch: 5| Step: 8
Training loss: 1.9728214610195536
Validation loss: 2.336337249690473

Epoch: 5| Step: 9
Training loss: 1.6041033430936102
Validation loss: 2.379333686156297

Epoch: 5| Step: 10
Training loss: 2.1892928269821263
Validation loss: 2.3520406233483575

Epoch: 225| Step: 0
Training loss: 1.7621175986935056
Validation loss: 2.3680811122333614

Epoch: 5| Step: 1
Training loss: 2.010127651279509
Validation loss: 2.3405047585211554

Epoch: 5| Step: 2
Training loss: 2.155329632253367
Validation loss: 2.364823668550244

Epoch: 5| Step: 3
Training loss: 2.1987881010136423
Validation loss: 2.3425384595005507

Epoch: 5| Step: 4
Training loss: 2.041654495929591
Validation loss: 2.334290192529892

Epoch: 5| Step: 5
Training loss: 1.4394323381141996
Validation loss: 2.3482029474716635

Epoch: 5| Step: 6
Training loss: 2.3113743903613306
Validation loss: 2.3518190939933747

Epoch: 5| Step: 7
Training loss: 1.4803729265348755
Validation loss: 2.3295115996638485

Epoch: 5| Step: 8
Training loss: 2.3940423214262077
Validation loss: 2.3349486910755837

Epoch: 5| Step: 9
Training loss: 1.5307174846579379
Validation loss: 2.374493937394279

Epoch: 5| Step: 10
Training loss: 2.235886282770754
Validation loss: 2.332684728536397

Epoch: 226| Step: 0
Training loss: 1.6873696594764165
Validation loss: 2.3758675664337283

Epoch: 5| Step: 1
Training loss: 2.3349043688907765
Validation loss: 2.381283147941456

Epoch: 5| Step: 2
Training loss: 1.6186768680975858
Validation loss: 2.325727525629202

Epoch: 5| Step: 3
Training loss: 1.7587145038159597
Validation loss: 2.35188415047864

Epoch: 5| Step: 4
Training loss: 2.036778833741682
Validation loss: 2.361903272911095

Epoch: 5| Step: 5
Training loss: 2.3367527588435912
Validation loss: 2.391211732404944

Epoch: 5| Step: 6
Training loss: 1.867631292872917
Validation loss: 2.3487971073415115

Epoch: 5| Step: 7
Training loss: 2.0916379837967254
Validation loss: 2.314085622146295

Epoch: 5| Step: 8
Training loss: 2.5260292184005184
Validation loss: 2.3793364837836477

Epoch: 5| Step: 9
Training loss: 1.7612393354928249
Validation loss: 2.3615202364907164

Epoch: 5| Step: 10
Training loss: 1.7140389815519195
Validation loss: 2.3339447285851276

Epoch: 227| Step: 0
Training loss: 2.031640352741642
Validation loss: 2.3469193969038473

Epoch: 5| Step: 1
Training loss: 1.360991207775499
Validation loss: 2.3399254289897393

Epoch: 5| Step: 2
Training loss: 1.7880202676661243
Validation loss: 2.3381739768417185

Epoch: 5| Step: 3
Training loss: 1.3329844713787515
Validation loss: 2.361031745776754

Epoch: 5| Step: 4
Training loss: 2.142226685013262
Validation loss: 2.38691844238721

Epoch: 5| Step: 5
Training loss: 2.014037579129969
Validation loss: 2.353845638856192

Epoch: 5| Step: 6
Training loss: 2.6156930784711188
Validation loss: 2.3916176982781785

Epoch: 5| Step: 7
Training loss: 2.2631955505516137
Validation loss: 2.367400875172373

Epoch: 5| Step: 8
Training loss: 2.2286226078067464
Validation loss: 2.364451003309898

Epoch: 5| Step: 9
Training loss: 1.816648602468756
Validation loss: 2.3538986156540176

Epoch: 5| Step: 10
Training loss: 1.7683708647263483
Validation loss: 2.3519785817543037

Epoch: 228| Step: 0
Training loss: 1.8069479521120264
Validation loss: 2.3770458388626934

Epoch: 5| Step: 1
Training loss: 2.0441157255837688
Validation loss: 2.3637618813212553

Epoch: 5| Step: 2
Training loss: 2.4197465957821023
Validation loss: 2.3832109220073168

Epoch: 5| Step: 3
Training loss: 2.0942417535199414
Validation loss: 2.3655809292347225

Epoch: 5| Step: 4
Training loss: 1.8105786103694566
Validation loss: 2.359741097781362

Epoch: 5| Step: 5
Training loss: 1.601851051202148
Validation loss: 2.3596995401523495

Epoch: 5| Step: 6
Training loss: 1.6795394477356713
Validation loss: 2.353083931537665

Epoch: 5| Step: 7
Training loss: 2.422329078683528
Validation loss: 2.3320522358592286

Epoch: 5| Step: 8
Training loss: 1.7944655476534197
Validation loss: 2.346959144739083

Epoch: 5| Step: 9
Training loss: 1.9867315642213257
Validation loss: 2.3483379379560705

Epoch: 5| Step: 10
Training loss: 1.6414269076994266
Validation loss: 2.3545089913462616

Epoch: 229| Step: 0
Training loss: 1.6274717312656235
Validation loss: 2.364036034497304

Epoch: 5| Step: 1
Training loss: 2.0266730755570785
Validation loss: 2.356116612665128

Epoch: 5| Step: 2
Training loss: 2.0961954439783206
Validation loss: 2.3330777119080808

Epoch: 5| Step: 3
Training loss: 2.550796485376352
Validation loss: 2.353826957503528

Epoch: 5| Step: 4
Training loss: 1.8424177367273866
Validation loss: 2.356096968407822

Epoch: 5| Step: 5
Training loss: 1.8946699897854196
Validation loss: 2.3667872233393443

Epoch: 5| Step: 6
Training loss: 1.6525707765274367
Validation loss: 2.3491631282560075

Epoch: 5| Step: 7
Training loss: 1.7680649903551704
Validation loss: 2.3878336188799336

Epoch: 5| Step: 8
Training loss: 1.819446930952371
Validation loss: 2.319983430196114

Epoch: 5| Step: 9
Training loss: 1.6102374090168248
Validation loss: 2.3517259442792837

Epoch: 5| Step: 10
Training loss: 2.4283329662286937
Validation loss: 2.3585068332508143

Epoch: 230| Step: 0
Training loss: 2.5608528239580894
Validation loss: 2.340079372439138

Epoch: 5| Step: 1
Training loss: 2.1382838903208032
Validation loss: 2.3560353970606065

Epoch: 5| Step: 2
Training loss: 1.879471913798903
Validation loss: 2.3932274209578686

Epoch: 5| Step: 3
Training loss: 2.194402648699445
Validation loss: 2.3659977410674373

Epoch: 5| Step: 4
Training loss: 1.5895647933632038
Validation loss: 2.3277170545536876

Epoch: 5| Step: 5
Training loss: 1.4628856541710857
Validation loss: 2.343565431936455

Epoch: 5| Step: 6
Training loss: 1.5913853774576985
Validation loss: 2.373570139690723

Epoch: 5| Step: 7
Training loss: 2.039626821717369
Validation loss: 2.3364708360502218

Epoch: 5| Step: 8
Training loss: 2.152012074248749
Validation loss: 2.3834574649076754

Epoch: 5| Step: 9
Training loss: 1.8179885371385025
Validation loss: 2.3707340390174347

Epoch: 5| Step: 10
Training loss: 1.894541946852856
Validation loss: 2.3865052779885687

Epoch: 231| Step: 0
Training loss: 2.0687699239180537
Validation loss: 2.384484865996971

Epoch: 5| Step: 1
Training loss: 1.8928306891348505
Validation loss: 2.3323740928476155

Epoch: 5| Step: 2
Training loss: 1.635850480323868
Validation loss: 2.338951441270404

Epoch: 5| Step: 3
Training loss: 2.4601675615386784
Validation loss: 2.3713547711817227

Epoch: 5| Step: 4
Training loss: 2.2809386367470985
Validation loss: 2.3484188390072585

Epoch: 5| Step: 5
Training loss: 1.8799379811304224
Validation loss: 2.355096313481873

Epoch: 5| Step: 6
Training loss: 1.5311284698215308
Validation loss: 2.3376168014187027

Epoch: 5| Step: 7
Training loss: 1.9802714292804073
Validation loss: 2.3424831836145117

Epoch: 5| Step: 8
Training loss: 2.1355294050524685
Validation loss: 2.3277770092940444

Epoch: 5| Step: 9
Training loss: 1.9927875886568138
Validation loss: 2.348837895206255

Epoch: 5| Step: 10
Training loss: 1.2138253509358186
Validation loss: 2.3283000163680234

Epoch: 232| Step: 0
Training loss: 2.1457260500066746
Validation loss: 2.381301136440481

Epoch: 5| Step: 1
Training loss: 1.4900238168336255
Validation loss: 2.3777992567357242

Epoch: 5| Step: 2
Training loss: 2.147314159447852
Validation loss: 2.3595277893928963

Epoch: 5| Step: 3
Training loss: 1.5600838863608937
Validation loss: 2.330496555273998

Epoch: 5| Step: 4
Training loss: 1.4733964188189563
Validation loss: 2.356851935850887

Epoch: 5| Step: 5
Training loss: 1.3579724848604486
Validation loss: 2.349235456293309

Epoch: 5| Step: 6
Training loss: 2.3769936475849445
Validation loss: 2.332395943946569

Epoch: 5| Step: 7
Training loss: 2.0318737539512264
Validation loss: 2.3596713026664746

Epoch: 5| Step: 8
Training loss: 1.7920032968618516
Validation loss: 2.3543625854531443

Epoch: 5| Step: 9
Training loss: 2.857957499033913
Validation loss: 2.3837874170643416

Epoch: 5| Step: 10
Training loss: 1.745926202505692
Validation loss: 2.370014586314867

Epoch: 233| Step: 0
Training loss: 2.264500305937184
Validation loss: 2.3555841664061825

Epoch: 5| Step: 1
Training loss: 2.6124870336475476
Validation loss: 2.3102303008787604

Epoch: 5| Step: 2
Training loss: 1.5656197492621844
Validation loss: 2.3546609238998277

Epoch: 5| Step: 3
Training loss: 1.6257406894183177
Validation loss: 2.3540903468006964

Epoch: 5| Step: 4
Training loss: 1.7865850627943052
Validation loss: 2.328502893318712

Epoch: 5| Step: 5
Training loss: 1.911788523857917
Validation loss: 2.304842121102339

Epoch: 5| Step: 6
Training loss: 1.7544323784143026
Validation loss: 2.3250744105020558

Epoch: 5| Step: 7
Training loss: 1.5625195311279312
Validation loss: 2.3104098318399022

Epoch: 5| Step: 8
Training loss: 2.100120645418086
Validation loss: 2.3184104789606024

Epoch: 5| Step: 9
Training loss: 1.7826491097979238
Validation loss: 2.347848427037067

Epoch: 5| Step: 10
Training loss: 2.01302033326084
Validation loss: 2.352460950195381

Epoch: 234| Step: 0
Training loss: 1.6485082240548912
Validation loss: 2.360398265482087

Epoch: 5| Step: 1
Training loss: 1.4580544159602284
Validation loss: 2.3066105987508108

Epoch: 5| Step: 2
Training loss: 1.6784974606574028
Validation loss: 2.3461283691367933

Epoch: 5| Step: 3
Training loss: 1.8668640367296494
Validation loss: 2.358809192151115

Epoch: 5| Step: 4
Training loss: 1.7187558954311177
Validation loss: 2.3335183721410386

Epoch: 5| Step: 5
Training loss: 2.3804588825959034
Validation loss: 2.306962633506252

Epoch: 5| Step: 6
Training loss: 1.72034879363786
Validation loss: 2.331239915053051

Epoch: 5| Step: 7
Training loss: 2.1383668446857222
Validation loss: 2.3444313967522374

Epoch: 5| Step: 8
Training loss: 2.244816531392496
Validation loss: 2.3558681334948526

Epoch: 5| Step: 9
Training loss: 1.5471409270462337
Validation loss: 2.3397500314877457

Epoch: 5| Step: 10
Training loss: 2.5295441142132176
Validation loss: 2.3579400918907534

Epoch: 235| Step: 0
Training loss: 1.4598261231913143
Validation loss: 2.324482448609634

Epoch: 5| Step: 1
Training loss: 1.9803856224656913
Validation loss: 2.350931207350796

Epoch: 5| Step: 2
Training loss: 1.8825810080395091
Validation loss: 2.3759208085859007

Epoch: 5| Step: 3
Training loss: 2.5193833418613156
Validation loss: 2.3599183852351433

Epoch: 5| Step: 4
Training loss: 2.0344217040154895
Validation loss: 2.367304011705947

Epoch: 5| Step: 5
Training loss: 1.5528579758686865
Validation loss: 2.377069126769125

Epoch: 5| Step: 6
Training loss: 1.994719508154966
Validation loss: 2.3719967655866134

Epoch: 5| Step: 7
Training loss: 1.8408337175199914
Validation loss: 2.3520950413733175

Epoch: 5| Step: 8
Training loss: 1.7070239173853883
Validation loss: 2.4039933471797843

Epoch: 5| Step: 9
Training loss: 2.2083515910227596
Validation loss: 2.3734372647890822

Epoch: 5| Step: 10
Training loss: 1.9120102448528145
Validation loss: 2.366600781297361

Epoch: 236| Step: 0
Training loss: 1.9392157925146842
Validation loss: 2.3455195986856094

Epoch: 5| Step: 1
Training loss: 2.2179901541241125
Validation loss: 2.336481458836523

Epoch: 5| Step: 2
Training loss: 2.261253295862296
Validation loss: 2.31520507803708

Epoch: 5| Step: 3
Training loss: 2.1735646652876497
Validation loss: 2.363777654018864

Epoch: 5| Step: 4
Training loss: 1.8635318995376715
Validation loss: 2.35750333318676

Epoch: 5| Step: 5
Training loss: 1.3473703274587898
Validation loss: 2.3205491751102123

Epoch: 5| Step: 6
Training loss: 1.2948490542366111
Validation loss: 2.3140436356714007

Epoch: 5| Step: 7
Training loss: 2.3531661031307034
Validation loss: 2.3452612321907753

Epoch: 5| Step: 8
Training loss: 1.6395555189294748
Validation loss: 2.3255239452062932

Epoch: 5| Step: 9
Training loss: 1.7426900780225754
Validation loss: 2.2940585115559946

Epoch: 5| Step: 10
Training loss: 2.067486024783965
Validation loss: 2.321768609184023

Epoch: 237| Step: 0
Training loss: 1.6233180217817176
Validation loss: 2.3364319966081686

Epoch: 5| Step: 1
Training loss: 1.7493417728126486
Validation loss: 2.3057559131977

Epoch: 5| Step: 2
Training loss: 2.0876560632537013
Validation loss: 2.3037737603970583

Epoch: 5| Step: 3
Training loss: 2.4205241712258876
Validation loss: 2.330607202422832

Epoch: 5| Step: 4
Training loss: 2.2558995363037573
Validation loss: 2.296862406525567

Epoch: 5| Step: 5
Training loss: 1.7979329850689174
Validation loss: 2.3158567278571036

Epoch: 5| Step: 6
Training loss: 1.252698227277896
Validation loss: 2.3707708853320155

Epoch: 5| Step: 7
Training loss: 1.9020865577873762
Validation loss: 2.3104318629278207

Epoch: 5| Step: 8
Training loss: 2.1340728501216786
Validation loss: 2.3380846469108225

Epoch: 5| Step: 9
Training loss: 1.9347718012106776
Validation loss: 2.3311040372768

Epoch: 5| Step: 10
Training loss: 1.5793299843004003
Validation loss: 2.3440882295868315

Epoch: 238| Step: 0
Training loss: 1.9161208315399636
Validation loss: 2.302187410057616

Epoch: 5| Step: 1
Training loss: 1.7106383597786432
Validation loss: 2.341748438069284

Epoch: 5| Step: 2
Training loss: 2.221621307612086
Validation loss: 2.327867528796996

Epoch: 5| Step: 3
Training loss: 1.4803386218371573
Validation loss: 2.3572596815601026

Epoch: 5| Step: 4
Training loss: 2.02674930508598
Validation loss: 2.3820661742723175

Epoch: 5| Step: 5
Training loss: 2.399335562602233
Validation loss: 2.380073971884073

Epoch: 5| Step: 6
Training loss: 1.5890029821061804
Validation loss: 2.3509459473064904

Epoch: 5| Step: 7
Training loss: 1.771340159273234
Validation loss: 2.334180094487772

Epoch: 5| Step: 8
Training loss: 2.497490386180684
Validation loss: 2.3735073064077095

Epoch: 5| Step: 9
Training loss: 1.826498041247454
Validation loss: 2.338930230142349

Epoch: 5| Step: 10
Training loss: 1.4490688688604276
Validation loss: 2.372738002261821

Epoch: 239| Step: 0
Training loss: 1.5411198221813223
Validation loss: 2.3200952151883216

Epoch: 5| Step: 1
Training loss: 2.212942663188611
Validation loss: 2.324946379001886

Epoch: 5| Step: 2
Training loss: 2.6570761798221776
Validation loss: 2.3497364248959443

Epoch: 5| Step: 3
Training loss: 1.8644208641945612
Validation loss: 2.3408178559898047

Epoch: 5| Step: 4
Training loss: 1.9290000525000424
Validation loss: 2.329387015793361

Epoch: 5| Step: 5
Training loss: 1.8234698373628824
Validation loss: 2.3223326933207953

Epoch: 5| Step: 6
Training loss: 1.9964626740239226
Validation loss: 2.3542264687008805

Epoch: 5| Step: 7
Training loss: 1.504445482163202
Validation loss: 2.3414876277430356

Epoch: 5| Step: 8
Training loss: 1.6750716549933566
Validation loss: 2.3527107873352975

Epoch: 5| Step: 9
Training loss: 1.8313430762479057
Validation loss: 2.3502203754232776

Epoch: 5| Step: 10
Training loss: 1.5215983709250394
Validation loss: 2.3280255762455884

Epoch: 240| Step: 0
Training loss: 1.7727907993031418
Validation loss: 2.355508616952933

Epoch: 5| Step: 1
Training loss: 2.1529201282758614
Validation loss: 2.3544454011188285

Epoch: 5| Step: 2
Training loss: 1.4565151415272581
Validation loss: 2.3155126794094345

Epoch: 5| Step: 3
Training loss: 2.1449951337212267
Validation loss: 2.356788385997007

Epoch: 5| Step: 4
Training loss: 2.187869013587805
Validation loss: 2.3160046784795765

Epoch: 5| Step: 5
Training loss: 1.811095647349321
Validation loss: 2.3129727734765764

Epoch: 5| Step: 6
Training loss: 2.269731575139945
Validation loss: 2.3359494712622433

Epoch: 5| Step: 7
Training loss: 1.8951354017171635
Validation loss: 2.344114395308372

Epoch: 5| Step: 8
Training loss: 1.8072194095058987
Validation loss: 2.364407532335571

Epoch: 5| Step: 9
Training loss: 1.812081782004905
Validation loss: 2.3555893239717003

Epoch: 5| Step: 10
Training loss: 1.603407304383197
Validation loss: 2.2990448606534417

Epoch: 241| Step: 0
Training loss: 1.7237098568563618
Validation loss: 2.3205021142367235

Epoch: 5| Step: 1
Training loss: 1.7801998455930823
Validation loss: 2.3564883385347377

Epoch: 5| Step: 2
Training loss: 2.166237519630541
Validation loss: 2.3661658368354406

Epoch: 5| Step: 3
Training loss: 1.9351252492147157
Validation loss: 2.3480577921098504

Epoch: 5| Step: 4
Training loss: 1.7437549604666647
Validation loss: 2.3521671986026447

Epoch: 5| Step: 5
Training loss: 1.7968742702316793
Validation loss: 2.3237934658604824

Epoch: 5| Step: 6
Training loss: 1.89539605292231
Validation loss: 2.344281991174849

Epoch: 5| Step: 7
Training loss: 2.148727896744785
Validation loss: 2.3326278585428653

Epoch: 5| Step: 8
Training loss: 1.4753512303771816
Validation loss: 2.326679684883779

Epoch: 5| Step: 9
Training loss: 1.8377558367899467
Validation loss: 2.3858512740077984

Epoch: 5| Step: 10
Training loss: 2.3823831140079883
Validation loss: 2.323750635402837

Epoch: 242| Step: 0
Training loss: 1.6016268089222887
Validation loss: 2.295128343554504

Epoch: 5| Step: 1
Training loss: 2.179200695737372
Validation loss: 2.36582818023226

Epoch: 5| Step: 2
Training loss: 1.6813991608092265
Validation loss: 2.350721207741011

Epoch: 5| Step: 3
Training loss: 1.6196525325897722
Validation loss: 2.328463847752552

Epoch: 5| Step: 4
Training loss: 1.7060305108386407
Validation loss: 2.3300172744392995

Epoch: 5| Step: 5
Training loss: 2.0728770368867737
Validation loss: 2.3409975851246014

Epoch: 5| Step: 6
Training loss: 2.0788520172281846
Validation loss: 2.359301296387638

Epoch: 5| Step: 7
Training loss: 1.8282893180359436
Validation loss: 2.329400782713898

Epoch: 5| Step: 8
Training loss: 1.7921322136410707
Validation loss: 2.353138628304114

Epoch: 5| Step: 9
Training loss: 2.0446227983524796
Validation loss: 2.3696592207151697

Epoch: 5| Step: 10
Training loss: 1.9063606855432709
Validation loss: 2.3851334362092333

Epoch: 243| Step: 0
Training loss: 1.9933397738034788
Validation loss: 2.335294218923055

Epoch: 5| Step: 1
Training loss: 1.8840272395924553
Validation loss: 2.2923799625906067

Epoch: 5| Step: 2
Training loss: 1.7378222598902957
Validation loss: 2.3625979772859007

Epoch: 5| Step: 3
Training loss: 1.6892283030956023
Validation loss: 2.3552184957216715

Epoch: 5| Step: 4
Training loss: 1.3855375175063296
Validation loss: 2.3063654849812343

Epoch: 5| Step: 5
Training loss: 2.099513419864043
Validation loss: 2.3322320441723727

Epoch: 5| Step: 6
Training loss: 2.079440969390144
Validation loss: 2.3251026083729522

Epoch: 5| Step: 7
Training loss: 2.249890430749555
Validation loss: 2.353110261971273

Epoch: 5| Step: 8
Training loss: 1.7744475861711795
Validation loss: 2.343860636188355

Epoch: 5| Step: 9
Training loss: 1.7113386406800721
Validation loss: 2.336438775384051

Epoch: 5| Step: 10
Training loss: 1.8567999310953243
Validation loss: 2.324978824739137

Epoch: 244| Step: 0
Training loss: 2.0104255741956436
Validation loss: 2.3618832925431574

Epoch: 5| Step: 1
Training loss: 1.901852021318281
Validation loss: 2.347999283291849

Epoch: 5| Step: 2
Training loss: 1.9479204949598041
Validation loss: 2.324199189106971

Epoch: 5| Step: 3
Training loss: 2.124454203804474
Validation loss: 2.316732570150194

Epoch: 5| Step: 4
Training loss: 1.7736086993830464
Validation loss: 2.3178749322324257

Epoch: 5| Step: 5
Training loss: 2.1023376623524133
Validation loss: 2.3178521039246354

Epoch: 5| Step: 6
Training loss: 1.976083931263968
Validation loss: 2.323690554710681

Epoch: 5| Step: 7
Training loss: 1.354195252141262
Validation loss: 2.3549347812391637

Epoch: 5| Step: 8
Training loss: 1.8454291246271737
Validation loss: 2.318476458517638

Epoch: 5| Step: 9
Training loss: 2.0316881147488095
Validation loss: 2.3378474792967143

Epoch: 5| Step: 10
Training loss: 1.688157695183893
Validation loss: 2.342060731120242

Epoch: 245| Step: 0
Training loss: 1.6423254011419552
Validation loss: 2.3392525512426934

Epoch: 5| Step: 1
Training loss: 1.7133690960685597
Validation loss: 2.310014907678008

Epoch: 5| Step: 2
Training loss: 1.7104526337881623
Validation loss: 2.3205088887280434

Epoch: 5| Step: 3
Training loss: 1.8171155631602385
Validation loss: 2.33304127903139

Epoch: 5| Step: 4
Training loss: 1.751083243120603
Validation loss: 2.384013245178136

Epoch: 5| Step: 5
Training loss: 2.110811323775784
Validation loss: 2.372216217206838

Epoch: 5| Step: 6
Training loss: 2.1231063932693326
Validation loss: 2.368798989829889

Epoch: 5| Step: 7
Training loss: 1.9764184107675116
Validation loss: 2.321493473135125

Epoch: 5| Step: 8
Training loss: 2.360267722898164
Validation loss: 2.3361994083825777

Epoch: 5| Step: 9
Training loss: 1.5302228012422407
Validation loss: 2.3185906475116016

Epoch: 5| Step: 10
Training loss: 1.7849366702003677
Validation loss: 2.364217891392418

Epoch: 246| Step: 0
Training loss: 1.7004214886266154
Validation loss: 2.3413381558568163

Epoch: 5| Step: 1
Training loss: 1.5325244349014298
Validation loss: 2.3616905782752347

Epoch: 5| Step: 2
Training loss: 1.5396292170740704
Validation loss: 2.31272285028419

Epoch: 5| Step: 3
Training loss: 1.6844903457016198
Validation loss: 2.3501910635767587

Epoch: 5| Step: 4
Training loss: 2.6327031053404295
Validation loss: 2.3363849122111304

Epoch: 5| Step: 5
Training loss: 1.6896610551009565
Validation loss: 2.332541662899515

Epoch: 5| Step: 6
Training loss: 1.8663224646570968
Validation loss: 2.3444693628374367

Epoch: 5| Step: 7
Training loss: 1.9266667989820987
Validation loss: 2.3736131350420764

Epoch: 5| Step: 8
Training loss: 2.1083373731893604
Validation loss: 2.3290692611521373

Epoch: 5| Step: 9
Training loss: 1.7759936224590958
Validation loss: 2.3043114718491484

Epoch: 5| Step: 10
Training loss: 1.7994795788673852
Validation loss: 2.3559453732988835

Epoch: 247| Step: 0
Training loss: 1.5755178236078777
Validation loss: 2.3405534347755994

Epoch: 5| Step: 1
Training loss: 1.6667679835359666
Validation loss: 2.305211340575208

Epoch: 5| Step: 2
Training loss: 2.4065914159547663
Validation loss: 2.330616343307611

Epoch: 5| Step: 3
Training loss: 2.046939644993912
Validation loss: 2.3132480009132688

Epoch: 5| Step: 4
Training loss: 1.6804126682260723
Validation loss: 2.319074207298262

Epoch: 5| Step: 5
Training loss: 1.7113825249749253
Validation loss: 2.324997026130855

Epoch: 5| Step: 6
Training loss: 1.606891382312688
Validation loss: 2.336714357995878

Epoch: 5| Step: 7
Training loss: 1.804638354140075
Validation loss: 2.3797877551746067

Epoch: 5| Step: 8
Training loss: 1.4700274492153311
Validation loss: 2.3617016889949207

Epoch: 5| Step: 9
Training loss: 2.19889349420952
Validation loss: 2.388923108397228

Epoch: 5| Step: 10
Training loss: 2.207715925843362
Validation loss: 2.3650782579779848

Epoch: 248| Step: 0
Training loss: 1.820398287736745
Validation loss: 2.3534412792855304

Epoch: 5| Step: 1
Training loss: 1.9578822678345416
Validation loss: 2.3140319776119127

Epoch: 5| Step: 2
Training loss: 1.6070954558027628
Validation loss: 2.3336205093345423

Epoch: 5| Step: 3
Training loss: 2.066529239679349
Validation loss: 2.341664044080899

Epoch: 5| Step: 4
Training loss: 2.0417674163041917
Validation loss: 2.3213364906398883

Epoch: 5| Step: 5
Training loss: 1.6029071652426887
Validation loss: 2.3271564022218794

Epoch: 5| Step: 6
Training loss: 1.7111169729641558
Validation loss: 2.3046602381363854

Epoch: 5| Step: 7
Training loss: 2.3830120065685163
Validation loss: 2.3229226078675014

Epoch: 5| Step: 8
Training loss: 1.802831711212968
Validation loss: 2.329185191036477

Epoch: 5| Step: 9
Training loss: 1.4771712728488304
Validation loss: 2.331765226596308

Epoch: 5| Step: 10
Training loss: 1.876127984579761
Validation loss: 2.3000844576569413

Epoch: 249| Step: 0
Training loss: 1.6842447602092994
Validation loss: 2.3196773411716913

Epoch: 5| Step: 1
Training loss: 2.194146440554982
Validation loss: 2.337656745263748

Epoch: 5| Step: 2
Training loss: 1.894640292146281
Validation loss: 2.3189600791501794

Epoch: 5| Step: 3
Training loss: 1.8519107796865348
Validation loss: 2.3178393028413873

Epoch: 5| Step: 4
Training loss: 2.1988062090517664
Validation loss: 2.3110224275057387

Epoch: 5| Step: 5
Training loss: 1.9007093862047624
Validation loss: 2.3529684524158587

Epoch: 5| Step: 6
Training loss: 1.8604989381421655
Validation loss: 2.333253516496218

Epoch: 5| Step: 7
Training loss: 1.2406572236841598
Validation loss: 2.310109087314367

Epoch: 5| Step: 8
Training loss: 1.6445685085688042
Validation loss: 2.3393906745579383

Epoch: 5| Step: 9
Training loss: 1.7499508850834837
Validation loss: 2.3284107987261224

Epoch: 5| Step: 10
Training loss: 1.9801193019297796
Validation loss: 2.3156324089137357

Epoch: 250| Step: 0
Training loss: 1.333492428506726
Validation loss: 2.353777581492681

Epoch: 5| Step: 1
Training loss: 1.879519673732886
Validation loss: 2.320727790158369

Epoch: 5| Step: 2
Training loss: 1.9155279660813416
Validation loss: 2.30232977412251

Epoch: 5| Step: 3
Training loss: 1.2196635710284354
Validation loss: 2.3305142559587364

Epoch: 5| Step: 4
Training loss: 2.158720287655275
Validation loss: 2.334307657978119

Epoch: 5| Step: 5
Training loss: 2.068303353304709
Validation loss: 2.350921703808869

Epoch: 5| Step: 6
Training loss: 2.476066563766884
Validation loss: 2.3053554467303146

Epoch: 5| Step: 7
Training loss: 1.7978804719124628
Validation loss: 2.3624583964502444

Epoch: 5| Step: 8
Training loss: 1.685165132190568
Validation loss: 2.3478002978533348

Epoch: 5| Step: 9
Training loss: 1.6124195818106393
Validation loss: 2.337331063895124

Epoch: 5| Step: 10
Training loss: 1.8129689497858403
Validation loss: 2.322882874740273

Epoch: 251| Step: 0
Training loss: 1.560467504361619
Validation loss: 2.318600467669425

Epoch: 5| Step: 1
Training loss: 1.6370116634058258
Validation loss: 2.319674889486192

Epoch: 5| Step: 2
Training loss: 1.6598530571026748
Validation loss: 2.3177936652083777

Epoch: 5| Step: 3
Training loss: 1.7390558809906749
Validation loss: 2.3184769511263847

Epoch: 5| Step: 4
Training loss: 2.470072138732882
Validation loss: 2.325891842427382

Epoch: 5| Step: 5
Training loss: 1.6285444630873802
Validation loss: 2.3162743238035426

Epoch: 5| Step: 6
Training loss: 2.153249892556013
Validation loss: 2.360426719092457

Epoch: 5| Step: 7
Training loss: 1.654216165386547
Validation loss: 2.3076982296682833

Epoch: 5| Step: 8
Training loss: 2.296728946946811
Validation loss: 2.3503021186540125

Epoch: 5| Step: 9
Training loss: 1.7468178291041605
Validation loss: 2.34516884082311

Epoch: 5| Step: 10
Training loss: 1.614030197721373
Validation loss: 2.3422510572747597

Epoch: 252| Step: 0
Training loss: 1.619194370385512
Validation loss: 2.3299043788298976

Epoch: 5| Step: 1
Training loss: 1.5481172447949774
Validation loss: 2.3028659179887874

Epoch: 5| Step: 2
Training loss: 1.6953500488623257
Validation loss: 2.3295910922313707

Epoch: 5| Step: 3
Training loss: 1.9802125543117604
Validation loss: 2.3061802199421475

Epoch: 5| Step: 4
Training loss: 1.3780111373955117
Validation loss: 2.34369566823681

Epoch: 5| Step: 5
Training loss: 1.9699060588067852
Validation loss: 2.348637988605193

Epoch: 5| Step: 6
Training loss: 1.9262375977628716
Validation loss: 2.2959530952815994

Epoch: 5| Step: 7
Training loss: 1.6563570959626137
Validation loss: 2.3107153755722867

Epoch: 5| Step: 8
Training loss: 2.676415762188731
Validation loss: 2.2986731177659596

Epoch: 5| Step: 9
Training loss: 1.9779046971010026
Validation loss: 2.3532006632812044

Epoch: 5| Step: 10
Training loss: 1.5049903034138628
Validation loss: 2.3431947347080198

Epoch: 253| Step: 0
Training loss: 1.5009582955236043
Validation loss: 2.307439885751014

Epoch: 5| Step: 1
Training loss: 2.195466168547151
Validation loss: 2.3286802019806996

Epoch: 5| Step: 2
Training loss: 2.232506564345326
Validation loss: 2.3506684341656214

Epoch: 5| Step: 3
Training loss: 1.6659705456697926
Validation loss: 2.3617156344454235

Epoch: 5| Step: 4
Training loss: 2.0926952836987613
Validation loss: 2.32327091961517

Epoch: 5| Step: 5
Training loss: 1.8301545964795927
Validation loss: 2.3560169000981728

Epoch: 5| Step: 6
Training loss: 1.9705524973019122
Validation loss: 2.2999312594745116

Epoch: 5| Step: 7
Training loss: 1.7631525603705873
Validation loss: 2.3379830896156597

Epoch: 5| Step: 8
Training loss: 1.7837876430461135
Validation loss: 2.305594895345941

Epoch: 5| Step: 9
Training loss: 1.499565776917561
Validation loss: 2.3450300345878614

Epoch: 5| Step: 10
Training loss: 1.6285107175845044
Validation loss: 2.339062222226695

Epoch: 254| Step: 0
Training loss: 1.6857341428053614
Validation loss: 2.3564966931032876

Epoch: 5| Step: 1
Training loss: 1.7283883085615104
Validation loss: 2.2876568032943

Epoch: 5| Step: 2
Training loss: 2.251319816053253
Validation loss: 2.323919424069938

Epoch: 5| Step: 3
Training loss: 1.5540886880711233
Validation loss: 2.310657473366384

Epoch: 5| Step: 4
Training loss: 1.9054095182014317
Validation loss: 2.3135861653777523

Epoch: 5| Step: 5
Training loss: 1.9097140371744477
Validation loss: 2.334092231764441

Epoch: 5| Step: 6
Training loss: 2.0524597855413997
Validation loss: 2.3070846891075205

Epoch: 5| Step: 7
Training loss: 1.405656943833905
Validation loss: 2.29790712658282

Epoch: 5| Step: 8
Training loss: 1.9222886795555987
Validation loss: 2.3587750510996233

Epoch: 5| Step: 9
Training loss: 1.6624381147066776
Validation loss: 2.3141000539556025

Epoch: 5| Step: 10
Training loss: 1.9427542659725938
Validation loss: 2.33628550528732

Epoch: 255| Step: 0
Training loss: 1.65919297938779
Validation loss: 2.312981027528663

Epoch: 5| Step: 1
Training loss: 1.5741290878622078
Validation loss: 2.3316104288193222

Epoch: 5| Step: 2
Training loss: 2.9437539912559196
Validation loss: 2.3130770858146397

Epoch: 5| Step: 3
Training loss: 1.2708545537125382
Validation loss: 2.3603979124978975

Epoch: 5| Step: 4
Training loss: 1.5528034698659814
Validation loss: 2.3151854874952105

Epoch: 5| Step: 5
Training loss: 1.8001184795381542
Validation loss: 2.288645143115133

Epoch: 5| Step: 6
Training loss: 1.7468917354539573
Validation loss: 2.31845698407858

Epoch: 5| Step: 7
Training loss: 1.7086373810676416
Validation loss: 2.376016262304701

Epoch: 5| Step: 8
Training loss: 1.4442057728228206
Validation loss: 2.3575793406724794

Epoch: 5| Step: 9
Training loss: 1.7625705326116825
Validation loss: 2.328011934439602

Epoch: 5| Step: 10
Training loss: 1.9080383791912245
Validation loss: 2.3228193855268295

Epoch: 256| Step: 0
Training loss: 2.0011571874308505
Validation loss: 2.3282783861347873

Epoch: 5| Step: 1
Training loss: 1.8013264457581313
Validation loss: 2.353071599667985

Epoch: 5| Step: 2
Training loss: 1.8887705259388055
Validation loss: 2.3507581725311604

Epoch: 5| Step: 3
Training loss: 1.5592029117277153
Validation loss: 2.366242005937338

Epoch: 5| Step: 4
Training loss: 1.81879659901073
Validation loss: 2.32050380675663

Epoch: 5| Step: 5
Training loss: 2.1471873582271686
Validation loss: 2.3345812629806386

Epoch: 5| Step: 6
Training loss: 1.411374060260452
Validation loss: 2.321291883145783

Epoch: 5| Step: 7
Training loss: 1.9349768421847482
Validation loss: 2.315321168416809

Epoch: 5| Step: 8
Training loss: 1.6516047419087545
Validation loss: 2.3516464929744556

Epoch: 5| Step: 9
Training loss: 2.075934266411317
Validation loss: 2.2745148806939732

Epoch: 5| Step: 10
Training loss: 1.4351724772192629
Validation loss: 2.2982294038979343

Epoch: 257| Step: 0
Training loss: 1.6696833568466618
Validation loss: 2.3168081297995724

Epoch: 5| Step: 1
Training loss: 1.9369709769316277
Validation loss: 2.2977532454559886

Epoch: 5| Step: 2
Training loss: 1.8213528783013886
Validation loss: 2.28343454799361

Epoch: 5| Step: 3
Training loss: 1.2795506815262294
Validation loss: 2.3594583486987046

Epoch: 5| Step: 4
Training loss: 2.3815033865453463
Validation loss: 2.316307097982596

Epoch: 5| Step: 5
Training loss: 1.9293302753629002
Validation loss: 2.2986275479491636

Epoch: 5| Step: 6
Training loss: 1.4382684560991013
Validation loss: 2.317148322134044

Epoch: 5| Step: 7
Training loss: 1.956875305663103
Validation loss: 2.30585858913939

Epoch: 5| Step: 8
Training loss: 1.869930981163036
Validation loss: 2.34817692447529

Epoch: 5| Step: 9
Training loss: 1.7312026007047498
Validation loss: 2.3231895367809536

Epoch: 5| Step: 10
Training loss: 1.7442602306676658
Validation loss: 2.328317659979932

Epoch: 258| Step: 0
Training loss: 1.5717663463860765
Validation loss: 2.304997353557925

Epoch: 5| Step: 1
Training loss: 1.9230720079799344
Validation loss: 2.3057988121834745

Epoch: 5| Step: 2
Training loss: 1.5497046896890196
Validation loss: 2.330027583916347

Epoch: 5| Step: 3
Training loss: 2.4095506695582687
Validation loss: 2.341967585708711

Epoch: 5| Step: 4
Training loss: 1.7043354037937715
Validation loss: 2.3545458925877334

Epoch: 5| Step: 5
Training loss: 1.5213112885691427
Validation loss: 2.3532913378222275

Epoch: 5| Step: 6
Training loss: 1.9426236240712724
Validation loss: 2.2922127122558664

Epoch: 5| Step: 7
Training loss: 1.9905159314037144
Validation loss: 2.3130329341676124

Epoch: 5| Step: 8
Training loss: 1.5564312381230103
Validation loss: 2.3020085185413928

Epoch: 5| Step: 9
Training loss: 1.829787647558946
Validation loss: 2.3403261833564324

Epoch: 5| Step: 10
Training loss: 1.7604535416873617
Validation loss: 2.3277076732008743

Epoch: 259| Step: 0
Training loss: 1.7301287521565256
Validation loss: 2.3376067568147225

Epoch: 5| Step: 1
Training loss: 1.5034358886760861
Validation loss: 2.31729269436083

Epoch: 5| Step: 2
Training loss: 1.875652454026571
Validation loss: 2.352354844556358

Epoch: 5| Step: 3
Training loss: 2.032929533067902
Validation loss: 2.324304864945542

Epoch: 5| Step: 4
Training loss: 2.038488431484621
Validation loss: 2.3324582239510883

Epoch: 5| Step: 5
Training loss: 1.5484711859894977
Validation loss: 2.335998217195931

Epoch: 5| Step: 6
Training loss: 2.0138946913127693
Validation loss: 2.2977630760108423

Epoch: 5| Step: 7
Training loss: 1.5027605721332336
Validation loss: 2.289475992692536

Epoch: 5| Step: 8
Training loss: 2.034671894213426
Validation loss: 2.3417001884384074

Epoch: 5| Step: 9
Training loss: 1.6932660949428713
Validation loss: 2.3059475065164405

Epoch: 5| Step: 10
Training loss: 1.6358805765852833
Validation loss: 2.294853989385372

Epoch: 260| Step: 0
Training loss: 1.726233058241371
Validation loss: 2.274339894940377

Epoch: 5| Step: 1
Training loss: 1.9659101197545241
Validation loss: 2.3158891935639163

Epoch: 5| Step: 2
Training loss: 1.8723840266577476
Validation loss: 2.310750603909555

Epoch: 5| Step: 3
Training loss: 2.100135063187692
Validation loss: 2.2940594569719552

Epoch: 5| Step: 4
Training loss: 1.6987094861407124
Validation loss: 2.311053539008788

Epoch: 5| Step: 5
Training loss: 1.7142437904204277
Validation loss: 2.3102965129431428

Epoch: 5| Step: 6
Training loss: 1.7117699117949567
Validation loss: 2.301385773739227

Epoch: 5| Step: 7
Training loss: 1.788021267732441
Validation loss: 2.331846415676588

Epoch: 5| Step: 8
Training loss: 1.615914991314603
Validation loss: 2.324077168612097

Epoch: 5| Step: 9
Training loss: 2.201993719447133
Validation loss: 2.3247416963323695

Epoch: 5| Step: 10
Training loss: 1.4222498808264117
Validation loss: 2.3108054562227807

Epoch: 261| Step: 0
Training loss: 1.967127721967509
Validation loss: 2.283750292999157

Epoch: 5| Step: 1
Training loss: 1.6918031433877176
Validation loss: 2.3012402130665857

Epoch: 5| Step: 2
Training loss: 2.3647765922273165
Validation loss: 2.3027243374400466

Epoch: 5| Step: 3
Training loss: 1.775834132026816
Validation loss: 2.310730166813096

Epoch: 5| Step: 4
Training loss: 1.291747100950856
Validation loss: 2.321937794768453

Epoch: 5| Step: 5
Training loss: 1.7290674050883936
Validation loss: 2.305863125256025

Epoch: 5| Step: 6
Training loss: 1.7490658310311014
Validation loss: 2.3201396490085453

Epoch: 5| Step: 7
Training loss: 1.8165712999399453
Validation loss: 2.362741751107319

Epoch: 5| Step: 8
Training loss: 1.291610603756585
Validation loss: 2.297249588296612

Epoch: 5| Step: 9
Training loss: 1.958043246055631
Validation loss: 2.2779831138030424

Epoch: 5| Step: 10
Training loss: 1.9661687853822962
Validation loss: 2.3099369011617306

Epoch: 262| Step: 0
Training loss: 1.7471223059007983
Validation loss: 2.3315524660662352

Epoch: 5| Step: 1
Training loss: 2.203853189234643
Validation loss: 2.274537408236911

Epoch: 5| Step: 2
Training loss: 1.6310877839911262
Validation loss: 2.311636783863822

Epoch: 5| Step: 3
Training loss: 1.5666992217935782
Validation loss: 2.286082167839205

Epoch: 5| Step: 4
Training loss: 1.8697649033808488
Validation loss: 2.2652748377624006

Epoch: 5| Step: 5
Training loss: 1.6080371518089687
Validation loss: 2.277182839077335

Epoch: 5| Step: 6
Training loss: 2.4670769539262936
Validation loss: 2.3222420292783337

Epoch: 5| Step: 7
Training loss: 1.7882512014655119
Validation loss: 2.2627823254593196

Epoch: 5| Step: 8
Training loss: 1.4060848562970552
Validation loss: 2.339229135635031

Epoch: 5| Step: 9
Training loss: 1.6224517649341579
Validation loss: 2.2846969649184494

Epoch: 5| Step: 10
Training loss: 1.7491167428045238
Validation loss: 2.301003320028393

Epoch: 263| Step: 0
Training loss: 2.243056922914805
Validation loss: 2.3365620693049323

Epoch: 5| Step: 1
Training loss: 2.197660771760923
Validation loss: 2.2806896533493917

Epoch: 5| Step: 2
Training loss: 1.673307785292556
Validation loss: 2.336925594342057

Epoch: 5| Step: 3
Training loss: 1.9751004929869926
Validation loss: 2.3320996198936124

Epoch: 5| Step: 4
Training loss: 1.8419722699077559
Validation loss: 2.3255678426207425

Epoch: 5| Step: 5
Training loss: 1.7409543176186892
Validation loss: 2.3263417663193326

Epoch: 5| Step: 6
Training loss: 1.1390739241499406
Validation loss: 2.3468851189347197

Epoch: 5| Step: 7
Training loss: 1.669853699837346
Validation loss: 2.2846935902236765

Epoch: 5| Step: 8
Training loss: 1.3485685936777345
Validation loss: 2.3630957756866513

Epoch: 5| Step: 9
Training loss: 1.7341038947390157
Validation loss: 2.3527953789207396

Epoch: 5| Step: 10
Training loss: 2.107731044318009
Validation loss: 2.34451358238214

Epoch: 264| Step: 0
Training loss: 1.9702462459741905
Validation loss: 2.340474015505564

Epoch: 5| Step: 1
Training loss: 1.3928531412619096
Validation loss: 2.2760367549840335

Epoch: 5| Step: 2
Training loss: 2.339339926454449
Validation loss: 2.317755928025572

Epoch: 5| Step: 3
Training loss: 1.8430395535609079
Validation loss: 2.34867095571773

Epoch: 5| Step: 4
Training loss: 1.8014231962951595
Validation loss: 2.31121718975641

Epoch: 5| Step: 5
Training loss: 1.5819051810060316
Validation loss: 2.33649105348125

Epoch: 5| Step: 6
Training loss: 1.545043940490255
Validation loss: 2.2999388536383556

Epoch: 5| Step: 7
Training loss: 1.5329032847732926
Validation loss: 2.3050321409934034

Epoch: 5| Step: 8
Training loss: 1.4191604524671626
Validation loss: 2.307273065972639

Epoch: 5| Step: 9
Training loss: 1.7500965909186743
Validation loss: 2.277473564347976

Epoch: 5| Step: 10
Training loss: 2.1374692278872214
Validation loss: 2.2871472389800847

Epoch: 265| Step: 0
Training loss: 1.6776458397132215
Validation loss: 2.293789761830596

Epoch: 5| Step: 1
Training loss: 1.756098746849192
Validation loss: 2.3358831083439213

Epoch: 5| Step: 2
Training loss: 2.2201309205019197
Validation loss: 2.320333023950041

Epoch: 5| Step: 3
Training loss: 1.8680946987294356
Validation loss: 2.29365930669943

Epoch: 5| Step: 4
Training loss: 1.0172890162754056
Validation loss: 2.320151939346015

Epoch: 5| Step: 5
Training loss: 2.088913755178683
Validation loss: 2.35058568992494

Epoch: 5| Step: 6
Training loss: 1.7202397219363743
Validation loss: 2.3169831263485468

Epoch: 5| Step: 7
Training loss: 1.5852345379128132
Validation loss: 2.3013451206993265

Epoch: 5| Step: 8
Training loss: 1.654729469062448
Validation loss: 2.33158103639914

Epoch: 5| Step: 9
Training loss: 1.3862770344167965
Validation loss: 2.3408188657548963

Epoch: 5| Step: 10
Training loss: 2.040529622160878
Validation loss: 2.3207033541553717

Epoch: 266| Step: 0
Training loss: 1.6014496554185935
Validation loss: 2.32458632938674

Epoch: 5| Step: 1
Training loss: 2.1064289005720758
Validation loss: 2.372912645174952

Epoch: 5| Step: 2
Training loss: 1.2119060457688364
Validation loss: 2.3294278419759498

Epoch: 5| Step: 3
Training loss: 1.242105445310952
Validation loss: 2.3267573923144202

Epoch: 5| Step: 4
Training loss: 2.196607757419065
Validation loss: 2.2927042904398336

Epoch: 5| Step: 5
Training loss: 2.313824454768103
Validation loss: 2.279150992422064

Epoch: 5| Step: 6
Training loss: 2.110055206263624
Validation loss: 2.307740121632169

Epoch: 5| Step: 7
Training loss: 1.6249386702481639
Validation loss: 2.26095169341523

Epoch: 5| Step: 8
Training loss: 1.7304318942930816
Validation loss: 2.3283886107461202

Epoch: 5| Step: 9
Training loss: 1.3703566088477108
Validation loss: 2.3060436243257665

Epoch: 5| Step: 10
Training loss: 1.5722718422334374
Validation loss: 2.309932828076694

Epoch: 267| Step: 0
Training loss: 1.5381437551136967
Validation loss: 2.288259311626135

Epoch: 5| Step: 1
Training loss: 1.8425487549127015
Validation loss: 2.3590124251381375

Epoch: 5| Step: 2
Training loss: 1.9694900332855045
Validation loss: 2.260190878087308

Epoch: 5| Step: 3
Training loss: 1.975769728343791
Validation loss: 2.300146794461004

Epoch: 5| Step: 4
Training loss: 1.8868194616381957
Validation loss: 2.3099348357644667

Epoch: 5| Step: 5
Training loss: 1.9904393323609053
Validation loss: 2.341177394633716

Epoch: 5| Step: 6
Training loss: 1.752524802539883
Validation loss: 2.3513479623123543

Epoch: 5| Step: 7
Training loss: 1.5842528768269208
Validation loss: 2.3445705035873456

Epoch: 5| Step: 8
Training loss: 1.8468316397442142
Validation loss: 2.2987311729582647

Epoch: 5| Step: 9
Training loss: 1.475721573923098
Validation loss: 2.334453085186284

Epoch: 5| Step: 10
Training loss: 1.5808209346002815
Validation loss: 2.3204852585713085

Epoch: 268| Step: 0
Training loss: 2.028527063329789
Validation loss: 2.3363512390049936

Epoch: 5| Step: 1
Training loss: 2.1976644603306017
Validation loss: 2.331547651165392

Epoch: 5| Step: 2
Training loss: 1.5803962453295017
Validation loss: 2.281403168241974

Epoch: 5| Step: 3
Training loss: 1.867899994201023
Validation loss: 2.3671406017319905

Epoch: 5| Step: 4
Training loss: 1.8377480527607764
Validation loss: 2.3115430036250677

Epoch: 5| Step: 5
Training loss: 1.3728164761713852
Validation loss: 2.336963280865097

Epoch: 5| Step: 6
Training loss: 1.7950490547426539
Validation loss: 2.321873289311992

Epoch: 5| Step: 7
Training loss: 1.9809696685109606
Validation loss: 2.333291539756931

Epoch: 5| Step: 8
Training loss: 1.4666887794619419
Validation loss: 2.3365033516196907

Epoch: 5| Step: 9
Training loss: 1.5755069280173646
Validation loss: 2.2962819658495977

Epoch: 5| Step: 10
Training loss: 1.6314985473233536
Validation loss: 2.2374491427039382

Epoch: 269| Step: 0
Training loss: 1.7546362090660763
Validation loss: 2.241987363168281

Epoch: 5| Step: 1
Training loss: 2.002969087671653
Validation loss: 2.3009966162361644

Epoch: 5| Step: 2
Training loss: 1.4787857836846112
Validation loss: 2.315267214790657

Epoch: 5| Step: 3
Training loss: 1.8176562530431006
Validation loss: 2.288853617139953

Epoch: 5| Step: 4
Training loss: 1.7112772704376484
Validation loss: 2.3511998031064203

Epoch: 5| Step: 5
Training loss: 1.552940882739721
Validation loss: 2.319522155574346

Epoch: 5| Step: 6
Training loss: 1.8126883573329826
Validation loss: 2.3204509491749405

Epoch: 5| Step: 7
Training loss: 1.816871763895077
Validation loss: 2.291793087765823

Epoch: 5| Step: 8
Training loss: 1.688866662344879
Validation loss: 2.2999530710316516

Epoch: 5| Step: 9
Training loss: 1.757794257175302
Validation loss: 2.3357263071002983

Epoch: 5| Step: 10
Training loss: 1.8050939589373294
Validation loss: 2.3431970765833907

Epoch: 270| Step: 0
Training loss: 1.8523015989658633
Validation loss: 2.3325346760627146

Epoch: 5| Step: 1
Training loss: 1.469665242180091
Validation loss: 2.3252250182748457

Epoch: 5| Step: 2
Training loss: 1.7846037095134468
Validation loss: 2.2840558343496387

Epoch: 5| Step: 3
Training loss: 1.9949945756652057
Validation loss: 2.2807121997092707

Epoch: 5| Step: 4
Training loss: 1.6020350805720656
Validation loss: 2.317257097504698

Epoch: 5| Step: 5
Training loss: 1.3121921541586143
Validation loss: 2.307023495429128

Epoch: 5| Step: 6
Training loss: 1.4636658675775769
Validation loss: 2.2899747981570706

Epoch: 5| Step: 7
Training loss: 1.7683660784729773
Validation loss: 2.303742417044432

Epoch: 5| Step: 8
Training loss: 2.085013309866231
Validation loss: 2.286305921254339

Epoch: 5| Step: 9
Training loss: 1.9269009753025261
Validation loss: 2.298682382850888

Epoch: 5| Step: 10
Training loss: 1.8526757993693797
Validation loss: 2.2810223244266576

Epoch: 271| Step: 0
Training loss: 2.199159231786482
Validation loss: 2.303224861790777

Epoch: 5| Step: 1
Training loss: 1.5030538149531245
Validation loss: 2.301476453475283

Epoch: 5| Step: 2
Training loss: 1.4728717190989957
Validation loss: 2.296371202687546

Epoch: 5| Step: 3
Training loss: 1.3095031766587129
Validation loss: 2.327741049630982

Epoch: 5| Step: 4
Training loss: 2.0758597281957707
Validation loss: 2.283214794504454

Epoch: 5| Step: 5
Training loss: 1.9376120996347859
Validation loss: 2.2871536571876367

Epoch: 5| Step: 6
Training loss: 1.4676281317120334
Validation loss: 2.2876753414130078

Epoch: 5| Step: 7
Training loss: 1.9288783056337007
Validation loss: 2.293778364067562

Epoch: 5| Step: 8
Training loss: 1.7620590794733426
Validation loss: 2.271477576188408

Epoch: 5| Step: 9
Training loss: 1.7374300469237578
Validation loss: 2.3544248184751484

Epoch: 5| Step: 10
Training loss: 1.3361179163057404
Validation loss: 2.245626509381596

Epoch: 272| Step: 0
Training loss: 1.6775596447729153
Validation loss: 2.254208069516767

Epoch: 5| Step: 1
Training loss: 1.6350992060670295
Validation loss: 2.3101932380281953

Epoch: 5| Step: 2
Training loss: 1.4486879266008947
Validation loss: 2.313735325987592

Epoch: 5| Step: 3
Training loss: 1.7353363122307535
Validation loss: 2.3123673841946224

Epoch: 5| Step: 4
Training loss: 1.6470735520718096
Validation loss: 2.3080097383777205

Epoch: 5| Step: 5
Training loss: 1.820064871648444
Validation loss: 2.2992438520174208

Epoch: 5| Step: 6
Training loss: 2.109820170581171
Validation loss: 2.313754813575955

Epoch: 5| Step: 7
Training loss: 1.6965704263448222
Validation loss: 2.3275642432696526

Epoch: 5| Step: 8
Training loss: 1.8647219927784309
Validation loss: 2.324307544060321

Epoch: 5| Step: 9
Training loss: 1.528671429066172
Validation loss: 2.3353401803479716

Epoch: 5| Step: 10
Training loss: 1.885243536093921
Validation loss: 2.289227636598437

Epoch: 273| Step: 0
Training loss: 1.2811346234732375
Validation loss: 2.3169942639111474

Epoch: 5| Step: 1
Training loss: 1.858734597589315
Validation loss: 2.30776482098212

Epoch: 5| Step: 2
Training loss: 1.6069040681160178
Validation loss: 2.308801827940993

Epoch: 5| Step: 3
Training loss: 1.803690779593471
Validation loss: 2.2960003009153658

Epoch: 5| Step: 4
Training loss: 2.0343455275877926
Validation loss: 2.2729496603195707

Epoch: 5| Step: 5
Training loss: 2.3234544026132617
Validation loss: 2.2496195896564215

Epoch: 5| Step: 6
Training loss: 1.396348895990578
Validation loss: 2.269497197678157

Epoch: 5| Step: 7
Training loss: 1.797650974071972
Validation loss: 2.2886449594094667

Epoch: 5| Step: 8
Training loss: 1.1562573716212172
Validation loss: 2.289665958229293

Epoch: 5| Step: 9
Training loss: 2.051317707922561
Validation loss: 2.27862587596867

Epoch: 5| Step: 10
Training loss: 1.4083575244759574
Validation loss: 2.289361178491702

Epoch: 274| Step: 0
Training loss: 1.524071977001993
Validation loss: 2.272185175466875

Epoch: 5| Step: 1
Training loss: 1.0001812413005575
Validation loss: 2.3012386434039027

Epoch: 5| Step: 2
Training loss: 1.361385481076292
Validation loss: 2.3277695918536625

Epoch: 5| Step: 3
Training loss: 2.15688126763467
Validation loss: 2.341849960156107

Epoch: 5| Step: 4
Training loss: 1.7236837838824899
Validation loss: 2.3471576346198515

Epoch: 5| Step: 5
Training loss: 1.8705591381751074
Validation loss: 2.359758587792313

Epoch: 5| Step: 6
Training loss: 1.941416258757368
Validation loss: 2.372404388887417

Epoch: 5| Step: 7
Training loss: 1.795017310460176
Validation loss: 2.41907267801711

Epoch: 5| Step: 8
Training loss: 1.8820863961912777
Validation loss: 2.3865882377721914

Epoch: 5| Step: 9
Training loss: 1.7171325008342084
Validation loss: 2.330668992346038

Epoch: 5| Step: 10
Training loss: 2.134562239246388
Validation loss: 2.3609805349894444

Epoch: 275| Step: 0
Training loss: 1.6415058496134534
Validation loss: 2.315548982313934

Epoch: 5| Step: 1
Training loss: 2.1142369504960925
Validation loss: 2.2870233879221593

Epoch: 5| Step: 2
Training loss: 1.4541640309890136
Validation loss: 2.3026660739733726

Epoch: 5| Step: 3
Training loss: 2.035146995128009
Validation loss: 2.2587284785300477

Epoch: 5| Step: 4
Training loss: 2.1083534310128074
Validation loss: 2.30766767282802

Epoch: 5| Step: 5
Training loss: 1.7061082103349465
Validation loss: 2.3075364480066267

Epoch: 5| Step: 6
Training loss: 1.4058577096329832
Validation loss: 2.2618187762106774

Epoch: 5| Step: 7
Training loss: 1.518229812264237
Validation loss: 2.31542627068243

Epoch: 5| Step: 8
Training loss: 1.8443787359434456
Validation loss: 2.288900101166924

Epoch: 5| Step: 9
Training loss: 1.8234403530121412
Validation loss: 2.3118113296332474

Epoch: 5| Step: 10
Training loss: 1.4844553875488076
Validation loss: 2.2901050019648848

Epoch: 276| Step: 0
Training loss: 1.5832614966040917
Validation loss: 2.3095464483229824

Epoch: 5| Step: 1
Training loss: 1.6251304280683574
Validation loss: 2.299377526863749

Epoch: 5| Step: 2
Training loss: 2.053351950911963
Validation loss: 2.3190198783439433

Epoch: 5| Step: 3
Training loss: 1.5529507852089608
Validation loss: 2.3142947405361687

Epoch: 5| Step: 4
Training loss: 1.3904559429147734
Validation loss: 2.2987364920969307

Epoch: 5| Step: 5
Training loss: 1.6591562647791227
Validation loss: 2.3183899999148525

Epoch: 5| Step: 6
Training loss: 1.4440372098793837
Validation loss: 2.330846112034504

Epoch: 5| Step: 7
Training loss: 1.7929703456896495
Validation loss: 2.3058763972372103

Epoch: 5| Step: 8
Training loss: 1.8655900066934161
Validation loss: 2.322061281233229

Epoch: 5| Step: 9
Training loss: 2.296963540790525
Validation loss: 2.3072421346071934

Epoch: 5| Step: 10
Training loss: 1.6792998110454243
Validation loss: 2.317384248432163

Epoch: 277| Step: 0
Training loss: 1.9963236637175354
Validation loss: 2.3318444488424945

Epoch: 5| Step: 1
Training loss: 1.2596322868812495
Validation loss: 2.2827424614734713

Epoch: 5| Step: 2
Training loss: 1.8301613706303625
Validation loss: 2.3034691022081923

Epoch: 5| Step: 3
Training loss: 1.6117870440231121
Validation loss: 2.309719723572251

Epoch: 5| Step: 4
Training loss: 1.616791017737865
Validation loss: 2.275203374088449

Epoch: 5| Step: 5
Training loss: 1.656887507555133
Validation loss: 2.29205814907027

Epoch: 5| Step: 6
Training loss: 1.6038419551755705
Validation loss: 2.306012143955397

Epoch: 5| Step: 7
Training loss: 2.2777387168553735
Validation loss: 2.3083717682687865

Epoch: 5| Step: 8
Training loss: 1.6479967441063725
Validation loss: 2.3036051237727437

Epoch: 5| Step: 9
Training loss: 1.7026323078296393
Validation loss: 2.322570634479096

Epoch: 5| Step: 10
Training loss: 1.6746870972749797
Validation loss: 2.303918169558317

Epoch: 278| Step: 0
Training loss: 1.5291127450913904
Validation loss: 2.319739271377193

Epoch: 5| Step: 1
Training loss: 1.8392665467870624
Validation loss: 2.287505646883632

Epoch: 5| Step: 2
Training loss: 1.685713422731174
Validation loss: 2.2861721280057896

Epoch: 5| Step: 3
Training loss: 1.734941613371958
Validation loss: 2.2699069409930357

Epoch: 5| Step: 4
Training loss: 1.3917003288690226
Validation loss: 2.2705071011640405

Epoch: 5| Step: 5
Training loss: 1.3584963710428963
Validation loss: 2.2775475066059383

Epoch: 5| Step: 6
Training loss: 2.226500179020917
Validation loss: 2.291125852548826

Epoch: 5| Step: 7
Training loss: 1.7712406213656107
Validation loss: 2.288318349982509

Epoch: 5| Step: 8
Training loss: 1.2689904102627436
Validation loss: 2.312642624926403

Epoch: 5| Step: 9
Training loss: 2.2437266739081725
Validation loss: 2.30935102230493

Epoch: 5| Step: 10
Training loss: 1.6372313504755087
Validation loss: 2.2881154852950347

Epoch: 279| Step: 0
Training loss: 1.2952430752508544
Validation loss: 2.3072361245096618

Epoch: 5| Step: 1
Training loss: 2.5211865096261326
Validation loss: 2.314272152466294

Epoch: 5| Step: 2
Training loss: 1.7460919749274395
Validation loss: 2.3310548414687933

Epoch: 5| Step: 3
Training loss: 1.2795356352965372
Validation loss: 2.2950030314718837

Epoch: 5| Step: 4
Training loss: 1.450465403878321
Validation loss: 2.332239436977823

Epoch: 5| Step: 5
Training loss: 1.8677363526738364
Validation loss: 2.379525592641579

Epoch: 5| Step: 6
Training loss: 1.7407654573761493
Validation loss: 2.3381659394586305

Epoch: 5| Step: 7
Training loss: 1.8163770447710912
Validation loss: 2.3132808789212564

Epoch: 5| Step: 8
Training loss: 1.1788321924932623
Validation loss: 2.3288860124733826

Epoch: 5| Step: 9
Training loss: 1.52315217304997
Validation loss: 2.3080844889694507

Epoch: 5| Step: 10
Training loss: 1.751273577338771
Validation loss: 2.341036756740543

Epoch: 280| Step: 0
Training loss: 1.8637118371833923
Validation loss: 2.3385544065898607

Epoch: 5| Step: 1
Training loss: 1.2205417862130283
Validation loss: 2.287358180764313

Epoch: 5| Step: 2
Training loss: 1.627007198465527
Validation loss: 2.304087716783347

Epoch: 5| Step: 3
Training loss: 1.8158032800860988
Validation loss: 2.336549614028677

Epoch: 5| Step: 4
Training loss: 1.9300620761830232
Validation loss: 2.2864221009438013

Epoch: 5| Step: 5
Training loss: 1.636460240599915
Validation loss: 2.3066042980346775

Epoch: 5| Step: 6
Training loss: 1.8106864537958969
Validation loss: 2.289893164560041

Epoch: 5| Step: 7
Training loss: 1.7671805761928494
Validation loss: 2.339967816029586

Epoch: 5| Step: 8
Training loss: 1.205345482744606
Validation loss: 2.3197423431165545

Epoch: 5| Step: 9
Training loss: 2.0204355956161324
Validation loss: 2.3254476368823926

Epoch: 5| Step: 10
Training loss: 1.4217436174330265
Validation loss: 2.2875536174420104

Epoch: 281| Step: 0
Training loss: 1.5157498180471718
Validation loss: 2.267530934796318

Epoch: 5| Step: 1
Training loss: 1.606118397943402
Validation loss: 2.3571418462469773

Epoch: 5| Step: 2
Training loss: 1.5437010753462033
Validation loss: 2.3243412362294626

Epoch: 5| Step: 3
Training loss: 1.5857412282576926
Validation loss: 2.305063030000957

Epoch: 5| Step: 4
Training loss: 1.61101936850102
Validation loss: 2.265814736257025

Epoch: 5| Step: 5
Training loss: 2.4038002127145432
Validation loss: 2.286218455740604

Epoch: 5| Step: 6
Training loss: 1.3019265296616318
Validation loss: 2.2990605660769496

Epoch: 5| Step: 7
Training loss: 1.5729727913988465
Validation loss: 2.292159911367135

Epoch: 5| Step: 8
Training loss: 1.8241983612685553
Validation loss: 2.3041528425402973

Epoch: 5| Step: 9
Training loss: 1.490539279608282
Validation loss: 2.358968150806012

Epoch: 5| Step: 10
Training loss: 2.1083195058899435
Validation loss: 2.292323361459038

Epoch: 282| Step: 0
Training loss: 1.828945921117693
Validation loss: 2.2871083841165567

Epoch: 5| Step: 1
Training loss: 1.4310219795463746
Validation loss: 2.2759099321338234

Epoch: 5| Step: 2
Training loss: 1.5750674097076895
Validation loss: 2.274853382346542

Epoch: 5| Step: 3
Training loss: 1.2948972949979065
Validation loss: 2.302919861589389

Epoch: 5| Step: 4
Training loss: 1.3869713781493624
Validation loss: 2.3124813820738828

Epoch: 5| Step: 5
Training loss: 1.548352162370186
Validation loss: 2.303073128126288

Epoch: 5| Step: 6
Training loss: 1.7131595900619179
Validation loss: 2.322446757840531

Epoch: 5| Step: 7
Training loss: 2.19709840943592
Validation loss: 2.3340732753355566

Epoch: 5| Step: 8
Training loss: 1.6852280899884902
Validation loss: 2.3252302707429284

Epoch: 5| Step: 9
Training loss: 1.5006650404094446
Validation loss: 2.3202529589671546

Epoch: 5| Step: 10
Training loss: 2.3101481257254846
Validation loss: 2.266982331439414

Epoch: 283| Step: 0
Training loss: 1.5846033356887237
Validation loss: 2.3204201255253456

Epoch: 5| Step: 1
Training loss: 1.571433810435888
Validation loss: 2.274248433052633

Epoch: 5| Step: 2
Training loss: 2.1092368751796644
Validation loss: 2.3237635018333753

Epoch: 5| Step: 3
Training loss: 1.5238785325401252
Validation loss: 2.2754268385101954

Epoch: 5| Step: 4
Training loss: 1.3405317314088927
Validation loss: 2.3119225716480876

Epoch: 5| Step: 5
Training loss: 1.6692356417353933
Validation loss: 2.3069049743848824

Epoch: 5| Step: 6
Training loss: 1.2958735080554757
Validation loss: 2.316232318342174

Epoch: 5| Step: 7
Training loss: 1.8526350689243682
Validation loss: 2.3234893296745702

Epoch: 5| Step: 8
Training loss: 2.3738429614079415
Validation loss: 2.2924618912078136

Epoch: 5| Step: 9
Training loss: 1.2282953838160713
Validation loss: 2.361362922876387

Epoch: 5| Step: 10
Training loss: 1.802939422948102
Validation loss: 2.218018023551096

Epoch: 284| Step: 0
Training loss: 2.1076855711050184
Validation loss: 2.3595015772948034

Epoch: 5| Step: 1
Training loss: 1.933269373339993
Validation loss: 2.2701194418503348

Epoch: 5| Step: 2
Training loss: 1.2724414510691349
Validation loss: 2.256810447894786

Epoch: 5| Step: 3
Training loss: 1.7693717160425195
Validation loss: 2.30268101544835

Epoch: 5| Step: 4
Training loss: 1.4324100607287797
Validation loss: 2.306949662816054

Epoch: 5| Step: 5
Training loss: 1.869088454201054
Validation loss: 2.273562146957489

Epoch: 5| Step: 6
Training loss: 1.1263709192427507
Validation loss: 2.2848909714715266

Epoch: 5| Step: 7
Training loss: 1.3367010243598905
Validation loss: 2.2613125843963817

Epoch: 5| Step: 8
Training loss: 1.7087194270068777
Validation loss: 2.302292364724652

Epoch: 5| Step: 9
Training loss: 2.0336036544130685
Validation loss: 2.2837611318257536

Epoch: 5| Step: 10
Training loss: 1.7502657824729517
Validation loss: 2.2818934193044793

Epoch: 285| Step: 0
Training loss: 1.492512213243261
Validation loss: 2.293331574744938

Epoch: 5| Step: 1
Training loss: 1.548921868468633
Validation loss: 2.2769999626902533

Epoch: 5| Step: 2
Training loss: 2.0518200958835506
Validation loss: 2.297281679759029

Epoch: 5| Step: 3
Training loss: 1.624002150294567
Validation loss: 2.277253452336554

Epoch: 5| Step: 4
Training loss: 1.8360360626385654
Validation loss: 2.278431294878935

Epoch: 5| Step: 5
Training loss: 1.9278600278830864
Validation loss: 2.2927962236840935

Epoch: 5| Step: 6
Training loss: 1.8086184011802064
Validation loss: 2.2887105884405803

Epoch: 5| Step: 7
Training loss: 1.580903129075823
Validation loss: 2.3350161872456043

Epoch: 5| Step: 8
Training loss: 1.5074375457225915
Validation loss: 2.2907536191459266

Epoch: 5| Step: 9
Training loss: 1.1266799146016298
Validation loss: 2.2912549850729818

Epoch: 5| Step: 10
Training loss: 1.6749066825037822
Validation loss: 2.322694085091359

Epoch: 286| Step: 0
Training loss: 1.9206843836275183
Validation loss: 2.2670828152093736

Epoch: 5| Step: 1
Training loss: 1.679447600510027
Validation loss: 2.28674273675271

Epoch: 5| Step: 2
Training loss: 1.7722877438842126
Validation loss: 2.2931194965476043

Epoch: 5| Step: 3
Training loss: 1.8440839174129413
Validation loss: 2.2853415445712786

Epoch: 5| Step: 4
Training loss: 1.5471228198741658
Validation loss: 2.2647550749401013

Epoch: 5| Step: 5
Training loss: 1.339957718965002
Validation loss: 2.3120919022432482

Epoch: 5| Step: 6
Training loss: 1.7209651890347772
Validation loss: 2.2841890601947754

Epoch: 5| Step: 7
Training loss: 1.6924032396073194
Validation loss: 2.2786148942994564

Epoch: 5| Step: 8
Training loss: 1.8798436861796792
Validation loss: 2.357079689855914

Epoch: 5| Step: 9
Training loss: 1.4011685433306937
Validation loss: 2.2644200595742365

Epoch: 5| Step: 10
Training loss: 1.2725387397220262
Validation loss: 2.3203986704237742

Epoch: 287| Step: 0
Training loss: 1.3240183900927402
Validation loss: 2.252839098037804

Epoch: 5| Step: 1
Training loss: 1.313953140189656
Validation loss: 2.2604861902083657

Epoch: 5| Step: 2
Training loss: 1.406487466047726
Validation loss: 2.318149685474755

Epoch: 5| Step: 3
Training loss: 1.7923135329000546
Validation loss: 2.333366057244108

Epoch: 5| Step: 4
Training loss: 1.2944148064814476
Validation loss: 2.3207704162582288

Epoch: 5| Step: 5
Training loss: 1.6907613815608167
Validation loss: 2.339295587742379

Epoch: 5| Step: 6
Training loss: 1.3676964820567223
Validation loss: 2.3220795319904943

Epoch: 5| Step: 7
Training loss: 1.8016908545315797
Validation loss: 2.268963723672917

Epoch: 5| Step: 8
Training loss: 1.5366767167750874
Validation loss: 2.273473108636701

Epoch: 5| Step: 9
Training loss: 1.9170393857815162
Validation loss: 2.2637975188718333

Epoch: 5| Step: 10
Training loss: 2.503944051519696
Validation loss: 2.3116704644140946

Epoch: 288| Step: 0
Training loss: 2.225481272734999
Validation loss: 2.3468222397345553

Epoch: 5| Step: 1
Training loss: 1.9307913769589689
Validation loss: 2.2646351587975233

Epoch: 5| Step: 2
Training loss: 1.4051875869580601
Validation loss: 2.289219114920901

Epoch: 5| Step: 3
Training loss: 1.9279679888287788
Validation loss: 2.27007900868051

Epoch: 5| Step: 4
Training loss: 1.3595214852518474
Validation loss: 2.258758100513766

Epoch: 5| Step: 5
Training loss: 1.243256307027879
Validation loss: 2.3148412296424214

Epoch: 5| Step: 6
Training loss: 1.568355270513387
Validation loss: 2.3043738578451505

Epoch: 5| Step: 7
Training loss: 1.4454449567155045
Validation loss: 2.323381911976162

Epoch: 5| Step: 8
Training loss: 1.5942032861300766
Validation loss: 2.3343562141588685

Epoch: 5| Step: 9
Training loss: 1.3316445782245516
Validation loss: 2.290808903275205

Epoch: 5| Step: 10
Training loss: 1.9762913815764083
Validation loss: 2.3079295624616134

Epoch: 289| Step: 0
Training loss: 1.46662505625451
Validation loss: 2.274541403817743

Epoch: 5| Step: 1
Training loss: 1.493116319390824
Validation loss: 2.305525877898665

Epoch: 5| Step: 2
Training loss: 1.6856726182909623
Validation loss: 2.3292106788772937

Epoch: 5| Step: 3
Training loss: 1.6051338384803975
Validation loss: 2.3356912019178013

Epoch: 5| Step: 4
Training loss: 1.628277041901379
Validation loss: 2.295643623502784

Epoch: 5| Step: 5
Training loss: 1.7327625924465897
Validation loss: 2.325314972318838

Epoch: 5| Step: 6
Training loss: 1.5763418869353298
Validation loss: 2.3368865611526957

Epoch: 5| Step: 7
Training loss: 2.155101304295207
Validation loss: 2.332492429269064

Epoch: 5| Step: 8
Training loss: 1.6996465034962194
Validation loss: 2.331917317893394

Epoch: 5| Step: 9
Training loss: 1.8066202358435621
Validation loss: 2.308541803514887

Epoch: 5| Step: 10
Training loss: 1.4864760938018673
Validation loss: 2.243978474463075

Epoch: 290| Step: 0
Training loss: 1.4819581282719887
Validation loss: 2.267207145525236

Epoch: 5| Step: 1
Training loss: 1.48876272508386
Validation loss: 2.312393921600562

Epoch: 5| Step: 2
Training loss: 1.5771033879982463
Validation loss: 2.269210170595618

Epoch: 5| Step: 3
Training loss: 1.6081325586870021
Validation loss: 2.3119623301355667

Epoch: 5| Step: 4
Training loss: 2.23435291199337
Validation loss: 2.268392362005652

Epoch: 5| Step: 5
Training loss: 1.614496839934299
Validation loss: 2.3054590645686166

Epoch: 5| Step: 6
Training loss: 1.7558879574156183
Validation loss: 2.250684652792667

Epoch: 5| Step: 7
Training loss: 1.798751116998152
Validation loss: 2.290175613063897

Epoch: 5| Step: 8
Training loss: 1.7234910944527915
Validation loss: 2.265499033695206

Epoch: 5| Step: 9
Training loss: 1.4740166894079172
Validation loss: 2.323134697680214

Epoch: 5| Step: 10
Training loss: 1.1879826618881688
Validation loss: 2.3034920143485067

Epoch: 291| Step: 0
Training loss: 1.3103794042063313
Validation loss: 2.2740436739988383

Epoch: 5| Step: 1
Training loss: 1.759890671498847
Validation loss: 2.2923348173416036

Epoch: 5| Step: 2
Training loss: 1.8220210100296264
Validation loss: 2.275811721571117

Epoch: 5| Step: 3
Training loss: 1.6336479422484658
Validation loss: 2.281424804094606

Epoch: 5| Step: 4
Training loss: 1.7765222013091715
Validation loss: 2.2940761000285996

Epoch: 5| Step: 5
Training loss: 1.6322056861081926
Validation loss: 2.287454663334022

Epoch: 5| Step: 6
Training loss: 2.09854067550914
Validation loss: 2.2810644337553936

Epoch: 5| Step: 7
Training loss: 1.537109840325136
Validation loss: 2.302778583829959

Epoch: 5| Step: 8
Training loss: 1.6950668649228704
Validation loss: 2.2976540918448833

Epoch: 5| Step: 9
Training loss: 1.182387539957698
Validation loss: 2.2765566697817636

Epoch: 5| Step: 10
Training loss: 1.7767054491062695
Validation loss: 2.306690427078186

Epoch: 292| Step: 0
Training loss: 1.2757290307948697
Validation loss: 2.2971996630129334

Epoch: 5| Step: 1
Training loss: 1.9289922040759055
Validation loss: 2.3173056337090756

Epoch: 5| Step: 2
Training loss: 1.4060488239075455
Validation loss: 2.3030072349175477

Epoch: 5| Step: 3
Training loss: 1.474200099711867
Validation loss: 2.312836369531764

Epoch: 5| Step: 4
Training loss: 1.31374459066829
Validation loss: 2.3395500644542135

Epoch: 5| Step: 5
Training loss: 1.774736441266382
Validation loss: 2.264116421332457

Epoch: 5| Step: 6
Training loss: 1.1275604568479005
Validation loss: 2.261715675966976

Epoch: 5| Step: 7
Training loss: 1.8833407219035736
Validation loss: 2.268728638046735

Epoch: 5| Step: 8
Training loss: 1.3540266209102636
Validation loss: 2.302266640121753

Epoch: 5| Step: 9
Training loss: 1.8180857779323285
Validation loss: 2.3078861493396894

Epoch: 5| Step: 10
Training loss: 2.3991889894627776
Validation loss: 2.2752677638201124

Epoch: 293| Step: 0
Training loss: 1.463987868451576
Validation loss: 2.26439393812231

Epoch: 5| Step: 1
Training loss: 1.8011083740212532
Validation loss: 2.2998027428683523

Epoch: 5| Step: 2
Training loss: 1.7792204956678612
Validation loss: 2.3153732385028785

Epoch: 5| Step: 3
Training loss: 1.4644668297623689
Validation loss: 2.308225659662737

Epoch: 5| Step: 4
Training loss: 1.7226494683026232
Validation loss: 2.3079546130137563

Epoch: 5| Step: 5
Training loss: 1.8653610426149196
Validation loss: 2.3616390534001686

Epoch: 5| Step: 6
Training loss: 1.368433793004763
Validation loss: 2.2484331942369002

Epoch: 5| Step: 7
Training loss: 1.6902859614033179
Validation loss: 2.303794042210034

Epoch: 5| Step: 8
Training loss: 1.533432475630445
Validation loss: 2.310426564057038

Epoch: 5| Step: 9
Training loss: 1.44763813038339
Validation loss: 2.315088070477212

Epoch: 5| Step: 10
Training loss: 1.701213498925694
Validation loss: 2.3451008590599187

Epoch: 294| Step: 0
Training loss: 1.251776148625626
Validation loss: 2.2912207750448075

Epoch: 5| Step: 1
Training loss: 1.6192553287457883
Validation loss: 2.319705194634706

Epoch: 5| Step: 2
Training loss: 1.3994351030725904
Validation loss: 2.275267521570486

Epoch: 5| Step: 3
Training loss: 1.510267166982277
Validation loss: 2.3469785716473455

Epoch: 5| Step: 4
Training loss: 1.6762952038659988
Validation loss: 2.331057021775791

Epoch: 5| Step: 5
Training loss: 1.6981915756501835
Validation loss: 2.3130731567999834

Epoch: 5| Step: 6
Training loss: 2.472747270737834
Validation loss: 2.330559398641387

Epoch: 5| Step: 7
Training loss: 1.7478662834438465
Validation loss: 2.3058516626499586

Epoch: 5| Step: 8
Training loss: 1.4556281567117966
Validation loss: 2.317723801494295

Epoch: 5| Step: 9
Training loss: 1.3281125236374005
Validation loss: 2.355061694064435

Epoch: 5| Step: 10
Training loss: 1.3922022329593393
Validation loss: 2.3171636000497866

Epoch: 295| Step: 0
Training loss: 1.2939978707633564
Validation loss: 2.2477302337181437

Epoch: 5| Step: 1
Training loss: 1.2836143264467907
Validation loss: 2.281648700759363

Epoch: 5| Step: 2
Training loss: 1.6036115239004058
Validation loss: 2.252287785148082

Epoch: 5| Step: 3
Training loss: 1.8465854372597033
Validation loss: 2.3017873095318704

Epoch: 5| Step: 4
Training loss: 2.227050941833611
Validation loss: 2.294105019748321

Epoch: 5| Step: 5
Training loss: 1.6881212574402875
Validation loss: 2.2828244423045554

Epoch: 5| Step: 6
Training loss: 2.279580328280514
Validation loss: 2.2686586713780756

Epoch: 5| Step: 7
Training loss: 1.4059972747895702
Validation loss: 2.330683648155397

Epoch: 5| Step: 8
Training loss: 1.2031760762259724
Validation loss: 2.238868802768981

Epoch: 5| Step: 9
Training loss: 1.555713257667295
Validation loss: 2.260156442305118

Epoch: 5| Step: 10
Training loss: 1.3270758131084628
Validation loss: 2.3096830854104637

Epoch: 296| Step: 0
Training loss: 2.170122496140343
Validation loss: 2.317041793239543

Epoch: 5| Step: 1
Training loss: 1.6049610086856456
Validation loss: 2.2714609774770755

Epoch: 5| Step: 2
Training loss: 1.0552605096708936
Validation loss: 2.3157098515986627

Epoch: 5| Step: 3
Training loss: 1.96405535251285
Validation loss: 2.2721092031974015

Epoch: 5| Step: 4
Training loss: 1.7516208363328842
Validation loss: 2.3094087352495274

Epoch: 5| Step: 5
Training loss: 0.9629385667360342
Validation loss: 2.297508666321336

Epoch: 5| Step: 6
Training loss: 1.6082002370575388
Validation loss: 2.3172219050230534

Epoch: 5| Step: 7
Training loss: 1.422352553437488
Validation loss: 2.2946185598001496

Epoch: 5| Step: 8
Training loss: 1.4040657033571726
Validation loss: 2.28427071470576

Epoch: 5| Step: 9
Training loss: 1.4152982591555656
Validation loss: 2.3130594678169567

Epoch: 5| Step: 10
Training loss: 1.7929255328652516
Validation loss: 2.3202545555428338

Epoch: 297| Step: 0
Training loss: 1.7703928754965685
Validation loss: 2.2940670336957196

Epoch: 5| Step: 1
Training loss: 1.7566495311970205
Validation loss: 2.2851969722754575

Epoch: 5| Step: 2
Training loss: 1.7353139174483225
Validation loss: 2.308984047509046

Epoch: 5| Step: 3
Training loss: 1.7520596100799652
Validation loss: 2.272254066649643

Epoch: 5| Step: 4
Training loss: 1.6868516594882208
Validation loss: 2.317104854369357

Epoch: 5| Step: 5
Training loss: 1.3415461809937184
Validation loss: 2.2745921110172547

Epoch: 5| Step: 6
Training loss: 1.6919013657645148
Validation loss: 2.30753913770211

Epoch: 5| Step: 7
Training loss: 1.4878102756316158
Validation loss: 2.2901483497226205

Epoch: 5| Step: 8
Training loss: 1.0168851810407544
Validation loss: 2.2915061667014593

Epoch: 5| Step: 9
Training loss: 1.446136487167519
Validation loss: 2.2863523376624406

Epoch: 5| Step: 10
Training loss: 1.9809257386377916
Validation loss: 2.2841069134061973

Epoch: 298| Step: 0
Training loss: 1.4965129693231178
Validation loss: 2.26151301860382

Epoch: 5| Step: 1
Training loss: 1.4635818132027973
Validation loss: 2.322287321724584

Epoch: 5| Step: 2
Training loss: 1.6397445496045302
Validation loss: 2.2339379941481075

Epoch: 5| Step: 3
Training loss: 1.3554658477488293
Validation loss: 2.2743686305211925

Epoch: 5| Step: 4
Training loss: 2.0790139498332074
Validation loss: 2.3373360368895173

Epoch: 5| Step: 5
Training loss: 1.332421119888794
Validation loss: 2.306183657684214

Epoch: 5| Step: 6
Training loss: 1.1355721895055506
Validation loss: 2.299543185833992

Epoch: 5| Step: 7
Training loss: 1.8878919535529026
Validation loss: 2.304621234689912

Epoch: 5| Step: 8
Training loss: 1.885971711234822
Validation loss: 2.2831919758685175

Epoch: 5| Step: 9
Training loss: 1.5462906629663231
Validation loss: 2.3205799274469703

Epoch: 5| Step: 10
Training loss: 1.6911903578341718
Validation loss: 2.290444546771305

Epoch: 299| Step: 0
Training loss: 1.4996606919852955
Validation loss: 2.3249570759456164

Epoch: 5| Step: 1
Training loss: 1.7917712498976646
Validation loss: 2.292697903425264

Epoch: 5| Step: 2
Training loss: 1.4733498151786502
Validation loss: 2.3244989245747454

Epoch: 5| Step: 3
Training loss: 1.3111782230336493
Validation loss: 2.2640144255795374

Epoch: 5| Step: 4
Training loss: 1.1376697455549971
Validation loss: 2.286297528289426

Epoch: 5| Step: 5
Training loss: 2.5082660395655876
Validation loss: 2.2700933583118026

Epoch: 5| Step: 6
Training loss: 1.2393566960893871
Validation loss: 2.2559326103165445

Epoch: 5| Step: 7
Training loss: 1.6141139506940627
Validation loss: 2.275858212893129

Epoch: 5| Step: 8
Training loss: 1.6064276511662132
Validation loss: 2.279892459505378

Epoch: 5| Step: 9
Training loss: 1.6350906030825008
Validation loss: 2.2819513660693485

Epoch: 5| Step: 10
Training loss: 1.3598516220606556
Validation loss: 2.2769795441070446

Epoch: 300| Step: 0
Training loss: 1.758754494775859
Validation loss: 2.2732793078259332

Epoch: 5| Step: 1
Training loss: 1.591637801196539
Validation loss: 2.286522421068446

Epoch: 5| Step: 2
Training loss: 1.622225887731362
Validation loss: 2.307547081228915

Epoch: 5| Step: 3
Training loss: 1.5650489615438294
Validation loss: 2.3033057685602865

Epoch: 5| Step: 4
Training loss: 1.688161296546076
Validation loss: 2.2965417028142134

Epoch: 5| Step: 5
Training loss: 1.7770165446149355
Validation loss: 2.2739644154805188

Epoch: 5| Step: 6
Training loss: 1.3743417638183486
Validation loss: 2.282093163671254

Epoch: 5| Step: 7
Training loss: 0.9257434563628285
Validation loss: 2.271384370939556

Epoch: 5| Step: 8
Training loss: 1.1904188723616593
Validation loss: 2.291798731185881

Epoch: 5| Step: 9
Training loss: 1.3198289154906258
Validation loss: 2.2918350131790115

Epoch: 5| Step: 10
Training loss: 2.4223189408516164
Validation loss: 2.316669185717029

Epoch: 301| Step: 0
Training loss: 1.5748158120130613
Validation loss: 2.302468995078424

Epoch: 5| Step: 1
Training loss: 1.8635927975504163
Validation loss: 2.3473659052807223

Epoch: 5| Step: 2
Training loss: 1.4264811430980713
Validation loss: 2.3209817152691494

Epoch: 5| Step: 3
Training loss: 1.6549233935740448
Validation loss: 2.2905570486401343

Epoch: 5| Step: 4
Training loss: 1.5662923947477772
Validation loss: 2.320281952389336

Epoch: 5| Step: 5
Training loss: 1.4430753973113946
Validation loss: 2.310242446409441

Epoch: 5| Step: 6
Training loss: 1.4857064148673447
Validation loss: 2.2794122594048

Epoch: 5| Step: 7
Training loss: 1.4600436490209834
Validation loss: 2.302098179850388

Epoch: 5| Step: 8
Training loss: 2.05442083100486
Validation loss: 2.3034912503173848

Epoch: 5| Step: 9
Training loss: 1.2000106036194569
Validation loss: 2.294083345917099

Epoch: 5| Step: 10
Training loss: 1.808713048044724
Validation loss: 2.319996826380453

Epoch: 302| Step: 0
Training loss: 1.4460803492423384
Validation loss: 2.285753871004351

Epoch: 5| Step: 1
Training loss: 1.6228498759337278
Validation loss: 2.293727083492102

Epoch: 5| Step: 2
Training loss: 1.7773017626822816
Validation loss: 2.2740280815827396

Epoch: 5| Step: 3
Training loss: 2.1159441348022408
Validation loss: 2.2223938053639727

Epoch: 5| Step: 4
Training loss: 1.8124039065439945
Validation loss: 2.273431874149738

Epoch: 5| Step: 5
Training loss: 1.7009397714078625
Validation loss: 2.2328869808273555

Epoch: 5| Step: 6
Training loss: 1.3738308183883892
Validation loss: 2.288154919108089

Epoch: 5| Step: 7
Training loss: 1.7077558363215974
Validation loss: 2.2466665605261604

Epoch: 5| Step: 8
Training loss: 1.570052319887993
Validation loss: 2.2774351033390716

Epoch: 5| Step: 9
Training loss: 1.0671526075163205
Validation loss: 2.2825350926825565

Epoch: 5| Step: 10
Training loss: 1.3947575489721264
Validation loss: 2.3155754589006703

Epoch: 303| Step: 0
Training loss: 1.7212937691192531
Validation loss: 2.2531838740849666

Epoch: 5| Step: 1
Training loss: 1.5722224069661876
Validation loss: 2.2961954463903975

Epoch: 5| Step: 2
Training loss: 2.0153175533525305
Validation loss: 2.2650595678283514

Epoch: 5| Step: 3
Training loss: 1.253949601324205
Validation loss: 2.3134620126627814

Epoch: 5| Step: 4
Training loss: 1.5004314755711177
Validation loss: 2.3102934009032103

Epoch: 5| Step: 5
Training loss: 1.5169135053515397
Validation loss: 2.3183486664129194

Epoch: 5| Step: 6
Training loss: 1.3565046326290655
Validation loss: 2.2898575884717918

Epoch: 5| Step: 7
Training loss: 1.9005204692522075
Validation loss: 2.3161711328017414

Epoch: 5| Step: 8
Training loss: 1.5796714985656788
Validation loss: 2.2786692964016786

Epoch: 5| Step: 9
Training loss: 1.384772253625928
Validation loss: 2.2498024041336766

Epoch: 5| Step: 10
Training loss: 1.2887270866747305
Validation loss: 2.2715910089434566

Epoch: 304| Step: 0
Training loss: 1.4529705170582614
Validation loss: 2.259633476712963

Epoch: 5| Step: 1
Training loss: 1.2459333549757783
Validation loss: 2.279284126478136

Epoch: 5| Step: 2
Training loss: 1.915298249846289
Validation loss: 2.2559365581648687

Epoch: 5| Step: 3
Training loss: 1.4214149820865294
Validation loss: 2.2849093788788712

Epoch: 5| Step: 4
Training loss: 1.5153677023919834
Validation loss: 2.300521297440347

Epoch: 5| Step: 5
Training loss: 1.0613413832717034
Validation loss: 2.3249083300780797

Epoch: 5| Step: 6
Training loss: 1.58393703629844
Validation loss: 2.299522621817159

Epoch: 5| Step: 7
Training loss: 2.145529703923649
Validation loss: 2.2414435793678105

Epoch: 5| Step: 8
Training loss: 1.288174780152597
Validation loss: 2.3158190548677235

Epoch: 5| Step: 9
Training loss: 1.9043271106373694
Validation loss: 2.278689860725771

Epoch: 5| Step: 10
Training loss: 1.7784391611721906
Validation loss: 2.331289130048557

Epoch: 305| Step: 0
Training loss: 2.0400203632759566
Validation loss: 2.263547384478935

Epoch: 5| Step: 1
Training loss: 2.1015749792699885
Validation loss: 2.2675862853913036

Epoch: 5| Step: 2
Training loss: 1.4460493529195682
Validation loss: 2.2700200219513884

Epoch: 5| Step: 3
Training loss: 1.083015187326953
Validation loss: 2.2959513070603657

Epoch: 5| Step: 4
Training loss: 0.9919226585817617
Validation loss: 2.2753883445954006

Epoch: 5| Step: 5
Training loss: 1.53461693373323
Validation loss: 2.2757243979557202

Epoch: 5| Step: 6
Training loss: 1.9185027022155072
Validation loss: 2.2719278214585295

Epoch: 5| Step: 7
Training loss: 1.8041924131933553
Validation loss: 2.3436261062964205

Epoch: 5| Step: 8
Training loss: 1.502644274444634
Validation loss: 2.30354210596856

Epoch: 5| Step: 9
Training loss: 1.1024765118542748
Validation loss: 2.3081706238672948

Epoch: 5| Step: 10
Training loss: 1.5464880102798506
Validation loss: 2.3124151084015936

Epoch: 306| Step: 0
Training loss: 1.8276220428586893
Validation loss: 2.264037759649206

Epoch: 5| Step: 1
Training loss: 1.2459943964940876
Validation loss: 2.287654442664079

Epoch: 5| Step: 2
Training loss: 1.640129450480695
Validation loss: 2.313366733346377

Epoch: 5| Step: 3
Training loss: 1.5582688836762473
Validation loss: 2.335945109901896

Epoch: 5| Step: 4
Training loss: 1.750715245811758
Validation loss: 2.322115942545831

Epoch: 5| Step: 5
Training loss: 2.1638088697405937
Validation loss: 2.325299071025572

Epoch: 5| Step: 6
Training loss: 1.4501197666823173
Validation loss: 2.3172051117922763

Epoch: 5| Step: 7
Training loss: 1.3040070272531314
Validation loss: 2.3175240871470932

Epoch: 5| Step: 8
Training loss: 1.645532950823375
Validation loss: 2.2968673454795

Epoch: 5| Step: 9
Training loss: 1.532353684626633
Validation loss: 2.269874776485488

Epoch: 5| Step: 10
Training loss: 0.9585302641224308
Validation loss: 2.27608842961964

Epoch: 307| Step: 0
Training loss: 1.2802465277432726
Validation loss: 2.3008554454559107

Epoch: 5| Step: 1
Training loss: 1.5004508612473193
Validation loss: 2.3193405168938237

Epoch: 5| Step: 2
Training loss: 1.2244285437816327
Validation loss: 2.32105781862938

Epoch: 5| Step: 3
Training loss: 1.5708120889348594
Validation loss: 2.268208338906987

Epoch: 5| Step: 4
Training loss: 1.8354302537511165
Validation loss: 2.330126715407033

Epoch: 5| Step: 5
Training loss: 1.3876761556614472
Validation loss: 2.3121231839678567

Epoch: 5| Step: 6
Training loss: 1.8093009208839201
Validation loss: 2.3161379980761017

Epoch: 5| Step: 7
Training loss: 1.9358767816290665
Validation loss: 2.338169914022304

Epoch: 5| Step: 8
Training loss: 1.3675026230725895
Validation loss: 2.3203065104990936

Epoch: 5| Step: 9
Training loss: 1.4118411071816104
Validation loss: 2.269960738357477

Epoch: 5| Step: 10
Training loss: 1.5775390141373646
Validation loss: 2.3169831241356342

Epoch: 308| Step: 0
Training loss: 1.7935692938719057
Validation loss: 2.282769803156636

Epoch: 5| Step: 1
Training loss: 1.560248622155922
Validation loss: 2.249130845684884

Epoch: 5| Step: 2
Training loss: 1.7412179207568181
Validation loss: 2.280016691732915

Epoch: 5| Step: 3
Training loss: 1.6786359467325243
Validation loss: 2.2509550246302568

Epoch: 5| Step: 4
Training loss: 1.2573020325712465
Validation loss: 2.3200973964023524

Epoch: 5| Step: 5
Training loss: 0.9824415929192023
Validation loss: 2.294943053864111

Epoch: 5| Step: 6
Training loss: 1.7235045128639572
Validation loss: 2.291462475432522

Epoch: 5| Step: 7
Training loss: 1.44914224839144
Validation loss: 2.304443255219322

Epoch: 5| Step: 8
Training loss: 1.2969909064651328
Validation loss: 2.2636015232546436

Epoch: 5| Step: 9
Training loss: 2.1817149369058204
Validation loss: 2.292246545119683

Epoch: 5| Step: 10
Training loss: 1.3743901634333928
Validation loss: 2.2670236470490814

Epoch: 309| Step: 0
Training loss: 1.5461858890598608
Validation loss: 2.3290940458118348

Epoch: 5| Step: 1
Training loss: 1.5271233206904673
Validation loss: 2.3064833429547527

Epoch: 5| Step: 2
Training loss: 1.3970216371175448
Validation loss: 2.2914970924381355

Epoch: 5| Step: 3
Training loss: 1.316873801311858
Validation loss: 2.2676798264990436

Epoch: 5| Step: 4
Training loss: 1.5216727966458097
Validation loss: 2.3158989194607296

Epoch: 5| Step: 5
Training loss: 1.7098005863386365
Validation loss: 2.3135582349220463

Epoch: 5| Step: 6
Training loss: 1.5846626908382557
Validation loss: 2.268683612019064

Epoch: 5| Step: 7
Training loss: 1.64834254565363
Validation loss: 2.2988489991171335

Epoch: 5| Step: 8
Training loss: 2.071605811029575
Validation loss: 2.2566501461102986

Epoch: 5| Step: 9
Training loss: 1.5156653487350296
Validation loss: 2.304290277848556

Epoch: 5| Step: 10
Training loss: 1.6002529838354216
Validation loss: 2.3396935310045475

Epoch: 310| Step: 0
Training loss: 1.6434429853789898
Validation loss: 2.326613024503333

Epoch: 5| Step: 1
Training loss: 1.0302247239298155
Validation loss: 2.2570365636645575

Epoch: 5| Step: 2
Training loss: 1.7650568225132128
Validation loss: 2.311760022125583

Epoch: 5| Step: 3
Training loss: 1.5413588998504513
Validation loss: 2.309732167029113

Epoch: 5| Step: 4
Training loss: 1.5395884897905374
Validation loss: 2.2293865216961057

Epoch: 5| Step: 5
Training loss: 1.3599936294406458
Validation loss: 2.3060423191835198

Epoch: 5| Step: 6
Training loss: 1.3413130375108406
Validation loss: 2.252695379924332

Epoch: 5| Step: 7
Training loss: 1.9374076452086093
Validation loss: 2.26509516330037

Epoch: 5| Step: 8
Training loss: 1.3040732576761584
Validation loss: 2.284082685538435

Epoch: 5| Step: 9
Training loss: 1.3893020423338724
Validation loss: 2.2804596403160526

Epoch: 5| Step: 10
Training loss: 2.0978542355210603
Validation loss: 2.2612005010483145

Epoch: 311| Step: 0
Training loss: 1.1460902821827064
Validation loss: 2.2904389324737635

Epoch: 5| Step: 1
Training loss: 1.0367475262739567
Validation loss: 2.243908899120351

Epoch: 5| Step: 2
Training loss: 1.3342052628706274
Validation loss: 2.2054217104025713

Epoch: 5| Step: 3
Training loss: 1.566829557608167
Validation loss: 2.2902057842658365

Epoch: 5| Step: 4
Training loss: 1.4446147987379847
Validation loss: 2.281081535759499

Epoch: 5| Step: 5
Training loss: 1.5494438188725679
Validation loss: 2.2838731496655766

Epoch: 5| Step: 6
Training loss: 1.8247238864788822
Validation loss: 2.263924150007565

Epoch: 5| Step: 7
Training loss: 1.338161246224427
Validation loss: 2.2928235427532

Epoch: 5| Step: 8
Training loss: 2.2535425484421543
Validation loss: 2.2833928200354845

Epoch: 5| Step: 9
Training loss: 1.5553904722051666
Validation loss: 2.2987855442466847

Epoch: 5| Step: 10
Training loss: 1.474300609877206
Validation loss: 2.3098097265136235

Epoch: 312| Step: 0
Training loss: 1.5222946183808728
Validation loss: 2.277100623049331

Epoch: 5| Step: 1
Training loss: 1.218925610141479
Validation loss: 2.2878351316950964

Epoch: 5| Step: 2
Training loss: 1.6520762125497581
Validation loss: 2.2614350689771765

Epoch: 5| Step: 3
Training loss: 1.4104189641230402
Validation loss: 2.271225166063807

Epoch: 5| Step: 4
Training loss: 1.8138159874362385
Validation loss: 2.322644760821798

Epoch: 5| Step: 5
Training loss: 1.3221344875742926
Validation loss: 2.3262574569886705

Epoch: 5| Step: 6
Training loss: 1.3114600375737315
Validation loss: 2.292311331798077

Epoch: 5| Step: 7
Training loss: 1.4437443654664637
Validation loss: 2.274629475006201

Epoch: 5| Step: 8
Training loss: 1.5641371732982088
Validation loss: 2.2784813714981187

Epoch: 5| Step: 9
Training loss: 1.5046498231538037
Validation loss: 2.2958647734653677

Epoch: 5| Step: 10
Training loss: 2.2186161054587337
Validation loss: 2.2688476635493524

Epoch: 313| Step: 0
Training loss: 1.6891618951705942
Validation loss: 2.2605176660860513

Epoch: 5| Step: 1
Training loss: 1.400709639940542
Validation loss: 2.2886975658369475

Epoch: 5| Step: 2
Training loss: 1.8826750392516018
Validation loss: 2.2618236587906364

Epoch: 5| Step: 3
Training loss: 1.5739996594352306
Validation loss: 2.2493407424162446

Epoch: 5| Step: 4
Training loss: 1.181634874566328
Validation loss: 2.300215892503612

Epoch: 5| Step: 5
Training loss: 1.2410445803397334
Validation loss: 2.2127594299035764

Epoch: 5| Step: 6
Training loss: 2.3562923275816225
Validation loss: 2.2843997734971797

Epoch: 5| Step: 7
Training loss: 1.4209952514805335
Validation loss: 2.2253437039010597

Epoch: 5| Step: 8
Training loss: 1.3983281694861733
Validation loss: 2.3082511046113234

Epoch: 5| Step: 9
Training loss: 1.537193984304743
Validation loss: 2.2797334535167044

Epoch: 5| Step: 10
Training loss: 1.0777748202636184
Validation loss: 2.267935384257996

Epoch: 314| Step: 0
Training loss: 1.4090204287686672
Validation loss: 2.257221914946107

Epoch: 5| Step: 1
Training loss: 1.3281100103990973
Validation loss: 2.291608626972176

Epoch: 5| Step: 2
Training loss: 1.8638414864245656
Validation loss: 2.28975366768363

Epoch: 5| Step: 3
Training loss: 1.4908509185220147
Validation loss: 2.3511379683053035

Epoch: 5| Step: 4
Training loss: 1.3624280210608253
Validation loss: 2.303717458123226

Epoch: 5| Step: 5
Training loss: 1.4322594193960996
Validation loss: 2.315080056484298

Epoch: 5| Step: 6
Training loss: 2.256429492858994
Validation loss: 2.270931943581448

Epoch: 5| Step: 7
Training loss: 1.4048025947578338
Validation loss: 2.317786383942118

Epoch: 5| Step: 8
Training loss: 1.61942626495074
Validation loss: 2.3438483793879152

Epoch: 5| Step: 9
Training loss: 1.4339920031272695
Validation loss: 2.2890423838897567

Epoch: 5| Step: 10
Training loss: 1.4337558083054909
Validation loss: 2.3012713482019778

Epoch: 315| Step: 0
Training loss: 1.6756683524989449
Validation loss: 2.3100413283921686

Epoch: 5| Step: 1
Training loss: 1.5338045726415979
Validation loss: 2.2654894840954936

Epoch: 5| Step: 2
Training loss: 1.6745528407127412
Validation loss: 2.299556597413779

Epoch: 5| Step: 3
Training loss: 1.3650502092957297
Validation loss: 2.236861840507131

Epoch: 5| Step: 4
Training loss: 1.2689299112929227
Validation loss: 2.327126244093819

Epoch: 5| Step: 5
Training loss: 1.6497477887759222
Validation loss: 2.300786209511979

Epoch: 5| Step: 6
Training loss: 2.0457238607646815
Validation loss: 2.233844439660465

Epoch: 5| Step: 7
Training loss: 1.283273819786121
Validation loss: 2.2724009086925987

Epoch: 5| Step: 8
Training loss: 1.357017577634465
Validation loss: 2.2837503799973486

Epoch: 5| Step: 9
Training loss: 1.6451343871069761
Validation loss: 2.264279183571955

Epoch: 5| Step: 10
Training loss: 1.234496484886656
Validation loss: 2.280570948000844

Epoch: 316| Step: 0
Training loss: 1.049229379970759
Validation loss: 2.2820373055382848

Epoch: 5| Step: 1
Training loss: 1.171002533702243
Validation loss: 2.255170662160885

Epoch: 5| Step: 2
Training loss: 1.5748664526859972
Validation loss: 2.229644899665348

Epoch: 5| Step: 3
Training loss: 1.4176532825298904
Validation loss: 2.302048829116642

Epoch: 5| Step: 4
Training loss: 1.6541323529327019
Validation loss: 2.313792971677802

Epoch: 5| Step: 5
Training loss: 1.8543421487241538
Validation loss: 2.294701561442529

Epoch: 5| Step: 6
Training loss: 1.9763912081472133
Validation loss: 2.300876551876096

Epoch: 5| Step: 7
Training loss: 1.2955471272673342
Validation loss: 2.3407664603426848

Epoch: 5| Step: 8
Training loss: 1.3158119739315253
Validation loss: 2.254963692146179

Epoch: 5| Step: 9
Training loss: 1.5994525688176755
Validation loss: 2.274642860477882

Epoch: 5| Step: 10
Training loss: 1.5570038834696747
Validation loss: 2.25613771314343

Epoch: 317| Step: 0
Training loss: 1.0821137655035673
Validation loss: 2.208703494339679

Epoch: 5| Step: 1
Training loss: 1.5082550980456322
Validation loss: 2.2893769005155002

Epoch: 5| Step: 2
Training loss: 1.3068558269099508
Validation loss: 2.2555061565608145

Epoch: 5| Step: 3
Training loss: 1.6213436807288666
Validation loss: 2.2854416373042583

Epoch: 5| Step: 4
Training loss: 1.953275751018115
Validation loss: 2.3003910669188414

Epoch: 5| Step: 5
Training loss: 1.5067023108634967
Validation loss: 2.2782704596427235

Epoch: 5| Step: 6
Training loss: 1.8167562824275552
Validation loss: 2.2986490713087098

Epoch: 5| Step: 7
Training loss: 1.3541823557409458
Validation loss: 2.293430911881203

Epoch: 5| Step: 8
Training loss: 1.8362445980275615
Validation loss: 2.320557657411314

Epoch: 5| Step: 9
Training loss: 1.618962148071921
Validation loss: 2.2572194248120367

Epoch: 5| Step: 10
Training loss: 1.1489346524539314
Validation loss: 2.277739348272044

Epoch: 318| Step: 0
Training loss: 1.3959282894953637
Validation loss: 2.279741551280678

Epoch: 5| Step: 1
Training loss: 1.6231585118796932
Validation loss: 2.2177245014471207

Epoch: 5| Step: 2
Training loss: 1.6007272915102961
Validation loss: 2.268029049434205

Epoch: 5| Step: 3
Training loss: 1.2720530186196093
Validation loss: 2.2400021877988627

Epoch: 5| Step: 4
Training loss: 1.3667626292955435
Validation loss: 2.247918180494289

Epoch: 5| Step: 5
Training loss: 1.6436852387989633
Validation loss: 2.2547509431236468

Epoch: 5| Step: 6
Training loss: 1.4399337897708875
Validation loss: 2.328142097665281

Epoch: 5| Step: 7
Training loss: 1.9664315999169917
Validation loss: 2.3229616207623582

Epoch: 5| Step: 8
Training loss: 1.255196356287543
Validation loss: 2.2358521485820533

Epoch: 5| Step: 9
Training loss: 1.508176848511914
Validation loss: 2.2209501310299626

Epoch: 5| Step: 10
Training loss: 1.6749122340424274
Validation loss: 2.261232833157266

Epoch: 319| Step: 0
Training loss: 1.8667774468428902
Validation loss: 2.323660907651828

Epoch: 5| Step: 1
Training loss: 1.4462703520744913
Validation loss: 2.2400526691560794

Epoch: 5| Step: 2
Training loss: 1.5815450038820265
Validation loss: 2.2584716649919283

Epoch: 5| Step: 3
Training loss: 0.9201524125710817
Validation loss: 2.290784934299745

Epoch: 5| Step: 4
Training loss: 1.7943502850559438
Validation loss: 2.3071844041344076

Epoch: 5| Step: 5
Training loss: 1.665751285310307
Validation loss: 2.254567379172462

Epoch: 5| Step: 6
Training loss: 1.1696784223101844
Validation loss: 2.348916287340662

Epoch: 5| Step: 7
Training loss: 1.7457618483275574
Validation loss: 2.3509382191190062

Epoch: 5| Step: 8
Training loss: 1.4066755710488716
Validation loss: 2.364312267030883

Epoch: 5| Step: 9
Training loss: 1.5287359970337289
Validation loss: 2.2874574130665604

Epoch: 5| Step: 10
Training loss: 1.274929132549004
Validation loss: 2.3499216379520034

Epoch: 320| Step: 0
Training loss: 1.695075163510982
Validation loss: 2.3184897705272953

Epoch: 5| Step: 1
Training loss: 1.5916526307823626
Validation loss: 2.3012524951666555

Epoch: 5| Step: 2
Training loss: 1.3941427592621658
Validation loss: 2.3152977366621164

Epoch: 5| Step: 3
Training loss: 1.821067817074577
Validation loss: 2.2956661067504616

Epoch: 5| Step: 4
Training loss: 1.026332052484225
Validation loss: 2.2866370067085784

Epoch: 5| Step: 5
Training loss: 1.207178298239678
Validation loss: 2.2689507159738036

Epoch: 5| Step: 6
Training loss: 1.9806933153431883
Validation loss: 2.293261332470295

Epoch: 5| Step: 7
Training loss: 1.7556555505568077
Validation loss: 2.3101922437293347

Epoch: 5| Step: 8
Training loss: 1.3155917129473647
Validation loss: 2.3308894412288277

Epoch: 5| Step: 9
Training loss: 1.3743698670281441
Validation loss: 2.2816627354951575

Epoch: 5| Step: 10
Training loss: 1.5613775417742992
Validation loss: 2.25789224828901

Epoch: 321| Step: 0
Training loss: 1.126525744977444
Validation loss: 2.285947435714474

Epoch: 5| Step: 1
Training loss: 1.5017815183072563
Validation loss: 2.2728587030721017

Epoch: 5| Step: 2
Training loss: 1.440234113444384
Validation loss: 2.222961874208064

Epoch: 5| Step: 3
Training loss: 1.1912516008908702
Validation loss: 2.289591951061127

Epoch: 5| Step: 4
Training loss: 1.5090853205804038
Validation loss: 2.289013520605421

Epoch: 5| Step: 5
Training loss: 2.0308991349237733
Validation loss: 2.26458712501645

Epoch: 5| Step: 6
Training loss: 1.2685643196474432
Validation loss: 2.242470533788058

Epoch: 5| Step: 7
Training loss: 2.01456559603068
Validation loss: 2.3043482365806756

Epoch: 5| Step: 8
Training loss: 1.5495256005603755
Validation loss: 2.315521284232969

Epoch: 5| Step: 9
Training loss: 1.3318901099104683
Validation loss: 2.2780050983725726

Epoch: 5| Step: 10
Training loss: 0.9636643030977068
Validation loss: 2.2905066058921117

Epoch: 322| Step: 0
Training loss: 1.0832263392407153
Validation loss: 2.2956749434228527

Epoch: 5| Step: 1
Training loss: 2.141295502062838
Validation loss: 2.265375163016366

Epoch: 5| Step: 2
Training loss: 1.4317783429987425
Validation loss: 2.2527196574415966

Epoch: 5| Step: 3
Training loss: 1.6898764372127553
Validation loss: 2.291427034469838

Epoch: 5| Step: 4
Training loss: 1.7323529940462004
Validation loss: 2.274775462725749

Epoch: 5| Step: 5
Training loss: 1.2865476178320097
Validation loss: 2.2715249106859714

Epoch: 5| Step: 6
Training loss: 1.707996505778399
Validation loss: 2.2820980346090884

Epoch: 5| Step: 7
Training loss: 1.3847820243348623
Validation loss: 2.245711092318267

Epoch: 5| Step: 8
Training loss: 1.2830463005863204
Validation loss: 2.2465312498505727

Epoch: 5| Step: 9
Training loss: 1.2565101847541345
Validation loss: 2.2058891283615263

Epoch: 5| Step: 10
Training loss: 1.1886332274643734
Validation loss: 2.2430553702538036

Epoch: 323| Step: 0
Training loss: 1.5268416494068011
Validation loss: 2.2966900778195978

Epoch: 5| Step: 1
Training loss: 1.7180111077097229
Validation loss: 2.3399488436554545

Epoch: 5| Step: 2
Training loss: 1.1045061105513356
Validation loss: 2.2775941043208254

Epoch: 5| Step: 3
Training loss: 1.3134216524012614
Validation loss: 2.3103851030666034

Epoch: 5| Step: 4
Training loss: 1.8143566093603445
Validation loss: 2.3192106168834483

Epoch: 5| Step: 5
Training loss: 1.5850296804735795
Validation loss: 2.2317925326001213

Epoch: 5| Step: 6
Training loss: 1.3771538337901517
Validation loss: 2.3200986522016986

Epoch: 5| Step: 7
Training loss: 1.3190024382891905
Validation loss: 2.3077041996806438

Epoch: 5| Step: 8
Training loss: 1.6726909322051688
Validation loss: 2.2942453957314566

Epoch: 5| Step: 9
Training loss: 1.6067636284648619
Validation loss: 2.2899796467326303

Epoch: 5| Step: 10
Training loss: 1.5480247617264042
Validation loss: 2.3239027895536566

Epoch: 324| Step: 0
Training loss: 1.4035610770242815
Validation loss: 2.266718093890671

Epoch: 5| Step: 1
Training loss: 1.282396361939356
Validation loss: 2.289759372670489

Epoch: 5| Step: 2
Training loss: 2.1191082226785465
Validation loss: 2.298398371368198

Epoch: 5| Step: 3
Training loss: 1.3648334836873965
Validation loss: 2.2992939631560185

Epoch: 5| Step: 4
Training loss: 1.7276610594995856
Validation loss: 2.268808589079238

Epoch: 5| Step: 5
Training loss: 1.21276058660922
Validation loss: 2.252249951490448

Epoch: 5| Step: 6
Training loss: 1.4964207224700197
Validation loss: 2.291246528558187

Epoch: 5| Step: 7
Training loss: 1.2840514840651283
Validation loss: 2.2687864566374394

Epoch: 5| Step: 8
Training loss: 1.827164226323084
Validation loss: 2.2367900140155528

Epoch: 5| Step: 9
Training loss: 1.2618672192028053
Validation loss: 2.317332784421947

Epoch: 5| Step: 10
Training loss: 1.2520266316418083
Validation loss: 2.289336993911404

Epoch: 325| Step: 0
Training loss: 1.6185434158059762
Validation loss: 2.2641134875622995

Epoch: 5| Step: 1
Training loss: 1.5239167071081172
Validation loss: 2.258449703681856

Epoch: 5| Step: 2
Training loss: 1.1857558542292457
Validation loss: 2.2120363455885794

Epoch: 5| Step: 3
Training loss: 1.3638085162705664
Validation loss: 2.276053781567031

Epoch: 5| Step: 4
Training loss: 1.5440632861316241
Validation loss: 2.233899037783141

Epoch: 5| Step: 5
Training loss: 1.5232100096824475
Validation loss: 2.230224422437741

Epoch: 5| Step: 6
Training loss: 1.5127225002852516
Validation loss: 2.2542559650858727

Epoch: 5| Step: 7
Training loss: 1.3461179052522474
Validation loss: 2.275250640088221

Epoch: 5| Step: 8
Training loss: 1.4712865313173087
Validation loss: 2.284751296537625

Epoch: 5| Step: 9
Training loss: 1.94432195852898
Validation loss: 2.301523281830058

Epoch: 5| Step: 10
Training loss: 1.5373431055916902
Validation loss: 2.317695410981517

Epoch: 326| Step: 0
Training loss: 1.7197630930913865
Validation loss: 2.3103959129219005

Epoch: 5| Step: 1
Training loss: 1.46963896125975
Validation loss: 2.2788401951087742

Epoch: 5| Step: 2
Training loss: 1.5139671775958838
Validation loss: 2.2772740812305408

Epoch: 5| Step: 3
Training loss: 1.2935934718436173
Validation loss: 2.228419150288121

Epoch: 5| Step: 4
Training loss: 1.1793433691654052
Validation loss: 2.2997493356401435

Epoch: 5| Step: 5
Training loss: 1.2402241864123824
Validation loss: 2.268424045749827

Epoch: 5| Step: 6
Training loss: 1.5688718953591627
Validation loss: 2.319994099191892

Epoch: 5| Step: 7
Training loss: 1.9710235788840391
Validation loss: 2.269016511850879

Epoch: 5| Step: 8
Training loss: 1.2406817252693612
Validation loss: 2.2968008679432406

Epoch: 5| Step: 9
Training loss: 1.5384784500403
Validation loss: 2.2920624474174685

Epoch: 5| Step: 10
Training loss: 1.2939244452179408
Validation loss: 2.2919611561710056

Epoch: 327| Step: 0
Training loss: 1.6742751816474541
Validation loss: 2.261089051611964

Epoch: 5| Step: 1
Training loss: 1.427131577764533
Validation loss: 2.303741759926692

Epoch: 5| Step: 2
Training loss: 1.097212460765527
Validation loss: 2.235853751536133

Epoch: 5| Step: 3
Training loss: 1.4327608022234344
Validation loss: 2.242558619564758

Epoch: 5| Step: 4
Training loss: 1.4953424943010385
Validation loss: 2.2718056814172747

Epoch: 5| Step: 5
Training loss: 1.2936886630053752
Validation loss: 2.2525817041073193

Epoch: 5| Step: 6
Training loss: 1.589282487403692
Validation loss: 2.255651092964383

Epoch: 5| Step: 7
Training loss: 2.0950626414909985
Validation loss: 2.3039010829576405

Epoch: 5| Step: 8
Training loss: 1.370220677986853
Validation loss: 2.3459583622541493

Epoch: 5| Step: 9
Training loss: 1.43824533130691
Validation loss: 2.236805477478675

Epoch: 5| Step: 10
Training loss: 1.0173078240220745
Validation loss: 2.280257053469653

Epoch: 328| Step: 0
Training loss: 1.8043511808043478
Validation loss: 2.301936615471668

Epoch: 5| Step: 1
Training loss: 1.40098795261962
Validation loss: 2.2903741818169507

Epoch: 5| Step: 2
Training loss: 1.6150762810422314
Validation loss: 2.327333451061536

Epoch: 5| Step: 3
Training loss: 1.263117578740429
Validation loss: 2.3327419257390374

Epoch: 5| Step: 4
Training loss: 1.6630813500010129
Validation loss: 2.3215971519608987

Epoch: 5| Step: 5
Training loss: 2.1373660486199966
Validation loss: 2.3192072973840108

Epoch: 5| Step: 6
Training loss: 1.1197517151322274
Validation loss: 2.279091839481463

Epoch: 5| Step: 7
Training loss: 1.3528189579524694
Validation loss: 2.2892721611337783

Epoch: 5| Step: 8
Training loss: 1.1203660364274433
Validation loss: 2.327770700891908

Epoch: 5| Step: 9
Training loss: 1.346383286929196
Validation loss: 2.27810295554912

Epoch: 5| Step: 10
Training loss: 1.4018008740675327
Validation loss: 2.2879047085774

Epoch: 329| Step: 0
Training loss: 1.5569543462539195
Validation loss: 2.3229788215437464

Epoch: 5| Step: 1
Training loss: 1.2281172308057275
Validation loss: 2.2551350669172807

Epoch: 5| Step: 2
Training loss: 1.3070532086084587
Validation loss: 2.22941868388379

Epoch: 5| Step: 3
Training loss: 2.031742564414345
Validation loss: 2.2989248928566646

Epoch: 5| Step: 4
Training loss: 1.2874685431776327
Validation loss: 2.2603769733166135

Epoch: 5| Step: 5
Training loss: 1.4779332978214708
Validation loss: 2.281582292176184

Epoch: 5| Step: 6
Training loss: 1.2489054656220169
Validation loss: 2.293277965668677

Epoch: 5| Step: 7
Training loss: 1.3089269868524773
Validation loss: 2.2188431025418485

Epoch: 5| Step: 8
Training loss: 1.222651569979062
Validation loss: 2.3154986981637387

Epoch: 5| Step: 9
Training loss: 1.536051404266694
Validation loss: 2.28536594081922

Epoch: 5| Step: 10
Training loss: 1.6012971983958293
Validation loss: 2.3089363095653743

Epoch: 330| Step: 0
Training loss: 1.5152776261067433
Validation loss: 2.330992780223263

Epoch: 5| Step: 1
Training loss: 1.7165143124400104
Validation loss: 2.300562452567823

Epoch: 5| Step: 2
Training loss: 1.5084585278366942
Validation loss: 2.264583005459002

Epoch: 5| Step: 3
Training loss: 1.6207943559420301
Validation loss: 2.286146892597411

Epoch: 5| Step: 4
Training loss: 2.0016990835384867
Validation loss: 2.292617250180912

Epoch: 5| Step: 5
Training loss: 0.9771627183778355
Validation loss: 2.2964682314772644

Epoch: 5| Step: 6
Training loss: 1.2015141689466782
Validation loss: 2.266938003538522

Epoch: 5| Step: 7
Training loss: 1.2333757242873529
Validation loss: 2.296007604375527

Epoch: 5| Step: 8
Training loss: 1.0840708655141527
Validation loss: 2.282792360416382

Epoch: 5| Step: 9
Training loss: 1.4663145285583776
Validation loss: 2.2505138436000123

Epoch: 5| Step: 10
Training loss: 1.6743352026230582
Validation loss: 2.274812915550996

Epoch: 331| Step: 0
Training loss: 1.3009112868736699
Validation loss: 2.2440441405760727

Epoch: 5| Step: 1
Training loss: 1.076146452615587
Validation loss: 2.3326112762375253

Epoch: 5| Step: 2
Training loss: 1.2877475389454482
Validation loss: 2.305079835785012

Epoch: 5| Step: 3
Training loss: 1.505530730922999
Validation loss: 2.353265003422973

Epoch: 5| Step: 4
Training loss: 1.5960241809533289
Validation loss: 2.2926308577075534

Epoch: 5| Step: 5
Training loss: 1.3039297770302696
Validation loss: 2.356264657461622

Epoch: 5| Step: 6
Training loss: 1.6036411844921055
Validation loss: 2.2997841520176188

Epoch: 5| Step: 7
Training loss: 1.372423966738912
Validation loss: 2.34949569461919

Epoch: 5| Step: 8
Training loss: 1.9325620422668695
Validation loss: 2.265746062272369

Epoch: 5| Step: 9
Training loss: 1.2280308869388497
Validation loss: 2.2701163046591915

Epoch: 5| Step: 10
Training loss: 1.6115462092000983
Validation loss: 2.3075397665193544

Epoch: 332| Step: 0
Training loss: 1.3452761655147523
Validation loss: 2.3293243069857064

Epoch: 5| Step: 1
Training loss: 1.4900782192103992
Validation loss: 2.2835139684212957

Epoch: 5| Step: 2
Training loss: 1.4874370914267765
Validation loss: 2.2738738742595346

Epoch: 5| Step: 3
Training loss: 1.4699809009582843
Validation loss: 2.317512118606342

Epoch: 5| Step: 4
Training loss: 1.4438938085760795
Validation loss: 2.285006437745159

Epoch: 5| Step: 5
Training loss: 1.4529702709225727
Validation loss: 2.3455144539536223

Epoch: 5| Step: 6
Training loss: 1.4484623582799387
Validation loss: 2.276630888428224

Epoch: 5| Step: 7
Training loss: 1.3446268281540337
Validation loss: 2.3106027706527437

Epoch: 5| Step: 8
Training loss: 1.1297465961875213
Validation loss: 2.3006432863762853

Epoch: 5| Step: 9
Training loss: 1.401186707468386
Validation loss: 2.269241681369308

Epoch: 5| Step: 10
Training loss: 2.0630772100840207
Validation loss: 2.247421148913289

Epoch: 333| Step: 0
Training loss: 1.9112222579429614
Validation loss: 2.279801074192191

Epoch: 5| Step: 1
Training loss: 1.2554749750387733
Validation loss: 2.2492177268772364

Epoch: 5| Step: 2
Training loss: 1.5842539302758514
Validation loss: 2.2073479270848932

Epoch: 5| Step: 3
Training loss: 1.441969763953336
Validation loss: 2.3083286683245086

Epoch: 5| Step: 4
Training loss: 1.1259467591628387
Validation loss: 2.2958403413837325

Epoch: 5| Step: 5
Training loss: 1.2505501966777286
Validation loss: 2.253287222488689

Epoch: 5| Step: 6
Training loss: 1.6816224773991755
Validation loss: 2.2929770715886066

Epoch: 5| Step: 7
Training loss: 1.4116269629088252
Validation loss: 2.296113470116674

Epoch: 5| Step: 8
Training loss: 1.3056196434893552
Validation loss: 2.3065582586052233

Epoch: 5| Step: 9
Training loss: 1.2930024018763209
Validation loss: 2.2951875947620364

Epoch: 5| Step: 10
Training loss: 1.4504284192911088
Validation loss: 2.2996857358874903

Epoch: 334| Step: 0
Training loss: 1.962761201909398
Validation loss: 2.2930714546031834

Epoch: 5| Step: 1
Training loss: 1.2030133777708552
Validation loss: 2.2290826351722006

Epoch: 5| Step: 2
Training loss: 1.3129618150136815
Validation loss: 2.3165901815354184

Epoch: 5| Step: 3
Training loss: 1.3242713220113762
Validation loss: 2.280160808827347

Epoch: 5| Step: 4
Training loss: 1.7326009801855466
Validation loss: 2.2544262599092235

Epoch: 5| Step: 5
Training loss: 1.3750611638423784
Validation loss: 2.2809466262682756

Epoch: 5| Step: 6
Training loss: 1.562138172217138
Validation loss: 2.2389503410552725

Epoch: 5| Step: 7
Training loss: 1.0508422266628943
Validation loss: 2.2722652677568917

Epoch: 5| Step: 8
Training loss: 1.605312516158811
Validation loss: 2.2695759000087756

Epoch: 5| Step: 9
Training loss: 1.545863967482289
Validation loss: 2.314026731853736

Epoch: 5| Step: 10
Training loss: 1.3294137424119679
Validation loss: 2.3045748285943923

Epoch: 335| Step: 0
Training loss: 1.1116139558899578
Validation loss: 2.293495874129838

Epoch: 5| Step: 1
Training loss: 1.524385128198739
Validation loss: 2.355972863272233

Epoch: 5| Step: 2
Training loss: 1.097132384704027
Validation loss: 2.341065287982485

Epoch: 5| Step: 3
Training loss: 1.4381186771046595
Validation loss: 2.259120752469735

Epoch: 5| Step: 4
Training loss: 1.2581320883811327
Validation loss: 2.314089753284445

Epoch: 5| Step: 5
Training loss: 1.2343482968303066
Validation loss: 2.342654009555567

Epoch: 5| Step: 6
Training loss: 1.5356473258619245
Validation loss: 2.3587998399019066

Epoch: 5| Step: 7
Training loss: 1.458792841134315
Validation loss: 2.3529043455034158

Epoch: 5| Step: 8
Training loss: 1.4085661992802545
Validation loss: 2.328597367800359

Epoch: 5| Step: 9
Training loss: 2.249099339253291
Validation loss: 2.3569715536891844

Epoch: 5| Step: 10
Training loss: 1.2941318132841468
Validation loss: 2.297965631195829

Epoch: 336| Step: 0
Training loss: 1.1288372401491809
Validation loss: 2.3408683820416183

Epoch: 5| Step: 1
Training loss: 1.2194914885251669
Validation loss: 2.2891239991102896

Epoch: 5| Step: 2
Training loss: 2.0335184195448472
Validation loss: 2.317719276423589

Epoch: 5| Step: 3
Training loss: 1.1852811361558868
Validation loss: 2.2850702786179213

Epoch: 5| Step: 4
Training loss: 1.8063808934920251
Validation loss: 2.241883241706956

Epoch: 5| Step: 5
Training loss: 1.1725361802592826
Validation loss: 2.2895060650596513

Epoch: 5| Step: 6
Training loss: 1.4753677944106613
Validation loss: 2.231065723140799

Epoch: 5| Step: 7
Training loss: 1.2906867227273513
Validation loss: 2.2663243352692155

Epoch: 5| Step: 8
Training loss: 1.1943094869758601
Validation loss: 2.214834743618244

Epoch: 5| Step: 9
Training loss: 1.151316970881953
Validation loss: 2.2928652598073

Epoch: 5| Step: 10
Training loss: 1.8485100932631204
Validation loss: 2.2533784344537446

Epoch: 337| Step: 0
Training loss: 1.1316354885123008
Validation loss: 2.2718105608707835

Epoch: 5| Step: 1
Training loss: 0.8691936348168994
Validation loss: 2.292253578704816

Epoch: 5| Step: 2
Training loss: 2.046141048786305
Validation loss: 2.314138002526483

Epoch: 5| Step: 3
Training loss: 1.5916617681351357
Validation loss: 2.3078182096222752

Epoch: 5| Step: 4
Training loss: 1.1083940279028475
Validation loss: 2.3048381713759722

Epoch: 5| Step: 5
Training loss: 1.5482215800092294
Validation loss: 2.271072761359671

Epoch: 5| Step: 6
Training loss: 1.329711684333167
Validation loss: 2.2507573246692902

Epoch: 5| Step: 7
Training loss: 1.605036767912788
Validation loss: 2.330618612573452

Epoch: 5| Step: 8
Training loss: 1.5444840728393001
Validation loss: 2.316483049832056

Epoch: 5| Step: 9
Training loss: 1.0659668404895124
Validation loss: 2.3011863682346707

Epoch: 5| Step: 10
Training loss: 1.0696367232685635
Validation loss: 2.29938337688409

Epoch: 338| Step: 0
Training loss: 1.0425468477293423
Validation loss: 2.246907608941372

Epoch: 5| Step: 1
Training loss: 1.1863554910236005
Validation loss: 2.219633112405261

Epoch: 5| Step: 2
Training loss: 1.3018419677821804
Validation loss: 2.287555188650182

Epoch: 5| Step: 3
Training loss: 1.4708191925896394
Validation loss: 2.2616684858619047

Epoch: 5| Step: 4
Training loss: 1.160696347066574
Validation loss: 2.305793232491947

Epoch: 5| Step: 5
Training loss: 1.7196113508841466
Validation loss: 2.267631975352265

Epoch: 5| Step: 6
Training loss: 2.267898471228278
Validation loss: 2.2976388002429182

Epoch: 5| Step: 7
Training loss: 1.0431180697074318
Validation loss: 2.279144537055793

Epoch: 5| Step: 8
Training loss: 1.1365104038653484
Validation loss: 2.2946765980308466

Epoch: 5| Step: 9
Training loss: 1.5326575991320985
Validation loss: 2.249321567520651

Epoch: 5| Step: 10
Training loss: 1.1865466457028095
Validation loss: 2.236784760173037

Epoch: 339| Step: 0
Training loss: 1.8146366810830965
Validation loss: 2.2496388554572695

Epoch: 5| Step: 1
Training loss: 1.3360483670102605
Validation loss: 2.2665199014511734

Epoch: 5| Step: 2
Training loss: 0.9561668073082121
Validation loss: 2.295440963933917

Epoch: 5| Step: 3
Training loss: 1.397481666267254
Validation loss: 2.2685089370163936

Epoch: 5| Step: 4
Training loss: 1.4461870176800098
Validation loss: 2.27903597640505

Epoch: 5| Step: 5
Training loss: 1.5128650508485075
Validation loss: 2.3476371677683696

Epoch: 5| Step: 6
Training loss: 1.1266580654884388
Validation loss: 2.338027122075958

Epoch: 5| Step: 7
Training loss: 0.844246435705178
Validation loss: 2.284478396150818

Epoch: 5| Step: 8
Training loss: 1.486775434959915
Validation loss: 2.350615086827123

Epoch: 5| Step: 9
Training loss: 1.4586861138299836
Validation loss: 2.323406232087816

Epoch: 5| Step: 10
Training loss: 2.25553953867687
Validation loss: 2.3046014751983557

Epoch: 340| Step: 0
Training loss: 1.7275151175073493
Validation loss: 2.2238532234565977

Epoch: 5| Step: 1
Training loss: 1.3028629359645927
Validation loss: 2.2860896857748254

Epoch: 5| Step: 2
Training loss: 1.3126301927935156
Validation loss: 2.242575692842936

Epoch: 5| Step: 3
Training loss: 1.1975102384762701
Validation loss: 2.249646548740258

Epoch: 5| Step: 4
Training loss: 1.4079616725863555
Validation loss: 2.235475153002583

Epoch: 5| Step: 5
Training loss: 1.4602297124042782
Validation loss: 2.2592663704416363

Epoch: 5| Step: 6
Training loss: 1.5664364628720073
Validation loss: 2.2963617703082386

Epoch: 5| Step: 7
Training loss: 1.1996470627722975
Validation loss: 2.260011258853648

Epoch: 5| Step: 8
Training loss: 1.5071167600744524
Validation loss: 2.237712784268763

Epoch: 5| Step: 9
Training loss: 1.1248355321402477
Validation loss: 2.243884285208086

Epoch: 5| Step: 10
Training loss: 1.6102750909251435
Validation loss: 2.2701242842736526

Epoch: 341| Step: 0
Training loss: 0.9334401918161082
Validation loss: 2.304194159218474

Epoch: 5| Step: 1
Training loss: 1.4127258390305772
Validation loss: 2.2972654761764932

Epoch: 5| Step: 2
Training loss: 2.056924972367603
Validation loss: 2.3029576871478117

Epoch: 5| Step: 3
Training loss: 1.5391804606355364
Validation loss: 2.3250656591029926

Epoch: 5| Step: 4
Training loss: 1.1422265188333849
Validation loss: 2.384932778488768

Epoch: 5| Step: 5
Training loss: 1.3238674811948505
Validation loss: 2.2803535559953336

Epoch: 5| Step: 6
Training loss: 1.4275092535838017
Validation loss: 2.2787126665056032

Epoch: 5| Step: 7
Training loss: 1.297472712646966
Validation loss: 2.3024720692596983

Epoch: 5| Step: 8
Training loss: 1.2770501595565846
Validation loss: 2.318500105830869

Epoch: 5| Step: 9
Training loss: 1.6376592806160313
Validation loss: 2.2770228974199065

Epoch: 5| Step: 10
Training loss: 1.493384954306785
Validation loss: 2.320793098492274

Epoch: 342| Step: 0
Training loss: 1.3019590343910061
Validation loss: 2.2803458426439973

Epoch: 5| Step: 1
Training loss: 1.917264230151808
Validation loss: 2.289682817963101

Epoch: 5| Step: 2
Training loss: 0.9517314917425884
Validation loss: 2.2850005138930953

Epoch: 5| Step: 3
Training loss: 1.747081707511574
Validation loss: 2.2408479909308743

Epoch: 5| Step: 4
Training loss: 1.3116711315352094
Validation loss: 2.301751590943646

Epoch: 5| Step: 5
Training loss: 1.1084741507730926
Validation loss: 2.3055786590103886

Epoch: 5| Step: 6
Training loss: 1.0845869709139033
Validation loss: 2.280551058818447

Epoch: 5| Step: 7
Training loss: 1.34422657521919
Validation loss: 2.282900562760704

Epoch: 5| Step: 8
Training loss: 1.2828494532439945
Validation loss: 2.2341500996708965

Epoch: 5| Step: 9
Training loss: 1.4569788046390237
Validation loss: 2.289371443171397

Epoch: 5| Step: 10
Training loss: 1.3777120892869479
Validation loss: 2.2786081941135765

Epoch: 343| Step: 0
Training loss: 1.523416059294235
Validation loss: 2.3034910371899397

Epoch: 5| Step: 1
Training loss: 1.5144722084021822
Validation loss: 2.2321824206524483

Epoch: 5| Step: 2
Training loss: 1.3487495741962825
Validation loss: 2.2808898515627942

Epoch: 5| Step: 3
Training loss: 1.038833420820236
Validation loss: 2.3111583128948423

Epoch: 5| Step: 4
Training loss: 1.6028231241755804
Validation loss: 2.2460152526806696

Epoch: 5| Step: 5
Training loss: 1.7935458980969297
Validation loss: 2.247543017775206

Epoch: 5| Step: 6
Training loss: 1.03076108266575
Validation loss: 2.255131846356697

Epoch: 5| Step: 7
Training loss: 1.2680918823550313
Validation loss: 2.285829879888351

Epoch: 5| Step: 8
Training loss: 1.405481213126869
Validation loss: 2.292777579934898

Epoch: 5| Step: 9
Training loss: 1.2123624723640483
Validation loss: 2.3102657352443057

Epoch: 5| Step: 10
Training loss: 1.5620051554058734
Validation loss: 2.2792094003388628

Epoch: 344| Step: 0
Training loss: 1.2595041876098994
Validation loss: 2.302906110026492

Epoch: 5| Step: 1
Training loss: 1.303611082903467
Validation loss: 2.259846664548114

Epoch: 5| Step: 2
Training loss: 1.5754401908812488
Validation loss: 2.3504060804349707

Epoch: 5| Step: 3
Training loss: 1.8544984870630892
Validation loss: 2.30013135224648

Epoch: 5| Step: 4
Training loss: 1.0083801681633902
Validation loss: 2.297553240150612

Epoch: 5| Step: 5
Training loss: 1.2405398976230488
Validation loss: 2.249567229513412

Epoch: 5| Step: 6
Training loss: 1.3852017553850948
Validation loss: 2.2733740395116335

Epoch: 5| Step: 7
Training loss: 1.1316804688575968
Validation loss: 2.2635020673733015

Epoch: 5| Step: 8
Training loss: 1.3824532252257702
Validation loss: 2.227858746124227

Epoch: 5| Step: 9
Training loss: 1.393365452835777
Validation loss: 2.2584195330658963

Epoch: 5| Step: 10
Training loss: 1.637843508034734
Validation loss: 2.3032123219582568

Epoch: 345| Step: 0
Training loss: 1.313666642626943
Validation loss: 2.310612816703916

Epoch: 5| Step: 1
Training loss: 2.0782604890409764
Validation loss: 2.295665501482386

Epoch: 5| Step: 2
Training loss: 1.1032776162369016
Validation loss: 2.267079562996571

Epoch: 5| Step: 3
Training loss: 1.4045286451564463
Validation loss: 2.2995941360431833

Epoch: 5| Step: 4
Training loss: 1.3614381064342833
Validation loss: 2.291745361438695

Epoch: 5| Step: 5
Training loss: 1.2093363358973108
Validation loss: 2.260854663228991

Epoch: 5| Step: 6
Training loss: 1.1855389816297928
Validation loss: 2.2487248734995915

Epoch: 5| Step: 7
Training loss: 1.2267433567710722
Validation loss: 2.285702712106446

Epoch: 5| Step: 8
Training loss: 1.7740212038658802
Validation loss: 2.296489661767036

Epoch: 5| Step: 9
Training loss: 1.2260667321368899
Validation loss: 2.283416181465059

Epoch: 5| Step: 10
Training loss: 1.2428765934720338
Validation loss: 2.2759433912002858

Epoch: 346| Step: 0
Training loss: 1.346876410817693
Validation loss: 2.209322581465876

Epoch: 5| Step: 1
Training loss: 1.1484783450797522
Validation loss: 2.2541553436943262

Epoch: 5| Step: 2
Training loss: 1.3990900658879795
Validation loss: 2.265366769458367

Epoch: 5| Step: 3
Training loss: 1.7049661186632992
Validation loss: 2.331756136392093

Epoch: 5| Step: 4
Training loss: 1.1413578657669592
Validation loss: 2.331226022631066

Epoch: 5| Step: 5
Training loss: 1.316546333624811
Validation loss: 2.291635698424333

Epoch: 5| Step: 6
Training loss: 1.4247544863500208
Validation loss: 2.323065543061067

Epoch: 5| Step: 7
Training loss: 1.3513357600717408
Validation loss: 2.3041354049774965

Epoch: 5| Step: 8
Training loss: 1.7254183331079027
Validation loss: 2.262962726200225

Epoch: 5| Step: 9
Training loss: 1.4313320852670142
Validation loss: 2.3120045049322893

Epoch: 5| Step: 10
Training loss: 1.2539089119666058
Validation loss: 2.2733201898523205

Epoch: 347| Step: 0
Training loss: 1.3580355128559254
Validation loss: 2.301785728547773

Epoch: 5| Step: 1
Training loss: 1.2927281827219852
Validation loss: 2.320965175676699

Epoch: 5| Step: 2
Training loss: 1.8794557398409892
Validation loss: 2.283546832206386

Epoch: 5| Step: 3
Training loss: 1.2997453935427443
Validation loss: 2.2767750199755206

Epoch: 5| Step: 4
Training loss: 1.6376740574239352
Validation loss: 2.2913058051828

Epoch: 5| Step: 5
Training loss: 1.220482255408954
Validation loss: 2.3471485658001843

Epoch: 5| Step: 6
Training loss: 1.6071857265022784
Validation loss: 2.2417705557407976

Epoch: 5| Step: 7
Training loss: 1.2558973434190517
Validation loss: 2.2348705636847663

Epoch: 5| Step: 8
Training loss: 1.2554360917786562
Validation loss: 2.252186471676616

Epoch: 5| Step: 9
Training loss: 1.2771258153689715
Validation loss: 2.2804690462869286

Epoch: 5| Step: 10
Training loss: 1.0068663066202204
Validation loss: 2.258024956875619

Epoch: 348| Step: 0
Training loss: 1.4366382005855594
Validation loss: 2.27379580043297

Epoch: 5| Step: 1
Training loss: 1.3437338096175573
Validation loss: 2.291184119677528

Epoch: 5| Step: 2
Training loss: 1.3278721288165027
Validation loss: 2.2366943475066927

Epoch: 5| Step: 3
Training loss: 1.0028820825141496
Validation loss: 2.270161805928484

Epoch: 5| Step: 4
Training loss: 2.1053249331244914
Validation loss: 2.2625919768654077

Epoch: 5| Step: 5
Training loss: 0.9225700150775464
Validation loss: 2.233310389902136

Epoch: 5| Step: 6
Training loss: 1.452920058370179
Validation loss: 2.2975516378420466

Epoch: 5| Step: 7
Training loss: 1.3469400022889793
Validation loss: 2.318284916453741

Epoch: 5| Step: 8
Training loss: 1.7009558907362132
Validation loss: 2.3436478940537286

Epoch: 5| Step: 9
Training loss: 1.1048063848211547
Validation loss: 2.222334497723467

Epoch: 5| Step: 10
Training loss: 1.146292987296138
Validation loss: 2.270961738275922

Epoch: 349| Step: 0
Training loss: 1.3191296848953875
Validation loss: 2.3229559769006523

Epoch: 5| Step: 1
Training loss: 1.2375418203204007
Validation loss: 2.2200176304303096

Epoch: 5| Step: 2
Training loss: 1.1334349927934968
Validation loss: 2.3132057631748704

Epoch: 5| Step: 3
Training loss: 1.3144049671074598
Validation loss: 2.2927839231202705

Epoch: 5| Step: 4
Training loss: 1.5614070884773341
Validation loss: 2.2633041675916425

Epoch: 5| Step: 5
Training loss: 1.7634045302158177
Validation loss: 2.2873791573120745

Epoch: 5| Step: 6
Training loss: 1.7606155764673233
Validation loss: 2.2684038364657044

Epoch: 5| Step: 7
Training loss: 1.0585226337714086
Validation loss: 2.274896639820168

Epoch: 5| Step: 8
Training loss: 0.6539953875204049
Validation loss: 2.2623485513136976

Epoch: 5| Step: 9
Training loss: 1.3792565957029754
Validation loss: 2.26624123548752

Epoch: 5| Step: 10
Training loss: 1.3940974396921477
Validation loss: 2.2410845060712434

Epoch: 350| Step: 0
Training loss: 1.2821717551982597
Validation loss: 2.326453101991692

Epoch: 5| Step: 1
Training loss: 1.047406189935446
Validation loss: 2.25986963326054

Epoch: 5| Step: 2
Training loss: 1.1483306835090468
Validation loss: 2.2866391391162146

Epoch: 5| Step: 3
Training loss: 1.5231650084327102
Validation loss: 2.2640634736128264

Epoch: 5| Step: 4
Training loss: 1.1922015927982936
Validation loss: 2.275716216053103

Epoch: 5| Step: 5
Training loss: 1.962104966562898
Validation loss: 2.219736026019941

Epoch: 5| Step: 6
Training loss: 1.1195884461044212
Validation loss: 2.227009858527953

Epoch: 5| Step: 7
Training loss: 1.7026061921464042
Validation loss: 2.261186488396806

Epoch: 5| Step: 8
Training loss: 1.0975112547764427
Validation loss: 2.266956121335493

Epoch: 5| Step: 9
Training loss: 1.234822928364003
Validation loss: 2.182408441423726

Epoch: 5| Step: 10
Training loss: 1.2726600473627117
Validation loss: 2.2595368097163324

Epoch: 351| Step: 0
Training loss: 1.0067457719273114
Validation loss: 2.2925015633736163

Epoch: 5| Step: 1
Training loss: 1.698781415411654
Validation loss: 2.3055542948411714

Epoch: 5| Step: 2
Training loss: 0.8097597275632827
Validation loss: 2.2845267096973

Epoch: 5| Step: 3
Training loss: 1.3562595578045862
Validation loss: 2.3311387980372618

Epoch: 5| Step: 4
Training loss: 1.1909144152423665
Validation loss: 2.391410961704536

Epoch: 5| Step: 5
Training loss: 1.204062406300814
Validation loss: 2.342563858960996

Epoch: 5| Step: 6
Training loss: 1.4821263195828882
Validation loss: 2.352884658083258

Epoch: 5| Step: 7
Training loss: 1.183121136771382
Validation loss: 2.3264572976717637

Epoch: 5| Step: 8
Training loss: 2.045501131432742
Validation loss: 2.385041033511633

Epoch: 5| Step: 9
Training loss: 1.6145748097184498
Validation loss: 2.281335582692681

Epoch: 5| Step: 10
Training loss: 1.3641130593140012
Validation loss: 2.254797076225385

Epoch: 352| Step: 0
Training loss: 1.2102208139375017
Validation loss: 2.2830361428256705

Epoch: 5| Step: 1
Training loss: 1.1509831041078633
Validation loss: 2.2333840799542974

Epoch: 5| Step: 2
Training loss: 0.9116582633043239
Validation loss: 2.2466838068396666

Epoch: 5| Step: 3
Training loss: 1.4413939271312255
Validation loss: 2.209164984282149

Epoch: 5| Step: 4
Training loss: 1.1623401572972816
Validation loss: 2.28230962278716

Epoch: 5| Step: 5
Training loss: 1.279909642353243
Validation loss: 2.2839429712758292

Epoch: 5| Step: 6
Training loss: 1.2951098919787967
Validation loss: 2.3092899391933894

Epoch: 5| Step: 7
Training loss: 1.5337508662811294
Validation loss: 2.2573376421032543

Epoch: 5| Step: 8
Training loss: 1.9357220890871214
Validation loss: 2.3003748111279054

Epoch: 5| Step: 9
Training loss: 1.7718584870606753
Validation loss: 2.302633373954641

Epoch: 5| Step: 10
Training loss: 0.9455956279380857
Validation loss: 2.2472733556798423

Epoch: 353| Step: 0
Training loss: 1.6533510280759482
Validation loss: 2.266717486547742

Epoch: 5| Step: 1
Training loss: 1.4869012316730572
Validation loss: 2.2170145647530575

Epoch: 5| Step: 2
Training loss: 1.364817281377933
Validation loss: 2.2672130276702847

Epoch: 5| Step: 3
Training loss: 1.1054384476784924
Validation loss: 2.2646516796197935

Epoch: 5| Step: 4
Training loss: 1.098528369601475
Validation loss: 2.2819754626554922

Epoch: 5| Step: 5
Training loss: 1.8073237596753349
Validation loss: 2.285256013742568

Epoch: 5| Step: 6
Training loss: 1.115918218723308
Validation loss: 2.286349619118009

Epoch: 5| Step: 7
Training loss: 1.3752095756338296
Validation loss: 2.303223767646916

Epoch: 5| Step: 8
Training loss: 0.979653494456144
Validation loss: 2.3056221739558027

Epoch: 5| Step: 9
Training loss: 1.1797914774968268
Validation loss: 2.295203983908104

Epoch: 5| Step: 10
Training loss: 1.2825837985020916
Validation loss: 2.3598605648269135

Epoch: 354| Step: 0
Training loss: 1.2102417947025699
Validation loss: 2.284465741071404

Epoch: 5| Step: 1
Training loss: 1.3124883742044633
Validation loss: 2.2602744577797127

Epoch: 5| Step: 2
Training loss: 1.549688227892376
Validation loss: 2.296136968129921

Epoch: 5| Step: 3
Training loss: 1.6063393415845437
Validation loss: 2.2529616097492613

Epoch: 5| Step: 4
Training loss: 1.1941132357335413
Validation loss: 2.250294893348331

Epoch: 5| Step: 5
Training loss: 1.8921835284266226
Validation loss: 2.299910353937252

Epoch: 5| Step: 6
Training loss: 1.2809939244861048
Validation loss: 2.298345153755472

Epoch: 5| Step: 7
Training loss: 1.1924713376837217
Validation loss: 2.2419163160935183

Epoch: 5| Step: 8
Training loss: 1.5058189218433502
Validation loss: 2.3134690737224015

Epoch: 5| Step: 9
Training loss: 1.2069447804313829
Validation loss: 2.2580656907522423

Epoch: 5| Step: 10
Training loss: 1.0215081235849217
Validation loss: 2.257295643816928

Epoch: 355| Step: 0
Training loss: 2.1238310347483287
Validation loss: 2.276687591989987

Epoch: 5| Step: 1
Training loss: 1.3053796725242017
Validation loss: 2.3140774783873557

Epoch: 5| Step: 2
Training loss: 0.9298756192719738
Validation loss: 2.308978085246985

Epoch: 5| Step: 3
Training loss: 1.3945206500166119
Validation loss: 2.2898677384106385

Epoch: 5| Step: 4
Training loss: 1.1779312804244069
Validation loss: 2.401711402531015

Epoch: 5| Step: 5
Training loss: 1.31251625777575
Validation loss: 2.3346184778294177

Epoch: 5| Step: 6
Training loss: 1.5449298998290317
Validation loss: 2.3112540997556046

Epoch: 5| Step: 7
Training loss: 1.1473334578455479
Validation loss: 2.314541268045132

Epoch: 5| Step: 8
Training loss: 1.661597920675726
Validation loss: 2.317151857007278

Epoch: 5| Step: 9
Training loss: 1.1416372223465756
Validation loss: 2.308412688482299

Epoch: 5| Step: 10
Training loss: 1.7785868897917765
Validation loss: 2.325387603342783

Epoch: 356| Step: 0
Training loss: 1.0921493261648771
Validation loss: 2.3424265723045563

Epoch: 5| Step: 1
Training loss: 1.506667577073714
Validation loss: 2.2476754805508663

Epoch: 5| Step: 2
Training loss: 1.0127661743680483
Validation loss: 2.247994053421787

Epoch: 5| Step: 3
Training loss: 1.4229082817549215
Validation loss: 2.249663240031212

Epoch: 5| Step: 4
Training loss: 1.1646617396693906
Validation loss: 2.299993771526326

Epoch: 5| Step: 5
Training loss: 1.553167011759668
Validation loss: 2.27348037057407

Epoch: 5| Step: 6
Training loss: 1.211919079077802
Validation loss: 2.2593437129456944

Epoch: 5| Step: 7
Training loss: 1.9417703390754362
Validation loss: 2.2223489722214107

Epoch: 5| Step: 8
Training loss: 1.3035554828900289
Validation loss: 2.268178053677783

Epoch: 5| Step: 9
Training loss: 1.5528974339500508
Validation loss: 2.284283623382075

Epoch: 5| Step: 10
Training loss: 1.113216465185997
Validation loss: 2.18460819345158

Epoch: 357| Step: 0
Training loss: 1.746991022996378
Validation loss: 2.2379488655350515

Epoch: 5| Step: 1
Training loss: 1.1321043760955232
Validation loss: 2.260970707315075

Epoch: 5| Step: 2
Training loss: 1.395831829278999
Validation loss: 2.2992197189838293

Epoch: 5| Step: 3
Training loss: 1.5567999821632517
Validation loss: 2.2891880488009577

Epoch: 5| Step: 4
Training loss: 1.217727623561832
Validation loss: 2.3206646258693207

Epoch: 5| Step: 5
Training loss: 1.2699924980903188
Validation loss: 2.3596011491243063

Epoch: 5| Step: 6
Training loss: 1.181961394349212
Validation loss: 2.3583934480449624

Epoch: 5| Step: 7
Training loss: 1.224086716864975
Validation loss: 2.332137185435455

Epoch: 5| Step: 8
Training loss: 1.2691425843603825
Validation loss: 2.3284297891437014

Epoch: 5| Step: 9
Training loss: 1.4262946053834127
Validation loss: 2.326782714486166

Epoch: 5| Step: 10
Training loss: 0.9990535071537711
Validation loss: 2.3139390046182116

Epoch: 358| Step: 0
Training loss: 1.3325688236634552
Validation loss: 2.3242299764266745

Epoch: 5| Step: 1
Training loss: 1.3048462457076846
Validation loss: 2.270176162376672

Epoch: 5| Step: 2
Training loss: 1.0575840487796486
Validation loss: 2.251358472116637

Epoch: 5| Step: 3
Training loss: 1.1189202695878375
Validation loss: 2.2750488261135713

Epoch: 5| Step: 4
Training loss: 1.1871799740473699
Validation loss: 2.2634597632651783

Epoch: 5| Step: 5
Training loss: 1.4042765015038103
Validation loss: 2.223126174601853

Epoch: 5| Step: 6
Training loss: 1.302913441854808
Validation loss: 2.2722911356952658

Epoch: 5| Step: 7
Training loss: 1.7436020244857051
Validation loss: 2.2735123566512994

Epoch: 5| Step: 8
Training loss: 1.429878180456872
Validation loss: 2.2388972493307566

Epoch: 5| Step: 9
Training loss: 1.5461009236960122
Validation loss: 2.2834079103601588

Epoch: 5| Step: 10
Training loss: 1.7274490082829221
Validation loss: 2.2687097490555437

Epoch: 359| Step: 0
Training loss: 1.4141378224581496
Validation loss: 2.328190152587035

Epoch: 5| Step: 1
Training loss: 1.1769389286191612
Validation loss: 2.237224482653493

Epoch: 5| Step: 2
Training loss: 1.45565870338558
Validation loss: 2.2386180971621106

Epoch: 5| Step: 3
Training loss: 1.3093400335991832
Validation loss: 2.3340374983497614

Epoch: 5| Step: 4
Training loss: 0.9618521888313388
Validation loss: 2.2863372322920483

Epoch: 5| Step: 5
Training loss: 1.4392161698360173
Validation loss: 2.3008279197992185

Epoch: 5| Step: 6
Training loss: 1.5280814572236943
Validation loss: 2.4014823932078495

Epoch: 5| Step: 7
Training loss: 1.3545778188336028
Validation loss: 2.3261875421967946

Epoch: 5| Step: 8
Training loss: 0.8050853153298206
Validation loss: 2.300899876456896

Epoch: 5| Step: 9
Training loss: 1.1546965809053336
Validation loss: 2.3266009225602806

Epoch: 5| Step: 10
Training loss: 2.00806766773663
Validation loss: 2.276413376924479

Epoch: 360| Step: 0
Training loss: 0.9502684828685174
Validation loss: 2.2760404866172963

Epoch: 5| Step: 1
Training loss: 1.714943919808035
Validation loss: 2.2935493205084043

Epoch: 5| Step: 2
Training loss: 1.392071389644979
Validation loss: 2.288506443380065

Epoch: 5| Step: 3
Training loss: 0.9585425452598874
Validation loss: 2.201985268240883

Epoch: 5| Step: 4
Training loss: 1.336203030081004
Validation loss: 2.32265632763804

Epoch: 5| Step: 5
Training loss: 1.209420712417827
Validation loss: 2.2608772497771548

Epoch: 5| Step: 6
Training loss: 1.2485056050502856
Validation loss: 2.254477868132995

Epoch: 5| Step: 7
Training loss: 2.00310668460846
Validation loss: 2.3372099768812387

Epoch: 5| Step: 8
Training loss: 1.4942488886685616
Validation loss: 2.253082190717319

Epoch: 5| Step: 9
Training loss: 1.2087479515807853
Validation loss: 2.2820496303260493

Epoch: 5| Step: 10
Training loss: 0.9724146837894305
Validation loss: 2.2586690744939824

Epoch: 361| Step: 0
Training loss: 1.4190849345772751
Validation loss: 2.293123606204578

Epoch: 5| Step: 1
Training loss: 1.1126575529853981
Validation loss: 2.213247075803094

Epoch: 5| Step: 2
Training loss: 1.2741040784550925
Validation loss: 2.2731765238121904

Epoch: 5| Step: 3
Training loss: 1.4445508444959576
Validation loss: 2.289440869226337

Epoch: 5| Step: 4
Training loss: 1.2189492282887051
Validation loss: 2.2937857807787925

Epoch: 5| Step: 5
Training loss: 1.5891230118744415
Validation loss: 2.279211663422894

Epoch: 5| Step: 6
Training loss: 1.0155498770293732
Validation loss: 2.2780716720045446

Epoch: 5| Step: 7
Training loss: 0.8749666888844453
Validation loss: 2.3035277471276765

Epoch: 5| Step: 8
Training loss: 1.5471191213618924
Validation loss: 2.309462624820632

Epoch: 5| Step: 9
Training loss: 1.2460649540841573
Validation loss: 2.2793733095229003

Epoch: 5| Step: 10
Training loss: 2.008103167797793
Validation loss: 2.259208992464189

Epoch: 362| Step: 0
Training loss: 1.4285001566682862
Validation loss: 2.257383966510643

Epoch: 5| Step: 1
Training loss: 0.908969711493629
Validation loss: 2.260985563194963

Epoch: 5| Step: 2
Training loss: 1.1775797019598178
Validation loss: 2.300382721443153

Epoch: 5| Step: 3
Training loss: 0.9956825454758177
Validation loss: 2.286700554293493

Epoch: 5| Step: 4
Training loss: 2.004989361056976
Validation loss: 2.2937246570191343

Epoch: 5| Step: 5
Training loss: 1.2210637162725735
Validation loss: 2.310074490638515

Epoch: 5| Step: 6
Training loss: 1.2745372493444163
Validation loss: 2.241419998646219

Epoch: 5| Step: 7
Training loss: 1.4958350054944962
Validation loss: 2.2601700127394078

Epoch: 5| Step: 8
Training loss: 1.135167429922121
Validation loss: 2.2691443464403624

Epoch: 5| Step: 9
Training loss: 1.2832874752289878
Validation loss: 2.288316438721888

Epoch: 5| Step: 10
Training loss: 1.115610516878892
Validation loss: 2.301599057312847

Epoch: 363| Step: 0
Training loss: 2.0939858147214463
Validation loss: 2.2331693141229376

Epoch: 5| Step: 1
Training loss: 1.0592173186125244
Validation loss: 2.2693062583344314

Epoch: 5| Step: 2
Training loss: 1.4814066872436664
Validation loss: 2.258291421442388

Epoch: 5| Step: 3
Training loss: 1.0434625720964552
Validation loss: 2.3147512141233

Epoch: 5| Step: 4
Training loss: 1.3043506210235007
Validation loss: 2.307068756616387

Epoch: 5| Step: 5
Training loss: 1.2370665937614322
Validation loss: 2.2673161990534427

Epoch: 5| Step: 6
Training loss: 1.0963567460392973
Validation loss: 2.3045642317170256

Epoch: 5| Step: 7
Training loss: 1.116331399339755
Validation loss: 2.262832287853321

Epoch: 5| Step: 8
Training loss: 1.2020805085588098
Validation loss: 2.2707107227103402

Epoch: 5| Step: 9
Training loss: 0.9975041595410501
Validation loss: 2.2457278516725134

Epoch: 5| Step: 10
Training loss: 1.3715600853614298
Validation loss: 2.2989290858079126

Epoch: 364| Step: 0
Training loss: 1.0699221602317983
Validation loss: 2.2527036966507508

Epoch: 5| Step: 1
Training loss: 1.448159131210542
Validation loss: 2.242071090900119

Epoch: 5| Step: 2
Training loss: 1.1469892335800487
Validation loss: 2.2513474118155052

Epoch: 5| Step: 3
Training loss: 0.8194249392377372
Validation loss: 2.25177275074712

Epoch: 5| Step: 4
Training loss: 2.1280232409376896
Validation loss: 2.2503362629967127

Epoch: 5| Step: 5
Training loss: 1.4458117473357763
Validation loss: 2.2447337717530007

Epoch: 5| Step: 6
Training loss: 1.435645026140781
Validation loss: 2.223706123460427

Epoch: 5| Step: 7
Training loss: 1.310892483071305
Validation loss: 2.2769615049406084

Epoch: 5| Step: 8
Training loss: 1.3016387587391338
Validation loss: 2.2712644405074

Epoch: 5| Step: 9
Training loss: 1.1119457600181544
Validation loss: 2.2689450908623217

Epoch: 5| Step: 10
Training loss: 1.117134413091436
Validation loss: 2.2614863608185205

Epoch: 365| Step: 0
Training loss: 1.221691689558101
Validation loss: 2.249999241162244

Epoch: 5| Step: 1
Training loss: 1.845500244616025
Validation loss: 2.342633744632779

Epoch: 5| Step: 2
Training loss: 1.1007870589374429
Validation loss: 2.288822743751401

Epoch: 5| Step: 3
Training loss: 1.439254602125058
Validation loss: 2.2920694312358014

Epoch: 5| Step: 4
Training loss: 1.2081886347368274
Validation loss: 2.306420031431078

Epoch: 5| Step: 5
Training loss: 1.4228157033701996
Validation loss: 2.2618605017967477

Epoch: 5| Step: 6
Training loss: 1.143743823509007
Validation loss: 2.291958712168951

Epoch: 5| Step: 7
Training loss: 1.5118911211180117
Validation loss: 2.2781650228374892

Epoch: 5| Step: 8
Training loss: 1.2115312658755324
Validation loss: 2.309321936050546

Epoch: 5| Step: 9
Training loss: 1.0930884949405062
Validation loss: 2.3421805023581594

Epoch: 5| Step: 10
Training loss: 1.4689330940565173
Validation loss: 2.2327695816268958

Epoch: 366| Step: 0
Training loss: 1.3935388191244618
Validation loss: 2.254671727287772

Epoch: 5| Step: 1
Training loss: 1.6716731297199112
Validation loss: 2.2316045976441363

Epoch: 5| Step: 2
Training loss: 1.0454842738497148
Validation loss: 2.2658193016256654

Epoch: 5| Step: 3
Training loss: 1.5965284923396816
Validation loss: 2.2391640440690423

Epoch: 5| Step: 4
Training loss: 1.4455244579060367
Validation loss: 2.2452740435168868

Epoch: 5| Step: 5
Training loss: 0.9924152142994065
Validation loss: 2.180357892102601

Epoch: 5| Step: 6
Training loss: 1.2072183902194167
Validation loss: 2.2451785966365048

Epoch: 5| Step: 7
Training loss: 1.0467372632870087
Validation loss: 2.21671954799764

Epoch: 5| Step: 8
Training loss: 1.0093485636836532
Validation loss: 2.249313066187666

Epoch: 5| Step: 9
Training loss: 1.2362334831376423
Validation loss: 2.332128001044494

Epoch: 5| Step: 10
Training loss: 1.8670421208563122
Validation loss: 2.2890822603517322

Epoch: 367| Step: 0
Training loss: 1.1353519782907697
Validation loss: 2.3119423977515945

Epoch: 5| Step: 1
Training loss: 0.9120738902735154
Validation loss: 2.316929395099921

Epoch: 5| Step: 2
Training loss: 1.3315872839676033
Validation loss: 2.265219097955496

Epoch: 5| Step: 3
Training loss: 1.3093901986125431
Validation loss: 2.300769724191036

Epoch: 5| Step: 4
Training loss: 1.4680380211565636
Validation loss: 2.328579500613843

Epoch: 5| Step: 5
Training loss: 1.1911793977483993
Validation loss: 2.240978240593487

Epoch: 5| Step: 6
Training loss: 1.0301883897435589
Validation loss: 2.2732244161325053

Epoch: 5| Step: 7
Training loss: 1.2949635770823242
Validation loss: 2.2138441178618877

Epoch: 5| Step: 8
Training loss: 1.0234218334134566
Validation loss: 2.213795029522517

Epoch: 5| Step: 9
Training loss: 1.8797883879491937
Validation loss: 2.258857161486855

Epoch: 5| Step: 10
Training loss: 1.3753637352925625
Validation loss: 2.2499868410789876

Epoch: 368| Step: 0
Training loss: 1.3034840589981826
Validation loss: 2.2326910705529497

Epoch: 5| Step: 1
Training loss: 1.8544106769376179
Validation loss: 2.2883492861911816

Epoch: 5| Step: 2
Training loss: 1.3088970231451293
Validation loss: 2.2620787275538143

Epoch: 5| Step: 3
Training loss: 1.1159366460886102
Validation loss: 2.227853295159004

Epoch: 5| Step: 4
Training loss: 1.020345078046073
Validation loss: 2.264985966049376

Epoch: 5| Step: 5
Training loss: 1.1823372797072478
Validation loss: 2.2549779373048984

Epoch: 5| Step: 6
Training loss: 1.0080153978132966
Validation loss: 2.336010593103863

Epoch: 5| Step: 7
Training loss: 1.0502032991417416
Validation loss: 2.281107185715604

Epoch: 5| Step: 8
Training loss: 1.2479970620591476
Validation loss: 2.3119034578348288

Epoch: 5| Step: 9
Training loss: 1.3583631147540605
Validation loss: 2.2752414238108236

Epoch: 5| Step: 10
Training loss: 1.7900796189528978
Validation loss: 2.2460785445188622

Epoch: 369| Step: 0
Training loss: 1.184251558418368
Validation loss: 2.2587434660606873

Epoch: 5| Step: 1
Training loss: 1.0461676755941511
Validation loss: 2.20882489841054

Epoch: 5| Step: 2
Training loss: 1.3109025316269103
Validation loss: 2.24653015205908

Epoch: 5| Step: 3
Training loss: 1.1245524257856785
Validation loss: 2.2773106137670833

Epoch: 5| Step: 4
Training loss: 1.2338163826040145
Validation loss: 2.2958892734009515

Epoch: 5| Step: 5
Training loss: 1.1470950318356683
Validation loss: 2.246463384330577

Epoch: 5| Step: 6
Training loss: 1.9460332063976251
Validation loss: 2.2703957765979883

Epoch: 5| Step: 7
Training loss: 1.459855602126059
Validation loss: 2.2724318709394637

Epoch: 5| Step: 8
Training loss: 1.2124900955110278
Validation loss: 2.2035275460041444

Epoch: 5| Step: 9
Training loss: 1.543299617783551
Validation loss: 2.2613023414314064

Epoch: 5| Step: 10
Training loss: 1.2199148822233439
Validation loss: 2.2771923824199933

Epoch: 370| Step: 0
Training loss: 1.2786528618872532
Validation loss: 2.296057134085253

Epoch: 5| Step: 1
Training loss: 1.0259532729024852
Validation loss: 2.2751486516376325

Epoch: 5| Step: 2
Training loss: 1.3442730883530516
Validation loss: 2.282140126897533

Epoch: 5| Step: 3
Training loss: 1.0331256455213464
Validation loss: 2.3041741401648923

Epoch: 5| Step: 4
Training loss: 1.383229683053072
Validation loss: 2.2438548153369235

Epoch: 5| Step: 5
Training loss: 1.2579626147805614
Validation loss: 2.2500202697606553

Epoch: 5| Step: 6
Training loss: 1.188380015706016
Validation loss: 2.3147090957409393

Epoch: 5| Step: 7
Training loss: 1.1554701985007718
Validation loss: 2.30510754978258

Epoch: 5| Step: 8
Training loss: 2.057519389880418
Validation loss: 2.314059908996719

Epoch: 5| Step: 9
Training loss: 0.9975089099553026
Validation loss: 2.280889684091985

Epoch: 5| Step: 10
Training loss: 1.1826176411055334
Validation loss: 2.312002349625586

Epoch: 371| Step: 0
Training loss: 1.6358175414079885
Validation loss: 2.2507176775744178

Epoch: 5| Step: 1
Training loss: 1.0286519239543117
Validation loss: 2.2637845018719642

Epoch: 5| Step: 2
Training loss: 1.5080112464647308
Validation loss: 2.2797222621143987

Epoch: 5| Step: 3
Training loss: 1.0681696135710979
Validation loss: 2.229873245274594

Epoch: 5| Step: 4
Training loss: 0.8544567863760508
Validation loss: 2.2348523859445404

Epoch: 5| Step: 5
Training loss: 1.0499503101217078
Validation loss: 2.260774212054945

Epoch: 5| Step: 6
Training loss: 1.8193390171027009
Validation loss: 2.32277075483395

Epoch: 5| Step: 7
Training loss: 1.035985880508826
Validation loss: 2.294407053086455

Epoch: 5| Step: 8
Training loss: 1.241790516114971
Validation loss: 2.2360949417518508

Epoch: 5| Step: 9
Training loss: 1.1973491098193614
Validation loss: 2.289839626126934

Epoch: 5| Step: 10
Training loss: 1.6580760174708258
Validation loss: 2.2922076995230465

Epoch: 372| Step: 0
Training loss: 1.2733738421109728
Validation loss: 2.222831686422441

Epoch: 5| Step: 1
Training loss: 1.1644277831566863
Validation loss: 2.273588465828874

Epoch: 5| Step: 2
Training loss: 1.2901376113386087
Validation loss: 2.3055367766981703

Epoch: 5| Step: 3
Training loss: 1.551262691916187
Validation loss: 2.326972107218524

Epoch: 5| Step: 4
Training loss: 1.5221217024038225
Validation loss: 2.290148954209994

Epoch: 5| Step: 5
Training loss: 1.7813732037684091
Validation loss: 2.181337129062298

Epoch: 5| Step: 6
Training loss: 1.0753916492727482
Validation loss: 2.275470222532566

Epoch: 5| Step: 7
Training loss: 0.9186126398699869
Validation loss: 2.290662605581206

Epoch: 5| Step: 8
Training loss: 1.1098174703720562
Validation loss: 2.2972422463783557

Epoch: 5| Step: 9
Training loss: 1.2547145151766723
Validation loss: 2.2857210501676586

Epoch: 5| Step: 10
Training loss: 0.9584941349019241
Validation loss: 2.276032213489116

Epoch: 373| Step: 0
Training loss: 0.8184802710334836
Validation loss: 2.27517019485118

Epoch: 5| Step: 1
Training loss: 1.3080768532237772
Validation loss: 2.2332377891171475

Epoch: 5| Step: 2
Training loss: 1.85576413664379
Validation loss: 2.310030219454787

Epoch: 5| Step: 3
Training loss: 1.0831679560292706
Validation loss: 2.314603184486338

Epoch: 5| Step: 4
Training loss: 1.266901338112471
Validation loss: 2.3325737754819693

Epoch: 5| Step: 5
Training loss: 1.2367973220744388
Validation loss: 2.2971191332313396

Epoch: 5| Step: 6
Training loss: 1.0298756197485233
Validation loss: 2.343517835049642

Epoch: 5| Step: 7
Training loss: 0.9958236627361894
Validation loss: 2.250499479622716

Epoch: 5| Step: 8
Training loss: 1.4357300518230312
Validation loss: 2.278306577305009

Epoch: 5| Step: 9
Training loss: 1.2612222928953691
Validation loss: 2.246524014915469

Epoch: 5| Step: 10
Training loss: 1.4420758271299838
Validation loss: 2.300120052781962

Epoch: 374| Step: 0
Training loss: 1.2394893300719383
Validation loss: 2.2930834976053123

Epoch: 5| Step: 1
Training loss: 1.2328915434083902
Validation loss: 2.2961684019012565

Epoch: 5| Step: 2
Training loss: 1.3606188553271414
Validation loss: 2.272597144327177

Epoch: 5| Step: 3
Training loss: 1.3966212065558221
Validation loss: 2.285576900066562

Epoch: 5| Step: 4
Training loss: 1.4385652327028675
Validation loss: 2.2541563595832654

Epoch: 5| Step: 5
Training loss: 1.0315265862593122
Validation loss: 2.254074902204194

Epoch: 5| Step: 6
Training loss: 1.0035804784005051
Validation loss: 2.2776553266725577

Epoch: 5| Step: 7
Training loss: 1.8059295739671442
Validation loss: 2.2836531835512472

Epoch: 5| Step: 8
Training loss: 1.1812831369424663
Validation loss: 2.3074528325760646

Epoch: 5| Step: 9
Training loss: 1.1251884408591
Validation loss: 2.219939430551108

Epoch: 5| Step: 10
Training loss: 1.0932009817666852
Validation loss: 2.2475978431764996

Epoch: 375| Step: 0
Training loss: 1.17410823380618
Validation loss: 2.296095734238502

Epoch: 5| Step: 1
Training loss: 1.1258983733795205
Validation loss: 2.2278691094804786

Epoch: 5| Step: 2
Training loss: 1.1892133699765803
Validation loss: 2.2523501722736183

Epoch: 5| Step: 3
Training loss: 1.1130801370566317
Validation loss: 2.311580979756773

Epoch: 5| Step: 4
Training loss: 1.9788353559021612
Validation loss: 2.277033900558884

Epoch: 5| Step: 5
Training loss: 1.4246769220955622
Validation loss: 2.310772639514536

Epoch: 5| Step: 6
Training loss: 1.4565089212518258
Validation loss: 2.267692259842625

Epoch: 5| Step: 7
Training loss: 1.03849329451562
Validation loss: 2.334033053235431

Epoch: 5| Step: 8
Training loss: 0.9782376684556597
Validation loss: 2.2353033043034385

Epoch: 5| Step: 9
Training loss: 1.0902307295046372
Validation loss: 2.2723159371846733

Epoch: 5| Step: 10
Training loss: 1.1219024399825803
Validation loss: 2.2536466391451033

Epoch: 376| Step: 0
Training loss: 1.0271757155236505
Validation loss: 2.2823229312030686

Epoch: 5| Step: 1
Training loss: 1.7325307990304915
Validation loss: 2.332747073363537

Epoch: 5| Step: 2
Training loss: 1.2331794550415145
Validation loss: 2.2561314890725903

Epoch: 5| Step: 3
Training loss: 1.2455017214119621
Validation loss: 2.302292104161766

Epoch: 5| Step: 4
Training loss: 1.4602826124512813
Validation loss: 2.2707553040855646

Epoch: 5| Step: 5
Training loss: 0.9636906207997942
Validation loss: 2.2959765318494427

Epoch: 5| Step: 6
Training loss: 0.9525347273295598
Validation loss: 2.3436099037220197

Epoch: 5| Step: 7
Training loss: 1.133573079462967
Validation loss: 2.2464054282694925

Epoch: 5| Step: 8
Training loss: 1.2450019573671205
Validation loss: 2.2977729266063585

Epoch: 5| Step: 9
Training loss: 1.1782009029474976
Validation loss: 2.2980851347984386

Epoch: 5| Step: 10
Training loss: 1.4129911125967296
Validation loss: 2.2666960722332687

Epoch: 377| Step: 0
Training loss: 1.1669124049283892
Validation loss: 2.3494118353508373

Epoch: 5| Step: 1
Training loss: 1.601928073749504
Validation loss: 2.313614460050461

Epoch: 5| Step: 2
Training loss: 1.7195417487912823
Validation loss: 2.3660591821044306

Epoch: 5| Step: 3
Training loss: 1.517176669521156
Validation loss: 2.2734764543178705

Epoch: 5| Step: 4
Training loss: 1.1738970794989763
Validation loss: 2.2403845057769147

Epoch: 5| Step: 5
Training loss: 1.1077586474329706
Validation loss: 2.2216006691146144

Epoch: 5| Step: 6
Training loss: 1.3441738524760243
Validation loss: 2.2745543541852307

Epoch: 5| Step: 7
Training loss: 0.9602529056527953
Validation loss: 2.3217329948256746

Epoch: 5| Step: 8
Training loss: 1.1247549849834484
Validation loss: 2.3108638084597857

Epoch: 5| Step: 9
Training loss: 1.0725316341331992
Validation loss: 2.2672279025768405

Epoch: 5| Step: 10
Training loss: 0.8961555692439549
Validation loss: 2.270197653402263

Epoch: 378| Step: 0
Training loss: 0.9490206476403317
Validation loss: 2.327749141181808

Epoch: 5| Step: 1
Training loss: 0.9935960158520061
Validation loss: 2.199744274522524

Epoch: 5| Step: 2
Training loss: 0.8632228020261964
Validation loss: 2.2155056575830168

Epoch: 5| Step: 3
Training loss: 1.048876883795925
Validation loss: 2.273858638359647

Epoch: 5| Step: 4
Training loss: 2.084591320428435
Validation loss: 2.2818324393030927

Epoch: 5| Step: 5
Training loss: 1.140166987603424
Validation loss: 2.3154075146335718

Epoch: 5| Step: 6
Training loss: 1.2875800654135896
Validation loss: 2.2797556129384318

Epoch: 5| Step: 7
Training loss: 1.4035215824127105
Validation loss: 2.2725148625154454

Epoch: 5| Step: 8
Training loss: 1.2090228787948059
Validation loss: 2.37674530916875

Epoch: 5| Step: 9
Training loss: 1.4344777388336245
Validation loss: 2.2672846321209046

Epoch: 5| Step: 10
Training loss: 1.0447315648833313
Validation loss: 2.3449273590277238

Epoch: 379| Step: 0
Training loss: 0.9709048147995456
Validation loss: 2.340339504723881

Epoch: 5| Step: 1
Training loss: 1.4948477474241737
Validation loss: 2.2608878178320473

Epoch: 5| Step: 2
Training loss: 1.1664461654098386
Validation loss: 2.2950926765969553

Epoch: 5| Step: 3
Training loss: 1.0389040489133299
Validation loss: 2.2763107580765274

Epoch: 5| Step: 4
Training loss: 1.2350344284756858
Validation loss: 2.310314179751828

Epoch: 5| Step: 5
Training loss: 1.8154365822598026
Validation loss: 2.2806880200841326

Epoch: 5| Step: 6
Training loss: 1.5152627571046011
Validation loss: 2.260729765828557

Epoch: 5| Step: 7
Training loss: 1.181851555779867
Validation loss: 2.2786461206017004

Epoch: 5| Step: 8
Training loss: 1.517608681546658
Validation loss: 2.3144706094390415

Epoch: 5| Step: 9
Training loss: 1.1134017076073899
Validation loss: 2.266536289771812

Epoch: 5| Step: 10
Training loss: 0.9412170789921577
Validation loss: 2.2804740331107767

Epoch: 380| Step: 0
Training loss: 0.9678508523566696
Validation loss: 2.3101234593480795

Epoch: 5| Step: 1
Training loss: 0.9343702845629865
Validation loss: 2.3329347934464133

Epoch: 5| Step: 2
Training loss: 1.0621227267774005
Validation loss: 2.361363631813191

Epoch: 5| Step: 3
Training loss: 1.302772441347892
Validation loss: 2.300971878773015

Epoch: 5| Step: 4
Training loss: 1.9382834542510643
Validation loss: 2.302980431832656

Epoch: 5| Step: 5
Training loss: 0.9258986772836989
Validation loss: 2.308264648295523

Epoch: 5| Step: 6
Training loss: 1.0023165335643331
Validation loss: 2.2546545523088954

Epoch: 5| Step: 7
Training loss: 1.2554012429984034
Validation loss: 2.3056113889751657

Epoch: 5| Step: 8
Training loss: 1.4114937818892264
Validation loss: 2.2631277271064048

Epoch: 5| Step: 9
Training loss: 1.272970991749567
Validation loss: 2.3134192834839085

Epoch: 5| Step: 10
Training loss: 1.5172245197906535
Validation loss: 2.30480836913202

Epoch: 381| Step: 0
Training loss: 0.9993047085221546
Validation loss: 2.3313084126214716

Epoch: 5| Step: 1
Training loss: 1.1551331461501648
Validation loss: 2.2641024986287133

Epoch: 5| Step: 2
Training loss: 1.1670898396643063
Validation loss: 2.290698256460891

Epoch: 5| Step: 3
Training loss: 1.3032333127754872
Validation loss: 2.325156246672894

Epoch: 5| Step: 4
Training loss: 1.706270026344457
Validation loss: 2.329672228329956

Epoch: 5| Step: 5
Training loss: 1.0740914564139001
Validation loss: 2.3604221042829314

Epoch: 5| Step: 6
Training loss: 1.3787698651263487
Validation loss: 2.319058026643598

Epoch: 5| Step: 7
Training loss: 1.0896675213491176
Validation loss: 2.316293630653517

Epoch: 5| Step: 8
Training loss: 1.2706091427693116
Validation loss: 2.265028588560217

Epoch: 5| Step: 9
Training loss: 1.259783462279848
Validation loss: 2.314699660560024

Epoch: 5| Step: 10
Training loss: 1.2455941756397118
Validation loss: 2.2834675959212283

Epoch: 382| Step: 0
Training loss: 1.7530511415532415
Validation loss: 2.234821925724458

Epoch: 5| Step: 1
Training loss: 1.27962721425303
Validation loss: 2.246925296095288

Epoch: 5| Step: 2
Training loss: 1.2866865050972176
Validation loss: 2.255902362000711

Epoch: 5| Step: 3
Training loss: 1.3874192308853621
Validation loss: 2.3274561886317398

Epoch: 5| Step: 4
Training loss: 1.3038007726685454
Validation loss: 2.2162160371496284

Epoch: 5| Step: 5
Training loss: 1.2576579123329743
Validation loss: 2.2631421094850537

Epoch: 5| Step: 6
Training loss: 1.531654538025984
Validation loss: 2.289773676780714

Epoch: 5| Step: 7
Training loss: 0.8754736435831896
Validation loss: 2.2386225530877537

Epoch: 5| Step: 8
Training loss: 1.0205123682239818
Validation loss: 2.272529029524951

Epoch: 5| Step: 9
Training loss: 0.9395633561462793
Validation loss: 2.2423558039978913

Epoch: 5| Step: 10
Training loss: 1.1208108684647256
Validation loss: 2.325545658382866

Epoch: 383| Step: 0
Training loss: 1.8634756054869281
Validation loss: 2.3554251159730737

Epoch: 5| Step: 1
Training loss: 1.3150870847694245
Validation loss: 2.3548564642617418

Epoch: 5| Step: 2
Training loss: 1.090998103202199
Validation loss: 2.3369480939956375

Epoch: 5| Step: 3
Training loss: 1.5823015146993318
Validation loss: 2.268917008596727

Epoch: 5| Step: 4
Training loss: 0.9884839660451693
Validation loss: 2.2695849478315684

Epoch: 5| Step: 5
Training loss: 1.1332902624323347
Validation loss: 2.3259754122224705

Epoch: 5| Step: 6
Training loss: 1.3057611125522115
Validation loss: 2.2256719702759984

Epoch: 5| Step: 7
Training loss: 1.461691106130153
Validation loss: 2.294189628983593

Epoch: 5| Step: 8
Training loss: 0.9292021053267369
Validation loss: 2.254652505629401

Epoch: 5| Step: 9
Training loss: 0.9890550441370525
Validation loss: 2.288954256298271

Epoch: 5| Step: 10
Training loss: 0.8687776986516041
Validation loss: 2.2363520437063875

Epoch: 384| Step: 0
Training loss: 1.3022009631111615
Validation loss: 2.237359281390816

Epoch: 5| Step: 1
Training loss: 1.10889333020032
Validation loss: 2.283532591253494

Epoch: 5| Step: 2
Training loss: 1.6663068223952886
Validation loss: 2.2694529070375737

Epoch: 5| Step: 3
Training loss: 1.124990993039845
Validation loss: 2.2800319070028094

Epoch: 5| Step: 4
Training loss: 1.2645744390452451
Validation loss: 2.226087876606774

Epoch: 5| Step: 5
Training loss: 0.8431849176877556
Validation loss: 2.2894389880167827

Epoch: 5| Step: 6
Training loss: 1.2398988765583168
Validation loss: 2.323680971752902

Epoch: 5| Step: 7
Training loss: 1.5675806984213707
Validation loss: 2.283182578308136

Epoch: 5| Step: 8
Training loss: 1.0456611656232346
Validation loss: 2.3295148032335407

Epoch: 5| Step: 9
Training loss: 0.9999033463975373
Validation loss: 2.2500633728737363

Epoch: 5| Step: 10
Training loss: 1.119766246891561
Validation loss: 2.257157000767905

Epoch: 385| Step: 0
Training loss: 1.199422315784379
Validation loss: 2.316395425030224

Epoch: 5| Step: 1
Training loss: 0.9702447618806546
Validation loss: 2.3083801953644136

Epoch: 5| Step: 2
Training loss: 0.8036922485106859
Validation loss: 2.344189196491833

Epoch: 5| Step: 3
Training loss: 1.73880429060402
Validation loss: 2.3453673319218638

Epoch: 5| Step: 4
Training loss: 1.3472667628831225
Validation loss: 2.327632789530456

Epoch: 5| Step: 5
Training loss: 1.1714213192446115
Validation loss: 2.320863129947785

Epoch: 5| Step: 6
Training loss: 1.3152717659792836
Validation loss: 2.2852245773899673

Epoch: 5| Step: 7
Training loss: 1.0072704306372227
Validation loss: 2.234390252426504

Epoch: 5| Step: 8
Training loss: 0.9911576881575059
Validation loss: 2.246847289930262

Epoch: 5| Step: 9
Training loss: 1.4332338135938292
Validation loss: 2.312948810290199

Epoch: 5| Step: 10
Training loss: 1.388772480642788
Validation loss: 2.2851481837643974

Epoch: 386| Step: 0
Training loss: 1.356704983666113
Validation loss: 2.268936576054203

Epoch: 5| Step: 1
Training loss: 1.1984231403390753
Validation loss: 2.2964083959599764

Epoch: 5| Step: 2
Training loss: 1.8453906243798552
Validation loss: 2.255506270222246

Epoch: 5| Step: 3
Training loss: 1.0864446539793355
Validation loss: 2.2699633347928914

Epoch: 5| Step: 4
Training loss: 1.0716439201013428
Validation loss: 2.2295508476770776

Epoch: 5| Step: 5
Training loss: 1.112119155160115
Validation loss: 2.298430076482231

Epoch: 5| Step: 6
Training loss: 1.4284697803028685
Validation loss: 2.2050268615462336

Epoch: 5| Step: 7
Training loss: 1.0673351783279812
Validation loss: 2.266350337756285

Epoch: 5| Step: 8
Training loss: 1.1150229766428437
Validation loss: 2.254184444338357

Epoch: 5| Step: 9
Training loss: 1.149210507527349
Validation loss: 2.347548474769708

Epoch: 5| Step: 10
Training loss: 1.0665168565114587
Validation loss: 2.2903011120401384

Epoch: 387| Step: 0
Training loss: 1.0804869721283488
Validation loss: 2.3642582429798042

Epoch: 5| Step: 1
Training loss: 0.7649367216530003
Validation loss: 2.3327040248500195

Epoch: 5| Step: 2
Training loss: 1.3247727217171754
Validation loss: 2.3052323114730706

Epoch: 5| Step: 3
Training loss: 1.975032229100198
Validation loss: 2.321837855430465

Epoch: 5| Step: 4
Training loss: 1.1589769219807178
Validation loss: 2.2864411014921604

Epoch: 5| Step: 5
Training loss: 1.029304692566227
Validation loss: 2.2762213367816897

Epoch: 5| Step: 6
Training loss: 1.5818764693284644
Validation loss: 2.227212896309573

Epoch: 5| Step: 7
Training loss: 1.2126741815103137
Validation loss: 2.2672710398193394

Epoch: 5| Step: 8
Training loss: 0.8031586502684686
Validation loss: 2.2726833202031154

Epoch: 5| Step: 9
Training loss: 1.3522102259186775
Validation loss: 2.276430056646506

Epoch: 5| Step: 10
Training loss: 1.2707214879498336
Validation loss: 2.25692999175445

Epoch: 388| Step: 0
Training loss: 1.354116859498192
Validation loss: 2.260522552893937

Epoch: 5| Step: 1
Training loss: 1.170479617645731
Validation loss: 2.3032800647366054

Epoch: 5| Step: 2
Training loss: 1.116069207325496
Validation loss: 2.3043085820224873

Epoch: 5| Step: 3
Training loss: 1.1031083967564144
Validation loss: 2.318256014722548

Epoch: 5| Step: 4
Training loss: 1.3110085141904249
Validation loss: 2.3354053072841428

Epoch: 5| Step: 5
Training loss: 1.306639986365922
Validation loss: 2.3484545824807546

Epoch: 5| Step: 6
Training loss: 0.9227728593155381
Validation loss: 2.3387339983571205

Epoch: 5| Step: 7
Training loss: 1.433249034546574
Validation loss: 2.288204258594752

Epoch: 5| Step: 8
Training loss: 1.8865398061492227
Validation loss: 2.2938280385869887

Epoch: 5| Step: 9
Training loss: 0.9014990018964967
Validation loss: 2.3330810797997015

Epoch: 5| Step: 10
Training loss: 0.7138436414016075
Validation loss: 2.2551804600759646

Epoch: 389| Step: 0
Training loss: 1.245784182945176
Validation loss: 2.2761150459131265

Epoch: 5| Step: 1
Training loss: 1.0159725474868941
Validation loss: 2.254544516773033

Epoch: 5| Step: 2
Training loss: 1.2468726136607804
Validation loss: 2.333507534268965

Epoch: 5| Step: 3
Training loss: 0.9641432593847267
Validation loss: 2.243009332252363

Epoch: 5| Step: 4
Training loss: 1.7117147552708265
Validation loss: 2.290212471510669

Epoch: 5| Step: 5
Training loss: 1.0888380106622058
Validation loss: 2.2575346897188924

Epoch: 5| Step: 6
Training loss: 1.0681416012370617
Validation loss: 2.262604230819579

Epoch: 5| Step: 7
Training loss: 1.3775970035744134
Validation loss: 2.2962930050939274

Epoch: 5| Step: 8
Training loss: 1.0010032389737984
Validation loss: 2.2371948562997837

Epoch: 5| Step: 9
Training loss: 1.2742845023642477
Validation loss: 2.234282735142568

Epoch: 5| Step: 10
Training loss: 1.245041022869622
Validation loss: 2.2545832619562707

Epoch: 390| Step: 0
Training loss: 1.5535913945310358
Validation loss: 2.234108348252258

Epoch: 5| Step: 1
Training loss: 0.9478262903635912
Validation loss: 2.241045187756825

Epoch: 5| Step: 2
Training loss: 1.073252350721755
Validation loss: 2.2826563396571498

Epoch: 5| Step: 3
Training loss: 0.9657583496459602
Validation loss: 2.344352890735659

Epoch: 5| Step: 4
Training loss: 0.9625848435498033
Validation loss: 2.3136241478629884

Epoch: 5| Step: 5
Training loss: 1.264412240023503
Validation loss: 2.24112738582416

Epoch: 5| Step: 6
Training loss: 1.2502716722904108
Validation loss: 2.2520115097556253

Epoch: 5| Step: 7
Training loss: 1.0802177352765872
Validation loss: 2.3678343595833877

Epoch: 5| Step: 8
Training loss: 1.8359273058019838
Validation loss: 2.3329798799517683

Epoch: 5| Step: 9
Training loss: 1.4141273272918458
Validation loss: 2.2832004537945463

Epoch: 5| Step: 10
Training loss: 1.211364719953838
Validation loss: 2.3405006937233273

Epoch: 391| Step: 0
Training loss: 0.9893705975934014
Validation loss: 2.324257191848273

Epoch: 5| Step: 1
Training loss: 1.8573378615126737
Validation loss: 2.2538734112747965

Epoch: 5| Step: 2
Training loss: 0.956903628189523
Validation loss: 2.3206410867800886

Epoch: 5| Step: 3
Training loss: 0.915080033955504
Validation loss: 2.269245563133759

Epoch: 5| Step: 4
Training loss: 1.069217260734015
Validation loss: 2.3275360124391575

Epoch: 5| Step: 5
Training loss: 1.3023138325440873
Validation loss: 2.1647433313945625

Epoch: 5| Step: 6
Training loss: 1.228005016571385
Validation loss: 2.301349831694237

Epoch: 5| Step: 7
Training loss: 1.590571806192445
Validation loss: 2.2772956195350047

Epoch: 5| Step: 8
Training loss: 1.2870444019456557
Validation loss: 2.313083276908535

Epoch: 5| Step: 9
Training loss: 0.9597266407036974
Validation loss: 2.286345771999289

Epoch: 5| Step: 10
Training loss: 1.225927151906887
Validation loss: 2.287744320833899

Epoch: 392| Step: 0
Training loss: 1.1231701061805386
Validation loss: 2.316795939017424

Epoch: 5| Step: 1
Training loss: 1.3516451418974094
Validation loss: 2.2928923080371795

Epoch: 5| Step: 2
Training loss: 1.1434281797985753
Validation loss: 2.277313597516868

Epoch: 5| Step: 3
Training loss: 1.8104122239363065
Validation loss: 2.2970073143671175

Epoch: 5| Step: 4
Training loss: 1.2584502694235409
Validation loss: 2.2788069236992863

Epoch: 5| Step: 5
Training loss: 0.7853965201859093
Validation loss: 2.2797557180814536

Epoch: 5| Step: 6
Training loss: 1.1569430362061388
Validation loss: 2.3050717252710355

Epoch: 5| Step: 7
Training loss: 1.1185888291522599
Validation loss: 2.26636184178488

Epoch: 5| Step: 8
Training loss: 1.5231481032718823
Validation loss: 2.2934126494406715

Epoch: 5| Step: 9
Training loss: 0.8923245660412673
Validation loss: 2.2656484204511402

Epoch: 5| Step: 10
Training loss: 0.703251933190448
Validation loss: 2.334706587576206

Epoch: 393| Step: 0
Training loss: 0.9961158301206274
Validation loss: 2.2959960836338746

Epoch: 5| Step: 1
Training loss: 1.2823132081111421
Validation loss: 2.289127722288398

Epoch: 5| Step: 2
Training loss: 1.1180604311966402
Validation loss: 2.262484019097323

Epoch: 5| Step: 3
Training loss: 1.5217736964416761
Validation loss: 2.292107198180017

Epoch: 5| Step: 4
Training loss: 1.1004473946809465
Validation loss: 2.3223705299964137

Epoch: 5| Step: 5
Training loss: 0.955440522694755
Validation loss: 2.2487413208243074

Epoch: 5| Step: 6
Training loss: 0.8536785677269327
Validation loss: 2.2640523191172015

Epoch: 5| Step: 7
Training loss: 1.708966727029414
Validation loss: 2.2591220552148843

Epoch: 5| Step: 8
Training loss: 1.1143874712303419
Validation loss: 2.2973798484833012

Epoch: 5| Step: 9
Training loss: 1.3231720064703096
Validation loss: 2.278806442764954

Epoch: 5| Step: 10
Training loss: 1.1026798290203594
Validation loss: 2.2442839022790335

Epoch: 394| Step: 0
Training loss: 1.8522142639337527
Validation loss: 2.272049349016158

Epoch: 5| Step: 1
Training loss: 1.2411820283009738
Validation loss: 2.3130080017915726

Epoch: 5| Step: 2
Training loss: 1.1218556330717304
Validation loss: 2.251138506193364

Epoch: 5| Step: 3
Training loss: 0.9722781078231573
Validation loss: 2.275912466587466

Epoch: 5| Step: 4
Training loss: 0.9342889790823736
Validation loss: 2.33476985565843

Epoch: 5| Step: 5
Training loss: 1.173808473749427
Validation loss: 2.293222704730187

Epoch: 5| Step: 6
Training loss: 1.3718652538048945
Validation loss: 2.302096709327293

Epoch: 5| Step: 7
Training loss: 1.0285077481198208
Validation loss: 2.320736953386034

Epoch: 5| Step: 8
Training loss: 1.0285065890682052
Validation loss: 2.277988799313286

Epoch: 5| Step: 9
Training loss: 1.1689843702682763
Validation loss: 2.2713404692499375

Epoch: 5| Step: 10
Training loss: 1.253101363874781
Validation loss: 2.322482020168121

Epoch: 395| Step: 0
Training loss: 1.3021868194146204
Validation loss: 2.282214357738895

Epoch: 5| Step: 1
Training loss: 1.7617895277062192
Validation loss: 2.306575387207543

Epoch: 5| Step: 2
Training loss: 1.2918045934233713
Validation loss: 2.2614716760036173

Epoch: 5| Step: 3
Training loss: 1.35072830122895
Validation loss: 2.3066914795675446

Epoch: 5| Step: 4
Training loss: 1.1007021526998708
Validation loss: 2.3215184391651857

Epoch: 5| Step: 5
Training loss: 0.923830802542615
Validation loss: 2.3382712905228913

Epoch: 5| Step: 6
Training loss: 1.055499915418888
Validation loss: 2.286652116264924

Epoch: 5| Step: 7
Training loss: 1.3537381692441601
Validation loss: 2.257391754914127

Epoch: 5| Step: 8
Training loss: 0.9447081975155418
Validation loss: 2.2586886921408604

Epoch: 5| Step: 9
Training loss: 0.9182960089236956
Validation loss: 2.253186785676969

Epoch: 5| Step: 10
Training loss: 0.935295405666602
Validation loss: 2.2910441570192375

Epoch: 396| Step: 0
Training loss: 1.236729079279896
Validation loss: 2.2364770398621237

Epoch: 5| Step: 1
Training loss: 1.2863297597699241
Validation loss: 2.305500837095885

Epoch: 5| Step: 2
Training loss: 0.9097802691265847
Validation loss: 2.283301924844353

Epoch: 5| Step: 3
Training loss: 0.8858201771713459
Validation loss: 2.2881340835607493

Epoch: 5| Step: 4
Training loss: 1.164681391719177
Validation loss: 2.2834569134408866

Epoch: 5| Step: 5
Training loss: 1.9918165871392322
Validation loss: 2.3226524324877844

Epoch: 5| Step: 6
Training loss: 1.066208538130286
Validation loss: 2.2976484895850096

Epoch: 5| Step: 7
Training loss: 1.0172898365582133
Validation loss: 2.341420154984018

Epoch: 5| Step: 8
Training loss: 1.2365363790834765
Validation loss: 2.2857135669105397

Epoch: 5| Step: 9
Training loss: 1.0967996859438034
Validation loss: 2.32251527742265

Epoch: 5| Step: 10
Training loss: 1.1371078611761545
Validation loss: 2.269042439422969

Epoch: 397| Step: 0
Training loss: 1.051340174305812
Validation loss: 2.2394549410037663

Epoch: 5| Step: 1
Training loss: 1.5549642805308443
Validation loss: 2.2376480482532637

Epoch: 5| Step: 2
Training loss: 1.2515507139110553
Validation loss: 2.277524969439703

Epoch: 5| Step: 3
Training loss: 1.1020979425415074
Validation loss: 2.231266724996691

Epoch: 5| Step: 4
Training loss: 1.1402827232698616
Validation loss: 2.252237194432212

Epoch: 5| Step: 5
Training loss: 0.96513263532081
Validation loss: 2.298518136884941

Epoch: 5| Step: 6
Training loss: 1.083822152310962
Validation loss: 2.2831822066492387

Epoch: 5| Step: 7
Training loss: 1.3272176897115178
Validation loss: 2.2411570036607658

Epoch: 5| Step: 8
Training loss: 1.1375225148749954
Validation loss: 2.27328601046718

Epoch: 5| Step: 9
Training loss: 1.1795883137013785
Validation loss: 2.2869399938294044

Epoch: 5| Step: 10
Training loss: 1.0952360140097532
Validation loss: 2.239624720365341

Epoch: 398| Step: 0
Training loss: 0.9015616788810812
Validation loss: 2.2849040909438623

Epoch: 5| Step: 1
Training loss: 1.2013029693770048
Validation loss: 2.2686757719794186

Epoch: 5| Step: 2
Training loss: 1.0808577801879102
Validation loss: 2.277906401355176

Epoch: 5| Step: 3
Training loss: 1.9090039730919908
Validation loss: 2.3051636101360176

Epoch: 5| Step: 4
Training loss: 0.764703000827038
Validation loss: 2.283128874093076

Epoch: 5| Step: 5
Training loss: 1.4144151785247536
Validation loss: 2.2518127879794334

Epoch: 5| Step: 6
Training loss: 1.0233151311736302
Validation loss: 2.306805572345617

Epoch: 5| Step: 7
Training loss: 1.269595851721714
Validation loss: 2.303707442652017

Epoch: 5| Step: 8
Training loss: 1.2495189694860942
Validation loss: 2.2809401821655606

Epoch: 5| Step: 9
Training loss: 1.0390014630510238
Validation loss: 2.2308369396525216

Epoch: 5| Step: 10
Training loss: 0.7115654320671108
Validation loss: 2.337420376561095

Epoch: 399| Step: 0
Training loss: 1.177179765830318
Validation loss: 2.290722935878443

Epoch: 5| Step: 1
Training loss: 1.097120378223536
Validation loss: 2.295078586594155

Epoch: 5| Step: 2
Training loss: 1.0309231558059406
Validation loss: 2.3377898567850095

Epoch: 5| Step: 3
Training loss: 1.066360360859471
Validation loss: 2.2573069464071756

Epoch: 5| Step: 4
Training loss: 1.0343767217984807
Validation loss: 2.2977847586453843

Epoch: 5| Step: 5
Training loss: 0.6766721332694103
Validation loss: 2.2535853418813256

Epoch: 5| Step: 6
Training loss: 1.199828052122484
Validation loss: 2.292457490167411

Epoch: 5| Step: 7
Training loss: 1.8861633494238612
Validation loss: 2.280190545891838

Epoch: 5| Step: 8
Training loss: 0.8664735828099371
Validation loss: 2.242504055651353

Epoch: 5| Step: 9
Training loss: 1.0925412174192555
Validation loss: 2.29240765678365

Epoch: 5| Step: 10
Training loss: 1.299234427095429
Validation loss: 2.27036088979524

Epoch: 400| Step: 0
Training loss: 1.1504273594948018
Validation loss: 2.217212660307363

Epoch: 5| Step: 1
Training loss: 1.0076706660808914
Validation loss: 2.3313728730994776

Epoch: 5| Step: 2
Training loss: 1.0667878191412363
Validation loss: 2.2688847204540648

Epoch: 5| Step: 3
Training loss: 1.3473281239750674
Validation loss: 2.2970389901326076

Epoch: 5| Step: 4
Training loss: 1.2609905113601352
Validation loss: 2.2335777394937626

Epoch: 5| Step: 5
Training loss: 1.1139640989357114
Validation loss: 2.25270854692229

Epoch: 5| Step: 6
Training loss: 0.8065681332580288
Validation loss: 2.227960673380461

Epoch: 5| Step: 7
Training loss: 1.672541690415147
Validation loss: 2.2904865712989126

Epoch: 5| Step: 8
Training loss: 1.2859920578202628
Validation loss: 2.2364924258229237

Epoch: 5| Step: 9
Training loss: 0.9221204657187825
Validation loss: 2.3050447432179517

Epoch: 5| Step: 10
Training loss: 1.157526600245752
Validation loss: 2.265008617227992

Epoch: 401| Step: 0
Training loss: 1.1459020536218403
Validation loss: 2.218848886442603

Epoch: 5| Step: 1
Training loss: 1.0280287746862666
Validation loss: 2.3153733647265993

Epoch: 5| Step: 2
Training loss: 1.035474332486726
Validation loss: 2.3000090502578283

Epoch: 5| Step: 3
Training loss: 1.558288391335599
Validation loss: 2.254445264026805

Epoch: 5| Step: 4
Training loss: 1.140599603239576
Validation loss: 2.326209066787005

Epoch: 5| Step: 5
Training loss: 0.8983663779593778
Validation loss: 2.2751672753345815

Epoch: 5| Step: 6
Training loss: 1.1433387767525
Validation loss: 2.279445871472087

Epoch: 5| Step: 7
Training loss: 1.1806515424015653
Validation loss: 2.2619868514959776

Epoch: 5| Step: 8
Training loss: 1.279409808350177
Validation loss: 2.2387392800637524

Epoch: 5| Step: 9
Training loss: 1.6310432010685159
Validation loss: 2.3006510542509515

Epoch: 5| Step: 10
Training loss: 0.7706343204896831
Validation loss: 2.342157371055929

Epoch: 402| Step: 0
Training loss: 0.9078484940082059
Validation loss: 2.2501554048073036

Epoch: 5| Step: 1
Training loss: 1.2716874811528043
Validation loss: 2.3084422415187213

Epoch: 5| Step: 2
Training loss: 1.2219850202819165
Validation loss: 2.262750223675104

Epoch: 5| Step: 3
Training loss: 0.9877604141188417
Validation loss: 2.2895380315981417

Epoch: 5| Step: 4
Training loss: 1.039959971684631
Validation loss: 2.270717823003032

Epoch: 5| Step: 5
Training loss: 1.1617815853690663
Validation loss: 2.255607310695347

Epoch: 5| Step: 6
Training loss: 0.953781152218959
Validation loss: 2.2892766539661777

Epoch: 5| Step: 7
Training loss: 1.147557550786427
Validation loss: 2.2725650032300653

Epoch: 5| Step: 8
Training loss: 1.250262137583135
Validation loss: 2.26014332266662

Epoch: 5| Step: 9
Training loss: 1.143503293805368
Validation loss: 2.3295178670349923

Epoch: 5| Step: 10
Training loss: 1.7046389369183665
Validation loss: 2.343676124420249

Epoch: 403| Step: 0
Training loss: 0.9884616852948315
Validation loss: 2.3343436878086203

Epoch: 5| Step: 1
Training loss: 1.1331237365412625
Validation loss: 2.356793555068194

Epoch: 5| Step: 2
Training loss: 1.3455867633977066
Validation loss: 2.295438530337935

Epoch: 5| Step: 3
Training loss: 1.1763813603798443
Validation loss: 2.35506362735727

Epoch: 5| Step: 4
Training loss: 0.8480852860757525
Validation loss: 2.358250540788862

Epoch: 5| Step: 5
Training loss: 1.5644921382463912
Validation loss: 2.2864747876657616

Epoch: 5| Step: 6
Training loss: 1.0025748244446544
Validation loss: 2.3512858212131635

Epoch: 5| Step: 7
Training loss: 2.0258140011106516
Validation loss: 2.3152240815458565

Epoch: 5| Step: 8
Training loss: 0.9311752596567293
Validation loss: 2.2822426908821627

Epoch: 5| Step: 9
Training loss: 1.0071565134345857
Validation loss: 2.2702941792615565

Epoch: 5| Step: 10
Training loss: 0.923465617311746
Validation loss: 2.2029425770162767

Epoch: 404| Step: 0
Training loss: 0.8168252116340949
Validation loss: 2.2229636355151987

Epoch: 5| Step: 1
Training loss: 1.7292136297014853
Validation loss: 2.32212452290043

Epoch: 5| Step: 2
Training loss: 1.1144192417367664
Validation loss: 2.2778680253110517

Epoch: 5| Step: 3
Training loss: 0.9453337485707514
Validation loss: 2.2609371735094457

Epoch: 5| Step: 4
Training loss: 1.201793131626263
Validation loss: 2.278462380520472

Epoch: 5| Step: 5
Training loss: 1.3377004223688496
Validation loss: 2.269756919639567

Epoch: 5| Step: 6
Training loss: 1.0224815155261195
Validation loss: 2.2860920149393023

Epoch: 5| Step: 7
Training loss: 1.0966879486832657
Validation loss: 2.257543124888084

Epoch: 5| Step: 8
Training loss: 0.9519744557592025
Validation loss: 2.321281690592429

Epoch: 5| Step: 9
Training loss: 1.3145916938012094
Validation loss: 2.3367929966640846

Epoch: 5| Step: 10
Training loss: 1.0833574561343273
Validation loss: 2.3896327915761733

Epoch: 405| Step: 0
Training loss: 1.0967521881297335
Validation loss: 2.3352470588910546

Epoch: 5| Step: 1
Training loss: 1.314341660828169
Validation loss: 2.347004025733077

Epoch: 5| Step: 2
Training loss: 1.2880406346427056
Validation loss: 2.2170043287358228

Epoch: 5| Step: 3
Training loss: 0.897302922896464
Validation loss: 2.3307708991315494

Epoch: 5| Step: 4
Training loss: 0.9308840000418774
Validation loss: 2.343187315198136

Epoch: 5| Step: 5
Training loss: 0.8598043929583886
Validation loss: 2.3553010336687223

Epoch: 5| Step: 6
Training loss: 1.132641009800371
Validation loss: 2.2749974850840498

Epoch: 5| Step: 7
Training loss: 1.0111231873621345
Validation loss: 2.244222547481524

Epoch: 5| Step: 8
Training loss: 0.8220714783881166
Validation loss: 2.2904667749340546

Epoch: 5| Step: 9
Training loss: 1.4050546864221525
Validation loss: 2.257813403820639

Epoch: 5| Step: 10
Training loss: 1.8753184366028932
Validation loss: 2.238674897239237

Epoch: 406| Step: 0
Training loss: 1.0905925407060832
Validation loss: 2.2791601057168704

Epoch: 5| Step: 1
Training loss: 0.9812320610398999
Validation loss: 2.2348624570491857

Epoch: 5| Step: 2
Training loss: 1.7008516029873157
Validation loss: 2.285939539932277

Epoch: 5| Step: 3
Training loss: 1.0004005226083554
Validation loss: 2.2497994836037662

Epoch: 5| Step: 4
Training loss: 1.0057286446068052
Validation loss: 2.275609339431

Epoch: 5| Step: 5
Training loss: 0.7816955059102401
Validation loss: 2.3052992414693434

Epoch: 5| Step: 6
Training loss: 1.480554341682921
Validation loss: 2.283542932091421

Epoch: 5| Step: 7
Training loss: 1.1609838340415786
Validation loss: 2.3528369092218084

Epoch: 5| Step: 8
Training loss: 0.8111110332531072
Validation loss: 2.30012264972437

Epoch: 5| Step: 9
Training loss: 1.474787295894053
Validation loss: 2.3318490311565827

Epoch: 5| Step: 10
Training loss: 1.0892945139616617
Validation loss: 2.33479747197536

Epoch: 407| Step: 0
Training loss: 1.049211485291509
Validation loss: 2.288342657358904

Epoch: 5| Step: 1
Training loss: 1.1257305951869938
Validation loss: 2.371171109022713

Epoch: 5| Step: 2
Training loss: 1.2370477543604768
Validation loss: 2.3768936621515557

Epoch: 5| Step: 3
Training loss: 1.739589653079799
Validation loss: 2.3802096983341423

Epoch: 5| Step: 4
Training loss: 0.8207194817359694
Validation loss: 2.352491612845257

Epoch: 5| Step: 5
Training loss: 1.1341803875069143
Validation loss: 2.2868022366215772

Epoch: 5| Step: 6
Training loss: 1.2498148304163599
Validation loss: 2.2531029442025714

Epoch: 5| Step: 7
Training loss: 0.9583069687133058
Validation loss: 2.223174496478909

Epoch: 5| Step: 8
Training loss: 1.126252377980693
Validation loss: 2.2605714589500714

Epoch: 5| Step: 9
Training loss: 1.2315905588937277
Validation loss: 2.2863302421770615

Epoch: 5| Step: 10
Training loss: 1.1507516498475117
Validation loss: 2.2735657484696423

Epoch: 408| Step: 0
Training loss: 1.026440821945333
Validation loss: 2.2829698795963456

Epoch: 5| Step: 1
Training loss: 1.0689803695018207
Validation loss: 2.29121037039561

Epoch: 5| Step: 2
Training loss: 1.5075425612987505
Validation loss: 2.2391884957720136

Epoch: 5| Step: 3
Training loss: 0.9220304842934259
Validation loss: 2.278296859153031

Epoch: 5| Step: 4
Training loss: 1.074574248704576
Validation loss: 2.2540452499524477

Epoch: 5| Step: 5
Training loss: 1.179907872919437
Validation loss: 2.306080710512257

Epoch: 5| Step: 6
Training loss: 0.8095210190365618
Validation loss: 2.29494872528476

Epoch: 5| Step: 7
Training loss: 1.6522501023901885
Validation loss: 2.3266415904809015

Epoch: 5| Step: 8
Training loss: 0.9961170268611503
Validation loss: 2.305113725580052

Epoch: 5| Step: 9
Training loss: 1.359013388757949
Validation loss: 2.341963658092305

Epoch: 5| Step: 10
Training loss: 1.299149322948625
Validation loss: 2.3116663999285487

Epoch: 409| Step: 0
Training loss: 1.0175452638910358
Validation loss: 2.282515462095561

Epoch: 5| Step: 1
Training loss: 0.9364940014172003
Validation loss: 2.2518010695888715

Epoch: 5| Step: 2
Training loss: 0.7893479463557925
Validation loss: 2.282686640006032

Epoch: 5| Step: 3
Training loss: 1.0410647496983918
Validation loss: 2.298600904029419

Epoch: 5| Step: 4
Training loss: 1.282849035079658
Validation loss: 2.2445513930713843

Epoch: 5| Step: 5
Training loss: 1.2226541537428366
Validation loss: 2.227249972577101

Epoch: 5| Step: 6
Training loss: 1.1998189113990314
Validation loss: 2.2536617708133324

Epoch: 5| Step: 7
Training loss: 1.5222017411356987
Validation loss: 2.246754037929058

Epoch: 5| Step: 8
Training loss: 1.0750424088385497
Validation loss: 2.257037916453932

Epoch: 5| Step: 9
Training loss: 1.3522265792852408
Validation loss: 2.3290798433986546

Epoch: 5| Step: 10
Training loss: 1.2128110113137243
Validation loss: 2.3378484399020385

Epoch: 410| Step: 0
Training loss: 0.9160754869499169
Validation loss: 2.316363092588444

Epoch: 5| Step: 1
Training loss: 1.16151708046633
Validation loss: 2.2942785427028274

Epoch: 5| Step: 2
Training loss: 1.0012881208156499
Validation loss: 2.2898967359088602

Epoch: 5| Step: 3
Training loss: 1.1612759205991605
Validation loss: 2.3072486069169402

Epoch: 5| Step: 4
Training loss: 0.7459270830389922
Validation loss: 2.2300202287407322

Epoch: 5| Step: 5
Training loss: 1.1500500108376477
Validation loss: 2.285749971290473

Epoch: 5| Step: 6
Training loss: 0.7294943935866491
Validation loss: 2.2609105367149986

Epoch: 5| Step: 7
Training loss: 1.0579347706032345
Validation loss: 2.3556169590362366

Epoch: 5| Step: 8
Training loss: 0.8381509443188897
Validation loss: 2.3036762658806573

Epoch: 5| Step: 9
Training loss: 1.597892613169814
Validation loss: 2.259948554595532

Epoch: 5| Step: 10
Training loss: 1.9615937612831076
Validation loss: 2.232903870878252

Epoch: 411| Step: 0
Training loss: 1.2119839976233164
Validation loss: 2.2757382585701027

Epoch: 5| Step: 1
Training loss: 1.249902482997321
Validation loss: 2.2362222875288746

Epoch: 5| Step: 2
Training loss: 0.9609174028481509
Validation loss: 2.3173953066287774

Epoch: 5| Step: 3
Training loss: 0.9008030143550151
Validation loss: 2.235424657726196

Epoch: 5| Step: 4
Training loss: 1.1153264049498008
Validation loss: 2.260022735029422

Epoch: 5| Step: 5
Training loss: 1.1003907918337479
Validation loss: 2.2918340478292714

Epoch: 5| Step: 6
Training loss: 1.2197809993669462
Validation loss: 2.219475026431446

Epoch: 5| Step: 7
Training loss: 0.7624928771139676
Validation loss: 2.2636744208905824

Epoch: 5| Step: 8
Training loss: 1.1676069739138366
Validation loss: 2.322061478855771

Epoch: 5| Step: 9
Training loss: 1.3140146961203205
Validation loss: 2.3650887181297118

Epoch: 5| Step: 10
Training loss: 1.762239840089255
Validation loss: 2.279859477823693

Epoch: 412| Step: 0
Training loss: 0.7264374656148832
Validation loss: 2.250826227034346

Epoch: 5| Step: 1
Training loss: 0.937734288504286
Validation loss: 2.2563024808658816

Epoch: 5| Step: 2
Training loss: 1.2204304382929467
Validation loss: 2.329111647085847

Epoch: 5| Step: 3
Training loss: 1.0390403573107656
Validation loss: 2.233442214358938

Epoch: 5| Step: 4
Training loss: 1.7729417553331963
Validation loss: 2.2858052956857313

Epoch: 5| Step: 5
Training loss: 0.9652237857992666
Validation loss: 2.2928007940294846

Epoch: 5| Step: 6
Training loss: 0.8858757212794572
Validation loss: 2.295538081182256

Epoch: 5| Step: 7
Training loss: 1.1465753522450475
Validation loss: 2.2575479522708126

Epoch: 5| Step: 8
Training loss: 1.309808150504699
Validation loss: 2.251670141202459

Epoch: 5| Step: 9
Training loss: 1.0948515658169717
Validation loss: 2.310062146685499

Epoch: 5| Step: 10
Training loss: 1.3641683758068777
Validation loss: 2.264598632341809

Epoch: 413| Step: 0
Training loss: 1.059344148889941
Validation loss: 2.2569934125520232

Epoch: 5| Step: 1
Training loss: 2.051237625930908
Validation loss: 2.2560990628345454

Epoch: 5| Step: 2
Training loss: 0.9161893765220627
Validation loss: 2.2749449624660443

Epoch: 5| Step: 3
Training loss: 1.2188941674672151
Validation loss: 2.316644855743922

Epoch: 5| Step: 4
Training loss: 0.8409064732799044
Validation loss: 2.3093398634219016

Epoch: 5| Step: 5
Training loss: 1.2325970363526226
Validation loss: 2.268207066246043

Epoch: 5| Step: 6
Training loss: 1.0073739213834754
Validation loss: 2.201288713421991

Epoch: 5| Step: 7
Training loss: 0.8493357952352721
Validation loss: 2.366960184624871

Epoch: 5| Step: 8
Training loss: 0.9448371196329349
Validation loss: 2.306968446512095

Epoch: 5| Step: 9
Training loss: 0.9883108323083822
Validation loss: 2.310121227933617

Epoch: 5| Step: 10
Training loss: 1.0236270525165587
Validation loss: 2.283583327259896

Epoch: 414| Step: 0
Training loss: 1.350593219331983
Validation loss: 2.3036980052562184

Epoch: 5| Step: 1
Training loss: 0.765937896940081
Validation loss: 2.279270774449414

Epoch: 5| Step: 2
Training loss: 1.3862382083043894
Validation loss: 2.3358857972267337

Epoch: 5| Step: 3
Training loss: 1.1694326763109657
Validation loss: 2.3459085763835783

Epoch: 5| Step: 4
Training loss: 1.0597956404634283
Validation loss: 2.2856404569362643

Epoch: 5| Step: 5
Training loss: 1.7932346786723061
Validation loss: 2.26397357933838

Epoch: 5| Step: 6
Training loss: 1.095189101468956
Validation loss: 2.3273623672927783

Epoch: 5| Step: 7
Training loss: 0.8549402076047506
Validation loss: 2.338045468598293

Epoch: 5| Step: 8
Training loss: 0.9542121003229845
Validation loss: 2.281421357137434

Epoch: 5| Step: 9
Training loss: 1.0000842178167473
Validation loss: 2.2891424766310147

Epoch: 5| Step: 10
Training loss: 1.122979256626042
Validation loss: 2.278985399015977

Epoch: 415| Step: 0
Training loss: 1.7895415218680986
Validation loss: 2.246531308049483

Epoch: 5| Step: 1
Training loss: 0.9060435224315111
Validation loss: 2.2734128742570836

Epoch: 5| Step: 2
Training loss: 1.1960016395787256
Validation loss: 2.290021298607651

Epoch: 5| Step: 3
Training loss: 0.7769593098098441
Validation loss: 2.305558164393038

Epoch: 5| Step: 4
Training loss: 1.246615405295267
Validation loss: 2.308692945128061

Epoch: 5| Step: 5
Training loss: 0.978785159818051
Validation loss: 2.2594586234200076

Epoch: 5| Step: 6
Training loss: 0.8839906578498107
Validation loss: 2.2389794919037107

Epoch: 5| Step: 7
Training loss: 1.0282003218588913
Validation loss: 2.348735021001508

Epoch: 5| Step: 8
Training loss: 1.035699550636594
Validation loss: 2.2884529503619824

Epoch: 5| Step: 9
Training loss: 0.991859201498955
Validation loss: 2.3379314276939316

Epoch: 5| Step: 10
Training loss: 1.474938523902604
Validation loss: 2.3205583257861577

Epoch: 416| Step: 0
Training loss: 1.0437292405308296
Validation loss: 2.35101065066033

Epoch: 5| Step: 1
Training loss: 0.8215369033163328
Validation loss: 2.292060048262922

Epoch: 5| Step: 2
Training loss: 0.9710636198689598
Validation loss: 2.308404810125975

Epoch: 5| Step: 3
Training loss: 0.8744147591484793
Validation loss: 2.383573912690397

Epoch: 5| Step: 4
Training loss: 1.081781571980369
Validation loss: 2.297404009770862

Epoch: 5| Step: 5
Training loss: 1.2452647641556374
Validation loss: 2.308944936676673

Epoch: 5| Step: 6
Training loss: 0.7569330756085143
Validation loss: 2.2923147886615136

Epoch: 5| Step: 7
Training loss: 0.978606503467635
Validation loss: 2.2786555025566497

Epoch: 5| Step: 8
Training loss: 1.4034809400231194
Validation loss: 2.304494331820068

Epoch: 5| Step: 9
Training loss: 1.1739001259960742
Validation loss: 2.2482779280881613

Epoch: 5| Step: 10
Training loss: 1.9542443691766438
Validation loss: 2.313396143861872

Epoch: 417| Step: 0
Training loss: 0.7339725609153906
Validation loss: 2.2223009634765734

Epoch: 5| Step: 1
Training loss: 0.7549378842576201
Validation loss: 2.3145080147291885

Epoch: 5| Step: 2
Training loss: 1.1753092480599028
Validation loss: 2.2823466627421922

Epoch: 5| Step: 3
Training loss: 0.8400087771070686
Validation loss: 2.2556800473048204

Epoch: 5| Step: 4
Training loss: 1.008324426553865
Validation loss: 2.31297322015156

Epoch: 5| Step: 5
Training loss: 1.1928121307828201
Validation loss: 2.274830559288582

Epoch: 5| Step: 6
Training loss: 1.1698262935052872
Validation loss: 2.2794834005142204

Epoch: 5| Step: 7
Training loss: 1.6647841630401454
Validation loss: 2.243017523166598

Epoch: 5| Step: 8
Training loss: 1.3000803940930121
Validation loss: 2.2624596537268027

Epoch: 5| Step: 9
Training loss: 1.005106761063348
Validation loss: 2.2272751133217064

Epoch: 5| Step: 10
Training loss: 0.9797803734375844
Validation loss: 2.2678418440825125

Epoch: 418| Step: 0
Training loss: 0.9562426373566064
Validation loss: 2.2370086667594706

Epoch: 5| Step: 1
Training loss: 0.8866667879314866
Validation loss: 2.30471429213101

Epoch: 5| Step: 2
Training loss: 1.0547972445434988
Validation loss: 2.2659992982379817

Epoch: 5| Step: 3
Training loss: 0.9447633393459609
Validation loss: 2.3346884640770287

Epoch: 5| Step: 4
Training loss: 0.8219835608548649
Validation loss: 2.312057931779068

Epoch: 5| Step: 5
Training loss: 1.5003507521936843
Validation loss: 2.3000294878756016

Epoch: 5| Step: 6
Training loss: 1.4428066491001565
Validation loss: 2.354624280049514

Epoch: 5| Step: 7
Training loss: 0.9089917112545391
Validation loss: 2.2333964172561047

Epoch: 5| Step: 8
Training loss: 1.060664667434135
Validation loss: 2.2582192565339634

Epoch: 5| Step: 9
Training loss: 1.2148329068892856
Validation loss: 2.2934737558063403

Epoch: 5| Step: 10
Training loss: 1.6741220222901818
Validation loss: 2.3333659413325507

Epoch: 419| Step: 0
Training loss: 0.8978848291640031
Validation loss: 2.3083500862365116

Epoch: 5| Step: 1
Training loss: 1.3099468466480197
Validation loss: 2.261596358998132

Epoch: 5| Step: 2
Training loss: 1.302903331683879
Validation loss: 2.33512745131655

Epoch: 5| Step: 3
Training loss: 0.9646252836548558
Validation loss: 2.294867865163183

Epoch: 5| Step: 4
Training loss: 0.8546888027146364
Validation loss: 2.338207156726204

Epoch: 5| Step: 5
Training loss: 1.128889829522798
Validation loss: 2.2708029073720457

Epoch: 5| Step: 6
Training loss: 0.9793985613025789
Validation loss: 2.3006343729557264

Epoch: 5| Step: 7
Training loss: 1.0214166855858884
Validation loss: 2.273570058098792

Epoch: 5| Step: 8
Training loss: 0.7526364479049605
Validation loss: 2.3333807807118037

Epoch: 5| Step: 9
Training loss: 0.9716505496769716
Validation loss: 2.3534256148730166

Epoch: 5| Step: 10
Training loss: 1.91728611624855
Validation loss: 2.272339596671016

Epoch: 420| Step: 0
Training loss: 1.499633267394407
Validation loss: 2.275765634837896

Epoch: 5| Step: 1
Training loss: 0.8488998783012175
Validation loss: 2.278728397871736

Epoch: 5| Step: 2
Training loss: 1.0205286635317525
Validation loss: 2.294440223420946

Epoch: 5| Step: 3
Training loss: 1.084359648758019
Validation loss: 2.273090139378173

Epoch: 5| Step: 4
Training loss: 1.2110018313147561
Validation loss: 2.3156264493774787

Epoch: 5| Step: 5
Training loss: 0.848348203283914
Validation loss: 2.3007871599631775

Epoch: 5| Step: 6
Training loss: 0.827465334451408
Validation loss: 2.2971624713918466

Epoch: 5| Step: 7
Training loss: 1.2175808703061466
Validation loss: 2.3535033792674045

Epoch: 5| Step: 8
Training loss: 0.9144149817944839
Validation loss: 2.289526848931071

Epoch: 5| Step: 9
Training loss: 1.0934325166137902
Validation loss: 2.2968284507902617

Epoch: 5| Step: 10
Training loss: 1.6832355728970223
Validation loss: 2.2179782165816095

Epoch: 421| Step: 0
Training loss: 1.31361863739915
Validation loss: 2.227550364734567

Epoch: 5| Step: 1
Training loss: 1.030649761876402
Validation loss: 2.222223138125378

Epoch: 5| Step: 2
Training loss: 1.278885916593117
Validation loss: 2.297801625750422

Epoch: 5| Step: 3
Training loss: 0.9413211514960801
Validation loss: 2.270198525189875

Epoch: 5| Step: 4
Training loss: 0.900075364931012
Validation loss: 2.2267103622841202

Epoch: 5| Step: 5
Training loss: 1.5999087844120117
Validation loss: 2.298379716733588

Epoch: 5| Step: 6
Training loss: 0.852774256613714
Validation loss: 2.2220401013341395

Epoch: 5| Step: 7
Training loss: 1.13551592028471
Validation loss: 2.2695322847045394

Epoch: 5| Step: 8
Training loss: 1.073477471952538
Validation loss: 2.2898510099080904

Epoch: 5| Step: 9
Training loss: 1.0681063894723068
Validation loss: 2.332643514249869

Epoch: 5| Step: 10
Training loss: 1.3065796796558375
Validation loss: 2.2561320486999272

Epoch: 422| Step: 0
Training loss: 1.130305917397448
Validation loss: 2.2776180185129524

Epoch: 5| Step: 1
Training loss: 1.1134145021164645
Validation loss: 2.2826552412696697

Epoch: 5| Step: 2
Training loss: 1.4112454168145605
Validation loss: 2.2473795944203436

Epoch: 5| Step: 3
Training loss: 0.8923158489842314
Validation loss: 2.249008218769346

Epoch: 5| Step: 4
Training loss: 1.096795012337093
Validation loss: 2.2885971775129983

Epoch: 5| Step: 5
Training loss: 1.0732167512553887
Validation loss: 2.2276230731974382

Epoch: 5| Step: 6
Training loss: 0.865629256750995
Validation loss: 2.267700130979844

Epoch: 5| Step: 7
Training loss: 1.0251747703420078
Validation loss: 2.3488313213898215

Epoch: 5| Step: 8
Training loss: 1.1178377833185158
Validation loss: 2.282063615413865

Epoch: 5| Step: 9
Training loss: 0.8246142627132095
Validation loss: 2.320994561703785

Epoch: 5| Step: 10
Training loss: 1.6988144667675689
Validation loss: 2.287208216268534

Epoch: 423| Step: 0
Training loss: 0.8971405619716877
Validation loss: 2.322199978312777

Epoch: 5| Step: 1
Training loss: 0.881628339459601
Validation loss: 2.270599827008431

Epoch: 5| Step: 2
Training loss: 0.9062569387762213
Validation loss: 2.3552825603275758

Epoch: 5| Step: 3
Training loss: 1.078571835123525
Validation loss: 2.330041229324789

Epoch: 5| Step: 4
Training loss: 0.7566704156827548
Validation loss: 2.2861013169952424

Epoch: 5| Step: 5
Training loss: 1.7540739867070274
Validation loss: 2.313571916521608

Epoch: 5| Step: 6
Training loss: 1.1428244300826678
Validation loss: 2.294145546301938

Epoch: 5| Step: 7
Training loss: 1.207711086975261
Validation loss: 2.3404214566867036

Epoch: 5| Step: 8
Training loss: 1.030532182500977
Validation loss: 2.2763626556739207

Epoch: 5| Step: 9
Training loss: 1.1416210371955502
Validation loss: 2.2925131771595373

Epoch: 5| Step: 10
Training loss: 1.1974027720025342
Validation loss: 2.2572033902136064

Epoch: 424| Step: 0
Training loss: 1.8619857538991507
Validation loss: 2.285994538442785

Epoch: 5| Step: 1
Training loss: 1.2053108670671404
Validation loss: 2.3113994207705204

Epoch: 5| Step: 2
Training loss: 1.1966526273118154
Validation loss: 2.2277687948617606

Epoch: 5| Step: 3
Training loss: 0.7901432831514759
Validation loss: 2.1897929510400727

Epoch: 5| Step: 4
Training loss: 1.17666673743128
Validation loss: 2.2013548278640678

Epoch: 5| Step: 5
Training loss: 0.8276673257845363
Validation loss: 2.265681921300812

Epoch: 5| Step: 6
Training loss: 0.9144361987333808
Validation loss: 2.2811607829994047

Epoch: 5| Step: 7
Training loss: 1.0736259350583286
Validation loss: 2.3029005372415257

Epoch: 5| Step: 8
Training loss: 1.139880472994396
Validation loss: 2.271606157635881

Epoch: 5| Step: 9
Training loss: 0.982507478234172
Validation loss: 2.271644647928958

Epoch: 5| Step: 10
Training loss: 0.8753017518303929
Validation loss: 2.3030457163574645

Epoch: 425| Step: 0
Training loss: 1.2032176886190418
Validation loss: 2.3318916809868164

Epoch: 5| Step: 1
Training loss: 0.9903991080656026
Validation loss: 2.25654392120397

Epoch: 5| Step: 2
Training loss: 1.7828730500191934
Validation loss: 2.273300485330644

Epoch: 5| Step: 3
Training loss: 1.1333209771062422
Validation loss: 2.3532284391512834

Epoch: 5| Step: 4
Training loss: 0.714793719432629
Validation loss: 2.3697572092830157

Epoch: 5| Step: 5
Training loss: 1.041061314480181
Validation loss: 2.304519385228149

Epoch: 5| Step: 6
Training loss: 1.0233194414142295
Validation loss: 2.277867254373441

Epoch: 5| Step: 7
Training loss: 0.8344083329304005
Validation loss: 2.2973088193878017

Epoch: 5| Step: 8
Training loss: 1.1723605358086866
Validation loss: 2.318830973742023

Epoch: 5| Step: 9
Training loss: 1.1524285236792937
Validation loss: 2.28373927226596

Epoch: 5| Step: 10
Training loss: 0.8627128628652783
Validation loss: 2.262792880085008

Epoch: 426| Step: 0
Training loss: 1.1815524990543356
Validation loss: 2.2368980394054385

Epoch: 5| Step: 1
Training loss: 1.2920552048773155
Validation loss: 2.2866796623313212

Epoch: 5| Step: 2
Training loss: 1.2328003122479083
Validation loss: 2.266278230939592

Epoch: 5| Step: 3
Training loss: 1.1626463603104198
Validation loss: 2.315738935112801

Epoch: 5| Step: 4
Training loss: 0.8895748371787614
Validation loss: 2.301479520071058

Epoch: 5| Step: 5
Training loss: 0.8755223554287459
Validation loss: 2.2533596858534377

Epoch: 5| Step: 6
Training loss: 0.9634493740660401
Validation loss: 2.3609652648106723

Epoch: 5| Step: 7
Training loss: 0.8358808123895758
Validation loss: 2.330695668402179

Epoch: 5| Step: 8
Training loss: 0.76669757994925
Validation loss: 2.2649444689552607

Epoch: 5| Step: 9
Training loss: 1.6106392052364118
Validation loss: 2.3193956170254073

Epoch: 5| Step: 10
Training loss: 0.9514822013060258
Validation loss: 2.320351847355085

Epoch: 427| Step: 0
Training loss: 1.6733572975408313
Validation loss: 2.2713182057187526

Epoch: 5| Step: 1
Training loss: 1.0353409512401899
Validation loss: 2.2717837581651374

Epoch: 5| Step: 2
Training loss: 0.8927003872731786
Validation loss: 2.240877635340946

Epoch: 5| Step: 3
Training loss: 1.049601860857105
Validation loss: 2.233715083549234

Epoch: 5| Step: 4
Training loss: 0.9868591389942752
Validation loss: 2.2573868295299784

Epoch: 5| Step: 5
Training loss: 0.8390974410469825
Validation loss: 2.2926051616780647

Epoch: 5| Step: 6
Training loss: 0.8773966392004038
Validation loss: 2.2679247552208768

Epoch: 5| Step: 7
Training loss: 1.2008337521910792
Validation loss: 2.298701677416769

Epoch: 5| Step: 8
Training loss: 0.975526214085105
Validation loss: 2.2560872604613484

Epoch: 5| Step: 9
Training loss: 1.3394703692341061
Validation loss: 2.261796464859512

Epoch: 5| Step: 10
Training loss: 1.2074566434101608
Validation loss: 2.236636848095365

Epoch: 428| Step: 0
Training loss: 0.9480854694572294
Validation loss: 2.2497578163564222

Epoch: 5| Step: 1
Training loss: 1.2516294349554502
Validation loss: 2.3121089837528035

Epoch: 5| Step: 2
Training loss: 1.084941214889512
Validation loss: 2.2752391804396503

Epoch: 5| Step: 3
Training loss: 0.867585855352527
Validation loss: 2.2772794279725095

Epoch: 5| Step: 4
Training loss: 1.0736111673966744
Validation loss: 2.3748781213969474

Epoch: 5| Step: 5
Training loss: 0.7788343467161591
Validation loss: 2.297091413254007

Epoch: 5| Step: 6
Training loss: 0.9355715308394766
Validation loss: 2.2927568831160015

Epoch: 5| Step: 7
Training loss: 1.8436360081493972
Validation loss: 2.2731539754519012

Epoch: 5| Step: 8
Training loss: 1.2853727767021421
Validation loss: 2.2788889364247273

Epoch: 5| Step: 9
Training loss: 1.0327095338220462
Validation loss: 2.2915351725540525

Epoch: 5| Step: 10
Training loss: 0.8662891718166909
Validation loss: 2.274148962566657

Epoch: 429| Step: 0
Training loss: 1.1939287840692754
Validation loss: 2.354445381519507

Epoch: 5| Step: 1
Training loss: 1.0612445594818882
Validation loss: 2.3047501472258185

Epoch: 5| Step: 2
Training loss: 1.0705050552797575
Validation loss: 2.2172222339937373

Epoch: 5| Step: 3
Training loss: 0.9033409982323242
Validation loss: 2.284499949013767

Epoch: 5| Step: 4
Training loss: 0.7048180435962585
Validation loss: 2.2553965013003103

Epoch: 5| Step: 5
Training loss: 1.0330981253505318
Validation loss: 2.2483115372527576

Epoch: 5| Step: 6
Training loss: 0.9906365294642954
Validation loss: 2.278177304431753

Epoch: 5| Step: 7
Training loss: 1.0268013686414335
Validation loss: 2.249088350482145

Epoch: 5| Step: 8
Training loss: 0.6999494687642779
Validation loss: 2.3222304708860935

Epoch: 5| Step: 9
Training loss: 1.7597235569810443
Validation loss: 2.216899065693754

Epoch: 5| Step: 10
Training loss: 1.2180459360815523
Validation loss: 2.3420139361201824

Epoch: 430| Step: 0
Training loss: 0.9182825079859473
Validation loss: 2.18621810761774

Epoch: 5| Step: 1
Training loss: 0.9673300765889942
Validation loss: 2.348684227571899

Epoch: 5| Step: 2
Training loss: 0.9717830737143117
Validation loss: 2.281547143822913

Epoch: 5| Step: 3
Training loss: 0.7365649421790594
Validation loss: 2.2893247083558244

Epoch: 5| Step: 4
Training loss: 1.0807478140941913
Validation loss: 2.224990294830404

Epoch: 5| Step: 5
Training loss: 1.052721805532858
Validation loss: 2.2897232637993787

Epoch: 5| Step: 6
Training loss: 1.0035182930571955
Validation loss: 2.2884179708319055

Epoch: 5| Step: 7
Training loss: 1.6750498066799084
Validation loss: 2.3137703631975364

Epoch: 5| Step: 8
Training loss: 1.274301715444287
Validation loss: 2.265072271344944

Epoch: 5| Step: 9
Training loss: 1.137117925341168
Validation loss: 2.3389274307676535

Epoch: 5| Step: 10
Training loss: 0.9567266485525838
Validation loss: 2.3020820363396095

Epoch: 431| Step: 0
Training loss: 0.8852536369277031
Validation loss: 2.39465180234612

Epoch: 5| Step: 1
Training loss: 1.9207836246747325
Validation loss: 2.3042419492354194

Epoch: 5| Step: 2
Training loss: 0.9740766701571711
Validation loss: 2.3104124593813404

Epoch: 5| Step: 3
Training loss: 0.9135186949697665
Validation loss: 2.322209722489336

Epoch: 5| Step: 4
Training loss: 0.8635544150546131
Validation loss: 2.3642804055356565

Epoch: 5| Step: 5
Training loss: 0.7773961188537191
Validation loss: 2.2373718225004846

Epoch: 5| Step: 6
Training loss: 1.398865703471086
Validation loss: 2.318228024414557

Epoch: 5| Step: 7
Training loss: 0.9459430703741721
Validation loss: 2.289953629319372

Epoch: 5| Step: 8
Training loss: 1.0777091730924342
Validation loss: 2.2380989308412023

Epoch: 5| Step: 9
Training loss: 1.121046696649078
Validation loss: 2.235705265297528

Epoch: 5| Step: 10
Training loss: 0.8427739679328248
Validation loss: 2.2596685007721886

Epoch: 432| Step: 0
Training loss: 1.102499921457024
Validation loss: 2.29999848194527

Epoch: 5| Step: 1
Training loss: 1.0480217417725777
Validation loss: 2.268557614396583

Epoch: 5| Step: 2
Training loss: 0.8953373371294172
Validation loss: 2.261077689694424

Epoch: 5| Step: 3
Training loss: 0.9249485955260106
Validation loss: 2.2305594055304723

Epoch: 5| Step: 4
Training loss: 0.9937141867848094
Validation loss: 2.281827126823242

Epoch: 5| Step: 5
Training loss: 0.8873937449180859
Validation loss: 2.312368989540891

Epoch: 5| Step: 6
Training loss: 0.809062545440425
Validation loss: 2.352605380566824

Epoch: 5| Step: 7
Training loss: 0.8926731117508254
Validation loss: 2.290977802014577

Epoch: 5| Step: 8
Training loss: 1.2274598162069632
Validation loss: 2.3151136791899813

Epoch: 5| Step: 9
Training loss: 1.590483365751103
Validation loss: 2.327095533649234

Epoch: 5| Step: 10
Training loss: 1.2162681643314615
Validation loss: 2.229870595835498

Epoch: 433| Step: 0
Training loss: 1.719243065595267
Validation loss: 2.322423301942233

Epoch: 5| Step: 1
Training loss: 0.95209666575996
Validation loss: 2.308757008800642

Epoch: 5| Step: 2
Training loss: 0.9405013678022109
Validation loss: 2.2631952843547376

Epoch: 5| Step: 3
Training loss: 1.127339632340047
Validation loss: 2.2298507706421797

Epoch: 5| Step: 4
Training loss: 0.9134535105734741
Validation loss: 2.278393621359616

Epoch: 5| Step: 5
Training loss: 0.9396440466629737
Validation loss: 2.29715180795666

Epoch: 5| Step: 6
Training loss: 1.04939910860978
Validation loss: 2.251013000220412

Epoch: 5| Step: 7
Training loss: 1.2391501666272213
Validation loss: 2.2812172138208493

Epoch: 5| Step: 8
Training loss: 0.9346082593972891
Validation loss: 2.3093332093627263

Epoch: 5| Step: 9
Training loss: 0.9430635671660758
Validation loss: 2.2163429103699657

Epoch: 5| Step: 10
Training loss: 1.094395801078538
Validation loss: 2.283051393556198

Epoch: 434| Step: 0
Training loss: 0.7353990192475262
Validation loss: 2.2442528841093585

Epoch: 5| Step: 1
Training loss: 1.2273675985465704
Validation loss: 2.330479264773011

Epoch: 5| Step: 2
Training loss: 1.006278652470349
Validation loss: 2.3315857159892657

Epoch: 5| Step: 3
Training loss: 1.1213694376362648
Validation loss: 2.365682641198938

Epoch: 5| Step: 4
Training loss: 0.9525837846886785
Validation loss: 2.3557865420459945

Epoch: 5| Step: 5
Training loss: 1.1014794933888143
Validation loss: 2.299289155963754

Epoch: 5| Step: 6
Training loss: 0.8541231764599887
Validation loss: 2.336727386181191

Epoch: 5| Step: 7
Training loss: 0.913020656924422
Validation loss: 2.290471925788487

Epoch: 5| Step: 8
Training loss: 1.6477060729190673
Validation loss: 2.237215915871646

Epoch: 5| Step: 9
Training loss: 0.8196694169429491
Validation loss: 2.2478533295209013

Epoch: 5| Step: 10
Training loss: 1.0312028931927102
Validation loss: 2.3083590875864206

Epoch: 435| Step: 0
Training loss: 1.1159051324385336
Validation loss: 2.1898888173867026

Epoch: 5| Step: 1
Training loss: 0.9938638298050816
Validation loss: 2.2569428023676004

Epoch: 5| Step: 2
Training loss: 0.9731997155115015
Validation loss: 2.2551157889572355

Epoch: 5| Step: 3
Training loss: 0.8873401430718005
Validation loss: 2.237596814908299

Epoch: 5| Step: 4
Training loss: 1.1541742818055565
Validation loss: 2.2402373549184627

Epoch: 5| Step: 5
Training loss: 1.0554686302789242
Validation loss: 2.2626306760201773

Epoch: 5| Step: 6
Training loss: 1.580273515953295
Validation loss: 2.272407957449615

Epoch: 5| Step: 7
Training loss: 1.0441316557847562
Validation loss: 2.2069450196773572

Epoch: 5| Step: 8
Training loss: 0.9914888640628181
Validation loss: 2.253778546972503

Epoch: 5| Step: 9
Training loss: 0.9483339557969699
Validation loss: 2.2696994589750417

Epoch: 5| Step: 10
Training loss: 0.7154977443774142
Validation loss: 2.313080673459147

Epoch: 436| Step: 0
Training loss: 1.0648965174586251
Validation loss: 2.325717666671009

Epoch: 5| Step: 1
Training loss: 0.7206102016679721
Validation loss: 2.2697107574019535

Epoch: 5| Step: 2
Training loss: 1.086921685013001
Validation loss: 2.2922417505486448

Epoch: 5| Step: 3
Training loss: 0.9811204059331431
Validation loss: 2.2936777532728976

Epoch: 5| Step: 4
Training loss: 1.0705690842082543
Validation loss: 2.243540500806799

Epoch: 5| Step: 5
Training loss: 1.2471698192546565
Validation loss: 2.29763850121605

Epoch: 5| Step: 6
Training loss: 0.7132175897641396
Validation loss: 2.2380006303535707

Epoch: 5| Step: 7
Training loss: 1.829859570915383
Validation loss: 2.339766489241018

Epoch: 5| Step: 8
Training loss: 0.8875760878600072
Validation loss: 2.2738233708973903

Epoch: 5| Step: 9
Training loss: 0.8620793878813172
Validation loss: 2.3450409673384165

Epoch: 5| Step: 10
Training loss: 0.7565134850514746
Validation loss: 2.250957505180142

Epoch: 437| Step: 0
Training loss: 0.9115669222133685
Validation loss: 2.3146196377369606

Epoch: 5| Step: 1
Training loss: 1.1906610378308184
Validation loss: 2.300494608590469

Epoch: 5| Step: 2
Training loss: 0.9991078271209699
Validation loss: 2.3238486369194176

Epoch: 5| Step: 3
Training loss: 1.1394194411306742
Validation loss: 2.2569845544886293

Epoch: 5| Step: 4
Training loss: 0.9671683474417695
Validation loss: 2.3499717391720685

Epoch: 5| Step: 5
Training loss: 1.6121907462530845
Validation loss: 2.215984388103276

Epoch: 5| Step: 6
Training loss: 1.0321498181876279
Validation loss: 2.2821274083007146

Epoch: 5| Step: 7
Training loss: 0.8471909753495277
Validation loss: 2.2940524574203227

Epoch: 5| Step: 8
Training loss: 0.623218381230392
Validation loss: 2.279921981928165

Epoch: 5| Step: 9
Training loss: 1.0110276855617208
Validation loss: 2.278698942113427

Epoch: 5| Step: 10
Training loss: 0.967290609653434
Validation loss: 2.274508482051132

Epoch: 438| Step: 0
Training loss: 0.9620478348249603
Validation loss: 2.283993260415417

Epoch: 5| Step: 1
Training loss: 1.2301282138989862
Validation loss: 2.2734436389155306

Epoch: 5| Step: 2
Training loss: 0.9257753911215254
Validation loss: 2.2486243001719672

Epoch: 5| Step: 3
Training loss: 0.8047628645187151
Validation loss: 2.215404360767391

Epoch: 5| Step: 4
Training loss: 0.8550278036716553
Validation loss: 2.2771290400849518

Epoch: 5| Step: 5
Training loss: 1.6338904076317362
Validation loss: 2.322182441672676

Epoch: 5| Step: 6
Training loss: 0.7415594555663299
Validation loss: 2.3284402807104616

Epoch: 5| Step: 7
Training loss: 1.1285817032875747
Validation loss: 2.4370971738079135

Epoch: 5| Step: 8
Training loss: 1.0743477483802757
Validation loss: 2.3130011598882865

Epoch: 5| Step: 9
Training loss: 0.9288052130982465
Validation loss: 2.2914744754271763

Epoch: 5| Step: 10
Training loss: 0.815852255603412
Validation loss: 2.365323504386324

Epoch: 439| Step: 0
Training loss: 0.8593533946702631
Validation loss: 2.316183757432531

Epoch: 5| Step: 1
Training loss: 1.8454291246271737
Validation loss: 2.276780348184582

Epoch: 5| Step: 2
Training loss: 0.987297533501761
Validation loss: 2.25944519110947

Epoch: 5| Step: 3
Training loss: 0.7850237682413166
Validation loss: 2.2933438634284893

Epoch: 5| Step: 4
Training loss: 1.0591066251214556
Validation loss: 2.1992442228415414

Epoch: 5| Step: 5
Training loss: 0.8780519190342242
Validation loss: 2.334020951322088

Epoch: 5| Step: 6
Training loss: 0.9793175554012954
Validation loss: 2.3233038119224285

Epoch: 5| Step: 7
Training loss: 0.9628816491998929
Validation loss: 2.29789441883277

Epoch: 5| Step: 8
Training loss: 1.0510094263722973
Validation loss: 2.2549878099542826

Epoch: 5| Step: 9
Training loss: 1.0520530860002428
Validation loss: 2.292255217150154

Epoch: 5| Step: 10
Training loss: 0.9101653528372249
Validation loss: 2.2852229226855045

Epoch: 440| Step: 0
Training loss: 0.6281135254376453
Validation loss: 2.273395395433481

Epoch: 5| Step: 1
Training loss: 0.9747030637427393
Validation loss: 2.285244630069147

Epoch: 5| Step: 2
Training loss: 1.294698060084945
Validation loss: 2.3705796868104363

Epoch: 5| Step: 3
Training loss: 1.7358443076375445
Validation loss: 2.2643003309006646

Epoch: 5| Step: 4
Training loss: 0.8333561337848651
Validation loss: 2.315750465571679

Epoch: 5| Step: 5
Training loss: 1.3011754901965173
Validation loss: 2.308177259064444

Epoch: 5| Step: 6
Training loss: 0.6208718101261312
Validation loss: 2.3831197007046927

Epoch: 5| Step: 7
Training loss: 0.671869921110607
Validation loss: 2.304656680766434

Epoch: 5| Step: 8
Training loss: 0.8375296359725755
Validation loss: 2.3064213997164047

Epoch: 5| Step: 9
Training loss: 0.9201786792396871
Validation loss: 2.2477877210839563

Epoch: 5| Step: 10
Training loss: 1.0355751197787797
Validation loss: 2.248192827094656

Epoch: 441| Step: 0
Training loss: 1.0920986788846931
Validation loss: 2.236429265621633

Epoch: 5| Step: 1
Training loss: 1.112700782830731
Validation loss: 2.269353073847031

Epoch: 5| Step: 2
Training loss: 0.7798095393563762
Validation loss: 2.258396888734344

Epoch: 5| Step: 3
Training loss: 0.9251984318975971
Validation loss: 2.2276616858901184

Epoch: 5| Step: 4
Training loss: 0.9413138696447684
Validation loss: 2.2527469970746914

Epoch: 5| Step: 5
Training loss: 1.0972585262993777
Validation loss: 2.2822266388848615

Epoch: 5| Step: 6
Training loss: 1.7394846661695846
Validation loss: 2.2847248706199053

Epoch: 5| Step: 7
Training loss: 0.7884111643296356
Validation loss: 2.2292602950858136

Epoch: 5| Step: 8
Training loss: 0.8146784994303471
Validation loss: 2.283737569337635

Epoch: 5| Step: 9
Training loss: 0.8571143500378654
Validation loss: 2.287569898782184

Epoch: 5| Step: 10
Training loss: 1.323439647398088
Validation loss: 2.2633585036064323

Epoch: 442| Step: 0
Training loss: 1.5432398304445845
Validation loss: 2.293871647918215

Epoch: 5| Step: 1
Training loss: 1.139363361912318
Validation loss: 2.2722065453832196

Epoch: 5| Step: 2
Training loss: 0.7499625276105312
Validation loss: 2.364510900499238

Epoch: 5| Step: 3
Training loss: 1.0350542702014558
Validation loss: 2.2759495954465905

Epoch: 5| Step: 4
Training loss: 1.0152245539050386
Validation loss: 2.3031321983187625

Epoch: 5| Step: 5
Training loss: 1.1148776203616155
Validation loss: 2.285797448200054

Epoch: 5| Step: 6
Training loss: 0.9598159447700261
Validation loss: 2.2825609975433823

Epoch: 5| Step: 7
Training loss: 0.9442108923600722
Validation loss: 2.255441341333563

Epoch: 5| Step: 8
Training loss: 0.8740817087877069
Validation loss: 2.3200484456650186

Epoch: 5| Step: 9
Training loss: 1.0815068706059652
Validation loss: 2.262893368622919

Epoch: 5| Step: 10
Training loss: 1.0605594079276444
Validation loss: 2.2704013467386095

Epoch: 443| Step: 0
Training loss: 0.8728026660839134
Validation loss: 2.181701362598632

Epoch: 5| Step: 1
Training loss: 0.5869731143435172
Validation loss: 2.301747977844482

Epoch: 5| Step: 2
Training loss: 1.0642206060549904
Validation loss: 2.286527594262639

Epoch: 5| Step: 3
Training loss: 1.0597186991070708
Validation loss: 2.266287035143788

Epoch: 5| Step: 4
Training loss: 1.6169058144386466
Validation loss: 2.2724704950318513

Epoch: 5| Step: 5
Training loss: 1.3269893952343372
Validation loss: 2.3248633996568007

Epoch: 5| Step: 6
Training loss: 0.9727337970996942
Validation loss: 2.3203021473572663

Epoch: 5| Step: 7
Training loss: 1.061179743262076
Validation loss: 2.2654335289013137

Epoch: 5| Step: 8
Training loss: 0.7157905853468792
Validation loss: 2.280930691593764

Epoch: 5| Step: 9
Training loss: 0.9918317382262073
Validation loss: 2.2595941203724847

Epoch: 5| Step: 10
Training loss: 0.8260249735495231
Validation loss: 2.2607324023493356

Epoch: 444| Step: 0
Training loss: 1.1748782013606907
Validation loss: 2.324115210184989

Epoch: 5| Step: 1
Training loss: 1.6121485985212372
Validation loss: 2.3381715537334316

Epoch: 5| Step: 2
Training loss: 0.7848089788147826
Validation loss: 2.29615994450172

Epoch: 5| Step: 3
Training loss: 1.0448720759708998
Validation loss: 2.216767035196701

Epoch: 5| Step: 4
Training loss: 1.2663335818151311
Validation loss: 2.275580557555298

Epoch: 5| Step: 5
Training loss: 1.1659542815207977
Validation loss: 2.2823645273652926

Epoch: 5| Step: 6
Training loss: 0.7087801384278638
Validation loss: 2.27910902490299

Epoch: 5| Step: 7
Training loss: 0.6800763344344002
Validation loss: 2.3051612296214246

Epoch: 5| Step: 8
Training loss: 0.8357183579169841
Validation loss: 2.3165142124987907

Epoch: 5| Step: 9
Training loss: 1.1738432567465307
Validation loss: 2.287532574131263

Epoch: 5| Step: 10
Training loss: 1.0102485372659713
Validation loss: 2.3197448915685737

Epoch: 445| Step: 0
Training loss: 1.6705067106841187
Validation loss: 2.2716350699943275

Epoch: 5| Step: 1
Training loss: 1.1408331694137273
Validation loss: 2.3001907643590465

Epoch: 5| Step: 2
Training loss: 0.9787542238789858
Validation loss: 2.327099382804906

Epoch: 5| Step: 3
Training loss: 1.1338396348607578
Validation loss: 2.3188596831256145

Epoch: 5| Step: 4
Training loss: 0.8766177753285131
Validation loss: 2.322019405851548

Epoch: 5| Step: 5
Training loss: 0.8781524138057492
Validation loss: 2.3034502799598173

Epoch: 5| Step: 6
Training loss: 0.7540155440253645
Validation loss: 2.2740989246972583

Epoch: 5| Step: 7
Training loss: 0.975903891681894
Validation loss: 2.3248899129667744

Epoch: 5| Step: 8
Training loss: 0.883222940282556
Validation loss: 2.305760963743062

Epoch: 5| Step: 9
Training loss: 0.8139536398589668
Validation loss: 2.3476048260645848

Epoch: 5| Step: 10
Training loss: 1.188622295688269
Validation loss: 2.31879612245188

Epoch: 446| Step: 0
Training loss: 1.1878827632605011
Validation loss: 2.335379609321874

Epoch: 5| Step: 1
Training loss: 0.829935290445345
Validation loss: 2.2781509417967882

Epoch: 5| Step: 2
Training loss: 0.8304716007905047
Validation loss: 2.309174044636403

Epoch: 5| Step: 3
Training loss: 0.864045163303169
Validation loss: 2.2863158043935607

Epoch: 5| Step: 4
Training loss: 0.8491690360558135
Validation loss: 2.240725836310714

Epoch: 5| Step: 5
Training loss: 1.7663624666533437
Validation loss: 2.2693803554322187

Epoch: 5| Step: 6
Training loss: 0.910100910649139
Validation loss: 2.293030011300883

Epoch: 5| Step: 7
Training loss: 1.28026515047256
Validation loss: 2.330070056940339

Epoch: 5| Step: 8
Training loss: 0.7819465583726019
Validation loss: 2.31242146922663

Epoch: 5| Step: 9
Training loss: 0.826613143782802
Validation loss: 2.2880321018751255

Epoch: 5| Step: 10
Training loss: 0.9670387350863037
Validation loss: 2.322236826353015

Epoch: 447| Step: 0
Training loss: 1.010846089353109
Validation loss: 2.2989016608687955

Epoch: 5| Step: 1
Training loss: 0.7132900425514217
Validation loss: 2.283557432312483

Epoch: 5| Step: 2
Training loss: 1.7324151315310554
Validation loss: 2.22154791688996

Epoch: 5| Step: 3
Training loss: 0.8151622950552949
Validation loss: 2.327594763594267

Epoch: 5| Step: 4
Training loss: 0.8562165218964589
Validation loss: 2.35583091262678

Epoch: 5| Step: 5
Training loss: 0.7326268430646627
Validation loss: 2.3356627806459973

Epoch: 5| Step: 6
Training loss: 1.01171886782848
Validation loss: 2.2810452085985475

Epoch: 5| Step: 7
Training loss: 0.8322590977133404
Validation loss: 2.279382042902078

Epoch: 5| Step: 8
Training loss: 0.9138616357493259
Validation loss: 2.2494768573655386

Epoch: 5| Step: 9
Training loss: 1.1938603375157264
Validation loss: 2.3124326714423167

Epoch: 5| Step: 10
Training loss: 0.9734721304671409
Validation loss: 2.357517803690686

Epoch: 448| Step: 0
Training loss: 1.508154479464701
Validation loss: 2.260543980327403

Epoch: 5| Step: 1
Training loss: 1.0700213739452908
Validation loss: 2.266787701437455

Epoch: 5| Step: 2
Training loss: 1.167482919343413
Validation loss: 2.2978987112833074

Epoch: 5| Step: 3
Training loss: 0.9728593729100437
Validation loss: 2.2255837281648776

Epoch: 5| Step: 4
Training loss: 0.8079371712141651
Validation loss: 2.3187730298530655

Epoch: 5| Step: 5
Training loss: 0.8931741206313721
Validation loss: 2.2364910686301167

Epoch: 5| Step: 6
Training loss: 0.866851844780882
Validation loss: 2.363470279486859

Epoch: 5| Step: 7
Training loss: 0.8362866679593007
Validation loss: 2.3129736579594633

Epoch: 5| Step: 8
Training loss: 0.9987897105432885
Validation loss: 2.202955104584294

Epoch: 5| Step: 9
Training loss: 1.0067386672710907
Validation loss: 2.2580386255540854

Epoch: 5| Step: 10
Training loss: 0.8156958962098169
Validation loss: 2.2890177445917144

Epoch: 449| Step: 0
Training loss: 0.5984541360320635
Validation loss: 2.317773947225412

Epoch: 5| Step: 1
Training loss: 1.3834027253789611
Validation loss: 2.3009146606022886

Epoch: 5| Step: 2
Training loss: 0.9951822036902175
Validation loss: 2.2788242023931655

Epoch: 5| Step: 3
Training loss: 1.5300757907969416
Validation loss: 2.2922268970448267

Epoch: 5| Step: 4
Training loss: 0.7751943882835532
Validation loss: 2.3616285280343394

Epoch: 5| Step: 5
Training loss: 1.0845350911366862
Validation loss: 2.261946424258928

Epoch: 5| Step: 6
Training loss: 0.7147432683979289
Validation loss: 2.213171972761082

Epoch: 5| Step: 7
Training loss: 0.8191024574916348
Validation loss: 2.316735748234255

Epoch: 5| Step: 8
Training loss: 0.7671946569913032
Validation loss: 2.2480902922025345

Epoch: 5| Step: 9
Training loss: 0.9900538714519138
Validation loss: 2.247728271977473

Epoch: 5| Step: 10
Training loss: 1.0713596651081134
Validation loss: 2.2236048658717786

Epoch: 450| Step: 0
Training loss: 1.0250660409819108
Validation loss: 2.249937993224087

Epoch: 5| Step: 1
Training loss: 1.0711426126254298
Validation loss: 2.297606251832494

Epoch: 5| Step: 2
Training loss: 0.9300899756396364
Validation loss: 2.267856704690832

Epoch: 5| Step: 3
Training loss: 0.6965065893202463
Validation loss: 2.3141916490342993

Epoch: 5| Step: 4
Training loss: 1.1581086350183865
Validation loss: 2.2787621789343913

Epoch: 5| Step: 5
Training loss: 0.8340119261289148
Validation loss: 2.3252303038188864

Epoch: 5| Step: 6
Training loss: 0.6569368310459851
Validation loss: 2.340528150413704

Epoch: 5| Step: 7
Training loss: 1.6145314690248176
Validation loss: 2.31230026686274

Epoch: 5| Step: 8
Training loss: 0.8823614740660344
Validation loss: 2.320178104299661

Epoch: 5| Step: 9
Training loss: 1.1122622460899896
Validation loss: 2.289653944277613

Epoch: 5| Step: 10
Training loss: 0.8224012032048259
Validation loss: 2.250153245800275

Epoch: 451| Step: 0
Training loss: 1.1423242009676027
Validation loss: 2.275818290026157

Epoch: 5| Step: 1
Training loss: 1.0586873255963236
Validation loss: 2.2980507085096127

Epoch: 5| Step: 2
Training loss: 1.0650960398070948
Validation loss: 2.2973068631580125

Epoch: 5| Step: 3
Training loss: 0.8025433018252824
Validation loss: 2.2179837692575126

Epoch: 5| Step: 4
Training loss: 1.0358041714905604
Validation loss: 2.2550897785695216

Epoch: 5| Step: 5
Training loss: 0.8499065011155214
Validation loss: 2.302110858827476

Epoch: 5| Step: 6
Training loss: 1.0431381830898918
Validation loss: 2.303787145122815

Epoch: 5| Step: 7
Training loss: 1.0733790774598357
Validation loss: 2.2668799647720896

Epoch: 5| Step: 8
Training loss: 1.587490129815604
Validation loss: 2.3081306479002506

Epoch: 5| Step: 9
Training loss: 1.0993345198300053
Validation loss: 2.2632083007789205

Epoch: 5| Step: 10
Training loss: 0.6179002436922466
Validation loss: 2.303488362244066

Epoch: 452| Step: 0
Training loss: 1.6448204529240198
Validation loss: 2.2685999573530586

Epoch: 5| Step: 1
Training loss: 0.859600800413644
Validation loss: 2.3087036846215003

Epoch: 5| Step: 2
Training loss: 0.9093294112586108
Validation loss: 2.337501734709413

Epoch: 5| Step: 3
Training loss: 0.7177647181390038
Validation loss: 2.3001734856747458

Epoch: 5| Step: 4
Training loss: 1.0575582922883398
Validation loss: 2.2714046174742983

Epoch: 5| Step: 5
Training loss: 1.1480314613909255
Validation loss: 2.3253717852310447

Epoch: 5| Step: 6
Training loss: 0.773859005523217
Validation loss: 2.3023751776876233

Epoch: 5| Step: 7
Training loss: 1.0081567102542763
Validation loss: 2.252419728164968

Epoch: 5| Step: 8
Training loss: 1.1869526153625627
Validation loss: 2.274471973262123

Epoch: 5| Step: 9
Training loss: 0.7477433109118173
Validation loss: 2.3395088867350156

Epoch: 5| Step: 10
Training loss: 0.7957799530767736
Validation loss: 2.290273854670237

Epoch: 453| Step: 0
Training loss: 0.9631554662996408
Validation loss: 2.305314934865175

Epoch: 5| Step: 1
Training loss: 0.9018688851490891
Validation loss: 2.3667282795660003

Epoch: 5| Step: 2
Training loss: 0.9129897449435568
Validation loss: 2.366931806305966

Epoch: 5| Step: 3
Training loss: 1.1616354609110469
Validation loss: 2.2272198970044172

Epoch: 5| Step: 4
Training loss: 0.840938581950081
Validation loss: 2.3543569030765705

Epoch: 5| Step: 5
Training loss: 0.8746235582667734
Validation loss: 2.3452703236120405

Epoch: 5| Step: 6
Training loss: 1.6356714216269042
Validation loss: 2.2945106329533136

Epoch: 5| Step: 7
Training loss: 0.9963000513998951
Validation loss: 2.307921112615339

Epoch: 5| Step: 8
Training loss: 0.8690656651093239
Validation loss: 2.361830180065314

Epoch: 5| Step: 9
Training loss: 0.9900678385505199
Validation loss: 2.3045511229363056

Epoch: 5| Step: 10
Training loss: 1.137051615530676
Validation loss: 2.312554325817027

Epoch: 454| Step: 0
Training loss: 1.5223162314969907
Validation loss: 2.222686877518049

Epoch: 5| Step: 1
Training loss: 0.6222792054614337
Validation loss: 2.2643667436413506

Epoch: 5| Step: 2
Training loss: 0.9842076840575729
Validation loss: 2.2799392724112972

Epoch: 5| Step: 3
Training loss: 0.9766689395118627
Validation loss: 2.2873472463430966

Epoch: 5| Step: 4
Training loss: 0.9100463211406062
Validation loss: 2.2637018581159634

Epoch: 5| Step: 5
Training loss: 1.0662377751891725
Validation loss: 2.2801796265686645

Epoch: 5| Step: 6
Training loss: 0.8911320096490843
Validation loss: 2.259180795984694

Epoch: 5| Step: 7
Training loss: 1.2282652486067733
Validation loss: 2.2533284126203013

Epoch: 5| Step: 8
Training loss: 1.0283432076741064
Validation loss: 2.2426079276608415

Epoch: 5| Step: 9
Training loss: 1.1133924462182951
Validation loss: 2.252887011331394

Epoch: 5| Step: 10
Training loss: 0.7902968543673439
Validation loss: 2.3493443402853598

Epoch: 455| Step: 0
Training loss: 1.173823351858276
Validation loss: 2.302222246076915

Epoch: 5| Step: 1
Training loss: 1.0139256859696406
Validation loss: 2.307852313031062

Epoch: 5| Step: 2
Training loss: 0.9695579789478674
Validation loss: 2.2716316471171196

Epoch: 5| Step: 3
Training loss: 0.8877947492479877
Validation loss: 2.2917135862169324

Epoch: 5| Step: 4
Training loss: 1.0589622616261931
Validation loss: 2.294210329638811

Epoch: 5| Step: 5
Training loss: 0.811001055217014
Validation loss: 2.2689126449335264

Epoch: 5| Step: 6
Training loss: 0.8868059291920132
Validation loss: 2.2687899323953853

Epoch: 5| Step: 7
Training loss: 0.8747019600771797
Validation loss: 2.310153830285408

Epoch: 5| Step: 8
Training loss: 0.7868590607668728
Validation loss: 2.3225780431358

Epoch: 5| Step: 9
Training loss: 1.4877013831498664
Validation loss: 2.3199456512798817

Epoch: 5| Step: 10
Training loss: 1.0956640117552363
Validation loss: 2.2639379350914255

Epoch: 456| Step: 0
Training loss: 0.9375696156403844
Validation loss: 2.1940851799051506

Epoch: 5| Step: 1
Training loss: 0.7430123012546117
Validation loss: 2.265403982887722

Epoch: 5| Step: 2
Training loss: 0.807343257773227
Validation loss: 2.2675425300653083

Epoch: 5| Step: 3
Training loss: 0.9859168073172414
Validation loss: 2.2999788621953927

Epoch: 5| Step: 4
Training loss: 1.2886678843047628
Validation loss: 2.2576938613167226

Epoch: 5| Step: 5
Training loss: 0.8639592058962158
Validation loss: 2.306989446998813

Epoch: 5| Step: 6
Training loss: 1.7889677464076226
Validation loss: 2.2618652003894364

Epoch: 5| Step: 7
Training loss: 0.9372989120989076
Validation loss: 2.2848479099459107

Epoch: 5| Step: 8
Training loss: 0.7772242008466108
Validation loss: 2.3096978643929433

Epoch: 5| Step: 9
Training loss: 0.7162725625470565
Validation loss: 2.348746465880624

Epoch: 5| Step: 10
Training loss: 1.1167280946508453
Validation loss: 2.3054674784033145

Epoch: 457| Step: 0
Training loss: 1.011939654296331
Validation loss: 2.2543104953094155

Epoch: 5| Step: 1
Training loss: 0.7946377183065297
Validation loss: 2.307159474114966

Epoch: 5| Step: 2
Training loss: 0.9406205693644354
Validation loss: 2.3277924167895443

Epoch: 5| Step: 3
Training loss: 1.3076268965664803
Validation loss: 2.3361231052840794

Epoch: 5| Step: 4
Training loss: 0.8923551251663799
Validation loss: 2.3588862552292933

Epoch: 5| Step: 5
Training loss: 1.7700955667935772
Validation loss: 2.3212024723079714

Epoch: 5| Step: 6
Training loss: 0.9371804328491726
Validation loss: 2.292518905472412

Epoch: 5| Step: 7
Training loss: 0.9629189136984564
Validation loss: 2.287043947748356

Epoch: 5| Step: 8
Training loss: 0.527908220888466
Validation loss: 2.238884128781207

Epoch: 5| Step: 9
Training loss: 1.1822744639933462
Validation loss: 2.250160597808866

Epoch: 5| Step: 10
Training loss: 0.8034026619633245
Validation loss: 2.2753020323050634

Epoch: 458| Step: 0
Training loss: 0.7912797651673558
Validation loss: 2.228248953174911

Epoch: 5| Step: 1
Training loss: 1.153413902833009
Validation loss: 2.274535170934

Epoch: 5| Step: 2
Training loss: 1.1139319943981862
Validation loss: 2.261138256071948

Epoch: 5| Step: 3
Training loss: 1.2008865141536476
Validation loss: 2.2637659158966676

Epoch: 5| Step: 4
Training loss: 1.0309406741377574
Validation loss: 2.257286278705809

Epoch: 5| Step: 5
Training loss: 0.9010236918396642
Validation loss: 2.289071527917067

Epoch: 5| Step: 6
Training loss: 1.5580698150887835
Validation loss: 2.3103244972565258

Epoch: 5| Step: 7
Training loss: 0.9110032098799433
Validation loss: 2.343928049632586

Epoch: 5| Step: 8
Training loss: 0.8143903310156814
Validation loss: 2.373701480009161

Epoch: 5| Step: 9
Training loss: 0.791422948632867
Validation loss: 2.327193375580031

Epoch: 5| Step: 10
Training loss: 0.5741652638963118
Validation loss: 2.334077473243909

Epoch: 459| Step: 0
Training loss: 0.7115230035688913
Validation loss: 2.2672700413965043

Epoch: 5| Step: 1
Training loss: 1.268256477620648
Validation loss: 2.304872663125655

Epoch: 5| Step: 2
Training loss: 0.683958599273726
Validation loss: 2.3040213541100374

Epoch: 5| Step: 3
Training loss: 1.164862952787256
Validation loss: 2.3565564992868224

Epoch: 5| Step: 4
Training loss: 0.8567878620963775
Validation loss: 2.287554070201109

Epoch: 5| Step: 5
Training loss: 1.0376098919315329
Validation loss: 2.3295945443971786

Epoch: 5| Step: 6
Training loss: 0.8105573538596924
Validation loss: 2.2850586825383212

Epoch: 5| Step: 7
Training loss: 0.5400426495451903
Validation loss: 2.252635613076807

Epoch: 5| Step: 8
Training loss: 0.8565024832039827
Validation loss: 2.3008944993675713

Epoch: 5| Step: 9
Training loss: 1.0210922392970425
Validation loss: 2.3487510501473032

Epoch: 5| Step: 10
Training loss: 1.7761380643963485
Validation loss: 2.213410850486168

Epoch: 460| Step: 0
Training loss: 0.7403080080797011
Validation loss: 2.288641319457872

Epoch: 5| Step: 1
Training loss: 0.9253403462784129
Validation loss: 2.271940638904383

Epoch: 5| Step: 2
Training loss: 0.891604169693443
Validation loss: 2.280864454305548

Epoch: 5| Step: 3
Training loss: 1.0244460632737122
Validation loss: 2.297529372778548

Epoch: 5| Step: 4
Training loss: 1.5615248116492546
Validation loss: 2.346237378747067

Epoch: 5| Step: 5
Training loss: 1.1580004458451278
Validation loss: 2.286100066630673

Epoch: 5| Step: 6
Training loss: 0.9793154556100295
Validation loss: 2.326932623920776

Epoch: 5| Step: 7
Training loss: 0.8592905870074551
Validation loss: 2.325537324356887

Epoch: 5| Step: 8
Training loss: 0.6720273266597728
Validation loss: 2.3136475910269025

Epoch: 5| Step: 9
Training loss: 0.636296746760662
Validation loss: 2.3795634049604617

Epoch: 5| Step: 10
Training loss: 1.185677686132988
Validation loss: 2.3123317636245724

Epoch: 461| Step: 0
Training loss: 1.2230147058721
Validation loss: 2.3275853569666904

Epoch: 5| Step: 1
Training loss: 0.8141556157546826
Validation loss: 2.2741326426336794

Epoch: 5| Step: 2
Training loss: 0.9439589843770206
Validation loss: 2.274362364475428

Epoch: 5| Step: 3
Training loss: 1.0393079883583727
Validation loss: 2.2862813141376894

Epoch: 5| Step: 4
Training loss: 0.8467539894386199
Validation loss: 2.252858913815998

Epoch: 5| Step: 5
Training loss: 1.0962386021298842
Validation loss: 2.2798571006863377

Epoch: 5| Step: 6
Training loss: 0.7730069744343248
Validation loss: 2.3063009574874784

Epoch: 5| Step: 7
Training loss: 1.0261203458152797
Validation loss: 2.275977850010167

Epoch: 5| Step: 8
Training loss: 1.4689012003238564
Validation loss: 2.3381195922581663

Epoch: 5| Step: 9
Training loss: 0.7990389221675258
Validation loss: 2.326447234087633

Epoch: 5| Step: 10
Training loss: 0.726843830729414
Validation loss: 2.3157815041458645

Epoch: 462| Step: 0
Training loss: 0.91830175325288
Validation loss: 2.3262409747437403

Epoch: 5| Step: 1
Training loss: 0.6925641940071808
Validation loss: 2.33550534881086

Epoch: 5| Step: 2
Training loss: 0.7332364448207459
Validation loss: 2.310153763424341

Epoch: 5| Step: 3
Training loss: 1.620615104883411
Validation loss: 2.30850433708933

Epoch: 5| Step: 4
Training loss: 1.0495674468490481
Validation loss: 2.3255472154975037

Epoch: 5| Step: 5
Training loss: 0.8800339986995886
Validation loss: 2.2796324590176402

Epoch: 5| Step: 6
Training loss: 0.9432538212391169
Validation loss: 2.2695021425287907

Epoch: 5| Step: 7
Training loss: 1.1652735612439595
Validation loss: 2.2246916410355086

Epoch: 5| Step: 8
Training loss: 0.9012398841702884
Validation loss: 2.2200311846650544

Epoch: 5| Step: 9
Training loss: 1.0410977272164974
Validation loss: 2.2592217589490846

Epoch: 5| Step: 10
Training loss: 1.0978817419665776
Validation loss: 2.2608608533195342

Epoch: 463| Step: 0
Training loss: 0.7927189325400178
Validation loss: 2.254157443425089

Epoch: 5| Step: 1
Training loss: 0.8304061779949122
Validation loss: 2.297616170047334

Epoch: 5| Step: 2
Training loss: 1.1396809158992716
Validation loss: 2.2533943227734907

Epoch: 5| Step: 3
Training loss: 0.8716899730187516
Validation loss: 2.2414208827704893

Epoch: 5| Step: 4
Training loss: 1.5127126496948702
Validation loss: 2.3466381476448492

Epoch: 5| Step: 5
Training loss: 0.7103056982262699
Validation loss: 2.2445231563722197

Epoch: 5| Step: 6
Training loss: 0.8995792597551391
Validation loss: 2.34594845936719

Epoch: 5| Step: 7
Training loss: 1.0577572265789272
Validation loss: 2.2848933736656725

Epoch: 5| Step: 8
Training loss: 1.0598365835863948
Validation loss: 2.299416538982227

Epoch: 5| Step: 9
Training loss: 1.0327031272421945
Validation loss: 2.2624419259786803

Epoch: 5| Step: 10
Training loss: 0.7593701664649128
Validation loss: 2.254128793659811

Epoch: 464| Step: 0
Training loss: 0.6388499160526504
Validation loss: 2.2723397969254995

Epoch: 5| Step: 1
Training loss: 0.9988204734965686
Validation loss: 2.295251110567787

Epoch: 5| Step: 2
Training loss: 0.8574489511025106
Validation loss: 2.2333221088905484

Epoch: 5| Step: 3
Training loss: 0.8104292451001686
Validation loss: 2.3079736384554064

Epoch: 5| Step: 4
Training loss: 1.1243558204970125
Validation loss: 2.283581016866825

Epoch: 5| Step: 5
Training loss: 0.7428543307570794
Validation loss: 2.2715475406751486

Epoch: 5| Step: 6
Training loss: 0.8330100306563009
Validation loss: 2.281833659986416

Epoch: 5| Step: 7
Training loss: 1.5977945804169311
Validation loss: 2.3129290521126906

Epoch: 5| Step: 8
Training loss: 1.1290622062270952
Validation loss: 2.259889015305239

Epoch: 5| Step: 9
Training loss: 0.8652105392720641
Validation loss: 2.3266232344702495

Epoch: 5| Step: 10
Training loss: 1.0067914773502262
Validation loss: 2.2947325981664553

Epoch: 465| Step: 0
Training loss: 1.0457144040171684
Validation loss: 2.2556839853664523

Epoch: 5| Step: 1
Training loss: 0.7886494225701784
Validation loss: 2.234000478298157

Epoch: 5| Step: 2
Training loss: 0.6490319985288001
Validation loss: 2.2196593633029

Epoch: 5| Step: 3
Training loss: 0.9202021599055052
Validation loss: 2.29167196286243

Epoch: 5| Step: 4
Training loss: 0.8860602265246939
Validation loss: 2.266824631989507

Epoch: 5| Step: 5
Training loss: 1.0564541749164633
Validation loss: 2.2053266427897023

Epoch: 5| Step: 6
Training loss: 0.9580013418805434
Validation loss: 2.2560326226174747

Epoch: 5| Step: 7
Training loss: 0.8660442273583331
Validation loss: 2.2799040143944267

Epoch: 5| Step: 8
Training loss: 1.0640026574245052
Validation loss: 2.313813965068816

Epoch: 5| Step: 9
Training loss: 1.6102950049763423
Validation loss: 2.2435488114763866

Epoch: 5| Step: 10
Training loss: 0.9974239966231835
Validation loss: 2.2757519557571864

Epoch: 466| Step: 0
Training loss: 0.9115658760204447
Validation loss: 2.3009839539594

Epoch: 5| Step: 1
Training loss: 0.6907934285531091
Validation loss: 2.2440004705800707

Epoch: 5| Step: 2
Training loss: 0.7625899590128093
Validation loss: 2.3224404923604607

Epoch: 5| Step: 3
Training loss: 0.924630298708134
Validation loss: 2.252459242867208

Epoch: 5| Step: 4
Training loss: 0.9951123058734687
Validation loss: 2.2889919161628134

Epoch: 5| Step: 5
Training loss: 1.4448523536410292
Validation loss: 2.283639375467176

Epoch: 5| Step: 6
Training loss: 1.1032649742992955
Validation loss: 2.3172863441412628

Epoch: 5| Step: 7
Training loss: 0.7635591623783349
Validation loss: 2.30815127128511

Epoch: 5| Step: 8
Training loss: 0.9684821958466119
Validation loss: 2.2983465915428907

Epoch: 5| Step: 9
Training loss: 0.9625085842691053
Validation loss: 2.2932058631962566

Epoch: 5| Step: 10
Training loss: 1.0550387327487545
Validation loss: 2.2429975918707483

Epoch: 467| Step: 0
Training loss: 1.6287492635261236
Validation loss: 2.3080842024031103

Epoch: 5| Step: 1
Training loss: 0.8417584616267212
Validation loss: 2.2461724146353554

Epoch: 5| Step: 2
Training loss: 0.8344414416658589
Validation loss: 2.245052551941457

Epoch: 5| Step: 3
Training loss: 1.08065879623313
Validation loss: 2.2765729481266894

Epoch: 5| Step: 4
Training loss: 1.0708645141950246
Validation loss: 2.227925401420635

Epoch: 5| Step: 5
Training loss: 1.046024318496257
Validation loss: 2.3152567399326713

Epoch: 5| Step: 6
Training loss: 0.8948561898631234
Validation loss: 2.2316684578566552

Epoch: 5| Step: 7
Training loss: 0.8801876645040978
Validation loss: 2.2596104851781327

Epoch: 5| Step: 8
Training loss: 0.7163907181481968
Validation loss: 2.2290808749622024

Epoch: 5| Step: 9
Training loss: 0.7336284413935401
Validation loss: 2.2130000429120957

Epoch: 5| Step: 10
Training loss: 1.1377520502047254
Validation loss: 2.268490345674642

Epoch: 468| Step: 0
Training loss: 1.0695402046090683
Validation loss: 2.3167411657398884

Epoch: 5| Step: 1
Training loss: 1.2162304780026516
Validation loss: 2.3244228974827306

Epoch: 5| Step: 2
Training loss: 0.935428269419824
Validation loss: 2.2531692614544463

Epoch: 5| Step: 3
Training loss: 0.8560371426719413
Validation loss: 2.3308716905998073

Epoch: 5| Step: 4
Training loss: 0.7594675298132483
Validation loss: 2.2702374385344015

Epoch: 5| Step: 5
Training loss: 0.9551922002585733
Validation loss: 2.255327577149389

Epoch: 5| Step: 6
Training loss: 0.6360635721520549
Validation loss: 2.287449971353586

Epoch: 5| Step: 7
Training loss: 0.8522409308889002
Validation loss: 2.29833113388671

Epoch: 5| Step: 8
Training loss: 0.7089990031096817
Validation loss: 2.290953511966716

Epoch: 5| Step: 9
Training loss: 1.554575010284389
Validation loss: 2.267782227290895

Epoch: 5| Step: 10
Training loss: 1.0344973212346185
Validation loss: 2.2846710292932584

Epoch: 469| Step: 0
Training loss: 0.8274707368937567
Validation loss: 2.3354381999339195

Epoch: 5| Step: 1
Training loss: 0.8806507684038835
Validation loss: 2.335711083650794

Epoch: 5| Step: 2
Training loss: 0.9098435220745941
Validation loss: 2.352585756027516

Epoch: 5| Step: 3
Training loss: 0.7846226563393603
Validation loss: 2.2497150669140162

Epoch: 5| Step: 4
Training loss: 1.2686223459151174
Validation loss: 2.2887100575015404

Epoch: 5| Step: 5
Training loss: 0.6807292102520868
Validation loss: 2.253171655370041

Epoch: 5| Step: 6
Training loss: 1.042209134313407
Validation loss: 2.362390664257385

Epoch: 5| Step: 7
Training loss: 0.8202657413780147
Validation loss: 2.27582622373932

Epoch: 5| Step: 8
Training loss: 1.5641989054920038
Validation loss: 2.2608089491293764

Epoch: 5| Step: 9
Training loss: 0.9355261368334489
Validation loss: 2.2910150834051715

Epoch: 5| Step: 10
Training loss: 0.6126066494559346
Validation loss: 2.293151196390499

Epoch: 470| Step: 0
Training loss: 0.7378979045938977
Validation loss: 2.314081092176998

Epoch: 5| Step: 1
Training loss: 0.7104081918727395
Validation loss: 2.2942427597310773

Epoch: 5| Step: 2
Training loss: 0.9361006465601147
Validation loss: 2.2417935684248587

Epoch: 5| Step: 3
Training loss: 0.9333553887781274
Validation loss: 2.242722458229078

Epoch: 5| Step: 4
Training loss: 1.028383374431505
Validation loss: 2.2778988580997552

Epoch: 5| Step: 5
Training loss: 1.3621219635522028
Validation loss: 2.257483564742245

Epoch: 5| Step: 6
Training loss: 0.7131499772374125
Validation loss: 2.2472817261248896

Epoch: 5| Step: 7
Training loss: 1.077442063457863
Validation loss: 2.3603044002392664

Epoch: 5| Step: 8
Training loss: 1.2834641932778377
Validation loss: 2.201390552046753

Epoch: 5| Step: 9
Training loss: 0.7255878268765357
Validation loss: 2.2927678118647217

Epoch: 5| Step: 10
Training loss: 0.8587210507906418
Validation loss: 2.280352276621855

Epoch: 471| Step: 0
Training loss: 1.064920473308423
Validation loss: 2.2049246647547833

Epoch: 5| Step: 1
Training loss: 1.4775540690848141
Validation loss: 2.261264997013418

Epoch: 5| Step: 2
Training loss: 0.7864023066557684
Validation loss: 2.2806464855194717

Epoch: 5| Step: 3
Training loss: 0.7631274377782377
Validation loss: 2.3531937247096093

Epoch: 5| Step: 4
Training loss: 0.8796082808225775
Validation loss: 2.273784593335696

Epoch: 5| Step: 5
Training loss: 0.9123770016900309
Validation loss: 2.2275088538734424

Epoch: 5| Step: 6
Training loss: 0.6988079206724168
Validation loss: 2.288383615885964

Epoch: 5| Step: 7
Training loss: 0.726911604493437
Validation loss: 2.301740419721663

Epoch: 5| Step: 8
Training loss: 0.9593231783610627
Validation loss: 2.3106190648830203

Epoch: 5| Step: 9
Training loss: 0.9838097175397398
Validation loss: 2.234147610787255

Epoch: 5| Step: 10
Training loss: 0.9460200664577613
Validation loss: 2.2523660923180615

Epoch: 472| Step: 0
Training loss: 0.8351009140024264
Validation loss: 2.353202996288238

Epoch: 5| Step: 1
Training loss: 0.9433335010463264
Validation loss: 2.181901133282005

Epoch: 5| Step: 2
Training loss: 0.8892091573151876
Validation loss: 2.278827780964277

Epoch: 5| Step: 3
Training loss: 0.7055368806673695
Validation loss: 2.2873607148616464

Epoch: 5| Step: 4
Training loss: 0.8678228439357459
Validation loss: 2.2497259939379384

Epoch: 5| Step: 5
Training loss: 1.5778249323130904
Validation loss: 2.227884040522637

Epoch: 5| Step: 6
Training loss: 0.8712173511074237
Validation loss: 2.300735401585568

Epoch: 5| Step: 7
Training loss: 1.0292645038530701
Validation loss: 2.3088030054955873

Epoch: 5| Step: 8
Training loss: 1.1812814718423712
Validation loss: 2.253430457461585

Epoch: 5| Step: 9
Training loss: 0.7865660048457109
Validation loss: 2.216509868890629

Epoch: 5| Step: 10
Training loss: 0.851923629760894
Validation loss: 2.269649020295085

Epoch: 473| Step: 0
Training loss: 0.9311260025627401
Validation loss: 2.260465457443183

Epoch: 5| Step: 1
Training loss: 0.699284172194175
Validation loss: 2.2330147902513398

Epoch: 5| Step: 2
Training loss: 0.7632631735091228
Validation loss: 2.2973144537220223

Epoch: 5| Step: 3
Training loss: 0.8519174378558356
Validation loss: 2.2831279190980074

Epoch: 5| Step: 4
Training loss: 1.0345087869565064
Validation loss: 2.260620806224892

Epoch: 5| Step: 5
Training loss: 0.8849659876025798
Validation loss: 2.375212456397771

Epoch: 5| Step: 6
Training loss: 1.00866663024593
Validation loss: 2.2329992833167474

Epoch: 5| Step: 7
Training loss: 1.4386938362195831
Validation loss: 2.335503466286607

Epoch: 5| Step: 8
Training loss: 0.9349968553684005
Validation loss: 2.279898865526908

Epoch: 5| Step: 9
Training loss: 0.8417935470904708
Validation loss: 2.2582460732212044

Epoch: 5| Step: 10
Training loss: 0.7848837460247631
Validation loss: 2.2798489291172164

Epoch: 474| Step: 0
Training loss: 0.863064803524895
Validation loss: 2.299635733060838

Epoch: 5| Step: 1
Training loss: 0.7018432378333506
Validation loss: 2.359344183412177

Epoch: 5| Step: 2
Training loss: 1.0063013975865924
Validation loss: 2.2988083614369272

Epoch: 5| Step: 3
Training loss: 0.9192077391731914
Validation loss: 2.2646298812557863

Epoch: 5| Step: 4
Training loss: 0.7815234277988055
Validation loss: 2.2305796169169225

Epoch: 5| Step: 5
Training loss: 0.8879725460821819
Validation loss: 2.279971357902205

Epoch: 5| Step: 6
Training loss: 0.7820914505415546
Validation loss: 2.264937045521754

Epoch: 5| Step: 7
Training loss: 1.6482219826347808
Validation loss: 2.2782281900825923

Epoch: 5| Step: 8
Training loss: 0.8967672994458867
Validation loss: 2.264876589219202

Epoch: 5| Step: 9
Training loss: 0.8126763005818709
Validation loss: 2.2949473903741295

Epoch: 5| Step: 10
Training loss: 0.8843802650753236
Validation loss: 2.264910967384804

Epoch: 475| Step: 0
Training loss: 0.6753612381745461
Validation loss: 2.258973290027243

Epoch: 5| Step: 1
Training loss: 1.4820495057376712
Validation loss: 2.3264141250569663

Epoch: 5| Step: 2
Training loss: 1.2397920074915407
Validation loss: 2.2508656148127955

Epoch: 5| Step: 3
Training loss: 0.8263087598881778
Validation loss: 2.300479905325132

Epoch: 5| Step: 4
Training loss: 1.1470482656372734
Validation loss: 2.331618743336911

Epoch: 5| Step: 5
Training loss: 0.9565110953425779
Validation loss: 2.2945626043652454

Epoch: 5| Step: 6
Training loss: 0.7206193828777404
Validation loss: 2.269051340235472

Epoch: 5| Step: 7
Training loss: 1.1147225670288914
Validation loss: 2.254172368090083

Epoch: 5| Step: 8
Training loss: 1.1002174444290274
Validation loss: 2.2224337443396607

Epoch: 5| Step: 9
Training loss: 0.5846397269471684
Validation loss: 2.2581599072188223

Epoch: 5| Step: 10
Training loss: 0.8924667656211013
Validation loss: 2.2442526579312503

Epoch: 476| Step: 0
Training loss: 0.7902830145702779
Validation loss: 2.2025894046950327

Epoch: 5| Step: 1
Training loss: 0.7243777827817507
Validation loss: 2.2712235068037887

Epoch: 5| Step: 2
Training loss: 1.4628404270008961
Validation loss: 2.293283330433526

Epoch: 5| Step: 3
Training loss: 0.9388426702705419
Validation loss: 2.256900876247604

Epoch: 5| Step: 4
Training loss: 1.1002030336964717
Validation loss: 2.2486762878079687

Epoch: 5| Step: 5
Training loss: 0.8158304474584435
Validation loss: 2.1847472160784442

Epoch: 5| Step: 6
Training loss: 0.8672904907103743
Validation loss: 2.2535358092617277

Epoch: 5| Step: 7
Training loss: 0.697596666412416
Validation loss: 2.2899313105317254

Epoch: 5| Step: 8
Training loss: 0.7689075556625571
Validation loss: 2.248874624420737

Epoch: 5| Step: 9
Training loss: 0.8116665747196634
Validation loss: 2.2610271675297757

Epoch: 5| Step: 10
Training loss: 0.7300773020536092
Validation loss: 2.2725966891523113

Epoch: 477| Step: 0
Training loss: 0.6593271048267394
Validation loss: 2.2480360173609952

Epoch: 5| Step: 1
Training loss: 1.5183939857944648
Validation loss: 2.294973661719445

Epoch: 5| Step: 2
Training loss: 0.9542180969226052
Validation loss: 2.315346026611822

Epoch: 5| Step: 3
Training loss: 0.9235165738042087
Validation loss: 2.316049905282936

Epoch: 5| Step: 4
Training loss: 0.7468267704542592
Validation loss: 2.265368732899623

Epoch: 5| Step: 5
Training loss: 0.6898304714424004
Validation loss: 2.2917539167901375

Epoch: 5| Step: 6
Training loss: 0.8448162758876809
Validation loss: 2.2229317244729674

Epoch: 5| Step: 7
Training loss: 0.932185367654682
Validation loss: 2.289419104769029

Epoch: 5| Step: 8
Training loss: 1.0037489593424456
Validation loss: 2.284725055762849

Epoch: 5| Step: 9
Training loss: 0.9936185713893693
Validation loss: 2.270022703019932

Epoch: 5| Step: 10
Training loss: 0.8608345468653508
Validation loss: 2.2246391228638904

Epoch: 478| Step: 0
Training loss: 1.5643257155905888
Validation loss: 2.3024365873241273

Epoch: 5| Step: 1
Training loss: 0.9366514180142488
Validation loss: 2.3469200938184858

Epoch: 5| Step: 2
Training loss: 0.7219463263609401
Validation loss: 2.224119760705998

Epoch: 5| Step: 3
Training loss: 1.2090295835556129
Validation loss: 2.2733189854602

Epoch: 5| Step: 4
Training loss: 0.7098143792295053
Validation loss: 2.2769775310053046

Epoch: 5| Step: 5
Training loss: 0.8751643571442372
Validation loss: 2.239027089217063

Epoch: 5| Step: 6
Training loss: 0.8248829267259415
Validation loss: 2.2315155257359027

Epoch: 5| Step: 7
Training loss: 0.7763282238281777
Validation loss: 2.293870806362082

Epoch: 5| Step: 8
Training loss: 0.6595652717033974
Validation loss: 2.2775470726814837

Epoch: 5| Step: 9
Training loss: 0.5969446221534737
Validation loss: 2.322013800549894

Epoch: 5| Step: 10
Training loss: 0.8213751676330256
Validation loss: 2.2738129807832963

Epoch: 479| Step: 0
Training loss: 0.824336798291059
Validation loss: 2.2878138102725787

Epoch: 5| Step: 1
Training loss: 0.979338522635263
Validation loss: 2.295443684554915

Epoch: 5| Step: 2
Training loss: 0.9774414074696055
Validation loss: 2.32977218482267

Epoch: 5| Step: 3
Training loss: 0.6917039047312992
Validation loss: 2.3519135791122063

Epoch: 5| Step: 4
Training loss: 0.9540546761025458
Validation loss: 2.2323948640855944

Epoch: 5| Step: 5
Training loss: 0.8024717026472021
Validation loss: 2.261788012115837

Epoch: 5| Step: 6
Training loss: 0.8628219141959482
Validation loss: 2.2633210475641405

Epoch: 5| Step: 7
Training loss: 0.9241802681580435
Validation loss: 2.2616222299433777

Epoch: 5| Step: 8
Training loss: 1.69531566426206
Validation loss: 2.3011755340561733

Epoch: 5| Step: 9
Training loss: 0.6757397280599288
Validation loss: 2.3445803800381637

Epoch: 5| Step: 10
Training loss: 0.6465590742120932
Validation loss: 2.330446506193177

Epoch: 480| Step: 0
Training loss: 0.7553149093318039
Validation loss: 2.2787641105835763

Epoch: 5| Step: 1
Training loss: 0.9235708511552195
Validation loss: 2.2666158283939764

Epoch: 5| Step: 2
Training loss: 0.8223125235985282
Validation loss: 2.2281911826138048

Epoch: 5| Step: 3
Training loss: 0.7756143242457092
Validation loss: 2.24173757069133

Epoch: 5| Step: 4
Training loss: 0.7137177985521685
Validation loss: 2.289151680058327

Epoch: 5| Step: 5
Training loss: 1.0751392096937713
Validation loss: 2.2953176832489954

Epoch: 5| Step: 6
Training loss: 1.0214104999502254
Validation loss: 2.2313420967785547

Epoch: 5| Step: 7
Training loss: 0.75022229238241
Validation loss: 2.322837860994115

Epoch: 5| Step: 8
Training loss: 0.8043753379578018
Validation loss: 2.301291334022051

Epoch: 5| Step: 9
Training loss: 1.640017297002246
Validation loss: 2.359009394209496

Epoch: 5| Step: 10
Training loss: 0.7014119366886707
Validation loss: 2.256669168988781

Epoch: 481| Step: 0
Training loss: 0.773836745667135
Validation loss: 2.298200436798542

Epoch: 5| Step: 1
Training loss: 1.106678546723021
Validation loss: 2.2559616570683434

Epoch: 5| Step: 2
Training loss: 0.8821399118342301
Validation loss: 2.249388098829936

Epoch: 5| Step: 3
Training loss: 0.5576718599203436
Validation loss: 2.320632757234778

Epoch: 5| Step: 4
Training loss: 0.43054986594484557
Validation loss: 2.213888490977516

Epoch: 5| Step: 5
Training loss: 1.0549023444732324
Validation loss: 2.2776261350538003

Epoch: 5| Step: 6
Training loss: 1.0510686318322493
Validation loss: 2.2136738615476346

Epoch: 5| Step: 7
Training loss: 1.5117358618268033
Validation loss: 2.2378229360193056

Epoch: 5| Step: 8
Training loss: 1.100106975382188
Validation loss: 2.2082868556841158

Epoch: 5| Step: 9
Training loss: 0.8842644693163078
Validation loss: 2.3109392377309974

Epoch: 5| Step: 10
Training loss: 0.6977510018418384
Validation loss: 2.2874579835221738

Epoch: 482| Step: 0
Training loss: 1.490568710959775
Validation loss: 2.335649953971284

Epoch: 5| Step: 1
Training loss: 0.8089589938792177
Validation loss: 2.3298581181625404

Epoch: 5| Step: 2
Training loss: 0.8358245488089002
Validation loss: 2.318132962554772

Epoch: 5| Step: 3
Training loss: 0.8699561247230668
Validation loss: 2.3336596773465588

Epoch: 5| Step: 4
Training loss: 0.8776376682003425
Validation loss: 2.3379801832927876

Epoch: 5| Step: 5
Training loss: 0.8935546875
Validation loss: 2.292401344988441

Epoch: 5| Step: 6
Training loss: 1.1225225933154583
Validation loss: 2.348326889006304

Epoch: 5| Step: 7
Training loss: 0.7206163224874816
Validation loss: 2.287161423799971

Epoch: 5| Step: 8
Training loss: 1.1351417535327486
Validation loss: 2.3208841847578987

Epoch: 5| Step: 9
Training loss: 0.7113148871860144
Validation loss: 2.2422814221080323

Epoch: 5| Step: 10
Training loss: 0.7880334092116025
Validation loss: 2.3274374094659978

Epoch: 483| Step: 0
Training loss: 0.6787136818809736
Validation loss: 2.243096474548453

Epoch: 5| Step: 1
Training loss: 0.9169727847450568
Validation loss: 2.3148549335608233

Epoch: 5| Step: 2
Training loss: 0.8261497620854032
Validation loss: 2.204871160085801

Epoch: 5| Step: 3
Training loss: 1.0338659918402686
Validation loss: 2.238820598630571

Epoch: 5| Step: 4
Training loss: 1.4851596565347982
Validation loss: 2.2883992757289024

Epoch: 5| Step: 5
Training loss: 1.1093159512130815
Validation loss: 2.301904980650338

Epoch: 5| Step: 6
Training loss: 0.78269512035057
Validation loss: 2.2631091006206177

Epoch: 5| Step: 7
Training loss: 0.9600672308904152
Validation loss: 2.3149399056788935

Epoch: 5| Step: 8
Training loss: 0.7507661641299254
Validation loss: 2.2868012220627962

Epoch: 5| Step: 9
Training loss: 0.7665378033795918
Validation loss: 2.225739801698818

Epoch: 5| Step: 10
Training loss: 0.7621554956602521
Validation loss: 2.3232209477081343

Epoch: 484| Step: 0
Training loss: 0.9213699315032227
Validation loss: 2.4194254257815766

Epoch: 5| Step: 1
Training loss: 0.7116178673474358
Validation loss: 2.402314228417045

Epoch: 5| Step: 2
Training loss: 1.196342722409417
Validation loss: 2.4378450579080817

Epoch: 5| Step: 3
Training loss: 0.8060923414815128
Validation loss: 2.274386576407793

Epoch: 5| Step: 4
Training loss: 1.0552363910064113
Validation loss: 2.285456888808837

Epoch: 5| Step: 5
Training loss: 1.525993355082872
Validation loss: 2.2948813453993044

Epoch: 5| Step: 6
Training loss: 0.6914322196264358
Validation loss: 2.2552802420107008

Epoch: 5| Step: 7
Training loss: 1.0576125661761338
Validation loss: 2.2391202004677275

Epoch: 5| Step: 8
Training loss: 0.9289584787634865
Validation loss: 2.2891239979903673

Epoch: 5| Step: 9
Training loss: 0.9688395797166763
Validation loss: 2.2186211989559466

Epoch: 5| Step: 10
Training loss: 0.6625578270272298
Validation loss: 2.202346161400349

Epoch: 485| Step: 0
Training loss: 1.6891972518934677
Validation loss: 2.221767662927148

Epoch: 5| Step: 1
Training loss: 1.1223052918394443
Validation loss: 2.224024570192736

Epoch: 5| Step: 2
Training loss: 0.7658145047205697
Validation loss: 2.241216512686479

Epoch: 5| Step: 3
Training loss: 0.6963952025080097
Validation loss: 2.232689366580463

Epoch: 5| Step: 4
Training loss: 0.7179166689839717
Validation loss: 2.1841936875374017

Epoch: 5| Step: 5
Training loss: 0.770976225178406
Validation loss: 2.235336309178171

Epoch: 5| Step: 6
Training loss: 0.7827021264026514
Validation loss: 2.3533698844488113

Epoch: 5| Step: 7
Training loss: 0.8209284331972189
Validation loss: 2.291909059773432

Epoch: 5| Step: 8
Training loss: 0.6855215301610603
Validation loss: 2.353855205742486

Epoch: 5| Step: 9
Training loss: 0.9674722797651376
Validation loss: 2.3133742795266623

Epoch: 5| Step: 10
Training loss: 0.9158745110001423
Validation loss: 2.3594205086305564

Epoch: 486| Step: 0
Training loss: 1.4384713415606627
Validation loss: 2.301462244378837

Epoch: 5| Step: 1
Training loss: 0.9166075658530496
Validation loss: 2.313869260510954

Epoch: 5| Step: 2
Training loss: 0.5315414638943021
Validation loss: 2.3988061955346325

Epoch: 5| Step: 3
Training loss: 0.8550205537210561
Validation loss: 2.2676495969556645

Epoch: 5| Step: 4
Training loss: 0.9923315769626792
Validation loss: 2.289131743358751

Epoch: 5| Step: 5
Training loss: 0.9198899962131649
Validation loss: 2.3549755956101457

Epoch: 5| Step: 6
Training loss: 1.009073990856534
Validation loss: 2.3504830749064167

Epoch: 5| Step: 7
Training loss: 0.8796003525492546
Validation loss: 2.232042988384463

Epoch: 5| Step: 8
Training loss: 0.7489761277915862
Validation loss: 2.2249508096332407

Epoch: 5| Step: 9
Training loss: 0.90609591917149
Validation loss: 2.2769074513248233

Epoch: 5| Step: 10
Training loss: 0.6689857637746701
Validation loss: 2.290530640457231

Epoch: 487| Step: 0
Training loss: 0.7667629970970128
Validation loss: 2.275251331349774

Epoch: 5| Step: 1
Training loss: 0.9087365993471942
Validation loss: 2.2791863813172077

Epoch: 5| Step: 2
Training loss: 0.6920143728982403
Validation loss: 2.240576672646037

Epoch: 5| Step: 3
Training loss: 0.7642867400897162
Validation loss: 2.295821602872916

Epoch: 5| Step: 4
Training loss: 1.3499591114775042
Validation loss: 2.3328249072706173

Epoch: 5| Step: 5
Training loss: 1.1045848966050476
Validation loss: 2.254902812121345

Epoch: 5| Step: 6
Training loss: 0.7923507537261446
Validation loss: 2.234685421190673

Epoch: 5| Step: 7
Training loss: 0.7926536648146245
Validation loss: 2.31285236094217

Epoch: 5| Step: 8
Training loss: 0.6624762719781493
Validation loss: 2.3185948557608733

Epoch: 5| Step: 9
Training loss: 0.9547528608208862
Validation loss: 2.301826728532795

Epoch: 5| Step: 10
Training loss: 1.236991716287765
Validation loss: 2.329575033595571

Epoch: 488| Step: 0
Training loss: 0.904811803154645
Validation loss: 2.323522834003285

Epoch: 5| Step: 1
Training loss: 0.6779031460950826
Validation loss: 2.273112652845655

Epoch: 5| Step: 2
Training loss: 1.4585618067197585
Validation loss: 2.246690775389951

Epoch: 5| Step: 3
Training loss: 1.0517482916525895
Validation loss: 2.209773100660247

Epoch: 5| Step: 4
Training loss: 0.8015316680272941
Validation loss: 2.2339882717117194

Epoch: 5| Step: 5
Training loss: 1.034896990860687
Validation loss: 2.2725802841831935

Epoch: 5| Step: 6
Training loss: 0.8055792006679972
Validation loss: 2.306520510989103

Epoch: 5| Step: 7
Training loss: 0.8320641667834946
Validation loss: 2.2711965035875368

Epoch: 5| Step: 8
Training loss: 0.9951706741828152
Validation loss: 2.246697332562649

Epoch: 5| Step: 9
Training loss: 1.0790509656548726
Validation loss: 2.299469487639948

Epoch: 5| Step: 10
Training loss: 0.7679421529888949
Validation loss: 2.3109904037184545

Epoch: 489| Step: 0
Training loss: 0.6743887738862019
Validation loss: 2.2547893311603473

Epoch: 5| Step: 1
Training loss: 0.966647666437494
Validation loss: 2.3649415368308855

Epoch: 5| Step: 2
Training loss: 0.8620621717119529
Validation loss: 2.352136432540956

Epoch: 5| Step: 3
Training loss: 1.15593942131054
Validation loss: 2.377287353121882

Epoch: 5| Step: 4
Training loss: 0.7132528142703077
Validation loss: 2.35021676866182

Epoch: 5| Step: 5
Training loss: 0.9581216944707796
Validation loss: 2.27555967728658

Epoch: 5| Step: 6
Training loss: 0.5904244349804743
Validation loss: 2.315773500301896

Epoch: 5| Step: 7
Training loss: 0.8552013658680371
Validation loss: 2.2819769332254283

Epoch: 5| Step: 8
Training loss: 0.6320263017194299
Validation loss: 2.2866260935039806

Epoch: 5| Step: 9
Training loss: 1.5817896528969846
Validation loss: 2.241640041043912

Epoch: 5| Step: 10
Training loss: 0.7051543725544716
Validation loss: 2.276356975111789

Epoch: 490| Step: 0
Training loss: 0.7276236875332501
Validation loss: 2.278592686937219

Epoch: 5| Step: 1
Training loss: 0.9827564193178228
Validation loss: 2.268676547170478

Epoch: 5| Step: 2
Training loss: 0.7308303835413119
Validation loss: 2.3380940414504368

Epoch: 5| Step: 3
Training loss: 1.4987522339665018
Validation loss: 2.2406189542793427

Epoch: 5| Step: 4
Training loss: 0.7656944399114305
Validation loss: 2.2320522532437757

Epoch: 5| Step: 5
Training loss: 0.6698200159515258
Validation loss: 2.290376114865945

Epoch: 5| Step: 6
Training loss: 0.7002417470519896
Validation loss: 2.2858945602008536

Epoch: 5| Step: 7
Training loss: 0.9639016621616983
Validation loss: 2.1868258250413355

Epoch: 5| Step: 8
Training loss: 0.9599915477261388
Validation loss: 2.26417958761834

Epoch: 5| Step: 9
Training loss: 0.8842248337572269
Validation loss: 2.2491537243596476

Epoch: 5| Step: 10
Training loss: 1.0360042337640394
Validation loss: 2.2814090317648414

Epoch: 491| Step: 0
Training loss: 0.7556673343180413
Validation loss: 2.3816500341226345

Epoch: 5| Step: 1
Training loss: 1.10619855858118
Validation loss: 2.338853295442305

Epoch: 5| Step: 2
Training loss: 1.15122999258808
Validation loss: 2.287609406438219

Epoch: 5| Step: 3
Training loss: 0.94656884434042
Validation loss: 2.325354378348519

Epoch: 5| Step: 4
Training loss: 0.8063363893933814
Validation loss: 2.35522717889251

Epoch: 5| Step: 5
Training loss: 0.8452288771356298
Validation loss: 2.269742221694022

Epoch: 5| Step: 6
Training loss: 0.5028606774843373
Validation loss: 2.288823871661149

Epoch: 5| Step: 7
Training loss: 0.6287604690195889
Validation loss: 2.2959353190835587

Epoch: 5| Step: 8
Training loss: 0.7657690885769407
Validation loss: 2.2181589285881795

Epoch: 5| Step: 9
Training loss: 1.5930111238195397
Validation loss: 2.241040926544022

Epoch: 5| Step: 10
Training loss: 0.8174112148659879
Validation loss: 2.2006038464924504

Epoch: 492| Step: 0
Training loss: 0.9099535736879919
Validation loss: 2.2967119815500094

Epoch: 5| Step: 1
Training loss: 1.0158692286353153
Validation loss: 2.219523493636028

Epoch: 5| Step: 2
Training loss: 0.9523350302944035
Validation loss: 2.314743567770607

Epoch: 5| Step: 3
Training loss: 0.7860745805295991
Validation loss: 2.2718954694702878

Epoch: 5| Step: 4
Training loss: 0.7712469967083442
Validation loss: 2.2411952956763694

Epoch: 5| Step: 5
Training loss: 0.6652375315816986
Validation loss: 2.323265950721517

Epoch: 5| Step: 6
Training loss: 0.9733946115711052
Validation loss: 2.3163445367017643

Epoch: 5| Step: 7
Training loss: 1.5369786130550176
Validation loss: 2.2506305398995963

Epoch: 5| Step: 8
Training loss: 0.7503506317681006
Validation loss: 2.299483018941413

Epoch: 5| Step: 9
Training loss: 0.8076334240168068
Validation loss: 2.320442099687881

Epoch: 5| Step: 10
Training loss: 0.7657604097785243
Validation loss: 2.2411831437188052

Epoch: 493| Step: 0
Training loss: 0.8030626873972411
Validation loss: 2.3267303736141134

Epoch: 5| Step: 1
Training loss: 0.8514178091893242
Validation loss: 2.3040952571925213

Epoch: 5| Step: 2
Training loss: 0.8330699186439067
Validation loss: 2.321083788919543

Epoch: 5| Step: 3
Training loss: 1.1274706414200324
Validation loss: 2.2214724349541473

Epoch: 5| Step: 4
Training loss: 0.8567361370509009
Validation loss: 2.221214798341667

Epoch: 5| Step: 5
Training loss: 0.690001834023844
Validation loss: 2.257442394212928

Epoch: 5| Step: 6
Training loss: 0.5458103443235538
Validation loss: 2.309960825674543

Epoch: 5| Step: 7
Training loss: 0.7410022708250559
Validation loss: 2.2259055572641637

Epoch: 5| Step: 8
Training loss: 0.7553780770549252
Validation loss: 2.291031118586262

Epoch: 5| Step: 9
Training loss: 0.8856580330470119
Validation loss: 2.2516943739853494

Epoch: 5| Step: 10
Training loss: 1.7084745333244118
Validation loss: 2.298148417137914

Epoch: 494| Step: 0
Training loss: 0.7491535337384
Validation loss: 2.2674414708253376

Epoch: 5| Step: 1
Training loss: 0.9434755305142947
Validation loss: 2.285600856359496

Epoch: 5| Step: 2
Training loss: 0.7456281317543584
Validation loss: 2.2642338414846246

Epoch: 5| Step: 3
Training loss: 0.8271690104874929
Validation loss: 2.2596535488747294

Epoch: 5| Step: 4
Training loss: 0.9938565730882845
Validation loss: 2.292552892608608

Epoch: 5| Step: 5
Training loss: 0.9739911520965349
Validation loss: 2.3203687393445693

Epoch: 5| Step: 6
Training loss: 0.7466097340705183
Validation loss: 2.3144770360586997

Epoch: 5| Step: 7
Training loss: 0.8915502861461915
Validation loss: 2.2622534049653833

Epoch: 5| Step: 8
Training loss: 1.456407592497797
Validation loss: 2.258362991482754

Epoch: 5| Step: 9
Training loss: 1.02775861246838
Validation loss: 2.280873005511367

Epoch: 5| Step: 10
Training loss: 0.8786917530686504
Validation loss: 2.2460514181962274

Epoch: 495| Step: 0
Training loss: 0.894087268975585
Validation loss: 2.244997069433217

Epoch: 5| Step: 1
Training loss: 0.7901221232845428
Validation loss: 2.210973216606488

Epoch: 5| Step: 2
Training loss: 1.5176813392446569
Validation loss: 2.252674198194176

Epoch: 5| Step: 3
Training loss: 0.7291799180779471
Validation loss: 2.258922755410736

Epoch: 5| Step: 4
Training loss: 0.972232833683293
Validation loss: 2.256307351238457

Epoch: 5| Step: 5
Training loss: 0.8857194420229337
Validation loss: 2.2656268874044905

Epoch: 5| Step: 6
Training loss: 0.9703419433647694
Validation loss: 2.284995873531585

Epoch: 5| Step: 7
Training loss: 0.9039000923916338
Validation loss: 2.1814183040101267

Epoch: 5| Step: 8
Training loss: 0.7306882966934284
Validation loss: 2.2705340437047012

Epoch: 5| Step: 9
Training loss: 0.4971726767430021
Validation loss: 2.2669108384459697

Epoch: 5| Step: 10
Training loss: 0.7850690575006848
Validation loss: 2.2733890940026984

Epoch: 496| Step: 0
Training loss: 0.8336372099597266
Validation loss: 2.3151856491632588

Epoch: 5| Step: 1
Training loss: 0.5077074969377021
Validation loss: 2.318117028584712

Epoch: 5| Step: 2
Training loss: 0.7316176818737142
Validation loss: 2.3276925625131835

Epoch: 5| Step: 3
Training loss: 0.8652857298066349
Validation loss: 2.3081624159220997

Epoch: 5| Step: 4
Training loss: 1.4594415359522948
Validation loss: 2.2761083318920603

Epoch: 5| Step: 5
Training loss: 1.0139412641424241
Validation loss: 2.2994295477058815

Epoch: 5| Step: 6
Training loss: 0.8508700433919872
Validation loss: 2.244451691562228

Epoch: 5| Step: 7
Training loss: 0.5940091922607468
Validation loss: 2.289516779221277

Epoch: 5| Step: 8
Training loss: 0.5117305725129698
Validation loss: 2.306034688422241

Epoch: 5| Step: 9
Training loss: 1.1390440972075229
Validation loss: 2.2417994017513756

Epoch: 5| Step: 10
Training loss: 1.0779163324517518
Validation loss: 2.36993724470958

Epoch: 497| Step: 0
Training loss: 1.1724179345308283
Validation loss: 2.2854719495206575

Epoch: 5| Step: 1
Training loss: 0.6721147065271009
Validation loss: 2.3410841385170915

Epoch: 5| Step: 2
Training loss: 0.8794961263800107
Validation loss: 2.2141775064665676

Epoch: 5| Step: 3
Training loss: 0.8302200734558022
Validation loss: 2.3133054304548675

Epoch: 5| Step: 4
Training loss: 0.9536232505859298
Validation loss: 2.2856096074438734

Epoch: 5| Step: 5
Training loss: 0.9105009154933661
Validation loss: 2.240872163990742

Epoch: 5| Step: 6
Training loss: 0.6654246328669674
Validation loss: 2.267476542176337

Epoch: 5| Step: 7
Training loss: 0.7865011359350267
Validation loss: 2.1972462173388716

Epoch: 5| Step: 8
Training loss: 1.552654912102902
Validation loss: 2.282299698711114

Epoch: 5| Step: 9
Training loss: 0.5915384515225917
Validation loss: 2.2434055366737877

Epoch: 5| Step: 10
Training loss: 0.6869169493856716
Validation loss: 2.2785317575521797

Epoch: 498| Step: 0
Training loss: 1.3873941845109203
Validation loss: 2.250569860469886

Epoch: 5| Step: 1
Training loss: 0.7722072257004468
Validation loss: 2.357854920524189

Epoch: 5| Step: 2
Training loss: 0.9941843619028202
Validation loss: 2.26259611477765

Epoch: 5| Step: 3
Training loss: 0.6300379835516058
Validation loss: 2.2535430535385927

Epoch: 5| Step: 4
Training loss: 0.8033632659743688
Validation loss: 2.259833945269347

Epoch: 5| Step: 5
Training loss: 0.9211508282681993
Validation loss: 2.2595708311799507

Epoch: 5| Step: 6
Training loss: 0.7332038468858827
Validation loss: 2.25594916305058

Epoch: 5| Step: 7
Training loss: 0.967881582551821
Validation loss: 2.3108192717178557

Epoch: 5| Step: 8
Training loss: 0.8737341034279491
Validation loss: 2.276222884276645

Epoch: 5| Step: 9
Training loss: 0.8522283767951551
Validation loss: 2.252737242062195

Epoch: 5| Step: 10
Training loss: 0.8314363385487531
Validation loss: 2.3031579978494556

Epoch: 499| Step: 0
Training loss: 0.8284817413063175
Validation loss: 2.312945474599404

Epoch: 5| Step: 1
Training loss: 1.4752111154540903
Validation loss: 2.229842274405284

Epoch: 5| Step: 2
Training loss: 0.8381817007549003
Validation loss: 2.3072041315047804

Epoch: 5| Step: 3
Training loss: 0.6941577666682579
Validation loss: 2.226029902547689

Epoch: 5| Step: 4
Training loss: 1.0141216008108096
Validation loss: 2.315564659939673

Epoch: 5| Step: 5
Training loss: 0.6946171058479429
Validation loss: 2.2040983453001695

Epoch: 5| Step: 6
Training loss: 0.8134504774291649
Validation loss: 2.2209202252487232

Epoch: 5| Step: 7
Training loss: 0.62854872782931
Validation loss: 2.2253991631847523

Epoch: 5| Step: 8
Training loss: 0.9571899905220632
Validation loss: 2.2483806810413873

Epoch: 5| Step: 9
Training loss: 0.8078563110158882
Validation loss: 2.193974634049567

Epoch: 5| Step: 10
Training loss: 0.7326844011927995
Validation loss: 2.3097237845463305

Epoch: 500| Step: 0
Training loss: 0.9911213651126904
Validation loss: 2.2275115849582092

Epoch: 5| Step: 1
Training loss: 0.7396150277738612
Validation loss: 2.3213370185340945

Epoch: 5| Step: 2
Training loss: 0.7609856231950537
Validation loss: 2.2774050753279496

Epoch: 5| Step: 3
Training loss: 0.7924402289007734
Validation loss: 2.226590427928037

Epoch: 5| Step: 4
Training loss: 0.8602648895979443
Validation loss: 2.23020098977851

Epoch: 5| Step: 5
Training loss: 0.6957069306909394
Validation loss: 2.2643601787631944

Epoch: 5| Step: 6
Training loss: 0.7493239773393044
Validation loss: 2.26060201165627

Epoch: 5| Step: 7
Training loss: 0.6327493188659185
Validation loss: 2.200547731432587

Epoch: 5| Step: 8
Training loss: 0.8769402449921521
Validation loss: 2.3035623219340855

Epoch: 5| Step: 9
Training loss: 1.6458537748330877
Validation loss: 2.37177448009174

Epoch: 5| Step: 10
Training loss: 0.7578608310664161
Validation loss: 2.270398403023183

Epoch: 501| Step: 0
Training loss: 1.5583849315294713
Validation loss: 2.244472638498357

Epoch: 5| Step: 1
Training loss: 0.6299914599021457
Validation loss: 2.2632133811399906

Epoch: 5| Step: 2
Training loss: 0.8772334477017293
Validation loss: 2.308225035474965

Epoch: 5| Step: 3
Training loss: 0.4621606857950518
Validation loss: 2.2583078882071765

Epoch: 5| Step: 4
Training loss: 0.7629855454826842
Validation loss: 2.290728203666357

Epoch: 5| Step: 5
Training loss: 0.6267785991052145
Validation loss: 2.2872186721889154

Epoch: 5| Step: 6
Training loss: 0.7272890211713048
Validation loss: 2.237962676591428

Epoch: 5| Step: 7
Training loss: 0.8420653302361654
Validation loss: 2.2025517020529275

Epoch: 5| Step: 8
Training loss: 0.7385280539724703
Validation loss: 2.2453917519805717

Epoch: 5| Step: 9
Training loss: 0.9944889380241116
Validation loss: 2.2408762098738886

Epoch: 5| Step: 10
Training loss: 0.9947688847408035
Validation loss: 2.290439503865719

Epoch: 502| Step: 0
Training loss: 0.5683074612848779
Validation loss: 2.294971577270426

Epoch: 5| Step: 1
Training loss: 1.5628437427066826
Validation loss: 2.2991828912009105

Epoch: 5| Step: 2
Training loss: 0.7168565772033225
Validation loss: 2.2754978487567183

Epoch: 5| Step: 3
Training loss: 0.7693350294872386
Validation loss: 2.2858856745048173

Epoch: 5| Step: 4
Training loss: 0.5433360990890755
Validation loss: 2.239497623010208

Epoch: 5| Step: 5
Training loss: 1.0639455722640874
Validation loss: 2.278082376361538

Epoch: 5| Step: 6
Training loss: 0.60214658347756
Validation loss: 2.260565135380816

Epoch: 5| Step: 7
Training loss: 0.6770766306814363
Validation loss: 2.2715510291370795

Epoch: 5| Step: 8
Training loss: 0.9342594406982045
Validation loss: 2.268255943373024

Epoch: 5| Step: 9
Training loss: 0.9246520547883492
Validation loss: 2.3162967230106597

Epoch: 5| Step: 10
Training loss: 1.0243690269905867
Validation loss: 2.2564283578456257

Epoch: 503| Step: 0
Training loss: 0.9529286792121958
Validation loss: 2.2678207229956038

Epoch: 5| Step: 1
Training loss: 0.7205331493378627
Validation loss: 2.2541864903055457

Epoch: 5| Step: 2
Training loss: 0.8682367661266932
Validation loss: 2.2580194439103285

Epoch: 5| Step: 3
Training loss: 0.753656454655151
Validation loss: 2.3040568984283465

Epoch: 5| Step: 4
Training loss: 1.3555435467841261
Validation loss: 2.2939458422273282

Epoch: 5| Step: 5
Training loss: 0.8554847053886292
Validation loss: 2.2555768596841212

Epoch: 5| Step: 6
Training loss: 0.8892608367714333
Validation loss: 2.2270179724516663

Epoch: 5| Step: 7
Training loss: 0.997873130650366
Validation loss: 2.245475325942162

Epoch: 5| Step: 8
Training loss: 0.5296487237020935
Validation loss: 2.253690933285172

Epoch: 5| Step: 9
Training loss: 0.8477200251201367
Validation loss: 2.2878812907315265

Epoch: 5| Step: 10
Training loss: 0.9647786971799105
Validation loss: 2.228720287826858

Epoch: 504| Step: 0
Training loss: 0.9926072982230008
Validation loss: 2.3387235650260907

Epoch: 5| Step: 1
Training loss: 0.8699113150590755
Validation loss: 2.237086250482764

Epoch: 5| Step: 2
Training loss: 0.7527719770382413
Validation loss: 2.249920549380007

Epoch: 5| Step: 3
Training loss: 0.6983164074272131
Validation loss: 2.2538636747868774

Epoch: 5| Step: 4
Training loss: 1.4943849052250895
Validation loss: 2.2712651493487126

Epoch: 5| Step: 5
Training loss: 0.8218895783962621
Validation loss: 2.277316013332543

Epoch: 5| Step: 6
Training loss: 0.7705584800702611
Validation loss: 2.251228310576304

Epoch: 5| Step: 7
Training loss: 0.7728389774634963
Validation loss: 2.2842947116321266

Epoch: 5| Step: 8
Training loss: 0.6054839839864639
Validation loss: 2.261321863677669

Epoch: 5| Step: 9
Training loss: 0.9308660714264388
Validation loss: 2.2190608618960357

Epoch: 5| Step: 10
Training loss: 0.7712147688276579
Validation loss: 2.2471707260702725

Epoch: 505| Step: 0
Training loss: 0.7871266782008808
Validation loss: 2.2693002799416675

Epoch: 5| Step: 1
Training loss: 1.5856640208806778
Validation loss: 2.330569052316652

Epoch: 5| Step: 2
Training loss: 0.7354546584851441
Validation loss: 2.2892694499761626

Epoch: 5| Step: 3
Training loss: 1.001698601055511
Validation loss: 2.345065354168717

Epoch: 5| Step: 4
Training loss: 0.8895565785323704
Validation loss: 2.418065420197636

Epoch: 5| Step: 5
Training loss: 0.8261773580454874
Validation loss: 2.3392727797016644

Epoch: 5| Step: 6
Training loss: 0.735329839175313
Validation loss: 2.2764407056576967

Epoch: 5| Step: 7
Training loss: 0.9210394612783279
Validation loss: 2.263110474701587

Epoch: 5| Step: 8
Training loss: 0.5288290229436955
Validation loss: 2.296046922741981

Epoch: 5| Step: 9
Training loss: 0.7131999977520458
Validation loss: 2.275410941231005

Epoch: 5| Step: 10
Training loss: 0.8525438516139291
Validation loss: 2.2517598572109896

Epoch: 506| Step: 0
Training loss: 0.9054421737759872
Validation loss: 2.2344770166565806

Epoch: 5| Step: 1
Training loss: 0.8935539870962931
Validation loss: 2.2276768709261168

Epoch: 5| Step: 2
Training loss: 0.8926574538222946
Validation loss: 2.3249625407295427

Epoch: 5| Step: 3
Training loss: 0.5595352667840388
Validation loss: 2.2988187328121703

Epoch: 5| Step: 4
Training loss: 1.0322499484586252
Validation loss: 2.280213658211793

Epoch: 5| Step: 5
Training loss: 0.9327516468844346
Validation loss: 2.3097486893854935

Epoch: 5| Step: 6
Training loss: 0.75806017888667
Validation loss: 2.2795825606318405

Epoch: 5| Step: 7
Training loss: 1.4054240026130804
Validation loss: 2.201257506338163

Epoch: 5| Step: 8
Training loss: 0.8116331978763868
Validation loss: 2.290093630640772

Epoch: 5| Step: 9
Training loss: 0.8168623530861643
Validation loss: 2.297920826620038

Epoch: 5| Step: 10
Training loss: 0.5786817035378565
Validation loss: 2.308651941046087

Epoch: 507| Step: 0
Training loss: 0.7478654208110965
Validation loss: 2.270725842276539

Epoch: 5| Step: 1
Training loss: 1.3866715544070398
Validation loss: 2.286975320487392

Epoch: 5| Step: 2
Training loss: 0.7727982162099593
Validation loss: 2.3410578841728458

Epoch: 5| Step: 3
Training loss: 0.9631785490384848
Validation loss: 2.3584563752790055

Epoch: 5| Step: 4
Training loss: 0.8599928628824961
Validation loss: 2.3200936831439076

Epoch: 5| Step: 5
Training loss: 0.7411908736296515
Validation loss: 2.3256826132387936

Epoch: 5| Step: 6
Training loss: 0.6318200181609414
Validation loss: 2.3446261501335908

Epoch: 5| Step: 7
Training loss: 0.7546613005519233
Validation loss: 2.3562080465083985

Epoch: 5| Step: 8
Training loss: 0.8177255802805934
Validation loss: 2.285742078751689

Epoch: 5| Step: 9
Training loss: 0.9794423479538716
Validation loss: 2.31608494677288

Epoch: 5| Step: 10
Training loss: 0.6503555700804272
Validation loss: 2.257694757236269

Epoch: 508| Step: 0
Training loss: 1.0184326098717675
Validation loss: 2.288057969149857

Epoch: 5| Step: 1
Training loss: 0.4927969444253324
Validation loss: 2.224111825821408

Epoch: 5| Step: 2
Training loss: 1.5322334090031868
Validation loss: 2.263237677228596

Epoch: 5| Step: 3
Training loss: 0.8046333887369037
Validation loss: 2.2409135348463387

Epoch: 5| Step: 4
Training loss: 0.8615870011048622
Validation loss: 2.26891013938257

Epoch: 5| Step: 5
Training loss: 0.9137147421238015
Validation loss: 2.248587436105444

Epoch: 5| Step: 6
Training loss: 0.865252768017503
Validation loss: 2.247305084492573

Epoch: 5| Step: 7
Training loss: 0.5930082305510711
Validation loss: 2.237574145743675

Epoch: 5| Step: 8
Training loss: 0.8733229915234675
Validation loss: 2.3037499430044397

Epoch: 5| Step: 9
Training loss: 0.8893805057465126
Validation loss: 2.2153718851889366

Epoch: 5| Step: 10
Training loss: 0.857621085067507
Validation loss: 2.3107756460680515

Epoch: 509| Step: 0
Training loss: 0.9404625495722728
Validation loss: 2.3065118970392464

Epoch: 5| Step: 1
Training loss: 0.8755365157363374
Validation loss: 2.299789159383718

Epoch: 5| Step: 2
Training loss: 0.5550439790535739
Validation loss: 2.1980495236795603

Epoch: 5| Step: 3
Training loss: 0.6219783936623893
Validation loss: 2.319031740715516

Epoch: 5| Step: 4
Training loss: 0.6793577336957193
Validation loss: 2.3012173954799997

Epoch: 5| Step: 5
Training loss: 0.6589869238550339
Validation loss: 2.2714131049720394

Epoch: 5| Step: 6
Training loss: 0.7371695489383623
Validation loss: 2.31231267536756

Epoch: 5| Step: 7
Training loss: 0.7215817272718943
Validation loss: 2.2499025465028866

Epoch: 5| Step: 8
Training loss: 0.8327341826582104
Validation loss: 2.154313736223927

Epoch: 5| Step: 9
Training loss: 0.7332637576852246
Validation loss: 2.2871582348852675

Epoch: 5| Step: 10
Training loss: 1.602417880258774
Validation loss: 2.2382355679452846

Epoch: 510| Step: 0
Training loss: 0.674043350124558
Validation loss: 2.2992490735233755

Epoch: 5| Step: 1
Training loss: 0.5896950591168378
Validation loss: 2.304870816200639

Epoch: 5| Step: 2
Training loss: 0.8055095732562226
Validation loss: 2.2382770854625798

Epoch: 5| Step: 3
Training loss: 0.8541142439843973
Validation loss: 2.2705505295094977

Epoch: 5| Step: 4
Training loss: 1.6579547961230876
Validation loss: 2.2971955673439015

Epoch: 5| Step: 5
Training loss: 0.7388097496204187
Validation loss: 2.263710550030949

Epoch: 5| Step: 6
Training loss: 0.8571386890650633
Validation loss: 2.2910916780776462

Epoch: 5| Step: 7
Training loss: 0.8388536516547452
Validation loss: 2.271531568845736

Epoch: 5| Step: 8
Training loss: 0.5710129812505337
Validation loss: 2.2783254413051117

Epoch: 5| Step: 9
Training loss: 0.7788662975782004
Validation loss: 2.2520653145548613

Epoch: 5| Step: 10
Training loss: 0.8188860889348414
Validation loss: 2.3152773064853354

Epoch: 511| Step: 0
Training loss: 0.690947817100402
Validation loss: 2.2404591852140805

Epoch: 5| Step: 1
Training loss: 0.5137127762092182
Validation loss: 2.3175326634847373

Epoch: 5| Step: 2
Training loss: 1.0732754536437634
Validation loss: 2.2530201726184163

Epoch: 5| Step: 3
Training loss: 1.0241541209951412
Validation loss: 2.3161992204638344

Epoch: 5| Step: 4
Training loss: 0.7600804635167894
Validation loss: 2.2307320328358857

Epoch: 5| Step: 5
Training loss: 1.4591008028814734
Validation loss: 2.2644662645685543

Epoch: 5| Step: 6
Training loss: 0.8268154874853346
Validation loss: 2.338832722462031

Epoch: 5| Step: 7
Training loss: 0.5586552619411085
Validation loss: 2.2160413593637918

Epoch: 5| Step: 8
Training loss: 0.7450489497904975
Validation loss: 2.3168084136270393

Epoch: 5| Step: 9
Training loss: 0.7221689591778199
Validation loss: 2.3045516168530207

Epoch: 5| Step: 10
Training loss: 0.8737152408676875
Validation loss: 2.2495269147005215

Epoch: 512| Step: 0
Training loss: 0.49277417473543217
Validation loss: 2.2610393449271444

Epoch: 5| Step: 1
Training loss: 0.7617944141857159
Validation loss: 2.3244933329723927

Epoch: 5| Step: 2
Training loss: 0.8100396465088411
Validation loss: 2.282859385135995

Epoch: 5| Step: 3
Training loss: 0.79150435808323
Validation loss: 2.3080903480215142

Epoch: 5| Step: 4
Training loss: 1.5014041050976912
Validation loss: 2.3115525293245742

Epoch: 5| Step: 5
Training loss: 1.1648882810701517
Validation loss: 2.315402564295689

Epoch: 5| Step: 6
Training loss: 0.5811230274691288
Validation loss: 2.2941416837609014

Epoch: 5| Step: 7
Training loss: 0.6947488321676799
Validation loss: 2.3366661536271893

Epoch: 5| Step: 8
Training loss: 0.6102299683567669
Validation loss: 2.332740415737723

Epoch: 5| Step: 9
Training loss: 0.688159279727377
Validation loss: 2.2628150858778358

Epoch: 5| Step: 10
Training loss: 1.0084989117534706
Validation loss: 2.33332347062073

Epoch: 513| Step: 0
Training loss: 0.571694802207265
Validation loss: 2.275275733255072

Epoch: 5| Step: 1
Training loss: 0.7684376492990765
Validation loss: 2.3511638440395073

Epoch: 5| Step: 2
Training loss: 0.6815647859110884
Validation loss: 2.2280577748947836

Epoch: 5| Step: 3
Training loss: 0.8258587399362012
Validation loss: 2.2699273164684746

Epoch: 5| Step: 4
Training loss: 0.9069150260436786
Validation loss: 2.2621778924340274

Epoch: 5| Step: 5
Training loss: 0.9481104278953411
Validation loss: 2.280375156837774

Epoch: 5| Step: 6
Training loss: 0.819587532489093
Validation loss: 2.2771592895796036

Epoch: 5| Step: 7
Training loss: 0.8820125364982632
Validation loss: 2.2976293842252

Epoch: 5| Step: 8
Training loss: 0.8101870921783609
Validation loss: 2.265231351278856

Epoch: 5| Step: 9
Training loss: 1.5182226670542112
Validation loss: 2.287669425592625

Epoch: 5| Step: 10
Training loss: 0.6396572199793664
Validation loss: 2.3012332047205186

Epoch: 514| Step: 0
Training loss: 0.7704486316536806
Validation loss: 2.2390303020278846

Epoch: 5| Step: 1
Training loss: 0.9141097097350431
Validation loss: 2.2873748636135587

Epoch: 5| Step: 2
Training loss: 0.662439449710174
Validation loss: 2.295148949735535

Epoch: 5| Step: 3
Training loss: 0.7800218083316203
Validation loss: 2.259690696425689

Epoch: 5| Step: 4
Training loss: 1.3614813172497644
Validation loss: 2.288096351875215

Epoch: 5| Step: 5
Training loss: 1.007869866682755
Validation loss: 2.3226258191320994

Epoch: 5| Step: 6
Training loss: 0.6049841387301038
Validation loss: 2.2454161204529974

Epoch: 5| Step: 7
Training loss: 0.6560718885042349
Validation loss: 2.309068223124743

Epoch: 5| Step: 8
Training loss: 0.8489266996204267
Validation loss: 2.2334328961513923

Epoch: 5| Step: 9
Training loss: 0.9044367968279939
Validation loss: 2.2411259965490404

Epoch: 5| Step: 10
Training loss: 0.7255469577428204
Validation loss: 2.3722909946730115

Epoch: 515| Step: 0
Training loss: 0.6394525359004808
Validation loss: 2.3512670235737385

Epoch: 5| Step: 1
Training loss: 0.8198864875124776
Validation loss: 2.30763735332375

Epoch: 5| Step: 2
Training loss: 0.7247445939156166
Validation loss: 2.3317329533523563

Epoch: 5| Step: 3
Training loss: 1.0272765627165659
Validation loss: 2.302298370468294

Epoch: 5| Step: 4
Training loss: 0.7306174876509688
Validation loss: 2.32246059239337

Epoch: 5| Step: 5
Training loss: 0.8200869295516692
Validation loss: 2.3161404198846394

Epoch: 5| Step: 6
Training loss: 0.7807356858103243
Validation loss: 2.3174361067803533

Epoch: 5| Step: 7
Training loss: 0.5288077483870494
Validation loss: 2.198289495993834

Epoch: 5| Step: 8
Training loss: 0.7371034056922652
Validation loss: 2.31337733367531

Epoch: 5| Step: 9
Training loss: 0.6658593047483381
Validation loss: 2.2612713027535025

Epoch: 5| Step: 10
Training loss: 1.706566788885081
Validation loss: 2.2710704376750064

Epoch: 516| Step: 0
Training loss: 0.9181712475081494
Validation loss: 2.267535964771593

Epoch: 5| Step: 1
Training loss: 0.6668147329968288
Validation loss: 2.246017833423672

Epoch: 5| Step: 2
Training loss: 1.4470090239638242
Validation loss: 2.2493843377976916

Epoch: 5| Step: 3
Training loss: 0.56453939128446
Validation loss: 2.23749190364731

Epoch: 5| Step: 4
Training loss: 0.8936224573002887
Validation loss: 2.3231872718452324

Epoch: 5| Step: 5
Training loss: 0.7405777187787752
Validation loss: 2.242313327312213

Epoch: 5| Step: 6
Training loss: 0.6093468048224155
Validation loss: 2.264935773852385

Epoch: 5| Step: 7
Training loss: 0.6969087686610783
Validation loss: 2.301325291861186

Epoch: 5| Step: 8
Training loss: 0.7018182479523818
Validation loss: 2.2781388524905366

Epoch: 5| Step: 9
Training loss: 0.9428784583982995
Validation loss: 2.354982377615951

Epoch: 5| Step: 10
Training loss: 0.7591822721075682
Validation loss: 2.298492057462136

Epoch: 517| Step: 0
Training loss: 0.9602475984975852
Validation loss: 2.3513096875276642

Epoch: 5| Step: 1
Training loss: 0.8005816699414725
Validation loss: 2.274803006102596

Epoch: 5| Step: 2
Training loss: 0.7683492965308761
Validation loss: 2.2661355404838277

Epoch: 5| Step: 3
Training loss: 0.8814190357500166
Validation loss: 2.296014687291653

Epoch: 5| Step: 4
Training loss: 0.69291004074134
Validation loss: 2.3285892450678247

Epoch: 5| Step: 5
Training loss: 0.8804781949637598
Validation loss: 2.2932598255383714

Epoch: 5| Step: 6
Training loss: 0.554105587750707
Validation loss: 2.267706533006385

Epoch: 5| Step: 7
Training loss: 0.8672367116350462
Validation loss: 2.201824883601252

Epoch: 5| Step: 8
Training loss: 1.5887148736631707
Validation loss: 2.261281534521961

Epoch: 5| Step: 9
Training loss: 0.5090261774470194
Validation loss: 2.274088837402007

Epoch: 5| Step: 10
Training loss: 0.573006888712672
Validation loss: 2.2292126189003634

Epoch: 518| Step: 0
Training loss: 0.8233337351441529
Validation loss: 2.251063856470193

Epoch: 5| Step: 1
Training loss: 0.5752991354331263
Validation loss: 2.3283184483458905

Epoch: 5| Step: 2
Training loss: 0.6063309467978938
Validation loss: 2.3363177156435846

Epoch: 5| Step: 3
Training loss: 0.7499430555342431
Validation loss: 2.2818840023527653

Epoch: 5| Step: 4
Training loss: 0.8814719833643082
Validation loss: 2.3182784622386916

Epoch: 5| Step: 5
Training loss: 0.6788976618286137
Validation loss: 2.3232211639912825

Epoch: 5| Step: 6
Training loss: 1.522611736588395
Validation loss: 2.2541846575784925

Epoch: 5| Step: 7
Training loss: 0.7819464059206217
Validation loss: 2.2561920194925453

Epoch: 5| Step: 8
Training loss: 0.9269925655264395
Validation loss: 2.2678202821230364

Epoch: 5| Step: 9
Training loss: 0.8548190641525607
Validation loss: 2.2122465390905512

Epoch: 5| Step: 10
Training loss: 0.6797093574254149
Validation loss: 2.222792164033569

Epoch: 519| Step: 0
Training loss: 0.8075238211929902
Validation loss: 2.2609709301199783

Epoch: 5| Step: 1
Training loss: 0.6960118880339119
Validation loss: 2.280312250306827

Epoch: 5| Step: 2
Training loss: 0.9114181873017843
Validation loss: 2.2016022012209233

Epoch: 5| Step: 3
Training loss: 1.0724556064976887
Validation loss: 2.198691818451686

Epoch: 5| Step: 4
Training loss: 0.840298906346147
Validation loss: 2.1981835927591504

Epoch: 5| Step: 5
Training loss: 0.7835142511752666
Validation loss: 2.251614857055555

Epoch: 5| Step: 6
Training loss: 0.7731437125134804
Validation loss: 2.2103674102277915

Epoch: 5| Step: 7
Training loss: 0.8379733527187115
Validation loss: 2.2058932668812834

Epoch: 5| Step: 8
Training loss: 0.7995941667550086
Validation loss: 2.284170469651186

Epoch: 5| Step: 9
Training loss: 0.8400352791916301
Validation loss: 2.30362535532189

Epoch: 5| Step: 10
Training loss: 1.4788981538723271
Validation loss: 2.2731214723077495

Epoch: 520| Step: 0
Training loss: 0.7644856597573361
Validation loss: 2.241271882892174

Epoch: 5| Step: 1
Training loss: 0.7526017599276347
Validation loss: 2.263934724788598

Epoch: 5| Step: 2
Training loss: 0.6486530635053621
Validation loss: 2.1980843627046682

Epoch: 5| Step: 3
Training loss: 0.6071640645057875
Validation loss: 2.3009602363749306

Epoch: 5| Step: 4
Training loss: 1.1159277796261866
Validation loss: 2.1999582772386446

Epoch: 5| Step: 5
Training loss: 0.7428165781360933
Validation loss: 2.261448942352668

Epoch: 5| Step: 6
Training loss: 0.6743620595317978
Validation loss: 2.3062939878632323

Epoch: 5| Step: 7
Training loss: 1.4324763878279356
Validation loss: 2.2933709982361514

Epoch: 5| Step: 8
Training loss: 0.8871262072129923
Validation loss: 2.2831267962343937

Epoch: 5| Step: 9
Training loss: 0.5579743051799867
Validation loss: 2.311837684351419

Epoch: 5| Step: 10
Training loss: 0.6866977519187276
Validation loss: 2.2517951221379415

Epoch: 521| Step: 0
Training loss: 1.5179469618949064
Validation loss: 2.3064447515867363

Epoch: 5| Step: 1
Training loss: 0.7329517126532687
Validation loss: 2.2075403339100346

Epoch: 5| Step: 2
Training loss: 0.7635641583039604
Validation loss: 2.245791953535878

Epoch: 5| Step: 3
Training loss: 0.7715483433725256
Validation loss: 2.3019378939858597

Epoch: 5| Step: 4
Training loss: 0.6723804125407523
Validation loss: 2.24495152860516

Epoch: 5| Step: 5
Training loss: 0.8009050227087389
Validation loss: 2.281024720017918

Epoch: 5| Step: 6
Training loss: 0.7372164035514153
Validation loss: 2.303920852350638

Epoch: 5| Step: 7
Training loss: 0.7962108537162703
Validation loss: 2.3187120865988056

Epoch: 5| Step: 8
Training loss: 0.8201855152480809
Validation loss: 2.2971663595436542

Epoch: 5| Step: 9
Training loss: 0.7467361001814556
Validation loss: 2.2977993664714744

Epoch: 5| Step: 10
Training loss: 0.5365659704523822
Validation loss: 2.2930047015505908

Epoch: 522| Step: 0
Training loss: 1.3810880868180422
Validation loss: 2.2727255597858553

Epoch: 5| Step: 1
Training loss: 0.639207644406908
Validation loss: 2.266072934417247

Epoch: 5| Step: 2
Training loss: 0.915856516344776
Validation loss: 2.250877003221636

Epoch: 5| Step: 3
Training loss: 0.6234855901005891
Validation loss: 2.158989602008589

Epoch: 5| Step: 4
Training loss: 0.7516635089337094
Validation loss: 2.258981832176309

Epoch: 5| Step: 5
Training loss: 0.9745753708528142
Validation loss: 2.2886585771120975

Epoch: 5| Step: 6
Training loss: 0.8355076834612427
Validation loss: 2.2098576661048943

Epoch: 5| Step: 7
Training loss: 0.8836486704898214
Validation loss: 2.2679148168056797

Epoch: 5| Step: 8
Training loss: 0.6839264632217088
Validation loss: 2.217625145806171

Epoch: 5| Step: 9
Training loss: 0.839874125086605
Validation loss: 2.3182597215247673

Epoch: 5| Step: 10
Training loss: 0.6164311953913274
Validation loss: 2.304983871311353

Epoch: 523| Step: 0
Training loss: 1.5149884017651456
Validation loss: 2.2491192364237733

Epoch: 5| Step: 1
Training loss: 0.9629563933964187
Validation loss: 2.2825409561055507

Epoch: 5| Step: 2
Training loss: 0.5019438924571182
Validation loss: 2.2635556420793312

Epoch: 5| Step: 3
Training loss: 0.7814851407000906
Validation loss: 2.3033545748170137

Epoch: 5| Step: 4
Training loss: 0.8718489037986987
Validation loss: 2.280081686491644

Epoch: 5| Step: 5
Training loss: 0.7892523433323058
Validation loss: 2.2459665033607266

Epoch: 5| Step: 6
Training loss: 0.7329883876781045
Validation loss: 2.423436203960469

Epoch: 5| Step: 7
Training loss: 0.5862913462001993
Validation loss: 2.2508039234646406

Epoch: 5| Step: 8
Training loss: 0.69044833448122
Validation loss: 2.200832864465951

Epoch: 5| Step: 9
Training loss: 0.8973189979525725
Validation loss: 2.2824401080174392

Epoch: 5| Step: 10
Training loss: 0.7410218974055623
Validation loss: 2.3063709082274784

Epoch: 524| Step: 0
Training loss: 1.4967146498897443
Validation loss: 2.2866188744364835

Epoch: 5| Step: 1
Training loss: 0.866073098553268
Validation loss: 2.2544962930197796

Epoch: 5| Step: 2
Training loss: 0.6415833074332941
Validation loss: 2.254466936849293

Epoch: 5| Step: 3
Training loss: 0.6356578014991159
Validation loss: 2.273674593984367

Epoch: 5| Step: 4
Training loss: 0.732774491941026
Validation loss: 2.2608398388060524

Epoch: 5| Step: 5
Training loss: 0.6814911249384716
Validation loss: 2.315028544573146

Epoch: 5| Step: 6
Training loss: 0.610359228467483
Validation loss: 2.258082244311968

Epoch: 5| Step: 7
Training loss: 0.9303918942884781
Validation loss: 2.2641220635358565

Epoch: 5| Step: 8
Training loss: 0.9436463734910551
Validation loss: 2.2263818385100858

Epoch: 5| Step: 9
Training loss: 0.6478127376778623
Validation loss: 2.352681285858912

Epoch: 5| Step: 10
Training loss: 0.6700439341929597
Validation loss: 2.3461656783697493

Epoch: 525| Step: 0
Training loss: 0.6931008730129808
Validation loss: 2.3947037350983478

Epoch: 5| Step: 1
Training loss: 1.0698949180234887
Validation loss: 2.309178237850817

Epoch: 5| Step: 2
Training loss: 0.6870288318056186
Validation loss: 2.3695912459060375

Epoch: 5| Step: 3
Training loss: 0.769263128828769
Validation loss: 2.4097542610255767

Epoch: 5| Step: 4
Training loss: 0.6862916514432351
Validation loss: 2.3065388747113267

Epoch: 5| Step: 5
Training loss: 0.7027517811695978
Validation loss: 2.325703029171533

Epoch: 5| Step: 6
Training loss: 0.8166025464194099
Validation loss: 2.260279972333718

Epoch: 5| Step: 7
Training loss: 1.0344172304873531
Validation loss: 2.266429159542648

Epoch: 5| Step: 8
Training loss: 0.48603200514808376
Validation loss: 2.2910720430376132

Epoch: 5| Step: 9
Training loss: 0.6767221857026425
Validation loss: 2.214809330863085

Epoch: 5| Step: 10
Training loss: 1.4920224403043763
Validation loss: 2.311785048913891

Epoch: 526| Step: 0
Training loss: 0.5244841573175346
Validation loss: 2.302879417087884

Epoch: 5| Step: 1
Training loss: 0.7432587371553856
Validation loss: 2.2280768727500475

Epoch: 5| Step: 2
Training loss: 0.7823899535410767
Validation loss: 2.253797902913044

Epoch: 5| Step: 3
Training loss: 0.5972832656560491
Validation loss: 2.2458395383129925

Epoch: 5| Step: 4
Training loss: 0.5887855992012562
Validation loss: 2.2659020751987327

Epoch: 5| Step: 5
Training loss: 0.9615668430174502
Validation loss: 2.2669601811677738

Epoch: 5| Step: 6
Training loss: 0.6627502040913087
Validation loss: 2.3102668693303317

Epoch: 5| Step: 7
Training loss: 1.0087097668571727
Validation loss: 2.2884886070985098

Epoch: 5| Step: 8
Training loss: 0.7239845646192855
Validation loss: 2.32848341575813

Epoch: 5| Step: 9
Training loss: 1.3458440122781046
Validation loss: 2.3065411043120005

Epoch: 5| Step: 10
Training loss: 0.8931309430062793
Validation loss: 2.307879421662874

Epoch: 527| Step: 0
Training loss: 0.7366573902843526
Validation loss: 2.32314794437421

Epoch: 5| Step: 1
Training loss: 0.8140934943743886
Validation loss: 2.2485174566762343

Epoch: 5| Step: 2
Training loss: 0.7124892685734546
Validation loss: 2.23729220216152

Epoch: 5| Step: 3
Training loss: 0.7241073473334885
Validation loss: 2.2811633723060054

Epoch: 5| Step: 4
Training loss: 0.6919843336796101
Validation loss: 2.2925614348823293

Epoch: 5| Step: 5
Training loss: 0.7456033902741986
Validation loss: 2.275583500199973

Epoch: 5| Step: 6
Training loss: 1.5314263222831404
Validation loss: 2.252133894600527

Epoch: 5| Step: 7
Training loss: 0.7376199818660082
Validation loss: 2.189911173588044

Epoch: 5| Step: 8
Training loss: 0.789318345393418
Validation loss: 2.2797960499121737

Epoch: 5| Step: 9
Training loss: 0.7530169603405872
Validation loss: 2.3129554974518154

Epoch: 5| Step: 10
Training loss: 0.6902199821936128
Validation loss: 2.2804187019132374

Epoch: 528| Step: 0
Training loss: 0.9086314514157834
Validation loss: 2.2445121834599027

Epoch: 5| Step: 1
Training loss: 0.6320096798529722
Validation loss: 2.305087910125053

Epoch: 5| Step: 2
Training loss: 0.5673380586238346
Validation loss: 2.3019239917764334

Epoch: 5| Step: 3
Training loss: 0.7912735506744287
Validation loss: 2.2946620948951506

Epoch: 5| Step: 4
Training loss: 0.754514656255708
Validation loss: 2.2611951451974295

Epoch: 5| Step: 5
Training loss: 1.069169596794159
Validation loss: 2.2624016609818507

Epoch: 5| Step: 6
Training loss: 0.6513807303923825
Validation loss: 2.2482903638226843

Epoch: 5| Step: 7
Training loss: 0.472330122740707
Validation loss: 2.246324768313035

Epoch: 5| Step: 8
Training loss: 1.5374991130050955
Validation loss: 2.286117266652982

Epoch: 5| Step: 9
Training loss: 0.833099109793968
Validation loss: 2.298867926507136

Epoch: 5| Step: 10
Training loss: 0.701130836582221
Validation loss: 2.2449993966954565

Epoch: 529| Step: 0
Training loss: 0.9793944229215683
Validation loss: 2.2591092785207385

Epoch: 5| Step: 1
Training loss: 1.41813646065598
Validation loss: 2.2203331186499717

Epoch: 5| Step: 2
Training loss: 0.846740826046006
Validation loss: 2.274227195612437

Epoch: 5| Step: 3
Training loss: 0.7236197157690092
Validation loss: 2.2467929265846474

Epoch: 5| Step: 4
Training loss: 0.5845076089221801
Validation loss: 2.236306417391827

Epoch: 5| Step: 5
Training loss: 0.6328565794109751
Validation loss: 2.3344849628250968

Epoch: 5| Step: 6
Training loss: 0.6631060050882861
Validation loss: 2.2994407295971735

Epoch: 5| Step: 7
Training loss: 0.5316318093605322
Validation loss: 2.3421675384368528

Epoch: 5| Step: 8
Training loss: 0.7834048498933133
Validation loss: 2.2673758672477273

Epoch: 5| Step: 9
Training loss: 0.7835816493673654
Validation loss: 2.300806729365243

Epoch: 5| Step: 10
Training loss: 0.7197202270725868
Validation loss: 2.3708921743715536

Epoch: 530| Step: 0
Training loss: 0.5648860393221236
Validation loss: 2.3195149991008965

Epoch: 5| Step: 1
Training loss: 0.6901906421150799
Validation loss: 2.273498212965465

Epoch: 5| Step: 2
Training loss: 0.8145575513605252
Validation loss: 2.3935348706662176

Epoch: 5| Step: 3
Training loss: 0.6287485955755425
Validation loss: 2.2909135472193096

Epoch: 5| Step: 4
Training loss: 0.6229389539663195
Validation loss: 2.277038062890752

Epoch: 5| Step: 5
Training loss: 1.4692573482737947
Validation loss: 2.286426822503991

Epoch: 5| Step: 6
Training loss: 0.9329156368114199
Validation loss: 2.2470721698540874

Epoch: 5| Step: 7
Training loss: 0.71595652534585
Validation loss: 2.233756548512035

Epoch: 5| Step: 8
Training loss: 0.7367903981001479
Validation loss: 2.302340954733302

Epoch: 5| Step: 9
Training loss: 0.854237231774565
Validation loss: 2.274115008700035

Epoch: 5| Step: 10
Training loss: 0.9914925010924668
Validation loss: 2.31876876333013

Epoch: 531| Step: 0
Training loss: 1.0194679328286784
Validation loss: 2.2628230912392993

Epoch: 5| Step: 1
Training loss: 0.7884548604764715
Validation loss: 2.2721405603729217

Epoch: 5| Step: 2
Training loss: 0.7951287977382505
Validation loss: 2.255906130916959

Epoch: 5| Step: 3
Training loss: 0.9509165771770048
Validation loss: 2.291175911860704

Epoch: 5| Step: 4
Training loss: 0.8549265079255979
Validation loss: 2.2493685641879075

Epoch: 5| Step: 5
Training loss: 0.9412848366601625
Validation loss: 2.43509840364739

Epoch: 5| Step: 6
Training loss: 0.7977768899252381
Validation loss: 2.3896819465101817

Epoch: 5| Step: 7
Training loss: 1.482295939407392
Validation loss: 2.398303088914232

Epoch: 5| Step: 8
Training loss: 0.9111845240990158
Validation loss: 2.350076506998464

Epoch: 5| Step: 9
Training loss: 0.8324175014228796
Validation loss: 2.407706460340421

Epoch: 5| Step: 10
Training loss: 0.7445874412123025
Validation loss: 2.296503326165515

Epoch: 532| Step: 0
Training loss: 0.3933642283862819
Validation loss: 2.2560291181141348

Epoch: 5| Step: 1
Training loss: 1.3243580972727926
Validation loss: 2.333319125227439

Epoch: 5| Step: 2
Training loss: 0.7976811389234586
Validation loss: 2.239402546397885

Epoch: 5| Step: 3
Training loss: 0.6495547034769208
Validation loss: 2.234795528290185

Epoch: 5| Step: 4
Training loss: 0.7536297622229022
Validation loss: 2.2099424846843188

Epoch: 5| Step: 5
Training loss: 0.9973234178567404
Validation loss: 2.2894605244144297

Epoch: 5| Step: 6
Training loss: 1.0902804795141958
Validation loss: 2.260901051643143

Epoch: 5| Step: 7
Training loss: 0.6127865977165076
Validation loss: 2.2892998436498306

Epoch: 5| Step: 8
Training loss: 0.5569995726664221
Validation loss: 2.2961807468574382

Epoch: 5| Step: 9
Training loss: 1.0578185899747956
Validation loss: 2.2948702245174277

Epoch: 5| Step: 10
Training loss: 0.5695986264409826
Validation loss: 2.257823182035437

Epoch: 533| Step: 0
Training loss: 0.7719015031967223
Validation loss: 2.3141919126885377

Epoch: 5| Step: 1
Training loss: 0.9545373614389234
Validation loss: 2.391929020412156

Epoch: 5| Step: 2
Training loss: 0.6523514250343788
Validation loss: 2.252895942402302

Epoch: 5| Step: 3
Training loss: 1.02862712344123
Validation loss: 2.2813506411138573

Epoch: 5| Step: 4
Training loss: 0.5610369092151954
Validation loss: 2.267540111751133

Epoch: 5| Step: 5
Training loss: 0.6680227558991259
Validation loss: 2.2624408857651757

Epoch: 5| Step: 6
Training loss: 0.7006846145462947
Validation loss: 2.2753984148629

Epoch: 5| Step: 7
Training loss: 0.7189853117162722
Validation loss: 2.239907605866692

Epoch: 5| Step: 8
Training loss: 1.3921815540259528
Validation loss: 2.3113454571221017

Epoch: 5| Step: 9
Training loss: 0.7777535973112858
Validation loss: 2.248813714071915

Epoch: 5| Step: 10
Training loss: 0.718441316412786
Validation loss: 2.2653085387885774

Epoch: 534| Step: 0
Training loss: 0.8407477902494821
Validation loss: 2.2818994719954113

Epoch: 5| Step: 1
Training loss: 0.9387426088552652
Validation loss: 2.3094549487473044

Epoch: 5| Step: 2
Training loss: 0.6931704626489253
Validation loss: 2.319844645904053

Epoch: 5| Step: 3
Training loss: 0.7606084703641334
Validation loss: 2.292597569499871

Epoch: 5| Step: 4
Training loss: 0.7506091902161338
Validation loss: 2.223793830809686

Epoch: 5| Step: 5
Training loss: 0.6673544797613079
Validation loss: 2.2519497308350727

Epoch: 5| Step: 6
Training loss: 0.4996596906795108
Validation loss: 2.2363241832322447

Epoch: 5| Step: 7
Training loss: 0.6374060075320578
Validation loss: 2.321830322955816

Epoch: 5| Step: 8
Training loss: 1.0836583102465436
Validation loss: 2.244377306029077

Epoch: 5| Step: 9
Training loss: 1.3110613431393068
Validation loss: 2.2529537201192773

Epoch: 5| Step: 10
Training loss: 0.6392221442603137
Validation loss: 2.262957123022526

Epoch: 535| Step: 0
Training loss: 0.6614485061596342
Validation loss: 2.303402844139928

Epoch: 5| Step: 1
Training loss: 0.9634919368523307
Validation loss: 2.252512349544238

Epoch: 5| Step: 2
Training loss: 1.48659036856818
Validation loss: 2.230958943961876

Epoch: 5| Step: 3
Training loss: 0.804692722044361
Validation loss: 2.2002455093810345

Epoch: 5| Step: 4
Training loss: 0.6300478223784974
Validation loss: 2.2566995586842737

Epoch: 5| Step: 5
Training loss: 0.710066292985567
Validation loss: 2.243225778813782

Epoch: 5| Step: 6
Training loss: 0.5836837658279167
Validation loss: 2.239001898376281

Epoch: 5| Step: 7
Training loss: 0.6405544009501093
Validation loss: 2.285462797456538

Epoch: 5| Step: 8
Training loss: 0.875819775893529
Validation loss: 2.283099169124095

Epoch: 5| Step: 9
Training loss: 0.6771264551565032
Validation loss: 2.2924130291767955

Epoch: 5| Step: 10
Training loss: 0.7669159262881328
Validation loss: 2.268205914521181

Epoch: 536| Step: 0
Training loss: 0.4804791395103042
Validation loss: 2.289654979965585

Epoch: 5| Step: 1
Training loss: 1.4105617119920748
Validation loss: 2.2384192297089576

Epoch: 5| Step: 2
Training loss: 0.964811780145081
Validation loss: 2.2679698630058542

Epoch: 5| Step: 3
Training loss: 0.7544059480957499
Validation loss: 2.296913139401077

Epoch: 5| Step: 4
Training loss: 0.5199349061406234
Validation loss: 2.196721556325031

Epoch: 5| Step: 5
Training loss: 0.7975147521588809
Validation loss: 2.2771663708912175

Epoch: 5| Step: 6
Training loss: 0.5215137201974966
Validation loss: 2.2560402497797267

Epoch: 5| Step: 7
Training loss: 0.904642191594009
Validation loss: 2.2772868027296007

Epoch: 5| Step: 8
Training loss: 0.8304342067133841
Validation loss: 2.2705874699911575

Epoch: 5| Step: 9
Training loss: 1.0207571208816657
Validation loss: 2.2979787011243107

Epoch: 5| Step: 10
Training loss: 0.6427560345482541
Validation loss: 2.268419854050343

Epoch: 537| Step: 0
Training loss: 0.8419849867082561
Validation loss: 2.2777445436653125

Epoch: 5| Step: 1
Training loss: 0.6550806390103328
Validation loss: 2.328623727953031

Epoch: 5| Step: 2
Training loss: 0.7147211271914229
Validation loss: 2.325066428724642

Epoch: 5| Step: 3
Training loss: 1.365223634865882
Validation loss: 2.245266760000567

Epoch: 5| Step: 4
Training loss: 0.8145680883855873
Validation loss: 2.322861261938066

Epoch: 5| Step: 5
Training loss: 0.9833951342014872
Validation loss: 2.3151682238294864

Epoch: 5| Step: 6
Training loss: 0.7003066906737003
Validation loss: 2.307836811291623

Epoch: 5| Step: 7
Training loss: 0.8182517552227305
Validation loss: 2.237412588355621

Epoch: 5| Step: 8
Training loss: 0.7725107053984036
Validation loss: 2.2194642542577103

Epoch: 5| Step: 9
Training loss: 0.46631514459771944
Validation loss: 2.260214450123804

Epoch: 5| Step: 10
Training loss: 0.5593352031936051
Validation loss: 2.267827511291883

Epoch: 538| Step: 0
Training loss: 0.8090356549892308
Validation loss: 2.244696918029051

Epoch: 5| Step: 1
Training loss: 1.4725301268625448
Validation loss: 2.2324601026770323

Epoch: 5| Step: 2
Training loss: 0.6940636939425378
Validation loss: 2.302552641185476

Epoch: 5| Step: 3
Training loss: 0.7268713428014985
Validation loss: 2.2655315273806296

Epoch: 5| Step: 4
Training loss: 0.6355210255041761
Validation loss: 2.2564421245307993

Epoch: 5| Step: 5
Training loss: 0.7493938539756413
Validation loss: 2.298284784834464

Epoch: 5| Step: 6
Training loss: 0.7862800412890231
Validation loss: 2.210418192606902

Epoch: 5| Step: 7
Training loss: 0.4768236726608686
Validation loss: 2.244304961583055

Epoch: 5| Step: 8
Training loss: 0.7645362586584942
Validation loss: 2.2476253489048177

Epoch: 5| Step: 9
Training loss: 0.6883015944627447
Validation loss: 2.2794171324162726

Epoch: 5| Step: 10
Training loss: 0.5430221531355134
Validation loss: 2.2824729061141635

Epoch: 539| Step: 0
Training loss: 0.6597827554560101
Validation loss: 2.2016759019619037

Epoch: 5| Step: 1
Training loss: 0.7713631063832329
Validation loss: 2.2619486796803057

Epoch: 5| Step: 2
Training loss: 0.6556746367510066
Validation loss: 2.2065238117371013

Epoch: 5| Step: 3
Training loss: 0.7493265227608457
Validation loss: 2.201111658948356

Epoch: 5| Step: 4
Training loss: 1.4004804297771685
Validation loss: 2.2234075923463026

Epoch: 5| Step: 5
Training loss: 0.5062830855307627
Validation loss: 2.289499015755562

Epoch: 5| Step: 6
Training loss: 0.9348006487803724
Validation loss: 2.27054792697105

Epoch: 5| Step: 7
Training loss: 0.8302595591007733
Validation loss: 2.2155464615718703

Epoch: 5| Step: 8
Training loss: 0.6894082333049601
Validation loss: 2.2613838213188555

Epoch: 5| Step: 9
Training loss: 0.6858387730484309
Validation loss: 2.264727885644603

Epoch: 5| Step: 10
Training loss: 0.9813858849292654
Validation loss: 2.2720112526057603

Epoch: 540| Step: 0
Training loss: 0.609465836821614
Validation loss: 2.2781284831838673

Epoch: 5| Step: 1
Training loss: 0.6223230731736751
Validation loss: 2.2010550193109246

Epoch: 5| Step: 2
Training loss: 0.4865972701029827
Validation loss: 2.2625293203350956

Epoch: 5| Step: 3
Training loss: 0.8584824174892303
Validation loss: 2.3289955715440493

Epoch: 5| Step: 4
Training loss: 0.8246091306858614
Validation loss: 2.222032304393931

Epoch: 5| Step: 5
Training loss: 0.7031201256477095
Validation loss: 2.2317172242774888

Epoch: 5| Step: 6
Training loss: 1.3174400006119453
Validation loss: 2.2935264208186408

Epoch: 5| Step: 7
Training loss: 0.6206152890416605
Validation loss: 2.2767896550676023

Epoch: 5| Step: 8
Training loss: 0.7475081613024949
Validation loss: 2.2423334733409397

Epoch: 5| Step: 9
Training loss: 0.8736871338741268
Validation loss: 2.3244472199376527

Epoch: 5| Step: 10
Training loss: 0.5674145898111004
Validation loss: 2.2911115445721912

Epoch: 541| Step: 0
Training loss: 0.6668605870098874
Validation loss: 2.2668896736265802

Epoch: 5| Step: 1
Training loss: 0.6947527357420262
Validation loss: 2.32183206308992

Epoch: 5| Step: 2
Training loss: 0.7305736364448693
Validation loss: 2.2574847764471127

Epoch: 5| Step: 3
Training loss: 0.6818583886617068
Validation loss: 2.239028545630808

Epoch: 5| Step: 4
Training loss: 0.7812375258403544
Validation loss: 2.2709421013437328

Epoch: 5| Step: 5
Training loss: 0.790602060218904
Validation loss: 2.3297434987736185

Epoch: 5| Step: 6
Training loss: 0.6473898640053346
Validation loss: 2.181281408047437

Epoch: 5| Step: 7
Training loss: 0.6896946297654278
Validation loss: 2.2462842435163006

Epoch: 5| Step: 8
Training loss: 0.8208567675684072
Validation loss: 2.284309983139415

Epoch: 5| Step: 9
Training loss: 0.783776318474784
Validation loss: 2.253003701343049

Epoch: 5| Step: 10
Training loss: 1.3796586963588933
Validation loss: 2.2222638773175896

Epoch: 542| Step: 0
Training loss: 0.6085359225142966
Validation loss: 2.2671738266508714

Epoch: 5| Step: 1
Training loss: 0.6870651170140627
Validation loss: 2.2598599373545487

Epoch: 5| Step: 2
Training loss: 0.7794060499159596
Validation loss: 2.2578000366625424

Epoch: 5| Step: 3
Training loss: 0.9090551829904171
Validation loss: 2.2311898472006493

Epoch: 5| Step: 4
Training loss: 0.6795410349218803
Validation loss: 2.252806420712274

Epoch: 5| Step: 5
Training loss: 0.7017282175543655
Validation loss: 2.296347345357815

Epoch: 5| Step: 6
Training loss: 0.7878408133515707
Validation loss: 2.2523107666349587

Epoch: 5| Step: 7
Training loss: 1.3522878034755212
Validation loss: 2.2745945088724793

Epoch: 5| Step: 8
Training loss: 0.8721383165455756
Validation loss: 2.3136372373707146

Epoch: 5| Step: 9
Training loss: 0.6579786195107646
Validation loss: 2.199668554283387

Epoch: 5| Step: 10
Training loss: 0.6083071963256289
Validation loss: 2.2786383170898983

Epoch: 543| Step: 0
Training loss: 0.7252050866070135
Validation loss: 2.3372403306651655

Epoch: 5| Step: 1
Training loss: 0.700113970129726
Validation loss: 2.254258062164113

Epoch: 5| Step: 2
Training loss: 0.7399530605945486
Validation loss: 2.3030143703319608

Epoch: 5| Step: 3
Training loss: 0.7905452507116205
Validation loss: 2.3563219350770486

Epoch: 5| Step: 4
Training loss: 0.7978244436037194
Validation loss: 2.2817324427295542

Epoch: 5| Step: 5
Training loss: 1.5443323990470244
Validation loss: 2.258514338361285

Epoch: 5| Step: 6
Training loss: 0.6775102931996753
Validation loss: 2.2536853497131473

Epoch: 5| Step: 7
Training loss: 0.8963952113670917
Validation loss: 2.3288846199593842

Epoch: 5| Step: 8
Training loss: 0.7363055400268498
Validation loss: 2.2942163582155626

Epoch: 5| Step: 9
Training loss: 0.7188837922005824
Validation loss: 2.227590748420158

Epoch: 5| Step: 10
Training loss: 0.61208873877098
Validation loss: 2.25265877253431

Epoch: 544| Step: 0
Training loss: 0.6371520738542937
Validation loss: 2.221981634576439

Epoch: 5| Step: 1
Training loss: 0.38390835759504677
Validation loss: 2.2396182083043485

Epoch: 5| Step: 2
Training loss: 1.3856216604066074
Validation loss: 2.2854170018122937

Epoch: 5| Step: 3
Training loss: 1.020560026886412
Validation loss: 2.239618703377325

Epoch: 5| Step: 4
Training loss: 0.6153568932990026
Validation loss: 2.211705097368713

Epoch: 5| Step: 5
Training loss: 0.7433146701345805
Validation loss: 2.257513860007832

Epoch: 5| Step: 6
Training loss: 0.699248691535792
Validation loss: 2.2850624667530415

Epoch: 5| Step: 7
Training loss: 0.698514829105478
Validation loss: 2.2763995801084347

Epoch: 5| Step: 8
Training loss: 0.8479040109000779
Validation loss: 2.348071416808008

Epoch: 5| Step: 9
Training loss: 0.6306868278810577
Validation loss: 2.278957420785189

Epoch: 5| Step: 10
Training loss: 0.6890711171828893
Validation loss: 2.2801041995109497

Epoch: 545| Step: 0
Training loss: 0.6991249106748303
Validation loss: 2.363838513975675

Epoch: 5| Step: 1
Training loss: 0.6498508676596368
Validation loss: 2.3344247334011836

Epoch: 5| Step: 2
Training loss: 0.5783854490712681
Validation loss: 2.3349364632520664

Epoch: 5| Step: 3
Training loss: 0.8959506238994707
Validation loss: 2.2706188018907434

Epoch: 5| Step: 4
Training loss: 0.6586082637902654
Validation loss: 2.308345340661843

Epoch: 5| Step: 5
Training loss: 0.7672999608419053
Validation loss: 2.318686789064074

Epoch: 5| Step: 6
Training loss: 0.7594412770802509
Validation loss: 2.316769931174064

Epoch: 5| Step: 7
Training loss: 1.3246006597773876
Validation loss: 2.2845498712888292

Epoch: 5| Step: 8
Training loss: 0.7352424530503228
Validation loss: 2.2518719744262605

Epoch: 5| Step: 9
Training loss: 0.5980196078890978
Validation loss: 2.217738384120928

Epoch: 5| Step: 10
Training loss: 0.7080344149097084
Validation loss: 2.2809916670426316

Epoch: 546| Step: 0
Training loss: 0.8662233921604967
Validation loss: 2.2131833611070264

Epoch: 5| Step: 1
Training loss: 0.6129703584135037
Validation loss: 2.3186249661918152

Epoch: 5| Step: 2
Training loss: 0.6949391595021437
Validation loss: 2.3030519561242278

Epoch: 5| Step: 3
Training loss: 0.6671627826266315
Validation loss: 2.259057601338216

Epoch: 5| Step: 4
Training loss: 0.7854287353182018
Validation loss: 2.3108473201471735

Epoch: 5| Step: 5
Training loss: 1.4642874106287684
Validation loss: 2.328414565332739

Epoch: 5| Step: 6
Training loss: 0.6289082165799876
Validation loss: 2.2695645387839534

Epoch: 5| Step: 7
Training loss: 0.7835025738112114
Validation loss: 2.224964174233616

Epoch: 5| Step: 8
Training loss: 1.0639529671778623
Validation loss: 2.243005170778722

Epoch: 5| Step: 9
Training loss: 0.6169269349750315
Validation loss: 2.2723520626200067

Epoch: 5| Step: 10
Training loss: 0.5681769219100834
Validation loss: 2.238636486530218

Epoch: 547| Step: 0
Training loss: 0.6505012532675866
Validation loss: 2.2521834085369834

Epoch: 5| Step: 1
Training loss: 0.7529449659249545
Validation loss: 2.2465970490322786

Epoch: 5| Step: 2
Training loss: 1.3010881308247237
Validation loss: 2.301772223313013

Epoch: 5| Step: 3
Training loss: 0.8010351383321864
Validation loss: 2.2614663389328586

Epoch: 5| Step: 4
Training loss: 0.9244628725720302
Validation loss: 2.276500629066248

Epoch: 5| Step: 5
Training loss: 0.7486141832493498
Validation loss: 2.2423238662425025

Epoch: 5| Step: 6
Training loss: 0.6900042959438879
Validation loss: 2.1763107613700807

Epoch: 5| Step: 7
Training loss: 0.6966398192971407
Validation loss: 2.3080837858822036

Epoch: 5| Step: 8
Training loss: 0.6567365341446905
Validation loss: 2.2994814491941185

Epoch: 5| Step: 9
Training loss: 0.7399512078979127
Validation loss: 2.300704249725855

Epoch: 5| Step: 10
Training loss: 0.5810411211241245
Validation loss: 2.2937165728555287

Epoch: 548| Step: 0
Training loss: 1.451030821895489
Validation loss: 2.236450461361319

Epoch: 5| Step: 1
Training loss: 0.5627042876259042
Validation loss: 2.298153506154595

Epoch: 5| Step: 2
Training loss: 0.6621646014111824
Validation loss: 2.308306985887394

Epoch: 5| Step: 3
Training loss: 0.9660129335753898
Validation loss: 2.2757283948320537

Epoch: 5| Step: 4
Training loss: 0.7058040443102399
Validation loss: 2.2736439903075683

Epoch: 5| Step: 5
Training loss: 0.7437159009537727
Validation loss: 2.3436010301069303

Epoch: 5| Step: 6
Training loss: 0.7290687404452152
Validation loss: 2.2460324252380985

Epoch: 5| Step: 7
Training loss: 0.6583245275809878
Validation loss: 2.2473828135421643

Epoch: 5| Step: 8
Training loss: 0.6831318848132978
Validation loss: 2.1746873415638053

Epoch: 5| Step: 9
Training loss: 0.8260589233815127
Validation loss: 2.281071398423524

Epoch: 5| Step: 10
Training loss: 0.6656457091857457
Validation loss: 2.226328791363476

Epoch: 549| Step: 0
Training loss: 0.5143367974705871
Validation loss: 2.232895711177548

Epoch: 5| Step: 1
Training loss: 0.7110593502715593
Validation loss: 2.274719139764368

Epoch: 5| Step: 2
Training loss: 0.7116591595053501
Validation loss: 2.2390134467419998

Epoch: 5| Step: 3
Training loss: 0.6811850263076585
Validation loss: 2.2432383339820903

Epoch: 5| Step: 4
Training loss: 0.7158391307319237
Validation loss: 2.2507538495395942

Epoch: 5| Step: 5
Training loss: 0.6013028959453561
Validation loss: 2.2718405042811765

Epoch: 5| Step: 6
Training loss: 1.422235715614987
Validation loss: 2.2897484821847636

Epoch: 5| Step: 7
Training loss: 0.8044533249928053
Validation loss: 2.2852521081309227

Epoch: 5| Step: 8
Training loss: 0.6939269630589345
Validation loss: 2.247021785728226

Epoch: 5| Step: 9
Training loss: 0.8445082189364389
Validation loss: 2.3090490779119923

Epoch: 5| Step: 10
Training loss: 0.5631579418898899
Validation loss: 2.2565349307250377

Epoch: 550| Step: 0
Training loss: 0.61490181305817
Validation loss: 2.279431611646181

Epoch: 5| Step: 1
Training loss: 0.6243558902508147
Validation loss: 2.266927530411012

Epoch: 5| Step: 2
Training loss: 1.310596084239366
Validation loss: 2.2923791031527165

Epoch: 5| Step: 3
Training loss: 0.4839228088285155
Validation loss: 2.247675478840005

Epoch: 5| Step: 4
Training loss: 0.7112417303720828
Validation loss: 2.281664113570997

Epoch: 5| Step: 5
Training loss: 0.5140098939084409
Validation loss: 2.241685849280104

Epoch: 5| Step: 6
Training loss: 0.4930421281905529
Validation loss: 2.293814374457317

Epoch: 5| Step: 7
Training loss: 0.6288320841210228
Validation loss: 2.3272994574248447

Epoch: 5| Step: 8
Training loss: 0.7848742154052624
Validation loss: 2.3130773141295315

Epoch: 5| Step: 9
Training loss: 0.8566942538248932
Validation loss: 2.2441798919378453

Epoch: 5| Step: 10
Training loss: 0.8971682996034038
Validation loss: 2.277764155717894

Epoch: 551| Step: 0
Training loss: 1.27719241304435
Validation loss: 2.295872540758242

Epoch: 5| Step: 1
Training loss: 0.9883481632543863
Validation loss: 2.2727250566965824

Epoch: 5| Step: 2
Training loss: 0.8670308770684055
Validation loss: 2.277136273476047

Epoch: 5| Step: 3
Training loss: 0.6998366710307375
Validation loss: 2.2538232645001455

Epoch: 5| Step: 4
Training loss: 0.6884272131582049
Validation loss: 2.325210244266575

Epoch: 5| Step: 5
Training loss: 0.5669428421187676
Validation loss: 2.2566001848719006

Epoch: 5| Step: 6
Training loss: 0.8341044712475955
Validation loss: 2.2772129426317376

Epoch: 5| Step: 7
Training loss: 0.5308022575724239
Validation loss: 2.2451318536799914

Epoch: 5| Step: 8
Training loss: 0.8526658425989511
Validation loss: 2.20806895101539

Epoch: 5| Step: 9
Training loss: 0.5618327474778723
Validation loss: 2.2838231867800074

Epoch: 5| Step: 10
Training loss: 0.5695309967333488
Validation loss: 2.225411048823994

Epoch: 552| Step: 0
Training loss: 0.7121323825051086
Validation loss: 2.3167761976043595

Epoch: 5| Step: 1
Training loss: 0.5528636821560396
Validation loss: 2.263153254873581

Epoch: 5| Step: 2
Training loss: 0.8262627734237151
Validation loss: 2.270219306836129

Epoch: 5| Step: 3
Training loss: 1.4063156960294525
Validation loss: 2.2225861363774952

Epoch: 5| Step: 4
Training loss: 0.5293036034638497
Validation loss: 2.2363064552221257

Epoch: 5| Step: 5
Training loss: 0.6894637152963422
Validation loss: 2.2025807771117947

Epoch: 5| Step: 6
Training loss: 0.6488185590191565
Validation loss: 2.276381965424849

Epoch: 5| Step: 7
Training loss: 0.7378441056329068
Validation loss: 2.294316682246501

Epoch: 5| Step: 8
Training loss: 0.9121927554066396
Validation loss: 2.2210796072893784

Epoch: 5| Step: 9
Training loss: 0.674844213451554
Validation loss: 2.273556374828898

Epoch: 5| Step: 10
Training loss: 0.6024885110036692
Validation loss: 2.3020009100457575

Epoch: 553| Step: 0
Training loss: 0.8732220433453641
Validation loss: 2.2034649388495593

Epoch: 5| Step: 1
Training loss: 0.6781610250792272
Validation loss: 2.1877853986724523

Epoch: 5| Step: 2
Training loss: 0.6134350091900154
Validation loss: 2.275217566892967

Epoch: 5| Step: 3
Training loss: 0.8210522177488621
Validation loss: 2.212328498876371

Epoch: 5| Step: 4
Training loss: 1.3410430078685944
Validation loss: 2.218675605512299

Epoch: 5| Step: 5
Training loss: 0.7942850997560756
Validation loss: 2.3015811888302435

Epoch: 5| Step: 6
Training loss: 0.7872452535792067
Validation loss: 2.174434662932652

Epoch: 5| Step: 7
Training loss: 0.6147696541292882
Validation loss: 2.2607483506830195

Epoch: 5| Step: 8
Training loss: 0.6286559702749398
Validation loss: 2.249151045770356

Epoch: 5| Step: 9
Training loss: 0.6658000429335054
Validation loss: 2.27020798214421

Epoch: 5| Step: 10
Training loss: 0.5584938386783874
Validation loss: 2.30943983074896

Epoch: 554| Step: 0
Training loss: 1.4676304872587471
Validation loss: 2.2758979193483766

Epoch: 5| Step: 1
Training loss: 0.5490170625352494
Validation loss: 2.23326801265898

Epoch: 5| Step: 2
Training loss: 0.6959640793163386
Validation loss: 2.2719836392764656

Epoch: 5| Step: 3
Training loss: 0.7605278290968182
Validation loss: 2.2123968529647184

Epoch: 5| Step: 4
Training loss: 0.5629057480463531
Validation loss: 2.2796091833615577

Epoch: 5| Step: 5
Training loss: 0.5015034126819788
Validation loss: 2.2742960463571933

Epoch: 5| Step: 6
Training loss: 0.728091650923579
Validation loss: 2.281151792328667

Epoch: 5| Step: 7
Training loss: 0.8030857328916288
Validation loss: 2.377388989116639

Epoch: 5| Step: 8
Training loss: 0.7233252650424753
Validation loss: 2.2605990098181614

Epoch: 5| Step: 9
Training loss: 0.6637902318755262
Validation loss: 2.2413082930869748

Epoch: 5| Step: 10
Training loss: 0.5946125240641
Validation loss: 2.2558258941996976

Epoch: 555| Step: 0
Training loss: 0.7446872975953052
Validation loss: 2.2565128801272247

Epoch: 5| Step: 1
Training loss: 1.4334595328966886
Validation loss: 2.2540080104981475

Epoch: 5| Step: 2
Training loss: 0.653079343413736
Validation loss: 2.3234881391509385

Epoch: 5| Step: 3
Training loss: 0.5901494023716354
Validation loss: 2.294673201144711

Epoch: 5| Step: 4
Training loss: 0.5213239901787572
Validation loss: 2.2428896236539497

Epoch: 5| Step: 5
Training loss: 0.6251564306951566
Validation loss: 2.2355260404815334

Epoch: 5| Step: 6
Training loss: 0.7012948908521421
Validation loss: 2.285366134884338

Epoch: 5| Step: 7
Training loss: 0.5052649639939405
Validation loss: 2.2464800753075598

Epoch: 5| Step: 8
Training loss: 0.6378194971368963
Validation loss: 2.286152013936598

Epoch: 5| Step: 9
Training loss: 0.7047415905004497
Validation loss: 2.24968710926236

Epoch: 5| Step: 10
Training loss: 0.8060124424336067
Validation loss: 2.283552849641854

Epoch: 556| Step: 0
Training loss: 0.6137061621243614
Validation loss: 2.239014260827401

Epoch: 5| Step: 1
Training loss: 1.4360994067146557
Validation loss: 2.3171461160163727

Epoch: 5| Step: 2
Training loss: 0.6037263965139231
Validation loss: 2.1957765069221833

Epoch: 5| Step: 3
Training loss: 0.7155466011780708
Validation loss: 2.3611608672122224

Epoch: 5| Step: 4
Training loss: 0.7168082254534955
Validation loss: 2.300229205427357

Epoch: 5| Step: 5
Training loss: 0.8376188037360204
Validation loss: 2.2219163392732986

Epoch: 5| Step: 6
Training loss: 0.43211535416381924
Validation loss: 2.2444241617892446

Epoch: 5| Step: 7
Training loss: 0.4608114361116273
Validation loss: 2.310639449706439

Epoch: 5| Step: 8
Training loss: 0.6155033068750145
Validation loss: 2.188837998140266

Epoch: 5| Step: 9
Training loss: 0.8522946771049312
Validation loss: 2.2268748086124974

Epoch: 5| Step: 10
Training loss: 0.7305591547707719
Validation loss: 2.251944387704437

Epoch: 557| Step: 0
Training loss: 0.645852878233794
Validation loss: 2.195893608194242

Epoch: 5| Step: 1
Training loss: 0.7417664387562095
Validation loss: 2.22300827376267

Epoch: 5| Step: 2
Training loss: 0.7242629053179462
Validation loss: 2.2334827787562346

Epoch: 5| Step: 3
Training loss: 1.4895464307931208
Validation loss: 2.3031086163955115

Epoch: 5| Step: 4
Training loss: 0.8456629860318864
Validation loss: 2.260779169464491

Epoch: 5| Step: 5
Training loss: 0.5253411592362115
Validation loss: 2.3131808448526754

Epoch: 5| Step: 6
Training loss: 0.6917406986632811
Validation loss: 2.2413860613925896

Epoch: 5| Step: 7
Training loss: 0.5208714916238342
Validation loss: 2.202763789860042

Epoch: 5| Step: 8
Training loss: 0.6920287998730577
Validation loss: 2.248182330500745

Epoch: 5| Step: 9
Training loss: 0.6072109383591081
Validation loss: 2.2869467971176043

Epoch: 5| Step: 10
Training loss: 0.5922870431541332
Validation loss: 2.293720272372618

Epoch: 558| Step: 0
Training loss: 0.6024247467562259
Validation loss: 2.2553009678806197

Epoch: 5| Step: 1
Training loss: 0.5394233656733002
Validation loss: 2.3066119496959083

Epoch: 5| Step: 2
Training loss: 1.351206252936445
Validation loss: 2.3111121478783754

Epoch: 5| Step: 3
Training loss: 0.8043292831553952
Validation loss: 2.2879709000372275

Epoch: 5| Step: 4
Training loss: 0.6406924747195387
Validation loss: 2.2696140734431474

Epoch: 5| Step: 5
Training loss: 0.7471837973572725
Validation loss: 2.312908193119794

Epoch: 5| Step: 6
Training loss: 0.8451663950450322
Validation loss: 2.302040151661487

Epoch: 5| Step: 7
Training loss: 0.4793076014231736
Validation loss: 2.2968597824578127

Epoch: 5| Step: 8
Training loss: 0.7787170930403381
Validation loss: 2.3238596014735458

Epoch: 5| Step: 9
Training loss: 0.6098918434705352
Validation loss: 2.3168731851332556

Epoch: 5| Step: 10
Training loss: 0.7366709429701654
Validation loss: 2.2993580852226754

Epoch: 559| Step: 0
Training loss: 0.5728551282488831
Validation loss: 2.2446237090166465

Epoch: 5| Step: 1
Training loss: 0.7523223763001653
Validation loss: 2.2812773146197225

Epoch: 5| Step: 2
Training loss: 0.510117975408622
Validation loss: 2.2572306369242576

Epoch: 5| Step: 3
Training loss: 0.8351559059991654
Validation loss: 2.230303213451587

Epoch: 5| Step: 4
Training loss: 1.3971093546583608
Validation loss: 2.274294805283449

Epoch: 5| Step: 5
Training loss: 0.6226111296384113
Validation loss: 2.27250306163623

Epoch: 5| Step: 6
Training loss: 0.5855070694823186
Validation loss: 2.228462413520576

Epoch: 5| Step: 7
Training loss: 1.0074741475690676
Validation loss: 2.3254808858997396

Epoch: 5| Step: 8
Training loss: 0.48514871944658317
Validation loss: 2.194966419990996

Epoch: 5| Step: 9
Training loss: 0.45439571574762
Validation loss: 2.3088514329490346

Epoch: 5| Step: 10
Training loss: 0.6212662511269644
Validation loss: 2.221697268555629

Epoch: 560| Step: 0
Training loss: 0.7355696112977532
Validation loss: 2.268477289491463

Epoch: 5| Step: 1
Training loss: 1.3869526840395772
Validation loss: 2.2361136476595798

Epoch: 5| Step: 2
Training loss: 0.5169320446580254
Validation loss: 2.2840216040418055

Epoch: 5| Step: 3
Training loss: 0.6852289315693464
Validation loss: 2.3364342349889125

Epoch: 5| Step: 4
Training loss: 0.8133196730977852
Validation loss: 2.3113194239957977

Epoch: 5| Step: 5
Training loss: 0.6131225672215718
Validation loss: 2.2713897338029514

Epoch: 5| Step: 6
Training loss: 0.832067748509452
Validation loss: 2.2923314443850065

Epoch: 5| Step: 7
Training loss: 0.6905920978838648
Validation loss: 2.1786478907834717

Epoch: 5| Step: 8
Training loss: 0.7170266762722877
Validation loss: 2.261084454016244

Epoch: 5| Step: 9
Training loss: 0.6047954630516321
Validation loss: 2.2191009347941395

Epoch: 5| Step: 10
Training loss: 0.9366913486828499
Validation loss: 2.2019925493895163

Epoch: 561| Step: 0
Training loss: 0.6667728091222922
Validation loss: 2.2215095689458204

Epoch: 5| Step: 1
Training loss: 0.4520666489254503
Validation loss: 2.2717980507615225

Epoch: 5| Step: 2
Training loss: 0.6046130378475162
Validation loss: 2.2455004538659513

Epoch: 5| Step: 3
Training loss: 0.5332416618310485
Validation loss: 2.2186608903950105

Epoch: 5| Step: 4
Training loss: 0.6053808333032965
Validation loss: 2.239164729869848

Epoch: 5| Step: 5
Training loss: 0.562318719686819
Validation loss: 2.223447366680378

Epoch: 5| Step: 6
Training loss: 0.6824331403827645
Validation loss: 2.2868085358444223

Epoch: 5| Step: 7
Training loss: 0.762368653663331
Validation loss: 2.2637665240314693

Epoch: 5| Step: 8
Training loss: 0.8772528800884464
Validation loss: 2.26150198302619

Epoch: 5| Step: 9
Training loss: 1.4381788558192905
Validation loss: 2.2534997263185006

Epoch: 5| Step: 10
Training loss: 0.48730091101152045
Validation loss: 2.2611270281887443

Epoch: 562| Step: 0
Training loss: 0.7079761156024399
Validation loss: 2.2610492364631023

Epoch: 5| Step: 1
Training loss: 0.7210862710054491
Validation loss: 2.2295361134988076

Epoch: 5| Step: 2
Training loss: 0.5262027972111867
Validation loss: 2.204293888084326

Epoch: 5| Step: 3
Training loss: 0.6916985405812648
Validation loss: 2.2811522868164786

Epoch: 5| Step: 4
Training loss: 0.6839860498918715
Validation loss: 2.209582923318177

Epoch: 5| Step: 5
Training loss: 0.6911405494639363
Validation loss: 2.3149112290797964

Epoch: 5| Step: 6
Training loss: 0.5056427598623323
Validation loss: 2.3172605868527234

Epoch: 5| Step: 7
Training loss: 0.8288416730370525
Validation loss: 2.2563510835658582

Epoch: 5| Step: 8
Training loss: 1.3823084801708017
Validation loss: 2.3096967488966267

Epoch: 5| Step: 9
Training loss: 0.6481899340407965
Validation loss: 2.1936501112049216

Epoch: 5| Step: 10
Training loss: 0.5624074859834479
Validation loss: 2.30808016936685

Epoch: 563| Step: 0
Training loss: 0.5909079242408013
Validation loss: 2.307824393162391

Epoch: 5| Step: 1
Training loss: 0.5399636462566655
Validation loss: 2.3251923510528067

Epoch: 5| Step: 2
Training loss: 0.6904763040088379
Validation loss: 2.2982734422696516

Epoch: 5| Step: 3
Training loss: 0.6011558743752471
Validation loss: 2.1834550308237657

Epoch: 5| Step: 4
Training loss: 0.7220818788748957
Validation loss: 2.234594611818772

Epoch: 5| Step: 5
Training loss: 0.6872000256585571
Validation loss: 2.1701766761908137

Epoch: 5| Step: 6
Training loss: 0.6874977892059846
Validation loss: 2.2738921386021493

Epoch: 5| Step: 7
Training loss: 0.5755282670543549
Validation loss: 2.2645699493896916

Epoch: 5| Step: 8
Training loss: 0.9211661636321717
Validation loss: 2.3402107900404783

Epoch: 5| Step: 9
Training loss: 1.2993620958004
Validation loss: 2.2940644198405993

Epoch: 5| Step: 10
Training loss: 0.50369332124835
Validation loss: 2.2691621986357133

Epoch: 564| Step: 0
Training loss: 1.3249318951072027
Validation loss: 2.279523778774713

Epoch: 5| Step: 1
Training loss: 0.5410137796198362
Validation loss: 2.3297629724018267

Epoch: 5| Step: 2
Training loss: 0.7133319063781417
Validation loss: 2.2491595351777054

Epoch: 5| Step: 3
Training loss: 0.5562864013076773
Validation loss: 2.335048897087576

Epoch: 5| Step: 4
Training loss: 0.9294804254289843
Validation loss: 2.2812125517159085

Epoch: 5| Step: 5
Training loss: 0.5392903938108474
Validation loss: 2.1888607006292573

Epoch: 5| Step: 6
Training loss: 0.7923055421662588
Validation loss: 2.291887077702564

Epoch: 5| Step: 7
Training loss: 0.7147513157851446
Validation loss: 2.3040324085686117

Epoch: 5| Step: 8
Training loss: 0.8733471518313891
Validation loss: 2.3331579905724142

Epoch: 5| Step: 9
Training loss: 0.6851453556251638
Validation loss: 2.238038106377334

Epoch: 5| Step: 10
Training loss: 0.6914105172752981
Validation loss: 2.3176702655036263

Epoch: 565| Step: 0
Training loss: 0.6683942543796436
Validation loss: 2.3060313332805746

Epoch: 5| Step: 1
Training loss: 0.7192263061603865
Validation loss: 2.2188205641335177

Epoch: 5| Step: 2
Training loss: 0.5831453298559488
Validation loss: 2.3039559297675116

Epoch: 5| Step: 3
Training loss: 0.6624192944438279
Validation loss: 2.2306602635308836

Epoch: 5| Step: 4
Training loss: 1.2648385041324246
Validation loss: 2.307486531977774

Epoch: 5| Step: 5
Training loss: 0.7335860701901408
Validation loss: 2.2700991465862264

Epoch: 5| Step: 6
Training loss: 0.6493851275200434
Validation loss: 2.1991122229514475

Epoch: 5| Step: 7
Training loss: 0.4600677852080873
Validation loss: 2.234106850763493

Epoch: 5| Step: 8
Training loss: 0.7574497416476762
Validation loss: 2.284653793696453

Epoch: 5| Step: 9
Training loss: 0.6823804715047778
Validation loss: 2.2610471490850337

Epoch: 5| Step: 10
Training loss: 0.6258741940782103
Validation loss: 2.2040022458646304

Epoch: 566| Step: 0
Training loss: 0.6918786800186719
Validation loss: 2.324099636015838

Epoch: 5| Step: 1
Training loss: 0.77545204207626
Validation loss: 2.318790229643186

Epoch: 5| Step: 2
Training loss: 0.7352598014004437
Validation loss: 2.3240475033201884

Epoch: 5| Step: 3
Training loss: 0.7826153840133949
Validation loss: 2.3534045200387084

Epoch: 5| Step: 4
Training loss: 0.6433395466067984
Validation loss: 2.320715474701304

Epoch: 5| Step: 5
Training loss: 0.6088845406671524
Validation loss: 2.3475846399155524

Epoch: 5| Step: 6
Training loss: 0.7190280459429302
Validation loss: 2.2776365041149567

Epoch: 5| Step: 7
Training loss: 0.5095735092910846
Validation loss: 2.3128447615167294

Epoch: 5| Step: 8
Training loss: 1.3887713218308855
Validation loss: 2.2909620344664794

Epoch: 5| Step: 9
Training loss: 0.5664220873493017
Validation loss: 2.291532771728723

Epoch: 5| Step: 10
Training loss: 0.7970302281002036
Validation loss: 2.247527296259675

Epoch: 567| Step: 0
Training loss: 1.3713257856821204
Validation loss: 2.25296118986484

Epoch: 5| Step: 1
Training loss: 0.3750636126287682
Validation loss: 2.2960319207889435

Epoch: 5| Step: 2
Training loss: 0.5978770876510447
Validation loss: 2.173170354855297

Epoch: 5| Step: 3
Training loss: 0.9016649740018722
Validation loss: 2.284239715964596

Epoch: 5| Step: 4
Training loss: 0.5733190221811615
Validation loss: 2.168997899143001

Epoch: 5| Step: 5
Training loss: 0.8592423770179046
Validation loss: 2.1892465372467185

Epoch: 5| Step: 6
Training loss: 0.7081192244641827
Validation loss: 2.232696820302264

Epoch: 5| Step: 7
Training loss: 0.7902675529299733
Validation loss: 2.212992054255345

Epoch: 5| Step: 8
Training loss: 0.5354765886946881
Validation loss: 2.2696746068688856

Epoch: 5| Step: 9
Training loss: 0.757694510486861
Validation loss: 2.2815716278358185

Epoch: 5| Step: 10
Training loss: 0.6126868410652693
Validation loss: 2.205278348332694

Epoch: 568| Step: 0
Training loss: 1.3506450295364294
Validation loss: 2.2760965572466496

Epoch: 5| Step: 1
Training loss: 0.8482547879408565
Validation loss: 2.286713663383781

Epoch: 5| Step: 2
Training loss: 0.716001604757695
Validation loss: 2.286577971188947

Epoch: 5| Step: 3
Training loss: 0.6403791839891828
Validation loss: 2.27447870000348

Epoch: 5| Step: 4
Training loss: 0.6342721517466363
Validation loss: 2.294543658778997

Epoch: 5| Step: 5
Training loss: 0.48010873099494417
Validation loss: 2.259375252395548

Epoch: 5| Step: 6
Training loss: 0.6773608054859414
Validation loss: 2.286593139435802

Epoch: 5| Step: 7
Training loss: 0.5001915028526431
Validation loss: 2.2673382079037285

Epoch: 5| Step: 8
Training loss: 0.5928024209492395
Validation loss: 2.2487612097623226

Epoch: 5| Step: 9
Training loss: 0.7470442225070512
Validation loss: 2.263549161490808

Epoch: 5| Step: 10
Training loss: 0.5647658171648803
Validation loss: 2.2414060396159696

Epoch: 569| Step: 0
Training loss: 1.284888799138086
Validation loss: 2.276372031273317

Epoch: 5| Step: 1
Training loss: 0.705742435870172
Validation loss: 2.3048009634201168

Epoch: 5| Step: 2
Training loss: 0.6156938562759209
Validation loss: 2.263962761845754

Epoch: 5| Step: 3
Training loss: 0.6200060406898202
Validation loss: 2.2963768929087585

Epoch: 5| Step: 4
Training loss: 0.6277357546512846
Validation loss: 2.236371056975317

Epoch: 5| Step: 5
Training loss: 0.7518555416845902
Validation loss: 2.2223678526621384

Epoch: 5| Step: 6
Training loss: 0.49269852524310787
Validation loss: 2.253994198237001

Epoch: 5| Step: 7
Training loss: 0.565816954186994
Validation loss: 2.3638206843266754

Epoch: 5| Step: 8
Training loss: 0.753441464743196
Validation loss: 2.2917073116632114

Epoch: 5| Step: 9
Training loss: 0.5201033690304036
Validation loss: 2.255583862134679

Epoch: 5| Step: 10
Training loss: 1.0226689721839544
Validation loss: 2.238674916134375

Epoch: 570| Step: 0
Training loss: 0.7001369138063932
Validation loss: 2.2428183113982594

Epoch: 5| Step: 1
Training loss: 0.692826982724478
Validation loss: 2.3235033737249533

Epoch: 5| Step: 2
Training loss: 0.8146502212874374
Validation loss: 2.2454976835802327

Epoch: 5| Step: 3
Training loss: 1.265347155932292
Validation loss: 2.221080439490325

Epoch: 5| Step: 4
Training loss: 0.6425997142005734
Validation loss: 2.285105875387491

Epoch: 5| Step: 5
Training loss: 0.593069816289351
Validation loss: 2.2915558669823612

Epoch: 5| Step: 6
Training loss: 0.656050878924268
Validation loss: 2.249720961747468

Epoch: 5| Step: 7
Training loss: 0.8013273656454148
Validation loss: 2.257544282620545

Epoch: 5| Step: 8
Training loss: 0.5347921427581098
Validation loss: 2.254232413762476

Epoch: 5| Step: 9
Training loss: 0.6540876367133935
Validation loss: 2.3351477231945723

Epoch: 5| Step: 10
Training loss: 0.8168556765056306
Validation loss: 2.2661021803992356

Epoch: 571| Step: 0
Training loss: 0.49544809031894677
Validation loss: 2.2771512535589222

Epoch: 5| Step: 1
Training loss: 0.5422176957310632
Validation loss: 2.2813230585145083

Epoch: 5| Step: 2
Training loss: 0.7501513805203549
Validation loss: 2.284830186479783

Epoch: 5| Step: 3
Training loss: 0.5894834415837809
Validation loss: 2.3339488328103455

Epoch: 5| Step: 4
Training loss: 0.5165559283402177
Validation loss: 2.2924896291422456

Epoch: 5| Step: 5
Training loss: 0.6117313018329554
Validation loss: 2.294562044893387

Epoch: 5| Step: 6
Training loss: 0.5393381105275451
Validation loss: 2.3555614573117185

Epoch: 5| Step: 7
Training loss: 0.7208527200403443
Validation loss: 2.2426868008700525

Epoch: 5| Step: 8
Training loss: 1.4959324682568265
Validation loss: 2.2321633142802524

Epoch: 5| Step: 9
Training loss: 0.7903714417982752
Validation loss: 2.217571112317536

Epoch: 5| Step: 10
Training loss: 0.3943504825836243
Validation loss: 2.275347879427177

Epoch: 572| Step: 0
Training loss: 0.8320740164927783
Validation loss: 2.298250903657012

Epoch: 5| Step: 1
Training loss: 1.3685291355949383
Validation loss: 2.3186907328905595

Epoch: 5| Step: 2
Training loss: 0.6343152605312987
Validation loss: 2.2462122150013575

Epoch: 5| Step: 3
Training loss: 0.7401185360255624
Validation loss: 2.285420244195629

Epoch: 5| Step: 4
Training loss: 0.877967706351433
Validation loss: 2.2988693210333744

Epoch: 5| Step: 5
Training loss: 0.7991595711524012
Validation loss: 2.20850269351583

Epoch: 5| Step: 6
Training loss: 0.8310144506591234
Validation loss: 2.2824961963713477

Epoch: 5| Step: 7
Training loss: 0.5705509993503207
Validation loss: 2.2960562961215025

Epoch: 5| Step: 8
Training loss: 0.5231414071339247
Validation loss: 2.2887586524750407

Epoch: 5| Step: 9
Training loss: 0.5578278846649382
Validation loss: 2.3035062081420645

Epoch: 5| Step: 10
Training loss: 0.6218132793526304
Validation loss: 2.314666357464106

Epoch: 573| Step: 0
Training loss: 1.3020394686621837
Validation loss: 2.3029160343594555

Epoch: 5| Step: 1
Training loss: 0.695192540996986
Validation loss: 2.3128474816173274

Epoch: 5| Step: 2
Training loss: 0.6471701496917002
Validation loss: 2.154099855223724

Epoch: 5| Step: 3
Training loss: 0.7519332288611724
Validation loss: 2.204754934762696

Epoch: 5| Step: 4
Training loss: 0.44519889787925687
Validation loss: 2.2385035982459875

Epoch: 5| Step: 5
Training loss: 0.8533885869997605
Validation loss: 2.3474193701443733

Epoch: 5| Step: 6
Training loss: 0.5437548319284008
Validation loss: 2.2629253899240043

Epoch: 5| Step: 7
Training loss: 0.7715978225156198
Validation loss: 2.2172273538177465

Epoch: 5| Step: 8
Training loss: 0.7774592941520575
Validation loss: 2.213079377651597

Epoch: 5| Step: 9
Training loss: 0.7789570920950819
Validation loss: 2.2035583957664633

Epoch: 5| Step: 10
Training loss: 0.5707012575968871
Validation loss: 2.242145599823257

Epoch: 574| Step: 0
Training loss: 0.5862217277346704
Validation loss: 2.305607039721058

Epoch: 5| Step: 1
Training loss: 0.705842805466341
Validation loss: 2.250830997067446

Epoch: 5| Step: 2
Training loss: 0.5701712341932221
Validation loss: 2.33900489351218

Epoch: 5| Step: 3
Training loss: 0.4776141023867714
Validation loss: 2.3417717606120645

Epoch: 5| Step: 4
Training loss: 1.414674910819444
Validation loss: 2.3292449814143885

Epoch: 5| Step: 5
Training loss: 0.956106213748523
Validation loss: 2.3665145880911846

Epoch: 5| Step: 6
Training loss: 0.4839107688370103
Validation loss: 2.317434319648863

Epoch: 5| Step: 7
Training loss: 0.6272470848696897
Validation loss: 2.291948138614245

Epoch: 5| Step: 8
Training loss: 0.6864136435781121
Validation loss: 2.2912516317855225

Epoch: 5| Step: 9
Training loss: 0.648003168454489
Validation loss: 2.276392074091848

Epoch: 5| Step: 10
Training loss: 0.5970722661409121
Validation loss: 2.30144347478096

Epoch: 575| Step: 0
Training loss: 1.3216195042210062
Validation loss: 2.292369916037901

Epoch: 5| Step: 1
Training loss: 0.5876930386368389
Validation loss: 2.258135749496109

Epoch: 5| Step: 2
Training loss: 0.6928086793731385
Validation loss: 2.2151581963000413

Epoch: 5| Step: 3
Training loss: 0.8055450166546353
Validation loss: 2.233389885886916

Epoch: 5| Step: 4
Training loss: 0.854815577755917
Validation loss: 2.2655045015839215

Epoch: 5| Step: 5
Training loss: 0.7281373706470757
Validation loss: 2.338514330629477

Epoch: 5| Step: 6
Training loss: 0.5337703049703778
Validation loss: 2.273187294075658

Epoch: 5| Step: 7
Training loss: 0.49690519636995006
Validation loss: 2.2006835104575586

Epoch: 5| Step: 8
Training loss: 0.7038699759939314
Validation loss: 2.2893583532191433

Epoch: 5| Step: 9
Training loss: 0.7581085727858567
Validation loss: 2.334651771933169

Epoch: 5| Step: 10
Training loss: 0.5214680015479497
Validation loss: 2.271814299445902

Epoch: 576| Step: 0
Training loss: 0.8533249910575171
Validation loss: 2.3260920980603785

Epoch: 5| Step: 1
Training loss: 1.376282657232362
Validation loss: 2.28396039519678

Epoch: 5| Step: 2
Training loss: 0.5019158078582745
Validation loss: 2.2635820478507083

Epoch: 5| Step: 3
Training loss: 0.6899417518134308
Validation loss: 2.220438163476737

Epoch: 5| Step: 4
Training loss: 0.5718691757822761
Validation loss: 2.332521720079659

Epoch: 5| Step: 5
Training loss: 0.7708085975458487
Validation loss: 2.212252386591416

Epoch: 5| Step: 6
Training loss: 0.6861832971240034
Validation loss: 2.232163301646747

Epoch: 5| Step: 7
Training loss: 0.5186007491809187
Validation loss: 2.2483538535836765

Epoch: 5| Step: 8
Training loss: 0.6811214973274236
Validation loss: 2.2056087813549383

Epoch: 5| Step: 9
Training loss: 0.5636711115313122
Validation loss: 2.2668307560165246

Epoch: 5| Step: 10
Training loss: 0.4409450552257273
Validation loss: 2.2876556876965095

Epoch: 577| Step: 0
Training loss: 0.6406589359506067
Validation loss: 2.2931086846265196

Epoch: 5| Step: 1
Training loss: 0.8625056031639428
Validation loss: 2.311737429250291

Epoch: 5| Step: 2
Training loss: 1.3270089340714126
Validation loss: 2.273790538516008

Epoch: 5| Step: 3
Training loss: 0.4725918371273719
Validation loss: 2.3462588210164643

Epoch: 5| Step: 4
Training loss: 0.4977073858748954
Validation loss: 2.2912689520163045

Epoch: 5| Step: 5
Training loss: 0.4810035799224378
Validation loss: 2.223140856703644

Epoch: 5| Step: 6
Training loss: 0.7124844164566285
Validation loss: 2.211769036626533

Epoch: 5| Step: 7
Training loss: 0.5548473718772592
Validation loss: 2.2339726636628634

Epoch: 5| Step: 8
Training loss: 0.5851126905457313
Validation loss: 2.249507719168787

Epoch: 5| Step: 9
Training loss: 0.7753087536230447
Validation loss: 2.226031890032604

Epoch: 5| Step: 10
Training loss: 0.7462263538697336
Validation loss: 2.2185189512315318

Epoch: 578| Step: 0
Training loss: 1.336955792240444
Validation loss: 2.310837879737867

Epoch: 5| Step: 1
Training loss: 0.42953247394852256
Validation loss: 2.2352210618067487

Epoch: 5| Step: 2
Training loss: 0.5351173776584062
Validation loss: 2.2470280219117638

Epoch: 5| Step: 3
Training loss: 0.7898206939501642
Validation loss: 2.2204298217274876

Epoch: 5| Step: 4
Training loss: 0.6538617181597637
Validation loss: 2.152318829817114

Epoch: 5| Step: 5
Training loss: 0.6831490514348152
Validation loss: 2.2299656851021195

Epoch: 5| Step: 6
Training loss: 0.657384663535664
Validation loss: 2.2537748672035933

Epoch: 5| Step: 7
Training loss: 0.5230851766908229
Validation loss: 2.2430278376298074

Epoch: 5| Step: 8
Training loss: 0.814511596629917
Validation loss: 2.2659708406212062

Epoch: 5| Step: 9
Training loss: 0.6783914376624386
Validation loss: 2.2481486099324695

Epoch: 5| Step: 10
Training loss: 0.7293081191779109
Validation loss: 2.291712526848843

Epoch: 579| Step: 0
Training loss: 0.6878294155566028
Validation loss: 2.2929981431961903

Epoch: 5| Step: 1
Training loss: 0.7184632600112708
Validation loss: 2.3779538696485254

Epoch: 5| Step: 2
Training loss: 0.6323011003782418
Validation loss: 2.3025958770795647

Epoch: 5| Step: 3
Training loss: 0.5073067714418955
Validation loss: 2.315244395373502

Epoch: 5| Step: 4
Training loss: 0.638425120244409
Validation loss: 2.276713263298561

Epoch: 5| Step: 5
Training loss: 0.5985808855594701
Validation loss: 2.207393203691333

Epoch: 5| Step: 6
Training loss: 1.2883526783996353
Validation loss: 2.27740780342381

Epoch: 5| Step: 7
Training loss: 0.6497216435607853
Validation loss: 2.276521040683723

Epoch: 5| Step: 8
Training loss: 0.9041234420663793
Validation loss: 2.237627166894252

Epoch: 5| Step: 9
Training loss: 0.5923762742765574
Validation loss: 2.2486660368761475

Epoch: 5| Step: 10
Training loss: 0.5829004287866706
Validation loss: 2.2328662776826618

Epoch: 580| Step: 0
Training loss: 0.6104382262691842
Validation loss: 2.1921962890093303

Epoch: 5| Step: 1
Training loss: 0.5206708813676619
Validation loss: 2.307405430154804

Epoch: 5| Step: 2
Training loss: 1.284991221861784
Validation loss: 2.2676821429181953

Epoch: 5| Step: 3
Training loss: 0.7799270873347923
Validation loss: 2.267232733084226

Epoch: 5| Step: 4
Training loss: 0.8915238445792343
Validation loss: 2.3117032140367173

Epoch: 5| Step: 5
Training loss: 0.5702258527594241
Validation loss: 2.2164799066691825

Epoch: 5| Step: 6
Training loss: 0.5153066924203382
Validation loss: 2.307398618858485

Epoch: 5| Step: 7
Training loss: 0.47355616627737385
Validation loss: 2.2880417747563784

Epoch: 5| Step: 8
Training loss: 0.35924772413696954
Validation loss: 2.2174615835297664

Epoch: 5| Step: 9
Training loss: 0.6494315467718005
Validation loss: 2.3105713768080336

Epoch: 5| Step: 10
Training loss: 0.4504900648014363
Validation loss: 2.262484891590959

Epoch: 581| Step: 0
Training loss: 0.6579623362043566
Validation loss: 2.262420983374595

Epoch: 5| Step: 1
Training loss: 0.5802785353820239
Validation loss: 2.3167520635108096

Epoch: 5| Step: 2
Training loss: 0.5085171139311871
Validation loss: 2.122435483871015

Epoch: 5| Step: 3
Training loss: 0.5381891667370454
Validation loss: 2.2328257181594457

Epoch: 5| Step: 4
Training loss: 0.4923560746955673
Validation loss: 2.292002233191746

Epoch: 5| Step: 5
Training loss: 0.611369073733393
Validation loss: 2.2393072218986343

Epoch: 5| Step: 6
Training loss: 0.6582278012141148
Validation loss: 2.268685283306803

Epoch: 5| Step: 7
Training loss: 0.7858661459959035
Validation loss: 2.2711085910683937

Epoch: 5| Step: 8
Training loss: 1.2590210126042924
Validation loss: 2.253913828624371

Epoch: 5| Step: 9
Training loss: 0.8156392267966823
Validation loss: 2.26850192078329

Epoch: 5| Step: 10
Training loss: 0.5209236130353743
Validation loss: 2.24669432755079

Epoch: 582| Step: 0
Training loss: 0.4164518120264484
Validation loss: 2.28533078447333

Epoch: 5| Step: 1
Training loss: 0.49707774698209917
Validation loss: 2.3069586218458085

Epoch: 5| Step: 2
Training loss: 1.3088689713931712
Validation loss: 2.375657105660342

Epoch: 5| Step: 3
Training loss: 0.6525863150803441
Validation loss: 2.2636342129256106

Epoch: 5| Step: 4
Training loss: 0.4877304480029641
Validation loss: 2.2513084446879508

Epoch: 5| Step: 5
Training loss: 0.5238972537903477
Validation loss: 2.2484038204749264

Epoch: 5| Step: 6
Training loss: 0.7966355356680669
Validation loss: 2.25144732462796

Epoch: 5| Step: 7
Training loss: 0.38517876534103707
Validation loss: 2.300005687998176

Epoch: 5| Step: 8
Training loss: 0.791665796647514
Validation loss: 2.2619419428773155

Epoch: 5| Step: 9
Training loss: 0.6721964887570443
Validation loss: 2.2357370332941806

Epoch: 5| Step: 10
Training loss: 0.8564595446388206
Validation loss: 2.2928899723635867

Epoch: 583| Step: 0
Training loss: 0.5859234108820428
Validation loss: 2.2960856207629745

Epoch: 5| Step: 1
Training loss: 0.6901549962356023
Validation loss: 2.197423499849319

Epoch: 5| Step: 2
Training loss: 0.5446834521162379
Validation loss: 2.323696375516306

Epoch: 5| Step: 3
Training loss: 0.6787712235056856
Validation loss: 2.1987848072491287

Epoch: 5| Step: 4
Training loss: 0.5583120315910209
Validation loss: 2.2469827595587177

Epoch: 5| Step: 5
Training loss: 1.2629923342081755
Validation loss: 2.1733495947734456

Epoch: 5| Step: 6
Training loss: 0.5785145091806555
Validation loss: 2.2458214282379068

Epoch: 5| Step: 7
Training loss: 0.5822137892024795
Validation loss: 2.250547979820281

Epoch: 5| Step: 8
Training loss: 0.6801343742303686
Validation loss: 2.2000356107311294

Epoch: 5| Step: 9
Training loss: 0.6460602628247162
Validation loss: 2.1658311535242567

Epoch: 5| Step: 10
Training loss: 0.5641258109112454
Validation loss: 2.2377518197366317

Epoch: 584| Step: 0
Training loss: 0.7205165631907319
Validation loss: 2.2543224724489903

Epoch: 5| Step: 1
Training loss: 0.706219349255112
Validation loss: 2.31806017500384

Epoch: 5| Step: 2
Training loss: 0.673074051567911
Validation loss: 2.2532789898331527

Epoch: 5| Step: 3
Training loss: 0.7335337426421115
Validation loss: 2.2286507434319875

Epoch: 5| Step: 4
Training loss: 0.8455072400749174
Validation loss: 2.2793657075755243

Epoch: 5| Step: 5
Training loss: 0.7368206936640089
Validation loss: 2.2296258451360123

Epoch: 5| Step: 6
Training loss: 0.5684680376034238
Validation loss: 2.285579290884021

Epoch: 5| Step: 7
Training loss: 0.609541601246174
Validation loss: 2.2452595780809506

Epoch: 5| Step: 8
Training loss: 0.6493974726572838
Validation loss: 2.2569465644348976

Epoch: 5| Step: 9
Training loss: 0.5041923597845673
Validation loss: 2.249352092956512

Epoch: 5| Step: 10
Training loss: 1.3914357511551119
Validation loss: 2.2468053979228144

Epoch: 585| Step: 0
Training loss: 0.5349203550468413
Validation loss: 2.2510120025586065

Epoch: 5| Step: 1
Training loss: 0.7592588170971225
Validation loss: 2.2697917874888467

Epoch: 5| Step: 2
Training loss: 0.4661741851907944
Validation loss: 2.2675057519651927

Epoch: 5| Step: 3
Training loss: 0.8945198558098357
Validation loss: 2.2666370376186182

Epoch: 5| Step: 4
Training loss: 0.6463248064584656
Validation loss: 2.2433236046408416

Epoch: 5| Step: 5
Training loss: 0.8708403009078135
Validation loss: 2.234226355243269

Epoch: 5| Step: 6
Training loss: 0.7704180724435638
Validation loss: 2.2589652528648037

Epoch: 5| Step: 7
Training loss: 0.5138437251987833
Validation loss: 2.2165460291843773

Epoch: 5| Step: 8
Training loss: 0.47741577491614823
Validation loss: 2.185813200718428

Epoch: 5| Step: 9
Training loss: 1.3845532339159072
Validation loss: 2.2081541047488926

Epoch: 5| Step: 10
Training loss: 0.5246914320088973
Validation loss: 2.2489952780367144

Epoch: 586| Step: 0
Training loss: 0.8705370710872375
Validation loss: 2.1956463590828026

Epoch: 5| Step: 1
Training loss: 0.5093025062321106
Validation loss: 2.2633269029964205

Epoch: 5| Step: 2
Training loss: 1.3675326102516252
Validation loss: 2.243668266665779

Epoch: 5| Step: 3
Training loss: 0.6175472804358878
Validation loss: 2.212639790229895

Epoch: 5| Step: 4
Training loss: 0.7429023111282531
Validation loss: 2.3025626215978416

Epoch: 5| Step: 5
Training loss: 0.684367020442899
Validation loss: 2.2607864395750883

Epoch: 5| Step: 6
Training loss: 0.5833843299735949
Validation loss: 2.203683597169969

Epoch: 5| Step: 7
Training loss: 0.4992939911736532
Validation loss: 2.2398053180621633

Epoch: 5| Step: 8
Training loss: 0.6123929241552767
Validation loss: 2.2103761309390286

Epoch: 5| Step: 9
Training loss: 0.6971241142222178
Validation loss: 2.30634507905542

Epoch: 5| Step: 10
Training loss: 0.6890598937177782
Validation loss: 2.2397606915137325

Epoch: 587| Step: 0
Training loss: 0.5466981056765987
Validation loss: 2.294059162507333

Epoch: 5| Step: 1
Training loss: 1.3292259141319303
Validation loss: 2.254317891757853

Epoch: 5| Step: 2
Training loss: 0.5196119546948101
Validation loss: 2.2666927844044222

Epoch: 5| Step: 3
Training loss: 0.5321130474021537
Validation loss: 2.267824272016651

Epoch: 5| Step: 4
Training loss: 0.7169823679385382
Validation loss: 2.352700983153329

Epoch: 5| Step: 5
Training loss: 0.9062074453951814
Validation loss: 2.274938203859658

Epoch: 5| Step: 6
Training loss: 0.5766519906082003
Validation loss: 2.193603552292622

Epoch: 5| Step: 7
Training loss: 0.7877989368110991
Validation loss: 2.286096158536105

Epoch: 5| Step: 8
Training loss: 0.5294383518003641
Validation loss: 2.257048172524668

Epoch: 5| Step: 9
Training loss: 0.6733704712826803
Validation loss: 2.22113587191258

Epoch: 5| Step: 10
Training loss: 0.429148526718809
Validation loss: 2.2580919887223643

Epoch: 588| Step: 0
Training loss: 0.5409131004608907
Validation loss: 2.2039515168863275

Epoch: 5| Step: 1
Training loss: 0.7485418051905247
Validation loss: 2.291390641967025

Epoch: 5| Step: 2
Training loss: 0.45031705190884763
Validation loss: 2.2373281683645065

Epoch: 5| Step: 3
Training loss: 0.5307988888131694
Validation loss: 2.2797222070119

Epoch: 5| Step: 4
Training loss: 0.7814178286531551
Validation loss: 2.285891869710395

Epoch: 5| Step: 5
Training loss: 0.613126091251316
Validation loss: 2.3257220642962206

Epoch: 5| Step: 6
Training loss: 0.7976508010543639
Validation loss: 2.339161643760709

Epoch: 5| Step: 7
Training loss: 1.3371393697964484
Validation loss: 2.2246296951826707

Epoch: 5| Step: 8
Training loss: 0.5113130082007954
Validation loss: 2.3134789616075544

Epoch: 5| Step: 9
Training loss: 0.6574148784045285
Validation loss: 2.2650213232940235

Epoch: 5| Step: 10
Training loss: 0.6672825997894145
Validation loss: 2.1984527541416305

Epoch: 589| Step: 0
Training loss: 0.5355777611928092
Validation loss: 2.1787200079013838

Epoch: 5| Step: 1
Training loss: 0.5663173737349375
Validation loss: 2.2713022706527792

Epoch: 5| Step: 2
Training loss: 0.4529331722018547
Validation loss: 2.196698122814964

Epoch: 5| Step: 3
Training loss: 0.5985719982826352
Validation loss: 2.189300359949682

Epoch: 5| Step: 4
Training loss: 0.5965362726104319
Validation loss: 2.2195553136324437

Epoch: 5| Step: 5
Training loss: 0.5719296767981918
Validation loss: 2.2168848753612274

Epoch: 5| Step: 6
Training loss: 0.7253908123453665
Validation loss: 2.241236677725061

Epoch: 5| Step: 7
Training loss: 0.687083313118599
Validation loss: 2.164272784576675

Epoch: 5| Step: 8
Training loss: 0.5398082274302868
Validation loss: 2.2856831373255524

Epoch: 5| Step: 9
Training loss: 1.295254073533642
Validation loss: 2.231657658383354

Epoch: 5| Step: 10
Training loss: 0.7393351304049905
Validation loss: 2.290928256489414

Epoch: 590| Step: 0
Training loss: 0.4599252188839469
Validation loss: 2.2670690927846544

Epoch: 5| Step: 1
Training loss: 0.5107429752380248
Validation loss: 2.2423476295306983

Epoch: 5| Step: 2
Training loss: 0.7214271196366936
Validation loss: 2.24168273977048

Epoch: 5| Step: 3
Training loss: 0.6567687754305112
Validation loss: 2.2866873431065455

Epoch: 5| Step: 4
Training loss: 0.5422835383158378
Validation loss: 2.329055025566181

Epoch: 5| Step: 5
Training loss: 0.8027277665434718
Validation loss: 2.303575658920954

Epoch: 5| Step: 6
Training loss: 0.6207293995217018
Validation loss: 2.224964026749887

Epoch: 5| Step: 7
Training loss: 1.2845739651384895
Validation loss: 2.242619186531787

Epoch: 5| Step: 8
Training loss: 0.5900060922906205
Validation loss: 2.3284015555952005

Epoch: 5| Step: 9
Training loss: 0.7026717314436584
Validation loss: 2.285854632055163

Epoch: 5| Step: 10
Training loss: 0.7358428813261583
Validation loss: 2.2815622505685744

Epoch: 591| Step: 0
Training loss: 0.3875137211308451
Validation loss: 2.2285837000195694

Epoch: 5| Step: 1
Training loss: 0.6107834165568362
Validation loss: 2.302268229683831

Epoch: 5| Step: 2
Training loss: 0.671930488246823
Validation loss: 2.216127513379205

Epoch: 5| Step: 3
Training loss: 0.6397167140251299
Validation loss: 2.213804007130409

Epoch: 5| Step: 4
Training loss: 0.7620010635313487
Validation loss: 2.2547247647979103

Epoch: 5| Step: 5
Training loss: 0.5011426267466471
Validation loss: 2.3299749731981665

Epoch: 5| Step: 6
Training loss: 1.3959177001204777
Validation loss: 2.2461170214231707

Epoch: 5| Step: 7
Training loss: 0.5507833331995317
Validation loss: 2.2974466540688794

Epoch: 5| Step: 8
Training loss: 0.5106791353419536
Validation loss: 2.2869972741038547

Epoch: 5| Step: 9
Training loss: 0.5831199295379553
Validation loss: 2.233056269365722

Epoch: 5| Step: 10
Training loss: 0.5649084874538421
Validation loss: 2.2592625940816298

Epoch: 592| Step: 0
Training loss: 0.6996860753905704
Validation loss: 2.305875814105484

Epoch: 5| Step: 1
Training loss: 0.7435813263754855
Validation loss: 2.2868159191079114

Epoch: 5| Step: 2
Training loss: 0.49444413947097193
Validation loss: 2.262495652695842

Epoch: 5| Step: 3
Training loss: 0.76122091604213
Validation loss: 2.2528318497903324

Epoch: 5| Step: 4
Training loss: 0.8087198647451934
Validation loss: 2.2405572496868253

Epoch: 5| Step: 5
Training loss: 1.2191579576095635
Validation loss: 2.2689490556154426

Epoch: 5| Step: 6
Training loss: 0.605644717333485
Validation loss: 2.2583914751523007

Epoch: 5| Step: 7
Training loss: 0.4815696261780367
Validation loss: 2.3359305233202483

Epoch: 5| Step: 8
Training loss: 0.7781302915339579
Validation loss: 2.217727709861616

Epoch: 5| Step: 9
Training loss: 0.7181746626531497
Validation loss: 2.2312946273639267

Epoch: 5| Step: 10
Training loss: 0.5252395753093784
Validation loss: 2.257050317553338

Epoch: 593| Step: 0
Training loss: 0.7345595026577451
Validation loss: 2.231872775284786

Epoch: 5| Step: 1
Training loss: 0.549823252498299
Validation loss: 2.2910008832802045

Epoch: 5| Step: 2
Training loss: 0.5418506334363589
Validation loss: 2.2163423638298325

Epoch: 5| Step: 3
Training loss: 0.7267814224373522
Validation loss: 2.20057934817164

Epoch: 5| Step: 4
Training loss: 0.5688086238452793
Validation loss: 2.251288536119886

Epoch: 5| Step: 5
Training loss: 1.2747178457379011
Validation loss: 2.300462741924379

Epoch: 5| Step: 6
Training loss: 0.6034077174434433
Validation loss: 2.2335941411123525

Epoch: 5| Step: 7
Training loss: 0.6599933490996048
Validation loss: 2.30645446840272

Epoch: 5| Step: 8
Training loss: 0.5602001752882401
Validation loss: 2.203972417199322

Epoch: 5| Step: 9
Training loss: 0.6821516247558929
Validation loss: 2.2764906188552163

Epoch: 5| Step: 10
Training loss: 0.510867335083511
Validation loss: 2.234994560457698

Epoch: 594| Step: 0
Training loss: 0.6010167755270651
Validation loss: 2.195917628764904

Epoch: 5| Step: 1
Training loss: 0.6072540296622669
Validation loss: 2.1816282899657513

Epoch: 5| Step: 2
Training loss: 0.6478627886761227
Validation loss: 2.2256004904900006

Epoch: 5| Step: 3
Training loss: 0.8080053353865257
Validation loss: 2.220799169554868

Epoch: 5| Step: 4
Training loss: 0.7127510247653002
Validation loss: 2.2946178637592536

Epoch: 5| Step: 5
Training loss: 0.6270009197900648
Validation loss: 2.230122968801187

Epoch: 5| Step: 6
Training loss: 0.5338817372219636
Validation loss: 2.24059891468956

Epoch: 5| Step: 7
Training loss: 0.4549627689964366
Validation loss: 2.2419935801947632

Epoch: 5| Step: 8
Training loss: 1.2774522834421478
Validation loss: 2.1508132009562084

Epoch: 5| Step: 9
Training loss: 0.578168686943047
Validation loss: 2.2981096049274665

Epoch: 5| Step: 10
Training loss: 0.5062504733048099
Validation loss: 2.305095406112392

Epoch: 595| Step: 0
Training loss: 0.7426187166039024
Validation loss: 2.2236546000195534

Epoch: 5| Step: 1
Training loss: 0.5093021551362613
Validation loss: 2.225950772545275

Epoch: 5| Step: 2
Training loss: 0.5740280872843266
Validation loss: 2.312608316684524

Epoch: 5| Step: 3
Training loss: 1.2746752942570059
Validation loss: 2.283540123196206

Epoch: 5| Step: 4
Training loss: 0.6550773634249333
Validation loss: 2.247663780510397

Epoch: 5| Step: 5
Training loss: 0.4911606537277506
Validation loss: 2.250976685501361

Epoch: 5| Step: 6
Training loss: 0.7512843737616828
Validation loss: 2.278054000477553

Epoch: 5| Step: 7
Training loss: 0.5644848032579184
Validation loss: 2.146248861338807

Epoch: 5| Step: 8
Training loss: 0.48966897222234956
Validation loss: 2.2456698069916996

Epoch: 5| Step: 9
Training loss: 0.5884009646004551
Validation loss: 2.2352753682516773

Epoch: 5| Step: 10
Training loss: 0.6168051150775953
Validation loss: 2.222709686982389

Epoch: 596| Step: 0
Training loss: 0.8990627600941632
Validation loss: 2.266440878651548

Epoch: 5| Step: 1
Training loss: 0.4415460888295974
Validation loss: 2.2293627846943767

Epoch: 5| Step: 2
Training loss: 1.3695281129356096
Validation loss: 2.2577470072396997

Epoch: 5| Step: 3
Training loss: 0.5591842091571081
Validation loss: 2.1832825285943467

Epoch: 5| Step: 4
Training loss: 0.5789292128895475
Validation loss: 2.252253747007234

Epoch: 5| Step: 5
Training loss: 0.571521991944051
Validation loss: 2.2456003605405526

Epoch: 5| Step: 6
Training loss: 0.5845583643331076
Validation loss: 2.2357007892239626

Epoch: 5| Step: 7
Training loss: 0.4921780994062501
Validation loss: 2.2333142216243806

Epoch: 5| Step: 8
Training loss: 0.7041011180691104
Validation loss: 2.2126667723439137

Epoch: 5| Step: 9
Training loss: 0.4791576360459676
Validation loss: 2.2722038155555744

Epoch: 5| Step: 10
Training loss: 0.639941991173861
Validation loss: 2.2881667134910617

Epoch: 597| Step: 0
Training loss: 1.252711121664788
Validation loss: 2.283136316977465

Epoch: 5| Step: 1
Training loss: 0.7288657566610348
Validation loss: 2.2249326240152336

Epoch: 5| Step: 2
Training loss: 0.5535094417638552
Validation loss: 2.2206496743660216

Epoch: 5| Step: 3
Training loss: 0.5618085585148351
Validation loss: 2.2716940650060815

Epoch: 5| Step: 4
Training loss: 0.6037238295828304
Validation loss: 2.2301250345438177

Epoch: 5| Step: 5
Training loss: 0.8285464527918147
Validation loss: 2.20266302846779

Epoch: 5| Step: 6
Training loss: 0.7374807791710636
Validation loss: 2.2206952448642765

Epoch: 5| Step: 7
Training loss: 0.7281823917413067
Validation loss: 2.2665263984295128

Epoch: 5| Step: 8
Training loss: 0.5408118239398215
Validation loss: 2.1808400650945896

Epoch: 5| Step: 9
Training loss: 0.5842126253535979
Validation loss: 2.2569605778532167

Epoch: 5| Step: 10
Training loss: 0.48427979241175373
Validation loss: 2.2369365389871105

Epoch: 598| Step: 0
Training loss: 0.5939889226355788
Validation loss: 2.258871628369973

Epoch: 5| Step: 1
Training loss: 0.6743595405058164
Validation loss: 2.2541323500217922

Epoch: 5| Step: 2
Training loss: 0.5001270013686687
Validation loss: 2.313536521712832

Epoch: 5| Step: 3
Training loss: 0.4611219425043178
Validation loss: 2.243051767184659

Epoch: 5| Step: 4
Training loss: 0.616201240475343
Validation loss: 2.271212972167515

Epoch: 5| Step: 5
Training loss: 0.6128331874096472
Validation loss: 2.3130100611195887

Epoch: 5| Step: 6
Training loss: 0.6300534512536337
Validation loss: 2.2697927464007837

Epoch: 5| Step: 7
Training loss: 0.6187116177531858
Validation loss: 2.2575508548276533

Epoch: 5| Step: 8
Training loss: 1.2430243881883583
Validation loss: 2.1953796889092096

Epoch: 5| Step: 9
Training loss: 0.7034512504680944
Validation loss: 2.2801979528329404

Epoch: 5| Step: 10
Training loss: 0.6563403884764561
Validation loss: 2.2465169830839753

Epoch: 599| Step: 0
Training loss: 0.6213156825445447
Validation loss: 2.14214435523563

Epoch: 5| Step: 1
Training loss: 0.6717580649172529
Validation loss: 2.2275721300493276

Epoch: 5| Step: 2
Training loss: 0.8120736690890242
Validation loss: 2.2525001994579474

Epoch: 5| Step: 3
Training loss: 0.5085845360455998
Validation loss: 2.2184029561514107

Epoch: 5| Step: 4
Training loss: 1.2850880706233416
Validation loss: 2.2381789852289655

Epoch: 5| Step: 5
Training loss: 0.5394405753010784
Validation loss: 2.2142499130619817

Epoch: 5| Step: 6
Training loss: 0.6510760158378411
Validation loss: 2.18673141501558

Epoch: 5| Step: 7
Training loss: 0.7009929545588571
Validation loss: 2.216181900179959

Epoch: 5| Step: 8
Training loss: 0.7054686165067054
Validation loss: 2.237691640011358

Epoch: 5| Step: 9
Training loss: 0.6578236286735166
Validation loss: 2.263838042715713

Epoch: 5| Step: 10
Training loss: 0.5724189995430153
Validation loss: 2.2053148529204276

Epoch: 600| Step: 0
Training loss: 0.6664366076800717
Validation loss: 2.2934025079246663

Epoch: 5| Step: 1
Training loss: 0.6643964264465838
Validation loss: 2.2617397353778386

Epoch: 5| Step: 2
Training loss: 0.5606067904573824
Validation loss: 2.250763667251233

Epoch: 5| Step: 3
Training loss: 0.5375030462045625
Validation loss: 2.288814346574663

Epoch: 5| Step: 4
Training loss: 0.7399412596431696
Validation loss: 2.275750911488979

Epoch: 5| Step: 5
Training loss: 1.2646694579273792
Validation loss: 2.2418102552890975

Epoch: 5| Step: 6
Training loss: 0.6541625155379973
Validation loss: 2.156737069405065

Epoch: 5| Step: 7
Training loss: 0.5427536023590149
Validation loss: 2.2299207317258403

Epoch: 5| Step: 8
Training loss: 0.7926282104489735
Validation loss: 2.2479596189712523

Epoch: 5| Step: 9
Training loss: 0.6304867946306719
Validation loss: 2.2371753280622486

Epoch: 5| Step: 10
Training loss: 0.7494966486804389
Validation loss: 2.2051632332111475

Epoch: 601| Step: 0
Training loss: 0.6482610347498585
Validation loss: 2.2467200483139917

Epoch: 5| Step: 1
Training loss: 0.6581801684986145
Validation loss: 2.222319054117522

Epoch: 5| Step: 2
Training loss: 0.3014181132377236
Validation loss: 2.2573938859883507

Epoch: 5| Step: 3
Training loss: 1.3611458830165506
Validation loss: 2.21705898426495

Epoch: 5| Step: 4
Training loss: 0.6398547123865361
Validation loss: 2.2903825699169804

Epoch: 5| Step: 5
Training loss: 0.4887339210304477
Validation loss: 2.273119040756144

Epoch: 5| Step: 6
Training loss: 0.6261085930424537
Validation loss: 2.2526932870815264

Epoch: 5| Step: 7
Training loss: 0.6870227804696485
Validation loss: 2.1789939395303137

Epoch: 5| Step: 8
Training loss: 0.5877731307219
Validation loss: 2.2480457836505665

Epoch: 5| Step: 9
Training loss: 0.6042301922867174
Validation loss: 2.2474939228920943

Epoch: 5| Step: 10
Training loss: 0.5613223569994404
Validation loss: 2.2381543403743933

Epoch: 602| Step: 0
Training loss: 0.6249451136330803
Validation loss: 2.23840575761439

Epoch: 5| Step: 1
Training loss: 0.8178397556962577
Validation loss: 2.2042701954695803

Epoch: 5| Step: 2
Training loss: 0.4878927134582925
Validation loss: 2.2151229898530125

Epoch: 5| Step: 3
Training loss: 0.6088871347874105
Validation loss: 2.2679236773932634

Epoch: 5| Step: 4
Training loss: 0.6506571867838825
Validation loss: 2.208779992385461

Epoch: 5| Step: 5
Training loss: 0.6559651074317663
Validation loss: 2.1601569454557894

Epoch: 5| Step: 6
Training loss: 0.7195628586907952
Validation loss: 2.2055271109066537

Epoch: 5| Step: 7
Training loss: 0.5842779946008775
Validation loss: 2.2387768777004866

Epoch: 5| Step: 8
Training loss: 0.5342043185788243
Validation loss: 2.255080760693517

Epoch: 5| Step: 9
Training loss: 0.5357219462755256
Validation loss: 2.262163616685382

Epoch: 5| Step: 10
Training loss: 1.3478597293877748
Validation loss: 2.247545133664025

Epoch: 603| Step: 0
Training loss: 0.4837692379884171
Validation loss: 2.282646191345346

Epoch: 5| Step: 1
Training loss: 0.45367293278731946
Validation loss: 2.331705970317087

Epoch: 5| Step: 2
Training loss: 0.5207502076253417
Validation loss: 2.337504242138679

Epoch: 5| Step: 3
Training loss: 1.303935719517588
Validation loss: 2.1901021074617484

Epoch: 5| Step: 4
Training loss: 0.5847314757095391
Validation loss: 2.326333648935146

Epoch: 5| Step: 5
Training loss: 0.7137997617594503
Validation loss: 2.341296609923171

Epoch: 5| Step: 6
Training loss: 0.5358728775790348
Validation loss: 2.3001625642488697

Epoch: 5| Step: 7
Training loss: 0.7131347238344091
Validation loss: 2.3250141490038674

Epoch: 5| Step: 8
Training loss: 0.5293041665113397
Validation loss: 2.2146919804575385

Epoch: 5| Step: 9
Training loss: 0.649583057414109
Validation loss: 2.1555403174190957

Epoch: 5| Step: 10
Training loss: 0.5549536858814746
Validation loss: 2.252122283744729

Epoch: 604| Step: 0
Training loss: 0.5492588402996427
Validation loss: 2.182905155894053

Epoch: 5| Step: 1
Training loss: 0.6471917699049483
Validation loss: 2.2715402003288276

Epoch: 5| Step: 2
Training loss: 0.44449154989966366
Validation loss: 2.203074548720087

Epoch: 5| Step: 3
Training loss: 0.4684512616936033
Validation loss: 2.211349945111707

Epoch: 5| Step: 4
Training loss: 0.7132651821302983
Validation loss: 2.233043043891746

Epoch: 5| Step: 5
Training loss: 0.6154306734368342
Validation loss: 2.1816014504200028

Epoch: 5| Step: 6
Training loss: 0.5959669435745857
Validation loss: 2.189044288922022

Epoch: 5| Step: 7
Training loss: 0.7070462557217191
Validation loss: 2.193634126155987

Epoch: 5| Step: 8
Training loss: 0.4983406696316474
Validation loss: 2.236446801226034

Epoch: 5| Step: 9
Training loss: 1.364781993741819
Validation loss: 2.279054182505517

Epoch: 5| Step: 10
Training loss: 0.6560034061523724
Validation loss: 2.321807267159979

Epoch: 605| Step: 0
Training loss: 0.761918770375359
Validation loss: 2.2719371013913374

Epoch: 5| Step: 1
Training loss: 0.5267633988731661
Validation loss: 2.278874179256791

Epoch: 5| Step: 2
Training loss: 0.7289786414273656
Validation loss: 2.2926460608277575

Epoch: 5| Step: 3
Training loss: 0.47002661434363224
Validation loss: 2.300249957608572

Epoch: 5| Step: 4
Training loss: 0.7490452013496973
Validation loss: 2.2653664271290976

Epoch: 5| Step: 5
Training loss: 0.45564794270714376
Validation loss: 2.2877474472988717

Epoch: 5| Step: 6
Training loss: 0.5387081695567407
Validation loss: 2.203985706615164

Epoch: 5| Step: 7
Training loss: 0.6473804268470486
Validation loss: 2.222968471966883

Epoch: 5| Step: 8
Training loss: 1.1832753373203222
Validation loss: 2.2216346437759933

Epoch: 5| Step: 9
Training loss: 0.549623232451931
Validation loss: 2.2522546655793856

Epoch: 5| Step: 10
Training loss: 0.5546715693805426
Validation loss: 2.1881978470291

Epoch: 606| Step: 0
Training loss: 0.5810187833576294
Validation loss: 2.1943707630506317

Epoch: 5| Step: 1
Training loss: 0.6538681675476136
Validation loss: 2.2554281141336316

Epoch: 5| Step: 2
Training loss: 0.43384355789286927
Validation loss: 2.239851825948108

Epoch: 5| Step: 3
Training loss: 0.823515967551854
Validation loss: 2.253433511511289

Epoch: 5| Step: 4
Training loss: 0.510671869692595
Validation loss: 2.2458814631757478

Epoch: 5| Step: 5
Training loss: 0.4525905779023026
Validation loss: 2.2367195502955743

Epoch: 5| Step: 6
Training loss: 0.7293278152776046
Validation loss: 2.27460392895328

Epoch: 5| Step: 7
Training loss: 1.1736590220787346
Validation loss: 2.1877948661868207

Epoch: 5| Step: 8
Training loss: 0.421513473170967
Validation loss: 2.358177525515845

Epoch: 5| Step: 9
Training loss: 0.5795286768169364
Validation loss: 2.2317514860369214

Epoch: 5| Step: 10
Training loss: 0.6662958623907353
Validation loss: 2.3011617653849292

Epoch: 607| Step: 0
Training loss: 0.48252132487238736
Validation loss: 2.2716864531602248

Epoch: 5| Step: 1
Training loss: 0.5840316294047803
Validation loss: 2.279556442546791

Epoch: 5| Step: 2
Training loss: 0.7930583809243502
Validation loss: 2.2811237737998615

Epoch: 5| Step: 3
Training loss: 0.6723832049219353
Validation loss: 2.2505086941312435

Epoch: 5| Step: 4
Training loss: 1.2154981316505424
Validation loss: 2.271490390531801

Epoch: 5| Step: 5
Training loss: 0.5309200945465951
Validation loss: 2.2891398347544993

Epoch: 5| Step: 6
Training loss: 0.5093817891797662
Validation loss: 2.2166328132752753

Epoch: 5| Step: 7
Training loss: 0.6608589315046534
Validation loss: 2.2552946261233915

Epoch: 5| Step: 8
Training loss: 0.5972873821000645
Validation loss: 2.302808778607591

Epoch: 5| Step: 9
Training loss: 0.4425532200161828
Validation loss: 2.196707546081501

Epoch: 5| Step: 10
Training loss: 0.8922842531135984
Validation loss: 2.18224923302116

Epoch: 608| Step: 0
Training loss: 0.6538031693932236
Validation loss: 2.251901712785837

Epoch: 5| Step: 1
Training loss: 0.7604824891190551
Validation loss: 2.1815489278579685

Epoch: 5| Step: 2
Training loss: 0.38838503427253485
Validation loss: 2.2486439974710066

Epoch: 5| Step: 3
Training loss: 0.6984457079513905
Validation loss: 2.2391984346025358

Epoch: 5| Step: 4
Training loss: 1.3097124015536104
Validation loss: 2.187148881968266

Epoch: 5| Step: 5
Training loss: 0.5695566891194119
Validation loss: 2.189293822323644

Epoch: 5| Step: 6
Training loss: 0.7787439205856969
Validation loss: 2.3482087064235397

Epoch: 5| Step: 7
Training loss: 0.6058803512906724
Validation loss: 2.314467331878298

Epoch: 5| Step: 8
Training loss: 0.48386359135455564
Validation loss: 2.2496428684802594

Epoch: 5| Step: 9
Training loss: 0.5884219078716908
Validation loss: 2.3090062243240843

Epoch: 5| Step: 10
Training loss: 0.4605077421146397
Validation loss: 2.2037465907297866

Epoch: 609| Step: 0
Training loss: 0.7508921879667706
Validation loss: 2.2317296845175414

Epoch: 5| Step: 1
Training loss: 0.40088799451220797
Validation loss: 2.2627392844866683

Epoch: 5| Step: 2
Training loss: 0.6209115534882346
Validation loss: 2.2296098708024634

Epoch: 5| Step: 3
Training loss: 0.5611765976210151
Validation loss: 2.2306150747548035

Epoch: 5| Step: 4
Training loss: 1.2290595325828906
Validation loss: 2.258273495230755

Epoch: 5| Step: 5
Training loss: 0.56429394124037
Validation loss: 2.2140532747939505

Epoch: 5| Step: 6
Training loss: 0.565151561267272
Validation loss: 2.2891446162239824

Epoch: 5| Step: 7
Training loss: 0.3963998601125534
Validation loss: 2.2831303837817027

Epoch: 5| Step: 8
Training loss: 0.9581358160116372
Validation loss: 2.268623566885051

Epoch: 5| Step: 9
Training loss: 0.6698545416533712
Validation loss: 2.296041616912098

Epoch: 5| Step: 10
Training loss: 0.5806876682342427
Validation loss: 2.174965776318733

Epoch: 610| Step: 0
Training loss: 0.4972740759959244
Validation loss: 2.1979190779941358

Epoch: 5| Step: 1
Training loss: 0.5341098607259196
Validation loss: 2.259578570066729

Epoch: 5| Step: 2
Training loss: 1.2410796401407918
Validation loss: 2.2121405953655673

Epoch: 5| Step: 3
Training loss: 0.6492552139930694
Validation loss: 2.260257255052251

Epoch: 5| Step: 4
Training loss: 0.7269414918225979
Validation loss: 2.2458558264114754

Epoch: 5| Step: 5
Training loss: 0.7069641840197598
Validation loss: 2.2928660575677733

Epoch: 5| Step: 6
Training loss: 0.5322377614934152
Validation loss: 2.2706757684891

Epoch: 5| Step: 7
Training loss: 0.6485552623396768
Validation loss: 2.262853305389016

Epoch: 5| Step: 8
Training loss: 0.5816402786284595
Validation loss: 2.2564819386022763

Epoch: 5| Step: 9
Training loss: 0.518711676962982
Validation loss: 2.2932979993513976

Epoch: 5| Step: 10
Training loss: 0.6108421856220096
Validation loss: 2.2588329907921976

Epoch: 611| Step: 0
Training loss: 0.5747702149797319
Validation loss: 2.270113365091346

Epoch: 5| Step: 1
Training loss: 0.5936900158748616
Validation loss: 2.285433784082967

Epoch: 5| Step: 2
Training loss: 0.5283919477991337
Validation loss: 2.2579509438462533

Epoch: 5| Step: 3
Training loss: 0.5158998450454062
Validation loss: 2.212079535775331

Epoch: 5| Step: 4
Training loss: 0.6012146674895511
Validation loss: 2.2958869363097674

Epoch: 5| Step: 5
Training loss: 0.5776179899918398
Validation loss: 2.2593647271913353

Epoch: 5| Step: 6
Training loss: 0.6240692121883066
Validation loss: 2.2078571255008703

Epoch: 5| Step: 7
Training loss: 1.1197779573296276
Validation loss: 2.1845601409771103

Epoch: 5| Step: 8
Training loss: 0.8241758651785788
Validation loss: 2.196987319147765

Epoch: 5| Step: 9
Training loss: 0.6632125576290822
Validation loss: 2.23794363159609

Epoch: 5| Step: 10
Training loss: 0.5221566713593863
Validation loss: 2.2208665861988557

Epoch: 612| Step: 0
Training loss: 0.5387133144624683
Validation loss: 2.2069041754326175

Epoch: 5| Step: 1
Training loss: 0.5806804060600687
Validation loss: 2.2151674773857177

Epoch: 5| Step: 2
Training loss: 0.6082696426267934
Validation loss: 2.2880300587216302

Epoch: 5| Step: 3
Training loss: 0.7894673961045995
Validation loss: 2.234237534722986

Epoch: 5| Step: 4
Training loss: 0.5683914909596338
Validation loss: 2.2599898501908857

Epoch: 5| Step: 5
Training loss: 0.6525990334989106
Validation loss: 2.297255037527049

Epoch: 5| Step: 6
Training loss: 1.2595726634255178
Validation loss: 2.3131460070721572

Epoch: 5| Step: 7
Training loss: 0.4802704223438882
Validation loss: 2.306979524631595

Epoch: 5| Step: 8
Training loss: 0.6781376894629383
Validation loss: 2.2573810285334366

Epoch: 5| Step: 9
Training loss: 0.6429098832354995
Validation loss: 2.2694921409853785

Epoch: 5| Step: 10
Training loss: 0.4475705136254384
Validation loss: 2.2809727795736983

Epoch: 613| Step: 0
Training loss: 0.605530323466279
Validation loss: 2.250625574659119

Epoch: 5| Step: 1
Training loss: 0.7717272026246343
Validation loss: 2.17722280740203

Epoch: 5| Step: 2
Training loss: 0.4468821084850977
Validation loss: 2.2827129620512556

Epoch: 5| Step: 3
Training loss: 1.2269651395980072
Validation loss: 2.2409963520565053

Epoch: 5| Step: 4
Training loss: 0.6065334188495346
Validation loss: 2.25069263922222

Epoch: 5| Step: 5
Training loss: 0.6587707833661576
Validation loss: 2.2228793077300875

Epoch: 5| Step: 6
Training loss: 0.6617147119031825
Validation loss: 2.2522708765519237

Epoch: 5| Step: 7
Training loss: 0.5447273590858956
Validation loss: 2.26480399741744

Epoch: 5| Step: 8
Training loss: 0.5273403026326844
Validation loss: 2.2875285418445794

Epoch: 5| Step: 9
Training loss: 0.6323450033535046
Validation loss: 2.222748303716195

Epoch: 5| Step: 10
Training loss: 0.6536024137465802
Validation loss: 2.1838988316780616

Epoch: 614| Step: 0
Training loss: 0.49134633679998835
Validation loss: 2.189874124238217

Epoch: 5| Step: 1
Training loss: 0.445850348667814
Validation loss: 2.241846512082329

Epoch: 5| Step: 2
Training loss: 0.6254343192701141
Validation loss: 2.1657885265932775

Epoch: 5| Step: 3
Training loss: 0.4960075664000825
Validation loss: 2.2202978152908694

Epoch: 5| Step: 4
Training loss: 0.5676302608270561
Validation loss: 2.198247549786891

Epoch: 5| Step: 5
Training loss: 0.7948583629083021
Validation loss: 2.238470957309192

Epoch: 5| Step: 6
Training loss: 0.6827798848688266
Validation loss: 2.2858851417881305

Epoch: 5| Step: 7
Training loss: 0.4886393492780851
Validation loss: 2.166134288102114

Epoch: 5| Step: 8
Training loss: 0.6119696569042054
Validation loss: 2.2275885333051195

Epoch: 5| Step: 9
Training loss: 1.1981280706980184
Validation loss: 2.286235770369945

Epoch: 5| Step: 10
Training loss: 0.3617861962930505
Validation loss: 2.2510835973370713

Epoch: 615| Step: 0
Training loss: 0.4678273657690075
Validation loss: 2.1536690530096756

Epoch: 5| Step: 1
Training loss: 0.6114960704858121
Validation loss: 2.2671425958393825

Epoch: 5| Step: 2
Training loss: 0.7538859310277968
Validation loss: 2.287918958172811

Epoch: 5| Step: 3
Training loss: 0.49420326951584514
Validation loss: 2.184916740318528

Epoch: 5| Step: 4
Training loss: 0.6154142813054136
Validation loss: 2.2284690502135325

Epoch: 5| Step: 5
Training loss: 0.6382743695003806
Validation loss: 2.2316625176358653

Epoch: 5| Step: 6
Training loss: 0.6672091933929205
Validation loss: 2.2017344183166223

Epoch: 5| Step: 7
Training loss: 1.2859724056285287
Validation loss: 2.2246679444008826

Epoch: 5| Step: 8
Training loss: 0.5139720895217688
Validation loss: 2.2479903020315666

Epoch: 5| Step: 9
Training loss: 0.5788116243893552
Validation loss: 2.269854944358684

Epoch: 5| Step: 10
Training loss: 0.5588965762194065
Validation loss: 2.2008697409851132

Epoch: 616| Step: 0
Training loss: 0.4447768319073403
Validation loss: 2.194387488090945

Epoch: 5| Step: 1
Training loss: 0.6449501525853293
Validation loss: 2.1928821514605437

Epoch: 5| Step: 2
Training loss: 0.4669682335862528
Validation loss: 2.197429204213825

Epoch: 5| Step: 3
Training loss: 0.5731874923997221
Validation loss: 2.2076130679356365

Epoch: 5| Step: 4
Training loss: 0.7024506832270179
Validation loss: 2.219886004835784

Epoch: 5| Step: 5
Training loss: 0.5856095731529243
Validation loss: 2.2643307370573478

Epoch: 5| Step: 6
Training loss: 0.7022032311803303
Validation loss: 2.2906066139460464

Epoch: 5| Step: 7
Training loss: 0.6294008288723192
Validation loss: 2.270437817102742

Epoch: 5| Step: 8
Training loss: 0.5205717351714622
Validation loss: 2.2593717179021886

Epoch: 5| Step: 9
Training loss: 1.2834745030146142
Validation loss: 2.2548492063471697

Epoch: 5| Step: 10
Training loss: 0.5067307908906321
Validation loss: 2.2579405119169698

Epoch: 617| Step: 0
Training loss: 0.6483321046776721
Validation loss: 2.26702837508548

Epoch: 5| Step: 1
Training loss: 1.1803222868344199
Validation loss: 2.1863954653149493

Epoch: 5| Step: 2
Training loss: 0.3844962556827816
Validation loss: 2.1663674778243727

Epoch: 5| Step: 3
Training loss: 0.6750151641343286
Validation loss: 2.2770943425675365

Epoch: 5| Step: 4
Training loss: 0.5190641842056317
Validation loss: 2.1741685493786935

Epoch: 5| Step: 5
Training loss: 0.7047043335251008
Validation loss: 2.2007804420873893

Epoch: 5| Step: 6
Training loss: 0.706370408419414
Validation loss: 2.239464275365353

Epoch: 5| Step: 7
Training loss: 0.5516429140081
Validation loss: 2.267558365493621

Epoch: 5| Step: 8
Training loss: 0.48968167703814386
Validation loss: 2.1967076721215744

Epoch: 5| Step: 9
Training loss: 0.7411414956997765
Validation loss: 2.22729688075074

Epoch: 5| Step: 10
Training loss: 0.6223823327764348
Validation loss: 2.1842212334931603

Epoch: 618| Step: 0
Training loss: 0.5375168797703523
Validation loss: 2.194832571966153

Epoch: 5| Step: 1
Training loss: 0.691788088432012
Validation loss: 2.265582723085201

Epoch: 5| Step: 2
Training loss: 1.3308399500211612
Validation loss: 2.2997824665437636

Epoch: 5| Step: 3
Training loss: 0.5476308775940985
Validation loss: 2.302611904538267

Epoch: 5| Step: 4
Training loss: 0.49551193782907016
Validation loss: 2.312270879550259

Epoch: 5| Step: 5
Training loss: 0.7424246158286331
Validation loss: 2.2590606665051487

Epoch: 5| Step: 6
Training loss: 0.4835516022293247
Validation loss: 2.3103347614524123

Epoch: 5| Step: 7
Training loss: 0.5859730773297271
Validation loss: 2.2757635536357865

Epoch: 5| Step: 8
Training loss: 0.4898451517623484
Validation loss: 2.2758848453962246

Epoch: 5| Step: 9
Training loss: 0.5494098499080997
Validation loss: 2.172892851576076

Epoch: 5| Step: 10
Training loss: 0.9152447806144131
Validation loss: 2.192889990085035

Epoch: 619| Step: 0
Training loss: 0.5390894786330933
Validation loss: 2.260869401943915

Epoch: 5| Step: 1
Training loss: 0.7127815058557755
Validation loss: 2.2712065800248467

Epoch: 5| Step: 2
Training loss: 0.7196058899378124
Validation loss: 2.2006697327959532

Epoch: 5| Step: 3
Training loss: 0.5688403215058243
Validation loss: 2.219848181943277

Epoch: 5| Step: 4
Training loss: 0.6459101405668146
Validation loss: 2.2350969388133084

Epoch: 5| Step: 5
Training loss: 0.5719345749638616
Validation loss: 2.2612086685831154

Epoch: 5| Step: 6
Training loss: 0.5635050430901466
Validation loss: 2.2611645568554652

Epoch: 5| Step: 7
Training loss: 0.5133169129870643
Validation loss: 2.2627652426321387

Epoch: 5| Step: 8
Training loss: 0.5162039887288588
Validation loss: 2.3022359343552212

Epoch: 5| Step: 9
Training loss: 1.321481672346806
Validation loss: 2.250203721589435

Epoch: 5| Step: 10
Training loss: 0.6816596872894221
Validation loss: 2.303602033297407

Epoch: 620| Step: 0
Training loss: 0.44373923678172555
Validation loss: 2.2864500982740914

Epoch: 5| Step: 1
Training loss: 0.6650193893502824
Validation loss: 2.228674997024445

Epoch: 5| Step: 2
Training loss: 1.1840451327208288
Validation loss: 2.2551816764286197

Epoch: 5| Step: 3
Training loss: 0.7309838177315767
Validation loss: 2.201137966512797

Epoch: 5| Step: 4
Training loss: 0.6169526824427883
Validation loss: 2.209358963534901

Epoch: 5| Step: 5
Training loss: 0.4087553897117357
Validation loss: 2.305702758663926

Epoch: 5| Step: 6
Training loss: 0.6210699256790104
Validation loss: 2.2567772436143345

Epoch: 5| Step: 7
Training loss: 0.5715872744305585
Validation loss: 2.2382118377405607

Epoch: 5| Step: 8
Training loss: 0.8400493281503718
Validation loss: 2.2631135162545992

Epoch: 5| Step: 9
Training loss: 0.5027656065303066
Validation loss: 2.211378961876983

Epoch: 5| Step: 10
Training loss: 0.49767844840804015
Validation loss: 2.245082978982201

Epoch: 621| Step: 0
Training loss: 0.4792498036146881
Validation loss: 2.201125663871108

Epoch: 5| Step: 1
Training loss: 0.6956827913597379
Validation loss: 2.2907820604231173

Epoch: 5| Step: 2
Training loss: 0.47527423646943906
Validation loss: 2.2990341881076843

Epoch: 5| Step: 3
Training loss: 0.532284514745553
Validation loss: 2.3139205699981256

Epoch: 5| Step: 4
Training loss: 1.2530157426878743
Validation loss: 2.2794454373466744

Epoch: 5| Step: 5
Training loss: 0.5113055475552905
Validation loss: 2.2374015038014936

Epoch: 5| Step: 6
Training loss: 0.5669615555602037
Validation loss: 2.2146970841372546

Epoch: 5| Step: 7
Training loss: 0.5893875530520154
Validation loss: 2.2620927205119896

Epoch: 5| Step: 8
Training loss: 0.6430306739698879
Validation loss: 2.293351448105705

Epoch: 5| Step: 9
Training loss: 0.6737441964333009
Validation loss: 2.1570462728305557

Epoch: 5| Step: 10
Training loss: 0.5418868228806136
Validation loss: 2.1943888970260716

Epoch: 622| Step: 0
Training loss: 0.7809797964132623
Validation loss: 2.3061515522530938

Epoch: 5| Step: 1
Training loss: 0.5287052522035854
Validation loss: 2.1888936292730485

Epoch: 5| Step: 2
Training loss: 0.6560623945287181
Validation loss: 2.2195351173606945

Epoch: 5| Step: 3
Training loss: 0.6211413239306794
Validation loss: 2.3301402238090767

Epoch: 5| Step: 4
Training loss: 0.6087557996830009
Validation loss: 2.288847961978145

Epoch: 5| Step: 5
Training loss: 0.5581811301274022
Validation loss: 2.225333625430553

Epoch: 5| Step: 6
Training loss: 0.6814601845183069
Validation loss: 2.217453778583553

Epoch: 5| Step: 7
Training loss: 1.1367182256428665
Validation loss: 2.2269052721995024

Epoch: 5| Step: 8
Training loss: 0.6628165055818938
Validation loss: 2.209421234266726

Epoch: 5| Step: 9
Training loss: 0.38912695691639543
Validation loss: 2.2774169495847683

Epoch: 5| Step: 10
Training loss: 0.5242520726808279
Validation loss: 2.217085154056934

Epoch: 623| Step: 0
Training loss: 0.5097379713486743
Validation loss: 2.2463495717506023

Epoch: 5| Step: 1
Training loss: 0.6449735106713868
Validation loss: 2.2726491577487637

Epoch: 5| Step: 2
Training loss: 0.6839994697931253
Validation loss: 2.1877693151119235

Epoch: 5| Step: 3
Training loss: 0.4886020217112368
Validation loss: 2.2532591202929586

Epoch: 5| Step: 4
Training loss: 0.6019535032514984
Validation loss: 2.2311291078529516

Epoch: 5| Step: 5
Training loss: 1.0622471901310373
Validation loss: 2.259749234657571

Epoch: 5| Step: 6
Training loss: 0.5025548037729697
Validation loss: 2.1804321595444285

Epoch: 5| Step: 7
Training loss: 0.6836502051883306
Validation loss: 2.212242923505589

Epoch: 5| Step: 8
Training loss: 0.523745716505356
Validation loss: 2.236529823955418

Epoch: 5| Step: 9
Training loss: 0.6234154403340295
Validation loss: 2.2284767475561837

Epoch: 5| Step: 10
Training loss: 0.522996431956693
Validation loss: 2.1798145393748567

Epoch: 624| Step: 0
Training loss: 0.4961379925080719
Validation loss: 2.2489553234466997

Epoch: 5| Step: 1
Training loss: 0.760827232376768
Validation loss: 2.2451369486821036

Epoch: 5| Step: 2
Training loss: 0.614468342858776
Validation loss: 2.2922134834015417

Epoch: 5| Step: 3
Training loss: 0.5857497359473447
Validation loss: 2.2448589835532484

Epoch: 5| Step: 4
Training loss: 0.5890059679260107
Validation loss: 2.197985983694814

Epoch: 5| Step: 5
Training loss: 0.5998044271415759
Validation loss: 2.133790864674075

Epoch: 5| Step: 6
Training loss: 1.2721902554996853
Validation loss: 2.2159437058444325

Epoch: 5| Step: 7
Training loss: 0.681301327617891
Validation loss: 2.1980902058937333

Epoch: 5| Step: 8
Training loss: 0.47184145662945537
Validation loss: 2.1788788370588885

Epoch: 5| Step: 9
Training loss: 0.5281823448784515
Validation loss: 2.250488294350209

Epoch: 5| Step: 10
Training loss: 0.5152626787557149
Validation loss: 2.242224871173325

Epoch: 625| Step: 0
Training loss: 0.4404503929532234
Validation loss: 2.2292017592285305

Epoch: 5| Step: 1
Training loss: 0.564628098767121
Validation loss: 2.137537190947867

Epoch: 5| Step: 2
Training loss: 0.6034156691851109
Validation loss: 2.2306032179942146

Epoch: 5| Step: 3
Training loss: 1.173088208669804
Validation loss: 2.213986565157348

Epoch: 5| Step: 4
Training loss: 0.46049656225116226
Validation loss: 2.1677439813963146

Epoch: 5| Step: 5
Training loss: 0.5500638361211256
Validation loss: 2.2739193093589063

Epoch: 5| Step: 6
Training loss: 0.6043555824845047
Validation loss: 2.2522084496666697

Epoch: 5| Step: 7
Training loss: 0.5757701960709882
Validation loss: 2.2498442505922642

Epoch: 5| Step: 8
Training loss: 0.5066639161767255
Validation loss: 2.2043075930841436

Epoch: 5| Step: 9
Training loss: 0.6149834499613375
Validation loss: 2.1903032608863495

Epoch: 5| Step: 10
Training loss: 0.4833272862330148
Validation loss: 2.2014801918519606

Epoch: 626| Step: 0
Training loss: 0.6002060595964421
Validation loss: 2.2462422565517994

Epoch: 5| Step: 1
Training loss: 0.5051053587850343
Validation loss: 2.25144475608656

Epoch: 5| Step: 2
Training loss: 0.6029593857994205
Validation loss: 2.24461372453854

Epoch: 5| Step: 3
Training loss: 0.46614456886958244
Validation loss: 2.3144820636964876

Epoch: 5| Step: 4
Training loss: 0.5856451195158429
Validation loss: 2.2357461813660877

Epoch: 5| Step: 5
Training loss: 0.46288238389288416
Validation loss: 2.3016678594773694

Epoch: 5| Step: 6
Training loss: 0.6745734474144187
Validation loss: 2.27994999948391

Epoch: 5| Step: 7
Training loss: 0.6876768404931808
Validation loss: 2.3196194316873036

Epoch: 5| Step: 8
Training loss: 0.5054959497695142
Validation loss: 2.3019001897694493

Epoch: 5| Step: 9
Training loss: 1.22385364923486
Validation loss: 2.341103538618339

Epoch: 5| Step: 10
Training loss: 0.3333882259331386
Validation loss: 2.2712917668571255

Epoch: 627| Step: 0
Training loss: 0.6100214683553989
Validation loss: 2.1964771934286933

Epoch: 5| Step: 1
Training loss: 0.6442334729903253
Validation loss: 2.2650444160979233

Epoch: 5| Step: 2
Training loss: 1.141071597942951
Validation loss: 2.247107622433392

Epoch: 5| Step: 3
Training loss: 0.6608492357193472
Validation loss: 2.2211232829899457

Epoch: 5| Step: 4
Training loss: 0.614982165760327
Validation loss: 2.2261638049084382

Epoch: 5| Step: 5
Training loss: 0.7500658006413491
Validation loss: 2.27739368899614

Epoch: 5| Step: 6
Training loss: 0.524134385530523
Validation loss: 2.252000509580957

Epoch: 5| Step: 7
Training loss: 0.41495048026427017
Validation loss: 2.260475360563321

Epoch: 5| Step: 8
Training loss: 0.37101905472552404
Validation loss: 2.2879581914434066

Epoch: 5| Step: 9
Training loss: 0.5436043346895355
Validation loss: 2.2144905881321004

Epoch: 5| Step: 10
Training loss: 0.544116583934558
Validation loss: 2.284307551713543

Epoch: 628| Step: 0
Training loss: 0.632197564007713
Validation loss: 2.2597836375060383

Epoch: 5| Step: 1
Training loss: 0.6508013141740145
Validation loss: 2.3338314863585574

Epoch: 5| Step: 2
Training loss: 0.659849061540331
Validation loss: 2.2564184199214092

Epoch: 5| Step: 3
Training loss: 0.5475865503382208
Validation loss: 2.2869355031324483

Epoch: 5| Step: 4
Training loss: 1.3196990263876127
Validation loss: 2.220585741735246

Epoch: 5| Step: 5
Training loss: 0.5988780976885975
Validation loss: 2.1781312195113003

Epoch: 5| Step: 6
Training loss: 0.4621750656735362
Validation loss: 2.2247969456031114

Epoch: 5| Step: 7
Training loss: 0.7218244146813236
Validation loss: 2.205542806345697

Epoch: 5| Step: 8
Training loss: 0.6187014541462762
Validation loss: 2.266448492278842

Epoch: 5| Step: 9
Training loss: 0.4187235567654155
Validation loss: 2.1746216807172734

Epoch: 5| Step: 10
Training loss: 0.5877525192719487
Validation loss: 2.267477548422539

Epoch: 629| Step: 0
Training loss: 0.48979364774696266
Validation loss: 2.2106071192567107

Epoch: 5| Step: 1
Training loss: 0.6303020176467424
Validation loss: 2.311460247943936

Epoch: 5| Step: 2
Training loss: 0.47444638251707355
Validation loss: 2.2419430556353506

Epoch: 5| Step: 3
Training loss: 0.5597060273648639
Validation loss: 2.267385512923179

Epoch: 5| Step: 4
Training loss: 1.192797189703713
Validation loss: 2.281054612154822

Epoch: 5| Step: 5
Training loss: 0.5344369885813917
Validation loss: 2.2697696770583686

Epoch: 5| Step: 6
Training loss: 0.501991122102694
Validation loss: 2.3977738392465127

Epoch: 5| Step: 7
Training loss: 0.5789257380902914
Validation loss: 2.285811913931615

Epoch: 5| Step: 8
Training loss: 0.6055312339781531
Validation loss: 2.274813530875267

Epoch: 5| Step: 9
Training loss: 0.7244665616929676
Validation loss: 2.3129220187770283

Epoch: 5| Step: 10
Training loss: 0.6859475293653662
Validation loss: 2.216893673354966

Epoch: 630| Step: 0
Training loss: 0.6543055747293597
Validation loss: 2.3185806537182394

Epoch: 5| Step: 1
Training loss: 0.5091045375395473
Validation loss: 2.226618033124791

Epoch: 5| Step: 2
Training loss: 0.6012195501329626
Validation loss: 2.247167024072637

Epoch: 5| Step: 3
Training loss: 0.5617788248208724
Validation loss: 2.2276558696314073

Epoch: 5| Step: 4
Training loss: 1.292196037144349
Validation loss: 2.2116232130096667

Epoch: 5| Step: 5
Training loss: 0.48842612596815427
Validation loss: 2.2608075753505017

Epoch: 5| Step: 6
Training loss: 0.5475731344454142
Validation loss: 2.2563933664326625

Epoch: 5| Step: 7
Training loss: 0.5774378946275929
Validation loss: 2.1838663184122415

Epoch: 5| Step: 8
Training loss: 0.6605561529282861
Validation loss: 2.2297245228859546

Epoch: 5| Step: 9
Training loss: 0.511459313940078
Validation loss: 2.1960578079245487

Epoch: 5| Step: 10
Training loss: 0.4620963577668506
Validation loss: 2.234222885095227

Epoch: 631| Step: 0
Training loss: 0.4769170724050629
Validation loss: 2.24616165978707

Epoch: 5| Step: 1
Training loss: 0.441599963732343
Validation loss: 2.2204235714564917

Epoch: 5| Step: 2
Training loss: 0.5361277262128524
Validation loss: 2.262644216885632

Epoch: 5| Step: 3
Training loss: 0.5305873440522555
Validation loss: 2.248858673959742

Epoch: 5| Step: 4
Training loss: 0.5849498563044873
Validation loss: 2.294023498483179

Epoch: 5| Step: 5
Training loss: 0.7533545971150941
Validation loss: 2.1831425877581823

Epoch: 5| Step: 6
Training loss: 0.49638643416734846
Validation loss: 2.238062428342934

Epoch: 5| Step: 7
Training loss: 0.44615565336459656
Validation loss: 2.2433529706414013

Epoch: 5| Step: 8
Training loss: 0.42501462813054636
Validation loss: 2.2261229942864196

Epoch: 5| Step: 9
Training loss: 0.7524981220513417
Validation loss: 2.3392281416227236

Epoch: 5| Step: 10
Training loss: 1.2664274803420024
Validation loss: 2.238719540278732

Epoch: 632| Step: 0
Training loss: 0.6244634948197801
Validation loss: 2.1913612555154156

Epoch: 5| Step: 1
Training loss: 1.2716469843846572
Validation loss: 2.2246223717332487

Epoch: 5| Step: 2
Training loss: 0.5202092500718543
Validation loss: 2.233078163552426

Epoch: 5| Step: 3
Training loss: 0.5174970455361768
Validation loss: 2.2076891526266618

Epoch: 5| Step: 4
Training loss: 0.5233329554675898
Validation loss: 2.1989915155144133

Epoch: 5| Step: 5
Training loss: 0.5704825683357853
Validation loss: 2.250601464780983

Epoch: 5| Step: 6
Training loss: 0.4336025305881327
Validation loss: 2.2584838414116684

Epoch: 5| Step: 7
Training loss: 0.6293105253589644
Validation loss: 2.200945536378278

Epoch: 5| Step: 8
Training loss: 0.40183027149061307
Validation loss: 2.258586589754366

Epoch: 5| Step: 9
Training loss: 0.4974374970034568
Validation loss: 2.2199583343716935

Epoch: 5| Step: 10
Training loss: 0.7225232801019679
Validation loss: 2.182052004331085

Epoch: 633| Step: 0
Training loss: 0.4937264436824606
Validation loss: 2.1998226253446242

Epoch: 5| Step: 1
Training loss: 0.4745043728690244
Validation loss: 2.2378980159652686

Epoch: 5| Step: 2
Training loss: 1.3063847814501628
Validation loss: 2.2396889594186784

Epoch: 5| Step: 3
Training loss: 0.6393762839445197
Validation loss: 2.2546399605805525

Epoch: 5| Step: 4
Training loss: 0.524104191959083
Validation loss: 2.1989103830473504

Epoch: 5| Step: 5
Training loss: 0.7243246254178822
Validation loss: 2.301872924965197

Epoch: 5| Step: 6
Training loss: 0.4965549938001879
Validation loss: 2.283679278356944

Epoch: 5| Step: 7
Training loss: 0.606559828605449
Validation loss: 2.1923814589886814

Epoch: 5| Step: 8
Training loss: 0.5651837276816699
Validation loss: 2.3124379452064994

Epoch: 5| Step: 9
Training loss: 0.740011659800971
Validation loss: 2.249242003178536

Epoch: 5| Step: 10
Training loss: 0.4349156753978018
Validation loss: 2.241371431894742

Epoch: 634| Step: 0
Training loss: 0.4674430907132272
Validation loss: 2.2810666590349196

Epoch: 5| Step: 1
Training loss: 0.690099764156094
Validation loss: 2.203874342903792

Epoch: 5| Step: 2
Training loss: 0.5573814949534972
Validation loss: 2.2574111519876903

Epoch: 5| Step: 3
Training loss: 0.5366305071878934
Validation loss: 2.2016024047073572

Epoch: 5| Step: 4
Training loss: 0.5680725579980399
Validation loss: 2.2260275139932837

Epoch: 5| Step: 5
Training loss: 0.630987384670036
Validation loss: 2.249118470449799

Epoch: 5| Step: 6
Training loss: 0.7892564591828288
Validation loss: 2.2067092560435735

Epoch: 5| Step: 7
Training loss: 1.1844709815435641
Validation loss: 2.1570453755159704

Epoch: 5| Step: 8
Training loss: 0.6179533444110772
Validation loss: 2.173857262282733

Epoch: 5| Step: 9
Training loss: 0.5947252095023865
Validation loss: 2.164398655323732

Epoch: 5| Step: 10
Training loss: 0.41023878447865864
Validation loss: 2.224263776708121

Epoch: 635| Step: 0
Training loss: 0.4107661481064083
Validation loss: 2.2071601942536336

Epoch: 5| Step: 1
Training loss: 1.1764106966649799
Validation loss: 2.230549421310376

Epoch: 5| Step: 2
Training loss: 0.5178395888449293
Validation loss: 2.2853638560203664

Epoch: 5| Step: 3
Training loss: 0.677315574332773
Validation loss: 2.274442855755629

Epoch: 5| Step: 4
Training loss: 0.402500381351077
Validation loss: 2.301924514099206

Epoch: 5| Step: 5
Training loss: 0.5757494913812031
Validation loss: 2.258465470623254

Epoch: 5| Step: 6
Training loss: 0.5996941124500329
Validation loss: 2.2269949924214822

Epoch: 5| Step: 7
Training loss: 0.4826181298265632
Validation loss: 2.2123446142138916

Epoch: 5| Step: 8
Training loss: 0.6650708340801186
Validation loss: 2.1807220399696625

Epoch: 5| Step: 9
Training loss: 0.5436250575985048
Validation loss: 2.213881096098999

Epoch: 5| Step: 10
Training loss: 0.7027221373276527
Validation loss: 2.2092439484780746

Epoch: 636| Step: 0
Training loss: 0.661796203187834
Validation loss: 2.298261939021287

Epoch: 5| Step: 1
Training loss: 0.6987613055384273
Validation loss: 2.296720946470184

Epoch: 5| Step: 2
Training loss: 0.46811795538782625
Validation loss: 2.220974453132154

Epoch: 5| Step: 3
Training loss: 0.6860093950206587
Validation loss: 2.259417266488939

Epoch: 5| Step: 4
Training loss: 0.5424824464832311
Validation loss: 2.2491806126600986

Epoch: 5| Step: 5
Training loss: 0.5428511128502997
Validation loss: 2.233419659133406

Epoch: 5| Step: 6
Training loss: 0.5784972255544643
Validation loss: 2.1969548490507123

Epoch: 5| Step: 7
Training loss: 1.2318691459063777
Validation loss: 2.339656308125719

Epoch: 5| Step: 8
Training loss: 0.4652655955359881
Validation loss: 2.2184054361200354

Epoch: 5| Step: 9
Training loss: 0.5486259495328664
Validation loss: 2.239587342434438

Epoch: 5| Step: 10
Training loss: 0.4722272959916547
Validation loss: 2.293005723985842

Epoch: 637| Step: 0
Training loss: 0.5601105270984722
Validation loss: 2.233781541428042

Epoch: 5| Step: 1
Training loss: 0.42272817031517085
Validation loss: 2.2517302294068267

Epoch: 5| Step: 2
Training loss: 0.765813843150834
Validation loss: 2.2100192460856456

Epoch: 5| Step: 3
Training loss: 0.48129714326194994
Validation loss: 2.288864626128478

Epoch: 5| Step: 4
Training loss: 0.5110796657710354
Validation loss: 2.3000304497856194

Epoch: 5| Step: 5
Training loss: 0.6634949222031182
Validation loss: 2.2781097042037763

Epoch: 5| Step: 6
Training loss: 0.618707138079722
Validation loss: 2.2415348009237857

Epoch: 5| Step: 7
Training loss: 0.49704444083464716
Validation loss: 2.2955509197975563

Epoch: 5| Step: 8
Training loss: 0.7030773146671906
Validation loss: 2.2645021625803063

Epoch: 5| Step: 9
Training loss: 1.1486420222229246
Validation loss: 2.246838322835769

Epoch: 5| Step: 10
Training loss: 0.5471443330479144
Validation loss: 2.2595449344777907

Epoch: 638| Step: 0
Training loss: 0.40888267061367467
Validation loss: 2.224382194174999

Epoch: 5| Step: 1
Training loss: 0.7699660413858459
Validation loss: 2.264028822141256

Epoch: 5| Step: 2
Training loss: 0.6194989584436043
Validation loss: 2.2909692152298136

Epoch: 5| Step: 3
Training loss: 0.5684220059942919
Validation loss: 2.233858578493105

Epoch: 5| Step: 4
Training loss: 0.7547200608584258
Validation loss: 2.2957978403318786

Epoch: 5| Step: 5
Training loss: 0.5755516981821439
Validation loss: 2.251886600028721

Epoch: 5| Step: 6
Training loss: 0.5342811334719968
Validation loss: 2.1928410441092563

Epoch: 5| Step: 7
Training loss: 0.6720363068451347
Validation loss: 2.336405462855011

Epoch: 5| Step: 8
Training loss: 1.1327922950784326
Validation loss: 2.2054197168402263

Epoch: 5| Step: 9
Training loss: 0.5253679064975877
Validation loss: 2.3061823276093545

Epoch: 5| Step: 10
Training loss: 0.5722566415127193
Validation loss: 2.245114647971093

Epoch: 639| Step: 0
Training loss: 0.6828830403219973
Validation loss: 2.184895875964935

Epoch: 5| Step: 1
Training loss: 0.6184855464335086
Validation loss: 2.2335077563707744

Epoch: 5| Step: 2
Training loss: 0.4894467596201867
Validation loss: 2.1895481635036282

Epoch: 5| Step: 3
Training loss: 1.2140841547189738
Validation loss: 2.246140274343575

Epoch: 5| Step: 4
Training loss: 0.4245928181190004
Validation loss: 2.217934079595596

Epoch: 5| Step: 5
Training loss: 0.5147815510481413
Validation loss: 2.2240666532658744

Epoch: 5| Step: 6
Training loss: 0.42598338097629607
Validation loss: 2.1946572376961315

Epoch: 5| Step: 7
Training loss: 0.37809830484658485
Validation loss: 2.2786694319714553

Epoch: 5| Step: 8
Training loss: 0.6007037783750785
Validation loss: 2.299603348922726

Epoch: 5| Step: 9
Training loss: 0.5137735128475018
Validation loss: 2.229580359435084

Epoch: 5| Step: 10
Training loss: 0.6918503364226383
Validation loss: 2.288312177030676

Epoch: 640| Step: 0
Training loss: 0.37329844036415166
Validation loss: 2.252892349950566

Epoch: 5| Step: 1
Training loss: 0.43531998681985096
Validation loss: 2.270000572251499

Epoch: 5| Step: 2
Training loss: 0.546539258075601
Validation loss: 2.227404343918895

Epoch: 5| Step: 3
Training loss: 0.5361040729539474
Validation loss: 2.24287696366234

Epoch: 5| Step: 4
Training loss: 0.677242639336168
Validation loss: 2.2830706130483853

Epoch: 5| Step: 5
Training loss: 0.7454478079053645
Validation loss: 2.299752519079123

Epoch: 5| Step: 6
Training loss: 1.1885361417507685
Validation loss: 2.2830417276041444

Epoch: 5| Step: 7
Training loss: 0.36996315843577887
Validation loss: 2.24956790017676

Epoch: 5| Step: 8
Training loss: 0.7254810283081133
Validation loss: 2.2988154987324374

Epoch: 5| Step: 9
Training loss: 0.41227312134329797
Validation loss: 2.3239124896345564

Epoch: 5| Step: 10
Training loss: 0.5870657167934421
Validation loss: 2.2576775973060386

Epoch: 641| Step: 0
Training loss: 0.6284659840840322
Validation loss: 2.321126065540239

Epoch: 5| Step: 1
Training loss: 1.1590054645425965
Validation loss: 2.2343297475197503

Epoch: 5| Step: 2
Training loss: 0.5162412255675285
Validation loss: 2.26124447801121

Epoch: 5| Step: 3
Training loss: 0.5892842904812675
Validation loss: 2.2193438451490035

Epoch: 5| Step: 4
Training loss: 0.6035954197350222
Validation loss: 2.2472491282705054

Epoch: 5| Step: 5
Training loss: 0.4080406851374784
Validation loss: 2.208308707541272

Epoch: 5| Step: 6
Training loss: 0.4450719752664416
Validation loss: 2.2842559810830827

Epoch: 5| Step: 7
Training loss: 0.6776006165356967
Validation loss: 2.234855856549028

Epoch: 5| Step: 8
Training loss: 0.5792182946235507
Validation loss: 2.2280268276912714

Epoch: 5| Step: 9
Training loss: 0.600757654964397
Validation loss: 2.3023934631259593

Epoch: 5| Step: 10
Training loss: 0.3786288750413366
Validation loss: 2.2562898023953992

Epoch: 642| Step: 0
Training loss: 0.5207013598767731
Validation loss: 2.274017246532352

Epoch: 5| Step: 1
Training loss: 1.1576779800910824
Validation loss: 2.2936262927299227

Epoch: 5| Step: 2
Training loss: 0.5368861896472347
Validation loss: 2.2407035809394924

Epoch: 5| Step: 3
Training loss: 0.4793518544743044
Validation loss: 2.2634473655686507

Epoch: 5| Step: 4
Training loss: 0.7569529584431098
Validation loss: 2.276480318055489

Epoch: 5| Step: 5
Training loss: 0.394386378213302
Validation loss: 2.2124059764557855

Epoch: 5| Step: 6
Training loss: 0.6059353414952519
Validation loss: 2.266625226213234

Epoch: 5| Step: 7
Training loss: 0.5466190829250105
Validation loss: 2.2589851556275966

Epoch: 5| Step: 8
Training loss: 0.7016959396932533
Validation loss: 2.22902384708653

Epoch: 5| Step: 9
Training loss: 0.49930388451521945
Validation loss: 2.2454692041826996

Epoch: 5| Step: 10
Training loss: 0.4115210396833045
Validation loss: 2.218122179429377

Epoch: 643| Step: 0
Training loss: 1.171101225663056
Validation loss: 2.2209243542282

Epoch: 5| Step: 1
Training loss: 0.5830102917284623
Validation loss: 2.211929949055719

Epoch: 5| Step: 2
Training loss: 0.40026084843622406
Validation loss: 2.2491773667611934

Epoch: 5| Step: 3
Training loss: 0.47396459854791806
Validation loss: 2.2080043687784645

Epoch: 5| Step: 4
Training loss: 0.49675491909304237
Validation loss: 2.2538268133819996

Epoch: 5| Step: 5
Training loss: 0.6425387245783548
Validation loss: 2.288130412545427

Epoch: 5| Step: 6
Training loss: 0.6372846183457755
Validation loss: 2.2711619615101073

Epoch: 5| Step: 7
Training loss: 0.6655484348014199
Validation loss: 2.2388039650592018

Epoch: 5| Step: 8
Training loss: 0.5196300498693163
Validation loss: 2.2105487516649673

Epoch: 5| Step: 9
Training loss: 0.5650809469301552
Validation loss: 2.2482456582563275

Epoch: 5| Step: 10
Training loss: 0.6102501380573321
Validation loss: 2.212309609817807

Epoch: 644| Step: 0
Training loss: 0.5972336415620987
Validation loss: 2.2212974613136542

Epoch: 5| Step: 1
Training loss: 0.47850120678413666
Validation loss: 2.228631377868434

Epoch: 5| Step: 2
Training loss: 0.4364388573822236
Validation loss: 2.2363732120926696

Epoch: 5| Step: 3
Training loss: 1.112580088615091
Validation loss: 2.23566517181198

Epoch: 5| Step: 4
Training loss: 0.6868407383045718
Validation loss: 2.2230606828518935

Epoch: 5| Step: 5
Training loss: 0.5395638995064621
Validation loss: 2.2370809251394923

Epoch: 5| Step: 6
Training loss: 0.4728151952662927
Validation loss: 2.219261565415076

Epoch: 5| Step: 7
Training loss: 0.33644347566488303
Validation loss: 2.1800311782024573

Epoch: 5| Step: 8
Training loss: 0.6590163190931042
Validation loss: 2.225506597034853

Epoch: 5| Step: 9
Training loss: 0.47661598093086865
Validation loss: 2.301010439374191

Epoch: 5| Step: 10
Training loss: 0.6058688410813278
Validation loss: 2.174879166968087

Epoch: 645| Step: 0
Training loss: 0.6144180210220529
Validation loss: 2.231726829937483

Epoch: 5| Step: 1
Training loss: 0.4910420455440224
Validation loss: 2.2800851708914815

Epoch: 5| Step: 2
Training loss: 0.5180130193097838
Validation loss: 2.1514950900342407

Epoch: 5| Step: 3
Training loss: 0.5003549388873133
Validation loss: 2.286050208487

Epoch: 5| Step: 4
Training loss: 0.4727416473671542
Validation loss: 2.213090784429201

Epoch: 5| Step: 5
Training loss: 0.4828369270244079
Validation loss: 2.294892333291543

Epoch: 5| Step: 6
Training loss: 0.43731910508017063
Validation loss: 2.27582998162646

Epoch: 5| Step: 7
Training loss: 0.6037553230982938
Validation loss: 2.268358330447804

Epoch: 5| Step: 8
Training loss: 0.7400559182561789
Validation loss: 2.279149394048533

Epoch: 5| Step: 9
Training loss: 1.2206730465044284
Validation loss: 2.303357152530604

Epoch: 5| Step: 10
Training loss: 0.4390784298053508
Validation loss: 2.2408550073744107

Epoch: 646| Step: 0
Training loss: 0.6380541786251325
Validation loss: 2.2358071381254447

Epoch: 5| Step: 1
Training loss: 0.5207724980747126
Validation loss: 2.233651752421318

Epoch: 5| Step: 2
Training loss: 0.6788190577170682
Validation loss: 2.2443073261161337

Epoch: 5| Step: 3
Training loss: 0.5171062117481433
Validation loss: 2.2095885719264956

Epoch: 5| Step: 4
Training loss: 0.6590759873943256
Validation loss: 2.1806473039179184

Epoch: 5| Step: 5
Training loss: 1.2406820615622622
Validation loss: 2.1616668181546177

Epoch: 5| Step: 6
Training loss: 0.47748913338164944
Validation loss: 2.2419385068254383

Epoch: 5| Step: 7
Training loss: 0.5573033186030152
Validation loss: 2.2182299593637125

Epoch: 5| Step: 8
Training loss: 0.46697943401591385
Validation loss: 2.1884485687288344

Epoch: 5| Step: 9
Training loss: 0.3948561586363204
Validation loss: 2.2545677384921183

Epoch: 5| Step: 10
Training loss: 0.7599959232823303
Validation loss: 2.223132606970353

Epoch: 647| Step: 0
Training loss: 0.6272775636487784
Validation loss: 2.268556760059592

Epoch: 5| Step: 1
Training loss: 0.4460901864839779
Validation loss: 2.2428057498779985

Epoch: 5| Step: 2
Training loss: 0.5889812757514505
Validation loss: 2.2166790099181592

Epoch: 5| Step: 3
Training loss: 0.45182566316706124
Validation loss: 2.2790347007914464

Epoch: 5| Step: 4
Training loss: 0.6714718074632218
Validation loss: 2.207558281316267

Epoch: 5| Step: 5
Training loss: 0.43913723930569837
Validation loss: 2.21798201353156

Epoch: 5| Step: 6
Training loss: 0.5355313789245981
Validation loss: 2.2221256651290484

Epoch: 5| Step: 7
Training loss: 0.35276990819252635
Validation loss: 2.1493056806424398

Epoch: 5| Step: 8
Training loss: 0.5818172291760069
Validation loss: 2.279246613838417

Epoch: 5| Step: 9
Training loss: 1.205007591223647
Validation loss: 2.2500823323762895

Epoch: 5| Step: 10
Training loss: 0.37260220773573166
Validation loss: 2.2333925351686714

Epoch: 648| Step: 0
Training loss: 0.6400765653349346
Validation loss: 2.172078826941105

Epoch: 5| Step: 1
Training loss: 0.4754636007952158
Validation loss: 2.1988448859040064

Epoch: 5| Step: 2
Training loss: 0.434530037717421
Validation loss: 2.2103358627472303

Epoch: 5| Step: 3
Training loss: 0.4763118678930814
Validation loss: 2.225736291539638

Epoch: 5| Step: 4
Training loss: 0.500700519499634
Validation loss: 2.2549857965466837

Epoch: 5| Step: 5
Training loss: 0.5978803526144072
Validation loss: 2.2837733069923365

Epoch: 5| Step: 6
Training loss: 1.1264329367534993
Validation loss: 2.203574020881527

Epoch: 5| Step: 7
Training loss: 0.6499277019640753
Validation loss: 2.1627300101006837

Epoch: 5| Step: 8
Training loss: 0.740693445704732
Validation loss: 2.2478264812279884

Epoch: 5| Step: 9
Training loss: 0.5024577769290028
Validation loss: 2.173177453849263

Epoch: 5| Step: 10
Training loss: 0.6189398214301876
Validation loss: 2.2014497496634347

Epoch: 649| Step: 0
Training loss: 0.4825924714574247
Validation loss: 2.1763556264583666

Epoch: 5| Step: 1
Training loss: 0.6610394049829296
Validation loss: 2.231975056776565

Epoch: 5| Step: 2
Training loss: 0.4523000936573867
Validation loss: 2.2950487626185048

Epoch: 5| Step: 3
Training loss: 1.1488438101602116
Validation loss: 2.218005972887129

Epoch: 5| Step: 4
Training loss: 0.46356136480189597
Validation loss: 2.2294126496998397

Epoch: 5| Step: 5
Training loss: 0.384017061256833
Validation loss: 2.3107673142440968

Epoch: 5| Step: 6
Training loss: 0.490523492432318
Validation loss: 2.2564859133244806

Epoch: 5| Step: 7
Training loss: 0.49906170244816045
Validation loss: 2.266411162524693

Epoch: 5| Step: 8
Training loss: 0.42930648556921236
Validation loss: 2.2394929341536858

Epoch: 5| Step: 9
Training loss: 0.6103586669508398
Validation loss: 2.201925520931534

Epoch: 5| Step: 10
Training loss: 0.8153902147070384
Validation loss: 2.218082954536361

Epoch: 650| Step: 0
Training loss: 0.5046910820234514
Validation loss: 2.2641350123564803

Epoch: 5| Step: 1
Training loss: 0.5801871097821862
Validation loss: 2.2190693254743907

Epoch: 5| Step: 2
Training loss: 0.5459794477430338
Validation loss: 2.252236056167872

Epoch: 5| Step: 3
Training loss: 1.110998282399468
Validation loss: 2.2567609593659874

Epoch: 5| Step: 4
Training loss: 0.6323616399701594
Validation loss: 2.1860595742220625

Epoch: 5| Step: 5
Training loss: 0.5634095467791489
Validation loss: 2.2950675124659194

Epoch: 5| Step: 6
Training loss: 0.4730887995316706
Validation loss: 2.213795584218726

Epoch: 5| Step: 7
Training loss: 0.3288007997564001
Validation loss: 2.2511931836744163

Epoch: 5| Step: 8
Training loss: 0.3984161446028093
Validation loss: 2.262719558634846

Epoch: 5| Step: 9
Training loss: 0.7168819366624996
Validation loss: 2.2551709537458153

Epoch: 5| Step: 10
Training loss: 0.38119910322556183
Validation loss: 2.2276310208932846

Epoch: 651| Step: 0
Training loss: 0.5281199359086701
Validation loss: 2.2823565293286467

Epoch: 5| Step: 1
Training loss: 0.4601480544806341
Validation loss: 2.2405230939784957

Epoch: 5| Step: 2
Training loss: 0.4477057977122056
Validation loss: 2.2830515024775897

Epoch: 5| Step: 3
Training loss: 0.5983370724067991
Validation loss: 2.25369360818495

Epoch: 5| Step: 4
Training loss: 0.6671551663070412
Validation loss: 2.2479385055209065

Epoch: 5| Step: 5
Training loss: 0.541433647970786
Validation loss: 2.3011028295499893

Epoch: 5| Step: 6
Training loss: 0.5953666362026814
Validation loss: 2.2384132879331307

Epoch: 5| Step: 7
Training loss: 0.5270118516642545
Validation loss: 2.176104801465565

Epoch: 5| Step: 8
Training loss: 0.45527890078139943
Validation loss: 2.207790393531578

Epoch: 5| Step: 9
Training loss: 1.131144644114858
Validation loss: 2.210314517489688

Epoch: 5| Step: 10
Training loss: 0.4468302877772456
Validation loss: 2.1661185544688997

Epoch: 652| Step: 0
Training loss: 0.6651054942915134
Validation loss: 2.1861064075549446

Epoch: 5| Step: 1
Training loss: 0.6024341213647247
Validation loss: 2.260615710965075

Epoch: 5| Step: 2
Training loss: 0.6626799384058716
Validation loss: 2.175786060249801

Epoch: 5| Step: 3
Training loss: 0.49585796369823876
Validation loss: 2.2460798051783764

Epoch: 5| Step: 4
Training loss: 0.7104545881455173
Validation loss: 2.166478769691526

Epoch: 5| Step: 5
Training loss: 0.4204575958246745
Validation loss: 2.240050644613355

Epoch: 5| Step: 6
Training loss: 0.4505009968383548
Validation loss: 2.2643857062220962

Epoch: 5| Step: 7
Training loss: 1.176204364471044
Validation loss: 2.3035611656279316

Epoch: 5| Step: 8
Training loss: 0.4549903621281627
Validation loss: 2.2241706521050904

Epoch: 5| Step: 9
Training loss: 0.6381779198368781
Validation loss: 2.295988901843595

Epoch: 5| Step: 10
Training loss: 0.41055899329044593
Validation loss: 2.265138475840647

Epoch: 653| Step: 0
Training loss: 0.5540236678180486
Validation loss: 2.24983173000926

Epoch: 5| Step: 1
Training loss: 0.39299359328384026
Validation loss: 2.318884728920129

Epoch: 5| Step: 2
Training loss: 0.8717110674571353
Validation loss: 2.217627787332569

Epoch: 5| Step: 3
Training loss: 0.6301551407573234
Validation loss: 2.2435423610831

Epoch: 5| Step: 4
Training loss: 0.6378602403177419
Validation loss: 2.1768571214357824

Epoch: 5| Step: 5
Training loss: 0.5005978943419664
Validation loss: 2.2616595265224415

Epoch: 5| Step: 6
Training loss: 1.1726412493250142
Validation loss: 2.2228600879480047

Epoch: 5| Step: 7
Training loss: 0.7684253937712766
Validation loss: 2.11983687817284

Epoch: 5| Step: 8
Training loss: 0.5192695187852061
Validation loss: 2.180810438037176

Epoch: 5| Step: 9
Training loss: 0.5483680507236111
Validation loss: 2.156794447940615

Epoch: 5| Step: 10
Training loss: 0.5956635258754945
Validation loss: 2.277831022262372

Epoch: 654| Step: 0
Training loss: 0.3591770373231612
Validation loss: 2.1987925478793917

Epoch: 5| Step: 1
Training loss: 0.839560101537119
Validation loss: 2.226407925202554

Epoch: 5| Step: 2
Training loss: 0.44412165914149165
Validation loss: 2.2654698879961956

Epoch: 5| Step: 3
Training loss: 0.5302590777453284
Validation loss: 2.2944695229069247

Epoch: 5| Step: 4
Training loss: 0.709648220868334
Validation loss: 2.273592308599909

Epoch: 5| Step: 5
Training loss: 1.1978825882196937
Validation loss: 2.217795207445616

Epoch: 5| Step: 6
Training loss: 0.4524831830371962
Validation loss: 2.3161164092235134

Epoch: 5| Step: 7
Training loss: 0.734003297603486
Validation loss: 2.2816552321862558

Epoch: 5| Step: 8
Training loss: 0.46813644945227895
Validation loss: 2.283388417514182

Epoch: 5| Step: 9
Training loss: 0.7031579327818115
Validation loss: 2.268516227276042

Epoch: 5| Step: 10
Training loss: 0.6072374658841875
Validation loss: 2.2086106474695355

Epoch: 655| Step: 0
Training loss: 0.49647223685108577
Validation loss: 2.2486520304809776

Epoch: 5| Step: 1
Training loss: 0.5066645043833085
Validation loss: 2.268009836988733

Epoch: 5| Step: 2
Training loss: 1.1226516160756508
Validation loss: 2.27927625316597

Epoch: 5| Step: 3
Training loss: 0.6178567854851115
Validation loss: 2.2358332960129936

Epoch: 5| Step: 4
Training loss: 0.40591036831441085
Validation loss: 2.1849031565698436

Epoch: 5| Step: 5
Training loss: 0.4899055016150516
Validation loss: 2.2423717555559253

Epoch: 5| Step: 6
Training loss: 0.7435451738426784
Validation loss: 2.2100260796838875

Epoch: 5| Step: 7
Training loss: 0.6507834087578733
Validation loss: 2.209182243689436

Epoch: 5| Step: 8
Training loss: 0.49131459835464775
Validation loss: 2.2402809626650546

Epoch: 5| Step: 9
Training loss: 0.5696061345438436
Validation loss: 2.2127108620414733

Epoch: 5| Step: 10
Training loss: 0.5524276043855504
Validation loss: 2.2476166586594566

Epoch: 656| Step: 0
Training loss: 0.44062389820042286
Validation loss: 2.2074751700521094

Epoch: 5| Step: 1
Training loss: 0.3800872409585952
Validation loss: 2.1673559272961724

Epoch: 5| Step: 2
Training loss: 0.6010269654678165
Validation loss: 2.204202597166855

Epoch: 5| Step: 3
Training loss: 0.4620706401723496
Validation loss: 2.178745373878234

Epoch: 5| Step: 4
Training loss: 0.5130508497980789
Validation loss: 2.2745147939060897

Epoch: 5| Step: 5
Training loss: 0.5380501016913612
Validation loss: 2.2900475548188077

Epoch: 5| Step: 6
Training loss: 0.45527860621362154
Validation loss: 2.333383806476733

Epoch: 5| Step: 7
Training loss: 1.1940851330303093
Validation loss: 2.2518779410277916

Epoch: 5| Step: 8
Training loss: 0.6445510861205426
Validation loss: 2.192125179510731

Epoch: 5| Step: 9
Training loss: 0.8158144471421381
Validation loss: 2.228794878444316

Epoch: 5| Step: 10
Training loss: 0.6831956194492069
Validation loss: 2.2234344737677194

Epoch: 657| Step: 0
Training loss: 0.6234114008055903
Validation loss: 2.1865967545518163

Epoch: 5| Step: 1
Training loss: 0.4705289304688392
Validation loss: 2.223553705568978

Epoch: 5| Step: 2
Training loss: 0.6732105465705996
Validation loss: 2.2083357866876883

Epoch: 5| Step: 3
Training loss: 0.5590923191773141
Validation loss: 2.238160374471515

Epoch: 5| Step: 4
Training loss: 0.4719137870561055
Validation loss: 2.1809916960048343

Epoch: 5| Step: 5
Training loss: 0.6552406450642263
Validation loss: 2.190175429376279

Epoch: 5| Step: 6
Training loss: 0.5628538608126841
Validation loss: 2.2445031188024562

Epoch: 5| Step: 7
Training loss: 0.6060880631536291
Validation loss: 2.212064530505778

Epoch: 5| Step: 8
Training loss: 0.4212165568515611
Validation loss: 2.2399569591576496

Epoch: 5| Step: 9
Training loss: 1.1381889876635114
Validation loss: 2.241814014733726

Epoch: 5| Step: 10
Training loss: 0.5607553021456239
Validation loss: 2.2192348844128413

Epoch: 658| Step: 0
Training loss: 0.6258096457526492
Validation loss: 2.3002831462207443

Epoch: 5| Step: 1
Training loss: 1.2592209222407762
Validation loss: 2.267620762663892

Epoch: 5| Step: 2
Training loss: 0.5127273404244637
Validation loss: 2.2534395769361546

Epoch: 5| Step: 3
Training loss: 0.5882671075871292
Validation loss: 2.2053494341883098

Epoch: 5| Step: 4
Training loss: 0.6959135693605395
Validation loss: 2.2210635830319796

Epoch: 5| Step: 5
Training loss: 0.5666981438234302
Validation loss: 2.245949848517857

Epoch: 5| Step: 6
Training loss: 0.6097006294561325
Validation loss: 2.19245386277796

Epoch: 5| Step: 7
Training loss: 0.5198819117158857
Validation loss: 2.2284516594821233

Epoch: 5| Step: 8
Training loss: 0.5777010265162934
Validation loss: 2.1525966112445647

Epoch: 5| Step: 9
Training loss: 0.4582515954334812
Validation loss: 2.203198036874701

Epoch: 5| Step: 10
Training loss: 0.46496641319759885
Validation loss: 2.297141301829878

Epoch: 659| Step: 0
Training loss: 0.501480711450966
Validation loss: 2.224989945280772

Epoch: 5| Step: 1
Training loss: 0.4164095880256539
Validation loss: 2.1309637174597844

Epoch: 5| Step: 2
Training loss: 0.4880060259493883
Validation loss: 2.2871934158222706

Epoch: 5| Step: 3
Training loss: 0.7452892739697645
Validation loss: 2.2506641708856243

Epoch: 5| Step: 4
Training loss: 0.47389751784734535
Validation loss: 2.2671227324621235

Epoch: 5| Step: 5
Training loss: 0.5291644279052155
Validation loss: 2.312646053616388

Epoch: 5| Step: 6
Training loss: 1.1239986201512022
Validation loss: 2.2260937142367614

Epoch: 5| Step: 7
Training loss: 0.6366192792646282
Validation loss: 2.230275433169347

Epoch: 5| Step: 8
Training loss: 0.47857097383479574
Validation loss: 2.307304904690232

Epoch: 5| Step: 9
Training loss: 0.566773762353294
Validation loss: 2.221082822976748

Epoch: 5| Step: 10
Training loss: 0.6742976667381626
Validation loss: 2.1815109561782684

Epoch: 660| Step: 0
Training loss: 0.7757247858157282
Validation loss: 2.2917625336344445

Epoch: 5| Step: 1
Training loss: 0.5297243426177758
Validation loss: 2.189757597558869

Epoch: 5| Step: 2
Training loss: 0.42366342816451935
Validation loss: 2.2522184938144614

Epoch: 5| Step: 3
Training loss: 0.6414695150976915
Validation loss: 2.2518852595137293

Epoch: 5| Step: 4
Training loss: 1.1825413321273959
Validation loss: 2.278192913461553

Epoch: 5| Step: 5
Training loss: 0.5374369783936849
Validation loss: 2.233059338077785

Epoch: 5| Step: 6
Training loss: 0.5158136773973637
Validation loss: 2.287242554123123

Epoch: 5| Step: 7
Training loss: 0.5670318831405826
Validation loss: 2.3100279543791795

Epoch: 5| Step: 8
Training loss: 0.43434414925554504
Validation loss: 2.3074916603942826

Epoch: 5| Step: 9
Training loss: 0.5759313566280749
Validation loss: 2.201664737626266

Epoch: 5| Step: 10
Training loss: 0.47013708563020074
Validation loss: 2.1924097188453295

Epoch: 661| Step: 0
Training loss: 0.6187872856157489
Validation loss: 2.316946081894642

Epoch: 5| Step: 1
Training loss: 0.49563959314285744
Validation loss: 2.2347510999638107

Epoch: 5| Step: 2
Training loss: 1.2234541754237784
Validation loss: 2.1645337386135

Epoch: 5| Step: 3
Training loss: 0.4222039070866145
Validation loss: 2.2745043393232365

Epoch: 5| Step: 4
Training loss: 0.5398040867324645
Validation loss: 2.2274517017325475

Epoch: 5| Step: 5
Training loss: 0.48880708990308885
Validation loss: 2.2442547986261685

Epoch: 5| Step: 6
Training loss: 0.4875023542249517
Validation loss: 2.2457707066937704

Epoch: 5| Step: 7
Training loss: 0.617255919321878
Validation loss: 2.266055182329929

Epoch: 5| Step: 8
Training loss: 0.4701066254085812
Validation loss: 2.260210454169375

Epoch: 5| Step: 9
Training loss: 0.7983265166963889
Validation loss: 2.266787825277302

Epoch: 5| Step: 10
Training loss: 0.5320079389442283
Validation loss: 2.25983671556431

Epoch: 662| Step: 0
Training loss: 0.5522254245171847
Validation loss: 2.306877998215879

Epoch: 5| Step: 1
Training loss: 0.5491742166232689
Validation loss: 2.2131769780109205

Epoch: 5| Step: 2
Training loss: 0.5606188312561121
Validation loss: 2.1583877709440036

Epoch: 5| Step: 3
Training loss: 0.47147902175152456
Validation loss: 2.183481511790608

Epoch: 5| Step: 4
Training loss: 0.567747698011145
Validation loss: 2.1847862403804506

Epoch: 5| Step: 5
Training loss: 1.1014534646038412
Validation loss: 2.181963617790766

Epoch: 5| Step: 6
Training loss: 0.5967596721576496
Validation loss: 2.2644571011954397

Epoch: 5| Step: 7
Training loss: 0.6646139660016737
Validation loss: 2.166778454685209

Epoch: 5| Step: 8
Training loss: 0.5430826026601746
Validation loss: 2.146696143832003

Epoch: 5| Step: 9
Training loss: 0.46281971770639996
Validation loss: 2.2133167648189485

Epoch: 5| Step: 10
Training loss: 0.5876408550149718
Validation loss: 2.2505451656264905

Epoch: 663| Step: 0
Training loss: 0.438943694796513
Validation loss: 2.224106057912517

Epoch: 5| Step: 1
Training loss: 0.5198146936008685
Validation loss: 2.2246559689394405

Epoch: 5| Step: 2
Training loss: 1.3721507201611658
Validation loss: 2.205063295889917

Epoch: 5| Step: 3
Training loss: 0.5667402137917703
Validation loss: 2.2787129798289456

Epoch: 5| Step: 4
Training loss: 0.4797016781628288
Validation loss: 2.257444838959427

Epoch: 5| Step: 5
Training loss: 0.4765991446992833
Validation loss: 2.239410810033118

Epoch: 5| Step: 6
Training loss: 0.4347434566909164
Validation loss: 2.2346464463068596

Epoch: 5| Step: 7
Training loss: 0.3575521138027518
Validation loss: 2.193967919303085

Epoch: 5| Step: 8
Training loss: 0.47032824898645254
Validation loss: 2.153611934037116

Epoch: 5| Step: 9
Training loss: 0.5600262660014497
Validation loss: 2.1989922138438454

Epoch: 5| Step: 10
Training loss: 0.7538972765136498
Validation loss: 2.198076437635996

Epoch: 664| Step: 0
Training loss: 0.5113028372157086
Validation loss: 2.1833564376485315

Epoch: 5| Step: 1
Training loss: 0.6089263633908534
Validation loss: 2.1982160557855424

Epoch: 5| Step: 2
Training loss: 0.44398677647397783
Validation loss: 2.2387613820494985

Epoch: 5| Step: 3
Training loss: 0.5300398675750954
Validation loss: 2.1179934427034603

Epoch: 5| Step: 4
Training loss: 0.4937098438496206
Validation loss: 2.181712703120251

Epoch: 5| Step: 5
Training loss: 0.4687190522468183
Validation loss: 2.166149087838588

Epoch: 5| Step: 6
Training loss: 0.4230305951227458
Validation loss: 2.225023495890089

Epoch: 5| Step: 7
Training loss: 0.4835370414158763
Validation loss: 2.215485091715204

Epoch: 5| Step: 8
Training loss: 1.0889235682922827
Validation loss: 2.2188872826807624

Epoch: 5| Step: 9
Training loss: 0.6814583039951891
Validation loss: 2.228525025888578

Epoch: 5| Step: 10
Training loss: 0.6019028035492954
Validation loss: 2.1613640379299546

Epoch: 665| Step: 0
Training loss: 0.4751194853830192
Validation loss: 2.2144283245020726

Epoch: 5| Step: 1
Training loss: 0.5104932597814765
Validation loss: 2.2273890442306725

Epoch: 5| Step: 2
Training loss: 0.7042570114490884
Validation loss: 2.212027262295362

Epoch: 5| Step: 3
Training loss: 0.3504008811546867
Validation loss: 2.2294119166273085

Epoch: 5| Step: 4
Training loss: 0.5581458903949327
Validation loss: 2.229001097059679

Epoch: 5| Step: 5
Training loss: 0.7524732500055248
Validation loss: 2.2708237241293507

Epoch: 5| Step: 6
Training loss: 0.3623242231587709
Validation loss: 2.2278898590624308

Epoch: 5| Step: 7
Training loss: 0.5714604047440348
Validation loss: 2.1893574218055107

Epoch: 5| Step: 8
Training loss: 0.4536598272022937
Validation loss: 2.1986135678377603

Epoch: 5| Step: 9
Training loss: 1.1385940865434632
Validation loss: 2.2382706759998596

Epoch: 5| Step: 10
Training loss: 0.37640512984866464
Validation loss: 2.219807303715573

Epoch: 666| Step: 0
Training loss: 0.5623819704202498
Validation loss: 2.234125039733408

Epoch: 5| Step: 1
Training loss: 0.4418717352113882
Validation loss: 2.1828023696842744

Epoch: 5| Step: 2
Training loss: 0.43269364690980944
Validation loss: 2.28772183705457

Epoch: 5| Step: 3
Training loss: 0.5555871196230827
Validation loss: 2.2704459547953095

Epoch: 5| Step: 4
Training loss: 0.5426080727053672
Validation loss: 2.2969677300674465

Epoch: 5| Step: 5
Training loss: 0.425759656166069
Validation loss: 2.2153914777494252

Epoch: 5| Step: 6
Training loss: 0.45432854998727723
Validation loss: 2.182071450792779

Epoch: 5| Step: 7
Training loss: 0.4794466886668001
Validation loss: 2.2295346876796045

Epoch: 5| Step: 8
Training loss: 0.6469979680705997
Validation loss: 2.206654601500794

Epoch: 5| Step: 9
Training loss: 0.6402932447793541
Validation loss: 2.2496794332114503

Epoch: 5| Step: 10
Training loss: 1.1668300116948105
Validation loss: 2.2188977081571304

Epoch: 667| Step: 0
Training loss: 0.447818198211045
Validation loss: 2.146755027926592

Epoch: 5| Step: 1
Training loss: 0.6205032468537154
Validation loss: 2.206513142480442

Epoch: 5| Step: 2
Training loss: 0.4923388536040889
Validation loss: 2.225282987582393

Epoch: 5| Step: 3
Training loss: 0.40195692781627257
Validation loss: 2.223356808010555

Epoch: 5| Step: 4
Training loss: 0.45285284156194205
Validation loss: 2.1778656906561027

Epoch: 5| Step: 5
Training loss: 0.4300277923041356
Validation loss: 2.234695405860646

Epoch: 5| Step: 6
Training loss: 0.5588637013138988
Validation loss: 2.1614862026330934

Epoch: 5| Step: 7
Training loss: 0.46994167485940314
Validation loss: 2.242035012113795

Epoch: 5| Step: 8
Training loss: 1.0725549192972603
Validation loss: 2.2076547810350893

Epoch: 5| Step: 9
Training loss: 0.5996664312099625
Validation loss: 2.2484217717862847

Epoch: 5| Step: 10
Training loss: 0.7184853688570758
Validation loss: 2.181068386710644

Epoch: 668| Step: 0
Training loss: 0.6622346742612812
Validation loss: 2.181837732840642

Epoch: 5| Step: 1
Training loss: 0.4994934317335469
Validation loss: 2.2162989588592863

Epoch: 5| Step: 2
Training loss: 0.7256068435881408
Validation loss: 2.1833143783262545

Epoch: 5| Step: 3
Training loss: 0.5471767682864569
Validation loss: 2.295574445904698

Epoch: 5| Step: 4
Training loss: 0.567454610933613
Validation loss: 2.252625385852867

Epoch: 5| Step: 5
Training loss: 0.5275221346328687
Validation loss: 2.284706655847151

Epoch: 5| Step: 6
Training loss: 0.6534069328875584
Validation loss: 2.241889059362652

Epoch: 5| Step: 7
Training loss: 0.6000121314093907
Validation loss: 2.213129605491439

Epoch: 5| Step: 8
Training loss: 1.022541906435411
Validation loss: 2.197513214564001

Epoch: 5| Step: 9
Training loss: 0.5813674213388705
Validation loss: 2.2125909289179764

Epoch: 5| Step: 10
Training loss: 0.491336465195522
Validation loss: 2.220409721158119

Epoch: 669| Step: 0
Training loss: 0.5072631505461971
Validation loss: 2.2198370501036107

Epoch: 5| Step: 1
Training loss: 0.5638177589075676
Validation loss: 2.277184990470212

Epoch: 5| Step: 2
Training loss: 0.55606198937486
Validation loss: 2.186264500170237

Epoch: 5| Step: 3
Training loss: 0.45383931452687626
Validation loss: 2.216648040324371

Epoch: 5| Step: 4
Training loss: 0.518797736671646
Validation loss: 2.16838806466653

Epoch: 5| Step: 5
Training loss: 0.40856711116626127
Validation loss: 2.1837826623493246

Epoch: 5| Step: 6
Training loss: 0.5743642350226816
Validation loss: 2.2518600639448643

Epoch: 5| Step: 7
Training loss: 1.1202898499395155
Validation loss: 2.313899370945204

Epoch: 5| Step: 8
Training loss: 0.49375153855192727
Validation loss: 2.277060940380976

Epoch: 5| Step: 9
Training loss: 0.45102692624762264
Validation loss: 2.2233053698737346

Epoch: 5| Step: 10
Training loss: 0.7523331511672913
Validation loss: 2.2244166824341107

Epoch: 670| Step: 0
Training loss: 1.0047448362895004
Validation loss: 2.251674990284707

Epoch: 5| Step: 1
Training loss: 0.5592551417312642
Validation loss: 2.2016832109148448

Epoch: 5| Step: 2
Training loss: 0.41410965920845055
Validation loss: 2.102767233063697

Epoch: 5| Step: 3
Training loss: 0.5500874308972059
Validation loss: 2.2002770331732857

Epoch: 5| Step: 4
Training loss: 0.325662432073168
Validation loss: 2.241312144878559

Epoch: 5| Step: 5
Training loss: 0.6191222130958992
Validation loss: 2.260127413166656

Epoch: 5| Step: 6
Training loss: 0.5217903182715379
Validation loss: 2.151318843588225

Epoch: 5| Step: 7
Training loss: 0.4820939466857212
Validation loss: 2.1933176115221653

Epoch: 5| Step: 8
Training loss: 0.4294818559473433
Validation loss: 2.191901538314564

Epoch: 5| Step: 9
Training loss: 0.4619250628913613
Validation loss: 2.219374315077592

Epoch: 5| Step: 10
Training loss: 0.449963276079858
Validation loss: 2.1998173228357696

Epoch: 671| Step: 0
Training loss: 0.44499039294020093
Validation loss: 2.220106046431756

Epoch: 5| Step: 1
Training loss: 0.6645686520675861
Validation loss: 2.1348828344531734

Epoch: 5| Step: 2
Training loss: 1.0644495972741141
Validation loss: 2.198778205131066

Epoch: 5| Step: 3
Training loss: 0.8009338605651445
Validation loss: 2.183708120268348

Epoch: 5| Step: 4
Training loss: 0.4540617402366378
Validation loss: 2.239736815504536

Epoch: 5| Step: 5
Training loss: 0.5809041317061765
Validation loss: 2.2430157144589535

Epoch: 5| Step: 6
Training loss: 0.5722338306330772
Validation loss: 2.2635153946288784

Epoch: 5| Step: 7
Training loss: 0.5903244586013988
Validation loss: 2.2188242140609784

Epoch: 5| Step: 8
Training loss: 0.5317713199156187
Validation loss: 2.2575346193121235

Epoch: 5| Step: 9
Training loss: 0.4859034817677055
Validation loss: 2.198628210743801

Epoch: 5| Step: 10
Training loss: 0.5209549062620684
Validation loss: 2.2352345089394428

Epoch: 672| Step: 0
Training loss: 0.5287618713308797
Validation loss: 2.2126972426893334

Epoch: 5| Step: 1
Training loss: 0.43100125007934903
Validation loss: 2.2359156868295855

Epoch: 5| Step: 2
Training loss: 0.39199767211057424
Validation loss: 2.298667964098583

Epoch: 5| Step: 3
Training loss: 0.4016784611859179
Validation loss: 2.233688744766708

Epoch: 5| Step: 4
Training loss: 0.5965999668639248
Validation loss: 2.199618494584462

Epoch: 5| Step: 5
Training loss: 1.143305620259845
Validation loss: 2.2353963309719567

Epoch: 5| Step: 6
Training loss: 0.6552599750619695
Validation loss: 2.157935951291092

Epoch: 5| Step: 7
Training loss: 0.5784283950229213
Validation loss: 2.283414534431899

Epoch: 5| Step: 8
Training loss: 0.38736626332276275
Validation loss: 2.2261229654959993

Epoch: 5| Step: 9
Training loss: 0.4506471398056162
Validation loss: 2.2632082237521765

Epoch: 5| Step: 10
Training loss: 0.7665504389924787
Validation loss: 2.2017428955196676

Epoch: 673| Step: 0
Training loss: 0.5220203859579747
Validation loss: 2.1828289231640534

Epoch: 5| Step: 1
Training loss: 0.4009350866243628
Validation loss: 2.194123209135391

Epoch: 5| Step: 2
Training loss: 0.47291348291017216
Validation loss: 2.2476821032851304

Epoch: 5| Step: 3
Training loss: 0.6130068705828715
Validation loss: 2.225083449650267

Epoch: 5| Step: 4
Training loss: 1.1913259010111565
Validation loss: 2.2720537153996707

Epoch: 5| Step: 5
Training loss: 0.5774033398260439
Validation loss: 2.1969251936752094

Epoch: 5| Step: 6
Training loss: 0.4906910444867015
Validation loss: 2.2781326958434764

Epoch: 5| Step: 7
Training loss: 0.5250844240428012
Validation loss: 2.2676920716133

Epoch: 5| Step: 8
Training loss: 0.5149317907791716
Validation loss: 2.1954184325491917

Epoch: 5| Step: 9
Training loss: 0.5547541188813035
Validation loss: 2.2437657772773987

Epoch: 5| Step: 10
Training loss: 0.510753011497623
Validation loss: 2.207101402434633

Epoch: 674| Step: 0
Training loss: 0.5189191324207996
Validation loss: 2.204448622630843

Epoch: 5| Step: 1
Training loss: 0.4235495253736232
Validation loss: 2.228100391031071

Epoch: 5| Step: 2
Training loss: 0.6033935917308872
Validation loss: 2.1334460870718592

Epoch: 5| Step: 3
Training loss: 1.1530572266549846
Validation loss: 2.2221739729989363

Epoch: 5| Step: 4
Training loss: 0.4913952976334455
Validation loss: 2.2518684520633467

Epoch: 5| Step: 5
Training loss: 0.4968404182059881
Validation loss: 2.2641895424289222

Epoch: 5| Step: 6
Training loss: 0.5887185537035309
Validation loss: 2.2354385514665522

Epoch: 5| Step: 7
Training loss: 0.5429618889903467
Validation loss: 2.2104311428837216

Epoch: 5| Step: 8
Training loss: 0.46081588239837035
Validation loss: 2.2359768591039284

Epoch: 5| Step: 9
Training loss: 0.5212461520357144
Validation loss: 2.248091232147144

Epoch: 5| Step: 10
Training loss: 0.37261152578880014
Validation loss: 2.156841052019174

Epoch: 675| Step: 0
Training loss: 0.6142730225831363
Validation loss: 2.2229316137590374

Epoch: 5| Step: 1
Training loss: 0.5504234450377953
Validation loss: 2.221610432757583

Epoch: 5| Step: 2
Training loss: 0.37698381921589114
Validation loss: 2.304188106680185

Epoch: 5| Step: 3
Training loss: 0.436544652504392
Validation loss: 2.1885570720285754

Epoch: 5| Step: 4
Training loss: 0.31210673143701984
Validation loss: 2.269371148639928

Epoch: 5| Step: 5
Training loss: 0.5935763054815085
Validation loss: 2.2518419305656607

Epoch: 5| Step: 6
Training loss: 0.5176688348706722
Validation loss: 2.2395108950767417

Epoch: 5| Step: 7
Training loss: 0.5480746870535825
Validation loss: 2.2423522929821367

Epoch: 5| Step: 8
Training loss: 0.5957787137461537
Validation loss: 2.218521911784527

Epoch: 5| Step: 9
Training loss: 1.0918050639437418
Validation loss: 2.279432430416105

Epoch: 5| Step: 10
Training loss: 0.48368421642028353
Validation loss: 2.2097528816914376

Epoch: 676| Step: 0
Training loss: 0.4089946829326642
Validation loss: 2.211322445522172

Epoch: 5| Step: 1
Training loss: 1.122793470901461
Validation loss: 2.2196110220721734

Epoch: 5| Step: 2
Training loss: 0.5741897368075582
Validation loss: 2.239343156883106

Epoch: 5| Step: 3
Training loss: 0.5867090866979482
Validation loss: 2.3107189125202714

Epoch: 5| Step: 4
Training loss: 0.3671604917617104
Validation loss: 2.122873182963516

Epoch: 5| Step: 5
Training loss: 0.5738817121129411
Validation loss: 2.193959681397575

Epoch: 5| Step: 6
Training loss: 0.43606835524050763
Validation loss: 2.220813602112902

Epoch: 5| Step: 7
Training loss: 0.6046345285875792
Validation loss: 2.2299970457018

Epoch: 5| Step: 8
Training loss: 0.37775845061366964
Validation loss: 2.28754854855123

Epoch: 5| Step: 9
Training loss: 0.5716432435331681
Validation loss: 2.2234513064868344

Epoch: 5| Step: 10
Training loss: 0.5677745208887367
Validation loss: 2.2677050000488235

Epoch: 677| Step: 0
Training loss: 0.6879784046598558
Validation loss: 2.1938835500018636

Epoch: 5| Step: 1
Training loss: 0.45567533084231393
Validation loss: 2.247280561964689

Epoch: 5| Step: 2
Training loss: 0.3927962043799274
Validation loss: 2.2021649486389427

Epoch: 5| Step: 3
Training loss: 0.6391322958216641
Validation loss: 2.2319595087343824

Epoch: 5| Step: 4
Training loss: 0.46491301845909017
Validation loss: 2.2780082033172007

Epoch: 5| Step: 5
Training loss: 0.5793164322600589
Validation loss: 2.2065581184560257

Epoch: 5| Step: 6
Training loss: 0.7514904233508848
Validation loss: 2.2220877107634527

Epoch: 5| Step: 7
Training loss: 0.643607523808502
Validation loss: 2.1883699073256557

Epoch: 5| Step: 8
Training loss: 0.5061708765245267
Validation loss: 2.1989333866809613

Epoch: 5| Step: 9
Training loss: 1.1029235331676235
Validation loss: 2.212481748008446

Epoch: 5| Step: 10
Training loss: 0.5639595328737356
Validation loss: 2.2008863572322883

Epoch: 678| Step: 0
Training loss: 0.44106809778649203
Validation loss: 2.241755730339951

Epoch: 5| Step: 1
Training loss: 0.5159372771255132
Validation loss: 2.176187085748011

Epoch: 5| Step: 2
Training loss: 0.49844293740873274
Validation loss: 2.1627033704681877

Epoch: 5| Step: 3
Training loss: 0.6628434829268957
Validation loss: 2.1799534067136617

Epoch: 5| Step: 4
Training loss: 0.4979482066833781
Validation loss: 2.190823953890761

Epoch: 5| Step: 5
Training loss: 0.42393778775393925
Validation loss: 2.2066519398680065

Epoch: 5| Step: 6
Training loss: 0.5287428486568135
Validation loss: 2.166092541767175

Epoch: 5| Step: 7
Training loss: 0.49919189774914113
Validation loss: 2.1611010424547437

Epoch: 5| Step: 8
Training loss: 0.4818474133087108
Validation loss: 2.2163719641337676

Epoch: 5| Step: 9
Training loss: 1.0582498364789743
Validation loss: 2.304622815397422

Epoch: 5| Step: 10
Training loss: 0.5618922606247327
Validation loss: 2.2691919126292452

Epoch: 679| Step: 0
Training loss: 0.6825305190616249
Validation loss: 2.2163206773555806

Epoch: 5| Step: 1
Training loss: 1.1599165543599712
Validation loss: 2.249600666709632

Epoch: 5| Step: 2
Training loss: 0.571869253953093
Validation loss: 2.2391922395827226

Epoch: 5| Step: 3
Training loss: 0.5526884888921939
Validation loss: 2.1846203180337462

Epoch: 5| Step: 4
Training loss: 0.5269841698959928
Validation loss: 2.1594641462631428

Epoch: 5| Step: 5
Training loss: 0.438025873754699
Validation loss: 2.1976304825603905

Epoch: 5| Step: 6
Training loss: 0.4851018773814612
Validation loss: 2.1496057431010795

Epoch: 5| Step: 7
Training loss: 0.5260913246309611
Validation loss: 2.1833562392130954

Epoch: 5| Step: 8
Training loss: 0.4769978957599635
Validation loss: 2.1389385910218635

Epoch: 5| Step: 9
Training loss: 0.4225269860333987
Validation loss: 2.253164083351701

Epoch: 5| Step: 10
Training loss: 0.40922007213494016
Validation loss: 2.1165480188117054

Epoch: 680| Step: 0
Training loss: 0.5669247325964715
Validation loss: 2.1979521601912273

Epoch: 5| Step: 1
Training loss: 0.396135110595465
Validation loss: 2.2248603455740197

Epoch: 5| Step: 2
Training loss: 1.094284471986372
Validation loss: 2.233443375975581

Epoch: 5| Step: 3
Training loss: 0.5959568671453591
Validation loss: 2.1643620481361747

Epoch: 5| Step: 4
Training loss: 0.5032746844616959
Validation loss: 2.2030949337083774

Epoch: 5| Step: 5
Training loss: 0.41494602731388136
Validation loss: 2.2137945095670717

Epoch: 5| Step: 6
Training loss: 0.41651531888077115
Validation loss: 2.155999751562642

Epoch: 5| Step: 7
Training loss: 0.37864686011691584
Validation loss: 2.219480700109481

Epoch: 5| Step: 8
Training loss: 0.4697260073462237
Validation loss: 2.1725049005831214

Epoch: 5| Step: 9
Training loss: 0.5534879312741579
Validation loss: 2.25029185782392

Epoch: 5| Step: 10
Training loss: 0.5580364461621526
Validation loss: 2.224247412325434

Epoch: 681| Step: 0
Training loss: 0.5439288480996092
Validation loss: 2.2034432658327683

Epoch: 5| Step: 1
Training loss: 0.6551460108103598
Validation loss: 2.2433837178502203

Epoch: 5| Step: 2
Training loss: 0.3643642607491837
Validation loss: 2.232963319144238

Epoch: 5| Step: 3
Training loss: 0.43482898343036563
Validation loss: 2.2579422771622006

Epoch: 5| Step: 4
Training loss: 1.0560667838378686
Validation loss: 2.1570986991242704

Epoch: 5| Step: 5
Training loss: 0.6320761646961462
Validation loss: 2.187426682164988

Epoch: 5| Step: 6
Training loss: 0.47397564936714676
Validation loss: 2.210912666281341

Epoch: 5| Step: 7
Training loss: 0.4228413604844731
Validation loss: 2.1807674314777086

Epoch: 5| Step: 8
Training loss: 0.6924285443137682
Validation loss: 2.247785107016935

Epoch: 5| Step: 9
Training loss: 0.4129760632136228
Validation loss: 2.1815776705886174

Epoch: 5| Step: 10
Training loss: 0.5361519064916589
Validation loss: 2.2030073821189373

Epoch: 682| Step: 0
Training loss: 0.4661674565533704
Validation loss: 2.153652097758361

Epoch: 5| Step: 1
Training loss: 0.5591356809769811
Validation loss: 2.2085601433221917

Epoch: 5| Step: 2
Training loss: 0.5452019850006967
Validation loss: 2.156262861858171

Epoch: 5| Step: 3
Training loss: 0.5795378561252763
Validation loss: 2.2072965363231773

Epoch: 5| Step: 4
Training loss: 0.6249160471798375
Validation loss: 2.2653348120907926

Epoch: 5| Step: 5
Training loss: 0.5784812036096657
Validation loss: 2.1714453730778205

Epoch: 5| Step: 6
Training loss: 0.4023871166968178
Validation loss: 2.1728742910267718

Epoch: 5| Step: 7
Training loss: 0.4786745391417925
Validation loss: 2.2177726109938454

Epoch: 5| Step: 8
Training loss: 0.4738191847496334
Validation loss: 2.2127736640707054

Epoch: 5| Step: 9
Training loss: 0.44020303108583436
Validation loss: 2.2094549402108985

Epoch: 5| Step: 10
Training loss: 1.08265904691987
Validation loss: 2.2292461377264248

Epoch: 683| Step: 0
Training loss: 0.5566285249164575
Validation loss: 2.2215030476349527

Epoch: 5| Step: 1
Training loss: 0.5502151393601836
Validation loss: 2.130939584885355

Epoch: 5| Step: 2
Training loss: 1.1360302704888277
Validation loss: 2.201487014692004

Epoch: 5| Step: 3
Training loss: 0.48806077175589124
Validation loss: 2.20852904827187

Epoch: 5| Step: 4
Training loss: 0.47269644448113507
Validation loss: 2.296572520993512

Epoch: 5| Step: 5
Training loss: 0.530897977546839
Validation loss: 2.1877708466614862

Epoch: 5| Step: 6
Training loss: 0.5803614993508283
Validation loss: 2.2051928016339266

Epoch: 5| Step: 7
Training loss: 0.382893845615257
Validation loss: 2.226209580366354

Epoch: 5| Step: 8
Training loss: 0.4043492822266424
Validation loss: 2.2752189840840313

Epoch: 5| Step: 9
Training loss: 0.5619434146156163
Validation loss: 2.226357020460626

Epoch: 5| Step: 10
Training loss: 0.6933248162052121
Validation loss: 2.1755188823367546

Epoch: 684| Step: 0
Training loss: 0.4465075068851967
Validation loss: 2.261279553927292

Epoch: 5| Step: 1
Training loss: 0.6032694342226015
Validation loss: 2.123267283484562

Epoch: 5| Step: 2
Training loss: 1.0954864886176252
Validation loss: 2.2149848679621233

Epoch: 5| Step: 3
Training loss: 0.4065553911131509
Validation loss: 2.2051689716134213

Epoch: 5| Step: 4
Training loss: 0.5426475068587173
Validation loss: 2.2407863795954865

Epoch: 5| Step: 5
Training loss: 0.45174549843002465
Validation loss: 2.1668164479125123

Epoch: 5| Step: 6
Training loss: 0.47439290828349473
Validation loss: 2.2054091951021695

Epoch: 5| Step: 7
Training loss: 0.6094114586120613
Validation loss: 2.1799590585963506

Epoch: 5| Step: 8
Training loss: 0.48173217274651586
Validation loss: 2.2052886062270654

Epoch: 5| Step: 9
Training loss: 0.7239619650623882
Validation loss: 2.1609302759830182

Epoch: 5| Step: 10
Training loss: 0.6067332200165131
Validation loss: 2.2229255037254814

Epoch: 685| Step: 0
Training loss: 0.6004698850574829
Validation loss: 2.3122137303249057

Epoch: 5| Step: 1
Training loss: 0.5519852701101535
Validation loss: 2.2376547562310596

Epoch: 5| Step: 2
Training loss: 0.6551517879626175
Validation loss: 2.300029170211139

Epoch: 5| Step: 3
Training loss: 0.5132290341832794
Validation loss: 2.262468043339427

Epoch: 5| Step: 4
Training loss: 0.5233314178921742
Validation loss: 2.244428040786906

Epoch: 5| Step: 5
Training loss: 1.0832600691059078
Validation loss: 2.18264839565006

Epoch: 5| Step: 6
Training loss: 0.49456185642404477
Validation loss: 2.2084008293803605

Epoch: 5| Step: 7
Training loss: 0.5326908151607797
Validation loss: 2.2355048090276144

Epoch: 5| Step: 8
Training loss: 0.6044394080272257
Validation loss: 2.2457241735523503

Epoch: 5| Step: 9
Training loss: 0.5855028193151027
Validation loss: 2.263146024933471

Epoch: 5| Step: 10
Training loss: 0.5678747936334892
Validation loss: 2.1620174103496006

Epoch: 686| Step: 0
Training loss: 0.6170043190599374
Validation loss: 2.146046313014696

Epoch: 5| Step: 1
Training loss: 0.4519817300380798
Validation loss: 2.186118502719332

Epoch: 5| Step: 2
Training loss: 0.5729911033362448
Validation loss: 2.188692287729614

Epoch: 5| Step: 3
Training loss: 0.5111329605982752
Validation loss: 2.123236767345806

Epoch: 5| Step: 4
Training loss: 0.46199886519428934
Validation loss: 2.23452531334932

Epoch: 5| Step: 5
Training loss: 0.6269563336156577
Validation loss: 2.197572852018623

Epoch: 5| Step: 6
Training loss: 1.076249301569022
Validation loss: 2.212386683649076

Epoch: 5| Step: 7
Training loss: 0.4862418347141388
Validation loss: 2.2244787846158713

Epoch: 5| Step: 8
Training loss: 0.5773370889529796
Validation loss: 2.2989810041701126

Epoch: 5| Step: 9
Training loss: 0.5729395312746297
Validation loss: 2.304450039095449

Epoch: 5| Step: 10
Training loss: 0.446604377325979
Validation loss: 2.290106039687753

Epoch: 687| Step: 0
Training loss: 0.7220914540950387
Validation loss: 2.2226435681877756

Epoch: 5| Step: 1
Training loss: 0.5625486617762291
Validation loss: 2.2323135755798855

Epoch: 5| Step: 2
Training loss: 0.5251762491655604
Validation loss: 2.2214343090151814

Epoch: 5| Step: 3
Training loss: 0.4001758650768884
Validation loss: 2.1807974270671706

Epoch: 5| Step: 4
Training loss: 0.3775931543081747
Validation loss: 2.149273230324903

Epoch: 5| Step: 5
Training loss: 0.6929888312731988
Validation loss: 2.1790644322327304

Epoch: 5| Step: 6
Training loss: 0.4314919815622436
Validation loss: 2.1555563661274757

Epoch: 5| Step: 7
Training loss: 0.6009825598634752
Validation loss: 2.186739179554777

Epoch: 5| Step: 8
Training loss: 0.38548969745351686
Validation loss: 2.224975388729432

Epoch: 5| Step: 9
Training loss: 1.0751769075542135
Validation loss: 2.2147072301111037

Epoch: 5| Step: 10
Training loss: 0.7377287800786888
Validation loss: 2.223302398394233

Epoch: 688| Step: 0
Training loss: 0.44023371563568425
Validation loss: 2.2495255910135477

Epoch: 5| Step: 1
Training loss: 0.5044397295100381
Validation loss: 2.186861761362944

Epoch: 5| Step: 2
Training loss: 0.47178263360233935
Validation loss: 2.2311567769669067

Epoch: 5| Step: 3
Training loss: 0.3739420152289886
Validation loss: 2.2712383588309404

Epoch: 5| Step: 4
Training loss: 0.9983176444502689
Validation loss: 2.1692018262437207

Epoch: 5| Step: 5
Training loss: 0.4764436667447441
Validation loss: 2.231468152493674

Epoch: 5| Step: 6
Training loss: 0.3948787254358214
Validation loss: 2.159138466863279

Epoch: 5| Step: 7
Training loss: 0.5282365376444592
Validation loss: 2.1385128450399264

Epoch: 5| Step: 8
Training loss: 0.47836946084608617
Validation loss: 2.2378293570747503

Epoch: 5| Step: 9
Training loss: 0.5192414529562566
Validation loss: 2.2335059015104206

Epoch: 5| Step: 10
Training loss: 0.658291932405747
Validation loss: 2.227853016684172

Epoch: 689| Step: 0
Training loss: 0.49077104168622304
Validation loss: 2.3059644006305873

Epoch: 5| Step: 1
Training loss: 0.31816059764008126
Validation loss: 2.176976093285382

Epoch: 5| Step: 2
Training loss: 0.6298352600600501
Validation loss: 2.2352918881595976

Epoch: 5| Step: 3
Training loss: 0.533046433897142
Validation loss: 2.265648137569563

Epoch: 5| Step: 4
Training loss: 1.0201995530054773
Validation loss: 2.212529120494913

Epoch: 5| Step: 5
Training loss: 0.46498525693553355
Validation loss: 2.1944018227369577

Epoch: 5| Step: 6
Training loss: 0.7068804374573388
Validation loss: 2.1909799386883986

Epoch: 5| Step: 7
Training loss: 0.46880866319423586
Validation loss: 2.191483179584298

Epoch: 5| Step: 8
Training loss: 0.5710157735169124
Validation loss: 2.1460921333278495

Epoch: 5| Step: 9
Training loss: 0.45404469123671465
Validation loss: 2.190948051787048

Epoch: 5| Step: 10
Training loss: 0.3422482262468595
Validation loss: 2.246114424814997

Epoch: 690| Step: 0
Training loss: 0.6613676028965416
Validation loss: 2.261776496158096

Epoch: 5| Step: 1
Training loss: 0.45454201615723683
Validation loss: 2.2262397421360505

Epoch: 5| Step: 2
Training loss: 1.048838013330656
Validation loss: 2.1588827381380633

Epoch: 5| Step: 3
Training loss: 0.6550893738246583
Validation loss: 2.2354886989511478

Epoch: 5| Step: 4
Training loss: 0.459185568359308
Validation loss: 2.27336618294476

Epoch: 5| Step: 5
Training loss: 0.5704575968069767
Validation loss: 2.1882107073838433

Epoch: 5| Step: 6
Training loss: 0.3613161033486324
Validation loss: 2.198917888896779

Epoch: 5| Step: 7
Training loss: 0.40775791329049743
Validation loss: 2.2169743454441013

Epoch: 5| Step: 8
Training loss: 0.48757275869811506
Validation loss: 2.213126428058317

Epoch: 5| Step: 9
Training loss: 0.6269985194424514
Validation loss: 2.186726863901879

Epoch: 5| Step: 10
Training loss: 0.45731693696198333
Validation loss: 2.1828534410091196

Epoch: 691| Step: 0
Training loss: 0.44524540312041705
Validation loss: 2.248646504511971

Epoch: 5| Step: 1
Training loss: 0.6760878997260454
Validation loss: 2.2118768557909623

Epoch: 5| Step: 2
Training loss: 1.0120152808456804
Validation loss: 2.1869383312077773

Epoch: 5| Step: 3
Training loss: 0.419197522342891
Validation loss: 2.2454738474508704

Epoch: 5| Step: 4
Training loss: 0.38205063191493793
Validation loss: 2.2385054432389393

Epoch: 5| Step: 5
Training loss: 0.5128457566193502
Validation loss: 2.2269451734343244

Epoch: 5| Step: 6
Training loss: 0.40540506454455594
Validation loss: 2.265370123716636

Epoch: 5| Step: 7
Training loss: 0.5510296092550075
Validation loss: 2.2147126509244015

Epoch: 5| Step: 8
Training loss: 0.5746484562947286
Validation loss: 2.2128314617731153

Epoch: 5| Step: 9
Training loss: 0.5705203892393429
Validation loss: 2.2022815766416826

Epoch: 5| Step: 10
Training loss: 0.44653305295646567
Validation loss: 2.163898117487561

Epoch: 692| Step: 0
Training loss: 0.5640244753799173
Validation loss: 2.2257087975008503

Epoch: 5| Step: 1
Training loss: 0.5460308098711296
Validation loss: 2.2042810482923185

Epoch: 5| Step: 2
Training loss: 0.43414743829652586
Validation loss: 2.236741122087051

Epoch: 5| Step: 3
Training loss: 0.48291111281621324
Validation loss: 2.227473146905063

Epoch: 5| Step: 4
Training loss: 0.9765598754847545
Validation loss: 2.2065976481321106

Epoch: 5| Step: 5
Training loss: 0.6180032578200361
Validation loss: 2.1613432694334938

Epoch: 5| Step: 6
Training loss: 0.4043003211127947
Validation loss: 2.2122068843759415

Epoch: 5| Step: 7
Training loss: 0.6401656527639893
Validation loss: 2.1971645385386784

Epoch: 5| Step: 8
Training loss: 0.37081053115448065
Validation loss: 2.215531779766891

Epoch: 5| Step: 9
Training loss: 0.37835988244970437
Validation loss: 2.254469452197746

Epoch: 5| Step: 10
Training loss: 0.5849459842050694
Validation loss: 2.1634920739002492

Epoch: 693| Step: 0
Training loss: 0.5476393671195191
Validation loss: 2.207781613836983

Epoch: 5| Step: 1
Training loss: 0.5556932921004234
Validation loss: 2.204610409505173

Epoch: 5| Step: 2
Training loss: 0.5401610086731848
Validation loss: 2.1252118689076536

Epoch: 5| Step: 3
Training loss: 0.42694517164858525
Validation loss: 2.1789634226136587

Epoch: 5| Step: 4
Training loss: 0.45587337573729364
Validation loss: 2.2612031585614876

Epoch: 5| Step: 5
Training loss: 0.30683232043663927
Validation loss: 2.149784290227007

Epoch: 5| Step: 6
Training loss: 0.5839347180334238
Validation loss: 2.2321605728079255

Epoch: 5| Step: 7
Training loss: 0.42653466856991845
Validation loss: 2.1993299927609353

Epoch: 5| Step: 8
Training loss: 0.6014739627831253
Validation loss: 2.284373746401129

Epoch: 5| Step: 9
Training loss: 0.5289521167876119
Validation loss: 2.221857961565074

Epoch: 5| Step: 10
Training loss: 1.1474877407108919
Validation loss: 2.217193297747197

Epoch: 694| Step: 0
Training loss: 0.3697348761492869
Validation loss: 2.215758786222943

Epoch: 5| Step: 1
Training loss: 0.5068977332985055
Validation loss: 2.2563235836547424

Epoch: 5| Step: 2
Training loss: 1.0123544706144056
Validation loss: 2.2612588975932977

Epoch: 5| Step: 3
Training loss: 0.41615864260951724
Validation loss: 2.1871797505945754

Epoch: 5| Step: 4
Training loss: 0.4904080877253236
Validation loss: 2.2216132345609267

Epoch: 5| Step: 5
Training loss: 0.49390128147965384
Validation loss: 2.216784619941716

Epoch: 5| Step: 6
Training loss: 0.5745249340632502
Validation loss: 2.1873190938326426

Epoch: 5| Step: 7
Training loss: 0.5215498065260963
Validation loss: 2.1810774420188483

Epoch: 5| Step: 8
Training loss: 0.5499024651482729
Validation loss: 2.1888695152242517

Epoch: 5| Step: 9
Training loss: 0.6213290890293228
Validation loss: 2.186466051207356

Epoch: 5| Step: 10
Training loss: 0.4832684274644191
Validation loss: 2.225406951208796

Epoch: 695| Step: 0
Training loss: 0.4396268035161844
Validation loss: 2.1715097581342966

Epoch: 5| Step: 1
Training loss: 0.470395521902848
Validation loss: 2.254705600442587

Epoch: 5| Step: 2
Training loss: 0.5912566284227511
Validation loss: 2.160855919608335

Epoch: 5| Step: 3
Training loss: 0.43207781645926224
Validation loss: 2.2126719293568513

Epoch: 5| Step: 4
Training loss: 1.246914249653305
Validation loss: 2.182845302092236

Epoch: 5| Step: 5
Training loss: 0.7408195336697561
Validation loss: 2.2660981111106904

Epoch: 5| Step: 6
Training loss: 0.5309193648125706
Validation loss: 2.217186828780606

Epoch: 5| Step: 7
Training loss: 0.5104598364447336
Validation loss: 2.240129845328852

Epoch: 5| Step: 8
Training loss: 0.4157626318535146
Validation loss: 2.2341607126802567

Epoch: 5| Step: 9
Training loss: 0.5055043804929746
Validation loss: 2.2200959216665974

Epoch: 5| Step: 10
Training loss: 0.3855154409222984
Validation loss: 2.2115728280830993

Epoch: 696| Step: 0
Training loss: 0.5432043319199353
Validation loss: 2.1955153409112658

Epoch: 5| Step: 1
Training loss: 0.4328722234345542
Validation loss: 2.2262938024466887

Epoch: 5| Step: 2
Training loss: 0.40681128974344205
Validation loss: 2.119885962402261

Epoch: 5| Step: 3
Training loss: 0.48710331549772073
Validation loss: 2.164164567584416

Epoch: 5| Step: 4
Training loss: 0.528442086730578
Validation loss: 2.2635976612577617

Epoch: 5| Step: 5
Training loss: 0.3573915228958535
Validation loss: 2.269330050871108

Epoch: 5| Step: 6
Training loss: 0.47426833155951265
Validation loss: 2.247514585397274

Epoch: 5| Step: 7
Training loss: 0.529110414664004
Validation loss: 2.2403065465035894

Epoch: 5| Step: 8
Training loss: 0.54737433389195
Validation loss: 2.190121875163767

Epoch: 5| Step: 9
Training loss: 1.0878561620544158
Validation loss: 2.2625347364804074

Epoch: 5| Step: 10
Training loss: 0.5461043786582186
Validation loss: 2.2698545857648593

Epoch: 697| Step: 0
Training loss: 1.134690930637898
Validation loss: 2.221891867101974

Epoch: 5| Step: 1
Training loss: 0.42457046190105313
Validation loss: 2.13080821368715

Epoch: 5| Step: 2
Training loss: 0.4731056346986722
Validation loss: 2.2425765387870524

Epoch: 5| Step: 3
Training loss: 0.593699754295536
Validation loss: 2.226470712793045

Epoch: 5| Step: 4
Training loss: 0.4380354329630863
Validation loss: 2.2232838176209415

Epoch: 5| Step: 5
Training loss: 0.45034082671740006
Validation loss: 2.2508355290451165

Epoch: 5| Step: 6
Training loss: 0.46957126834074914
Validation loss: 2.232591811987128

Epoch: 5| Step: 7
Training loss: 0.41502033864589544
Validation loss: 2.159864598118478

Epoch: 5| Step: 8
Training loss: 0.4205577205908504
Validation loss: 2.1513839191571518

Epoch: 5| Step: 9
Training loss: 0.5365157852765864
Validation loss: 2.209002617637299

Epoch: 5| Step: 10
Training loss: 0.6512018591574249
Validation loss: 2.241565068136018

Epoch: 698| Step: 0
Training loss: 0.539351869398792
Validation loss: 2.243132905985094

Epoch: 5| Step: 1
Training loss: 0.4054246183865575
Validation loss: 2.188364578237821

Epoch: 5| Step: 2
Training loss: 0.3984542917939297
Validation loss: 2.1793781034026027

Epoch: 5| Step: 3
Training loss: 0.5403880255949475
Validation loss: 2.264750960499044

Epoch: 5| Step: 4
Training loss: 1.0307495752556235
Validation loss: 2.1754920876165516

Epoch: 5| Step: 5
Training loss: 0.5458236943430029
Validation loss: 2.201861331924019

Epoch: 5| Step: 6
Training loss: 0.47609720810378275
Validation loss: 2.2023453547136813

Epoch: 5| Step: 7
Training loss: 0.6045333281338592
Validation loss: 2.234774673620574

Epoch: 5| Step: 8
Training loss: 0.4977999205834834
Validation loss: 2.149190476248791

Epoch: 5| Step: 9
Training loss: 0.4529036441634048
Validation loss: 2.2398973565803577

Epoch: 5| Step: 10
Training loss: 0.5689235129143047
Validation loss: 2.163174199418149

Epoch: 699| Step: 0
Training loss: 0.37344183659928504
Validation loss: 2.251087522940534

Epoch: 5| Step: 1
Training loss: 0.6045968453518372
Validation loss: 2.228941742669822

Epoch: 5| Step: 2
Training loss: 0.4217287622530341
Validation loss: 2.244769265831808

Epoch: 5| Step: 3
Training loss: 0.4522895675123161
Validation loss: 2.193210059688325

Epoch: 5| Step: 4
Training loss: 0.5219278914095096
Validation loss: 2.3243908377314746

Epoch: 5| Step: 5
Training loss: 0.378797181152502
Validation loss: 2.2454056422763182

Epoch: 5| Step: 6
Training loss: 0.5967131010648689
Validation loss: 2.19283251203357

Epoch: 5| Step: 7
Training loss: 0.40049943143349437
Validation loss: 2.2465748050369316

Epoch: 5| Step: 8
Training loss: 1.0211481011306582
Validation loss: 2.2028583896784397

Epoch: 5| Step: 9
Training loss: 0.483678008644328
Validation loss: 2.324682512459508

Epoch: 5| Step: 10
Training loss: 0.4477788820445709
Validation loss: 2.214537851660727

Epoch: 700| Step: 0
Training loss: 0.5877036877862889
Validation loss: 2.246624264619889

Epoch: 5| Step: 1
Training loss: 0.5337675970334829
Validation loss: 2.1840336408798944

Epoch: 5| Step: 2
Training loss: 0.3292448258359087
Validation loss: 2.173332056700946

Epoch: 5| Step: 3
Training loss: 0.5776613283437143
Validation loss: 2.258730085679328

Epoch: 5| Step: 4
Training loss: 0.4836740343935723
Validation loss: 2.1681621299346836

Epoch: 5| Step: 5
Training loss: 0.5880802140326377
Validation loss: 2.2034935062313252

Epoch: 5| Step: 6
Training loss: 0.982406403740163
Validation loss: 2.181768812042331

Epoch: 5| Step: 7
Training loss: 0.49488074019577283
Validation loss: 2.1674305308437956

Epoch: 5| Step: 8
Training loss: 0.4084442375695624
Validation loss: 2.196053427899022

Epoch: 5| Step: 9
Training loss: 0.4681608153012957
Validation loss: 2.1729862671987066

Epoch: 5| Step: 10
Training loss: 0.48081246154162194
Validation loss: 2.2005122918122595

Epoch: 701| Step: 0
Training loss: 0.4527949249089736
Validation loss: 2.106336374338443

Epoch: 5| Step: 1
Training loss: 0.511253961207333
Validation loss: 2.1966671860441704

Epoch: 5| Step: 2
Training loss: 0.6059741218363809
Validation loss: 2.139297265202146

Epoch: 5| Step: 3
Training loss: 0.9870994648890706
Validation loss: 2.1598286037093204

Epoch: 5| Step: 4
Training loss: 0.6002507957189482
Validation loss: 2.1572676711222676

Epoch: 5| Step: 5
Training loss: 0.47170521289952577
Validation loss: 2.210016733506272

Epoch: 5| Step: 6
Training loss: 0.3312039109321631
Validation loss: 2.2532420323937656

Epoch: 5| Step: 7
Training loss: 0.5503836745722817
Validation loss: 2.1544110025247325

Epoch: 5| Step: 8
Training loss: 0.46418253569582657
Validation loss: 2.1069586838796197

Epoch: 5| Step: 9
Training loss: 0.5170345691102867
Validation loss: 2.2942455002104256

Epoch: 5| Step: 10
Training loss: 0.40482400999893414
Validation loss: 2.231771357524492

Epoch: 702| Step: 0
Training loss: 0.645604090356632
Validation loss: 2.2181634550845346

Epoch: 5| Step: 1
Training loss: 0.6724650431343409
Validation loss: 2.2603624485848233

Epoch: 5| Step: 2
Training loss: 0.38912023629134895
Validation loss: 2.213981852378754

Epoch: 5| Step: 3
Training loss: 0.45633115699830545
Validation loss: 2.176414948448268

Epoch: 5| Step: 4
Training loss: 0.5394157137041982
Validation loss: 2.2689634875294673

Epoch: 5| Step: 5
Training loss: 0.3876580861858039
Validation loss: 2.2488067361401383

Epoch: 5| Step: 6
Training loss: 0.9547120935546956
Validation loss: 2.1922874799943077

Epoch: 5| Step: 7
Training loss: 0.434801670167149
Validation loss: 2.2163057661548047

Epoch: 5| Step: 8
Training loss: 0.5112686215859039
Validation loss: 2.1858683488095947

Epoch: 5| Step: 9
Training loss: 0.31084785031653284
Validation loss: 2.2198150426422467

Epoch: 5| Step: 10
Training loss: 0.4380862191378351
Validation loss: 2.1609807680491326

Epoch: 703| Step: 0
Training loss: 0.4380498734356763
Validation loss: 2.211025840240617

Epoch: 5| Step: 1
Training loss: 1.0216482698382496
Validation loss: 2.19633415738091

Epoch: 5| Step: 2
Training loss: 0.47271001525765743
Validation loss: 2.2704272923706537

Epoch: 5| Step: 3
Training loss: 0.4278756174099229
Validation loss: 2.251963967168234

Epoch: 5| Step: 4
Training loss: 0.6356930105757934
Validation loss: 2.2206402343655234

Epoch: 5| Step: 5
Training loss: 0.5223099249666413
Validation loss: 2.2826373519672742

Epoch: 5| Step: 6
Training loss: 0.6867789909317654
Validation loss: 2.202472985631936

Epoch: 5| Step: 7
Training loss: 0.47399150990777567
Validation loss: 2.215058516064599

Epoch: 5| Step: 8
Training loss: 0.4147639181619669
Validation loss: 2.1566580418567076

Epoch: 5| Step: 9
Training loss: 0.550599927342206
Validation loss: 2.181963897422575

Epoch: 5| Step: 10
Training loss: 0.4276745898126557
Validation loss: 2.236912389295721

Epoch: 704| Step: 0
Training loss: 0.9324956525133666
Validation loss: 2.2667689382087834

Epoch: 5| Step: 1
Training loss: 0.5203610726902025
Validation loss: 2.2932855595069577

Epoch: 5| Step: 2
Training loss: 0.7050304449555416
Validation loss: 2.217127243099976

Epoch: 5| Step: 3
Training loss: 0.4975851574096995
Validation loss: 2.220962097616019

Epoch: 5| Step: 4
Training loss: 0.45624646028687127
Validation loss: 2.206677698669105

Epoch: 5| Step: 5
Training loss: 0.34861258440077886
Validation loss: 2.203226106212124

Epoch: 5| Step: 6
Training loss: 0.3542940621227575
Validation loss: 2.2772656054452045

Epoch: 5| Step: 7
Training loss: 0.5697408973164211
Validation loss: 2.221008600124617

Epoch: 5| Step: 8
Training loss: 0.5022585344192345
Validation loss: 2.160665523593233

Epoch: 5| Step: 9
Training loss: 0.5683618919080868
Validation loss: 2.2372936975182323

Epoch: 5| Step: 10
Training loss: 0.4733775443962381
Validation loss: 2.231782391930406

Epoch: 705| Step: 0
Training loss: 0.3757648813406161
Validation loss: 2.204473404153306

Epoch: 5| Step: 1
Training loss: 0.49470517925159924
Validation loss: 2.191783780748235

Epoch: 5| Step: 2
Training loss: 0.6100283568076079
Validation loss: 2.2082801118993793

Epoch: 5| Step: 3
Training loss: 0.44579538298197385
Validation loss: 2.275985676160369

Epoch: 5| Step: 4
Training loss: 0.4243182675021211
Validation loss: 2.134267619615456

Epoch: 5| Step: 5
Training loss: 0.39433863630878074
Validation loss: 2.233279502858447

Epoch: 5| Step: 6
Training loss: 0.5373354904014764
Validation loss: 2.1571619323672864

Epoch: 5| Step: 7
Training loss: 0.537132567858631
Validation loss: 2.20746056260418

Epoch: 5| Step: 8
Training loss: 0.4904462500859066
Validation loss: 2.183248885346329

Epoch: 5| Step: 9
Training loss: 0.8946056751457542
Validation loss: 2.2911826320793462

Epoch: 5| Step: 10
Training loss: 0.46939239987810194
Validation loss: 2.1983759433796037

Epoch: 706| Step: 0
Training loss: 0.5937283913545184
Validation loss: 2.1566497755526393

Epoch: 5| Step: 1
Training loss: 0.3835298667589978
Validation loss: 2.1632626414226825

Epoch: 5| Step: 2
Training loss: 0.4311990507408674
Validation loss: 2.2380032134655763

Epoch: 5| Step: 3
Training loss: 0.39886543256354706
Validation loss: 2.2865009063301063

Epoch: 5| Step: 4
Training loss: 0.47265205696705154
Validation loss: 2.2225484044205888

Epoch: 5| Step: 5
Training loss: 0.45532563645493207
Validation loss: 2.2386265429144454

Epoch: 5| Step: 6
Training loss: 0.5962456905761069
Validation loss: 2.205242412776048

Epoch: 5| Step: 7
Training loss: 0.3310535172073249
Validation loss: 2.1962116834635212

Epoch: 5| Step: 8
Training loss: 1.012580534004505
Validation loss: 2.240052512365668

Epoch: 5| Step: 9
Training loss: 0.4565273833036999
Validation loss: 2.2367742020211345

Epoch: 5| Step: 10
Training loss: 0.4875839747949133
Validation loss: 2.1888769044182426

Epoch: 707| Step: 0
Training loss: 0.5213139001754107
Validation loss: 2.125539820880971

Epoch: 5| Step: 1
Training loss: 0.5265722777593608
Validation loss: 2.1893127103069063

Epoch: 5| Step: 2
Training loss: 0.5044726655604074
Validation loss: 2.19912697561531

Epoch: 5| Step: 3
Training loss: 0.48240269302348726
Validation loss: 2.291997575407731

Epoch: 5| Step: 4
Training loss: 0.4461955968034263
Validation loss: 2.2030015345165213

Epoch: 5| Step: 5
Training loss: 0.4315267559389058
Validation loss: 2.227399150806983

Epoch: 5| Step: 6
Training loss: 0.47641034120458875
Validation loss: 2.2013884162516297

Epoch: 5| Step: 7
Training loss: 0.5565601759213604
Validation loss: 2.2085981235422905

Epoch: 5| Step: 8
Training loss: 0.49881671423470764
Validation loss: 2.164245578770275

Epoch: 5| Step: 9
Training loss: 1.0183621422979159
Validation loss: 2.20065466487239

Epoch: 5| Step: 10
Training loss: 0.6443232345138291
Validation loss: 2.231313699238317

Epoch: 708| Step: 0
Training loss: 0.39960335347550757
Validation loss: 2.2178505191155695

Epoch: 5| Step: 1
Training loss: 0.4402610980557017
Validation loss: 2.1750423400401355

Epoch: 5| Step: 2
Training loss: 0.5724263665267895
Validation loss: 2.145260536579015

Epoch: 5| Step: 3
Training loss: 0.47788218397387816
Validation loss: 2.220054562999445

Epoch: 5| Step: 4
Training loss: 0.4428581563958862
Validation loss: 2.258672179913911

Epoch: 5| Step: 5
Training loss: 0.5412203404887613
Validation loss: 2.1757779072677885

Epoch: 5| Step: 6
Training loss: 1.0358799545852717
Validation loss: 2.207940359397327

Epoch: 5| Step: 7
Training loss: 0.4177682342133931
Validation loss: 2.271041342029375

Epoch: 5| Step: 8
Training loss: 0.5067382894836884
Validation loss: 2.205953644688857

Epoch: 5| Step: 9
Training loss: 0.5512489064956164
Validation loss: 2.233548568647784

Epoch: 5| Step: 10
Training loss: 0.5923679227935477
Validation loss: 2.2692649876725337

Epoch: 709| Step: 0
Training loss: 0.4873996863715971
Validation loss: 2.2512492969475377

Epoch: 5| Step: 1
Training loss: 0.3148145553267309
Validation loss: 2.2214215983000254

Epoch: 5| Step: 2
Training loss: 0.5418648510062798
Validation loss: 2.1791164488011803

Epoch: 5| Step: 3
Training loss: 0.6302024562551147
Validation loss: 2.2279126969575365

Epoch: 5| Step: 4
Training loss: 0.2538106444900874
Validation loss: 2.2566549924438015

Epoch: 5| Step: 5
Training loss: 0.5037371033657609
Validation loss: 2.1301755275066103

Epoch: 5| Step: 6
Training loss: 0.5315823917602837
Validation loss: 2.167371839426071

Epoch: 5| Step: 7
Training loss: 0.4710664415431211
Validation loss: 2.209621463166241

Epoch: 5| Step: 8
Training loss: 1.0117280584076491
Validation loss: 2.2388991546867096

Epoch: 5| Step: 9
Training loss: 0.44161297168865765
Validation loss: 2.191822317179717

Epoch: 5| Step: 10
Training loss: 0.5604509012290426
Validation loss: 2.2323981243378763

Epoch: 710| Step: 0
Training loss: 0.3612170693128811
Validation loss: 2.181325238913521

Epoch: 5| Step: 1
Training loss: 0.5463689915403688
Validation loss: 2.2154637330036855

Epoch: 5| Step: 2
Training loss: 0.489539425145768
Validation loss: 2.209578608971379

Epoch: 5| Step: 3
Training loss: 0.5030065385192536
Validation loss: 2.2333839169563667

Epoch: 5| Step: 4
Training loss: 0.49675889368067827
Validation loss: 2.2491887075827237

Epoch: 5| Step: 5
Training loss: 0.5566180040548213
Validation loss: 2.234285175684478

Epoch: 5| Step: 6
Training loss: 1.0143630771089034
Validation loss: 2.203942870789499

Epoch: 5| Step: 7
Training loss: 0.5201635886511425
Validation loss: 2.215771687931232

Epoch: 5| Step: 8
Training loss: 0.4279152997034384
Validation loss: 2.2393490858883296

Epoch: 5| Step: 9
Training loss: 0.42780167559687476
Validation loss: 2.198608394174207

Epoch: 5| Step: 10
Training loss: 0.7585923026922623
Validation loss: 2.1922700191672315

Epoch: 711| Step: 0
Training loss: 0.37332851703054676
Validation loss: 2.2414216096278916

Epoch: 5| Step: 1
Training loss: 0.41074548811590855
Validation loss: 2.2609836084198247

Epoch: 5| Step: 2
Training loss: 1.0408543216634478
Validation loss: 2.145594652782009

Epoch: 5| Step: 3
Training loss: 0.4705927232614203
Validation loss: 2.231086264028264

Epoch: 5| Step: 4
Training loss: 0.3275878119315785
Validation loss: 2.1891956829856465

Epoch: 5| Step: 5
Training loss: 0.5559458361767795
Validation loss: 2.209794971464123

Epoch: 5| Step: 6
Training loss: 0.4568576809200585
Validation loss: 2.16597643768083

Epoch: 5| Step: 7
Training loss: 0.5294375355882287
Validation loss: 2.2407172188448534

Epoch: 5| Step: 8
Training loss: 0.3830094901071989
Validation loss: 2.2410551561032626

Epoch: 5| Step: 9
Training loss: 0.5680052712726458
Validation loss: 2.229599832888019

Epoch: 5| Step: 10
Training loss: 0.44830172274282143
Validation loss: 2.1727881115577055

Epoch: 712| Step: 0
Training loss: 0.4230560794861031
Validation loss: 2.195608221374071

Epoch: 5| Step: 1
Training loss: 0.4179565035728267
Validation loss: 2.2159052267857673

Epoch: 5| Step: 2
Training loss: 1.1058828703750192
Validation loss: 2.210925619459494

Epoch: 5| Step: 3
Training loss: 0.4235727622004968
Validation loss: 2.2458192205452723

Epoch: 5| Step: 4
Training loss: 0.3918182458497329
Validation loss: 2.278912365679307

Epoch: 5| Step: 5
Training loss: 0.5236713114966915
Validation loss: 2.1849250076256572

Epoch: 5| Step: 6
Training loss: 0.5850657272095007
Validation loss: 2.2632205128829117

Epoch: 5| Step: 7
Training loss: 0.4646231023448485
Validation loss: 2.228938470460943

Epoch: 5| Step: 8
Training loss: 0.3022563852459237
Validation loss: 2.235456575928643

Epoch: 5| Step: 9
Training loss: 0.43603474615917165
Validation loss: 2.2551147533220957

Epoch: 5| Step: 10
Training loss: 0.5985016920357403
Validation loss: 2.246816721335861

Epoch: 713| Step: 0
Training loss: 0.5019808512945247
Validation loss: 2.2808263016896055

Epoch: 5| Step: 1
Training loss: 0.42611182792427277
Validation loss: 2.175790085769722

Epoch: 5| Step: 2
Training loss: 0.3535843250267644
Validation loss: 2.210142756836503

Epoch: 5| Step: 3
Training loss: 0.39992253924413573
Validation loss: 2.2477861950713787

Epoch: 5| Step: 4
Training loss: 0.3521137260640466
Validation loss: 2.22573232583058

Epoch: 5| Step: 5
Training loss: 0.5868093235288654
Validation loss: 2.188043230991567

Epoch: 5| Step: 6
Training loss: 0.4768489070818211
Validation loss: 2.169480367086706

Epoch: 5| Step: 7
Training loss: 0.6870949375529052
Validation loss: 2.262964627153842

Epoch: 5| Step: 8
Training loss: 0.984870241109363
Validation loss: 2.246585150524843

Epoch: 5| Step: 9
Training loss: 0.5067664008683459
Validation loss: 2.131456490591477

Epoch: 5| Step: 10
Training loss: 0.40506273790378117
Validation loss: 2.12656822945522

Epoch: 714| Step: 0
Training loss: 0.47301425459111346
Validation loss: 2.1919602892895202

Epoch: 5| Step: 1
Training loss: 0.588949219919121
Validation loss: 2.167056670557158

Epoch: 5| Step: 2
Training loss: 0.4498025500718423
Validation loss: 2.2028644317204877

Epoch: 5| Step: 3
Training loss: 0.4609146435776606
Validation loss: 2.2237907285608776

Epoch: 5| Step: 4
Training loss: 0.37478766787850015
Validation loss: 2.1783568234487434

Epoch: 5| Step: 5
Training loss: 0.9842062608720119
Validation loss: 2.240571726030397

Epoch: 5| Step: 6
Training loss: 0.5396115920376277
Validation loss: 2.2271473293371815

Epoch: 5| Step: 7
Training loss: 0.5267429461448193
Validation loss: 2.133205737715971

Epoch: 5| Step: 8
Training loss: 0.5564253809188757
Validation loss: 2.1686867871891833

Epoch: 5| Step: 9
Training loss: 0.3726759859373107
Validation loss: 2.2130214613130974

Epoch: 5| Step: 10
Training loss: 0.4348966766014223
Validation loss: 2.2435895382257796

Epoch: 715| Step: 0
Training loss: 0.34005255149278957
Validation loss: 2.1949357467195596

Epoch: 5| Step: 1
Training loss: 0.5196115818874426
Validation loss: 2.184235759857217

Epoch: 5| Step: 2
Training loss: 0.9739629401983693
Validation loss: 2.213081395590943

Epoch: 5| Step: 3
Training loss: 0.5700981050691024
Validation loss: 2.2088109631962065

Epoch: 5| Step: 4
Training loss: 0.5270082324758509
Validation loss: 2.217133261288842

Epoch: 5| Step: 5
Training loss: 0.49514487525824885
Validation loss: 2.1910642062633667

Epoch: 5| Step: 6
Training loss: 0.49276732547944513
Validation loss: 2.2522343647060006

Epoch: 5| Step: 7
Training loss: 0.5071127545366525
Validation loss: 2.1737276162440353

Epoch: 5| Step: 8
Training loss: 0.35203763855251896
Validation loss: 2.1328373313725515

Epoch: 5| Step: 9
Training loss: 0.4754577557975335
Validation loss: 2.192238181435414

Epoch: 5| Step: 10
Training loss: 0.4341293841216692
Validation loss: 2.1823735395161052

Epoch: 716| Step: 0
Training loss: 0.39484881848794556
Validation loss: 2.218453322314498

Epoch: 5| Step: 1
Training loss: 0.3324621321869931
Validation loss: 2.2066087044409066

Epoch: 5| Step: 2
Training loss: 0.5627755179108267
Validation loss: 2.2050332949756895

Epoch: 5| Step: 3
Training loss: 0.47312106772115253
Validation loss: 2.1723216994652708

Epoch: 5| Step: 4
Training loss: 0.42839920075878063
Validation loss: 2.2571062943004043

Epoch: 5| Step: 5
Training loss: 1.049691297927986
Validation loss: 2.2270138599502225

Epoch: 5| Step: 6
Training loss: 0.44289540284049733
Validation loss: 2.245509601550031

Epoch: 5| Step: 7
Training loss: 0.3766422274384734
Validation loss: 2.133385350361642

Epoch: 5| Step: 8
Training loss: 0.5235778278877184
Validation loss: 2.19439836496488

Epoch: 5| Step: 9
Training loss: 0.5369207709966355
Validation loss: 2.118593503231482

Epoch: 5| Step: 10
Training loss: 0.3909907726579557
Validation loss: 2.202297899366332

Epoch: 717| Step: 0
Training loss: 0.3687480675921481
Validation loss: 2.1424220091618476

Epoch: 5| Step: 1
Training loss: 0.5731002657928809
Validation loss: 2.202998377386615

Epoch: 5| Step: 2
Training loss: 0.532207607666698
Validation loss: 2.2151494845778434

Epoch: 5| Step: 3
Training loss: 0.4653091344974261
Validation loss: 2.265960232915922

Epoch: 5| Step: 4
Training loss: 0.6053993677563196
Validation loss: 2.1015886527076177

Epoch: 5| Step: 5
Training loss: 0.4394039719961173
Validation loss: 2.189648964078995

Epoch: 5| Step: 6
Training loss: 0.2868912056062673
Validation loss: 2.2551472227015776

Epoch: 5| Step: 7
Training loss: 0.5818284980884803
Validation loss: 2.2356321568849418

Epoch: 5| Step: 8
Training loss: 0.9791293779672444
Validation loss: 2.236794915986196

Epoch: 5| Step: 9
Training loss: 0.5672827680041369
Validation loss: 2.2667547179518817

Epoch: 5| Step: 10
Training loss: 0.4029236290569146
Validation loss: 2.2300088039448624

Epoch: 718| Step: 0
Training loss: 0.5232012201200194
Validation loss: 2.168713637028202

Epoch: 5| Step: 1
Training loss: 0.36818369198385464
Validation loss: 2.203522621217542

Epoch: 5| Step: 2
Training loss: 0.6393900108999119
Validation loss: 2.263840592949144

Epoch: 5| Step: 3
Training loss: 0.36824170414553087
Validation loss: 2.2021419904038915

Epoch: 5| Step: 4
Training loss: 0.942961298827004
Validation loss: 2.2048063196513175

Epoch: 5| Step: 5
Training loss: 0.5146293853765642
Validation loss: 2.245758691936527

Epoch: 5| Step: 6
Training loss: 0.3206141261251575
Validation loss: 2.2020833393560695

Epoch: 5| Step: 7
Training loss: 0.445060089586928
Validation loss: 2.1911615774676343

Epoch: 5| Step: 8
Training loss: 0.49369597501587914
Validation loss: 2.1920498153438324

Epoch: 5| Step: 9
Training loss: 0.4438322796901602
Validation loss: 2.217172830784581

Epoch: 5| Step: 10
Training loss: 0.43126501596264827
Validation loss: 2.2381142248982875

Epoch: 719| Step: 0
Training loss: 0.4742167069015608
Validation loss: 2.182684382544724

Epoch: 5| Step: 1
Training loss: 0.9682183498840619
Validation loss: 2.2587637237550133

Epoch: 5| Step: 2
Training loss: 0.44644779913230886
Validation loss: 2.225448569818271

Epoch: 5| Step: 3
Training loss: 0.49843129300644423
Validation loss: 2.2970534297126206

Epoch: 5| Step: 4
Training loss: 0.4354713613967697
Validation loss: 2.2514680416589665

Epoch: 5| Step: 5
Training loss: 0.4065047529055331
Validation loss: 2.1591683782323443

Epoch: 5| Step: 6
Training loss: 0.43180214116885046
Validation loss: 2.27045117816912

Epoch: 5| Step: 7
Training loss: 0.4320414826490258
Validation loss: 2.283567024232212

Epoch: 5| Step: 8
Training loss: 0.4100527314841104
Validation loss: 2.2176794854746857

Epoch: 5| Step: 9
Training loss: 0.5157785476017476
Validation loss: 2.1838754067270045

Epoch: 5| Step: 10
Training loss: 0.4987393968693175
Validation loss: 2.21637660763437

Epoch: 720| Step: 0
Training loss: 0.3688492205048575
Validation loss: 2.102044848544862

Epoch: 5| Step: 1
Training loss: 0.5553392154619453
Validation loss: 2.194872718120147

Epoch: 5| Step: 2
Training loss: 0.5961515646079163
Validation loss: 2.176833651328744

Epoch: 5| Step: 3
Training loss: 0.44623331602414296
Validation loss: 2.2090128881212685

Epoch: 5| Step: 4
Training loss: 0.7541115436817195
Validation loss: 2.2651346187277963

Epoch: 5| Step: 5
Training loss: 0.4751562413695766
Validation loss: 2.2091939908711042

Epoch: 5| Step: 6
Training loss: 0.37468521496073615
Validation loss: 2.196215081474821

Epoch: 5| Step: 7
Training loss: 0.44550285955382596
Validation loss: 2.1737659467823494

Epoch: 5| Step: 8
Training loss: 0.9647893851713222
Validation loss: 2.2799446022209793

Epoch: 5| Step: 9
Training loss: 0.5706212240221618
Validation loss: 2.178408147866889

Epoch: 5| Step: 10
Training loss: 0.3691470836901907
Validation loss: 2.1923805585962395

Epoch: 721| Step: 0
Training loss: 0.49893799888359397
Validation loss: 2.2439474726359037

Epoch: 5| Step: 1
Training loss: 0.3333873431835383
Validation loss: 2.224670251444459

Epoch: 5| Step: 2
Training loss: 0.44973756435922574
Validation loss: 2.2795181791917996

Epoch: 5| Step: 3
Training loss: 0.5718680292757367
Validation loss: 2.230343765973245

Epoch: 5| Step: 4
Training loss: 0.3256102655265782
Validation loss: 2.2489355240003777

Epoch: 5| Step: 5
Training loss: 0.46890748875170574
Validation loss: 2.2248712644611754

Epoch: 5| Step: 6
Training loss: 0.5858514849788595
Validation loss: 2.2507786708005657

Epoch: 5| Step: 7
Training loss: 0.47851093834897995
Validation loss: 2.253056333788463

Epoch: 5| Step: 8
Training loss: 0.9148135563846324
Validation loss: 2.1917526629070383

Epoch: 5| Step: 9
Training loss: 0.6503731435998175
Validation loss: 2.228539629857953

Epoch: 5| Step: 10
Training loss: 0.4904865209173974
Validation loss: 2.1537196141306

Epoch: 722| Step: 0
Training loss: 0.47375181610443756
Validation loss: 2.136309965758715

Epoch: 5| Step: 1
Training loss: 0.43812388826737997
Validation loss: 2.2003666921269835

Epoch: 5| Step: 2
Training loss: 0.5774385139629018
Validation loss: 2.186742153824379

Epoch: 5| Step: 3
Training loss: 0.399981238252995
Validation loss: 2.1579071781904444

Epoch: 5| Step: 4
Training loss: 0.2871832201185305
Validation loss: 2.201184302002487

Epoch: 5| Step: 5
Training loss: 0.4716029292295127
Validation loss: 2.21792252145617

Epoch: 5| Step: 6
Training loss: 0.41663987153044346
Validation loss: 2.1965284404984233

Epoch: 5| Step: 7
Training loss: 1.0771428485908667
Validation loss: 2.1507586284754923

Epoch: 5| Step: 8
Training loss: 0.5299346009877116
Validation loss: 2.2053408348397068

Epoch: 5| Step: 9
Training loss: 0.4534031737602677
Validation loss: 2.2761562959914206

Epoch: 5| Step: 10
Training loss: 0.669600629383336
Validation loss: 2.195261778085139

Epoch: 723| Step: 0
Training loss: 0.5369245731439274
Validation loss: 2.2168845960868007

Epoch: 5| Step: 1
Training loss: 0.4226329141263379
Validation loss: 2.187493360307171

Epoch: 5| Step: 2
Training loss: 0.4638673963044349
Validation loss: 2.2072774410193476

Epoch: 5| Step: 3
Training loss: 0.6229772738143161
Validation loss: 2.206862904100054

Epoch: 5| Step: 4
Training loss: 0.4575385839837079
Validation loss: 2.225966683305405

Epoch: 5| Step: 5
Training loss: 0.3399872531675248
Validation loss: 2.1874672085930884

Epoch: 5| Step: 6
Training loss: 0.48308457483034817
Validation loss: 2.1741199513305403

Epoch: 5| Step: 7
Training loss: 0.3975868494295041
Validation loss: 2.198872349751986

Epoch: 5| Step: 8
Training loss: 0.6475089905457101
Validation loss: 2.167748772228086

Epoch: 5| Step: 9
Training loss: 0.9587929839603614
Validation loss: 2.1706855888824403

Epoch: 5| Step: 10
Training loss: 0.531171007454432
Validation loss: 2.255490001803385

Epoch: 724| Step: 0
Training loss: 0.4567868320906678
Validation loss: 2.15079865029746

Epoch: 5| Step: 1
Training loss: 0.4853467422952137
Validation loss: 2.2409351692259256

Epoch: 5| Step: 2
Training loss: 0.4911855308074834
Validation loss: 2.176980515226826

Epoch: 5| Step: 3
Training loss: 1.0404311609588954
Validation loss: 2.129852540402491

Epoch: 5| Step: 4
Training loss: 0.48370585829156654
Validation loss: 2.1733994105378693

Epoch: 5| Step: 5
Training loss: 0.5342984529514608
Validation loss: 2.2094265612997908

Epoch: 5| Step: 6
Training loss: 0.41351231423599805
Validation loss: 2.189385565106679

Epoch: 5| Step: 7
Training loss: 0.6031729703810788
Validation loss: 2.221548457533483

Epoch: 5| Step: 8
Training loss: 0.6047157034592943
Validation loss: 2.2033087890038825

Epoch: 5| Step: 9
Training loss: 0.4522794035372618
Validation loss: 2.276981614627615

Epoch: 5| Step: 10
Training loss: 0.4099435527254055
Validation loss: 2.2240190216481035

Epoch: 725| Step: 0
Training loss: 0.5823377275987129
Validation loss: 2.1826018146499226

Epoch: 5| Step: 1
Training loss: 0.5300049497265277
Validation loss: 2.167538831380743

Epoch: 5| Step: 2
Training loss: 0.5155126564866075
Validation loss: 2.2473980039249257

Epoch: 5| Step: 3
Training loss: 0.3197088950932065
Validation loss: 2.2318467455756297

Epoch: 5| Step: 4
Training loss: 0.50122742200121
Validation loss: 2.1976325065196

Epoch: 5| Step: 5
Training loss: 0.5391516128081487
Validation loss: 2.241586850623174

Epoch: 5| Step: 6
Training loss: 0.45360470733916375
Validation loss: 2.216411466832849

Epoch: 5| Step: 7
Training loss: 0.5125815419712724
Validation loss: 2.2307096478778963

Epoch: 5| Step: 8
Training loss: 0.5443101409394937
Validation loss: 2.1777094098622816

Epoch: 5| Step: 9
Training loss: 0.4535251034872304
Validation loss: 2.1664324752980937

Epoch: 5| Step: 10
Training loss: 1.0193861934905666
Validation loss: 2.211702593659284

Epoch: 726| Step: 0
Training loss: 0.9962932611259948
Validation loss: 2.208816942820038

Epoch: 5| Step: 1
Training loss: 0.4963620429066221
Validation loss: 2.117249552589289

Epoch: 5| Step: 2
Training loss: 0.5250801388566128
Validation loss: 2.2087961823601487

Epoch: 5| Step: 3
Training loss: 0.4727019768656419
Validation loss: 2.16129868638464

Epoch: 5| Step: 4
Training loss: 0.2922589923480268
Validation loss: 2.158366678054536

Epoch: 5| Step: 5
Training loss: 0.56350554552032
Validation loss: 2.2133466806736997

Epoch: 5| Step: 6
Training loss: 0.5087740085007504
Validation loss: 2.2600121254958214

Epoch: 5| Step: 7
Training loss: 0.48581707004864655
Validation loss: 2.3225182533215785

Epoch: 5| Step: 8
Training loss: 0.29085062456967264
Validation loss: 2.1594205626153475

Epoch: 5| Step: 9
Training loss: 0.6521400773299983
Validation loss: 2.1857851992266384

Epoch: 5| Step: 10
Training loss: 0.48557216612177406
Validation loss: 2.115766703238965

Epoch: 727| Step: 0
Training loss: 0.4298023763898013
Validation loss: 2.2342577306216707

Epoch: 5| Step: 1
Training loss: 0.44843455988222536
Validation loss: 2.129816533499307

Epoch: 5| Step: 2
Training loss: 0.3980172502838461
Validation loss: 2.1282623765396638

Epoch: 5| Step: 3
Training loss: 0.44756531981895814
Validation loss: 2.141566239154581

Epoch: 5| Step: 4
Training loss: 0.42658921671610334
Validation loss: 2.2044967631535584

Epoch: 5| Step: 5
Training loss: 0.4466282830393931
Validation loss: 2.1783512939226877

Epoch: 5| Step: 6
Training loss: 1.0156845662182201
Validation loss: 2.180856180361446

Epoch: 5| Step: 7
Training loss: 0.5971510004360516
Validation loss: 2.2046519392915247

Epoch: 5| Step: 8
Training loss: 0.440532156449288
Validation loss: 2.244470532848394

Epoch: 5| Step: 9
Training loss: 0.43424523013739535
Validation loss: 2.235097131508131

Epoch: 5| Step: 10
Training loss: 0.40728687964875876
Validation loss: 2.1718340309394377

Epoch: 728| Step: 0
Training loss: 0.4597762723223018
Validation loss: 2.2129404284875656

Epoch: 5| Step: 1
Training loss: 0.6154121989649973
Validation loss: 2.1665612172228017

Epoch: 5| Step: 2
Training loss: 0.4906068579848751
Validation loss: 2.2671811257266943

Epoch: 5| Step: 3
Training loss: 0.5152245903098283
Validation loss: 2.1966086093951604

Epoch: 5| Step: 4
Training loss: 0.5361523233834544
Validation loss: 2.2526219303915647

Epoch: 5| Step: 5
Training loss: 0.530324634869489
Validation loss: 2.1648641502114394

Epoch: 5| Step: 6
Training loss: 0.3320267284309833
Validation loss: 2.167384138496867

Epoch: 5| Step: 7
Training loss: 0.6405951562768615
Validation loss: 2.156521601585852

Epoch: 5| Step: 8
Training loss: 0.34611305889059857
Validation loss: 2.196988654651976

Epoch: 5| Step: 9
Training loss: 0.961844411739133
Validation loss: 2.1524083860496352

Epoch: 5| Step: 10
Training loss: 0.3898725319368715
Validation loss: 2.1600752800884853

Epoch: 729| Step: 0
Training loss: 0.34853725031904764
Validation loss: 2.191732185292465

Epoch: 5| Step: 1
Training loss: 0.4670218559997355
Validation loss: 2.1534230582912937

Epoch: 5| Step: 2
Training loss: 0.48730930486719953
Validation loss: 2.1736948806673344

Epoch: 5| Step: 3
Training loss: 0.41097921732637954
Validation loss: 2.229448084701159

Epoch: 5| Step: 4
Training loss: 0.488365928936682
Validation loss: 2.217574057951146

Epoch: 5| Step: 5
Training loss: 0.4290420192267434
Validation loss: 2.200551170513292

Epoch: 5| Step: 6
Training loss: 0.6180172183854107
Validation loss: 2.2563461769295627

Epoch: 5| Step: 7
Training loss: 1.065095536151171
Validation loss: 2.1881687202780116

Epoch: 5| Step: 8
Training loss: 0.3893776815759893
Validation loss: 2.212815000101311

Epoch: 5| Step: 9
Training loss: 0.572334103181455
Validation loss: 2.2029163858482756

Epoch: 5| Step: 10
Training loss: 0.5432005188636801
Validation loss: 2.1408957230926617

Epoch: 730| Step: 0
Training loss: 0.6003259856076053
Validation loss: 2.2095864591386722

Epoch: 5| Step: 1
Training loss: 0.4890436705111936
Validation loss: 2.1709694044447527

Epoch: 5| Step: 2
Training loss: 0.3949770910524857
Validation loss: 2.1931809650194376

Epoch: 5| Step: 3
Training loss: 0.44374993216823005
Validation loss: 2.2231432299089207

Epoch: 5| Step: 4
Training loss: 0.5220319180796874
Validation loss: 2.1936521890891147

Epoch: 5| Step: 5
Training loss: 0.3761543547134208
Validation loss: 2.2257355756853308

Epoch: 5| Step: 6
Training loss: 0.4103664586133731
Validation loss: 2.1781937627330685

Epoch: 5| Step: 7
Training loss: 0.6066175329918848
Validation loss: 2.2337510206981794

Epoch: 5| Step: 8
Training loss: 0.43927544286617765
Validation loss: 2.240825752789714

Epoch: 5| Step: 9
Training loss: 0.375098910797651
Validation loss: 2.2127004022011216

Epoch: 5| Step: 10
Training loss: 0.9996835684810791
Validation loss: 2.3239835577913293

Epoch: 731| Step: 0
Training loss: 0.4632197147820766
Validation loss: 2.241163247012336

Epoch: 5| Step: 1
Training loss: 0.4122559526301731
Validation loss: 2.1920598059243703

Epoch: 5| Step: 2
Training loss: 0.7353672061385894
Validation loss: 2.20701918464838

Epoch: 5| Step: 3
Training loss: 0.4091198861571472
Validation loss: 2.156282752526777

Epoch: 5| Step: 4
Training loss: 0.33363920076375586
Validation loss: 2.1333548155242648

Epoch: 5| Step: 5
Training loss: 0.4938544247453658
Validation loss: 2.1772396135375542

Epoch: 5| Step: 6
Training loss: 1.0176860144415212
Validation loss: 2.170951690086368

Epoch: 5| Step: 7
Training loss: 0.5074692079288416
Validation loss: 2.1853951337310265

Epoch: 5| Step: 8
Training loss: 0.5182747812819096
Validation loss: 2.229304558858585

Epoch: 5| Step: 9
Training loss: 0.5544541365039248
Validation loss: 2.2453195972136215

Epoch: 5| Step: 10
Training loss: 0.3727047534782788
Validation loss: 2.171006731540964

Epoch: 732| Step: 0
Training loss: 0.5328651446961965
Validation loss: 2.1944627585407726

Epoch: 5| Step: 1
Training loss: 0.35752787868129604
Validation loss: 2.231289614499861

Epoch: 5| Step: 2
Training loss: 0.4347440736541094
Validation loss: 2.1890018165546477

Epoch: 5| Step: 3
Training loss: 0.490104506111095
Validation loss: 2.2313386362192826

Epoch: 5| Step: 4
Training loss: 0.5188347873567295
Validation loss: 2.2157353463653777

Epoch: 5| Step: 5
Training loss: 0.39444578774802547
Validation loss: 2.2437906344244247

Epoch: 5| Step: 6
Training loss: 0.54349349757273
Validation loss: 2.176040326168632

Epoch: 5| Step: 7
Training loss: 0.4069043904484594
Validation loss: 2.181265421679251

Epoch: 5| Step: 8
Training loss: 0.43828376320511053
Validation loss: 2.1824889216632686

Epoch: 5| Step: 9
Training loss: 0.41632516296902145
Validation loss: 2.231166548199682

Epoch: 5| Step: 10
Training loss: 1.0385197534165584
Validation loss: 2.187575044531316

Epoch: 733| Step: 0
Training loss: 0.5071216872899019
Validation loss: 2.1244244432438153

Epoch: 5| Step: 1
Training loss: 0.45450801911954175
Validation loss: 2.205644155068174

Epoch: 5| Step: 2
Training loss: 0.4312262639133955
Validation loss: 2.15923809936961

Epoch: 5| Step: 3
Training loss: 0.5211973221778878
Validation loss: 2.1759731203485173

Epoch: 5| Step: 4
Training loss: 0.44315304765592684
Validation loss: 2.236389697525376

Epoch: 5| Step: 5
Training loss: 0.8370011950863746
Validation loss: 2.1756737203197662

Epoch: 5| Step: 6
Training loss: 0.34489495160447053
Validation loss: 2.2102181217178907

Epoch: 5| Step: 7
Training loss: 0.45378029236154915
Validation loss: 2.161255854702709

Epoch: 5| Step: 8
Training loss: 0.35988143812981466
Validation loss: 2.1930726916579544

Epoch: 5| Step: 9
Training loss: 0.5405138353487917
Validation loss: 2.136361321717203

Epoch: 5| Step: 10
Training loss: 0.3631073730445079
Validation loss: 2.1590940763549686

Epoch: 734| Step: 0
Training loss: 0.8957130587959014
Validation loss: 2.181778229288291

Epoch: 5| Step: 1
Training loss: 0.60284799233025
Validation loss: 2.1807695992242153

Epoch: 5| Step: 2
Training loss: 0.44060785111407585
Validation loss: 2.2532538092799097

Epoch: 5| Step: 3
Training loss: 0.5426362755567721
Validation loss: 2.160992799794777

Epoch: 5| Step: 4
Training loss: 0.550884399494873
Validation loss: 2.2035813363360592

Epoch: 5| Step: 5
Training loss: 0.4207235446462066
Validation loss: 2.1645091926936773

Epoch: 5| Step: 6
Training loss: 0.31961799554008674
Validation loss: 2.2218521820360198

Epoch: 5| Step: 7
Training loss: 0.36985272140806447
Validation loss: 2.2097426178372466

Epoch: 5| Step: 8
Training loss: 0.6107022186073466
Validation loss: 2.152752957403307

Epoch: 5| Step: 9
Training loss: 0.29381591382018307
Validation loss: 2.2092918649903455

Epoch: 5| Step: 10
Training loss: 0.42529533376813533
Validation loss: 2.2070268348346946

Epoch: 735| Step: 0
Training loss: 0.44714847013170633
Validation loss: 2.2201882553210774

Epoch: 5| Step: 1
Training loss: 0.5997370978395145
Validation loss: 2.1856645293297308

Epoch: 5| Step: 2
Training loss: 0.36503836528125716
Validation loss: 2.2356517255496007

Epoch: 5| Step: 3
Training loss: 0.38700120417336104
Validation loss: 2.2751125959614455

Epoch: 5| Step: 4
Training loss: 0.5124976367430745
Validation loss: 2.231183162874008

Epoch: 5| Step: 5
Training loss: 0.7072563866724376
Validation loss: 2.1858389951531043

Epoch: 5| Step: 6
Training loss: 0.5449732547724541
Validation loss: 2.254869866825959

Epoch: 5| Step: 7
Training loss: 0.4198259998256245
Validation loss: 2.2472823706621257

Epoch: 5| Step: 8
Training loss: 0.9755813858185705
Validation loss: 2.1115690766611275

Epoch: 5| Step: 9
Training loss: 0.4311456733783807
Validation loss: 2.1868967938576667

Epoch: 5| Step: 10
Training loss: 0.32193779888298424
Validation loss: 2.1805843384639294

Epoch: 736| Step: 0
Training loss: 0.4118807913527898
Validation loss: 2.203636099676224

Epoch: 5| Step: 1
Training loss: 0.7557147772427103
Validation loss: 2.1657704366453654

Epoch: 5| Step: 2
Training loss: 0.4697663732459604
Validation loss: 2.1083817975898596

Epoch: 5| Step: 3
Training loss: 0.4444538504959545
Validation loss: 2.154145938021981

Epoch: 5| Step: 4
Training loss: 0.47822164730552164
Validation loss: 2.212799786066447

Epoch: 5| Step: 5
Training loss: 0.45382828231601285
Validation loss: 2.1704014660110738

Epoch: 5| Step: 6
Training loss: 0.6656226735678837
Validation loss: 2.1911835942589133

Epoch: 5| Step: 7
Training loss: 0.5307605957468571
Validation loss: 2.184382935297631

Epoch: 5| Step: 8
Training loss: 0.5800717542921423
Validation loss: 2.167489215349806

Epoch: 5| Step: 9
Training loss: 0.947513319842841
Validation loss: 2.245725777450928

Epoch: 5| Step: 10
Training loss: 0.4181978186248085
Validation loss: 2.229085204466757

Epoch: 737| Step: 0
Training loss: 0.444449542268021
Validation loss: 2.2527666264626

Epoch: 5| Step: 1
Training loss: 0.380614725422106
Validation loss: 2.1413126482401545

Epoch: 5| Step: 2
Training loss: 0.4807252276897412
Validation loss: 2.1872296267304066

Epoch: 5| Step: 3
Training loss: 0.43189390872573546
Validation loss: 2.1119313029346682

Epoch: 5| Step: 4
Training loss: 0.5871365549137458
Validation loss: 2.1988611402855893

Epoch: 5| Step: 5
Training loss: 0.3697554095944846
Validation loss: 2.2676944061080286

Epoch: 5| Step: 6
Training loss: 0.4132846687911025
Validation loss: 2.2020165406853995

Epoch: 5| Step: 7
Training loss: 0.34251281959669416
Validation loss: 2.1446445778158014

Epoch: 5| Step: 8
Training loss: 0.89722201183646
Validation loss: 2.2193810528743785

Epoch: 5| Step: 9
Training loss: 0.5616444598268789
Validation loss: 2.092742146561879

Epoch: 5| Step: 10
Training loss: 0.5058530416791791
Validation loss: 2.1558266025320827

Epoch: 738| Step: 0
Training loss: 0.4838748472356888
Validation loss: 2.154435403494235

Epoch: 5| Step: 1
Training loss: 0.4400642892351199
Validation loss: 2.1176829194916817

Epoch: 5| Step: 2
Training loss: 0.4438463469130337
Validation loss: 2.1375559791757612

Epoch: 5| Step: 3
Training loss: 0.5341788785325084
Validation loss: 2.178146352030801

Epoch: 5| Step: 4
Training loss: 0.5536368991660874
Validation loss: 2.15361316698442

Epoch: 5| Step: 5
Training loss: 0.3777688840075527
Validation loss: 2.153490740472949

Epoch: 5| Step: 6
Training loss: 0.6580420503571938
Validation loss: 2.1916316460498275

Epoch: 5| Step: 7
Training loss: 0.8984136163605334
Validation loss: 2.1925573423915736

Epoch: 5| Step: 8
Training loss: 0.44451628996711395
Validation loss: 2.15325148080425

Epoch: 5| Step: 9
Training loss: 0.378183698433017
Validation loss: 2.19731056391657

Epoch: 5| Step: 10
Training loss: 0.3558605047515791
Validation loss: 2.1575395040365506

Epoch: 739| Step: 0
Training loss: 0.5409274528623756
Validation loss: 2.2546954798235115

Epoch: 5| Step: 1
Training loss: 0.5038336472364671
Validation loss: 2.1848955368676766

Epoch: 5| Step: 2
Training loss: 0.5099696777716803
Validation loss: 2.1606340928448646

Epoch: 5| Step: 3
Training loss: 0.502947612554123
Validation loss: 2.1948726573834523

Epoch: 5| Step: 4
Training loss: 0.5247625404302465
Validation loss: 2.20189322320214

Epoch: 5| Step: 5
Training loss: 0.9909988552263963
Validation loss: 2.172117873480197

Epoch: 5| Step: 6
Training loss: 0.47097120130274484
Validation loss: 2.206061183590117

Epoch: 5| Step: 7
Training loss: 0.5955643038730883
Validation loss: 2.1945830223472216

Epoch: 5| Step: 8
Training loss: 0.3587898383134772
Validation loss: 2.2610211423016473

Epoch: 5| Step: 9
Training loss: 0.44017554349529375
Validation loss: 2.202389249446696

Epoch: 5| Step: 10
Training loss: 0.5119384119442276
Validation loss: 2.2107275299270563

Epoch: 740| Step: 0
Training loss: 0.35215376830337314
Validation loss: 2.176288011011418

Epoch: 5| Step: 1
Training loss: 0.9169916024983158
Validation loss: 2.183361911641442

Epoch: 5| Step: 2
Training loss: 0.5891953245213771
Validation loss: 2.1174758662078954

Epoch: 5| Step: 3
Training loss: 0.3518120303988648
Validation loss: 2.2179971365395543

Epoch: 5| Step: 4
Training loss: 0.4700543693282597
Validation loss: 2.234582665463422

Epoch: 5| Step: 5
Training loss: 0.33694844830613235
Validation loss: 2.2115874257574633

Epoch: 5| Step: 6
Training loss: 0.5265495536412542
Validation loss: 2.2226819052175175

Epoch: 5| Step: 7
Training loss: 0.5108528673732037
Validation loss: 2.2651204985602824

Epoch: 5| Step: 8
Training loss: 0.4676408998039346
Validation loss: 2.228705236431144

Epoch: 5| Step: 9
Training loss: 0.5640411721632916
Validation loss: 2.252338859606264

Epoch: 5| Step: 10
Training loss: 0.5382962793652146
Validation loss: 2.2264772287651815

Epoch: 741| Step: 0
Training loss: 0.38122040680644814
Validation loss: 2.259531680243593

Epoch: 5| Step: 1
Training loss: 0.581459993965769
Validation loss: 2.1641230178058875

Epoch: 5| Step: 2
Training loss: 0.8816526102004362
Validation loss: 2.1964078752775733

Epoch: 5| Step: 3
Training loss: 0.5968562737368381
Validation loss: 2.226710022646753

Epoch: 5| Step: 4
Training loss: 0.5499847009004833
Validation loss: 2.1379222785455765

Epoch: 5| Step: 5
Training loss: 0.39681010654392757
Validation loss: 2.1852830590173222

Epoch: 5| Step: 6
Training loss: 0.38133739892350105
Validation loss: 2.1937056524426994

Epoch: 5| Step: 7
Training loss: 0.36755393391541935
Validation loss: 2.230886717122535

Epoch: 5| Step: 8
Training loss: 0.49267314989580074
Validation loss: 2.1580654050047534

Epoch: 5| Step: 9
Training loss: 0.2804021107980224
Validation loss: 2.217218996519879

Epoch: 5| Step: 10
Training loss: 0.5672804039145196
Validation loss: 2.2036156237153137

Epoch: 742| Step: 0
Training loss: 0.44938527213547075
Validation loss: 2.1817699782578512

Epoch: 5| Step: 1
Training loss: 0.5662986390063963
Validation loss: 2.26987409770432

Epoch: 5| Step: 2
Training loss: 0.3865231298567833
Validation loss: 2.2800680512946547

Epoch: 5| Step: 3
Training loss: 0.48589696500438395
Validation loss: 2.23304889663286

Epoch: 5| Step: 4
Training loss: 0.3913842642390341
Validation loss: 2.2198974713354485

Epoch: 5| Step: 5
Training loss: 0.35604143646408387
Validation loss: 2.21270784157648

Epoch: 5| Step: 6
Training loss: 0.28388565950356814
Validation loss: 2.16447772507938

Epoch: 5| Step: 7
Training loss: 0.6406968704474667
Validation loss: 2.2684804131276883

Epoch: 5| Step: 8
Training loss: 0.9323432879656962
Validation loss: 2.0990248708016725

Epoch: 5| Step: 9
Training loss: 0.44297025636554765
Validation loss: 2.1344678626256144

Epoch: 5| Step: 10
Training loss: 0.5691881724167548
Validation loss: 2.1748358615887464

Epoch: 743| Step: 0
Training loss: 0.5533554308377907
Validation loss: 2.1533374843638677

Epoch: 5| Step: 1
Training loss: 0.4791437813919077
Validation loss: 2.1425318681788283

Epoch: 5| Step: 2
Training loss: 0.42414255388755456
Validation loss: 2.1937432272337065

Epoch: 5| Step: 3
Training loss: 0.5093981708335011
Validation loss: 2.1550908741333203

Epoch: 5| Step: 4
Training loss: 0.46763228036698634
Validation loss: 2.217894866402473

Epoch: 5| Step: 5
Training loss: 0.9364440693403673
Validation loss: 2.256742804590913

Epoch: 5| Step: 6
Training loss: 0.39804489764170714
Validation loss: 2.1062804267530555

Epoch: 5| Step: 7
Training loss: 0.46602056905165484
Validation loss: 2.1525157928716374

Epoch: 5| Step: 8
Training loss: 0.4003786596975955
Validation loss: 2.1761241644162808

Epoch: 5| Step: 9
Training loss: 0.44748662294607533
Validation loss: 2.1951418457685414

Epoch: 5| Step: 10
Training loss: 0.4896425725390112
Validation loss: 2.2004401689076847

Epoch: 744| Step: 0
Training loss: 0.565472747797035
Validation loss: 2.1448824414681904

Epoch: 5| Step: 1
Training loss: 0.3929668798079837
Validation loss: 2.1689365965937384

Epoch: 5| Step: 2
Training loss: 0.4037729637359183
Validation loss: 2.2122809181411816

Epoch: 5| Step: 3
Training loss: 0.3780630502316845
Validation loss: 2.175222577163329

Epoch: 5| Step: 4
Training loss: 0.4026242176736398
Validation loss: 2.199733829943949

Epoch: 5| Step: 5
Training loss: 0.4880970569334689
Validation loss: 2.149997737842313

Epoch: 5| Step: 6
Training loss: 0.5318531091042421
Validation loss: 2.218706197853672

Epoch: 5| Step: 7
Training loss: 0.42410815783787936
Validation loss: 2.2058103317187183

Epoch: 5| Step: 8
Training loss: 0.5760341156320333
Validation loss: 2.1744644994734137

Epoch: 5| Step: 9
Training loss: 0.3599295069964058
Validation loss: 2.153859469393191

Epoch: 5| Step: 10
Training loss: 0.9846142674861587
Validation loss: 2.2124601175495537

Epoch: 745| Step: 0
Training loss: 0.4360588895996276
Validation loss: 2.1870457014880866

Epoch: 5| Step: 1
Training loss: 0.9135033617213572
Validation loss: 2.256695531513653

Epoch: 5| Step: 2
Training loss: 0.4399923788299304
Validation loss: 2.170239341746231

Epoch: 5| Step: 3
Training loss: 0.5248424123217204
Validation loss: 2.1593646571551854

Epoch: 5| Step: 4
Training loss: 0.5124015038906723
Validation loss: 2.1430325575245206

Epoch: 5| Step: 5
Training loss: 0.5876010422357829
Validation loss: 2.245190942205087

Epoch: 5| Step: 6
Training loss: 0.4246478087043616
Validation loss: 2.14495934993801

Epoch: 5| Step: 7
Training loss: 0.3827887936472486
Validation loss: 2.1876906533081355

Epoch: 5| Step: 8
Training loss: 0.452211182032817
Validation loss: 2.1406924173726756

Epoch: 5| Step: 9
Training loss: 0.399382200579138
Validation loss: 2.1167841580356273

Epoch: 5| Step: 10
Training loss: 0.5686099362041562
Validation loss: 2.187786750340016

Epoch: 746| Step: 0
Training loss: 0.49944496640995056
Validation loss: 2.192604345608732

Epoch: 5| Step: 1
Training loss: 0.8506988555551636
Validation loss: 2.2440817487233495

Epoch: 5| Step: 2
Training loss: 0.4536169111519272
Validation loss: 2.1645763559084976

Epoch: 5| Step: 3
Training loss: 0.36249496111162943
Validation loss: 2.21209173809327

Epoch: 5| Step: 4
Training loss: 0.42523818424164983
Validation loss: 2.201127020740672

Epoch: 5| Step: 5
Training loss: 0.5479665761294834
Validation loss: 2.28662613610751

Epoch: 5| Step: 6
Training loss: 0.5187236848154392
Validation loss: 2.1978584643038466

Epoch: 5| Step: 7
Training loss: 0.527314333625075
Validation loss: 2.259824285512394

Epoch: 5| Step: 8
Training loss: 0.5866618701574372
Validation loss: 2.2100068629625107

Epoch: 5| Step: 9
Training loss: 0.4002437787474918
Validation loss: 2.2060816746198855

Epoch: 5| Step: 10
Training loss: 0.725153099534881
Validation loss: 2.352590897282525

Epoch: 747| Step: 0
Training loss: 0.5459017130799535
Validation loss: 2.192250199501159

Epoch: 5| Step: 1
Training loss: 0.46907975995497514
Validation loss: 2.2036174542917633

Epoch: 5| Step: 2
Training loss: 0.34039899257612816
Validation loss: 2.1498662809249103

Epoch: 5| Step: 3
Training loss: 0.9154198179044616
Validation loss: 2.196268659573772

Epoch: 5| Step: 4
Training loss: 0.5156415589881485
Validation loss: 2.1559650505722123

Epoch: 5| Step: 5
Training loss: 0.4353411064415448
Validation loss: 2.194088825996027

Epoch: 5| Step: 6
Training loss: 0.2999304467278294
Validation loss: 2.1081718644504526

Epoch: 5| Step: 7
Training loss: 0.6016986742338207
Validation loss: 2.1646956261038337

Epoch: 5| Step: 8
Training loss: 0.4453122490330039
Validation loss: 2.202409605857468

Epoch: 5| Step: 9
Training loss: 0.39460394916569047
Validation loss: 2.080035520428567

Epoch: 5| Step: 10
Training loss: 0.34344077290094016
Validation loss: 2.188422461816017

Epoch: 748| Step: 0
Training loss: 0.4448573480155063
Validation loss: 2.189286578569039

Epoch: 5| Step: 1
Training loss: 0.9732718606919437
Validation loss: 2.2587004616256956

Epoch: 5| Step: 2
Training loss: 0.45749498950841044
Validation loss: 2.2320943291072397

Epoch: 5| Step: 3
Training loss: 0.6102097735697832
Validation loss: 2.2084207821242647

Epoch: 5| Step: 4
Training loss: 0.3957338417234287
Validation loss: 2.1671983663607985

Epoch: 5| Step: 5
Training loss: 0.40272611208115744
Validation loss: 2.2454596687270314

Epoch: 5| Step: 6
Training loss: 0.5794313723516133
Validation loss: 2.178916796956401

Epoch: 5| Step: 7
Training loss: 0.38035424798724754
Validation loss: 2.154990434848314

Epoch: 5| Step: 8
Training loss: 0.5922556694471135
Validation loss: 2.201750025520198

Epoch: 5| Step: 9
Training loss: 0.48723932106857815
Validation loss: 2.14973811571922

Epoch: 5| Step: 10
Training loss: 0.4341345842128931
Validation loss: 2.2139769809530883

Epoch: 749| Step: 0
Training loss: 0.903291806982667
Validation loss: 2.21885396669617

Epoch: 5| Step: 1
Training loss: 0.4620860064056287
Validation loss: 2.1512592299702504

Epoch: 5| Step: 2
Training loss: 0.3991681486784488
Validation loss: 2.188839664805062

Epoch: 5| Step: 3
Training loss: 0.4024808520447935
Validation loss: 2.128330760676764

Epoch: 5| Step: 4
Training loss: 0.5319676600697566
Validation loss: 2.216543778164974

Epoch: 5| Step: 5
Training loss: 0.4654817770536869
Validation loss: 2.206135965108991

Epoch: 5| Step: 6
Training loss: 0.4536414491840875
Validation loss: 2.2861788870423903

Epoch: 5| Step: 7
Training loss: 0.43278698140187016
Validation loss: 2.2214178822428132

Epoch: 5| Step: 8
Training loss: 0.3610392678862206
Validation loss: 2.2312710450895556

Epoch: 5| Step: 9
Training loss: 0.408134162589675
Validation loss: 2.232668249959061

Epoch: 5| Step: 10
Training loss: 0.4429290296181465
Validation loss: 2.156813971176545

Epoch: 750| Step: 0
Training loss: 0.3085058304330012
Validation loss: 2.1234964351215346

Epoch: 5| Step: 1
Training loss: 0.3390607583313259
Validation loss: 2.2563675525611613

Epoch: 5| Step: 2
Training loss: 0.4018684653941873
Validation loss: 2.171930839580323

Epoch: 5| Step: 3
Training loss: 0.6883457140659647
Validation loss: 2.2523213213879987

Epoch: 5| Step: 4
Training loss: 0.8546269076277101
Validation loss: 2.1688999477985473

Epoch: 5| Step: 5
Training loss: 0.37701474807740354
Validation loss: 2.184212026898509

Epoch: 5| Step: 6
Training loss: 0.4766725037985421
Validation loss: 2.1963437421196774

Epoch: 5| Step: 7
Training loss: 0.5134767226911421
Validation loss: 2.238744213265125

Epoch: 5| Step: 8
Training loss: 0.5517337760078316
Validation loss: 2.2473214475256365

Epoch: 5| Step: 9
Training loss: 0.45221734397278934
Validation loss: 2.2108609513729856

Epoch: 5| Step: 10
Training loss: 0.5268866642014921
Validation loss: 2.2495230336686216

Epoch: 751| Step: 0
Training loss: 0.4215002868307457
Validation loss: 2.203439394963925

Epoch: 5| Step: 1
Training loss: 0.3297605510430669
Validation loss: 2.198059760492343

Epoch: 5| Step: 2
Training loss: 0.45093409560115344
Validation loss: 2.2033855697523363

Epoch: 5| Step: 3
Training loss: 0.5201825526638275
Validation loss: 2.221556110769833

Epoch: 5| Step: 4
Training loss: 0.5894993161657766
Validation loss: 2.188352637238341

Epoch: 5| Step: 5
Training loss: 0.9385525199327521
Validation loss: 2.154944130393829

Epoch: 5| Step: 6
Training loss: 0.43632092995034627
Validation loss: 2.2917733776347102

Epoch: 5| Step: 7
Training loss: 0.4448891685461196
Validation loss: 2.1817779978086542

Epoch: 5| Step: 8
Training loss: 0.3798251659910931
Validation loss: 2.1662508949768498

Epoch: 5| Step: 9
Training loss: 0.4559797597103271
Validation loss: 2.206969160418438

Epoch: 5| Step: 10
Training loss: 0.408420340681775
Validation loss: 2.174745839678743

Epoch: 752| Step: 0
Training loss: 0.4981592089059796
Validation loss: 2.1581565307344857

Epoch: 5| Step: 1
Training loss: 0.5635914809326995
Validation loss: 2.219730750291565

Epoch: 5| Step: 2
Training loss: 0.9156441982717274
Validation loss: 2.1995907871375437

Epoch: 5| Step: 3
Training loss: 0.5898867711426395
Validation loss: 2.2566491498046295

Epoch: 5| Step: 4
Training loss: 0.4038262876534135
Validation loss: 2.210634662535237

Epoch: 5| Step: 5
Training loss: 0.3966620850331844
Validation loss: 2.1457161310360076

Epoch: 5| Step: 6
Training loss: 0.3835922590797803
Validation loss: 2.236938752008147

Epoch: 5| Step: 7
Training loss: 0.45609276753470396
Validation loss: 2.2343275169985444

Epoch: 5| Step: 8
Training loss: 0.36524033159100766
Validation loss: 2.2713218299769005

Epoch: 5| Step: 9
Training loss: 0.4334732953715313
Validation loss: 2.2201522908942946

Epoch: 5| Step: 10
Training loss: 0.5271110021041108
Validation loss: 2.1986465194862506

Epoch: 753| Step: 0
Training loss: 0.5566072955944954
Validation loss: 2.139684885209141

Epoch: 5| Step: 1
Training loss: 0.3699661188142405
Validation loss: 2.169053691053282

Epoch: 5| Step: 2
Training loss: 0.3226156241493022
Validation loss: 2.163624539513344

Epoch: 5| Step: 3
Training loss: 0.4088249945306576
Validation loss: 2.2303111263087816

Epoch: 5| Step: 4
Training loss: 0.2762053187514572
Validation loss: 2.139923650274522

Epoch: 5| Step: 5
Training loss: 0.4587396496844664
Validation loss: 2.1842979017691717

Epoch: 5| Step: 6
Training loss: 0.5378406332438899
Validation loss: 2.1768028220653703

Epoch: 5| Step: 7
Training loss: 0.9467960412872998
Validation loss: 2.1254177322319245

Epoch: 5| Step: 8
Training loss: 0.5077965953977202
Validation loss: 2.2218722522486054

Epoch: 5| Step: 9
Training loss: 0.5524680638468976
Validation loss: 2.2696185306396957

Epoch: 5| Step: 10
Training loss: 0.45015491296052573
Validation loss: 2.3046620346172477

Epoch: 754| Step: 0
Training loss: 0.44758489615961156
Validation loss: 2.1680678998555036

Epoch: 5| Step: 1
Training loss: 0.5031213191590808
Validation loss: 2.204432161159111

Epoch: 5| Step: 2
Training loss: 0.4437599389212374
Validation loss: 2.1711468033927117

Epoch: 5| Step: 3
Training loss: 0.4599566935284735
Validation loss: 2.2577764638312963

Epoch: 5| Step: 4
Training loss: 0.551234714702693
Validation loss: 2.2422156826479247

Epoch: 5| Step: 5
Training loss: 0.3140381746693091
Validation loss: 2.215381721414255

Epoch: 5| Step: 6
Training loss: 0.5436246738481102
Validation loss: 2.239472081444342

Epoch: 5| Step: 7
Training loss: 0.44946623909203887
Validation loss: 2.1855111334792916

Epoch: 5| Step: 8
Training loss: 0.4082190040529768
Validation loss: 2.17546887971418

Epoch: 5| Step: 9
Training loss: 0.6235940378179342
Validation loss: 2.206568825835349

Epoch: 5| Step: 10
Training loss: 0.9162115607323578
Validation loss: 2.227927242803757

Epoch: 755| Step: 0
Training loss: 0.849193988849659
Validation loss: 2.1997436288760563

Epoch: 5| Step: 1
Training loss: 0.4337608427841705
Validation loss: 2.2625895849855207

Epoch: 5| Step: 2
Training loss: 0.6018549963537488
Validation loss: 2.250448086601327

Epoch: 5| Step: 3
Training loss: 0.31440698984186277
Validation loss: 2.2328890853454575

Epoch: 5| Step: 4
Training loss: 0.49612722509187457
Validation loss: 2.1743977719663135

Epoch: 5| Step: 5
Training loss: 0.44174685882310777
Validation loss: 2.1592341765616734

Epoch: 5| Step: 6
Training loss: 0.4441513516515563
Validation loss: 2.1449610566730914

Epoch: 5| Step: 7
Training loss: 0.37945241989689127
Validation loss: 2.2196535797815997

Epoch: 5| Step: 8
Training loss: 0.6258141460177994
Validation loss: 2.188576895269444

Epoch: 5| Step: 9
Training loss: 0.41665038633329793
Validation loss: 2.1740490158866543

Epoch: 5| Step: 10
Training loss: 0.4819616369496598
Validation loss: 2.1472734452834206

Epoch: 756| Step: 0
Training loss: 0.6282446087880277
Validation loss: 2.188264171298818

Epoch: 5| Step: 1
Training loss: 0.5855415023343462
Validation loss: 2.131246970709856

Epoch: 5| Step: 2
Training loss: 0.41528833420872957
Validation loss: 2.121340536486954

Epoch: 5| Step: 3
Training loss: 0.5237525447337529
Validation loss: 2.151044889129495

Epoch: 5| Step: 4
Training loss: 0.4968969646133524
Validation loss: 2.152712572371477

Epoch: 5| Step: 5
Training loss: 0.36244001714414836
Validation loss: 2.152164086436746

Epoch: 5| Step: 6
Training loss: 0.29870555583006464
Validation loss: 2.1844371838501435

Epoch: 5| Step: 7
Training loss: 0.3854855613305231
Validation loss: 2.184411029288801

Epoch: 5| Step: 8
Training loss: 0.4533322123584959
Validation loss: 2.2176844215952576

Epoch: 5| Step: 9
Training loss: 0.9414264471016465
Validation loss: 2.17289894951046

Epoch: 5| Step: 10
Training loss: 0.38395155555895827
Validation loss: 2.1541107061295284

Epoch: 757| Step: 0
Training loss: 0.43673209509480154
Validation loss: 2.276956172651837

Epoch: 5| Step: 1
Training loss: 0.40743835576812104
Validation loss: 2.1934675921348807

Epoch: 5| Step: 2
Training loss: 0.8951240807304675
Validation loss: 2.155538443040145

Epoch: 5| Step: 3
Training loss: 0.3701153757659937
Validation loss: 2.1629609877456275

Epoch: 5| Step: 4
Training loss: 0.34669899685235656
Validation loss: 2.094923770034652

Epoch: 5| Step: 5
Training loss: 0.44696347887928584
Validation loss: 2.2517473939584747

Epoch: 5| Step: 6
Training loss: 0.3507408925992814
Validation loss: 2.161339679598905

Epoch: 5| Step: 7
Training loss: 0.512276207513658
Validation loss: 2.153184489404951

Epoch: 5| Step: 8
Training loss: 0.5238814392950187
Validation loss: 2.1734757401614004

Epoch: 5| Step: 9
Training loss: 0.42344343948421564
Validation loss: 2.184579420182817

Epoch: 5| Step: 10
Training loss: 0.42592955989811593
Validation loss: 2.1617899583357962

Epoch: 758| Step: 0
Training loss: 0.4252121473001462
Validation loss: 2.1522681952903735

Epoch: 5| Step: 1
Training loss: 0.6828605861884823
Validation loss: 2.235823787112201

Epoch: 5| Step: 2
Training loss: 0.3494718483595895
Validation loss: 2.1388076002703778

Epoch: 5| Step: 3
Training loss: 0.5015076913329396
Validation loss: 2.145419580186935

Epoch: 5| Step: 4
Training loss: 0.3985353611462082
Validation loss: 2.189301437842267

Epoch: 5| Step: 5
Training loss: 0.4427203812549271
Validation loss: 2.1886513699194876

Epoch: 5| Step: 6
Training loss: 0.5858666186375151
Validation loss: 2.1942613859016022

Epoch: 5| Step: 7
Training loss: 0.891571044399582
Validation loss: 2.1682412891642655

Epoch: 5| Step: 8
Training loss: 0.3312827256069708
Validation loss: 2.189267682163298

Epoch: 5| Step: 9
Training loss: 0.5006067052158184
Validation loss: 2.155757140904026

Epoch: 5| Step: 10
Training loss: 0.30251232740804684
Validation loss: 2.226275381369979

Epoch: 759| Step: 0
Training loss: 0.3399337123316869
Validation loss: 2.192550012371192

Epoch: 5| Step: 1
Training loss: 0.46221699368435465
Validation loss: 2.206398026715132

Epoch: 5| Step: 2
Training loss: 0.5711153728185502
Validation loss: 2.231626535941191

Epoch: 5| Step: 3
Training loss: 0.6413109061482789
Validation loss: 2.2481526581150595

Epoch: 5| Step: 4
Training loss: 0.48724491769577843
Validation loss: 2.1906127744910515

Epoch: 5| Step: 5
Training loss: 0.5144024719003134
Validation loss: 2.16086798289538

Epoch: 5| Step: 6
Training loss: 0.5373099767437772
Validation loss: 2.1982213201725167

Epoch: 5| Step: 7
Training loss: 0.4046808529458894
Validation loss: 2.191971557437186

Epoch: 5| Step: 8
Training loss: 0.4165771348447204
Validation loss: 2.2480802966071107

Epoch: 5| Step: 9
Training loss: 0.8379747397432601
Validation loss: 2.227370280014589

Epoch: 5| Step: 10
Training loss: 0.46327946422933913
Validation loss: 2.199145442243772

Epoch: 760| Step: 0
Training loss: 0.30133642013640516
Validation loss: 2.2048853254184966

Epoch: 5| Step: 1
Training loss: 0.34798030537747826
Validation loss: 2.2275433685309594

Epoch: 5| Step: 2
Training loss: 0.2757267355058108
Validation loss: 2.148314792563202

Epoch: 5| Step: 3
Training loss: 0.494010938430642
Validation loss: 2.1831291937751454

Epoch: 5| Step: 4
Training loss: 0.5227220399786898
Validation loss: 2.1728662858081425

Epoch: 5| Step: 5
Training loss: 0.5182690309562532
Validation loss: 2.1982402842232127

Epoch: 5| Step: 6
Training loss: 0.34233890606627687
Validation loss: 2.178840404680356

Epoch: 5| Step: 7
Training loss: 0.4741920237417805
Validation loss: 2.2326433978723665

Epoch: 5| Step: 8
Training loss: 0.425190524563622
Validation loss: 2.1492701493352855

Epoch: 5| Step: 9
Training loss: 0.8992709067668787
Validation loss: 2.2040247741257337

Epoch: 5| Step: 10
Training loss: 0.44333537704790243
Validation loss: 2.246158951378764

Epoch: 761| Step: 0
Training loss: 0.3428978001540666
Validation loss: 2.1406128932944957

Epoch: 5| Step: 1
Training loss: 0.37139304288845576
Validation loss: 2.215209985059766

Epoch: 5| Step: 2
Training loss: 0.5159871534626149
Validation loss: 2.168748090593704

Epoch: 5| Step: 3
Training loss: 0.9938101828243264
Validation loss: 2.2016247176521553

Epoch: 5| Step: 4
Training loss: 0.40299797570404067
Validation loss: 2.1531781558527245

Epoch: 5| Step: 5
Training loss: 0.3514337727855986
Validation loss: 2.2140387229040153

Epoch: 5| Step: 6
Training loss: 0.5807305465704656
Validation loss: 2.2036706421404584

Epoch: 5| Step: 7
Training loss: 0.4902395270939353
Validation loss: 2.257938447778973

Epoch: 5| Step: 8
Training loss: 0.305217770548835
Validation loss: 2.2012698554100685

Epoch: 5| Step: 9
Training loss: 0.5641829956354937
Validation loss: 2.2081608587868273

Epoch: 5| Step: 10
Training loss: 0.5731677343312922
Validation loss: 2.1666440721979203

Epoch: 762| Step: 0
Training loss: 0.4148396450493371
Validation loss: 2.162689296914277

Epoch: 5| Step: 1
Training loss: 0.3436514431377121
Validation loss: 2.1822004108016158

Epoch: 5| Step: 2
Training loss: 0.3006303829972166
Validation loss: 2.156611376764018

Epoch: 5| Step: 3
Training loss: 0.5511196530784194
Validation loss: 2.2872295343695663

Epoch: 5| Step: 4
Training loss: 0.43868108113004955
Validation loss: 2.1516547367897623

Epoch: 5| Step: 5
Training loss: 0.37386968256116127
Validation loss: 2.1976781016853626

Epoch: 5| Step: 6
Training loss: 0.9128990267626919
Validation loss: 2.2183511015218955

Epoch: 5| Step: 7
Training loss: 0.48430525369868443
Validation loss: 2.2648662644617876

Epoch: 5| Step: 8
Training loss: 0.4673610773066067
Validation loss: 2.2450856829790804

Epoch: 5| Step: 9
Training loss: 0.42320291489230966
Validation loss: 2.176929765401466

Epoch: 5| Step: 10
Training loss: 0.44418822128260954
Validation loss: 2.1283124228159886

Epoch: 763| Step: 0
Training loss: 0.44463856211331654
Validation loss: 2.183297461608218

Epoch: 5| Step: 1
Training loss: 0.404948423657197
Validation loss: 2.206739008796775

Epoch: 5| Step: 2
Training loss: 0.4247296848075347
Validation loss: 2.267910783551056

Epoch: 5| Step: 3
Training loss: 0.35821807231105185
Validation loss: 2.154527510915261

Epoch: 5| Step: 4
Training loss: 0.5798588604861178
Validation loss: 2.191194382031491

Epoch: 5| Step: 5
Training loss: 0.582579361048591
Validation loss: 2.226605570761026

Epoch: 5| Step: 6
Training loss: 0.45530758749694933
Validation loss: 2.1543884088321055

Epoch: 5| Step: 7
Training loss: 0.44278491610677795
Validation loss: 2.191288494480526

Epoch: 5| Step: 8
Training loss: 0.8955997598715899
Validation loss: 2.215016245063779

Epoch: 5| Step: 9
Training loss: 0.34126382951695095
Validation loss: 2.197115275900794

Epoch: 5| Step: 10
Training loss: 0.4012365569480182
Validation loss: 2.1815575851485964

Epoch: 764| Step: 0
Training loss: 0.38459663746609163
Validation loss: 2.2386212710509454

Epoch: 5| Step: 1
Training loss: 0.6653336868030371
Validation loss: 2.2245400374472153

Epoch: 5| Step: 2
Training loss: 0.3903498252571177
Validation loss: 2.1726681363336606

Epoch: 5| Step: 3
Training loss: 0.44963774007480267
Validation loss: 2.1062652793766543

Epoch: 5| Step: 4
Training loss: 0.4349896925494266
Validation loss: 2.1430916499418102

Epoch: 5| Step: 5
Training loss: 0.410721706980835
Validation loss: 2.1894394078101764

Epoch: 5| Step: 6
Training loss: 0.42679646402081206
Validation loss: 2.207766864428834

Epoch: 5| Step: 7
Training loss: 0.42534520630996714
Validation loss: 2.2257719382589576

Epoch: 5| Step: 8
Training loss: 0.9852142692016574
Validation loss: 2.1908561731670253

Epoch: 5| Step: 9
Training loss: 0.5554850579938118
Validation loss: 2.210083955040484

Epoch: 5| Step: 10
Training loss: 0.39309754811004805
Validation loss: 2.168529546978737

Epoch: 765| Step: 0
Training loss: 0.5137320363600538
Validation loss: 2.2144705696797864

Epoch: 5| Step: 1
Training loss: 0.5060200086376951
Validation loss: 2.165112451101969

Epoch: 5| Step: 2
Training loss: 0.5317686017992483
Validation loss: 2.173368977552534

Epoch: 5| Step: 3
Training loss: 0.341712309048847
Validation loss: 2.1791689711695628

Epoch: 5| Step: 4
Training loss: 0.3497889180252444
Validation loss: 2.1509303333022753

Epoch: 5| Step: 5
Training loss: 0.4838397083100113
Validation loss: 2.1901257119209028

Epoch: 5| Step: 6
Training loss: 0.5451675462850769
Validation loss: 2.125954948466645

Epoch: 5| Step: 7
Training loss: 0.39738437374419144
Validation loss: 2.148005819347818

Epoch: 5| Step: 8
Training loss: 0.34122371027359877
Validation loss: 2.175809198198066

Epoch: 5| Step: 9
Training loss: 0.8023970143319679
Validation loss: 2.221484237163673

Epoch: 5| Step: 10
Training loss: 0.449063017014622
Validation loss: 2.2450765295710915

Epoch: 766| Step: 0
Training loss: 0.3649221095168304
Validation loss: 2.1542060685723037

Epoch: 5| Step: 1
Training loss: 0.5358320549533875
Validation loss: 2.180230648628817

Epoch: 5| Step: 2
Training loss: 0.42873269549445797
Validation loss: 2.202230180571499

Epoch: 5| Step: 3
Training loss: 0.8574356738394382
Validation loss: 2.2669816953303275

Epoch: 5| Step: 4
Training loss: 0.405031743424507
Validation loss: 2.191971276158166

Epoch: 5| Step: 5
Training loss: 0.45295728670940394
Validation loss: 2.1835236477312656

Epoch: 5| Step: 6
Training loss: 0.48421549478072484
Validation loss: 2.1720858660631595

Epoch: 5| Step: 7
Training loss: 0.3526217292382437
Validation loss: 2.178679962415304

Epoch: 5| Step: 8
Training loss: 0.5214862609143391
Validation loss: 2.1311776041330215

Epoch: 5| Step: 9
Training loss: 0.37265179469486265
Validation loss: 2.1124491553981626

Epoch: 5| Step: 10
Training loss: 0.5286221585038391
Validation loss: 2.185882273714235

Epoch: 767| Step: 0
Training loss: 0.544817569279781
Validation loss: 2.2053077141018584

Epoch: 5| Step: 1
Training loss: 0.2847793387419319
Validation loss: 2.2120644771947333

Epoch: 5| Step: 2
Training loss: 0.44608226968453285
Validation loss: 2.2274530621312056

Epoch: 5| Step: 3
Training loss: 0.4366084619792477
Validation loss: 2.204872569879413

Epoch: 5| Step: 4
Training loss: 0.5302241462293078
Validation loss: 2.1669216321513787

Epoch: 5| Step: 5
Training loss: 0.3278839724713181
Validation loss: 2.237058416915285

Epoch: 5| Step: 6
Training loss: 0.3952833881137891
Validation loss: 2.2344192028944003

Epoch: 5| Step: 7
Training loss: 0.4492603116919124
Validation loss: 2.0920605835891433

Epoch: 5| Step: 8
Training loss: 0.9208873048273272
Validation loss: 2.1803811961143142

Epoch: 5| Step: 9
Training loss: 0.5066591516782354
Validation loss: 2.229152426004757

Epoch: 5| Step: 10
Training loss: 0.3256526858005967
Validation loss: 2.2345528526437914

Epoch: 768| Step: 0
Training loss: 0.3958255574650532
Validation loss: 2.228254383613479

Epoch: 5| Step: 1
Training loss: 0.4482175533531634
Validation loss: 2.190952494088543

Epoch: 5| Step: 2
Training loss: 0.4951390970713264
Validation loss: 2.1402548049287575

Epoch: 5| Step: 3
Training loss: 0.3706191189831656
Validation loss: 2.24336750093848

Epoch: 5| Step: 4
Training loss: 0.5283704300270603
Validation loss: 2.156167513099022

Epoch: 5| Step: 5
Training loss: 0.44062090526869613
Validation loss: 2.137750987163257

Epoch: 5| Step: 6
Training loss: 0.32981849933363255
Validation loss: 2.2412136781966048

Epoch: 5| Step: 7
Training loss: 0.5485625795501446
Validation loss: 2.208487788731275

Epoch: 5| Step: 8
Training loss: 0.33946274632908774
Validation loss: 2.168958067162184

Epoch: 5| Step: 9
Training loss: 0.4407382062133577
Validation loss: 2.222770002447265

Epoch: 5| Step: 10
Training loss: 0.9253431482724387
Validation loss: 2.1626514137356283

Epoch: 769| Step: 0
Training loss: 0.33109927932061145
Validation loss: 2.13591069935337

Epoch: 5| Step: 1
Training loss: 0.3659948296272933
Validation loss: 2.1575916783300064

Epoch: 5| Step: 2
Training loss: 0.3799056999941214
Validation loss: 2.1622788891127263

Epoch: 5| Step: 3
Training loss: 0.5404305720347895
Validation loss: 2.1705361500269027

Epoch: 5| Step: 4
Training loss: 0.4801850295325395
Validation loss: 2.092903552608713

Epoch: 5| Step: 5
Training loss: 0.30495051500411735
Validation loss: 2.1557119053884994

Epoch: 5| Step: 6
Training loss: 0.46598601842747206
Validation loss: 2.2211614754396614

Epoch: 5| Step: 7
Training loss: 0.880064815280064
Validation loss: 2.2296144752350413

Epoch: 5| Step: 8
Training loss: 0.36995828483596405
Validation loss: 2.123689524884473

Epoch: 5| Step: 9
Training loss: 0.4361195242361171
Validation loss: 2.2058001680665287

Epoch: 5| Step: 10
Training loss: 0.48824778632889304
Validation loss: 2.21172980454003

Epoch: 770| Step: 0
Training loss: 0.2704145084690753
Validation loss: 2.167184862007375

Epoch: 5| Step: 1
Training loss: 0.37090748579529853
Validation loss: 2.2320049097706454

Epoch: 5| Step: 2
Training loss: 0.8076670030500546
Validation loss: 2.1602104402885054

Epoch: 5| Step: 3
Training loss: 0.47547939603271533
Validation loss: 2.1657217117006833

Epoch: 5| Step: 4
Training loss: 0.4183428329203541
Validation loss: 2.144773587969032

Epoch: 5| Step: 5
Training loss: 0.39473133867593396
Validation loss: 2.1764119777343884

Epoch: 5| Step: 6
Training loss: 0.47632677470662294
Validation loss: 2.189057456992103

Epoch: 5| Step: 7
Training loss: 0.4168986588588965
Validation loss: 2.172094829580182

Epoch: 5| Step: 8
Training loss: 0.4867338762948474
Validation loss: 2.167073803962597

Epoch: 5| Step: 9
Training loss: 0.4269846088775777
Validation loss: 2.280515873212497

Epoch: 5| Step: 10
Training loss: 0.36085632038826354
Validation loss: 2.1923388787915017

Epoch: 771| Step: 0
Training loss: 0.4775001494422399
Validation loss: 2.233798942883381

Epoch: 5| Step: 1
Training loss: 0.4466525377730346
Validation loss: 2.1698362292709787

Epoch: 5| Step: 2
Training loss: 0.4831813748767972
Validation loss: 2.177060040337898

Epoch: 5| Step: 3
Training loss: 0.49104714364531127
Validation loss: 2.1826467665416356

Epoch: 5| Step: 4
Training loss: 0.3589529586178545
Validation loss: 2.1829356094854195

Epoch: 5| Step: 5
Training loss: 0.45812596340520506
Validation loss: 2.226541961419757

Epoch: 5| Step: 6
Training loss: 0.5265100741676965
Validation loss: 2.2424166553956826

Epoch: 5| Step: 7
Training loss: 0.39734137984036566
Validation loss: 2.12741106326083

Epoch: 5| Step: 8
Training loss: 0.32665725957615394
Validation loss: 2.1102941736761887

Epoch: 5| Step: 9
Training loss: 0.8679046071521549
Validation loss: 2.2012292441895966

Epoch: 5| Step: 10
Training loss: 0.38377166786280514
Validation loss: 2.113432131118965

Epoch: 772| Step: 0
Training loss: 0.3446266634731112
Validation loss: 2.217538674829301

Epoch: 5| Step: 1
Training loss: 0.47930349766664615
Validation loss: 2.162921703598883

Epoch: 5| Step: 2
Training loss: 0.506053577982821
Validation loss: 2.210725826420182

Epoch: 5| Step: 3
Training loss: 0.5611495124729802
Validation loss: 2.171668378589578

Epoch: 5| Step: 4
Training loss: 0.9320475331472466
Validation loss: 2.137260723268233

Epoch: 5| Step: 5
Training loss: 0.3976522823952707
Validation loss: 2.2095559319717286

Epoch: 5| Step: 6
Training loss: 0.4112513319243223
Validation loss: 2.232093901277548

Epoch: 5| Step: 7
Training loss: 0.3668690375862222
Validation loss: 2.1851674525026903

Epoch: 5| Step: 8
Training loss: 0.3149403298529631
Validation loss: 2.2366227789781643

Epoch: 5| Step: 9
Training loss: 0.5726569858770079
Validation loss: 2.1446322317152493

Epoch: 5| Step: 10
Training loss: 0.35851655931282456
Validation loss: 2.2588779453309042

Epoch: 773| Step: 0
Training loss: 0.3975513552234202
Validation loss: 2.214463954706135

Epoch: 5| Step: 1
Training loss: 0.3747215429244417
Validation loss: 2.262857306872761

Epoch: 5| Step: 2
Training loss: 0.3399679022952968
Validation loss: 2.1929566108322653

Epoch: 5| Step: 3
Training loss: 0.5592162391795954
Validation loss: 2.198310845475465

Epoch: 5| Step: 4
Training loss: 0.9055077374073496
Validation loss: 2.193749979479189

Epoch: 5| Step: 5
Training loss: 0.432013958659096
Validation loss: 2.18544781899622

Epoch: 5| Step: 6
Training loss: 0.6078386257018981
Validation loss: 2.1882623589245362

Epoch: 5| Step: 7
Training loss: 0.4243064326089777
Validation loss: 2.140816570009696

Epoch: 5| Step: 8
Training loss: 0.3420050613707801
Validation loss: 2.1131479348138713

Epoch: 5| Step: 9
Training loss: 0.4208692642333174
Validation loss: 2.209326461753358

Epoch: 5| Step: 10
Training loss: 0.3956884089573802
Validation loss: 2.2292921770620886

Epoch: 774| Step: 0
Training loss: 0.7049787456609232
Validation loss: 2.239499951408456

Epoch: 5| Step: 1
Training loss: 0.382646816755777
Validation loss: 2.2072714572249175

Epoch: 5| Step: 2
Training loss: 0.3806262549957482
Validation loss: 2.1692827273129933

Epoch: 5| Step: 3
Training loss: 0.33136296055643144
Validation loss: 2.1396408471445247

Epoch: 5| Step: 4
Training loss: 0.4728131467331966
Validation loss: 2.23876331843918

Epoch: 5| Step: 5
Training loss: 0.34586374678605036
Validation loss: 2.213690825231761

Epoch: 5| Step: 6
Training loss: 0.37733438215612647
Validation loss: 2.134155136908638

Epoch: 5| Step: 7
Training loss: 0.4014306122724817
Validation loss: 2.2271425652702117

Epoch: 5| Step: 8
Training loss: 0.8585010245933039
Validation loss: 2.205107431818186

Epoch: 5| Step: 9
Training loss: 0.45436725022162344
Validation loss: 2.15726482377648

Epoch: 5| Step: 10
Training loss: 0.44021570797381854
Validation loss: 2.1644100995326228

Epoch: 775| Step: 0
Training loss: 0.44396893782043456
Validation loss: 2.134632134755767

Epoch: 5| Step: 1
Training loss: 0.4046650191731253
Validation loss: 2.191910578693012

Epoch: 5| Step: 2
Training loss: 0.5375931659064003
Validation loss: 2.154225690834407

Epoch: 5| Step: 3
Training loss: 0.4834508385818567
Validation loss: 2.2029842080667086

Epoch: 5| Step: 4
Training loss: 0.8644723399664547
Validation loss: 2.1395531565170893

Epoch: 5| Step: 5
Training loss: 0.31635937520121976
Validation loss: 2.1279873271683214

Epoch: 5| Step: 6
Training loss: 0.5126689795134766
Validation loss: 2.149127595954597

Epoch: 5| Step: 7
Training loss: 0.5081338305955281
Validation loss: 2.1693677342983797

Epoch: 5| Step: 8
Training loss: 0.45865448804572667
Validation loss: 2.132548930789211

Epoch: 5| Step: 9
Training loss: 0.520195958829683
Validation loss: 2.169739735987424

Epoch: 5| Step: 10
Training loss: 0.6250616996827908
Validation loss: 2.2416842241930452

Epoch: 776| Step: 0
Training loss: 0.4325686012006446
Validation loss: 2.1668944513201454

Epoch: 5| Step: 1
Training loss: 0.46885476531074083
Validation loss: 2.1780577493229067

Epoch: 5| Step: 2
Training loss: 0.36686605221626245
Validation loss: 2.2202263460783045

Epoch: 5| Step: 3
Training loss: 0.35296818196595897
Validation loss: 2.162006966715186

Epoch: 5| Step: 4
Training loss: 0.4663971182793453
Validation loss: 2.2220338550157672

Epoch: 5| Step: 5
Training loss: 0.423626953056338
Validation loss: 2.216890052628595

Epoch: 5| Step: 6
Training loss: 0.8661091947959149
Validation loss: 2.220906668936719

Epoch: 5| Step: 7
Training loss: 0.4277007381503746
Validation loss: 2.2607272965681364

Epoch: 5| Step: 8
Training loss: 0.3411106523422866
Validation loss: 2.1699669135312014

Epoch: 5| Step: 9
Training loss: 0.3883587328165562
Validation loss: 2.185240019645466

Epoch: 5| Step: 10
Training loss: 0.39565920345950667
Validation loss: 2.1945867032400312

Epoch: 777| Step: 0
Training loss: 0.534703585339824
Validation loss: 2.1581600278635436

Epoch: 5| Step: 1
Training loss: 0.5299480416362593
Validation loss: 2.171207741267865

Epoch: 5| Step: 2
Training loss: 0.39503386557544284
Validation loss: 2.154898354352258

Epoch: 5| Step: 3
Training loss: 0.38218780071530556
Validation loss: 2.101437947213403

Epoch: 5| Step: 4
Training loss: 0.5207830563756252
Validation loss: 2.1686595888800664

Epoch: 5| Step: 5
Training loss: 0.8233902369332032
Validation loss: 2.1739584584439062

Epoch: 5| Step: 6
Training loss: 0.5260162032608758
Validation loss: 2.1457720097748454

Epoch: 5| Step: 7
Training loss: 0.2785557470540892
Validation loss: 2.197798637467881

Epoch: 5| Step: 8
Training loss: 0.3250428492469108
Validation loss: 2.2299343637242726

Epoch: 5| Step: 9
Training loss: 0.259519288133603
Validation loss: 2.173768267750752

Epoch: 5| Step: 10
Training loss: 0.3252305134918109
Validation loss: 2.1941261605429796

Epoch: 778| Step: 0
Training loss: 0.47428949196073483
Validation loss: 2.22086689411969

Epoch: 5| Step: 1
Training loss: 0.5496221750988003
Validation loss: 2.1462099258781318

Epoch: 5| Step: 2
Training loss: 0.8275802908146759
Validation loss: 2.153686077465407

Epoch: 5| Step: 3
Training loss: 0.4177118742008706
Validation loss: 2.208666390533337

Epoch: 5| Step: 4
Training loss: 0.4819827223823112
Validation loss: 2.1497347813852734

Epoch: 5| Step: 5
Training loss: 0.3566167131912561
Validation loss: 2.1997641199009834

Epoch: 5| Step: 6
Training loss: 0.47769084616705293
Validation loss: 2.1663129877156186

Epoch: 5| Step: 7
Training loss: 0.4021087626913362
Validation loss: 2.1850783806809684

Epoch: 5| Step: 8
Training loss: 0.40858459900041383
Validation loss: 2.113019882834002

Epoch: 5| Step: 9
Training loss: 0.404181920170113
Validation loss: 2.1965825947979765

Epoch: 5| Step: 10
Training loss: 0.4624191168348211
Validation loss: 2.2050199886207835

Epoch: 779| Step: 0
Training loss: 0.8630578282741087
Validation loss: 2.1316190079763966

Epoch: 5| Step: 1
Training loss: 0.380999612665355
Validation loss: 2.1656014385154165

Epoch: 5| Step: 2
Training loss: 0.3788252478466886
Validation loss: 2.1871796322102903

Epoch: 5| Step: 3
Training loss: 0.3750753922969763
Validation loss: 2.1925880179511577

Epoch: 5| Step: 4
Training loss: 0.34645796656899797
Validation loss: 2.1911233271834565

Epoch: 5| Step: 5
Training loss: 0.33318118507269984
Validation loss: 2.241986160239702

Epoch: 5| Step: 6
Training loss: 0.47810232258292185
Validation loss: 2.1567759497343904

Epoch: 5| Step: 7
Training loss: 0.28839277317437323
Validation loss: 2.1530845880834915

Epoch: 5| Step: 8
Training loss: 0.5002014231280643
Validation loss: 2.2007726566117616

Epoch: 5| Step: 9
Training loss: 0.4110909302461454
Validation loss: 2.267865395377241

Epoch: 5| Step: 10
Training loss: 0.44338735416538255
Validation loss: 2.1910246631132844

Epoch: 780| Step: 0
Training loss: 0.5351187421365526
Validation loss: 2.148063200771411

Epoch: 5| Step: 1
Training loss: 0.827306486880963
Validation loss: 2.1441009022148316

Epoch: 5| Step: 2
Training loss: 0.36370013298281867
Validation loss: 2.1460659244721714

Epoch: 5| Step: 3
Training loss: 0.38002268513301396
Validation loss: 2.171234907657158

Epoch: 5| Step: 4
Training loss: 0.3774517694508854
Validation loss: 2.229862895256524

Epoch: 5| Step: 5
Training loss: 0.4318878881019208
Validation loss: 2.178975783322353

Epoch: 5| Step: 6
Training loss: 0.5952924469701751
Validation loss: 2.12816955759244

Epoch: 5| Step: 7
Training loss: 0.45695424857664246
Validation loss: 2.178896759347504

Epoch: 5| Step: 8
Training loss: 0.393491773096434
Validation loss: 2.1851842773134273

Epoch: 5| Step: 9
Training loss: 0.43981330522293033
Validation loss: 2.183387468501804

Epoch: 5| Step: 10
Training loss: 0.500865217480331
Validation loss: 2.1600129730252045

Epoch: 781| Step: 0
Training loss: 0.462915057732607
Validation loss: 2.223212265664563

Epoch: 5| Step: 1
Training loss: 0.33326047110937423
Validation loss: 2.19451047327157

Epoch: 5| Step: 2
Training loss: 0.5392453256810341
Validation loss: 2.226053828258625

Epoch: 5| Step: 3
Training loss: 0.5684434494286024
Validation loss: 2.1643498752148633

Epoch: 5| Step: 4
Training loss: 0.8230566718519181
Validation loss: 2.148907814789872

Epoch: 5| Step: 5
Training loss: 0.6159356374339873
Validation loss: 2.1509652037139007

Epoch: 5| Step: 6
Training loss: 0.44947374818732483
Validation loss: 2.189310315066718

Epoch: 5| Step: 7
Training loss: 0.55736991891472
Validation loss: 2.1919166301526234

Epoch: 5| Step: 8
Training loss: 0.5141100736826097
Validation loss: 2.1391764596736604

Epoch: 5| Step: 9
Training loss: 0.4797234220443125
Validation loss: 2.1476823188392293

Epoch: 5| Step: 10
Training loss: 0.39445462757533856
Validation loss: 2.1999770060742483

Epoch: 782| Step: 0
Training loss: 0.4791666856710458
Validation loss: 2.1944934255729778

Epoch: 5| Step: 1
Training loss: 0.8100371814953733
Validation loss: 2.1783736002402936

Epoch: 5| Step: 2
Training loss: 0.450047748072279
Validation loss: 2.175342455108482

Epoch: 5| Step: 3
Training loss: 0.3785092742040716
Validation loss: 2.1971609261383356

Epoch: 5| Step: 4
Training loss: 0.4727242160828345
Validation loss: 2.177604430015393

Epoch: 5| Step: 5
Training loss: 0.48582251436391394
Validation loss: 2.154754500517975

Epoch: 5| Step: 6
Training loss: 0.4050390829843609
Validation loss: 2.1866307466699597

Epoch: 5| Step: 7
Training loss: 0.3527074395897153
Validation loss: 2.185116413557027

Epoch: 5| Step: 8
Training loss: 0.4746349626087785
Validation loss: 2.232066619930596

Epoch: 5| Step: 9
Training loss: 0.5711920761858409
Validation loss: 2.1743803932629024

Epoch: 5| Step: 10
Training loss: 0.33800697528466944
Validation loss: 2.1844808437216403

Epoch: 783| Step: 0
Training loss: 0.586198087602136
Validation loss: 2.1664001614098347

Epoch: 5| Step: 1
Training loss: 0.2221549313251607
Validation loss: 2.26993864990165

Epoch: 5| Step: 2
Training loss: 0.3143638578908975
Validation loss: 2.220730711026895

Epoch: 5| Step: 3
Training loss: 0.4189848803350533
Validation loss: 2.174566744909356

Epoch: 5| Step: 4
Training loss: 0.4042014410193312
Validation loss: 2.130202446353842

Epoch: 5| Step: 5
Training loss: 0.5795235085709545
Validation loss: 2.180179539969961

Epoch: 5| Step: 6
Training loss: 0.544849623398757
Validation loss: 2.202126679348111

Epoch: 5| Step: 7
Training loss: 0.33107653970531026
Validation loss: 2.0622106108587133

Epoch: 5| Step: 8
Training loss: 0.8550733932984589
Validation loss: 2.252236426103846

Epoch: 5| Step: 9
Training loss: 0.49571085593926356
Validation loss: 2.142288535877406

Epoch: 5| Step: 10
Training loss: 0.5317800346074134
Validation loss: 2.157216168758609

Epoch: 784| Step: 0
Training loss: 0.3766927264420467
Validation loss: 2.197420341121832

Epoch: 5| Step: 1
Training loss: 0.40247539107397706
Validation loss: 2.1371127840209785

Epoch: 5| Step: 2
Training loss: 0.4510653811850758
Validation loss: 2.2338892796501346

Epoch: 5| Step: 3
Training loss: 0.4292284160312996
Validation loss: 2.16682260849793

Epoch: 5| Step: 4
Training loss: 0.4029102041514553
Validation loss: 2.1608067356276943

Epoch: 5| Step: 5
Training loss: 0.4266538165934
Validation loss: 2.1768836496890667

Epoch: 5| Step: 6
Training loss: 0.43494818899573773
Validation loss: 2.243603443107082

Epoch: 5| Step: 7
Training loss: 0.4106045044613352
Validation loss: 2.224232852787534

Epoch: 5| Step: 8
Training loss: 0.798724179395285
Validation loss: 2.2168062018438186

Epoch: 5| Step: 9
Training loss: 0.5422663914342976
Validation loss: 2.1683592889762076

Epoch: 5| Step: 10
Training loss: 0.5020475781109827
Validation loss: 2.1432343356577133

Epoch: 785| Step: 0
Training loss: 0.44965682852289823
Validation loss: 2.1305781957810987

Epoch: 5| Step: 1
Training loss: 0.475749870731258
Validation loss: 2.157323187672267

Epoch: 5| Step: 2
Training loss: 0.5541142738882365
Validation loss: 2.1290546703805897

Epoch: 5| Step: 3
Training loss: 0.2974564354719291
Validation loss: 2.1591628678370034

Epoch: 5| Step: 4
Training loss: 0.37782090861616063
Validation loss: 2.1769302388128917

Epoch: 5| Step: 5
Training loss: 0.41693102278586636
Validation loss: 2.1492681066713253

Epoch: 5| Step: 6
Training loss: 0.53128163860579
Validation loss: 2.0930299887667183

Epoch: 5| Step: 7
Training loss: 0.5365038978954115
Validation loss: 2.247145347014305

Epoch: 5| Step: 8
Training loss: 0.3860649593399068
Validation loss: 2.1747629166325546

Epoch: 5| Step: 9
Training loss: 0.3672051121160574
Validation loss: 2.1791889127501167

Epoch: 5| Step: 10
Training loss: 0.9441672710025084
Validation loss: 2.159691972018077

Epoch: 786| Step: 0
Training loss: 0.42266321722976175
Validation loss: 2.1840101305118784

Epoch: 5| Step: 1
Training loss: 0.4298541699460035
Validation loss: 2.2172347519888054

Epoch: 5| Step: 2
Training loss: 0.2838695314897712
Validation loss: 2.2488917398053014

Epoch: 5| Step: 3
Training loss: 0.35421519321023964
Validation loss: 2.1921813400149617

Epoch: 5| Step: 4
Training loss: 0.4080760338166578
Validation loss: 2.1920338934746666

Epoch: 5| Step: 5
Training loss: 0.5030316592049711
Validation loss: 2.1607148638439257

Epoch: 5| Step: 6
Training loss: 0.3860162654609671
Validation loss: 2.1876457072072406

Epoch: 5| Step: 7
Training loss: 0.8546211886441614
Validation loss: 2.1847274273215778

Epoch: 5| Step: 8
Training loss: 0.21979732645500552
Validation loss: 2.1754125240422626

Epoch: 5| Step: 9
Training loss: 0.47843547850517515
Validation loss: 2.182813057354855

Epoch: 5| Step: 10
Training loss: 0.5104587855445122
Validation loss: 2.208219177753482

Epoch: 787| Step: 0
Training loss: 0.3906417270893715
Validation loss: 2.178223042875248

Epoch: 5| Step: 1
Training loss: 0.5296123732681589
Validation loss: 2.125469582951771

Epoch: 5| Step: 2
Training loss: 0.4354332403590889
Validation loss: 2.1727340214051036

Epoch: 5| Step: 3
Training loss: 0.9041212006020614
Validation loss: 2.1921635830546435

Epoch: 5| Step: 4
Training loss: 0.5016267658072333
Validation loss: 2.242751450312752

Epoch: 5| Step: 5
Training loss: 0.5175010479810488
Validation loss: 2.1911906632657163

Epoch: 5| Step: 6
Training loss: 0.45824101088989594
Validation loss: 2.097584676286273

Epoch: 5| Step: 7
Training loss: 0.525194379607791
Validation loss: 2.1789690429445896

Epoch: 5| Step: 8
Training loss: 0.5874398870353689
Validation loss: 2.1619464768326626

Epoch: 5| Step: 9
Training loss: 0.5079608993838866
Validation loss: 2.1635380307048027

Epoch: 5| Step: 10
Training loss: 0.290548051368607
Validation loss: 2.1122932898951454

Epoch: 788| Step: 0
Training loss: 0.42761962257110786
Validation loss: 2.1068141668183418

Epoch: 5| Step: 1
Training loss: 0.5983416796830895
Validation loss: 2.159088049263249

Epoch: 5| Step: 2
Training loss: 0.8438606542860505
Validation loss: 2.197929197609172

Epoch: 5| Step: 3
Training loss: 0.3874439798900278
Validation loss: 2.1786978681012776

Epoch: 5| Step: 4
Training loss: 0.4824196201534317
Validation loss: 2.101965081945232

Epoch: 5| Step: 5
Training loss: 0.5289453275097532
Validation loss: 2.1832449064576793

Epoch: 5| Step: 6
Training loss: 0.31821012216241434
Validation loss: 2.1785491936124797

Epoch: 5| Step: 7
Training loss: 0.3949224024919106
Validation loss: 2.1817535184046846

Epoch: 5| Step: 8
Training loss: 0.2595899891625108
Validation loss: 2.2137665985501083

Epoch: 5| Step: 9
Training loss: 0.3204754438217307
Validation loss: 2.2243283121509023

Epoch: 5| Step: 10
Training loss: 0.3881299635589726
Validation loss: 2.2179447048933945

Epoch: 789| Step: 0
Training loss: 0.2789841348160452
Validation loss: 2.198024066151151

Epoch: 5| Step: 1
Training loss: 0.5222727499042883
Validation loss: 2.177019856567679

Epoch: 5| Step: 2
Training loss: 0.46122866663922996
Validation loss: 2.1429065084728562

Epoch: 5| Step: 3
Training loss: 0.30804747505719693
Validation loss: 2.159194883381754

Epoch: 5| Step: 4
Training loss: 0.46832943169177943
Validation loss: 2.1501740341548983

Epoch: 5| Step: 5
Training loss: 0.43748000644230406
Validation loss: 2.1777614434924195

Epoch: 5| Step: 6
Training loss: 0.4586818753365566
Validation loss: 2.199186294197564

Epoch: 5| Step: 7
Training loss: 0.460803982421973
Validation loss: 2.213520582606586

Epoch: 5| Step: 8
Training loss: 0.32319088669940593
Validation loss: 2.199957477833577

Epoch: 5| Step: 9
Training loss: 0.372391889680197
Validation loss: 2.1479185137920753

Epoch: 5| Step: 10
Training loss: 0.9447261158088605
Validation loss: 2.188781409842408

Epoch: 790| Step: 0
Training loss: 0.41392237613493993
Validation loss: 2.1189109212375095

Epoch: 5| Step: 1
Training loss: 0.46720928664424743
Validation loss: 2.112193131298303

Epoch: 5| Step: 2
Training loss: 0.3290929821491928
Validation loss: 2.202411137702359

Epoch: 5| Step: 3
Training loss: 0.834591682387242
Validation loss: 2.126248283186113

Epoch: 5| Step: 4
Training loss: 0.3082387910809746
Validation loss: 2.1913483984416833

Epoch: 5| Step: 5
Training loss: 0.4147481639389134
Validation loss: 2.0916299728562993

Epoch: 5| Step: 6
Training loss: 0.3918855926079834
Validation loss: 2.1508317105153414

Epoch: 5| Step: 7
Training loss: 0.46132716179601
Validation loss: 2.203841590400307

Epoch: 5| Step: 8
Training loss: 0.3477869002628506
Validation loss: 2.176559577967436

Epoch: 5| Step: 9
Training loss: 0.5206116077216421
Validation loss: 2.1733062188092602

Epoch: 5| Step: 10
Training loss: 0.5651967519222024
Validation loss: 2.2266044067284763

Epoch: 791| Step: 0
Training loss: 0.521530863657814
Validation loss: 2.1889645035263254

Epoch: 5| Step: 1
Training loss: 0.3542227653878237
Validation loss: 2.1947742132559

Epoch: 5| Step: 2
Training loss: 0.7996582716996368
Validation loss: 2.16052669922475

Epoch: 5| Step: 3
Training loss: 0.5537969936123929
Validation loss: 2.223351453241853

Epoch: 5| Step: 4
Training loss: 0.38777592202930916
Validation loss: 2.214147292692548

Epoch: 5| Step: 5
Training loss: 0.5568075097199012
Validation loss: 2.1313566028519166

Epoch: 5| Step: 6
Training loss: 0.42219508355570134
Validation loss: 2.1800716166221052

Epoch: 5| Step: 7
Training loss: 0.5058834703517241
Validation loss: 2.0553279411826306

Epoch: 5| Step: 8
Training loss: 0.48429131554066246
Validation loss: 2.135575628079102

Epoch: 5| Step: 9
Training loss: 0.5341124832307944
Validation loss: 2.1553720485444825

Epoch: 5| Step: 10
Training loss: 0.2940251821702098
Validation loss: 2.2134377096956164

Epoch: 792| Step: 0
Training loss: 0.6055050008442866
Validation loss: 2.2216464555092412

Epoch: 5| Step: 1
Training loss: 0.4741696648120232
Validation loss: 2.244733491946102

Epoch: 5| Step: 2
Training loss: 0.5352205947841511
Validation loss: 2.202019813316798

Epoch: 5| Step: 3
Training loss: 0.47775098470788996
Validation loss: 2.1255252708902566

Epoch: 5| Step: 4
Training loss: 0.8195222226819376
Validation loss: 2.2155642940788525

Epoch: 5| Step: 5
Training loss: 0.4141925211760806
Validation loss: 2.166166889402842

Epoch: 5| Step: 6
Training loss: 0.46367114291177497
Validation loss: 2.169806714259007

Epoch: 5| Step: 7
Training loss: 0.4612850882977381
Validation loss: 2.1666823742331065

Epoch: 5| Step: 8
Training loss: 0.4854971439000595
Validation loss: 2.146372920706012

Epoch: 5| Step: 9
Training loss: 0.6442198492388214
Validation loss: 2.0957595200919217

Epoch: 5| Step: 10
Training loss: 0.42981301988573295
Validation loss: 2.1461892108167007

Epoch: 793| Step: 0
Training loss: 0.5234499687873291
Validation loss: 2.1944709057724965

Epoch: 5| Step: 1
Training loss: 0.33244918997905865
Validation loss: 2.11194257260813

Epoch: 5| Step: 2
Training loss: 0.4193234815377748
Validation loss: 2.221286398482614

Epoch: 5| Step: 3
Training loss: 0.4101407729362265
Validation loss: 2.2609284516563863

Epoch: 5| Step: 4
Training loss: 0.7283158833866986
Validation loss: 2.2649741947040822

Epoch: 5| Step: 5
Training loss: 0.4631952659492255
Validation loss: 2.1703667741030013

Epoch: 5| Step: 6
Training loss: 0.8741259296357198
Validation loss: 2.223425739705086

Epoch: 5| Step: 7
Training loss: 0.32751542189738153
Validation loss: 2.151157555893105

Epoch: 5| Step: 8
Training loss: 0.4456317159031612
Validation loss: 2.2118961556523438

Epoch: 5| Step: 9
Training loss: 0.6103685544509754
Validation loss: 2.1207187795313316

Epoch: 5| Step: 10
Training loss: 0.40706816229505405
Validation loss: 2.1484772172316267

Epoch: 794| Step: 0
Training loss: 0.5146159500204714
Validation loss: 2.184479524628844

Epoch: 5| Step: 1
Training loss: 0.5098798485011266
Validation loss: 2.152271370852279

Epoch: 5| Step: 2
Training loss: 0.46743508926118826
Validation loss: 2.159037676794461

Epoch: 5| Step: 3
Training loss: 0.7851632720481428
Validation loss: 2.215370434631308

Epoch: 5| Step: 4
Training loss: 0.32901135575196355
Validation loss: 2.2142130677645873

Epoch: 5| Step: 5
Training loss: 0.4124460517400209
Validation loss: 2.183835029057928

Epoch: 5| Step: 6
Training loss: 0.6072914744050216
Validation loss: 2.1758221082120195

Epoch: 5| Step: 7
Training loss: 0.5216627923021268
Validation loss: 2.2060103386813985

Epoch: 5| Step: 8
Training loss: 0.4751147652316287
Validation loss: 2.2616305104423535

Epoch: 5| Step: 9
Training loss: 0.359804415190729
Validation loss: 2.204203908527236

Epoch: 5| Step: 10
Training loss: 0.5219999186691133
Validation loss: 2.201483305743349

Epoch: 795| Step: 0
Training loss: 0.40382713635088013
Validation loss: 2.1454303525144187

Epoch: 5| Step: 1
Training loss: 0.4702684920496368
Validation loss: 2.097583852532101

Epoch: 5| Step: 2
Training loss: 0.6063472650114748
Validation loss: 2.0895957470711415

Epoch: 5| Step: 3
Training loss: 0.8071856193210434
Validation loss: 2.2603042239621307

Epoch: 5| Step: 4
Training loss: 0.290596128383248
Validation loss: 2.149850328663068

Epoch: 5| Step: 5
Training loss: 0.5376138433501946
Validation loss: 2.163911353279651

Epoch: 5| Step: 6
Training loss: 0.3831277444563825
Validation loss: 2.1251622246064783

Epoch: 5| Step: 7
Training loss: 0.36111784306185196
Validation loss: 2.2530814596568267

Epoch: 5| Step: 8
Training loss: 0.3084819204776413
Validation loss: 2.1333330941857054

Epoch: 5| Step: 9
Training loss: 0.42957113597708035
Validation loss: 2.1515546792442453

Epoch: 5| Step: 10
Training loss: 0.49586191542440305
Validation loss: 2.187803044108267

Epoch: 796| Step: 0
Training loss: 0.40645616142022456
Validation loss: 2.149383600316401

Epoch: 5| Step: 1
Training loss: 0.4961769154442335
Validation loss: 2.1543349836295627

Epoch: 5| Step: 2
Training loss: 0.7924731730785171
Validation loss: 2.1638191666517774

Epoch: 5| Step: 3
Training loss: 0.38592567425729674
Validation loss: 2.1152815317514153

Epoch: 5| Step: 4
Training loss: 0.5897870068066774
Validation loss: 2.097558784706856

Epoch: 5| Step: 5
Training loss: 0.5051746521042468
Validation loss: 2.1759226050499794

Epoch: 5| Step: 6
Training loss: 0.4752642818624709
Validation loss: 2.140419866584766

Epoch: 5| Step: 7
Training loss: 0.44038844285511974
Validation loss: 2.217334639623452

Epoch: 5| Step: 8
Training loss: 0.4494775441281534
Validation loss: 2.1079238937939615

Epoch: 5| Step: 9
Training loss: 0.3819233240684459
Validation loss: 2.1581350845616325

Epoch: 5| Step: 10
Training loss: 0.3079180986545768
Validation loss: 2.166503797385694

Epoch: 797| Step: 0
Training loss: 0.3375358372664327
Validation loss: 2.223301622372739

Epoch: 5| Step: 1
Training loss: 0.9093639215797381
Validation loss: 2.166713273546549

Epoch: 5| Step: 2
Training loss: 0.40586669885894866
Validation loss: 2.180508319698522

Epoch: 5| Step: 3
Training loss: 0.31776866053464864
Validation loss: 2.182011990035751

Epoch: 5| Step: 4
Training loss: 0.408239317389216
Validation loss: 2.1891513749827403

Epoch: 5| Step: 5
Training loss: 0.5380310196726199
Validation loss: 2.1878102212959845

Epoch: 5| Step: 6
Training loss: 0.45690776102150016
Validation loss: 2.224403202751118

Epoch: 5| Step: 7
Training loss: 0.427763689682668
Validation loss: 2.1619070200941

Epoch: 5| Step: 8
Training loss: 0.37705879509191814
Validation loss: 2.147540860977847

Epoch: 5| Step: 9
Training loss: 0.37996656970366366
Validation loss: 2.0957367051070457

Epoch: 5| Step: 10
Training loss: 0.37624050635340056
Validation loss: 2.1936920553353567

Epoch: 798| Step: 0
Training loss: 0.7735551301534683
Validation loss: 2.171540194449764

Epoch: 5| Step: 1
Training loss: 0.33189383636511416
Validation loss: 2.125603831938023

Epoch: 5| Step: 2
Training loss: 0.4686016324796338
Validation loss: 2.1681825558441474

Epoch: 5| Step: 3
Training loss: 0.3944795593543155
Validation loss: 2.1649579685112403

Epoch: 5| Step: 4
Training loss: 0.43194914273851337
Validation loss: 2.1686571040384015

Epoch: 5| Step: 5
Training loss: 0.3768476032148976
Validation loss: 2.092744751554772

Epoch: 5| Step: 6
Training loss: 0.4822985997398578
Validation loss: 2.104004787804262

Epoch: 5| Step: 7
Training loss: 0.5488873107057776
Validation loss: 2.1453809092962937

Epoch: 5| Step: 8
Training loss: 0.5684092653800555
Validation loss: 2.139263317891824

Epoch: 5| Step: 9
Training loss: 0.29405066037641453
Validation loss: 2.137676510505906

Epoch: 5| Step: 10
Training loss: 0.31024719269440687
Validation loss: 2.124221438357647

Epoch: 799| Step: 0
Training loss: 0.7824110177972757
Validation loss: 2.1733249480379815

Epoch: 5| Step: 1
Training loss: 0.5464738191753543
Validation loss: 2.198119836221466

Epoch: 5| Step: 2
Training loss: 0.2982440051589866
Validation loss: 2.162588735165054

Epoch: 5| Step: 3
Training loss: 0.4384062780790424
Validation loss: 2.1748823000855513

Epoch: 5| Step: 4
Training loss: 0.5994033459513043
Validation loss: 2.1980869717313256

Epoch: 5| Step: 5
Training loss: 0.4750552967159282
Validation loss: 2.1557409343354643

Epoch: 5| Step: 6
Training loss: 0.3879777854577076
Validation loss: 2.0992905058165223

Epoch: 5| Step: 7
Training loss: 0.34093903930204683
Validation loss: 2.2522121163435607

Epoch: 5| Step: 8
Training loss: 0.47745600565114277
Validation loss: 2.252786999922602

Epoch: 5| Step: 9
Training loss: 0.5510725779477694
Validation loss: 2.1286101008162928

Epoch: 5| Step: 10
Training loss: 0.40702675873663635
Validation loss: 2.152835024380056

Epoch: 800| Step: 0
Training loss: 0.2995623251964012
Validation loss: 2.220911741885967

Epoch: 5| Step: 1
Training loss: 0.8583698289636854
Validation loss: 2.1157447886088745

Epoch: 5| Step: 2
Training loss: 0.4004022736134224
Validation loss: 2.1739913987758066

Epoch: 5| Step: 3
Training loss: 0.43863134901811746
Validation loss: 2.141461317913471

Epoch: 5| Step: 4
Training loss: 0.5500486655812843
Validation loss: 2.1171682519094146

Epoch: 5| Step: 5
Training loss: 0.3526444634194812
Validation loss: 2.212146185872258

Epoch: 5| Step: 6
Training loss: 0.37195763671548815
Validation loss: 2.1776830685475854

Epoch: 5| Step: 7
Training loss: 0.3080985163706797
Validation loss: 2.208308831758298

Epoch: 5| Step: 8
Training loss: 0.5658676743889559
Validation loss: 2.161949563473281

Epoch: 5| Step: 9
Training loss: 0.4273453776940515
Validation loss: 2.1842746119632728

Epoch: 5| Step: 10
Training loss: 0.3419741143767393
Validation loss: 2.1963859196090736

Testing loss: 2.676797037611568
