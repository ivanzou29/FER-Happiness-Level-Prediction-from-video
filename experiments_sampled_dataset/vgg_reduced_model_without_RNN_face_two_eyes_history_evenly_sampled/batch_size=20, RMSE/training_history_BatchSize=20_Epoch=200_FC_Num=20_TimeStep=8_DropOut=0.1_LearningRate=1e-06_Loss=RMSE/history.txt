Epoch: 1| Step: 0
Training loss: 8.891697180378928
Validation loss: 8.73967647936747

Epoch: 5| Step: 1
Training loss: 8.687909233279496
Validation loss: 8.738001154049078

Epoch: 5| Step: 2
Training loss: 8.333384958743084
Validation loss: 8.731345923149782

Epoch: 5| Step: 3
Training loss: 8.97129992877896
Validation loss: 8.725468462570824

Epoch: 5| Step: 4
Training loss: 8.848663798177869
Validation loss: 8.715717681209732

Epoch: 5| Step: 5
Training loss: 9.097755624859792
Validation loss: 8.711438956225662

Epoch: 5| Step: 6
Training loss: 8.378037542379685
Validation loss: 8.70685107375133

Epoch: 5| Step: 7
Training loss: 8.657956612707153
Validation loss: 8.697586088853775

Epoch: 5| Step: 8
Training loss: 8.167910837910432
Validation loss: 8.695932130787785

Epoch: 5| Step: 9
Training loss: 9.085593639371352
Validation loss: 8.690944033521655

Epoch: 5| Step: 10
Training loss: 7.99927255184136
Validation loss: 8.682072724579072

Epoch: 2| Step: 0
Training loss: 9.010075333732301
Validation loss: 8.680201530954237

Epoch: 5| Step: 1
Training loss: 9.813119662211545
Validation loss: 8.671913852399523

Epoch: 5| Step: 2
Training loss: 8.608796309668802
Validation loss: 8.66611286631009

Epoch: 5| Step: 3
Training loss: 8.035631936271992
Validation loss: 8.661529952924571

Epoch: 5| Step: 4
Training loss: 8.1079683645767
Validation loss: 8.655121118361052

Epoch: 5| Step: 5
Training loss: 8.39250789947638
Validation loss: 8.64933756090679

Epoch: 5| Step: 6
Training loss: 8.913896457152065
Validation loss: 8.644394820851769

Epoch: 5| Step: 7
Training loss: 8.805098651807736
Validation loss: 8.638492587756158

Epoch: 5| Step: 8
Training loss: 8.81958848196507
Validation loss: 8.632364584827211

Epoch: 5| Step: 9
Training loss: 7.453470474009647
Validation loss: 8.629489490569172

Epoch: 5| Step: 10
Training loss: 8.381345707676186
Validation loss: 8.621243041905071

Epoch: 3| Step: 0
Training loss: 9.326326692105049
Validation loss: 8.617881496979305

Epoch: 5| Step: 1
Training loss: 8.866552926770508
Validation loss: 8.609886039772539

Epoch: 5| Step: 2
Training loss: 10.015639473224722
Validation loss: 8.60363957017823

Epoch: 5| Step: 3
Training loss: 7.515193807878191
Validation loss: 8.597885534674802

Epoch: 5| Step: 4
Training loss: 8.413542920064854
Validation loss: 8.590978745613356

Epoch: 5| Step: 5
Training loss: 7.802532704293043
Validation loss: 8.586665049179333

Epoch: 5| Step: 6
Training loss: 7.7505867028426465
Validation loss: 8.58044719907169

Epoch: 5| Step: 7
Training loss: 8.808818941134806
Validation loss: 8.575542760991695

Epoch: 5| Step: 8
Training loss: 8.079558077520536
Validation loss: 8.568385544061348

Epoch: 5| Step: 9
Training loss: 8.742455417867365
Validation loss: 8.565274544681486

Epoch: 5| Step: 10
Training loss: 8.2091007809823
Validation loss: 8.55825446517136

Epoch: 4| Step: 0
Training loss: 9.20448280253211
Validation loss: 8.5538334027041

Epoch: 5| Step: 1
Training loss: 7.712577792228217
Validation loss: 8.546935988146352

Epoch: 5| Step: 2
Training loss: 8.827273707572369
Validation loss: 8.540440148134032

Epoch: 5| Step: 3
Training loss: 8.250044851470175
Validation loss: 8.532283051649962

Epoch: 5| Step: 4
Training loss: 9.126355214272031
Validation loss: 8.525925300529643

Epoch: 5| Step: 5
Training loss: 8.04815770268119
Validation loss: 8.520881382116512

Epoch: 5| Step: 6
Training loss: 8.220567393524876
Validation loss: 8.515581518436452

Epoch: 5| Step: 7
Training loss: 9.265938713333789
Validation loss: 8.510633092469346

Epoch: 5| Step: 8
Training loss: 7.718523153454303
Validation loss: 8.503091760156085

Epoch: 5| Step: 9
Training loss: 8.579341169907394
Validation loss: 8.496036384755662

Epoch: 5| Step: 10
Training loss: 7.963925086488642
Validation loss: 8.488877887557994

Epoch: 5| Step: 0
Training loss: 8.74827645901854
Validation loss: 8.485264474392936

Epoch: 5| Step: 1
Training loss: 8.84169440760981
Validation loss: 8.475857885298385

Epoch: 5| Step: 2
Training loss: 8.945529985074511
Validation loss: 8.473712627276068

Epoch: 5| Step: 3
Training loss: 7.618225590320854
Validation loss: 8.464995773362153

Epoch: 5| Step: 4
Training loss: 9.377812485030532
Validation loss: 8.457591142820268

Epoch: 5| Step: 5
Training loss: 8.760086349688793
Validation loss: 8.452990838777936

Epoch: 5| Step: 6
Training loss: 7.9589711943909265
Validation loss: 8.446461099247141

Epoch: 5| Step: 7
Training loss: 8.691156070837541
Validation loss: 8.439039928871498

Epoch: 5| Step: 8
Training loss: 7.589993524963271
Validation loss: 8.431815038458724

Epoch: 5| Step: 9
Training loss: 7.417277050261236
Validation loss: 8.423888862148406

Epoch: 5| Step: 10
Training loss: 8.157443956702263
Validation loss: 8.419313841968927

Epoch: 6| Step: 0
Training loss: 8.444408160126125
Validation loss: 8.412086469509367

Epoch: 5| Step: 1
Training loss: 8.909010502836352
Validation loss: 8.404340397891229

Epoch: 5| Step: 2
Training loss: 7.693443667823318
Validation loss: 8.399844569864555

Epoch: 5| Step: 3
Training loss: 8.114150565036974
Validation loss: 8.391485258166586

Epoch: 5| Step: 4
Training loss: 9.202124756632085
Validation loss: 8.38579021323222

Epoch: 5| Step: 5
Training loss: 8.623187330750211
Validation loss: 8.37766192342793

Epoch: 5| Step: 6
Training loss: 7.648545729092527
Validation loss: 8.369607579432033

Epoch: 5| Step: 7
Training loss: 7.366723022705667
Validation loss: 8.362858181396811

Epoch: 5| Step: 8
Training loss: 7.771575674099298
Validation loss: 8.356007722932523

Epoch: 5| Step: 9
Training loss: 9.089502974918634
Validation loss: 8.34798344492159

Epoch: 5| Step: 10
Training loss: 8.499528310815116
Validation loss: 8.34281097765611

Epoch: 7| Step: 0
Training loss: 8.531778954956021
Validation loss: 8.335688683502207

Epoch: 5| Step: 1
Training loss: 8.106714889148705
Validation loss: 8.328574256082259

Epoch: 5| Step: 2
Training loss: 9.050622773213334
Validation loss: 8.320438684583817

Epoch: 5| Step: 3
Training loss: 9.458465127124757
Validation loss: 8.31250818144064

Epoch: 5| Step: 4
Training loss: 8.109052295180772
Validation loss: 8.303798861484442

Epoch: 5| Step: 5
Training loss: 6.768779767958117
Validation loss: 8.297978911058346

Epoch: 5| Step: 6
Training loss: 6.801643049664458
Validation loss: 8.29347047701426

Epoch: 5| Step: 7
Training loss: 7.922267445130085
Validation loss: 8.28447500017598

Epoch: 5| Step: 8
Training loss: 8.694444254860624
Validation loss: 8.277430093914772

Epoch: 5| Step: 9
Training loss: 8.402019584925327
Validation loss: 8.268893060299325

Epoch: 5| Step: 10
Training loss: 8.498633330933412
Validation loss: 8.260951835182487

Epoch: 8| Step: 0
Training loss: 8.072435511534955
Validation loss: 8.253346673923296

Epoch: 5| Step: 1
Training loss: 9.278880218163577
Validation loss: 8.244951938000606

Epoch: 5| Step: 2
Training loss: 6.917240563295312
Validation loss: 8.236493213233038

Epoch: 5| Step: 3
Training loss: 8.905447297982759
Validation loss: 8.229642953066032

Epoch: 5| Step: 4
Training loss: 7.283811978020324
Validation loss: 8.220524970898058

Epoch: 5| Step: 5
Training loss: 7.892748012663666
Validation loss: 8.215321129735264

Epoch: 5| Step: 6
Training loss: 8.708858881762922
Validation loss: 8.206855730464484

Epoch: 5| Step: 7
Training loss: 8.415193132891673
Validation loss: 8.198475609926223

Epoch: 5| Step: 8
Training loss: 8.017199147940282
Validation loss: 8.189470487528524

Epoch: 5| Step: 9
Training loss: 8.085176500270563
Validation loss: 8.180440314399446

Epoch: 5| Step: 10
Training loss: 7.891850200749153
Validation loss: 8.174406090661279

Epoch: 9| Step: 0
Training loss: 8.903905084671328
Validation loss: 8.16422708507073

Epoch: 5| Step: 1
Training loss: 8.449400696578879
Validation loss: 8.15998035556424

Epoch: 5| Step: 2
Training loss: 8.420495198020292
Validation loss: 8.14874480498052

Epoch: 5| Step: 3
Training loss: 7.141906489734059
Validation loss: 8.135659948205646

Epoch: 5| Step: 4
Training loss: 7.074671426968219
Validation loss: 8.130087648704887

Epoch: 5| Step: 5
Training loss: 7.897898005654089
Validation loss: 8.124013099020724

Epoch: 5| Step: 6
Training loss: 8.319812283232276
Validation loss: 8.110915923325514

Epoch: 5| Step: 7
Training loss: 7.481545186095051
Validation loss: 8.104533827574569

Epoch: 5| Step: 8
Training loss: 7.905593060728949
Validation loss: 8.093955667644414

Epoch: 5| Step: 9
Training loss: 7.808468442200544
Validation loss: 8.085926963811573

Epoch: 5| Step: 10
Training loss: 9.278270512920901
Validation loss: 8.080205601696141

Epoch: 10| Step: 0
Training loss: 7.318508711696912
Validation loss: 8.066793494302562

Epoch: 5| Step: 1
Training loss: 8.509175453269915
Validation loss: 8.058847752316415

Epoch: 5| Step: 2
Training loss: 9.186814885966923
Validation loss: 8.05003522700762

Epoch: 5| Step: 3
Training loss: 7.433387452799531
Validation loss: 8.039758108813617

Epoch: 5| Step: 4
Training loss: 7.157655003315288
Validation loss: 8.0316652765423

Epoch: 5| Step: 5
Training loss: 7.827641576889555
Validation loss: 8.02180882054024

Epoch: 5| Step: 6
Training loss: 8.079848439523111
Validation loss: 8.013425485470357

Epoch: 5| Step: 7
Training loss: 8.625927861379699
Validation loss: 8.003018194413926

Epoch: 5| Step: 8
Training loss: 8.331267545871903
Validation loss: 7.991231240099498

Epoch: 5| Step: 9
Training loss: 6.552365570377701
Validation loss: 7.981677420486958

Epoch: 5| Step: 10
Training loss: 8.31596359716157
Validation loss: 7.97193211834708

Epoch: 11| Step: 0
Training loss: 8.245313758409038
Validation loss: 7.962083575132061

Epoch: 5| Step: 1
Training loss: 8.41445783077778
Validation loss: 7.9523388290528265

Epoch: 5| Step: 2
Training loss: 6.36725729687588
Validation loss: 7.939717683280667

Epoch: 5| Step: 3
Training loss: 8.122099373313556
Validation loss: 7.932091678226034

Epoch: 5| Step: 4
Training loss: 8.03357422442439
Validation loss: 7.92156013409455

Epoch: 5| Step: 5
Training loss: 8.829778951813609
Validation loss: 7.9128574328125065

Epoch: 5| Step: 6
Training loss: 7.180995751404498
Validation loss: 7.897984041790627

Epoch: 5| Step: 7
Training loss: 7.879007440010835
Validation loss: 7.887682183723861

Epoch: 5| Step: 8
Training loss: 6.867041402918329
Validation loss: 7.876925127497608

Epoch: 5| Step: 9
Training loss: 8.167715148053713
Validation loss: 7.867984681685655

Epoch: 5| Step: 10
Training loss: 8.004098319285262
Validation loss: 7.8553335559476

Epoch: 12| Step: 0
Training loss: 6.7741746688321856
Validation loss: 7.845585209173767

Epoch: 5| Step: 1
Training loss: 8.856321208831798
Validation loss: 7.82737634855002

Epoch: 5| Step: 2
Training loss: 7.679284148232625
Validation loss: 7.820237159150957

Epoch: 5| Step: 3
Training loss: 7.694377025151275
Validation loss: 7.80761067497917

Epoch: 5| Step: 4
Training loss: 7.843422689105852
Validation loss: 7.798944659761919

Epoch: 5| Step: 5
Training loss: 6.729437697614431
Validation loss: 7.784248594973565

Epoch: 5| Step: 6
Training loss: 8.615778762059632
Validation loss: 7.767577229921291

Epoch: 5| Step: 7
Training loss: 7.351629696740583
Validation loss: 7.763149587025539

Epoch: 5| Step: 8
Training loss: 6.544669205339886
Validation loss: 7.746236881892597

Epoch: 5| Step: 9
Training loss: 8.413597327844801
Validation loss: 7.7355442357002

Epoch: 5| Step: 10
Training loss: 8.224597547708784
Validation loss: 7.721634807521166

Epoch: 13| Step: 0
Training loss: 7.680588259022786
Validation loss: 7.707577132559397

Epoch: 5| Step: 1
Training loss: 7.218082545746276
Validation loss: 7.694717267439264

Epoch: 5| Step: 2
Training loss: 6.987820247074185
Validation loss: 7.679171339371718

Epoch: 5| Step: 3
Training loss: 7.267588360396582
Validation loss: 7.667355762809908

Epoch: 5| Step: 4
Training loss: 8.013398870791491
Validation loss: 7.658181995079899

Epoch: 5| Step: 5
Training loss: 8.433309234866163
Validation loss: 7.637484814827293

Epoch: 5| Step: 6
Training loss: 7.890092707138877
Validation loss: 7.623496658004226

Epoch: 5| Step: 7
Training loss: 7.88090560124299
Validation loss: 7.614973728185057

Epoch: 5| Step: 8
Training loss: 6.889985277578185
Validation loss: 7.598432250525885

Epoch: 5| Step: 9
Training loss: 7.782616185130717
Validation loss: 7.577861607174029

Epoch: 5| Step: 10
Training loss: 7.163976504476369
Validation loss: 7.56422574800676

Epoch: 14| Step: 0
Training loss: 8.65400000019748
Validation loss: 7.552463978533506

Epoch: 5| Step: 1
Training loss: 8.423046250014469
Validation loss: 7.532830890529157

Epoch: 5| Step: 2
Training loss: 7.861133052703946
Validation loss: 7.515670915740146

Epoch: 5| Step: 3
Training loss: 8.219492599531312
Validation loss: 7.499534663596029

Epoch: 5| Step: 4
Training loss: 6.980377213743006
Validation loss: 7.484549171568314

Epoch: 5| Step: 5
Training loss: 7.440445517049869
Validation loss: 7.4650954486788015

Epoch: 5| Step: 6
Training loss: 5.897345071643931
Validation loss: 7.450045567337576

Epoch: 5| Step: 7
Training loss: 7.171909839154895
Validation loss: 7.429979807121923

Epoch: 5| Step: 8
Training loss: 7.0850841677127745
Validation loss: 7.411251200439777

Epoch: 5| Step: 9
Training loss: 6.413279774865831
Validation loss: 7.399914828660905

Epoch: 5| Step: 10
Training loss: 6.888431537308725
Validation loss: 7.3796327201050955

Epoch: 15| Step: 0
Training loss: 6.070082180214741
Validation loss: 7.367123983466032

Epoch: 5| Step: 1
Training loss: 7.829940737601128
Validation loss: 7.346573713417426

Epoch: 5| Step: 2
Training loss: 7.114448363632898
Validation loss: 7.334142962795954

Epoch: 5| Step: 3
Training loss: 7.444185986310343
Validation loss: 7.313549307580408

Epoch: 5| Step: 4
Training loss: 7.278183975079062
Validation loss: 7.293911111777368

Epoch: 5| Step: 5
Training loss: 7.967532794215804
Validation loss: 7.2771325442072285

Epoch: 5| Step: 6
Training loss: 7.185504138650433
Validation loss: 7.259008392980226

Epoch: 5| Step: 7
Training loss: 6.949994906416749
Validation loss: 7.241495328774934

Epoch: 5| Step: 8
Training loss: 6.993054622821394
Validation loss: 7.225351855576885

Epoch: 5| Step: 9
Training loss: 7.862404574981091
Validation loss: 7.210164168792627

Epoch: 5| Step: 10
Training loss: 6.350793996116038
Validation loss: 7.18662893073783

Epoch: 16| Step: 0
Training loss: 6.5391278371885155
Validation loss: 7.1708899910535955

Epoch: 5| Step: 1
Training loss: 7.364388282995054
Validation loss: 7.145207262651702

Epoch: 5| Step: 2
Training loss: 6.824467777278697
Validation loss: 7.12789199417416

Epoch: 5| Step: 3
Training loss: 7.144263744821184
Validation loss: 7.105871299957468

Epoch: 5| Step: 4
Training loss: 7.676380582517796
Validation loss: 7.087896843223842

Epoch: 5| Step: 5
Training loss: 6.193169048636589
Validation loss: 7.063236623222361

Epoch: 5| Step: 6
Training loss: 7.838425246141949
Validation loss: 7.053710163360699

Epoch: 5| Step: 7
Training loss: 6.828719124162963
Validation loss: 7.027925170747537

Epoch: 5| Step: 8
Training loss: 7.070880879692071
Validation loss: 7.012863572016076

Epoch: 5| Step: 9
Training loss: 6.772789806475269
Validation loss: 6.9845425389145275

Epoch: 5| Step: 10
Training loss: 6.648115605272987
Validation loss: 6.9647551150477645

Epoch: 17| Step: 0
Training loss: 6.9748606896930205
Validation loss: 6.946044859639021

Epoch: 5| Step: 1
Training loss: 6.948715354694449
Validation loss: 6.925867298119777

Epoch: 5| Step: 2
Training loss: 6.220092015214435
Validation loss: 6.899940365389015

Epoch: 5| Step: 3
Training loss: 6.678696872357795
Validation loss: 6.877505033803145

Epoch: 5| Step: 4
Training loss: 8.022761865266682
Validation loss: 6.85551652340387

Epoch: 5| Step: 5
Training loss: 7.0883327418773385
Validation loss: 6.838343011739666

Epoch: 5| Step: 6
Training loss: 6.649072636928577
Validation loss: 6.809394913779785

Epoch: 5| Step: 7
Training loss: 6.926978578468574
Validation loss: 6.789918737143149

Epoch: 5| Step: 8
Training loss: 6.829802492561725
Validation loss: 6.764316697112724

Epoch: 5| Step: 9
Training loss: 5.995078929798316
Validation loss: 6.741430335303049

Epoch: 5| Step: 10
Training loss: 5.874875655786024
Validation loss: 6.720453731700434

Epoch: 18| Step: 0
Training loss: 6.785123079402224
Validation loss: 6.703022226026246

Epoch: 5| Step: 1
Training loss: 7.276534620628495
Validation loss: 6.676583388023094

Epoch: 5| Step: 2
Training loss: 5.791620304644791
Validation loss: 6.66004305733637

Epoch: 5| Step: 3
Training loss: 5.350119024360963
Validation loss: 6.630567154498428

Epoch: 5| Step: 4
Training loss: 5.735906162659561
Validation loss: 6.6054779342005645

Epoch: 5| Step: 5
Training loss: 7.415000928491597
Validation loss: 6.585746165135555

Epoch: 5| Step: 6
Training loss: 5.670560994593763
Validation loss: 6.551962296945278

Epoch: 5| Step: 7
Training loss: 5.9365384578122615
Validation loss: 6.532875982419841

Epoch: 5| Step: 8
Training loss: 6.460518875305883
Validation loss: 6.511501847982959

Epoch: 5| Step: 9
Training loss: 7.474215116088277
Validation loss: 6.4842272677780315

Epoch: 5| Step: 10
Training loss: 7.475659609879465
Validation loss: 6.4547902984983985

Epoch: 19| Step: 0
Training loss: 5.945300950629386
Validation loss: 6.443936427772553

Epoch: 5| Step: 1
Training loss: 6.699222735968202
Validation loss: 6.407956461674761

Epoch: 5| Step: 2
Training loss: 6.564635882888124
Validation loss: 6.386501305317954

Epoch: 5| Step: 3
Training loss: 6.196992624679493
Validation loss: 6.353213367602486

Epoch: 5| Step: 4
Training loss: 5.792605902535563
Validation loss: 6.335668086000324

Epoch: 5| Step: 5
Training loss: 6.930974967597621
Validation loss: 6.3098723389568185

Epoch: 5| Step: 6
Training loss: 6.153590523472163
Validation loss: 6.27675145670992

Epoch: 5| Step: 7
Training loss: 6.2250153690745895
Validation loss: 6.256879643710967

Epoch: 5| Step: 8
Training loss: 6.042031253030529
Validation loss: 6.22393459858391

Epoch: 5| Step: 9
Training loss: 6.588070995622267
Validation loss: 6.196225809074574

Epoch: 5| Step: 10
Training loss: 5.364170609186744
Validation loss: 6.175832198970891

Epoch: 20| Step: 0
Training loss: 6.246669950263844
Validation loss: 6.151068276165636

Epoch: 5| Step: 1
Training loss: 5.76094870383878
Validation loss: 6.119244635400913

Epoch: 5| Step: 2
Training loss: 5.547200110135711
Validation loss: 6.096003253128992

Epoch: 5| Step: 3
Training loss: 6.439802035967501
Validation loss: 6.059285353437061

Epoch: 5| Step: 4
Training loss: 5.626908550728085
Validation loss: 6.039481018105525

Epoch: 5| Step: 5
Training loss: 6.4225589731374
Validation loss: 6.007729774207553

Epoch: 5| Step: 6
Training loss: 5.378250558596626
Validation loss: 5.974067287111488

Epoch: 5| Step: 7
Training loss: 5.8576830239383515
Validation loss: 5.954057292280552

Epoch: 5| Step: 8
Training loss: 6.52826794166073
Validation loss: 5.918051578236261

Epoch: 5| Step: 9
Training loss: 5.764460086734293
Validation loss: 5.895916553122908

Epoch: 5| Step: 10
Training loss: 5.70997822398294
Validation loss: 5.863886161742643

Epoch: 21| Step: 0
Training loss: 5.720855825462867
Validation loss: 5.822614322467584

Epoch: 5| Step: 1
Training loss: 5.522309399860541
Validation loss: 5.801565165891793

Epoch: 5| Step: 2
Training loss: 5.756345150437628
Validation loss: 5.766801819553307

Epoch: 5| Step: 3
Training loss: 5.35844070698769
Validation loss: 5.736134410787229

Epoch: 5| Step: 4
Training loss: 5.98365942757972
Validation loss: 5.711411705601115

Epoch: 5| Step: 5
Training loss: 5.592868501052779
Validation loss: 5.684188886828865

Epoch: 5| Step: 6
Training loss: 5.4793546037630465
Validation loss: 5.644306073312038

Epoch: 5| Step: 7
Training loss: 5.587403687878072
Validation loss: 5.622668411332077

Epoch: 5| Step: 8
Training loss: 5.31004312587546
Validation loss: 5.585812081649253

Epoch: 5| Step: 9
Training loss: 5.558281145132017
Validation loss: 5.55057237802279

Epoch: 5| Step: 10
Training loss: 6.162825272895401
Validation loss: 5.534522772010415

Epoch: 22| Step: 0
Training loss: 5.54079875985555
Validation loss: 5.507475042001668

Epoch: 5| Step: 1
Training loss: 5.529192180713621
Validation loss: 5.46181385648181

Epoch: 5| Step: 2
Training loss: 5.38023901823242
Validation loss: 5.4283543723447245

Epoch: 5| Step: 3
Training loss: 5.239822513690286
Validation loss: 5.389913635256027

Epoch: 5| Step: 4
Training loss: 5.823966908015043
Validation loss: 5.369092281200917

Epoch: 5| Step: 5
Training loss: 4.9106332430406825
Validation loss: 5.324019682272832

Epoch: 5| Step: 6
Training loss: 5.278203864493702
Validation loss: 5.30374452078956

Epoch: 5| Step: 7
Training loss: 5.902199622868037
Validation loss: 5.265002071934636

Epoch: 5| Step: 8
Training loss: 4.339685088655762
Validation loss: 5.2295923272639415

Epoch: 5| Step: 9
Training loss: 5.381157298070476
Validation loss: 5.19384434597551

Epoch: 5| Step: 10
Training loss: 4.6346127388000244
Validation loss: 5.170052697357886

Epoch: 23| Step: 0
Training loss: 4.988884204578159
Validation loss: 5.137550988605608

Epoch: 5| Step: 1
Training loss: 4.0745057163139915
Validation loss: 5.102024621204073

Epoch: 5| Step: 2
Training loss: 5.652097579351297
Validation loss: 5.073953162541956

Epoch: 5| Step: 3
Training loss: 4.912905121616821
Validation loss: 5.030690920250402

Epoch: 5| Step: 4
Training loss: 5.042873626922874
Validation loss: 5.01401235396824

Epoch: 5| Step: 5
Training loss: 4.684695816505964
Validation loss: 4.974663559120887

Epoch: 5| Step: 6
Training loss: 4.862231037771946
Validation loss: 4.938123031027245

Epoch: 5| Step: 7
Training loss: 4.717646994107416
Validation loss: 4.887836272286139

Epoch: 5| Step: 8
Training loss: 5.752591419910995
Validation loss: 4.876484928990791

Epoch: 5| Step: 9
Training loss: 4.687990900401895
Validation loss: 4.839194207218213

Epoch: 5| Step: 10
Training loss: 4.624534995957216
Validation loss: 4.7797835286938275

Epoch: 24| Step: 0
Training loss: 4.569001464603062
Validation loss: 4.7641383743280485

Epoch: 5| Step: 1
Training loss: 4.723947857975166
Validation loss: 4.745353161491357

Epoch: 5| Step: 2
Training loss: 3.0741790419926036
Validation loss: 4.702323644981981

Epoch: 5| Step: 3
Training loss: 4.90540709817525
Validation loss: 4.661097516424203

Epoch: 5| Step: 4
Training loss: 4.7467355050942395
Validation loss: 4.61864732903528

Epoch: 5| Step: 5
Training loss: 4.556960413928492
Validation loss: 4.592831876281882

Epoch: 5| Step: 6
Training loss: 5.00420012493314
Validation loss: 4.55408180689979

Epoch: 5| Step: 7
Training loss: 4.725172509975
Validation loss: 4.518039114123137

Epoch: 5| Step: 8
Training loss: 4.450700494731007
Validation loss: 4.474021447703113

Epoch: 5| Step: 9
Training loss: 4.1660982634355355
Validation loss: 4.4537312343783295

Epoch: 5| Step: 10
Training loss: 4.994256344596948
Validation loss: 4.41937546754793

Epoch: 25| Step: 0
Training loss: 3.909051973580464
Validation loss: 4.38567426930072

Epoch: 5| Step: 1
Training loss: 4.1295425372276355
Validation loss: 4.335445078025194

Epoch: 5| Step: 2
Training loss: 3.8395679332129706
Validation loss: 4.311160744729959

Epoch: 5| Step: 3
Training loss: 4.107637103178801
Validation loss: 4.26211485524823

Epoch: 5| Step: 4
Training loss: 4.5220074278995295
Validation loss: 4.211588649611431

Epoch: 5| Step: 5
Training loss: 4.228892250115382
Validation loss: 4.19514992464367

Epoch: 5| Step: 6
Training loss: 4.467191411030336
Validation loss: 4.1382763836483125

Epoch: 5| Step: 7
Training loss: 3.5531243880379586
Validation loss: 4.107088975725546

Epoch: 5| Step: 8
Training loss: 4.805225968619693
Validation loss: 4.073061864487899

Epoch: 5| Step: 9
Training loss: 4.665582508218155
Validation loss: 4.035641188248819

Epoch: 5| Step: 10
Training loss: 3.3301756366313455
Validation loss: 4.009519069005508

Epoch: 26| Step: 0
Training loss: 4.422324868762249
Validation loss: 3.965451555245686

Epoch: 5| Step: 1
Training loss: 3.938103281459786
Validation loss: 3.9428724120230036

Epoch: 5| Step: 2
Training loss: 4.247369737698933
Validation loss: 3.8957112751470966

Epoch: 5| Step: 3
Training loss: 4.30105354354868
Validation loss: 3.8548198081124774

Epoch: 5| Step: 4
Training loss: 3.173916615352927
Validation loss: 3.8312488540047887

Epoch: 5| Step: 5
Training loss: 3.6216145195493197
Validation loss: 3.802582067710894

Epoch: 5| Step: 6
Training loss: 4.144224509663903
Validation loss: 3.754572810032837

Epoch: 5| Step: 7
Training loss: 3.775869782142167
Validation loss: 3.7169360504425133

Epoch: 5| Step: 8
Training loss: 3.116515887960019
Validation loss: 3.6928876809008653

Epoch: 5| Step: 9
Training loss: 3.359797677351905
Validation loss: 3.6760898784090608

Epoch: 5| Step: 10
Training loss: 3.533499347337463
Validation loss: 3.645571498111784

Epoch: 27| Step: 0
Training loss: 3.6020843723546405
Validation loss: 3.6065177686839665

Epoch: 5| Step: 1
Training loss: 3.991063626051018
Validation loss: 3.586991154272236

Epoch: 5| Step: 2
Training loss: 4.3684252791544536
Validation loss: 3.5526962773877333

Epoch: 5| Step: 3
Training loss: 2.9790512453853215
Validation loss: 3.528724488205622

Epoch: 5| Step: 4
Training loss: 3.32034481257255
Validation loss: 3.509792682971324

Epoch: 5| Step: 5
Training loss: 3.9043002946770917
Validation loss: 3.4797187049387057

Epoch: 5| Step: 6
Training loss: 3.8121193867788525
Validation loss: 3.4608669486313506

Epoch: 5| Step: 7
Training loss: 3.5373292430197885
Validation loss: 3.4385462752509963

Epoch: 5| Step: 8
Training loss: 3.147921763697263
Validation loss: 3.417881580559673

Epoch: 5| Step: 9
Training loss: 2.898087719481515
Validation loss: 3.3888901684675306

Epoch: 5| Step: 10
Training loss: 2.688051388975923
Validation loss: 3.3559669112326826

Epoch: 28| Step: 0
Training loss: 3.2546869374099368
Validation loss: 3.359456966818643

Epoch: 5| Step: 1
Training loss: 3.5812580101895586
Validation loss: 3.336083447234298

Epoch: 5| Step: 2
Training loss: 3.433943694837818
Validation loss: 3.3237838752757707

Epoch: 5| Step: 3
Training loss: 4.359702258661672
Validation loss: 3.2993970612882086

Epoch: 5| Step: 4
Training loss: 2.962702967133216
Validation loss: 3.2906343926906483

Epoch: 5| Step: 5
Training loss: 3.310773579534893
Validation loss: 3.274674775226775

Epoch: 5| Step: 6
Training loss: 2.580137080313844
Validation loss: 3.2585380987322545

Epoch: 5| Step: 7
Training loss: 3.255885736808395
Validation loss: 3.2335054658343747

Epoch: 5| Step: 8
Training loss: 4.208978030737678
Validation loss: 3.2372192801155246

Epoch: 5| Step: 9
Training loss: 2.453905892455601
Validation loss: 3.207979741859214

Epoch: 5| Step: 10
Training loss: 2.8019483361229205
Validation loss: 3.2060829860945432

Epoch: 29| Step: 0
Training loss: 3.3954566949524425
Validation loss: 3.1951482462687784

Epoch: 5| Step: 1
Training loss: 3.3025924498723143
Validation loss: 3.2056349609897903

Epoch: 5| Step: 2
Training loss: 3.352054301994236
Validation loss: 3.17300816699607

Epoch: 5| Step: 3
Training loss: 2.7288040522046226
Validation loss: 3.176481827807994

Epoch: 5| Step: 4
Training loss: 2.916672588524029
Validation loss: 3.1593203576680047

Epoch: 5| Step: 5
Training loss: 2.815164448354102
Validation loss: 3.1446961690021373

Epoch: 5| Step: 6
Training loss: 3.366737140887313
Validation loss: 3.1428021683324316

Epoch: 5| Step: 7
Training loss: 3.7423880569136965
Validation loss: 3.1547203585068693

Epoch: 5| Step: 8
Training loss: 3.614716775649797
Validation loss: 3.117848192666137

Epoch: 5| Step: 9
Training loss: 3.469559583610524
Validation loss: 3.132531713914379

Epoch: 5| Step: 10
Training loss: 2.801591444743594
Validation loss: 3.119393130627309

Epoch: 30| Step: 0
Training loss: 2.9473020274528756
Validation loss: 3.128166109244625

Epoch: 5| Step: 1
Training loss: 4.168429319752755
Validation loss: 3.124087945065367

Epoch: 5| Step: 2
Training loss: 3.7960623668214213
Validation loss: 3.117685597348291

Epoch: 5| Step: 3
Training loss: 3.4473784949652435
Validation loss: 3.0945685969152317

Epoch: 5| Step: 4
Training loss: 2.6320613163006126
Validation loss: 3.1029305431456926

Epoch: 5| Step: 5
Training loss: 2.9670623801127722
Validation loss: 3.0929010029483015

Epoch: 5| Step: 6
Training loss: 2.6987457965148445
Validation loss: 3.1034794572762956

Epoch: 5| Step: 7
Training loss: 2.6472864040703605
Validation loss: 3.0912004540934626

Epoch: 5| Step: 8
Training loss: 3.1445148728222594
Validation loss: 3.0976275062631786

Epoch: 5| Step: 9
Training loss: 3.1596258258205028
Validation loss: 3.0843635762424064

Epoch: 5| Step: 10
Training loss: 3.0590773160004563
Validation loss: 3.0821331274600445

Epoch: 31| Step: 0
Training loss: 3.4422622984223814
Validation loss: 3.080190309353776

Epoch: 5| Step: 1
Training loss: 3.623036214396378
Validation loss: 3.0661618530035772

Epoch: 5| Step: 2
Training loss: 3.4857202507521894
Validation loss: 3.077585537335847

Epoch: 5| Step: 3
Training loss: 3.562468946890428
Validation loss: 3.0850621099324824

Epoch: 5| Step: 4
Training loss: 2.713334488723971
Validation loss: 3.070321114446683

Epoch: 5| Step: 5
Training loss: 2.0327327305054674
Validation loss: 3.0741147622341938

Epoch: 5| Step: 6
Training loss: 2.734621745284476
Validation loss: 3.0789636302691243

Epoch: 5| Step: 7
Training loss: 3.0716288998690486
Validation loss: 3.076571167141969

Epoch: 5| Step: 8
Training loss: 3.2738472402142254
Validation loss: 3.0730503949321704

Epoch: 5| Step: 9
Training loss: 3.4625042195759206
Validation loss: 3.059820181758631

Epoch: 5| Step: 10
Training loss: 3.09963937323031
Validation loss: 3.051781739657544

Epoch: 32| Step: 0
Training loss: 2.7504759289982044
Validation loss: 3.094506521030613

Epoch: 5| Step: 1
Training loss: 3.9966038353196454
Validation loss: 3.078282850836391

Epoch: 5| Step: 2
Training loss: 3.434452995268531
Validation loss: 3.0667753682080745

Epoch: 5| Step: 3
Training loss: 3.202826360411424
Validation loss: 3.0464458170664797

Epoch: 5| Step: 4
Training loss: 3.5108952559207567
Validation loss: 3.047421110532028

Epoch: 5| Step: 5
Training loss: 2.8056559896170405
Validation loss: 3.03916345762832

Epoch: 5| Step: 6
Training loss: 3.031221841897647
Validation loss: 3.0599367599874667

Epoch: 5| Step: 7
Training loss: 3.043569013474594
Validation loss: 3.0761165592958166

Epoch: 5| Step: 8
Training loss: 3.2232644726703406
Validation loss: 3.060799572588658

Epoch: 5| Step: 9
Training loss: 2.737899949630335
Validation loss: 3.0617761164505937

Epoch: 5| Step: 10
Training loss: 2.8788766018338516
Validation loss: 3.0628289637661683

Epoch: 33| Step: 0
Training loss: 2.8621259286661322
Validation loss: 3.0503990683206585

Epoch: 5| Step: 1
Training loss: 2.981859355206647
Validation loss: 3.057257840328824

Epoch: 5| Step: 2
Training loss: 3.0611796744303508
Validation loss: 3.0715396844516145

Epoch: 5| Step: 3
Training loss: 3.3449016263492135
Validation loss: 3.046630948044629

Epoch: 5| Step: 4
Training loss: 3.1726582880114576
Validation loss: 3.050717895735687

Epoch: 5| Step: 5
Training loss: 3.238070381026402
Validation loss: 3.0479413081112217

Epoch: 5| Step: 6
Training loss: 2.860790131803215
Validation loss: 3.043431278550315

Epoch: 5| Step: 7
Training loss: 3.2127205383360518
Validation loss: 3.0726842582056904

Epoch: 5| Step: 8
Training loss: 2.4817044281589813
Validation loss: 3.041811976808701

Epoch: 5| Step: 9
Training loss: 3.644953696083702
Validation loss: 3.0530935114578557

Epoch: 5| Step: 10
Training loss: 3.7934498349240693
Validation loss: 3.0661394444070846

Epoch: 34| Step: 0
Training loss: 3.0913264482410665
Validation loss: 3.040136501643007

Epoch: 5| Step: 1
Training loss: 2.755514424753686
Validation loss: 3.049704480593361

Epoch: 5| Step: 2
Training loss: 3.6835920671639184
Validation loss: 3.0515133000164316

Epoch: 5| Step: 3
Training loss: 3.0996412192657696
Validation loss: 3.0622663678775175

Epoch: 5| Step: 4
Training loss: 3.192820129594501
Validation loss: 3.0524124348299027

Epoch: 5| Step: 5
Training loss: 3.2543678276872363
Validation loss: 3.050350117201944

Epoch: 5| Step: 6
Training loss: 2.7231390592025218
Validation loss: 3.0602690787402156

Epoch: 5| Step: 7
Training loss: 3.0335407842884536
Validation loss: 3.025330757357961

Epoch: 5| Step: 8
Training loss: 3.272229538502598
Validation loss: 3.0621328730268083

Epoch: 5| Step: 9
Training loss: 3.187235952174163
Validation loss: 3.0542310609696455

Epoch: 5| Step: 10
Training loss: 3.2303654240201802
Validation loss: 3.0454058575711773

Epoch: 35| Step: 0
Training loss: 3.2626299835853345
Validation loss: 3.0474497566158654

Epoch: 5| Step: 1
Training loss: 2.766785200482967
Validation loss: 3.0256246490837233

Epoch: 5| Step: 2
Training loss: 3.0516117152529327
Validation loss: 3.0475309925242557

Epoch: 5| Step: 3
Training loss: 2.6555579686475332
Validation loss: 3.05570469066905

Epoch: 5| Step: 4
Training loss: 3.3881259973239892
Validation loss: 3.06158685956242

Epoch: 5| Step: 5
Training loss: 3.577575108281517
Validation loss: 3.0451990297803544

Epoch: 5| Step: 6
Training loss: 3.057406646975221
Validation loss: 3.0629413128552407

Epoch: 5| Step: 7
Training loss: 2.5411460426634362
Validation loss: 3.0220675913364476

Epoch: 5| Step: 8
Training loss: 3.7043760093918
Validation loss: 3.051371564938893

Epoch: 5| Step: 9
Training loss: 3.1290543767605907
Validation loss: 3.036176503627753

Epoch: 5| Step: 10
Training loss: 3.3555254503995062
Validation loss: 3.0607988388753222

Epoch: 36| Step: 0
Training loss: 3.4893131588022346
Validation loss: 3.061754930884665

Epoch: 5| Step: 1
Training loss: 3.5151303091625303
Validation loss: 3.051391205298315

Epoch: 5| Step: 2
Training loss: 3.3745441835387595
Validation loss: 3.026353713471174

Epoch: 5| Step: 3
Training loss: 3.0317561719983677
Validation loss: 3.044066010565276

Epoch: 5| Step: 4
Training loss: 3.8055967775759028
Validation loss: 3.0447857884019367

Epoch: 5| Step: 5
Training loss: 2.626097495123523
Validation loss: 3.0594618198315437

Epoch: 5| Step: 6
Training loss: 2.8374752362888973
Validation loss: 3.0513172464247136

Epoch: 5| Step: 7
Training loss: 3.3434191388585934
Validation loss: 3.0492699654341737

Epoch: 5| Step: 8
Training loss: 3.097026592590054
Validation loss: 3.0456766174551992

Epoch: 5| Step: 9
Training loss: 2.7834487110673214
Validation loss: 3.0453686899300325

Epoch: 5| Step: 10
Training loss: 2.4732566936097338
Validation loss: 3.0550765984682804

Epoch: 37| Step: 0
Training loss: 3.459685432820068
Validation loss: 3.061681239944234

Epoch: 5| Step: 1
Training loss: 2.6861601749985593
Validation loss: 3.0402853342682348

Epoch: 5| Step: 2
Training loss: 2.845649001340567
Validation loss: 3.0420443617400656

Epoch: 5| Step: 3
Training loss: 3.3183211514683486
Validation loss: 3.057951618633533

Epoch: 5| Step: 4
Training loss: 3.1161504947033043
Validation loss: 3.0503447182013756

Epoch: 5| Step: 5
Training loss: 3.5928924864330942
Validation loss: 3.047651241550825

Epoch: 5| Step: 6
Training loss: 3.044603175722516
Validation loss: 3.0573928083120374

Epoch: 5| Step: 7
Training loss: 3.3310027240065216
Validation loss: 3.0393934910296334

Epoch: 5| Step: 8
Training loss: 3.2350446956795564
Validation loss: 3.0523780182952915

Epoch: 5| Step: 9
Training loss: 3.12487304429616
Validation loss: 3.0768089248115302

Epoch: 5| Step: 10
Training loss: 2.40744107975465
Validation loss: 3.019774844219013

Epoch: 38| Step: 0
Training loss: 3.267133300565208
Validation loss: 3.054249000007545

Epoch: 5| Step: 1
Training loss: 3.2623905792010506
Validation loss: 3.04844274750585

Epoch: 5| Step: 2
Training loss: 2.7732928171163236
Validation loss: 3.0319387780105913

Epoch: 5| Step: 3
Training loss: 2.6376433383265647
Validation loss: 3.0523528519350918

Epoch: 5| Step: 4
Training loss: 3.3240041517835412
Validation loss: 3.0398438299154837

Epoch: 5| Step: 5
Training loss: 3.541369092819147
Validation loss: 3.0558889528459754

Epoch: 5| Step: 6
Training loss: 3.562798470826772
Validation loss: 3.0555678132135435

Epoch: 5| Step: 7
Training loss: 1.5850669087388183
Validation loss: 3.0270392812527143

Epoch: 5| Step: 8
Training loss: 3.6929295540398646
Validation loss: 3.04586967414149

Epoch: 5| Step: 9
Training loss: 3.3513712795100754
Validation loss: 3.0492151218448096

Epoch: 5| Step: 10
Training loss: 2.940073225445905
Validation loss: 3.0202209400720275

Epoch: 39| Step: 0
Training loss: 3.9758120205228744
Validation loss: 3.040935744320256

Epoch: 5| Step: 1
Training loss: 3.4516704827371525
Validation loss: 3.0302212687105494

Epoch: 5| Step: 2
Training loss: 2.8437288723674294
Validation loss: 3.011380084285249

Epoch: 5| Step: 3
Training loss: 3.3009548886465994
Validation loss: 3.0317414154681357

Epoch: 5| Step: 4
Training loss: 3.1542856883509063
Validation loss: 3.0769491048943336

Epoch: 5| Step: 5
Training loss: 3.104487579620676
Validation loss: 3.052438465761419

Epoch: 5| Step: 6
Training loss: 3.768765481439427
Validation loss: 3.044119936328584

Epoch: 5| Step: 7
Training loss: 2.9279299741302975
Validation loss: 3.047658796230211

Epoch: 5| Step: 8
Training loss: 2.5554708510564867
Validation loss: 3.0182145048185616

Epoch: 5| Step: 9
Training loss: 2.002896476481425
Validation loss: 3.042364244178509

Epoch: 5| Step: 10
Training loss: 2.9094478282561176
Validation loss: 3.0372837740002856

Epoch: 40| Step: 0
Training loss: 2.9322970149170438
Validation loss: 3.0420392176744935

Epoch: 5| Step: 1
Training loss: 3.3428979661565785
Validation loss: 3.0366120582451166

Epoch: 5| Step: 2
Training loss: 3.704884429035179
Validation loss: 3.025747233650347

Epoch: 5| Step: 3
Training loss: 2.649980933642624
Validation loss: 3.0650728462672303

Epoch: 5| Step: 4
Training loss: 3.266110032853165
Validation loss: 3.0226991110089623

Epoch: 5| Step: 5
Training loss: 3.2497174066780947
Validation loss: 3.0356521483235617

Epoch: 5| Step: 6
Training loss: 1.7919552001462131
Validation loss: 3.0317294958666645

Epoch: 5| Step: 7
Training loss: 3.8860699442774322
Validation loss: 3.0036903908769226

Epoch: 5| Step: 8
Training loss: 2.7688206028601337
Validation loss: 3.0158362467907973

Epoch: 5| Step: 9
Training loss: 3.252208399562077
Validation loss: 3.0311325671266047

Epoch: 5| Step: 10
Training loss: 3.1199894217776434
Validation loss: 3.0333592026896654

Epoch: 41| Step: 0
Training loss: 3.4010799263656453
Validation loss: 3.0272464300702575

Epoch: 5| Step: 1
Training loss: 3.149845385919791
Validation loss: 3.0398951698664165

Epoch: 5| Step: 2
Training loss: 2.6008832348313535
Validation loss: 3.0289110844492146

Epoch: 5| Step: 3
Training loss: 2.55961502309767
Validation loss: 3.0330775335508893

Epoch: 5| Step: 4
Training loss: 2.2273725140499545
Validation loss: 3.040234082700025

Epoch: 5| Step: 5
Training loss: 3.1132935029558126
Validation loss: 3.035373376062721

Epoch: 5| Step: 6
Training loss: 3.213922973630844
Validation loss: 3.0508939091394645

Epoch: 5| Step: 7
Training loss: 3.3225621400049596
Validation loss: 3.044472810181305

Epoch: 5| Step: 8
Training loss: 3.4000115618789657
Validation loss: 3.023884532385756

Epoch: 5| Step: 9
Training loss: 3.1445999422330173
Validation loss: 3.0205730259600205

Epoch: 5| Step: 10
Training loss: 3.870998654703563
Validation loss: 3.0033222128226194

Epoch: 42| Step: 0
Training loss: 3.477444311884914
Validation loss: 3.0188116950300397

Epoch: 5| Step: 1
Training loss: 3.0290834215174263
Validation loss: 3.0339778309665544

Epoch: 5| Step: 2
Training loss: 2.938102984935254
Validation loss: 3.0277793204148176

Epoch: 5| Step: 3
Training loss: 2.7263122268844175
Validation loss: 3.0357080121904896

Epoch: 5| Step: 4
Training loss: 2.1150917857569476
Validation loss: 3.037256168146534

Epoch: 5| Step: 5
Training loss: 3.877116947892689
Validation loss: 3.0320741416680685

Epoch: 5| Step: 6
Training loss: 3.036535472555265
Validation loss: 3.057523037179195

Epoch: 5| Step: 7
Training loss: 2.5084988139200854
Validation loss: 3.0509996874183853

Epoch: 5| Step: 8
Training loss: 3.2381955493220933
Validation loss: 2.99807216201662

Epoch: 5| Step: 9
Training loss: 3.3080461897940654
Validation loss: 3.022650581490908

Epoch: 5| Step: 10
Training loss: 3.5526684738682395
Validation loss: 3.0377438261896654

Epoch: 43| Step: 0
Training loss: 3.283380307347259
Validation loss: 3.0116419007160222

Epoch: 5| Step: 1
Training loss: 2.8599799511613577
Validation loss: 3.0342517549835724

Epoch: 5| Step: 2
Training loss: 3.434776198024782
Validation loss: 3.0268875393332255

Epoch: 5| Step: 3
Training loss: 2.8855992522236336
Validation loss: 3.0348359389507324

Epoch: 5| Step: 4
Training loss: 2.3806825216949874
Validation loss: 3.045325128998464

Epoch: 5| Step: 5
Training loss: 3.224010428078117
Validation loss: 3.0225059713067863

Epoch: 5| Step: 6
Training loss: 3.408124775245557
Validation loss: 3.024099810935257

Epoch: 5| Step: 7
Training loss: 3.1870393607201946
Validation loss: 3.0278640754026798

Epoch: 5| Step: 8
Training loss: 3.4307577422805973
Validation loss: 3.0354114768879517

Epoch: 5| Step: 9
Training loss: 2.307078217449123
Validation loss: 3.022132458968387

Epoch: 5| Step: 10
Training loss: 3.521350589354109
Validation loss: 3.0199863953784125

Epoch: 44| Step: 0
Training loss: 2.7499432991424633
Validation loss: 3.0221050871148636

Epoch: 5| Step: 1
Training loss: 3.453686284496783
Validation loss: 3.020636074653988

Epoch: 5| Step: 2
Training loss: 3.7040626851703506
Validation loss: 3.0178644892064046

Epoch: 5| Step: 3
Training loss: 3.225118909905839
Validation loss: 3.030476523776415

Epoch: 5| Step: 4
Training loss: 3.4085386094733483
Validation loss: 3.0154613671721617

Epoch: 5| Step: 5
Training loss: 2.9327342555929308
Validation loss: 3.005984106272233

Epoch: 5| Step: 6
Training loss: 3.0121775474348302
Validation loss: 3.018557403541256

Epoch: 5| Step: 7
Training loss: 3.452365291102674
Validation loss: 3.0142031244113583

Epoch: 5| Step: 8
Training loss: 3.1880624312314976
Validation loss: 3.0267849788437835

Epoch: 5| Step: 9
Training loss: 1.5867810941888751
Validation loss: 3.0140098936372

Epoch: 5| Step: 10
Training loss: 2.9470866801831086
Validation loss: 3.0330137756776363

Epoch: 45| Step: 0
Training loss: 2.637524019828005
Validation loss: 3.016473518041348

Epoch: 5| Step: 1
Training loss: 3.4569575932301513
Validation loss: 3.018749202700226

Epoch: 5| Step: 2
Training loss: 3.878223063222743
Validation loss: 3.027008101122241

Epoch: 5| Step: 3
Training loss: 3.260803167247638
Validation loss: 3.0103551500174137

Epoch: 5| Step: 4
Training loss: 3.6214504621784083
Validation loss: 3.029056362148932

Epoch: 5| Step: 5
Training loss: 3.227209880622335
Validation loss: 3.02957965891366

Epoch: 5| Step: 6
Training loss: 2.5827087344575768
Validation loss: 3.010622609275928

Epoch: 5| Step: 7
Training loss: 2.737189800506681
Validation loss: 3.0254067013573835

Epoch: 5| Step: 8
Training loss: 2.4160134539829574
Validation loss: 3.0299551324857017

Epoch: 5| Step: 9
Training loss: 3.1952699691068474
Validation loss: 3.026361274724713

Epoch: 5| Step: 10
Training loss: 2.740651192099533
Validation loss: 3.024990807016483

Epoch: 46| Step: 0
Training loss: 3.4844011382760502
Validation loss: 3.009369781213264

Epoch: 5| Step: 1
Training loss: 2.9166312260972265
Validation loss: 3.0448402091208915

Epoch: 5| Step: 2
Training loss: 2.7237518601851045
Validation loss: 3.019827546632302

Epoch: 5| Step: 3
Training loss: 3.230826822752678
Validation loss: 3.0019342039181045

Epoch: 5| Step: 4
Training loss: 3.1688726337486175
Validation loss: 3.0154169414568504

Epoch: 5| Step: 5
Training loss: 3.2827819154631928
Validation loss: 3.0197967657501295

Epoch: 5| Step: 6
Training loss: 3.078310268655098
Validation loss: 3.0154257475859674

Epoch: 5| Step: 7
Training loss: 2.942308102737636
Validation loss: 2.9874923789710226

Epoch: 5| Step: 8
Training loss: 3.4201363104709945
Validation loss: 3.0394672989173945

Epoch: 5| Step: 9
Training loss: 3.3072798280679274
Validation loss: 3.034444933629368

Epoch: 5| Step: 10
Training loss: 2.1410371703796995
Validation loss: 3.021254425628701

Epoch: 47| Step: 0
Training loss: 3.2072819229643694
Validation loss: 3.022814643561684

Epoch: 5| Step: 1
Training loss: 2.5524813490885823
Validation loss: 3.0109799861440814

Epoch: 5| Step: 2
Training loss: 3.7801205548231636
Validation loss: 3.0072260305782046

Epoch: 5| Step: 3
Training loss: 2.5863444304892105
Validation loss: 2.98544299114187

Epoch: 5| Step: 4
Training loss: 3.0249730826197
Validation loss: 3.0242751042570513

Epoch: 5| Step: 5
Training loss: 1.9166167985261369
Validation loss: 2.9899374967989183

Epoch: 5| Step: 6
Training loss: 3.7720020794261004
Validation loss: 2.9933914559364796

Epoch: 5| Step: 7
Training loss: 2.464983227345815
Validation loss: 3.017377830776967

Epoch: 5| Step: 8
Training loss: 2.894400445656982
Validation loss: 2.985554786695657

Epoch: 5| Step: 9
Training loss: 3.5752071827428593
Validation loss: 3.0021424786991524

Epoch: 5| Step: 10
Training loss: 3.422749725437634
Validation loss: 3.009886378602593

Epoch: 48| Step: 0
Training loss: 3.5365512182128747
Validation loss: 2.991011042660645

Epoch: 5| Step: 1
Training loss: 3.40878691387158
Validation loss: 3.0049991452041147

Epoch: 5| Step: 2
Training loss: 3.5285961340000194
Validation loss: 3.005759644253314

Epoch: 5| Step: 3
Training loss: 2.4288840974157657
Validation loss: 2.993704531943446

Epoch: 5| Step: 4
Training loss: 2.6978027339331243
Validation loss: 3.001342507231764

Epoch: 5| Step: 5
Training loss: 3.2808259235815496
Validation loss: 3.0042212425514134

Epoch: 5| Step: 6
Training loss: 2.8985098858043368
Validation loss: 3.0030782316257705

Epoch: 5| Step: 7
Training loss: 2.4700154791281306
Validation loss: 3.0040684854399116

Epoch: 5| Step: 8
Training loss: 3.2094509275493928
Validation loss: 3.003317535082228

Epoch: 5| Step: 9
Training loss: 3.153581907893385
Validation loss: 3.0063144020903376

Epoch: 5| Step: 10
Training loss: 3.1033266368866106
Validation loss: 3.006202223882104

Epoch: 49| Step: 0
Training loss: 2.70254439805338
Validation loss: 2.9918992351271725

Epoch: 5| Step: 1
Training loss: 3.00111543263948
Validation loss: 3.01605820321777

Epoch: 5| Step: 2
Training loss: 2.882282818356852
Validation loss: 2.98105609669357

Epoch: 5| Step: 3
Training loss: 3.5364771951538527
Validation loss: 3.0061584919566116

Epoch: 5| Step: 4
Training loss: 2.7173626747281747
Validation loss: 3.010799885296014

Epoch: 5| Step: 5
Training loss: 2.495943020133556
Validation loss: 2.999575468673016

Epoch: 5| Step: 6
Training loss: 3.561991203515716
Validation loss: 2.991717669421038

Epoch: 5| Step: 7
Training loss: 3.7248757821691627
Validation loss: 2.998435986868645

Epoch: 5| Step: 8
Training loss: 2.311222651532841
Validation loss: 3.0148672888012267

Epoch: 5| Step: 9
Training loss: 3.384846628565846
Validation loss: 2.9878944021644394

Epoch: 5| Step: 10
Training loss: 3.0020274622790084
Validation loss: 3.012582684304969

Epoch: 50| Step: 0
Training loss: 2.377276684595133
Validation loss: 2.9970311562680467

Epoch: 5| Step: 1
Training loss: 3.4493344591028565
Validation loss: 3.0022744543282798

Epoch: 5| Step: 2
Training loss: 2.4943011179214136
Validation loss: 3.0174498339653417

Epoch: 5| Step: 3
Training loss: 3.3242929093978986
Validation loss: 3.0012561695908637

Epoch: 5| Step: 4
Training loss: 2.8537333547045733
Validation loss: 2.9979095430737104

Epoch: 5| Step: 5
Training loss: 3.2934483080522914
Validation loss: 2.9953146232425296

Epoch: 5| Step: 6
Training loss: 3.6241944832142554
Validation loss: 2.982030396699917

Epoch: 5| Step: 7
Training loss: 3.4571278014412554
Validation loss: 2.9732515550393748

Epoch: 5| Step: 8
Training loss: 2.5179659927168427
Validation loss: 2.9956340502105987

Epoch: 5| Step: 9
Training loss: 2.7314139764302348
Validation loss: 2.980579416152076

Epoch: 5| Step: 10
Training loss: 3.0268628335251786
Validation loss: 2.996041855421005

Epoch: 51| Step: 0
Training loss: 3.3696539181006404
Validation loss: 2.96601062545614

Epoch: 5| Step: 1
Training loss: 2.974605367436155
Validation loss: 2.9878887152746048

Epoch: 5| Step: 2
Training loss: 3.33973409907721
Validation loss: 3.017301188501072

Epoch: 5| Step: 3
Training loss: 2.6556793497493825
Validation loss: 2.9962111118782593

Epoch: 5| Step: 4
Training loss: 3.0584180447715896
Validation loss: 2.9959428118722937

Epoch: 5| Step: 5
Training loss: 2.6295182534581834
Validation loss: 3.002485908260134

Epoch: 5| Step: 6
Training loss: 2.9356219192628408
Validation loss: 2.997051251102157

Epoch: 5| Step: 7
Training loss: 3.1465568131598043
Validation loss: 2.985818910591196

Epoch: 5| Step: 8
Training loss: 3.5879121550286244
Validation loss: 2.9773199157590047

Epoch: 5| Step: 9
Training loss: 3.221849745199122
Validation loss: 2.98948574146265

Epoch: 5| Step: 10
Training loss: 2.4969972697507745
Validation loss: 2.976779509423341

Epoch: 52| Step: 0
Training loss: 2.8903805191164857
Validation loss: 2.9892258746434255

Epoch: 5| Step: 1
Training loss: 2.8827584114272886
Validation loss: 2.9904908845792546

Epoch: 5| Step: 2
Training loss: 2.1559707903113012
Validation loss: 2.9722946550970315

Epoch: 5| Step: 3
Training loss: 2.8917280412329798
Validation loss: 3.0008165827354096

Epoch: 5| Step: 4
Training loss: 3.073078491777582
Validation loss: 2.9642708338720754

Epoch: 5| Step: 5
Training loss: 3.5593019821273364
Validation loss: 2.984069368750106

Epoch: 5| Step: 6
Training loss: 3.0298976437745364
Validation loss: 2.972204567774357

Epoch: 5| Step: 7
Training loss: 3.080557699368045
Validation loss: 2.9820442756054284

Epoch: 5| Step: 8
Training loss: 3.209838084953229
Validation loss: 2.981927926012467

Epoch: 5| Step: 9
Training loss: 3.4896642115695427
Validation loss: 2.985070595330663

Epoch: 5| Step: 10
Training loss: 2.846280826741756
Validation loss: 2.974992156059339

Epoch: 53| Step: 0
Training loss: 2.568283625308797
Validation loss: 2.96435632622116

Epoch: 5| Step: 1
Training loss: 3.1260618313210293
Validation loss: 2.9938750688315516

Epoch: 5| Step: 2
Training loss: 3.160796865596004
Validation loss: 2.9874836312362723

Epoch: 5| Step: 3
Training loss: 4.00157849637446
Validation loss: 2.972950342235119

Epoch: 5| Step: 4
Training loss: 2.5238320245965076
Validation loss: 2.9709826499566088

Epoch: 5| Step: 5
Training loss: 2.4844816173012356
Validation loss: 2.98699819392451

Epoch: 5| Step: 6
Training loss: 3.0158947443517965
Validation loss: 2.967957672102008

Epoch: 5| Step: 7
Training loss: 2.929818193699453
Validation loss: 2.9636726903347896

Epoch: 5| Step: 8
Training loss: 3.281197974382943
Validation loss: 2.969287451047001

Epoch: 5| Step: 9
Training loss: 3.1138803630723104
Validation loss: 2.9743307011376485

Epoch: 5| Step: 10
Training loss: 2.962651624702612
Validation loss: 2.9412646356852545

Epoch: 54| Step: 0
Training loss: 3.791250827888577
Validation loss: 2.955124491037277

Epoch: 5| Step: 1
Training loss: 2.523874156480759
Validation loss: 2.9711645854107753

Epoch: 5| Step: 2
Training loss: 3.134265134793268
Validation loss: 2.971607891781512

Epoch: 5| Step: 3
Training loss: 3.155231273656305
Validation loss: 2.991501966454771

Epoch: 5| Step: 4
Training loss: 2.780663589206341
Validation loss: 2.9890511108934157

Epoch: 5| Step: 5
Training loss: 2.9977402123291528
Validation loss: 2.974145728679713

Epoch: 5| Step: 6
Training loss: 2.7900875996609384
Validation loss: 2.9540987576910616

Epoch: 5| Step: 7
Training loss: 2.717674130192485
Validation loss: 2.9583743807625447

Epoch: 5| Step: 8
Training loss: 2.5776773699940216
Validation loss: 2.980814979400828

Epoch: 5| Step: 9
Training loss: 3.8208636488937286
Validation loss: 2.9527404486163586

Epoch: 5| Step: 10
Training loss: 2.6730174695038844
Validation loss: 2.9608942787868133

Epoch: 55| Step: 0
Training loss: 2.23042535155076
Validation loss: 2.976722928926662

Epoch: 5| Step: 1
Training loss: 2.65541350713215
Validation loss: 2.960281336162508

Epoch: 5| Step: 2
Training loss: 2.9785180263822286
Validation loss: 2.956922780368501

Epoch: 5| Step: 3
Training loss: 2.565118149979071
Validation loss: 2.959114542349015

Epoch: 5| Step: 4
Training loss: 3.5441075758526726
Validation loss: 2.959530907899328

Epoch: 5| Step: 5
Training loss: 3.381383580867375
Validation loss: 2.966345467300491

Epoch: 5| Step: 6
Training loss: 2.704962926952557
Validation loss: 2.964331931221151

Epoch: 5| Step: 7
Training loss: 3.4807901458825197
Validation loss: 2.996133936705974

Epoch: 5| Step: 8
Training loss: 2.7518717724679167
Validation loss: 2.9644177832963514

Epoch: 5| Step: 9
Training loss: 2.5371389761733045
Validation loss: 2.9638793367699523

Epoch: 5| Step: 10
Training loss: 3.965537385446151
Validation loss: 2.9704538325295546

Epoch: 56| Step: 0
Training loss: 4.071207193460554
Validation loss: 2.954384610609497

Epoch: 5| Step: 1
Training loss: 3.578309833133774
Validation loss: 2.972606669787275

Epoch: 5| Step: 2
Training loss: 2.9321537470976264
Validation loss: 2.929092018124861

Epoch: 5| Step: 3
Training loss: 2.5656233570311997
Validation loss: 2.981298155002386

Epoch: 5| Step: 4
Training loss: 2.4413289050248363
Validation loss: 2.9373012109788164

Epoch: 5| Step: 5
Training loss: 2.1630924405587915
Validation loss: 2.9797606463734154

Epoch: 5| Step: 6
Training loss: 2.7107172719894836
Validation loss: 2.9893247848370876

Epoch: 5| Step: 7
Training loss: 3.3361714837163583
Validation loss: 2.9677855535024213

Epoch: 5| Step: 8
Training loss: 2.56297139739807
Validation loss: 2.973018428679935

Epoch: 5| Step: 9
Training loss: 2.9146636261058885
Validation loss: 2.959801465723379

Epoch: 5| Step: 10
Training loss: 3.3604880684639507
Validation loss: 2.949737658340829

Epoch: 57| Step: 0
Training loss: 2.7920641734719136
Validation loss: 2.9792518772772754

Epoch: 5| Step: 1
Training loss: 3.4405311398432303
Validation loss: 2.9549172826688395

Epoch: 5| Step: 2
Training loss: 4.109508207649698
Validation loss: 2.9406537450307595

Epoch: 5| Step: 3
Training loss: 2.846164558612546
Validation loss: 2.9611271224891884

Epoch: 5| Step: 4
Training loss: 2.739941582022195
Validation loss: 2.958118202698406

Epoch: 5| Step: 5
Training loss: 3.0190422974915356
Validation loss: 2.9459032445663107

Epoch: 5| Step: 6
Training loss: 2.3052913585891566
Validation loss: 2.9413843909500823

Epoch: 5| Step: 7
Training loss: 2.234086344820195
Validation loss: 2.948386471690102

Epoch: 5| Step: 8
Training loss: 3.2086784045112187
Validation loss: 2.9363294742180077

Epoch: 5| Step: 9
Training loss: 2.6943265576698816
Validation loss: 2.950446191772617

Epoch: 5| Step: 10
Training loss: 3.098259154018822
Validation loss: 2.953492378266318

Epoch: 58| Step: 0
Training loss: 3.0124373116836356
Validation loss: 2.9668677744277803

Epoch: 5| Step: 1
Training loss: 2.280198887131179
Validation loss: 2.9399289343864843

Epoch: 5| Step: 2
Training loss: 3.5504819032492327
Validation loss: 2.945404720638825

Epoch: 5| Step: 3
Training loss: 3.6958368747927883
Validation loss: 2.9525745124226326

Epoch: 5| Step: 4
Training loss: 2.929513015637422
Validation loss: 2.9529162856908475

Epoch: 5| Step: 5
Training loss: 2.7394592972635174
Validation loss: 2.948118751585676

Epoch: 5| Step: 6
Training loss: 2.4881648301417543
Validation loss: 2.9369717954123593

Epoch: 5| Step: 7
Training loss: 2.88086566471771
Validation loss: 2.9296593335619585

Epoch: 5| Step: 8
Training loss: 2.6957913622961924
Validation loss: 2.93721232230684

Epoch: 5| Step: 9
Training loss: 3.483690545293691
Validation loss: 2.9402818391333

Epoch: 5| Step: 10
Training loss: 2.820613517442014
Validation loss: 2.929640775137031

Epoch: 59| Step: 0
Training loss: 3.4884853324696605
Validation loss: 2.929534856504531

Epoch: 5| Step: 1
Training loss: 3.6680834085014524
Validation loss: 2.9332756644627556

Epoch: 5| Step: 2
Training loss: 2.6437765422237187
Validation loss: 2.9412341726989863

Epoch: 5| Step: 3
Training loss: 2.5303162159279404
Validation loss: 2.9579253937297483

Epoch: 5| Step: 4
Training loss: 3.153581000663624
Validation loss: 2.9379814083365807

Epoch: 5| Step: 5
Training loss: 2.593353333073292
Validation loss: 2.9314256113078447

Epoch: 5| Step: 6
Training loss: 2.679307827313278
Validation loss: 2.96117608456608

Epoch: 5| Step: 7
Training loss: 2.954328987888241
Validation loss: 2.948388784575974

Epoch: 5| Step: 8
Training loss: 3.0657981706990944
Validation loss: 2.9457962884801705

Epoch: 5| Step: 9
Training loss: 3.3005986450969202
Validation loss: 2.922437793402245

Epoch: 5| Step: 10
Training loss: 2.5439879547469766
Validation loss: 2.941058361546049

Epoch: 60| Step: 0
Training loss: 2.887900228134818
Validation loss: 2.9200902092659278

Epoch: 5| Step: 1
Training loss: 3.54917396283719
Validation loss: 2.954761531517525

Epoch: 5| Step: 2
Training loss: 3.3445579051911714
Validation loss: 2.9300891319262714

Epoch: 5| Step: 3
Training loss: 2.8666323090497823
Validation loss: 2.9116761742110087

Epoch: 5| Step: 4
Training loss: 3.123654953455889
Validation loss: 2.925748335325152

Epoch: 5| Step: 5
Training loss: 2.5635927243026364
Validation loss: 2.927452099790228

Epoch: 5| Step: 6
Training loss: 2.056016383480595
Validation loss: 2.9383138254950683

Epoch: 5| Step: 7
Training loss: 3.6265634256515407
Validation loss: 2.9117976940077894

Epoch: 5| Step: 8
Training loss: 2.4957773787181208
Validation loss: 2.9482019566779174

Epoch: 5| Step: 9
Training loss: 3.27927215548679
Validation loss: 2.9491076998253543

Epoch: 5| Step: 10
Training loss: 2.6517329685530613
Validation loss: 2.94881743186348

Epoch: 61| Step: 0
Training loss: 2.7463387479059302
Validation loss: 2.9443924943078232

Epoch: 5| Step: 1
Training loss: 3.5070215365725086
Validation loss: 2.926227531326695

Epoch: 5| Step: 2
Training loss: 3.154908452224715
Validation loss: 2.9465429906634353

Epoch: 5| Step: 3
Training loss: 3.102561040457645
Validation loss: 2.947967647707511

Epoch: 5| Step: 4
Training loss: 3.190075151999218
Validation loss: 2.917906727550166

Epoch: 5| Step: 5
Training loss: 3.3154350089703244
Validation loss: 2.9237292507678907

Epoch: 5| Step: 6
Training loss: 2.661512659243788
Validation loss: 2.9339293538145865

Epoch: 5| Step: 7
Training loss: 2.5210055037623382
Validation loss: 2.93555893537783

Epoch: 5| Step: 8
Training loss: 2.7239729599471865
Validation loss: 2.9085977496589495

Epoch: 5| Step: 9
Training loss: 2.759324650720928
Validation loss: 2.9396646605784262

Epoch: 5| Step: 10
Training loss: 2.8846671075340846
Validation loss: 2.9284146628065706

Epoch: 62| Step: 0
Training loss: 2.7842420278666093
Validation loss: 2.9352387264564315

Epoch: 5| Step: 1
Training loss: 2.0465106202984
Validation loss: 2.9171689428715615

Epoch: 5| Step: 2
Training loss: 3.603490350732843
Validation loss: 2.9197714384618916

Epoch: 5| Step: 3
Training loss: 2.685524591526869
Validation loss: 2.9164964377187554

Epoch: 5| Step: 4
Training loss: 2.4371002065024787
Validation loss: 2.947534890743712

Epoch: 5| Step: 5
Training loss: 3.2892182012025395
Validation loss: 2.9351218779156847

Epoch: 5| Step: 6
Training loss: 3.320390336863385
Validation loss: 2.8988085907975947

Epoch: 5| Step: 7
Training loss: 2.9636211865063617
Validation loss: 2.916773883472083

Epoch: 5| Step: 8
Training loss: 2.592848103915466
Validation loss: 2.929121833691209

Epoch: 5| Step: 9
Training loss: 3.066956527804857
Validation loss: 2.9290370144091002

Epoch: 5| Step: 10
Training loss: 3.515199084443367
Validation loss: 2.921560554283453

Epoch: 63| Step: 0
Training loss: 2.461493535273724
Validation loss: 2.918569159390122

Epoch: 5| Step: 1
Training loss: 3.3171466409805515
Validation loss: 2.917078501255018

Epoch: 5| Step: 2
Training loss: 3.4205489702939076
Validation loss: 2.9271912414561694

Epoch: 5| Step: 3
Training loss: 3.724467778427402
Validation loss: 2.9330994024948245

Epoch: 5| Step: 4
Training loss: 3.395230448434043
Validation loss: 2.9196215104793155

Epoch: 5| Step: 5
Training loss: 3.0308971396285127
Validation loss: 2.934258218901436

Epoch: 5| Step: 6
Training loss: 2.445792154185349
Validation loss: 2.9233410245711164

Epoch: 5| Step: 7
Training loss: 2.5383940300934684
Validation loss: 2.935586903736049

Epoch: 5| Step: 8
Training loss: 2.92946141705788
Validation loss: 2.925977717426501

Epoch: 5| Step: 9
Training loss: 2.102751441643946
Validation loss: 2.9269880018641907

Epoch: 5| Step: 10
Training loss: 2.344001044497729
Validation loss: 2.930086946335183

Epoch: 64| Step: 0
Training loss: 2.704101386161515
Validation loss: 2.932287189772598

Epoch: 5| Step: 1
Training loss: 2.5414174588293683
Validation loss: 2.920255319025021

Epoch: 5| Step: 2
Training loss: 2.3868911605971106
Validation loss: 2.9318707720186494

Epoch: 5| Step: 3
Training loss: 2.638093717019513
Validation loss: 2.9155325540729438

Epoch: 5| Step: 4
Training loss: 3.897256859712818
Validation loss: 2.916764669632306

Epoch: 5| Step: 5
Training loss: 3.398678545241052
Validation loss: 2.945276968188874

Epoch: 5| Step: 6
Training loss: 2.394891758425924
Validation loss: 2.9199064259770844

Epoch: 5| Step: 7
Training loss: 3.0866207090819238
Validation loss: 2.947112413150753

Epoch: 5| Step: 8
Training loss: 2.567196148180427
Validation loss: 2.9107276084186404

Epoch: 5| Step: 9
Training loss: 3.183454451994689
Validation loss: 2.9163957045129623

Epoch: 5| Step: 10
Training loss: 3.002454230652905
Validation loss: 2.9399523302596844

Epoch: 65| Step: 0
Training loss: 3.0556664032529386
Validation loss: 2.933774709728861

Epoch: 5| Step: 1
Training loss: 2.583058301580042
Validation loss: 2.9370058491041386

Epoch: 5| Step: 2
Training loss: 2.9129972172627907
Validation loss: 2.9364912980041513

Epoch: 5| Step: 3
Training loss: 2.9815564651836004
Validation loss: 2.9307342335118003

Epoch: 5| Step: 4
Training loss: 2.614362689633789
Validation loss: 2.910364289771518

Epoch: 5| Step: 5
Training loss: 2.272987452266378
Validation loss: 2.916822069543019

Epoch: 5| Step: 6
Training loss: 3.335610295492565
Validation loss: 2.894120837352007

Epoch: 5| Step: 7
Training loss: 3.367092901259615
Validation loss: 2.9293885008573484

Epoch: 5| Step: 8
Training loss: 2.6334939408718765
Validation loss: 2.9238493594983375

Epoch: 5| Step: 9
Training loss: 3.1162531702520506
Validation loss: 2.917794211521503

Epoch: 5| Step: 10
Training loss: 3.274900123296269
Validation loss: 2.9216299541558577

Epoch: 66| Step: 0
Training loss: 3.0135905464358266
Validation loss: 2.915482942416661

Epoch: 5| Step: 1
Training loss: 2.20110016970884
Validation loss: 2.9204746628636773

Epoch: 5| Step: 2
Training loss: 2.2396155303296696
Validation loss: 2.8995573512219988

Epoch: 5| Step: 3
Training loss: 2.461937110971543
Validation loss: 2.8935426434202807

Epoch: 5| Step: 4
Training loss: 3.3822748404459206
Validation loss: 2.8935515652937696

Epoch: 5| Step: 5
Training loss: 3.1867489397396276
Validation loss: 2.8923505834683416

Epoch: 5| Step: 6
Training loss: 2.9556154114375484
Validation loss: 2.911498894303357

Epoch: 5| Step: 7
Training loss: 2.827377895076313
Validation loss: 2.904280177682973

Epoch: 5| Step: 8
Training loss: 2.857785809925684
Validation loss: 2.9063137473953584

Epoch: 5| Step: 9
Training loss: 2.8306101633914067
Validation loss: 2.9165315980590765

Epoch: 5| Step: 10
Training loss: 3.968014866785686
Validation loss: 2.903660808524432

Epoch: 67| Step: 0
Training loss: 2.4254064592903464
Validation loss: 2.8997652284119653

Epoch: 5| Step: 1
Training loss: 2.5174490434628236
Validation loss: 2.905680332108332

Epoch: 5| Step: 2
Training loss: 2.4318935768282612
Validation loss: 2.9166877382516367

Epoch: 5| Step: 3
Training loss: 3.358633128022092
Validation loss: 2.9008020171044793

Epoch: 5| Step: 4
Training loss: 3.7000347393570143
Validation loss: 2.9076485516609885

Epoch: 5| Step: 5
Training loss: 2.2173232743330797
Validation loss: 2.923258710594368

Epoch: 5| Step: 6
Training loss: 3.1821402572516018
Validation loss: 2.914561536546574

Epoch: 5| Step: 7
Training loss: 2.8513409254133415
Validation loss: 2.877976903614346

Epoch: 5| Step: 8
Training loss: 2.8592774421433647
Validation loss: 2.9073134748083493

Epoch: 5| Step: 9
Training loss: 3.0260829342749123
Validation loss: 2.9077456539339446

Epoch: 5| Step: 10
Training loss: 3.295054724185317
Validation loss: 2.876907856980946

Epoch: 68| Step: 0
Training loss: 2.4026158620661473
Validation loss: 2.91010655990235

Epoch: 5| Step: 1
Training loss: 3.081447918398705
Validation loss: 2.9008315419289894

Epoch: 5| Step: 2
Training loss: 2.8402485513051348
Validation loss: 2.885224349523455

Epoch: 5| Step: 3
Training loss: 3.740937280964799
Validation loss: 2.899244356204384

Epoch: 5| Step: 4
Training loss: 2.958929583857406
Validation loss: 2.877471081231384

Epoch: 5| Step: 5
Training loss: 2.1543180130918422
Validation loss: 2.9082994392150745

Epoch: 5| Step: 6
Training loss: 2.62658552696396
Validation loss: 2.929658358740036

Epoch: 5| Step: 7
Training loss: 2.700675869166656
Validation loss: 2.920811048202693

Epoch: 5| Step: 8
Training loss: 3.6207484602263444
Validation loss: 2.9085625075123906

Epoch: 5| Step: 9
Training loss: 3.0366556006466188
Validation loss: 2.9013762001799464

Epoch: 5| Step: 10
Training loss: 2.399717405689001
Validation loss: 2.878981743071785

Epoch: 69| Step: 0
Training loss: 2.8478360845350426
Validation loss: 2.8945118180231146

Epoch: 5| Step: 1
Training loss: 2.734882591000948
Validation loss: 2.9226154290540873

Epoch: 5| Step: 2
Training loss: 2.3623209365721127
Validation loss: 2.890907927826289

Epoch: 5| Step: 3
Training loss: 3.1784187053649444
Validation loss: 2.9183472539440967

Epoch: 5| Step: 4
Training loss: 2.7382896085821073
Validation loss: 2.8921943676923187

Epoch: 5| Step: 5
Training loss: 3.137431480601798
Validation loss: 2.8853628306736083

Epoch: 5| Step: 6
Training loss: 2.2636645023202844
Validation loss: 2.8937014584007144

Epoch: 5| Step: 7
Training loss: 3.6853970495679116
Validation loss: 2.933485916882587

Epoch: 5| Step: 8
Training loss: 3.2528525818315863
Validation loss: 2.934607188671656

Epoch: 5| Step: 9
Training loss: 2.6304173654013225
Validation loss: 2.9035590508098355

Epoch: 5| Step: 10
Training loss: 2.793192906487843
Validation loss: 2.9051150689306477

Epoch: 70| Step: 0
Training loss: 3.1176506597093794
Validation loss: 2.9005467095777133

Epoch: 5| Step: 1
Training loss: 2.9992989674696733
Validation loss: 2.8949441265342415

Epoch: 5| Step: 2
Training loss: 2.9950135433546756
Validation loss: 2.901877499669994

Epoch: 5| Step: 3
Training loss: 3.2151196200363334
Validation loss: 2.904935553875813

Epoch: 5| Step: 4
Training loss: 2.1165222023552563
Validation loss: 2.8832173628290563

Epoch: 5| Step: 5
Training loss: 3.566566555602802
Validation loss: 2.8857477007917467

Epoch: 5| Step: 6
Training loss: 3.0123317307452524
Validation loss: 2.889775570818227

Epoch: 5| Step: 7
Training loss: 3.2508077351307834
Validation loss: 2.917547822094915

Epoch: 5| Step: 8
Training loss: 2.750721750046558
Validation loss: 2.8817664306461332

Epoch: 5| Step: 9
Training loss: 2.250168794022577
Validation loss: 2.9025576367805273

Epoch: 5| Step: 10
Training loss: 2.2247121517564037
Validation loss: 2.9043346934149206

Epoch: 71| Step: 0
Training loss: 2.8510858842911926
Validation loss: 2.905532688408076

Epoch: 5| Step: 1
Training loss: 2.8515526340261688
Validation loss: 2.89296284694605

Epoch: 5| Step: 2
Training loss: 2.475089323955816
Validation loss: 2.908266856469863

Epoch: 5| Step: 3
Training loss: 2.5038984420583215
Validation loss: 2.8893922517982755

Epoch: 5| Step: 4
Training loss: 2.8741948202702203
Validation loss: 2.895944497739903

Epoch: 5| Step: 5
Training loss: 3.0296799831287293
Validation loss: 2.924189886545566

Epoch: 5| Step: 6
Training loss: 3.0713163874976828
Validation loss: 2.884930392688298

Epoch: 5| Step: 7
Training loss: 2.7680537879105804
Validation loss: 2.886698306298513

Epoch: 5| Step: 8
Training loss: 3.2604814386890983
Validation loss: 2.9321815660791084

Epoch: 5| Step: 9
Training loss: 3.094055623072965
Validation loss: 2.8780833203104494

Epoch: 5| Step: 10
Training loss: 3.134260874959167
Validation loss: 2.9176472932976436

Epoch: 72| Step: 0
Training loss: 3.571759287644467
Validation loss: 2.875407052349354

Epoch: 5| Step: 1
Training loss: 3.2898080302527575
Validation loss: 2.9138866665017815

Epoch: 5| Step: 2
Training loss: 2.279480130004633
Validation loss: 2.917416040044904

Epoch: 5| Step: 3
Training loss: 2.385075229601908
Validation loss: 2.9064899706732756

Epoch: 5| Step: 4
Training loss: 2.3967178591627016
Validation loss: 2.922753392022617

Epoch: 5| Step: 5
Training loss: 2.9313795569445724
Validation loss: 2.898942275500247

Epoch: 5| Step: 6
Training loss: 3.3578506204847387
Validation loss: 2.8890048967050608

Epoch: 5| Step: 7
Training loss: 2.6238355324421825
Validation loss: 2.8904538419603725

Epoch: 5| Step: 8
Training loss: 2.550665906836554
Validation loss: 2.8960365961221712

Epoch: 5| Step: 9
Training loss: 2.705371694781974
Validation loss: 2.884902646806913

Epoch: 5| Step: 10
Training loss: 3.5395987064476033
Validation loss: 2.910181830299889

Epoch: 73| Step: 0
Training loss: 3.2054864877818545
Validation loss: 2.9076267721071574

Epoch: 5| Step: 1
Training loss: 2.439592294869277
Validation loss: 2.893757809722546

Epoch: 5| Step: 2
Training loss: 2.508465358094225
Validation loss: 2.9140603965217897

Epoch: 5| Step: 3
Training loss: 2.158056635653473
Validation loss: 2.8641145103646317

Epoch: 5| Step: 4
Training loss: 2.516374464524155
Validation loss: 2.906185543295116

Epoch: 5| Step: 5
Training loss: 3.1188724715471157
Validation loss: 2.912048669777957

Epoch: 5| Step: 6
Training loss: 3.233133713632873
Validation loss: 2.9029247160849265

Epoch: 5| Step: 7
Training loss: 3.211658109195898
Validation loss: 2.9046813192690517

Epoch: 5| Step: 8
Training loss: 3.554273778293458
Validation loss: 2.853275466824197

Epoch: 5| Step: 9
Training loss: 2.5470385352680434
Validation loss: 2.884502822514056

Epoch: 5| Step: 10
Training loss: 2.955831750554393
Validation loss: 2.885824809371597

Epoch: 74| Step: 0
Training loss: 2.6652752305809875
Validation loss: 2.9060752993448964

Epoch: 5| Step: 1
Training loss: 3.2656450042841993
Validation loss: 2.899858413071608

Epoch: 5| Step: 2
Training loss: 3.2373104319801973
Validation loss: 2.881687876355704

Epoch: 5| Step: 3
Training loss: 2.8836301558931865
Validation loss: 2.8966873209921062

Epoch: 5| Step: 4
Training loss: 2.9778040902159817
Validation loss: 2.908111503606446

Epoch: 5| Step: 5
Training loss: 3.066934761132119
Validation loss: 2.881533692844873

Epoch: 5| Step: 6
Training loss: 2.5106874902881002
Validation loss: 2.8645231444597554

Epoch: 5| Step: 7
Training loss: 2.5214908047216626
Validation loss: 2.8703012479462338

Epoch: 5| Step: 8
Training loss: 2.837262477260108
Validation loss: 2.8679793106860654

Epoch: 5| Step: 9
Training loss: 2.4063893067299884
Validation loss: 2.87210166974202

Epoch: 5| Step: 10
Training loss: 3.0493654685429536
Validation loss: 2.857156415656656

Epoch: 75| Step: 0
Training loss: 3.5769802077899993
Validation loss: 2.876574715917479

Epoch: 5| Step: 1
Training loss: 3.4448095114520383
Validation loss: 2.8830793299324164

Epoch: 5| Step: 2
Training loss: 2.488636799895809
Validation loss: 2.8959846896719403

Epoch: 5| Step: 3
Training loss: 2.5411570199599143
Validation loss: 2.864440401301842

Epoch: 5| Step: 4
Training loss: 2.7301539511117756
Validation loss: 2.8779889745317164

Epoch: 5| Step: 5
Training loss: 2.581113066285494
Validation loss: 2.894115960079071

Epoch: 5| Step: 6
Training loss: 2.7544166470731746
Validation loss: 2.8948522325037893

Epoch: 5| Step: 7
Training loss: 2.8697710999976698
Validation loss: 2.8747123192682866

Epoch: 5| Step: 8
Training loss: 3.2126034315505927
Validation loss: 2.8746236373786362

Epoch: 5| Step: 9
Training loss: 2.2930016068504084
Validation loss: 2.8775587229865707

Epoch: 5| Step: 10
Training loss: 2.8862920505108773
Validation loss: 2.870843233752593

Epoch: 76| Step: 0
Training loss: 3.5396947569632533
Validation loss: 2.858802308152045

Epoch: 5| Step: 1
Training loss: 2.007467989921708
Validation loss: 2.9117751583763587

Epoch: 5| Step: 2
Training loss: 2.0453648711305004
Validation loss: 2.8769167627179835

Epoch: 5| Step: 3
Training loss: 2.687776506970421
Validation loss: 2.882761530205057

Epoch: 5| Step: 4
Training loss: 2.8206492722234238
Validation loss: 2.862375036839021

Epoch: 5| Step: 5
Training loss: 3.225881287568086
Validation loss: 2.864605377798567

Epoch: 5| Step: 6
Training loss: 3.700658822042784
Validation loss: 2.866722130638347

Epoch: 5| Step: 7
Training loss: 3.1558979706801
Validation loss: 2.8892001351038026

Epoch: 5| Step: 8
Training loss: 2.0822135459007134
Validation loss: 2.880745386170063

Epoch: 5| Step: 9
Training loss: 2.9495566471374732
Validation loss: 2.8713242367501928

Epoch: 5| Step: 10
Training loss: 2.6900193581717713
Validation loss: 2.85311867953441

Epoch: 77| Step: 0
Training loss: 2.2877191240596777
Validation loss: 2.859693701663677

Epoch: 5| Step: 1
Training loss: 2.951733296563314
Validation loss: 2.8646851781973193

Epoch: 5| Step: 2
Training loss: 2.98766716525319
Validation loss: 2.853167069085465

Epoch: 5| Step: 3
Training loss: 3.4720797666360994
Validation loss: 2.8759579776766726

Epoch: 5| Step: 4
Training loss: 2.937134577971151
Validation loss: 2.855567944434107

Epoch: 5| Step: 5
Training loss: 3.111657000136587
Validation loss: 2.892818901911902

Epoch: 5| Step: 6
Training loss: 3.106418143006382
Validation loss: 2.883972430834165

Epoch: 5| Step: 7
Training loss: 2.3250002789240845
Validation loss: 2.888628005606729

Epoch: 5| Step: 8
Training loss: 2.4259578622113067
Validation loss: 2.8828201095979065

Epoch: 5| Step: 9
Training loss: 2.9038758784058762
Validation loss: 2.872706834050544

Epoch: 5| Step: 10
Training loss: 2.7404925985335535
Validation loss: 2.8575701814804653

Epoch: 78| Step: 0
Training loss: 3.087237043418574
Validation loss: 2.876989554544852

Epoch: 5| Step: 1
Training loss: 3.0985415565765826
Validation loss: 2.882480662154666

Epoch: 5| Step: 2
Training loss: 2.725499686527182
Validation loss: 2.8656489998610697

Epoch: 5| Step: 3
Training loss: 2.7468581024448717
Validation loss: 2.879124175221284

Epoch: 5| Step: 4
Training loss: 1.6590106197658807
Validation loss: 2.8683326510727167

Epoch: 5| Step: 5
Training loss: 3.068990874305798
Validation loss: 2.864142811184607

Epoch: 5| Step: 6
Training loss: 3.1772930305359135
Validation loss: 2.8924562728052177

Epoch: 5| Step: 7
Training loss: 2.2713036239751645
Validation loss: 2.872118029285362

Epoch: 5| Step: 8
Training loss: 3.1323987730434735
Validation loss: 2.913429911006151

Epoch: 5| Step: 9
Training loss: 3.127874806828103
Validation loss: 2.8935862938895194

Epoch: 5| Step: 10
Training loss: 2.9018056378361785
Validation loss: 2.8443501085048597

Epoch: 79| Step: 0
Training loss: 2.6013496013968873
Validation loss: 2.887437086339316

Epoch: 5| Step: 1
Training loss: 2.0843218429169807
Validation loss: 2.8677662622969993

Epoch: 5| Step: 2
Training loss: 2.5904982072197784
Validation loss: 2.8522958506715597

Epoch: 5| Step: 3
Training loss: 3.090417782092106
Validation loss: 2.8497508093889388

Epoch: 5| Step: 4
Training loss: 2.7662738965532596
Validation loss: 2.8698196536321716

Epoch: 5| Step: 5
Training loss: 2.525523359995374
Validation loss: 2.861961733670635

Epoch: 5| Step: 6
Training loss: 3.0608673414803707
Validation loss: 2.845908528425439

Epoch: 5| Step: 7
Training loss: 2.3926645193266602
Validation loss: 2.8679940659902456

Epoch: 5| Step: 8
Training loss: 3.0884801505761583
Validation loss: 2.855573830202197

Epoch: 5| Step: 9
Training loss: 3.5839250356974577
Validation loss: 2.8586822447011797

Epoch: 5| Step: 10
Training loss: 3.0976353147936946
Validation loss: 2.8744765113167974

Epoch: 80| Step: 0
Training loss: 2.6526798265713456
Validation loss: 2.879762878369744

Epoch: 5| Step: 1
Training loss: 2.757412284362084
Validation loss: 2.876611041527917

Epoch: 5| Step: 2
Training loss: 3.1253101957862124
Validation loss: 2.909416847971777

Epoch: 5| Step: 3
Training loss: 2.7657350852306926
Validation loss: 2.8771487423766

Epoch: 5| Step: 4
Training loss: 3.389605672176928
Validation loss: 2.8533646693544075

Epoch: 5| Step: 5
Training loss: 2.094598968105523
Validation loss: 2.8943860561452075

Epoch: 5| Step: 6
Training loss: 3.0932471897473506
Validation loss: 2.84411553385725

Epoch: 5| Step: 7
Training loss: 2.691472599446362
Validation loss: 2.833247276340783

Epoch: 5| Step: 8
Training loss: 2.8852584924046516
Validation loss: 2.8717320457960094

Epoch: 5| Step: 9
Training loss: 2.906751199799636
Validation loss: 2.874105107341276

Epoch: 5| Step: 10
Training loss: 2.933214836183589
Validation loss: 2.8697124829316887

Epoch: 81| Step: 0
Training loss: 2.5644776691037947
Validation loss: 2.896654195202757

Epoch: 5| Step: 1
Training loss: 2.877063508256638
Validation loss: 2.8955548783253304

Epoch: 5| Step: 2
Training loss: 3.1863776830364343
Validation loss: 2.873586461433239

Epoch: 5| Step: 3
Training loss: 3.3230603863638857
Validation loss: 2.874988649960264

Epoch: 5| Step: 4
Training loss: 3.1595413118955586
Validation loss: 2.8442399825386313

Epoch: 5| Step: 5
Training loss: 2.7302534157646305
Validation loss: 2.897812183509127

Epoch: 5| Step: 6
Training loss: 2.82511429682059
Validation loss: 2.8493344730025947

Epoch: 5| Step: 7
Training loss: 2.4810608645211127
Validation loss: 2.8521379147329013

Epoch: 5| Step: 8
Training loss: 3.2479863898081387
Validation loss: 2.8796720453679705

Epoch: 5| Step: 9
Training loss: 2.055687258628035
Validation loss: 2.846883668804504

Epoch: 5| Step: 10
Training loss: 2.379815189495
Validation loss: 2.8558534153489257

Epoch: 82| Step: 0
Training loss: 2.901161086377123
Validation loss: 2.8627367328273174

Epoch: 5| Step: 1
Training loss: 2.9717242951794938
Validation loss: 2.8560934375390694

Epoch: 5| Step: 2
Training loss: 2.4640241369576246
Validation loss: 2.8518853935666146

Epoch: 5| Step: 3
Training loss: 2.9928940220253697
Validation loss: 2.852981156503528

Epoch: 5| Step: 4
Training loss: 3.180587153900155
Validation loss: 2.8675493354772033

Epoch: 5| Step: 5
Training loss: 2.768127085447441
Validation loss: 2.8456798947808433

Epoch: 5| Step: 6
Training loss: 2.5802549869003872
Validation loss: 2.806199988751711

Epoch: 5| Step: 7
Training loss: 2.311018804495949
Validation loss: 2.8631982605392725

Epoch: 5| Step: 8
Training loss: 2.175276583043645
Validation loss: 2.871047675252969

Epoch: 5| Step: 9
Training loss: 3.0211472622216378
Validation loss: 2.8537897424427605

Epoch: 5| Step: 10
Training loss: 3.307669230058174
Validation loss: 2.8416604279403423

Epoch: 83| Step: 0
Training loss: 2.5903111837197126
Validation loss: 2.847373789159523

Epoch: 5| Step: 1
Training loss: 2.1162306534254043
Validation loss: 2.8415254386089726

Epoch: 5| Step: 2
Training loss: 3.647383674507987
Validation loss: 2.863715967026869

Epoch: 5| Step: 3
Training loss: 2.795678847280669
Validation loss: 2.858500809147312

Epoch: 5| Step: 4
Training loss: 2.0766861602496913
Validation loss: 2.8698351650374394

Epoch: 5| Step: 5
Training loss: 3.1836803213881173
Validation loss: 2.8538914251282277

Epoch: 5| Step: 6
Training loss: 3.3691958215587277
Validation loss: 2.8625249934033405

Epoch: 5| Step: 7
Training loss: 2.924505345178403
Validation loss: 2.810538703947455

Epoch: 5| Step: 8
Training loss: 2.6010659233635556
Validation loss: 2.8395151742434965

Epoch: 5| Step: 9
Training loss: 3.3814045925373404
Validation loss: 2.85814790907863

Epoch: 5| Step: 10
Training loss: 2.2163160701742424
Validation loss: 2.8672153618742935

Epoch: 84| Step: 0
Training loss: 2.7326720247975396
Validation loss: 2.856525290601574

Epoch: 5| Step: 1
Training loss: 2.902206890016371
Validation loss: 2.8433153166648117

Epoch: 5| Step: 2
Training loss: 3.3834516877267737
Validation loss: 2.856211925978141

Epoch: 5| Step: 3
Training loss: 3.0006927644037824
Validation loss: 2.89329240334299

Epoch: 5| Step: 4
Training loss: 2.4627519004287026
Validation loss: 2.8437373870854774

Epoch: 5| Step: 5
Training loss: 2.7238026289387367
Validation loss: 2.866098755211973

Epoch: 5| Step: 6
Training loss: 2.3940802642637236
Validation loss: 2.8745330174480084

Epoch: 5| Step: 7
Training loss: 2.9838551972362417
Validation loss: 2.8769424746041614

Epoch: 5| Step: 8
Training loss: 2.838024873964585
Validation loss: 2.8551100095688384

Epoch: 5| Step: 9
Training loss: 3.0043044998217017
Validation loss: 2.837358363374497

Epoch: 5| Step: 10
Training loss: 2.292291024437463
Validation loss: 2.844708146611932

Epoch: 85| Step: 0
Training loss: 2.636981594971884
Validation loss: 2.8593954471883856

Epoch: 5| Step: 1
Training loss: 2.7102635669986226
Validation loss: 2.85396679749608

Epoch: 5| Step: 2
Training loss: 3.8071754670925593
Validation loss: 2.860109346661431

Epoch: 5| Step: 3
Training loss: 3.216219453573926
Validation loss: 2.85995100139303

Epoch: 5| Step: 4
Training loss: 2.839493468876102
Validation loss: 2.869937716507092

Epoch: 5| Step: 5
Training loss: 2.81703760951147
Validation loss: 2.933777675529844

Epoch: 5| Step: 6
Training loss: 2.8654974756184797
Validation loss: 2.8641198048178698

Epoch: 5| Step: 7
Training loss: 2.3748287339949603
Validation loss: 2.859853039176988

Epoch: 5| Step: 8
Training loss: 2.469776374794224
Validation loss: 2.867149667288248

Epoch: 5| Step: 9
Training loss: 2.7097625384863764
Validation loss: 2.8509634114875655

Epoch: 5| Step: 10
Training loss: 2.342579256750498
Validation loss: 2.9020054704981746

Epoch: 86| Step: 0
Training loss: 2.9474642960292474
Validation loss: 2.849992017477529

Epoch: 5| Step: 1
Training loss: 2.2157925519553454
Validation loss: 2.8394517766983656

Epoch: 5| Step: 2
Training loss: 3.205172744832757
Validation loss: 2.8221043642247334

Epoch: 5| Step: 3
Training loss: 2.140479535360333
Validation loss: 2.86688388628439

Epoch: 5| Step: 4
Training loss: 3.1275119603795116
Validation loss: 2.8604089535283412

Epoch: 5| Step: 5
Training loss: 3.114173445421585
Validation loss: 2.847884474725863

Epoch: 5| Step: 6
Training loss: 2.483788859001476
Validation loss: 2.834148918142329

Epoch: 5| Step: 7
Training loss: 3.389038699300863
Validation loss: 2.8740187972910243

Epoch: 5| Step: 8
Training loss: 2.7502126611498743
Validation loss: 2.8411681796572923

Epoch: 5| Step: 9
Training loss: 3.079121539689
Validation loss: 2.8617123109135782

Epoch: 5| Step: 10
Training loss: 2.137231294573975
Validation loss: 2.897250913792944

Epoch: 87| Step: 0
Training loss: 2.4803906045453696
Validation loss: 2.878285972097782

Epoch: 5| Step: 1
Training loss: 2.6942179793350274
Validation loss: 2.8586296832948617

Epoch: 5| Step: 2
Training loss: 2.8574222087533983
Validation loss: 2.8519657638201905

Epoch: 5| Step: 3
Training loss: 3.158963085455187
Validation loss: 2.872501901966723

Epoch: 5| Step: 4
Training loss: 3.5317449982330187
Validation loss: 2.8699745414899307

Epoch: 5| Step: 5
Training loss: 2.642419600260631
Validation loss: 2.839037961869204

Epoch: 5| Step: 6
Training loss: 2.3822091761491984
Validation loss: 2.876304172830834

Epoch: 5| Step: 7
Training loss: 2.707751950193979
Validation loss: 2.881224488706485

Epoch: 5| Step: 8
Training loss: 2.322132257557294
Validation loss: 2.850777358791881

Epoch: 5| Step: 9
Training loss: 3.10700415315771
Validation loss: 2.858016547355121

Epoch: 5| Step: 10
Training loss: 2.759394983238708
Validation loss: 2.8430175874804724

Epoch: 88| Step: 0
Training loss: 2.8493066513187926
Validation loss: 2.852992918931985

Epoch: 5| Step: 1
Training loss: 3.197375687724567
Validation loss: 2.8579617311638756

Epoch: 5| Step: 2
Training loss: 2.5465317009151622
Validation loss: 2.816463187534523

Epoch: 5| Step: 3
Training loss: 2.987243871203843
Validation loss: 2.881547904545617

Epoch: 5| Step: 4
Training loss: 2.690324851207228
Validation loss: 2.815009978992556

Epoch: 5| Step: 5
Training loss: 2.7039894089011716
Validation loss: 2.821028523671627

Epoch: 5| Step: 6
Training loss: 2.520278512308124
Validation loss: 2.8292218736480983

Epoch: 5| Step: 7
Training loss: 2.7647740838467603
Validation loss: 2.8363347936998418

Epoch: 5| Step: 8
Training loss: 2.552447255455502
Validation loss: 2.805032622547384

Epoch: 5| Step: 9
Training loss: 2.9395949015850475
Validation loss: 2.8369899808008476

Epoch: 5| Step: 10
Training loss: 3.3057220498976014
Validation loss: 2.8497661430584396

Epoch: 89| Step: 0
Training loss: 3.04514063843914
Validation loss: 2.8842559330188884

Epoch: 5| Step: 1
Training loss: 1.9744036196584305
Validation loss: 2.837689083351983

Epoch: 5| Step: 2
Training loss: 2.762999759537379
Validation loss: 2.8169398904570797

Epoch: 5| Step: 3
Training loss: 2.8918159299761403
Validation loss: 2.8360885516158754

Epoch: 5| Step: 4
Training loss: 2.2988529122960055
Validation loss: 2.845755141408929

Epoch: 5| Step: 5
Training loss: 2.8311943132932473
Validation loss: 2.845441132162947

Epoch: 5| Step: 6
Training loss: 2.95631760888888
Validation loss: 2.856666063098607

Epoch: 5| Step: 7
Training loss: 2.7921960148524074
Validation loss: 2.8660985557450562

Epoch: 5| Step: 8
Training loss: 2.1917001999681727
Validation loss: 2.8076988011893254

Epoch: 5| Step: 9
Training loss: 3.785310188997556
Validation loss: 2.831141796641798

Epoch: 5| Step: 10
Training loss: 3.1177323326532203
Validation loss: 2.8384308956615145

Epoch: 90| Step: 0
Training loss: 3.4007484734163094
Validation loss: 2.8760258403589734

Epoch: 5| Step: 1
Training loss: 2.5562014512206215
Validation loss: 2.828840459958188

Epoch: 5| Step: 2
Training loss: 2.54118619869693
Validation loss: 2.829520711971193

Epoch: 5| Step: 3
Training loss: 2.6677556993082043
Validation loss: 2.8492461628269723

Epoch: 5| Step: 4
Training loss: 2.4026337239247124
Validation loss: 2.867232469061498

Epoch: 5| Step: 5
Training loss: 2.2231780447005858
Validation loss: 2.840077589761172

Epoch: 5| Step: 6
Training loss: 2.916974205878624
Validation loss: 2.842639015980221

Epoch: 5| Step: 7
Training loss: 2.4287645359360193
Validation loss: 2.810873061017691

Epoch: 5| Step: 8
Training loss: 2.7481244367052775
Validation loss: 2.827070355129191

Epoch: 5| Step: 9
Training loss: 3.1675703030968445
Validation loss: 2.8316295189766203

Epoch: 5| Step: 10
Training loss: 3.503545463980205
Validation loss: 2.8409165838744985

Epoch: 91| Step: 0
Training loss: 2.2127470018691713
Validation loss: 2.8522880688592713

Epoch: 5| Step: 1
Training loss: 2.358037506348798
Validation loss: 2.8292327417411984

Epoch: 5| Step: 2
Training loss: 2.4430594012377336
Validation loss: 2.822292428837307

Epoch: 5| Step: 3
Training loss: 2.7488495414304
Validation loss: 2.8560220932940554

Epoch: 5| Step: 4
Training loss: 2.2345102976136855
Validation loss: 2.8445555600622425

Epoch: 5| Step: 5
Training loss: 2.803730665965943
Validation loss: 2.8672452173500713

Epoch: 5| Step: 6
Training loss: 2.446268498073494
Validation loss: 2.824648204638356

Epoch: 5| Step: 7
Training loss: 3.171285941010889
Validation loss: 2.85571325184648

Epoch: 5| Step: 8
Training loss: 2.854150219797979
Validation loss: 2.855694582729442

Epoch: 5| Step: 9
Training loss: 3.9563367258603144
Validation loss: 2.849318057324276

Epoch: 5| Step: 10
Training loss: 3.264335706351258
Validation loss: 2.841352975840855

Epoch: 92| Step: 0
Training loss: 3.5815665007002155
Validation loss: 2.8312637315367466

Epoch: 5| Step: 1
Training loss: 2.261516555418538
Validation loss: 2.843255933275956

Epoch: 5| Step: 2
Training loss: 2.494859942707812
Validation loss: 2.848777014899671

Epoch: 5| Step: 3
Training loss: 2.6541371637817592
Validation loss: 2.808265430548117

Epoch: 5| Step: 4
Training loss: 2.109714508991262
Validation loss: 2.856797271548446

Epoch: 5| Step: 5
Training loss: 2.9333778840352083
Validation loss: 2.8544767076784052

Epoch: 5| Step: 6
Training loss: 2.0118571706019153
Validation loss: 2.816499753218584

Epoch: 5| Step: 7
Training loss: 3.771067378471728
Validation loss: 2.818361581741199

Epoch: 5| Step: 8
Training loss: 2.304810187743424
Validation loss: 2.853515696873182

Epoch: 5| Step: 9
Training loss: 2.3669408285708813
Validation loss: 2.8427905952794044

Epoch: 5| Step: 10
Training loss: 3.3941957858908176
Validation loss: 2.8326932924930053

Epoch: 93| Step: 0
Training loss: 3.123963145860453
Validation loss: 2.8737292198702287

Epoch: 5| Step: 1
Training loss: 3.2229234619332012
Validation loss: 2.8556355402599354

Epoch: 5| Step: 2
Training loss: 2.187934287421686
Validation loss: 2.847676644493538

Epoch: 5| Step: 3
Training loss: 3.095287672980238
Validation loss: 2.835518709581165

Epoch: 5| Step: 4
Training loss: 2.1042785111216062
Validation loss: 2.8542565386330674

Epoch: 5| Step: 5
Training loss: 2.550208408590579
Validation loss: 2.884322248128085

Epoch: 5| Step: 6
Training loss: 2.4054429323273485
Validation loss: 2.8741875294543773

Epoch: 5| Step: 7
Training loss: 3.0578819801105253
Validation loss: 2.8167485805958568

Epoch: 5| Step: 8
Training loss: 2.6480476745163086
Validation loss: 2.872449520254461

Epoch: 5| Step: 9
Training loss: 2.234585838774069
Validation loss: 2.8391460394332957

Epoch: 5| Step: 10
Training loss: 3.4004987406975817
Validation loss: 2.823637253546454

Epoch: 94| Step: 0
Training loss: 2.508566294483923
Validation loss: 2.825765300299291

Epoch: 5| Step: 1
Training loss: 3.0982106736069057
Validation loss: 2.8339683308540193

Epoch: 5| Step: 2
Training loss: 2.6907820953692108
Validation loss: 2.855801213022302

Epoch: 5| Step: 3
Training loss: 3.163209701335658
Validation loss: 2.8503729105112443

Epoch: 5| Step: 4
Training loss: 3.0773348496079085
Validation loss: 2.834578595740412

Epoch: 5| Step: 5
Training loss: 2.947474649852554
Validation loss: 2.8623501613899656

Epoch: 5| Step: 6
Training loss: 2.227839160791232
Validation loss: 2.864472039858387

Epoch: 5| Step: 7
Training loss: 2.626657870692647
Validation loss: 2.8567064190726303

Epoch: 5| Step: 8
Training loss: 2.3801666078033485
Validation loss: 2.8358792919066937

Epoch: 5| Step: 9
Training loss: 2.407181002357902
Validation loss: 2.8368375375944503

Epoch: 5| Step: 10
Training loss: 3.259391420346791
Validation loss: 2.796603042653911

Epoch: 95| Step: 0
Training loss: 2.4140316859380473
Validation loss: 2.846631104816648

Epoch: 5| Step: 1
Training loss: 2.2796760250270767
Validation loss: 2.8371002887884855

Epoch: 5| Step: 2
Training loss: 2.53799378424831
Validation loss: 2.803730431887814

Epoch: 5| Step: 3
Training loss: 3.006446429078757
Validation loss: 2.8479614409364036

Epoch: 5| Step: 4
Training loss: 3.1616571019305666
Validation loss: 2.860427296115668

Epoch: 5| Step: 5
Training loss: 2.607687672986819
Validation loss: 2.844519065726316

Epoch: 5| Step: 6
Training loss: 3.7910650565507957
Validation loss: 2.83087432483411

Epoch: 5| Step: 7
Training loss: 2.8230997192791287
Validation loss: 2.8241740146768515

Epoch: 5| Step: 8
Training loss: 3.165674924315576
Validation loss: 2.8641984238352607

Epoch: 5| Step: 9
Training loss: 2.1703706649774768
Validation loss: 2.836099791125474

Epoch: 5| Step: 10
Training loss: 1.672824198002981
Validation loss: 2.8350874581893644

Epoch: 96| Step: 0
Training loss: 2.6708985267653094
Validation loss: 2.8341111744723464

Epoch: 5| Step: 1
Training loss: 2.5503457414694766
Validation loss: 2.8169828977789995

Epoch: 5| Step: 2
Training loss: 2.7616581458277025
Validation loss: 2.809818103928658

Epoch: 5| Step: 3
Training loss: 2.5761329121567877
Validation loss: 2.8435095769143044

Epoch: 5| Step: 4
Training loss: 2.730530919580147
Validation loss: 2.823374931071237

Epoch: 5| Step: 5
Training loss: 2.694534853000726
Validation loss: 2.8165377620212477

Epoch: 5| Step: 6
Training loss: 3.247340654864431
Validation loss: 2.824408374805733

Epoch: 5| Step: 7
Training loss: 2.5418879824312226
Validation loss: 2.8374254867862363

Epoch: 5| Step: 8
Training loss: 3.3664483411897064
Validation loss: 2.811147813691018

Epoch: 5| Step: 9
Training loss: 2.50556345832896
Validation loss: 2.804794285268098

Epoch: 5| Step: 10
Training loss: 3.014534392329778
Validation loss: 2.834213281853265

Epoch: 97| Step: 0
Training loss: 2.861339290453898
Validation loss: 2.8045870507906896

Epoch: 5| Step: 1
Training loss: 3.03532246216787
Validation loss: 2.820069470599696

Epoch: 5| Step: 2
Training loss: 2.375094562454941
Validation loss: 2.828800195828059

Epoch: 5| Step: 3
Training loss: 2.5036035316046217
Validation loss: 2.8307754143470722

Epoch: 5| Step: 4
Training loss: 2.8062955449068028
Validation loss: 2.827820344446022

Epoch: 5| Step: 5
Training loss: 3.1017039384469536
Validation loss: 2.8556548166364757

Epoch: 5| Step: 6
Training loss: 2.360412975643961
Validation loss: 2.8524745281122903

Epoch: 5| Step: 7
Training loss: 2.6176222710529404
Validation loss: 2.815080272618728

Epoch: 5| Step: 8
Training loss: 2.7240597843998167
Validation loss: 2.844172443978339

Epoch: 5| Step: 9
Training loss: 3.2855118458147823
Validation loss: 2.8216261997081546

Epoch: 5| Step: 10
Training loss: 2.248863038916322
Validation loss: 2.8212698966184644

Epoch: 98| Step: 0
Training loss: 1.8608329890937447
Validation loss: 2.8283229992669066

Epoch: 5| Step: 1
Training loss: 3.7281516343577885
Validation loss: 2.8695450546482797

Epoch: 5| Step: 2
Training loss: 3.5790921032872953
Validation loss: 2.8282107445194016

Epoch: 5| Step: 3
Training loss: 2.4600212207902357
Validation loss: 2.8226002114433757

Epoch: 5| Step: 4
Training loss: 2.41300817879193
Validation loss: 2.8351118024249073

Epoch: 5| Step: 5
Training loss: 2.729894225618045
Validation loss: 2.8673906116040944

Epoch: 5| Step: 6
Training loss: 2.423144001899778
Validation loss: 2.808782374218914

Epoch: 5| Step: 7
Training loss: 2.5881225942615713
Validation loss: 2.8267322066479745

Epoch: 5| Step: 8
Training loss: 2.7386027758195977
Validation loss: 2.845868578746187

Epoch: 5| Step: 9
Training loss: 2.2841523402461905
Validation loss: 2.849284946761803

Epoch: 5| Step: 10
Training loss: 2.992795558728938
Validation loss: 2.849552764191938

Epoch: 99| Step: 0
Training loss: 2.6279043751393827
Validation loss: 2.843043593319515

Epoch: 5| Step: 1
Training loss: 3.5939737001538368
Validation loss: 2.784524952571158

Epoch: 5| Step: 2
Training loss: 3.1102756748493485
Validation loss: 2.8161685239037126

Epoch: 5| Step: 3
Training loss: 2.905283941682691
Validation loss: 2.8120331115771013

Epoch: 5| Step: 4
Training loss: 2.1170409880333985
Validation loss: 2.806177504961285

Epoch: 5| Step: 5
Training loss: 3.0291887334118677
Validation loss: 2.841867181722767

Epoch: 5| Step: 6
Training loss: 2.249293534313256
Validation loss: 2.821130835579608

Epoch: 5| Step: 7
Training loss: 2.244612495606342
Validation loss: 2.8442427956340506

Epoch: 5| Step: 8
Training loss: 2.757576389309496
Validation loss: 2.8301914370489123

Epoch: 5| Step: 9
Training loss: 2.979583568790814
Validation loss: 2.845091647403858

Epoch: 5| Step: 10
Training loss: 2.5395176875637664
Validation loss: 2.7856132913454243

Epoch: 100| Step: 0
Training loss: 3.2370100851058003
Validation loss: 2.807199686261793

Epoch: 5| Step: 1
Training loss: 2.416694662874666
Validation loss: 2.781961491754462

Epoch: 5| Step: 2
Training loss: 2.3241368896429737
Validation loss: 2.781107794847902

Epoch: 5| Step: 3
Training loss: 2.8085247344343336
Validation loss: 2.8436362762050824

Epoch: 5| Step: 4
Training loss: 3.666420899448679
Validation loss: 2.7981294096806884

Epoch: 5| Step: 5
Training loss: 2.758748357691965
Validation loss: 2.8698478910448295

Epoch: 5| Step: 6
Training loss: 3.023458160408657
Validation loss: 2.802733399937426

Epoch: 5| Step: 7
Training loss: 2.1885946532172897
Validation loss: 2.7968029829414336

Epoch: 5| Step: 8
Training loss: 2.452837787507056
Validation loss: 2.8056214728690616

Epoch: 5| Step: 9
Training loss: 3.022324625864006
Validation loss: 2.830539410409584

Epoch: 5| Step: 10
Training loss: 2.3819465439481045
Validation loss: 2.8346485252928346

Epoch: 101| Step: 0
Training loss: 3.3575761103862014
Validation loss: 2.813307308335102

Epoch: 5| Step: 1
Training loss: 2.2632389526839187
Validation loss: 2.791189340867732

Epoch: 5| Step: 2
Training loss: 3.2237791012607526
Validation loss: 2.8022209603638357

Epoch: 5| Step: 3
Training loss: 2.968894714040746
Validation loss: 2.827632703704312

Epoch: 5| Step: 4
Training loss: 2.0047848208821692
Validation loss: 2.828101505736493

Epoch: 5| Step: 5
Training loss: 2.284326647287193
Validation loss: 2.8129102947708495

Epoch: 5| Step: 6
Training loss: 3.3650663204374416
Validation loss: 2.855359142642907

Epoch: 5| Step: 7
Training loss: 2.548233886667805
Validation loss: 2.8130256644694738

Epoch: 5| Step: 8
Training loss: 2.6115079830660437
Validation loss: 2.7902786491013725

Epoch: 5| Step: 9
Training loss: 2.10082881557287
Validation loss: 2.804516978636861

Epoch: 5| Step: 10
Training loss: 2.8844335283517943
Validation loss: 2.830897970411969

Epoch: 102| Step: 0
Training loss: 2.605238142202722
Validation loss: 2.813484169189666

Epoch: 5| Step: 1
Training loss: 2.4577536680791554
Validation loss: 2.853832911291934

Epoch: 5| Step: 2
Training loss: 2.8229107921206076
Validation loss: 2.8144371790175624

Epoch: 5| Step: 3
Training loss: 2.958561167652151
Validation loss: 2.82499457393368

Epoch: 5| Step: 4
Training loss: 2.3891821602393377
Validation loss: 2.7987868731026473

Epoch: 5| Step: 5
Training loss: 2.3547735754125454
Validation loss: 2.8442301118956874

Epoch: 5| Step: 6
Training loss: 2.703135054905884
Validation loss: 2.866060779323073

Epoch: 5| Step: 7
Training loss: 3.1476537898080794
Validation loss: 2.813906645318876

Epoch: 5| Step: 8
Training loss: 2.896043307881546
Validation loss: 2.8333146066306165

Epoch: 5| Step: 9
Training loss: 2.623631165872473
Validation loss: 2.808307404969129

Epoch: 5| Step: 10
Training loss: 2.8055620025543906
Validation loss: 2.8251476697906255

Epoch: 103| Step: 0
Training loss: 2.905600362383194
Validation loss: 2.8427817269225946

Epoch: 5| Step: 1
Training loss: 2.291505414896025
Validation loss: 2.8314664784061256

Epoch: 5| Step: 2
Training loss: 2.8927653868317686
Validation loss: 2.841732190484894

Epoch: 5| Step: 3
Training loss: 2.4451858438956626
Validation loss: 2.7940186428212357

Epoch: 5| Step: 4
Training loss: 2.2123675894043857
Validation loss: 2.793126938511734

Epoch: 5| Step: 5
Training loss: 3.37168410558963
Validation loss: 2.822219343544347

Epoch: 5| Step: 6
Training loss: 2.0282996245033065
Validation loss: 2.775932467934321

Epoch: 5| Step: 7
Training loss: 2.7858341456746905
Validation loss: 2.831957945308122

Epoch: 5| Step: 8
Training loss: 3.101035892548256
Validation loss: 2.8093469508231115

Epoch: 5| Step: 9
Training loss: 3.036235367106406
Validation loss: 2.8204150723934225

Epoch: 5| Step: 10
Training loss: 2.546210734795443
Validation loss: 2.81727976389914

Epoch: 104| Step: 0
Training loss: 2.3880295969983574
Validation loss: 2.804564929762914

Epoch: 5| Step: 1
Training loss: 3.653471844917714
Validation loss: 2.8183970549143287

Epoch: 5| Step: 2
Training loss: 2.7290050856730543
Validation loss: 2.8063469835922956

Epoch: 5| Step: 3
Training loss: 2.552813014341992
Validation loss: 2.760178325174668

Epoch: 5| Step: 4
Training loss: 3.079823756191523
Validation loss: 2.8167792704103087

Epoch: 5| Step: 5
Training loss: 2.4229735805379438
Validation loss: 2.772034824913937

Epoch: 5| Step: 6
Training loss: 2.8450926241688683
Validation loss: 2.817364136892781

Epoch: 5| Step: 7
Training loss: 1.7860903643636992
Validation loss: 2.7693101105697306

Epoch: 5| Step: 8
Training loss: 3.127211589245853
Validation loss: 2.805973081576149

Epoch: 5| Step: 9
Training loss: 2.94193695670913
Validation loss: 2.8154019441725513

Epoch: 5| Step: 10
Training loss: 2.266080297564176
Validation loss: 2.7923313892873156

Epoch: 105| Step: 0
Training loss: 3.2126645829013967
Validation loss: 2.7808680118225313

Epoch: 5| Step: 1
Training loss: 2.513774594073293
Validation loss: 2.794278251319208

Epoch: 5| Step: 2
Training loss: 2.9256252761641846
Validation loss: 2.798172062954594

Epoch: 5| Step: 3
Training loss: 2.0107443218025343
Validation loss: 2.8193390818802975

Epoch: 5| Step: 4
Training loss: 2.539819410917966
Validation loss: 2.8044578075887956

Epoch: 5| Step: 5
Training loss: 3.10690101847462
Validation loss: 2.7991863001196564

Epoch: 5| Step: 6
Training loss: 3.1977337382098967
Validation loss: 2.7879316303597914

Epoch: 5| Step: 7
Training loss: 2.740819171216715
Validation loss: 2.786975865360174

Epoch: 5| Step: 8
Training loss: 2.5694500714031387
Validation loss: 2.793108191588713

Epoch: 5| Step: 9
Training loss: 2.2050329293281283
Validation loss: 2.8021157220103907

Epoch: 5| Step: 10
Training loss: 2.7218483118791976
Validation loss: 2.821828441621668

Epoch: 106| Step: 0
Training loss: 2.1288163192372953
Validation loss: 2.8531343113881698

Epoch: 5| Step: 1
Training loss: 3.9258906866354093
Validation loss: 2.7963825222367866

Epoch: 5| Step: 2
Training loss: 2.5491182710215234
Validation loss: 2.8160987208108876

Epoch: 5| Step: 3
Training loss: 2.532883858543289
Validation loss: 2.8080708228004263

Epoch: 5| Step: 4
Training loss: 2.7049042243008126
Validation loss: 2.8266414471612022

Epoch: 5| Step: 5
Training loss: 2.6109183310188007
Validation loss: 2.8236533663812344

Epoch: 5| Step: 6
Training loss: 2.6701570754691986
Validation loss: 2.8173488689186432

Epoch: 5| Step: 7
Training loss: 2.7740115149272055
Validation loss: 2.8184906257962594

Epoch: 5| Step: 8
Training loss: 3.0732141038298186
Validation loss: 2.842150505527944

Epoch: 5| Step: 9
Training loss: 2.642584891638371
Validation loss: 2.828293616694078

Epoch: 5| Step: 10
Training loss: 2.220323461388759
Validation loss: 2.8277635249851496

Epoch: 107| Step: 0
Training loss: 2.8005485065538562
Validation loss: 2.8377616094230773

Epoch: 5| Step: 1
Training loss: 2.802776567626665
Validation loss: 2.85766478333207

Epoch: 5| Step: 2
Training loss: 3.3828917179126603
Validation loss: 2.8597147427241083

Epoch: 5| Step: 3
Training loss: 2.01498118919509
Validation loss: 2.804978677442186

Epoch: 5| Step: 4
Training loss: 3.1211655552401854
Validation loss: 2.7925417016487604

Epoch: 5| Step: 5
Training loss: 2.6883248238883133
Validation loss: 2.765060130973832

Epoch: 5| Step: 6
Training loss: 2.142598377225958
Validation loss: 2.7737367668724024

Epoch: 5| Step: 7
Training loss: 2.857600093767222
Validation loss: 2.8348698681179707

Epoch: 5| Step: 8
Training loss: 2.6496893250793945
Validation loss: 2.78125089134026

Epoch: 5| Step: 9
Training loss: 2.2352341287346187
Validation loss: 2.8014514727757263

Epoch: 5| Step: 10
Training loss: 2.973907327743477
Validation loss: 2.8262234934593797

Epoch: 108| Step: 0
Training loss: 2.08463615371402
Validation loss: 2.7525022156835295

Epoch: 5| Step: 1
Training loss: 3.102517084386665
Validation loss: 2.7964066020236107

Epoch: 5| Step: 2
Training loss: 2.373413961769699
Validation loss: 2.820164980424937

Epoch: 5| Step: 3
Training loss: 2.0020620921182792
Validation loss: 2.8098288445242283

Epoch: 5| Step: 4
Training loss: 2.561398711460171
Validation loss: 2.7802809736675704

Epoch: 5| Step: 5
Training loss: 2.394614885621371
Validation loss: 2.807971905186944

Epoch: 5| Step: 6
Training loss: 3.139054394374957
Validation loss: 2.8272094187244368

Epoch: 5| Step: 7
Training loss: 3.2216511216621564
Validation loss: 2.77224085110074

Epoch: 5| Step: 8
Training loss: 2.455197764586882
Validation loss: 2.7915280956196815

Epoch: 5| Step: 9
Training loss: 3.2679585419526647
Validation loss: 2.819431836793635

Epoch: 5| Step: 10
Training loss: 2.884857692811879
Validation loss: 2.8106866311648138

Epoch: 109| Step: 0
Training loss: 2.6956665691068946
Validation loss: 2.786159965787942

Epoch: 5| Step: 1
Training loss: 2.661244980434201
Validation loss: 2.800938430727785

Epoch: 5| Step: 2
Training loss: 2.6495998836247794
Validation loss: 2.829245552518026

Epoch: 5| Step: 3
Training loss: 1.8045677376514129
Validation loss: 2.8127812553704983

Epoch: 5| Step: 4
Training loss: 2.1119757549165827
Validation loss: 2.8142618073291406

Epoch: 5| Step: 5
Training loss: 3.379395906987962
Validation loss: 2.783822822254289

Epoch: 5| Step: 6
Training loss: 3.2663757337391486
Validation loss: 2.829530253394198

Epoch: 5| Step: 7
Training loss: 2.2548432675045826
Validation loss: 2.84780702481983

Epoch: 5| Step: 8
Training loss: 3.3262535887092803
Validation loss: 2.8156364298738246

Epoch: 5| Step: 9
Training loss: 2.35866055818841
Validation loss: 2.7809023647347058

Epoch: 5| Step: 10
Training loss: 2.7322998892199495
Validation loss: 2.7906348725103753

Epoch: 110| Step: 0
Training loss: 3.0966143978650202
Validation loss: 2.835298225752616

Epoch: 5| Step: 1
Training loss: 2.3013835435998486
Validation loss: 2.8034641187817013

Epoch: 5| Step: 2
Training loss: 2.7611719693598697
Validation loss: 2.794464829084026

Epoch: 5| Step: 3
Training loss: 2.4786261495562245
Validation loss: 2.8035059483660167

Epoch: 5| Step: 4
Training loss: 2.265272441925037
Validation loss: 2.7677083595405523

Epoch: 5| Step: 5
Training loss: 2.3388648429333236
Validation loss: 2.789737588347063

Epoch: 5| Step: 6
Training loss: 3.1240992964668344
Validation loss: 2.791199349483597

Epoch: 5| Step: 7
Training loss: 3.0819990690651986
Validation loss: 2.7943089145243354

Epoch: 5| Step: 8
Training loss: 2.399010108414439
Validation loss: 2.8146569534439765

Epoch: 5| Step: 9
Training loss: 3.448251867375255
Validation loss: 2.796480998142298

Epoch: 5| Step: 10
Training loss: 2.932929196116673
Validation loss: 2.824099827929971

Epoch: 111| Step: 0
Training loss: 2.8458832505085137
Validation loss: 2.795839722245543

Epoch: 5| Step: 1
Training loss: 3.5023172064819224
Validation loss: 2.7728238453061818

Epoch: 5| Step: 2
Training loss: 2.814124930714944
Validation loss: 2.7912535057874117

Epoch: 5| Step: 3
Training loss: 2.559786220207473
Validation loss: 2.778298500912998

Epoch: 5| Step: 4
Training loss: 2.8584239607995263
Validation loss: 2.8209553592854095

Epoch: 5| Step: 5
Training loss: 2.2720578126670903
Validation loss: 2.785408153486105

Epoch: 5| Step: 6
Training loss: 2.7537885059048937
Validation loss: 2.774545687390065

Epoch: 5| Step: 7
Training loss: 2.6297105576246076
Validation loss: 2.7695165366162304

Epoch: 5| Step: 8
Training loss: 2.0197030147503736
Validation loss: 2.7995619455372442

Epoch: 5| Step: 9
Training loss: 2.415348734979312
Validation loss: 2.7999878004866017

Epoch: 5| Step: 10
Training loss: 2.787641489175764
Validation loss: 2.747459920277533

Epoch: 112| Step: 0
Training loss: 2.412772120807475
Validation loss: 2.801067204802629

Epoch: 5| Step: 1
Training loss: 2.4872119947699454
Validation loss: 2.8033912220861974

Epoch: 5| Step: 2
Training loss: 3.11714986907502
Validation loss: 2.8041868745364935

Epoch: 5| Step: 3
Training loss: 3.1991652413203
Validation loss: 2.796127497178307

Epoch: 5| Step: 4
Training loss: 2.9378992986176975
Validation loss: 2.8013674226358294

Epoch: 5| Step: 5
Training loss: 2.8034323431334767
Validation loss: 2.779877695916864

Epoch: 5| Step: 6
Training loss: 2.9641237854843085
Validation loss: 2.8082448721643525

Epoch: 5| Step: 7
Training loss: 2.193750552098566
Validation loss: 2.7729939664324323

Epoch: 5| Step: 8
Training loss: 1.728637966848023
Validation loss: 2.8261512037673095

Epoch: 5| Step: 9
Training loss: 2.8327805783997615
Validation loss: 2.850680956386162

Epoch: 5| Step: 10
Training loss: 2.4439994040830295
Validation loss: 2.79483872234597

Epoch: 113| Step: 0
Training loss: 3.1352985820311163
Validation loss: 2.749399385278322

Epoch: 5| Step: 1
Training loss: 3.1700602634610293
Validation loss: 2.821940828517927

Epoch: 5| Step: 2
Training loss: 2.1996087766797934
Validation loss: 2.8430943058248737

Epoch: 5| Step: 3
Training loss: 2.5646477049478715
Validation loss: 2.7751566814492334

Epoch: 5| Step: 4
Training loss: 2.7039497308064946
Validation loss: 2.7942520044786456

Epoch: 5| Step: 5
Training loss: 2.6481623773950838
Validation loss: 2.827090492783256

Epoch: 5| Step: 6
Training loss: 2.660602638557489
Validation loss: 2.8541332928854777

Epoch: 5| Step: 7
Training loss: 3.1467363859254758
Validation loss: 2.8257411631388543

Epoch: 5| Step: 8
Training loss: 2.433921828588972
Validation loss: 2.8466642831705595

Epoch: 5| Step: 9
Training loss: 2.7741833181006585
Validation loss: 2.7906294928406163

Epoch: 5| Step: 10
Training loss: 2.0132407347540426
Validation loss: 2.845411309190185

Epoch: 114| Step: 0
Training loss: 2.518014187925088
Validation loss: 2.814191602575377

Epoch: 5| Step: 1
Training loss: 2.4502859999658035
Validation loss: 2.810065015939086

Epoch: 5| Step: 2
Training loss: 2.5800136237561015
Validation loss: 2.788059491680301

Epoch: 5| Step: 3
Training loss: 2.859966279477955
Validation loss: 2.841407009905557

Epoch: 5| Step: 4
Training loss: 2.7443308048255948
Validation loss: 2.781235970801301

Epoch: 5| Step: 5
Training loss: 2.6633237110802814
Validation loss: 2.7645924293301722

Epoch: 5| Step: 6
Training loss: 2.7965205303593232
Validation loss: 2.8061997430032384

Epoch: 5| Step: 7
Training loss: 2.462603583311536
Validation loss: 2.777716623439793

Epoch: 5| Step: 8
Training loss: 2.531553462169766
Validation loss: 2.7838648557949375

Epoch: 5| Step: 9
Training loss: 3.57849918724393
Validation loss: 2.7569258817467617

Epoch: 5| Step: 10
Training loss: 2.239251317689829
Validation loss: 2.767174419005912

Epoch: 115| Step: 0
Training loss: 1.8783554570481225
Validation loss: 2.787756839704363

Epoch: 5| Step: 1
Training loss: 2.825906631687541
Validation loss: 2.7806501802922075

Epoch: 5| Step: 2
Training loss: 1.9704656845430706
Validation loss: 2.8175376785972985

Epoch: 5| Step: 3
Training loss: 3.7159918806892773
Validation loss: 2.771228944926944

Epoch: 5| Step: 4
Training loss: 2.653904676057912
Validation loss: 2.7760377292196874

Epoch: 5| Step: 5
Training loss: 1.9897635879215605
Validation loss: 2.8213650050714163

Epoch: 5| Step: 6
Training loss: 3.7629320321170456
Validation loss: 2.800623615575039

Epoch: 5| Step: 7
Training loss: 2.6662007361902855
Validation loss: 2.8358626491804944

Epoch: 5| Step: 8
Training loss: 2.3644074586056565
Validation loss: 2.764614871124682

Epoch: 5| Step: 9
Training loss: 2.6485577671347116
Validation loss: 2.783892506379801

Epoch: 5| Step: 10
Training loss: 2.4616493769791594
Validation loss: 2.7608345376388006

Epoch: 116| Step: 0
Training loss: 3.1896195190157752
Validation loss: 2.8140888024280155

Epoch: 5| Step: 1
Training loss: 2.0466669573871683
Validation loss: 2.808917673949476

Epoch: 5| Step: 2
Training loss: 2.6894947899255395
Validation loss: 2.750753661142691

Epoch: 5| Step: 3
Training loss: 2.4598218538552454
Validation loss: 2.8469259158093

Epoch: 5| Step: 4
Training loss: 3.073973824076249
Validation loss: 2.8082763733529146

Epoch: 5| Step: 5
Training loss: 2.4614824932869825
Validation loss: 2.753807864951354

Epoch: 5| Step: 6
Training loss: 2.028142694475429
Validation loss: 2.758751809952834

Epoch: 5| Step: 7
Training loss: 3.2901815291301033
Validation loss: 2.8214463973623114

Epoch: 5| Step: 8
Training loss: 2.3566952069760707
Validation loss: 2.7606784556339363

Epoch: 5| Step: 9
Training loss: 2.9999725022645225
Validation loss: 2.7846691466920515

Epoch: 5| Step: 10
Training loss: 2.2893561998283234
Validation loss: 2.810382637574361

Epoch: 117| Step: 0
Training loss: 3.3934918777910443
Validation loss: 2.769471676743744

Epoch: 5| Step: 1
Training loss: 2.33988002436928
Validation loss: 2.797058484425907

Epoch: 5| Step: 2
Training loss: 2.6585100320508737
Validation loss: 2.7841270897225283

Epoch: 5| Step: 3
Training loss: 3.0817875638869436
Validation loss: 2.7824620178523767

Epoch: 5| Step: 4
Training loss: 2.6212346455529536
Validation loss: 2.770553294064665

Epoch: 5| Step: 5
Training loss: 2.223804143940169
Validation loss: 2.752680498515125

Epoch: 5| Step: 6
Training loss: 2.8469733111326767
Validation loss: 2.840906982331598

Epoch: 5| Step: 7
Training loss: 2.613519905722438
Validation loss: 2.784452689746948

Epoch: 5| Step: 8
Training loss: 2.129194943513372
Validation loss: 2.7617782352209184

Epoch: 5| Step: 9
Training loss: 2.711060095221938
Validation loss: 2.7591479140317072

Epoch: 5| Step: 10
Training loss: 2.647846347246284
Validation loss: 2.782775416343639

Epoch: 118| Step: 0
Training loss: 3.2402012635344812
Validation loss: 2.777294148281324

Epoch: 5| Step: 1
Training loss: 2.178262552435994
Validation loss: 2.7997886535102317

Epoch: 5| Step: 2
Training loss: 2.5048736750564333
Validation loss: 2.8055391006233554

Epoch: 5| Step: 3
Training loss: 3.350410743698339
Validation loss: 2.803308774247388

Epoch: 5| Step: 4
Training loss: 2.574876900850779
Validation loss: 2.7713491561236934

Epoch: 5| Step: 5
Training loss: 2.2491497976606394
Validation loss: 2.767708957909837

Epoch: 5| Step: 6
Training loss: 2.999320589062076
Validation loss: 2.7923211836643405

Epoch: 5| Step: 7
Training loss: 2.7627904126548963
Validation loss: 2.777989941530721

Epoch: 5| Step: 8
Training loss: 2.3250971825090607
Validation loss: 2.784771837479497

Epoch: 5| Step: 9
Training loss: 2.0609853558193603
Validation loss: 2.7832757712013247

Epoch: 5| Step: 10
Training loss: 3.1793601127622417
Validation loss: 2.7976272899437573

Epoch: 119| Step: 0
Training loss: 2.597014154224507
Validation loss: 2.8047747544012123

Epoch: 5| Step: 1
Training loss: 2.3511228435554536
Validation loss: 2.800461506788408

Epoch: 5| Step: 2
Training loss: 2.1650048142659353
Validation loss: 2.75411791418941

Epoch: 5| Step: 3
Training loss: 2.2112211982227112
Validation loss: 2.8079990481464523

Epoch: 5| Step: 4
Training loss: 2.847773796763742
Validation loss: 2.7575455212484083

Epoch: 5| Step: 5
Training loss: 2.865135685235869
Validation loss: 2.8231009760812977

Epoch: 5| Step: 6
Training loss: 2.486389974467613
Validation loss: 2.77591252343542

Epoch: 5| Step: 7
Training loss: 3.2609097693908806
Validation loss: 2.795701773131681

Epoch: 5| Step: 8
Training loss: 2.888393881358148
Validation loss: 2.7853604800310636

Epoch: 5| Step: 9
Training loss: 3.1183139228590475
Validation loss: 2.8038045029249647

Epoch: 5| Step: 10
Training loss: 2.58528299490739
Validation loss: 2.7844052365563288

Epoch: 120| Step: 0
Training loss: 2.120848808406987
Validation loss: 2.73643312033714

Epoch: 5| Step: 1
Training loss: 2.6135858606276554
Validation loss: 2.7715184168744895

Epoch: 5| Step: 2
Training loss: 2.5342625716515594
Validation loss: 2.7930898061732337

Epoch: 5| Step: 3
Training loss: 2.820023455826627
Validation loss: 2.8097708400759016

Epoch: 5| Step: 4
Training loss: 2.656607390651461
Validation loss: 2.810696937929625

Epoch: 5| Step: 5
Training loss: 2.6249375108819555
Validation loss: 2.8045932702416203

Epoch: 5| Step: 6
Training loss: 2.326371217220872
Validation loss: 2.7939036618482875

Epoch: 5| Step: 7
Training loss: 2.5813750155935056
Validation loss: 2.8010545635192283

Epoch: 5| Step: 8
Training loss: 2.710002023196433
Validation loss: 2.7622913235193303

Epoch: 5| Step: 9
Training loss: 3.27272262596995
Validation loss: 2.7726398795992364

Epoch: 5| Step: 10
Training loss: 2.8152201743606047
Validation loss: 2.7476728610605257

Epoch: 121| Step: 0
Training loss: 2.458185794950483
Validation loss: 2.81720846592167

Epoch: 5| Step: 1
Training loss: 2.833582044418974
Validation loss: 2.8047115761241703

Epoch: 5| Step: 2
Training loss: 2.145866714761085
Validation loss: 2.7734640140701714

Epoch: 5| Step: 3
Training loss: 2.695342752038107
Validation loss: 2.8453619606330625

Epoch: 5| Step: 4
Training loss: 2.752214840315377
Validation loss: 2.8149265427052876

Epoch: 5| Step: 5
Training loss: 2.9372373422922524
Validation loss: 2.790549110740613

Epoch: 5| Step: 6
Training loss: 3.108291207063018
Validation loss: 2.8099463223541084

Epoch: 5| Step: 7
Training loss: 1.8129158200742965
Validation loss: 2.8050677734985334

Epoch: 5| Step: 8
Training loss: 2.644571098354228
Validation loss: 2.814204139299532

Epoch: 5| Step: 9
Training loss: 2.9673924604821598
Validation loss: 2.8225781552938094

Epoch: 5| Step: 10
Training loss: 2.899901644913306
Validation loss: 2.8137065764967155

Epoch: 122| Step: 0
Training loss: 2.776548805696788
Validation loss: 2.8011024448703887

Epoch: 5| Step: 1
Training loss: 2.762421212432134
Validation loss: 2.802411654669741

Epoch: 5| Step: 2
Training loss: 2.298686967144222
Validation loss: 2.7941280763898084

Epoch: 5| Step: 3
Training loss: 3.070179089469938
Validation loss: 2.750507965978354

Epoch: 5| Step: 4
Training loss: 2.512823499663318
Validation loss: 2.752464762555239

Epoch: 5| Step: 5
Training loss: 2.3761746362798357
Validation loss: 2.8249095022719835

Epoch: 5| Step: 6
Training loss: 2.2120288541198416
Validation loss: 2.8158775721909874

Epoch: 5| Step: 7
Training loss: 2.3241189374248106
Validation loss: 2.802393644068429

Epoch: 5| Step: 8
Training loss: 3.1660648744530815
Validation loss: 2.804625166191956

Epoch: 5| Step: 9
Training loss: 2.8597978789927456
Validation loss: 2.7891050207795773

Epoch: 5| Step: 10
Training loss: 2.3385726711424026
Validation loss: 2.7724922016969558

Epoch: 123| Step: 0
Training loss: 3.1722634364217916
Validation loss: 2.743514922877918

Epoch: 5| Step: 1
Training loss: 2.5135859405838272
Validation loss: 2.7664050830566

Epoch: 5| Step: 2
Training loss: 2.0050117165087595
Validation loss: 2.732176823154659

Epoch: 5| Step: 3
Training loss: 2.960487512702293
Validation loss: 2.7761627049593915

Epoch: 5| Step: 4
Training loss: 2.335779701440114
Validation loss: 2.7869764338364824

Epoch: 5| Step: 5
Training loss: 2.904158629338341
Validation loss: 2.7591122672627075

Epoch: 5| Step: 6
Training loss: 1.8898204636449996
Validation loss: 2.79590444612993

Epoch: 5| Step: 7
Training loss: 2.5082928444096497
Validation loss: 2.7735507681405793

Epoch: 5| Step: 8
Training loss: 2.8440749433383776
Validation loss: 2.7705175358757668

Epoch: 5| Step: 9
Training loss: 3.000054517886388
Validation loss: 2.773077860092805

Epoch: 5| Step: 10
Training loss: 2.7140701179639057
Validation loss: 2.7523316755791956

Epoch: 124| Step: 0
Training loss: 2.8368779244148357
Validation loss: 2.7665611700153745

Epoch: 5| Step: 1
Training loss: 2.674064408444616
Validation loss: 2.7483238004127855

Epoch: 5| Step: 2
Training loss: 2.2800092066194133
Validation loss: 2.779982066388411

Epoch: 5| Step: 3
Training loss: 2.670971277000379
Validation loss: 2.7703415835773497

Epoch: 5| Step: 4
Training loss: 2.918611550161704
Validation loss: 2.7851707537393553

Epoch: 5| Step: 5
Training loss: 2.63982022453634
Validation loss: 2.7755026219032835

Epoch: 5| Step: 6
Training loss: 2.005505375514676
Validation loss: 2.793031480714184

Epoch: 5| Step: 7
Training loss: 2.658770184711549
Validation loss: 2.7501698979373557

Epoch: 5| Step: 8
Training loss: 2.742994662439241
Validation loss: 2.7971919820741236

Epoch: 5| Step: 9
Training loss: 2.791048598311611
Validation loss: 2.7630198065237885

Epoch: 5| Step: 10
Training loss: 2.5076976524033237
Validation loss: 2.802054438038126

Epoch: 125| Step: 0
Training loss: 1.9614599375448962
Validation loss: 2.778153269283524

Epoch: 5| Step: 1
Training loss: 3.0383303037270157
Validation loss: 2.7830117538049657

Epoch: 5| Step: 2
Training loss: 2.6091306651955866
Validation loss: 2.799667145278977

Epoch: 5| Step: 3
Training loss: 2.1406088501258376
Validation loss: 2.791946731964812

Epoch: 5| Step: 4
Training loss: 2.4027651037373157
Validation loss: 2.8083616430618688

Epoch: 5| Step: 5
Training loss: 2.69829193411774
Validation loss: 2.8002034447412356

Epoch: 5| Step: 6
Training loss: 2.911406833327405
Validation loss: 2.7963716658210083

Epoch: 5| Step: 7
Training loss: 2.7711046320290458
Validation loss: 2.7524857925141206

Epoch: 5| Step: 8
Training loss: 2.846486881067066
Validation loss: 2.808641155971897

Epoch: 5| Step: 9
Training loss: 2.8762710083779055
Validation loss: 2.775722043296098

Epoch: 5| Step: 10
Training loss: 2.870248766229419
Validation loss: 2.767470087130822

Epoch: 126| Step: 0
Training loss: 2.406018828149504
Validation loss: 2.7937004335105535

Epoch: 5| Step: 1
Training loss: 2.5040842073376335
Validation loss: 2.7544946827766275

Epoch: 5| Step: 2
Training loss: 1.85247998905056
Validation loss: 2.7391321141383274

Epoch: 5| Step: 3
Training loss: 2.977913297191646
Validation loss: 2.7919829870009414

Epoch: 5| Step: 4
Training loss: 2.8582262743890503
Validation loss: 2.7842655423374882

Epoch: 5| Step: 5
Training loss: 2.2250800300521143
Validation loss: 2.7698531300261813

Epoch: 5| Step: 6
Training loss: 2.919760198805764
Validation loss: 2.788054555761554

Epoch: 5| Step: 7
Training loss: 3.2820799731565518
Validation loss: 2.741021541030643

Epoch: 5| Step: 8
Training loss: 2.4015228605752896
Validation loss: 2.7896999661148607

Epoch: 5| Step: 9
Training loss: 2.4224882272408683
Validation loss: 2.7507678467362786

Epoch: 5| Step: 10
Training loss: 3.0204020400571747
Validation loss: 2.7689119794428843

Epoch: 127| Step: 0
Training loss: 2.625243402731256
Validation loss: 2.7265058138344367

Epoch: 5| Step: 1
Training loss: 2.9208638282595207
Validation loss: 2.80882627129475

Epoch: 5| Step: 2
Training loss: 2.1935949156629206
Validation loss: 2.8204834943337196

Epoch: 5| Step: 3
Training loss: 2.315268328710399
Validation loss: 2.7627996565501878

Epoch: 5| Step: 4
Training loss: 2.1157437853239034
Validation loss: 2.7529380705175424

Epoch: 5| Step: 5
Training loss: 2.709699364487607
Validation loss: 2.808994441083015

Epoch: 5| Step: 6
Training loss: 2.955362269726794
Validation loss: 2.7725048687236895

Epoch: 5| Step: 7
Training loss: 2.776508790603865
Validation loss: 2.761952204641323

Epoch: 5| Step: 8
Training loss: 2.464156500862351
Validation loss: 2.7341260796147435

Epoch: 5| Step: 9
Training loss: 2.6476740003831076
Validation loss: 2.7456171248820644

Epoch: 5| Step: 10
Training loss: 3.1421559715870684
Validation loss: 2.7597318896198964

Epoch: 128| Step: 0
Training loss: 2.4148530622368773
Validation loss: 2.7370086119138337

Epoch: 5| Step: 1
Training loss: 2.430965761961208
Validation loss: 2.7885924542078255

Epoch: 5| Step: 2
Training loss: 2.978654581799605
Validation loss: 2.774002478440216

Epoch: 5| Step: 3
Training loss: 3.5450878598364755
Validation loss: 2.7442978302248378

Epoch: 5| Step: 4
Training loss: 1.9570747416340646
Validation loss: 2.7622339904848134

Epoch: 5| Step: 5
Training loss: 2.8365022291433264
Validation loss: 2.751899910336352

Epoch: 5| Step: 6
Training loss: 1.9761738753209694
Validation loss: 2.773273729049844

Epoch: 5| Step: 7
Training loss: 2.340626784605357
Validation loss: 2.7982426925245982

Epoch: 5| Step: 8
Training loss: 2.6418798952258107
Validation loss: 2.7403508921860387

Epoch: 5| Step: 9
Training loss: 3.0367058488960907
Validation loss: 2.751300856473897

Epoch: 5| Step: 10
Training loss: 2.2098388098711617
Validation loss: 2.729939629732664

Epoch: 129| Step: 0
Training loss: 2.9749233909167696
Validation loss: 2.727943003931551

Epoch: 5| Step: 1
Training loss: 2.181248587796429
Validation loss: 2.7822265569713904

Epoch: 5| Step: 2
Training loss: 2.712408804349304
Validation loss: 2.785712290130625

Epoch: 5| Step: 3
Training loss: 2.344267114177116
Validation loss: 2.7348937468089076

Epoch: 5| Step: 4
Training loss: 1.9522951117750342
Validation loss: 2.7767791070234478

Epoch: 5| Step: 5
Training loss: 2.238958392814261
Validation loss: 2.7504367341740124

Epoch: 5| Step: 6
Training loss: 2.426424048822334
Validation loss: 2.7782838920920825

Epoch: 5| Step: 7
Training loss: 3.0592174454391117
Validation loss: 2.7658807232943303

Epoch: 5| Step: 8
Training loss: 2.8858791673813347
Validation loss: 2.7847891938199516

Epoch: 5| Step: 9
Training loss: 2.9818300910403153
Validation loss: 2.824536261291273

Epoch: 5| Step: 10
Training loss: 3.037202633716894
Validation loss: 2.7336282571242814

Epoch: 130| Step: 0
Training loss: 3.1621933679104965
Validation loss: 2.771571235434805

Epoch: 5| Step: 1
Training loss: 2.7820634830946087
Validation loss: 2.772453815601448

Epoch: 5| Step: 2
Training loss: 2.738594853486987
Validation loss: 2.786381173793004

Epoch: 5| Step: 3
Training loss: 2.247262454946541
Validation loss: 2.732598494873864

Epoch: 5| Step: 4
Training loss: 3.275598945885266
Validation loss: 2.748845162761364

Epoch: 5| Step: 5
Training loss: 1.9544284590975303
Validation loss: 2.7861885689280004

Epoch: 5| Step: 6
Training loss: 2.291311363651338
Validation loss: 2.7871071122403897

Epoch: 5| Step: 7
Training loss: 2.2300859379994837
Validation loss: 2.8102909030775174

Epoch: 5| Step: 8
Training loss: 3.0083302238074916
Validation loss: 2.766473848325357

Epoch: 5| Step: 9
Training loss: 2.4263314868542474
Validation loss: 2.777699817739329

Epoch: 5| Step: 10
Training loss: 3.151392607679471
Validation loss: 2.7711463848218405

Epoch: 131| Step: 0
Training loss: 1.558922066204448
Validation loss: 2.796046396599863

Epoch: 5| Step: 1
Training loss: 2.4153843689525427
Validation loss: 2.7252972082796876

Epoch: 5| Step: 2
Training loss: 2.426523681644543
Validation loss: 2.7507773332703978

Epoch: 5| Step: 3
Training loss: 3.0192823615892412
Validation loss: 2.7409249663145405

Epoch: 5| Step: 4
Training loss: 2.4442291297392256
Validation loss: 2.741725399708422

Epoch: 5| Step: 5
Training loss: 2.8449052413418543
Validation loss: 2.7476992393463715

Epoch: 5| Step: 6
Training loss: 2.855130239478964
Validation loss: 2.7492008147996163

Epoch: 5| Step: 7
Training loss: 2.5530544275921345
Validation loss: 2.7665906318459133

Epoch: 5| Step: 8
Training loss: 2.3100864083779125
Validation loss: 2.774570508307834

Epoch: 5| Step: 9
Training loss: 3.290175442177456
Validation loss: 2.7721145222111097

Epoch: 5| Step: 10
Training loss: 2.8364966815920334
Validation loss: 2.7582785580839237

Epoch: 132| Step: 0
Training loss: 2.5172512886967713
Validation loss: 2.69884546594773

Epoch: 5| Step: 1
Training loss: 3.011572135394497
Validation loss: 2.753142734129801

Epoch: 5| Step: 2
Training loss: 2.166023330055615
Validation loss: 2.732517528706072

Epoch: 5| Step: 3
Training loss: 2.5594421377912924
Validation loss: 2.763179644629794

Epoch: 5| Step: 4
Training loss: 2.0502987248557267
Validation loss: 2.804121558320827

Epoch: 5| Step: 5
Training loss: 3.037084097312412
Validation loss: 2.7642687681819273

Epoch: 5| Step: 6
Training loss: 2.671912388233246
Validation loss: 2.751485541735956

Epoch: 5| Step: 7
Training loss: 2.596975779500129
Validation loss: 2.7514574396947507

Epoch: 5| Step: 8
Training loss: 2.222664080507131
Validation loss: 2.78259569063161

Epoch: 5| Step: 9
Training loss: 3.1338477956867594
Validation loss: 2.7707349334300733

Epoch: 5| Step: 10
Training loss: 2.3284045570018312
Validation loss: 2.7866974028939118

Epoch: 133| Step: 0
Training loss: 2.472332057822772
Validation loss: 2.796665591931105

Epoch: 5| Step: 1
Training loss: 2.2544365693672317
Validation loss: 2.751842503338943

Epoch: 5| Step: 2
Training loss: 2.7744578888763907
Validation loss: 2.7876015468667523

Epoch: 5| Step: 3
Training loss: 3.05684887843884
Validation loss: 2.7267756286096083

Epoch: 5| Step: 4
Training loss: 2.2449941049681073
Validation loss: 2.742871162596752

Epoch: 5| Step: 5
Training loss: 2.397749811548936
Validation loss: 2.782862690814084

Epoch: 5| Step: 6
Training loss: 2.6150625227971944
Validation loss: 2.8118635818000937

Epoch: 5| Step: 7
Training loss: 2.6180788258924568
Validation loss: 2.785909742041153

Epoch: 5| Step: 8
Training loss: 2.043323726704072
Validation loss: 2.7879416056129713

Epoch: 5| Step: 9
Training loss: 3.161191339336948
Validation loss: 2.754776139836117

Epoch: 5| Step: 10
Training loss: 2.4685748074334346
Validation loss: 2.726028126278254

Epoch: 134| Step: 0
Training loss: 2.185682795357411
Validation loss: 2.7397411727836953

Epoch: 5| Step: 1
Training loss: 1.7947745610368642
Validation loss: 2.7754641121047214

Epoch: 5| Step: 2
Training loss: 1.7286048650604042
Validation loss: 2.785435962701436

Epoch: 5| Step: 3
Training loss: 2.5052026020283216
Validation loss: 2.7770375152068247

Epoch: 5| Step: 4
Training loss: 3.2364165271571363
Validation loss: 2.7681841880728153

Epoch: 5| Step: 5
Training loss: 2.3320404512616846
Validation loss: 2.7310820653325134

Epoch: 5| Step: 6
Training loss: 3.0934384892392064
Validation loss: 2.7406731246393745

Epoch: 5| Step: 7
Training loss: 2.6087080051641034
Validation loss: 2.7106483425596237

Epoch: 5| Step: 8
Training loss: 2.430479257990685
Validation loss: 2.787988331033388

Epoch: 5| Step: 9
Training loss: 2.81279176682145
Validation loss: 2.770615166559462

Epoch: 5| Step: 10
Training loss: 3.3309201247190394
Validation loss: 2.761298995693932

Epoch: 135| Step: 0
Training loss: 2.540286100900107
Validation loss: 2.7523724017005535

Epoch: 5| Step: 1
Training loss: 2.4017669729675575
Validation loss: 2.777864190179511

Epoch: 5| Step: 2
Training loss: 2.4631268163411533
Validation loss: 2.791229708517876

Epoch: 5| Step: 3
Training loss: 2.8634655985483435
Validation loss: 2.784731117985612

Epoch: 5| Step: 4
Training loss: 2.425330078627528
Validation loss: 2.7659005348285204

Epoch: 5| Step: 5
Training loss: 2.7686167768886483
Validation loss: 2.7288612956379397

Epoch: 5| Step: 6
Training loss: 2.145866270337203
Validation loss: 2.7277613195492783

Epoch: 5| Step: 7
Training loss: 3.1453446941367305
Validation loss: 2.738147393118874

Epoch: 5| Step: 8
Training loss: 2.637789134588792
Validation loss: 2.7666065635656367

Epoch: 5| Step: 9
Training loss: 2.4834692881532066
Validation loss: 2.7721902462540418

Epoch: 5| Step: 10
Training loss: 2.640393399346811
Validation loss: 2.786515175614631

Epoch: 136| Step: 0
Training loss: 2.1833127955084692
Validation loss: 2.759912875718855

Epoch: 5| Step: 1
Training loss: 3.109289426919991
Validation loss: 2.7381947201367276

Epoch: 5| Step: 2
Training loss: 2.06537797290459
Validation loss: 2.809052194161118

Epoch: 5| Step: 3
Training loss: 2.2864707882715005
Validation loss: 2.808196563934648

Epoch: 5| Step: 4
Training loss: 2.3364788946255257
Validation loss: 2.7164123106809503

Epoch: 5| Step: 5
Training loss: 3.051102742193453
Validation loss: 2.7698658285582844

Epoch: 5| Step: 6
Training loss: 1.9969909801441823
Validation loss: 2.8175320172752936

Epoch: 5| Step: 7
Training loss: 3.487562697199081
Validation loss: 2.8012910152644035

Epoch: 5| Step: 8
Training loss: 2.7858038493140587
Validation loss: 2.7622704619500538

Epoch: 5| Step: 9
Training loss: 2.617382531941398
Validation loss: 2.7867812299173482

Epoch: 5| Step: 10
Training loss: 2.399705682033128
Validation loss: 2.756794473854406

Epoch: 137| Step: 0
Training loss: 2.951977865255017
Validation loss: 2.7409695283157087

Epoch: 5| Step: 1
Training loss: 2.2871779668541294
Validation loss: 2.771496812607424

Epoch: 5| Step: 2
Training loss: 2.332394365574248
Validation loss: 2.7878492062576052

Epoch: 5| Step: 3
Training loss: 2.3203772333536454
Validation loss: 2.7749978436217115

Epoch: 5| Step: 4
Training loss: 2.879424463885986
Validation loss: 2.7708887438091487

Epoch: 5| Step: 5
Training loss: 2.6008580259230416
Validation loss: 2.7265020057545963

Epoch: 5| Step: 6
Training loss: 2.2096710352067763
Validation loss: 2.748393761502391

Epoch: 5| Step: 7
Training loss: 2.656330601086406
Validation loss: 2.7980557885361663

Epoch: 5| Step: 8
Training loss: 2.4359703154736208
Validation loss: 2.8011112877660733

Epoch: 5| Step: 9
Training loss: 3.236003078973199
Validation loss: 2.70398909697768

Epoch: 5| Step: 10
Training loss: 2.456168649505659
Validation loss: 2.7737103820336624

Epoch: 138| Step: 0
Training loss: 3.213037551256775
Validation loss: 2.768988309074001

Epoch: 5| Step: 1
Training loss: 2.435102604265032
Validation loss: 2.771360925528669

Epoch: 5| Step: 2
Training loss: 2.114241461217083
Validation loss: 2.7111596741087736

Epoch: 5| Step: 3
Training loss: 2.566655023556678
Validation loss: 2.7532069486442037

Epoch: 5| Step: 4
Training loss: 2.256046858754056
Validation loss: 2.712814310727251

Epoch: 5| Step: 5
Training loss: 2.1053093051872005
Validation loss: 2.7570787515930903

Epoch: 5| Step: 6
Training loss: 2.8738963455164748
Validation loss: 2.75872557637902

Epoch: 5| Step: 7
Training loss: 2.7401395361238814
Validation loss: 2.7369960316331734

Epoch: 5| Step: 8
Training loss: 2.4471768715512816
Validation loss: 2.7434837330772646

Epoch: 5| Step: 9
Training loss: 2.88884387429534
Validation loss: 2.711857601420853

Epoch: 5| Step: 10
Training loss: 2.486384988210963
Validation loss: 2.7600050724800913

Epoch: 139| Step: 0
Training loss: 1.9804521970038331
Validation loss: 2.78909318469945

Epoch: 5| Step: 1
Training loss: 2.8068864538196463
Validation loss: 2.6979570828019432

Epoch: 5| Step: 2
Training loss: 2.720346267201395
Validation loss: 2.7127629998993057

Epoch: 5| Step: 3
Training loss: 2.3950365040651143
Validation loss: 2.797356282778856

Epoch: 5| Step: 4
Training loss: 2.9352140256969252
Validation loss: 2.7479668369956545

Epoch: 5| Step: 5
Training loss: 2.7481355415577573
Validation loss: 2.703970063888033

Epoch: 5| Step: 6
Training loss: 2.565721115560784
Validation loss: 2.7619615126028907

Epoch: 5| Step: 7
Training loss: 3.137041315236536
Validation loss: 2.7770537719477595

Epoch: 5| Step: 8
Training loss: 2.3989755232064383
Validation loss: 2.7668868404504505

Epoch: 5| Step: 9
Training loss: 2.3799914060165013
Validation loss: 2.780315240704149

Epoch: 5| Step: 10
Training loss: 2.202689378024789
Validation loss: 2.7762429292292032

Epoch: 140| Step: 0
Training loss: 2.857017003421036
Validation loss: 2.762848848548023

Epoch: 5| Step: 1
Training loss: 2.8998243607574214
Validation loss: 2.7749498573598355

Epoch: 5| Step: 2
Training loss: 1.5120015040092456
Validation loss: 2.7887785427403204

Epoch: 5| Step: 3
Training loss: 2.1875342230163337
Validation loss: 2.6978026203758736

Epoch: 5| Step: 4
Training loss: 2.7056273415833596
Validation loss: 2.7837138824047925

Epoch: 5| Step: 5
Training loss: 2.595310982388507
Validation loss: 2.76491433169987

Epoch: 5| Step: 6
Training loss: 2.8699983959658724
Validation loss: 2.6957914678548454

Epoch: 5| Step: 7
Training loss: 2.5527059820532694
Validation loss: 2.727328705399621

Epoch: 5| Step: 8
Training loss: 2.989852910841401
Validation loss: 2.7770563106125112

Epoch: 5| Step: 9
Training loss: 2.221823913587826
Validation loss: 2.719961369636453

Epoch: 5| Step: 10
Training loss: 2.7325871317409356
Validation loss: 2.789144709932263

Epoch: 141| Step: 0
Training loss: 2.7044197465665154
Validation loss: 2.7889719927391137

Epoch: 5| Step: 1
Training loss: 2.150143809277354
Validation loss: 2.7696873024000452

Epoch: 5| Step: 2
Training loss: 2.1893864807821037
Validation loss: 2.74140160766063

Epoch: 5| Step: 3
Training loss: 2.8245607118947618
Validation loss: 2.776365912312573

Epoch: 5| Step: 4
Training loss: 2.3658610741401
Validation loss: 2.7688676491011077

Epoch: 5| Step: 5
Training loss: 2.5566664564024015
Validation loss: 2.747859342607

Epoch: 5| Step: 6
Training loss: 3.039358404115413
Validation loss: 2.7560139988256265

Epoch: 5| Step: 7
Training loss: 2.1235641789771993
Validation loss: 2.7665332878298563

Epoch: 5| Step: 8
Training loss: 2.6577991231842972
Validation loss: 2.725022270410426

Epoch: 5| Step: 9
Training loss: 3.437637603779938
Validation loss: 2.7913475466438102

Epoch: 5| Step: 10
Training loss: 2.1879189226377043
Validation loss: 2.7496107260344225

Epoch: 142| Step: 0
Training loss: 2.504547370327102
Validation loss: 2.7903148118844596

Epoch: 5| Step: 1
Training loss: 2.0652560690917747
Validation loss: 2.7394316651687878

Epoch: 5| Step: 2
Training loss: 2.1015763406404133
Validation loss: 2.7200759824362057

Epoch: 5| Step: 3
Training loss: 2.4584229232066934
Validation loss: 2.7674002655416365

Epoch: 5| Step: 4
Training loss: 2.514246971897025
Validation loss: 2.751958377659937

Epoch: 5| Step: 5
Training loss: 2.9924163332455276
Validation loss: 2.7322594766053467

Epoch: 5| Step: 6
Training loss: 2.9196393440862063
Validation loss: 2.7648293020433763

Epoch: 5| Step: 7
Training loss: 2.9651599258084067
Validation loss: 2.7575877098981336

Epoch: 5| Step: 8
Training loss: 2.424626122981165
Validation loss: 2.7191792386053217

Epoch: 5| Step: 9
Training loss: 2.936262641187717
Validation loss: 2.7949023008275606

Epoch: 5| Step: 10
Training loss: 2.3681878220457597
Validation loss: 2.7767586174258447

Epoch: 143| Step: 0
Training loss: 2.5526731056151433
Validation loss: 2.7934123378774225

Epoch: 5| Step: 1
Training loss: 2.442879828727762
Validation loss: 2.7244226561147955

Epoch: 5| Step: 2
Training loss: 2.0832570888554782
Validation loss: 2.801487062153455

Epoch: 5| Step: 3
Training loss: 3.8034653472946602
Validation loss: 2.768529261681928

Epoch: 5| Step: 4
Training loss: 2.8080719740356987
Validation loss: 2.747126256099126

Epoch: 5| Step: 5
Training loss: 2.219995927892851
Validation loss: 2.783046787709091

Epoch: 5| Step: 6
Training loss: 2.440285973440742
Validation loss: 2.75832013511592

Epoch: 5| Step: 7
Training loss: 2.107706384836701
Validation loss: 2.7931168083051134

Epoch: 5| Step: 8
Training loss: 2.387246430997091
Validation loss: 2.784692475273714

Epoch: 5| Step: 9
Training loss: 2.89528383672106
Validation loss: 2.7261242883270187

Epoch: 5| Step: 10
Training loss: 1.8826494581613071
Validation loss: 2.7967780980904

Epoch: 144| Step: 0
Training loss: 2.3579038365939593
Validation loss: 2.7715627284049993

Epoch: 5| Step: 1
Training loss: 2.4004519076862385
Validation loss: 2.7919612729683774

Epoch: 5| Step: 2
Training loss: 2.2767894456335953
Validation loss: 2.715156957914524

Epoch: 5| Step: 3
Training loss: 3.0339954959984317
Validation loss: 2.7912233481557838

Epoch: 5| Step: 4
Training loss: 2.6671471957539876
Validation loss: 2.765496510243328

Epoch: 5| Step: 5
Training loss: 2.6097874115638477
Validation loss: 2.771312037259469

Epoch: 5| Step: 6
Training loss: 3.1483492022454853
Validation loss: 2.7278481023659995

Epoch: 5| Step: 7
Training loss: 3.0795679728219927
Validation loss: 2.7339995564481105

Epoch: 5| Step: 8
Training loss: 2.2698188638888617
Validation loss: 2.7666379022591747

Epoch: 5| Step: 9
Training loss: 2.3275951832321735
Validation loss: 2.721956032922994

Epoch: 5| Step: 10
Training loss: 1.5881788079079955
Validation loss: 2.7477445465775725

Epoch: 145| Step: 0
Training loss: 2.17367874002382
Validation loss: 2.736286132295409

Epoch: 5| Step: 1
Training loss: 3.471035865714888
Validation loss: 2.7437129405922724

Epoch: 5| Step: 2
Training loss: 3.080755977992262
Validation loss: 2.7411827282552053

Epoch: 5| Step: 3
Training loss: 2.556009586286403
Validation loss: 2.764419093458221

Epoch: 5| Step: 4
Training loss: 1.6647390503632824
Validation loss: 2.771399254608867

Epoch: 5| Step: 5
Training loss: 2.442690775360144
Validation loss: 2.786638682826151

Epoch: 5| Step: 6
Training loss: 2.3200881798198734
Validation loss: 2.7368609185271953

Epoch: 5| Step: 7
Training loss: 2.426195880142826
Validation loss: 2.7712014011125827

Epoch: 5| Step: 8
Training loss: 2.1705105014943302
Validation loss: 2.7652180087589837

Epoch: 5| Step: 9
Training loss: 2.726710799154645
Validation loss: 2.727163359385676

Epoch: 5| Step: 10
Training loss: 2.8582446256019995
Validation loss: 2.7761101612202657

Epoch: 146| Step: 0
Training loss: 2.664981627553052
Validation loss: 2.7641405752374806

Epoch: 5| Step: 1
Training loss: 2.8870998022668894
Validation loss: 2.73433265852484

Epoch: 5| Step: 2
Training loss: 2.08371916694919
Validation loss: 2.755240564960121

Epoch: 5| Step: 3
Training loss: 3.07523237141254
Validation loss: 2.7381337376115042

Epoch: 5| Step: 4
Training loss: 2.4650167897176862
Validation loss: 2.7931635416883522

Epoch: 5| Step: 5
Training loss: 3.1051607183119927
Validation loss: 2.7552552429246577

Epoch: 5| Step: 6
Training loss: 2.3756770122708346
Validation loss: 2.7704381775860023

Epoch: 5| Step: 7
Training loss: 2.371535032331679
Validation loss: 2.7270160183515157

Epoch: 5| Step: 8
Training loss: 2.244894593277002
Validation loss: 2.760906788149079

Epoch: 5| Step: 9
Training loss: 2.440055583414564
Validation loss: 2.741337718399317

Epoch: 5| Step: 10
Training loss: 2.2843465821550732
Validation loss: 2.758395542657331

Epoch: 147| Step: 0
Training loss: 2.472184701222878
Validation loss: 2.7577089154692858

Epoch: 5| Step: 1
Training loss: 2.884928270634988
Validation loss: 2.7603049700089852

Epoch: 5| Step: 2
Training loss: 2.562317818469098
Validation loss: 2.771072446461372

Epoch: 5| Step: 3
Training loss: 2.4896202137874215
Validation loss: 2.7644006350147503

Epoch: 5| Step: 4
Training loss: 2.5269910987905555
Validation loss: 2.785710278393637

Epoch: 5| Step: 5
Training loss: 2.743476325704475
Validation loss: 2.767760640410842

Epoch: 5| Step: 6
Training loss: 3.2996409596570477
Validation loss: 2.7148535235395697

Epoch: 5| Step: 7
Training loss: 3.0900150449318646
Validation loss: 2.7204323894295475

Epoch: 5| Step: 8
Training loss: 1.8217334358610835
Validation loss: 2.755256525556386

Epoch: 5| Step: 9
Training loss: 1.596206641627734
Validation loss: 2.790010671581592

Epoch: 5| Step: 10
Training loss: 2.1966296822768214
Validation loss: 2.716963409535359

Epoch: 148| Step: 0
Training loss: 2.88687418311455
Validation loss: 2.727373210377177

Epoch: 5| Step: 1
Training loss: 2.1276734308542364
Validation loss: 2.692700858956786

Epoch: 5| Step: 2
Training loss: 2.604956809654159
Validation loss: 2.7589152200790994

Epoch: 5| Step: 3
Training loss: 2.2383334435041355
Validation loss: 2.746142399197583

Epoch: 5| Step: 4
Training loss: 2.9635423460268515
Validation loss: 2.6946327773163716

Epoch: 5| Step: 5
Training loss: 2.547403854038234
Validation loss: 2.7672291677804166

Epoch: 5| Step: 6
Training loss: 3.0129151497486553
Validation loss: 2.711651154825006

Epoch: 5| Step: 7
Training loss: 1.9433139201460161
Validation loss: 2.719174091858364

Epoch: 5| Step: 8
Training loss: 2.8952612734944796
Validation loss: 2.7522495760192376

Epoch: 5| Step: 9
Training loss: 2.5875265074030973
Validation loss: 2.7574172054026747

Epoch: 5| Step: 10
Training loss: 2.547858674290573
Validation loss: 2.7646670148363572

Epoch: 149| Step: 0
Training loss: 2.369214389341402
Validation loss: 2.721516039571989

Epoch: 5| Step: 1
Training loss: 2.702871145334844
Validation loss: 2.751364766891649

Epoch: 5| Step: 2
Training loss: 2.4855557880544557
Validation loss: 2.7166897788676123

Epoch: 5| Step: 3
Training loss: 3.132959528871367
Validation loss: 2.749013697783029

Epoch: 5| Step: 4
Training loss: 2.697359142850655
Validation loss: 2.7701566302991454

Epoch: 5| Step: 5
Training loss: 3.2539408339623717
Validation loss: 2.707009354570755

Epoch: 5| Step: 6
Training loss: 2.2982652051130756
Validation loss: 2.7383558837078144

Epoch: 5| Step: 7
Training loss: 2.205927912297714
Validation loss: 2.7254648610462744

Epoch: 5| Step: 8
Training loss: 2.451460741507169
Validation loss: 2.8060466229035788

Epoch: 5| Step: 9
Training loss: 2.356559741154285
Validation loss: 2.793520777457735

Epoch: 5| Step: 10
Training loss: 2.2715523890827733
Validation loss: 2.787611492952498

Epoch: 150| Step: 0
Training loss: 2.256117240402503
Validation loss: 2.730250919028054

Epoch: 5| Step: 1
Training loss: 2.727696049232669
Validation loss: 2.746157115522091

Epoch: 5| Step: 2
Training loss: 3.007869888352684
Validation loss: 2.7624078411824833

Epoch: 5| Step: 3
Training loss: 2.5919708216579
Validation loss: 2.787864019676203

Epoch: 5| Step: 4
Training loss: 2.4269910366425664
Validation loss: 2.7726593427997646

Epoch: 5| Step: 5
Training loss: 2.8691133688715578
Validation loss: 2.7899058727036956

Epoch: 5| Step: 6
Training loss: 2.894592861080967
Validation loss: 2.7021253326970047

Epoch: 5| Step: 7
Training loss: 2.339185517057001
Validation loss: 2.745926040333486

Epoch: 5| Step: 8
Training loss: 2.608440208886096
Validation loss: 2.733965801319993

Epoch: 5| Step: 9
Training loss: 2.119891365074927
Validation loss: 2.7066916795088383

Epoch: 5| Step: 10
Training loss: 1.972900677635985
Validation loss: 2.7394892424021156

Epoch: 151| Step: 0
Training loss: 2.5753375156272185
Validation loss: 2.75834320998672

Epoch: 5| Step: 1
Training loss: 2.1040169942771447
Validation loss: 2.688709085307192

Epoch: 5| Step: 2
Training loss: 2.88477074913856
Validation loss: 2.7215339495671205

Epoch: 5| Step: 3
Training loss: 2.323737394351021
Validation loss: 2.7231095810347474

Epoch: 5| Step: 4
Training loss: 2.510947671239414
Validation loss: 2.6962893268233143

Epoch: 5| Step: 5
Training loss: 2.4192817832827633
Validation loss: 2.7528102365046485

Epoch: 5| Step: 6
Training loss: 2.9871083469720836
Validation loss: 2.7741718000142344

Epoch: 5| Step: 7
Training loss: 1.8765955176454312
Validation loss: 2.697032611789783

Epoch: 5| Step: 8
Training loss: 2.8153306068348796
Validation loss: 2.6993649927805157

Epoch: 5| Step: 9
Training loss: 3.2421922063218855
Validation loss: 2.7903174367918067

Epoch: 5| Step: 10
Training loss: 1.490279410745406
Validation loss: 2.759378973648253

Epoch: 152| Step: 0
Training loss: 2.1417672110184727
Validation loss: 2.7088947260163763

Epoch: 5| Step: 1
Training loss: 2.5386445156254327
Validation loss: 2.7767237220735104

Epoch: 5| Step: 2
Training loss: 2.5675607346108733
Validation loss: 2.737229329249532

Epoch: 5| Step: 3
Training loss: 2.7429696296292825
Validation loss: 2.8045003554737717

Epoch: 5| Step: 4
Training loss: 2.4692879585638345
Validation loss: 2.732489897716957

Epoch: 5| Step: 5
Training loss: 2.2988831959936595
Validation loss: 2.7194214320501073

Epoch: 5| Step: 6
Training loss: 2.5605744361121574
Validation loss: 2.760912356194924

Epoch: 5| Step: 7
Training loss: 2.314588274007675
Validation loss: 2.760160848907114

Epoch: 5| Step: 8
Training loss: 3.329422245710864
Validation loss: 2.794747907718473

Epoch: 5| Step: 9
Training loss: 2.3294024962820528
Validation loss: 2.775134972480159

Epoch: 5| Step: 10
Training loss: 2.6734762468768536
Validation loss: 2.775402779076373

Epoch: 153| Step: 0
Training loss: 2.4400436627280437
Validation loss: 2.7147856595096775

Epoch: 5| Step: 1
Training loss: 2.6612711403268223
Validation loss: 2.7163671891519847

Epoch: 5| Step: 2
Training loss: 1.903455217648811
Validation loss: 2.694544476620436

Epoch: 5| Step: 3
Training loss: 1.8385764777010145
Validation loss: 2.7679475042848227

Epoch: 5| Step: 4
Training loss: 2.242289045739272
Validation loss: 2.7533400920093816

Epoch: 5| Step: 5
Training loss: 2.6064192426513304
Validation loss: 2.792304536556967

Epoch: 5| Step: 6
Training loss: 3.124708848741639
Validation loss: 2.7500034469292034

Epoch: 5| Step: 7
Training loss: 2.62317939474675
Validation loss: 2.7353598953572766

Epoch: 5| Step: 8
Training loss: 3.033995653163182
Validation loss: 2.7718692267700766

Epoch: 5| Step: 9
Training loss: 2.883993594327842
Validation loss: 2.763426614057247

Epoch: 5| Step: 10
Training loss: 2.1725367354435705
Validation loss: 2.7047475952062405

Epoch: 154| Step: 0
Training loss: 2.5461565186125044
Validation loss: 2.8013738006899627

Epoch: 5| Step: 1
Training loss: 2.309006604039399
Validation loss: 2.740658575304057

Epoch: 5| Step: 2
Training loss: 2.505022154384571
Validation loss: 2.7874017044130346

Epoch: 5| Step: 3
Training loss: 2.0308335097350287
Validation loss: 2.754479372525379

Epoch: 5| Step: 4
Training loss: 2.5042436821678784
Validation loss: 2.745166860720622

Epoch: 5| Step: 5
Training loss: 2.4757714196416543
Validation loss: 2.76821852520787

Epoch: 5| Step: 6
Training loss: 2.4312442808893007
Validation loss: 2.682339097362392

Epoch: 5| Step: 7
Training loss: 3.1654824167358857
Validation loss: 2.7250972484340465

Epoch: 5| Step: 8
Training loss: 2.38674452248002
Validation loss: 2.7666357515576956

Epoch: 5| Step: 9
Training loss: 2.5535510974116584
Validation loss: 2.6889608313919773

Epoch: 5| Step: 10
Training loss: 3.0670075234046306
Validation loss: 2.7280136436934606

Epoch: 155| Step: 0
Training loss: 2.983097941597392
Validation loss: 2.7814561952480954

Epoch: 5| Step: 1
Training loss: 1.9214905765291455
Validation loss: 2.6926531617142038

Epoch: 5| Step: 2
Training loss: 2.0464089132319154
Validation loss: 2.774708892658232

Epoch: 5| Step: 3
Training loss: 2.521751951030643
Validation loss: 2.6793222964491554

Epoch: 5| Step: 4
Training loss: 2.330119258137041
Validation loss: 2.773346793415798

Epoch: 5| Step: 5
Training loss: 2.058487312127688
Validation loss: 2.7387402451889917

Epoch: 5| Step: 6
Training loss: 3.012851210259334
Validation loss: 2.7093246734419134

Epoch: 5| Step: 7
Training loss: 2.684969131746925
Validation loss: 2.7467650070659673

Epoch: 5| Step: 8
Training loss: 2.8214137075215464
Validation loss: 2.788133333563094

Epoch: 5| Step: 9
Training loss: 2.590266450704354
Validation loss: 2.7314755754418756

Epoch: 5| Step: 10
Training loss: 2.485479049560556
Validation loss: 2.717836420050153

Epoch: 156| Step: 0
Training loss: 3.0316743848582526
Validation loss: 2.7249331039070466

Epoch: 5| Step: 1
Training loss: 2.4363855601958626
Validation loss: 2.789893604920797

Epoch: 5| Step: 2
Training loss: 2.3092904370921947
Validation loss: 2.7423177531061524

Epoch: 5| Step: 3
Training loss: 1.9475544339408954
Validation loss: 2.7362936650026413

Epoch: 5| Step: 4
Training loss: 2.2391824289535407
Validation loss: 2.739037692911041

Epoch: 5| Step: 5
Training loss: 1.3439717664250814
Validation loss: 2.755479039865311

Epoch: 5| Step: 6
Training loss: 3.059851143152149
Validation loss: 2.7480573457994377

Epoch: 5| Step: 7
Training loss: 2.941771951867934
Validation loss: 2.7165004148884933

Epoch: 5| Step: 8
Training loss: 2.6994349700844515
Validation loss: 2.74612034323395

Epoch: 5| Step: 9
Training loss: 2.473131661414564
Validation loss: 2.720212303400448

Epoch: 5| Step: 10
Training loss: 2.688124739312747
Validation loss: 2.692767898155597

Epoch: 157| Step: 0
Training loss: 2.87119157066564
Validation loss: 2.7284657416539395

Epoch: 5| Step: 1
Training loss: 3.0481814982325104
Validation loss: 2.694573969494588

Epoch: 5| Step: 2
Training loss: 2.364782238183275
Validation loss: 2.738545235180336

Epoch: 5| Step: 3
Training loss: 1.665160985157618
Validation loss: 2.7372366945231024

Epoch: 5| Step: 4
Training loss: 2.897047671014387
Validation loss: 2.7092534290574726

Epoch: 5| Step: 5
Training loss: 2.6385181757778193
Validation loss: 2.7626419660469517

Epoch: 5| Step: 6
Training loss: 2.045179990201786
Validation loss: 2.7483543028534254

Epoch: 5| Step: 7
Training loss: 2.671009659761466
Validation loss: 2.8044777785284163

Epoch: 5| Step: 8
Training loss: 2.5155971359700042
Validation loss: 2.8157020616847506

Epoch: 5| Step: 9
Training loss: 2.472238610840767
Validation loss: 2.7524429984882177

Epoch: 5| Step: 10
Training loss: 2.84087335321316
Validation loss: 2.762956399057947

Epoch: 158| Step: 0
Training loss: 3.0820337254426056
Validation loss: 2.737516135071141

Epoch: 5| Step: 1
Training loss: 2.1701106307839026
Validation loss: 2.7069973536790375

Epoch: 5| Step: 2
Training loss: 3.070445749434392
Validation loss: 2.7474908820555823

Epoch: 5| Step: 3
Training loss: 2.658503305946463
Validation loss: 2.7329088227937777

Epoch: 5| Step: 4
Training loss: 2.3145875529592135
Validation loss: 2.7480235151967385

Epoch: 5| Step: 5
Training loss: 2.4989017935480393
Validation loss: 2.736238924047161

Epoch: 5| Step: 6
Training loss: 2.2772057623960005
Validation loss: 2.69718177989853

Epoch: 5| Step: 7
Training loss: 2.216597789277507
Validation loss: 2.7096820820637912

Epoch: 5| Step: 8
Training loss: 1.6606226366950156
Validation loss: 2.7530283339403625

Epoch: 5| Step: 9
Training loss: 3.053595852734271
Validation loss: 2.74943251828109

Epoch: 5| Step: 10
Training loss: 2.4146581612403297
Validation loss: 2.770270309282898

Epoch: 159| Step: 0
Training loss: 2.2494398055475364
Validation loss: 2.7556544777640193

Epoch: 5| Step: 1
Training loss: 3.021646131588452
Validation loss: 2.759445241154567

Epoch: 5| Step: 2
Training loss: 2.3670538433350674
Validation loss: 2.762030930554295

Epoch: 5| Step: 3
Training loss: 2.3498798826645713
Validation loss: 2.7328468583401664

Epoch: 5| Step: 4
Training loss: 2.6316454193855225
Validation loss: 2.7643756300447024

Epoch: 5| Step: 5
Training loss: 2.5146977392011665
Validation loss: 2.727484491732275

Epoch: 5| Step: 6
Training loss: 2.063337329476492
Validation loss: 2.7320144050324195

Epoch: 5| Step: 7
Training loss: 2.768147584293763
Validation loss: 2.743980075864898

Epoch: 5| Step: 8
Training loss: 2.544737966571797
Validation loss: 2.75953688405578

Epoch: 5| Step: 9
Training loss: 2.5200777629177127
Validation loss: 2.740836918596931

Epoch: 5| Step: 10
Training loss: 2.628234958956524
Validation loss: 2.780030419493165

Epoch: 160| Step: 0
Training loss: 2.734495410992763
Validation loss: 2.7288159111599763

Epoch: 5| Step: 1
Training loss: 2.5792034321158694
Validation loss: 2.6869593708729527

Epoch: 5| Step: 2
Training loss: 2.4310787424996927
Validation loss: 2.7499637200506437

Epoch: 5| Step: 3
Training loss: 2.7723284155926744
Validation loss: 2.7381694178060467

Epoch: 5| Step: 4
Training loss: 2.441214347926702
Validation loss: 2.7484559360349334

Epoch: 5| Step: 5
Training loss: 2.7418213515623253
Validation loss: 2.767113314514691

Epoch: 5| Step: 6
Training loss: 2.668175528738813
Validation loss: 2.71659404158802

Epoch: 5| Step: 7
Training loss: 2.680585616167756
Validation loss: 2.754113792430799

Epoch: 5| Step: 8
Training loss: 2.41589680828997
Validation loss: 2.7662853400220824

Epoch: 5| Step: 9
Training loss: 1.9898169681587452
Validation loss: 2.729008615954228

Epoch: 5| Step: 10
Training loss: 2.686514740364421
Validation loss: 2.747264266653452

Epoch: 161| Step: 0
Training loss: 2.455428287416677
Validation loss: 2.736557692964507

Epoch: 5| Step: 1
Training loss: 2.7289752941641754
Validation loss: 2.70370450062513

Epoch: 5| Step: 2
Training loss: 2.7007378417728978
Validation loss: 2.708514347763726

Epoch: 5| Step: 3
Training loss: 1.8285450249068445
Validation loss: 2.753440567261757

Epoch: 5| Step: 4
Training loss: 2.493800104923783
Validation loss: 2.7955209709930045

Epoch: 5| Step: 5
Training loss: 2.9195957371687014
Validation loss: 2.75867716395425

Epoch: 5| Step: 6
Training loss: 2.8720478989583604
Validation loss: 2.8142222674387165

Epoch: 5| Step: 7
Training loss: 2.9784379792645814
Validation loss: 2.730072202533411

Epoch: 5| Step: 8
Training loss: 2.0397764395716007
Validation loss: 2.7518137695793476

Epoch: 5| Step: 9
Training loss: 2.3194756331285316
Validation loss: 2.751931208765598

Epoch: 5| Step: 10
Training loss: 1.797714965869379
Validation loss: 2.7789223473183

Epoch: 162| Step: 0
Training loss: 3.075431768606563
Validation loss: 2.715360008193115

Epoch: 5| Step: 1
Training loss: 2.2060108087574033
Validation loss: 2.7866499207699973

Epoch: 5| Step: 2
Training loss: 3.049318869156832
Validation loss: 2.7964505265190684

Epoch: 5| Step: 3
Training loss: 3.0615583256584697
Validation loss: 2.76995594018641

Epoch: 5| Step: 4
Training loss: 2.3435364689513434
Validation loss: 2.696008908955445

Epoch: 5| Step: 5
Training loss: 1.4841738112782985
Validation loss: 2.710580801688787

Epoch: 5| Step: 6
Training loss: 2.2870738273483746
Validation loss: 2.743187125377835

Epoch: 5| Step: 7
Training loss: 2.6070104610173237
Validation loss: 2.726733952305421

Epoch: 5| Step: 8
Training loss: 1.7776845081353658
Validation loss: 2.7153505149945807

Epoch: 5| Step: 9
Training loss: 2.6602276807877083
Validation loss: 2.746159443763618

Epoch: 5| Step: 10
Training loss: 2.699740987292673
Validation loss: 2.7842759211260573

Epoch: 163| Step: 0
Training loss: 2.7691822343224737
Validation loss: 2.755328941407673

Epoch: 5| Step: 1
Training loss: 2.255580656990392
Validation loss: 2.7243913907704393

Epoch: 5| Step: 2
Training loss: 1.82508466863841
Validation loss: 2.7363204462322606

Epoch: 5| Step: 3
Training loss: 2.506985822238098
Validation loss: 2.798984169301625

Epoch: 5| Step: 4
Training loss: 2.7322089635151445
Validation loss: 2.7418779464248786

Epoch: 5| Step: 5
Training loss: 2.219133585693927
Validation loss: 2.776015107338068

Epoch: 5| Step: 6
Training loss: 2.971464983617466
Validation loss: 2.7567818118255945

Epoch: 5| Step: 7
Training loss: 2.6140086440371757
Validation loss: 2.7260217684888532

Epoch: 5| Step: 8
Training loss: 2.3570189175079257
Validation loss: 2.756798351682091

Epoch: 5| Step: 9
Training loss: 2.7530038207249676
Validation loss: 2.6621342359761244

Epoch: 5| Step: 10
Training loss: 2.470960665461919
Validation loss: 2.736626722037728

Epoch: 164| Step: 0
Training loss: 2.35093462599934
Validation loss: 2.717245458608071

Epoch: 5| Step: 1
Training loss: 3.240827822246919
Validation loss: 2.7844135432248445

Epoch: 5| Step: 2
Training loss: 2.328071030368839
Validation loss: 2.704594865167089

Epoch: 5| Step: 3
Training loss: 2.234519046861891
Validation loss: 2.7621562959434245

Epoch: 5| Step: 4
Training loss: 2.788950087047671
Validation loss: 2.6962021804945766

Epoch: 5| Step: 5
Training loss: 2.078957297792555
Validation loss: 2.6982797566895846

Epoch: 5| Step: 6
Training loss: 2.576254055976914
Validation loss: 2.7056351349381704

Epoch: 5| Step: 7
Training loss: 2.1788773757372755
Validation loss: 2.7422052371221532

Epoch: 5| Step: 8
Training loss: 2.141850030473551
Validation loss: 2.7608567843377787

Epoch: 5| Step: 9
Training loss: 2.1477315956795158
Validation loss: 2.731664411854234

Epoch: 5| Step: 10
Training loss: 2.9594411969459964
Validation loss: 2.7292987935849746

Epoch: 165| Step: 0
Training loss: 2.5827375360723
Validation loss: 2.731606723182986

Epoch: 5| Step: 1
Training loss: 3.551692161760935
Validation loss: 2.7195360544076626

Epoch: 5| Step: 2
Training loss: 2.182361562211957
Validation loss: 2.727759118459048

Epoch: 5| Step: 3
Training loss: 2.313051931138819
Validation loss: 2.71497339620915

Epoch: 5| Step: 4
Training loss: 2.214005461330277
Validation loss: 2.753952041113785

Epoch: 5| Step: 5
Training loss: 1.9959967602720705
Validation loss: 2.6957286597258707

Epoch: 5| Step: 6
Training loss: 2.7702887054815695
Validation loss: 2.725109336129445

Epoch: 5| Step: 7
Training loss: 2.6497640072808384
Validation loss: 2.7133387782501366

Epoch: 5| Step: 8
Training loss: 2.6498841242377384
Validation loss: 2.7178777272078394

Epoch: 5| Step: 9
Training loss: 2.1707786152899935
Validation loss: 2.6986214643671076

Epoch: 5| Step: 10
Training loss: 2.367480067941614
Validation loss: 2.790259480614988

Epoch: 166| Step: 0
Training loss: 2.082372354760514
Validation loss: 2.761952001365785

Epoch: 5| Step: 1
Training loss: 2.994550683097572
Validation loss: 2.7159146243418526

Epoch: 5| Step: 2
Training loss: 2.494820092237726
Validation loss: 2.7289862242371314

Epoch: 5| Step: 3
Training loss: 2.330034535360822
Validation loss: 2.7464502754576148

Epoch: 5| Step: 4
Training loss: 2.726234394432854
Validation loss: 2.7679501578130736

Epoch: 5| Step: 5
Training loss: 2.5607447311345672
Validation loss: 2.7894342306375712

Epoch: 5| Step: 6
Training loss: 2.257329552553589
Validation loss: 2.7305657452307184

Epoch: 5| Step: 7
Training loss: 2.8182517683459647
Validation loss: 2.7569980459252195

Epoch: 5| Step: 8
Training loss: 2.7733871240473342
Validation loss: 2.704237199415197

Epoch: 5| Step: 9
Training loss: 2.1507480473281704
Validation loss: 2.679341460614185

Epoch: 5| Step: 10
Training loss: 2.0018255723466094
Validation loss: 2.702463950612759

Epoch: 167| Step: 0
Training loss: 2.279702275563623
Validation loss: 2.7373791811309314

Epoch: 5| Step: 1
Training loss: 2.4416087806618765
Validation loss: 2.7545054175853227

Epoch: 5| Step: 2
Training loss: 2.869533815702127
Validation loss: 2.6910931643114333

Epoch: 5| Step: 3
Training loss: 2.853295371911243
Validation loss: 2.7210062876889562

Epoch: 5| Step: 4
Training loss: 2.6095435721945486
Validation loss: 2.66519907558675

Epoch: 5| Step: 5
Training loss: 1.9080963573436434
Validation loss: 2.710353899025269

Epoch: 5| Step: 6
Training loss: 2.024871789146584
Validation loss: 2.773209353348138

Epoch: 5| Step: 7
Training loss: 2.8154999733790897
Validation loss: 2.790903400944729

Epoch: 5| Step: 8
Training loss: 2.752436685414281
Validation loss: 2.6577245896020543

Epoch: 5| Step: 9
Training loss: 2.5180084121236352
Validation loss: 2.7225720794849946

Epoch: 5| Step: 10
Training loss: 1.9723634408111288
Validation loss: 2.7613076485393226

Epoch: 168| Step: 0
Training loss: 1.6544588588419435
Validation loss: 2.7220926929588845

Epoch: 5| Step: 1
Training loss: 2.032141269871894
Validation loss: 2.7011846150071186

Epoch: 5| Step: 2
Training loss: 3.0660742318759238
Validation loss: 2.7582499499262223

Epoch: 5| Step: 3
Training loss: 2.6415599544724535
Validation loss: 2.679529644686854

Epoch: 5| Step: 4
Training loss: 2.6394170221465334
Validation loss: 2.7286711406323185

Epoch: 5| Step: 5
Training loss: 2.5892138053041576
Validation loss: 2.772588088327986

Epoch: 5| Step: 6
Training loss: 2.91972165649255
Validation loss: 2.738523288406875

Epoch: 5| Step: 7
Training loss: 2.115786718952077
Validation loss: 2.773568342127521

Epoch: 5| Step: 8
Training loss: 2.4707978844847105
Validation loss: 2.791554230317666

Epoch: 5| Step: 9
Training loss: 2.2773045950348614
Validation loss: 2.75700532351723

Epoch: 5| Step: 10
Training loss: 2.2845089770061593
Validation loss: 2.7897177021106963

Epoch: 169| Step: 0
Training loss: 2.42039375538182
Validation loss: 2.740198737597962

Epoch: 5| Step: 1
Training loss: 2.5445878694563726
Validation loss: 2.753608480270928

Epoch: 5| Step: 2
Training loss: 3.2838155253610166
Validation loss: 2.7165471706032727

Epoch: 5| Step: 3
Training loss: 2.0785009287927756
Validation loss: 2.7502672954881398

Epoch: 5| Step: 4
Training loss: 2.205282791411114
Validation loss: 2.7361508773216228

Epoch: 5| Step: 5
Training loss: 2.8286154305969955
Validation loss: 2.6942958203714484

Epoch: 5| Step: 6
Training loss: 2.686747157198207
Validation loss: 2.750472232399559

Epoch: 5| Step: 7
Training loss: 2.166427917041961
Validation loss: 2.7258031245817675

Epoch: 5| Step: 8
Training loss: 2.0263942486897872
Validation loss: 2.761659116826824

Epoch: 5| Step: 9
Training loss: 3.075171898479855
Validation loss: 2.7384635227177854

Epoch: 5| Step: 10
Training loss: 1.7710424038007053
Validation loss: 2.6817208348243247

Epoch: 170| Step: 0
Training loss: 2.56372562034171
Validation loss: 2.7572179701519746

Epoch: 5| Step: 1
Training loss: 2.8566604820134067
Validation loss: 2.6841613433905627

Epoch: 5| Step: 2
Training loss: 2.1692684642203326
Validation loss: 2.733334808089096

Epoch: 5| Step: 3
Training loss: 2.49161209591036
Validation loss: 2.744323855609852

Epoch: 5| Step: 4
Training loss: 2.6203130022570518
Validation loss: 2.7522967779068597

Epoch: 5| Step: 5
Training loss: 2.4486704430111788
Validation loss: 2.746803976154289

Epoch: 5| Step: 6
Training loss: 2.7070780167936737
Validation loss: 2.6491063784264735

Epoch: 5| Step: 7
Training loss: 2.2923298194144235
Validation loss: 2.7256045967277807

Epoch: 5| Step: 8
Training loss: 2.103768591161169
Validation loss: 2.7370889984577214

Epoch: 5| Step: 9
Training loss: 2.3811431540400374
Validation loss: 2.686108734392319

Epoch: 5| Step: 10
Training loss: 2.9599997613236613
Validation loss: 2.725413985922719

Epoch: 171| Step: 0
Training loss: 2.1460411440272784
Validation loss: 2.759280518942538

Epoch: 5| Step: 1
Training loss: 2.622777088462098
Validation loss: 2.685857515120623

Epoch: 5| Step: 2
Training loss: 2.468261090890746
Validation loss: 2.7237487231081614

Epoch: 5| Step: 3
Training loss: 1.9598263940025162
Validation loss: 2.8076414393821674

Epoch: 5| Step: 4
Training loss: 2.6867617990517414
Validation loss: 2.752077159064392

Epoch: 5| Step: 5
Training loss: 2.1608937334219687
Validation loss: 2.661531860139908

Epoch: 5| Step: 6
Training loss: 3.477962049315589
Validation loss: 2.6913701927519798

Epoch: 5| Step: 7
Training loss: 2.2646930751044985
Validation loss: 2.677318806038345

Epoch: 5| Step: 8
Training loss: 2.839853656651823
Validation loss: 2.7214898775606104

Epoch: 5| Step: 9
Training loss: 2.5667676047091743
Validation loss: 2.7176307332803495

Epoch: 5| Step: 10
Training loss: 2.1672601865035537
Validation loss: 2.7007805941255754

Epoch: 172| Step: 0
Training loss: 2.60214483485194
Validation loss: 2.7609294697524005

Epoch: 5| Step: 1
Training loss: 2.2437261426077026
Validation loss: 2.767656087871824

Epoch: 5| Step: 2
Training loss: 2.514871235579064
Validation loss: 2.7293890310060425

Epoch: 5| Step: 3
Training loss: 2.5862242202617045
Validation loss: 2.7664940962459834

Epoch: 5| Step: 4
Training loss: 2.331000376573268
Validation loss: 2.6988123920323415

Epoch: 5| Step: 5
Training loss: 2.6218600794443785
Validation loss: 2.6767053871611597

Epoch: 5| Step: 6
Training loss: 2.3718417400294847
Validation loss: 2.8002707217931917

Epoch: 5| Step: 7
Training loss: 2.3962445003026533
Validation loss: 2.751639145192223

Epoch: 5| Step: 8
Training loss: 2.097793546193517
Validation loss: 2.688033502905504

Epoch: 5| Step: 9
Training loss: 2.3451615215707124
Validation loss: 2.754290756277964

Epoch: 5| Step: 10
Training loss: 3.029987977007187
Validation loss: 2.767121458152289

Epoch: 173| Step: 0
Training loss: 3.152320152676549
Validation loss: 2.767781857957652

Epoch: 5| Step: 1
Training loss: 2.6745009874879417
Validation loss: 2.6949004426763206

Epoch: 5| Step: 2
Training loss: 2.33914128172767
Validation loss: 2.696413013980215

Epoch: 5| Step: 3
Training loss: 2.376491479859588
Validation loss: 2.7417880312102323

Epoch: 5| Step: 4
Training loss: 2.4854881623806766
Validation loss: 2.665987788938567

Epoch: 5| Step: 5
Training loss: 2.0262217568294743
Validation loss: 2.6708541692177286

Epoch: 5| Step: 6
Training loss: 2.581980740836582
Validation loss: 2.776330760861861

Epoch: 5| Step: 7
Training loss: 2.041663370973172
Validation loss: 2.7498539133507207

Epoch: 5| Step: 8
Training loss: 1.6813405973281061
Validation loss: 2.7361205377272855

Epoch: 5| Step: 9
Training loss: 2.8594220267008903
Validation loss: 2.714631763183925

Epoch: 5| Step: 10
Training loss: 2.835094484238242
Validation loss: 2.73189872407062

Epoch: 174| Step: 0
Training loss: 3.070884282497349
Validation loss: 2.7316889138498843

Epoch: 5| Step: 1
Training loss: 2.60204239734939
Validation loss: 2.7199082378532706

Epoch: 5| Step: 2
Training loss: 1.9032842985986393
Validation loss: 2.662113870331595

Epoch: 5| Step: 3
Training loss: 2.3984865065547574
Validation loss: 2.780530734475219

Epoch: 5| Step: 4
Training loss: 1.893478069358728
Validation loss: 2.7385080976242557

Epoch: 5| Step: 5
Training loss: 2.023931141145647
Validation loss: 2.74439679954533

Epoch: 5| Step: 6
Training loss: 1.9085203315145594
Validation loss: 2.7279575599995503

Epoch: 5| Step: 7
Training loss: 2.4410529041175417
Validation loss: 2.781377638491631

Epoch: 5| Step: 8
Training loss: 2.744762808969555
Validation loss: 2.674880877627378

Epoch: 5| Step: 9
Training loss: 2.33017338496469
Validation loss: 2.6981936323812477

Epoch: 5| Step: 10
Training loss: 3.356396725535736
Validation loss: 2.755610517929969

Epoch: 175| Step: 0
Training loss: 2.394004178807588
Validation loss: 2.7286120272835914

Epoch: 5| Step: 1
Training loss: 2.5039311019449704
Validation loss: 2.8135271550739414

Epoch: 5| Step: 2
Training loss: 2.2123173697576144
Validation loss: 2.7408377042904575

Epoch: 5| Step: 3
Training loss: 1.7051541900272766
Validation loss: 2.735223351763019

Epoch: 5| Step: 4
Training loss: 3.1138495832313007
Validation loss: 2.746214348242463

Epoch: 5| Step: 5
Training loss: 2.933488419796818
Validation loss: 2.6949711095211253

Epoch: 5| Step: 6
Training loss: 2.6088036008628084
Validation loss: 2.6885472961637142

Epoch: 5| Step: 7
Training loss: 2.0838431942425317
Validation loss: 2.704365728340557

Epoch: 5| Step: 8
Training loss: 2.7874483625478788
Validation loss: 2.7356666010711117

Epoch: 5| Step: 9
Training loss: 2.112536851008497
Validation loss: 2.7204143826569567

Epoch: 5| Step: 10
Training loss: 2.3896795659752272
Validation loss: 2.667377850722168

Epoch: 176| Step: 0
Training loss: 2.797271870847307
Validation loss: 2.7255691706103913

Epoch: 5| Step: 1
Training loss: 1.7957972736086862
Validation loss: 2.6704416153600437

Epoch: 5| Step: 2
Training loss: 2.6668163396634292
Validation loss: 2.765152306075722

Epoch: 5| Step: 3
Training loss: 2.772537300264843
Validation loss: 2.695618919585448

Epoch: 5| Step: 4
Training loss: 2.191942010077642
Validation loss: 2.696474194668226

Epoch: 5| Step: 5
Training loss: 2.959545281253448
Validation loss: 2.758132787223029

Epoch: 5| Step: 6
Training loss: 1.8448166428922779
Validation loss: 2.6901760643054473

Epoch: 5| Step: 7
Training loss: 2.081881920360102
Validation loss: 2.7157256254475395

Epoch: 5| Step: 8
Training loss: 2.925187135888619
Validation loss: 2.7355045077665165

Epoch: 5| Step: 9
Training loss: 1.6423767184088762
Validation loss: 2.693440548388203

Epoch: 5| Step: 10
Training loss: 2.58867940146102
Validation loss: 2.7247403235136924

Epoch: 177| Step: 0
Training loss: 2.1898205029508797
Validation loss: 2.7559482571786926

Epoch: 5| Step: 1
Training loss: 2.02877939067806
Validation loss: 2.763104102296558

Epoch: 5| Step: 2
Training loss: 2.4789775060300228
Validation loss: 2.7702427365032283

Epoch: 5| Step: 3
Training loss: 2.7007173609549424
Validation loss: 2.715757309624888

Epoch: 5| Step: 4
Training loss: 2.6475544135217683
Validation loss: 2.6875308875187938

Epoch: 5| Step: 5
Training loss: 2.7665816554448375
Validation loss: 2.7938651781202264

Epoch: 5| Step: 6
Training loss: 3.031020637565287
Validation loss: 2.708686378381819

Epoch: 5| Step: 7
Training loss: 2.412672611840962
Validation loss: 2.7447424754590677

Epoch: 5| Step: 8
Training loss: 2.0871691550122433
Validation loss: 2.6709956350966078

Epoch: 5| Step: 9
Training loss: 2.0818323323055496
Validation loss: 2.751005414967362

Epoch: 5| Step: 10
Training loss: 2.306791114904584
Validation loss: 2.732070185873672

Epoch: 178| Step: 0
Training loss: 2.5606049764575136
Validation loss: 2.744970784952238

Epoch: 5| Step: 1
Training loss: 2.5972756013694416
Validation loss: 2.7135696184525817

Epoch: 5| Step: 2
Training loss: 2.0064566817732494
Validation loss: 2.690016358065026

Epoch: 5| Step: 3
Training loss: 2.6853595460232986
Validation loss: 2.7354158694567086

Epoch: 5| Step: 4
Training loss: 2.151241733461996
Validation loss: 2.7031152694103078

Epoch: 5| Step: 5
Training loss: 2.071424883571405
Validation loss: 2.7387883079935187

Epoch: 5| Step: 6
Training loss: 2.1438712127493735
Validation loss: 2.724465778289462

Epoch: 5| Step: 7
Training loss: 2.7465286887181173
Validation loss: 2.677102821240542

Epoch: 5| Step: 8
Training loss: 2.0714644771902875
Validation loss: 2.6665230937988285

Epoch: 5| Step: 9
Training loss: 2.483766685241653
Validation loss: 2.741420209738618

Epoch: 5| Step: 10
Training loss: 3.047116157573679
Validation loss: 2.6508451153980963

Epoch: 179| Step: 0
Training loss: 1.9632901368735085
Validation loss: 2.7321820584743866

Epoch: 5| Step: 1
Training loss: 3.4785962274841826
Validation loss: 2.709827259701836

Epoch: 5| Step: 2
Training loss: 2.4592390708730902
Validation loss: 2.7211221335295255

Epoch: 5| Step: 3
Training loss: 2.1010977645997935
Validation loss: 2.7106566057097123

Epoch: 5| Step: 4
Training loss: 2.0940557228187067
Validation loss: 2.7222137414067538

Epoch: 5| Step: 5
Training loss: 2.4442097185125684
Validation loss: 2.71939206819032

Epoch: 5| Step: 6
Training loss: 2.4043482411628134
Validation loss: 2.7188308622701554

Epoch: 5| Step: 7
Training loss: 2.676222716062783
Validation loss: 2.7514107638257728

Epoch: 5| Step: 8
Training loss: 2.647205977930978
Validation loss: 2.768479792804893

Epoch: 5| Step: 9
Training loss: 2.1745268734630727
Validation loss: 2.7320578925103085

Epoch: 5| Step: 10
Training loss: 2.34388803711348
Validation loss: 2.725780936958666

Epoch: 180| Step: 0
Training loss: 2.278665097109792
Validation loss: 2.7444465642706692

Epoch: 5| Step: 1
Training loss: 2.608273484962261
Validation loss: 2.718337657051825

Epoch: 5| Step: 2
Training loss: 1.8492437724397577
Validation loss: 2.759639039951052

Epoch: 5| Step: 3
Training loss: 3.1723593356163895
Validation loss: 2.773047355954109

Epoch: 5| Step: 4
Training loss: 2.740454144953581
Validation loss: 2.6982952366549053

Epoch: 5| Step: 5
Training loss: 3.1123385467937768
Validation loss: 2.679562811185474

Epoch: 5| Step: 6
Training loss: 2.302377868958731
Validation loss: 2.735983563589732

Epoch: 5| Step: 7
Training loss: 2.2475269289705415
Validation loss: 2.702017864731107

Epoch: 5| Step: 8
Training loss: 2.2484097689150517
Validation loss: 2.7461390011007873

Epoch: 5| Step: 9
Training loss: 1.8620728226873853
Validation loss: 2.7398702495468705

Epoch: 5| Step: 10
Training loss: 2.113457014915147
Validation loss: 2.7146273727634216

Epoch: 181| Step: 0
Training loss: 2.4480255968463527
Validation loss: 2.702362973614239

Epoch: 5| Step: 1
Training loss: 3.006382034796634
Validation loss: 2.691139765108631

Epoch: 5| Step: 2
Training loss: 2.171819672462994
Validation loss: 2.7149681272335324

Epoch: 5| Step: 3
Training loss: 2.541331618274752
Validation loss: 2.6555729610623673

Epoch: 5| Step: 4
Training loss: 2.2829347424999216
Validation loss: 2.7546794880142946

Epoch: 5| Step: 5
Training loss: 2.0597439471615524
Validation loss: 2.7242178985706262

Epoch: 5| Step: 6
Training loss: 2.322594852707419
Validation loss: 2.7514371221156764

Epoch: 5| Step: 7
Training loss: 2.2051766224057063
Validation loss: 2.772310866804819

Epoch: 5| Step: 8
Training loss: 1.5009045257853917
Validation loss: 2.761249296084401

Epoch: 5| Step: 9
Training loss: 3.0052346019599505
Validation loss: 2.725165029712085

Epoch: 5| Step: 10
Training loss: 2.8478617024972075
Validation loss: 2.680612873625913

Epoch: 182| Step: 0
Training loss: 1.6650903240826054
Validation loss: 2.657400211545235

Epoch: 5| Step: 1
Training loss: 1.4629559776060694
Validation loss: 2.7379187992862493

Epoch: 5| Step: 2
Training loss: 2.4657657790999474
Validation loss: 2.709438528850933

Epoch: 5| Step: 3
Training loss: 2.6740833102182497
Validation loss: 2.733388286643931

Epoch: 5| Step: 4
Training loss: 2.4595900949261025
Validation loss: 2.7435950346919484

Epoch: 5| Step: 5
Training loss: 3.3116615241871035
Validation loss: 2.739188571765736

Epoch: 5| Step: 6
Training loss: 1.4822814633663217
Validation loss: 2.706950894232845

Epoch: 5| Step: 7
Training loss: 2.0798500186693007
Validation loss: 2.8028356497739084

Epoch: 5| Step: 8
Training loss: 2.469172284672097
Validation loss: 2.758604692416082

Epoch: 5| Step: 9
Training loss: 2.7468336256294132
Validation loss: 2.720050295730307

Epoch: 5| Step: 10
Training loss: 3.0834606419305035
Validation loss: 2.74808601481952

Epoch: 183| Step: 0
Training loss: 2.948558202879679
Validation loss: 2.659231500079906

Epoch: 5| Step: 1
Training loss: 2.0328379366292633
Validation loss: 2.7795404007799167

Epoch: 5| Step: 2
Training loss: 2.2296214724136028
Validation loss: 2.735470072069499

Epoch: 5| Step: 3
Training loss: 2.221514631574769
Validation loss: 2.699888657424153

Epoch: 5| Step: 4
Training loss: 2.3229722727690296
Validation loss: 2.687327689208002

Epoch: 5| Step: 5
Training loss: 2.867733770817236
Validation loss: 2.7940670906651994

Epoch: 5| Step: 6
Training loss: 3.035054444479873
Validation loss: 2.716138321516687

Epoch: 5| Step: 7
Training loss: 1.629219080024145
Validation loss: 2.710024966246884

Epoch: 5| Step: 8
Training loss: 2.3204170999807987
Validation loss: 2.7803894486952254

Epoch: 5| Step: 9
Training loss: 2.367323264078125
Validation loss: 2.7727406669875014

Epoch: 5| Step: 10
Training loss: 2.229142043313431
Validation loss: 2.7542207281029265

Epoch: 184| Step: 0
Training loss: 2.581034550207578
Validation loss: 2.796319257948331

Epoch: 5| Step: 1
Training loss: 1.2469382936862226
Validation loss: 2.677165286861956

Epoch: 5| Step: 2
Training loss: 1.77344838949885
Validation loss: 2.7005207235294137

Epoch: 5| Step: 3
Training loss: 2.8110874443498717
Validation loss: 2.7105634842157373

Epoch: 5| Step: 4
Training loss: 2.421549424468314
Validation loss: 2.768426318901182

Epoch: 5| Step: 5
Training loss: 2.431711807128313
Validation loss: 2.7024342213074806

Epoch: 5| Step: 6
Training loss: 2.4465144801643937
Validation loss: 2.7081429091938

Epoch: 5| Step: 7
Training loss: 2.755401681462885
Validation loss: 2.756678919525816

Epoch: 5| Step: 8
Training loss: 2.638959731997071
Validation loss: 2.7635506118404467

Epoch: 5| Step: 9
Training loss: 2.2410452987198424
Validation loss: 2.725170388096823

Epoch: 5| Step: 10
Training loss: 2.9294436747495713
Validation loss: 2.676921353268374

Epoch: 185| Step: 0
Training loss: 1.9441291856266325
Validation loss: 2.763483466855793

Epoch: 5| Step: 1
Training loss: 3.2161798678719578
Validation loss: 2.6813679999676348

Epoch: 5| Step: 2
Training loss: 2.1177268379429965
Validation loss: 2.7378990029773607

Epoch: 5| Step: 3
Training loss: 2.2645376819078904
Validation loss: 2.71801766996933

Epoch: 5| Step: 4
Training loss: 2.55443868096153
Validation loss: 2.746323913069169

Epoch: 5| Step: 5
Training loss: 2.5366419125860054
Validation loss: 2.724450649331371

Epoch: 5| Step: 6
Training loss: 2.7372420620567564
Validation loss: 2.760517526843784

Epoch: 5| Step: 7
Training loss: 1.7507633179372277
Validation loss: 2.6808824054239153

Epoch: 5| Step: 8
Training loss: 2.3795897655993494
Validation loss: 2.7209073979933964

Epoch: 5| Step: 9
Training loss: 2.2384520993095474
Validation loss: 2.7344777790213644

Epoch: 5| Step: 10
Training loss: 2.70049020767626
Validation loss: 2.6799104578006463

Epoch: 186| Step: 0
Training loss: 2.892110247123812
Validation loss: 2.7416352709686165

Epoch: 5| Step: 1
Training loss: 2.520956514569827
Validation loss: 2.7187514577976497

Epoch: 5| Step: 2
Training loss: 2.5293490960463347
Validation loss: 2.711742144941092

Epoch: 5| Step: 3
Training loss: 2.0530505023138788
Validation loss: 2.7458285644192064

Epoch: 5| Step: 4
Training loss: 2.881483976251735
Validation loss: 2.7028042078163623

Epoch: 5| Step: 5
Training loss: 2.879389356143073
Validation loss: 2.6932692906342695

Epoch: 5| Step: 6
Training loss: 2.166936405215166
Validation loss: 2.7103243366639047

Epoch: 5| Step: 7
Training loss: 1.6728405882502702
Validation loss: 2.7613684265867473

Epoch: 5| Step: 8
Training loss: 2.252295171165498
Validation loss: 2.6985125805086843

Epoch: 5| Step: 9
Training loss: 2.4159173351823466
Validation loss: 2.6689834881060164

Epoch: 5| Step: 10
Training loss: 1.7422485340871459
Validation loss: 2.7081311480934867

Epoch: 187| Step: 0
Training loss: 2.272605297976986
Validation loss: 2.7772494731152135

Epoch: 5| Step: 1
Training loss: 2.9598956929979363
Validation loss: 2.792797504857308

Epoch: 5| Step: 2
Training loss: 2.2413028473801386
Validation loss: 2.7315322945600653

Epoch: 5| Step: 3
Training loss: 2.516554950819792
Validation loss: 2.7452701546077574

Epoch: 5| Step: 4
Training loss: 2.2209032382901457
Validation loss: 2.754563730487085

Epoch: 5| Step: 5
Training loss: 2.3368611120529064
Validation loss: 2.716329427490436

Epoch: 5| Step: 6
Training loss: 2.661935264619961
Validation loss: 2.711267399051534

Epoch: 5| Step: 7
Training loss: 2.429161677238178
Validation loss: 2.779700073773755

Epoch: 5| Step: 8
Training loss: 2.8788171389490573
Validation loss: 2.744963111682629

Epoch: 5| Step: 9
Training loss: 2.1288150872826614
Validation loss: 2.8054788235067374

Epoch: 5| Step: 10
Training loss: 1.7517791967908176
Validation loss: 2.7198496145846285

Epoch: 188| Step: 0
Training loss: 2.4713315383202112
Validation loss: 2.72199069609464

Epoch: 5| Step: 1
Training loss: 2.7303663242759186
Validation loss: 2.7499662911818614

Epoch: 5| Step: 2
Training loss: 1.930772484073125
Validation loss: 2.7798983773990438

Epoch: 5| Step: 3
Training loss: 2.48148854836153
Validation loss: 2.7208684245278563

Epoch: 5| Step: 4
Training loss: 2.292211144240219
Validation loss: 2.7296879363007847

Epoch: 5| Step: 5
Training loss: 3.061594147907502
Validation loss: 2.688384331985902

Epoch: 5| Step: 6
Training loss: 2.4203832154258924
Validation loss: 2.6617277343083665

Epoch: 5| Step: 7
Training loss: 2.1825752407881978
Validation loss: 2.7149567998455937

Epoch: 5| Step: 8
Training loss: 2.479544495928153
Validation loss: 2.6968076283128535

Epoch: 5| Step: 9
Training loss: 2.1727697052699053
Validation loss: 2.696162325043126

Epoch: 5| Step: 10
Training loss: 2.2332812213036974
Validation loss: 2.655643370218421

Epoch: 189| Step: 0
Training loss: 2.972119637577815
Validation loss: 2.6841703002969073

Epoch: 5| Step: 1
Training loss: 2.871660698168444
Validation loss: 2.7116040830579577

Epoch: 5| Step: 2
Training loss: 2.0856443049080684
Validation loss: 2.72269412070412

Epoch: 5| Step: 3
Training loss: 2.647297481611434
Validation loss: 2.69672985692776

Epoch: 5| Step: 4
Training loss: 2.9213231835524858
Validation loss: 2.7071782696217186

Epoch: 5| Step: 5
Training loss: 2.3214850240697182
Validation loss: 2.7158165819458455

Epoch: 5| Step: 6
Training loss: 2.228943632382639
Validation loss: 2.6784009200447407

Epoch: 5| Step: 7
Training loss: 1.214873335008906
Validation loss: 2.753144199789113

Epoch: 5| Step: 8
Training loss: 2.408897033859847
Validation loss: 2.7100117318964587

Epoch: 5| Step: 9
Training loss: 1.9513005394655647
Validation loss: 2.7583025559912655

Epoch: 5| Step: 10
Training loss: 2.7089785663127164
Validation loss: 2.7406764107168247

Epoch: 190| Step: 0
Training loss: 2.1809250247946705
Validation loss: 2.7326391510860093

Epoch: 5| Step: 1
Training loss: 2.7083048501106393
Validation loss: 2.713326645676326

Epoch: 5| Step: 2
Training loss: 1.8051247995826996
Validation loss: 2.7500131966580947

Epoch: 5| Step: 3
Training loss: 2.3659275844065393
Validation loss: 2.7447920779388064

Epoch: 5| Step: 4
Training loss: 2.1891413389245407
Validation loss: 2.7132225448106073

Epoch: 5| Step: 5
Training loss: 2.662135884635065
Validation loss: 2.7496433735312893

Epoch: 5| Step: 6
Training loss: 2.4685738416185643
Validation loss: 2.733775118934347

Epoch: 5| Step: 7
Training loss: 2.4052250648556495
Validation loss: 2.764466496057093

Epoch: 5| Step: 8
Training loss: 2.5995518701671827
Validation loss: 2.794890122394395

Epoch: 5| Step: 9
Training loss: 2.6212130887512037
Validation loss: 2.7937568849644534

Epoch: 5| Step: 10
Training loss: 1.8177760711844304
Validation loss: 2.745898681512334

Epoch: 191| Step: 0
Training loss: 2.045484347078179
Validation loss: 2.7346646213235957

Epoch: 5| Step: 1
Training loss: 2.0170766644865683
Validation loss: 2.7686364405992996

Epoch: 5| Step: 2
Training loss: 2.6851342012478514
Validation loss: 2.7124690240881653

Epoch: 5| Step: 3
Training loss: 2.6629601488386903
Validation loss: 2.6949995047308386

Epoch: 5| Step: 4
Training loss: 2.0530111342256863
Validation loss: 2.691188343661096

Epoch: 5| Step: 5
Training loss: 2.8342473481862314
Validation loss: 2.7045377337340697

Epoch: 5| Step: 6
Training loss: 2.988905418882863
Validation loss: 2.711820370176116

Epoch: 5| Step: 7
Training loss: 2.235899291921647
Validation loss: 2.641059424231326

Epoch: 5| Step: 8
Training loss: 2.216257441422674
Validation loss: 2.7519123442312523

Epoch: 5| Step: 9
Training loss: 2.6769091380006853
Validation loss: 2.702411372237224

Epoch: 5| Step: 10
Training loss: 2.3707329414266445
Validation loss: 2.6863138930168473

Epoch: 192| Step: 0
Training loss: 2.740396376570407
Validation loss: 2.6933469925166227

Epoch: 5| Step: 1
Training loss: 1.5839427561531059
Validation loss: 2.6987705897774483

Epoch: 5| Step: 2
Training loss: 2.4116598969184153
Validation loss: 2.6820414083027564

Epoch: 5| Step: 3
Training loss: 1.8833035663626672
Validation loss: 2.6796044395066194

Epoch: 5| Step: 4
Training loss: 2.7055796685037476
Validation loss: 2.629050918911481

Epoch: 5| Step: 5
Training loss: 2.5140760877774317
Validation loss: 2.6679159972461775

Epoch: 5| Step: 6
Training loss: 2.1209312081626552
Validation loss: 2.7655331769211196

Epoch: 5| Step: 7
Training loss: 2.663012524198962
Validation loss: 2.741694929180037

Epoch: 5| Step: 8
Training loss: 1.5994132903368892
Validation loss: 2.698919912596325

Epoch: 5| Step: 9
Training loss: 2.8378005620602194
Validation loss: 2.700001486493381

Epoch: 5| Step: 10
Training loss: 2.8801321579492525
Validation loss: 2.736059675754681

Epoch: 193| Step: 0
Training loss: 2.614878167984991
Validation loss: 2.700880175180572

Epoch: 5| Step: 1
Training loss: 2.541464646445687
Validation loss: 2.720006134650909

Epoch: 5| Step: 2
Training loss: 2.063724154536368
Validation loss: 2.743850619230322

Epoch: 5| Step: 3
Training loss: 2.30770541945425
Validation loss: 2.7478587986917367

Epoch: 5| Step: 4
Training loss: 2.8697529886527424
Validation loss: 2.74935125247932

Epoch: 5| Step: 5
Training loss: 2.9463714395904295
Validation loss: 2.688384064024567

Epoch: 5| Step: 6
Training loss: 2.1254908051005863
Validation loss: 2.741984322418791

Epoch: 5| Step: 7
Training loss: 1.898884724501514
Validation loss: 2.734933559952031

Epoch: 5| Step: 8
Training loss: 1.9682067848286315
Validation loss: 2.684684698249706

Epoch: 5| Step: 9
Training loss: 1.9937069353098484
Validation loss: 2.7453040564934446

Epoch: 5| Step: 10
Training loss: 2.5909172123381685
Validation loss: 2.747331993731063

Epoch: 194| Step: 0
Training loss: 1.8595189912323191
Validation loss: 2.7205236003642495

Epoch: 5| Step: 1
Training loss: 2.3614181867388786
Validation loss: 2.7027694626715015

Epoch: 5| Step: 2
Training loss: 2.644388169625725
Validation loss: 2.7260870163552373

Epoch: 5| Step: 3
Training loss: 2.395751443099183
Validation loss: 2.7046580219020795

Epoch: 5| Step: 4
Training loss: 2.195372991305434
Validation loss: 2.7578061267093914

Epoch: 5| Step: 5
Training loss: 2.6395548621501113
Validation loss: 2.683237603411813

Epoch: 5| Step: 6
Training loss: 2.1647169314862245
Validation loss: 2.6754227909147636

Epoch: 5| Step: 7
Training loss: 2.898945972024705
Validation loss: 2.70056065752825

Epoch: 5| Step: 8
Training loss: 2.4820708139908665
Validation loss: 2.713880082816076

Epoch: 5| Step: 9
Training loss: 2.7709250662014773
Validation loss: 2.6668610075793953

Epoch: 5| Step: 10
Training loss: 1.4582717973351038
Validation loss: 2.760425877957213

Epoch: 195| Step: 0
Training loss: 1.8748865729037805
Validation loss: 2.740178351508268

Epoch: 5| Step: 1
Training loss: 1.8510382831680667
Validation loss: 2.7218812396269008

Epoch: 5| Step: 2
Training loss: 2.127749963727432
Validation loss: 2.7217902729284122

Epoch: 5| Step: 3
Training loss: 2.2686237352613503
Validation loss: 2.661219099651061

Epoch: 5| Step: 4
Training loss: 2.726250748177294
Validation loss: 2.764760208422017

Epoch: 5| Step: 5
Training loss: 2.1504888555419344
Validation loss: 2.765673945231193

Epoch: 5| Step: 6
Training loss: 2.6959582453643995
Validation loss: 2.729725863472903

Epoch: 5| Step: 7
Training loss: 1.9533761435212633
Validation loss: 2.7435769183051955

Epoch: 5| Step: 8
Training loss: 2.969236153399686
Validation loss: 2.7048521009117823

Epoch: 5| Step: 9
Training loss: 2.7753067809291796
Validation loss: 2.7299741398856407

Epoch: 5| Step: 10
Training loss: 3.071816888765981
Validation loss: 2.6967119789836724

Epoch: 196| Step: 0
Training loss: 2.084266936605027
Validation loss: 2.671297535923136

Epoch: 5| Step: 1
Training loss: 3.1383909563827417
Validation loss: 2.7353831233792447

Epoch: 5| Step: 2
Training loss: 2.862013469810964
Validation loss: 2.6981321001686185

Epoch: 5| Step: 3
Training loss: 2.5558994230024292
Validation loss: 2.7205769378044358

Epoch: 5| Step: 4
Training loss: 2.3175927865589983
Validation loss: 2.7786168696077636

Epoch: 5| Step: 5
Training loss: 2.681680277554159
Validation loss: 2.6781796878636563

Epoch: 5| Step: 6
Training loss: 2.4454591359788016
Validation loss: 2.705294346803746

Epoch: 5| Step: 7
Training loss: 1.8672681974585854
Validation loss: 2.6919320742716155

Epoch: 5| Step: 8
Training loss: 1.7880388021376463
Validation loss: 2.6621601733460625

Epoch: 5| Step: 9
Training loss: 2.149752349784801
Validation loss: 2.7246893784080783

Epoch: 5| Step: 10
Training loss: 2.0508829727375937
Validation loss: 2.7019283024555767

Epoch: 197| Step: 0
Training loss: 2.7748968878482128
Validation loss: 2.659352807019294

Epoch: 5| Step: 1
Training loss: 1.793334657652034
Validation loss: 2.7929137347484088

Epoch: 5| Step: 2
Training loss: 2.639360926611143
Validation loss: 2.6998391861615345

Epoch: 5| Step: 3
Training loss: 2.4995675666652235
Validation loss: 2.719074762165015

Epoch: 5| Step: 4
Training loss: 2.515659687442819
Validation loss: 2.72417491363274

Epoch: 5| Step: 5
Training loss: 2.2134480056394894
Validation loss: 2.700699500389237

Epoch: 5| Step: 6
Training loss: 1.9864704152383104
Validation loss: 2.718994870754911

Epoch: 5| Step: 7
Training loss: 2.4223727791432172
Validation loss: 2.7278841661392583

Epoch: 5| Step: 8
Training loss: 2.9758104390510223
Validation loss: 2.6497543893685487

Epoch: 5| Step: 9
Training loss: 2.0816690154885733
Validation loss: 2.719655743782624

Epoch: 5| Step: 10
Training loss: 2.031066534119877
Validation loss: 2.7073334986836017

Epoch: 198| Step: 0
Training loss: 2.2043088072704466
Validation loss: 2.7109906326528947

Epoch: 5| Step: 1
Training loss: 2.3055316995308273
Validation loss: 2.7090110732245742

Epoch: 5| Step: 2
Training loss: 2.360613365316365
Validation loss: 2.7306639528066174

Epoch: 5| Step: 3
Training loss: 2.2441298946857806
Validation loss: 2.7009146769622983

Epoch: 5| Step: 4
Training loss: 2.3765781580141443
Validation loss: 2.7355539675552536

Epoch: 5| Step: 5
Training loss: 2.529199970995993
Validation loss: 2.7087713674583296

Epoch: 5| Step: 6
Training loss: 2.0372101419603488
Validation loss: 2.752635172408538

Epoch: 5| Step: 7
Training loss: 2.7074208605358074
Validation loss: 2.6541318996019307

Epoch: 5| Step: 8
Training loss: 1.859537966983486
Validation loss: 2.705523171884201

Epoch: 5| Step: 9
Training loss: 3.190676583555916
Validation loss: 2.743433663071608

Epoch: 5| Step: 10
Training loss: 2.026335537215173
Validation loss: 2.670196850549921

Epoch: 199| Step: 0
Training loss: 2.6520251615087274
Validation loss: 2.732394347188199

Epoch: 5| Step: 1
Training loss: 2.425802184673404
Validation loss: 2.7032740415120964

Epoch: 5| Step: 2
Training loss: 2.2162054810675755
Validation loss: 2.7390585844834883

Epoch: 5| Step: 3
Training loss: 3.0693710475640628
Validation loss: 2.7186747441421386

Epoch: 5| Step: 4
Training loss: 2.553904375441439
Validation loss: 2.673330683216525

Epoch: 5| Step: 5
Training loss: 1.9470169995295135
Validation loss: 2.659818301757409

Epoch: 5| Step: 6
Training loss: 2.7913103208331997
Validation loss: 2.6905676048609286

Epoch: 5| Step: 7
Training loss: 2.299427404861539
Validation loss: 2.7551730378722286

Epoch: 5| Step: 8
Training loss: 2.4212018461859732
Validation loss: 2.744436017108843

Epoch: 5| Step: 9
Training loss: 1.819137914654345
Validation loss: 2.6897010823263505

Epoch: 5| Step: 10
Training loss: 1.5909500958991774
Validation loss: 2.7371839402201106

Epoch: 200| Step: 0
Training loss: 2.2434523998742897
Validation loss: 2.7236933723537304

Epoch: 5| Step: 1
Training loss: 2.5372785199101924
Validation loss: 2.7830400853166597

Epoch: 5| Step: 2
Training loss: 2.132980731295842
Validation loss: 2.7245557307161232

Epoch: 5| Step: 3
Training loss: 2.1555816056730075
Validation loss: 2.7399892775674064

Epoch: 5| Step: 4
Training loss: 1.9053109154077579
Validation loss: 2.6622377123836776

Epoch: 5| Step: 5
Training loss: 2.9416965782078455
Validation loss: 2.689011839424065

Epoch: 5| Step: 6
Training loss: 2.395174173540254
Validation loss: 2.7444024510640452

Epoch: 5| Step: 7
Training loss: 2.7353954917706007
Validation loss: 2.6380088532236354

Epoch: 5| Step: 8
Training loss: 2.031659598501218
Validation loss: 2.6691077692430283

Epoch: 5| Step: 9
Training loss: 1.7732940481370953
Validation loss: 2.7664708903558504

Epoch: 5| Step: 10
Training loss: 2.590701322271064
Validation loss: 2.7291562542735894

Testing loss: 2.704500929868521
