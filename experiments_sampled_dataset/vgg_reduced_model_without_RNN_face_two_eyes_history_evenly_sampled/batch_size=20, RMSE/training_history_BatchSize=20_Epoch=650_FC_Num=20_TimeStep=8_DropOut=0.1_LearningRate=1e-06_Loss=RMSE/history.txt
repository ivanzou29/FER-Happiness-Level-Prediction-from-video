Epoch: 1| Step: 0
Training loss: 2.891496186814753
Validation loss: 2.679533779758209

Epoch: 5| Step: 1
Training loss: 2.732168648078923
Validation loss: 2.673824732797548

Epoch: 5| Step: 2
Training loss: 3.5409072211326627
Validation loss: 2.672722765987827

Epoch: 5| Step: 3
Training loss: 2.784840527117237
Validation loss: 2.672308374719011

Epoch: 5| Step: 4
Training loss: 3.3622481014244365
Validation loss: 2.6695287257042404

Epoch: 5| Step: 5
Training loss: 3.0479501245678264
Validation loss: 2.6693753203383968

Epoch: 5| Step: 6
Training loss: 2.8941900590177703
Validation loss: 2.6685843289272344

Epoch: 5| Step: 7
Training loss: 3.547458684679335
Validation loss: 2.6631045205826807

Epoch: 5| Step: 8
Training loss: 3.3880226942561102
Validation loss: 2.662159669700867

Epoch: 5| Step: 9
Training loss: 2.1926656493852175
Validation loss: 2.6613297554318973

Epoch: 5| Step: 10
Training loss: 2.9747675893064627
Validation loss: 2.6616449465043197

Epoch: 2| Step: 0
Training loss: 3.0110787232343577
Validation loss: 2.658182633758373

Epoch: 5| Step: 1
Training loss: 2.878644871848171
Validation loss: 2.654046817416957

Epoch: 5| Step: 2
Training loss: 2.6115897824335708
Validation loss: 2.6537451924078725

Epoch: 5| Step: 3
Training loss: 2.7894428752459253
Validation loss: 2.65164211680906

Epoch: 5| Step: 4
Training loss: 3.5475894695717964
Validation loss: 2.649742753205685

Epoch: 5| Step: 5
Training loss: 2.7359365309665082
Validation loss: 2.648996298856813

Epoch: 5| Step: 6
Training loss: 3.585623933134673
Validation loss: 2.6494924651321994

Epoch: 5| Step: 7
Training loss: 2.599091051850028
Validation loss: 2.646085595496327

Epoch: 5| Step: 8
Training loss: 2.903175614719568
Validation loss: 2.6426823380406077

Epoch: 5| Step: 9
Training loss: 3.242178381481906
Validation loss: 2.640879079574415

Epoch: 5| Step: 10
Training loss: 3.4049282484294916
Validation loss: 2.6424632942026185

Epoch: 3| Step: 0
Training loss: 3.222165120009822
Validation loss: 2.6392370912504983

Epoch: 5| Step: 1
Training loss: 2.9206902861201365
Validation loss: 2.6386787789302297

Epoch: 5| Step: 2
Training loss: 2.676184942603067
Validation loss: 2.636533631237739

Epoch: 5| Step: 3
Training loss: 3.5771453715776516
Validation loss: 2.6351366368944276

Epoch: 5| Step: 4
Training loss: 3.151145962757212
Validation loss: 2.633341300428412

Epoch: 5| Step: 5
Training loss: 2.593710841607176
Validation loss: 2.6300324701130906

Epoch: 5| Step: 6
Training loss: 3.192808779224932
Validation loss: 2.6313800217566126

Epoch: 5| Step: 7
Training loss: 2.7675664089819056
Validation loss: 2.6292527688433935

Epoch: 5| Step: 8
Training loss: 2.8879562017548666
Validation loss: 2.6258829646595645

Epoch: 5| Step: 9
Training loss: 3.2538076250716053
Validation loss: 2.627211410292714

Epoch: 5| Step: 10
Training loss: 2.944836808299341
Validation loss: 2.626376522125597

Epoch: 4| Step: 0
Training loss: 2.42427642881502
Validation loss: 2.622020223620393

Epoch: 5| Step: 1
Training loss: 2.9929282762961797
Validation loss: 2.621215207176217

Epoch: 5| Step: 2
Training loss: 3.042190158335382
Validation loss: 2.61935738815307

Epoch: 5| Step: 3
Training loss: 3.7081424506847513
Validation loss: 2.6174531065071527

Epoch: 5| Step: 4
Training loss: 2.528309185170087
Validation loss: 2.616212570022785

Epoch: 5| Step: 5
Training loss: 3.228057736548137
Validation loss: 2.614236401161535

Epoch: 5| Step: 6
Training loss: 2.952258755019925
Validation loss: 2.6142315381331835

Epoch: 5| Step: 7
Training loss: 2.87502355151274
Validation loss: 2.61360163623638

Epoch: 5| Step: 8
Training loss: 3.0093733267616063
Validation loss: 2.6151157153021343

Epoch: 5| Step: 9
Training loss: 3.0375213245538113
Validation loss: 2.611525773821915

Epoch: 5| Step: 10
Training loss: 3.2267191481722794
Validation loss: 2.6089462017356664

Epoch: 5| Step: 0
Training loss: 2.416620473310595
Validation loss: 2.60580990406367

Epoch: 5| Step: 1
Training loss: 3.269125198800084
Validation loss: 2.6057520047936706

Epoch: 5| Step: 2
Training loss: 3.11003604168875
Validation loss: 2.6062672710458767

Epoch: 5| Step: 3
Training loss: 2.604616772218295
Validation loss: 2.6053144912302675

Epoch: 5| Step: 4
Training loss: 3.1412374174546858
Validation loss: 2.60015144427696

Epoch: 5| Step: 5
Training loss: 2.895458078198505
Validation loss: 2.6006517166947605

Epoch: 5| Step: 6
Training loss: 2.8613964502294578
Validation loss: 2.604293099236265

Epoch: 5| Step: 7
Training loss: 3.3270918267766088
Validation loss: 2.599658242901169

Epoch: 5| Step: 8
Training loss: 3.582449486130783
Validation loss: 2.599337205186431

Epoch: 5| Step: 9
Training loss: 2.6809231325461105
Validation loss: 2.595249551548258

Epoch: 5| Step: 10
Training loss: 2.9784210089992555
Validation loss: 2.5952683042643363

Epoch: 6| Step: 0
Training loss: 2.6846849646704523
Validation loss: 2.593809387816007

Epoch: 5| Step: 1
Training loss: 2.7981156309446833
Validation loss: 2.593384099306802

Epoch: 5| Step: 2
Training loss: 2.9782109539361077
Validation loss: 2.5907124220822073

Epoch: 5| Step: 3
Training loss: 2.520405084052904
Validation loss: 2.590017494262623

Epoch: 5| Step: 4
Training loss: 2.9719259841348307
Validation loss: 2.589633402345604

Epoch: 5| Step: 5
Training loss: 2.8842652338205443
Validation loss: 2.5894309955588564

Epoch: 5| Step: 6
Training loss: 3.3332533032028917
Validation loss: 2.5857632228248324

Epoch: 5| Step: 7
Training loss: 3.328148783567454
Validation loss: 2.584332965067997

Epoch: 5| Step: 8
Training loss: 3.012858015764556
Validation loss: 2.5854791554076546

Epoch: 5| Step: 9
Training loss: 3.2487304848954106
Validation loss: 2.582740608185876

Epoch: 5| Step: 10
Training loss: 3.1478255744510317
Validation loss: 2.579962966782255

Epoch: 7| Step: 0
Training loss: 2.599421080914383
Validation loss: 2.5823418470757327

Epoch: 5| Step: 1
Training loss: 3.0130949327242242
Validation loss: 2.5817720264684763

Epoch: 5| Step: 2
Training loss: 2.6672170984897488
Validation loss: 2.5789775672975903

Epoch: 5| Step: 3
Training loss: 3.554472327793921
Validation loss: 2.5795075419540634

Epoch: 5| Step: 4
Training loss: 2.6819565844566995
Validation loss: 2.5784332926342923

Epoch: 5| Step: 5
Training loss: 3.569122316410166
Validation loss: 2.578174989078332

Epoch: 5| Step: 6
Training loss: 2.697006798769225
Validation loss: 2.574469499094226

Epoch: 5| Step: 7
Training loss: 3.18443465097428
Validation loss: 2.5758243641023197

Epoch: 5| Step: 8
Training loss: 2.9405957405994023
Validation loss: 2.57543757315164

Epoch: 5| Step: 9
Training loss: 2.99826221997371
Validation loss: 2.573695453820676

Epoch: 5| Step: 10
Training loss: 2.7519267874892988
Validation loss: 2.5735451703404744

Epoch: 8| Step: 0
Training loss: 2.66016153791577
Validation loss: 2.5689518859298524

Epoch: 5| Step: 1
Training loss: 3.093013483096414
Validation loss: 2.569241709103076

Epoch: 5| Step: 2
Training loss: 2.5517301561599255
Validation loss: 2.568802888287504

Epoch: 5| Step: 3
Training loss: 3.06196106820301
Validation loss: 2.5677262561660723

Epoch: 5| Step: 4
Training loss: 2.734006497211452
Validation loss: 2.568911199898729

Epoch: 5| Step: 5
Training loss: 2.91760104516787
Validation loss: 2.5679135867768603

Epoch: 5| Step: 6
Training loss: 2.953384953113023
Validation loss: 2.566650210211802

Epoch: 5| Step: 7
Training loss: 2.8474844421551158
Validation loss: 2.5645235137255264

Epoch: 5| Step: 8
Training loss: 3.332539098214076
Validation loss: 2.5639794253644816

Epoch: 5| Step: 9
Training loss: 3.127204575158942
Validation loss: 2.5650700752354414

Epoch: 5| Step: 10
Training loss: 3.488057059914969
Validation loss: 2.5620398079437656

Epoch: 9| Step: 0
Training loss: 2.7293534736666683
Validation loss: 2.5599964416547114

Epoch: 5| Step: 1
Training loss: 2.9581145263847537
Validation loss: 2.5600499812016673

Epoch: 5| Step: 2
Training loss: 3.0795452114080817
Validation loss: 2.56051446768654

Epoch: 5| Step: 3
Training loss: 3.2974662069884006
Validation loss: 2.5584542255297826

Epoch: 5| Step: 4
Training loss: 3.017081585866774
Validation loss: 2.557575340836885

Epoch: 5| Step: 5
Training loss: 2.8149986188488785
Validation loss: 2.558156957903373

Epoch: 5| Step: 6
Training loss: 3.0014709998843854
Validation loss: 2.5549604000378623

Epoch: 5| Step: 7
Training loss: 2.6677968987764675
Validation loss: 2.556580406867389

Epoch: 5| Step: 8
Training loss: 2.7121330505243173
Validation loss: 2.555213343501167

Epoch: 5| Step: 9
Training loss: 3.348402262905907
Validation loss: 2.5560272678571945

Epoch: 5| Step: 10
Training loss: 3.042108651713171
Validation loss: 2.551712256939021

Epoch: 10| Step: 0
Training loss: 3.2399878704173664
Validation loss: 2.5525192789129463

Epoch: 5| Step: 1
Training loss: 3.028719602929017
Validation loss: 2.552005669368696

Epoch: 5| Step: 2
Training loss: 3.199903403254719
Validation loss: 2.550020612753604

Epoch: 5| Step: 3
Training loss: 2.798300608870931
Validation loss: 2.5500782503205843

Epoch: 5| Step: 4
Training loss: 2.7883097169662254
Validation loss: 2.5483605316397977

Epoch: 5| Step: 5
Training loss: 2.9588770478678925
Validation loss: 2.545785412798

Epoch: 5| Step: 6
Training loss: 2.8642902756108684
Validation loss: 2.547559952935985

Epoch: 5| Step: 7
Training loss: 2.9114415549862214
Validation loss: 2.5451385076187223

Epoch: 5| Step: 8
Training loss: 2.975446997648493
Validation loss: 2.5416786627954555

Epoch: 5| Step: 9
Training loss: 2.894574740310931
Validation loss: 2.5468480214242026

Epoch: 5| Step: 10
Training loss: 3.0179374406826303
Validation loss: 2.545589676060061

Epoch: 11| Step: 0
Training loss: 3.0419616207834275
Validation loss: 2.5405081582050206

Epoch: 5| Step: 1
Training loss: 2.328388788012975
Validation loss: 2.541682184966463

Epoch: 5| Step: 2
Training loss: 3.1586279645260746
Validation loss: 2.5445018728946445

Epoch: 5| Step: 3
Training loss: 3.04488491699027
Validation loss: 2.5399726532583164

Epoch: 5| Step: 4
Training loss: 2.9502127683818236
Validation loss: 2.5406086489931736

Epoch: 5| Step: 5
Training loss: 3.044555563728053
Validation loss: 2.538550568900633

Epoch: 5| Step: 6
Training loss: 2.8392783419366836
Validation loss: 2.5398889077370597

Epoch: 5| Step: 7
Training loss: 2.9952682690844536
Validation loss: 2.5381918854130974

Epoch: 5| Step: 8
Training loss: 3.1087293098230555
Validation loss: 2.5381164333047033

Epoch: 5| Step: 9
Training loss: 2.9422753659750533
Validation loss: 2.535506326769897

Epoch: 5| Step: 10
Training loss: 3.0852556851616475
Validation loss: 2.535128835250549

Epoch: 12| Step: 0
Training loss: 2.9184654865011574
Validation loss: 2.5399707405996

Epoch: 5| Step: 1
Training loss: 2.5903508537104782
Validation loss: 2.534408351067322

Epoch: 5| Step: 2
Training loss: 3.0724385207429483
Validation loss: 2.536107711544263

Epoch: 5| Step: 3
Training loss: 3.3844756867849526
Validation loss: 2.5340535619831908

Epoch: 5| Step: 4
Training loss: 2.7354180662602383
Validation loss: 2.530351868118056

Epoch: 5| Step: 5
Training loss: 3.2142957959698197
Validation loss: 2.5346283835774637

Epoch: 5| Step: 6
Training loss: 2.8200694478729447
Validation loss: 2.531626759530205

Epoch: 5| Step: 7
Training loss: 2.936928226746036
Validation loss: 2.5326877958218823

Epoch: 5| Step: 8
Training loss: 3.0140099820969697
Validation loss: 2.529179842505205

Epoch: 5| Step: 9
Training loss: 2.9856345829002353
Validation loss: 2.5297472204890545

Epoch: 5| Step: 10
Training loss: 2.7496241399360732
Validation loss: 2.5275688440756423

Epoch: 13| Step: 0
Training loss: 2.7058197877680166
Validation loss: 2.5259348329246767

Epoch: 5| Step: 1
Training loss: 3.2699668530291968
Validation loss: 2.530483800864469

Epoch: 5| Step: 2
Training loss: 3.2450033070880986
Validation loss: 2.5280717083248905

Epoch: 5| Step: 3
Training loss: 3.089171595713989
Validation loss: 2.526707726062518

Epoch: 5| Step: 4
Training loss: 3.0813211800360207
Validation loss: 2.5268101505882097

Epoch: 5| Step: 5
Training loss: 2.673634535341462
Validation loss: 2.527361675735921

Epoch: 5| Step: 6
Training loss: 2.5885572733622886
Validation loss: 2.5258507102759156

Epoch: 5| Step: 7
Training loss: 2.7219172477728164
Validation loss: 2.5265294799761553

Epoch: 5| Step: 8
Training loss: 3.413115974697942
Validation loss: 2.5278260694696835

Epoch: 5| Step: 9
Training loss: 2.9533097143785936
Validation loss: 2.5252831065494252

Epoch: 5| Step: 10
Training loss: 2.5443288795828356
Validation loss: 2.5264026731902236

Epoch: 14| Step: 0
Training loss: 3.1062388490902717
Validation loss: 2.5238483144968615

Epoch: 5| Step: 1
Training loss: 2.9767824427127145
Validation loss: 2.5216365467818904

Epoch: 5| Step: 2
Training loss: 2.995101744590527
Validation loss: 2.5222613538232297

Epoch: 5| Step: 3
Training loss: 2.701522263800371
Validation loss: 2.5208229614575983

Epoch: 5| Step: 4
Training loss: 2.593653665615015
Validation loss: 2.520297013170037

Epoch: 5| Step: 5
Training loss: 2.6323337742273467
Validation loss: 2.5199275886710875

Epoch: 5| Step: 6
Training loss: 3.2869090372235634
Validation loss: 2.5217870136983995

Epoch: 5| Step: 7
Training loss: 3.0886550719533927
Validation loss: 2.5200378707361883

Epoch: 5| Step: 8
Training loss: 2.872789943261684
Validation loss: 2.5209815757104796

Epoch: 5| Step: 9
Training loss: 3.243523526968028
Validation loss: 2.5207753920161244

Epoch: 5| Step: 10
Training loss: 2.871675974660509
Validation loss: 2.5182380106439877

Epoch: 15| Step: 0
Training loss: 3.127876636199346
Validation loss: 2.518778595522484

Epoch: 5| Step: 1
Training loss: 2.7104152209321803
Validation loss: 2.5175883242356614

Epoch: 5| Step: 2
Training loss: 3.320168453906653
Validation loss: 2.5136389643158146

Epoch: 5| Step: 3
Training loss: 2.4867482875420386
Validation loss: 2.514191080426818

Epoch: 5| Step: 4
Training loss: 2.7466371088227612
Validation loss: 2.5173321027620204

Epoch: 5| Step: 5
Training loss: 3.005420397455553
Validation loss: 2.513797580076987

Epoch: 5| Step: 6
Training loss: 3.1165542915470996
Validation loss: 2.514412139867633

Epoch: 5| Step: 7
Training loss: 2.936623138064721
Validation loss: 2.5147153299691376

Epoch: 5| Step: 8
Training loss: 2.936477320784371
Validation loss: 2.5132624867925326

Epoch: 5| Step: 9
Training loss: 3.0529736640461502
Validation loss: 2.5153134111702444

Epoch: 5| Step: 10
Training loss: 2.8606391155285547
Validation loss: 2.5139004908326297

Epoch: 16| Step: 0
Training loss: 2.8204522349223997
Validation loss: 2.509836469828015

Epoch: 5| Step: 1
Training loss: 2.8374478440385755
Validation loss: 2.5134230877340777

Epoch: 5| Step: 2
Training loss: 2.968175250182492
Validation loss: 2.5123025972833384

Epoch: 5| Step: 3
Training loss: 3.051714843447496
Validation loss: 2.510347874374182

Epoch: 5| Step: 4
Training loss: 2.6343421001800906
Validation loss: 2.508003201800397

Epoch: 5| Step: 5
Training loss: 2.3860865378406655
Validation loss: 2.5070138228814365

Epoch: 5| Step: 6
Training loss: 3.064119805904548
Validation loss: 2.5088358205064014

Epoch: 5| Step: 7
Training loss: 3.491670506246879
Validation loss: 2.5058899386851294

Epoch: 5| Step: 8
Training loss: 3.3949370498326856
Validation loss: 2.5080616403985343

Epoch: 5| Step: 9
Training loss: 2.8396791937794634
Validation loss: 2.505718630941132

Epoch: 5| Step: 10
Training loss: 2.649357008750322
Validation loss: 2.508280133965655

Epoch: 17| Step: 0
Training loss: 2.8652137386356373
Validation loss: 2.5056153565145007

Epoch: 5| Step: 1
Training loss: 3.01379908492859
Validation loss: 2.5044026135196757

Epoch: 5| Step: 2
Training loss: 2.9757251913489444
Validation loss: 2.506728938399851

Epoch: 5| Step: 3
Training loss: 2.8147418094485013
Validation loss: 2.505272117691165

Epoch: 5| Step: 4
Training loss: 2.964071341558209
Validation loss: 2.5036623442449697

Epoch: 5| Step: 5
Training loss: 2.824755183726891
Validation loss: 2.5034308856492697

Epoch: 5| Step: 6
Training loss: 2.657678825699236
Validation loss: 2.5021288288463843

Epoch: 5| Step: 7
Training loss: 3.0743674953591666
Validation loss: 2.5043238708031064

Epoch: 5| Step: 8
Training loss: 2.889272342403724
Validation loss: 2.502084003928696

Epoch: 5| Step: 9
Training loss: 3.212935297229331
Validation loss: 2.503542412547851

Epoch: 5| Step: 10
Training loss: 3.031655982447653
Validation loss: 2.496645610027821

Epoch: 18| Step: 0
Training loss: 2.5947346484396028
Validation loss: 2.5036387194155494

Epoch: 5| Step: 1
Training loss: 2.8794955060751244
Validation loss: 2.499261975819908

Epoch: 5| Step: 2
Training loss: 2.990431626464821
Validation loss: 2.500769353228586

Epoch: 5| Step: 3
Training loss: 2.779095533186015
Validation loss: 2.5025512086002535

Epoch: 5| Step: 4
Training loss: 2.8590040956503215
Validation loss: 2.5013334450801192

Epoch: 5| Step: 5
Training loss: 3.1320515229236787
Validation loss: 2.4998544486549776

Epoch: 5| Step: 6
Training loss: 3.073886179596959
Validation loss: 2.4991523269505462

Epoch: 5| Step: 7
Training loss: 2.826868948026492
Validation loss: 2.4956096728161454

Epoch: 5| Step: 8
Training loss: 3.0952898297160876
Validation loss: 2.49819252960668

Epoch: 5| Step: 9
Training loss: 3.10149162461329
Validation loss: 2.4949637959134408

Epoch: 5| Step: 10
Training loss: 2.9040512463380224
Validation loss: 2.498008385922769

Epoch: 19| Step: 0
Training loss: 2.9965948807290292
Validation loss: 2.4980528416569925

Epoch: 5| Step: 1
Training loss: 2.9481661705585855
Validation loss: 2.4962517819603205

Epoch: 5| Step: 2
Training loss: 2.5972137303703686
Validation loss: 2.4941626911149393

Epoch: 5| Step: 3
Training loss: 2.5773165273254945
Validation loss: 2.494477696819898

Epoch: 5| Step: 4
Training loss: 2.573923282135055
Validation loss: 2.4947478971551575

Epoch: 5| Step: 5
Training loss: 3.176034539551379
Validation loss: 2.497032028078585

Epoch: 5| Step: 6
Training loss: 3.2486719205602346
Validation loss: 2.498084323900642

Epoch: 5| Step: 7
Training loss: 3.3673136747223547
Validation loss: 2.496546824587586

Epoch: 5| Step: 8
Training loss: 2.722699245731842
Validation loss: 2.4976492217329835

Epoch: 5| Step: 9
Training loss: 3.1059639014156253
Validation loss: 2.4977047997811193

Epoch: 5| Step: 10
Training loss: 2.7538017523669187
Validation loss: 2.4949729850632076

Epoch: 20| Step: 0
Training loss: 2.753525554775994
Validation loss: 2.4960598495661417

Epoch: 5| Step: 1
Training loss: 2.5013019986064102
Validation loss: 2.492556511948667

Epoch: 5| Step: 2
Training loss: 3.246183942696306
Validation loss: 2.49325228735518

Epoch: 5| Step: 3
Training loss: 2.582531117402281
Validation loss: 2.49307242363498

Epoch: 5| Step: 4
Training loss: 3.1855715733733674
Validation loss: 2.492461777932131

Epoch: 5| Step: 5
Training loss: 2.644194859080795
Validation loss: 2.493907025500924

Epoch: 5| Step: 6
Training loss: 3.1788676936674753
Validation loss: 2.489855602395312

Epoch: 5| Step: 7
Training loss: 2.9783763415179534
Validation loss: 2.488677434408218

Epoch: 5| Step: 8
Training loss: 2.9232349188958877
Validation loss: 2.4934038924015907

Epoch: 5| Step: 9
Training loss: 3.200315108281896
Validation loss: 2.490770981825437

Epoch: 5| Step: 10
Training loss: 2.9012925720378515
Validation loss: 2.490851028855387

Epoch: 21| Step: 0
Training loss: 2.4959476052066902
Validation loss: 2.4927320558863206

Epoch: 5| Step: 1
Training loss: 3.2767363975558643
Validation loss: 2.4877517751690523

Epoch: 5| Step: 2
Training loss: 3.4427688447113662
Validation loss: 2.490766343994202

Epoch: 5| Step: 3
Training loss: 2.9704421190197072
Validation loss: 2.493421400002191

Epoch: 5| Step: 4
Training loss: 2.729702166565403
Validation loss: 2.490914918069688

Epoch: 5| Step: 5
Training loss: 2.788317840071017
Validation loss: 2.4885830456570366

Epoch: 5| Step: 6
Training loss: 3.347198989245844
Validation loss: 2.4928127824581234

Epoch: 5| Step: 7
Training loss: 2.5269584538947134
Validation loss: 2.490197266172089

Epoch: 5| Step: 8
Training loss: 3.14936182732845
Validation loss: 2.4895238599359515

Epoch: 5| Step: 9
Training loss: 2.837405662816958
Validation loss: 2.4892928539722945

Epoch: 5| Step: 10
Training loss: 2.30485032363129
Validation loss: 2.4864721761483013

Epoch: 22| Step: 0
Training loss: 3.161768856645983
Validation loss: 2.490177202302329

Epoch: 5| Step: 1
Training loss: 2.8042995854051274
Validation loss: 2.4901141960264535

Epoch: 5| Step: 2
Training loss: 2.7121300616458197
Validation loss: 2.491953509601034

Epoch: 5| Step: 3
Training loss: 3.155936197223389
Validation loss: 2.483464892692575

Epoch: 5| Step: 4
Training loss: 2.755546005892186
Validation loss: 2.485872380460325

Epoch: 5| Step: 5
Training loss: 2.7792943014855442
Validation loss: 2.4887025702809416

Epoch: 5| Step: 6
Training loss: 2.9364174004487515
Validation loss: 2.4851122780055395

Epoch: 5| Step: 7
Training loss: 2.4276369524901584
Validation loss: 2.4882773637592353

Epoch: 5| Step: 8
Training loss: 3.0255808564204316
Validation loss: 2.4871138252062286

Epoch: 5| Step: 9
Training loss: 3.210460172569241
Validation loss: 2.489082582289474

Epoch: 5| Step: 10
Training loss: 3.129667839487517
Validation loss: 2.486859381214014

Epoch: 23| Step: 0
Training loss: 3.2841362747558134
Validation loss: 2.4836209536190297

Epoch: 5| Step: 1
Training loss: 2.870096586243689
Validation loss: 2.4861105338001783

Epoch: 5| Step: 2
Training loss: 3.231632857818842
Validation loss: 2.4865272627241986

Epoch: 5| Step: 3
Training loss: 2.711731280553689
Validation loss: 2.4855184123718717

Epoch: 5| Step: 4
Training loss: 2.2094068856750915
Validation loss: 2.4840717880063843

Epoch: 5| Step: 5
Training loss: 2.3758411925511562
Validation loss: 2.486043790466939

Epoch: 5| Step: 6
Training loss: 2.825759235409175
Validation loss: 2.4875415865515293

Epoch: 5| Step: 7
Training loss: 3.244185454847163
Validation loss: 2.4841951312995088

Epoch: 5| Step: 8
Training loss: 3.0403362831034775
Validation loss: 2.4859152371638222

Epoch: 5| Step: 9
Training loss: 3.2848586810645948
Validation loss: 2.4833405231201895

Epoch: 5| Step: 10
Training loss: 2.807128863783375
Validation loss: 2.4841780901490447

Epoch: 24| Step: 0
Training loss: 2.834903581113295
Validation loss: 2.484060033138402

Epoch: 5| Step: 1
Training loss: 3.053689857168605
Validation loss: 2.487092388204219

Epoch: 5| Step: 2
Training loss: 3.2997432724474947
Validation loss: 2.483998777920448

Epoch: 5| Step: 3
Training loss: 2.483363683459628
Validation loss: 2.4839321584599525

Epoch: 5| Step: 4
Training loss: 2.673020948088907
Validation loss: 2.4851315636837508

Epoch: 5| Step: 5
Training loss: 3.042012565140415
Validation loss: 2.4818449185043527

Epoch: 5| Step: 6
Training loss: 2.8293120701260817
Validation loss: 2.4804210810384153

Epoch: 5| Step: 7
Training loss: 2.8911806964278406
Validation loss: 2.482722950707445

Epoch: 5| Step: 8
Training loss: 3.069280630566772
Validation loss: 2.4871556380123696

Epoch: 5| Step: 9
Training loss: 2.7717172364901144
Validation loss: 2.479865598061773

Epoch: 5| Step: 10
Training loss: 3.095944945700993
Validation loss: 2.481883956764891

Epoch: 25| Step: 0
Training loss: 2.892519768043169
Validation loss: 2.4844041511639983

Epoch: 5| Step: 1
Training loss: 2.5981995437495993
Validation loss: 2.4854277365909825

Epoch: 5| Step: 2
Training loss: 3.0605141565537353
Validation loss: 2.48326264560429

Epoch: 5| Step: 3
Training loss: 2.8489429722196897
Validation loss: 2.4765962812100093

Epoch: 5| Step: 4
Training loss: 3.065034245957791
Validation loss: 2.4810614235277244

Epoch: 5| Step: 5
Training loss: 3.073354674766513
Validation loss: 2.4819957195385642

Epoch: 5| Step: 6
Training loss: 2.8440741050390397
Validation loss: 2.4831552873459697

Epoch: 5| Step: 7
Training loss: 3.0227532610555032
Validation loss: 2.478487712004391

Epoch: 5| Step: 8
Training loss: 2.8131301174019807
Validation loss: 2.4813065197773447

Epoch: 5| Step: 9
Training loss: 2.784126080519085
Validation loss: 2.481449113360179

Epoch: 5| Step: 10
Training loss: 3.020842786752225
Validation loss: 2.4784193007697586

Epoch: 26| Step: 0
Training loss: 2.5786568757705988
Validation loss: 2.4781556188121514

Epoch: 5| Step: 1
Training loss: 3.2852016813241613
Validation loss: 2.4835241719159513

Epoch: 5| Step: 2
Training loss: 3.0577190215296146
Validation loss: 2.4785771026106986

Epoch: 5| Step: 3
Training loss: 2.760531719377219
Validation loss: 2.480570968215461

Epoch: 5| Step: 4
Training loss: 2.419505874062219
Validation loss: 2.4773210304782016

Epoch: 5| Step: 5
Training loss: 2.6494320602733703
Validation loss: 2.477592065078899

Epoch: 5| Step: 6
Training loss: 3.0609126745739066
Validation loss: 2.477810297768124

Epoch: 5| Step: 7
Training loss: 2.5557808592436233
Validation loss: 2.4804456251592706

Epoch: 5| Step: 8
Training loss: 2.517564109129915
Validation loss: 2.4778216342882

Epoch: 5| Step: 9
Training loss: 3.450622756700248
Validation loss: 2.4775181148745067

Epoch: 5| Step: 10
Training loss: 3.5387980044392395
Validation loss: 2.481836666192158

Epoch: 27| Step: 0
Training loss: 3.199695220976697
Validation loss: 2.4771808403434985

Epoch: 5| Step: 1
Training loss: 2.8623661593002434
Validation loss: 2.4770814069858433

Epoch: 5| Step: 2
Training loss: 3.1595880966690566
Validation loss: 2.4828797108257583

Epoch: 5| Step: 3
Training loss: 2.936461894256573
Validation loss: 2.476790460920342

Epoch: 5| Step: 4
Training loss: 2.5942777533376034
Validation loss: 2.4828334149756914

Epoch: 5| Step: 5
Training loss: 2.768935038495126
Validation loss: 2.4801639420313455

Epoch: 5| Step: 6
Training loss: 2.730741866481968
Validation loss: 2.4775820509346977

Epoch: 5| Step: 7
Training loss: 3.3419492632189507
Validation loss: 2.474804353899983

Epoch: 5| Step: 8
Training loss: 2.5737771102566844
Validation loss: 2.4764422424399477

Epoch: 5| Step: 9
Training loss: 3.1322587206348653
Validation loss: 2.475416096248214

Epoch: 5| Step: 10
Training loss: 2.5180898402323626
Validation loss: 2.4767347789398095

Epoch: 28| Step: 0
Training loss: 2.6562136479302505
Validation loss: 2.4767060550567472

Epoch: 5| Step: 1
Training loss: 3.037761498015149
Validation loss: 2.4765585415416025

Epoch: 5| Step: 2
Training loss: 2.988941633270407
Validation loss: 2.4757383748115496

Epoch: 5| Step: 3
Training loss: 3.4549815162793607
Validation loss: 2.47693608209065

Epoch: 5| Step: 4
Training loss: 2.8492007155353636
Validation loss: 2.474434468813032

Epoch: 5| Step: 5
Training loss: 3.122807611075882
Validation loss: 2.478017287396334

Epoch: 5| Step: 6
Training loss: 2.3316503881504738
Validation loss: 2.472425108290417

Epoch: 5| Step: 7
Training loss: 2.6694958004315588
Validation loss: 2.471851143089787

Epoch: 5| Step: 8
Training loss: 2.7571224397542866
Validation loss: 2.4737709921783555

Epoch: 5| Step: 9
Training loss: 3.0080973700834273
Validation loss: 2.4750043173120786

Epoch: 5| Step: 10
Training loss: 2.992626665919467
Validation loss: 2.4753411437546546

Epoch: 29| Step: 0
Training loss: 3.2316443669331956
Validation loss: 2.474065964607572

Epoch: 5| Step: 1
Training loss: 2.8332382260983975
Validation loss: 2.473697000289684

Epoch: 5| Step: 2
Training loss: 3.104524135275219
Validation loss: 2.4765414054015955

Epoch: 5| Step: 3
Training loss: 2.889101688991915
Validation loss: 2.474365484458827

Epoch: 5| Step: 4
Training loss: 2.8937733593650856
Validation loss: 2.4741719666723365

Epoch: 5| Step: 5
Training loss: 2.6734832920275085
Validation loss: 2.476128214517832

Epoch: 5| Step: 6
Training loss: 2.841731266693255
Validation loss: 2.4734268064801976

Epoch: 5| Step: 7
Training loss: 2.6745453813646085
Validation loss: 2.4732082823613686

Epoch: 5| Step: 8
Training loss: 2.9633761305520245
Validation loss: 2.4773426710399833

Epoch: 5| Step: 9
Training loss: 2.660094317865016
Validation loss: 2.473971758267948

Epoch: 5| Step: 10
Training loss: 3.126686709108622
Validation loss: 2.4754866534153925

Epoch: 30| Step: 0
Training loss: 2.9992550878765414
Validation loss: 2.4719653299327455

Epoch: 5| Step: 1
Training loss: 2.808874888137069
Validation loss: 2.474419091694333

Epoch: 5| Step: 2
Training loss: 3.0495365353516157
Validation loss: 2.474926325609999

Epoch: 5| Step: 3
Training loss: 3.036104542627313
Validation loss: 2.4763844262572188

Epoch: 5| Step: 4
Training loss: 3.2697017356331513
Validation loss: 2.4688430525601857

Epoch: 5| Step: 5
Training loss: 2.919800700349382
Validation loss: 2.471293594805986

Epoch: 5| Step: 6
Training loss: 2.9789361575566438
Validation loss: 2.4717055251999254

Epoch: 5| Step: 7
Training loss: 2.8354311824728793
Validation loss: 2.4713533526984746

Epoch: 5| Step: 8
Training loss: 2.448095815609758
Validation loss: 2.478639139283772

Epoch: 5| Step: 9
Training loss: 2.6344518792823206
Validation loss: 2.466901212309648

Epoch: 5| Step: 10
Training loss: 2.8019292758345213
Validation loss: 2.475232940112396

Epoch: 31| Step: 0
Training loss: 3.3154747039929866
Validation loss: 2.4744673259205223

Epoch: 5| Step: 1
Training loss: 2.7612543430527343
Validation loss: 2.470949019410911

Epoch: 5| Step: 2
Training loss: 2.3451100790056336
Validation loss: 2.473974021425791

Epoch: 5| Step: 3
Training loss: 2.9246476833381614
Validation loss: 2.473811072914325

Epoch: 5| Step: 4
Training loss: 2.6113067603253732
Validation loss: 2.4700010439076037

Epoch: 5| Step: 5
Training loss: 3.161003687604511
Validation loss: 2.470109489707453

Epoch: 5| Step: 6
Training loss: 3.156596098704883
Validation loss: 2.4681756184887056

Epoch: 5| Step: 7
Training loss: 2.939834965336164
Validation loss: 2.4695735444081173

Epoch: 5| Step: 8
Training loss: 2.5898132782721417
Validation loss: 2.4727525395366245

Epoch: 5| Step: 9
Training loss: 2.778805633688131
Validation loss: 2.4681777830934855

Epoch: 5| Step: 10
Training loss: 3.178017217408217
Validation loss: 2.4716529668584126

Epoch: 32| Step: 0
Training loss: 2.5963460041454773
Validation loss: 2.470028929298311

Epoch: 5| Step: 1
Training loss: 2.971934006483253
Validation loss: 2.4729077857399604

Epoch: 5| Step: 2
Training loss: 2.677632069041948
Validation loss: 2.472351571772191

Epoch: 5| Step: 3
Training loss: 3.3225851023088877
Validation loss: 2.4660480272529313

Epoch: 5| Step: 4
Training loss: 2.379341774646638
Validation loss: 2.471129594985824

Epoch: 5| Step: 5
Training loss: 3.154563831098927
Validation loss: 2.4654779585078543

Epoch: 5| Step: 6
Training loss: 3.11814953483736
Validation loss: 2.4660144622827493

Epoch: 5| Step: 7
Training loss: 2.476918095712624
Validation loss: 2.4715967096390177

Epoch: 5| Step: 8
Training loss: 2.9106703745733467
Validation loss: 2.463103870594175

Epoch: 5| Step: 9
Training loss: 3.1112082746258864
Validation loss: 2.469437505140309

Epoch: 5| Step: 10
Training loss: 2.9686965134470444
Validation loss: 2.4706489193552303

Epoch: 33| Step: 0
Training loss: 3.0076155957261683
Validation loss: 2.460443400028789

Epoch: 5| Step: 1
Training loss: 2.5272698841178776
Validation loss: 2.4683361472429612

Epoch: 5| Step: 2
Training loss: 3.0031858058969996
Validation loss: 2.46835789150336

Epoch: 5| Step: 3
Training loss: 3.1070853386176305
Validation loss: 2.469510818036024

Epoch: 5| Step: 4
Training loss: 2.8701545684342684
Validation loss: 2.468080817531667

Epoch: 5| Step: 5
Training loss: 2.9437037761971006
Validation loss: 2.469272109191789

Epoch: 5| Step: 6
Training loss: 2.72245115714489
Validation loss: 2.4601473871867436

Epoch: 5| Step: 7
Training loss: 2.9751250232744453
Validation loss: 2.46856507345617

Epoch: 5| Step: 8
Training loss: 2.7823113977172267
Validation loss: 2.4679538538093837

Epoch: 5| Step: 9
Training loss: 2.8879477810140988
Validation loss: 2.4678625897949105

Epoch: 5| Step: 10
Training loss: 2.9637518318263925
Validation loss: 2.4659979811090773

Epoch: 34| Step: 0
Training loss: 2.7663118188486204
Validation loss: 2.4679158781011727

Epoch: 5| Step: 1
Training loss: 2.9074819271349237
Validation loss: 2.465736886888204

Epoch: 5| Step: 2
Training loss: 2.8154821056894104
Validation loss: 2.463554989150172

Epoch: 5| Step: 3
Training loss: 2.8715539265038754
Validation loss: 2.466920185184145

Epoch: 5| Step: 4
Training loss: 3.006098112524204
Validation loss: 2.464692358235247

Epoch: 5| Step: 5
Training loss: 2.9282037258251896
Validation loss: 2.4710688606177365

Epoch: 5| Step: 6
Training loss: 2.9868004015658536
Validation loss: 2.461868810477183

Epoch: 5| Step: 7
Training loss: 2.793659770285096
Validation loss: 2.462140901033476

Epoch: 5| Step: 8
Training loss: 3.0950034328558744
Validation loss: 2.4680166613026255

Epoch: 5| Step: 9
Training loss: 2.7179983568895327
Validation loss: 2.4638078473753335

Epoch: 5| Step: 10
Training loss: 2.8231756412945903
Validation loss: 2.462950876136587

Epoch: 35| Step: 0
Training loss: 2.9886436093107727
Validation loss: 2.4644528279469715

Epoch: 5| Step: 1
Training loss: 2.584872484585296
Validation loss: 2.464835046575001

Epoch: 5| Step: 2
Training loss: 3.03259216168548
Validation loss: 2.465411966813959

Epoch: 5| Step: 3
Training loss: 2.8419354696658963
Validation loss: 2.4652354388770807

Epoch: 5| Step: 4
Training loss: 3.1599534468300026
Validation loss: 2.4627044392151887

Epoch: 5| Step: 5
Training loss: 2.610944081999577
Validation loss: 2.4640745836919695

Epoch: 5| Step: 6
Training loss: 2.6543292113096517
Validation loss: 2.463274938036449

Epoch: 5| Step: 7
Training loss: 2.6482578993133647
Validation loss: 2.4662876167441246

Epoch: 5| Step: 8
Training loss: 3.488853142859614
Validation loss: 2.4654001323357897

Epoch: 5| Step: 9
Training loss: 2.781818888914049
Validation loss: 2.4617777999093216

Epoch: 5| Step: 10
Training loss: 2.814794918063413
Validation loss: 2.4687060939861234

Epoch: 36| Step: 0
Training loss: 3.079220649407778
Validation loss: 2.466351868363267

Epoch: 5| Step: 1
Training loss: 3.3257298693855963
Validation loss: 2.469035034423143

Epoch: 5| Step: 2
Training loss: 2.8356576996957426
Validation loss: 2.4689706153681854

Epoch: 5| Step: 3
Training loss: 3.395178484038293
Validation loss: 2.4653771266381317

Epoch: 5| Step: 4
Training loss: 3.0192040269817753
Validation loss: 2.465967196932005

Epoch: 5| Step: 5
Training loss: 2.8943500333371075
Validation loss: 2.4621602120219617

Epoch: 5| Step: 6
Training loss: 2.332206885594491
Validation loss: 2.459673022362598

Epoch: 5| Step: 7
Training loss: 2.6032337399561705
Validation loss: 2.4643926083297543

Epoch: 5| Step: 8
Training loss: 2.588334278009082
Validation loss: 2.4633081339299663

Epoch: 5| Step: 9
Training loss: 2.857397510896641
Validation loss: 2.4633763279121803

Epoch: 5| Step: 10
Training loss: 2.542645833832095
Validation loss: 2.46469680589681

Epoch: 37| Step: 0
Training loss: 3.071859887086902
Validation loss: 2.462746165741135

Epoch: 5| Step: 1
Training loss: 2.743085491376543
Validation loss: 2.4643956958575344

Epoch: 5| Step: 2
Training loss: 2.9532204264405992
Validation loss: 2.465167486633592

Epoch: 5| Step: 3
Training loss: 2.802031723360219
Validation loss: 2.458953030732057

Epoch: 5| Step: 4
Training loss: 2.6348797297672117
Validation loss: 2.4645710107405847

Epoch: 5| Step: 5
Training loss: 3.066151524551386
Validation loss: 2.46264298384487

Epoch: 5| Step: 6
Training loss: 2.506581417250625
Validation loss: 2.4631732858719246

Epoch: 5| Step: 7
Training loss: 2.873100482536499
Validation loss: 2.459937552654831

Epoch: 5| Step: 8
Training loss: 2.8245466999522564
Validation loss: 2.4615695999061176

Epoch: 5| Step: 9
Training loss: 3.116212926736673
Validation loss: 2.4629813873145445

Epoch: 5| Step: 10
Training loss: 3.0706005786349326
Validation loss: 2.462065911446816

Epoch: 38| Step: 0
Training loss: 2.8363400008143818
Validation loss: 2.4634959235219047

Epoch: 5| Step: 1
Training loss: 3.059326707655592
Validation loss: 2.4623772876614147

Epoch: 5| Step: 2
Training loss: 2.614738206468613
Validation loss: 2.463747498573894

Epoch: 5| Step: 3
Training loss: 2.5407101024530587
Validation loss: 2.459581534468316

Epoch: 5| Step: 4
Training loss: 3.0509015986385393
Validation loss: 2.458954733776188

Epoch: 5| Step: 5
Training loss: 3.2097024514688792
Validation loss: 2.46414026059426

Epoch: 5| Step: 6
Training loss: 2.8243050252101396
Validation loss: 2.4572296581555952

Epoch: 5| Step: 7
Training loss: 3.005126070497702
Validation loss: 2.459142856331749

Epoch: 5| Step: 8
Training loss: 3.1877228902041415
Validation loss: 2.46011815805042

Epoch: 5| Step: 9
Training loss: 2.2878055180877
Validation loss: 2.460988297518472

Epoch: 5| Step: 10
Training loss: 2.8626551756797727
Validation loss: 2.454977596967605

Epoch: 39| Step: 0
Training loss: 2.6263300841084996
Validation loss: 2.4576796477211977

Epoch: 5| Step: 1
Training loss: 2.840884599059909
Validation loss: 2.462267093649335

Epoch: 5| Step: 2
Training loss: 2.673710688818755
Validation loss: 2.4575701182854446

Epoch: 5| Step: 3
Training loss: 3.416610081521992
Validation loss: 2.4550744984227384

Epoch: 5| Step: 4
Training loss: 2.717626756170179
Validation loss: 2.4589305261467826

Epoch: 5| Step: 5
Training loss: 2.883053653213823
Validation loss: 2.4593104382405886

Epoch: 5| Step: 6
Training loss: 2.7980304228115105
Validation loss: 2.4612293847052604

Epoch: 5| Step: 7
Training loss: 2.8518865531839523
Validation loss: 2.453703687236209

Epoch: 5| Step: 8
Training loss: 2.8911670073568407
Validation loss: 2.456557371388644

Epoch: 5| Step: 9
Training loss: 2.82718453128946
Validation loss: 2.455275507980059

Epoch: 5| Step: 10
Training loss: 3.073753544703391
Validation loss: 2.456547522480868

Epoch: 40| Step: 0
Training loss: 3.2467965697581156
Validation loss: 2.453893050743438

Epoch: 5| Step: 1
Training loss: 3.186823754475582
Validation loss: 2.456312355883008

Epoch: 5| Step: 2
Training loss: 3.124104333314912
Validation loss: 2.4601717735390074

Epoch: 5| Step: 3
Training loss: 2.4718938197445515
Validation loss: 2.455817674017038

Epoch: 5| Step: 4
Training loss: 2.943536116489755
Validation loss: 2.455950638875633

Epoch: 5| Step: 5
Training loss: 2.764902656317863
Validation loss: 2.4559352420605234

Epoch: 5| Step: 6
Training loss: 2.3869518909120915
Validation loss: 2.4624460009012727

Epoch: 5| Step: 7
Training loss: 2.839042036185364
Validation loss: 2.4546406060472283

Epoch: 5| Step: 8
Training loss: 2.7757193621009915
Validation loss: 2.4580571426353357

Epoch: 5| Step: 9
Training loss: 3.0331273508524594
Validation loss: 2.458434546215374

Epoch: 5| Step: 10
Training loss: 2.6416496681444652
Validation loss: 2.4527708986375

Epoch: 41| Step: 0
Training loss: 2.856345150487486
Validation loss: 2.4592084913727703

Epoch: 5| Step: 1
Training loss: 2.8085407787946295
Validation loss: 2.4551410707932475

Epoch: 5| Step: 2
Training loss: 3.1125677384814843
Validation loss: 2.4578822476215945

Epoch: 5| Step: 3
Training loss: 2.205837771021298
Validation loss: 2.4598112076998255

Epoch: 5| Step: 4
Training loss: 2.9224379706020454
Validation loss: 2.45650067714324

Epoch: 5| Step: 5
Training loss: 2.678706932273482
Validation loss: 2.4537206976391874

Epoch: 5| Step: 6
Training loss: 2.892787475016157
Validation loss: 2.451252788454619

Epoch: 5| Step: 7
Training loss: 2.7704265745271415
Validation loss: 2.455353518290109

Epoch: 5| Step: 8
Training loss: 3.0912326628078888
Validation loss: 2.45594436481561

Epoch: 5| Step: 9
Training loss: 3.3657421718592233
Validation loss: 2.4537066105974374

Epoch: 5| Step: 10
Training loss: 2.6371294168042114
Validation loss: 2.460173203241587

Epoch: 42| Step: 0
Training loss: 3.1204547633795063
Validation loss: 2.4553878512710883

Epoch: 5| Step: 1
Training loss: 2.807612092386681
Validation loss: 2.4548300372208995

Epoch: 5| Step: 2
Training loss: 2.884666115730409
Validation loss: 2.4571159112531613

Epoch: 5| Step: 3
Training loss: 3.1026043811486588
Validation loss: 2.4491730404578886

Epoch: 5| Step: 4
Training loss: 2.8747152104510683
Validation loss: 2.456063990910801

Epoch: 5| Step: 5
Training loss: 2.613641962037857
Validation loss: 2.457007577464727

Epoch: 5| Step: 6
Training loss: 2.8684092732790423
Validation loss: 2.4549013980510614

Epoch: 5| Step: 7
Training loss: 2.8439562376923417
Validation loss: 2.450189792212225

Epoch: 5| Step: 8
Training loss: 2.3291920514392523
Validation loss: 2.4513270886352894

Epoch: 5| Step: 9
Training loss: 3.0711845731927587
Validation loss: 2.451877249235291

Epoch: 5| Step: 10
Training loss: 2.9120779361985045
Validation loss: 2.4554507839041575

Epoch: 43| Step: 0
Training loss: 2.872624286456148
Validation loss: 2.453363339464451

Epoch: 5| Step: 1
Training loss: 2.668606638575452
Validation loss: 2.4514351573676643

Epoch: 5| Step: 2
Training loss: 2.2694426895170094
Validation loss: 2.456506381535498

Epoch: 5| Step: 3
Training loss: 2.8295028449335944
Validation loss: 2.455164163008478

Epoch: 5| Step: 4
Training loss: 3.053207155838333
Validation loss: 2.458739557034119

Epoch: 5| Step: 5
Training loss: 2.734934635113517
Validation loss: 2.4569162636984467

Epoch: 5| Step: 6
Training loss: 2.869689182637006
Validation loss: 2.4541795432714006

Epoch: 5| Step: 7
Training loss: 3.0629860628504044
Validation loss: 2.4540244860225426

Epoch: 5| Step: 8
Training loss: 2.718873909066866
Validation loss: 2.4475701108816184

Epoch: 5| Step: 9
Training loss: 2.9970965640651377
Validation loss: 2.45388840903091

Epoch: 5| Step: 10
Training loss: 3.300102787150988
Validation loss: 2.4493361459978575

Epoch: 44| Step: 0
Training loss: 2.619886959054275
Validation loss: 2.4551997380649144

Epoch: 5| Step: 1
Training loss: 2.7968117477680927
Validation loss: 2.4530848174615016

Epoch: 5| Step: 2
Training loss: 2.67877217221752
Validation loss: 2.4500611197369517

Epoch: 5| Step: 3
Training loss: 2.9950851871558366
Validation loss: 2.449195489728649

Epoch: 5| Step: 4
Training loss: 2.7108481444657713
Validation loss: 2.4467766454164424

Epoch: 5| Step: 5
Training loss: 3.1733395056571023
Validation loss: 2.453866253429949

Epoch: 5| Step: 6
Training loss: 2.9622046343519832
Validation loss: 2.4460330548762776

Epoch: 5| Step: 7
Training loss: 2.214191535845458
Validation loss: 2.4519001243886884

Epoch: 5| Step: 8
Training loss: 2.6938906250113286
Validation loss: 2.453349968255043

Epoch: 5| Step: 9
Training loss: 3.309631545197414
Validation loss: 2.446164849600649

Epoch: 5| Step: 10
Training loss: 3.1156731849548627
Validation loss: 2.4443553194067125

Epoch: 45| Step: 0
Training loss: 2.730351130362991
Validation loss: 2.446667147601691

Epoch: 5| Step: 1
Training loss: 2.97324889763087
Validation loss: 2.4544978253692693

Epoch: 5| Step: 2
Training loss: 3.0563364090825145
Validation loss: 2.4504153448516988

Epoch: 5| Step: 3
Training loss: 2.884904469407509
Validation loss: 2.4500659863423837

Epoch: 5| Step: 4
Training loss: 2.9155454569573207
Validation loss: 2.4462305158368953

Epoch: 5| Step: 5
Training loss: 3.018199079010858
Validation loss: 2.4484746467669694

Epoch: 5| Step: 6
Training loss: 2.9170019956103936
Validation loss: 2.451782657718697

Epoch: 5| Step: 7
Training loss: 2.4604427748631883
Validation loss: 2.452743147326679

Epoch: 5| Step: 8
Training loss: 2.7664691908193086
Validation loss: 2.4502596957567544

Epoch: 5| Step: 9
Training loss: 2.8235788636107797
Validation loss: 2.449726268627508

Epoch: 5| Step: 10
Training loss: 2.750364539520215
Validation loss: 2.446808694163656

Epoch: 46| Step: 0
Training loss: 3.201914488775835
Validation loss: 2.447184725328925

Epoch: 5| Step: 1
Training loss: 2.66933369384189
Validation loss: 2.452330300221321

Epoch: 5| Step: 2
Training loss: 3.0978603608470827
Validation loss: 2.4478314016796294

Epoch: 5| Step: 3
Training loss: 2.8339465169658635
Validation loss: 2.447524882749055

Epoch: 5| Step: 4
Training loss: 2.5970176428076965
Validation loss: 2.450846805351033

Epoch: 5| Step: 5
Training loss: 2.5592906672518505
Validation loss: 2.4464180088214036

Epoch: 5| Step: 6
Training loss: 2.962526564338146
Validation loss: 2.446236189682518

Epoch: 5| Step: 7
Training loss: 3.0327865009873824
Validation loss: 2.4523405836974312

Epoch: 5| Step: 8
Training loss: 2.941057688614555
Validation loss: 2.446641427938985

Epoch: 5| Step: 9
Training loss: 2.500805534285403
Validation loss: 2.450836583598911

Epoch: 5| Step: 10
Training loss: 2.89066261060836
Validation loss: 2.446640178412919

Epoch: 47| Step: 0
Training loss: 2.598133198255094
Validation loss: 2.449133863909772

Epoch: 5| Step: 1
Training loss: 2.886803487687702
Validation loss: 2.449117931215519

Epoch: 5| Step: 2
Training loss: 2.987090787434404
Validation loss: 2.4524941721134015

Epoch: 5| Step: 3
Training loss: 2.863710712111748
Validation loss: 2.4544478513186583

Epoch: 5| Step: 4
Training loss: 3.2477804087273183
Validation loss: 2.450270734958624

Epoch: 5| Step: 5
Training loss: 2.691516093322727
Validation loss: 2.4475091370248383

Epoch: 5| Step: 6
Training loss: 2.5105591940618384
Validation loss: 2.4423957525181947

Epoch: 5| Step: 7
Training loss: 3.117395226768324
Validation loss: 2.44032996479469

Epoch: 5| Step: 8
Training loss: 2.5415047974452087
Validation loss: 2.4478638733403186

Epoch: 5| Step: 9
Training loss: 2.926455899978929
Validation loss: 2.4461128355928894

Epoch: 5| Step: 10
Training loss: 2.8761186496628537
Validation loss: 2.447199105523131

Epoch: 48| Step: 0
Training loss: 3.1008927321150574
Validation loss: 2.4430129531226754

Epoch: 5| Step: 1
Training loss: 2.6583624125676946
Validation loss: 2.4478756805388864

Epoch: 5| Step: 2
Training loss: 2.8338312571704427
Validation loss: 2.443150289573558

Epoch: 5| Step: 3
Training loss: 2.494089865410704
Validation loss: 2.4419890674890805

Epoch: 5| Step: 4
Training loss: 2.812911194306433
Validation loss: 2.4456442991453624

Epoch: 5| Step: 5
Training loss: 2.9797035924980033
Validation loss: 2.449042806134496

Epoch: 5| Step: 6
Training loss: 3.382704241916702
Validation loss: 2.4455625281802513

Epoch: 5| Step: 7
Training loss: 2.963112869929839
Validation loss: 2.450714005026471

Epoch: 5| Step: 8
Training loss: 2.4348946365652697
Validation loss: 2.4452758291472874

Epoch: 5| Step: 9
Training loss: 2.8653691734012092
Validation loss: 2.437778181468058

Epoch: 5| Step: 10
Training loss: 2.4972472294154215
Validation loss: 2.441911144659267

Epoch: 49| Step: 0
Training loss: 3.238519197379703
Validation loss: 2.4472231206885713

Epoch: 5| Step: 1
Training loss: 2.8113683331163606
Validation loss: 2.4440136330897673

Epoch: 5| Step: 2
Training loss: 2.5878581955515267
Validation loss: 2.444442164823054

Epoch: 5| Step: 3
Training loss: 2.4635356448679926
Validation loss: 2.45137303933156

Epoch: 5| Step: 4
Training loss: 2.4178139385896062
Validation loss: 2.4449499221106668

Epoch: 5| Step: 5
Training loss: 2.442587800024318
Validation loss: 2.440603146743998

Epoch: 5| Step: 6
Training loss: 2.5256165346618773
Validation loss: 2.4416557962181993

Epoch: 5| Step: 7
Training loss: 3.1129324800231544
Validation loss: 2.4423765985798105

Epoch: 5| Step: 8
Training loss: 3.0128282613493345
Validation loss: 2.441138503883489

Epoch: 5| Step: 9
Training loss: 3.4918840861095597
Validation loss: 2.4477596812986078

Epoch: 5| Step: 10
Training loss: 2.91060566344257
Validation loss: 2.4396759829669943

Epoch: 50| Step: 0
Training loss: 2.3514038235177006
Validation loss: 2.4404845013169143

Epoch: 5| Step: 1
Training loss: 2.452567164661158
Validation loss: 2.442137517540878

Epoch: 5| Step: 2
Training loss: 2.866063867074306
Validation loss: 2.444176990627682

Epoch: 5| Step: 3
Training loss: 3.14717231868794
Validation loss: 2.442276632065082

Epoch: 5| Step: 4
Training loss: 2.8435984141432433
Validation loss: 2.441552169278422

Epoch: 5| Step: 5
Training loss: 2.803588992090721
Validation loss: 2.4508646525200874

Epoch: 5| Step: 6
Training loss: 3.6144753622296335
Validation loss: 2.439958546745465

Epoch: 5| Step: 7
Training loss: 3.1420122565328477
Validation loss: 2.4486799870078224

Epoch: 5| Step: 8
Training loss: 2.509735795968166
Validation loss: 2.440189523758346

Epoch: 5| Step: 9
Training loss: 2.6804158191352436
Validation loss: 2.4435116436399418

Epoch: 5| Step: 10
Training loss: 2.5025826465476646
Validation loss: 2.4477148017742913

Epoch: 51| Step: 0
Training loss: 2.2089722866601162
Validation loss: 2.44757147986278

Epoch: 5| Step: 1
Training loss: 2.584099522661149
Validation loss: 2.4391670479342853

Epoch: 5| Step: 2
Training loss: 3.1461849058295863
Validation loss: 2.4406228760415196

Epoch: 5| Step: 3
Training loss: 3.214656560182869
Validation loss: 2.441899617278068

Epoch: 5| Step: 4
Training loss: 3.1631456341811943
Validation loss: 2.4424708763246383

Epoch: 5| Step: 5
Training loss: 3.0248086663889535
Validation loss: 2.4436687810882756

Epoch: 5| Step: 6
Training loss: 1.9510866438662249
Validation loss: 2.4424510858573365

Epoch: 5| Step: 7
Training loss: 3.217085917398968
Validation loss: 2.4381980117437148

Epoch: 5| Step: 8
Training loss: 3.2489273061653856
Validation loss: 2.443246825936253

Epoch: 5| Step: 9
Training loss: 2.2432750231045384
Validation loss: 2.4341242589624312

Epoch: 5| Step: 10
Training loss: 2.713113400764689
Validation loss: 2.445410174428353

Epoch: 52| Step: 0
Training loss: 3.0747569290481307
Validation loss: 2.4433915294242596

Epoch: 5| Step: 1
Training loss: 2.6952152842805313
Validation loss: 2.44098496239135

Epoch: 5| Step: 2
Training loss: 2.4742257920632635
Validation loss: 2.440016991740882

Epoch: 5| Step: 3
Training loss: 3.073886644972475
Validation loss: 2.439997566967657

Epoch: 5| Step: 4
Training loss: 2.4933572254294156
Validation loss: 2.435813872792739

Epoch: 5| Step: 5
Training loss: 2.6333642036302503
Validation loss: 2.441258133527831

Epoch: 5| Step: 6
Training loss: 2.8738304744833743
Validation loss: 2.441242678702247

Epoch: 5| Step: 7
Training loss: 3.1252606092504385
Validation loss: 2.4427209833639134

Epoch: 5| Step: 8
Training loss: 2.7982701066739044
Validation loss: 2.4395925849033024

Epoch: 5| Step: 9
Training loss: 3.0858489591233966
Validation loss: 2.4402642774008765

Epoch: 5| Step: 10
Training loss: 2.6577908702869504
Validation loss: 2.4377261788622078

Epoch: 53| Step: 0
Training loss: 2.728410591829056
Validation loss: 2.44628046702461

Epoch: 5| Step: 1
Training loss: 2.4567228527019065
Validation loss: 2.4427197974263293

Epoch: 5| Step: 2
Training loss: 3.1739051973815053
Validation loss: 2.4393967273739747

Epoch: 5| Step: 3
Training loss: 3.363921172153982
Validation loss: 2.4401050621513747

Epoch: 5| Step: 4
Training loss: 3.177128242216967
Validation loss: 2.4423472564870123

Epoch: 5| Step: 5
Training loss: 2.7166877905681615
Validation loss: 2.4392963539247354

Epoch: 5| Step: 6
Training loss: 2.2796853330208386
Validation loss: 2.4386428738905264

Epoch: 5| Step: 7
Training loss: 2.959109746209543
Validation loss: 2.433297286003326

Epoch: 5| Step: 8
Training loss: 2.6545499859197568
Validation loss: 2.4387867772803578

Epoch: 5| Step: 9
Training loss: 2.482353491632865
Validation loss: 2.4373496150935323

Epoch: 5| Step: 10
Training loss: 2.905064823129927
Validation loss: 2.43871079256344

Epoch: 54| Step: 0
Training loss: 2.9368291859971376
Validation loss: 2.436056719997062

Epoch: 5| Step: 1
Training loss: 3.10789584915452
Validation loss: 2.4355527632005214

Epoch: 5| Step: 2
Training loss: 2.979779925060647
Validation loss: 2.4303460029551314

Epoch: 5| Step: 3
Training loss: 2.560854685982257
Validation loss: 2.4416497158929427

Epoch: 5| Step: 4
Training loss: 2.8566157467850437
Validation loss: 2.4398733847137772

Epoch: 5| Step: 5
Training loss: 2.864780839989236
Validation loss: 2.4365484580109302

Epoch: 5| Step: 6
Training loss: 2.552600626517218
Validation loss: 2.436316139312863

Epoch: 5| Step: 7
Training loss: 2.7238141830746194
Validation loss: 2.431179478419153

Epoch: 5| Step: 8
Training loss: 3.124122954319118
Validation loss: 2.432955921245037

Epoch: 5| Step: 9
Training loss: 2.566241533402023
Validation loss: 2.438329291068624

Epoch: 5| Step: 10
Training loss: 2.690254839911679
Validation loss: 2.4386625480877897

Epoch: 55| Step: 0
Training loss: 2.6475264971364405
Validation loss: 2.4356543150518553

Epoch: 5| Step: 1
Training loss: 2.5476419429149217
Validation loss: 2.439542383283041

Epoch: 5| Step: 2
Training loss: 3.1182691184248155
Validation loss: 2.437465693776941

Epoch: 5| Step: 3
Training loss: 2.6117156717668535
Validation loss: 2.434487406113369

Epoch: 5| Step: 4
Training loss: 3.1663495122464944
Validation loss: 2.438448785183596

Epoch: 5| Step: 5
Training loss: 3.2235032326842
Validation loss: 2.4398208877308605

Epoch: 5| Step: 6
Training loss: 2.705758195904314
Validation loss: 2.433551607893101

Epoch: 5| Step: 7
Training loss: 2.9855948147237057
Validation loss: 2.4377897157184605

Epoch: 5| Step: 8
Training loss: 2.7193605460903063
Validation loss: 2.433872417962261

Epoch: 5| Step: 9
Training loss: 2.5222418346940216
Validation loss: 2.442729788670091

Epoch: 5| Step: 10
Training loss: 2.559673704571923
Validation loss: 2.4353429928030117

Epoch: 56| Step: 0
Training loss: 2.975685771473002
Validation loss: 2.4371077193216677

Epoch: 5| Step: 1
Training loss: 2.702877143565806
Validation loss: 2.4377652705725272

Epoch: 5| Step: 2
Training loss: 2.6010243085394804
Validation loss: 2.435517264314263

Epoch: 5| Step: 3
Training loss: 2.8037946124530593
Validation loss: 2.4364752686104225

Epoch: 5| Step: 4
Training loss: 2.9235583673362293
Validation loss: 2.434570411483469

Epoch: 5| Step: 5
Training loss: 3.091114192930334
Validation loss: 2.434420161000997

Epoch: 5| Step: 6
Training loss: 2.604378033007546
Validation loss: 2.43971728583121

Epoch: 5| Step: 7
Training loss: 2.8916741194248807
Validation loss: 2.4372061359557295

Epoch: 5| Step: 8
Training loss: 2.918922932176246
Validation loss: 2.4370891749658514

Epoch: 5| Step: 9
Training loss: 2.8261140871499943
Validation loss: 2.4306786406291416

Epoch: 5| Step: 10
Training loss: 2.533311357737477
Validation loss: 2.436590649291425

Epoch: 57| Step: 0
Training loss: 2.6669559818521495
Validation loss: 2.4363770823552144

Epoch: 5| Step: 1
Training loss: 2.9910065633739413
Validation loss: 2.4410445653628265

Epoch: 5| Step: 2
Training loss: 2.490887820210604
Validation loss: 2.4357430315699915

Epoch: 5| Step: 3
Training loss: 2.971581163130131
Validation loss: 2.4328472850821052

Epoch: 5| Step: 4
Training loss: 3.018644254423768
Validation loss: 2.4268377631309055

Epoch: 5| Step: 5
Training loss: 3.0676190935938163
Validation loss: 2.436438846700043

Epoch: 5| Step: 6
Training loss: 2.603774038598509
Validation loss: 2.4338303502007

Epoch: 5| Step: 7
Training loss: 2.7537042638415214
Validation loss: 2.437601505434657

Epoch: 5| Step: 8
Training loss: 3.134540794604848
Validation loss: 2.4344372835047414

Epoch: 5| Step: 9
Training loss: 2.491285011210094
Validation loss: 2.432530490071327

Epoch: 5| Step: 10
Training loss: 2.5117935478024913
Validation loss: 2.4295924645270723

Epoch: 58| Step: 0
Training loss: 2.7234830326163175
Validation loss: 2.4312959887631744

Epoch: 5| Step: 1
Training loss: 2.2205865270758887
Validation loss: 2.436022676540801

Epoch: 5| Step: 2
Training loss: 2.504746889587049
Validation loss: 2.431879737583672

Epoch: 5| Step: 3
Training loss: 2.956571313925333
Validation loss: 2.440868390433591

Epoch: 5| Step: 4
Training loss: 3.0248654170087677
Validation loss: 2.4295654814904806

Epoch: 5| Step: 5
Training loss: 2.7065170262067393
Validation loss: 2.4302879577813665

Epoch: 5| Step: 6
Training loss: 2.6364262171346224
Validation loss: 2.433464907936372

Epoch: 5| Step: 7
Training loss: 2.879994408019253
Validation loss: 2.4320070402731484

Epoch: 5| Step: 8
Training loss: 2.91717935325004
Validation loss: 2.436580448748304

Epoch: 5| Step: 9
Training loss: 2.8818049957568843
Validation loss: 2.435464128172343

Epoch: 5| Step: 10
Training loss: 3.284733113402326
Validation loss: 2.4295757990658244

Epoch: 59| Step: 0
Training loss: 2.1348969610216995
Validation loss: 2.4344585533841103

Epoch: 5| Step: 1
Training loss: 2.8163326851685304
Validation loss: 2.4273655594548176

Epoch: 5| Step: 2
Training loss: 2.9138003479393313
Validation loss: 2.429090819318632

Epoch: 5| Step: 3
Training loss: 2.7450483999519233
Validation loss: 2.4333706489507874

Epoch: 5| Step: 4
Training loss: 3.3972891434900117
Validation loss: 2.4333206834968584

Epoch: 5| Step: 5
Training loss: 2.8129186530584858
Validation loss: 2.4307601792964015

Epoch: 5| Step: 6
Training loss: 2.4965060614388714
Validation loss: 2.4297330432837745

Epoch: 5| Step: 7
Training loss: 2.7912782901845556
Validation loss: 2.4295461113853714

Epoch: 5| Step: 8
Training loss: 2.9207402438041874
Validation loss: 2.429406716359342

Epoch: 5| Step: 9
Training loss: 2.458338742869832
Validation loss: 2.4325344211101703

Epoch: 5| Step: 10
Training loss: 3.1550269448267803
Validation loss: 2.4339226027615624

Epoch: 60| Step: 0
Training loss: 2.669070015152951
Validation loss: 2.4318200986887755

Epoch: 5| Step: 1
Training loss: 2.953113212763761
Validation loss: 2.432963354134906

Epoch: 5| Step: 2
Training loss: 2.4654875819756668
Validation loss: 2.4289615906385587

Epoch: 5| Step: 3
Training loss: 2.618441881794626
Validation loss: 2.4289675222444083

Epoch: 5| Step: 4
Training loss: 2.9174253476095173
Validation loss: 2.4326038234506275

Epoch: 5| Step: 5
Training loss: 2.7170129247195827
Validation loss: 2.435241247953189

Epoch: 5| Step: 6
Training loss: 3.117931917642558
Validation loss: 2.4302968666792744

Epoch: 5| Step: 7
Training loss: 3.0470078659431827
Validation loss: 2.4292031778695042

Epoch: 5| Step: 8
Training loss: 2.2753481881437
Validation loss: 2.4301801966129606

Epoch: 5| Step: 9
Training loss: 3.318182910809747
Validation loss: 2.424721281210908

Epoch: 5| Step: 10
Training loss: 2.4685846587235276
Validation loss: 2.4227587148453322

Epoch: 61| Step: 0
Training loss: 3.494501017476604
Validation loss: 2.428108594164877

Epoch: 5| Step: 1
Training loss: 2.4955379721019346
Validation loss: 2.426524287551558

Epoch: 5| Step: 2
Training loss: 2.6675556806993455
Validation loss: 2.4292498362109343

Epoch: 5| Step: 3
Training loss: 2.79109609286337
Validation loss: 2.423143381922755

Epoch: 5| Step: 4
Training loss: 2.669032765758713
Validation loss: 2.4241765989359854

Epoch: 5| Step: 5
Training loss: 2.6899069719643216
Validation loss: 2.428164614163194

Epoch: 5| Step: 6
Training loss: 2.5903324454376437
Validation loss: 2.4254373381232477

Epoch: 5| Step: 7
Training loss: 2.8757800826878914
Validation loss: 2.4282682972148675

Epoch: 5| Step: 8
Training loss: 2.743338840412655
Validation loss: 2.426007737316392

Epoch: 5| Step: 9
Training loss: 2.5193645096837036
Validation loss: 2.4278137686664274

Epoch: 5| Step: 10
Training loss: 3.0478179255092757
Validation loss: 2.426928354746538

Epoch: 62| Step: 0
Training loss: 2.4684589069508887
Validation loss: 2.423735546396497

Epoch: 5| Step: 1
Training loss: 2.410015677088482
Validation loss: 2.4265771572423986

Epoch: 5| Step: 2
Training loss: 3.49111450915782
Validation loss: 2.422401041359662

Epoch: 5| Step: 3
Training loss: 2.7822913459902376
Validation loss: 2.425132469852855

Epoch: 5| Step: 4
Training loss: 3.274375908478875
Validation loss: 2.4255683293843

Epoch: 5| Step: 5
Training loss: 3.092636061984929
Validation loss: 2.4229194286499527

Epoch: 5| Step: 6
Training loss: 2.426828646633472
Validation loss: 2.4219591372903273

Epoch: 5| Step: 7
Training loss: 2.263483442835399
Validation loss: 2.4201715497101186

Epoch: 5| Step: 8
Training loss: 2.6916230976684576
Validation loss: 2.428389270311717

Epoch: 5| Step: 9
Training loss: 2.65876866027855
Validation loss: 2.42744533693347

Epoch: 5| Step: 10
Training loss: 2.8408708354801764
Validation loss: 2.423215588077708

Epoch: 63| Step: 0
Training loss: 2.864462740122619
Validation loss: 2.4210093305710165

Epoch: 5| Step: 1
Training loss: 2.866935698135068
Validation loss: 2.42619635669207

Epoch: 5| Step: 2
Training loss: 3.0369236340409653
Validation loss: 2.4195537259788926

Epoch: 5| Step: 3
Training loss: 2.466377953653112
Validation loss: 2.4266398872990256

Epoch: 5| Step: 4
Training loss: 3.1171143793311478
Validation loss: 2.4143557438282617

Epoch: 5| Step: 5
Training loss: 3.058975838951425
Validation loss: 2.4273168402311325

Epoch: 5| Step: 6
Training loss: 2.410374463062754
Validation loss: 2.4242759085313947

Epoch: 5| Step: 7
Training loss: 2.422620498605019
Validation loss: 2.428023014388701

Epoch: 5| Step: 8
Training loss: 2.7505525554052563
Validation loss: 2.42431262737983

Epoch: 5| Step: 9
Training loss: 2.7821324695062346
Validation loss: 2.4289012890269013

Epoch: 5| Step: 10
Training loss: 2.7289654218328914
Validation loss: 2.422364502024254

Epoch: 64| Step: 0
Training loss: 2.69621319303118
Validation loss: 2.4324690965376665

Epoch: 5| Step: 1
Training loss: 2.863674246136994
Validation loss: 2.423692775935195

Epoch: 5| Step: 2
Training loss: 2.9307123858374395
Validation loss: 2.4195516026377026

Epoch: 5| Step: 3
Training loss: 3.0157815368819807
Validation loss: 2.4232503266708965

Epoch: 5| Step: 4
Training loss: 2.444537250124967
Validation loss: 2.42862331420783

Epoch: 5| Step: 5
Training loss: 2.7376937344770993
Validation loss: 2.412098708504288

Epoch: 5| Step: 6
Training loss: 3.1253829721386435
Validation loss: 2.423977557183637

Epoch: 5| Step: 7
Training loss: 2.692508200630302
Validation loss: 2.4088965592094906

Epoch: 5| Step: 8
Training loss: 2.204646673980274
Validation loss: 2.4247824702090996

Epoch: 5| Step: 9
Training loss: 2.886465017603983
Validation loss: 2.4192085277076063

Epoch: 5| Step: 10
Training loss: 2.8449999399302497
Validation loss: 2.4156923915037263

Epoch: 65| Step: 0
Training loss: 3.0024672535199235
Validation loss: 2.420559081892864

Epoch: 5| Step: 1
Training loss: 2.8221904388233336
Validation loss: 2.430505102271676

Epoch: 5| Step: 2
Training loss: 2.8794461576074917
Validation loss: 2.418428583547328

Epoch: 5| Step: 3
Training loss: 2.63574879077651
Validation loss: 2.428986720705665

Epoch: 5| Step: 4
Training loss: 2.533428808554749
Validation loss: 2.418182069418938

Epoch: 5| Step: 5
Training loss: 2.446925402203793
Validation loss: 2.4214927559582393

Epoch: 5| Step: 6
Training loss: 3.232506106106094
Validation loss: 2.4195041617932893

Epoch: 5| Step: 7
Training loss: 3.3274519692041897
Validation loss: 2.41910651067361

Epoch: 5| Step: 8
Training loss: 2.804297289892799
Validation loss: 2.423879804932266

Epoch: 5| Step: 9
Training loss: 1.8853362963777718
Validation loss: 2.421863673643791

Epoch: 5| Step: 10
Training loss: 2.656278183731455
Validation loss: 2.42138004279932

Epoch: 66| Step: 0
Training loss: 2.975113002650494
Validation loss: 2.4199719423050476

Epoch: 5| Step: 1
Training loss: 2.899468333737613
Validation loss: 2.413189161445424

Epoch: 5| Step: 2
Training loss: 2.705814853421441
Validation loss: 2.4162155465105712

Epoch: 5| Step: 3
Training loss: 2.9892209638675418
Validation loss: 2.4225323523619826

Epoch: 5| Step: 4
Training loss: 2.585316102200487
Validation loss: 2.4228271602712437

Epoch: 5| Step: 5
Training loss: 2.582904246801366
Validation loss: 2.42301896540555

Epoch: 5| Step: 6
Training loss: 2.536859583726775
Validation loss: 2.4224369028384465

Epoch: 5| Step: 7
Training loss: 2.495183214482301
Validation loss: 2.4196649328395172

Epoch: 5| Step: 8
Training loss: 2.708648770865265
Validation loss: 2.417802669552012

Epoch: 5| Step: 9
Training loss: 2.8779663042186185
Validation loss: 2.419606231460344

Epoch: 5| Step: 10
Training loss: 3.0796658295014616
Validation loss: 2.4148403913155865

Epoch: 67| Step: 0
Training loss: 2.998167909049133
Validation loss: 2.419982680034431

Epoch: 5| Step: 1
Training loss: 2.7883965047037065
Validation loss: 2.417894690713345

Epoch: 5| Step: 2
Training loss: 2.6971052758840655
Validation loss: 2.409041753159179

Epoch: 5| Step: 3
Training loss: 2.8163243042430186
Validation loss: 2.410828671484603

Epoch: 5| Step: 4
Training loss: 2.471464282611794
Validation loss: 2.4217869420074734

Epoch: 5| Step: 5
Training loss: 2.773201859900504
Validation loss: 2.421146606405828

Epoch: 5| Step: 6
Training loss: 2.636282968183837
Validation loss: 2.41510530117264

Epoch: 5| Step: 7
Training loss: 2.796893242291678
Validation loss: 2.418760913119316

Epoch: 5| Step: 8
Training loss: 2.4555776204785937
Validation loss: 2.417119443279394

Epoch: 5| Step: 9
Training loss: 3.114517024088159
Validation loss: 2.4189948075917074

Epoch: 5| Step: 10
Training loss: 2.7662005499114346
Validation loss: 2.420957734437343

Epoch: 68| Step: 0
Training loss: 2.2995669620698616
Validation loss: 2.420892832405056

Epoch: 5| Step: 1
Training loss: 2.0278148067118518
Validation loss: 2.4113245399610728

Epoch: 5| Step: 2
Training loss: 2.7969279364152815
Validation loss: 2.4134030584184294

Epoch: 5| Step: 3
Training loss: 3.116586421674697
Validation loss: 2.4169651767567584

Epoch: 5| Step: 4
Training loss: 3.092763107566819
Validation loss: 2.4186637163704

Epoch: 5| Step: 5
Training loss: 2.576518349995072
Validation loss: 2.416851267555117

Epoch: 5| Step: 6
Training loss: 3.378198873751401
Validation loss: 2.4192768918405103

Epoch: 5| Step: 7
Training loss: 2.863253771557693
Validation loss: 2.41561955294004

Epoch: 5| Step: 8
Training loss: 2.5437244985740883
Validation loss: 2.419232868415184

Epoch: 5| Step: 9
Training loss: 3.2159085370243132
Validation loss: 2.4145841713512572

Epoch: 5| Step: 10
Training loss: 1.9421103599493974
Validation loss: 2.412721677772789

Epoch: 69| Step: 0
Training loss: 2.3589381135566247
Validation loss: 2.419410183283785

Epoch: 5| Step: 1
Training loss: 2.694854785920701
Validation loss: 2.4216602210355775

Epoch: 5| Step: 2
Training loss: 2.9477213512908502
Validation loss: 2.4116639672152766

Epoch: 5| Step: 3
Training loss: 2.837241973572498
Validation loss: 2.415203872418554

Epoch: 5| Step: 4
Training loss: 2.9427023738474407
Validation loss: 2.418309686093032

Epoch: 5| Step: 5
Training loss: 2.5287184123745434
Validation loss: 2.4157934920437882

Epoch: 5| Step: 6
Training loss: 2.638115226259362
Validation loss: 2.417024875128563

Epoch: 5| Step: 7
Training loss: 3.0186409371776866
Validation loss: 2.4151020964940657

Epoch: 5| Step: 8
Training loss: 3.365078931905839
Validation loss: 2.4135217758951586

Epoch: 5| Step: 9
Training loss: 1.9060747660155826
Validation loss: 2.41207742107327

Epoch: 5| Step: 10
Training loss: 2.7633818241676513
Validation loss: 2.414909894516569

Epoch: 70| Step: 0
Training loss: 2.221658009853033
Validation loss: 2.415437493620924

Epoch: 5| Step: 1
Training loss: 2.555610326742103
Validation loss: 2.4206796014825134

Epoch: 5| Step: 2
Training loss: 2.783795424229076
Validation loss: 2.4183086180459883

Epoch: 5| Step: 3
Training loss: 2.4585459881201945
Validation loss: 2.410974103164488

Epoch: 5| Step: 4
Training loss: 2.9932835416610315
Validation loss: 2.4152784929167503

Epoch: 5| Step: 5
Training loss: 3.036482394839048
Validation loss: 2.419722220511865

Epoch: 5| Step: 6
Training loss: 2.8496378216751825
Validation loss: 2.4124208273571868

Epoch: 5| Step: 7
Training loss: 2.7087504334706876
Validation loss: 2.4126364314922903

Epoch: 5| Step: 8
Training loss: 3.066866817024218
Validation loss: 2.4173029057482704

Epoch: 5| Step: 9
Training loss: 2.313110374109658
Validation loss: 2.4074426334169643

Epoch: 5| Step: 10
Training loss: 3.1020456701639185
Validation loss: 2.410736136015424

Epoch: 71| Step: 0
Training loss: 2.792812785882456
Validation loss: 2.4034043110748855

Epoch: 5| Step: 1
Training loss: 2.589844026177163
Validation loss: 2.414643040472995

Epoch: 5| Step: 2
Training loss: 2.6269538510686727
Validation loss: 2.4074312146677297

Epoch: 5| Step: 3
Training loss: 3.027697496973354
Validation loss: 2.407939737901303

Epoch: 5| Step: 4
Training loss: 3.1737324204320476
Validation loss: 2.410288104710626

Epoch: 5| Step: 5
Training loss: 2.5888961968798583
Validation loss: 2.4116945192033623

Epoch: 5| Step: 6
Training loss: 2.5688786086955098
Validation loss: 2.4075321414153796

Epoch: 5| Step: 7
Training loss: 2.6748812533252515
Validation loss: 2.4105129858464154

Epoch: 5| Step: 8
Training loss: 2.5923637454388557
Validation loss: 2.4126996977357895

Epoch: 5| Step: 9
Training loss: 2.8152106891608013
Validation loss: 2.405377926083498

Epoch: 5| Step: 10
Training loss: 2.596373001586386
Validation loss: 2.4135593466467644

Epoch: 72| Step: 0
Training loss: 2.2158887439851793
Validation loss: 2.412850624494295

Epoch: 5| Step: 1
Training loss: 2.861175803859459
Validation loss: 2.4076016516813104

Epoch: 5| Step: 2
Training loss: 2.9876930206383805
Validation loss: 2.4155538293053396

Epoch: 5| Step: 3
Training loss: 2.745861494028945
Validation loss: 2.4134308494091314

Epoch: 5| Step: 4
Training loss: 3.0750466071837903
Validation loss: 2.4056193123577363

Epoch: 5| Step: 5
Training loss: 2.644562714021881
Validation loss: 2.4075729649706346

Epoch: 5| Step: 6
Training loss: 2.5685779783097806
Validation loss: 2.415563645300236

Epoch: 5| Step: 7
Training loss: 3.238393894348495
Validation loss: 2.4010166704953764

Epoch: 5| Step: 8
Training loss: 2.4941770450857463
Validation loss: 2.403297841127446

Epoch: 5| Step: 9
Training loss: 2.3870857318749152
Validation loss: 2.402923322520691

Epoch: 5| Step: 10
Training loss: 2.7214646215092912
Validation loss: 2.4032177623532394

Epoch: 73| Step: 0
Training loss: 2.149427595013625
Validation loss: 2.4078805270909083

Epoch: 5| Step: 1
Training loss: 2.7462991607808083
Validation loss: 2.409528079673021

Epoch: 5| Step: 2
Training loss: 3.175642810539598
Validation loss: 2.411354635904204

Epoch: 5| Step: 3
Training loss: 2.671309026370344
Validation loss: 2.410913499456388

Epoch: 5| Step: 4
Training loss: 2.0578401116189258
Validation loss: 2.4020822492915315

Epoch: 5| Step: 5
Training loss: 3.2830212853049896
Validation loss: 2.402931769027098

Epoch: 5| Step: 6
Training loss: 2.9740772835926337
Validation loss: 2.40910084391224

Epoch: 5| Step: 7
Training loss: 2.629814183883369
Validation loss: 2.412302609384566

Epoch: 5| Step: 8
Training loss: 2.878653982385722
Validation loss: 2.4050669537905276

Epoch: 5| Step: 9
Training loss: 2.8276209935373697
Validation loss: 2.4047856962083545

Epoch: 5| Step: 10
Training loss: 2.2846509064968514
Validation loss: 2.4046499666915437

Epoch: 74| Step: 0
Training loss: 2.8066877707581215
Validation loss: 2.4115797843391777

Epoch: 5| Step: 1
Training loss: 2.5753726023004773
Validation loss: 2.408223887796497

Epoch: 5| Step: 2
Training loss: 2.9474168944675063
Validation loss: 2.3962709502486517

Epoch: 5| Step: 3
Training loss: 1.9213882698333955
Validation loss: 2.399158467358336

Epoch: 5| Step: 4
Training loss: 2.7417668294340536
Validation loss: 2.406300806692557

Epoch: 5| Step: 5
Training loss: 2.026754010518502
Validation loss: 2.4098986091759924

Epoch: 5| Step: 6
Training loss: 2.5400121233493107
Validation loss: 2.4048907309940324

Epoch: 5| Step: 7
Training loss: 3.04815052427736
Validation loss: 2.4118395755397213

Epoch: 5| Step: 8
Training loss: 3.0373610413716197
Validation loss: 2.406396278353395

Epoch: 5| Step: 9
Training loss: 3.345990580042173
Validation loss: 2.401476600814408

Epoch: 5| Step: 10
Training loss: 2.803026988209507
Validation loss: 2.4054405631271227

Epoch: 75| Step: 0
Training loss: 2.727448502569293
Validation loss: 2.402164727146956

Epoch: 5| Step: 1
Training loss: 2.4052640207704927
Validation loss: 2.4139209730651974

Epoch: 5| Step: 2
Training loss: 2.446481248688227
Validation loss: 2.4129454715184866

Epoch: 5| Step: 3
Training loss: 2.406058563940278
Validation loss: 2.4023679409081353

Epoch: 5| Step: 4
Training loss: 2.9701194415494996
Validation loss: 2.404911130632285

Epoch: 5| Step: 5
Training loss: 2.8946561181526205
Validation loss: 2.4100243061674558

Epoch: 5| Step: 6
Training loss: 3.011946415985609
Validation loss: 2.405269152812707

Epoch: 5| Step: 7
Training loss: 2.7342831841448705
Validation loss: 2.410659233103149

Epoch: 5| Step: 8
Training loss: 2.239621917628808
Validation loss: 2.4119026368166

Epoch: 5| Step: 9
Training loss: 3.0804481066428835
Validation loss: 2.407172493549035

Epoch: 5| Step: 10
Training loss: 2.8589920871514374
Validation loss: 2.4054823184738328

Epoch: 76| Step: 0
Training loss: 2.7734152349733487
Validation loss: 2.4006836988934066

Epoch: 5| Step: 1
Training loss: 2.3651813529487384
Validation loss: 2.4022475618117176

Epoch: 5| Step: 2
Training loss: 2.6190172773725693
Validation loss: 2.4062950844943236

Epoch: 5| Step: 3
Training loss: 2.5697964321216507
Validation loss: 2.403338179790016

Epoch: 5| Step: 4
Training loss: 2.769961475696596
Validation loss: 2.3989540349018372

Epoch: 5| Step: 5
Training loss: 2.648507806525555
Validation loss: 2.399516271992808

Epoch: 5| Step: 6
Training loss: 2.370728818157392
Validation loss: 2.403472906613387

Epoch: 5| Step: 7
Training loss: 2.6334292088531206
Validation loss: 2.405450227488379

Epoch: 5| Step: 8
Training loss: 3.1331111166323224
Validation loss: 2.3959707059350497

Epoch: 5| Step: 9
Training loss: 2.9973110227851847
Validation loss: 2.4007703044852438

Epoch: 5| Step: 10
Training loss: 2.9119986827134725
Validation loss: 2.40294999660838

Epoch: 77| Step: 0
Training loss: 1.9864862579746048
Validation loss: 2.4025743850166075

Epoch: 5| Step: 1
Training loss: 3.3068596665396934
Validation loss: 2.4109195966875077

Epoch: 5| Step: 2
Training loss: 2.7255432497328953
Validation loss: 2.4046520472199386

Epoch: 5| Step: 3
Training loss: 2.52519292566501
Validation loss: 2.3925046030936086

Epoch: 5| Step: 4
Training loss: 2.6829400522684366
Validation loss: 2.397008865540812

Epoch: 5| Step: 5
Training loss: 2.2915167557205525
Validation loss: 2.4078554525017437

Epoch: 5| Step: 6
Training loss: 2.8259422351308574
Validation loss: 2.40674807301622

Epoch: 5| Step: 7
Training loss: 2.6895795361654327
Validation loss: 2.409453359820633

Epoch: 5| Step: 8
Training loss: 2.7880305242960914
Validation loss: 2.4046150153577797

Epoch: 5| Step: 9
Training loss: 2.786252184696291
Validation loss: 2.405566008163961

Epoch: 5| Step: 10
Training loss: 2.96466506198399
Validation loss: 2.4041286483058775

Epoch: 78| Step: 0
Training loss: 2.6289096962621357
Validation loss: 2.4084021355969485

Epoch: 5| Step: 1
Training loss: 2.6387479532541986
Validation loss: 2.4038500655010697

Epoch: 5| Step: 2
Training loss: 2.4687053821249934
Validation loss: 2.4090486192028195

Epoch: 5| Step: 3
Training loss: 3.2330620353639548
Validation loss: 2.3985510892706623

Epoch: 5| Step: 4
Training loss: 2.5368024421610365
Validation loss: 2.403302823761221

Epoch: 5| Step: 5
Training loss: 2.3492800766425277
Validation loss: 2.403533116627493

Epoch: 5| Step: 6
Training loss: 2.7038793668868197
Validation loss: 2.4022581114379333

Epoch: 5| Step: 7
Training loss: 2.3871323746859288
Validation loss: 2.402672374013946

Epoch: 5| Step: 8
Training loss: 2.6263804665958363
Validation loss: 2.404549481370456

Epoch: 5| Step: 9
Training loss: 3.3468758776295826
Validation loss: 2.4006888471344086

Epoch: 5| Step: 10
Training loss: 2.5796903539742315
Validation loss: 2.3972355923251896

Epoch: 79| Step: 0
Training loss: 3.139360467450701
Validation loss: 2.4139395217641777

Epoch: 5| Step: 1
Training loss: 2.819513265796023
Validation loss: 2.4025903537361066

Epoch: 5| Step: 2
Training loss: 2.6061765518633657
Validation loss: 2.402534903714671

Epoch: 5| Step: 3
Training loss: 2.5718392241018697
Validation loss: 2.400941489290218

Epoch: 5| Step: 4
Training loss: 2.1875258307975463
Validation loss: 2.3945874784686643

Epoch: 5| Step: 5
Training loss: 3.0505610153281224
Validation loss: 2.402618510409834

Epoch: 5| Step: 6
Training loss: 2.962848459344823
Validation loss: 2.3995961388262144

Epoch: 5| Step: 7
Training loss: 2.0294745094895794
Validation loss: 2.4018530517156633

Epoch: 5| Step: 8
Training loss: 2.9960658981043276
Validation loss: 2.3923036131127904

Epoch: 5| Step: 9
Training loss: 2.7914176848866243
Validation loss: 2.399225350694218

Epoch: 5| Step: 10
Training loss: 2.137592478753752
Validation loss: 2.4007650934161733

Epoch: 80| Step: 0
Training loss: 2.5766876838027617
Validation loss: 2.4045637796340635

Epoch: 5| Step: 1
Training loss: 2.488602885444291
Validation loss: 2.403287627282609

Epoch: 5| Step: 2
Training loss: 2.3054747190692275
Validation loss: 2.3926565958782464

Epoch: 5| Step: 3
Training loss: 2.443929652954456
Validation loss: 2.3995018549742344

Epoch: 5| Step: 4
Training loss: 2.656804284999003
Validation loss: 2.4078707170390103

Epoch: 5| Step: 5
Training loss: 2.6466041903804864
Validation loss: 2.393628721234043

Epoch: 5| Step: 6
Training loss: 2.460680654534402
Validation loss: 2.4000362940833218

Epoch: 5| Step: 7
Training loss: 2.829033637161359
Validation loss: 2.398606738268726

Epoch: 5| Step: 8
Training loss: 3.042006138360867
Validation loss: 2.395742032815787

Epoch: 5| Step: 9
Training loss: 3.146689410073584
Validation loss: 2.404391042261532

Epoch: 5| Step: 10
Training loss: 2.8972466585326178
Validation loss: 2.396400291126514

Epoch: 81| Step: 0
Training loss: 2.7651953067059325
Validation loss: 2.3985424851828765

Epoch: 5| Step: 1
Training loss: 2.84913929440684
Validation loss: 2.386926345144269

Epoch: 5| Step: 2
Training loss: 2.998622578071915
Validation loss: 2.398506604200827

Epoch: 5| Step: 3
Training loss: 2.2736725046667963
Validation loss: 2.4030569876424153

Epoch: 5| Step: 4
Training loss: 2.3011868027148012
Validation loss: 2.4042127391323085

Epoch: 5| Step: 5
Training loss: 2.4048356692822987
Validation loss: 2.407179072582497

Epoch: 5| Step: 6
Training loss: 2.62371240553472
Validation loss: 2.397271832399992

Epoch: 5| Step: 7
Training loss: 2.877129139536717
Validation loss: 2.395614960408127

Epoch: 5| Step: 8
Training loss: 2.618118985793654
Validation loss: 2.3897438749879916

Epoch: 5| Step: 9
Training loss: 2.806254764544344
Validation loss: 2.3896792977760075

Epoch: 5| Step: 10
Training loss: 2.9477532187576845
Validation loss: 2.396736165021322

Epoch: 82| Step: 0
Training loss: 2.8665045566705603
Validation loss: 2.4035460876780803

Epoch: 5| Step: 1
Training loss: 2.470675333341717
Validation loss: 2.401743999256155

Epoch: 5| Step: 2
Training loss: 2.4794026644494935
Validation loss: 2.4036786750842314

Epoch: 5| Step: 3
Training loss: 3.161666000224036
Validation loss: 2.3966180120091067

Epoch: 5| Step: 4
Training loss: 2.5511545372559117
Validation loss: 2.3943008964864188

Epoch: 5| Step: 5
Training loss: 3.1306027350659242
Validation loss: 2.3978283516002237

Epoch: 5| Step: 6
Training loss: 2.446049978180752
Validation loss: 2.3854959806726326

Epoch: 5| Step: 7
Training loss: 2.520089778057805
Validation loss: 2.3994229476675852

Epoch: 5| Step: 8
Training loss: 2.574655591283387
Validation loss: 2.3966794285986475

Epoch: 5| Step: 9
Training loss: 2.5568565003577404
Validation loss: 2.4003398096253576

Epoch: 5| Step: 10
Training loss: 2.494087571167578
Validation loss: 2.397754311748772

Epoch: 83| Step: 0
Training loss: 2.6791844020827997
Validation loss: 2.3944651209762022

Epoch: 5| Step: 1
Training loss: 2.2001723395382995
Validation loss: 2.3889806385534427

Epoch: 5| Step: 2
Training loss: 2.676726014353039
Validation loss: 2.396725132747201

Epoch: 5| Step: 3
Training loss: 2.480711725304353
Validation loss: 2.39733413158104

Epoch: 5| Step: 4
Training loss: 2.6441273232879334
Validation loss: 2.393755691848414

Epoch: 5| Step: 5
Training loss: 2.952667362337367
Validation loss: 2.3866858782447316

Epoch: 5| Step: 6
Training loss: 2.585422798864658
Validation loss: 2.399672214708022

Epoch: 5| Step: 7
Training loss: 2.7035776983023916
Validation loss: 2.3925876270178335

Epoch: 5| Step: 8
Training loss: 2.8271392453164466
Validation loss: 2.391100221847805

Epoch: 5| Step: 9
Training loss: 2.7353717839979073
Validation loss: 2.4045824527547137

Epoch: 5| Step: 10
Training loss: 2.8354567443421956
Validation loss: 2.3988055698018034

Epoch: 84| Step: 0
Training loss: 2.5806836927136922
Validation loss: 2.4000255408175657

Epoch: 5| Step: 1
Training loss: 3.049507764274444
Validation loss: 2.395500521306818

Epoch: 5| Step: 2
Training loss: 2.694724552324937
Validation loss: 2.3991526148575204

Epoch: 5| Step: 3
Training loss: 2.4981304807891545
Validation loss: 2.390445196038859

Epoch: 5| Step: 4
Training loss: 2.359904551919662
Validation loss: 2.399260905716193

Epoch: 5| Step: 5
Training loss: 3.0893719454006843
Validation loss: 2.3928672001458073

Epoch: 5| Step: 6
Training loss: 2.0413742115471685
Validation loss: 2.388358014793165

Epoch: 5| Step: 7
Training loss: 3.047025393173327
Validation loss: 2.38921508885524

Epoch: 5| Step: 8
Training loss: 2.345583897593133
Validation loss: 2.3943225967954254

Epoch: 5| Step: 9
Training loss: 2.303458710592093
Validation loss: 2.3998855567700286

Epoch: 5| Step: 10
Training loss: 3.042148778323165
Validation loss: 2.3902514227004703

Epoch: 85| Step: 0
Training loss: 2.742745106401425
Validation loss: 2.3935928404945273

Epoch: 5| Step: 1
Training loss: 2.6575326851874004
Validation loss: 2.3924784029683

Epoch: 5| Step: 2
Training loss: 2.797415910126872
Validation loss: 2.3890167763553474

Epoch: 5| Step: 3
Training loss: 3.0986735921028385
Validation loss: 2.3939073530020982

Epoch: 5| Step: 4
Training loss: 2.688798280333015
Validation loss: 2.3977374399653044

Epoch: 5| Step: 5
Training loss: 2.445633254784277
Validation loss: 2.3831549446981968

Epoch: 5| Step: 6
Training loss: 2.7945934345257513
Validation loss: 2.3933140703497195

Epoch: 5| Step: 7
Training loss: 2.4048598596423543
Validation loss: 2.3943883228944487

Epoch: 5| Step: 8
Training loss: 2.161342412452212
Validation loss: 2.3910666437232098

Epoch: 5| Step: 9
Training loss: 2.3519067860770986
Validation loss: 2.3927470127056005

Epoch: 5| Step: 10
Training loss: 2.9506211742141186
Validation loss: 2.386534532144496

Epoch: 86| Step: 0
Training loss: 2.4479470000856374
Validation loss: 2.3940712805618043

Epoch: 5| Step: 1
Training loss: 2.800148098298732
Validation loss: 2.3827759948225777

Epoch: 5| Step: 2
Training loss: 2.4485045247985524
Validation loss: 2.3837934901143645

Epoch: 5| Step: 3
Training loss: 2.7307798456706904
Validation loss: 2.3848605699113854

Epoch: 5| Step: 4
Training loss: 2.450645116613041
Validation loss: 2.388890677991412

Epoch: 5| Step: 5
Training loss: 3.0153008321353885
Validation loss: 2.398221627401306

Epoch: 5| Step: 6
Training loss: 2.4058756351308577
Validation loss: 2.4040370333023597

Epoch: 5| Step: 7
Training loss: 2.7113393875941165
Validation loss: 2.390545398604849

Epoch: 5| Step: 8
Training loss: 2.6256347978604793
Validation loss: 2.3934570369696937

Epoch: 5| Step: 9
Training loss: 2.886686704300309
Validation loss: 2.3915746385653023

Epoch: 5| Step: 10
Training loss: 2.516310320082387
Validation loss: 2.3950071846328873

Epoch: 87| Step: 0
Training loss: 2.555401436908429
Validation loss: 2.3847099454179936

Epoch: 5| Step: 1
Training loss: 2.1877051121053173
Validation loss: 2.3771622081713626

Epoch: 5| Step: 2
Training loss: 2.940787889953352
Validation loss: 2.384428334783699

Epoch: 5| Step: 3
Training loss: 2.6744833367057366
Validation loss: 2.3953421889592645

Epoch: 5| Step: 4
Training loss: 2.71676923133065
Validation loss: 2.3916121757016344

Epoch: 5| Step: 5
Training loss: 2.440433986090652
Validation loss: 2.389130165408457

Epoch: 5| Step: 6
Training loss: 2.400800801826605
Validation loss: 2.401156453807353

Epoch: 5| Step: 7
Training loss: 2.6269380590297526
Validation loss: 2.3909954459890246

Epoch: 5| Step: 8
Training loss: 2.608010214961121
Validation loss: 2.3897764407827284

Epoch: 5| Step: 9
Training loss: 3.044286479316928
Validation loss: 2.381562356463139

Epoch: 5| Step: 10
Training loss: 2.797681383213385
Validation loss: 2.3916778916060557

Epoch: 88| Step: 0
Training loss: 2.5535312100653065
Validation loss: 2.392967455028182

Epoch: 5| Step: 1
Training loss: 3.185485801836381
Validation loss: 2.3934730841912026

Epoch: 5| Step: 2
Training loss: 2.682542531155381
Validation loss: 2.399804867653136

Epoch: 5| Step: 3
Training loss: 2.5901987054077713
Validation loss: 2.381083100300576

Epoch: 5| Step: 4
Training loss: 2.8629811378148124
Validation loss: 2.389291913732032

Epoch: 5| Step: 5
Training loss: 2.7147557525644075
Validation loss: 2.386358639793952

Epoch: 5| Step: 6
Training loss: 2.672466011937465
Validation loss: 2.4019817846279565

Epoch: 5| Step: 7
Training loss: 2.3583546636400854
Validation loss: 2.396047992550848

Epoch: 5| Step: 8
Training loss: 2.653297309087807
Validation loss: 2.3854372724270103

Epoch: 5| Step: 9
Training loss: 2.106526012050889
Validation loss: 2.3971574167855128

Epoch: 5| Step: 10
Training loss: 2.425616419992505
Validation loss: 2.3801133453773264

Epoch: 89| Step: 0
Training loss: 2.466839884355117
Validation loss: 2.390949982932952

Epoch: 5| Step: 1
Training loss: 2.4885847783868544
Validation loss: 2.380389055216388

Epoch: 5| Step: 2
Training loss: 2.740403249679819
Validation loss: 2.394509433276984

Epoch: 5| Step: 3
Training loss: 2.4792056254256303
Validation loss: 2.3866952694537646

Epoch: 5| Step: 4
Training loss: 2.4151444957778074
Validation loss: 2.3784940844698417

Epoch: 5| Step: 5
Training loss: 2.809102528293571
Validation loss: 2.381164949497155

Epoch: 5| Step: 6
Training loss: 2.980821341160842
Validation loss: 2.392502267156906

Epoch: 5| Step: 7
Training loss: 3.2840365249052303
Validation loss: 2.3795376856030006

Epoch: 5| Step: 8
Training loss: 2.154557932498211
Validation loss: 2.379081368986628

Epoch: 5| Step: 9
Training loss: 2.4804544283235663
Validation loss: 2.3850688072579795

Epoch: 5| Step: 10
Training loss: 2.467027183769519
Validation loss: 2.3822976177239945

Epoch: 90| Step: 0
Training loss: 2.423954618413155
Validation loss: 2.389956158827016

Epoch: 5| Step: 1
Training loss: 2.731129491316705
Validation loss: 2.3864442247753326

Epoch: 5| Step: 2
Training loss: 2.729453054840229
Validation loss: 2.38172455738019

Epoch: 5| Step: 3
Training loss: 2.8196200632940895
Validation loss: 2.3873057884681055

Epoch: 5| Step: 4
Training loss: 2.7637921310519267
Validation loss: 2.390213807348658

Epoch: 5| Step: 5
Training loss: 2.3860620572316833
Validation loss: 2.389192940848612

Epoch: 5| Step: 6
Training loss: 1.919385957478555
Validation loss: 2.3940201773858094

Epoch: 5| Step: 7
Training loss: 2.754390852475495
Validation loss: 2.3949129363526103

Epoch: 5| Step: 8
Training loss: 2.9077252981156523
Validation loss: 2.37819197852827

Epoch: 5| Step: 9
Training loss: 2.6691249503612355
Validation loss: 2.3799567329377167

Epoch: 5| Step: 10
Training loss: 2.6506083995656358
Validation loss: 2.3796380576658667

Epoch: 91| Step: 0
Training loss: 2.7719678826666447
Validation loss: 2.3847151453444075

Epoch: 5| Step: 1
Training loss: 2.771125797143419
Validation loss: 2.39896290360628

Epoch: 5| Step: 2
Training loss: 2.62716222448477
Validation loss: 2.375051609033397

Epoch: 5| Step: 3
Training loss: 2.0793503898629595
Validation loss: 2.3843587021409194

Epoch: 5| Step: 4
Training loss: 3.2062524925653535
Validation loss: 2.3918336786891508

Epoch: 5| Step: 5
Training loss: 1.8153588997848542
Validation loss: 2.386936235905141

Epoch: 5| Step: 6
Training loss: 3.0270926685193684
Validation loss: 2.3862519421731747

Epoch: 5| Step: 7
Training loss: 2.6290747487907233
Validation loss: 2.3781596033693355

Epoch: 5| Step: 8
Training loss: 2.3336403054445456
Validation loss: 2.3860762492466585

Epoch: 5| Step: 9
Training loss: 2.6350026062983267
Validation loss: 2.3934986414882617

Epoch: 5| Step: 10
Training loss: 2.5404385168649903
Validation loss: 2.3757426952404765

Epoch: 92| Step: 0
Training loss: 2.1742104248150667
Validation loss: 2.385834219193845

Epoch: 5| Step: 1
Training loss: 2.640457870340893
Validation loss: 2.397835075481581

Epoch: 5| Step: 2
Training loss: 2.518806672701055
Validation loss: 2.3927694888806315

Epoch: 5| Step: 3
Training loss: 2.4651069319243604
Validation loss: 2.3865549119805354

Epoch: 5| Step: 4
Training loss: 3.0653789767627755
Validation loss: 2.3883765854487895

Epoch: 5| Step: 5
Training loss: 2.5308334572994773
Validation loss: 2.3883264976954197

Epoch: 5| Step: 6
Training loss: 2.4517278884134885
Validation loss: 2.393907867035096

Epoch: 5| Step: 7
Training loss: 2.520888798211214
Validation loss: 2.3881680407462893

Epoch: 5| Step: 8
Training loss: 2.7263510548272603
Validation loss: 2.3837842079238154

Epoch: 5| Step: 9
Training loss: 2.665148829586069
Validation loss: 2.3829356989623443

Epoch: 5| Step: 10
Training loss: 2.827494345472974
Validation loss: 2.380998895684465

Epoch: 93| Step: 0
Training loss: 2.6923381814173486
Validation loss: 2.3880277333355764

Epoch: 5| Step: 1
Training loss: 2.6080459590794045
Validation loss: 2.383897587766054

Epoch: 5| Step: 2
Training loss: 2.180197051180539
Validation loss: 2.4020929629334713

Epoch: 5| Step: 3
Training loss: 2.3258470489451084
Validation loss: 2.391767024899908

Epoch: 5| Step: 4
Training loss: 1.908776656828419
Validation loss: 2.3902725108920055

Epoch: 5| Step: 5
Training loss: 2.9480029701207595
Validation loss: 2.3798073503805544

Epoch: 5| Step: 6
Training loss: 2.7073866045339576
Validation loss: 2.3935225854750084

Epoch: 5| Step: 7
Training loss: 2.9999386463249325
Validation loss: 2.389637086062037

Epoch: 5| Step: 8
Training loss: 2.4691821335784363
Validation loss: 2.3739033311355278

Epoch: 5| Step: 9
Training loss: 2.8695831684636675
Validation loss: 2.3756538456091945

Epoch: 5| Step: 10
Training loss: 2.6883786561586076
Validation loss: 2.3819463233107623

Epoch: 94| Step: 0
Training loss: 2.1802332478603486
Validation loss: 2.3871950544614204

Epoch: 5| Step: 1
Training loss: 3.0054916345266975
Validation loss: 2.380676537625803

Epoch: 5| Step: 2
Training loss: 2.6828123507002544
Validation loss: 2.3817483990774537

Epoch: 5| Step: 3
Training loss: 2.5230238253586976
Validation loss: 2.378366909735062

Epoch: 5| Step: 4
Training loss: 2.359621047775516
Validation loss: 2.3853839621796418

Epoch: 5| Step: 5
Training loss: 2.509428745326046
Validation loss: 2.381060413141528

Epoch: 5| Step: 6
Training loss: 2.353383927202163
Validation loss: 2.3921163498157725

Epoch: 5| Step: 7
Training loss: 2.688893777362944
Validation loss: 2.394322647119099

Epoch: 5| Step: 8
Training loss: 3.0721350931325504
Validation loss: 2.3823086393303865

Epoch: 5| Step: 9
Training loss: 2.588794340290866
Validation loss: 2.3956752865858766

Epoch: 5| Step: 10
Training loss: 2.494853731045719
Validation loss: 2.3972466350830715

Epoch: 95| Step: 0
Training loss: 2.2716290074466703
Validation loss: 2.3786137968205683

Epoch: 5| Step: 1
Training loss: 2.588507904712676
Validation loss: 2.3782078851308692

Epoch: 5| Step: 2
Training loss: 3.034068576729257
Validation loss: 2.366707002168083

Epoch: 5| Step: 3
Training loss: 2.514426093780687
Validation loss: 2.3888520335080816

Epoch: 5| Step: 4
Training loss: 2.0139749559741342
Validation loss: 2.3789291026459143

Epoch: 5| Step: 5
Training loss: 2.5498867832556558
Validation loss: 2.379988383492902

Epoch: 5| Step: 6
Training loss: 3.0867787433761884
Validation loss: 2.384597081537788

Epoch: 5| Step: 7
Training loss: 2.8908396048398544
Validation loss: 2.390552616437758

Epoch: 5| Step: 8
Training loss: 2.2481005386324067
Validation loss: 2.395338368125477

Epoch: 5| Step: 9
Training loss: 2.3293478397703034
Validation loss: 2.3923241259767876

Epoch: 5| Step: 10
Training loss: 2.5207778567260157
Validation loss: 2.3930609416520356

Epoch: 96| Step: 0
Training loss: 2.637056727470785
Validation loss: 2.398355223728332

Epoch: 5| Step: 1
Training loss: 2.560064600636072
Validation loss: 2.40251945802128

Epoch: 5| Step: 2
Training loss: 2.8753311961598205
Validation loss: 2.3767462864118434

Epoch: 5| Step: 3
Training loss: 2.5023217863940586
Validation loss: 2.398334425736596

Epoch: 5| Step: 4
Training loss: 2.5854556277216365
Validation loss: 2.386229325106858

Epoch: 5| Step: 5
Training loss: 2.7397661522807653
Validation loss: 2.3891410857473727

Epoch: 5| Step: 6
Training loss: 2.243738256227155
Validation loss: 2.3918175218594326

Epoch: 5| Step: 7
Training loss: 2.641949112851851
Validation loss: 2.3994521832266678

Epoch: 5| Step: 8
Training loss: 2.638102393036521
Validation loss: 2.3914880622917996

Epoch: 5| Step: 9
Training loss: 2.6061423373225905
Validation loss: 2.383485392630365

Epoch: 5| Step: 10
Training loss: 2.334318997325433
Validation loss: 2.3863511208281203

Epoch: 97| Step: 0
Training loss: 2.94632224019064
Validation loss: 2.3778167610873715

Epoch: 5| Step: 1
Training loss: 2.4559757652267464
Validation loss: 2.387306053712384

Epoch: 5| Step: 2
Training loss: 2.2381627981855208
Validation loss: 2.37625445583531

Epoch: 5| Step: 3
Training loss: 2.1636951561670608
Validation loss: 2.3801167781200694

Epoch: 5| Step: 4
Training loss: 3.1238486648615087
Validation loss: 2.379882863129009

Epoch: 5| Step: 5
Training loss: 2.2413670969562016
Validation loss: 2.380185625808941

Epoch: 5| Step: 6
Training loss: 2.541797186413411
Validation loss: 2.387354393184684

Epoch: 5| Step: 7
Training loss: 2.8757689733017804
Validation loss: 2.381698188077424

Epoch: 5| Step: 8
Training loss: 2.622679911243383
Validation loss: 2.379314203954957

Epoch: 5| Step: 9
Training loss: 2.3306704948897243
Validation loss: 2.3742995942962315

Epoch: 5| Step: 10
Training loss: 2.5721086991509132
Validation loss: 2.3746549358889437

Epoch: 98| Step: 0
Training loss: 2.771605066275154
Validation loss: 2.3870640774701744

Epoch: 5| Step: 1
Training loss: 2.294804996192604
Validation loss: 2.388973513087907

Epoch: 5| Step: 2
Training loss: 2.536670485337834
Validation loss: 2.3912911384792346

Epoch: 5| Step: 3
Training loss: 2.271765864504404
Validation loss: 2.3993556595472043

Epoch: 5| Step: 4
Training loss: 2.6751785824783054
Validation loss: 2.374831418723575

Epoch: 5| Step: 5
Training loss: 2.5748533818252115
Validation loss: 2.389257878853465

Epoch: 5| Step: 6
Training loss: 3.2367405004228615
Validation loss: 2.384005869364115

Epoch: 5| Step: 7
Training loss: 2.6222605261546397
Validation loss: 2.384180823997262

Epoch: 5| Step: 8
Training loss: 2.5358029144732495
Validation loss: 2.382498575932011

Epoch: 5| Step: 9
Training loss: 2.126161706561265
Validation loss: 2.381579989779214

Epoch: 5| Step: 10
Training loss: 2.472473041321882
Validation loss: 2.391923974429295

Epoch: 99| Step: 0
Training loss: 2.12960708701447
Validation loss: 2.384957063229573

Epoch: 5| Step: 1
Training loss: 2.631873894525684
Validation loss: 2.386349330517933

Epoch: 5| Step: 2
Training loss: 2.334755180479765
Validation loss: 2.3830589410413245

Epoch: 5| Step: 3
Training loss: 1.9880717528766867
Validation loss: 2.3834937993862577

Epoch: 5| Step: 4
Training loss: 2.8235627358237188
Validation loss: 2.394415558877419

Epoch: 5| Step: 5
Training loss: 2.2654378879496377
Validation loss: 2.3838926258707684

Epoch: 5| Step: 6
Training loss: 3.1384833326129606
Validation loss: 2.394721916112976

Epoch: 5| Step: 7
Training loss: 2.6625963578674856
Validation loss: 2.3994227115422246

Epoch: 5| Step: 8
Training loss: 2.902703366905181
Validation loss: 2.383331447812548

Epoch: 5| Step: 9
Training loss: 2.611957482767411
Validation loss: 2.3941791379052026

Epoch: 5| Step: 10
Training loss: 2.3741183401241437
Validation loss: 2.3891561372125776

Epoch: 100| Step: 0
Training loss: 2.4406955020114283
Validation loss: 2.3833876317995117

Epoch: 5| Step: 1
Training loss: 2.685454011178517
Validation loss: 2.4000764803424874

Epoch: 5| Step: 2
Training loss: 2.0707521367672834
Validation loss: 2.378495457640054

Epoch: 5| Step: 3
Training loss: 2.2815689491020943
Validation loss: 2.387780530697123

Epoch: 5| Step: 4
Training loss: 2.521697114440015
Validation loss: 2.376836164092712

Epoch: 5| Step: 5
Training loss: 2.998989411847032
Validation loss: 2.389677020227021

Epoch: 5| Step: 6
Training loss: 2.4964144743944883
Validation loss: 2.385701421290541

Epoch: 5| Step: 7
Training loss: 3.0482209191747778
Validation loss: 2.378071186853436

Epoch: 5| Step: 8
Training loss: 2.055574986935895
Validation loss: 2.3897097435591848

Epoch: 5| Step: 9
Training loss: 2.411917613202403
Validation loss: 2.392398798946089

Epoch: 5| Step: 10
Training loss: 2.838934373667472
Validation loss: 2.3844063724006532

Epoch: 101| Step: 0
Training loss: 2.964564213497854
Validation loss: 2.3782535066087034

Epoch: 5| Step: 1
Training loss: 2.466923098079545
Validation loss: 2.393577674478909

Epoch: 5| Step: 2
Training loss: 2.579994864495659
Validation loss: 2.3781475761652504

Epoch: 5| Step: 3
Training loss: 2.328933882525394
Validation loss: 2.385722191867149

Epoch: 5| Step: 4
Training loss: 2.6947906431223947
Validation loss: 2.3753567844826633

Epoch: 5| Step: 5
Training loss: 2.5004262560805843
Validation loss: 2.3885287636391026

Epoch: 5| Step: 6
Training loss: 2.381575666770883
Validation loss: 2.394800090869093

Epoch: 5| Step: 7
Training loss: 2.204428753717957
Validation loss: 2.396495455451261

Epoch: 5| Step: 8
Training loss: 2.8085246495432945
Validation loss: 2.3849555067433337

Epoch: 5| Step: 9
Training loss: 2.220544009182504
Validation loss: 2.380269664251501

Epoch: 5| Step: 10
Training loss: 2.7621240385904695
Validation loss: 2.3730412325025427

Epoch: 102| Step: 0
Training loss: 2.4995487759602812
Validation loss: 2.373303009515015

Epoch: 5| Step: 1
Training loss: 2.7701078818070184
Validation loss: 2.374521035028152

Epoch: 5| Step: 2
Training loss: 3.1963097990944354
Validation loss: 2.369981353066463

Epoch: 5| Step: 3
Training loss: 2.334637844909211
Validation loss: 2.3859143957449316

Epoch: 5| Step: 4
Training loss: 2.2463928554241974
Validation loss: 2.3861912950343065

Epoch: 5| Step: 5
Training loss: 3.1139900042129054
Validation loss: 2.3887711608476265

Epoch: 5| Step: 6
Training loss: 2.3950813993187774
Validation loss: 2.3822906374545183

Epoch: 5| Step: 7
Training loss: 2.7189062665557113
Validation loss: 2.3959876425879454

Epoch: 5| Step: 8
Training loss: 2.315771520923768
Validation loss: 2.374835634183972

Epoch: 5| Step: 9
Training loss: 2.185826015288067
Validation loss: 2.395314816885174

Epoch: 5| Step: 10
Training loss: 1.5834695941449792
Validation loss: 2.3888490297077

Epoch: 103| Step: 0
Training loss: 2.6727664642668962
Validation loss: 2.3812038274720972

Epoch: 5| Step: 1
Training loss: 2.2782026866335396
Validation loss: 2.3849694280147684

Epoch: 5| Step: 2
Training loss: 3.1030898477305455
Validation loss: 2.3961731889462574

Epoch: 5| Step: 3
Training loss: 2.6165706078296562
Validation loss: 2.3779670939632673

Epoch: 5| Step: 4
Training loss: 2.3660518326680475
Validation loss: 2.394842040301987

Epoch: 5| Step: 5
Training loss: 2.744711906726776
Validation loss: 2.3936814023231405

Epoch: 5| Step: 6
Training loss: 2.6198512854848537
Validation loss: 2.3894276149428144

Epoch: 5| Step: 7
Training loss: 1.7408727637330208
Validation loss: 2.380980558199356

Epoch: 5| Step: 8
Training loss: 2.746548827924303
Validation loss: 2.3882908314146496

Epoch: 5| Step: 9
Training loss: 2.56306432697302
Validation loss: 2.388151878439718

Epoch: 5| Step: 10
Training loss: 2.1494251547305794
Validation loss: 2.392545627878074

Epoch: 104| Step: 0
Training loss: 2.648432908855949
Validation loss: 2.4016582368332986

Epoch: 5| Step: 1
Training loss: 2.6785441369982417
Validation loss: 2.393747376822561

Epoch: 5| Step: 2
Training loss: 2.6826480270740527
Validation loss: 2.3740790783152286

Epoch: 5| Step: 3
Training loss: 2.0408559344301787
Validation loss: 2.3720779567089014

Epoch: 5| Step: 4
Training loss: 2.5393849329527654
Validation loss: 2.400012719512035

Epoch: 5| Step: 5
Training loss: 2.283290838509772
Validation loss: 2.3825754398399166

Epoch: 5| Step: 6
Training loss: 3.0014598791162985
Validation loss: 2.3855250301234157

Epoch: 5| Step: 7
Training loss: 2.3253210194783707
Validation loss: 2.397521204398012

Epoch: 5| Step: 8
Training loss: 2.548454403426515
Validation loss: 2.3839117733095865

Epoch: 5| Step: 9
Training loss: 2.9684647272477505
Validation loss: 2.39234848142559

Epoch: 5| Step: 10
Training loss: 1.5546049930014816
Validation loss: 2.383348036494884

Epoch: 105| Step: 0
Training loss: 2.5741492856831187
Validation loss: 2.379042293610149

Epoch: 5| Step: 1
Training loss: 2.5778863044982567
Validation loss: 2.373566283809513

Epoch: 5| Step: 2
Training loss: 2.9497952535665704
Validation loss: 2.395718581852064

Epoch: 5| Step: 3
Training loss: 3.066958704463634
Validation loss: 2.3776324955973793

Epoch: 5| Step: 4
Training loss: 2.5656864544551157
Validation loss: 2.389432245617622

Epoch: 5| Step: 5
Training loss: 2.1729763175211017
Validation loss: 2.3764844431616807

Epoch: 5| Step: 6
Training loss: 2.3330237546546146
Validation loss: 2.376699066558551

Epoch: 5| Step: 7
Training loss: 2.2746864899304087
Validation loss: 2.3850229743299343

Epoch: 5| Step: 8
Training loss: 2.6470399843430656
Validation loss: 2.3791263573531256

Epoch: 5| Step: 9
Training loss: 2.087251056743523
Validation loss: 2.3800674407188636

Epoch: 5| Step: 10
Training loss: 2.233728488675516
Validation loss: 2.371173299473461

Epoch: 106| Step: 0
Training loss: 2.0455133699377863
Validation loss: 2.3984788123706693

Epoch: 5| Step: 1
Training loss: 2.353117875168185
Validation loss: 2.3784244527067413

Epoch: 5| Step: 2
Training loss: 2.643828395826471
Validation loss: 2.3815236145940935

Epoch: 5| Step: 3
Training loss: 2.7749865007501753
Validation loss: 2.3909143086091387

Epoch: 5| Step: 4
Training loss: 2.607937536790477
Validation loss: 2.3882454532000743

Epoch: 5| Step: 5
Training loss: 2.710238055932397
Validation loss: 2.393805602280476

Epoch: 5| Step: 6
Training loss: 2.468504108786375
Validation loss: 2.3855114893039833

Epoch: 5| Step: 7
Training loss: 2.455628302327511
Validation loss: 2.4000437723119514

Epoch: 5| Step: 8
Training loss: 2.6241593604310673
Validation loss: 2.3747736958497296

Epoch: 5| Step: 9
Training loss: 2.407152477308247
Validation loss: 2.374670585494129

Epoch: 5| Step: 10
Training loss: 2.5059035216298327
Validation loss: 2.3960801206572695

Epoch: 107| Step: 0
Training loss: 2.255214793935307
Validation loss: 2.394094740701078

Epoch: 5| Step: 1
Training loss: 2.346840207264879
Validation loss: 2.3821235799930682

Epoch: 5| Step: 2
Training loss: 2.713083962018304
Validation loss: 2.391216225611323

Epoch: 5| Step: 3
Training loss: 2.2892751757670595
Validation loss: 2.377782530151007

Epoch: 5| Step: 4
Training loss: 2.587270249196382
Validation loss: 2.3878701068597756

Epoch: 5| Step: 5
Training loss: 2.3089793443181326
Validation loss: 2.3791642029555575

Epoch: 5| Step: 6
Training loss: 3.1272471168792046
Validation loss: 2.403658669744913

Epoch: 5| Step: 7
Training loss: 2.862665836244678
Validation loss: 2.384614064569102

Epoch: 5| Step: 8
Training loss: 2.3788707711717043
Validation loss: 2.377675797020373

Epoch: 5| Step: 9
Training loss: 2.450059956186769
Validation loss: 2.3908259262911367

Epoch: 5| Step: 10
Training loss: 2.0550572747929543
Validation loss: 2.3884784010829034

Epoch: 108| Step: 0
Training loss: 2.1635076038640446
Validation loss: 2.391985885588009

Epoch: 5| Step: 1
Training loss: 2.9110595939614026
Validation loss: 2.383422465787139

Epoch: 5| Step: 2
Training loss: 2.8594815593937977
Validation loss: 2.392516728497205

Epoch: 5| Step: 3
Training loss: 2.818752967173163
Validation loss: 2.391795782744643

Epoch: 5| Step: 4
Training loss: 2.670273507214667
Validation loss: 2.389884397021211

Epoch: 5| Step: 5
Training loss: 2.6169079076111417
Validation loss: 2.3909589456599267

Epoch: 5| Step: 6
Training loss: 2.4154136851513157
Validation loss: 2.3802027415609324

Epoch: 5| Step: 7
Training loss: 1.8411206392527544
Validation loss: 2.3815925066525088

Epoch: 5| Step: 8
Training loss: 2.330547224789465
Validation loss: 2.3844365059814496

Epoch: 5| Step: 9
Training loss: 2.4195124762462337
Validation loss: 2.3845007177192574

Epoch: 5| Step: 10
Training loss: 2.2639011533544093
Validation loss: 2.4072560493992734

Epoch: 109| Step: 0
Training loss: 2.545046097013823
Validation loss: 2.365994690373543

Epoch: 5| Step: 1
Training loss: 2.3197692851742797
Validation loss: 2.3781241381961666

Epoch: 5| Step: 2
Training loss: 2.4228520545205567
Validation loss: 2.3879955752616833

Epoch: 5| Step: 3
Training loss: 2.606664929190184
Validation loss: 2.39509638027188

Epoch: 5| Step: 4
Training loss: 2.8211969484032284
Validation loss: 2.381857284250245

Epoch: 5| Step: 5
Training loss: 2.5768918874234896
Validation loss: 2.3791189038902196

Epoch: 5| Step: 6
Training loss: 2.691683507183606
Validation loss: 2.394430459413618

Epoch: 5| Step: 7
Training loss: 2.668822390715807
Validation loss: 2.380365283909542

Epoch: 5| Step: 8
Training loss: 2.002919926612613
Validation loss: 2.3826761347581673

Epoch: 5| Step: 9
Training loss: 2.1271039981068642
Validation loss: 2.3763428245127747

Epoch: 5| Step: 10
Training loss: 2.4117489688365334
Validation loss: 2.3825513858373673

Epoch: 110| Step: 0
Training loss: 2.8353247282625786
Validation loss: 2.3833739626681525

Epoch: 5| Step: 1
Training loss: 2.7914927603989703
Validation loss: 2.389453231603191

Epoch: 5| Step: 2
Training loss: 2.5536241097213193
Validation loss: 2.3700130254237752

Epoch: 5| Step: 3
Training loss: 2.3236327386237066
Validation loss: 2.387929383339326

Epoch: 5| Step: 4
Training loss: 2.4364811650892095
Validation loss: 2.3998484665791295

Epoch: 5| Step: 5
Training loss: 2.5484843405904263
Validation loss: 2.3919105823734617

Epoch: 5| Step: 6
Training loss: 2.4785468878852295
Validation loss: 2.391451748505734

Epoch: 5| Step: 7
Training loss: 1.8707828143916243
Validation loss: 2.3904183706160786

Epoch: 5| Step: 8
Training loss: 2.6338362245789035
Validation loss: 2.3857061763275316

Epoch: 5| Step: 9
Training loss: 2.305976843228823
Validation loss: 2.384933829772063

Epoch: 5| Step: 10
Training loss: 2.374965065147053
Validation loss: 2.3893575711366624

Epoch: 111| Step: 0
Training loss: 2.170580031931168
Validation loss: 2.386387897896035

Epoch: 5| Step: 1
Training loss: 2.323573226401989
Validation loss: 2.3903266291056595

Epoch: 5| Step: 2
Training loss: 2.4373138552283207
Validation loss: 2.3816239535532118

Epoch: 5| Step: 3
Training loss: 2.5217516673961735
Validation loss: 2.3706166079794806

Epoch: 5| Step: 4
Training loss: 2.642959916756596
Validation loss: 2.397397543398989

Epoch: 5| Step: 5
Training loss: 2.4618068552185655
Validation loss: 2.3884013106771014

Epoch: 5| Step: 6
Training loss: 2.7551123176290773
Validation loss: 2.4017085610508095

Epoch: 5| Step: 7
Training loss: 2.6266783843610138
Validation loss: 2.3776082708243393

Epoch: 5| Step: 8
Training loss: 2.112391822347503
Validation loss: 2.400658912217008

Epoch: 5| Step: 9
Training loss: 2.753286998195719
Validation loss: 2.3793405183303737

Epoch: 5| Step: 10
Training loss: 2.3802958221271955
Validation loss: 2.395592235901895

Epoch: 112| Step: 0
Training loss: 2.2023433083124115
Validation loss: 2.396381623250575

Epoch: 5| Step: 1
Training loss: 2.6325087556032245
Validation loss: 2.4020478379905517

Epoch: 5| Step: 2
Training loss: 2.601979448511474
Validation loss: 2.4003871294014827

Epoch: 5| Step: 3
Training loss: 2.2459920578202195
Validation loss: 2.390694510178368

Epoch: 5| Step: 4
Training loss: 2.6978074178092153
Validation loss: 2.395086879644014

Epoch: 5| Step: 5
Training loss: 2.5706808179957843
Validation loss: 2.3920761402158437

Epoch: 5| Step: 6
Training loss: 2.540690114593343
Validation loss: 2.384276036810581

Epoch: 5| Step: 7
Training loss: 2.587817934562837
Validation loss: 2.388656686326327

Epoch: 5| Step: 8
Training loss: 2.4408205352096903
Validation loss: 2.4020540057528987

Epoch: 5| Step: 9
Training loss: 2.4363696093725435
Validation loss: 2.384661589966996

Epoch: 5| Step: 10
Training loss: 2.2536103634518474
Validation loss: 2.4023077571829456

Epoch: 113| Step: 0
Training loss: 2.352949981462609
Validation loss: 2.4016813447945555

Epoch: 5| Step: 1
Training loss: 2.3480221277588225
Validation loss: 2.377761800192426

Epoch: 5| Step: 2
Training loss: 2.419645304419728
Validation loss: 2.384378937146663

Epoch: 5| Step: 3
Training loss: 2.49401740454602
Validation loss: 2.3802979260966777

Epoch: 5| Step: 4
Training loss: 1.8723542938788698
Validation loss: 2.3994327388362797

Epoch: 5| Step: 5
Training loss: 2.5099858168850986
Validation loss: 2.3970813584149293

Epoch: 5| Step: 6
Training loss: 2.1395473691399545
Validation loss: 2.380151642743823

Epoch: 5| Step: 7
Training loss: 2.2396785508843684
Validation loss: 2.4113217236300906

Epoch: 5| Step: 8
Training loss: 2.897945557666706
Validation loss: 2.401759617518478

Epoch: 5| Step: 9
Training loss: 3.2573066153984875
Validation loss: 2.380019584455231

Epoch: 5| Step: 10
Training loss: 2.2532947576858757
Validation loss: 2.3960512772811127

Epoch: 114| Step: 0
Training loss: 2.5370294970946667
Validation loss: 2.4024871940749972

Epoch: 5| Step: 1
Training loss: 2.6205134424491865
Validation loss: 2.3993853489520762

Epoch: 5| Step: 2
Training loss: 2.03229742187853
Validation loss: 2.3797264542097163

Epoch: 5| Step: 3
Training loss: 2.326699863987635
Validation loss: 2.3916247547661027

Epoch: 5| Step: 4
Training loss: 2.6959816806861308
Validation loss: 2.388093433011706

Epoch: 5| Step: 5
Training loss: 2.217474449896459
Validation loss: 2.3858704094885685

Epoch: 5| Step: 6
Training loss: 2.672743895832285
Validation loss: 2.406052576922809

Epoch: 5| Step: 7
Training loss: 2.242449489267052
Validation loss: 2.3956616683031156

Epoch: 5| Step: 8
Training loss: 2.3888794753409135
Validation loss: 2.404884126512106

Epoch: 5| Step: 9
Training loss: 2.454087086948703
Validation loss: 2.4019998667951246

Epoch: 5| Step: 10
Training loss: 2.8554842801069644
Validation loss: 2.3890145625604786

Epoch: 115| Step: 0
Training loss: 2.4684187268466755
Validation loss: 2.4028374890966604

Epoch: 5| Step: 1
Training loss: 2.48355924060962
Validation loss: 2.379493855126459

Epoch: 5| Step: 2
Training loss: 2.009226853766453
Validation loss: 2.3888272753836297

Epoch: 5| Step: 3
Training loss: 2.4259917679259413
Validation loss: 2.3857002048592166

Epoch: 5| Step: 4
Training loss: 2.3475913548188005
Validation loss: 2.3785514659259186

Epoch: 5| Step: 5
Training loss: 2.1814917750110627
Validation loss: 2.3897763748083976

Epoch: 5| Step: 6
Training loss: 2.3431475055679103
Validation loss: 2.385558025339603

Epoch: 5| Step: 7
Training loss: 2.897028578027697
Validation loss: 2.3863143539365064

Epoch: 5| Step: 8
Training loss: 2.4834161983549414
Validation loss: 2.387964825275266

Epoch: 5| Step: 9
Training loss: 2.8710570456306046
Validation loss: 2.3874260463427097

Epoch: 5| Step: 10
Training loss: 2.3411111853853557
Validation loss: 2.407304562805475

Epoch: 116| Step: 0
Training loss: 2.4235650841229703
Validation loss: 2.392411648196942

Epoch: 5| Step: 1
Training loss: 2.773489938159638
Validation loss: 2.4015006574103968

Epoch: 5| Step: 2
Training loss: 2.540450341859318
Validation loss: 2.399060106689861

Epoch: 5| Step: 3
Training loss: 2.29206978691336
Validation loss: 2.3859987046332343

Epoch: 5| Step: 4
Training loss: 2.43652852579629
Validation loss: 2.3903579192754183

Epoch: 5| Step: 5
Training loss: 2.635669369449615
Validation loss: 2.39980374917371

Epoch: 5| Step: 6
Training loss: 2.6436519090568193
Validation loss: 2.391780893662905

Epoch: 5| Step: 7
Training loss: 2.5753612153850325
Validation loss: 2.397305600046742

Epoch: 5| Step: 8
Training loss: 2.095361687113468
Validation loss: 2.414410731243634

Epoch: 5| Step: 9
Training loss: 2.46682152090197
Validation loss: 2.3875156057395706

Epoch: 5| Step: 10
Training loss: 1.7778064838052152
Validation loss: 2.397644431325915

Epoch: 117| Step: 0
Training loss: 2.208089875050667
Validation loss: 2.4039027140189435

Epoch: 5| Step: 1
Training loss: 2.7002013166750607
Validation loss: 2.3985300760031536

Epoch: 5| Step: 2
Training loss: 2.3866994704046904
Validation loss: 2.3982749756435604

Epoch: 5| Step: 3
Training loss: 2.1145171607677136
Validation loss: 2.3889454799695478

Epoch: 5| Step: 4
Training loss: 2.2570497484990684
Validation loss: 2.40259799260559

Epoch: 5| Step: 5
Training loss: 2.2603614437078803
Validation loss: 2.3857949739620214

Epoch: 5| Step: 6
Training loss: 2.593926297366491
Validation loss: 2.4113793689853504

Epoch: 5| Step: 7
Training loss: 2.812309936883079
Validation loss: 2.396323322912189

Epoch: 5| Step: 8
Training loss: 2.096292347124861
Validation loss: 2.3885935511950755

Epoch: 5| Step: 9
Training loss: 2.508454998103124
Validation loss: 2.4020418836674917

Epoch: 5| Step: 10
Training loss: 2.8442499748284296
Validation loss: 2.391457469772623

Epoch: 118| Step: 0
Training loss: 2.5930331974692282
Validation loss: 2.394748260835907

Epoch: 5| Step: 1
Training loss: 2.6420176969768607
Validation loss: 2.4077688419613925

Epoch: 5| Step: 2
Training loss: 2.6481131295934555
Validation loss: 2.384931414399631

Epoch: 5| Step: 3
Training loss: 1.8375128297941767
Validation loss: 2.402031255713792

Epoch: 5| Step: 4
Training loss: 2.207022067700755
Validation loss: 2.3860634529071234

Epoch: 5| Step: 5
Training loss: 2.4994531987160755
Validation loss: 2.3843072784340906

Epoch: 5| Step: 6
Training loss: 2.311202020059444
Validation loss: 2.3845808068703933

Epoch: 5| Step: 7
Training loss: 2.33792856133068
Validation loss: 2.4095982350866056

Epoch: 5| Step: 8
Training loss: 2.7834934230457447
Validation loss: 2.3867468081979126

Epoch: 5| Step: 9
Training loss: 2.416249787339992
Validation loss: 2.3768643740055846

Epoch: 5| Step: 10
Training loss: 2.3940931109149597
Validation loss: 2.409896614557562

Epoch: 119| Step: 0
Training loss: 2.6073438768471964
Validation loss: 2.3761256000400826

Epoch: 5| Step: 1
Training loss: 2.7386644995822276
Validation loss: 2.4067989320394285

Epoch: 5| Step: 2
Training loss: 2.475644492034335
Validation loss: 2.392258354953033

Epoch: 5| Step: 3
Training loss: 2.1374296299465936
Validation loss: 2.402643842384598

Epoch: 5| Step: 4
Training loss: 2.3007005246675027
Validation loss: 2.408860546171238

Epoch: 5| Step: 5
Training loss: 2.5892937307750463
Validation loss: 2.3927231188150357

Epoch: 5| Step: 6
Training loss: 2.2617043081293557
Validation loss: 2.406264436249936

Epoch: 5| Step: 7
Training loss: 2.485204786002381
Validation loss: 2.3870922567253583

Epoch: 5| Step: 8
Training loss: 1.732343704197483
Validation loss: 2.3915785425921405

Epoch: 5| Step: 9
Training loss: 2.8521734549915436
Validation loss: 2.3905091873932256

Epoch: 5| Step: 10
Training loss: 2.4552164091922317
Validation loss: 2.393840145449731

Epoch: 120| Step: 0
Training loss: 1.7014400301489434
Validation loss: 2.3945112271217757

Epoch: 5| Step: 1
Training loss: 2.2951149976919707
Validation loss: 2.3867991675092903

Epoch: 5| Step: 2
Training loss: 2.4682308568638103
Validation loss: 2.3863767296905496

Epoch: 5| Step: 3
Training loss: 2.3565666208609315
Validation loss: 2.39777090328926

Epoch: 5| Step: 4
Training loss: 2.331753866034397
Validation loss: 2.401212486565145

Epoch: 5| Step: 5
Training loss: 2.4305070188005464
Validation loss: 2.4267481315794224

Epoch: 5| Step: 6
Training loss: 2.4170072797824256
Validation loss: 2.3907937168545206

Epoch: 5| Step: 7
Training loss: 2.335353204124099
Validation loss: 2.4040339343715256

Epoch: 5| Step: 8
Training loss: 2.7715463127328483
Validation loss: 2.3951818938598475

Epoch: 5| Step: 9
Training loss: 2.542481172054949
Validation loss: 2.391096325617285

Epoch: 5| Step: 10
Training loss: 2.8418134865816036
Validation loss: 2.398210694427445

Epoch: 121| Step: 0
Training loss: 2.6118021201732353
Validation loss: 2.4100810518039864

Epoch: 5| Step: 1
Training loss: 2.771309995642758
Validation loss: 2.4061747958583983

Epoch: 5| Step: 2
Training loss: 1.8671367430870895
Validation loss: 2.400429295186207

Epoch: 5| Step: 3
Training loss: 2.2574534411186336
Validation loss: 2.386430720862083

Epoch: 5| Step: 4
Training loss: 1.9981620210971212
Validation loss: 2.3898295768827036

Epoch: 5| Step: 5
Training loss: 2.390441688041819
Validation loss: 2.3933502428727023

Epoch: 5| Step: 6
Training loss: 2.9502404066501513
Validation loss: 2.4073516551615683

Epoch: 5| Step: 7
Training loss: 2.023227636581581
Validation loss: 2.4064631522839273

Epoch: 5| Step: 8
Training loss: 2.5864384560673246
Validation loss: 2.4137286462352945

Epoch: 5| Step: 9
Training loss: 2.6736653001806596
Validation loss: 2.4075176701730876

Epoch: 5| Step: 10
Training loss: 2.2650191976984173
Validation loss: 2.3911983695957333

Epoch: 122| Step: 0
Training loss: 2.7059018199615523
Validation loss: 2.3872720528067584

Epoch: 5| Step: 1
Training loss: 2.2454387207231794
Validation loss: 2.3898554681411426

Epoch: 5| Step: 2
Training loss: 2.5884833121422224
Validation loss: 2.405199899696292

Epoch: 5| Step: 3
Training loss: 2.2090091990619976
Validation loss: 2.422431249446922

Epoch: 5| Step: 4
Training loss: 2.369477527184222
Validation loss: 2.3899461775870514

Epoch: 5| Step: 5
Training loss: 1.8176715340664866
Validation loss: 2.3948144923023906

Epoch: 5| Step: 6
Training loss: 2.3333519753210967
Validation loss: 2.4034189201505494

Epoch: 5| Step: 7
Training loss: 2.5867947082519676
Validation loss: 2.397263802267775

Epoch: 5| Step: 8
Training loss: 1.653600192503971
Validation loss: 2.386241180507276

Epoch: 5| Step: 9
Training loss: 2.9568333830451676
Validation loss: 2.406024676734802

Epoch: 5| Step: 10
Training loss: 2.728599071933292
Validation loss: 2.3993214703859693

Epoch: 123| Step: 0
Training loss: 2.539121280870074
Validation loss: 2.406738020810311

Epoch: 5| Step: 1
Training loss: 2.6354975832452405
Validation loss: 2.3911281492933765

Epoch: 5| Step: 2
Training loss: 2.402209369653664
Validation loss: 2.398279813715062

Epoch: 5| Step: 3
Training loss: 2.301302424988364
Validation loss: 2.3961081355693765

Epoch: 5| Step: 4
Training loss: 2.3902571650735713
Validation loss: 2.409294702654828

Epoch: 5| Step: 5
Training loss: 2.5889679361408158
Validation loss: 2.3942009833364764

Epoch: 5| Step: 6
Training loss: 2.271584925963962
Validation loss: 2.4124599465576377

Epoch: 5| Step: 7
Training loss: 2.3012224431747557
Validation loss: 2.4107650004274817

Epoch: 5| Step: 8
Training loss: 1.9796465910890135
Validation loss: 2.3843774738238994

Epoch: 5| Step: 9
Training loss: 2.808483052625521
Validation loss: 2.4157280819590228

Epoch: 5| Step: 10
Training loss: 2.079447390067631
Validation loss: 2.397236056451424

Epoch: 124| Step: 0
Training loss: 2.0567669807012248
Validation loss: 2.4097720641212836

Epoch: 5| Step: 1
Training loss: 2.2571211551705974
Validation loss: 2.3864501390581316

Epoch: 5| Step: 2
Training loss: 2.303430764179786
Validation loss: 2.4082421807108676

Epoch: 5| Step: 3
Training loss: 2.7432579277060993
Validation loss: 2.3989138394576326

Epoch: 5| Step: 4
Training loss: 2.6564264575464964
Validation loss: 2.386676564337306

Epoch: 5| Step: 5
Training loss: 2.340060776467362
Validation loss: 2.4112534949071835

Epoch: 5| Step: 6
Training loss: 1.933233979018061
Validation loss: 2.3952432520158506

Epoch: 5| Step: 7
Training loss: 2.4562365000113564
Validation loss: 2.4123589358562523

Epoch: 5| Step: 8
Training loss: 2.012318108910158
Validation loss: 2.41029922062098

Epoch: 5| Step: 9
Training loss: 3.0187499304982683
Validation loss: 2.403053814903557

Epoch: 5| Step: 10
Training loss: 2.3522148368121667
Validation loss: 2.3992291557211454

Epoch: 125| Step: 0
Training loss: 2.116137254644217
Validation loss: 2.42379256333749

Epoch: 5| Step: 1
Training loss: 2.7940606817101545
Validation loss: 2.3825566119949158

Epoch: 5| Step: 2
Training loss: 2.7255902237347613
Validation loss: 2.408484548709638

Epoch: 5| Step: 3
Training loss: 2.5835336074311708
Validation loss: 2.3844272617743356

Epoch: 5| Step: 4
Training loss: 1.7172469068947254
Validation loss: 2.4155368939936412

Epoch: 5| Step: 5
Training loss: 2.7561387988989936
Validation loss: 2.407070041486673

Epoch: 5| Step: 6
Training loss: 2.1575799793257953
Validation loss: 2.3838953100702804

Epoch: 5| Step: 7
Training loss: 2.246881336951306
Validation loss: 2.4214596426911426

Epoch: 5| Step: 8
Training loss: 2.0693368592199457
Validation loss: 2.4114670904923625

Epoch: 5| Step: 9
Training loss: 2.9200490866415234
Validation loss: 2.400546367812053

Epoch: 5| Step: 10
Training loss: 2.0224042338366193
Validation loss: 2.401511794780127

Epoch: 126| Step: 0
Training loss: 2.5746553134769967
Validation loss: 2.419976941457084

Epoch: 5| Step: 1
Training loss: 2.8264055452056485
Validation loss: 2.4124223873765636

Epoch: 5| Step: 2
Training loss: 2.6785218842783616
Validation loss: 2.4138465808945853

Epoch: 5| Step: 3
Training loss: 2.2605075261244503
Validation loss: 2.3860349762390864

Epoch: 5| Step: 4
Training loss: 1.7983855822482437
Validation loss: 2.4223481424339743

Epoch: 5| Step: 5
Training loss: 2.5593291412455645
Validation loss: 2.3961541234387713

Epoch: 5| Step: 6
Training loss: 2.1235304968583915
Validation loss: 2.414121493346061

Epoch: 5| Step: 7
Training loss: 2.0444050803518268
Validation loss: 2.4258442141123586

Epoch: 5| Step: 8
Training loss: 2.5192773498825223
Validation loss: 2.380463336327916

Epoch: 5| Step: 9
Training loss: 2.330210219137912
Validation loss: 2.411360124960579

Epoch: 5| Step: 10
Training loss: 2.3638073044098986
Validation loss: 2.4117535311418736

Epoch: 127| Step: 0
Training loss: 2.501193429287153
Validation loss: 2.407180845803332

Epoch: 5| Step: 1
Training loss: 2.575277617220251
Validation loss: 2.4176973150816523

Epoch: 5| Step: 2
Training loss: 1.6320099386866258
Validation loss: 2.412262827662808

Epoch: 5| Step: 3
Training loss: 2.5880151797856175
Validation loss: 2.4052341449262298

Epoch: 5| Step: 4
Training loss: 2.524997382587549
Validation loss: 2.3894471654277325

Epoch: 5| Step: 5
Training loss: 2.216019575659157
Validation loss: 2.390069216924152

Epoch: 5| Step: 6
Training loss: 2.478406346093679
Validation loss: 2.389645931412673

Epoch: 5| Step: 7
Training loss: 2.8386147212622217
Validation loss: 2.4098214593235006

Epoch: 5| Step: 8
Training loss: 2.34407977009463
Validation loss: 2.401523959038958

Epoch: 5| Step: 9
Training loss: 2.2530748761192787
Validation loss: 2.399520930207654

Epoch: 5| Step: 10
Training loss: 2.0553140011469164
Validation loss: 2.3915646726557034

Epoch: 128| Step: 0
Training loss: 2.344469697443634
Validation loss: 2.4093168520822568

Epoch: 5| Step: 1
Training loss: 2.26070232315015
Validation loss: 2.4011230387339095

Epoch: 5| Step: 2
Training loss: 2.1998134100421938
Validation loss: 2.411870892736116

Epoch: 5| Step: 3
Training loss: 2.061922743962317
Validation loss: 2.385818761014327

Epoch: 5| Step: 4
Training loss: 2.5216997617510946
Validation loss: 2.405705840438225

Epoch: 5| Step: 5
Training loss: 2.960368964938211
Validation loss: 2.402030096647108

Epoch: 5| Step: 6
Training loss: 2.1374334224571796
Validation loss: 2.4144394487320806

Epoch: 5| Step: 7
Training loss: 3.0648385286347475
Validation loss: 2.4154061451876183

Epoch: 5| Step: 8
Training loss: 2.107779683733552
Validation loss: 2.406236344612879

Epoch: 5| Step: 9
Training loss: 2.0407062788895463
Validation loss: 2.4084482995923713

Epoch: 5| Step: 10
Training loss: 2.385618065296035
Validation loss: 2.4305444272006795

Epoch: 129| Step: 0
Training loss: 2.1141598156778043
Validation loss: 2.3927856039260345

Epoch: 5| Step: 1
Training loss: 2.6499456651983295
Validation loss: 2.4149807953810303

Epoch: 5| Step: 2
Training loss: 2.582982059920064
Validation loss: 2.3980486411186526

Epoch: 5| Step: 3
Training loss: 2.1351753532708004
Validation loss: 2.3911544446236883

Epoch: 5| Step: 4
Training loss: 1.9981560551410946
Validation loss: 2.383217927011838

Epoch: 5| Step: 5
Training loss: 2.1288816118127043
Validation loss: 2.393889340894891

Epoch: 5| Step: 6
Training loss: 1.9201899639171318
Validation loss: 2.4213349564901576

Epoch: 5| Step: 7
Training loss: 2.6645738217261354
Validation loss: 2.3945104134412247

Epoch: 5| Step: 8
Training loss: 2.453179620025389
Validation loss: 2.3843877697480944

Epoch: 5| Step: 9
Training loss: 2.9133709043383265
Validation loss: 2.393881469156147

Epoch: 5| Step: 10
Training loss: 2.544247354160285
Validation loss: 2.399961196464378

Epoch: 130| Step: 0
Training loss: 2.0919439013018124
Validation loss: 2.4176793524386766

Epoch: 5| Step: 1
Training loss: 2.301997693800579
Validation loss: 2.4133505289868147

Epoch: 5| Step: 2
Training loss: 2.6118894785388234
Validation loss: 2.3971147763547402

Epoch: 5| Step: 3
Training loss: 2.1116145925064966
Validation loss: 2.403920834525829

Epoch: 5| Step: 4
Training loss: 2.193140007048145
Validation loss: 2.4122558719314684

Epoch: 5| Step: 5
Training loss: 2.5355811093701623
Validation loss: 2.4054911044934344

Epoch: 5| Step: 6
Training loss: 2.45679660762303
Validation loss: 2.4097790695759898

Epoch: 5| Step: 7
Training loss: 2.2825564471281257
Validation loss: 2.433786028586741

Epoch: 5| Step: 8
Training loss: 2.389898651081038
Validation loss: 2.4275935432175992

Epoch: 5| Step: 9
Training loss: 2.4938948472102127
Validation loss: 2.3888505686326975

Epoch: 5| Step: 10
Training loss: 2.4687359966412084
Validation loss: 2.41027442008347

Epoch: 131| Step: 0
Training loss: 1.6321160688404972
Validation loss: 2.4092772200411754

Epoch: 5| Step: 1
Training loss: 2.5415614580569494
Validation loss: 2.4052509268187845

Epoch: 5| Step: 2
Training loss: 1.9419667837443204
Validation loss: 2.3865440034403544

Epoch: 5| Step: 3
Training loss: 2.3831536721046174
Validation loss: 2.4074754794565227

Epoch: 5| Step: 4
Training loss: 2.2459648825124146
Validation loss: 2.403395875829251

Epoch: 5| Step: 5
Training loss: 2.545950692609584
Validation loss: 2.4048740356004896

Epoch: 5| Step: 6
Training loss: 2.814623645538019
Validation loss: 2.4118270476969452

Epoch: 5| Step: 7
Training loss: 2.261995657669608
Validation loss: 2.4047709834991524

Epoch: 5| Step: 8
Training loss: 2.5396629210454207
Validation loss: 2.4110870635426904

Epoch: 5| Step: 9
Training loss: 2.3339752835531615
Validation loss: 2.420639756207082

Epoch: 5| Step: 10
Training loss: 2.6094219637544858
Validation loss: 2.4209200180003805

Epoch: 132| Step: 0
Training loss: 2.015630677680957
Validation loss: 2.426946664597854

Epoch: 5| Step: 1
Training loss: 1.9669317901917305
Validation loss: 2.410714108098745

Epoch: 5| Step: 2
Training loss: 2.664812894053716
Validation loss: 2.4113156508055456

Epoch: 5| Step: 3
Training loss: 2.301765270326272
Validation loss: 2.4260062256604256

Epoch: 5| Step: 4
Training loss: 2.86302960423211
Validation loss: 2.404555159745556

Epoch: 5| Step: 5
Training loss: 2.1855514567227443
Validation loss: 2.3906037090205157

Epoch: 5| Step: 6
Training loss: 2.260941287804036
Validation loss: 2.4030617286068634

Epoch: 5| Step: 7
Training loss: 2.917069507208852
Validation loss: 2.418884099844669

Epoch: 5| Step: 8
Training loss: 2.389070990617832
Validation loss: 2.4076821580302643

Epoch: 5| Step: 9
Training loss: 2.234293262613889
Validation loss: 2.3879841923484464

Epoch: 5| Step: 10
Training loss: 1.9167276317464976
Validation loss: 2.404774177425849

Epoch: 133| Step: 0
Training loss: 2.6992795194859696
Validation loss: 2.4149441533276836

Epoch: 5| Step: 1
Training loss: 2.269189805627198
Validation loss: 2.407995437150671

Epoch: 5| Step: 2
Training loss: 2.258681397401648
Validation loss: 2.3882948749867188

Epoch: 5| Step: 3
Training loss: 2.643095136479612
Validation loss: 2.393389524352698

Epoch: 5| Step: 4
Training loss: 2.6898780769597517
Validation loss: 2.4200812697826235

Epoch: 5| Step: 5
Training loss: 2.210786632337441
Validation loss: 2.4048374804762425

Epoch: 5| Step: 6
Training loss: 2.045753579485392
Validation loss: 2.4109592442638523

Epoch: 5| Step: 7
Training loss: 2.484790503346312
Validation loss: 2.3893579541767083

Epoch: 5| Step: 8
Training loss: 2.6032135910584415
Validation loss: 2.4123988637075384

Epoch: 5| Step: 9
Training loss: 2.2768960450524713
Validation loss: 2.43324437110139

Epoch: 5| Step: 10
Training loss: 1.64179057542789
Validation loss: 2.400834162655292

Epoch: 134| Step: 0
Training loss: 2.134431441134687
Validation loss: 2.395466618518791

Epoch: 5| Step: 1
Training loss: 2.7468088882006954
Validation loss: 2.4263479770179583

Epoch: 5| Step: 2
Training loss: 2.4087144195985304
Validation loss: 2.3965364905438227

Epoch: 5| Step: 3
Training loss: 2.164328548451762
Validation loss: 2.416714629254968

Epoch: 5| Step: 4
Training loss: 2.068751484389219
Validation loss: 2.4140899780888736

Epoch: 5| Step: 5
Training loss: 2.3774995199337385
Validation loss: 2.398349576637656

Epoch: 5| Step: 6
Training loss: 1.7838059541818674
Validation loss: 2.4306428216444074

Epoch: 5| Step: 7
Training loss: 2.7196438076503187
Validation loss: 2.424472133194105

Epoch: 5| Step: 8
Training loss: 2.213345890737247
Validation loss: 2.4063003059608032

Epoch: 5| Step: 9
Training loss: 2.7392080265083543
Validation loss: 2.405695678377543

Epoch: 5| Step: 10
Training loss: 2.28003817208443
Validation loss: 2.4110134382964072

Epoch: 135| Step: 0
Training loss: 2.1100871826528866
Validation loss: 2.4020783746095398

Epoch: 5| Step: 1
Training loss: 2.480061751489009
Validation loss: 2.427149390477839

Epoch: 5| Step: 2
Training loss: 2.2754469966863664
Validation loss: 2.41719090507978

Epoch: 5| Step: 3
Training loss: 1.9693523272750058
Validation loss: 2.399956256030274

Epoch: 5| Step: 4
Training loss: 2.4105927552768454
Validation loss: 2.411068942135046

Epoch: 5| Step: 5
Training loss: 2.258668730582083
Validation loss: 2.4126705950766754

Epoch: 5| Step: 6
Training loss: 2.1064155445639434
Validation loss: 2.3872633275262842

Epoch: 5| Step: 7
Training loss: 2.482802367144698
Validation loss: 2.4028006373216324

Epoch: 5| Step: 8
Training loss: 2.9683127633406055
Validation loss: 2.4126803441718714

Epoch: 5| Step: 9
Training loss: 2.300171232069121
Validation loss: 2.404131393087124

Epoch: 5| Step: 10
Training loss: 2.3074552823876147
Validation loss: 2.4156625618548273

Epoch: 136| Step: 0
Training loss: 2.0335965027938894
Validation loss: 2.4245494512787054

Epoch: 5| Step: 1
Training loss: 2.63786478638616
Validation loss: 2.3905953830313607

Epoch: 5| Step: 2
Training loss: 2.3127446431840277
Validation loss: 2.4078941433426353

Epoch: 5| Step: 3
Training loss: 2.901138733222156
Validation loss: 2.403805753149095

Epoch: 5| Step: 4
Training loss: 2.365032965529138
Validation loss: 2.401351254951256

Epoch: 5| Step: 5
Training loss: 2.1592744265596107
Validation loss: 2.3936833933174118

Epoch: 5| Step: 6
Training loss: 2.2078568526319517
Validation loss: 2.4185852349517902

Epoch: 5| Step: 7
Training loss: 2.4974814126179337
Validation loss: 2.4025509159120886

Epoch: 5| Step: 8
Training loss: 1.829376444449472
Validation loss: 2.402375865407808

Epoch: 5| Step: 9
Training loss: 2.3917855830208703
Validation loss: 2.4053367404672086

Epoch: 5| Step: 10
Training loss: 2.2259185395189047
Validation loss: 2.423968441562859

Epoch: 137| Step: 0
Training loss: 2.4905772971607054
Validation loss: 2.406056788826846

Epoch: 5| Step: 1
Training loss: 1.7487064758076165
Validation loss: 2.422941405913212

Epoch: 5| Step: 2
Training loss: 2.3937309881904527
Validation loss: 2.397773246388719

Epoch: 5| Step: 3
Training loss: 2.688020434001047
Validation loss: 2.4145379250593093

Epoch: 5| Step: 4
Training loss: 2.618559247264248
Validation loss: 2.411225378464007

Epoch: 5| Step: 5
Training loss: 2.1142627742436004
Validation loss: 2.4151205018425044

Epoch: 5| Step: 6
Training loss: 1.8183945141274456
Validation loss: 2.4211162785211893

Epoch: 5| Step: 7
Training loss: 1.9943631129327495
Validation loss: 2.409714640965911

Epoch: 5| Step: 8
Training loss: 2.6119092866646683
Validation loss: 2.436110332556224

Epoch: 5| Step: 9
Training loss: 2.0718835016366746
Validation loss: 2.424862038760515

Epoch: 5| Step: 10
Training loss: 2.9283255297738324
Validation loss: 2.4240120786245924

Epoch: 138| Step: 0
Training loss: 1.9817978351238952
Validation loss: 2.4128190480121825

Epoch: 5| Step: 1
Training loss: 1.8468148571878384
Validation loss: 2.4160459956897924

Epoch: 5| Step: 2
Training loss: 2.619860567939977
Validation loss: 2.398280842044512

Epoch: 5| Step: 3
Training loss: 2.0539843150118497
Validation loss: 2.3882316283131626

Epoch: 5| Step: 4
Training loss: 2.1772461485023262
Validation loss: 2.419403534727298

Epoch: 5| Step: 5
Training loss: 2.497148508839916
Validation loss: 2.414123865177207

Epoch: 5| Step: 6
Training loss: 2.5193116084919653
Validation loss: 2.4032914008099744

Epoch: 5| Step: 7
Training loss: 2.4465970209102785
Validation loss: 2.408276298051395

Epoch: 5| Step: 8
Training loss: 2.2945987555107545
Validation loss: 2.3938227748654604

Epoch: 5| Step: 9
Training loss: 2.810131347138668
Validation loss: 2.4120024735578136

Epoch: 5| Step: 10
Training loss: 2.0624206990111094
Validation loss: 2.423368325835669

Epoch: 139| Step: 0
Training loss: 2.1942017484072935
Validation loss: 2.422526513999322

Epoch: 5| Step: 1
Training loss: 1.843171950421721
Validation loss: 2.3998967446313104

Epoch: 5| Step: 2
Training loss: 2.2838289497981314
Validation loss: 2.4253698901852476

Epoch: 5| Step: 3
Training loss: 2.495062625534793
Validation loss: 2.4170490591070974

Epoch: 5| Step: 4
Training loss: 2.4968457350370596
Validation loss: 2.3906402048539888

Epoch: 5| Step: 5
Training loss: 2.6315777427269036
Validation loss: 2.398178051280104

Epoch: 5| Step: 6
Training loss: 2.1236736421739466
Validation loss: 2.414052002491016

Epoch: 5| Step: 7
Training loss: 2.495342207166279
Validation loss: 2.3918059856404486

Epoch: 5| Step: 8
Training loss: 2.504522810082908
Validation loss: 2.4007479891770833

Epoch: 5| Step: 9
Training loss: 2.3112929003186142
Validation loss: 2.4047406665698268

Epoch: 5| Step: 10
Training loss: 1.926055455369077
Validation loss: 2.4190655129574723

Epoch: 140| Step: 0
Training loss: 1.6915436792374918
Validation loss: 2.388306515111896

Epoch: 5| Step: 1
Training loss: 2.6763314899579655
Validation loss: 2.428041008205713

Epoch: 5| Step: 2
Training loss: 2.411819255231114
Validation loss: 2.4090867598679475

Epoch: 5| Step: 3
Training loss: 2.6078276472068898
Validation loss: 2.404893553257228

Epoch: 5| Step: 4
Training loss: 2.035493614072441
Validation loss: 2.4264986644728594

Epoch: 5| Step: 5
Training loss: 1.9761406369142895
Validation loss: 2.394355181687986

Epoch: 5| Step: 6
Training loss: 2.013024004842835
Validation loss: 2.405042311954296

Epoch: 5| Step: 7
Training loss: 2.629023239004012
Validation loss: 2.4311982049340437

Epoch: 5| Step: 8
Training loss: 2.4218799221850182
Validation loss: 2.4139716103423154

Epoch: 5| Step: 9
Training loss: 2.2558367575300156
Validation loss: 2.3980502906665695

Epoch: 5| Step: 10
Training loss: 2.5086249345702143
Validation loss: 2.3967209376030705

Epoch: 141| Step: 0
Training loss: 1.6868580904180595
Validation loss: 2.4094441498827597

Epoch: 5| Step: 1
Training loss: 1.9993165755850622
Validation loss: 2.423683954354332

Epoch: 5| Step: 2
Training loss: 2.2883899729313817
Validation loss: 2.4133711896055314

Epoch: 5| Step: 3
Training loss: 2.01738077031192
Validation loss: 2.4107522245409054

Epoch: 5| Step: 4
Training loss: 2.5334397251810605
Validation loss: 2.420375545834096

Epoch: 5| Step: 5
Training loss: 2.5260043950952515
Validation loss: 2.4069812315091927

Epoch: 5| Step: 6
Training loss: 2.437124370095318
Validation loss: 2.404528647397575

Epoch: 5| Step: 7
Training loss: 2.2577471344141538
Validation loss: 2.412855447152232

Epoch: 5| Step: 8
Training loss: 2.6410657526141503
Validation loss: 2.4054032327283275

Epoch: 5| Step: 9
Training loss: 2.689663570594999
Validation loss: 2.4143646844387074

Epoch: 5| Step: 10
Training loss: 2.447148715284136
Validation loss: 2.3956377307143324

Epoch: 142| Step: 0
Training loss: 2.6128328905244116
Validation loss: 2.3923669878860303

Epoch: 5| Step: 1
Training loss: 2.2561854007169817
Validation loss: 2.430114316095939

Epoch: 5| Step: 2
Training loss: 1.9359214874418178
Validation loss: 2.413647649578211

Epoch: 5| Step: 3
Training loss: 2.7389686581453856
Validation loss: 2.3889060924156524

Epoch: 5| Step: 4
Training loss: 2.464552679271642
Validation loss: 2.4003742160418327

Epoch: 5| Step: 5
Training loss: 2.415731501236359
Validation loss: 2.4156561789116067

Epoch: 5| Step: 6
Training loss: 2.139920195223422
Validation loss: 2.3944576692215573

Epoch: 5| Step: 7
Training loss: 1.9526127257879837
Validation loss: 2.4122998983437074

Epoch: 5| Step: 8
Training loss: 2.326069686272165
Validation loss: 2.412472369098336

Epoch: 5| Step: 9
Training loss: 2.6296476364514185
Validation loss: 2.4140292731302666

Epoch: 5| Step: 10
Training loss: 1.7159509234579842
Validation loss: 2.4371280060268097

Epoch: 143| Step: 0
Training loss: 2.9947495609585335
Validation loss: 2.415241616555224

Epoch: 5| Step: 1
Training loss: 2.47024355749335
Validation loss: 2.414547917187347

Epoch: 5| Step: 2
Training loss: 2.2835333905903723
Validation loss: 2.3880430763040636

Epoch: 5| Step: 3
Training loss: 2.419948673176881
Validation loss: 2.4017872747867406

Epoch: 5| Step: 4
Training loss: 2.2964327639473914
Validation loss: 2.4054668133729624

Epoch: 5| Step: 5
Training loss: 2.3193281249868423
Validation loss: 2.4423426862516617

Epoch: 5| Step: 6
Training loss: 2.535881984852819
Validation loss: 2.416298486741838

Epoch: 5| Step: 7
Training loss: 2.140353443156831
Validation loss: 2.416382993259018

Epoch: 5| Step: 8
Training loss: 1.9794087178303779
Validation loss: 2.3865594569223454

Epoch: 5| Step: 9
Training loss: 1.6696961367435683
Validation loss: 2.411664810719395

Epoch: 5| Step: 10
Training loss: 1.732881538797587
Validation loss: 2.4074469131710954

Epoch: 144| Step: 0
Training loss: 2.72530075653349
Validation loss: 2.4167103553050655

Epoch: 5| Step: 1
Training loss: 1.992376221338414
Validation loss: 2.4115075976090083

Epoch: 5| Step: 2
Training loss: 2.1621100366276087
Validation loss: 2.4290300554760877

Epoch: 5| Step: 3
Training loss: 2.519266466525109
Validation loss: 2.4088707587356093

Epoch: 5| Step: 4
Training loss: 1.8647207781323614
Validation loss: 2.429674806730843

Epoch: 5| Step: 5
Training loss: 2.258435542854125
Validation loss: 2.4347828965478935

Epoch: 5| Step: 6
Training loss: 2.092751677769809
Validation loss: 2.3942274692424754

Epoch: 5| Step: 7
Training loss: 2.8794630487889266
Validation loss: 2.404077031119245

Epoch: 5| Step: 8
Training loss: 2.0316755582611226
Validation loss: 2.4165178913690797

Epoch: 5| Step: 9
Training loss: 2.385348511989626
Validation loss: 2.428493669003855

Epoch: 5| Step: 10
Training loss: 2.0113669671186347
Validation loss: 2.43601112339973

Epoch: 145| Step: 0
Training loss: 2.782139753685876
Validation loss: 2.408311320795878

Epoch: 5| Step: 1
Training loss: 2.242891739360638
Validation loss: 2.418507277811198

Epoch: 5| Step: 2
Training loss: 2.165579694353837
Validation loss: 2.4346199485191233

Epoch: 5| Step: 3
Training loss: 2.35834394751363
Validation loss: 2.407462875660451

Epoch: 5| Step: 4
Training loss: 1.8358601005958926
Validation loss: 2.418345622023284

Epoch: 5| Step: 5
Training loss: 2.4459080565008393
Validation loss: 2.4244283553165418

Epoch: 5| Step: 6
Training loss: 2.5523871935091664
Validation loss: 2.390275234582152

Epoch: 5| Step: 7
Training loss: 2.2845467561582096
Validation loss: 2.4257153039108967

Epoch: 5| Step: 8
Training loss: 2.202825972372054
Validation loss: 2.441858168649071

Epoch: 5| Step: 9
Training loss: 2.294197234331043
Validation loss: 2.3843976000778375

Epoch: 5| Step: 10
Training loss: 1.7762366567240717
Validation loss: 2.4276671693463237

Epoch: 146| Step: 0
Training loss: 2.541978493828368
Validation loss: 2.4176593272215787

Epoch: 5| Step: 1
Training loss: 2.182316551582523
Validation loss: 2.409103187165719

Epoch: 5| Step: 2
Training loss: 2.424174343222428
Validation loss: 2.409028780305855

Epoch: 5| Step: 3
Training loss: 2.149758338653863
Validation loss: 2.41723799891487

Epoch: 5| Step: 4
Training loss: 2.0980758389419933
Validation loss: 2.4032060435055724

Epoch: 5| Step: 5
Training loss: 2.5213898183761545
Validation loss: 2.4055818403297895

Epoch: 5| Step: 6
Training loss: 1.8066030137554578
Validation loss: 2.392178158473143

Epoch: 5| Step: 7
Training loss: 2.0265813139878177
Validation loss: 2.4454086448882797

Epoch: 5| Step: 8
Training loss: 2.687442335352922
Validation loss: 2.428442302616993

Epoch: 5| Step: 9
Training loss: 2.3758585532500183
Validation loss: 2.432791464591218

Epoch: 5| Step: 10
Training loss: 2.4720231582087693
Validation loss: 2.40142231699677

Epoch: 147| Step: 0
Training loss: 1.95745942386749
Validation loss: 2.4250530476038494

Epoch: 5| Step: 1
Training loss: 2.62446243594717
Validation loss: 2.3898922867525187

Epoch: 5| Step: 2
Training loss: 2.0508754163648524
Validation loss: 2.408077651261961

Epoch: 5| Step: 3
Training loss: 2.3678118697517143
Validation loss: 2.4249132547445265

Epoch: 5| Step: 4
Training loss: 2.461380788448262
Validation loss: 2.4137761326192813

Epoch: 5| Step: 5
Training loss: 2.4534060566254667
Validation loss: 2.428831466348767

Epoch: 5| Step: 6
Training loss: 2.336576750690042
Validation loss: 2.395757014988247

Epoch: 5| Step: 7
Training loss: 1.8851448902937176
Validation loss: 2.414875960070115

Epoch: 5| Step: 8
Training loss: 1.6605921274075064
Validation loss: 2.397677772987864

Epoch: 5| Step: 9
Training loss: 2.7605046000360276
Validation loss: 2.4338391655520333

Epoch: 5| Step: 10
Training loss: 2.6040927622162955
Validation loss: 2.4073585648950737

Epoch: 148| Step: 0
Training loss: 2.594648458377087
Validation loss: 2.411990567810715

Epoch: 5| Step: 1
Training loss: 2.0755270874490805
Validation loss: 2.390688148504703

Epoch: 5| Step: 2
Training loss: 1.9772706704442917
Validation loss: 2.4041745765931117

Epoch: 5| Step: 3
Training loss: 2.3519085094083056
Validation loss: 2.400822040817634

Epoch: 5| Step: 4
Training loss: 1.9010548072953015
Validation loss: 2.399824624165589

Epoch: 5| Step: 5
Training loss: 2.409354350079462
Validation loss: 2.4214504477160124

Epoch: 5| Step: 6
Training loss: 2.4834504716456873
Validation loss: 2.4024006429065374

Epoch: 5| Step: 7
Training loss: 2.3951699928050187
Validation loss: 2.4272245309434903

Epoch: 5| Step: 8
Training loss: 2.053230842637515
Validation loss: 2.418230334478848

Epoch: 5| Step: 9
Training loss: 2.328081885841088
Validation loss: 2.430993892640527

Epoch: 5| Step: 10
Training loss: 2.4507212920024624
Validation loss: 2.438422857930907

Epoch: 149| Step: 0
Training loss: 1.8171069034668017
Validation loss: 2.4090089135765997

Epoch: 5| Step: 1
Training loss: 2.114572747365327
Validation loss: 2.4318557759387662

Epoch: 5| Step: 2
Training loss: 1.9582702613034653
Validation loss: 2.3750972555181393

Epoch: 5| Step: 3
Training loss: 2.7907981280611027
Validation loss: 2.3930573169701446

Epoch: 5| Step: 4
Training loss: 2.1143426116077437
Validation loss: 2.4050312287750963

Epoch: 5| Step: 5
Training loss: 1.942722787539085
Validation loss: 2.4043903225542724

Epoch: 5| Step: 6
Training loss: 1.6553329232028837
Validation loss: 2.3940896757248153

Epoch: 5| Step: 7
Training loss: 2.479471802299029
Validation loss: 2.426293189873605

Epoch: 5| Step: 8
Training loss: 2.529473800068052
Validation loss: 2.4180491661681334

Epoch: 5| Step: 9
Training loss: 2.5332517832462997
Validation loss: 2.4029413741315

Epoch: 5| Step: 10
Training loss: 2.656584415702137
Validation loss: 2.4090104726128883

Epoch: 150| Step: 0
Training loss: 2.381687886984674
Validation loss: 2.4136475900981633

Epoch: 5| Step: 1
Training loss: 1.8542588314624247
Validation loss: 2.416222375192656

Epoch: 5| Step: 2
Training loss: 2.3237893100510045
Validation loss: 2.4168599468775316

Epoch: 5| Step: 3
Training loss: 2.74208785960132
Validation loss: 2.424674984026678

Epoch: 5| Step: 4
Training loss: 2.2606743755016026
Validation loss: 2.38408951184339

Epoch: 5| Step: 5
Training loss: 2.6736685995771783
Validation loss: 2.4045410842594555

Epoch: 5| Step: 6
Training loss: 2.102557659288402
Validation loss: 2.416647028038787

Epoch: 5| Step: 7
Training loss: 2.033852655765951
Validation loss: 2.4080237712286388

Epoch: 5| Step: 8
Training loss: 1.7224096696972888
Validation loss: 2.401416512181555

Epoch: 5| Step: 9
Training loss: 2.5651426877196943
Validation loss: 2.394654364217016

Epoch: 5| Step: 10
Training loss: 2.1318741854820162
Validation loss: 2.4110023969206558

Epoch: 151| Step: 0
Training loss: 1.5622352375780408
Validation loss: 2.4148885188061984

Epoch: 5| Step: 1
Training loss: 2.2734700099023284
Validation loss: 2.4173859592635365

Epoch: 5| Step: 2
Training loss: 2.1607933277683844
Validation loss: 2.426499171601668

Epoch: 5| Step: 3
Training loss: 2.0424462082315133
Validation loss: 2.4414830675078876

Epoch: 5| Step: 4
Training loss: 2.6289827015432086
Validation loss: 2.411686208624696

Epoch: 5| Step: 5
Training loss: 2.5513312548604086
Validation loss: 2.4092968286511725

Epoch: 5| Step: 6
Training loss: 1.7639212701316633
Validation loss: 2.417017335948373

Epoch: 5| Step: 7
Training loss: 2.0025227848047344
Validation loss: 2.4006601216025953

Epoch: 5| Step: 8
Training loss: 2.1720549145284735
Validation loss: 2.440788161006748

Epoch: 5| Step: 9
Training loss: 2.6372976614188883
Validation loss: 2.43708424352568

Epoch: 5| Step: 10
Training loss: 2.8856410594589974
Validation loss: 2.421327116273921

Epoch: 152| Step: 0
Training loss: 2.287617823166843
Validation loss: 2.409879378857964

Epoch: 5| Step: 1
Training loss: 2.8019194903682316
Validation loss: 2.463410587583308

Epoch: 5| Step: 2
Training loss: 2.149521543804354
Validation loss: 2.424067651813139

Epoch: 5| Step: 3
Training loss: 2.030014131618978
Validation loss: 2.4056958563418527

Epoch: 5| Step: 4
Training loss: 2.2276207266307897
Validation loss: 2.424979154985403

Epoch: 5| Step: 5
Training loss: 2.5532282123224355
Validation loss: 2.429680337754533

Epoch: 5| Step: 6
Training loss: 2.0321073630046795
Validation loss: 2.4257877473878082

Epoch: 5| Step: 7
Training loss: 2.305622493073488
Validation loss: 2.3956173521672595

Epoch: 5| Step: 8
Training loss: 2.4264256209696393
Validation loss: 2.3920289454000923

Epoch: 5| Step: 9
Training loss: 1.919079057143433
Validation loss: 2.416126444021522

Epoch: 5| Step: 10
Training loss: 2.241237425803438
Validation loss: 2.3794351350823555

Epoch: 153| Step: 0
Training loss: 2.1040702520760535
Validation loss: 2.4105680279503376

Epoch: 5| Step: 1
Training loss: 2.483367043678141
Validation loss: 2.409932711044872

Epoch: 5| Step: 2
Training loss: 2.4512484230763967
Validation loss: 2.4020272918314927

Epoch: 5| Step: 3
Training loss: 2.704280275643525
Validation loss: 2.4030255971863723

Epoch: 5| Step: 4
Training loss: 2.321183474670517
Validation loss: 2.426143933600696

Epoch: 5| Step: 5
Training loss: 2.0393394779030865
Validation loss: 2.404227428600062

Epoch: 5| Step: 6
Training loss: 2.0535583874780015
Validation loss: 2.418846006619254

Epoch: 5| Step: 7
Training loss: 1.9975538792224676
Validation loss: 2.4533901391362365

Epoch: 5| Step: 8
Training loss: 2.215404513516279
Validation loss: 2.3910519248666446

Epoch: 5| Step: 9
Training loss: 2.1581025941659493
Validation loss: 2.3920448596611794

Epoch: 5| Step: 10
Training loss: 2.2262077182736393
Validation loss: 2.434313297828524

Epoch: 154| Step: 0
Training loss: 1.865165157931188
Validation loss: 2.4273812314826406

Epoch: 5| Step: 1
Training loss: 2.118680533111469
Validation loss: 2.3904430779428214

Epoch: 5| Step: 2
Training loss: 2.2051617021154724
Validation loss: 2.399840117114427

Epoch: 5| Step: 3
Training loss: 2.197043283021407
Validation loss: 2.407865263680526

Epoch: 5| Step: 4
Training loss: 2.647483811513597
Validation loss: 2.4370758112447937

Epoch: 5| Step: 5
Training loss: 1.9158541643432498
Validation loss: 2.3909650262275512

Epoch: 5| Step: 6
Training loss: 2.236761992233394
Validation loss: 2.4455447995607296

Epoch: 5| Step: 7
Training loss: 2.4215076783251677
Validation loss: 2.4265180726393774

Epoch: 5| Step: 8
Training loss: 2.0355839197583236
Validation loss: 2.417673130164994

Epoch: 5| Step: 9
Training loss: 2.194794400259765
Validation loss: 2.4053436455972252

Epoch: 5| Step: 10
Training loss: 2.6381046524112675
Validation loss: 2.4352260318108283

Epoch: 155| Step: 0
Training loss: 2.4986540031980726
Validation loss: 2.445825373012687

Epoch: 5| Step: 1
Training loss: 1.99418001948646
Validation loss: 2.4107566090150216

Epoch: 5| Step: 2
Training loss: 2.1788431261725196
Validation loss: 2.4186773545917175

Epoch: 5| Step: 3
Training loss: 2.000208605377663
Validation loss: 2.41237946203396

Epoch: 5| Step: 4
Training loss: 1.954215820876394
Validation loss: 2.43318794440973

Epoch: 5| Step: 5
Training loss: 2.260240668082722
Validation loss: 2.3765610873536973

Epoch: 5| Step: 6
Training loss: 1.866006645387058
Validation loss: 2.426942946336517

Epoch: 5| Step: 7
Training loss: 2.437706865189004
Validation loss: 2.4284598235562758

Epoch: 5| Step: 8
Training loss: 2.4669634958325806
Validation loss: 2.428214987664456

Epoch: 5| Step: 9
Training loss: 2.5869797741099663
Validation loss: 2.41197763473241

Epoch: 5| Step: 10
Training loss: 2.4766596344873224
Validation loss: 2.414613732966924

Epoch: 156| Step: 0
Training loss: 2.370306698233156
Validation loss: 2.4113728189536094

Epoch: 5| Step: 1
Training loss: 1.8936195932943545
Validation loss: 2.4085684863932806

Epoch: 5| Step: 2
Training loss: 2.119053992684843
Validation loss: 2.40946790987602

Epoch: 5| Step: 3
Training loss: 2.042008650287834
Validation loss: 2.4198168130294224

Epoch: 5| Step: 4
Training loss: 2.6327387858861866
Validation loss: 2.422349220870711

Epoch: 5| Step: 5
Training loss: 2.3888375574949907
Validation loss: 2.432231197109232

Epoch: 5| Step: 6
Training loss: 2.651300104181275
Validation loss: 2.433795384467698

Epoch: 5| Step: 7
Training loss: 1.9608178577171766
Validation loss: 2.442560272029016

Epoch: 5| Step: 8
Training loss: 2.293496690114446
Validation loss: 2.429478168125341

Epoch: 5| Step: 9
Training loss: 2.632342469228724
Validation loss: 2.4283212012521247

Epoch: 5| Step: 10
Training loss: 1.6747209800509901
Validation loss: 2.397324899679684

Epoch: 157| Step: 0
Training loss: 2.197787264469262
Validation loss: 2.4083189947439

Epoch: 5| Step: 1
Training loss: 1.8967442123346907
Validation loss: 2.4397077235857663

Epoch: 5| Step: 2
Training loss: 1.6111225898742998
Validation loss: 2.4121138430955855

Epoch: 5| Step: 3
Training loss: 2.4988258465566737
Validation loss: 2.408422504960943

Epoch: 5| Step: 4
Training loss: 2.415121691779173
Validation loss: 2.430773513932103

Epoch: 5| Step: 5
Training loss: 2.4402444501277722
Validation loss: 2.439065108391439

Epoch: 5| Step: 6
Training loss: 2.100708514990505
Validation loss: 2.4430364202189536

Epoch: 5| Step: 7
Training loss: 2.383488893656285
Validation loss: 2.4486213362779936

Epoch: 5| Step: 8
Training loss: 1.5301780841383288
Validation loss: 2.441987824505922

Epoch: 5| Step: 9
Training loss: 2.7546308713946375
Validation loss: 2.4217435358511175

Epoch: 5| Step: 10
Training loss: 2.4882242384866426
Validation loss: 2.4528972498325037

Epoch: 158| Step: 0
Training loss: 2.4331112011239666
Validation loss: 2.4195708313102102

Epoch: 5| Step: 1
Training loss: 2.324303479613675
Validation loss: 2.4335678373890377

Epoch: 5| Step: 2
Training loss: 2.7535995853745163
Validation loss: 2.438809839339943

Epoch: 5| Step: 3
Training loss: 2.3536757798529218
Validation loss: 2.436349382117895

Epoch: 5| Step: 4
Training loss: 1.7895967443790417
Validation loss: 2.4136633586323546

Epoch: 5| Step: 5
Training loss: 1.8275238091917823
Validation loss: 2.385375625494448

Epoch: 5| Step: 6
Training loss: 2.270294638850293
Validation loss: 2.398005336605524

Epoch: 5| Step: 7
Training loss: 2.3932693915295307
Validation loss: 2.3887980707693877

Epoch: 5| Step: 8
Training loss: 2.014196199961587
Validation loss: 2.3954181709133784

Epoch: 5| Step: 9
Training loss: 1.935160855352091
Validation loss: 2.4195076371893554

Epoch: 5| Step: 10
Training loss: 2.084867052738374
Validation loss: 2.4053178443170338

Epoch: 159| Step: 0
Training loss: 2.6363753935871626
Validation loss: 2.4014073685683024

Epoch: 5| Step: 1
Training loss: 2.033138746841915
Validation loss: 2.3956828533351797

Epoch: 5| Step: 2
Training loss: 2.1750686546978066
Validation loss: 2.3867306738614125

Epoch: 5| Step: 3
Training loss: 2.390101556256292
Validation loss: 2.3789081121874167

Epoch: 5| Step: 4
Training loss: 2.116121143219249
Validation loss: 2.399798508230697

Epoch: 5| Step: 5
Training loss: 2.0370844458191204
Validation loss: 2.433814672300178

Epoch: 5| Step: 6
Training loss: 1.7807791907517898
Validation loss: 2.3978288818990725

Epoch: 5| Step: 7
Training loss: 2.247215879683103
Validation loss: 2.439409948065566

Epoch: 5| Step: 8
Training loss: 2.159761196110545
Validation loss: 2.3918299396050218

Epoch: 5| Step: 9
Training loss: 2.4500684222573614
Validation loss: 2.430250134554777

Epoch: 5| Step: 10
Training loss: 2.4249436165458595
Validation loss: 2.4408152962119725

Epoch: 160| Step: 0
Training loss: 2.1837809965208006
Validation loss: 2.4032054978585036

Epoch: 5| Step: 1
Training loss: 2.0460396729293113
Validation loss: 2.4417383867657216

Epoch: 5| Step: 2
Training loss: 2.8353267463890406
Validation loss: 2.4014535933665617

Epoch: 5| Step: 3
Training loss: 2.0737638675163943
Validation loss: 2.3874079976853513

Epoch: 5| Step: 4
Training loss: 2.269765713738683
Validation loss: 2.4082025629201658

Epoch: 5| Step: 5
Training loss: 2.300346812762018
Validation loss: 2.4158331079157533

Epoch: 5| Step: 6
Training loss: 2.3525780800845455
Validation loss: 2.3978564754529574

Epoch: 5| Step: 7
Training loss: 1.6749258992899305
Validation loss: 2.4240296083185506

Epoch: 5| Step: 8
Training loss: 2.3453720583332824
Validation loss: 2.4279152260776993

Epoch: 5| Step: 9
Training loss: 2.1384576002104763
Validation loss: 2.4359716215146494

Epoch: 5| Step: 10
Training loss: 1.9756680602099916
Validation loss: 2.4217688974882314

Epoch: 161| Step: 0
Training loss: 1.2468954634361578
Validation loss: 2.418227432898908

Epoch: 5| Step: 1
Training loss: 2.4570688023449376
Validation loss: 2.430563437062819

Epoch: 5| Step: 2
Training loss: 2.2313271388976674
Validation loss: 2.4052781351925328

Epoch: 5| Step: 3
Training loss: 2.1268604212823727
Validation loss: 2.3935580206363367

Epoch: 5| Step: 4
Training loss: 2.473945462377429
Validation loss: 2.422724305699399

Epoch: 5| Step: 5
Training loss: 2.620512987541007
Validation loss: 2.4324931765029167

Epoch: 5| Step: 6
Training loss: 2.2255827237114794
Validation loss: 2.4235436794998066

Epoch: 5| Step: 7
Training loss: 2.411341741941495
Validation loss: 2.4008034564438026

Epoch: 5| Step: 8
Training loss: 2.7470434942200974
Validation loss: 2.4431717217918436

Epoch: 5| Step: 9
Training loss: 1.6529316318540643
Validation loss: 2.41604669706974

Epoch: 5| Step: 10
Training loss: 1.7512960403130136
Validation loss: 2.4162802176847555

Epoch: 162| Step: 0
Training loss: 2.000132079531572
Validation loss: 2.3976814115345286

Epoch: 5| Step: 1
Training loss: 2.8961676169093487
Validation loss: 2.4041889037444264

Epoch: 5| Step: 2
Training loss: 2.3647315249170515
Validation loss: 2.394415694853127

Epoch: 5| Step: 3
Training loss: 1.9952009559705535
Validation loss: 2.4016855187317456

Epoch: 5| Step: 4
Training loss: 2.0419771256842294
Validation loss: 2.403730002197803

Epoch: 5| Step: 5
Training loss: 1.8591180191047476
Validation loss: 2.3938148113421476

Epoch: 5| Step: 6
Training loss: 1.5929499095122508
Validation loss: 2.4227382289866974

Epoch: 5| Step: 7
Training loss: 2.460133836098376
Validation loss: 2.4350463480237132

Epoch: 5| Step: 8
Training loss: 2.6269863424363606
Validation loss: 2.41126826481284

Epoch: 5| Step: 9
Training loss: 2.147169259018436
Validation loss: 2.4165638780498644

Epoch: 5| Step: 10
Training loss: 1.8610677627082706
Validation loss: 2.431657840348075

Epoch: 163| Step: 0
Training loss: 2.2944246053671833
Validation loss: 2.3987088143666973

Epoch: 5| Step: 1
Training loss: 2.745663952463221
Validation loss: 2.396446360040611

Epoch: 5| Step: 2
Training loss: 1.9354281268757458
Validation loss: 2.4054250327114017

Epoch: 5| Step: 3
Training loss: 2.294311961838421
Validation loss: 2.426664625169467

Epoch: 5| Step: 4
Training loss: 1.7574214245960331
Validation loss: 2.4361165687741644

Epoch: 5| Step: 5
Training loss: 1.9855853617178518
Validation loss: 2.4316154169307285

Epoch: 5| Step: 6
Training loss: 2.1299503111080567
Validation loss: 2.430184321338523

Epoch: 5| Step: 7
Training loss: 1.8556155498054574
Validation loss: 2.4249051512223625

Epoch: 5| Step: 8
Training loss: 2.249405464459994
Validation loss: 2.4082491512285014

Epoch: 5| Step: 9
Training loss: 2.42515076630688
Validation loss: 2.4291148673393574

Epoch: 5| Step: 10
Training loss: 2.1824693872985623
Validation loss: 2.415669212748044

Epoch: 164| Step: 0
Training loss: 2.2368499280361704
Validation loss: 2.418137993196504

Epoch: 5| Step: 1
Training loss: 2.2540107583819045
Validation loss: 2.4363864724800477

Epoch: 5| Step: 2
Training loss: 2.26490446011304
Validation loss: 2.425099580709977

Epoch: 5| Step: 3
Training loss: 2.0602165065802174
Validation loss: 2.4159444356340134

Epoch: 5| Step: 4
Training loss: 2.5270698788109915
Validation loss: 2.422131493912837

Epoch: 5| Step: 5
Training loss: 1.8178299113569854
Validation loss: 2.434456219793192

Epoch: 5| Step: 6
Training loss: 2.061061241709629
Validation loss: 2.4440218767499102

Epoch: 5| Step: 7
Training loss: 2.2740785933629257
Validation loss: 2.4096291452078784

Epoch: 5| Step: 8
Training loss: 2.150851582278912
Validation loss: 2.423011697747234

Epoch: 5| Step: 9
Training loss: 2.011698128307534
Validation loss: 2.4407563015695666

Epoch: 5| Step: 10
Training loss: 2.3045774271913544
Validation loss: 2.399149005256144

Epoch: 165| Step: 0
Training loss: 1.5808152788599543
Validation loss: 2.3885732338314942

Epoch: 5| Step: 1
Training loss: 2.0457609216910617
Validation loss: 2.4158071788351223

Epoch: 5| Step: 2
Training loss: 2.1116996106611623
Validation loss: 2.377992698783143

Epoch: 5| Step: 3
Training loss: 2.36239925351362
Validation loss: 2.4181223640998644

Epoch: 5| Step: 4
Training loss: 2.3823272711313455
Validation loss: 2.444959420863665

Epoch: 5| Step: 5
Training loss: 1.8695373433034124
Validation loss: 2.4274618934575543

Epoch: 5| Step: 6
Training loss: 2.477820910043693
Validation loss: 2.4697742520727477

Epoch: 5| Step: 7
Training loss: 2.0223775908179284
Validation loss: 2.3975891983880047

Epoch: 5| Step: 8
Training loss: 2.0604058240008003
Validation loss: 2.4231140925885724

Epoch: 5| Step: 9
Training loss: 1.9750500950314933
Validation loss: 2.4083940925460388

Epoch: 5| Step: 10
Training loss: 3.147436849068154
Validation loss: 2.4281806188854813

Epoch: 166| Step: 0
Training loss: 1.9719047096783135
Validation loss: 2.401237794938039

Epoch: 5| Step: 1
Training loss: 2.264636962124602
Validation loss: 2.403116838965219

Epoch: 5| Step: 2
Training loss: 2.1928721266314923
Validation loss: 2.424437423739176

Epoch: 5| Step: 3
Training loss: 2.0677909033853714
Validation loss: 2.4056835607887113

Epoch: 5| Step: 4
Training loss: 2.229633128005154
Validation loss: 2.3974261299789252

Epoch: 5| Step: 5
Training loss: 2.4190403253948105
Validation loss: 2.4257586981801222

Epoch: 5| Step: 6
Training loss: 2.5597636802196755
Validation loss: 2.450943678708206

Epoch: 5| Step: 7
Training loss: 1.7876165285341201
Validation loss: 2.4373722050803543

Epoch: 5| Step: 8
Training loss: 2.255353704147211
Validation loss: 2.4262919309249247

Epoch: 5| Step: 9
Training loss: 2.180293282720363
Validation loss: 2.3970636386004904

Epoch: 5| Step: 10
Training loss: 1.6650951924190083
Validation loss: 2.4047707276436925

Epoch: 167| Step: 0
Training loss: 2.182732973718523
Validation loss: 2.4000913638923023

Epoch: 5| Step: 1
Training loss: 2.440499636352487
Validation loss: 2.423341552779791

Epoch: 5| Step: 2
Training loss: 1.7634438740143408
Validation loss: 2.448764496239707

Epoch: 5| Step: 3
Training loss: 2.2443474656840485
Validation loss: 2.452326244106249

Epoch: 5| Step: 4
Training loss: 2.499293990581136
Validation loss: 2.426676889422476

Epoch: 5| Step: 5
Training loss: 1.7970352764795992
Validation loss: 2.447989605454284

Epoch: 5| Step: 6
Training loss: 2.3067509094282794
Validation loss: 2.4342439989907727

Epoch: 5| Step: 7
Training loss: 2.7430932269078223
Validation loss: 2.412272987564367

Epoch: 5| Step: 8
Training loss: 1.7273956636092398
Validation loss: 2.412379610812245

Epoch: 5| Step: 9
Training loss: 2.1872254335569723
Validation loss: 2.400366135411085

Epoch: 5| Step: 10
Training loss: 1.8681592766739863
Validation loss: 2.4195565952413727

Epoch: 168| Step: 0
Training loss: 2.0800894723502106
Validation loss: 2.393676112632091

Epoch: 5| Step: 1
Training loss: 2.1481906818451675
Validation loss: 2.436874244117799

Epoch: 5| Step: 2
Training loss: 1.995252577584641
Validation loss: 2.440442140996343

Epoch: 5| Step: 3
Training loss: 1.8578126899327725
Validation loss: 2.4021049935114474

Epoch: 5| Step: 4
Training loss: 1.8397917851522283
Validation loss: 2.3974651869535353

Epoch: 5| Step: 5
Training loss: 2.4730365093172435
Validation loss: 2.429717198614313

Epoch: 5| Step: 6
Training loss: 2.534704511978312
Validation loss: 2.406465043216824

Epoch: 5| Step: 7
Training loss: 1.784651870759305
Validation loss: 2.4058005519550103

Epoch: 5| Step: 8
Training loss: 1.8468915393172685
Validation loss: 2.4376448048463737

Epoch: 5| Step: 9
Training loss: 2.5683960422465772
Validation loss: 2.387765378226189

Epoch: 5| Step: 10
Training loss: 2.57433007423596
Validation loss: 2.4378371466998896

Epoch: 169| Step: 0
Training loss: 2.2664831180680136
Validation loss: 2.4435532027090545

Epoch: 5| Step: 1
Training loss: 1.7903428472875635
Validation loss: 2.40623838488201

Epoch: 5| Step: 2
Training loss: 1.8427271187706902
Validation loss: 2.4689916739314883

Epoch: 5| Step: 3
Training loss: 2.140475191317857
Validation loss: 2.4127840381046406

Epoch: 5| Step: 4
Training loss: 2.47091666644504
Validation loss: 2.4255395269857445

Epoch: 5| Step: 5
Training loss: 2.08126101104298
Validation loss: 2.40082958066765

Epoch: 5| Step: 6
Training loss: 2.1111991624148936
Validation loss: 2.4297160031642595

Epoch: 5| Step: 7
Training loss: 2.5079967395450993
Validation loss: 2.4530389772120906

Epoch: 5| Step: 8
Training loss: 2.451961751779571
Validation loss: 2.3946436649352614

Epoch: 5| Step: 9
Training loss: 2.1322470114435754
Validation loss: 2.4286999195804784

Epoch: 5| Step: 10
Training loss: 1.6775701617876781
Validation loss: 2.3817187513794917

Epoch: 170| Step: 0
Training loss: 2.340651332977028
Validation loss: 2.420993979975782

Epoch: 5| Step: 1
Training loss: 1.9719042260472188
Validation loss: 2.4417287715394167

Epoch: 5| Step: 2
Training loss: 2.3579302273652636
Validation loss: 2.437783974890768

Epoch: 5| Step: 3
Training loss: 1.9395892046529843
Validation loss: 2.441775058248712

Epoch: 5| Step: 4
Training loss: 1.9688738223904199
Validation loss: 2.4289279775799777

Epoch: 5| Step: 5
Training loss: 2.1210571061090007
Validation loss: 2.427684887016261

Epoch: 5| Step: 6
Training loss: 2.17969482858171
Validation loss: 2.4077587684633195

Epoch: 5| Step: 7
Training loss: 2.3962573353511347
Validation loss: 2.4174746961306792

Epoch: 5| Step: 8
Training loss: 2.391426999071564
Validation loss: 2.4204927245047756

Epoch: 5| Step: 9
Training loss: 2.075927260622116
Validation loss: 2.405360176262063

Epoch: 5| Step: 10
Training loss: 1.9802416910180918
Validation loss: 2.4256714660332084

Epoch: 171| Step: 0
Training loss: 1.647490098081247
Validation loss: 2.411911538689492

Epoch: 5| Step: 1
Training loss: 2.4096750431285465
Validation loss: 2.444563593361895

Epoch: 5| Step: 2
Training loss: 1.6565301046494336
Validation loss: 2.4432122037749315

Epoch: 5| Step: 3
Training loss: 2.382694429067557
Validation loss: 2.3731289181844697

Epoch: 5| Step: 4
Training loss: 2.428935630721254
Validation loss: 2.4268701554700267

Epoch: 5| Step: 5
Training loss: 2.5464733719825756
Validation loss: 2.4347926202789196

Epoch: 5| Step: 6
Training loss: 1.788871255173001
Validation loss: 2.4318960140789025

Epoch: 5| Step: 7
Training loss: 2.1922129405932025
Validation loss: 2.412414320003898

Epoch: 5| Step: 8
Training loss: 2.0559673312148483
Validation loss: 2.407318566224489

Epoch: 5| Step: 9
Training loss: 2.3067262070014687
Validation loss: 2.386947661406752

Epoch: 5| Step: 10
Training loss: 1.9448825100517702
Validation loss: 2.422447362953756

Epoch: 172| Step: 0
Training loss: 2.0571592135384638
Validation loss: 2.4119369154900916

Epoch: 5| Step: 1
Training loss: 2.1833360550647494
Validation loss: 2.446513994998358

Epoch: 5| Step: 2
Training loss: 1.9944820578784905
Validation loss: 2.408842827333181

Epoch: 5| Step: 3
Training loss: 2.1629220319179345
Validation loss: 2.3740928743921548

Epoch: 5| Step: 4
Training loss: 2.1882891730070106
Validation loss: 2.4139010361479962

Epoch: 5| Step: 5
Training loss: 1.8701242631026396
Validation loss: 2.423191754465651

Epoch: 5| Step: 6
Training loss: 2.090031068196794
Validation loss: 2.425841010938861

Epoch: 5| Step: 7
Training loss: 1.954338673204291
Validation loss: 2.4323496543628123

Epoch: 5| Step: 8
Training loss: 1.9694022657322299
Validation loss: 2.3865387666788314

Epoch: 5| Step: 9
Training loss: 2.8452302203361097
Validation loss: 2.456432744181168

Epoch: 5| Step: 10
Training loss: 2.16413025457308
Validation loss: 2.4202814549859926

Epoch: 173| Step: 0
Training loss: 1.7571643906114573
Validation loss: 2.433703478390294

Epoch: 5| Step: 1
Training loss: 1.9835247711411907
Validation loss: 2.4176061103421356

Epoch: 5| Step: 2
Training loss: 1.9186113761007078
Validation loss: 2.399024109489913

Epoch: 5| Step: 3
Training loss: 2.2668378017372053
Validation loss: 2.445821023103566

Epoch: 5| Step: 4
Training loss: 1.6194384845051804
Validation loss: 2.4374571944507153

Epoch: 5| Step: 5
Training loss: 2.519163308889574
Validation loss: 2.4371929285546146

Epoch: 5| Step: 6
Training loss: 2.016819208329218
Validation loss: 2.4304612463620905

Epoch: 5| Step: 7
Training loss: 2.2907201604085126
Validation loss: 2.4620529436117926

Epoch: 5| Step: 8
Training loss: 2.3828250071713253
Validation loss: 2.40774372255445

Epoch: 5| Step: 9
Training loss: 2.0620692410170265
Validation loss: 2.438881372490079

Epoch: 5| Step: 10
Training loss: 2.846044432228226
Validation loss: 2.459272036136786

Epoch: 174| Step: 0
Training loss: 2.3100317076781685
Validation loss: 2.4338662297135385

Epoch: 5| Step: 1
Training loss: 2.045964045599289
Validation loss: 2.462853570506011

Epoch: 5| Step: 2
Training loss: 2.3504731452736984
Validation loss: 2.410873227995357

Epoch: 5| Step: 3
Training loss: 1.6133184913604102
Validation loss: 2.40930193614223

Epoch: 5| Step: 4
Training loss: 1.5812939845062939
Validation loss: 2.4190037649695677

Epoch: 5| Step: 5
Training loss: 1.560287511324825
Validation loss: 2.412583589962671

Epoch: 5| Step: 6
Training loss: 2.219188378237744
Validation loss: 2.434545411711626

Epoch: 5| Step: 7
Training loss: 2.193816846388793
Validation loss: 2.389732890891718

Epoch: 5| Step: 8
Training loss: 2.862022966507332
Validation loss: 2.451710261887419

Epoch: 5| Step: 9
Training loss: 2.211118010036796
Validation loss: 2.4005896360985184

Epoch: 5| Step: 10
Training loss: 2.12253472433453
Validation loss: 2.4019384026677204

Epoch: 175| Step: 0
Training loss: 2.2183244323934033
Validation loss: 2.4138901460452207

Epoch: 5| Step: 1
Training loss: 2.112948971501833
Validation loss: 2.431704499032207

Epoch: 5| Step: 2
Training loss: 2.572123252039381
Validation loss: 2.401582468316384

Epoch: 5| Step: 3
Training loss: 1.4167907697884208
Validation loss: 2.4105968135502343

Epoch: 5| Step: 4
Training loss: 2.364227256908343
Validation loss: 2.4339104561232325

Epoch: 5| Step: 5
Training loss: 1.8892152432642715
Validation loss: 2.4331709358611224

Epoch: 5| Step: 6
Training loss: 2.0562140881959157
Validation loss: 2.3822385917526616

Epoch: 5| Step: 7
Training loss: 2.5797596690886437
Validation loss: 2.4001371333806896

Epoch: 5| Step: 8
Training loss: 1.9337823332713882
Validation loss: 2.419650954784896

Epoch: 5| Step: 9
Training loss: 2.0987849262505422
Validation loss: 2.418698324253658

Epoch: 5| Step: 10
Training loss: 1.9475440894683165
Validation loss: 2.405062553614388

Epoch: 176| Step: 0
Training loss: 1.9348709358129768
Validation loss: 2.429737858810442

Epoch: 5| Step: 1
Training loss: 2.3766818867428356
Validation loss: 2.4451880215130584

Epoch: 5| Step: 2
Training loss: 2.1427238922469134
Validation loss: 2.428949195435374

Epoch: 5| Step: 3
Training loss: 1.8776006464896533
Validation loss: 2.4423224591312445

Epoch: 5| Step: 4
Training loss: 2.091705006809099
Validation loss: 2.4295945790930635

Epoch: 5| Step: 5
Training loss: 2.396663743000962
Validation loss: 2.4440596573015503

Epoch: 5| Step: 6
Training loss: 2.5239500109925914
Validation loss: 2.423361881202655

Epoch: 5| Step: 7
Training loss: 1.910416349399198
Validation loss: 2.425811705562332

Epoch: 5| Step: 8
Training loss: 2.348872372787636
Validation loss: 2.435642856998293

Epoch: 5| Step: 9
Training loss: 1.5077171493187485
Validation loss: 2.4294320919146113

Epoch: 5| Step: 10
Training loss: 2.305681744790043
Validation loss: 2.463550567524154

Epoch: 177| Step: 0
Training loss: 2.038605152740598
Validation loss: 2.4209463614320623

Epoch: 5| Step: 1
Training loss: 2.078353525087621
Validation loss: 2.414365275876972

Epoch: 5| Step: 2
Training loss: 2.1864139585700557
Validation loss: 2.4365179956626797

Epoch: 5| Step: 3
Training loss: 1.7488908658884248
Validation loss: 2.440381174459222

Epoch: 5| Step: 4
Training loss: 2.446157291236448
Validation loss: 2.445329550951945

Epoch: 5| Step: 5
Training loss: 1.6648511137278124
Validation loss: 2.392076448871761

Epoch: 5| Step: 6
Training loss: 2.1910464285488986
Validation loss: 2.4305592823927786

Epoch: 5| Step: 7
Training loss: 2.2527624761853806
Validation loss: 2.4247161586213153

Epoch: 5| Step: 8
Training loss: 2.4429218928201872
Validation loss: 2.4556201487862834

Epoch: 5| Step: 9
Training loss: 2.0485494040410934
Validation loss: 2.4516344570746305

Epoch: 5| Step: 10
Training loss: 2.2933227681685464
Validation loss: 2.4082300450639154

Epoch: 178| Step: 0
Training loss: 2.04233484298495
Validation loss: 2.3967128221925

Epoch: 5| Step: 1
Training loss: 2.313819302716831
Validation loss: 2.3745475655453774

Epoch: 5| Step: 2
Training loss: 2.307653245228499
Validation loss: 2.44509570015693

Epoch: 5| Step: 3
Training loss: 2.03015952549907
Validation loss: 2.4159123912988085

Epoch: 5| Step: 4
Training loss: 1.9939614569479078
Validation loss: 2.4215870421746613

Epoch: 5| Step: 5
Training loss: 1.875942247782858
Validation loss: 2.4399036034327297

Epoch: 5| Step: 6
Training loss: 2.523629007070161
Validation loss: 2.4317104993265195

Epoch: 5| Step: 7
Training loss: 1.9772423340266212
Validation loss: 2.4575171679195855

Epoch: 5| Step: 8
Training loss: 1.6152109792507185
Validation loss: 2.437608519253267

Epoch: 5| Step: 9
Training loss: 2.276984420354498
Validation loss: 2.391993604408667

Epoch: 5| Step: 10
Training loss: 2.3176643853182046
Validation loss: 2.4477974465757524

Epoch: 179| Step: 0
Training loss: 2.1190076373162023
Validation loss: 2.420604472844487

Epoch: 5| Step: 1
Training loss: 1.8240230871964676
Validation loss: 2.4178145631141468

Epoch: 5| Step: 2
Training loss: 2.4716476625246515
Validation loss: 2.366589052827499

Epoch: 5| Step: 3
Training loss: 2.2319617410477663
Validation loss: 2.4182493860157193

Epoch: 5| Step: 4
Training loss: 1.9355181740981933
Validation loss: 2.441827937372737

Epoch: 5| Step: 5
Training loss: 2.3546713116550677
Validation loss: 2.3748283842351583

Epoch: 5| Step: 6
Training loss: 1.8673103962440258
Validation loss: 2.44795133050809

Epoch: 5| Step: 7
Training loss: 2.318113164514117
Validation loss: 2.4337524537184936

Epoch: 5| Step: 8
Training loss: 2.0721871579600974
Validation loss: 2.433975760970533

Epoch: 5| Step: 9
Training loss: 1.647031573212417
Validation loss: 2.384511603353299

Epoch: 5| Step: 10
Training loss: 2.3598934387136508
Validation loss: 2.418200734383586

Epoch: 180| Step: 0
Training loss: 2.274531884292584
Validation loss: 2.4330002442829035

Epoch: 5| Step: 1
Training loss: 2.149959399704943
Validation loss: 2.4219941500577553

Epoch: 5| Step: 2
Training loss: 1.6655497464183378
Validation loss: 2.4198024565718925

Epoch: 5| Step: 3
Training loss: 2.311464026090108
Validation loss: 2.4195035641941947

Epoch: 5| Step: 4
Training loss: 2.035767095640877
Validation loss: 2.3997936689478374

Epoch: 5| Step: 5
Training loss: 2.306888163282799
Validation loss: 2.436358901775333

Epoch: 5| Step: 6
Training loss: 1.9342415389208352
Validation loss: 2.376897247307754

Epoch: 5| Step: 7
Training loss: 2.495620133385426
Validation loss: 2.3838098895305646

Epoch: 5| Step: 8
Training loss: 1.5861064651756736
Validation loss: 2.409269722589295

Epoch: 5| Step: 9
Training loss: 2.117091778495155
Validation loss: 2.432590267523001

Epoch: 5| Step: 10
Training loss: 2.0592315670187373
Validation loss: 2.4302812946786587

Epoch: 181| Step: 0
Training loss: 2.0843789210704426
Validation loss: 2.431688241286081

Epoch: 5| Step: 1
Training loss: 1.7149194513873542
Validation loss: 2.4364678143423246

Epoch: 5| Step: 2
Training loss: 2.199801162924183
Validation loss: 2.422330156070416

Epoch: 5| Step: 3
Training loss: 2.4310210760058957
Validation loss: 2.40276059158321

Epoch: 5| Step: 4
Training loss: 2.5034170639962037
Validation loss: 2.4204595668411986

Epoch: 5| Step: 5
Training loss: 1.942203043524858
Validation loss: 2.423119544426508

Epoch: 5| Step: 6
Training loss: 1.7380822228493709
Validation loss: 2.432426601899824

Epoch: 5| Step: 7
Training loss: 2.2636414362100936
Validation loss: 2.414563568359088

Epoch: 5| Step: 8
Training loss: 2.1357001015729344
Validation loss: 2.4487354463566287

Epoch: 5| Step: 9
Training loss: 2.0744752886907745
Validation loss: 2.4176956184977043

Epoch: 5| Step: 10
Training loss: 2.192993133485466
Validation loss: 2.41613574520301

Epoch: 182| Step: 0
Training loss: 2.4744794972576822
Validation loss: 2.4134227365442995

Epoch: 5| Step: 1
Training loss: 1.7676619536190563
Validation loss: 2.4489736131927584

Epoch: 5| Step: 2
Training loss: 2.4524173566326923
Validation loss: 2.4529203940030273

Epoch: 5| Step: 3
Training loss: 2.019792019740902
Validation loss: 2.4271055542084765

Epoch: 5| Step: 4
Training loss: 1.9579439452450005
Validation loss: 2.4129001840435493

Epoch: 5| Step: 5
Training loss: 1.8815844951333038
Validation loss: 2.4274942410333797

Epoch: 5| Step: 6
Training loss: 1.7220614351396595
Validation loss: 2.4429983111270466

Epoch: 5| Step: 7
Training loss: 2.1399006975610724
Validation loss: 2.433588869415895

Epoch: 5| Step: 8
Training loss: 1.6611323819168313
Validation loss: 2.440641076328054

Epoch: 5| Step: 9
Training loss: 2.4611546980665278
Validation loss: 2.4018561470561743

Epoch: 5| Step: 10
Training loss: 2.0915636632515113
Validation loss: 2.430029465266174

Epoch: 183| Step: 0
Training loss: 1.899845558715933
Validation loss: 2.417083060092518

Epoch: 5| Step: 1
Training loss: 1.8849301913663707
Validation loss: 2.4362695436946984

Epoch: 5| Step: 2
Training loss: 2.5095938657180388
Validation loss: 2.3828847910813256

Epoch: 5| Step: 3
Training loss: 1.9696719115226113
Validation loss: 2.410715960603883

Epoch: 5| Step: 4
Training loss: 2.1542985350670736
Validation loss: 2.4208723529954392

Epoch: 5| Step: 5
Training loss: 2.5472684217021433
Validation loss: 2.3949529067169024

Epoch: 5| Step: 6
Training loss: 2.0345579941068963
Validation loss: 2.4455921283567776

Epoch: 5| Step: 7
Training loss: 2.3906603043885184
Validation loss: 2.4407135956695107

Epoch: 5| Step: 8
Training loss: 1.6649550788707763
Validation loss: 2.4275644913295324

Epoch: 5| Step: 9
Training loss: 1.5716125269141303
Validation loss: 2.4096031674548524

Epoch: 5| Step: 10
Training loss: 2.3990160713309425
Validation loss: 2.4109469611983845

Epoch: 184| Step: 0
Training loss: 2.2008324998678033
Validation loss: 2.4309903883191057

Epoch: 5| Step: 1
Training loss: 1.6325146709209368
Validation loss: 2.4101731007966953

Epoch: 5| Step: 2
Training loss: 2.0990962763311094
Validation loss: 2.3997438013322157

Epoch: 5| Step: 3
Training loss: 2.0532477959036157
Validation loss: 2.4089203916501902

Epoch: 5| Step: 4
Training loss: 2.351276671822624
Validation loss: 2.446045135027419

Epoch: 5| Step: 5
Training loss: 2.3258371056207534
Validation loss: 2.436750745403307

Epoch: 5| Step: 6
Training loss: 1.9407439608516193
Validation loss: 2.437902487272949

Epoch: 5| Step: 7
Training loss: 1.9074389392683986
Validation loss: 2.4140947090673968

Epoch: 5| Step: 8
Training loss: 2.139120422426149
Validation loss: 2.42386424458888

Epoch: 5| Step: 9
Training loss: 2.2374469473745457
Validation loss: 2.4087431166620474

Epoch: 5| Step: 10
Training loss: 2.2651887671018165
Validation loss: 2.443411975634516

Epoch: 185| Step: 0
Training loss: 1.753370989236795
Validation loss: 2.4449957142744165

Epoch: 5| Step: 1
Training loss: 2.501483191162828
Validation loss: 2.420791153750967

Epoch: 5| Step: 2
Training loss: 1.695478580619669
Validation loss: 2.442112326493616

Epoch: 5| Step: 3
Training loss: 2.1353823651295794
Validation loss: 2.4366620866172943

Epoch: 5| Step: 4
Training loss: 2.15755931520756
Validation loss: 2.436374759019774

Epoch: 5| Step: 5
Training loss: 1.8769486791456842
Validation loss: 2.413914716146041

Epoch: 5| Step: 6
Training loss: 2.4393067144189304
Validation loss: 2.415274574126875

Epoch: 5| Step: 7
Training loss: 2.3850429414286225
Validation loss: 2.386921762235745

Epoch: 5| Step: 8
Training loss: 2.25789116851081
Validation loss: 2.39686034038552

Epoch: 5| Step: 9
Training loss: 1.477910067716797
Validation loss: 2.397980368296306

Epoch: 5| Step: 10
Training loss: 2.0185353167914295
Validation loss: 2.4488283078279327

Epoch: 186| Step: 0
Training loss: 2.036012670691134
Validation loss: 2.4122604013954683

Epoch: 5| Step: 1
Training loss: 2.7439956138008585
Validation loss: 2.422490617072342

Epoch: 5| Step: 2
Training loss: 1.8991356339150343
Validation loss: 2.4084379404726324

Epoch: 5| Step: 3
Training loss: 1.7763506787389143
Validation loss: 2.389423748172267

Epoch: 5| Step: 4
Training loss: 2.433939852526967
Validation loss: 2.3916300629292304

Epoch: 5| Step: 5
Training loss: 1.9501999581348022
Validation loss: 2.418484093172782

Epoch: 5| Step: 6
Training loss: 2.658701584361257
Validation loss: 2.4050049625823338

Epoch: 5| Step: 7
Training loss: 1.5032607241320508
Validation loss: 2.408341253738616

Epoch: 5| Step: 8
Training loss: 1.544003451155724
Validation loss: 2.421778789915553

Epoch: 5| Step: 9
Training loss: 1.9342999026214238
Validation loss: 2.4054685734683154

Epoch: 5| Step: 10
Training loss: 2.118669617514999
Validation loss: 2.4356173640566823

Epoch: 187| Step: 0
Training loss: 1.9324144871040174
Validation loss: 2.3838507932093917

Epoch: 5| Step: 1
Training loss: 2.1249921461969983
Validation loss: 2.4336758093459183

Epoch: 5| Step: 2
Training loss: 1.797458520763513
Validation loss: 2.3894765208960482

Epoch: 5| Step: 3
Training loss: 2.3567036037796765
Validation loss: 2.402007438168569

Epoch: 5| Step: 4
Training loss: 2.1909425078195914
Validation loss: 2.447616867386927

Epoch: 5| Step: 5
Training loss: 1.665687519782435
Validation loss: 2.413032950170151

Epoch: 5| Step: 6
Training loss: 2.2720331527883535
Validation loss: 2.4317896372002163

Epoch: 5| Step: 7
Training loss: 2.3393446146331636
Validation loss: 2.426440591712451

Epoch: 5| Step: 8
Training loss: 2.050520816796842
Validation loss: 2.447955364548909

Epoch: 5| Step: 9
Training loss: 2.06555908374965
Validation loss: 2.424914360585112

Epoch: 5| Step: 10
Training loss: 2.2396324566325614
Validation loss: 2.409215578716979

Epoch: 188| Step: 0
Training loss: 2.014364868858206
Validation loss: 2.401807750417202

Epoch: 5| Step: 1
Training loss: 1.8159256494148874
Validation loss: 2.4088942295901288

Epoch: 5| Step: 2
Training loss: 2.9187755771472013
Validation loss: 2.4285861232289214

Epoch: 5| Step: 3
Training loss: 2.1095290516301572
Validation loss: 2.4395031561117144

Epoch: 5| Step: 4
Training loss: 2.175749910358338
Validation loss: 2.437039180556203

Epoch: 5| Step: 5
Training loss: 1.975995792975175
Validation loss: 2.4192887124558036

Epoch: 5| Step: 6
Training loss: 1.8279652321929434
Validation loss: 2.408066635815548

Epoch: 5| Step: 7
Training loss: 1.7728958310951122
Validation loss: 2.431322570893616

Epoch: 5| Step: 8
Training loss: 1.790721473957659
Validation loss: 2.41071380820972

Epoch: 5| Step: 9
Training loss: 2.1042507519933085
Validation loss: 2.418095618836297

Epoch: 5| Step: 10
Training loss: 2.16285997161997
Validation loss: 2.383317250209623

Epoch: 189| Step: 0
Training loss: 1.4107228670324867
Validation loss: 2.442521280151975

Epoch: 5| Step: 1
Training loss: 2.050088936341939
Validation loss: 2.4095478117877653

Epoch: 5| Step: 2
Training loss: 2.627980765105391
Validation loss: 2.4162055570348753

Epoch: 5| Step: 3
Training loss: 1.6480608324471184
Validation loss: 2.3953339190404703

Epoch: 5| Step: 4
Training loss: 2.420469011303424
Validation loss: 2.4263049472499074

Epoch: 5| Step: 5
Training loss: 1.6153447806508605
Validation loss: 2.4412613206730747

Epoch: 5| Step: 6
Training loss: 2.0047895778674327
Validation loss: 2.411662786202714

Epoch: 5| Step: 7
Training loss: 2.0232369459761723
Validation loss: 2.4214961649781572

Epoch: 5| Step: 8
Training loss: 2.343488551498261
Validation loss: 2.3763155486090177

Epoch: 5| Step: 9
Training loss: 1.6565325513981162
Validation loss: 2.430135007728847

Epoch: 5| Step: 10
Training loss: 2.540020946656611
Validation loss: 2.4442858511305317

Epoch: 190| Step: 0
Training loss: 2.132782652929034
Validation loss: 2.4559230894688713

Epoch: 5| Step: 1
Training loss: 2.631722969079425
Validation loss: 2.3875648493593546

Epoch: 5| Step: 2
Training loss: 2.010408615596904
Validation loss: 2.4292710137915363

Epoch: 5| Step: 3
Training loss: 1.9675603027021273
Validation loss: 2.390503678342188

Epoch: 5| Step: 4
Training loss: 1.9602321860914007
Validation loss: 2.4135239385315383

Epoch: 5| Step: 5
Training loss: 1.7413120550639285
Validation loss: 2.4341213860709408

Epoch: 5| Step: 6
Training loss: 1.7949448543567808
Validation loss: 2.3904761371863157

Epoch: 5| Step: 7
Training loss: 2.319508628439391
Validation loss: 2.406901766303819

Epoch: 5| Step: 8
Training loss: 1.8444953963443824
Validation loss: 2.452038305517392

Epoch: 5| Step: 9
Training loss: 2.153835769513008
Validation loss: 2.436062444900163

Epoch: 5| Step: 10
Training loss: 2.0417964919976446
Validation loss: 2.364723163124191

Epoch: 191| Step: 0
Training loss: 1.8734799899642993
Validation loss: 2.422463953636894

Epoch: 5| Step: 1
Training loss: 1.9544570652853814
Validation loss: 2.4098924992556

Epoch: 5| Step: 2
Training loss: 2.2923691337614813
Validation loss: 2.451721152349613

Epoch: 5| Step: 3
Training loss: 1.7885696198625356
Validation loss: 2.3930932025252094

Epoch: 5| Step: 4
Training loss: 1.9880548434454406
Validation loss: 2.42918830805234

Epoch: 5| Step: 5
Training loss: 2.5589081316277924
Validation loss: 2.4455795784372376

Epoch: 5| Step: 6
Training loss: 2.031987687186235
Validation loss: 2.438166074825437

Epoch: 5| Step: 7
Training loss: 2.3846120574019247
Validation loss: 2.4202931780126513

Epoch: 5| Step: 8
Training loss: 1.9528590517177256
Validation loss: 2.4726590172075436

Epoch: 5| Step: 9
Training loss: 1.9834355811468458
Validation loss: 2.4357167155537924

Epoch: 5| Step: 10
Training loss: 1.7027044214430636
Validation loss: 2.403013477868504

Epoch: 192| Step: 0
Training loss: 2.4610798143684107
Validation loss: 2.422743927162597

Epoch: 5| Step: 1
Training loss: 1.5646383530669512
Validation loss: 2.440370031955062

Epoch: 5| Step: 2
Training loss: 1.9649646031732055
Validation loss: 2.4315593024717357

Epoch: 5| Step: 3
Training loss: 1.79954125333594
Validation loss: 2.4293496021873118

Epoch: 5| Step: 4
Training loss: 2.5779616795452203
Validation loss: 2.398953603167467

Epoch: 5| Step: 5
Training loss: 1.651999579764398
Validation loss: 2.4329880414083975

Epoch: 5| Step: 6
Training loss: 1.9604546913840177
Validation loss: 2.3805780524605744

Epoch: 5| Step: 7
Training loss: 2.2500434447438704
Validation loss: 2.414831015608477

Epoch: 5| Step: 8
Training loss: 2.303266598037874
Validation loss: 2.434762489747991

Epoch: 5| Step: 9
Training loss: 1.7250469339592422
Validation loss: 2.4333819860122525

Epoch: 5| Step: 10
Training loss: 1.9879316760858257
Validation loss: 2.400836362347954

Epoch: 193| Step: 0
Training loss: 1.6371415714200852
Validation loss: 2.4369743565002007

Epoch: 5| Step: 1
Training loss: 1.7507888514614587
Validation loss: 2.405148773428706

Epoch: 5| Step: 2
Training loss: 2.703181889106251
Validation loss: 2.4207061826388925

Epoch: 5| Step: 3
Training loss: 1.8155614057161562
Validation loss: 2.407495352983007

Epoch: 5| Step: 4
Training loss: 1.7716572434302444
Validation loss: 2.421248795302375

Epoch: 5| Step: 5
Training loss: 1.641857810277154
Validation loss: 2.4479994390488233

Epoch: 5| Step: 6
Training loss: 2.018134750290676
Validation loss: 2.4192658987754063

Epoch: 5| Step: 7
Training loss: 2.547989396694524
Validation loss: 2.4657218911676475

Epoch: 5| Step: 8
Training loss: 2.368119361691522
Validation loss: 2.442853658857183

Epoch: 5| Step: 9
Training loss: 1.8155052001088607
Validation loss: 2.4247831923218315

Epoch: 5| Step: 10
Training loss: 2.023108613964585
Validation loss: 2.411317070138282

Epoch: 194| Step: 0
Training loss: 1.9744165403724312
Validation loss: 2.4234009729491484

Epoch: 5| Step: 1
Training loss: 2.3911793383992452
Validation loss: 2.4078166694735708

Epoch: 5| Step: 2
Training loss: 1.8875407763996546
Validation loss: 2.417914106446798

Epoch: 5| Step: 3
Training loss: 2.245008654333481
Validation loss: 2.42354170668959

Epoch: 5| Step: 4
Training loss: 2.465146972576895
Validation loss: 2.3972724248470882

Epoch: 5| Step: 5
Training loss: 1.9177070019531048
Validation loss: 2.4031706295271076

Epoch: 5| Step: 6
Training loss: 2.2253669607609408
Validation loss: 2.4183663899679395

Epoch: 5| Step: 7
Training loss: 2.177032932507267
Validation loss: 2.397664582007042

Epoch: 5| Step: 8
Training loss: 1.4228977256098825
Validation loss: 2.3917315632037366

Epoch: 5| Step: 9
Training loss: 1.8661002980187387
Validation loss: 2.45970285504371

Epoch: 5| Step: 10
Training loss: 1.3295299503931115
Validation loss: 2.4160688854004677

Epoch: 195| Step: 0
Training loss: 1.8632729328217805
Validation loss: 2.416505876849148

Epoch: 5| Step: 1
Training loss: 1.7841571040151878
Validation loss: 2.4103791439003808

Epoch: 5| Step: 2
Training loss: 2.1462859876900353
Validation loss: 2.392720534519133

Epoch: 5| Step: 3
Training loss: 1.9874378506522106
Validation loss: 2.386934945995009

Epoch: 5| Step: 4
Training loss: 1.8815791098826609
Validation loss: 2.4615166907902197

Epoch: 5| Step: 5
Training loss: 1.9476905596328087
Validation loss: 2.4259850269771257

Epoch: 5| Step: 6
Training loss: 2.0185355530207025
Validation loss: 2.4153501561876665

Epoch: 5| Step: 7
Training loss: 1.5702248923692321
Validation loss: 2.4248915897879324

Epoch: 5| Step: 8
Training loss: 1.9872551389323754
Validation loss: 2.406553608587928

Epoch: 5| Step: 9
Training loss: 2.4533253970570668
Validation loss: 2.4240144814957203

Epoch: 5| Step: 10
Training loss: 2.722055639848882
Validation loss: 2.4104012275251194

Epoch: 196| Step: 0
Training loss: 1.846178233844505
Validation loss: 2.413272503135098

Epoch: 5| Step: 1
Training loss: 1.8330390939700612
Validation loss: 2.422553535224698

Epoch: 5| Step: 2
Training loss: 2.3291003341191727
Validation loss: 2.415738566878539

Epoch: 5| Step: 3
Training loss: 2.1390177686540897
Validation loss: 2.428086217056156

Epoch: 5| Step: 4
Training loss: 2.0076064660900967
Validation loss: 2.423728467575529

Epoch: 5| Step: 5
Training loss: 2.052291110859017
Validation loss: 2.393672032097095

Epoch: 5| Step: 6
Training loss: 1.5798757680508824
Validation loss: 2.4018679488057924

Epoch: 5| Step: 7
Training loss: 2.2148596815178783
Validation loss: 2.418826846375551

Epoch: 5| Step: 8
Training loss: 2.3676349481392074
Validation loss: 2.418924389491923

Epoch: 5| Step: 9
Training loss: 2.255710983349878
Validation loss: 2.411490829490853

Epoch: 5| Step: 10
Training loss: 1.333620437864552
Validation loss: 2.392178381917641

Epoch: 197| Step: 0
Training loss: 2.4819551594915663
Validation loss: 2.4663455126599043

Epoch: 5| Step: 1
Training loss: 1.9501313116415144
Validation loss: 2.4180624102789494

Epoch: 5| Step: 2
Training loss: 1.2021316787456453
Validation loss: 2.4222499571710703

Epoch: 5| Step: 3
Training loss: 1.8082669253248749
Validation loss: 2.3899813547023667

Epoch: 5| Step: 4
Training loss: 2.62595268400379
Validation loss: 2.403073834879584

Epoch: 5| Step: 5
Training loss: 2.3541382531896073
Validation loss: 2.4136661908184256

Epoch: 5| Step: 6
Training loss: 2.1065398200794405
Validation loss: 2.4275294342880667

Epoch: 5| Step: 7
Training loss: 1.6203165788148548
Validation loss: 2.40947096245053

Epoch: 5| Step: 8
Training loss: 1.509462550686518
Validation loss: 2.4421808708959154

Epoch: 5| Step: 9
Training loss: 2.0335664891670095
Validation loss: 2.4210743046611993

Epoch: 5| Step: 10
Training loss: 1.8448438470814097
Validation loss: 2.4258287815618824

Epoch: 198| Step: 0
Training loss: 2.3535582732455858
Validation loss: 2.418161614759116

Epoch: 5| Step: 1
Training loss: 1.5132599300838288
Validation loss: 2.4177638329584057

Epoch: 5| Step: 2
Training loss: 2.19878311314461
Validation loss: 2.3987552985021394

Epoch: 5| Step: 3
Training loss: 2.30067824439149
Validation loss: 2.423804913517151

Epoch: 5| Step: 4
Training loss: 1.831815336798746
Validation loss: 2.423121346185893

Epoch: 5| Step: 5
Training loss: 1.57624364828937
Validation loss: 2.436520958582573

Epoch: 5| Step: 6
Training loss: 1.9886446697507516
Validation loss: 2.3985060045766384

Epoch: 5| Step: 7
Training loss: 2.048491793101405
Validation loss: 2.426037744100032

Epoch: 5| Step: 8
Training loss: 2.6377259541849876
Validation loss: 2.4277382103188594

Epoch: 5| Step: 9
Training loss: 1.5761547820382802
Validation loss: 2.3991589022615147

Epoch: 5| Step: 10
Training loss: 2.0212096686459042
Validation loss: 2.457291513902805

Epoch: 199| Step: 0
Training loss: 1.932789151567999
Validation loss: 2.417211125081514

Epoch: 5| Step: 1
Training loss: 1.7182419459513436
Validation loss: 2.41507626783962

Epoch: 5| Step: 2
Training loss: 2.0191914551090133
Validation loss: 2.4407935092971167

Epoch: 5| Step: 3
Training loss: 1.9465246751790568
Validation loss: 2.3978844439525706

Epoch: 5| Step: 4
Training loss: 2.5856461375227524
Validation loss: 2.4347560099925607

Epoch: 5| Step: 5
Training loss: 2.020340128486223
Validation loss: 2.4527922342496917

Epoch: 5| Step: 6
Training loss: 2.3019022000083584
Validation loss: 2.4404082254228165

Epoch: 5| Step: 7
Training loss: 2.0250641753777074
Validation loss: 2.388664011288767

Epoch: 5| Step: 8
Training loss: 2.119494318121844
Validation loss: 2.375370139276459

Epoch: 5| Step: 9
Training loss: 1.5711940739040144
Validation loss: 2.3939648768931985

Epoch: 5| Step: 10
Training loss: 1.9302582919769384
Validation loss: 2.419794739583213

Epoch: 200| Step: 0
Training loss: 2.2017058001651715
Validation loss: 2.355432468636151

Epoch: 5| Step: 1
Training loss: 2.263120542962743
Validation loss: 2.4064673379018484

Epoch: 5| Step: 2
Training loss: 1.630879695560154
Validation loss: 2.3894322547373386

Epoch: 5| Step: 3
Training loss: 1.7034047448230467
Validation loss: 2.400096210051909

Epoch: 5| Step: 4
Training loss: 1.7502815837475998
Validation loss: 2.4077772214272044

Epoch: 5| Step: 5
Training loss: 1.8948872339923342
Validation loss: 2.411343061321947

Epoch: 5| Step: 6
Training loss: 2.5872506210380957
Validation loss: 2.431158358060998

Epoch: 5| Step: 7
Training loss: 2.302883670746043
Validation loss: 2.4187040902428656

Epoch: 5| Step: 8
Training loss: 1.7714782512857568
Validation loss: 2.4224408862385536

Epoch: 5| Step: 9
Training loss: 1.8763033469568922
Validation loss: 2.445050458756699

Epoch: 5| Step: 10
Training loss: 2.0047213140476834
Validation loss: 2.4218826902481125

Epoch: 201| Step: 0
Training loss: 1.6674272073530794
Validation loss: 2.3954557585877376

Epoch: 5| Step: 1
Training loss: 1.7411301487672566
Validation loss: 2.4065510119794844

Epoch: 5| Step: 2
Training loss: 1.6958496367899443
Validation loss: 2.3918382243185987

Epoch: 5| Step: 3
Training loss: 1.5479737050092766
Validation loss: 2.4552548726409196

Epoch: 5| Step: 4
Training loss: 1.9408817311868738
Validation loss: 2.4018437058978326

Epoch: 5| Step: 5
Training loss: 2.369258767599926
Validation loss: 2.431847095714028

Epoch: 5| Step: 6
Training loss: 2.6207519854205383
Validation loss: 2.3911741675398472

Epoch: 5| Step: 7
Training loss: 2.044150949514403
Validation loss: 2.4383359127283226

Epoch: 5| Step: 8
Training loss: 2.5354516279014234
Validation loss: 2.4207231548600947

Epoch: 5| Step: 9
Training loss: 1.7789686216360723
Validation loss: 2.4273450343210747

Epoch: 5| Step: 10
Training loss: 1.9082936447991656
Validation loss: 2.4174244795405904

Epoch: 202| Step: 0
Training loss: 2.4744812315751115
Validation loss: 2.421468758492556

Epoch: 5| Step: 1
Training loss: 1.6580324478287445
Validation loss: 2.4310893088474193

Epoch: 5| Step: 2
Training loss: 2.1760650394901595
Validation loss: 2.4392017054414272

Epoch: 5| Step: 3
Training loss: 2.468201974811696
Validation loss: 2.4069805232272787

Epoch: 5| Step: 4
Training loss: 2.354524084545191
Validation loss: 2.4162207857963427

Epoch: 5| Step: 5
Training loss: 1.6872042644054337
Validation loss: 2.4022865025138613

Epoch: 5| Step: 6
Training loss: 1.7803155556120722
Validation loss: 2.4388132851223614

Epoch: 5| Step: 7
Training loss: 2.0627791475911956
Validation loss: 2.4566827644916804

Epoch: 5| Step: 8
Training loss: 1.4907420082473017
Validation loss: 2.426213683578624

Epoch: 5| Step: 9
Training loss: 1.5918122273272315
Validation loss: 2.405305778116095

Epoch: 5| Step: 10
Training loss: 2.153288645954799
Validation loss: 2.4420293118764387

Epoch: 203| Step: 0
Training loss: 2.254132713960022
Validation loss: 2.406426303298061

Epoch: 5| Step: 1
Training loss: 1.5694356719290423
Validation loss: 2.4028845532408356

Epoch: 5| Step: 2
Training loss: 2.479874571274061
Validation loss: 2.415386551148815

Epoch: 5| Step: 3
Training loss: 1.8656461091500691
Validation loss: 2.430746478089001

Epoch: 5| Step: 4
Training loss: 1.7405591805031337
Validation loss: 2.444883669929743

Epoch: 5| Step: 5
Training loss: 1.6076821618221564
Validation loss: 2.440325029398224

Epoch: 5| Step: 6
Training loss: 1.9370319662533588
Validation loss: 2.4221513075177254

Epoch: 5| Step: 7
Training loss: 1.7039673848053034
Validation loss: 2.437076300393621

Epoch: 5| Step: 8
Training loss: 1.9657379603108798
Validation loss: 2.401209406409591

Epoch: 5| Step: 9
Training loss: 2.1519499209011927
Validation loss: 2.3651282213155134

Epoch: 5| Step: 10
Training loss: 2.3291368781717234
Validation loss: 2.3931013023576857

Epoch: 204| Step: 0
Training loss: 2.108641546385392
Validation loss: 2.392108285229657

Epoch: 5| Step: 1
Training loss: 1.6708508500903605
Validation loss: 2.453703723804366

Epoch: 5| Step: 2
Training loss: 1.8236700699084814
Validation loss: 2.4381936661015073

Epoch: 5| Step: 3
Training loss: 1.7576469512972914
Validation loss: 2.4678005512747054

Epoch: 5| Step: 4
Training loss: 1.8033869296915659
Validation loss: 2.411508301372021

Epoch: 5| Step: 5
Training loss: 1.923940525547374
Validation loss: 2.446435489046168

Epoch: 5| Step: 6
Training loss: 2.371889788313891
Validation loss: 2.424670097120583

Epoch: 5| Step: 7
Training loss: 2.3248652224289725
Validation loss: 2.4462649412265454

Epoch: 5| Step: 8
Training loss: 2.184935019637669
Validation loss: 2.388257758022789

Epoch: 5| Step: 9
Training loss: 1.8321257934901733
Validation loss: 2.402592250918139

Epoch: 5| Step: 10
Training loss: 2.1790597756928287
Validation loss: 2.4480828837295503

Epoch: 205| Step: 0
Training loss: 2.2314093054739885
Validation loss: 2.4080417952506794

Epoch: 5| Step: 1
Training loss: 1.6833063221013842
Validation loss: 2.400439261672116

Epoch: 5| Step: 2
Training loss: 1.8680606859302937
Validation loss: 2.410686116168738

Epoch: 5| Step: 3
Training loss: 2.4069630941011013
Validation loss: 2.4043873339009325

Epoch: 5| Step: 4
Training loss: 2.1844026708419277
Validation loss: 2.4258486347173362

Epoch: 5| Step: 5
Training loss: 1.8971227795126109
Validation loss: 2.445706651259315

Epoch: 5| Step: 6
Training loss: 2.285406115312541
Validation loss: 2.4122286843411787

Epoch: 5| Step: 7
Training loss: 1.7553972393523996
Validation loss: 2.3991490699041735

Epoch: 5| Step: 8
Training loss: 1.8247428320929324
Validation loss: 2.4535969926161503

Epoch: 5| Step: 9
Training loss: 1.661650149315277
Validation loss: 2.4797830864055252

Epoch: 5| Step: 10
Training loss: 1.8694459034065547
Validation loss: 2.447654637486038

Epoch: 206| Step: 0
Training loss: 2.381599993278598
Validation loss: 2.403739483595581

Epoch: 5| Step: 1
Training loss: 1.6780528076101102
Validation loss: 2.368103300718388

Epoch: 5| Step: 2
Training loss: 1.9487865022246669
Validation loss: 2.4071306764618354

Epoch: 5| Step: 3
Training loss: 1.5264762112175498
Validation loss: 2.394787487269084

Epoch: 5| Step: 4
Training loss: 2.2781027417344886
Validation loss: 2.3879268609544946

Epoch: 5| Step: 5
Training loss: 1.948377653302592
Validation loss: 2.428124560191407

Epoch: 5| Step: 6
Training loss: 1.5330232745579253
Validation loss: 2.4338417514806787

Epoch: 5| Step: 7
Training loss: 1.9519255960816104
Validation loss: 2.416879149099682

Epoch: 5| Step: 8
Training loss: 2.0009030449143967
Validation loss: 2.423803852122347

Epoch: 5| Step: 9
Training loss: 2.0568128841529267
Validation loss: 2.4272212535448974

Epoch: 5| Step: 10
Training loss: 2.28680412672657
Validation loss: 2.4306049527853624

Epoch: 207| Step: 0
Training loss: 1.6953858390449805
Validation loss: 2.4063532620281567

Epoch: 5| Step: 1
Training loss: 1.8440217286648126
Validation loss: 2.3988726227453805

Epoch: 5| Step: 2
Training loss: 1.8622612870614697
Validation loss: 2.399036517182827

Epoch: 5| Step: 3
Training loss: 2.100808955102444
Validation loss: 2.3977034132370423

Epoch: 5| Step: 4
Training loss: 1.8187313826089855
Validation loss: 2.458095360867663

Epoch: 5| Step: 5
Training loss: 1.8949735459466568
Validation loss: 2.447356818557794

Epoch: 5| Step: 6
Training loss: 2.301642109516393
Validation loss: 2.40446660179536

Epoch: 5| Step: 7
Training loss: 2.0854626518715396
Validation loss: 2.3985726250067585

Epoch: 5| Step: 8
Training loss: 1.559833922349001
Validation loss: 2.4334323521208265

Epoch: 5| Step: 9
Training loss: 2.1698785841063053
Validation loss: 2.3994346630889827

Epoch: 5| Step: 10
Training loss: 2.3370917795071384
Validation loss: 2.4065286224404994

Epoch: 208| Step: 0
Training loss: 1.9481769598651615
Validation loss: 2.4172044275229623

Epoch: 5| Step: 1
Training loss: 2.1248035340087297
Validation loss: 2.4260640383010994

Epoch: 5| Step: 2
Training loss: 2.09765602268097
Validation loss: 2.4056631527811776

Epoch: 5| Step: 3
Training loss: 2.1085365041712243
Validation loss: 2.439622176599436

Epoch: 5| Step: 4
Training loss: 2.1957713017638376
Validation loss: 2.4203749950545754

Epoch: 5| Step: 5
Training loss: 0.9767786015779365
Validation loss: 2.4181548085159177

Epoch: 5| Step: 6
Training loss: 2.0198270776591296
Validation loss: 2.385748040661119

Epoch: 5| Step: 7
Training loss: 1.9407849305820293
Validation loss: 2.3959003569299737

Epoch: 5| Step: 8
Training loss: 1.8686446246288504
Validation loss: 2.4065853663472714

Epoch: 5| Step: 9
Training loss: 2.244510842538242
Validation loss: 2.4481659580102204

Epoch: 5| Step: 10
Training loss: 1.9363255171212832
Validation loss: 2.423426666333931

Epoch: 209| Step: 0
Training loss: 1.7472616978956608
Validation loss: 2.431261979872401

Epoch: 5| Step: 1
Training loss: 1.70417732135952
Validation loss: 2.416668887308845

Epoch: 5| Step: 2
Training loss: 1.9792318902227344
Validation loss: 2.4687720095680237

Epoch: 5| Step: 3
Training loss: 2.2410502989136014
Validation loss: 2.415693040985367

Epoch: 5| Step: 4
Training loss: 1.9625088296679478
Validation loss: 2.4604478553710383

Epoch: 5| Step: 5
Training loss: 2.2676902040157865
Validation loss: 2.4043018331716746

Epoch: 5| Step: 6
Training loss: 1.7309737663374727
Validation loss: 2.3914138824215345

Epoch: 5| Step: 7
Training loss: 1.851457037517663
Validation loss: 2.4551264572714833

Epoch: 5| Step: 8
Training loss: 1.4735735153897747
Validation loss: 2.3977673915760174

Epoch: 5| Step: 9
Training loss: 2.4018810291795303
Validation loss: 2.4136581361001417

Epoch: 5| Step: 10
Training loss: 1.8704213505096607
Validation loss: 2.467653462223921

Epoch: 210| Step: 0
Training loss: 1.925475183272037
Validation loss: 2.3766152556693085

Epoch: 5| Step: 1
Training loss: 2.190429469808839
Validation loss: 2.403148199959659

Epoch: 5| Step: 2
Training loss: 1.523627244919364
Validation loss: 2.389583432864276

Epoch: 5| Step: 3
Training loss: 2.1304664983901858
Validation loss: 2.403466578229209

Epoch: 5| Step: 4
Training loss: 1.9074594381876901
Validation loss: 2.4249644421599816

Epoch: 5| Step: 5
Training loss: 2.0510514144962886
Validation loss: 2.4467997736149387

Epoch: 5| Step: 6
Training loss: 2.5631564160207394
Validation loss: 2.3892649702084694

Epoch: 5| Step: 7
Training loss: 1.6393251628622998
Validation loss: 2.4007981904535254

Epoch: 5| Step: 8
Training loss: 1.7857423316932979
Validation loss: 2.4180443750730345

Epoch: 5| Step: 9
Training loss: 1.893166780209123
Validation loss: 2.43219996604871

Epoch: 5| Step: 10
Training loss: 1.9416741353274711
Validation loss: 2.4240289811648688

Epoch: 211| Step: 0
Training loss: 2.8322090461430784
Validation loss: 2.43311183436581

Epoch: 5| Step: 1
Training loss: 1.3737348892033405
Validation loss: 2.438865937291533

Epoch: 5| Step: 2
Training loss: 1.8449199649850172
Validation loss: 2.3902347510781334

Epoch: 5| Step: 3
Training loss: 2.1145467019001027
Validation loss: 2.4397997286959536

Epoch: 5| Step: 4
Training loss: 1.9857570611241555
Validation loss: 2.451480209306006

Epoch: 5| Step: 5
Training loss: 1.8390016349631713
Validation loss: 2.414266188302649

Epoch: 5| Step: 6
Training loss: 2.081245316966977
Validation loss: 2.4199851398745693

Epoch: 5| Step: 7
Training loss: 1.5856386100356354
Validation loss: 2.397582916490975

Epoch: 5| Step: 8
Training loss: 2.084186862307255
Validation loss: 2.4459138919827472

Epoch: 5| Step: 9
Training loss: 1.9376723920360333
Validation loss: 2.419325496399941

Epoch: 5| Step: 10
Training loss: 1.7386545530513504
Validation loss: 2.421210867398954

Epoch: 212| Step: 0
Training loss: 2.447864602258963
Validation loss: 2.3589665451123

Epoch: 5| Step: 1
Training loss: 1.8329827739324451
Validation loss: 2.4098388379895637

Epoch: 5| Step: 2
Training loss: 1.5673424261005975
Validation loss: 2.439198171396718

Epoch: 5| Step: 3
Training loss: 1.6921138560718663
Validation loss: 2.4384873617255085

Epoch: 5| Step: 4
Training loss: 1.9318637699725159
Validation loss: 2.42728158316382

Epoch: 5| Step: 5
Training loss: 2.270475575207971
Validation loss: 2.4206977303732775

Epoch: 5| Step: 6
Training loss: 2.2008596908029086
Validation loss: 2.4323441230851324

Epoch: 5| Step: 7
Training loss: 1.739305584447977
Validation loss: 2.4302092045727663

Epoch: 5| Step: 8
Training loss: 1.6318445576429264
Validation loss: 2.421477503182088

Epoch: 5| Step: 9
Training loss: 1.9773799728638728
Validation loss: 2.4257544084597353

Epoch: 5| Step: 10
Training loss: 1.96242731044783
Validation loss: 2.3953700899583876

Epoch: 213| Step: 0
Training loss: 1.3720835186197198
Validation loss: 2.4527001604478995

Epoch: 5| Step: 1
Training loss: 2.3540466975698675
Validation loss: 2.429177954004531

Epoch: 5| Step: 2
Training loss: 2.519596164074134
Validation loss: 2.433610170939363

Epoch: 5| Step: 3
Training loss: 1.4390439573868146
Validation loss: 2.4156168105996105

Epoch: 5| Step: 4
Training loss: 2.035146409375201
Validation loss: 2.43184220002831

Epoch: 5| Step: 5
Training loss: 1.8763417847082104
Validation loss: 2.4070704752266705

Epoch: 5| Step: 6
Training loss: 1.6865322729076975
Validation loss: 2.400926630230287

Epoch: 5| Step: 7
Training loss: 2.092245101990438
Validation loss: 2.4015339882345392

Epoch: 5| Step: 8
Training loss: 2.393707183375283
Validation loss: 2.3822763168885217

Epoch: 5| Step: 9
Training loss: 1.770886237158295
Validation loss: 2.4562276168338184

Epoch: 5| Step: 10
Training loss: 1.4323145176769723
Validation loss: 2.3957555029712356

Epoch: 214| Step: 0
Training loss: 1.6844568717465127
Validation loss: 2.367047416500196

Epoch: 5| Step: 1
Training loss: 1.789677876412795
Validation loss: 2.415315948245219

Epoch: 5| Step: 2
Training loss: 1.6984670796139165
Validation loss: 2.4077915984783047

Epoch: 5| Step: 3
Training loss: 1.9895632345039869
Validation loss: 2.4368375251843304

Epoch: 5| Step: 4
Training loss: 1.951860308315503
Validation loss: 2.361175441247616

Epoch: 5| Step: 5
Training loss: 1.8251233359687784
Validation loss: 2.4328390709978875

Epoch: 5| Step: 6
Training loss: 2.2541536562315576
Validation loss: 2.440481264835785

Epoch: 5| Step: 7
Training loss: 1.6075567696426467
Validation loss: 2.4182876762779135

Epoch: 5| Step: 8
Training loss: 1.8893490734081817
Validation loss: 2.4623400047208084

Epoch: 5| Step: 9
Training loss: 2.010530050239553
Validation loss: 2.4218032302304877

Epoch: 5| Step: 10
Training loss: 2.526891275787963
Validation loss: 2.429611282939014

Epoch: 215| Step: 0
Training loss: 1.3856199397440778
Validation loss: 2.425735674795181

Epoch: 5| Step: 1
Training loss: 2.6173930073233476
Validation loss: 2.3840732466149497

Epoch: 5| Step: 2
Training loss: 1.2583747223285078
Validation loss: 2.3907577013480488

Epoch: 5| Step: 3
Training loss: 2.236693879581158
Validation loss: 2.4233946532318185

Epoch: 5| Step: 4
Training loss: 2.1680380320433104
Validation loss: 2.4096027099664186

Epoch: 5| Step: 5
Training loss: 1.6578175306468574
Validation loss: 2.4498000426874462

Epoch: 5| Step: 6
Training loss: 1.8474702963293055
Validation loss: 2.4419059573444613

Epoch: 5| Step: 7
Training loss: 2.5128514893287814
Validation loss: 2.378540279248183

Epoch: 5| Step: 8
Training loss: 1.8869182726006883
Validation loss: 2.3959423587883304

Epoch: 5| Step: 9
Training loss: 1.5396412956810606
Validation loss: 2.3732149543420924

Epoch: 5| Step: 10
Training loss: 1.848158979674368
Validation loss: 2.3754300104391146

Epoch: 216| Step: 0
Training loss: 1.989802889335115
Validation loss: 2.4088102628148573

Epoch: 5| Step: 1
Training loss: 1.8403171327169559
Validation loss: 2.408008181884469

Epoch: 5| Step: 2
Training loss: 1.696760060613417
Validation loss: 2.3819748854519913

Epoch: 5| Step: 3
Training loss: 2.040375268677316
Validation loss: 2.376401606942498

Epoch: 5| Step: 4
Training loss: 1.7219535795859955
Validation loss: 2.4083679662832136

Epoch: 5| Step: 5
Training loss: 1.964395521240628
Validation loss: 2.3688939773016986

Epoch: 5| Step: 6
Training loss: 1.7537983816573752
Validation loss: 2.4132548230648476

Epoch: 5| Step: 7
Training loss: 1.9166572266498239
Validation loss: 2.3938103604964365

Epoch: 5| Step: 8
Training loss: 1.8179317508304569
Validation loss: 2.4390289175046327

Epoch: 5| Step: 9
Training loss: 2.010134767787466
Validation loss: 2.4359549881194895

Epoch: 5| Step: 10
Training loss: 2.348820503967295
Validation loss: 2.400523582125875

Epoch: 217| Step: 0
Training loss: 1.582320726072142
Validation loss: 2.40339784970925

Epoch: 5| Step: 1
Training loss: 1.6159840404364496
Validation loss: 2.389422702083155

Epoch: 5| Step: 2
Training loss: 1.8841755472024844
Validation loss: 2.4198482102660113

Epoch: 5| Step: 3
Training loss: 2.258749269233083
Validation loss: 2.4108452304692163

Epoch: 5| Step: 4
Training loss: 2.179683781008812
Validation loss: 2.443314975472079

Epoch: 5| Step: 5
Training loss: 1.7615460567035128
Validation loss: 2.409274644989371

Epoch: 5| Step: 6
Training loss: 1.970045057352719
Validation loss: 2.4306233219557796

Epoch: 5| Step: 7
Training loss: 1.9575787842390113
Validation loss: 2.453637584699989

Epoch: 5| Step: 8
Training loss: 2.2454579390513163
Validation loss: 2.405594899443618

Epoch: 5| Step: 9
Training loss: 1.9407885545495314
Validation loss: 2.4291033974362333

Epoch: 5| Step: 10
Training loss: 1.6191085977918471
Validation loss: 2.4119743153586732

Epoch: 218| Step: 0
Training loss: 2.0262432896987153
Validation loss: 2.3890469193881896

Epoch: 5| Step: 1
Training loss: 1.7522664380036583
Validation loss: 2.4199055433911965

Epoch: 5| Step: 2
Training loss: 2.2324894772203647
Validation loss: 2.395333539096576

Epoch: 5| Step: 3
Training loss: 1.9299245217739118
Validation loss: 2.4109321558291406

Epoch: 5| Step: 4
Training loss: 1.560725921557555
Validation loss: 2.3863704236491667

Epoch: 5| Step: 5
Training loss: 2.006148424280751
Validation loss: 2.414072449493693

Epoch: 5| Step: 6
Training loss: 1.7763855751264515
Validation loss: 2.402198477773892

Epoch: 5| Step: 7
Training loss: 2.3342709927962644
Validation loss: 2.4139549304945667

Epoch: 5| Step: 8
Training loss: 2.0376654622112707
Validation loss: 2.383846569225048

Epoch: 5| Step: 9
Training loss: 1.5717692284613036
Validation loss: 2.4334453002273873

Epoch: 5| Step: 10
Training loss: 1.888999681714073
Validation loss: 2.4549993979355538

Epoch: 219| Step: 0
Training loss: 2.374178493368092
Validation loss: 2.4168246906738045

Epoch: 5| Step: 1
Training loss: 2.3993836565152193
Validation loss: 2.4397319291290507

Epoch: 5| Step: 2
Training loss: 1.4973157070670295
Validation loss: 2.401815610587836

Epoch: 5| Step: 3
Training loss: 2.143974078954036
Validation loss: 2.4052482302126337

Epoch: 5| Step: 4
Training loss: 1.5269182397854117
Validation loss: 2.4320785890430656

Epoch: 5| Step: 5
Training loss: 2.0371771386964586
Validation loss: 2.3946766137310185

Epoch: 5| Step: 6
Training loss: 1.4126094708177726
Validation loss: 2.433122328665868

Epoch: 5| Step: 7
Training loss: 1.8867881872695713
Validation loss: 2.4341745286170653

Epoch: 5| Step: 8
Training loss: 1.9743815214188876
Validation loss: 2.4345224366728195

Epoch: 5| Step: 9
Training loss: 1.8946111603234108
Validation loss: 2.446132861588432

Epoch: 5| Step: 10
Training loss: 2.037656452748473
Validation loss: 2.438833594956975

Epoch: 220| Step: 0
Training loss: 1.962210010558008
Validation loss: 2.423422212748789

Epoch: 5| Step: 1
Training loss: 2.4420166229194655
Validation loss: 2.4383055978280854

Epoch: 5| Step: 2
Training loss: 2.035880108344241
Validation loss: 2.3890629951591733

Epoch: 5| Step: 3
Training loss: 1.5262317560778567
Validation loss: 2.41358989269941

Epoch: 5| Step: 4
Training loss: 1.932207940302143
Validation loss: 2.4120956417186172

Epoch: 5| Step: 5
Training loss: 1.8489281307135617
Validation loss: 2.399317970024325

Epoch: 5| Step: 6
Training loss: 1.9519723161078804
Validation loss: 2.3905369587369307

Epoch: 5| Step: 7
Training loss: 1.8846004749738354
Validation loss: 2.386925007971259

Epoch: 5| Step: 8
Training loss: 1.450118533584097
Validation loss: 2.4287089826093236

Epoch: 5| Step: 9
Training loss: 1.9671700813909998
Validation loss: 2.413344288647418

Epoch: 5| Step: 10
Training loss: 1.625978542017376
Validation loss: 2.448233533959202

Epoch: 221| Step: 0
Training loss: 1.2271677455570096
Validation loss: 2.4559855073467363

Epoch: 5| Step: 1
Training loss: 1.6937449015297816
Validation loss: 2.372407993795038

Epoch: 5| Step: 2
Training loss: 2.037699393596747
Validation loss: 2.38804129209323

Epoch: 5| Step: 3
Training loss: 1.964362508337809
Validation loss: 2.427102092860725

Epoch: 5| Step: 4
Training loss: 1.9924776950482765
Validation loss: 2.429991033501158

Epoch: 5| Step: 5
Training loss: 2.071828150615092
Validation loss: 2.4344980040006834

Epoch: 5| Step: 6
Training loss: 1.94430056069885
Validation loss: 2.450289418100713

Epoch: 5| Step: 7
Training loss: 2.1739655457251947
Validation loss: 2.427459037763558

Epoch: 5| Step: 8
Training loss: 1.897954306314734
Validation loss: 2.4630076722356784

Epoch: 5| Step: 9
Training loss: 2.16988528656006
Validation loss: 2.420017170536244

Epoch: 5| Step: 10
Training loss: 1.868245993939789
Validation loss: 2.450353526864279

Epoch: 222| Step: 0
Training loss: 1.9099174615491685
Validation loss: 2.396326056307147

Epoch: 5| Step: 1
Training loss: 2.345191410606045
Validation loss: 2.4144538370783106

Epoch: 5| Step: 2
Training loss: 1.781079602038496
Validation loss: 2.405364493294156

Epoch: 5| Step: 3
Training loss: 1.9170990815483457
Validation loss: 2.408825178606616

Epoch: 5| Step: 4
Training loss: 1.6695434855475546
Validation loss: 2.415469882293844

Epoch: 5| Step: 5
Training loss: 1.3708397176220921
Validation loss: 2.4293050500270548

Epoch: 5| Step: 6
Training loss: 1.7799746314394806
Validation loss: 2.4338110940927904

Epoch: 5| Step: 7
Training loss: 2.518106693628291
Validation loss: 2.4007810907215776

Epoch: 5| Step: 8
Training loss: 1.5010451013903883
Validation loss: 2.416435725712502

Epoch: 5| Step: 9
Training loss: 1.5668933900500286
Validation loss: 2.345995926074941

Epoch: 5| Step: 10
Training loss: 2.5060102695336868
Validation loss: 2.421684339668422

Epoch: 223| Step: 0
Training loss: 2.02808238779688
Validation loss: 2.4361097200884645

Epoch: 5| Step: 1
Training loss: 2.3408921174648634
Validation loss: 2.369605836790876

Epoch: 5| Step: 2
Training loss: 1.9822743027354717
Validation loss: 2.414189021393122

Epoch: 5| Step: 3
Training loss: 1.4532462448893209
Validation loss: 2.4326155223988857

Epoch: 5| Step: 4
Training loss: 1.8051716869205665
Validation loss: 2.403508851050096

Epoch: 5| Step: 5
Training loss: 2.457251121981034
Validation loss: 2.3570842111472166

Epoch: 5| Step: 6
Training loss: 1.7760034894522332
Validation loss: 2.4019443583146245

Epoch: 5| Step: 7
Training loss: 1.4623372924805584
Validation loss: 2.406356446130841

Epoch: 5| Step: 8
Training loss: 1.8398074654728862
Validation loss: 2.38464566190967

Epoch: 5| Step: 9
Training loss: 1.994683471082766
Validation loss: 2.428454250693051

Epoch: 5| Step: 10
Training loss: 1.7520485876435463
Validation loss: 2.4160837993542694

Epoch: 224| Step: 0
Training loss: 1.250696893977091
Validation loss: 2.4324146385557333

Epoch: 5| Step: 1
Training loss: 1.4521380939128086
Validation loss: 2.4114487986532396

Epoch: 5| Step: 2
Training loss: 2.175648875293174
Validation loss: 2.3815573670969106

Epoch: 5| Step: 3
Training loss: 1.329287659610055
Validation loss: 2.4537728721695196

Epoch: 5| Step: 4
Training loss: 1.974329897518454
Validation loss: 2.4676179274954846

Epoch: 5| Step: 5
Training loss: 1.7469876793840178
Validation loss: 2.4180249693974623

Epoch: 5| Step: 6
Training loss: 2.319534222609612
Validation loss: 2.445201995647673

Epoch: 5| Step: 7
Training loss: 2.061918003157644
Validation loss: 2.4158178411606044

Epoch: 5| Step: 8
Training loss: 2.1404049057130266
Validation loss: 2.3786334507365314

Epoch: 5| Step: 9
Training loss: 1.9119232055931779
Validation loss: 2.399395366786198

Epoch: 5| Step: 10
Training loss: 2.1315091241278408
Validation loss: 2.4360408680490275

Epoch: 225| Step: 0
Training loss: 2.010476330545474
Validation loss: 2.4309359267395756

Epoch: 5| Step: 1
Training loss: 2.553123625401252
Validation loss: 2.3958068714223133

Epoch: 5| Step: 2
Training loss: 2.0249608024288497
Validation loss: 2.41517783468133

Epoch: 5| Step: 3
Training loss: 1.7173129229433486
Validation loss: 2.425041315343962

Epoch: 5| Step: 4
Training loss: 2.269056575858302
Validation loss: 2.3920502044027354

Epoch: 5| Step: 5
Training loss: 1.7303129173362357
Validation loss: 2.4688576534252933

Epoch: 5| Step: 6
Training loss: 1.5121141650932832
Validation loss: 2.390575460164227

Epoch: 5| Step: 7
Training loss: 1.9252761890397054
Validation loss: 2.4383850194805143

Epoch: 5| Step: 8
Training loss: 1.1270632367742772
Validation loss: 2.413150713793316

Epoch: 5| Step: 9
Training loss: 1.9522851587901549
Validation loss: 2.397371805240605

Epoch: 5| Step: 10
Training loss: 1.486841742138403
Validation loss: 2.3640696029079775

Epoch: 226| Step: 0
Training loss: 1.5310116017884354
Validation loss: 2.419920379141091

Epoch: 5| Step: 1
Training loss: 1.7154788707209112
Validation loss: 2.440633448337372

Epoch: 5| Step: 2
Training loss: 2.4873345938278653
Validation loss: 2.3982545660577426

Epoch: 5| Step: 3
Training loss: 2.04065931212479
Validation loss: 2.411795620446414

Epoch: 5| Step: 4
Training loss: 1.5918804497807124
Validation loss: 2.4053931541194156

Epoch: 5| Step: 5
Training loss: 1.729734381201489
Validation loss: 2.388316570829101

Epoch: 5| Step: 6
Training loss: 1.9178170884220307
Validation loss: 2.397327332507828

Epoch: 5| Step: 7
Training loss: 2.3069169979566726
Validation loss: 2.3948140630332384

Epoch: 5| Step: 8
Training loss: 1.6587716106510504
Validation loss: 2.3862011372726366

Epoch: 5| Step: 9
Training loss: 1.7117759705472253
Validation loss: 2.427094475132022

Epoch: 5| Step: 10
Training loss: 2.155750603825395
Validation loss: 2.4020856789215133

Epoch: 227| Step: 0
Training loss: 1.4743110405477555
Validation loss: 2.427613455863067

Epoch: 5| Step: 1
Training loss: 1.8499505474594866
Validation loss: 2.4593615695771005

Epoch: 5| Step: 2
Training loss: 2.030915805027524
Validation loss: 2.4112790987128956

Epoch: 5| Step: 3
Training loss: 1.8675846331925203
Validation loss: 2.429285377083042

Epoch: 5| Step: 4
Training loss: 2.2283449767937205
Validation loss: 2.434478356171884

Epoch: 5| Step: 5
Training loss: 2.109347986118978
Validation loss: 2.445124202994044

Epoch: 5| Step: 6
Training loss: 2.470171844898419
Validation loss: 2.4058548243634914

Epoch: 5| Step: 7
Training loss: 1.6869240943687251
Validation loss: 2.4243299814765793

Epoch: 5| Step: 8
Training loss: 1.164961295078408
Validation loss: 2.40989117216629

Epoch: 5| Step: 9
Training loss: 1.547594461839616
Validation loss: 2.41461819855179

Epoch: 5| Step: 10
Training loss: 1.9831480302985212
Validation loss: 2.3828184625667674

Epoch: 228| Step: 0
Training loss: 2.1331062533798
Validation loss: 2.4127842745161905

Epoch: 5| Step: 1
Training loss: 1.3517805155178813
Validation loss: 2.427129740198529

Epoch: 5| Step: 2
Training loss: 1.442484052097218
Validation loss: 2.4624241138602647

Epoch: 5| Step: 3
Training loss: 2.1926877223939143
Validation loss: 2.430392076079771

Epoch: 5| Step: 4
Training loss: 1.7525448687546608
Validation loss: 2.437524443599288

Epoch: 5| Step: 5
Training loss: 1.886035045006922
Validation loss: 2.4125697377109163

Epoch: 5| Step: 6
Training loss: 2.1833150887151693
Validation loss: 2.4098074880021256

Epoch: 5| Step: 7
Training loss: 1.7195246251354308
Validation loss: 2.4007149042620264

Epoch: 5| Step: 8
Training loss: 2.2504776341721726
Validation loss: 2.371774958928449

Epoch: 5| Step: 9
Training loss: 1.6138662242921153
Validation loss: 2.416125372356741

Epoch: 5| Step: 10
Training loss: 1.7889087727562472
Validation loss: 2.4668604352561783

Epoch: 229| Step: 0
Training loss: 2.325461688398453
Validation loss: 2.4153635467101635

Epoch: 5| Step: 1
Training loss: 1.9317520155769656
Validation loss: 2.3877475597507543

Epoch: 5| Step: 2
Training loss: 1.6704374175647425
Validation loss: 2.461378150211529

Epoch: 5| Step: 3
Training loss: 1.6100383243382788
Validation loss: 2.3921165094996613

Epoch: 5| Step: 4
Training loss: 1.4630133420762155
Validation loss: 2.4052164558640117

Epoch: 5| Step: 5
Training loss: 1.706834375826218
Validation loss: 2.3683771949007513

Epoch: 5| Step: 6
Training loss: 1.648775039031552
Validation loss: 2.3677511509032008

Epoch: 5| Step: 7
Training loss: 2.3100290242142854
Validation loss: 2.3969494232133415

Epoch: 5| Step: 8
Training loss: 1.9108110487390306
Validation loss: 2.3662337632420103

Epoch: 5| Step: 9
Training loss: 2.076119279598973
Validation loss: 2.368982879180994

Epoch: 5| Step: 10
Training loss: 1.5214817110755723
Validation loss: 2.3285264002746526

Epoch: 230| Step: 0
Training loss: 2.1629059382994233
Validation loss: 2.373853539531467

Epoch: 5| Step: 1
Training loss: 1.4828257456631049
Validation loss: 2.386693778549434

Epoch: 5| Step: 2
Training loss: 1.7746201659505725
Validation loss: 2.3870436235805843

Epoch: 5| Step: 3
Training loss: 2.0934366020113018
Validation loss: 2.3860891465122127

Epoch: 5| Step: 4
Training loss: 2.417783665390809
Validation loss: 2.4128988782642162

Epoch: 5| Step: 5
Training loss: 1.9492860832128138
Validation loss: 2.4263844510826997

Epoch: 5| Step: 6
Training loss: 2.261880872117468
Validation loss: 2.434235775928541

Epoch: 5| Step: 7
Training loss: 1.435865302029797
Validation loss: 2.3805924930855316

Epoch: 5| Step: 8
Training loss: 1.3166006606896388
Validation loss: 2.3852827807737746

Epoch: 5| Step: 9
Training loss: 1.889677835083021
Validation loss: 2.4097484893133987

Epoch: 5| Step: 10
Training loss: 1.550727747227252
Validation loss: 2.4034749812275296

Epoch: 231| Step: 0
Training loss: 1.665933765757105
Validation loss: 2.4353140238871522

Epoch: 5| Step: 1
Training loss: 1.703944577744076
Validation loss: 2.407937981209254

Epoch: 5| Step: 2
Training loss: 1.8775061706563474
Validation loss: 2.365083233330534

Epoch: 5| Step: 3
Training loss: 1.7076942675150346
Validation loss: 2.4346076147670557

Epoch: 5| Step: 4
Training loss: 1.8548635680417533
Validation loss: 2.4243404085736815

Epoch: 5| Step: 5
Training loss: 1.544562180961428
Validation loss: 2.4833895523794776

Epoch: 5| Step: 6
Training loss: 2.489043833057357
Validation loss: 2.426286009683763

Epoch: 5| Step: 7
Training loss: 1.2691555934597445
Validation loss: 2.385866711560949

Epoch: 5| Step: 8
Training loss: 2.331824723240791
Validation loss: 2.43379395928347

Epoch: 5| Step: 9
Training loss: 1.855449218647203
Validation loss: 2.4301871738300598

Epoch: 5| Step: 10
Training loss: 1.8068322322379855
Validation loss: 2.4241458457546403

Epoch: 232| Step: 0
Training loss: 1.8507673914379632
Validation loss: 2.4262047760654997

Epoch: 5| Step: 1
Training loss: 1.763898021777815
Validation loss: 2.4713554315325945

Epoch: 5| Step: 2
Training loss: 1.5379184401605357
Validation loss: 2.422842062780288

Epoch: 5| Step: 3
Training loss: 1.9164776570654634
Validation loss: 2.43570646714468

Epoch: 5| Step: 4
Training loss: 2.1015678320607893
Validation loss: 2.422586066331439

Epoch: 5| Step: 5
Training loss: 1.5668275033624375
Validation loss: 2.3896062037842962

Epoch: 5| Step: 6
Training loss: 1.6937577814014924
Validation loss: 2.3643376971491117

Epoch: 5| Step: 7
Training loss: 2.328233959541293
Validation loss: 2.407488634784645

Epoch: 5| Step: 8
Training loss: 1.679139016667629
Validation loss: 2.4018128161955192

Epoch: 5| Step: 9
Training loss: 1.8861781386330796
Validation loss: 2.41818280728464

Epoch: 5| Step: 10
Training loss: 1.9520316153412758
Validation loss: 2.3886974063933195

Epoch: 233| Step: 0
Training loss: 1.6749851140741505
Validation loss: 2.4551789934945707

Epoch: 5| Step: 1
Training loss: 2.00044758080012
Validation loss: 2.412420629697984

Epoch: 5| Step: 2
Training loss: 1.4099940579201233
Validation loss: 2.4519894105172404

Epoch: 5| Step: 3
Training loss: 1.6132508060270643
Validation loss: 2.4143050259430536

Epoch: 5| Step: 4
Training loss: 2.1164216067410737
Validation loss: 2.3787211824660743

Epoch: 5| Step: 5
Training loss: 1.757929547969366
Validation loss: 2.4189433264011417

Epoch: 5| Step: 6
Training loss: 2.199452904386289
Validation loss: 2.441252704344967

Epoch: 5| Step: 7
Training loss: 0.9429450537004241
Validation loss: 2.4007002328130116

Epoch: 5| Step: 8
Training loss: 2.147272633427825
Validation loss: 2.4214091424194653

Epoch: 5| Step: 9
Training loss: 1.9718428039340543
Validation loss: 2.47372292884476

Epoch: 5| Step: 10
Training loss: 2.372486792508536
Validation loss: 2.3825168640726435

Epoch: 234| Step: 0
Training loss: 1.5836419089267715
Validation loss: 2.3995156437741505

Epoch: 5| Step: 1
Training loss: 1.4447875023057362
Validation loss: 2.3692206057885903

Epoch: 5| Step: 2
Training loss: 2.206198854366887
Validation loss: 2.442656839056531

Epoch: 5| Step: 3
Training loss: 1.9057560265055586
Validation loss: 2.3807061853807023

Epoch: 5| Step: 4
Training loss: 1.996015035790514
Validation loss: 2.394880185633218

Epoch: 5| Step: 5
Training loss: 1.9976113479574558
Validation loss: 2.455844905174936

Epoch: 5| Step: 6
Training loss: 2.123420352599892
Validation loss: 2.419261804179685

Epoch: 5| Step: 7
Training loss: 1.8977266715541463
Validation loss: 2.4374535185171244

Epoch: 5| Step: 8
Training loss: 1.7268968491443948
Validation loss: 2.3846315006206025

Epoch: 5| Step: 9
Training loss: 1.446258812484335
Validation loss: 2.3759913715089036

Epoch: 5| Step: 10
Training loss: 1.9646466196114154
Validation loss: 2.389904465099694

Epoch: 235| Step: 0
Training loss: 2.0436581092264983
Validation loss: 2.3903962241060754

Epoch: 5| Step: 1
Training loss: 1.3811130317682476
Validation loss: 2.472124232327788

Epoch: 5| Step: 2
Training loss: 1.8662852896785913
Validation loss: 2.4138983269023258

Epoch: 5| Step: 3
Training loss: 1.536609146561436
Validation loss: 2.4384739951537218

Epoch: 5| Step: 4
Training loss: 2.2614154513484275
Validation loss: 2.4137194377409004

Epoch: 5| Step: 5
Training loss: 1.9881398688452583
Validation loss: 2.3836372522980884

Epoch: 5| Step: 6
Training loss: 2.2500362393321813
Validation loss: 2.4200202214569013

Epoch: 5| Step: 7
Training loss: 1.897726231835858
Validation loss: 2.425999700854255

Epoch: 5| Step: 8
Training loss: 1.6121908941379228
Validation loss: 2.39069836095314

Epoch: 5| Step: 9
Training loss: 1.4618296627534564
Validation loss: 2.4009359614658594

Epoch: 5| Step: 10
Training loss: 2.003163577465584
Validation loss: 2.390876607183053

Epoch: 236| Step: 0
Training loss: 1.4846208870665296
Validation loss: 2.392772265977507

Epoch: 5| Step: 1
Training loss: 1.583833397985553
Validation loss: 2.3760808526442045

Epoch: 5| Step: 2
Training loss: 1.823903483363628
Validation loss: 2.4142912621459027

Epoch: 5| Step: 3
Training loss: 2.062002410976062
Validation loss: 2.4227344428932382

Epoch: 5| Step: 4
Training loss: 1.4301857835622405
Validation loss: 2.454840542064651

Epoch: 5| Step: 5
Training loss: 1.7670640060757854
Validation loss: 2.4380951274003233

Epoch: 5| Step: 6
Training loss: 1.7263878090976903
Validation loss: 2.460078653511649

Epoch: 5| Step: 7
Training loss: 1.8463873024044404
Validation loss: 2.484338224673739

Epoch: 5| Step: 8
Training loss: 1.843018855585769
Validation loss: 2.455369787440658

Epoch: 5| Step: 9
Training loss: 2.449152262635484
Validation loss: 2.4302273699746046

Epoch: 5| Step: 10
Training loss: 2.1453228932883937
Validation loss: 2.4142769397283885

Epoch: 237| Step: 0
Training loss: 1.6867467824029716
Validation loss: 2.409031087979429

Epoch: 5| Step: 1
Training loss: 1.4124767200273216
Validation loss: 2.394856385818176

Epoch: 5| Step: 2
Training loss: 2.332751496750835
Validation loss: 2.377157751489854

Epoch: 5| Step: 3
Training loss: 1.902280583204362
Validation loss: 2.4132455522101552

Epoch: 5| Step: 4
Training loss: 2.0736268199278225
Validation loss: 2.4061145741697767

Epoch: 5| Step: 5
Training loss: 2.0225835345809355
Validation loss: 2.3866890738164046

Epoch: 5| Step: 6
Training loss: 1.9854698464902512
Validation loss: 2.445623277498724

Epoch: 5| Step: 7
Training loss: 1.6426893779440708
Validation loss: 2.394267782979816

Epoch: 5| Step: 8
Training loss: 1.3433790360210243
Validation loss: 2.360219095324843

Epoch: 5| Step: 9
Training loss: 1.732942419109186
Validation loss: 2.387438801017215

Epoch: 5| Step: 10
Training loss: 1.8231482949009374
Validation loss: 2.403800085801649

Epoch: 238| Step: 0
Training loss: 1.0887937238740784
Validation loss: 2.384561096076138

Epoch: 5| Step: 1
Training loss: 1.8991569129232515
Validation loss: 2.4134783485568367

Epoch: 5| Step: 2
Training loss: 1.7930662174369147
Validation loss: 2.36581442698433

Epoch: 5| Step: 3
Training loss: 1.8104920939662932
Validation loss: 2.3955269355900732

Epoch: 5| Step: 4
Training loss: 1.778484875241224
Validation loss: 2.409670296025481

Epoch: 5| Step: 5
Training loss: 1.8847686609431507
Validation loss: 2.417725303243149

Epoch: 5| Step: 6
Training loss: 1.8560102134497563
Validation loss: 2.3776289978085687

Epoch: 5| Step: 7
Training loss: 1.6755617082388983
Validation loss: 2.410783839791762

Epoch: 5| Step: 8
Training loss: 2.4944105607157288
Validation loss: 2.407322746095363

Epoch: 5| Step: 9
Training loss: 1.8107020569832044
Validation loss: 2.3908065833101233

Epoch: 5| Step: 10
Training loss: 1.7215811560051522
Validation loss: 2.3250362423848374

Epoch: 239| Step: 0
Training loss: 1.7619426441231876
Validation loss: 2.428399962904263

Epoch: 5| Step: 1
Training loss: 1.7913662932207435
Validation loss: 2.3778594419257324

Epoch: 5| Step: 2
Training loss: 1.413404111229561
Validation loss: 2.4118596033710857

Epoch: 5| Step: 3
Training loss: 1.8755061420125518
Validation loss: 2.448176736484975

Epoch: 5| Step: 4
Training loss: 1.8271426308324021
Validation loss: 2.444495777002569

Epoch: 5| Step: 5
Training loss: 1.3188621636009064
Validation loss: 2.4138363564582592

Epoch: 5| Step: 6
Training loss: 1.267410055576987
Validation loss: 2.3968526757427964

Epoch: 5| Step: 7
Training loss: 1.9384545466712646
Validation loss: 2.4027069753621952

Epoch: 5| Step: 8
Training loss: 2.39766916897383
Validation loss: 2.4011381976634016

Epoch: 5| Step: 9
Training loss: 2.354819238289753
Validation loss: 2.4113146120873505

Epoch: 5| Step: 10
Training loss: 2.110519324840719
Validation loss: 2.379191925161577

Epoch: 240| Step: 0
Training loss: 2.103827408235133
Validation loss: 2.376774956344978

Epoch: 5| Step: 1
Training loss: 1.7449446957412944
Validation loss: 2.351263956492995

Epoch: 5| Step: 2
Training loss: 1.7363416501731734
Validation loss: 2.3941074753747125

Epoch: 5| Step: 3
Training loss: 1.6876811177579776
Validation loss: 2.388728873521865

Epoch: 5| Step: 4
Training loss: 1.7858456672293563
Validation loss: 2.415481134089238

Epoch: 5| Step: 5
Training loss: 2.1619541074556
Validation loss: 2.447292196039549

Epoch: 5| Step: 6
Training loss: 1.630095050357329
Validation loss: 2.3583309702606114

Epoch: 5| Step: 7
Training loss: 1.8585972802351929
Validation loss: 2.453414537272762

Epoch: 5| Step: 8
Training loss: 2.08187951542397
Validation loss: 2.430587605520457

Epoch: 5| Step: 9
Training loss: 1.7672323826656304
Validation loss: 2.4369060107090617

Epoch: 5| Step: 10
Training loss: 1.4986568636426543
Validation loss: 2.409406032963312

Epoch: 241| Step: 0
Training loss: 1.631373597355293
Validation loss: 2.4072959809520587

Epoch: 5| Step: 1
Training loss: 1.6794180720505483
Validation loss: 2.435877977334763

Epoch: 5| Step: 2
Training loss: 1.7633088710989462
Validation loss: 2.3616992395500476

Epoch: 5| Step: 3
Training loss: 1.5376799129265881
Validation loss: 2.4076447958377813

Epoch: 5| Step: 4
Training loss: 1.5965169187868495
Validation loss: 2.357856273095973

Epoch: 5| Step: 5
Training loss: 2.018604058343377
Validation loss: 2.3703721612106516

Epoch: 5| Step: 6
Training loss: 1.621302653261349
Validation loss: 2.3864631830856746

Epoch: 5| Step: 7
Training loss: 2.1825788456154065
Validation loss: 2.4541790732004967

Epoch: 5| Step: 8
Training loss: 1.4888896349451148
Validation loss: 2.3616161517680787

Epoch: 5| Step: 9
Training loss: 2.231565402950145
Validation loss: 2.4199735239408304

Epoch: 5| Step: 10
Training loss: 1.8430879341711177
Validation loss: 2.430816521021925

Epoch: 242| Step: 0
Training loss: 1.2142141495380523
Validation loss: 2.4118423296155567

Epoch: 5| Step: 1
Training loss: 1.8911091838686893
Validation loss: 2.4142093817526535

Epoch: 5| Step: 2
Training loss: 1.74078196120926
Validation loss: 2.386722946613094

Epoch: 5| Step: 3
Training loss: 2.3030418598380935
Validation loss: 2.367162134069891

Epoch: 5| Step: 4
Training loss: 1.6298699398458112
Validation loss: 2.411679344775212

Epoch: 5| Step: 5
Training loss: 2.4084128035618892
Validation loss: 2.382828446766416

Epoch: 5| Step: 6
Training loss: 2.137210656821662
Validation loss: 2.4047069047150265

Epoch: 5| Step: 7
Training loss: 1.3160425243985814
Validation loss: 2.406177329479078

Epoch: 5| Step: 8
Training loss: 1.9430025779561735
Validation loss: 2.43380516849816

Epoch: 5| Step: 9
Training loss: 1.4319394412581792
Validation loss: 2.3563665474398854

Epoch: 5| Step: 10
Training loss: 1.7822622133634622
Validation loss: 2.4030339153130966

Epoch: 243| Step: 0
Training loss: 1.5405574451050832
Validation loss: 2.4011641730427953

Epoch: 5| Step: 1
Training loss: 2.101549566860181
Validation loss: 2.4233922518618565

Epoch: 5| Step: 2
Training loss: 1.8866650433527745
Validation loss: 2.4105393786681564

Epoch: 5| Step: 3
Training loss: 1.659685207186512
Validation loss: 2.415357237804881

Epoch: 5| Step: 4
Training loss: 1.354141024811378
Validation loss: 2.394939502696397

Epoch: 5| Step: 5
Training loss: 1.4775899713170741
Validation loss: 2.4311529811928017

Epoch: 5| Step: 6
Training loss: 1.572959831942333
Validation loss: 2.4273885029565685

Epoch: 5| Step: 7
Training loss: 2.259044482694504
Validation loss: 2.46969892801452

Epoch: 5| Step: 8
Training loss: 2.077534182895052
Validation loss: 2.4235847960957475

Epoch: 5| Step: 9
Training loss: 1.751155131436761
Validation loss: 2.4074550914310318

Epoch: 5| Step: 10
Training loss: 1.8950458260382608
Validation loss: 2.383237221325464

Epoch: 244| Step: 0
Training loss: 1.5874434964194288
Validation loss: 2.4531320749847945

Epoch: 5| Step: 1
Training loss: 1.355803478586743
Validation loss: 2.4093095132980795

Epoch: 5| Step: 2
Training loss: 2.0206659254229846
Validation loss: 2.3859139702469405

Epoch: 5| Step: 3
Training loss: 1.7996825468084947
Validation loss: 2.4182562821028855

Epoch: 5| Step: 4
Training loss: 1.8432044175696085
Validation loss: 2.357196560873698

Epoch: 5| Step: 5
Training loss: 2.128423961640594
Validation loss: 2.3781644327753892

Epoch: 5| Step: 6
Training loss: 1.3499544312592335
Validation loss: 2.411328665045437

Epoch: 5| Step: 7
Training loss: 2.2148660325640037
Validation loss: 2.402566700722762

Epoch: 5| Step: 8
Training loss: 1.9822544572164031
Validation loss: 2.4040821283724063

Epoch: 5| Step: 9
Training loss: 1.7611584501927078
Validation loss: 2.3493498061767513

Epoch: 5| Step: 10
Training loss: 1.21877073612668
Validation loss: 2.4145602992569764

Epoch: 245| Step: 0
Training loss: 1.2071483765102684
Validation loss: 2.4294887409066863

Epoch: 5| Step: 1
Training loss: 1.4472180151476557
Validation loss: 2.3703061704294033

Epoch: 5| Step: 2
Training loss: 2.422878623482241
Validation loss: 2.413843794588636

Epoch: 5| Step: 3
Training loss: 2.0174673960342653
Validation loss: 2.3852979328937565

Epoch: 5| Step: 4
Training loss: 1.961875539185935
Validation loss: 2.376767329399915

Epoch: 5| Step: 5
Training loss: 1.7439383018849175
Validation loss: 2.3745044284048613

Epoch: 5| Step: 6
Training loss: 1.9519044037533195
Validation loss: 2.350979291521624

Epoch: 5| Step: 7
Training loss: 1.6741834016415744
Validation loss: 2.3705619705876675

Epoch: 5| Step: 8
Training loss: 1.3664565393911363
Validation loss: 2.4271935100776196

Epoch: 5| Step: 9
Training loss: 1.6986519405309553
Validation loss: 2.393955731590752

Epoch: 5| Step: 10
Training loss: 2.1002654997702424
Validation loss: 2.3908148538771186

Epoch: 246| Step: 0
Training loss: 1.8392675838026589
Validation loss: 2.4001510787484084

Epoch: 5| Step: 1
Training loss: 1.439959702192811
Validation loss: 2.427191688104325

Epoch: 5| Step: 2
Training loss: 1.669464584112035
Validation loss: 2.420152919012202

Epoch: 5| Step: 3
Training loss: 1.1394670958344162
Validation loss: 2.4318868962505884

Epoch: 5| Step: 4
Training loss: 2.2752982059423235
Validation loss: 2.4166522621458166

Epoch: 5| Step: 5
Training loss: 1.721463991048374
Validation loss: 2.460611654971072

Epoch: 5| Step: 6
Training loss: 2.4036547053467143
Validation loss: 2.3783673937119136

Epoch: 5| Step: 7
Training loss: 1.8863672280460186
Validation loss: 2.4344070443202894

Epoch: 5| Step: 8
Training loss: 1.6542575295553519
Validation loss: 2.4159382566431846

Epoch: 5| Step: 9
Training loss: 1.3962826883285537
Validation loss: 2.4021886978781737

Epoch: 5| Step: 10
Training loss: 1.9553666945072996
Validation loss: 2.4161297799730046

Epoch: 247| Step: 0
Training loss: 1.902765810790411
Validation loss: 2.3385646663725743

Epoch: 5| Step: 1
Training loss: 1.6429799208757851
Validation loss: 2.445613130354206

Epoch: 5| Step: 2
Training loss: 1.6771390522611733
Validation loss: 2.3866308482180547

Epoch: 5| Step: 3
Training loss: 1.2885088569742305
Validation loss: 2.41143875541138

Epoch: 5| Step: 4
Training loss: 2.1586721333573324
Validation loss: 2.461241344439872

Epoch: 5| Step: 5
Training loss: 1.604974823870131
Validation loss: 2.3749206305185666

Epoch: 5| Step: 6
Training loss: 1.639384790959209
Validation loss: 2.3880911292595237

Epoch: 5| Step: 7
Training loss: 1.9691305852299974
Validation loss: 2.4141676254950464

Epoch: 5| Step: 8
Training loss: 1.8459187699545139
Validation loss: 2.358929504090332

Epoch: 5| Step: 9
Training loss: 1.9395520817922418
Validation loss: 2.3745985852283544

Epoch: 5| Step: 10
Training loss: 1.991334081623885
Validation loss: 2.4054477399954894

Epoch: 248| Step: 0
Training loss: 1.944509685269574
Validation loss: 2.40606572724486

Epoch: 5| Step: 1
Training loss: 2.1905271021235824
Validation loss: 2.4191135505620505

Epoch: 5| Step: 2
Training loss: 2.185248606001555
Validation loss: 2.355808684728173

Epoch: 5| Step: 3
Training loss: 1.231587703498245
Validation loss: 2.3963981151764275

Epoch: 5| Step: 4
Training loss: 1.7817897313541329
Validation loss: 2.3871302128406158

Epoch: 5| Step: 5
Training loss: 1.5064930256790696
Validation loss: 2.3918923274711896

Epoch: 5| Step: 6
Training loss: 1.7133814109681749
Validation loss: 2.3875293918220626

Epoch: 5| Step: 7
Training loss: 2.1575921345970146
Validation loss: 2.419214748681461

Epoch: 5| Step: 8
Training loss: 1.4592991582535155
Validation loss: 2.3460585482260194

Epoch: 5| Step: 9
Training loss: 1.6818190423508677
Validation loss: 2.396752573215644

Epoch: 5| Step: 10
Training loss: 1.729167095628555
Validation loss: 2.4097211763551227

Epoch: 249| Step: 0
Training loss: 1.8448283388042237
Validation loss: 2.3870462644995745

Epoch: 5| Step: 1
Training loss: 2.1426454462204494
Validation loss: 2.4343569042604196

Epoch: 5| Step: 2
Training loss: 1.6087994333303204
Validation loss: 2.388309295251438

Epoch: 5| Step: 3
Training loss: 1.0861081325482576
Validation loss: 2.399447687813859

Epoch: 5| Step: 4
Training loss: 1.9544075988841974
Validation loss: 2.400891636973054

Epoch: 5| Step: 5
Training loss: 1.9458314134586945
Validation loss: 2.4035927385105897

Epoch: 5| Step: 6
Training loss: 1.531917270931638
Validation loss: 2.386925276479956

Epoch: 5| Step: 7
Training loss: 2.0497268727413744
Validation loss: 2.4194525632297474

Epoch: 5| Step: 8
Training loss: 2.271478812029678
Validation loss: 2.4247077319643244

Epoch: 5| Step: 9
Training loss: 0.9864335107684614
Validation loss: 2.3705833236916987

Epoch: 5| Step: 10
Training loss: 1.7400417371106955
Validation loss: 2.387796138296582

Epoch: 250| Step: 0
Training loss: 2.0217948933080945
Validation loss: 2.458218114192255

Epoch: 5| Step: 1
Training loss: 1.8740650389060804
Validation loss: 2.4354852227699806

Epoch: 5| Step: 2
Training loss: 1.708926547570745
Validation loss: 2.398854416548359

Epoch: 5| Step: 3
Training loss: 1.7259450645633259
Validation loss: 2.3685674758674256

Epoch: 5| Step: 4
Training loss: 1.824441638865129
Validation loss: 2.4148647919760617

Epoch: 5| Step: 5
Training loss: 1.6617737553383356
Validation loss: 2.423210424218852

Epoch: 5| Step: 6
Training loss: 2.3166946308817544
Validation loss: 2.369511305217246

Epoch: 5| Step: 7
Training loss: 1.4827357828053278
Validation loss: 2.3864439454699977

Epoch: 5| Step: 8
Training loss: 1.5942565262642818
Validation loss: 2.3826367482031148

Epoch: 5| Step: 9
Training loss: 1.1948682670128206
Validation loss: 2.409814491226186

Epoch: 5| Step: 10
Training loss: 1.603409460458614
Validation loss: 2.4242634920141573

Epoch: 251| Step: 0
Training loss: 1.6349302001659498
Validation loss: 2.3586852677638186

Epoch: 5| Step: 1
Training loss: 1.8200428644309696
Validation loss: 2.3735523172584982

Epoch: 5| Step: 2
Training loss: 2.056400527778028
Validation loss: 2.3742877807651843

Epoch: 5| Step: 3
Training loss: 1.3794679875352829
Validation loss: 2.3875106717651646

Epoch: 5| Step: 4
Training loss: 1.4982210577771622
Validation loss: 2.351353713561438

Epoch: 5| Step: 5
Training loss: 1.7203820542801558
Validation loss: 2.3801671581934807

Epoch: 5| Step: 6
Training loss: 1.7808868305677918
Validation loss: 2.3465204339206047

Epoch: 5| Step: 7
Training loss: 1.7609598424081387
Validation loss: 2.369909193029074

Epoch: 5| Step: 8
Training loss: 2.1775852579973
Validation loss: 2.3793626362953972

Epoch: 5| Step: 9
Training loss: 1.10512836729084
Validation loss: 2.398636288381529

Epoch: 5| Step: 10
Training loss: 2.255195024434934
Validation loss: 2.4211366923360433

Epoch: 252| Step: 0
Training loss: 1.5817166992945964
Validation loss: 2.406558458778678

Epoch: 5| Step: 1
Training loss: 2.0094854013065047
Validation loss: 2.417185998800516

Epoch: 5| Step: 2
Training loss: 1.4786095532674588
Validation loss: 2.409022114804195

Epoch: 5| Step: 3
Training loss: 1.7329878199832234
Validation loss: 2.3524519301543814

Epoch: 5| Step: 4
Training loss: 1.6201623653944313
Validation loss: 2.414367348564325

Epoch: 5| Step: 5
Training loss: 1.4575502018600879
Validation loss: 2.428652417820579

Epoch: 5| Step: 6
Training loss: 1.720578833257534
Validation loss: 2.344361121787078

Epoch: 5| Step: 7
Training loss: 2.2346387587438103
Validation loss: 2.3948224953211747

Epoch: 5| Step: 8
Training loss: 2.053590430888524
Validation loss: 2.335575110906373

Epoch: 5| Step: 9
Training loss: 1.7449490680202506
Validation loss: 2.3391766124106366

Epoch: 5| Step: 10
Training loss: 1.4945130127244248
Validation loss: 2.3670882234644277

Epoch: 253| Step: 0
Training loss: 1.7093229296353278
Validation loss: 2.4039370177191928

Epoch: 5| Step: 1
Training loss: 1.8088034061332328
Validation loss: 2.3886521421551876

Epoch: 5| Step: 2
Training loss: 1.5721255032669819
Validation loss: 2.4035495872152204

Epoch: 5| Step: 3
Training loss: 1.5188541423742752
Validation loss: 2.3657769974164538

Epoch: 5| Step: 4
Training loss: 1.8239485808118485
Validation loss: 2.465574061004027

Epoch: 5| Step: 5
Training loss: 1.2432347807206776
Validation loss: 2.415532001335894

Epoch: 5| Step: 6
Training loss: 1.8389609905998876
Validation loss: 2.4919815063209074

Epoch: 5| Step: 7
Training loss: 2.1327989738510538
Validation loss: 2.4465834806927123

Epoch: 5| Step: 8
Training loss: 1.8306735280365154
Validation loss: 2.4664553342494595

Epoch: 5| Step: 9
Training loss: 1.6118939879986347
Validation loss: 2.375441625108016

Epoch: 5| Step: 10
Training loss: 2.087195542113404
Validation loss: 2.3935321651447796

Epoch: 254| Step: 0
Training loss: 2.0666226884818264
Validation loss: 2.3659697846236627

Epoch: 5| Step: 1
Training loss: 1.5709083147982243
Validation loss: 2.3928510237780256

Epoch: 5| Step: 2
Training loss: 1.6371398966626238
Validation loss: 2.39540312775876

Epoch: 5| Step: 3
Training loss: 1.7411960124062382
Validation loss: 2.373108771981379

Epoch: 5| Step: 4
Training loss: 1.369023381980246
Validation loss: 2.4288099434771557

Epoch: 5| Step: 5
Training loss: 1.8676556754432496
Validation loss: 2.3957354293301245

Epoch: 5| Step: 6
Training loss: 1.870406054305695
Validation loss: 2.4216176563504033

Epoch: 5| Step: 7
Training loss: 2.0512738898616214
Validation loss: 2.3945059157099293

Epoch: 5| Step: 8
Training loss: 1.6843199966877034
Validation loss: 2.386346726965138

Epoch: 5| Step: 9
Training loss: 1.2318626622279403
Validation loss: 2.374365910293448

Epoch: 5| Step: 10
Training loss: 1.7455093805503055
Validation loss: 2.371268390763215

Epoch: 255| Step: 0
Training loss: 1.60193931054589
Validation loss: 2.372958754684159

Epoch: 5| Step: 1
Training loss: 1.9578085324672676
Validation loss: 2.385586284176384

Epoch: 5| Step: 2
Training loss: 1.5520494017849609
Validation loss: 2.4192811040341162

Epoch: 5| Step: 3
Training loss: 1.350747143660679
Validation loss: 2.3804797845325814

Epoch: 5| Step: 4
Training loss: 1.6281761527491745
Validation loss: 2.3604329869212126

Epoch: 5| Step: 5
Training loss: 1.2820858903639747
Validation loss: 2.3808476952349227

Epoch: 5| Step: 6
Training loss: 1.692785674064461
Validation loss: 2.3833838466583788

Epoch: 5| Step: 7
Training loss: 1.731695287294777
Validation loss: 2.3825174720250133

Epoch: 5| Step: 8
Training loss: 1.904689587911912
Validation loss: 2.3821495071165733

Epoch: 5| Step: 9
Training loss: 2.1646817970338432
Validation loss: 2.3805430664675424

Epoch: 5| Step: 10
Training loss: 2.1073697201247303
Validation loss: 2.3622469450355705

Epoch: 256| Step: 0
Training loss: 2.0708267436955667
Validation loss: 2.39498112427913

Epoch: 5| Step: 1
Training loss: 2.3514564464898706
Validation loss: 2.394421869962291

Epoch: 5| Step: 2
Training loss: 1.4464902460987132
Validation loss: 2.3934308740482604

Epoch: 5| Step: 3
Training loss: 1.4827814482803114
Validation loss: 2.334037272085189

Epoch: 5| Step: 4
Training loss: 1.778645937590552
Validation loss: 2.422663241436236

Epoch: 5| Step: 5
Training loss: 1.576947518887499
Validation loss: 2.3829644170728614

Epoch: 5| Step: 6
Training loss: 1.3990222411661173
Validation loss: 2.38573976703584

Epoch: 5| Step: 7
Training loss: 1.9716307741231887
Validation loss: 2.376446941083133

Epoch: 5| Step: 8
Training loss: 1.84499013541461
Validation loss: 2.397070553391719

Epoch: 5| Step: 9
Training loss: 1.4147075214658733
Validation loss: 2.3678617905659007

Epoch: 5| Step: 10
Training loss: 1.5441007300660323
Validation loss: 2.3929832430604576

Epoch: 257| Step: 0
Training loss: 2.119120598623691
Validation loss: 2.384360680491244

Epoch: 5| Step: 1
Training loss: 1.6399475152060858
Validation loss: 2.3817481644289553

Epoch: 5| Step: 2
Training loss: 1.8412206077948952
Validation loss: 2.4085876494781795

Epoch: 5| Step: 3
Training loss: 1.2624767376862247
Validation loss: 2.3508536653961545

Epoch: 5| Step: 4
Training loss: 2.0638802273914973
Validation loss: 2.4744283781199368

Epoch: 5| Step: 5
Training loss: 1.3585866637261732
Validation loss: 2.3534260985323763

Epoch: 5| Step: 6
Training loss: 1.6907850715037733
Validation loss: 2.3693061649516545

Epoch: 5| Step: 7
Training loss: 1.9645075425070937
Validation loss: 2.442915379088133

Epoch: 5| Step: 8
Training loss: 1.495155219373608
Validation loss: 2.389028609070233

Epoch: 5| Step: 9
Training loss: 1.2244037656340445
Validation loss: 2.3999849114747005

Epoch: 5| Step: 10
Training loss: 1.8330199739665487
Validation loss: 2.376579479434563

Epoch: 258| Step: 0
Training loss: 1.8765478103405782
Validation loss: 2.37103480083842

Epoch: 5| Step: 1
Training loss: 1.491418610447159
Validation loss: 2.365364589287144

Epoch: 5| Step: 2
Training loss: 1.8439773807296824
Validation loss: 2.406300107798846

Epoch: 5| Step: 3
Training loss: 1.3515927085367072
Validation loss: 2.3763961585023714

Epoch: 5| Step: 4
Training loss: 1.2165316419707863
Validation loss: 2.421589354289971

Epoch: 5| Step: 5
Training loss: 1.7189821953420088
Validation loss: 2.3726525938651

Epoch: 5| Step: 6
Training loss: 1.4018183071800763
Validation loss: 2.3696273142714195

Epoch: 5| Step: 7
Training loss: 2.2873477697529294
Validation loss: 2.352168432375669

Epoch: 5| Step: 8
Training loss: 1.3083856673413976
Validation loss: 2.367060951389781

Epoch: 5| Step: 9
Training loss: 1.8659905463712105
Validation loss: 2.357076621637656

Epoch: 5| Step: 10
Training loss: 2.3493182349952093
Validation loss: 2.3648736871328406

Epoch: 259| Step: 0
Training loss: 1.3416338825761682
Validation loss: 2.426433374451379

Epoch: 5| Step: 1
Training loss: 1.4315994902109719
Validation loss: 2.336357258696799

Epoch: 5| Step: 2
Training loss: 1.666889851249728
Validation loss: 2.406845524084064

Epoch: 5| Step: 3
Training loss: 1.4929539175210025
Validation loss: 2.390106691895045

Epoch: 5| Step: 4
Training loss: 1.6529941586381427
Validation loss: 2.4374407336926205

Epoch: 5| Step: 5
Training loss: 2.2298514719539275
Validation loss: 2.383050371384204

Epoch: 5| Step: 6
Training loss: 2.125248389593146
Validation loss: 2.415961372333448

Epoch: 5| Step: 7
Training loss: 1.9141676270556278
Validation loss: 2.3526046945988206

Epoch: 5| Step: 8
Training loss: 1.2617514874725613
Validation loss: 2.3710377407086254

Epoch: 5| Step: 9
Training loss: 1.8086570250810405
Validation loss: 2.432147229653418

Epoch: 5| Step: 10
Training loss: 1.4839816726776445
Validation loss: 2.403358706742197

Epoch: 260| Step: 0
Training loss: 1.2968310153350358
Validation loss: 2.445382705462244

Epoch: 5| Step: 1
Training loss: 1.8862770463889027
Validation loss: 2.3599311821204068

Epoch: 5| Step: 2
Training loss: 1.475781027055262
Validation loss: 2.3726531622057063

Epoch: 5| Step: 3
Training loss: 1.3663882289808278
Validation loss: 2.41655277822593

Epoch: 5| Step: 4
Training loss: 1.91532302144018
Validation loss: 2.374145319485809

Epoch: 5| Step: 5
Training loss: 2.2646937067624
Validation loss: 2.390023601096403

Epoch: 5| Step: 6
Training loss: 1.9778781779066688
Validation loss: 2.3970314472067336

Epoch: 5| Step: 7
Training loss: 1.7736753060634045
Validation loss: 2.4033326676118767

Epoch: 5| Step: 8
Training loss: 2.130845053228681
Validation loss: 2.4095376531628703

Epoch: 5| Step: 9
Training loss: 1.5163859394016306
Validation loss: 2.416184290932233

Epoch: 5| Step: 10
Training loss: 0.9198872100065344
Validation loss: 2.354808218662086

Epoch: 261| Step: 0
Training loss: 2.478637211359724
Validation loss: 2.3687935287732045

Epoch: 5| Step: 1
Training loss: 1.5090940099393944
Validation loss: 2.3762505821932502

Epoch: 5| Step: 2
Training loss: 1.6878315635187957
Validation loss: 2.3686084806881738

Epoch: 5| Step: 3
Training loss: 1.3904574003912729
Validation loss: 2.4264363185175024

Epoch: 5| Step: 4
Training loss: 1.5582332337540992
Validation loss: 2.418555444162214

Epoch: 5| Step: 5
Training loss: 1.1562716507817752
Validation loss: 2.3972762832354273

Epoch: 5| Step: 6
Training loss: 1.6280540963400882
Validation loss: 2.4267112594262255

Epoch: 5| Step: 7
Training loss: 1.695524633117844
Validation loss: 2.469104210274708

Epoch: 5| Step: 8
Training loss: 1.8755665241139683
Validation loss: 2.3666165924869857

Epoch: 5| Step: 9
Training loss: 1.4732983552799666
Validation loss: 2.392636193011741

Epoch: 5| Step: 10
Training loss: 1.9315424355139186
Validation loss: 2.3781057521324707

Epoch: 262| Step: 0
Training loss: 1.5547985248123917
Validation loss: 2.3670757804365827

Epoch: 5| Step: 1
Training loss: 1.5213256283018046
Validation loss: 2.3871798725001296

Epoch: 5| Step: 2
Training loss: 1.6426547618863943
Validation loss: 2.3913299300838484

Epoch: 5| Step: 3
Training loss: 1.7761198755609575
Validation loss: 2.385416576748929

Epoch: 5| Step: 4
Training loss: 1.7454882773161695
Validation loss: 2.4140571370901376

Epoch: 5| Step: 5
Training loss: 1.8965598031472835
Validation loss: 2.429032307735819

Epoch: 5| Step: 6
Training loss: 1.842261796768318
Validation loss: 2.4149815098090275

Epoch: 5| Step: 7
Training loss: 2.1936842558048912
Validation loss: 2.3468293686483235

Epoch: 5| Step: 8
Training loss: 1.344433145085887
Validation loss: 2.39476424159695

Epoch: 5| Step: 9
Training loss: 2.213490982971369
Validation loss: 2.4596743887767145

Epoch: 5| Step: 10
Training loss: 0.9817477087776603
Validation loss: 2.4138159021453327

Epoch: 263| Step: 0
Training loss: 1.4632554051468691
Validation loss: 2.4442546262094274

Epoch: 5| Step: 1
Training loss: 1.8206547100289596
Validation loss: 2.4069316193186516

Epoch: 5| Step: 2
Training loss: 1.8556320600417096
Validation loss: 2.403892273989756

Epoch: 5| Step: 3
Training loss: 1.8192670054540618
Validation loss: 2.4045202640740997

Epoch: 5| Step: 4
Training loss: 1.7493517219872763
Validation loss: 2.3849490701029863

Epoch: 5| Step: 5
Training loss: 1.4540596693984125
Validation loss: 2.398449877592477

Epoch: 5| Step: 6
Training loss: 1.4360416312332773
Validation loss: 2.43528757375227

Epoch: 5| Step: 7
Training loss: 2.150066631970186
Validation loss: 2.3454823775466527

Epoch: 5| Step: 8
Training loss: 1.5780616974173451
Validation loss: 2.3765969695781375

Epoch: 5| Step: 9
Training loss: 1.8102121712480812
Validation loss: 2.3987501877921864

Epoch: 5| Step: 10
Training loss: 1.3631948099358802
Validation loss: 2.3484046071829847

Epoch: 264| Step: 0
Training loss: 1.7261963883347264
Validation loss: 2.4094771420666987

Epoch: 5| Step: 1
Training loss: 1.8782014218743903
Validation loss: 2.4131008077401583

Epoch: 5| Step: 2
Training loss: 1.2416304772925493
Validation loss: 2.372581695548238

Epoch: 5| Step: 3
Training loss: 2.1034864956708144
Validation loss: 2.4059238316653913

Epoch: 5| Step: 4
Training loss: 1.131268889970236
Validation loss: 2.3868570324119194

Epoch: 5| Step: 5
Training loss: 2.235588437816666
Validation loss: 2.3750131193272526

Epoch: 5| Step: 6
Training loss: 1.479193548397026
Validation loss: 2.382241639401063

Epoch: 5| Step: 7
Training loss: 1.7738785384355702
Validation loss: 2.3368677952384576

Epoch: 5| Step: 8
Training loss: 1.6798993354111633
Validation loss: 2.3786076604285213

Epoch: 5| Step: 9
Training loss: 1.5195313284513556
Validation loss: 2.3889264528248577

Epoch: 5| Step: 10
Training loss: 1.227150842766573
Validation loss: 2.4163518745878987

Epoch: 265| Step: 0
Training loss: 1.5834597319628316
Validation loss: 2.3484937192300483

Epoch: 5| Step: 1
Training loss: 1.4644168486010651
Validation loss: 2.4023695821546256

Epoch: 5| Step: 2
Training loss: 2.010190512894816
Validation loss: 2.3958689315598063

Epoch: 5| Step: 3
Training loss: 1.5108828734944424
Validation loss: 2.3827402637492225

Epoch: 5| Step: 4
Training loss: 1.7636157731335251
Validation loss: 2.4133161806287795

Epoch: 5| Step: 5
Training loss: 1.4179320107316482
Validation loss: 2.3812300289161605

Epoch: 5| Step: 6
Training loss: 1.7292116304855782
Validation loss: 2.4051157751659322

Epoch: 5| Step: 7
Training loss: 1.7202955059767817
Validation loss: 2.4065650730467727

Epoch: 5| Step: 8
Training loss: 1.6876840844237226
Validation loss: 2.3438642270271743

Epoch: 5| Step: 9
Training loss: 1.7740290659229634
Validation loss: 2.38592862087273

Epoch: 5| Step: 10
Training loss: 1.9920636905270095
Validation loss: 2.4129107853731178

Epoch: 266| Step: 0
Training loss: 2.2713016295456465
Validation loss: 2.403486583034126

Epoch: 5| Step: 1
Training loss: 1.3083888106925148
Validation loss: 2.4237685048185464

Epoch: 5| Step: 2
Training loss: 1.8074088447979966
Validation loss: 2.4032149815922956

Epoch: 5| Step: 3
Training loss: 1.750291595688311
Validation loss: 2.441354200764056

Epoch: 5| Step: 4
Training loss: 1.537538577580484
Validation loss: 2.3903455737838404

Epoch: 5| Step: 5
Training loss: 1.4881911363128304
Validation loss: 2.4181742354128053

Epoch: 5| Step: 6
Training loss: 2.1726044452174027
Validation loss: 2.451457048924315

Epoch: 5| Step: 7
Training loss: 1.3051819920704264
Validation loss: 2.369993401159914

Epoch: 5| Step: 8
Training loss: 1.5244501905051864
Validation loss: 2.3487878734905583

Epoch: 5| Step: 9
Training loss: 1.6819407409044786
Validation loss: 2.380858096872328

Epoch: 5| Step: 10
Training loss: 1.6045540758805628
Validation loss: 2.398434434451683

Epoch: 267| Step: 0
Training loss: 1.2844509984013837
Validation loss: 2.3856353946076028

Epoch: 5| Step: 1
Training loss: 1.5436325769901855
Validation loss: 2.3527519568259843

Epoch: 5| Step: 2
Training loss: 1.5565143376029185
Validation loss: 2.3687843977630654

Epoch: 5| Step: 3
Training loss: 1.5939799124242935
Validation loss: 2.388528468477818

Epoch: 5| Step: 4
Training loss: 1.8232942317324294
Validation loss: 2.418567504679782

Epoch: 5| Step: 5
Training loss: 1.490293409145668
Validation loss: 2.3681430480721537

Epoch: 5| Step: 6
Training loss: 1.6280050368969203
Validation loss: 2.385492993065239

Epoch: 5| Step: 7
Training loss: 1.8393122397320885
Validation loss: 2.419138596417843

Epoch: 5| Step: 8
Training loss: 2.2560796192539585
Validation loss: 2.379520194988286

Epoch: 5| Step: 9
Training loss: 1.5448313613013653
Validation loss: 2.397471297000098

Epoch: 5| Step: 10
Training loss: 1.4972952457864848
Validation loss: 2.419693905287043

Epoch: 268| Step: 0
Training loss: 1.5623162733779365
Validation loss: 2.3526245124008303

Epoch: 5| Step: 1
Training loss: 1.8152955956311418
Validation loss: 2.3875634309391236

Epoch: 5| Step: 2
Training loss: 1.5623786879176342
Validation loss: 2.409142920501763

Epoch: 5| Step: 3
Training loss: 1.8902156796588192
Validation loss: 2.403110042384495

Epoch: 5| Step: 4
Training loss: 1.8364122142255102
Validation loss: 2.3996144195223335

Epoch: 5| Step: 5
Training loss: 1.7384090076602885
Validation loss: 2.3844261242548637

Epoch: 5| Step: 6
Training loss: 1.6488301320302137
Validation loss: 2.4027864699362875

Epoch: 5| Step: 7
Training loss: 1.6167954416538253
Validation loss: 2.4096807711310904

Epoch: 5| Step: 8
Training loss: 1.4188658343514697
Validation loss: 2.3568497429673005

Epoch: 5| Step: 9
Training loss: 1.5804976954239696
Validation loss: 2.425859788175421

Epoch: 5| Step: 10
Training loss: 1.5126314783880443
Validation loss: 2.4039447674839876

Epoch: 269| Step: 0
Training loss: 1.4129895518133282
Validation loss: 2.3782272292531363

Epoch: 5| Step: 1
Training loss: 1.6021316633470606
Validation loss: 2.387238378954515

Epoch: 5| Step: 2
Training loss: 2.3804721032254545
Validation loss: 2.38577693445646

Epoch: 5| Step: 3
Training loss: 1.4767409928232653
Validation loss: 2.3757688511636

Epoch: 5| Step: 4
Training loss: 1.9665146504934736
Validation loss: 2.415487745151291

Epoch: 5| Step: 5
Training loss: 1.3758599886438792
Validation loss: 2.3742699399652145

Epoch: 5| Step: 6
Training loss: 1.4712157147738678
Validation loss: 2.4035595503620892

Epoch: 5| Step: 7
Training loss: 2.2413807125238945
Validation loss: 2.3788172221623047

Epoch: 5| Step: 8
Training loss: 1.3389970422901538
Validation loss: 2.356927173582075

Epoch: 5| Step: 9
Training loss: 1.3951386483314974
Validation loss: 2.403857633179926

Epoch: 5| Step: 10
Training loss: 1.4423284294398282
Validation loss: 2.4010042111065846

Epoch: 270| Step: 0
Training loss: 1.4869967947837492
Validation loss: 2.413594054274407

Epoch: 5| Step: 1
Training loss: 2.11620924755499
Validation loss: 2.4020156050645087

Epoch: 5| Step: 2
Training loss: 2.2679023609437894
Validation loss: 2.3907893987110986

Epoch: 5| Step: 3
Training loss: 1.1659045909366839
Validation loss: 2.3458337382264127

Epoch: 5| Step: 4
Training loss: 1.605143938829653
Validation loss: 2.3864434454059404

Epoch: 5| Step: 5
Training loss: 1.3062244431035228
Validation loss: 2.413569285468476

Epoch: 5| Step: 6
Training loss: 1.852309000050502
Validation loss: 2.4311385841188597

Epoch: 5| Step: 7
Training loss: 1.6275640213147973
Validation loss: 2.3563721531647994

Epoch: 5| Step: 8
Training loss: 1.673215382257641
Validation loss: 2.4171712714182085

Epoch: 5| Step: 9
Training loss: 1.3477659319044046
Validation loss: 2.4114963639501465

Epoch: 5| Step: 10
Training loss: 1.762026808505538
Validation loss: 2.4198583234880986

Epoch: 271| Step: 0
Training loss: 0.9986670670434262
Validation loss: 2.3496713089455636

Epoch: 5| Step: 1
Training loss: 1.3706756562953697
Validation loss: 2.3748948052883474

Epoch: 5| Step: 2
Training loss: 1.9778415326166328
Validation loss: 2.4695793930026126

Epoch: 5| Step: 3
Training loss: 1.2109527094716461
Validation loss: 2.3920486343124607

Epoch: 5| Step: 4
Training loss: 2.1895958805420395
Validation loss: 2.4266574180827503

Epoch: 5| Step: 5
Training loss: 1.8028403733522667
Validation loss: 2.4039683600158304

Epoch: 5| Step: 6
Training loss: 1.7508871690745684
Validation loss: 2.399603135527773

Epoch: 5| Step: 7
Training loss: 1.6100093739396626
Validation loss: 2.398683026152205

Epoch: 5| Step: 8
Training loss: 1.977449481960243
Validation loss: 2.4198108653493593

Epoch: 5| Step: 9
Training loss: 1.5640778013961423
Validation loss: 2.359292021065527

Epoch: 5| Step: 10
Training loss: 1.4958419388689106
Validation loss: 2.376458755747269

Epoch: 272| Step: 0
Training loss: 1.5568286968805092
Validation loss: 2.3391098166184756

Epoch: 5| Step: 1
Training loss: 1.744272190783354
Validation loss: 2.394234702208665

Epoch: 5| Step: 2
Training loss: 1.9020272682954888
Validation loss: 2.382106339211797

Epoch: 5| Step: 3
Training loss: 1.6175247061963658
Validation loss: 2.380421616524248

Epoch: 5| Step: 4
Training loss: 1.461286207391738
Validation loss: 2.4468117263465237

Epoch: 5| Step: 5
Training loss: 1.133158558571092
Validation loss: 2.390897646970327

Epoch: 5| Step: 6
Training loss: 1.7347259166478988
Validation loss: 2.3797015429699244

Epoch: 5| Step: 7
Training loss: 1.8798306227536326
Validation loss: 2.432802347010864

Epoch: 5| Step: 8
Training loss: 1.9558259522675718
Validation loss: 2.3440011691798515

Epoch: 5| Step: 9
Training loss: 1.8604378107057655
Validation loss: 2.3970107671404715

Epoch: 5| Step: 10
Training loss: 1.730303134269369
Validation loss: 2.3995140839107862

Epoch: 273| Step: 0
Training loss: 1.7997777298281248
Validation loss: 2.4234337486810937

Epoch: 5| Step: 1
Training loss: 1.7692998267414566
Validation loss: 2.402806322496987

Epoch: 5| Step: 2
Training loss: 1.7620087446240418
Validation loss: 2.3881720705711014

Epoch: 5| Step: 3
Training loss: 1.4804154439302493
Validation loss: 2.348207557909525

Epoch: 5| Step: 4
Training loss: 1.436698026440228
Validation loss: 2.4026330180957247

Epoch: 5| Step: 5
Training loss: 1.3857784468118908
Validation loss: 2.367327094391344

Epoch: 5| Step: 6
Training loss: 1.615692774754848
Validation loss: 2.3847240240017324

Epoch: 5| Step: 7
Training loss: 1.9361113217008754
Validation loss: 2.3980445070878775

Epoch: 5| Step: 8
Training loss: 1.5046994978286758
Validation loss: 2.3922773143393803

Epoch: 5| Step: 9
Training loss: 1.6946468892437836
Validation loss: 2.3239677814185264

Epoch: 5| Step: 10
Training loss: 1.9828865295971458
Validation loss: 2.3471927048345615

Epoch: 274| Step: 0
Training loss: 1.8542183286634728
Validation loss: 2.4026358280727855

Epoch: 5| Step: 1
Training loss: 1.5605552778149088
Validation loss: 2.4027665547947685

Epoch: 5| Step: 2
Training loss: 1.5249727778272022
Validation loss: 2.4322543381915698

Epoch: 5| Step: 3
Training loss: 1.821670091468172
Validation loss: 2.377648210784166

Epoch: 5| Step: 4
Training loss: 1.8366778889617263
Validation loss: 2.3877093326812853

Epoch: 5| Step: 5
Training loss: 1.4412474506021469
Validation loss: 2.338666539330066

Epoch: 5| Step: 6
Training loss: 1.694324750615987
Validation loss: 2.357851623899035

Epoch: 5| Step: 7
Training loss: 1.7341025198578779
Validation loss: 2.3549100480959164

Epoch: 5| Step: 8
Training loss: 1.388460339022008
Validation loss: 2.3745056073855553

Epoch: 5| Step: 9
Training loss: 1.6137881464036035
Validation loss: 2.3728541366282836

Epoch: 5| Step: 10
Training loss: 1.3577764034411697
Validation loss: 2.372038166132603

Epoch: 275| Step: 0
Training loss: 1.5487014314611498
Validation loss: 2.362072854471709

Epoch: 5| Step: 1
Training loss: 1.8310702473297216
Validation loss: 2.4314154299797717

Epoch: 5| Step: 2
Training loss: 1.681213820965138
Validation loss: 2.424880547642504

Epoch: 5| Step: 3
Training loss: 1.457634113350995
Validation loss: 2.3087613571176093

Epoch: 5| Step: 4
Training loss: 1.6283628440116817
Validation loss: 2.425709671370834

Epoch: 5| Step: 5
Training loss: 2.016330565931797
Validation loss: 2.3746632389587328

Epoch: 5| Step: 6
Training loss: 1.5357229337100247
Validation loss: 2.391480467262148

Epoch: 5| Step: 7
Training loss: 1.6766166827573525
Validation loss: 2.3969234069718404

Epoch: 5| Step: 8
Training loss: 1.5186056343192131
Validation loss: 2.39233516783013

Epoch: 5| Step: 9
Training loss: 1.3039194918920645
Validation loss: 2.3894117508438

Epoch: 5| Step: 10
Training loss: 1.6874114119270993
Validation loss: 2.4302905801896126

Epoch: 276| Step: 0
Training loss: 1.6670978783040746
Validation loss: 2.454303262803022

Epoch: 5| Step: 1
Training loss: 1.6141358114249895
Validation loss: 2.440321992832284

Epoch: 5| Step: 2
Training loss: 1.1805053301330986
Validation loss: 2.334614845317339

Epoch: 5| Step: 3
Training loss: 1.4463916770495155
Validation loss: 2.3807223282406262

Epoch: 5| Step: 4
Training loss: 1.9676852904613515
Validation loss: 2.3780434952432015

Epoch: 5| Step: 5
Training loss: 1.6308715819855653
Validation loss: 2.392910450333423

Epoch: 5| Step: 6
Training loss: 1.9319784179571966
Validation loss: 2.379707498249376

Epoch: 5| Step: 7
Training loss: 1.88220337951133
Validation loss: 2.412578258831624

Epoch: 5| Step: 8
Training loss: 1.5061962577128012
Validation loss: 2.383790292811933

Epoch: 5| Step: 9
Training loss: 1.4511362228018725
Validation loss: 2.3529679305287083

Epoch: 5| Step: 10
Training loss: 1.326361708614991
Validation loss: 2.3518940545335503

Epoch: 277| Step: 0
Training loss: 1.4101234495622612
Validation loss: 2.379686687025145

Epoch: 5| Step: 1
Training loss: 1.5110301733936373
Validation loss: 2.3530822929574144

Epoch: 5| Step: 2
Training loss: 1.779163276019949
Validation loss: 2.3596224558309644

Epoch: 5| Step: 3
Training loss: 1.651890036333736
Validation loss: 2.3095995898752997

Epoch: 5| Step: 4
Training loss: 1.7637991452686623
Validation loss: 2.4543962823292955

Epoch: 5| Step: 5
Training loss: 1.6097928588014954
Validation loss: 2.415527676472909

Epoch: 5| Step: 6
Training loss: 1.6922398158446201
Validation loss: 2.3773596536942696

Epoch: 5| Step: 7
Training loss: 1.7215905039294956
Validation loss: 2.414633522261313

Epoch: 5| Step: 8
Training loss: 1.3308583574484296
Validation loss: 2.3701969536237955

Epoch: 5| Step: 9
Training loss: 2.0609870910462367
Validation loss: 2.412914947056911

Epoch: 5| Step: 10
Training loss: 1.2756342282818844
Validation loss: 2.4096903695476213

Epoch: 278| Step: 0
Training loss: 2.248233101403649
Validation loss: 2.4491305268557895

Epoch: 5| Step: 1
Training loss: 1.339742317475225
Validation loss: 2.4150310776449975

Epoch: 5| Step: 2
Training loss: 2.0421350940847853
Validation loss: 2.4244456461975417

Epoch: 5| Step: 3
Training loss: 1.035743000074079
Validation loss: 2.429227288097846

Epoch: 5| Step: 4
Training loss: 1.6580059172383221
Validation loss: 2.3715691118425717

Epoch: 5| Step: 5
Training loss: 1.9033628393425956
Validation loss: 2.4279458111434904

Epoch: 5| Step: 6
Training loss: 1.4870224482644692
Validation loss: 2.3798391009506283

Epoch: 5| Step: 7
Training loss: 1.2494975987747523
Validation loss: 2.432154011496495

Epoch: 5| Step: 8
Training loss: 1.514495349971349
Validation loss: 2.4306964639660236

Epoch: 5| Step: 9
Training loss: 1.6365655722670303
Validation loss: 2.3869103355361196

Epoch: 5| Step: 10
Training loss: 1.4646366227260088
Validation loss: 2.3835283715354914

Epoch: 279| Step: 0
Training loss: 1.6724699869014636
Validation loss: 2.39099495491844

Epoch: 5| Step: 1
Training loss: 1.3659831382721692
Validation loss: 2.4390580236093475

Epoch: 5| Step: 2
Training loss: 1.256355721499326
Validation loss: 2.416657429409796

Epoch: 5| Step: 3
Training loss: 1.5332169647564058
Validation loss: 2.366114275604362

Epoch: 5| Step: 4
Training loss: 1.2814225336534955
Validation loss: 2.3539909960075107

Epoch: 5| Step: 5
Training loss: 1.2606575107874065
Validation loss: 2.328092284825084

Epoch: 5| Step: 6
Training loss: 2.0504424478323107
Validation loss: 2.3304007815785583

Epoch: 5| Step: 7
Training loss: 2.0057037798327304
Validation loss: 2.386042514466508

Epoch: 5| Step: 8
Training loss: 1.8164737811917238
Validation loss: 2.384726250917318

Epoch: 5| Step: 9
Training loss: 1.8693742914941402
Validation loss: 2.403617168560407

Epoch: 5| Step: 10
Training loss: 1.4818118804270026
Validation loss: 2.3682858390185513

Epoch: 280| Step: 0
Training loss: 1.7359654462952887
Validation loss: 2.4015456549278222

Epoch: 5| Step: 1
Training loss: 1.3363317610561007
Validation loss: 2.3700223388335604

Epoch: 5| Step: 2
Training loss: 1.4884974205038306
Validation loss: 2.4532629532982364

Epoch: 5| Step: 3
Training loss: 1.811000203453318
Validation loss: 2.3683405559820763

Epoch: 5| Step: 4
Training loss: 1.696220892907348
Validation loss: 2.3891440945457476

Epoch: 5| Step: 5
Training loss: 1.3815394861996204
Validation loss: 2.4271822043151587

Epoch: 5| Step: 6
Training loss: 2.205968334167859
Validation loss: 2.404448281222794

Epoch: 5| Step: 7
Training loss: 1.3452258765569576
Validation loss: 2.373255854019204

Epoch: 5| Step: 8
Training loss: 1.5416673797743239
Validation loss: 2.409681394571853

Epoch: 5| Step: 9
Training loss: 1.611467057220708
Validation loss: 2.3618154374830245

Epoch: 5| Step: 10
Training loss: 1.6329615036724523
Validation loss: 2.3809623368592727

Epoch: 281| Step: 0
Training loss: 1.4204325643052433
Validation loss: 2.4235368185561237

Epoch: 5| Step: 1
Training loss: 1.5197993730851227
Validation loss: 2.4103828036900663

Epoch: 5| Step: 2
Training loss: 1.640321976061452
Validation loss: 2.411122288413456

Epoch: 5| Step: 3
Training loss: 1.6491947694568279
Validation loss: 2.33719064427804

Epoch: 5| Step: 4
Training loss: 2.2908579584294313
Validation loss: 2.381481980107185

Epoch: 5| Step: 5
Training loss: 1.578593873725621
Validation loss: 2.413213584644776

Epoch: 5| Step: 6
Training loss: 1.7737050799864258
Validation loss: 2.4062981666631136

Epoch: 5| Step: 7
Training loss: 1.6605090675186833
Validation loss: 2.4278060137854154

Epoch: 5| Step: 8
Training loss: 1.5616947387864635
Validation loss: 2.3643431842199294

Epoch: 5| Step: 9
Training loss: 1.5170540905175096
Validation loss: 2.3761687120653177

Epoch: 5| Step: 10
Training loss: 1.2532846686793728
Validation loss: 2.433829460131787

Epoch: 282| Step: 0
Training loss: 1.4064960688303156
Validation loss: 2.375000513807499

Epoch: 5| Step: 1
Training loss: 1.2588778420829945
Validation loss: 2.415396134321069

Epoch: 5| Step: 2
Training loss: 1.615692848536998
Validation loss: 2.4930415387955054

Epoch: 5| Step: 3
Training loss: 1.6189139912728274
Validation loss: 2.460774563345115

Epoch: 5| Step: 4
Training loss: 2.083290163228666
Validation loss: 2.4203372875432443

Epoch: 5| Step: 5
Training loss: 1.2449762481507318
Validation loss: 2.461724362071278

Epoch: 5| Step: 6
Training loss: 1.8689285524732822
Validation loss: 2.4203341459302554

Epoch: 5| Step: 7
Training loss: 1.847229019031433
Validation loss: 2.427528570950814

Epoch: 5| Step: 8
Training loss: 1.3309351194977996
Validation loss: 2.3959734226126232

Epoch: 5| Step: 9
Training loss: 1.3242878853634177
Validation loss: 2.401104956369704

Epoch: 5| Step: 10
Training loss: 1.3665625315434373
Validation loss: 2.4313732859664547

Epoch: 283| Step: 0
Training loss: 1.9735931286793107
Validation loss: 2.305197836781849

Epoch: 5| Step: 1
Training loss: 1.5973626872047177
Validation loss: 2.3862509537822043

Epoch: 5| Step: 2
Training loss: 1.5030824460927608
Validation loss: 2.3931359542477577

Epoch: 5| Step: 3
Training loss: 1.3450672878748977
Validation loss: 2.3510772457330558

Epoch: 5| Step: 4
Training loss: 2.0445334749716233
Validation loss: 2.4249483580651803

Epoch: 5| Step: 5
Training loss: 1.5506424157096004
Validation loss: 2.371164124649956

Epoch: 5| Step: 6
Training loss: 1.6989887651921856
Validation loss: 2.3764987236560744

Epoch: 5| Step: 7
Training loss: 1.5322656960774963
Validation loss: 2.3883193015801782

Epoch: 5| Step: 8
Training loss: 1.4131252913409358
Validation loss: 2.377230852952496

Epoch: 5| Step: 9
Training loss: 1.6542246689064053
Validation loss: 2.336849121325734

Epoch: 5| Step: 10
Training loss: 1.3369939096150885
Validation loss: 2.380582974419508

Epoch: 284| Step: 0
Training loss: 1.0433729438656365
Validation loss: 2.39125937432897

Epoch: 5| Step: 1
Training loss: 1.5205647305399277
Validation loss: 2.352394956086717

Epoch: 5| Step: 2
Training loss: 1.8734446750532106
Validation loss: 2.390473695240706

Epoch: 5| Step: 3
Training loss: 1.4014032551978746
Validation loss: 2.3481300188134786

Epoch: 5| Step: 4
Training loss: 1.259601765702925
Validation loss: 2.3659297905475616

Epoch: 5| Step: 5
Training loss: 2.152332783582827
Validation loss: 2.4368581878714477

Epoch: 5| Step: 6
Training loss: 1.810232058976302
Validation loss: 2.3565167283900736

Epoch: 5| Step: 7
Training loss: 1.4406842333352108
Validation loss: 2.4223119272124127

Epoch: 5| Step: 8
Training loss: 1.2471371291504554
Validation loss: 2.3805668446143566

Epoch: 5| Step: 9
Training loss: 1.6331338520591185
Validation loss: 2.3963768540931025

Epoch: 5| Step: 10
Training loss: 1.8791765744215243
Validation loss: 2.3785819851657006

Epoch: 285| Step: 0
Training loss: 1.345030064016381
Validation loss: 2.3451514196421592

Epoch: 5| Step: 1
Training loss: 1.9145903813090919
Validation loss: 2.3572894405799842

Epoch: 5| Step: 2
Training loss: 2.1338578900512757
Validation loss: 2.4487899423475827

Epoch: 5| Step: 3
Training loss: 1.3326631540608704
Validation loss: 2.447223979173078

Epoch: 5| Step: 4
Training loss: 1.5288680097644558
Validation loss: 2.3820054028033746

Epoch: 5| Step: 5
Training loss: 1.62560305042694
Validation loss: 2.4544157352001834

Epoch: 5| Step: 6
Training loss: 1.2898034942648238
Validation loss: 2.4232704114781614

Epoch: 5| Step: 7
Training loss: 1.515431971891805
Validation loss: 2.419487654123593

Epoch: 5| Step: 8
Training loss: 1.763618206504517
Validation loss: 2.363048457727471

Epoch: 5| Step: 9
Training loss: 1.2760938309367849
Validation loss: 2.4033873397529337

Epoch: 5| Step: 10
Training loss: 1.9051170734665865
Validation loss: 2.3909558029729077

Epoch: 286| Step: 0
Training loss: 1.4850846050064284
Validation loss: 2.383205222896004

Epoch: 5| Step: 1
Training loss: 1.766340532729597
Validation loss: 2.3553851088336804

Epoch: 5| Step: 2
Training loss: 1.493839567683371
Validation loss: 2.3340123685693297

Epoch: 5| Step: 3
Training loss: 2.2266972015860778
Validation loss: 2.361788247261158

Epoch: 5| Step: 4
Training loss: 1.7977772313489007
Validation loss: 2.341812411389

Epoch: 5| Step: 5
Training loss: 1.1068004230208945
Validation loss: 2.386974969401389

Epoch: 5| Step: 6
Training loss: 1.4942118708759238
Validation loss: 2.3744130815330093

Epoch: 5| Step: 7
Training loss: 1.5492490795281115
Validation loss: 2.422792491796286

Epoch: 5| Step: 8
Training loss: 1.322376466328574
Validation loss: 2.4001866488958803

Epoch: 5| Step: 9
Training loss: 1.5358814341808582
Validation loss: 2.3753240701010823

Epoch: 5| Step: 10
Training loss: 1.7202764495204421
Validation loss: 2.395785794493151

Epoch: 287| Step: 0
Training loss: 1.3803947562749017
Validation loss: 2.422216212873345

Epoch: 5| Step: 1
Training loss: 1.5604376342885833
Validation loss: 2.4288557470348584

Epoch: 5| Step: 2
Training loss: 1.6902682592576197
Validation loss: 2.394239705845176

Epoch: 5| Step: 3
Training loss: 1.4602371413845696
Validation loss: 2.40979763738995

Epoch: 5| Step: 4
Training loss: 1.4528665620423749
Validation loss: 2.3710089192272354

Epoch: 5| Step: 5
Training loss: 1.2182337327697346
Validation loss: 2.3664568064344547

Epoch: 5| Step: 6
Training loss: 1.760071519352229
Validation loss: 2.3784764810904298

Epoch: 5| Step: 7
Training loss: 1.358174243144865
Validation loss: 2.4410261559381112

Epoch: 5| Step: 8
Training loss: 1.476440586123196
Validation loss: 2.398650785417477

Epoch: 5| Step: 9
Training loss: 1.3877742565016353
Validation loss: 2.4274608785459826

Epoch: 5| Step: 10
Training loss: 2.246471393184865
Validation loss: 2.3923346298838752

Epoch: 288| Step: 0
Training loss: 1.6942690965291958
Validation loss: 2.394514699179229

Epoch: 5| Step: 1
Training loss: 1.3304729127846788
Validation loss: 2.3960014815709316

Epoch: 5| Step: 2
Training loss: 1.3213763944715748
Validation loss: 2.3631327638799795

Epoch: 5| Step: 3
Training loss: 1.9228489586622162
Validation loss: 2.391485255831994

Epoch: 5| Step: 4
Training loss: 1.6771431037566578
Validation loss: 2.392824023102153

Epoch: 5| Step: 5
Training loss: 1.2563082781127175
Validation loss: 2.396293260711051

Epoch: 5| Step: 6
Training loss: 1.5055468837414785
Validation loss: 2.305835948447351

Epoch: 5| Step: 7
Training loss: 1.0934137644975763
Validation loss: 2.3662249094631513

Epoch: 5| Step: 8
Training loss: 1.5479536052966836
Validation loss: 2.415177688729097

Epoch: 5| Step: 9
Training loss: 1.9662917396688906
Validation loss: 2.373139390383134

Epoch: 5| Step: 10
Training loss: 1.791660138791043
Validation loss: 2.4265737891681574

Epoch: 289| Step: 0
Training loss: 1.7848104396578015
Validation loss: 2.375836012048289

Epoch: 5| Step: 1
Training loss: 1.7424410648312902
Validation loss: 2.4288015832715106

Epoch: 5| Step: 2
Training loss: 1.4736341877116264
Validation loss: 2.4044782691861193

Epoch: 5| Step: 3
Training loss: 1.097258363335096
Validation loss: 2.438754309853327

Epoch: 5| Step: 4
Training loss: 1.6860797698313017
Validation loss: 2.405090937167209

Epoch: 5| Step: 5
Training loss: 1.3559654710868958
Validation loss: 2.3915460056245474

Epoch: 5| Step: 6
Training loss: 1.7804807373821725
Validation loss: 2.427314431123638

Epoch: 5| Step: 7
Training loss: 1.6796224892033904
Validation loss: 2.4050576684287837

Epoch: 5| Step: 8
Training loss: 1.9269354342505578
Validation loss: 2.435031801307388

Epoch: 5| Step: 9
Training loss: 1.2767876864178924
Validation loss: 2.353138111901986

Epoch: 5| Step: 10
Training loss: 1.125703326883218
Validation loss: 2.4442072861985378

Epoch: 290| Step: 0
Training loss: 1.2356880061554854
Validation loss: 2.440013112157008

Epoch: 5| Step: 1
Training loss: 1.481939465984041
Validation loss: 2.3842361057295918

Epoch: 5| Step: 2
Training loss: 2.1285323908399847
Validation loss: 2.4147393862331086

Epoch: 5| Step: 3
Training loss: 1.199620679667306
Validation loss: 2.4080504133045064

Epoch: 5| Step: 4
Training loss: 1.4568626981303396
Validation loss: 2.3801511828257924

Epoch: 5| Step: 5
Training loss: 1.5708375119559297
Validation loss: 2.3925725746383395

Epoch: 5| Step: 6
Training loss: 1.6219410348139072
Validation loss: 2.3839330272705013

Epoch: 5| Step: 7
Training loss: 1.4094096820226456
Validation loss: 2.3594945779362826

Epoch: 5| Step: 8
Training loss: 1.5191821013458395
Validation loss: 2.3973114265792574

Epoch: 5| Step: 9
Training loss: 2.0663615980894625
Validation loss: 2.364376175229066

Epoch: 5| Step: 10
Training loss: 1.7172373270679815
Validation loss: 2.369801023497033

Epoch: 291| Step: 0
Training loss: 1.487717328904677
Validation loss: 2.4154479989061555

Epoch: 5| Step: 1
Training loss: 1.4630205939584575
Validation loss: 2.3914010572902553

Epoch: 5| Step: 2
Training loss: 1.4697725510610193
Validation loss: 2.4604540101067545

Epoch: 5| Step: 3
Training loss: 1.869504504524593
Validation loss: 2.3872759466877898

Epoch: 5| Step: 4
Training loss: 2.0247313144592676
Validation loss: 2.406130658436959

Epoch: 5| Step: 5
Training loss: 1.4182209389632727
Validation loss: 2.4534465505116714

Epoch: 5| Step: 6
Training loss: 1.5429322829946965
Validation loss: 2.4356602482520517

Epoch: 5| Step: 7
Training loss: 1.524061730458744
Validation loss: 2.4195141061278393

Epoch: 5| Step: 8
Training loss: 1.2234095973393124
Validation loss: 2.4151476133584326

Epoch: 5| Step: 9
Training loss: 1.8978612205649847
Validation loss: 2.40399794393227

Epoch: 5| Step: 10
Training loss: 1.6577948077639306
Validation loss: 2.4189917850520817

Epoch: 292| Step: 0
Training loss: 1.9052613618234375
Validation loss: 2.3998288309763174

Epoch: 5| Step: 1
Training loss: 1.890036373091181
Validation loss: 2.4004948556843804

Epoch: 5| Step: 2
Training loss: 1.3813967165118017
Validation loss: 2.400378756178101

Epoch: 5| Step: 3
Training loss: 1.5708384985126331
Validation loss: 2.382766315961431

Epoch: 5| Step: 4
Training loss: 1.5809582497659613
Validation loss: 2.4102361844021796

Epoch: 5| Step: 5
Training loss: 1.3412312699545086
Validation loss: 2.4168137901432063

Epoch: 5| Step: 6
Training loss: 1.5808729664619128
Validation loss: 2.3865364077154254

Epoch: 5| Step: 7
Training loss: 1.129351095971535
Validation loss: 2.403348223815441

Epoch: 5| Step: 8
Training loss: 2.0864680040668317
Validation loss: 2.3576384435881184

Epoch: 5| Step: 9
Training loss: 1.6266749626219112
Validation loss: 2.394615952995152

Epoch: 5| Step: 10
Training loss: 1.3927810756466952
Validation loss: 2.3652749162645557

Epoch: 293| Step: 0
Training loss: 1.5161900990754502
Validation loss: 2.411861971580464

Epoch: 5| Step: 1
Training loss: 1.9883729804862034
Validation loss: 2.4144721332269294

Epoch: 5| Step: 2
Training loss: 1.5845412699415788
Validation loss: 2.3700136592992838

Epoch: 5| Step: 3
Training loss: 1.3970314928162755
Validation loss: 2.4141830157790136

Epoch: 5| Step: 4
Training loss: 1.5342522597312602
Validation loss: 2.421731261964047

Epoch: 5| Step: 5
Training loss: 1.356963507016115
Validation loss: 2.4264309512598774

Epoch: 5| Step: 6
Training loss: 1.61489757638223
Validation loss: 2.4131198062854593

Epoch: 5| Step: 7
Training loss: 1.4763633149640392
Validation loss: 2.4026532053631415

Epoch: 5| Step: 8
Training loss: 1.7488310860955358
Validation loss: 2.394282775448096

Epoch: 5| Step: 9
Training loss: 1.1639363265302776
Validation loss: 2.3598062074627064

Epoch: 5| Step: 10
Training loss: 1.4149777311587957
Validation loss: 2.2982961758654903

Epoch: 294| Step: 0
Training loss: 0.929877317909524
Validation loss: 2.3646578072084634

Epoch: 5| Step: 1
Training loss: 2.1471753661304613
Validation loss: 2.3552107086244405

Epoch: 5| Step: 2
Training loss: 2.065437998653491
Validation loss: 2.434286767312965

Epoch: 5| Step: 3
Training loss: 1.219541732674608
Validation loss: 2.376229869617895

Epoch: 5| Step: 4
Training loss: 1.4102413331461847
Validation loss: 2.398573096356009

Epoch: 5| Step: 5
Training loss: 1.9401661156785008
Validation loss: 2.4188789696626745

Epoch: 5| Step: 6
Training loss: 1.2715567525722975
Validation loss: 2.408340681578419

Epoch: 5| Step: 7
Training loss: 1.3427090272193853
Validation loss: 2.3980605834778435

Epoch: 5| Step: 8
Training loss: 1.8079041058040333
Validation loss: 2.3574084424533344

Epoch: 5| Step: 9
Training loss: 1.4234277819103893
Validation loss: 2.4190955115354864

Epoch: 5| Step: 10
Training loss: 1.4569691499050432
Validation loss: 2.3874726411643197

Epoch: 295| Step: 0
Training loss: 1.2700647260286804
Validation loss: 2.36304215561028

Epoch: 5| Step: 1
Training loss: 1.9064819945198714
Validation loss: 2.42713653923007

Epoch: 5| Step: 2
Training loss: 1.8246974276197303
Validation loss: 2.435557293547472

Epoch: 5| Step: 3
Training loss: 1.5421903167667965
Validation loss: 2.372043530015137

Epoch: 5| Step: 4
Training loss: 1.8005480170485284
Validation loss: 2.3568028946112505

Epoch: 5| Step: 5
Training loss: 1.5393760090746034
Validation loss: 2.4025413593982003

Epoch: 5| Step: 6
Training loss: 1.108725989252703
Validation loss: 2.4039185406093413

Epoch: 5| Step: 7
Training loss: 2.1430821482283817
Validation loss: 2.3392799187453326

Epoch: 5| Step: 8
Training loss: 1.6270282998182373
Validation loss: 2.406874317989639

Epoch: 5| Step: 9
Training loss: 1.4081586388956493
Validation loss: 2.3944236456712713

Epoch: 5| Step: 10
Training loss: 1.1399764215808386
Validation loss: 2.342004263942284

Epoch: 296| Step: 0
Training loss: 1.764576963783247
Validation loss: 2.371104782599696

Epoch: 5| Step: 1
Training loss: 1.140035659918283
Validation loss: 2.3638797982069373

Epoch: 5| Step: 2
Training loss: 1.6877725169222817
Validation loss: 2.36287911923686

Epoch: 5| Step: 3
Training loss: 1.6588205506787792
Validation loss: 2.32932391847595

Epoch: 5| Step: 4
Training loss: 1.4241387089990505
Validation loss: 2.3808983747924617

Epoch: 5| Step: 5
Training loss: 1.1579887616331976
Validation loss: 2.422478140872031

Epoch: 5| Step: 6
Training loss: 2.148394331064879
Validation loss: 2.332147547099897

Epoch: 5| Step: 7
Training loss: 1.4070641597984894
Validation loss: 2.3369909184325257

Epoch: 5| Step: 8
Training loss: 1.776326586409803
Validation loss: 2.3823204636645343

Epoch: 5| Step: 9
Training loss: 1.6137995960938083
Validation loss: 2.4077089231397095

Epoch: 5| Step: 10
Training loss: 1.4328618897024052
Validation loss: 2.377120512933589

Epoch: 297| Step: 0
Training loss: 1.245153568708683
Validation loss: 2.362966000534595

Epoch: 5| Step: 1
Training loss: 1.7365942151460176
Validation loss: 2.384964383430932

Epoch: 5| Step: 2
Training loss: 1.2627266085611901
Validation loss: 2.41864302623522

Epoch: 5| Step: 3
Training loss: 1.390754736517
Validation loss: 2.3459954119252626

Epoch: 5| Step: 4
Training loss: 1.6853982057570236
Validation loss: 2.4075598715972077

Epoch: 5| Step: 5
Training loss: 1.2547505706098725
Validation loss: 2.4445005765567185

Epoch: 5| Step: 6
Training loss: 1.81745463643925
Validation loss: 2.4009302958864853

Epoch: 5| Step: 7
Training loss: 1.8546890065959156
Validation loss: 2.3709311310508165

Epoch: 5| Step: 8
Training loss: 1.2659281614811828
Validation loss: 2.3919500080711775

Epoch: 5| Step: 9
Training loss: 1.2239457420621325
Validation loss: 2.3946957220477225

Epoch: 5| Step: 10
Training loss: 1.7897323620360437
Validation loss: 2.4167863289680795

Epoch: 298| Step: 0
Training loss: 1.1171092292736995
Validation loss: 2.348744553583879

Epoch: 5| Step: 1
Training loss: 1.7952824708769473
Validation loss: 2.376785805095549

Epoch: 5| Step: 2
Training loss: 1.3900483896902804
Validation loss: 2.372862605898588

Epoch: 5| Step: 3
Training loss: 1.3228029317349825
Validation loss: 2.3582040387861505

Epoch: 5| Step: 4
Training loss: 2.1560672184970233
Validation loss: 2.3821952742606944

Epoch: 5| Step: 5
Training loss: 1.1822278793985572
Validation loss: 2.4116396489763

Epoch: 5| Step: 6
Training loss: 1.4899390891765263
Validation loss: 2.3997011737412466

Epoch: 5| Step: 7
Training loss: 1.37523913471456
Validation loss: 2.4093674802523815

Epoch: 5| Step: 8
Training loss: 1.6107135132288417
Validation loss: 2.4137471066647884

Epoch: 5| Step: 9
Training loss: 1.8601043296595
Validation loss: 2.370529553407159

Epoch: 5| Step: 10
Training loss: 1.3824401181653803
Validation loss: 2.4417664783805506

Epoch: 299| Step: 0
Training loss: 1.4294711089922318
Validation loss: 2.3950855545196474

Epoch: 5| Step: 1
Training loss: 1.2463367189407446
Validation loss: 2.378917730232898

Epoch: 5| Step: 2
Training loss: 1.4621607101604925
Validation loss: 2.435616494639518

Epoch: 5| Step: 3
Training loss: 1.3036982732150577
Validation loss: 2.394754880960467

Epoch: 5| Step: 4
Training loss: 1.5215381225964746
Validation loss: 2.3877159884269963

Epoch: 5| Step: 5
Training loss: 1.3041771901511492
Validation loss: 2.333830828375765

Epoch: 5| Step: 6
Training loss: 1.5738932459981472
Validation loss: 2.3877059688330737

Epoch: 5| Step: 7
Training loss: 2.194348106469373
Validation loss: 2.332186096792226

Epoch: 5| Step: 8
Training loss: 1.3639308398352084
Validation loss: 2.3458864227630674

Epoch: 5| Step: 9
Training loss: 1.8814153909061198
Validation loss: 2.349621219867868

Epoch: 5| Step: 10
Training loss: 1.0610293701126459
Validation loss: 2.3958732458983745

Epoch: 300| Step: 0
Training loss: 1.112068077422019
Validation loss: 2.404173874948647

Epoch: 5| Step: 1
Training loss: 1.6454770954106277
Validation loss: 2.4231626032526536

Epoch: 5| Step: 2
Training loss: 1.2326974696654753
Validation loss: 2.3276959370950934

Epoch: 5| Step: 3
Training loss: 1.3634447147336752
Validation loss: 2.467061120485164

Epoch: 5| Step: 4
Training loss: 1.441975302909325
Validation loss: 2.44642683540216

Epoch: 5| Step: 5
Training loss: 1.2795243155705767
Validation loss: 2.39887558193399

Epoch: 5| Step: 6
Training loss: 1.8367644699812289
Validation loss: 2.4521067439156488

Epoch: 5| Step: 7
Training loss: 1.734304615688951
Validation loss: 2.4191533139428723

Epoch: 5| Step: 8
Training loss: 1.9785870824413958
Validation loss: 2.4112084916950436

Epoch: 5| Step: 9
Training loss: 1.2156847039395948
Validation loss: 2.3665293003162526

Epoch: 5| Step: 10
Training loss: 2.122007169806676
Validation loss: 2.4438635839657246

Epoch: 301| Step: 0
Training loss: 1.6552135895568985
Validation loss: 2.39445848077872

Epoch: 5| Step: 1
Training loss: 1.7714781166983926
Validation loss: 2.4330373930766376

Epoch: 5| Step: 2
Training loss: 2.046192666976745
Validation loss: 2.3326581323760593

Epoch: 5| Step: 3
Training loss: 1.1695949498872495
Validation loss: 2.3687561787473754

Epoch: 5| Step: 4
Training loss: 2.021602078019566
Validation loss: 2.377308341715189

Epoch: 5| Step: 5
Training loss: 1.3863865414132936
Validation loss: 2.3383420894725697

Epoch: 5| Step: 6
Training loss: 1.051312563981504
Validation loss: 2.3877550292254615

Epoch: 5| Step: 7
Training loss: 1.3738809279858069
Validation loss: 2.3928799981344775

Epoch: 5| Step: 8
Training loss: 1.6089777780329526
Validation loss: 2.3771520524254273

Epoch: 5| Step: 9
Training loss: 1.6640675146179578
Validation loss: 2.3884174605621395

Epoch: 5| Step: 10
Training loss: 1.2262059076063923
Validation loss: 2.346031195053306

Epoch: 302| Step: 0
Training loss: 1.219951819578501
Validation loss: 2.40072370105498

Epoch: 5| Step: 1
Training loss: 1.6705050693767303
Validation loss: 2.4183300546934694

Epoch: 5| Step: 2
Training loss: 1.5126441666173958
Validation loss: 2.3968837545086106

Epoch: 5| Step: 3
Training loss: 1.205301174499299
Validation loss: 2.388025518623825

Epoch: 5| Step: 4
Training loss: 1.5371658334215201
Validation loss: 2.427676305927038

Epoch: 5| Step: 5
Training loss: 1.5657882422586193
Validation loss: 2.4293932692231293

Epoch: 5| Step: 6
Training loss: 1.5439738802405274
Validation loss: 2.4062496718539763

Epoch: 5| Step: 7
Training loss: 1.1000406561187344
Validation loss: 2.37565595099196

Epoch: 5| Step: 8
Training loss: 1.766245370090731
Validation loss: 2.397564553475977

Epoch: 5| Step: 9
Training loss: 1.8876924075653412
Validation loss: 2.308065175651379

Epoch: 5| Step: 10
Training loss: 1.3023981807252
Validation loss: 2.434620726155201

Epoch: 303| Step: 0
Training loss: 2.0052794869089134
Validation loss: 2.338776573056103

Epoch: 5| Step: 1
Training loss: 1.4230648553776752
Validation loss: 2.355556892284968

Epoch: 5| Step: 2
Training loss: 1.523416607053248
Validation loss: 2.331860616631262

Epoch: 5| Step: 3
Training loss: 1.926306724431012
Validation loss: 2.343122705990489

Epoch: 5| Step: 4
Training loss: 1.4769072760866178
Validation loss: 2.3748491344019236

Epoch: 5| Step: 5
Training loss: 1.4555841782031038
Validation loss: 2.438709342919842

Epoch: 5| Step: 6
Training loss: 1.3298050520291622
Validation loss: 2.350448608953908

Epoch: 5| Step: 7
Training loss: 0.8515426213455305
Validation loss: 2.3835576181302924

Epoch: 5| Step: 8
Training loss: 1.4692528046650493
Validation loss: 2.4148388928397897

Epoch: 5| Step: 9
Training loss: 1.5958973499070765
Validation loss: 2.3434731760925183

Epoch: 5| Step: 10
Training loss: 1.0177419461049
Validation loss: 2.338670051544522

Epoch: 304| Step: 0
Training loss: 1.6263606170635188
Validation loss: 2.3297229939026525

Epoch: 5| Step: 1
Training loss: 1.43939341365616
Validation loss: 2.376870423219147

Epoch: 5| Step: 2
Training loss: 1.4820225596235963
Validation loss: 2.3769858849080765

Epoch: 5| Step: 3
Training loss: 1.5009227139921915
Validation loss: 2.35985056493014

Epoch: 5| Step: 4
Training loss: 1.320690304125002
Validation loss: 2.407220206709586

Epoch: 5| Step: 5
Training loss: 2.0642592123407475
Validation loss: 2.4050981012219164

Epoch: 5| Step: 6
Training loss: 1.4185475410828696
Validation loss: 2.4201935328594066

Epoch: 5| Step: 7
Training loss: 1.3081493932761594
Validation loss: 2.3906900803320483

Epoch: 5| Step: 8
Training loss: 1.3734886793510905
Validation loss: 2.3349888370172684

Epoch: 5| Step: 9
Training loss: 1.5138522920452766
Validation loss: 2.391535303156221

Epoch: 5| Step: 10
Training loss: 1.3881012807963964
Validation loss: 2.3553025585945453

Epoch: 305| Step: 0
Training loss: 1.6643364192832932
Validation loss: 2.463010138026465

Epoch: 5| Step: 1
Training loss: 1.3685323150186721
Validation loss: 2.400135219304287

Epoch: 5| Step: 2
Training loss: 2.0859851617404237
Validation loss: 2.3628564075598657

Epoch: 5| Step: 3
Training loss: 1.2704966469112078
Validation loss: 2.3998796277939682

Epoch: 5| Step: 4
Training loss: 1.2613173280255603
Validation loss: 2.5070045889006103

Epoch: 5| Step: 5
Training loss: 1.1838703398880153
Validation loss: 2.386699187906816

Epoch: 5| Step: 6
Training loss: 1.5454308289987775
Validation loss: 2.439116418185559

Epoch: 5| Step: 7
Training loss: 1.3994695169305222
Validation loss: 2.3929975579386804

Epoch: 5| Step: 8
Training loss: 1.7118048711968379
Validation loss: 2.380874997821043

Epoch: 5| Step: 9
Training loss: 1.5042387359486504
Validation loss: 2.419674393117333

Epoch: 5| Step: 10
Training loss: 1.3359665449230933
Validation loss: 2.4319881471084392

Epoch: 306| Step: 0
Training loss: 1.9077890780524087
Validation loss: 2.40125796350775

Epoch: 5| Step: 1
Training loss: 1.2473998683580136
Validation loss: 2.3467462547207156

Epoch: 5| Step: 2
Training loss: 1.4355457124251245
Validation loss: 2.446982092525356

Epoch: 5| Step: 3
Training loss: 1.2098648735132593
Validation loss: 2.3828889298953366

Epoch: 5| Step: 4
Training loss: 1.565031061565019
Validation loss: 2.3412488470106485

Epoch: 5| Step: 5
Training loss: 1.6382674944749924
Validation loss: 2.3793276168074695

Epoch: 5| Step: 6
Training loss: 1.7548959229520356
Validation loss: 2.35727784740186

Epoch: 5| Step: 7
Training loss: 1.3991248290437506
Validation loss: 2.352692254427684

Epoch: 5| Step: 8
Training loss: 1.6712247350433609
Validation loss: 2.36071632622818

Epoch: 5| Step: 9
Training loss: 1.3621106737686937
Validation loss: 2.3708473087362196

Epoch: 5| Step: 10
Training loss: 1.5129748899364208
Validation loss: 2.380477420103424

Epoch: 307| Step: 0
Training loss: 1.038028173553091
Validation loss: 2.3877028830645397

Epoch: 5| Step: 1
Training loss: 1.3251574404764783
Validation loss: 2.4539376987011337

Epoch: 5| Step: 2
Training loss: 2.2176763596446416
Validation loss: 2.3572493802524668

Epoch: 5| Step: 3
Training loss: 1.6337965778695573
Validation loss: 2.387572137942983

Epoch: 5| Step: 4
Training loss: 1.2953098458146717
Validation loss: 2.4399931373244157

Epoch: 5| Step: 5
Training loss: 1.3694226985199565
Validation loss: 2.4101727976493295

Epoch: 5| Step: 6
Training loss: 1.7252519561752067
Validation loss: 2.4532139761152054

Epoch: 5| Step: 7
Training loss: 1.3684880637448698
Validation loss: 2.406392094742567

Epoch: 5| Step: 8
Training loss: 1.3914038373785933
Validation loss: 2.342405749434758

Epoch: 5| Step: 9
Training loss: 1.5681045724291611
Validation loss: 2.36678694821332

Epoch: 5| Step: 10
Training loss: 1.5166739540483953
Validation loss: 2.377348810797473

Epoch: 308| Step: 0
Training loss: 1.4359062315947435
Validation loss: 2.3586485913308213

Epoch: 5| Step: 1
Training loss: 1.337429930732158
Validation loss: 2.3867393806808765

Epoch: 5| Step: 2
Training loss: 1.2178997595273993
Validation loss: 2.4025747952930785

Epoch: 5| Step: 3
Training loss: 1.2355042133328926
Validation loss: 2.3269141710498946

Epoch: 5| Step: 4
Training loss: 1.318644129765598
Validation loss: 2.3739891632059016

Epoch: 5| Step: 5
Training loss: 1.543650030072956
Validation loss: 2.3543830929637237

Epoch: 5| Step: 6
Training loss: 2.0291208699389442
Validation loss: 2.333140347303723

Epoch: 5| Step: 7
Training loss: 1.499564584479002
Validation loss: 2.290102920920521

Epoch: 5| Step: 8
Training loss: 1.424303851825884
Validation loss: 2.382883423668098

Epoch: 5| Step: 9
Training loss: 1.4857522297431176
Validation loss: 2.4175133433076974

Epoch: 5| Step: 10
Training loss: 1.9802447611832548
Validation loss: 2.404553659657906

Epoch: 309| Step: 0
Training loss: 1.319590083109909
Validation loss: 2.39484582981316

Epoch: 5| Step: 1
Training loss: 1.103420071136068
Validation loss: 2.3576216011533737

Epoch: 5| Step: 2
Training loss: 1.4172744942979465
Validation loss: 2.435412457215106

Epoch: 5| Step: 3
Training loss: 1.1267113913926754
Validation loss: 2.3844638395095816

Epoch: 5| Step: 4
Training loss: 1.2291107919353441
Validation loss: 2.3670716692085505

Epoch: 5| Step: 5
Training loss: 1.5824772712316735
Validation loss: 2.416689001354281

Epoch: 5| Step: 6
Training loss: 2.0093885833613347
Validation loss: 2.4290359700281114

Epoch: 5| Step: 7
Training loss: 1.564812360611562
Validation loss: 2.3865010890494016

Epoch: 5| Step: 8
Training loss: 1.463137026561796
Validation loss: 2.3341148993170795

Epoch: 5| Step: 9
Training loss: 1.476805813234652
Validation loss: 2.384495730200798

Epoch: 5| Step: 10
Training loss: 1.7851978522530332
Validation loss: 2.351325276632107

Epoch: 310| Step: 0
Training loss: 1.5679083492731904
Validation loss: 2.323202581222827

Epoch: 5| Step: 1
Training loss: 1.0970545847238908
Validation loss: 2.3477071055273857

Epoch: 5| Step: 2
Training loss: 1.3038823732963585
Validation loss: 2.4677725830476605

Epoch: 5| Step: 3
Training loss: 1.1567706405087579
Validation loss: 2.405940260846423

Epoch: 5| Step: 4
Training loss: 1.5150777871082295
Validation loss: 2.3170180901046176

Epoch: 5| Step: 5
Training loss: 1.5659737691521551
Validation loss: 2.364031128513597

Epoch: 5| Step: 6
Training loss: 1.8207817291466024
Validation loss: 2.3667162755105213

Epoch: 5| Step: 7
Training loss: 2.004045805059264
Validation loss: 2.36526739801735

Epoch: 5| Step: 8
Training loss: 1.749904357476414
Validation loss: 2.416256029193983

Epoch: 5| Step: 9
Training loss: 1.2787377919409533
Validation loss: 2.4070705901184986

Epoch: 5| Step: 10
Training loss: 1.7310283780694535
Validation loss: 2.421325494230066

Epoch: 311| Step: 0
Training loss: 1.7931073702413889
Validation loss: 2.3768344275561373

Epoch: 5| Step: 1
Training loss: 1.731017015114586
Validation loss: 2.4018611785770303

Epoch: 5| Step: 2
Training loss: 1.4042295564477834
Validation loss: 2.3825637631073002

Epoch: 5| Step: 3
Training loss: 1.6557206081550375
Validation loss: 2.4627654568897093

Epoch: 5| Step: 4
Training loss: 1.1950221986983234
Validation loss: 2.3407698445520757

Epoch: 5| Step: 5
Training loss: 0.9697966920017019
Validation loss: 2.382721824541273

Epoch: 5| Step: 6
Training loss: 1.6300810092852058
Validation loss: 2.4108874845012473

Epoch: 5| Step: 7
Training loss: 1.4400390095195297
Validation loss: 2.403679510191806

Epoch: 5| Step: 8
Training loss: 1.5407746371939794
Validation loss: 2.354332537900834

Epoch: 5| Step: 9
Training loss: 1.7727234196787756
Validation loss: 2.3945214066703513

Epoch: 5| Step: 10
Training loss: 1.358120920778162
Validation loss: 2.3249791367893993

Epoch: 312| Step: 0
Training loss: 1.366223851239004
Validation loss: 2.3297015711045383

Epoch: 5| Step: 1
Training loss: 1.2839276316620563
Validation loss: 2.3708695037722225

Epoch: 5| Step: 2
Training loss: 1.4358976804838741
Validation loss: 2.429449427380888

Epoch: 5| Step: 3
Training loss: 1.2526602094753516
Validation loss: 2.423727074021113

Epoch: 5| Step: 4
Training loss: 1.3467265142386713
Validation loss: 2.3700687771552085

Epoch: 5| Step: 5
Training loss: 1.544174302822171
Validation loss: 2.450080618537515

Epoch: 5| Step: 6
Training loss: 1.5526678874817816
Validation loss: 2.3961474290772915

Epoch: 5| Step: 7
Training loss: 1.1203473627047582
Validation loss: 2.3858876214583518

Epoch: 5| Step: 8
Training loss: 1.5374491024121528
Validation loss: 2.340314637598776

Epoch: 5| Step: 9
Training loss: 2.21717413158298
Validation loss: 2.346712689224016

Epoch: 5| Step: 10
Training loss: 1.6014835245152612
Validation loss: 2.4318071034501187

Epoch: 313| Step: 0
Training loss: 0.8362600114391323
Validation loss: 2.381870711304417

Epoch: 5| Step: 1
Training loss: 1.7011732764955478
Validation loss: 2.347927883482557

Epoch: 5| Step: 2
Training loss: 1.3242089375270205
Validation loss: 2.4280031483925386

Epoch: 5| Step: 3
Training loss: 1.1333814047454378
Validation loss: 2.388546037487265

Epoch: 5| Step: 4
Training loss: 1.2592167567942505
Validation loss: 2.35224197149041

Epoch: 5| Step: 5
Training loss: 1.7870545425758189
Validation loss: 2.414168653428476

Epoch: 5| Step: 6
Training loss: 1.4461899027293994
Validation loss: 2.351458505943299

Epoch: 5| Step: 7
Training loss: 1.2563800118198083
Validation loss: 2.3589097267600745

Epoch: 5| Step: 8
Training loss: 1.9255752298521895
Validation loss: 2.389369696416554

Epoch: 5| Step: 9
Training loss: 1.4396127847767863
Validation loss: 2.3828900186593565

Epoch: 5| Step: 10
Training loss: 1.6068173427022867
Validation loss: 2.3516678881043727

Epoch: 314| Step: 0
Training loss: 1.4159037368241227
Validation loss: 2.427980450382292

Epoch: 5| Step: 1
Training loss: 1.830563736265224
Validation loss: 2.377424664746836

Epoch: 5| Step: 2
Training loss: 1.857118214716227
Validation loss: 2.363203670672815

Epoch: 5| Step: 3
Training loss: 1.3651382346949519
Validation loss: 2.3493343927450567

Epoch: 5| Step: 4
Training loss: 1.0903789887692605
Validation loss: 2.4163611865721086

Epoch: 5| Step: 5
Training loss: 1.2875285876905738
Validation loss: 2.295177496552585

Epoch: 5| Step: 6
Training loss: 1.2625552023725877
Validation loss: 2.3620107806269717

Epoch: 5| Step: 7
Training loss: 1.4962553330456272
Validation loss: 2.2790458865710703

Epoch: 5| Step: 8
Training loss: 1.647740655204934
Validation loss: 2.3573601240192605

Epoch: 5| Step: 9
Training loss: 1.7226954864393222
Validation loss: 2.33311564078962

Epoch: 5| Step: 10
Training loss: 1.3592271834060428
Validation loss: 2.410112254633259

Epoch: 315| Step: 0
Training loss: 1.8331570612811858
Validation loss: 2.3338444438583443

Epoch: 5| Step: 1
Training loss: 1.582132971990139
Validation loss: 2.460603625776887

Epoch: 5| Step: 2
Training loss: 1.5010072187520784
Validation loss: 2.3804601533992615

Epoch: 5| Step: 3
Training loss: 1.4403318624090942
Validation loss: 2.3382409265497914

Epoch: 5| Step: 4
Training loss: 1.428683235697776
Validation loss: 2.4098498729944806

Epoch: 5| Step: 5
Training loss: 1.0361975273035082
Validation loss: 2.4093618089628084

Epoch: 5| Step: 6
Training loss: 1.7144293838425126
Validation loss: 2.3365113623542704

Epoch: 5| Step: 7
Training loss: 1.2956159523824218
Validation loss: 2.4045553948338347

Epoch: 5| Step: 8
Training loss: 1.5506516409649194
Validation loss: 2.370726847896119

Epoch: 5| Step: 9
Training loss: 1.3994344216015122
Validation loss: 2.4123741517058974

Epoch: 5| Step: 10
Training loss: 1.3158184969361362
Validation loss: 2.4286453316914294

Epoch: 316| Step: 0
Training loss: 1.2417505803438063
Validation loss: 2.347121756709495

Epoch: 5| Step: 1
Training loss: 1.5407885636791563
Validation loss: 2.368279971927161

Epoch: 5| Step: 2
Training loss: 1.1863215773184779
Validation loss: 2.3936760505137626

Epoch: 5| Step: 3
Training loss: 1.188554245628415
Validation loss: 2.440408994911482

Epoch: 5| Step: 4
Training loss: 1.2883526783996353
Validation loss: 2.399723540981979

Epoch: 5| Step: 5
Training loss: 1.4380180420572708
Validation loss: 2.385146026870488

Epoch: 5| Step: 6
Training loss: 1.6018817862472237
Validation loss: 2.3908349388079797

Epoch: 5| Step: 7
Training loss: 1.3984095394813012
Validation loss: 2.4276920847167376

Epoch: 5| Step: 8
Training loss: 1.9641154401225214
Validation loss: 2.415597209248678

Epoch: 5| Step: 9
Training loss: 1.6808417324423062
Validation loss: 2.36037384319607

Epoch: 5| Step: 10
Training loss: 1.532226873705354
Validation loss: 2.4199380581850045

Epoch: 317| Step: 0
Training loss: 1.3966229990199939
Validation loss: 2.394672182686615

Epoch: 5| Step: 1
Training loss: 1.7306384139059463
Validation loss: 2.3589906825673834

Epoch: 5| Step: 2
Training loss: 1.7476746232043678
Validation loss: 2.3664225731326587

Epoch: 5| Step: 3
Training loss: 1.152444815648821
Validation loss: 2.397431298047164

Epoch: 5| Step: 4
Training loss: 1.3570451172431444
Validation loss: 2.3861462991255564

Epoch: 5| Step: 5
Training loss: 1.5079398620260633
Validation loss: 2.3941694976478205

Epoch: 5| Step: 6
Training loss: 1.2627767844885482
Validation loss: 2.3635532820231475

Epoch: 5| Step: 7
Training loss: 1.9095601592994242
Validation loss: 2.311327689498029

Epoch: 5| Step: 8
Training loss: 1.0517450613454937
Validation loss: 2.344868113934057

Epoch: 5| Step: 9
Training loss: 1.8169546304475008
Validation loss: 2.3383446253280384

Epoch: 5| Step: 10
Training loss: 1.0368806690983143
Validation loss: 2.4702217841676357

Epoch: 318| Step: 0
Training loss: 1.6094067764848745
Validation loss: 2.417047643140285

Epoch: 5| Step: 1
Training loss: 1.2264597175443024
Validation loss: 2.3260982214501764

Epoch: 5| Step: 2
Training loss: 1.2209216601259865
Validation loss: 2.3858029739254465

Epoch: 5| Step: 3
Training loss: 1.2132108944293991
Validation loss: 2.332027538704248

Epoch: 5| Step: 4
Training loss: 1.5231657910745007
Validation loss: 2.420584390275885

Epoch: 5| Step: 5
Training loss: 2.0434009685596575
Validation loss: 2.4009013634242136

Epoch: 5| Step: 6
Training loss: 1.7652002009244934
Validation loss: 2.416000151951288

Epoch: 5| Step: 7
Training loss: 1.540921709996686
Validation loss: 2.3968569016742958

Epoch: 5| Step: 8
Training loss: 1.3183959051651926
Validation loss: 2.4281350961065815

Epoch: 5| Step: 9
Training loss: 1.306475390833535
Validation loss: 2.370338037451847

Epoch: 5| Step: 10
Training loss: 1.0512753144072817
Validation loss: 2.3176883661161973

Epoch: 319| Step: 0
Training loss: 1.21491091625331
Validation loss: 2.382508888583999

Epoch: 5| Step: 1
Training loss: 1.1328014504781694
Validation loss: 2.363726871478169

Epoch: 5| Step: 2
Training loss: 1.1078262801718912
Validation loss: 2.4013131835890476

Epoch: 5| Step: 3
Training loss: 1.901397908593943
Validation loss: 2.3713119413742696

Epoch: 5| Step: 4
Training loss: 1.9356396265065439
Validation loss: 2.4159426497449337

Epoch: 5| Step: 5
Training loss: 1.0295244287498477
Validation loss: 2.3381832548014567

Epoch: 5| Step: 6
Training loss: 1.387010441579206
Validation loss: 2.3644225005449284

Epoch: 5| Step: 7
Training loss: 1.552551181950825
Validation loss: 2.39101948259143

Epoch: 5| Step: 8
Training loss: 1.5288383020458671
Validation loss: 2.3636345505949485

Epoch: 5| Step: 9
Training loss: 1.1720087102266898
Validation loss: 2.324523624517611

Epoch: 5| Step: 10
Training loss: 1.2007280723893534
Validation loss: 2.4349078353753617

Epoch: 320| Step: 0
Training loss: 1.6528712663825433
Validation loss: 2.3860274186479495

Epoch: 5| Step: 1
Training loss: 1.248092244596664
Validation loss: 2.398440552717861

Epoch: 5| Step: 2
Training loss: 1.386506916038523
Validation loss: 2.4252504725786346

Epoch: 5| Step: 3
Training loss: 1.5549786932365592
Validation loss: 2.427341348354521

Epoch: 5| Step: 4
Training loss: 1.1543649824417246
Validation loss: 2.427627454600057

Epoch: 5| Step: 5
Training loss: 1.0047355818329742
Validation loss: 2.363389022622048

Epoch: 5| Step: 6
Training loss: 1.1921749449302557
Validation loss: 2.3457629642967333

Epoch: 5| Step: 7
Training loss: 2.0555423945214675
Validation loss: 2.4105833646442494

Epoch: 5| Step: 8
Training loss: 1.5034898850380143
Validation loss: 2.356626203893694

Epoch: 5| Step: 9
Training loss: 1.3266115428903746
Validation loss: 2.3365271522315716

Epoch: 5| Step: 10
Training loss: 1.8241744434277474
Validation loss: 2.358461680917048

Epoch: 321| Step: 0
Training loss: 1.4419831566164198
Validation loss: 2.393904223823844

Epoch: 5| Step: 1
Training loss: 1.4365634355091819
Validation loss: 2.407468818705668

Epoch: 5| Step: 2
Training loss: 2.0860240218259736
Validation loss: 2.3327687385399183

Epoch: 5| Step: 3
Training loss: 1.2831088747106643
Validation loss: 2.3550056387677456

Epoch: 5| Step: 4
Training loss: 1.5436094088763617
Validation loss: 2.3543715965407355

Epoch: 5| Step: 5
Training loss: 0.9780333162183468
Validation loss: 2.421842593777756

Epoch: 5| Step: 6
Training loss: 1.0822864327963515
Validation loss: 2.3286148682403116

Epoch: 5| Step: 7
Training loss: 1.305550615265249
Validation loss: 2.407936799433882

Epoch: 5| Step: 8
Training loss: 1.6225939324083907
Validation loss: 2.362625845587979

Epoch: 5| Step: 9
Training loss: 1.3526487891242724
Validation loss: 2.412111006429771

Epoch: 5| Step: 10
Training loss: 1.4185548522100362
Validation loss: 2.366575614358255

Epoch: 322| Step: 0
Training loss: 1.3347089595226158
Validation loss: 2.3125323681615595

Epoch: 5| Step: 1
Training loss: 1.3413955110398885
Validation loss: 2.2969510895469862

Epoch: 5| Step: 2
Training loss: 1.6229656396543888
Validation loss: 2.3928465306951288

Epoch: 5| Step: 3
Training loss: 1.4167398639543216
Validation loss: 2.2996198381458393

Epoch: 5| Step: 4
Training loss: 1.9969863836658053
Validation loss: 2.4144978796862295

Epoch: 5| Step: 5
Training loss: 1.1101233953329694
Validation loss: 2.333307409655219

Epoch: 5| Step: 6
Training loss: 1.0744310758734938
Validation loss: 2.3830409582806737

Epoch: 5| Step: 7
Training loss: 1.4014988641315802
Validation loss: 2.3655613256409356

Epoch: 5| Step: 8
Training loss: 1.283506035434277
Validation loss: 2.3602215066600087

Epoch: 5| Step: 9
Training loss: 1.1777030978628265
Validation loss: 2.407133070624038

Epoch: 5| Step: 10
Training loss: 1.2612268297923452
Validation loss: 2.3694835947151907

Epoch: 323| Step: 0
Training loss: 1.8604179470603213
Validation loss: 2.406197613264527

Epoch: 5| Step: 1
Training loss: 1.3460281046105573
Validation loss: 2.3849636643108245

Epoch: 5| Step: 2
Training loss: 1.1634246307407217
Validation loss: 2.411984951581087

Epoch: 5| Step: 3
Training loss: 1.2910458190434244
Validation loss: 2.3474938492402417

Epoch: 5| Step: 4
Training loss: 1.4966410539696853
Validation loss: 2.4037848396748416

Epoch: 5| Step: 5
Training loss: 1.554669557400781
Validation loss: 2.422044008347284

Epoch: 5| Step: 6
Training loss: 1.4798246809502427
Validation loss: 2.344294264298836

Epoch: 5| Step: 7
Training loss: 1.3608670870131385
Validation loss: 2.436251579083842

Epoch: 5| Step: 8
Training loss: 1.4532518228952238
Validation loss: 2.4181754821553127

Epoch: 5| Step: 9
Training loss: 1.7104571639303052
Validation loss: 2.4193301037580186

Epoch: 5| Step: 10
Training loss: 1.1649338705916155
Validation loss: 2.359145136110929

Epoch: 324| Step: 0
Training loss: 1.5104253395971587
Validation loss: 2.3974479736260994

Epoch: 5| Step: 1
Training loss: 1.3977104726628975
Validation loss: 2.303321483886042

Epoch: 5| Step: 2
Training loss: 1.1921433466863212
Validation loss: 2.3906367177861734

Epoch: 5| Step: 3
Training loss: 1.450652038374827
Validation loss: 2.4517693291245397

Epoch: 5| Step: 4
Training loss: 1.4102966999476527
Validation loss: 2.348275818187652

Epoch: 5| Step: 5
Training loss: 1.5148176422151478
Validation loss: 2.503118734451885

Epoch: 5| Step: 6
Training loss: 1.401655618047241
Validation loss: 2.424468583494442

Epoch: 5| Step: 7
Training loss: 1.206982559160266
Validation loss: 2.34534458128812

Epoch: 5| Step: 8
Training loss: 1.65520357867887
Validation loss: 2.4380924040312144

Epoch: 5| Step: 9
Training loss: 1.8646085797808172
Validation loss: 2.3507153698792873

Epoch: 5| Step: 10
Training loss: 1.3274946175302702
Validation loss: 2.3329487108571754

Epoch: 325| Step: 0
Training loss: 1.261130795322865
Validation loss: 2.3999301650285174

Epoch: 5| Step: 1
Training loss: 0.8903002899928704
Validation loss: 2.344855525662105

Epoch: 5| Step: 2
Training loss: 1.5923080653250776
Validation loss: 2.3638901085782127

Epoch: 5| Step: 3
Training loss: 1.5479134821014024
Validation loss: 2.35109925394171

Epoch: 5| Step: 4
Training loss: 1.590029319037023
Validation loss: 2.3180157350542645

Epoch: 5| Step: 5
Training loss: 1.1287627343423698
Validation loss: 2.3488789966950305

Epoch: 5| Step: 6
Training loss: 1.677170184554076
Validation loss: 2.32992289026676

Epoch: 5| Step: 7
Training loss: 1.4520449983123882
Validation loss: 2.362156503567274

Epoch: 5| Step: 8
Training loss: 2.159382631589264
Validation loss: 2.323112409649156

Epoch: 5| Step: 9
Training loss: 1.0527660244800359
Validation loss: 2.423013777321803

Epoch: 5| Step: 10
Training loss: 1.3815315046028245
Validation loss: 2.3972191211327694

Epoch: 326| Step: 0
Training loss: 1.4211763614845643
Validation loss: 2.3973865654971

Epoch: 5| Step: 1
Training loss: 1.8448937957713938
Validation loss: 2.345723486357351

Epoch: 5| Step: 2
Training loss: 1.7700901790857853
Validation loss: 2.428489934109398

Epoch: 5| Step: 3
Training loss: 2.015615892020059
Validation loss: 2.373712718651224

Epoch: 5| Step: 4
Training loss: 1.0300743453036398
Validation loss: 2.3920289298598165

Epoch: 5| Step: 5
Training loss: 1.1596931535094233
Validation loss: 2.38304823192351

Epoch: 5| Step: 6
Training loss: 1.5994989266184776
Validation loss: 2.385424393131181

Epoch: 5| Step: 7
Training loss: 1.1366563498027875
Validation loss: 2.389783851887619

Epoch: 5| Step: 8
Training loss: 1.4631762155778236
Validation loss: 2.351216756417943

Epoch: 5| Step: 9
Training loss: 0.9750755280804794
Validation loss: 2.4287577868499075

Epoch: 5| Step: 10
Training loss: 1.1322088277367839
Validation loss: 2.371562199987451

Epoch: 327| Step: 0
Training loss: 1.9149171128026452
Validation loss: 2.3796705856186975

Epoch: 5| Step: 1
Training loss: 1.2544494117975975
Validation loss: 2.3866950406623104

Epoch: 5| Step: 2
Training loss: 1.1448976626743246
Validation loss: 2.3519381513794277

Epoch: 5| Step: 3
Training loss: 1.6901922296074825
Validation loss: 2.3855007565379758

Epoch: 5| Step: 4
Training loss: 1.1249071718700645
Validation loss: 2.309225465109259

Epoch: 5| Step: 5
Training loss: 1.220864588930857
Validation loss: 2.364524771918514

Epoch: 5| Step: 6
Training loss: 1.2569934713638697
Validation loss: 2.4013935180363357

Epoch: 5| Step: 7
Training loss: 1.2996288154783062
Validation loss: 2.396568792882992

Epoch: 5| Step: 8
Training loss: 1.896380090645441
Validation loss: 2.4153268351036257

Epoch: 5| Step: 9
Training loss: 1.2347119511273772
Validation loss: 2.334174308612193

Epoch: 5| Step: 10
Training loss: 1.2746392880482817
Validation loss: 2.3928851878062463

Epoch: 328| Step: 0
Training loss: 1.684630391252041
Validation loss: 2.366669930099509

Epoch: 5| Step: 1
Training loss: 1.2974497888658314
Validation loss: 2.3929704791027535

Epoch: 5| Step: 2
Training loss: 1.1835895701923154
Validation loss: 2.350736353614682

Epoch: 5| Step: 3
Training loss: 1.6087226656686386
Validation loss: 2.3895623568299804

Epoch: 5| Step: 4
Training loss: 1.29339841405259
Validation loss: 2.341856817393634

Epoch: 5| Step: 5
Training loss: 1.166356789216701
Validation loss: 2.4611689174722593

Epoch: 5| Step: 6
Training loss: 1.7973760818402846
Validation loss: 2.385185545035556

Epoch: 5| Step: 7
Training loss: 1.0771637653494928
Validation loss: 2.3879636314682764

Epoch: 5| Step: 8
Training loss: 1.2997881790133092
Validation loss: 2.393782765282508

Epoch: 5| Step: 9
Training loss: 1.5738834752934792
Validation loss: 2.350294261274299

Epoch: 5| Step: 10
Training loss: 1.6582210975634526
Validation loss: 2.429152357334075

Epoch: 329| Step: 0
Training loss: 1.570817249461972
Validation loss: 2.3569876839901513

Epoch: 5| Step: 1
Training loss: 1.0721106912379257
Validation loss: 2.355105403947306

Epoch: 5| Step: 2
Training loss: 1.4923244233747668
Validation loss: 2.388064649905483

Epoch: 5| Step: 3
Training loss: 1.4408803254306497
Validation loss: 2.333715643377504

Epoch: 5| Step: 4
Training loss: 1.4460175315353436
Validation loss: 2.344449076427389

Epoch: 5| Step: 5
Training loss: 2.107732288596117
Validation loss: 2.335783675674002

Epoch: 5| Step: 6
Training loss: 1.1492042836225946
Validation loss: 2.4516996212892526

Epoch: 5| Step: 7
Training loss: 1.1266466381805824
Validation loss: 2.3521091217109906

Epoch: 5| Step: 8
Training loss: 1.1579055789903046
Validation loss: 2.39532019714121

Epoch: 5| Step: 9
Training loss: 1.3773311447804417
Validation loss: 2.4024470620126124

Epoch: 5| Step: 10
Training loss: 1.4076779638904944
Validation loss: 2.351334945357502

Epoch: 330| Step: 0
Training loss: 1.4529745372686087
Validation loss: 2.3540084034999254

Epoch: 5| Step: 1
Training loss: 1.4040220201210964
Validation loss: 2.347363690429748

Epoch: 5| Step: 2
Training loss: 1.4317585270772437
Validation loss: 2.344590143824291

Epoch: 5| Step: 3
Training loss: 1.3449771511874045
Validation loss: 2.3766070737611744

Epoch: 5| Step: 4
Training loss: 1.3450557220006016
Validation loss: 2.35497621393829

Epoch: 5| Step: 5
Training loss: 1.0648434544518803
Validation loss: 2.364654998448608

Epoch: 5| Step: 6
Training loss: 1.2326465528843897
Validation loss: 2.4184926517562038

Epoch: 5| Step: 7
Training loss: 1.594827400004864
Validation loss: 2.299128403308686

Epoch: 5| Step: 8
Training loss: 1.240780879684641
Validation loss: 2.3523864741559994

Epoch: 5| Step: 9
Training loss: 1.8449453584596764
Validation loss: 2.4245933168444314

Epoch: 5| Step: 10
Training loss: 1.1901019852477044
Validation loss: 2.4155676936303343

Epoch: 331| Step: 0
Training loss: 0.8981249058138719
Validation loss: 2.411926369402492

Epoch: 5| Step: 1
Training loss: 1.36982655450561
Validation loss: 2.390774482988075

Epoch: 5| Step: 2
Training loss: 1.5092281356979387
Validation loss: 2.4205751538482154

Epoch: 5| Step: 3
Training loss: 1.0575086374133005
Validation loss: 2.33165186037536

Epoch: 5| Step: 4
Training loss: 1.2543568974867492
Validation loss: 2.3994731563663243

Epoch: 5| Step: 5
Training loss: 1.359674968727492
Validation loss: 2.3455004329441542

Epoch: 5| Step: 6
Training loss: 1.6507851033271845
Validation loss: 2.398657732506274

Epoch: 5| Step: 7
Training loss: 1.2876122842362103
Validation loss: 2.3758746373295656

Epoch: 5| Step: 8
Training loss: 0.9254572176532759
Validation loss: 2.3552193120918496

Epoch: 5| Step: 9
Training loss: 1.4910811871812168
Validation loss: 2.4381654355360434

Epoch: 5| Step: 10
Training loss: 2.366312904065887
Validation loss: 2.441902077087202

Epoch: 332| Step: 0
Training loss: 1.4949483844688258
Validation loss: 2.40805666470115

Epoch: 5| Step: 1
Training loss: 1.3091419039803842
Validation loss: 2.394966443395542

Epoch: 5| Step: 2
Training loss: 1.32936832349183
Validation loss: 2.4039420662133653

Epoch: 5| Step: 3
Training loss: 1.4406748003844054
Validation loss: 2.3757421815934907

Epoch: 5| Step: 4
Training loss: 1.1148303581133838
Validation loss: 2.3970091051125055

Epoch: 5| Step: 5
Training loss: 0.9997729997481382
Validation loss: 2.3999043824604867

Epoch: 5| Step: 6
Training loss: 1.6351125478941826
Validation loss: 2.356102767909266

Epoch: 5| Step: 7
Training loss: 1.265729876281993
Validation loss: 2.363916474813815

Epoch: 5| Step: 8
Training loss: 1.2490202879101708
Validation loss: 2.3993687333160842

Epoch: 5| Step: 9
Training loss: 1.7073038612412774
Validation loss: 2.425279110339073

Epoch: 5| Step: 10
Training loss: 1.5858870625109698
Validation loss: 2.3737726780566395

Epoch: 333| Step: 0
Training loss: 1.3281397201619913
Validation loss: 2.3349504225310964

Epoch: 5| Step: 1
Training loss: 1.3317270239152603
Validation loss: 2.3725185092191183

Epoch: 5| Step: 2
Training loss: 1.3488966830782734
Validation loss: 2.326496386280256

Epoch: 5| Step: 3
Training loss: 1.2372700988222318
Validation loss: 2.3568698100602754

Epoch: 5| Step: 4
Training loss: 1.2323484565158418
Validation loss: 2.385454076450429

Epoch: 5| Step: 5
Training loss: 1.5769933287697748
Validation loss: 2.3436978351434696

Epoch: 5| Step: 6
Training loss: 1.5617687039880361
Validation loss: 2.3988995481280417

Epoch: 5| Step: 7
Training loss: 1.2897651375763812
Validation loss: 2.3290747047300324

Epoch: 5| Step: 8
Training loss: 1.003422186255583
Validation loss: 2.387341592957627

Epoch: 5| Step: 9
Training loss: 1.3812088800583975
Validation loss: 2.385444152676543

Epoch: 5| Step: 10
Training loss: 1.8419337621246226
Validation loss: 2.4603726865404942

Epoch: 334| Step: 0
Training loss: 1.3722358576594351
Validation loss: 2.32876269635163

Epoch: 5| Step: 1
Training loss: 1.7728868209293083
Validation loss: 2.324716639201703

Epoch: 5| Step: 2
Training loss: 1.5859709487168894
Validation loss: 2.3905380247142687

Epoch: 5| Step: 3
Training loss: 1.3741938221694463
Validation loss: 2.445435049500948

Epoch: 5| Step: 4
Training loss: 0.6871065617905497
Validation loss: 2.418296457117778

Epoch: 5| Step: 5
Training loss: 1.8235360610069784
Validation loss: 2.3576395744594056

Epoch: 5| Step: 6
Training loss: 1.230628060820935
Validation loss: 2.4050734804904548

Epoch: 5| Step: 7
Training loss: 1.2187081354237956
Validation loss: 2.431080541523817

Epoch: 5| Step: 8
Training loss: 1.0774097004732928
Validation loss: 2.3836500783328027

Epoch: 5| Step: 9
Training loss: 1.6277566416210474
Validation loss: 2.37304990852554

Epoch: 5| Step: 10
Training loss: 1.4578616151375965
Validation loss: 2.4202259516288542

Epoch: 335| Step: 0
Training loss: 1.112120012688685
Validation loss: 2.3563270039891933

Epoch: 5| Step: 1
Training loss: 0.9817136179528645
Validation loss: 2.380248877329306

Epoch: 5| Step: 2
Training loss: 1.418288686089198
Validation loss: 2.388180644392583

Epoch: 5| Step: 3
Training loss: 1.4020171993958324
Validation loss: 2.3462579774902053

Epoch: 5| Step: 4
Training loss: 1.4835537696662175
Validation loss: 2.3528042611713134

Epoch: 5| Step: 5
Training loss: 2.184910358536777
Validation loss: 2.3394188089062538

Epoch: 5| Step: 6
Training loss: 1.3511230989305694
Validation loss: 2.2618588396339527

Epoch: 5| Step: 7
Training loss: 1.27905890894166
Validation loss: 2.386582004260352

Epoch: 5| Step: 8
Training loss: 1.1400924379951685
Validation loss: 2.3860010592932217

Epoch: 5| Step: 9
Training loss: 1.6127198653438566
Validation loss: 2.3843146662182395

Epoch: 5| Step: 10
Training loss: 1.1455444434147366
Validation loss: 2.3855272656945647

Epoch: 336| Step: 0
Training loss: 1.5490961023395053
Validation loss: 2.3553247297724917

Epoch: 5| Step: 1
Training loss: 1.3030990250374872
Validation loss: 2.3324245808867303

Epoch: 5| Step: 2
Training loss: 1.4247476253888003
Validation loss: 2.4017779223086015

Epoch: 5| Step: 3
Training loss: 1.3587358221667254
Validation loss: 2.3513376361955216

Epoch: 5| Step: 4
Training loss: 1.6066440262261135
Validation loss: 2.3790687764018834

Epoch: 5| Step: 5
Training loss: 1.7195427193577626
Validation loss: 2.3547456990987876

Epoch: 5| Step: 6
Training loss: 1.5058493211858366
Validation loss: 2.4473602790179885

Epoch: 5| Step: 7
Training loss: 1.0724328749664935
Validation loss: 2.4202438519421947

Epoch: 5| Step: 8
Training loss: 1.2186491508818058
Validation loss: 2.410361977593867

Epoch: 5| Step: 9
Training loss: 1.3806040742323584
Validation loss: 2.3356274714482588

Epoch: 5| Step: 10
Training loss: 1.1845944646651578
Validation loss: 2.3134598562206294

Epoch: 337| Step: 0
Training loss: 1.321849402502232
Validation loss: 2.351501892505841

Epoch: 5| Step: 1
Training loss: 1.0447195267168499
Validation loss: 2.3638910423331883

Epoch: 5| Step: 2
Training loss: 1.1003388446491487
Validation loss: 2.4106410319096683

Epoch: 5| Step: 3
Training loss: 1.1246741140745005
Validation loss: 2.358264270749445

Epoch: 5| Step: 4
Training loss: 1.6801127050832712
Validation loss: 2.3611631049508364

Epoch: 5| Step: 5
Training loss: 1.4517660862586699
Validation loss: 2.348337272029338

Epoch: 5| Step: 6
Training loss: 1.405989983149914
Validation loss: 2.3592997023300715

Epoch: 5| Step: 7
Training loss: 1.333192649015527
Validation loss: 2.363635963851811

Epoch: 5| Step: 8
Training loss: 1.7377883726714651
Validation loss: 2.406134839838703

Epoch: 5| Step: 9
Training loss: 1.7285337630360145
Validation loss: 2.3732826919563546

Epoch: 5| Step: 10
Training loss: 1.5879144232774214
Validation loss: 2.3967936916143686

Epoch: 338| Step: 0
Training loss: 1.316661368532426
Validation loss: 2.4361309606330015

Epoch: 5| Step: 1
Training loss: 0.9861985527515332
Validation loss: 2.424765379440163

Epoch: 5| Step: 2
Training loss: 1.090432612985564
Validation loss: 2.3544990536490413

Epoch: 5| Step: 3
Training loss: 1.1789751238766795
Validation loss: 2.3472800553412445

Epoch: 5| Step: 4
Training loss: 1.156544055147441
Validation loss: 2.330893471644351

Epoch: 5| Step: 5
Training loss: 1.4258564132317724
Validation loss: 2.3663176698953676

Epoch: 5| Step: 6
Training loss: 2.371879635933227
Validation loss: 2.368303156595789

Epoch: 5| Step: 7
Training loss: 1.5467691096273273
Validation loss: 2.3492024747313245

Epoch: 5| Step: 8
Training loss: 1.2738004295990468
Validation loss: 2.4253564555488016

Epoch: 5| Step: 9
Training loss: 0.9287858004235368
Validation loss: 2.3735599556144216

Epoch: 5| Step: 10
Training loss: 1.4305762358387724
Validation loss: 2.5231754074546724

Epoch: 339| Step: 0
Training loss: 1.5408585810445306
Validation loss: 2.4014151190238153

Epoch: 5| Step: 1
Training loss: 1.184579470253915
Validation loss: 2.4458797907701917

Epoch: 5| Step: 2
Training loss: 1.6820033232784213
Validation loss: 2.35836161420368

Epoch: 5| Step: 3
Training loss: 1.0947690848294016
Validation loss: 2.3701715842076307

Epoch: 5| Step: 4
Training loss: 1.3994096328654597
Validation loss: 2.4332542484825774

Epoch: 5| Step: 5
Training loss: 1.5426678714258428
Validation loss: 2.3905545044060568

Epoch: 5| Step: 6
Training loss: 1.6560622774659481
Validation loss: 2.390608521866554

Epoch: 5| Step: 7
Training loss: 1.2689801237625413
Validation loss: 2.4559968089090685

Epoch: 5| Step: 8
Training loss: 1.5993724456563976
Validation loss: 2.3386095807575202

Epoch: 5| Step: 9
Training loss: 1.2796799879587206
Validation loss: 2.3669364582463728

Epoch: 5| Step: 10
Training loss: 1.1265644216322679
Validation loss: 2.367617490325288

Epoch: 340| Step: 0
Training loss: 1.0404070422596023
Validation loss: 2.406044667729179

Epoch: 5| Step: 1
Training loss: 1.2154735637568983
Validation loss: 2.307821049509414

Epoch: 5| Step: 2
Training loss: 0.9909919384090518
Validation loss: 2.3565113541871123

Epoch: 5| Step: 3
Training loss: 1.686102394334249
Validation loss: 2.39145475868496

Epoch: 5| Step: 4
Training loss: 1.1032131084235974
Validation loss: 2.411338024070213

Epoch: 5| Step: 5
Training loss: 1.720305207364375
Validation loss: 2.4015123413457773

Epoch: 5| Step: 6
Training loss: 1.0949221733166346
Validation loss: 2.390632644395525

Epoch: 5| Step: 7
Training loss: 2.12647925108136
Validation loss: 2.3311650893122

Epoch: 5| Step: 8
Training loss: 1.2226861334613055
Validation loss: 2.3910585477200046

Epoch: 5| Step: 9
Training loss: 1.113897641518299
Validation loss: 2.4104772309368845

Epoch: 5| Step: 10
Training loss: 1.2567743317415332
Validation loss: 2.3728216897193994

Epoch: 341| Step: 0
Training loss: 1.3436129300491597
Validation loss: 2.4079867885578286

Epoch: 5| Step: 1
Training loss: 1.0498281928691222
Validation loss: 2.3517589553122527

Epoch: 5| Step: 2
Training loss: 1.4540743444187025
Validation loss: 2.374498139418284

Epoch: 5| Step: 3
Training loss: 1.161878392962036
Validation loss: 2.373233588401037

Epoch: 5| Step: 4
Training loss: 1.472887339787873
Validation loss: 2.387725342300563

Epoch: 5| Step: 5
Training loss: 1.855907508773491
Validation loss: 2.398870151942994

Epoch: 5| Step: 6
Training loss: 1.3955313892121406
Validation loss: 2.2969675380986168

Epoch: 5| Step: 7
Training loss: 1.3350931812298827
Validation loss: 2.3162132699779803

Epoch: 5| Step: 8
Training loss: 1.388432435158046
Validation loss: 2.3529049349576416

Epoch: 5| Step: 9
Training loss: 1.287957845223118
Validation loss: 2.3389596244704327

Epoch: 5| Step: 10
Training loss: 1.3394321888344023
Validation loss: 2.3754508567974635

Epoch: 342| Step: 0
Training loss: 1.4238354927364245
Validation loss: 2.3007398280192293

Epoch: 5| Step: 1
Training loss: 1.2944393035520996
Validation loss: 2.365987808284059

Epoch: 5| Step: 2
Training loss: 1.7517635451269924
Validation loss: 2.378614177818481

Epoch: 5| Step: 3
Training loss: 1.2853584478333286
Validation loss: 2.3190786236013516

Epoch: 5| Step: 4
Training loss: 1.3499540780345545
Validation loss: 2.3597977271838197

Epoch: 5| Step: 5
Training loss: 2.101708049059199
Validation loss: 2.4106515251298375

Epoch: 5| Step: 6
Training loss: 0.7067407886038434
Validation loss: 2.3638481922519454

Epoch: 5| Step: 7
Training loss: 1.0049563604341003
Validation loss: 2.312409409974415

Epoch: 5| Step: 8
Training loss: 1.3485615219068112
Validation loss: 2.4024851122054

Epoch: 5| Step: 9
Training loss: 1.2185358201633045
Validation loss: 2.3936604062827374

Epoch: 5| Step: 10
Training loss: 1.3810864468228328
Validation loss: 2.3648157699838044

Epoch: 343| Step: 0
Training loss: 1.0531616476230845
Validation loss: 2.3874430028074243

Epoch: 5| Step: 1
Training loss: 1.5844150997105897
Validation loss: 2.3577917782609386

Epoch: 5| Step: 2
Training loss: 1.0799206141152866
Validation loss: 2.383017219882128

Epoch: 5| Step: 3
Training loss: 1.2886101131202814
Validation loss: 2.3959802426474366

Epoch: 5| Step: 4
Training loss: 2.1020228225674047
Validation loss: 2.472783293670606

Epoch: 5| Step: 5
Training loss: 1.0239737467157117
Validation loss: 2.363842558163844

Epoch: 5| Step: 6
Training loss: 1.1944823530130304
Validation loss: 2.3893999948626323

Epoch: 5| Step: 7
Training loss: 1.344997935453057
Validation loss: 2.35486532050316

Epoch: 5| Step: 8
Training loss: 1.5658833303923492
Validation loss: 2.359994447467655

Epoch: 5| Step: 9
Training loss: 1.3643960848553889
Validation loss: 2.3406914139683708

Epoch: 5| Step: 10
Training loss: 1.1392582059375929
Validation loss: 2.349514269108231

Epoch: 344| Step: 0
Training loss: 1.3723495687930134
Validation loss: 2.36859167621161

Epoch: 5| Step: 1
Training loss: 1.1715369181919302
Validation loss: 2.3603362958550305

Epoch: 5| Step: 2
Training loss: 0.9428615480687497
Validation loss: 2.347105574989552

Epoch: 5| Step: 3
Training loss: 1.293245591320382
Validation loss: 2.376552010998113

Epoch: 5| Step: 4
Training loss: 1.415417606749104
Validation loss: 2.366732025269459

Epoch: 5| Step: 5
Training loss: 1.8639497017766262
Validation loss: 2.3532566297554194

Epoch: 5| Step: 6
Training loss: 1.376282787157654
Validation loss: 2.310290681679292

Epoch: 5| Step: 7
Training loss: 1.9075906760485626
Validation loss: 2.355113463528314

Epoch: 5| Step: 8
Training loss: 1.2773081923269047
Validation loss: 2.3667431431929913

Epoch: 5| Step: 9
Training loss: 1.2483614195366406
Validation loss: 2.3630940767869624

Epoch: 5| Step: 10
Training loss: 1.2460711725276348
Validation loss: 2.400890815844788

Epoch: 345| Step: 0
Training loss: 1.3974509568727713
Validation loss: 2.2996644825336925

Epoch: 5| Step: 1
Training loss: 1.0811370570118812
Validation loss: 2.3097788912726407

Epoch: 5| Step: 2
Training loss: 1.4467944821061347
Validation loss: 2.406320189192913

Epoch: 5| Step: 3
Training loss: 1.1590503597986488
Validation loss: 2.364439145993232

Epoch: 5| Step: 4
Training loss: 1.8188769528890558
Validation loss: 2.313527608101655

Epoch: 5| Step: 5
Training loss: 1.7417592433193034
Validation loss: 2.3308373449100546

Epoch: 5| Step: 6
Training loss: 1.359497284047878
Validation loss: 2.3392531101633485

Epoch: 5| Step: 7
Training loss: 1.2697090376563016
Validation loss: 2.304371798586875

Epoch: 5| Step: 8
Training loss: 1.1057330243616406
Validation loss: 2.3259297562246806

Epoch: 5| Step: 9
Training loss: 1.477656045280185
Validation loss: 2.3693867071124477

Epoch: 5| Step: 10
Training loss: 1.2356541440205888
Validation loss: 2.2900434564337133

Epoch: 346| Step: 0
Training loss: 0.9915927395926823
Validation loss: 2.350669084708848

Epoch: 5| Step: 1
Training loss: 2.025525050912123
Validation loss: 2.3764380498407998

Epoch: 5| Step: 2
Training loss: 1.5301852514275922
Validation loss: 2.3800924989255208

Epoch: 5| Step: 3
Training loss: 1.6066680661006758
Validation loss: 2.3812410759192737

Epoch: 5| Step: 4
Training loss: 1.5002705012241164
Validation loss: 2.373358001832537

Epoch: 5| Step: 5
Training loss: 1.0511204622270303
Validation loss: 2.401678495806729

Epoch: 5| Step: 6
Training loss: 1.049399619799153
Validation loss: 2.3948957758664626

Epoch: 5| Step: 7
Training loss: 1.4399328791022101
Validation loss: 2.3604599755390345

Epoch: 5| Step: 8
Training loss: 0.9983402724229217
Validation loss: 2.423141297698494

Epoch: 5| Step: 9
Training loss: 1.1610887164572896
Validation loss: 2.368702527707247

Epoch: 5| Step: 10
Training loss: 1.2545062379556513
Validation loss: 2.3753562556425076

Epoch: 347| Step: 0
Training loss: 1.9200260603646109
Validation loss: 2.3165126620391763

Epoch: 5| Step: 1
Training loss: 1.314471535178234
Validation loss: 2.403787048932113

Epoch: 5| Step: 2
Training loss: 1.6698424917169747
Validation loss: 2.3769952783100896

Epoch: 5| Step: 3
Training loss: 1.3595677820068974
Validation loss: 2.4338643505894506

Epoch: 5| Step: 4
Training loss: 1.2006155819302573
Validation loss: 2.371441881403922

Epoch: 5| Step: 5
Training loss: 1.1071532123714258
Validation loss: 2.3699864830868065

Epoch: 5| Step: 6
Training loss: 1.478475229978849
Validation loss: 2.4206549274182985

Epoch: 5| Step: 7
Training loss: 1.3631704990466638
Validation loss: 2.300583409010953

Epoch: 5| Step: 8
Training loss: 1.0733808544155208
Validation loss: 2.3178518857579378

Epoch: 5| Step: 9
Training loss: 1.1251285267632538
Validation loss: 2.402707542995565

Epoch: 5| Step: 10
Training loss: 1.1172098010845064
Validation loss: 2.39447329700187

Epoch: 348| Step: 0
Training loss: 1.2876243197964514
Validation loss: 2.3574543315969727

Epoch: 5| Step: 1
Training loss: 1.5133387832851557
Validation loss: 2.320249259768903

Epoch: 5| Step: 2
Training loss: 1.5356028443517076
Validation loss: 2.4181409892389003

Epoch: 5| Step: 3
Training loss: 0.9854454396558818
Validation loss: 2.3704060768264648

Epoch: 5| Step: 4
Training loss: 1.2583275919061165
Validation loss: 2.3745942894558483

Epoch: 5| Step: 5
Training loss: 1.4829452857163905
Validation loss: 2.354051403287951

Epoch: 5| Step: 6
Training loss: 1.1855998145260325
Validation loss: 2.2747057744644144

Epoch: 5| Step: 7
Training loss: 1.0153365679301358
Validation loss: 2.3085696275338226

Epoch: 5| Step: 8
Training loss: 0.9444850421264318
Validation loss: 2.3306784404258285

Epoch: 5| Step: 9
Training loss: 1.9075246832814199
Validation loss: 2.369318016305468

Epoch: 5| Step: 10
Training loss: 1.2955280340909179
Validation loss: 2.409431536168809

Epoch: 349| Step: 0
Training loss: 1.2517738630527908
Validation loss: 2.314355411857882

Epoch: 5| Step: 1
Training loss: 1.250609440056174
Validation loss: 2.374202409763004

Epoch: 5| Step: 2
Training loss: 1.2338184115874657
Validation loss: 2.3196461066124043

Epoch: 5| Step: 3
Training loss: 1.1109735496455733
Validation loss: 2.4077703794411667

Epoch: 5| Step: 4
Training loss: 1.3246952876109341
Validation loss: 2.341614178950337

Epoch: 5| Step: 5
Training loss: 1.064465555940889
Validation loss: 2.4045520700117633

Epoch: 5| Step: 6
Training loss: 2.1644725204559845
Validation loss: 2.3318127835746996

Epoch: 5| Step: 7
Training loss: 1.7034654189603469
Validation loss: 2.41070797950817

Epoch: 5| Step: 8
Training loss: 1.152121157079899
Validation loss: 2.4481939182788026

Epoch: 5| Step: 9
Training loss: 1.245661932765699
Validation loss: 2.425765206196714

Epoch: 5| Step: 10
Training loss: 1.1815452852485764
Validation loss: 2.424983082407719

Epoch: 350| Step: 0
Training loss: 1.4761276008323971
Validation loss: 2.3840960701637264

Epoch: 5| Step: 1
Training loss: 1.261465749973426
Validation loss: 2.335132884614308

Epoch: 5| Step: 2
Training loss: 1.4378839063085866
Validation loss: 2.3487508405810216

Epoch: 5| Step: 3
Training loss: 1.1549360696843716
Validation loss: 2.390196558424174

Epoch: 5| Step: 4
Training loss: 1.3139238354688632
Validation loss: 2.3580649635067257

Epoch: 5| Step: 5
Training loss: 1.1931168080243997
Validation loss: 2.2740370598332205

Epoch: 5| Step: 6
Training loss: 1.2781417640388752
Validation loss: 2.352237610911943

Epoch: 5| Step: 7
Training loss: 1.8406423467521404
Validation loss: 2.3605719750870664

Epoch: 5| Step: 8
Training loss: 1.3330784146681829
Validation loss: 2.3691522650918877

Epoch: 5| Step: 9
Training loss: 1.2831398122371964
Validation loss: 2.341079025650364

Epoch: 5| Step: 10
Training loss: 1.1351971486987973
Validation loss: 2.383363549422225

Epoch: 351| Step: 0
Training loss: 0.8932228681307045
Validation loss: 2.362307089109696

Epoch: 5| Step: 1
Training loss: 1.8142323600896564
Validation loss: 2.369530632700274

Epoch: 5| Step: 2
Training loss: 1.1156815736247916
Validation loss: 2.3950870123704853

Epoch: 5| Step: 3
Training loss: 0.8769404149143314
Validation loss: 2.3614150427348792

Epoch: 5| Step: 4
Training loss: 1.2341229628132013
Validation loss: 2.384482916778321

Epoch: 5| Step: 5
Training loss: 1.497686509377411
Validation loss: 2.418415419355465

Epoch: 5| Step: 6
Training loss: 1.9021987389786645
Validation loss: 2.3476433763766504

Epoch: 5| Step: 7
Training loss: 1.28091649622936
Validation loss: 2.430129249872958

Epoch: 5| Step: 8
Training loss: 1.4465016190183237
Validation loss: 2.3346586854513802

Epoch: 5| Step: 9
Training loss: 1.346487140791011
Validation loss: 2.477872804989305

Epoch: 5| Step: 10
Training loss: 0.9232784192307686
Validation loss: 2.4115671233273726

Epoch: 352| Step: 0
Training loss: 2.3859381515212252
Validation loss: 2.324299905983073

Epoch: 5| Step: 1
Training loss: 1.2591152197735298
Validation loss: 2.4089606478680268

Epoch: 5| Step: 2
Training loss: 1.3422558483977574
Validation loss: 2.335071078871199

Epoch: 5| Step: 3
Training loss: 1.0876802141672963
Validation loss: 2.326589021097912

Epoch: 5| Step: 4
Training loss: 1.2099761592470946
Validation loss: 2.3083011384913914

Epoch: 5| Step: 5
Training loss: 1.2180971206441855
Validation loss: 2.289618204358067

Epoch: 5| Step: 6
Training loss: 1.181608896381228
Validation loss: 2.2946832543713374

Epoch: 5| Step: 7
Training loss: 1.3657270205731125
Validation loss: 2.3353148110003334

Epoch: 5| Step: 8
Training loss: 1.0445057833754783
Validation loss: 2.3551845088915404

Epoch: 5| Step: 9
Training loss: 1.2916771929322248
Validation loss: 2.3353293662993013

Epoch: 5| Step: 10
Training loss: 1.1839462611433036
Validation loss: 2.3400788260406133

Epoch: 353| Step: 0
Training loss: 1.0831560699004021
Validation loss: 2.337792044244139

Epoch: 5| Step: 1
Training loss: 1.2645657191969224
Validation loss: 2.3754944694077667

Epoch: 5| Step: 2
Training loss: 1.5715843857268916
Validation loss: 2.3644770651273177

Epoch: 5| Step: 3
Training loss: 0.9609805151763242
Validation loss: 2.385307832556422

Epoch: 5| Step: 4
Training loss: 1.284313818595128
Validation loss: 2.4101656984057698

Epoch: 5| Step: 5
Training loss: 1.0359418083550116
Validation loss: 2.406423918020681

Epoch: 5| Step: 6
Training loss: 1.1890455026702507
Validation loss: 2.3834677094130283

Epoch: 5| Step: 7
Training loss: 1.1447968679257299
Validation loss: 2.3756192354821577

Epoch: 5| Step: 8
Training loss: 1.4695480288937357
Validation loss: 2.3692811571346235

Epoch: 5| Step: 9
Training loss: 1.3523600876480766
Validation loss: 2.321719790851764

Epoch: 5| Step: 10
Training loss: 1.9038304466838583
Validation loss: 2.3008298914200083

Epoch: 354| Step: 0
Training loss: 1.1488106050163882
Validation loss: 2.3731179916803495

Epoch: 5| Step: 1
Training loss: 1.2160656049623761
Validation loss: 2.3745036273022606

Epoch: 5| Step: 2
Training loss: 1.3119849602285019
Validation loss: 2.322521089031809

Epoch: 5| Step: 3
Training loss: 1.389087040859258
Validation loss: 2.3569982812006205

Epoch: 5| Step: 4
Training loss: 1.106063844352216
Validation loss: 2.392615372629646

Epoch: 5| Step: 5
Training loss: 1.3422761863389359
Validation loss: 2.3166907013627336

Epoch: 5| Step: 6
Training loss: 1.1128497441911744
Validation loss: 2.3922673845777735

Epoch: 5| Step: 7
Training loss: 1.1916737740755983
Validation loss: 2.2983661649938565

Epoch: 5| Step: 8
Training loss: 1.6907281022707659
Validation loss: 2.3655965451273566

Epoch: 5| Step: 9
Training loss: 1.4507342945690367
Validation loss: 2.382004874363057

Epoch: 5| Step: 10
Training loss: 1.4647860502959056
Validation loss: 2.3093316540818662

Epoch: 355| Step: 0
Training loss: 1.6066932927427624
Validation loss: 2.3612757849970047

Epoch: 5| Step: 1
Training loss: 1.833045402226785
Validation loss: 2.3243343206998293

Epoch: 5| Step: 2
Training loss: 1.0605834617415846
Validation loss: 2.3510717778604286

Epoch: 5| Step: 3
Training loss: 1.055076809839575
Validation loss: 2.3533013427141714

Epoch: 5| Step: 4
Training loss: 1.3565105644992985
Validation loss: 2.4331700402828838

Epoch: 5| Step: 5
Training loss: 1.2493826772311774
Validation loss: 2.3522716343261556

Epoch: 5| Step: 6
Training loss: 1.2585720351635092
Validation loss: 2.305715243257109

Epoch: 5| Step: 7
Training loss: 0.8354929517383615
Validation loss: 2.3641808572828693

Epoch: 5| Step: 8
Training loss: 1.5405224686679995
Validation loss: 2.416692562480792

Epoch: 5| Step: 9
Training loss: 1.2522345597040077
Validation loss: 2.268312831993458

Epoch: 5| Step: 10
Training loss: 1.1460559050819652
Validation loss: 2.3645814764888216

Epoch: 356| Step: 0
Training loss: 1.0860342627577309
Validation loss: 2.3773493046868355

Epoch: 5| Step: 1
Training loss: 1.6139945976989412
Validation loss: 2.3913041335867837

Epoch: 5| Step: 2
Training loss: 1.3130107975593523
Validation loss: 2.4041311744857805

Epoch: 5| Step: 3
Training loss: 1.3345621625444017
Validation loss: 2.348572983012858

Epoch: 5| Step: 4
Training loss: 0.9850621322941921
Validation loss: 2.357493625600455

Epoch: 5| Step: 5
Training loss: 1.8512952909525207
Validation loss: 2.2954711228872626

Epoch: 5| Step: 6
Training loss: 1.643749495241501
Validation loss: 2.3425354028792444

Epoch: 5| Step: 7
Training loss: 0.7413928546238071
Validation loss: 2.316154153749142

Epoch: 5| Step: 8
Training loss: 1.2015361450638502
Validation loss: 2.3961336904386017

Epoch: 5| Step: 9
Training loss: 1.256456200676872
Validation loss: 2.469292332540711

Epoch: 5| Step: 10
Training loss: 1.3443355615170003
Validation loss: 2.407214342924257

Epoch: 357| Step: 0
Training loss: 1.0407734029073479
Validation loss: 2.3283912873640924

Epoch: 5| Step: 1
Training loss: 1.2155868367380245
Validation loss: 2.3949771787001564

Epoch: 5| Step: 2
Training loss: 1.4760779337531815
Validation loss: 2.4320779091520257

Epoch: 5| Step: 3
Training loss: 1.8616453783029905
Validation loss: 2.3321912060708714

Epoch: 5| Step: 4
Training loss: 1.2199612003160138
Validation loss: 2.3932784858954714

Epoch: 5| Step: 5
Training loss: 1.271266561154618
Validation loss: 2.3795962048854684

Epoch: 5| Step: 6
Training loss: 1.7163283888216574
Validation loss: 2.4260143693589815

Epoch: 5| Step: 7
Training loss: 1.04342567064698
Validation loss: 2.3850935033598755

Epoch: 5| Step: 8
Training loss: 0.9684289584871022
Validation loss: 2.40359796531423

Epoch: 5| Step: 9
Training loss: 1.2940256460911812
Validation loss: 2.416501257740996

Epoch: 5| Step: 10
Training loss: 1.0847668272402582
Validation loss: 2.3346157611325857

Epoch: 358| Step: 0
Training loss: 1.517281325294248
Validation loss: 2.3249869236979195

Epoch: 5| Step: 1
Training loss: 1.4554891735370097
Validation loss: 2.311611704455057

Epoch: 5| Step: 2
Training loss: 1.2572497418020867
Validation loss: 2.374392811262808

Epoch: 5| Step: 3
Training loss: 1.383344041637354
Validation loss: 2.354685296564983

Epoch: 5| Step: 4
Training loss: 1.4526889926256255
Validation loss: 2.3721091871478355

Epoch: 5| Step: 5
Training loss: 1.2991495523473495
Validation loss: 2.3836549729759637

Epoch: 5| Step: 6
Training loss: 0.9795677330876679
Validation loss: 2.299407595163295

Epoch: 5| Step: 7
Training loss: 1.3886541051572712
Validation loss: 2.366879464576809

Epoch: 5| Step: 8
Training loss: 1.1187855421845803
Validation loss: 2.307963810292614

Epoch: 5| Step: 9
Training loss: 1.6475403862085543
Validation loss: 2.347684079455167

Epoch: 5| Step: 10
Training loss: 1.0087706867918886
Validation loss: 2.291942649921264

Epoch: 359| Step: 0
Training loss: 1.2253188127093866
Validation loss: 2.408798332243514

Epoch: 5| Step: 1
Training loss: 1.3461464205736198
Validation loss: 2.363331819198526

Epoch: 5| Step: 2
Training loss: 1.3513987888567303
Validation loss: 2.431509862814353

Epoch: 5| Step: 3
Training loss: 1.1383156063678572
Validation loss: 2.40984997299333

Epoch: 5| Step: 4
Training loss: 1.8154028305193024
Validation loss: 2.4527455690855273

Epoch: 5| Step: 5
Training loss: 1.767601459833886
Validation loss: 2.3454552805269833

Epoch: 5| Step: 6
Training loss: 0.9277042102929126
Validation loss: 2.407091057417715

Epoch: 5| Step: 7
Training loss: 1.389466306609397
Validation loss: 2.3783072030513273

Epoch: 5| Step: 8
Training loss: 0.8703111288994719
Validation loss: 2.3850142139491006

Epoch: 5| Step: 9
Training loss: 1.0437670449332768
Validation loss: 2.437459779696255

Epoch: 5| Step: 10
Training loss: 1.4765234240654515
Validation loss: 2.435568316760053

Epoch: 360| Step: 0
Training loss: 1.1831768044295667
Validation loss: 2.390629592967234

Epoch: 5| Step: 1
Training loss: 0.8808010107357694
Validation loss: 2.344152850459975

Epoch: 5| Step: 2
Training loss: 1.3715005906813376
Validation loss: 2.328972893793109

Epoch: 5| Step: 3
Training loss: 1.3252419538730416
Validation loss: 2.377063197234458

Epoch: 5| Step: 4
Training loss: 1.5170001054687061
Validation loss: 2.3341227386716517

Epoch: 5| Step: 5
Training loss: 1.3452748806220527
Validation loss: 2.3792617892911117

Epoch: 5| Step: 6
Training loss: 1.4407040919771306
Validation loss: 2.327041190911686

Epoch: 5| Step: 7
Training loss: 0.9030135670062026
Validation loss: 2.347986895237223

Epoch: 5| Step: 8
Training loss: 1.1605561463079739
Validation loss: 2.3664343349276677

Epoch: 5| Step: 9
Training loss: 1.0353716931979362
Validation loss: 2.3736167829362786

Epoch: 5| Step: 10
Training loss: 1.8484561148550218
Validation loss: 2.3268347368706146

Epoch: 361| Step: 0
Training loss: 1.2573882625527728
Validation loss: 2.370488768372846

Epoch: 5| Step: 1
Training loss: 1.2316491172393706
Validation loss: 2.37257693203636

Epoch: 5| Step: 2
Training loss: 1.6737234289839336
Validation loss: 2.3882382836767397

Epoch: 5| Step: 3
Training loss: 1.0060052562219866
Validation loss: 2.371190731107852

Epoch: 5| Step: 4
Training loss: 1.3981234235076816
Validation loss: 2.388396215379664

Epoch: 5| Step: 5
Training loss: 1.876252518969223
Validation loss: 2.405375687912198

Epoch: 5| Step: 6
Training loss: 1.4210107713058893
Validation loss: 2.4235172743862123

Epoch: 5| Step: 7
Training loss: 1.2878607031713525
Validation loss: 2.3350300768800296

Epoch: 5| Step: 8
Training loss: 0.6930443921354849
Validation loss: 2.4201248487581966

Epoch: 5| Step: 9
Training loss: 1.3506331142480121
Validation loss: 2.4100574659242024

Epoch: 5| Step: 10
Training loss: 0.6770608947165823
Validation loss: 2.415879810651653

Epoch: 362| Step: 0
Training loss: 1.4165574293468717
Validation loss: 2.295263743598429

Epoch: 5| Step: 1
Training loss: 1.1171489788963664
Validation loss: 2.3936287362284183

Epoch: 5| Step: 2
Training loss: 1.3727509571767516
Validation loss: 2.3518152525937532

Epoch: 5| Step: 3
Training loss: 0.9072755404125731
Validation loss: 2.3724064009798163

Epoch: 5| Step: 4
Training loss: 1.6023794184173819
Validation loss: 2.368289077819971

Epoch: 5| Step: 5
Training loss: 1.6028935553511896
Validation loss: 2.3770195546277257

Epoch: 5| Step: 6
Training loss: 1.2381343814623447
Validation loss: 2.343284893852723

Epoch: 5| Step: 7
Training loss: 1.0098323836846006
Validation loss: 2.348563242880024

Epoch: 5| Step: 8
Training loss: 1.839859689048195
Validation loss: 2.3184117583420685

Epoch: 5| Step: 9
Training loss: 1.01965530050061
Validation loss: 2.3689894133104494

Epoch: 5| Step: 10
Training loss: 0.9549061126893647
Validation loss: 2.394924155739401

Epoch: 363| Step: 0
Training loss: 1.6328383448257369
Validation loss: 2.3954365305831415

Epoch: 5| Step: 1
Training loss: 1.3633988556509993
Validation loss: 2.443434429310275

Epoch: 5| Step: 2
Training loss: 1.1011273221153728
Validation loss: 2.3495770555334765

Epoch: 5| Step: 3
Training loss: 0.8821847422249607
Validation loss: 2.332533277483855

Epoch: 5| Step: 4
Training loss: 1.5860012398675254
Validation loss: 2.37038170465695

Epoch: 5| Step: 5
Training loss: 1.0496960109082878
Validation loss: 2.3605522136899335

Epoch: 5| Step: 6
Training loss: 1.5063106983665182
Validation loss: 2.4125315564724064

Epoch: 5| Step: 7
Training loss: 0.9648245682141686
Validation loss: 2.2920982767302083

Epoch: 5| Step: 8
Training loss: 1.1782985367194223
Validation loss: 2.3627278095431623

Epoch: 5| Step: 9
Training loss: 1.5664389742431961
Validation loss: 2.3813445891560985

Epoch: 5| Step: 10
Training loss: 1.5500237370796146
Validation loss: 2.3449332189519487

Epoch: 364| Step: 0
Training loss: 1.2591622260415327
Validation loss: 2.3866282036168815

Epoch: 5| Step: 1
Training loss: 0.8774436139740763
Validation loss: 2.3390138404616034

Epoch: 5| Step: 2
Training loss: 1.6644076137233816
Validation loss: 2.3438177786703553

Epoch: 5| Step: 3
Training loss: 0.9940193566964751
Validation loss: 2.3153531068386175

Epoch: 5| Step: 4
Training loss: 1.1103961167333567
Validation loss: 2.321083753575493

Epoch: 5| Step: 5
Training loss: 1.1880910306084838
Validation loss: 2.3169566431650517

Epoch: 5| Step: 6
Training loss: 1.5199567106005385
Validation loss: 2.3827156858177605

Epoch: 5| Step: 7
Training loss: 1.692412326068932
Validation loss: 2.3700093357457352

Epoch: 5| Step: 8
Training loss: 0.9199466904453831
Validation loss: 2.364804314522219

Epoch: 5| Step: 9
Training loss: 1.1735657765337213
Validation loss: 2.353368543460069

Epoch: 5| Step: 10
Training loss: 1.2417917160882193
Validation loss: 2.4175419613753184

Epoch: 365| Step: 0
Training loss: 1.2743578434379073
Validation loss: 2.2863532363680035

Epoch: 5| Step: 1
Training loss: 1.478333879031339
Validation loss: 2.3673195409687513

Epoch: 5| Step: 2
Training loss: 0.9654774303080021
Validation loss: 2.3729087855243924

Epoch: 5| Step: 3
Training loss: 1.6545555516010153
Validation loss: 2.4054609394517192

Epoch: 5| Step: 4
Training loss: 1.2266487528609005
Validation loss: 2.3539878976259025

Epoch: 5| Step: 5
Training loss: 1.4054841393247932
Validation loss: 2.3570959347053133

Epoch: 5| Step: 6
Training loss: 1.7114905591342704
Validation loss: 2.372328450062411

Epoch: 5| Step: 7
Training loss: 1.0531069745521886
Validation loss: 2.314508455569691

Epoch: 5| Step: 8
Training loss: 0.9970197076313201
Validation loss: 2.3715771695225016

Epoch: 5| Step: 9
Training loss: 1.1417184056904994
Validation loss: 2.341133869296661

Epoch: 5| Step: 10
Training loss: 1.3147773512849403
Validation loss: 2.3482267763398132

Epoch: 366| Step: 0
Training loss: 1.21845339564883
Validation loss: 2.321184718285515

Epoch: 5| Step: 1
Training loss: 1.021837454289821
Validation loss: 2.4204526526707655

Epoch: 5| Step: 2
Training loss: 0.7137233103824367
Validation loss: 2.318042171300389

Epoch: 5| Step: 3
Training loss: 1.6761235952258349
Validation loss: 2.3379334036622677

Epoch: 5| Step: 4
Training loss: 1.0210864603122418
Validation loss: 2.392510542577439

Epoch: 5| Step: 5
Training loss: 1.2675358511013444
Validation loss: 2.386418828266952

Epoch: 5| Step: 6
Training loss: 1.1463040107640246
Validation loss: 2.35859056697077

Epoch: 5| Step: 7
Training loss: 1.4789843200615878
Validation loss: 2.3625657758201

Epoch: 5| Step: 8
Training loss: 1.7739153650903592
Validation loss: 2.4360983862500727

Epoch: 5| Step: 9
Training loss: 1.0621491021053255
Validation loss: 2.396511897385799

Epoch: 5| Step: 10
Training loss: 1.570575445374802
Validation loss: 2.36203021398313

Epoch: 367| Step: 0
Training loss: 0.9420532915425434
Validation loss: 2.373348911067093

Epoch: 5| Step: 1
Training loss: 1.337635188534563
Validation loss: 2.4035203342984883

Epoch: 5| Step: 2
Training loss: 1.0165329029595538
Validation loss: 2.3464401898751333

Epoch: 5| Step: 3
Training loss: 0.9221321329257474
Validation loss: 2.339048335711424

Epoch: 5| Step: 4
Training loss: 1.2624474184020662
Validation loss: 2.355257378574795

Epoch: 5| Step: 5
Training loss: 0.940957560000766
Validation loss: 2.345072965059863

Epoch: 5| Step: 6
Training loss: 2.0900565065839993
Validation loss: 2.341183592039116

Epoch: 5| Step: 7
Training loss: 1.1012682690874929
Validation loss: 2.369523999444506

Epoch: 5| Step: 8
Training loss: 1.2559665379106228
Validation loss: 2.357585116954167

Epoch: 5| Step: 9
Training loss: 1.3353392839948286
Validation loss: 2.360917835741831

Epoch: 5| Step: 10
Training loss: 1.2457703556401152
Validation loss: 2.35248643868053

Epoch: 368| Step: 0
Training loss: 0.9827785564922925
Validation loss: 2.3456772666246937

Epoch: 5| Step: 1
Training loss: 1.305998457640457
Validation loss: 2.4030530318530396

Epoch: 5| Step: 2
Training loss: 1.0239284589929818
Validation loss: 2.3309815638213305

Epoch: 5| Step: 3
Training loss: 1.227405914150421
Validation loss: 2.406843568476164

Epoch: 5| Step: 4
Training loss: 1.1475127772531992
Validation loss: 2.4650454532501422

Epoch: 5| Step: 5
Training loss: 1.1419639045001437
Validation loss: 2.3951494529373325

Epoch: 5| Step: 6
Training loss: 1.091212189446464
Validation loss: 2.415180183714965

Epoch: 5| Step: 7
Training loss: 1.4049353494397336
Validation loss: 2.412738209952343

Epoch: 5| Step: 8
Training loss: 1.0403482040369971
Validation loss: 2.3309843380945185

Epoch: 5| Step: 9
Training loss: 1.9940887952564474
Validation loss: 2.3727354966814462

Epoch: 5| Step: 10
Training loss: 1.5179104435001078
Validation loss: 2.4000502726158794

Epoch: 369| Step: 0
Training loss: 1.3044659089458523
Validation loss: 2.3300413514531444

Epoch: 5| Step: 1
Training loss: 0.9425240366372505
Validation loss: 2.3633853063317383

Epoch: 5| Step: 2
Training loss: 1.4189574102632938
Validation loss: 2.390218469749544

Epoch: 5| Step: 3
Training loss: 1.606208352465567
Validation loss: 2.3380956850524024

Epoch: 5| Step: 4
Training loss: 1.1925542584757178
Validation loss: 2.357078529893685

Epoch: 5| Step: 5
Training loss: 1.6339197374472836
Validation loss: 2.3378005078466466

Epoch: 5| Step: 6
Training loss: 1.3171955764541001
Validation loss: 2.3486611521365313

Epoch: 5| Step: 7
Training loss: 1.0649750436178058
Validation loss: 2.3904071622554732

Epoch: 5| Step: 8
Training loss: 1.1803817727079342
Validation loss: 2.3295499222562546

Epoch: 5| Step: 9
Training loss: 1.0571607060748276
Validation loss: 2.4160245403682015

Epoch: 5| Step: 10
Training loss: 0.9960934807272155
Validation loss: 2.392641794656317

Epoch: 370| Step: 0
Training loss: 1.6565208213642106
Validation loss: 2.3231119395423216

Epoch: 5| Step: 1
Training loss: 1.1293119869586747
Validation loss: 2.416492235920465

Epoch: 5| Step: 2
Training loss: 1.0102497762648182
Validation loss: 2.3213437353699797

Epoch: 5| Step: 3
Training loss: 1.214260586911364
Validation loss: 2.325492230805469

Epoch: 5| Step: 4
Training loss: 1.8096865160173137
Validation loss: 2.3894545249819057

Epoch: 5| Step: 5
Training loss: 0.9174974895723595
Validation loss: 2.3699186620768913

Epoch: 5| Step: 6
Training loss: 1.0340720202600575
Validation loss: 2.3324765142579023

Epoch: 5| Step: 7
Training loss: 1.152517118182041
Validation loss: 2.3264381952825164

Epoch: 5| Step: 8
Training loss: 1.4654079317178383
Validation loss: 2.4090779348181046

Epoch: 5| Step: 9
Training loss: 1.1432510872073898
Validation loss: 2.326378455087888

Epoch: 5| Step: 10
Training loss: 1.1087410418332402
Validation loss: 2.4235409048713596

Epoch: 371| Step: 0
Training loss: 1.7476589347808502
Validation loss: 2.3904083607407096

Epoch: 5| Step: 1
Training loss: 1.1001306521245917
Validation loss: 2.4133244484144303

Epoch: 5| Step: 2
Training loss: 1.1280671271276232
Validation loss: 2.3658086632097097

Epoch: 5| Step: 3
Training loss: 1.1603091360752813
Validation loss: 2.4192976242396362

Epoch: 5| Step: 4
Training loss: 1.4094179709369137
Validation loss: 2.3899700981676113

Epoch: 5| Step: 5
Training loss: 1.148599937525048
Validation loss: 2.3850755826959644

Epoch: 5| Step: 6
Training loss: 1.091330659033082
Validation loss: 2.362356717127566

Epoch: 5| Step: 7
Training loss: 1.1219803232041765
Validation loss: 2.3476940045045747

Epoch: 5| Step: 8
Training loss: 1.6067149576604052
Validation loss: 2.4288898851380747

Epoch: 5| Step: 9
Training loss: 0.9964573514437571
Validation loss: 2.3708511192989272

Epoch: 5| Step: 10
Training loss: 1.153960977856499
Validation loss: 2.3108103132335156

Epoch: 372| Step: 0
Training loss: 1.8514383652678645
Validation loss: 2.3551667307435644

Epoch: 5| Step: 1
Training loss: 1.2012010028067668
Validation loss: 2.3808016905950864

Epoch: 5| Step: 2
Training loss: 1.2635069183745915
Validation loss: 2.3738127160302156

Epoch: 5| Step: 3
Training loss: 1.1786795345696461
Validation loss: 2.4703103894038683

Epoch: 5| Step: 4
Training loss: 0.9193863656529839
Validation loss: 2.398458458497335

Epoch: 5| Step: 5
Training loss: 1.224509981979987
Validation loss: 2.374497938602301

Epoch: 5| Step: 6
Training loss: 1.3822333205940396
Validation loss: 2.380792239527151

Epoch: 5| Step: 7
Training loss: 1.264589050548184
Validation loss: 2.351449319611439

Epoch: 5| Step: 8
Training loss: 1.5393820493833306
Validation loss: 2.4436977931130044

Epoch: 5| Step: 9
Training loss: 1.1133012736343448
Validation loss: 2.320882405252194

Epoch: 5| Step: 10
Training loss: 1.2562279523746205
Validation loss: 2.3810696720350273

Epoch: 373| Step: 0
Training loss: 1.1517205056185003
Validation loss: 2.353758816278447

Epoch: 5| Step: 1
Training loss: 1.6222971666274753
Validation loss: 2.409549988630385

Epoch: 5| Step: 2
Training loss: 1.511194261354422
Validation loss: 2.3973343925076556

Epoch: 5| Step: 3
Training loss: 1.409100589131641
Validation loss: 2.3847495901360802

Epoch: 5| Step: 4
Training loss: 1.265854897046493
Validation loss: 2.364645282005615

Epoch: 5| Step: 5
Training loss: 1.482283071822311
Validation loss: 2.274680930846578

Epoch: 5| Step: 6
Training loss: 1.3017862464220447
Validation loss: 2.3660450780575553

Epoch: 5| Step: 7
Training loss: 1.0024955129166258
Validation loss: 2.366883607007878

Epoch: 5| Step: 8
Training loss: 0.8861081882323633
Validation loss: 2.3268630665535657

Epoch: 5| Step: 9
Training loss: 1.1922443381343248
Validation loss: 2.4231278845616027

Epoch: 5| Step: 10
Training loss: 0.8140492707274013
Validation loss: 2.294312842341363

Epoch: 374| Step: 0
Training loss: 1.0094703227759139
Validation loss: 2.3877518082388027

Epoch: 5| Step: 1
Training loss: 1.0105477998461656
Validation loss: 2.291775020897862

Epoch: 5| Step: 2
Training loss: 2.075815624200827
Validation loss: 2.3387379730515714

Epoch: 5| Step: 3
Training loss: 1.4453368313777537
Validation loss: 2.4470040160628357

Epoch: 5| Step: 4
Training loss: 1.336237020545492
Validation loss: 2.2954165407435387

Epoch: 5| Step: 5
Training loss: 1.0167288430280004
Validation loss: 2.309288715261088

Epoch: 5| Step: 6
Training loss: 1.3264935065526444
Validation loss: 2.312102654223053

Epoch: 5| Step: 7
Training loss: 1.0402958942347342
Validation loss: 2.3786565528122847

Epoch: 5| Step: 8
Training loss: 1.4558196975136382
Validation loss: 2.451274373640107

Epoch: 5| Step: 9
Training loss: 1.1271395471249033
Validation loss: 2.302531182150339

Epoch: 5| Step: 10
Training loss: 0.9277964360409813
Validation loss: 2.285555815000925

Epoch: 375| Step: 0
Training loss: 1.1531637603944414
Validation loss: 2.453746831013618

Epoch: 5| Step: 1
Training loss: 1.1628125539655092
Validation loss: 2.3706312633861732

Epoch: 5| Step: 2
Training loss: 1.2278371614351884
Validation loss: 2.3408043810053347

Epoch: 5| Step: 3
Training loss: 1.2760093788681224
Validation loss: 2.3909660180308903

Epoch: 5| Step: 4
Training loss: 1.1089920135052243
Validation loss: 2.250541098965009

Epoch: 5| Step: 5
Training loss: 1.193086983268391
Validation loss: 2.363394107834112

Epoch: 5| Step: 6
Training loss: 1.5461349258221437
Validation loss: 2.413975398497459

Epoch: 5| Step: 7
Training loss: 1.2771979199146137
Validation loss: 2.444496534192771

Epoch: 5| Step: 8
Training loss: 1.0708711377507578
Validation loss: 2.3564212256716504

Epoch: 5| Step: 9
Training loss: 0.9185212116439823
Validation loss: 2.3942957398636175

Epoch: 5| Step: 10
Training loss: 1.9409890906780558
Validation loss: 2.3361968295963673

Epoch: 376| Step: 0
Training loss: 1.0783021753655189
Validation loss: 2.305821142488595

Epoch: 5| Step: 1
Training loss: 1.008312012838474
Validation loss: 2.2822079290105983

Epoch: 5| Step: 2
Training loss: 0.9442732591943288
Validation loss: 2.3751641256187708

Epoch: 5| Step: 3
Training loss: 0.9545353632451321
Validation loss: 2.3195656377218614

Epoch: 5| Step: 4
Training loss: 1.5227251783949218
Validation loss: 2.3222121628049512

Epoch: 5| Step: 5
Training loss: 1.6041041605607993
Validation loss: 2.383402166728624

Epoch: 5| Step: 6
Training loss: 1.5808554718821504
Validation loss: 2.3422068076020754

Epoch: 5| Step: 7
Training loss: 1.036996436570022
Validation loss: 2.334469192079896

Epoch: 5| Step: 8
Training loss: 1.1629388493593475
Validation loss: 2.385664436987776

Epoch: 5| Step: 9
Training loss: 1.570259283122472
Validation loss: 2.3440835607383494

Epoch: 5| Step: 10
Training loss: 0.9851470825833621
Validation loss: 2.419156543456925

Epoch: 377| Step: 0
Training loss: 0.742032004681523
Validation loss: 2.3532367546356925

Epoch: 5| Step: 1
Training loss: 1.5447210092091432
Validation loss: 2.429587882961111

Epoch: 5| Step: 2
Training loss: 1.0532475567148059
Validation loss: 2.4103795900738176

Epoch: 5| Step: 3
Training loss: 1.418912211148229
Validation loss: 2.4147712571606457

Epoch: 5| Step: 4
Training loss: 1.2524138033020629
Validation loss: 2.3537579525674404

Epoch: 5| Step: 5
Training loss: 1.0312785520357912
Validation loss: 2.3542614564824897

Epoch: 5| Step: 6
Training loss: 1.0566184558058775
Validation loss: 2.4180293634790346

Epoch: 5| Step: 7
Training loss: 1.0914640243410059
Validation loss: 2.3404238555581114

Epoch: 5| Step: 8
Training loss: 1.5163505626517801
Validation loss: 2.3431256940107468

Epoch: 5| Step: 9
Training loss: 0.9591396540150362
Validation loss: 2.3535774278327652

Epoch: 5| Step: 10
Training loss: 1.7780336487271156
Validation loss: 2.4525021912708804

Epoch: 378| Step: 0
Training loss: 1.1835418790523744
Validation loss: 2.3939302305763435

Epoch: 5| Step: 1
Training loss: 0.9242959642442065
Validation loss: 2.3736878760618025

Epoch: 5| Step: 2
Training loss: 1.0515470302401817
Validation loss: 2.361420470915954

Epoch: 5| Step: 3
Training loss: 1.2473888781943636
Validation loss: 2.3571114616139264

Epoch: 5| Step: 4
Training loss: 1.676345267891981
Validation loss: 2.3918781635345785

Epoch: 5| Step: 5
Training loss: 1.2375151854845297
Validation loss: 2.384550242921168

Epoch: 5| Step: 6
Training loss: 0.9886120329327341
Validation loss: 2.3325957478040165

Epoch: 5| Step: 7
Training loss: 1.3089786248235897
Validation loss: 2.37012120907659

Epoch: 5| Step: 8
Training loss: 1.8303673188993315
Validation loss: 2.3537476566285975

Epoch: 5| Step: 9
Training loss: 0.8505816629260775
Validation loss: 2.407544444565028

Epoch: 5| Step: 10
Training loss: 1.1015027618442843
Validation loss: 2.296121517928578

Epoch: 379| Step: 0
Training loss: 1.4213341323523456
Validation loss: 2.3510872693153724

Epoch: 5| Step: 1
Training loss: 0.9922187980461296
Validation loss: 2.4256735523109705

Epoch: 5| Step: 2
Training loss: 1.3771497220855855
Validation loss: 2.4119170052203476

Epoch: 5| Step: 3
Training loss: 0.8940993686555614
Validation loss: 2.4014282829977494

Epoch: 5| Step: 4
Training loss: 1.2875959434685944
Validation loss: 2.403414320690628

Epoch: 5| Step: 5
Training loss: 1.76505749789808
Validation loss: 2.415446570325902

Epoch: 5| Step: 6
Training loss: 1.1024646176393451
Validation loss: 2.4293607195218745

Epoch: 5| Step: 7
Training loss: 1.2917689723856152
Validation loss: 2.4222752854593113

Epoch: 5| Step: 8
Training loss: 1.0840261640312006
Validation loss: 2.380831435855603

Epoch: 5| Step: 9
Training loss: 1.312232671488446
Validation loss: 2.3591364801293055

Epoch: 5| Step: 10
Training loss: 1.0287849557530067
Validation loss: 2.365642201203469

Epoch: 380| Step: 0
Training loss: 1.000366024741155
Validation loss: 2.3532944055288083

Epoch: 5| Step: 1
Training loss: 1.5597778258693153
Validation loss: 2.3512404228117845

Epoch: 5| Step: 2
Training loss: 0.8490712533442734
Validation loss: 2.3368792307696644

Epoch: 5| Step: 3
Training loss: 1.8833184413264874
Validation loss: 2.334547847076859

Epoch: 5| Step: 4
Training loss: 1.28347645349604
Validation loss: 2.4047687181113235

Epoch: 5| Step: 5
Training loss: 1.1841645831403629
Validation loss: 2.293854901675444

Epoch: 5| Step: 6
Training loss: 1.076308946136124
Validation loss: 2.2868793669949223

Epoch: 5| Step: 7
Training loss: 1.3973612986404012
Validation loss: 2.3748552486605754

Epoch: 5| Step: 8
Training loss: 0.9838112927625657
Validation loss: 2.2909723809355325

Epoch: 5| Step: 9
Training loss: 1.222281694169447
Validation loss: 2.4047224429668903

Epoch: 5| Step: 10
Training loss: 0.9718401445719159
Validation loss: 2.3781002396814066

Epoch: 381| Step: 0
Training loss: 1.059721342652771
Validation loss: 2.3808283691734675

Epoch: 5| Step: 1
Training loss: 1.0510179898204157
Validation loss: 2.3768004850222058

Epoch: 5| Step: 2
Training loss: 0.9873137733048952
Validation loss: 2.3638642712907427

Epoch: 5| Step: 3
Training loss: 1.0458896041767798
Validation loss: 2.3698409771220446

Epoch: 5| Step: 4
Training loss: 1.1240791684808655
Validation loss: 2.367373885006025

Epoch: 5| Step: 5
Training loss: 0.8559243717697926
Validation loss: 2.3415425428380368

Epoch: 5| Step: 6
Training loss: 1.9217229643441383
Validation loss: 2.342814985695231

Epoch: 5| Step: 7
Training loss: 1.2815389074848254
Validation loss: 2.3278645674454723

Epoch: 5| Step: 8
Training loss: 1.3639024341261983
Validation loss: 2.3445694648217636

Epoch: 5| Step: 9
Training loss: 1.5221848252769659
Validation loss: 2.3900541551196746

Epoch: 5| Step: 10
Training loss: 1.2073108139472615
Validation loss: 2.3705456882434617

Epoch: 382| Step: 0
Training loss: 1.110335726528591
Validation loss: 2.355248197263612

Epoch: 5| Step: 1
Training loss: 1.1257305951869938
Validation loss: 2.31172278418505

Epoch: 5| Step: 2
Training loss: 1.1650173700044602
Validation loss: 2.3449819989729943

Epoch: 5| Step: 3
Training loss: 0.765461417647979
Validation loss: 2.347857040558206

Epoch: 5| Step: 4
Training loss: 1.141878458319544
Validation loss: 2.370767025979375

Epoch: 5| Step: 5
Training loss: 1.032236436636045
Validation loss: 2.395475762333869

Epoch: 5| Step: 6
Training loss: 0.9922414149256328
Validation loss: 2.4416810392232327

Epoch: 5| Step: 7
Training loss: 0.9702824500401868
Validation loss: 2.378767478450628

Epoch: 5| Step: 8
Training loss: 1.1676464337773869
Validation loss: 2.3924443692189543

Epoch: 5| Step: 9
Training loss: 1.5985648782192416
Validation loss: 2.3273917678283236

Epoch: 5| Step: 10
Training loss: 1.9089902349654917
Validation loss: 2.4552818030656924

Epoch: 383| Step: 0
Training loss: 0.7781590542369525
Validation loss: 2.389652435862481

Epoch: 5| Step: 1
Training loss: 1.1774476874327051
Validation loss: 2.3303662375306518

Epoch: 5| Step: 2
Training loss: 1.4365043509205335
Validation loss: 2.3779281307263456

Epoch: 5| Step: 3
Training loss: 1.6675851278008342
Validation loss: 2.3330877990860768

Epoch: 5| Step: 4
Training loss: 1.24640056217154
Validation loss: 2.4025981153138694

Epoch: 5| Step: 5
Training loss: 1.2560465481873588
Validation loss: 2.3530762152746254

Epoch: 5| Step: 6
Training loss: 1.0475865123958377
Validation loss: 2.3989212506535047

Epoch: 5| Step: 7
Training loss: 0.8283433086618448
Validation loss: 2.3263323772164037

Epoch: 5| Step: 8
Training loss: 1.0650991736608244
Validation loss: 2.3087995844230096

Epoch: 5| Step: 9
Training loss: 1.3087186383677016
Validation loss: 2.334663418168847

Epoch: 5| Step: 10
Training loss: 1.4445126356428526
Validation loss: 2.3095002510866642

Epoch: 384| Step: 0
Training loss: 1.5488168877173527
Validation loss: 2.3378805272924676

Epoch: 5| Step: 1
Training loss: 1.2127513959157472
Validation loss: 2.322929258315649

Epoch: 5| Step: 2
Training loss: 1.2173999253332053
Validation loss: 2.3158043221450386

Epoch: 5| Step: 3
Training loss: 1.2845853331669177
Validation loss: 2.367106364239949

Epoch: 5| Step: 4
Training loss: 1.0502707223207666
Validation loss: 2.33167395793041

Epoch: 5| Step: 5
Training loss: 0.9939397222924289
Validation loss: 2.3521242526529695

Epoch: 5| Step: 6
Training loss: 0.8985069248079087
Validation loss: 2.342702207806847

Epoch: 5| Step: 7
Training loss: 1.166718799697836
Validation loss: 2.3435983839866568

Epoch: 5| Step: 8
Training loss: 1.4867389527239652
Validation loss: 2.354936895892078

Epoch: 5| Step: 9
Training loss: 0.9350446973918441
Validation loss: 2.35325785751027

Epoch: 5| Step: 10
Training loss: 1.636325907392677
Validation loss: 2.2498710588541577

Epoch: 385| Step: 0
Training loss: 0.9939087782876971
Validation loss: 2.301055680686493

Epoch: 5| Step: 1
Training loss: 1.695485963165397
Validation loss: 2.3682900737072172

Epoch: 5| Step: 2
Training loss: 1.1305993922735524
Validation loss: 2.3517111563417408

Epoch: 5| Step: 3
Training loss: 0.7315456998868555
Validation loss: 2.4072694308989155

Epoch: 5| Step: 4
Training loss: 1.6046572674036343
Validation loss: 2.37230238750659

Epoch: 5| Step: 5
Training loss: 0.8323245897015885
Validation loss: 2.3443313369886067

Epoch: 5| Step: 6
Training loss: 1.0594788401976407
Validation loss: 2.2784779487794746

Epoch: 5| Step: 7
Training loss: 1.0231623971450972
Validation loss: 2.307602517396839

Epoch: 5| Step: 8
Training loss: 1.491043371192747
Validation loss: 2.3504288267958566

Epoch: 5| Step: 9
Training loss: 1.3460401935074364
Validation loss: 2.4329994187125883

Epoch: 5| Step: 10
Training loss: 1.251801861032473
Validation loss: 2.360170082231276

Epoch: 386| Step: 0
Training loss: 1.4975931408022032
Validation loss: 2.328858634284546

Epoch: 5| Step: 1
Training loss: 0.8916079133424898
Validation loss: 2.355773441337142

Epoch: 5| Step: 2
Training loss: 1.3669401980576612
Validation loss: 2.383473464365196

Epoch: 5| Step: 3
Training loss: 1.1927042909689731
Validation loss: 2.3718252546197727

Epoch: 5| Step: 4
Training loss: 0.855784667048128
Validation loss: 2.2745639682919965

Epoch: 5| Step: 5
Training loss: 0.7995990493472976
Validation loss: 2.3972098224840304

Epoch: 5| Step: 6
Training loss: 1.2125681081303674
Validation loss: 2.369178474296457

Epoch: 5| Step: 7
Training loss: 0.7804572470182914
Validation loss: 2.411644195011546

Epoch: 5| Step: 8
Training loss: 1.730145839762161
Validation loss: 2.333458227632666

Epoch: 5| Step: 9
Training loss: 1.1153338867257572
Validation loss: 2.351300825526005

Epoch: 5| Step: 10
Training loss: 1.0230670870153122
Validation loss: 2.296647154921338

Epoch: 387| Step: 0
Training loss: 1.082635043136512
Validation loss: 2.420520338245033

Epoch: 5| Step: 1
Training loss: 1.0547785966879522
Validation loss: 2.348416199953008

Epoch: 5| Step: 2
Training loss: 1.1373455508668953
Validation loss: 2.307638839757509

Epoch: 5| Step: 3
Training loss: 0.9354884501712181
Validation loss: 2.310925571606915

Epoch: 5| Step: 4
Training loss: 0.9984859389135018
Validation loss: 2.333797144681649

Epoch: 5| Step: 5
Training loss: 1.7588085827970052
Validation loss: 2.3476508020056563

Epoch: 5| Step: 6
Training loss: 1.5672990723103295
Validation loss: 2.3535767775487964

Epoch: 5| Step: 7
Training loss: 1.0677508027849192
Validation loss: 2.3366869799191354

Epoch: 5| Step: 8
Training loss: 1.5561974635314468
Validation loss: 2.3246422833721248

Epoch: 5| Step: 9
Training loss: 1.0476017038139946
Validation loss: 2.416103639741269

Epoch: 5| Step: 10
Training loss: 1.2444591264246543
Validation loss: 2.362247055731592

Epoch: 388| Step: 0
Training loss: 1.0252697101327168
Validation loss: 2.407800218492365

Epoch: 5| Step: 1
Training loss: 1.0317910249067221
Validation loss: 2.3664650434779513

Epoch: 5| Step: 2
Training loss: 1.0111739411296483
Validation loss: 2.3620477293726188

Epoch: 5| Step: 3
Training loss: 1.3553923219796264
Validation loss: 2.3961736329503758

Epoch: 5| Step: 4
Training loss: 1.1457137421130015
Validation loss: 2.3868143261141235

Epoch: 5| Step: 5
Training loss: 0.9853950543819359
Validation loss: 2.398106765884497

Epoch: 5| Step: 6
Training loss: 1.1785714130897025
Validation loss: 2.351502527555497

Epoch: 5| Step: 7
Training loss: 1.6109855518888974
Validation loss: 2.435328238373718

Epoch: 5| Step: 8
Training loss: 1.2617225765016715
Validation loss: 2.3288582379914033

Epoch: 5| Step: 9
Training loss: 1.698983643150514
Validation loss: 2.382908720147862

Epoch: 5| Step: 10
Training loss: 1.2283777302068926
Validation loss: 2.4444638971944985

Epoch: 389| Step: 0
Training loss: 1.1928050350428334
Validation loss: 2.4147085086148525

Epoch: 5| Step: 1
Training loss: 1.6007228976589676
Validation loss: 2.31395359466446

Epoch: 5| Step: 2
Training loss: 1.171288457949522
Validation loss: 2.3765294105710675

Epoch: 5| Step: 3
Training loss: 1.1588592472036485
Validation loss: 2.2733399133740693

Epoch: 5| Step: 4
Training loss: 1.1962447675951264
Validation loss: 2.367668854239517

Epoch: 5| Step: 5
Training loss: 0.6639188050025406
Validation loss: 2.3772781059178465

Epoch: 5| Step: 6
Training loss: 1.7998854918614897
Validation loss: 2.3295328987524817

Epoch: 5| Step: 7
Training loss: 0.8183730677367298
Validation loss: 2.373597991495943

Epoch: 5| Step: 8
Training loss: 1.3513599751171532
Validation loss: 2.3402068819328656

Epoch: 5| Step: 9
Training loss: 0.8938430070834311
Validation loss: 2.3074122842062788

Epoch: 5| Step: 10
Training loss: 0.9350660518020131
Validation loss: 2.3418153419660412

Epoch: 390| Step: 0
Training loss: 1.0153383290582672
Validation loss: 2.3282472812770094

Epoch: 5| Step: 1
Training loss: 1.492861131335528
Validation loss: 2.363542328063713

Epoch: 5| Step: 2
Training loss: 1.6903025349573453
Validation loss: 2.3779792649251625

Epoch: 5| Step: 3
Training loss: 1.3082149583674878
Validation loss: 2.3936721041223463

Epoch: 5| Step: 4
Training loss: 0.9940646878901667
Validation loss: 2.3205621283382154

Epoch: 5| Step: 5
Training loss: 1.0673288678971933
Validation loss: 2.337475729397308

Epoch: 5| Step: 6
Training loss: 0.8973294930817541
Validation loss: 2.3231587621573384

Epoch: 5| Step: 7
Training loss: 1.1270851309169083
Validation loss: 2.3451917746242064

Epoch: 5| Step: 8
Training loss: 0.9788272688803535
Validation loss: 2.3997204837534536

Epoch: 5| Step: 9
Training loss: 0.7989947604579315
Validation loss: 2.3752653818871563

Epoch: 5| Step: 10
Training loss: 1.353854402582842
Validation loss: 2.320092437286633

Epoch: 391| Step: 0
Training loss: 1.0964519913161586
Validation loss: 2.355905684036392

Epoch: 5| Step: 1
Training loss: 1.8550584198834332
Validation loss: 2.342746328844982

Epoch: 5| Step: 2
Training loss: 1.340962912914998
Validation loss: 2.3653877385862567

Epoch: 5| Step: 3
Training loss: 0.9026321346633334
Validation loss: 2.411181368581643

Epoch: 5| Step: 4
Training loss: 1.1519261524849622
Validation loss: 2.3084548206848092

Epoch: 5| Step: 5
Training loss: 0.8838992898392891
Validation loss: 2.4181307267711114

Epoch: 5| Step: 6
Training loss: 0.8084570359095099
Validation loss: 2.348944763256446

Epoch: 5| Step: 7
Training loss: 1.0585886261875825
Validation loss: 2.404416819367953

Epoch: 5| Step: 8
Training loss: 1.51971246183095
Validation loss: 2.329761910528234

Epoch: 5| Step: 9
Training loss: 1.085160395900642
Validation loss: 2.306889325700411

Epoch: 5| Step: 10
Training loss: 1.424760761590501
Validation loss: 2.371056543249436

Epoch: 392| Step: 0
Training loss: 1.4396745570971181
Validation loss: 2.3422888584070893

Epoch: 5| Step: 1
Training loss: 1.1853589281301782
Validation loss: 2.4214119247843295

Epoch: 5| Step: 2
Training loss: 1.2333692968555048
Validation loss: 2.3938871042977867

Epoch: 5| Step: 3
Training loss: 0.9901595529432259
Validation loss: 2.4169902634367

Epoch: 5| Step: 4
Training loss: 0.9807150482009656
Validation loss: 2.385668180899463

Epoch: 5| Step: 5
Training loss: 1.304688139589804
Validation loss: 2.523702060194755

Epoch: 5| Step: 6
Training loss: 1.1517151233252174
Validation loss: 2.3998359583950313

Epoch: 5| Step: 7
Training loss: 1.3780149437519
Validation loss: 2.4395841707500154

Epoch: 5| Step: 8
Training loss: 0.9127188367891585
Validation loss: 2.3489198682679855

Epoch: 5| Step: 9
Training loss: 1.1370091018312452
Validation loss: 2.3876573965054764

Epoch: 5| Step: 10
Training loss: 1.7301985484502425
Validation loss: 2.292868820377303

Epoch: 393| Step: 0
Training loss: 1.0248762311875688
Validation loss: 2.3733444283217895

Epoch: 5| Step: 1
Training loss: 1.0532953186861171
Validation loss: 2.362396046789266

Epoch: 5| Step: 2
Training loss: 1.9622882583004824
Validation loss: 2.348214121463036

Epoch: 5| Step: 3
Training loss: 1.1127942007006948
Validation loss: 2.3282805415145953

Epoch: 5| Step: 4
Training loss: 1.337427568702649
Validation loss: 2.330958855899978

Epoch: 5| Step: 5
Training loss: 1.353583836453677
Validation loss: 2.372320381966473

Epoch: 5| Step: 6
Training loss: 1.0311306393067163
Validation loss: 2.4298684926843346

Epoch: 5| Step: 7
Training loss: 0.898234402464599
Validation loss: 2.3363097766670546

Epoch: 5| Step: 8
Training loss: 0.8374273268640243
Validation loss: 2.355498004333658

Epoch: 5| Step: 9
Training loss: 1.222341088574055
Validation loss: 2.3404851190526683

Epoch: 5| Step: 10
Training loss: 0.9431017411323617
Validation loss: 2.379401142914731

Epoch: 394| Step: 0
Training loss: 1.1156029835299661
Validation loss: 2.363445842845056

Epoch: 5| Step: 1
Training loss: 1.351229632186184
Validation loss: 2.3819270675116058

Epoch: 5| Step: 2
Training loss: 0.9086049493311021
Validation loss: 2.3724790664126743

Epoch: 5| Step: 3
Training loss: 1.7902789249158364
Validation loss: 2.3218142741321572

Epoch: 5| Step: 4
Training loss: 1.109319121336988
Validation loss: 2.344211950136581

Epoch: 5| Step: 5
Training loss: 0.9786203903185178
Validation loss: 2.36335480508669

Epoch: 5| Step: 6
Training loss: 1.24757851661257
Validation loss: 2.329678674088319

Epoch: 5| Step: 7
Training loss: 1.124798544754183
Validation loss: 2.2916088054060766

Epoch: 5| Step: 8
Training loss: 1.229971067506995
Validation loss: 2.433541443597325

Epoch: 5| Step: 9
Training loss: 1.3331313079527367
Validation loss: 2.3473490208117616

Epoch: 5| Step: 10
Training loss: 0.856030075342597
Validation loss: 2.3162614417817444

Epoch: 395| Step: 0
Training loss: 0.7510228335011689
Validation loss: 2.353507844250582

Epoch: 5| Step: 1
Training loss: 1.2844660334567535
Validation loss: 2.2750645794334954

Epoch: 5| Step: 2
Training loss: 1.2186828007878658
Validation loss: 2.372539546483129

Epoch: 5| Step: 3
Training loss: 1.0159692034296635
Validation loss: 2.3594965673555715

Epoch: 5| Step: 4
Training loss: 1.1436517871317544
Validation loss: 2.308732921907763

Epoch: 5| Step: 5
Training loss: 0.7553380701284652
Validation loss: 2.325929977766944

Epoch: 5| Step: 6
Training loss: 1.5010234202489934
Validation loss: 2.365929823054536

Epoch: 5| Step: 7
Training loss: 1.2468023886129331
Validation loss: 2.3065855447165107

Epoch: 5| Step: 8
Training loss: 1.223341825795298
Validation loss: 2.3209497996262303

Epoch: 5| Step: 9
Training loss: 1.7664737518113942
Validation loss: 2.312584605799174

Epoch: 5| Step: 10
Training loss: 0.9440712148446603
Validation loss: 2.3805146196089444

Epoch: 396| Step: 0
Training loss: 1.259242790608977
Validation loss: 2.4046642894112846

Epoch: 5| Step: 1
Training loss: 1.1969735067681515
Validation loss: 2.351886194842059

Epoch: 5| Step: 2
Training loss: 1.668316699861932
Validation loss: 2.418313198188818

Epoch: 5| Step: 3
Training loss: 0.9873137733048952
Validation loss: 2.3966666375277352

Epoch: 5| Step: 4
Training loss: 1.3960452796620966
Validation loss: 2.3991432991256603

Epoch: 5| Step: 5
Training loss: 1.2054940221662809
Validation loss: 2.355533982127369

Epoch: 5| Step: 6
Training loss: 1.1824351768388162
Validation loss: 2.336236275935285

Epoch: 5| Step: 7
Training loss: 0.9191246708994245
Validation loss: 2.400552791465434

Epoch: 5| Step: 8
Training loss: 1.447889021282515
Validation loss: 2.317214836591253

Epoch: 5| Step: 9
Training loss: 0.8459486043459826
Validation loss: 2.337805899840714

Epoch: 5| Step: 10
Training loss: 1.3617212940045667
Validation loss: 2.3831602555906937

Epoch: 397| Step: 0
Training loss: 1.2823884139864887
Validation loss: 2.345781461240946

Epoch: 5| Step: 1
Training loss: 1.7405524000714283
Validation loss: 2.3029440234753986

Epoch: 5| Step: 2
Training loss: 1.1388685210404483
Validation loss: 2.34769543500114

Epoch: 5| Step: 3
Training loss: 1.1126200000465023
Validation loss: 2.3547716963165892

Epoch: 5| Step: 4
Training loss: 0.8295475599302603
Validation loss: 2.3485458659810288

Epoch: 5| Step: 5
Training loss: 1.4914035835062431
Validation loss: 2.3166774443048666

Epoch: 5| Step: 6
Training loss: 0.948502729708575
Validation loss: 2.354067231246373

Epoch: 5| Step: 7
Training loss: 1.2214656797905243
Validation loss: 2.3802390751016116

Epoch: 5| Step: 8
Training loss: 0.9526984088735866
Validation loss: 2.3899335371261814

Epoch: 5| Step: 9
Training loss: 1.040743851389924
Validation loss: 2.3618218275386424

Epoch: 5| Step: 10
Training loss: 1.2194234014668501
Validation loss: 2.3718467617227885

Epoch: 398| Step: 0
Training loss: 0.9586077103845725
Validation loss: 2.349414629325842

Epoch: 5| Step: 1
Training loss: 1.252503082362968
Validation loss: 2.3619559669560495

Epoch: 5| Step: 2
Training loss: 1.4505680517139479
Validation loss: 2.359772549071453

Epoch: 5| Step: 3
Training loss: 0.990347771105259
Validation loss: 2.4121806839247695

Epoch: 5| Step: 4
Training loss: 1.3385625112768413
Validation loss: 2.4114417331992133

Epoch: 5| Step: 5
Training loss: 1.316533973904542
Validation loss: 2.3807542765878837

Epoch: 5| Step: 6
Training loss: 0.7686280890461801
Validation loss: 2.3536215476010107

Epoch: 5| Step: 7
Training loss: 0.9991434720623923
Validation loss: 2.3937098886989046

Epoch: 5| Step: 8
Training loss: 0.940202600427978
Validation loss: 2.411895959061726

Epoch: 5| Step: 9
Training loss: 1.7214158624701124
Validation loss: 2.3487535616667543

Epoch: 5| Step: 10
Training loss: 1.1020356372879514
Validation loss: 2.3207277951293888

Epoch: 399| Step: 0
Training loss: 0.8771133446410342
Validation loss: 2.3065909574423795

Epoch: 5| Step: 1
Training loss: 1.0543234868063704
Validation loss: 2.3339601003076407

Epoch: 5| Step: 2
Training loss: 1.2171805620301805
Validation loss: 2.309983052486895

Epoch: 5| Step: 3
Training loss: 1.005539037564116
Validation loss: 2.368769484984825

Epoch: 5| Step: 4
Training loss: 1.0513532138372772
Validation loss: 2.3674200054738606

Epoch: 5| Step: 5
Training loss: 1.059009203027031
Validation loss: 2.354355778250761

Epoch: 5| Step: 6
Training loss: 1.237378389952922
Validation loss: 2.305369744702153

Epoch: 5| Step: 7
Training loss: 1.5434988149546334
Validation loss: 2.447438864243706

Epoch: 5| Step: 8
Training loss: 1.8813454385165687
Validation loss: 2.3372912285558836

Epoch: 5| Step: 9
Training loss: 1.077977985918119
Validation loss: 2.3480244670031

Epoch: 5| Step: 10
Training loss: 0.8937761876464492
Validation loss: 2.393325891726835

Epoch: 400| Step: 0
Training loss: 0.6536925756350604
Validation loss: 2.25897187370925

Epoch: 5| Step: 1
Training loss: 1.8809535556557306
Validation loss: 2.454099957939959

Epoch: 5| Step: 2
Training loss: 0.7760079182363392
Validation loss: 2.354969932130461

Epoch: 5| Step: 3
Training loss: 0.9524283442740259
Validation loss: 2.3746486980415735

Epoch: 5| Step: 4
Training loss: 1.451729216923321
Validation loss: 2.3705821189686396

Epoch: 5| Step: 5
Training loss: 1.1780599014550663
Validation loss: 2.30379222613486

Epoch: 5| Step: 6
Training loss: 0.8049316036003366
Validation loss: 2.3588512512734887

Epoch: 5| Step: 7
Training loss: 0.9997850127388563
Validation loss: 2.416119946118069

Epoch: 5| Step: 8
Training loss: 1.2808694972283685
Validation loss: 2.3486857671632535

Epoch: 5| Step: 9
Training loss: 1.2021632127760262
Validation loss: 2.385312075717027

Epoch: 5| Step: 10
Training loss: 1.2727458456312934
Validation loss: 2.4073916719181994

Epoch: 401| Step: 0
Training loss: 0.8198935029026573
Validation loss: 2.4187306560126416

Epoch: 5| Step: 1
Training loss: 1.140698783264822
Validation loss: 2.3067962470898125

Epoch: 5| Step: 2
Training loss: 1.0021837352067005
Validation loss: 2.3262106471520183

Epoch: 5| Step: 3
Training loss: 1.4395306383895776
Validation loss: 2.354400841640639

Epoch: 5| Step: 4
Training loss: 1.2284299399085785
Validation loss: 2.34971361127934

Epoch: 5| Step: 5
Training loss: 1.1773797002516895
Validation loss: 2.297793000313513

Epoch: 5| Step: 6
Training loss: 1.3126016304995263
Validation loss: 2.3507266551628896

Epoch: 5| Step: 7
Training loss: 0.9121624361406283
Validation loss: 2.3623508374811317

Epoch: 5| Step: 8
Training loss: 0.9539261249593088
Validation loss: 2.3463189990580675

Epoch: 5| Step: 9
Training loss: 0.9625861748599575
Validation loss: 2.3766825317836804

Epoch: 5| Step: 10
Training loss: 1.8528597508410132
Validation loss: 2.3478925752982014

Epoch: 402| Step: 0
Training loss: 1.0290342860983508
Validation loss: 2.3699458531295585

Epoch: 5| Step: 1
Training loss: 1.4538568274098806
Validation loss: 2.4151352810054196

Epoch: 5| Step: 2
Training loss: 1.0073128578037234
Validation loss: 2.3387374649794497

Epoch: 5| Step: 3
Training loss: 1.0015338816251254
Validation loss: 2.369948920371921

Epoch: 5| Step: 4
Training loss: 1.7510679256263793
Validation loss: 2.3714318730477095

Epoch: 5| Step: 5
Training loss: 1.1230750569663708
Validation loss: 2.413402248451646

Epoch: 5| Step: 6
Training loss: 1.0363906697689902
Validation loss: 2.3564499296579458

Epoch: 5| Step: 7
Training loss: 1.0064142270861056
Validation loss: 2.4226683017007025

Epoch: 5| Step: 8
Training loss: 1.2301568983384696
Validation loss: 2.376843088115216

Epoch: 5| Step: 9
Training loss: 1.0924812587640726
Validation loss: 2.377834015181434

Epoch: 5| Step: 10
Training loss: 1.2975447889914173
Validation loss: 2.328027656977375

Epoch: 403| Step: 0
Training loss: 0.7555723212016641
Validation loss: 2.340962855768598

Epoch: 5| Step: 1
Training loss: 1.6783887943522873
Validation loss: 2.3364245638520202

Epoch: 5| Step: 2
Training loss: 0.9106896928731115
Validation loss: 2.3892477428682093

Epoch: 5| Step: 3
Training loss: 1.0381176316598644
Validation loss: 2.363265943702238

Epoch: 5| Step: 4
Training loss: 1.3399100328960498
Validation loss: 2.4257120931691443

Epoch: 5| Step: 5
Training loss: 0.9884276752785668
Validation loss: 2.3981257565376217

Epoch: 5| Step: 6
Training loss: 1.0566895873735678
Validation loss: 2.402859307556382

Epoch: 5| Step: 7
Training loss: 1.4314044585860624
Validation loss: 2.356657380196016

Epoch: 5| Step: 8
Training loss: 1.3581824497759027
Validation loss: 2.3697040704392682

Epoch: 5| Step: 9
Training loss: 0.9993843925564319
Validation loss: 2.2952320070327183

Epoch: 5| Step: 10
Training loss: 1.335607610650898
Validation loss: 2.3752929234843885

Epoch: 404| Step: 0
Training loss: 1.4320013780906908
Validation loss: 2.3165468466108456

Epoch: 5| Step: 1
Training loss: 1.0440586981294542
Validation loss: 2.352231502164955

Epoch: 5| Step: 2
Training loss: 1.2918086076497217
Validation loss: 2.3788056951032193

Epoch: 5| Step: 3
Training loss: 1.3172442658162553
Validation loss: 2.2855739411250475

Epoch: 5| Step: 4
Training loss: 0.9766544756491945
Validation loss: 2.367361181415276

Epoch: 5| Step: 5
Training loss: 1.142828915451773
Validation loss: 2.3604870659383255

Epoch: 5| Step: 6
Training loss: 0.8939332920805682
Validation loss: 2.3220527801358686

Epoch: 5| Step: 7
Training loss: 1.205223927881915
Validation loss: 2.3524537152032976

Epoch: 5| Step: 8
Training loss: 0.9438141857829624
Validation loss: 2.392340638908127

Epoch: 5| Step: 9
Training loss: 1.360878518509348
Validation loss: 2.4015472615089246

Epoch: 5| Step: 10
Training loss: 1.6437984473917668
Validation loss: 2.373310307331364

Epoch: 405| Step: 0
Training loss: 1.2303058819233097
Validation loss: 2.384770615179016

Epoch: 5| Step: 1
Training loss: 0.6759330490819352
Validation loss: 2.448747960210775

Epoch: 5| Step: 2
Training loss: 1.2108618928009502
Validation loss: 2.3621424228860457

Epoch: 5| Step: 3
Training loss: 0.971472329869161
Validation loss: 2.383663837029764

Epoch: 5| Step: 4
Training loss: 1.9080378168944825
Validation loss: 2.338587883089423

Epoch: 5| Step: 5
Training loss: 1.1062593901499698
Validation loss: 2.4004375080349676

Epoch: 5| Step: 6
Training loss: 1.104048446708358
Validation loss: 2.361288235788854

Epoch: 5| Step: 7
Training loss: 0.7609793179592698
Validation loss: 2.33031671481133

Epoch: 5| Step: 8
Training loss: 1.2451342772264684
Validation loss: 2.368802407583494

Epoch: 5| Step: 9
Training loss: 1.468119871634811
Validation loss: 2.3909073154314173

Epoch: 5| Step: 10
Training loss: 1.2029946491918373
Validation loss: 2.402872813563786

Epoch: 406| Step: 0
Training loss: 1.3152046492559393
Validation loss: 2.416223661669213

Epoch: 5| Step: 1
Training loss: 0.7210380788950995
Validation loss: 2.4003454466936307

Epoch: 5| Step: 2
Training loss: 1.135810095609281
Validation loss: 2.4407262472856113

Epoch: 5| Step: 3
Training loss: 1.4042413989743083
Validation loss: 2.466423384878579

Epoch: 5| Step: 4
Training loss: 0.9699062092653203
Validation loss: 2.3973168953903223

Epoch: 5| Step: 5
Training loss: 1.132608329526493
Validation loss: 2.3749811520392594

Epoch: 5| Step: 6
Training loss: 0.8994522997818309
Validation loss: 2.4304742250639824

Epoch: 5| Step: 7
Training loss: 0.8973395231221458
Validation loss: 2.3447886352574865

Epoch: 5| Step: 8
Training loss: 0.7987244778944925
Validation loss: 2.337800513329665

Epoch: 5| Step: 9
Training loss: 1.6381437157497254
Validation loss: 2.3834520352858513

Epoch: 5| Step: 10
Training loss: 1.4991334160338146
Validation loss: 2.358649941273653

Epoch: 407| Step: 0
Training loss: 0.949386927144894
Validation loss: 2.3923278551798504

Epoch: 5| Step: 1
Training loss: 0.8501701521267014
Validation loss: 2.353652634085848

Epoch: 5| Step: 2
Training loss: 1.2645459225613036
Validation loss: 2.3916172116230716

Epoch: 5| Step: 3
Training loss: 0.98199620514387
Validation loss: 2.3389240417003045

Epoch: 5| Step: 4
Training loss: 1.1254645554033944
Validation loss: 2.3541255870751994

Epoch: 5| Step: 5
Training loss: 1.0103689490517846
Validation loss: 2.3704128817380297

Epoch: 5| Step: 6
Training loss: 1.0330511605148551
Validation loss: 2.3632113544105

Epoch: 5| Step: 7
Training loss: 1.1215039609277027
Validation loss: 2.3359016275499758

Epoch: 5| Step: 8
Training loss: 0.9904703916122956
Validation loss: 2.337633346571678

Epoch: 5| Step: 9
Training loss: 1.1639872789081072
Validation loss: 2.4737861805696535

Epoch: 5| Step: 10
Training loss: 2.0152685752195247
Validation loss: 2.3496090547643957

Epoch: 408| Step: 0
Training loss: 1.2810394300159123
Validation loss: 2.3676279013611143

Epoch: 5| Step: 1
Training loss: 1.0833230140390178
Validation loss: 2.36461060615638

Epoch: 5| Step: 2
Training loss: 1.1074354382849965
Validation loss: 2.4104283639371222

Epoch: 5| Step: 3
Training loss: 0.7725230504272784
Validation loss: 2.328072812638678

Epoch: 5| Step: 4
Training loss: 0.8285143674618801
Validation loss: 2.351931091361583

Epoch: 5| Step: 5
Training loss: 1.0749038453679494
Validation loss: 2.3303691527992156

Epoch: 5| Step: 6
Training loss: 0.7550474631314699
Validation loss: 2.340485488184187

Epoch: 5| Step: 7
Training loss: 1.3711286578394355
Validation loss: 2.3511059097391045

Epoch: 5| Step: 8
Training loss: 1.1041396815523292
Validation loss: 2.262172960188355

Epoch: 5| Step: 9
Training loss: 0.8344946557588684
Validation loss: 2.391367751399693

Epoch: 5| Step: 10
Training loss: 2.0273624485454533
Validation loss: 2.356254956740234

Epoch: 409| Step: 0
Training loss: 1.1187987013291374
Validation loss: 2.3686548888249375

Epoch: 5| Step: 1
Training loss: 1.3618684022208796
Validation loss: 2.366072587751317

Epoch: 5| Step: 2
Training loss: 0.8820676784240388
Validation loss: 2.3085544365527766

Epoch: 5| Step: 3
Training loss: 0.9913500458016858
Validation loss: 2.3836761840556844

Epoch: 5| Step: 4
Training loss: 1.1466296752149034
Validation loss: 2.380224615638094

Epoch: 5| Step: 5
Training loss: 0.7309154429864939
Validation loss: 2.3173331204573198

Epoch: 5| Step: 6
Training loss: 1.7486955004060194
Validation loss: 2.3213003583153493

Epoch: 5| Step: 7
Training loss: 1.2289914906131914
Validation loss: 2.400607403038265

Epoch: 5| Step: 8
Training loss: 1.059733379139185
Validation loss: 2.381058954777731

Epoch: 5| Step: 9
Training loss: 0.9547787062411586
Validation loss: 2.326173570007107

Epoch: 5| Step: 10
Training loss: 0.976119284188214
Validation loss: 2.3280221878257805

Epoch: 410| Step: 0
Training loss: 1.139184800268553
Validation loss: 2.321981347607789

Epoch: 5| Step: 1
Training loss: 0.9414484798092739
Validation loss: 2.426496016836151

Epoch: 5| Step: 2
Training loss: 0.8641731867334269
Validation loss: 2.394900710682947

Epoch: 5| Step: 3
Training loss: 1.2675359921734286
Validation loss: 2.4192347673817016

Epoch: 5| Step: 4
Training loss: 0.7317781187805752
Validation loss: 2.3690525882576576

Epoch: 5| Step: 5
Training loss: 1.0287178046564212
Validation loss: 2.3525561538181896

Epoch: 5| Step: 6
Training loss: 1.4805723773047592
Validation loss: 2.3278758566831703

Epoch: 5| Step: 7
Training loss: 1.6049011415119903
Validation loss: 2.381309105208455

Epoch: 5| Step: 8
Training loss: 1.2029569434168639
Validation loss: 2.325842873657895

Epoch: 5| Step: 9
Training loss: 1.2267342222484552
Validation loss: 2.377382446801011

Epoch: 5| Step: 10
Training loss: 1.3296806649055928
Validation loss: 2.412276386233182

Epoch: 411| Step: 0
Training loss: 1.1403508836762948
Validation loss: 2.3163594701846906

Epoch: 5| Step: 1
Training loss: 0.9961796143866667
Validation loss: 2.3003315669217312

Epoch: 5| Step: 2
Training loss: 1.202576152904229
Validation loss: 2.358827691127758

Epoch: 5| Step: 3
Training loss: 1.0224731794351305
Validation loss: 2.3303800151677843

Epoch: 5| Step: 4
Training loss: 1.397946319417182
Validation loss: 2.3694099804933098

Epoch: 5| Step: 5
Training loss: 1.2685718843558682
Validation loss: 2.347654245087136

Epoch: 5| Step: 6
Training loss: 0.8655962736135047
Validation loss: 2.3738138651153804

Epoch: 5| Step: 7
Training loss: 0.847075443546938
Validation loss: 2.428432179748822

Epoch: 5| Step: 8
Training loss: 0.9375336640989577
Validation loss: 2.3431567550816967

Epoch: 5| Step: 9
Training loss: 1.7935585265361016
Validation loss: 2.359885349831088

Epoch: 5| Step: 10
Training loss: 1.2392211620060591
Validation loss: 2.3384635826931572

Epoch: 412| Step: 0
Training loss: 1.1207726314420179
Validation loss: 2.3510963840049093

Epoch: 5| Step: 1
Training loss: 1.1732994069447031
Validation loss: 2.343153709113836

Epoch: 5| Step: 2
Training loss: 1.406540988909337
Validation loss: 2.365777945597584

Epoch: 5| Step: 3
Training loss: 0.8866542170900636
Validation loss: 2.3927392663154894

Epoch: 5| Step: 4
Training loss: 1.1297248591449136
Validation loss: 2.3532566188614075

Epoch: 5| Step: 5
Training loss: 1.2147647059198732
Validation loss: 2.356607160027414

Epoch: 5| Step: 6
Training loss: 1.1442630180100097
Validation loss: 2.322275996487967

Epoch: 5| Step: 7
Training loss: 1.1984453223419542
Validation loss: 2.399707982113377

Epoch: 5| Step: 8
Training loss: 1.05188894207079
Validation loss: 2.2742117228174874

Epoch: 5| Step: 9
Training loss: 1.588069741444823
Validation loss: 2.3189857235946603

Epoch: 5| Step: 10
Training loss: 1.030111377860683
Validation loss: 2.2713545270478486

Epoch: 413| Step: 0
Training loss: 0.9796233769167653
Validation loss: 2.3690878445759997

Epoch: 5| Step: 1
Training loss: 1.502983464102476
Validation loss: 2.3004518480603258

Epoch: 5| Step: 2
Training loss: 1.79145519723746
Validation loss: 2.395872106323094

Epoch: 5| Step: 3
Training loss: 1.1608171218338883
Validation loss: 2.3810111475136413

Epoch: 5| Step: 4
Training loss: 1.2738913914873602
Validation loss: 2.3278926544301033

Epoch: 5| Step: 5
Training loss: 0.9365693559417942
Validation loss: 2.3288793905940444

Epoch: 5| Step: 6
Training loss: 0.8716740065485042
Validation loss: 2.3716721700342274

Epoch: 5| Step: 7
Training loss: 0.849938410042265
Validation loss: 2.342226416216305

Epoch: 5| Step: 8
Training loss: 0.8076255272062228
Validation loss: 2.3280822767604774

Epoch: 5| Step: 9
Training loss: 1.3181061678138473
Validation loss: 2.3312219048146274

Epoch: 5| Step: 10
Training loss: 0.7646769278371894
Validation loss: 2.3650764065805077

Epoch: 414| Step: 0
Training loss: 0.9153044324983648
Validation loss: 2.3567722722803044

Epoch: 5| Step: 1
Training loss: 1.0539279604655791
Validation loss: 2.3207083694089965

Epoch: 5| Step: 2
Training loss: 1.3173782427731853
Validation loss: 2.2933870655709274

Epoch: 5| Step: 3
Training loss: 1.2128804032882483
Validation loss: 2.3173268159830878

Epoch: 5| Step: 4
Training loss: 0.8042978250610017
Validation loss: 2.3136146074234136

Epoch: 5| Step: 5
Training loss: 0.8581104685198282
Validation loss: 2.269059532612771

Epoch: 5| Step: 6
Training loss: 1.0781969792760482
Validation loss: 2.3546912165825975

Epoch: 5| Step: 7
Training loss: 1.1489932214322844
Validation loss: 2.4035694654707824

Epoch: 5| Step: 8
Training loss: 1.6020877628075025
Validation loss: 2.334619398035631

Epoch: 5| Step: 9
Training loss: 1.4701091078405333
Validation loss: 2.3301021551755525

Epoch: 5| Step: 10
Training loss: 1.1363842134346631
Validation loss: 2.2524084511304596

Epoch: 415| Step: 0
Training loss: 1.0617147236481728
Validation loss: 2.326793944518071

Epoch: 5| Step: 1
Training loss: 2.0222654740921326
Validation loss: 2.4461582051164448

Epoch: 5| Step: 2
Training loss: 0.8096771721897132
Validation loss: 2.3784834935715367

Epoch: 5| Step: 3
Training loss: 0.917255465379196
Validation loss: 2.3379227704766787

Epoch: 5| Step: 4
Training loss: 0.9555146949432554
Validation loss: 2.407212351406557

Epoch: 5| Step: 5
Training loss: 1.003475111473585
Validation loss: 2.3878454700728753

Epoch: 5| Step: 6
Training loss: 0.9803379777121454
Validation loss: 2.3301174449760205

Epoch: 5| Step: 7
Training loss: 1.1643314946842027
Validation loss: 2.3818383872250184

Epoch: 5| Step: 8
Training loss: 0.753555730263614
Validation loss: 2.3355710471334907

Epoch: 5| Step: 9
Training loss: 1.2227698325149814
Validation loss: 2.341744686888529

Epoch: 5| Step: 10
Training loss: 1.0539961067504207
Validation loss: 2.3393268706272075

Epoch: 416| Step: 0
Training loss: 0.9548728425817665
Validation loss: 2.3243277514790996

Epoch: 5| Step: 1
Training loss: 0.6488166068545809
Validation loss: 2.3654014953989058

Epoch: 5| Step: 2
Training loss: 1.0172063986902147
Validation loss: 2.308937553670093

Epoch: 5| Step: 3
Training loss: 1.1982202504581925
Validation loss: 2.354576150003747

Epoch: 5| Step: 4
Training loss: 1.5605241871737434
Validation loss: 2.317550863622504

Epoch: 5| Step: 5
Training loss: 1.4055123831828717
Validation loss: 2.2520636104428804

Epoch: 5| Step: 6
Training loss: 1.4181691598216133
Validation loss: 2.298815072168133

Epoch: 5| Step: 7
Training loss: 0.894529484243191
Validation loss: 2.274777137708425

Epoch: 5| Step: 8
Training loss: 1.0165606370469669
Validation loss: 2.3648178839315666

Epoch: 5| Step: 9
Training loss: 1.0129018810160222
Validation loss: 2.406568747158851

Epoch: 5| Step: 10
Training loss: 1.3661406078328369
Validation loss: 2.341873423451037

Epoch: 417| Step: 0
Training loss: 0.6434240830936903
Validation loss: 2.3894823434520163

Epoch: 5| Step: 1
Training loss: 1.3169585294805535
Validation loss: 2.39861088094971

Epoch: 5| Step: 2
Training loss: 0.8206257903072738
Validation loss: 2.4180847614068033

Epoch: 5| Step: 3
Training loss: 1.1605043242315207
Validation loss: 2.4033372794951178

Epoch: 5| Step: 4
Training loss: 0.8627125519611972
Validation loss: 2.3519528523243367

Epoch: 5| Step: 5
Training loss: 1.492588568508388
Validation loss: 2.3735732654340875

Epoch: 5| Step: 6
Training loss: 0.8169372146135494
Validation loss: 2.375451637075393

Epoch: 5| Step: 7
Training loss: 1.033404671349736
Validation loss: 2.344598250485859

Epoch: 5| Step: 8
Training loss: 1.7084287601273211
Validation loss: 2.3842966897028197

Epoch: 5| Step: 9
Training loss: 1.2005517366725051
Validation loss: 2.41084290804977

Epoch: 5| Step: 10
Training loss: 1.070261042116691
Validation loss: 2.397456025062445

Epoch: 418| Step: 0
Training loss: 0.9744301977176978
Validation loss: 2.3516723658386387

Epoch: 5| Step: 1
Training loss: 0.9797946999046186
Validation loss: 2.2747369814552507

Epoch: 5| Step: 2
Training loss: 1.0499386156395158
Validation loss: 2.347774019246559

Epoch: 5| Step: 3
Training loss: 1.0313755883703055
Validation loss: 2.38804646436862

Epoch: 5| Step: 4
Training loss: 1.4357177632661848
Validation loss: 2.3792357999905107

Epoch: 5| Step: 5
Training loss: 1.5722127017005134
Validation loss: 2.324422085737226

Epoch: 5| Step: 6
Training loss: 1.1471964559722436
Validation loss: 2.3452731219743637

Epoch: 5| Step: 7
Training loss: 0.8039087026723625
Validation loss: 2.3568046948566765

Epoch: 5| Step: 8
Training loss: 1.4340253382988666
Validation loss: 2.345172143798397

Epoch: 5| Step: 9
Training loss: 0.8603018530904945
Validation loss: 2.327899632072604

Epoch: 5| Step: 10
Training loss: 0.8875781696441454
Validation loss: 2.3078861882183066

Epoch: 419| Step: 0
Training loss: 0.9248342378400746
Validation loss: 2.3379984254666732

Epoch: 5| Step: 1
Training loss: 0.9689690126989617
Validation loss: 2.3120236015549387

Epoch: 5| Step: 2
Training loss: 0.9483879126668626
Validation loss: 2.3187228930138524

Epoch: 5| Step: 3
Training loss: 0.8253819361823784
Validation loss: 2.283730563407548

Epoch: 5| Step: 4
Training loss: 1.1947821144757595
Validation loss: 2.38806730043055

Epoch: 5| Step: 5
Training loss: 1.357414278516851
Validation loss: 2.32811209105289

Epoch: 5| Step: 6
Training loss: 0.9505732099481664
Validation loss: 2.2996208013420203

Epoch: 5| Step: 7
Training loss: 1.3225246158897759
Validation loss: 2.360312597386328

Epoch: 5| Step: 8
Training loss: 0.7882604772063211
Validation loss: 2.3526860825709197

Epoch: 5| Step: 9
Training loss: 1.6610704485418193
Validation loss: 2.3609802570150893

Epoch: 5| Step: 10
Training loss: 0.9866953553290424
Validation loss: 2.301019713431049

Epoch: 420| Step: 0
Training loss: 1.0412308289776873
Validation loss: 2.393475739437945

Epoch: 5| Step: 1
Training loss: 1.1230464504075284
Validation loss: 2.2625196766183255

Epoch: 5| Step: 2
Training loss: 1.077797328524766
Validation loss: 2.255455652810541

Epoch: 5| Step: 3
Training loss: 1.5126604798987477
Validation loss: 2.3267919535808756

Epoch: 5| Step: 4
Training loss: 1.128483518234187
Validation loss: 2.4097051947811092

Epoch: 5| Step: 5
Training loss: 0.8757328302506366
Validation loss: 2.3540304251438315

Epoch: 5| Step: 6
Training loss: 1.2133886325377279
Validation loss: 2.374106410688867

Epoch: 5| Step: 7
Training loss: 1.0494957757713064
Validation loss: 2.387565842575139

Epoch: 5| Step: 8
Training loss: 1.1236788091291103
Validation loss: 2.3490479311262313

Epoch: 5| Step: 9
Training loss: 1.1616913885243494
Validation loss: 2.3730554429711552

Epoch: 5| Step: 10
Training loss: 0.8071798595815627
Validation loss: 2.3978288145425717

Epoch: 421| Step: 0
Training loss: 0.8974597088262638
Validation loss: 2.342527483880466

Epoch: 5| Step: 1
Training loss: 1.0440835887945057
Validation loss: 2.3517523275254244

Epoch: 5| Step: 2
Training loss: 0.9207214314805889
Validation loss: 2.333278062784031

Epoch: 5| Step: 3
Training loss: 0.8147544029166034
Validation loss: 2.462645070552326

Epoch: 5| Step: 4
Training loss: 0.8788364637007927
Validation loss: 2.414110230434861

Epoch: 5| Step: 5
Training loss: 1.1062795408798243
Validation loss: 2.369132640731737

Epoch: 5| Step: 6
Training loss: 1.0461441449539755
Validation loss: 2.4299617702613703

Epoch: 5| Step: 7
Training loss: 1.186375637817533
Validation loss: 2.377262047509895

Epoch: 5| Step: 8
Training loss: 0.8572421569865932
Validation loss: 2.3872645087968922

Epoch: 5| Step: 9
Training loss: 1.9001771467847959
Validation loss: 2.3897796086212133

Epoch: 5| Step: 10
Training loss: 0.8655388772035284
Validation loss: 2.340393246212623

Epoch: 422| Step: 0
Training loss: 0.8907582032829396
Validation loss: 2.3358338452679654

Epoch: 5| Step: 1
Training loss: 1.3834638193167614
Validation loss: 2.3370735670040217

Epoch: 5| Step: 2
Training loss: 1.1062794870013568
Validation loss: 2.382740531653573

Epoch: 5| Step: 3
Training loss: 1.1998784242079024
Validation loss: 2.351702497525372

Epoch: 5| Step: 4
Training loss: 0.7269287416856889
Validation loss: 2.309332902136558

Epoch: 5| Step: 5
Training loss: 0.727040328545685
Validation loss: 2.281079240814435

Epoch: 5| Step: 6
Training loss: 1.0613914765680814
Validation loss: 2.3534275696623164

Epoch: 5| Step: 7
Training loss: 1.171767064528003
Validation loss: 2.3259294630393637

Epoch: 5| Step: 8
Training loss: 1.271158953156673
Validation loss: 2.366235205282395

Epoch: 5| Step: 9
Training loss: 1.5825763281422993
Validation loss: 2.336785503619712

Epoch: 5| Step: 10
Training loss: 1.3438368037375858
Validation loss: 2.2436881708657204

Epoch: 423| Step: 0
Training loss: 0.9339191077325182
Validation loss: 2.3101208151092205

Epoch: 5| Step: 1
Training loss: 0.849800176132877
Validation loss: 2.412237239612349

Epoch: 5| Step: 2
Training loss: 1.2345462149169415
Validation loss: 2.3893764387365257

Epoch: 5| Step: 3
Training loss: 1.375718362595918
Validation loss: 2.386211835732134

Epoch: 5| Step: 4
Training loss: 1.632275725844526
Validation loss: 2.421143022182571

Epoch: 5| Step: 5
Training loss: 0.9490022765675965
Validation loss: 2.396316605487225

Epoch: 5| Step: 6
Training loss: 1.1797168551196846
Validation loss: 2.352713532172032

Epoch: 5| Step: 7
Training loss: 0.9319944209762717
Validation loss: 2.4530235819782362

Epoch: 5| Step: 8
Training loss: 0.9494159007098796
Validation loss: 2.4024514755158677

Epoch: 5| Step: 9
Training loss: 1.2282678690891065
Validation loss: 2.3002320546839488

Epoch: 5| Step: 10
Training loss: 1.3103367826111845
Validation loss: 2.3202115680498068

Epoch: 424| Step: 0
Training loss: 0.9454919628949557
Validation loss: 2.2623074307909756

Epoch: 5| Step: 1
Training loss: 0.8943152687498567
Validation loss: 2.3040004634307665

Epoch: 5| Step: 2
Training loss: 1.7687249441360386
Validation loss: 2.3031015642009267

Epoch: 5| Step: 3
Training loss: 1.3615539451051943
Validation loss: 2.3013487438997444

Epoch: 5| Step: 4
Training loss: 1.3211252994932234
Validation loss: 2.3500764699087004

Epoch: 5| Step: 5
Training loss: 1.0651648145848671
Validation loss: 2.3256859841232544

Epoch: 5| Step: 6
Training loss: 1.0623578369176172
Validation loss: 2.3128109894389577

Epoch: 5| Step: 7
Training loss: 0.9541358590184653
Validation loss: 2.31287407503216

Epoch: 5| Step: 8
Training loss: 1.0982541122481104
Validation loss: 2.3423085330985143

Epoch: 5| Step: 9
Training loss: 0.9394801209312358
Validation loss: 2.287762453150677

Epoch: 5| Step: 10
Training loss: 1.1122581733442747
Validation loss: 2.410496085844398

Epoch: 425| Step: 0
Training loss: 1.1676467911051167
Validation loss: 2.318354624480485

Epoch: 5| Step: 1
Training loss: 1.0700999696324285
Validation loss: 2.4221450004161045

Epoch: 5| Step: 2
Training loss: 1.0582106907187898
Validation loss: 2.5111109755890473

Epoch: 5| Step: 3
Training loss: 1.4133873270775368
Validation loss: 2.4952710607542143

Epoch: 5| Step: 4
Training loss: 1.524895542507047
Validation loss: 2.422370743996911

Epoch: 5| Step: 5
Training loss: 0.9048995446466098
Validation loss: 2.4182071970118573

Epoch: 5| Step: 6
Training loss: 1.021117222814588
Validation loss: 2.385635475741067

Epoch: 5| Step: 7
Training loss: 1.126666794603856
Validation loss: 2.395381318976657

Epoch: 5| Step: 8
Training loss: 1.0145524450426726
Validation loss: 2.3245077178109605

Epoch: 5| Step: 9
Training loss: 0.9985869377905447
Validation loss: 2.2669350383625306

Epoch: 5| Step: 10
Training loss: 1.0724956772901657
Validation loss: 2.313792505217393

Epoch: 426| Step: 0
Training loss: 1.0663477843190712
Validation loss: 2.32784883664778

Epoch: 5| Step: 1
Training loss: 1.2085057606936596
Validation loss: 2.3282044821016177

Epoch: 5| Step: 2
Training loss: 0.8777889355287004
Validation loss: 2.2875483804472085

Epoch: 5| Step: 3
Training loss: 1.1902196759930377
Validation loss: 2.3540201508163685

Epoch: 5| Step: 4
Training loss: 0.912408979657766
Validation loss: 2.3209291767479825

Epoch: 5| Step: 5
Training loss: 1.8366045450250086
Validation loss: 2.32355136073897

Epoch: 5| Step: 6
Training loss: 0.9944162043025323
Validation loss: 2.2998160264143004

Epoch: 5| Step: 7
Training loss: 0.9998242700666974
Validation loss: 2.4004525548835476

Epoch: 5| Step: 8
Training loss: 1.1646784234620837
Validation loss: 2.3095281762265425

Epoch: 5| Step: 9
Training loss: 0.7771926042843935
Validation loss: 2.358597210323676

Epoch: 5| Step: 10
Training loss: 0.6609130449031874
Validation loss: 2.450607670873951

Epoch: 427| Step: 0
Training loss: 1.759411368663258
Validation loss: 2.3825290871135527

Epoch: 5| Step: 1
Training loss: 1.114661181336767
Validation loss: 2.381851333269523

Epoch: 5| Step: 2
Training loss: 0.8509921692578694
Validation loss: 2.3599069000258486

Epoch: 5| Step: 3
Training loss: 0.7873727816804679
Validation loss: 2.392282090597901

Epoch: 5| Step: 4
Training loss: 1.3280960079843438
Validation loss: 2.387442504563329

Epoch: 5| Step: 5
Training loss: 1.3921129217412527
Validation loss: 2.3267419311379087

Epoch: 5| Step: 6
Training loss: 1.106482159235871
Validation loss: 2.372011991768149

Epoch: 5| Step: 7
Training loss: 0.9746618161206894
Validation loss: 2.4006465000946586

Epoch: 5| Step: 8
Training loss: 1.2798830509403867
Validation loss: 2.4107337305435332

Epoch: 5| Step: 9
Training loss: 1.0883895852962802
Validation loss: 2.3264971614892342

Epoch: 5| Step: 10
Training loss: 0.646949347310069
Validation loss: 2.3612102858891464

Epoch: 428| Step: 0
Training loss: 1.0993883036057381
Validation loss: 2.398261784740614

Epoch: 5| Step: 1
Training loss: 0.7112991335479165
Validation loss: 2.3442763319340445

Epoch: 5| Step: 2
Training loss: 1.474547853512796
Validation loss: 2.320201205012424

Epoch: 5| Step: 3
Training loss: 1.844333168519743
Validation loss: 2.3114399585334486

Epoch: 5| Step: 4
Training loss: 0.7663089266548196
Validation loss: 2.3951920363076047

Epoch: 5| Step: 5
Training loss: 1.3783232237104148
Validation loss: 2.3360689456634627

Epoch: 5| Step: 6
Training loss: 0.9735671837209088
Validation loss: 2.2724866802458275

Epoch: 5| Step: 7
Training loss: 0.9443903752507442
Validation loss: 2.2969962623725033

Epoch: 5| Step: 8
Training loss: 1.03518947332077
Validation loss: 2.2842918144391926

Epoch: 5| Step: 9
Training loss: 1.0142154008183875
Validation loss: 2.284841099286093

Epoch: 5| Step: 10
Training loss: 0.7340117428617235
Validation loss: 2.3422510578220197

Epoch: 429| Step: 0
Training loss: 1.4159550094784747
Validation loss: 2.4056980419982565

Epoch: 5| Step: 1
Training loss: 0.8794460080345018
Validation loss: 2.385870623853222

Epoch: 5| Step: 2
Training loss: 0.6506730803754319
Validation loss: 2.388697220186533

Epoch: 5| Step: 3
Training loss: 1.0622317031501969
Validation loss: 2.323104833854896

Epoch: 5| Step: 4
Training loss: 1.6350332243923802
Validation loss: 2.324165237871004

Epoch: 5| Step: 5
Training loss: 1.1684851892109696
Validation loss: 2.358374426601952

Epoch: 5| Step: 6
Training loss: 0.8901872395602975
Validation loss: 2.3046292105218074

Epoch: 5| Step: 7
Training loss: 0.739608338878015
Validation loss: 2.395058079966543

Epoch: 5| Step: 8
Training loss: 0.9338351460335484
Validation loss: 2.3287718158542203

Epoch: 5| Step: 9
Training loss: 1.4207116702318108
Validation loss: 2.299715060511163

Epoch: 5| Step: 10
Training loss: 0.6739309923462218
Validation loss: 2.383590987979202

Epoch: 430| Step: 0
Training loss: 1.2003533776832607
Validation loss: 2.3076941642965427

Epoch: 5| Step: 1
Training loss: 0.7905044976479874
Validation loss: 2.3899105386959594

Epoch: 5| Step: 2
Training loss: 1.0506615552834369
Validation loss: 2.2882391915359697

Epoch: 5| Step: 3
Training loss: 0.6249118981254698
Validation loss: 2.332550324701641

Epoch: 5| Step: 4
Training loss: 0.8181521351323473
Validation loss: 2.2720184853649723

Epoch: 5| Step: 5
Training loss: 1.052841718930072
Validation loss: 2.3194307964207432

Epoch: 5| Step: 6
Training loss: 1.1492748710989897
Validation loss: 2.3560873943028144

Epoch: 5| Step: 7
Training loss: 0.9369234537493324
Validation loss: 2.302824289423818

Epoch: 5| Step: 8
Training loss: 1.2780234951760892
Validation loss: 2.3138963917170696

Epoch: 5| Step: 9
Training loss: 1.0350263981977104
Validation loss: 2.297890762294507

Epoch: 5| Step: 10
Training loss: 1.7298629768218932
Validation loss: 2.291688200401047

Epoch: 431| Step: 0
Training loss: 1.3445566107371338
Validation loss: 2.3222402922113106

Epoch: 5| Step: 1
Training loss: 1.0940832992620726
Validation loss: 2.3792182214941593

Epoch: 5| Step: 2
Training loss: 0.9500582087402115
Validation loss: 2.330902367789954

Epoch: 5| Step: 3
Training loss: 0.9069511726510193
Validation loss: 2.3496063193941

Epoch: 5| Step: 4
Training loss: 0.9739164897613569
Validation loss: 2.2705021839069874

Epoch: 5| Step: 5
Training loss: 0.7529723554858542
Validation loss: 2.3296915793068003

Epoch: 5| Step: 6
Training loss: 0.8593577643313328
Validation loss: 2.3215560654954484

Epoch: 5| Step: 7
Training loss: 0.9873819594514058
Validation loss: 2.350195348322537

Epoch: 5| Step: 8
Training loss: 1.7786082035252562
Validation loss: 2.3273743837642518

Epoch: 5| Step: 9
Training loss: 1.005115537692114
Validation loss: 2.411538922305817

Epoch: 5| Step: 10
Training loss: 0.9161346943785169
Validation loss: 2.4374411444109487

Epoch: 432| Step: 0
Training loss: 0.7793695707522097
Validation loss: 2.4260628812058536

Epoch: 5| Step: 1
Training loss: 0.9604586206624689
Validation loss: 2.3253590914162183

Epoch: 5| Step: 2
Training loss: 0.7547047393914875
Validation loss: 2.262533884401502

Epoch: 5| Step: 3
Training loss: 1.2054742443382263
Validation loss: 2.2913531266973575

Epoch: 5| Step: 4
Training loss: 1.166481730017596
Validation loss: 2.3155696652876068

Epoch: 5| Step: 5
Training loss: 1.1649974166448545
Validation loss: 2.404595260888914

Epoch: 5| Step: 6
Training loss: 1.0352114104922976
Validation loss: 2.382967546631011

Epoch: 5| Step: 7
Training loss: 0.9777550396810095
Validation loss: 2.378513410096992

Epoch: 5| Step: 8
Training loss: 0.8682782298693357
Validation loss: 2.2624755694889473

Epoch: 5| Step: 9
Training loss: 1.6163706905091304
Validation loss: 2.299471261418944

Epoch: 5| Step: 10
Training loss: 1.0322393237924803
Validation loss: 2.3137552761659634

Epoch: 433| Step: 0
Training loss: 1.0001029319240367
Validation loss: 2.310028450454233

Epoch: 5| Step: 1
Training loss: 0.8336989117459129
Validation loss: 2.328205387775509

Epoch: 5| Step: 2
Training loss: 0.8924929455069623
Validation loss: 2.2857418925695443

Epoch: 5| Step: 3
Training loss: 0.9192602933256014
Validation loss: 2.375175417243829

Epoch: 5| Step: 4
Training loss: 1.6780252437670544
Validation loss: 2.427432995242323

Epoch: 5| Step: 5
Training loss: 1.1614007408106881
Validation loss: 2.360723149297372

Epoch: 5| Step: 6
Training loss: 1.02844967802726
Validation loss: 2.3633231481778734

Epoch: 5| Step: 7
Training loss: 1.2794364095987616
Validation loss: 2.4176349818057306

Epoch: 5| Step: 8
Training loss: 1.4568861001867086
Validation loss: 2.375109191310179

Epoch: 5| Step: 9
Training loss: 1.1033810153657622
Validation loss: 2.2905590934568543

Epoch: 5| Step: 10
Training loss: 0.9250103601958056
Validation loss: 2.3069917506176663

Epoch: 434| Step: 0
Training loss: 0.8023575318219802
Validation loss: 2.3996481996088534

Epoch: 5| Step: 1
Training loss: 1.1774615577529324
Validation loss: 2.2758981654734085

Epoch: 5| Step: 2
Training loss: 1.0311301190603792
Validation loss: 2.315527425612814

Epoch: 5| Step: 3
Training loss: 1.9259048638897063
Validation loss: 2.3237128509870746

Epoch: 5| Step: 4
Training loss: 0.87310012552577
Validation loss: 2.38679583460112

Epoch: 5| Step: 5
Training loss: 1.1275013560352503
Validation loss: 2.2906641310092692

Epoch: 5| Step: 6
Training loss: 0.8920881065681635
Validation loss: 2.326564673652202

Epoch: 5| Step: 7
Training loss: 1.1196579195331833
Validation loss: 2.2979326021160706

Epoch: 5| Step: 8
Training loss: 1.0073621468145901
Validation loss: 2.332791150806982

Epoch: 5| Step: 9
Training loss: 0.9721771653649007
Validation loss: 2.321037036002696

Epoch: 5| Step: 10
Training loss: 1.100626283869084
Validation loss: 2.402792608062135

Epoch: 435| Step: 0
Training loss: 0.8070373667866458
Validation loss: 2.323352277530231

Epoch: 5| Step: 1
Training loss: 1.2716342351351801
Validation loss: 2.373395153061236

Epoch: 5| Step: 2
Training loss: 0.7453993516776395
Validation loss: 2.408194510686319

Epoch: 5| Step: 3
Training loss: 1.6170590851887432
Validation loss: 2.3650101314496683

Epoch: 5| Step: 4
Training loss: 1.1546425342192743
Validation loss: 2.326499270585275

Epoch: 5| Step: 5
Training loss: 0.8283465107177294
Validation loss: 2.312203210589051

Epoch: 5| Step: 6
Training loss: 0.9643787699914349
Validation loss: 2.312178168369282

Epoch: 5| Step: 7
Training loss: 1.5916951714538012
Validation loss: 2.3781913231170435

Epoch: 5| Step: 8
Training loss: 1.0194927807562142
Validation loss: 2.297180683375637

Epoch: 5| Step: 9
Training loss: 0.7586656074787494
Validation loss: 2.3007334393551084

Epoch: 5| Step: 10
Training loss: 1.1889416326180187
Validation loss: 2.276301299446798

Epoch: 436| Step: 0
Training loss: 1.3739987108815905
Validation loss: 2.3387285734254144

Epoch: 5| Step: 1
Training loss: 0.7949849321628856
Validation loss: 2.25157554728404

Epoch: 5| Step: 2
Training loss: 1.0365180504750369
Validation loss: 2.2968651879671445

Epoch: 5| Step: 3
Training loss: 0.9577622093949929
Validation loss: 2.357175967450017

Epoch: 5| Step: 4
Training loss: 0.842354185067685
Validation loss: 2.344022931577087

Epoch: 5| Step: 5
Training loss: 1.0524178278507315
Validation loss: 2.375558580752189

Epoch: 5| Step: 6
Training loss: 0.8761972002781848
Validation loss: 2.408623149318102

Epoch: 5| Step: 7
Training loss: 0.7946545200502336
Validation loss: 2.3677994879103457

Epoch: 5| Step: 8
Training loss: 1.7236357864483904
Validation loss: 2.3780869422622644

Epoch: 5| Step: 9
Training loss: 0.7965422290783322
Validation loss: 2.401790862277536

Epoch: 5| Step: 10
Training loss: 1.3806412024041586
Validation loss: 2.4061761223338136

Epoch: 437| Step: 0
Training loss: 0.8893630138348175
Validation loss: 2.414921124504681

Epoch: 5| Step: 1
Training loss: 1.0514580344561313
Validation loss: 2.3647285555245285

Epoch: 5| Step: 2
Training loss: 1.057311291191491
Validation loss: 2.3028249509780827

Epoch: 5| Step: 3
Training loss: 1.636443995901232
Validation loss: 2.301357392213795

Epoch: 5| Step: 4
Training loss: 0.7196948433955661
Validation loss: 2.3520624432452246

Epoch: 5| Step: 5
Training loss: 1.2169120819758463
Validation loss: 2.3064757103180695

Epoch: 5| Step: 6
Training loss: 1.28546222418495
Validation loss: 2.3456274862637936

Epoch: 5| Step: 7
Training loss: 1.0840613535448589
Validation loss: 2.3719185450502325

Epoch: 5| Step: 8
Training loss: 1.1367746450832827
Validation loss: 2.3623686326452282

Epoch: 5| Step: 9
Training loss: 0.9768909054740799
Validation loss: 2.295637996235179

Epoch: 5| Step: 10
Training loss: 0.9976158331060445
Validation loss: 2.3264071787731138

Epoch: 438| Step: 0
Training loss: 0.9381432869365895
Validation loss: 2.3452745670648496

Epoch: 5| Step: 1
Training loss: 0.8974168370217472
Validation loss: 2.420109981423209

Epoch: 5| Step: 2
Training loss: 1.1080387288014466
Validation loss: 2.4209598925490736

Epoch: 5| Step: 3
Training loss: 1.3072204671774916
Validation loss: 2.413623239799429

Epoch: 5| Step: 4
Training loss: 0.8898559060409332
Validation loss: 2.2858788638528083

Epoch: 5| Step: 5
Training loss: 0.943565930485293
Validation loss: 2.310697126032866

Epoch: 5| Step: 6
Training loss: 0.8894809938000946
Validation loss: 2.2891022165211328

Epoch: 5| Step: 7
Training loss: 1.7833527317358715
Validation loss: 2.3496528169828275

Epoch: 5| Step: 8
Training loss: 0.9167324100384966
Validation loss: 2.3464524973250467

Epoch: 5| Step: 9
Training loss: 0.862438774700095
Validation loss: 2.318139746181468

Epoch: 5| Step: 10
Training loss: 1.1651000448991595
Validation loss: 2.3790708755298295

Epoch: 439| Step: 0
Training loss: 0.984638572404646
Validation loss: 2.321200230835612

Epoch: 5| Step: 1
Training loss: 0.9569890849887143
Validation loss: 2.380205562400825

Epoch: 5| Step: 2
Training loss: 1.3771320632569226
Validation loss: 2.3604283884153094

Epoch: 5| Step: 3
Training loss: 0.7694014231578178
Validation loss: 2.356977932948177

Epoch: 5| Step: 4
Training loss: 1.6070354456051665
Validation loss: 2.3776082363205475

Epoch: 5| Step: 5
Training loss: 1.0792981275122517
Validation loss: 2.4067002263986175

Epoch: 5| Step: 6
Training loss: 1.052227060805245
Validation loss: 2.3736491244728626

Epoch: 5| Step: 7
Training loss: 0.9376889991984733
Validation loss: 2.4084132889521057

Epoch: 5| Step: 8
Training loss: 1.2842602606614664
Validation loss: 2.3998944821200427

Epoch: 5| Step: 9
Training loss: 0.8247658238253074
Validation loss: 2.391849317183058

Epoch: 5| Step: 10
Training loss: 0.6761588436393784
Validation loss: 2.4090722335824752

Epoch: 440| Step: 0
Training loss: 0.9463384436289888
Validation loss: 2.3117181508867226

Epoch: 5| Step: 1
Training loss: 0.8145152921300736
Validation loss: 2.3638779079131003

Epoch: 5| Step: 2
Training loss: 0.9803226559678053
Validation loss: 2.3346057914650222

Epoch: 5| Step: 3
Training loss: 0.9297468342800256
Validation loss: 2.2792950798972598

Epoch: 5| Step: 4
Training loss: 1.1531941524952787
Validation loss: 2.2405100098391966

Epoch: 5| Step: 5
Training loss: 1.1010119638373324
Validation loss: 2.424484865332955

Epoch: 5| Step: 6
Training loss: 0.8210223078839148
Validation loss: 2.3398450866878373

Epoch: 5| Step: 7
Training loss: 0.9885696472827997
Validation loss: 2.342124109215469

Epoch: 5| Step: 8
Training loss: 1.1583978447456753
Validation loss: 2.2912073448816965

Epoch: 5| Step: 9
Training loss: 1.8342911501278907
Validation loss: 2.3159443215674904

Epoch: 5| Step: 10
Training loss: 0.920105869172586
Validation loss: 2.269125419672251

Epoch: 441| Step: 0
Training loss: 0.8910253193957971
Validation loss: 2.328815079062937

Epoch: 5| Step: 1
Training loss: 1.126949845810058
Validation loss: 2.3069471513477358

Epoch: 5| Step: 2
Training loss: 0.8982898756732147
Validation loss: 2.3630601744784046

Epoch: 5| Step: 3
Training loss: 0.8868217912537129
Validation loss: 2.376351193965541

Epoch: 5| Step: 4
Training loss: 0.7823251574001984
Validation loss: 2.3954166592175983

Epoch: 5| Step: 5
Training loss: 1.4949772505799501
Validation loss: 2.3206450482748346

Epoch: 5| Step: 6
Training loss: 1.1234179605156285
Validation loss: 2.399042114569064

Epoch: 5| Step: 7
Training loss: 0.9506085742883175
Validation loss: 2.4129540338102866

Epoch: 5| Step: 8
Training loss: 1.114903656513508
Validation loss: 2.3044196244132076

Epoch: 5| Step: 9
Training loss: 0.9975872437129583
Validation loss: 2.3718505641946313

Epoch: 5| Step: 10
Training loss: 1.1588974105253034
Validation loss: 2.314538094701214

Epoch: 442| Step: 0
Training loss: 0.8474152393772323
Validation loss: 2.3308353079319954

Epoch: 5| Step: 1
Training loss: 1.0349097768186293
Validation loss: 2.3355819349774434

Epoch: 5| Step: 2
Training loss: 0.8364536438870281
Validation loss: 2.299044752489764

Epoch: 5| Step: 3
Training loss: 1.6572569179508492
Validation loss: 2.313614634017028

Epoch: 5| Step: 4
Training loss: 0.7768327576622108
Validation loss: 2.259147473347305

Epoch: 5| Step: 5
Training loss: 0.8711075033291025
Validation loss: 2.4181469601092083

Epoch: 5| Step: 6
Training loss: 0.9707463521562207
Validation loss: 2.2816454108816573

Epoch: 5| Step: 7
Training loss: 1.026049941492681
Validation loss: 2.336166558822863

Epoch: 5| Step: 8
Training loss: 1.056091109293822
Validation loss: 2.331467036659209

Epoch: 5| Step: 9
Training loss: 1.189160039963912
Validation loss: 2.3490890736847474

Epoch: 5| Step: 10
Training loss: 1.0871006067808562
Validation loss: 2.3365738508467553

Epoch: 443| Step: 0
Training loss: 0.9158992734107959
Validation loss: 2.336718455710836

Epoch: 5| Step: 1
Training loss: 0.851993836519397
Validation loss: 2.407672780535411

Epoch: 5| Step: 2
Training loss: 1.2890485358204344
Validation loss: 2.358729731630827

Epoch: 5| Step: 3
Training loss: 0.6481741174977672
Validation loss: 2.3725490704058148

Epoch: 5| Step: 4
Training loss: 1.0144637878821172
Validation loss: 2.3443831667996484

Epoch: 5| Step: 5
Training loss: 0.9996432621747261
Validation loss: 2.3589438278252857

Epoch: 5| Step: 6
Training loss: 1.188324090209225
Validation loss: 2.3478126950819815

Epoch: 5| Step: 7
Training loss: 1.0890575020236206
Validation loss: 2.395256750663456

Epoch: 5| Step: 8
Training loss: 1.567742669457178
Validation loss: 2.3398528926008635

Epoch: 5| Step: 9
Training loss: 1.2958481181651547
Validation loss: 2.3128082050051315

Epoch: 5| Step: 10
Training loss: 0.6957673074801793
Validation loss: 2.3416456470838694

Epoch: 444| Step: 0
Training loss: 0.8413078852742955
Validation loss: 2.3412809978431404

Epoch: 5| Step: 1
Training loss: 0.8984062852827313
Validation loss: 2.315431912968227

Epoch: 5| Step: 2
Training loss: 0.9387680061635089
Validation loss: 2.298318605278592

Epoch: 5| Step: 3
Training loss: 0.9488573053363702
Validation loss: 2.3329566656668264

Epoch: 5| Step: 4
Training loss: 0.9683517745051727
Validation loss: 2.2799016429257692

Epoch: 5| Step: 5
Training loss: 0.6049832273948403
Validation loss: 2.277539910946219

Epoch: 5| Step: 6
Training loss: 1.7759595238566663
Validation loss: 2.3473069603725176

Epoch: 5| Step: 7
Training loss: 1.2206449693178236
Validation loss: 2.3729593596835374

Epoch: 5| Step: 8
Training loss: 1.0568441311362284
Validation loss: 2.256870550603005

Epoch: 5| Step: 9
Training loss: 1.0461324648997021
Validation loss: 2.329483248265228

Epoch: 5| Step: 10
Training loss: 1.3220425168210945
Validation loss: 2.4310919251186403

Epoch: 445| Step: 0
Training loss: 0.9996310387872969
Validation loss: 2.3807621944223416

Epoch: 5| Step: 1
Training loss: 1.1957609046153288
Validation loss: 2.38595923969174

Epoch: 5| Step: 2
Training loss: 0.9384178119414518
Validation loss: 2.4303826474997097

Epoch: 5| Step: 3
Training loss: 1.6867135652548122
Validation loss: 2.348499422888502

Epoch: 5| Step: 4
Training loss: 0.6679808409193311
Validation loss: 2.357042320621618

Epoch: 5| Step: 5
Training loss: 1.1006456171083583
Validation loss: 2.3678934263139233

Epoch: 5| Step: 6
Training loss: 0.8111758078577431
Validation loss: 2.3632657766450036

Epoch: 5| Step: 7
Training loss: 1.0287381995858074
Validation loss: 2.324347710558334

Epoch: 5| Step: 8
Training loss: 0.9790820463964689
Validation loss: 2.266389822234488

Epoch: 5| Step: 9
Training loss: 1.2669621691757644
Validation loss: 2.338016908180466

Epoch: 5| Step: 10
Training loss: 0.9235217370664475
Validation loss: 2.287995592066237

Epoch: 446| Step: 0
Training loss: 1.3488524504632549
Validation loss: 2.3373841199567593

Epoch: 5| Step: 1
Training loss: 0.9505923657957277
Validation loss: 2.316695299264501

Epoch: 5| Step: 2
Training loss: 1.0125708802456064
Validation loss: 2.339719574943343

Epoch: 5| Step: 3
Training loss: 0.911983799918079
Validation loss: 2.350367914111126

Epoch: 5| Step: 4
Training loss: 1.01305898612514
Validation loss: 2.424374369954097

Epoch: 5| Step: 5
Training loss: 0.6708739608008871
Validation loss: 2.3640141938992123

Epoch: 5| Step: 6
Training loss: 0.9488779091838794
Validation loss: 2.3998550074713725

Epoch: 5| Step: 7
Training loss: 1.0978599169334708
Validation loss: 2.4236120043842244

Epoch: 5| Step: 8
Training loss: 1.057799826339012
Validation loss: 2.390277744836063

Epoch: 5| Step: 9
Training loss: 1.5820023145501991
Validation loss: 2.3810757929303756

Epoch: 5| Step: 10
Training loss: 0.679202816787064
Validation loss: 2.335632046340374

Epoch: 447| Step: 0
Training loss: 0.8873817553125374
Validation loss: 2.3521292673956973

Epoch: 5| Step: 1
Training loss: 0.7497643259428138
Validation loss: 2.3514181625684825

Epoch: 5| Step: 2
Training loss: 1.5467694179067644
Validation loss: 2.3926196114026164

Epoch: 5| Step: 3
Training loss: 0.9738503904586003
Validation loss: 2.2820798033633523

Epoch: 5| Step: 4
Training loss: 0.8085197746604583
Validation loss: 2.3444817432349363

Epoch: 5| Step: 5
Training loss: 1.1365730218450114
Validation loss: 2.3746205001328153

Epoch: 5| Step: 6
Training loss: 0.9000657627133196
Validation loss: 2.346627040437693

Epoch: 5| Step: 7
Training loss: 1.027556190717762
Validation loss: 2.3071713591319827

Epoch: 5| Step: 8
Training loss: 1.3423906592199826
Validation loss: 2.3535225495512426

Epoch: 5| Step: 9
Training loss: 1.0945650606018167
Validation loss: 2.413475382310681

Epoch: 5| Step: 10
Training loss: 0.8418367026835656
Validation loss: 2.341523364251229

Epoch: 448| Step: 0
Training loss: 0.9019873439531071
Validation loss: 2.358962240978347

Epoch: 5| Step: 1
Training loss: 0.8140117446394243
Validation loss: 2.2765458383201795

Epoch: 5| Step: 2
Training loss: 1.041747961051013
Validation loss: 2.4055890999014093

Epoch: 5| Step: 3
Training loss: 1.2313931338382909
Validation loss: 2.3783685664661025

Epoch: 5| Step: 4
Training loss: 1.0260840405591056
Validation loss: 2.3390309977278956

Epoch: 5| Step: 5
Training loss: 1.181997702375267
Validation loss: 2.370803488987552

Epoch: 5| Step: 6
Training loss: 0.9725224046651488
Validation loss: 2.3143796922367095

Epoch: 5| Step: 7
Training loss: 0.8051374344169824
Validation loss: 2.3576676133696157

Epoch: 5| Step: 8
Training loss: 0.9393814916126264
Validation loss: 2.3658883513772966

Epoch: 5| Step: 9
Training loss: 1.7624576482351313
Validation loss: 2.392485604789958

Epoch: 5| Step: 10
Training loss: 0.7229167984037985
Validation loss: 2.3943501343939233

Epoch: 449| Step: 0
Training loss: 1.0800433023919962
Validation loss: 2.4156758668067044

Epoch: 5| Step: 1
Training loss: 1.0402204901541772
Validation loss: 2.3031372137109423

Epoch: 5| Step: 2
Training loss: 0.8281636498986712
Validation loss: 2.3260196119252003

Epoch: 5| Step: 3
Training loss: 0.8496903304192841
Validation loss: 2.30803057388512

Epoch: 5| Step: 4
Training loss: 1.1825510600318785
Validation loss: 2.2787536153074512

Epoch: 5| Step: 5
Training loss: 1.082572443610578
Validation loss: 2.287181242048575

Epoch: 5| Step: 6
Training loss: 0.8153705506952659
Validation loss: 2.294852117081741

Epoch: 5| Step: 7
Training loss: 1.5723535738212313
Validation loss: 2.297180667751716

Epoch: 5| Step: 8
Training loss: 0.8907903551226181
Validation loss: 2.3551811285229634

Epoch: 5| Step: 9
Training loss: 0.9851431498613229
Validation loss: 2.3414422840734623

Epoch: 5| Step: 10
Training loss: 0.9044755466670936
Validation loss: 2.370133829730411

Epoch: 450| Step: 0
Training loss: 0.906997799646722
Validation loss: 2.3386458567304893

Epoch: 5| Step: 1
Training loss: 1.0125289677373197
Validation loss: 2.3136113402847434

Epoch: 5| Step: 2
Training loss: 0.8132842020792889
Validation loss: 2.3479368575751027

Epoch: 5| Step: 3
Training loss: 0.8747807636809497
Validation loss: 2.3438134833594777

Epoch: 5| Step: 4
Training loss: 1.035454876128826
Validation loss: 2.291682083510582

Epoch: 5| Step: 5
Training loss: 0.9397075411680004
Validation loss: 2.3433262475436005

Epoch: 5| Step: 6
Training loss: 1.6316212228064835
Validation loss: 2.3469885357264886

Epoch: 5| Step: 7
Training loss: 0.8047276459095876
Validation loss: 2.4087813845577966

Epoch: 5| Step: 8
Training loss: 0.9345119541805812
Validation loss: 2.3262345888893887

Epoch: 5| Step: 9
Training loss: 0.8503435492463282
Validation loss: 2.4092992685435637

Epoch: 5| Step: 10
Training loss: 1.2931754416671035
Validation loss: 2.348037571641188

Epoch: 451| Step: 0
Training loss: 0.8370225228500364
Validation loss: 2.3346734644554026

Epoch: 5| Step: 1
Training loss: 0.8254296686675158
Validation loss: 2.3181523971388036

Epoch: 5| Step: 2
Training loss: 0.9085160895472782
Validation loss: 2.3173187831813316

Epoch: 5| Step: 3
Training loss: 1.0065838917327687
Validation loss: 2.466451629815019

Epoch: 5| Step: 4
Training loss: 0.8948389715110745
Validation loss: 2.4333058693948995

Epoch: 5| Step: 5
Training loss: 0.944710531960334
Validation loss: 2.3262610606733616

Epoch: 5| Step: 6
Training loss: 0.7647639512544414
Validation loss: 2.3034493895942107

Epoch: 5| Step: 7
Training loss: 1.4367817452638934
Validation loss: 2.2781626084847786

Epoch: 5| Step: 8
Training loss: 1.1827470123827382
Validation loss: 2.386066064827174

Epoch: 5| Step: 9
Training loss: 1.0783978545408104
Validation loss: 2.346246338545109

Epoch: 5| Step: 10
Training loss: 1.1699413877461613
Validation loss: 2.299895388331702

Epoch: 452| Step: 0
Training loss: 1.27992813027793
Validation loss: 2.3260261163003055

Epoch: 5| Step: 1
Training loss: 0.8733164394603491
Validation loss: 2.2629527852516946

Epoch: 5| Step: 2
Training loss: 1.580290715235467
Validation loss: 2.2733708938433996

Epoch: 5| Step: 3
Training loss: 0.8279641553035365
Validation loss: 2.2746650390612446

Epoch: 5| Step: 4
Training loss: 0.5405492597235971
Validation loss: 2.301755593858847

Epoch: 5| Step: 5
Training loss: 1.0445998791993474
Validation loss: 2.28748785463199

Epoch: 5| Step: 6
Training loss: 0.5571671254641765
Validation loss: 2.374494518789873

Epoch: 5| Step: 7
Training loss: 0.910425923880179
Validation loss: 2.256058311347101

Epoch: 5| Step: 8
Training loss: 1.2246437858845334
Validation loss: 2.3808949609430727

Epoch: 5| Step: 9
Training loss: 1.4208381141887936
Validation loss: 2.353008784463494

Epoch: 5| Step: 10
Training loss: 0.8977193864974236
Validation loss: 2.2722364446508796

Epoch: 453| Step: 0
Training loss: 0.9822374174497127
Validation loss: 2.333437975684649

Epoch: 5| Step: 1
Training loss: 0.9465954484365502
Validation loss: 2.316648475488203

Epoch: 5| Step: 2
Training loss: 0.9391201959997653
Validation loss: 2.3293637398386497

Epoch: 5| Step: 3
Training loss: 1.0321041962156767
Validation loss: 2.422864522182307

Epoch: 5| Step: 4
Training loss: 0.7439152734309763
Validation loss: 2.406544367312299

Epoch: 5| Step: 5
Training loss: 1.6048389693909422
Validation loss: 2.334829226328318

Epoch: 5| Step: 6
Training loss: 1.4041182572861646
Validation loss: 2.38948426928047

Epoch: 5| Step: 7
Training loss: 0.8807096840485543
Validation loss: 2.3331942743916625

Epoch: 5| Step: 8
Training loss: 0.8799595942215847
Validation loss: 2.3354425605943376

Epoch: 5| Step: 9
Training loss: 1.001855202215702
Validation loss: 2.3754073507710647

Epoch: 5| Step: 10
Training loss: 1.015396033666895
Validation loss: 2.3218429863765566

Epoch: 454| Step: 0
Training loss: 0.8950685112053905
Validation loss: 2.415612834518842

Epoch: 5| Step: 1
Training loss: 1.5389726486700446
Validation loss: 2.352357433964504

Epoch: 5| Step: 2
Training loss: 1.0891840315536074
Validation loss: 2.3142006188004833

Epoch: 5| Step: 3
Training loss: 0.9290771404181652
Validation loss: 2.356338535478907

Epoch: 5| Step: 4
Training loss: 1.108224298855099
Validation loss: 2.312206853363455

Epoch: 5| Step: 5
Training loss: 1.0089543106615395
Validation loss: 2.3551126786891823

Epoch: 5| Step: 6
Training loss: 0.8097933656363743
Validation loss: 2.425280906265904

Epoch: 5| Step: 7
Training loss: 0.8543265394686606
Validation loss: 2.3004106692227633

Epoch: 5| Step: 8
Training loss: 1.0557492598491065
Validation loss: 2.2927183223531604

Epoch: 5| Step: 9
Training loss: 0.7121667818920001
Validation loss: 2.439893654202507

Epoch: 5| Step: 10
Training loss: 1.2372203819258552
Validation loss: 2.415169446924873

Epoch: 455| Step: 0
Training loss: 1.1733747422342087
Validation loss: 2.3327446006589074

Epoch: 5| Step: 1
Training loss: 1.4531294299642656
Validation loss: 2.2830000954946525

Epoch: 5| Step: 2
Training loss: 0.9611335802453085
Validation loss: 2.2981032848085476

Epoch: 5| Step: 3
Training loss: 0.9864086760308766
Validation loss: 2.427346399922735

Epoch: 5| Step: 4
Training loss: 1.1875308183385322
Validation loss: 2.312215584135117

Epoch: 5| Step: 5
Training loss: 0.9238058656103676
Validation loss: 2.295598215225224

Epoch: 5| Step: 6
Training loss: 0.6479825641529234
Validation loss: 2.328692744483993

Epoch: 5| Step: 7
Training loss: 0.8897900599491443
Validation loss: 2.3462725643329243

Epoch: 5| Step: 8
Training loss: 0.6927208122525254
Validation loss: 2.387197780857378

Epoch: 5| Step: 9
Training loss: 0.8154885276534772
Validation loss: 2.3728443351847304

Epoch: 5| Step: 10
Training loss: 0.9904564301903634
Validation loss: 2.3518820052849363

Epoch: 456| Step: 0
Training loss: 0.98702660935582
Validation loss: 2.4111843626357783

Epoch: 5| Step: 1
Training loss: 1.0734027329413114
Validation loss: 2.3845193366925552

Epoch: 5| Step: 2
Training loss: 1.7386452968728305
Validation loss: 2.4663044707099613

Epoch: 5| Step: 3
Training loss: 0.8144051883046975
Validation loss: 2.3495344615924205

Epoch: 5| Step: 4
Training loss: 0.8410472319989494
Validation loss: 2.4468181636981083

Epoch: 5| Step: 5
Training loss: 1.020034256715154
Validation loss: 2.3722168072658736

Epoch: 5| Step: 6
Training loss: 0.845459759871865
Validation loss: 2.3338722787324655

Epoch: 5| Step: 7
Training loss: 0.7473664937036913
Validation loss: 2.25074087100467

Epoch: 5| Step: 8
Training loss: 0.9475934277472828
Validation loss: 2.327079430801595

Epoch: 5| Step: 9
Training loss: 0.9235170255908071
Validation loss: 2.411025842770909

Epoch: 5| Step: 10
Training loss: 1.170515467075912
Validation loss: 2.404749120551908

Epoch: 457| Step: 0
Training loss: 0.6209582534877358
Validation loss: 2.369371947710479

Epoch: 5| Step: 1
Training loss: 0.9550521004530449
Validation loss: 2.3017420948515253

Epoch: 5| Step: 2
Training loss: 0.8156759107346767
Validation loss: 2.3462278540071653

Epoch: 5| Step: 3
Training loss: 0.7210233643670612
Validation loss: 2.335456321456997

Epoch: 5| Step: 4
Training loss: 0.9037352232826423
Validation loss: 2.397471201831484

Epoch: 5| Step: 5
Training loss: 1.2152016655233093
Validation loss: 2.3651124771356273

Epoch: 5| Step: 6
Training loss: 1.391122236186187
Validation loss: 2.363278165967965

Epoch: 5| Step: 7
Training loss: 0.8374045858547791
Validation loss: 2.311153005151769

Epoch: 5| Step: 8
Training loss: 0.8520070586695665
Validation loss: 2.258928877594699

Epoch: 5| Step: 9
Training loss: 0.7126923585863438
Validation loss: 2.4170646304447145

Epoch: 5| Step: 10
Training loss: 1.6457593957573977
Validation loss: 2.3277936926665688

Epoch: 458| Step: 0
Training loss: 0.9005811907498997
Validation loss: 2.245514651169847

Epoch: 5| Step: 1
Training loss: 0.8503202424122731
Validation loss: 2.339277995696185

Epoch: 5| Step: 2
Training loss: 0.9106516329000066
Validation loss: 2.326869740995616

Epoch: 5| Step: 3
Training loss: 0.9450265120768503
Validation loss: 2.329848271731754

Epoch: 5| Step: 4
Training loss: 0.7064188417807186
Validation loss: 2.2652975918666196

Epoch: 5| Step: 5
Training loss: 0.9688203847603776
Validation loss: 2.317871052273783

Epoch: 5| Step: 6
Training loss: 0.6561153137413565
Validation loss: 2.383067567683617

Epoch: 5| Step: 7
Training loss: 1.3187207892197457
Validation loss: 2.2859330386903864

Epoch: 5| Step: 8
Training loss: 1.6483621444472771
Validation loss: 2.367266990138954

Epoch: 5| Step: 9
Training loss: 0.9062940981428952
Validation loss: 2.3866096983087632

Epoch: 5| Step: 10
Training loss: 0.96812877425264
Validation loss: 2.3931993332244774

Epoch: 459| Step: 0
Training loss: 1.016891159745143
Validation loss: 2.416232749744508

Epoch: 5| Step: 1
Training loss: 1.7051410466805106
Validation loss: 2.3123289370380515

Epoch: 5| Step: 2
Training loss: 0.8082540415843631
Validation loss: 2.291129307844092

Epoch: 5| Step: 3
Training loss: 0.8883247452070865
Validation loss: 2.4116587042106423

Epoch: 5| Step: 4
Training loss: 1.1613708714054682
Validation loss: 2.336584583430745

Epoch: 5| Step: 5
Training loss: 0.8435589256100666
Validation loss: 2.355428407831359

Epoch: 5| Step: 6
Training loss: 0.878070315087096
Validation loss: 2.3018770256765393

Epoch: 5| Step: 7
Training loss: 0.7911665784180697
Validation loss: 2.3146437840965004

Epoch: 5| Step: 8
Training loss: 1.084049862094911
Validation loss: 2.314019637043822

Epoch: 5| Step: 9
Training loss: 0.9169615069082055
Validation loss: 2.341576931313917

Epoch: 5| Step: 10
Training loss: 0.8056972797366342
Validation loss: 2.328841158243272

Epoch: 460| Step: 0
Training loss: 0.6159187990675641
Validation loss: 2.3203649210077786

Epoch: 5| Step: 1
Training loss: 0.755807091139279
Validation loss: 2.3360031546170923

Epoch: 5| Step: 2
Training loss: 1.0653951134041328
Validation loss: 2.3486138260729947

Epoch: 5| Step: 3
Training loss: 0.9016823594730845
Validation loss: 2.3143848347327602

Epoch: 5| Step: 4
Training loss: 0.9404438211838693
Validation loss: 2.3220708631470863

Epoch: 5| Step: 5
Training loss: 1.2647921329590217
Validation loss: 2.312300714776331

Epoch: 5| Step: 6
Training loss: 0.9608205708640124
Validation loss: 2.3466487304144437

Epoch: 5| Step: 7
Training loss: 1.4871318714232877
Validation loss: 2.350177138099031

Epoch: 5| Step: 8
Training loss: 0.8331550924099158
Validation loss: 2.3134144729527395

Epoch: 5| Step: 9
Training loss: 0.9390229253316454
Validation loss: 2.265654906350257

Epoch: 5| Step: 10
Training loss: 1.1985925288188564
Validation loss: 2.4235430903014277

Epoch: 461| Step: 0
Training loss: 0.7852922008728012
Validation loss: 2.260289420881658

Epoch: 5| Step: 1
Training loss: 1.1947592159122538
Validation loss: 2.3943885059819316

Epoch: 5| Step: 2
Training loss: 0.8038644377545875
Validation loss: 2.3741712964826087

Epoch: 5| Step: 3
Training loss: 0.9512219112324537
Validation loss: 2.2744293670991085

Epoch: 5| Step: 4
Training loss: 0.6593634681235624
Validation loss: 2.203244997513829

Epoch: 5| Step: 5
Training loss: 0.8041333262461516
Validation loss: 2.3045315480639665

Epoch: 5| Step: 6
Training loss: 1.4689926596315972
Validation loss: 2.444048364525303

Epoch: 5| Step: 7
Training loss: 0.6314849350235502
Validation loss: 2.333936500890704

Epoch: 5| Step: 8
Training loss: 1.3191668714827192
Validation loss: 2.399670176334456

Epoch: 5| Step: 9
Training loss: 1.2718665607744146
Validation loss: 2.3882939765350084

Epoch: 5| Step: 10
Training loss: 1.2136299472291132
Validation loss: 2.38934984809205

Epoch: 462| Step: 0
Training loss: 0.8457086576144266
Validation loss: 2.357832757916121

Epoch: 5| Step: 1
Training loss: 0.8127809918965065
Validation loss: 2.3429654083136757

Epoch: 5| Step: 2
Training loss: 1.4510570290713702
Validation loss: 2.2459356231456287

Epoch: 5| Step: 3
Training loss: 1.037955590836127
Validation loss: 2.3879524963980785

Epoch: 5| Step: 4
Training loss: 0.9732358806359058
Validation loss: 2.3282247333261363

Epoch: 5| Step: 5
Training loss: 0.9865498208653111
Validation loss: 2.318879479214878

Epoch: 5| Step: 6
Training loss: 0.740340494485658
Validation loss: 2.351606211693636

Epoch: 5| Step: 7
Training loss: 0.37407255721693944
Validation loss: 2.3338066212905777

Epoch: 5| Step: 8
Training loss: 1.2811337860249812
Validation loss: 2.36200818660643

Epoch: 5| Step: 9
Training loss: 0.7914116139055987
Validation loss: 2.3835009745762843

Epoch: 5| Step: 10
Training loss: 1.0857178170820758
Validation loss: 2.3244599694654613

Epoch: 463| Step: 0
Training loss: 0.7929071862887991
Validation loss: 2.346459319261087

Epoch: 5| Step: 1
Training loss: 0.7570947610611616
Validation loss: 2.2782824239103414

Epoch: 5| Step: 2
Training loss: 1.4643454556124393
Validation loss: 2.352937491995842

Epoch: 5| Step: 3
Training loss: 0.8732153540071755
Validation loss: 2.212114664918139

Epoch: 5| Step: 4
Training loss: 0.6617374106774369
Validation loss: 2.2870554900455806

Epoch: 5| Step: 5
Training loss: 0.642098824905998
Validation loss: 2.314737160718954

Epoch: 5| Step: 6
Training loss: 0.5727531257487489
Validation loss: 2.3208062486406016

Epoch: 5| Step: 7
Training loss: 1.1991283867306115
Validation loss: 2.373777100594113

Epoch: 5| Step: 8
Training loss: 1.0939606055083124
Validation loss: 2.2824905310741026

Epoch: 5| Step: 9
Training loss: 1.0068074027161007
Validation loss: 2.3160684939697105

Epoch: 5| Step: 10
Training loss: 1.2215264801390546
Validation loss: 2.336359455452505

Epoch: 464| Step: 0
Training loss: 1.1039600658865083
Validation loss: 2.355696021772024

Epoch: 5| Step: 1
Training loss: 1.4852929740150416
Validation loss: 2.3111289077339934

Epoch: 5| Step: 2
Training loss: 0.9509503617734726
Validation loss: 2.357478587299168

Epoch: 5| Step: 3
Training loss: 1.3329912680692628
Validation loss: 2.316203709211793

Epoch: 5| Step: 4
Training loss: 0.8812955127623904
Validation loss: 2.4002782485176835

Epoch: 5| Step: 5
Training loss: 0.9564060582492775
Validation loss: 2.361605443927798

Epoch: 5| Step: 6
Training loss: 1.0151202194539093
Validation loss: 2.3466116244166506

Epoch: 5| Step: 7
Training loss: 0.9546878071736092
Validation loss: 2.2839908090096928

Epoch: 5| Step: 8
Training loss: 0.714895152760928
Validation loss: 2.296549230045465

Epoch: 5| Step: 9
Training loss: 0.9157425528308628
Validation loss: 2.2876878621924717

Epoch: 5| Step: 10
Training loss: 0.8342471635591359
Validation loss: 2.3427533727702072

Epoch: 465| Step: 0
Training loss: 1.1283526267557946
Validation loss: 2.33708980831191

Epoch: 5| Step: 1
Training loss: 0.9129364707315769
Validation loss: 2.3562823332135445

Epoch: 5| Step: 2
Training loss: 0.9285876074890603
Validation loss: 2.3617974042338465

Epoch: 5| Step: 3
Training loss: 0.8925679412861853
Validation loss: 2.3863419484956747

Epoch: 5| Step: 4
Training loss: 1.4966124589076468
Validation loss: 2.377300406715821

Epoch: 5| Step: 5
Training loss: 0.8400136376590841
Validation loss: 2.3812172420617994

Epoch: 5| Step: 6
Training loss: 0.7344592431629912
Validation loss: 2.2586390904007145

Epoch: 5| Step: 7
Training loss: 1.2732610287700805
Validation loss: 2.2937631092164668

Epoch: 5| Step: 8
Training loss: 0.8237363298407739
Validation loss: 2.364894931159595

Epoch: 5| Step: 9
Training loss: 1.0721695653693482
Validation loss: 2.2958517880920106

Epoch: 5| Step: 10
Training loss: 0.7359616609725732
Validation loss: 2.2725128479969183

Epoch: 466| Step: 0
Training loss: 1.0168842432015825
Validation loss: 2.4764871039442458

Epoch: 5| Step: 1
Training loss: 0.7927356997631398
Validation loss: 2.3005772895843686

Epoch: 5| Step: 2
Training loss: 1.3553596914430046
Validation loss: 2.310610606010557

Epoch: 5| Step: 3
Training loss: 0.7508819480791716
Validation loss: 2.332037779931387

Epoch: 5| Step: 4
Training loss: 0.7912370913327909
Validation loss: 2.322964046492997

Epoch: 5| Step: 5
Training loss: 0.9267600313728871
Validation loss: 2.3856823269007976

Epoch: 5| Step: 6
Training loss: 0.7317940831591833
Validation loss: 2.3107057548910532

Epoch: 5| Step: 7
Training loss: 1.0514736234337871
Validation loss: 2.19978188135414

Epoch: 5| Step: 8
Training loss: 1.526734213410585
Validation loss: 2.3045921176634243

Epoch: 5| Step: 9
Training loss: 0.9910202369086433
Validation loss: 2.3919182917909914

Epoch: 5| Step: 10
Training loss: 0.7606074908082009
Validation loss: 2.3968666241763343

Epoch: 467| Step: 0
Training loss: 1.072082281506276
Validation loss: 2.3972761816426877

Epoch: 5| Step: 1
Training loss: 0.7433481477179235
Validation loss: 2.418771243926208

Epoch: 5| Step: 2
Training loss: 1.4133240684319566
Validation loss: 2.3813648707660344

Epoch: 5| Step: 3
Training loss: 0.6149701474473034
Validation loss: 2.3995577522230236

Epoch: 5| Step: 4
Training loss: 1.051163274247144
Validation loss: 2.3653667255047206

Epoch: 5| Step: 5
Training loss: 0.8468763217704565
Validation loss: 2.390380265622035

Epoch: 5| Step: 6
Training loss: 0.7464166711339695
Validation loss: 2.3679658469833282

Epoch: 5| Step: 7
Training loss: 0.7384301494631289
Validation loss: 2.4023924068896187

Epoch: 5| Step: 8
Training loss: 1.5575319272805586
Validation loss: 2.3598956906901236

Epoch: 5| Step: 9
Training loss: 0.9724719627477099
Validation loss: 2.3456281611569185

Epoch: 5| Step: 10
Training loss: 1.0469913133371986
Validation loss: 2.2501947883777746

Epoch: 468| Step: 0
Training loss: 0.9648401978462098
Validation loss: 2.297180651011801

Epoch: 5| Step: 1
Training loss: 0.7766897239318623
Validation loss: 2.3536407811865554

Epoch: 5| Step: 2
Training loss: 0.8895994941321486
Validation loss: 2.2908743986933495

Epoch: 5| Step: 3
Training loss: 0.6616179181124779
Validation loss: 2.324197856657158

Epoch: 5| Step: 4
Training loss: 1.00106730724342
Validation loss: 2.3511727714342983

Epoch: 5| Step: 5
Training loss: 1.1654355956308682
Validation loss: 2.276242355142198

Epoch: 5| Step: 6
Training loss: 1.624704260691047
Validation loss: 2.3708177485529482

Epoch: 5| Step: 7
Training loss: 1.1783477552377586
Validation loss: 2.3202200781030435

Epoch: 5| Step: 8
Training loss: 0.8525985225117048
Validation loss: 2.354609743312637

Epoch: 5| Step: 9
Training loss: 0.9823046513842351
Validation loss: 2.3314770956193285

Epoch: 5| Step: 10
Training loss: 1.043480279758995
Validation loss: 2.411913614548381

Epoch: 469| Step: 0
Training loss: 1.0885961357737746
Validation loss: 2.395162881471076

Epoch: 5| Step: 1
Training loss: 0.6678052557131499
Validation loss: 2.390983024445538

Epoch: 5| Step: 2
Training loss: 1.1635297541860898
Validation loss: 2.3815480029917078

Epoch: 5| Step: 3
Training loss: 0.9023287883360362
Validation loss: 2.306418684263903

Epoch: 5| Step: 4
Training loss: 0.8086175224016251
Validation loss: 2.3961719794358247

Epoch: 5| Step: 5
Training loss: 1.5781212230674946
Validation loss: 2.3463692613341744

Epoch: 5| Step: 6
Training loss: 0.7931530367177201
Validation loss: 2.351578392678547

Epoch: 5| Step: 7
Training loss: 0.6213168817052317
Validation loss: 2.3732392185586453

Epoch: 5| Step: 8
Training loss: 0.7648728237529479
Validation loss: 2.318029781853241

Epoch: 5| Step: 9
Training loss: 0.8845180139728877
Validation loss: 2.3257748142069765

Epoch: 5| Step: 10
Training loss: 1.2544152008290006
Validation loss: 2.3271547795359395

Epoch: 470| Step: 0
Training loss: 1.6755726646665123
Validation loss: 2.2630273781184553

Epoch: 5| Step: 1
Training loss: 1.2026375612975377
Validation loss: 2.3302590125190816

Epoch: 5| Step: 2
Training loss: 0.8828136815426102
Validation loss: 2.3412609958768784

Epoch: 5| Step: 3
Training loss: 0.7039837149990664
Validation loss: 2.3619832198270845

Epoch: 5| Step: 4
Training loss: 0.8589202718160979
Validation loss: 2.3553155645063613

Epoch: 5| Step: 5
Training loss: 0.8389507070049033
Validation loss: 2.3475901863462054

Epoch: 5| Step: 6
Training loss: 0.9237763468968835
Validation loss: 2.3212708093931917

Epoch: 5| Step: 7
Training loss: 0.7135035140332606
Validation loss: 2.370325647175264

Epoch: 5| Step: 8
Training loss: 1.1609689454123715
Validation loss: 2.3165318130753625

Epoch: 5| Step: 9
Training loss: 0.9267947608649026
Validation loss: 2.2994220477419463

Epoch: 5| Step: 10
Training loss: 0.8141767366763324
Validation loss: 2.3321342113676318

Epoch: 471| Step: 0
Training loss: 0.9971296122792072
Validation loss: 2.3520048749680442

Epoch: 5| Step: 1
Training loss: 0.91660262375418
Validation loss: 2.4463639745306716

Epoch: 5| Step: 2
Training loss: 0.7893285774842675
Validation loss: 2.434061341046523

Epoch: 5| Step: 3
Training loss: 0.7122686730022848
Validation loss: 2.342476391686629

Epoch: 5| Step: 4
Training loss: 0.8263195437944851
Validation loss: 2.414227542239303

Epoch: 5| Step: 5
Training loss: 0.92396763721987
Validation loss: 2.3469143852294754

Epoch: 5| Step: 6
Training loss: 1.5458028140829785
Validation loss: 2.2460264716431606

Epoch: 5| Step: 7
Training loss: 1.4100290172377712
Validation loss: 2.375562566407567

Epoch: 5| Step: 8
Training loss: 0.6141857838814866
Validation loss: 2.4101123354745915

Epoch: 5| Step: 9
Training loss: 0.8934823095473463
Validation loss: 2.336404537865955

Epoch: 5| Step: 10
Training loss: 0.9758421720815178
Validation loss: 2.4048916179152497

Epoch: 472| Step: 0
Training loss: 1.0229672815007311
Validation loss: 2.2944656128667353

Epoch: 5| Step: 1
Training loss: 0.7523026483861593
Validation loss: 2.2930246280550945

Epoch: 5| Step: 2
Training loss: 0.9242407621211434
Validation loss: 2.3569070357322404

Epoch: 5| Step: 3
Training loss: 0.6496038403392832
Validation loss: 2.326395255381967

Epoch: 5| Step: 4
Training loss: 1.0755303715736284
Validation loss: 2.337646971710316

Epoch: 5| Step: 5
Training loss: 0.9530350376885318
Validation loss: 2.267784877515167

Epoch: 5| Step: 6
Training loss: 1.7031175805726437
Validation loss: 2.3780561848905806

Epoch: 5| Step: 7
Training loss: 0.8958784062483276
Validation loss: 2.3418269000298007

Epoch: 5| Step: 8
Training loss: 0.9237203394008497
Validation loss: 2.346705130625895

Epoch: 5| Step: 9
Training loss: 0.8836812496286667
Validation loss: 2.365901990419751

Epoch: 5| Step: 10
Training loss: 0.6643651609149763
Validation loss: 2.306043579857559

Epoch: 473| Step: 0
Training loss: 0.6289917787005503
Validation loss: 2.381496125677046

Epoch: 5| Step: 1
Training loss: 0.7369582416992108
Validation loss: 2.3187140021042243

Epoch: 5| Step: 2
Training loss: 0.9040837211768626
Validation loss: 2.322988060041229

Epoch: 5| Step: 3
Training loss: 0.7568314090716338
Validation loss: 2.275412539977288

Epoch: 5| Step: 4
Training loss: 1.6378081344840365
Validation loss: 2.269415418000762

Epoch: 5| Step: 5
Training loss: 0.91257028962194
Validation loss: 2.3939424826198996

Epoch: 5| Step: 6
Training loss: 1.164065008992813
Validation loss: 2.269545657879386

Epoch: 5| Step: 7
Training loss: 0.8682873598645423
Validation loss: 2.3821843123954447

Epoch: 5| Step: 8
Training loss: 1.0429104563677654
Validation loss: 2.337809922718567

Epoch: 5| Step: 9
Training loss: 0.9438100492560411
Validation loss: 2.2842490519379166

Epoch: 5| Step: 10
Training loss: 0.8504362445417489
Validation loss: 2.394537421063995

Epoch: 474| Step: 0
Training loss: 0.9993944718955184
Validation loss: 2.318180968396484

Epoch: 5| Step: 1
Training loss: 1.1025178702845932
Validation loss: 2.342930316402267

Epoch: 5| Step: 2
Training loss: 0.8207329172267462
Validation loss: 2.3650265939054975

Epoch: 5| Step: 3
Training loss: 1.0806730263464253
Validation loss: 2.3667170072158803

Epoch: 5| Step: 4
Training loss: 0.559244430476743
Validation loss: 2.3162718091641388

Epoch: 5| Step: 5
Training loss: 0.882226192262313
Validation loss: 2.2614189514723573

Epoch: 5| Step: 6
Training loss: 1.0322241372591543
Validation loss: 2.315435160930081

Epoch: 5| Step: 7
Training loss: 0.8643359822412757
Validation loss: 2.3888908196473513

Epoch: 5| Step: 8
Training loss: 0.8896868935071448
Validation loss: 2.392715210560774

Epoch: 5| Step: 9
Training loss: 1.5243399270289963
Validation loss: 2.401692484528677

Epoch: 5| Step: 10
Training loss: 0.6381386914031412
Validation loss: 2.257229063915519

Epoch: 475| Step: 0
Training loss: 0.9171487595338953
Validation loss: 2.401336741122971

Epoch: 5| Step: 1
Training loss: 0.9465332660965288
Validation loss: 2.3887201320981672

Epoch: 5| Step: 2
Training loss: 1.0486901901158778
Validation loss: 2.3532160274218055

Epoch: 5| Step: 3
Training loss: 0.6735705560643301
Validation loss: 2.3369602849656235

Epoch: 5| Step: 4
Training loss: 0.750441818437107
Validation loss: 2.33044908144191

Epoch: 5| Step: 5
Training loss: 0.6834980488953721
Validation loss: 2.3190679128081837

Epoch: 5| Step: 6
Training loss: 0.8459400083112222
Validation loss: 2.372981564674557

Epoch: 5| Step: 7
Training loss: 0.8099253282154171
Validation loss: 2.318607822671159

Epoch: 5| Step: 8
Training loss: 0.8133466417625654
Validation loss: 2.373296289584644

Epoch: 5| Step: 9
Training loss: 0.8086775952788148
Validation loss: 2.3880384772885903

Epoch: 5| Step: 10
Training loss: 1.8085601342127722
Validation loss: 2.378394232715007

Epoch: 476| Step: 0
Training loss: 0.8362330333203076
Validation loss: 2.348199978194228

Epoch: 5| Step: 1
Training loss: 0.8501332038401661
Validation loss: 2.3952594831349576

Epoch: 5| Step: 2
Training loss: 1.1881533883128226
Validation loss: 2.304092739274952

Epoch: 5| Step: 3
Training loss: 1.0641896332961194
Validation loss: 2.2235321482290216

Epoch: 5| Step: 4
Training loss: 1.1949732180511143
Validation loss: 2.2807049990165056

Epoch: 5| Step: 5
Training loss: 0.9615779076334535
Validation loss: 2.3356371832047187

Epoch: 5| Step: 6
Training loss: 0.909954850994649
Validation loss: 2.3246213386948993

Epoch: 5| Step: 7
Training loss: 1.0713710701362655
Validation loss: 2.3671745582328865

Epoch: 5| Step: 8
Training loss: 0.8317630675894271
Validation loss: 2.348965636207603

Epoch: 5| Step: 9
Training loss: 1.560174508482216
Validation loss: 2.2599684356534695

Epoch: 5| Step: 10
Training loss: 0.4943727845047066
Validation loss: 2.3379310395179353

Epoch: 477| Step: 0
Training loss: 0.9601157481727782
Validation loss: 2.3268052185672032

Epoch: 5| Step: 1
Training loss: 0.8686248277462821
Validation loss: 2.3142091520655974

Epoch: 5| Step: 2
Training loss: 0.926169205512516
Validation loss: 2.3427822354621406

Epoch: 5| Step: 3
Training loss: 1.1012637768164037
Validation loss: 2.3071354961067847

Epoch: 5| Step: 4
Training loss: 0.9749916565366916
Validation loss: 2.26531457666167

Epoch: 5| Step: 5
Training loss: 0.8792632331665798
Validation loss: 2.333860801006322

Epoch: 5| Step: 6
Training loss: 0.9331225558821907
Validation loss: 2.2528109259565037

Epoch: 5| Step: 7
Training loss: 0.8321341151018611
Validation loss: 2.315457737100824

Epoch: 5| Step: 8
Training loss: 1.0795415887352753
Validation loss: 2.2420020240943312

Epoch: 5| Step: 9
Training loss: 1.5922375402551525
Validation loss: 2.372129455317336

Epoch: 5| Step: 10
Training loss: 1.04175082184677
Validation loss: 2.344240376024871

Epoch: 478| Step: 0
Training loss: 0.8123848173220652
Validation loss: 2.310321107842582

Epoch: 5| Step: 1
Training loss: 0.9618233420100344
Validation loss: 2.352950041387484

Epoch: 5| Step: 2
Training loss: 1.3207300191880984
Validation loss: 2.323693632810999

Epoch: 5| Step: 3
Training loss: 0.6066042189718319
Validation loss: 2.3718328261193813

Epoch: 5| Step: 4
Training loss: 0.7000990499513716
Validation loss: 2.3661183072349457

Epoch: 5| Step: 5
Training loss: 1.1610913858811858
Validation loss: 2.367496272830234

Epoch: 5| Step: 6
Training loss: 0.9821273938732824
Validation loss: 2.3506518613389904

Epoch: 5| Step: 7
Training loss: 0.8183389811375946
Validation loss: 2.2829955802039135

Epoch: 5| Step: 8
Training loss: 0.8236933475399417
Validation loss: 2.298309702920368

Epoch: 5| Step: 9
Training loss: 1.384821536895194
Validation loss: 2.285336240809564

Epoch: 5| Step: 10
Training loss: 1.1460983952361181
Validation loss: 2.2838486701209875

Epoch: 479| Step: 0
Training loss: 0.8516021859256969
Validation loss: 2.3502496999937645

Epoch: 5| Step: 1
Training loss: 1.0253938802031664
Validation loss: 2.364979302653668

Epoch: 5| Step: 2
Training loss: 0.7203702080173559
Validation loss: 2.294099721719598

Epoch: 5| Step: 3
Training loss: 1.4905509562466237
Validation loss: 2.280823842384076

Epoch: 5| Step: 4
Training loss: 0.789209257773784
Validation loss: 2.3413125142531044

Epoch: 5| Step: 5
Training loss: 0.7493551183867724
Validation loss: 2.2448645719487454

Epoch: 5| Step: 6
Training loss: 1.0433356964726441
Validation loss: 2.3069678575444774

Epoch: 5| Step: 7
Training loss: 1.0218560616607746
Validation loss: 2.3240156027535024

Epoch: 5| Step: 8
Training loss: 1.1575622329295554
Validation loss: 2.3286271732960193

Epoch: 5| Step: 9
Training loss: 0.7641174499473202
Validation loss: 2.3009367436088586

Epoch: 5| Step: 10
Training loss: 1.0322150714274354
Validation loss: 2.3812823222048314

Epoch: 480| Step: 0
Training loss: 0.9696118919899908
Validation loss: 2.321914035067809

Epoch: 5| Step: 1
Training loss: 0.7431371937129135
Validation loss: 2.2734270771118794

Epoch: 5| Step: 2
Training loss: 0.718522326027649
Validation loss: 2.327764377054032

Epoch: 5| Step: 3
Training loss: 0.7865115941351694
Validation loss: 2.333149078853976

Epoch: 5| Step: 4
Training loss: 0.8643100183958734
Validation loss: 2.315379591754933

Epoch: 5| Step: 5
Training loss: 0.8527555944482349
Validation loss: 2.2951220169015247

Epoch: 5| Step: 6
Training loss: 1.2706994418710311
Validation loss: 2.397344621022478

Epoch: 5| Step: 7
Training loss: 0.8779231019245144
Validation loss: 2.3567938106932638

Epoch: 5| Step: 8
Training loss: 0.7850559227455846
Validation loss: 2.3214158302461416

Epoch: 5| Step: 9
Training loss: 0.9004306742931789
Validation loss: 2.3076552626760374

Epoch: 5| Step: 10
Training loss: 1.6138203530669908
Validation loss: 2.2955070586993997

Epoch: 481| Step: 0
Training loss: 0.6465728099991077
Validation loss: 2.225917996481644

Epoch: 5| Step: 1
Training loss: 1.5428278218869016
Validation loss: 2.340151962334418

Epoch: 5| Step: 2
Training loss: 0.6698418394274612
Validation loss: 2.2608552902896766

Epoch: 5| Step: 3
Training loss: 1.182411484661644
Validation loss: 2.3608576693064807

Epoch: 5| Step: 4
Training loss: 0.8957875853693255
Validation loss: 2.358444423690457

Epoch: 5| Step: 5
Training loss: 0.9506629976883488
Validation loss: 2.2908555910261854

Epoch: 5| Step: 6
Training loss: 0.7222079561935664
Validation loss: 2.3262213768542894

Epoch: 5| Step: 7
Training loss: 0.8145920888783064
Validation loss: 2.3085424209539998

Epoch: 5| Step: 8
Training loss: 0.721648673706168
Validation loss: 2.3478059016468316

Epoch: 5| Step: 9
Training loss: 0.7933291288138885
Validation loss: 2.2699334479362583

Epoch: 5| Step: 10
Training loss: 1.2258974446937299
Validation loss: 2.3343512457986386

Epoch: 482| Step: 0
Training loss: 0.8162743858912478
Validation loss: 2.344033756921871

Epoch: 5| Step: 1
Training loss: 1.4561736418388287
Validation loss: 2.3438269150668307

Epoch: 5| Step: 2
Training loss: 0.8206652654805786
Validation loss: 2.386054097353494

Epoch: 5| Step: 3
Training loss: 1.0644778187538515
Validation loss: 2.3369917576248045

Epoch: 5| Step: 4
Training loss: 1.0651079595944397
Validation loss: 2.3010314535713547

Epoch: 5| Step: 5
Training loss: 0.8892962264174478
Validation loss: 2.217527248734331

Epoch: 5| Step: 6
Training loss: 0.7056377440823058
Validation loss: 2.3150483723152777

Epoch: 5| Step: 7
Training loss: 0.952427342965294
Validation loss: 2.2753302656154424

Epoch: 5| Step: 8
Training loss: 0.9635969438247861
Validation loss: 2.3144684173838908

Epoch: 5| Step: 9
Training loss: 0.890780719729488
Validation loss: 2.327071252094297

Epoch: 5| Step: 10
Training loss: 0.7302668083238955
Validation loss: 2.227193505582168

Epoch: 483| Step: 0
Training loss: 0.6311396870678729
Validation loss: 2.3633116366667615

Epoch: 5| Step: 1
Training loss: 1.2316865737624298
Validation loss: 2.3606594560534724

Epoch: 5| Step: 2
Training loss: 0.7192835693189394
Validation loss: 2.2807326169105635

Epoch: 5| Step: 3
Training loss: 1.6157242056457892
Validation loss: 2.297866601104508

Epoch: 5| Step: 4
Training loss: 0.75726613277606
Validation loss: 2.335299503632774

Epoch: 5| Step: 5
Training loss: 0.7362368904073552
Validation loss: 2.256780634494657

Epoch: 5| Step: 6
Training loss: 0.7725325791115394
Validation loss: 2.3744941781579314

Epoch: 5| Step: 7
Training loss: 1.043013668164588
Validation loss: 2.3954882280030674

Epoch: 5| Step: 8
Training loss: 0.8726581160235967
Validation loss: 2.358900645521339

Epoch: 5| Step: 9
Training loss: 0.7955609875839282
Validation loss: 2.3297971666735475

Epoch: 5| Step: 10
Training loss: 0.9171920087401324
Validation loss: 2.289121522401149

Epoch: 484| Step: 0
Training loss: 0.9146835955766834
Validation loss: 2.332858009384328

Epoch: 5| Step: 1
Training loss: 0.6556951811459368
Validation loss: 2.291903094478586

Epoch: 5| Step: 2
Training loss: 1.0915451715045679
Validation loss: 2.3906301473827147

Epoch: 5| Step: 3
Training loss: 0.8642345360676474
Validation loss: 2.3226395643174436

Epoch: 5| Step: 4
Training loss: 1.7224518185369937
Validation loss: 2.2835300865879526

Epoch: 5| Step: 5
Training loss: 0.8840046825090733
Validation loss: 2.3678569942810994

Epoch: 5| Step: 6
Training loss: 0.748487656411911
Validation loss: 2.3122914316385486

Epoch: 5| Step: 7
Training loss: 0.7905373339996639
Validation loss: 2.28708377666637

Epoch: 5| Step: 8
Training loss: 0.489962483424689
Validation loss: 2.3387902638798383

Epoch: 5| Step: 9
Training loss: 1.0994304829921595
Validation loss: 2.360702872246444

Epoch: 5| Step: 10
Training loss: 1.014146227091242
Validation loss: 2.325155116541405

Epoch: 485| Step: 0
Training loss: 0.9462253167222401
Validation loss: 2.2515902841167432

Epoch: 5| Step: 1
Training loss: 1.473479994224807
Validation loss: 2.394702066116467

Epoch: 5| Step: 2
Training loss: 0.7541627595775694
Validation loss: 2.3649799118623194

Epoch: 5| Step: 3
Training loss: 1.0185954743189465
Validation loss: 2.358859639315437

Epoch: 5| Step: 4
Training loss: 1.0269128163967272
Validation loss: 2.3725795912192864

Epoch: 5| Step: 5
Training loss: 0.915113513242393
Validation loss: 2.414037569270854

Epoch: 5| Step: 6
Training loss: 0.943291829536258
Validation loss: 2.3257831953306916

Epoch: 5| Step: 7
Training loss: 0.623112426944713
Validation loss: 2.3555104443081487

Epoch: 5| Step: 8
Training loss: 0.9385889404844255
Validation loss: 2.3480141857750993

Epoch: 5| Step: 9
Training loss: 0.8577259541195547
Validation loss: 2.322599328543034

Epoch: 5| Step: 10
Training loss: 1.249454856255493
Validation loss: 2.2638637367240984

Epoch: 486| Step: 0
Training loss: 1.1305242117541874
Validation loss: 2.375740311529052

Epoch: 5| Step: 1
Training loss: 1.0126882495836151
Validation loss: 2.316223516932702

Epoch: 5| Step: 2
Training loss: 0.6722107868780739
Validation loss: 2.3137681250512316

Epoch: 5| Step: 3
Training loss: 0.5209033887160845
Validation loss: 2.283219578838074

Epoch: 5| Step: 4
Training loss: 0.7485590443839932
Validation loss: 2.3589286248840406

Epoch: 5| Step: 5
Training loss: 0.9897421793020458
Validation loss: 2.2959727349172576

Epoch: 5| Step: 6
Training loss: 0.885694475161155
Validation loss: 2.327422483176033

Epoch: 5| Step: 7
Training loss: 1.5668346551692698
Validation loss: 2.344135421728372

Epoch: 5| Step: 8
Training loss: 1.1501246405518954
Validation loss: 2.3532077118641532

Epoch: 5| Step: 9
Training loss: 0.6792187663925797
Validation loss: 2.2646520079068044

Epoch: 5| Step: 10
Training loss: 0.9526828303045907
Validation loss: 2.334390671708419

Epoch: 487| Step: 0
Training loss: 0.579677070667808
Validation loss: 2.3787208882433037

Epoch: 5| Step: 1
Training loss: 0.9548748400693405
Validation loss: 2.371198008936762

Epoch: 5| Step: 2
Training loss: 0.8821172423970971
Validation loss: 2.375172773919313

Epoch: 5| Step: 3
Training loss: 0.8547908936609474
Validation loss: 2.34179420385171

Epoch: 5| Step: 4
Training loss: 1.5117673250028554
Validation loss: 2.317760769918122

Epoch: 5| Step: 5
Training loss: 0.6871709903331517
Validation loss: 2.241259799408289

Epoch: 5| Step: 6
Training loss: 0.9706462943252224
Validation loss: 2.393076919218654

Epoch: 5| Step: 7
Training loss: 1.0963490803918476
Validation loss: 2.3015866957505295

Epoch: 5| Step: 8
Training loss: 0.8982462140329204
Validation loss: 2.339672820776705

Epoch: 5| Step: 9
Training loss: 0.8955777639110146
Validation loss: 2.2828558353447104

Epoch: 5| Step: 10
Training loss: 1.2223245091455701
Validation loss: 2.29797941790156

Epoch: 488| Step: 0
Training loss: 0.6172226763008378
Validation loss: 2.397606207009402

Epoch: 5| Step: 1
Training loss: 0.7131555352456272
Validation loss: 2.3091532782875785

Epoch: 5| Step: 2
Training loss: 0.8491804070401452
Validation loss: 2.3938619120489433

Epoch: 5| Step: 3
Training loss: 0.9120870583395584
Validation loss: 2.388349284892847

Epoch: 5| Step: 4
Training loss: 0.6879015313518109
Validation loss: 2.309675241356338

Epoch: 5| Step: 5
Training loss: 0.7325101672043045
Validation loss: 2.3201113488308236

Epoch: 5| Step: 6
Training loss: 0.7082656285708979
Validation loss: 2.3209211287996685

Epoch: 5| Step: 7
Training loss: 1.2203288977152587
Validation loss: 2.31167126455686

Epoch: 5| Step: 8
Training loss: 1.2804592762957958
Validation loss: 2.3325704942333414

Epoch: 5| Step: 9
Training loss: 1.4306613961152628
Validation loss: 2.3518336098272052

Epoch: 5| Step: 10
Training loss: 0.8205006701497486
Validation loss: 2.3331604046033476

Epoch: 489| Step: 0
Training loss: 1.0524563962009237
Validation loss: 2.3467701158585745

Epoch: 5| Step: 1
Training loss: 1.0948894015507287
Validation loss: 2.296410074979315

Epoch: 5| Step: 2
Training loss: 0.6973685821686438
Validation loss: 2.4253480596559975

Epoch: 5| Step: 3
Training loss: 0.9164182839412444
Validation loss: 2.3361883667681758

Epoch: 5| Step: 4
Training loss: 0.6783058988762611
Validation loss: 2.3233443047327462

Epoch: 5| Step: 5
Training loss: 0.9514727106936876
Validation loss: 2.297279430012253

Epoch: 5| Step: 6
Training loss: 0.9571217396832441
Validation loss: 2.312370820499035

Epoch: 5| Step: 7
Training loss: 0.9509496096248338
Validation loss: 2.2739145032026222

Epoch: 5| Step: 8
Training loss: 0.8421387299127183
Validation loss: 2.361355560994789

Epoch: 5| Step: 9
Training loss: 1.62766619347956
Validation loss: 2.2847633979821333

Epoch: 5| Step: 10
Training loss: 0.8377144723961517
Validation loss: 2.389416725418579

Epoch: 490| Step: 0
Training loss: 0.781035851692402
Validation loss: 2.2982808969015793

Epoch: 5| Step: 1
Training loss: 0.7433479472578396
Validation loss: 2.3568614720426346

Epoch: 5| Step: 2
Training loss: 0.997514317632043
Validation loss: 2.357508609433995

Epoch: 5| Step: 3
Training loss: 0.6753788008793855
Validation loss: 2.306695770651712

Epoch: 5| Step: 4
Training loss: 0.8470989452023604
Validation loss: 2.2829034645266852

Epoch: 5| Step: 5
Training loss: 1.0983013822995418
Validation loss: 2.266893792384904

Epoch: 5| Step: 6
Training loss: 0.6261189458017059
Validation loss: 2.287575473052501

Epoch: 5| Step: 7
Training loss: 1.6564525984163179
Validation loss: 2.2538740334531435

Epoch: 5| Step: 8
Training loss: 0.9053392766983089
Validation loss: 2.3807476530670777

Epoch: 5| Step: 9
Training loss: 0.7455130109438344
Validation loss: 2.328713235308008

Epoch: 5| Step: 10
Training loss: 0.7707067505973071
Validation loss: 2.3539817738178495

Epoch: 491| Step: 0
Training loss: 0.9659969835530449
Validation loss: 2.3331321206184747

Epoch: 5| Step: 1
Training loss: 1.0596653768198188
Validation loss: 2.315147281475358

Epoch: 5| Step: 2
Training loss: 1.1433888224676119
Validation loss: 2.2727300221602738

Epoch: 5| Step: 3
Training loss: 1.4629703189344792
Validation loss: 2.362862872918318

Epoch: 5| Step: 4
Training loss: 0.7400594620398663
Validation loss: 2.382765520864265

Epoch: 5| Step: 5
Training loss: 0.8690889150259997
Validation loss: 2.4031405665728784

Epoch: 5| Step: 6
Training loss: 0.7743654945412065
Validation loss: 2.3593497760861095

Epoch: 5| Step: 7
Training loss: 1.0237898474869351
Validation loss: 2.3497810019108045

Epoch: 5| Step: 8
Training loss: 0.8996347825458104
Validation loss: 2.326855183184323

Epoch: 5| Step: 9
Training loss: 0.8516996780636761
Validation loss: 2.2933627328516883

Epoch: 5| Step: 10
Training loss: 0.8962288286589519
Validation loss: 2.28129336093538

Epoch: 492| Step: 0
Training loss: 0.8613636589073166
Validation loss: 2.363528647203195

Epoch: 5| Step: 1
Training loss: 1.672115843350934
Validation loss: 2.3201480598803452

Epoch: 5| Step: 2
Training loss: 0.5205338634391695
Validation loss: 2.2843889371396484

Epoch: 5| Step: 3
Training loss: 0.7160540897674255
Validation loss: 2.2964512920631064

Epoch: 5| Step: 4
Training loss: 0.620382657635829
Validation loss: 2.3794592523705878

Epoch: 5| Step: 5
Training loss: 0.5394192220211964
Validation loss: 2.3581281721095086

Epoch: 5| Step: 6
Training loss: 1.2266353415466582
Validation loss: 2.348144305798879

Epoch: 5| Step: 7
Training loss: 0.8807648398681047
Validation loss: 2.309329868449409

Epoch: 5| Step: 8
Training loss: 0.9275358931390301
Validation loss: 2.3374483377545983

Epoch: 5| Step: 9
Training loss: 0.8954662117816428
Validation loss: 2.3106968453378705

Epoch: 5| Step: 10
Training loss: 0.8144173740069155
Validation loss: 2.3284398986592745

Epoch: 493| Step: 0
Training loss: 0.8193457219809281
Validation loss: 2.310980986634913

Epoch: 5| Step: 1
Training loss: 0.8913119160036554
Validation loss: 2.3430660242422334

Epoch: 5| Step: 2
Training loss: 1.5193411504693077
Validation loss: 2.334839482716369

Epoch: 5| Step: 3
Training loss: 0.9211537724190593
Validation loss: 2.24470140414487

Epoch: 5| Step: 4
Training loss: 0.793370788582274
Validation loss: 2.3377105149785886

Epoch: 5| Step: 5
Training loss: 0.6964872487469413
Validation loss: 2.3320938574378838

Epoch: 5| Step: 6
Training loss: 0.618831304545133
Validation loss: 2.3123491709753443

Epoch: 5| Step: 7
Training loss: 0.6680412030104713
Validation loss: 2.3149118536796105

Epoch: 5| Step: 8
Training loss: 1.3253578080786788
Validation loss: 2.249628147380058

Epoch: 5| Step: 9
Training loss: 0.95146870142967
Validation loss: 2.3433547377820605

Epoch: 5| Step: 10
Training loss: 0.8229355427633336
Validation loss: 2.330416256433085

Epoch: 494| Step: 0
Training loss: 0.962814204218519
Validation loss: 2.230732799377086

Epoch: 5| Step: 1
Training loss: 0.586539124931018
Validation loss: 2.3208908874400125

Epoch: 5| Step: 2
Training loss: 0.7212450837838797
Validation loss: 2.232247283016415

Epoch: 5| Step: 3
Training loss: 0.8822757135515521
Validation loss: 2.3720013632812025

Epoch: 5| Step: 4
Training loss: 0.6617096901445675
Validation loss: 2.3184868657535698

Epoch: 5| Step: 5
Training loss: 0.6691829955253228
Validation loss: 2.326438945716805

Epoch: 5| Step: 6
Training loss: 0.8997696330034306
Validation loss: 2.321394137524125

Epoch: 5| Step: 7
Training loss: 1.707466262104281
Validation loss: 2.219988741590707

Epoch: 5| Step: 8
Training loss: 0.9002494122037952
Validation loss: 2.334049996687388

Epoch: 5| Step: 9
Training loss: 0.8865021428460452
Validation loss: 2.3302633526172576

Epoch: 5| Step: 10
Training loss: 0.9910803798138748
Validation loss: 2.341652394344922

Epoch: 495| Step: 0
Training loss: 0.7570576004780544
Validation loss: 2.4078424482363734

Epoch: 5| Step: 1
Training loss: 1.3760724653579774
Validation loss: 2.3438056288376132

Epoch: 5| Step: 2
Training loss: 1.0720909546157322
Validation loss: 2.318198924575209

Epoch: 5| Step: 3
Training loss: 1.1269306464903714
Validation loss: 2.3477974872160963

Epoch: 5| Step: 4
Training loss: 1.061643142758968
Validation loss: 2.3216366034267564

Epoch: 5| Step: 5
Training loss: 1.0430864132006263
Validation loss: 2.351544859633344

Epoch: 5| Step: 6
Training loss: 0.7072208635026309
Validation loss: 2.3884149370827155

Epoch: 5| Step: 7
Training loss: 0.6274694770441346
Validation loss: 2.3091885348965326

Epoch: 5| Step: 8
Training loss: 0.9548178163982091
Validation loss: 2.2451104989638853

Epoch: 5| Step: 9
Training loss: 0.7022713459446861
Validation loss: 2.312204339289815

Epoch: 5| Step: 10
Training loss: 0.8778251271682416
Validation loss: 2.3462613100727516

Epoch: 496| Step: 0
Training loss: 0.7551579732656204
Validation loss: 2.3385066655044593

Epoch: 5| Step: 1
Training loss: 0.7824737882032591
Validation loss: 2.2435375132775333

Epoch: 5| Step: 2
Training loss: 0.5864595249450756
Validation loss: 2.348856149101636

Epoch: 5| Step: 3
Training loss: 1.4510250710412143
Validation loss: 2.2910938505380423

Epoch: 5| Step: 4
Training loss: 0.9475143263445861
Validation loss: 2.3038505134214735

Epoch: 5| Step: 5
Training loss: 1.1215273453928478
Validation loss: 2.312152551536564

Epoch: 5| Step: 6
Training loss: 0.9195733837758443
Validation loss: 2.2580662164081082

Epoch: 5| Step: 7
Training loss: 0.6971628236186693
Validation loss: 2.3343233496433373

Epoch: 5| Step: 8
Training loss: 1.084561086292892
Validation loss: 2.2972004534092565

Epoch: 5| Step: 9
Training loss: 0.8034007701097082
Validation loss: 2.3288816808164325

Epoch: 5| Step: 10
Training loss: 0.6636199374024669
Validation loss: 2.2583726291108217

Epoch: 497| Step: 0
Training loss: 1.257136951315
Validation loss: 2.2271220798100044

Epoch: 5| Step: 1
Training loss: 0.7069009481671119
Validation loss: 2.3355877228541684

Epoch: 5| Step: 2
Training loss: 0.9233061463063749
Validation loss: 2.2920685051317116

Epoch: 5| Step: 3
Training loss: 1.413474745865883
Validation loss: 2.3876295578464752

Epoch: 5| Step: 4
Training loss: 0.8274889608724416
Validation loss: 2.2753709170009837

Epoch: 5| Step: 5
Training loss: 0.952579842672815
Validation loss: 2.3616563003091025

Epoch: 5| Step: 6
Training loss: 0.772709089271777
Validation loss: 2.346577615077197

Epoch: 5| Step: 7
Training loss: 0.5587755454280878
Validation loss: 2.3232760220167807

Epoch: 5| Step: 8
Training loss: 0.8071134719249861
Validation loss: 2.3753935947059652

Epoch: 5| Step: 9
Training loss: 0.6241431322953461
Validation loss: 2.3341699812774994

Epoch: 5| Step: 10
Training loss: 0.7969975470764818
Validation loss: 2.3321604095263724

Epoch: 498| Step: 0
Training loss: 1.5688202253330565
Validation loss: 2.299476495787073

Epoch: 5| Step: 1
Training loss: 0.9413271668959807
Validation loss: 2.265024185714348

Epoch: 5| Step: 2
Training loss: 1.1783239808761323
Validation loss: 2.3616916594437467

Epoch: 5| Step: 3
Training loss: 0.7720600925563352
Validation loss: 2.2873480510716555

Epoch: 5| Step: 4
Training loss: 0.6458423572853264
Validation loss: 2.2800673241080935

Epoch: 5| Step: 5
Training loss: 0.6632290939835088
Validation loss: 2.3306334908947557

Epoch: 5| Step: 6
Training loss: 0.5851980502550469
Validation loss: 2.309965420324616

Epoch: 5| Step: 7
Training loss: 0.8869233084513622
Validation loss: 2.3461688777749456

Epoch: 5| Step: 8
Training loss: 1.0428046050900297
Validation loss: 2.3908823804903765

Epoch: 5| Step: 9
Training loss: 0.8459775272477847
Validation loss: 2.341876543881326

Epoch: 5| Step: 10
Training loss: 0.7352579368777737
Validation loss: 2.2440836496773646

Epoch: 499| Step: 0
Training loss: 1.1194729669364407
Validation loss: 2.2921882473988107

Epoch: 5| Step: 1
Training loss: 0.8111269793816228
Validation loss: 2.3420657208898215

Epoch: 5| Step: 2
Training loss: 0.8017874002514797
Validation loss: 2.344232267032131

Epoch: 5| Step: 3
Training loss: 0.6653079303030861
Validation loss: 2.3853269971161186

Epoch: 5| Step: 4
Training loss: 1.444587814519222
Validation loss: 2.3512347568771212

Epoch: 5| Step: 5
Training loss: 0.8037105296100309
Validation loss: 2.2907090025378016

Epoch: 5| Step: 6
Training loss: 0.5476659776637239
Validation loss: 2.26520280366024

Epoch: 5| Step: 7
Training loss: 1.0697479986968623
Validation loss: 2.353526509073905

Epoch: 5| Step: 8
Training loss: 0.9295603561012435
Validation loss: 2.3647819736649023

Epoch: 5| Step: 9
Training loss: 0.6932594119800793
Validation loss: 2.3511984957713428

Epoch: 5| Step: 10
Training loss: 1.122706140990437
Validation loss: 2.3136216591528105

Epoch: 500| Step: 0
Training loss: 1.0513494153817615
Validation loss: 2.2812015541226707

Epoch: 5| Step: 1
Training loss: 0.8882675760335609
Validation loss: 2.3198843371364686

Epoch: 5| Step: 2
Training loss: 0.932771520177731
Validation loss: 2.358201150317965

Epoch: 5| Step: 3
Training loss: 1.5567762442637605
Validation loss: 2.295740659592837

Epoch: 5| Step: 4
Training loss: 0.6216725944955727
Validation loss: 2.301903284757046

Epoch: 5| Step: 5
Training loss: 0.6952807387052165
Validation loss: 2.271320879611418

Epoch: 5| Step: 6
Training loss: 0.7370470013531527
Validation loss: 2.3313410089891873

Epoch: 5| Step: 7
Training loss: 0.7486256882477592
Validation loss: 2.2837386503661126

Epoch: 5| Step: 8
Training loss: 0.6105817437053841
Validation loss: 2.3824874562090366

Epoch: 5| Step: 9
Training loss: 1.1731659454370222
Validation loss: 2.2967453463019885

Epoch: 5| Step: 10
Training loss: 1.123171273680899
Validation loss: 2.3577774007727346

Epoch: 501| Step: 0
Training loss: 1.5966421327053253
Validation loss: 2.2717224836551804

Epoch: 5| Step: 1
Training loss: 0.6601693191588995
Validation loss: 2.331371940065753

Epoch: 5| Step: 2
Training loss: 0.8061248016735749
Validation loss: 2.312006402432155

Epoch: 5| Step: 3
Training loss: 0.9335040444407532
Validation loss: 2.29277997610235

Epoch: 5| Step: 4
Training loss: 0.897248850139605
Validation loss: 2.283618073807877

Epoch: 5| Step: 5
Training loss: 0.6605251793707633
Validation loss: 2.3394115971385436

Epoch: 5| Step: 6
Training loss: 0.9522906544430386
Validation loss: 2.406731718054726

Epoch: 5| Step: 7
Training loss: 0.7114960708402444
Validation loss: 2.2349545912970155

Epoch: 5| Step: 8
Training loss: 0.7758935791318294
Validation loss: 2.3689553475508687

Epoch: 5| Step: 9
Training loss: 1.0305586722864648
Validation loss: 2.3754318170731863

Epoch: 5| Step: 10
Training loss: 0.9357675120972221
Validation loss: 2.318233499531614

Epoch: 502| Step: 0
Training loss: 0.872393369908437
Validation loss: 2.3396909768881624

Epoch: 5| Step: 1
Training loss: 0.8243535370017436
Validation loss: 2.3243166937268906

Epoch: 5| Step: 2
Training loss: 1.2744564356281807
Validation loss: 2.3476798785771886

Epoch: 5| Step: 3
Training loss: 0.8173606441139595
Validation loss: 2.3148827774936254

Epoch: 5| Step: 4
Training loss: 0.7905182958677709
Validation loss: 2.2989182967489965

Epoch: 5| Step: 5
Training loss: 0.8294765311951435
Validation loss: 2.314660500659393

Epoch: 5| Step: 6
Training loss: 0.7129379883800703
Validation loss: 2.2590635364781178

Epoch: 5| Step: 7
Training loss: 0.7296180871789932
Validation loss: 2.3322060787567427

Epoch: 5| Step: 8
Training loss: 1.4552440983885746
Validation loss: 2.296673578724352

Epoch: 5| Step: 9
Training loss: 0.7914930998283929
Validation loss: 2.307790119934286

Epoch: 5| Step: 10
Training loss: 0.7260089118899197
Validation loss: 2.2848449983071712

Epoch: 503| Step: 0
Training loss: 0.9505431116010344
Validation loss: 2.271389269921129

Epoch: 5| Step: 1
Training loss: 0.6064275717482334
Validation loss: 2.312675947742167

Epoch: 5| Step: 2
Training loss: 1.4026618957915837
Validation loss: 2.323769726788238

Epoch: 5| Step: 3
Training loss: 0.7682558906346719
Validation loss: 2.294357528539328

Epoch: 5| Step: 4
Training loss: 0.8062798753274779
Validation loss: 2.321208897960516

Epoch: 5| Step: 5
Training loss: 0.8609004959489632
Validation loss: 2.2674059845489953

Epoch: 5| Step: 6
Training loss: 0.8356603715667362
Validation loss: 2.3575507004583307

Epoch: 5| Step: 7
Training loss: 1.1297866925474687
Validation loss: 2.3465456176617407

Epoch: 5| Step: 8
Training loss: 0.8260877489767049
Validation loss: 2.364991871615327

Epoch: 5| Step: 9
Training loss: 0.7452543639855387
Validation loss: 2.358078444226128

Epoch: 5| Step: 10
Training loss: 0.8547760410230313
Validation loss: 2.286766959980333

Epoch: 504| Step: 0
Training loss: 0.7776793709066198
Validation loss: 2.376314166627315

Epoch: 5| Step: 1
Training loss: 0.6820178586643642
Validation loss: 2.382102384146063

Epoch: 5| Step: 2
Training loss: 1.6212434630604107
Validation loss: 2.2932801645642265

Epoch: 5| Step: 3
Training loss: 0.8437178217085435
Validation loss: 2.232228437901415

Epoch: 5| Step: 4
Training loss: 0.5315430618221574
Validation loss: 2.206654024097533

Epoch: 5| Step: 5
Training loss: 0.9066369776095647
Validation loss: 2.263335848373194

Epoch: 5| Step: 6
Training loss: 0.962716108063871
Validation loss: 2.3141044919376683

Epoch: 5| Step: 7
Training loss: 0.8280227885957233
Validation loss: 2.2760171714120325

Epoch: 5| Step: 8
Training loss: 1.1917865083806862
Validation loss: 2.331119216029995

Epoch: 5| Step: 9
Training loss: 0.9263057591055514
Validation loss: 2.321711798093656

Epoch: 5| Step: 10
Training loss: 0.5607267881887826
Validation loss: 2.3151596835797257

Epoch: 505| Step: 0
Training loss: 1.44649725116847
Validation loss: 2.4199964379454144

Epoch: 5| Step: 1
Training loss: 0.6262841859878786
Validation loss: 2.343289230885327

Epoch: 5| Step: 2
Training loss: 0.7705333787667681
Validation loss: 2.3833615691685743

Epoch: 5| Step: 3
Training loss: 1.1633848739800141
Validation loss: 2.4240879614561006

Epoch: 5| Step: 4
Training loss: 0.7346146780875592
Validation loss: 2.472127103832668

Epoch: 5| Step: 5
Training loss: 0.7394888553359934
Validation loss: 2.359986584880584

Epoch: 5| Step: 6
Training loss: 0.9210300452646716
Validation loss: 2.313606510761661

Epoch: 5| Step: 7
Training loss: 0.8579462832995233
Validation loss: 2.379420761775561

Epoch: 5| Step: 8
Training loss: 1.132059044032744
Validation loss: 2.3540612388726787

Epoch: 5| Step: 9
Training loss: 0.8121018901588287
Validation loss: 2.274833732802743

Epoch: 5| Step: 10
Training loss: 0.5717122654157453
Validation loss: 2.3350660736059248

Epoch: 506| Step: 0
Training loss: 0.997984285127685
Validation loss: 2.3181806985606253

Epoch: 5| Step: 1
Training loss: 0.5783227891492134
Validation loss: 2.3852195488139314

Epoch: 5| Step: 2
Training loss: 0.8566496201933108
Validation loss: 2.3774121334785336

Epoch: 5| Step: 3
Training loss: 0.7822432879351684
Validation loss: 2.2746552428002547

Epoch: 5| Step: 4
Training loss: 0.6036268458919776
Validation loss: 2.339153446471829

Epoch: 5| Step: 5
Training loss: 0.7546460173837746
Validation loss: 2.2750019999092665

Epoch: 5| Step: 6
Training loss: 1.1789415034438648
Validation loss: 2.3169634877720036

Epoch: 5| Step: 7
Training loss: 0.7503413377309757
Validation loss: 2.3148484149622677

Epoch: 5| Step: 8
Training loss: 0.9319836446878275
Validation loss: 2.3193857764700363

Epoch: 5| Step: 9
Training loss: 0.9812667456491855
Validation loss: 2.3507360657043987

Epoch: 5| Step: 10
Training loss: 1.6360574993437906
Validation loss: 2.3214440214814247

Epoch: 507| Step: 0
Training loss: 0.9045500431820094
Validation loss: 2.328205958157183

Epoch: 5| Step: 1
Training loss: 0.6348485569697991
Validation loss: 2.432299484539351

Epoch: 5| Step: 2
Training loss: 0.7428045819494027
Validation loss: 2.474954052959867

Epoch: 5| Step: 3
Training loss: 0.8375130894335527
Validation loss: 2.5195310017282844

Epoch: 5| Step: 4
Training loss: 0.9362644955336733
Validation loss: 2.375480248707949

Epoch: 5| Step: 5
Training loss: 1.171863861031045
Validation loss: 2.3512792624181365

Epoch: 5| Step: 6
Training loss: 0.9098103074549662
Validation loss: 2.437547319876877

Epoch: 5| Step: 7
Training loss: 0.7519346556934321
Validation loss: 2.364133428746045

Epoch: 5| Step: 8
Training loss: 0.8190580676620001
Validation loss: 2.2793596220066137

Epoch: 5| Step: 9
Training loss: 1.483343066851509
Validation loss: 2.350734520367163

Epoch: 5| Step: 10
Training loss: 0.7932368234092453
Validation loss: 2.3044442197368737

Epoch: 508| Step: 0
Training loss: 0.7991331679238378
Validation loss: 2.3361930908999855

Epoch: 5| Step: 1
Training loss: 0.582150491878384
Validation loss: 2.2988544679751257

Epoch: 5| Step: 2
Training loss: 1.0195037721168438
Validation loss: 2.317881257612879

Epoch: 5| Step: 3
Training loss: 0.7183232906669188
Validation loss: 2.300149525119692

Epoch: 5| Step: 4
Training loss: 0.9954866541394685
Validation loss: 2.3501011486535495

Epoch: 5| Step: 5
Training loss: 0.8313623882983792
Validation loss: 2.328722891132115

Epoch: 5| Step: 6
Training loss: 0.781702444671638
Validation loss: 2.373851712257142

Epoch: 5| Step: 7
Training loss: 0.7500165699082063
Validation loss: 2.30762261447023

Epoch: 5| Step: 8
Training loss: 1.6118465814825362
Validation loss: 2.333765962884466

Epoch: 5| Step: 9
Training loss: 1.0582333898036043
Validation loss: 2.3083209218438268

Epoch: 5| Step: 10
Training loss: 0.8860555512965131
Validation loss: 2.4317169413373416

Epoch: 509| Step: 0
Training loss: 0.7133022426428249
Validation loss: 2.349164173720732

Epoch: 5| Step: 1
Training loss: 1.7112982382708275
Validation loss: 2.39082372703886

Epoch: 5| Step: 2
Training loss: 0.7317871598744936
Validation loss: 2.320544656653754

Epoch: 5| Step: 3
Training loss: 0.9524197392427612
Validation loss: 2.333113322308558

Epoch: 5| Step: 4
Training loss: 0.6851581656104073
Validation loss: 2.3574110899282097

Epoch: 5| Step: 5
Training loss: 0.6899084689410518
Validation loss: 2.2602940501510083

Epoch: 5| Step: 6
Training loss: 0.952638846062143
Validation loss: 2.262430244512192

Epoch: 5| Step: 7
Training loss: 0.9604335486913573
Validation loss: 2.2328898660717993

Epoch: 5| Step: 8
Training loss: 0.9802423952990225
Validation loss: 2.390446696400436

Epoch: 5| Step: 9
Training loss: 0.8360450532833368
Validation loss: 2.33143413361626

Epoch: 5| Step: 10
Training loss: 0.7192651726796685
Validation loss: 2.2159906728758934

Epoch: 510| Step: 0
Training loss: 1.0555028518826164
Validation loss: 2.2347239342266247

Epoch: 5| Step: 1
Training loss: 0.8055044675024732
Validation loss: 2.404258696735619

Epoch: 5| Step: 2
Training loss: 0.6772618914180157
Validation loss: 2.316666450184726

Epoch: 5| Step: 3
Training loss: 0.8080823082500559
Validation loss: 2.3656124903651206

Epoch: 5| Step: 4
Training loss: 0.8380319613960007
Validation loss: 2.329315975473319

Epoch: 5| Step: 5
Training loss: 1.495164786988255
Validation loss: 2.317383278790858

Epoch: 5| Step: 6
Training loss: 0.9615784035236268
Validation loss: 2.319354247283769

Epoch: 5| Step: 7
Training loss: 0.8178903697005532
Validation loss: 2.392322133315469

Epoch: 5| Step: 8
Training loss: 1.105319279247371
Validation loss: 2.316533272775123

Epoch: 5| Step: 9
Training loss: 0.48620625389836336
Validation loss: 2.3236550161474767

Epoch: 5| Step: 10
Training loss: 0.6879954936703323
Validation loss: 2.4390371969320994

Epoch: 511| Step: 0
Training loss: 0.873763266259417
Validation loss: 2.2555753400778755

Epoch: 5| Step: 1
Training loss: 0.7360305792064054
Validation loss: 2.2555182080504372

Epoch: 5| Step: 2
Training loss: 0.7259854722316545
Validation loss: 2.359978850450502

Epoch: 5| Step: 3
Training loss: 1.5180755938880464
Validation loss: 2.3563804961777586

Epoch: 5| Step: 4
Training loss: 0.8732261047042634
Validation loss: 2.299324754480961

Epoch: 5| Step: 5
Training loss: 0.7623554014459798
Validation loss: 2.338082532914913

Epoch: 5| Step: 6
Training loss: 1.0168930354098644
Validation loss: 2.3809870830913424

Epoch: 5| Step: 7
Training loss: 0.6953240940113191
Validation loss: 2.384820519619819

Epoch: 5| Step: 8
Training loss: 0.6929130299561247
Validation loss: 2.3368189385390745

Epoch: 5| Step: 9
Training loss: 1.1677753709418839
Validation loss: 2.3402964972800437

Epoch: 5| Step: 10
Training loss: 0.636230140855753
Validation loss: 2.2867511112673293

Epoch: 512| Step: 0
Training loss: 0.8739188531287045
Validation loss: 2.3228233675873993

Epoch: 5| Step: 1
Training loss: 0.7877855449273284
Validation loss: 2.3237161259880543

Epoch: 5| Step: 2
Training loss: 1.077119607271558
Validation loss: 2.4508586687852687

Epoch: 5| Step: 3
Training loss: 1.5207513848091028
Validation loss: 2.358382025522967

Epoch: 5| Step: 4
Training loss: 0.6291548906786338
Validation loss: 2.2786624712124195

Epoch: 5| Step: 5
Training loss: 0.7225567310988249
Validation loss: 2.24184183042564

Epoch: 5| Step: 6
Training loss: 0.6903841470377993
Validation loss: 2.3751886052197215

Epoch: 5| Step: 7
Training loss: 0.9804376240079287
Validation loss: 2.3388960773229366

Epoch: 5| Step: 8
Training loss: 0.8776690103514321
Validation loss: 2.3133870983909297

Epoch: 5| Step: 9
Training loss: 0.8583153173413889
Validation loss: 2.3488657826961306

Epoch: 5| Step: 10
Training loss: 1.114540218101668
Validation loss: 2.2319170033271694

Epoch: 513| Step: 0
Training loss: 0.8517247316706429
Validation loss: 2.332862278162324

Epoch: 5| Step: 1
Training loss: 1.0177089731506606
Validation loss: 2.301922032786557

Epoch: 5| Step: 2
Training loss: 0.9916378511254645
Validation loss: 2.3147867152298534

Epoch: 5| Step: 3
Training loss: 0.8784670262105579
Validation loss: 2.2492344658019867

Epoch: 5| Step: 4
Training loss: 0.7601137908023748
Validation loss: 2.3952902186758505

Epoch: 5| Step: 5
Training loss: 1.4271296565573033
Validation loss: 2.3267642576718854

Epoch: 5| Step: 6
Training loss: 0.9298904902576499
Validation loss: 2.347729940279774

Epoch: 5| Step: 7
Training loss: 0.6461270315692215
Validation loss: 2.2789287672516196

Epoch: 5| Step: 8
Training loss: 0.7025870490528092
Validation loss: 2.309357775112552

Epoch: 5| Step: 9
Training loss: 0.865772398645427
Validation loss: 2.2684172959684075

Epoch: 5| Step: 10
Training loss: 0.8346906257893637
Validation loss: 2.3192209113914486

Epoch: 514| Step: 0
Training loss: 0.5729124300250994
Validation loss: 2.443265852911325

Epoch: 5| Step: 1
Training loss: 0.903912917947532
Validation loss: 2.369180895990252

Epoch: 5| Step: 2
Training loss: 0.8681595998505592
Validation loss: 2.4070916772690714

Epoch: 5| Step: 3
Training loss: 0.559750060392839
Validation loss: 2.2858539445608996

Epoch: 5| Step: 4
Training loss: 0.7803514654034697
Validation loss: 2.2632433068972073

Epoch: 5| Step: 5
Training loss: 1.549194908247188
Validation loss: 2.384243836736702

Epoch: 5| Step: 6
Training loss: 0.7313484565770215
Validation loss: 2.293433703632442

Epoch: 5| Step: 7
Training loss: 0.6098961924338213
Validation loss: 2.271722522588458

Epoch: 5| Step: 8
Training loss: 1.2376989686324116
Validation loss: 2.2550023596413635

Epoch: 5| Step: 9
Training loss: 0.8921705521612315
Validation loss: 2.275672761242114

Epoch: 5| Step: 10
Training loss: 0.5560206658447193
Validation loss: 2.332053442897667

Epoch: 515| Step: 0
Training loss: 1.210714307335726
Validation loss: 2.3589365942413267

Epoch: 5| Step: 1
Training loss: 0.8494573347481521
Validation loss: 2.3797228787022684

Epoch: 5| Step: 2
Training loss: 1.0825336267829488
Validation loss: 2.2543461831766276

Epoch: 5| Step: 3
Training loss: 0.8504703412522038
Validation loss: 2.305151815415592

Epoch: 5| Step: 4
Training loss: 0.6982102180044691
Validation loss: 2.2386983013215707

Epoch: 5| Step: 5
Training loss: 0.6686077073493127
Validation loss: 2.3244204633482832

Epoch: 5| Step: 6
Training loss: 0.9959320236261366
Validation loss: 2.264643947880918

Epoch: 5| Step: 7
Training loss: 0.7429654912546214
Validation loss: 2.4265667054208473

Epoch: 5| Step: 8
Training loss: 0.6955129355949209
Validation loss: 2.339500909276263

Epoch: 5| Step: 9
Training loss: 1.5465795061336887
Validation loss: 2.381154923870052

Epoch: 5| Step: 10
Training loss: 0.6445297472387193
Validation loss: 2.365598504489514

Epoch: 516| Step: 0
Training loss: 1.1883168171933767
Validation loss: 2.371274556959083

Epoch: 5| Step: 1
Training loss: 0.7387024016303443
Validation loss: 2.3630231341586043

Epoch: 5| Step: 2
Training loss: 0.7843521327602726
Validation loss: 2.404372824005474

Epoch: 5| Step: 3
Training loss: 0.5258302232173748
Validation loss: 2.3235736291130977

Epoch: 5| Step: 4
Training loss: 1.0466246803836297
Validation loss: 2.336748000736122

Epoch: 5| Step: 5
Training loss: 1.557813252991214
Validation loss: 2.2439664124086103

Epoch: 5| Step: 6
Training loss: 0.5953796008483099
Validation loss: 2.3043613531906524

Epoch: 5| Step: 7
Training loss: 1.0412582486891793
Validation loss: 2.236383439701069

Epoch: 5| Step: 8
Training loss: 0.8441102706909794
Validation loss: 2.299048940762065

Epoch: 5| Step: 9
Training loss: 0.7676963812123263
Validation loss: 2.310956421222562

Epoch: 5| Step: 10
Training loss: 0.7719892950032267
Validation loss: 2.251691564070687

Epoch: 517| Step: 0
Training loss: 0.9324580670968928
Validation loss: 2.2668237249761582

Epoch: 5| Step: 1
Training loss: 0.8469292120103988
Validation loss: 2.23307843678354

Epoch: 5| Step: 2
Training loss: 0.693092445248814
Validation loss: 2.304838714727917

Epoch: 5| Step: 3
Training loss: 1.435751307456836
Validation loss: 2.319616537169814

Epoch: 5| Step: 4
Training loss: 1.246447761019417
Validation loss: 2.3465802927979644

Epoch: 5| Step: 5
Training loss: 0.6560777029285819
Validation loss: 2.3033105974212176

Epoch: 5| Step: 6
Training loss: 0.8313302682541195
Validation loss: 2.363914123641208

Epoch: 5| Step: 7
Training loss: 0.7048374515523486
Validation loss: 2.3218530417613734

Epoch: 5| Step: 8
Training loss: 0.6890024543948259
Validation loss: 2.2734340798365267

Epoch: 5| Step: 9
Training loss: 0.7487960529971227
Validation loss: 2.315977152442554

Epoch: 5| Step: 10
Training loss: 0.820161060705046
Validation loss: 2.3190088704554586

Epoch: 518| Step: 0
Training loss: 0.862001912411385
Validation loss: 2.425697508442776

Epoch: 5| Step: 1
Training loss: 0.7603303041580357
Validation loss: 2.2630687546033847

Epoch: 5| Step: 2
Training loss: 1.0850652031709644
Validation loss: 2.3284279416365474

Epoch: 5| Step: 3
Training loss: 1.142544216076694
Validation loss: 2.3428367219064397

Epoch: 5| Step: 4
Training loss: 1.363830980227005
Validation loss: 2.320124792894729

Epoch: 5| Step: 5
Training loss: 0.8697619328394347
Validation loss: 2.2984324946414914

Epoch: 5| Step: 6
Training loss: 0.8791897464874544
Validation loss: 2.2189176936011825

Epoch: 5| Step: 7
Training loss: 0.775897919486101
Validation loss: 2.3490338002443756

Epoch: 5| Step: 8
Training loss: 0.8512522280939774
Validation loss: 2.317101277450372

Epoch: 5| Step: 9
Training loss: 0.7645056580283622
Validation loss: 2.2266896477638842

Epoch: 5| Step: 10
Training loss: 0.6846751351852693
Validation loss: 2.3248260760699058

Epoch: 519| Step: 0
Training loss: 1.0140089235421008
Validation loss: 2.3440497315418303

Epoch: 5| Step: 1
Training loss: 0.7816331305423367
Validation loss: 2.3108086968197012

Epoch: 5| Step: 2
Training loss: 0.9712376187982446
Validation loss: 2.335513452429277

Epoch: 5| Step: 3
Training loss: 0.6935732229640883
Validation loss: 2.339257481795001

Epoch: 5| Step: 4
Training loss: 0.9917976033830466
Validation loss: 2.4310390149412586

Epoch: 5| Step: 5
Training loss: 0.8172204005545753
Validation loss: 2.3778788276949454

Epoch: 5| Step: 6
Training loss: 0.7408668815202738
Validation loss: 2.3772549548590742

Epoch: 5| Step: 7
Training loss: 1.0668341368596868
Validation loss: 2.356858559086593

Epoch: 5| Step: 8
Training loss: 1.5990783033397058
Validation loss: 2.32365037905967

Epoch: 5| Step: 9
Training loss: 0.8182730253635568
Validation loss: 2.337648701715597

Epoch: 5| Step: 10
Training loss: 0.8182475666880594
Validation loss: 2.28707577271471

Epoch: 520| Step: 0
Training loss: 0.8686943365692983
Validation loss: 2.296772461573004

Epoch: 5| Step: 1
Training loss: 0.6950027976219898
Validation loss: 2.2444297335629364

Epoch: 5| Step: 2
Training loss: 0.7037082584191409
Validation loss: 2.3123022126253585

Epoch: 5| Step: 3
Training loss: 0.8237718934664878
Validation loss: 2.310967985250246

Epoch: 5| Step: 4
Training loss: 0.9432645951513629
Validation loss: 2.255777189834075

Epoch: 5| Step: 5
Training loss: 0.5407665794959557
Validation loss: 2.2536390084321964

Epoch: 5| Step: 6
Training loss: 1.6348965135540316
Validation loss: 2.3431099228882672

Epoch: 5| Step: 7
Training loss: 0.7251217411035761
Validation loss: 2.3287844866634595

Epoch: 5| Step: 8
Training loss: 0.6517992088242254
Validation loss: 2.381472761570469

Epoch: 5| Step: 9
Training loss: 0.9351969723610862
Validation loss: 2.318957341621868

Epoch: 5| Step: 10
Training loss: 0.6817212426023972
Validation loss: 2.3683555859308667

Epoch: 521| Step: 0
Training loss: 0.6656957400704401
Validation loss: 2.256253802127252

Epoch: 5| Step: 1
Training loss: 0.8143803040221212
Validation loss: 2.327703581099764

Epoch: 5| Step: 2
Training loss: 1.054885789103865
Validation loss: 2.3217239812831285

Epoch: 5| Step: 3
Training loss: 0.8262854243315494
Validation loss: 2.303099993580583

Epoch: 5| Step: 4
Training loss: 0.5607458950918006
Validation loss: 2.386985676206657

Epoch: 5| Step: 5
Training loss: 0.7553696339549364
Validation loss: 2.3286395531491135

Epoch: 5| Step: 6
Training loss: 0.5307119674316598
Validation loss: 2.181718524353609

Epoch: 5| Step: 7
Training loss: 0.7833164732383403
Validation loss: 2.294127173891116

Epoch: 5| Step: 8
Training loss: 0.9597388133743241
Validation loss: 2.3771674963245357

Epoch: 5| Step: 9
Training loss: 1.5038049440818348
Validation loss: 2.280286567799326

Epoch: 5| Step: 10
Training loss: 0.7598265792597819
Validation loss: 2.2969414709263045

Epoch: 522| Step: 0
Training loss: 0.774268965338887
Validation loss: 2.2184720128808273

Epoch: 5| Step: 1
Training loss: 0.8826945740923355
Validation loss: 2.294314773189272

Epoch: 5| Step: 2
Training loss: 0.7511602011024925
Validation loss: 2.3285636227143383

Epoch: 5| Step: 3
Training loss: 0.5585995920582698
Validation loss: 2.2177394036868683

Epoch: 5| Step: 4
Training loss: 0.8621256762382042
Validation loss: 2.344315624827315

Epoch: 5| Step: 5
Training loss: 1.1208058163598835
Validation loss: 2.299117934648098

Epoch: 5| Step: 6
Training loss: 0.9249497554639124
Validation loss: 2.3889224237360294

Epoch: 5| Step: 7
Training loss: 0.7045076550974098
Validation loss: 2.368224982934964

Epoch: 5| Step: 8
Training loss: 1.4132420388386702
Validation loss: 2.3555752813058666

Epoch: 5| Step: 9
Training loss: 0.5742168556234032
Validation loss: 2.3268871971381553

Epoch: 5| Step: 10
Training loss: 0.5934406277622842
Validation loss: 2.399309113851492

Epoch: 523| Step: 0
Training loss: 0.6099148584184328
Validation loss: 2.345780724644597

Epoch: 5| Step: 1
Training loss: 0.8525966000012428
Validation loss: 2.3002617557308067

Epoch: 5| Step: 2
Training loss: 0.9279033627446363
Validation loss: 2.24278549207085

Epoch: 5| Step: 3
Training loss: 0.7304283579710161
Validation loss: 2.2836097360766345

Epoch: 5| Step: 4
Training loss: 0.6378883431855765
Validation loss: 2.2655189390325363

Epoch: 5| Step: 5
Training loss: 0.9718331220625838
Validation loss: 2.2454472595586776

Epoch: 5| Step: 6
Training loss: 0.8014034924057143
Validation loss: 2.3304945658498744

Epoch: 5| Step: 7
Training loss: 0.5035261746434095
Validation loss: 2.2911869225582784

Epoch: 5| Step: 8
Training loss: 0.8136049240338393
Validation loss: 2.3014636278648015

Epoch: 5| Step: 9
Training loss: 0.9239866350578031
Validation loss: 2.2497604816885977

Epoch: 5| Step: 10
Training loss: 1.7087099389024327
Validation loss: 2.2352262109401266

Epoch: 524| Step: 0
Training loss: 0.9974662749246821
Validation loss: 2.263195686481921

Epoch: 5| Step: 1
Training loss: 0.7730391661503939
Validation loss: 2.329290252978966

Epoch: 5| Step: 2
Training loss: 0.6788692811090449
Validation loss: 2.3490215734378928

Epoch: 5| Step: 3
Training loss: 0.8976282870699023
Validation loss: 2.2951941982404054

Epoch: 5| Step: 4
Training loss: 1.52197265625
Validation loss: 2.2499932992030987

Epoch: 5| Step: 5
Training loss: 1.0558135061853702
Validation loss: 2.3361794781319056

Epoch: 5| Step: 6
Training loss: 0.5666965661388622
Validation loss: 2.3179149458626163

Epoch: 5| Step: 7
Training loss: 0.75061141364692
Validation loss: 2.3079682345261388

Epoch: 5| Step: 8
Training loss: 0.6782651905758899
Validation loss: 2.26457998286056

Epoch: 5| Step: 9
Training loss: 0.6823633947355146
Validation loss: 2.3262450369072196

Epoch: 5| Step: 10
Training loss: 0.8731391397149102
Validation loss: 2.2997603066836616

Epoch: 525| Step: 0
Training loss: 0.94773610809296
Validation loss: 2.3082919547734475

Epoch: 5| Step: 1
Training loss: 0.7022179368896178
Validation loss: 2.2837599273271354

Epoch: 5| Step: 2
Training loss: 1.3330938849414997
Validation loss: 2.302220737772326

Epoch: 5| Step: 3
Training loss: 0.7789627544450713
Validation loss: 2.3212013877426556

Epoch: 5| Step: 4
Training loss: 0.8458581302246451
Validation loss: 2.2173891540533144

Epoch: 5| Step: 5
Training loss: 0.6926156797086606
Validation loss: 2.237405468306177

Epoch: 5| Step: 6
Training loss: 0.8096482040427758
Validation loss: 2.335104751325072

Epoch: 5| Step: 7
Training loss: 0.7835094965692132
Validation loss: 2.3261700488433665

Epoch: 5| Step: 8
Training loss: 0.7527190827982525
Validation loss: 2.277535266640318

Epoch: 5| Step: 9
Training loss: 0.9323425208061737
Validation loss: 2.253640706802704

Epoch: 5| Step: 10
Training loss: 0.7330784410682971
Validation loss: 2.284275847546276

Epoch: 526| Step: 0
Training loss: 0.6399819472866272
Validation loss: 2.303773895045917

Epoch: 5| Step: 1
Training loss: 0.9231660175960545
Validation loss: 2.3111758222596994

Epoch: 5| Step: 2
Training loss: 0.6186132260595554
Validation loss: 2.347604477708927

Epoch: 5| Step: 3
Training loss: 0.6740891545330816
Validation loss: 2.3361183585141814

Epoch: 5| Step: 4
Training loss: 0.5723323848178108
Validation loss: 2.3268844207344417

Epoch: 5| Step: 5
Training loss: 0.710328060974909
Validation loss: 2.3983084186400974

Epoch: 5| Step: 6
Training loss: 0.9059587865764969
Validation loss: 2.301111644230324

Epoch: 5| Step: 7
Training loss: 0.947703152319051
Validation loss: 2.258294450754895

Epoch: 5| Step: 8
Training loss: 0.9279659905676048
Validation loss: 2.365289700690061

Epoch: 5| Step: 9
Training loss: 1.423652125235566
Validation loss: 2.2457794394698607

Epoch: 5| Step: 10
Training loss: 1.1883892444139288
Validation loss: 2.208016468513025

Epoch: 527| Step: 0
Training loss: 0.6333703772686904
Validation loss: 2.3271797388102033

Epoch: 5| Step: 1
Training loss: 0.5146921562720738
Validation loss: 2.343664135744452

Epoch: 5| Step: 2
Training loss: 0.7501470898396917
Validation loss: 2.23630298858844

Epoch: 5| Step: 3
Training loss: 0.7620201101578042
Validation loss: 2.255960809325091

Epoch: 5| Step: 4
Training loss: 1.401816181202349
Validation loss: 2.3575216260115672

Epoch: 5| Step: 5
Training loss: 0.9679540625343843
Validation loss: 2.2407078153349334

Epoch: 5| Step: 6
Training loss: 1.0099927399629327
Validation loss: 2.2704796084230017

Epoch: 5| Step: 7
Training loss: 0.9730931109113887
Validation loss: 2.270531896171698

Epoch: 5| Step: 8
Training loss: 0.8458916363721265
Validation loss: 2.269787942236615

Epoch: 5| Step: 9
Training loss: 0.7990803961452387
Validation loss: 2.2496728465554376

Epoch: 5| Step: 10
Training loss: 0.6318968518003799
Validation loss: 2.301824415289922

Epoch: 528| Step: 0
Training loss: 0.629559148386624
Validation loss: 2.29931022101359

Epoch: 5| Step: 1
Training loss: 0.6957773090887439
Validation loss: 2.2963807823906803

Epoch: 5| Step: 2
Training loss: 0.7936319668936145
Validation loss: 2.343592292101054

Epoch: 5| Step: 3
Training loss: 1.0727351816007784
Validation loss: 2.3553108123336695

Epoch: 5| Step: 4
Training loss: 0.7947424233823313
Validation loss: 2.3420891141583065

Epoch: 5| Step: 5
Training loss: 0.5660391571650114
Validation loss: 2.2752177629504597

Epoch: 5| Step: 6
Training loss: 0.7231664145569524
Validation loss: 2.3112556703807936

Epoch: 5| Step: 7
Training loss: 0.9533806129771486
Validation loss: 2.346890403760692

Epoch: 5| Step: 8
Training loss: 0.5412696765203917
Validation loss: 2.3554996281730767

Epoch: 5| Step: 9
Training loss: 1.508041522564915
Validation loss: 2.234639971363705

Epoch: 5| Step: 10
Training loss: 0.7535407806200031
Validation loss: 2.273700087337711

Epoch: 529| Step: 0
Training loss: 1.3525753746253733
Validation loss: 2.332281871920309

Epoch: 5| Step: 1
Training loss: 0.6676638615676732
Validation loss: 2.3163584298354833

Epoch: 5| Step: 2
Training loss: 1.0437282125974419
Validation loss: 2.3362221114545854

Epoch: 5| Step: 3
Training loss: 0.6678823002425728
Validation loss: 2.3229884526455193

Epoch: 5| Step: 4
Training loss: 0.943710419791169
Validation loss: 2.3840390157211035

Epoch: 5| Step: 5
Training loss: 0.5729383869099777
Validation loss: 2.34625125877087

Epoch: 5| Step: 6
Training loss: 0.7140834496427861
Validation loss: 2.320452159486059

Epoch: 5| Step: 7
Training loss: 1.0953590002270293
Validation loss: 2.2929299412359647

Epoch: 5| Step: 8
Training loss: 0.7843576801713141
Validation loss: 2.2993367892596708

Epoch: 5| Step: 9
Training loss: 0.6597495773288057
Validation loss: 2.313656839914113

Epoch: 5| Step: 10
Training loss: 0.7365689882907905
Validation loss: 2.2844782569980686

Epoch: 530| Step: 0
Training loss: 0.6055972547444969
Validation loss: 2.3704580681480896

Epoch: 5| Step: 1
Training loss: 0.6734197512454
Validation loss: 2.2896680956536066

Epoch: 5| Step: 2
Training loss: 0.9247235722804265
Validation loss: 2.306842646282574

Epoch: 5| Step: 3
Training loss: 0.7945204712503259
Validation loss: 2.3638752508710144

Epoch: 5| Step: 4
Training loss: 1.4779567695355527
Validation loss: 2.3514229269691347

Epoch: 5| Step: 5
Training loss: 0.806046125968718
Validation loss: 2.3485683056146502

Epoch: 5| Step: 6
Training loss: 0.5507651522833864
Validation loss: 2.276244955674972

Epoch: 5| Step: 7
Training loss: 0.5104389348005838
Validation loss: 2.34804274796673

Epoch: 5| Step: 8
Training loss: 1.194017044875434
Validation loss: 2.285078062408469

Epoch: 5| Step: 9
Training loss: 0.7567457576061912
Validation loss: 2.3183986537712657

Epoch: 5| Step: 10
Training loss: 0.8861185134497459
Validation loss: 2.256961929552255

Epoch: 531| Step: 0
Training loss: 0.6838969402973815
Validation loss: 2.2891986440632976

Epoch: 5| Step: 1
Training loss: 0.6498120916625245
Validation loss: 2.240982761037091

Epoch: 5| Step: 2
Training loss: 1.0234748309366732
Validation loss: 2.212872014728044

Epoch: 5| Step: 3
Training loss: 0.8165888239941991
Validation loss: 2.2855855923557282

Epoch: 5| Step: 4
Training loss: 0.5917175290135674
Validation loss: 2.314856708286524

Epoch: 5| Step: 5
Training loss: 1.4605262707963036
Validation loss: 2.3838786961602563

Epoch: 5| Step: 6
Training loss: 0.7625257472084417
Validation loss: 2.2985762417195903

Epoch: 5| Step: 7
Training loss: 1.0993126151995571
Validation loss: 2.305720627449853

Epoch: 5| Step: 8
Training loss: 0.6643876345663087
Validation loss: 2.3202361114358636

Epoch: 5| Step: 9
Training loss: 0.6798563780298931
Validation loss: 2.268552420565148

Epoch: 5| Step: 10
Training loss: 0.5628481423351317
Validation loss: 2.2607614900568525

Epoch: 532| Step: 0
Training loss: 0.6929978193617582
Validation loss: 2.2543500087114303

Epoch: 5| Step: 1
Training loss: 1.428155881184727
Validation loss: 2.3066684369425348

Epoch: 5| Step: 2
Training loss: 0.6463445414262713
Validation loss: 2.3271529502949346

Epoch: 5| Step: 3
Training loss: 0.6722485590557914
Validation loss: 2.3083813109416487

Epoch: 5| Step: 4
Training loss: 0.7933814191737355
Validation loss: 2.231738712318329

Epoch: 5| Step: 5
Training loss: 0.7394338823929183
Validation loss: 2.266260141659797

Epoch: 5| Step: 6
Training loss: 0.6551413026210406
Validation loss: 2.34538514226711

Epoch: 5| Step: 7
Training loss: 0.7371780387785514
Validation loss: 2.3497863849607126

Epoch: 5| Step: 8
Training loss: 0.7021180465976019
Validation loss: 2.314438346475349

Epoch: 5| Step: 9
Training loss: 0.986833620369557
Validation loss: 2.3130865021227427

Epoch: 5| Step: 10
Training loss: 0.9252063237590535
Validation loss: 2.3168724382396757

Epoch: 533| Step: 0
Training loss: 0.994263467150272
Validation loss: 2.372769970598849

Epoch: 5| Step: 1
Training loss: 1.421284815111061
Validation loss: 2.2795355424650525

Epoch: 5| Step: 2
Training loss: 0.6117200722320805
Validation loss: 2.307644143363133

Epoch: 5| Step: 3
Training loss: 0.8259354201141622
Validation loss: 2.3426507353127164

Epoch: 5| Step: 4
Training loss: 0.7742354390244296
Validation loss: 2.322542908100168

Epoch: 5| Step: 5
Training loss: 0.8635816439833831
Validation loss: 2.288028589801264

Epoch: 5| Step: 6
Training loss: 0.9724794403295673
Validation loss: 2.2518043279291793

Epoch: 5| Step: 7
Training loss: 0.6539517075793497
Validation loss: 2.2330030593174763

Epoch: 5| Step: 8
Training loss: 0.8251584377740174
Validation loss: 2.363116848016514

Epoch: 5| Step: 9
Training loss: 0.9226646920382404
Validation loss: 2.3469109869411353

Epoch: 5| Step: 10
Training loss: 0.7720070529057202
Validation loss: 2.2572510461873594

Epoch: 534| Step: 0
Training loss: 0.9997741921109895
Validation loss: 2.314619618907996

Epoch: 5| Step: 1
Training loss: 1.3758310927417672
Validation loss: 2.2166226703324847

Epoch: 5| Step: 2
Training loss: 0.6833970141007611
Validation loss: 2.307674071179024

Epoch: 5| Step: 3
Training loss: 0.7466433832321798
Validation loss: 2.356715997141708

Epoch: 5| Step: 4
Training loss: 0.7121259795160908
Validation loss: 2.371073108607644

Epoch: 5| Step: 5
Training loss: 0.728518120400908
Validation loss: 2.2771765644512825

Epoch: 5| Step: 6
Training loss: 0.7550662115255434
Validation loss: 2.3174714541991093

Epoch: 5| Step: 7
Training loss: 1.0953419680039322
Validation loss: 2.342212098058485

Epoch: 5| Step: 8
Training loss: 0.5872428087595618
Validation loss: 2.294192300803356

Epoch: 5| Step: 9
Training loss: 0.7025332609970573
Validation loss: 2.2924118269874993

Epoch: 5| Step: 10
Training loss: 0.8372563448939186
Validation loss: 2.3146043181085356

Epoch: 535| Step: 0
Training loss: 0.6552548128713217
Validation loss: 2.2703831440826816

Epoch: 5| Step: 1
Training loss: 0.5889877777871625
Validation loss: 2.3124943328229244

Epoch: 5| Step: 2
Training loss: 0.8692630295872699
Validation loss: 2.256368883028042

Epoch: 5| Step: 3
Training loss: 1.3777847700471408
Validation loss: 2.3472357098862036

Epoch: 5| Step: 4
Training loss: 0.8363471765321494
Validation loss: 2.2588616767940857

Epoch: 5| Step: 5
Training loss: 0.8693515821603441
Validation loss: 2.2676049333240687

Epoch: 5| Step: 6
Training loss: 0.7535300230209973
Validation loss: 2.287764864095884

Epoch: 5| Step: 7
Training loss: 1.1112209060516292
Validation loss: 2.2983902779891587

Epoch: 5| Step: 8
Training loss: 0.7788041165501206
Validation loss: 2.29444538407048

Epoch: 5| Step: 9
Training loss: 0.5990655526654028
Validation loss: 2.228646118028154

Epoch: 5| Step: 10
Training loss: 0.8060800299278215
Validation loss: 2.3307075802427906

Epoch: 536| Step: 0
Training loss: 1.1029810868316487
Validation loss: 2.4118320020806934

Epoch: 5| Step: 1
Training loss: 1.4931595916381726
Validation loss: 2.351026417307599

Epoch: 5| Step: 2
Training loss: 0.5872130433800483
Validation loss: 2.3329543942796844

Epoch: 5| Step: 3
Training loss: 0.859434125773664
Validation loss: 2.211339746056351

Epoch: 5| Step: 4
Training loss: 0.7890736040901469
Validation loss: 2.2456227534655038

Epoch: 5| Step: 5
Training loss: 0.8703245179255726
Validation loss: 2.3514358311417336

Epoch: 5| Step: 6
Training loss: 0.7235105259333288
Validation loss: 2.3166940643055

Epoch: 5| Step: 7
Training loss: 0.693480811431869
Validation loss: 2.269696295507083

Epoch: 5| Step: 8
Training loss: 1.0880659362784284
Validation loss: 2.3232062448207706

Epoch: 5| Step: 9
Training loss: 0.6981665510279357
Validation loss: 2.318867189319305

Epoch: 5| Step: 10
Training loss: 0.7596482527028365
Validation loss: 2.2655663555901886

Epoch: 537| Step: 0
Training loss: 0.7059328177179867
Validation loss: 2.190831396171424

Epoch: 5| Step: 1
Training loss: 1.5421291722917387
Validation loss: 2.329033876209778

Epoch: 5| Step: 2
Training loss: 0.6394363634153274
Validation loss: 2.3040567971759414

Epoch: 5| Step: 3
Training loss: 0.7232500677995488
Validation loss: 2.306094324194733

Epoch: 5| Step: 4
Training loss: 0.7442015775613074
Validation loss: 2.381993163083852

Epoch: 5| Step: 5
Training loss: 0.7762400397062522
Validation loss: 2.3071433276834576

Epoch: 5| Step: 6
Training loss: 0.6704096672573099
Validation loss: 2.3841548748772574

Epoch: 5| Step: 7
Training loss: 0.9106128840533909
Validation loss: 2.2656863172109847

Epoch: 5| Step: 8
Training loss: 1.0540351262907863
Validation loss: 2.302064559147996

Epoch: 5| Step: 9
Training loss: 0.8447012307663093
Validation loss: 2.230244609846964

Epoch: 5| Step: 10
Training loss: 0.8470420545949002
Validation loss: 2.1580658772087187

Epoch: 538| Step: 0
Training loss: 0.7829255256605023
Validation loss: 2.2973975875598245

Epoch: 5| Step: 1
Training loss: 0.5901505133622976
Validation loss: 2.2512310994325024

Epoch: 5| Step: 2
Training loss: 0.6972595983934013
Validation loss: 2.269381836423172

Epoch: 5| Step: 3
Training loss: 1.3606088234847051
Validation loss: 2.1802295009915613

Epoch: 5| Step: 4
Training loss: 0.6048422001922548
Validation loss: 2.3177597362813724

Epoch: 5| Step: 5
Training loss: 0.8556657329195597
Validation loss: 2.213446419468457

Epoch: 5| Step: 6
Training loss: 0.95687214054251
Validation loss: 2.1917386828940955

Epoch: 5| Step: 7
Training loss: 0.8679641819652592
Validation loss: 2.2462340985107483

Epoch: 5| Step: 8
Training loss: 0.7809671652945981
Validation loss: 2.309604708049863

Epoch: 5| Step: 9
Training loss: 0.8479828095628035
Validation loss: 2.2567963358512957

Epoch: 5| Step: 10
Training loss: 0.6038481157556947
Validation loss: 2.2389539432820853

Epoch: 539| Step: 0
Training loss: 0.6283058712680866
Validation loss: 2.363295975844925

Epoch: 5| Step: 1
Training loss: 0.696270122511239
Validation loss: 2.218604379855539

Epoch: 5| Step: 2
Training loss: 0.8755527521533375
Validation loss: 2.27894283223707

Epoch: 5| Step: 3
Training loss: 0.8343826165012379
Validation loss: 2.306993414155755

Epoch: 5| Step: 4
Training loss: 0.6904277450771606
Validation loss: 2.328325531515778

Epoch: 5| Step: 5
Training loss: 1.0499903882812895
Validation loss: 2.2917675551713774

Epoch: 5| Step: 6
Training loss: 0.8876500217814849
Validation loss: 2.3411451941968187

Epoch: 5| Step: 7
Training loss: 0.5289548212059747
Validation loss: 2.3700042809532142

Epoch: 5| Step: 8
Training loss: 1.3822874807463534
Validation loss: 2.3754699416961267

Epoch: 5| Step: 9
Training loss: 0.7586186633748165
Validation loss: 2.33435664246529

Epoch: 5| Step: 10
Training loss: 0.4768168130425301
Validation loss: 2.33895952637304

Epoch: 540| Step: 0
Training loss: 0.8679737272901001
Validation loss: 2.2529998103699818

Epoch: 5| Step: 1
Training loss: 0.6040178449991422
Validation loss: 2.259634087094465

Epoch: 5| Step: 2
Training loss: 1.4042538356419616
Validation loss: 2.325195978439207

Epoch: 5| Step: 3
Training loss: 0.43399395387037404
Validation loss: 2.2008624433086945

Epoch: 5| Step: 4
Training loss: 0.7678254483737692
Validation loss: 2.286886239966599

Epoch: 5| Step: 5
Training loss: 1.0849249530802687
Validation loss: 2.255338120341636

Epoch: 5| Step: 6
Training loss: 0.9515516396389782
Validation loss: 2.304514132834469

Epoch: 5| Step: 7
Training loss: 0.7167520535043466
Validation loss: 2.2807980824604996

Epoch: 5| Step: 8
Training loss: 0.8845325356618826
Validation loss: 2.312540218598853

Epoch: 5| Step: 9
Training loss: 0.5391156543564669
Validation loss: 2.3254883040257823

Epoch: 5| Step: 10
Training loss: 0.658700771844903
Validation loss: 2.349743181655324

Epoch: 541| Step: 0
Training loss: 0.8874148690670608
Validation loss: 2.221808027391697

Epoch: 5| Step: 1
Training loss: 0.8771944797130823
Validation loss: 2.314206063842589

Epoch: 5| Step: 2
Training loss: 0.940565564885375
Validation loss: 2.261963832880197

Epoch: 5| Step: 3
Training loss: 0.7000972407783151
Validation loss: 2.2164105750456713

Epoch: 5| Step: 4
Training loss: 0.742049636082881
Validation loss: 2.302317614687324

Epoch: 5| Step: 5
Training loss: 0.7107992352189054
Validation loss: 2.333287721692045

Epoch: 5| Step: 6
Training loss: 0.6944230208801068
Validation loss: 2.2758915183985478

Epoch: 5| Step: 7
Training loss: 0.7141329039876263
Validation loss: 2.267775834945684

Epoch: 5| Step: 8
Training loss: 0.7305275796466062
Validation loss: 2.3114785618856666

Epoch: 5| Step: 9
Training loss: 0.7008665264727061
Validation loss: 2.2547329165637473

Epoch: 5| Step: 10
Training loss: 1.601256997348526
Validation loss: 2.2160619131281654

Epoch: 542| Step: 0
Training loss: 1.3284128213805295
Validation loss: 2.302518200414202

Epoch: 5| Step: 1
Training loss: 0.936145662521585
Validation loss: 2.2580838229706135

Epoch: 5| Step: 2
Training loss: 0.6153448580888389
Validation loss: 2.320478836991272

Epoch: 5| Step: 3
Training loss: 0.9113860764699562
Validation loss: 2.2679279937873944

Epoch: 5| Step: 4
Training loss: 0.6880779871182182
Validation loss: 2.2432946782345042

Epoch: 5| Step: 5
Training loss: 0.8026962828125599
Validation loss: 2.3313084725528013

Epoch: 5| Step: 6
Training loss: 0.7826367087579702
Validation loss: 2.3750888816466844

Epoch: 5| Step: 7
Training loss: 0.6658655484164099
Validation loss: 2.311007690828067

Epoch: 5| Step: 8
Training loss: 0.6731131257025503
Validation loss: 2.3304623498131205

Epoch: 5| Step: 9
Training loss: 0.8219168822781908
Validation loss: 2.375071875839818

Epoch: 5| Step: 10
Training loss: 0.5555975259053626
Validation loss: 2.3689388085069214

Epoch: 543| Step: 0
Training loss: 1.06621837707708
Validation loss: 2.2436689088132176

Epoch: 5| Step: 1
Training loss: 1.3554496214118796
Validation loss: 2.338590406071682

Epoch: 5| Step: 2
Training loss: 0.7828996788714193
Validation loss: 2.300956740134405

Epoch: 5| Step: 3
Training loss: 0.6205712285714529
Validation loss: 2.2362026418876653

Epoch: 5| Step: 4
Training loss: 0.7731884642127762
Validation loss: 2.2871585986123186

Epoch: 5| Step: 5
Training loss: 0.8621097054802798
Validation loss: 2.285607300781524

Epoch: 5| Step: 6
Training loss: 0.8521205578408857
Validation loss: 2.337095935794802

Epoch: 5| Step: 7
Training loss: 0.8861160919111918
Validation loss: 2.271054397017932

Epoch: 5| Step: 8
Training loss: 1.0070357767244555
Validation loss: 2.3356941116376677

Epoch: 5| Step: 9
Training loss: 0.6594751670650643
Validation loss: 2.32750953367745

Epoch: 5| Step: 10
Training loss: 0.5994910207239809
Validation loss: 2.271218170073551

Epoch: 544| Step: 0
Training loss: 0.6025550629950459
Validation loss: 2.3488981326863834

Epoch: 5| Step: 1
Training loss: 0.699223417128006
Validation loss: 2.2574587388445195

Epoch: 5| Step: 2
Training loss: 0.5886095030407945
Validation loss: 2.3357844187155994

Epoch: 5| Step: 3
Training loss: 1.3945607842061392
Validation loss: 2.300970343466127

Epoch: 5| Step: 4
Training loss: 0.8707018599366231
Validation loss: 2.2681140809476226

Epoch: 5| Step: 5
Training loss: 0.7771518796358962
Validation loss: 2.2228715350695523

Epoch: 5| Step: 6
Training loss: 0.6989839894967441
Validation loss: 2.2810147903516085

Epoch: 5| Step: 7
Training loss: 0.6646981058498624
Validation loss: 2.3229995845911393

Epoch: 5| Step: 8
Training loss: 1.0728109116268874
Validation loss: 2.234195790675564

Epoch: 5| Step: 9
Training loss: 0.7868622422642266
Validation loss: 2.330058265618389

Epoch: 5| Step: 10
Training loss: 0.792876327465425
Validation loss: 2.202984850436009

Epoch: 545| Step: 0
Training loss: 0.8337395194680317
Validation loss: 2.285877620936768

Epoch: 5| Step: 1
Training loss: 0.8245310259615052
Validation loss: 2.279210946929833

Epoch: 5| Step: 2
Training loss: 0.6039030936135222
Validation loss: 2.276608275327038

Epoch: 5| Step: 3
Training loss: 0.5275821570738459
Validation loss: 2.298965961146592

Epoch: 5| Step: 4
Training loss: 1.5045232918921352
Validation loss: 2.2185506203925054

Epoch: 5| Step: 5
Training loss: 0.7250838872456369
Validation loss: 2.296980110348955

Epoch: 5| Step: 6
Training loss: 0.6092982610654222
Validation loss: 2.2987685572256304

Epoch: 5| Step: 7
Training loss: 0.9971741445729514
Validation loss: 2.216154810479731

Epoch: 5| Step: 8
Training loss: 0.6989681924464769
Validation loss: 2.2668496962890003

Epoch: 5| Step: 9
Training loss: 0.7370790249914431
Validation loss: 2.310933600006998

Epoch: 5| Step: 10
Training loss: 0.8653383558494432
Validation loss: 2.3591936016318247

Epoch: 546| Step: 0
Training loss: 0.8795350940462442
Validation loss: 2.2917264630374157

Epoch: 5| Step: 1
Training loss: 0.9010137358876948
Validation loss: 2.328149230923432

Epoch: 5| Step: 2
Training loss: 0.9453811935813065
Validation loss: 2.2670780171761242

Epoch: 5| Step: 3
Training loss: 0.6140408519394246
Validation loss: 2.213121492197089

Epoch: 5| Step: 4
Training loss: 1.4037881282475604
Validation loss: 2.3039403317104417

Epoch: 5| Step: 5
Training loss: 0.6618737670843728
Validation loss: 2.2640882633229307

Epoch: 5| Step: 6
Training loss: 0.6006667416186539
Validation loss: 2.295626699222095

Epoch: 5| Step: 7
Training loss: 0.6993751350995872
Validation loss: 2.3493850477217793

Epoch: 5| Step: 8
Training loss: 0.8865116902724668
Validation loss: 2.2386101999254056

Epoch: 5| Step: 9
Training loss: 0.6837870733193494
Validation loss: 2.2937385658939693

Epoch: 5| Step: 10
Training loss: 0.8422852977807852
Validation loss: 2.2967162332359936

Epoch: 547| Step: 0
Training loss: 0.7385736522195739
Validation loss: 2.3706351056571906

Epoch: 5| Step: 1
Training loss: 1.0646568173442799
Validation loss: 2.3920335185237396

Epoch: 5| Step: 2
Training loss: 1.3164875220501735
Validation loss: 2.3534066965245515

Epoch: 5| Step: 3
Training loss: 0.9654540012391882
Validation loss: 2.3403284760698413

Epoch: 5| Step: 4
Training loss: 0.7311125585391292
Validation loss: 2.3102331738656985

Epoch: 5| Step: 5
Training loss: 0.6233731554523086
Validation loss: 2.248891511813823

Epoch: 5| Step: 6
Training loss: 0.7036273856936651
Validation loss: 2.268270294930616

Epoch: 5| Step: 7
Training loss: 0.6399636925889087
Validation loss: 2.3401135329120084

Epoch: 5| Step: 8
Training loss: 0.9265235146463345
Validation loss: 2.313982123040994

Epoch: 5| Step: 9
Training loss: 0.7258422727359174
Validation loss: 2.336579804134456

Epoch: 5| Step: 10
Training loss: 0.5811457202029444
Validation loss: 2.33735576423944

Epoch: 548| Step: 0
Training loss: 0.911577449462837
Validation loss: 2.340859961838831

Epoch: 5| Step: 1
Training loss: 0.739472009223217
Validation loss: 2.3032314644871548

Epoch: 5| Step: 2
Training loss: 0.9625073147780653
Validation loss: 2.1850620132119802

Epoch: 5| Step: 3
Training loss: 0.7235639078588365
Validation loss: 2.2995593934340257

Epoch: 5| Step: 4
Training loss: 0.6900206437339885
Validation loss: 2.3871614063712325

Epoch: 5| Step: 5
Training loss: 0.6501594567947494
Validation loss: 2.325748438298864

Epoch: 5| Step: 6
Training loss: 0.6468720440635777
Validation loss: 2.2962580260924073

Epoch: 5| Step: 7
Training loss: 0.7464548804795681
Validation loss: 2.2130658949430466

Epoch: 5| Step: 8
Training loss: 0.7948196307887804
Validation loss: 2.2426410548037343

Epoch: 5| Step: 9
Training loss: 0.674971652318724
Validation loss: 2.2996378116099474

Epoch: 5| Step: 10
Training loss: 1.5250600928051556
Validation loss: 2.3431603809161503

Epoch: 549| Step: 0
Training loss: 0.9809480080918229
Validation loss: 2.281059608937328

Epoch: 5| Step: 1
Training loss: 0.8294490809295767
Validation loss: 2.235497576824063

Epoch: 5| Step: 2
Training loss: 1.3819366094898549
Validation loss: 2.308341965556113

Epoch: 5| Step: 3
Training loss: 0.8935481170245965
Validation loss: 2.221172938240342

Epoch: 5| Step: 4
Training loss: 0.8007346907315485
Validation loss: 2.236577421677131

Epoch: 5| Step: 5
Training loss: 0.5034370011765834
Validation loss: 2.3013957759211765

Epoch: 5| Step: 6
Training loss: 0.8161457869175304
Validation loss: 2.215293118593084

Epoch: 5| Step: 7
Training loss: 0.6358761975783478
Validation loss: 2.2800726437802274

Epoch: 5| Step: 8
Training loss: 0.7187210160092037
Validation loss: 2.2986805030705018

Epoch: 5| Step: 9
Training loss: 0.7483654489259771
Validation loss: 2.2788662915912115

Epoch: 5| Step: 10
Training loss: 0.8512546087692011
Validation loss: 2.3400934672859033

Epoch: 550| Step: 0
Training loss: 0.6296906643922869
Validation loss: 2.3338768109303447

Epoch: 5| Step: 1
Training loss: 0.6043125804001939
Validation loss: 2.336800641080494

Epoch: 5| Step: 2
Training loss: 0.6632571104799431
Validation loss: 2.2822781992065106

Epoch: 5| Step: 3
Training loss: 0.7501409716044466
Validation loss: 2.3187314195869453

Epoch: 5| Step: 4
Training loss: 0.7203791854342301
Validation loss: 2.283650190684177

Epoch: 5| Step: 5
Training loss: 1.531940693685936
Validation loss: 2.35609277491327

Epoch: 5| Step: 6
Training loss: 0.5507242700849618
Validation loss: 2.1945982400129145

Epoch: 5| Step: 7
Training loss: 1.0503349632759809
Validation loss: 2.3688112160144006

Epoch: 5| Step: 8
Training loss: 0.8067365686287391
Validation loss: 2.2866545513640175

Epoch: 5| Step: 9
Training loss: 0.8395260232023979
Validation loss: 2.277193992862159

Epoch: 5| Step: 10
Training loss: 0.8891472519635237
Validation loss: 2.244956640003903

Epoch: 551| Step: 0
Training loss: 0.6405145968695389
Validation loss: 2.200449600032768

Epoch: 5| Step: 1
Training loss: 0.7230222033181891
Validation loss: 2.3003289635283775

Epoch: 5| Step: 2
Training loss: 0.837833322552975
Validation loss: 2.3449776533187534

Epoch: 5| Step: 3
Training loss: 0.8995488135243442
Validation loss: 2.306851711302943

Epoch: 5| Step: 4
Training loss: 0.8524223326376861
Validation loss: 2.3177423402550397

Epoch: 5| Step: 5
Training loss: 0.6987702833517554
Validation loss: 2.307012763115869

Epoch: 5| Step: 6
Training loss: 1.387719709167142
Validation loss: 2.3105438076788745

Epoch: 5| Step: 7
Training loss: 1.0746473532385552
Validation loss: 2.354157371477236

Epoch: 5| Step: 8
Training loss: 0.6468974289253764
Validation loss: 2.3853417077713197

Epoch: 5| Step: 9
Training loss: 0.7407621650997201
Validation loss: 2.285142300667234

Epoch: 5| Step: 10
Training loss: 0.6651377779703384
Validation loss: 2.3357398753139162

Epoch: 552| Step: 0
Training loss: 0.6340349657858994
Validation loss: 2.307088147170294

Epoch: 5| Step: 1
Training loss: 0.8548943319888895
Validation loss: 2.2766317521220287

Epoch: 5| Step: 2
Training loss: 0.6589686076975034
Validation loss: 2.3458749524558806

Epoch: 5| Step: 3
Training loss: 0.8799181051511362
Validation loss: 2.2108907595722265

Epoch: 5| Step: 4
Training loss: 0.4919873996454707
Validation loss: 2.2651616806271444

Epoch: 5| Step: 5
Training loss: 1.0063282290549618
Validation loss: 2.2972456216102963

Epoch: 5| Step: 6
Training loss: 0.7150571327458162
Validation loss: 2.3281256034361926

Epoch: 5| Step: 7
Training loss: 0.8073153502569098
Validation loss: 2.3114498428985644

Epoch: 5| Step: 8
Training loss: 1.381033404875081
Validation loss: 2.2843331615179263

Epoch: 5| Step: 9
Training loss: 0.6477590941714972
Validation loss: 2.1697244296356053

Epoch: 5| Step: 10
Training loss: 0.7281106022405894
Validation loss: 2.2249386236840087

Epoch: 553| Step: 0
Training loss: 0.9939929725103049
Validation loss: 2.3011738718825785

Epoch: 5| Step: 1
Training loss: 0.7169094153260736
Validation loss: 2.281018793692564

Epoch: 5| Step: 2
Training loss: 0.7319733734212848
Validation loss: 2.250118787425924

Epoch: 5| Step: 3
Training loss: 1.390164759908833
Validation loss: 2.301934627536605

Epoch: 5| Step: 4
Training loss: 0.7843947252323804
Validation loss: 2.2039793753962367

Epoch: 5| Step: 5
Training loss: 0.5340050615881586
Validation loss: 2.3208495774903457

Epoch: 5| Step: 6
Training loss: 0.5591372000448267
Validation loss: 2.25049967327701

Epoch: 5| Step: 7
Training loss: 0.8070889536344023
Validation loss: 2.244841296678017

Epoch: 5| Step: 8
Training loss: 0.7410901037742165
Validation loss: 2.2131606747087527

Epoch: 5| Step: 9
Training loss: 0.831988624591274
Validation loss: 2.311174990886775

Epoch: 5| Step: 10
Training loss: 0.657246582270486
Validation loss: 2.2687715512704716

Epoch: 554| Step: 0
Training loss: 0.6236216605336568
Validation loss: 2.2952164200565712

Epoch: 5| Step: 1
Training loss: 0.7613809080895163
Validation loss: 2.2839755550111036

Epoch: 5| Step: 2
Training loss: 0.9174705614465585
Validation loss: 2.248741031540766

Epoch: 5| Step: 3
Training loss: 0.8199525315803988
Validation loss: 2.2694393265927717

Epoch: 5| Step: 4
Training loss: 0.8549036049182621
Validation loss: 2.2494367671596973

Epoch: 5| Step: 5
Training loss: 0.842595617601727
Validation loss: 2.250419864082639

Epoch: 5| Step: 6
Training loss: 1.3619229783477924
Validation loss: 2.255912314130609

Epoch: 5| Step: 7
Training loss: 0.9893464089248869
Validation loss: 2.2231038133854084

Epoch: 5| Step: 8
Training loss: 1.0341675841404003
Validation loss: 2.2955900862882426

Epoch: 5| Step: 9
Training loss: 0.5093237763374934
Validation loss: 2.2717466554494243

Epoch: 5| Step: 10
Training loss: 0.6397626236195233
Validation loss: 2.246537606075593

Epoch: 555| Step: 0
Training loss: 0.7542074125744529
Validation loss: 2.3304373899438047

Epoch: 5| Step: 1
Training loss: 1.069952577092636
Validation loss: 2.3062642550095283

Epoch: 5| Step: 2
Training loss: 0.7330213204492864
Validation loss: 2.264827399192047

Epoch: 5| Step: 3
Training loss: 0.612081191844929
Validation loss: 2.340254283250045

Epoch: 5| Step: 4
Training loss: 0.5714765713746246
Validation loss: 2.2859450794871754

Epoch: 5| Step: 5
Training loss: 0.6558085500848515
Validation loss: 2.321176198515417

Epoch: 5| Step: 6
Training loss: 0.6796058737312389
Validation loss: 2.299428039241784

Epoch: 5| Step: 7
Training loss: 1.6090777224444646
Validation loss: 2.320381927804998

Epoch: 5| Step: 8
Training loss: 0.6616342015393218
Validation loss: 2.2043842771149857

Epoch: 5| Step: 9
Training loss: 0.5596489975815228
Validation loss: 2.277340578857875

Epoch: 5| Step: 10
Training loss: 0.638737363111755
Validation loss: 2.291495897599651

Epoch: 556| Step: 0
Training loss: 0.7782218612377707
Validation loss: 2.2975080236002725

Epoch: 5| Step: 1
Training loss: 0.9274583265294083
Validation loss: 2.261690767304148

Epoch: 5| Step: 2
Training loss: 0.6568599999382015
Validation loss: 2.3044579799208162

Epoch: 5| Step: 3
Training loss: 0.6930589481730253
Validation loss: 2.25702609343356

Epoch: 5| Step: 4
Training loss: 0.6985598395130465
Validation loss: 2.3002578148571082

Epoch: 5| Step: 5
Training loss: 1.5184578916849127
Validation loss: 2.2735122078064625

Epoch: 5| Step: 6
Training loss: 0.5769906901512579
Validation loss: 2.37212877877784

Epoch: 5| Step: 7
Training loss: 0.5236796203432038
Validation loss: 2.2416893922174053

Epoch: 5| Step: 8
Training loss: 0.6451372938634863
Validation loss: 2.2807645091484585

Epoch: 5| Step: 9
Training loss: 0.6817622253908128
Validation loss: 2.320492751773203

Epoch: 5| Step: 10
Training loss: 0.7496996119078545
Validation loss: 2.319261293100623

Epoch: 557| Step: 0
Training loss: 0.8308167526008865
Validation loss: 2.2996826847362115

Epoch: 5| Step: 1
Training loss: 1.4346642096674511
Validation loss: 2.2578083135798317

Epoch: 5| Step: 2
Training loss: 0.8357185718813057
Validation loss: 2.2371888642893882

Epoch: 5| Step: 3
Training loss: 0.9701779516431311
Validation loss: 2.3830378175231717

Epoch: 5| Step: 4
Training loss: 0.7538418915312204
Validation loss: 2.231354877363297

Epoch: 5| Step: 5
Training loss: 0.7171245522393791
Validation loss: 2.280257430102428

Epoch: 5| Step: 6
Training loss: 0.64234537471936
Validation loss: 2.336815611689213

Epoch: 5| Step: 7
Training loss: 0.5142398493520223
Validation loss: 2.218478329318305

Epoch: 5| Step: 8
Training loss: 0.5679343820534379
Validation loss: 2.2684471078694495

Epoch: 5| Step: 9
Training loss: 0.8943431606530042
Validation loss: 2.3206295336706244

Epoch: 5| Step: 10
Training loss: 0.8949889632029358
Validation loss: 2.3199058041776355

Epoch: 558| Step: 0
Training loss: 0.7361188434298682
Validation loss: 2.3634674321649443

Epoch: 5| Step: 1
Training loss: 0.7241568990589339
Validation loss: 2.224269576192016

Epoch: 5| Step: 2
Training loss: 0.8680455885420904
Validation loss: 2.357341944130104

Epoch: 5| Step: 3
Training loss: 1.1165120677304368
Validation loss: 2.355894998665377

Epoch: 5| Step: 4
Training loss: 0.6238618978914212
Validation loss: 2.282892389732825

Epoch: 5| Step: 5
Training loss: 0.7053003568537783
Validation loss: 2.289676662125685

Epoch: 5| Step: 6
Training loss: 0.4844859519138325
Validation loss: 2.353063716127715

Epoch: 5| Step: 7
Training loss: 0.6817267945484048
Validation loss: 2.336043888217844

Epoch: 5| Step: 8
Training loss: 0.7184888116367607
Validation loss: 2.368227768246125

Epoch: 5| Step: 9
Training loss: 1.4923689167727228
Validation loss: 2.3025323222727314

Epoch: 5| Step: 10
Training loss: 0.9218864763483058
Validation loss: 2.3233906156504704

Epoch: 559| Step: 0
Training loss: 0.8459860876734066
Validation loss: 2.251531577594812

Epoch: 5| Step: 1
Training loss: 0.898187220999088
Validation loss: 2.2834086985134303

Epoch: 5| Step: 2
Training loss: 1.3058326857678224
Validation loss: 2.238317955664051

Epoch: 5| Step: 3
Training loss: 0.7508745657479974
Validation loss: 2.342120896896581

Epoch: 5| Step: 4
Training loss: 0.8348640608775529
Validation loss: 2.219484436736014

Epoch: 5| Step: 5
Training loss: 0.5345653975528759
Validation loss: 2.285364273877701

Epoch: 5| Step: 6
Training loss: 0.6918548378767736
Validation loss: 2.3241000871707294

Epoch: 5| Step: 7
Training loss: 0.8145248783988553
Validation loss: 2.2889755570177726

Epoch: 5| Step: 8
Training loss: 0.6005509529158931
Validation loss: 2.3045782086609723

Epoch: 5| Step: 9
Training loss: 0.6489682840244679
Validation loss: 2.327534094831799

Epoch: 5| Step: 10
Training loss: 0.6909122749875817
Validation loss: 2.329611842014836

Epoch: 560| Step: 0
Training loss: 0.5956579472654868
Validation loss: 2.2731029333527815

Epoch: 5| Step: 1
Training loss: 0.6179283620799759
Validation loss: 2.2723629219689516

Epoch: 5| Step: 2
Training loss: 0.5399384223743768
Validation loss: 2.2272229055583526

Epoch: 5| Step: 3
Training loss: 0.6092612820669776
Validation loss: 2.1820370951031003

Epoch: 5| Step: 4
Training loss: 0.6967339291643968
Validation loss: 2.2641979726201495

Epoch: 5| Step: 5
Training loss: 1.0159696727716931
Validation loss: 2.2739136655346535

Epoch: 5| Step: 6
Training loss: 0.7977534669222762
Validation loss: 2.302437185244978

Epoch: 5| Step: 7
Training loss: 0.7446765321603428
Validation loss: 2.2874520447248448

Epoch: 5| Step: 8
Training loss: 0.6659838984922946
Validation loss: 2.2423892892769923

Epoch: 5| Step: 9
Training loss: 1.5086499986479336
Validation loss: 2.256883425165119

Epoch: 5| Step: 10
Training loss: 0.5890196544334224
Validation loss: 2.337408323992435

Epoch: 561| Step: 0
Training loss: 0.7837198127518212
Validation loss: 2.26908586981511

Epoch: 5| Step: 1
Training loss: 0.6335187667710442
Validation loss: 2.381918507774036

Epoch: 5| Step: 2
Training loss: 0.7375954162167677
Validation loss: 2.3441071433042104

Epoch: 5| Step: 3
Training loss: 0.9337047367283442
Validation loss: 2.3366394272405664

Epoch: 5| Step: 4
Training loss: 0.8775763728931602
Validation loss: 2.3008744839167554

Epoch: 5| Step: 5
Training loss: 0.5939534742151458
Validation loss: 2.357576153489909

Epoch: 5| Step: 6
Training loss: 1.473979406127545
Validation loss: 2.2971551113390483

Epoch: 5| Step: 7
Training loss: 0.5772051323478117
Validation loss: 2.3787265900154595

Epoch: 5| Step: 8
Training loss: 0.8032856183173513
Validation loss: 2.3647077295598087

Epoch: 5| Step: 9
Training loss: 0.8246569079022409
Validation loss: 2.2939355136399406

Epoch: 5| Step: 10
Training loss: 0.7723445684114936
Validation loss: 2.279118726093834

Epoch: 562| Step: 0
Training loss: 0.8084104763331802
Validation loss: 2.355754757316071

Epoch: 5| Step: 1
Training loss: 0.7235045119819121
Validation loss: 2.312600350634587

Epoch: 5| Step: 2
Training loss: 1.145616296963014
Validation loss: 2.3194854301974366

Epoch: 5| Step: 3
Training loss: 1.335138003613573
Validation loss: 2.319817525142094

Epoch: 5| Step: 4
Training loss: 0.8083002414680828
Validation loss: 2.287456088353763

Epoch: 5| Step: 5
Training loss: 0.8506609843068288
Validation loss: 2.2432691467597845

Epoch: 5| Step: 6
Training loss: 0.5728755213672481
Validation loss: 2.2966584703561215

Epoch: 5| Step: 7
Training loss: 0.658425268160084
Validation loss: 2.256407670735172

Epoch: 5| Step: 8
Training loss: 0.4968338649444696
Validation loss: 2.280351010738427

Epoch: 5| Step: 9
Training loss: 0.7524484959589542
Validation loss: 2.277727587685752

Epoch: 5| Step: 10
Training loss: 0.43519537046175477
Validation loss: 2.2682268330990687

Epoch: 563| Step: 0
Training loss: 0.6275186572777774
Validation loss: 2.23647696936558

Epoch: 5| Step: 1
Training loss: 0.6797142900470813
Validation loss: 2.2620239669621958

Epoch: 5| Step: 2
Training loss: 0.5903198644805714
Validation loss: 2.361491568079667

Epoch: 5| Step: 3
Training loss: 1.4720802698536293
Validation loss: 2.2959407223030373

Epoch: 5| Step: 4
Training loss: 1.053785206578793
Validation loss: 2.299532663876491

Epoch: 5| Step: 5
Training loss: 0.7507922835635861
Validation loss: 2.2456426922850015

Epoch: 5| Step: 6
Training loss: 0.6192490395533506
Validation loss: 2.2981511557486853

Epoch: 5| Step: 7
Training loss: 0.654869193672992
Validation loss: 2.2046444494755186

Epoch: 5| Step: 8
Training loss: 0.9241024843865939
Validation loss: 2.2660683441049687

Epoch: 5| Step: 9
Training loss: 0.6206493827355782
Validation loss: 2.2660386759825535

Epoch: 5| Step: 10
Training loss: 0.57411426449935
Validation loss: 2.278799474549454

Epoch: 564| Step: 0
Training loss: 0.54174799186359
Validation loss: 2.1986340419933743

Epoch: 5| Step: 1
Training loss: 0.5939224143414069
Validation loss: 2.1917576849054803

Epoch: 5| Step: 2
Training loss: 1.052250568707857
Validation loss: 2.2977830828619483

Epoch: 5| Step: 3
Training loss: 0.8406590607276617
Validation loss: 2.3126310440532976

Epoch: 5| Step: 4
Training loss: 0.5475515540337021
Validation loss: 2.3092417690579348

Epoch: 5| Step: 5
Training loss: 0.795590955630678
Validation loss: 2.2738237333751488

Epoch: 5| Step: 6
Training loss: 0.538587499127968
Validation loss: 2.290894377858741

Epoch: 5| Step: 7
Training loss: 0.7765245194233048
Validation loss: 2.2360688809376246

Epoch: 5| Step: 8
Training loss: 0.7829930887148687
Validation loss: 2.254253128795821

Epoch: 5| Step: 9
Training loss: 0.5287629140354513
Validation loss: 2.2348867619554

Epoch: 5| Step: 10
Training loss: 1.5379743263076102
Validation loss: 2.324394275562076

Epoch: 565| Step: 0
Training loss: 0.7625351272371249
Validation loss: 2.3287676485630144

Epoch: 5| Step: 1
Training loss: 0.6331395140224131
Validation loss: 2.2437220613018316

Epoch: 5| Step: 2
Training loss: 0.7509461633608753
Validation loss: 2.3222811253620796

Epoch: 5| Step: 3
Training loss: 1.3428314529370426
Validation loss: 2.3265321717951823

Epoch: 5| Step: 4
Training loss: 0.9290967073889069
Validation loss: 2.3759147510199994

Epoch: 5| Step: 5
Training loss: 0.7364000846852384
Validation loss: 2.262107005207781

Epoch: 5| Step: 6
Training loss: 0.7504987250589804
Validation loss: 2.228175393589343

Epoch: 5| Step: 7
Training loss: 0.7474386267201799
Validation loss: 2.4023765120868052

Epoch: 5| Step: 8
Training loss: 0.8807814536129113
Validation loss: 2.289006226188891

Epoch: 5| Step: 9
Training loss: 0.6757513712192726
Validation loss: 2.2111930332799004

Epoch: 5| Step: 10
Training loss: 0.5264122542018768
Validation loss: 2.310843342410813

Epoch: 566| Step: 0
Training loss: 0.6011530238040838
Validation loss: 2.309235811901963

Epoch: 5| Step: 1
Training loss: 0.6556223410887936
Validation loss: 2.3280726075428206

Epoch: 5| Step: 2
Training loss: 0.6697761888826734
Validation loss: 2.3194633303652754

Epoch: 5| Step: 3
Training loss: 0.7750007937027343
Validation loss: 2.2988750686359882

Epoch: 5| Step: 4
Training loss: 0.9718007074644376
Validation loss: 2.279908147310793

Epoch: 5| Step: 5
Training loss: 0.5629723737707509
Validation loss: 2.2395926480816195

Epoch: 5| Step: 6
Training loss: 1.4071016487840107
Validation loss: 2.3066147632824374

Epoch: 5| Step: 7
Training loss: 0.7487033921193578
Validation loss: 2.236896001692925

Epoch: 5| Step: 8
Training loss: 0.7516933636530606
Validation loss: 2.300393467971839

Epoch: 5| Step: 9
Training loss: 0.6340814747610372
Validation loss: 2.184529255284488

Epoch: 5| Step: 10
Training loss: 0.7521944525745639
Validation loss: 2.3076667418745247

Epoch: 567| Step: 0
Training loss: 0.7737266693541939
Validation loss: 2.270654105859767

Epoch: 5| Step: 1
Training loss: 0.44067257698705703
Validation loss: 2.338303852868001

Epoch: 5| Step: 2
Training loss: 1.1212404268126142
Validation loss: 2.3410577001997597

Epoch: 5| Step: 3
Training loss: 0.531094107474835
Validation loss: 2.257467227104161

Epoch: 5| Step: 4
Training loss: 0.615173797047102
Validation loss: 2.2475857303978852

Epoch: 5| Step: 5
Training loss: 1.4129668148001786
Validation loss: 2.3075300764932516

Epoch: 5| Step: 6
Training loss: 0.6102045477240358
Validation loss: 2.350164638805313

Epoch: 5| Step: 7
Training loss: 0.8664786388539945
Validation loss: 2.3113696221582622

Epoch: 5| Step: 8
Training loss: 0.697971702417432
Validation loss: 2.3324696327405117

Epoch: 5| Step: 9
Training loss: 0.6704035103642846
Validation loss: 2.3523215165702194

Epoch: 5| Step: 10
Training loss: 0.8155242316892746
Validation loss: 2.271759305773544

Epoch: 568| Step: 0
Training loss: 0.619933478109207
Validation loss: 2.336998122312512

Epoch: 5| Step: 1
Training loss: 0.6927231139324672
Validation loss: 2.291576305036082

Epoch: 5| Step: 2
Training loss: 1.4915088488386317
Validation loss: 2.1961450307182315

Epoch: 5| Step: 3
Training loss: 0.8926469371489478
Validation loss: 2.275428586528128

Epoch: 5| Step: 4
Training loss: 0.5936683548457614
Validation loss: 2.3423081505731282

Epoch: 5| Step: 5
Training loss: 0.7007762036944558
Validation loss: 2.247385992163775

Epoch: 5| Step: 6
Training loss: 0.6647117806516231
Validation loss: 2.2163803974963145

Epoch: 5| Step: 7
Training loss: 0.5171971772547619
Validation loss: 2.31898379781142

Epoch: 5| Step: 8
Training loss: 0.8431710977020026
Validation loss: 2.338315421710533

Epoch: 5| Step: 9
Training loss: 0.8294432961373012
Validation loss: 2.2737958083252727

Epoch: 5| Step: 10
Training loss: 0.9087301058474059
Validation loss: 2.2658458937251518

Epoch: 569| Step: 0
Training loss: 0.8002721889700427
Validation loss: 2.272734360446114

Epoch: 5| Step: 1
Training loss: 0.8161294276169531
Validation loss: 2.301700594932219

Epoch: 5| Step: 2
Training loss: 1.248195012573537
Validation loss: 2.30316798454335

Epoch: 5| Step: 3
Training loss: 1.0647734833649245
Validation loss: 2.283237300209904

Epoch: 5| Step: 4
Training loss: 0.650472504098447
Validation loss: 2.2592940109806436

Epoch: 5| Step: 5
Training loss: 0.7055100784784949
Validation loss: 2.247181594164616

Epoch: 5| Step: 6
Training loss: 0.9388538439798191
Validation loss: 2.2694314247743557

Epoch: 5| Step: 7
Training loss: 0.7862554039943788
Validation loss: 2.236435505549962

Epoch: 5| Step: 8
Training loss: 0.6040503346046523
Validation loss: 2.1995100392619045

Epoch: 5| Step: 9
Training loss: 0.6892578885993689
Validation loss: 2.237242587836257

Epoch: 5| Step: 10
Training loss: 0.7398354051516126
Validation loss: 2.219800717349176

Epoch: 570| Step: 0
Training loss: 0.4349600084052507
Validation loss: 2.2587937930182926

Epoch: 5| Step: 1
Training loss: 0.6267995913742793
Validation loss: 2.26727442065897

Epoch: 5| Step: 2
Training loss: 0.9231679868406888
Validation loss: 2.197460366500801

Epoch: 5| Step: 3
Training loss: 0.47703716215686415
Validation loss: 2.224174236774254

Epoch: 5| Step: 4
Training loss: 0.6571834601089009
Validation loss: 2.2936887033408913

Epoch: 5| Step: 5
Training loss: 0.6657794522465085
Validation loss: 2.286173184334354

Epoch: 5| Step: 6
Training loss: 1.4617870125257693
Validation loss: 2.329113040014459

Epoch: 5| Step: 7
Training loss: 0.6695971132730655
Validation loss: 2.3266310439738427

Epoch: 5| Step: 8
Training loss: 0.7621442340052368
Validation loss: 2.2180701622030905

Epoch: 5| Step: 9
Training loss: 0.568867564364618
Validation loss: 2.182360659447599

Epoch: 5| Step: 10
Training loss: 0.610681649023583
Validation loss: 2.256313985563189

Epoch: 571| Step: 0
Training loss: 0.7001542806906269
Validation loss: 2.2286455313684392

Epoch: 5| Step: 1
Training loss: 0.6716910931150447
Validation loss: 2.248494191854501

Epoch: 5| Step: 2
Training loss: 0.6997937869416218
Validation loss: 2.294352474680363

Epoch: 5| Step: 3
Training loss: 0.6416566961512907
Validation loss: 2.2814934645984883

Epoch: 5| Step: 4
Training loss: 0.7518048028687474
Validation loss: 2.3064073944829793

Epoch: 5| Step: 5
Training loss: 0.8670742888913037
Validation loss: 2.310314331773903

Epoch: 5| Step: 6
Training loss: 0.7634146566951318
Validation loss: 2.3189267604056885

Epoch: 5| Step: 7
Training loss: 0.7665992688187223
Validation loss: 2.2714912460226473

Epoch: 5| Step: 8
Training loss: 0.6964545996137294
Validation loss: 2.286520609774995

Epoch: 5| Step: 9
Training loss: 1.4163078900969173
Validation loss: 2.266465497575391

Epoch: 5| Step: 10
Training loss: 0.7136303969483355
Validation loss: 2.2993517406618795

Epoch: 572| Step: 0
Training loss: 1.3524793921573546
Validation loss: 2.300344376554849

Epoch: 5| Step: 1
Training loss: 0.9670758393991795
Validation loss: 2.285930210302339

Epoch: 5| Step: 2
Training loss: 0.7354511735581427
Validation loss: 2.2872389517297185

Epoch: 5| Step: 3
Training loss: 0.9382128230799244
Validation loss: 2.2841635885078473

Epoch: 5| Step: 4
Training loss: 0.7494876223986926
Validation loss: 2.278256290357804

Epoch: 5| Step: 5
Training loss: 0.7007233399073829
Validation loss: 2.220741799137087

Epoch: 5| Step: 6
Training loss: 0.7062562520248369
Validation loss: 2.2735248404134705

Epoch: 5| Step: 7
Training loss: 0.5627493835337384
Validation loss: 2.398532027166545

Epoch: 5| Step: 8
Training loss: 0.7461896904580048
Validation loss: 2.294892014915983

Epoch: 5| Step: 9
Training loss: 0.5926476836949447
Validation loss: 2.3072725370828855

Epoch: 5| Step: 10
Training loss: 0.6848857767698784
Validation loss: 2.2891801748352005

Epoch: 573| Step: 0
Training loss: 0.6930793519119194
Validation loss: 2.235998738451514

Epoch: 5| Step: 1
Training loss: 0.6270428174470678
Validation loss: 2.3024249194856137

Epoch: 5| Step: 2
Training loss: 1.289613178423429
Validation loss: 2.316979924261729

Epoch: 5| Step: 3
Training loss: 0.8534078988326793
Validation loss: 2.326346556179839

Epoch: 5| Step: 4
Training loss: 0.6713367124487921
Validation loss: 2.2431640910717023

Epoch: 5| Step: 5
Training loss: 0.7051020906131985
Validation loss: 2.299651201456763

Epoch: 5| Step: 6
Training loss: 0.7196104041350927
Validation loss: 2.303663223269702

Epoch: 5| Step: 7
Training loss: 0.5825188149945827
Validation loss: 2.2462367406327717

Epoch: 5| Step: 8
Training loss: 0.7262451545304192
Validation loss: 2.2584452970915123

Epoch: 5| Step: 9
Training loss: 1.0872764840021991
Validation loss: 2.2900956691545944

Epoch: 5| Step: 10
Training loss: 0.7256466415292859
Validation loss: 2.2862377489681296

Epoch: 574| Step: 0
Training loss: 0.6144427823058984
Validation loss: 2.2599811235474965

Epoch: 5| Step: 1
Training loss: 0.9085828090018825
Validation loss: 2.308189854113362

Epoch: 5| Step: 2
Training loss: 1.3708004542681451
Validation loss: 2.3512038515881666

Epoch: 5| Step: 3
Training loss: 0.8605002578943322
Validation loss: 2.2632536753055588

Epoch: 5| Step: 4
Training loss: 0.5598719983609155
Validation loss: 2.2858328547608124

Epoch: 5| Step: 5
Training loss: 0.746713869917433
Validation loss: 2.25129139607287

Epoch: 5| Step: 6
Training loss: 0.48906792403068255
Validation loss: 2.323434817631084

Epoch: 5| Step: 7
Training loss: 1.0289584622354395
Validation loss: 2.295010211879055

Epoch: 5| Step: 8
Training loss: 0.5978992441897696
Validation loss: 2.325344070202245

Epoch: 5| Step: 9
Training loss: 0.7267171633597889
Validation loss: 2.2645279584412124

Epoch: 5| Step: 10
Training loss: 0.5814075071981976
Validation loss: 2.2865521437909964

Epoch: 575| Step: 0
Training loss: 0.5147165908420789
Validation loss: 2.218371742516161

Epoch: 5| Step: 1
Training loss: 0.8565667478448418
Validation loss: 2.3214073974633576

Epoch: 5| Step: 2
Training loss: 0.5678561890106553
Validation loss: 2.3083000995080827

Epoch: 5| Step: 3
Training loss: 0.548159534840957
Validation loss: 2.284514947020065

Epoch: 5| Step: 4
Training loss: 0.7569912265082721
Validation loss: 2.334460943721384

Epoch: 5| Step: 5
Training loss: 0.6525846710296912
Validation loss: 2.2612312776712007

Epoch: 5| Step: 6
Training loss: 0.7542443579670424
Validation loss: 2.3755545861869245

Epoch: 5| Step: 7
Training loss: 0.624288272924907
Validation loss: 2.294429990914973

Epoch: 5| Step: 8
Training loss: 0.7628019798019073
Validation loss: 2.284561241030681

Epoch: 5| Step: 9
Training loss: 0.9465875145121607
Validation loss: 2.2853588641617364

Epoch: 5| Step: 10
Training loss: 1.4034925765224109
Validation loss: 2.285874865378561

Epoch: 576| Step: 0
Training loss: 0.6851972030527448
Validation loss: 2.346379184297027

Epoch: 5| Step: 1
Training loss: 0.9436347512112632
Validation loss: 2.316108705946337

Epoch: 5| Step: 2
Training loss: 0.5130992351851918
Validation loss: 2.291323881344716

Epoch: 5| Step: 3
Training loss: 1.2649638485925812
Validation loss: 2.3068180104067104

Epoch: 5| Step: 4
Training loss: 0.578290271333067
Validation loss: 2.217558292754267

Epoch: 5| Step: 5
Training loss: 0.6169944654460708
Validation loss: 2.2704101897180973

Epoch: 5| Step: 6
Training loss: 0.624639407086599
Validation loss: 2.303380516406575

Epoch: 5| Step: 7
Training loss: 0.9159624291694135
Validation loss: 2.280686855552924

Epoch: 5| Step: 8
Training loss: 0.6617538713054455
Validation loss: 2.2638929977981976

Epoch: 5| Step: 9
Training loss: 0.5620607674520135
Validation loss: 2.3010663070907675

Epoch: 5| Step: 10
Training loss: 0.7560143127146192
Validation loss: 2.2863298766362927

Epoch: 577| Step: 0
Training loss: 0.634305205992279
Validation loss: 2.26688988058249

Epoch: 5| Step: 1
Training loss: 0.8208964494621679
Validation loss: 2.283208294486672

Epoch: 5| Step: 2
Training loss: 0.878443278127779
Validation loss: 2.2933466189552427

Epoch: 5| Step: 3
Training loss: 1.3619160196850182
Validation loss: 2.323012076100189

Epoch: 5| Step: 4
Training loss: 0.6615287237685408
Validation loss: 2.2562798865853986

Epoch: 5| Step: 5
Training loss: 0.5985284312911865
Validation loss: 2.318850364333928

Epoch: 5| Step: 6
Training loss: 0.617408881742778
Validation loss: 2.2912816724564147

Epoch: 5| Step: 7
Training loss: 0.7234635251597922
Validation loss: 2.2278080459942444

Epoch: 5| Step: 8
Training loss: 0.9451188764026905
Validation loss: 2.3428398744281806

Epoch: 5| Step: 9
Training loss: 0.7704818199037834
Validation loss: 2.332212820350222

Epoch: 5| Step: 10
Training loss: 0.6097894872850841
Validation loss: 2.3442353105049802

Epoch: 578| Step: 0
Training loss: 0.6638581354164365
Validation loss: 2.2540185402431416

Epoch: 5| Step: 1
Training loss: 0.5577496372992868
Validation loss: 2.3327451369612895

Epoch: 5| Step: 2
Training loss: 0.8968255883405674
Validation loss: 2.2956625683867644

Epoch: 5| Step: 3
Training loss: 0.6066158871786663
Validation loss: 2.2845039305367485

Epoch: 5| Step: 4
Training loss: 0.7907166092462254
Validation loss: 2.3174953147570996

Epoch: 5| Step: 5
Training loss: 0.5867623944056335
Validation loss: 2.283468022545785

Epoch: 5| Step: 6
Training loss: 0.6365393637496296
Validation loss: 2.3657229222886835

Epoch: 5| Step: 7
Training loss: 0.5911950806481464
Validation loss: 2.30013232971777

Epoch: 5| Step: 8
Training loss: 0.7006593919355808
Validation loss: 2.1837768113998393

Epoch: 5| Step: 9
Training loss: 0.5405976922519777
Validation loss: 2.2677131735495175

Epoch: 5| Step: 10
Training loss: 1.403398802280445
Validation loss: 2.193099730983282

Epoch: 579| Step: 0
Training loss: 0.9492338830816904
Validation loss: 2.2537651757896486

Epoch: 5| Step: 1
Training loss: 0.6833039895789648
Validation loss: 2.2874820602056913

Epoch: 5| Step: 2
Training loss: 0.6226784744029759
Validation loss: 2.2663922134971872

Epoch: 5| Step: 3
Training loss: 1.3234081656887946
Validation loss: 2.3086994744439893

Epoch: 5| Step: 4
Training loss: 0.8185355422471366
Validation loss: 2.2231233631735625

Epoch: 5| Step: 5
Training loss: 0.8253641711941113
Validation loss: 2.2837743498373504

Epoch: 5| Step: 6
Training loss: 0.5726978115180518
Validation loss: 2.2947990244612932

Epoch: 5| Step: 7
Training loss: 0.5632174737515065
Validation loss: 2.3106069191129865

Epoch: 5| Step: 8
Training loss: 0.6359533612571922
Validation loss: 2.373049189035859

Epoch: 5| Step: 9
Training loss: 0.8532069016711751
Validation loss: 2.320528308384976

Epoch: 5| Step: 10
Training loss: 0.6287804234843701
Validation loss: 2.2564207768733264

Epoch: 580| Step: 0
Training loss: 0.6078606887974588
Validation loss: 2.3163018479692683

Epoch: 5| Step: 1
Training loss: 0.7072431552376405
Validation loss: 2.2751845061749565

Epoch: 5| Step: 2
Training loss: 0.7390993621214389
Validation loss: 2.2937777404189603

Epoch: 5| Step: 3
Training loss: 0.71731656643914
Validation loss: 2.2183800977825636

Epoch: 5| Step: 4
Training loss: 1.4460894171898724
Validation loss: 2.2085008153327856

Epoch: 5| Step: 5
Training loss: 0.5419654358456376
Validation loss: 2.251691198599357

Epoch: 5| Step: 6
Training loss: 0.8728249286950853
Validation loss: 2.236762792238424

Epoch: 5| Step: 7
Training loss: 0.7740931573617361
Validation loss: 2.234656061172772

Epoch: 5| Step: 8
Training loss: 0.6119947120369487
Validation loss: 2.1742826077597734

Epoch: 5| Step: 9
Training loss: 0.7693740761671555
Validation loss: 2.2639130321944694

Epoch: 5| Step: 10
Training loss: 0.6037366147660379
Validation loss: 2.322082968826866

Epoch: 581| Step: 0
Training loss: 0.9309464913734664
Validation loss: 2.2570029503933

Epoch: 5| Step: 1
Training loss: 1.321202221009238
Validation loss: 2.303314447369009

Epoch: 5| Step: 2
Training loss: 0.7110430460962223
Validation loss: 2.3514812339471787

Epoch: 5| Step: 3
Training loss: 0.8834309057712205
Validation loss: 2.3945346010481745

Epoch: 5| Step: 4
Training loss: 0.801546503394458
Validation loss: 2.282932169800888

Epoch: 5| Step: 5
Training loss: 0.7028544223235144
Validation loss: 2.342942145797597

Epoch: 5| Step: 6
Training loss: 0.5878460128940982
Validation loss: 2.285341933827417

Epoch: 5| Step: 7
Training loss: 0.9564130382300056
Validation loss: 2.2276607433672306

Epoch: 5| Step: 8
Training loss: 0.6197465885556263
Validation loss: 2.255647356013479

Epoch: 5| Step: 9
Training loss: 0.4753054157709786
Validation loss: 2.24592151068833

Epoch: 5| Step: 10
Training loss: 0.8420817519344057
Validation loss: 2.227848786624176

Epoch: 582| Step: 0
Training loss: 0.6893124099082518
Validation loss: 2.241891174870071

Epoch: 5| Step: 1
Training loss: 0.5986830424258219
Validation loss: 2.275171350374758

Epoch: 5| Step: 2
Training loss: 0.4376302763569885
Validation loss: 2.255411315466535

Epoch: 5| Step: 3
Training loss: 0.5650010930531825
Validation loss: 2.3199827682858003

Epoch: 5| Step: 4
Training loss: 0.7599587084821582
Validation loss: 2.317785110851896

Epoch: 5| Step: 5
Training loss: 0.7354411644317917
Validation loss: 2.2866047748222487

Epoch: 5| Step: 6
Training loss: 1.593773860378797
Validation loss: 2.262014303524103

Epoch: 5| Step: 7
Training loss: 0.6300787096204132
Validation loss: 2.2463907738280624

Epoch: 5| Step: 8
Training loss: 0.5830586473548474
Validation loss: 2.3234550635345697

Epoch: 5| Step: 9
Training loss: 0.6479787697625622
Validation loss: 2.289612684327022

Epoch: 5| Step: 10
Training loss: 0.8151383113514191
Validation loss: 2.3023786038522394

Epoch: 583| Step: 0
Training loss: 0.605964506903927
Validation loss: 2.2563155864788405

Epoch: 5| Step: 1
Training loss: 0.6358629806309464
Validation loss: 2.274488793459599

Epoch: 5| Step: 2
Training loss: 0.706520591650385
Validation loss: 2.3658496833380234

Epoch: 5| Step: 3
Training loss: 1.3317603230077182
Validation loss: 2.275256174118383

Epoch: 5| Step: 4
Training loss: 0.6820298534610604
Validation loss: 2.317786744521845

Epoch: 5| Step: 5
Training loss: 0.7942621366097697
Validation loss: 2.289038087151261

Epoch: 5| Step: 6
Training loss: 0.476800624577022
Validation loss: 2.2840347273853614

Epoch: 5| Step: 7
Training loss: 0.7721527680907468
Validation loss: 2.3066741217672293

Epoch: 5| Step: 8
Training loss: 0.7847618516875905
Validation loss: 2.2941658852976237

Epoch: 5| Step: 9
Training loss: 1.0621608866146197
Validation loss: 2.256739264838634

Epoch: 5| Step: 10
Training loss: 0.5999140509000693
Validation loss: 2.2174172530124507

Epoch: 584| Step: 0
Training loss: 0.8210236146483496
Validation loss: 2.2828671798339024

Epoch: 5| Step: 1
Training loss: 0.565733042561878
Validation loss: 2.3427428085158626

Epoch: 5| Step: 2
Training loss: 0.693072321397432
Validation loss: 2.2638708439114996

Epoch: 5| Step: 3
Training loss: 0.879675634382051
Validation loss: 2.3168042569066865

Epoch: 5| Step: 4
Training loss: 0.7208200168665863
Validation loss: 2.38397861446338

Epoch: 5| Step: 5
Training loss: 0.43692875079863974
Validation loss: 2.391939297764466

Epoch: 5| Step: 6
Training loss: 0.6722293628973671
Validation loss: 2.2538771056694853

Epoch: 5| Step: 7
Training loss: 0.578536480019654
Validation loss: 2.263060213154155

Epoch: 5| Step: 8
Training loss: 0.6678218122233783
Validation loss: 2.3538693746609423

Epoch: 5| Step: 9
Training loss: 1.2791910142269238
Validation loss: 2.2631147589288996

Epoch: 5| Step: 10
Training loss: 0.6142790143306639
Validation loss: 2.288238615113156

Epoch: 585| Step: 0
Training loss: 0.9593945964091679
Validation loss: 2.2112217755927506

Epoch: 5| Step: 1
Training loss: 0.5758800996273484
Validation loss: 2.3399962019944307

Epoch: 5| Step: 2
Training loss: 0.7872801943210036
Validation loss: 2.4085950596459815

Epoch: 5| Step: 3
Training loss: 0.7933501280147579
Validation loss: 2.2615759220684084

Epoch: 5| Step: 4
Training loss: 0.5261621022608964
Validation loss: 2.33652220494566

Epoch: 5| Step: 5
Training loss: 0.6186534758138197
Validation loss: 2.30013905274736

Epoch: 5| Step: 6
Training loss: 0.6612582292026676
Validation loss: 2.3070035987164985

Epoch: 5| Step: 7
Training loss: 0.6748095013989157
Validation loss: 2.318877618570994

Epoch: 5| Step: 8
Training loss: 0.7306170797449002
Validation loss: 2.3218681661617637

Epoch: 5| Step: 9
Training loss: 1.3224503854339902
Validation loss: 2.3150997254332863

Epoch: 5| Step: 10
Training loss: 0.6519602030649284
Validation loss: 2.3168777572232266

Epoch: 586| Step: 0
Training loss: 0.8642309842013591
Validation loss: 2.301916263835679

Epoch: 5| Step: 1
Training loss: 0.5788489268309857
Validation loss: 2.3019691950882963

Epoch: 5| Step: 2
Training loss: 0.6443200430018248
Validation loss: 2.212716715846143

Epoch: 5| Step: 3
Training loss: 1.3019099565154122
Validation loss: 2.3017607829363884

Epoch: 5| Step: 4
Training loss: 0.6675803410474894
Validation loss: 2.2921902465826225

Epoch: 5| Step: 5
Training loss: 0.5450581479331319
Validation loss: 2.288347390080479

Epoch: 5| Step: 6
Training loss: 0.4871989500499947
Validation loss: 2.348980053715144

Epoch: 5| Step: 7
Training loss: 0.8481583404734513
Validation loss: 2.2925059078567744

Epoch: 5| Step: 8
Training loss: 0.5814153241313393
Validation loss: 2.238539404122512

Epoch: 5| Step: 9
Training loss: 0.9489295424704519
Validation loss: 2.3090013135557768

Epoch: 5| Step: 10
Training loss: 0.6432861786774683
Validation loss: 2.282601703785614

Epoch: 587| Step: 0
Training loss: 0.6605354213341953
Validation loss: 2.1980834331579895

Epoch: 5| Step: 1
Training loss: 0.5862659805169484
Validation loss: 2.3063441258926343

Epoch: 5| Step: 2
Training loss: 0.4422076217332693
Validation loss: 2.289295605066224

Epoch: 5| Step: 3
Training loss: 0.888814591905522
Validation loss: 2.309984405344015

Epoch: 5| Step: 4
Training loss: 0.7367061383329905
Validation loss: 2.2618690738450113

Epoch: 5| Step: 5
Training loss: 0.5856660086767936
Validation loss: 2.336402942450993

Epoch: 5| Step: 6
Training loss: 0.6753559207328833
Validation loss: 2.3045885223664806

Epoch: 5| Step: 7
Training loss: 0.6990418876436443
Validation loss: 2.2707072397314882

Epoch: 5| Step: 8
Training loss: 1.4094614446481268
Validation loss: 2.286497945220717

Epoch: 5| Step: 9
Training loss: 0.6056635881537111
Validation loss: 2.2823943457937537

Epoch: 5| Step: 10
Training loss: 0.81550756756413
Validation loss: 2.293661870160575

Epoch: 588| Step: 0
Training loss: 0.6811441838038901
Validation loss: 2.312955685599828

Epoch: 5| Step: 1
Training loss: 0.6918673513346355
Validation loss: 2.256686259337783

Epoch: 5| Step: 2
Training loss: 0.7470879845617135
Validation loss: 2.2493063633443544

Epoch: 5| Step: 3
Training loss: 0.6036837198668509
Validation loss: 2.2572579003420055

Epoch: 5| Step: 4
Training loss: 1.3214289442452158
Validation loss: 2.2024721091527257

Epoch: 5| Step: 5
Training loss: 0.6490889344872626
Validation loss: 2.270220052704317

Epoch: 5| Step: 6
Training loss: 0.684201782113737
Validation loss: 2.2823259157012843

Epoch: 5| Step: 7
Training loss: 0.4888896661117666
Validation loss: 2.324886925768583

Epoch: 5| Step: 8
Training loss: 0.8553878536905899
Validation loss: 2.286027092375464

Epoch: 5| Step: 9
Training loss: 0.5880156475972634
Validation loss: 2.2823991363400746

Epoch: 5| Step: 10
Training loss: 0.8531713424224614
Validation loss: 2.192477341651284

Epoch: 589| Step: 0
Training loss: 0.5511141643415025
Validation loss: 2.2545329774614102

Epoch: 5| Step: 1
Training loss: 0.6887170682673933
Validation loss: 2.295812432883873

Epoch: 5| Step: 2
Training loss: 0.6558530151713171
Validation loss: 2.206431763737871

Epoch: 5| Step: 3
Training loss: 0.8857262388095216
Validation loss: 2.3136737951879405

Epoch: 5| Step: 4
Training loss: 0.7036626879190925
Validation loss: 2.306848345125086

Epoch: 5| Step: 5
Training loss: 0.8079785572903436
Validation loss: 2.303291452489147

Epoch: 5| Step: 6
Training loss: 0.5237364698041685
Validation loss: 2.2356603568071414

Epoch: 5| Step: 7
Training loss: 1.3810415619873952
Validation loss: 2.3211015219002653

Epoch: 5| Step: 8
Training loss: 0.5860988649060176
Validation loss: 2.238378059567015

Epoch: 5| Step: 9
Training loss: 0.5299553241883742
Validation loss: 2.2561590606385233

Epoch: 5| Step: 10
Training loss: 0.465131734548611
Validation loss: 2.274547016779807

Epoch: 590| Step: 0
Training loss: 0.8072510411694979
Validation loss: 2.2971047520979626

Epoch: 5| Step: 1
Training loss: 0.7335308580180961
Validation loss: 2.2354815441041884

Epoch: 5| Step: 2
Training loss: 0.5204110977184379
Validation loss: 2.3057001207519643

Epoch: 5| Step: 3
Training loss: 0.6470421174386579
Validation loss: 2.2692822441243043

Epoch: 5| Step: 4
Training loss: 1.4618032409617427
Validation loss: 2.3474101243212204

Epoch: 5| Step: 5
Training loss: 0.7302575443535008
Validation loss: 2.2992829795738303

Epoch: 5| Step: 6
Training loss: 0.7257636816487456
Validation loss: 2.310330827774081

Epoch: 5| Step: 7
Training loss: 0.684609144037302
Validation loss: 2.259960504123765

Epoch: 5| Step: 8
Training loss: 0.5297793902245985
Validation loss: 2.2256967493148268

Epoch: 5| Step: 9
Training loss: 0.5697983553654805
Validation loss: 2.2781211544767213

Epoch: 5| Step: 10
Training loss: 0.7937087566443959
Validation loss: 2.236640941756863

Epoch: 591| Step: 0
Training loss: 0.6697250833436613
Validation loss: 2.2463373928958292

Epoch: 5| Step: 1
Training loss: 0.7117777459726212
Validation loss: 2.2606888103436216

Epoch: 5| Step: 2
Training loss: 0.6584556163220118
Validation loss: 2.2563177282272435

Epoch: 5| Step: 3
Training loss: 1.1963030133115118
Validation loss: 2.371094120313004

Epoch: 5| Step: 4
Training loss: 0.6789745889032428
Validation loss: 2.3474511394150848

Epoch: 5| Step: 5
Training loss: 0.8436379534888011
Validation loss: 2.2699816091418694

Epoch: 5| Step: 6
Training loss: 0.535558674555033
Validation loss: 2.3218651684511618

Epoch: 5| Step: 7
Training loss: 0.576714186111619
Validation loss: 2.2943238340736403

Epoch: 5| Step: 8
Training loss: 0.716090548144213
Validation loss: 2.4088936846993914

Epoch: 5| Step: 9
Training loss: 0.5971016149080256
Validation loss: 2.2776156052687693

Epoch: 5| Step: 10
Training loss: 0.9402062773616894
Validation loss: 2.345691332479585

Epoch: 592| Step: 0
Training loss: 0.4088571592897688
Validation loss: 2.2902833311512585

Epoch: 5| Step: 1
Training loss: 0.42337715310111546
Validation loss: 2.265528033044624

Epoch: 5| Step: 2
Training loss: 0.8241739848486669
Validation loss: 2.300323698780416

Epoch: 5| Step: 3
Training loss: 0.6389440254132696
Validation loss: 2.3223168218355017

Epoch: 5| Step: 4
Training loss: 0.6007703544511697
Validation loss: 2.299729999978653

Epoch: 5| Step: 5
Training loss: 0.5547323611748619
Validation loss: 2.274292423457009

Epoch: 5| Step: 6
Training loss: 0.607329873725607
Validation loss: 2.2193351608308665

Epoch: 5| Step: 7
Training loss: 1.0368997538016387
Validation loss: 2.29800354276417

Epoch: 5| Step: 8
Training loss: 0.8129828192266781
Validation loss: 2.264185658789873

Epoch: 5| Step: 9
Training loss: 1.4575216577664554
Validation loss: 2.3264627170577

Epoch: 5| Step: 10
Training loss: 0.5358456813799474
Validation loss: 2.285781125074372

Epoch: 593| Step: 0
Training loss: 0.6184335274975967
Validation loss: 2.3054885531647358

Epoch: 5| Step: 1
Training loss: 0.6992153828289429
Validation loss: 2.225654770206886

Epoch: 5| Step: 2
Training loss: 0.5331476483112592
Validation loss: 2.319590023265747

Epoch: 5| Step: 3
Training loss: 0.6660357833004259
Validation loss: 2.199529766120344

Epoch: 5| Step: 4
Training loss: 0.7193503153366423
Validation loss: 2.3453998438433494

Epoch: 5| Step: 5
Training loss: 0.6094974003643271
Validation loss: 2.2649881080880823

Epoch: 5| Step: 6
Training loss: 0.6936762770581727
Validation loss: 2.2954709799335973

Epoch: 5| Step: 7
Training loss: 1.3598289608690861
Validation loss: 2.219896671026739

Epoch: 5| Step: 8
Training loss: 0.7648142979438574
Validation loss: 2.2391383813434977

Epoch: 5| Step: 9
Training loss: 0.8683000593222967
Validation loss: 2.2728565791663944

Epoch: 5| Step: 10
Training loss: 0.7583857462310093
Validation loss: 2.277253811453936

Epoch: 594| Step: 0
Training loss: 0.6656352772165562
Validation loss: 2.2706016425341984

Epoch: 5| Step: 1
Training loss: 0.48763702618697
Validation loss: 2.210879139680919

Epoch: 5| Step: 2
Training loss: 0.8884239773252862
Validation loss: 2.3364249786122864

Epoch: 5| Step: 3
Training loss: 0.6261836764151028
Validation loss: 2.272526455198653

Epoch: 5| Step: 4
Training loss: 0.6742166919168509
Validation loss: 2.284710922019603

Epoch: 5| Step: 5
Training loss: 0.9083487445212212
Validation loss: 2.211774757890191

Epoch: 5| Step: 6
Training loss: 0.47198530133240735
Validation loss: 2.3188247659323125

Epoch: 5| Step: 7
Training loss: 0.5177057936495448
Validation loss: 2.2352989449811314

Epoch: 5| Step: 8
Training loss: 1.2375086832223523
Validation loss: 2.330402679225663

Epoch: 5| Step: 9
Training loss: 0.5431367627923398
Validation loss: 2.297348037370473

Epoch: 5| Step: 10
Training loss: 1.0450762197998
Validation loss: 2.262067316207978

Epoch: 595| Step: 0
Training loss: 0.6286743636927618
Validation loss: 2.241557908666844

Epoch: 5| Step: 1
Training loss: 0.6557111798749232
Validation loss: 2.3289366608889845

Epoch: 5| Step: 2
Training loss: 0.7675056326221457
Validation loss: 2.3322117381570493

Epoch: 5| Step: 3
Training loss: 1.2574066075858426
Validation loss: 2.2798277033661223

Epoch: 5| Step: 4
Training loss: 0.5298567903669428
Validation loss: 2.2547058437644054

Epoch: 5| Step: 5
Training loss: 0.6307722332649895
Validation loss: 2.2982381258593096

Epoch: 5| Step: 6
Training loss: 0.6366834806257535
Validation loss: 2.270417031810814

Epoch: 5| Step: 7
Training loss: 0.728187875938957
Validation loss: 2.2360402952079625

Epoch: 5| Step: 8
Training loss: 0.6568368830632922
Validation loss: 2.2278344566033503

Epoch: 5| Step: 9
Training loss: 0.6035129584096126
Validation loss: 2.1811124639862642

Epoch: 5| Step: 10
Training loss: 0.8462736746830472
Validation loss: 2.203691339787964

Epoch: 596| Step: 0
Training loss: 0.6887306988845041
Validation loss: 2.3178345274758856

Epoch: 5| Step: 1
Training loss: 0.6127569788360674
Validation loss: 2.2606061622834326

Epoch: 5| Step: 2
Training loss: 1.0313005146023477
Validation loss: 2.3318480087120412

Epoch: 5| Step: 3
Training loss: 0.5671344154254017
Validation loss: 2.284343971766802

Epoch: 5| Step: 4
Training loss: 0.8396848661369354
Validation loss: 2.248924670651703

Epoch: 5| Step: 5
Training loss: 0.6244841592656465
Validation loss: 2.3301940630018976

Epoch: 5| Step: 6
Training loss: 0.6662083679704368
Validation loss: 2.3415071482213095

Epoch: 5| Step: 7
Training loss: 0.7520621084527513
Validation loss: 2.3455476819249013

Epoch: 5| Step: 8
Training loss: 0.6509191524943431
Validation loss: 2.3079859835816015

Epoch: 5| Step: 9
Training loss: 1.305500576651777
Validation loss: 2.3220107467202142

Epoch: 5| Step: 10
Training loss: 0.4884404647649307
Validation loss: 2.2719725642873105

Epoch: 597| Step: 0
Training loss: 0.5535255404319863
Validation loss: 2.2454130092588147

Epoch: 5| Step: 1
Training loss: 0.4679869162674648
Validation loss: 2.2896562283888433

Epoch: 5| Step: 2
Training loss: 0.45344114784545353
Validation loss: 2.29199979007238

Epoch: 5| Step: 3
Training loss: 0.6074579356979589
Validation loss: 2.262395444511941

Epoch: 5| Step: 4
Training loss: 1.4832827112939513
Validation loss: 2.3316593919070994

Epoch: 5| Step: 5
Training loss: 0.7191523379522519
Validation loss: 2.2674035977473963

Epoch: 5| Step: 6
Training loss: 0.8143271662145066
Validation loss: 2.2593993389979263

Epoch: 5| Step: 7
Training loss: 0.5743420007999624
Validation loss: 2.341934022054725

Epoch: 5| Step: 8
Training loss: 0.8646455918535171
Validation loss: 2.335325376472434

Epoch: 5| Step: 9
Training loss: 0.7369905926972289
Validation loss: 2.2869256944152214

Epoch: 5| Step: 10
Training loss: 0.8090595617495123
Validation loss: 2.155638077818188

Epoch: 598| Step: 0
Training loss: 0.7360204969770662
Validation loss: 2.240567287711481

Epoch: 5| Step: 1
Training loss: 0.5426084297126464
Validation loss: 2.2681018471541443

Epoch: 5| Step: 2
Training loss: 0.737248541102578
Validation loss: 2.2467748173481366

Epoch: 5| Step: 3
Training loss: 0.6990352794819795
Validation loss: 2.1876686453084857

Epoch: 5| Step: 4
Training loss: 0.7503268403919502
Validation loss: 2.2087674467854375

Epoch: 5| Step: 5
Training loss: 0.4945555441434837
Validation loss: 2.1660878993564863

Epoch: 5| Step: 6
Training loss: 0.5508664383176392
Validation loss: 2.2932578831821493

Epoch: 5| Step: 7
Training loss: 1.3713056612497532
Validation loss: 2.2726869208518963

Epoch: 5| Step: 8
Training loss: 0.751322494220766
Validation loss: 2.2497357152867017

Epoch: 5| Step: 9
Training loss: 0.9519928633919257
Validation loss: 2.356087040672779

Epoch: 5| Step: 10
Training loss: 0.6720534242981963
Validation loss: 2.2715043390554075

Epoch: 599| Step: 0
Training loss: 0.6180251509323111
Validation loss: 2.316552228868392

Epoch: 5| Step: 1
Training loss: 0.8204496723108139
Validation loss: 2.2830943890296704

Epoch: 5| Step: 2
Training loss: 0.9285376353979099
Validation loss: 2.2924110212407394

Epoch: 5| Step: 3
Training loss: 0.6890329696313401
Validation loss: 2.3103003490300997

Epoch: 5| Step: 4
Training loss: 0.4604494776477268
Validation loss: 2.2432864071930383

Epoch: 5| Step: 5
Training loss: 0.4341036230151827
Validation loss: 2.2942646119597896

Epoch: 5| Step: 6
Training loss: 0.5789121475640047
Validation loss: 2.3019238614741457

Epoch: 5| Step: 7
Training loss: 0.4566829364841479
Validation loss: 2.210406622712533

Epoch: 5| Step: 8
Training loss: 0.604595859493346
Validation loss: 2.1627643109521304

Epoch: 5| Step: 9
Training loss: 0.9667452711725109
Validation loss: 2.2566009380817373

Epoch: 5| Step: 10
Training loss: 1.3992549701988848
Validation loss: 2.3202920686782056

Epoch: 600| Step: 0
Training loss: 0.9213496505485738
Validation loss: 2.3514016266435434

Epoch: 5| Step: 1
Training loss: 0.45022999925686313
Validation loss: 2.258856120757479

Epoch: 5| Step: 2
Training loss: 0.7565087577201963
Validation loss: 2.226657607345224

Epoch: 5| Step: 3
Training loss: 0.7249435929026651
Validation loss: 2.274340510956224

Epoch: 5| Step: 4
Training loss: 0.5170996991912256
Validation loss: 2.22976509168088

Epoch: 5| Step: 5
Training loss: 0.579434741251771
Validation loss: 2.324100260352412

Epoch: 5| Step: 6
Training loss: 1.2691700113310465
Validation loss: 2.349960644448513

Epoch: 5| Step: 7
Training loss: 0.4826970416040608
Validation loss: 2.225065596939613

Epoch: 5| Step: 8
Training loss: 0.5438922191849551
Validation loss: 2.2413537518124267

Epoch: 5| Step: 9
Training loss: 0.6147761985188507
Validation loss: 2.274756094257848

Epoch: 5| Step: 10
Training loss: 0.6161774688192067
Validation loss: 2.236844619894778

Epoch: 601| Step: 0
Training loss: 0.8369253151136026
Validation loss: 2.3066722701719073

Epoch: 5| Step: 1
Training loss: 0.6399039653534793
Validation loss: 2.248067504483675

Epoch: 5| Step: 2
Training loss: 0.7429784475309384
Validation loss: 2.2394852746748084

Epoch: 5| Step: 3
Training loss: 0.6167408256358679
Validation loss: 2.272051622616993

Epoch: 5| Step: 4
Training loss: 0.6517754780699008
Validation loss: 2.279947969889661

Epoch: 5| Step: 5
Training loss: 0.6303026796028883
Validation loss: 2.180918901694305

Epoch: 5| Step: 6
Training loss: 0.6929357389653233
Validation loss: 2.256167869105869

Epoch: 5| Step: 7
Training loss: 0.9395819752099033
Validation loss: 2.301638838192035

Epoch: 5| Step: 8
Training loss: 0.623390222731118
Validation loss: 2.346744247118665

Epoch: 5| Step: 9
Training loss: 1.264827288496353
Validation loss: 2.2848811382693492

Epoch: 5| Step: 10
Training loss: 0.4043803842884768
Validation loss: 2.228999638694588

Epoch: 602| Step: 0
Training loss: 0.6703712135334617
Validation loss: 2.2138488057471504

Epoch: 5| Step: 1
Training loss: 0.4964069669272265
Validation loss: 2.2279337867350857

Epoch: 5| Step: 2
Training loss: 0.4896328491845885
Validation loss: 2.235954647615163

Epoch: 5| Step: 3
Training loss: 0.5620402735690216
Validation loss: 2.2709473337363373

Epoch: 5| Step: 4
Training loss: 0.7889094440337371
Validation loss: 2.261983164679771

Epoch: 5| Step: 5
Training loss: 0.8678103092043693
Validation loss: 2.3403281518257497

Epoch: 5| Step: 6
Training loss: 0.46312392266852187
Validation loss: 2.2401235384429095

Epoch: 5| Step: 7
Training loss: 0.8145960766965448
Validation loss: 2.1978561874378912

Epoch: 5| Step: 8
Training loss: 0.5208700612151927
Validation loss: 2.2404790275284125

Epoch: 5| Step: 9
Training loss: 0.7537903375412696
Validation loss: 2.2525048686361386

Epoch: 5| Step: 10
Training loss: 1.3465173746596495
Validation loss: 2.245265780337845

Epoch: 603| Step: 0
Training loss: 0.7612972952020625
Validation loss: 2.2933736967201113

Epoch: 5| Step: 1
Training loss: 0.6251948053035568
Validation loss: 2.2073709833178854

Epoch: 5| Step: 2
Training loss: 0.6011763980886183
Validation loss: 2.225324615422448

Epoch: 5| Step: 3
Training loss: 0.7821328705910932
Validation loss: 2.2467087312601026

Epoch: 5| Step: 4
Training loss: 0.9259798826726591
Validation loss: 2.3490040495927382

Epoch: 5| Step: 5
Training loss: 0.5959929714780527
Validation loss: 2.272699571018371

Epoch: 5| Step: 6
Training loss: 0.5919849361326702
Validation loss: 2.332956381056754

Epoch: 5| Step: 7
Training loss: 0.5466504317098134
Validation loss: 2.2873899201027665

Epoch: 5| Step: 8
Training loss: 0.6328244384769764
Validation loss: 2.322177866779219

Epoch: 5| Step: 9
Training loss: 1.2818595552746224
Validation loss: 2.267229052537046

Epoch: 5| Step: 10
Training loss: 0.651140233525695
Validation loss: 2.224536643519795

Epoch: 604| Step: 0
Training loss: 0.5128445653287708
Validation loss: 2.280230533868776

Epoch: 5| Step: 1
Training loss: 0.5387757685931037
Validation loss: 2.196043744124211

Epoch: 5| Step: 2
Training loss: 0.6625984208756872
Validation loss: 2.2815089026175186

Epoch: 5| Step: 3
Training loss: 0.5086209537479222
Validation loss: 2.2472510790215496

Epoch: 5| Step: 4
Training loss: 0.41765425784702326
Validation loss: 2.2839062765551987

Epoch: 5| Step: 5
Training loss: 0.7131681973131191
Validation loss: 2.23387721935135

Epoch: 5| Step: 6
Training loss: 0.5817693850898532
Validation loss: 2.238947200838518

Epoch: 5| Step: 7
Training loss: 0.4298931323367837
Validation loss: 2.2615684178634874

Epoch: 5| Step: 8
Training loss: 0.9461437385387779
Validation loss: 2.2165828209556535

Epoch: 5| Step: 9
Training loss: 1.3116210992032191
Validation loss: 2.2193305587522523

Epoch: 5| Step: 10
Training loss: 0.7892451311021081
Validation loss: 2.2525701649835965

Epoch: 605| Step: 0
Training loss: 0.5953349241904348
Validation loss: 2.2949422138179463

Epoch: 5| Step: 1
Training loss: 0.6103730953232926
Validation loss: 2.3551721384932107

Epoch: 5| Step: 2
Training loss: 0.8916341184457067
Validation loss: 2.378194740847449

Epoch: 5| Step: 3
Training loss: 1.3842614120831447
Validation loss: 2.355226874931729

Epoch: 5| Step: 4
Training loss: 0.6220614014949967
Validation loss: 2.3077140500561826

Epoch: 5| Step: 5
Training loss: 0.6299948895716402
Validation loss: 2.2666429257672687

Epoch: 5| Step: 6
Training loss: 0.41083936571111995
Validation loss: 2.303404360574287

Epoch: 5| Step: 7
Training loss: 0.5402744049445322
Validation loss: 2.232623218373851

Epoch: 5| Step: 8
Training loss: 0.796809399466437
Validation loss: 2.2695034596476678

Epoch: 5| Step: 9
Training loss: 0.677934292816372
Validation loss: 2.2763596216879005

Epoch: 5| Step: 10
Training loss: 0.6202999536509037
Validation loss: 2.3021131291871977

Epoch: 606| Step: 0
Training loss: 0.6268875705755541
Validation loss: 2.190594056877434

Epoch: 5| Step: 1
Training loss: 0.5374922618752527
Validation loss: 2.3760776449634786

Epoch: 5| Step: 2
Training loss: 0.7057111439861109
Validation loss: 2.3027258036657634

Epoch: 5| Step: 3
Training loss: 0.6563580060817407
Validation loss: 2.363209242280098

Epoch: 5| Step: 4
Training loss: 0.8696318534788281
Validation loss: 2.265908813804557

Epoch: 5| Step: 5
Training loss: 1.2275405191854423
Validation loss: 2.3058374838499636

Epoch: 5| Step: 6
Training loss: 0.37558365145189415
Validation loss: 2.2555049437929906

Epoch: 5| Step: 7
Training loss: 0.7699632158410696
Validation loss: 2.23794506723618

Epoch: 5| Step: 8
Training loss: 0.6031865083628796
Validation loss: 2.2265278521182355

Epoch: 5| Step: 9
Training loss: 0.6414732783022954
Validation loss: 2.2462703015891905

Epoch: 5| Step: 10
Training loss: 0.7699347662850481
Validation loss: 2.24954977168296

Epoch: 607| Step: 0
Training loss: 0.4513259888701281
Validation loss: 2.1988285766044027

Epoch: 5| Step: 1
Training loss: 0.5451941681497493
Validation loss: 2.2060249900143565

Epoch: 5| Step: 2
Training loss: 0.6077204519359731
Validation loss: 2.2859211206334735

Epoch: 5| Step: 3
Training loss: 0.9169015402875909
Validation loss: 2.270061788212697

Epoch: 5| Step: 4
Training loss: 0.6458136314545354
Validation loss: 2.385478695485106

Epoch: 5| Step: 5
Training loss: 1.2937911262056934
Validation loss: 2.2939946872550854

Epoch: 5| Step: 6
Training loss: 0.49150712049901
Validation loss: 2.345520159391855

Epoch: 5| Step: 7
Training loss: 0.6741777480511016
Validation loss: 2.3096239596550032

Epoch: 5| Step: 8
Training loss: 0.6361609513896606
Validation loss: 2.24428813962884

Epoch: 5| Step: 9
Training loss: 0.7206444858586473
Validation loss: 2.345866570440981

Epoch: 5| Step: 10
Training loss: 0.6805824876719848
Validation loss: 2.260568768940348

Epoch: 608| Step: 0
Training loss: 0.6626488617330222
Validation loss: 2.1755294561321405

Epoch: 5| Step: 1
Training loss: 0.7281042988335246
Validation loss: 2.1953581013105543

Epoch: 5| Step: 2
Training loss: 1.3669793978759242
Validation loss: 2.180666295008509

Epoch: 5| Step: 3
Training loss: 0.5223272419933195
Validation loss: 2.202268141325798

Epoch: 5| Step: 4
Training loss: 0.79052067094688
Validation loss: 2.2893312055651567

Epoch: 5| Step: 5
Training loss: 0.6504073498840812
Validation loss: 2.2262602593219856

Epoch: 5| Step: 6
Training loss: 0.6892723084133676
Validation loss: 2.2704918006123322

Epoch: 5| Step: 7
Training loss: 0.6994562438329476
Validation loss: 2.328589787831942

Epoch: 5| Step: 8
Training loss: 0.5185593139671942
Validation loss: 2.2206470912709375

Epoch: 5| Step: 9
Training loss: 0.6297994632429741
Validation loss: 2.302201280610213

Epoch: 5| Step: 10
Training loss: 0.8504734950412445
Validation loss: 2.2935527050870776

Epoch: 609| Step: 0
Training loss: 0.7940039806578469
Validation loss: 2.2909677672173263

Epoch: 5| Step: 1
Training loss: 0.7201683313900364
Validation loss: 2.3239688470427167

Epoch: 5| Step: 2
Training loss: 0.6703412714476634
Validation loss: 2.3086604415188465

Epoch: 5| Step: 3
Training loss: 0.5856431857677714
Validation loss: 2.2300654950965444

Epoch: 5| Step: 4
Training loss: 1.399229028132616
Validation loss: 2.306803172965679

Epoch: 5| Step: 5
Training loss: 0.5253687006690492
Validation loss: 2.3019136065495807

Epoch: 5| Step: 6
Training loss: 0.7491026914760812
Validation loss: 2.282722633326152

Epoch: 5| Step: 7
Training loss: 0.5590203263659547
Validation loss: 2.242471800477176

Epoch: 5| Step: 8
Training loss: 0.5433658273123201
Validation loss: 2.2532077862335225

Epoch: 5| Step: 9
Training loss: 0.6784930421434517
Validation loss: 2.192993550823581

Epoch: 5| Step: 10
Training loss: 0.5358027430573433
Validation loss: 2.275177913917833

Epoch: 610| Step: 0
Training loss: 0.6226422421974938
Validation loss: 2.2282460061209823

Epoch: 5| Step: 1
Training loss: 0.792856180253052
Validation loss: 2.1958954107676916

Epoch: 5| Step: 2
Training loss: 0.5392940410974463
Validation loss: 2.365247678017742

Epoch: 5| Step: 3
Training loss: 0.7667591880518978
Validation loss: 2.229391346801291

Epoch: 5| Step: 4
Training loss: 0.5850460391798035
Validation loss: 2.235414653950303

Epoch: 5| Step: 5
Training loss: 0.44283458555032784
Validation loss: 2.2443976425611583

Epoch: 5| Step: 6
Training loss: 0.7404193898589018
Validation loss: 2.293594061820722

Epoch: 5| Step: 7
Training loss: 0.6239826983076718
Validation loss: 2.3281986659601

Epoch: 5| Step: 8
Training loss: 0.4012825684090185
Validation loss: 2.2864697971113137

Epoch: 5| Step: 9
Training loss: 0.663107375864431
Validation loss: 2.2474983646423783

Epoch: 5| Step: 10
Training loss: 1.3988946774738085
Validation loss: 2.3131790139815545

Epoch: 611| Step: 0
Training loss: 0.7189922339214956
Validation loss: 2.2718140771402187

Epoch: 5| Step: 1
Training loss: 0.47504232619583625
Validation loss: 2.2548034296147166

Epoch: 5| Step: 2
Training loss: 0.6346220118114365
Validation loss: 2.327382851104038

Epoch: 5| Step: 3
Training loss: 0.6500613550426023
Validation loss: 2.2268362041493055

Epoch: 5| Step: 4
Training loss: 0.7622772907765256
Validation loss: 2.249694040020981

Epoch: 5| Step: 5
Training loss: 0.5779483370593579
Validation loss: 2.2922184150369693

Epoch: 5| Step: 6
Training loss: 1.2701233407448884
Validation loss: 2.2418239808050995

Epoch: 5| Step: 7
Training loss: 0.6518633781267578
Validation loss: 2.2649347393117583

Epoch: 5| Step: 8
Training loss: 0.5482387160737281
Validation loss: 2.193342421211416

Epoch: 5| Step: 9
Training loss: 0.709803378791646
Validation loss: 2.2257394912846364

Epoch: 5| Step: 10
Training loss: 0.8320498039075283
Validation loss: 2.365455578958388

Epoch: 612| Step: 0
Training loss: 0.7950193453180442
Validation loss: 2.225285706998331

Epoch: 5| Step: 1
Training loss: 0.8580005752254772
Validation loss: 2.219633598075962

Epoch: 5| Step: 2
Training loss: 0.669737098056964
Validation loss: 2.3286771690032455

Epoch: 5| Step: 3
Training loss: 0.612065756874141
Validation loss: 2.223757858983239

Epoch: 5| Step: 4
Training loss: 0.5941653054031394
Validation loss: 2.2970365258637884

Epoch: 5| Step: 5
Training loss: 0.5442686643663717
Validation loss: 2.2388673920537783

Epoch: 5| Step: 6
Training loss: 0.6509390915490892
Validation loss: 2.3030787316614525

Epoch: 5| Step: 7
Training loss: 0.722461694870155
Validation loss: 2.1742007206901692

Epoch: 5| Step: 8
Training loss: 0.49431127684901643
Validation loss: 2.160790499898928

Epoch: 5| Step: 9
Training loss: 1.5156502475798603
Validation loss: 2.1506927532221654

Epoch: 5| Step: 10
Training loss: 0.5441315090842601
Validation loss: 2.234897253315686

Epoch: 613| Step: 0
Training loss: 0.8176297597532264
Validation loss: 2.2403998151270668

Epoch: 5| Step: 1
Training loss: 0.6304201658075732
Validation loss: 2.2371488793272243

Epoch: 5| Step: 2
Training loss: 0.7961899299659363
Validation loss: 2.285111441083961

Epoch: 5| Step: 3
Training loss: 0.4480309747137786
Validation loss: 2.2550615453637555

Epoch: 5| Step: 4
Training loss: 1.4164666240300077
Validation loss: 2.2695537761792886

Epoch: 5| Step: 5
Training loss: 0.7962417330230385
Validation loss: 2.3143425507250797

Epoch: 5| Step: 6
Training loss: 0.8037749365798932
Validation loss: 2.2324056071673066

Epoch: 5| Step: 7
Training loss: 0.48211272368800384
Validation loss: 2.2703510038239254

Epoch: 5| Step: 8
Training loss: 0.5990273947222796
Validation loss: 2.337135162932198

Epoch: 5| Step: 9
Training loss: 0.5395008461055537
Validation loss: 2.242043493590821

Epoch: 5| Step: 10
Training loss: 0.5225729278611698
Validation loss: 2.352369023056778

Epoch: 614| Step: 0
Training loss: 0.7623967601111861
Validation loss: 2.2645295026061327

Epoch: 5| Step: 1
Training loss: 0.9165599645299273
Validation loss: 2.3190436245831383

Epoch: 5| Step: 2
Training loss: 0.7162202599893726
Validation loss: 2.2384614619036243

Epoch: 5| Step: 3
Training loss: 0.5116799900430585
Validation loss: 2.325571277609038

Epoch: 5| Step: 4
Training loss: 0.5491345184980889
Validation loss: 2.217710869535182

Epoch: 5| Step: 5
Training loss: 0.6042245941234613
Validation loss: 2.238453164413967

Epoch: 5| Step: 6
Training loss: 1.262080137858098
Validation loss: 2.2635083770746625

Epoch: 5| Step: 7
Training loss: 0.5324681285042066
Validation loss: 2.294584748503792

Epoch: 5| Step: 8
Training loss: 0.5547516476785912
Validation loss: 2.207535030777474

Epoch: 5| Step: 9
Training loss: 0.6981172036305099
Validation loss: 2.242845568266466

Epoch: 5| Step: 10
Training loss: 0.5420206423326573
Validation loss: 2.1893874386109746

Epoch: 615| Step: 0
Training loss: 1.2171002495066885
Validation loss: 2.2919919347143147

Epoch: 5| Step: 1
Training loss: 0.5050542898078434
Validation loss: 2.27727912148785

Epoch: 5| Step: 2
Training loss: 0.681768214135983
Validation loss: 2.297902722025816

Epoch: 5| Step: 3
Training loss: 0.5412817895905423
Validation loss: 2.343467630857399

Epoch: 5| Step: 4
Training loss: 0.5927147624153742
Validation loss: 2.2652014495223534

Epoch: 5| Step: 5
Training loss: 0.8549204772084427
Validation loss: 2.32430566570228

Epoch: 5| Step: 6
Training loss: 0.5557925003796299
Validation loss: 2.257377291039319

Epoch: 5| Step: 7
Training loss: 0.6804629758114656
Validation loss: 2.127078545393349

Epoch: 5| Step: 8
Training loss: 0.6369865649945939
Validation loss: 2.1965883929636805

Epoch: 5| Step: 9
Training loss: 1.0069871228407128
Validation loss: 2.1991910628711353

Epoch: 5| Step: 10
Training loss: 0.7421281088104851
Validation loss: 2.246546954372427

Epoch: 616| Step: 0
Training loss: 0.5482162105221194
Validation loss: 2.2049122681347395

Epoch: 5| Step: 1
Training loss: 0.5581827051847136
Validation loss: 2.2345140205801632

Epoch: 5| Step: 2
Training loss: 0.7370974217806688
Validation loss: 2.169415134775718

Epoch: 5| Step: 3
Training loss: 0.583521375547351
Validation loss: 2.228794581683347

Epoch: 5| Step: 4
Training loss: 1.464144527128241
Validation loss: 2.2640061051086997

Epoch: 5| Step: 5
Training loss: 0.6370173497165319
Validation loss: 2.32826554740708

Epoch: 5| Step: 6
Training loss: 0.5817098818422456
Validation loss: 2.2855613896967326

Epoch: 5| Step: 7
Training loss: 0.5592513315323934
Validation loss: 2.2169677298465915

Epoch: 5| Step: 8
Training loss: 0.4650362241386813
Validation loss: 2.297798984904144

Epoch: 5| Step: 9
Training loss: 0.7484840330817487
Validation loss: 2.21813810762616

Epoch: 5| Step: 10
Training loss: 0.7051899786907878
Validation loss: 2.1684014196540033

Epoch: 617| Step: 0
Training loss: 1.2755615680628933
Validation loss: 2.315138868492187

Epoch: 5| Step: 1
Training loss: 0.386433505814252
Validation loss: 2.195722759193404

Epoch: 5| Step: 2
Training loss: 0.5932030919623997
Validation loss: 2.2808689502116577

Epoch: 5| Step: 3
Training loss: 0.8065046144957712
Validation loss: 2.3033145475410253

Epoch: 5| Step: 4
Training loss: 0.5703610177500948
Validation loss: 2.272649745457867

Epoch: 5| Step: 5
Training loss: 0.928310785419255
Validation loss: 2.2006396207271828

Epoch: 5| Step: 6
Training loss: 0.5436876327000539
Validation loss: 2.245325415099837

Epoch: 5| Step: 7
Training loss: 0.5554578294498737
Validation loss: 2.3034923938598655

Epoch: 5| Step: 8
Training loss: 0.5126409301980142
Validation loss: 2.3087644218100407

Epoch: 5| Step: 9
Training loss: 0.6222104045075856
Validation loss: 2.2647069749336217

Epoch: 5| Step: 10
Training loss: 0.5168548424606009
Validation loss: 2.2498578330898638

Epoch: 618| Step: 0
Training loss: 0.5016863221482246
Validation loss: 2.2482354914529337

Epoch: 5| Step: 1
Training loss: 0.5516590671457651
Validation loss: 2.24873834191457

Epoch: 5| Step: 2
Training loss: 0.5193074253342559
Validation loss: 2.2297482123464762

Epoch: 5| Step: 3
Training loss: 0.8267729536364724
Validation loss: 2.2202689225916226

Epoch: 5| Step: 4
Training loss: 0.5185485379703926
Validation loss: 2.2721193269248725

Epoch: 5| Step: 5
Training loss: 0.5588236782388223
Validation loss: 2.2427327986256977

Epoch: 5| Step: 6
Training loss: 0.5588927102521812
Validation loss: 2.253314554097755

Epoch: 5| Step: 7
Training loss: 0.6456236396324693
Validation loss: 2.3550933874570346

Epoch: 5| Step: 8
Training loss: 0.5776295472036059
Validation loss: 2.2507815593069145

Epoch: 5| Step: 9
Training loss: 1.0287555813087546
Validation loss: 2.209355764433956

Epoch: 5| Step: 10
Training loss: 1.4335245640662213
Validation loss: 2.2827812132093386

Epoch: 619| Step: 0
Training loss: 1.2051238757681095
Validation loss: 2.218092709970059

Epoch: 5| Step: 1
Training loss: 0.9100365948916852
Validation loss: 2.299619319758839

Epoch: 5| Step: 2
Training loss: 0.4887372138650931
Validation loss: 2.2614903477168378

Epoch: 5| Step: 3
Training loss: 0.41360623034247723
Validation loss: 2.215667289655317

Epoch: 5| Step: 4
Training loss: 0.6959735642446893
Validation loss: 2.3034764777007815

Epoch: 5| Step: 5
Training loss: 0.4965965246375464
Validation loss: 2.2462338006298417

Epoch: 5| Step: 6
Training loss: 0.8304835507499554
Validation loss: 2.225313017906585

Epoch: 5| Step: 7
Training loss: 0.6189738388927001
Validation loss: 2.249025748057023

Epoch: 5| Step: 8
Training loss: 0.6449401714241159
Validation loss: 2.2158731172005512

Epoch: 5| Step: 9
Training loss: 0.5877839051774372
Validation loss: 2.2333663234407655

Epoch: 5| Step: 10
Training loss: 0.5403528388405477
Validation loss: 2.2396797916810343

Epoch: 620| Step: 0
Training loss: 0.46444938664580127
Validation loss: 2.2632921994704502

Epoch: 5| Step: 1
Training loss: 0.5911733029966978
Validation loss: 2.247693603061076

Epoch: 5| Step: 2
Training loss: 1.0574262874695812
Validation loss: 2.223606741673374

Epoch: 5| Step: 3
Training loss: 0.5812471471736999
Validation loss: 2.2361627734250233

Epoch: 5| Step: 4
Training loss: 0.6591467050848651
Validation loss: 2.264899043975042

Epoch: 5| Step: 5
Training loss: 0.5232093940303463
Validation loss: 2.2927416427133864

Epoch: 5| Step: 6
Training loss: 0.5818238881052126
Validation loss: 2.258937915857647

Epoch: 5| Step: 7
Training loss: 0.6113251268599729
Validation loss: 2.2979231259423845

Epoch: 5| Step: 8
Training loss: 0.9054040577960402
Validation loss: 2.331186540450255

Epoch: 5| Step: 9
Training loss: 1.2523073358887638
Validation loss: 2.2479958033841667

Epoch: 5| Step: 10
Training loss: 0.5718967954724269
Validation loss: 2.322230533811594

Epoch: 621| Step: 0
Training loss: 0.7116717225668686
Validation loss: 2.265907845329197

Epoch: 5| Step: 1
Training loss: 0.660259893283294
Validation loss: 2.1742202845389196

Epoch: 5| Step: 2
Training loss: 0.9380327936003408
Validation loss: 2.243382511099357

Epoch: 5| Step: 3
Training loss: 1.3874484868840047
Validation loss: 2.2527568146350294

Epoch: 5| Step: 4
Training loss: 0.5620814461625724
Validation loss: 2.2528225480566864

Epoch: 5| Step: 5
Training loss: 0.7415836889661417
Validation loss: 2.2163031843588636

Epoch: 5| Step: 6
Training loss: 0.7498757736321611
Validation loss: 2.1927790297297247

Epoch: 5| Step: 7
Training loss: 0.4816987181293061
Validation loss: 2.1910911469364804

Epoch: 5| Step: 8
Training loss: 0.5631931590535831
Validation loss: 2.1789472627578603

Epoch: 5| Step: 9
Training loss: 0.6333576726837639
Validation loss: 2.2153959132746217

Epoch: 5| Step: 10
Training loss: 0.673936608468964
Validation loss: 2.267979523110501

Epoch: 622| Step: 0
Training loss: 0.5241745840646179
Validation loss: 2.2445068391855867

Epoch: 5| Step: 1
Training loss: 0.4396691194174988
Validation loss: 2.199027160343691

Epoch: 5| Step: 2
Training loss: 0.7891565399030415
Validation loss: 2.226431587773328

Epoch: 5| Step: 3
Training loss: 0.596611056462396
Validation loss: 2.343102457703749

Epoch: 5| Step: 4
Training loss: 0.5542100544008857
Validation loss: 2.263604425976995

Epoch: 5| Step: 5
Training loss: 0.5888306209414639
Validation loss: 2.317174537599257

Epoch: 5| Step: 6
Training loss: 0.6061463778709076
Validation loss: 2.2436268237724653

Epoch: 5| Step: 7
Training loss: 1.2339381640102607
Validation loss: 2.294588144962244

Epoch: 5| Step: 8
Training loss: 0.9748127940992471
Validation loss: 2.240283961975284

Epoch: 5| Step: 9
Training loss: 0.6633253606320334
Validation loss: 2.221960473881755

Epoch: 5| Step: 10
Training loss: 0.7142317606780542
Validation loss: 2.1711437510815133

Epoch: 623| Step: 0
Training loss: 0.6385614142130984
Validation loss: 2.2255267903771303

Epoch: 5| Step: 1
Training loss: 0.8400489379046905
Validation loss: 2.196578456826358

Epoch: 5| Step: 2
Training loss: 0.6758431643309172
Validation loss: 2.256065983307632

Epoch: 5| Step: 3
Training loss: 1.2661808818243294
Validation loss: 2.262217194758058

Epoch: 5| Step: 4
Training loss: 0.7495648393227894
Validation loss: 2.243454591612495

Epoch: 5| Step: 5
Training loss: 0.5709331479713176
Validation loss: 2.249112504506671

Epoch: 5| Step: 6
Training loss: 0.4357095423173336
Validation loss: 2.237562144260852

Epoch: 5| Step: 7
Training loss: 0.5776888774627174
Validation loss: 2.205402937134726

Epoch: 5| Step: 8
Training loss: 0.6132275989171806
Validation loss: 2.2407761667920942

Epoch: 5| Step: 9
Training loss: 0.8534472545064928
Validation loss: 2.1679219845516395

Epoch: 5| Step: 10
Training loss: 0.5351706454157747
Validation loss: 2.2002629529397884

Epoch: 624| Step: 0
Training loss: 0.989559658503508
Validation loss: 2.2976081821442835

Epoch: 5| Step: 1
Training loss: 0.6002652932808167
Validation loss: 2.282600786194596

Epoch: 5| Step: 2
Training loss: 0.6355555856737309
Validation loss: 2.2052799223599298

Epoch: 5| Step: 3
Training loss: 0.7229786746413798
Validation loss: 2.268131609512735

Epoch: 5| Step: 4
Training loss: 0.41432250154939193
Validation loss: 2.151080659274902

Epoch: 5| Step: 5
Training loss: 0.6985227434678566
Validation loss: 2.275092376227238

Epoch: 5| Step: 6
Training loss: 0.45049090828120286
Validation loss: 2.2206903477602764

Epoch: 5| Step: 7
Training loss: 0.42504791662829466
Validation loss: 2.2527882027737496

Epoch: 5| Step: 8
Training loss: 0.5603082394796958
Validation loss: 2.2301593311097268

Epoch: 5| Step: 9
Training loss: 0.46350234289924863
Validation loss: 2.2736298293997286

Epoch: 5| Step: 10
Training loss: 1.3949826148532454
Validation loss: 2.3509358724144622

Epoch: 625| Step: 0
Training loss: 0.8481645949586961
Validation loss: 2.2592859119825746

Epoch: 5| Step: 1
Training loss: 0.6940327772554568
Validation loss: 2.345172016718928

Epoch: 5| Step: 2
Training loss: 0.5988772019433595
Validation loss: 2.2824874412123637

Epoch: 5| Step: 3
Training loss: 0.5916318505972773
Validation loss: 2.2681316920237156

Epoch: 5| Step: 4
Training loss: 1.365202940222868
Validation loss: 2.3144055923559215

Epoch: 5| Step: 5
Training loss: 0.7257727566028069
Validation loss: 2.270518680105004

Epoch: 5| Step: 6
Training loss: 0.8163914656327126
Validation loss: 2.2446030501663357

Epoch: 5| Step: 7
Training loss: 0.6373765508016037
Validation loss: 2.244344388989869

Epoch: 5| Step: 8
Training loss: 0.6019881587939205
Validation loss: 2.231894434698178

Epoch: 5| Step: 9
Training loss: 0.3987348232550041
Validation loss: 2.25313283357329

Epoch: 5| Step: 10
Training loss: 0.5667822280558178
Validation loss: 2.25942127575995

Epoch: 626| Step: 0
Training loss: 0.5997553346403814
Validation loss: 2.268199506557503

Epoch: 5| Step: 1
Training loss: 0.7024400129533789
Validation loss: 2.2642513842372343

Epoch: 5| Step: 2
Training loss: 0.40086637935046593
Validation loss: 2.262585362081982

Epoch: 5| Step: 3
Training loss: 1.357870957989503
Validation loss: 2.2537437601195163

Epoch: 5| Step: 4
Training loss: 0.7294859368849304
Validation loss: 2.3009140255177334

Epoch: 5| Step: 5
Training loss: 0.5164832284314826
Validation loss: 2.303580065429309

Epoch: 5| Step: 6
Training loss: 0.7927431058003442
Validation loss: 2.3627368945176084

Epoch: 5| Step: 7
Training loss: 0.5651760553671159
Validation loss: 2.316830763409393

Epoch: 5| Step: 8
Training loss: 0.9239843127624072
Validation loss: 2.3654656689569595

Epoch: 5| Step: 9
Training loss: 0.5535638199999687
Validation loss: 2.289169114728898

Epoch: 5| Step: 10
Training loss: 0.6639178847875569
Validation loss: 2.220046749847754

Epoch: 627| Step: 0
Training loss: 0.619894104727983
Validation loss: 2.193534214039134

Epoch: 5| Step: 1
Training loss: 1.1947371650288954
Validation loss: 2.243687934347274

Epoch: 5| Step: 2
Training loss: 0.7143314798203187
Validation loss: 2.29959988294902

Epoch: 5| Step: 3
Training loss: 0.6372056515265834
Validation loss: 2.2654218719139014

Epoch: 5| Step: 4
Training loss: 0.5735206252715301
Validation loss: 2.16550401544025

Epoch: 5| Step: 5
Training loss: 0.5566675815412957
Validation loss: 2.2627663110207203

Epoch: 5| Step: 6
Training loss: 0.6949723729810592
Validation loss: 2.298998995452379

Epoch: 5| Step: 7
Training loss: 0.5965533083671701
Validation loss: 2.299181075943578

Epoch: 5| Step: 8
Training loss: 0.8242605117414507
Validation loss: 2.210772812114292

Epoch: 5| Step: 9
Training loss: 0.6719316414311639
Validation loss: 2.2424673876401506

Epoch: 5| Step: 10
Training loss: 0.3729827186579976
Validation loss: 2.240033389575473

Epoch: 628| Step: 0
Training loss: 0.7098836108970277
Validation loss: 2.2362103171959213

Epoch: 5| Step: 1
Training loss: 0.7523602857188686
Validation loss: 2.196385751531022

Epoch: 5| Step: 2
Training loss: 0.6082065334726816
Validation loss: 2.3013747488982674

Epoch: 5| Step: 3
Training loss: 0.6491380606956578
Validation loss: 2.3529767699085986

Epoch: 5| Step: 4
Training loss: 0.6479783328313364
Validation loss: 2.275040078353837

Epoch: 5| Step: 5
Training loss: 1.26259202527338
Validation loss: 2.288366632870461

Epoch: 5| Step: 6
Training loss: 0.6043548921082365
Validation loss: 2.3304131520097138

Epoch: 5| Step: 7
Training loss: 0.5247828147881664
Validation loss: 2.2702106375826

Epoch: 5| Step: 8
Training loss: 0.6452079457335334
Validation loss: 2.2345282475325137

Epoch: 5| Step: 9
Training loss: 0.5415529137768361
Validation loss: 2.2054265484163498

Epoch: 5| Step: 10
Training loss: 0.911770939579452
Validation loss: 2.2505061401817383

Epoch: 629| Step: 0
Training loss: 1.2213200589469202
Validation loss: 2.2199988379748405

Epoch: 5| Step: 1
Training loss: 0.4980501511409941
Validation loss: 2.1679864470485612

Epoch: 5| Step: 2
Training loss: 0.377773459620589
Validation loss: 2.2432515559177504

Epoch: 5| Step: 3
Training loss: 0.6595811765598966
Validation loss: 2.2159613156333355

Epoch: 5| Step: 4
Training loss: 0.8129189951472432
Validation loss: 2.225633123214098

Epoch: 5| Step: 5
Training loss: 0.6502022456094269
Validation loss: 2.2954391155627207

Epoch: 5| Step: 6
Training loss: 0.7617512231409452
Validation loss: 2.2959423670499017

Epoch: 5| Step: 7
Training loss: 0.5415262780069957
Validation loss: 2.2027119802338015

Epoch: 5| Step: 8
Training loss: 0.6823817817251762
Validation loss: 2.258278718946468

Epoch: 5| Step: 9
Training loss: 0.6037282723412812
Validation loss: 2.2574096801781156

Epoch: 5| Step: 10
Training loss: 0.5972975358740067
Validation loss: 2.252491926936515

Epoch: 630| Step: 0
Training loss: 0.6583969555263538
Validation loss: 2.3086425416299394

Epoch: 5| Step: 1
Training loss: 0.6256187713800785
Validation loss: 2.268051460545634

Epoch: 5| Step: 2
Training loss: 0.44459284806490174
Validation loss: 2.183226432741415

Epoch: 5| Step: 3
Training loss: 1.3691851163810216
Validation loss: 2.299063104559307

Epoch: 5| Step: 4
Training loss: 0.6154083006110894
Validation loss: 2.2455017947674962

Epoch: 5| Step: 5
Training loss: 0.5483387023968253
Validation loss: 2.173865925439652

Epoch: 5| Step: 6
Training loss: 0.39029622547192283
Validation loss: 2.2617169522806044

Epoch: 5| Step: 7
Training loss: 0.829251153433926
Validation loss: 2.330043449089166

Epoch: 5| Step: 8
Training loss: 0.9110812615206144
Validation loss: 2.289729617125492

Epoch: 5| Step: 9
Training loss: 0.4341327822081352
Validation loss: 2.2844049986321524

Epoch: 5| Step: 10
Training loss: 0.5674648783650594
Validation loss: 2.3180185779315203

Epoch: 631| Step: 0
Training loss: 0.7262130224955025
Validation loss: 2.313344826067632

Epoch: 5| Step: 1
Training loss: 1.3130988616738555
Validation loss: 2.3266508802705865

Epoch: 5| Step: 2
Training loss: 0.7787661167148657
Validation loss: 2.3803864682997076

Epoch: 5| Step: 3
Training loss: 0.5484030220953617
Validation loss: 2.3312728653739616

Epoch: 5| Step: 4
Training loss: 0.7194309326222078
Validation loss: 2.2615433417926667

Epoch: 5| Step: 5
Training loss: 0.6459533492728978
Validation loss: 2.2419443992363117

Epoch: 5| Step: 6
Training loss: 0.5595760644746909
Validation loss: 2.1901784259013284

Epoch: 5| Step: 7
Training loss: 0.5509927762799022
Validation loss: 2.2125612438492976

Epoch: 5| Step: 8
Training loss: 0.5760013651301843
Validation loss: 2.2211946685194803

Epoch: 5| Step: 9
Training loss: 0.7245702604445681
Validation loss: 2.2045984018392475

Epoch: 5| Step: 10
Training loss: 0.7965647523593
Validation loss: 2.224889687945295

Epoch: 632| Step: 0
Training loss: 0.489220486433468
Validation loss: 2.309287954813028

Epoch: 5| Step: 1
Training loss: 0.6723038834851898
Validation loss: 2.2912356949316752

Epoch: 5| Step: 2
Training loss: 0.9644556230131842
Validation loss: 2.2327168527380574

Epoch: 5| Step: 3
Training loss: 1.2920065811981667
Validation loss: 2.267233870603897

Epoch: 5| Step: 4
Training loss: 0.5166407896555291
Validation loss: 2.310917020670087

Epoch: 5| Step: 5
Training loss: 0.4852322713904293
Validation loss: 2.269459620414932

Epoch: 5| Step: 6
Training loss: 0.4380209750047864
Validation loss: 2.245144017378906

Epoch: 5| Step: 7
Training loss: 0.57980887589551
Validation loss: 2.2169398668748155

Epoch: 5| Step: 8
Training loss: 0.788569948167132
Validation loss: 2.201579763742351

Epoch: 5| Step: 9
Training loss: 0.707266246880077
Validation loss: 2.2719441493305443

Epoch: 5| Step: 10
Training loss: 0.4855544282259731
Validation loss: 2.2807296303274023

Epoch: 633| Step: 0
Training loss: 0.5264281908118197
Validation loss: 2.2622930108095836

Epoch: 5| Step: 1
Training loss: 1.2474197937556275
Validation loss: 2.1996405275423534

Epoch: 5| Step: 2
Training loss: 0.4654952380482772
Validation loss: 2.255992916241966

Epoch: 5| Step: 3
Training loss: 0.5875340390997189
Validation loss: 2.306112664630584

Epoch: 5| Step: 4
Training loss: 0.5314059869978135
Validation loss: 2.2421145257733137

Epoch: 5| Step: 5
Training loss: 0.6692946809510298
Validation loss: 2.3666177071523697

Epoch: 5| Step: 6
Training loss: 0.5984264970370491
Validation loss: 2.2493886652636412

Epoch: 5| Step: 7
Training loss: 0.6208644899661845
Validation loss: 2.2431952385820755

Epoch: 5| Step: 8
Training loss: 0.6746377255347655
Validation loss: 2.241246428461017

Epoch: 5| Step: 9
Training loss: 0.8926113130839326
Validation loss: 2.2471153289458106

Epoch: 5| Step: 10
Training loss: 0.735957935478781
Validation loss: 2.3180001591659525

Epoch: 634| Step: 0
Training loss: 0.599064731822585
Validation loss: 2.225233551926773

Epoch: 5| Step: 1
Training loss: 0.5603412157860572
Validation loss: 2.2272333446766317

Epoch: 5| Step: 2
Training loss: 0.799488270528611
Validation loss: 2.3061547554794184

Epoch: 5| Step: 3
Training loss: 1.2531154908083424
Validation loss: 2.30339189684546

Epoch: 5| Step: 4
Training loss: 0.7442016976994027
Validation loss: 2.25855786904393

Epoch: 5| Step: 5
Training loss: 0.6752912696491526
Validation loss: 2.2101115779163583

Epoch: 5| Step: 6
Training loss: 0.5624764755416174
Validation loss: 2.250737443119005

Epoch: 5| Step: 7
Training loss: 0.5028338294664784
Validation loss: 2.2828233080615377

Epoch: 5| Step: 8
Training loss: 0.951933913884281
Validation loss: 2.218952340156757

Epoch: 5| Step: 9
Training loss: 0.6378103155447276
Validation loss: 2.303005676477761

Epoch: 5| Step: 10
Training loss: 0.5875320862063673
Validation loss: 2.212923150893825

Epoch: 635| Step: 0
Training loss: 0.40378818667968996
Validation loss: 2.355552800268877

Epoch: 5| Step: 1
Training loss: 0.49467320446244345
Validation loss: 2.3476693506875006

Epoch: 5| Step: 2
Training loss: 0.8623515167135403
Validation loss: 2.209986787655465

Epoch: 5| Step: 3
Training loss: 1.2479464351731369
Validation loss: 2.3213893092839166

Epoch: 5| Step: 4
Training loss: 0.6552391213813347
Validation loss: 2.254181806414052

Epoch: 5| Step: 5
Training loss: 0.47990288015162286
Validation loss: 2.252774653591421

Epoch: 5| Step: 6
Training loss: 0.6805231941945561
Validation loss: 2.3330383500697534

Epoch: 5| Step: 7
Training loss: 0.6263095487809244
Validation loss: 2.250251446053837

Epoch: 5| Step: 8
Training loss: 0.46099599370125827
Validation loss: 2.293783237573778

Epoch: 5| Step: 9
Training loss: 0.3590822686180843
Validation loss: 2.273756446816837

Epoch: 5| Step: 10
Training loss: 0.7034934244248482
Validation loss: 2.2776320392534917

Epoch: 636| Step: 0
Training loss: 0.6723557238406856
Validation loss: 2.286157120125743

Epoch: 5| Step: 1
Training loss: 0.6104701300850259
Validation loss: 2.237005390306387

Epoch: 5| Step: 2
Training loss: 0.5415150509677231
Validation loss: 2.18802348786181

Epoch: 5| Step: 3
Training loss: 0.5667772064897644
Validation loss: 2.249609160118205

Epoch: 5| Step: 4
Training loss: 0.49457737314360345
Validation loss: 2.280751218615801

Epoch: 5| Step: 5
Training loss: 0.4387250845918004
Validation loss: 2.2506515381096515

Epoch: 5| Step: 6
Training loss: 0.5127566636934454
Validation loss: 2.2643228434518017

Epoch: 5| Step: 7
Training loss: 0.5477369872044378
Validation loss: 2.201684958679031

Epoch: 5| Step: 8
Training loss: 0.6216603939167762
Validation loss: 2.231496576789464

Epoch: 5| Step: 9
Training loss: 1.179483307604298
Validation loss: 2.320283879304902

Epoch: 5| Step: 10
Training loss: 0.9098321231110278
Validation loss: 2.1734509572942664

Epoch: 637| Step: 0
Training loss: 0.5804815462943042
Validation loss: 2.243503827452788

Epoch: 5| Step: 1
Training loss: 0.7280571034090886
Validation loss: 2.187379871826044

Epoch: 5| Step: 2
Training loss: 0.398667717788075
Validation loss: 2.1866064775263325

Epoch: 5| Step: 3
Training loss: 0.6915084418514534
Validation loss: 2.1801163128872205

Epoch: 5| Step: 4
Training loss: 0.8349828527597264
Validation loss: 2.2223394979103626

Epoch: 5| Step: 5
Training loss: 0.560135454459549
Validation loss: 2.205327479772701

Epoch: 5| Step: 6
Training loss: 0.5818849418110416
Validation loss: 2.199087559960241

Epoch: 5| Step: 7
Training loss: 1.3062573884453876
Validation loss: 2.2084010836083334

Epoch: 5| Step: 8
Training loss: 0.6307348358714323
Validation loss: 2.203064512377945

Epoch: 5| Step: 9
Training loss: 0.7536082098655412
Validation loss: 2.3040502691680667

Epoch: 5| Step: 10
Training loss: 0.5723948934846428
Validation loss: 2.240180814752754

Epoch: 638| Step: 0
Training loss: 0.771237181645094
Validation loss: 2.2487450361906998

Epoch: 5| Step: 1
Training loss: 0.5830206430323662
Validation loss: 2.364965363439889

Epoch: 5| Step: 2
Training loss: 0.4589804466566432
Validation loss: 2.2472213795091283

Epoch: 5| Step: 3
Training loss: 0.7695118470819862
Validation loss: 2.2995028502872445

Epoch: 5| Step: 4
Training loss: 0.48261831508058595
Validation loss: 2.3792565580513108

Epoch: 5| Step: 5
Training loss: 0.537771309533685
Validation loss: 2.263705782222431

Epoch: 5| Step: 6
Training loss: 0.6894455604030169
Validation loss: 2.310949100941538

Epoch: 5| Step: 7
Training loss: 1.290878219333039
Validation loss: 2.299238185616377

Epoch: 5| Step: 8
Training loss: 0.959305222051924
Validation loss: 2.287877285952219

Epoch: 5| Step: 9
Training loss: 0.41168491144844716
Validation loss: 2.279881141819347

Epoch: 5| Step: 10
Training loss: 0.9531556108906012
Validation loss: 2.222439706920414

Epoch: 639| Step: 0
Training loss: 1.2689242276234736
Validation loss: 2.2526500026960052

Epoch: 5| Step: 1
Training loss: 0.4259736387632587
Validation loss: 2.2206658903622336

Epoch: 5| Step: 2
Training loss: 0.7520817634235034
Validation loss: 2.2616611497252403

Epoch: 5| Step: 3
Training loss: 0.6056010932258655
Validation loss: 2.305544455809136

Epoch: 5| Step: 4
Training loss: 0.6855807391114088
Validation loss: 2.2375923947485656

Epoch: 5| Step: 5
Training loss: 0.7605154069171283
Validation loss: 2.26558507333213

Epoch: 5| Step: 6
Training loss: 0.5904023512740469
Validation loss: 2.366593488789269

Epoch: 5| Step: 7
Training loss: 0.46374823400258863
Validation loss: 2.2236875495192314

Epoch: 5| Step: 8
Training loss: 0.5299758778786732
Validation loss: 2.3061218481338215

Epoch: 5| Step: 9
Training loss: 0.5228577719979816
Validation loss: 2.2225968484362175

Epoch: 5| Step: 10
Training loss: 0.5618640165348103
Validation loss: 2.2949799798448844

Epoch: 640| Step: 0
Training loss: 0.8069586692587835
Validation loss: 2.277608966582913

Epoch: 5| Step: 1
Training loss: 0.7035669209589696
Validation loss: 2.230175926848708

Epoch: 5| Step: 2
Training loss: 0.4118281304199181
Validation loss: 2.20857985783092

Epoch: 5| Step: 3
Training loss: 0.5682997262597956
Validation loss: 2.2812795801474257

Epoch: 5| Step: 4
Training loss: 0.5176814426011087
Validation loss: 2.288793981304987

Epoch: 5| Step: 5
Training loss: 0.6691641790605849
Validation loss: 2.2691631905771388

Epoch: 5| Step: 6
Training loss: 0.7036766854917252
Validation loss: 2.264897381212419

Epoch: 5| Step: 7
Training loss: 1.1686623341530287
Validation loss: 2.2427881279679758

Epoch: 5| Step: 8
Training loss: 0.46448616892032263
Validation loss: 2.295260208523698

Epoch: 5| Step: 9
Training loss: 0.6337893916571516
Validation loss: 2.264487681855688

Epoch: 5| Step: 10
Training loss: 0.6477578059366208
Validation loss: 2.3038604726327856

Epoch: 641| Step: 0
Training loss: 0.45843607841848566
Validation loss: 2.2449547192338906

Epoch: 5| Step: 1
Training loss: 0.5955627776365566
Validation loss: 2.3151028869338197

Epoch: 5| Step: 2
Training loss: 0.5327932158529397
Validation loss: 2.30632435615167

Epoch: 5| Step: 3
Training loss: 0.4630156722351489
Validation loss: 2.2672239540364734

Epoch: 5| Step: 4
Training loss: 0.54829641630472
Validation loss: 2.2437552953927193

Epoch: 5| Step: 5
Training loss: 0.7607950723504536
Validation loss: 2.3225411673948475

Epoch: 5| Step: 6
Training loss: 1.3006227872170686
Validation loss: 2.2911486833605186

Epoch: 5| Step: 7
Training loss: 0.5485675233782832
Validation loss: 2.203003479064241

Epoch: 5| Step: 8
Training loss: 0.6678626662223373
Validation loss: 2.1495981407971776

Epoch: 5| Step: 9
Training loss: 0.7535338593882612
Validation loss: 2.1765797572310914

Epoch: 5| Step: 10
Training loss: 0.5819906694231257
Validation loss: 2.17653989615898

Epoch: 642| Step: 0
Training loss: 0.7019609776706703
Validation loss: 2.258387465755851

Epoch: 5| Step: 1
Training loss: 0.6110096793695743
Validation loss: 2.293439952783409

Epoch: 5| Step: 2
Training loss: 0.5174433694712314
Validation loss: 2.2165727327215854

Epoch: 5| Step: 3
Training loss: 0.5232885348022805
Validation loss: 2.2455212819895656

Epoch: 5| Step: 4
Training loss: 0.5145292198310231
Validation loss: 2.210006310795404

Epoch: 5| Step: 5
Training loss: 0.6154177195730051
Validation loss: 2.335995817072117

Epoch: 5| Step: 6
Training loss: 0.7999931364957118
Validation loss: 2.2785025006523334

Epoch: 5| Step: 7
Training loss: 0.8761670640123712
Validation loss: 2.2322375923128797

Epoch: 5| Step: 8
Training loss: 0.4345637288827143
Validation loss: 2.3347324280058053

Epoch: 5| Step: 9
Training loss: 0.5556838529847039
Validation loss: 2.2961474833180633

Epoch: 5| Step: 10
Training loss: 1.4083132971893955
Validation loss: 2.278007936600485

Epoch: 643| Step: 0
Training loss: 0.6620174332870222
Validation loss: 2.2751112392706814

Epoch: 5| Step: 1
Training loss: 0.5565116063558821
Validation loss: 2.2342823989511134

Epoch: 5| Step: 2
Training loss: 0.5463361264993946
Validation loss: 2.241034126317976

Epoch: 5| Step: 3
Training loss: 1.2202456662367391
Validation loss: 2.1903930239363807

Epoch: 5| Step: 4
Training loss: 0.8641870846875986
Validation loss: 2.237086416075869

Epoch: 5| Step: 5
Training loss: 0.6249194570142415
Validation loss: 2.14808340844456

Epoch: 5| Step: 6
Training loss: 0.5435218463918337
Validation loss: 2.243409882243425

Epoch: 5| Step: 7
Training loss: 0.4747955051477304
Validation loss: 2.287042593091123

Epoch: 5| Step: 8
Training loss: 0.46832920896788877
Validation loss: 2.276884000313628

Epoch: 5| Step: 9
Training loss: 0.5574846260448508
Validation loss: 2.3094934409733163

Epoch: 5| Step: 10
Training loss: 0.5140773782635112
Validation loss: 2.3460390699891853

Epoch: 644| Step: 0
Training loss: 0.5799977153700195
Validation loss: 2.3450484946778154

Epoch: 5| Step: 1
Training loss: 0.7837610326717489
Validation loss: 2.2502032960635776

Epoch: 5| Step: 2
Training loss: 0.5371803375530031
Validation loss: 2.1758391961596035

Epoch: 5| Step: 3
Training loss: 0.5257042725032234
Validation loss: 2.2391390784582725

Epoch: 5| Step: 4
Training loss: 0.47560937341993154
Validation loss: 2.233353915951537

Epoch: 5| Step: 5
Training loss: 0.7191896752367435
Validation loss: 2.207799362462735

Epoch: 5| Step: 6
Training loss: 0.6504920445086941
Validation loss: 2.2139745597104348

Epoch: 5| Step: 7
Training loss: 1.151765426085305
Validation loss: 2.1964559737712115

Epoch: 5| Step: 8
Training loss: 0.6941326289019611
Validation loss: 2.224359688841129

Epoch: 5| Step: 9
Training loss: 0.5412853133418694
Validation loss: 2.2675550591299927

Epoch: 5| Step: 10
Training loss: 0.6637329630272658
Validation loss: 2.1969190264830747

Epoch: 645| Step: 0
Training loss: 1.230348514555895
Validation loss: 2.236157455054111

Epoch: 5| Step: 1
Training loss: 0.5921449047058481
Validation loss: 2.2868222844349795

Epoch: 5| Step: 2
Training loss: 0.3604428969009458
Validation loss: 2.3134333875578905

Epoch: 5| Step: 3
Training loss: 0.5810425316316448
Validation loss: 2.205450207104065

Epoch: 5| Step: 4
Training loss: 0.6694985211450769
Validation loss: 2.157538258777237

Epoch: 5| Step: 5
Training loss: 0.5143958382076258
Validation loss: 2.248792358408813

Epoch: 5| Step: 6
Training loss: 0.6272263689071129
Validation loss: 2.2066640780957023

Epoch: 5| Step: 7
Training loss: 0.6986873034906832
Validation loss: 2.176132963451514

Epoch: 5| Step: 8
Training loss: 0.5312120199651803
Validation loss: 2.2678491251823254

Epoch: 5| Step: 9
Training loss: 0.8545119277853751
Validation loss: 2.3219879698378167

Epoch: 5| Step: 10
Training loss: 0.5803500735722181
Validation loss: 2.258834278949092

Epoch: 646| Step: 0
Training loss: 0.4601003026710067
Validation loss: 2.2306281491264106

Epoch: 5| Step: 1
Training loss: 0.835377157772188
Validation loss: 2.1780464097805177

Epoch: 5| Step: 2
Training loss: 0.5053436714140692
Validation loss: 2.2085893667915313

Epoch: 5| Step: 3
Training loss: 0.524546175037867
Validation loss: 2.2641896148932608

Epoch: 5| Step: 4
Training loss: 1.2081922854391454
Validation loss: 2.210128190218535

Epoch: 5| Step: 5
Training loss: 0.5484844502841641
Validation loss: 2.2165380032849584

Epoch: 5| Step: 6
Training loss: 0.5637443078254862
Validation loss: 2.2517042018278524

Epoch: 5| Step: 7
Training loss: 0.6327655209657733
Validation loss: 2.2982619775049775

Epoch: 5| Step: 8
Training loss: 0.9143134530683287
Validation loss: 2.264093508724216

Epoch: 5| Step: 9
Training loss: 0.5970754606345079
Validation loss: 2.262933872405737

Epoch: 5| Step: 10
Training loss: 0.615399728988325
Validation loss: 2.2952996659037166

Epoch: 647| Step: 0
Training loss: 0.7365966630991109
Validation loss: 2.243391004051871

Epoch: 5| Step: 1
Training loss: 0.5348726342459377
Validation loss: 2.2634914684851535

Epoch: 5| Step: 2
Training loss: 0.6794680098497273
Validation loss: 2.299871772662212

Epoch: 5| Step: 3
Training loss: 1.2833651319915618
Validation loss: 2.225735466838598

Epoch: 5| Step: 4
Training loss: 0.8271947710375547
Validation loss: 2.212339544506144

Epoch: 5| Step: 5
Training loss: 0.654026852587248
Validation loss: 2.2503063740758913

Epoch: 5| Step: 6
Training loss: 0.48432146822543953
Validation loss: 2.2514242042338464

Epoch: 5| Step: 7
Training loss: 0.4958834465197932
Validation loss: 2.206564919785674

Epoch: 5| Step: 8
Training loss: 0.4749669898006989
Validation loss: 2.207829221866751

Epoch: 5| Step: 9
Training loss: 0.49191091728674124
Validation loss: 2.1762708570860765

Epoch: 5| Step: 10
Training loss: 0.5027699929923228
Validation loss: 2.2468264917843466

Epoch: 648| Step: 0
Training loss: 0.6188981938385538
Validation loss: 2.1999117661799747

Epoch: 5| Step: 1
Training loss: 0.635675851668858
Validation loss: 2.2351537922412996

Epoch: 5| Step: 2
Training loss: 0.5456114476936168
Validation loss: 2.2268044887690506

Epoch: 5| Step: 3
Training loss: 0.5780661269445447
Validation loss: 2.309513395048164

Epoch: 5| Step: 4
Training loss: 0.5894195850454135
Validation loss: 2.270752931247544

Epoch: 5| Step: 5
Training loss: 0.8299382709045989
Validation loss: 2.249688664468563

Epoch: 5| Step: 6
Training loss: 0.43125896928277957
Validation loss: 2.2388909069112475

Epoch: 5| Step: 7
Training loss: 0.5806958284488026
Validation loss: 2.2804790581454184

Epoch: 5| Step: 8
Training loss: 1.2075234801416426
Validation loss: 2.271494021286907

Epoch: 5| Step: 9
Training loss: 0.6570801252949192
Validation loss: 2.329584162573567

Epoch: 5| Step: 10
Training loss: 0.48517061848026405
Validation loss: 2.24241087169145

Epoch: 649| Step: 0
Training loss: 0.5693088740988103
Validation loss: 2.2596336012285336

Epoch: 5| Step: 1
Training loss: 0.5206101193539642
Validation loss: 2.3445793746266665

Epoch: 5| Step: 2
Training loss: 0.5069351246236938
Validation loss: 2.238542260322253

Epoch: 5| Step: 3
Training loss: 0.40665914033481
Validation loss: 2.250232221954707

Epoch: 5| Step: 4
Training loss: 1.2571455330402208
Validation loss: 2.2411962731148147

Epoch: 5| Step: 5
Training loss: 0.5734350084879536
Validation loss: 2.22009793091883

Epoch: 5| Step: 6
Training loss: 0.7269257488558721
Validation loss: 2.2501797382113518

Epoch: 5| Step: 7
Training loss: 0.7767155855214515
Validation loss: 2.209512348433796

Epoch: 5| Step: 8
Training loss: 0.648826528383021
Validation loss: 2.2406464203944374

Epoch: 5| Step: 9
Training loss: 0.6591775173575388
Validation loss: 2.2785661310885703

Epoch: 5| Step: 10
Training loss: 0.6959964945419869
Validation loss: 2.185515494017179

Epoch: 650| Step: 0
Training loss: 0.6289112967531519
Validation loss: 2.270790354455665

Epoch: 5| Step: 1
Training loss: 1.1840486061648248
Validation loss: 2.2778375601341163

Epoch: 5| Step: 2
Training loss: 0.7671319960893176
Validation loss: 2.2399558575718763

Epoch: 5| Step: 3
Training loss: 0.728324803783249
Validation loss: 2.2604591335773914

Epoch: 5| Step: 4
Training loss: 0.5968406447664307
Validation loss: 2.2981242023221786

Epoch: 5| Step: 5
Training loss: 0.7973149524999967
Validation loss: 2.2816636489690847

Epoch: 5| Step: 6
Training loss: 0.5541857209431436
Validation loss: 2.2808526794854487

Epoch: 5| Step: 7
Training loss: 0.5500207615315008
Validation loss: 2.1749837326197707

Epoch: 5| Step: 8
Training loss: 0.386266906794175
Validation loss: 2.2350196955261916

Epoch: 5| Step: 9
Training loss: 0.49421513414100404
Validation loss: 2.259008290276551

Epoch: 5| Step: 10
Training loss: 0.601605550043016
Validation loss: 2.247076253061392

Testing loss: 2.8421956566503717
