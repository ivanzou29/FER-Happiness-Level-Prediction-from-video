Epoch: 1| Step: 0
Training loss: 5.615247622266982
Validation loss: 6.461858760363752

Epoch: 5| Step: 1
Training loss: 6.446480717993419
Validation loss: 6.456691627227821

Epoch: 5| Step: 2
Training loss: 6.394932719720051
Validation loss: 6.452725927162811

Epoch: 5| Step: 3
Training loss: 7.1773275288607925
Validation loss: 6.449319640888983

Epoch: 5| Step: 4
Training loss: 6.638600909355179
Validation loss: 6.442042508995683

Epoch: 5| Step: 5
Training loss: 6.211478578043096
Validation loss: 6.438725801710296

Epoch: 5| Step: 6
Training loss: 6.6712460366591655
Validation loss: 6.432636947767252

Epoch: 5| Step: 7
Training loss: 6.478224445615746
Validation loss: 6.428371017308889

Epoch: 5| Step: 8
Training loss: 5.831436975227025
Validation loss: 6.424604715935614

Epoch: 5| Step: 9
Training loss: 6.9390520988649245
Validation loss: 6.418528648509291

Epoch: 5| Step: 10
Training loss: 6.329691224484371
Validation loss: 6.4128966020076295

Epoch: 2| Step: 0
Training loss: 7.0988310375448
Validation loss: 6.405767892164077

Epoch: 5| Step: 1
Training loss: 5.9884981537894335
Validation loss: 6.403054677781621

Epoch: 5| Step: 2
Training loss: 6.0561650792832005
Validation loss: 6.3978717785297246

Epoch: 5| Step: 3
Training loss: 7.073700521983316
Validation loss: 6.392049856486648

Epoch: 5| Step: 4
Training loss: 5.2465905517395335
Validation loss: 6.387383257043868

Epoch: 5| Step: 5
Training loss: 6.56497291111932
Validation loss: 6.383205659015172

Epoch: 5| Step: 6
Training loss: 6.191902212982431
Validation loss: 6.378276741266399

Epoch: 5| Step: 7
Training loss: 7.154437372784372
Validation loss: 6.371111545105453

Epoch: 5| Step: 8
Training loss: 6.761496466955836
Validation loss: 6.36626024890951

Epoch: 5| Step: 9
Training loss: 5.512793313870923
Validation loss: 6.362584886484876

Epoch: 5| Step: 10
Training loss: 6.325291430125998
Validation loss: 6.359325689220511

Epoch: 3| Step: 0
Training loss: 7.299800702862625
Validation loss: 6.35230897254684

Epoch: 5| Step: 1
Training loss: 5.981106894125458
Validation loss: 6.3459376227482895

Epoch: 5| Step: 2
Training loss: 6.466572418050433
Validation loss: 6.341985079047789

Epoch: 5| Step: 3
Training loss: 6.63033382260057
Validation loss: 6.336082902212044

Epoch: 5| Step: 4
Training loss: 5.158757380412548
Validation loss: 6.330625681719474

Epoch: 5| Step: 5
Training loss: 6.851904622391186
Validation loss: 6.327135039769278

Epoch: 5| Step: 6
Training loss: 7.257839831084168
Validation loss: 6.323546460463977

Epoch: 5| Step: 7
Training loss: 6.36934935020992
Validation loss: 6.316249984819432

Epoch: 5| Step: 8
Training loss: 5.93628527613344
Validation loss: 6.311585387586601

Epoch: 5| Step: 9
Training loss: 5.525352653192253
Validation loss: 6.306476631573363

Epoch: 5| Step: 10
Training loss: 5.7956350805005075
Validation loss: 6.301024456624959

Epoch: 4| Step: 0
Training loss: 6.148302554209227
Validation loss: 6.294532093494413

Epoch: 5| Step: 1
Training loss: 7.020390105099802
Validation loss: 6.29057063309633

Epoch: 5| Step: 2
Training loss: 6.039073870057214
Validation loss: 6.285250027676357

Epoch: 5| Step: 3
Training loss: 5.819621983472602
Validation loss: 6.28110926460297

Epoch: 5| Step: 4
Training loss: 5.962295317585465
Validation loss: 6.273441220349079

Epoch: 5| Step: 5
Training loss: 6.3443945947141005
Validation loss: 6.272996197985762

Epoch: 5| Step: 6
Training loss: 5.6279189271706525
Validation loss: 6.267716876968868

Epoch: 5| Step: 7
Training loss: 6.004446607210184
Validation loss: 6.258741583192933

Epoch: 5| Step: 8
Training loss: 6.019573075373836
Validation loss: 6.255029491479206

Epoch: 5| Step: 9
Training loss: 6.650840316110468
Validation loss: 6.249556163492454

Epoch: 5| Step: 10
Training loss: 7.398754592432632
Validation loss: 6.242185186960423

Epoch: 5| Step: 0
Training loss: 6.703748127177565
Validation loss: 6.239338062659157

Epoch: 5| Step: 1
Training loss: 6.158762772401511
Validation loss: 6.2326128125310545

Epoch: 5| Step: 2
Training loss: 6.655122616710907
Validation loss: 6.229700040218095

Epoch: 5| Step: 3
Training loss: 5.691809059398632
Validation loss: 6.224557421662141

Epoch: 5| Step: 4
Training loss: 5.975046401861205
Validation loss: 6.215217657717556

Epoch: 5| Step: 5
Training loss: 6.713640976302755
Validation loss: 6.208602586704976

Epoch: 5| Step: 6
Training loss: 5.835175613859456
Validation loss: 6.206049845292065

Epoch: 5| Step: 7
Training loss: 6.461575422425809
Validation loss: 6.196578764221695

Epoch: 5| Step: 8
Training loss: 6.863344612328462
Validation loss: 6.194239398604908

Epoch: 5| Step: 9
Training loss: 5.819939559150762
Validation loss: 6.187168437700092

Epoch: 5| Step: 10
Training loss: 5.206516203193945
Validation loss: 6.1818523567259245

Epoch: 6| Step: 0
Training loss: 6.300480342900018
Validation loss: 6.174549460094741

Epoch: 5| Step: 1
Training loss: 5.39623713608676
Validation loss: 6.169532586618259

Epoch: 5| Step: 2
Training loss: 5.834483260390031
Validation loss: 6.15902067776818

Epoch: 5| Step: 3
Training loss: 6.198927066625623
Validation loss: 6.156899609857618

Epoch: 5| Step: 4
Training loss: 6.040092350841124
Validation loss: 6.149062671825296

Epoch: 5| Step: 5
Training loss: 6.647925674335144
Validation loss: 6.1450469195032005

Epoch: 5| Step: 6
Training loss: 6.167366331806724
Validation loss: 6.1396882512360005

Epoch: 5| Step: 7
Training loss: 6.110035580096
Validation loss: 6.133585394396501

Epoch: 5| Step: 8
Training loss: 5.435626880250228
Validation loss: 6.127289967391634

Epoch: 5| Step: 9
Training loss: 7.488441206885741
Validation loss: 6.120537782183027

Epoch: 5| Step: 10
Training loss: 5.756825252455097
Validation loss: 6.116051534952929

Epoch: 7| Step: 0
Training loss: 6.3775285680258875
Validation loss: 6.106248642140428

Epoch: 5| Step: 1
Training loss: 7.035481311462319
Validation loss: 6.100784765417981

Epoch: 5| Step: 2
Training loss: 6.322448143314609
Validation loss: 6.094394511974892

Epoch: 5| Step: 3
Training loss: 5.233947372049492
Validation loss: 6.088674422593064

Epoch: 5| Step: 4
Training loss: 6.017837395015073
Validation loss: 6.080489661182869

Epoch: 5| Step: 5
Training loss: 6.129110708527998
Validation loss: 6.075233884328555

Epoch: 5| Step: 6
Training loss: 5.9089146007564874
Validation loss: 6.066518375586126

Epoch: 5| Step: 7
Training loss: 5.914097976074244
Validation loss: 6.062054408716064

Epoch: 5| Step: 8
Training loss: 6.684954292409302
Validation loss: 6.053339598869611

Epoch: 5| Step: 9
Training loss: 6.05147785390549
Validation loss: 6.047642548377696

Epoch: 5| Step: 10
Training loss: 4.830488398087971
Validation loss: 6.040535817237213

Epoch: 8| Step: 0
Training loss: 5.740203473143259
Validation loss: 6.0358332539023385

Epoch: 5| Step: 1
Training loss: 5.530826875699065
Validation loss: 6.025866659353357

Epoch: 5| Step: 2
Training loss: 5.27878598850637
Validation loss: 6.018383892829971

Epoch: 5| Step: 3
Training loss: 6.003027470048121
Validation loss: 6.0147643879094375

Epoch: 5| Step: 4
Training loss: 6.48713467254732
Validation loss: 6.006687508470508

Epoch: 5| Step: 5
Training loss: 6.1840231018029685
Validation loss: 5.999926221387091

Epoch: 5| Step: 6
Training loss: 6.340694800491387
Validation loss: 5.991551448272092

Epoch: 5| Step: 7
Training loss: 5.4955981586260245
Validation loss: 5.985868129927372

Epoch: 5| Step: 8
Training loss: 6.509077922252062
Validation loss: 5.97516686636469

Epoch: 5| Step: 9
Training loss: 5.648293478832564
Validation loss: 5.968948430540107

Epoch: 5| Step: 10
Training loss: 6.825183225973881
Validation loss: 5.960302163441201

Epoch: 9| Step: 0
Training loss: 6.429289387166032
Validation loss: 5.953945818291202

Epoch: 5| Step: 1
Training loss: 6.6952686286121
Validation loss: 5.944135739083664

Epoch: 5| Step: 2
Training loss: 5.304655858705339
Validation loss: 5.938185281288075

Epoch: 5| Step: 3
Training loss: 5.5377631338043924
Validation loss: 5.932225006845959

Epoch: 5| Step: 4
Training loss: 5.987138951511567
Validation loss: 5.9202258808773935

Epoch: 5| Step: 5
Training loss: 5.8860998606738075
Validation loss: 5.911441405023042

Epoch: 5| Step: 6
Training loss: 5.019776904555499
Validation loss: 5.906246886952722

Epoch: 5| Step: 7
Training loss: 6.155821809545733
Validation loss: 5.896247470349273

Epoch: 5| Step: 8
Training loss: 5.801925063471492
Validation loss: 5.888607278969294

Epoch: 5| Step: 9
Training loss: 6.363634637114055
Validation loss: 5.877712624534699

Epoch: 5| Step: 10
Training loss: 5.8394547450914205
Validation loss: 5.871532704299613

Epoch: 10| Step: 0
Training loss: 6.372346512811878
Validation loss: 5.863926778432356

Epoch: 5| Step: 1
Training loss: 4.522203978913854
Validation loss: 5.85361200825294

Epoch: 5| Step: 2
Training loss: 5.896272173434067
Validation loss: 5.8433948650438

Epoch: 5| Step: 3
Training loss: 6.759349141135378
Validation loss: 5.836121030446616

Epoch: 5| Step: 4
Training loss: 4.28819680293229
Validation loss: 5.827655058384617

Epoch: 5| Step: 5
Training loss: 6.17993996896568
Validation loss: 5.818413369141665

Epoch: 5| Step: 6
Training loss: 4.618523883575701
Validation loss: 5.807247972169975

Epoch: 5| Step: 7
Training loss: 5.6185628721924346
Validation loss: 5.7998102755380545

Epoch: 5| Step: 8
Training loss: 6.290745480364825
Validation loss: 5.793531528237981

Epoch: 5| Step: 9
Training loss: 6.8369887584523
Validation loss: 5.781093144083464

Epoch: 5| Step: 10
Training loss: 6.155741869099481
Validation loss: 5.7684328103321985

Epoch: 11| Step: 0
Training loss: 5.942069132666885
Validation loss: 5.7627295058680765

Epoch: 5| Step: 1
Training loss: 5.975413492491545
Validation loss: 5.74984378076381

Epoch: 5| Step: 2
Training loss: 5.375668506302118
Validation loss: 5.742199840062219

Epoch: 5| Step: 3
Training loss: 5.783141450511226
Validation loss: 5.7323829311487415

Epoch: 5| Step: 4
Training loss: 5.969720412054127
Validation loss: 5.7197921989432405

Epoch: 5| Step: 5
Training loss: 5.825617928534927
Validation loss: 5.711603603821318

Epoch: 5| Step: 6
Training loss: 5.572144280739326
Validation loss: 5.697710282490252

Epoch: 5| Step: 7
Training loss: 5.2348146168585545
Validation loss: 5.68817835993408

Epoch: 5| Step: 8
Training loss: 5.977325191326894
Validation loss: 5.679637264100579

Epoch: 5| Step: 9
Training loss: 5.799935491795092
Validation loss: 5.670543847452743

Epoch: 5| Step: 10
Training loss: 5.513757146269864
Validation loss: 5.654567760459708

Epoch: 12| Step: 0
Training loss: 4.861687113226648
Validation loss: 5.6476461470342345

Epoch: 5| Step: 1
Training loss: 5.688836915222482
Validation loss: 5.6377447298320735

Epoch: 5| Step: 2
Training loss: 5.40283289175462
Validation loss: 5.62587367921539

Epoch: 5| Step: 3
Training loss: 4.972715702585483
Validation loss: 5.61282253018784

Epoch: 5| Step: 4
Training loss: 6.709610084995683
Validation loss: 5.6035537387596515

Epoch: 5| Step: 5
Training loss: 4.817361333224211
Validation loss: 5.5872475291869526

Epoch: 5| Step: 6
Training loss: 6.007354679199424
Validation loss: 5.58007105348939

Epoch: 5| Step: 7
Training loss: 5.215268372810689
Validation loss: 5.565066731792339

Epoch: 5| Step: 8
Training loss: 5.873988612350009
Validation loss: 5.552594339034583

Epoch: 5| Step: 9
Training loss: 6.028805884810732
Validation loss: 5.537717417568629

Epoch: 5| Step: 10
Training loss: 5.859314778336359
Validation loss: 5.528562075866471

Epoch: 13| Step: 0
Training loss: 5.589912504763656
Validation loss: 5.513187612062125

Epoch: 5| Step: 1
Training loss: 3.9647036372641336
Validation loss: 5.50487819551817

Epoch: 5| Step: 2
Training loss: 5.374981192622438
Validation loss: 5.493700239849397

Epoch: 5| Step: 3
Training loss: 6.316238957857271
Validation loss: 5.479558409079987

Epoch: 5| Step: 4
Training loss: 5.664159481928342
Validation loss: 5.462676485181949

Epoch: 5| Step: 5
Training loss: 5.966276764872594
Validation loss: 5.451784175394223

Epoch: 5| Step: 6
Training loss: 4.228793022800655
Validation loss: 5.437789771600582

Epoch: 5| Step: 7
Training loss: 5.638188985265511
Validation loss: 5.426432932919426

Epoch: 5| Step: 8
Training loss: 5.105838403256697
Validation loss: 5.4103535604741495

Epoch: 5| Step: 9
Training loss: 6.154068768582885
Validation loss: 5.3948133578911035

Epoch: 5| Step: 10
Training loss: 5.7917714646918474
Validation loss: 5.378129451114668

Epoch: 14| Step: 0
Training loss: 4.3697777233727315
Validation loss: 5.3716301853636494

Epoch: 5| Step: 1
Training loss: 5.9484027545897185
Validation loss: 5.349847892889056

Epoch: 5| Step: 2
Training loss: 4.981366149237432
Validation loss: 5.338552447132318

Epoch: 5| Step: 3
Training loss: 5.168912563512117
Validation loss: 5.326030408622011

Epoch: 5| Step: 4
Training loss: 5.58504469345638
Validation loss: 5.310427519753078

Epoch: 5| Step: 5
Training loss: 6.216241225070156
Validation loss: 5.291340093182039

Epoch: 5| Step: 6
Training loss: 4.721649289748325
Validation loss: 5.277214829552729

Epoch: 5| Step: 7
Training loss: 5.496174609057826
Validation loss: 5.261184375470522

Epoch: 5| Step: 8
Training loss: 5.734841309590999
Validation loss: 5.247133328857064

Epoch: 5| Step: 9
Training loss: 4.683614519214792
Validation loss: 5.228783096988065

Epoch: 5| Step: 10
Training loss: 5.362370757566243
Validation loss: 5.209952173810854

Epoch: 15| Step: 0
Training loss: 6.127137414545924
Validation loss: 5.191913998637824

Epoch: 5| Step: 1
Training loss: 3.6283693111413324
Validation loss: 5.18076024716921

Epoch: 5| Step: 2
Training loss: 6.101172987927263
Validation loss: 5.164086849269484

Epoch: 5| Step: 3
Training loss: 5.141646356197328
Validation loss: 5.143347444079043

Epoch: 5| Step: 4
Training loss: 4.6232432560212215
Validation loss: 5.12764849834985

Epoch: 5| Step: 5
Training loss: 4.649644916061761
Validation loss: 5.110808758726795

Epoch: 5| Step: 6
Training loss: 4.600218908657322
Validation loss: 5.09981895381188

Epoch: 5| Step: 7
Training loss: 5.147215725727148
Validation loss: 5.080681948407359

Epoch: 5| Step: 8
Training loss: 5.461615044252164
Validation loss: 5.057304425480783

Epoch: 5| Step: 9
Training loss: 5.083118976179977
Validation loss: 5.046559689591783

Epoch: 5| Step: 10
Training loss: 5.630676795838953
Validation loss: 5.031249757457298

Epoch: 16| Step: 0
Training loss: 4.886585456378038
Validation loss: 5.003875465148194

Epoch: 5| Step: 1
Training loss: 4.366186365012771
Validation loss: 4.9923547643583825

Epoch: 5| Step: 2
Training loss: 5.6129232676059475
Validation loss: 4.969275806539812

Epoch: 5| Step: 3
Training loss: 5.4072038988654985
Validation loss: 4.95299321398454

Epoch: 5| Step: 4
Training loss: 5.33899963895629
Validation loss: 4.931921525572322

Epoch: 5| Step: 5
Training loss: 4.067916780113826
Validation loss: 4.914858771229297

Epoch: 5| Step: 6
Training loss: 4.8744277618248715
Validation loss: 4.8930561756549

Epoch: 5| Step: 7
Training loss: 5.383230074117564
Validation loss: 4.874885669226862

Epoch: 5| Step: 8
Training loss: 5.058576217090755
Validation loss: 4.855389022802873

Epoch: 5| Step: 9
Training loss: 3.862070478241723
Validation loss: 4.829044352079042

Epoch: 5| Step: 10
Training loss: 5.351469119851357
Validation loss: 4.815218724995115

Epoch: 17| Step: 0
Training loss: 5.2445557840206165
Validation loss: 4.793806302250079

Epoch: 5| Step: 1
Training loss: 4.367242966301393
Validation loss: 4.780104817759089

Epoch: 5| Step: 2
Training loss: 3.9169385017590588
Validation loss: 4.756535587455458

Epoch: 5| Step: 3
Training loss: 5.175060754686583
Validation loss: 4.739605125783722

Epoch: 5| Step: 4
Training loss: 4.076687497335028
Validation loss: 4.711511562710624

Epoch: 5| Step: 5
Training loss: 4.865946848863222
Validation loss: 4.687702754841574

Epoch: 5| Step: 6
Training loss: 5.179675716427019
Validation loss: 4.671233275749625

Epoch: 5| Step: 7
Training loss: 5.031843257069988
Validation loss: 4.646547646745994

Epoch: 5| Step: 8
Training loss: 4.7019165108625725
Validation loss: 4.630765120433697

Epoch: 5| Step: 9
Training loss: 4.684729609386387
Validation loss: 4.597212532817343

Epoch: 5| Step: 10
Training loss: 4.641724940995152
Validation loss: 4.5862182099709665

Epoch: 18| Step: 0
Training loss: 4.558897712726459
Validation loss: 4.570416038146021

Epoch: 5| Step: 1
Training loss: 4.619094170947698
Validation loss: 4.542249776288404

Epoch: 5| Step: 2
Training loss: 4.897303302392054
Validation loss: 4.517978670654724

Epoch: 5| Step: 3
Training loss: 4.1609823490236915
Validation loss: 4.494314623152398

Epoch: 5| Step: 4
Training loss: 3.991824139148134
Validation loss: 4.477052387729994

Epoch: 5| Step: 5
Training loss: 4.7122361653183695
Validation loss: 4.450952376053762

Epoch: 5| Step: 6
Training loss: 4.694406533072515
Validation loss: 4.4267248034807745

Epoch: 5| Step: 7
Training loss: 4.61149646624641
Validation loss: 4.405179224909936

Epoch: 5| Step: 8
Training loss: 3.91832934590446
Validation loss: 4.383938805046376

Epoch: 5| Step: 9
Training loss: 4.697210401182654
Validation loss: 4.355307156727832

Epoch: 5| Step: 10
Training loss: 4.653766353720867
Validation loss: 4.341599088943624

Epoch: 19| Step: 0
Training loss: 4.839917444833407
Validation loss: 4.316812135344768

Epoch: 5| Step: 1
Training loss: 5.0046395710708405
Validation loss: 4.283190110467408

Epoch: 5| Step: 2
Training loss: 3.5992976616169696
Validation loss: 4.264703502553275

Epoch: 5| Step: 3
Training loss: 4.1847356525459825
Validation loss: 4.235391500941089

Epoch: 5| Step: 4
Training loss: 3.692678403890009
Validation loss: 4.214778594724082

Epoch: 5| Step: 5
Training loss: 3.610957471725451
Validation loss: 4.187051277931656

Epoch: 5| Step: 6
Training loss: 5.318244251990325
Validation loss: 4.165544084662942

Epoch: 5| Step: 7
Training loss: 3.200588952941461
Validation loss: 4.142944789418832

Epoch: 5| Step: 8
Training loss: 4.226495710539754
Validation loss: 4.118522002329251

Epoch: 5| Step: 9
Training loss: 4.662230062980188
Validation loss: 4.1000144938231005

Epoch: 5| Step: 10
Training loss: 4.0421812903109915
Validation loss: 4.074472114881435

Epoch: 20| Step: 0
Training loss: 4.462362993632238
Validation loss: 4.038149245771335

Epoch: 5| Step: 1
Training loss: 3.635205602485074
Validation loss: 4.01920462398928

Epoch: 5| Step: 2
Training loss: 3.587487776997974
Validation loss: 3.9949485225097963

Epoch: 5| Step: 3
Training loss: 4.069620553214213
Validation loss: 3.9717364906431682

Epoch: 5| Step: 4
Training loss: 3.9463790811543755
Validation loss: 3.945145093902896

Epoch: 5| Step: 5
Training loss: 2.7967051875386972
Validation loss: 3.9239232806331024

Epoch: 5| Step: 6
Training loss: 4.09029749527507
Validation loss: 3.894679204502379

Epoch: 5| Step: 7
Training loss: 3.4154367016318723
Validation loss: 3.864521992098767

Epoch: 5| Step: 8
Training loss: 4.855903391208579
Validation loss: 3.847342192464678

Epoch: 5| Step: 9
Training loss: 4.262501002336759
Validation loss: 3.824397062860378

Epoch: 5| Step: 10
Training loss: 4.663078472670726
Validation loss: 3.797798385093622

Epoch: 21| Step: 0
Training loss: 4.318306593483972
Validation loss: 3.783765340815061

Epoch: 5| Step: 1
Training loss: 4.0615641763179875
Validation loss: 3.7451392388463707

Epoch: 5| Step: 2
Training loss: 3.711706720235123
Validation loss: 3.7207958439520494

Epoch: 5| Step: 3
Training loss: 3.4472203929840597
Validation loss: 3.7100046481210716

Epoch: 5| Step: 4
Training loss: 4.095076018618776
Validation loss: 3.6731986741368057

Epoch: 5| Step: 5
Training loss: 2.4523222757974854
Validation loss: 3.656749746230041

Epoch: 5| Step: 6
Training loss: 3.243367102337085
Validation loss: 3.6192719773533404

Epoch: 5| Step: 7
Training loss: 3.951610410738492
Validation loss: 3.6035865166446652

Epoch: 5| Step: 8
Training loss: 4.449387866147752
Validation loss: 3.590682089068032

Epoch: 5| Step: 9
Training loss: 4.00142954077052
Validation loss: 3.560378830041201

Epoch: 5| Step: 10
Training loss: 3.0830157004670236
Validation loss: 3.5280697493722726

Epoch: 22| Step: 0
Training loss: 4.040778203362507
Validation loss: 3.5123816810543613

Epoch: 5| Step: 1
Training loss: 4.0017581890358676
Validation loss: 3.482719073151249

Epoch: 5| Step: 2
Training loss: 3.237779824672178
Validation loss: 3.457447370445179

Epoch: 5| Step: 3
Training loss: 3.388502449835187
Validation loss: 3.4416861318867955

Epoch: 5| Step: 4
Training loss: 3.2385415776693325
Validation loss: 3.421329786186108

Epoch: 5| Step: 5
Training loss: 3.8998651432294396
Validation loss: 3.379029905290152

Epoch: 5| Step: 6
Training loss: 3.8412425228385016
Validation loss: 3.365004915608882

Epoch: 5| Step: 7
Training loss: 3.833645199791355
Validation loss: 3.3507425425952775

Epoch: 5| Step: 8
Training loss: 2.9645341352150054
Validation loss: 3.328527985109726

Epoch: 5| Step: 9
Training loss: 3.59035085722191
Validation loss: 3.297883229165876

Epoch: 5| Step: 10
Training loss: 2.4211369528151665
Validation loss: 3.272866896001971

Epoch: 23| Step: 0
Training loss: 3.7696472466365747
Validation loss: 3.2631722457609937

Epoch: 5| Step: 1
Training loss: 3.3895792249308054
Validation loss: 3.2422700636455324

Epoch: 5| Step: 2
Training loss: 2.5292684074773457
Validation loss: 3.2220856995727845

Epoch: 5| Step: 3
Training loss: 2.845611633631337
Validation loss: 3.2073984823050363

Epoch: 5| Step: 4
Training loss: 3.6935028096734834
Validation loss: 3.1787950095108277

Epoch: 5| Step: 5
Training loss: 3.393321850150813
Validation loss: 3.1680666096375982

Epoch: 5| Step: 6
Training loss: 2.842785011302015
Validation loss: 3.142904394094494

Epoch: 5| Step: 7
Training loss: 3.440002362893646
Validation loss: 3.129717826375845

Epoch: 5| Step: 8
Training loss: 3.409060097757455
Validation loss: 3.122767522630276

Epoch: 5| Step: 9
Training loss: 3.601466510676846
Validation loss: 3.107307870326557

Epoch: 5| Step: 10
Training loss: 3.431544884967467
Validation loss: 3.085747875630176

Epoch: 24| Step: 0
Training loss: 3.1520451400738976
Validation loss: 3.062201151561202

Epoch: 5| Step: 1
Training loss: 3.556121603955858
Validation loss: 3.0544532333773975

Epoch: 5| Step: 2
Training loss: 3.748887978024596
Validation loss: 3.0383445447807906

Epoch: 5| Step: 3
Training loss: 3.3716303640294716
Validation loss: 3.0128322861430017

Epoch: 5| Step: 4
Training loss: 2.7783132757489977
Validation loss: 3.0042173913977637

Epoch: 5| Step: 5
Training loss: 3.4244273521458317
Validation loss: 2.993370283113323

Epoch: 5| Step: 6
Training loss: 2.826587406552701
Validation loss: 2.9770629692898174

Epoch: 5| Step: 7
Training loss: 2.8077705460833378
Validation loss: 2.96925630165055

Epoch: 5| Step: 8
Training loss: 3.38335528875534
Validation loss: 2.94105552860802

Epoch: 5| Step: 9
Training loss: 3.077698963715406
Validation loss: 2.9335594023942972

Epoch: 5| Step: 10
Training loss: 2.868271126598089
Validation loss: 2.919679971990174

Epoch: 25| Step: 0
Training loss: 2.575329368785098
Validation loss: 2.8980044635240763

Epoch: 5| Step: 1
Training loss: 3.854049405900256
Validation loss: 2.8977522448374606

Epoch: 5| Step: 2
Training loss: 2.8724370396074463
Validation loss: 2.8690637694518797

Epoch: 5| Step: 3
Training loss: 3.434753013959918
Validation loss: 2.8809331243692564

Epoch: 5| Step: 4
Training loss: 3.379545047771879
Validation loss: 2.841808354448614

Epoch: 5| Step: 5
Training loss: 2.9937078930913943
Validation loss: 2.850205623852747

Epoch: 5| Step: 6
Training loss: 2.3328692337976236
Validation loss: 2.8457021358321977

Epoch: 5| Step: 7
Training loss: 2.5678764324346717
Validation loss: 2.8388381018982014

Epoch: 5| Step: 8
Training loss: 3.0629482330520923
Validation loss: 2.8240763283211434

Epoch: 5| Step: 9
Training loss: 3.0261870900248398
Validation loss: 2.82334778520122

Epoch: 5| Step: 10
Training loss: 3.6496577376752537
Validation loss: 2.809674313581668

Epoch: 26| Step: 0
Training loss: 2.4167629310464798
Validation loss: 2.802066648462345

Epoch: 5| Step: 1
Training loss: 3.1336906134719036
Validation loss: 2.7851050642762374

Epoch: 5| Step: 2
Training loss: 3.435714674208381
Validation loss: 2.7764806371317095

Epoch: 5| Step: 3
Training loss: 3.989587941511529
Validation loss: 2.786519222765375

Epoch: 5| Step: 4
Training loss: 2.671970209578094
Validation loss: 2.7686433676812814

Epoch: 5| Step: 5
Training loss: 2.8550099892783902
Validation loss: 2.76455264270854

Epoch: 5| Step: 6
Training loss: 3.177737376112596
Validation loss: 2.7557677856266944

Epoch: 5| Step: 7
Training loss: 3.2262655865109107
Validation loss: 2.7699869309416134

Epoch: 5| Step: 8
Training loss: 3.070347754200829
Validation loss: 2.7464026342435113

Epoch: 5| Step: 9
Training loss: 2.530783716275829
Validation loss: 2.7442128993144173

Epoch: 5| Step: 10
Training loss: 2.5321229912775847
Validation loss: 2.755907176457651

Epoch: 27| Step: 0
Training loss: 3.0343580534252577
Validation loss: 2.737156545532059

Epoch: 5| Step: 1
Training loss: 3.243917495430962
Validation loss: 2.7374863266164424

Epoch: 5| Step: 2
Training loss: 3.408836013050083
Validation loss: 2.7331109209934947

Epoch: 5| Step: 3
Training loss: 2.9139756095143006
Validation loss: 2.7260646166274203

Epoch: 5| Step: 4
Training loss: 3.0471538709518486
Validation loss: 2.725375375090344

Epoch: 5| Step: 5
Training loss: 2.677246850706053
Validation loss: 2.714018838434798

Epoch: 5| Step: 6
Training loss: 2.5334766155012174
Validation loss: 2.73274599365866

Epoch: 5| Step: 7
Training loss: 3.6171107768084876
Validation loss: 2.7353901852811364

Epoch: 5| Step: 8
Training loss: 2.937871544249383
Validation loss: 2.725262875016872

Epoch: 5| Step: 9
Training loss: 2.9895138261714256
Validation loss: 2.721261814766371

Epoch: 5| Step: 10
Training loss: 2.6312161368685083
Validation loss: 2.7246716679252265

Epoch: 28| Step: 0
Training loss: 3.280187525622136
Validation loss: 2.722940458566356

Epoch: 5| Step: 1
Training loss: 3.34075165839462
Validation loss: 2.702306289260706

Epoch: 5| Step: 2
Training loss: 3.3333700336979053
Validation loss: 2.713528530087556

Epoch: 5| Step: 3
Training loss: 2.8439632796909438
Validation loss: 2.7181101192043573

Epoch: 5| Step: 4
Training loss: 3.088120087042774
Validation loss: 2.7157980461508875

Epoch: 5| Step: 5
Training loss: 1.8511936770055035
Validation loss: 2.7161230678337946

Epoch: 5| Step: 6
Training loss: 3.1854329606299174
Validation loss: 2.6940992737760876

Epoch: 5| Step: 7
Training loss: 3.4953148682833115
Validation loss: 2.710510302519651

Epoch: 5| Step: 8
Training loss: 2.827662308922475
Validation loss: 2.722656073921652

Epoch: 5| Step: 9
Training loss: 3.074322050460278
Validation loss: 2.7062227290352756

Epoch: 5| Step: 10
Training loss: 2.287824797371249
Validation loss: 2.711606290643676

Epoch: 29| Step: 0
Training loss: 3.161849088364714
Validation loss: 2.6946107982667593

Epoch: 5| Step: 1
Training loss: 2.7004080110903765
Validation loss: 2.7052746576503726

Epoch: 5| Step: 2
Training loss: 2.8529265185338737
Validation loss: 2.694589052131662

Epoch: 5| Step: 3
Training loss: 3.8629901957633126
Validation loss: 2.690333810463249

Epoch: 5| Step: 4
Training loss: 2.9203423544968596
Validation loss: 2.692554519864119

Epoch: 5| Step: 5
Training loss: 2.876986107828161
Validation loss: 2.704715753621242

Epoch: 5| Step: 6
Training loss: 2.4021572629917047
Validation loss: 2.718893549713452

Epoch: 5| Step: 7
Training loss: 2.6203380239991687
Validation loss: 2.7014319173584513

Epoch: 5| Step: 8
Training loss: 3.049557488030474
Validation loss: 2.6912766468307585

Epoch: 5| Step: 9
Training loss: 3.0532424513716414
Validation loss: 2.699975051445587

Epoch: 5| Step: 10
Training loss: 3.1727060817101242
Validation loss: 2.7011913975997257

Epoch: 30| Step: 0
Training loss: 3.3961573877157445
Validation loss: 2.701435249271672

Epoch: 5| Step: 1
Training loss: 3.4428747986192128
Validation loss: 2.7009363266076574

Epoch: 5| Step: 2
Training loss: 2.522373317565765
Validation loss: 2.6875814467019903

Epoch: 5| Step: 3
Training loss: 3.002386892000325
Validation loss: 2.6964746814460665

Epoch: 5| Step: 4
Training loss: 2.5040469792136264
Validation loss: 2.6782044590117096

Epoch: 5| Step: 5
Training loss: 3.081410005759732
Validation loss: 2.7062833668240605

Epoch: 5| Step: 6
Training loss: 3.0354663587354493
Validation loss: 2.7033619812064913

Epoch: 5| Step: 7
Training loss: 3.0014614677999765
Validation loss: 2.6775144224589513

Epoch: 5| Step: 8
Training loss: 3.1466757717916796
Validation loss: 2.6811164201576116

Epoch: 5| Step: 9
Training loss: 2.4100784956942203
Validation loss: 2.7032322143635175

Epoch: 5| Step: 10
Training loss: 3.225383995911424
Validation loss: 2.6827252558546175

Epoch: 31| Step: 0
Training loss: 3.3648371802470254
Validation loss: 2.6688671969996784

Epoch: 5| Step: 1
Training loss: 2.3321596554368367
Validation loss: 2.6962959006689213

Epoch: 5| Step: 2
Training loss: 3.159275681984374
Validation loss: 2.693502497108653

Epoch: 5| Step: 3
Training loss: 3.045488717082844
Validation loss: 2.675010679060948

Epoch: 5| Step: 4
Training loss: 3.6827461505362478
Validation loss: 2.6908535315600552

Epoch: 5| Step: 5
Training loss: 2.714197139442043
Validation loss: 2.690522481539213

Epoch: 5| Step: 6
Training loss: 2.881287871999354
Validation loss: 2.684652193765317

Epoch: 5| Step: 7
Training loss: 2.7225735842005663
Validation loss: 2.688124286786283

Epoch: 5| Step: 8
Training loss: 2.789806277478229
Validation loss: 2.6816926747124605

Epoch: 5| Step: 9
Training loss: 3.3411869671916663
Validation loss: 2.6943272693887104

Epoch: 5| Step: 10
Training loss: 2.44019237400949
Validation loss: 2.677862882602776

Epoch: 32| Step: 0
Training loss: 3.554796690888215
Validation loss: 2.69808515930904

Epoch: 5| Step: 1
Training loss: 3.3020021607122163
Validation loss: 2.6949883854496828

Epoch: 5| Step: 2
Training loss: 2.890140472218905
Validation loss: 2.6757962594039095

Epoch: 5| Step: 3
Training loss: 2.460135968180132
Validation loss: 2.6672308200722896

Epoch: 5| Step: 4
Training loss: 3.1413922487680708
Validation loss: 2.674323219599596

Epoch: 5| Step: 5
Training loss: 2.8513233659362083
Validation loss: 2.6993096149951605

Epoch: 5| Step: 6
Training loss: 3.0449931275238504
Validation loss: 2.693160465966021

Epoch: 5| Step: 7
Training loss: 2.916840974957901
Validation loss: 2.6938361091974983

Epoch: 5| Step: 8
Training loss: 2.749201571992724
Validation loss: 2.677483010545358

Epoch: 5| Step: 9
Training loss: 3.122172640643986
Validation loss: 2.682141493932138

Epoch: 5| Step: 10
Training loss: 2.4841070450524665
Validation loss: 2.688243951394587

Epoch: 33| Step: 0
Training loss: 2.96360059164471
Validation loss: 2.695050309055025

Epoch: 5| Step: 1
Training loss: 2.6311219897811395
Validation loss: 2.684826852402018

Epoch: 5| Step: 2
Training loss: 2.8080150872936476
Validation loss: 2.688721427173557

Epoch: 5| Step: 3
Training loss: 3.538716212966658
Validation loss: 2.689604228056832

Epoch: 5| Step: 4
Training loss: 2.6630860270271803
Validation loss: 2.6873223927393606

Epoch: 5| Step: 5
Training loss: 3.5620250719956186
Validation loss: 2.6771350831812892

Epoch: 5| Step: 6
Training loss: 2.8232982607497976
Validation loss: 2.6862333841956674

Epoch: 5| Step: 7
Training loss: 3.003436822014981
Validation loss: 2.6815501307004945

Epoch: 5| Step: 8
Training loss: 3.467527294312793
Validation loss: 2.684184819628833

Epoch: 5| Step: 9
Training loss: 2.3457472365882532
Validation loss: 2.7073517818416524

Epoch: 5| Step: 10
Training loss: 2.5056320646304884
Validation loss: 2.7010715055403556

Epoch: 34| Step: 0
Training loss: 2.5557740493563834
Validation loss: 2.6933529500887574

Epoch: 5| Step: 1
Training loss: 3.645258889129058
Validation loss: 2.7006369749012094

Epoch: 5| Step: 2
Training loss: 2.869650632481669
Validation loss: 2.6820093095696502

Epoch: 5| Step: 3
Training loss: 2.5368178554732985
Validation loss: 2.6711462706572346

Epoch: 5| Step: 4
Training loss: 3.500276827082529
Validation loss: 2.69548011937461

Epoch: 5| Step: 5
Training loss: 3.2385960553594884
Validation loss: 2.6910516327356917

Epoch: 5| Step: 6
Training loss: 2.8653515334772433
Validation loss: 2.6885773144268903

Epoch: 5| Step: 7
Training loss: 2.441917036410865
Validation loss: 2.6867664248876104

Epoch: 5| Step: 8
Training loss: 2.833502278246417
Validation loss: 2.6906825188438797

Epoch: 5| Step: 9
Training loss: 3.102104389502646
Validation loss: 2.6820166114175916

Epoch: 5| Step: 10
Training loss: 2.8110248511812803
Validation loss: 2.691172037864513

Epoch: 35| Step: 0
Training loss: 2.1149089418473572
Validation loss: 2.6808765310664104

Epoch: 5| Step: 1
Training loss: 3.1269186614863775
Validation loss: 2.683503016813245

Epoch: 5| Step: 2
Training loss: 2.2847193634520337
Validation loss: 2.6945740037452945

Epoch: 5| Step: 3
Training loss: 2.7640573832549182
Validation loss: 2.6911630833042968

Epoch: 5| Step: 4
Training loss: 2.8916721406238057
Validation loss: 2.7070188306160663

Epoch: 5| Step: 5
Training loss: 3.049595640299864
Validation loss: 2.6740123444691783

Epoch: 5| Step: 6
Training loss: 3.090292491711128
Validation loss: 2.689861855192162

Epoch: 5| Step: 7
Training loss: 2.873891533829656
Validation loss: 2.6849368359930046

Epoch: 5| Step: 8
Training loss: 3.284287853881465
Validation loss: 2.7049702976288277

Epoch: 5| Step: 9
Training loss: 3.808130355422992
Validation loss: 2.6895471699520397

Epoch: 5| Step: 10
Training loss: 3.0377049883208436
Validation loss: 2.686613718478685

Epoch: 36| Step: 0
Training loss: 2.7148679004939757
Validation loss: 2.697780021437512

Epoch: 5| Step: 1
Training loss: 3.422548689346117
Validation loss: 2.6893800568311277

Epoch: 5| Step: 2
Training loss: 3.2333185064493644
Validation loss: 2.688378883115641

Epoch: 5| Step: 3
Training loss: 2.7999098524840678
Validation loss: 2.6937108066721516

Epoch: 5| Step: 4
Training loss: 2.393072832305568
Validation loss: 2.6794657014349847

Epoch: 5| Step: 5
Training loss: 3.043608964163005
Validation loss: 2.684531417904708

Epoch: 5| Step: 6
Training loss: 2.675658374944455
Validation loss: 2.6945965320532057

Epoch: 5| Step: 7
Training loss: 3.4395087181853667
Validation loss: 2.6982267024797286

Epoch: 5| Step: 8
Training loss: 3.126844243400261
Validation loss: 2.679527189664609

Epoch: 5| Step: 9
Training loss: 2.669878833035923
Validation loss: 2.6923490288418988

Epoch: 5| Step: 10
Training loss: 2.6147920036381556
Validation loss: 2.7015863710832244

Epoch: 37| Step: 0
Training loss: 2.842060803089806
Validation loss: 2.6831891656356572

Epoch: 5| Step: 1
Training loss: 2.8494750024542794
Validation loss: 2.6790536660470465

Epoch: 5| Step: 2
Training loss: 2.7127786589903238
Validation loss: 2.6965747951390755

Epoch: 5| Step: 3
Training loss: 2.9512382817954665
Validation loss: 2.6695403130756277

Epoch: 5| Step: 4
Training loss: 2.577437338007223
Validation loss: 2.6625385072311336

Epoch: 5| Step: 5
Training loss: 3.1215596907562255
Validation loss: 2.699329407016374

Epoch: 5| Step: 6
Training loss: 4.151119880784996
Validation loss: 2.690495822816405

Epoch: 5| Step: 7
Training loss: 2.5717944479062655
Validation loss: 2.6717186117852614

Epoch: 5| Step: 8
Training loss: 2.9072787197202445
Validation loss: 2.6753916582021495

Epoch: 5| Step: 9
Training loss: 2.7798874335517607
Validation loss: 2.682516437259928

Epoch: 5| Step: 10
Training loss: 2.6391028356546937
Validation loss: 2.672999260327383

Epoch: 38| Step: 0
Training loss: 2.8754076461381484
Validation loss: 2.6755709772774234

Epoch: 5| Step: 1
Training loss: 2.654439151815946
Validation loss: 2.682417457053063

Epoch: 5| Step: 2
Training loss: 2.3010292113902295
Validation loss: 2.6802507722931406

Epoch: 5| Step: 3
Training loss: 2.7217480144814097
Validation loss: 2.6788814765944724

Epoch: 5| Step: 4
Training loss: 3.129113655978909
Validation loss: 2.6755258865725695

Epoch: 5| Step: 5
Training loss: 2.975113002650494
Validation loss: 2.666846046900527

Epoch: 5| Step: 6
Training loss: 2.815905903512062
Validation loss: 2.691468658931019

Epoch: 5| Step: 7
Training loss: 3.4914966557036182
Validation loss: 2.664611836753301

Epoch: 5| Step: 8
Training loss: 3.473396419774715
Validation loss: 2.678709889059563

Epoch: 5| Step: 9
Training loss: 2.574778841761827
Validation loss: 2.6759408899441683

Epoch: 5| Step: 10
Training loss: 3.3198631072259914
Validation loss: 2.67583439762731

Epoch: 39| Step: 0
Training loss: 2.8733006306297035
Validation loss: 2.691724504228943

Epoch: 5| Step: 1
Training loss: 2.631007087712472
Validation loss: 2.669066112640294

Epoch: 5| Step: 2
Training loss: 3.151991133130377
Validation loss: 2.6758774731326422

Epoch: 5| Step: 3
Training loss: 2.4867116627785433
Validation loss: 2.6923386099066824

Epoch: 5| Step: 4
Training loss: 3.01421896615892
Validation loss: 2.6991144269984773

Epoch: 5| Step: 5
Training loss: 2.626100400343274
Validation loss: 2.6760954440444302

Epoch: 5| Step: 6
Training loss: 3.1266899117240823
Validation loss: 2.6825378636313397

Epoch: 5| Step: 7
Training loss: 3.414555913331353
Validation loss: 2.677685332161629

Epoch: 5| Step: 8
Training loss: 3.09974951808854
Validation loss: 2.68838740638735

Epoch: 5| Step: 9
Training loss: 2.820078324927878
Validation loss: 2.6917869343530634

Epoch: 5| Step: 10
Training loss: 3.0628451717250536
Validation loss: 2.688348820677859

Epoch: 40| Step: 0
Training loss: 2.8150681532474446
Validation loss: 2.686115934905315

Epoch: 5| Step: 1
Training loss: 3.396391434629065
Validation loss: 2.6887143447188526

Epoch: 5| Step: 2
Training loss: 2.8639010269922434
Validation loss: 2.6699197750568042

Epoch: 5| Step: 3
Training loss: 2.9093339206241584
Validation loss: 2.6857596741432705

Epoch: 5| Step: 4
Training loss: 3.0830068845025527
Validation loss: 2.6749906261250334

Epoch: 5| Step: 5
Training loss: 2.9509999536289997
Validation loss: 2.6743946554345985

Epoch: 5| Step: 6
Training loss: 2.784708337492877
Validation loss: 2.695470740672796

Epoch: 5| Step: 7
Training loss: 2.819612453154924
Validation loss: 2.6881597981994427

Epoch: 5| Step: 8
Training loss: 3.011880556106588
Validation loss: 2.670976556942293

Epoch: 5| Step: 9
Training loss: 2.475170237533764
Validation loss: 2.673360126272515

Epoch: 5| Step: 10
Training loss: 3.109462257579441
Validation loss: 2.681663326010827

Epoch: 41| Step: 0
Training loss: 3.3066471142600973
Validation loss: 2.658589841405073

Epoch: 5| Step: 1
Training loss: 2.446046176814511
Validation loss: 2.6902036700981293

Epoch: 5| Step: 2
Training loss: 3.5550005764430956
Validation loss: 2.6929766253402008

Epoch: 5| Step: 3
Training loss: 2.832468648873379
Validation loss: 2.6863311826299667

Epoch: 5| Step: 4
Training loss: 2.8368547285641124
Validation loss: 2.6624087996930785

Epoch: 5| Step: 5
Training loss: 3.4896782857398
Validation loss: 2.6811040647975273

Epoch: 5| Step: 6
Training loss: 2.4722977268342627
Validation loss: 2.682023164806802

Epoch: 5| Step: 7
Training loss: 2.8050485872626694
Validation loss: 2.658683244833601

Epoch: 5| Step: 8
Training loss: 2.484178547319447
Validation loss: 2.6593809838956264

Epoch: 5| Step: 9
Training loss: 2.814557742650281
Validation loss: 2.6796243909449715

Epoch: 5| Step: 10
Training loss: 2.977084857432191
Validation loss: 2.676161548501783

Epoch: 42| Step: 0
Training loss: 2.9617438916764582
Validation loss: 2.669933886989005

Epoch: 5| Step: 1
Training loss: 3.2839100545815856
Validation loss: 2.6745694126433706

Epoch: 5| Step: 2
Training loss: 3.177569609569116
Validation loss: 2.672763947400464

Epoch: 5| Step: 3
Training loss: 3.463375705194224
Validation loss: 2.6724657442985986

Epoch: 5| Step: 4
Training loss: 2.6283263067015694
Validation loss: 2.6708899044905317

Epoch: 5| Step: 5
Training loss: 2.0976432927759734
Validation loss: 2.6891698149862324

Epoch: 5| Step: 6
Training loss: 2.776097271465542
Validation loss: 2.669713148700878

Epoch: 5| Step: 7
Training loss: 2.9031501563617583
Validation loss: 2.6798435456222975

Epoch: 5| Step: 8
Training loss: 2.599771060400858
Validation loss: 2.667034516676544

Epoch: 5| Step: 9
Training loss: 3.634087845273293
Validation loss: 2.661758918003669

Epoch: 5| Step: 10
Training loss: 2.0916243053670622
Validation loss: 2.6706832120837687

Epoch: 43| Step: 0
Training loss: 2.095147648527048
Validation loss: 2.6704599878964155

Epoch: 5| Step: 1
Training loss: 2.8291558341791325
Validation loss: 2.669719752457111

Epoch: 5| Step: 2
Training loss: 2.788274317054327
Validation loss: 2.6580048209757545

Epoch: 5| Step: 3
Training loss: 3.5563711350229483
Validation loss: 2.6536724887020258

Epoch: 5| Step: 4
Training loss: 3.0416593856376
Validation loss: 2.6732722794625627

Epoch: 5| Step: 5
Training loss: 3.427411899449964
Validation loss: 2.6724705848167454

Epoch: 5| Step: 6
Training loss: 2.827783469132161
Validation loss: 2.6689638845625274

Epoch: 5| Step: 7
Training loss: 3.139466181043603
Validation loss: 2.660056302849248

Epoch: 5| Step: 8
Training loss: 2.6066769110762062
Validation loss: 2.6695624994959615

Epoch: 5| Step: 9
Training loss: 2.734292688493252
Validation loss: 2.6744951259534955

Epoch: 5| Step: 10
Training loss: 2.942632695579132
Validation loss: 2.67906304480575

Epoch: 44| Step: 0
Training loss: 2.6013350287072963
Validation loss: 2.657460453614862

Epoch: 5| Step: 1
Training loss: 3.9489312524788525
Validation loss: 2.6760060095532334

Epoch: 5| Step: 2
Training loss: 3.040098665794601
Validation loss: 2.659887086310029

Epoch: 5| Step: 3
Training loss: 2.107526407132944
Validation loss: 2.6562150464300682

Epoch: 5| Step: 4
Training loss: 3.0898364967617935
Validation loss: 2.660986508105823

Epoch: 5| Step: 5
Training loss: 3.081074187735438
Validation loss: 2.669499738809169

Epoch: 5| Step: 6
Training loss: 2.1948670719363528
Validation loss: 2.6687350218221133

Epoch: 5| Step: 7
Training loss: 3.1458173503006552
Validation loss: 2.646528822305357

Epoch: 5| Step: 8
Training loss: 2.4629042743785634
Validation loss: 2.6785909197479527

Epoch: 5| Step: 9
Training loss: 3.307887771031131
Validation loss: 2.662222930836253

Epoch: 5| Step: 10
Training loss: 2.831865734656842
Validation loss: 2.6652295838236033

Epoch: 45| Step: 0
Training loss: 2.728144233347419
Validation loss: 2.6672604409951624

Epoch: 5| Step: 1
Training loss: 2.642251140385256
Validation loss: 2.66357932037776

Epoch: 5| Step: 2
Training loss: 2.038833897663555
Validation loss: 2.660380093014472

Epoch: 5| Step: 3
Training loss: 3.1275602915172067
Validation loss: 2.668053630363325

Epoch: 5| Step: 4
Training loss: 3.3914221604401753
Validation loss: 2.663012433706626

Epoch: 5| Step: 5
Training loss: 3.2433175564964083
Validation loss: 2.6760666805995688

Epoch: 5| Step: 6
Training loss: 3.0044957489069932
Validation loss: 2.676017736528489

Epoch: 5| Step: 7
Training loss: 2.6675028582685436
Validation loss: 2.6512182207428814

Epoch: 5| Step: 8
Training loss: 2.794831536390517
Validation loss: 2.6617413445333096

Epoch: 5| Step: 9
Training loss: 2.906577799368904
Validation loss: 2.671735515118709

Epoch: 5| Step: 10
Training loss: 3.415796044927805
Validation loss: 2.6748100355915865

Epoch: 46| Step: 0
Training loss: 2.5051247522656555
Validation loss: 2.6763001551611674

Epoch: 5| Step: 1
Training loss: 2.811443215087254
Validation loss: 2.6609786649134173

Epoch: 5| Step: 2
Training loss: 3.1238868256606436
Validation loss: 2.6768020099656007

Epoch: 5| Step: 3
Training loss: 3.3128872051295577
Validation loss: 2.661110948854954

Epoch: 5| Step: 4
Training loss: 3.0426239876101135
Validation loss: 2.66026682471272

Epoch: 5| Step: 5
Training loss: 3.097538949445989
Validation loss: 2.661460261110123

Epoch: 5| Step: 6
Training loss: 2.7516594128327285
Validation loss: 2.661785595823974

Epoch: 5| Step: 7
Training loss: 3.0816353083064323
Validation loss: 2.6708643993642784

Epoch: 5| Step: 8
Training loss: 2.7565097055027326
Validation loss: 2.676778154840999

Epoch: 5| Step: 9
Training loss: 2.966622162245781
Validation loss: 2.6855792541043537

Epoch: 5| Step: 10
Training loss: 2.356009501925415
Validation loss: 2.6796882797054

Epoch: 47| Step: 0
Training loss: 2.9034196751307797
Validation loss: 2.6630199936568086

Epoch: 5| Step: 1
Training loss: 3.113405921574493
Validation loss: 2.6761660096915403

Epoch: 5| Step: 2
Training loss: 2.7696918822973378
Validation loss: 2.651163081774943

Epoch: 5| Step: 3
Training loss: 3.5788576134035566
Validation loss: 2.668531378430946

Epoch: 5| Step: 4
Training loss: 2.8946295964757662
Validation loss: 2.6652578572802703

Epoch: 5| Step: 5
Training loss: 2.523242671283528
Validation loss: 2.66607058227778

Epoch: 5| Step: 6
Training loss: 2.6258044145646804
Validation loss: 2.6720878623266158

Epoch: 5| Step: 7
Training loss: 2.578640603034696
Validation loss: 2.6714892461235857

Epoch: 5| Step: 8
Training loss: 3.1404561618951403
Validation loss: 2.6505608250211394

Epoch: 5| Step: 9
Training loss: 3.0186437805316935
Validation loss: 2.6610072484742355

Epoch: 5| Step: 10
Training loss: 2.788064045995492
Validation loss: 2.6520573418515863

Epoch: 48| Step: 0
Training loss: 2.551633263171434
Validation loss: 2.644876304272885

Epoch: 5| Step: 1
Training loss: 3.4706719375093553
Validation loss: 2.673716321953608

Epoch: 5| Step: 2
Training loss: 3.114894243285089
Validation loss: 2.6679394223304413

Epoch: 5| Step: 3
Training loss: 2.754120081181978
Validation loss: 2.6654002799929652

Epoch: 5| Step: 4
Training loss: 2.533935441023489
Validation loss: 2.664940339347799

Epoch: 5| Step: 5
Training loss: 2.6366475865686065
Validation loss: 2.6639434852343133

Epoch: 5| Step: 6
Training loss: 2.0011129858707277
Validation loss: 2.670645220123394

Epoch: 5| Step: 7
Training loss: 3.7165233453278868
Validation loss: 2.6648534454027817

Epoch: 5| Step: 8
Training loss: 3.111562601510713
Validation loss: 2.6814228151612984

Epoch: 5| Step: 9
Training loss: 2.4997462143829763
Validation loss: 2.6576185374537693

Epoch: 5| Step: 10
Training loss: 3.2135141990802576
Validation loss: 2.6656578838734664

Epoch: 49| Step: 0
Training loss: 3.3789011696132327
Validation loss: 2.6521021906802065

Epoch: 5| Step: 1
Training loss: 2.5349287451185623
Validation loss: 2.6716561253281452

Epoch: 5| Step: 2
Training loss: 3.3180008324638735
Validation loss: 2.6792251339655864

Epoch: 5| Step: 3
Training loss: 2.871239566343928
Validation loss: 2.6744904510949827

Epoch: 5| Step: 4
Training loss: 2.4779729346705377
Validation loss: 2.6705111918664852

Epoch: 5| Step: 5
Training loss: 3.199033627027166
Validation loss: 2.656982802395283

Epoch: 5| Step: 6
Training loss: 3.2320688475555954
Validation loss: 2.6448929090531528

Epoch: 5| Step: 7
Training loss: 2.074447935269772
Validation loss: 2.647138151914707

Epoch: 5| Step: 8
Training loss: 2.4022353729364876
Validation loss: 2.655920453412647

Epoch: 5| Step: 9
Training loss: 3.3817176368548334
Validation loss: 2.6823882615525205

Epoch: 5| Step: 10
Training loss: 2.5356820946843346
Validation loss: 2.6738414794782055

Epoch: 50| Step: 0
Training loss: 2.510954887553072
Validation loss: 2.6663643062462716

Epoch: 5| Step: 1
Training loss: 2.8758712775189363
Validation loss: 2.6561320877686794

Epoch: 5| Step: 2
Training loss: 3.5879251793042113
Validation loss: 2.637424587510471

Epoch: 5| Step: 3
Training loss: 2.8505646932554556
Validation loss: 2.6835730198814196

Epoch: 5| Step: 4
Training loss: 3.095630112999418
Validation loss: 2.6612488973059016

Epoch: 5| Step: 5
Training loss: 2.60642509695584
Validation loss: 2.664706829617355

Epoch: 5| Step: 6
Training loss: 3.0648234370343936
Validation loss: 2.683499312982267

Epoch: 5| Step: 7
Training loss: 3.0979657974571566
Validation loss: 2.673940567651779

Epoch: 5| Step: 8
Training loss: 2.5946658252617993
Validation loss: 2.6741454830343057

Epoch: 5| Step: 9
Training loss: 2.6947692323588166
Validation loss: 2.6695273140120963

Epoch: 5| Step: 10
Training loss: 2.839371548817859
Validation loss: 2.6517897971669817

Epoch: 51| Step: 0
Training loss: 2.084144764871179
Validation loss: 2.6527895696752646

Epoch: 5| Step: 1
Training loss: 3.042278402466282
Validation loss: 2.672659071382675

Epoch: 5| Step: 2
Training loss: 2.728770239384061
Validation loss: 2.6624325823207715

Epoch: 5| Step: 3
Training loss: 3.189733283872056
Validation loss: 2.651697058741692

Epoch: 5| Step: 4
Training loss: 2.6203570403633805
Validation loss: 2.6543064812817465

Epoch: 5| Step: 5
Training loss: 3.637886687499547
Validation loss: 2.66237967750439

Epoch: 5| Step: 6
Training loss: 3.088305064890469
Validation loss: 2.654225811001764

Epoch: 5| Step: 7
Training loss: 3.010438877186575
Validation loss: 2.6654254257487917

Epoch: 5| Step: 8
Training loss: 2.892050561697706
Validation loss: 2.651477616301073

Epoch: 5| Step: 9
Training loss: 1.9939423256073658
Validation loss: 2.654790295046413

Epoch: 5| Step: 10
Training loss: 3.1287384559701854
Validation loss: 2.652909531281783

Epoch: 52| Step: 0
Training loss: 3.267016100845852
Validation loss: 2.6654223537165262

Epoch: 5| Step: 1
Training loss: 2.7464132326602364
Validation loss: 2.675589314591877

Epoch: 5| Step: 2
Training loss: 2.8099132085951775
Validation loss: 2.6592540462965006

Epoch: 5| Step: 3
Training loss: 2.3596107415663052
Validation loss: 2.6460114237372765

Epoch: 5| Step: 4
Training loss: 2.4789765442680674
Validation loss: 2.6731719423210896

Epoch: 5| Step: 5
Training loss: 3.120703069992724
Validation loss: 2.65277387152032

Epoch: 5| Step: 6
Training loss: 2.786081724771496
Validation loss: 2.656092994870677

Epoch: 5| Step: 7
Training loss: 3.220648936873586
Validation loss: 2.6661802150688794

Epoch: 5| Step: 8
Training loss: 2.838280080705271
Validation loss: 2.6782249416049506

Epoch: 5| Step: 9
Training loss: 3.22249836852844
Validation loss: 2.6660141604827916

Epoch: 5| Step: 10
Training loss: 2.8542589789913655
Validation loss: 2.6577998022434333

Epoch: 53| Step: 0
Training loss: 3.1363590552054057
Validation loss: 2.6543455879355555

Epoch: 5| Step: 1
Training loss: 2.3419595618922573
Validation loss: 2.6793558491962033

Epoch: 5| Step: 2
Training loss: 3.198924813839739
Validation loss: 2.6569131031959627

Epoch: 5| Step: 3
Training loss: 2.896108179748497
Validation loss: 2.642858311421696

Epoch: 5| Step: 4
Training loss: 2.1644760452816625
Validation loss: 2.6435273572941216

Epoch: 5| Step: 5
Training loss: 3.0245493340349454
Validation loss: 2.6601034068861704

Epoch: 5| Step: 6
Training loss: 2.965555500144699
Validation loss: 2.653734670211077

Epoch: 5| Step: 7
Training loss: 2.504293759929723
Validation loss: 2.6562313496600254

Epoch: 5| Step: 8
Training loss: 3.1093023090396055
Validation loss: 2.6619770674816476

Epoch: 5| Step: 9
Training loss: 3.0856156193384128
Validation loss: 2.6488457615330865

Epoch: 5| Step: 10
Training loss: 3.1385343814684696
Validation loss: 2.6753909970233454

Epoch: 54| Step: 0
Training loss: 2.5564742533243234
Validation loss: 2.6554055055589325

Epoch: 5| Step: 1
Training loss: 3.374925824515835
Validation loss: 2.66621998409323

Epoch: 5| Step: 2
Training loss: 3.1031533108406126
Validation loss: 2.6423268138460694

Epoch: 5| Step: 3
Training loss: 2.9356868911011285
Validation loss: 2.65178231927854

Epoch: 5| Step: 4
Training loss: 2.827430429049621
Validation loss: 2.643601691845129

Epoch: 5| Step: 5
Training loss: 3.2483940558305986
Validation loss: 2.6614353264104276

Epoch: 5| Step: 6
Training loss: 2.1697361795403034
Validation loss: 2.662109648495113

Epoch: 5| Step: 7
Training loss: 2.9645217499510133
Validation loss: 2.651384603474553

Epoch: 5| Step: 8
Training loss: 2.8465391461340617
Validation loss: 2.648358581162828

Epoch: 5| Step: 9
Training loss: 2.696111499835171
Validation loss: 2.656571191120036

Epoch: 5| Step: 10
Training loss: 2.7997148470772997
Validation loss: 2.641295774353881

Epoch: 55| Step: 0
Training loss: 2.6605830137324085
Validation loss: 2.654605523884465

Epoch: 5| Step: 1
Training loss: 3.5596595282029537
Validation loss: 2.651647442006737

Epoch: 5| Step: 2
Training loss: 3.105131848372363
Validation loss: 2.6547871537331664

Epoch: 5| Step: 3
Training loss: 2.7046056672249925
Validation loss: 2.6655599097725053

Epoch: 5| Step: 4
Training loss: 2.6873887504794713
Validation loss: 2.6559551275609117

Epoch: 5| Step: 5
Training loss: 3.236735933494394
Validation loss: 2.6641046332284737

Epoch: 5| Step: 6
Training loss: 2.4336268635512996
Validation loss: 2.6523050429877566

Epoch: 5| Step: 7
Training loss: 2.919275443180924
Validation loss: 2.646028817800144

Epoch: 5| Step: 8
Training loss: 3.146750781610673
Validation loss: 2.6587280951906918

Epoch: 5| Step: 9
Training loss: 2.226289538332782
Validation loss: 2.645680092141501

Epoch: 5| Step: 10
Training loss: 2.706558780806351
Validation loss: 2.65156267215579

Epoch: 56| Step: 0
Training loss: 2.403902370088984
Validation loss: 2.657169861739228

Epoch: 5| Step: 1
Training loss: 2.843644863323058
Validation loss: 2.650702087623213

Epoch: 5| Step: 2
Training loss: 2.7146980520987234
Validation loss: 2.6596909787517142

Epoch: 5| Step: 3
Training loss: 2.726899921339204
Validation loss: 2.651945871885582

Epoch: 5| Step: 4
Training loss: 2.3545607402984188
Validation loss: 2.672268276107546

Epoch: 5| Step: 5
Training loss: 2.8903844784858084
Validation loss: 2.6601162235964493

Epoch: 5| Step: 6
Training loss: 2.414699334645931
Validation loss: 2.6524952553695273

Epoch: 5| Step: 7
Training loss: 2.78052091150321
Validation loss: 2.6520075989388228

Epoch: 5| Step: 8
Training loss: 3.1155264116642223
Validation loss: 2.6670040242803545

Epoch: 5| Step: 9
Training loss: 2.9537047770715366
Validation loss: 2.655959017002518

Epoch: 5| Step: 10
Training loss: 4.175716388937333
Validation loss: 2.6533213811180474

Epoch: 57| Step: 0
Training loss: 3.28419623936507
Validation loss: 2.635464737671917

Epoch: 5| Step: 1
Training loss: 2.5340784541437094
Validation loss: 2.65297664444625

Epoch: 5| Step: 2
Training loss: 2.4003261622688314
Validation loss: 2.6835894769338204

Epoch: 5| Step: 3
Training loss: 3.1179612807927795
Validation loss: 2.657751784425378

Epoch: 5| Step: 4
Training loss: 3.3702544297975225
Validation loss: 2.64765040955633

Epoch: 5| Step: 5
Training loss: 2.741447153164056
Validation loss: 2.648702283163274

Epoch: 5| Step: 6
Training loss: 2.7963653611596
Validation loss: 2.65484159265827

Epoch: 5| Step: 7
Training loss: 3.0180120162370736
Validation loss: 2.663009675614275

Epoch: 5| Step: 8
Training loss: 2.7788498197911613
Validation loss: 2.6448243510213207

Epoch: 5| Step: 9
Training loss: 2.7378181795170837
Validation loss: 2.658484344508472

Epoch: 5| Step: 10
Training loss: 2.69552372643797
Validation loss: 2.635961769426483

Epoch: 58| Step: 0
Training loss: 3.175685604292719
Validation loss: 2.647143215973812

Epoch: 5| Step: 1
Training loss: 2.79982274039349
Validation loss: 2.6547569967437386

Epoch: 5| Step: 2
Training loss: 3.0772037579821796
Validation loss: 2.6619015399626327

Epoch: 5| Step: 3
Training loss: 2.4079031281740573
Validation loss: 2.642551149466268

Epoch: 5| Step: 4
Training loss: 3.186406864391981
Validation loss: 2.6468279339143796

Epoch: 5| Step: 5
Training loss: 2.6049979955625235
Validation loss: 2.650808237564634

Epoch: 5| Step: 6
Training loss: 2.7402805751350803
Validation loss: 2.6491598192773225

Epoch: 5| Step: 7
Training loss: 3.0742973889540974
Validation loss: 2.65854164692442

Epoch: 5| Step: 8
Training loss: 2.8465567351234817
Validation loss: 2.648133947552823

Epoch: 5| Step: 9
Training loss: 2.7865274486110474
Validation loss: 2.66267793280278

Epoch: 5| Step: 10
Training loss: 2.9883916697328208
Validation loss: 2.6330945317377736

Epoch: 59| Step: 0
Training loss: 3.111713699233285
Validation loss: 2.646063507728931

Epoch: 5| Step: 1
Training loss: 3.0732376879237
Validation loss: 2.6478230784315446

Epoch: 5| Step: 2
Training loss: 2.3979727328916085
Validation loss: 2.6674451611358436

Epoch: 5| Step: 3
Training loss: 3.2048351653704166
Validation loss: 2.660135163765152

Epoch: 5| Step: 4
Training loss: 2.659503694282515
Validation loss: 2.6555674429367833

Epoch: 5| Step: 5
Training loss: 2.7019461117276067
Validation loss: 2.6517424468407205

Epoch: 5| Step: 6
Training loss: 3.093241486035349
Validation loss: 2.646463835644529

Epoch: 5| Step: 7
Training loss: 3.0210812872488284
Validation loss: 2.654557561278503

Epoch: 5| Step: 8
Training loss: 2.6052081250832915
Validation loss: 2.664332683256504

Epoch: 5| Step: 9
Training loss: 2.8067668549271207
Validation loss: 2.6615503861667027

Epoch: 5| Step: 10
Training loss: 2.56332319109646
Validation loss: 2.6465310977346714

Epoch: 60| Step: 0
Training loss: 3.010952982048611
Validation loss: 2.658482450575182

Epoch: 5| Step: 1
Training loss: 2.725661864089358
Validation loss: 2.6510541174895383

Epoch: 5| Step: 2
Training loss: 2.7315074598534164
Validation loss: 2.6402460185401972

Epoch: 5| Step: 3
Training loss: 2.805303054458815
Validation loss: 2.6650932102486817

Epoch: 5| Step: 4
Training loss: 2.973844794373598
Validation loss: 2.6389988776102475

Epoch: 5| Step: 5
Training loss: 2.389940450556928
Validation loss: 2.635582209828045

Epoch: 5| Step: 6
Training loss: 3.1588445895501374
Validation loss: 2.650439028632286

Epoch: 5| Step: 7
Training loss: 3.304813463772876
Validation loss: 2.658674245936584

Epoch: 5| Step: 8
Training loss: 3.110244399399993
Validation loss: 2.6483429051438723

Epoch: 5| Step: 9
Training loss: 2.3953656832071846
Validation loss: 2.653868064852109

Epoch: 5| Step: 10
Training loss: 2.7445703136119257
Validation loss: 2.652916848478202

Epoch: 61| Step: 0
Training loss: 2.9254440296630047
Validation loss: 2.6347421667133726

Epoch: 5| Step: 1
Training loss: 3.202329657831429
Validation loss: 2.660731425349247

Epoch: 5| Step: 2
Training loss: 2.3890244854534135
Validation loss: 2.6538495049996373

Epoch: 5| Step: 3
Training loss: 2.724952550352458
Validation loss: 2.636836894497877

Epoch: 5| Step: 4
Training loss: 2.9983021382067383
Validation loss: 2.633707186549127

Epoch: 5| Step: 5
Training loss: 3.223966057212998
Validation loss: 2.6415134097312536

Epoch: 5| Step: 6
Training loss: 2.807203009531882
Validation loss: 2.6495946897702263

Epoch: 5| Step: 7
Training loss: 2.7854934210082467
Validation loss: 2.6481890692414667

Epoch: 5| Step: 8
Training loss: 3.2611402169841677
Validation loss: 2.655182500277387

Epoch: 5| Step: 9
Training loss: 2.3027300264351434
Validation loss: 2.658527268158176

Epoch: 5| Step: 10
Training loss: 2.6747908715472413
Validation loss: 2.6663406327220662

Epoch: 62| Step: 0
Training loss: 3.4666524507769076
Validation loss: 2.6464938430244427

Epoch: 5| Step: 1
Training loss: 2.521446363663432
Validation loss: 2.6549542084041464

Epoch: 5| Step: 2
Training loss: 2.876533762608525
Validation loss: 2.628210199679755

Epoch: 5| Step: 3
Training loss: 2.7623601058129643
Validation loss: 2.6278130683352328

Epoch: 5| Step: 4
Training loss: 2.681902178784645
Validation loss: 2.6451970248399745

Epoch: 5| Step: 5
Training loss: 2.318105656431799
Validation loss: 2.6555161989279332

Epoch: 5| Step: 6
Training loss: 2.938261379833023
Validation loss: 2.6581458326464826

Epoch: 5| Step: 7
Training loss: 2.966765694269162
Validation loss: 2.6485367376226283

Epoch: 5| Step: 8
Training loss: 3.0399452633698303
Validation loss: 2.658650662076749

Epoch: 5| Step: 9
Training loss: 2.4810992062963493
Validation loss: 2.6527506700879666

Epoch: 5| Step: 10
Training loss: 3.2709829373172683
Validation loss: 2.6499327267392467

Epoch: 63| Step: 0
Training loss: 2.807496345904886
Validation loss: 2.6391240569073844

Epoch: 5| Step: 1
Training loss: 2.9688018794295115
Validation loss: 2.648234047472466

Epoch: 5| Step: 2
Training loss: 3.2790377470765613
Validation loss: 2.642099346443284

Epoch: 5| Step: 3
Training loss: 2.951160564691265
Validation loss: 2.6381852695230137

Epoch: 5| Step: 4
Training loss: 3.00934100265551
Validation loss: 2.6534259287235953

Epoch: 5| Step: 5
Training loss: 2.7852336343124033
Validation loss: 2.6388386310511547

Epoch: 5| Step: 6
Training loss: 2.987981245153108
Validation loss: 2.645955696664497

Epoch: 5| Step: 7
Training loss: 2.8029230459688925
Validation loss: 2.645028947817993

Epoch: 5| Step: 8
Training loss: 2.7905444741244763
Validation loss: 2.6613026742347126

Epoch: 5| Step: 9
Training loss: 2.6292455944500617
Validation loss: 2.649948020892733

Epoch: 5| Step: 10
Training loss: 2.0908674068216127
Validation loss: 2.6288762047219154

Epoch: 64| Step: 0
Training loss: 3.235931022191805
Validation loss: 2.6324518603716083

Epoch: 5| Step: 1
Training loss: 2.716648912274281
Validation loss: 2.6560384744561234

Epoch: 5| Step: 2
Training loss: 2.6880078390381814
Validation loss: 2.6627934159152296

Epoch: 5| Step: 3
Training loss: 2.6518268334309454
Validation loss: 2.630960443975945

Epoch: 5| Step: 4
Training loss: 3.3253802949647935
Validation loss: 2.6449317584618837

Epoch: 5| Step: 5
Training loss: 3.0762992905159767
Validation loss: 2.658427680217981

Epoch: 5| Step: 6
Training loss: 2.8149116349114087
Validation loss: 2.6327376485409535

Epoch: 5| Step: 7
Training loss: 2.690634917308505
Validation loss: 2.6609239093256005

Epoch: 5| Step: 8
Training loss: 2.765002854192271
Validation loss: 2.6584322328853967

Epoch: 5| Step: 9
Training loss: 2.6411673987597766
Validation loss: 2.6696168311028448

Epoch: 5| Step: 10
Training loss: 2.788561864206676
Validation loss: 2.655059202017072

Epoch: 65| Step: 0
Training loss: 3.086212068728671
Validation loss: 2.6207045927694095

Epoch: 5| Step: 1
Training loss: 2.9599279126848708
Validation loss: 2.6435592473556855

Epoch: 5| Step: 2
Training loss: 3.350243368845488
Validation loss: 2.6498748540785972

Epoch: 5| Step: 3
Training loss: 2.4475899228028983
Validation loss: 2.6461122976344487

Epoch: 5| Step: 4
Training loss: 3.0426352713612013
Validation loss: 2.6294714263422465

Epoch: 5| Step: 5
Training loss: 2.708840474306392
Validation loss: 2.650885029378408

Epoch: 5| Step: 6
Training loss: 2.5335155756132623
Validation loss: 2.6393635831457374

Epoch: 5| Step: 7
Training loss: 2.5005960707551167
Validation loss: 2.6340820760782497

Epoch: 5| Step: 8
Training loss: 2.7863014723694164
Validation loss: 2.643431461743581

Epoch: 5| Step: 9
Training loss: 2.996924731465463
Validation loss: 2.6480207004856395

Epoch: 5| Step: 10
Training loss: 2.800161380885517
Validation loss: 2.624856969371448

Epoch: 66| Step: 0
Training loss: 2.5466932922322876
Validation loss: 2.634908296780655

Epoch: 5| Step: 1
Training loss: 2.9247489299777105
Validation loss: 2.6345203963325243

Epoch: 5| Step: 2
Training loss: 3.07457904570505
Validation loss: 2.632875130349877

Epoch: 5| Step: 3
Training loss: 2.4965379585361536
Validation loss: 2.6506426746058365

Epoch: 5| Step: 4
Training loss: 3.183238153549293
Validation loss: 2.647928885842881

Epoch: 5| Step: 5
Training loss: 2.4091465348157217
Validation loss: 2.6354608136072635

Epoch: 5| Step: 6
Training loss: 3.1784020527247097
Validation loss: 2.6541025301163907

Epoch: 5| Step: 7
Training loss: 2.809040739650132
Validation loss: 2.6592592203211205

Epoch: 5| Step: 8
Training loss: 2.878641393271682
Validation loss: 2.638904720626631

Epoch: 5| Step: 9
Training loss: 2.9328661141959462
Validation loss: 2.642723451119946

Epoch: 5| Step: 10
Training loss: 2.8655437362280547
Validation loss: 2.662665504881948

Epoch: 67| Step: 0
Training loss: 2.629024689997733
Validation loss: 2.633723705031279

Epoch: 5| Step: 1
Training loss: 2.0696306365338932
Validation loss: 2.6375090550644997

Epoch: 5| Step: 2
Training loss: 2.961537162025921
Validation loss: 2.622916465608815

Epoch: 5| Step: 3
Training loss: 2.1714557270452977
Validation loss: 2.65855261585248

Epoch: 5| Step: 4
Training loss: 3.2183738414625864
Validation loss: 2.6508687029387454

Epoch: 5| Step: 5
Training loss: 2.091450581527841
Validation loss: 2.654440812980607

Epoch: 5| Step: 6
Training loss: 2.853237214237191
Validation loss: 2.650506607685613

Epoch: 5| Step: 7
Training loss: 3.6787903941429017
Validation loss: 2.6419940672880786

Epoch: 5| Step: 8
Training loss: 2.821889843062084
Validation loss: 2.653023283766622

Epoch: 5| Step: 9
Training loss: 3.2470930744033026
Validation loss: 2.646065226469618

Epoch: 5| Step: 10
Training loss: 3.1093003153817276
Validation loss: 2.6514635405347136

Epoch: 68| Step: 0
Training loss: 3.576610661186972
Validation loss: 2.6528663901425475

Epoch: 5| Step: 1
Training loss: 2.2099028953519126
Validation loss: 2.632972755008482

Epoch: 5| Step: 2
Training loss: 2.8710450875446654
Validation loss: 2.6411139233459244

Epoch: 5| Step: 3
Training loss: 2.9860892440428954
Validation loss: 2.6587507430631434

Epoch: 5| Step: 4
Training loss: 3.251784641609545
Validation loss: 2.6558339728740594

Epoch: 5| Step: 5
Training loss: 2.83423355237474
Validation loss: 2.6333008031547953

Epoch: 5| Step: 6
Training loss: 2.7330202942983486
Validation loss: 2.6382820009751837

Epoch: 5| Step: 7
Training loss: 2.301051281042176
Validation loss: 2.6467984272046152

Epoch: 5| Step: 8
Training loss: 3.2775683865952505
Validation loss: 2.632086852637366

Epoch: 5| Step: 9
Training loss: 2.654279089861773
Validation loss: 2.6608091861932857

Epoch: 5| Step: 10
Training loss: 2.092651762386806
Validation loss: 2.6475159792738525

Epoch: 69| Step: 0
Training loss: 2.8332944381138496
Validation loss: 2.6274346303708853

Epoch: 5| Step: 1
Training loss: 2.6796076014760413
Validation loss: 2.634813946913786

Epoch: 5| Step: 2
Training loss: 2.3794670258329633
Validation loss: 2.6542379906113918

Epoch: 5| Step: 3
Training loss: 2.4107061961204796
Validation loss: 2.6464201457557244

Epoch: 5| Step: 4
Training loss: 3.038652956318051
Validation loss: 2.643130108363129

Epoch: 5| Step: 5
Training loss: 3.520020852027166
Validation loss: 2.6510428767450636

Epoch: 5| Step: 6
Training loss: 2.503519251489416
Validation loss: 2.6295662564799

Epoch: 5| Step: 7
Training loss: 3.827521451744198
Validation loss: 2.6470128334611047

Epoch: 5| Step: 8
Training loss: 2.6965194874488496
Validation loss: 2.631480309870068

Epoch: 5| Step: 9
Training loss: 2.050661501340144
Validation loss: 2.6399208543081283

Epoch: 5| Step: 10
Training loss: 2.8922381874230356
Validation loss: 2.643181970767909

Epoch: 70| Step: 0
Training loss: 2.1441275350373
Validation loss: 2.6413701828686165

Epoch: 5| Step: 1
Training loss: 2.2983374059731867
Validation loss: 2.6520572819185984

Epoch: 5| Step: 2
Training loss: 2.847395519988998
Validation loss: 2.649560417621889

Epoch: 5| Step: 3
Training loss: 2.897377169805707
Validation loss: 2.6632174930003956

Epoch: 5| Step: 4
Training loss: 3.6058250242954055
Validation loss: 2.642718071077085

Epoch: 5| Step: 5
Training loss: 3.0409878709294675
Validation loss: 2.6497330800682355

Epoch: 5| Step: 6
Training loss: 2.8317261419698116
Validation loss: 2.6493615847459524

Epoch: 5| Step: 7
Training loss: 2.6224681815225415
Validation loss: 2.626064477309515

Epoch: 5| Step: 8
Training loss: 2.5514872159673128
Validation loss: 2.6491201551073518

Epoch: 5| Step: 9
Training loss: 3.491077357584358
Validation loss: 2.639013762039103

Epoch: 5| Step: 10
Training loss: 2.4871423051995794
Validation loss: 2.653417663190513

Epoch: 71| Step: 0
Training loss: 2.839918636714647
Validation loss: 2.6190625216613164

Epoch: 5| Step: 1
Training loss: 3.4408149687582674
Validation loss: 2.6419494068707876

Epoch: 5| Step: 2
Training loss: 2.960637945557973
Validation loss: 2.638779873872897

Epoch: 5| Step: 3
Training loss: 2.638163124356667
Validation loss: 2.6479914733069227

Epoch: 5| Step: 4
Training loss: 2.7689000797283705
Validation loss: 2.6458413399544605

Epoch: 5| Step: 5
Training loss: 2.2899174574589143
Validation loss: 2.6516587768690174

Epoch: 5| Step: 6
Training loss: 2.569164448738275
Validation loss: 2.6171809904568244

Epoch: 5| Step: 7
Training loss: 2.4055345140358666
Validation loss: 2.663878388334446

Epoch: 5| Step: 8
Training loss: 3.1161468221918
Validation loss: 2.6366961306775707

Epoch: 5| Step: 9
Training loss: 2.9641688286064984
Validation loss: 2.6428888757865523

Epoch: 5| Step: 10
Training loss: 3.0726138897887343
Validation loss: 2.6313204501326926

Epoch: 72| Step: 0
Training loss: 2.9458425029807964
Validation loss: 2.6465789122955514

Epoch: 5| Step: 1
Training loss: 2.976989234912541
Validation loss: 2.6489406036087764

Epoch: 5| Step: 2
Training loss: 2.6631092144655626
Validation loss: 2.6403300754180328

Epoch: 5| Step: 3
Training loss: 2.975447318163113
Validation loss: 2.6264914237466384

Epoch: 5| Step: 4
Training loss: 2.9807843882362293
Validation loss: 2.643348328827008

Epoch: 5| Step: 5
Training loss: 2.3787361673022067
Validation loss: 2.637724174611344

Epoch: 5| Step: 6
Training loss: 2.5816382312460533
Validation loss: 2.6241137018659284

Epoch: 5| Step: 7
Training loss: 2.8253377594360325
Validation loss: 2.6105556615792773

Epoch: 5| Step: 8
Training loss: 2.799781099345831
Validation loss: 2.618819940410192

Epoch: 5| Step: 9
Training loss: 3.3230966899900687
Validation loss: 2.623597447674192

Epoch: 5| Step: 10
Training loss: 2.4093956141202293
Validation loss: 2.6368424527931573

Epoch: 73| Step: 0
Training loss: 2.4548506771754988
Validation loss: 2.622016411429314

Epoch: 5| Step: 1
Training loss: 3.1681720936492743
Validation loss: 2.6303234899152788

Epoch: 5| Step: 2
Training loss: 2.9963366075586197
Validation loss: 2.657814805161963

Epoch: 5| Step: 3
Training loss: 2.5852147501243015
Validation loss: 2.626235770648081

Epoch: 5| Step: 4
Training loss: 2.964553758514354
Validation loss: 2.622076971716617

Epoch: 5| Step: 5
Training loss: 2.935475889808328
Validation loss: 2.6298910857142084

Epoch: 5| Step: 6
Training loss: 3.017428792573159
Validation loss: 2.6405618088091845

Epoch: 5| Step: 7
Training loss: 2.656001000794831
Validation loss: 2.6280740394854187

Epoch: 5| Step: 8
Training loss: 2.790436991032342
Validation loss: 2.6473236040496686

Epoch: 5| Step: 9
Training loss: 2.577572850142267
Validation loss: 2.6548519984532613

Epoch: 5| Step: 10
Training loss: 2.7763533617038356
Validation loss: 2.625392320011966

Epoch: 74| Step: 0
Training loss: 2.797643630471486
Validation loss: 2.644922544609673

Epoch: 5| Step: 1
Training loss: 2.8768719093891244
Validation loss: 2.6341283141719964

Epoch: 5| Step: 2
Training loss: 2.6550441024192075
Validation loss: 2.6418113812745

Epoch: 5| Step: 3
Training loss: 2.720861557662719
Validation loss: 2.6385112947463294

Epoch: 5| Step: 4
Training loss: 2.2959177526702406
Validation loss: 2.6368202739875692

Epoch: 5| Step: 5
Training loss: 3.064323972043369
Validation loss: 2.659298713019551

Epoch: 5| Step: 6
Training loss: 2.7561311864870413
Validation loss: 2.6425649127854713

Epoch: 5| Step: 7
Training loss: 3.304106388448181
Validation loss: 2.6307586212857497

Epoch: 5| Step: 8
Training loss: 2.7887317450664133
Validation loss: 2.640410351753151

Epoch: 5| Step: 9
Training loss: 2.5484211914738175
Validation loss: 2.6540779030026496

Epoch: 5| Step: 10
Training loss: 3.2483695415307547
Validation loss: 2.637204510095958

Epoch: 75| Step: 0
Training loss: 2.555971342161943
Validation loss: 2.632348318470884

Epoch: 5| Step: 1
Training loss: 3.052273081500129
Validation loss: 2.63953326460317

Epoch: 5| Step: 2
Training loss: 2.4258421861056108
Validation loss: 2.6167100941435235

Epoch: 5| Step: 3
Training loss: 2.792511674520188
Validation loss: 2.6612798178481936

Epoch: 5| Step: 4
Training loss: 3.4549984920073338
Validation loss: 2.65375949661639

Epoch: 5| Step: 5
Training loss: 3.2282035293702553
Validation loss: 2.6495905186177393

Epoch: 5| Step: 6
Training loss: 3.092414799027712
Validation loss: 2.647642673067203

Epoch: 5| Step: 7
Training loss: 2.8701911182103728
Validation loss: 2.625925140334395

Epoch: 5| Step: 8
Training loss: 2.244296793073044
Validation loss: 2.6270158833319837

Epoch: 5| Step: 9
Training loss: 2.5866292621752747
Validation loss: 2.636720467053777

Epoch: 5| Step: 10
Training loss: 2.3636081942300207
Validation loss: 2.6436888847772213

Epoch: 76| Step: 0
Training loss: 2.746613411279073
Validation loss: 2.620038959652183

Epoch: 5| Step: 1
Training loss: 2.918131996092475
Validation loss: 2.631763488684341

Epoch: 5| Step: 2
Training loss: 2.577986927381092
Validation loss: 2.640647420625986

Epoch: 5| Step: 3
Training loss: 2.403181621544225
Validation loss: 2.632336701781421

Epoch: 5| Step: 4
Training loss: 2.7412272018966637
Validation loss: 2.6469904609405805

Epoch: 5| Step: 5
Training loss: 2.6270298148947506
Validation loss: 2.6283763963523

Epoch: 5| Step: 6
Training loss: 2.8361355630947855
Validation loss: 2.648243462774909

Epoch: 5| Step: 7
Training loss: 2.755496946817339
Validation loss: 2.6479287725671954

Epoch: 5| Step: 8
Training loss: 3.047405490176458
Validation loss: 2.6364397343257675

Epoch: 5| Step: 9
Training loss: 3.4786694260812063
Validation loss: 2.6505904165500995

Epoch: 5| Step: 10
Training loss: 2.8076068274265378
Validation loss: 2.6289380677799112

Epoch: 77| Step: 0
Training loss: 3.277121571590366
Validation loss: 2.6451841789698967

Epoch: 5| Step: 1
Training loss: 3.039967693859906
Validation loss: 2.633228427743921

Epoch: 5| Step: 2
Training loss: 2.9680843209270207
Validation loss: 2.638527444057756

Epoch: 5| Step: 3
Training loss: 2.4762807980682133
Validation loss: 2.660041561222999

Epoch: 5| Step: 4
Training loss: 2.5610012230384225
Validation loss: 2.6488578923255295

Epoch: 5| Step: 5
Training loss: 2.7923057356073953
Validation loss: 2.6397257860729506

Epoch: 5| Step: 6
Training loss: 2.387094720924379
Validation loss: 2.622390372808736

Epoch: 5| Step: 7
Training loss: 2.719482761598445
Validation loss: 2.6350218262170966

Epoch: 5| Step: 8
Training loss: 2.40298339267791
Validation loss: 2.6337491833944546

Epoch: 5| Step: 9
Training loss: 3.3276515856807474
Validation loss: 2.660333581705472

Epoch: 5| Step: 10
Training loss: 2.8278442580680045
Validation loss: 2.644334702144779

Epoch: 78| Step: 0
Training loss: 2.1194958929592187
Validation loss: 2.6364134457028094

Epoch: 5| Step: 1
Training loss: 2.754716210261661
Validation loss: 2.63729043406093

Epoch: 5| Step: 2
Training loss: 2.8204516431980626
Validation loss: 2.623652182975139

Epoch: 5| Step: 3
Training loss: 2.499628611635328
Validation loss: 2.642512483342918

Epoch: 5| Step: 4
Training loss: 3.316722985049868
Validation loss: 2.638153768310569

Epoch: 5| Step: 5
Training loss: 2.5941637927058943
Validation loss: 2.6331455743872723

Epoch: 5| Step: 6
Training loss: 2.5322634704936573
Validation loss: 2.6333528552481162

Epoch: 5| Step: 7
Training loss: 3.272769395480105
Validation loss: 2.6165245630749823

Epoch: 5| Step: 8
Training loss: 2.972771099744245
Validation loss: 2.616812338561536

Epoch: 5| Step: 9
Training loss: 2.465110220311642
Validation loss: 2.648824180702452

Epoch: 5| Step: 10
Training loss: 3.41495514467419
Validation loss: 2.634938228521601

Epoch: 79| Step: 0
Training loss: 2.1284791850532234
Validation loss: 2.6293507756482715

Epoch: 5| Step: 1
Training loss: 3.0713441780130166
Validation loss: 2.6489100669718715

Epoch: 5| Step: 2
Training loss: 3.006520020855212
Validation loss: 2.6298710036040918

Epoch: 5| Step: 3
Training loss: 2.918244089722398
Validation loss: 2.646182969175007

Epoch: 5| Step: 4
Training loss: 2.9851916728629786
Validation loss: 2.63953461463714

Epoch: 5| Step: 5
Training loss: 2.6383166635275455
Validation loss: 2.628526117302373

Epoch: 5| Step: 6
Training loss: 3.2513756408233205
Validation loss: 2.6432357263455883

Epoch: 5| Step: 7
Training loss: 2.97460921469755
Validation loss: 2.6451745133916083

Epoch: 5| Step: 8
Training loss: 2.1469185193133336
Validation loss: 2.6380706721825655

Epoch: 5| Step: 9
Training loss: 2.458390143648618
Validation loss: 2.6402784575104397

Epoch: 5| Step: 10
Training loss: 3.176154045568193
Validation loss: 2.644776298274321

Epoch: 80| Step: 0
Training loss: 2.4409136221736905
Validation loss: 2.6348039864234742

Epoch: 5| Step: 1
Training loss: 2.8142034670075016
Validation loss: 2.6388030679589805

Epoch: 5| Step: 2
Training loss: 2.1869826658771596
Validation loss: 2.631922965007597

Epoch: 5| Step: 3
Training loss: 3.193585439723733
Validation loss: 2.63925417444552

Epoch: 5| Step: 4
Training loss: 2.4520479984595056
Validation loss: 2.6217297508515016

Epoch: 5| Step: 5
Training loss: 3.0210554019377316
Validation loss: 2.645097552883947

Epoch: 5| Step: 6
Training loss: 2.955949673710759
Validation loss: 2.6320423348245567

Epoch: 5| Step: 7
Training loss: 2.813752721906351
Validation loss: 2.6626809853754834

Epoch: 5| Step: 8
Training loss: 2.7386759039615653
Validation loss: 2.6451840491007346

Epoch: 5| Step: 9
Training loss: 2.7928660553945734
Validation loss: 2.6284763123761614

Epoch: 5| Step: 10
Training loss: 3.4248795926724487
Validation loss: 2.628021176573326

Epoch: 81| Step: 0
Training loss: 2.936198169288145
Validation loss: 2.6233869187476686

Epoch: 5| Step: 1
Training loss: 2.299299660081166
Validation loss: 2.638930801795644

Epoch: 5| Step: 2
Training loss: 2.9895827307794653
Validation loss: 2.641029207074162

Epoch: 5| Step: 3
Training loss: 2.9976317276696025
Validation loss: 2.6275310297428964

Epoch: 5| Step: 4
Training loss: 2.810406223406852
Validation loss: 2.625951087800729

Epoch: 5| Step: 5
Training loss: 2.8521010634932615
Validation loss: 2.6208938970646343

Epoch: 5| Step: 6
Training loss: 3.014766907040108
Validation loss: 2.6629874442266632

Epoch: 5| Step: 7
Training loss: 3.028574126234678
Validation loss: 2.64218125730118

Epoch: 5| Step: 8
Training loss: 2.6048454213910737
Validation loss: 2.6382186360848143

Epoch: 5| Step: 9
Training loss: 2.86190900407106
Validation loss: 2.64075808217947

Epoch: 5| Step: 10
Training loss: 2.279057219653627
Validation loss: 2.6403497449430793

Epoch: 82| Step: 0
Training loss: 3.088498060016168
Validation loss: 2.6320482568104318

Epoch: 5| Step: 1
Training loss: 2.7305855787439146
Validation loss: 2.6523012501611833

Epoch: 5| Step: 2
Training loss: 2.3406510273972208
Validation loss: 2.6255183067120598

Epoch: 5| Step: 3
Training loss: 2.4533483318547633
Validation loss: 2.6343184123465093

Epoch: 5| Step: 4
Training loss: 3.2388616577829987
Validation loss: 2.617697715340292

Epoch: 5| Step: 5
Training loss: 2.5456400492499838
Validation loss: 2.619053624978202

Epoch: 5| Step: 6
Training loss: 2.5489353201237406
Validation loss: 2.6552252339958526

Epoch: 5| Step: 7
Training loss: 3.2900577588794238
Validation loss: 2.6362935843463675

Epoch: 5| Step: 8
Training loss: 3.198004076298447
Validation loss: 2.631386228741195

Epoch: 5| Step: 9
Training loss: 2.495924488710491
Validation loss: 2.6515006296990453

Epoch: 5| Step: 10
Training loss: 2.7285794118908524
Validation loss: 2.6251240245390868

Epoch: 83| Step: 0
Training loss: 2.2931583982475185
Validation loss: 2.6488612603671924

Epoch: 5| Step: 1
Training loss: 2.703504414473849
Validation loss: 2.6478532137005373

Epoch: 5| Step: 2
Training loss: 2.616437297738206
Validation loss: 2.628668588414302

Epoch: 5| Step: 3
Training loss: 1.9061944672046862
Validation loss: 2.638066781633703

Epoch: 5| Step: 4
Training loss: 3.052313386928663
Validation loss: 2.6419265062879607

Epoch: 5| Step: 5
Training loss: 2.7296231206017585
Validation loss: 2.6299935419586733

Epoch: 5| Step: 6
Training loss: 2.4537515022479224
Validation loss: 2.6253571518829277

Epoch: 5| Step: 7
Training loss: 3.467175925580613
Validation loss: 2.6239937446985135

Epoch: 5| Step: 8
Training loss: 3.023231045872292
Validation loss: 2.621362475573656

Epoch: 5| Step: 9
Training loss: 3.0680780797818192
Validation loss: 2.637445566626248

Epoch: 5| Step: 10
Training loss: 3.1427536767797437
Validation loss: 2.6514393665514095

Epoch: 84| Step: 0
Training loss: 2.572522173045462
Validation loss: 2.6461841317431753

Epoch: 5| Step: 1
Training loss: 3.0541226774606636
Validation loss: 2.617036941304455

Epoch: 5| Step: 2
Training loss: 2.9775619631068344
Validation loss: 2.636458541202343

Epoch: 5| Step: 3
Training loss: 3.0870421158883716
Validation loss: 2.637154640619556

Epoch: 5| Step: 4
Training loss: 2.6500084642958868
Validation loss: 2.6377523541307415

Epoch: 5| Step: 5
Training loss: 2.1217045756287316
Validation loss: 2.6200019123985028

Epoch: 5| Step: 6
Training loss: 3.0968001001502383
Validation loss: 2.6412202664489137

Epoch: 5| Step: 7
Training loss: 3.170825352368397
Validation loss: 2.6149760380621583

Epoch: 5| Step: 8
Training loss: 2.735659575493318
Validation loss: 2.6122529755945267

Epoch: 5| Step: 9
Training loss: 2.42369965759217
Validation loss: 2.633962463885471

Epoch: 5| Step: 10
Training loss: 2.6442669013695856
Validation loss: 2.646995223107219

Epoch: 85| Step: 0
Training loss: 2.867453580977816
Validation loss: 2.6172406787027542

Epoch: 5| Step: 1
Training loss: 3.1951020784741946
Validation loss: 2.6212202709483687

Epoch: 5| Step: 2
Training loss: 2.8348077042100464
Validation loss: 2.649276514833664

Epoch: 5| Step: 3
Training loss: 2.92698019441056
Validation loss: 2.6257935988050245

Epoch: 5| Step: 4
Training loss: 3.0060760638067032
Validation loss: 2.6447752940562315

Epoch: 5| Step: 5
Training loss: 3.136037940301854
Validation loss: 2.632477106607693

Epoch: 5| Step: 6
Training loss: 3.2116686505989738
Validation loss: 2.648961186666445

Epoch: 5| Step: 7
Training loss: 2.2241825702432627
Validation loss: 2.629549806937391

Epoch: 5| Step: 8
Training loss: 2.581493235066261
Validation loss: 2.6378984952054143

Epoch: 5| Step: 9
Training loss: 2.4377791416060464
Validation loss: 2.652280514206872

Epoch: 5| Step: 10
Training loss: 1.8180944329633268
Validation loss: 2.6332320922709083

Epoch: 86| Step: 0
Training loss: 2.84110380025669
Validation loss: 2.6404800554865413

Epoch: 5| Step: 1
Training loss: 3.0474799704890967
Validation loss: 2.624403690008341

Epoch: 5| Step: 2
Training loss: 3.3105687683641856
Validation loss: 2.6583511429349964

Epoch: 5| Step: 3
Training loss: 2.975140089054549
Validation loss: 2.638567036220696

Epoch: 5| Step: 4
Training loss: 2.832408548412398
Validation loss: 2.624665356667557

Epoch: 5| Step: 5
Training loss: 2.2297886013535173
Validation loss: 2.6476661942478854

Epoch: 5| Step: 6
Training loss: 2.9607299087745917
Validation loss: 2.645704257701809

Epoch: 5| Step: 7
Training loss: 2.768020110013158
Validation loss: 2.623541822008733

Epoch: 5| Step: 8
Training loss: 2.3572270803556066
Validation loss: 2.6377421238550993

Epoch: 5| Step: 9
Training loss: 2.7310384393457077
Validation loss: 2.646066297048794

Epoch: 5| Step: 10
Training loss: 2.4620756877789716
Validation loss: 2.637037752786842

Epoch: 87| Step: 0
Training loss: 2.947979192890667
Validation loss: 2.6393990221299166

Epoch: 5| Step: 1
Training loss: 2.751758620005959
Validation loss: 2.630501531688472

Epoch: 5| Step: 2
Training loss: 3.0230660616981417
Validation loss: 2.6326990038286615

Epoch: 5| Step: 3
Training loss: 3.214410170915841
Validation loss: 2.6342272684983725

Epoch: 5| Step: 4
Training loss: 2.8326605577744908
Validation loss: 2.632439668584963

Epoch: 5| Step: 5
Training loss: 2.407494755597607
Validation loss: 2.6226196649748936

Epoch: 5| Step: 6
Training loss: 2.589645815458926
Validation loss: 2.6395744034217836

Epoch: 5| Step: 7
Training loss: 2.224583438926399
Validation loss: 2.6249008101373192

Epoch: 5| Step: 8
Training loss: 2.941167449376352
Validation loss: 2.6260817272215564

Epoch: 5| Step: 9
Training loss: 3.2720670539868424
Validation loss: 2.617058105404624

Epoch: 5| Step: 10
Training loss: 2.215968685638125
Validation loss: 2.630819751620082

Epoch: 88| Step: 0
Training loss: 2.9281464045667436
Validation loss: 2.636591741312685

Epoch: 5| Step: 1
Training loss: 2.876700023076114
Validation loss: 2.6148511763050433

Epoch: 5| Step: 2
Training loss: 2.711582425932229
Validation loss: 2.615857863364426

Epoch: 5| Step: 3
Training loss: 2.75133568664529
Validation loss: 2.6212097947240514

Epoch: 5| Step: 4
Training loss: 3.3816289439070664
Validation loss: 2.6349799479209426

Epoch: 5| Step: 5
Training loss: 2.8130818083116433
Validation loss: 2.6281397744883157

Epoch: 5| Step: 6
Training loss: 2.871729109652168
Validation loss: 2.6294403501481254

Epoch: 5| Step: 7
Training loss: 2.644925560002879
Validation loss: 2.6120815063001377

Epoch: 5| Step: 8
Training loss: 2.2469804423371933
Validation loss: 2.6651638036397576

Epoch: 5| Step: 9
Training loss: 2.656473845979395
Validation loss: 2.6240921232867254

Epoch: 5| Step: 10
Training loss: 2.688554867270242
Validation loss: 2.6404457504734045

Epoch: 89| Step: 0
Training loss: 3.1778394122545155
Validation loss: 2.624854711778769

Epoch: 5| Step: 1
Training loss: 3.1015583489916336
Validation loss: 2.6311331314798947

Epoch: 5| Step: 2
Training loss: 2.632289211894497
Validation loss: 2.655773717077664

Epoch: 5| Step: 3
Training loss: 2.863922338807344
Validation loss: 2.6406759883479367

Epoch: 5| Step: 4
Training loss: 2.8969793636283594
Validation loss: 2.633152548302324

Epoch: 5| Step: 5
Training loss: 3.2579338362165293
Validation loss: 2.625301700702649

Epoch: 5| Step: 6
Training loss: 2.5024819451746887
Validation loss: 2.621158144071697

Epoch: 5| Step: 7
Training loss: 2.743583823626613
Validation loss: 2.6348564164962767

Epoch: 5| Step: 8
Training loss: 2.5262624322961886
Validation loss: 2.608993441463214

Epoch: 5| Step: 9
Training loss: 2.31644021535227
Validation loss: 2.6204100119063565

Epoch: 5| Step: 10
Training loss: 2.4863520978444638
Validation loss: 2.6352642556274475

Epoch: 90| Step: 0
Training loss: 2.6692462504425682
Validation loss: 2.6476613684142514

Epoch: 5| Step: 1
Training loss: 3.1060730544106554
Validation loss: 2.6419537851291044

Epoch: 5| Step: 2
Training loss: 2.4733671639828674
Validation loss: 2.613977308496993

Epoch: 5| Step: 3
Training loss: 2.827726135789946
Validation loss: 2.6461930447488284

Epoch: 5| Step: 4
Training loss: 2.392085607789294
Validation loss: 2.639546736745758

Epoch: 5| Step: 5
Training loss: 3.3064416148396982
Validation loss: 2.6063069824417067

Epoch: 5| Step: 6
Training loss: 3.2068743835817384
Validation loss: 2.6288804048403454

Epoch: 5| Step: 7
Training loss: 3.346668004064812
Validation loss: 2.6192027982635717

Epoch: 5| Step: 8
Training loss: 2.26601411832231
Validation loss: 2.6203067250153613

Epoch: 5| Step: 9
Training loss: 2.3169457256099815
Validation loss: 2.6166570868890564

Epoch: 5| Step: 10
Training loss: 2.0985180666775007
Validation loss: 2.628726854797884

Epoch: 91| Step: 0
Training loss: 3.469683135018828
Validation loss: 2.626608978063473

Epoch: 5| Step: 1
Training loss: 2.588007809846818
Validation loss: 2.6173570930927235

Epoch: 5| Step: 2
Training loss: 3.33910782050944
Validation loss: 2.604302014843152

Epoch: 5| Step: 3
Training loss: 2.841884462245594
Validation loss: 2.6269100943378674

Epoch: 5| Step: 4
Training loss: 2.5309543201449527
Validation loss: 2.631133401374417

Epoch: 5| Step: 5
Training loss: 2.6631688383800887
Validation loss: 2.6230855622242095

Epoch: 5| Step: 6
Training loss: 2.706427084258589
Validation loss: 2.637392155722234

Epoch: 5| Step: 7
Training loss: 2.4048397340729233
Validation loss: 2.648099376716725

Epoch: 5| Step: 8
Training loss: 2.5584950668290385
Validation loss: 2.6286656967608244

Epoch: 5| Step: 9
Training loss: 2.606068051800028
Validation loss: 2.640545383589741

Epoch: 5| Step: 10
Training loss: 2.6539931639329595
Validation loss: 2.6236650653821054

Epoch: 92| Step: 0
Training loss: 2.774517440078377
Validation loss: 2.6147888583921497

Epoch: 5| Step: 1
Training loss: 2.6815972376770505
Validation loss: 2.6239854367699222

Epoch: 5| Step: 2
Training loss: 2.4259497051135916
Validation loss: 2.650433662316558

Epoch: 5| Step: 3
Training loss: 2.551884130890875
Validation loss: 2.615376214529564

Epoch: 5| Step: 4
Training loss: 2.4228707512276713
Validation loss: 2.6202058164869952

Epoch: 5| Step: 5
Training loss: 2.8694869547186967
Validation loss: 2.613066460050354

Epoch: 5| Step: 6
Training loss: 3.3495666679128764
Validation loss: 2.63242406770972

Epoch: 5| Step: 7
Training loss: 3.198631148819177
Validation loss: 2.623124968187742

Epoch: 5| Step: 8
Training loss: 2.240702812088665
Validation loss: 2.6314469786715717

Epoch: 5| Step: 9
Training loss: 2.833193962558861
Validation loss: 2.6147950900541863

Epoch: 5| Step: 10
Training loss: 3.121873894157634
Validation loss: 2.6404061952196067

Epoch: 93| Step: 0
Training loss: 3.000053087400568
Validation loss: 2.6194582833666775

Epoch: 5| Step: 1
Training loss: 2.0785792721884544
Validation loss: 2.6226019269929397

Epoch: 5| Step: 2
Training loss: 2.545298831685216
Validation loss: 2.616000837720387

Epoch: 5| Step: 3
Training loss: 3.3763827564248845
Validation loss: 2.637393246346619

Epoch: 5| Step: 4
Training loss: 2.628098611778565
Validation loss: 2.6201891883234465

Epoch: 5| Step: 5
Training loss: 2.484807006894344
Validation loss: 2.615560789566484

Epoch: 5| Step: 6
Training loss: 2.6091111101124285
Validation loss: 2.649543115441791

Epoch: 5| Step: 7
Training loss: 2.3667041045796227
Validation loss: 2.639548554911563

Epoch: 5| Step: 8
Training loss: 3.1115183128567114
Validation loss: 2.6514533418904493

Epoch: 5| Step: 9
Training loss: 2.846600120832711
Validation loss: 2.6199904758048866

Epoch: 5| Step: 10
Training loss: 3.236850694033679
Validation loss: 2.632513315115148

Epoch: 94| Step: 0
Training loss: 2.6504201304087207
Validation loss: 2.647923982066231

Epoch: 5| Step: 1
Training loss: 1.8616775232793659
Validation loss: 2.63639010904292

Epoch: 5| Step: 2
Training loss: 2.941972776773249
Validation loss: 2.631694837025068

Epoch: 5| Step: 3
Training loss: 2.951580632781616
Validation loss: 2.6096009865267153

Epoch: 5| Step: 4
Training loss: 2.9647231247077284
Validation loss: 2.643588635058676

Epoch: 5| Step: 5
Training loss: 3.3186336805860948
Validation loss: 2.6200019887205714

Epoch: 5| Step: 6
Training loss: 2.651348753245078
Validation loss: 2.635296162993088

Epoch: 5| Step: 7
Training loss: 3.146817455504307
Validation loss: 2.6409898236386766

Epoch: 5| Step: 8
Training loss: 2.529608017330747
Validation loss: 2.6345874237756757

Epoch: 5| Step: 9
Training loss: 2.2675905317678464
Validation loss: 2.6208096863423767

Epoch: 5| Step: 10
Training loss: 2.9705769589209554
Validation loss: 2.631828306481072

Epoch: 95| Step: 0
Training loss: 3.079009727707971
Validation loss: 2.6404428144336882

Epoch: 5| Step: 1
Training loss: 2.70077694911024
Validation loss: 2.631946724076903

Epoch: 5| Step: 2
Training loss: 2.2076688402524134
Validation loss: 2.625264586607719

Epoch: 5| Step: 3
Training loss: 3.2885614226388946
Validation loss: 2.631416722739405

Epoch: 5| Step: 4
Training loss: 2.8491737707346467
Validation loss: 2.633720008093005

Epoch: 5| Step: 5
Training loss: 2.22970434341538
Validation loss: 2.623977739443524

Epoch: 5| Step: 6
Training loss: 2.4698040800347107
Validation loss: 2.6182274877884146

Epoch: 5| Step: 7
Training loss: 2.602309294500868
Validation loss: 2.639212305996522

Epoch: 5| Step: 8
Training loss: 2.8674441022671155
Validation loss: 2.6189918260154417

Epoch: 5| Step: 9
Training loss: 2.5752183654933742
Validation loss: 2.6276224751333994

Epoch: 5| Step: 10
Training loss: 3.518204348928628
Validation loss: 2.6280591730877436

Epoch: 96| Step: 0
Training loss: 2.9175837210416273
Validation loss: 2.608803552711084

Epoch: 5| Step: 1
Training loss: 2.8466890678447507
Validation loss: 2.6385053785217667

Epoch: 5| Step: 2
Training loss: 3.0693721350375105
Validation loss: 2.623222212477359

Epoch: 5| Step: 3
Training loss: 2.3063389954802296
Validation loss: 2.6363283168017926

Epoch: 5| Step: 4
Training loss: 3.226113350482077
Validation loss: 2.6142993480745083

Epoch: 5| Step: 5
Training loss: 2.876572883583072
Validation loss: 2.6127988200570087

Epoch: 5| Step: 6
Training loss: 3.2153721835121076
Validation loss: 2.5920570710850264

Epoch: 5| Step: 7
Training loss: 2.2552536981144464
Validation loss: 2.6379965374599585

Epoch: 5| Step: 8
Training loss: 2.5384521689831163
Validation loss: 2.6245313715388527

Epoch: 5| Step: 9
Training loss: 2.4917238575507517
Validation loss: 2.6215074082348133

Epoch: 5| Step: 10
Training loss: 2.5058150373001733
Validation loss: 2.6194826869167875

Epoch: 97| Step: 0
Training loss: 2.1623248343553794
Validation loss: 2.6238515072989426

Epoch: 5| Step: 1
Training loss: 2.8930902639443503
Validation loss: 2.6406301687798854

Epoch: 5| Step: 2
Training loss: 3.4232137491152006
Validation loss: 2.6423927463235386

Epoch: 5| Step: 3
Training loss: 2.945868401721093
Validation loss: 2.6426420052564152

Epoch: 5| Step: 4
Training loss: 2.2073380248629477
Validation loss: 2.6364257455242996

Epoch: 5| Step: 5
Training loss: 3.6019429897475614
Validation loss: 2.641813997499027

Epoch: 5| Step: 6
Training loss: 2.9356534307839928
Validation loss: 2.6309299183797585

Epoch: 5| Step: 7
Training loss: 2.325776522179598
Validation loss: 2.63846353511288

Epoch: 5| Step: 8
Training loss: 2.309117291722348
Validation loss: 2.6262668359537815

Epoch: 5| Step: 9
Training loss: 2.544052619647806
Validation loss: 2.613493895653334

Epoch: 5| Step: 10
Training loss: 2.72152463144835
Validation loss: 2.6438682799851447

Epoch: 98| Step: 0
Training loss: 3.2050040339356745
Validation loss: 2.5898223278673145

Epoch: 5| Step: 1
Training loss: 2.7234979146799194
Validation loss: 2.647924173763889

Epoch: 5| Step: 2
Training loss: 2.374165137270266
Validation loss: 2.6194940210088653

Epoch: 5| Step: 3
Training loss: 2.452743792223421
Validation loss: 2.626045715094874

Epoch: 5| Step: 4
Training loss: 2.4546512788058537
Validation loss: 2.6225664115678637

Epoch: 5| Step: 5
Training loss: 3.0948344170027178
Validation loss: 2.6298326170149506

Epoch: 5| Step: 6
Training loss: 2.525347102262966
Validation loss: 2.623884902740358

Epoch: 5| Step: 7
Training loss: 2.982213061104335
Validation loss: 2.626401910705672

Epoch: 5| Step: 8
Training loss: 2.426579588211523
Validation loss: 2.6334045889489577

Epoch: 5| Step: 9
Training loss: 2.992058415031358
Validation loss: 2.629960147077378

Epoch: 5| Step: 10
Training loss: 3.063989860766893
Validation loss: 2.6341737543839336

Epoch: 99| Step: 0
Training loss: 2.566062683612391
Validation loss: 2.618435064514049

Epoch: 5| Step: 1
Training loss: 2.869420151568185
Validation loss: 2.6390117404739706

Epoch: 5| Step: 2
Training loss: 2.72800265427849
Validation loss: 2.6343475391747906

Epoch: 5| Step: 3
Training loss: 2.6444773365650076
Validation loss: 2.6346494519433152

Epoch: 5| Step: 4
Training loss: 2.2028835516034544
Validation loss: 2.6422648412311007

Epoch: 5| Step: 5
Training loss: 2.28549217950171
Validation loss: 2.6540549225775685

Epoch: 5| Step: 6
Training loss: 3.3341907511092876
Validation loss: 2.6385563339878244

Epoch: 5| Step: 7
Training loss: 3.2259006514177373
Validation loss: 2.614597863885514

Epoch: 5| Step: 8
Training loss: 2.227228004983244
Validation loss: 2.6286788910620835

Epoch: 5| Step: 9
Training loss: 3.1982401001901586
Validation loss: 2.640726068975917

Epoch: 5| Step: 10
Training loss: 2.6893722754732163
Validation loss: 2.621936191827097

Epoch: 100| Step: 0
Training loss: 3.373940902120032
Validation loss: 2.6403448610733014

Epoch: 5| Step: 1
Training loss: 3.0286019940646125
Validation loss: 2.6052096533038975

Epoch: 5| Step: 2
Training loss: 2.804575713328705
Validation loss: 2.628889250714443

Epoch: 5| Step: 3
Training loss: 2.1427223344814297
Validation loss: 2.6317783994224113

Epoch: 5| Step: 4
Training loss: 2.9937246174224073
Validation loss: 2.624709148867093

Epoch: 5| Step: 5
Training loss: 2.312938957823926
Validation loss: 2.6474872887879193

Epoch: 5| Step: 6
Training loss: 2.7804930439096993
Validation loss: 2.6314985735082312

Epoch: 5| Step: 7
Training loss: 2.8230014990040133
Validation loss: 2.604621119725904

Epoch: 5| Step: 8
Training loss: 2.688173254094825
Validation loss: 2.6484708312929435

Epoch: 5| Step: 9
Training loss: 2.6375927190167006
Validation loss: 2.636566072127976

Epoch: 5| Step: 10
Training loss: 2.563926299834667
Validation loss: 2.621349369628042

Epoch: 101| Step: 0
Training loss: 3.1658735955283763
Validation loss: 2.637942321371562

Epoch: 5| Step: 1
Training loss: 2.5060377644694465
Validation loss: 2.62132419714859

Epoch: 5| Step: 2
Training loss: 3.118338542086398
Validation loss: 2.626518883392739

Epoch: 5| Step: 3
Training loss: 2.127072725882937
Validation loss: 2.6170411055665252

Epoch: 5| Step: 4
Training loss: 3.184621071783833
Validation loss: 2.6364678497835685

Epoch: 5| Step: 5
Training loss: 2.738959170022892
Validation loss: 2.6330313633122153

Epoch: 5| Step: 6
Training loss: 3.064626150309709
Validation loss: 2.6369945221178446

Epoch: 5| Step: 7
Training loss: 2.7317413726081115
Validation loss: 2.602663505294234

Epoch: 5| Step: 8
Training loss: 2.2339782362571934
Validation loss: 2.5985510906523075

Epoch: 5| Step: 9
Training loss: 2.9956888375343866
Validation loss: 2.615048559830445

Epoch: 5| Step: 10
Training loss: 2.009105221686779
Validation loss: 2.6131939499334025

Epoch: 102| Step: 0
Training loss: 2.4743118408344085
Validation loss: 2.6107317117879654

Epoch: 5| Step: 1
Training loss: 3.1383993128970036
Validation loss: 2.632763295167088

Epoch: 5| Step: 2
Training loss: 3.356972620511779
Validation loss: 2.6247481358610076

Epoch: 5| Step: 3
Training loss: 2.1885675277767684
Validation loss: 2.635480002947678

Epoch: 5| Step: 4
Training loss: 2.5556295448686353
Validation loss: 2.6208017679107547

Epoch: 5| Step: 5
Training loss: 2.774147823869817
Validation loss: 2.6212983095064657

Epoch: 5| Step: 6
Training loss: 1.9342878848967455
Validation loss: 2.600558125160108

Epoch: 5| Step: 7
Training loss: 2.783085935032791
Validation loss: 2.6352157804796996

Epoch: 5| Step: 8
Training loss: 2.9759524063078318
Validation loss: 2.6132932967073503

Epoch: 5| Step: 9
Training loss: 2.861535928620952
Validation loss: 2.5991722250889118

Epoch: 5| Step: 10
Training loss: 2.9872508946713605
Validation loss: 2.62177812333101

Epoch: 103| Step: 0
Training loss: 2.578599181061738
Validation loss: 2.6292225091124726

Epoch: 5| Step: 1
Training loss: 2.711511556655254
Validation loss: 2.629052595142556

Epoch: 5| Step: 2
Training loss: 3.4688337161297733
Validation loss: 2.636858197181854

Epoch: 5| Step: 3
Training loss: 2.931797742604363
Validation loss: 2.641239654659126

Epoch: 5| Step: 4
Training loss: 2.3559794465416832
Validation loss: 2.6472354476559548

Epoch: 5| Step: 5
Training loss: 2.675081704576454
Validation loss: 2.621443121515532

Epoch: 5| Step: 6
Training loss: 2.610685008251817
Validation loss: 2.6218969576862663

Epoch: 5| Step: 7
Training loss: 2.864551964790371
Validation loss: 2.6350735047749687

Epoch: 5| Step: 8
Training loss: 2.1603935345913716
Validation loss: 2.625731254523182

Epoch: 5| Step: 9
Training loss: 2.6004051406361235
Validation loss: 2.6195377469891703

Epoch: 5| Step: 10
Training loss: 3.2070050813487767
Validation loss: 2.63356950189442

Epoch: 104| Step: 0
Training loss: 2.7178453716225826
Validation loss: 2.632290132249284

Epoch: 5| Step: 1
Training loss: 2.845710665366211
Validation loss: 2.650113348646666

Epoch: 5| Step: 2
Training loss: 2.854352699027283
Validation loss: 2.626908846142446

Epoch: 5| Step: 3
Training loss: 2.98893253983109
Validation loss: 2.6213534106593763

Epoch: 5| Step: 4
Training loss: 2.9002318059421115
Validation loss: 2.6373174206325514

Epoch: 5| Step: 5
Training loss: 2.2008570908873835
Validation loss: 2.635409012293389

Epoch: 5| Step: 6
Training loss: 2.799991597435469
Validation loss: 2.640497532589714

Epoch: 5| Step: 7
Training loss: 2.191187448169124
Validation loss: 2.6267615500385735

Epoch: 5| Step: 8
Training loss: 3.1975176600609054
Validation loss: 2.6355632002105738

Epoch: 5| Step: 9
Training loss: 2.3340184931475974
Validation loss: 2.613506617234409

Epoch: 5| Step: 10
Training loss: 3.194331757773939
Validation loss: 2.602451852267952

Epoch: 105| Step: 0
Training loss: 2.780026713318402
Validation loss: 2.614770224104574

Epoch: 5| Step: 1
Training loss: 2.870940452168073
Validation loss: 2.6100066409546923

Epoch: 5| Step: 2
Training loss: 2.973403495878788
Validation loss: 2.624899594192961

Epoch: 5| Step: 3
Training loss: 2.4854583297609865
Validation loss: 2.6165256241856953

Epoch: 5| Step: 4
Training loss: 2.8310878681976748
Validation loss: 2.659226648959782

Epoch: 5| Step: 5
Training loss: 3.0053071127556965
Validation loss: 2.6038373506758137

Epoch: 5| Step: 6
Training loss: 2.4429044231342427
Validation loss: 2.6476482599959117

Epoch: 5| Step: 7
Training loss: 2.9159585547307962
Validation loss: 2.6266700405155192

Epoch: 5| Step: 8
Training loss: 3.058868434843933
Validation loss: 2.63310863851944

Epoch: 5| Step: 9
Training loss: 2.315976390869822
Validation loss: 2.6108848561315203

Epoch: 5| Step: 10
Training loss: 2.4148192963215114
Validation loss: 2.6381983520796854

Epoch: 106| Step: 0
Training loss: 2.750934788742558
Validation loss: 2.612988355677343

Epoch: 5| Step: 1
Training loss: 2.6831375911549613
Validation loss: 2.624484686950531

Epoch: 5| Step: 2
Training loss: 2.3115430346787567
Validation loss: 2.6391424191856636

Epoch: 5| Step: 3
Training loss: 2.7925051857977845
Validation loss: 2.6348378745100085

Epoch: 5| Step: 4
Training loss: 2.5732294013558046
Validation loss: 2.640848747259717

Epoch: 5| Step: 5
Training loss: 2.7600919904444003
Validation loss: 2.6244474650838403

Epoch: 5| Step: 6
Training loss: 3.2974190647237
Validation loss: 2.6070674020968

Epoch: 5| Step: 7
Training loss: 2.9089082435674434
Validation loss: 2.657104313302923

Epoch: 5| Step: 8
Training loss: 2.895524115942718
Validation loss: 2.628617332043894

Epoch: 5| Step: 9
Training loss: 2.486896794471238
Validation loss: 2.615395503201732

Epoch: 5| Step: 10
Training loss: 2.6318573167035177
Validation loss: 2.6215982863142484

Epoch: 107| Step: 0
Training loss: 2.800756308046848
Validation loss: 2.6181858451350735

Epoch: 5| Step: 1
Training loss: 2.963281031155245
Validation loss: 2.6356417172247975

Epoch: 5| Step: 2
Training loss: 2.5357666221298754
Validation loss: 2.6355179853093174

Epoch: 5| Step: 3
Training loss: 2.9204773849711505
Validation loss: 2.6259213953180804

Epoch: 5| Step: 4
Training loss: 2.574464916447312
Validation loss: 2.638376187955482

Epoch: 5| Step: 5
Training loss: 2.5540677406689474
Validation loss: 2.6109291229748943

Epoch: 5| Step: 6
Training loss: 2.5288121292846735
Validation loss: 2.6280085330579306

Epoch: 5| Step: 7
Training loss: 2.716725088634173
Validation loss: 2.6472253900917813

Epoch: 5| Step: 8
Training loss: 2.1106432457638764
Validation loss: 2.630886393433436

Epoch: 5| Step: 9
Training loss: 2.617097858772686
Validation loss: 2.637424744978394

Epoch: 5| Step: 10
Training loss: 3.8424565069433725
Validation loss: 2.6425392846456512

Epoch: 108| Step: 0
Training loss: 2.900657934335996
Validation loss: 2.608815850043042

Epoch: 5| Step: 1
Training loss: 2.1679965730548534
Validation loss: 2.631137420558522

Epoch: 5| Step: 2
Training loss: 2.714242465169426
Validation loss: 2.627857021727745

Epoch: 5| Step: 3
Training loss: 3.395770269327108
Validation loss: 2.64378451111468

Epoch: 5| Step: 4
Training loss: 2.6943341677232318
Validation loss: 2.6268074231588865

Epoch: 5| Step: 5
Training loss: 3.1504570705078323
Validation loss: 2.6191078679448037

Epoch: 5| Step: 6
Training loss: 2.72163553684588
Validation loss: 2.638864413653264

Epoch: 5| Step: 7
Training loss: 2.0347202881104787
Validation loss: 2.634049448385389

Epoch: 5| Step: 8
Training loss: 2.5351902940342232
Validation loss: 2.6179692513357526

Epoch: 5| Step: 9
Training loss: 2.8419091271322245
Validation loss: 2.618104614156199

Epoch: 5| Step: 10
Training loss: 2.4273615556204438
Validation loss: 2.6377582934260895

Epoch: 109| Step: 0
Training loss: 3.0533272526887316
Validation loss: 2.6276777256285726

Epoch: 5| Step: 1
Training loss: 2.703673378770947
Validation loss: 2.6330369422982782

Epoch: 5| Step: 2
Training loss: 3.2347285128176897
Validation loss: 2.618244190096629

Epoch: 5| Step: 3
Training loss: 2.620026736523438
Validation loss: 2.6237138799846726

Epoch: 5| Step: 4
Training loss: 2.320898733353301
Validation loss: 2.6208867056587435

Epoch: 5| Step: 5
Training loss: 2.5600584540548073
Validation loss: 2.622643173041333

Epoch: 5| Step: 6
Training loss: 1.9193613004304233
Validation loss: 2.6247807121582682

Epoch: 5| Step: 7
Training loss: 3.1033069691697373
Validation loss: 2.6308165163957233

Epoch: 5| Step: 8
Training loss: 2.8629553220342707
Validation loss: 2.610489706715232

Epoch: 5| Step: 9
Training loss: 2.4312096638998635
Validation loss: 2.6225953883667716

Epoch: 5| Step: 10
Training loss: 3.0969700865096903
Validation loss: 2.6137696670937363

Epoch: 110| Step: 0
Training loss: 2.7856792370893464
Validation loss: 2.6357365558812447

Epoch: 5| Step: 1
Training loss: 3.0375825470433786
Validation loss: 2.6271703852649213

Epoch: 5| Step: 2
Training loss: 2.700480760934883
Validation loss: 2.6165982578077984

Epoch: 5| Step: 3
Training loss: 2.747434633291388
Validation loss: 2.6206699134599796

Epoch: 5| Step: 4
Training loss: 2.7180205495645584
Validation loss: 2.617004874501271

Epoch: 5| Step: 5
Training loss: 2.5307093855377927
Validation loss: 2.6340497977892046

Epoch: 5| Step: 6
Training loss: 2.820853902571798
Validation loss: 2.623593371013327

Epoch: 5| Step: 7
Training loss: 2.9095930335338265
Validation loss: 2.628443569255965

Epoch: 5| Step: 8
Training loss: 2.418075041522307
Validation loss: 2.6213040670105974

Epoch: 5| Step: 9
Training loss: 3.0466637171335225
Validation loss: 2.6158124283988284

Epoch: 5| Step: 10
Training loss: 2.195812996390724
Validation loss: 2.6056540735798146

Epoch: 111| Step: 0
Training loss: 2.860159677702979
Validation loss: 2.660170027277789

Epoch: 5| Step: 1
Training loss: 2.8102155096419783
Validation loss: 2.6254102075827643

Epoch: 5| Step: 2
Training loss: 2.4033859845380285
Validation loss: 2.6246395576556076

Epoch: 5| Step: 3
Training loss: 2.5290731795083254
Validation loss: 2.6270855023488817

Epoch: 5| Step: 4
Training loss: 1.8145058155108529
Validation loss: 2.6188574644748654

Epoch: 5| Step: 5
Training loss: 2.504147236812659
Validation loss: 2.607558062603464

Epoch: 5| Step: 6
Training loss: 3.1553376644944895
Validation loss: 2.6098541277716065

Epoch: 5| Step: 7
Training loss: 2.470566093655484
Validation loss: 2.6177725786744697

Epoch: 5| Step: 8
Training loss: 3.1698591469359605
Validation loss: 2.625193653200326

Epoch: 5| Step: 9
Training loss: 2.9823876599420815
Validation loss: 2.6405143357818237

Epoch: 5| Step: 10
Training loss: 3.081370854667471
Validation loss: 2.619639253746418

Epoch: 112| Step: 0
Training loss: 3.1377761597699734
Validation loss: 2.6328306949999805

Epoch: 5| Step: 1
Training loss: 2.4002732200870165
Validation loss: 2.5983533399023044

Epoch: 5| Step: 2
Training loss: 2.1955144931816113
Validation loss: 2.6304628775152152

Epoch: 5| Step: 3
Training loss: 3.5745103727513823
Validation loss: 2.625806516593319

Epoch: 5| Step: 4
Training loss: 2.60525717726999
Validation loss: 2.629686926534091

Epoch: 5| Step: 5
Training loss: 2.8278762960936428
Validation loss: 2.589494523675524

Epoch: 5| Step: 6
Training loss: 2.4099702686042916
Validation loss: 2.617606104416861

Epoch: 5| Step: 7
Training loss: 2.547138036706992
Validation loss: 2.6280602012520746

Epoch: 5| Step: 8
Training loss: 3.0371527076892626
Validation loss: 2.61356098219229

Epoch: 5| Step: 9
Training loss: 2.4777753008367744
Validation loss: 2.65001795842561

Epoch: 5| Step: 10
Training loss: 2.5897305148817074
Validation loss: 2.6475890166493166

Epoch: 113| Step: 0
Training loss: 2.4063517561365533
Validation loss: 2.614868879607882

Epoch: 5| Step: 1
Training loss: 2.552575501194928
Validation loss: 2.6186262588581712

Epoch: 5| Step: 2
Training loss: 2.810347517523498
Validation loss: 2.624236767937828

Epoch: 5| Step: 3
Training loss: 2.283472728882972
Validation loss: 2.625342835492561

Epoch: 5| Step: 4
Training loss: 2.51635807326399
Validation loss: 2.6365026450916744

Epoch: 5| Step: 5
Training loss: 2.7884083897106677
Validation loss: 2.6170090941621673

Epoch: 5| Step: 6
Training loss: 3.148473393919542
Validation loss: 2.6459255901669594

Epoch: 5| Step: 7
Training loss: 3.143151325230126
Validation loss: 2.6259777447527872

Epoch: 5| Step: 8
Training loss: 2.7550742411778772
Validation loss: 2.626396973568492

Epoch: 5| Step: 9
Training loss: 2.1527641979595913
Validation loss: 2.629087358900499

Epoch: 5| Step: 10
Training loss: 3.2740055583703938
Validation loss: 2.6256790327863424

Epoch: 114| Step: 0
Training loss: 2.8858066299911163
Validation loss: 2.6144858126676014

Epoch: 5| Step: 1
Training loss: 2.315110872056574
Validation loss: 2.608755725817539

Epoch: 5| Step: 2
Training loss: 2.808174452169006
Validation loss: 2.6261708343430534

Epoch: 5| Step: 3
Training loss: 2.768705904159564
Validation loss: 2.6322568405232167

Epoch: 5| Step: 4
Training loss: 3.1870416049833006
Validation loss: 2.6259204073201854

Epoch: 5| Step: 5
Training loss: 2.9793444671570777
Validation loss: 2.5934321622282757

Epoch: 5| Step: 6
Training loss: 2.5523456257047554
Validation loss: 2.6120079442254105

Epoch: 5| Step: 7
Training loss: 2.876072724941571
Validation loss: 2.635393205744419

Epoch: 5| Step: 8
Training loss: 2.8798048255272235
Validation loss: 2.6322063504012934

Epoch: 5| Step: 9
Training loss: 1.9880953179080143
Validation loss: 2.62083883833865

Epoch: 5| Step: 10
Training loss: 2.81250635782159
Validation loss: 2.601671899408716

Epoch: 115| Step: 0
Training loss: 2.411737402524697
Validation loss: 2.623707904011415

Epoch: 5| Step: 1
Training loss: 2.8134345303394475
Validation loss: 2.614050668044431

Epoch: 5| Step: 2
Training loss: 1.7369890875201792
Validation loss: 2.6333731979939428

Epoch: 5| Step: 3
Training loss: 3.288547792732076
Validation loss: 2.6232898129826085

Epoch: 5| Step: 4
Training loss: 3.523582844580509
Validation loss: 2.6212849337985276

Epoch: 5| Step: 5
Training loss: 2.6970179372946994
Validation loss: 2.6093487855221897

Epoch: 5| Step: 6
Training loss: 2.4951676395339537
Validation loss: 2.6310791101211093

Epoch: 5| Step: 7
Training loss: 2.6417073396104755
Validation loss: 2.6076834701934164

Epoch: 5| Step: 8
Training loss: 2.199036937942893
Validation loss: 2.6197074316038953

Epoch: 5| Step: 9
Training loss: 3.036925204172758
Validation loss: 2.6039369510525674

Epoch: 5| Step: 10
Training loss: 2.523654231634589
Validation loss: 2.6275096241189986

Epoch: 116| Step: 0
Training loss: 2.8860972642693876
Validation loss: 2.609252535789454

Epoch: 5| Step: 1
Training loss: 2.91849800018561
Validation loss: 2.620453888427185

Epoch: 5| Step: 2
Training loss: 2.67622743770776
Validation loss: 2.6203860053952437

Epoch: 5| Step: 3
Training loss: 2.1653473823370346
Validation loss: 2.590739195220763

Epoch: 5| Step: 4
Training loss: 2.252318035909137
Validation loss: 2.6205590404791352

Epoch: 5| Step: 5
Training loss: 3.1986465035465983
Validation loss: 2.621111515793647

Epoch: 5| Step: 6
Training loss: 2.3296002316008444
Validation loss: 2.6185199537141766

Epoch: 5| Step: 7
Training loss: 2.584143347546286
Validation loss: 2.6069452071055235

Epoch: 5| Step: 8
Training loss: 2.9953663327150966
Validation loss: 2.62063868789579

Epoch: 5| Step: 9
Training loss: 2.6708430031667336
Validation loss: 2.5969467794254864

Epoch: 5| Step: 10
Training loss: 3.046628345384836
Validation loss: 2.6318286201384002

Epoch: 117| Step: 0
Training loss: 2.584458034523748
Validation loss: 2.6370339360571013

Epoch: 5| Step: 1
Training loss: 2.472697807553371
Validation loss: 2.6105794771401545

Epoch: 5| Step: 2
Training loss: 2.361136681910656
Validation loss: 2.604731521545956

Epoch: 5| Step: 3
Training loss: 3.1362273899082855
Validation loss: 2.6125561233146763

Epoch: 5| Step: 4
Training loss: 2.6148285668453446
Validation loss: 2.601346977983714

Epoch: 5| Step: 5
Training loss: 3.221364265164968
Validation loss: 2.6087929573447006

Epoch: 5| Step: 6
Training loss: 2.1607536055625167
Validation loss: 2.626489323242215

Epoch: 5| Step: 7
Training loss: 3.0781882032692693
Validation loss: 2.633978971033743

Epoch: 5| Step: 8
Training loss: 2.145667270296249
Validation loss: 2.642185369320569

Epoch: 5| Step: 9
Training loss: 2.3103942562721373
Validation loss: 2.63719727470585

Epoch: 5| Step: 10
Training loss: 3.5178294412408815
Validation loss: 2.623234205225818

Epoch: 118| Step: 0
Training loss: 2.8233593995903834
Validation loss: 2.6066832039292778

Epoch: 5| Step: 1
Training loss: 3.0634510354172346
Validation loss: 2.6556565762524413

Epoch: 5| Step: 2
Training loss: 2.4489770310657764
Validation loss: 2.646068895502512

Epoch: 5| Step: 3
Training loss: 3.0518707791591613
Validation loss: 2.6268848570579784

Epoch: 5| Step: 4
Training loss: 2.2544009295548957
Validation loss: 2.647656546444893

Epoch: 5| Step: 5
Training loss: 3.501907646194512
Validation loss: 2.618153653849711

Epoch: 5| Step: 6
Training loss: 2.0819696413697892
Validation loss: 2.6218469896753525

Epoch: 5| Step: 7
Training loss: 2.4417654032701286
Validation loss: 2.6067403080366645

Epoch: 5| Step: 8
Training loss: 3.08168729886262
Validation loss: 2.6175506041154866

Epoch: 5| Step: 9
Training loss: 1.8970713154041865
Validation loss: 2.64001493523712

Epoch: 5| Step: 10
Training loss: 2.710236120600332
Validation loss: 2.629935102831408

Epoch: 119| Step: 0
Training loss: 2.464745666196747
Validation loss: 2.6130664188447787

Epoch: 5| Step: 1
Training loss: 2.324044152121104
Validation loss: 2.6413767589727972

Epoch: 5| Step: 2
Training loss: 2.736539322015582
Validation loss: 2.6227330968554226

Epoch: 5| Step: 3
Training loss: 2.5714719064784872
Validation loss: 2.638060832829088

Epoch: 5| Step: 4
Training loss: 3.0618631128850122
Validation loss: 2.6125069677549764

Epoch: 5| Step: 5
Training loss: 3.034229190988589
Validation loss: 2.6101105171453898

Epoch: 5| Step: 6
Training loss: 2.4755346048363838
Validation loss: 2.641622092107508

Epoch: 5| Step: 7
Training loss: 3.0389357199616107
Validation loss: 2.6106475660654023

Epoch: 5| Step: 8
Training loss: 2.86262902381334
Validation loss: 2.623183541439363

Epoch: 5| Step: 9
Training loss: 2.773454864877416
Validation loss: 2.6202394100453343

Epoch: 5| Step: 10
Training loss: 2.3617246940050904
Validation loss: 2.650553481009212

Epoch: 120| Step: 0
Training loss: 2.26658599466864
Validation loss: 2.6311504582623244

Epoch: 5| Step: 1
Training loss: 2.450535762361677
Validation loss: 2.6119172595376945

Epoch: 5| Step: 2
Training loss: 3.0685702517944335
Validation loss: 2.6322401716147246

Epoch: 5| Step: 3
Training loss: 2.482128351057424
Validation loss: 2.638144919489451

Epoch: 5| Step: 4
Training loss: 2.64892411614291
Validation loss: 2.6176449215105455

Epoch: 5| Step: 5
Training loss: 2.892222689801452
Validation loss: 2.625870978638733

Epoch: 5| Step: 6
Training loss: 2.3263291979165066
Validation loss: 2.6121763268791627

Epoch: 5| Step: 7
Training loss: 2.093459949045612
Validation loss: 2.6358215268783134

Epoch: 5| Step: 8
Training loss: 3.0881498880624525
Validation loss: 2.610535081122263

Epoch: 5| Step: 9
Training loss: 3.0408240069888115
Validation loss: 2.6467994868328306

Epoch: 5| Step: 10
Training loss: 3.0299376173490526
Validation loss: 2.605770491064268

Epoch: 121| Step: 0
Training loss: 2.2637942579757215
Validation loss: 2.6158755804350324

Epoch: 5| Step: 1
Training loss: 3.3057102217050502
Validation loss: 2.63558764212958

Epoch: 5| Step: 2
Training loss: 2.1848189136179537
Validation loss: 2.616409232570119

Epoch: 5| Step: 3
Training loss: 2.970316905059036
Validation loss: 2.6388885804244335

Epoch: 5| Step: 4
Training loss: 2.3000952535061274
Validation loss: 2.642846358737283

Epoch: 5| Step: 5
Training loss: 2.5059645073973424
Validation loss: 2.624228730894805

Epoch: 5| Step: 6
Training loss: 2.711167735236318
Validation loss: 2.646418723674098

Epoch: 5| Step: 7
Training loss: 3.0210715013646103
Validation loss: 2.6168776893083177

Epoch: 5| Step: 8
Training loss: 2.868667428484275
Validation loss: 2.6145504106691653

Epoch: 5| Step: 9
Training loss: 2.7189122294113646
Validation loss: 2.5854166570417556

Epoch: 5| Step: 10
Training loss: 2.6840209620889444
Validation loss: 2.634598913773062

Epoch: 122| Step: 0
Training loss: 2.501341459860272
Validation loss: 2.6390127886571424

Epoch: 5| Step: 1
Training loss: 3.083140822578194
Validation loss: 2.6287964246018753

Epoch: 5| Step: 2
Training loss: 2.0457615044046684
Validation loss: 2.627651625451134

Epoch: 5| Step: 3
Training loss: 2.6783675343249254
Validation loss: 2.591789759142956

Epoch: 5| Step: 4
Training loss: 3.230487348325393
Validation loss: 2.6075338650153115

Epoch: 5| Step: 5
Training loss: 3.139119408919028
Validation loss: 2.642174231535453

Epoch: 5| Step: 6
Training loss: 2.84203077055067
Validation loss: 2.6391611038359146

Epoch: 5| Step: 7
Training loss: 2.6626619030077783
Validation loss: 2.596916271593677

Epoch: 5| Step: 8
Training loss: 2.6592957033198306
Validation loss: 2.5878987441861376

Epoch: 5| Step: 9
Training loss: 2.44320431834016
Validation loss: 2.6369663733877227

Epoch: 5| Step: 10
Training loss: 2.070793355124771
Validation loss: 2.631919425285326

Epoch: 123| Step: 0
Training loss: 2.8795263070390047
Validation loss: 2.6031501810853923

Epoch: 5| Step: 1
Training loss: 2.025742679556828
Validation loss: 2.6186377875616533

Epoch: 5| Step: 2
Training loss: 2.6083680911282285
Validation loss: 2.6229407519513015

Epoch: 5| Step: 3
Training loss: 1.8744536557536864
Validation loss: 2.599280713168504

Epoch: 5| Step: 4
Training loss: 2.5014760428361695
Validation loss: 2.616475229279928

Epoch: 5| Step: 5
Training loss: 2.932249856021763
Validation loss: 2.6303114841686326

Epoch: 5| Step: 6
Training loss: 2.6548168130670717
Validation loss: 2.620454024902725

Epoch: 5| Step: 7
Training loss: 2.0810084022304687
Validation loss: 2.593734771806373

Epoch: 5| Step: 8
Training loss: 3.4259017870933737
Validation loss: 2.6186945443440854

Epoch: 5| Step: 9
Training loss: 2.761941989794984
Validation loss: 2.624639813566486

Epoch: 5| Step: 10
Training loss: 3.4874061435115706
Validation loss: 2.6004931490200858

Epoch: 124| Step: 0
Training loss: 2.8995895358340564
Validation loss: 2.6068962063494756

Epoch: 5| Step: 1
Training loss: 2.1628397988838626
Validation loss: 2.646644875423882

Epoch: 5| Step: 2
Training loss: 3.3872292385772846
Validation loss: 2.634600043503331

Epoch: 5| Step: 3
Training loss: 2.8936629543848227
Validation loss: 2.6056442898980134

Epoch: 5| Step: 4
Training loss: 3.2628136904220812
Validation loss: 2.6227391253893466

Epoch: 5| Step: 5
Training loss: 2.0470165174644332
Validation loss: 2.591052494397202

Epoch: 5| Step: 6
Training loss: 2.7488127659895354
Validation loss: 2.6197919723056184

Epoch: 5| Step: 7
Training loss: 2.2083750187040434
Validation loss: 2.622386658915575

Epoch: 5| Step: 8
Training loss: 2.264408179431476
Validation loss: 2.631169151923248

Epoch: 5| Step: 9
Training loss: 2.3509143430357082
Validation loss: 2.6191030697545266

Epoch: 5| Step: 10
Training loss: 2.9470612775517613
Validation loss: 2.619503856702251

Epoch: 125| Step: 0
Training loss: 1.8775468060059877
Validation loss: 2.6026595485198603

Epoch: 5| Step: 1
Training loss: 2.8545787170429255
Validation loss: 2.624254279950943

Epoch: 5| Step: 2
Training loss: 3.0021948732563706
Validation loss: 2.606390506992535

Epoch: 5| Step: 3
Training loss: 2.547305018157383
Validation loss: 2.6321475143233513

Epoch: 5| Step: 4
Training loss: 2.27754527225994
Validation loss: 2.621664255561964

Epoch: 5| Step: 5
Training loss: 3.3790943600546037
Validation loss: 2.6438360358440356

Epoch: 5| Step: 6
Training loss: 2.445317667507769
Validation loss: 2.603213765367756

Epoch: 5| Step: 7
Training loss: 2.9043822490814284
Validation loss: 2.613471292108431

Epoch: 5| Step: 8
Training loss: 2.3032404090402587
Validation loss: 2.5934282279447354

Epoch: 5| Step: 9
Training loss: 2.3359456652240236
Validation loss: 2.613773027384921

Epoch: 5| Step: 10
Training loss: 3.323481943167813
Validation loss: 2.597658460666858

Epoch: 126| Step: 0
Training loss: 2.4987477027077203
Validation loss: 2.595328932575147

Epoch: 5| Step: 1
Training loss: 3.1168847570425315
Validation loss: 2.6242934046054653

Epoch: 5| Step: 2
Training loss: 2.18497604810912
Validation loss: 2.5957138330560063

Epoch: 5| Step: 3
Training loss: 2.7147570699123182
Validation loss: 2.6254350093766208

Epoch: 5| Step: 4
Training loss: 3.046735867967178
Validation loss: 2.6146546838510716

Epoch: 5| Step: 5
Training loss: 2.6031377565362144
Validation loss: 2.6242759255793975

Epoch: 5| Step: 6
Training loss: 2.166598820235407
Validation loss: 2.619692695832719

Epoch: 5| Step: 7
Training loss: 2.3279892030576996
Validation loss: 2.6182874982997286

Epoch: 5| Step: 8
Training loss: 3.3273734376885695
Validation loss: 2.578131499768588

Epoch: 5| Step: 9
Training loss: 2.7895484308666583
Validation loss: 2.601569206290492

Epoch: 5| Step: 10
Training loss: 2.7279682197397674
Validation loss: 2.6173015786955456

Epoch: 127| Step: 0
Training loss: 2.6676684723040456
Validation loss: 2.601645657568576

Epoch: 5| Step: 1
Training loss: 2.424077367762816
Validation loss: 2.6320892136012937

Epoch: 5| Step: 2
Training loss: 2.2508061342409675
Validation loss: 2.61688690491862

Epoch: 5| Step: 3
Training loss: 2.281429440482575
Validation loss: 2.597252870497712

Epoch: 5| Step: 4
Training loss: 2.7994114120919047
Validation loss: 2.615581434864283

Epoch: 5| Step: 5
Training loss: 3.113478210421981
Validation loss: 2.588723081471559

Epoch: 5| Step: 6
Training loss: 2.5513230313618984
Validation loss: 2.58065223067992

Epoch: 5| Step: 7
Training loss: 2.5455807632884713
Validation loss: 2.624141745205352

Epoch: 5| Step: 8
Training loss: 2.7285545963461497
Validation loss: 2.604175435369352

Epoch: 5| Step: 9
Training loss: 2.6321221870073632
Validation loss: 2.619919037061505

Epoch: 5| Step: 10
Training loss: 3.425849174426389
Validation loss: 2.622759096427913

Epoch: 128| Step: 0
Training loss: 2.936871725219797
Validation loss: 2.6285589696035014

Epoch: 5| Step: 1
Training loss: 2.4665930294523895
Validation loss: 2.6419130918882665

Epoch: 5| Step: 2
Training loss: 2.7212809040240513
Validation loss: 2.6057326850741838

Epoch: 5| Step: 3
Training loss: 3.1801608996201978
Validation loss: 2.5998139732535006

Epoch: 5| Step: 4
Training loss: 2.5464957487294417
Validation loss: 2.6147098955945376

Epoch: 5| Step: 5
Training loss: 2.4848538303176775
Validation loss: 2.6235593611352566

Epoch: 5| Step: 6
Training loss: 2.7033801537193547
Validation loss: 2.640580292155963

Epoch: 5| Step: 7
Training loss: 3.069064520044869
Validation loss: 2.606249061754082

Epoch: 5| Step: 8
Training loss: 2.116645546554967
Validation loss: 2.6330343640876888

Epoch: 5| Step: 9
Training loss: 2.717603419774116
Validation loss: 2.627645585260242

Epoch: 5| Step: 10
Training loss: 2.478142171369713
Validation loss: 2.6097002686966904

Epoch: 129| Step: 0
Training loss: 3.3904518751254242
Validation loss: 2.614651985543447

Epoch: 5| Step: 1
Training loss: 2.954583347851168
Validation loss: 2.6150379113393596

Epoch: 5| Step: 2
Training loss: 2.3616998599171146
Validation loss: 2.629359239687662

Epoch: 5| Step: 3
Training loss: 2.1299915032374015
Validation loss: 2.6147837032394854

Epoch: 5| Step: 4
Training loss: 1.9148359954564906
Validation loss: 2.6278692962354055

Epoch: 5| Step: 5
Training loss: 2.6378561095876547
Validation loss: 2.613929521344685

Epoch: 5| Step: 6
Training loss: 3.0458691624013947
Validation loss: 2.6045947747224947

Epoch: 5| Step: 7
Training loss: 3.521807579065387
Validation loss: 2.609181502616659

Epoch: 5| Step: 8
Training loss: 2.4930348644856077
Validation loss: 2.631772990186177

Epoch: 5| Step: 9
Training loss: 2.403639628415074
Validation loss: 2.62321843379494

Epoch: 5| Step: 10
Training loss: 2.198242838252347
Validation loss: 2.6251399124525325

Epoch: 130| Step: 0
Training loss: 2.7517608727037333
Validation loss: 2.596638125791777

Epoch: 5| Step: 1
Training loss: 2.978242495161425
Validation loss: 2.6409901614464473

Epoch: 5| Step: 2
Training loss: 2.161140865926307
Validation loss: 2.6076854147849837

Epoch: 5| Step: 3
Training loss: 2.4011295878985957
Validation loss: 2.6299428348730114

Epoch: 5| Step: 4
Training loss: 3.0394117453768206
Validation loss: 2.6146421041445884

Epoch: 5| Step: 5
Training loss: 2.3900041958440874
Validation loss: 2.615985626844597

Epoch: 5| Step: 6
Training loss: 3.391087232452599
Validation loss: 2.605466016596492

Epoch: 5| Step: 7
Training loss: 2.808245344132488
Validation loss: 2.6130707719159227

Epoch: 5| Step: 8
Training loss: 1.6608584366333738
Validation loss: 2.5936037623562846

Epoch: 5| Step: 9
Training loss: 2.644368244145382
Validation loss: 2.6064952856201447

Epoch: 5| Step: 10
Training loss: 3.073035976011879
Validation loss: 2.5976708319778474

Epoch: 131| Step: 0
Training loss: 2.732910287109721
Validation loss: 2.5906607759400386

Epoch: 5| Step: 1
Training loss: 2.8437992971989114
Validation loss: 2.6153107174573016

Epoch: 5| Step: 2
Training loss: 2.3870144175496395
Validation loss: 2.586603637825368

Epoch: 5| Step: 3
Training loss: 2.862998292688626
Validation loss: 2.6030194248996916

Epoch: 5| Step: 4
Training loss: 3.1970448915863474
Validation loss: 2.621177020493258

Epoch: 5| Step: 5
Training loss: 2.483805081237171
Validation loss: 2.6054882359943314

Epoch: 5| Step: 6
Training loss: 2.0843196695696258
Validation loss: 2.606588823307342

Epoch: 5| Step: 7
Training loss: 2.150525552256802
Validation loss: 2.5991448513379414

Epoch: 5| Step: 8
Training loss: 3.1281665780184316
Validation loss: 2.589230481895361

Epoch: 5| Step: 9
Training loss: 2.9701595774721286
Validation loss: 2.5910755052492167

Epoch: 5| Step: 10
Training loss: 2.556408690211317
Validation loss: 2.634252852935293

Epoch: 132| Step: 0
Training loss: 2.610229352322994
Validation loss: 2.6263206214833557

Epoch: 5| Step: 1
Training loss: 2.516438607330871
Validation loss: 2.5928246193665467

Epoch: 5| Step: 2
Training loss: 2.0353865538926725
Validation loss: 2.6123929858645143

Epoch: 5| Step: 3
Training loss: 2.388018714518354
Validation loss: 2.660761258333981

Epoch: 5| Step: 4
Training loss: 3.1952751922294813
Validation loss: 2.6120487765314357

Epoch: 5| Step: 5
Training loss: 2.148202446303694
Validation loss: 2.5984993773383733

Epoch: 5| Step: 6
Training loss: 3.496999271697093
Validation loss: 2.603088858426083

Epoch: 5| Step: 7
Training loss: 2.8187888301365516
Validation loss: 2.6314058189835725

Epoch: 5| Step: 8
Training loss: 2.6692908210316184
Validation loss: 2.619835380176942

Epoch: 5| Step: 9
Training loss: 2.76151517686985
Validation loss: 2.609859290696886

Epoch: 5| Step: 10
Training loss: 2.4822236348854596
Validation loss: 2.6216089590084932

Epoch: 133| Step: 0
Training loss: 2.6252726458691726
Validation loss: 2.6420264823698387

Epoch: 5| Step: 1
Training loss: 3.1117501699981314
Validation loss: 2.6099720434516898

Epoch: 5| Step: 2
Training loss: 2.4674341099066774
Validation loss: 2.5933753745173207

Epoch: 5| Step: 3
Training loss: 2.940238487795217
Validation loss: 2.595550289895445

Epoch: 5| Step: 4
Training loss: 2.8016763743773807
Validation loss: 2.6145601384722044

Epoch: 5| Step: 5
Training loss: 2.1004551802922395
Validation loss: 2.6089987780492816

Epoch: 5| Step: 6
Training loss: 2.3912972894948896
Validation loss: 2.5995981593350144

Epoch: 5| Step: 7
Training loss: 2.645942075001627
Validation loss: 2.6250300310470895

Epoch: 5| Step: 8
Training loss: 3.5864693573446123
Validation loss: 2.623208055950149

Epoch: 5| Step: 9
Training loss: 2.3024022038304093
Validation loss: 2.622384915857298

Epoch: 5| Step: 10
Training loss: 2.085641218424729
Validation loss: 2.6215577103172887

Epoch: 134| Step: 0
Training loss: 2.59607270812267
Validation loss: 2.628507418498978

Epoch: 5| Step: 1
Training loss: 1.6924164114388756
Validation loss: 2.609134852884523

Epoch: 5| Step: 2
Training loss: 2.8366015789067127
Validation loss: 2.6088982698567382

Epoch: 5| Step: 3
Training loss: 3.454649023620751
Validation loss: 2.6193043512786516

Epoch: 5| Step: 4
Training loss: 2.6125571212729612
Validation loss: 2.57872763035708

Epoch: 5| Step: 5
Training loss: 2.844785397016465
Validation loss: 2.656125157780574

Epoch: 5| Step: 6
Training loss: 2.9601743816868487
Validation loss: 2.632981547213507

Epoch: 5| Step: 7
Training loss: 3.197742685230446
Validation loss: 2.6181216325477448

Epoch: 5| Step: 8
Training loss: 2.177956170389836
Validation loss: 2.6078650502536402

Epoch: 5| Step: 9
Training loss: 2.0514883221176063
Validation loss: 2.5916578560634456

Epoch: 5| Step: 10
Training loss: 2.646770571615672
Validation loss: 2.6113419390020103

Epoch: 135| Step: 0
Training loss: 2.2167480463372335
Validation loss: 2.629584645528082

Epoch: 5| Step: 1
Training loss: 2.3777111039167407
Validation loss: 2.642307817823259

Epoch: 5| Step: 2
Training loss: 2.7147441598752287
Validation loss: 2.6000761810545128

Epoch: 5| Step: 3
Training loss: 2.9155837273819647
Validation loss: 2.5876055437894285

Epoch: 5| Step: 4
Training loss: 3.2626093762066315
Validation loss: 2.596455669752733

Epoch: 5| Step: 5
Training loss: 2.5716723523310936
Validation loss: 2.6230433995332723

Epoch: 5| Step: 6
Training loss: 3.308349600366786
Validation loss: 2.607029535262033

Epoch: 5| Step: 7
Training loss: 2.1041296272668863
Validation loss: 2.583368376739966

Epoch: 5| Step: 8
Training loss: 2.465527423044692
Validation loss: 2.605643154500542

Epoch: 5| Step: 9
Training loss: 2.626667310630732
Validation loss: 2.6090005526508846

Epoch: 5| Step: 10
Training loss: 2.7924061455318427
Validation loss: 2.61927648224092

Epoch: 136| Step: 0
Training loss: 1.7870924318271282
Validation loss: 2.628702348842827

Epoch: 5| Step: 1
Training loss: 3.271472714531458
Validation loss: 2.590170704332372

Epoch: 5| Step: 2
Training loss: 2.2676909399760072
Validation loss: 2.5939873157968805

Epoch: 5| Step: 3
Training loss: 2.7523449523386088
Validation loss: 2.6199311158725704

Epoch: 5| Step: 4
Training loss: 3.206250113028065
Validation loss: 2.643896953503686

Epoch: 5| Step: 5
Training loss: 2.399557541752062
Validation loss: 2.6199157110732094

Epoch: 5| Step: 6
Training loss: 2.441050462356673
Validation loss: 2.6255292939924826

Epoch: 5| Step: 7
Training loss: 2.4426031245909505
Validation loss: 2.6177298524929364

Epoch: 5| Step: 8
Training loss: 3.0285736538963675
Validation loss: 2.6056507834962286

Epoch: 5| Step: 9
Training loss: 2.356804970060237
Validation loss: 2.6148474242522153

Epoch: 5| Step: 10
Training loss: 3.0970318274336024
Validation loss: 2.594715455160164

Epoch: 137| Step: 0
Training loss: 2.4059236974056426
Validation loss: 2.6207451790402305

Epoch: 5| Step: 1
Training loss: 2.6009069768161224
Validation loss: 2.615802104476726

Epoch: 5| Step: 2
Training loss: 2.4247393989146393
Validation loss: 2.619935400784145

Epoch: 5| Step: 3
Training loss: 3.0788415374963187
Validation loss: 2.620797461917266

Epoch: 5| Step: 4
Training loss: 2.2836842548029193
Validation loss: 2.599895937417104

Epoch: 5| Step: 5
Training loss: 2.6745382498678354
Validation loss: 2.624323490628457

Epoch: 5| Step: 6
Training loss: 2.532820885260208
Validation loss: 2.62085660952838

Epoch: 5| Step: 7
Training loss: 2.288833658803033
Validation loss: 2.641655836441894

Epoch: 5| Step: 8
Training loss: 3.202726758065479
Validation loss: 2.6307217469184465

Epoch: 5| Step: 9
Training loss: 3.3161425446356754
Validation loss: 2.5920469047526318

Epoch: 5| Step: 10
Training loss: 2.455411295107871
Validation loss: 2.613091631630177

Epoch: 138| Step: 0
Training loss: 2.366081860871464
Validation loss: 2.614794042947758

Epoch: 5| Step: 1
Training loss: 2.987573158294148
Validation loss: 2.602341685723417

Epoch: 5| Step: 2
Training loss: 2.206662199509508
Validation loss: 2.615984648814058

Epoch: 5| Step: 3
Training loss: 3.306179278073439
Validation loss: 2.5766497356501294

Epoch: 5| Step: 4
Training loss: 2.484757112111557
Validation loss: 2.618835416264194

Epoch: 5| Step: 5
Training loss: 2.631844271786433
Validation loss: 2.632214714681242

Epoch: 5| Step: 6
Training loss: 2.250458564653147
Validation loss: 2.621267590215988

Epoch: 5| Step: 7
Training loss: 2.5067773506739783
Validation loss: 2.6180527759238874

Epoch: 5| Step: 8
Training loss: 2.912028976139066
Validation loss: 2.6169058924806885

Epoch: 5| Step: 9
Training loss: 2.596270152690107
Validation loss: 2.6047391364799477

Epoch: 5| Step: 10
Training loss: 3.0793268790955457
Validation loss: 2.630965190334751

Epoch: 139| Step: 0
Training loss: 2.7838561459787945
Validation loss: 2.6132302205913067

Epoch: 5| Step: 1
Training loss: 2.5569815412025916
Validation loss: 2.6322763658507036

Epoch: 5| Step: 2
Training loss: 2.2993734874756657
Validation loss: 2.6015666781919773

Epoch: 5| Step: 3
Training loss: 2.6451853361620024
Validation loss: 2.599135480104332

Epoch: 5| Step: 4
Training loss: 2.838104177002501
Validation loss: 2.6190505484748527

Epoch: 5| Step: 5
Training loss: 2.633733842869876
Validation loss: 2.6129751841826443

Epoch: 5| Step: 6
Training loss: 3.219193659455367
Validation loss: 2.5978685108341253

Epoch: 5| Step: 7
Training loss: 2.1696715669790043
Validation loss: 2.584549643003372

Epoch: 5| Step: 8
Training loss: 2.4456348145831726
Validation loss: 2.600060240558036

Epoch: 5| Step: 9
Training loss: 3.0072434716920857
Validation loss: 2.6062167623753436

Epoch: 5| Step: 10
Training loss: 2.581648205206189
Validation loss: 2.595422143728991

Epoch: 140| Step: 0
Training loss: 2.487587728822372
Validation loss: 2.619958682438572

Epoch: 5| Step: 1
Training loss: 2.9415792183850273
Validation loss: 2.6271984642831248

Epoch: 5| Step: 2
Training loss: 2.0372252390198566
Validation loss: 2.6301180742522927

Epoch: 5| Step: 3
Training loss: 3.3945534445297154
Validation loss: 2.614599852360034

Epoch: 5| Step: 4
Training loss: 2.318287489177476
Validation loss: 2.6362417060399777

Epoch: 5| Step: 5
Training loss: 2.205203867892605
Validation loss: 2.6254646790428997

Epoch: 5| Step: 6
Training loss: 2.519107280220081
Validation loss: 2.6009755599407116

Epoch: 5| Step: 7
Training loss: 3.0121419290181723
Validation loss: 2.6215073476033917

Epoch: 5| Step: 8
Training loss: 2.4270643198035313
Validation loss: 2.582701778188165

Epoch: 5| Step: 9
Training loss: 2.7041328623989807
Validation loss: 2.6032985718663517

Epoch: 5| Step: 10
Training loss: 2.973917749843952
Validation loss: 2.581671558064268

Epoch: 141| Step: 0
Training loss: 2.3598117045270275
Validation loss: 2.605232755107799

Epoch: 5| Step: 1
Training loss: 3.0227780275914
Validation loss: 2.6114596657733005

Epoch: 5| Step: 2
Training loss: 2.6253013437872075
Validation loss: 2.6012470468356907

Epoch: 5| Step: 3
Training loss: 2.8636672526093165
Validation loss: 2.6143077549372675

Epoch: 5| Step: 4
Training loss: 3.124620643478087
Validation loss: 2.6184607356979055

Epoch: 5| Step: 5
Training loss: 2.9143177564980527
Validation loss: 2.6160699663933964

Epoch: 5| Step: 6
Training loss: 2.691934608453137
Validation loss: 2.648895617050983

Epoch: 5| Step: 7
Training loss: 2.664171143942579
Validation loss: 2.597031177557934

Epoch: 5| Step: 8
Training loss: 2.4530729057466276
Validation loss: 2.6136006484857712

Epoch: 5| Step: 9
Training loss: 2.360363279604761
Validation loss: 2.6078460401199304

Epoch: 5| Step: 10
Training loss: 1.523603381393578
Validation loss: 2.6030248288860895

Epoch: 142| Step: 0
Training loss: 3.197980219471481
Validation loss: 2.616220338700688

Epoch: 5| Step: 1
Training loss: 2.492883375828516
Validation loss: 2.60553804741347

Epoch: 5| Step: 2
Training loss: 2.9089510271730616
Validation loss: 2.5987275891035457

Epoch: 5| Step: 3
Training loss: 2.600986726298006
Validation loss: 2.6246018535058386

Epoch: 5| Step: 4
Training loss: 2.7964437141558296
Validation loss: 2.616580320283957

Epoch: 5| Step: 5
Training loss: 2.078137620012785
Validation loss: 2.6065549721853114

Epoch: 5| Step: 6
Training loss: 2.4711889460290806
Validation loss: 2.6050762912787575

Epoch: 5| Step: 7
Training loss: 3.1913826426796694
Validation loss: 2.6129695025140425

Epoch: 5| Step: 8
Training loss: 2.4405306046873845
Validation loss: 2.5901887425982726

Epoch: 5| Step: 9
Training loss: 2.6944063736715615
Validation loss: 2.6241207339775916

Epoch: 5| Step: 10
Training loss: 1.9295917440895736
Validation loss: 2.599588454437165

Epoch: 143| Step: 0
Training loss: 2.347125763074226
Validation loss: 2.6059706440165247

Epoch: 5| Step: 1
Training loss: 2.718247465846974
Validation loss: 2.6191311089933764

Epoch: 5| Step: 2
Training loss: 2.6826559368788585
Validation loss: 2.600660262308159

Epoch: 5| Step: 3
Training loss: 2.2929379722700163
Validation loss: 2.617256392611592

Epoch: 5| Step: 4
Training loss: 2.411801263690848
Validation loss: 2.6051520241043016

Epoch: 5| Step: 5
Training loss: 2.839852313379025
Validation loss: 2.6079965799101505

Epoch: 5| Step: 6
Training loss: 3.064466506802363
Validation loss: 2.6165947595692054

Epoch: 5| Step: 7
Training loss: 2.6094058828753477
Validation loss: 2.613048959395284

Epoch: 5| Step: 8
Training loss: 2.7286801571891925
Validation loss: 2.5875404098341086

Epoch: 5| Step: 9
Training loss: 2.7783845005766272
Validation loss: 2.5721303674857996

Epoch: 5| Step: 10
Training loss: 2.708012214599289
Validation loss: 2.605313003415356

Epoch: 144| Step: 0
Training loss: 2.959577988105024
Validation loss: 2.630090741372021

Epoch: 5| Step: 1
Training loss: 2.1779204832191614
Validation loss: 2.6059452728121366

Epoch: 5| Step: 2
Training loss: 3.2694888095083745
Validation loss: 2.614454089640223

Epoch: 5| Step: 3
Training loss: 2.111870426964416
Validation loss: 2.612883617648353

Epoch: 5| Step: 4
Training loss: 2.5503203134752432
Validation loss: 2.6151488193946886

Epoch: 5| Step: 5
Training loss: 2.683323653620287
Validation loss: 2.60535177587002

Epoch: 5| Step: 6
Training loss: 2.726303831580825
Validation loss: 2.5999770924290257

Epoch: 5| Step: 7
Training loss: 3.1761795676272757
Validation loss: 2.6162213685779268

Epoch: 5| Step: 8
Training loss: 2.9672692069183215
Validation loss: 2.593921212432501

Epoch: 5| Step: 9
Training loss: 1.37344385000243
Validation loss: 2.5844048622444484

Epoch: 5| Step: 10
Training loss: 2.6181900154031204
Validation loss: 2.606089731909614

Epoch: 145| Step: 0
Training loss: 2.5888630432763415
Validation loss: 2.632239169431586

Epoch: 5| Step: 1
Training loss: 2.108991800045389
Validation loss: 2.590925475902331

Epoch: 5| Step: 2
Training loss: 2.744965018794727
Validation loss: 2.603175258482455

Epoch: 5| Step: 3
Training loss: 3.088161159875766
Validation loss: 2.608170998202827

Epoch: 5| Step: 4
Training loss: 2.625833015873667
Validation loss: 2.6148979446476184

Epoch: 5| Step: 5
Training loss: 3.044024106946572
Validation loss: 2.5942033533842466

Epoch: 5| Step: 6
Training loss: 2.7214608544178818
Validation loss: 2.6330475549965517

Epoch: 5| Step: 7
Training loss: 2.2939230705472378
Validation loss: 2.6253289125547226

Epoch: 5| Step: 8
Training loss: 2.6810937867085967
Validation loss: 2.6184820082245044

Epoch: 5| Step: 9
Training loss: 2.892145530194196
Validation loss: 2.5980558322602945

Epoch: 5| Step: 10
Training loss: 1.9978039128611107
Validation loss: 2.6273797016367926

Epoch: 146| Step: 0
Training loss: 2.5505754232974955
Validation loss: 2.615398692807867

Epoch: 5| Step: 1
Training loss: 2.287518602306
Validation loss: 2.6056564275021987

Epoch: 5| Step: 2
Training loss: 2.8980186139148034
Validation loss: 2.590386793011939

Epoch: 5| Step: 3
Training loss: 2.6625247219890067
Validation loss: 2.607957533688008

Epoch: 5| Step: 4
Training loss: 2.142434462231523
Validation loss: 2.6324828562181057

Epoch: 5| Step: 5
Training loss: 2.674299868646945
Validation loss: 2.613995604198541

Epoch: 5| Step: 6
Training loss: 2.132604791497081
Validation loss: 2.608303599492981

Epoch: 5| Step: 7
Training loss: 3.4591921157531806
Validation loss: 2.5886961721092856

Epoch: 5| Step: 8
Training loss: 2.858578430284858
Validation loss: 2.5862643474597475

Epoch: 5| Step: 9
Training loss: 2.8431439435105124
Validation loss: 2.606611173776718

Epoch: 5| Step: 10
Training loss: 2.0878660737638026
Validation loss: 2.6045635336086894

Epoch: 147| Step: 0
Training loss: 2.2693889002057794
Validation loss: 2.6171142940112

Epoch: 5| Step: 1
Training loss: 2.9016579065367756
Validation loss: 2.577356447060514

Epoch: 5| Step: 2
Training loss: 2.4103420192157725
Validation loss: 2.593217838875876

Epoch: 5| Step: 3
Training loss: 2.8329680899274816
Validation loss: 2.5876464683995932

Epoch: 5| Step: 4
Training loss: 2.8172659441477887
Validation loss: 2.626726049863613

Epoch: 5| Step: 5
Training loss: 2.7304664797357336
Validation loss: 2.5992006233371057

Epoch: 5| Step: 6
Training loss: 2.629442361522374
Validation loss: 2.617052077988204

Epoch: 5| Step: 7
Training loss: 2.4914554489412084
Validation loss: 2.6098309652071574

Epoch: 5| Step: 8
Training loss: 3.043898473482668
Validation loss: 2.6063816870538448

Epoch: 5| Step: 9
Training loss: 2.6915768595575646
Validation loss: 2.599939522659076

Epoch: 5| Step: 10
Training loss: 2.3356500659278456
Validation loss: 2.593209785773383

Epoch: 148| Step: 0
Training loss: 2.8732651161480627
Validation loss: 2.574657495102717

Epoch: 5| Step: 1
Training loss: 2.004584422624295
Validation loss: 2.6045056937427677

Epoch: 5| Step: 2
Training loss: 3.056352010635398
Validation loss: 2.6314047414655772

Epoch: 5| Step: 3
Training loss: 2.6103769537321946
Validation loss: 2.6156739056857785

Epoch: 5| Step: 4
Training loss: 2.294895902446114
Validation loss: 2.5864664856539297

Epoch: 5| Step: 5
Training loss: 2.9287198922941626
Validation loss: 2.6185198313339417

Epoch: 5| Step: 6
Training loss: 2.0719215905660167
Validation loss: 2.5890500228569007

Epoch: 5| Step: 7
Training loss: 2.6637417328883912
Validation loss: 2.601950332767179

Epoch: 5| Step: 8
Training loss: 2.892337765904113
Validation loss: 2.5663326043898986

Epoch: 5| Step: 9
Training loss: 2.8627844323517833
Validation loss: 2.6088621369795506

Epoch: 5| Step: 10
Training loss: 2.5308242251379136
Validation loss: 2.57625238121639

Epoch: 149| Step: 0
Training loss: 2.7716121200573993
Validation loss: 2.5892891070383435

Epoch: 5| Step: 1
Training loss: 2.3685241551293914
Validation loss: 2.6006922344232675

Epoch: 5| Step: 2
Training loss: 2.7748196448750453
Validation loss: 2.598670864825872

Epoch: 5| Step: 3
Training loss: 2.8153204445182194
Validation loss: 2.581288804522338

Epoch: 5| Step: 4
Training loss: 2.6085905620581746
Validation loss: 2.5924600980900614

Epoch: 5| Step: 5
Training loss: 2.8875442171220445
Validation loss: 2.6186982047349687

Epoch: 5| Step: 6
Training loss: 2.868486240204352
Validation loss: 2.601219267188796

Epoch: 5| Step: 7
Training loss: 3.1827076808053736
Validation loss: 2.596920500697118

Epoch: 5| Step: 8
Training loss: 2.188990167134778
Validation loss: 2.562821159776351

Epoch: 5| Step: 9
Training loss: 2.4611388109005548
Validation loss: 2.6324254734916814

Epoch: 5| Step: 10
Training loss: 1.951444039823052
Validation loss: 2.605595798933649

Epoch: 150| Step: 0
Training loss: 2.6541722867018898
Validation loss: 2.604967517068841

Epoch: 5| Step: 1
Training loss: 3.465253149916377
Validation loss: 2.6045134791299716

Epoch: 5| Step: 2
Training loss: 2.4943518732117607
Validation loss: 2.618462482347495

Epoch: 5| Step: 3
Training loss: 2.3225672392048073
Validation loss: 2.589914316761964

Epoch: 5| Step: 4
Training loss: 2.5673630322970906
Validation loss: 2.611329026235534

Epoch: 5| Step: 5
Training loss: 2.5634441962242445
Validation loss: 2.5840748286107083

Epoch: 5| Step: 6
Training loss: 2.817089236085468
Validation loss: 2.615249594656436

Epoch: 5| Step: 7
Training loss: 2.480027142960693
Validation loss: 2.6183444770997832

Epoch: 5| Step: 8
Training loss: 2.146276656592365
Validation loss: 2.6118004201106646

Epoch: 5| Step: 9
Training loss: 2.9087174308602637
Validation loss: 2.5998555956180724

Epoch: 5| Step: 10
Training loss: 2.3497934372392972
Validation loss: 2.608053690156245

Epoch: 151| Step: 0
Training loss: 3.0349889289364946
Validation loss: 2.6275760288907466

Epoch: 5| Step: 1
Training loss: 1.8262665912728329
Validation loss: 2.638353205830083

Epoch: 5| Step: 2
Training loss: 2.40416379385192
Validation loss: 2.5930202419733854

Epoch: 5| Step: 3
Training loss: 2.45328973107706
Validation loss: 2.600843873342614

Epoch: 5| Step: 4
Training loss: 2.8518601353659427
Validation loss: 2.6202933095132575

Epoch: 5| Step: 5
Training loss: 3.2434101786695386
Validation loss: 2.5927182035744814

Epoch: 5| Step: 6
Training loss: 2.4677654186219637
Validation loss: 2.5997275817937697

Epoch: 5| Step: 7
Training loss: 2.8300424050972164
Validation loss: 2.5998332033420644

Epoch: 5| Step: 8
Training loss: 2.479435166209982
Validation loss: 2.62281216900611

Epoch: 5| Step: 9
Training loss: 2.670643305056255
Validation loss: 2.621113779055562

Epoch: 5| Step: 10
Training loss: 2.404152488556502
Validation loss: 2.610246881703844

Epoch: 152| Step: 0
Training loss: 3.1123920161500904
Validation loss: 2.617380874192446

Epoch: 5| Step: 1
Training loss: 2.3806697028247648
Validation loss: 2.598868101645124

Epoch: 5| Step: 2
Training loss: 2.4718001632839766
Validation loss: 2.557805272518984

Epoch: 5| Step: 3
Training loss: 2.6942588626446438
Validation loss: 2.604851351077773

Epoch: 5| Step: 4
Training loss: 2.3816269223327518
Validation loss: 2.6075368794028715

Epoch: 5| Step: 5
Training loss: 2.530785223593939
Validation loss: 2.6011066485142864

Epoch: 5| Step: 6
Training loss: 2.6273695831889086
Validation loss: 2.578099105172922

Epoch: 5| Step: 7
Training loss: 2.4436558971189397
Validation loss: 2.60281922229362

Epoch: 5| Step: 8
Training loss: 2.4112377244351113
Validation loss: 2.5869374540385346

Epoch: 5| Step: 9
Training loss: 3.2851008026124853
Validation loss: 2.594986742434578

Epoch: 5| Step: 10
Training loss: 2.5313346754440085
Validation loss: 2.602901209028388

Epoch: 153| Step: 0
Training loss: 2.539499849653305
Validation loss: 2.6235379807592314

Epoch: 5| Step: 1
Training loss: 2.4758994962911687
Validation loss: 2.5883658615933656

Epoch: 5| Step: 2
Training loss: 3.1646999140936964
Validation loss: 2.594137118158977

Epoch: 5| Step: 3
Training loss: 1.7901911611083736
Validation loss: 2.627569574842055

Epoch: 5| Step: 4
Training loss: 2.9739769146144472
Validation loss: 2.5956267441289924

Epoch: 5| Step: 5
Training loss: 2.710929936555101
Validation loss: 2.613199262244772

Epoch: 5| Step: 6
Training loss: 2.45169735325484
Validation loss: 2.600800125827904

Epoch: 5| Step: 7
Training loss: 2.9090523283740963
Validation loss: 2.5987560602782036

Epoch: 5| Step: 8
Training loss: 2.689907946943725
Validation loss: 2.616886828505699

Epoch: 5| Step: 9
Training loss: 2.79684456750094
Validation loss: 2.622316929815017

Epoch: 5| Step: 10
Training loss: 2.3534577801825565
Validation loss: 2.619195130438022

Epoch: 154| Step: 0
Training loss: 2.740889282707091
Validation loss: 2.644418354702249

Epoch: 5| Step: 1
Training loss: 2.7311418874193096
Validation loss: 2.627105071966153

Epoch: 5| Step: 2
Training loss: 2.710030879587288
Validation loss: 2.6171001490153545

Epoch: 5| Step: 3
Training loss: 2.6119125727908337
Validation loss: 2.620333874760237

Epoch: 5| Step: 4
Training loss: 2.3354859186726773
Validation loss: 2.6125273118885497

Epoch: 5| Step: 5
Training loss: 2.353535986847862
Validation loss: 2.611423383285886

Epoch: 5| Step: 6
Training loss: 2.5843405964601422
Validation loss: 2.6387168376629493

Epoch: 5| Step: 7
Training loss: 2.7855683138264
Validation loss: 2.6034322465170474

Epoch: 5| Step: 8
Training loss: 2.54213334056932
Validation loss: 2.6259762286184394

Epoch: 5| Step: 9
Training loss: 3.2202377584595054
Validation loss: 2.609767506782306

Epoch: 5| Step: 10
Training loss: 2.356817210603482
Validation loss: 2.585905183365202

Epoch: 155| Step: 0
Training loss: 2.624757028869874
Validation loss: 2.6019709348181834

Epoch: 5| Step: 1
Training loss: 3.3527235318732678
Validation loss: 2.5933922269961327

Epoch: 5| Step: 2
Training loss: 2.3594178454822448
Validation loss: 2.596769396303551

Epoch: 5| Step: 3
Training loss: 2.573746448308746
Validation loss: 2.6226230960376835

Epoch: 5| Step: 4
Training loss: 2.910118072054524
Validation loss: 2.5981983912850266

Epoch: 5| Step: 5
Training loss: 2.256288218504759
Validation loss: 2.595268778414693

Epoch: 5| Step: 6
Training loss: 2.4076976632391243
Validation loss: 2.6165489910474395

Epoch: 5| Step: 7
Training loss: 3.3340716180185974
Validation loss: 2.614642301223855

Epoch: 5| Step: 8
Training loss: 2.63479584831396
Validation loss: 2.6080735362612897

Epoch: 5| Step: 9
Training loss: 1.9159691481246643
Validation loss: 2.6188845910667813

Epoch: 5| Step: 10
Training loss: 2.3547730691672584
Validation loss: 2.5924491422282383

Epoch: 156| Step: 0
Training loss: 2.297713146264052
Validation loss: 2.584578233659065

Epoch: 5| Step: 1
Training loss: 2.2832158645522473
Validation loss: 2.5904282501592513

Epoch: 5| Step: 2
Training loss: 2.201320369013768
Validation loss: 2.5920111012215377

Epoch: 5| Step: 3
Training loss: 2.8452922286139497
Validation loss: 2.629472255061728

Epoch: 5| Step: 4
Training loss: 2.6383846191543205
Validation loss: 2.627336869209407

Epoch: 5| Step: 5
Training loss: 2.166596839464281
Validation loss: 2.601755272228458

Epoch: 5| Step: 6
Training loss: 3.1420831284529056
Validation loss: 2.614490346738493

Epoch: 5| Step: 7
Training loss: 2.8687701521687163
Validation loss: 2.5989519131061427

Epoch: 5| Step: 8
Training loss: 2.8869336452172236
Validation loss: 2.6248111139284265

Epoch: 5| Step: 9
Training loss: 2.503138860504599
Validation loss: 2.589283710028164

Epoch: 5| Step: 10
Training loss: 3.0578467381294896
Validation loss: 2.612896535487075

Epoch: 157| Step: 0
Training loss: 2.732408175866973
Validation loss: 2.616262558435599

Epoch: 5| Step: 1
Training loss: 2.934157884912008
Validation loss: 2.6129855153494645

Epoch: 5| Step: 2
Training loss: 2.3660330900391906
Validation loss: 2.5985273991624283

Epoch: 5| Step: 3
Training loss: 2.6635488423258398
Validation loss: 2.6046401228848723

Epoch: 5| Step: 4
Training loss: 2.7547880451896254
Validation loss: 2.6113386045436435

Epoch: 5| Step: 5
Training loss: 2.777245027528563
Validation loss: 2.612316623890866

Epoch: 5| Step: 6
Training loss: 1.9779205481769264
Validation loss: 2.590165609551118

Epoch: 5| Step: 7
Training loss: 2.4965973586311967
Validation loss: 2.6478565355785997

Epoch: 5| Step: 8
Training loss: 2.731630441108528
Validation loss: 2.6081886750947887

Epoch: 5| Step: 9
Training loss: 1.82210822207555
Validation loss: 2.6013653280233955

Epoch: 5| Step: 10
Training loss: 3.2755123290969927
Validation loss: 2.6269243187466116

Epoch: 158| Step: 0
Training loss: 2.70820501952777
Validation loss: 2.626478006648122

Epoch: 5| Step: 1
Training loss: 2.4819799430522447
Validation loss: 2.599828249770049

Epoch: 5| Step: 2
Training loss: 3.4393964217979955
Validation loss: 2.606256314206038

Epoch: 5| Step: 3
Training loss: 2.5914055213317675
Validation loss: 2.5888706850809697

Epoch: 5| Step: 4
Training loss: 2.495574562868084
Validation loss: 2.6200607413767467

Epoch: 5| Step: 5
Training loss: 2.3616356535037113
Validation loss: 2.5912339566802136

Epoch: 5| Step: 6
Training loss: 2.7878540156385894
Validation loss: 2.6086192154992114

Epoch: 5| Step: 7
Training loss: 2.28679891379976
Validation loss: 2.6050070652320616

Epoch: 5| Step: 8
Training loss: 2.38848601746534
Validation loss: 2.6142398961817688

Epoch: 5| Step: 9
Training loss: 2.8364480980277387
Validation loss: 2.6048143299282214

Epoch: 5| Step: 10
Training loss: 2.1340684930379568
Validation loss: 2.6052177667331176

Epoch: 159| Step: 0
Training loss: 2.823836473523072
Validation loss: 2.623810535260142

Epoch: 5| Step: 1
Training loss: 2.5730297254260446
Validation loss: 2.5910116428786742

Epoch: 5| Step: 2
Training loss: 2.786892685356069
Validation loss: 2.6237879346088615

Epoch: 5| Step: 3
Training loss: 2.2029905886940395
Validation loss: 2.606350772278992

Epoch: 5| Step: 4
Training loss: 2.3492875865800738
Validation loss: 2.5944733651901237

Epoch: 5| Step: 5
Training loss: 2.6330837030837184
Validation loss: 2.6157144847463685

Epoch: 5| Step: 6
Training loss: 3.0948512111513597
Validation loss: 2.6110736833623176

Epoch: 5| Step: 7
Training loss: 2.302641293211215
Validation loss: 2.5690733534006798

Epoch: 5| Step: 8
Training loss: 3.0049924635197582
Validation loss: 2.6198693708788405

Epoch: 5| Step: 9
Training loss: 2.4297170361259908
Validation loss: 2.5912961287475866

Epoch: 5| Step: 10
Training loss: 2.583510997774648
Validation loss: 2.609198161629522

Epoch: 160| Step: 0
Training loss: 2.80251157719095
Validation loss: 2.5958565199577603

Epoch: 5| Step: 1
Training loss: 3.005523048110696
Validation loss: 2.6016153900939907

Epoch: 5| Step: 2
Training loss: 2.4367799918161723
Validation loss: 2.630047788363234

Epoch: 5| Step: 3
Training loss: 2.011792938938448
Validation loss: 2.6117448720186736

Epoch: 5| Step: 4
Training loss: 2.4180400388004215
Validation loss: 2.562907509924195

Epoch: 5| Step: 5
Training loss: 2.9537367414192253
Validation loss: 2.612572332975362

Epoch: 5| Step: 6
Training loss: 1.9575653870088945
Validation loss: 2.6023784504546663

Epoch: 5| Step: 7
Training loss: 2.3795372638129177
Validation loss: 2.5930600909895287

Epoch: 5| Step: 8
Training loss: 2.654715330304708
Validation loss: 2.60544650091735

Epoch: 5| Step: 9
Training loss: 3.222198416815622
Validation loss: 2.603368644921819

Epoch: 5| Step: 10
Training loss: 2.525467000397922
Validation loss: 2.5737257129631486

Epoch: 161| Step: 0
Training loss: 2.158714102759699
Validation loss: 2.605452863158948

Epoch: 5| Step: 1
Training loss: 2.8826732240026507
Validation loss: 2.6075854404505874

Epoch: 5| Step: 2
Training loss: 2.571623123090383
Validation loss: 2.589434909184588

Epoch: 5| Step: 3
Training loss: 2.7665829481151056
Validation loss: 2.6284749868977904

Epoch: 5| Step: 4
Training loss: 2.5390209018527528
Validation loss: 2.614742288111513

Epoch: 5| Step: 5
Training loss: 2.4395983540512063
Validation loss: 2.5963999523395835

Epoch: 5| Step: 6
Training loss: 2.48113716310926
Validation loss: 2.593949639506999

Epoch: 5| Step: 7
Training loss: 3.5097448383409913
Validation loss: 2.590920623046705

Epoch: 5| Step: 8
Training loss: 2.327599178049087
Validation loss: 2.609572738789923

Epoch: 5| Step: 9
Training loss: 2.4839028923538455
Validation loss: 2.6131796905179066

Epoch: 5| Step: 10
Training loss: 2.354651668405054
Validation loss: 2.598716648813147

Epoch: 162| Step: 0
Training loss: 2.9369446249739837
Validation loss: 2.617539484913471

Epoch: 5| Step: 1
Training loss: 2.5654037584636087
Validation loss: 2.5853878872560245

Epoch: 5| Step: 2
Training loss: 3.445928747723494
Validation loss: 2.594137068746773

Epoch: 5| Step: 3
Training loss: 2.586747241518565
Validation loss: 2.6284547184068523

Epoch: 5| Step: 4
Training loss: 2.162509181714273
Validation loss: 2.593168079476503

Epoch: 5| Step: 5
Training loss: 2.7548956209822766
Validation loss: 2.614256208175688

Epoch: 5| Step: 6
Training loss: 1.6875535461972633
Validation loss: 2.6218213056904855

Epoch: 5| Step: 7
Training loss: 2.1877660317097836
Validation loss: 2.6038081296811404

Epoch: 5| Step: 8
Training loss: 2.792151015288266
Validation loss: 2.613502567013026

Epoch: 5| Step: 9
Training loss: 2.3191642617384405
Validation loss: 2.586244570908319

Epoch: 5| Step: 10
Training loss: 2.970445169037513
Validation loss: 2.5919630604138235

Epoch: 163| Step: 0
Training loss: 2.41855329556484
Validation loss: 2.6079782824267275

Epoch: 5| Step: 1
Training loss: 2.977549952321018
Validation loss: 2.5860088256639524

Epoch: 5| Step: 2
Training loss: 1.792116049661774
Validation loss: 2.60452868958036

Epoch: 5| Step: 3
Training loss: 2.6381450497051318
Validation loss: 2.5987736483061528

Epoch: 5| Step: 4
Training loss: 2.3841635954044973
Validation loss: 2.602231633966806

Epoch: 5| Step: 5
Training loss: 2.6990604602646573
Validation loss: 2.5978095098930725

Epoch: 5| Step: 6
Training loss: 2.5064083934018777
Validation loss: 2.6012410581771848

Epoch: 5| Step: 7
Training loss: 2.408507835991553
Validation loss: 2.581508081138665

Epoch: 5| Step: 8
Training loss: 2.8240855331975903
Validation loss: 2.611663432852309

Epoch: 5| Step: 9
Training loss: 2.8055189170165638
Validation loss: 2.573969881304379

Epoch: 5| Step: 10
Training loss: 3.213295027028346
Validation loss: 2.597943671244918

Epoch: 164| Step: 0
Training loss: 2.9058427422774757
Validation loss: 2.6078343383690212

Epoch: 5| Step: 1
Training loss: 2.6868753816294215
Validation loss: 2.596032980401798

Epoch: 5| Step: 2
Training loss: 2.7220149112660166
Validation loss: 2.6339484619273126

Epoch: 5| Step: 3
Training loss: 2.705061731392112
Validation loss: 2.6039870717457805

Epoch: 5| Step: 4
Training loss: 2.28839122316504
Validation loss: 2.611212884060942

Epoch: 5| Step: 5
Training loss: 2.4230597766739987
Validation loss: 2.6364015289501306

Epoch: 5| Step: 6
Training loss: 2.3073910131371544
Validation loss: 2.597660369339319

Epoch: 5| Step: 7
Training loss: 2.4116572276758714
Validation loss: 2.6022835812180714

Epoch: 5| Step: 8
Training loss: 2.6603878329354274
Validation loss: 2.607131056041156

Epoch: 5| Step: 9
Training loss: 3.443268253810643
Validation loss: 2.6299873433845122

Epoch: 5| Step: 10
Training loss: 2.176892091178555
Validation loss: 2.605157427603215

Epoch: 165| Step: 0
Training loss: 2.60289704972222
Validation loss: 2.6194966154824177

Epoch: 5| Step: 1
Training loss: 3.119106686669622
Validation loss: 2.609871239254196

Epoch: 5| Step: 2
Training loss: 1.7436555570232575
Validation loss: 2.6172562314814485

Epoch: 5| Step: 3
Training loss: 2.917404590082824
Validation loss: 2.577962164834246

Epoch: 5| Step: 4
Training loss: 2.7467004748766737
Validation loss: 2.6169290051598986

Epoch: 5| Step: 5
Training loss: 2.320208922877589
Validation loss: 2.593698263115652

Epoch: 5| Step: 6
Training loss: 2.671117307074299
Validation loss: 2.60358335857395

Epoch: 5| Step: 7
Training loss: 2.944398935634077
Validation loss: 2.604460323061043

Epoch: 5| Step: 8
Training loss: 2.9784743209226274
Validation loss: 2.6123583758049445

Epoch: 5| Step: 9
Training loss: 2.148960895940523
Validation loss: 2.587450621323345

Epoch: 5| Step: 10
Training loss: 2.1134952570778753
Validation loss: 2.578882149357903

Epoch: 166| Step: 0
Training loss: 2.4368109095819515
Validation loss: 2.6069732000999015

Epoch: 5| Step: 1
Training loss: 2.847646035593392
Validation loss: 2.586925833611623

Epoch: 5| Step: 2
Training loss: 2.3623499020321583
Validation loss: 2.5943455433085383

Epoch: 5| Step: 3
Training loss: 2.5080135657021176
Validation loss: 2.5911112653125223

Epoch: 5| Step: 4
Training loss: 1.748703612666015
Validation loss: 2.595203845680394

Epoch: 5| Step: 5
Training loss: 2.6101042134025563
Validation loss: 2.6004340676382918

Epoch: 5| Step: 6
Training loss: 3.0815642840754838
Validation loss: 2.594168461118698

Epoch: 5| Step: 7
Training loss: 3.3122646320142772
Validation loss: 2.6059570956863887

Epoch: 5| Step: 8
Training loss: 3.1635434325389857
Validation loss: 2.566626133363651

Epoch: 5| Step: 9
Training loss: 2.0046812347290417
Validation loss: 2.552652149878604

Epoch: 5| Step: 10
Training loss: 1.938494703846944
Validation loss: 2.5787337344274315

Epoch: 167| Step: 0
Training loss: 2.737412079396439
Validation loss: 2.602714179448588

Epoch: 5| Step: 1
Training loss: 2.635108286389718
Validation loss: 2.5950418144671494

Epoch: 5| Step: 2
Training loss: 2.68230468351792
Validation loss: 2.5682141267350986

Epoch: 5| Step: 3
Training loss: 2.475633609470728
Validation loss: 2.6088805609230286

Epoch: 5| Step: 4
Training loss: 2.0267471876377816
Validation loss: 2.5802970201482167

Epoch: 5| Step: 5
Training loss: 2.6311756331927976
Validation loss: 2.5826690781107438

Epoch: 5| Step: 6
Training loss: 2.416221566701471
Validation loss: 2.593034860402881

Epoch: 5| Step: 7
Training loss: 2.5983761815160955
Validation loss: 2.6205876491448277

Epoch: 5| Step: 8
Training loss: 2.727027481785538
Validation loss: 2.5913594944020475

Epoch: 5| Step: 9
Training loss: 2.837244494525685
Validation loss: 2.5996307194414596

Epoch: 5| Step: 10
Training loss: 2.9260897505600405
Validation loss: 2.571147618585223

Epoch: 168| Step: 0
Training loss: 2.283284364532558
Validation loss: 2.595614751728091

Epoch: 5| Step: 1
Training loss: 2.335471422527344
Validation loss: 2.562882778732514

Epoch: 5| Step: 2
Training loss: 2.4473772685652575
Validation loss: 2.6243161464586797

Epoch: 5| Step: 3
Training loss: 2.3846459511011844
Validation loss: 2.56076975127538

Epoch: 5| Step: 4
Training loss: 2.903142108189297
Validation loss: 2.590472638954129

Epoch: 5| Step: 5
Training loss: 2.9309577324434612
Validation loss: 2.6052537853303765

Epoch: 5| Step: 6
Training loss: 2.6754495011327672
Validation loss: 2.615140563262053

Epoch: 5| Step: 7
Training loss: 2.747294569032532
Validation loss: 2.578209139239295

Epoch: 5| Step: 8
Training loss: 2.7397176808726535
Validation loss: 2.5927479589080336

Epoch: 5| Step: 9
Training loss: 2.586048872932095
Validation loss: 2.612434840578345

Epoch: 5| Step: 10
Training loss: 2.353863879511524
Validation loss: 2.57894939567898

Epoch: 169| Step: 0
Training loss: 3.0932903526323674
Validation loss: 2.5706714098149464

Epoch: 5| Step: 1
Training loss: 2.900182810315921
Validation loss: 2.5897949651683208

Epoch: 5| Step: 2
Training loss: 2.4466013086651475
Validation loss: 2.6115997264264483

Epoch: 5| Step: 3
Training loss: 2.343368499224298
Validation loss: 2.566668575586068

Epoch: 5| Step: 4
Training loss: 3.0155990678532034
Validation loss: 2.587647749899358

Epoch: 5| Step: 5
Training loss: 2.1498027001274087
Validation loss: 2.6061987819258654

Epoch: 5| Step: 6
Training loss: 2.9364748850222115
Validation loss: 2.595802176289248

Epoch: 5| Step: 7
Training loss: 2.7341439285735785
Validation loss: 2.5721943478106906

Epoch: 5| Step: 8
Training loss: 2.5233289382305024
Validation loss: 2.612120774022298

Epoch: 5| Step: 9
Training loss: 2.0027294607531867
Validation loss: 2.604108323622953

Epoch: 5| Step: 10
Training loss: 1.9823251785222626
Validation loss: 2.581865636699494

Epoch: 170| Step: 0
Training loss: 2.8563746986464125
Validation loss: 2.5986873919419353

Epoch: 5| Step: 1
Training loss: 2.5432760636000866
Validation loss: 2.579156460828722

Epoch: 5| Step: 2
Training loss: 2.5412088096421517
Validation loss: 2.604797525758766

Epoch: 5| Step: 3
Training loss: 2.9452440167871337
Validation loss: 2.6098018103384786

Epoch: 5| Step: 4
Training loss: 2.311613376867717
Validation loss: 2.593248477212552

Epoch: 5| Step: 5
Training loss: 2.554793516053297
Validation loss: 2.6181946351006125

Epoch: 5| Step: 6
Training loss: 2.715164977904431
Validation loss: 2.599412427672113

Epoch: 5| Step: 7
Training loss: 2.254615817447276
Validation loss: 2.595272675334657

Epoch: 5| Step: 8
Training loss: 2.31791115777006
Validation loss: 2.607710074990265

Epoch: 5| Step: 9
Training loss: 3.163942386560804
Validation loss: 2.603380077725422

Epoch: 5| Step: 10
Training loss: 2.1331251425286197
Validation loss: 2.5777982855917694

Epoch: 171| Step: 0
Training loss: 1.912983804481655
Validation loss: 2.5995982332976166

Epoch: 5| Step: 1
Training loss: 3.2194500504464014
Validation loss: 2.595770827377851

Epoch: 5| Step: 2
Training loss: 2.024689629399516
Validation loss: 2.593234731921973

Epoch: 5| Step: 3
Training loss: 2.6546391707809702
Validation loss: 2.594090498314098

Epoch: 5| Step: 4
Training loss: 3.0082078550029365
Validation loss: 2.5830435373654437

Epoch: 5| Step: 5
Training loss: 2.5617907403182203
Validation loss: 2.612243863366485

Epoch: 5| Step: 6
Training loss: 2.78486809436992
Validation loss: 2.6059354902236094

Epoch: 5| Step: 7
Training loss: 2.788256531421718
Validation loss: 2.5732321500733235

Epoch: 5| Step: 8
Training loss: 2.342593200034609
Validation loss: 2.6131575355386287

Epoch: 5| Step: 9
Training loss: 2.5967494672600457
Validation loss: 2.599208959690871

Epoch: 5| Step: 10
Training loss: 2.226812730079692
Validation loss: 2.5962457709008153

Epoch: 172| Step: 0
Training loss: 2.6728256943509825
Validation loss: 2.609975878146285

Epoch: 5| Step: 1
Training loss: 2.65549215837864
Validation loss: 2.593652225474609

Epoch: 5| Step: 2
Training loss: 2.588508365245475
Validation loss: 2.584801572889077

Epoch: 5| Step: 3
Training loss: 2.0472117139781525
Validation loss: 2.5894762875192576

Epoch: 5| Step: 4
Training loss: 2.502700396277799
Validation loss: 2.583862646584388

Epoch: 5| Step: 5
Training loss: 2.5405477551944067
Validation loss: 2.594426894666734

Epoch: 5| Step: 6
Training loss: 3.1405997963268857
Validation loss: 2.574638318937679

Epoch: 5| Step: 7
Training loss: 2.6569853718404843
Validation loss: 2.5886987672446247

Epoch: 5| Step: 8
Training loss: 2.1666743082743163
Validation loss: 2.6080629163039024

Epoch: 5| Step: 9
Training loss: 2.9150894441835455
Validation loss: 2.6157928781841617

Epoch: 5| Step: 10
Training loss: 2.131964210918411
Validation loss: 2.587753413241526

Epoch: 173| Step: 0
Training loss: 2.265079406289518
Validation loss: 2.605410654226792

Epoch: 5| Step: 1
Training loss: 3.3344617523091045
Validation loss: 2.598051143943589

Epoch: 5| Step: 2
Training loss: 2.3275838133311235
Validation loss: 2.614105791533544

Epoch: 5| Step: 3
Training loss: 2.755798036364462
Validation loss: 2.592472529312893

Epoch: 5| Step: 4
Training loss: 2.97254075416238
Validation loss: 2.615825478291612

Epoch: 5| Step: 5
Training loss: 2.412784077418024
Validation loss: 2.600184483526304

Epoch: 5| Step: 6
Training loss: 2.5276669232254605
Validation loss: 2.6028307776736153

Epoch: 5| Step: 7
Training loss: 2.7520246855160915
Validation loss: 2.5718261060202687

Epoch: 5| Step: 8
Training loss: 2.110056901137407
Validation loss: 2.5754367419762705

Epoch: 5| Step: 9
Training loss: 2.201915544260587
Validation loss: 2.581555854236103

Epoch: 5| Step: 10
Training loss: 2.7769932264136186
Validation loss: 2.5948940985346653

Epoch: 174| Step: 0
Training loss: 2.2885971898349777
Validation loss: 2.5873296331541993

Epoch: 5| Step: 1
Training loss: 2.4205407189575117
Validation loss: 2.6281089088569978

Epoch: 5| Step: 2
Training loss: 2.4474577345038293
Validation loss: 2.6204638163927187

Epoch: 5| Step: 3
Training loss: 2.404571046543894
Validation loss: 2.568699354676442

Epoch: 5| Step: 4
Training loss: 2.5744119435637285
Validation loss: 2.5921637988494637

Epoch: 5| Step: 5
Training loss: 3.0823914060004056
Validation loss: 2.5761725427359767

Epoch: 5| Step: 6
Training loss: 2.7931811271964038
Validation loss: 2.5613441791912805

Epoch: 5| Step: 7
Training loss: 2.5301309631587974
Validation loss: 2.602897705677648

Epoch: 5| Step: 8
Training loss: 2.4492173871731655
Validation loss: 2.592894980424461

Epoch: 5| Step: 9
Training loss: 2.888050149138763
Validation loss: 2.6056773441122183

Epoch: 5| Step: 10
Training loss: 2.3373402750043106
Validation loss: 2.6213685537136406

Epoch: 175| Step: 0
Training loss: 2.8423804034703424
Validation loss: 2.6146881006698726

Epoch: 5| Step: 1
Training loss: 2.680937272621089
Validation loss: 2.6048676263990993

Epoch: 5| Step: 2
Training loss: 2.984656675137833
Validation loss: 2.596864652580351

Epoch: 5| Step: 3
Training loss: 2.373277340596371
Validation loss: 2.576429470913007

Epoch: 5| Step: 4
Training loss: 2.2962414133641276
Validation loss: 2.599030592182666

Epoch: 5| Step: 5
Training loss: 2.426132004790586
Validation loss: 2.6017403786143163

Epoch: 5| Step: 6
Training loss: 2.348943830108416
Validation loss: 2.612244135212628

Epoch: 5| Step: 7
Training loss: 2.233184070248973
Validation loss: 2.5797792876607097

Epoch: 5| Step: 8
Training loss: 2.605587797862391
Validation loss: 2.6237351397216373

Epoch: 5| Step: 9
Training loss: 2.614537232335776
Validation loss: 2.5750328476034623

Epoch: 5| Step: 10
Training loss: 3.1209953588605828
Validation loss: 2.5650234208245783

Epoch: 176| Step: 0
Training loss: 2.621908456363846
Validation loss: 2.5949258225889476

Epoch: 5| Step: 1
Training loss: 2.009953644820545
Validation loss: 2.5955880219663987

Epoch: 5| Step: 2
Training loss: 2.836110007343665
Validation loss: 2.5908585587288018

Epoch: 5| Step: 3
Training loss: 1.9870944275096043
Validation loss: 2.5753369103886117

Epoch: 5| Step: 4
Training loss: 2.8162028203501075
Validation loss: 2.6159110543970114

Epoch: 5| Step: 5
Training loss: 2.69904376510296
Validation loss: 2.5583220316848476

Epoch: 5| Step: 6
Training loss: 2.9008862621019555
Validation loss: 2.588827741351674

Epoch: 5| Step: 7
Training loss: 2.792745258486063
Validation loss: 2.6092946393437444

Epoch: 5| Step: 8
Training loss: 2.5315878371856813
Validation loss: 2.617282294275597

Epoch: 5| Step: 9
Training loss: 2.5642643878685973
Validation loss: 2.5562979263573404

Epoch: 5| Step: 10
Training loss: 2.224567041170124
Validation loss: 2.6042249224309804

Epoch: 177| Step: 0
Training loss: 2.528485425005276
Validation loss: 2.6059637183613575

Epoch: 5| Step: 1
Training loss: 2.642214776185394
Validation loss: 2.6161509851878173

Epoch: 5| Step: 2
Training loss: 2.2336575083056935
Validation loss: 2.5854547194503015

Epoch: 5| Step: 3
Training loss: 2.7450035828947437
Validation loss: 2.616742928240588

Epoch: 5| Step: 4
Training loss: 2.384904187275227
Validation loss: 2.6070250255831193

Epoch: 5| Step: 5
Training loss: 1.9539442861729752
Validation loss: 2.590488805696101

Epoch: 5| Step: 6
Training loss: 2.812396492642855
Validation loss: 2.5780034339561344

Epoch: 5| Step: 7
Training loss: 2.341493359416414
Validation loss: 2.5780193855377598

Epoch: 5| Step: 8
Training loss: 2.440530995452507
Validation loss: 2.590629852677106

Epoch: 5| Step: 9
Training loss: 3.085736309205031
Validation loss: 2.5889245088101376

Epoch: 5| Step: 10
Training loss: 3.2399407748708016
Validation loss: 2.5995432587802108

Epoch: 178| Step: 0
Training loss: 1.8979634136496446
Validation loss: 2.580665410190532

Epoch: 5| Step: 1
Training loss: 1.786783023907471
Validation loss: 2.59986409454492

Epoch: 5| Step: 2
Training loss: 2.7882291686884786
Validation loss: 2.5835316198533227

Epoch: 5| Step: 3
Training loss: 2.67624766050804
Validation loss: 2.561025708130277

Epoch: 5| Step: 4
Training loss: 2.9830320841962523
Validation loss: 2.571631980495504

Epoch: 5| Step: 5
Training loss: 2.696454588476744
Validation loss: 2.596339354963081

Epoch: 5| Step: 6
Training loss: 2.843115096428227
Validation loss: 2.582194900805991

Epoch: 5| Step: 7
Training loss: 2.5915898899428145
Validation loss: 2.559259195657886

Epoch: 5| Step: 8
Training loss: 2.424544014287135
Validation loss: 2.607520595179715

Epoch: 5| Step: 9
Training loss: 2.7861004656048136
Validation loss: 2.590241570982896

Epoch: 5| Step: 10
Training loss: 2.3823470864954683
Validation loss: 2.5809113719939196

Epoch: 179| Step: 0
Training loss: 3.0064020193766194
Validation loss: 2.574119239669026

Epoch: 5| Step: 1
Training loss: 2.6245860727112893
Validation loss: 2.609037835709917

Epoch: 5| Step: 2
Training loss: 2.5014280055511424
Validation loss: 2.619120897992045

Epoch: 5| Step: 3
Training loss: 2.534122579588953
Validation loss: 2.581991753032453

Epoch: 5| Step: 4
Training loss: 2.46055207640296
Validation loss: 2.5887420409039477

Epoch: 5| Step: 5
Training loss: 2.3479112432688574
Validation loss: 2.6024708003411186

Epoch: 5| Step: 6
Training loss: 2.2505972387481488
Validation loss: 2.5865376738284165

Epoch: 5| Step: 7
Training loss: 2.9491998330829574
Validation loss: 2.6048391157326662

Epoch: 5| Step: 8
Training loss: 2.207064197935759
Validation loss: 2.5817191786905522

Epoch: 5| Step: 9
Training loss: 2.6693551299888068
Validation loss: 2.5875356551556243

Epoch: 5| Step: 10
Training loss: 2.6771023127455766
Validation loss: 2.576383953574198

Epoch: 180| Step: 0
Training loss: 2.5422155902719727
Validation loss: 2.554347066482732

Epoch: 5| Step: 1
Training loss: 2.468673511720556
Validation loss: 2.622730319864157

Epoch: 5| Step: 2
Training loss: 2.3483830753398136
Validation loss: 2.5957131298535363

Epoch: 5| Step: 3
Training loss: 2.6908061074015337
Validation loss: 2.5945804105283496

Epoch: 5| Step: 4
Training loss: 2.4293399083787954
Validation loss: 2.620731718828221

Epoch: 5| Step: 5
Training loss: 2.3329077627733494
Validation loss: 2.6031573348255503

Epoch: 5| Step: 6
Training loss: 2.7757887638590515
Validation loss: 2.5878619050072826

Epoch: 5| Step: 7
Training loss: 2.732845030951408
Validation loss: 2.5808590380232883

Epoch: 5| Step: 8
Training loss: 2.839221408660737
Validation loss: 2.5758352831860085

Epoch: 5| Step: 9
Training loss: 2.9571230028800963
Validation loss: 2.6107233297426196

Epoch: 5| Step: 10
Training loss: 2.05053686229851
Validation loss: 2.591882599066879

Epoch: 181| Step: 0
Training loss: 2.72204136301716
Validation loss: 2.5878393197928395

Epoch: 5| Step: 1
Training loss: 2.8700640226659857
Validation loss: 2.5842288780891267

Epoch: 5| Step: 2
Training loss: 2.366278546257347
Validation loss: 2.5880269716440423

Epoch: 5| Step: 3
Training loss: 3.000633649664602
Validation loss: 2.583168918850224

Epoch: 5| Step: 4
Training loss: 2.677877009159323
Validation loss: 2.572722987474111

Epoch: 5| Step: 5
Training loss: 2.541559300474008
Validation loss: 2.5993405861076777

Epoch: 5| Step: 6
Training loss: 2.2449997335658947
Validation loss: 2.5983243364563284

Epoch: 5| Step: 7
Training loss: 2.3352896005556003
Validation loss: 2.5852584192582344

Epoch: 5| Step: 8
Training loss: 2.466191475005122
Validation loss: 2.578938329735294

Epoch: 5| Step: 9
Training loss: 2.0863432186047124
Validation loss: 2.599810763540996

Epoch: 5| Step: 10
Training loss: 2.6492060893596303
Validation loss: 2.5973380547207356

Epoch: 182| Step: 0
Training loss: 2.3081609898025293
Validation loss: 2.6128201430959384

Epoch: 5| Step: 1
Training loss: 3.018728921946987
Validation loss: 2.592001905964136

Epoch: 5| Step: 2
Training loss: 2.7826957802388113
Validation loss: 2.603949188667693

Epoch: 5| Step: 3
Training loss: 2.552207559689136
Validation loss: 2.5930197555478305

Epoch: 5| Step: 4
Training loss: 2.529544962495262
Validation loss: 2.5720059564655733

Epoch: 5| Step: 5
Training loss: 2.994360391274242
Validation loss: 2.5901171074245948

Epoch: 5| Step: 6
Training loss: 2.1356349058203397
Validation loss: 2.5924919567493045

Epoch: 5| Step: 7
Training loss: 2.777127929543099
Validation loss: 2.5948487470160124

Epoch: 5| Step: 8
Training loss: 2.467505322327908
Validation loss: 2.6179843669611897

Epoch: 5| Step: 9
Training loss: 2.5555573362077046
Validation loss: 2.589017948558949

Epoch: 5| Step: 10
Training loss: 1.6645576564191398
Validation loss: 2.588315405722313

Epoch: 183| Step: 0
Training loss: 2.4941624197608827
Validation loss: 2.577000799154067

Epoch: 5| Step: 1
Training loss: 2.6445973330288917
Validation loss: 2.6024270338759843

Epoch: 5| Step: 2
Training loss: 1.7561842773738099
Validation loss: 2.6166032506645256

Epoch: 5| Step: 3
Training loss: 2.6221290510762523
Validation loss: 2.6072490722598216

Epoch: 5| Step: 4
Training loss: 2.635723372594017
Validation loss: 2.605862692209141

Epoch: 5| Step: 5
Training loss: 2.7976876042709464
Validation loss: 2.6061674980679204

Epoch: 5| Step: 6
Training loss: 2.5803464624369608
Validation loss: 2.583362210681636

Epoch: 5| Step: 7
Training loss: 2.6422775785587973
Validation loss: 2.61827719196994

Epoch: 5| Step: 8
Training loss: 2.3363484815288866
Validation loss: 2.5734062707114402

Epoch: 5| Step: 9
Training loss: 3.0764594049650564
Validation loss: 2.5630870209742036

Epoch: 5| Step: 10
Training loss: 2.5295501464349064
Validation loss: 2.5973365914540247

Epoch: 184| Step: 0
Training loss: 2.7707497051114602
Validation loss: 2.5888705989288336

Epoch: 5| Step: 1
Training loss: 2.5140081860902925
Validation loss: 2.611141423131132

Epoch: 5| Step: 2
Training loss: 2.7757794015944275
Validation loss: 2.5848609818243573

Epoch: 5| Step: 3
Training loss: 2.3019861974691818
Validation loss: 2.5992410837950946

Epoch: 5| Step: 4
Training loss: 2.707483559344561
Validation loss: 2.608935529320162

Epoch: 5| Step: 5
Training loss: 2.442076861022519
Validation loss: 2.581587214889947

Epoch: 5| Step: 6
Training loss: 2.4106446796036263
Validation loss: 2.5762714742178994

Epoch: 5| Step: 7
Training loss: 2.4097167963802977
Validation loss: 2.5696894138594613

Epoch: 5| Step: 8
Training loss: 2.537630305209561
Validation loss: 2.6027006161369455

Epoch: 5| Step: 9
Training loss: 2.7625001829673743
Validation loss: 2.5761173648694884

Epoch: 5| Step: 10
Training loss: 2.2908084187055358
Validation loss: 2.5710973333398726

Epoch: 185| Step: 0
Training loss: 1.9591901676786412
Validation loss: 2.6010387223135663

Epoch: 5| Step: 1
Training loss: 2.7229720032450837
Validation loss: 2.6020838904721133

Epoch: 5| Step: 2
Training loss: 3.1938824053228325
Validation loss: 2.603000781208231

Epoch: 5| Step: 3
Training loss: 2.797595565295393
Validation loss: 2.5878348876250703

Epoch: 5| Step: 4
Training loss: 2.993140484715456
Validation loss: 2.599474638852782

Epoch: 5| Step: 5
Training loss: 2.068269347626134
Validation loss: 2.586286994503238

Epoch: 5| Step: 6
Training loss: 2.1233920577395926
Validation loss: 2.5877186262011986

Epoch: 5| Step: 7
Training loss: 2.34262770167285
Validation loss: 2.6044947565607908

Epoch: 5| Step: 8
Training loss: 2.9027294862696014
Validation loss: 2.608636677079686

Epoch: 5| Step: 9
Training loss: 2.3780281438164694
Validation loss: 2.6085318802909603

Epoch: 5| Step: 10
Training loss: 2.1094763837397914
Validation loss: 2.57828215427405

Epoch: 186| Step: 0
Training loss: 2.62882979623343
Validation loss: 2.5937123365715653

Epoch: 5| Step: 1
Training loss: 2.5563714779667324
Validation loss: 2.5866058257269953

Epoch: 5| Step: 2
Training loss: 3.2561771670230097
Validation loss: 2.6055461794984374

Epoch: 5| Step: 3
Training loss: 1.9605474198046662
Validation loss: 2.619828882595049

Epoch: 5| Step: 4
Training loss: 2.5456584997335416
Validation loss: 2.5861868442415252

Epoch: 5| Step: 5
Training loss: 2.9740479428519366
Validation loss: 2.6155628277866034

Epoch: 5| Step: 6
Training loss: 2.5272540352181876
Validation loss: 2.5536957993208986

Epoch: 5| Step: 7
Training loss: 2.3543953798534547
Validation loss: 2.579383890278034

Epoch: 5| Step: 8
Training loss: 2.381728729425345
Validation loss: 2.604175434384917

Epoch: 5| Step: 9
Training loss: 2.4751894059581443
Validation loss: 2.5829056502552024

Epoch: 5| Step: 10
Training loss: 1.9958538351685005
Validation loss: 2.555981592806903

Epoch: 187| Step: 0
Training loss: 1.94813100550157
Validation loss: 2.5588206586595845

Epoch: 5| Step: 1
Training loss: 2.167998002688343
Validation loss: 2.566554363938423

Epoch: 5| Step: 2
Training loss: 2.3569276761015674
Validation loss: 2.606338290199484

Epoch: 5| Step: 3
Training loss: 2.6777391830167447
Validation loss: 2.6073899382099084

Epoch: 5| Step: 4
Training loss: 3.3269550971580393
Validation loss: 2.577895609773703

Epoch: 5| Step: 5
Training loss: 2.1080228639770606
Validation loss: 2.6242089561668434

Epoch: 5| Step: 6
Training loss: 2.5243290604644577
Validation loss: 2.585412099748171

Epoch: 5| Step: 7
Training loss: 3.1237344849664095
Validation loss: 2.588149997423567

Epoch: 5| Step: 8
Training loss: 2.496823868210076
Validation loss: 2.584045842984642

Epoch: 5| Step: 9
Training loss: 2.7258101247765274
Validation loss: 2.5960064909666594

Epoch: 5| Step: 10
Training loss: 2.146729834478193
Validation loss: 2.5976005963354467

Epoch: 188| Step: 0
Training loss: 2.282613477445218
Validation loss: 2.582596889906268

Epoch: 5| Step: 1
Training loss: 2.5825477349004706
Validation loss: 2.5793217849133026

Epoch: 5| Step: 2
Training loss: 2.9595153130819747
Validation loss: 2.5716628032300126

Epoch: 5| Step: 3
Training loss: 2.1222773669048105
Validation loss: 2.574607700603491

Epoch: 5| Step: 4
Training loss: 2.0731312115184894
Validation loss: 2.5534133596267083

Epoch: 5| Step: 5
Training loss: 2.9061426942765682
Validation loss: 2.573989602270158

Epoch: 5| Step: 6
Training loss: 2.7720544079647054
Validation loss: 2.525790968949279

Epoch: 5| Step: 7
Training loss: 2.319446132250671
Validation loss: 2.5938075919490213

Epoch: 5| Step: 8
Training loss: 2.3420793809932614
Validation loss: 2.5974202277912353

Epoch: 5| Step: 9
Training loss: 2.6757990704242354
Validation loss: 2.6138178161425434

Epoch: 5| Step: 10
Training loss: 3.010629894972471
Validation loss: 2.6126467662026447

Epoch: 189| Step: 0
Training loss: 2.1088556851335785
Validation loss: 2.57825342817422

Epoch: 5| Step: 1
Training loss: 2.0425764768516848
Validation loss: 2.5754862277990256

Epoch: 5| Step: 2
Training loss: 3.147678179556815
Validation loss: 2.583461934585969

Epoch: 5| Step: 3
Training loss: 2.0881607837231306
Validation loss: 2.579136584051136

Epoch: 5| Step: 4
Training loss: 2.48661415390666
Validation loss: 2.581003063645788

Epoch: 5| Step: 5
Training loss: 2.5400113724281255
Validation loss: 2.6132500224785504

Epoch: 5| Step: 6
Training loss: 3.3154492474570287
Validation loss: 2.575930232774374

Epoch: 5| Step: 7
Training loss: 2.4757429144633787
Validation loss: 2.6031971443804482

Epoch: 5| Step: 8
Training loss: 2.755471768011177
Validation loss: 2.5721661238260314

Epoch: 5| Step: 9
Training loss: 2.41862239846063
Validation loss: 2.5936601595806943

Epoch: 5| Step: 10
Training loss: 2.0904923332783607
Validation loss: 2.5713852058607736

Epoch: 190| Step: 0
Training loss: 1.872343406597629
Validation loss: 2.6039401478027924

Epoch: 5| Step: 1
Training loss: 2.0279165057915156
Validation loss: 2.582222087896157

Epoch: 5| Step: 2
Training loss: 2.994773922190411
Validation loss: 2.603562727926105

Epoch: 5| Step: 3
Training loss: 2.9097274157089057
Validation loss: 2.593807832122829

Epoch: 5| Step: 4
Training loss: 2.7840162943111064
Validation loss: 2.635560230523006

Epoch: 5| Step: 5
Training loss: 2.2687717026862604
Validation loss: 2.6229452362207892

Epoch: 5| Step: 6
Training loss: 2.8699806183482885
Validation loss: 2.5721424773542534

Epoch: 5| Step: 7
Training loss: 1.9769899411213305
Validation loss: 2.565966534647923

Epoch: 5| Step: 8
Training loss: 2.4132894617733185
Validation loss: 2.6156183663457084

Epoch: 5| Step: 9
Training loss: 3.072880959168642
Validation loss: 2.584472461333872

Epoch: 5| Step: 10
Training loss: 2.3599961833599714
Validation loss: 2.5815796493408585

Epoch: 191| Step: 0
Training loss: 2.2888375129406917
Validation loss: 2.60467962975961

Epoch: 5| Step: 1
Training loss: 2.923633230029531
Validation loss: 2.5832969181327115

Epoch: 5| Step: 2
Training loss: 2.294295231100913
Validation loss: 2.60319881017697

Epoch: 5| Step: 3
Training loss: 2.3828715332723225
Validation loss: 2.59550561951878

Epoch: 5| Step: 4
Training loss: 2.5563745556917197
Validation loss: 2.563580531045763

Epoch: 5| Step: 5
Training loss: 2.3702684754197882
Validation loss: 2.603301165739426

Epoch: 5| Step: 6
Training loss: 2.5052163063815973
Validation loss: 2.5703060906722377

Epoch: 5| Step: 7
Training loss: 2.565080506397992
Validation loss: 2.594137573739456

Epoch: 5| Step: 8
Training loss: 2.8554134754931435
Validation loss: 2.615162273051062

Epoch: 5| Step: 9
Training loss: 2.1738498409039986
Validation loss: 2.5911780537723876

Epoch: 5| Step: 10
Training loss: 2.9369577759619228
Validation loss: 2.6314712116141568

Epoch: 192| Step: 0
Training loss: 2.9355811487000367
Validation loss: 2.6066530416649902

Epoch: 5| Step: 1
Training loss: 3.061736031045738
Validation loss: 2.6001225259621674

Epoch: 5| Step: 2
Training loss: 2.563181530641362
Validation loss: 2.5903220169940666

Epoch: 5| Step: 3
Training loss: 2.1095283735111696
Validation loss: 2.6256707160327544

Epoch: 5| Step: 4
Training loss: 2.266498265836108
Validation loss: 2.5922321375990824

Epoch: 5| Step: 5
Training loss: 2.190466912370386
Validation loss: 2.592253695084386

Epoch: 5| Step: 6
Training loss: 2.7171540234671374
Validation loss: 2.604608998458957

Epoch: 5| Step: 7
Training loss: 3.035043760986572
Validation loss: 2.560926347856781

Epoch: 5| Step: 8
Training loss: 2.4714426735618193
Validation loss: 2.6509572486355415

Epoch: 5| Step: 9
Training loss: 1.8682274894894708
Validation loss: 2.593137785220035

Epoch: 5| Step: 10
Training loss: 2.274694770207076
Validation loss: 2.6094401872556134

Epoch: 193| Step: 0
Training loss: 1.6049580376626926
Validation loss: 2.5668629002025067

Epoch: 5| Step: 1
Training loss: 2.585462451645196
Validation loss: 2.5831497234970975

Epoch: 5| Step: 2
Training loss: 2.249191456795101
Validation loss: 2.584667677598052

Epoch: 5| Step: 3
Training loss: 2.460846139332174
Validation loss: 2.5687413315017587

Epoch: 5| Step: 4
Training loss: 2.358674305326443
Validation loss: 2.613034167433915

Epoch: 5| Step: 5
Training loss: 2.328821884413604
Validation loss: 2.5661025396478316

Epoch: 5| Step: 6
Training loss: 3.1802474145188313
Validation loss: 2.5715833785361544

Epoch: 5| Step: 7
Training loss: 3.1881569578045648
Validation loss: 2.555705193144929

Epoch: 5| Step: 8
Training loss: 2.1884342923182394
Validation loss: 2.614490061398191

Epoch: 5| Step: 9
Training loss: 2.4414028320288574
Validation loss: 2.579400993192403

Epoch: 5| Step: 10
Training loss: 2.7864879190650913
Validation loss: 2.597761828953724

Epoch: 194| Step: 0
Training loss: 2.4437147289179575
Validation loss: 2.569936196710019

Epoch: 5| Step: 1
Training loss: 2.348718387051974
Validation loss: 2.5660460213002785

Epoch: 5| Step: 2
Training loss: 2.606291176450101
Validation loss: 2.573684847398034

Epoch: 5| Step: 3
Training loss: 2.2038530810520354
Validation loss: 2.581361572552572

Epoch: 5| Step: 4
Training loss: 3.0469225757503566
Validation loss: 2.5463187086234145

Epoch: 5| Step: 5
Training loss: 3.56954674052607
Validation loss: 2.5691788731178407

Epoch: 5| Step: 6
Training loss: 2.5647956985401867
Validation loss: 2.575716868721546

Epoch: 5| Step: 7
Training loss: 2.0305308315977
Validation loss: 2.5981372961170397

Epoch: 5| Step: 8
Training loss: 1.8348851860777684
Validation loss: 2.590177218907421

Epoch: 5| Step: 9
Training loss: 2.373836332642498
Validation loss: 2.6145995846808594

Epoch: 5| Step: 10
Training loss: 2.387801953140049
Validation loss: 2.547405939244007

Epoch: 195| Step: 0
Training loss: 2.221283876142499
Validation loss: 2.5866804813718702

Epoch: 5| Step: 1
Training loss: 2.441614248952122
Validation loss: 2.5701654444936692

Epoch: 5| Step: 2
Training loss: 2.612718735440392
Validation loss: 2.5831706571086204

Epoch: 5| Step: 3
Training loss: 2.517411918273581
Validation loss: 2.5939985715342058

Epoch: 5| Step: 4
Training loss: 2.0355214909632715
Validation loss: 2.602173045984034

Epoch: 5| Step: 5
Training loss: 3.332519781650632
Validation loss: 2.5651973081354034

Epoch: 5| Step: 6
Training loss: 2.367422564326761
Validation loss: 2.604760108190316

Epoch: 5| Step: 7
Training loss: 2.0671568807005167
Validation loss: 2.5927027765064197

Epoch: 5| Step: 8
Training loss: 2.578355998469992
Validation loss: 2.584299988028838

Epoch: 5| Step: 9
Training loss: 2.408084120830418
Validation loss: 2.5873720746278077

Epoch: 5| Step: 10
Training loss: 2.992593045552887
Validation loss: 2.5694230445060082

Epoch: 196| Step: 0
Training loss: 2.4193806262333974
Validation loss: 2.5568927590523294

Epoch: 5| Step: 1
Training loss: 2.9017862475048877
Validation loss: 2.5687676769486996

Epoch: 5| Step: 2
Training loss: 2.1510549795802527
Validation loss: 2.578775018043138

Epoch: 5| Step: 3
Training loss: 2.3634489141842048
Validation loss: 2.5939996423536296

Epoch: 5| Step: 4
Training loss: 2.5561297250819948
Validation loss: 2.5844532354886143

Epoch: 5| Step: 5
Training loss: 2.47608370319311
Validation loss: 2.5918483649730764

Epoch: 5| Step: 6
Training loss: 2.984958132349578
Validation loss: 2.580822148522042

Epoch: 5| Step: 7
Training loss: 2.434539758006221
Validation loss: 2.573695825363427

Epoch: 5| Step: 8
Training loss: 2.5058992402019435
Validation loss: 2.580262229949658

Epoch: 5| Step: 9
Training loss: 2.3095449176061567
Validation loss: 2.5401301494530917

Epoch: 5| Step: 10
Training loss: 2.6433962213251836
Validation loss: 2.5906489238309502

Epoch: 197| Step: 0
Training loss: 2.4950078712599137
Validation loss: 2.5834772292863173

Epoch: 5| Step: 1
Training loss: 2.4758192806386496
Validation loss: 2.579084887013093

Epoch: 5| Step: 2
Training loss: 2.707332797959322
Validation loss: 2.5494833053586614

Epoch: 5| Step: 3
Training loss: 2.69533514483241
Validation loss: 2.637193988978677

Epoch: 5| Step: 4
Training loss: 1.9448735611326318
Validation loss: 2.576290677532882

Epoch: 5| Step: 5
Training loss: 3.3306190565975715
Validation loss: 2.596074657461261

Epoch: 5| Step: 6
Training loss: 2.508933033864058
Validation loss: 2.6150875085083065

Epoch: 5| Step: 7
Training loss: 2.3491611322683057
Validation loss: 2.5808883479986027

Epoch: 5| Step: 8
Training loss: 2.3046478785325664
Validation loss: 2.6184432671797913

Epoch: 5| Step: 9
Training loss: 2.286370996242407
Validation loss: 2.5705788709322936

Epoch: 5| Step: 10
Training loss: 2.587691435435619
Validation loss: 2.596853612137421

Epoch: 198| Step: 0
Training loss: 1.9397704449743962
Validation loss: 2.594651706093157

Epoch: 5| Step: 1
Training loss: 2.8627870973763985
Validation loss: 2.5526438050969387

Epoch: 5| Step: 2
Training loss: 2.564362198204759
Validation loss: 2.597371602043107

Epoch: 5| Step: 3
Training loss: 2.3126813456594664
Validation loss: 2.5668593871157324

Epoch: 5| Step: 4
Training loss: 1.8457058376716178
Validation loss: 2.5775413411854062

Epoch: 5| Step: 5
Training loss: 2.6224131780894924
Validation loss: 2.5791510724350304

Epoch: 5| Step: 6
Training loss: 2.9396396717176296
Validation loss: 2.588455454938033

Epoch: 5| Step: 7
Training loss: 2.5970546398620877
Validation loss: 2.565338105775055

Epoch: 5| Step: 8
Training loss: 2.2291965898543498
Validation loss: 2.5695686519467067

Epoch: 5| Step: 9
Training loss: 2.8863768007255395
Validation loss: 2.5957189371940705

Epoch: 5| Step: 10
Training loss: 3.082116342199072
Validation loss: 2.5969605860167113

Epoch: 199| Step: 0
Training loss: 2.466928220319303
Validation loss: 2.5926471168752125

Epoch: 5| Step: 1
Training loss: 2.7181447550252433
Validation loss: 2.559479476669598

Epoch: 5| Step: 2
Training loss: 1.8496382488506578
Validation loss: 2.5534175884936774

Epoch: 5| Step: 3
Training loss: 2.7133379156213007
Validation loss: 2.592845941550305

Epoch: 5| Step: 4
Training loss: 2.4370963911764454
Validation loss: 2.610491695372876

Epoch: 5| Step: 5
Training loss: 2.3848696974181482
Validation loss: 2.5784279176433005

Epoch: 5| Step: 6
Training loss: 2.0282021764992026
Validation loss: 2.574768901927986

Epoch: 5| Step: 7
Training loss: 2.3441502547229196
Validation loss: 2.5946684554301416

Epoch: 5| Step: 8
Training loss: 2.6789960942369833
Validation loss: 2.5575025285369053

Epoch: 5| Step: 9
Training loss: 2.619016367036381
Validation loss: 2.5639074848621606

Epoch: 5| Step: 10
Training loss: 2.9941578246815186
Validation loss: 2.6096034758966633

Epoch: 200| Step: 0
Training loss: 2.7299508188869006
Validation loss: 2.577870902040549

Epoch: 5| Step: 1
Training loss: 2.386488283708426
Validation loss: 2.5789435421267393

Epoch: 5| Step: 2
Training loss: 2.4433178063385443
Validation loss: 2.5925522890570103

Epoch: 5| Step: 3
Training loss: 2.6570457612886136
Validation loss: 2.6065511816348343

Epoch: 5| Step: 4
Training loss: 2.483424934728873
Validation loss: 2.5972799137868963

Epoch: 5| Step: 5
Training loss: 2.731155069128664
Validation loss: 2.580147835086766

Epoch: 5| Step: 6
Training loss: 2.6049231282495375
Validation loss: 2.5950671342090423

Epoch: 5| Step: 7
Training loss: 2.37554674380462
Validation loss: 2.5684824395287227

Epoch: 5| Step: 8
Training loss: 1.7799757699710297
Validation loss: 2.5886793321380877

Epoch: 5| Step: 9
Training loss: 2.624551098905137
Validation loss: 2.5711945527206708

Epoch: 5| Step: 10
Training loss: 2.911628422463211
Validation loss: 2.580891815666413

Epoch: 201| Step: 0
Training loss: 2.718057653908972
Validation loss: 2.5774136782274915

Epoch: 5| Step: 1
Training loss: 1.9629074475530683
Validation loss: 2.592074677863867

Epoch: 5| Step: 2
Training loss: 2.3698140796537697
Validation loss: 2.5814771768417244

Epoch: 5| Step: 3
Training loss: 3.000255097033889
Validation loss: 2.5604187271503838

Epoch: 5| Step: 4
Training loss: 2.714203903212976
Validation loss: 2.570155978568242

Epoch: 5| Step: 5
Training loss: 2.141945647339924
Validation loss: 2.604178087435054

Epoch: 5| Step: 6
Training loss: 2.500967506115241
Validation loss: 2.577884157428222

Epoch: 5| Step: 7
Training loss: 2.2715669782581025
Validation loss: 2.5659704660780625

Epoch: 5| Step: 8
Training loss: 2.7672167146972524
Validation loss: 2.5744933995269634

Epoch: 5| Step: 9
Training loss: 2.9586082294956944
Validation loss: 2.564152420665942

Epoch: 5| Step: 10
Training loss: 1.7395384624732233
Validation loss: 2.557136385737226

Epoch: 202| Step: 0
Training loss: 2.8804554801616633
Validation loss: 2.6034254381837196

Epoch: 5| Step: 1
Training loss: 2.1938378210503164
Validation loss: 2.580396115892027

Epoch: 5| Step: 2
Training loss: 3.1615512253983598
Validation loss: 2.5932667758141554

Epoch: 5| Step: 3
Training loss: 2.1815595347088292
Validation loss: 2.625738716778697

Epoch: 5| Step: 4
Training loss: 2.333709266441966
Validation loss: 2.5912153004159397

Epoch: 5| Step: 5
Training loss: 2.3487892400154706
Validation loss: 2.594577817817651

Epoch: 5| Step: 6
Training loss: 2.8685440887153555
Validation loss: 2.585048138814532

Epoch: 5| Step: 7
Training loss: 2.080669709375844
Validation loss: 2.569361025642228

Epoch: 5| Step: 8
Training loss: 2.082369034439684
Validation loss: 2.607402094726455

Epoch: 5| Step: 9
Training loss: 2.2444139651105917
Validation loss: 2.6047935850206594

Epoch: 5| Step: 10
Training loss: 2.6268769774337613
Validation loss: 2.5882631095341972

Epoch: 203| Step: 0
Training loss: 2.193985942096583
Validation loss: 2.564304631761093

Epoch: 5| Step: 1
Training loss: 1.8989121585434798
Validation loss: 2.6052358041389634

Epoch: 5| Step: 2
Training loss: 2.612702218584354
Validation loss: 2.5949892665702627

Epoch: 5| Step: 3
Training loss: 2.8129961212001278
Validation loss: 2.5806102101717654

Epoch: 5| Step: 4
Training loss: 3.344074839562173
Validation loss: 2.587313320834235

Epoch: 5| Step: 5
Training loss: 2.02042839738657
Validation loss: 2.5847487949879335

Epoch: 5| Step: 6
Training loss: 2.1447680399925617
Validation loss: 2.5616484246746096

Epoch: 5| Step: 7
Training loss: 2.1092413965935726
Validation loss: 2.585310149523196

Epoch: 5| Step: 8
Training loss: 3.352598514802009
Validation loss: 2.6043000509906626

Epoch: 5| Step: 9
Training loss: 2.233355202733853
Validation loss: 2.60860737913855

Epoch: 5| Step: 10
Training loss: 2.184916032797035
Validation loss: 2.5412050578109264

Epoch: 204| Step: 0
Training loss: 2.6387979179451597
Validation loss: 2.5884264356665074

Epoch: 5| Step: 1
Training loss: 1.8470801328285256
Validation loss: 2.557996697093167

Epoch: 5| Step: 2
Training loss: 3.0943957338850088
Validation loss: 2.5401898966832834

Epoch: 5| Step: 3
Training loss: 2.6745879025194186
Validation loss: 2.5806244558354843

Epoch: 5| Step: 4
Training loss: 2.4939526850809264
Validation loss: 2.5379889650319822

Epoch: 5| Step: 5
Training loss: 2.4592637925167935
Validation loss: 2.5547549857958995

Epoch: 5| Step: 6
Training loss: 2.39616649356815
Validation loss: 2.540525191847961

Epoch: 5| Step: 7
Training loss: 1.8307360399821706
Validation loss: 2.5492811273881713

Epoch: 5| Step: 8
Training loss: 2.6045716441291944
Validation loss: 2.575822492994098

Epoch: 5| Step: 9
Training loss: 2.471187595318515
Validation loss: 2.5735179897077973

Epoch: 5| Step: 10
Training loss: 2.4265854833807725
Validation loss: 2.572335353460642

Epoch: 205| Step: 0
Training loss: 2.808454698454993
Validation loss: 2.5683909486897734

Epoch: 5| Step: 1
Training loss: 2.5832737228735203
Validation loss: 2.552832042638013

Epoch: 5| Step: 2
Training loss: 2.3250914401869687
Validation loss: 2.5987182025542195

Epoch: 5| Step: 3
Training loss: 2.794608876358205
Validation loss: 2.5565889674287563

Epoch: 5| Step: 4
Training loss: 2.260683023490143
Validation loss: 2.5876522433169833

Epoch: 5| Step: 5
Training loss: 1.965892959063479
Validation loss: 2.5764249375240116

Epoch: 5| Step: 6
Training loss: 3.1391411307679995
Validation loss: 2.5552042114657456

Epoch: 5| Step: 7
Training loss: 2.4903665903932937
Validation loss: 2.5918481720953026

Epoch: 5| Step: 8
Training loss: 2.5686553900529163
Validation loss: 2.557714003146829

Epoch: 5| Step: 9
Training loss: 2.1827657422878817
Validation loss: 2.5408279074554705

Epoch: 5| Step: 10
Training loss: 1.987249680116325
Validation loss: 2.5736027387804734

Epoch: 206| Step: 0
Training loss: 2.1776519349236034
Validation loss: 2.556113557663991

Epoch: 5| Step: 1
Training loss: 2.4445640710496916
Validation loss: 2.5945872223100426

Epoch: 5| Step: 2
Training loss: 2.593533058745664
Validation loss: 2.5730380718444943

Epoch: 5| Step: 3
Training loss: 2.3589224476083497
Validation loss: 2.5906061966117164

Epoch: 5| Step: 4
Training loss: 2.052021341952756
Validation loss: 2.584374150312016

Epoch: 5| Step: 5
Training loss: 1.9001343604314567
Validation loss: 2.6147637551148017

Epoch: 5| Step: 6
Training loss: 2.21156426162725
Validation loss: 2.5370845671420588

Epoch: 5| Step: 7
Training loss: 3.327032491971895
Validation loss: 2.5754546435431016

Epoch: 5| Step: 8
Training loss: 2.445416043072888
Validation loss: 2.583855734596865

Epoch: 5| Step: 9
Training loss: 3.07853471381953
Validation loss: 2.5878121312860762

Epoch: 5| Step: 10
Training loss: 2.4911511218502485
Validation loss: 2.5923639244333887

Epoch: 207| Step: 0
Training loss: 2.4719060690912995
Validation loss: 2.5640551592374625

Epoch: 5| Step: 1
Training loss: 2.3382012360887114
Validation loss: 2.5580959997880393

Epoch: 5| Step: 2
Training loss: 2.9205547756811385
Validation loss: 2.5269026700981727

Epoch: 5| Step: 3
Training loss: 2.290362304778897
Validation loss: 2.582822231763756

Epoch: 5| Step: 4
Training loss: 2.741189019550779
Validation loss: 2.580865724108236

Epoch: 5| Step: 5
Training loss: 2.324093496329568
Validation loss: 2.6034685743955985

Epoch: 5| Step: 6
Training loss: 2.5231978831183746
Validation loss: 2.5743163061070233

Epoch: 5| Step: 7
Training loss: 2.4766458683843466
Validation loss: 2.5814108335669257

Epoch: 5| Step: 8
Training loss: 2.6362699451659726
Validation loss: 2.605500388592531

Epoch: 5| Step: 9
Training loss: 2.078425450224841
Validation loss: 2.57486970239104

Epoch: 5| Step: 10
Training loss: 2.3174290063677123
Validation loss: 2.5873890098041477

Epoch: 208| Step: 0
Training loss: 2.044926538616936
Validation loss: 2.555291781144271

Epoch: 5| Step: 1
Training loss: 2.6301246755659693
Validation loss: 2.57990255371176

Epoch: 5| Step: 2
Training loss: 2.520210020910859
Validation loss: 2.562077388134719

Epoch: 5| Step: 3
Training loss: 2.437170250913895
Validation loss: 2.5742359171074654

Epoch: 5| Step: 4
Training loss: 2.543932847708186
Validation loss: 2.5687708046915985

Epoch: 5| Step: 5
Training loss: 2.6172472591125264
Validation loss: 2.5904967326672685

Epoch: 5| Step: 6
Training loss: 2.7332679469343595
Validation loss: 2.5964019883221034

Epoch: 5| Step: 7
Training loss: 2.4595151635912518
Validation loss: 2.5852972287055676

Epoch: 5| Step: 8
Training loss: 2.396285691609873
Validation loss: 2.5608315817704277

Epoch: 5| Step: 9
Training loss: 2.296937798919621
Validation loss: 2.589157614213207

Epoch: 5| Step: 10
Training loss: 2.513585845731855
Validation loss: 2.582566746616717

Epoch: 209| Step: 0
Training loss: 2.3480315709761617
Validation loss: 2.5719814433362638

Epoch: 5| Step: 1
Training loss: 2.6805343846707776
Validation loss: 2.5799357489299224

Epoch: 5| Step: 2
Training loss: 2.5587035177432
Validation loss: 2.575825592265169

Epoch: 5| Step: 3
Training loss: 2.106567549043724
Validation loss: 2.6079403550917695

Epoch: 5| Step: 4
Training loss: 2.30510591491176
Validation loss: 2.598801398852922

Epoch: 5| Step: 5
Training loss: 2.1318962169028715
Validation loss: 2.5743405106985056

Epoch: 5| Step: 6
Training loss: 2.3170803176466053
Validation loss: 2.5577581207584505

Epoch: 5| Step: 7
Training loss: 2.4955824923889733
Validation loss: 2.5775589019066047

Epoch: 5| Step: 8
Training loss: 2.2454041060818817
Validation loss: 2.534371018100924

Epoch: 5| Step: 9
Training loss: 2.7524935081467743
Validation loss: 2.5779430704321595

Epoch: 5| Step: 10
Training loss: 3.186502936505075
Validation loss: 2.5751083310615814

Epoch: 210| Step: 0
Training loss: 1.8818118653591398
Validation loss: 2.572130729287634

Epoch: 5| Step: 1
Training loss: 2.9481931810580044
Validation loss: 2.5513791684709886

Epoch: 5| Step: 2
Training loss: 2.4258655773008737
Validation loss: 2.5475512050490976

Epoch: 5| Step: 3
Training loss: 2.520433273306967
Validation loss: 2.5537223075140343

Epoch: 5| Step: 4
Training loss: 2.5681634980558736
Validation loss: 2.5566305665156164

Epoch: 5| Step: 5
Training loss: 2.223837379424249
Validation loss: 2.6034614874858706

Epoch: 5| Step: 6
Training loss: 2.183431383896644
Validation loss: 2.573388825107342

Epoch: 5| Step: 7
Training loss: 2.633142648706116
Validation loss: 2.542965742749306

Epoch: 5| Step: 8
Training loss: 2.559501382131738
Validation loss: 2.5563007604731705

Epoch: 5| Step: 9
Training loss: 2.7299289852030415
Validation loss: 2.600428121470933

Epoch: 5| Step: 10
Training loss: 2.439662170005032
Validation loss: 2.5743674112823167

Epoch: 211| Step: 0
Training loss: 3.2036129463520058
Validation loss: 2.5487761682716825

Epoch: 5| Step: 1
Training loss: 2.3858948829307254
Validation loss: 2.605003630649547

Epoch: 5| Step: 2
Training loss: 2.8172250686992544
Validation loss: 2.569226943321015

Epoch: 5| Step: 3
Training loss: 2.5076766408086146
Validation loss: 2.5635163427372984

Epoch: 5| Step: 4
Training loss: 2.001535898786749
Validation loss: 2.551519619376974

Epoch: 5| Step: 5
Training loss: 2.2149235140853714
Validation loss: 2.5549098930285616

Epoch: 5| Step: 6
Training loss: 2.2035091416957227
Validation loss: 2.5690597701495297

Epoch: 5| Step: 7
Training loss: 2.1934632899193076
Validation loss: 2.5628706621219997

Epoch: 5| Step: 8
Training loss: 2.454382701577075
Validation loss: 2.5822795090603456

Epoch: 5| Step: 9
Training loss: 2.4740823065497475
Validation loss: 2.5816051716222637

Epoch: 5| Step: 10
Training loss: 2.5810228187767232
Validation loss: 2.5709936936949838

Epoch: 212| Step: 0
Training loss: 2.946660793120225
Validation loss: 2.586469848708146

Epoch: 5| Step: 1
Training loss: 2.2605146981588153
Validation loss: 2.5971206901246626

Epoch: 5| Step: 2
Training loss: 2.0530165923832846
Validation loss: 2.570485617616948

Epoch: 5| Step: 3
Training loss: 2.8033352197859225
Validation loss: 2.5799486737441293

Epoch: 5| Step: 4
Training loss: 2.626197723347711
Validation loss: 2.5867624018308115

Epoch: 5| Step: 5
Training loss: 2.6754438869784964
Validation loss: 2.5661001539377564

Epoch: 5| Step: 6
Training loss: 2.364692607040809
Validation loss: 2.543533679054193

Epoch: 5| Step: 7
Training loss: 1.73682965307624
Validation loss: 2.5534516239913287

Epoch: 5| Step: 8
Training loss: 2.097943334274232
Validation loss: 2.592679515098655

Epoch: 5| Step: 9
Training loss: 2.9004609892558997
Validation loss: 2.59189542276446

Epoch: 5| Step: 10
Training loss: 2.348116558223249
Validation loss: 2.5813955027883098

Epoch: 213| Step: 0
Training loss: 2.388468548908433
Validation loss: 2.6080417991313083

Epoch: 5| Step: 1
Training loss: 2.658860035042011
Validation loss: 2.5526213275802685

Epoch: 5| Step: 2
Training loss: 2.3905317500259393
Validation loss: 2.577677035823687

Epoch: 5| Step: 3
Training loss: 2.5658104145364105
Validation loss: 2.5896650463119544

Epoch: 5| Step: 4
Training loss: 2.3610632710814947
Validation loss: 2.551812244220575

Epoch: 5| Step: 5
Training loss: 2.4010778549898495
Validation loss: 2.6069537389725133

Epoch: 5| Step: 6
Training loss: 2.0674289415318947
Validation loss: 2.580199294226559

Epoch: 5| Step: 7
Training loss: 2.7469405581969433
Validation loss: 2.5881655011552223

Epoch: 5| Step: 8
Training loss: 2.8683786854177717
Validation loss: 2.593689878409161

Epoch: 5| Step: 9
Training loss: 1.9275376548997736
Validation loss: 2.5853727178921972

Epoch: 5| Step: 10
Training loss: 2.3982886849127274
Validation loss: 2.592838776169185

Epoch: 214| Step: 0
Training loss: 1.9473775909894355
Validation loss: 2.559008852581011

Epoch: 5| Step: 1
Training loss: 2.396938986589381
Validation loss: 2.573574339978661

Epoch: 5| Step: 2
Training loss: 2.984734638374278
Validation loss: 2.553813668347007

Epoch: 5| Step: 3
Training loss: 2.175067229711732
Validation loss: 2.5624858576686727

Epoch: 5| Step: 4
Training loss: 2.628467721625881
Validation loss: 2.589778279343249

Epoch: 5| Step: 5
Training loss: 2.869450728327602
Validation loss: 2.5808744236413554

Epoch: 5| Step: 6
Training loss: 2.2094586821899256
Validation loss: 2.5559228566559837

Epoch: 5| Step: 7
Training loss: 3.010094032466353
Validation loss: 2.5781019401824135

Epoch: 5| Step: 8
Training loss: 2.37957383483619
Validation loss: 2.560806385037831

Epoch: 5| Step: 9
Training loss: 2.151429579319697
Validation loss: 2.5685604160729243

Epoch: 5| Step: 10
Training loss: 2.035362540715943
Validation loss: 2.573468325077706

Epoch: 215| Step: 0
Training loss: 1.5832699294529307
Validation loss: 2.5569830992491673

Epoch: 5| Step: 1
Training loss: 2.137063732576716
Validation loss: 2.562204882707621

Epoch: 5| Step: 2
Training loss: 2.459986233401352
Validation loss: 2.566635762132348

Epoch: 5| Step: 3
Training loss: 2.967356625879978
Validation loss: 2.5700940252703472

Epoch: 5| Step: 4
Training loss: 3.0119774456218242
Validation loss: 2.5684101510367547

Epoch: 5| Step: 5
Training loss: 2.550475121160457
Validation loss: 2.5652492750537776

Epoch: 5| Step: 6
Training loss: 2.476082066286741
Validation loss: 2.5634536539314965

Epoch: 5| Step: 7
Training loss: 2.1835804292275935
Validation loss: 2.5771996680547336

Epoch: 5| Step: 8
Training loss: 2.243510955572956
Validation loss: 2.5892664402130663

Epoch: 5| Step: 9
Training loss: 3.213437037977545
Validation loss: 2.5545972652805617

Epoch: 5| Step: 10
Training loss: 1.6917199951685926
Validation loss: 2.5523560596539117

Epoch: 216| Step: 0
Training loss: 2.6039903097836725
Validation loss: 2.609156044727719

Epoch: 5| Step: 1
Training loss: 1.8990006730016689
Validation loss: 2.590640087903372

Epoch: 5| Step: 2
Training loss: 2.204629262780891
Validation loss: 2.5877053369805556

Epoch: 5| Step: 3
Training loss: 1.7862286508083869
Validation loss: 2.611189862163864

Epoch: 5| Step: 4
Training loss: 3.1331808201892772
Validation loss: 2.550531533242673

Epoch: 5| Step: 5
Training loss: 2.4187851422736255
Validation loss: 2.5969781950889717

Epoch: 5| Step: 6
Training loss: 2.336876313749129
Validation loss: 2.565518135250446

Epoch: 5| Step: 7
Training loss: 2.3632745916099385
Validation loss: 2.565046866071394

Epoch: 5| Step: 8
Training loss: 2.9706318562703595
Validation loss: 2.5782084034206556

Epoch: 5| Step: 9
Training loss: 2.697051087395951
Validation loss: 2.5712246538492165

Epoch: 5| Step: 10
Training loss: 2.1168010964345365
Validation loss: 2.56259316375836

Epoch: 217| Step: 0
Training loss: 2.7465585502468506
Validation loss: 2.575003229050205

Epoch: 5| Step: 1
Training loss: 2.611988061272996
Validation loss: 2.597628224699949

Epoch: 5| Step: 2
Training loss: 2.9921814442864636
Validation loss: 2.5703858151492818

Epoch: 5| Step: 3
Training loss: 2.5563068448860324
Validation loss: 2.55467866613381

Epoch: 5| Step: 4
Training loss: 2.297501459131618
Validation loss: 2.5626231188226214

Epoch: 5| Step: 5
Training loss: 2.29638448654673
Validation loss: 2.554298096491708

Epoch: 5| Step: 6
Training loss: 1.770341228847941
Validation loss: 2.589755023344714

Epoch: 5| Step: 7
Training loss: 2.0403701272551187
Validation loss: 2.5185576801286804

Epoch: 5| Step: 8
Training loss: 2.2008433329499364
Validation loss: 2.5577163766327624

Epoch: 5| Step: 9
Training loss: 2.4822502407043507
Validation loss: 2.5854355048756035

Epoch: 5| Step: 10
Training loss: 2.6862529256528718
Validation loss: 2.5949492397129648

Epoch: 218| Step: 0
Training loss: 1.762522850159045
Validation loss: 2.577327800165084

Epoch: 5| Step: 1
Training loss: 2.2693318527267654
Validation loss: 2.533523163769625

Epoch: 5| Step: 2
Training loss: 3.095512273543224
Validation loss: 2.5628266385217944

Epoch: 5| Step: 3
Training loss: 1.8827902131720375
Validation loss: 2.582260657053986

Epoch: 5| Step: 4
Training loss: 1.839021859574784
Validation loss: 2.583929937410858

Epoch: 5| Step: 5
Training loss: 2.4970584730360703
Validation loss: 2.5804306434935063

Epoch: 5| Step: 6
Training loss: 2.611346111364057
Validation loss: 2.5556503798910892

Epoch: 5| Step: 7
Training loss: 2.4906915940555985
Validation loss: 2.5215255329672774

Epoch: 5| Step: 8
Training loss: 2.7070526518533042
Validation loss: 2.544138114462684

Epoch: 5| Step: 9
Training loss: 2.910819286622335
Validation loss: 2.5311567734221536

Epoch: 5| Step: 10
Training loss: 2.284389895535396
Validation loss: 2.553319155080371

Epoch: 219| Step: 0
Training loss: 1.9717380917473573
Validation loss: 2.5428007861229887

Epoch: 5| Step: 1
Training loss: 2.2931889650828245
Validation loss: 2.562753855378804

Epoch: 5| Step: 2
Training loss: 3.2149409004818903
Validation loss: 2.521433387052032

Epoch: 5| Step: 3
Training loss: 2.2338098198000553
Validation loss: 2.574198543297423

Epoch: 5| Step: 4
Training loss: 2.5175117383302537
Validation loss: 2.565193687331441

Epoch: 5| Step: 5
Training loss: 2.265798733068141
Validation loss: 2.570797408168662

Epoch: 5| Step: 6
Training loss: 2.527599763948285
Validation loss: 2.5476732561374322

Epoch: 5| Step: 7
Training loss: 2.235997817787375
Validation loss: 2.5872914893335914

Epoch: 5| Step: 8
Training loss: 2.501935972204083
Validation loss: 2.5856803476453356

Epoch: 5| Step: 9
Training loss: 2.1878353406816955
Validation loss: 2.5730877163837853

Epoch: 5| Step: 10
Training loss: 2.8979062315814454
Validation loss: 2.558425760284729

Epoch: 220| Step: 0
Training loss: 1.979935493381762
Validation loss: 2.5568868835804968

Epoch: 5| Step: 1
Training loss: 2.5826053413997014
Validation loss: 2.603776462649219

Epoch: 5| Step: 2
Training loss: 2.2105305974603358
Validation loss: 2.561364054918499

Epoch: 5| Step: 3
Training loss: 1.870734512789051
Validation loss: 2.6023942201191224

Epoch: 5| Step: 4
Training loss: 2.6414899143168697
Validation loss: 2.5869496452234184

Epoch: 5| Step: 5
Training loss: 2.5479968823843526
Validation loss: 2.5744901139338925

Epoch: 5| Step: 6
Training loss: 2.5039251032222163
Validation loss: 2.5763402703421807

Epoch: 5| Step: 7
Training loss: 2.562470970919796
Validation loss: 2.5644520358449525

Epoch: 5| Step: 8
Training loss: 2.067148691794874
Validation loss: 2.5703208587328046

Epoch: 5| Step: 9
Training loss: 2.7731472669442128
Validation loss: 2.574334635712223

Epoch: 5| Step: 10
Training loss: 3.0476694489608604
Validation loss: 2.5671374908611977

Epoch: 221| Step: 0
Training loss: 2.2833431517489693
Validation loss: 2.5755887122097185

Epoch: 5| Step: 1
Training loss: 2.7601223962706833
Validation loss: 2.6045424727131685

Epoch: 5| Step: 2
Training loss: 2.8515106614509027
Validation loss: 2.567278156131945

Epoch: 5| Step: 3
Training loss: 2.6278753427409915
Validation loss: 2.586653084446006

Epoch: 5| Step: 4
Training loss: 2.2263741396820462
Validation loss: 2.542227562297507

Epoch: 5| Step: 5
Training loss: 2.3526974597399155
Validation loss: 2.5277098086468173

Epoch: 5| Step: 6
Training loss: 2.4581951059392186
Validation loss: 2.591238759976233

Epoch: 5| Step: 7
Training loss: 2.0218879333742787
Validation loss: 2.581253588707056

Epoch: 5| Step: 8
Training loss: 2.343853554027438
Validation loss: 2.578797705010859

Epoch: 5| Step: 9
Training loss: 2.4452711595447183
Validation loss: 2.607173982464185

Epoch: 5| Step: 10
Training loss: 2.4460192746691964
Validation loss: 2.4900987067395035

Epoch: 222| Step: 0
Training loss: 2.3890218907180056
Validation loss: 2.5966153760109996

Epoch: 5| Step: 1
Training loss: 2.6480583887318376
Validation loss: 2.5513051855554822

Epoch: 5| Step: 2
Training loss: 2.771279540500283
Validation loss: 2.5675913226557814

Epoch: 5| Step: 3
Training loss: 1.9020730203917893
Validation loss: 2.567914415146041

Epoch: 5| Step: 4
Training loss: 2.30842168847754
Validation loss: 2.568653883000429

Epoch: 5| Step: 5
Training loss: 2.5365918155041554
Validation loss: 2.515533193875943

Epoch: 5| Step: 6
Training loss: 2.5024338319245127
Validation loss: 2.583033550928295

Epoch: 5| Step: 7
Training loss: 2.644975498136455
Validation loss: 2.559414907050638

Epoch: 5| Step: 8
Training loss: 2.3512330695784387
Validation loss: 2.604004760303207

Epoch: 5| Step: 9
Training loss: 2.3068585014321714
Validation loss: 2.5696500384613037

Epoch: 5| Step: 10
Training loss: 2.2490437912941337
Validation loss: 2.5672685886892284

Epoch: 223| Step: 0
Training loss: 2.6887703488057406
Validation loss: 2.5659925728921262

Epoch: 5| Step: 1
Training loss: 1.9643793182859617
Validation loss: 2.5488330182682426

Epoch: 5| Step: 2
Training loss: 2.6529877320490174
Validation loss: 2.522258473328035

Epoch: 5| Step: 3
Training loss: 2.5392722644721806
Validation loss: 2.6184965770274338

Epoch: 5| Step: 4
Training loss: 2.2067080100682146
Validation loss: 2.561120047621269

Epoch: 5| Step: 5
Training loss: 3.1134272102018214
Validation loss: 2.5400925806439725

Epoch: 5| Step: 6
Training loss: 2.4380619672828323
Validation loss: 2.5861379904260833

Epoch: 5| Step: 7
Training loss: 2.7576637984431933
Validation loss: 2.559243745205432

Epoch: 5| Step: 8
Training loss: 2.0117871319157614
Validation loss: 2.5875892233013738

Epoch: 5| Step: 9
Training loss: 1.7278654265719102
Validation loss: 2.5652465747467508

Epoch: 5| Step: 10
Training loss: 2.0696002238765634
Validation loss: 2.568215266202056

Epoch: 224| Step: 0
Training loss: 2.556979116904295
Validation loss: 2.568159195642728

Epoch: 5| Step: 1
Training loss: 2.114181016756264
Validation loss: 2.5588459085082285

Epoch: 5| Step: 2
Training loss: 2.3089217261209867
Validation loss: 2.5906496749180397

Epoch: 5| Step: 3
Training loss: 2.589478249743758
Validation loss: 2.55343639943719

Epoch: 5| Step: 4
Training loss: 2.4167149856823174
Validation loss: 2.5579196382875646

Epoch: 5| Step: 5
Training loss: 2.4815467714647825
Validation loss: 2.5711929030809

Epoch: 5| Step: 6
Training loss: 2.6369982309924986
Validation loss: 2.542766790547358

Epoch: 5| Step: 7
Training loss: 2.258498566085499
Validation loss: 2.5529484809104046

Epoch: 5| Step: 8
Training loss: 2.322799223481225
Validation loss: 2.5574548389103953

Epoch: 5| Step: 9
Training loss: 2.173331780676882
Validation loss: 2.552970647263599

Epoch: 5| Step: 10
Training loss: 2.8935110170620355
Validation loss: 2.569687303837082

Epoch: 225| Step: 0
Training loss: 2.241989180138076
Validation loss: 2.5697284913602774

Epoch: 5| Step: 1
Training loss: 2.443234081394834
Validation loss: 2.567166678882015

Epoch: 5| Step: 2
Training loss: 2.4545648321998774
Validation loss: 2.557972590408173

Epoch: 5| Step: 3
Training loss: 2.362414997327605
Validation loss: 2.5738150768579815

Epoch: 5| Step: 4
Training loss: 2.8342337206167483
Validation loss: 2.547407402509973

Epoch: 5| Step: 5
Training loss: 2.2140141839225214
Validation loss: 2.562441725409678

Epoch: 5| Step: 6
Training loss: 2.677732238100898
Validation loss: 2.564835717197203

Epoch: 5| Step: 7
Training loss: 2.633900946594645
Validation loss: 2.6010249255421134

Epoch: 5| Step: 8
Training loss: 2.4339554274528425
Validation loss: 2.5993445262364285

Epoch: 5| Step: 9
Training loss: 2.2591826297651476
Validation loss: 2.546903351254083

Epoch: 5| Step: 10
Training loss: 2.2013750634091878
Validation loss: 2.581218096304447

Epoch: 226| Step: 0
Training loss: 2.2483764724985362
Validation loss: 2.5859416618000157

Epoch: 5| Step: 1
Training loss: 2.325558880319946
Validation loss: 2.5973474082574053

Epoch: 5| Step: 2
Training loss: 2.6415235807574677
Validation loss: 2.5870581820921728

Epoch: 5| Step: 3
Training loss: 1.9064819319914594
Validation loss: 2.534340344712985

Epoch: 5| Step: 4
Training loss: 2.4738943847957664
Validation loss: 2.57993797974933

Epoch: 5| Step: 5
Training loss: 2.359112453379022
Validation loss: 2.599783421165797

Epoch: 5| Step: 6
Training loss: 2.500852534843167
Validation loss: 2.596381056726325

Epoch: 5| Step: 7
Training loss: 3.3081355582695227
Validation loss: 2.5919310933778923

Epoch: 5| Step: 8
Training loss: 1.924717731340602
Validation loss: 2.5570584227507367

Epoch: 5| Step: 9
Training loss: 2.516177193829133
Validation loss: 2.548145694138899

Epoch: 5| Step: 10
Training loss: 2.4035129586162682
Validation loss: 2.564334340894129

Epoch: 227| Step: 0
Training loss: 2.145530592910753
Validation loss: 2.550306649442405

Epoch: 5| Step: 1
Training loss: 2.2078164653378005
Validation loss: 2.55483077084884

Epoch: 5| Step: 2
Training loss: 2.6106562409873035
Validation loss: 2.5357895442556377

Epoch: 5| Step: 3
Training loss: 2.624190887003437
Validation loss: 2.580120655948291

Epoch: 5| Step: 4
Training loss: 3.14607441633113
Validation loss: 2.5661739520747355

Epoch: 5| Step: 5
Training loss: 1.8712087448556725
Validation loss: 2.5688167203972805

Epoch: 5| Step: 6
Training loss: 1.9150510765216278
Validation loss: 2.545290453730676

Epoch: 5| Step: 7
Training loss: 2.8093370241986717
Validation loss: 2.5324088436373255

Epoch: 5| Step: 8
Training loss: 2.5113714995549454
Validation loss: 2.5608369726717233

Epoch: 5| Step: 9
Training loss: 2.195693013619753
Validation loss: 2.5756494643490937

Epoch: 5| Step: 10
Training loss: 2.2230046272452757
Validation loss: 2.5512032440173464

Epoch: 228| Step: 0
Training loss: 2.2680403889620515
Validation loss: 2.552673016232754

Epoch: 5| Step: 1
Training loss: 2.887360415036682
Validation loss: 2.5566842096371847

Epoch: 5| Step: 2
Training loss: 2.2383807361589145
Validation loss: 2.5537305734804505

Epoch: 5| Step: 3
Training loss: 2.7626719252997813
Validation loss: 2.583711813420023

Epoch: 5| Step: 4
Training loss: 2.4146394009426073
Validation loss: 2.5651905352390387

Epoch: 5| Step: 5
Training loss: 2.080566463546555
Validation loss: 2.596554776257041

Epoch: 5| Step: 6
Training loss: 2.154053606009153
Validation loss: 2.523921595909022

Epoch: 5| Step: 7
Training loss: 2.415162758565167
Validation loss: 2.5619972290023822

Epoch: 5| Step: 8
Training loss: 2.3361295793337296
Validation loss: 2.516130636439247

Epoch: 5| Step: 9
Training loss: 3.0221135200168527
Validation loss: 2.5814293253223024

Epoch: 5| Step: 10
Training loss: 1.908130656089359
Validation loss: 2.530858831895265

Epoch: 229| Step: 0
Training loss: 2.121818292278582
Validation loss: 2.5821938772140003

Epoch: 5| Step: 1
Training loss: 2.1990736918607086
Validation loss: 2.5426510223176777

Epoch: 5| Step: 2
Training loss: 2.196539593592217
Validation loss: 2.578795386716315

Epoch: 5| Step: 3
Training loss: 2.76501803014578
Validation loss: 2.616968521461251

Epoch: 5| Step: 4
Training loss: 2.268358462678211
Validation loss: 2.539629518917935

Epoch: 5| Step: 5
Training loss: 2.283456231960939
Validation loss: 2.5618772562873615

Epoch: 5| Step: 6
Training loss: 2.893575286534424
Validation loss: 2.5509520098553473

Epoch: 5| Step: 7
Training loss: 2.3754992713164325
Validation loss: 2.5708303888860864

Epoch: 5| Step: 8
Training loss: 2.2806598474794053
Validation loss: 2.5774041056379215

Epoch: 5| Step: 9
Training loss: 2.329111798981698
Validation loss: 2.557232131868171

Epoch: 5| Step: 10
Training loss: 2.6861970981307577
Validation loss: 2.547568922180746

Epoch: 230| Step: 0
Training loss: 1.6264493054552738
Validation loss: 2.570821273434248

Epoch: 5| Step: 1
Training loss: 1.849465127897215
Validation loss: 2.5740867472722786

Epoch: 5| Step: 2
Training loss: 2.5514137687247596
Validation loss: 2.5485874330019906

Epoch: 5| Step: 3
Training loss: 2.428898134214941
Validation loss: 2.5664397586324323

Epoch: 5| Step: 4
Training loss: 2.799016888915391
Validation loss: 2.582932203577185

Epoch: 5| Step: 5
Training loss: 2.846438300496808
Validation loss: 2.523582910205982

Epoch: 5| Step: 6
Training loss: 2.0304323164521185
Validation loss: 2.574474696136559

Epoch: 5| Step: 7
Training loss: 3.2905429579894596
Validation loss: 2.551453388378098

Epoch: 5| Step: 8
Training loss: 2.4022685217515014
Validation loss: 2.552557643053778

Epoch: 5| Step: 9
Training loss: 1.944616844466654
Validation loss: 2.5925074819806775

Epoch: 5| Step: 10
Training loss: 2.159376448590777
Validation loss: 2.5818848182653844

Epoch: 231| Step: 0
Training loss: 1.6700829143841838
Validation loss: 2.5211084660290304

Epoch: 5| Step: 1
Training loss: 2.7472851964480425
Validation loss: 2.5790382276803263

Epoch: 5| Step: 2
Training loss: 1.9887205586630865
Validation loss: 2.565243462694342

Epoch: 5| Step: 3
Training loss: 2.3284328180393263
Validation loss: 2.5106313704943837

Epoch: 5| Step: 4
Training loss: 2.2137711230260555
Validation loss: 2.5914201414504427

Epoch: 5| Step: 5
Training loss: 2.220322709727857
Validation loss: 2.5730397696204617

Epoch: 5| Step: 6
Training loss: 3.0660194881986906
Validation loss: 2.5769678198105783

Epoch: 5| Step: 7
Training loss: 2.879812111023878
Validation loss: 2.5122151659411243

Epoch: 5| Step: 8
Training loss: 2.5887002160826458
Validation loss: 2.5270444093585316

Epoch: 5| Step: 9
Training loss: 1.8700293458074149
Validation loss: 2.5524592558234795

Epoch: 5| Step: 10
Training loss: 2.7576140853785494
Validation loss: 2.56916799210103

Epoch: 232| Step: 0
Training loss: 2.389131865108783
Validation loss: 2.5448520935316834

Epoch: 5| Step: 1
Training loss: 1.975399172558659
Validation loss: 2.5515283004066016

Epoch: 5| Step: 2
Training loss: 2.481369695971303
Validation loss: 2.5463480698422436

Epoch: 5| Step: 3
Training loss: 2.681618131250116
Validation loss: 2.5706807711245

Epoch: 5| Step: 4
Training loss: 3.0111982833456077
Validation loss: 2.5905605899183994

Epoch: 5| Step: 5
Training loss: 2.1948487141465405
Validation loss: 2.5840013780163824

Epoch: 5| Step: 6
Training loss: 2.639093711221272
Validation loss: 2.5643088076761082

Epoch: 5| Step: 7
Training loss: 2.2382039161624006
Validation loss: 2.5895453065358724

Epoch: 5| Step: 8
Training loss: 2.231620958623195
Validation loss: 2.5789295749616183

Epoch: 5| Step: 9
Training loss: 2.168161084690494
Validation loss: 2.5823982668844288

Epoch: 5| Step: 10
Training loss: 2.2401680707889042
Validation loss: 2.5425284568926876

Epoch: 233| Step: 0
Training loss: 2.1929354032856048
Validation loss: 2.5531808916893217

Epoch: 5| Step: 1
Training loss: 2.355776638576293
Validation loss: 2.5297826557268315

Epoch: 5| Step: 2
Training loss: 2.4232669890853185
Validation loss: 2.5416972958517805

Epoch: 5| Step: 3
Training loss: 1.9051372219334655
Validation loss: 2.5991111725390916

Epoch: 5| Step: 4
Training loss: 2.0244691788806746
Validation loss: 2.5849250149948184

Epoch: 5| Step: 5
Training loss: 2.553005306281714
Validation loss: 2.5653338705758206

Epoch: 5| Step: 6
Training loss: 2.046009026135534
Validation loss: 2.616369544187189

Epoch: 5| Step: 7
Training loss: 2.5004693544398173
Validation loss: 2.5516249331423855

Epoch: 5| Step: 8
Training loss: 2.6007960568044077
Validation loss: 2.536908788269447

Epoch: 5| Step: 9
Training loss: 3.151862541444911
Validation loss: 2.5699520577109154

Epoch: 5| Step: 10
Training loss: 2.1831803314335043
Validation loss: 2.586082023951743

Epoch: 234| Step: 0
Training loss: 1.8849924850314066
Validation loss: 2.5889003885821125

Epoch: 5| Step: 1
Training loss: 2.5799055944218483
Validation loss: 2.5662997691584866

Epoch: 5| Step: 2
Training loss: 3.027826952364814
Validation loss: 2.5914595377510197

Epoch: 5| Step: 3
Training loss: 2.384564665404076
Validation loss: 2.569782896587352

Epoch: 5| Step: 4
Training loss: 2.340731597225065
Validation loss: 2.5518168343950896

Epoch: 5| Step: 5
Training loss: 2.4518251316076083
Validation loss: 2.527935434994892

Epoch: 5| Step: 6
Training loss: 1.985934748373819
Validation loss: 2.5520721130593222

Epoch: 5| Step: 7
Training loss: 2.4035337896604556
Validation loss: 2.536431749661957

Epoch: 5| Step: 8
Training loss: 2.3518838757893117
Validation loss: 2.5528979406242733

Epoch: 5| Step: 9
Training loss: 2.2479675438054993
Validation loss: 2.5169599483073672

Epoch: 5| Step: 10
Training loss: 2.3225265882466863
Validation loss: 2.5785761592877483

Epoch: 235| Step: 0
Training loss: 2.400892461304398
Validation loss: 2.5848647744285507

Epoch: 5| Step: 1
Training loss: 1.9556476628522537
Validation loss: 2.543432041886347

Epoch: 5| Step: 2
Training loss: 1.9598433036837146
Validation loss: 2.5782163641717006

Epoch: 5| Step: 3
Training loss: 2.78561761359968
Validation loss: 2.551385311846371

Epoch: 5| Step: 4
Training loss: 2.557648042810968
Validation loss: 2.5527724125374087

Epoch: 5| Step: 5
Training loss: 2.8122155787446714
Validation loss: 2.5235994048877273

Epoch: 5| Step: 6
Training loss: 2.4483406403157484
Validation loss: 2.572736776585577

Epoch: 5| Step: 7
Training loss: 2.318363282892136
Validation loss: 2.5848607685893854

Epoch: 5| Step: 8
Training loss: 2.6288960925695304
Validation loss: 2.5367838787576154

Epoch: 5| Step: 9
Training loss: 2.288174297402934
Validation loss: 2.592258960313213

Epoch: 5| Step: 10
Training loss: 2.1997867480873112
Validation loss: 2.5842832399402655

Epoch: 236| Step: 0
Training loss: 2.3365278741899176
Validation loss: 2.5479917022692122

Epoch: 5| Step: 1
Training loss: 2.2631879656275196
Validation loss: 2.580202646571436

Epoch: 5| Step: 2
Training loss: 1.5627445792465893
Validation loss: 2.5477648072194863

Epoch: 5| Step: 3
Training loss: 2.0095587235579195
Validation loss: 2.5291977572550226

Epoch: 5| Step: 4
Training loss: 2.570179480731139
Validation loss: 2.5535609240668933

Epoch: 5| Step: 5
Training loss: 2.9111295365421017
Validation loss: 2.5763678356423774

Epoch: 5| Step: 6
Training loss: 3.018691801217021
Validation loss: 2.543609292988699

Epoch: 5| Step: 7
Training loss: 2.666801320093657
Validation loss: 2.5635841896289273

Epoch: 5| Step: 8
Training loss: 2.0675613261379477
Validation loss: 2.5193048750522835

Epoch: 5| Step: 9
Training loss: 2.1714329990184074
Validation loss: 2.565373168319226

Epoch: 5| Step: 10
Training loss: 2.2764551644035405
Validation loss: 2.5450339670040214

Epoch: 237| Step: 0
Training loss: 2.356434688868251
Validation loss: 2.5551212200143048

Epoch: 5| Step: 1
Training loss: 2.443561938920481
Validation loss: 2.5953612528711374

Epoch: 5| Step: 2
Training loss: 2.039517289814347
Validation loss: 2.5669425518502025

Epoch: 5| Step: 3
Training loss: 2.018088203347534
Validation loss: 2.542121024213436

Epoch: 5| Step: 4
Training loss: 2.986738617092814
Validation loss: 2.519052625217892

Epoch: 5| Step: 5
Training loss: 2.666176860251469
Validation loss: 2.5585141761126993

Epoch: 5| Step: 6
Training loss: 1.9946945273018435
Validation loss: 2.545351874637175

Epoch: 5| Step: 7
Training loss: 1.8500393425134656
Validation loss: 2.5612312835759163

Epoch: 5| Step: 8
Training loss: 2.3608100013464184
Validation loss: 2.5900224136432395

Epoch: 5| Step: 9
Training loss: 3.1223905731402906
Validation loss: 2.535341148725699

Epoch: 5| Step: 10
Training loss: 2.0226622757098105
Validation loss: 2.541369697863738

Epoch: 238| Step: 0
Training loss: 2.995771288770894
Validation loss: 2.561105127908698

Epoch: 5| Step: 1
Training loss: 1.9863476297476792
Validation loss: 2.5354046590156725

Epoch: 5| Step: 2
Training loss: 2.0639539275682757
Validation loss: 2.528094669798295

Epoch: 5| Step: 3
Training loss: 2.1719329606699493
Validation loss: 2.551307576056724

Epoch: 5| Step: 4
Training loss: 2.5706600429632926
Validation loss: 2.55984584315682

Epoch: 5| Step: 5
Training loss: 2.45332821532766
Validation loss: 2.5401682929737044

Epoch: 5| Step: 6
Training loss: 2.306683313037732
Validation loss: 2.5580284357704315

Epoch: 5| Step: 7
Training loss: 2.8654701848366853
Validation loss: 2.5607390742382607

Epoch: 5| Step: 8
Training loss: 2.1513978849446893
Validation loss: 2.601312625021156

Epoch: 5| Step: 9
Training loss: 2.0731063704851103
Validation loss: 2.5624312354825056

Epoch: 5| Step: 10
Training loss: 2.2966340645781624
Validation loss: 2.588605973570722

Epoch: 239| Step: 0
Training loss: 2.205161269641786
Validation loss: 2.5427388176318164

Epoch: 5| Step: 1
Training loss: 2.110837302381798
Validation loss: 2.539862759342943

Epoch: 5| Step: 2
Training loss: 2.4880039413887034
Validation loss: 2.5633718456594417

Epoch: 5| Step: 3
Training loss: 2.110449510213962
Validation loss: 2.5883755887605124

Epoch: 5| Step: 4
Training loss: 1.9926814644958468
Validation loss: 2.555237593100636

Epoch: 5| Step: 5
Training loss: 2.3100583357277653
Validation loss: 2.5168881010519977

Epoch: 5| Step: 6
Training loss: 3.1956900301307005
Validation loss: 2.5656039899365704

Epoch: 5| Step: 7
Training loss: 2.6253393044753373
Validation loss: 2.5272048151489543

Epoch: 5| Step: 8
Training loss: 2.346208529057575
Validation loss: 2.543131239079287

Epoch: 5| Step: 9
Training loss: 2.32568302991477
Validation loss: 2.5487496433379415

Epoch: 5| Step: 10
Training loss: 1.9334209326377536
Validation loss: 2.5494538630990267

Epoch: 240| Step: 0
Training loss: 2.628748079844312
Validation loss: 2.558641418398743

Epoch: 5| Step: 1
Training loss: 1.8472011400834667
Validation loss: 2.6002619895322523

Epoch: 5| Step: 2
Training loss: 2.523583658904533
Validation loss: 2.550852554677196

Epoch: 5| Step: 3
Training loss: 2.470089126708645
Validation loss: 2.5534763461285426

Epoch: 5| Step: 4
Training loss: 1.8470312113786505
Validation loss: 2.5560087548112613

Epoch: 5| Step: 5
Training loss: 2.83289604926477
Validation loss: 2.5577947555586897

Epoch: 5| Step: 6
Training loss: 2.501681906467131
Validation loss: 2.540985057045041

Epoch: 5| Step: 7
Training loss: 2.275445948898242
Validation loss: 2.6107299010484897

Epoch: 5| Step: 8
Training loss: 1.758063675631017
Validation loss: 2.582786701362064

Epoch: 5| Step: 9
Training loss: 2.3994779535589568
Validation loss: 2.5501565925762795

Epoch: 5| Step: 10
Training loss: 2.58023050047421
Validation loss: 2.5770540779432105

Epoch: 241| Step: 0
Training loss: 2.529962094290617
Validation loss: 2.5510670647325586

Epoch: 5| Step: 1
Training loss: 2.226952448377923
Validation loss: 2.565503894640102

Epoch: 5| Step: 2
Training loss: 2.444281607560161
Validation loss: 2.5442340595555515

Epoch: 5| Step: 3
Training loss: 2.3670801320921955
Validation loss: 2.520987760620107

Epoch: 5| Step: 4
Training loss: 2.547411154263714
Validation loss: 2.5703876253857403

Epoch: 5| Step: 5
Training loss: 2.0902491666483964
Validation loss: 2.5757764503651033

Epoch: 5| Step: 6
Training loss: 2.0725355197269324
Validation loss: 2.5279648971610147

Epoch: 5| Step: 7
Training loss: 2.876126939245606
Validation loss: 2.5684751552757334

Epoch: 5| Step: 8
Training loss: 2.404333168580151
Validation loss: 2.5550448390494744

Epoch: 5| Step: 9
Training loss: 2.1535854738595805
Validation loss: 2.5405004158316356

Epoch: 5| Step: 10
Training loss: 2.302422603503382
Validation loss: 2.555674098707251

Epoch: 242| Step: 0
Training loss: 2.2490464415141913
Validation loss: 2.5314420715567656

Epoch: 5| Step: 1
Training loss: 2.7136165342540215
Validation loss: 2.5398507670862016

Epoch: 5| Step: 2
Training loss: 1.632475822818829
Validation loss: 2.530967456600579

Epoch: 5| Step: 3
Training loss: 2.1568162699739437
Validation loss: 2.5448986472946165

Epoch: 5| Step: 4
Training loss: 2.3799932091880533
Validation loss: 2.5621827652254394

Epoch: 5| Step: 5
Training loss: 2.5081108129743175
Validation loss: 2.5806133305152934

Epoch: 5| Step: 6
Training loss: 2.5483807752179595
Validation loss: 2.5537167218980676

Epoch: 5| Step: 7
Training loss: 2.779745831019592
Validation loss: 2.555505379860006

Epoch: 5| Step: 8
Training loss: 2.5089376902256975
Validation loss: 2.5587851441416913

Epoch: 5| Step: 9
Training loss: 2.128917225100724
Validation loss: 2.5813111347035362

Epoch: 5| Step: 10
Training loss: 2.0453300178074896
Validation loss: 2.5398856778102608

Epoch: 243| Step: 0
Training loss: 2.7059699285828236
Validation loss: 2.5433603154800752

Epoch: 5| Step: 1
Training loss: 2.114524602465905
Validation loss: 2.5845908138838096

Epoch: 5| Step: 2
Training loss: 2.3976041358710973
Validation loss: 2.5273830693956882

Epoch: 5| Step: 3
Training loss: 2.328897335287523
Validation loss: 2.5415563087033264

Epoch: 5| Step: 4
Training loss: 2.983602693498886
Validation loss: 2.5583677170579904

Epoch: 5| Step: 5
Training loss: 2.072036428477429
Validation loss: 2.5627058753332035

Epoch: 5| Step: 6
Training loss: 2.7380485925590956
Validation loss: 2.5128016902589976

Epoch: 5| Step: 7
Training loss: 2.3585320792233433
Validation loss: 2.5472477848255095

Epoch: 5| Step: 8
Training loss: 2.248562459541751
Validation loss: 2.537460549269794

Epoch: 5| Step: 9
Training loss: 1.8836349020805325
Validation loss: 2.570436303811697

Epoch: 5| Step: 10
Training loss: 1.5832993687784747
Validation loss: 2.5816931193261956

Epoch: 244| Step: 0
Training loss: 1.5895076462044873
Validation loss: 2.5521211980874066

Epoch: 5| Step: 1
Training loss: 2.8231199034179735
Validation loss: 2.5222591263693124

Epoch: 5| Step: 2
Training loss: 2.5670106777003268
Validation loss: 2.525959692435662

Epoch: 5| Step: 3
Training loss: 2.2863606726804573
Validation loss: 2.5706508989837697

Epoch: 5| Step: 4
Training loss: 2.104440866362338
Validation loss: 2.5875732038986907

Epoch: 5| Step: 5
Training loss: 2.418470093452889
Validation loss: 2.529584314564278

Epoch: 5| Step: 6
Training loss: 1.8933678899329174
Validation loss: 2.570420561991597

Epoch: 5| Step: 7
Training loss: 2.223161529335275
Validation loss: 2.528685881022118

Epoch: 5| Step: 8
Training loss: 2.6982182416429756
Validation loss: 2.526449361938859

Epoch: 5| Step: 9
Training loss: 2.6145752581184176
Validation loss: 2.5240586222253976

Epoch: 5| Step: 10
Training loss: 2.2493051939634205
Validation loss: 2.6012688203445107

Epoch: 245| Step: 0
Training loss: 2.5427879820062755
Validation loss: 2.588857932553156

Epoch: 5| Step: 1
Training loss: 2.065077240725478
Validation loss: 2.56777950774707

Epoch: 5| Step: 2
Training loss: 1.7457237449003524
Validation loss: 2.5938239242114607

Epoch: 5| Step: 3
Training loss: 2.394074488227525
Validation loss: 2.5915501835216066

Epoch: 5| Step: 4
Training loss: 1.7610997637206984
Validation loss: 2.5762793016409042

Epoch: 5| Step: 5
Training loss: 1.9490070724985304
Validation loss: 2.569974894387629

Epoch: 5| Step: 6
Training loss: 2.7746927348990926
Validation loss: 2.530806804076839

Epoch: 5| Step: 7
Training loss: 2.469692291830483
Validation loss: 2.5710639392536225

Epoch: 5| Step: 8
Training loss: 2.5056065634784015
Validation loss: 2.5381465580567437

Epoch: 5| Step: 9
Training loss: 1.8624379550917025
Validation loss: 2.569379149138229

Epoch: 5| Step: 10
Training loss: 3.2062104042389357
Validation loss: 2.5798158581808224

Epoch: 246| Step: 0
Training loss: 2.1372742427709777
Validation loss: 2.556675175106111

Epoch: 5| Step: 1
Training loss: 2.8071765109325586
Validation loss: 2.546450063794757

Epoch: 5| Step: 2
Training loss: 1.838122686639528
Validation loss: 2.543502075992608

Epoch: 5| Step: 3
Training loss: 2.5877560217058244
Validation loss: 2.5602196642454937

Epoch: 5| Step: 4
Training loss: 2.4735258239668845
Validation loss: 2.52876411655502

Epoch: 5| Step: 5
Training loss: 2.2186633885631433
Validation loss: 2.5263936501103

Epoch: 5| Step: 6
Training loss: 2.6107362405950822
Validation loss: 2.581394194846319

Epoch: 5| Step: 7
Training loss: 1.9400700167182852
Validation loss: 2.5031002756129563

Epoch: 5| Step: 8
Training loss: 2.4193024785518347
Validation loss: 2.512469178738593

Epoch: 5| Step: 9
Training loss: 2.334295301596118
Validation loss: 2.562205836241465

Epoch: 5| Step: 10
Training loss: 2.3753548407246963
Validation loss: 2.572256271451566

Epoch: 247| Step: 0
Training loss: 2.0826819227972933
Validation loss: 2.5288933311721737

Epoch: 5| Step: 1
Training loss: 2.5876973321091823
Validation loss: 2.500377992541507

Epoch: 5| Step: 2
Training loss: 2.1588709285685104
Validation loss: 2.4899747374959262

Epoch: 5| Step: 3
Training loss: 1.998418957920266
Validation loss: 2.5565645962765

Epoch: 5| Step: 4
Training loss: 2.629295377004058
Validation loss: 2.5714390885189613

Epoch: 5| Step: 5
Training loss: 2.1936187183190845
Validation loss: 2.5281426384553134

Epoch: 5| Step: 6
Training loss: 2.0908125583695543
Validation loss: 2.561351269532857

Epoch: 5| Step: 7
Training loss: 2.3254042735404936
Validation loss: 2.5514582650566178

Epoch: 5| Step: 8
Training loss: 2.6444408226611698
Validation loss: 2.564036106247404

Epoch: 5| Step: 9
Training loss: 2.505880972694095
Validation loss: 2.548486659297621

Epoch: 5| Step: 10
Training loss: 2.5229638189502794
Validation loss: 2.511893445181493

Epoch: 248| Step: 0
Training loss: 3.0169567270788633
Validation loss: 2.5440985592470136

Epoch: 5| Step: 1
Training loss: 2.293888148167585
Validation loss: 2.5467338842507474

Epoch: 5| Step: 2
Training loss: 2.354941237864581
Validation loss: 2.5613883543819025

Epoch: 5| Step: 3
Training loss: 2.161377601188236
Validation loss: 2.5490158367110527

Epoch: 5| Step: 4
Training loss: 2.311741988209335
Validation loss: 2.58081565999989

Epoch: 5| Step: 5
Training loss: 1.9947671382448462
Validation loss: 2.561937543046261

Epoch: 5| Step: 6
Training loss: 2.3916625719555973
Validation loss: 2.51292036492107

Epoch: 5| Step: 7
Training loss: 2.161195143030482
Validation loss: 2.553163761741302

Epoch: 5| Step: 8
Training loss: 2.2969076971724034
Validation loss: 2.529170904341659

Epoch: 5| Step: 9
Training loss: 1.9886118795695926
Validation loss: 2.610019145762241

Epoch: 5| Step: 10
Training loss: 2.2911874327829085
Validation loss: 2.5420817825119535

Epoch: 249| Step: 0
Training loss: 1.8683916622293515
Validation loss: 2.5268190757964746

Epoch: 5| Step: 1
Training loss: 2.9015685081933285
Validation loss: 2.5517752301741194

Epoch: 5| Step: 2
Training loss: 2.3517355617575935
Validation loss: 2.5500072688257096

Epoch: 5| Step: 3
Training loss: 2.588898222919641
Validation loss: 2.54983074499969

Epoch: 5| Step: 4
Training loss: 2.512500694616421
Validation loss: 2.5849473088056656

Epoch: 5| Step: 5
Training loss: 1.6023910240219041
Validation loss: 2.56500015077045

Epoch: 5| Step: 6
Training loss: 2.8254260256751547
Validation loss: 2.55630563843446

Epoch: 5| Step: 7
Training loss: 2.011235625391696
Validation loss: 2.5593217157467127

Epoch: 5| Step: 8
Training loss: 2.2051842987475836
Validation loss: 2.5643620332511814

Epoch: 5| Step: 9
Training loss: 2.1406457162119157
Validation loss: 2.5751861736736443

Epoch: 5| Step: 10
Training loss: 2.4077958925183163
Validation loss: 2.5498993928748592

Epoch: 250| Step: 0
Training loss: 2.401089075465867
Validation loss: 2.5278466602948875

Epoch: 5| Step: 1
Training loss: 2.408643349710018
Validation loss: 2.571702716023836

Epoch: 5| Step: 2
Training loss: 2.1462455526404716
Validation loss: 2.5228633610346725

Epoch: 5| Step: 3
Training loss: 2.6838085638300653
Validation loss: 2.521876759301108

Epoch: 5| Step: 4
Training loss: 2.0813895376356513
Validation loss: 2.515097380674312

Epoch: 5| Step: 5
Training loss: 2.4239235366620937
Validation loss: 2.5225310324756443

Epoch: 5| Step: 6
Training loss: 2.1370968667167882
Validation loss: 2.635027541087696

Epoch: 5| Step: 7
Training loss: 2.138168150224686
Validation loss: 2.548973199121863

Epoch: 5| Step: 8
Training loss: 2.3403911682590772
Validation loss: 2.5392225832520574

Epoch: 5| Step: 9
Training loss: 2.3659759543350605
Validation loss: 2.5512043111944878

Epoch: 5| Step: 10
Training loss: 2.3445893882653848
Validation loss: 2.5487086871152007

Epoch: 251| Step: 0
Training loss: 2.319245269609376
Validation loss: 2.5468754912123717

Epoch: 5| Step: 1
Training loss: 1.9685081454479858
Validation loss: 2.5538445876807825

Epoch: 5| Step: 2
Training loss: 3.273980216328312
Validation loss: 2.564860012756319

Epoch: 5| Step: 3
Training loss: 2.375942143740889
Validation loss: 2.5337857339798475

Epoch: 5| Step: 4
Training loss: 2.017842809961393
Validation loss: 2.490316970681157

Epoch: 5| Step: 5
Training loss: 1.7823027461242837
Validation loss: 2.5451622589249645

Epoch: 5| Step: 6
Training loss: 1.9225310779733356
Validation loss: 2.5398019011583317

Epoch: 5| Step: 7
Training loss: 2.442450557899423
Validation loss: 2.555324345989416

Epoch: 5| Step: 8
Training loss: 2.503154766843968
Validation loss: 2.5467760771582126

Epoch: 5| Step: 9
Training loss: 2.358652168351563
Validation loss: 2.568365192285871

Epoch: 5| Step: 10
Training loss: 2.1714595699248833
Validation loss: 2.52852379792605

Epoch: 252| Step: 0
Training loss: 2.091148012254339
Validation loss: 2.5051411310644367

Epoch: 5| Step: 1
Training loss: 2.480371187949696
Validation loss: 2.5643293212475

Epoch: 5| Step: 2
Training loss: 2.6933282154651526
Validation loss: 2.5261417194456586

Epoch: 5| Step: 3
Training loss: 1.8872619226129366
Validation loss: 2.5508407447390677

Epoch: 5| Step: 4
Training loss: 1.895293218226837
Validation loss: 2.551177169384794

Epoch: 5| Step: 5
Training loss: 2.8221559707828505
Validation loss: 2.611655668288424

Epoch: 5| Step: 6
Training loss: 2.1814867475947777
Validation loss: 2.606657190060432

Epoch: 5| Step: 7
Training loss: 2.1574721259198446
Validation loss: 2.5525466826469105

Epoch: 5| Step: 8
Training loss: 2.3178974774508254
Validation loss: 2.550339767481757

Epoch: 5| Step: 9
Training loss: 2.2819585875448696
Validation loss: 2.5842431266215415

Epoch: 5| Step: 10
Training loss: 2.477810999253668
Validation loss: 2.5663203512271355

Epoch: 253| Step: 0
Training loss: 2.2895106374939598
Validation loss: 2.55686381269788

Epoch: 5| Step: 1
Training loss: 2.5836132472167437
Validation loss: 2.508712951910458

Epoch: 5| Step: 2
Training loss: 2.4235390145679636
Validation loss: 2.5313261692381386

Epoch: 5| Step: 3
Training loss: 2.8181322287785955
Validation loss: 2.5415952095168843

Epoch: 5| Step: 4
Training loss: 2.410387519609646
Validation loss: 2.5239176893813666

Epoch: 5| Step: 5
Training loss: 1.936024442356862
Validation loss: 2.5754621041515735

Epoch: 5| Step: 6
Training loss: 2.589232681933987
Validation loss: 2.5122059592423875

Epoch: 5| Step: 7
Training loss: 1.407994989047562
Validation loss: 2.5407450871355155

Epoch: 5| Step: 8
Training loss: 2.667386305583905
Validation loss: 2.5559470644185804

Epoch: 5| Step: 9
Training loss: 2.3480315709761617
Validation loss: 2.5494303187000176

Epoch: 5| Step: 10
Training loss: 2.022880094481121
Validation loss: 2.5404777173475552

Epoch: 254| Step: 0
Training loss: 2.571819014652551
Validation loss: 2.5355175468788302

Epoch: 5| Step: 1
Training loss: 2.365029537992321
Validation loss: 2.5076608878754065

Epoch: 5| Step: 2
Training loss: 2.507283187575056
Validation loss: 2.528436527000481

Epoch: 5| Step: 3
Training loss: 3.0071656163146905
Validation loss: 2.4782561190387478

Epoch: 5| Step: 4
Training loss: 2.2431175084279937
Validation loss: 2.5094066964764044

Epoch: 5| Step: 5
Training loss: 1.6077684698572852
Validation loss: 2.469659278807634

Epoch: 5| Step: 6
Training loss: 2.1547275641840415
Validation loss: 2.5410332444370454

Epoch: 5| Step: 7
Training loss: 1.8386842349990211
Validation loss: 2.585558961334113

Epoch: 5| Step: 8
Training loss: 2.6234654073497503
Validation loss: 2.567021988806322

Epoch: 5| Step: 9
Training loss: 1.868579999661151
Validation loss: 2.580731905740615

Epoch: 5| Step: 10
Training loss: 1.964012501033924
Validation loss: 2.562351134443381

Epoch: 255| Step: 0
Training loss: 1.9048845998097967
Validation loss: 2.567099971763424

Epoch: 5| Step: 1
Training loss: 2.1395025721545893
Validation loss: 2.5886690970819273

Epoch: 5| Step: 2
Training loss: 2.0757424600384544
Validation loss: 2.565912256318103

Epoch: 5| Step: 3
Training loss: 2.526941187782179
Validation loss: 2.568191069265542

Epoch: 5| Step: 4
Training loss: 2.646408158784903
Validation loss: 2.5089267262530845

Epoch: 5| Step: 5
Training loss: 2.1406907120245884
Validation loss: 2.57933880176897

Epoch: 5| Step: 6
Training loss: 2.7705159017440066
Validation loss: 2.574313486347689

Epoch: 5| Step: 7
Training loss: 2.185945558021859
Validation loss: 2.5783018178953476

Epoch: 5| Step: 8
Training loss: 2.02392866734942
Validation loss: 2.5278902594122465

Epoch: 5| Step: 9
Training loss: 2.4859710940447446
Validation loss: 2.576261772001532

Epoch: 5| Step: 10
Training loss: 2.366001045845942
Validation loss: 2.5799411505899874

Epoch: 256| Step: 0
Training loss: 2.235163836181311
Validation loss: 2.5427551820012004

Epoch: 5| Step: 1
Training loss: 2.495650799868939
Validation loss: 2.5192407879244727

Epoch: 5| Step: 2
Training loss: 2.2647836109399777
Validation loss: 2.5020238426659223

Epoch: 5| Step: 3
Training loss: 1.8715284634952394
Validation loss: 2.5985264106146815

Epoch: 5| Step: 4
Training loss: 2.0196916822684994
Validation loss: 2.607039608751258

Epoch: 5| Step: 5
Training loss: 2.2284747562121288
Validation loss: 2.556730187485546

Epoch: 5| Step: 6
Training loss: 2.4411801653130443
Validation loss: 2.5875579482704394

Epoch: 5| Step: 7
Training loss: 2.049322514119293
Validation loss: 2.5518490768984137

Epoch: 5| Step: 8
Training loss: 3.118339459569375
Validation loss: 2.512567960566597

Epoch: 5| Step: 9
Training loss: 2.064617341727331
Validation loss: 2.550733569387596

Epoch: 5| Step: 10
Training loss: 2.6223047133938677
Validation loss: 2.5333655781210416

Epoch: 257| Step: 0
Training loss: 2.274623705586082
Validation loss: 2.569000459836162

Epoch: 5| Step: 1
Training loss: 2.419088126114458
Validation loss: 2.5312683447129154

Epoch: 5| Step: 2
Training loss: 2.453465723563641
Validation loss: 2.5476269513142893

Epoch: 5| Step: 3
Training loss: 2.545311851805809
Validation loss: 2.56638340354459

Epoch: 5| Step: 4
Training loss: 1.8167415842596524
Validation loss: 2.5226226642110308

Epoch: 5| Step: 5
Training loss: 1.6992144003626082
Validation loss: 2.52616200407296

Epoch: 5| Step: 6
Training loss: 2.3465277931815733
Validation loss: 2.568230864320892

Epoch: 5| Step: 7
Training loss: 2.000484765431222
Validation loss: 2.5501915954427496

Epoch: 5| Step: 8
Training loss: 2.0757609523230185
Validation loss: 2.4926121433825226

Epoch: 5| Step: 9
Training loss: 2.6643925347714257
Validation loss: 2.5156300944105583

Epoch: 5| Step: 10
Training loss: 2.816865119112678
Validation loss: 2.5534784685425835

Epoch: 258| Step: 0
Training loss: 2.472329261215139
Validation loss: 2.556794083424637

Epoch: 5| Step: 1
Training loss: 2.3091511577891652
Validation loss: 2.560294449950161

Epoch: 5| Step: 2
Training loss: 1.9870886682924163
Validation loss: 2.528249317895343

Epoch: 5| Step: 3
Training loss: 2.0450330993659835
Validation loss: 2.533248991147836

Epoch: 5| Step: 4
Training loss: 3.2096936863477588
Validation loss: 2.5211504502255253

Epoch: 5| Step: 5
Training loss: 2.164981798267277
Validation loss: 2.548059442372279

Epoch: 5| Step: 6
Training loss: 1.9108222783208784
Validation loss: 2.5426484835302916

Epoch: 5| Step: 7
Training loss: 2.6045069256062665
Validation loss: 2.533478070621882

Epoch: 5| Step: 8
Training loss: 1.8257239460471015
Validation loss: 2.547150205007572

Epoch: 5| Step: 9
Training loss: 2.1771139723767936
Validation loss: 2.5413713073451696

Epoch: 5| Step: 10
Training loss: 2.3726979191411677
Validation loss: 2.537772441362353

Epoch: 259| Step: 0
Training loss: 2.2194393322880064
Validation loss: 2.5545631306416703

Epoch: 5| Step: 1
Training loss: 2.2207544433246973
Validation loss: 2.575017838257505

Epoch: 5| Step: 2
Training loss: 2.759982371204855
Validation loss: 2.527587667867326

Epoch: 5| Step: 3
Training loss: 1.886389978168485
Validation loss: 2.5268926778864267

Epoch: 5| Step: 4
Training loss: 1.9026251551482252
Validation loss: 2.5391195609194224

Epoch: 5| Step: 5
Training loss: 2.2658823853664525
Validation loss: 2.5644145509349974

Epoch: 5| Step: 6
Training loss: 3.1207334766447095
Validation loss: 2.570238786778613

Epoch: 5| Step: 7
Training loss: 1.8562525970749075
Validation loss: 2.564336579287456

Epoch: 5| Step: 8
Training loss: 2.157914445307177
Validation loss: 2.5565757450245035

Epoch: 5| Step: 9
Training loss: 2.361063372060819
Validation loss: 2.5564693074940146

Epoch: 5| Step: 10
Training loss: 2.1998873248290147
Validation loss: 2.5466604770927073

Epoch: 260| Step: 0
Training loss: 2.4436491650317262
Validation loss: 2.553432414572862

Epoch: 5| Step: 1
Training loss: 2.3125389714436815
Validation loss: 2.5607136688582446

Epoch: 5| Step: 2
Training loss: 2.556210125376653
Validation loss: 2.615561153692003

Epoch: 5| Step: 3
Training loss: 2.2524857036039507
Validation loss: 2.5583154329865025

Epoch: 5| Step: 4
Training loss: 2.5412530927362496
Validation loss: 2.5328212870909326

Epoch: 5| Step: 5
Training loss: 2.0972419201709687
Validation loss: 2.580127765237321

Epoch: 5| Step: 6
Training loss: 2.2745384880024653
Validation loss: 2.5711549421295867

Epoch: 5| Step: 7
Training loss: 2.2993626001577905
Validation loss: 2.594750165192277

Epoch: 5| Step: 8
Training loss: 2.00016295246044
Validation loss: 2.5003230245129684

Epoch: 5| Step: 9
Training loss: 2.3302930938988986
Validation loss: 2.524476668426351

Epoch: 5| Step: 10
Training loss: 2.1865618192533463
Validation loss: 2.512170389352

Epoch: 261| Step: 0
Training loss: 2.323672652001234
Validation loss: 2.545962223148068

Epoch: 5| Step: 1
Training loss: 2.7027751718290527
Validation loss: 2.5699599412902243

Epoch: 5| Step: 2
Training loss: 2.628255823170109
Validation loss: 2.5451930929873074

Epoch: 5| Step: 3
Training loss: 2.1860527700771573
Validation loss: 2.536978324400422

Epoch: 5| Step: 4
Training loss: 2.018909469305512
Validation loss: 2.5156457974407247

Epoch: 5| Step: 5
Training loss: 2.1105194378074987
Validation loss: 2.545391138440623

Epoch: 5| Step: 6
Training loss: 1.8195428490013108
Validation loss: 2.5664785859446213

Epoch: 5| Step: 7
Training loss: 2.2185634480882803
Validation loss: 2.5334352696893703

Epoch: 5| Step: 8
Training loss: 1.730866603883573
Validation loss: 2.5316548901616653

Epoch: 5| Step: 9
Training loss: 2.218122796610847
Validation loss: 2.5402751935115795

Epoch: 5| Step: 10
Training loss: 2.719978230473411
Validation loss: 2.516370032302892

Epoch: 262| Step: 0
Training loss: 1.9533560654334066
Validation loss: 2.5711421136990005

Epoch: 5| Step: 1
Training loss: 2.404315914323478
Validation loss: 2.5083418203083636

Epoch: 5| Step: 2
Training loss: 2.9714827959646457
Validation loss: 2.5706143546536047

Epoch: 5| Step: 3
Training loss: 1.9789182473597227
Validation loss: 2.556907269204104

Epoch: 5| Step: 4
Training loss: 2.326666970658305
Validation loss: 2.5066145484409135

Epoch: 5| Step: 5
Training loss: 2.6079048080975165
Validation loss: 2.545375342950402

Epoch: 5| Step: 6
Training loss: 1.593521026917866
Validation loss: 2.5145280948798248

Epoch: 5| Step: 7
Training loss: 2.1770537403291748
Validation loss: 2.5525076906154394

Epoch: 5| Step: 8
Training loss: 2.160579701975858
Validation loss: 2.5444868023417024

Epoch: 5| Step: 9
Training loss: 1.678346888472599
Validation loss: 2.5570028745274547

Epoch: 5| Step: 10
Training loss: 2.603010628009192
Validation loss: 2.5066334978857667

Epoch: 263| Step: 0
Training loss: 2.7473450762985197
Validation loss: 2.5458559813218016

Epoch: 5| Step: 1
Training loss: 1.994489827904495
Validation loss: 2.5675652936355506

Epoch: 5| Step: 2
Training loss: 2.364327998106311
Validation loss: 2.557971011416637

Epoch: 5| Step: 3
Training loss: 2.4246536558129232
Validation loss: 2.59643821709036

Epoch: 5| Step: 4
Training loss: 2.3491200280766913
Validation loss: 2.52092487711714

Epoch: 5| Step: 5
Training loss: 2.2414655952136244
Validation loss: 2.5505960453115732

Epoch: 5| Step: 6
Training loss: 1.9787972222559493
Validation loss: 2.54099634275504

Epoch: 5| Step: 7
Training loss: 1.9116503405130199
Validation loss: 2.550612304994265

Epoch: 5| Step: 8
Training loss: 2.149667062042542
Validation loss: 2.5530204500613456

Epoch: 5| Step: 9
Training loss: 2.2647386592973087
Validation loss: 2.5404788309085213

Epoch: 5| Step: 10
Training loss: 2.6155802332101885
Validation loss: 2.582580172465057

Epoch: 264| Step: 0
Training loss: 2.3268211861411676
Validation loss: 2.519869560059192

Epoch: 5| Step: 1
Training loss: 2.446311283581711
Validation loss: 2.533772403707375

Epoch: 5| Step: 2
Training loss: 2.1657279866709382
Validation loss: 2.584211216863149

Epoch: 5| Step: 3
Training loss: 2.3450479600959437
Validation loss: 2.5329231901144045

Epoch: 5| Step: 4
Training loss: 1.7211712515442308
Validation loss: 2.536625695748727

Epoch: 5| Step: 5
Training loss: 1.843829977596185
Validation loss: 2.570737811847679

Epoch: 5| Step: 6
Training loss: 1.7955718912993546
Validation loss: 2.547254191785939

Epoch: 5| Step: 7
Training loss: 2.3078443727765308
Validation loss: 2.5210439981620456

Epoch: 5| Step: 8
Training loss: 2.8808509335151746
Validation loss: 2.5363808165840176

Epoch: 5| Step: 9
Training loss: 2.007605753544211
Validation loss: 2.508115219416415

Epoch: 5| Step: 10
Training loss: 2.6684741411419672
Validation loss: 2.532102092257843

Epoch: 265| Step: 0
Training loss: 1.7781745059022052
Validation loss: 2.523803586853074

Epoch: 5| Step: 1
Training loss: 2.49796154839858
Validation loss: 2.5844234362369694

Epoch: 5| Step: 2
Training loss: 2.42710980140323
Validation loss: 2.586622121199741

Epoch: 5| Step: 3
Training loss: 2.454270210953061
Validation loss: 2.5684782564257014

Epoch: 5| Step: 4
Training loss: 2.4155622348305075
Validation loss: 2.551854803230492

Epoch: 5| Step: 5
Training loss: 2.488503726134022
Validation loss: 2.5668485342189986

Epoch: 5| Step: 6
Training loss: 2.367787200200506
Validation loss: 2.544240431784952

Epoch: 5| Step: 7
Training loss: 2.3948309307908886
Validation loss: 2.5434171847277076

Epoch: 5| Step: 8
Training loss: 2.2530689502363312
Validation loss: 2.5231499962307953

Epoch: 5| Step: 9
Training loss: 1.6552024263437002
Validation loss: 2.5187425250591327

Epoch: 5| Step: 10
Training loss: 2.438697129717162
Validation loss: 2.5708580950342284

Epoch: 266| Step: 0
Training loss: 2.204166680127476
Validation loss: 2.5311547771263343

Epoch: 5| Step: 1
Training loss: 2.287647838713854
Validation loss: 2.5436739171233342

Epoch: 5| Step: 2
Training loss: 2.106075390559468
Validation loss: 2.5319939921038133

Epoch: 5| Step: 3
Training loss: 1.9777326776360482
Validation loss: 2.5335813881241047

Epoch: 5| Step: 4
Training loss: 2.4660550630830844
Validation loss: 2.5154911067537196

Epoch: 5| Step: 5
Training loss: 2.3425454668418264
Validation loss: 2.5812734367682966

Epoch: 5| Step: 6
Training loss: 2.412585056366992
Validation loss: 2.5586978848891326

Epoch: 5| Step: 7
Training loss: 2.8942047223255383
Validation loss: 2.512803365479345

Epoch: 5| Step: 8
Training loss: 2.36470954546981
Validation loss: 2.5088057351737794

Epoch: 5| Step: 9
Training loss: 2.280468114347719
Validation loss: 2.5828950002646662

Epoch: 5| Step: 10
Training loss: 1.4757596209724748
Validation loss: 2.495394993924702

Epoch: 267| Step: 0
Training loss: 2.735173048999129
Validation loss: 2.522166127015125

Epoch: 5| Step: 1
Training loss: 2.0671672609568215
Validation loss: 2.5455930921106846

Epoch: 5| Step: 2
Training loss: 3.3361457563159997
Validation loss: 2.524690033308605

Epoch: 5| Step: 3
Training loss: 1.8916556331407972
Validation loss: 2.5163136531151684

Epoch: 5| Step: 4
Training loss: 2.3432140500497574
Validation loss: 2.492643145647007

Epoch: 5| Step: 5
Training loss: 2.471066703732798
Validation loss: 2.519666365199104

Epoch: 5| Step: 6
Training loss: 1.7635975227440652
Validation loss: 2.536212809619679

Epoch: 5| Step: 7
Training loss: 2.0961121855844604
Validation loss: 2.543816196305661

Epoch: 5| Step: 8
Training loss: 2.1714023652144565
Validation loss: 2.5505266562999283

Epoch: 5| Step: 9
Training loss: 1.6282141516470299
Validation loss: 2.558197391071862

Epoch: 5| Step: 10
Training loss: 1.9828933230401606
Validation loss: 2.5509684843421554

Epoch: 268| Step: 0
Training loss: 2.2722265420181924
Validation loss: 2.517125135334499

Epoch: 5| Step: 1
Training loss: 2.200488088390491
Validation loss: 2.5498127349192266

Epoch: 5| Step: 2
Training loss: 2.200983941518323
Validation loss: 2.545164952337303

Epoch: 5| Step: 3
Training loss: 2.072483637322967
Validation loss: 2.56676157305911

Epoch: 5| Step: 4
Training loss: 2.6451562230318997
Validation loss: 2.5415674012352722

Epoch: 5| Step: 5
Training loss: 2.674921006079138
Validation loss: 2.550970758582785

Epoch: 5| Step: 6
Training loss: 2.4421645306796322
Validation loss: 2.5560170886071742

Epoch: 5| Step: 7
Training loss: 2.007957245474141
Validation loss: 2.545908427619193

Epoch: 5| Step: 8
Training loss: 1.9588511641328157
Validation loss: 2.5910396952210983

Epoch: 5| Step: 9
Training loss: 2.5065676252433753
Validation loss: 2.5570647590114173

Epoch: 5| Step: 10
Training loss: 1.6013854138234704
Validation loss: 2.537060437071544

Epoch: 269| Step: 0
Training loss: 1.855369163651524
Validation loss: 2.5670409557194573

Epoch: 5| Step: 1
Training loss: 3.1374924253091145
Validation loss: 2.5456450080634645

Epoch: 5| Step: 2
Training loss: 2.5690610674070022
Validation loss: 2.5445022708656513

Epoch: 5| Step: 3
Training loss: 1.9580938990972534
Validation loss: 2.5187019725249065

Epoch: 5| Step: 4
Training loss: 2.195194987888564
Validation loss: 2.5426241037828925

Epoch: 5| Step: 5
Training loss: 2.128874444286495
Validation loss: 2.5566108610568925

Epoch: 5| Step: 6
Training loss: 2.2639940376540215
Validation loss: 2.561580668125448

Epoch: 5| Step: 7
Training loss: 1.7723056357367466
Validation loss: 2.503569559804498

Epoch: 5| Step: 8
Training loss: 2.007407655979207
Validation loss: 2.5297041811121943

Epoch: 5| Step: 9
Training loss: 2.1670149621028885
Validation loss: 2.5552098911501493

Epoch: 5| Step: 10
Training loss: 2.430075169880206
Validation loss: 2.5084922106301955

Epoch: 270| Step: 0
Training loss: 2.3323712636209413
Validation loss: 2.476970375700972

Epoch: 5| Step: 1
Training loss: 1.3668985551950799
Validation loss: 2.5184258504455346

Epoch: 5| Step: 2
Training loss: 1.8506071305885747
Validation loss: 2.524039283568101

Epoch: 5| Step: 3
Training loss: 1.829678389007792
Validation loss: 2.53051044938448

Epoch: 5| Step: 4
Training loss: 2.9046193131789555
Validation loss: 2.5826730645188105

Epoch: 5| Step: 5
Training loss: 2.3872376422632136
Validation loss: 2.5937927594436583

Epoch: 5| Step: 6
Training loss: 2.4463784329046887
Validation loss: 2.5586629272517656

Epoch: 5| Step: 7
Training loss: 1.9145991604565555
Validation loss: 2.545115928563311

Epoch: 5| Step: 8
Training loss: 2.4039384712685594
Validation loss: 2.548723578808755

Epoch: 5| Step: 9
Training loss: 2.807529635183804
Validation loss: 2.571288891011617

Epoch: 5| Step: 10
Training loss: 2.1381480790503677
Validation loss: 2.552355586571464

Epoch: 271| Step: 0
Training loss: 2.0921186098205267
Validation loss: 2.541923069910592

Epoch: 5| Step: 1
Training loss: 2.7116840664759225
Validation loss: 2.5681886116266455

Epoch: 5| Step: 2
Training loss: 2.7281340958311464
Validation loss: 2.530478214608567

Epoch: 5| Step: 3
Training loss: 2.0443056010470677
Validation loss: 2.558574415865143

Epoch: 5| Step: 4
Training loss: 1.6567075565186293
Validation loss: 2.557534891819812

Epoch: 5| Step: 5
Training loss: 2.386174466120127
Validation loss: 2.5573826266527417

Epoch: 5| Step: 6
Training loss: 2.606295384439555
Validation loss: 2.529960420298844

Epoch: 5| Step: 7
Training loss: 2.303966862142198
Validation loss: 2.551675071649686

Epoch: 5| Step: 8
Training loss: 1.7261121343740533
Validation loss: 2.5472140347933707

Epoch: 5| Step: 9
Training loss: 2.1116517389738836
Validation loss: 2.517431822111239

Epoch: 5| Step: 10
Training loss: 1.9722895819693043
Validation loss: 2.5553790443439213

Epoch: 272| Step: 0
Training loss: 1.8973004739069017
Validation loss: 2.571779655910419

Epoch: 5| Step: 1
Training loss: 1.8295007729311068
Validation loss: 2.533187900194205

Epoch: 5| Step: 2
Training loss: 2.48594030815268
Validation loss: 2.5304060891018967

Epoch: 5| Step: 3
Training loss: 2.011267394754642
Validation loss: 2.5165639796336414

Epoch: 5| Step: 4
Training loss: 2.335373009697035
Validation loss: 2.488774172287255

Epoch: 5| Step: 5
Training loss: 1.7030769831336856
Validation loss: 2.5242446364938314

Epoch: 5| Step: 6
Training loss: 2.580658656035026
Validation loss: 2.539895747598174

Epoch: 5| Step: 7
Training loss: 2.2740996664746915
Validation loss: 2.507308614416498

Epoch: 5| Step: 8
Training loss: 2.6795421149404883
Validation loss: 2.5315608815215094

Epoch: 5| Step: 9
Training loss: 2.438173054424717
Validation loss: 2.5321528309557944

Epoch: 5| Step: 10
Training loss: 1.9596985934562012
Validation loss: 2.531613117385424

Epoch: 273| Step: 0
Training loss: 2.090797050022389
Validation loss: 2.521835411374946

Epoch: 5| Step: 1
Training loss: 2.208080805129192
Validation loss: 2.5366940238610107

Epoch: 5| Step: 2
Training loss: 1.8185880293937648
Validation loss: 2.5017703504792275

Epoch: 5| Step: 3
Training loss: 2.190600677224602
Validation loss: 2.5292440284982107

Epoch: 5| Step: 4
Training loss: 1.755129109602975
Validation loss: 2.5319627026630322

Epoch: 5| Step: 5
Training loss: 2.9384374543031475
Validation loss: 2.5470461953632673

Epoch: 5| Step: 6
Training loss: 2.953657637099267
Validation loss: 2.4977323225071424

Epoch: 5| Step: 7
Training loss: 1.911502168934056
Validation loss: 2.533654784663929

Epoch: 5| Step: 8
Training loss: 2.326625264117302
Validation loss: 2.551915930522404

Epoch: 5| Step: 9
Training loss: 1.8432051289947329
Validation loss: 2.56473320993321

Epoch: 5| Step: 10
Training loss: 1.872482326103297
Validation loss: 2.5215221747975716

Epoch: 274| Step: 0
Training loss: 1.9562890630849898
Validation loss: 2.5480458738702705

Epoch: 5| Step: 1
Training loss: 1.7266962336189795
Validation loss: 2.5348818039640775

Epoch: 5| Step: 2
Training loss: 2.2417842489080755
Validation loss: 2.5725266345849165

Epoch: 5| Step: 3
Training loss: 2.9214119773817173
Validation loss: 2.5377838848058896

Epoch: 5| Step: 4
Training loss: 2.0880883946617055
Validation loss: 2.5073429721439644

Epoch: 5| Step: 5
Training loss: 1.7600282394787925
Validation loss: 2.537520013836662

Epoch: 5| Step: 6
Training loss: 1.9198992117614258
Validation loss: 2.5239200337049805

Epoch: 5| Step: 7
Training loss: 2.4856891155534533
Validation loss: 2.5234696139107493

Epoch: 5| Step: 8
Training loss: 2.210072702100946
Validation loss: 2.52083768482353

Epoch: 5| Step: 9
Training loss: 2.016733500526531
Validation loss: 2.538959052137492

Epoch: 5| Step: 10
Training loss: 2.066692137817602
Validation loss: 2.53078326651138

Epoch: 275| Step: 0
Training loss: 2.4993124970206653
Validation loss: 2.54594434379285

Epoch: 5| Step: 1
Training loss: 2.5555999712839093
Validation loss: 2.5023816833492574

Epoch: 5| Step: 2
Training loss: 1.8907583520692959
Validation loss: 2.5264475161611086

Epoch: 5| Step: 3
Training loss: 2.500172895175016
Validation loss: 2.538695099329818

Epoch: 5| Step: 4
Training loss: 1.7411011186800007
Validation loss: 2.5709562677671967

Epoch: 5| Step: 5
Training loss: 2.4182540897747704
Validation loss: 2.578097509173573

Epoch: 5| Step: 6
Training loss: 1.5288688674590434
Validation loss: 2.498963295910887

Epoch: 5| Step: 7
Training loss: 2.4243476304793097
Validation loss: 2.5254026432869785

Epoch: 5| Step: 8
Training loss: 1.7271980738363617
Validation loss: 2.5067152484524744

Epoch: 5| Step: 9
Training loss: 2.768289952344932
Validation loss: 2.5362944265217267

Epoch: 5| Step: 10
Training loss: 2.0014052222799688
Validation loss: 2.524715233056415

Epoch: 276| Step: 0
Training loss: 2.093677348684144
Validation loss: 2.548549324955671

Epoch: 5| Step: 1
Training loss: 2.2921274126598417
Validation loss: 2.5295025054777374

Epoch: 5| Step: 2
Training loss: 2.9568867616615053
Validation loss: 2.5417856662300333

Epoch: 5| Step: 3
Training loss: 1.9565884209064188
Validation loss: 2.5169273576654128

Epoch: 5| Step: 4
Training loss: 2.114180678442851
Validation loss: 2.5705416214735903

Epoch: 5| Step: 5
Training loss: 2.6607443989762243
Validation loss: 2.5096085145024185

Epoch: 5| Step: 6
Training loss: 1.8311113272489854
Validation loss: 2.594337128084469

Epoch: 5| Step: 7
Training loss: 2.5112446623802898
Validation loss: 2.5684444519922023

Epoch: 5| Step: 8
Training loss: 1.7537399926855122
Validation loss: 2.5371598165259392

Epoch: 5| Step: 9
Training loss: 1.985143197417181
Validation loss: 2.5291899949556704

Epoch: 5| Step: 10
Training loss: 2.0568083634039196
Validation loss: 2.563044614465845

Epoch: 277| Step: 0
Training loss: 2.018408693922191
Validation loss: 2.5768062297500838

Epoch: 5| Step: 1
Training loss: 2.0737964034910283
Validation loss: 2.550600700996901

Epoch: 5| Step: 2
Training loss: 2.5018474428487476
Validation loss: 2.559396961407467

Epoch: 5| Step: 3
Training loss: 2.0258777882280294
Validation loss: 2.5280770879583305

Epoch: 5| Step: 4
Training loss: 2.6560407668340162
Validation loss: 2.530686902128531

Epoch: 5| Step: 5
Training loss: 2.154613481983343
Validation loss: 2.485073527730618

Epoch: 5| Step: 6
Training loss: 2.535163773582827
Validation loss: 2.543359052488554

Epoch: 5| Step: 7
Training loss: 2.2314662540045793
Validation loss: 2.5407278763705925

Epoch: 5| Step: 8
Training loss: 2.1646417056141374
Validation loss: 2.5155890565461148

Epoch: 5| Step: 9
Training loss: 2.06511279982646
Validation loss: 2.562919304269899

Epoch: 5| Step: 10
Training loss: 1.8969812027236692
Validation loss: 2.5303291074709593

Epoch: 278| Step: 0
Training loss: 1.8088587655330168
Validation loss: 2.5420578723285385

Epoch: 5| Step: 1
Training loss: 2.962883221913131
Validation loss: 2.51939516697638

Epoch: 5| Step: 2
Training loss: 2.3931184617852606
Validation loss: 2.5173450577426415

Epoch: 5| Step: 3
Training loss: 1.7447519629976156
Validation loss: 2.5420702484910316

Epoch: 5| Step: 4
Training loss: 2.308080832469137
Validation loss: 2.484423419637659

Epoch: 5| Step: 5
Training loss: 2.004316202508035
Validation loss: 2.4941893227274163

Epoch: 5| Step: 6
Training loss: 2.3037020370615475
Validation loss: 2.5224858414099463

Epoch: 5| Step: 7
Training loss: 2.225467774157212
Validation loss: 2.5646771322191264

Epoch: 5| Step: 8
Training loss: 2.178496442125176
Validation loss: 2.563994655306578

Epoch: 5| Step: 9
Training loss: 1.627358339182946
Validation loss: 2.552179818823022

Epoch: 5| Step: 10
Training loss: 2.40189522378603
Validation loss: 2.5451837960713495

Epoch: 279| Step: 0
Training loss: 1.9983262568717848
Validation loss: 2.5132002275796115

Epoch: 5| Step: 1
Training loss: 1.84614730415041
Validation loss: 2.531934438254673

Epoch: 5| Step: 2
Training loss: 2.3138916364665953
Validation loss: 2.503031789908644

Epoch: 5| Step: 3
Training loss: 2.4036651202771595
Validation loss: 2.5405568329493544

Epoch: 5| Step: 4
Training loss: 1.9138316735418766
Validation loss: 2.5289743003407628

Epoch: 5| Step: 5
Training loss: 2.341470449061992
Validation loss: 2.5517030400370753

Epoch: 5| Step: 6
Training loss: 2.0006157404057574
Validation loss: 2.526384534656193

Epoch: 5| Step: 7
Training loss: 1.858272129242698
Validation loss: 2.5128122924873324

Epoch: 5| Step: 8
Training loss: 2.2813384156533725
Validation loss: 2.5523780453357183

Epoch: 5| Step: 9
Training loss: 2.7026211483997056
Validation loss: 2.5024350336145256

Epoch: 5| Step: 10
Training loss: 2.339719740394676
Validation loss: 2.4863875638261717

Epoch: 280| Step: 0
Training loss: 1.9447110023653764
Validation loss: 2.5323038425514675

Epoch: 5| Step: 1
Training loss: 2.2401869086214843
Validation loss: 2.532569964443524

Epoch: 5| Step: 2
Training loss: 1.7676133294577767
Validation loss: 2.499359448726127

Epoch: 5| Step: 3
Training loss: 2.4680927222530413
Validation loss: 2.5602258810337575

Epoch: 5| Step: 4
Training loss: 2.613078886445005
Validation loss: 2.5618037226532606

Epoch: 5| Step: 5
Training loss: 2.691400137618921
Validation loss: 2.518737249663495

Epoch: 5| Step: 6
Training loss: 1.9581233649272893
Validation loss: 2.5214642113516055

Epoch: 5| Step: 7
Training loss: 2.0430209151367684
Validation loss: 2.4952894778525248

Epoch: 5| Step: 8
Training loss: 2.495131711674948
Validation loss: 2.5667467011208474

Epoch: 5| Step: 9
Training loss: 1.924934742799892
Validation loss: 2.56006264090168

Epoch: 5| Step: 10
Training loss: 1.8083489336785308
Validation loss: 2.558621571619788

Epoch: 281| Step: 0
Training loss: 2.060635851344658
Validation loss: 2.4929172608412133

Epoch: 5| Step: 1
Training loss: 2.2938434550608906
Validation loss: 2.5001145757035883

Epoch: 5| Step: 2
Training loss: 1.8796089111540653
Validation loss: 2.570507265724579

Epoch: 5| Step: 3
Training loss: 1.8828273788434082
Validation loss: 2.4957197485159797

Epoch: 5| Step: 4
Training loss: 2.9316677877551593
Validation loss: 2.5311163255890254

Epoch: 5| Step: 5
Training loss: 2.6424039908789845
Validation loss: 2.5122247654856653

Epoch: 5| Step: 6
Training loss: 1.706019191012381
Validation loss: 2.4965406540902157

Epoch: 5| Step: 7
Training loss: 1.9397475219899527
Validation loss: 2.5426423936566493

Epoch: 5| Step: 8
Training loss: 2.4978497795034786
Validation loss: 2.54306972421584

Epoch: 5| Step: 9
Training loss: 1.94169151006476
Validation loss: 2.5255766903789993

Epoch: 5| Step: 10
Training loss: 2.145219424924406
Validation loss: 2.5749277932874857

Epoch: 282| Step: 0
Training loss: 2.2341347945417
Validation loss: 2.552359040774408

Epoch: 5| Step: 1
Training loss: 2.140728022191595
Validation loss: 2.5160174625761793

Epoch: 5| Step: 2
Training loss: 2.489952687805977
Validation loss: 2.5090472598807048

Epoch: 5| Step: 3
Training loss: 1.824056287306923
Validation loss: 2.5220926045158576

Epoch: 5| Step: 4
Training loss: 2.166204611098586
Validation loss: 2.5048444443266296

Epoch: 5| Step: 5
Training loss: 2.173254220064762
Validation loss: 2.484509768383976

Epoch: 5| Step: 6
Training loss: 1.9290342267620368
Validation loss: 2.498547696179776

Epoch: 5| Step: 7
Training loss: 2.4194806476409525
Validation loss: 2.517832203595971

Epoch: 5| Step: 8
Training loss: 1.767108665212179
Validation loss: 2.5184187878736246

Epoch: 5| Step: 9
Training loss: 2.3664835773980615
Validation loss: 2.5555705889601037

Epoch: 5| Step: 10
Training loss: 2.6692458038397135
Validation loss: 2.5534366905960932

Epoch: 283| Step: 0
Training loss: 2.2525507984932283
Validation loss: 2.5563692867526475

Epoch: 5| Step: 1
Training loss: 2.049392200710734
Validation loss: 2.5312522686626964

Epoch: 5| Step: 2
Training loss: 2.42924461130642
Validation loss: 2.509996424879453

Epoch: 5| Step: 3
Training loss: 1.6752967400815537
Validation loss: 2.528478545659561

Epoch: 5| Step: 4
Training loss: 2.1795317344656784
Validation loss: 2.5192879625099387

Epoch: 5| Step: 5
Training loss: 2.7171979837067286
Validation loss: 2.5394670445305993

Epoch: 5| Step: 6
Training loss: 2.1705236827908956
Validation loss: 2.5111224118964364

Epoch: 5| Step: 7
Training loss: 2.5423843954655325
Validation loss: 2.540564584737097

Epoch: 5| Step: 8
Training loss: 2.192116688504352
Validation loss: 2.502104173140614

Epoch: 5| Step: 9
Training loss: 1.8094337440665988
Validation loss: 2.506186334918722

Epoch: 5| Step: 10
Training loss: 2.0770474271690267
Validation loss: 2.4905201560104686

Epoch: 284| Step: 0
Training loss: 1.8941660735563912
Validation loss: 2.550220751230281

Epoch: 5| Step: 1
Training loss: 2.1830737427974576
Validation loss: 2.5003327035506446

Epoch: 5| Step: 2
Training loss: 2.348579415648201
Validation loss: 2.4741965510254706

Epoch: 5| Step: 3
Training loss: 2.141280804717041
Validation loss: 2.505337169964501

Epoch: 5| Step: 4
Training loss: 2.223433373796571
Validation loss: 2.527749821131441

Epoch: 5| Step: 5
Training loss: 1.9780488588645682
Validation loss: 2.527819460127346

Epoch: 5| Step: 6
Training loss: 2.097265224843974
Validation loss: 2.535972053518318

Epoch: 5| Step: 7
Training loss: 2.1951098365501083
Validation loss: 2.5338003440802805

Epoch: 5| Step: 8
Training loss: 1.6762256522120729
Validation loss: 2.54542008332387

Epoch: 5| Step: 9
Training loss: 2.7349087439451285
Validation loss: 2.498449406643599

Epoch: 5| Step: 10
Training loss: 2.207286286598791
Validation loss: 2.5226522961475406

Epoch: 285| Step: 0
Training loss: 1.6713602574911983
Validation loss: 2.5556236805365455

Epoch: 5| Step: 1
Training loss: 2.466993455461435
Validation loss: 2.5872585836932314

Epoch: 5| Step: 2
Training loss: 1.9858496885897474
Validation loss: 2.512105571177249

Epoch: 5| Step: 3
Training loss: 2.4110104918787605
Validation loss: 2.5423072123454307

Epoch: 5| Step: 4
Training loss: 1.6654509004280043
Validation loss: 2.5673647967345268

Epoch: 5| Step: 5
Training loss: 2.1448573019228045
Validation loss: 2.5480255763188384

Epoch: 5| Step: 6
Training loss: 2.425765327733071
Validation loss: 2.5499542261978148

Epoch: 5| Step: 7
Training loss: 2.071783270322804
Validation loss: 2.547819126526575

Epoch: 5| Step: 8
Training loss: 2.1063669868377035
Validation loss: 2.5811770394795417

Epoch: 5| Step: 9
Training loss: 2.0941838057039677
Validation loss: 2.605014212888834

Epoch: 5| Step: 10
Training loss: 2.6829006849313446
Validation loss: 2.532675034715295

Epoch: 286| Step: 0
Training loss: 1.64829155877036
Validation loss: 2.5328664556969773

Epoch: 5| Step: 1
Training loss: 2.283222651989584
Validation loss: 2.505692518840431

Epoch: 5| Step: 2
Training loss: 2.8239096740185197
Validation loss: 2.532132041526236

Epoch: 5| Step: 3
Training loss: 2.058813441676582
Validation loss: 2.4857253356257734

Epoch: 5| Step: 4
Training loss: 2.4504514083730293
Validation loss: 2.5204811823132696

Epoch: 5| Step: 5
Training loss: 1.9099233910540587
Validation loss: 2.5504168080315957

Epoch: 5| Step: 6
Training loss: 2.4081995609006475
Validation loss: 2.5194960745381256

Epoch: 5| Step: 7
Training loss: 2.3903068380629153
Validation loss: 2.5240332777879173

Epoch: 5| Step: 8
Training loss: 1.8364125387966441
Validation loss: 2.5311001576694236

Epoch: 5| Step: 9
Training loss: 2.0167907182775724
Validation loss: 2.5263603977733813

Epoch: 5| Step: 10
Training loss: 1.6338589613988743
Validation loss: 2.5117060027968576

Epoch: 287| Step: 0
Training loss: 2.0122801950914115
Validation loss: 2.5639126043241642

Epoch: 5| Step: 1
Training loss: 2.328781342635904
Validation loss: 2.4928889280659416

Epoch: 5| Step: 2
Training loss: 2.213472025654653
Validation loss: 2.5446941113358426

Epoch: 5| Step: 3
Training loss: 2.461664001766442
Validation loss: 2.5407137778248576

Epoch: 5| Step: 4
Training loss: 2.936824315054463
Validation loss: 2.5205785130499794

Epoch: 5| Step: 5
Training loss: 1.739624053417578
Validation loss: 2.5588049570905143

Epoch: 5| Step: 6
Training loss: 2.142683389976264
Validation loss: 2.5270314696096676

Epoch: 5| Step: 7
Training loss: 1.8824363111079767
Validation loss: 2.5140137446997404

Epoch: 5| Step: 8
Training loss: 1.8045135017834852
Validation loss: 2.5009360857924317

Epoch: 5| Step: 9
Training loss: 1.6802222531761564
Validation loss: 2.5287110946816003

Epoch: 5| Step: 10
Training loss: 2.4025555276953887
Validation loss: 2.5597203062589657

Epoch: 288| Step: 0
Training loss: 2.7235522772917564
Validation loss: 2.555233904005952

Epoch: 5| Step: 1
Training loss: 2.227523863864743
Validation loss: 2.537623055646281

Epoch: 5| Step: 2
Training loss: 1.921489894088943
Validation loss: 2.518223233902138

Epoch: 5| Step: 3
Training loss: 2.086606722002181
Validation loss: 2.490832114756437

Epoch: 5| Step: 4
Training loss: 2.0965727950744726
Validation loss: 2.5097751920337457

Epoch: 5| Step: 5
Training loss: 2.232026686778893
Validation loss: 2.5394112326505747

Epoch: 5| Step: 6
Training loss: 1.9406907050516706
Validation loss: 2.518017264681885

Epoch: 5| Step: 7
Training loss: 2.106982987091221
Validation loss: 2.4788128050607403

Epoch: 5| Step: 8
Training loss: 2.011089219043836
Validation loss: 2.5109192682889985

Epoch: 5| Step: 9
Training loss: 2.4247039024249566
Validation loss: 2.487676914037697

Epoch: 5| Step: 10
Training loss: 1.7974047336083505
Validation loss: 2.519154424740566

Epoch: 289| Step: 0
Training loss: 2.2701340628204076
Validation loss: 2.543870206392645

Epoch: 5| Step: 1
Training loss: 2.5325186105328648
Validation loss: 2.548575977713155

Epoch: 5| Step: 2
Training loss: 1.7215100408743769
Validation loss: 2.5204948280051735

Epoch: 5| Step: 3
Training loss: 2.1059499555186316
Validation loss: 2.5187378135399983

Epoch: 5| Step: 4
Training loss: 2.127255196747354
Validation loss: 2.5242938360820375

Epoch: 5| Step: 5
Training loss: 1.7601074835078585
Validation loss: 2.496248505840879

Epoch: 5| Step: 6
Training loss: 1.7410494247555204
Validation loss: 2.5094001504873384

Epoch: 5| Step: 7
Training loss: 2.441967611243354
Validation loss: 2.568909971424044

Epoch: 5| Step: 8
Training loss: 2.0508249623317556
Validation loss: 2.5650416159458627

Epoch: 5| Step: 9
Training loss: 2.6620106780241417
Validation loss: 2.5201053302089393

Epoch: 5| Step: 10
Training loss: 1.7527227338009401
Validation loss: 2.4966844076227845

Epoch: 290| Step: 0
Training loss: 1.9120717809642223
Validation loss: 2.495897665048456

Epoch: 5| Step: 1
Training loss: 1.950711215973079
Validation loss: 2.555248293150685

Epoch: 5| Step: 2
Training loss: 1.840669418343036
Validation loss: 2.513790689091152

Epoch: 5| Step: 3
Training loss: 1.9153334776952105
Validation loss: 2.511497261076166

Epoch: 5| Step: 4
Training loss: 2.183549856655777
Validation loss: 2.4858246232979484

Epoch: 5| Step: 5
Training loss: 2.5160539154801564
Validation loss: 2.489218979484264

Epoch: 5| Step: 6
Training loss: 1.7511154434604486
Validation loss: 2.5045926230262263

Epoch: 5| Step: 7
Training loss: 2.2035944012493056
Validation loss: 2.5560824712028896

Epoch: 5| Step: 8
Training loss: 2.5096837368085385
Validation loss: 2.5363403530055435

Epoch: 5| Step: 9
Training loss: 2.4905570026913226
Validation loss: 2.53274470935172

Epoch: 5| Step: 10
Training loss: 1.995438141477917
Validation loss: 2.539101416807836

Epoch: 291| Step: 0
Training loss: 1.9547501173593846
Validation loss: 2.5064491601795953

Epoch: 5| Step: 1
Training loss: 2.0394746210455565
Validation loss: 2.5202391492076117

Epoch: 5| Step: 2
Training loss: 2.6983641225162898
Validation loss: 2.5116883082774533

Epoch: 5| Step: 3
Training loss: 2.1807802803992367
Validation loss: 2.520042374329997

Epoch: 5| Step: 4
Training loss: 2.0913675902437556
Validation loss: 2.511331215909869

Epoch: 5| Step: 5
Training loss: 1.7298016435544572
Validation loss: 2.50471312878806

Epoch: 5| Step: 6
Training loss: 2.377082112808204
Validation loss: 2.5087880222424723

Epoch: 5| Step: 7
Training loss: 1.9415141330885397
Validation loss: 2.5140911978661697

Epoch: 5| Step: 8
Training loss: 1.889485670073237
Validation loss: 2.5291930864984864

Epoch: 5| Step: 9
Training loss: 2.517075683080318
Validation loss: 2.54716666986368

Epoch: 5| Step: 10
Training loss: 1.7946518787300973
Validation loss: 2.551914692861715

Epoch: 292| Step: 0
Training loss: 2.0512425076512315
Validation loss: 2.550601600572426

Epoch: 5| Step: 1
Training loss: 1.9589360574409604
Validation loss: 2.593468739905862

Epoch: 5| Step: 2
Training loss: 2.6194896081469654
Validation loss: 2.5177971673104267

Epoch: 5| Step: 3
Training loss: 1.7511127204102308
Validation loss: 2.531875015142022

Epoch: 5| Step: 4
Training loss: 1.9809440930183533
Validation loss: 2.562933996361711

Epoch: 5| Step: 5
Training loss: 1.7482644739521473
Validation loss: 2.5496635677437216

Epoch: 5| Step: 6
Training loss: 1.963804906979561
Validation loss: 2.520325035797078

Epoch: 5| Step: 7
Training loss: 2.0687699239180537
Validation loss: 2.5452041278687765

Epoch: 5| Step: 8
Training loss: 1.8270829319998787
Validation loss: 2.524433554678053

Epoch: 5| Step: 9
Training loss: 2.714743105991939
Validation loss: 2.526582875369598

Epoch: 5| Step: 10
Training loss: 2.0899208696343043
Validation loss: 2.5620685137079433

Epoch: 293| Step: 0
Training loss: 2.9152379669367696
Validation loss: 2.5349219459613317

Epoch: 5| Step: 1
Training loss: 2.2392693114619715
Validation loss: 2.5614908523822986

Epoch: 5| Step: 2
Training loss: 1.9035358179729076
Validation loss: 2.536460799817633

Epoch: 5| Step: 3
Training loss: 2.0283382967802246
Validation loss: 2.5591751927147595

Epoch: 5| Step: 4
Training loss: 1.8089831861913404
Validation loss: 2.4746771177039406

Epoch: 5| Step: 5
Training loss: 2.3918874561153936
Validation loss: 2.54979919485033

Epoch: 5| Step: 6
Training loss: 1.7570925446195673
Validation loss: 2.489193719057829

Epoch: 5| Step: 7
Training loss: 1.7192906309704232
Validation loss: 2.505360561846456

Epoch: 5| Step: 8
Training loss: 2.583804077409317
Validation loss: 2.5362911892377586

Epoch: 5| Step: 9
Training loss: 1.7628772250747515
Validation loss: 2.5342297503251627

Epoch: 5| Step: 10
Training loss: 1.7874193933625524
Validation loss: 2.4841122360924213

Epoch: 294| Step: 0
Training loss: 2.1132850858473735
Validation loss: 2.526631142624694

Epoch: 5| Step: 1
Training loss: 2.0658452042144586
Validation loss: 2.50661236793645

Epoch: 5| Step: 2
Training loss: 2.1150894185816806
Validation loss: 2.5289086781373213

Epoch: 5| Step: 3
Training loss: 2.5772219839294914
Validation loss: 2.5578796271869253

Epoch: 5| Step: 4
Training loss: 2.0599112013779273
Validation loss: 2.571274334397867

Epoch: 5| Step: 5
Training loss: 1.7203281439988907
Validation loss: 2.5464363075146874

Epoch: 5| Step: 6
Training loss: 2.474540583038988
Validation loss: 2.5128211296838883

Epoch: 5| Step: 7
Training loss: 1.6498983698670329
Validation loss: 2.5049549897637413

Epoch: 5| Step: 8
Training loss: 1.6713108287346574
Validation loss: 2.498518993227586

Epoch: 5| Step: 9
Training loss: 2.1810290948885216
Validation loss: 2.5113799692259953

Epoch: 5| Step: 10
Training loss: 2.4024498396607954
Validation loss: 2.513007452421903

Epoch: 295| Step: 0
Training loss: 1.8099981338533508
Validation loss: 2.4922361247967517

Epoch: 5| Step: 1
Training loss: 2.4772754689854457
Validation loss: 2.5240130207435834

Epoch: 5| Step: 2
Training loss: 2.0506566182366974
Validation loss: 2.560944825353481

Epoch: 5| Step: 3
Training loss: 1.8711587978197695
Validation loss: 2.5167977227502565

Epoch: 5| Step: 4
Training loss: 1.85637531820804
Validation loss: 2.5117295997183837

Epoch: 5| Step: 5
Training loss: 2.4945056621267807
Validation loss: 2.552457050202663

Epoch: 5| Step: 6
Training loss: 2.1273325291847964
Validation loss: 2.54962521560953

Epoch: 5| Step: 7
Training loss: 2.0803648845030382
Validation loss: 2.560989120549662

Epoch: 5| Step: 8
Training loss: 1.6948011479721161
Validation loss: 2.5546777117974653

Epoch: 5| Step: 9
Training loss: 2.4247402838620364
Validation loss: 2.518996493331948

Epoch: 5| Step: 10
Training loss: 2.4405395922693667
Validation loss: 2.520964246289811

Epoch: 296| Step: 0
Training loss: 2.2139636785599963
Validation loss: 2.524043781037968

Epoch: 5| Step: 1
Training loss: 2.7529410327841335
Validation loss: 2.500564442770615

Epoch: 5| Step: 2
Training loss: 2.3261246248021803
Validation loss: 2.541908204940736

Epoch: 5| Step: 3
Training loss: 2.3389112241418024
Validation loss: 2.4845977722536343

Epoch: 5| Step: 4
Training loss: 1.3057951650942783
Validation loss: 2.536907287621301

Epoch: 5| Step: 5
Training loss: 1.7752081816109546
Validation loss: 2.5452105908392992

Epoch: 5| Step: 6
Training loss: 2.015476783211797
Validation loss: 2.5575094260422757

Epoch: 5| Step: 7
Training loss: 1.3859121636415455
Validation loss: 2.5509312188669657

Epoch: 5| Step: 8
Training loss: 2.39063976009026
Validation loss: 2.53663732021783

Epoch: 5| Step: 9
Training loss: 2.2735315677019217
Validation loss: 2.6233209356510248

Epoch: 5| Step: 10
Training loss: 2.119893052084612
Validation loss: 2.565986042874584

Epoch: 297| Step: 0
Training loss: 1.6084282321636985
Validation loss: 2.5114168538663044

Epoch: 5| Step: 1
Training loss: 1.9137501987330099
Validation loss: 2.5319740842760328

Epoch: 5| Step: 2
Training loss: 1.8741819504515664
Validation loss: 2.5533973632616025

Epoch: 5| Step: 3
Training loss: 2.246486463630354
Validation loss: 2.518778917150749

Epoch: 5| Step: 4
Training loss: 2.700062775765132
Validation loss: 2.5318831980215846

Epoch: 5| Step: 5
Training loss: 2.2679304297741707
Validation loss: 2.5143872100293887

Epoch: 5| Step: 6
Training loss: 2.2511748319676266
Validation loss: 2.5054662257609377

Epoch: 5| Step: 7
Training loss: 1.912911329727965
Validation loss: 2.500318714048114

Epoch: 5| Step: 8
Training loss: 1.7798704192325443
Validation loss: 2.536107173263189

Epoch: 5| Step: 9
Training loss: 2.3948898669188132
Validation loss: 2.5182863004113094

Epoch: 5| Step: 10
Training loss: 2.1180923611582023
Validation loss: 2.5663742153583105

Epoch: 298| Step: 0
Training loss: 1.8551204314300602
Validation loss: 2.5441394365196985

Epoch: 5| Step: 1
Training loss: 2.224476690580514
Validation loss: 2.5162931164078604

Epoch: 5| Step: 2
Training loss: 2.171714721913084
Validation loss: 2.5607478776870014

Epoch: 5| Step: 3
Training loss: 1.8003894437594439
Validation loss: 2.5321710739597876

Epoch: 5| Step: 4
Training loss: 2.933673395327793
Validation loss: 2.596640007076432

Epoch: 5| Step: 5
Training loss: 1.9328432418364447
Validation loss: 2.4808571845069283

Epoch: 5| Step: 6
Training loss: 2.1232567536913542
Validation loss: 2.55217556078382

Epoch: 5| Step: 7
Training loss: 2.181294604176043
Validation loss: 2.5120029440827887

Epoch: 5| Step: 8
Training loss: 2.03108496362303
Validation loss: 2.4925492099704516

Epoch: 5| Step: 9
Training loss: 1.867699397318012
Validation loss: 2.475849718140227

Epoch: 5| Step: 10
Training loss: 1.8026176571903778
Validation loss: 2.5125228892629425

Epoch: 299| Step: 0
Training loss: 2.3428185201412104
Validation loss: 2.539599538444838

Epoch: 5| Step: 1
Training loss: 1.8863382844380783
Validation loss: 2.4992260134740016

Epoch: 5| Step: 2
Training loss: 1.7393138775793144
Validation loss: 2.5623355655650224

Epoch: 5| Step: 3
Training loss: 2.361707128457699
Validation loss: 2.5543277403498528

Epoch: 5| Step: 4
Training loss: 2.1687856973573973
Validation loss: 2.512890972233842

Epoch: 5| Step: 5
Training loss: 2.030455448566474
Validation loss: 2.5371594062884073

Epoch: 5| Step: 6
Training loss: 1.9053529598625827
Validation loss: 2.5292650646560073

Epoch: 5| Step: 7
Training loss: 2.290584539912217
Validation loss: 2.4961205325269784

Epoch: 5| Step: 8
Training loss: 2.224500162794708
Validation loss: 2.5327123299239

Epoch: 5| Step: 9
Training loss: 2.10065222103116
Validation loss: 2.5234718707737187

Epoch: 5| Step: 10
Training loss: 2.045340625403451
Validation loss: 2.5573167590195167

Epoch: 300| Step: 0
Training loss: 2.1486885062889187
Validation loss: 2.4718102267813493

Epoch: 5| Step: 1
Training loss: 2.0318108591301143
Validation loss: 2.5146679666352014

Epoch: 5| Step: 2
Training loss: 1.6339331618638366
Validation loss: 2.498151997528225

Epoch: 5| Step: 3
Training loss: 1.8975280341488658
Validation loss: 2.5393803011248726

Epoch: 5| Step: 4
Training loss: 1.600103914343499
Validation loss: 2.51416093987451

Epoch: 5| Step: 5
Training loss: 2.065572588511041
Validation loss: 2.517225782278567

Epoch: 5| Step: 6
Training loss: 1.9386788135399018
Validation loss: 2.472870921260339

Epoch: 5| Step: 7
Training loss: 2.3853438142759815
Validation loss: 2.4986524847048006

Epoch: 5| Step: 8
Training loss: 2.152136597123478
Validation loss: 2.534573591924838

Epoch: 5| Step: 9
Training loss: 2.2159696539581004
Validation loss: 2.581372427495765

Epoch: 5| Step: 10
Training loss: 2.672323802710061
Validation loss: 2.5065166335341096

Epoch: 301| Step: 0
Training loss: 1.959144715035128
Validation loss: 2.5031596408350087

Epoch: 5| Step: 1
Training loss: 1.8319196524720738
Validation loss: 2.569859406135417

Epoch: 5| Step: 2
Training loss: 1.8846809328648242
Validation loss: 2.4983058234219575

Epoch: 5| Step: 3
Training loss: 1.92484339535296
Validation loss: 2.492704416243347

Epoch: 5| Step: 4
Training loss: 2.3596948065863756
Validation loss: 2.5431630987621534

Epoch: 5| Step: 5
Training loss: 2.1387414372248776
Validation loss: 2.4726633769268958

Epoch: 5| Step: 6
Training loss: 2.043368298644728
Validation loss: 2.5300153554288025

Epoch: 5| Step: 7
Training loss: 2.6541245876871216
Validation loss: 2.539683787120773

Epoch: 5| Step: 8
Training loss: 1.8952814563495177
Validation loss: 2.5628652384873076

Epoch: 5| Step: 9
Training loss: 2.180671934462952
Validation loss: 2.588450374112963

Epoch: 5| Step: 10
Training loss: 1.7223311136884927
Validation loss: 2.5625517605071706

Epoch: 302| Step: 0
Training loss: 2.470398557685273
Validation loss: 2.520709131758029

Epoch: 5| Step: 1
Training loss: 1.824306902501542
Validation loss: 2.564710018711967

Epoch: 5| Step: 2
Training loss: 2.285281238235152
Validation loss: 2.559170897229127

Epoch: 5| Step: 3
Training loss: 2.2882562981752974
Validation loss: 2.5457660347607725

Epoch: 5| Step: 4
Training loss: 2.1364228150012834
Validation loss: 2.553004334249027

Epoch: 5| Step: 5
Training loss: 2.3185032427915035
Validation loss: 2.5541178211855295

Epoch: 5| Step: 6
Training loss: 1.733885412449346
Validation loss: 2.5058565145269105

Epoch: 5| Step: 7
Training loss: 2.6148746120522435
Validation loss: 2.5326171023090756

Epoch: 5| Step: 8
Training loss: 1.314051846019905
Validation loss: 2.5219395291059183

Epoch: 5| Step: 9
Training loss: 1.8167381721679539
Validation loss: 2.5578475724531895

Epoch: 5| Step: 10
Training loss: 1.7251479624440418
Validation loss: 2.5267217094754417

Epoch: 303| Step: 0
Training loss: 1.8146573743229581
Validation loss: 2.5933236084109934

Epoch: 5| Step: 1
Training loss: 2.1852141289790676
Validation loss: 2.503542667525151

Epoch: 5| Step: 2
Training loss: 2.485663793470698
Validation loss: 2.5160392736543606

Epoch: 5| Step: 3
Training loss: 2.2920971437209334
Validation loss: 2.51347454926521

Epoch: 5| Step: 4
Training loss: 1.8257366783829274
Validation loss: 2.4776038247656884

Epoch: 5| Step: 5
Training loss: 1.8215834474299901
Validation loss: 2.549588525763647

Epoch: 5| Step: 6
Training loss: 2.077335293664036
Validation loss: 2.574315209174702

Epoch: 5| Step: 7
Training loss: 1.8835652219873744
Validation loss: 2.4758327717618087

Epoch: 5| Step: 8
Training loss: 2.1280552834450033
Validation loss: 2.5022491920057313

Epoch: 5| Step: 9
Training loss: 2.1318730671297077
Validation loss: 2.460721361051201

Epoch: 5| Step: 10
Training loss: 2.0929546838439355
Validation loss: 2.5223652954194904

Epoch: 304| Step: 0
Training loss: 1.68815035120583
Validation loss: 2.578924343157508

Epoch: 5| Step: 1
Training loss: 2.142159016737722
Validation loss: 2.5660941556853727

Epoch: 5| Step: 2
Training loss: 2.26659146445941
Validation loss: 2.5369279297923675

Epoch: 5| Step: 3
Training loss: 1.8910029640396426
Validation loss: 2.5465078456012797

Epoch: 5| Step: 4
Training loss: 2.1627368378353906
Validation loss: 2.476178858293213

Epoch: 5| Step: 5
Training loss: 1.6325049589820775
Validation loss: 2.480513358851506

Epoch: 5| Step: 6
Training loss: 1.8892470453453003
Validation loss: 2.482776317602416

Epoch: 5| Step: 7
Training loss: 2.2925128646040354
Validation loss: 2.5308623752018105

Epoch: 5| Step: 8
Training loss: 2.0863018503482667
Validation loss: 2.540205532412435

Epoch: 5| Step: 9
Training loss: 2.2871932902851135
Validation loss: 2.5203008917423517

Epoch: 5| Step: 10
Training loss: 2.6432900608107794
Validation loss: 2.4983915825739342

Epoch: 305| Step: 0
Training loss: 1.8031393569559835
Validation loss: 2.531198203041642

Epoch: 5| Step: 1
Training loss: 1.7572759190795786
Validation loss: 2.5036539744128197

Epoch: 5| Step: 2
Training loss: 2.3296529377165136
Validation loss: 2.565200862974399

Epoch: 5| Step: 3
Training loss: 1.9813621657717966
Validation loss: 2.5227056262522978

Epoch: 5| Step: 4
Training loss: 2.62371213292261
Validation loss: 2.499057852712977

Epoch: 5| Step: 5
Training loss: 1.5914746666323252
Validation loss: 2.5328890174308425

Epoch: 5| Step: 6
Training loss: 2.1589308948632806
Validation loss: 2.4952835436288408

Epoch: 5| Step: 7
Training loss: 1.6263768158828418
Validation loss: 2.552365633779204

Epoch: 5| Step: 8
Training loss: 2.524425679222546
Validation loss: 2.4803457319899103

Epoch: 5| Step: 9
Training loss: 1.8576517534454238
Validation loss: 2.516688665228538

Epoch: 5| Step: 10
Training loss: 1.985943152106741
Validation loss: 2.577084142463785

Epoch: 306| Step: 0
Training loss: 2.146989813209677
Validation loss: 2.504683302020388

Epoch: 5| Step: 1
Training loss: 1.6302383793833655
Validation loss: 2.487956933041016

Epoch: 5| Step: 2
Training loss: 1.7174311346160105
Validation loss: 2.594300900608658

Epoch: 5| Step: 3
Training loss: 1.6619041665836454
Validation loss: 2.537545902482196

Epoch: 5| Step: 4
Training loss: 2.1876453896299197
Validation loss: 2.532696174976277

Epoch: 5| Step: 5
Training loss: 1.9623779842082598
Validation loss: 2.525620066037054

Epoch: 5| Step: 6
Training loss: 1.9068349347301918
Validation loss: 2.472064109363527

Epoch: 5| Step: 7
Training loss: 2.354195980013302
Validation loss: 2.506970899409733

Epoch: 5| Step: 8
Training loss: 1.837595544004871
Validation loss: 2.477204893430542

Epoch: 5| Step: 9
Training loss: 2.9539838884104093
Validation loss: 2.4903684958545296

Epoch: 5| Step: 10
Training loss: 1.7816630102155162
Validation loss: 2.4759917655660257

Epoch: 307| Step: 0
Training loss: 1.4549616210175556
Validation loss: 2.5315675929958075

Epoch: 5| Step: 1
Training loss: 1.7965001254252881
Validation loss: 2.602846367308872

Epoch: 5| Step: 2
Training loss: 1.9187345199706058
Validation loss: 2.47045428182008

Epoch: 5| Step: 3
Training loss: 2.7592476630719855
Validation loss: 2.6029796224756496

Epoch: 5| Step: 4
Training loss: 1.772210389811612
Validation loss: 2.4789982220851337

Epoch: 5| Step: 5
Training loss: 1.9180798158516286
Validation loss: 2.5146908353900463

Epoch: 5| Step: 6
Training loss: 1.7943609147696578
Validation loss: 2.5632565874840423

Epoch: 5| Step: 7
Training loss: 2.0098137882196627
Validation loss: 2.544570295790099

Epoch: 5| Step: 8
Training loss: 2.1223631936276326
Validation loss: 2.5601781344910113

Epoch: 5| Step: 9
Training loss: 2.5227878549223286
Validation loss: 2.534150915697597

Epoch: 5| Step: 10
Training loss: 1.8803937262295125
Validation loss: 2.5867961908610355

Epoch: 308| Step: 0
Training loss: 1.9290955288035576
Validation loss: 2.5090781341706037

Epoch: 5| Step: 1
Training loss: 2.242765877058253
Validation loss: 2.563091559950371

Epoch: 5| Step: 2
Training loss: 1.877730035112229
Validation loss: 2.5790199593375154

Epoch: 5| Step: 3
Training loss: 1.4757002477594094
Validation loss: 2.5131516534078573

Epoch: 5| Step: 4
Training loss: 1.6871577021678361
Validation loss: 2.545783933494533

Epoch: 5| Step: 5
Training loss: 2.256965557553907
Validation loss: 2.546201968177215

Epoch: 5| Step: 6
Training loss: 1.8457018978377204
Validation loss: 2.562519088421909

Epoch: 5| Step: 7
Training loss: 2.530253932558216
Validation loss: 2.5068420785652887

Epoch: 5| Step: 8
Training loss: 3.1489882827497184
Validation loss: 2.4817314310529897

Epoch: 5| Step: 9
Training loss: 1.330804388479548
Validation loss: 2.5661698251495233

Epoch: 5| Step: 10
Training loss: 1.907561804493859
Validation loss: 2.544757999201503

Epoch: 309| Step: 0
Training loss: 2.1607176342682637
Validation loss: 2.5595179328010187

Epoch: 5| Step: 1
Training loss: 1.6400885295233523
Validation loss: 2.4614826422218625

Epoch: 5| Step: 2
Training loss: 2.050910524199309
Validation loss: 2.5280584969917785

Epoch: 5| Step: 3
Training loss: 1.5997850184255487
Validation loss: 2.5283530097751865

Epoch: 5| Step: 4
Training loss: 2.4933202196310145
Validation loss: 2.5230313272025104

Epoch: 5| Step: 5
Training loss: 2.0134902413384905
Validation loss: 2.534384988060793

Epoch: 5| Step: 6
Training loss: 1.7477320552751021
Validation loss: 2.5087515332506864

Epoch: 5| Step: 7
Training loss: 2.5705241664009444
Validation loss: 2.537815865158651

Epoch: 5| Step: 8
Training loss: 2.2376269171324963
Validation loss: 2.5181072515375

Epoch: 5| Step: 9
Training loss: 1.9878038234128528
Validation loss: 2.5452904688388185

Epoch: 5| Step: 10
Training loss: 1.9609495367767402
Validation loss: 2.511304840603215

Epoch: 310| Step: 0
Training loss: 2.1396182400667456
Validation loss: 2.5971889517481435

Epoch: 5| Step: 1
Training loss: 2.1495396232067554
Validation loss: 2.562661116622464

Epoch: 5| Step: 2
Training loss: 2.3364175666816145
Validation loss: 2.592878658624646

Epoch: 5| Step: 3
Training loss: 1.7058045892323417
Validation loss: 2.5000019124751827

Epoch: 5| Step: 4
Training loss: 1.8254854105416296
Validation loss: 2.5173058799499928

Epoch: 5| Step: 5
Training loss: 1.3743346078166532
Validation loss: 2.5687574922968204

Epoch: 5| Step: 6
Training loss: 2.0863116782403837
Validation loss: 2.5285688628305754

Epoch: 5| Step: 7
Training loss: 1.6426757348050793
Validation loss: 2.5025159880826355

Epoch: 5| Step: 8
Training loss: 2.393489941048508
Validation loss: 2.518523344081473

Epoch: 5| Step: 9
Training loss: 2.4297767941665374
Validation loss: 2.4915076656918993

Epoch: 5| Step: 10
Training loss: 1.9911896244721317
Validation loss: 2.462768276328591

Epoch: 311| Step: 0
Training loss: 2.0812731538234996
Validation loss: 2.4995518067286975

Epoch: 5| Step: 1
Training loss: 2.4014267574707713
Validation loss: 2.5623670684085846

Epoch: 5| Step: 2
Training loss: 2.2025113164154204
Validation loss: 2.528793565518208

Epoch: 5| Step: 3
Training loss: 2.1556210913751284
Validation loss: 2.480886370806181

Epoch: 5| Step: 4
Training loss: 1.8775760756113857
Validation loss: 2.513918575653276

Epoch: 5| Step: 5
Training loss: 2.2835901876990152
Validation loss: 2.4884731374373747

Epoch: 5| Step: 6
Training loss: 2.1637309677723837
Validation loss: 2.5408445878326598

Epoch: 5| Step: 7
Training loss: 1.187602440280405
Validation loss: 2.5137276189169198

Epoch: 5| Step: 8
Training loss: 1.6536247752693607
Validation loss: 2.4630535736349435

Epoch: 5| Step: 9
Training loss: 2.272049207973848
Validation loss: 2.561638104634111

Epoch: 5| Step: 10
Training loss: 1.8050613346404507
Validation loss: 2.465920849706727

Epoch: 312| Step: 0
Training loss: 2.049798173971309
Validation loss: 2.4939704175446686

Epoch: 5| Step: 1
Training loss: 2.606069881518137
Validation loss: 2.5380616452365152

Epoch: 5| Step: 2
Training loss: 1.4619262124004548
Validation loss: 2.5432247131778674

Epoch: 5| Step: 3
Training loss: 1.772933216070027
Validation loss: 2.489714814463009

Epoch: 5| Step: 4
Training loss: 1.8708366583757086
Validation loss: 2.552635095722966

Epoch: 5| Step: 5
Training loss: 1.3113849081018378
Validation loss: 2.487894233253512

Epoch: 5| Step: 6
Training loss: 2.2670882136913963
Validation loss: 2.54099271874206

Epoch: 5| Step: 7
Training loss: 2.3678755059379903
Validation loss: 2.5252921579618723

Epoch: 5| Step: 8
Training loss: 1.8410773869318016
Validation loss: 2.4597128685001

Epoch: 5| Step: 9
Training loss: 1.8624112639314327
Validation loss: 2.556800816397117

Epoch: 5| Step: 10
Training loss: 2.285949047839082
Validation loss: 2.5459595940166952

Epoch: 313| Step: 0
Training loss: 2.0848915249350144
Validation loss: 2.493747323470358

Epoch: 5| Step: 1
Training loss: 1.8259781188990853
Validation loss: 2.548360164451212

Epoch: 5| Step: 2
Training loss: 1.7822361274358058
Validation loss: 2.5618762085664812

Epoch: 5| Step: 3
Training loss: 2.5018395331844703
Validation loss: 2.4660724290643508

Epoch: 5| Step: 4
Training loss: 2.2141833523413648
Validation loss: 2.5589672701158697

Epoch: 5| Step: 5
Training loss: 2.3346552056351317
Validation loss: 2.4995506518576467

Epoch: 5| Step: 6
Training loss: 2.178509575101986
Validation loss: 2.4909265489909096

Epoch: 5| Step: 7
Training loss: 1.9762176092148727
Validation loss: 2.576950720146809

Epoch: 5| Step: 8
Training loss: 1.6785978819551153
Validation loss: 2.464769407948325

Epoch: 5| Step: 9
Training loss: 1.7552085748176145
Validation loss: 2.519404084873445

Epoch: 5| Step: 10
Training loss: 1.727679620505205
Validation loss: 2.5192663830807662

Epoch: 314| Step: 0
Training loss: 2.233804483202871
Validation loss: 2.5108833003547466

Epoch: 5| Step: 1
Training loss: 1.7112115788517899
Validation loss: 2.5830454826418903

Epoch: 5| Step: 2
Training loss: 1.8502647262047
Validation loss: 2.5243200563774835

Epoch: 5| Step: 3
Training loss: 2.1434946247279916
Validation loss: 2.571523980875546

Epoch: 5| Step: 4
Training loss: 1.818420081349367
Validation loss: 2.6358982850551484

Epoch: 5| Step: 5
Training loss: 2.2273093593890083
Validation loss: 2.586540229501268

Epoch: 5| Step: 6
Training loss: 1.9073276912912875
Validation loss: 2.484792370782541

Epoch: 5| Step: 7
Training loss: 2.564665646837014
Validation loss: 2.5064792830034945

Epoch: 5| Step: 8
Training loss: 2.056692327445442
Validation loss: 2.5073466325234492

Epoch: 5| Step: 9
Training loss: 1.5947568368461702
Validation loss: 2.4673717042302274

Epoch: 5| Step: 10
Training loss: 2.022359081965587
Validation loss: 2.5622677601507005

Epoch: 315| Step: 0
Training loss: 2.9585068521966664
Validation loss: 2.530314731633365

Epoch: 5| Step: 1
Training loss: 2.0467721461888
Validation loss: 2.537436662222227

Epoch: 5| Step: 2
Training loss: 1.9252925353275887
Validation loss: 2.544983493172712

Epoch: 5| Step: 3
Training loss: 2.088069098100243
Validation loss: 2.531915859410807

Epoch: 5| Step: 4
Training loss: 2.163877072980116
Validation loss: 2.5330787594197495

Epoch: 5| Step: 5
Training loss: 2.0140089313494665
Validation loss: 2.5155877281469303

Epoch: 5| Step: 6
Training loss: 1.7568382445527515
Validation loss: 2.500966580486293

Epoch: 5| Step: 7
Training loss: 2.0280391257610577
Validation loss: 2.5366085348545075

Epoch: 5| Step: 8
Training loss: 1.685831304534179
Validation loss: 2.4925625400886604

Epoch: 5| Step: 9
Training loss: 1.9386170151415891
Validation loss: 2.5007330711830438

Epoch: 5| Step: 10
Training loss: 1.4887108370532751
Validation loss: 2.4992672461644436

Epoch: 316| Step: 0
Training loss: 2.64338179023972
Validation loss: 2.513468814029998

Epoch: 5| Step: 1
Training loss: 1.8443242488071774
Validation loss: 2.568393926170903

Epoch: 5| Step: 2
Training loss: 2.1276460890139686
Validation loss: 2.566224569556278

Epoch: 5| Step: 3
Training loss: 1.6944039015097363
Validation loss: 2.5384627610309862

Epoch: 5| Step: 4
Training loss: 2.3137044089929906
Validation loss: 2.4476809812116933

Epoch: 5| Step: 5
Training loss: 1.8971227795126109
Validation loss: 2.538148027670873

Epoch: 5| Step: 6
Training loss: 1.7986699965700432
Validation loss: 2.4813942890818645

Epoch: 5| Step: 7
Training loss: 1.6068543629339311
Validation loss: 2.5437873672103497

Epoch: 5| Step: 8
Training loss: 2.604384624261103
Validation loss: 2.5276445217843895

Epoch: 5| Step: 9
Training loss: 1.5026499070776123
Validation loss: 2.5530755306474964

Epoch: 5| Step: 10
Training loss: 2.1107467147257593
Validation loss: 2.5409762754244696

Epoch: 317| Step: 0
Training loss: 2.5296846423919352
Validation loss: 2.5349189989462704

Epoch: 5| Step: 1
Training loss: 1.3085811329703088
Validation loss: 2.5225262050604353

Epoch: 5| Step: 2
Training loss: 2.3149083973370357
Validation loss: 2.5169666880202435

Epoch: 5| Step: 3
Training loss: 2.408232132612452
Validation loss: 2.5628197023100525

Epoch: 5| Step: 4
Training loss: 1.8784005164537256
Validation loss: 2.4857241299830637

Epoch: 5| Step: 5
Training loss: 1.403756962365729
Validation loss: 2.548380100199881

Epoch: 5| Step: 6
Training loss: 1.713290890911372
Validation loss: 2.4965551011835094

Epoch: 5| Step: 7
Training loss: 2.2237588999989875
Validation loss: 2.5449957513535004

Epoch: 5| Step: 8
Training loss: 2.150187719267408
Validation loss: 2.532324144381543

Epoch: 5| Step: 9
Training loss: 1.7209819520162464
Validation loss: 2.55096847831235

Epoch: 5| Step: 10
Training loss: 2.2162021460963484
Validation loss: 2.5214358079073493

Epoch: 318| Step: 0
Training loss: 1.8773373975578842
Validation loss: 2.531884070327238

Epoch: 5| Step: 1
Training loss: 1.9584438076377275
Validation loss: 2.5457364850596007

Epoch: 5| Step: 2
Training loss: 1.7897199730302513
Validation loss: 2.5492411722795723

Epoch: 5| Step: 3
Training loss: 2.089660978792163
Validation loss: 2.4824699397912298

Epoch: 5| Step: 4
Training loss: 2.0372495813297933
Validation loss: 2.515990795560765

Epoch: 5| Step: 5
Training loss: 1.9489174650125407
Validation loss: 2.5199597244214975

Epoch: 5| Step: 6
Training loss: 2.0913516300038655
Validation loss: 2.517377487165184

Epoch: 5| Step: 7
Training loss: 2.4103786174262547
Validation loss: 2.5376745184090876

Epoch: 5| Step: 8
Training loss: 1.551914982551437
Validation loss: 2.5603024563880417

Epoch: 5| Step: 9
Training loss: 1.9762446332613746
Validation loss: 2.525701727837598

Epoch: 5| Step: 10
Training loss: 2.6041743367400065
Validation loss: 2.534850395937532

Epoch: 319| Step: 0
Training loss: 1.6422451194287646
Validation loss: 2.536666719719811

Epoch: 5| Step: 1
Training loss: 2.6822135741090807
Validation loss: 2.543770033919808

Epoch: 5| Step: 2
Training loss: 2.1756052600082323
Validation loss: 2.4602769086496385

Epoch: 5| Step: 3
Training loss: 1.6801764198042597
Validation loss: 2.5403916785287812

Epoch: 5| Step: 4
Training loss: 2.0800326203576014
Validation loss: 2.476348173086019

Epoch: 5| Step: 5
Training loss: 1.9344220477716412
Validation loss: 2.5304410212171593

Epoch: 5| Step: 6
Training loss: 1.5654950238334253
Validation loss: 2.6078895465599023

Epoch: 5| Step: 7
Training loss: 1.5943687584192956
Validation loss: 2.4865365119199394

Epoch: 5| Step: 8
Training loss: 2.2525389439543018
Validation loss: 2.5039759132495707

Epoch: 5| Step: 9
Training loss: 2.368209769210981
Validation loss: 2.4870179582038148

Epoch: 5| Step: 10
Training loss: 1.9719926076599597
Validation loss: 2.520586891775873

Epoch: 320| Step: 0
Training loss: 1.8092334514059818
Validation loss: 2.5557917265382493

Epoch: 5| Step: 1
Training loss: 2.0629842940974785
Validation loss: 2.5001772438304632

Epoch: 5| Step: 2
Training loss: 1.6493654938453144
Validation loss: 2.5051740884033946

Epoch: 5| Step: 3
Training loss: 1.6696914246141936
Validation loss: 2.5132736042375408

Epoch: 5| Step: 4
Training loss: 1.9055350792207604
Validation loss: 2.5606615873665954

Epoch: 5| Step: 5
Training loss: 2.6774852366890816
Validation loss: 2.567495076169321

Epoch: 5| Step: 6
Training loss: 1.8394130842574088
Validation loss: 2.5409236839398535

Epoch: 5| Step: 7
Training loss: 2.6133088023468143
Validation loss: 2.4867384504759187

Epoch: 5| Step: 8
Training loss: 1.7767948854186444
Validation loss: 2.499751199626931

Epoch: 5| Step: 9
Training loss: 2.1290128628694736
Validation loss: 2.5734863534029198

Epoch: 5| Step: 10
Training loss: 1.5879826630479532
Validation loss: 2.5535157600935436

Epoch: 321| Step: 0
Training loss: 1.666327998402625
Validation loss: 2.4726364367449927

Epoch: 5| Step: 1
Training loss: 1.7169619189056844
Validation loss: 2.4796037747913013

Epoch: 5| Step: 2
Training loss: 1.6568750605516627
Validation loss: 2.5316398859144407

Epoch: 5| Step: 3
Training loss: 2.000411229771469
Validation loss: 2.522606638755396

Epoch: 5| Step: 4
Training loss: 2.196609602588795
Validation loss: 2.501789336615764

Epoch: 5| Step: 5
Training loss: 1.9111262629829968
Validation loss: 2.5250109520927153

Epoch: 5| Step: 6
Training loss: 2.2046176912866065
Validation loss: 2.481314017566044

Epoch: 5| Step: 7
Training loss: 1.7199911318040269
Validation loss: 2.6099183220196633

Epoch: 5| Step: 8
Training loss: 2.71216311494247
Validation loss: 2.498863084754339

Epoch: 5| Step: 9
Training loss: 1.6472101207172123
Validation loss: 2.513542117571598

Epoch: 5| Step: 10
Training loss: 2.258407356015643
Validation loss: 2.570169508147904

Epoch: 322| Step: 0
Training loss: 2.6574192839428608
Validation loss: 2.504101639242294

Epoch: 5| Step: 1
Training loss: 2.1671632662231612
Validation loss: 2.550273130886856

Epoch: 5| Step: 2
Training loss: 1.4671016127662722
Validation loss: 2.5282314293801753

Epoch: 5| Step: 3
Training loss: 1.7207764903263973
Validation loss: 2.506966082936197

Epoch: 5| Step: 4
Training loss: 2.0417044759350516
Validation loss: 2.532853943468493

Epoch: 5| Step: 5
Training loss: 1.9169501495804637
Validation loss: 2.5496160140380377

Epoch: 5| Step: 6
Training loss: 1.8338877822090411
Validation loss: 2.5223434191113974

Epoch: 5| Step: 7
Training loss: 1.6525534638774961
Validation loss: 2.505307230902092

Epoch: 5| Step: 8
Training loss: 2.141447257394207
Validation loss: 2.547159591367461

Epoch: 5| Step: 9
Training loss: 2.0266878981900303
Validation loss: 2.543581005807033

Epoch: 5| Step: 10
Training loss: 1.6497634689259881
Validation loss: 2.526729363692203

Epoch: 323| Step: 0
Training loss: 2.2931790880887624
Validation loss: 2.5131744043700657

Epoch: 5| Step: 1
Training loss: 1.8735889211361314
Validation loss: 2.5206670761368866

Epoch: 5| Step: 2
Training loss: 1.8485939920564063
Validation loss: 2.4815206715506632

Epoch: 5| Step: 3
Training loss: 2.0318089816428415
Validation loss: 2.5854573282506252

Epoch: 5| Step: 4
Training loss: 1.9403904919056578
Validation loss: 2.554069858576555

Epoch: 5| Step: 5
Training loss: 2.361550042237036
Validation loss: 2.5583757585852616

Epoch: 5| Step: 6
Training loss: 2.059682829430085
Validation loss: 2.5379800735487907

Epoch: 5| Step: 7
Training loss: 1.8138452339014475
Validation loss: 2.547404725557843

Epoch: 5| Step: 8
Training loss: 1.8991950136786084
Validation loss: 2.4637916053293294

Epoch: 5| Step: 9
Training loss: 1.5526989051078435
Validation loss: 2.5472536387509543

Epoch: 5| Step: 10
Training loss: 2.0432115924697527
Validation loss: 2.46738549298356

Epoch: 324| Step: 0
Training loss: 1.5287803664353548
Validation loss: 2.5167067585357925

Epoch: 5| Step: 1
Training loss: 2.075875807544172
Validation loss: 2.5723889082673996

Epoch: 5| Step: 2
Training loss: 1.891758791603015
Validation loss: 2.5630064613117094

Epoch: 5| Step: 3
Training loss: 1.65396031871093
Validation loss: 2.4947677670418016

Epoch: 5| Step: 4
Training loss: 2.1058897259307674
Validation loss: 2.542306083955245

Epoch: 5| Step: 5
Training loss: 1.8987520687250214
Validation loss: 2.4987161067302317

Epoch: 5| Step: 6
Training loss: 1.8412282476545208
Validation loss: 2.512705319338935

Epoch: 5| Step: 7
Training loss: 2.1063528381054706
Validation loss: 2.5066466227060378

Epoch: 5| Step: 8
Training loss: 1.9247101751355356
Validation loss: 2.474145473964642

Epoch: 5| Step: 9
Training loss: 1.9467250490687567
Validation loss: 2.4854170680884904

Epoch: 5| Step: 10
Training loss: 2.6956590512603946
Validation loss: 2.533685105636576

Epoch: 325| Step: 0
Training loss: 1.7320764792958783
Validation loss: 2.511291833025223

Epoch: 5| Step: 1
Training loss: 2.061812893249239
Validation loss: 2.549086390226795

Epoch: 5| Step: 2
Training loss: 2.443501835000614
Validation loss: 2.4984361310212972

Epoch: 5| Step: 3
Training loss: 1.3081527650149316
Validation loss: 2.560654394998701

Epoch: 5| Step: 4
Training loss: 2.199130285187867
Validation loss: 2.5997418849167464

Epoch: 5| Step: 5
Training loss: 2.20020062225419
Validation loss: 2.5053332605519048

Epoch: 5| Step: 6
Training loss: 1.8533381064557055
Validation loss: 2.513555365426181

Epoch: 5| Step: 7
Training loss: 1.9205673234933565
Validation loss: 2.518977076629107

Epoch: 5| Step: 8
Training loss: 1.8136543675665675
Validation loss: 2.480576161487846

Epoch: 5| Step: 9
Training loss: 2.0271775723304364
Validation loss: 2.509272943435333

Epoch: 5| Step: 10
Training loss: 1.7014257370814339
Validation loss: 2.5161197384519873

Epoch: 326| Step: 0
Training loss: 1.6451424303397337
Validation loss: 2.4665654637956087

Epoch: 5| Step: 1
Training loss: 2.119339978382356
Validation loss: 2.47513438554261

Epoch: 5| Step: 2
Training loss: 1.5846854844303362
Validation loss: 2.5513000870178177

Epoch: 5| Step: 3
Training loss: 1.8523703313792237
Validation loss: 2.475346197827125

Epoch: 5| Step: 4
Training loss: 1.808729261425738
Validation loss: 2.4749727631519645

Epoch: 5| Step: 5
Training loss: 2.0797202505374623
Validation loss: 2.4996472068759386

Epoch: 5| Step: 6
Training loss: 2.6914716250337505
Validation loss: 2.5128843582962315

Epoch: 5| Step: 7
Training loss: 1.4992245418084857
Validation loss: 2.5235252170828475

Epoch: 5| Step: 8
Training loss: 1.8461324525473877
Validation loss: 2.504926979411009

Epoch: 5| Step: 9
Training loss: 1.9513348119022218
Validation loss: 2.5311728277966865

Epoch: 5| Step: 10
Training loss: 2.4209686552253706
Validation loss: 2.53771847222335

Epoch: 327| Step: 0
Training loss: 1.998414006814668
Validation loss: 2.5229479277583953

Epoch: 5| Step: 1
Training loss: 1.9724122151420707
Validation loss: 2.4780291764528224

Epoch: 5| Step: 2
Training loss: 2.4350759728582
Validation loss: 2.521445992555438

Epoch: 5| Step: 3
Training loss: 1.706530045663694
Validation loss: 2.598753013016213

Epoch: 5| Step: 4
Training loss: 1.9705132354198907
Validation loss: 2.495590301694287

Epoch: 5| Step: 5
Training loss: 1.4169903366739292
Validation loss: 2.50788690523533

Epoch: 5| Step: 6
Training loss: 2.03206688520783
Validation loss: 2.541200007609356

Epoch: 5| Step: 7
Training loss: 1.5967916746851325
Validation loss: 2.537376952207464

Epoch: 5| Step: 8
Training loss: 1.857025136203355
Validation loss: 2.548737972521047

Epoch: 5| Step: 9
Training loss: 1.923633980031724
Validation loss: 2.5283557413732325

Epoch: 5| Step: 10
Training loss: 2.632157331952976
Validation loss: 2.495108511587193

Epoch: 328| Step: 0
Training loss: 2.15098636977924
Validation loss: 2.5174557617539675

Epoch: 5| Step: 1
Training loss: 1.3586689222443127
Validation loss: 2.539753961933729

Epoch: 5| Step: 2
Training loss: 2.2248244612810253
Validation loss: 2.579345450050343

Epoch: 5| Step: 3
Training loss: 1.8666644141773985
Validation loss: 2.5422568366473954

Epoch: 5| Step: 4
Training loss: 1.7320223823977654
Validation loss: 2.465395888193785

Epoch: 5| Step: 5
Training loss: 2.787525683229101
Validation loss: 2.5243514903118234

Epoch: 5| Step: 6
Training loss: 1.8173828780939336
Validation loss: 2.5228288498676714

Epoch: 5| Step: 7
Training loss: 1.8165276599629305
Validation loss: 2.4966609067272802

Epoch: 5| Step: 8
Training loss: 2.2081605975652887
Validation loss: 2.5056922814750515

Epoch: 5| Step: 9
Training loss: 1.6234341927018314
Validation loss: 2.556016790721328

Epoch: 5| Step: 10
Training loss: 1.528401040574583
Validation loss: 2.4742997132251547

Epoch: 329| Step: 0
Training loss: 2.2652402353778305
Validation loss: 2.532814481264212

Epoch: 5| Step: 1
Training loss: 1.7766289583657402
Validation loss: 2.515111826162995

Epoch: 5| Step: 2
Training loss: 1.959948225602617
Validation loss: 2.542840536949504

Epoch: 5| Step: 3
Training loss: 2.0383652704481214
Validation loss: 2.5265099458769233

Epoch: 5| Step: 4
Training loss: 1.7222590604896229
Validation loss: 2.5337055671427433

Epoch: 5| Step: 5
Training loss: 1.692810603255684
Validation loss: 2.526317676163504

Epoch: 5| Step: 6
Training loss: 1.6412483847523722
Validation loss: 2.4953511483545516

Epoch: 5| Step: 7
Training loss: 2.4694292124033037
Validation loss: 2.5197513190089276

Epoch: 5| Step: 8
Training loss: 2.0280187875829223
Validation loss: 2.538268421024413

Epoch: 5| Step: 9
Training loss: 2.4147061474439115
Validation loss: 2.573471582089915

Epoch: 5| Step: 10
Training loss: 1.6186145622711694
Validation loss: 2.5217896975125518

Epoch: 330| Step: 0
Training loss: 1.7109075395582416
Validation loss: 2.531591198205787

Epoch: 5| Step: 1
Training loss: 2.0766255411491685
Validation loss: 2.536170959533242

Epoch: 5| Step: 2
Training loss: 1.793725678814013
Validation loss: 2.502963426263739

Epoch: 5| Step: 3
Training loss: 1.4836358890505064
Validation loss: 2.544669386991953

Epoch: 5| Step: 4
Training loss: 2.643124633125141
Validation loss: 2.555301936195503

Epoch: 5| Step: 5
Training loss: 1.8884773351446993
Validation loss: 2.509803952926394

Epoch: 5| Step: 6
Training loss: 1.6193771649680762
Validation loss: 2.4994446947838243

Epoch: 5| Step: 7
Training loss: 2.047855753751076
Validation loss: 2.5315006718897695

Epoch: 5| Step: 8
Training loss: 1.777864082380684
Validation loss: 2.518577772382693

Epoch: 5| Step: 9
Training loss: 2.333259195330689
Validation loss: 2.5097951441767297

Epoch: 5| Step: 10
Training loss: 1.7473553019416959
Validation loss: 2.570363343176665

Epoch: 331| Step: 0
Training loss: 1.9668479086989337
Validation loss: 2.5889875750444773

Epoch: 5| Step: 1
Training loss: 1.7337583528192326
Validation loss: 2.489954769644408

Epoch: 5| Step: 2
Training loss: 2.564310318281948
Validation loss: 2.5004381380389753

Epoch: 5| Step: 3
Training loss: 1.7184232921467375
Validation loss: 2.487917443941159

Epoch: 5| Step: 4
Training loss: 1.8845926946654485
Validation loss: 2.544674492770241

Epoch: 5| Step: 5
Training loss: 1.5346681241051465
Validation loss: 2.5156375204712416

Epoch: 5| Step: 6
Training loss: 1.4212082357988796
Validation loss: 2.55288556172176

Epoch: 5| Step: 7
Training loss: 2.0413903289419335
Validation loss: 2.5558914800053163

Epoch: 5| Step: 8
Training loss: 2.082374759127466
Validation loss: 2.5455414339264095

Epoch: 5| Step: 9
Training loss: 2.0704199421191958
Validation loss: 2.5165200047364786

Epoch: 5| Step: 10
Training loss: 1.9808842149853434
Validation loss: 2.541900392703127

Epoch: 332| Step: 0
Training loss: 1.4640078181230005
Validation loss: 2.4814644407166013

Epoch: 5| Step: 1
Training loss: 1.376503122804912
Validation loss: 2.541090508781456

Epoch: 5| Step: 2
Training loss: 1.355723772051651
Validation loss: 2.515797458251283

Epoch: 5| Step: 3
Training loss: 1.940691073608941
Validation loss: 2.5196489494058785

Epoch: 5| Step: 4
Training loss: 2.3819264249673036
Validation loss: 2.5358016487286372

Epoch: 5| Step: 5
Training loss: 2.19118810101663
Validation loss: 2.503165686455172

Epoch: 5| Step: 6
Training loss: 1.7382399650557294
Validation loss: 2.515500188304596

Epoch: 5| Step: 7
Training loss: 2.5380008297220713
Validation loss: 2.6273677526921495

Epoch: 5| Step: 8
Training loss: 2.164258927337329
Validation loss: 2.4859971740469393

Epoch: 5| Step: 9
Training loss: 1.8791045720681256
Validation loss: 2.5088035197868828

Epoch: 5| Step: 10
Training loss: 1.8215140114307387
Validation loss: 2.5423881223641325

Epoch: 333| Step: 0
Training loss: 2.027568826694883
Validation loss: 2.505649493951797

Epoch: 5| Step: 1
Training loss: 1.6761446472104347
Validation loss: 2.5157453166438652

Epoch: 5| Step: 2
Training loss: 1.7108146588544575
Validation loss: 2.484892131106366

Epoch: 5| Step: 3
Training loss: 1.7884520442890492
Validation loss: 2.519781415074432

Epoch: 5| Step: 4
Training loss: 1.8928853544410378
Validation loss: 2.5557138148177865

Epoch: 5| Step: 5
Training loss: 1.4932288884922278
Validation loss: 2.550500463681097

Epoch: 5| Step: 6
Training loss: 1.90885684510616
Validation loss: 2.584037534601462

Epoch: 5| Step: 7
Training loss: 2.5828927084762454
Validation loss: 2.586836652084088

Epoch: 5| Step: 8
Training loss: 1.7393774797844763
Validation loss: 2.5246725881974417

Epoch: 5| Step: 9
Training loss: 2.3761551707939694
Validation loss: 2.4964723329625906

Epoch: 5| Step: 10
Training loss: 1.9775127192496922
Validation loss: 2.501443718821595

Epoch: 334| Step: 0
Training loss: 2.365510251929516
Validation loss: 2.519935420195705

Epoch: 5| Step: 1
Training loss: 2.023492760805792
Validation loss: 2.5452946024230805

Epoch: 5| Step: 2
Training loss: 1.7264250273369124
Validation loss: 2.5481755956929786

Epoch: 5| Step: 3
Training loss: 1.8023545018914235
Validation loss: 2.5888693304125705

Epoch: 5| Step: 4
Training loss: 2.1747232326812136
Validation loss: 2.5416226513496127

Epoch: 5| Step: 5
Training loss: 1.5387104231999709
Validation loss: 2.5408433084560462

Epoch: 5| Step: 6
Training loss: 2.099652297889746
Validation loss: 2.5643069051712604

Epoch: 5| Step: 7
Training loss: 1.9536364686748786
Validation loss: 2.494830500628259

Epoch: 5| Step: 8
Training loss: 1.70818214988087
Validation loss: 2.595014947411962

Epoch: 5| Step: 9
Training loss: 1.8478085090210896
Validation loss: 2.476796109266949

Epoch: 5| Step: 10
Training loss: 1.7984258841927427
Validation loss: 2.4843455905144873

Epoch: 335| Step: 0
Training loss: 1.5307122668198372
Validation loss: 2.535284431003349

Epoch: 5| Step: 1
Training loss: 2.0656605404380346
Validation loss: 2.5253203779379163

Epoch: 5| Step: 2
Training loss: 2.2100696815103698
Validation loss: 2.456737435857474

Epoch: 5| Step: 3
Training loss: 2.0286020479059736
Validation loss: 2.530194440087941

Epoch: 5| Step: 4
Training loss: 2.0455387791715722
Validation loss: 2.519654548479014

Epoch: 5| Step: 5
Training loss: 2.5327936810706833
Validation loss: 2.5043348917795356

Epoch: 5| Step: 6
Training loss: 1.694021550893783
Validation loss: 2.468733328880719

Epoch: 5| Step: 7
Training loss: 1.8672675590430108
Validation loss: 2.509922416178241

Epoch: 5| Step: 8
Training loss: 1.7032706522124164
Validation loss: 2.5191878464817736

Epoch: 5| Step: 9
Training loss: 2.0162535877515135
Validation loss: 2.479738896559931

Epoch: 5| Step: 10
Training loss: 1.2930272483845815
Validation loss: 2.4718383977183356

Epoch: 336| Step: 0
Training loss: 2.3727345955794488
Validation loss: 2.4820513165478126

Epoch: 5| Step: 1
Training loss: 2.4966189409523474
Validation loss: 2.571501709265312

Epoch: 5| Step: 2
Training loss: 1.656702015932659
Validation loss: 2.528948340167901

Epoch: 5| Step: 3
Training loss: 1.7479806557158915
Validation loss: 2.544281413584813

Epoch: 5| Step: 4
Training loss: 1.6552300821663577
Validation loss: 2.585522377850434

Epoch: 5| Step: 5
Training loss: 1.9762987405652614
Validation loss: 2.570155514746975

Epoch: 5| Step: 6
Training loss: 1.5047216013433975
Validation loss: 2.5583005099448792

Epoch: 5| Step: 7
Training loss: 1.7310400852782728
Validation loss: 2.5462259995332106

Epoch: 5| Step: 8
Training loss: 2.206462091296188
Validation loss: 2.505147715301136

Epoch: 5| Step: 9
Training loss: 1.4776383774402493
Validation loss: 2.56479970673114

Epoch: 5| Step: 10
Training loss: 2.334332479270958
Validation loss: 2.537061283850936

Epoch: 337| Step: 0
Training loss: 1.7817501236032525
Validation loss: 2.5314253271979155

Epoch: 5| Step: 1
Training loss: 1.656339247116389
Validation loss: 2.463445046587194

Epoch: 5| Step: 2
Training loss: 1.6362497754894596
Validation loss: 2.5150295129312137

Epoch: 5| Step: 3
Training loss: 1.8755188541954535
Validation loss: 2.538699179024086

Epoch: 5| Step: 4
Training loss: 1.7698649582291388
Validation loss: 2.559987653146856

Epoch: 5| Step: 5
Training loss: 1.6663247075542809
Validation loss: 2.5658673996727726

Epoch: 5| Step: 6
Training loss: 1.7927882284403536
Validation loss: 2.4512782160530224

Epoch: 5| Step: 7
Training loss: 2.5040789706784494
Validation loss: 2.526145358674854

Epoch: 5| Step: 8
Training loss: 1.9068004251236759
Validation loss: 2.5615785504229316

Epoch: 5| Step: 9
Training loss: 2.1879640359520605
Validation loss: 2.5432654674061124

Epoch: 5| Step: 10
Training loss: 2.024220672217825
Validation loss: 2.48667702617971

Epoch: 338| Step: 0
Training loss: 1.7802665404805031
Validation loss: 2.5125307857019306

Epoch: 5| Step: 1
Training loss: 2.102067624333653
Validation loss: 2.5011657232516984

Epoch: 5| Step: 2
Training loss: 1.8657292373648977
Validation loss: 2.5278451935657524

Epoch: 5| Step: 3
Training loss: 1.8953125276746379
Validation loss: 2.5645944203258018

Epoch: 5| Step: 4
Training loss: 1.8421736622064964
Validation loss: 2.5656430097564393

Epoch: 5| Step: 5
Training loss: 1.8192416467153771
Validation loss: 2.4749069852680927

Epoch: 5| Step: 6
Training loss: 2.290186270921555
Validation loss: 2.560686025147753

Epoch: 5| Step: 7
Training loss: 1.706443633106755
Validation loss: 2.54121961113231

Epoch: 5| Step: 8
Training loss: 1.3971146875024596
Validation loss: 2.5099479388502104

Epoch: 5| Step: 9
Training loss: 2.193060863967064
Validation loss: 2.542405810940943

Epoch: 5| Step: 10
Training loss: 2.3180818978193067
Validation loss: 2.554225000068216

Epoch: 339| Step: 0
Training loss: 1.7146632766472591
Validation loss: 2.4985755282066986

Epoch: 5| Step: 1
Training loss: 2.0408129431735427
Validation loss: 2.52590094731413

Epoch: 5| Step: 2
Training loss: 1.80011291679553
Validation loss: 2.5055569498770556

Epoch: 5| Step: 3
Training loss: 2.570922964585198
Validation loss: 2.4987604842115587

Epoch: 5| Step: 4
Training loss: 2.0955144934183743
Validation loss: 2.4233002807751545

Epoch: 5| Step: 5
Training loss: 1.544294729149762
Validation loss: 2.539652421824778

Epoch: 5| Step: 6
Training loss: 2.2408849674440887
Validation loss: 2.4513909579663027

Epoch: 5| Step: 7
Training loss: 2.33725744610746
Validation loss: 2.4905818581439227

Epoch: 5| Step: 8
Training loss: 1.145198484316778
Validation loss: 2.5234970821781966

Epoch: 5| Step: 9
Training loss: 1.4377029109878932
Validation loss: 2.4843185819809968

Epoch: 5| Step: 10
Training loss: 1.8840837421190983
Validation loss: 2.48540430873455

Epoch: 340| Step: 0
Training loss: 1.7763120234786
Validation loss: 2.5833515228784916

Epoch: 5| Step: 1
Training loss: 1.7320234147971318
Validation loss: 2.471396756815249

Epoch: 5| Step: 2
Training loss: 2.0804067146200245
Validation loss: 2.450642456357735

Epoch: 5| Step: 3
Training loss: 1.7060307903395735
Validation loss: 2.5534345560993623

Epoch: 5| Step: 4
Training loss: 2.1791512434676807
Validation loss: 2.5349588774127754

Epoch: 5| Step: 5
Training loss: 2.6377207116800534
Validation loss: 2.4765320464146106

Epoch: 5| Step: 6
Training loss: 1.591909130795423
Validation loss: 2.480718213166163

Epoch: 5| Step: 7
Training loss: 1.3444380218616923
Validation loss: 2.5047977054612254

Epoch: 5| Step: 8
Training loss: 1.9077364644762798
Validation loss: 2.4964784409877607

Epoch: 5| Step: 9
Training loss: 2.243265882879036
Validation loss: 2.5600433929656687

Epoch: 5| Step: 10
Training loss: 1.408999700544879
Validation loss: 2.599637157057857

Epoch: 341| Step: 0
Training loss: 1.8822833065430662
Validation loss: 2.5219946887593934

Epoch: 5| Step: 1
Training loss: 1.5155307701156173
Validation loss: 2.515459573308076

Epoch: 5| Step: 2
Training loss: 2.03841848909296
Validation loss: 2.5056435791484524

Epoch: 5| Step: 3
Training loss: 2.4715493664095334
Validation loss: 2.510250359896234

Epoch: 5| Step: 4
Training loss: 1.6730124623894176
Validation loss: 2.508300829797977

Epoch: 5| Step: 5
Training loss: 1.6329890251561758
Validation loss: 2.5352960707228425

Epoch: 5| Step: 6
Training loss: 1.44536660582848
Validation loss: 2.547680231070618

Epoch: 5| Step: 7
Training loss: 2.4983154343397973
Validation loss: 2.531613013841854

Epoch: 5| Step: 8
Training loss: 2.124278899867291
Validation loss: 2.480826625533896

Epoch: 5| Step: 9
Training loss: 1.829825368584828
Validation loss: 2.456780359399545

Epoch: 5| Step: 10
Training loss: 1.9637532478563051
Validation loss: 2.512188939720881

Epoch: 342| Step: 0
Training loss: 1.7273752362346149
Validation loss: 2.516615064201001

Epoch: 5| Step: 1
Training loss: 2.233334172187002
Validation loss: 2.476664207644535

Epoch: 5| Step: 2
Training loss: 1.9675652708595903
Validation loss: 2.4931537941953623

Epoch: 5| Step: 3
Training loss: 2.5302491269697636
Validation loss: 2.539332564941707

Epoch: 5| Step: 4
Training loss: 1.4546690090491587
Validation loss: 2.502348741994184

Epoch: 5| Step: 5
Training loss: 1.711021247103124
Validation loss: 2.5426945513386867

Epoch: 5| Step: 6
Training loss: 1.8993977445475152
Validation loss: 2.483085091593389

Epoch: 5| Step: 7
Training loss: 1.8573216231735308
Validation loss: 2.4939155884062827

Epoch: 5| Step: 8
Training loss: 1.989773712902638
Validation loss: 2.5496884887428433

Epoch: 5| Step: 9
Training loss: 1.3230933524461188
Validation loss: 2.4791060799027007

Epoch: 5| Step: 10
Training loss: 1.7525473174973447
Validation loss: 2.488894732185078

Epoch: 343| Step: 0
Training loss: 1.4109820117033611
Validation loss: 2.530945878500425

Epoch: 5| Step: 1
Training loss: 2.0173672974915307
Validation loss: 2.5548678063525845

Epoch: 5| Step: 2
Training loss: 1.7689206583571644
Validation loss: 2.5180771772042645

Epoch: 5| Step: 3
Training loss: 2.533091499263328
Validation loss: 2.484489793757373

Epoch: 5| Step: 4
Training loss: 1.7921580890081417
Validation loss: 2.516128154441064

Epoch: 5| Step: 5
Training loss: 1.941523772890629
Validation loss: 2.524623165482094

Epoch: 5| Step: 6
Training loss: 2.0891562783898885
Validation loss: 2.516935377791278

Epoch: 5| Step: 7
Training loss: 1.502440454125064
Validation loss: 2.489605620388248

Epoch: 5| Step: 8
Training loss: 1.527783342794436
Validation loss: 2.5947527004262065

Epoch: 5| Step: 9
Training loss: 1.5932611950035531
Validation loss: 2.5034195473320997

Epoch: 5| Step: 10
Training loss: 2.383578218092525
Validation loss: 2.517444956826692

Epoch: 344| Step: 0
Training loss: 1.4689513535154086
Validation loss: 2.542375250625445

Epoch: 5| Step: 1
Training loss: 1.9406117707567903
Validation loss: 2.505470622529105

Epoch: 5| Step: 2
Training loss: 1.7131325214920905
Validation loss: 2.5308579220102145

Epoch: 5| Step: 3
Training loss: 1.2987242234052125
Validation loss: 2.540540339383195

Epoch: 5| Step: 4
Training loss: 1.490216296325055
Validation loss: 2.4820309585625395

Epoch: 5| Step: 5
Training loss: 2.8143204625330998
Validation loss: 2.50758484527879

Epoch: 5| Step: 6
Training loss: 1.9352777103381291
Validation loss: 2.5190281443179985

Epoch: 5| Step: 7
Training loss: 2.038313103131235
Validation loss: 2.49668352353228

Epoch: 5| Step: 8
Training loss: 1.7190636088623066
Validation loss: 2.5111417356868713

Epoch: 5| Step: 9
Training loss: 2.0630295969420525
Validation loss: 2.5007586148559016

Epoch: 5| Step: 10
Training loss: 2.13426622864799
Validation loss: 2.523389844216781

Epoch: 345| Step: 0
Training loss: 1.393031876995506
Validation loss: 2.506360979466458

Epoch: 5| Step: 1
Training loss: 1.5325839402078305
Validation loss: 2.4984025968833468

Epoch: 5| Step: 2
Training loss: 2.2006980568812784
Validation loss: 2.4648562517589014

Epoch: 5| Step: 3
Training loss: 1.5481800007665645
Validation loss: 2.5363034719933

Epoch: 5| Step: 4
Training loss: 1.9548609228982905
Validation loss: 2.497625540025945

Epoch: 5| Step: 5
Training loss: 2.8359290929412233
Validation loss: 2.488351793693462

Epoch: 5| Step: 6
Training loss: 1.50984173936936
Validation loss: 2.558692223467547

Epoch: 5| Step: 7
Training loss: 1.81097650625829
Validation loss: 2.533847890065644

Epoch: 5| Step: 8
Training loss: 1.890067215284379
Validation loss: 2.5551944377839

Epoch: 5| Step: 9
Training loss: 1.884219455151039
Validation loss: 2.4890820858515825

Epoch: 5| Step: 10
Training loss: 1.266110174173058
Validation loss: 2.5648228591589364

Epoch: 346| Step: 0
Training loss: 2.236378658340086
Validation loss: 2.458801167311956

Epoch: 5| Step: 1
Training loss: 1.658508919600755
Validation loss: 2.5275191351627924

Epoch: 5| Step: 2
Training loss: 1.8687313831639567
Validation loss: 2.4838939502077917

Epoch: 5| Step: 3
Training loss: 1.667741603706095
Validation loss: 2.4976755821485264

Epoch: 5| Step: 4
Training loss: 2.4167901588545155
Validation loss: 2.591564137570298

Epoch: 5| Step: 5
Training loss: 1.8857417449871632
Validation loss: 2.469772073297071

Epoch: 5| Step: 6
Training loss: 1.8540022987919356
Validation loss: 2.496827971142482

Epoch: 5| Step: 7
Training loss: 1.7385683658378985
Validation loss: 2.512379973610844

Epoch: 5| Step: 8
Training loss: 1.8930400209947085
Validation loss: 2.5099429626236667

Epoch: 5| Step: 9
Training loss: 2.064656719465049
Validation loss: 2.499342236075236

Epoch: 5| Step: 10
Training loss: 1.933322648588888
Validation loss: 2.5095588579437806

Epoch: 347| Step: 0
Training loss: 1.8138789489042746
Validation loss: 2.516494939913548

Epoch: 5| Step: 1
Training loss: 1.8016163509423049
Validation loss: 2.489566492109624

Epoch: 5| Step: 2
Training loss: 2.201607472357711
Validation loss: 2.556507437873392

Epoch: 5| Step: 3
Training loss: 2.63357985545759
Validation loss: 2.5140628151343503

Epoch: 5| Step: 4
Training loss: 2.0417535205454325
Validation loss: 2.4902962334848144

Epoch: 5| Step: 5
Training loss: 1.9791962939270094
Validation loss: 2.4857416401069274

Epoch: 5| Step: 6
Training loss: 1.4534673800172366
Validation loss: 2.556806139593933

Epoch: 5| Step: 7
Training loss: 1.584516292494277
Validation loss: 2.502064402700598

Epoch: 5| Step: 8
Training loss: 1.5000312325087057
Validation loss: 2.477005002098788

Epoch: 5| Step: 9
Training loss: 1.743955049114836
Validation loss: 2.5393706467450263

Epoch: 5| Step: 10
Training loss: 1.5434848356895314
Validation loss: 2.5140217098770687

Epoch: 348| Step: 0
Training loss: 1.6066253282972116
Validation loss: 2.517080687982492

Epoch: 5| Step: 1
Training loss: 1.7948556582717596
Validation loss: 2.5834700825752157

Epoch: 5| Step: 2
Training loss: 1.8192575696856117
Validation loss: 2.541681503126179

Epoch: 5| Step: 3
Training loss: 1.5942095673620138
Validation loss: 2.5182946602955494

Epoch: 5| Step: 4
Training loss: 1.9784389831219267
Validation loss: 2.560102822667239

Epoch: 5| Step: 5
Training loss: 1.6942698001320948
Validation loss: 2.509080539359618

Epoch: 5| Step: 6
Training loss: 2.3177140710881106
Validation loss: 2.5050473032993756

Epoch: 5| Step: 7
Training loss: 1.5296865773027732
Validation loss: 2.5580863120671555

Epoch: 5| Step: 8
Training loss: 1.3811123844136426
Validation loss: 2.525800404234751

Epoch: 5| Step: 9
Training loss: 1.7100298838764807
Validation loss: 2.51960030419997

Epoch: 5| Step: 10
Training loss: 2.731805956929576
Validation loss: 2.573759075999577

Epoch: 349| Step: 0
Training loss: 2.025897441787494
Validation loss: 2.532422738879759

Epoch: 5| Step: 1
Training loss: 2.3962514650661744
Validation loss: 2.4713863939208363

Epoch: 5| Step: 2
Training loss: 2.243228683902667
Validation loss: 2.515317300484816

Epoch: 5| Step: 3
Training loss: 1.7821699075969348
Validation loss: 2.5193851836564

Epoch: 5| Step: 4
Training loss: 1.5760494217699679
Validation loss: 2.546019153094798

Epoch: 5| Step: 5
Training loss: 1.6982238663249436
Validation loss: 2.565782563956922

Epoch: 5| Step: 6
Training loss: 1.005964906952564
Validation loss: 2.5169935652086544

Epoch: 5| Step: 7
Training loss: 1.2683252328237211
Validation loss: 2.5554889185701932

Epoch: 5| Step: 8
Training loss: 1.5917180141268652
Validation loss: 2.542730529040055

Epoch: 5| Step: 9
Training loss: 1.9084563072705816
Validation loss: 2.532858892901322

Epoch: 5| Step: 10
Training loss: 2.1392588467483575
Validation loss: 2.502119015363611

Epoch: 350| Step: 0
Training loss: 1.5197374061832003
Validation loss: 2.5319531901022865

Epoch: 5| Step: 1
Training loss: 2.5457706046193547
Validation loss: 2.553364647333218

Epoch: 5| Step: 2
Training loss: 1.1495807692105238
Validation loss: 2.4512798182767703

Epoch: 5| Step: 3
Training loss: 1.9445930590678235
Validation loss: 2.4892099143091433

Epoch: 5| Step: 4
Training loss: 1.4082801152318591
Validation loss: 2.4920490144250746

Epoch: 5| Step: 5
Training loss: 1.6888754149089091
Validation loss: 2.5203252260109488

Epoch: 5| Step: 6
Training loss: 2.1949273582725377
Validation loss: 2.531944360449657

Epoch: 5| Step: 7
Training loss: 1.78861754102256
Validation loss: 2.5136704328909745

Epoch: 5| Step: 8
Training loss: 1.9517811538948147
Validation loss: 2.5290187104836797

Epoch: 5| Step: 9
Training loss: 2.1455922654919246
Validation loss: 2.5117850182873225

Epoch: 5| Step: 10
Training loss: 1.9650544495355038
Validation loss: 2.504534045395797

Epoch: 351| Step: 0
Training loss: 1.791751356858615
Validation loss: 2.490389144434284

Epoch: 5| Step: 1
Training loss: 1.626337747867444
Validation loss: 2.534486462554908

Epoch: 5| Step: 2
Training loss: 1.6135330557875598
Validation loss: 2.5542411121935458

Epoch: 5| Step: 3
Training loss: 1.891506336436497
Validation loss: 2.5652898073000876

Epoch: 5| Step: 4
Training loss: 1.8422696911415228
Validation loss: 2.5309507648121365

Epoch: 5| Step: 5
Training loss: 1.4869998411577419
Validation loss: 2.498057625029611

Epoch: 5| Step: 6
Training loss: 2.0498550503356268
Validation loss: 2.5355079253123756

Epoch: 5| Step: 7
Training loss: 2.4488048051559526
Validation loss: 2.5270774589314544

Epoch: 5| Step: 8
Training loss: 1.5387862678920596
Validation loss: 2.4975575544603954

Epoch: 5| Step: 9
Training loss: 2.1106089055987085
Validation loss: 2.509815704942854

Epoch: 5| Step: 10
Training loss: 2.0137987957091465
Validation loss: 2.485089227838945

Epoch: 352| Step: 0
Training loss: 1.9297878223858473
Validation loss: 2.513435235663462

Epoch: 5| Step: 1
Training loss: 1.7757232992212888
Validation loss: 2.566843784657753

Epoch: 5| Step: 2
Training loss: 1.9607236829200463
Validation loss: 2.504123559738792

Epoch: 5| Step: 3
Training loss: 2.2687392305481096
Validation loss: 2.5258698650597844

Epoch: 5| Step: 4
Training loss: 1.4677354270901644
Validation loss: 2.5242277783762024

Epoch: 5| Step: 5
Training loss: 1.699865950179876
Validation loss: 2.543739719777759

Epoch: 5| Step: 6
Training loss: 2.0630491277084566
Validation loss: 2.542832887877345

Epoch: 5| Step: 7
Training loss: 2.0254407709106887
Validation loss: 2.5230319836000814

Epoch: 5| Step: 8
Training loss: 1.8148409754337378
Validation loss: 2.4968696315420744

Epoch: 5| Step: 9
Training loss: 1.7472646998525174
Validation loss: 2.527038477676313

Epoch: 5| Step: 10
Training loss: 1.4313689802931182
Validation loss: 2.5097661061105114

Epoch: 353| Step: 0
Training loss: 1.7681375366500034
Validation loss: 2.5572241478976747

Epoch: 5| Step: 1
Training loss: 2.024525118117318
Validation loss: 2.557565142688893

Epoch: 5| Step: 2
Training loss: 1.5463892626824276
Validation loss: 2.5160638921493215

Epoch: 5| Step: 3
Training loss: 1.5832435013568265
Validation loss: 2.5200111796311293

Epoch: 5| Step: 4
Training loss: 1.6698971038230372
Validation loss: 2.524241945133728

Epoch: 5| Step: 5
Training loss: 1.6405007451551907
Validation loss: 2.530992419628737

Epoch: 5| Step: 6
Training loss: 2.377376772538067
Validation loss: 2.377013193564069

Epoch: 5| Step: 7
Training loss: 1.21982331575576
Validation loss: 2.4564767208470797

Epoch: 5| Step: 8
Training loss: 2.4603649623863584
Validation loss: 2.5397501110503025

Epoch: 5| Step: 9
Training loss: 1.3839578142021125
Validation loss: 2.5052839695037474

Epoch: 5| Step: 10
Training loss: 2.2290508085666487
Validation loss: 2.5030920821103426

Epoch: 354| Step: 0
Training loss: 1.6639313981972015
Validation loss: 2.517938293061261

Epoch: 5| Step: 1
Training loss: 1.8287010263494037
Validation loss: 2.477217365922922

Epoch: 5| Step: 2
Training loss: 1.8918374327605474
Validation loss: 2.4930008874928817

Epoch: 5| Step: 3
Training loss: 2.0121459507344106
Validation loss: 2.5894064464070787

Epoch: 5| Step: 4
Training loss: 1.3641479273172925
Validation loss: 2.523067628983264

Epoch: 5| Step: 5
Training loss: 1.722471196967759
Validation loss: 2.5306724113187706

Epoch: 5| Step: 6
Training loss: 1.4264948483122373
Validation loss: 2.5074586263057785

Epoch: 5| Step: 7
Training loss: 2.5549901380553903
Validation loss: 2.5303451630441813

Epoch: 5| Step: 8
Training loss: 1.5061547055312805
Validation loss: 2.518050210789684

Epoch: 5| Step: 9
Training loss: 2.3995503878651534
Validation loss: 2.495525526455307

Epoch: 5| Step: 10
Training loss: 2.0852366209352136
Validation loss: 2.477269576986151

Epoch: 355| Step: 0
Training loss: 1.7268959517421165
Validation loss: 2.5405278185304856

Epoch: 5| Step: 1
Training loss: 1.427541237016703
Validation loss: 2.5505182794354524

Epoch: 5| Step: 2
Training loss: 1.6112579145451693
Validation loss: 2.5499886296352754

Epoch: 5| Step: 3
Training loss: 1.6559819418433963
Validation loss: 2.5846435354984583

Epoch: 5| Step: 4
Training loss: 2.719103033888
Validation loss: 2.5337086046087673

Epoch: 5| Step: 5
Training loss: 2.118877229274513
Validation loss: 2.6056673932597243

Epoch: 5| Step: 6
Training loss: 2.3578654127206655
Validation loss: 2.5292221610067624

Epoch: 5| Step: 7
Training loss: 1.8432201335333882
Validation loss: 2.5238855806640523

Epoch: 5| Step: 8
Training loss: 1.421018237539863
Validation loss: 2.475625361306864

Epoch: 5| Step: 9
Training loss: 1.8122528170704375
Validation loss: 2.5565643275347174

Epoch: 5| Step: 10
Training loss: 1.0503090857666237
Validation loss: 2.53053871652778

Epoch: 356| Step: 0
Training loss: 1.7226054558217914
Validation loss: 2.547485928542135

Epoch: 5| Step: 1
Training loss: 1.6639144903275007
Validation loss: 2.492300280920179

Epoch: 5| Step: 2
Training loss: 1.5752811302084062
Validation loss: 2.5644592090645704

Epoch: 5| Step: 3
Training loss: 1.732037042411097
Validation loss: 2.5305053970881675

Epoch: 5| Step: 4
Training loss: 2.334013487821831
Validation loss: 2.478717927416264

Epoch: 5| Step: 5
Training loss: 1.814646337957731
Validation loss: 2.4390972090652396

Epoch: 5| Step: 6
Training loss: 1.575685560794403
Validation loss: 2.49298681468557

Epoch: 5| Step: 7
Training loss: 1.7121154353360686
Validation loss: 2.5132068488464974

Epoch: 5| Step: 8
Training loss: 1.8084931644292586
Validation loss: 2.548094131972654

Epoch: 5| Step: 9
Training loss: 1.877444898505367
Validation loss: 2.52676778255878

Epoch: 5| Step: 10
Training loss: 1.9679490534034112
Validation loss: 2.4706558341690488

Epoch: 357| Step: 0
Training loss: 1.842027279630073
Validation loss: 2.490037067791573

Epoch: 5| Step: 1
Training loss: 1.8056158675203482
Validation loss: 2.5019565514464546

Epoch: 5| Step: 2
Training loss: 1.91962232610426
Validation loss: 2.519390685120826

Epoch: 5| Step: 3
Training loss: 1.5529000439823362
Validation loss: 2.4865421721509486

Epoch: 5| Step: 4
Training loss: 1.3261467955160342
Validation loss: 2.512326421258281

Epoch: 5| Step: 5
Training loss: 2.0147721016411544
Validation loss: 2.5126914701407745

Epoch: 5| Step: 6
Training loss: 2.523521965195802
Validation loss: 2.4839530220643087

Epoch: 5| Step: 7
Training loss: 2.1022451206803447
Validation loss: 2.501966943469175

Epoch: 5| Step: 8
Training loss: 1.7636755925305159
Validation loss: 2.533077235249234

Epoch: 5| Step: 9
Training loss: 1.3306220870660277
Validation loss: 2.507085628959794

Epoch: 5| Step: 10
Training loss: 1.5097607295461544
Validation loss: 2.470880545745929

Epoch: 358| Step: 0
Training loss: 2.067171989722968
Validation loss: 2.537298515447879

Epoch: 5| Step: 1
Training loss: 1.6804566507511316
Validation loss: 2.4999536653552306

Epoch: 5| Step: 2
Training loss: 2.147465489457715
Validation loss: 2.538084660773105

Epoch: 5| Step: 3
Training loss: 1.9806470922343637
Validation loss: 2.483647699816573

Epoch: 5| Step: 4
Training loss: 1.813433702626937
Validation loss: 2.593663096686316

Epoch: 5| Step: 5
Training loss: 1.4866224441166354
Validation loss: 2.53590013936238

Epoch: 5| Step: 6
Training loss: 1.7367630061020485
Validation loss: 2.553486285516833

Epoch: 5| Step: 7
Training loss: 1.3829858531159396
Validation loss: 2.5475575468424023

Epoch: 5| Step: 8
Training loss: 1.8644028332966798
Validation loss: 2.4792794415400015

Epoch: 5| Step: 9
Training loss: 2.3436601748737607
Validation loss: 2.5042251899041896

Epoch: 5| Step: 10
Training loss: 1.6990914132648935
Validation loss: 2.60932574619581

Epoch: 359| Step: 0
Training loss: 1.6294080661100647
Validation loss: 2.599249183306998

Epoch: 5| Step: 1
Training loss: 2.402632235441571
Validation loss: 2.5943054027605084

Epoch: 5| Step: 2
Training loss: 2.0587000665590636
Validation loss: 2.5209024518662204

Epoch: 5| Step: 3
Training loss: 1.9411309582428873
Validation loss: 2.4779611477672923

Epoch: 5| Step: 4
Training loss: 1.3738271305968954
Validation loss: 2.549316946770075

Epoch: 5| Step: 5
Training loss: 2.1607250271905127
Validation loss: 2.474423160289072

Epoch: 5| Step: 6
Training loss: 1.4892633356711107
Validation loss: 2.482071579342688

Epoch: 5| Step: 7
Training loss: 1.1418225520741434
Validation loss: 2.4920241026229517

Epoch: 5| Step: 8
Training loss: 1.8483221616255452
Validation loss: 2.5046312821658434

Epoch: 5| Step: 9
Training loss: 2.0908214528108755
Validation loss: 2.471976943194491

Epoch: 5| Step: 10
Training loss: 1.9703294382721015
Validation loss: 2.5247217215674342

Epoch: 360| Step: 0
Training loss: 1.7890109258822389
Validation loss: 2.464554486107499

Epoch: 5| Step: 1
Training loss: 1.9834125016811182
Validation loss: 2.469239470543744

Epoch: 5| Step: 2
Training loss: 1.4154866670973008
Validation loss: 2.54365623131779

Epoch: 5| Step: 3
Training loss: 2.4277672738556797
Validation loss: 2.511019310713253

Epoch: 5| Step: 4
Training loss: 2.056997530871269
Validation loss: 2.52490552430835

Epoch: 5| Step: 5
Training loss: 1.3510505721073967
Validation loss: 2.5811012627053365

Epoch: 5| Step: 6
Training loss: 1.8376188979315147
Validation loss: 2.5649097266282497

Epoch: 5| Step: 7
Training loss: 1.451582715701617
Validation loss: 2.5263498615346687

Epoch: 5| Step: 8
Training loss: 1.8329036237954015
Validation loss: 2.603579169833075

Epoch: 5| Step: 9
Training loss: 1.8776018528035616
Validation loss: 2.501355086464946

Epoch: 5| Step: 10
Training loss: 1.4442368087126511
Validation loss: 2.5827749823564585

Epoch: 361| Step: 0
Training loss: 2.1352348684443148
Validation loss: 2.57620327233555

Epoch: 5| Step: 1
Training loss: 1.4370473895504778
Validation loss: 2.5275144846329645

Epoch: 5| Step: 2
Training loss: 1.3433570287206447
Validation loss: 2.5546879616120703

Epoch: 5| Step: 3
Training loss: 2.1416293941277496
Validation loss: 2.5092329188118803

Epoch: 5| Step: 4
Training loss: 2.827708008094281
Validation loss: 2.535737699496018

Epoch: 5| Step: 5
Training loss: 1.6715200172113502
Validation loss: 2.4821083851533956

Epoch: 5| Step: 6
Training loss: 1.6649895176829614
Validation loss: 2.5251088838869897

Epoch: 5| Step: 7
Training loss: 1.7005537729933502
Validation loss: 2.4997036932631125

Epoch: 5| Step: 8
Training loss: 1.377899667046516
Validation loss: 2.5135625242770434

Epoch: 5| Step: 9
Training loss: 1.7814334975642219
Validation loss: 2.485477171294327

Epoch: 5| Step: 10
Training loss: 1.5858959324091877
Validation loss: 2.5443983978170914

Epoch: 362| Step: 0
Training loss: 1.7706199816663988
Validation loss: 2.5373557852715516

Epoch: 5| Step: 1
Training loss: 1.895412090858118
Validation loss: 2.5410985928775025

Epoch: 5| Step: 2
Training loss: 1.9210317358903397
Validation loss: 2.5424121133868205

Epoch: 5| Step: 3
Training loss: 1.8588300916274718
Validation loss: 2.564023224202241

Epoch: 5| Step: 4
Training loss: 1.8007243844609075
Validation loss: 2.468574833396195

Epoch: 5| Step: 5
Training loss: 2.64056089425006
Validation loss: 2.5495901486587242

Epoch: 5| Step: 6
Training loss: 1.5878607452696878
Validation loss: 2.4966097999615693

Epoch: 5| Step: 7
Training loss: 1.1999549221473058
Validation loss: 2.480919861671847

Epoch: 5| Step: 8
Training loss: 1.5187040690945202
Validation loss: 2.542020849372553

Epoch: 5| Step: 9
Training loss: 1.8996677258719437
Validation loss: 2.4774420587287023

Epoch: 5| Step: 10
Training loss: 1.350761264280309
Validation loss: 2.6068203668458305

Epoch: 363| Step: 0
Training loss: 1.7115224595999217
Validation loss: 2.5195193766830632

Epoch: 5| Step: 1
Training loss: 1.822408819756504
Validation loss: 2.5260346460239558

Epoch: 5| Step: 2
Training loss: 2.3603244917251933
Validation loss: 2.5753989620351305

Epoch: 5| Step: 3
Training loss: 1.8089476665478297
Validation loss: 2.533335709719145

Epoch: 5| Step: 4
Training loss: 2.220707848912082
Validation loss: 2.484055931821944

Epoch: 5| Step: 5
Training loss: 1.7409823230676436
Validation loss: 2.4916973888997074

Epoch: 5| Step: 6
Training loss: 1.5808250067207879
Validation loss: 2.492243150471681

Epoch: 5| Step: 7
Training loss: 1.4635529794855349
Validation loss: 2.5081601327934746

Epoch: 5| Step: 8
Training loss: 1.326551065743888
Validation loss: 2.536074985363558

Epoch: 5| Step: 9
Training loss: 1.5663885938453175
Validation loss: 2.44874797486764

Epoch: 5| Step: 10
Training loss: 1.5563365682400956
Validation loss: 2.489174254749596

Epoch: 364| Step: 0
Training loss: 1.7800032954239076
Validation loss: 2.4814193014014503

Epoch: 5| Step: 1
Training loss: 1.7628037860494716
Validation loss: 2.504232477031752

Epoch: 5| Step: 2
Training loss: 1.625635976318004
Validation loss: 2.4897585893948126

Epoch: 5| Step: 3
Training loss: 2.184920834082667
Validation loss: 2.575403214029519

Epoch: 5| Step: 4
Training loss: 1.378104995616951
Validation loss: 2.4947914563517886

Epoch: 5| Step: 5
Training loss: 1.6699063127472964
Validation loss: 2.4823222617137928

Epoch: 5| Step: 6
Training loss: 1.8570504283436287
Validation loss: 2.4957800905014946

Epoch: 5| Step: 7
Training loss: 1.7733508521603354
Validation loss: 2.5853393505314766

Epoch: 5| Step: 8
Training loss: 1.5107884267426854
Validation loss: 2.5093661856478304

Epoch: 5| Step: 9
Training loss: 2.324128375179647
Validation loss: 2.505280361368502

Epoch: 5| Step: 10
Training loss: 1.7501304441609429
Validation loss: 2.490839935867498

Epoch: 365| Step: 0
Training loss: 1.550096259665943
Validation loss: 2.5495852839924433

Epoch: 5| Step: 1
Training loss: 1.4206734075996463
Validation loss: 2.4890687633578996

Epoch: 5| Step: 2
Training loss: 1.5429810342420414
Validation loss: 2.535194081058429

Epoch: 5| Step: 3
Training loss: 2.3042672501512556
Validation loss: 2.604481367887435

Epoch: 5| Step: 4
Training loss: 2.006390138289143
Validation loss: 2.491928583984428

Epoch: 5| Step: 5
Training loss: 1.5022635070985821
Validation loss: 2.4959085208857488

Epoch: 5| Step: 6
Training loss: 1.5259298428998205
Validation loss: 2.4854943438139485

Epoch: 5| Step: 7
Training loss: 1.4885292947876572
Validation loss: 2.547615597367146

Epoch: 5| Step: 8
Training loss: 1.9745369283816823
Validation loss: 2.4801580196822988

Epoch: 5| Step: 9
Training loss: 1.9647134847668581
Validation loss: 2.565178420534599

Epoch: 5| Step: 10
Training loss: 1.9670197285805555
Validation loss: 2.5202746042023687

Epoch: 366| Step: 0
Training loss: 1.6824942625268202
Validation loss: 2.521812661288915

Epoch: 5| Step: 1
Training loss: 1.6039618406774792
Validation loss: 2.5346586650889464

Epoch: 5| Step: 2
Training loss: 1.544437067134689
Validation loss: 2.544602289585025

Epoch: 5| Step: 3
Training loss: 2.192368457636747
Validation loss: 2.564224613237504

Epoch: 5| Step: 4
Training loss: 1.870309494130867
Validation loss: 2.518406181469462

Epoch: 5| Step: 5
Training loss: 2.1235435206743465
Validation loss: 2.4867564441743544

Epoch: 5| Step: 6
Training loss: 1.362532051829339
Validation loss: 2.517615735495046

Epoch: 5| Step: 7
Training loss: 1.996070219673871
Validation loss: 2.503681341632684

Epoch: 5| Step: 8
Training loss: 1.4866763294801173
Validation loss: 2.5118658030754366

Epoch: 5| Step: 9
Training loss: 1.7332797329513525
Validation loss: 2.4987632779125124

Epoch: 5| Step: 10
Training loss: 1.8919291766462059
Validation loss: 2.477342642064606

Epoch: 367| Step: 0
Training loss: 1.3018798770895599
Validation loss: 2.4659472457231963

Epoch: 5| Step: 1
Training loss: 1.4760376335453274
Validation loss: 2.501455414546875

Epoch: 5| Step: 2
Training loss: 1.570139861224908
Validation loss: 2.568866481444953

Epoch: 5| Step: 3
Training loss: 1.7747523605174074
Validation loss: 2.5361441005962404

Epoch: 5| Step: 4
Training loss: 2.40517520432905
Validation loss: 2.536872912935599

Epoch: 5| Step: 5
Training loss: 1.6101180648162745
Validation loss: 2.451823520329762

Epoch: 5| Step: 6
Training loss: 2.0822591173822214
Validation loss: 2.5357996914737435

Epoch: 5| Step: 7
Training loss: 1.8198984354625865
Validation loss: 2.5592940529945203

Epoch: 5| Step: 8
Training loss: 1.5667677008062793
Validation loss: 2.507987987057148

Epoch: 5| Step: 9
Training loss: 2.140597712210597
Validation loss: 2.5206240007142693

Epoch: 5| Step: 10
Training loss: 1.7842391515217342
Validation loss: 2.5403504886581936

Epoch: 368| Step: 0
Training loss: 1.8977257293005467
Validation loss: 2.5501441179327435

Epoch: 5| Step: 1
Training loss: 1.5175225874902458
Validation loss: 2.5189178526491967

Epoch: 5| Step: 2
Training loss: 2.023800732622901
Validation loss: 2.5974094803810415

Epoch: 5| Step: 3
Training loss: 1.90672658997296
Validation loss: 2.5244947681159733

Epoch: 5| Step: 4
Training loss: 1.6149259224309873
Validation loss: 2.404430000493717

Epoch: 5| Step: 5
Training loss: 1.7887524331940656
Validation loss: 2.528324784103202

Epoch: 5| Step: 6
Training loss: 1.492655815412757
Validation loss: 2.5370165688642707

Epoch: 5| Step: 7
Training loss: 1.4903923540884683
Validation loss: 2.495630518921489

Epoch: 5| Step: 8
Training loss: 1.852723928346082
Validation loss: 2.530084425435912

Epoch: 5| Step: 9
Training loss: 2.6737004340857764
Validation loss: 2.5496723056180586

Epoch: 5| Step: 10
Training loss: 1.337682688348981
Validation loss: 2.536662955612151

Epoch: 369| Step: 0
Training loss: 1.6880694241010104
Validation loss: 2.520796780044519

Epoch: 5| Step: 1
Training loss: 1.3970413911103876
Validation loss: 2.4809261061544285

Epoch: 5| Step: 2
Training loss: 2.2157154016385654
Validation loss: 2.433818791919537

Epoch: 5| Step: 3
Training loss: 1.6362894810866802
Validation loss: 2.491358930423896

Epoch: 5| Step: 4
Training loss: 1.3947109672936266
Validation loss: 2.535639529119615

Epoch: 5| Step: 5
Training loss: 1.6825928157695191
Validation loss: 2.4489735870221963

Epoch: 5| Step: 6
Training loss: 1.7700977892182639
Validation loss: 2.5136425288363347

Epoch: 5| Step: 7
Training loss: 2.145354344014773
Validation loss: 2.558289227418276

Epoch: 5| Step: 8
Training loss: 1.4906398876414402
Validation loss: 2.4675861084982675

Epoch: 5| Step: 9
Training loss: 2.390775688259157
Validation loss: 2.5677681810085127

Epoch: 5| Step: 10
Training loss: 1.4854742697969014
Validation loss: 2.494631883905029

Epoch: 370| Step: 0
Training loss: 1.3937678451422044
Validation loss: 2.53666722099403

Epoch: 5| Step: 1
Training loss: 1.9346209639302396
Validation loss: 2.494945727313782

Epoch: 5| Step: 2
Training loss: 2.1065048471101218
Validation loss: 2.564024576999997

Epoch: 5| Step: 3
Training loss: 1.3133449105577064
Validation loss: 2.514867722750385

Epoch: 5| Step: 4
Training loss: 1.4968751306075834
Validation loss: 2.469105495674598

Epoch: 5| Step: 5
Training loss: 1.9766441599747673
Validation loss: 2.4886305098620434

Epoch: 5| Step: 6
Training loss: 1.8588084792357273
Validation loss: 2.5298957711457

Epoch: 5| Step: 7
Training loss: 1.8347850022928223
Validation loss: 2.564412573531176

Epoch: 5| Step: 8
Training loss: 2.5843495451885583
Validation loss: 2.5060856315561635

Epoch: 5| Step: 9
Training loss: 1.104383981060476
Validation loss: 2.5499709162460023

Epoch: 5| Step: 10
Training loss: 1.7428349544890551
Validation loss: 2.503991212264543

Epoch: 371| Step: 0
Training loss: 1.2698277992738443
Validation loss: 2.4997953249096705

Epoch: 5| Step: 1
Training loss: 2.0215676405707605
Validation loss: 2.4817351385046718

Epoch: 5| Step: 2
Training loss: 1.9659455927929494
Validation loss: 2.4583292780850186

Epoch: 5| Step: 3
Training loss: 1.7441905186470126
Validation loss: 2.4768776264020302

Epoch: 5| Step: 4
Training loss: 1.772958026886169
Validation loss: 2.53272188821939

Epoch: 5| Step: 5
Training loss: 1.856991177432662
Validation loss: 2.4781189658511487

Epoch: 5| Step: 6
Training loss: 1.5652557485828569
Validation loss: 2.5481507285625966

Epoch: 5| Step: 7
Training loss: 1.4032793244791577
Validation loss: 2.510784699341623

Epoch: 5| Step: 8
Training loss: 1.772332607699371
Validation loss: 2.494933467266174

Epoch: 5| Step: 9
Training loss: 2.4458819326568717
Validation loss: 2.5661788242555557

Epoch: 5| Step: 10
Training loss: 1.694647170622236
Validation loss: 2.5024209513694893

Epoch: 372| Step: 0
Training loss: 2.3522825437733808
Validation loss: 2.5478164329014517

Epoch: 5| Step: 1
Training loss: 1.4874913479849892
Validation loss: 2.5293340689988515

Epoch: 5| Step: 2
Training loss: 2.094836280634736
Validation loss: 2.493349856393243

Epoch: 5| Step: 3
Training loss: 1.5339066173175715
Validation loss: 2.5430095385736933

Epoch: 5| Step: 4
Training loss: 1.3912459712214373
Validation loss: 2.513480882181793

Epoch: 5| Step: 5
Training loss: 1.631550862713403
Validation loss: 2.5253891185226256

Epoch: 5| Step: 6
Training loss: 1.5009621872024288
Validation loss: 2.457699628493225

Epoch: 5| Step: 7
Training loss: 1.650413305363759
Validation loss: 2.6003745649320287

Epoch: 5| Step: 8
Training loss: 1.6318880959741027
Validation loss: 2.468416736934112

Epoch: 5| Step: 9
Training loss: 1.8080816676844556
Validation loss: 2.487060023619458

Epoch: 5| Step: 10
Training loss: 2.1593755653038333
Validation loss: 2.5549100174522965

Epoch: 373| Step: 0
Training loss: 1.9082834623169824
Validation loss: 2.5446713777228274

Epoch: 5| Step: 1
Training loss: 1.3455016230300874
Validation loss: 2.568825510634398

Epoch: 5| Step: 2
Training loss: 1.3338555962215908
Validation loss: 2.5416516512530305

Epoch: 5| Step: 3
Training loss: 2.331048550735533
Validation loss: 2.474116269798317

Epoch: 5| Step: 4
Training loss: 1.6491161233187
Validation loss: 2.5314426204506506

Epoch: 5| Step: 5
Training loss: 1.7217341786036109
Validation loss: 2.506202183556967

Epoch: 5| Step: 6
Training loss: 1.6300642622233215
Validation loss: 2.46016485218285

Epoch: 5| Step: 7
Training loss: 2.106447010278349
Validation loss: 2.4921876378418903

Epoch: 5| Step: 8
Training loss: 1.8945087864124102
Validation loss: 2.4861507641379506

Epoch: 5| Step: 9
Training loss: 1.6166989238050924
Validation loss: 2.5429564911213696

Epoch: 5| Step: 10
Training loss: 1.7615890962718872
Validation loss: 2.5392603249547623

Epoch: 374| Step: 0
Training loss: 1.3732805772172731
Validation loss: 2.509081725605347

Epoch: 5| Step: 1
Training loss: 1.6169678912115437
Validation loss: 2.5832406955930605

Epoch: 5| Step: 2
Training loss: 1.7338479418273762
Validation loss: 2.598112189827395

Epoch: 5| Step: 3
Training loss: 1.6504408247496685
Validation loss: 2.565761935109381

Epoch: 5| Step: 4
Training loss: 1.9663644900640964
Validation loss: 2.4938690307231073

Epoch: 5| Step: 5
Training loss: 1.485351883526428
Validation loss: 2.4562624751107176

Epoch: 5| Step: 6
Training loss: 1.9984860650694094
Validation loss: 2.5659468304491115

Epoch: 5| Step: 7
Training loss: 2.093837906999043
Validation loss: 2.4903746445857866

Epoch: 5| Step: 8
Training loss: 1.3778606913897407
Validation loss: 2.5225000768964123

Epoch: 5| Step: 9
Training loss: 1.6336353911497636
Validation loss: 2.5143244739577204

Epoch: 5| Step: 10
Training loss: 2.493045001655514
Validation loss: 2.5562636950845303

Epoch: 375| Step: 0
Training loss: 1.797924896021015
Validation loss: 2.510726764207664

Epoch: 5| Step: 1
Training loss: 1.3386277444476324
Validation loss: 2.5828265097515524

Epoch: 5| Step: 2
Training loss: 1.6357181376496934
Validation loss: 2.56979947980177

Epoch: 5| Step: 3
Training loss: 0.9841531170443377
Validation loss: 2.4888429694604923

Epoch: 5| Step: 4
Training loss: 1.5444021785603146
Validation loss: 2.45687490562818

Epoch: 5| Step: 5
Training loss: 2.2547543415992557
Validation loss: 2.5288503299780594

Epoch: 5| Step: 6
Training loss: 2.0918543190641885
Validation loss: 2.507778002519856

Epoch: 5| Step: 7
Training loss: 1.5822453860189858
Validation loss: 2.486838312105862

Epoch: 5| Step: 8
Training loss: 1.924851818078646
Validation loss: 2.5411964060811303

Epoch: 5| Step: 9
Training loss: 1.3311824835191082
Validation loss: 2.450231771616747

Epoch: 5| Step: 10
Training loss: 2.2853356967470164
Validation loss: 2.5092486802661385

Epoch: 376| Step: 0
Training loss: 1.3690764103304474
Validation loss: 2.5171248740944647

Epoch: 5| Step: 1
Training loss: 1.6111753449113386
Validation loss: 2.4985339080507885

Epoch: 5| Step: 2
Training loss: 2.3794816547415247
Validation loss: 2.4768862554253297

Epoch: 5| Step: 3
Training loss: 1.6347959599933402
Validation loss: 2.5595030618432495

Epoch: 5| Step: 4
Training loss: 1.6668411481442893
Validation loss: 2.574222595131305

Epoch: 5| Step: 5
Training loss: 2.1685785759008036
Validation loss: 2.520660608717262

Epoch: 5| Step: 6
Training loss: 1.4739332253122743
Validation loss: 2.5401363513213218

Epoch: 5| Step: 7
Training loss: 1.2501380844140935
Validation loss: 2.514545542571857

Epoch: 5| Step: 8
Training loss: 1.9457272007143267
Validation loss: 2.536566909602486

Epoch: 5| Step: 9
Training loss: 2.1282775510539196
Validation loss: 2.4808993145988536

Epoch: 5| Step: 10
Training loss: 1.4780304086109617
Validation loss: 2.5438506535292

Epoch: 377| Step: 0
Training loss: 2.3835387076965304
Validation loss: 2.479527318388842

Epoch: 5| Step: 1
Training loss: 1.8509382652321065
Validation loss: 2.4477058866225696

Epoch: 5| Step: 2
Training loss: 1.579923832059398
Validation loss: 2.489868140220152

Epoch: 5| Step: 3
Training loss: 1.9371424929662298
Validation loss: 2.526350651018395

Epoch: 5| Step: 4
Training loss: 1.7353406400234839
Validation loss: 2.5620019670352914

Epoch: 5| Step: 5
Training loss: 2.0338753973080315
Validation loss: 2.4878504894062354

Epoch: 5| Step: 6
Training loss: 1.1952872180134981
Validation loss: 2.502954729408553

Epoch: 5| Step: 7
Training loss: 1.7775271813612037
Validation loss: 2.5152616182989442

Epoch: 5| Step: 8
Training loss: 1.5581389028798827
Validation loss: 2.5400242874341483

Epoch: 5| Step: 9
Training loss: 1.61720747635892
Validation loss: 2.5417333375957343

Epoch: 5| Step: 10
Training loss: 1.307380181870995
Validation loss: 2.549001900169393

Epoch: 378| Step: 0
Training loss: 1.4801041045819685
Validation loss: 2.5259298658647813

Epoch: 5| Step: 1
Training loss: 1.624244954685421
Validation loss: 2.501562886191535

Epoch: 5| Step: 2
Training loss: 1.560796190190908
Validation loss: 2.5330592345843823

Epoch: 5| Step: 3
Training loss: 1.8930334718528936
Validation loss: 2.5373070875139083

Epoch: 5| Step: 4
Training loss: 1.3385675430270538
Validation loss: 2.551936897327486

Epoch: 5| Step: 5
Training loss: 2.807280465541898
Validation loss: 2.544424166603581

Epoch: 5| Step: 6
Training loss: 1.7833368224112822
Validation loss: 2.598606108849938

Epoch: 5| Step: 7
Training loss: 1.6706316593949369
Validation loss: 2.611633769345384

Epoch: 5| Step: 8
Training loss: 1.8382628304158126
Validation loss: 2.4857999677932736

Epoch: 5| Step: 9
Training loss: 1.5889103279282766
Validation loss: 2.4922814199936205

Epoch: 5| Step: 10
Training loss: 1.501144608253214
Validation loss: 2.540812116893466

Epoch: 379| Step: 0
Training loss: 1.428090104693045
Validation loss: 2.5387181293199723

Epoch: 5| Step: 1
Training loss: 1.1291456133767184
Validation loss: 2.416827941862562

Epoch: 5| Step: 2
Training loss: 1.1330050600751993
Validation loss: 2.5287512687373472

Epoch: 5| Step: 3
Training loss: 1.2091328617543515
Validation loss: 2.472517048932618

Epoch: 5| Step: 4
Training loss: 1.7351627794578295
Validation loss: 2.5363902397656983

Epoch: 5| Step: 5
Training loss: 2.292083829421911
Validation loss: 2.4812458723000894

Epoch: 5| Step: 6
Training loss: 1.8580734441837097
Validation loss: 2.4633355887757364

Epoch: 5| Step: 7
Training loss: 1.4804515988607037
Validation loss: 2.4879249671457675

Epoch: 5| Step: 8
Training loss: 1.734467031425624
Validation loss: 2.5821746949654734

Epoch: 5| Step: 9
Training loss: 2.1689527873013925
Validation loss: 2.4773718004361025

Epoch: 5| Step: 10
Training loss: 2.288288597545764
Validation loss: 2.5002294655569486

Epoch: 380| Step: 0
Training loss: 1.5184016797664424
Validation loss: 2.4880485284818867

Epoch: 5| Step: 1
Training loss: 0.9777800942132223
Validation loss: 2.507650828192068

Epoch: 5| Step: 2
Training loss: 1.5099952197472903
Validation loss: 2.5619925039690736

Epoch: 5| Step: 3
Training loss: 2.4409263200153446
Validation loss: 2.5334165541100706

Epoch: 5| Step: 4
Training loss: 1.4439141184346094
Validation loss: 2.5188749529029795

Epoch: 5| Step: 5
Training loss: 1.5302580130943293
Validation loss: 2.5310973983942575

Epoch: 5| Step: 6
Training loss: 2.2604702944627335
Validation loss: 2.5794565540219607

Epoch: 5| Step: 7
Training loss: 2.0170416769659054
Validation loss: 2.5098963386195634

Epoch: 5| Step: 8
Training loss: 1.4417034556081059
Validation loss: 2.583515115852786

Epoch: 5| Step: 9
Training loss: 1.897228593879204
Validation loss: 2.506568654149168

Epoch: 5| Step: 10
Training loss: 1.6644452868126873
Validation loss: 2.559697140729484

Epoch: 381| Step: 0
Training loss: 1.6976200695018206
Validation loss: 2.475087485450929

Epoch: 5| Step: 1
Training loss: 2.0984755750483988
Validation loss: 2.429523723247224

Epoch: 5| Step: 2
Training loss: 1.845957646657963
Validation loss: 2.549963677638434

Epoch: 5| Step: 3
Training loss: 2.0119887087525985
Validation loss: 2.6057208326500447

Epoch: 5| Step: 4
Training loss: 1.763437857579667
Validation loss: 2.4964781431859384

Epoch: 5| Step: 5
Training loss: 1.5531802898674196
Validation loss: 2.534332919842104

Epoch: 5| Step: 6
Training loss: 1.8880104082192422
Validation loss: 2.47380078956683

Epoch: 5| Step: 7
Training loss: 1.3745762432124058
Validation loss: 2.5112110172669335

Epoch: 5| Step: 8
Training loss: 1.287682875820967
Validation loss: 2.445904268539797

Epoch: 5| Step: 9
Training loss: 1.6914366263465668
Validation loss: 2.4915972101334973

Epoch: 5| Step: 10
Training loss: 1.7258352413685762
Validation loss: 2.4957779375100873

Epoch: 382| Step: 0
Training loss: 1.4235157983812357
Validation loss: 2.5985139683969893

Epoch: 5| Step: 1
Training loss: 2.044370327287895
Validation loss: 2.5097722604353523

Epoch: 5| Step: 2
Training loss: 1.3962847373554979
Validation loss: 2.537062507537601

Epoch: 5| Step: 3
Training loss: 1.3158649724080171
Validation loss: 2.5112250698715446

Epoch: 5| Step: 4
Training loss: 1.7788878723455084
Validation loss: 2.5457284202230905

Epoch: 5| Step: 5
Training loss: 2.1498196681490063
Validation loss: 2.5732953149722486

Epoch: 5| Step: 6
Training loss: 2.1051420336939612
Validation loss: 2.5818539050731486

Epoch: 5| Step: 7
Training loss: 1.3566241438260247
Validation loss: 2.506511283312891

Epoch: 5| Step: 8
Training loss: 1.7758582981645556
Validation loss: 2.5514610377308125

Epoch: 5| Step: 9
Training loss: 1.8279934045100854
Validation loss: 2.5278182765897674

Epoch: 5| Step: 10
Training loss: 1.7860902976205522
Validation loss: 2.474696974187192

Epoch: 383| Step: 0
Training loss: 1.730230241790298
Validation loss: 2.4955462992989372

Epoch: 5| Step: 1
Training loss: 1.2877715148550406
Validation loss: 2.527396852290095

Epoch: 5| Step: 2
Training loss: 1.704990450253409
Validation loss: 2.477701794807727

Epoch: 5| Step: 3
Training loss: 1.6771648537230086
Validation loss: 2.5637033339836335

Epoch: 5| Step: 4
Training loss: 1.8028733023264094
Validation loss: 2.521396797386239

Epoch: 5| Step: 5
Training loss: 1.4155780405504141
Validation loss: 2.453214493396614

Epoch: 5| Step: 6
Training loss: 2.0496034564308485
Validation loss: 2.43782783051738

Epoch: 5| Step: 7
Training loss: 1.34613650226948
Validation loss: 2.510482923712148

Epoch: 5| Step: 8
Training loss: 2.312552167974174
Validation loss: 2.5302438325036913

Epoch: 5| Step: 9
Training loss: 1.5705516120715104
Validation loss: 2.5535683261597244

Epoch: 5| Step: 10
Training loss: 1.2624689476046833
Validation loss: 2.485798331097208

Epoch: 384| Step: 0
Training loss: 1.2798982327954307
Validation loss: 2.498711999716286

Epoch: 5| Step: 1
Training loss: 1.5784663218402728
Validation loss: 2.551789442916151

Epoch: 5| Step: 2
Training loss: 1.908708206848386
Validation loss: 2.4830009843693515

Epoch: 5| Step: 3
Training loss: 1.6757039227906818
Validation loss: 2.5387572977982438

Epoch: 5| Step: 4
Training loss: 2.562124085184178
Validation loss: 2.483326174131145

Epoch: 5| Step: 5
Training loss: 1.4281896864517194
Validation loss: 2.4928758058845895

Epoch: 5| Step: 6
Training loss: 1.8640558643974388
Validation loss: 2.480795619758033

Epoch: 5| Step: 7
Training loss: 1.8956862871203204
Validation loss: 2.534998319887871

Epoch: 5| Step: 8
Training loss: 1.7968416957256672
Validation loss: 2.4655421984732406

Epoch: 5| Step: 9
Training loss: 1.4166445262899185
Validation loss: 2.5085839129177865

Epoch: 5| Step: 10
Training loss: 1.3000814027242338
Validation loss: 2.512087665162701

Epoch: 385| Step: 0
Training loss: 1.6228824169509808
Validation loss: 2.53386339824337

Epoch: 5| Step: 1
Training loss: 1.8156784076025094
Validation loss: 2.5648491319086255

Epoch: 5| Step: 2
Training loss: 1.658656980411626
Validation loss: 2.5419594054652648

Epoch: 5| Step: 3
Training loss: 1.5344558166228588
Validation loss: 2.5247770773318186

Epoch: 5| Step: 4
Training loss: 1.596958222432173
Validation loss: 2.5252489908792763

Epoch: 5| Step: 5
Training loss: 2.180850248678121
Validation loss: 2.502909787151953

Epoch: 5| Step: 6
Training loss: 1.6326364668725357
Validation loss: 2.5213534121137693

Epoch: 5| Step: 7
Training loss: 1.9459875689635817
Validation loss: 2.49045929747328

Epoch: 5| Step: 8
Training loss: 1.9485621751238749
Validation loss: 2.5145717029231376

Epoch: 5| Step: 9
Training loss: 1.5946724410021629
Validation loss: 2.5871703807594986

Epoch: 5| Step: 10
Training loss: 1.1974503093117785
Validation loss: 2.50797998380654

Epoch: 386| Step: 0
Training loss: 1.7342219929605092
Validation loss: 2.519806377006077

Epoch: 5| Step: 1
Training loss: 1.7846744479832797
Validation loss: 2.493060643850966

Epoch: 5| Step: 2
Training loss: 0.9673899671296539
Validation loss: 2.471623845780549

Epoch: 5| Step: 3
Training loss: 2.089838616195505
Validation loss: 2.481653918322648

Epoch: 5| Step: 4
Training loss: 1.6397730477236085
Validation loss: 2.5125111226147014

Epoch: 5| Step: 5
Training loss: 1.8814996598056117
Validation loss: 2.5555588218917173

Epoch: 5| Step: 6
Training loss: 1.8027714057003836
Validation loss: 2.5180933027521135

Epoch: 5| Step: 7
Training loss: 2.3001934136046547
Validation loss: 2.5076658880546208

Epoch: 5| Step: 8
Training loss: 2.0917409111109073
Validation loss: 2.5225134972268415

Epoch: 5| Step: 9
Training loss: 1.5863303463715286
Validation loss: 2.461896134026294

Epoch: 5| Step: 10
Training loss: 1.3230892979882536
Validation loss: 2.5181482361465277

Epoch: 387| Step: 0
Training loss: 1.2081381651135885
Validation loss: 2.5401853127479295

Epoch: 5| Step: 1
Training loss: 1.4061901079775325
Validation loss: 2.481000467299569

Epoch: 5| Step: 2
Training loss: 1.516681106554536
Validation loss: 2.5968005292970098

Epoch: 5| Step: 3
Training loss: 1.8915498851517445
Validation loss: 2.539963215106259

Epoch: 5| Step: 4
Training loss: 2.542841426163992
Validation loss: 2.4761852192989138

Epoch: 5| Step: 5
Training loss: 1.3765947457216172
Validation loss: 2.523166879838181

Epoch: 5| Step: 6
Training loss: 1.6136890847242549
Validation loss: 2.463380267486396

Epoch: 5| Step: 7
Training loss: 2.060590727280705
Validation loss: 2.5162538937092997

Epoch: 5| Step: 8
Training loss: 1.6624975591655968
Validation loss: 2.5194643225894193

Epoch: 5| Step: 9
Training loss: 1.2237535616517963
Validation loss: 2.4905262024609565

Epoch: 5| Step: 10
Training loss: 1.4199306902290412
Validation loss: 2.509343749558587

Epoch: 388| Step: 0
Training loss: 1.4584374072767792
Validation loss: 2.489293439966565

Epoch: 5| Step: 1
Training loss: 2.1970717145339003
Validation loss: 2.5156187825427696

Epoch: 5| Step: 2
Training loss: 1.5645872289589624
Validation loss: 2.4730335994760537

Epoch: 5| Step: 3
Training loss: 1.484725990960707
Validation loss: 2.492614392701397

Epoch: 5| Step: 4
Training loss: 1.4173692008462608
Validation loss: 2.551748447072865

Epoch: 5| Step: 5
Training loss: 1.8152208623676638
Validation loss: 2.5076449068636584

Epoch: 5| Step: 6
Training loss: 2.2066230869119607
Validation loss: 2.4918328487192563

Epoch: 5| Step: 7
Training loss: 1.7902952386546982
Validation loss: 2.453269969365793

Epoch: 5| Step: 8
Training loss: 1.2736941119989749
Validation loss: 2.575983618298645

Epoch: 5| Step: 9
Training loss: 1.6104319536767444
Validation loss: 2.480834380017448

Epoch: 5| Step: 10
Training loss: 1.645101923930067
Validation loss: 2.530080616577873

Epoch: 389| Step: 0
Training loss: 1.494639115297133
Validation loss: 2.552996638307747

Epoch: 5| Step: 1
Training loss: 1.5101917844835573
Validation loss: 2.554732390379984

Epoch: 5| Step: 2
Training loss: 1.4265527597452083
Validation loss: 2.477072318090621

Epoch: 5| Step: 3
Training loss: 1.5148855548852607
Validation loss: 2.516927766107797

Epoch: 5| Step: 4
Training loss: 2.074543555739586
Validation loss: 2.4517461714740145

Epoch: 5| Step: 5
Training loss: 1.5399998942288449
Validation loss: 2.5055095566642773

Epoch: 5| Step: 6
Training loss: 1.4533177729890627
Validation loss: 2.5401596488143925

Epoch: 5| Step: 7
Training loss: 1.6125461483051635
Validation loss: 2.4924317664962614

Epoch: 5| Step: 8
Training loss: 2.3464711986036533
Validation loss: 2.5359175982207485

Epoch: 5| Step: 9
Training loss: 1.5630024674262488
Validation loss: 2.4316927076701322

Epoch: 5| Step: 10
Training loss: 1.8306078230760812
Validation loss: 2.492714669943866

Epoch: 390| Step: 0
Training loss: 1.8930230183680516
Validation loss: 2.550853832551233

Epoch: 5| Step: 1
Training loss: 2.0416074341985424
Validation loss: 2.4980282945294783

Epoch: 5| Step: 2
Training loss: 1.9875961952202228
Validation loss: 2.5246211873754274

Epoch: 5| Step: 3
Training loss: 1.4616302642871009
Validation loss: 2.447126034571428

Epoch: 5| Step: 4
Training loss: 1.8678739554787707
Validation loss: 2.5318084945338333

Epoch: 5| Step: 5
Training loss: 1.3193969260688374
Validation loss: 2.4361582634687853

Epoch: 5| Step: 6
Training loss: 1.734638572116928
Validation loss: 2.5258790630597603

Epoch: 5| Step: 7
Training loss: 1.947044551318101
Validation loss: 2.4852133644498595

Epoch: 5| Step: 8
Training loss: 1.370014080754893
Validation loss: 2.508480362989196

Epoch: 5| Step: 9
Training loss: 1.5591082572224604
Validation loss: 2.544468558470607

Epoch: 5| Step: 10
Training loss: 1.222927270655931
Validation loss: 2.5272362121880656

Epoch: 391| Step: 0
Training loss: 1.5108596765936164
Validation loss: 2.503639903119832

Epoch: 5| Step: 1
Training loss: 1.525942029944326
Validation loss: 2.526966908859725

Epoch: 5| Step: 2
Training loss: 1.948277982225216
Validation loss: 2.4978875372034377

Epoch: 5| Step: 3
Training loss: 1.4815318937907938
Validation loss: 2.4860431717390714

Epoch: 5| Step: 4
Training loss: 1.5202533016460682
Validation loss: 2.518562217415211

Epoch: 5| Step: 5
Training loss: 1.6820729195145885
Validation loss: 2.5128057120102314

Epoch: 5| Step: 6
Training loss: 1.7337190229513006
Validation loss: 2.599945577914851

Epoch: 5| Step: 7
Training loss: 1.6346968587360617
Validation loss: 2.4949816953554085

Epoch: 5| Step: 8
Training loss: 2.2275856210541485
Validation loss: 2.507068464241316

Epoch: 5| Step: 9
Training loss: 1.7905526431178975
Validation loss: 2.5160647801285285

Epoch: 5| Step: 10
Training loss: 1.6640124962685938
Validation loss: 2.5418448591648874

Epoch: 392| Step: 0
Training loss: 1.4461016176113808
Validation loss: 2.550285346553489

Epoch: 5| Step: 1
Training loss: 1.5197607813366594
Validation loss: 2.511615944806185

Epoch: 5| Step: 2
Training loss: 2.4082873748125238
Validation loss: 2.4506529237081844

Epoch: 5| Step: 3
Training loss: 1.5292362283931886
Validation loss: 2.5617173673230753

Epoch: 5| Step: 4
Training loss: 1.4385520568221986
Validation loss: 2.5012141243095063

Epoch: 5| Step: 5
Training loss: 1.362069583417718
Validation loss: 2.479304016091933

Epoch: 5| Step: 6
Training loss: 1.657041756301227
Validation loss: 2.5055379963830022

Epoch: 5| Step: 7
Training loss: 1.279061565161167
Validation loss: 2.56637564283581

Epoch: 5| Step: 8
Training loss: 2.289003651353983
Validation loss: 2.496184131275542

Epoch: 5| Step: 9
Training loss: 1.122948630638244
Validation loss: 2.4966426537709423

Epoch: 5| Step: 10
Training loss: 2.214842781187784
Validation loss: 2.519634164150494

Epoch: 393| Step: 0
Training loss: 1.326777234350154
Validation loss: 2.3927216991669273

Epoch: 5| Step: 1
Training loss: 1.693393024959416
Validation loss: 2.4112823648212043

Epoch: 5| Step: 2
Training loss: 1.9580873240168177
Validation loss: 2.5374067876888744

Epoch: 5| Step: 3
Training loss: 1.5045108521140778
Validation loss: 2.4734592561707704

Epoch: 5| Step: 4
Training loss: 1.5749102793978698
Validation loss: 2.4950515615465445

Epoch: 5| Step: 5
Training loss: 1.6531881424900206
Validation loss: 2.500853541497723

Epoch: 5| Step: 6
Training loss: 1.4298530024221954
Validation loss: 2.4998597085208045

Epoch: 5| Step: 7
Training loss: 1.4947658452407817
Validation loss: 2.464857693305393

Epoch: 5| Step: 8
Training loss: 1.8723196580978392
Validation loss: 2.5516019332393967

Epoch: 5| Step: 9
Training loss: 2.3117194018116476
Validation loss: 2.5363353987426693

Epoch: 5| Step: 10
Training loss: 1.701370105077462
Validation loss: 2.565097056049448

Epoch: 394| Step: 0
Training loss: 1.5729688505227832
Validation loss: 2.525496951202432

Epoch: 5| Step: 1
Training loss: 1.4686488664587052
Validation loss: 2.4939187288161855

Epoch: 5| Step: 2
Training loss: 1.5666519695296022
Validation loss: 2.462552375625822

Epoch: 5| Step: 3
Training loss: 1.236978079812091
Validation loss: 2.523339678085729

Epoch: 5| Step: 4
Training loss: 2.0681201771287663
Validation loss: 2.480468800901387

Epoch: 5| Step: 5
Training loss: 1.4892623751210845
Validation loss: 2.5356101015308465

Epoch: 5| Step: 6
Training loss: 1.89353063842548
Validation loss: 2.5145377957034682

Epoch: 5| Step: 7
Training loss: 1.809429000549393
Validation loss: 2.520731492113815

Epoch: 5| Step: 8
Training loss: 1.2823567146435146
Validation loss: 2.5426353802013164

Epoch: 5| Step: 9
Training loss: 1.3313699014602065
Validation loss: 2.518877913600261

Epoch: 5| Step: 10
Training loss: 2.5861016996407953
Validation loss: 2.507938619386515

Epoch: 395| Step: 0
Training loss: 1.9670929368661454
Validation loss: 2.521288567685574

Epoch: 5| Step: 1
Training loss: 1.6846157432732638
Validation loss: 2.5100419046405804

Epoch: 5| Step: 2
Training loss: 1.4395222744319782
Validation loss: 2.4349577998462983

Epoch: 5| Step: 3
Training loss: 2.04385805923415
Validation loss: 2.489912326359927

Epoch: 5| Step: 4
Training loss: 1.4100330753369978
Validation loss: 2.4664343132772033

Epoch: 5| Step: 5
Training loss: 1.3838547911072474
Validation loss: 2.483290793471661

Epoch: 5| Step: 6
Training loss: 1.3747984998617682
Validation loss: 2.4923390412397057

Epoch: 5| Step: 7
Training loss: 1.121711959255061
Validation loss: 2.5368819229964497

Epoch: 5| Step: 8
Training loss: 2.189608838059551
Validation loss: 2.507676929102012

Epoch: 5| Step: 9
Training loss: 2.104465337524484
Validation loss: 2.527411527216664

Epoch: 5| Step: 10
Training loss: 1.125034967514834
Validation loss: 2.471710004841112

Epoch: 396| Step: 0
Training loss: 1.351726985029253
Validation loss: 2.49864559504299

Epoch: 5| Step: 1
Training loss: 1.655957322082116
Validation loss: 2.4858218759028334

Epoch: 5| Step: 2
Training loss: 1.5445528421547292
Validation loss: 2.487614443191057

Epoch: 5| Step: 3
Training loss: 1.410435191962076
Validation loss: 2.5425871001629643

Epoch: 5| Step: 4
Training loss: 1.7592231346161789
Validation loss: 2.4775737740763435

Epoch: 5| Step: 5
Training loss: 1.4525370074759398
Validation loss: 2.5385214012743833

Epoch: 5| Step: 6
Training loss: 1.9663835259732196
Validation loss: 2.479037831544427

Epoch: 5| Step: 7
Training loss: 1.1870364237967965
Validation loss: 2.543169042229771

Epoch: 5| Step: 8
Training loss: 2.5163006556377536
Validation loss: 2.509968656679147

Epoch: 5| Step: 9
Training loss: 1.6277734124244827
Validation loss: 2.5038440263970876

Epoch: 5| Step: 10
Training loss: 1.8862370415122993
Validation loss: 2.513334241848242

Epoch: 397| Step: 0
Training loss: 1.5464777580904003
Validation loss: 2.4699204353297093

Epoch: 5| Step: 1
Training loss: 1.7504329826952383
Validation loss: 2.506282914055287

Epoch: 5| Step: 2
Training loss: 2.482245342181497
Validation loss: 2.491871252113882

Epoch: 5| Step: 3
Training loss: 1.8205727321613931
Validation loss: 2.503506148162409

Epoch: 5| Step: 4
Training loss: 1.6303617346335892
Validation loss: 2.56031422168092

Epoch: 5| Step: 5
Training loss: 1.951196007870496
Validation loss: 2.4302217136079394

Epoch: 5| Step: 6
Training loss: 1.57148410494634
Validation loss: 2.5062552192753733

Epoch: 5| Step: 7
Training loss: 1.092629485411428
Validation loss: 2.50656214217069

Epoch: 5| Step: 8
Training loss: 1.4690752683797517
Validation loss: 2.516379545192046

Epoch: 5| Step: 9
Training loss: 1.3475805288962703
Validation loss: 2.5053139436356964

Epoch: 5| Step: 10
Training loss: 0.8489684043864196
Validation loss: 2.580676285943129

Epoch: 398| Step: 0
Training loss: 1.5190635294735169
Validation loss: 2.511509830195975

Epoch: 5| Step: 1
Training loss: 1.3254319656450078
Validation loss: 2.5241352390260414

Epoch: 5| Step: 2
Training loss: 1.5259524201041232
Validation loss: 2.5084572040888338

Epoch: 5| Step: 3
Training loss: 1.3889090420002577
Validation loss: 2.458712880576916

Epoch: 5| Step: 4
Training loss: 1.7018199435156778
Validation loss: 2.478151604966675

Epoch: 5| Step: 5
Training loss: 2.087075940763399
Validation loss: 2.550090780578577

Epoch: 5| Step: 6
Training loss: 1.6526353366852564
Validation loss: 2.5006659758960117

Epoch: 5| Step: 7
Training loss: 1.6655763715619933
Validation loss: 2.469372321587166

Epoch: 5| Step: 8
Training loss: 1.8550815539670746
Validation loss: 2.523046586877735

Epoch: 5| Step: 9
Training loss: 2.144423296214147
Validation loss: 2.477880698819022

Epoch: 5| Step: 10
Training loss: 1.319597852165507
Validation loss: 2.555970389311253

Epoch: 399| Step: 0
Training loss: 1.5278742422610556
Validation loss: 2.5363257393425767

Epoch: 5| Step: 1
Training loss: 1.2915657014251025
Validation loss: 2.5254948052728543

Epoch: 5| Step: 2
Training loss: 2.2141274668140807
Validation loss: 2.4843226421027182

Epoch: 5| Step: 3
Training loss: 1.5514185290273779
Validation loss: 2.4338724590416465

Epoch: 5| Step: 4
Training loss: 1.6398687163583765
Validation loss: 2.494156538360018

Epoch: 5| Step: 5
Training loss: 1.818055353860024
Validation loss: 2.503948567678369

Epoch: 5| Step: 6
Training loss: 1.269609607332436
Validation loss: 2.535615220495875

Epoch: 5| Step: 7
Training loss: 1.2697235431291973
Validation loss: 2.4841195561627356

Epoch: 5| Step: 8
Training loss: 1.578233167510515
Validation loss: 2.5150314249354544

Epoch: 5| Step: 9
Training loss: 1.977981178876859
Validation loss: 2.5175315609318263

Epoch: 5| Step: 10
Training loss: 1.6904234817188226
Validation loss: 2.5143931899096503

Epoch: 400| Step: 0
Training loss: 1.342035752623219
Validation loss: 2.445690354515905

Epoch: 5| Step: 1
Training loss: 1.6173661727611321
Validation loss: 2.505199175928289

Epoch: 5| Step: 2
Training loss: 1.5955123133601132
Validation loss: 2.495013229708563

Epoch: 5| Step: 3
Training loss: 0.9799398994506445
Validation loss: 2.43591574948505

Epoch: 5| Step: 4
Training loss: 1.433320479372333
Validation loss: 2.5255847571384336

Epoch: 5| Step: 5
Training loss: 1.749655757833466
Validation loss: 2.5550391800688663

Epoch: 5| Step: 6
Training loss: 2.417556555006578
Validation loss: 2.499711717371007

Epoch: 5| Step: 7
Training loss: 2.027526024064618
Validation loss: 2.5346397107398637

Epoch: 5| Step: 8
Training loss: 1.3436004644182453
Validation loss: 2.5216798722844938

Epoch: 5| Step: 9
Training loss: 1.7947195642666773
Validation loss: 2.533132241435939

Epoch: 5| Step: 10
Training loss: 1.2384890312814858
Validation loss: 2.5184939719964095

Epoch: 401| Step: 0
Training loss: 1.737383664305043
Validation loss: 2.476188813922513

Epoch: 5| Step: 1
Training loss: 2.2311252890390096
Validation loss: 2.55544009385524

Epoch: 5| Step: 2
Training loss: 1.7143652037515538
Validation loss: 2.549524672971488

Epoch: 5| Step: 3
Training loss: 1.3110684353318147
Validation loss: 2.474670608824386

Epoch: 5| Step: 4
Training loss: 1.480477526797244
Validation loss: 2.4826958605003027

Epoch: 5| Step: 5
Training loss: 1.0359359395977714
Validation loss: 2.5319945226530787

Epoch: 5| Step: 6
Training loss: 1.9307950814247112
Validation loss: 2.499213826225433

Epoch: 5| Step: 7
Training loss: 1.899052461462966
Validation loss: 2.4958220963173168

Epoch: 5| Step: 8
Training loss: 1.3382331799426945
Validation loss: 2.44110119744477

Epoch: 5| Step: 9
Training loss: 1.7347096300783729
Validation loss: 2.478104259720373

Epoch: 5| Step: 10
Training loss: 1.9592735252082674
Validation loss: 2.4502065225381533

Epoch: 402| Step: 0
Training loss: 1.7200765865485552
Validation loss: 2.5030039961664183

Epoch: 5| Step: 1
Training loss: 1.6543456591694548
Validation loss: 2.486710316375731

Epoch: 5| Step: 2
Training loss: 1.5333407394949028
Validation loss: 2.519065478740004

Epoch: 5| Step: 3
Training loss: 1.2716888872674208
Validation loss: 2.471971948088193

Epoch: 5| Step: 4
Training loss: 2.0815799073626944
Validation loss: 2.5144430512595237

Epoch: 5| Step: 5
Training loss: 1.7405715769816987
Validation loss: 2.5478263692145955

Epoch: 5| Step: 6
Training loss: 1.408199315588424
Validation loss: 2.5246720104149225

Epoch: 5| Step: 7
Training loss: 1.5258680468363577
Validation loss: 2.5416729821244854

Epoch: 5| Step: 8
Training loss: 2.1036498187232717
Validation loss: 2.573249464734391

Epoch: 5| Step: 9
Training loss: 1.3842894000246588
Validation loss: 2.484919450131612

Epoch: 5| Step: 10
Training loss: 1.6625817386352566
Validation loss: 2.544076900052176

Epoch: 403| Step: 0
Training loss: 1.4211898662155384
Validation loss: 2.559541337332034

Epoch: 5| Step: 1
Training loss: 2.140770232014472
Validation loss: 2.5639672019506876

Epoch: 5| Step: 2
Training loss: 1.6085205772916928
Validation loss: 2.505350986140955

Epoch: 5| Step: 3
Training loss: 1.3654552275623972
Validation loss: 2.5142069708854713

Epoch: 5| Step: 4
Training loss: 1.4096349878156051
Validation loss: 2.5070549203304013

Epoch: 5| Step: 5
Training loss: 1.861985689876485
Validation loss: 2.544673803672112

Epoch: 5| Step: 6
Training loss: 1.2901568304880395
Validation loss: 2.5316273255990183

Epoch: 5| Step: 7
Training loss: 1.5682966663940314
Validation loss: 2.474517330795258

Epoch: 5| Step: 8
Training loss: 2.272557143866233
Validation loss: 2.49152748116175

Epoch: 5| Step: 9
Training loss: 0.9732815061830069
Validation loss: 2.5265389858146556

Epoch: 5| Step: 10
Training loss: 1.6673219664098629
Validation loss: 2.4065135603182206

Epoch: 404| Step: 0
Training loss: 1.348956511900076
Validation loss: 2.4928401915660467

Epoch: 5| Step: 1
Training loss: 1.1938311304614138
Validation loss: 2.5748846080590155

Epoch: 5| Step: 2
Training loss: 1.763854227534813
Validation loss: 2.4965441377686304

Epoch: 5| Step: 3
Training loss: 1.6474997940410665
Validation loss: 2.457869314037185

Epoch: 5| Step: 4
Training loss: 1.2178058390524529
Validation loss: 2.513755928945077

Epoch: 5| Step: 5
Training loss: 1.1313511861154202
Validation loss: 2.5284516739548657

Epoch: 5| Step: 6
Training loss: 1.4200074223875099
Validation loss: 2.5447698323317662

Epoch: 5| Step: 7
Training loss: 2.06950575746969
Validation loss: 2.5062954136858235

Epoch: 5| Step: 8
Training loss: 1.9695954702363967
Validation loss: 2.55117867319532

Epoch: 5| Step: 9
Training loss: 1.887509450825658
Validation loss: 2.5465623643700743

Epoch: 5| Step: 10
Training loss: 1.7818914228985074
Validation loss: 2.5343604180560972

Epoch: 405| Step: 0
Training loss: 1.833737552759198
Validation loss: 2.472686916168219

Epoch: 5| Step: 1
Training loss: 1.6123290126543643
Validation loss: 2.537032340609381

Epoch: 5| Step: 2
Training loss: 1.375645702644768
Validation loss: 2.484989491934009

Epoch: 5| Step: 3
Training loss: 1.7156257671083497
Validation loss: 2.4842033737131297

Epoch: 5| Step: 4
Training loss: 1.6542583943004567
Validation loss: 2.5198655216042583

Epoch: 5| Step: 5
Training loss: 1.3334080357287839
Validation loss: 2.5167355942843805

Epoch: 5| Step: 6
Training loss: 1.8666151757745255
Validation loss: 2.540693940844295

Epoch: 5| Step: 7
Training loss: 1.5440779549976158
Validation loss: 2.5785014956834726

Epoch: 5| Step: 8
Training loss: 1.490192937712317
Validation loss: 2.49232263899771

Epoch: 5| Step: 9
Training loss: 1.3298639917743627
Validation loss: 2.452150459432632

Epoch: 5| Step: 10
Training loss: 2.3228357640249344
Validation loss: 2.4677438675633394

Epoch: 406| Step: 0
Training loss: 1.4236258322515458
Validation loss: 2.4637233182658607

Epoch: 5| Step: 1
Training loss: 1.7499551086117529
Validation loss: 2.5058505920277208

Epoch: 5| Step: 2
Training loss: 1.431403292646748
Validation loss: 2.518281791640985

Epoch: 5| Step: 3
Training loss: 1.7045815914831755
Validation loss: 2.48068148697339

Epoch: 5| Step: 4
Training loss: 1.8989287317772463
Validation loss: 2.5133185503862108

Epoch: 5| Step: 5
Training loss: 2.2769477722450593
Validation loss: 2.4929799525564142

Epoch: 5| Step: 6
Training loss: 1.4568009999979306
Validation loss: 2.442453497878321

Epoch: 5| Step: 7
Training loss: 1.410248645069734
Validation loss: 2.5082264163996446

Epoch: 5| Step: 8
Training loss: 1.5623721261151025
Validation loss: 2.51931757363084

Epoch: 5| Step: 9
Training loss: 1.3684606237520192
Validation loss: 2.428921752458449

Epoch: 5| Step: 10
Training loss: 1.8229506207891566
Validation loss: 2.5152574537046006

Epoch: 407| Step: 0
Training loss: 1.4393827299505957
Validation loss: 2.491801855406652

Epoch: 5| Step: 1
Training loss: 1.670467318861704
Validation loss: 2.4672774074982953

Epoch: 5| Step: 2
Training loss: 1.6467286423102712
Validation loss: 2.478407872853978

Epoch: 5| Step: 3
Training loss: 1.8202817856976572
Validation loss: 2.5348090831531405

Epoch: 5| Step: 4
Training loss: 1.1462466043736073
Validation loss: 2.5067960350377274

Epoch: 5| Step: 5
Training loss: 2.0619761639835175
Validation loss: 2.4990752817222597

Epoch: 5| Step: 6
Training loss: 1.4818926483480601
Validation loss: 2.5324497020734515

Epoch: 5| Step: 7
Training loss: 1.3716235319209849
Validation loss: 2.548451111926551

Epoch: 5| Step: 8
Training loss: 2.424869187749672
Validation loss: 2.4863065739888497

Epoch: 5| Step: 9
Training loss: 1.5203457490553036
Validation loss: 2.463049803715528

Epoch: 5| Step: 10
Training loss: 1.374731991397595
Validation loss: 2.4445473304225698

Epoch: 408| Step: 0
Training loss: 1.905917967348949
Validation loss: 2.4987296465932487

Epoch: 5| Step: 1
Training loss: 1.80683210028407
Validation loss: 2.426656659552003

Epoch: 5| Step: 2
Training loss: 1.399638124086037
Validation loss: 2.5221627249747507

Epoch: 5| Step: 3
Training loss: 1.2975000001470018
Validation loss: 2.5517702511245406

Epoch: 5| Step: 4
Training loss: 1.5764363384901192
Validation loss: 2.5408214298054843

Epoch: 5| Step: 5
Training loss: 2.3584965971743643
Validation loss: 2.5675884950117505

Epoch: 5| Step: 6
Training loss: 1.3217235902327162
Validation loss: 2.5180821760435137

Epoch: 5| Step: 7
Training loss: 1.0266301682928647
Validation loss: 2.4846590586189117

Epoch: 5| Step: 8
Training loss: 2.096587464676777
Validation loss: 2.523545340897946

Epoch: 5| Step: 9
Training loss: 1.1928401635399812
Validation loss: 2.562353511637998

Epoch: 5| Step: 10
Training loss: 1.1138044767403843
Validation loss: 2.4908567070710252

Epoch: 409| Step: 0
Training loss: 1.386490666074318
Validation loss: 2.462361593704894

Epoch: 5| Step: 1
Training loss: 1.2991746483231972
Validation loss: 2.4736023674111496

Epoch: 5| Step: 2
Training loss: 1.8077867985829688
Validation loss: 2.512653776754555

Epoch: 5| Step: 3
Training loss: 1.4948500600789096
Validation loss: 2.5105409910958416

Epoch: 5| Step: 4
Training loss: 1.1985997892110007
Validation loss: 2.500452198642311

Epoch: 5| Step: 5
Training loss: 1.7238210602318833
Validation loss: 2.5213399896756665

Epoch: 5| Step: 6
Training loss: 1.9416616720809332
Validation loss: 2.4610846466851695

Epoch: 5| Step: 7
Training loss: 1.4748045937365468
Validation loss: 2.471947462950572

Epoch: 5| Step: 8
Training loss: 2.0735396658270266
Validation loss: 2.533343496758303

Epoch: 5| Step: 9
Training loss: 1.697848273774028
Validation loss: 2.50695185229918

Epoch: 5| Step: 10
Training loss: 1.261177442900272
Validation loss: 2.5083325544225334

Epoch: 410| Step: 0
Training loss: 1.738988291073076
Validation loss: 2.5603580862214357

Epoch: 5| Step: 1
Training loss: 1.912259369715366
Validation loss: 2.4940746362017863

Epoch: 5| Step: 2
Training loss: 0.9795404424219293
Validation loss: 2.5096284802287925

Epoch: 5| Step: 3
Training loss: 1.3300515955045134
Validation loss: 2.4672689464466817

Epoch: 5| Step: 4
Training loss: 1.8864644828989645
Validation loss: 2.453687394500862

Epoch: 5| Step: 5
Training loss: 1.3936854770932605
Validation loss: 2.5419105356979133

Epoch: 5| Step: 6
Training loss: 2.358743747365293
Validation loss: 2.456582742514997

Epoch: 5| Step: 7
Training loss: 1.6554392863771046
Validation loss: 2.538243500263851

Epoch: 5| Step: 8
Training loss: 1.6294226982647446
Validation loss: 2.4930542534066795

Epoch: 5| Step: 9
Training loss: 1.3254162260596654
Validation loss: 2.4900677608220434

Epoch: 5| Step: 10
Training loss: 1.5838669664024003
Validation loss: 2.5086534707985524

Epoch: 411| Step: 0
Training loss: 1.160819175717861
Validation loss: 2.523967434181508

Epoch: 5| Step: 1
Training loss: 1.4633805354824931
Validation loss: 2.542206355074268

Epoch: 5| Step: 2
Training loss: 1.7510308907756138
Validation loss: 2.4702689982085917

Epoch: 5| Step: 3
Training loss: 1.151756783689208
Validation loss: 2.41083934891636

Epoch: 5| Step: 4
Training loss: 2.582712519303483
Validation loss: 2.5361194349239193

Epoch: 5| Step: 5
Training loss: 1.663018198924174
Validation loss: 2.4892113932470337

Epoch: 5| Step: 6
Training loss: 1.2579995721109751
Validation loss: 2.5467254017964462

Epoch: 5| Step: 7
Training loss: 2.0245502019467527
Validation loss: 2.505767826987452

Epoch: 5| Step: 8
Training loss: 1.2382425007337916
Validation loss: 2.476852063119258

Epoch: 5| Step: 9
Training loss: 1.520228287343397
Validation loss: 2.5620107556378655

Epoch: 5| Step: 10
Training loss: 1.7466141780702837
Validation loss: 2.499362678713374

Epoch: 412| Step: 0
Training loss: 1.3260783863402457
Validation loss: 2.5057256801999412

Epoch: 5| Step: 1
Training loss: 1.812945081061023
Validation loss: 2.4709233901240535

Epoch: 5| Step: 2
Training loss: 1.5132043128673895
Validation loss: 2.4614829859177054

Epoch: 5| Step: 3
Training loss: 1.7349991920975005
Validation loss: 2.448197098489118

Epoch: 5| Step: 4
Training loss: 1.793322293532377
Validation loss: 2.51954833490179

Epoch: 5| Step: 5
Training loss: 1.682084471360676
Validation loss: 2.498644704464321

Epoch: 5| Step: 6
Training loss: 1.4412412471455829
Validation loss: 2.5097329685146597

Epoch: 5| Step: 7
Training loss: 1.635344080518908
Validation loss: 2.5044241644052194

Epoch: 5| Step: 8
Training loss: 1.2131509547574575
Validation loss: 2.4902942826723597

Epoch: 5| Step: 9
Training loss: 2.247975816440486
Validation loss: 2.513885875216566

Epoch: 5| Step: 10
Training loss: 1.4106193056950802
Validation loss: 2.516884197867534

Epoch: 413| Step: 0
Training loss: 0.9527656628240392
Validation loss: 2.4912336181897596

Epoch: 5| Step: 1
Training loss: 2.1222699523915365
Validation loss: 2.5608640811749486

Epoch: 5| Step: 2
Training loss: 1.645465648801426
Validation loss: 2.494869727200258

Epoch: 5| Step: 3
Training loss: 1.248919592291775
Validation loss: 2.4660886753203037

Epoch: 5| Step: 4
Training loss: 1.4697590871868376
Validation loss: 2.4859749921407555

Epoch: 5| Step: 5
Training loss: 1.523035162591819
Validation loss: 2.5483765903041884

Epoch: 5| Step: 6
Training loss: 1.5822679884116027
Validation loss: 2.49430349316418

Epoch: 5| Step: 7
Training loss: 1.4592753047503824
Validation loss: 2.6074376397253327

Epoch: 5| Step: 8
Training loss: 1.6749727303861492
Validation loss: 2.565301687630028

Epoch: 5| Step: 9
Training loss: 2.269333428643236
Validation loss: 2.550599132015813

Epoch: 5| Step: 10
Training loss: 1.0749246393447243
Validation loss: 2.450261427338007

Epoch: 414| Step: 0
Training loss: 1.5654383687083837
Validation loss: 2.463716734662965

Epoch: 5| Step: 1
Training loss: 1.405455089118899
Validation loss: 2.5210999334548614

Epoch: 5| Step: 2
Training loss: 2.2382416247310544
Validation loss: 2.51161384417665

Epoch: 5| Step: 3
Training loss: 1.0024792217660334
Validation loss: 2.51290715350619

Epoch: 5| Step: 4
Training loss: 1.4939698763750604
Validation loss: 2.5185810998700524

Epoch: 5| Step: 5
Training loss: 1.368585362396164
Validation loss: 2.4826569444641517

Epoch: 5| Step: 6
Training loss: 1.3965280806097815
Validation loss: 2.4278637397484135

Epoch: 5| Step: 7
Training loss: 2.015647474060149
Validation loss: 2.396964998918407

Epoch: 5| Step: 8
Training loss: 1.8203385641826997
Validation loss: 2.5123020084924734

Epoch: 5| Step: 9
Training loss: 1.69071294305497
Validation loss: 2.443536926225597

Epoch: 5| Step: 10
Training loss: 1.280600127113118
Validation loss: 2.5190060446440734

Epoch: 415| Step: 0
Training loss: 1.2637867234173936
Validation loss: 2.5309125927831726

Epoch: 5| Step: 1
Training loss: 1.110539107642717
Validation loss: 2.457557502267209

Epoch: 5| Step: 2
Training loss: 2.4872048054272944
Validation loss: 2.4428894751041077

Epoch: 5| Step: 3
Training loss: 1.4862894662248296
Validation loss: 2.448167211469793

Epoch: 5| Step: 4
Training loss: 1.6899996716877093
Validation loss: 2.457923093311757

Epoch: 5| Step: 5
Training loss: 1.1822375090486317
Validation loss: 2.5366505192113658

Epoch: 5| Step: 6
Training loss: 1.524464266119589
Validation loss: 2.4515485001515147

Epoch: 5| Step: 7
Training loss: 1.5097736787766267
Validation loss: 2.4822009730838346

Epoch: 5| Step: 8
Training loss: 1.5774212769514833
Validation loss: 2.510310223923074

Epoch: 5| Step: 9
Training loss: 1.9139219894216684
Validation loss: 2.5185810347250377

Epoch: 5| Step: 10
Training loss: 1.294301017956767
Validation loss: 2.4922740611488146

Epoch: 416| Step: 0
Training loss: 1.230327053085734
Validation loss: 2.578215236582427

Epoch: 5| Step: 1
Training loss: 1.2701681094907034
Validation loss: 2.524602708047415

Epoch: 5| Step: 2
Training loss: 1.6267539608832269
Validation loss: 2.496739669332279

Epoch: 5| Step: 3
Training loss: 2.035289093777949
Validation loss: 2.578118006503159

Epoch: 5| Step: 4
Training loss: 1.2826132616145947
Validation loss: 2.48032690418923

Epoch: 5| Step: 5
Training loss: 2.3949804584765144
Validation loss: 2.479814578323345

Epoch: 5| Step: 6
Training loss: 1.3715415288608708
Validation loss: 2.537854378330847

Epoch: 5| Step: 7
Training loss: 1.6487310066893335
Validation loss: 2.4814880710665257

Epoch: 5| Step: 8
Training loss: 1.62404230213506
Validation loss: 2.556807210448537

Epoch: 5| Step: 9
Training loss: 1.3098114269609147
Validation loss: 2.512008271381452

Epoch: 5| Step: 10
Training loss: 1.1342752943541807
Validation loss: 2.6093422559324795

Epoch: 417| Step: 0
Training loss: 2.3956745150350716
Validation loss: 2.510308877922396

Epoch: 5| Step: 1
Training loss: 1.774240253272825
Validation loss: 2.520253431461089

Epoch: 5| Step: 2
Training loss: 1.5538553282313634
Validation loss: 2.4557012267722063

Epoch: 5| Step: 3
Training loss: 1.2532984606392585
Validation loss: 2.564397315080241

Epoch: 5| Step: 4
Training loss: 1.4322557571995904
Validation loss: 2.4981283154562677

Epoch: 5| Step: 5
Training loss: 0.9609857872716773
Validation loss: 2.5385193784534468

Epoch: 5| Step: 6
Training loss: 2.0003075363223934
Validation loss: 2.5454501115676167

Epoch: 5| Step: 7
Training loss: 1.6339624909119406
Validation loss: 2.431882717750628

Epoch: 5| Step: 8
Training loss: 1.9140684789447435
Validation loss: 2.4778116883233454

Epoch: 5| Step: 9
Training loss: 1.1765361402985932
Validation loss: 2.4618007330233964

Epoch: 5| Step: 10
Training loss: 1.4004205889402421
Validation loss: 2.4871853348308033

Epoch: 418| Step: 0
Training loss: 1.4695773939303431
Validation loss: 2.5425648412683155

Epoch: 5| Step: 1
Training loss: 1.6042249924926635
Validation loss: 2.47791888081413

Epoch: 5| Step: 2
Training loss: 1.6483952666020534
Validation loss: 2.572223964821009

Epoch: 5| Step: 3
Training loss: 1.2713117116017318
Validation loss: 2.5560851059693945

Epoch: 5| Step: 4
Training loss: 1.63574138584402
Validation loss: 2.4535861271977146

Epoch: 5| Step: 5
Training loss: 1.6112004269948808
Validation loss: 2.567792670462719

Epoch: 5| Step: 6
Training loss: 1.5478842939411879
Validation loss: 2.5363154244191115

Epoch: 5| Step: 7
Training loss: 1.5363902793511222
Validation loss: 2.5785028731979542

Epoch: 5| Step: 8
Training loss: 1.6384401578152243
Validation loss: 2.535579857669762

Epoch: 5| Step: 9
Training loss: 1.0620557192752822
Validation loss: 2.4870876981589496

Epoch: 5| Step: 10
Training loss: 2.3512399648708775
Validation loss: 2.4993628171852653

Epoch: 419| Step: 0
Training loss: 1.8120081003862754
Validation loss: 2.5038825578490003

Epoch: 5| Step: 1
Training loss: 1.2574045218591339
Validation loss: 2.5251083752419583

Epoch: 5| Step: 2
Training loss: 1.3958650936479917
Validation loss: 2.4362158841286052

Epoch: 5| Step: 3
Training loss: 2.387184110185394
Validation loss: 2.530762100141349

Epoch: 5| Step: 4
Training loss: 1.6153965860489201
Validation loss: 2.5173687759488286

Epoch: 5| Step: 5
Training loss: 1.7400764025433575
Validation loss: 2.521498040680719

Epoch: 5| Step: 6
Training loss: 1.076864251754532
Validation loss: 2.4978790566781077

Epoch: 5| Step: 7
Training loss: 1.4929186243159223
Validation loss: 2.4536800181210783

Epoch: 5| Step: 8
Training loss: 1.7111396844275464
Validation loss: 2.515937204413434

Epoch: 5| Step: 9
Training loss: 1.313672314206225
Validation loss: 2.584399203570674

Epoch: 5| Step: 10
Training loss: 1.76797221306071
Validation loss: 2.4517498186590245

Epoch: 420| Step: 0
Training loss: 1.474243118577991
Validation loss: 2.450522581294274

Epoch: 5| Step: 1
Training loss: 1.6505709036152698
Validation loss: 2.441831257109585

Epoch: 5| Step: 2
Training loss: 1.3270157164510408
Validation loss: 2.4583752543227986

Epoch: 5| Step: 3
Training loss: 1.1812292470572312
Validation loss: 2.482561372632541

Epoch: 5| Step: 4
Training loss: 1.3821622106113145
Validation loss: 2.460937235399718

Epoch: 5| Step: 5
Training loss: 1.267293466072032
Validation loss: 2.4995786106640923

Epoch: 5| Step: 6
Training loss: 1.5018211276980424
Validation loss: 2.479423763655754

Epoch: 5| Step: 7
Training loss: 2.484460697255498
Validation loss: 2.506521476952397

Epoch: 5| Step: 8
Training loss: 1.9104308260604752
Validation loss: 2.4900593319102935

Epoch: 5| Step: 9
Training loss: 1.2211818397266234
Validation loss: 2.4550055825165162

Epoch: 5| Step: 10
Training loss: 1.4133052168079718
Validation loss: 2.490310683861725

Epoch: 421| Step: 0
Training loss: 1.2067832815521302
Validation loss: 2.4790779201982027

Epoch: 5| Step: 1
Training loss: 2.140292399386263
Validation loss: 2.498250890868062

Epoch: 5| Step: 2
Training loss: 1.397322951141461
Validation loss: 2.5256149415319658

Epoch: 5| Step: 3
Training loss: 2.008625266778577
Validation loss: 2.4970698032769003

Epoch: 5| Step: 4
Training loss: 1.2951500693012792
Validation loss: 2.5772070524880117

Epoch: 5| Step: 5
Training loss: 1.951366395771659
Validation loss: 2.521003028088968

Epoch: 5| Step: 6
Training loss: 1.7193038741570044
Validation loss: 2.530833280030947

Epoch: 5| Step: 7
Training loss: 1.07560645894856
Validation loss: 2.449657611976798

Epoch: 5| Step: 8
Training loss: 1.1351003235326593
Validation loss: 2.457330410165952

Epoch: 5| Step: 9
Training loss: 1.7853822126888523
Validation loss: 2.536136239266863

Epoch: 5| Step: 10
Training loss: 0.8770137162718153
Validation loss: 2.5529948292962614

Epoch: 422| Step: 0
Training loss: 1.6539071985385285
Validation loss: 2.537760445288945

Epoch: 5| Step: 1
Training loss: 1.3082842560490646
Validation loss: 2.5144679795245715

Epoch: 5| Step: 2
Training loss: 1.1075441000362403
Validation loss: 2.4731568982741443

Epoch: 5| Step: 3
Training loss: 1.403750211082164
Validation loss: 2.5770617308901524

Epoch: 5| Step: 4
Training loss: 1.3104483600093133
Validation loss: 2.524286499469081

Epoch: 5| Step: 5
Training loss: 2.0267340123548374
Validation loss: 2.5311323954127602

Epoch: 5| Step: 6
Training loss: 2.1286063166728115
Validation loss: 2.532961992752497

Epoch: 5| Step: 7
Training loss: 1.2835607857630258
Validation loss: 2.421009124082781

Epoch: 5| Step: 8
Training loss: 1.780917755729708
Validation loss: 2.4915825290229128

Epoch: 5| Step: 9
Training loss: 1.41044896857472
Validation loss: 2.5135810613121436

Epoch: 5| Step: 10
Training loss: 1.3705490638860252
Validation loss: 2.4454153616482897

Epoch: 423| Step: 0
Training loss: 1.36176016258172
Validation loss: 2.447000164843005

Epoch: 5| Step: 1
Training loss: 2.269233303242727
Validation loss: 2.4577480729765218

Epoch: 5| Step: 2
Training loss: 1.6423704036407643
Validation loss: 2.5377921094965132

Epoch: 5| Step: 3
Training loss: 1.22935188104935
Validation loss: 2.501415471349296

Epoch: 5| Step: 4
Training loss: 1.4255120846367577
Validation loss: 2.565586651656395

Epoch: 5| Step: 5
Training loss: 1.612135066647337
Validation loss: 2.480288044008394

Epoch: 5| Step: 6
Training loss: 1.4449253697906084
Validation loss: 2.5248983834035075

Epoch: 5| Step: 7
Training loss: 1.6998841835288365
Validation loss: 2.517774700455774

Epoch: 5| Step: 8
Training loss: 1.5901767841162917
Validation loss: 2.507911945689652

Epoch: 5| Step: 9
Training loss: 1.130881564592991
Validation loss: 2.5008555701822

Epoch: 5| Step: 10
Training loss: 1.444816958044024
Validation loss: 2.492548605713954

Epoch: 424| Step: 0
Training loss: 1.927421382087427
Validation loss: 2.526237012547021

Epoch: 5| Step: 1
Training loss: 1.819982277710533
Validation loss: 2.529436877720812

Epoch: 5| Step: 2
Training loss: 1.540094871695056
Validation loss: 2.499181837107883

Epoch: 5| Step: 3
Training loss: 1.276921567063062
Validation loss: 2.527378677274157

Epoch: 5| Step: 4
Training loss: 1.4162591553785209
Validation loss: 2.5223093521059097

Epoch: 5| Step: 5
Training loss: 1.414056851707685
Validation loss: 2.4799006213178094

Epoch: 5| Step: 6
Training loss: 1.5345188205543052
Validation loss: 2.3939428006731625

Epoch: 5| Step: 7
Training loss: 1.5494478965189826
Validation loss: 2.4852713734122607

Epoch: 5| Step: 8
Training loss: 1.339639586972673
Validation loss: 2.4565632509720903

Epoch: 5| Step: 9
Training loss: 1.798168347167372
Validation loss: 2.484390258742204

Epoch: 5| Step: 10
Training loss: 1.2706407130030237
Validation loss: 2.4682716040067794

Epoch: 425| Step: 0
Training loss: 1.129073345133296
Validation loss: 2.538589131013733

Epoch: 5| Step: 1
Training loss: 1.8629169867792652
Validation loss: 2.5793940906177033

Epoch: 5| Step: 2
Training loss: 1.4530412383190427
Validation loss: 2.5135666192651995

Epoch: 5| Step: 3
Training loss: 1.258665755027775
Validation loss: 2.4474839326570637

Epoch: 5| Step: 4
Training loss: 1.174630041926963
Validation loss: 2.515009872692612

Epoch: 5| Step: 5
Training loss: 1.279048330609247
Validation loss: 2.458962128737728

Epoch: 5| Step: 6
Training loss: 2.1712285458784617
Validation loss: 2.5377287753826843

Epoch: 5| Step: 7
Training loss: 1.9931565265428948
Validation loss: 2.507413947789834

Epoch: 5| Step: 8
Training loss: 1.5820940170081403
Validation loss: 2.5021762235944163

Epoch: 5| Step: 9
Training loss: 1.2788170766530884
Validation loss: 2.490431230112562

Epoch: 5| Step: 10
Training loss: 1.687472590471119
Validation loss: 2.4778005374763095

Epoch: 426| Step: 0
Training loss: 1.4892729411372971
Validation loss: 2.462237700180627

Epoch: 5| Step: 1
Training loss: 1.7091196933034263
Validation loss: 2.4907522657665133

Epoch: 5| Step: 2
Training loss: 1.249859134366216
Validation loss: 2.472544464252675

Epoch: 5| Step: 3
Training loss: 1.7322574782615436
Validation loss: 2.4231518944261734

Epoch: 5| Step: 4
Training loss: 1.5821097648823188
Validation loss: 2.5486879753959366

Epoch: 5| Step: 5
Training loss: 1.7235598454146315
Validation loss: 2.557576635900537

Epoch: 5| Step: 6
Training loss: 1.1954917025403797
Validation loss: 2.4761246565609696

Epoch: 5| Step: 7
Training loss: 1.3402521606439282
Validation loss: 2.5199644707886737

Epoch: 5| Step: 8
Training loss: 1.6507861143185845
Validation loss: 2.520367579263926

Epoch: 5| Step: 9
Training loss: 2.096485457643073
Validation loss: 2.551661058204883

Epoch: 5| Step: 10
Training loss: 1.831451844948925
Validation loss: 2.5264576674146886

Epoch: 427| Step: 0
Training loss: 1.1172108681108832
Validation loss: 2.492270059754974

Epoch: 5| Step: 1
Training loss: 1.6306527926327081
Validation loss: 2.5284055463851165

Epoch: 5| Step: 2
Training loss: 1.4594982217723629
Validation loss: 2.516933624345826

Epoch: 5| Step: 3
Training loss: 1.1005780305214525
Validation loss: 2.4652261336807744

Epoch: 5| Step: 4
Training loss: 1.3311122733496543
Validation loss: 2.514160008906132

Epoch: 5| Step: 5
Training loss: 2.1771590905644542
Validation loss: 2.4093177309898097

Epoch: 5| Step: 6
Training loss: 1.3972755165165893
Validation loss: 2.5305075438341134

Epoch: 5| Step: 7
Training loss: 1.647127616371311
Validation loss: 2.4922974264861075

Epoch: 5| Step: 8
Training loss: 1.6063177458136193
Validation loss: 2.4515054274887644

Epoch: 5| Step: 9
Training loss: 1.4208564883197707
Validation loss: 2.4940980905427748

Epoch: 5| Step: 10
Training loss: 1.7990332868548915
Validation loss: 2.4447081376394952

Epoch: 428| Step: 0
Training loss: 1.213466832987512
Validation loss: 2.4898206326813006

Epoch: 5| Step: 1
Training loss: 1.3285589070323363
Validation loss: 2.4578959394153825

Epoch: 5| Step: 2
Training loss: 2.5345031179084194
Validation loss: 2.5471666024303525

Epoch: 5| Step: 3
Training loss: 1.6654096711124526
Validation loss: 2.5281688979282193

Epoch: 5| Step: 4
Training loss: 1.2678987306263707
Validation loss: 2.5285606697321614

Epoch: 5| Step: 5
Training loss: 1.96246849569315
Validation loss: 2.451921989314343

Epoch: 5| Step: 6
Training loss: 1.2438609049821419
Validation loss: 2.443213875294961

Epoch: 5| Step: 7
Training loss: 1.3754692144023715
Validation loss: 2.5388533518231853

Epoch: 5| Step: 8
Training loss: 1.1686793178461856
Validation loss: 2.4987891412997705

Epoch: 5| Step: 9
Training loss: 1.2591017755634815
Validation loss: 2.5202795162895457

Epoch: 5| Step: 10
Training loss: 1.296173411491366
Validation loss: 2.5011396517673266

Epoch: 429| Step: 0
Training loss: 1.4097436528490017
Validation loss: 2.4595059211826005

Epoch: 5| Step: 1
Training loss: 1.5726466505020145
Validation loss: 2.4317702521304

Epoch: 5| Step: 2
Training loss: 2.3452163178445034
Validation loss: 2.533132596663268

Epoch: 5| Step: 3
Training loss: 1.6637752087959636
Validation loss: 2.4391953320705455

Epoch: 5| Step: 4
Training loss: 1.0896002931654671
Validation loss: 2.4429523099454493

Epoch: 5| Step: 5
Training loss: 1.5673893533255268
Validation loss: 2.4838967585653005

Epoch: 5| Step: 6
Training loss: 1.318811906925352
Validation loss: 2.4491934957116674

Epoch: 5| Step: 7
Training loss: 1.704749146630918
Validation loss: 2.482487521404833

Epoch: 5| Step: 8
Training loss: 1.2611286212295567
Validation loss: 2.4918887910584444

Epoch: 5| Step: 9
Training loss: 1.4199878619575201
Validation loss: 2.4671328653095084

Epoch: 5| Step: 10
Training loss: 1.3947126767405198
Validation loss: 2.43008276138578

Epoch: 430| Step: 0
Training loss: 1.2173437662165028
Validation loss: 2.4870781871323016

Epoch: 5| Step: 1
Training loss: 1.5025326487569062
Validation loss: 2.501271992796052

Epoch: 5| Step: 2
Training loss: 1.2751275297973177
Validation loss: 2.545117088947915

Epoch: 5| Step: 3
Training loss: 0.9484917325095388
Validation loss: 2.5416992571385557

Epoch: 5| Step: 4
Training loss: 1.449847390924374
Validation loss: 2.4932966746873553

Epoch: 5| Step: 5
Training loss: 1.458168547266587
Validation loss: 2.5168937579594988

Epoch: 5| Step: 6
Training loss: 2.1329446269599326
Validation loss: 2.4399006467220183

Epoch: 5| Step: 7
Training loss: 1.3675274235627477
Validation loss: 2.4483048849659568

Epoch: 5| Step: 8
Training loss: 1.9238388448503685
Validation loss: 2.5146466513656356

Epoch: 5| Step: 9
Training loss: 1.8227740495387785
Validation loss: 2.5235769134984474

Epoch: 5| Step: 10
Training loss: 1.4257557487820052
Validation loss: 2.510091061403081

Epoch: 431| Step: 0
Training loss: 1.753821559976813
Validation loss: 2.494170301350781

Epoch: 5| Step: 1
Training loss: 2.135757369487649
Validation loss: 2.3988943853602858

Epoch: 5| Step: 2
Training loss: 1.402886670778279
Validation loss: 2.508819579253858

Epoch: 5| Step: 3
Training loss: 1.3466333017528003
Validation loss: 2.5396722684546384

Epoch: 5| Step: 4
Training loss: 1.4417086648428097
Validation loss: 2.5658327565295456

Epoch: 5| Step: 5
Training loss: 1.3677979768466169
Validation loss: 2.4808253896091714

Epoch: 5| Step: 6
Training loss: 1.2763147905214387
Validation loss: 2.4769678658479064

Epoch: 5| Step: 7
Training loss: 1.623487061670157
Validation loss: 2.469766158726253

Epoch: 5| Step: 8
Training loss: 1.3843510576162632
Validation loss: 2.4370273282193553

Epoch: 5| Step: 9
Training loss: 2.0293953277819825
Validation loss: 2.521636240767973

Epoch: 5| Step: 10
Training loss: 1.2556204323806586
Validation loss: 2.4678608362828034

Epoch: 432| Step: 0
Training loss: 1.5376969684256134
Validation loss: 2.5235389214904886

Epoch: 5| Step: 1
Training loss: 1.4610768623995642
Validation loss: 2.5131044381030048

Epoch: 5| Step: 2
Training loss: 1.2934310409336698
Validation loss: 2.477730616822684

Epoch: 5| Step: 3
Training loss: 1.7442961107687096
Validation loss: 2.480422366774998

Epoch: 5| Step: 4
Training loss: 1.4918070203221891
Validation loss: 2.501422210924669

Epoch: 5| Step: 5
Training loss: 1.2331037614852411
Validation loss: 2.5000411901874924

Epoch: 5| Step: 6
Training loss: 0.9070636779613491
Validation loss: 2.491228858760865

Epoch: 5| Step: 7
Training loss: 1.6319963523599588
Validation loss: 2.547231168520965

Epoch: 5| Step: 8
Training loss: 2.228598858067154
Validation loss: 2.549620787396672

Epoch: 5| Step: 9
Training loss: 1.6698259292612518
Validation loss: 2.52773413244274

Epoch: 5| Step: 10
Training loss: 1.2412728835164126
Validation loss: 2.495171386612999

Epoch: 433| Step: 0
Training loss: 1.3387371865450932
Validation loss: 2.4723224703293765

Epoch: 5| Step: 1
Training loss: 1.4433707725890486
Validation loss: 2.534060013431482

Epoch: 5| Step: 2
Training loss: 1.455604652534465
Validation loss: 2.486027656056235

Epoch: 5| Step: 3
Training loss: 1.55701843042068
Validation loss: 2.5337444458257763

Epoch: 5| Step: 4
Training loss: 1.164239242756307
Validation loss: 2.4919422198815613

Epoch: 5| Step: 5
Training loss: 1.4906226136130498
Validation loss: 2.548383972246013

Epoch: 5| Step: 6
Training loss: 1.5342668670030484
Validation loss: 2.491646673166404

Epoch: 5| Step: 7
Training loss: 1.0571071419887175
Validation loss: 2.493315976231461

Epoch: 5| Step: 8
Training loss: 2.205223977440825
Validation loss: 2.5312126700786943

Epoch: 5| Step: 9
Training loss: 1.4415784283280435
Validation loss: 2.421763698787114

Epoch: 5| Step: 10
Training loss: 1.4946942269957275
Validation loss: 2.460299752595591

Epoch: 434| Step: 0
Training loss: 1.193124501391587
Validation loss: 2.526713943627899

Epoch: 5| Step: 1
Training loss: 1.6160403988575738
Validation loss: 2.4758657863393574

Epoch: 5| Step: 2
Training loss: 2.1060745981232736
Validation loss: 2.473579646317203

Epoch: 5| Step: 3
Training loss: 1.0005011494871567
Validation loss: 2.475430095994021

Epoch: 5| Step: 4
Training loss: 1.110724098966509
Validation loss: 2.537371967132105

Epoch: 5| Step: 5
Training loss: 2.2027316993660597
Validation loss: 2.4829668184481704

Epoch: 5| Step: 6
Training loss: 1.7966304446776002
Validation loss: 2.526050963330243

Epoch: 5| Step: 7
Training loss: 0.8735917543740865
Validation loss: 2.4563411731733655

Epoch: 5| Step: 8
Training loss: 1.5129845024469932
Validation loss: 2.512423820975339

Epoch: 5| Step: 9
Training loss: 1.4584634813635025
Validation loss: 2.507344235895698

Epoch: 5| Step: 10
Training loss: 1.612916475672289
Validation loss: 2.4280709856382825

Epoch: 435| Step: 0
Training loss: 1.156840560210854
Validation loss: 2.5422755305081752

Epoch: 5| Step: 1
Training loss: 1.4681213332090224
Validation loss: 2.4781866327907474

Epoch: 5| Step: 2
Training loss: 1.5251985983435201
Validation loss: 2.52659493465985

Epoch: 5| Step: 3
Training loss: 2.1520854151058066
Validation loss: 2.4590198728953245

Epoch: 5| Step: 4
Training loss: 1.4641439571946218
Validation loss: 2.498370272097163

Epoch: 5| Step: 5
Training loss: 1.2212647633748577
Validation loss: 2.4411369249337755

Epoch: 5| Step: 6
Training loss: 1.091305207454198
Validation loss: 2.508379196250829

Epoch: 5| Step: 7
Training loss: 1.6120694021709399
Validation loss: 2.464383103338715

Epoch: 5| Step: 8
Training loss: 1.2494649695729045
Validation loss: 2.464275337665662

Epoch: 5| Step: 9
Training loss: 2.0095425881464215
Validation loss: 2.533493835050106

Epoch: 5| Step: 10
Training loss: 1.6007637823519272
Validation loss: 2.5177209380318653

Epoch: 436| Step: 0
Training loss: 1.0943333296410287
Validation loss: 2.4522192689672684

Epoch: 5| Step: 1
Training loss: 1.0899350801435892
Validation loss: 2.538086275872922

Epoch: 5| Step: 2
Training loss: 1.2495310857538267
Validation loss: 2.5198034469042283

Epoch: 5| Step: 3
Training loss: 1.54674745284309
Validation loss: 2.486556809304256

Epoch: 5| Step: 4
Training loss: 1.317446289343004
Validation loss: 2.470562872715255

Epoch: 5| Step: 5
Training loss: 1.1022978147889086
Validation loss: 2.5177356576459946

Epoch: 5| Step: 6
Training loss: 1.4751146271987998
Validation loss: 2.549815442522209

Epoch: 5| Step: 7
Training loss: 1.6392311351272972
Validation loss: 2.4860917775000124

Epoch: 5| Step: 8
Training loss: 2.1585258967489906
Validation loss: 2.4680076517290734

Epoch: 5| Step: 9
Training loss: 1.949626749947622
Validation loss: 2.472561452868295

Epoch: 5| Step: 10
Training loss: 1.683223674840833
Validation loss: 2.4445426515630118

Epoch: 437| Step: 0
Training loss: 1.7474420790562335
Validation loss: 2.5005483477149655

Epoch: 5| Step: 1
Training loss: 2.2310142584891812
Validation loss: 2.475029865497784

Epoch: 5| Step: 2
Training loss: 1.0403054053035152
Validation loss: 2.546068678031853

Epoch: 5| Step: 3
Training loss: 1.240505735492478
Validation loss: 2.4148100622604303

Epoch: 5| Step: 4
Training loss: 1.4171511812613844
Validation loss: 2.4394393549145206

Epoch: 5| Step: 5
Training loss: 1.0587606263331155
Validation loss: 2.5182516155537544

Epoch: 5| Step: 6
Training loss: 1.4882334303494995
Validation loss: 2.482595567884381

Epoch: 5| Step: 7
Training loss: 1.4622377535456699
Validation loss: 2.454473107423985

Epoch: 5| Step: 8
Training loss: 1.9478901404004318
Validation loss: 2.4464457983486385

Epoch: 5| Step: 9
Training loss: 1.3214242982979396
Validation loss: 2.514486008266718

Epoch: 5| Step: 10
Training loss: 1.4767539894227064
Validation loss: 2.4580464095718435

Epoch: 438| Step: 0
Training loss: 1.1792576493028701
Validation loss: 2.4599913346526225

Epoch: 5| Step: 1
Training loss: 1.6445812661726822
Validation loss: 2.5329568046622715

Epoch: 5| Step: 2
Training loss: 1.1673183097206634
Validation loss: 2.5545187511156393

Epoch: 5| Step: 3
Training loss: 1.5896871053771302
Validation loss: 2.5380610674717423

Epoch: 5| Step: 4
Training loss: 1.3936476699828784
Validation loss: 2.4732692254010518

Epoch: 5| Step: 5
Training loss: 1.0530374688694109
Validation loss: 2.5483103575957387

Epoch: 5| Step: 6
Training loss: 2.3537782894466424
Validation loss: 2.52150798208393

Epoch: 5| Step: 7
Training loss: 1.8297105743751454
Validation loss: 2.5465931955737076

Epoch: 5| Step: 8
Training loss: 1.4975027118078779
Validation loss: 2.4816148630136827

Epoch: 5| Step: 9
Training loss: 1.258231951985262
Validation loss: 2.5339956105080237

Epoch: 5| Step: 10
Training loss: 1.2274266497261939
Validation loss: 2.469740011129555

Epoch: 439| Step: 0
Training loss: 1.4727948272829736
Validation loss: 2.494327451025117

Epoch: 5| Step: 1
Training loss: 1.1441898292388186
Validation loss: 2.512331402968089

Epoch: 5| Step: 2
Training loss: 1.27835947884518
Validation loss: 2.41634021890801

Epoch: 5| Step: 3
Training loss: 1.578262625254784
Validation loss: 2.5181292226775915

Epoch: 5| Step: 4
Training loss: 1.5754134044329264
Validation loss: 2.470991115086825

Epoch: 5| Step: 5
Training loss: 1.426171988678183
Validation loss: 2.4587214834199465

Epoch: 5| Step: 6
Training loss: 1.2438007171871697
Validation loss: 2.487571721911741

Epoch: 5| Step: 7
Training loss: 1.7323104667752112
Validation loss: 2.488269391383122

Epoch: 5| Step: 8
Training loss: 2.3679002752569653
Validation loss: 2.5062232699106897

Epoch: 5| Step: 9
Training loss: 1.3934892453263534
Validation loss: 2.377541740113793

Epoch: 5| Step: 10
Training loss: 1.403579082800941
Validation loss: 2.4773160363163527

Epoch: 440| Step: 0
Training loss: 1.246040223505668
Validation loss: 2.4749144413291115

Epoch: 5| Step: 1
Training loss: 2.2727791268762148
Validation loss: 2.4227661673799634

Epoch: 5| Step: 2
Training loss: 1.9583747805274299
Validation loss: 2.496717689654674

Epoch: 5| Step: 3
Training loss: 1.3368901653954428
Validation loss: 2.5072067940500906

Epoch: 5| Step: 4
Training loss: 1.7529974199135698
Validation loss: 2.517707015617035

Epoch: 5| Step: 5
Training loss: 1.0371068462333812
Validation loss: 2.506740532763416

Epoch: 5| Step: 6
Training loss: 1.3893067616098755
Validation loss: 2.4585184052306226

Epoch: 5| Step: 7
Training loss: 1.5435578971905686
Validation loss: 2.5566116908320895

Epoch: 5| Step: 8
Training loss: 1.097756595029678
Validation loss: 2.5258690799930767

Epoch: 5| Step: 9
Training loss: 1.1459107921890759
Validation loss: 2.4445600072921336

Epoch: 5| Step: 10
Training loss: 1.5075342583757065
Validation loss: 2.5316105166430756

Epoch: 441| Step: 0
Training loss: 1.605720964283574
Validation loss: 2.415511372465823

Epoch: 5| Step: 1
Training loss: 1.1949688286486622
Validation loss: 2.479135625997701

Epoch: 5| Step: 2
Training loss: 0.7960144707284538
Validation loss: 2.4869976279890986

Epoch: 5| Step: 3
Training loss: 1.9727988616457437
Validation loss: 2.493757156533276

Epoch: 5| Step: 4
Training loss: 1.3877397244223675
Validation loss: 2.4780017173222375

Epoch: 5| Step: 5
Training loss: 1.5751164529527806
Validation loss: 2.4966023255183787

Epoch: 5| Step: 6
Training loss: 1.1999994774658338
Validation loss: 2.4690883296126223

Epoch: 5| Step: 7
Training loss: 1.7030221050572776
Validation loss: 2.4939096735285786

Epoch: 5| Step: 8
Training loss: 1.492335766521416
Validation loss: 2.518286868460825

Epoch: 5| Step: 9
Training loss: 1.1578023130146329
Validation loss: 2.53776063015518

Epoch: 5| Step: 10
Training loss: 1.7736809517215197
Validation loss: 2.566922229444493

Epoch: 442| Step: 0
Training loss: 1.1795228754843603
Validation loss: 2.4905928617002866

Epoch: 5| Step: 1
Training loss: 1.755095149012207
Validation loss: 2.4830856976366027

Epoch: 5| Step: 2
Training loss: 1.119409765132849
Validation loss: 2.4794112164428554

Epoch: 5| Step: 3
Training loss: 2.159671004636262
Validation loss: 2.5291603291295917

Epoch: 5| Step: 4
Training loss: 1.1422774481678408
Validation loss: 2.5542167788605155

Epoch: 5| Step: 5
Training loss: 1.5034250257375377
Validation loss: 2.527063778785869

Epoch: 5| Step: 6
Training loss: 1.4588191540171103
Validation loss: 2.4430705821072825

Epoch: 5| Step: 7
Training loss: 1.4685923714970688
Validation loss: 2.386592349217109

Epoch: 5| Step: 8
Training loss: 1.679281354194892
Validation loss: 2.5093279202513044

Epoch: 5| Step: 9
Training loss: 1.4633861563206707
Validation loss: 2.497127933092372

Epoch: 5| Step: 10
Training loss: 1.331584866811944
Validation loss: 2.5284984333558165

Epoch: 443| Step: 0
Training loss: 1.3638298002229365
Validation loss: 2.421108805024897

Epoch: 5| Step: 1
Training loss: 1.5651371635559672
Validation loss: 2.5534861931509787

Epoch: 5| Step: 2
Training loss: 1.078159442296171
Validation loss: 2.439952052945784

Epoch: 5| Step: 3
Training loss: 1.3499829979991524
Validation loss: 2.5096149041650566

Epoch: 5| Step: 4
Training loss: 2.0911040026771044
Validation loss: 2.4568459380779486

Epoch: 5| Step: 5
Training loss: 1.612613641445631
Validation loss: 2.449762438569549

Epoch: 5| Step: 6
Training loss: 1.1898610084369092
Validation loss: 2.4547481853097333

Epoch: 5| Step: 7
Training loss: 1.1192685465244216
Validation loss: 2.4433130144288575

Epoch: 5| Step: 8
Training loss: 1.666391524810043
Validation loss: 2.457559637627255

Epoch: 5| Step: 9
Training loss: 1.5522556166643244
Validation loss: 2.461663295679584

Epoch: 5| Step: 10
Training loss: 1.617621395856095
Validation loss: 2.486170169624347

Epoch: 444| Step: 0
Training loss: 1.2187600746716507
Validation loss: 2.4872234121248797

Epoch: 5| Step: 1
Training loss: 1.541963428424815
Validation loss: 2.543189028751432

Epoch: 5| Step: 2
Training loss: 1.464950923813743
Validation loss: 2.453776098432703

Epoch: 5| Step: 3
Training loss: 2.4113532112778078
Validation loss: 2.4509059153635393

Epoch: 5| Step: 4
Training loss: 1.2473552859199495
Validation loss: 2.498301690079704

Epoch: 5| Step: 5
Training loss: 1.2145963459833673
Validation loss: 2.4708088474886174

Epoch: 5| Step: 6
Training loss: 1.374998742883281
Validation loss: 2.4611863137633603

Epoch: 5| Step: 7
Training loss: 1.2830096001626399
Validation loss: 2.5159733762322536

Epoch: 5| Step: 8
Training loss: 1.448891656778054
Validation loss: 2.4366853160802955

Epoch: 5| Step: 9
Training loss: 1.6537273557097327
Validation loss: 2.423571153756356

Epoch: 5| Step: 10
Training loss: 1.2101218152795825
Validation loss: 2.462718756893852

Epoch: 445| Step: 0
Training loss: 1.4712917978577056
Validation loss: 2.4878139849473913

Epoch: 5| Step: 1
Training loss: 1.7956200239176967
Validation loss: 2.457377942831675

Epoch: 5| Step: 2
Training loss: 1.0622631818851702
Validation loss: 2.517580233890874

Epoch: 5| Step: 3
Training loss: 1.2094583645262291
Validation loss: 2.5161742727463148

Epoch: 5| Step: 4
Training loss: 1.5006667880365117
Validation loss: 2.5019795025737173

Epoch: 5| Step: 5
Training loss: 1.1316542393185092
Validation loss: 2.4757097667365735

Epoch: 5| Step: 6
Training loss: 1.1494570507738824
Validation loss: 2.5200544364344197

Epoch: 5| Step: 7
Training loss: 2.3707962980768924
Validation loss: 2.5187940936833506

Epoch: 5| Step: 8
Training loss: 1.107763543816041
Validation loss: 2.509981700734257

Epoch: 5| Step: 9
Training loss: 1.3243774048953074
Validation loss: 2.496684196098256

Epoch: 5| Step: 10
Training loss: 1.7234284277060696
Validation loss: 2.4699663110180667

Epoch: 446| Step: 0
Training loss: 1.858706698807965
Validation loss: 2.4662575705794145

Epoch: 5| Step: 1
Training loss: 1.2836016960617846
Validation loss: 2.4892627662252127

Epoch: 5| Step: 2
Training loss: 2.0244219531849956
Validation loss: 2.482853559873689

Epoch: 5| Step: 3
Training loss: 1.3974515966587062
Validation loss: 2.524123961211457

Epoch: 5| Step: 4
Training loss: 1.5607269908865506
Validation loss: 2.524127101616618

Epoch: 5| Step: 5
Training loss: 1.3650242284923124
Validation loss: 2.48216171362034

Epoch: 5| Step: 6
Training loss: 0.9669743230560662
Validation loss: 2.5507721176754097

Epoch: 5| Step: 7
Training loss: 1.2835910158598391
Validation loss: 2.602978583912164

Epoch: 5| Step: 8
Training loss: 1.7393155224932275
Validation loss: 2.5637661246790135

Epoch: 5| Step: 9
Training loss: 1.41499264300695
Validation loss: 2.5971940194264778

Epoch: 5| Step: 10
Training loss: 1.3820738894201552
Validation loss: 2.5510747906130864

Epoch: 447| Step: 0
Training loss: 1.2144896061602892
Validation loss: 2.4434817077046973

Epoch: 5| Step: 1
Training loss: 1.7133128081971196
Validation loss: 2.513902287694996

Epoch: 5| Step: 2
Training loss: 1.3203408052017473
Validation loss: 2.5252820060838785

Epoch: 5| Step: 3
Training loss: 1.4633294581808745
Validation loss: 2.438873954482921

Epoch: 5| Step: 4
Training loss: 1.5720102422637794
Validation loss: 2.4970829013654696

Epoch: 5| Step: 5
Training loss: 1.0853135216749608
Validation loss: 2.5224776204231114

Epoch: 5| Step: 6
Training loss: 2.1512473857005947
Validation loss: 2.458810424881317

Epoch: 5| Step: 7
Training loss: 1.6853898595211316
Validation loss: 2.5514306893691794

Epoch: 5| Step: 8
Training loss: 1.2483394082960986
Validation loss: 2.4695050585573743

Epoch: 5| Step: 9
Training loss: 1.5107344545192358
Validation loss: 2.469762806472428

Epoch: 5| Step: 10
Training loss: 1.4330281069408906
Validation loss: 2.454754078103548

Epoch: 448| Step: 0
Training loss: 1.3412400246539862
Validation loss: 2.444233850628612

Epoch: 5| Step: 1
Training loss: 1.6962526588728326
Validation loss: 2.4064025351125227

Epoch: 5| Step: 2
Training loss: 1.3024768946642924
Validation loss: 2.5139557524309395

Epoch: 5| Step: 3
Training loss: 1.903006498910027
Validation loss: 2.5718933464459206

Epoch: 5| Step: 4
Training loss: 1.4563209909317862
Validation loss: 2.464818080632381

Epoch: 5| Step: 5
Training loss: 1.0107845279099708
Validation loss: 2.4581302588840517

Epoch: 5| Step: 6
Training loss: 1.0652491961218544
Validation loss: 2.5175116090032024

Epoch: 5| Step: 7
Training loss: 1.2302019586917452
Validation loss: 2.4560474038222497

Epoch: 5| Step: 8
Training loss: 1.7263748274080724
Validation loss: 2.467926952591894

Epoch: 5| Step: 9
Training loss: 1.358427133812413
Validation loss: 2.521160313685089

Epoch: 5| Step: 10
Training loss: 1.8709426213594669
Validation loss: 2.471037034702379

Epoch: 449| Step: 0
Training loss: 1.1241464025614212
Validation loss: 2.5109209488492326

Epoch: 5| Step: 1
Training loss: 1.139712818095694
Validation loss: 2.547868692946583

Epoch: 5| Step: 2
Training loss: 2.3499815432858573
Validation loss: 2.573777468838848

Epoch: 5| Step: 3
Training loss: 1.2029526326945101
Validation loss: 2.4825171124509677

Epoch: 5| Step: 4
Training loss: 1.235278269889163
Validation loss: 2.481982040874165

Epoch: 5| Step: 5
Training loss: 1.5682832122209722
Validation loss: 2.543794391598783

Epoch: 5| Step: 6
Training loss: 1.2185558262223704
Validation loss: 2.491863570041979

Epoch: 5| Step: 7
Training loss: 1.024048950180172
Validation loss: 2.535910015207337

Epoch: 5| Step: 8
Training loss: 1.8364731027662338
Validation loss: 2.5849065849423076

Epoch: 5| Step: 9
Training loss: 1.5272704592239994
Validation loss: 2.5020792359380746

Epoch: 5| Step: 10
Training loss: 1.4616707986115731
Validation loss: 2.4740348430173533

Epoch: 450| Step: 0
Training loss: 1.0708169792400892
Validation loss: 2.4666973057512176

Epoch: 5| Step: 1
Training loss: 1.194900840731271
Validation loss: 2.517463914363081

Epoch: 5| Step: 2
Training loss: 1.4125338558764502
Validation loss: 2.426502258746003

Epoch: 5| Step: 3
Training loss: 1.154869028154646
Validation loss: 2.464338091189608

Epoch: 5| Step: 4
Training loss: 1.1995888800502181
Validation loss: 2.4117579850150435

Epoch: 5| Step: 5
Training loss: 2.1983492336705583
Validation loss: 2.542254282844382

Epoch: 5| Step: 6
Training loss: 1.640667433417021
Validation loss: 2.450625902663285

Epoch: 5| Step: 7
Training loss: 1.2958649528219168
Validation loss: 2.493979445371531

Epoch: 5| Step: 8
Training loss: 1.5554528580931022
Validation loss: 2.395474015765146

Epoch: 5| Step: 9
Training loss: 2.053285301604518
Validation loss: 2.49867166792666

Epoch: 5| Step: 10
Training loss: 1.2516381020636906
Validation loss: 2.515127107385583

Epoch: 451| Step: 0
Training loss: 2.2960309404554655
Validation loss: 2.4329837791862747

Epoch: 5| Step: 1
Training loss: 1.2734840712193274
Validation loss: 2.5281916830932234

Epoch: 5| Step: 2
Training loss: 1.4601661971617272
Validation loss: 2.502082623789227

Epoch: 5| Step: 3
Training loss: 1.4570185683774939
Validation loss: 2.503494932045044

Epoch: 5| Step: 4
Training loss: 1.1659114925333423
Validation loss: 2.411933587557128

Epoch: 5| Step: 5
Training loss: 1.3128466375462255
Validation loss: 2.4816606733432316

Epoch: 5| Step: 6
Training loss: 1.272193956801489
Validation loss: 2.5512649144670956

Epoch: 5| Step: 7
Training loss: 1.6893563832715457
Validation loss: 2.4448884273038423

Epoch: 5| Step: 8
Training loss: 1.0037412990321213
Validation loss: 2.4951951070236853

Epoch: 5| Step: 9
Training loss: 1.2616765159884304
Validation loss: 2.450057372203519

Epoch: 5| Step: 10
Training loss: 1.807515426401074
Validation loss: 2.54860375076481

Epoch: 452| Step: 0
Training loss: 1.4975714892866692
Validation loss: 2.5040215335855596

Epoch: 5| Step: 1
Training loss: 1.4673714356912475
Validation loss: 2.49016210564969

Epoch: 5| Step: 2
Training loss: 2.1093266234325325
Validation loss: 2.5029612543573223

Epoch: 5| Step: 3
Training loss: 0.8657572524747078
Validation loss: 2.4918479506820033

Epoch: 5| Step: 4
Training loss: 1.1184755915816529
Validation loss: 2.5133481507451942

Epoch: 5| Step: 5
Training loss: 1.5687753166192453
Validation loss: 2.456903944834484

Epoch: 5| Step: 6
Training loss: 1.3533410073909944
Validation loss: 2.4889411635239123

Epoch: 5| Step: 7
Training loss: 1.3902392763253462
Validation loss: 2.4753634913765428

Epoch: 5| Step: 8
Training loss: 1.4794828408326874
Validation loss: 2.4582500680038777

Epoch: 5| Step: 9
Training loss: 1.3843628118594178
Validation loss: 2.500485922647439

Epoch: 5| Step: 10
Training loss: 1.7411216588861562
Validation loss: 2.536945163304754

Epoch: 453| Step: 0
Training loss: 1.326832220651976
Validation loss: 2.566222541599486

Epoch: 5| Step: 1
Training loss: 1.354814134990545
Validation loss: 2.4570580592255404

Epoch: 5| Step: 2
Training loss: 1.6242001105372497
Validation loss: 2.43830134805542

Epoch: 5| Step: 3
Training loss: 1.459306428593035
Validation loss: 2.4824090548112365

Epoch: 5| Step: 4
Training loss: 1.404408711740543
Validation loss: 2.493615227700092

Epoch: 5| Step: 5
Training loss: 2.124761006996558
Validation loss: 2.549017153221008

Epoch: 5| Step: 6
Training loss: 1.4040181993652592
Validation loss: 2.44106862899902

Epoch: 5| Step: 7
Training loss: 1.3751348949499762
Validation loss: 2.4416569774227823

Epoch: 5| Step: 8
Training loss: 1.3448292589830708
Validation loss: 2.4487676573880797

Epoch: 5| Step: 9
Training loss: 0.9263924942886931
Validation loss: 2.481424419545975

Epoch: 5| Step: 10
Training loss: 1.4219474354832333
Validation loss: 2.4625874650137605

Epoch: 454| Step: 0
Training loss: 1.0880089632113883
Validation loss: 2.446520147064227

Epoch: 5| Step: 1
Training loss: 1.4833988393113757
Validation loss: 2.563090127643202

Epoch: 5| Step: 2
Training loss: 1.6690122391175988
Validation loss: 2.418494156978296

Epoch: 5| Step: 3
Training loss: 1.725892640400603
Validation loss: 2.4370322240083335

Epoch: 5| Step: 4
Training loss: 1.9848020199263787
Validation loss: 2.458745284383959

Epoch: 5| Step: 5
Training loss: 1.33997248706756
Validation loss: 2.5002453960450866

Epoch: 5| Step: 6
Training loss: 1.1895975861416501
Validation loss: 2.51827970267986

Epoch: 5| Step: 7
Training loss: 1.1299142000657363
Validation loss: 2.509088294392606

Epoch: 5| Step: 8
Training loss: 1.356464075517616
Validation loss: 2.511533497350685

Epoch: 5| Step: 9
Training loss: 1.3589826434180052
Validation loss: 2.4581596941671564

Epoch: 5| Step: 10
Training loss: 1.269691621481243
Validation loss: 2.478731876451602

Epoch: 455| Step: 0
Training loss: 1.2657221062223942
Validation loss: 2.4959966651674277

Epoch: 5| Step: 1
Training loss: 1.2904955672047926
Validation loss: 2.465699513864616

Epoch: 5| Step: 2
Training loss: 1.5820735219323527
Validation loss: 2.497929213799724

Epoch: 5| Step: 3
Training loss: 1.0248102198502875
Validation loss: 2.416605339361252

Epoch: 5| Step: 4
Training loss: 1.6089518462965795
Validation loss: 2.4170551350271814

Epoch: 5| Step: 5
Training loss: 2.370672901895574
Validation loss: 2.423027600019743

Epoch: 5| Step: 6
Training loss: 0.893858977656318
Validation loss: 2.5193068471572304

Epoch: 5| Step: 7
Training loss: 1.2503077128270308
Validation loss: 2.518510855261381

Epoch: 5| Step: 8
Training loss: 1.3752362308447417
Validation loss: 2.504070717927055

Epoch: 5| Step: 9
Training loss: 1.397511010169262
Validation loss: 2.451940162189725

Epoch: 5| Step: 10
Training loss: 1.649278254589753
Validation loss: 2.480891125534293

Epoch: 456| Step: 0
Training loss: 1.3349738856415314
Validation loss: 2.4553731770944776

Epoch: 5| Step: 1
Training loss: 1.4460496002332834
Validation loss: 2.4907533341418975

Epoch: 5| Step: 2
Training loss: 1.579034071348755
Validation loss: 2.432111367998471

Epoch: 5| Step: 3
Training loss: 1.1308742383859682
Validation loss: 2.4687705266931723

Epoch: 5| Step: 4
Training loss: 1.469683086981567
Validation loss: 2.475877544906435

Epoch: 5| Step: 5
Training loss: 1.1939896887169463
Validation loss: 2.4527102281016306

Epoch: 5| Step: 6
Training loss: 2.326565930919282
Validation loss: 2.493801955847296

Epoch: 5| Step: 7
Training loss: 0.9601363276998011
Validation loss: 2.48050618006589

Epoch: 5| Step: 8
Training loss: 1.1985164909740114
Validation loss: 2.425658497039354

Epoch: 5| Step: 9
Training loss: 1.7918475599419914
Validation loss: 2.4615041335347274

Epoch: 5| Step: 10
Training loss: 1.5343634424337582
Validation loss: 2.501153600803757

Epoch: 457| Step: 0
Training loss: 1.848562393419081
Validation loss: 2.4083831796711808

Epoch: 5| Step: 1
Training loss: 2.176174600818949
Validation loss: 2.4321834354536613

Epoch: 5| Step: 2
Training loss: 1.3244592678881906
Validation loss: 2.465474004088744

Epoch: 5| Step: 3
Training loss: 1.4925075008133564
Validation loss: 2.5011136599611605

Epoch: 5| Step: 4
Training loss: 1.5756239760084203
Validation loss: 2.5534621257081627

Epoch: 5| Step: 5
Training loss: 0.9105751808902179
Validation loss: 2.5308399199951257

Epoch: 5| Step: 6
Training loss: 1.2149376541593657
Validation loss: 2.480044552723387

Epoch: 5| Step: 7
Training loss: 1.400851505047457
Validation loss: 2.439920484669236

Epoch: 5| Step: 8
Training loss: 1.414614827737608
Validation loss: 2.5477305825483034

Epoch: 5| Step: 9
Training loss: 1.2219301450339342
Validation loss: 2.461870310005255

Epoch: 5| Step: 10
Training loss: 1.1649721930627512
Validation loss: 2.5174226619865165

Epoch: 458| Step: 0
Training loss: 1.5095312570758073
Validation loss: 2.4225984554665088

Epoch: 5| Step: 1
Training loss: 1.594091266670902
Validation loss: 2.5023095312378505

Epoch: 5| Step: 2
Training loss: 1.362039782291814
Validation loss: 2.4493195075908147

Epoch: 5| Step: 3
Training loss: 1.9967141577666865
Validation loss: 2.4609948550857372

Epoch: 5| Step: 4
Training loss: 1.3659660332535288
Validation loss: 2.450035432563938

Epoch: 5| Step: 5
Training loss: 1.0880754680194913
Validation loss: 2.5113726418444156

Epoch: 5| Step: 6
Training loss: 1.3750190733540397
Validation loss: 2.504839181111244

Epoch: 5| Step: 7
Training loss: 1.4239692775005297
Validation loss: 2.4787538201410824

Epoch: 5| Step: 8
Training loss: 1.4464342867353173
Validation loss: 2.4792197288928115

Epoch: 5| Step: 9
Training loss: 1.476048213465926
Validation loss: 2.4571519400741795

Epoch: 5| Step: 10
Training loss: 1.2926841491764975
Validation loss: 2.4760564885782186

Epoch: 459| Step: 0
Training loss: 1.3112908197527715
Validation loss: 2.4690333814221925

Epoch: 5| Step: 1
Training loss: 2.052558521175248
Validation loss: 2.443287724279921

Epoch: 5| Step: 2
Training loss: 1.3137048005405387
Validation loss: 2.462177897012403

Epoch: 5| Step: 3
Training loss: 0.9035098974934485
Validation loss: 2.50719438792194

Epoch: 5| Step: 4
Training loss: 1.4737407222646668
Validation loss: 2.5284973778873128

Epoch: 5| Step: 5
Training loss: 1.599625770196046
Validation loss: 2.5193079054585263

Epoch: 5| Step: 6
Training loss: 1.2967160138952722
Validation loss: 2.498929058927433

Epoch: 5| Step: 7
Training loss: 1.0392142163563352
Validation loss: 2.505214528872265

Epoch: 5| Step: 8
Training loss: 1.431557937877941
Validation loss: 2.4632877428070783

Epoch: 5| Step: 9
Training loss: 1.525085731347853
Validation loss: 2.479265045781319

Epoch: 5| Step: 10
Training loss: 1.611695255879379
Validation loss: 2.5227109116414606

Epoch: 460| Step: 0
Training loss: 1.2149958867917865
Validation loss: 2.4537753524641963

Epoch: 5| Step: 1
Training loss: 1.4823686391647493
Validation loss: 2.4640172118566106

Epoch: 5| Step: 2
Training loss: 1.485992032724126
Validation loss: 2.4422078961518108

Epoch: 5| Step: 3
Training loss: 2.1810880147253378
Validation loss: 2.4432307992396955

Epoch: 5| Step: 4
Training loss: 0.8076281840856925
Validation loss: 2.474749050923018

Epoch: 5| Step: 5
Training loss: 1.463960264172178
Validation loss: 2.4926543565987043

Epoch: 5| Step: 6
Training loss: 1.780155514877919
Validation loss: 2.450583976040295

Epoch: 5| Step: 7
Training loss: 1.4126702720841513
Validation loss: 2.461924729760151

Epoch: 5| Step: 8
Training loss: 1.3362836779640632
Validation loss: 2.513430075605584

Epoch: 5| Step: 9
Training loss: 1.39975876432776
Validation loss: 2.499339496872109

Epoch: 5| Step: 10
Training loss: 0.8748746509684839
Validation loss: 2.4392785356215145

Epoch: 461| Step: 0
Training loss: 1.4026425184164368
Validation loss: 2.5275662302970505

Epoch: 5| Step: 1
Training loss: 1.837775231852543
Validation loss: 2.38695627077285

Epoch: 5| Step: 2
Training loss: 1.1453249526029954
Validation loss: 2.5421579156203937

Epoch: 5| Step: 3
Training loss: 1.3069887253523813
Validation loss: 2.475114375131961

Epoch: 5| Step: 4
Training loss: 2.1393054319856346
Validation loss: 2.4645658794409124

Epoch: 5| Step: 5
Training loss: 1.3690951308502306
Validation loss: 2.5053905493875637

Epoch: 5| Step: 6
Training loss: 1.0906027062003865
Validation loss: 2.426991086817012

Epoch: 5| Step: 7
Training loss: 1.8352717714420064
Validation loss: 2.526435062453337

Epoch: 5| Step: 8
Training loss: 1.1996725509837007
Validation loss: 2.471408588511238

Epoch: 5| Step: 9
Training loss: 0.8150164807882424
Validation loss: 2.510241815946037

Epoch: 5| Step: 10
Training loss: 1.2930740359677386
Validation loss: 2.494998919593853

Epoch: 462| Step: 0
Training loss: 1.2704037529145258
Validation loss: 2.4646205070020146

Epoch: 5| Step: 1
Training loss: 1.424682946654932
Validation loss: 2.4270098081505207

Epoch: 5| Step: 2
Training loss: 1.1896109139651758
Validation loss: 2.459810409366588

Epoch: 5| Step: 3
Training loss: 0.9309053538529206
Validation loss: 2.498935526165707

Epoch: 5| Step: 4
Training loss: 1.5458399845333224
Validation loss: 2.465200834350804

Epoch: 5| Step: 5
Training loss: 1.4026094997723435
Validation loss: 2.4912596708851487

Epoch: 5| Step: 6
Training loss: 2.276583248507296
Validation loss: 2.48486465857298

Epoch: 5| Step: 7
Training loss: 1.5770152505198909
Validation loss: 2.502480184163061

Epoch: 5| Step: 8
Training loss: 1.2906719448612858
Validation loss: 2.4712711585112963

Epoch: 5| Step: 9
Training loss: 1.3641359551960823
Validation loss: 2.541388315532116

Epoch: 5| Step: 10
Training loss: 1.3326589050874795
Validation loss: 2.4552944547920683

Epoch: 463| Step: 0
Training loss: 1.4092991303113365
Validation loss: 2.525812733184713

Epoch: 5| Step: 1
Training loss: 1.0431201839164421
Validation loss: 2.4606632275803273

Epoch: 5| Step: 2
Training loss: 1.9725210615612225
Validation loss: 2.517783188297165

Epoch: 5| Step: 3
Training loss: 1.1585452007223107
Validation loss: 2.5159104871272264

Epoch: 5| Step: 4
Training loss: 1.1601626206553832
Validation loss: 2.5282711202868486

Epoch: 5| Step: 5
Training loss: 1.1697473156957936
Validation loss: 2.493898606481278

Epoch: 5| Step: 6
Training loss: 1.4072379986035572
Validation loss: 2.485509327511396

Epoch: 5| Step: 7
Training loss: 2.1737014445694447
Validation loss: 2.5125453551228145

Epoch: 5| Step: 8
Training loss: 1.3860387719966665
Validation loss: 2.460782226831007

Epoch: 5| Step: 9
Training loss: 1.0761972967838749
Validation loss: 2.485738149024224

Epoch: 5| Step: 10
Training loss: 0.8089258737377752
Validation loss: 2.417778623531975

Epoch: 464| Step: 0
Training loss: 1.388597102774458
Validation loss: 2.4555745688437476

Epoch: 5| Step: 1
Training loss: 1.3746637886987254
Validation loss: 2.4712657184986764

Epoch: 5| Step: 2
Training loss: 1.874084376248331
Validation loss: 2.4960723521186363

Epoch: 5| Step: 3
Training loss: 1.0984467615901057
Validation loss: 2.4539948319000278

Epoch: 5| Step: 4
Training loss: 0.9655492265223408
Validation loss: 2.45638068354923

Epoch: 5| Step: 5
Training loss: 1.4768877428096727
Validation loss: 2.3796851917298447

Epoch: 5| Step: 6
Training loss: 0.9134250602697299
Validation loss: 2.448885738720021

Epoch: 5| Step: 7
Training loss: 2.3558879624752618
Validation loss: 2.459263346351443

Epoch: 5| Step: 8
Training loss: 1.3460686661945287
Validation loss: 2.5187366277706706

Epoch: 5| Step: 9
Training loss: 1.4592893554912016
Validation loss: 2.5099477182295384

Epoch: 5| Step: 10
Training loss: 1.1837057432060654
Validation loss: 2.5160430202173405

Epoch: 465| Step: 0
Training loss: 2.204988813999028
Validation loss: 2.4792006112767893

Epoch: 5| Step: 1
Training loss: 1.786632303232463
Validation loss: 2.484104394831464

Epoch: 5| Step: 2
Training loss: 1.3861946082507173
Validation loss: 2.4712085613340267

Epoch: 5| Step: 3
Training loss: 1.4326276720283526
Validation loss: 2.4554989162150034

Epoch: 5| Step: 4
Training loss: 1.2379908657445708
Validation loss: 2.535414097958959

Epoch: 5| Step: 5
Training loss: 1.4051442355313901
Validation loss: 2.4071121194939686

Epoch: 5| Step: 6
Training loss: 1.2111985448216271
Validation loss: 2.4433525618296383

Epoch: 5| Step: 7
Training loss: 1.189798439650956
Validation loss: 2.4939489896239246

Epoch: 5| Step: 8
Training loss: 1.3057913764505267
Validation loss: 2.4660197371498964

Epoch: 5| Step: 9
Training loss: 1.5379830849787608
Validation loss: 2.4971669931946283

Epoch: 5| Step: 10
Training loss: 0.908431354681697
Validation loss: 2.435429146947838

Epoch: 466| Step: 0
Training loss: 1.1746075116705061
Validation loss: 2.53069019191422

Epoch: 5| Step: 1
Training loss: 1.1092990258219715
Validation loss: 2.5078351491276476

Epoch: 5| Step: 2
Training loss: 1.50253463222813
Validation loss: 2.4779476997867804

Epoch: 5| Step: 3
Training loss: 1.6890250485032587
Validation loss: 2.5105096497435975

Epoch: 5| Step: 4
Training loss: 1.3868058727996078
Validation loss: 2.4397110966458553

Epoch: 5| Step: 5
Training loss: 1.4793113673537532
Validation loss: 2.4372374774758834

Epoch: 5| Step: 6
Training loss: 1.132488862208151
Validation loss: 2.461730937464366

Epoch: 5| Step: 7
Training loss: 2.0013871151082903
Validation loss: 2.5289716672337295

Epoch: 5| Step: 8
Training loss: 1.4690893876812952
Validation loss: 2.4868805434370427

Epoch: 5| Step: 9
Training loss: 1.1561024545918521
Validation loss: 2.4130612734371057

Epoch: 5| Step: 10
Training loss: 1.1453087154809893
Validation loss: 2.5264747562131618

Epoch: 467| Step: 0
Training loss: 1.5612394970555086
Validation loss: 2.4412155482475706

Epoch: 5| Step: 1
Training loss: 1.480165234053931
Validation loss: 2.48681242030056

Epoch: 5| Step: 2
Training loss: 1.316940154069282
Validation loss: 2.4888822481687694

Epoch: 5| Step: 3
Training loss: 1.6006058976218829
Validation loss: 2.42777557743316

Epoch: 5| Step: 4
Training loss: 1.2642461070475461
Validation loss: 2.526656130231581

Epoch: 5| Step: 5
Training loss: 1.8516159371821426
Validation loss: 2.436891787541492

Epoch: 5| Step: 6
Training loss: 1.0673797970351389
Validation loss: 2.4718668058364397

Epoch: 5| Step: 7
Training loss: 1.563531230135181
Validation loss: 2.527386371089412

Epoch: 5| Step: 8
Training loss: 1.0636063593742828
Validation loss: 2.489062352880175

Epoch: 5| Step: 9
Training loss: 1.2505726456252289
Validation loss: 2.454657948342581

Epoch: 5| Step: 10
Training loss: 1.4780935594630413
Validation loss: 2.4346655406342226

Epoch: 468| Step: 0
Training loss: 1.3684814433525108
Validation loss: 2.4973197505487974

Epoch: 5| Step: 1
Training loss: 1.8917531832545598
Validation loss: 2.5896419526398637

Epoch: 5| Step: 2
Training loss: 1.5737962179388902
Validation loss: 2.4592072862820626

Epoch: 5| Step: 3
Training loss: 1.0467951729928113
Validation loss: 2.4268121048040423

Epoch: 5| Step: 4
Training loss: 1.5034645125397235
Validation loss: 2.471428550609523

Epoch: 5| Step: 5
Training loss: 1.4608710778788323
Validation loss: 2.5426466858091756

Epoch: 5| Step: 6
Training loss: 1.2635774415002567
Validation loss: 2.506614742763452

Epoch: 5| Step: 7
Training loss: 1.1551839708397036
Validation loss: 2.472214687277244

Epoch: 5| Step: 8
Training loss: 1.2655310419315466
Validation loss: 2.46410431002367

Epoch: 5| Step: 9
Training loss: 1.5737488000212223
Validation loss: 2.514923697042576

Epoch: 5| Step: 10
Training loss: 1.4477442723383087
Validation loss: 2.504411232667767

Epoch: 469| Step: 0
Training loss: 2.0813297428285042
Validation loss: 2.4861255756546385

Epoch: 5| Step: 1
Training loss: 1.372989658775199
Validation loss: 2.522081075645548

Epoch: 5| Step: 2
Training loss: 1.8131389806998055
Validation loss: 2.4238467316794465

Epoch: 5| Step: 3
Training loss: 1.1656728269363161
Validation loss: 2.472343901633602

Epoch: 5| Step: 4
Training loss: 1.17110489018634
Validation loss: 2.4297082817877875

Epoch: 5| Step: 5
Training loss: 1.255360125891047
Validation loss: 2.5110393601702983

Epoch: 5| Step: 6
Training loss: 1.3282133185248655
Validation loss: 2.4495320042036037

Epoch: 5| Step: 7
Training loss: 1.2324380284140966
Validation loss: 2.53570666856427

Epoch: 5| Step: 8
Training loss: 1.287333999969123
Validation loss: 2.482169169578528

Epoch: 5| Step: 9
Training loss: 1.43950985262309
Validation loss: 2.564391850687278

Epoch: 5| Step: 10
Training loss: 1.2553076117840367
Validation loss: 2.469393610831245

Epoch: 470| Step: 0
Training loss: 1.1776482343407242
Validation loss: 2.4080980904399314

Epoch: 5| Step: 1
Training loss: 1.400502986470327
Validation loss: 2.405815849243935

Epoch: 5| Step: 2
Training loss: 1.1455475132819513
Validation loss: 2.471255973335526

Epoch: 5| Step: 3
Training loss: 1.3318809804867142
Validation loss: 2.53412541523737

Epoch: 5| Step: 4
Training loss: 1.3651249613870615
Validation loss: 2.4797199163122055

Epoch: 5| Step: 5
Training loss: 2.059762698829232
Validation loss: 2.511593360394804

Epoch: 5| Step: 6
Training loss: 1.5519189000766636
Validation loss: 2.4800287111054713

Epoch: 5| Step: 7
Training loss: 1.1255329776916623
Validation loss: 2.441488647908083

Epoch: 5| Step: 8
Training loss: 1.1711521207934785
Validation loss: 2.3787078831293926

Epoch: 5| Step: 9
Training loss: 1.7410073153250623
Validation loss: 2.558168231994084

Epoch: 5| Step: 10
Training loss: 1.1982050286013202
Validation loss: 2.4689702644079143

Epoch: 471| Step: 0
Training loss: 1.11317084584825
Validation loss: 2.47162382918488

Epoch: 5| Step: 1
Training loss: 1.314645013505792
Validation loss: 2.4948733709428375

Epoch: 5| Step: 2
Training loss: 1.3084001540272272
Validation loss: 2.4599202642550093

Epoch: 5| Step: 3
Training loss: 1.2420244889693786
Validation loss: 2.4897593472350423

Epoch: 5| Step: 4
Training loss: 1.5297444785926
Validation loss: 2.457814402912293

Epoch: 5| Step: 5
Training loss: 1.2789828548430517
Validation loss: 2.458018734509667

Epoch: 5| Step: 6
Training loss: 1.5249210274681926
Validation loss: 2.4569821100361766

Epoch: 5| Step: 7
Training loss: 1.3549196301797835
Validation loss: 2.4236122593084284

Epoch: 5| Step: 8
Training loss: 2.2912447685519117
Validation loss: 2.475458254734005

Epoch: 5| Step: 9
Training loss: 1.137982534408626
Validation loss: 2.511453341902405

Epoch: 5| Step: 10
Training loss: 1.087859613877179
Validation loss: 2.506012290974666

Epoch: 472| Step: 0
Training loss: 1.3986041007086687
Validation loss: 2.4687425315518623

Epoch: 5| Step: 1
Training loss: 1.3257824153141977
Validation loss: 2.483265373118776

Epoch: 5| Step: 2
Training loss: 1.3494071753775163
Validation loss: 2.4694386548885157

Epoch: 5| Step: 3
Training loss: 1.406544294292448
Validation loss: 2.481895109924365

Epoch: 5| Step: 4
Training loss: 1.1569147003632663
Validation loss: 2.4667540488470165

Epoch: 5| Step: 5
Training loss: 1.5892470081079755
Validation loss: 2.4453334477864828

Epoch: 5| Step: 6
Training loss: 1.0408369701882914
Validation loss: 2.4446528060998327

Epoch: 5| Step: 7
Training loss: 2.0337811471984164
Validation loss: 2.4524221025284882

Epoch: 5| Step: 8
Training loss: 0.9927940016798165
Validation loss: 2.485292173166369

Epoch: 5| Step: 9
Training loss: 1.3431184304681567
Validation loss: 2.4911731218272974

Epoch: 5| Step: 10
Training loss: 1.1600770762750485
Validation loss: 2.4615971402745602

Epoch: 473| Step: 0
Training loss: 0.8919483859820143
Validation loss: 2.3863522547442586

Epoch: 5| Step: 1
Training loss: 1.132300530860734
Validation loss: 2.402075227259617

Epoch: 5| Step: 2
Training loss: 1.6146637024924435
Validation loss: 2.4897913884265193

Epoch: 5| Step: 3
Training loss: 1.4775597973646306
Validation loss: 2.4921182859493674

Epoch: 5| Step: 4
Training loss: 1.3739297342782442
Validation loss: 2.4980079949124088

Epoch: 5| Step: 5
Training loss: 1.0697744646085356
Validation loss: 2.4820550870431966

Epoch: 5| Step: 6
Training loss: 2.2890702074982228
Validation loss: 2.540335704302741

Epoch: 5| Step: 7
Training loss: 1.4318046527900448
Validation loss: 2.5537234243345965

Epoch: 5| Step: 8
Training loss: 1.3669863307635022
Validation loss: 2.424243862228815

Epoch: 5| Step: 9
Training loss: 0.9650949622159809
Validation loss: 2.5292760722317285

Epoch: 5| Step: 10
Training loss: 0.9988429110569792
Validation loss: 2.4896091688616533

Epoch: 474| Step: 0
Training loss: 1.3470917777306024
Validation loss: 2.439759948225819

Epoch: 5| Step: 1
Training loss: 1.2656414831524536
Validation loss: 2.509476110493483

Epoch: 5| Step: 2
Training loss: 1.2761309637886358
Validation loss: 2.4659313156207134

Epoch: 5| Step: 3
Training loss: 1.3065160398290667
Validation loss: 2.398264816303012

Epoch: 5| Step: 4
Training loss: 1.2380173459108903
Validation loss: 2.4476247595539173

Epoch: 5| Step: 5
Training loss: 1.475962845073629
Validation loss: 2.4580810230380634

Epoch: 5| Step: 6
Training loss: 2.1507136823777575
Validation loss: 2.466384557177576

Epoch: 5| Step: 7
Training loss: 1.2339374877484512
Validation loss: 2.450721321292589

Epoch: 5| Step: 8
Training loss: 1.22902670025669
Validation loss: 2.4804346230978624

Epoch: 5| Step: 9
Training loss: 1.1790639985391218
Validation loss: 2.472641031858358

Epoch: 5| Step: 10
Training loss: 1.5240649373995336
Validation loss: 2.3949542126468497

Epoch: 475| Step: 0
Training loss: 1.1108458533491288
Validation loss: 2.485983523587231

Epoch: 5| Step: 1
Training loss: 1.3547734392795512
Validation loss: 2.3940983172317734

Epoch: 5| Step: 2
Training loss: 1.1908377870263294
Validation loss: 2.439340923285355

Epoch: 5| Step: 3
Training loss: 1.0798579124302456
Validation loss: 2.535589497162395

Epoch: 5| Step: 4
Training loss: 1.2118769785258454
Validation loss: 2.5322168788208503

Epoch: 5| Step: 5
Training loss: 2.4483982883957798
Validation loss: 2.458679994098811

Epoch: 5| Step: 6
Training loss: 1.2027595262168052
Validation loss: 2.5023375483504835

Epoch: 5| Step: 7
Training loss: 1.284415544672788
Validation loss: 2.5105124855128307

Epoch: 5| Step: 8
Training loss: 1.1951609496738527
Validation loss: 2.544139353891155

Epoch: 5| Step: 9
Training loss: 1.1920097948574382
Validation loss: 2.4928720630679297

Epoch: 5| Step: 10
Training loss: 1.6188433734372074
Validation loss: 2.448680545031047

Epoch: 476| Step: 0
Training loss: 1.37186885997467
Validation loss: 2.4959953679385456

Epoch: 5| Step: 1
Training loss: 1.9740414430003392
Validation loss: 2.4956775501691024

Epoch: 5| Step: 2
Training loss: 1.5941789835114897
Validation loss: 2.4841340538218626

Epoch: 5| Step: 3
Training loss: 1.193838419810257
Validation loss: 2.481210395850483

Epoch: 5| Step: 4
Training loss: 1.4135614424212126
Validation loss: 2.4860379496697362

Epoch: 5| Step: 5
Training loss: 1.3241245382548172
Validation loss: 2.4084468626024673

Epoch: 5| Step: 6
Training loss: 1.354720731017453
Validation loss: 2.454181734845227

Epoch: 5| Step: 7
Training loss: 1.2639147659186525
Validation loss: 2.4257121872297764

Epoch: 5| Step: 8
Training loss: 1.3315385819108614
Validation loss: 2.4015756866080027

Epoch: 5| Step: 9
Training loss: 1.1373388951833785
Validation loss: 2.4993767792153556

Epoch: 5| Step: 10
Training loss: 1.2866374005726586
Validation loss: 2.4219483723344686

Epoch: 477| Step: 0
Training loss: 0.9585607334908398
Validation loss: 2.452495188686664

Epoch: 5| Step: 1
Training loss: 1.9535941819275395
Validation loss: 2.421144992711878

Epoch: 5| Step: 2
Training loss: 1.2289977469458542
Validation loss: 2.392677684836237

Epoch: 5| Step: 3
Training loss: 1.4101734952849594
Validation loss: 2.446426271625308

Epoch: 5| Step: 4
Training loss: 1.2823964084184676
Validation loss: 2.419964449384171

Epoch: 5| Step: 5
Training loss: 1.243955254032121
Validation loss: 2.5033930262014588

Epoch: 5| Step: 6
Training loss: 1.4379259390666979
Validation loss: 2.478197746211032

Epoch: 5| Step: 7
Training loss: 1.3238094901458655
Validation loss: 2.5280817602696968

Epoch: 5| Step: 8
Training loss: 1.3678299184748588
Validation loss: 2.4748562372574394

Epoch: 5| Step: 9
Training loss: 1.5569715734396912
Validation loss: 2.3651192306157807

Epoch: 5| Step: 10
Training loss: 1.4153424787389104
Validation loss: 2.42712000794904

Epoch: 478| Step: 0
Training loss: 1.1641683850358766
Validation loss: 2.5232499692752213

Epoch: 5| Step: 1
Training loss: 1.3587254254769296
Validation loss: 2.428448204876791

Epoch: 5| Step: 2
Training loss: 1.0861314559184456
Validation loss: 2.4622710126131624

Epoch: 5| Step: 3
Training loss: 1.2569681970917406
Validation loss: 2.4410861317767583

Epoch: 5| Step: 4
Training loss: 1.240857353840463
Validation loss: 2.527310896640589

Epoch: 5| Step: 5
Training loss: 1.3727893832088518
Validation loss: 2.4607069681989593

Epoch: 5| Step: 6
Training loss: 1.9423591224909664
Validation loss: 2.4727245415274792

Epoch: 5| Step: 7
Training loss: 1.439264955475727
Validation loss: 2.4876079099353934

Epoch: 5| Step: 8
Training loss: 1.4019728146092714
Validation loss: 2.394563349208709

Epoch: 5| Step: 9
Training loss: 1.4301169328964685
Validation loss: 2.4450311651927215

Epoch: 5| Step: 10
Training loss: 1.298121255677305
Validation loss: 2.4729806422561738

Epoch: 479| Step: 0
Training loss: 1.3822845916835291
Validation loss: 2.4581181067149735

Epoch: 5| Step: 1
Training loss: 1.147237085462157
Validation loss: 2.399064525088269

Epoch: 5| Step: 2
Training loss: 1.0555756396898175
Validation loss: 2.4717754570841457

Epoch: 5| Step: 3
Training loss: 1.0355804150134709
Validation loss: 2.4523139115935195

Epoch: 5| Step: 4
Training loss: 1.1746835241836524
Validation loss: 2.4739622185789383

Epoch: 5| Step: 5
Training loss: 2.010425811377828
Validation loss: 2.4788346182401972

Epoch: 5| Step: 6
Training loss: 1.5099049808593106
Validation loss: 2.46568944570155

Epoch: 5| Step: 7
Training loss: 1.1230079179724137
Validation loss: 2.468659980433867

Epoch: 5| Step: 8
Training loss: 1.4519594501791706
Validation loss: 2.483273947942307

Epoch: 5| Step: 9
Training loss: 1.337825177673279
Validation loss: 2.4669812451120534

Epoch: 5| Step: 10
Training loss: 1.325483904950573
Validation loss: 2.4769098042154036

Epoch: 480| Step: 0
Training loss: 1.1955890211005196
Validation loss: 2.457038735264953

Epoch: 5| Step: 1
Training loss: 0.9585168013276706
Validation loss: 2.410134038083061

Epoch: 5| Step: 2
Training loss: 1.3163849690242493
Validation loss: 2.4911181549665353

Epoch: 5| Step: 3
Training loss: 1.3713047484715213
Validation loss: 2.472704284301976

Epoch: 5| Step: 4
Training loss: 1.3708331085869663
Validation loss: 2.488995686641069

Epoch: 5| Step: 5
Training loss: 1.1053321673126728
Validation loss: 2.5310809535886962

Epoch: 5| Step: 6
Training loss: 0.9005903572763313
Validation loss: 2.4276610740493605

Epoch: 5| Step: 7
Training loss: 1.1428526980449891
Validation loss: 2.3715223445449842

Epoch: 5| Step: 8
Training loss: 1.3280463700299425
Validation loss: 2.43239820427564

Epoch: 5| Step: 9
Training loss: 2.501136426124857
Validation loss: 2.460623216068665

Epoch: 5| Step: 10
Training loss: 1.006917452541774
Validation loss: 2.51624462333751

Epoch: 481| Step: 0
Training loss: 1.1822179471642138
Validation loss: 2.5267541463934973

Epoch: 5| Step: 1
Training loss: 2.2299341205736076
Validation loss: 2.5693996312088587

Epoch: 5| Step: 2
Training loss: 1.3711641299016122
Validation loss: 2.4015019032013716

Epoch: 5| Step: 3
Training loss: 1.4411671344527948
Validation loss: 2.4480218802318148

Epoch: 5| Step: 4
Training loss: 1.5726397525321898
Validation loss: 2.4486273066347346

Epoch: 5| Step: 5
Training loss: 1.2359140676020495
Validation loss: 2.4286899508430255

Epoch: 5| Step: 6
Training loss: 1.3616920980711245
Validation loss: 2.404059206110581

Epoch: 5| Step: 7
Training loss: 1.070994974001677
Validation loss: 2.4043394339068302

Epoch: 5| Step: 8
Training loss: 1.309191348140461
Validation loss: 2.4700041254626974

Epoch: 5| Step: 9
Training loss: 0.966078489412262
Validation loss: 2.393549456437342

Epoch: 5| Step: 10
Training loss: 0.6360714202012477
Validation loss: 2.483949878343696

Epoch: 482| Step: 0
Training loss: 1.238459529136927
Validation loss: 2.5065281869455216

Epoch: 5| Step: 1
Training loss: 1.0147924091605536
Validation loss: 2.5173294294714226

Epoch: 5| Step: 2
Training loss: 1.1789263865758985
Validation loss: 2.484897463395137

Epoch: 5| Step: 3
Training loss: 0.9968489532894569
Validation loss: 2.4263625641738638

Epoch: 5| Step: 4
Training loss: 1.3264616479717908
Validation loss: 2.4660499151194935

Epoch: 5| Step: 5
Training loss: 1.182035925453152
Validation loss: 2.4074728843748074

Epoch: 5| Step: 6
Training loss: 1.5304572719827059
Validation loss: 2.497342707333571

Epoch: 5| Step: 7
Training loss: 2.1563476319254957
Validation loss: 2.5360001900326288

Epoch: 5| Step: 8
Training loss: 1.3562645238986422
Validation loss: 2.455732936688989

Epoch: 5| Step: 9
Training loss: 1.4333457628346977
Validation loss: 2.410757879266826

Epoch: 5| Step: 10
Training loss: 1.383682968390688
Validation loss: 2.486456487865382

Epoch: 483| Step: 0
Training loss: 1.175406513506069
Validation loss: 2.5024658737207015

Epoch: 5| Step: 1
Training loss: 1.278780301463115
Validation loss: 2.443070440444779

Epoch: 5| Step: 2
Training loss: 1.1103403968216075
Validation loss: 2.4611071320938027

Epoch: 5| Step: 3
Training loss: 1.0616392126880347
Validation loss: 2.4529634632447146

Epoch: 5| Step: 4
Training loss: 1.064320855278307
Validation loss: 2.452605659204398

Epoch: 5| Step: 5
Training loss: 1.1894702628268148
Validation loss: 2.53594947271119

Epoch: 5| Step: 6
Training loss: 1.0399783694328668
Validation loss: 2.4685285725170036

Epoch: 5| Step: 7
Training loss: 1.636040230543189
Validation loss: 2.442377448796176

Epoch: 5| Step: 8
Training loss: 2.0774465041267716
Validation loss: 2.4122555934892462

Epoch: 5| Step: 9
Training loss: 1.412280777992732
Validation loss: 2.4754430382836548

Epoch: 5| Step: 10
Training loss: 1.5476881259830217
Validation loss: 2.5311969390456786

Epoch: 484| Step: 0
Training loss: 0.909699910903814
Validation loss: 2.4226203483392297

Epoch: 5| Step: 1
Training loss: 0.8813100199179249
Validation loss: 2.474066535556709

Epoch: 5| Step: 2
Training loss: 1.2640447759151943
Validation loss: 2.4821305613333413

Epoch: 5| Step: 3
Training loss: 1.400082904200222
Validation loss: 2.512143001336156

Epoch: 5| Step: 4
Training loss: 1.2909683472810791
Validation loss: 2.4478712976179113

Epoch: 5| Step: 5
Training loss: 1.3202211246810889
Validation loss: 2.462237056729298

Epoch: 5| Step: 6
Training loss: 2.045478286027407
Validation loss: 2.5055892730094147

Epoch: 5| Step: 7
Training loss: 1.141959415733463
Validation loss: 2.509425535446489

Epoch: 5| Step: 8
Training loss: 1.6183094795006456
Validation loss: 2.4735157125183127

Epoch: 5| Step: 9
Training loss: 1.5162209980857049
Validation loss: 2.402358974859077

Epoch: 5| Step: 10
Training loss: 1.3579032648124976
Validation loss: 2.560316934199072

Epoch: 485| Step: 0
Training loss: 1.479441102408063
Validation loss: 2.5407572840354633

Epoch: 5| Step: 1
Training loss: 1.4855977693917943
Validation loss: 2.435897508630099

Epoch: 5| Step: 2
Training loss: 1.192378513537756
Validation loss: 2.458120532564716

Epoch: 5| Step: 3
Training loss: 1.1469720326467014
Validation loss: 2.4967905978612825

Epoch: 5| Step: 4
Training loss: 1.14586683860112
Validation loss: 2.5327949321236476

Epoch: 5| Step: 5
Training loss: 1.1793113260309316
Validation loss: 2.4441141264347896

Epoch: 5| Step: 6
Training loss: 1.9432432513790319
Validation loss: 2.413080059283774

Epoch: 5| Step: 7
Training loss: 1.3600089688566335
Validation loss: 2.491185575839886

Epoch: 5| Step: 8
Training loss: 1.4394440152463606
Validation loss: 2.4913462776483706

Epoch: 5| Step: 9
Training loss: 0.9491427041819984
Validation loss: 2.46793739311834

Epoch: 5| Step: 10
Training loss: 1.246816013250727
Validation loss: 2.483165584091001

Epoch: 486| Step: 0
Training loss: 1.0694680885629682
Validation loss: 2.4279436555456773

Epoch: 5| Step: 1
Training loss: 1.6846451806279674
Validation loss: 2.506790823474411

Epoch: 5| Step: 2
Training loss: 0.858535286992996
Validation loss: 2.4993353175429243

Epoch: 5| Step: 3
Training loss: 1.073459093079364
Validation loss: 2.4253142971553263

Epoch: 5| Step: 4
Training loss: 1.4663215202196207
Validation loss: 2.4962775658458907

Epoch: 5| Step: 5
Training loss: 1.203402351018642
Validation loss: 2.428724011582615

Epoch: 5| Step: 6
Training loss: 1.4397290404023362
Validation loss: 2.5231047014358485

Epoch: 5| Step: 7
Training loss: 1.127771302039143
Validation loss: 2.452007797226003

Epoch: 5| Step: 8
Training loss: 0.9681415185079381
Validation loss: 2.433254127320278

Epoch: 5| Step: 9
Training loss: 2.431963281021742
Validation loss: 2.4821691070927545

Epoch: 5| Step: 10
Training loss: 1.0918603104125655
Validation loss: 2.5274751921322443

Epoch: 487| Step: 0
Training loss: 2.1836346944883864
Validation loss: 2.4719930448636362

Epoch: 5| Step: 1
Training loss: 1.374784365998455
Validation loss: 2.459414026798949

Epoch: 5| Step: 2
Training loss: 1.0970650163264264
Validation loss: 2.4025807226865528

Epoch: 5| Step: 3
Training loss: 1.065410330620162
Validation loss: 2.4285278011126703

Epoch: 5| Step: 4
Training loss: 1.2708654347518742
Validation loss: 2.391240827133517

Epoch: 5| Step: 5
Training loss: 1.445825186861304
Validation loss: 2.450907549210564

Epoch: 5| Step: 6
Training loss: 1.0692627485477195
Validation loss: 2.420727146375427

Epoch: 5| Step: 7
Training loss: 1.4424730607133671
Validation loss: 2.501313138976445

Epoch: 5| Step: 8
Training loss: 1.1648128062793977
Validation loss: 2.4625243909964696

Epoch: 5| Step: 9
Training loss: 1.2105065840361267
Validation loss: 2.500526633220035

Epoch: 5| Step: 10
Training loss: 1.1612733542534033
Validation loss: 2.4333288611880732

Epoch: 488| Step: 0
Training loss: 1.2303979762477377
Validation loss: 2.471264667632921

Epoch: 5| Step: 1
Training loss: 1.0122023203731427
Validation loss: 2.47182613247907

Epoch: 5| Step: 2
Training loss: 1.702990325362657
Validation loss: 2.491846460963199

Epoch: 5| Step: 3
Training loss: 0.9013582933840547
Validation loss: 2.468904572696336

Epoch: 5| Step: 4
Training loss: 0.971038637569155
Validation loss: 2.5008363145275907

Epoch: 5| Step: 5
Training loss: 1.0339187999031116
Validation loss: 2.4928483951114524

Epoch: 5| Step: 6
Training loss: 2.278365624047115
Validation loss: 2.471699467714349

Epoch: 5| Step: 7
Training loss: 1.4468555358500286
Validation loss: 2.468128398679502

Epoch: 5| Step: 8
Training loss: 1.0972698250972313
Validation loss: 2.490440745833564

Epoch: 5| Step: 9
Training loss: 0.9903953466553365
Validation loss: 2.393530773824369

Epoch: 5| Step: 10
Training loss: 1.3573856047031538
Validation loss: 2.446459232442593

Epoch: 489| Step: 0
Training loss: 1.1366681484220211
Validation loss: 2.483618669317423

Epoch: 5| Step: 1
Training loss: 1.8820098178984448
Validation loss: 2.4473783464479637

Epoch: 5| Step: 2
Training loss: 1.7040656755488806
Validation loss: 2.5186742270171996

Epoch: 5| Step: 3
Training loss: 1.447796722859693
Validation loss: 2.4136737686125183

Epoch: 5| Step: 4
Training loss: 1.2494645879397714
Validation loss: 2.4786574612102967

Epoch: 5| Step: 5
Training loss: 1.074316679218758
Validation loss: 2.4444940754212374

Epoch: 5| Step: 6
Training loss: 1.3266164402503617
Validation loss: 2.4800551688766115

Epoch: 5| Step: 7
Training loss: 1.4751682056273443
Validation loss: 2.521168489141913

Epoch: 5| Step: 8
Training loss: 1.4765809880466645
Validation loss: 2.4325695377573533

Epoch: 5| Step: 9
Training loss: 1.0774530168632266
Validation loss: 2.4092206720149965

Epoch: 5| Step: 10
Training loss: 1.4096850931615965
Validation loss: 2.440017991973828

Epoch: 490| Step: 0
Training loss: 1.4974434046168548
Validation loss: 2.468408820888185

Epoch: 5| Step: 1
Training loss: 1.1217055827716476
Validation loss: 2.4425844382837054

Epoch: 5| Step: 2
Training loss: 1.142987143837223
Validation loss: 2.483007165799595

Epoch: 5| Step: 3
Training loss: 2.050739629413965
Validation loss: 2.5048957960458385

Epoch: 5| Step: 4
Training loss: 1.297847245484026
Validation loss: 2.434359463311419

Epoch: 5| Step: 5
Training loss: 0.9613800270426281
Validation loss: 2.4837547390116597

Epoch: 5| Step: 6
Training loss: 1.1298031527463925
Validation loss: 2.3958321266831137

Epoch: 5| Step: 7
Training loss: 1.1368020672758554
Validation loss: 2.436871573037354

Epoch: 5| Step: 8
Training loss: 1.500990937659896
Validation loss: 2.4473892457114363

Epoch: 5| Step: 9
Training loss: 1.357393903924381
Validation loss: 2.473706982489111

Epoch: 5| Step: 10
Training loss: 0.9359659359390278
Validation loss: 2.542419496260931

Epoch: 491| Step: 0
Training loss: 1.4677153656436621
Validation loss: 2.539174668932079

Epoch: 5| Step: 1
Training loss: 1.452861310762926
Validation loss: 2.532957446342364

Epoch: 5| Step: 2
Training loss: 1.0594720891612917
Validation loss: 2.482822967649517

Epoch: 5| Step: 3
Training loss: 1.3322668678216603
Validation loss: 2.426731232132171

Epoch: 5| Step: 4
Training loss: 1.932578080192689
Validation loss: 2.518685517019651

Epoch: 5| Step: 5
Training loss: 1.2748914036597345
Validation loss: 2.4814054366936906

Epoch: 5| Step: 6
Training loss: 1.4431701453521233
Validation loss: 2.471845852664062

Epoch: 5| Step: 7
Training loss: 1.444933207463079
Validation loss: 2.4438018929276595

Epoch: 5| Step: 8
Training loss: 0.9647945128939585
Validation loss: 2.4184760815310797

Epoch: 5| Step: 9
Training loss: 1.1015537342777895
Validation loss: 2.4705057932014283

Epoch: 5| Step: 10
Training loss: 1.3925459805880964
Validation loss: 2.4635926064707547

Epoch: 492| Step: 0
Training loss: 1.0565564021532836
Validation loss: 2.474654161991489

Epoch: 5| Step: 1
Training loss: 1.3149875954307628
Validation loss: 2.4515724742796325

Epoch: 5| Step: 2
Training loss: 1.426164633012375
Validation loss: 2.5211108414372227

Epoch: 5| Step: 3
Training loss: 1.2555520733266459
Validation loss: 2.473982875078338

Epoch: 5| Step: 4
Training loss: 0.9801349755679436
Validation loss: 2.39553642912182

Epoch: 5| Step: 5
Training loss: 1.3738434435760758
Validation loss: 2.4042708769526815

Epoch: 5| Step: 6
Training loss: 2.0842195787491793
Validation loss: 2.4644769074760444

Epoch: 5| Step: 7
Training loss: 1.1604115625859344
Validation loss: 2.489913571159079

Epoch: 5| Step: 8
Training loss: 1.1247275870371543
Validation loss: 2.4207595474084997

Epoch: 5| Step: 9
Training loss: 1.2345693893924032
Validation loss: 2.5034394170027277

Epoch: 5| Step: 10
Training loss: 1.363338480188095
Validation loss: 2.520506290898865

Epoch: 493| Step: 0
Training loss: 1.056447799490683
Validation loss: 2.479773216022985

Epoch: 5| Step: 1
Training loss: 1.1561234894696337
Validation loss: 2.4446843940145384

Epoch: 5| Step: 2
Training loss: 0.9027564686110591
Validation loss: 2.5061750075332294

Epoch: 5| Step: 3
Training loss: 1.4211629405067698
Validation loss: 2.5470226282047777

Epoch: 5| Step: 4
Training loss: 1.977261024049825
Validation loss: 2.459071306350355

Epoch: 5| Step: 5
Training loss: 1.1835576923782567
Validation loss: 2.471823971069192

Epoch: 5| Step: 6
Training loss: 0.8997883799561267
Validation loss: 2.48006681248063

Epoch: 5| Step: 7
Training loss: 1.8816985321162454
Validation loss: 2.4751832547195294

Epoch: 5| Step: 8
Training loss: 1.2172993071185356
Validation loss: 2.5559780442027624

Epoch: 5| Step: 9
Training loss: 1.2431923502710025
Validation loss: 2.50978300314348

Epoch: 5| Step: 10
Training loss: 1.369412992325584
Validation loss: 2.456975905910228

Epoch: 494| Step: 0
Training loss: 2.048094175244729
Validation loss: 2.4449054843589946

Epoch: 5| Step: 1
Training loss: 0.9341712346732359
Validation loss: 2.467825458286605

Epoch: 5| Step: 2
Training loss: 1.079202307231634
Validation loss: 2.3779692167033892

Epoch: 5| Step: 3
Training loss: 1.2220997381729608
Validation loss: 2.4644567340728463

Epoch: 5| Step: 4
Training loss: 1.375854356806524
Validation loss: 2.408102266828564

Epoch: 5| Step: 5
Training loss: 1.3706092956728726
Validation loss: 2.4128609062321367

Epoch: 5| Step: 6
Training loss: 1.1002521702684989
Validation loss: 2.480129801115128

Epoch: 5| Step: 7
Training loss: 1.3887045812175653
Validation loss: 2.4847665174991858

Epoch: 5| Step: 8
Training loss: 1.5332402121559416
Validation loss: 2.471775671777429

Epoch: 5| Step: 9
Training loss: 1.3020347993070567
Validation loss: 2.4084117662528643

Epoch: 5| Step: 10
Training loss: 0.8313964786396238
Validation loss: 2.543606506212342

Epoch: 495| Step: 0
Training loss: 0.9283110422497797
Validation loss: 2.46182771472178

Epoch: 5| Step: 1
Training loss: 2.0057078214183344
Validation loss: 2.4822206428619804

Epoch: 5| Step: 2
Training loss: 1.0805619933964343
Validation loss: 2.3957386262070393

Epoch: 5| Step: 3
Training loss: 1.6227500451299073
Validation loss: 2.48630983949305

Epoch: 5| Step: 4
Training loss: 1.3054871992157886
Validation loss: 2.4109966699313836

Epoch: 5| Step: 5
Training loss: 1.007997481055367
Validation loss: 2.402249059604271

Epoch: 5| Step: 6
Training loss: 1.4213752287462853
Validation loss: 2.49063953414923

Epoch: 5| Step: 7
Training loss: 1.1579324492845073
Validation loss: 2.4652284797416257

Epoch: 5| Step: 8
Training loss: 1.047079550274169
Validation loss: 2.4873471361148245

Epoch: 5| Step: 9
Training loss: 1.2692644044225165
Validation loss: 2.4521808174947495

Epoch: 5| Step: 10
Training loss: 1.2361295278417856
Validation loss: 2.5202185971871383

Epoch: 496| Step: 0
Training loss: 1.5490388474343035
Validation loss: 2.541492021095568

Epoch: 5| Step: 1
Training loss: 1.269582800185356
Validation loss: 2.495653664848939

Epoch: 5| Step: 2
Training loss: 1.1923141272255258
Validation loss: 2.486445137615543

Epoch: 5| Step: 3
Training loss: 1.985962240453683
Validation loss: 2.5031192393718826

Epoch: 5| Step: 4
Training loss: 0.7555326401244532
Validation loss: 2.524280117492185

Epoch: 5| Step: 5
Training loss: 1.3591754810757675
Validation loss: 2.4071092013168127

Epoch: 5| Step: 6
Training loss: 0.8605636006312992
Validation loss: 2.4904365088510745

Epoch: 5| Step: 7
Training loss: 1.565202816749064
Validation loss: 2.468734062541102

Epoch: 5| Step: 8
Training loss: 1.1538562740591256
Validation loss: 2.4319088623130973

Epoch: 5| Step: 9
Training loss: 1.4246706464857946
Validation loss: 2.5135479015961484

Epoch: 5| Step: 10
Training loss: 1.022024329237432
Validation loss: 2.4795553375472394

Epoch: 497| Step: 0
Training loss: 1.2293033954846233
Validation loss: 2.4317788735928647

Epoch: 5| Step: 1
Training loss: 1.1581008634404122
Validation loss: 2.4952205296451675

Epoch: 5| Step: 2
Training loss: 1.0771341608230551
Validation loss: 2.5122192110816184

Epoch: 5| Step: 3
Training loss: 1.0707074849632476
Validation loss: 2.492595571177742

Epoch: 5| Step: 4
Training loss: 1.1853096487391659
Validation loss: 2.4594133336170594

Epoch: 5| Step: 5
Training loss: 2.027147346053035
Validation loss: 2.451332364255719

Epoch: 5| Step: 6
Training loss: 1.4450124068206054
Validation loss: 2.4374332971020545

Epoch: 5| Step: 7
Training loss: 1.3116966241148502
Validation loss: 2.4231935921419665

Epoch: 5| Step: 8
Training loss: 1.3199888656609002
Validation loss: 2.4258317437991055

Epoch: 5| Step: 9
Training loss: 1.0923673882734874
Validation loss: 2.5529208193935142

Epoch: 5| Step: 10
Training loss: 1.396895981530786
Validation loss: 2.537908643075886

Epoch: 498| Step: 0
Training loss: 1.3892464823792432
Validation loss: 2.5174335146175726

Epoch: 5| Step: 1
Training loss: 1.992578744804078
Validation loss: 2.4184036130226723

Epoch: 5| Step: 2
Training loss: 1.0176683850811685
Validation loss: 2.4618955014196353

Epoch: 5| Step: 3
Training loss: 0.870433950938888
Validation loss: 2.4005742280815725

Epoch: 5| Step: 4
Training loss: 1.03590055373923
Validation loss: 2.3813384662602664

Epoch: 5| Step: 5
Training loss: 1.2389052590731737
Validation loss: 2.471008543901883

Epoch: 5| Step: 6
Training loss: 0.8755157177057235
Validation loss: 2.409398917894283

Epoch: 5| Step: 7
Training loss: 1.4551649643759856
Validation loss: 2.4723012897800927

Epoch: 5| Step: 8
Training loss: 1.495003165812633
Validation loss: 2.460435305163912

Epoch: 5| Step: 9
Training loss: 1.3217405462762093
Validation loss: 2.3884913884171577

Epoch: 5| Step: 10
Training loss: 1.5251169972800303
Validation loss: 2.448615941219741

Epoch: 499| Step: 0
Training loss: 1.271966283273382
Validation loss: 2.4658014891937645

Epoch: 5| Step: 1
Training loss: 2.097081508786005
Validation loss: 2.463873853940226

Epoch: 5| Step: 2
Training loss: 1.3131306813265577
Validation loss: 2.429006274694359

Epoch: 5| Step: 3
Training loss: 1.4856825039157613
Validation loss: 2.413690278339007

Epoch: 5| Step: 4
Training loss: 1.1397702920943522
Validation loss: 2.4699397752761554

Epoch: 5| Step: 5
Training loss: 0.7432999555580827
Validation loss: 2.470793188411181

Epoch: 5| Step: 6
Training loss: 0.8350720069583341
Validation loss: 2.416784213272776

Epoch: 5| Step: 7
Training loss: 1.081783445330979
Validation loss: 2.4774160770003406

Epoch: 5| Step: 8
Training loss: 1.2218543399712951
Validation loss: 2.5275667648185425

Epoch: 5| Step: 9
Training loss: 1.5861218725812927
Validation loss: 2.54333887175444

Epoch: 5| Step: 10
Training loss: 1.1601130416479035
Validation loss: 2.383563805774057

Epoch: 500| Step: 0
Training loss: 1.1524400573831188
Validation loss: 2.4139469962160836

Epoch: 5| Step: 1
Training loss: 1.0679164156477494
Validation loss: 2.4543327403281463

Epoch: 5| Step: 2
Training loss: 0.9378281019184787
Validation loss: 2.4553858246957248

Epoch: 5| Step: 3
Training loss: 1.4148900260919393
Validation loss: 2.4102134265022057

Epoch: 5| Step: 4
Training loss: 2.0391010850785345
Validation loss: 2.522528355548015

Epoch: 5| Step: 5
Training loss: 1.2964770154522869
Validation loss: 2.471595325959572

Epoch: 5| Step: 6
Training loss: 1.1920865477370057
Validation loss: 2.45508010066264

Epoch: 5| Step: 7
Training loss: 1.4774587827506975
Validation loss: 2.457797268554441

Epoch: 5| Step: 8
Training loss: 1.1143794482319402
Validation loss: 2.5254182368250335

Epoch: 5| Step: 9
Training loss: 1.279556550905321
Validation loss: 2.4606510962554027

Epoch: 5| Step: 10
Training loss: 1.16219210290164
Validation loss: 2.406470292012634

Testing loss: 3.155368501382999
