Epoch: 1| Step: 0
Training loss: 7.401195233707267
Validation loss: 6.735495238388252

Epoch: 5| Step: 1
Training loss: 5.771016729679293
Validation loss: 6.7281330558956824

Epoch: 5| Step: 2
Training loss: 7.21248549752455
Validation loss: 6.723893394171561

Epoch: 5| Step: 3
Training loss: 6.937492026934467
Validation loss: 6.717255511841685

Epoch: 5| Step: 4
Training loss: 6.869976080751494
Validation loss: 6.709169275988929

Epoch: 5| Step: 5
Training loss: 5.997746044230614
Validation loss: 6.706192844001543

Epoch: 5| Step: 6
Training loss: 6.730983933598079
Validation loss: 6.698190643071224

Epoch: 5| Step: 7
Training loss: 6.782665192912048
Validation loss: 6.693336198104508

Epoch: 5| Step: 8
Training loss: 6.682289732062837
Validation loss: 6.688857948024435

Epoch: 5| Step: 9
Training loss: 6.670343084705297
Validation loss: 6.6842067101300335

Epoch: 5| Step: 10
Training loss: 6.4885705083023435
Validation loss: 6.675454347903402

Epoch: 2| Step: 0
Training loss: 5.996567698084867
Validation loss: 6.670363589669318

Epoch: 5| Step: 1
Training loss: 6.602642408898513
Validation loss: 6.66558370510545

Epoch: 5| Step: 2
Training loss: 6.28786382210306
Validation loss: 6.658714576488874

Epoch: 5| Step: 3
Training loss: 7.132483584454964
Validation loss: 6.6547665639324265

Epoch: 5| Step: 4
Training loss: 7.1639235222002196
Validation loss: 6.6476935641179145

Epoch: 5| Step: 5
Training loss: 6.411940117797323
Validation loss: 6.644645620532994

Epoch: 5| Step: 6
Training loss: 6.795474554898247
Validation loss: 6.636611208402653

Epoch: 5| Step: 7
Training loss: 7.06393634065001
Validation loss: 6.629986292575043

Epoch: 5| Step: 8
Training loss: 6.642253361933817
Validation loss: 6.628685014412176

Epoch: 5| Step: 9
Training loss: 6.148605014792354
Validation loss: 6.620832882148054

Epoch: 5| Step: 10
Training loss: 6.710572558106885
Validation loss: 6.616255192841168

Epoch: 3| Step: 0
Training loss: 7.375746866975786
Validation loss: 6.6104902951041495

Epoch: 5| Step: 1
Training loss: 6.1547564713544665
Validation loss: 6.605187442742359

Epoch: 5| Step: 2
Training loss: 6.687780356546715
Validation loss: 6.600822720378025

Epoch: 5| Step: 3
Training loss: 5.705081468246196
Validation loss: 6.5947032589905055

Epoch: 5| Step: 4
Training loss: 6.071937373023051
Validation loss: 6.589841095265247

Epoch: 5| Step: 5
Training loss: 6.37558339759335
Validation loss: 6.585473837902136

Epoch: 5| Step: 6
Training loss: 6.531168813976573
Validation loss: 6.577947552461553

Epoch: 5| Step: 7
Training loss: 7.043529858402741
Validation loss: 6.573458168469991

Epoch: 5| Step: 8
Training loss: 7.376334376768086
Validation loss: 6.567721179156782

Epoch: 5| Step: 9
Training loss: 5.548466671668508
Validation loss: 6.562010641061697

Epoch: 5| Step: 10
Training loss: 7.33241234400185
Validation loss: 6.558116055218632

Epoch: 4| Step: 0
Training loss: 6.13456943882022
Validation loss: 6.553960519686776

Epoch: 5| Step: 1
Training loss: 6.315662158552859
Validation loss: 6.54780828408381

Epoch: 5| Step: 2
Training loss: 6.6812849309737885
Validation loss: 6.541549586992357

Epoch: 5| Step: 3
Training loss: 7.099862443907777
Validation loss: 6.535454031102526

Epoch: 5| Step: 4
Training loss: 5.432654315356007
Validation loss: 6.5298319554488735

Epoch: 5| Step: 5
Training loss: 7.503794155445292
Validation loss: 6.525722872765603

Epoch: 5| Step: 6
Training loss: 6.464508287652128
Validation loss: 6.522804231579556

Epoch: 5| Step: 7
Training loss: 6.721007637590571
Validation loss: 6.514639990206783

Epoch: 5| Step: 8
Training loss: 6.17610398281102
Validation loss: 6.511636803927925

Epoch: 5| Step: 9
Training loss: 6.351830958925286
Validation loss: 6.507322359838463

Epoch: 5| Step: 10
Training loss: 6.718234729969093
Validation loss: 6.497525784689432

Epoch: 5| Step: 0
Training loss: 6.470074062011959
Validation loss: 6.492817557135231

Epoch: 5| Step: 1
Training loss: 5.91427857824386
Validation loss: 6.488184021646168

Epoch: 5| Step: 2
Training loss: 6.427494310030056
Validation loss: 6.482576937604039

Epoch: 5| Step: 3
Training loss: 6.549529709567238
Validation loss: 6.477714770254256

Epoch: 5| Step: 4
Training loss: 6.4699735359700155
Validation loss: 6.469823620474298

Epoch: 5| Step: 5
Training loss: 7.1007268936506
Validation loss: 6.466548475896559

Epoch: 5| Step: 6
Training loss: 6.808011597494609
Validation loss: 6.458024929064991

Epoch: 5| Step: 7
Training loss: 7.041923864358786
Validation loss: 6.452375286648873

Epoch: 5| Step: 8
Training loss: 6.9439570989206425
Validation loss: 6.447099294881389

Epoch: 5| Step: 9
Training loss: 6.158159763366211
Validation loss: 6.439829243183576

Epoch: 5| Step: 10
Training loss: 4.641579475245944
Validation loss: 6.437208606127592

Epoch: 6| Step: 0
Training loss: 6.698187443395076
Validation loss: 6.430652538859224

Epoch: 5| Step: 1
Training loss: 7.025053150342474
Validation loss: 6.422908115323063

Epoch: 5| Step: 2
Training loss: 6.325490445508609
Validation loss: 6.4162537444970305

Epoch: 5| Step: 3
Training loss: 6.49245366952117
Validation loss: 6.409611894060082

Epoch: 5| Step: 4
Training loss: 5.875564548070672
Validation loss: 6.406119979231261

Epoch: 5| Step: 5
Training loss: 5.776497201754277
Validation loss: 6.397713657925653

Epoch: 5| Step: 6
Training loss: 6.444405712727464
Validation loss: 6.392297205798715

Epoch: 5| Step: 7
Training loss: 6.589927975806591
Validation loss: 6.388505592398904

Epoch: 5| Step: 8
Training loss: 6.646718826216824
Validation loss: 6.378350773700972

Epoch: 5| Step: 9
Training loss: 6.18910119502783
Validation loss: 6.372808013220314

Epoch: 5| Step: 10
Training loss: 6.201431158457371
Validation loss: 6.366655193529624

Epoch: 7| Step: 0
Training loss: 6.038708122485654
Validation loss: 6.360091801395724

Epoch: 5| Step: 1
Training loss: 6.533131013708906
Validation loss: 6.354038096686711

Epoch: 5| Step: 2
Training loss: 6.026484528942881
Validation loss: 6.347034004602717

Epoch: 5| Step: 3
Training loss: 6.240319957355233
Validation loss: 6.340688205294945

Epoch: 5| Step: 4
Training loss: 7.366884583346984
Validation loss: 6.335668215483906

Epoch: 5| Step: 5
Training loss: 6.340857236170986
Validation loss: 6.3262422670418585

Epoch: 5| Step: 6
Training loss: 5.570461447758776
Validation loss: 6.3192444790840865

Epoch: 5| Step: 7
Training loss: 6.638344622248115
Validation loss: 6.311379041453048

Epoch: 5| Step: 8
Training loss: 5.763756922343558
Validation loss: 6.303565615796324

Epoch: 5| Step: 9
Training loss: 7.151703168849504
Validation loss: 6.296977491457413

Epoch: 5| Step: 10
Training loss: 5.5673364765491975
Validation loss: 6.290119680440576

Epoch: 8| Step: 0
Training loss: 5.893807358528386
Validation loss: 6.281600348939574

Epoch: 5| Step: 1
Training loss: 5.918913974121996
Validation loss: 6.277506474002322

Epoch: 5| Step: 2
Training loss: 6.162701474623936
Validation loss: 6.269657489051439

Epoch: 5| Step: 3
Training loss: 6.464929309290326
Validation loss: 6.261015588008326

Epoch: 5| Step: 4
Training loss: 6.053547334683355
Validation loss: 6.25616428538255

Epoch: 5| Step: 5
Training loss: 6.7084060886141845
Validation loss: 6.245745438447219

Epoch: 5| Step: 6
Training loss: 6.070640839837161
Validation loss: 6.239466263546937

Epoch: 5| Step: 7
Training loss: 5.782315872499982
Validation loss: 6.233327186997767

Epoch: 5| Step: 8
Training loss: 6.6635784943849865
Validation loss: 6.222694992942752

Epoch: 5| Step: 9
Training loss: 6.835155647252517
Validation loss: 6.216942160640323

Epoch: 5| Step: 10
Training loss: 6.0423800693994885
Validation loss: 6.207398908016606

Epoch: 9| Step: 0
Training loss: 5.4382453495304395
Validation loss: 6.200680953283968

Epoch: 5| Step: 1
Training loss: 6.439134705029218
Validation loss: 6.189793540865461

Epoch: 5| Step: 2
Training loss: 6.537715066614354
Validation loss: 6.1843838734329335

Epoch: 5| Step: 3
Training loss: 5.389953040659777
Validation loss: 6.178670988512561

Epoch: 5| Step: 4
Training loss: 6.338513247056085
Validation loss: 6.166979725525947

Epoch: 5| Step: 5
Training loss: 6.502947505818245
Validation loss: 6.15801886925245

Epoch: 5| Step: 6
Training loss: 6.176424228269832
Validation loss: 6.1498355465655985

Epoch: 5| Step: 7
Training loss: 6.4658872010067245
Validation loss: 6.142647669438746

Epoch: 5| Step: 8
Training loss: 6.624436264524998
Validation loss: 6.133353448026042

Epoch: 5| Step: 9
Training loss: 5.83591200734894
Validation loss: 6.122613404642766

Epoch: 5| Step: 10
Training loss: 5.816589229618444
Validation loss: 6.114802658385776

Epoch: 10| Step: 0
Training loss: 6.782494496709923
Validation loss: 6.107732192701563

Epoch: 5| Step: 1
Training loss: 5.504741705465978
Validation loss: 6.096657726540292

Epoch: 5| Step: 2
Training loss: 6.563342521716587
Validation loss: 6.088165765362103

Epoch: 5| Step: 3
Training loss: 5.946122824828732
Validation loss: 6.0813389114702625

Epoch: 5| Step: 4
Training loss: 6.108274394848652
Validation loss: 6.067344246534037

Epoch: 5| Step: 5
Training loss: 5.743253315733308
Validation loss: 6.060882183349625

Epoch: 5| Step: 6
Training loss: 6.230714875624476
Validation loss: 6.048517404608732

Epoch: 5| Step: 7
Training loss: 5.734112892085373
Validation loss: 6.043898900844439

Epoch: 5| Step: 8
Training loss: 5.532666041265271
Validation loss: 6.031640365492421

Epoch: 5| Step: 9
Training loss: 6.596312689296249
Validation loss: 6.019186302238975

Epoch: 5| Step: 10
Training loss: 5.741275969317219
Validation loss: 6.011546359789827

Epoch: 11| Step: 0
Training loss: 6.005750761213002
Validation loss: 5.995700464701455

Epoch: 5| Step: 1
Training loss: 5.644672663940065
Validation loss: 5.988722176370844

Epoch: 5| Step: 2
Training loss: 6.073902850507435
Validation loss: 5.976894246829012

Epoch: 5| Step: 3
Training loss: 6.045000756755115
Validation loss: 5.962199991265286

Epoch: 5| Step: 4
Training loss: 5.914573979905022
Validation loss: 5.956865808753898

Epoch: 5| Step: 5
Training loss: 5.725312017075671
Validation loss: 5.943352639106657

Epoch: 5| Step: 6
Training loss: 5.593464934688153
Validation loss: 5.929972640346231

Epoch: 5| Step: 7
Training loss: 6.375752423331935
Validation loss: 5.924815922879584

Epoch: 5| Step: 8
Training loss: 5.584469560997711
Validation loss: 5.910573780976389

Epoch: 5| Step: 9
Training loss: 5.9177002697968994
Validation loss: 5.900597468277017

Epoch: 5| Step: 10
Training loss: 6.562102678169391
Validation loss: 5.887800369663103

Epoch: 12| Step: 0
Training loss: 5.506134253680677
Validation loss: 5.877108863711456

Epoch: 5| Step: 1
Training loss: 5.756229177762455
Validation loss: 5.866334370229035

Epoch: 5| Step: 2
Training loss: 5.987478223534088
Validation loss: 5.852734634030121

Epoch: 5| Step: 3
Training loss: 6.599990856279917
Validation loss: 5.841515846242893

Epoch: 5| Step: 4
Training loss: 6.634202431848028
Validation loss: 5.829023614411865

Epoch: 5| Step: 5
Training loss: 5.52508546236663
Validation loss: 5.813223344030095

Epoch: 5| Step: 6
Training loss: 5.743163647365441
Validation loss: 5.801542979548718

Epoch: 5| Step: 7
Training loss: 5.005922433944902
Validation loss: 5.788393032819299

Epoch: 5| Step: 8
Training loss: 4.250111746721389
Validation loss: 5.776172561410292

Epoch: 5| Step: 9
Training loss: 5.741348392134315
Validation loss: 5.763610155199331

Epoch: 5| Step: 10
Training loss: 6.976024987167264
Validation loss: 5.752538529961564

Epoch: 13| Step: 0
Training loss: 6.792045192662511
Validation loss: 5.738148780241452

Epoch: 5| Step: 1
Training loss: 5.290522634436356
Validation loss: 5.728634797258635

Epoch: 5| Step: 2
Training loss: 5.155974779586725
Validation loss: 5.714093609699612

Epoch: 5| Step: 3
Training loss: 5.3444566761351835
Validation loss: 5.697731526924345

Epoch: 5| Step: 4
Training loss: 4.884526456997285
Validation loss: 5.683089973268139

Epoch: 5| Step: 5
Training loss: 5.043621892613908
Validation loss: 5.673556001058782

Epoch: 5| Step: 6
Training loss: 5.397784887855076
Validation loss: 5.659535118197983

Epoch: 5| Step: 7
Training loss: 5.981913326715779
Validation loss: 5.649949855438541

Epoch: 5| Step: 8
Training loss: 5.931502676305848
Validation loss: 5.636064630423829

Epoch: 5| Step: 9
Training loss: 5.649651656763755
Validation loss: 5.6153989866007485

Epoch: 5| Step: 10
Training loss: 6.872671946917109
Validation loss: 5.601784939213144

Epoch: 14| Step: 0
Training loss: 5.893473697791694
Validation loss: 5.592993480648776

Epoch: 5| Step: 1
Training loss: 5.421854244489271
Validation loss: 5.582305006609261

Epoch: 5| Step: 2
Training loss: 5.971415458816034
Validation loss: 5.5683332079709515

Epoch: 5| Step: 3
Training loss: 4.546432001615387
Validation loss: 5.542444340945665

Epoch: 5| Step: 4
Training loss: 4.986679070775182
Validation loss: 5.534048753669909

Epoch: 5| Step: 5
Training loss: 5.440311450457457
Validation loss: 5.519525538909667

Epoch: 5| Step: 6
Training loss: 5.017733977240864
Validation loss: 5.507919680284843

Epoch: 5| Step: 7
Training loss: 6.051570518246043
Validation loss: 5.492931184393114

Epoch: 5| Step: 8
Training loss: 5.5638374692322925
Validation loss: 5.476247920190624

Epoch: 5| Step: 9
Training loss: 6.458946576280388
Validation loss: 5.462793568945247

Epoch: 5| Step: 10
Training loss: 5.149088932670308
Validation loss: 5.447360009749686

Epoch: 15| Step: 0
Training loss: 5.028825637813686
Validation loss: 5.43141952868033

Epoch: 5| Step: 1
Training loss: 5.761373135820683
Validation loss: 5.413537168166387

Epoch: 5| Step: 2
Training loss: 5.361581064730055
Validation loss: 5.397135943600245

Epoch: 5| Step: 3
Training loss: 5.172059024176014
Validation loss: 5.3819373677772075

Epoch: 5| Step: 4
Training loss: 6.227995014891837
Validation loss: 5.370108398741567

Epoch: 5| Step: 5
Training loss: 5.022314631381809
Validation loss: 5.353294790277814

Epoch: 5| Step: 6
Training loss: 5.442598955676781
Validation loss: 5.334017457205084

Epoch: 5| Step: 7
Training loss: 4.617087116215234
Validation loss: 5.3183071625332285

Epoch: 5| Step: 8
Training loss: 5.170536847750465
Validation loss: 5.299522774591434

Epoch: 5| Step: 9
Training loss: 5.687003648499522
Validation loss: 5.28873522409929

Epoch: 5| Step: 10
Training loss: 5.356108534735294
Validation loss: 5.279276603963406

Epoch: 16| Step: 0
Training loss: 5.112504939517594
Validation loss: 5.253874373141995

Epoch: 5| Step: 1
Training loss: 5.698271559612603
Validation loss: 5.2383178573603795

Epoch: 5| Step: 2
Training loss: 4.808905113421617
Validation loss: 5.217156849677911

Epoch: 5| Step: 3
Training loss: 4.342353870873789
Validation loss: 5.193760015077384

Epoch: 5| Step: 4
Training loss: 5.313189652501336
Validation loss: 5.181055677239804

Epoch: 5| Step: 5
Training loss: 6.293482166944189
Validation loss: 5.166245612388361

Epoch: 5| Step: 6
Training loss: 4.950078273886438
Validation loss: 5.145027410734208

Epoch: 5| Step: 7
Training loss: 6.194975681457326
Validation loss: 5.131450984010835

Epoch: 5| Step: 8
Training loss: 5.2739863357338
Validation loss: 5.119502208340517

Epoch: 5| Step: 9
Training loss: 4.179359380374254
Validation loss: 5.089333863644454

Epoch: 5| Step: 10
Training loss: 4.282884939945676
Validation loss: 5.068957161822707

Epoch: 17| Step: 0
Training loss: 5.522417678461206
Validation loss: 5.052569377401518

Epoch: 5| Step: 1
Training loss: 5.174110321378725
Validation loss: 5.036711347566407

Epoch: 5| Step: 2
Training loss: 4.393480343093216
Validation loss: 5.0202002800441585

Epoch: 5| Step: 3
Training loss: 5.047387064652355
Validation loss: 4.998981659256042

Epoch: 5| Step: 4
Training loss: 4.677637125489619
Validation loss: 4.975513406078134

Epoch: 5| Step: 5
Training loss: 5.461557770567844
Validation loss: 4.961929617151497

Epoch: 5| Step: 6
Training loss: 4.579676654845782
Validation loss: 4.93780160265489

Epoch: 5| Step: 7
Training loss: 5.845422189310971
Validation loss: 4.923039949200771

Epoch: 5| Step: 8
Training loss: 4.901728399191297
Validation loss: 4.90165636797937

Epoch: 5| Step: 9
Training loss: 4.762926081623437
Validation loss: 4.881051553684329

Epoch: 5| Step: 10
Training loss: 4.173670236031561
Validation loss: 4.858203172787894

Epoch: 18| Step: 0
Training loss: 5.517138913658287
Validation loss: 4.84559303175788

Epoch: 5| Step: 1
Training loss: 4.260643590030681
Validation loss: 4.82133424261554

Epoch: 5| Step: 2
Training loss: 4.259538157326531
Validation loss: 4.801022911032027

Epoch: 5| Step: 3
Training loss: 4.603030011245183
Validation loss: 4.784092863794805

Epoch: 5| Step: 4
Training loss: 5.541571862502136
Validation loss: 4.76134725808369

Epoch: 5| Step: 5
Training loss: 5.35889719620986
Validation loss: 4.737342431107234

Epoch: 5| Step: 6
Training loss: 5.417631659991728
Validation loss: 4.716249827833366

Epoch: 5| Step: 7
Training loss: 4.541154861776649
Validation loss: 4.699665234298236

Epoch: 5| Step: 8
Training loss: 4.588656345742855
Validation loss: 4.667773112668538

Epoch: 5| Step: 9
Training loss: 3.5029938019031484
Validation loss: 4.654932003348288

Epoch: 5| Step: 10
Training loss: 4.481477552353252
Validation loss: 4.635023188531394

Epoch: 19| Step: 0
Training loss: 3.8843346419505025
Validation loss: 4.609438012500426

Epoch: 5| Step: 1
Training loss: 3.442945986733733
Validation loss: 4.585872431596351

Epoch: 5| Step: 2
Training loss: 4.616718817093846
Validation loss: 4.570415127210831

Epoch: 5| Step: 3
Training loss: 4.899122759085931
Validation loss: 4.54325612344778

Epoch: 5| Step: 4
Training loss: 4.674532845559944
Validation loss: 4.520650567438138

Epoch: 5| Step: 5
Training loss: 4.7325911481798295
Validation loss: 4.502674814105556

Epoch: 5| Step: 6
Training loss: 4.951381051424567
Validation loss: 4.483533003502616

Epoch: 5| Step: 7
Training loss: 5.12838558857631
Validation loss: 4.457665777653814

Epoch: 5| Step: 8
Training loss: 3.829666014369427
Validation loss: 4.437658503242294

Epoch: 5| Step: 9
Training loss: 4.987770383002277
Validation loss: 4.416477704702681

Epoch: 5| Step: 10
Training loss: 4.47965239027759
Validation loss: 4.380256883845415

Epoch: 20| Step: 0
Training loss: 4.901485778383261
Validation loss: 4.362021187175981

Epoch: 5| Step: 1
Training loss: 4.007895782973621
Validation loss: 4.352002650547397

Epoch: 5| Step: 2
Training loss: 4.399902533405347
Validation loss: 4.309159875628098

Epoch: 5| Step: 3
Training loss: 4.042955068666465
Validation loss: 4.2874705278913225

Epoch: 5| Step: 4
Training loss: 3.4867076506919883
Validation loss: 4.265743457859678

Epoch: 5| Step: 5
Training loss: 4.255036903517168
Validation loss: 4.234933017281824

Epoch: 5| Step: 6
Training loss: 5.278620499818444
Validation loss: 4.217143740391223

Epoch: 5| Step: 7
Training loss: 4.469786197063674
Validation loss: 4.191346108021413

Epoch: 5| Step: 8
Training loss: 3.9939956899895717
Validation loss: 4.168964518182468

Epoch: 5| Step: 9
Training loss: 4.459582762767022
Validation loss: 4.152933783120585

Epoch: 5| Step: 10
Training loss: 3.6415190683536323
Validation loss: 4.112974162438056

Epoch: 21| Step: 0
Training loss: 5.365056799084001
Validation loss: 4.087410769304444

Epoch: 5| Step: 1
Training loss: 4.327926906638339
Validation loss: 4.064063822071134

Epoch: 5| Step: 2
Training loss: 4.000012874582552
Validation loss: 4.039552452561139

Epoch: 5| Step: 3
Training loss: 3.2283857980645716
Validation loss: 4.012872350589667

Epoch: 5| Step: 4
Training loss: 3.8548802445509383
Validation loss: 3.9979762436344295

Epoch: 5| Step: 5
Training loss: 4.3634220056191095
Validation loss: 3.9562853858001716

Epoch: 5| Step: 6
Training loss: 3.554915401991983
Validation loss: 3.9419529521052876

Epoch: 5| Step: 7
Training loss: 3.83299176449666
Validation loss: 3.920477663585625

Epoch: 5| Step: 8
Training loss: 3.898831578826368
Validation loss: 3.894635868254377

Epoch: 5| Step: 9
Training loss: 4.102525463594755
Validation loss: 3.8713273219791775

Epoch: 5| Step: 10
Training loss: 3.537012849835627
Validation loss: 3.8559533356685436

Epoch: 22| Step: 0
Training loss: 3.684551547336591
Validation loss: 3.8168470109466783

Epoch: 5| Step: 1
Training loss: 4.215788981851672
Validation loss: 3.800455071019563

Epoch: 5| Step: 2
Training loss: 2.694659256210343
Validation loss: 3.761355258435854

Epoch: 5| Step: 3
Training loss: 4.962463432580853
Validation loss: 3.74445768585871

Epoch: 5| Step: 4
Training loss: 2.399315291325319
Validation loss: 3.7169908730259613

Epoch: 5| Step: 5
Training loss: 3.8249239247055824
Validation loss: 3.691606328216458

Epoch: 5| Step: 6
Training loss: 4.172417651827211
Validation loss: 3.6724646463803925

Epoch: 5| Step: 7
Training loss: 4.070184570176485
Validation loss: 3.6428786781503817

Epoch: 5| Step: 8
Training loss: 3.5833434319169033
Validation loss: 3.633216459846808

Epoch: 5| Step: 9
Training loss: 3.739133859185405
Validation loss: 3.5917528806833

Epoch: 5| Step: 10
Training loss: 3.846120336093174
Validation loss: 3.5726484771291127

Epoch: 23| Step: 0
Training loss: 3.40847593598323
Validation loss: 3.5572105247960266

Epoch: 5| Step: 1
Training loss: 4.0269627210484416
Validation loss: 3.534742072850605

Epoch: 5| Step: 2
Training loss: 3.4982552948186973
Validation loss: 3.5132338809552706

Epoch: 5| Step: 3
Training loss: 3.949527475607508
Validation loss: 3.487508159652458

Epoch: 5| Step: 4
Training loss: 3.6742259189958366
Validation loss: 3.4756515358390447

Epoch: 5| Step: 5
Training loss: 3.9547169009426657
Validation loss: 3.4370128133468016

Epoch: 5| Step: 6
Training loss: 3.401530785121444
Validation loss: 3.426371594032391

Epoch: 5| Step: 7
Training loss: 3.6113072627338183
Validation loss: 3.3916443767320588

Epoch: 5| Step: 8
Training loss: 2.7937474159041025
Validation loss: 3.3715493121072906

Epoch: 5| Step: 9
Training loss: 3.6946121423149565
Validation loss: 3.353011489104549

Epoch: 5| Step: 10
Training loss: 2.8664920805471197
Validation loss: 3.340028750137639

Epoch: 24| Step: 0
Training loss: 3.732367578547703
Validation loss: 3.3060877615048336

Epoch: 5| Step: 1
Training loss: 3.2760825020691664
Validation loss: 3.2967841100807496

Epoch: 5| Step: 2
Training loss: 3.019792750238753
Validation loss: 3.266057505470693

Epoch: 5| Step: 3
Training loss: 4.067405673142539
Validation loss: 3.2478846298818693

Epoch: 5| Step: 4
Training loss: 3.8442246058775718
Validation loss: 3.2243410552883742

Epoch: 5| Step: 5
Training loss: 2.904702707859261
Validation loss: 3.2048946603385633

Epoch: 5| Step: 6
Training loss: 2.8516629972124004
Validation loss: 3.18506527961086

Epoch: 5| Step: 7
Training loss: 2.556646779798264
Validation loss: 3.170454199171749

Epoch: 5| Step: 8
Training loss: 3.2899557246327715
Validation loss: 3.1585445845644102

Epoch: 5| Step: 9
Training loss: 3.718684348159978
Validation loss: 3.1340465286310892

Epoch: 5| Step: 10
Training loss: 3.5034631217146903
Validation loss: 3.130657399227231

Epoch: 25| Step: 0
Training loss: 3.333504068452542
Validation loss: 3.1059301855823507

Epoch: 5| Step: 1
Training loss: 3.5790229570154004
Validation loss: 3.0827389360069977

Epoch: 5| Step: 2
Training loss: 2.7998941844291623
Validation loss: 3.079374909203392

Epoch: 5| Step: 3
Training loss: 3.5984845362515596
Validation loss: 3.050257805079471

Epoch: 5| Step: 4
Training loss: 3.266956112812352
Validation loss: 3.040857919464278

Epoch: 5| Step: 5
Training loss: 3.932360367669558
Validation loss: 3.031211222705162

Epoch: 5| Step: 6
Training loss: 2.9317195101499474
Validation loss: 3.0183207607636526

Epoch: 5| Step: 7
Training loss: 3.344473787209294
Validation loss: 2.988346053199698

Epoch: 5| Step: 8
Training loss: 2.52749864436716
Validation loss: 2.9801147579294316

Epoch: 5| Step: 9
Training loss: 3.0004543913998436
Validation loss: 2.966924271547333

Epoch: 5| Step: 10
Training loss: 2.7177626472173957
Validation loss: 2.95489918479932

Epoch: 26| Step: 0
Training loss: 2.958050853155421
Validation loss: 2.9496314844568987

Epoch: 5| Step: 1
Training loss: 3.888439499154696
Validation loss: 2.927540461655193

Epoch: 5| Step: 2
Training loss: 3.434769256704409
Validation loss: 2.9298246355672966

Epoch: 5| Step: 3
Training loss: 3.065371821192438
Validation loss: 2.9226727938798702

Epoch: 5| Step: 4
Training loss: 3.3363064063896912
Validation loss: 2.9154702458965756

Epoch: 5| Step: 5
Training loss: 3.1254757328314926
Validation loss: 2.879773328272139

Epoch: 5| Step: 6
Training loss: 2.615330187956181
Validation loss: 2.8815865989130978

Epoch: 5| Step: 7
Training loss: 3.244131071018066
Validation loss: 2.8576091745092547

Epoch: 5| Step: 8
Training loss: 2.962257916180679
Validation loss: 2.849866151284238

Epoch: 5| Step: 9
Training loss: 2.2446437235242125
Validation loss: 2.8356565542354346

Epoch: 5| Step: 10
Training loss: 3.1241933162919793
Validation loss: 2.8353562766952893

Epoch: 27| Step: 0
Training loss: 2.7983110885993145
Validation loss: 2.8313069622406513

Epoch: 5| Step: 1
Training loss: 2.6705706351630205
Validation loss: 2.829196810002602

Epoch: 5| Step: 2
Training loss: 3.1150699775391595
Validation loss: 2.825746229192555

Epoch: 5| Step: 3
Training loss: 2.748908780080047
Validation loss: 2.8076922608227974

Epoch: 5| Step: 4
Training loss: 2.1793173198763163
Validation loss: 2.8176355106683966

Epoch: 5| Step: 5
Training loss: 3.722107725770603
Validation loss: 2.795401265514017

Epoch: 5| Step: 6
Training loss: 3.822550299583601
Validation loss: 2.7957091475844917

Epoch: 5| Step: 7
Training loss: 2.430361540786289
Validation loss: 2.794523177835227

Epoch: 5| Step: 8
Training loss: 3.3458378058214016
Validation loss: 2.7905193579912653

Epoch: 5| Step: 9
Training loss: 3.160118678073543
Validation loss: 2.7872774542702468

Epoch: 5| Step: 10
Training loss: 3.2584194285798116
Validation loss: 2.79046454250178

Epoch: 28| Step: 0
Training loss: 3.1054417255113442
Validation loss: 2.779800147749571

Epoch: 5| Step: 1
Training loss: 3.137906392439067
Validation loss: 2.7787427543467547

Epoch: 5| Step: 2
Training loss: 3.1499038197199494
Validation loss: 2.749427722813226

Epoch: 5| Step: 3
Training loss: 3.0176625064051605
Validation loss: 2.772683125628256

Epoch: 5| Step: 4
Training loss: 2.120273944501381
Validation loss: 2.7546519481014884

Epoch: 5| Step: 5
Training loss: 3.387672932282301
Validation loss: 2.7623019547104426

Epoch: 5| Step: 6
Training loss: 3.5673241327212626
Validation loss: 2.7663588317643177

Epoch: 5| Step: 7
Training loss: 3.1227839432587094
Validation loss: 2.746185608805706

Epoch: 5| Step: 8
Training loss: 2.207696810942438
Validation loss: 2.746774989021725

Epoch: 5| Step: 9
Training loss: 2.657666625202746
Validation loss: 2.7619475311565687

Epoch: 5| Step: 10
Training loss: 3.4187087647568193
Validation loss: 2.73532562373015

Epoch: 29| Step: 0
Training loss: 2.808701981327989
Validation loss: 2.76107635199962

Epoch: 5| Step: 1
Training loss: 2.577134930631998
Validation loss: 2.741726388987401

Epoch: 5| Step: 2
Training loss: 2.941610341888167
Validation loss: 2.7424330095307052

Epoch: 5| Step: 3
Training loss: 2.8204436971735105
Validation loss: 2.7495623936759497

Epoch: 5| Step: 4
Training loss: 2.2111342918782593
Validation loss: 2.736272930332751

Epoch: 5| Step: 5
Training loss: 3.3698620717605685
Validation loss: 2.738219718890701

Epoch: 5| Step: 6
Training loss: 3.0018238245779365
Validation loss: 2.7418716660600313

Epoch: 5| Step: 7
Training loss: 3.141571964958107
Validation loss: 2.7375838120754827

Epoch: 5| Step: 8
Training loss: 3.6447893809729024
Validation loss: 2.734862189656085

Epoch: 5| Step: 9
Training loss: 3.096561580006833
Validation loss: 2.7118568602703843

Epoch: 5| Step: 10
Training loss: 3.274495320345764
Validation loss: 2.724574131656286

Epoch: 30| Step: 0
Training loss: 2.9261313052020075
Validation loss: 2.7321895893603023

Epoch: 5| Step: 1
Training loss: 2.899319661017932
Validation loss: 2.7266536610081524

Epoch: 5| Step: 2
Training loss: 2.6290983268775125
Validation loss: 2.7204478526550977

Epoch: 5| Step: 3
Training loss: 4.105511491808907
Validation loss: 2.7188775269921184

Epoch: 5| Step: 4
Training loss: 3.599290110214145
Validation loss: 2.730676748147591

Epoch: 5| Step: 5
Training loss: 2.2609731337896855
Validation loss: 2.7264038551277845

Epoch: 5| Step: 6
Training loss: 2.6275048793235647
Validation loss: 2.7230110689943223

Epoch: 5| Step: 7
Training loss: 2.6735582013420123
Validation loss: 2.705492984407022

Epoch: 5| Step: 8
Training loss: 2.8381873420029313
Validation loss: 2.734357058792907

Epoch: 5| Step: 9
Training loss: 3.145294968640986
Validation loss: 2.715338513202694

Epoch: 5| Step: 10
Training loss: 2.862192902062711
Validation loss: 2.7141426716282986

Epoch: 31| Step: 0
Training loss: 3.3116043607408234
Validation loss: 2.715663959940177

Epoch: 5| Step: 1
Training loss: 3.0072973825849427
Validation loss: 2.7186532678157724

Epoch: 5| Step: 2
Training loss: 2.687054530639202
Validation loss: 2.7059085372006666

Epoch: 5| Step: 3
Training loss: 3.012981620056427
Validation loss: 2.7197595649505355

Epoch: 5| Step: 4
Training loss: 2.3629758527170104
Validation loss: 2.710437330037452

Epoch: 5| Step: 5
Training loss: 3.3060722606167325
Validation loss: 2.708723283118786

Epoch: 5| Step: 6
Training loss: 2.6440794430627093
Validation loss: 2.7157781697779617

Epoch: 5| Step: 7
Training loss: 3.7134167550770822
Validation loss: 2.7033580314686754

Epoch: 5| Step: 8
Training loss: 2.8278334662302753
Validation loss: 2.7171878534692637

Epoch: 5| Step: 9
Training loss: 3.1671844527573834
Validation loss: 2.724346062629574

Epoch: 5| Step: 10
Training loss: 2.7860675193069984
Validation loss: 2.7302930759170816

Epoch: 32| Step: 0
Training loss: 3.1059809424312466
Validation loss: 2.7210794873788426

Epoch: 5| Step: 1
Training loss: 2.3180911544505314
Validation loss: 2.7106786116502843

Epoch: 5| Step: 2
Training loss: 3.1601770728029983
Validation loss: 2.7116112484870207

Epoch: 5| Step: 3
Training loss: 2.231025586209356
Validation loss: 2.7109113219554244

Epoch: 5| Step: 4
Training loss: 3.1957828390085523
Validation loss: 2.7005892374596696

Epoch: 5| Step: 5
Training loss: 3.2656019292135112
Validation loss: 2.7308437345714487

Epoch: 5| Step: 6
Training loss: 2.47443527175253
Validation loss: 2.7067298900759735

Epoch: 5| Step: 7
Training loss: 3.0149102030930943
Validation loss: 2.7131995220280243

Epoch: 5| Step: 8
Training loss: 3.05779496598711
Validation loss: 2.7065326323976207

Epoch: 5| Step: 9
Training loss: 3.6070368075395107
Validation loss: 2.7077775698920488

Epoch: 5| Step: 10
Training loss: 3.2676986608259746
Validation loss: 2.725000156396186

Epoch: 33| Step: 0
Training loss: 3.443521254570134
Validation loss: 2.70889242726121

Epoch: 5| Step: 1
Training loss: 3.1420301643637942
Validation loss: 2.707598838568195

Epoch: 5| Step: 2
Training loss: 2.2791149651929916
Validation loss: 2.7141433734280844

Epoch: 5| Step: 3
Training loss: 2.709628094002274
Validation loss: 2.7225488043105472

Epoch: 5| Step: 4
Training loss: 3.1311714269103357
Validation loss: 2.703036810746153

Epoch: 5| Step: 5
Training loss: 2.912278352743333
Validation loss: 2.693536777402545

Epoch: 5| Step: 6
Training loss: 3.256987908748194
Validation loss: 2.6923615920702413

Epoch: 5| Step: 7
Training loss: 3.1679294644893816
Validation loss: 2.7073036845990464

Epoch: 5| Step: 8
Training loss: 2.694011694992497
Validation loss: 2.7173783837305954

Epoch: 5| Step: 9
Training loss: 3.198382332330237
Validation loss: 2.712749797807259

Epoch: 5| Step: 10
Training loss: 2.5821766776308572
Validation loss: 2.7063578125326258

Epoch: 34| Step: 0
Training loss: 3.3423297753709975
Validation loss: 2.72262781084522

Epoch: 5| Step: 1
Training loss: 2.934085240951918
Validation loss: 2.7068461143967126

Epoch: 5| Step: 2
Training loss: 2.976957520232781
Validation loss: 2.717839950218038

Epoch: 5| Step: 3
Training loss: 3.7396726181436732
Validation loss: 2.711031590213982

Epoch: 5| Step: 4
Training loss: 2.8412274920893257
Validation loss: 2.706111040393547

Epoch: 5| Step: 5
Training loss: 2.459177895855018
Validation loss: 2.7077863312808437

Epoch: 5| Step: 6
Training loss: 2.843112412963832
Validation loss: 2.7011735207121994

Epoch: 5| Step: 7
Training loss: 3.118984689081153
Validation loss: 2.720074853334615

Epoch: 5| Step: 8
Training loss: 2.7763331810703145
Validation loss: 2.7179824939535178

Epoch: 5| Step: 9
Training loss: 2.6245649068011647
Validation loss: 2.7046386541830425

Epoch: 5| Step: 10
Training loss: 3.0145865910707355
Validation loss: 2.710173203583173

Epoch: 35| Step: 0
Training loss: 3.034470096437649
Validation loss: 2.6927677734374837

Epoch: 5| Step: 1
Training loss: 3.276867655750043
Validation loss: 2.7212697800234196

Epoch: 5| Step: 2
Training loss: 3.0681943308770987
Validation loss: 2.700879765131711

Epoch: 5| Step: 3
Training loss: 3.546137392759225
Validation loss: 2.723711711351244

Epoch: 5| Step: 4
Training loss: 2.957856439827317
Validation loss: 2.7025465608664367

Epoch: 5| Step: 5
Training loss: 2.450405289739715
Validation loss: 2.717669296608446

Epoch: 5| Step: 6
Training loss: 2.9392251975066004
Validation loss: 2.7109136104875753

Epoch: 5| Step: 7
Training loss: 2.883562522849323
Validation loss: 2.7048390668272377

Epoch: 5| Step: 8
Training loss: 2.8809492504518714
Validation loss: 2.6990893728452106

Epoch: 5| Step: 9
Training loss: 2.6545617516671762
Validation loss: 2.6990907063877745

Epoch: 5| Step: 10
Training loss: 2.7866450927513755
Validation loss: 2.696761350758877

Epoch: 36| Step: 0
Training loss: 3.575875587210769
Validation loss: 2.71007293289416

Epoch: 5| Step: 1
Training loss: 2.611149167624465
Validation loss: 2.699113633908631

Epoch: 5| Step: 2
Training loss: 2.875056722330224
Validation loss: 2.700373166759845

Epoch: 5| Step: 3
Training loss: 3.202868195450634
Validation loss: 2.6979444800643457

Epoch: 5| Step: 4
Training loss: 2.6221486909258633
Validation loss: 2.7093688856149725

Epoch: 5| Step: 5
Training loss: 2.90968480739852
Validation loss: 2.700235068549202

Epoch: 5| Step: 6
Training loss: 2.8943088461495283
Validation loss: 2.7152360907814734

Epoch: 5| Step: 7
Training loss: 2.724911777573109
Validation loss: 2.7053256215310006

Epoch: 5| Step: 8
Training loss: 2.9854060284428794
Validation loss: 2.6884462751567284

Epoch: 5| Step: 9
Training loss: 3.486309797308268
Validation loss: 2.6853686268588723

Epoch: 5| Step: 10
Training loss: 2.6061875296957058
Validation loss: 2.7035276487813644

Epoch: 37| Step: 0
Training loss: 2.8113077815704397
Validation loss: 2.692135496412575

Epoch: 5| Step: 1
Training loss: 2.770724062569584
Validation loss: 2.700284669272045

Epoch: 5| Step: 2
Training loss: 2.404768053952511
Validation loss: 2.7183321908890674

Epoch: 5| Step: 3
Training loss: 3.4829829561493906
Validation loss: 2.701217835929033

Epoch: 5| Step: 4
Training loss: 2.848248622907682
Validation loss: 2.6971075932400987

Epoch: 5| Step: 5
Training loss: 3.213013657646228
Validation loss: 2.728987259468244

Epoch: 5| Step: 6
Training loss: 3.370459716863996
Validation loss: 2.7008329479632387

Epoch: 5| Step: 7
Training loss: 3.5343979838979003
Validation loss: 2.699899062416179

Epoch: 5| Step: 8
Training loss: 2.91520558046169
Validation loss: 2.7187738866608893

Epoch: 5| Step: 9
Training loss: 2.2261630586743086
Validation loss: 2.690671575138699

Epoch: 5| Step: 10
Training loss: 2.6444651653197475
Validation loss: 2.6993507763859825

Epoch: 38| Step: 0
Training loss: 2.905729842039172
Validation loss: 2.691954326608544

Epoch: 5| Step: 1
Training loss: 2.486780980919753
Validation loss: 2.7015961166690476

Epoch: 5| Step: 2
Training loss: 3.153571323529933
Validation loss: 2.7081802795049286

Epoch: 5| Step: 3
Training loss: 2.5040246039878897
Validation loss: 2.688194951995528

Epoch: 5| Step: 4
Training loss: 2.766917643213063
Validation loss: 2.7059100123382502

Epoch: 5| Step: 5
Training loss: 2.9671597688894695
Validation loss: 2.708476382911651

Epoch: 5| Step: 6
Training loss: 2.562350943347253
Validation loss: 2.697724039987728

Epoch: 5| Step: 7
Training loss: 2.965969188723071
Validation loss: 2.7058982813246497

Epoch: 5| Step: 8
Training loss: 3.7874136886582175
Validation loss: 2.6812483602638735

Epoch: 5| Step: 9
Training loss: 3.0801496479290895
Validation loss: 2.6863729942702377

Epoch: 5| Step: 10
Training loss: 3.0878960297529394
Validation loss: 2.692827195727805

Epoch: 39| Step: 0
Training loss: 2.4924936136452787
Validation loss: 2.6925049557404446

Epoch: 5| Step: 1
Training loss: 2.8631536811835994
Validation loss: 2.69779930630755

Epoch: 5| Step: 2
Training loss: 3.277615377925359
Validation loss: 2.7119491366731516

Epoch: 5| Step: 3
Training loss: 2.9040256314578325
Validation loss: 2.688473744710121

Epoch: 5| Step: 4
Training loss: 3.0502294610429965
Validation loss: 2.7133319801983684

Epoch: 5| Step: 5
Training loss: 2.3713207858896452
Validation loss: 2.720254728010755

Epoch: 5| Step: 6
Training loss: 3.270626345035882
Validation loss: 2.7035431792997033

Epoch: 5| Step: 7
Training loss: 2.870818538839886
Validation loss: 2.6886317223301957

Epoch: 5| Step: 8
Training loss: 2.910999314229787
Validation loss: 2.6790844614767155

Epoch: 5| Step: 9
Training loss: 2.453502844607296
Validation loss: 2.710371375796594

Epoch: 5| Step: 10
Training loss: 3.7792467848344002
Validation loss: 2.6817719193823013

Epoch: 40| Step: 0
Training loss: 3.2149346710734292
Validation loss: 2.689591428906681

Epoch: 5| Step: 1
Training loss: 2.5717652456195648
Validation loss: 2.69332651927045

Epoch: 5| Step: 2
Training loss: 2.858646821235455
Validation loss: 2.6924693550048313

Epoch: 5| Step: 3
Training loss: 3.595997513919773
Validation loss: 2.698316664094312

Epoch: 5| Step: 4
Training loss: 2.6983456559004892
Validation loss: 2.6935749328353498

Epoch: 5| Step: 5
Training loss: 3.399720118727592
Validation loss: 2.6912407164455487

Epoch: 5| Step: 6
Training loss: 2.5583979640919194
Validation loss: 2.6889813712459847

Epoch: 5| Step: 7
Training loss: 2.312857625990369
Validation loss: 2.6948166904673143

Epoch: 5| Step: 8
Training loss: 3.5335985324109522
Validation loss: 2.6975953286125707

Epoch: 5| Step: 9
Training loss: 2.4488908709460153
Validation loss: 2.6920205206522936

Epoch: 5| Step: 10
Training loss: 2.8651012345514975
Validation loss: 2.6774974770953115

Epoch: 41| Step: 0
Training loss: 2.7686911789822233
Validation loss: 2.6917397037879334

Epoch: 5| Step: 1
Training loss: 2.915813502916307
Validation loss: 2.67472072681105

Epoch: 5| Step: 2
Training loss: 3.501732806005238
Validation loss: 2.6857006844395186

Epoch: 5| Step: 3
Training loss: 3.080892799827797
Validation loss: 2.6793668745216648

Epoch: 5| Step: 4
Training loss: 2.9200080986433203
Validation loss: 2.6868752389863024

Epoch: 5| Step: 5
Training loss: 2.755630710774987
Validation loss: 2.6779859982647825

Epoch: 5| Step: 6
Training loss: 2.9175660699392805
Validation loss: 2.681171935148084

Epoch: 5| Step: 7
Training loss: 3.287033361234883
Validation loss: 2.677537711866133

Epoch: 5| Step: 8
Training loss: 2.522735309041288
Validation loss: 2.7038648660827174

Epoch: 5| Step: 9
Training loss: 2.2962107833312726
Validation loss: 2.682672739761221

Epoch: 5| Step: 10
Training loss: 3.2532946686192905
Validation loss: 2.6962474883036154

Epoch: 42| Step: 0
Training loss: 2.6365644847812213
Validation loss: 2.6774987926675564

Epoch: 5| Step: 1
Training loss: 2.092356887353392
Validation loss: 2.696674393656324

Epoch: 5| Step: 2
Training loss: 2.7845128668530457
Validation loss: 2.6955176614367367

Epoch: 5| Step: 3
Training loss: 3.3473007031144233
Validation loss: 2.670726586649706

Epoch: 5| Step: 4
Training loss: 2.8394289828859147
Validation loss: 2.6895064085196068

Epoch: 5| Step: 5
Training loss: 2.875791026220309
Validation loss: 2.681711440505451

Epoch: 5| Step: 6
Training loss: 2.730787965290779
Validation loss: 2.6848222117659764

Epoch: 5| Step: 7
Training loss: 3.162434476995383
Validation loss: 2.6849035678284765

Epoch: 5| Step: 8
Training loss: 3.303911699717662
Validation loss: 2.675599588913726

Epoch: 5| Step: 9
Training loss: 3.0755945638830093
Validation loss: 2.7009186891219605

Epoch: 5| Step: 10
Training loss: 3.1632900472505945
Validation loss: 2.6982151774928576

Epoch: 43| Step: 0
Training loss: 2.68055404131577
Validation loss: 2.702260711146107

Epoch: 5| Step: 1
Training loss: 3.640388972281236
Validation loss: 2.697951402407711

Epoch: 5| Step: 2
Training loss: 2.994170565122648
Validation loss: 2.6714926787171005

Epoch: 5| Step: 3
Training loss: 2.3116781475476036
Validation loss: 2.6926498789155033

Epoch: 5| Step: 4
Training loss: 3.121579243470619
Validation loss: 2.705912366682696

Epoch: 5| Step: 5
Training loss: 2.8409775854003265
Validation loss: 2.6959341479927885

Epoch: 5| Step: 6
Training loss: 2.4961523010359445
Validation loss: 2.6849939576978876

Epoch: 5| Step: 7
Training loss: 2.996375914893198
Validation loss: 2.691277004046051

Epoch: 5| Step: 8
Training loss: 3.42016698284627
Validation loss: 2.6806119775130495

Epoch: 5| Step: 9
Training loss: 2.7258350527726942
Validation loss: 2.684273052346115

Epoch: 5| Step: 10
Training loss: 2.850938033614338
Validation loss: 2.69014883036567

Epoch: 44| Step: 0
Training loss: 3.2322657982523277
Validation loss: 2.6923837170735188

Epoch: 5| Step: 1
Training loss: 2.6374526973297274
Validation loss: 2.6851279972539928

Epoch: 5| Step: 2
Training loss: 2.7039718624377778
Validation loss: 2.6763401435541834

Epoch: 5| Step: 3
Training loss: 3.024171725286684
Validation loss: 2.6860670107402425

Epoch: 5| Step: 4
Training loss: 3.239927234774463
Validation loss: 2.674212346054873

Epoch: 5| Step: 5
Training loss: 3.2479078454629264
Validation loss: 2.6771859770627517

Epoch: 5| Step: 6
Training loss: 2.6530059751809274
Validation loss: 2.6878263089876926

Epoch: 5| Step: 7
Training loss: 2.5695005485205984
Validation loss: 2.6785513745957212

Epoch: 5| Step: 8
Training loss: 2.3254024280394012
Validation loss: 2.675799384675813

Epoch: 5| Step: 9
Training loss: 3.073125972192939
Validation loss: 2.6751353922205565

Epoch: 5| Step: 10
Training loss: 3.2772619807849117
Validation loss: 2.67995941113313

Epoch: 45| Step: 0
Training loss: 2.75265331579315
Validation loss: 2.697754878868633

Epoch: 5| Step: 1
Training loss: 2.371362309588862
Validation loss: 2.6591383863354965

Epoch: 5| Step: 2
Training loss: 3.162633200995349
Validation loss: 2.6683874045452343

Epoch: 5| Step: 3
Training loss: 3.2629504773388636
Validation loss: 2.68597047688628

Epoch: 5| Step: 4
Training loss: 3.0927974891510317
Validation loss: 2.6848988977250867

Epoch: 5| Step: 5
Training loss: 3.401475832899137
Validation loss: 2.6693317182886833

Epoch: 5| Step: 6
Training loss: 2.490456006528299
Validation loss: 2.680257723595739

Epoch: 5| Step: 7
Training loss: 2.870349273695264
Validation loss: 2.683382511191445

Epoch: 5| Step: 8
Training loss: 2.563512648555532
Validation loss: 2.669046400205745

Epoch: 5| Step: 9
Training loss: 2.8908529655674764
Validation loss: 2.664967486510976

Epoch: 5| Step: 10
Training loss: 3.0575566780782077
Validation loss: 2.6655735865081125

Epoch: 46| Step: 0
Training loss: 3.3364547578616026
Validation loss: 2.685613816904559

Epoch: 5| Step: 1
Training loss: 2.2865233415704793
Validation loss: 2.6815861173159146

Epoch: 5| Step: 2
Training loss: 3.5412639314139795
Validation loss: 2.66256426253627

Epoch: 5| Step: 3
Training loss: 2.993284019568099
Validation loss: 2.680622530012006

Epoch: 5| Step: 4
Training loss: 3.362501384068314
Validation loss: 2.6788826752138237

Epoch: 5| Step: 5
Training loss: 3.0826259179551494
Validation loss: 2.672083044141158

Epoch: 5| Step: 6
Training loss: 2.79257263362343
Validation loss: 2.6720404677747145

Epoch: 5| Step: 7
Training loss: 2.3033348122503203
Validation loss: 2.669311764831214

Epoch: 5| Step: 8
Training loss: 2.614308701234719
Validation loss: 2.6779744742417324

Epoch: 5| Step: 9
Training loss: 3.005391997350638
Validation loss: 2.6751364674574303

Epoch: 5| Step: 10
Training loss: 2.418251230628202
Validation loss: 2.679745145926477

Epoch: 47| Step: 0
Training loss: 2.398430143960116
Validation loss: 2.6866895679960527

Epoch: 5| Step: 1
Training loss: 2.740312592850835
Validation loss: 2.6781606829021887

Epoch: 5| Step: 2
Training loss: 3.194932089548028
Validation loss: 2.672560838345885

Epoch: 5| Step: 3
Training loss: 2.7370866681204107
Validation loss: 2.667937499555615

Epoch: 5| Step: 4
Training loss: 2.9004683872677446
Validation loss: 2.658628723055865

Epoch: 5| Step: 5
Training loss: 2.951183993139829
Validation loss: 2.664032883937031

Epoch: 5| Step: 6
Training loss: 3.3539107483718813
Validation loss: 2.6705039516781865

Epoch: 5| Step: 7
Training loss: 3.1300679120871076
Validation loss: 2.6648069568542065

Epoch: 5| Step: 8
Training loss: 3.071073093310872
Validation loss: 2.669409425480515

Epoch: 5| Step: 9
Training loss: 2.1496748256961307
Validation loss: 2.665683169533833

Epoch: 5| Step: 10
Training loss: 3.27409469089119
Validation loss: 2.6756633792763393

Epoch: 48| Step: 0
Training loss: 2.823326296957076
Validation loss: 2.6661955035212523

Epoch: 5| Step: 1
Training loss: 3.205547774900635
Validation loss: 2.6621653629083046

Epoch: 5| Step: 2
Training loss: 2.6158934169486816
Validation loss: 2.663713048742347

Epoch: 5| Step: 3
Training loss: 2.905860300495971
Validation loss: 2.6681384119428935

Epoch: 5| Step: 4
Training loss: 2.9866187164453843
Validation loss: 2.667575047604757

Epoch: 5| Step: 5
Training loss: 3.39857991238067
Validation loss: 2.6732079861005946

Epoch: 5| Step: 6
Training loss: 2.99341990138264
Validation loss: 2.6732635670267566

Epoch: 5| Step: 7
Training loss: 2.358335758742668
Validation loss: 2.659863961382108

Epoch: 5| Step: 8
Training loss: 3.291152978402264
Validation loss: 2.659285506755773

Epoch: 5| Step: 9
Training loss: 2.1877542620436343
Validation loss: 2.648767656249454

Epoch: 5| Step: 10
Training loss: 2.8865727244443122
Validation loss: 2.6549250744523887

Epoch: 49| Step: 0
Training loss: 2.6467570597236576
Validation loss: 2.653657723205285

Epoch: 5| Step: 1
Training loss: 2.2464015583924106
Validation loss: 2.6882241187640274

Epoch: 5| Step: 2
Training loss: 3.2066620441120586
Validation loss: 2.666643971941369

Epoch: 5| Step: 3
Training loss: 2.8809280645942374
Validation loss: 2.6749050477358973

Epoch: 5| Step: 4
Training loss: 2.199340600115722
Validation loss: 2.671200588285512

Epoch: 5| Step: 5
Training loss: 3.536872371356457
Validation loss: 2.6605883162169714

Epoch: 5| Step: 6
Training loss: 2.8268144637581374
Validation loss: 2.6600178169713478

Epoch: 5| Step: 7
Training loss: 2.9629315025813976
Validation loss: 2.6787512545326475

Epoch: 5| Step: 8
Training loss: 3.454472343684171
Validation loss: 2.6619140297166997

Epoch: 5| Step: 9
Training loss: 2.902765461613163
Validation loss: 2.6391182246255167

Epoch: 5| Step: 10
Training loss: 2.7066149811280686
Validation loss: 2.6607079594478837

Epoch: 50| Step: 0
Training loss: 3.5479542438863874
Validation loss: 2.6585557748953677

Epoch: 5| Step: 1
Training loss: 3.2558338917156595
Validation loss: 2.664374410016055

Epoch: 5| Step: 2
Training loss: 3.2046116798095183
Validation loss: 2.672923706169208

Epoch: 5| Step: 3
Training loss: 2.5786359800796292
Validation loss: 2.671171288901291

Epoch: 5| Step: 4
Training loss: 3.297624692605459
Validation loss: 2.6492705181402614

Epoch: 5| Step: 5
Training loss: 1.9897082890388658
Validation loss: 2.6675348739973073

Epoch: 5| Step: 6
Training loss: 2.4764803803604627
Validation loss: 2.6535702873485874

Epoch: 5| Step: 7
Training loss: 2.83716550359467
Validation loss: 2.6561467613314527

Epoch: 5| Step: 8
Training loss: 3.3038382374602118
Validation loss: 2.645109672274724

Epoch: 5| Step: 9
Training loss: 2.4334566864554494
Validation loss: 2.6794955143181114

Epoch: 5| Step: 10
Training loss: 2.209651289826482
Validation loss: 2.6793944524672115

Testing loss: 2.591282744760228
