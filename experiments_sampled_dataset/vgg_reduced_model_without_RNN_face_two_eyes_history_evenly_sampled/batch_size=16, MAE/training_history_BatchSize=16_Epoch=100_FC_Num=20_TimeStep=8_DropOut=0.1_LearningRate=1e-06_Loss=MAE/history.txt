Epoch: 1| Step: 0
Training loss: 3.4591150283813477
Validation loss: 3.807336832887383

Epoch: 6| Step: 1
Training loss: 4.195130348205566
Validation loss: 3.798656366204703

Epoch: 6| Step: 2
Training loss: 3.889103889465332
Validation loss: 3.793720435070735

Epoch: 6| Step: 3
Training loss: 3.9375200271606445
Validation loss: 3.786897813120196

Epoch: 6| Step: 4
Training loss: 4.563161373138428
Validation loss: 3.779422426736483

Epoch: 6| Step: 5
Training loss: 2.652604341506958
Validation loss: 3.772724959158128

Epoch: 6| Step: 6
Training loss: 2.684471368789673
Validation loss: 3.7701018164234776

Epoch: 6| Step: 7
Training loss: 4.057826995849609
Validation loss: 3.762116503971879

Epoch: 6| Step: 8
Training loss: 3.9700355529785156
Validation loss: 3.7569368039408038

Epoch: 6| Step: 9
Training loss: 3.3880343437194824
Validation loss: 3.751158527148667

Epoch: 6| Step: 10
Training loss: 4.060802459716797
Validation loss: 3.742602256036574

Epoch: 6| Step: 11
Training loss: 3.4686241149902344
Validation loss: 3.741689917861774

Epoch: 6| Step: 12
Training loss: 3.1024792194366455
Validation loss: 3.7327002581729682

Epoch: 6| Step: 13
Training loss: 3.9172749519348145
Validation loss: 3.7278012973006054

Epoch: 2| Step: 0
Training loss: 3.116321563720703
Validation loss: 3.722687262360768

Epoch: 6| Step: 1
Training loss: 3.407991886138916
Validation loss: 3.7182466932522353

Epoch: 6| Step: 2
Training loss: 3.7161855697631836
Validation loss: 3.7124454898218953

Epoch: 6| Step: 3
Training loss: 3.0665102005004883
Validation loss: 3.708778868439377

Epoch: 6| Step: 4
Training loss: 4.161953926086426
Validation loss: 3.700287054943782

Epoch: 6| Step: 5
Training loss: 4.074131011962891
Validation loss: 3.695742132843182

Epoch: 6| Step: 6
Training loss: 3.058933973312378
Validation loss: 3.693467611907631

Epoch: 6| Step: 7
Training loss: 4.014299392700195
Validation loss: 3.6829270496163318

Epoch: 6| Step: 8
Training loss: 3.7148165702819824
Validation loss: 3.6784777000386226

Epoch: 6| Step: 9
Training loss: 3.2736639976501465
Validation loss: 3.672041500768354

Epoch: 6| Step: 10
Training loss: 3.974181890487671
Validation loss: 3.6677895156286096

Epoch: 6| Step: 11
Training loss: 3.324842929840088
Validation loss: 3.6626382514994633

Epoch: 6| Step: 12
Training loss: 3.26010799407959
Validation loss: 3.6577102984151533

Epoch: 6| Step: 13
Training loss: 4.522942543029785
Validation loss: 3.649550591745684

Epoch: 3| Step: 0
Training loss: 2.904085636138916
Validation loss: 3.6445904880441646

Epoch: 6| Step: 1
Training loss: 3.125448703765869
Validation loss: 3.6401855689223095

Epoch: 6| Step: 2
Training loss: 3.128268241882324
Validation loss: 3.6362265361252653

Epoch: 6| Step: 3
Training loss: 3.549661636352539
Validation loss: 3.6314281827660015

Epoch: 6| Step: 4
Training loss: 4.682961463928223
Validation loss: 3.6236478385104927

Epoch: 6| Step: 5
Training loss: 2.60186767578125
Validation loss: 3.6174289641841764

Epoch: 6| Step: 6
Training loss: 3.567713737487793
Validation loss: 3.6098538726888676

Epoch: 6| Step: 7
Training loss: 2.684605121612549
Validation loss: 3.6061728154459307

Epoch: 6| Step: 8
Training loss: 2.9628498554229736
Validation loss: 3.6013812121524604

Epoch: 6| Step: 9
Training loss: 3.6639866828918457
Validation loss: 3.5950289541675198

Epoch: 6| Step: 10
Training loss: 3.5535776615142822
Validation loss: 3.5849862534512758

Epoch: 6| Step: 11
Training loss: 4.262067794799805
Validation loss: 3.5794700858413533

Epoch: 6| Step: 12
Training loss: 4.2243242263793945
Validation loss: 3.5758156468791347

Epoch: 6| Step: 13
Training loss: 5.041025638580322
Validation loss: 3.5683976860456568

Epoch: 4| Step: 0
Training loss: 2.4594216346740723
Validation loss: 3.5635090181904454

Epoch: 6| Step: 1
Training loss: 3.9277005195617676
Validation loss: 3.562164496350032

Epoch: 6| Step: 2
Training loss: 3.087759256362915
Validation loss: 3.5483120179945424

Epoch: 6| Step: 3
Training loss: 4.07271146774292
Validation loss: 3.5422035699249594

Epoch: 6| Step: 4
Training loss: 2.961721658706665
Validation loss: 3.53788491987413

Epoch: 6| Step: 5
Training loss: 2.8758726119995117
Validation loss: 3.5308567272719515

Epoch: 6| Step: 6
Training loss: 3.9048869609832764
Validation loss: 3.5250881410414174

Epoch: 6| Step: 7
Training loss: 2.6630730628967285
Validation loss: 3.5166774847174205

Epoch: 6| Step: 8
Training loss: 3.3140101432800293
Validation loss: 3.5130404144205074

Epoch: 6| Step: 9
Training loss: 3.827451467514038
Validation loss: 3.5037009690397527

Epoch: 6| Step: 10
Training loss: 4.569903373718262
Validation loss: 3.500652313232422

Epoch: 6| Step: 11
Training loss: 3.0930213928222656
Validation loss: 3.4925532571731077

Epoch: 6| Step: 12
Training loss: 3.4545340538024902
Validation loss: 3.4836742929233018

Epoch: 6| Step: 13
Training loss: 4.487813949584961
Validation loss: 3.4782522519429526

Epoch: 5| Step: 0
Training loss: 4.03856897354126
Validation loss: 3.471136982722949

Epoch: 6| Step: 1
Training loss: 4.18021297454834
Validation loss: 3.461997288529591

Epoch: 6| Step: 2
Training loss: 2.423348903656006
Validation loss: 3.458127103826051

Epoch: 6| Step: 3
Training loss: 2.504732847213745
Validation loss: 3.4537503488602175

Epoch: 6| Step: 4
Training loss: 3.1920080184936523
Validation loss: 3.446557047546551

Epoch: 6| Step: 5
Training loss: 3.406777858734131
Validation loss: 3.4423892369834324

Epoch: 6| Step: 6
Training loss: 3.4912071228027344
Validation loss: 3.4300788602521344

Epoch: 6| Step: 7
Training loss: 2.7399978637695312
Validation loss: 3.4270629421357186

Epoch: 6| Step: 8
Training loss: 3.261983871459961
Validation loss: 3.4200677000066286

Epoch: 6| Step: 9
Training loss: 3.2821409702301025
Validation loss: 3.4131176881892706

Epoch: 6| Step: 10
Training loss: 3.8592689037323
Validation loss: 3.403250237946869

Epoch: 6| Step: 11
Training loss: 3.910820960998535
Validation loss: 3.4033107270476637

Epoch: 6| Step: 12
Training loss: 3.2073988914489746
Validation loss: 3.391563205308812

Epoch: 6| Step: 13
Training loss: 3.7852678298950195
Validation loss: 3.3864970976306545

Epoch: 6| Step: 0
Training loss: 3.116330146789551
Validation loss: 3.380291651653987

Epoch: 6| Step: 1
Training loss: 3.8070735931396484
Validation loss: 3.369841734568278

Epoch: 6| Step: 2
Training loss: 3.2730374336242676
Validation loss: 3.3614689714165142

Epoch: 6| Step: 3
Training loss: 2.4335825443267822
Validation loss: 3.355095294214064

Epoch: 6| Step: 4
Training loss: 3.5866289138793945
Validation loss: 3.3488381472967004

Epoch: 6| Step: 5
Training loss: 3.59383487701416
Validation loss: 3.3380782065852994

Epoch: 6| Step: 6
Training loss: 2.9360084533691406
Validation loss: 3.3342217604319253

Epoch: 6| Step: 7
Training loss: 3.465297222137451
Validation loss: 3.3234340862561296

Epoch: 6| Step: 8
Training loss: 2.9436824321746826
Validation loss: 3.3193735768718104

Epoch: 6| Step: 9
Training loss: 2.9298691749572754
Validation loss: 3.309395710627238

Epoch: 6| Step: 10
Training loss: 2.9171876907348633
Validation loss: 3.304436804145895

Epoch: 6| Step: 11
Training loss: 3.0843400955200195
Validation loss: 3.2931912868253645

Epoch: 6| Step: 12
Training loss: 4.533864974975586
Validation loss: 3.2890437726051576

Epoch: 6| Step: 13
Training loss: 3.4334499835968018
Validation loss: 3.2812183544199955

Epoch: 7| Step: 0
Training loss: 3.0177793502807617
Validation loss: 3.2748650427787536

Epoch: 6| Step: 1
Training loss: 3.419065475463867
Validation loss: 3.2639755484878377

Epoch: 6| Step: 2
Training loss: 3.1008801460266113
Validation loss: 3.257969717825613

Epoch: 6| Step: 3
Training loss: 3.3663978576660156
Validation loss: 3.250062629740725

Epoch: 6| Step: 4
Training loss: 3.033618927001953
Validation loss: 3.2426425026309107

Epoch: 6| Step: 5
Training loss: 3.455012798309326
Validation loss: 3.234375374291533

Epoch: 6| Step: 6
Training loss: 2.6435444355010986
Validation loss: 3.227150212052048

Epoch: 6| Step: 7
Training loss: 3.2260923385620117
Validation loss: 3.2184771107089136

Epoch: 6| Step: 8
Training loss: 4.335263252258301
Validation loss: 3.2080495229331394

Epoch: 6| Step: 9
Training loss: 4.651008605957031
Validation loss: 3.206244883998748

Epoch: 6| Step: 10
Training loss: 2.967298984527588
Validation loss: 3.1940376425302155

Epoch: 6| Step: 11
Training loss: 2.101872444152832
Validation loss: 3.179124019479239

Epoch: 6| Step: 12
Training loss: 2.3017797470092773
Validation loss: 3.176456279652093

Epoch: 6| Step: 13
Training loss: 3.1081671714782715
Validation loss: 3.166527130270517

Epoch: 8| Step: 0
Training loss: 3.4573426246643066
Validation loss: 3.1620872815450034

Epoch: 6| Step: 1
Training loss: 2.7807869911193848
Validation loss: 3.1532062510008454

Epoch: 6| Step: 2
Training loss: 2.760190486907959
Validation loss: 3.139993841930102

Epoch: 6| Step: 3
Training loss: 3.4611921310424805
Validation loss: 3.1323876278374785

Epoch: 6| Step: 4
Training loss: 3.389319896697998
Validation loss: 3.1206263098665463

Epoch: 6| Step: 5
Training loss: 3.5729007720947266
Validation loss: 3.111815911467357

Epoch: 6| Step: 6
Training loss: 3.2168922424316406
Validation loss: 3.10124982044261

Epoch: 6| Step: 7
Training loss: 2.8659706115722656
Validation loss: 3.095066398702642

Epoch: 6| Step: 8
Training loss: 2.131739854812622
Validation loss: 3.0865811147997455

Epoch: 6| Step: 9
Training loss: 3.0742855072021484
Validation loss: 3.0711009425501667

Epoch: 6| Step: 10
Training loss: 3.3980183601379395
Validation loss: 3.0678384175864597

Epoch: 6| Step: 11
Training loss: 2.8305540084838867
Validation loss: 3.0612742490665887

Epoch: 6| Step: 12
Training loss: 3.8830606937408447
Validation loss: 3.049735120547715

Epoch: 6| Step: 13
Training loss: 2.4492926597595215
Validation loss: 3.040940341129098

Epoch: 9| Step: 0
Training loss: 3.340632915496826
Validation loss: 3.0338558227785173

Epoch: 6| Step: 1
Training loss: 2.883800506591797
Validation loss: 3.0234501182392077

Epoch: 6| Step: 2
Training loss: 2.1531026363372803
Validation loss: 3.0156021374528126

Epoch: 6| Step: 3
Training loss: 3.128788948059082
Validation loss: 3.0113645471552366

Epoch: 6| Step: 4
Training loss: 2.936304807662964
Validation loss: 3.0061074277406097

Epoch: 6| Step: 5
Training loss: 3.4892377853393555
Validation loss: 2.9923457176454606

Epoch: 6| Step: 6
Training loss: 2.397700786590576
Validation loss: 2.986259091284967

Epoch: 6| Step: 7
Training loss: 3.403703212738037
Validation loss: 2.97732449090609

Epoch: 6| Step: 8
Training loss: 3.0897254943847656
Validation loss: 2.970003738198229

Epoch: 6| Step: 9
Training loss: 2.950340509414673
Validation loss: 2.9613720370877172

Epoch: 6| Step: 10
Training loss: 2.9732534885406494
Validation loss: 2.9563194449229906

Epoch: 6| Step: 11
Training loss: 3.4042439460754395
Validation loss: 2.9435056076254895

Epoch: 6| Step: 12
Training loss: 2.4615447521209717
Validation loss: 2.9348408406780613

Epoch: 6| Step: 13
Training loss: 4.162369251251221
Validation loss: 2.924598006791966

Epoch: 10| Step: 0
Training loss: 3.4419565200805664
Validation loss: 2.9161461553265973

Epoch: 6| Step: 1
Training loss: 2.9441113471984863
Validation loss: 2.909733749205066

Epoch: 6| Step: 2
Training loss: 2.7098162174224854
Validation loss: 2.8973939188065065

Epoch: 6| Step: 3
Training loss: 2.7677268981933594
Validation loss: 2.8832211622627835

Epoch: 6| Step: 4
Training loss: 3.5101332664489746
Validation loss: 2.878505834969141

Epoch: 6| Step: 5
Training loss: 2.074960470199585
Validation loss: 2.8675978491383214

Epoch: 6| Step: 6
Training loss: 2.7688748836517334
Validation loss: 2.8584253377811883

Epoch: 6| Step: 7
Training loss: 2.727787971496582
Validation loss: 2.8505982070840816

Epoch: 6| Step: 8
Training loss: 3.371513843536377
Validation loss: 2.843616090795045

Epoch: 6| Step: 9
Training loss: 3.0924062728881836
Validation loss: 2.8300181563182543

Epoch: 6| Step: 10
Training loss: 2.7489917278289795
Validation loss: 2.827496187661284

Epoch: 6| Step: 11
Training loss: 3.093540668487549
Validation loss: 2.8114571109894784

Epoch: 6| Step: 12
Training loss: 3.3125863075256348
Validation loss: 2.7954176574624996

Epoch: 6| Step: 13
Training loss: 2.4014151096343994
Validation loss: 2.7970544881718133

Epoch: 11| Step: 0
Training loss: 3.629520893096924
Validation loss: 2.788821292179887

Epoch: 6| Step: 1
Training loss: 1.9872322082519531
Validation loss: 2.7771056416214153

Epoch: 6| Step: 2
Training loss: 2.322697877883911
Validation loss: 2.7648049605790006

Epoch: 6| Step: 3
Training loss: 3.3054795265197754
Validation loss: 2.759425122250793

Epoch: 6| Step: 4
Training loss: 2.302834987640381
Validation loss: 2.7471597733036166

Epoch: 6| Step: 5
Training loss: 3.1703402996063232
Validation loss: 2.7403904135509203

Epoch: 6| Step: 6
Training loss: 2.6596295833587646
Validation loss: 2.727546981585923

Epoch: 6| Step: 7
Training loss: 2.876336097717285
Validation loss: 2.7158228838315575

Epoch: 6| Step: 8
Training loss: 2.5553088188171387
Validation loss: 2.706030455968713

Epoch: 6| Step: 9
Training loss: 2.4914286136627197
Validation loss: 2.697033941104848

Epoch: 6| Step: 10
Training loss: 3.6373329162597656
Validation loss: 2.686490338335755

Epoch: 6| Step: 11
Training loss: 2.891453742980957
Validation loss: 2.675874722901211

Epoch: 6| Step: 12
Training loss: 3.181497812271118
Validation loss: 2.6625124587807605

Epoch: 6| Step: 13
Training loss: 3.1448397636413574
Validation loss: 2.6534469281473467

Epoch: 12| Step: 0
Training loss: 2.9273436069488525
Validation loss: 2.6551121588676208

Epoch: 6| Step: 1
Training loss: 2.351459503173828
Validation loss: 2.643991780537431

Epoch: 6| Step: 2
Training loss: 2.890270709991455
Validation loss: 2.630556873095933

Epoch: 6| Step: 3
Training loss: 2.6721959114074707
Validation loss: 2.6166971191283195

Epoch: 6| Step: 4
Training loss: 2.6651153564453125
Validation loss: 2.6104347680204656

Epoch: 6| Step: 5
Training loss: 3.6058804988861084
Validation loss: 2.5966153144836426

Epoch: 6| Step: 6
Training loss: 2.609984874725342
Validation loss: 2.590222691976896

Epoch: 6| Step: 7
Training loss: 3.1774988174438477
Validation loss: 2.583447092322893

Epoch: 6| Step: 8
Training loss: 2.795206308364868
Validation loss: 2.5680129553682063

Epoch: 6| Step: 9
Training loss: 2.985464572906494
Validation loss: 2.5629859278278966

Epoch: 6| Step: 10
Training loss: 2.6260287761688232
Validation loss: 2.555559463398431

Epoch: 6| Step: 11
Training loss: 2.873570680618286
Validation loss: 2.5425451212031867

Epoch: 6| Step: 12
Training loss: 2.348475933074951
Validation loss: 2.537182830995129

Epoch: 6| Step: 13
Training loss: 2.0941646099090576
Validation loss: 2.520495596752372

Epoch: 13| Step: 0
Training loss: 2.719564437866211
Validation loss: 2.5163616288092827

Epoch: 6| Step: 1
Training loss: 3.3045458793640137
Validation loss: 2.50461212665804

Epoch: 6| Step: 2
Training loss: 3.0104618072509766
Validation loss: 2.4968569022352978

Epoch: 6| Step: 3
Training loss: 3.0979247093200684
Validation loss: 2.487093238420384

Epoch: 6| Step: 4
Training loss: 3.1165010929107666
Validation loss: 2.4663732410759054

Epoch: 6| Step: 5
Training loss: 2.7594892978668213
Validation loss: 2.459601556101153

Epoch: 6| Step: 6
Training loss: 3.1894400119781494
Validation loss: 2.4525047220209593

Epoch: 6| Step: 7
Training loss: 2.637460470199585
Validation loss: 2.4382187884341002

Epoch: 6| Step: 8
Training loss: 2.8774709701538086
Validation loss: 2.4334785630626063

Epoch: 6| Step: 9
Training loss: 1.671924352645874
Validation loss: 2.425476030636859

Epoch: 6| Step: 10
Training loss: 2.56547212600708
Validation loss: 2.4182693445554344

Epoch: 6| Step: 11
Training loss: 2.437865734100342
Validation loss: 2.4032061023096882

Epoch: 6| Step: 12
Training loss: 2.151738166809082
Validation loss: 2.3981024988235964

Epoch: 6| Step: 13
Training loss: 2.065324068069458
Validation loss: 2.3857382164206555

Epoch: 14| Step: 0
Training loss: 3.285963535308838
Validation loss: 2.374384126355571

Epoch: 6| Step: 1
Training loss: 2.225428342819214
Validation loss: 2.370785536304597

Epoch: 6| Step: 2
Training loss: 2.60288405418396
Validation loss: 2.3630729336892404

Epoch: 6| Step: 3
Training loss: 2.9404869079589844
Validation loss: 2.351047582523797

Epoch: 6| Step: 4
Training loss: 2.3722381591796875
Validation loss: 2.345372925522507

Epoch: 6| Step: 5
Training loss: 2.160534620285034
Validation loss: 2.3392973881895824

Epoch: 6| Step: 6
Training loss: 2.3901538848876953
Validation loss: 2.3317810643103813

Epoch: 6| Step: 7
Training loss: 3.6980390548706055
Validation loss: 2.3382294306191067

Epoch: 6| Step: 8
Training loss: 2.4812729358673096
Validation loss: 2.3258981550893476

Epoch: 6| Step: 9
Training loss: 2.8002614974975586
Validation loss: 2.3260859033112884

Epoch: 6| Step: 10
Training loss: 1.9106853008270264
Validation loss: 2.3098051163458053

Epoch: 6| Step: 11
Training loss: 2.4689955711364746
Validation loss: 2.306720390114733

Epoch: 6| Step: 12
Training loss: 2.488220453262329
Validation loss: 2.305259258516373

Epoch: 6| Step: 13
Training loss: 3.1187145709991455
Validation loss: 2.301134617097916

Epoch: 15| Step: 0
Training loss: 2.851198673248291
Validation loss: 2.2825760533732753

Epoch: 6| Step: 1
Training loss: 2.5661487579345703
Validation loss: 2.283777142083773

Epoch: 6| Step: 2
Training loss: 2.165308713912964
Validation loss: 2.2694191035404

Epoch: 6| Step: 3
Training loss: 2.7328708171844482
Validation loss: 2.26656327965439

Epoch: 6| Step: 4
Training loss: 2.361527919769287
Validation loss: 2.2524209509613695

Epoch: 6| Step: 5
Training loss: 3.9011096954345703
Validation loss: 2.2575664981718986

Epoch: 6| Step: 6
Training loss: 2.3416714668273926
Validation loss: 2.2459700517756964

Epoch: 6| Step: 7
Training loss: 2.841066837310791
Validation loss: 2.2353853384653726

Epoch: 6| Step: 8
Training loss: 2.3239054679870605
Validation loss: 2.234310406510548

Epoch: 6| Step: 9
Training loss: 2.6576144695281982
Validation loss: 2.223952733060365

Epoch: 6| Step: 10
Training loss: 1.7899889945983887
Validation loss: 2.220447583865094

Epoch: 6| Step: 11
Training loss: 2.650594711303711
Validation loss: 2.216691001769035

Epoch: 6| Step: 12
Training loss: 2.2783541679382324
Validation loss: 2.203942568071427

Epoch: 6| Step: 13
Training loss: 2.5615475177764893
Validation loss: 2.2010443851511967

Epoch: 16| Step: 0
Training loss: 2.764526844024658
Validation loss: 2.197899026255454

Epoch: 6| Step: 1
Training loss: 3.044490337371826
Validation loss: 2.1900958258618592

Epoch: 6| Step: 2
Training loss: 2.470107078552246
Validation loss: 2.1828910535381687

Epoch: 6| Step: 3
Training loss: 2.085516929626465
Validation loss: 2.1802962364689

Epoch: 6| Step: 4
Training loss: 3.169273614883423
Validation loss: 2.1794614535506054

Epoch: 6| Step: 5
Training loss: 2.372114896774292
Validation loss: 2.167910816848919

Epoch: 6| Step: 6
Training loss: 2.6071629524230957
Validation loss: 2.174767933866029

Epoch: 6| Step: 7
Training loss: 2.6226091384887695
Validation loss: 2.1775369900529102

Epoch: 6| Step: 8
Training loss: 2.171288251876831
Validation loss: 2.1621814517564673

Epoch: 6| Step: 9
Training loss: 2.6168408393859863
Validation loss: 2.1524196235082482

Epoch: 6| Step: 10
Training loss: 2.3328118324279785
Validation loss: 2.1601956634111303

Epoch: 6| Step: 11
Training loss: 2.7303895950317383
Validation loss: 2.1570309413376676

Epoch: 6| Step: 12
Training loss: 2.4818625450134277
Validation loss: 2.144302968055971

Epoch: 6| Step: 13
Training loss: 1.2907252311706543
Validation loss: 2.152518960737413

Epoch: 17| Step: 0
Training loss: 2.7182693481445312
Validation loss: 2.140936754083121

Epoch: 6| Step: 1
Training loss: 1.8126318454742432
Validation loss: 2.1402724994126188

Epoch: 6| Step: 2
Training loss: 3.2809314727783203
Validation loss: 2.1338206516799105

Epoch: 6| Step: 3
Training loss: 2.6380951404571533
Validation loss: 2.135276125323388

Epoch: 6| Step: 4
Training loss: 2.302793502807617
Validation loss: 2.1236626871170534

Epoch: 6| Step: 5
Training loss: 2.297661304473877
Validation loss: 2.1110751923694404

Epoch: 6| Step: 6
Training loss: 2.07515287399292
Validation loss: 2.120424084765937

Epoch: 6| Step: 7
Training loss: 2.370516300201416
Validation loss: 2.113943919058769

Epoch: 6| Step: 8
Training loss: 2.3333959579467773
Validation loss: 2.124308286174651

Epoch: 6| Step: 9
Training loss: 1.942924976348877
Validation loss: 2.0982981369059575

Epoch: 6| Step: 10
Training loss: 2.2819762229919434
Validation loss: 2.104814029509021

Epoch: 6| Step: 11
Training loss: 3.505864381790161
Validation loss: 2.097005250633404

Epoch: 6| Step: 12
Training loss: 3.0935685634613037
Validation loss: 2.087342086658683

Epoch: 6| Step: 13
Training loss: 2.028073787689209
Validation loss: 2.1006784644178165

Epoch: 18| Step: 0
Training loss: 2.6738486289978027
Validation loss: 2.08852957910107

Epoch: 6| Step: 1
Training loss: 2.2841556072235107
Validation loss: 2.095780077800956

Epoch: 6| Step: 2
Training loss: 2.8931055068969727
Validation loss: 2.0794836718549012

Epoch: 6| Step: 3
Training loss: 2.999746322631836
Validation loss: 2.0850800493712067

Epoch: 6| Step: 4
Training loss: 2.0320849418640137
Validation loss: 2.084832678559006

Epoch: 6| Step: 5
Training loss: 2.1657216548919678
Validation loss: 2.0782286890091433

Epoch: 6| Step: 6
Training loss: 1.8490169048309326
Validation loss: 2.0871733798775622

Epoch: 6| Step: 7
Training loss: 2.66458797454834
Validation loss: 2.074638285944539

Epoch: 6| Step: 8
Training loss: 2.7167141437530518
Validation loss: 2.0683718548026135

Epoch: 6| Step: 9
Training loss: 2.322726249694824
Validation loss: 2.06505093010523

Epoch: 6| Step: 10
Training loss: 2.6600122451782227
Validation loss: 2.0679153319328063

Epoch: 6| Step: 11
Training loss: 2.220426082611084
Validation loss: 2.0683739710879583

Epoch: 6| Step: 12
Training loss: 2.5408763885498047
Validation loss: 2.051036796262187

Epoch: 6| Step: 13
Training loss: 2.8031768798828125
Validation loss: 2.056851835661037

Epoch: 19| Step: 0
Training loss: 2.6265416145324707
Validation loss: 2.0561314859697895

Epoch: 6| Step: 1
Training loss: 2.6339967250823975
Validation loss: 2.061582444816507

Epoch: 6| Step: 2
Training loss: 2.3667430877685547
Validation loss: 2.061300250791734

Epoch: 6| Step: 3
Training loss: 2.40571928024292
Validation loss: 2.0643246135404034

Epoch: 6| Step: 4
Training loss: 2.6580138206481934
Validation loss: 2.062663806382046

Epoch: 6| Step: 5
Training loss: 2.4735593795776367
Validation loss: 2.067754545519429

Epoch: 6| Step: 6
Training loss: 2.382476806640625
Validation loss: 2.06266926950024

Epoch: 6| Step: 7
Training loss: 2.237203598022461
Validation loss: 2.064264961468276

Epoch: 6| Step: 8
Training loss: 2.4575281143188477
Validation loss: 2.0645663507523073

Epoch: 6| Step: 9
Training loss: 2.735846757888794
Validation loss: 2.0666323361858243

Epoch: 6| Step: 10
Training loss: 1.961179256439209
Validation loss: 2.0579143698497484

Epoch: 6| Step: 11
Training loss: 2.69960618019104
Validation loss: 2.060948089886737

Epoch: 6| Step: 12
Training loss: 2.690736770629883
Validation loss: 2.054065513354476

Epoch: 6| Step: 13
Training loss: 2.060330629348755
Validation loss: 2.0511160332669496

Epoch: 20| Step: 0
Training loss: 3.0851635932922363
Validation loss: 2.0537597389631372

Epoch: 6| Step: 1
Training loss: 2.6794049739837646
Validation loss: 2.038935084496775

Epoch: 6| Step: 2
Training loss: 2.9952898025512695
Validation loss: 2.058306678648918

Epoch: 6| Step: 3
Training loss: 1.7000572681427002
Validation loss: 2.0579082837668796

Epoch: 6| Step: 4
Training loss: 2.757502555847168
Validation loss: 2.05793664532323

Epoch: 6| Step: 5
Training loss: 2.614006996154785
Validation loss: 2.056349303132744

Epoch: 6| Step: 6
Training loss: 2.1219639778137207
Validation loss: 2.062959219819756

Epoch: 6| Step: 7
Training loss: 2.8370048999786377
Validation loss: 2.0583525114161993

Epoch: 6| Step: 8
Training loss: 2.3363265991210938
Validation loss: 2.0548164459966842

Epoch: 6| Step: 9
Training loss: 2.555375814437866
Validation loss: 2.056231544863793

Epoch: 6| Step: 10
Training loss: 2.1114354133605957
Validation loss: 2.057307336920051

Epoch: 6| Step: 11
Training loss: 2.1120879650115967
Validation loss: 2.0611564984885593

Epoch: 6| Step: 12
Training loss: 1.7866346836090088
Validation loss: 2.044241641157417

Epoch: 6| Step: 13
Training loss: 2.807811975479126
Validation loss: 2.0578551177055604

Epoch: 21| Step: 0
Training loss: 2.1884350776672363
Validation loss: 2.0567965302416074

Epoch: 6| Step: 1
Training loss: 2.4877748489379883
Validation loss: 2.0342585809769167

Epoch: 6| Step: 2
Training loss: 2.0666556358337402
Validation loss: 2.0561394537648847

Epoch: 6| Step: 3
Training loss: 2.926271915435791
Validation loss: 2.0477869792651107

Epoch: 6| Step: 4
Training loss: 2.559532403945923
Validation loss: 2.047033235590945

Epoch: 6| Step: 5
Training loss: 1.541562795639038
Validation loss: 2.0373939198832356

Epoch: 6| Step: 6
Training loss: 2.094409465789795
Validation loss: 2.041901873004052

Epoch: 6| Step: 7
Training loss: 2.084897041320801
Validation loss: 2.0410956375060545

Epoch: 6| Step: 8
Training loss: 3.4310503005981445
Validation loss: 2.039841116115611

Epoch: 6| Step: 9
Training loss: 2.3553643226623535
Validation loss: 2.0451318064043598

Epoch: 6| Step: 10
Training loss: 2.6335506439208984
Validation loss: 2.026596612827752

Epoch: 6| Step: 11
Training loss: 2.376986026763916
Validation loss: 2.039100134244529

Epoch: 6| Step: 12
Training loss: 2.5280961990356445
Validation loss: 2.036256087723599

Epoch: 6| Step: 13
Training loss: 3.5213544368743896
Validation loss: 2.020503008237449

Epoch: 22| Step: 0
Training loss: 2.172530174255371
Validation loss: 2.03010533958353

Epoch: 6| Step: 1
Training loss: 2.854271411895752
Validation loss: 2.0341492981039067

Epoch: 6| Step: 2
Training loss: 2.5179874897003174
Validation loss: 2.0304021989145586

Epoch: 6| Step: 3
Training loss: 2.2241322994232178
Validation loss: 2.02852261835529

Epoch: 6| Step: 4
Training loss: 2.0806667804718018
Validation loss: 2.041476509904349

Epoch: 6| Step: 5
Training loss: 1.8955649137496948
Validation loss: 2.0289925888020504

Epoch: 6| Step: 6
Training loss: 2.293551445007324
Validation loss: 2.033697692296838

Epoch: 6| Step: 7
Training loss: 2.490446090698242
Validation loss: 2.025054736803937

Epoch: 6| Step: 8
Training loss: 2.6300389766693115
Validation loss: 2.0231917519723215

Epoch: 6| Step: 9
Training loss: 2.7271628379821777
Validation loss: 2.024670805982364

Epoch: 6| Step: 10
Training loss: 2.8885204792022705
Validation loss: 2.0350831772691462

Epoch: 6| Step: 11
Training loss: 2.34743595123291
Validation loss: 2.0373125281385196

Epoch: 6| Step: 12
Training loss: 2.684830665588379
Validation loss: 2.031707368871217

Epoch: 6| Step: 13
Training loss: 2.3499462604522705
Validation loss: 2.0203456135206324

Epoch: 23| Step: 0
Training loss: 2.6133861541748047
Validation loss: 2.0208707265956427

Epoch: 6| Step: 1
Training loss: 2.0867879390716553
Validation loss: 2.03084570618086

Epoch: 6| Step: 2
Training loss: 1.7310618162155151
Validation loss: 2.021873199811546

Epoch: 6| Step: 3
Training loss: 2.705160140991211
Validation loss: 2.0379603178270402

Epoch: 6| Step: 4
Training loss: 2.2654590606689453
Validation loss: 2.037924951122653

Epoch: 6| Step: 5
Training loss: 2.707406520843506
Validation loss: 2.0306044740061604

Epoch: 6| Step: 6
Training loss: 2.4533939361572266
Validation loss: 2.0311746417835193

Epoch: 6| Step: 7
Training loss: 2.633059024810791
Validation loss: 2.030415896446474

Epoch: 6| Step: 8
Training loss: 2.2101216316223145
Validation loss: 2.0240747928619385

Epoch: 6| Step: 9
Training loss: 2.9853882789611816
Validation loss: 2.0417223438139884

Epoch: 6| Step: 10
Training loss: 2.550082206726074
Validation loss: 2.0294879687729703

Epoch: 6| Step: 11
Training loss: 2.876162052154541
Validation loss: 2.0197795796137985

Epoch: 6| Step: 12
Training loss: 1.763500452041626
Validation loss: 2.0275229074621715

Epoch: 6| Step: 13
Training loss: 2.4814088344573975
Validation loss: 2.0360399305179553

Epoch: 24| Step: 0
Training loss: 2.0352816581726074
Validation loss: 2.034313383922782

Epoch: 6| Step: 1
Training loss: 1.9863594770431519
Validation loss: 2.0312683684851534

Epoch: 6| Step: 2
Training loss: 2.749995708465576
Validation loss: 2.036614916657889

Epoch: 6| Step: 3
Training loss: 2.715857744216919
Validation loss: 2.0265080595529206

Epoch: 6| Step: 4
Training loss: 3.0245609283447266
Validation loss: 2.0373998085657754

Epoch: 6| Step: 5
Training loss: 1.5763816833496094
Validation loss: 2.0335613425059984

Epoch: 6| Step: 6
Training loss: 1.8527092933654785
Validation loss: 2.028328808405066

Epoch: 6| Step: 7
Training loss: 2.7211568355560303
Validation loss: 2.0286957474165064

Epoch: 6| Step: 8
Training loss: 3.8103156089782715
Validation loss: 2.035153337704238

Epoch: 6| Step: 9
Training loss: 2.455955982208252
Validation loss: 2.022284710279075

Epoch: 6| Step: 10
Training loss: 1.7659871578216553
Validation loss: 2.0286661501853698

Epoch: 6| Step: 11
Training loss: 2.3439507484436035
Validation loss: 2.0292323968743764

Epoch: 6| Step: 12
Training loss: 2.37387752532959
Validation loss: 2.0272796666750343

Epoch: 6| Step: 13
Training loss: 2.3875629901885986
Validation loss: 2.0265149403643865

Epoch: 25| Step: 0
Training loss: 2.502963066101074
Validation loss: 2.0370503907562583

Epoch: 6| Step: 1
Training loss: 2.523517608642578
Validation loss: 2.0339630649935816

Epoch: 6| Step: 2
Training loss: 2.353132724761963
Validation loss: 2.0216705440193095

Epoch: 6| Step: 3
Training loss: 2.110015869140625
Validation loss: 2.025416347288316

Epoch: 6| Step: 4
Training loss: 2.3510422706604004
Validation loss: 2.0276626028040403

Epoch: 6| Step: 5
Training loss: 2.082038164138794
Validation loss: 2.0276689298691286

Epoch: 6| Step: 6
Training loss: 2.584808111190796
Validation loss: 2.028683170195549

Epoch: 6| Step: 7
Training loss: 2.6394765377044678
Validation loss: 2.0401580577255576

Epoch: 6| Step: 8
Training loss: 2.3683648109436035
Validation loss: 2.0381231769438712

Epoch: 6| Step: 9
Training loss: 2.6976239681243896
Validation loss: 2.0357081967015422

Epoch: 6| Step: 10
Training loss: 2.610644578933716
Validation loss: 2.0316760809190813

Epoch: 6| Step: 11
Training loss: 2.0755157470703125
Validation loss: 2.0301783571961107

Epoch: 6| Step: 12
Training loss: 2.669738292694092
Validation loss: 2.0338081211172123

Epoch: 6| Step: 13
Training loss: 2.0317728519439697
Validation loss: 2.0232411533273678

Epoch: 26| Step: 0
Training loss: 2.693315029144287
Validation loss: 2.0288471175778295

Epoch: 6| Step: 1
Training loss: 2.1298329830169678
Validation loss: 2.0246432468455327

Epoch: 6| Step: 2
Training loss: 2.1899735927581787
Validation loss: 2.0275504166080105

Epoch: 6| Step: 3
Training loss: 2.0028836727142334
Validation loss: 2.023837640721311

Epoch: 6| Step: 4
Training loss: 2.3033909797668457
Validation loss: 2.0113170775034095

Epoch: 6| Step: 5
Training loss: 3.2664921283721924
Validation loss: 2.0254738125749814

Epoch: 6| Step: 6
Training loss: 2.184171676635742
Validation loss: 2.0134293981777724

Epoch: 6| Step: 7
Training loss: 2.2149343490600586
Validation loss: 2.0213631250525035

Epoch: 6| Step: 8
Training loss: 2.3043694496154785
Validation loss: 2.0117871607503583

Epoch: 6| Step: 9
Training loss: 2.7389514446258545
Validation loss: 2.006053629741874

Epoch: 6| Step: 10
Training loss: 2.8103206157684326
Validation loss: 2.012564197663338

Epoch: 6| Step: 11
Training loss: 2.343538284301758
Validation loss: 2.009045257363268

Epoch: 6| Step: 12
Training loss: 2.1346378326416016
Validation loss: 2.002140878349222

Epoch: 6| Step: 13
Training loss: 2.5168659687042236
Validation loss: 2.0154382977434384

Epoch: 27| Step: 0
Training loss: 2.038386106491089
Validation loss: 2.0157947514646795

Epoch: 6| Step: 1
Training loss: 2.521615505218506
Validation loss: 2.0108592638405423

Epoch: 6| Step: 2
Training loss: 2.9636194705963135
Validation loss: 2.020997121769895

Epoch: 6| Step: 3
Training loss: 2.414628505706787
Validation loss: 2.0047260240841935

Epoch: 6| Step: 4
Training loss: 2.58030104637146
Validation loss: 2.0275262760859665

Epoch: 6| Step: 5
Training loss: 2.369157552719116
Validation loss: 2.006946199683733

Epoch: 6| Step: 6
Training loss: 2.251516819000244
Validation loss: 2.0097791328225085

Epoch: 6| Step: 7
Training loss: 2.557223320007324
Validation loss: 2.0218269773708877

Epoch: 6| Step: 8
Training loss: 2.090792417526245
Validation loss: 2.011280285414829

Epoch: 6| Step: 9
Training loss: 2.6417620182037354
Validation loss: 2.0087771108073573

Epoch: 6| Step: 10
Training loss: 2.1438870429992676
Validation loss: 2.0189300506345687

Epoch: 6| Step: 11
Training loss: 2.7766690254211426
Validation loss: 2.0129100225305043

Epoch: 6| Step: 12
Training loss: 1.982725977897644
Validation loss: 2.014653580163115

Epoch: 6| Step: 13
Training loss: 2.219604969024658
Validation loss: 2.0068245997992893

Epoch: 28| Step: 0
Training loss: 2.6996636390686035
Validation loss: 2.0168062153682915

Epoch: 6| Step: 1
Training loss: 1.6841150522232056
Validation loss: 2.0115060575546755

Epoch: 6| Step: 2
Training loss: 2.401991367340088
Validation loss: 2.0157984930981874

Epoch: 6| Step: 3
Training loss: 2.122605800628662
Validation loss: 2.0090541096143824

Epoch: 6| Step: 4
Training loss: 3.0422801971435547
Validation loss: 2.0186062487222816

Epoch: 6| Step: 5
Training loss: 2.3931291103363037
Validation loss: 2.005715807278951

Epoch: 6| Step: 6
Training loss: 2.1573591232299805
Validation loss: 2.0046566327412925

Epoch: 6| Step: 7
Training loss: 2.6939854621887207
Validation loss: 2.020575573367457

Epoch: 6| Step: 8
Training loss: 2.289170265197754
Validation loss: 2.0198111816119124

Epoch: 6| Step: 9
Training loss: 2.6198081970214844
Validation loss: 2.015114015148532

Epoch: 6| Step: 10
Training loss: 1.9866352081298828
Validation loss: 2.0120937926794893

Epoch: 6| Step: 11
Training loss: 2.104295253753662
Validation loss: 2.0180845093983475

Epoch: 6| Step: 12
Training loss: 2.3849081993103027
Validation loss: 2.0123432592679094

Epoch: 6| Step: 13
Training loss: 3.2179315090179443
Validation loss: 2.0095176953141407

Epoch: 29| Step: 0
Training loss: 2.174185037612915
Validation loss: 2.0051442448810866

Epoch: 6| Step: 1
Training loss: 2.203920364379883
Validation loss: 2.0088366385429137

Epoch: 6| Step: 2
Training loss: 2.343808889389038
Validation loss: 2.0163790436201197

Epoch: 6| Step: 3
Training loss: 2.463169574737549
Validation loss: 2.016246913581766

Epoch: 6| Step: 4
Training loss: 2.81998872756958
Validation loss: 2.012077748134572

Epoch: 6| Step: 5
Training loss: 2.16095232963562
Validation loss: 2.019600413178885

Epoch: 6| Step: 6
Training loss: 2.4675509929656982
Validation loss: 2.003083267519551

Epoch: 6| Step: 7
Training loss: 2.6780388355255127
Validation loss: 2.018073530607326

Epoch: 6| Step: 8
Training loss: 2.209699869155884
Validation loss: 2.019923711335787

Epoch: 6| Step: 9
Training loss: 2.579922676086426
Validation loss: 2.0162320906116116

Epoch: 6| Step: 10
Training loss: 2.299792528152466
Validation loss: 2.0230637750317975

Epoch: 6| Step: 11
Training loss: 2.254542350769043
Validation loss: 2.026640538246401

Epoch: 6| Step: 12
Training loss: 2.3895373344421387
Validation loss: 2.0142625762570288

Epoch: 6| Step: 13
Training loss: 2.2626047134399414
Validation loss: 2.0167723471118557

Epoch: 30| Step: 0
Training loss: 2.2155492305755615
Validation loss: 2.0131301341518277

Epoch: 6| Step: 1
Training loss: 3.058657169342041
Validation loss: 2.012422957727986

Epoch: 6| Step: 2
Training loss: 2.032538890838623
Validation loss: 2.0105804602305093

Epoch: 6| Step: 3
Training loss: 1.9737483263015747
Validation loss: 2.0151923061698995

Epoch: 6| Step: 4
Training loss: 2.514557361602783
Validation loss: 2.010784943898519

Epoch: 6| Step: 5
Training loss: 2.6034812927246094
Validation loss: 1.9965147574742634

Epoch: 6| Step: 6
Training loss: 2.0039896965026855
Validation loss: 1.9971905639094691

Epoch: 6| Step: 7
Training loss: 2.078373670578003
Validation loss: 1.9916624407614432

Epoch: 6| Step: 8
Training loss: 2.003990650177002
Validation loss: 1.9978288860731228

Epoch: 6| Step: 9
Training loss: 3.180544137954712
Validation loss: 2.007787468612835

Epoch: 6| Step: 10
Training loss: 2.028327226638794
Validation loss: 1.9970158659001833

Epoch: 6| Step: 11
Training loss: 2.6417012214660645
Validation loss: 2.006812636570264

Epoch: 6| Step: 12
Training loss: 2.3455302715301514
Validation loss: 1.9960834441646453

Epoch: 6| Step: 13
Training loss: 2.9262003898620605
Validation loss: 1.9999603763703377

Epoch: 31| Step: 0
Training loss: 2.5099987983703613
Validation loss: 1.9970834742310226

Epoch: 6| Step: 1
Training loss: 2.893321990966797
Validation loss: 1.997914142506097

Epoch: 6| Step: 2
Training loss: 2.320301055908203
Validation loss: 2.003473822788526

Epoch: 6| Step: 3
Training loss: 2.422630548477173
Validation loss: 2.0122163347018662

Epoch: 6| Step: 4
Training loss: 2.201097249984741
Validation loss: 2.006005797334897

Epoch: 6| Step: 5
Training loss: 2.1684861183166504
Validation loss: 2.0072514741651473

Epoch: 6| Step: 6
Training loss: 2.3373212814331055
Validation loss: 2.015010772212859

Epoch: 6| Step: 7
Training loss: 2.1687707901000977
Validation loss: 2.007863583103303

Epoch: 6| Step: 8
Training loss: 2.858595371246338
Validation loss: 2.0006485062260784

Epoch: 6| Step: 9
Training loss: 2.45774507522583
Validation loss: 2.011017603258933

Epoch: 6| Step: 10
Training loss: 2.0499088764190674
Validation loss: 2.0247590849476476

Epoch: 6| Step: 11
Training loss: 2.2311370372772217
Validation loss: 2.0127602418263755

Epoch: 6| Step: 12
Training loss: 2.336832284927368
Validation loss: 2.0080153096106743

Epoch: 6| Step: 13
Training loss: 2.1119682788848877
Validation loss: 2.013937650188323

Epoch: 32| Step: 0
Training loss: 2.2979049682617188
Validation loss: 2.0172911433763403

Epoch: 6| Step: 1
Training loss: 2.4068033695220947
Validation loss: 2.0061988907475627

Epoch: 6| Step: 2
Training loss: 1.6982182264328003
Validation loss: 2.0163140373845256

Epoch: 6| Step: 3
Training loss: 2.626405715942383
Validation loss: 1.9979726511945006

Epoch: 6| Step: 4
Training loss: 2.8152685165405273
Validation loss: 2.0004513225247784

Epoch: 6| Step: 5
Training loss: 2.705653667449951
Validation loss: 2.0215989158999537

Epoch: 6| Step: 6
Training loss: 2.8770880699157715
Validation loss: 2.0051358733125912

Epoch: 6| Step: 7
Training loss: 2.2445414066314697
Validation loss: 2.0053079435902257

Epoch: 6| Step: 8
Training loss: 2.5326645374298096
Validation loss: 1.9959348299170052

Epoch: 6| Step: 9
Training loss: 2.053985118865967
Validation loss: 1.9988839908312726

Epoch: 6| Step: 10
Training loss: 2.280890464782715
Validation loss: 2.0120745756292857

Epoch: 6| Step: 11
Training loss: 2.318941354751587
Validation loss: 2.0051385894898446

Epoch: 6| Step: 12
Training loss: 2.294933795928955
Validation loss: 1.9995438924399755

Epoch: 6| Step: 13
Training loss: 1.8462380170822144
Validation loss: 2.0016371473189323

Epoch: 33| Step: 0
Training loss: 2.484147071838379
Validation loss: 2.0024555152462375

Epoch: 6| Step: 1
Training loss: 2.2978897094726562
Validation loss: 1.998597696263303

Epoch: 6| Step: 2
Training loss: 2.911559820175171
Validation loss: 1.9946501716490714

Epoch: 6| Step: 3
Training loss: 1.9657959938049316
Validation loss: 2.0070764787735476

Epoch: 6| Step: 4
Training loss: 2.090999126434326
Validation loss: 1.989531615728973

Epoch: 6| Step: 5
Training loss: 2.146437168121338
Validation loss: 2.003553177720757

Epoch: 6| Step: 6
Training loss: 1.6601921319961548
Validation loss: 2.012744494663772

Epoch: 6| Step: 7
Training loss: 2.2676949501037598
Validation loss: 1.9954548035898516

Epoch: 6| Step: 8
Training loss: 2.800676107406616
Validation loss: 1.9899858031221616

Epoch: 6| Step: 9
Training loss: 2.6144087314605713
Validation loss: 2.0048632301310056

Epoch: 6| Step: 10
Training loss: 2.848586082458496
Validation loss: 1.994029350178216

Epoch: 6| Step: 11
Training loss: 2.6091818809509277
Validation loss: 2.0038562974622174

Epoch: 6| Step: 12
Training loss: 2.060452938079834
Validation loss: 1.9966245594845022

Epoch: 6| Step: 13
Training loss: 2.1681249141693115
Validation loss: 1.9966750093685683

Epoch: 34| Step: 0
Training loss: 2.282650947570801
Validation loss: 1.98724603268408

Epoch: 6| Step: 1
Training loss: 2.2041072845458984
Validation loss: 1.9848912505693332

Epoch: 6| Step: 2
Training loss: 1.9777430295944214
Validation loss: 2.0050036868741437

Epoch: 6| Step: 3
Training loss: 3.0243592262268066
Validation loss: 1.9936482842250536

Epoch: 6| Step: 4
Training loss: 2.1251907348632812
Validation loss: 1.9835962762114823

Epoch: 6| Step: 5
Training loss: 2.358335018157959
Validation loss: 2.000193859941216

Epoch: 6| Step: 6
Training loss: 2.335033416748047
Validation loss: 1.994576164471206

Epoch: 6| Step: 7
Training loss: 2.81514310836792
Validation loss: 1.9861723530677058

Epoch: 6| Step: 8
Training loss: 1.9764432907104492
Validation loss: 1.9907454431697886

Epoch: 6| Step: 9
Training loss: 2.4742488861083984
Validation loss: 1.9982508215852963

Epoch: 6| Step: 10
Training loss: 2.2294020652770996
Validation loss: 1.9971495789866294

Epoch: 6| Step: 11
Training loss: 2.091702699661255
Validation loss: 1.9887058363165906

Epoch: 6| Step: 12
Training loss: 2.7683560848236084
Validation loss: 1.996495000777706

Epoch: 6| Step: 13
Training loss: 2.25521183013916
Validation loss: 1.9939138735494306

Epoch: 35| Step: 0
Training loss: 2.4335591793060303
Validation loss: 1.9959154539210822

Epoch: 6| Step: 1
Training loss: 3.009840488433838
Validation loss: 1.9876256911985335

Epoch: 6| Step: 2
Training loss: 2.0096230506896973
Validation loss: 2.0056559065336823

Epoch: 6| Step: 3
Training loss: 2.626249313354492
Validation loss: 2.001271576009771

Epoch: 6| Step: 4
Training loss: 2.3350772857666016
Validation loss: 1.9950691692290767

Epoch: 6| Step: 5
Training loss: 2.343294382095337
Validation loss: 1.98994626281082

Epoch: 6| Step: 6
Training loss: 2.621091842651367
Validation loss: 1.9935079646366898

Epoch: 6| Step: 7
Training loss: 2.053046703338623
Validation loss: 1.9884593115057996

Epoch: 6| Step: 8
Training loss: 2.623687267303467
Validation loss: 2.001896471105596

Epoch: 6| Step: 9
Training loss: 2.5443673133850098
Validation loss: 1.9889635168096071

Epoch: 6| Step: 10
Training loss: 1.3193302154541016
Validation loss: 1.995180852951542

Epoch: 6| Step: 11
Training loss: 2.6327319145202637
Validation loss: 1.9982119990933327

Epoch: 6| Step: 12
Training loss: 2.3537657260894775
Validation loss: 1.9966905860490696

Epoch: 6| Step: 13
Training loss: 1.6403154134750366
Validation loss: 1.9892020251161309

Epoch: 36| Step: 0
Training loss: 2.6088695526123047
Validation loss: 1.9868673970622401

Epoch: 6| Step: 1
Training loss: 2.1691489219665527
Validation loss: 1.9840019620874876

Epoch: 6| Step: 2
Training loss: 2.512206792831421
Validation loss: 1.9839581648508708

Epoch: 6| Step: 3
Training loss: 2.601665735244751
Validation loss: 1.9989153672290105

Epoch: 6| Step: 4
Training loss: 2.3129241466522217
Validation loss: 1.9919802091454948

Epoch: 6| Step: 5
Training loss: 1.9163376092910767
Validation loss: 1.9916705264840076

Epoch: 6| Step: 6
Training loss: 2.183638334274292
Validation loss: 1.9914545384786462

Epoch: 6| Step: 7
Training loss: 2.11452054977417
Validation loss: 1.9893432278786936

Epoch: 6| Step: 8
Training loss: 2.9355297088623047
Validation loss: 1.9992237988338675

Epoch: 6| Step: 9
Training loss: 2.3027729988098145
Validation loss: 1.9902354645472702

Epoch: 6| Step: 10
Training loss: 2.574425458908081
Validation loss: 1.996475806800268

Epoch: 6| Step: 11
Training loss: 2.007113456726074
Validation loss: 1.9998328365305418

Epoch: 6| Step: 12
Training loss: 2.4217562675476074
Validation loss: 1.9901013156419158

Epoch: 6| Step: 13
Training loss: 2.057400703430176
Validation loss: 1.9858196473890735

Epoch: 37| Step: 0
Training loss: 2.8828125
Validation loss: 1.9985456197492537

Epoch: 6| Step: 1
Training loss: 2.3302597999572754
Validation loss: 1.9972794107211533

Epoch: 6| Step: 2
Training loss: 2.171830177307129
Validation loss: 2.0027421264238257

Epoch: 6| Step: 3
Training loss: 1.5926378965377808
Validation loss: 2.0009735989314255

Epoch: 6| Step: 4
Training loss: 2.404888153076172
Validation loss: 1.97985359802041

Epoch: 6| Step: 5
Training loss: 2.7147722244262695
Validation loss: 1.995453530742276

Epoch: 6| Step: 6
Training loss: 2.788558006286621
Validation loss: 1.9952802593990038

Epoch: 6| Step: 7
Training loss: 2.6008124351501465
Validation loss: 1.987840703738633

Epoch: 6| Step: 8
Training loss: 2.2730553150177
Validation loss: 1.99379188142797

Epoch: 6| Step: 9
Training loss: 2.0840351581573486
Validation loss: 1.9761653202836231

Epoch: 6| Step: 10
Training loss: 2.5606961250305176
Validation loss: 2.0009540742443455

Epoch: 6| Step: 11
Training loss: 2.426377534866333
Validation loss: 1.9899080517471477

Epoch: 6| Step: 12
Training loss: 1.9625359773635864
Validation loss: 1.9915381157270042

Epoch: 6| Step: 13
Training loss: 1.717775583267212
Validation loss: 1.978248808973579

Epoch: 38| Step: 0
Training loss: 2.8683996200561523
Validation loss: 1.9876968014624812

Epoch: 6| Step: 1
Training loss: 2.928565502166748
Validation loss: 1.979625399394702

Epoch: 6| Step: 2
Training loss: 2.721015453338623
Validation loss: 1.980617307847546

Epoch: 6| Step: 3
Training loss: 2.6221184730529785
Validation loss: 1.987618548895723

Epoch: 6| Step: 4
Training loss: 2.6478333473205566
Validation loss: 1.9889856410282913

Epoch: 6| Step: 5
Training loss: 2.411614418029785
Validation loss: 1.9846854825173654

Epoch: 6| Step: 6
Training loss: 1.8384919166564941
Validation loss: 1.9901092924097532

Epoch: 6| Step: 7
Training loss: 2.7931771278381348
Validation loss: 1.9943964173716884

Epoch: 6| Step: 8
Training loss: 1.8090524673461914
Validation loss: 1.986962285093082

Epoch: 6| Step: 9
Training loss: 1.89509117603302
Validation loss: 1.9899262715411443

Epoch: 6| Step: 10
Training loss: 1.8801524639129639
Validation loss: 1.975203178262198

Epoch: 6| Step: 11
Training loss: 2.336796283721924
Validation loss: 1.981981497938915

Epoch: 6| Step: 12
Training loss: 1.9928315877914429
Validation loss: 1.981893306137413

Epoch: 6| Step: 13
Training loss: 1.5958278179168701
Validation loss: 1.9876070612220353

Epoch: 39| Step: 0
Training loss: 1.6931772232055664
Validation loss: 1.9833254352692635

Epoch: 6| Step: 1
Training loss: 2.3111114501953125
Validation loss: 1.9859569047086982

Epoch: 6| Step: 2
Training loss: 1.8147870302200317
Validation loss: 1.9734363607181016

Epoch: 6| Step: 3
Training loss: 2.916759967803955
Validation loss: 1.9758183007599206

Epoch: 6| Step: 4
Training loss: 2.0152931213378906
Validation loss: 1.9715800618612638

Epoch: 6| Step: 5
Training loss: 3.1945695877075195
Validation loss: 1.973402295061337

Epoch: 6| Step: 6
Training loss: 2.7489349842071533
Validation loss: 1.972220988042893

Epoch: 6| Step: 7
Training loss: 2.7408955097198486
Validation loss: 1.981485430912305

Epoch: 6| Step: 8
Training loss: 2.5285089015960693
Validation loss: 1.9715214390908518

Epoch: 6| Step: 9
Training loss: 1.943586826324463
Validation loss: 1.9728012097779142

Epoch: 6| Step: 10
Training loss: 2.5892562866210938
Validation loss: 1.9840271498567315

Epoch: 6| Step: 11
Training loss: 2.0306336879730225
Validation loss: 1.9653322799231416

Epoch: 6| Step: 12
Training loss: 1.9839203357696533
Validation loss: 1.9732601578517626

Epoch: 6| Step: 13
Training loss: 1.6842929124832153
Validation loss: 1.9661030525802283

Epoch: 40| Step: 0
Training loss: 2.4844703674316406
Validation loss: 1.9618164800828504

Epoch: 6| Step: 1
Training loss: 2.3269007205963135
Validation loss: 1.978136561250174

Epoch: 6| Step: 2
Training loss: 2.306368827819824
Validation loss: 1.9735854966666109

Epoch: 6| Step: 3
Training loss: 2.1741013526916504
Validation loss: 1.9677730811539518

Epoch: 6| Step: 4
Training loss: 2.9446020126342773
Validation loss: 1.9675711406174528

Epoch: 6| Step: 5
Training loss: 2.2099828720092773
Validation loss: 1.9700738588968914

Epoch: 6| Step: 6
Training loss: 1.5724011659622192
Validation loss: 1.9617327874706638

Epoch: 6| Step: 7
Training loss: 1.8511223793029785
Validation loss: 1.96130923814671

Epoch: 6| Step: 8
Training loss: 2.463460683822632
Validation loss: 1.9589644196212932

Epoch: 6| Step: 9
Training loss: 2.2331595420837402
Validation loss: 1.96616804727944

Epoch: 6| Step: 10
Training loss: 2.729309320449829
Validation loss: 1.9602257205593971

Epoch: 6| Step: 11
Training loss: 2.2555689811706543
Validation loss: 1.9696540294154998

Epoch: 6| Step: 12
Training loss: 2.251112937927246
Validation loss: 1.9596283846004035

Epoch: 6| Step: 13
Training loss: 3.0136637687683105
Validation loss: 1.977869192759196

Epoch: 41| Step: 0
Training loss: 2.2522473335266113
Validation loss: 1.980224658084172

Epoch: 6| Step: 1
Training loss: 2.184605121612549
Validation loss: 1.9691663608756116

Epoch: 6| Step: 2
Training loss: 2.7740471363067627
Validation loss: 1.9743435985298567

Epoch: 6| Step: 3
Training loss: 2.181776523590088
Validation loss: 1.9653082432285431

Epoch: 6| Step: 4
Training loss: 2.4216935634613037
Validation loss: 1.9751018144751107

Epoch: 6| Step: 5
Training loss: 2.821044445037842
Validation loss: 1.9755908648173015

Epoch: 6| Step: 6
Training loss: 1.7906734943389893
Validation loss: 1.968043206840433

Epoch: 6| Step: 7
Training loss: 2.1527228355407715
Validation loss: 1.9601323476401709

Epoch: 6| Step: 8
Training loss: 2.4265379905700684
Validation loss: 1.9809499607291272

Epoch: 6| Step: 9
Training loss: 2.4265871047973633
Validation loss: 1.9695748411199099

Epoch: 6| Step: 10
Training loss: 2.1338586807250977
Validation loss: 1.9823728325546428

Epoch: 6| Step: 11
Training loss: 2.1287100315093994
Validation loss: 1.9750794236378004

Epoch: 6| Step: 12
Training loss: 2.6092774868011475
Validation loss: 1.9810750266557098

Epoch: 6| Step: 13
Training loss: 1.8135157823562622
Validation loss: 1.9808292799098517

Epoch: 42| Step: 0
Training loss: 2.5992393493652344
Validation loss: 1.9710115271229898

Epoch: 6| Step: 1
Training loss: 2.1714420318603516
Validation loss: 1.9781338604547645

Epoch: 6| Step: 2
Training loss: 2.1025991439819336
Validation loss: 1.9792889856523084

Epoch: 6| Step: 3
Training loss: 2.494511604309082
Validation loss: 1.963207673001033

Epoch: 6| Step: 4
Training loss: 2.2236740589141846
Validation loss: 1.9790864170238536

Epoch: 6| Step: 5
Training loss: 2.699601650238037
Validation loss: 1.9694514902689124

Epoch: 6| Step: 6
Training loss: 2.2735648155212402
Validation loss: 1.9740228832408946

Epoch: 6| Step: 7
Training loss: 1.5535987615585327
Validation loss: 1.9737831507959673

Epoch: 6| Step: 8
Training loss: 2.577214241027832
Validation loss: 1.9859308811926073

Epoch: 6| Step: 9
Training loss: 2.197277545928955
Validation loss: 1.9856434047863047

Epoch: 6| Step: 10
Training loss: 2.2366087436676025
Validation loss: 1.9753616881626908

Epoch: 6| Step: 11
Training loss: 2.2523279190063477
Validation loss: 1.9891688285335418

Epoch: 6| Step: 12
Training loss: 2.435272693634033
Validation loss: 1.9814927013971473

Epoch: 6| Step: 13
Training loss: 2.5977776050567627
Validation loss: 1.9736919685076642

Epoch: 43| Step: 0
Training loss: 3.5664572715759277
Validation loss: 1.9802822912892988

Epoch: 6| Step: 1
Training loss: 1.979649305343628
Validation loss: 1.9840583519269062

Epoch: 6| Step: 2
Training loss: 1.9280166625976562
Validation loss: 1.975137907971618

Epoch: 6| Step: 3
Training loss: 2.0747199058532715
Validation loss: 1.9713772817324566

Epoch: 6| Step: 4
Training loss: 1.8078367710113525
Validation loss: 1.9852609890763477

Epoch: 6| Step: 5
Training loss: 2.8958325386047363
Validation loss: 1.9972879079080397

Epoch: 6| Step: 6
Training loss: 1.9001832008361816
Validation loss: 1.9681709261350735

Epoch: 6| Step: 7
Training loss: 1.985090970993042
Validation loss: 1.9794313164167507

Epoch: 6| Step: 8
Training loss: 2.8470263481140137
Validation loss: 1.9737100062831756

Epoch: 6| Step: 9
Training loss: 2.3028268814086914
Validation loss: 1.9792825816780009

Epoch: 6| Step: 10
Training loss: 2.6851744651794434
Validation loss: 1.9739696146339498

Epoch: 6| Step: 11
Training loss: 1.8444312810897827
Validation loss: 1.973377348274313

Epoch: 6| Step: 12
Training loss: 2.2131853103637695
Validation loss: 1.9734910547092397

Epoch: 6| Step: 13
Training loss: 2.1530563831329346
Validation loss: 1.9723809944686068

Epoch: 44| Step: 0
Training loss: 2.1417341232299805
Validation loss: 1.9834584779636835

Epoch: 6| Step: 1
Training loss: 2.69472336769104
Validation loss: 1.9813502680870794

Epoch: 6| Step: 2
Training loss: 2.153242588043213
Validation loss: 1.9804916369017733

Epoch: 6| Step: 3
Training loss: 1.93473219871521
Validation loss: 1.979160806184174

Epoch: 6| Step: 4
Training loss: 2.002746820449829
Validation loss: 1.9812346760944655

Epoch: 6| Step: 5
Training loss: 2.507873058319092
Validation loss: 1.9864463049878356

Epoch: 6| Step: 6
Training loss: 2.480309247970581
Validation loss: 1.9865829290882233

Epoch: 6| Step: 7
Training loss: 2.3959946632385254
Validation loss: 1.9811409340109876

Epoch: 6| Step: 8
Training loss: 2.6170105934143066
Validation loss: 1.9865118457425026

Epoch: 6| Step: 9
Training loss: 2.035654067993164
Validation loss: 1.9850812176222443

Epoch: 6| Step: 10
Training loss: 2.6316823959350586
Validation loss: 1.9972687998125631

Epoch: 6| Step: 11
Training loss: 1.8919496536254883
Validation loss: 1.9807174462144093

Epoch: 6| Step: 12
Training loss: 2.4816598892211914
Validation loss: 1.981943025383898

Epoch: 6| Step: 13
Training loss: 2.182292938232422
Validation loss: 1.9938576682921378

Epoch: 45| Step: 0
Training loss: 2.6592862606048584
Validation loss: 1.9880214788580453

Epoch: 6| Step: 1
Training loss: 2.3323440551757812
Validation loss: 1.977031805182016

Epoch: 6| Step: 2
Training loss: 1.9663057327270508
Validation loss: 1.9702586563684608

Epoch: 6| Step: 3
Training loss: 2.4566216468811035
Validation loss: 1.974621529220253

Epoch: 6| Step: 4
Training loss: 2.447233200073242
Validation loss: 1.9724286397298176

Epoch: 6| Step: 5
Training loss: 2.2458300590515137
Validation loss: 1.9731253244543587

Epoch: 6| Step: 6
Training loss: 2.314793825149536
Validation loss: 1.972479776669574

Epoch: 6| Step: 7
Training loss: 2.117781162261963
Validation loss: 1.973863793957618

Epoch: 6| Step: 8
Training loss: 2.4986305236816406
Validation loss: 1.968845199513179

Epoch: 6| Step: 9
Training loss: 2.3211686611175537
Validation loss: 1.9650498154342815

Epoch: 6| Step: 10
Training loss: 2.0282480716705322
Validation loss: 1.9632621196008497

Epoch: 6| Step: 11
Training loss: 2.543321132659912
Validation loss: 1.951494812965393

Epoch: 6| Step: 12
Training loss: 2.2174949645996094
Validation loss: 1.9641055035334762

Epoch: 6| Step: 13
Training loss: 1.9377375841140747
Validation loss: 1.9643585117914344

Epoch: 46| Step: 0
Training loss: 1.9939242601394653
Validation loss: 1.9640969896829257

Epoch: 6| Step: 1
Training loss: 2.0198166370391846
Validation loss: 1.9582755514370498

Epoch: 6| Step: 2
Training loss: 2.1761817932128906
Validation loss: 1.9587465768219323

Epoch: 6| Step: 3
Training loss: 2.7156264781951904
Validation loss: 1.967381699110872

Epoch: 6| Step: 4
Training loss: 2.289100170135498
Validation loss: 1.9692750502658147

Epoch: 6| Step: 5
Training loss: 2.533405303955078
Validation loss: 1.9633500781110538

Epoch: 6| Step: 6
Training loss: 2.3058876991271973
Validation loss: 1.95585282387272

Epoch: 6| Step: 7
Training loss: 2.3655591011047363
Validation loss: 1.95669585915022

Epoch: 6| Step: 8
Training loss: 2.0918712615966797
Validation loss: 1.9683376922402331

Epoch: 6| Step: 9
Training loss: 1.8388746976852417
Validation loss: 1.979628247599448

Epoch: 6| Step: 10
Training loss: 2.82475209236145
Validation loss: 1.961733953927153

Epoch: 6| Step: 11
Training loss: 2.215721607208252
Validation loss: 1.9718748805343465

Epoch: 6| Step: 12
Training loss: 2.3726396560668945
Validation loss: 1.9735913366399787

Epoch: 6| Step: 13
Training loss: 2.367223024368286
Validation loss: 1.9542132833952546

Epoch: 47| Step: 0
Training loss: 2.920755386352539
Validation loss: 1.9739476916610554

Epoch: 6| Step: 1
Training loss: 2.14479660987854
Validation loss: 1.9599495241718907

Epoch: 6| Step: 2
Training loss: 2.94417142868042
Validation loss: 1.9647233268266082

Epoch: 6| Step: 3
Training loss: 2.8809595108032227
Validation loss: 1.966679576904543

Epoch: 6| Step: 4
Training loss: 2.7873923778533936
Validation loss: 1.9678059060086486

Epoch: 6| Step: 5
Training loss: 2.5244994163513184
Validation loss: 1.962100882684031

Epoch: 6| Step: 6
Training loss: 2.2077012062072754
Validation loss: 1.9574239048906552

Epoch: 6| Step: 7
Training loss: 2.1792025566101074
Validation loss: 1.9636890452395204

Epoch: 6| Step: 8
Training loss: 2.0585358142852783
Validation loss: 1.9649165407303841

Epoch: 6| Step: 9
Training loss: 1.167091727256775
Validation loss: 1.9715954437050769

Epoch: 6| Step: 10
Training loss: 1.7368587255477905
Validation loss: 1.9681350133752311

Epoch: 6| Step: 11
Training loss: 1.9934418201446533
Validation loss: 1.9718398637669061

Epoch: 6| Step: 12
Training loss: 2.350376605987549
Validation loss: 1.9860175745461577

Epoch: 6| Step: 13
Training loss: 2.0188188552856445
Validation loss: 1.9677455912354171

Epoch: 48| Step: 0
Training loss: 2.5859079360961914
Validation loss: 1.9898296081891624

Epoch: 6| Step: 1
Training loss: 1.964208722114563
Validation loss: 1.9807700598111717

Epoch: 6| Step: 2
Training loss: 2.214399576187134
Validation loss: 1.960166609415444

Epoch: 6| Step: 3
Training loss: 2.68050479888916
Validation loss: 1.95535094763643

Epoch: 6| Step: 4
Training loss: 2.2211170196533203
Validation loss: 1.9618848613513413

Epoch: 6| Step: 5
Training loss: 2.2908997535705566
Validation loss: 1.965068478738108

Epoch: 6| Step: 6
Training loss: 2.122419595718384
Validation loss: 1.9615439240650465

Epoch: 6| Step: 7
Training loss: 2.9474220275878906
Validation loss: 1.9581909051505468

Epoch: 6| Step: 8
Training loss: 2.0085535049438477
Validation loss: 1.9629216976063226

Epoch: 6| Step: 9
Training loss: 1.896641492843628
Validation loss: 1.9643291017060638

Epoch: 6| Step: 10
Training loss: 3.0036442279815674
Validation loss: 1.9693504507823656

Epoch: 6| Step: 11
Training loss: 1.629638910293579
Validation loss: 1.9596157099611016

Epoch: 6| Step: 12
Training loss: 2.4200823307037354
Validation loss: 1.9595146550927112

Epoch: 6| Step: 13
Training loss: 1.8087667226791382
Validation loss: 1.969251440417382

Epoch: 49| Step: 0
Training loss: 2.1931185722351074
Validation loss: 1.9559893531184043

Epoch: 6| Step: 1
Training loss: 1.9151396751403809
Validation loss: 1.9748945492570118

Epoch: 6| Step: 2
Training loss: 2.909853219985962
Validation loss: 1.9697111639925229

Epoch: 6| Step: 3
Training loss: 2.4780197143554688
Validation loss: 1.9741390264162453

Epoch: 6| Step: 4
Training loss: 2.2630412578582764
Validation loss: 1.9693629985214562

Epoch: 6| Step: 5
Training loss: 2.016895294189453
Validation loss: 1.9744380417690481

Epoch: 6| Step: 6
Training loss: 2.790531635284424
Validation loss: 1.9738143259479153

Epoch: 6| Step: 7
Training loss: 2.6413912773132324
Validation loss: 1.9765791264913415

Epoch: 6| Step: 8
Training loss: 2.540767192840576
Validation loss: 1.9871430973852835

Epoch: 6| Step: 9
Training loss: 2.099740982055664
Validation loss: 1.9706894390044674

Epoch: 6| Step: 10
Training loss: 1.3945204019546509
Validation loss: 1.9800238801587013

Epoch: 6| Step: 11
Training loss: 2.547517776489258
Validation loss: 1.9797690299249464

Epoch: 6| Step: 12
Training loss: 1.86726713180542
Validation loss: 1.9683186097811627

Epoch: 6| Step: 13
Training loss: 2.1136012077331543
Validation loss: 1.9718446218839256

Epoch: 50| Step: 0
Training loss: 2.3791041374206543
Validation loss: 1.9698885922790856

Epoch: 6| Step: 1
Training loss: 2.179473876953125
Validation loss: 1.9686387995237946

Epoch: 6| Step: 2
Training loss: 1.875863790512085
Validation loss: 1.9614991834086757

Epoch: 6| Step: 3
Training loss: 2.690521001815796
Validation loss: 1.969828567197246

Epoch: 6| Step: 4
Training loss: 2.253565788269043
Validation loss: 1.9716926941307642

Epoch: 6| Step: 5
Training loss: 2.467588424682617
Validation loss: 1.9793642900323356

Epoch: 6| Step: 6
Training loss: 1.9519444704055786
Validation loss: 1.9781460018568142

Epoch: 6| Step: 7
Training loss: 2.3309226036071777
Validation loss: 1.9728947711247269

Epoch: 6| Step: 8
Training loss: 2.358549118041992
Validation loss: 1.9812604868283836

Epoch: 6| Step: 9
Training loss: 2.5145223140716553
Validation loss: 1.9723178904543641

Epoch: 6| Step: 10
Training loss: 2.120131015777588
Validation loss: 1.9695348854987853

Epoch: 6| Step: 11
Training loss: 1.7261180877685547
Validation loss: 1.9665671868990826

Epoch: 6| Step: 12
Training loss: 2.3026061058044434
Validation loss: 1.9599621821475286

Epoch: 6| Step: 13
Training loss: 2.9642698764801025
Validation loss: 1.9690589212602185

Epoch: 51| Step: 0
Training loss: 2.03709077835083
Validation loss: 1.972412327284454

Epoch: 6| Step: 1
Training loss: 1.887529730796814
Validation loss: 1.9645365207426009

Epoch: 6| Step: 2
Training loss: 2.690028429031372
Validation loss: 1.9556088063024706

Epoch: 6| Step: 3
Training loss: 2.1440134048461914
Validation loss: 1.982488360456241

Epoch: 6| Step: 4
Training loss: 2.3281302452087402
Validation loss: 1.9556035764755741

Epoch: 6| Step: 5
Training loss: 2.854945659637451
Validation loss: 1.9511322962340487

Epoch: 6| Step: 6
Training loss: 1.7163126468658447
Validation loss: 1.9463247278685212

Epoch: 6| Step: 7
Training loss: 1.9810295104980469
Validation loss: 1.9527984665286156

Epoch: 6| Step: 8
Training loss: 2.026231288909912
Validation loss: 1.9491430713284401

Epoch: 6| Step: 9
Training loss: 2.007944107055664
Validation loss: 1.9409074629506757

Epoch: 6| Step: 10
Training loss: 2.760275363922119
Validation loss: 1.9559480477404851

Epoch: 6| Step: 11
Training loss: 2.6287641525268555
Validation loss: 1.9423838610290198

Epoch: 6| Step: 12
Training loss: 2.2779312133789062
Validation loss: 1.9413387339602235

Epoch: 6| Step: 13
Training loss: 2.6426286697387695
Validation loss: 1.951156065028201

Epoch: 52| Step: 0
Training loss: 2.4337635040283203
Validation loss: 1.9514355159574939

Epoch: 6| Step: 1
Training loss: 3.046076774597168
Validation loss: 1.9514067916459934

Epoch: 6| Step: 2
Training loss: 2.154175043106079
Validation loss: 1.9564540616927608

Epoch: 6| Step: 3
Training loss: 2.532914161682129
Validation loss: 1.9495361735743861

Epoch: 6| Step: 4
Training loss: 1.9495642185211182
Validation loss: 1.9469721060927196

Epoch: 6| Step: 5
Training loss: 1.7868316173553467
Validation loss: 1.951325184555464

Epoch: 6| Step: 6
Training loss: 2.2304935455322266
Validation loss: 1.9517321022607947

Epoch: 6| Step: 7
Training loss: 1.9418516159057617
Validation loss: 1.9600577469794982

Epoch: 6| Step: 8
Training loss: 1.9329893589019775
Validation loss: 1.9659302003922001

Epoch: 6| Step: 9
Training loss: 2.4957451820373535
Validation loss: 1.960624087241388

Epoch: 6| Step: 10
Training loss: 2.4246511459350586
Validation loss: 1.9503312546719787

Epoch: 6| Step: 11
Training loss: 1.7510433197021484
Validation loss: 1.9579279679124073

Epoch: 6| Step: 12
Training loss: 2.6178956031799316
Validation loss: 1.962218887062483

Epoch: 6| Step: 13
Training loss: 2.433894634246826
Validation loss: 1.9526620295739943

Epoch: 53| Step: 0
Training loss: 3.019277572631836
Validation loss: 1.9633603993282522

Epoch: 6| Step: 1
Training loss: 2.77937388420105
Validation loss: 1.9683686969100789

Epoch: 6| Step: 2
Training loss: 1.7134026288986206
Validation loss: 1.9542961505151564

Epoch: 6| Step: 3
Training loss: 1.5635151863098145
Validation loss: 1.9537120403782013

Epoch: 6| Step: 4
Training loss: 2.350783586502075
Validation loss: 1.9831735857071415

Epoch: 6| Step: 5
Training loss: 2.170534610748291
Validation loss: 1.9648605533825454

Epoch: 6| Step: 6
Training loss: 2.6100149154663086
Validation loss: 1.973373846341205

Epoch: 6| Step: 7
Training loss: 2.0123140811920166
Validation loss: 1.9672162481533584

Epoch: 6| Step: 8
Training loss: 2.3768787384033203
Validation loss: 1.9643638300639328

Epoch: 6| Step: 9
Training loss: 2.023526906967163
Validation loss: 1.9715589746352165

Epoch: 6| Step: 10
Training loss: 2.3468756675720215
Validation loss: 1.968304552057738

Epoch: 6| Step: 11
Training loss: 1.8392503261566162
Validation loss: 1.9805823551711215

Epoch: 6| Step: 12
Training loss: 2.471412420272827
Validation loss: 1.9713993021236953

Epoch: 6| Step: 13
Training loss: 2.6410179138183594
Validation loss: 1.9691877518930743

Epoch: 54| Step: 0
Training loss: 2.6020073890686035
Validation loss: 1.968806762849131

Epoch: 6| Step: 1
Training loss: 1.895206093788147
Validation loss: 1.96148592938659

Epoch: 6| Step: 2
Training loss: 1.8281702995300293
Validation loss: 1.9714770752896544

Epoch: 6| Step: 3
Training loss: 2.14497447013855
Validation loss: 1.9669310815872685

Epoch: 6| Step: 4
Training loss: 2.5478668212890625
Validation loss: 1.9576014395683043

Epoch: 6| Step: 5
Training loss: 2.82753324508667
Validation loss: 1.9630109661368913

Epoch: 6| Step: 6
Training loss: 2.0718135833740234
Validation loss: 1.9631375292296052

Epoch: 6| Step: 7
Training loss: 2.0638628005981445
Validation loss: 1.9595011357338197

Epoch: 6| Step: 8
Training loss: 1.8241896629333496
Validation loss: 1.9565735991283129

Epoch: 6| Step: 9
Training loss: 2.1979355812072754
Validation loss: 1.950306515539846

Epoch: 6| Step: 10
Training loss: 2.1863646507263184
Validation loss: 1.9523693156498734

Epoch: 6| Step: 11
Training loss: 2.177544116973877
Validation loss: 1.954489779728715

Epoch: 6| Step: 12
Training loss: 2.9900031089782715
Validation loss: 1.949848134030578

Epoch: 6| Step: 13
Training loss: 2.1532187461853027
Validation loss: 1.969648238151304

Epoch: 55| Step: 0
Training loss: 2.1542680263519287
Validation loss: 1.9540181159973145

Epoch: 6| Step: 1
Training loss: 1.8628838062286377
Validation loss: 1.9454176605388682

Epoch: 6| Step: 2
Training loss: 2.7773027420043945
Validation loss: 1.94521285897942

Epoch: 6| Step: 3
Training loss: 1.769805669784546
Validation loss: 1.9494161105925036

Epoch: 6| Step: 4
Training loss: 1.8475075960159302
Validation loss: 1.9516190944179412

Epoch: 6| Step: 5
Training loss: 2.345346450805664
Validation loss: 1.9503316648544804

Epoch: 6| Step: 6
Training loss: 2.6613407135009766
Validation loss: 1.9479935707584504

Epoch: 6| Step: 7
Training loss: 2.584214210510254
Validation loss: 1.9581987498908915

Epoch: 6| Step: 8
Training loss: 1.7217825651168823
Validation loss: 1.9557268055536414

Epoch: 6| Step: 9
Training loss: 2.394695281982422
Validation loss: 1.9463557427929294

Epoch: 6| Step: 10
Training loss: 2.6326041221618652
Validation loss: 1.9445996412666895

Epoch: 6| Step: 11
Training loss: 2.1651439666748047
Validation loss: 1.9586220351598596

Epoch: 6| Step: 12
Training loss: 2.2969613075256348
Validation loss: 1.9453732147011706

Epoch: 6| Step: 13
Training loss: 2.4763429164886475
Validation loss: 1.9518224206022037

Epoch: 56| Step: 0
Training loss: 1.6633038520812988
Validation loss: 1.9442872616552538

Epoch: 6| Step: 1
Training loss: 2.622467517852783
Validation loss: 1.948125054759364

Epoch: 6| Step: 2
Training loss: 2.1978261470794678
Validation loss: 1.9477986827973397

Epoch: 6| Step: 3
Training loss: 2.242645263671875
Validation loss: 1.9495152350394958

Epoch: 6| Step: 4
Training loss: 2.4758191108703613
Validation loss: 1.9446099317202004

Epoch: 6| Step: 5
Training loss: 2.4474358558654785
Validation loss: 1.943411773250949

Epoch: 6| Step: 6
Training loss: 2.068235397338867
Validation loss: 1.942096975541884

Epoch: 6| Step: 7
Training loss: 1.7728254795074463
Validation loss: 1.9529066598543556

Epoch: 6| Step: 8
Training loss: 2.9638397693634033
Validation loss: 1.9392049594592022

Epoch: 6| Step: 9
Training loss: 2.119429588317871
Validation loss: 1.9446613250240203

Epoch: 6| Step: 10
Training loss: 2.761348247528076
Validation loss: 1.9556567681733

Epoch: 6| Step: 11
Training loss: 2.3215160369873047
Validation loss: 1.9518256430984826

Epoch: 6| Step: 12
Training loss: 1.5470678806304932
Validation loss: 1.9602789237935057

Epoch: 6| Step: 13
Training loss: 2.217357635498047
Validation loss: 1.9410269068133446

Epoch: 57| Step: 0
Training loss: 2.5817599296569824
Validation loss: 1.9620022799379082

Epoch: 6| Step: 1
Training loss: 2.504680633544922
Validation loss: 1.953776636431294

Epoch: 6| Step: 2
Training loss: 2.272197723388672
Validation loss: 1.9460303270688621

Epoch: 6| Step: 3
Training loss: 2.391890287399292
Validation loss: 1.9541380431062432

Epoch: 6| Step: 4
Training loss: 2.490262508392334
Validation loss: 1.9637049321205384

Epoch: 6| Step: 5
Training loss: 2.4024548530578613
Validation loss: 1.9500996822951941

Epoch: 6| Step: 6
Training loss: 1.819559097290039
Validation loss: 1.9478960165413477

Epoch: 6| Step: 7
Training loss: 2.6170568466186523
Validation loss: 1.9366382527095016

Epoch: 6| Step: 8
Training loss: 1.7347395420074463
Validation loss: 1.9511768561537548

Epoch: 6| Step: 9
Training loss: 1.8282759189605713
Validation loss: 1.9476669616596674

Epoch: 6| Step: 10
Training loss: 1.9314744472503662
Validation loss: 1.9315508770686325

Epoch: 6| Step: 11
Training loss: 2.047196388244629
Validation loss: 1.9637595581751999

Epoch: 6| Step: 12
Training loss: 2.4740653038024902
Validation loss: 1.9496520001401183

Epoch: 6| Step: 13
Training loss: 2.2662971019744873
Validation loss: 1.9645709709454608

Epoch: 58| Step: 0
Training loss: 1.8809213638305664
Validation loss: 1.9444663729718936

Epoch: 6| Step: 1
Training loss: 2.3117241859436035
Validation loss: 1.956179718817434

Epoch: 6| Step: 2
Training loss: 1.9041681289672852
Validation loss: 1.9398157340224071

Epoch: 6| Step: 3
Training loss: 2.3496785163879395
Validation loss: 1.947052655681487

Epoch: 6| Step: 4
Training loss: 2.355158805847168
Validation loss: 1.959222319305584

Epoch: 6| Step: 5
Training loss: 3.2274699211120605
Validation loss: 1.9522756940575057

Epoch: 6| Step: 6
Training loss: 2.8478174209594727
Validation loss: 1.9455170682681504

Epoch: 6| Step: 7
Training loss: 2.0008249282836914
Validation loss: 1.937527738591676

Epoch: 6| Step: 8
Training loss: 2.271851062774658
Validation loss: 1.9449764708037018

Epoch: 6| Step: 9
Training loss: 2.1143956184387207
Validation loss: 1.9399101477797314

Epoch: 6| Step: 10
Training loss: 2.5893495082855225
Validation loss: 1.9273375593205935

Epoch: 6| Step: 11
Training loss: 2.001086711883545
Validation loss: 1.9358418423642394

Epoch: 6| Step: 12
Training loss: 1.4997644424438477
Validation loss: 1.9464051467116161

Epoch: 6| Step: 13
Training loss: 1.944352626800537
Validation loss: 1.9474504878444057

Epoch: 59| Step: 0
Training loss: 2.169238567352295
Validation loss: 1.965740047475343

Epoch: 6| Step: 1
Training loss: 2.253387928009033
Validation loss: 1.9449610902417092

Epoch: 6| Step: 2
Training loss: 2.566589593887329
Validation loss: 1.937592520508715

Epoch: 6| Step: 3
Training loss: 2.3235397338867188
Validation loss: 1.9338327864164948

Epoch: 6| Step: 4
Training loss: 2.48765230178833
Validation loss: 1.9492499443792528

Epoch: 6| Step: 5
Training loss: 1.9076900482177734
Validation loss: 1.950123301116369

Epoch: 6| Step: 6
Training loss: 2.3584821224212646
Validation loss: 1.9648453702208817

Epoch: 6| Step: 7
Training loss: 2.5054593086242676
Validation loss: 1.9527934007747199

Epoch: 6| Step: 8
Training loss: 1.790862798690796
Validation loss: 1.9487874674540695

Epoch: 6| Step: 9
Training loss: 1.7227190732955933
Validation loss: 1.9511295480112876

Epoch: 6| Step: 10
Training loss: 2.154330253601074
Validation loss: 1.9562836449633363

Epoch: 6| Step: 11
Training loss: 2.1233344078063965
Validation loss: 1.9617746478767806

Epoch: 6| Step: 12
Training loss: 2.7902936935424805
Validation loss: 1.9578734495306527

Epoch: 6| Step: 13
Training loss: 2.0066635608673096
Validation loss: 1.9373956418806506

Epoch: 60| Step: 0
Training loss: 1.6724165678024292
Validation loss: 1.9355820378949564

Epoch: 6| Step: 1
Training loss: 2.4283499717712402
Validation loss: 1.9598505317523915

Epoch: 6| Step: 2
Training loss: 2.475587844848633
Validation loss: 1.9415714458752704

Epoch: 6| Step: 3
Training loss: 2.714564561843872
Validation loss: 1.949982604672832

Epoch: 6| Step: 4
Training loss: 1.8942629098892212
Validation loss: 1.9315600638748498

Epoch: 6| Step: 5
Training loss: 2.170485019683838
Validation loss: 1.9381260192522438

Epoch: 6| Step: 6
Training loss: 2.5825352668762207
Validation loss: 1.941562291114561

Epoch: 6| Step: 7
Training loss: 2.3916337490081787
Validation loss: 1.9451853036880493

Epoch: 6| Step: 8
Training loss: 1.982981562614441
Validation loss: 1.9582024620425316

Epoch: 6| Step: 9
Training loss: 1.9368505477905273
Validation loss: 1.9291203547549505

Epoch: 6| Step: 10
Training loss: 1.998087763786316
Validation loss: 1.9338242866659676

Epoch: 6| Step: 11
Training loss: 2.1988682746887207
Validation loss: 1.9630214603998328

Epoch: 6| Step: 12
Training loss: 2.1862523555755615
Validation loss: 1.9421396614402853

Epoch: 6| Step: 13
Training loss: 2.718839645385742
Validation loss: 1.9470769487401491

Epoch: 61| Step: 0
Training loss: 2.0740153789520264
Validation loss: 1.9385683600620558

Epoch: 6| Step: 1
Training loss: 1.5299981832504272
Validation loss: 1.9454517467047578

Epoch: 6| Step: 2
Training loss: 2.2003798484802246
Validation loss: 1.9305390260552848

Epoch: 6| Step: 3
Training loss: 2.4130897521972656
Validation loss: 1.9353763723886142

Epoch: 6| Step: 4
Training loss: 2.6113338470458984
Validation loss: 1.9369319344079623

Epoch: 6| Step: 5
Training loss: 2.1435375213623047
Validation loss: 1.9461999580424318

Epoch: 6| Step: 6
Training loss: 2.5051724910736084
Validation loss: 1.9327522221431936

Epoch: 6| Step: 7
Training loss: 1.9011619091033936
Validation loss: 1.9379756758289952

Epoch: 6| Step: 8
Training loss: 2.4631564617156982
Validation loss: 1.9460413802054621

Epoch: 6| Step: 9
Training loss: 1.5137660503387451
Validation loss: 1.9470112003305906

Epoch: 6| Step: 10
Training loss: 2.9569153785705566
Validation loss: 1.9487389979823944

Epoch: 6| Step: 11
Training loss: 2.0935425758361816
Validation loss: 1.9223579745138846

Epoch: 6| Step: 12
Training loss: 2.644301414489746
Validation loss: 1.9260074207859654

Epoch: 6| Step: 13
Training loss: 2.0967249870300293
Validation loss: 1.9360310134067331

Epoch: 62| Step: 0
Training loss: 1.7313642501831055
Validation loss: 1.9438123523548085

Epoch: 6| Step: 1
Training loss: 2.0207107067108154
Validation loss: 1.9477025796008367

Epoch: 6| Step: 2
Training loss: 2.4401779174804688
Validation loss: 1.931210494810535

Epoch: 6| Step: 3
Training loss: 2.00211238861084
Validation loss: 1.917546776033217

Epoch: 6| Step: 4
Training loss: 2.107771396636963
Validation loss: 1.9302694041241881

Epoch: 6| Step: 5
Training loss: 1.8892638683319092
Validation loss: 1.9406832341224916

Epoch: 6| Step: 6
Training loss: 2.2862493991851807
Validation loss: 1.9351667306756462

Epoch: 6| Step: 7
Training loss: 2.128756046295166
Validation loss: 1.9213554679706533

Epoch: 6| Step: 8
Training loss: 2.3637282848358154
Validation loss: 1.935742147507206

Epoch: 6| Step: 9
Training loss: 2.7404685020446777
Validation loss: 1.9341681682935326

Epoch: 6| Step: 10
Training loss: 2.9929404258728027
Validation loss: 1.9269244337594638

Epoch: 6| Step: 11
Training loss: 2.6153407096862793
Validation loss: 1.9227272349019204

Epoch: 6| Step: 12
Training loss: 2.123643636703491
Validation loss: 1.9384679768675117

Epoch: 6| Step: 13
Training loss: 1.6902083158493042
Validation loss: 1.9399161748988654

Epoch: 63| Step: 0
Training loss: 2.78515887260437
Validation loss: 1.9325771203605078

Epoch: 6| Step: 1
Training loss: 1.6805496215820312
Validation loss: 1.9334546353227349

Epoch: 6| Step: 2
Training loss: 2.100806713104248
Validation loss: 1.938732062616656

Epoch: 6| Step: 3
Training loss: 2.226747989654541
Validation loss: 1.9315806101727229

Epoch: 6| Step: 4
Training loss: 1.3878741264343262
Validation loss: 1.9370476020279752

Epoch: 6| Step: 5
Training loss: 2.1938018798828125
Validation loss: 1.9449570230258408

Epoch: 6| Step: 6
Training loss: 2.4713354110717773
Validation loss: 1.9378652072721911

Epoch: 6| Step: 7
Training loss: 2.254847526550293
Validation loss: 1.927337202974545

Epoch: 6| Step: 8
Training loss: 2.7216873168945312
Validation loss: 1.9457390218652704

Epoch: 6| Step: 9
Training loss: 2.4108829498291016
Validation loss: 1.9530688947246921

Epoch: 6| Step: 10
Training loss: 1.604293704032898
Validation loss: 1.933951372741371

Epoch: 6| Step: 11
Training loss: 2.4456238746643066
Validation loss: 1.9481079809127315

Epoch: 6| Step: 12
Training loss: 2.4019875526428223
Validation loss: 1.9492094375753914

Epoch: 6| Step: 13
Training loss: 2.561561107635498
Validation loss: 1.937316866331203

Epoch: 64| Step: 0
Training loss: 1.5853265523910522
Validation loss: 1.922940291384215

Epoch: 6| Step: 1
Training loss: 2.009284496307373
Validation loss: 1.9373617415787072

Epoch: 6| Step: 2
Training loss: 2.926309585571289
Validation loss: 1.9345252693340342

Epoch: 6| Step: 3
Training loss: 2.3432435989379883
Validation loss: 1.9492834729533042

Epoch: 6| Step: 4
Training loss: 2.8255019187927246
Validation loss: 1.9506201615897558

Epoch: 6| Step: 5
Training loss: 1.835383415222168
Validation loss: 1.9565475820213236

Epoch: 6| Step: 6
Training loss: 2.289299726486206
Validation loss: 1.9478703596258675

Epoch: 6| Step: 7
Training loss: 2.074125289916992
Validation loss: 1.9662797412564677

Epoch: 6| Step: 8
Training loss: 2.7823598384857178
Validation loss: 1.974653354255102

Epoch: 6| Step: 9
Training loss: 1.870650291442871
Validation loss: 1.975297789419851

Epoch: 6| Step: 10
Training loss: 2.2788052558898926
Validation loss: 1.9614478336867465

Epoch: 6| Step: 11
Training loss: 2.337240219116211
Validation loss: 1.9639836049848987

Epoch: 6| Step: 12
Training loss: 1.6371005773544312
Validation loss: 1.957865092062181

Epoch: 6| Step: 13
Training loss: 2.420839548110962
Validation loss: 1.9591499554213656

Epoch: 65| Step: 0
Training loss: 2.200664520263672
Validation loss: 1.9497684919705955

Epoch: 6| Step: 1
Training loss: 2.139690399169922
Validation loss: 1.944206036547179

Epoch: 6| Step: 2
Training loss: 2.2282304763793945
Validation loss: 1.9466497782737977

Epoch: 6| Step: 3
Training loss: 2.4254398345947266
Validation loss: 1.9591225283120268

Epoch: 6| Step: 4
Training loss: 2.3067665100097656
Validation loss: 1.946595508565185

Epoch: 6| Step: 5
Training loss: 2.8233137130737305
Validation loss: 1.9485392878132481

Epoch: 6| Step: 6
Training loss: 2.2158327102661133
Validation loss: 1.94570372181554

Epoch: 6| Step: 7
Training loss: 2.3040194511413574
Validation loss: 1.9613859602200088

Epoch: 6| Step: 8
Training loss: 2.4550509452819824
Validation loss: 1.945761861339692

Epoch: 6| Step: 9
Training loss: 2.2171530723571777
Validation loss: 1.9434509431162188

Epoch: 6| Step: 10
Training loss: 1.998506784439087
Validation loss: 1.9370141183176348

Epoch: 6| Step: 11
Training loss: 1.751588225364685
Validation loss: 1.9519360591006536

Epoch: 6| Step: 12
Training loss: 2.1776366233825684
Validation loss: 1.966228094152225

Epoch: 6| Step: 13
Training loss: 1.4573220014572144
Validation loss: 1.934438564444101

Epoch: 66| Step: 0
Training loss: 1.6282321214675903
Validation loss: 1.9366050715087562

Epoch: 6| Step: 1
Training loss: 2.319573402404785
Validation loss: 1.9510039924293436

Epoch: 6| Step: 2
Training loss: 2.2494819164276123
Validation loss: 1.941844496675717

Epoch: 6| Step: 3
Training loss: 2.295022487640381
Validation loss: 1.9350724822731429

Epoch: 6| Step: 4
Training loss: 1.9952373504638672
Validation loss: 1.936114889319225

Epoch: 6| Step: 5
Training loss: 2.6739120483398438
Validation loss: 1.9421171654937088

Epoch: 6| Step: 6
Training loss: 2.216569423675537
Validation loss: 1.9532228772358229

Epoch: 6| Step: 7
Training loss: 1.8903014659881592
Validation loss: 1.9376733764525382

Epoch: 6| Step: 8
Training loss: 2.447356700897217
Validation loss: 1.94470517353345

Epoch: 6| Step: 9
Training loss: 1.9583854675292969
Validation loss: 1.9334858489292923

Epoch: 6| Step: 10
Training loss: 1.8310046195983887
Validation loss: 1.9371130184460712

Epoch: 6| Step: 11
Training loss: 2.549367904663086
Validation loss: 1.94042666240405

Epoch: 6| Step: 12
Training loss: 2.278958797454834
Validation loss: 1.959218901972617

Epoch: 6| Step: 13
Training loss: 3.0021860599517822
Validation loss: 1.9349230745787263

Epoch: 67| Step: 0
Training loss: 2.175462245941162
Validation loss: 1.9572285016377766

Epoch: 6| Step: 1
Training loss: 2.548067569732666
Validation loss: 1.9501758749767015

Epoch: 6| Step: 2
Training loss: 1.723160743713379
Validation loss: 1.9532733963381859

Epoch: 6| Step: 3
Training loss: 3.0395426750183105
Validation loss: 1.9487959236227057

Epoch: 6| Step: 4
Training loss: 2.6526527404785156
Validation loss: 1.9545766410007273

Epoch: 6| Step: 5
Training loss: 2.2523045539855957
Validation loss: 1.956174078808036

Epoch: 6| Step: 6
Training loss: 1.6260560750961304
Validation loss: 1.961192545070443

Epoch: 6| Step: 7
Training loss: 1.8718650341033936
Validation loss: 1.9619515570261146

Epoch: 6| Step: 8
Training loss: 2.2138671875
Validation loss: 1.9545087173420896

Epoch: 6| Step: 9
Training loss: 2.1108593940734863
Validation loss: 1.968236489962506

Epoch: 6| Step: 10
Training loss: 2.0091309547424316
Validation loss: 1.9639389079104188

Epoch: 6| Step: 11
Training loss: 1.7862850427627563
Validation loss: 1.9601808799210416

Epoch: 6| Step: 12
Training loss: 2.6818690299987793
Validation loss: 1.9615135346689532

Epoch: 6| Step: 13
Training loss: 2.264397382736206
Validation loss: 1.9540908990367767

Epoch: 68| Step: 0
Training loss: 2.5977931022644043
Validation loss: 1.9607037241740892

Epoch: 6| Step: 1
Training loss: 1.9409053325653076
Validation loss: 1.9528019351343955

Epoch: 6| Step: 2
Training loss: 2.3423240184783936
Validation loss: 1.9501235613258936

Epoch: 6| Step: 3
Training loss: 1.815727949142456
Validation loss: 1.9486874277873705

Epoch: 6| Step: 4
Training loss: 2.6271274089813232
Validation loss: 1.951467429437945

Epoch: 6| Step: 5
Training loss: 2.113463878631592
Validation loss: 1.95362183355516

Epoch: 6| Step: 6
Training loss: 1.4939708709716797
Validation loss: 1.9503464468063847

Epoch: 6| Step: 7
Training loss: 1.894761085510254
Validation loss: 1.9564871300933182

Epoch: 6| Step: 8
Training loss: 1.6099309921264648
Validation loss: 1.9501832659526537

Epoch: 6| Step: 9
Training loss: 2.4180314540863037
Validation loss: 1.9619233454427412

Epoch: 6| Step: 10
Training loss: 2.9109151363372803
Validation loss: 1.9601474782472015

Epoch: 6| Step: 11
Training loss: 1.8616317510604858
Validation loss: 1.943246535075608

Epoch: 6| Step: 12
Training loss: 2.5015926361083984
Validation loss: 1.951836355270878

Epoch: 6| Step: 13
Training loss: 3.229710578918457
Validation loss: 1.9482050006107619

Epoch: 69| Step: 0
Training loss: 2.3122692108154297
Validation loss: 1.9387098614887526

Epoch: 6| Step: 1
Training loss: 2.3481087684631348
Validation loss: 1.9432583432043753

Epoch: 6| Step: 2
Training loss: 2.172762393951416
Validation loss: 1.9512665810123566

Epoch: 6| Step: 3
Training loss: 1.7464995384216309
Validation loss: 1.9504247891005648

Epoch: 6| Step: 4
Training loss: 2.9049179553985596
Validation loss: 1.9475741078776698

Epoch: 6| Step: 5
Training loss: 1.9934159517288208
Validation loss: 1.9373968467917493

Epoch: 6| Step: 6
Training loss: 2.5260932445526123
Validation loss: 1.954498972944034

Epoch: 6| Step: 7
Training loss: 1.8548551797866821
Validation loss: 1.9391397071141068

Epoch: 6| Step: 8
Training loss: 2.486356019973755
Validation loss: 1.9265247083479358

Epoch: 6| Step: 9
Training loss: 1.5473586320877075
Validation loss: 1.953490662318404

Epoch: 6| Step: 10
Training loss: 2.4041857719421387
Validation loss: 1.933509103713497

Epoch: 6| Step: 11
Training loss: 2.0350329875946045
Validation loss: 1.9409132542148713

Epoch: 6| Step: 12
Training loss: 2.033653736114502
Validation loss: 1.9443197352911836

Epoch: 6| Step: 13
Training loss: 2.653583526611328
Validation loss: 1.917482602980829

Epoch: 70| Step: 0
Training loss: 2.2121059894561768
Validation loss: 1.9356983746251752

Epoch: 6| Step: 1
Training loss: 2.291893243789673
Validation loss: 1.9455914369193457

Epoch: 6| Step: 2
Training loss: 1.7726243734359741
Validation loss: 1.9355829774692495

Epoch: 6| Step: 3
Training loss: 2.0355780124664307
Validation loss: 1.9398048154769405

Epoch: 6| Step: 4
Training loss: 2.435436725616455
Validation loss: 1.941726751224969

Epoch: 6| Step: 5
Training loss: 2.634850263595581
Validation loss: 1.9359502023266209

Epoch: 6| Step: 6
Training loss: 2.2248358726501465
Validation loss: 1.9375408541771673

Epoch: 6| Step: 7
Training loss: 2.1578385829925537
Validation loss: 1.934127648671468

Epoch: 6| Step: 8
Training loss: 1.572662353515625
Validation loss: 1.9568478830399052

Epoch: 6| Step: 9
Training loss: 1.6954060792922974
Validation loss: 1.9395766591513028

Epoch: 6| Step: 10
Training loss: 2.9201018810272217
Validation loss: 1.9346257461014615

Epoch: 6| Step: 11
Training loss: 2.3903870582580566
Validation loss: 1.9555070156692176

Epoch: 6| Step: 12
Training loss: 2.380650043487549
Validation loss: 1.9418306645526682

Epoch: 6| Step: 13
Training loss: 2.09063720703125
Validation loss: 1.9509734312693279

Epoch: 71| Step: 0
Training loss: 1.6002850532531738
Validation loss: 1.951389458871657

Epoch: 6| Step: 1
Training loss: 2.089244842529297
Validation loss: 1.9516394843337357

Epoch: 6| Step: 2
Training loss: 1.8306901454925537
Validation loss: 1.9427153205358854

Epoch: 6| Step: 3
Training loss: 2.2336173057556152
Validation loss: 1.9444816907246907

Epoch: 6| Step: 4
Training loss: 2.6194164752960205
Validation loss: 1.9475494174547092

Epoch: 6| Step: 5
Training loss: 2.8815383911132812
Validation loss: 1.9433691924618137

Epoch: 6| Step: 6
Training loss: 2.199202060699463
Validation loss: 1.9456929058156989

Epoch: 6| Step: 7
Training loss: 1.5818569660186768
Validation loss: 1.9516398176070182

Epoch: 6| Step: 8
Training loss: 1.7916157245635986
Validation loss: 1.928181835400161

Epoch: 6| Step: 9
Training loss: 2.050002098083496
Validation loss: 1.9410330582690496

Epoch: 6| Step: 10
Training loss: 2.6160616874694824
Validation loss: 1.9486448713528213

Epoch: 6| Step: 11
Training loss: 2.4100427627563477
Validation loss: 1.9310018400992117

Epoch: 6| Step: 12
Training loss: 2.0760600566864014
Validation loss: 1.9432926024160078

Epoch: 6| Step: 13
Training loss: 3.1621463298797607
Validation loss: 1.9465528136940413

Epoch: 72| Step: 0
Training loss: 2.6034793853759766
Validation loss: 1.9405380910442722

Epoch: 6| Step: 1
Training loss: 2.261443614959717
Validation loss: 1.9612602956833378

Epoch: 6| Step: 2
Training loss: 2.649106979370117
Validation loss: 1.9596100366243752

Epoch: 6| Step: 3
Training loss: 2.9276390075683594
Validation loss: 1.9490505367197015

Epoch: 6| Step: 4
Training loss: 1.834660530090332
Validation loss: 1.9528765165677635

Epoch: 6| Step: 5
Training loss: 1.7614514827728271
Validation loss: 1.9496651439256565

Epoch: 6| Step: 6
Training loss: 2.497786045074463
Validation loss: 1.9666992861737487

Epoch: 6| Step: 7
Training loss: 1.6195471286773682
Validation loss: 1.9672166814086258

Epoch: 6| Step: 8
Training loss: 2.3493239879608154
Validation loss: 1.9558786499884822

Epoch: 6| Step: 9
Training loss: 1.9809215068817139
Validation loss: 1.9579869393379457

Epoch: 6| Step: 10
Training loss: 1.9820423126220703
Validation loss: 1.9480611970347743

Epoch: 6| Step: 11
Training loss: 1.7209782600402832
Validation loss: 1.9587324998712028

Epoch: 6| Step: 12
Training loss: 2.67142391204834
Validation loss: 1.960686384990651

Epoch: 6| Step: 13
Training loss: 1.5176922082901
Validation loss: 1.9571544765144266

Epoch: 73| Step: 0
Training loss: 1.6112313270568848
Validation loss: 1.9508488537162862

Epoch: 6| Step: 1
Training loss: 2.241905689239502
Validation loss: 1.945457867396775

Epoch: 6| Step: 2
Training loss: 2.2152256965637207
Validation loss: 1.9633527648064397

Epoch: 6| Step: 3
Training loss: 2.3947629928588867
Validation loss: 1.9549689895363265

Epoch: 6| Step: 4
Training loss: 2.431443214416504
Validation loss: 1.9707233226427467

Epoch: 6| Step: 5
Training loss: 2.238173246383667
Validation loss: 1.9498287939256238

Epoch: 6| Step: 6
Training loss: 1.9879082441329956
Validation loss: 1.9584388040727185

Epoch: 6| Step: 7
Training loss: 2.6687002182006836
Validation loss: 1.9602531258777907

Epoch: 6| Step: 8
Training loss: 2.384230613708496
Validation loss: 1.9683471930924283

Epoch: 6| Step: 9
Training loss: 1.956538438796997
Validation loss: 1.9551592667897542

Epoch: 6| Step: 10
Training loss: 2.086513042449951
Validation loss: 1.9615955545056252

Epoch: 6| Step: 11
Training loss: 2.0251903533935547
Validation loss: 1.9736776531383555

Epoch: 6| Step: 12
Training loss: 1.791668176651001
Validation loss: 1.9773520820884294

Epoch: 6| Step: 13
Training loss: 3.070253849029541
Validation loss: 1.9774354504000755

Epoch: 74| Step: 0
Training loss: 2.065355062484741
Validation loss: 1.9580592647675545

Epoch: 6| Step: 1
Training loss: 2.110914707183838
Validation loss: 1.9591399379955825

Epoch: 6| Step: 2
Training loss: 2.3966312408447266
Validation loss: 1.9592900173638457

Epoch: 6| Step: 3
Training loss: 2.229762554168701
Validation loss: 1.9542706807454426

Epoch: 6| Step: 4
Training loss: 2.2740421295166016
Validation loss: 1.9502479222513014

Epoch: 6| Step: 5
Training loss: 1.624485969543457
Validation loss: 1.9527088852338894

Epoch: 6| Step: 6
Training loss: 2.338602304458618
Validation loss: 1.9587970472151233

Epoch: 6| Step: 7
Training loss: 2.116401195526123
Validation loss: 1.9395074523905271

Epoch: 6| Step: 8
Training loss: 2.18064546585083
Validation loss: 1.945209559573922

Epoch: 6| Step: 9
Training loss: 2.5601181983947754
Validation loss: 1.9667261313366633

Epoch: 6| Step: 10
Training loss: 2.417187213897705
Validation loss: 1.9621624151865642

Epoch: 6| Step: 11
Training loss: 2.2951273918151855
Validation loss: 1.9609615905310518

Epoch: 6| Step: 12
Training loss: 1.6468744277954102
Validation loss: 1.956960246127139

Epoch: 6| Step: 13
Training loss: 2.513094663619995
Validation loss: 1.9587375899796844

Epoch: 75| Step: 0
Training loss: 2.026230573654175
Validation loss: 1.958323594062559

Epoch: 6| Step: 1
Training loss: 1.5044082403182983
Validation loss: 1.9706480156990789

Epoch: 6| Step: 2
Training loss: 2.7220540046691895
Validation loss: 1.94133456548055

Epoch: 6| Step: 3
Training loss: 1.6055759191513062
Validation loss: 1.9390482966617872

Epoch: 6| Step: 4
Training loss: 2.4092869758605957
Validation loss: 1.9589695827935332

Epoch: 6| Step: 5
Training loss: 2.093057155609131
Validation loss: 1.9465072244726203

Epoch: 6| Step: 6
Training loss: 2.1670496463775635
Validation loss: 1.922402584424583

Epoch: 6| Step: 7
Training loss: 2.3653011322021484
Validation loss: 1.9396520506951116

Epoch: 6| Step: 8
Training loss: 1.9873064756393433
Validation loss: 1.9319254864928543

Epoch: 6| Step: 9
Training loss: 2.078134059906006
Validation loss: 1.9445652538730251

Epoch: 6| Step: 10
Training loss: 2.7860419750213623
Validation loss: 1.9281285475659113

Epoch: 6| Step: 11
Training loss: 2.4974358081817627
Validation loss: 1.9398776510710358

Epoch: 6| Step: 12
Training loss: 2.482107400894165
Validation loss: 1.9424042842721427

Epoch: 6| Step: 13
Training loss: 1.7112793922424316
Validation loss: 1.9251554742936166

Epoch: 76| Step: 0
Training loss: 1.7412536144256592
Validation loss: 1.9430778077853623

Epoch: 6| Step: 1
Training loss: 2.0651233196258545
Validation loss: 1.9372653897090624

Epoch: 6| Step: 2
Training loss: 2.0151119232177734
Validation loss: 1.9321329016839304

Epoch: 6| Step: 3
Training loss: 2.3428115844726562
Validation loss: 1.9316815676227692

Epoch: 6| Step: 4
Training loss: 2.5378918647766113
Validation loss: 1.9441299284658125

Epoch: 6| Step: 5
Training loss: 2.4745707511901855
Validation loss: 1.9382902704259402

Epoch: 6| Step: 6
Training loss: 1.848989486694336
Validation loss: 1.9446485106663038

Epoch: 6| Step: 7
Training loss: 2.1808714866638184
Validation loss: 1.9383729273273098

Epoch: 6| Step: 8
Training loss: 1.7890424728393555
Validation loss: 1.961605271985454

Epoch: 6| Step: 9
Training loss: 2.1321945190429688
Validation loss: 1.9581070023198281

Epoch: 6| Step: 10
Training loss: 2.4071950912475586
Validation loss: 1.9372814291266984

Epoch: 6| Step: 11
Training loss: 2.553039789199829
Validation loss: 1.9582826219579226

Epoch: 6| Step: 12
Training loss: 2.2499470710754395
Validation loss: 1.949738403802277

Epoch: 6| Step: 13
Training loss: 2.3366880416870117
Validation loss: 1.957742803840227

Epoch: 77| Step: 0
Training loss: 2.022092580795288
Validation loss: 1.9386947667726906

Epoch: 6| Step: 1
Training loss: 2.063095808029175
Validation loss: 1.9498920274037186

Epoch: 6| Step: 2
Training loss: 2.5949525833129883
Validation loss: 1.9548358942872734

Epoch: 6| Step: 3
Training loss: 2.029062271118164
Validation loss: 1.9487419359145626

Epoch: 6| Step: 4
Training loss: 1.8247472047805786
Validation loss: 1.964533875065465

Epoch: 6| Step: 5
Training loss: 3.093989610671997
Validation loss: 1.9555663485680856

Epoch: 6| Step: 6
Training loss: 2.1248135566711426
Validation loss: 1.9557398890936246

Epoch: 6| Step: 7
Training loss: 1.8282467126846313
Validation loss: 1.947075810483707

Epoch: 6| Step: 8
Training loss: 1.9076972007751465
Validation loss: 1.9568464371465868

Epoch: 6| Step: 9
Training loss: 2.5099401473999023
Validation loss: 1.968302147362822

Epoch: 6| Step: 10
Training loss: 1.7181442975997925
Validation loss: 1.980590908758102

Epoch: 6| Step: 11
Training loss: 2.4148006439208984
Validation loss: 1.953843629488381

Epoch: 6| Step: 12
Training loss: 2.347743511199951
Validation loss: 1.9657684936318347

Epoch: 6| Step: 13
Training loss: 2.0297112464904785
Validation loss: 1.9510154685666483

Epoch: 78| Step: 0
Training loss: 1.656266212463379
Validation loss: 1.937237428080651

Epoch: 6| Step: 1
Training loss: 1.8951029777526855
Validation loss: 1.9560509791938208

Epoch: 6| Step: 2
Training loss: 2.244105815887451
Validation loss: 1.9364355840990621

Epoch: 6| Step: 3
Training loss: 2.674708604812622
Validation loss: 1.936981644681705

Epoch: 6| Step: 4
Training loss: 2.2970592975616455
Validation loss: 1.9467376842293689

Epoch: 6| Step: 5
Training loss: 2.5860235691070557
Validation loss: 1.9484073218478952

Epoch: 6| Step: 6
Training loss: 1.9784343242645264
Validation loss: 1.9624790812051425

Epoch: 6| Step: 7
Training loss: 2.405761241912842
Validation loss: 1.9501084614825506

Epoch: 6| Step: 8
Training loss: 2.1549081802368164
Validation loss: 1.9504980989681777

Epoch: 6| Step: 9
Training loss: 1.8760952949523926
Validation loss: 1.9384151658704203

Epoch: 6| Step: 10
Training loss: 1.7459561824798584
Validation loss: 1.9501153628031414

Epoch: 6| Step: 11
Training loss: 2.324223041534424
Validation loss: 1.94577839169451

Epoch: 6| Step: 12
Training loss: 2.448178768157959
Validation loss: 1.945807530033973

Epoch: 6| Step: 13
Training loss: 2.2367103099823
Validation loss: 1.9558309252544115

Epoch: 79| Step: 0
Training loss: 1.6194710731506348
Validation loss: 1.9427271530192385

Epoch: 6| Step: 1
Training loss: 2.3544387817382812
Validation loss: 1.9460969714708225

Epoch: 6| Step: 2
Training loss: 2.2914345264434814
Validation loss: 1.9557665266016477

Epoch: 6| Step: 3
Training loss: 2.3664844036102295
Validation loss: 1.9436800749071184

Epoch: 6| Step: 4
Training loss: 2.0826659202575684
Validation loss: 1.950945399140799

Epoch: 6| Step: 5
Training loss: 2.5649383068084717
Validation loss: 1.958514562217138

Epoch: 6| Step: 6
Training loss: 2.0113563537597656
Validation loss: 1.9436883836664178

Epoch: 6| Step: 7
Training loss: 1.4173312187194824
Validation loss: 1.9355429782662341

Epoch: 6| Step: 8
Training loss: 2.6418275833129883
Validation loss: 1.9520839824471423

Epoch: 6| Step: 9
Training loss: 2.2489945888519287
Validation loss: 1.9491634855988205

Epoch: 6| Step: 10
Training loss: 2.5895068645477295
Validation loss: 1.9473498431585168

Epoch: 6| Step: 11
Training loss: 1.7806479930877686
Validation loss: 1.933618232768069

Epoch: 6| Step: 12
Training loss: 2.698289632797241
Validation loss: 1.928747416824423

Epoch: 6| Step: 13
Training loss: 1.26323401927948
Validation loss: 1.9416217060499295

Epoch: 80| Step: 0
Training loss: 1.8047778606414795
Validation loss: 1.9603911356259418

Epoch: 6| Step: 1
Training loss: 1.6215687990188599
Validation loss: 1.941885862299191

Epoch: 6| Step: 2
Training loss: 1.606269359588623
Validation loss: 1.9333253522073068

Epoch: 6| Step: 3
Training loss: 2.4253342151641846
Validation loss: 1.941861601286037

Epoch: 6| Step: 4
Training loss: 2.4701056480407715
Validation loss: 1.9514392909183298

Epoch: 6| Step: 5
Training loss: 2.317838668823242
Validation loss: 1.9479606254126436

Epoch: 6| Step: 6
Training loss: 2.968346357345581
Validation loss: 1.9433656123376661

Epoch: 6| Step: 7
Training loss: 1.8905665874481201
Validation loss: 1.9481796244139313

Epoch: 6| Step: 8
Training loss: 2.868739366531372
Validation loss: 1.9410270542226813

Epoch: 6| Step: 9
Training loss: 2.289815902709961
Validation loss: 1.9491779022319342

Epoch: 6| Step: 10
Training loss: 1.9442665576934814
Validation loss: 1.94430830401759

Epoch: 6| Step: 11
Training loss: 1.5224456787109375
Validation loss: 1.9353007142261793

Epoch: 6| Step: 12
Training loss: 2.5373456478118896
Validation loss: 1.9559130732731154

Epoch: 6| Step: 13
Training loss: 1.7501108646392822
Validation loss: 1.9388201159815635

Epoch: 81| Step: 0
Training loss: 1.8756846189498901
Validation loss: 1.9188353553895028

Epoch: 6| Step: 1
Training loss: 2.53717303276062
Validation loss: 1.947109373666907

Epoch: 6| Step: 2
Training loss: 2.433865785598755
Validation loss: 1.948270672111101

Epoch: 6| Step: 3
Training loss: 2.358764886856079
Validation loss: 1.9561221702124483

Epoch: 6| Step: 4
Training loss: 2.2632951736450195
Validation loss: 1.965354698960499

Epoch: 6| Step: 5
Training loss: 1.6885021924972534
Validation loss: 1.9394671186324088

Epoch: 6| Step: 6
Training loss: 1.9131255149841309
Validation loss: 1.9526669248457877

Epoch: 6| Step: 7
Training loss: 2.537130832672119
Validation loss: 1.9632155549141668

Epoch: 6| Step: 8
Training loss: 2.3485186100006104
Validation loss: 1.9436993073391657

Epoch: 6| Step: 9
Training loss: 2.4150052070617676
Validation loss: 1.9451305353513328

Epoch: 6| Step: 10
Training loss: 1.6529054641723633
Validation loss: 1.9500633644801315

Epoch: 6| Step: 11
Training loss: 2.6531972885131836
Validation loss: 1.953008887588337

Epoch: 6| Step: 12
Training loss: 1.727323293685913
Validation loss: 1.943946902469922

Epoch: 6| Step: 13
Training loss: 1.635306715965271
Validation loss: 1.943809042694748

Epoch: 82| Step: 0
Training loss: 2.1798744201660156
Validation loss: 1.9597957441883702

Epoch: 6| Step: 1
Training loss: 2.1148111820220947
Validation loss: 1.9420214160796134

Epoch: 6| Step: 2
Training loss: 1.819528341293335
Validation loss: 1.9540116248592254

Epoch: 6| Step: 3
Training loss: 2.273299217224121
Validation loss: 1.9702751046867781

Epoch: 6| Step: 4
Training loss: 2.094554901123047
Validation loss: 1.9375833516479821

Epoch: 6| Step: 5
Training loss: 2.727332592010498
Validation loss: 1.9467147665639077

Epoch: 6| Step: 6
Training loss: 2.1486244201660156
Validation loss: 1.9331915224752119

Epoch: 6| Step: 7
Training loss: 2.0151150226593018
Validation loss: 1.9450348038827219

Epoch: 6| Step: 8
Training loss: 1.7857177257537842
Validation loss: 1.9479335277311263

Epoch: 6| Step: 9
Training loss: 2.326943874359131
Validation loss: 1.9457040755979476

Epoch: 6| Step: 10
Training loss: 2.1437909603118896
Validation loss: 1.9629727832732662

Epoch: 6| Step: 11
Training loss: 2.089188575744629
Validation loss: 1.9308430661437332

Epoch: 6| Step: 12
Training loss: 2.0951662063598633
Validation loss: 1.9508676862203946

Epoch: 6| Step: 13
Training loss: 2.249535322189331
Validation loss: 1.9306082712706698

Epoch: 83| Step: 0
Training loss: 1.8763442039489746
Validation loss: 1.9381123640203988

Epoch: 6| Step: 1
Training loss: 2.2195498943328857
Validation loss: 1.9333900969515565

Epoch: 6| Step: 2
Training loss: 2.073784112930298
Validation loss: 1.9379891298150504

Epoch: 6| Step: 3
Training loss: 2.0189452171325684
Validation loss: 1.9572108509720012

Epoch: 6| Step: 4
Training loss: 1.5733201503753662
Validation loss: 1.936165346894213

Epoch: 6| Step: 5
Training loss: 1.8310660123825073
Validation loss: 1.94693838268198

Epoch: 6| Step: 6
Training loss: 2.3268485069274902
Validation loss: 1.9339881250935216

Epoch: 6| Step: 7
Training loss: 2.527308940887451
Validation loss: 1.9349893318709506

Epoch: 6| Step: 8
Training loss: 1.7095617055892944
Validation loss: 1.9508090865227483

Epoch: 6| Step: 9
Training loss: 2.3879342079162598
Validation loss: 1.938311848589169

Epoch: 6| Step: 10
Training loss: 2.2776541709899902
Validation loss: 1.9467615722328104

Epoch: 6| Step: 11
Training loss: 2.350834846496582
Validation loss: 1.9544493075340026

Epoch: 6| Step: 12
Training loss: 2.643275737762451
Validation loss: 1.9533861760170228

Epoch: 6| Step: 13
Training loss: 2.3662524223327637
Validation loss: 1.9489560434895177

Epoch: 84| Step: 0
Training loss: 1.4441301822662354
Validation loss: 1.9390606367459862

Epoch: 6| Step: 1
Training loss: 2.7811455726623535
Validation loss: 1.9553754662954679

Epoch: 6| Step: 2
Training loss: 2.2683870792388916
Validation loss: 1.9367206045376357

Epoch: 6| Step: 3
Training loss: 2.1401801109313965
Validation loss: 1.9373795742629676

Epoch: 6| Step: 4
Training loss: 1.564092993736267
Validation loss: 1.9333831866582234

Epoch: 6| Step: 5
Training loss: 2.677163600921631
Validation loss: 1.9421224030115272

Epoch: 6| Step: 6
Training loss: 2.3608264923095703
Validation loss: 1.9282935460408528

Epoch: 6| Step: 7
Training loss: 2.252080202102661
Validation loss: 1.953157599254321

Epoch: 6| Step: 8
Training loss: 2.3644351959228516
Validation loss: 1.9510969128659976

Epoch: 6| Step: 9
Training loss: 2.5204920768737793
Validation loss: 1.9576378022470782

Epoch: 6| Step: 10
Training loss: 1.536509394645691
Validation loss: 1.9307791622736121

Epoch: 6| Step: 11
Training loss: 2.034853458404541
Validation loss: 1.9346310220738894

Epoch: 6| Step: 12
Training loss: 2.170767307281494
Validation loss: 1.9375291152666974

Epoch: 6| Step: 13
Training loss: 1.793601155281067
Validation loss: 1.9376163636484454

Epoch: 85| Step: 0
Training loss: 2.0368895530700684
Validation loss: 1.9458356954718148

Epoch: 6| Step: 1
Training loss: 2.631988525390625
Validation loss: 1.9298093395848428

Epoch: 6| Step: 2
Training loss: 1.9462846517562866
Validation loss: 1.9411358602585331

Epoch: 6| Step: 3
Training loss: 1.9787943363189697
Validation loss: 1.9265891211007231

Epoch: 6| Step: 4
Training loss: 2.9321587085723877
Validation loss: 1.9443415570002731

Epoch: 6| Step: 5
Training loss: 2.0919668674468994
Validation loss: 1.941454590007823

Epoch: 6| Step: 6
Training loss: 2.001188278198242
Validation loss: 1.9411758556160876

Epoch: 6| Step: 7
Training loss: 1.2298201322555542
Validation loss: 1.9616654444766302

Epoch: 6| Step: 8
Training loss: 1.9541456699371338
Validation loss: 1.9241199647226641

Epoch: 6| Step: 9
Training loss: 1.6899279356002808
Validation loss: 1.9526512674106065

Epoch: 6| Step: 10
Training loss: 2.4870786666870117
Validation loss: 1.94529374184147

Epoch: 6| Step: 11
Training loss: 2.4598522186279297
Validation loss: 1.9315384126478625

Epoch: 6| Step: 12
Training loss: 1.9789741039276123
Validation loss: 1.9315593447736514

Epoch: 6| Step: 13
Training loss: 3.059835195541382
Validation loss: 1.9338631142852127

Epoch: 86| Step: 0
Training loss: 2.76338267326355
Validation loss: 1.9533813025361748

Epoch: 6| Step: 1
Training loss: 1.7647535800933838
Validation loss: 1.9281828300927275

Epoch: 6| Step: 2
Training loss: 1.8443619012832642
Validation loss: 1.9426627979483655

Epoch: 6| Step: 3
Training loss: 2.362497091293335
Validation loss: 1.9572139350316857

Epoch: 6| Step: 4
Training loss: 2.281099319458008
Validation loss: 1.9336617813315442

Epoch: 6| Step: 5
Training loss: 2.058119535446167
Validation loss: 1.933180550093292

Epoch: 6| Step: 6
Training loss: 1.912522792816162
Validation loss: 1.945570340720556

Epoch: 6| Step: 7
Training loss: 2.301799774169922
Validation loss: 1.9440358018362394

Epoch: 6| Step: 8
Training loss: 1.8871283531188965
Validation loss: 1.940677935077298

Epoch: 6| Step: 9
Training loss: 2.4868950843811035
Validation loss: 1.9371508334272651

Epoch: 6| Step: 10
Training loss: 1.5668878555297852
Validation loss: 1.9382035245177567

Epoch: 6| Step: 11
Training loss: 2.104231119155884
Validation loss: 1.9262936602356613

Epoch: 6| Step: 12
Training loss: 2.8280391693115234
Validation loss: 1.9340578330460416

Epoch: 6| Step: 13
Training loss: 1.4390021562576294
Validation loss: 1.9415277704115836

Epoch: 87| Step: 0
Training loss: 2.4040780067443848
Validation loss: 1.9479536241100681

Epoch: 6| Step: 1
Training loss: 2.2102982997894287
Validation loss: 1.9364310285096527

Epoch: 6| Step: 2
Training loss: 1.8615097999572754
Validation loss: 1.9406898444698704

Epoch: 6| Step: 3
Training loss: 1.6556516885757446
Validation loss: 1.9397820118934876

Epoch: 6| Step: 4
Training loss: 2.225416421890259
Validation loss: 1.9294388268583564

Epoch: 6| Step: 5
Training loss: 2.39626145362854
Validation loss: 1.9459581426394883

Epoch: 6| Step: 6
Training loss: 2.4571149349212646
Validation loss: 1.9281873369729647

Epoch: 6| Step: 7
Training loss: 2.705894947052002
Validation loss: 1.9500681777154245

Epoch: 6| Step: 8
Training loss: 2.237095355987549
Validation loss: 1.9319810085399176

Epoch: 6| Step: 9
Training loss: 1.7916953563690186
Validation loss: 1.9475353302494172

Epoch: 6| Step: 10
Training loss: 2.1821727752685547
Validation loss: 1.9367400702609812

Epoch: 6| Step: 11
Training loss: 2.0282063484191895
Validation loss: 1.9381910075423538

Epoch: 6| Step: 12
Training loss: 1.981337547302246
Validation loss: 1.9328656286321662

Epoch: 6| Step: 13
Training loss: 1.9377695322036743
Validation loss: 1.9416304993373092

Epoch: 88| Step: 0
Training loss: 1.96562659740448
Validation loss: 1.9424967791444512

Epoch: 6| Step: 1
Training loss: 2.0887508392333984
Validation loss: 1.9321700603731218

Epoch: 6| Step: 2
Training loss: 1.5101501941680908
Validation loss: 1.9437199202916955

Epoch: 6| Step: 3
Training loss: 1.832803726196289
Validation loss: 1.9468030339928084

Epoch: 6| Step: 4
Training loss: 1.8681527376174927
Validation loss: 1.9389312882577219

Epoch: 6| Step: 5
Training loss: 2.0234174728393555
Validation loss: 1.957530358786224

Epoch: 6| Step: 6
Training loss: 2.7425830364227295
Validation loss: 1.9377949019914031

Epoch: 6| Step: 7
Training loss: 2.4261717796325684
Validation loss: 1.9515994620579544

Epoch: 6| Step: 8
Training loss: 2.52891206741333
Validation loss: 1.9573246932798816

Epoch: 6| Step: 9
Training loss: 1.9534316062927246
Validation loss: 1.941207460177842

Epoch: 6| Step: 10
Training loss: 2.1732373237609863
Validation loss: 1.961597559272602

Epoch: 6| Step: 11
Training loss: 2.4272360801696777
Validation loss: 1.9519872319313787

Epoch: 6| Step: 12
Training loss: 2.1665987968444824
Validation loss: 1.9570934170035905

Epoch: 6| Step: 13
Training loss: 2.1124823093414307
Validation loss: 1.9440827151780486

Epoch: 89| Step: 0
Training loss: 2.0226049423217773
Validation loss: 1.9559941407172912

Epoch: 6| Step: 1
Training loss: 1.5527362823486328
Validation loss: 1.965815467219199

Epoch: 6| Step: 2
Training loss: 2.2942895889282227
Validation loss: 1.9354641411894111

Epoch: 6| Step: 3
Training loss: 1.4929916858673096
Validation loss: 1.9561204192458943

Epoch: 6| Step: 4
Training loss: 2.1686182022094727
Validation loss: 1.9471098761404715

Epoch: 6| Step: 5
Training loss: 2.3453354835510254
Validation loss: 1.9535585065041818

Epoch: 6| Step: 6
Training loss: 2.2537074089050293
Validation loss: 1.9469335386829991

Epoch: 6| Step: 7
Training loss: 2.0705130100250244
Validation loss: 1.9691651918554818

Epoch: 6| Step: 8
Training loss: 2.5940990447998047
Validation loss: 1.9444718591628536

Epoch: 6| Step: 9
Training loss: 2.732235908508301
Validation loss: 1.9644519898199266

Epoch: 6| Step: 10
Training loss: 2.357306480407715
Validation loss: 1.9635750401404597

Epoch: 6| Step: 11
Training loss: 2.1304385662078857
Validation loss: 1.9581866046433807

Epoch: 6| Step: 12
Training loss: 1.8024015426635742
Validation loss: 1.9617548655438166

Epoch: 6| Step: 13
Training loss: 1.9736870527267456
Validation loss: 1.9411932793996667

Epoch: 90| Step: 0
Training loss: 1.6098921298980713
Validation loss: 1.9580851831743795

Epoch: 6| Step: 1
Training loss: 1.6174354553222656
Validation loss: 1.9556358988567064

Epoch: 6| Step: 2
Training loss: 2.120769500732422
Validation loss: 1.9536113149376326

Epoch: 6| Step: 3
Training loss: 2.064910888671875
Validation loss: 1.9604752781570598

Epoch: 6| Step: 4
Training loss: 2.4379827976226807
Validation loss: 1.944531424071199

Epoch: 6| Step: 5
Training loss: 2.06900691986084
Validation loss: 1.9569107435082878

Epoch: 6| Step: 6
Training loss: 1.8880695104599
Validation loss: 1.9486401875813801

Epoch: 6| Step: 7
Training loss: 2.680863380432129
Validation loss: 1.9525216176945677

Epoch: 6| Step: 8
Training loss: 2.6486172676086426
Validation loss: 1.9435172004084433

Epoch: 6| Step: 9
Training loss: 2.125437021255493
Validation loss: 1.9632696618315995

Epoch: 6| Step: 10
Training loss: 2.02219820022583
Validation loss: 1.945979679784467

Epoch: 6| Step: 11
Training loss: 1.80928635597229
Validation loss: 1.955675208440391

Epoch: 6| Step: 12
Training loss: 2.6188039779663086
Validation loss: 1.9583634868744881

Epoch: 6| Step: 13
Training loss: 2.065152168273926
Validation loss: 1.9509883311487013

Epoch: 91| Step: 0
Training loss: 2.38985276222229
Validation loss: 1.9406072478140555

Epoch: 6| Step: 1
Training loss: 2.1386494636535645
Validation loss: 1.9431499640146892

Epoch: 6| Step: 2
Training loss: 2.8499221801757812
Validation loss: 1.9462963214484594

Epoch: 6| Step: 3
Training loss: 1.9110596179962158
Validation loss: 1.9487492909995459

Epoch: 6| Step: 4
Training loss: 1.7895052433013916
Validation loss: 1.937445750800512

Epoch: 6| Step: 5
Training loss: 2.6700382232666016
Validation loss: 1.9490186681029618

Epoch: 6| Step: 6
Training loss: 1.6834428310394287
Validation loss: 1.94340310430014

Epoch: 6| Step: 7
Training loss: 1.5982348918914795
Validation loss: 1.9628220873494302

Epoch: 6| Step: 8
Training loss: 2.190505027770996
Validation loss: 1.9459854082394672

Epoch: 6| Step: 9
Training loss: 1.6980351209640503
Validation loss: 1.9473733171339958

Epoch: 6| Step: 10
Training loss: 2.4292354583740234
Validation loss: 1.9761983451022898

Epoch: 6| Step: 11
Training loss: 1.7003298997879028
Validation loss: 1.9458947027883222

Epoch: 6| Step: 12
Training loss: 2.3100757598876953
Validation loss: 1.9577832029711815

Epoch: 6| Step: 13
Training loss: 2.64589786529541
Validation loss: 1.951981072784752

Epoch: 92| Step: 0
Training loss: 2.0318312644958496
Validation loss: 1.9504247519277758

Epoch: 6| Step: 1
Training loss: 2.0438759326934814
Validation loss: 1.9503192337610389

Epoch: 6| Step: 2
Training loss: 2.4400479793548584
Validation loss: 1.9429600982255832

Epoch: 6| Step: 3
Training loss: 2.5110180377960205
Validation loss: 1.9432904630578973

Epoch: 6| Step: 4
Training loss: 2.5205514430999756
Validation loss: 1.940206197000319

Epoch: 6| Step: 5
Training loss: 2.025946617126465
Validation loss: 1.9427237408135527

Epoch: 6| Step: 6
Training loss: 2.212095260620117
Validation loss: 1.9590597473165041

Epoch: 6| Step: 7
Training loss: 1.761303424835205
Validation loss: 1.9550321640506867

Epoch: 6| Step: 8
Training loss: 2.314394950866699
Validation loss: 1.9580704576225691

Epoch: 6| Step: 9
Training loss: 1.505181074142456
Validation loss: 1.9283771822529454

Epoch: 6| Step: 10
Training loss: 2.028820276260376
Validation loss: 1.9323486845980409

Epoch: 6| Step: 11
Training loss: 2.3986597061157227
Validation loss: 1.946741755290698

Epoch: 6| Step: 12
Training loss: 1.785219430923462
Validation loss: 1.929104406346557

Epoch: 6| Step: 13
Training loss: 2.2162020206451416
Validation loss: 1.9403788838335263

Epoch: 93| Step: 0
Training loss: 2.870830535888672
Validation loss: 1.955826990066036

Epoch: 6| Step: 1
Training loss: 1.8737763166427612
Validation loss: 1.9416167607871435

Epoch: 6| Step: 2
Training loss: 2.1488404273986816
Validation loss: 1.9499622750025924

Epoch: 6| Step: 3
Training loss: 1.8291844129562378
Validation loss: 1.937410262323195

Epoch: 6| Step: 4
Training loss: 2.2329440116882324
Validation loss: 1.952744545475129

Epoch: 6| Step: 5
Training loss: 2.2006232738494873
Validation loss: 1.9467426397467171

Epoch: 6| Step: 6
Training loss: 2.2530102729797363
Validation loss: 1.925024535066338

Epoch: 6| Step: 7
Training loss: 1.9962412118911743
Validation loss: 1.9451608324563632

Epoch: 6| Step: 8
Training loss: 1.7887804508209229
Validation loss: 1.938799943975223

Epoch: 6| Step: 9
Training loss: 1.6360154151916504
Validation loss: 1.9470843730434295

Epoch: 6| Step: 10
Training loss: 2.190215587615967
Validation loss: 1.9457944003484582

Epoch: 6| Step: 11
Training loss: 2.1435933113098145
Validation loss: 1.9282937229320567

Epoch: 6| Step: 12
Training loss: 2.046908378601074
Validation loss: 1.9468905400204402

Epoch: 6| Step: 13
Training loss: 2.504166603088379
Validation loss: 1.927821534936146

Epoch: 94| Step: 0
Training loss: 1.9951176643371582
Validation loss: 1.9264607301322363

Epoch: 6| Step: 1
Training loss: 2.0553014278411865
Validation loss: 1.9381192473955051

Epoch: 6| Step: 2
Training loss: 2.2002763748168945
Validation loss: 1.9389464842375888

Epoch: 6| Step: 3
Training loss: 2.4200868606567383
Validation loss: 1.950780858275711

Epoch: 6| Step: 4
Training loss: 1.4974145889282227
Validation loss: 1.9282169470223047

Epoch: 6| Step: 5
Training loss: 1.6275335550308228
Validation loss: 1.9309591939372401

Epoch: 6| Step: 6
Training loss: 1.4421207904815674
Validation loss: 1.9346446144965388

Epoch: 6| Step: 7
Training loss: 1.8596330881118774
Validation loss: 1.9102176876478298

Epoch: 6| Step: 8
Training loss: 2.213400363922119
Validation loss: 1.9379806640327617

Epoch: 6| Step: 9
Training loss: 2.7297892570495605
Validation loss: 1.9398993394708122

Epoch: 6| Step: 10
Training loss: 2.7059779167175293
Validation loss: 1.9435241248017998

Epoch: 6| Step: 11
Training loss: 1.580662727355957
Validation loss: 1.9285815467116654

Epoch: 6| Step: 12
Training loss: 2.886678695678711
Validation loss: 1.9226887738832863

Epoch: 6| Step: 13
Training loss: 2.5183587074279785
Validation loss: 1.9425212631943405

Epoch: 95| Step: 0
Training loss: 2.037935733795166
Validation loss: 1.9376751222918112

Epoch: 6| Step: 1
Training loss: 1.508498191833496
Validation loss: 1.9382600733028945

Epoch: 6| Step: 2
Training loss: 2.54182767868042
Validation loss: 1.9300357808348954

Epoch: 6| Step: 3
Training loss: 2.3969531059265137
Validation loss: 1.9439366248346144

Epoch: 6| Step: 4
Training loss: 2.6273751258850098
Validation loss: 1.9311749114785144

Epoch: 6| Step: 5
Training loss: 2.020076274871826
Validation loss: 1.9147079144754717

Epoch: 6| Step: 6
Training loss: 2.096747398376465
Validation loss: 1.9321467209887762

Epoch: 6| Step: 7
Training loss: 2.0637309551239014
Validation loss: 1.9354996783759004

Epoch: 6| Step: 8
Training loss: 1.7619094848632812
Validation loss: 1.9347876297530306

Epoch: 6| Step: 9
Training loss: 1.7920368909835815
Validation loss: 1.9387525909690446

Epoch: 6| Step: 10
Training loss: 1.7651119232177734
Validation loss: 1.9349743653369207

Epoch: 6| Step: 11
Training loss: 2.550417900085449
Validation loss: 1.9377157841959307

Epoch: 6| Step: 12
Training loss: 2.0656328201293945
Validation loss: 1.9455613705419725

Epoch: 6| Step: 13
Training loss: 2.4079580307006836
Validation loss: 1.9395751709579139

Epoch: 96| Step: 0
Training loss: 1.830030918121338
Validation loss: 1.9275562968305362

Epoch: 6| Step: 1
Training loss: 2.4154908657073975
Validation loss: 1.9271255834128267

Epoch: 6| Step: 2
Training loss: 2.061215877532959
Validation loss: 1.9492904870740828

Epoch: 6| Step: 3
Training loss: 1.75165855884552
Validation loss: 1.935043429815641

Epoch: 6| Step: 4
Training loss: 2.938356399536133
Validation loss: 1.935188502393743

Epoch: 6| Step: 5
Training loss: 1.9942902326583862
Validation loss: 1.937685549900096

Epoch: 6| Step: 6
Training loss: 1.906430959701538
Validation loss: 1.9364151236831502

Epoch: 6| Step: 7
Training loss: 2.4935009479522705
Validation loss: 1.9472020236394738

Epoch: 6| Step: 8
Training loss: 1.775062084197998
Validation loss: 1.9382023426794237

Epoch: 6| Step: 9
Training loss: 1.978816032409668
Validation loss: 1.9138545656716952

Epoch: 6| Step: 10
Training loss: 1.6967296600341797
Validation loss: 1.9626223835893857

Epoch: 6| Step: 11
Training loss: 2.350773811340332
Validation loss: 1.9295983006877284

Epoch: 6| Step: 12
Training loss: 1.6904759407043457
Validation loss: 1.9278274915551628

Epoch: 6| Step: 13
Training loss: 2.7050485610961914
Validation loss: 1.9257849493334371

Epoch: 97| Step: 0
Training loss: 2.043424129486084
Validation loss: 1.9436425342354724

Epoch: 6| Step: 1
Training loss: 1.7021222114562988
Validation loss: 1.9461845287712671

Epoch: 6| Step: 2
Training loss: 2.3577754497528076
Validation loss: 1.9338574409484863

Epoch: 6| Step: 3
Training loss: 2.3509609699249268
Validation loss: 1.9375838246396793

Epoch: 6| Step: 4
Training loss: 1.8438119888305664
Validation loss: 1.926692247390747

Epoch: 6| Step: 5
Training loss: 2.1144063472747803
Validation loss: 1.944965221548593

Epoch: 6| Step: 6
Training loss: 1.9627232551574707
Validation loss: 1.927425092266452

Epoch: 6| Step: 7
Training loss: 2.0806384086608887
Validation loss: 1.943142298729189

Epoch: 6| Step: 8
Training loss: 2.1665844917297363
Validation loss: 1.9451892170854794

Epoch: 6| Step: 9
Training loss: 2.1136341094970703
Validation loss: 1.9360468515785791

Epoch: 6| Step: 10
Training loss: 1.8539960384368896
Validation loss: 1.9386178524263444

Epoch: 6| Step: 11
Training loss: 2.231287956237793
Validation loss: 1.9244476210686468

Epoch: 6| Step: 12
Training loss: 2.060645818710327
Validation loss: 1.9486128835267917

Epoch: 6| Step: 13
Training loss: 2.6232614517211914
Validation loss: 1.9474390129889212

Epoch: 98| Step: 0
Training loss: 1.6622661352157593
Validation loss: 1.919511023388114

Epoch: 6| Step: 1
Training loss: 2.4512994289398193
Validation loss: 1.9525646394298923

Epoch: 6| Step: 2
Training loss: 2.2445425987243652
Validation loss: 1.9356557810178368

Epoch: 6| Step: 3
Training loss: 1.626845121383667
Validation loss: 1.9480573079919303

Epoch: 6| Step: 4
Training loss: 2.028174877166748
Validation loss: 1.9408468713042557

Epoch: 6| Step: 5
Training loss: 2.815593957901001
Validation loss: 1.9647305857750677

Epoch: 6| Step: 6
Training loss: 1.9686647653579712
Validation loss: 1.94758447652222

Epoch: 6| Step: 7
Training loss: 1.9505648612976074
Validation loss: 1.955122705428831

Epoch: 6| Step: 8
Training loss: 1.6689233779907227
Validation loss: 1.9548027694866221

Epoch: 6| Step: 9
Training loss: 1.2326947450637817
Validation loss: 1.9426269377431562

Epoch: 6| Step: 10
Training loss: 2.176180839538574
Validation loss: 1.9421183665593464

Epoch: 6| Step: 11
Training loss: 1.8330981731414795
Validation loss: 1.9725163636669036

Epoch: 6| Step: 12
Training loss: 3.495553493499756
Validation loss: 1.9661819601571688

Epoch: 6| Step: 13
Training loss: 2.0278615951538086
Validation loss: 1.9356171738716863

Epoch: 99| Step: 0
Training loss: 2.0064938068389893
Validation loss: 1.9567603526576873

Epoch: 6| Step: 1
Training loss: 2.0578837394714355
Validation loss: 1.9589586552753244

Epoch: 6| Step: 2
Training loss: 1.867506742477417
Validation loss: 1.9659734797734085

Epoch: 6| Step: 3
Training loss: 2.20701265335083
Validation loss: 1.9390401045481365

Epoch: 6| Step: 4
Training loss: 1.9033010005950928
Validation loss: 1.9501375152218727

Epoch: 6| Step: 5
Training loss: 2.069784641265869
Validation loss: 1.930418441372533

Epoch: 6| Step: 6
Training loss: 1.862845778465271
Validation loss: 1.9463533842435448

Epoch: 6| Step: 7
Training loss: 1.9226703643798828
Validation loss: 1.9381998610752884

Epoch: 6| Step: 8
Training loss: 1.3169777393341064
Validation loss: 1.9586615152256464

Epoch: 6| Step: 9
Training loss: 1.5235605239868164
Validation loss: 1.935800838214095

Epoch: 6| Step: 10
Training loss: 2.6289873123168945
Validation loss: 1.948724546740132

Epoch: 6| Step: 11
Training loss: 2.7333767414093018
Validation loss: 1.942372824556084

Epoch: 6| Step: 12
Training loss: 2.9250311851501465
Validation loss: 1.9558952290524718

Epoch: 6| Step: 13
Training loss: 2.1642751693725586
Validation loss: 1.952785958525955

Epoch: 100| Step: 0
Training loss: 2.7336459159851074
Validation loss: 1.9240091103379444

Epoch: 6| Step: 1
Training loss: 1.9012503623962402
Validation loss: 1.9393395711016912

Epoch: 6| Step: 2
Training loss: 1.9163503646850586
Validation loss: 1.948532981257285

Epoch: 6| Step: 3
Training loss: 2.1889820098876953
Validation loss: 1.9391564553783787

Epoch: 6| Step: 4
Training loss: 2.309246301651001
Validation loss: 1.9399517031126126

Epoch: 6| Step: 5
Training loss: 2.375521183013916
Validation loss: 1.9391621876788396

Epoch: 6| Step: 6
Training loss: 1.5613839626312256
Validation loss: 1.9379599325118526

Epoch: 6| Step: 7
Training loss: 1.7921751737594604
Validation loss: 1.9548580467060048

Epoch: 6| Step: 8
Training loss: 2.3965234756469727
Validation loss: 1.9424614662765174

Epoch: 6| Step: 9
Training loss: 2.469155788421631
Validation loss: 1.9442145427068074

Epoch: 6| Step: 10
Training loss: 2.1478118896484375
Validation loss: 1.9327829486580306

Epoch: 6| Step: 11
Training loss: 1.2565906047821045
Validation loss: 1.942402789669652

Epoch: 6| Step: 12
Training loss: 2.2134335041046143
Validation loss: 1.9368063262713853

Epoch: 6| Step: 13
Training loss: 1.8881443738937378
Validation loss: 1.9365629855022635

Testing loss: 2.1901305516560874
