Epoch: 1| Step: 0
Training loss: 4.936755180358887
Validation loss: 4.695159860836562

Epoch: 6| Step: 1
Training loss: 3.7848501205444336
Validation loss: 4.689158788291357

Epoch: 6| Step: 2
Training loss: 4.270468711853027
Validation loss: 4.685600444834719

Epoch: 6| Step: 3
Training loss: 3.835610866546631
Validation loss: 4.6790088633055325

Epoch: 6| Step: 4
Training loss: 5.142762184143066
Validation loss: 4.674927224395096

Epoch: 6| Step: 5
Training loss: 3.5664162635803223
Validation loss: 4.668624529274561

Epoch: 6| Step: 6
Training loss: 5.6657915115356445
Validation loss: 4.6643121421978035

Epoch: 6| Step: 7
Training loss: 5.486907482147217
Validation loss: 4.6579202528922785

Epoch: 6| Step: 8
Training loss: 4.0594892501831055
Validation loss: 4.653731120529995

Epoch: 6| Step: 9
Training loss: 4.57940149307251
Validation loss: 4.647859086272537

Epoch: 6| Step: 10
Training loss: 3.8752830028533936
Validation loss: 4.6428038689398

Epoch: 6| Step: 11
Training loss: 4.612028121948242
Validation loss: 4.636583953775386

Epoch: 6| Step: 12
Training loss: 4.324749946594238
Validation loss: 4.63110210049537

Epoch: 6| Step: 13
Training loss: 4.176582336425781
Validation loss: 4.625122162603563

Epoch: 2| Step: 0
Training loss: 3.3594138622283936
Validation loss: 4.621494570086079

Epoch: 6| Step: 1
Training loss: 4.077970027923584
Validation loss: 4.616088554423342

Epoch: 6| Step: 2
Training loss: 4.846819877624512
Validation loss: 4.611081477134459

Epoch: 6| Step: 3
Training loss: 4.3514556884765625
Validation loss: 4.604589831444525

Epoch: 6| Step: 4
Training loss: 3.8482770919799805
Validation loss: 4.600144576000911

Epoch: 6| Step: 5
Training loss: 3.1850228309631348
Validation loss: 4.5949081041479625

Epoch: 6| Step: 6
Training loss: 4.831080436706543
Validation loss: 4.588569238621702

Epoch: 6| Step: 7
Training loss: 4.085310459136963
Validation loss: 4.584554687623055

Epoch: 6| Step: 8
Training loss: 3.693871021270752
Validation loss: 4.576940213480303

Epoch: 6| Step: 9
Training loss: 5.309771537780762
Validation loss: 4.572245813185169

Epoch: 6| Step: 10
Training loss: 4.687590599060059
Validation loss: 4.564252361174552

Epoch: 6| Step: 11
Training loss: 5.434914588928223
Validation loss: 4.560850030632429

Epoch: 6| Step: 12
Training loss: 4.967451095581055
Validation loss: 4.554545443545106

Epoch: 6| Step: 13
Training loss: 4.9530558586120605
Validation loss: 4.548612599731774

Epoch: 3| Step: 0
Training loss: 5.068877220153809
Validation loss: 4.542270245090608

Epoch: 6| Step: 1
Training loss: 4.0099921226501465
Validation loss: 4.533959829679099

Epoch: 6| Step: 2
Training loss: 3.605318546295166
Validation loss: 4.5319557651396725

Epoch: 6| Step: 3
Training loss: 4.229958534240723
Validation loss: 4.524608694097047

Epoch: 6| Step: 4
Training loss: 5.219989776611328
Validation loss: 4.518139357207923

Epoch: 6| Step: 5
Training loss: 4.153021812438965
Validation loss: 4.510022742773897

Epoch: 6| Step: 6
Training loss: 3.7532103061676025
Validation loss: 4.50357558137627

Epoch: 6| Step: 7
Training loss: 4.5706024169921875
Validation loss: 4.499227698131274

Epoch: 6| Step: 8
Training loss: 3.773122787475586
Validation loss: 4.492317061270437

Epoch: 6| Step: 9
Training loss: 5.023468017578125
Validation loss: 4.486110430891796

Epoch: 6| Step: 10
Training loss: 4.4571213722229
Validation loss: 4.478108416321457

Epoch: 6| Step: 11
Training loss: 3.775062084197998
Validation loss: 4.4747458939911215

Epoch: 6| Step: 12
Training loss: 4.145343780517578
Validation loss: 4.464806361864972

Epoch: 6| Step: 13
Training loss: 4.644908905029297
Validation loss: 4.459681187906573

Epoch: 4| Step: 0
Training loss: 3.7804646492004395
Validation loss: 4.45279606439734

Epoch: 6| Step: 1
Training loss: 3.101374626159668
Validation loss: 4.445566741369104

Epoch: 6| Step: 2
Training loss: 4.167981147766113
Validation loss: 4.437876552663823

Epoch: 6| Step: 3
Training loss: 4.974607467651367
Validation loss: 4.431390818729196

Epoch: 6| Step: 4
Training loss: 4.66456413269043
Validation loss: 4.424372226961197

Epoch: 6| Step: 5
Training loss: 3.7288990020751953
Validation loss: 4.415017243354551

Epoch: 6| Step: 6
Training loss: 4.410131931304932
Validation loss: 4.412355771628759

Epoch: 6| Step: 7
Training loss: 4.072222709655762
Validation loss: 4.404096157320084

Epoch: 6| Step: 8
Training loss: 2.731262683868408
Validation loss: 4.39546569701164

Epoch: 6| Step: 9
Training loss: 4.616908550262451
Validation loss: 4.387137741170903

Epoch: 6| Step: 10
Training loss: 4.103998184204102
Validation loss: 4.381440506186537

Epoch: 6| Step: 11
Training loss: 4.898067951202393
Validation loss: 4.373431303167856

Epoch: 6| Step: 12
Training loss: 5.608168601989746
Validation loss: 4.367901048352642

Epoch: 6| Step: 13
Training loss: 4.01886510848999
Validation loss: 4.357970381295809

Epoch: 5| Step: 0
Training loss: 4.241282939910889
Validation loss: 4.348344654165288

Epoch: 6| Step: 1
Training loss: 4.971756935119629
Validation loss: 4.341481634365615

Epoch: 6| Step: 2
Training loss: 4.024609565734863
Validation loss: 4.334043082370553

Epoch: 6| Step: 3
Training loss: 3.623136520385742
Validation loss: 4.325731810703073

Epoch: 6| Step: 4
Training loss: 3.542245388031006
Validation loss: 4.321389854595226

Epoch: 6| Step: 5
Training loss: 4.869594097137451
Validation loss: 4.309207434295326

Epoch: 6| Step: 6
Training loss: 3.6848859786987305
Validation loss: 4.302935328534854

Epoch: 6| Step: 7
Training loss: 2.9643001556396484
Validation loss: 4.297995813431278

Epoch: 6| Step: 8
Training loss: 4.423340320587158
Validation loss: 4.284161285687518

Epoch: 6| Step: 9
Training loss: 4.885889053344727
Validation loss: 4.277814549784506

Epoch: 6| Step: 10
Training loss: 5.233831405639648
Validation loss: 4.269185563569428

Epoch: 6| Step: 11
Training loss: 3.037193536758423
Validation loss: 4.260962422176074

Epoch: 6| Step: 12
Training loss: 3.7726306915283203
Validation loss: 4.252992060876662

Epoch: 6| Step: 13
Training loss: 4.3954057693481445
Validation loss: 4.2458871615830285

Epoch: 6| Step: 0
Training loss: 4.293013095855713
Validation loss: 4.235103402086484

Epoch: 6| Step: 1
Training loss: 4.595703125
Validation loss: 4.225296133308

Epoch: 6| Step: 2
Training loss: 3.579366683959961
Validation loss: 4.218745011155323

Epoch: 6| Step: 3
Training loss: 3.825066089630127
Validation loss: 4.208040580954603

Epoch: 6| Step: 4
Training loss: 4.485467433929443
Validation loss: 4.198487312563004

Epoch: 6| Step: 5
Training loss: 3.689267635345459
Validation loss: 4.191343958659838

Epoch: 6| Step: 6
Training loss: 3.093379497528076
Validation loss: 4.181155799537577

Epoch: 6| Step: 7
Training loss: 4.035418510437012
Validation loss: 4.174294594795473

Epoch: 6| Step: 8
Training loss: 4.945490837097168
Validation loss: 4.165119468524892

Epoch: 6| Step: 9
Training loss: 4.021996021270752
Validation loss: 4.154753218414963

Epoch: 6| Step: 10
Training loss: 2.600459098815918
Validation loss: 4.1449937153888

Epoch: 6| Step: 11
Training loss: 3.983078956604004
Validation loss: 4.133078590516122

Epoch: 6| Step: 12
Training loss: 3.7185580730438232
Validation loss: 4.125073653395458

Epoch: 6| Step: 13
Training loss: 5.991632461547852
Validation loss: 4.11333022322706

Epoch: 7| Step: 0
Training loss: 3.9129714965820312
Validation loss: 4.105103477354972

Epoch: 6| Step: 1
Training loss: 3.592799186706543
Validation loss: 4.097010417651105

Epoch: 6| Step: 2
Training loss: 3.1939282417297363
Validation loss: 4.085010641364641

Epoch: 6| Step: 3
Training loss: 4.643914699554443
Validation loss: 4.077792700900827

Epoch: 6| Step: 4
Training loss: 3.195133686065674
Validation loss: 4.068955047156221

Epoch: 6| Step: 5
Training loss: 5.090583801269531
Validation loss: 4.058160597278226

Epoch: 6| Step: 6
Training loss: 3.0968523025512695
Validation loss: 4.04669282256916

Epoch: 6| Step: 7
Training loss: 4.2874274253845215
Validation loss: 4.038762054135723

Epoch: 6| Step: 8
Training loss: 4.679537296295166
Validation loss: 4.028826000869915

Epoch: 6| Step: 9
Training loss: 3.3285365104675293
Validation loss: 4.016078354209982

Epoch: 6| Step: 10
Training loss: 3.436588764190674
Validation loss: 4.006738244846303

Epoch: 6| Step: 11
Training loss: 3.1243886947631836
Validation loss: 3.998029455061882

Epoch: 6| Step: 12
Training loss: 4.1905364990234375
Validation loss: 3.984325255117109

Epoch: 6| Step: 13
Training loss: 4.973088264465332
Validation loss: 3.973673100112587

Epoch: 8| Step: 0
Training loss: 4.169118881225586
Validation loss: 3.96181910012358

Epoch: 6| Step: 1
Training loss: 3.6882576942443848
Validation loss: 3.9518304845338226

Epoch: 6| Step: 2
Training loss: 4.431370735168457
Validation loss: 3.9423458140383483

Epoch: 6| Step: 3
Training loss: 1.6521433591842651
Validation loss: 3.9303987410760697

Epoch: 6| Step: 4
Training loss: 3.9917004108428955
Validation loss: 3.9213206691126667

Epoch: 6| Step: 5
Training loss: 3.959691286087036
Validation loss: 3.908557794427359

Epoch: 6| Step: 6
Training loss: 4.146060943603516
Validation loss: 3.898559801040157

Epoch: 6| Step: 7
Training loss: 5.27801513671875
Validation loss: 3.885326621352985

Epoch: 6| Step: 8
Training loss: 3.7825448513031006
Validation loss: 3.876561716038694

Epoch: 6| Step: 9
Training loss: 3.5377886295318604
Validation loss: 3.868585865984681

Epoch: 6| Step: 10
Training loss: 3.382148265838623
Validation loss: 3.8545896571169616

Epoch: 6| Step: 11
Training loss: 3.088967800140381
Validation loss: 3.841707552632978

Epoch: 6| Step: 12
Training loss: 3.3055100440979004
Validation loss: 3.8311403489881948

Epoch: 6| Step: 13
Training loss: 4.381404876708984
Validation loss: 3.820211297722273

Epoch: 9| Step: 0
Training loss: 3.5589330196380615
Validation loss: 3.809248980655465

Epoch: 6| Step: 1
Training loss: 2.8751792907714844
Validation loss: 3.7987137738094536

Epoch: 6| Step: 2
Training loss: 5.070830345153809
Validation loss: 3.7886809456732964

Epoch: 6| Step: 3
Training loss: 2.643714666366577
Validation loss: 3.7773131837127027

Epoch: 6| Step: 4
Training loss: 4.4766950607299805
Validation loss: 3.765130332721177

Epoch: 6| Step: 5
Training loss: 4.405781269073486
Validation loss: 3.753342902788552

Epoch: 6| Step: 6
Training loss: 3.9811081886291504
Validation loss: 3.7424657421727336

Epoch: 6| Step: 7
Training loss: 3.6151909828186035
Validation loss: 3.732807210696641

Epoch: 6| Step: 8
Training loss: 3.762284517288208
Validation loss: 3.7239441948552288

Epoch: 6| Step: 9
Training loss: 3.6981351375579834
Validation loss: 3.707884350130635

Epoch: 6| Step: 10
Training loss: 2.609236240386963
Validation loss: 3.696550553844821

Epoch: 6| Step: 11
Training loss: 2.995609760284424
Validation loss: 3.685708297196255

Epoch: 6| Step: 12
Training loss: 3.482415199279785
Validation loss: 3.6685272186033187

Epoch: 6| Step: 13
Training loss: 3.3685786724090576
Validation loss: 3.6561384431777464

Epoch: 10| Step: 0
Training loss: 4.20095157623291
Validation loss: 3.6438388311734764

Epoch: 6| Step: 1
Training loss: 3.5863006114959717
Validation loss: 3.630517377648302

Epoch: 6| Step: 2
Training loss: 3.1816518306732178
Validation loss: 3.622872414127473

Epoch: 6| Step: 3
Training loss: 3.2176713943481445
Validation loss: 3.610345942999727

Epoch: 6| Step: 4
Training loss: 4.461340427398682
Validation loss: 3.6004012451376965

Epoch: 6| Step: 5
Training loss: 3.982692003250122
Validation loss: 3.5860697018202914

Epoch: 6| Step: 6
Training loss: 3.1697659492492676
Validation loss: 3.5719576266504105

Epoch: 6| Step: 7
Training loss: 3.8044328689575195
Validation loss: 3.555894523538569

Epoch: 6| Step: 8
Training loss: 3.376206398010254
Validation loss: 3.545483450735769

Epoch: 6| Step: 9
Training loss: 4.222142219543457
Validation loss: 3.530957237366707

Epoch: 6| Step: 10
Training loss: 1.8815109729766846
Validation loss: 3.5182166407185216

Epoch: 6| Step: 11
Training loss: 3.1795928478240967
Validation loss: 3.5027407420578824

Epoch: 6| Step: 12
Training loss: 2.8907291889190674
Validation loss: 3.491040814307428

Epoch: 6| Step: 13
Training loss: 3.4528369903564453
Validation loss: 3.482772170856435

Epoch: 11| Step: 0
Training loss: 2.862137794494629
Validation loss: 3.4685081615242908

Epoch: 6| Step: 1
Training loss: 3.150818347930908
Validation loss: 3.4518846132422007

Epoch: 6| Step: 2
Training loss: 3.709235191345215
Validation loss: 3.440629287432599

Epoch: 6| Step: 3
Training loss: 3.3306069374084473
Validation loss: 3.4248699116450485

Epoch: 6| Step: 4
Training loss: 3.0206923484802246
Validation loss: 3.4126268561168382

Epoch: 6| Step: 5
Training loss: 3.91178035736084
Validation loss: 3.4018489391573015

Epoch: 6| Step: 6
Training loss: 4.407555103302002
Validation loss: 3.385197206210065

Epoch: 6| Step: 7
Training loss: 3.3220930099487305
Validation loss: 3.3721930339772213

Epoch: 6| Step: 8
Training loss: 3.1230952739715576
Validation loss: 3.3626217713920017

Epoch: 6| Step: 9
Training loss: 2.9387412071228027
Validation loss: 3.337692645288283

Epoch: 6| Step: 10
Training loss: 3.7985148429870605
Validation loss: 3.3244712583480345

Epoch: 6| Step: 11
Training loss: 3.1264452934265137
Validation loss: 3.3044462332161526

Epoch: 6| Step: 12
Training loss: 3.1583051681518555
Validation loss: 3.2971613509680635

Epoch: 6| Step: 13
Training loss: 1.8187792301177979
Validation loss: 3.2773951740675074

Epoch: 12| Step: 0
Training loss: 3.35870623588562
Validation loss: 3.262784204175395

Epoch: 6| Step: 1
Training loss: 2.9904794692993164
Validation loss: 3.245081624677104

Epoch: 6| Step: 2
Training loss: 3.438730001449585
Validation loss: 3.235057471900858

Epoch: 6| Step: 3
Training loss: 2.890471935272217
Validation loss: 3.2163953934946368

Epoch: 6| Step: 4
Training loss: 3.7362101078033447
Validation loss: 3.2033906059880413

Epoch: 6| Step: 5
Training loss: 2.4250378608703613
Validation loss: 3.1931739725092405

Epoch: 6| Step: 6
Training loss: 2.477511405944824
Validation loss: 3.1747026853663947

Epoch: 6| Step: 7
Training loss: 3.2664859294891357
Validation loss: 3.1524240586065475

Epoch: 6| Step: 8
Training loss: 3.0380306243896484
Validation loss: 3.1427874385669665

Epoch: 6| Step: 9
Training loss: 3.4209938049316406
Validation loss: 3.1339633105903544

Epoch: 6| Step: 10
Training loss: 2.918285369873047
Validation loss: 3.1217441892111175

Epoch: 6| Step: 11
Training loss: 3.2494802474975586
Validation loss: 3.0998964309692383

Epoch: 6| Step: 12
Training loss: 3.7118186950683594
Validation loss: 3.088676788473642

Epoch: 6| Step: 13
Training loss: 3.0091712474823
Validation loss: 3.0707727298941663

Epoch: 13| Step: 0
Training loss: 3.547790288925171
Validation loss: 3.056636884648313

Epoch: 6| Step: 1
Training loss: 2.041139841079712
Validation loss: 3.0417744959554365

Epoch: 6| Step: 2
Training loss: 2.5902204513549805
Validation loss: 3.027872341935353

Epoch: 6| Step: 3
Training loss: 2.7495217323303223
Validation loss: 3.016215575638638

Epoch: 6| Step: 4
Training loss: 4.240516185760498
Validation loss: 2.9967545693920505

Epoch: 6| Step: 5
Training loss: 3.8969154357910156
Validation loss: 2.9780331580869612

Epoch: 6| Step: 6
Training loss: 3.6914851665496826
Validation loss: 2.9699221682804886

Epoch: 6| Step: 7
Training loss: 2.028073787689209
Validation loss: 2.9552353787165817

Epoch: 6| Step: 8
Training loss: 2.7318525314331055
Validation loss: 2.9402010799736105

Epoch: 6| Step: 9
Training loss: 2.858311891555786
Validation loss: 2.9224245240611415

Epoch: 6| Step: 10
Training loss: 3.381080150604248
Validation loss: 2.9112013898869997

Epoch: 6| Step: 11
Training loss: 2.790520429611206
Validation loss: 2.8894853156100035

Epoch: 6| Step: 12
Training loss: 2.609522819519043
Validation loss: 2.8843989679890294

Epoch: 6| Step: 13
Training loss: 2.607174873352051
Validation loss: 2.8649453629729567

Epoch: 14| Step: 0
Training loss: 3.207306385040283
Validation loss: 2.8543914159139

Epoch: 6| Step: 1
Training loss: 2.006139039993286
Validation loss: 2.8322564248115785

Epoch: 6| Step: 2
Training loss: 2.941108226776123
Validation loss: 2.821188429350494

Epoch: 6| Step: 3
Training loss: 2.374014139175415
Validation loss: 2.804445787142682

Epoch: 6| Step: 4
Training loss: 3.0012593269348145
Validation loss: 2.7918487018154514

Epoch: 6| Step: 5
Training loss: 3.0485024452209473
Validation loss: 2.783168315887451

Epoch: 6| Step: 6
Training loss: 3.002084732055664
Validation loss: 2.7704988397577757

Epoch: 6| Step: 7
Training loss: 3.0639336109161377
Validation loss: 2.754858873223746

Epoch: 6| Step: 8
Training loss: 3.651919364929199
Validation loss: 2.7371411579911427

Epoch: 6| Step: 9
Training loss: 3.197953224182129
Validation loss: 2.7241989848434285

Epoch: 6| Step: 10
Training loss: 2.5136592388153076
Validation loss: 2.7049270240209435

Epoch: 6| Step: 11
Training loss: 2.105926036834717
Validation loss: 2.690605527611189

Epoch: 6| Step: 12
Training loss: 3.058669090270996
Validation loss: 2.671715469770534

Epoch: 6| Step: 13
Training loss: 2.808789014816284
Validation loss: 2.6575330124106458

Epoch: 15| Step: 0
Training loss: 3.071023941040039
Validation loss: 2.6423971473529773

Epoch: 6| Step: 1
Training loss: 2.3543508052825928
Validation loss: 2.619891110286918

Epoch: 6| Step: 2
Training loss: 2.5224215984344482
Validation loss: 2.6054430059207383

Epoch: 6| Step: 3
Training loss: 2.9433016777038574
Validation loss: 2.5952686520032984

Epoch: 6| Step: 4
Training loss: 3.0581212043762207
Validation loss: 2.56874055247153

Epoch: 6| Step: 5
Training loss: 2.9612765312194824
Validation loss: 2.563033442343435

Epoch: 6| Step: 6
Training loss: 2.364330530166626
Validation loss: 2.542044770333075

Epoch: 6| Step: 7
Training loss: 2.7288146018981934
Validation loss: 2.5274940459958968

Epoch: 6| Step: 8
Training loss: 3.017538547515869
Validation loss: 2.5149955441874843

Epoch: 6| Step: 9
Training loss: 2.5698821544647217
Validation loss: 2.4888122697030344

Epoch: 6| Step: 10
Training loss: 2.5772924423217773
Validation loss: 2.4831953817798245

Epoch: 6| Step: 11
Training loss: 2.594031810760498
Validation loss: 2.475765971727269

Epoch: 6| Step: 12
Training loss: 2.968977451324463
Validation loss: 2.4568365132936867

Epoch: 6| Step: 13
Training loss: 2.4981043338775635
Validation loss: 2.4497838609962055

Epoch: 16| Step: 0
Training loss: 2.4467132091522217
Validation loss: 2.437712105371619

Epoch: 6| Step: 1
Training loss: 2.4619975090026855
Validation loss: 2.4195517340014057

Epoch: 6| Step: 2
Training loss: 3.238053321838379
Validation loss: 2.403864309351931

Epoch: 6| Step: 3
Training loss: 2.9122719764709473
Validation loss: 2.401128831730094

Epoch: 6| Step: 4
Training loss: 3.0084152221679688
Validation loss: 2.3799311627623854

Epoch: 6| Step: 5
Training loss: 2.209595203399658
Validation loss: 2.3736247913811797

Epoch: 6| Step: 6
Training loss: 2.5872671604156494
Validation loss: 2.3648375926479215

Epoch: 6| Step: 7
Training loss: 3.164999008178711
Validation loss: 2.3607221726448304

Epoch: 6| Step: 8
Training loss: 2.0806264877319336
Validation loss: 2.3499188448793147

Epoch: 6| Step: 9
Training loss: 1.636558175086975
Validation loss: 2.3489090140147875

Epoch: 6| Step: 10
Training loss: 3.2058911323547363
Validation loss: 2.342387495502349

Epoch: 6| Step: 11
Training loss: 2.635173797607422
Validation loss: 2.31758616816613

Epoch: 6| Step: 12
Training loss: 2.839263439178467
Validation loss: 2.310376972280523

Epoch: 6| Step: 13
Training loss: 1.8296148777008057
Validation loss: 2.3078051356859106

Epoch: 17| Step: 0
Training loss: 2.7869057655334473
Validation loss: 2.297694465165497

Epoch: 6| Step: 1
Training loss: 2.3537683486938477
Validation loss: 2.289747025377007

Epoch: 6| Step: 2
Training loss: 2.144151449203491
Validation loss: 2.2829674854073474

Epoch: 6| Step: 3
Training loss: 2.964320182800293
Validation loss: 2.2686399567511772

Epoch: 6| Step: 4
Training loss: 2.5393338203430176
Validation loss: 2.267839406126289

Epoch: 6| Step: 5
Training loss: 3.042774200439453
Validation loss: 2.2553840478261313

Epoch: 6| Step: 6
Training loss: 2.246896505355835
Validation loss: 2.2483529967646443

Epoch: 6| Step: 7
Training loss: 2.237260341644287
Validation loss: 2.238969933602118

Epoch: 6| Step: 8
Training loss: 2.2614099979400635
Validation loss: 2.2296063489811395

Epoch: 6| Step: 9
Training loss: 2.8952999114990234
Validation loss: 2.2338036580752303

Epoch: 6| Step: 10
Training loss: 2.3143858909606934
Validation loss: 2.2252241693517214

Epoch: 6| Step: 11
Training loss: 2.729980945587158
Validation loss: 2.220888360854118

Epoch: 6| Step: 12
Training loss: 2.7427151203155518
Validation loss: 2.2090324227527907

Epoch: 6| Step: 13
Training loss: 2.1309919357299805
Validation loss: 2.21877355985744

Epoch: 18| Step: 0
Training loss: 2.786355972290039
Validation loss: 2.2035489518155336

Epoch: 6| Step: 1
Training loss: 2.6299936771392822
Validation loss: 2.193343062554636

Epoch: 6| Step: 2
Training loss: 2.373447895050049
Validation loss: 2.1931356486453804

Epoch: 6| Step: 3
Training loss: 2.93967342376709
Validation loss: 2.1999419966051654

Epoch: 6| Step: 4
Training loss: 2.0944442749023438
Validation loss: 2.1942387985926803

Epoch: 6| Step: 5
Training loss: 2.890122175216675
Validation loss: 2.176656018021286

Epoch: 6| Step: 6
Training loss: 2.847756862640381
Validation loss: 2.1824642304451234

Epoch: 6| Step: 7
Training loss: 2.4787192344665527
Validation loss: 2.1789546397424515

Epoch: 6| Step: 8
Training loss: 2.573436737060547
Validation loss: 2.1661590401844313

Epoch: 6| Step: 9
Training loss: 2.7436883449554443
Validation loss: 2.1650217220347416

Epoch: 6| Step: 10
Training loss: 1.8160252571105957
Validation loss: 2.155287124777353

Epoch: 6| Step: 11
Training loss: 2.472689151763916
Validation loss: 2.154004593049326

Epoch: 6| Step: 12
Training loss: 2.1022675037384033
Validation loss: 2.1575560621035996

Epoch: 6| Step: 13
Training loss: 2.200350284576416
Validation loss: 2.159727168339555

Epoch: 19| Step: 0
Training loss: 1.7946553230285645
Validation loss: 2.147630294164022

Epoch: 6| Step: 1
Training loss: 2.4408011436462402
Validation loss: 2.146956177167995

Epoch: 6| Step: 2
Training loss: 2.4555866718292236
Validation loss: 2.1442103719198577

Epoch: 6| Step: 3
Training loss: 2.5200510025024414
Validation loss: 2.1447773851374143

Epoch: 6| Step: 4
Training loss: 2.298948049545288
Validation loss: 2.1462020617659374

Epoch: 6| Step: 5
Training loss: 2.8619985580444336
Validation loss: 2.1398953186568392

Epoch: 6| Step: 6
Training loss: 2.455930709838867
Validation loss: 2.13439485590945

Epoch: 6| Step: 7
Training loss: 2.1292459964752197
Validation loss: 2.1318585026648735

Epoch: 6| Step: 8
Training loss: 3.113846778869629
Validation loss: 2.125724520734561

Epoch: 6| Step: 9
Training loss: 1.9618778228759766
Validation loss: 2.1331491957428637

Epoch: 6| Step: 10
Training loss: 2.7286391258239746
Validation loss: 2.129766656506446

Epoch: 6| Step: 11
Training loss: 2.695517063140869
Validation loss: 2.1323566359858357

Epoch: 6| Step: 12
Training loss: 2.396946430206299
Validation loss: 2.129127820332845

Epoch: 6| Step: 13
Training loss: 3.0769643783569336
Validation loss: 2.1188321113586426

Epoch: 20| Step: 0
Training loss: 2.54819917678833
Validation loss: 2.1270887300532353

Epoch: 6| Step: 1
Training loss: 1.6163170337677002
Validation loss: 2.1292972077605543

Epoch: 6| Step: 2
Training loss: 2.406864643096924
Validation loss: 2.133073196616224

Epoch: 6| Step: 3
Training loss: 2.3708581924438477
Validation loss: 2.117578003996162

Epoch: 6| Step: 4
Training loss: 2.3730416297912598
Validation loss: 2.113304697057252

Epoch: 6| Step: 5
Training loss: 2.927553176879883
Validation loss: 2.1189815844258955

Epoch: 6| Step: 6
Training loss: 2.8433542251586914
Validation loss: 2.1161492229789816

Epoch: 6| Step: 7
Training loss: 1.3341710567474365
Validation loss: 2.1032932983931674

Epoch: 6| Step: 8
Training loss: 2.5176472663879395
Validation loss: 2.102227421217067

Epoch: 6| Step: 9
Training loss: 3.3319196701049805
Validation loss: 2.10502270472947

Epoch: 6| Step: 10
Training loss: 2.6541104316711426
Validation loss: 2.1117746560804305

Epoch: 6| Step: 11
Training loss: 2.773444890975952
Validation loss: 2.0983341983569566

Epoch: 6| Step: 12
Training loss: 2.509674549102783
Validation loss: 2.1131071134280135

Epoch: 6| Step: 13
Training loss: 2.0985634326934814
Validation loss: 2.093563175970508

Epoch: 21| Step: 0
Training loss: 2.470205783843994
Validation loss: 2.0920010920493834

Epoch: 6| Step: 1
Training loss: 3.038670539855957
Validation loss: 2.0898390482830744

Epoch: 6| Step: 2
Training loss: 2.2373290061950684
Validation loss: 2.0935620877050583

Epoch: 6| Step: 3
Training loss: 3.121938943862915
Validation loss: 2.0884795522177093

Epoch: 6| Step: 4
Training loss: 3.1872143745422363
Validation loss: 2.081667318139025

Epoch: 6| Step: 5
Training loss: 3.0526697635650635
Validation loss: 2.087866976696958

Epoch: 6| Step: 6
Training loss: 1.7230768203735352
Validation loss: 2.085551705411685

Epoch: 6| Step: 7
Training loss: 1.6818599700927734
Validation loss: 2.0911111101027458

Epoch: 6| Step: 8
Training loss: 2.2578442096710205
Validation loss: 2.0792980027455155

Epoch: 6| Step: 9
Training loss: 2.314293384552002
Validation loss: 2.0929967408539145

Epoch: 6| Step: 10
Training loss: 2.7131340503692627
Validation loss: 2.0812482859498713

Epoch: 6| Step: 11
Training loss: 1.6347897052764893
Validation loss: 2.0876287362908803

Epoch: 6| Step: 12
Training loss: 2.056321620941162
Validation loss: 2.0788040622588126

Epoch: 6| Step: 13
Training loss: 3.2115402221679688
Validation loss: 2.0796146982459613

Epoch: 22| Step: 0
Training loss: 2.4763402938842773
Validation loss: 2.086194061463879

Epoch: 6| Step: 1
Training loss: 2.060114860534668
Validation loss: 2.080524335625351

Epoch: 6| Step: 2
Training loss: 2.655590534210205
Validation loss: 2.070091568013673

Epoch: 6| Step: 3
Training loss: 2.305086135864258
Validation loss: 2.0745833689166653

Epoch: 6| Step: 4
Training loss: 2.234755516052246
Validation loss: 2.079884877768896

Epoch: 6| Step: 5
Training loss: 2.3436741828918457
Validation loss: 2.076730123130224

Epoch: 6| Step: 6
Training loss: 3.2198991775512695
Validation loss: 2.0802718336864183

Epoch: 6| Step: 7
Training loss: 3.075080633163452
Validation loss: 2.067531672857141

Epoch: 6| Step: 8
Training loss: 1.8660948276519775
Validation loss: 2.079084647599087

Epoch: 6| Step: 9
Training loss: 2.4948570728302
Validation loss: 2.0986687573053504

Epoch: 6| Step: 10
Training loss: 1.8980263471603394
Validation loss: 2.0763603692413657

Epoch: 6| Step: 11
Training loss: 2.9094724655151367
Validation loss: 2.07456309564652

Epoch: 6| Step: 12
Training loss: 1.577962040901184
Validation loss: 2.079816682364351

Epoch: 6| Step: 13
Training loss: 3.6684062480926514
Validation loss: 2.0756423473358154

Epoch: 23| Step: 0
Training loss: 2.7468810081481934
Validation loss: 2.071311204664169

Epoch: 6| Step: 1
Training loss: 1.9569870233535767
Validation loss: 2.0749703402160318

Epoch: 6| Step: 2
Training loss: 2.517456293106079
Validation loss: 2.095020008343522

Epoch: 6| Step: 3
Training loss: 2.3298730850219727
Validation loss: 2.0809658970884097

Epoch: 6| Step: 4
Training loss: 2.5450029373168945
Validation loss: 2.080827602776148

Epoch: 6| Step: 5
Training loss: 2.2572154998779297
Validation loss: 2.0794815312149706

Epoch: 6| Step: 6
Training loss: 1.8940045833587646
Validation loss: 2.089067764179681

Epoch: 6| Step: 7
Training loss: 2.7827532291412354
Validation loss: 2.0942314581204484

Epoch: 6| Step: 8
Training loss: 2.892434597015381
Validation loss: 2.0783773468386744

Epoch: 6| Step: 9
Training loss: 2.0893101692199707
Validation loss: 2.0912132468274844

Epoch: 6| Step: 10
Training loss: 2.1989595890045166
Validation loss: 2.0873533487319946

Epoch: 6| Step: 11
Training loss: 3.07932710647583
Validation loss: 2.0953541442912114

Epoch: 6| Step: 12
Training loss: 2.03141713142395
Validation loss: 2.0934655461260068

Epoch: 6| Step: 13
Training loss: 3.057404041290283
Validation loss: 2.094714818462249

Epoch: 24| Step: 0
Training loss: 2.0345120429992676
Validation loss: 2.0809911425395677

Epoch: 6| Step: 1
Training loss: 2.7643423080444336
Validation loss: 2.0845409465092484

Epoch: 6| Step: 2
Training loss: 2.660785675048828
Validation loss: 2.0875855748371412

Epoch: 6| Step: 3
Training loss: 2.9483814239501953
Validation loss: 2.086052207536595

Epoch: 6| Step: 4
Training loss: 2.2540555000305176
Validation loss: 2.086190833840319

Epoch: 6| Step: 5
Training loss: 1.8164865970611572
Validation loss: 2.0826164676297094

Epoch: 6| Step: 6
Training loss: 3.242489814758301
Validation loss: 2.0821577887381277

Epoch: 6| Step: 7
Training loss: 2.6030712127685547
Validation loss: 2.065972405095254

Epoch: 6| Step: 8
Training loss: 2.5192408561706543
Validation loss: 2.071259888269568

Epoch: 6| Step: 9
Training loss: 2.1172964572906494
Validation loss: 2.0766566235532045

Epoch: 6| Step: 10
Training loss: 2.5316810607910156
Validation loss: 2.0969176497510684

Epoch: 6| Step: 11
Training loss: 1.7245445251464844
Validation loss: 2.0787810484568277

Epoch: 6| Step: 12
Training loss: 2.5873374938964844
Validation loss: 2.0794662070530716

Epoch: 6| Step: 13
Training loss: 1.9872450828552246
Validation loss: 2.079553557980445

Epoch: 25| Step: 0
Training loss: 2.7999250888824463
Validation loss: 2.094769125343651

Epoch: 6| Step: 1
Training loss: 1.9879803657531738
Validation loss: 2.0854161324039584

Epoch: 6| Step: 2
Training loss: 2.1578903198242188
Validation loss: 2.0821213247955486

Epoch: 6| Step: 3
Training loss: 2.164262056350708
Validation loss: 2.0786004451013382

Epoch: 6| Step: 4
Training loss: 1.9359557628631592
Validation loss: 2.078728824533442

Epoch: 6| Step: 5
Training loss: 2.1597342491149902
Validation loss: 2.057140586196735

Epoch: 6| Step: 6
Training loss: 1.946976661682129
Validation loss: 2.0728563031842633

Epoch: 6| Step: 7
Training loss: 2.908794641494751
Validation loss: 2.057250180552083

Epoch: 6| Step: 8
Training loss: 2.7762296199798584
Validation loss: 2.0722952952948948

Epoch: 6| Step: 9
Training loss: 2.661971092224121
Validation loss: 2.0637657719273723

Epoch: 6| Step: 10
Training loss: 2.633387565612793
Validation loss: 2.0703154904868013

Epoch: 6| Step: 11
Training loss: 2.527587413787842
Validation loss: 2.075203893005207

Epoch: 6| Step: 12
Training loss: 2.455859661102295
Validation loss: 2.0635844469070435

Epoch: 6| Step: 13
Training loss: 3.161890983581543
Validation loss: 2.076560604956842

Epoch: 26| Step: 0
Training loss: 2.1425139904022217
Validation loss: 2.068596557904315

Epoch: 6| Step: 1
Training loss: 2.2859396934509277
Validation loss: 2.066796184867941

Epoch: 6| Step: 2
Training loss: 2.3233070373535156
Validation loss: 2.084115274490849

Epoch: 6| Step: 3
Training loss: 1.8234460353851318
Validation loss: 2.0528919312261764

Epoch: 6| Step: 4
Training loss: 2.379824161529541
Validation loss: 2.065265788826891

Epoch: 6| Step: 5
Training loss: 2.6360907554626465
Validation loss: 2.0658778118830856

Epoch: 6| Step: 6
Training loss: 2.5816359519958496
Validation loss: 2.063007623918595

Epoch: 6| Step: 7
Training loss: 2.854869842529297
Validation loss: 2.0673345109467864

Epoch: 6| Step: 8
Training loss: 2.02056884765625
Validation loss: 2.067031168168591

Epoch: 6| Step: 9
Training loss: 2.177957057952881
Validation loss: 2.068252678840391

Epoch: 6| Step: 10
Training loss: 2.7639942169189453
Validation loss: 2.0635598846661147

Epoch: 6| Step: 11
Training loss: 2.7712674140930176
Validation loss: 2.066745417092436

Epoch: 6| Step: 12
Training loss: 2.5012145042419434
Validation loss: 2.0540594208625054

Epoch: 6| Step: 13
Training loss: 2.6297407150268555
Validation loss: 2.054402224479183

Epoch: 27| Step: 0
Training loss: 2.1513049602508545
Validation loss: 2.0593880632872223

Epoch: 6| Step: 1
Training loss: 2.6680831909179688
Validation loss: 2.063118403957736

Epoch: 6| Step: 2
Training loss: 2.2478232383728027
Validation loss: 2.0640536841525825

Epoch: 6| Step: 3
Training loss: 2.345449924468994
Validation loss: 2.0604548967012795

Epoch: 6| Step: 4
Training loss: 2.7223479747772217
Validation loss: 2.0710374078442975

Epoch: 6| Step: 5
Training loss: 2.560612678527832
Validation loss: 2.0734749827333676

Epoch: 6| Step: 6
Training loss: 2.186572313308716
Validation loss: 2.065924790597731

Epoch: 6| Step: 7
Training loss: 2.011910915374756
Validation loss: 2.078413672344659

Epoch: 6| Step: 8
Training loss: 2.9516897201538086
Validation loss: 2.067794192221857

Epoch: 6| Step: 9
Training loss: 2.1785964965820312
Validation loss: 2.0605537878569735

Epoch: 6| Step: 10
Training loss: 2.218409538269043
Validation loss: 2.0555002817543606

Epoch: 6| Step: 11
Training loss: 2.2755160331726074
Validation loss: 2.068908505542304

Epoch: 6| Step: 12
Training loss: 2.7204437255859375
Validation loss: 2.0571368381541264

Epoch: 6| Step: 13
Training loss: 2.459538459777832
Validation loss: 2.068365240609774

Epoch: 28| Step: 0
Training loss: 2.5804715156555176
Validation loss: 2.0607687504060808

Epoch: 6| Step: 1
Training loss: 2.9848103523254395
Validation loss: 2.0668961668527253

Epoch: 6| Step: 2
Training loss: 2.0515072345733643
Validation loss: 2.063453823007563

Epoch: 6| Step: 3
Training loss: 2.562192916870117
Validation loss: 2.0534745518879225

Epoch: 6| Step: 4
Training loss: 2.1351230144500732
Validation loss: 2.0472188495820567

Epoch: 6| Step: 5
Training loss: 2.3889193534851074
Validation loss: 2.063345580972651

Epoch: 6| Step: 6
Training loss: 2.049022912979126
Validation loss: 2.0568874010475735

Epoch: 6| Step: 7
Training loss: 2.7582807540893555
Validation loss: 2.0519824028015137

Epoch: 6| Step: 8
Training loss: 2.26446795463562
Validation loss: 2.061472732533691

Epoch: 6| Step: 9
Training loss: 2.5148849487304688
Validation loss: 2.055941063870666

Epoch: 6| Step: 10
Training loss: 2.7393431663513184
Validation loss: 2.0632953541253203

Epoch: 6| Step: 11
Training loss: 1.8342928886413574
Validation loss: 2.0716016266935613

Epoch: 6| Step: 12
Training loss: 2.287515163421631
Validation loss: 2.056142714715773

Epoch: 6| Step: 13
Training loss: 2.583850860595703
Validation loss: 2.059467866856565

Epoch: 29| Step: 0
Training loss: 2.0730783939361572
Validation loss: 2.055454311832305

Epoch: 6| Step: 1
Training loss: 2.623137950897217
Validation loss: 2.067573698618079

Epoch: 6| Step: 2
Training loss: 2.3596479892730713
Validation loss: 2.0655575042129843

Epoch: 6| Step: 3
Training loss: 2.628725051879883
Validation loss: 2.0571229227127565

Epoch: 6| Step: 4
Training loss: 1.6984783411026
Validation loss: 2.055704738504143

Epoch: 6| Step: 5
Training loss: 2.738999366760254
Validation loss: 2.0571222561661915

Epoch: 6| Step: 6
Training loss: 2.8008675575256348
Validation loss: 2.044610504181154

Epoch: 6| Step: 7
Training loss: 2.3186333179473877
Validation loss: 2.046591438272948

Epoch: 6| Step: 8
Training loss: 2.075101852416992
Validation loss: 2.0504072032948977

Epoch: 6| Step: 9
Training loss: 2.804046630859375
Validation loss: 2.0525731886586835

Epoch: 6| Step: 10
Training loss: 2.22076153755188
Validation loss: 2.0497423397597445

Epoch: 6| Step: 11
Training loss: 2.992032289505005
Validation loss: 2.048617639849263

Epoch: 6| Step: 12
Training loss: 1.7423427104949951
Validation loss: 2.055832393707768

Epoch: 6| Step: 13
Training loss: 2.355170726776123
Validation loss: 2.04171694478681

Epoch: 30| Step: 0
Training loss: 2.7894985675811768
Validation loss: 2.0443416744150142

Epoch: 6| Step: 1
Training loss: 2.122318744659424
Validation loss: 2.0465262577097905

Epoch: 6| Step: 2
Training loss: 2.905125856399536
Validation loss: 2.0349337541928856

Epoch: 6| Step: 3
Training loss: 2.2496254444122314
Validation loss: 2.0510154693357405

Epoch: 6| Step: 4
Training loss: 2.4446587562561035
Validation loss: 2.0497823889537523

Epoch: 6| Step: 5
Training loss: 1.9261242151260376
Validation loss: 2.052167346400599

Epoch: 6| Step: 6
Training loss: 1.5231788158416748
Validation loss: 2.052496712694886

Epoch: 6| Step: 7
Training loss: 2.3208770751953125
Validation loss: 2.0485321770432177

Epoch: 6| Step: 8
Training loss: 3.0516529083251953
Validation loss: 2.0391124551014235

Epoch: 6| Step: 9
Training loss: 2.7962965965270996
Validation loss: 2.0600489903521795

Epoch: 6| Step: 10
Training loss: 2.4678590297698975
Validation loss: 2.050374436122115

Epoch: 6| Step: 11
Training loss: 2.3968963623046875
Validation loss: 2.0590790035904094

Epoch: 6| Step: 12
Training loss: 2.109442710876465
Validation loss: 2.050780621908044

Epoch: 6| Step: 13
Training loss: 2.2758474349975586
Validation loss: 2.040496018625075

Epoch: 31| Step: 0
Training loss: 2.3913159370422363
Validation loss: 2.0480182440050188

Epoch: 6| Step: 1
Training loss: 2.930290699005127
Validation loss: 2.0556186783698296

Epoch: 6| Step: 2
Training loss: 3.0472922325134277
Validation loss: 2.054314628724129

Epoch: 6| Step: 3
Training loss: 1.9134454727172852
Validation loss: 2.0611270730213453

Epoch: 6| Step: 4
Training loss: 2.29732346534729
Validation loss: 2.05060548551621

Epoch: 6| Step: 5
Training loss: 2.007448196411133
Validation loss: 2.0618016040453346

Epoch: 6| Step: 6
Training loss: 2.5719804763793945
Validation loss: 2.058862501575101

Epoch: 6| Step: 7
Training loss: 2.4185690879821777
Validation loss: 2.0569641513209187

Epoch: 6| Step: 8
Training loss: 2.510270118713379
Validation loss: 2.0664269513981317

Epoch: 6| Step: 9
Training loss: 2.329498291015625
Validation loss: 2.0611009008140972

Epoch: 6| Step: 10
Training loss: 2.1442418098449707
Validation loss: 2.074971559227154

Epoch: 6| Step: 11
Training loss: 2.1106250286102295
Validation loss: 2.069443775761512

Epoch: 6| Step: 12
Training loss: 2.642326831817627
Validation loss: 2.06004508080021

Epoch: 6| Step: 13
Training loss: 1.5607056617736816
Validation loss: 2.070237572475146

Epoch: 32| Step: 0
Training loss: 2.459418535232544
Validation loss: 2.0725159516898533

Epoch: 6| Step: 1
Training loss: 1.9661366939544678
Validation loss: 2.062039897006045

Epoch: 6| Step: 2
Training loss: 2.4695935249328613
Validation loss: 2.050997452069354

Epoch: 6| Step: 3
Training loss: 2.45849609375
Validation loss: 2.068587250606988

Epoch: 6| Step: 4
Training loss: 2.684760570526123
Validation loss: 2.05777165197557

Epoch: 6| Step: 5
Training loss: 2.40360689163208
Validation loss: 2.066111933800482

Epoch: 6| Step: 6
Training loss: 2.6860148906707764
Validation loss: 2.064790689817039

Epoch: 6| Step: 7
Training loss: 2.4424960613250732
Validation loss: 2.0629092801001763

Epoch: 6| Step: 8
Training loss: 2.752718925476074
Validation loss: 2.056504399545731

Epoch: 6| Step: 9
Training loss: 1.9275107383728027
Validation loss: 2.05993438664303

Epoch: 6| Step: 10
Training loss: 2.6315743923187256
Validation loss: 2.0469361223200315

Epoch: 6| Step: 11
Training loss: 1.934763789176941
Validation loss: 2.052932411111811

Epoch: 6| Step: 12
Training loss: 2.0297980308532715
Validation loss: 2.0530778772087506

Epoch: 6| Step: 13
Training loss: 2.2568070888519287
Validation loss: 2.0483736145880913

Epoch: 33| Step: 0
Training loss: 2.412336826324463
Validation loss: 2.0589443111932404

Epoch: 6| Step: 1
Training loss: 1.9730077981948853
Validation loss: 2.060112707076534

Epoch: 6| Step: 2
Training loss: 2.6924076080322266
Validation loss: 2.052082484768283

Epoch: 6| Step: 3
Training loss: 2.31787109375
Validation loss: 2.0487633238556566

Epoch: 6| Step: 4
Training loss: 2.485706329345703
Validation loss: 2.0487300606184107

Epoch: 6| Step: 5
Training loss: 2.3006134033203125
Validation loss: 2.0528076797403316

Epoch: 6| Step: 6
Training loss: 2.804412364959717
Validation loss: 2.051520978250811

Epoch: 6| Step: 7
Training loss: 1.8076775074005127
Validation loss: 2.0402719307971258

Epoch: 6| Step: 8
Training loss: 2.515613079071045
Validation loss: 2.0517001562221076

Epoch: 6| Step: 9
Training loss: 2.063157558441162
Validation loss: 2.059389593780682

Epoch: 6| Step: 10
Training loss: 2.6227846145629883
Validation loss: 2.056175157588015

Epoch: 6| Step: 11
Training loss: 2.7799179553985596
Validation loss: 2.054478519706316

Epoch: 6| Step: 12
Training loss: 2.421203851699829
Validation loss: 2.05629809441105

Epoch: 6| Step: 13
Training loss: 1.3956271409988403
Validation loss: 2.0526897086892077

Epoch: 34| Step: 0
Training loss: 2.025146007537842
Validation loss: 2.059190188684771

Epoch: 6| Step: 1
Training loss: 2.064377546310425
Validation loss: 2.034936776725195

Epoch: 6| Step: 2
Training loss: 3.420518398284912
Validation loss: 2.0436634914849394

Epoch: 6| Step: 3
Training loss: 1.7804648876190186
Validation loss: 2.0474074566236107

Epoch: 6| Step: 4
Training loss: 2.5010695457458496
Validation loss: 2.055585627914757

Epoch: 6| Step: 5
Training loss: 2.009082317352295
Validation loss: 2.039363807247531

Epoch: 6| Step: 6
Training loss: 2.380725145339966
Validation loss: 2.0387335695246214

Epoch: 6| Step: 7
Training loss: 2.6375694274902344
Validation loss: 2.0332150151652675

Epoch: 6| Step: 8
Training loss: 1.8300368785858154
Validation loss: 2.035090187544464

Epoch: 6| Step: 9
Training loss: 2.706782102584839
Validation loss: 2.048065887984409

Epoch: 6| Step: 10
Training loss: 2.3872768878936768
Validation loss: 2.03385865816506

Epoch: 6| Step: 11
Training loss: 2.5462026596069336
Validation loss: 2.029163458014047

Epoch: 6| Step: 12
Training loss: 2.2966976165771484
Validation loss: 2.050979015647724

Epoch: 6| Step: 13
Training loss: 2.4759082794189453
Validation loss: 2.0256192504718737

Epoch: 35| Step: 0
Training loss: 2.762744903564453
Validation loss: 2.042066261332522

Epoch: 6| Step: 1
Training loss: 2.4789090156555176
Validation loss: 2.047092604380782

Epoch: 6| Step: 2
Training loss: 2.3678033351898193
Validation loss: 2.0411021337714246

Epoch: 6| Step: 3
Training loss: 2.2534284591674805
Validation loss: 2.0424921333148913

Epoch: 6| Step: 4
Training loss: 2.6263084411621094
Validation loss: 2.0565904994164743

Epoch: 6| Step: 5
Training loss: 2.156248092651367
Validation loss: 2.0492110790744906

Epoch: 6| Step: 6
Training loss: 2.5653738975524902
Validation loss: 2.0474689596442768

Epoch: 6| Step: 7
Training loss: 2.8233625888824463
Validation loss: 2.062338063793798

Epoch: 6| Step: 8
Training loss: 1.6564133167266846
Validation loss: 2.062963342153898

Epoch: 6| Step: 9
Training loss: 1.9166339635849
Validation loss: 2.057867180916571

Epoch: 6| Step: 10
Training loss: 2.1941795349121094
Validation loss: 2.0670672552559965

Epoch: 6| Step: 11
Training loss: 1.9223326444625854
Validation loss: 2.046326575740691

Epoch: 6| Step: 12
Training loss: 2.91534423828125
Validation loss: 2.0510682111145346

Epoch: 6| Step: 13
Training loss: 2.279967784881592
Validation loss: 2.0514363076097224

Epoch: 36| Step: 0
Training loss: 2.2950780391693115
Validation loss: 2.0534346231850247

Epoch: 6| Step: 1
Training loss: 2.2374913692474365
Validation loss: 2.025913305180047

Epoch: 6| Step: 2
Training loss: 2.437629222869873
Validation loss: 2.035213424313453

Epoch: 6| Step: 3
Training loss: 2.249485731124878
Validation loss: 2.051752600618588

Epoch: 6| Step: 4
Training loss: 2.9244909286499023
Validation loss: 2.0405227394514185

Epoch: 6| Step: 5
Training loss: 2.586170196533203
Validation loss: 2.0432723055603685

Epoch: 6| Step: 6
Training loss: 2.4442806243896484
Validation loss: 2.0428225327563543

Epoch: 6| Step: 7
Training loss: 1.9239457845687866
Validation loss: 2.026689883201353

Epoch: 6| Step: 8
Training loss: 2.8270161151885986
Validation loss: 2.033258450928555

Epoch: 6| Step: 9
Training loss: 1.9846066236495972
Validation loss: 2.0292773400583575

Epoch: 6| Step: 10
Training loss: 2.499682903289795
Validation loss: 2.030818339317076

Epoch: 6| Step: 11
Training loss: 2.284468650817871
Validation loss: 2.0318757282790316

Epoch: 6| Step: 12
Training loss: 1.705730676651001
Validation loss: 2.039988543397637

Epoch: 6| Step: 13
Training loss: 2.3285276889801025
Validation loss: 2.02069418661056

Epoch: 37| Step: 0
Training loss: 1.9466431140899658
Validation loss: 2.026299520205426

Epoch: 6| Step: 1
Training loss: 2.5627057552337646
Validation loss: 2.015608120990056

Epoch: 6| Step: 2
Training loss: 2.6912169456481934
Validation loss: 2.0230209853059504

Epoch: 6| Step: 3
Training loss: 2.396481513977051
Validation loss: 2.018156240063329

Epoch: 6| Step: 4
Training loss: 2.219414472579956
Validation loss: 2.00519036862158

Epoch: 6| Step: 5
Training loss: 2.0356926918029785
Validation loss: 2.0016543198657293

Epoch: 6| Step: 6
Training loss: 2.581078290939331
Validation loss: 2.013709096498387

Epoch: 6| Step: 7
Training loss: 2.407290458679199
Validation loss: 2.0193081825010237

Epoch: 6| Step: 8
Training loss: 1.8649002313613892
Validation loss: 2.0146637783255628

Epoch: 6| Step: 9
Training loss: 2.132902145385742
Validation loss: 2.010016933564217

Epoch: 6| Step: 10
Training loss: 2.9983131885528564
Validation loss: 2.0152681950599916

Epoch: 6| Step: 11
Training loss: 1.741865634918213
Validation loss: 2.0209339921192457

Epoch: 6| Step: 12
Training loss: 2.0500364303588867
Validation loss: 2.0181295256460867

Epoch: 6| Step: 13
Training loss: 3.5310044288635254
Validation loss: 2.017072691712328

Epoch: 38| Step: 0
Training loss: 2.1941933631896973
Validation loss: 2.0070005040014944

Epoch: 6| Step: 1
Training loss: 2.3061203956604004
Validation loss: 2.0144982286678847

Epoch: 6| Step: 2
Training loss: 2.7160096168518066
Validation loss: 2.0135329102957122

Epoch: 6| Step: 3
Training loss: 2.3759467601776123
Validation loss: 2.0030746998325473

Epoch: 6| Step: 4
Training loss: 2.276700258255005
Validation loss: 2.0049436669195853

Epoch: 6| Step: 5
Training loss: 2.4144363403320312
Validation loss: 2.0000473888971473

Epoch: 6| Step: 6
Training loss: 2.489307165145874
Validation loss: 2.018605609093943

Epoch: 6| Step: 7
Training loss: 1.6129913330078125
Validation loss: 2.02136319170716

Epoch: 6| Step: 8
Training loss: 2.727672815322876
Validation loss: 2.0139187125749487

Epoch: 6| Step: 9
Training loss: 2.6341652870178223
Validation loss: 2.0140747613804315

Epoch: 6| Step: 10
Training loss: 2.8401877880096436
Validation loss: 2.0158517924688195

Epoch: 6| Step: 11
Training loss: 1.7598257064819336
Validation loss: 2.0156264715297247

Epoch: 6| Step: 12
Training loss: 1.9593639373779297
Validation loss: 2.0155665528389717

Epoch: 6| Step: 13
Training loss: 2.250525712966919
Validation loss: 2.028520691779352

Epoch: 39| Step: 0
Training loss: 2.0403308868408203
Validation loss: 2.008340812498523

Epoch: 6| Step: 1
Training loss: 2.1100566387176514
Validation loss: 2.018912128222886

Epoch: 6| Step: 2
Training loss: 2.182011127471924
Validation loss: 2.004675078135665

Epoch: 6| Step: 3
Training loss: 2.734969139099121
Validation loss: 2.0119809258368706

Epoch: 6| Step: 4
Training loss: 2.701141357421875
Validation loss: 2.0240481976539857

Epoch: 6| Step: 5
Training loss: 2.7853682041168213
Validation loss: 2.0185526109510854

Epoch: 6| Step: 6
Training loss: 1.9433039426803589
Validation loss: 2.004387982429997

Epoch: 6| Step: 7
Training loss: 2.727027416229248
Validation loss: 2.036226939129573

Epoch: 6| Step: 8
Training loss: 1.775667667388916
Validation loss: 2.034711850586758

Epoch: 6| Step: 9
Training loss: 2.3659284114837646
Validation loss: 2.014633127438125

Epoch: 6| Step: 10
Training loss: 2.3166887760162354
Validation loss: 2.0133586211871077

Epoch: 6| Step: 11
Training loss: 1.846256971359253
Validation loss: 2.023118629250475

Epoch: 6| Step: 12
Training loss: 2.495906352996826
Validation loss: 2.042917977097214

Epoch: 6| Step: 13
Training loss: 2.5764243602752686
Validation loss: 2.008062961280987

Epoch: 40| Step: 0
Training loss: 1.6778465509414673
Validation loss: 2.023402157650199

Epoch: 6| Step: 1
Training loss: 2.419759750366211
Validation loss: 2.0328253392250306

Epoch: 6| Step: 2
Training loss: 2.760380268096924
Validation loss: 2.0230602782259703

Epoch: 6| Step: 3
Training loss: 2.3524723052978516
Validation loss: 2.026343196950933

Epoch: 6| Step: 4
Training loss: 1.8679161071777344
Validation loss: 2.0415383987529303

Epoch: 6| Step: 5
Training loss: 2.0784759521484375
Validation loss: 2.035172511172551

Epoch: 6| Step: 6
Training loss: 1.8918821811676025
Validation loss: 2.0343822356193297

Epoch: 6| Step: 7
Training loss: 2.147019624710083
Validation loss: 2.0307262328363236

Epoch: 6| Step: 8
Training loss: 3.0573668479919434
Validation loss: 2.0400536406424736

Epoch: 6| Step: 9
Training loss: 2.6298582553863525
Validation loss: 2.032067024579612

Epoch: 6| Step: 10
Training loss: 2.0516610145568848
Validation loss: 2.024192299894107

Epoch: 6| Step: 11
Training loss: 2.300844430923462
Validation loss: 2.025223949904083

Epoch: 6| Step: 12
Training loss: 2.6198761463165283
Validation loss: 2.032873063959101

Epoch: 6| Step: 13
Training loss: 2.8370938301086426
Validation loss: 2.026471270027981

Epoch: 41| Step: 0
Training loss: 1.6872950792312622
Validation loss: 2.037812245789395

Epoch: 6| Step: 1
Training loss: 2.1654393672943115
Validation loss: 2.0276991193012526

Epoch: 6| Step: 2
Training loss: 2.101834535598755
Validation loss: 2.010548694159395

Epoch: 6| Step: 3
Training loss: 2.710751533508301
Validation loss: 2.023473657587523

Epoch: 6| Step: 4
Training loss: 2.3989882469177246
Validation loss: 2.0135434981315368

Epoch: 6| Step: 5
Training loss: 1.8140923976898193
Validation loss: 2.0179986774280505

Epoch: 6| Step: 6
Training loss: 2.373736619949341
Validation loss: 2.014610755828119

Epoch: 6| Step: 7
Training loss: 1.9901305437088013
Validation loss: 2.010190151071036

Epoch: 6| Step: 8
Training loss: 2.069796085357666
Validation loss: 2.0028562853413243

Epoch: 6| Step: 9
Training loss: 2.545922040939331
Validation loss: 2.0109184121572845

Epoch: 6| Step: 10
Training loss: 2.1565122604370117
Validation loss: 1.997304867672664

Epoch: 6| Step: 11
Training loss: 2.852877140045166
Validation loss: 2.0050915120750346

Epoch: 6| Step: 12
Training loss: 3.0591137409210205
Validation loss: 1.99878736465208

Epoch: 6| Step: 13
Training loss: 2.403724431991577
Validation loss: 2.0001850115355624

Epoch: 42| Step: 0
Training loss: 1.4973583221435547
Validation loss: 1.9886885035422541

Epoch: 6| Step: 1
Training loss: 1.680499792098999
Validation loss: 2.0082112794281333

Epoch: 6| Step: 2
Training loss: 2.8270788192749023
Validation loss: 1.9963381239162978

Epoch: 6| Step: 3
Training loss: 3.197155237197876
Validation loss: 2.0009361825963503

Epoch: 6| Step: 4
Training loss: 2.499897003173828
Validation loss: 1.9955457474595757

Epoch: 6| Step: 5
Training loss: 1.7355279922485352
Validation loss: 1.986830315282268

Epoch: 6| Step: 6
Training loss: 2.400252103805542
Validation loss: 2.0120905496740855

Epoch: 6| Step: 7
Training loss: 2.1987862586975098
Validation loss: 2.000611236018519

Epoch: 6| Step: 8
Training loss: 2.333749294281006
Validation loss: 2.006746102404851

Epoch: 6| Step: 9
Training loss: 2.398221015930176
Validation loss: 1.997917995657972

Epoch: 6| Step: 10
Training loss: 2.27388334274292
Validation loss: 2.0096245081193986

Epoch: 6| Step: 11
Training loss: 1.5040717124938965
Validation loss: 1.9796836786372687

Epoch: 6| Step: 12
Training loss: 2.8362817764282227
Validation loss: 1.9894675977768437

Epoch: 6| Step: 13
Training loss: 3.02567458152771
Validation loss: 1.9989174194233392

Epoch: 43| Step: 0
Training loss: 2.5681042671203613
Validation loss: 2.0027520887313353

Epoch: 6| Step: 1
Training loss: 2.0833983421325684
Validation loss: 1.994678561405469

Epoch: 6| Step: 2
Training loss: 1.8951308727264404
Validation loss: 1.9864962203528291

Epoch: 6| Step: 3
Training loss: 2.5352792739868164
Validation loss: 1.9879157671364405

Epoch: 6| Step: 4
Training loss: 2.4419026374816895
Validation loss: 1.9925001898119528

Epoch: 6| Step: 5
Training loss: 1.6985247135162354
Validation loss: 1.9872524456311298

Epoch: 6| Step: 6
Training loss: 2.550532817840576
Validation loss: 1.992158676988335

Epoch: 6| Step: 7
Training loss: 2.4909846782684326
Validation loss: 1.9861895871418778

Epoch: 6| Step: 8
Training loss: 2.407616138458252
Validation loss: 1.9744188439461492

Epoch: 6| Step: 9
Training loss: 2.1042327880859375
Validation loss: 1.9948704140160674

Epoch: 6| Step: 10
Training loss: 2.314854145050049
Validation loss: 1.989873661789843

Epoch: 6| Step: 11
Training loss: 2.553964614868164
Validation loss: 1.976878628935865

Epoch: 6| Step: 12
Training loss: 2.2621865272521973
Validation loss: 1.9886539469483078

Epoch: 6| Step: 13
Training loss: 1.9955370426177979
Validation loss: 1.9841726287718742

Epoch: 44| Step: 0
Training loss: 2.187959671020508
Validation loss: 1.9820765526063981

Epoch: 6| Step: 1
Training loss: 2.050199270248413
Validation loss: 1.9896645033231346

Epoch: 6| Step: 2
Training loss: 1.8920847177505493
Validation loss: 2.0039149279235513

Epoch: 6| Step: 3
Training loss: 2.7308435440063477
Validation loss: 1.9766789918304772

Epoch: 6| Step: 4
Training loss: 1.9147781133651733
Validation loss: 1.9969379517339891

Epoch: 6| Step: 5
Training loss: 2.535956382751465
Validation loss: 2.0000746634698685

Epoch: 6| Step: 6
Training loss: 2.3742825984954834
Validation loss: 1.9924407800038655

Epoch: 6| Step: 7
Training loss: 2.23838472366333
Validation loss: 1.99550155157684

Epoch: 6| Step: 8
Training loss: 2.000680446624756
Validation loss: 1.9997455689214891

Epoch: 6| Step: 9
Training loss: 2.3293116092681885
Validation loss: 1.9973884654301468

Epoch: 6| Step: 10
Training loss: 2.7193329334259033
Validation loss: 1.9962646294665594

Epoch: 6| Step: 11
Training loss: 2.4996259212493896
Validation loss: 1.981633678559334

Epoch: 6| Step: 12
Training loss: 2.139272451400757
Validation loss: 1.9840601657026558

Epoch: 6| Step: 13
Training loss: 2.712209939956665
Validation loss: 1.9843301849980508

Epoch: 45| Step: 0
Training loss: 2.366497755050659
Validation loss: 1.99329956628943

Epoch: 6| Step: 1
Training loss: 2.2980971336364746
Validation loss: 1.9894187719591203

Epoch: 6| Step: 2
Training loss: 2.242757797241211
Validation loss: 1.9828895727793376

Epoch: 6| Step: 3
Training loss: 2.2366554737091064
Validation loss: 1.980619397214664

Epoch: 6| Step: 4
Training loss: 2.5867531299591064
Validation loss: 1.9780523110461492

Epoch: 6| Step: 5
Training loss: 2.225048303604126
Validation loss: 1.9978237408463673

Epoch: 6| Step: 6
Training loss: 2.450676918029785
Validation loss: 1.971314085427151

Epoch: 6| Step: 7
Training loss: 1.8890159130096436
Validation loss: 1.9711169991441952

Epoch: 6| Step: 8
Training loss: 2.5925791263580322
Validation loss: 1.9685997732224003

Epoch: 6| Step: 9
Training loss: 2.3306093215942383
Validation loss: 1.9856654854230984

Epoch: 6| Step: 10
Training loss: 1.7433655261993408
Validation loss: 1.9856243671909455

Epoch: 6| Step: 11
Training loss: 2.5431785583496094
Validation loss: 1.9832343516811248

Epoch: 6| Step: 12
Training loss: 2.332336187362671
Validation loss: 1.9871223101051905

Epoch: 6| Step: 13
Training loss: 2.325814962387085
Validation loss: 1.9727939739022204

Epoch: 46| Step: 0
Training loss: 2.142652988433838
Validation loss: 1.9872478426143687

Epoch: 6| Step: 1
Training loss: 2.159698247909546
Validation loss: 2.0006732043399604

Epoch: 6| Step: 2
Training loss: 1.7952680587768555
Validation loss: 1.9821943659936228

Epoch: 6| Step: 3
Training loss: 2.338951587677002
Validation loss: 1.9839721854015062

Epoch: 6| Step: 4
Training loss: 1.6321849822998047
Validation loss: 1.967699598240596

Epoch: 6| Step: 5
Training loss: 1.82210111618042
Validation loss: 1.9762421654116722

Epoch: 6| Step: 6
Training loss: 1.4008398056030273
Validation loss: 1.988023760498211

Epoch: 6| Step: 7
Training loss: 2.8858840465545654
Validation loss: 1.969419305042554

Epoch: 6| Step: 8
Training loss: 2.360286235809326
Validation loss: 1.9625438438948763

Epoch: 6| Step: 9
Training loss: 2.532560110092163
Validation loss: 1.9777405684994114

Epoch: 6| Step: 10
Training loss: 3.0194921493530273
Validation loss: 1.9671760297590686

Epoch: 6| Step: 11
Training loss: 2.569725275039673
Validation loss: 1.9609807742539274

Epoch: 6| Step: 12
Training loss: 2.8513851165771484
Validation loss: 1.9681448141733806

Epoch: 6| Step: 13
Training loss: 2.712202548980713
Validation loss: 1.9631048146114554

Epoch: 47| Step: 0
Training loss: 2.2594552040100098
Validation loss: 1.9682380204559655

Epoch: 6| Step: 1
Training loss: 2.0144855976104736
Validation loss: 1.9732649531415714

Epoch: 6| Step: 2
Training loss: 1.3314119577407837
Validation loss: 1.961468590203152

Epoch: 6| Step: 3
Training loss: 2.251340866088867
Validation loss: 1.9731998687149377

Epoch: 6| Step: 4
Training loss: 2.648918867111206
Validation loss: 1.9684512692113076

Epoch: 6| Step: 5
Training loss: 2.541689395904541
Validation loss: 1.9695874696136804

Epoch: 6| Step: 6
Training loss: 2.414330005645752
Validation loss: 1.9827896292491625

Epoch: 6| Step: 7
Training loss: 3.17877459526062
Validation loss: 1.988638044685446

Epoch: 6| Step: 8
Training loss: 2.5204293727874756
Validation loss: 1.9778856410775134

Epoch: 6| Step: 9
Training loss: 1.8268946409225464
Validation loss: 1.987359062317879

Epoch: 6| Step: 10
Training loss: 2.426886558532715
Validation loss: 1.9992974573566067

Epoch: 6| Step: 11
Training loss: 2.697110652923584
Validation loss: 1.9767705420012116

Epoch: 6| Step: 12
Training loss: 1.8820350170135498
Validation loss: 1.9904669202784055

Epoch: 6| Step: 13
Training loss: 1.6563756465911865
Validation loss: 1.9731613025870374

Epoch: 48| Step: 0
Training loss: 2.185084819793701
Validation loss: 1.9912967720339376

Epoch: 6| Step: 1
Training loss: 2.187502861022949
Validation loss: 1.987176195267708

Epoch: 6| Step: 2
Training loss: 1.9282832145690918
Validation loss: 1.987734494670745

Epoch: 6| Step: 3
Training loss: 2.549116611480713
Validation loss: 1.9609836198950326

Epoch: 6| Step: 4
Training loss: 2.2817835807800293
Validation loss: 1.9830754623618176

Epoch: 6| Step: 5
Training loss: 1.9769287109375
Validation loss: 1.9791055494739163

Epoch: 6| Step: 6
Training loss: 2.3198537826538086
Validation loss: 1.955019615029776

Epoch: 6| Step: 7
Training loss: 2.3092527389526367
Validation loss: 1.968969759120736

Epoch: 6| Step: 8
Training loss: 2.7177305221557617
Validation loss: 1.9693353329935381

Epoch: 6| Step: 9
Training loss: 2.2845001220703125
Validation loss: 1.9700295976413194

Epoch: 6| Step: 10
Training loss: 2.0648703575134277
Validation loss: 1.9557191402681413

Epoch: 6| Step: 11
Training loss: 2.4568777084350586
Validation loss: 1.965692577823516

Epoch: 6| Step: 12
Training loss: 2.269411563873291
Validation loss: 1.9744912988396102

Epoch: 6| Step: 13
Training loss: 2.383634328842163
Validation loss: 1.9648860744250718

Epoch: 49| Step: 0
Training loss: 2.867295742034912
Validation loss: 1.977971666602678

Epoch: 6| Step: 1
Training loss: 1.7639188766479492
Validation loss: 1.9751937466282998

Epoch: 6| Step: 2
Training loss: 2.226710319519043
Validation loss: 1.9679103718009046

Epoch: 6| Step: 3
Training loss: 1.8893184661865234
Validation loss: 1.9744276308244275

Epoch: 6| Step: 4
Training loss: 2.583400011062622
Validation loss: 1.9763196437589583

Epoch: 6| Step: 5
Training loss: 2.5285863876342773
Validation loss: 1.9602408332209433

Epoch: 6| Step: 6
Training loss: 2.0128579139709473
Validation loss: 1.9727459697313205

Epoch: 6| Step: 7
Training loss: 2.6558189392089844
Validation loss: 1.9676796390164284

Epoch: 6| Step: 8
Training loss: 2.211655616760254
Validation loss: 1.9720471712850756

Epoch: 6| Step: 9
Training loss: 2.0369272232055664
Validation loss: 1.9779400774227676

Epoch: 6| Step: 10
Training loss: 1.611607313156128
Validation loss: 1.9806739514873875

Epoch: 6| Step: 11
Training loss: 2.4159669876098633
Validation loss: 1.9648423361521896

Epoch: 6| Step: 12
Training loss: 2.3178465366363525
Validation loss: 1.9521413644154866

Epoch: 6| Step: 13
Training loss: 2.980781078338623
Validation loss: 1.9842900640221053

Epoch: 50| Step: 0
Training loss: 2.3711767196655273
Validation loss: 1.9909907079512073

Epoch: 6| Step: 1
Training loss: 2.4595279693603516
Validation loss: 1.965644339079498

Epoch: 6| Step: 2
Training loss: 2.6589114665985107
Validation loss: 1.9815190658774426

Epoch: 6| Step: 3
Training loss: 2.5858101844787598
Validation loss: 1.97399265022688

Epoch: 6| Step: 4
Training loss: 2.389749050140381
Validation loss: 1.9659006236701884

Epoch: 6| Step: 5
Training loss: 2.596950054168701
Validation loss: 1.9635122053084835

Epoch: 6| Step: 6
Training loss: 2.3348519802093506
Validation loss: 1.9848920658070555

Epoch: 6| Step: 7
Training loss: 2.0981571674346924
Validation loss: 1.9744355165830223

Epoch: 6| Step: 8
Training loss: 2.1636767387390137
Validation loss: 1.9678945977200744

Epoch: 6| Step: 9
Training loss: 1.6381654739379883
Validation loss: 1.9688620041775446

Epoch: 6| Step: 10
Training loss: 2.165487051010132
Validation loss: 1.9886115122866888

Epoch: 6| Step: 11
Training loss: 1.973303198814392
Validation loss: 1.9785653570646882

Epoch: 6| Step: 12
Training loss: 1.9336726665496826
Validation loss: 1.9865545585591307

Epoch: 6| Step: 13
Training loss: 2.4524710178375244
Validation loss: 1.9828464036346765

Epoch: 51| Step: 0
Training loss: 1.754341959953308
Validation loss: 1.9754032883592831

Epoch: 6| Step: 1
Training loss: 2.1317806243896484
Validation loss: 1.9793593678423154

Epoch: 6| Step: 2
Training loss: 2.581953287124634
Validation loss: 1.9676392680855208

Epoch: 6| Step: 3
Training loss: 1.8770712614059448
Validation loss: 1.9740273683301863

Epoch: 6| Step: 4
Training loss: 1.5359443426132202
Validation loss: 1.9870603148655226

Epoch: 6| Step: 5
Training loss: 2.422755718231201
Validation loss: 1.9614089586401497

Epoch: 6| Step: 6
Training loss: 2.603668689727783
Validation loss: 1.952486740645542

Epoch: 6| Step: 7
Training loss: 2.984809398651123
Validation loss: 1.9693663914998372

Epoch: 6| Step: 8
Training loss: 2.0394630432128906
Validation loss: 1.9633510625490578

Epoch: 6| Step: 9
Training loss: 2.4057059288024902
Validation loss: 1.9608463753936112

Epoch: 6| Step: 10
Training loss: 2.6369738578796387
Validation loss: 1.9764683618340442

Epoch: 6| Step: 11
Training loss: 2.371339797973633
Validation loss: 1.968749289871544

Epoch: 6| Step: 12
Training loss: 2.088480234146118
Validation loss: 1.9732452489996468

Epoch: 6| Step: 13
Training loss: 2.338543176651001
Validation loss: 1.9720725372273435

Epoch: 52| Step: 0
Training loss: 2.4471096992492676
Validation loss: 1.971218660313596

Epoch: 6| Step: 1
Training loss: 2.6127853393554688
Validation loss: 1.9729781740455217

Epoch: 6| Step: 2
Training loss: 1.9546416997909546
Validation loss: 1.9811793142749416

Epoch: 6| Step: 3
Training loss: 2.0088412761688232
Validation loss: 1.9756036932750414

Epoch: 6| Step: 4
Training loss: 2.9502015113830566
Validation loss: 1.9867785746051418

Epoch: 6| Step: 5
Training loss: 2.24576997756958
Validation loss: 1.9749949427061184

Epoch: 6| Step: 6
Training loss: 1.954150676727295
Validation loss: 1.983202572791807

Epoch: 6| Step: 7
Training loss: 1.8622698783874512
Validation loss: 1.9970796646610383

Epoch: 6| Step: 8
Training loss: 2.425076484680176
Validation loss: 1.99227100546642

Epoch: 6| Step: 9
Training loss: 2.0956695079803467
Validation loss: 2.002001157370947

Epoch: 6| Step: 10
Training loss: 3.1111338138580322
Validation loss: 1.985657230500252

Epoch: 6| Step: 11
Training loss: 2.357785224914551
Validation loss: 1.9897869530544485

Epoch: 6| Step: 12
Training loss: 1.5750563144683838
Validation loss: 1.9792927503585815

Epoch: 6| Step: 13
Training loss: 1.9560418128967285
Validation loss: 1.9797525457156602

Epoch: 53| Step: 0
Training loss: 2.770132303237915
Validation loss: 1.9867587448448263

Epoch: 6| Step: 1
Training loss: 2.5091731548309326
Validation loss: 1.970777980742916

Epoch: 6| Step: 2
Training loss: 2.185703754425049
Validation loss: 1.9739138131500573

Epoch: 6| Step: 3
Training loss: 2.5513947010040283
Validation loss: 1.9751241566032491

Epoch: 6| Step: 4
Training loss: 2.131692409515381
Validation loss: 1.9662624302730765

Epoch: 6| Step: 5
Training loss: 2.1583263874053955
Validation loss: 1.970541000366211

Epoch: 6| Step: 6
Training loss: 1.705849289894104
Validation loss: 1.9668099598218036

Epoch: 6| Step: 7
Training loss: 2.7882509231567383
Validation loss: 1.9619682104356828

Epoch: 6| Step: 8
Training loss: 1.8471335172653198
Validation loss: 1.9763541067800214

Epoch: 6| Step: 9
Training loss: 2.511944532394409
Validation loss: 1.9665164819327734

Epoch: 6| Step: 10
Training loss: 2.417175054550171
Validation loss: 1.96144667748482

Epoch: 6| Step: 11
Training loss: 2.010767936706543
Validation loss: 1.9745972989707865

Epoch: 6| Step: 12
Training loss: 2.3443665504455566
Validation loss: 1.9677584043113134

Epoch: 6| Step: 13
Training loss: 1.2646918296813965
Validation loss: 1.9834292550240793

Epoch: 54| Step: 0
Training loss: 2.255068302154541
Validation loss: 1.9822052730027067

Epoch: 6| Step: 1
Training loss: 2.2209131717681885
Validation loss: 1.9873735058692195

Epoch: 6| Step: 2
Training loss: 1.564051628112793
Validation loss: 1.9724014805209251

Epoch: 6| Step: 3
Training loss: 1.7625644207000732
Validation loss: 1.958634731590107

Epoch: 6| Step: 4
Training loss: 2.355177402496338
Validation loss: 1.991562933050176

Epoch: 6| Step: 5
Training loss: 1.8659954071044922
Validation loss: 1.9684413812493766

Epoch: 6| Step: 6
Training loss: 1.9886596202850342
Validation loss: 1.970394463949306

Epoch: 6| Step: 7
Training loss: 2.3477942943573
Validation loss: 1.9883619021343928

Epoch: 6| Step: 8
Training loss: 2.433546543121338
Validation loss: 1.9636745811790548

Epoch: 6| Step: 9
Training loss: 2.006995677947998
Validation loss: 1.9675361084681686

Epoch: 6| Step: 10
Training loss: 2.8024864196777344
Validation loss: 1.9564348190061507

Epoch: 6| Step: 11
Training loss: 2.622241973876953
Validation loss: 1.9791917749630508

Epoch: 6| Step: 12
Training loss: 2.8344509601593018
Validation loss: 1.9731563393787672

Epoch: 6| Step: 13
Training loss: 2.4575917720794678
Validation loss: 1.9538378664242324

Epoch: 55| Step: 0
Training loss: 1.5845234394073486
Validation loss: 1.961303416118827

Epoch: 6| Step: 1
Training loss: 2.396002769470215
Validation loss: 1.9725416821818198

Epoch: 6| Step: 2
Training loss: 2.277097702026367
Validation loss: 1.9698506798795474

Epoch: 6| Step: 3
Training loss: 2.339559555053711
Validation loss: 1.9863203648597962

Epoch: 6| Step: 4
Training loss: 1.819708228111267
Validation loss: 1.9795405941624795

Epoch: 6| Step: 5
Training loss: 2.00050687789917
Validation loss: 1.987527242270849

Epoch: 6| Step: 6
Training loss: 2.52909517288208
Validation loss: 1.9881372246690976

Epoch: 6| Step: 7
Training loss: 2.775744915008545
Validation loss: 1.9824673283484675

Epoch: 6| Step: 8
Training loss: 2.4849720001220703
Validation loss: 1.980289654065204

Epoch: 6| Step: 9
Training loss: 2.8361802101135254
Validation loss: 1.9654076407032628

Epoch: 6| Step: 10
Training loss: 2.001300811767578
Validation loss: 1.9900823011193225

Epoch: 6| Step: 11
Training loss: 1.9984514713287354
Validation loss: 1.9789535460933563

Epoch: 6| Step: 12
Training loss: 2.660914421081543
Validation loss: 1.9801595621211554

Epoch: 6| Step: 13
Training loss: 1.511971354484558
Validation loss: 2.00259901631263

Epoch: 56| Step: 0
Training loss: 2.1333625316619873
Validation loss: 1.993115061072893

Epoch: 6| Step: 1
Training loss: 2.225160598754883
Validation loss: 1.9840298929522115

Epoch: 6| Step: 2
Training loss: 2.1672701835632324
Validation loss: 1.9881618253646358

Epoch: 6| Step: 3
Training loss: 2.542018413543701
Validation loss: 1.9921281722284132

Epoch: 6| Step: 4
Training loss: 1.890986680984497
Validation loss: 1.9701613585154216

Epoch: 6| Step: 5
Training loss: 2.392082929611206
Validation loss: 1.9812675086400842

Epoch: 6| Step: 6
Training loss: 1.8927392959594727
Validation loss: 1.9656252963568575

Epoch: 6| Step: 7
Training loss: 2.0282163619995117
Validation loss: 1.9578508305293258

Epoch: 6| Step: 8
Training loss: 2.3636796474456787
Validation loss: 1.9711666722451486

Epoch: 6| Step: 9
Training loss: 2.261707067489624
Validation loss: 1.971551856686992

Epoch: 6| Step: 10
Training loss: 2.0759835243225098
Validation loss: 1.9715539998905633

Epoch: 6| Step: 11
Training loss: 2.9353737831115723
Validation loss: 1.9751411163678734

Epoch: 6| Step: 12
Training loss: 2.3113512992858887
Validation loss: 1.9749843420520905

Epoch: 6| Step: 13
Training loss: 1.9923101663589478
Validation loss: 1.9546562266606156

Epoch: 57| Step: 0
Training loss: 2.7027711868286133
Validation loss: 1.9737186060156873

Epoch: 6| Step: 1
Training loss: 2.004969835281372
Validation loss: 1.978006996134276

Epoch: 6| Step: 2
Training loss: 2.33842134475708
Validation loss: 1.9733947323214622

Epoch: 6| Step: 3
Training loss: 3.0254387855529785
Validation loss: 1.9753872271507018

Epoch: 6| Step: 4
Training loss: 2.936350107192993
Validation loss: 1.9723976440327142

Epoch: 6| Step: 5
Training loss: 1.7361376285552979
Validation loss: 1.9659250961836947

Epoch: 6| Step: 6
Training loss: 2.4412524700164795
Validation loss: 1.975976400477912

Epoch: 6| Step: 7
Training loss: 1.9761667251586914
Validation loss: 1.9665640195210774

Epoch: 6| Step: 8
Training loss: 2.8290092945098877
Validation loss: 1.9648863000254477

Epoch: 6| Step: 9
Training loss: 1.6432464122772217
Validation loss: 1.97929540629028

Epoch: 6| Step: 10
Training loss: 1.7740252017974854
Validation loss: 1.9810551738226285

Epoch: 6| Step: 11
Training loss: 1.9192209243774414
Validation loss: 1.9735602947973436

Epoch: 6| Step: 12
Training loss: 2.279865026473999
Validation loss: 1.9892831694695257

Epoch: 6| Step: 13
Training loss: 1.4922804832458496
Validation loss: 1.973802549864656

Epoch: 58| Step: 0
Training loss: 2.6642308235168457
Validation loss: 1.9771677832449637

Epoch: 6| Step: 1
Training loss: 2.7101123332977295
Validation loss: 1.9812905532057568

Epoch: 6| Step: 2
Training loss: 1.8918037414550781
Validation loss: 1.9827285658928655

Epoch: 6| Step: 3
Training loss: 2.012138843536377
Validation loss: 1.9680576170644453

Epoch: 6| Step: 4
Training loss: 1.7632966041564941
Validation loss: 1.9760824582910026

Epoch: 6| Step: 5
Training loss: 2.0279974937438965
Validation loss: 1.9772906636679044

Epoch: 6| Step: 6
Training loss: 2.077524423599243
Validation loss: 1.995656745408171

Epoch: 6| Step: 7
Training loss: 2.770888328552246
Validation loss: 1.992128731102072

Epoch: 6| Step: 8
Training loss: 2.2250540256500244
Validation loss: 1.9939835930383334

Epoch: 6| Step: 9
Training loss: 2.395707130432129
Validation loss: 1.9802250349393455

Epoch: 6| Step: 10
Training loss: 2.75039005279541
Validation loss: 1.97616821207026

Epoch: 6| Step: 11
Training loss: 2.058826208114624
Validation loss: 2.0008718172709146

Epoch: 6| Step: 12
Training loss: 1.7698034048080444
Validation loss: 1.9849551698212982

Epoch: 6| Step: 13
Training loss: 2.1708223819732666
Validation loss: 1.9787051216248543

Epoch: 59| Step: 0
Training loss: 2.317392349243164
Validation loss: 1.972771377973659

Epoch: 6| Step: 1
Training loss: 2.449251174926758
Validation loss: 1.9659571622007637

Epoch: 6| Step: 2
Training loss: 2.7412242889404297
Validation loss: 1.9796828249449372

Epoch: 6| Step: 3
Training loss: 2.754678249359131
Validation loss: 1.9838500433070685

Epoch: 6| Step: 4
Training loss: 2.507296562194824
Validation loss: 1.9673253989988757

Epoch: 6| Step: 5
Training loss: 1.7821340560913086
Validation loss: 1.9607731180806314

Epoch: 6| Step: 6
Training loss: 2.512985944747925
Validation loss: 1.961096727719871

Epoch: 6| Step: 7
Training loss: 2.3568358421325684
Validation loss: 1.9638816605332077

Epoch: 6| Step: 8
Training loss: 2.1816601753234863
Validation loss: 1.9661850595986972

Epoch: 6| Step: 9
Training loss: 1.9303112030029297
Validation loss: 1.9655561921417073

Epoch: 6| Step: 10
Training loss: 1.3555243015289307
Validation loss: 1.9559059143066406

Epoch: 6| Step: 11
Training loss: 1.9245641231536865
Validation loss: 1.9887617480370305

Epoch: 6| Step: 12
Training loss: 2.342092990875244
Validation loss: 1.9688358050520702

Epoch: 6| Step: 13
Training loss: 1.9219766855239868
Validation loss: 1.9803794058420325

Epoch: 60| Step: 0
Training loss: 2.1499152183532715
Validation loss: 1.960522449144753

Epoch: 6| Step: 1
Training loss: 2.2581019401550293
Validation loss: 1.9606513464322655

Epoch: 6| Step: 2
Training loss: 2.7855820655822754
Validation loss: 1.9624704814726306

Epoch: 6| Step: 3
Training loss: 1.3581807613372803
Validation loss: 1.9708894401468255

Epoch: 6| Step: 4
Training loss: 2.1905579566955566
Validation loss: 1.9744118131617063

Epoch: 6| Step: 5
Training loss: 1.8092659711837769
Validation loss: 1.962817362559739

Epoch: 6| Step: 6
Training loss: 2.46565580368042
Validation loss: 1.9790413174577939

Epoch: 6| Step: 7
Training loss: 2.178215980529785
Validation loss: 1.9489779754351544

Epoch: 6| Step: 8
Training loss: 2.0006558895111084
Validation loss: 1.9674724917257986

Epoch: 6| Step: 9
Training loss: 1.9995715618133545
Validation loss: 1.970275091868575

Epoch: 6| Step: 10
Training loss: 2.1356682777404785
Validation loss: 1.9525092314648371

Epoch: 6| Step: 11
Training loss: 2.320178508758545
Validation loss: 1.9739488452993414

Epoch: 6| Step: 12
Training loss: 2.6978769302368164
Validation loss: 1.961575654245192

Epoch: 6| Step: 13
Training loss: 3.332246780395508
Validation loss: 1.9690240326748099

Epoch: 61| Step: 0
Training loss: 1.9720468521118164
Validation loss: 1.9601319054121613

Epoch: 6| Step: 1
Training loss: 2.09934663772583
Validation loss: 1.9638965411852765

Epoch: 6| Step: 2
Training loss: 2.0704054832458496
Validation loss: 1.9761400286869337

Epoch: 6| Step: 3
Training loss: 2.0840675830841064
Validation loss: 1.958443990317724

Epoch: 6| Step: 4
Training loss: 2.056997776031494
Validation loss: 1.960596033321914

Epoch: 6| Step: 5
Training loss: 2.3448519706726074
Validation loss: 1.9649260685008059

Epoch: 6| Step: 6
Training loss: 2.010948896408081
Validation loss: 1.9620046295145506

Epoch: 6| Step: 7
Training loss: 2.526538848876953
Validation loss: 1.9669206911517727

Epoch: 6| Step: 8
Training loss: 2.1658830642700195
Validation loss: 1.964682166294385

Epoch: 6| Step: 9
Training loss: 2.574368953704834
Validation loss: 1.9851952522031722

Epoch: 6| Step: 10
Training loss: 2.3495635986328125
Validation loss: 1.9808348891555623

Epoch: 6| Step: 11
Training loss: 2.319563388824463
Validation loss: 1.989403534961003

Epoch: 6| Step: 12
Training loss: 2.7941184043884277
Validation loss: 1.9855203538812616

Epoch: 6| Step: 13
Training loss: 1.6165789365768433
Validation loss: 1.9895380684124526

Epoch: 62| Step: 0
Training loss: 2.424259901046753
Validation loss: 1.9956508733892953

Epoch: 6| Step: 1
Training loss: 2.000194787979126
Validation loss: 1.9778594252883748

Epoch: 6| Step: 2
Training loss: 2.4256463050842285
Validation loss: 1.9884562210370136

Epoch: 6| Step: 3
Training loss: 2.0547780990600586
Validation loss: 1.9779956353608

Epoch: 6| Step: 4
Training loss: 2.518355369567871
Validation loss: 1.9761768925574519

Epoch: 6| Step: 5
Training loss: 2.1129136085510254
Validation loss: 1.990566235716625

Epoch: 6| Step: 6
Training loss: 1.788180947303772
Validation loss: 1.9797861076170398

Epoch: 6| Step: 7
Training loss: 2.0368525981903076
Validation loss: 1.9849373473916003

Epoch: 6| Step: 8
Training loss: 1.5592020750045776
Validation loss: 1.9718228309385237

Epoch: 6| Step: 9
Training loss: 2.892247438430786
Validation loss: 1.964011380749364

Epoch: 6| Step: 10
Training loss: 2.1463370323181152
Validation loss: 1.9868911338108841

Epoch: 6| Step: 11
Training loss: 2.4703824520111084
Validation loss: 1.9763770641819123

Epoch: 6| Step: 12
Training loss: 2.35548996925354
Validation loss: 1.969779340169763

Epoch: 6| Step: 13
Training loss: 2.445178747177124
Validation loss: 1.9795238151345202

Epoch: 63| Step: 0
Training loss: 2.9174139499664307
Validation loss: 1.9805962629215692

Epoch: 6| Step: 1
Training loss: 1.9061545133590698
Validation loss: 1.9740809368830856

Epoch: 6| Step: 2
Training loss: 2.775876522064209
Validation loss: 1.9628699530837357

Epoch: 6| Step: 3
Training loss: 2.3010571002960205
Validation loss: 1.9712960386788974

Epoch: 6| Step: 4
Training loss: 1.830176830291748
Validation loss: 1.9742682249315324

Epoch: 6| Step: 5
Training loss: 2.0932154655456543
Validation loss: 1.9923048083500197

Epoch: 6| Step: 6
Training loss: 2.0617284774780273
Validation loss: 1.9711375133965605

Epoch: 6| Step: 7
Training loss: 2.168233871459961
Validation loss: 1.9855988064119894

Epoch: 6| Step: 8
Training loss: 2.5861103534698486
Validation loss: 1.9819083636806858

Epoch: 6| Step: 9
Training loss: 2.25933837890625
Validation loss: 1.977091791809246

Epoch: 6| Step: 10
Training loss: 2.8862833976745605
Validation loss: 1.987456508862075

Epoch: 6| Step: 11
Training loss: 1.5058789253234863
Validation loss: 1.9893244735656246

Epoch: 6| Step: 12
Training loss: 1.7538132667541504
Validation loss: 1.9791402278407928

Epoch: 6| Step: 13
Training loss: 1.9753063917160034
Validation loss: 1.9695187294355003

Epoch: 64| Step: 0
Training loss: 2.1617631912231445
Validation loss: 1.986323659138013

Epoch: 6| Step: 1
Training loss: 2.1987650394439697
Validation loss: 1.9722814111299412

Epoch: 6| Step: 2
Training loss: 2.511235237121582
Validation loss: 1.988723934337657

Epoch: 6| Step: 3
Training loss: 2.096757411956787
Validation loss: 1.9780867984217982

Epoch: 6| Step: 4
Training loss: 1.9408173561096191
Validation loss: 1.9674827129610124

Epoch: 6| Step: 5
Training loss: 2.372896671295166
Validation loss: 1.9942404095844557

Epoch: 6| Step: 6
Training loss: 2.0380115509033203
Validation loss: 1.9988493509190057

Epoch: 6| Step: 7
Training loss: 2.389388084411621
Validation loss: 1.9856326964593702

Epoch: 6| Step: 8
Training loss: 2.4401378631591797
Validation loss: 1.9714832152089765

Epoch: 6| Step: 9
Training loss: 2.2308688163757324
Validation loss: 1.9797782436493905

Epoch: 6| Step: 10
Training loss: 2.2809934616088867
Validation loss: 1.983585770412158

Epoch: 6| Step: 11
Training loss: 1.7621310949325562
Validation loss: 1.9769633123951573

Epoch: 6| Step: 12
Training loss: 2.2145445346832275
Validation loss: 1.9642702071897444

Epoch: 6| Step: 13
Training loss: 2.49330472946167
Validation loss: 1.9706304509152648

Epoch: 65| Step: 0
Training loss: 1.9673250913619995
Validation loss: 1.96604581545758

Epoch: 6| Step: 1
Training loss: 2.1602115631103516
Validation loss: 1.9456753371864237

Epoch: 6| Step: 2
Training loss: 2.351881980895996
Validation loss: 1.9704976248484787

Epoch: 6| Step: 3
Training loss: 1.5321671962738037
Validation loss: 1.9722178084875948

Epoch: 6| Step: 4
Training loss: 1.8548316955566406
Validation loss: 1.9637320862021497

Epoch: 6| Step: 5
Training loss: 2.2087111473083496
Validation loss: 1.9680626700001378

Epoch: 6| Step: 6
Training loss: 2.6815123558044434
Validation loss: 1.958307509781212

Epoch: 6| Step: 7
Training loss: 2.409665584564209
Validation loss: 1.9742034686509

Epoch: 6| Step: 8
Training loss: 2.383502244949341
Validation loss: 1.9733921302262174

Epoch: 6| Step: 9
Training loss: 2.5282576084136963
Validation loss: 1.9664387651669082

Epoch: 6| Step: 10
Training loss: 2.6138715744018555
Validation loss: 1.970420047801028

Epoch: 6| Step: 11
Training loss: 2.0571131706237793
Validation loss: 1.9631936396321943

Epoch: 6| Step: 12
Training loss: 1.9250984191894531
Validation loss: 1.9709385928287302

Epoch: 6| Step: 13
Training loss: 2.549130439758301
Validation loss: 1.9727122963115733

Epoch: 66| Step: 0
Training loss: 2.517118453979492
Validation loss: 1.9712624472956504

Epoch: 6| Step: 1
Training loss: 2.5719940662384033
Validation loss: 1.9734609280863116

Epoch: 6| Step: 2
Training loss: 1.7915663719177246
Validation loss: 1.9660767778273551

Epoch: 6| Step: 3
Training loss: 1.692335605621338
Validation loss: 1.9599616707012217

Epoch: 6| Step: 4
Training loss: 2.5165228843688965
Validation loss: 1.9776859552629533

Epoch: 6| Step: 5
Training loss: 2.3473258018493652
Validation loss: 1.991985256953906

Epoch: 6| Step: 6
Training loss: 2.588613748550415
Validation loss: 1.9617846550480011

Epoch: 6| Step: 7
Training loss: 2.0316247940063477
Validation loss: 1.962548145683863

Epoch: 6| Step: 8
Training loss: 2.1635842323303223
Validation loss: 1.9763471208592898

Epoch: 6| Step: 9
Training loss: 2.2785534858703613
Validation loss: 1.982303342511577

Epoch: 6| Step: 10
Training loss: 2.2565271854400635
Validation loss: 1.9673028607522287

Epoch: 6| Step: 11
Training loss: 2.282867670059204
Validation loss: 1.9747857509120819

Epoch: 6| Step: 12
Training loss: 1.725964903831482
Validation loss: 1.9824997622479674

Epoch: 6| Step: 13
Training loss: 2.3458547592163086
Validation loss: 1.974278639721614

Epoch: 67| Step: 0
Training loss: 1.7885369062423706
Validation loss: 1.9655482897194483

Epoch: 6| Step: 1
Training loss: 1.9123128652572632
Validation loss: 1.9727560025389477

Epoch: 6| Step: 2
Training loss: 1.6981186866760254
Validation loss: 1.9682741947071527

Epoch: 6| Step: 3
Training loss: 2.5256094932556152
Validation loss: 1.9700279697295158

Epoch: 6| Step: 4
Training loss: 2.3726112842559814
Validation loss: 1.9655008469858477

Epoch: 6| Step: 5
Training loss: 1.8448925018310547
Validation loss: 1.972827103830153

Epoch: 6| Step: 6
Training loss: 2.403172492980957
Validation loss: 1.9633181428396573

Epoch: 6| Step: 7
Training loss: 2.015878438949585
Validation loss: 1.9660363786964006

Epoch: 6| Step: 8
Training loss: 2.6310904026031494
Validation loss: 1.9656017134266515

Epoch: 6| Step: 9
Training loss: 2.5153794288635254
Validation loss: 1.9662230271165089

Epoch: 6| Step: 10
Training loss: 2.33689546585083
Validation loss: 1.9557472428967875

Epoch: 6| Step: 11
Training loss: 1.95448899269104
Validation loss: 1.9523108454160794

Epoch: 6| Step: 12
Training loss: 2.5748586654663086
Validation loss: 1.9460005593556229

Epoch: 6| Step: 13
Training loss: 2.456249713897705
Validation loss: 1.9522522239274875

Epoch: 68| Step: 0
Training loss: 3.113569736480713
Validation loss: 1.9662051534139982

Epoch: 6| Step: 1
Training loss: 1.9417115449905396
Validation loss: 1.9623241834743048

Epoch: 6| Step: 2
Training loss: 2.621488094329834
Validation loss: 1.966721406546972

Epoch: 6| Step: 3
Training loss: 2.2067575454711914
Validation loss: 1.9838186528093071

Epoch: 6| Step: 4
Training loss: 1.7003356218338013
Validation loss: 1.9770016900954708

Epoch: 6| Step: 5
Training loss: 1.8278015851974487
Validation loss: 1.9923483274316276

Epoch: 6| Step: 6
Training loss: 1.956895112991333
Validation loss: 1.9717443912259993

Epoch: 6| Step: 7
Training loss: 2.7936506271362305
Validation loss: 1.9662278749609505

Epoch: 6| Step: 8
Training loss: 2.7359447479248047
Validation loss: 1.98947585269969

Epoch: 6| Step: 9
Training loss: 1.697936773300171
Validation loss: 1.966565102659246

Epoch: 6| Step: 10
Training loss: 2.4121670722961426
Validation loss: 1.9830679265401696

Epoch: 6| Step: 11
Training loss: 2.4073877334594727
Validation loss: 1.9786861378659484

Epoch: 6| Step: 12
Training loss: 1.7307943105697632
Validation loss: 1.9798918231841056

Epoch: 6| Step: 13
Training loss: 1.438180923461914
Validation loss: 2.0042344472741567

Epoch: 69| Step: 0
Training loss: 2.1149697303771973
Validation loss: 1.9794077168228805

Epoch: 6| Step: 1
Training loss: 2.421940565109253
Validation loss: 1.9648643783343736

Epoch: 6| Step: 2
Training loss: 2.1619632244110107
Validation loss: 1.974350654950706

Epoch: 6| Step: 3
Training loss: 2.4984254837036133
Validation loss: 1.9675229621189896

Epoch: 6| Step: 4
Training loss: 2.793780565261841
Validation loss: 1.9631786243889922

Epoch: 6| Step: 5
Training loss: 1.8359774351119995
Validation loss: 1.9613940767062608

Epoch: 6| Step: 6
Training loss: 2.5010533332824707
Validation loss: 1.971879102850473

Epoch: 6| Step: 7
Training loss: 2.1772828102111816
Validation loss: 1.9604516452358616

Epoch: 6| Step: 8
Training loss: 2.4334726333618164
Validation loss: 1.9534319946842809

Epoch: 6| Step: 9
Training loss: 2.6802456378936768
Validation loss: 1.952904115441025

Epoch: 6| Step: 10
Training loss: 1.1777424812316895
Validation loss: 1.9713794621088172

Epoch: 6| Step: 11
Training loss: 2.270404100418091
Validation loss: 1.9664571746703117

Epoch: 6| Step: 12
Training loss: 2.3502111434936523
Validation loss: 1.9659482791859617

Epoch: 6| Step: 13
Training loss: 1.1200567483901978
Validation loss: 1.96148883399143

Epoch: 70| Step: 0
Training loss: 2.551224708557129
Validation loss: 1.9628326175033406

Epoch: 6| Step: 1
Training loss: 1.2377057075500488
Validation loss: 1.9670564397688834

Epoch: 6| Step: 2
Training loss: 2.61964750289917
Validation loss: 1.983083301974881

Epoch: 6| Step: 3
Training loss: 1.8816657066345215
Validation loss: 1.9788167938109367

Epoch: 6| Step: 4
Training loss: 2.5485267639160156
Validation loss: 1.9802037592857116

Epoch: 6| Step: 5
Training loss: 2.028707265853882
Validation loss: 1.984264769861775

Epoch: 6| Step: 6
Training loss: 2.9708549976348877
Validation loss: 1.973376581745763

Epoch: 6| Step: 7
Training loss: 1.4512156248092651
Validation loss: 1.9788582760800597

Epoch: 6| Step: 8
Training loss: 2.1162567138671875
Validation loss: 1.9673346998871013

Epoch: 6| Step: 9
Training loss: 2.2574520111083984
Validation loss: 1.9692223033597391

Epoch: 6| Step: 10
Training loss: 1.8449645042419434
Validation loss: 1.9740090831633537

Epoch: 6| Step: 11
Training loss: 1.8308842182159424
Validation loss: 1.9740823238126692

Epoch: 6| Step: 12
Training loss: 3.182154655456543
Validation loss: 1.9784852984131023

Epoch: 6| Step: 13
Training loss: 2.0865986347198486
Validation loss: 1.9745946853391585

Epoch: 71| Step: 0
Training loss: 3.0728726387023926
Validation loss: 1.9711902628662765

Epoch: 6| Step: 1
Training loss: 2.099761486053467
Validation loss: 1.9789021438167942

Epoch: 6| Step: 2
Training loss: 1.8460748195648193
Validation loss: 1.9841489048414334

Epoch: 6| Step: 3
Training loss: 1.438407063484192
Validation loss: 1.9850133619000834

Epoch: 6| Step: 4
Training loss: 2.102508068084717
Validation loss: 1.9692262244480911

Epoch: 6| Step: 5
Training loss: 2.321413040161133
Validation loss: 1.9616740134454542

Epoch: 6| Step: 6
Training loss: 1.883843183517456
Validation loss: 1.9834139834168136

Epoch: 6| Step: 7
Training loss: 2.536924123764038
Validation loss: 1.9719946999703684

Epoch: 6| Step: 8
Training loss: 2.0928821563720703
Validation loss: 1.9864423556994366

Epoch: 6| Step: 9
Training loss: 1.9678664207458496
Validation loss: 1.9783869879220122

Epoch: 6| Step: 10
Training loss: 2.6880085468292236
Validation loss: 1.9874659520323559

Epoch: 6| Step: 11
Training loss: 2.055225133895874
Validation loss: 1.9688696630539433

Epoch: 6| Step: 12
Training loss: 1.9231996536254883
Validation loss: 1.9940938872675742

Epoch: 6| Step: 13
Training loss: 3.0287177562713623
Validation loss: 1.9783331950505574

Epoch: 72| Step: 0
Training loss: 1.6432859897613525
Validation loss: 1.9693886567187566

Epoch: 6| Step: 1
Training loss: 2.7641172409057617
Validation loss: 1.9842467205498808

Epoch: 6| Step: 2
Training loss: 2.3390777111053467
Validation loss: 1.9674759885316253

Epoch: 6| Step: 3
Training loss: 1.9633179903030396
Validation loss: 1.9817852871392363

Epoch: 6| Step: 4
Training loss: 2.450284481048584
Validation loss: 1.9785164504922845

Epoch: 6| Step: 5
Training loss: 1.7051825523376465
Validation loss: 1.9768696087662891

Epoch: 6| Step: 6
Training loss: 1.9164515733718872
Validation loss: 1.9723709526882376

Epoch: 6| Step: 7
Training loss: 2.3035295009613037
Validation loss: 1.965478717639882

Epoch: 6| Step: 8
Training loss: 2.110989570617676
Validation loss: 1.96341650332174

Epoch: 6| Step: 9
Training loss: 2.3605475425720215
Validation loss: 1.97758021021402

Epoch: 6| Step: 10
Training loss: 3.177389621734619
Validation loss: 1.9803714265105545

Epoch: 6| Step: 11
Training loss: 2.0218594074249268
Validation loss: 1.9626739102025186

Epoch: 6| Step: 12
Training loss: 2.0530343055725098
Validation loss: 1.9692289675435712

Epoch: 6| Step: 13
Training loss: 1.841856598854065
Validation loss: 1.9578243295351665

Epoch: 73| Step: 0
Training loss: 2.1338627338409424
Validation loss: 1.973524611483338

Epoch: 6| Step: 1
Training loss: 1.6095510721206665
Validation loss: 1.9715079851047967

Epoch: 6| Step: 2
Training loss: 1.9386190176010132
Validation loss: 1.9571664666616788

Epoch: 6| Step: 3
Training loss: 2.250230550765991
Validation loss: 1.9608835328009822

Epoch: 6| Step: 4
Training loss: 1.6848055124282837
Validation loss: 1.9555653961755897

Epoch: 6| Step: 5
Training loss: 2.2120790481567383
Validation loss: 1.9674914242118917

Epoch: 6| Step: 6
Training loss: 2.246469259262085
Validation loss: 1.9468711140335246

Epoch: 6| Step: 7
Training loss: 2.76371431350708
Validation loss: 1.9646454741877895

Epoch: 6| Step: 8
Training loss: 3.1630871295928955
Validation loss: 1.971765466915664

Epoch: 6| Step: 9
Training loss: 2.082272529602051
Validation loss: 1.9666495220635527

Epoch: 6| Step: 10
Training loss: 1.6248595714569092
Validation loss: 1.9615782127585462

Epoch: 6| Step: 11
Training loss: 2.3474349975585938
Validation loss: 1.9708483039691884

Epoch: 6| Step: 12
Training loss: 2.3352489471435547
Validation loss: 1.9668054285869803

Epoch: 6| Step: 13
Training loss: 2.0250067710876465
Validation loss: 1.9623852955397738

Epoch: 74| Step: 0
Training loss: 2.313607692718506
Validation loss: 1.9710679310624317

Epoch: 6| Step: 1
Training loss: 1.6405370235443115
Validation loss: 1.9606084105789021

Epoch: 6| Step: 2
Training loss: 2.9210357666015625
Validation loss: 1.964864005324661

Epoch: 6| Step: 3
Training loss: 2.068549633026123
Validation loss: 1.9715826357564619

Epoch: 6| Step: 4
Training loss: 1.9734257459640503
Validation loss: 1.9809292054945422

Epoch: 6| Step: 5
Training loss: 2.2867207527160645
Validation loss: 1.9714232567817933

Epoch: 6| Step: 6
Training loss: 1.8690481185913086
Validation loss: 1.9679604704662035

Epoch: 6| Step: 7
Training loss: 1.69154953956604
Validation loss: 1.9651907067145071

Epoch: 6| Step: 8
Training loss: 2.395078659057617
Validation loss: 1.9798068666970858

Epoch: 6| Step: 9
Training loss: 2.0753214359283447
Validation loss: 1.9918781557390768

Epoch: 6| Step: 10
Training loss: 2.2977356910705566
Validation loss: 1.9859194742735995

Epoch: 6| Step: 11
Training loss: 2.082854986190796
Validation loss: 1.9844164489417948

Epoch: 6| Step: 12
Training loss: 2.4424636363983154
Validation loss: 2.0000916693800237

Epoch: 6| Step: 13
Training loss: 3.135258913040161
Validation loss: 1.989863254690683

Epoch: 75| Step: 0
Training loss: 1.9935537576675415
Validation loss: 1.9919187894431494

Epoch: 6| Step: 1
Training loss: 2.0563395023345947
Validation loss: 1.9802103837331135

Epoch: 6| Step: 2
Training loss: 1.9264016151428223
Validation loss: 1.9788371119447934

Epoch: 6| Step: 3
Training loss: 2.945044755935669
Validation loss: 1.984550137673655

Epoch: 6| Step: 4
Training loss: 2.1847822666168213
Validation loss: 1.9960539956246652

Epoch: 6| Step: 5
Training loss: 1.8418800830841064
Validation loss: 1.9890746275583904

Epoch: 6| Step: 6
Training loss: 2.3516845703125
Validation loss: 2.003881654431743

Epoch: 6| Step: 7
Training loss: 2.4562902450561523
Validation loss: 1.9960969340416692

Epoch: 6| Step: 8
Training loss: 1.5701344013214111
Validation loss: 2.0115426509611067

Epoch: 6| Step: 9
Training loss: 1.8749916553497314
Validation loss: 1.975204429318828

Epoch: 6| Step: 10
Training loss: 2.465010404586792
Validation loss: 1.9856714240966304

Epoch: 6| Step: 11
Training loss: 2.4843716621398926
Validation loss: 1.9756511026813137

Epoch: 6| Step: 12
Training loss: 2.043985605239868
Validation loss: 1.967717730870811

Epoch: 6| Step: 13
Training loss: 2.5570898056030273
Validation loss: 1.975418221565985

Epoch: 76| Step: 0
Training loss: 2.026763439178467
Validation loss: 1.981897625871884

Epoch: 6| Step: 1
Training loss: 2.1190526485443115
Validation loss: 1.9905369666314894

Epoch: 6| Step: 2
Training loss: 1.7809175252914429
Validation loss: 1.959287155059076

Epoch: 6| Step: 3
Training loss: 1.9331703186035156
Validation loss: 1.9811377115147089

Epoch: 6| Step: 4
Training loss: 2.737809658050537
Validation loss: 1.9810000529853247

Epoch: 6| Step: 5
Training loss: 2.079054832458496
Validation loss: 1.9825293530700028

Epoch: 6| Step: 6
Training loss: 2.0799946784973145
Validation loss: 1.975037472222441

Epoch: 6| Step: 7
Training loss: 2.0821146965026855
Validation loss: 1.971019652581984

Epoch: 6| Step: 8
Training loss: 2.2332210540771484
Validation loss: 1.9583968142027497

Epoch: 6| Step: 9
Training loss: 2.6640658378601074
Validation loss: 1.9661265163011448

Epoch: 6| Step: 10
Training loss: 2.04060435295105
Validation loss: 1.961561995167886

Epoch: 6| Step: 11
Training loss: 2.0972900390625
Validation loss: 1.9611363769859396

Epoch: 6| Step: 12
Training loss: 2.6975016593933105
Validation loss: 1.9646898982345418

Epoch: 6| Step: 13
Training loss: 1.7104982137680054
Validation loss: 1.94878093401591

Epoch: 77| Step: 0
Training loss: 2.089935541152954
Validation loss: 1.949925144513448

Epoch: 6| Step: 1
Training loss: 1.9617269039154053
Validation loss: 1.9606060469022362

Epoch: 6| Step: 2
Training loss: 2.5607309341430664
Validation loss: 1.9552903098444785

Epoch: 6| Step: 3
Training loss: 2.4032862186431885
Validation loss: 1.962840259716075

Epoch: 6| Step: 4
Training loss: 2.587265968322754
Validation loss: 1.9686372305757256

Epoch: 6| Step: 5
Training loss: 2.3943629264831543
Validation loss: 1.9597215678102227

Epoch: 6| Step: 6
Training loss: 2.6855950355529785
Validation loss: 1.9569977034804642

Epoch: 6| Step: 7
Training loss: 1.7554253339767456
Validation loss: 1.9745670492931078

Epoch: 6| Step: 8
Training loss: 2.571296215057373
Validation loss: 1.962449114809754

Epoch: 6| Step: 9
Training loss: 1.6874257326126099
Validation loss: 1.9541715229711225

Epoch: 6| Step: 10
Training loss: 2.125548839569092
Validation loss: 1.9591052327104794

Epoch: 6| Step: 11
Training loss: 1.668229341506958
Validation loss: 1.9396399349294684

Epoch: 6| Step: 12
Training loss: 2.089210033416748
Validation loss: 1.9555042033554406

Epoch: 6| Step: 13
Training loss: 1.8284045457839966
Validation loss: 1.9608454012101697

Epoch: 78| Step: 0
Training loss: 2.4813108444213867
Validation loss: 1.9654333565824775

Epoch: 6| Step: 1
Training loss: 2.095073699951172
Validation loss: 1.9657454618843653

Epoch: 6| Step: 2
Training loss: 2.5746443271636963
Validation loss: 1.9446026432898738

Epoch: 6| Step: 3
Training loss: 2.4403090476989746
Validation loss: 1.9653769628975981

Epoch: 6| Step: 4
Training loss: 1.9677225351333618
Validation loss: 1.965456675457698

Epoch: 6| Step: 5
Training loss: 1.8830268383026123
Validation loss: 1.9713275701768938

Epoch: 6| Step: 6
Training loss: 2.1168465614318848
Validation loss: 1.9500244714880501

Epoch: 6| Step: 7
Training loss: 2.0999016761779785
Validation loss: 1.9536607444927256

Epoch: 6| Step: 8
Training loss: 2.1529035568237305
Validation loss: 1.9584689153138028

Epoch: 6| Step: 9
Training loss: 1.639143943786621
Validation loss: 1.9902391690079884

Epoch: 6| Step: 10
Training loss: 2.2563347816467285
Validation loss: 1.9802028325296217

Epoch: 6| Step: 11
Training loss: 1.875866413116455
Validation loss: 1.9776918734273603

Epoch: 6| Step: 12
Training loss: 2.3566009998321533
Validation loss: 1.9751095592334706

Epoch: 6| Step: 13
Training loss: 2.9529507160186768
Validation loss: 1.973453273055374

Epoch: 79| Step: 0
Training loss: 1.8863615989685059
Validation loss: 1.970973471159576

Epoch: 6| Step: 1
Training loss: 2.1741509437561035
Validation loss: 1.9765753143577165

Epoch: 6| Step: 2
Training loss: 2.876203775405884
Validation loss: 1.9795158896394955

Epoch: 6| Step: 3
Training loss: 2.097414493560791
Validation loss: 1.969683592037488

Epoch: 6| Step: 4
Training loss: 2.8668320178985596
Validation loss: 1.980160972123505

Epoch: 6| Step: 5
Training loss: 1.819058895111084
Validation loss: 1.9702025049476213

Epoch: 6| Step: 6
Training loss: 2.144413948059082
Validation loss: 1.9789212467849895

Epoch: 6| Step: 7
Training loss: 2.3231263160705566
Validation loss: 1.9944533455756404

Epoch: 6| Step: 8
Training loss: 2.006930351257324
Validation loss: 1.9680017425167946

Epoch: 6| Step: 9
Training loss: 2.484403371810913
Validation loss: 1.9928211012194235

Epoch: 6| Step: 10
Training loss: 2.2994375228881836
Validation loss: 1.9802118706446823

Epoch: 6| Step: 11
Training loss: 1.883146047592163
Validation loss: 1.9765501868340276

Epoch: 6| Step: 12
Training loss: 1.612548828125
Validation loss: 1.9777583511926795

Epoch: 6| Step: 13
Training loss: 2.058140277862549
Validation loss: 1.9738765826789282

Epoch: 80| Step: 0
Training loss: 2.928798198699951
Validation loss: 1.965264222955191

Epoch: 6| Step: 1
Training loss: 1.8588454723358154
Validation loss: 1.9706767515469623

Epoch: 6| Step: 2
Training loss: 2.5965492725372314
Validation loss: 1.96938838753649

Epoch: 6| Step: 3
Training loss: 3.0646257400512695
Validation loss: 1.96466274287111

Epoch: 6| Step: 4
Training loss: 2.1658716201782227
Validation loss: 1.9400227787674114

Epoch: 6| Step: 5
Training loss: 2.6372547149658203
Validation loss: 1.954139478744999

Epoch: 6| Step: 6
Training loss: 1.7724368572235107
Validation loss: 1.9599974424608293

Epoch: 6| Step: 7
Training loss: 2.1908364295959473
Validation loss: 1.9445844363140803

Epoch: 6| Step: 8
Training loss: 2.254016160964966
Validation loss: 1.955368918757285

Epoch: 6| Step: 9
Training loss: 1.25892972946167
Validation loss: 1.9579193771526378

Epoch: 6| Step: 10
Training loss: 1.6550023555755615
Validation loss: 1.9670535890004968

Epoch: 6| Step: 11
Training loss: 1.896242618560791
Validation loss: 1.939424027678787

Epoch: 6| Step: 12
Training loss: 2.3074116706848145
Validation loss: 1.94910841859797

Epoch: 6| Step: 13
Training loss: 1.6800312995910645
Validation loss: 1.9360295431588286

Epoch: 81| Step: 0
Training loss: 1.8683897256851196
Validation loss: 1.9706138436512282

Epoch: 6| Step: 1
Training loss: 2.2935800552368164
Validation loss: 1.9656782304086993

Epoch: 6| Step: 2
Training loss: 2.2108840942382812
Validation loss: 1.9630972787898073

Epoch: 6| Step: 3
Training loss: 1.7163245677947998
Validation loss: 1.9601611219426638

Epoch: 6| Step: 4
Training loss: 2.1796231269836426
Validation loss: 1.960197699967251

Epoch: 6| Step: 5
Training loss: 1.4302241802215576
Validation loss: 1.979348446733208

Epoch: 6| Step: 6
Training loss: 2.9393365383148193
Validation loss: 1.9901993300325127

Epoch: 6| Step: 7
Training loss: 1.9390636682510376
Validation loss: 1.9959479685752624

Epoch: 6| Step: 8
Training loss: 2.18070387840271
Validation loss: 1.9764788560969855

Epoch: 6| Step: 9
Training loss: 2.9811923503875732
Validation loss: 1.9948579098588677

Epoch: 6| Step: 10
Training loss: 2.3761990070343018
Validation loss: 1.9777235241346462

Epoch: 6| Step: 11
Training loss: 2.2506816387176514
Validation loss: 1.9856283997976651

Epoch: 6| Step: 12
Training loss: 2.0988149642944336
Validation loss: 1.9694043282539613

Epoch: 6| Step: 13
Training loss: 1.7363168001174927
Validation loss: 1.9892263553475822

Epoch: 82| Step: 0
Training loss: 2.264193534851074
Validation loss: 1.9840627818979242

Epoch: 6| Step: 1
Training loss: 1.8307708501815796
Validation loss: 1.9838095121486212

Epoch: 6| Step: 2
Training loss: 2.887805461883545
Validation loss: 1.9776921387641662

Epoch: 6| Step: 3
Training loss: 2.3084840774536133
Validation loss: 1.9917345226451915

Epoch: 6| Step: 4
Training loss: 2.609555721282959
Validation loss: 1.981937575083907

Epoch: 6| Step: 5
Training loss: 1.0905057191848755
Validation loss: 1.9861628791337371

Epoch: 6| Step: 6
Training loss: 2.7458291053771973
Validation loss: 1.9746759630018664

Epoch: 6| Step: 7
Training loss: 2.0183703899383545
Validation loss: 1.9755065697495655

Epoch: 6| Step: 8
Training loss: 2.657757520675659
Validation loss: 1.958514222534754

Epoch: 6| Step: 9
Training loss: 1.3283977508544922
Validation loss: 1.9903371718622023

Epoch: 6| Step: 10
Training loss: 2.374260425567627
Validation loss: 1.980230717248814

Epoch: 6| Step: 11
Training loss: 1.7996671199798584
Validation loss: 1.9721350413496777

Epoch: 6| Step: 12
Training loss: 2.2704787254333496
Validation loss: 1.9786930289319766

Epoch: 6| Step: 13
Training loss: 1.9110897779464722
Validation loss: 1.966483877551171

Epoch: 83| Step: 0
Training loss: 2.4026389122009277
Validation loss: 1.9653119681983866

Epoch: 6| Step: 1
Training loss: 2.6311588287353516
Validation loss: 1.9741259095489339

Epoch: 6| Step: 2
Training loss: 1.6081129312515259
Validation loss: 1.9697948425046858

Epoch: 6| Step: 3
Training loss: 2.069891929626465
Validation loss: 1.9824764908000987

Epoch: 6| Step: 4
Training loss: 1.6197950839996338
Validation loss: 1.972457116649997

Epoch: 6| Step: 5
Training loss: 2.552030563354492
Validation loss: 1.954751060855004

Epoch: 6| Step: 6
Training loss: 3.19972825050354
Validation loss: 1.9750962757295178

Epoch: 6| Step: 7
Training loss: 2.438213348388672
Validation loss: 1.9750236029266028

Epoch: 6| Step: 8
Training loss: 2.2193849086761475
Validation loss: 1.9826525206206946

Epoch: 6| Step: 9
Training loss: 1.5384206771850586
Validation loss: 1.9784613860550748

Epoch: 6| Step: 10
Training loss: 1.745647668838501
Validation loss: 1.9820517314377653

Epoch: 6| Step: 11
Training loss: 2.1610536575317383
Validation loss: 1.9689805507659912

Epoch: 6| Step: 12
Training loss: 2.3477020263671875
Validation loss: 1.972378292391377

Epoch: 6| Step: 13
Training loss: 1.322383165359497
Validation loss: 1.9668502269252655

Epoch: 84| Step: 0
Training loss: 2.1891469955444336
Validation loss: 1.9516090398193688

Epoch: 6| Step: 1
Training loss: 1.8913664817810059
Validation loss: 1.9706832157668246

Epoch: 6| Step: 2
Training loss: 1.783921480178833
Validation loss: 1.9652113196670369

Epoch: 6| Step: 3
Training loss: 1.8843189477920532
Validation loss: 1.9852582562354304

Epoch: 6| Step: 4
Training loss: 2.617241382598877
Validation loss: 1.98464596656061

Epoch: 6| Step: 5
Training loss: 3.0583744049072266
Validation loss: 1.9728925638301398

Epoch: 6| Step: 6
Training loss: 2.6470911502838135
Validation loss: 1.9670533403273551

Epoch: 6| Step: 7
Training loss: 2.4886465072631836
Validation loss: 1.9723529046581638

Epoch: 6| Step: 8
Training loss: 1.4953515529632568
Validation loss: 1.9799032352303947

Epoch: 6| Step: 9
Training loss: 2.419322967529297
Validation loss: 1.9716440041859944

Epoch: 6| Step: 10
Training loss: 1.9802871942520142
Validation loss: 1.955254316329956

Epoch: 6| Step: 11
Training loss: 1.3484588861465454
Validation loss: 1.9537141861454133

Epoch: 6| Step: 12
Training loss: 2.358448028564453
Validation loss: 1.9830570567038752

Epoch: 6| Step: 13
Training loss: 1.9364484548568726
Validation loss: 1.9786937416240733

Epoch: 85| Step: 0
Training loss: 2.383371353149414
Validation loss: 1.981005850658622

Epoch: 6| Step: 1
Training loss: 2.8950653076171875
Validation loss: 1.9695428212483723

Epoch: 6| Step: 2
Training loss: 2.0770821571350098
Validation loss: 1.9642609255288237

Epoch: 6| Step: 3
Training loss: 2.736525058746338
Validation loss: 1.963765949331304

Epoch: 6| Step: 4
Training loss: 1.7056083679199219
Validation loss: 1.9786338331878826

Epoch: 6| Step: 5
Training loss: 1.958061695098877
Validation loss: 1.976658180195798

Epoch: 6| Step: 6
Training loss: 2.392075777053833
Validation loss: 1.9887671483460294

Epoch: 6| Step: 7
Training loss: 2.739351987838745
Validation loss: 1.9674502495796449

Epoch: 6| Step: 8
Training loss: 1.612709403038025
Validation loss: 1.9622984663132699

Epoch: 6| Step: 9
Training loss: 1.9928669929504395
Validation loss: 1.9810757778024162

Epoch: 6| Step: 10
Training loss: 2.1068246364593506
Validation loss: 1.9687432678796912

Epoch: 6| Step: 11
Training loss: 1.534173607826233
Validation loss: 1.9511829576184672

Epoch: 6| Step: 12
Training loss: 2.6576642990112305
Validation loss: 1.981575705671823

Epoch: 6| Step: 13
Training loss: 1.2356126308441162
Validation loss: 1.9491987202757148

Epoch: 86| Step: 0
Training loss: 2.1363213062286377
Validation loss: 1.9696393089909707

Epoch: 6| Step: 1
Training loss: 2.3433589935302734
Validation loss: 1.9704642911111154

Epoch: 6| Step: 2
Training loss: 2.386298179626465
Validation loss: 1.9654906795870872

Epoch: 6| Step: 3
Training loss: 2.052224636077881
Validation loss: 1.9859926880046885

Epoch: 6| Step: 4
Training loss: 2.0090510845184326
Validation loss: 1.9670129129963536

Epoch: 6| Step: 5
Training loss: 1.8321188688278198
Validation loss: 1.979206205696188

Epoch: 6| Step: 6
Training loss: 2.3023746013641357
Validation loss: 1.9641188267738587

Epoch: 6| Step: 7
Training loss: 2.266730785369873
Validation loss: 1.9877070124431322

Epoch: 6| Step: 8
Training loss: 1.8448081016540527
Validation loss: 1.9808544279426656

Epoch: 6| Step: 9
Training loss: 1.7370773553848267
Validation loss: 1.9821414191235778

Epoch: 6| Step: 10
Training loss: 2.2600369453430176
Validation loss: 1.985742397205804

Epoch: 6| Step: 11
Training loss: 2.6636548042297363
Validation loss: 1.9856740954101726

Epoch: 6| Step: 12
Training loss: 1.78397798538208
Validation loss: 1.9839378992716472

Epoch: 6| Step: 13
Training loss: 2.823855400085449
Validation loss: 1.9649239919518913

Epoch: 87| Step: 0
Training loss: 1.187584638595581
Validation loss: 1.967475337366904

Epoch: 6| Step: 1
Training loss: 2.177395820617676
Validation loss: 1.971595920542235

Epoch: 6| Step: 2
Training loss: 2.6722421646118164
Validation loss: 1.9709374071449361

Epoch: 6| Step: 3
Training loss: 2.2208447456359863
Validation loss: 1.9593601983080629

Epoch: 6| Step: 4
Training loss: 2.959463119506836
Validation loss: 1.973123529905914

Epoch: 6| Step: 5
Training loss: 1.730191707611084
Validation loss: 1.979424927824287

Epoch: 6| Step: 6
Training loss: 3.042024612426758
Validation loss: 1.9643255100455335

Epoch: 6| Step: 7
Training loss: 2.9463160037994385
Validation loss: 1.9745997305839293

Epoch: 6| Step: 8
Training loss: 2.0102319717407227
Validation loss: 1.9519775811062063

Epoch: 6| Step: 9
Training loss: 1.3924038410186768
Validation loss: 1.9620254655038156

Epoch: 6| Step: 10
Training loss: 1.5787912607192993
Validation loss: 1.9636005791284705

Epoch: 6| Step: 11
Training loss: 1.6656134128570557
Validation loss: 1.942037029932904

Epoch: 6| Step: 12
Training loss: 2.3134543895721436
Validation loss: 1.9570094231636292

Epoch: 6| Step: 13
Training loss: 2.376511812210083
Validation loss: 1.9488915038365189

Epoch: 88| Step: 0
Training loss: 1.9373527765274048
Validation loss: 1.9576401223418534

Epoch: 6| Step: 1
Training loss: 2.1527984142303467
Validation loss: 1.9573016910142795

Epoch: 6| Step: 2
Training loss: 1.9790960550308228
Validation loss: 1.9630846490142166

Epoch: 6| Step: 3
Training loss: 1.5000193119049072
Validation loss: 1.966795080451555

Epoch: 6| Step: 4
Training loss: 2.4835147857666016
Validation loss: 1.9616804635652931

Epoch: 6| Step: 5
Training loss: 2.2270779609680176
Validation loss: 1.9691668812946608

Epoch: 6| Step: 6
Training loss: 1.6145973205566406
Validation loss: 1.9682855862443165

Epoch: 6| Step: 7
Training loss: 2.755082607269287
Validation loss: 1.9727139396052207

Epoch: 6| Step: 8
Training loss: 2.083341121673584
Validation loss: 1.9710280356868621

Epoch: 6| Step: 9
Training loss: 2.011657238006592
Validation loss: 1.9815734727408296

Epoch: 6| Step: 10
Training loss: 2.210092544555664
Validation loss: 1.9655804890458302

Epoch: 6| Step: 11
Training loss: 3.0953822135925293
Validation loss: 1.9751939030103787

Epoch: 6| Step: 12
Training loss: 1.9128282070159912
Validation loss: 1.9660897690762755

Epoch: 6| Step: 13
Training loss: 1.942758560180664
Validation loss: 1.9534635108004335

Epoch: 89| Step: 0
Training loss: 2.1467947959899902
Validation loss: 1.9695804362655969

Epoch: 6| Step: 1
Training loss: 1.464382529258728
Validation loss: 1.9693613321550432

Epoch: 6| Step: 2
Training loss: 3.1626358032226562
Validation loss: 1.9692954004451793

Epoch: 6| Step: 3
Training loss: 2.267425537109375
Validation loss: 1.9849129235872658

Epoch: 6| Step: 4
Training loss: 1.2419843673706055
Validation loss: 1.9671761323046941

Epoch: 6| Step: 5
Training loss: 2.441257953643799
Validation loss: 1.9683653795590965

Epoch: 6| Step: 6
Training loss: 2.3984568119049072
Validation loss: 1.9751703892984698

Epoch: 6| Step: 7
Training loss: 1.9524747133255005
Validation loss: 1.9744642883218744

Epoch: 6| Step: 8
Training loss: 2.219768524169922
Validation loss: 1.9717506670182752

Epoch: 6| Step: 9
Training loss: 2.214784622192383
Validation loss: 1.9458658797766573

Epoch: 6| Step: 10
Training loss: 2.880772352218628
Validation loss: 1.9643650362568517

Epoch: 6| Step: 11
Training loss: 1.7218317985534668
Validation loss: 1.981324266361934

Epoch: 6| Step: 12
Training loss: 1.710243582725525
Validation loss: 1.9582513327239661

Epoch: 6| Step: 13
Training loss: 1.9636456966400146
Validation loss: 1.9861582043350383

Epoch: 90| Step: 0
Training loss: 1.9053459167480469
Validation loss: 1.9844207507307812

Epoch: 6| Step: 1
Training loss: 2.270745038986206
Validation loss: 1.9592259212206768

Epoch: 6| Step: 2
Training loss: 2.7342138290405273
Validation loss: 1.979806415496334

Epoch: 6| Step: 3
Training loss: 2.1678719520568848
Validation loss: 1.9824749654339207

Epoch: 6| Step: 4
Training loss: 3.1446762084960938
Validation loss: 1.9663607676823933

Epoch: 6| Step: 5
Training loss: 2.198004722595215
Validation loss: 1.99425858066928

Epoch: 6| Step: 6
Training loss: 1.8409662246704102
Validation loss: 1.9776225038754043

Epoch: 6| Step: 7
Training loss: 2.408557415008545
Validation loss: 1.986152172088623

Epoch: 6| Step: 8
Training loss: 1.6062099933624268
Validation loss: 2.003690183803599

Epoch: 6| Step: 9
Training loss: 2.267059803009033
Validation loss: 2.000569861422303

Epoch: 6| Step: 10
Training loss: 1.9536380767822266
Validation loss: 1.9640890808515652

Epoch: 6| Step: 11
Training loss: 1.7450580596923828
Validation loss: 1.978286268890545

Epoch: 6| Step: 12
Training loss: 2.1234800815582275
Validation loss: 1.9766359406132852

Epoch: 6| Step: 13
Training loss: 1.2819838523864746
Validation loss: 1.9652846013346026

Epoch: 91| Step: 0
Training loss: 2.0628552436828613
Validation loss: 1.9882901432693645

Epoch: 6| Step: 1
Training loss: 2.1253089904785156
Validation loss: 1.9764550360300208

Epoch: 6| Step: 2
Training loss: 1.9471620321273804
Validation loss: 1.9590531292782034

Epoch: 6| Step: 3
Training loss: 1.9896998405456543
Validation loss: 1.9864491749835271

Epoch: 6| Step: 4
Training loss: 2.1780943870544434
Validation loss: 1.9716267560117988

Epoch: 6| Step: 5
Training loss: 1.797573208808899
Validation loss: 1.9737048174745293

Epoch: 6| Step: 6
Training loss: 2.5739898681640625
Validation loss: 1.9684138580035138

Epoch: 6| Step: 7
Training loss: 1.8286857604980469
Validation loss: 1.9819356600443523

Epoch: 6| Step: 8
Training loss: 1.6609282493591309
Validation loss: 1.9619021569528887

Epoch: 6| Step: 9
Training loss: 2.2189087867736816
Validation loss: 1.9839257578695975

Epoch: 6| Step: 10
Training loss: 2.6517038345336914
Validation loss: 1.9556633195569437

Epoch: 6| Step: 11
Training loss: 2.169537305831909
Validation loss: 1.9700741998610958

Epoch: 6| Step: 12
Training loss: 2.0516653060913086
Validation loss: 1.9632666739084388

Epoch: 6| Step: 13
Training loss: 3.0649333000183105
Validation loss: 1.960151772345266

Epoch: 92| Step: 0
Training loss: 1.8531544208526611
Validation loss: 1.962969373631221

Epoch: 6| Step: 1
Training loss: 2.84926700592041
Validation loss: 1.9651236841755528

Epoch: 6| Step: 2
Training loss: 2.4216465950012207
Validation loss: 1.9778446125727829

Epoch: 6| Step: 3
Training loss: 1.9019153118133545
Validation loss: 1.9782168096111667

Epoch: 6| Step: 4
Training loss: 1.9417762756347656
Validation loss: 1.970710059647919

Epoch: 6| Step: 5
Training loss: 2.0607595443725586
Validation loss: 1.9680595679949688

Epoch: 6| Step: 6
Training loss: 2.5148963928222656
Validation loss: 1.9773625981423162

Epoch: 6| Step: 7
Training loss: 2.1132540702819824
Validation loss: 1.9670018906234412

Epoch: 6| Step: 8
Training loss: 2.0417234897613525
Validation loss: 1.962083960092196

Epoch: 6| Step: 9
Training loss: 1.9669288396835327
Validation loss: 1.960874576722422

Epoch: 6| Step: 10
Training loss: 1.6081225872039795
Validation loss: 1.961136289822158

Epoch: 6| Step: 11
Training loss: 2.0697145462036133
Validation loss: 1.9617833655367616

Epoch: 6| Step: 12
Training loss: 2.2206602096557617
Validation loss: 1.961365415203956

Epoch: 6| Step: 13
Training loss: 2.39898943901062
Validation loss: 1.9585392834037862

Epoch: 93| Step: 0
Training loss: 2.2350523471832275
Validation loss: 1.961180486986714

Epoch: 6| Step: 1
Training loss: 1.6420048475265503
Validation loss: 1.9455885387236072

Epoch: 6| Step: 2
Training loss: 2.5062756538391113
Validation loss: 1.9681033344678982

Epoch: 6| Step: 3
Training loss: 1.7710657119750977
Validation loss: 1.960157964819221

Epoch: 6| Step: 4
Training loss: 1.9421571493148804
Validation loss: 1.9652309968907347

Epoch: 6| Step: 5
Training loss: 2.5107481479644775
Validation loss: 1.9696631444397794

Epoch: 6| Step: 6
Training loss: 2.584883213043213
Validation loss: 1.9605475856411843

Epoch: 6| Step: 7
Training loss: 2.3869404792785645
Validation loss: 1.9413984872961556

Epoch: 6| Step: 8
Training loss: 2.890275239944458
Validation loss: 1.9537177598604591

Epoch: 6| Step: 9
Training loss: 2.131519079208374
Validation loss: 1.952228976834205

Epoch: 6| Step: 10
Training loss: 1.8400113582611084
Validation loss: 1.9595558822795909

Epoch: 6| Step: 11
Training loss: 1.8978912830352783
Validation loss: 1.9715442580561484

Epoch: 6| Step: 12
Training loss: 1.6556308269500732
Validation loss: 1.9637403244613318

Epoch: 6| Step: 13
Training loss: 1.7943649291992188
Validation loss: 1.9628734306622577

Epoch: 94| Step: 0
Training loss: 1.7869279384613037
Validation loss: 1.9732529027487642

Epoch: 6| Step: 1
Training loss: 1.933746099472046
Validation loss: 1.9738441987704205

Epoch: 6| Step: 2
Training loss: 1.9936189651489258
Validation loss: 1.9633359165601834

Epoch: 6| Step: 3
Training loss: 2.134950637817383
Validation loss: 1.969687977144795

Epoch: 6| Step: 4
Training loss: 2.009816884994507
Validation loss: 1.9578327337900798

Epoch: 6| Step: 5
Training loss: 2.3504104614257812
Validation loss: 1.9737458203428535

Epoch: 6| Step: 6
Training loss: 2.116295337677002
Validation loss: 1.968855514321276

Epoch: 6| Step: 7
Training loss: 2.494001865386963
Validation loss: 1.9646169831675868

Epoch: 6| Step: 8
Training loss: 2.139648914337158
Validation loss: 1.9740509922786424

Epoch: 6| Step: 9
Training loss: 3.1140975952148438
Validation loss: 1.9658121421772947

Epoch: 6| Step: 10
Training loss: 2.0965754985809326
Validation loss: 1.9798633270366217

Epoch: 6| Step: 11
Training loss: 2.1226086616516113
Validation loss: 1.9788494494653517

Epoch: 6| Step: 12
Training loss: 1.344117522239685
Validation loss: 1.9750558522439772

Epoch: 6| Step: 13
Training loss: 2.388530731201172
Validation loss: 1.9585889667593024

Epoch: 95| Step: 0
Training loss: 2.4166293144226074
Validation loss: 1.997575185632193

Epoch: 6| Step: 1
Training loss: 2.092485189437866
Validation loss: 1.9643581080180343

Epoch: 6| Step: 2
Training loss: 1.7956287860870361
Validation loss: 1.9721680046409689

Epoch: 6| Step: 3
Training loss: 1.2599772214889526
Validation loss: 1.9566649006259056

Epoch: 6| Step: 4
Training loss: 2.7870843410491943
Validation loss: 1.9775858925234886

Epoch: 6| Step: 5
Training loss: 1.979730486869812
Validation loss: 1.9783495908142419

Epoch: 6| Step: 6
Training loss: 2.2571465969085693
Validation loss: 1.9759284655253093

Epoch: 6| Step: 7
Training loss: 2.4557127952575684
Validation loss: 1.9833502833561232

Epoch: 6| Step: 8
Training loss: 2.579423427581787
Validation loss: 1.9708469657487766

Epoch: 6| Step: 9
Training loss: 2.243116855621338
Validation loss: 1.9892985333678543

Epoch: 6| Step: 10
Training loss: 1.8712153434753418
Validation loss: 1.9879828063390588

Epoch: 6| Step: 11
Training loss: 2.1697165966033936
Validation loss: 1.9741128875363259

Epoch: 6| Step: 12
Training loss: 1.7997877597808838
Validation loss: 1.9897090260700514

Epoch: 6| Step: 13
Training loss: 2.0565948486328125
Validation loss: 1.974591229551582

Epoch: 96| Step: 0
Training loss: 1.7706032991409302
Validation loss: 1.9797189722778976

Epoch: 6| Step: 1
Training loss: 1.8052937984466553
Validation loss: 1.9670039171813636

Epoch: 6| Step: 2
Training loss: 2.7595748901367188
Validation loss: 1.9630444447199504

Epoch: 6| Step: 3
Training loss: 2.0046796798706055
Validation loss: 1.9337851821735341

Epoch: 6| Step: 4
Training loss: 1.832416296005249
Validation loss: 1.9532106384154289

Epoch: 6| Step: 5
Training loss: 2.2772724628448486
Validation loss: 1.9676105796649892

Epoch: 6| Step: 6
Training loss: 2.0598268508911133
Validation loss: 1.9525793137088898

Epoch: 6| Step: 7
Training loss: 1.7034811973571777
Validation loss: 1.9911282267621768

Epoch: 6| Step: 8
Training loss: 1.9729760885238647
Validation loss: 1.9622112198542523

Epoch: 6| Step: 9
Training loss: 2.552501916885376
Validation loss: 1.957145478135796

Epoch: 6| Step: 10
Training loss: 1.9501688480377197
Validation loss: 1.9806484048084547

Epoch: 6| Step: 11
Training loss: 2.6236612796783447
Validation loss: 1.9528159582486717

Epoch: 6| Step: 12
Training loss: 2.158879280090332
Validation loss: 1.9562645522497033

Epoch: 6| Step: 13
Training loss: 2.3915605545043945
Validation loss: 1.975941147855533

Epoch: 97| Step: 0
Training loss: 1.9485045671463013
Validation loss: 1.9437357020634476

Epoch: 6| Step: 1
Training loss: 2.4714512825012207
Validation loss: 1.9531127996342157

Epoch: 6| Step: 2
Training loss: 1.7766532897949219
Validation loss: 1.949062160266343

Epoch: 6| Step: 3
Training loss: 1.7254047393798828
Validation loss: 1.9620154160325245

Epoch: 6| Step: 4
Training loss: 2.1583480834960938
Validation loss: 1.9589347018990466

Epoch: 6| Step: 5
Training loss: 2.321378707885742
Validation loss: 1.9669564718841224

Epoch: 6| Step: 6
Training loss: 2.287191390991211
Validation loss: 1.9490771562822404

Epoch: 6| Step: 7
Training loss: 2.2124061584472656
Validation loss: 1.9491678873697917

Epoch: 6| Step: 8
Training loss: 2.891256093978882
Validation loss: 1.9638325962969052

Epoch: 6| Step: 9
Training loss: 2.2713115215301514
Validation loss: 1.9590288567286667

Epoch: 6| Step: 10
Training loss: 1.8547923564910889
Validation loss: 1.957644329276136

Epoch: 6| Step: 11
Training loss: 1.507962703704834
Validation loss: 1.96949996999515

Epoch: 6| Step: 12
Training loss: 1.9594453573226929
Validation loss: 1.9830540123806204

Epoch: 6| Step: 13
Training loss: 2.510422706604004
Validation loss: 1.968462949158043

Epoch: 98| Step: 0
Training loss: 1.6406922340393066
Validation loss: 1.965965884988026

Epoch: 6| Step: 1
Training loss: 2.19926118850708
Validation loss: 1.9556573719106696

Epoch: 6| Step: 2
Training loss: 2.696441173553467
Validation loss: 1.9775035048043856

Epoch: 6| Step: 3
Training loss: 2.4816083908081055
Validation loss: 1.973550522199241

Epoch: 6| Step: 4
Training loss: 2.0039663314819336
Validation loss: 1.9758613391589093

Epoch: 6| Step: 5
Training loss: 2.137540102005005
Validation loss: 1.96331984766068

Epoch: 6| Step: 6
Training loss: 2.1769518852233887
Validation loss: 1.9580677452907767

Epoch: 6| Step: 7
Training loss: 2.3400189876556396
Validation loss: 1.9556598817148516

Epoch: 6| Step: 8
Training loss: 2.2783215045928955
Validation loss: 1.958974640856507

Epoch: 6| Step: 9
Training loss: 2.082462787628174
Validation loss: 1.9748897526853828

Epoch: 6| Step: 10
Training loss: 1.9062609672546387
Validation loss: 1.968548305573002

Epoch: 6| Step: 11
Training loss: 2.0534963607788086
Validation loss: 1.9678703802888111

Epoch: 6| Step: 12
Training loss: 2.093132495880127
Validation loss: 1.9697848519971293

Epoch: 6| Step: 13
Training loss: 1.3043038845062256
Validation loss: 1.9667367281452302

Epoch: 99| Step: 0
Training loss: 2.427987575531006
Validation loss: 1.966457595107376

Epoch: 6| Step: 1
Training loss: 2.0851588249206543
Validation loss: 1.9740338402409707

Epoch: 6| Step: 2
Training loss: 2.325901508331299
Validation loss: 1.9550088297936223

Epoch: 6| Step: 3
Training loss: 1.9913363456726074
Validation loss: 1.9785892963409424

Epoch: 6| Step: 4
Training loss: 1.7017563581466675
Validation loss: 1.952261358179072

Epoch: 6| Step: 5
Training loss: 2.1264665126800537
Validation loss: 1.9600264410818777

Epoch: 6| Step: 6
Training loss: 1.4642080068588257
Validation loss: 1.9573312933726976

Epoch: 6| Step: 7
Training loss: 2.0820345878601074
Validation loss: 1.9623678691925541

Epoch: 6| Step: 8
Training loss: 3.0495941638946533
Validation loss: 1.9520905915127005

Epoch: 6| Step: 9
Training loss: 2.0901708602905273
Validation loss: 1.9770839380961593

Epoch: 6| Step: 10
Training loss: 2.257288932800293
Validation loss: 1.9665270928413636

Epoch: 6| Step: 11
Training loss: 1.7461256980895996
Validation loss: 1.953951319058736

Epoch: 6| Step: 12
Training loss: 2.189479112625122
Validation loss: 1.9667964545629357

Epoch: 6| Step: 13
Training loss: 2.3261380195617676
Validation loss: 1.9752220594754784

Epoch: 100| Step: 0
Training loss: 1.9791512489318848
Validation loss: 1.9641980894150273

Epoch: 6| Step: 1
Training loss: 2.253035306930542
Validation loss: 1.9861591862094017

Epoch: 6| Step: 2
Training loss: 2.2466702461242676
Validation loss: 1.9710577226454211

Epoch: 6| Step: 3
Training loss: 2.010134696960449
Validation loss: 1.9877095555746427

Epoch: 6| Step: 4
Training loss: 2.384617805480957
Validation loss: 1.978166744273196

Epoch: 6| Step: 5
Training loss: 1.535731315612793
Validation loss: 1.9862828408518145

Epoch: 6| Step: 6
Training loss: 2.478799343109131
Validation loss: 1.9801592019296461

Epoch: 6| Step: 7
Training loss: 2.098471164703369
Validation loss: 1.9828719208317418

Epoch: 6| Step: 8
Training loss: 2.362570285797119
Validation loss: 1.9850548749328942

Epoch: 6| Step: 9
Training loss: 2.4386234283447266
Validation loss: 1.971567133421539

Epoch: 6| Step: 10
Training loss: 1.9891725778579712
Validation loss: 1.9776714822297454

Epoch: 6| Step: 11
Training loss: 2.3662726879119873
Validation loss: 1.9882682625965407

Epoch: 6| Step: 12
Training loss: 1.7644243240356445
Validation loss: 1.9834649485926474

Epoch: 6| Step: 13
Training loss: 1.5744988918304443
Validation loss: 1.9543530864100302

Epoch: 101| Step: 0
Training loss: 2.408795118331909
Validation loss: 1.9837670582596973

Epoch: 6| Step: 1
Training loss: 2.186096668243408
Validation loss: 1.9786339959790629

Epoch: 6| Step: 2
Training loss: 1.798405647277832
Validation loss: 1.9835585189122025

Epoch: 6| Step: 3
Training loss: 2.005359649658203
Validation loss: 2.0008753832950386

Epoch: 6| Step: 4
Training loss: 2.7793262004852295
Validation loss: 1.979356247891662

Epoch: 6| Step: 5
Training loss: 2.4828944206237793
Validation loss: 1.9972187088381859

Epoch: 6| Step: 6
Training loss: 1.802950143814087
Validation loss: 1.9659816808598016

Epoch: 6| Step: 7
Training loss: 2.2369747161865234
Validation loss: 1.9953413278825822

Epoch: 6| Step: 8
Training loss: 2.010244846343994
Validation loss: 1.9960257148229947

Epoch: 6| Step: 9
Training loss: 2.071333408355713
Validation loss: 1.9895342280787807

Epoch: 6| Step: 10
Training loss: 2.162930965423584
Validation loss: 2.0069016897550194

Epoch: 6| Step: 11
Training loss: 2.28780460357666
Validation loss: 1.9992521860266244

Epoch: 6| Step: 12
Training loss: 1.8321013450622559
Validation loss: 2.002417015772994

Epoch: 6| Step: 13
Training loss: 1.2135720252990723
Validation loss: 2.0153969257108626

Epoch: 102| Step: 0
Training loss: 2.5750203132629395
Validation loss: 1.981231028033841

Epoch: 6| Step: 1
Training loss: 1.833827257156372
Validation loss: 1.9672071344108992

Epoch: 6| Step: 2
Training loss: 1.7361469268798828
Validation loss: 1.9700352376507175

Epoch: 6| Step: 3
Training loss: 1.9592974185943604
Validation loss: 1.9713154992749613

Epoch: 6| Step: 4
Training loss: 2.3628852367401123
Validation loss: 1.947853317824743

Epoch: 6| Step: 5
Training loss: 1.9421114921569824
Validation loss: 1.9560919269438712

Epoch: 6| Step: 6
Training loss: 2.5651941299438477
Validation loss: 1.958884762179467

Epoch: 6| Step: 7
Training loss: 2.4198365211486816
Validation loss: 1.9812365501157698

Epoch: 6| Step: 8
Training loss: 2.521303653717041
Validation loss: 1.9520776015456005

Epoch: 6| Step: 9
Training loss: 1.7294862270355225
Validation loss: 1.9785931905110676

Epoch: 6| Step: 10
Training loss: 2.946133613586426
Validation loss: 1.9541636231125041

Epoch: 6| Step: 11
Training loss: 1.4618935585021973
Validation loss: 1.965414060059414

Epoch: 6| Step: 12
Training loss: 1.5177881717681885
Validation loss: 1.9549830498233918

Epoch: 6| Step: 13
Training loss: 1.897178053855896
Validation loss: 1.9437176001969205

Epoch: 103| Step: 0
Training loss: 1.8056204319000244
Validation loss: 1.962963076048

Epoch: 6| Step: 1
Training loss: 1.7792165279388428
Validation loss: 1.9484080319763513

Epoch: 6| Step: 2
Training loss: 1.9042279720306396
Validation loss: 1.9556719333894792

Epoch: 6| Step: 3
Training loss: 1.8000948429107666
Validation loss: 1.9726499998441307

Epoch: 6| Step: 4
Training loss: 1.8822405338287354
Validation loss: 1.9726959902753112

Epoch: 6| Step: 5
Training loss: 2.3619484901428223
Validation loss: 1.9558762914390975

Epoch: 6| Step: 6
Training loss: 2.5204930305480957
Validation loss: 1.960594997611097

Epoch: 6| Step: 7
Training loss: 1.9942651987075806
Validation loss: 1.9442178536486883

Epoch: 6| Step: 8
Training loss: 2.1729273796081543
Validation loss: 1.9674870737137333

Epoch: 6| Step: 9
Training loss: 1.974739670753479
Validation loss: 1.9594999551773071

Epoch: 6| Step: 10
Training loss: 2.653886318206787
Validation loss: 1.9727429677081365

Epoch: 6| Step: 11
Training loss: 2.2503743171691895
Validation loss: 1.9716908688186316

Epoch: 6| Step: 12
Training loss: 2.3105597496032715
Validation loss: 1.9660393679013817

Epoch: 6| Step: 13
Training loss: 2.1732771396636963
Validation loss: 1.974259937963178

Epoch: 104| Step: 0
Training loss: 1.5931031703948975
Validation loss: 1.9677876708328084

Epoch: 6| Step: 1
Training loss: 1.9674720764160156
Validation loss: 1.982773575731503

Epoch: 6| Step: 2
Training loss: 1.637937068939209
Validation loss: 1.9797629271784136

Epoch: 6| Step: 3
Training loss: 2.2517120838165283
Validation loss: 1.9655747093180174

Epoch: 6| Step: 4
Training loss: 2.3946733474731445
Validation loss: 1.972120015851913

Epoch: 6| Step: 5
Training loss: 2.6985604763031006
Validation loss: 1.9839714611730268

Epoch: 6| Step: 6
Training loss: 2.114382743835449
Validation loss: 1.9671169057969125

Epoch: 6| Step: 7
Training loss: 2.199202060699463
Validation loss: 1.973224745001844

Epoch: 6| Step: 8
Training loss: 1.8497629165649414
Validation loss: 1.9694005456022037

Epoch: 6| Step: 9
Training loss: 2.5105767250061035
Validation loss: 1.9710316273473925

Epoch: 6| Step: 10
Training loss: 1.4644355773925781
Validation loss: 1.9711093800042265

Epoch: 6| Step: 11
Training loss: 2.400724411010742
Validation loss: 1.980871618434947

Epoch: 6| Step: 12
Training loss: 2.1530489921569824
Validation loss: 1.9712496367833947

Epoch: 6| Step: 13
Training loss: 2.4137840270996094
Validation loss: 1.9887112263710267

Epoch: 105| Step: 0
Training loss: 2.394376516342163
Validation loss: 1.969763090533595

Epoch: 6| Step: 1
Training loss: 2.270169734954834
Validation loss: 1.9597935958575177

Epoch: 6| Step: 2
Training loss: 2.172450542449951
Validation loss: 1.9607115253325431

Epoch: 6| Step: 3
Training loss: 1.9040721654891968
Validation loss: 1.974855435791836

Epoch: 6| Step: 4
Training loss: 2.0872676372528076
Validation loss: 1.967632717983697

Epoch: 6| Step: 5
Training loss: 2.0654892921447754
Validation loss: 1.9574612584165347

Epoch: 6| Step: 6
Training loss: 2.307974100112915
Validation loss: 1.953946158450137

Epoch: 6| Step: 7
Training loss: 1.8840004205703735
Validation loss: 1.9689340642703477

Epoch: 6| Step: 8
Training loss: 1.3202629089355469
Validation loss: 1.974510504353431

Epoch: 6| Step: 9
Training loss: 1.969318151473999
Validation loss: 1.9730391681835215

Epoch: 6| Step: 10
Training loss: 2.367074489593506
Validation loss: 1.9664353709067068

Epoch: 6| Step: 11
Training loss: 1.8609557151794434
Validation loss: 1.9521502435848277

Epoch: 6| Step: 12
Training loss: 2.336195945739746
Validation loss: 1.9870629361880723

Epoch: 6| Step: 13
Training loss: 2.502474784851074
Validation loss: 1.9637440263584096

Epoch: 106| Step: 0
Training loss: 1.904954433441162
Validation loss: 1.9639678027040215

Epoch: 6| Step: 1
Training loss: 2.8588051795959473
Validation loss: 1.9626895381558327

Epoch: 6| Step: 2
Training loss: 1.9025379419326782
Validation loss: 1.9468330183336813

Epoch: 6| Step: 3
Training loss: 2.429722785949707
Validation loss: 1.981836151051265

Epoch: 6| Step: 4
Training loss: 1.804983377456665
Validation loss: 1.9780615786070466

Epoch: 6| Step: 5
Training loss: 2.7353014945983887
Validation loss: 1.9930020916846491

Epoch: 6| Step: 6
Training loss: 2.1446034908294678
Validation loss: 1.9623437337977911

Epoch: 6| Step: 7
Training loss: 1.6815435886383057
Validation loss: 1.989203929901123

Epoch: 6| Step: 8
Training loss: 1.9898791313171387
Validation loss: 1.985929698072454

Epoch: 6| Step: 9
Training loss: 1.4558804035186768
Validation loss: 1.9924737330405944

Epoch: 6| Step: 10
Training loss: 2.0997464656829834
Validation loss: 1.9912117988832536

Epoch: 6| Step: 11
Training loss: 2.4133758544921875
Validation loss: 1.990721914076036

Epoch: 6| Step: 12
Training loss: 1.9421027898788452
Validation loss: 1.9904730396886026

Epoch: 6| Step: 13
Training loss: 2.4924376010894775
Validation loss: 1.9725033531906784

Epoch: 107| Step: 0
Training loss: 2.1937971115112305
Validation loss: 1.9558406183796544

Epoch: 6| Step: 1
Training loss: 1.782543420791626
Validation loss: 1.981084644153554

Epoch: 6| Step: 2
Training loss: 2.280036211013794
Validation loss: 1.982422669728597

Epoch: 6| Step: 3
Training loss: 2.390049934387207
Validation loss: 1.9734616817966584

Epoch: 6| Step: 4
Training loss: 1.7330400943756104
Validation loss: 1.968749124516723

Epoch: 6| Step: 5
Training loss: 2.101816177368164
Validation loss: 1.9587570031483967

Epoch: 6| Step: 6
Training loss: 1.8751786947250366
Validation loss: 1.9838421319120674

Epoch: 6| Step: 7
Training loss: 2.1953237056732178
Validation loss: 1.95168181901337

Epoch: 6| Step: 8
Training loss: 1.75634765625
Validation loss: 1.9579120630859046

Epoch: 6| Step: 9
Training loss: 2.559577465057373
Validation loss: 1.949521956905242

Epoch: 6| Step: 10
Training loss: 2.4878721237182617
Validation loss: 1.9500041700178576

Epoch: 6| Step: 11
Training loss: 1.73610520362854
Validation loss: 1.955581239474717

Epoch: 6| Step: 12
Training loss: 2.358269214630127
Validation loss: 1.9663055917268157

Epoch: 6| Step: 13
Training loss: 1.8674041032791138
Validation loss: 1.9549079941165062

Epoch: 108| Step: 0
Training loss: 1.7085554599761963
Validation loss: 1.9677700919489707

Epoch: 6| Step: 1
Training loss: 1.6451927423477173
Validation loss: 1.9566586325245519

Epoch: 6| Step: 2
Training loss: 2.3086490631103516
Validation loss: 1.9645323830266153

Epoch: 6| Step: 3
Training loss: 2.258922576904297
Validation loss: 1.95451174500168

Epoch: 6| Step: 4
Training loss: 2.6321465969085693
Validation loss: 1.9576664317038752

Epoch: 6| Step: 5
Training loss: 1.7327791452407837
Validation loss: 1.9552568145977554

Epoch: 6| Step: 6
Training loss: 2.3213610649108887
Validation loss: 1.9697314180353636

Epoch: 6| Step: 7
Training loss: 1.8484898805618286
Validation loss: 1.949038633736231

Epoch: 6| Step: 8
Training loss: 2.8799519538879395
Validation loss: 1.962202884817636

Epoch: 6| Step: 9
Training loss: 1.7977354526519775
Validation loss: 1.953044658066124

Epoch: 6| Step: 10
Training loss: 2.1245312690734863
Validation loss: 1.938600585024844

Epoch: 6| Step: 11
Training loss: 1.7547965049743652
Validation loss: 1.9661229912952711

Epoch: 6| Step: 12
Training loss: 2.0917303562164307
Validation loss: 1.9549004313766316

Epoch: 6| Step: 13
Training loss: 2.533543586730957
Validation loss: 1.9639538846990114

Epoch: 109| Step: 0
Training loss: 3.1182408332824707
Validation loss: 1.9691131012414091

Epoch: 6| Step: 1
Training loss: 2.6605653762817383
Validation loss: 1.970246761075912

Epoch: 6| Step: 2
Training loss: 2.051332712173462
Validation loss: 1.9699724566551946

Epoch: 6| Step: 3
Training loss: 2.3864493370056152
Validation loss: 1.9684451600556732

Epoch: 6| Step: 4
Training loss: 2.1184275150299072
Validation loss: 1.9700854529616654

Epoch: 6| Step: 5
Training loss: 1.5150511264801025
Validation loss: 1.9738873307422926

Epoch: 6| Step: 6
Training loss: 1.831423044204712
Validation loss: 1.9622027566356044

Epoch: 6| Step: 7
Training loss: 1.976427435874939
Validation loss: 1.968256360741072

Epoch: 6| Step: 8
Training loss: 2.073099136352539
Validation loss: 1.9805166106070242

Epoch: 6| Step: 9
Training loss: 2.2583608627319336
Validation loss: 1.977264242787515

Epoch: 6| Step: 10
Training loss: 1.992960810661316
Validation loss: 1.976217701870908

Epoch: 6| Step: 11
Training loss: 1.7506582736968994
Validation loss: 1.9795595651031823

Epoch: 6| Step: 12
Training loss: 1.5810296535491943
Validation loss: 1.9664173933767504

Epoch: 6| Step: 13
Training loss: 2.2841310501098633
Validation loss: 1.983979348213442

Epoch: 110| Step: 0
Training loss: 1.9965323209762573
Validation loss: 1.9826426198405604

Epoch: 6| Step: 1
Training loss: 2.4977097511291504
Validation loss: 1.9848222206997614

Epoch: 6| Step: 2
Training loss: 2.0190815925598145
Validation loss: 1.9737346659424484

Epoch: 6| Step: 3
Training loss: 1.8271582126617432
Validation loss: 1.9800127270401164

Epoch: 6| Step: 4
Training loss: 2.3094310760498047
Validation loss: 1.9877923842399352

Epoch: 6| Step: 5
Training loss: 1.8505926132202148
Validation loss: 1.9837594378379084

Epoch: 6| Step: 6
Training loss: 2.4460177421569824
Validation loss: 1.9814093882037747

Epoch: 6| Step: 7
Training loss: 1.9061617851257324
Validation loss: 1.9856092827294463

Epoch: 6| Step: 8
Training loss: 2.520988941192627
Validation loss: 1.9877914292837984

Epoch: 6| Step: 9
Training loss: 1.8017642498016357
Validation loss: 1.9857648341886458

Epoch: 6| Step: 10
Training loss: 2.1300301551818848
Validation loss: 1.9595507267982728

Epoch: 6| Step: 11
Training loss: 1.4484208822250366
Validation loss: 1.9626631775209982

Epoch: 6| Step: 12
Training loss: 2.425791025161743
Validation loss: 1.9670380879473943

Epoch: 6| Step: 13
Training loss: 2.264882802963257
Validation loss: 1.9717990864989579

Epoch: 111| Step: 0
Training loss: 2.6268715858459473
Validation loss: 1.9566643648250128

Epoch: 6| Step: 1
Training loss: 1.7662863731384277
Validation loss: 1.9658983522845852

Epoch: 6| Step: 2
Training loss: 1.9842629432678223
Validation loss: 1.96678804069437

Epoch: 6| Step: 3
Training loss: 2.5829243659973145
Validation loss: 1.958547169162381

Epoch: 6| Step: 4
Training loss: 1.6642816066741943
Validation loss: 1.9481592082208203

Epoch: 6| Step: 5
Training loss: 1.8615162372589111
Validation loss: 1.9706914681260304

Epoch: 6| Step: 6
Training loss: 2.4433488845825195
Validation loss: 1.9581469297409058

Epoch: 6| Step: 7
Training loss: 1.645287036895752
Validation loss: 1.9713838177342569

Epoch: 6| Step: 8
Training loss: 1.8448727130889893
Validation loss: 1.9475198996964322

Epoch: 6| Step: 9
Training loss: 1.9372143745422363
Validation loss: 1.9611323213064542

Epoch: 6| Step: 10
Training loss: 2.0634469985961914
Validation loss: 1.9768933814059022

Epoch: 6| Step: 11
Training loss: 1.6087558269500732
Validation loss: 1.9654105594081264

Epoch: 6| Step: 12
Training loss: 3.0869786739349365
Validation loss: 1.969782688284433

Epoch: 6| Step: 13
Training loss: 2.449291706085205
Validation loss: 1.9549827767956642

Epoch: 112| Step: 0
Training loss: 2.002901315689087
Validation loss: 1.9518257289804437

Epoch: 6| Step: 1
Training loss: 2.0095040798187256
Validation loss: 1.96400922600941

Epoch: 6| Step: 2
Training loss: 2.2678685188293457
Validation loss: 1.9615752696990967

Epoch: 6| Step: 3
Training loss: 1.9975087642669678
Validation loss: 1.9714719787720711

Epoch: 6| Step: 4
Training loss: 2.5185623168945312
Validation loss: 1.9545775594249848

Epoch: 6| Step: 5
Training loss: 1.3864250183105469
Validation loss: 1.9514428236151253

Epoch: 6| Step: 6
Training loss: 2.148336410522461
Validation loss: 1.9564022735882831

Epoch: 6| Step: 7
Training loss: 2.489190101623535
Validation loss: 1.9697575184606737

Epoch: 6| Step: 8
Training loss: 1.658841609954834
Validation loss: 1.9212717394674979

Epoch: 6| Step: 9
Training loss: 2.3361496925354004
Validation loss: 1.93267152642691

Epoch: 6| Step: 10
Training loss: 1.9364022016525269
Validation loss: 1.9588956909794961

Epoch: 6| Step: 11
Training loss: 1.4354119300842285
Validation loss: 1.9692545372952697

Epoch: 6| Step: 12
Training loss: 2.491631031036377
Validation loss: 1.9379134434525684

Epoch: 6| Step: 13
Training loss: 2.734315872192383
Validation loss: 1.9683869820769115

Epoch: 113| Step: 0
Training loss: 2.2780964374542236
Validation loss: 1.9514649145064815

Epoch: 6| Step: 1
Training loss: 1.8412331342697144
Validation loss: 1.9618603670468895

Epoch: 6| Step: 2
Training loss: 2.989260673522949
Validation loss: 1.9806007159653531

Epoch: 6| Step: 3
Training loss: 2.2801101207733154
Validation loss: 1.9639012198294363

Epoch: 6| Step: 4
Training loss: 1.837766170501709
Validation loss: 1.97321532874979

Epoch: 6| Step: 5
Training loss: 2.607179641723633
Validation loss: 1.9668099598218036

Epoch: 6| Step: 6
Training loss: 1.585842251777649
Validation loss: 1.975774431741366

Epoch: 6| Step: 7
Training loss: 2.2872376441955566
Validation loss: 1.9810227681231756

Epoch: 6| Step: 8
Training loss: 2.1933908462524414
Validation loss: 1.9915918714256697

Epoch: 6| Step: 9
Training loss: 1.8208532333374023
Validation loss: 1.9869258557596514

Epoch: 6| Step: 10
Training loss: 1.76478910446167
Validation loss: 1.977077655894782

Epoch: 6| Step: 11
Training loss: 1.768216848373413
Validation loss: 1.9662547611421155

Epoch: 6| Step: 12
Training loss: 1.9569388628005981
Validation loss: 1.9810785542252243

Epoch: 6| Step: 13
Training loss: 2.103614568710327
Validation loss: 1.997792136284613

Epoch: 114| Step: 0
Training loss: 1.8127321004867554
Validation loss: 1.9796233651458577

Epoch: 6| Step: 1
Training loss: 2.785977840423584
Validation loss: 1.9580527890113093

Epoch: 6| Step: 2
Training loss: 2.9038355350494385
Validation loss: 1.9691813299732823

Epoch: 6| Step: 3
Training loss: 2.20066499710083
Validation loss: 1.985025687884259

Epoch: 6| Step: 4
Training loss: 1.8794217109680176
Validation loss: 1.9731185795158468

Epoch: 6| Step: 5
Training loss: 2.5612945556640625
Validation loss: 1.9682999477591565

Epoch: 6| Step: 6
Training loss: 2.467210292816162
Validation loss: 1.9707556475875199

Epoch: 6| Step: 7
Training loss: 2.157351016998291
Validation loss: 1.9877381606768536

Epoch: 6| Step: 8
Training loss: 1.616642951965332
Validation loss: 1.9866838685927852

Epoch: 6| Step: 9
Training loss: 2.088522434234619
Validation loss: 1.9580450211801836

Epoch: 6| Step: 10
Training loss: 1.561405897140503
Validation loss: 1.9804962758095033

Epoch: 6| Step: 11
Training loss: 2.0660133361816406
Validation loss: 1.9867847209335656

Epoch: 6| Step: 12
Training loss: 1.3655439615249634
Validation loss: 1.9782686694975822

Epoch: 6| Step: 13
Training loss: 1.4192309379577637
Validation loss: 1.9963486066428564

Epoch: 115| Step: 0
Training loss: 2.0212700366973877
Validation loss: 1.957447741621284

Epoch: 6| Step: 1
Training loss: 1.9329371452331543
Validation loss: 1.9776212092368834

Epoch: 6| Step: 2
Training loss: 1.9858031272888184
Validation loss: 1.9653807327311525

Epoch: 6| Step: 3
Training loss: 2.912189483642578
Validation loss: 1.9801312262012112

Epoch: 6| Step: 4
Training loss: 2.3880228996276855
Validation loss: 1.9757928848266602

Epoch: 6| Step: 5
Training loss: 1.765433669090271
Validation loss: 1.9613920155391897

Epoch: 6| Step: 6
Training loss: 2.1703219413757324
Validation loss: 1.969614774950089

Epoch: 6| Step: 7
Training loss: 1.9856884479522705
Validation loss: 1.9619852535186275

Epoch: 6| Step: 8
Training loss: 2.332507610321045
Validation loss: 1.9633929293642762

Epoch: 6| Step: 9
Training loss: 1.282421350479126
Validation loss: 1.9601653737406577

Epoch: 6| Step: 10
Training loss: 2.5536794662475586
Validation loss: 1.9780198976557741

Epoch: 6| Step: 11
Training loss: 2.006364583969116
Validation loss: 1.9788462910600888

Epoch: 6| Step: 12
Training loss: 1.610883116722107
Validation loss: 1.9770523963436004

Epoch: 6| Step: 13
Training loss: 2.279524803161621
Validation loss: 1.9947367791206605

Epoch: 116| Step: 0
Training loss: 2.083632707595825
Validation loss: 1.9613529700104908

Epoch: 6| Step: 1
Training loss: 2.477356195449829
Validation loss: 1.9718112394373903

Epoch: 6| Step: 2
Training loss: 0.7605481147766113
Validation loss: 1.9605447194909538

Epoch: 6| Step: 3
Training loss: 2.1361258029937744
Validation loss: 1.9609337827210784

Epoch: 6| Step: 4
Training loss: 2.705803871154785
Validation loss: 1.9674157993767851

Epoch: 6| Step: 5
Training loss: 1.8671302795410156
Validation loss: 1.969293112395912

Epoch: 6| Step: 6
Training loss: 2.1477997303009033
Validation loss: 1.9498497811696862

Epoch: 6| Step: 7
Training loss: 1.6211035251617432
Validation loss: 1.95668190140878

Epoch: 6| Step: 8
Training loss: 2.0362484455108643
Validation loss: 1.9667999462414814

Epoch: 6| Step: 9
Training loss: 2.095280647277832
Validation loss: 1.994933125793293

Epoch: 6| Step: 10
Training loss: 2.1795718669891357
Validation loss: 1.9767259820815055

Epoch: 6| Step: 11
Training loss: 2.6082215309143066
Validation loss: 1.94453872916519

Epoch: 6| Step: 12
Training loss: 2.490159034729004
Validation loss: 1.9676172041123914

Epoch: 6| Step: 13
Training loss: 1.4916584491729736
Validation loss: 1.9643264432107248

Epoch: 117| Step: 0
Training loss: 1.577404260635376
Validation loss: 1.9590181137925835

Epoch: 6| Step: 1
Training loss: 2.269397020339966
Validation loss: 1.9780965261561896

Epoch: 6| Step: 2
Training loss: 1.2935394048690796
Validation loss: 1.9724610800384192

Epoch: 6| Step: 3
Training loss: 2.1385257244110107
Validation loss: 1.9664602382208711

Epoch: 6| Step: 4
Training loss: 2.0050432682037354
Validation loss: 1.9761051003650953

Epoch: 6| Step: 5
Training loss: 1.6895419359207153
Validation loss: 1.9713609795416556

Epoch: 6| Step: 6
Training loss: 2.729706048965454
Validation loss: 1.9680842494451871

Epoch: 6| Step: 7
Training loss: 2.582693099975586
Validation loss: 1.9695280200691634

Epoch: 6| Step: 8
Training loss: 2.3748228549957275
Validation loss: 1.9787845637208672

Epoch: 6| Step: 9
Training loss: 1.38568115234375
Validation loss: 1.97790801653298

Epoch: 6| Step: 10
Training loss: 2.605515480041504
Validation loss: 1.9786341703066261

Epoch: 6| Step: 11
Training loss: 2.716609477996826
Validation loss: 1.9711467604483328

Epoch: 6| Step: 12
Training loss: 1.9240270853042603
Validation loss: 1.9616775281967656

Epoch: 6| Step: 13
Training loss: 1.7918709516525269
Validation loss: 1.9866521422581007

Epoch: 118| Step: 0
Training loss: 2.367061138153076
Validation loss: 1.9632372330593806

Epoch: 6| Step: 1
Training loss: 2.0026986598968506
Validation loss: 1.983345599584682

Epoch: 6| Step: 2
Training loss: 1.451521396636963
Validation loss: 1.9686864422213646

Epoch: 6| Step: 3
Training loss: 1.8781276941299438
Validation loss: 1.9797879803565241

Epoch: 6| Step: 4
Training loss: 1.830544352531433
Validation loss: 1.9614451546822824

Epoch: 6| Step: 5
Training loss: 2.279338836669922
Validation loss: 1.956245486454297

Epoch: 6| Step: 6
Training loss: 2.961090087890625
Validation loss: 1.9587159233708535

Epoch: 6| Step: 7
Training loss: 1.8768291473388672
Validation loss: 1.9831457253425353

Epoch: 6| Step: 8
Training loss: 2.145145893096924
Validation loss: 1.952461132439234

Epoch: 6| Step: 9
Training loss: 2.527073860168457
Validation loss: 1.9818837360669208

Epoch: 6| Step: 10
Training loss: 2.5820884704589844
Validation loss: 1.9583750437664729

Epoch: 6| Step: 11
Training loss: 1.4766080379486084
Validation loss: 1.9753301015464209

Epoch: 6| Step: 12
Training loss: 1.7569475173950195
Validation loss: 1.974447347784555

Epoch: 6| Step: 13
Training loss: 1.7932804822921753
Validation loss: 1.9649435756027058

Epoch: 119| Step: 0
Training loss: 1.752394437789917
Validation loss: 1.974903747599612

Epoch: 6| Step: 1
Training loss: 1.8088233470916748
Validation loss: 1.9692577277460406

Epoch: 6| Step: 2
Training loss: 2.231196403503418
Validation loss: 1.962236237782304

Epoch: 6| Step: 3
Training loss: 2.1630632877349854
Validation loss: 1.999347843149657

Epoch: 6| Step: 4
Training loss: 2.3543925285339355
Validation loss: 1.949270898295987

Epoch: 6| Step: 5
Training loss: 1.5096665620803833
Validation loss: 1.9455951529164468

Epoch: 6| Step: 6
Training loss: 2.131711006164551
Validation loss: 1.9669761016804685

Epoch: 6| Step: 7
Training loss: 1.7959990501403809
Validation loss: 1.978682869224138

Epoch: 6| Step: 8
Training loss: 2.2637763023376465
Validation loss: 1.9610100997391569

Epoch: 6| Step: 9
Training loss: 1.9762051105499268
Validation loss: 1.977691327371905

Epoch: 6| Step: 10
Training loss: 2.0495412349700928
Validation loss: 1.9673646342369817

Epoch: 6| Step: 11
Training loss: 2.305802822113037
Validation loss: 1.9628234178789201

Epoch: 6| Step: 12
Training loss: 2.105595350265503
Validation loss: 1.969765737492551

Epoch: 6| Step: 13
Training loss: 2.9620046615600586
Validation loss: 1.94005254391701

Epoch: 120| Step: 0
Training loss: 2.2820355892181396
Validation loss: 1.9620953426566174

Epoch: 6| Step: 1
Training loss: 1.8585213422775269
Validation loss: 1.974383351623371

Epoch: 6| Step: 2
Training loss: 2.6585350036621094
Validation loss: 1.970874471049155

Epoch: 6| Step: 3
Training loss: 1.9566906690597534
Validation loss: 1.960298361316804

Epoch: 6| Step: 4
Training loss: 2.188284397125244
Validation loss: 2.001796773684922

Epoch: 6| Step: 5
Training loss: 1.761507511138916
Validation loss: 1.9817341694267847

Epoch: 6| Step: 6
Training loss: 2.162959337234497
Validation loss: 1.981902801862327

Epoch: 6| Step: 7
Training loss: 1.5029197931289673
Validation loss: 1.9788320218363116

Epoch: 6| Step: 8
Training loss: 2.4400813579559326
Validation loss: 1.986965016652179

Epoch: 6| Step: 9
Training loss: 1.790924072265625
Validation loss: 1.9554309011787496

Epoch: 6| Step: 10
Training loss: 1.9497236013412476
Validation loss: 1.9460287299207462

Epoch: 6| Step: 11
Training loss: 1.977891206741333
Validation loss: 1.9658252410991217

Epoch: 6| Step: 12
Training loss: 1.6521629095077515
Validation loss: 1.9505998780650478

Epoch: 6| Step: 13
Training loss: 3.0364317893981934
Validation loss: 1.9792272019129928

Epoch: 121| Step: 0
Training loss: 2.324502468109131
Validation loss: 1.9828049252110143

Epoch: 6| Step: 1
Training loss: 2.3013861179351807
Validation loss: 1.943649443246985

Epoch: 6| Step: 2
Training loss: 2.261052370071411
Validation loss: 1.9651978849082865

Epoch: 6| Step: 3
Training loss: 1.8986239433288574
Validation loss: 1.9702002886802918

Epoch: 6| Step: 4
Training loss: 2.1089632511138916
Validation loss: 1.9713364160189064

Epoch: 6| Step: 5
Training loss: 2.0727322101593018
Validation loss: 1.9899332241345478

Epoch: 6| Step: 6
Training loss: 1.8988817930221558
Validation loss: 1.9639991714108376

Epoch: 6| Step: 7
Training loss: 1.842686653137207
Validation loss: 1.9820449557355655

Epoch: 6| Step: 8
Training loss: 1.6323339939117432
Validation loss: 1.9965555296149304

Epoch: 6| Step: 9
Training loss: 2.724705219268799
Validation loss: 1.9630340530026344

Epoch: 6| Step: 10
Training loss: 2.441932201385498
Validation loss: 1.977609839490665

Epoch: 6| Step: 11
Training loss: 1.6868466138839722
Validation loss: 1.9675279304545412

Epoch: 6| Step: 12
Training loss: 2.100339412689209
Validation loss: 1.954474422239488

Epoch: 6| Step: 13
Training loss: 1.3708038330078125
Validation loss: 1.9525826143962082

Epoch: 122| Step: 0
Training loss: 1.5028207302093506
Validation loss: 1.9719543328849218

Epoch: 6| Step: 1
Training loss: 2.1473278999328613
Validation loss: 1.9704967647470453

Epoch: 6| Step: 2
Training loss: 2.224226474761963
Validation loss: 1.949016103180506

Epoch: 6| Step: 3
Training loss: 2.585733413696289
Validation loss: 1.9604749910293087

Epoch: 6| Step: 4
Training loss: 2.9357385635375977
Validation loss: 1.9771551752603183

Epoch: 6| Step: 5
Training loss: 1.8559436798095703
Validation loss: 1.9589647093126852

Epoch: 6| Step: 6
Training loss: 2.276022434234619
Validation loss: 1.9536052673093733

Epoch: 6| Step: 7
Training loss: 2.1424951553344727
Validation loss: 1.954069314464446

Epoch: 6| Step: 8
Training loss: 1.976322889328003
Validation loss: 1.9706153049263904

Epoch: 6| Step: 9
Training loss: 1.4833929538726807
Validation loss: 1.9613555503147904

Epoch: 6| Step: 10
Training loss: 2.150810718536377
Validation loss: 1.9461911493732083

Epoch: 6| Step: 11
Training loss: 1.616809368133545
Validation loss: 1.972466350883566

Epoch: 6| Step: 12
Training loss: 1.9456892013549805
Validation loss: 1.9864883025487263

Epoch: 6| Step: 13
Training loss: 1.9144554138183594
Validation loss: 1.9493677334118915

Epoch: 123| Step: 0
Training loss: 2.215512752532959
Validation loss: 1.973564665804627

Epoch: 6| Step: 1
Training loss: 2.4283251762390137
Validation loss: 1.9645355491228

Epoch: 6| Step: 2
Training loss: 1.6658916473388672
Validation loss: 1.9636530260885916

Epoch: 6| Step: 3
Training loss: 1.658268690109253
Validation loss: 1.9834827043676888

Epoch: 6| Step: 4
Training loss: 2.3095550537109375
Validation loss: 1.9860885771371986

Epoch: 6| Step: 5
Training loss: 1.5666980743408203
Validation loss: 1.950876735871838

Epoch: 6| Step: 6
Training loss: 2.7172048091888428
Validation loss: 1.9682006887210313

Epoch: 6| Step: 7
Training loss: 1.8365219831466675
Validation loss: 1.9643588514738186

Epoch: 6| Step: 8
Training loss: 1.9670796394348145
Validation loss: 1.961024425363028

Epoch: 6| Step: 9
Training loss: 1.5765482187271118
Validation loss: 1.973992250298941

Epoch: 6| Step: 10
Training loss: 1.7250778675079346
Validation loss: 1.9545391413473314

Epoch: 6| Step: 11
Training loss: 2.3586339950561523
Validation loss: 1.9567755729921403

Epoch: 6| Step: 12
Training loss: 2.5953850746154785
Validation loss: 1.942601409009708

Epoch: 6| Step: 13
Training loss: 2.012080669403076
Validation loss: 1.9665304691560808

Epoch: 124| Step: 0
Training loss: 2.1744165420532227
Validation loss: 1.97580547102036

Epoch: 6| Step: 1
Training loss: 2.4389829635620117
Validation loss: 1.9656747989757086

Epoch: 6| Step: 2
Training loss: 1.5814403295516968
Validation loss: 1.9787567456563313

Epoch: 6| Step: 3
Training loss: 2.346229314804077
Validation loss: 1.947370986784658

Epoch: 6| Step: 4
Training loss: 2.2637081146240234
Validation loss: 1.973193489095216

Epoch: 6| Step: 5
Training loss: 1.9682562351226807
Validation loss: 1.9358328696220153

Epoch: 6| Step: 6
Training loss: 1.1619328260421753
Validation loss: 1.9685755134910665

Epoch: 6| Step: 7
Training loss: 1.8297572135925293
Validation loss: 1.9490458926846903

Epoch: 6| Step: 8
Training loss: 1.89060640335083
Validation loss: 1.9610264121845205

Epoch: 6| Step: 9
Training loss: 2.589478015899658
Validation loss: 1.9621585043527747

Epoch: 6| Step: 10
Training loss: 2.5441532135009766
Validation loss: 1.9467874726941508

Epoch: 6| Step: 11
Training loss: 2.1064233779907227
Validation loss: 1.9436055319283598

Epoch: 6| Step: 12
Training loss: 2.0823795795440674
Validation loss: 1.9968329270680745

Epoch: 6| Step: 13
Training loss: 1.5148944854736328
Validation loss: 1.9578663610642957

Epoch: 125| Step: 0
Training loss: 2.781543254852295
Validation loss: 1.9720321137418029

Epoch: 6| Step: 1
Training loss: 2.3284144401550293
Validation loss: 1.9821860149342527

Epoch: 6| Step: 2
Training loss: 2.186634063720703
Validation loss: 1.987446351717877

Epoch: 6| Step: 3
Training loss: 2.048827648162842
Validation loss: 1.9695138034000192

Epoch: 6| Step: 4
Training loss: 2.1461479663848877
Validation loss: 1.9585985240115915

Epoch: 6| Step: 5
Training loss: 1.7742085456848145
Validation loss: 1.9630922925087713

Epoch: 6| Step: 6
Training loss: 1.911787509918213
Validation loss: 1.9373443075405654

Epoch: 6| Step: 7
Training loss: 2.751011610031128
Validation loss: 1.9625534678018222

Epoch: 6| Step: 8
Training loss: 1.5634520053863525
Validation loss: 1.9547907562666043

Epoch: 6| Step: 9
Training loss: 1.4379312992095947
Validation loss: 1.9794226590023245

Epoch: 6| Step: 10
Training loss: 1.6900599002838135
Validation loss: 1.9652162533934399

Epoch: 6| Step: 11
Training loss: 1.5759973526000977
Validation loss: 1.9645525011965024

Epoch: 6| Step: 12
Training loss: 2.3520045280456543
Validation loss: 1.9699367143774544

Epoch: 6| Step: 13
Training loss: 2.1634469032287598
Validation loss: 1.9648638335607385

Epoch: 126| Step: 0
Training loss: 2.1934452056884766
Validation loss: 1.9404637249567176

Epoch: 6| Step: 1
Training loss: 2.0718562602996826
Validation loss: 1.9636525825787616

Epoch: 6| Step: 2
Training loss: 2.043665647506714
Validation loss: 1.9526576534394295

Epoch: 6| Step: 3
Training loss: 1.9130465984344482
Validation loss: 1.9708804404863747

Epoch: 6| Step: 4
Training loss: 2.6541738510131836
Validation loss: 1.9615407707870647

Epoch: 6| Step: 5
Training loss: 1.9464240074157715
Validation loss: 1.956939689574703

Epoch: 6| Step: 6
Training loss: 1.7249932289123535
Validation loss: 1.9626515526925363

Epoch: 6| Step: 7
Training loss: 2.2278192043304443
Validation loss: 1.9495870631228212

Epoch: 6| Step: 8
Training loss: 1.8278288841247559
Validation loss: 1.9517584334137619

Epoch: 6| Step: 9
Training loss: 2.133305549621582
Validation loss: 1.977852713677191

Epoch: 6| Step: 10
Training loss: 1.4809415340423584
Validation loss: 1.9754808243884836

Epoch: 6| Step: 11
Training loss: 1.4868743419647217
Validation loss: 1.9770554214395502

Epoch: 6| Step: 12
Training loss: 2.7205862998962402
Validation loss: 1.9710073599251368

Epoch: 6| Step: 13
Training loss: 2.2770562171936035
Validation loss: 1.9571922722683157

Epoch: 127| Step: 0
Training loss: 2.1149098873138428
Validation loss: 1.974896523260301

Epoch: 6| Step: 1
Training loss: 1.5898867845535278
Validation loss: 1.9623148851497199

Epoch: 6| Step: 2
Training loss: 2.1609463691711426
Validation loss: 1.998751941547599

Epoch: 6| Step: 3
Training loss: 1.6644543409347534
Validation loss: 1.9506989614937895

Epoch: 6| Step: 4
Training loss: 2.1556942462921143
Validation loss: 1.9531270034851567

Epoch: 6| Step: 5
Training loss: 1.472099781036377
Validation loss: 1.9704328634405648

Epoch: 6| Step: 6
Training loss: 2.519967555999756
Validation loss: 1.9670441342938332

Epoch: 6| Step: 7
Training loss: 2.5106616020202637
Validation loss: 1.943622144319678

Epoch: 6| Step: 8
Training loss: 2.0712318420410156
Validation loss: 1.9563921497714134

Epoch: 6| Step: 9
Training loss: 2.584061622619629
Validation loss: 1.9556563464544152

Epoch: 6| Step: 10
Training loss: 2.425678253173828
Validation loss: 1.9464704887841338

Epoch: 6| Step: 11
Training loss: 1.7877397537231445
Validation loss: 1.9528617935795938

Epoch: 6| Step: 12
Training loss: 1.7931628227233887
Validation loss: 1.9672343500198857

Epoch: 6| Step: 13
Training loss: 1.632630467414856
Validation loss: 1.943718175734243

Epoch: 128| Step: 0
Training loss: 1.5982565879821777
Validation loss: 1.9563717226828299

Epoch: 6| Step: 1
Training loss: 1.7430472373962402
Validation loss: 1.9620047256510744

Epoch: 6| Step: 2
Training loss: 1.666635274887085
Validation loss: 1.9533364952251475

Epoch: 6| Step: 3
Training loss: 2.1185529232025146
Validation loss: 1.9719442116316928

Epoch: 6| Step: 4
Training loss: 1.6135175228118896
Validation loss: 1.950707738117505

Epoch: 6| Step: 5
Training loss: 2.7432680130004883
Validation loss: 1.9655102081196283

Epoch: 6| Step: 6
Training loss: 2.2491965293884277
Validation loss: 1.968709558568975

Epoch: 6| Step: 7
Training loss: 1.9003130197525024
Validation loss: 1.9607992223514024

Epoch: 6| Step: 8
Training loss: 2.548337936401367
Validation loss: 1.9635837706186439

Epoch: 6| Step: 9
Training loss: 2.2635746002197266
Validation loss: 1.9525508201250465

Epoch: 6| Step: 10
Training loss: 1.9695830345153809
Validation loss: 1.9725584086551462

Epoch: 6| Step: 11
Training loss: 2.366311550140381
Validation loss: 1.9609263917451263

Epoch: 6| Step: 12
Training loss: 1.8458075523376465
Validation loss: 1.9658825602582706

Epoch: 6| Step: 13
Training loss: 2.1702237129211426
Validation loss: 1.9595117158787225

Epoch: 129| Step: 0
Training loss: 2.033377170562744
Validation loss: 1.954952173335578

Epoch: 6| Step: 1
Training loss: 1.9155969619750977
Validation loss: 1.9735859914492535

Epoch: 6| Step: 2
Training loss: 2.675845146179199
Validation loss: 1.9825058573035783

Epoch: 6| Step: 3
Training loss: 2.229893684387207
Validation loss: 1.9723488925605692

Epoch: 6| Step: 4
Training loss: 1.4365229606628418
Validation loss: 1.9501011884340675

Epoch: 6| Step: 5
Training loss: 1.7247319221496582
Validation loss: 1.965632261768464

Epoch: 6| Step: 6
Training loss: 1.5619633197784424
Validation loss: 1.9608908250767698

Epoch: 6| Step: 7
Training loss: 2.635101556777954
Validation loss: 1.972089930247235

Epoch: 6| Step: 8
Training loss: 1.7370901107788086
Validation loss: 1.9776046109455887

Epoch: 6| Step: 9
Training loss: 1.944689154624939
Validation loss: 1.949176255092826

Epoch: 6| Step: 10
Training loss: 1.9869869947433472
Validation loss: 1.9907750442463865

Epoch: 6| Step: 11
Training loss: 1.9114432334899902
Validation loss: 1.942215996403848

Epoch: 6| Step: 12
Training loss: 2.8730950355529785
Validation loss: 1.9626654271156556

Epoch: 6| Step: 13
Training loss: 1.6862651109695435
Validation loss: 1.9707419590283466

Epoch: 130| Step: 0
Training loss: 2.46738338470459
Validation loss: 1.9656969603671823

Epoch: 6| Step: 1
Training loss: 2.32674241065979
Validation loss: 1.9464462252073391

Epoch: 6| Step: 2
Training loss: 1.787245273590088
Validation loss: 1.961361426179127

Epoch: 6| Step: 3
Training loss: 1.4495620727539062
Validation loss: 1.9546992125049714

Epoch: 6| Step: 4
Training loss: 2.617093563079834
Validation loss: 1.9592922451675578

Epoch: 6| Step: 5
Training loss: 2.085984706878662
Validation loss: 1.9383700996316888

Epoch: 6| Step: 6
Training loss: 2.194344997406006
Validation loss: 1.9570813589198615

Epoch: 6| Step: 7
Training loss: 1.8941534757614136
Validation loss: 1.9560560654568415

Epoch: 6| Step: 8
Training loss: 1.2404924631118774
Validation loss: 1.9665067362528976

Epoch: 6| Step: 9
Training loss: 2.1318917274475098
Validation loss: 1.9577429948314544

Epoch: 6| Step: 10
Training loss: 2.163867473602295
Validation loss: 1.9556776951718073

Epoch: 6| Step: 11
Training loss: 1.4844770431518555
Validation loss: 1.948731917206959

Epoch: 6| Step: 12
Training loss: 2.2873589992523193
Validation loss: 1.9506548732839606

Epoch: 6| Step: 13
Training loss: 2.5389175415039062
Validation loss: 1.9392690530387304

Epoch: 131| Step: 0
Training loss: 2.308260917663574
Validation loss: 1.9524815056913642

Epoch: 6| Step: 1
Training loss: 2.2260069847106934
Validation loss: 1.956651718385758

Epoch: 6| Step: 2
Training loss: 2.1540422439575195
Validation loss: 1.9520006525901057

Epoch: 6| Step: 3
Training loss: 1.289802074432373
Validation loss: 1.9428508768799484

Epoch: 6| Step: 4
Training loss: 2.2153892517089844
Validation loss: 1.9723149743131412

Epoch: 6| Step: 5
Training loss: 2.401045083999634
Validation loss: 1.9541973401141424

Epoch: 6| Step: 6
Training loss: 2.57692813873291
Validation loss: 1.9705361371399255

Epoch: 6| Step: 7
Training loss: 2.4203803539276123
Validation loss: 1.9638681745016446

Epoch: 6| Step: 8
Training loss: 1.9426723718643188
Validation loss: 1.9637738696990474

Epoch: 6| Step: 9
Training loss: 1.5785584449768066
Validation loss: 1.965334394926666

Epoch: 6| Step: 10
Training loss: 1.9512910842895508
Validation loss: 1.9653862522494407

Epoch: 6| Step: 11
Training loss: 1.6444687843322754
Validation loss: 1.9437002815226072

Epoch: 6| Step: 12
Training loss: 1.8049376010894775
Validation loss: 1.9706244314870527

Epoch: 6| Step: 13
Training loss: 1.8658150434494019
Validation loss: 1.9923771696705972

Epoch: 132| Step: 0
Training loss: 2.239577293395996
Validation loss: 1.9482529112087783

Epoch: 6| Step: 1
Training loss: 2.313786745071411
Validation loss: 1.962052168384675

Epoch: 6| Step: 2
Training loss: 1.8843765258789062
Validation loss: 1.9651255017967635

Epoch: 6| Step: 3
Training loss: 2.317500591278076
Validation loss: 1.9340559923520653

Epoch: 6| Step: 4
Training loss: 2.1969194412231445
Validation loss: 1.981553195625223

Epoch: 6| Step: 5
Training loss: 2.2439255714416504
Validation loss: 1.9644836200180875

Epoch: 6| Step: 6
Training loss: 0.8200293779373169
Validation loss: 1.9652015573234969

Epoch: 6| Step: 7
Training loss: 2.287623882293701
Validation loss: 1.9766286598738803

Epoch: 6| Step: 8
Training loss: 2.282240390777588
Validation loss: 1.9750299697281213

Epoch: 6| Step: 9
Training loss: 2.051745891571045
Validation loss: 1.9796417849038237

Epoch: 6| Step: 10
Training loss: 1.7628921270370483
Validation loss: 1.9638100260047502

Epoch: 6| Step: 11
Training loss: 1.805683970451355
Validation loss: 1.9583294904360207

Epoch: 6| Step: 12
Training loss: 2.1911160945892334
Validation loss: 1.967754288386273

Epoch: 6| Step: 13
Training loss: 1.954498529434204
Validation loss: 1.9651750056974349

Epoch: 133| Step: 0
Training loss: 1.6616935729980469
Validation loss: 1.9522911246104906

Epoch: 6| Step: 1
Training loss: 1.743998408317566
Validation loss: 1.9727576958235873

Epoch: 6| Step: 2
Training loss: 2.586552619934082
Validation loss: 1.9329740949856338

Epoch: 6| Step: 3
Training loss: 1.8110018968582153
Validation loss: 1.930123839327084

Epoch: 6| Step: 4
Training loss: 2.3306612968444824
Validation loss: 1.9810065428415935

Epoch: 6| Step: 5
Training loss: 1.9150745868682861
Validation loss: 1.9397462926885134

Epoch: 6| Step: 6
Training loss: 1.7877845764160156
Validation loss: 1.970052869089188

Epoch: 6| Step: 7
Training loss: 2.3704710006713867
Validation loss: 1.9524315608445035

Epoch: 6| Step: 8
Training loss: 2.0574264526367188
Validation loss: 1.9509292981957878

Epoch: 6| Step: 9
Training loss: 1.8819024562835693
Validation loss: 1.9424888792858328

Epoch: 6| Step: 10
Training loss: 2.186373710632324
Validation loss: 1.9649711731941468

Epoch: 6| Step: 11
Training loss: 2.98663330078125
Validation loss: 1.949320508587745

Epoch: 6| Step: 12
Training loss: 1.658210039138794
Validation loss: 1.9506496383297829

Epoch: 6| Step: 13
Training loss: 1.366564393043518
Validation loss: 1.9541773719172324

Epoch: 134| Step: 0
Training loss: 2.1661221981048584
Validation loss: 1.926320154179809

Epoch: 6| Step: 1
Training loss: 2.806319236755371
Validation loss: 1.9461055365941857

Epoch: 6| Step: 2
Training loss: 2.6322741508483887
Validation loss: 1.9641639365944812

Epoch: 6| Step: 3
Training loss: 1.2462273836135864
Validation loss: 1.9456474319581063

Epoch: 6| Step: 4
Training loss: 1.2803059816360474
Validation loss: 1.9684915914330432

Epoch: 6| Step: 5
Training loss: 1.7585978507995605
Validation loss: 1.9446977594847321

Epoch: 6| Step: 6
Training loss: 2.3712961673736572
Validation loss: 1.9404054995506042

Epoch: 6| Step: 7
Training loss: 2.7821006774902344
Validation loss: 1.9825475856822024

Epoch: 6| Step: 8
Training loss: 2.063605785369873
Validation loss: 1.9710097466745684

Epoch: 6| Step: 9
Training loss: 2.6325297355651855
Validation loss: 1.9479560672595937

Epoch: 6| Step: 10
Training loss: 1.5479300022125244
Validation loss: 1.950655544957807

Epoch: 6| Step: 11
Training loss: 1.7492023706436157
Validation loss: 1.9751376105893044

Epoch: 6| Step: 12
Training loss: 1.4052002429962158
Validation loss: 1.9507536170303181

Epoch: 6| Step: 13
Training loss: 1.9214608669281006
Validation loss: 1.9488844948430215

Epoch: 135| Step: 0
Training loss: 1.7613718509674072
Validation loss: 1.9715519002688828

Epoch: 6| Step: 1
Training loss: 2.761214017868042
Validation loss: 1.9372606021101757

Epoch: 6| Step: 2
Training loss: 1.6370365619659424
Validation loss: 1.9684964713229929

Epoch: 6| Step: 3
Training loss: 1.7021024227142334
Validation loss: 1.935407320658366

Epoch: 6| Step: 4
Training loss: 2.382240056991577
Validation loss: 1.954721761006181

Epoch: 6| Step: 5
Training loss: 2.0772767066955566
Validation loss: 1.9400797159441057

Epoch: 6| Step: 6
Training loss: 2.4157567024230957
Validation loss: 1.940745771572154

Epoch: 6| Step: 7
Training loss: 1.990992784500122
Validation loss: 1.9494657772843555

Epoch: 6| Step: 8
Training loss: 1.748029351234436
Validation loss: 1.9589286593980686

Epoch: 6| Step: 9
Training loss: 2.3713326454162598
Validation loss: 1.946974576160472

Epoch: 6| Step: 10
Training loss: 1.2625627517700195
Validation loss: 1.9611243535113592

Epoch: 6| Step: 11
Training loss: 2.042558431625366
Validation loss: 1.9481114469548708

Epoch: 6| Step: 12
Training loss: 2.1392440795898438
Validation loss: 1.9655819913392425

Epoch: 6| Step: 13
Training loss: 2.0322265625
Validation loss: 1.9485054503205002

Epoch: 136| Step: 0
Training loss: 1.92768132686615
Validation loss: 1.9514765726622714

Epoch: 6| Step: 1
Training loss: 2.069626569747925
Validation loss: 1.9478110113451559

Epoch: 6| Step: 2
Training loss: 1.4279487133026123
Validation loss: 1.96846999660615

Epoch: 6| Step: 3
Training loss: 2.2524871826171875
Validation loss: 1.958616768160174

Epoch: 6| Step: 4
Training loss: 1.594671607017517
Validation loss: 1.9764568395512079

Epoch: 6| Step: 5
Training loss: 2.720724105834961
Validation loss: 1.9647675111729612

Epoch: 6| Step: 6
Training loss: 2.1825013160705566
Validation loss: 1.9657887130655267

Epoch: 6| Step: 7
Training loss: 2.818425178527832
Validation loss: 1.9944389763698782

Epoch: 6| Step: 8
Training loss: 1.319532871246338
Validation loss: 1.9794547224557528

Epoch: 6| Step: 9
Training loss: 2.295289993286133
Validation loss: 1.947171002305964

Epoch: 6| Step: 10
Training loss: 2.5518035888671875
Validation loss: 1.9755519782343218

Epoch: 6| Step: 11
Training loss: 1.6136215925216675
Validation loss: 1.9634645985018822

Epoch: 6| Step: 12
Training loss: 2.009188652038574
Validation loss: 1.9635717304803992

Epoch: 6| Step: 13
Training loss: 1.1526565551757812
Validation loss: 1.9844442554699477

Epoch: 137| Step: 0
Training loss: 2.114818572998047
Validation loss: 1.9711831218452864

Epoch: 6| Step: 1
Training loss: 2.122286319732666
Validation loss: 1.9740430898563837

Epoch: 6| Step: 2
Training loss: 1.682692527770996
Validation loss: 1.9619942249790314

Epoch: 6| Step: 3
Training loss: 1.4874645471572876
Validation loss: 1.964943862730457

Epoch: 6| Step: 4
Training loss: 2.353513479232788
Validation loss: 1.9489374045402772

Epoch: 6| Step: 5
Training loss: 2.8615007400512695
Validation loss: 1.9572383998542704

Epoch: 6| Step: 6
Training loss: 2.2078495025634766
Validation loss: 1.9517723206550843

Epoch: 6| Step: 7
Training loss: 2.6310672760009766
Validation loss: 1.9588176665767547

Epoch: 6| Step: 8
Training loss: 1.9764153957366943
Validation loss: 1.9627605766378424

Epoch: 6| Step: 9
Training loss: 1.8896604776382446
Validation loss: 1.9517739152395597

Epoch: 6| Step: 10
Training loss: 1.463064432144165
Validation loss: 1.9504030763462026

Epoch: 6| Step: 11
Training loss: 1.6142401695251465
Validation loss: 1.9565544436054845

Epoch: 6| Step: 12
Training loss: 1.799782395362854
Validation loss: 1.9530394141392042

Epoch: 6| Step: 13
Training loss: 1.9686557054519653
Validation loss: 1.9556492682426208

Epoch: 138| Step: 0
Training loss: 1.6051691770553589
Validation loss: 1.9850637002657818

Epoch: 6| Step: 1
Training loss: 1.6096398830413818
Validation loss: 1.965957800547282

Epoch: 6| Step: 2
Training loss: 2.5959606170654297
Validation loss: 1.982603185920305

Epoch: 6| Step: 3
Training loss: 1.8803622722625732
Validation loss: 1.9638026311833372

Epoch: 6| Step: 4
Training loss: 2.0854902267456055
Validation loss: 1.9553550161341184

Epoch: 6| Step: 5
Training loss: 2.315889358520508
Validation loss: 1.9813006411316574

Epoch: 6| Step: 6
Training loss: 1.868587851524353
Validation loss: 1.981208559005491

Epoch: 6| Step: 7
Training loss: 2.542515277862549
Validation loss: 1.93125488937542

Epoch: 6| Step: 8
Training loss: 1.8694496154785156
Validation loss: 1.9627426696080033

Epoch: 6| Step: 9
Training loss: 2.255014657974243
Validation loss: 1.9663010912556802

Epoch: 6| Step: 10
Training loss: 1.7902486324310303
Validation loss: 1.9778722704097789

Epoch: 6| Step: 11
Training loss: 2.255781412124634
Validation loss: 1.9387380794812274

Epoch: 6| Step: 12
Training loss: 1.2765989303588867
Validation loss: 1.9659929711331603

Epoch: 6| Step: 13
Training loss: 2.6663992404937744
Validation loss: 1.9595598136225054

Epoch: 139| Step: 0
Training loss: 1.3326706886291504
Validation loss: 1.956345481257285

Epoch: 6| Step: 1
Training loss: 1.467617392539978
Validation loss: 1.9778822583536948

Epoch: 6| Step: 2
Training loss: 1.9901666641235352
Validation loss: 1.9656767588789745

Epoch: 6| Step: 3
Training loss: 2.345810890197754
Validation loss: 1.9630549671829387

Epoch: 6| Step: 4
Training loss: 2.3770570755004883
Validation loss: 1.961718911765724

Epoch: 6| Step: 5
Training loss: 1.5897538661956787
Validation loss: 1.984781567768384

Epoch: 6| Step: 6
Training loss: 2.6132452487945557
Validation loss: 1.959100543811757

Epoch: 6| Step: 7
Training loss: 2.1898717880249023
Validation loss: 1.9681677382479432

Epoch: 6| Step: 8
Training loss: 2.258087158203125
Validation loss: 1.9822060779858661

Epoch: 6| Step: 9
Training loss: 1.6502153873443604
Validation loss: 1.965616726106213

Epoch: 6| Step: 10
Training loss: 1.6102368831634521
Validation loss: 1.9563169428097305

Epoch: 6| Step: 11
Training loss: 1.9195232391357422
Validation loss: 1.9601018300620459

Epoch: 6| Step: 12
Training loss: 2.4647562503814697
Validation loss: 1.9713973845205

Epoch: 6| Step: 13
Training loss: 2.4541175365448
Validation loss: 1.941142161687215

Epoch: 140| Step: 0
Training loss: 1.8416502475738525
Validation loss: 1.9594534353543354

Epoch: 6| Step: 1
Training loss: 1.7559791803359985
Validation loss: 1.9563475116606681

Epoch: 6| Step: 2
Training loss: 2.6853156089782715
Validation loss: 1.9472387362551946

Epoch: 6| Step: 3
Training loss: 1.4179883003234863
Validation loss: 1.9338345527648926

Epoch: 6| Step: 4
Training loss: 2.221088409423828
Validation loss: 1.9472734235948133

Epoch: 6| Step: 5
Training loss: 2.0470662117004395
Validation loss: 1.9658461257975588

Epoch: 6| Step: 6
Training loss: 1.5454522371292114
Validation loss: 1.9597457583232591

Epoch: 6| Step: 7
Training loss: 1.7496665716171265
Validation loss: 1.9557716051737468

Epoch: 6| Step: 8
Training loss: 2.826775550842285
Validation loss: 1.9829213055231238

Epoch: 6| Step: 9
Training loss: 1.8338195085525513
Validation loss: 1.9605306181856381

Epoch: 6| Step: 10
Training loss: 2.229301691055298
Validation loss: 1.9756433886866416

Epoch: 6| Step: 11
Training loss: 1.4359208345413208
Validation loss: 1.9459235219545261

Epoch: 6| Step: 12
Training loss: 2.4748878479003906
Validation loss: 1.9622817770127328

Epoch: 6| Step: 13
Training loss: 2.1655383110046387
Validation loss: 1.9598996126523582

Epoch: 141| Step: 0
Training loss: 2.7494237422943115
Validation loss: 1.9496083413400958

Epoch: 6| Step: 1
Training loss: 1.7711288928985596
Validation loss: 1.9522739841092018

Epoch: 6| Step: 2
Training loss: 1.624955177307129
Validation loss: 1.9502918777927276

Epoch: 6| Step: 3
Training loss: 1.583571195602417
Validation loss: 1.9427645860179779

Epoch: 6| Step: 4
Training loss: 2.065476655960083
Validation loss: 1.965092174468502

Epoch: 6| Step: 5
Training loss: 2.4277727603912354
Validation loss: 1.9615439368832497

Epoch: 6| Step: 6
Training loss: 2.030217170715332
Validation loss: 1.929757018243113

Epoch: 6| Step: 7
Training loss: 1.5482521057128906
Validation loss: 1.960148576767214

Epoch: 6| Step: 8
Training loss: 2.3935952186584473
Validation loss: 1.9623221274345153

Epoch: 6| Step: 9
Training loss: 2.0925493240356445
Validation loss: 1.942775978836962

Epoch: 6| Step: 10
Training loss: 2.2097978591918945
Validation loss: 1.9592981082136913

Epoch: 6| Step: 11
Training loss: 1.6379008293151855
Validation loss: 1.9558426667285222

Epoch: 6| Step: 12
Training loss: 1.992222547531128
Validation loss: 1.9535952768018168

Epoch: 6| Step: 13
Training loss: 2.299826145172119
Validation loss: 1.972631622386235

Epoch: 142| Step: 0
Training loss: 1.6548771858215332
Validation loss: 1.9616864945298882

Epoch: 6| Step: 1
Training loss: 1.684725284576416
Validation loss: 1.9698501658696

Epoch: 6| Step: 2
Training loss: 2.3622872829437256
Validation loss: 1.9491705458651307

Epoch: 6| Step: 3
Training loss: 2.1025896072387695
Validation loss: 1.9547331192160164

Epoch: 6| Step: 4
Training loss: 2.7374281883239746
Validation loss: 1.955492546481471

Epoch: 6| Step: 5
Training loss: 1.5482561588287354
Validation loss: 1.9598084316458753

Epoch: 6| Step: 6
Training loss: 2.054323673248291
Validation loss: 1.9555153641649472

Epoch: 6| Step: 7
Training loss: 1.5425610542297363
Validation loss: 1.9577565270085489

Epoch: 6| Step: 8
Training loss: 2.0185487270355225
Validation loss: 1.9807084029720676

Epoch: 6| Step: 9
Training loss: 1.6473698616027832
Validation loss: 1.963180531737625

Epoch: 6| Step: 10
Training loss: 2.400196075439453
Validation loss: 1.9728936585046912

Epoch: 6| Step: 11
Training loss: 1.4673525094985962
Validation loss: 1.9579278551122195

Epoch: 6| Step: 12
Training loss: 2.934591770172119
Validation loss: 1.9435615283186718

Epoch: 6| Step: 13
Training loss: 1.4006292819976807
Validation loss: 1.9373291128425187

Epoch: 143| Step: 0
Training loss: 2.2201786041259766
Validation loss: 1.950488075133293

Epoch: 6| Step: 1
Training loss: 2.7005562782287598
Validation loss: 1.9372569694313952

Epoch: 6| Step: 2
Training loss: 1.7242207527160645
Validation loss: 1.9771792042639948

Epoch: 6| Step: 3
Training loss: 2.501028060913086
Validation loss: 1.964876300545149

Epoch: 6| Step: 4
Training loss: 1.8947267532348633
Validation loss: 1.9628728820431618

Epoch: 6| Step: 5
Training loss: 1.358760118484497
Validation loss: 1.9670796907076271

Epoch: 6| Step: 6
Training loss: 1.5319586992263794
Validation loss: 1.9449394851602533

Epoch: 6| Step: 7
Training loss: 2.364189863204956
Validation loss: 1.9541818288064772

Epoch: 6| Step: 8
Training loss: 1.081632137298584
Validation loss: 1.9579820184297458

Epoch: 6| Step: 9
Training loss: 1.3735363483428955
Validation loss: 1.9571180010354647

Epoch: 6| Step: 10
Training loss: 1.992560625076294
Validation loss: 1.9661472664084485

Epoch: 6| Step: 11
Training loss: 2.193992853164673
Validation loss: 1.9404473330384941

Epoch: 6| Step: 12
Training loss: 2.785658597946167
Validation loss: 1.9722454483791063

Epoch: 6| Step: 13
Training loss: 2.432173252105713
Validation loss: 1.9871320288668397

Epoch: 144| Step: 0
Training loss: 2.0585532188415527
Validation loss: 1.9475471076144968

Epoch: 6| Step: 1
Training loss: 1.7067599296569824
Validation loss: 1.9448050709180935

Epoch: 6| Step: 2
Training loss: 1.9448472261428833
Validation loss: 1.9594699426363873

Epoch: 6| Step: 3
Training loss: 2.553051471710205
Validation loss: 1.942882965969783

Epoch: 6| Step: 4
Training loss: 2.539475917816162
Validation loss: 1.9627322202087731

Epoch: 6| Step: 5
Training loss: 1.8939040899276733
Validation loss: 1.9381348292032878

Epoch: 6| Step: 6
Training loss: 2.48490571975708
Validation loss: 1.9337212847125145

Epoch: 6| Step: 7
Training loss: 1.783552885055542
Validation loss: 1.9516254496830765

Epoch: 6| Step: 8
Training loss: 1.7039711475372314
Validation loss: 1.9519755558301044

Epoch: 6| Step: 9
Training loss: 2.7059617042541504
Validation loss: 1.9808631199662403

Epoch: 6| Step: 10
Training loss: 1.617584228515625
Validation loss: 1.9591481378001552

Epoch: 6| Step: 11
Training loss: 1.6949454545974731
Validation loss: 1.9491714021211028

Epoch: 6| Step: 12
Training loss: 1.5506840944290161
Validation loss: 1.9395736827645251

Epoch: 6| Step: 13
Training loss: 1.7482962608337402
Validation loss: 1.9549122664236254

Epoch: 145| Step: 0
Training loss: 1.9922114610671997
Validation loss: 1.9856934009059783

Epoch: 6| Step: 1
Training loss: 2.2922468185424805
Validation loss: 1.9636931034826464

Epoch: 6| Step: 2
Training loss: 1.4274680614471436
Validation loss: 1.9703328045465613

Epoch: 6| Step: 3
Training loss: 2.0546140670776367
Validation loss: 1.936576513833897

Epoch: 6| Step: 4
Training loss: 2.068695306777954
Validation loss: 1.9858808991729573

Epoch: 6| Step: 5
Training loss: 2.7678089141845703
Validation loss: 1.9646141464992235

Epoch: 6| Step: 6
Training loss: 1.5459295511245728
Validation loss: 1.9657048127984489

Epoch: 6| Step: 7
Training loss: 2.1379811763763428
Validation loss: 1.9913802608366935

Epoch: 6| Step: 8
Training loss: 2.085602283477783
Validation loss: 1.9634700039381623

Epoch: 6| Step: 9
Training loss: 1.629815697669983
Validation loss: 1.9874673517801429

Epoch: 6| Step: 10
Training loss: 2.2632269859313965
Validation loss: 1.9575785847120388

Epoch: 6| Step: 11
Training loss: 2.148473024368286
Validation loss: 1.9690414295401624

Epoch: 6| Step: 12
Training loss: 2.0223729610443115
Validation loss: 1.9403005902485182

Epoch: 6| Step: 13
Training loss: 1.0573369264602661
Validation loss: 1.9763562525472333

Epoch: 146| Step: 0
Training loss: 1.48919677734375
Validation loss: 1.9557845669407998

Epoch: 6| Step: 1
Training loss: 2.4176511764526367
Validation loss: 1.9598476015111452

Epoch: 6| Step: 2
Training loss: 1.9909908771514893
Validation loss: 1.9973928082373835

Epoch: 6| Step: 3
Training loss: 2.0873703956604004
Validation loss: 1.944158810441212

Epoch: 6| Step: 4
Training loss: 2.1111412048339844
Validation loss: 1.9669797035955614

Epoch: 6| Step: 5
Training loss: 2.122011661529541
Validation loss: 1.9484184019027218

Epoch: 6| Step: 6
Training loss: 2.0205018520355225
Validation loss: 1.9623338676268054

Epoch: 6| Step: 7
Training loss: 1.0283392667770386
Validation loss: 1.9403976676284627

Epoch: 6| Step: 8
Training loss: 2.1721012592315674
Validation loss: 1.9256730848743069

Epoch: 6| Step: 9
Training loss: 2.1894571781158447
Validation loss: 1.9440351506715179

Epoch: 6| Step: 10
Training loss: 1.5526621341705322
Validation loss: 1.9495175730797552

Epoch: 6| Step: 11
Training loss: 2.5027594566345215
Validation loss: 1.9405917890610234

Epoch: 6| Step: 12
Training loss: 2.0604658126831055
Validation loss: 1.941694700589744

Epoch: 6| Step: 13
Training loss: 2.5112693309783936
Validation loss: 1.9619778074244016

Epoch: 147| Step: 0
Training loss: 2.165894031524658
Validation loss: 1.957482381533551

Epoch: 6| Step: 1
Training loss: 1.919364094734192
Validation loss: 1.9392846579192786

Epoch: 6| Step: 2
Training loss: 2.3253884315490723
Validation loss: 1.969185729180613

Epoch: 6| Step: 3
Training loss: 2.725358486175537
Validation loss: 1.936715989984492

Epoch: 6| Step: 4
Training loss: 1.7063887119293213
Validation loss: 1.9463652872270154

Epoch: 6| Step: 5
Training loss: 1.8886942863464355
Validation loss: 1.9389603894243959

Epoch: 6| Step: 6
Training loss: 1.7059061527252197
Validation loss: 1.950786870013001

Epoch: 6| Step: 7
Training loss: 2.493725299835205
Validation loss: 1.9578689618777203

Epoch: 6| Step: 8
Training loss: 1.367785930633545
Validation loss: 1.9469566601578907

Epoch: 6| Step: 9
Training loss: 1.7438199520111084
Validation loss: 1.984102194027234

Epoch: 6| Step: 10
Training loss: 2.4248781204223633
Validation loss: 1.9673651444014681

Epoch: 6| Step: 11
Training loss: 1.5214303731918335
Validation loss: 1.9829486993051344

Epoch: 6| Step: 12
Training loss: 2.2374656200408936
Validation loss: 1.9551569466949792

Epoch: 6| Step: 13
Training loss: 1.1671339273452759
Validation loss: 1.9582919561734764

Epoch: 148| Step: 0
Training loss: 1.7287758588790894
Validation loss: 1.9423147042592366

Epoch: 6| Step: 1
Training loss: 1.7308262586593628
Validation loss: 1.9555582051636071

Epoch: 6| Step: 2
Training loss: 2.2176432609558105
Validation loss: 1.9665804857848792

Epoch: 6| Step: 3
Training loss: 2.0715861320495605
Validation loss: 1.9800256836798884

Epoch: 6| Step: 4
Training loss: 2.2106564044952393
Validation loss: 1.9789078248444425

Epoch: 6| Step: 5
Training loss: 1.6178812980651855
Validation loss: 1.9562183144272014

Epoch: 6| Step: 6
Training loss: 2.3266124725341797
Validation loss: 1.9579957044252785

Epoch: 6| Step: 7
Training loss: 1.7381541728973389
Validation loss: 1.9498908404381043

Epoch: 6| Step: 8
Training loss: 2.0983939170837402
Validation loss: 1.9744103929047943

Epoch: 6| Step: 9
Training loss: 2.4771432876586914
Validation loss: 1.973877699144425

Epoch: 6| Step: 10
Training loss: 1.577673077583313
Validation loss: 1.9755653642839002

Epoch: 6| Step: 11
Training loss: 1.9478784799575806
Validation loss: 1.9311694739967264

Epoch: 6| Step: 12
Training loss: 1.5658831596374512
Validation loss: 1.9761315148363832

Epoch: 6| Step: 13
Training loss: 2.717599391937256
Validation loss: 1.962443499154942

Epoch: 149| Step: 0
Training loss: 1.9501760005950928
Validation loss: 1.95749992580824

Epoch: 6| Step: 1
Training loss: 1.6685503721237183
Validation loss: 1.9394439804938532

Epoch: 6| Step: 2
Training loss: 2.002562999725342
Validation loss: 1.9586009005064606

Epoch: 6| Step: 3
Training loss: 1.7347301244735718
Validation loss: 1.9720371461683703

Epoch: 6| Step: 4
Training loss: 1.485174298286438
Validation loss: 1.9686584254746795

Epoch: 6| Step: 5
Training loss: 2.290672779083252
Validation loss: 1.9498985736600813

Epoch: 6| Step: 6
Training loss: 2.3053395748138428
Validation loss: 1.943184744927191

Epoch: 6| Step: 7
Training loss: 1.7271897792816162
Validation loss: 1.9662181408174577

Epoch: 6| Step: 8
Training loss: 2.0063815116882324
Validation loss: 1.948042691394847

Epoch: 6| Step: 9
Training loss: 1.6703039407730103
Validation loss: 1.9693311798957087

Epoch: 6| Step: 10
Training loss: 1.8685319423675537
Validation loss: 1.9292573800650976

Epoch: 6| Step: 11
Training loss: 1.955338478088379
Validation loss: 1.9310462679914249

Epoch: 6| Step: 12
Training loss: 2.653897762298584
Validation loss: 1.9359947904463737

Epoch: 6| Step: 13
Training loss: 3.032355785369873
Validation loss: 1.9236094720901982

Epoch: 150| Step: 0
Training loss: 1.7391183376312256
Validation loss: 1.9662313089575818

Epoch: 6| Step: 1
Training loss: 2.8602428436279297
Validation loss: 1.9453990651715187

Epoch: 6| Step: 2
Training loss: 1.712646245956421
Validation loss: 1.9439881129931378

Epoch: 6| Step: 3
Training loss: 1.7715067863464355
Validation loss: 1.95322677909687

Epoch: 6| Step: 4
Training loss: 2.5145177841186523
Validation loss: 1.9370212567749845

Epoch: 6| Step: 5
Training loss: 2.1483569145202637
Validation loss: 1.973297740823479

Epoch: 6| Step: 6
Training loss: 2.169536590576172
Validation loss: 1.9607506541795627

Epoch: 6| Step: 7
Training loss: 1.6204471588134766
Validation loss: 1.9704268927215247

Epoch: 6| Step: 8
Training loss: 1.6677480936050415
Validation loss: 1.9820482397592196

Epoch: 6| Step: 9
Training loss: 1.8435397148132324
Validation loss: 1.9609709375648088

Epoch: 6| Step: 10
Training loss: 2.0117552280426025
Validation loss: 1.9804097631926179

Epoch: 6| Step: 11
Training loss: 1.9159247875213623
Validation loss: 1.9618319824177732

Epoch: 6| Step: 12
Training loss: 2.1053595542907715
Validation loss: 1.976757582797799

Epoch: 6| Step: 13
Training loss: 1.3975530862808228
Validation loss: 2.018540790004115

Epoch: 151| Step: 0
Training loss: 1.9653778076171875
Validation loss: 1.9487562769202775

Epoch: 6| Step: 1
Training loss: 1.643660068511963
Validation loss: 1.9637476821099558

Epoch: 6| Step: 2
Training loss: 2.0844082832336426
Validation loss: 1.9632460173740183

Epoch: 6| Step: 3
Training loss: 2.9660916328430176
Validation loss: 1.9932363340931554

Epoch: 6| Step: 4
Training loss: 2.2582297325134277
Validation loss: 1.9561898939071163

Epoch: 6| Step: 5
Training loss: 1.6116843223571777
Validation loss: 1.9549790377257972

Epoch: 6| Step: 6
Training loss: 1.8700230121612549
Validation loss: 1.9697351878689182

Epoch: 6| Step: 7
Training loss: 2.050262928009033
Validation loss: 1.9673002381478586

Epoch: 6| Step: 8
Training loss: 1.8561264276504517
Validation loss: 1.9468278654160038

Epoch: 6| Step: 9
Training loss: 1.3221858739852905
Validation loss: 1.9485234124686128

Epoch: 6| Step: 10
Training loss: 1.9606540203094482
Validation loss: 1.9502110968353927

Epoch: 6| Step: 11
Training loss: 2.215615749359131
Validation loss: 1.9471778818356094

Epoch: 6| Step: 12
Training loss: 2.090430498123169
Validation loss: 1.9593783194018948

Epoch: 6| Step: 13
Training loss: 1.1740422248840332
Validation loss: 1.9426141426127443

Epoch: 152| Step: 0
Training loss: 1.9953192472457886
Validation loss: 1.9752351942882742

Epoch: 6| Step: 1
Training loss: 1.9220750331878662
Validation loss: 1.9615479912809146

Epoch: 6| Step: 2
Training loss: 1.795336365699768
Validation loss: 1.9530595528182162

Epoch: 6| Step: 3
Training loss: 2.2857415676116943
Validation loss: 1.9587944412744174

Epoch: 6| Step: 4
Training loss: 2.0962719917297363
Validation loss: 1.9640273663305468

Epoch: 6| Step: 5
Training loss: 1.9387965202331543
Validation loss: 1.9410230087977585

Epoch: 6| Step: 6
Training loss: 1.7523260116577148
Validation loss: 1.9647190596467705

Epoch: 6| Step: 7
Training loss: 1.7976155281066895
Validation loss: 1.9347501288178146

Epoch: 6| Step: 8
Training loss: 1.6980358362197876
Validation loss: 1.9505506612921273

Epoch: 6| Step: 9
Training loss: 2.5272440910339355
Validation loss: 1.9382191152982815

Epoch: 6| Step: 10
Training loss: 1.9961282014846802
Validation loss: 1.9268569946289062

Epoch: 6| Step: 11
Training loss: 1.6101422309875488
Validation loss: 1.9727298098225747

Epoch: 6| Step: 12
Training loss: 2.0843071937561035
Validation loss: 1.954220861516973

Epoch: 6| Step: 13
Training loss: 1.9313087463378906
Validation loss: 1.962307257037009

Epoch: 153| Step: 0
Training loss: 2.518256664276123
Validation loss: 1.951334232925087

Epoch: 6| Step: 1
Training loss: 2.598163604736328
Validation loss: 1.9520872997981247

Epoch: 6| Step: 2
Training loss: 1.5661287307739258
Validation loss: 1.949453068035905

Epoch: 6| Step: 3
Training loss: 2.097768783569336
Validation loss: 1.9473226942041868

Epoch: 6| Step: 4
Training loss: 1.4520444869995117
Validation loss: 1.9900922634268319

Epoch: 6| Step: 5
Training loss: 1.771875262260437
Validation loss: 1.9434195692821215

Epoch: 6| Step: 6
Training loss: 1.8154352903366089
Validation loss: 1.9526290483372186

Epoch: 6| Step: 7
Training loss: 2.0624303817749023
Validation loss: 1.9400757051283313

Epoch: 6| Step: 8
Training loss: 1.8047845363616943
Validation loss: 1.9740635784723426

Epoch: 6| Step: 9
Training loss: 2.101707935333252
Validation loss: 1.9518619301498576

Epoch: 6| Step: 10
Training loss: 2.1106820106506348
Validation loss: 1.9576778822047736

Epoch: 6| Step: 11
Training loss: 2.2344822883605957
Validation loss: 1.9600384543018956

Epoch: 6| Step: 12
Training loss: 1.633361577987671
Validation loss: 1.9717016861002932

Epoch: 6| Step: 13
Training loss: 2.0995399951934814
Validation loss: 1.958747826596742

Epoch: 154| Step: 0
Training loss: 2.116797924041748
Validation loss: 1.9583107886775848

Epoch: 6| Step: 1
Training loss: 2.561814308166504
Validation loss: 1.9599240672203802

Epoch: 6| Step: 2
Training loss: 1.590024471282959
Validation loss: 1.9613770643870037

Epoch: 6| Step: 3
Training loss: 1.9906610250473022
Validation loss: 1.9590354427214591

Epoch: 6| Step: 4
Training loss: 2.312932014465332
Validation loss: 1.943078907587195

Epoch: 6| Step: 5
Training loss: 2.144707441329956
Validation loss: 1.9493724005196684

Epoch: 6| Step: 6
Training loss: 1.9020142555236816
Validation loss: 1.93747337531018

Epoch: 6| Step: 7
Training loss: 1.8773568868637085
Validation loss: 1.9366767855100735

Epoch: 6| Step: 8
Training loss: 2.354651927947998
Validation loss: 1.929137522174466

Epoch: 6| Step: 9
Training loss: 2.2319648265838623
Validation loss: 1.9287923023264895

Epoch: 6| Step: 10
Training loss: 2.0606420040130615
Validation loss: 1.9681284966007355

Epoch: 6| Step: 11
Training loss: 1.7034456729888916
Validation loss: 1.9938453269261185

Epoch: 6| Step: 12
Training loss: 1.214530110359192
Validation loss: 1.9503939843946887

Epoch: 6| Step: 13
Training loss: 1.3225865364074707
Validation loss: 1.9564620499969811

Epoch: 155| Step: 0
Training loss: 1.6175661087036133
Validation loss: 1.9560772270284674

Epoch: 6| Step: 1
Training loss: 2.3975839614868164
Validation loss: 1.977597446851833

Epoch: 6| Step: 2
Training loss: 2.2409257888793945
Validation loss: 1.9778542210978847

Epoch: 6| Step: 3
Training loss: 1.5249028205871582
Validation loss: 1.968178637566105

Epoch: 6| Step: 4
Training loss: 1.8887276649475098
Validation loss: 1.980253582359642

Epoch: 6| Step: 5
Training loss: 2.158444404602051
Validation loss: 1.9639844240680817

Epoch: 6| Step: 6
Training loss: 1.0355325937271118
Validation loss: 2.0023274331964473

Epoch: 6| Step: 7
Training loss: 2.8885762691497803
Validation loss: 1.9782684644063313

Epoch: 6| Step: 8
Training loss: 2.0835750102996826
Validation loss: 1.9954221351172334

Epoch: 6| Step: 9
Training loss: 1.4735074043273926
Validation loss: 1.9626355812113772

Epoch: 6| Step: 10
Training loss: 2.3154048919677734
Validation loss: 1.962087997826197

Epoch: 6| Step: 11
Training loss: 1.7858797311782837
Validation loss: 1.9671882378157748

Epoch: 6| Step: 12
Training loss: 1.8263126611709595
Validation loss: 1.9703539020271712

Epoch: 6| Step: 13
Training loss: 3.1012468338012695
Validation loss: 1.968827300174262

Epoch: 156| Step: 0
Training loss: 1.9642448425292969
Validation loss: 1.9617690681129374

Epoch: 6| Step: 1
Training loss: 1.9646879434585571
Validation loss: 1.9464502155139882

Epoch: 6| Step: 2
Training loss: 2.248680591583252
Validation loss: 1.9502405569117556

Epoch: 6| Step: 3
Training loss: 2.220282554626465
Validation loss: 1.9641397665905695

Epoch: 6| Step: 4
Training loss: 1.9490538835525513
Validation loss: 1.9554007514830558

Epoch: 6| Step: 5
Training loss: 1.6484192609786987
Validation loss: 1.9493119152643348

Epoch: 6| Step: 6
Training loss: 2.299469470977783
Validation loss: 1.9626950474195584

Epoch: 6| Step: 7
Training loss: 1.4797062873840332
Validation loss: 1.9634897837074854

Epoch: 6| Step: 8
Training loss: 1.789992332458496
Validation loss: 1.9626729975464523

Epoch: 6| Step: 9
Training loss: 1.5109407901763916
Validation loss: 1.9386279454795263

Epoch: 6| Step: 10
Training loss: 2.7937915325164795
Validation loss: 1.943419974337342

Epoch: 6| Step: 11
Training loss: 1.510852336883545
Validation loss: 1.9263522394241825

Epoch: 6| Step: 12
Training loss: 2.0525639057159424
Validation loss: 1.951215059526505

Epoch: 6| Step: 13
Training loss: 1.9899194240570068
Validation loss: 1.9504442394420665

Epoch: 157| Step: 0
Training loss: 2.004998207092285
Validation loss: 1.947589994758688

Epoch: 6| Step: 1
Training loss: 1.6880576610565186
Validation loss: 1.9182437286582044

Epoch: 6| Step: 2
Training loss: 1.9294227361679077
Validation loss: 1.90955069885459

Epoch: 6| Step: 3
Training loss: 1.8187305927276611
Validation loss: 1.9573237280691824

Epoch: 6| Step: 4
Training loss: 1.5789151191711426
Validation loss: 1.9555217399392077

Epoch: 6| Step: 5
Training loss: 1.110412836074829
Validation loss: 1.955947228657302

Epoch: 6| Step: 6
Training loss: 2.6438827514648438
Validation loss: 1.96110277534813

Epoch: 6| Step: 7
Training loss: 1.6671438217163086
Validation loss: 1.9268616835276287

Epoch: 6| Step: 8
Training loss: 2.5225884914398193
Validation loss: 1.9453496881710586

Epoch: 6| Step: 9
Training loss: 2.3180689811706543
Validation loss: 1.9503209590911865

Epoch: 6| Step: 10
Training loss: 1.9265689849853516
Validation loss: 1.9355314752107025

Epoch: 6| Step: 11
Training loss: 2.205678939819336
Validation loss: 1.9345901576421594

Epoch: 6| Step: 12
Training loss: 2.432300090789795
Validation loss: 1.9199065598108436

Epoch: 6| Step: 13
Training loss: 1.796109914779663
Validation loss: 1.9601931482233026

Epoch: 158| Step: 0
Training loss: 1.3897054195404053
Validation loss: 1.9585855750627414

Epoch: 6| Step: 1
Training loss: 1.5426037311553955
Validation loss: 1.9316137952189292

Epoch: 6| Step: 2
Training loss: 2.2322041988372803
Validation loss: 1.9467903478171236

Epoch: 6| Step: 3
Training loss: 2.343656063079834
Validation loss: 1.9587947207112466

Epoch: 6| Step: 4
Training loss: 1.7519936561584473
Validation loss: 1.9547328769519765

Epoch: 6| Step: 5
Training loss: 1.4347970485687256
Validation loss: 1.9101891504820956

Epoch: 6| Step: 6
Training loss: 1.7424468994140625
Validation loss: 1.9545396092117473

Epoch: 6| Step: 7
Training loss: 1.9163503646850586
Validation loss: 1.9635236173547723

Epoch: 6| Step: 8
Training loss: 1.778630256652832
Validation loss: 1.958301523680328

Epoch: 6| Step: 9
Training loss: 1.720409870147705
Validation loss: 1.9564995816958848

Epoch: 6| Step: 10
Training loss: 2.419154167175293
Validation loss: 1.9400250757894208

Epoch: 6| Step: 11
Training loss: 2.694489002227783
Validation loss: 1.9601700011120047

Epoch: 6| Step: 12
Training loss: 2.2794055938720703
Validation loss: 1.9471634562297533

Epoch: 6| Step: 13
Training loss: 2.298295021057129
Validation loss: 1.9754146786146267

Epoch: 159| Step: 0
Training loss: 1.9443144798278809
Validation loss: 1.9673408449337046

Epoch: 6| Step: 1
Training loss: 1.6040781736373901
Validation loss: 1.964139590981186

Epoch: 6| Step: 2
Training loss: 2.2198214530944824
Validation loss: 1.9467724228418002

Epoch: 6| Step: 3
Training loss: 1.763350486755371
Validation loss: 1.9446761685032998

Epoch: 6| Step: 4
Training loss: 1.806067705154419
Validation loss: 1.9319917130213913

Epoch: 6| Step: 5
Training loss: 2.1030449867248535
Validation loss: 1.9144377016252088

Epoch: 6| Step: 6
Training loss: 2.152338981628418
Validation loss: 1.9547140393205868

Epoch: 6| Step: 7
Training loss: 1.9765708446502686
Validation loss: 1.9330877745023338

Epoch: 6| Step: 8
Training loss: 1.9145959615707397
Validation loss: 1.964865630672824

Epoch: 6| Step: 9
Training loss: 1.9974071979522705
Validation loss: 1.9376821953763244

Epoch: 6| Step: 10
Training loss: 1.488555908203125
Validation loss: 1.9413289203438708

Epoch: 6| Step: 11
Training loss: 1.8070796728134155
Validation loss: 1.984977993913876

Epoch: 6| Step: 12
Training loss: 1.7218010425567627
Validation loss: 1.934784734120933

Epoch: 6| Step: 13
Training loss: 3.2882509231567383
Validation loss: 1.9402104308528285

Epoch: 160| Step: 0
Training loss: 2.293027877807617
Validation loss: 1.9429202669410295

Epoch: 6| Step: 1
Training loss: 0.8096606731414795
Validation loss: 1.9331859414295485

Epoch: 6| Step: 2
Training loss: 2.386134147644043
Validation loss: 1.9438302683573898

Epoch: 6| Step: 3
Training loss: 1.2903492450714111
Validation loss: 1.9389433142959431

Epoch: 6| Step: 4
Training loss: 2.2050442695617676
Validation loss: 1.9280168907616728

Epoch: 6| Step: 5
Training loss: 1.655566692352295
Validation loss: 1.9502533860104059

Epoch: 6| Step: 6
Training loss: 1.94297194480896
Validation loss: 1.9516854363103067

Epoch: 6| Step: 7
Training loss: 2.320204734802246
Validation loss: 1.9699581259040422

Epoch: 6| Step: 8
Training loss: 2.48933482170105
Validation loss: 1.9686710520457196

Epoch: 6| Step: 9
Training loss: 2.220392942428589
Validation loss: 1.9874604876323412

Epoch: 6| Step: 10
Training loss: 1.6842734813690186
Validation loss: 1.9715419635977796

Epoch: 6| Step: 11
Training loss: 1.6824471950531006
Validation loss: 1.9445726820217666

Epoch: 6| Step: 12
Training loss: 2.2528131008148193
Validation loss: 1.9554318535712458

Epoch: 6| Step: 13
Training loss: 2.2237064838409424
Validation loss: 1.9496416507228729

Epoch: 161| Step: 0
Training loss: 1.5672070980072021
Validation loss: 1.9545669606936875

Epoch: 6| Step: 1
Training loss: 1.9588993787765503
Validation loss: 1.9399802569420106

Epoch: 6| Step: 2
Training loss: 2.1934804916381836
Validation loss: 1.9534963523187945

Epoch: 6| Step: 3
Training loss: 1.9400222301483154
Validation loss: 1.9386895625822005

Epoch: 6| Step: 4
Training loss: 2.148627996444702
Validation loss: 1.9712227518840502

Epoch: 6| Step: 5
Training loss: 1.400559902191162
Validation loss: 1.9499552262726652

Epoch: 6| Step: 6
Training loss: 2.5642952919006348
Validation loss: 1.9609437065739785

Epoch: 6| Step: 7
Training loss: 1.2853235006332397
Validation loss: 1.9626399150458715

Epoch: 6| Step: 8
Training loss: 1.8496849536895752
Validation loss: 1.9492980844231063

Epoch: 6| Step: 9
Training loss: 2.186840534210205
Validation loss: 1.9609192391877532

Epoch: 6| Step: 10
Training loss: 1.7339690923690796
Validation loss: 1.9479593179559196

Epoch: 6| Step: 11
Training loss: 2.116520404815674
Validation loss: 1.9385358928352274

Epoch: 6| Step: 12
Training loss: 2.035703182220459
Validation loss: 1.9312015323228733

Epoch: 6| Step: 13
Training loss: 2.5415682792663574
Validation loss: 1.9452784394705167

Epoch: 162| Step: 0
Training loss: 2.4273571968078613
Validation loss: 1.9442167051376835

Epoch: 6| Step: 1
Training loss: 2.238389730453491
Validation loss: 1.9584434916896205

Epoch: 6| Step: 2
Training loss: 1.861952304840088
Validation loss: 1.9380591800135951

Epoch: 6| Step: 3
Training loss: 2.1748759746551514
Validation loss: 1.9345079929597917

Epoch: 6| Step: 4
Training loss: 2.3650832176208496
Validation loss: 1.928320489903932

Epoch: 6| Step: 5
Training loss: 1.0884960889816284
Validation loss: 1.9586711583598968

Epoch: 6| Step: 6
Training loss: 1.779739499092102
Validation loss: 1.953198266285722

Epoch: 6| Step: 7
Training loss: 1.7940068244934082
Validation loss: 1.9461390613227763

Epoch: 6| Step: 8
Training loss: 3.072840690612793
Validation loss: 1.9069971115358415

Epoch: 6| Step: 9
Training loss: 2.0095109939575195
Validation loss: 1.939922595536837

Epoch: 6| Step: 10
Training loss: 1.7634952068328857
Validation loss: 1.938509229690798

Epoch: 6| Step: 11
Training loss: 1.258534550666809
Validation loss: 1.9410477043480001

Epoch: 6| Step: 12
Training loss: 1.632017731666565
Validation loss: 1.9252200690648889

Epoch: 6| Step: 13
Training loss: 1.6767069101333618
Validation loss: 1.9328195074553132

Epoch: 163| Step: 0
Training loss: 1.528116226196289
Validation loss: 1.947071575349377

Epoch: 6| Step: 1
Training loss: 1.4320800304412842
Validation loss: 1.9718561749304495

Epoch: 6| Step: 2
Training loss: 1.6043767929077148
Validation loss: 1.9369762584727297

Epoch: 6| Step: 3
Training loss: 2.828164577484131
Validation loss: 1.9472379005083473

Epoch: 6| Step: 4
Training loss: 2.323309898376465
Validation loss: 1.953280455322676

Epoch: 6| Step: 5
Training loss: 2.0645604133605957
Validation loss: 1.9213743132929648

Epoch: 6| Step: 6
Training loss: 2.144547700881958
Validation loss: 1.955641468365987

Epoch: 6| Step: 7
Training loss: 1.3135716915130615
Validation loss: 1.955568091843718

Epoch: 6| Step: 8
Training loss: 2.1023340225219727
Validation loss: 1.951267309086297

Epoch: 6| Step: 9
Training loss: 1.625705599784851
Validation loss: 1.9458542498209144

Epoch: 6| Step: 10
Training loss: 2.367043972015381
Validation loss: 1.9591122211948517

Epoch: 6| Step: 11
Training loss: 2.3341903686523438
Validation loss: 1.9428393802335184

Epoch: 6| Step: 12
Training loss: 1.94840669631958
Validation loss: 1.9407990568427629

Epoch: 6| Step: 13
Training loss: 1.4922966957092285
Validation loss: 1.9310783211902907

Epoch: 164| Step: 0
Training loss: 1.6448060274124146
Validation loss: 1.9542809212079613

Epoch: 6| Step: 1
Training loss: 1.9589900970458984
Validation loss: 1.9273369543014034

Epoch: 6| Step: 2
Training loss: 1.9880924224853516
Validation loss: 1.9620494663074453

Epoch: 6| Step: 3
Training loss: 2.1467387676239014
Validation loss: 1.9377788766737907

Epoch: 6| Step: 4
Training loss: 1.8220702409744263
Validation loss: 1.9472331641822733

Epoch: 6| Step: 5
Training loss: 1.04067862033844
Validation loss: 1.9559604698611843

Epoch: 6| Step: 6
Training loss: 2.0124473571777344
Validation loss: 1.960943014391007

Epoch: 6| Step: 7
Training loss: 2.303619861602783
Validation loss: 1.9553715272616314

Epoch: 6| Step: 8
Training loss: 1.785085916519165
Validation loss: 1.953259846215607

Epoch: 6| Step: 9
Training loss: 2.203523635864258
Validation loss: 1.9496181523928078

Epoch: 6| Step: 10
Training loss: 2.0624608993530273
Validation loss: 1.9536142323606758

Epoch: 6| Step: 11
Training loss: 2.2590322494506836
Validation loss: 1.9411684390037292

Epoch: 6| Step: 12
Training loss: 2.4401283264160156
Validation loss: 1.9388347082240607

Epoch: 6| Step: 13
Training loss: 1.3001782894134521
Validation loss: 1.941291214317404

Epoch: 165| Step: 0
Training loss: 1.8267648220062256
Validation loss: 1.9525238544710222

Epoch: 6| Step: 1
Training loss: 2.4804959297180176
Validation loss: 1.952066316399523

Epoch: 6| Step: 2
Training loss: 1.8214925527572632
Validation loss: 1.9436486639002317

Epoch: 6| Step: 3
Training loss: 2.136957883834839
Validation loss: 1.912706821195541

Epoch: 6| Step: 4
Training loss: 1.7914619445800781
Validation loss: 1.9299161485446397

Epoch: 6| Step: 5
Training loss: 1.59799063205719
Validation loss: 1.9508127448379353

Epoch: 6| Step: 6
Training loss: 1.908229112625122
Validation loss: 1.9361680912715133

Epoch: 6| Step: 7
Training loss: 1.6226534843444824
Validation loss: 1.9233345934139785

Epoch: 6| Step: 8
Training loss: 2.602034568786621
Validation loss: 1.979268240672286

Epoch: 6| Step: 9
Training loss: 1.6044459342956543
Validation loss: 1.9152791820546633

Epoch: 6| Step: 10
Training loss: 1.4290777444839478
Validation loss: 1.9297820239938714

Epoch: 6| Step: 11
Training loss: 1.661634087562561
Validation loss: 1.9330517938060146

Epoch: 6| Step: 12
Training loss: 2.4184422492980957
Validation loss: 1.941672622516591

Epoch: 6| Step: 13
Training loss: 2.5534934997558594
Validation loss: 1.9414052706892773

Epoch: 166| Step: 0
Training loss: 2.548903465270996
Validation loss: 1.9356290422460085

Epoch: 6| Step: 1
Training loss: 2.47480845451355
Validation loss: 1.9632415938121017

Epoch: 6| Step: 2
Training loss: 1.1206810474395752
Validation loss: 1.9015954732894897

Epoch: 6| Step: 3
Training loss: 1.965868592262268
Validation loss: 1.9173708615764495

Epoch: 6| Step: 4
Training loss: 2.272040367126465
Validation loss: 1.9107008928893714

Epoch: 6| Step: 5
Training loss: 1.394081950187683
Validation loss: 1.9301298869553434

Epoch: 6| Step: 6
Training loss: 1.2038477659225464
Validation loss: 1.952907153355178

Epoch: 6| Step: 7
Training loss: 1.7629387378692627
Validation loss: 1.9229720613007903

Epoch: 6| Step: 8
Training loss: 1.7179381847381592
Validation loss: 1.9509786226416146

Epoch: 6| Step: 9
Training loss: 1.843611478805542
Validation loss: 1.9315604343209216

Epoch: 6| Step: 10
Training loss: 2.8820509910583496
Validation loss: 1.9515165180288336

Epoch: 6| Step: 11
Training loss: 1.619615077972412
Validation loss: 1.976945939884391

Epoch: 6| Step: 12
Training loss: 1.9884517192840576
Validation loss: 1.9203159078474967

Epoch: 6| Step: 13
Training loss: 2.7292888164520264
Validation loss: 1.9316251893197336

Epoch: 167| Step: 0
Training loss: 1.835519790649414
Validation loss: 1.9363547038006526

Epoch: 6| Step: 1
Training loss: 2.0070619583129883
Validation loss: 1.9444644040958856

Epoch: 6| Step: 2
Training loss: 2.2180087566375732
Validation loss: 1.9231799443562825

Epoch: 6| Step: 3
Training loss: 2.1428580284118652
Validation loss: 1.9249679747448172

Epoch: 6| Step: 4
Training loss: 2.2760186195373535
Validation loss: 1.9323588084149104

Epoch: 6| Step: 5
Training loss: 1.7593023777008057
Validation loss: 1.9567265087558376

Epoch: 6| Step: 6
Training loss: 1.9568274021148682
Validation loss: 1.9442810525176346

Epoch: 6| Step: 7
Training loss: 2.3132739067077637
Validation loss: 1.9476935068766277

Epoch: 6| Step: 8
Training loss: 2.155010938644409
Validation loss: 1.9533945514309792

Epoch: 6| Step: 9
Training loss: 1.5383057594299316
Validation loss: 1.9673483397371025

Epoch: 6| Step: 10
Training loss: 1.8945283889770508
Validation loss: 1.950591815415249

Epoch: 6| Step: 11
Training loss: 1.646926999092102
Validation loss: 1.9747074086179015

Epoch: 6| Step: 12
Training loss: 1.3071765899658203
Validation loss: 1.9869866883882912

Epoch: 6| Step: 13
Training loss: 2.5895261764526367
Validation loss: 1.9613001423497354

Epoch: 168| Step: 0
Training loss: 2.2802813053131104
Validation loss: 1.9370663653137863

Epoch: 6| Step: 1
Training loss: 2.3798556327819824
Validation loss: 1.9445745765521962

Epoch: 6| Step: 2
Training loss: 2.0833706855773926
Validation loss: 1.961209007488784

Epoch: 6| Step: 3
Training loss: 2.150745391845703
Validation loss: 1.9301203720031246

Epoch: 6| Step: 4
Training loss: 1.7621843814849854
Validation loss: 1.9495486751679452

Epoch: 6| Step: 5
Training loss: 1.8862311840057373
Validation loss: 1.937363047753611

Epoch: 6| Step: 6
Training loss: 2.0671143531799316
Validation loss: 1.9018018989152805

Epoch: 6| Step: 7
Training loss: 1.6505385637283325
Validation loss: 1.9292008979346162

Epoch: 6| Step: 8
Training loss: 1.9811021089553833
Validation loss: 1.9390178136928107

Epoch: 6| Step: 9
Training loss: 1.6693440675735474
Validation loss: 1.9460577887873496

Epoch: 6| Step: 10
Training loss: 1.9777318239212036
Validation loss: 1.93434444550545

Epoch: 6| Step: 11
Training loss: 1.4071179628372192
Validation loss: 1.939496745345413

Epoch: 6| Step: 12
Training loss: 2.319697380065918
Validation loss: 1.94783967028382

Epoch: 6| Step: 13
Training loss: 0.9872616529464722
Validation loss: 1.9353659101711806

Epoch: 169| Step: 0
Training loss: 1.5908498764038086
Validation loss: 1.9146019156261156

Epoch: 6| Step: 1
Training loss: 2.4474871158599854
Validation loss: 1.9150875665808236

Epoch: 6| Step: 2
Training loss: 1.6531245708465576
Validation loss: 1.9478340892381565

Epoch: 6| Step: 3
Training loss: 2.7384185791015625
Validation loss: 1.9393427192523915

Epoch: 6| Step: 4
Training loss: 1.4490489959716797
Validation loss: 1.9295099666041713

Epoch: 6| Step: 5
Training loss: 2.341732978820801
Validation loss: 1.9342729532590477

Epoch: 6| Step: 6
Training loss: 2.0631277561187744
Validation loss: 1.9290979280266711

Epoch: 6| Step: 7
Training loss: 1.8472594022750854
Validation loss: 1.934357132962955

Epoch: 6| Step: 8
Training loss: 2.023606777191162
Validation loss: 1.9528844100172802

Epoch: 6| Step: 9
Training loss: 1.6459776163101196
Validation loss: 1.9588377270647275

Epoch: 6| Step: 10
Training loss: 1.9242274761199951
Validation loss: 1.9133912670996882

Epoch: 6| Step: 11
Training loss: 1.6870386600494385
Validation loss: 1.9290499494921776

Epoch: 6| Step: 12
Training loss: 1.7933992147445679
Validation loss: 1.9513016080343595

Epoch: 6| Step: 13
Training loss: 1.639157772064209
Validation loss: 1.9663918018341064

Epoch: 170| Step: 0
Training loss: 1.7879126071929932
Validation loss: 1.9255364979467084

Epoch: 6| Step: 1
Training loss: 2.1485612392425537
Validation loss: 1.9071353712389547

Epoch: 6| Step: 2
Training loss: 2.211740732192993
Validation loss: 1.9355381381127141

Epoch: 6| Step: 3
Training loss: 2.1093757152557373
Validation loss: 1.9615045555176274

Epoch: 6| Step: 4
Training loss: 1.6504242420196533
Validation loss: 1.948762688585507

Epoch: 6| Step: 5
Training loss: 1.7499737739562988
Validation loss: 1.957143105486388

Epoch: 6| Step: 6
Training loss: 2.2494969367980957
Validation loss: 1.9649788154068815

Epoch: 6| Step: 7
Training loss: 2.9257121086120605
Validation loss: 1.9557373421166533

Epoch: 6| Step: 8
Training loss: 1.711906909942627
Validation loss: 1.938251426143031

Epoch: 6| Step: 9
Training loss: 1.7297801971435547
Validation loss: 1.9536420452979304

Epoch: 6| Step: 10
Training loss: 1.5968267917633057
Validation loss: 1.9571887575170046

Epoch: 6| Step: 11
Training loss: 1.3710683584213257
Validation loss: 1.9607088386371572

Epoch: 6| Step: 12
Training loss: 2.0169217586517334
Validation loss: 1.9307791468917683

Epoch: 6| Step: 13
Training loss: 1.5768160820007324
Validation loss: 1.95950537214997

Epoch: 171| Step: 0
Training loss: 2.04171085357666
Validation loss: 1.9503143436165267

Epoch: 6| Step: 1
Training loss: 2.0338172912597656
Validation loss: 1.919024593086653

Epoch: 6| Step: 2
Training loss: 1.8156163692474365
Validation loss: 1.9515399317587576

Epoch: 6| Step: 3
Training loss: 1.6597611904144287
Validation loss: 1.9389479788400794

Epoch: 6| Step: 4
Training loss: 1.9520275592803955
Validation loss: 1.9279919285928049

Epoch: 6| Step: 5
Training loss: 2.894624948501587
Validation loss: 1.933795314963146

Epoch: 6| Step: 6
Training loss: 2.175323963165283
Validation loss: 1.9357328299553163

Epoch: 6| Step: 7
Training loss: 1.8081986904144287
Validation loss: 1.9463269710540771

Epoch: 6| Step: 8
Training loss: 2.0562944412231445
Validation loss: 1.9266289818671443

Epoch: 6| Step: 9
Training loss: 1.1249175071716309
Validation loss: 1.925794005393982

Epoch: 6| Step: 10
Training loss: 1.8002102375030518
Validation loss: 1.9626589564866916

Epoch: 6| Step: 11
Training loss: 1.9761568307876587
Validation loss: 1.9193589533528974

Epoch: 6| Step: 12
Training loss: 1.7090595960617065
Validation loss: 1.9609148758713917

Epoch: 6| Step: 13
Training loss: 1.5654773712158203
Validation loss: 1.9150436078348467

Epoch: 172| Step: 0
Training loss: 2.020921230316162
Validation loss: 1.9463853938605196

Epoch: 6| Step: 1
Training loss: 2.1266355514526367
Validation loss: 1.9481957727862942

Epoch: 6| Step: 2
Training loss: 2.521084785461426
Validation loss: 1.943019010687387

Epoch: 6| Step: 3
Training loss: 1.557478666305542
Validation loss: 1.9157997920948973

Epoch: 6| Step: 4
Training loss: 1.4722119569778442
Validation loss: 1.928714830388305

Epoch: 6| Step: 5
Training loss: 1.4156596660614014
Validation loss: 1.925684534093385

Epoch: 6| Step: 6
Training loss: 1.4293627738952637
Validation loss: 1.9449921090115783

Epoch: 6| Step: 7
Training loss: 2.4139418601989746
Validation loss: 1.9546777240691646

Epoch: 6| Step: 8
Training loss: 1.9665921926498413
Validation loss: 1.9417482140243694

Epoch: 6| Step: 9
Training loss: 1.843928575515747
Validation loss: 1.955501312850624

Epoch: 6| Step: 10
Training loss: 1.9158152341842651
Validation loss: 1.9433723816307642

Epoch: 6| Step: 11
Training loss: 1.8750107288360596
Validation loss: 1.9843802836633497

Epoch: 6| Step: 12
Training loss: 2.3435750007629395
Validation loss: 1.9471109246694913

Epoch: 6| Step: 13
Training loss: 1.78748619556427
Validation loss: 1.9264534493928314

Epoch: 173| Step: 0
Training loss: 2.376729726791382
Validation loss: 1.9405068005284956

Epoch: 6| Step: 1
Training loss: 2.336660385131836
Validation loss: 1.9502788205300607

Epoch: 6| Step: 2
Training loss: 2.000445604324341
Validation loss: 1.9338434127069288

Epoch: 6| Step: 3
Training loss: 1.3243378400802612
Validation loss: 1.9528586377379715

Epoch: 6| Step: 4
Training loss: 2.112948417663574
Validation loss: 1.9339255235528434

Epoch: 6| Step: 5
Training loss: 1.646481990814209
Validation loss: 1.9355086588090467

Epoch: 6| Step: 6
Training loss: 1.4559857845306396
Validation loss: 1.9473829448864024

Epoch: 6| Step: 7
Training loss: 2.646806240081787
Validation loss: 1.9479097397096696

Epoch: 6| Step: 8
Training loss: 1.0412368774414062
Validation loss: 1.9198552690526491

Epoch: 6| Step: 9
Training loss: 1.7234742641448975
Validation loss: 1.9277264982141473

Epoch: 6| Step: 10
Training loss: 2.011044502258301
Validation loss: 1.9180192332113943

Epoch: 6| Step: 11
Training loss: 2.0060057640075684
Validation loss: 1.926587503443482

Epoch: 6| Step: 12
Training loss: 2.574237823486328
Validation loss: 1.945107292103511

Epoch: 6| Step: 13
Training loss: 1.3465828895568848
Validation loss: 1.9417041181236185

Epoch: 174| Step: 0
Training loss: 2.1720998287200928
Validation loss: 1.9048028748522523

Epoch: 6| Step: 1
Training loss: 2.249704122543335
Validation loss: 1.940729505272322

Epoch: 6| Step: 2
Training loss: 1.0061599016189575
Validation loss: 1.930916860539426

Epoch: 6| Step: 3
Training loss: 0.933243989944458
Validation loss: 1.9288127550514795

Epoch: 6| Step: 4
Training loss: 2.448138952255249
Validation loss: 1.934997009974654

Epoch: 6| Step: 5
Training loss: 0.8122217059135437
Validation loss: 1.9280916926681355

Epoch: 6| Step: 6
Training loss: 2.1935319900512695
Validation loss: 1.9240581066377702

Epoch: 6| Step: 7
Training loss: 2.004434585571289
Validation loss: 1.9324158007098782

Epoch: 6| Step: 8
Training loss: 2.027334451675415
Validation loss: 1.92956970584008

Epoch: 6| Step: 9
Training loss: 2.1020491123199463
Validation loss: 1.9027399734784198

Epoch: 6| Step: 10
Training loss: 1.8890146017074585
Validation loss: 1.916117839915778

Epoch: 6| Step: 11
Training loss: 2.8619461059570312
Validation loss: 1.9008962031333678

Epoch: 6| Step: 12
Training loss: 2.091811180114746
Validation loss: 1.9193332759282922

Epoch: 6| Step: 13
Training loss: 1.8426399230957031
Validation loss: 1.9233700254912018

Epoch: 175| Step: 0
Training loss: 2.4305951595306396
Validation loss: 1.9484520522497033

Epoch: 6| Step: 1
Training loss: 1.0598750114440918
Validation loss: 1.9245296767962876

Epoch: 6| Step: 2
Training loss: 1.3755990266799927
Validation loss: 1.9301432319866714

Epoch: 6| Step: 3
Training loss: 1.5853114128112793
Validation loss: 1.9216090953478249

Epoch: 6| Step: 4
Training loss: 2.384176254272461
Validation loss: 1.9324253489894252

Epoch: 6| Step: 5
Training loss: 1.7567545175552368
Validation loss: 1.9296784170212284

Epoch: 6| Step: 6
Training loss: 2.6239771842956543
Validation loss: 1.9256359159305532

Epoch: 6| Step: 7
Training loss: 1.8617875576019287
Validation loss: 1.9179158826028146

Epoch: 6| Step: 8
Training loss: 2.1713595390319824
Validation loss: 1.908395844121133

Epoch: 6| Step: 9
Training loss: 2.3578367233276367
Validation loss: 1.9199163708635556

Epoch: 6| Step: 10
Training loss: 1.8201889991760254
Validation loss: 1.922647495423594

Epoch: 6| Step: 11
Training loss: 1.7326526641845703
Validation loss: 1.9250224303173762

Epoch: 6| Step: 12
Training loss: 1.8512275218963623
Validation loss: 1.9348012401211647

Epoch: 6| Step: 13
Training loss: 1.6072660684585571
Validation loss: 1.9232587673330819

Epoch: 176| Step: 0
Training loss: 1.6318495273590088
Validation loss: 1.9249003843594623

Epoch: 6| Step: 1
Training loss: 1.0959889888763428
Validation loss: 1.9306995484136766

Epoch: 6| Step: 2
Training loss: 2.44290828704834
Validation loss: 1.9422997941253006

Epoch: 6| Step: 3
Training loss: 1.4565794467926025
Validation loss: 1.9282409324440906

Epoch: 6| Step: 4
Training loss: 2.2326741218566895
Validation loss: 1.9101637999216716

Epoch: 6| Step: 5
Training loss: 1.492863655090332
Validation loss: 1.9049928060141943

Epoch: 6| Step: 6
Training loss: 2.09274959564209
Validation loss: 1.9388410814346806

Epoch: 6| Step: 7
Training loss: 2.179572582244873
Validation loss: 1.9185932105587375

Epoch: 6| Step: 8
Training loss: 1.5631206035614014
Validation loss: 1.917158346022329

Epoch: 6| Step: 9
Training loss: 2.083677053451538
Validation loss: 1.948495755913437

Epoch: 6| Step: 10
Training loss: 1.871697187423706
Validation loss: 1.9309163619113225

Epoch: 6| Step: 11
Training loss: 2.3006415367126465
Validation loss: 1.915511578641912

Epoch: 6| Step: 12
Training loss: 1.9903069734573364
Validation loss: 1.9563523095141175

Epoch: 6| Step: 13
Training loss: 2.3002233505249023
Validation loss: 1.9375526341058875

Epoch: 177| Step: 0
Training loss: 1.6714234352111816
Validation loss: 1.9093102844812537

Epoch: 6| Step: 1
Training loss: 1.9405133724212646
Validation loss: 1.936078538176834

Epoch: 6| Step: 2
Training loss: 2.4977729320526123
Validation loss: 1.905326630479546

Epoch: 6| Step: 3
Training loss: 1.6020735502243042
Validation loss: 1.9229439868721911

Epoch: 6| Step: 4
Training loss: 1.8734418153762817
Validation loss: 1.9276448885599773

Epoch: 6| Step: 5
Training loss: 1.530717372894287
Validation loss: 1.9037800629933674

Epoch: 6| Step: 6
Training loss: 1.542649745941162
Validation loss: 1.8934625887101697

Epoch: 6| Step: 7
Training loss: 2.075615644454956
Validation loss: 1.9301310841755202

Epoch: 6| Step: 8
Training loss: 1.6401079893112183
Validation loss: 1.914640167708038

Epoch: 6| Step: 9
Training loss: 1.8949496746063232
Validation loss: 1.9147681920759139

Epoch: 6| Step: 10
Training loss: 2.727151870727539
Validation loss: 1.9265352756746355

Epoch: 6| Step: 11
Training loss: 1.7029590606689453
Validation loss: 1.942101909268287

Epoch: 6| Step: 12
Training loss: 2.182612895965576
Validation loss: 1.9566808336524553

Epoch: 6| Step: 13
Training loss: 1.6280466318130493
Validation loss: 1.953289249891876

Epoch: 178| Step: 0
Training loss: 2.3104867935180664
Validation loss: 1.9547962552757674

Epoch: 6| Step: 1
Training loss: 1.5303239822387695
Validation loss: 1.9422613010611585

Epoch: 6| Step: 2
Training loss: 2.287909984588623
Validation loss: 1.939787664721089

Epoch: 6| Step: 3
Training loss: 1.483931541442871
Validation loss: 1.9325350971632107

Epoch: 6| Step: 4
Training loss: 2.081131935119629
Validation loss: 1.9192829875535862

Epoch: 6| Step: 5
Training loss: 2.312504768371582
Validation loss: 1.9077284246362665

Epoch: 6| Step: 6
Training loss: 1.3874967098236084
Validation loss: 1.9327170836028231

Epoch: 6| Step: 7
Training loss: 1.2987160682678223
Validation loss: 1.9298212143682665

Epoch: 6| Step: 8
Training loss: 2.111232280731201
Validation loss: 1.943357216414585

Epoch: 6| Step: 9
Training loss: 1.8994650840759277
Validation loss: 1.9368540433145338

Epoch: 6| Step: 10
Training loss: 1.8550798892974854
Validation loss: 1.9330954090241463

Epoch: 6| Step: 11
Training loss: 2.394221544265747
Validation loss: 1.9174477669500536

Epoch: 6| Step: 12
Training loss: 1.952893853187561
Validation loss: 1.9341002997531687

Epoch: 6| Step: 13
Training loss: 1.4377992153167725
Validation loss: 1.9438735528658795

Epoch: 179| Step: 0
Training loss: 1.6748919486999512
Validation loss: 1.9397597723109747

Epoch: 6| Step: 1
Training loss: 2.1345903873443604
Validation loss: 1.914162394821003

Epoch: 6| Step: 2
Training loss: 2.852254867553711
Validation loss: 1.9251739876244658

Epoch: 6| Step: 3
Training loss: 2.515528440475464
Validation loss: 1.9072169642294607

Epoch: 6| Step: 4
Training loss: 1.4450900554656982
Validation loss: 1.921752675887077

Epoch: 6| Step: 5
Training loss: 1.7259901762008667
Validation loss: 1.9230921909373293

Epoch: 6| Step: 6
Training loss: 1.4442424774169922
Validation loss: 1.93209679536922

Epoch: 6| Step: 7
Training loss: 1.6653392314910889
Validation loss: 1.9291745078179143

Epoch: 6| Step: 8
Training loss: 1.6374619007110596
Validation loss: 1.9512019823956233

Epoch: 6| Step: 9
Training loss: 1.7768752574920654
Validation loss: 1.9438081941296976

Epoch: 6| Step: 10
Training loss: 1.799485206604004
Validation loss: 1.9250585468866492

Epoch: 6| Step: 11
Training loss: 2.4521961212158203
Validation loss: 1.9442945423946585

Epoch: 6| Step: 12
Training loss: 1.9374704360961914
Validation loss: 1.9208340465381581

Epoch: 6| Step: 13
Training loss: 1.734176516532898
Validation loss: 1.9246637282832977

Epoch: 180| Step: 0
Training loss: 2.0154502391815186
Validation loss: 1.9226005179907686

Epoch: 6| Step: 1
Training loss: 1.9845819473266602
Validation loss: 1.8942841970792381

Epoch: 6| Step: 2
Training loss: 2.1661112308502197
Validation loss: 1.900693565286616

Epoch: 6| Step: 3
Training loss: 2.480046272277832
Validation loss: 1.9256857390044837

Epoch: 6| Step: 4
Training loss: 1.329559087753296
Validation loss: 1.8991789484536776

Epoch: 6| Step: 5
Training loss: 2.1149511337280273
Validation loss: 1.9242171087572653

Epoch: 6| Step: 6
Training loss: 2.2022247314453125
Validation loss: 1.9151158768643615

Epoch: 6| Step: 7
Training loss: 1.600386619567871
Validation loss: 1.9263891071401618

Epoch: 6| Step: 8
Training loss: 2.1342849731445312
Validation loss: 1.9312758497012559

Epoch: 6| Step: 9
Training loss: 1.935023307800293
Validation loss: 1.9090889756397535

Epoch: 6| Step: 10
Training loss: 1.8414826393127441
Validation loss: 1.8926793644505162

Epoch: 6| Step: 11
Training loss: 1.7973188161849976
Validation loss: 1.9480227590889059

Epoch: 6| Step: 12
Training loss: 1.50439453125
Validation loss: 1.9205256892788796

Epoch: 6| Step: 13
Training loss: 1.1938310861587524
Validation loss: 1.9344152481325212

Epoch: 181| Step: 0
Training loss: 1.3555881977081299
Validation loss: 1.918337095168329

Epoch: 6| Step: 1
Training loss: 1.3579668998718262
Validation loss: 1.9510564291349022

Epoch: 6| Step: 2
Training loss: 1.8205070495605469
Validation loss: 1.9228823877150012

Epoch: 6| Step: 3
Training loss: 1.83148193359375
Validation loss: 1.934913630126625

Epoch: 6| Step: 4
Training loss: 1.8256335258483887
Validation loss: 1.9129502491284442

Epoch: 6| Step: 5
Training loss: 1.7612844705581665
Validation loss: 1.933043852929146

Epoch: 6| Step: 6
Training loss: 2.469010353088379
Validation loss: 1.9550011055443877

Epoch: 6| Step: 7
Training loss: 2.0713446140289307
Validation loss: 1.927793804035392

Epoch: 6| Step: 8
Training loss: 1.945412516593933
Validation loss: 1.9286644356225127

Epoch: 6| Step: 9
Training loss: 1.8795218467712402
Validation loss: 1.9015094387915827

Epoch: 6| Step: 10
Training loss: 1.2980908155441284
Validation loss: 1.9349925377035653

Epoch: 6| Step: 11
Training loss: 2.3261568546295166
Validation loss: 1.9389879190793602

Epoch: 6| Step: 12
Training loss: 2.572835922241211
Validation loss: 1.9066401232955277

Epoch: 6| Step: 13
Training loss: 1.8029437065124512
Validation loss: 1.9139104632921116

Epoch: 182| Step: 0
Training loss: 1.7361379861831665
Validation loss: 1.9532342392911193

Epoch: 6| Step: 1
Training loss: 2.1402618885040283
Validation loss: 1.9489053359595678

Epoch: 6| Step: 2
Training loss: 2.112651824951172
Validation loss: 1.8946149028757566

Epoch: 6| Step: 3
Training loss: 2.4584665298461914
Validation loss: 1.9286692591123684

Epoch: 6| Step: 4
Training loss: 2.3527374267578125
Validation loss: 1.9209546812119023

Epoch: 6| Step: 5
Training loss: 2.5591306686401367
Validation loss: 1.9389908300933016

Epoch: 6| Step: 6
Training loss: 1.7095575332641602
Validation loss: 1.9303020405512985

Epoch: 6| Step: 7
Training loss: 1.7935967445373535
Validation loss: 1.9264668367242301

Epoch: 6| Step: 8
Training loss: 1.9595447778701782
Validation loss: 1.9410676635721678

Epoch: 6| Step: 9
Training loss: 1.59600830078125
Validation loss: 1.939755649976833

Epoch: 6| Step: 10
Training loss: 1.939557433128357
Validation loss: 1.934756407173731

Epoch: 6| Step: 11
Training loss: 1.5394786596298218
Validation loss: 1.921633271760838

Epoch: 6| Step: 12
Training loss: 1.0055813789367676
Validation loss: 1.948551542015486

Epoch: 6| Step: 13
Training loss: 1.8488421440124512
Validation loss: 1.9456931544888405

Epoch: 183| Step: 0
Training loss: 1.4174749851226807
Validation loss: 1.925697547133251

Epoch: 6| Step: 1
Training loss: 2.258847236633301
Validation loss: 1.9163073506406558

Epoch: 6| Step: 2
Training loss: 2.1515302658081055
Validation loss: 1.9287707254450808

Epoch: 6| Step: 3
Training loss: 1.7546546459197998
Validation loss: 1.9488344551414571

Epoch: 6| Step: 4
Training loss: 1.0973446369171143
Validation loss: 1.9327919854912707

Epoch: 6| Step: 5
Training loss: 2.0699679851531982
Validation loss: 1.9194666390777917

Epoch: 6| Step: 6
Training loss: 1.8078181743621826
Validation loss: 1.9396407629853936

Epoch: 6| Step: 7
Training loss: 2.0525708198547363
Validation loss: 1.919663244678128

Epoch: 6| Step: 8
Training loss: 1.8254519701004028
Validation loss: 1.91940063558599

Epoch: 6| Step: 9
Training loss: 2.1238436698913574
Validation loss: 1.886482419506196

Epoch: 6| Step: 10
Training loss: 1.4766039848327637
Validation loss: 1.9253254987860238

Epoch: 6| Step: 11
Training loss: 2.3358521461486816
Validation loss: 1.90975175621689

Epoch: 6| Step: 12
Training loss: 2.0007219314575195
Validation loss: 1.9185495376586914

Epoch: 6| Step: 13
Training loss: 1.8292315006256104
Validation loss: 1.9085030555725098

Epoch: 184| Step: 0
Training loss: 1.5075571537017822
Validation loss: 1.9298164011329733

Epoch: 6| Step: 1
Training loss: 1.5152406692504883
Validation loss: 1.9262521036209599

Epoch: 6| Step: 2
Training loss: 1.9809712171554565
Validation loss: 1.9114564247028802

Epoch: 6| Step: 3
Training loss: 1.221212387084961
Validation loss: 1.9469728085302538

Epoch: 6| Step: 4
Training loss: 2.3884963989257812
Validation loss: 1.9091108332398117

Epoch: 6| Step: 5
Training loss: 2.0076065063476562
Validation loss: 1.9647134914193103

Epoch: 6| Step: 6
Training loss: 1.4963409900665283
Validation loss: 1.9516365553743096

Epoch: 6| Step: 7
Training loss: 1.1808428764343262
Validation loss: 1.939441994954181

Epoch: 6| Step: 8
Training loss: 1.9519500732421875
Validation loss: 1.9169101048541326

Epoch: 6| Step: 9
Training loss: 2.1547021865844727
Validation loss: 1.964628840005526

Epoch: 6| Step: 10
Training loss: 2.029534339904785
Validation loss: 1.9194911077458372

Epoch: 6| Step: 11
Training loss: 2.729306697845459
Validation loss: 1.9288712701489847

Epoch: 6| Step: 12
Training loss: 2.114307165145874
Validation loss: 1.960917826621763

Epoch: 6| Step: 13
Training loss: 2.259843111038208
Validation loss: 1.9555458612339471

Epoch: 185| Step: 0
Training loss: 1.4144468307495117
Validation loss: 1.9144082466761272

Epoch: 6| Step: 1
Training loss: 1.3953735828399658
Validation loss: 1.9265549836620208

Epoch: 6| Step: 2
Training loss: 2.1370015144348145
Validation loss: 1.9213250170471847

Epoch: 6| Step: 3
Training loss: 2.0464537143707275
Validation loss: 1.9429276963715911

Epoch: 6| Step: 4
Training loss: 2.185025215148926
Validation loss: 1.8941654184813141

Epoch: 6| Step: 5
Training loss: 2.229097366333008
Validation loss: 1.8913546992886452

Epoch: 6| Step: 6
Training loss: 2.176178216934204
Validation loss: 1.9332647990154963

Epoch: 6| Step: 7
Training loss: 1.4823079109191895
Validation loss: 1.945993519598438

Epoch: 6| Step: 8
Training loss: 2.0049009323120117
Validation loss: 1.9171426398779756

Epoch: 6| Step: 9
Training loss: 1.9524562358856201
Validation loss: 1.9448742148696736

Epoch: 6| Step: 10
Training loss: 1.6195052862167358
Validation loss: 1.911277037794872

Epoch: 6| Step: 11
Training loss: 1.3672223091125488
Validation loss: 1.9176737698175574

Epoch: 6| Step: 12
Training loss: 2.404419422149658
Validation loss: 1.9165696867050663

Epoch: 6| Step: 13
Training loss: 1.8842822313308716
Validation loss: 1.9225172381247244

Epoch: 186| Step: 0
Training loss: 1.7434277534484863
Validation loss: 1.9464105162569272

Epoch: 6| Step: 1
Training loss: 2.877044200897217
Validation loss: 1.9178543308729767

Epoch: 6| Step: 2
Training loss: 2.246175765991211
Validation loss: 1.926913329350051

Epoch: 6| Step: 3
Training loss: 1.8406481742858887
Validation loss: 1.9307361354110062

Epoch: 6| Step: 4
Training loss: 1.352086067199707
Validation loss: 1.9297220630030478

Epoch: 6| Step: 5
Training loss: 2.2366044521331787
Validation loss: 1.9345860506898613

Epoch: 6| Step: 6
Training loss: 1.6979925632476807
Validation loss: 1.9626331149890859

Epoch: 6| Step: 7
Training loss: 2.1106925010681152
Validation loss: 1.9062403004656556

Epoch: 6| Step: 8
Training loss: 2.069242238998413
Validation loss: 1.949106156185109

Epoch: 6| Step: 9
Training loss: 1.918481707572937
Validation loss: 1.9451290945852957

Epoch: 6| Step: 10
Training loss: 1.1725835800170898
Validation loss: 1.9293986712732623

Epoch: 6| Step: 11
Training loss: 1.5632342100143433
Validation loss: 1.9422295208900207

Epoch: 6| Step: 12
Training loss: 1.551598310470581
Validation loss: 1.9554103382172123

Epoch: 6| Step: 13
Training loss: 1.8290143013000488
Validation loss: 1.9469609670741583

Epoch: 187| Step: 0
Training loss: 2.4204905033111572
Validation loss: 1.9117154152162614

Epoch: 6| Step: 1
Training loss: 2.7857260704040527
Validation loss: 1.9261305793639152

Epoch: 6| Step: 2
Training loss: 2.00342059135437
Validation loss: 1.943819938167449

Epoch: 6| Step: 3
Training loss: 1.8209998607635498
Validation loss: 1.910213553777305

Epoch: 6| Step: 4
Training loss: 1.600320816040039
Validation loss: 1.9467435703482678

Epoch: 6| Step: 5
Training loss: 2.663745880126953
Validation loss: 1.9256619740557928

Epoch: 6| Step: 6
Training loss: 1.456467866897583
Validation loss: 1.9601253617194392

Epoch: 6| Step: 7
Training loss: 1.7059717178344727
Validation loss: 1.9525215728308565

Epoch: 6| Step: 8
Training loss: 2.057919502258301
Validation loss: 1.926581298151324

Epoch: 6| Step: 9
Training loss: 1.6565194129943848
Validation loss: 1.906339713322219

Epoch: 6| Step: 10
Training loss: 1.7774797677993774
Validation loss: 1.911764285897696

Epoch: 6| Step: 11
Training loss: 1.2555041313171387
Validation loss: 1.9014584607975458

Epoch: 6| Step: 12
Training loss: 1.782662272453308
Validation loss: 1.9039094319907568

Epoch: 6| Step: 13
Training loss: 1.7170798778533936
Validation loss: 1.884450166456161

Epoch: 188| Step: 0
Training loss: 2.148656129837036
Validation loss: 1.9253786815110074

Epoch: 6| Step: 1
Training loss: 1.9622211456298828
Validation loss: 1.8945368361729447

Epoch: 6| Step: 2
Training loss: 1.9545437097549438
Validation loss: 1.9126677615668184

Epoch: 6| Step: 3
Training loss: 1.5917203426361084
Validation loss: 1.932374644023116

Epoch: 6| Step: 4
Training loss: 2.1814239025115967
Validation loss: 1.9241481865606

Epoch: 6| Step: 5
Training loss: 1.4427698850631714
Validation loss: 1.9058548519688268

Epoch: 6| Step: 6
Training loss: 1.7850233316421509
Validation loss: 1.9325207741029802

Epoch: 6| Step: 7
Training loss: 1.6691234111785889
Validation loss: 1.917013455462712

Epoch: 6| Step: 8
Training loss: 1.5084750652313232
Validation loss: 1.8829868173086515

Epoch: 6| Step: 9
Training loss: 1.8223708868026733
Validation loss: 1.9121243107703425

Epoch: 6| Step: 10
Training loss: 2.035684823989868
Validation loss: 1.856390353172056

Epoch: 6| Step: 11
Training loss: 1.9910461902618408
Validation loss: 1.9042276900301698

Epoch: 6| Step: 12
Training loss: 1.832113265991211
Validation loss: 1.9028965247574674

Epoch: 6| Step: 13
Training loss: 2.5922257900238037
Validation loss: 1.9150174433185208

Epoch: 189| Step: 0
Training loss: 2.1190707683563232
Validation loss: 1.9334325149495115

Epoch: 6| Step: 1
Training loss: 1.539735198020935
Validation loss: 1.9159304839308544

Epoch: 6| Step: 2
Training loss: 2.24807071685791
Validation loss: 1.914918117625739

Epoch: 6| Step: 3
Training loss: 1.6859256029129028
Validation loss: 1.910606203540679

Epoch: 6| Step: 4
Training loss: 1.2783317565917969
Validation loss: 1.911410553480989

Epoch: 6| Step: 5
Training loss: 2.0133607387542725
Validation loss: 1.901226734602323

Epoch: 6| Step: 6
Training loss: 1.4686650037765503
Validation loss: 1.9163665143392419

Epoch: 6| Step: 7
Training loss: 2.6393465995788574
Validation loss: 1.9257621867682344

Epoch: 6| Step: 8
Training loss: 1.9970703125
Validation loss: 1.911360541979472

Epoch: 6| Step: 9
Training loss: 1.6170134544372559
Validation loss: 1.9405705185346707

Epoch: 6| Step: 10
Training loss: 1.9806804656982422
Validation loss: 1.9258141658639396

Epoch: 6| Step: 11
Training loss: 1.383864402770996
Validation loss: 1.8978994533579836

Epoch: 6| Step: 12
Training loss: 2.2214207649230957
Validation loss: 1.897009475256807

Epoch: 6| Step: 13
Training loss: 2.254178047180176
Validation loss: 1.9054690137986214

Epoch: 190| Step: 0
Training loss: 1.530205488204956
Validation loss: 1.9337214859583045

Epoch: 6| Step: 1
Training loss: 1.6541743278503418
Validation loss: 1.922415341100385

Epoch: 6| Step: 2
Training loss: 1.8483694791793823
Validation loss: 1.9387614009200886

Epoch: 6| Step: 3
Training loss: 2.0430595874786377
Validation loss: 1.920500211818244

Epoch: 6| Step: 4
Training loss: 2.2454476356506348
Validation loss: 1.9190744533333728

Epoch: 6| Step: 5
Training loss: 2.171198606491089
Validation loss: 1.9193408143135808

Epoch: 6| Step: 6
Training loss: 1.767819881439209
Validation loss: 1.9394840604515486

Epoch: 6| Step: 7
Training loss: 2.096607208251953
Validation loss: 1.9192791113289454

Epoch: 6| Step: 8
Training loss: 2.0840959548950195
Validation loss: 1.9433106991552538

Epoch: 6| Step: 9
Training loss: 1.693117618560791
Validation loss: 1.9349241846351213

Epoch: 6| Step: 10
Training loss: 0.9099425673484802
Validation loss: 1.950323361222462

Epoch: 6| Step: 11
Training loss: 2.427365303039551
Validation loss: 1.906825973141578

Epoch: 6| Step: 12
Training loss: 1.7250089645385742
Validation loss: 1.9683985710144043

Epoch: 6| Step: 13
Training loss: 1.933443307876587
Validation loss: 1.9249429292576288

Epoch: 191| Step: 0
Training loss: 1.6216322183609009
Validation loss: 1.9319608006426083

Epoch: 6| Step: 1
Training loss: 1.976322889328003
Validation loss: 1.930058971528084

Epoch: 6| Step: 2
Training loss: 1.6213018894195557
Validation loss: 1.9310943080532936

Epoch: 6| Step: 3
Training loss: 1.9533909559249878
Validation loss: 1.9222536868946527

Epoch: 6| Step: 4
Training loss: 1.9448614120483398
Validation loss: 1.9153846002394153

Epoch: 6| Step: 5
Training loss: 2.001800775527954
Validation loss: 1.9189606276891564

Epoch: 6| Step: 6
Training loss: 1.5117526054382324
Validation loss: 1.9264638526465303

Epoch: 6| Step: 7
Training loss: 2.1108508110046387
Validation loss: 1.9064722407248713

Epoch: 6| Step: 8
Training loss: 1.6961764097213745
Validation loss: 1.9026668994657454

Epoch: 6| Step: 9
Training loss: 1.813854694366455
Validation loss: 1.8977125037101008

Epoch: 6| Step: 10
Training loss: 1.9231669902801514
Validation loss: 1.910648294674453

Epoch: 6| Step: 11
Training loss: 1.8823425769805908
Validation loss: 1.913134136507588

Epoch: 6| Step: 12
Training loss: 1.9617434740066528
Validation loss: 1.93498868326987

Epoch: 6| Step: 13
Training loss: 2.079291343688965
Validation loss: 1.897513936924678

Epoch: 192| Step: 0
Training loss: 2.2558200359344482
Validation loss: 1.882356914140845

Epoch: 6| Step: 1
Training loss: 1.6749426126480103
Validation loss: 1.8939045488193471

Epoch: 6| Step: 2
Training loss: 1.5042080879211426
Validation loss: 1.9260663704205585

Epoch: 6| Step: 3
Training loss: 1.9649858474731445
Validation loss: 1.9324533759906728

Epoch: 6| Step: 4
Training loss: 1.7151820659637451
Validation loss: 1.9043964621841267

Epoch: 6| Step: 5
Training loss: 1.5602364540100098
Validation loss: 1.9236384643021451

Epoch: 6| Step: 6
Training loss: 1.7012939453125
Validation loss: 1.8952930550421438

Epoch: 6| Step: 7
Training loss: 2.340425968170166
Validation loss: 1.9075139337970364

Epoch: 6| Step: 8
Training loss: 2.130012035369873
Validation loss: 1.9066023608689666

Epoch: 6| Step: 9
Training loss: 2.0438380241394043
Validation loss: 1.9034849443743307

Epoch: 6| Step: 10
Training loss: 1.9330666065216064
Validation loss: 1.9549193536081622

Epoch: 6| Step: 11
Training loss: 1.315125584602356
Validation loss: 1.922873112463182

Epoch: 6| Step: 12
Training loss: 1.772066354751587
Validation loss: 1.9110264893501037

Epoch: 6| Step: 13
Training loss: 2.663209915161133
Validation loss: 1.8966013116221274

Epoch: 193| Step: 0
Training loss: 1.889176845550537
Validation loss: 1.914923947344544

Epoch: 6| Step: 1
Training loss: 1.8911731243133545
Validation loss: 1.9071896614566926

Epoch: 6| Step: 2
Training loss: 1.6789933443069458
Validation loss: 1.8847132280308714

Epoch: 6| Step: 3
Training loss: 1.9398243427276611
Validation loss: 1.9097643026741602

Epoch: 6| Step: 4
Training loss: 1.6339625120162964
Validation loss: 1.9330376348187845

Epoch: 6| Step: 5
Training loss: 2.2464261054992676
Validation loss: 1.9233189885334303

Epoch: 6| Step: 6
Training loss: 2.1931772232055664
Validation loss: 1.9283017650727303

Epoch: 6| Step: 7
Training loss: 2.0639448165893555
Validation loss: 1.9380095222944855

Epoch: 6| Step: 8
Training loss: 1.5272216796875
Validation loss: 1.934231622244722

Epoch: 6| Step: 9
Training loss: 1.795358657836914
Validation loss: 1.9086540322149954

Epoch: 6| Step: 10
Training loss: 1.671435832977295
Validation loss: 1.912987171962697

Epoch: 6| Step: 11
Training loss: 2.13476824760437
Validation loss: 1.9039694455362135

Epoch: 6| Step: 12
Training loss: 1.4085981845855713
Validation loss: 1.8922112987887474

Epoch: 6| Step: 13
Training loss: 2.0755133628845215
Validation loss: 1.940926233927409

Epoch: 194| Step: 0
Training loss: 1.2507075071334839
Validation loss: 1.902407197542088

Epoch: 6| Step: 1
Training loss: 2.0022974014282227
Validation loss: 1.9065867675248014

Epoch: 6| Step: 2
Training loss: 2.4167983531951904
Validation loss: 1.9084949147316717

Epoch: 6| Step: 3
Training loss: 1.7779765129089355
Validation loss: 1.9066750657173894

Epoch: 6| Step: 4
Training loss: 1.7275683879852295
Validation loss: 1.8892988363901775

Epoch: 6| Step: 5
Training loss: 1.7890172004699707
Validation loss: 1.9357114632924397

Epoch: 6| Step: 6
Training loss: 1.5566788911819458
Validation loss: 1.9056757342430852

Epoch: 6| Step: 7
Training loss: 1.7241125106811523
Validation loss: 1.9144416906500374

Epoch: 6| Step: 8
Training loss: 1.9377994537353516
Validation loss: 1.8926705416812692

Epoch: 6| Step: 9
Training loss: 1.1655328273773193
Validation loss: 1.9313412661193519

Epoch: 6| Step: 10
Training loss: 2.4486262798309326
Validation loss: 1.89299105059716

Epoch: 6| Step: 11
Training loss: 1.716760516166687
Validation loss: 1.9002571375139299

Epoch: 6| Step: 12
Training loss: 2.361849784851074
Validation loss: 1.8952168956879647

Epoch: 6| Step: 13
Training loss: 2.3374171257019043
Validation loss: 1.9316283272158714

Epoch: 195| Step: 0
Training loss: 1.5571963787078857
Validation loss: 1.9147559801737468

Epoch: 6| Step: 1
Training loss: 2.070035457611084
Validation loss: 1.923862862330611

Epoch: 6| Step: 2
Training loss: 1.8496612310409546
Validation loss: 1.9354277721015356

Epoch: 6| Step: 3
Training loss: 1.2894189357757568
Validation loss: 1.9111052815632155

Epoch: 6| Step: 4
Training loss: 2.276973247528076
Validation loss: 1.924771362735379

Epoch: 6| Step: 5
Training loss: 1.7944179773330688
Validation loss: 1.9233974667005642

Epoch: 6| Step: 6
Training loss: 2.114640235900879
Validation loss: 1.9319920616765176

Epoch: 6| Step: 7
Training loss: 1.9895272254943848
Validation loss: 1.9455326116213234

Epoch: 6| Step: 8
Training loss: 0.9536417722702026
Validation loss: 1.9370801448822021

Epoch: 6| Step: 9
Training loss: 2.3475637435913086
Validation loss: 1.9261861334564865

Epoch: 6| Step: 10
Training loss: 2.427093029022217
Validation loss: 1.9110969471675094

Epoch: 6| Step: 11
Training loss: 1.4966446161270142
Validation loss: 1.9533096654440767

Epoch: 6| Step: 12
Training loss: 1.552765965461731
Validation loss: 1.9461520679535405

Epoch: 6| Step: 13
Training loss: 2.3542213439941406
Validation loss: 1.89066279831753

Epoch: 196| Step: 0
Training loss: 1.8302606344223022
Validation loss: 1.9228209782672185

Epoch: 6| Step: 1
Training loss: 1.1711543798446655
Validation loss: 1.9006617838336575

Epoch: 6| Step: 2
Training loss: 2.002784490585327
Validation loss: 1.8687146991811774

Epoch: 6| Step: 3
Training loss: 1.4634544849395752
Validation loss: 1.8711926578193583

Epoch: 6| Step: 4
Training loss: 2.1803388595581055
Validation loss: 1.9127373605646112

Epoch: 6| Step: 5
Training loss: 2.436846971511841
Validation loss: 1.9059493003352996

Epoch: 6| Step: 6
Training loss: 1.9549362659454346
Validation loss: 1.9137598006956038

Epoch: 6| Step: 7
Training loss: 1.8981962203979492
Validation loss: 1.882816719752486

Epoch: 6| Step: 8
Training loss: 2.5409979820251465
Validation loss: 1.9094116790320284

Epoch: 6| Step: 9
Training loss: 1.2086005210876465
Validation loss: 1.9258771122142833

Epoch: 6| Step: 10
Training loss: 1.599952220916748
Validation loss: 1.884469336079013

Epoch: 6| Step: 11
Training loss: 1.607130527496338
Validation loss: 1.8844307327783236

Epoch: 6| Step: 12
Training loss: 2.290963649749756
Validation loss: 1.9023714744916527

Epoch: 6| Step: 13
Training loss: 1.6503766775131226
Validation loss: 1.8854803923637635

Epoch: 197| Step: 0
Training loss: 1.746242880821228
Validation loss: 1.867783078583338

Epoch: 6| Step: 1
Training loss: 2.0890657901763916
Validation loss: 1.8987464212602185

Epoch: 6| Step: 2
Training loss: 1.4172214269638062
Validation loss: 1.8708512039594754

Epoch: 6| Step: 3
Training loss: 2.102613925933838
Validation loss: 1.8809418280919392

Epoch: 6| Step: 4
Training loss: 1.5964746475219727
Validation loss: 1.8659444342377365

Epoch: 6| Step: 5
Training loss: 2.621528148651123
Validation loss: 1.8878611262126634

Epoch: 6| Step: 6
Training loss: 1.5844156742095947
Validation loss: 1.914446274439494

Epoch: 6| Step: 7
Training loss: 1.7202386856079102
Validation loss: 1.8971389724362282

Epoch: 6| Step: 8
Training loss: 1.6781752109527588
Validation loss: 1.9100775205960838

Epoch: 6| Step: 9
Training loss: 1.5006688833236694
Validation loss: 1.9295420697940293

Epoch: 6| Step: 10
Training loss: 2.3882946968078613
Validation loss: 1.921336486775388

Epoch: 6| Step: 11
Training loss: 1.696122646331787
Validation loss: 1.9620118243719942

Epoch: 6| Step: 12
Training loss: 2.2289066314697266
Validation loss: 1.9410444510880338

Epoch: 6| Step: 13
Training loss: 1.9328274726867676
Validation loss: 1.9555136234529558

Epoch: 198| Step: 0
Training loss: 1.7615329027175903
Validation loss: 1.9379184938246203

Epoch: 6| Step: 1
Training loss: 2.4453842639923096
Validation loss: 1.9278659807738436

Epoch: 6| Step: 2
Training loss: 1.7500622272491455
Validation loss: 1.9028187413369455

Epoch: 6| Step: 3
Training loss: 1.422775387763977
Validation loss: 1.9262866794422109

Epoch: 6| Step: 4
Training loss: 1.132907509803772
Validation loss: 1.9083334143443773

Epoch: 6| Step: 5
Training loss: 1.6696929931640625
Validation loss: 1.8981200469437467

Epoch: 6| Step: 6
Training loss: 1.8193213939666748
Validation loss: 1.926035342677947

Epoch: 6| Step: 7
Training loss: 1.4875613451004028
Validation loss: 1.9146102936037126

Epoch: 6| Step: 8
Training loss: 1.9051626920700073
Validation loss: 1.894425836942529

Epoch: 6| Step: 9
Training loss: 2.2493984699249268
Validation loss: 1.8891373039573751

Epoch: 6| Step: 10
Training loss: 1.8085956573486328
Validation loss: 1.92144940745446

Epoch: 6| Step: 11
Training loss: 2.449856996536255
Validation loss: 1.8983951640385452

Epoch: 6| Step: 12
Training loss: 2.4518661499023438
Validation loss: 1.9268355882295998

Epoch: 6| Step: 13
Training loss: 1.1652789115905762
Validation loss: 1.9340702103030296

Epoch: 199| Step: 0
Training loss: 2.7233219146728516
Validation loss: 1.8990191926238358

Epoch: 6| Step: 1
Training loss: 1.5279890298843384
Validation loss: 1.9114605521643033

Epoch: 6| Step: 2
Training loss: 1.5494095087051392
Validation loss: 1.9035077248850176

Epoch: 6| Step: 3
Training loss: 1.7230935096740723
Validation loss: 1.9107148416580693

Epoch: 6| Step: 4
Training loss: 1.8931142091751099
Validation loss: 1.922730351007113

Epoch: 6| Step: 5
Training loss: 1.5616765022277832
Validation loss: 1.8898515906385196

Epoch: 6| Step: 6
Training loss: 2.0204122066497803
Validation loss: 1.9162458706927556

Epoch: 6| Step: 7
Training loss: 1.3206671476364136
Validation loss: 1.9059255712775773

Epoch: 6| Step: 8
Training loss: 1.83890700340271
Validation loss: 1.864429384149531

Epoch: 6| Step: 9
Training loss: 2.2420504093170166
Validation loss: 1.883309329709699

Epoch: 6| Step: 10
Training loss: 1.5068588256835938
Validation loss: 1.891210881612634

Epoch: 6| Step: 11
Training loss: 1.9685626029968262
Validation loss: 1.8960584350811538

Epoch: 6| Step: 12
Training loss: 2.231044054031372
Validation loss: 1.9003540098026235

Epoch: 6| Step: 13
Training loss: 1.466847538948059
Validation loss: 1.9217807528793172

Epoch: 200| Step: 0
Training loss: 1.6410911083221436
Validation loss: 1.8952009485613914

Epoch: 6| Step: 1
Training loss: 1.437808871269226
Validation loss: 1.907557290087464

Epoch: 6| Step: 2
Training loss: 1.0053036212921143
Validation loss: 1.9010608567986438

Epoch: 6| Step: 3
Training loss: 2.1800825595855713
Validation loss: 1.9305101722799323

Epoch: 6| Step: 4
Training loss: 1.8561382293701172
Validation loss: 1.9190218576820948

Epoch: 6| Step: 5
Training loss: 1.5455979108810425
Validation loss: 1.8749578870752805

Epoch: 6| Step: 6
Training loss: 2.5029184818267822
Validation loss: 1.8758225287160566

Epoch: 6| Step: 7
Training loss: 2.184354543685913
Validation loss: 1.903589133293398

Epoch: 6| Step: 8
Training loss: 1.8183245658874512
Validation loss: 1.9019634569844892

Epoch: 6| Step: 9
Training loss: 1.7336313724517822
Validation loss: 1.8913488323970506

Epoch: 6| Step: 10
Training loss: 2.0351645946502686
Validation loss: 1.8914819616143421

Epoch: 6| Step: 11
Training loss: 1.5769221782684326
Validation loss: 1.919019240205006

Epoch: 6| Step: 12
Training loss: 2.4581732749938965
Validation loss: 1.9335397033281223

Epoch: 6| Step: 13
Training loss: 1.711111068725586
Validation loss: 1.8607750900330082

Epoch: 201| Step: 0
Training loss: 2.046759843826294
Validation loss: 1.9014915740618141

Epoch: 6| Step: 1
Training loss: 2.114699363708496
Validation loss: 1.8594776250982796

Epoch: 6| Step: 2
Training loss: 1.9832353591918945
Validation loss: 1.9303253568628782

Epoch: 6| Step: 3
Training loss: 1.711511492729187
Validation loss: 1.9143127100442046

Epoch: 6| Step: 4
Training loss: 2.0908467769622803
Validation loss: 1.9181907138516825

Epoch: 6| Step: 5
Training loss: 2.3282132148742676
Validation loss: 1.8958313234390751

Epoch: 6| Step: 6
Training loss: 1.3602139949798584
Validation loss: 1.8870641595573836

Epoch: 6| Step: 7
Training loss: 1.3833298683166504
Validation loss: 1.9222545085414764

Epoch: 6| Step: 8
Training loss: 1.4406955242156982
Validation loss: 1.9135790742853636

Epoch: 6| Step: 9
Training loss: 1.8783538341522217
Validation loss: 1.9094565735068372

Epoch: 6| Step: 10
Training loss: 1.5998492240905762
Validation loss: 1.8910868808787356

Epoch: 6| Step: 11
Training loss: 2.310652732849121
Validation loss: 1.9141284291462233

Epoch: 6| Step: 12
Training loss: 1.9766888618469238
Validation loss: 1.9170090126734909

Epoch: 6| Step: 13
Training loss: 1.3740086555480957
Validation loss: 1.9157114490385978

Epoch: 202| Step: 0
Training loss: 2.550447463989258
Validation loss: 1.9135394378374981

Epoch: 6| Step: 1
Training loss: 1.809291124343872
Validation loss: 1.9325781201803556

Epoch: 6| Step: 2
Training loss: 1.5158672332763672
Validation loss: 1.9085318093658776

Epoch: 6| Step: 3
Training loss: 1.9447104930877686
Validation loss: 1.888946174293436

Epoch: 6| Step: 4
Training loss: 1.5414633750915527
Validation loss: 1.9297868500473678

Epoch: 6| Step: 5
Training loss: 0.8901803493499756
Validation loss: 1.9059163549894929

Epoch: 6| Step: 6
Training loss: 1.7781034708023071
Validation loss: 1.8752629910745928

Epoch: 6| Step: 7
Training loss: 2.302314043045044
Validation loss: 1.8903011019511888

Epoch: 6| Step: 8
Training loss: 1.9233295917510986
Validation loss: 1.9154010485577326

Epoch: 6| Step: 9
Training loss: 2.200075387954712
Validation loss: 1.9129711197268577

Epoch: 6| Step: 10
Training loss: 1.7449703216552734
Validation loss: 1.9065712139170656

Epoch: 6| Step: 11
Training loss: 1.9104546308517456
Validation loss: 1.90915040046938

Epoch: 6| Step: 12
Training loss: 1.5935399532318115
Validation loss: 1.893324972480856

Epoch: 6| Step: 13
Training loss: 1.7358616590499878
Validation loss: 1.9056313589055052

Epoch: 203| Step: 0
Training loss: 2.1657328605651855
Validation loss: 1.920428692653615

Epoch: 6| Step: 1
Training loss: 1.694077968597412
Validation loss: 1.9194001536215506

Epoch: 6| Step: 2
Training loss: 1.5231612920761108
Validation loss: 1.9143326256864814

Epoch: 6| Step: 3
Training loss: 1.6255306005477905
Validation loss: 1.9101672275092012

Epoch: 6| Step: 4
Training loss: 2.11795973777771
Validation loss: 1.9007407772925593

Epoch: 6| Step: 5
Training loss: 1.7104238271713257
Validation loss: 1.8905533616260817

Epoch: 6| Step: 6
Training loss: 1.4717767238616943
Validation loss: 1.9191077652797903

Epoch: 6| Step: 7
Training loss: 1.6794219017028809
Validation loss: 1.897995033571797

Epoch: 6| Step: 8
Training loss: 1.1197305917739868
Validation loss: 1.8980461474387877

Epoch: 6| Step: 9
Training loss: 2.7642126083374023
Validation loss: 1.9118342027869275

Epoch: 6| Step: 10
Training loss: 1.9694865942001343
Validation loss: 1.9018462140073058

Epoch: 6| Step: 11
Training loss: 2.1820859909057617
Validation loss: 1.897800442993

Epoch: 6| Step: 12
Training loss: 1.8256088495254517
Validation loss: 1.8926301002502441

Epoch: 6| Step: 13
Training loss: 1.540945053100586
Validation loss: 1.9396768769910258

Epoch: 204| Step: 0
Training loss: 2.1884610652923584
Validation loss: 1.9207873382875997

Epoch: 6| Step: 1
Training loss: 1.46297025680542
Validation loss: 1.9174299073475662

Epoch: 6| Step: 2
Training loss: 1.7056517601013184
Validation loss: 1.8857672124780633

Epoch: 6| Step: 3
Training loss: 1.6253199577331543
Validation loss: 1.9341025839569748

Epoch: 6| Step: 4
Training loss: 1.7515937089920044
Validation loss: 1.8642935932323497

Epoch: 6| Step: 5
Training loss: 1.4276130199432373
Validation loss: 1.9025131592186548

Epoch: 6| Step: 6
Training loss: 1.8886878490447998
Validation loss: 1.8863252170624272

Epoch: 6| Step: 7
Training loss: 1.999725103378296
Validation loss: 1.8953517521581342

Epoch: 6| Step: 8
Training loss: 1.9592359066009521
Validation loss: 1.907392732558712

Epoch: 6| Step: 9
Training loss: 1.8452494144439697
Validation loss: 1.8877365512232627

Epoch: 6| Step: 10
Training loss: 1.6542112827301025
Validation loss: 1.8779481316125521

Epoch: 6| Step: 11
Training loss: 1.8222438097000122
Validation loss: 1.8973852049919866

Epoch: 6| Step: 12
Training loss: 1.7416437864303589
Validation loss: 1.862038020164736

Epoch: 6| Step: 13
Training loss: 3.218500852584839
Validation loss: 1.9090855672795286

Epoch: 205| Step: 0
Training loss: 1.0786125659942627
Validation loss: 1.9070897935539164

Epoch: 6| Step: 1
Training loss: 1.636888027191162
Validation loss: 1.9188767992040163

Epoch: 6| Step: 2
Training loss: 2.091423988342285
Validation loss: 1.9079008666417931

Epoch: 6| Step: 3
Training loss: 1.8697129487991333
Validation loss: 1.926120852911344

Epoch: 6| Step: 4
Training loss: 1.8851048946380615
Validation loss: 1.9176505739970873

Epoch: 6| Step: 5
Training loss: 1.706465244293213
Validation loss: 1.9343373929300616

Epoch: 6| Step: 6
Training loss: 1.9234795570373535
Validation loss: 1.9085787983350857

Epoch: 6| Step: 7
Training loss: 2.304023027420044
Validation loss: 1.9228621208539574

Epoch: 6| Step: 8
Training loss: 2.1692919731140137
Validation loss: 1.911801238213816

Epoch: 6| Step: 9
Training loss: 2.027358055114746
Validation loss: 1.9241236884106871

Epoch: 6| Step: 10
Training loss: 1.5410921573638916
Validation loss: 1.9092065467629382

Epoch: 6| Step: 11
Training loss: 1.8012120723724365
Validation loss: 1.9049533695302985

Epoch: 6| Step: 12
Training loss: 2.094921588897705
Validation loss: 1.9034043947855632

Epoch: 6| Step: 13
Training loss: 1.165174961090088
Validation loss: 1.9273215814303326

Epoch: 206| Step: 0
Training loss: 1.6714788675308228
Validation loss: 1.909648831172656

Epoch: 6| Step: 1
Training loss: 2.1005630493164062
Validation loss: 1.9095554454352266

Epoch: 6| Step: 2
Training loss: 1.8854334354400635
Validation loss: 1.8838297167131979

Epoch: 6| Step: 3
Training loss: 2.2197136878967285
Validation loss: 1.899664330226119

Epoch: 6| Step: 4
Training loss: 1.4806795120239258
Validation loss: 1.902924979886701

Epoch: 6| Step: 5
Training loss: 1.9786272048950195
Validation loss: 1.90227561484101

Epoch: 6| Step: 6
Training loss: 1.9017635583877563
Validation loss: 1.8943056137331071

Epoch: 6| Step: 7
Training loss: 2.008105993270874
Validation loss: 1.9043950701272616

Epoch: 6| Step: 8
Training loss: 1.7122868299484253
Validation loss: 1.899622530065557

Epoch: 6| Step: 9
Training loss: 1.8633781671524048
Validation loss: 1.8861655394236247

Epoch: 6| Step: 10
Training loss: 1.8396177291870117
Validation loss: 1.8998022207649805

Epoch: 6| Step: 11
Training loss: 1.4529924392700195
Validation loss: 1.8795939286549885

Epoch: 6| Step: 12
Training loss: 1.8293254375457764
Validation loss: 1.8969362807530228

Epoch: 6| Step: 13
Training loss: 1.217806339263916
Validation loss: 1.912722800367622

Epoch: 207| Step: 0
Training loss: 1.7966904640197754
Validation loss: 1.8615018680531492

Epoch: 6| Step: 1
Training loss: 1.9792289733886719
Validation loss: 1.888305506398601

Epoch: 6| Step: 2
Training loss: 1.7632594108581543
Validation loss: 1.8845088917721984

Epoch: 6| Step: 3
Training loss: 2.4754137992858887
Validation loss: 1.8889262599329795

Epoch: 6| Step: 4
Training loss: 2.1117701530456543
Validation loss: 1.8873413378192532

Epoch: 6| Step: 5
Training loss: 2.1388580799102783
Validation loss: 1.882501689336633

Epoch: 6| Step: 6
Training loss: 1.6772489547729492
Validation loss: 1.878403223970885

Epoch: 6| Step: 7
Training loss: 2.1001038551330566
Validation loss: 1.8963467754343504

Epoch: 6| Step: 8
Training loss: 1.3721556663513184
Validation loss: 1.8501873798267816

Epoch: 6| Step: 9
Training loss: 1.8220770359039307
Validation loss: 1.8819274107615154

Epoch: 6| Step: 10
Training loss: 2.1176958084106445
Validation loss: 1.8649126214365805

Epoch: 6| Step: 11
Training loss: 1.1720259189605713
Validation loss: 1.9183993659993654

Epoch: 6| Step: 12
Training loss: 1.1946310997009277
Validation loss: 1.8648686306450957

Epoch: 6| Step: 13
Training loss: 1.6289490461349487
Validation loss: 1.8612514875268424

Epoch: 208| Step: 0
Training loss: 1.0599348545074463
Validation loss: 1.906828918764668

Epoch: 6| Step: 1
Training loss: 2.4527268409729004
Validation loss: 1.870425824196108

Epoch: 6| Step: 2
Training loss: 1.7905791997909546
Validation loss: 1.8820531727165304

Epoch: 6| Step: 3
Training loss: 1.5433789491653442
Validation loss: 1.8841503691929642

Epoch: 6| Step: 4
Training loss: 1.938136100769043
Validation loss: 1.8897112133682414

Epoch: 6| Step: 5
Training loss: 1.5172903537750244
Validation loss: 1.8798327369074668

Epoch: 6| Step: 6
Training loss: 1.470343828201294
Validation loss: 1.8949577923743957

Epoch: 6| Step: 7
Training loss: 2.099912166595459
Validation loss: 1.883813323513154

Epoch: 6| Step: 8
Training loss: 1.4016237258911133
Validation loss: 1.879164376566487

Epoch: 6| Step: 9
Training loss: 2.3798255920410156
Validation loss: 1.8975724481767224

Epoch: 6| Step: 10
Training loss: 1.6707558631896973
Validation loss: 1.909769537628338

Epoch: 6| Step: 11
Training loss: 2.0412912368774414
Validation loss: 1.9260566080770185

Epoch: 6| Step: 12
Training loss: 2.176490306854248
Validation loss: 1.9287453928301412

Epoch: 6| Step: 13
Training loss: 1.8296551704406738
Validation loss: 1.8898654227615685

Epoch: 209| Step: 0
Training loss: 1.620933175086975
Validation loss: 1.9569873527813983

Epoch: 6| Step: 1
Training loss: 2.047738552093506
Validation loss: 1.917787908225931

Epoch: 6| Step: 2
Training loss: 2.2258548736572266
Validation loss: 1.9278208953078075

Epoch: 6| Step: 3
Training loss: 1.8233028650283813
Validation loss: 1.9216686333379438

Epoch: 6| Step: 4
Training loss: 1.9086635112762451
Validation loss: 1.9008944137122041

Epoch: 6| Step: 5
Training loss: 1.6366828680038452
Validation loss: 1.9291789198434481

Epoch: 6| Step: 6
Training loss: 2.3815743923187256
Validation loss: 1.9317277733997633

Epoch: 6| Step: 7
Training loss: 1.679706335067749
Validation loss: 1.915975957788447

Epoch: 6| Step: 8
Training loss: 1.5766502618789673
Validation loss: 1.9225235446806876

Epoch: 6| Step: 9
Training loss: 1.4839251041412354
Validation loss: 1.9100405016253073

Epoch: 6| Step: 10
Training loss: 1.7761895656585693
Validation loss: 1.9281838145307315

Epoch: 6| Step: 11
Training loss: 1.2263498306274414
Validation loss: 1.9059212259067002

Epoch: 6| Step: 12
Training loss: 2.0060555934906006
Validation loss: 1.92699985478514

Epoch: 6| Step: 13
Training loss: 2.035153388977051
Validation loss: 1.9042792038250995

Epoch: 210| Step: 0
Training loss: 1.9334827661514282
Validation loss: 1.8820498246018604

Epoch: 6| Step: 1
Training loss: 1.8059613704681396
Validation loss: 1.8710901134757585

Epoch: 6| Step: 2
Training loss: 1.7549647092819214
Validation loss: 1.8679472861751434

Epoch: 6| Step: 3
Training loss: 1.9344810247421265
Validation loss: 1.8984573451421594

Epoch: 6| Step: 4
Training loss: 2.7505011558532715
Validation loss: 1.8967302255733038

Epoch: 6| Step: 5
Training loss: 1.5941662788391113
Validation loss: 1.8651173806959582

Epoch: 6| Step: 6
Training loss: 2.19442081451416
Validation loss: 1.908484887051326

Epoch: 6| Step: 7
Training loss: 1.2007665634155273
Validation loss: 1.8948753162096905

Epoch: 6| Step: 8
Training loss: 2.1650257110595703
Validation loss: 1.8531581496679654

Epoch: 6| Step: 9
Training loss: 1.7397751808166504
Validation loss: 1.8970926833409134

Epoch: 6| Step: 10
Training loss: 1.403552532196045
Validation loss: 1.885624135694196

Epoch: 6| Step: 11
Training loss: 1.3672964572906494
Validation loss: 1.912946747195336

Epoch: 6| Step: 12
Training loss: 1.8785898685455322
Validation loss: 1.864948667505736

Epoch: 6| Step: 13
Training loss: 1.7323877811431885
Validation loss: 1.883014863537204

Epoch: 211| Step: 0
Training loss: 1.700035572052002
Validation loss: 1.8749491732607606

Epoch: 6| Step: 1
Training loss: 1.6321439743041992
Validation loss: 1.9016818820789296

Epoch: 6| Step: 2
Training loss: 1.819138765335083
Validation loss: 1.8879213512584727

Epoch: 6| Step: 3
Training loss: 1.625288486480713
Validation loss: 1.8818294925074424

Epoch: 6| Step: 4
Training loss: 1.892824649810791
Validation loss: 1.9060642834632628

Epoch: 6| Step: 5
Training loss: 2.5154471397399902
Validation loss: 1.8928825880891533

Epoch: 6| Step: 6
Training loss: 1.485175371170044
Validation loss: 1.8585306162475257

Epoch: 6| Step: 7
Training loss: 2.034791946411133
Validation loss: 1.880880981363276

Epoch: 6| Step: 8
Training loss: 1.776344895362854
Validation loss: 1.8549778564001924

Epoch: 6| Step: 9
Training loss: 2.033560037612915
Validation loss: 1.8849168157064786

Epoch: 6| Step: 10
Training loss: 1.8618526458740234
Validation loss: 1.8621657945776497

Epoch: 6| Step: 11
Training loss: 1.6779273748397827
Validation loss: 1.8858601380419988

Epoch: 6| Step: 12
Training loss: 1.3683338165283203
Validation loss: 1.8716689079038558

Epoch: 6| Step: 13
Training loss: 1.4864686727523804
Validation loss: 1.8853353197856615

Epoch: 212| Step: 0
Training loss: 2.2823634147644043
Validation loss: 1.8837878537434403

Epoch: 6| Step: 1
Training loss: 1.7203819751739502
Validation loss: 1.8981976252730175

Epoch: 6| Step: 2
Training loss: 1.5540812015533447
Validation loss: 1.8966839941599036

Epoch: 6| Step: 3
Training loss: 2.098684310913086
Validation loss: 1.8952730919725151

Epoch: 6| Step: 4
Training loss: 1.2924147844314575
Validation loss: 1.9075400252496042

Epoch: 6| Step: 5
Training loss: 1.8035390377044678
Validation loss: 1.909282317725561

Epoch: 6| Step: 6
Training loss: 1.330817461013794
Validation loss: 1.9033710687391219

Epoch: 6| Step: 7
Training loss: 1.2795051336288452
Validation loss: 1.9069761871009745

Epoch: 6| Step: 8
Training loss: 2.0091819763183594
Validation loss: 1.9255413316911267

Epoch: 6| Step: 9
Training loss: 1.8314752578735352
Validation loss: 1.9215403320968791

Epoch: 6| Step: 10
Training loss: 1.3193325996398926
Validation loss: 1.9305672825023692

Epoch: 6| Step: 11
Training loss: 2.451955795288086
Validation loss: 1.907459633324736

Epoch: 6| Step: 12
Training loss: 1.9723435640335083
Validation loss: 1.9107378528964134

Epoch: 6| Step: 13
Training loss: 1.9074311256408691
Validation loss: 1.890127860089784

Epoch: 213| Step: 0
Training loss: 1.094563364982605
Validation loss: 1.9411024919120214

Epoch: 6| Step: 1
Training loss: 1.8536608219146729
Validation loss: 1.9438877733804847

Epoch: 6| Step: 2
Training loss: 1.7496106624603271
Validation loss: 1.9154718909212338

Epoch: 6| Step: 3
Training loss: 2.307368755340576
Validation loss: 1.9044560040197065

Epoch: 6| Step: 4
Training loss: 1.4977011680603027
Validation loss: 1.9328247013912405

Epoch: 6| Step: 5
Training loss: 1.5320193767547607
Validation loss: 1.9279724859422254

Epoch: 6| Step: 6
Training loss: 1.7572485208511353
Validation loss: 1.9262767453347482

Epoch: 6| Step: 7
Training loss: 2.3160343170166016
Validation loss: 1.9615259901169808

Epoch: 6| Step: 8
Training loss: 1.7354583740234375
Validation loss: 1.9124006673853884

Epoch: 6| Step: 9
Training loss: 2.0588924884796143
Validation loss: 1.9145375490188599

Epoch: 6| Step: 10
Training loss: 1.5999505519866943
Validation loss: 1.9050718071640178

Epoch: 6| Step: 11
Training loss: 2.0144927501678467
Validation loss: 1.9200134610617032

Epoch: 6| Step: 12
Training loss: 1.9705723524093628
Validation loss: 1.8771252811595958

Epoch: 6| Step: 13
Training loss: 1.6686850786209106
Validation loss: 1.8674917272342149

Epoch: 214| Step: 0
Training loss: 1.8437410593032837
Validation loss: 1.9432628539300734

Epoch: 6| Step: 1
Training loss: 1.6654945611953735
Validation loss: 1.8956753617973738

Epoch: 6| Step: 2
Training loss: 2.272505760192871
Validation loss: 1.8810738722483318

Epoch: 6| Step: 3
Training loss: 1.9812209606170654
Validation loss: 1.8851758613381335

Epoch: 6| Step: 4
Training loss: 1.5788015127182007
Validation loss: 1.8794883117880872

Epoch: 6| Step: 5
Training loss: 1.6982420682907104
Validation loss: 1.8825380635517899

Epoch: 6| Step: 6
Training loss: 2.12540340423584
Validation loss: 1.873899298329507

Epoch: 6| Step: 7
Training loss: 1.5233182907104492
Validation loss: 1.861296812693278

Epoch: 6| Step: 8
Training loss: 1.635825276374817
Validation loss: 1.8668761637903029

Epoch: 6| Step: 9
Training loss: 1.6696546077728271
Validation loss: 1.900245851086032

Epoch: 6| Step: 10
Training loss: 1.8814738988876343
Validation loss: 1.8708805653356737

Epoch: 6| Step: 11
Training loss: 1.732604742050171
Validation loss: 1.8567807751317178

Epoch: 6| Step: 12
Training loss: 1.860573172569275
Validation loss: 1.8649150876588718

Epoch: 6| Step: 13
Training loss: 2.260335683822632
Validation loss: 1.8861271719778738

Epoch: 215| Step: 0
Training loss: 1.3328614234924316
Validation loss: 1.8928946705274685

Epoch: 6| Step: 1
Training loss: 2.0223968029022217
Validation loss: 1.8790450365312639

Epoch: 6| Step: 2
Training loss: 1.8471534252166748
Validation loss: 1.8697842564634097

Epoch: 6| Step: 3
Training loss: 1.5576834678649902
Validation loss: 1.8890898086691414

Epoch: 6| Step: 4
Training loss: 1.9064950942993164
Validation loss: 1.9010051386330717

Epoch: 6| Step: 5
Training loss: 1.6832222938537598
Validation loss: 1.8925786710554553

Epoch: 6| Step: 6
Training loss: 2.2281126976013184
Validation loss: 1.8692146116687405

Epoch: 6| Step: 7
Training loss: 1.9478954076766968
Validation loss: 1.8988941202881515

Epoch: 6| Step: 8
Training loss: 1.8622429370880127
Validation loss: 1.8675411670438704

Epoch: 6| Step: 9
Training loss: 1.1224596500396729
Validation loss: 1.8724507465157458

Epoch: 6| Step: 10
Training loss: 1.9626978635787964
Validation loss: 1.8890610971758444

Epoch: 6| Step: 11
Training loss: 2.384401321411133
Validation loss: 1.9060295012689406

Epoch: 6| Step: 12
Training loss: 1.105279564857483
Validation loss: 1.9209754774647374

Epoch: 6| Step: 13
Training loss: 1.832194447517395
Validation loss: 1.9088554138778357

Epoch: 216| Step: 0
Training loss: 1.835362434387207
Validation loss: 1.8923469615238968

Epoch: 6| Step: 1
Training loss: 1.788341999053955
Validation loss: 1.9238578568222702

Epoch: 6| Step: 2
Training loss: 1.7721962928771973
Validation loss: 1.9085170658685828

Epoch: 6| Step: 3
Training loss: 2.000514507293701
Validation loss: 1.8808866162453928

Epoch: 6| Step: 4
Training loss: 1.8813130855560303
Validation loss: 1.8614711787111016

Epoch: 6| Step: 5
Training loss: 1.7107665538787842
Validation loss: 1.8795884373367473

Epoch: 6| Step: 6
Training loss: 1.8771551847457886
Validation loss: 1.8924487842026578

Epoch: 6| Step: 7
Training loss: 1.3811402320861816
Validation loss: 1.8821294922982492

Epoch: 6| Step: 8
Training loss: 1.8461626768112183
Validation loss: 1.8563895302434121

Epoch: 6| Step: 9
Training loss: 1.7330853939056396
Validation loss: 1.9306729237238567

Epoch: 6| Step: 10
Training loss: 1.4741883277893066
Validation loss: 1.8577491416726062

Epoch: 6| Step: 11
Training loss: 1.921173095703125
Validation loss: 1.87632800814926

Epoch: 6| Step: 12
Training loss: 1.8989825248718262
Validation loss: 1.8958816989775626

Epoch: 6| Step: 13
Training loss: 1.604237675666809
Validation loss: 1.8727116277140956

Epoch: 217| Step: 0
Training loss: 1.683335304260254
Validation loss: 1.9263429949360509

Epoch: 6| Step: 1
Training loss: 1.9440116882324219
Validation loss: 1.8586140345501643

Epoch: 6| Step: 2
Training loss: 1.6801859140396118
Validation loss: 1.8927373834835586

Epoch: 6| Step: 3
Training loss: 2.0117883682250977
Validation loss: 1.8680869956170358

Epoch: 6| Step: 4
Training loss: 1.7229816913604736
Validation loss: 1.8806435062039284

Epoch: 6| Step: 5
Training loss: 1.6825635433197021
Validation loss: 1.8877902748764201

Epoch: 6| Step: 6
Training loss: 1.6362988948822021
Validation loss: 1.8723475984347764

Epoch: 6| Step: 7
Training loss: 1.8835111856460571
Validation loss: 1.8767161228323495

Epoch: 6| Step: 8
Training loss: 1.9292175769805908
Validation loss: 1.8739844111986057

Epoch: 6| Step: 9
Training loss: 1.9542542695999146
Validation loss: 1.8456194041877665

Epoch: 6| Step: 10
Training loss: 1.8993184566497803
Validation loss: 1.883987226793843

Epoch: 6| Step: 11
Training loss: 1.2957308292388916
Validation loss: 1.878587939405954

Epoch: 6| Step: 12
Training loss: 1.4745709896087646
Validation loss: 1.9023438628001879

Epoch: 6| Step: 13
Training loss: 2.390713691711426
Validation loss: 1.8678025891703944

Epoch: 218| Step: 0
Training loss: 1.4782108068466187
Validation loss: 1.8845876801398493

Epoch: 6| Step: 1
Training loss: 1.2632107734680176
Validation loss: 1.8885446466425413

Epoch: 6| Step: 2
Training loss: 2.029155969619751
Validation loss: 1.8561569593286003

Epoch: 6| Step: 3
Training loss: 1.3634212017059326
Validation loss: 1.8840549889431204

Epoch: 6| Step: 4
Training loss: 2.541750907897949
Validation loss: 1.8744343185937533

Epoch: 6| Step: 5
Training loss: 2.0188515186309814
Validation loss: 1.882338236736995

Epoch: 6| Step: 6
Training loss: 2.9091789722442627
Validation loss: 1.8890800129982732

Epoch: 6| Step: 7
Training loss: 1.8024954795837402
Validation loss: 1.8193243626625306

Epoch: 6| Step: 8
Training loss: 1.348766803741455
Validation loss: 1.8704045805879819

Epoch: 6| Step: 9
Training loss: 1.180956244468689
Validation loss: 1.8687026667338547

Epoch: 6| Step: 10
Training loss: 1.931962013244629
Validation loss: 1.86320052864731

Epoch: 6| Step: 11
Training loss: 1.5116671323776245
Validation loss: 1.8878378752739198

Epoch: 6| Step: 12
Training loss: 2.187548875808716
Validation loss: 1.87474609703146

Epoch: 6| Step: 13
Training loss: 1.1824688911437988
Validation loss: 1.881174418234056

Epoch: 219| Step: 0
Training loss: 1.8979403972625732
Validation loss: 1.893129705100931

Epoch: 6| Step: 1
Training loss: 1.5391244888305664
Validation loss: 1.8568098968075168

Epoch: 6| Step: 2
Training loss: 2.2856411933898926
Validation loss: 1.895109430436165

Epoch: 6| Step: 3
Training loss: 1.9748570919036865
Validation loss: 1.8771406976125573

Epoch: 6| Step: 4
Training loss: 1.602241039276123
Validation loss: 1.867436690997052

Epoch: 6| Step: 5
Training loss: 2.8844332695007324
Validation loss: 1.8951399531415714

Epoch: 6| Step: 6
Training loss: 1.7556320428848267
Validation loss: 1.9104184771096835

Epoch: 6| Step: 7
Training loss: 1.5852084159851074
Validation loss: 1.869352859835471

Epoch: 6| Step: 8
Training loss: 1.453113079071045
Validation loss: 1.887842115535531

Epoch: 6| Step: 9
Training loss: 1.8577136993408203
Validation loss: 1.891967833683055

Epoch: 6| Step: 10
Training loss: 1.8422640562057495
Validation loss: 1.8634258803500925

Epoch: 6| Step: 11
Training loss: 1.906190037727356
Validation loss: 1.894734295465613

Epoch: 6| Step: 12
Training loss: 1.0962255001068115
Validation loss: 1.8821819815584409

Epoch: 6| Step: 13
Training loss: 1.1272063255310059
Validation loss: 1.8708860912630636

Epoch: 220| Step: 0
Training loss: 2.008061408996582
Validation loss: 1.8713708462253693

Epoch: 6| Step: 1
Training loss: 1.901136875152588
Validation loss: 1.9058055621321484

Epoch: 6| Step: 2
Training loss: 1.8331904411315918
Validation loss: 1.9037623584911387

Epoch: 6| Step: 3
Training loss: 1.528080701828003
Validation loss: 1.886731211857129

Epoch: 6| Step: 4
Training loss: 1.2625653743743896
Validation loss: 1.878708634325253

Epoch: 6| Step: 5
Training loss: 1.1749613285064697
Validation loss: 1.8962687446225075

Epoch: 6| Step: 6
Training loss: 1.719695806503296
Validation loss: 1.8962465460582445

Epoch: 6| Step: 7
Training loss: 1.289913535118103
Validation loss: 1.8852983238876506

Epoch: 6| Step: 8
Training loss: 1.9189473390579224
Validation loss: 1.9285178389600528

Epoch: 6| Step: 9
Training loss: 1.511975646018982
Validation loss: 1.8620767465201757

Epoch: 6| Step: 10
Training loss: 2.855942487716675
Validation loss: 1.9058230820522513

Epoch: 6| Step: 11
Training loss: 2.066206216812134
Validation loss: 1.923595142620866

Epoch: 6| Step: 12
Training loss: 2.044661521911621
Validation loss: 1.9120490038266746

Epoch: 6| Step: 13
Training loss: 1.5997956991195679
Validation loss: 1.8899582227071126

Epoch: 221| Step: 0
Training loss: 1.9758317470550537
Validation loss: 1.9047866098342403

Epoch: 6| Step: 1
Training loss: 1.785549521446228
Validation loss: 1.9033134880886282

Epoch: 6| Step: 2
Training loss: 1.608046293258667
Validation loss: 1.9121047207104263

Epoch: 6| Step: 3
Training loss: 1.9642215967178345
Validation loss: 1.8863373443644533

Epoch: 6| Step: 4
Training loss: 1.7704219818115234
Validation loss: 1.9319859884118522

Epoch: 6| Step: 5
Training loss: 1.5293824672698975
Validation loss: 1.8771832578925676

Epoch: 6| Step: 6
Training loss: 1.9364113807678223
Validation loss: 1.8573440505612282

Epoch: 6| Step: 7
Training loss: 2.119349718093872
Validation loss: 1.9047994562374648

Epoch: 6| Step: 8
Training loss: 2.1567420959472656
Validation loss: 1.8698931829903715

Epoch: 6| Step: 9
Training loss: 1.5106775760650635
Validation loss: 1.8763489479659705

Epoch: 6| Step: 10
Training loss: 1.6219167709350586
Validation loss: 1.8752916371950539

Epoch: 6| Step: 11
Training loss: 2.070247173309326
Validation loss: 1.9197884144321564

Epoch: 6| Step: 12
Training loss: 1.4709162712097168
Validation loss: 1.8452131261107743

Epoch: 6| Step: 13
Training loss: 1.0437668561935425
Validation loss: 1.8660458057157454

Epoch: 222| Step: 0
Training loss: 1.7378517389297485
Validation loss: 1.8992394016635032

Epoch: 6| Step: 1
Training loss: 1.6901156902313232
Validation loss: 1.8717009444390573

Epoch: 6| Step: 2
Training loss: 2.257880926132202
Validation loss: 1.8506362322838075

Epoch: 6| Step: 3
Training loss: 1.8001720905303955
Validation loss: 1.8853943322294502

Epoch: 6| Step: 4
Training loss: 2.131127119064331
Validation loss: 1.876742680867513

Epoch: 6| Step: 5
Training loss: 1.0464833974838257
Validation loss: 1.869881106961158

Epoch: 6| Step: 6
Training loss: 1.9159175157546997
Validation loss: 1.8533154572210004

Epoch: 6| Step: 7
Training loss: 1.5023632049560547
Validation loss: 1.8813416278490456

Epoch: 6| Step: 8
Training loss: 2.098971366882324
Validation loss: 1.8673180328902377

Epoch: 6| Step: 9
Training loss: 1.2020494937896729
Validation loss: 1.8962838213930848

Epoch: 6| Step: 10
Training loss: 2.4306180477142334
Validation loss: 1.8638391007659256

Epoch: 6| Step: 11
Training loss: 1.8888614177703857
Validation loss: 1.8858605123335315

Epoch: 6| Step: 12
Training loss: 1.7574595212936401
Validation loss: 1.8684060137758973

Epoch: 6| Step: 13
Training loss: 0.9634681344032288
Validation loss: 1.8914263632989698

Epoch: 223| Step: 0
Training loss: 1.782927393913269
Validation loss: 1.9010981821244763

Epoch: 6| Step: 1
Training loss: 1.4049509763717651
Validation loss: 1.868366224791414

Epoch: 6| Step: 2
Training loss: 1.5055530071258545
Validation loss: 1.8644878043923327

Epoch: 6| Step: 3
Training loss: 1.5482959747314453
Validation loss: 1.9009609094230078

Epoch: 6| Step: 4
Training loss: 1.9602606296539307
Validation loss: 1.867445324056892

Epoch: 6| Step: 5
Training loss: 1.3585586547851562
Validation loss: 1.882410954403621

Epoch: 6| Step: 6
Training loss: 1.254335641860962
Validation loss: 1.87515135734312

Epoch: 6| Step: 7
Training loss: 1.5455551147460938
Validation loss: 1.9232332065541258

Epoch: 6| Step: 8
Training loss: 2.8081302642822266
Validation loss: 1.9244992835547334

Epoch: 6| Step: 9
Training loss: 1.7829591035842896
Validation loss: 1.8973264027667303

Epoch: 6| Step: 10
Training loss: 2.2668023109436035
Validation loss: 1.8999068685757217

Epoch: 6| Step: 11
Training loss: 1.3415114879608154
Validation loss: 1.9091779455061881

Epoch: 6| Step: 12
Training loss: 2.1232802867889404
Validation loss: 1.9045111774116434

Epoch: 6| Step: 13
Training loss: 2.295135498046875
Validation loss: 1.9445981107732302

Epoch: 224| Step: 0
Training loss: 1.1273550987243652
Validation loss: 1.87574972773111

Epoch: 6| Step: 1
Training loss: 2.277292251586914
Validation loss: 1.883655813432509

Epoch: 6| Step: 2
Training loss: 2.3393678665161133
Validation loss: 1.89731599438575

Epoch: 6| Step: 3
Training loss: 1.6183198690414429
Validation loss: 1.9128028372282624

Epoch: 6| Step: 4
Training loss: 1.222298502922058
Validation loss: 1.8763842121247323

Epoch: 6| Step: 5
Training loss: 1.54241144657135
Validation loss: 1.8936597044749925

Epoch: 6| Step: 6
Training loss: 2.6082847118377686
Validation loss: 1.8626548115925123

Epoch: 6| Step: 7
Training loss: 2.004955291748047
Validation loss: 1.890372436533692

Epoch: 6| Step: 8
Training loss: 1.2914137840270996
Validation loss: 1.8726192110328264

Epoch: 6| Step: 9
Training loss: 1.6131815910339355
Validation loss: 1.861590886628756

Epoch: 6| Step: 10
Training loss: 1.6505165100097656
Validation loss: 1.8588521044741395

Epoch: 6| Step: 11
Training loss: 1.6243298053741455
Validation loss: 1.8446226709632463

Epoch: 6| Step: 12
Training loss: 1.8186135292053223
Validation loss: 1.8597165781964538

Epoch: 6| Step: 13
Training loss: 1.5396077632904053
Validation loss: 1.8549448725997761

Epoch: 225| Step: 0
Training loss: 1.8885174989700317
Validation loss: 1.845890711712581

Epoch: 6| Step: 1
Training loss: 2.4675955772399902
Validation loss: 1.8640101699418918

Epoch: 6| Step: 2
Training loss: 1.5769357681274414
Validation loss: 1.8801856374227872

Epoch: 6| Step: 3
Training loss: 1.3765990734100342
Validation loss: 1.8625785407199655

Epoch: 6| Step: 4
Training loss: 1.358454704284668
Validation loss: 1.8441882851303264

Epoch: 6| Step: 5
Training loss: 2.616971969604492
Validation loss: 1.8563063183138448

Epoch: 6| Step: 6
Training loss: 1.7757691144943237
Validation loss: 1.8602438972842308

Epoch: 6| Step: 7
Training loss: 1.5750789642333984
Validation loss: 1.8661247402109125

Epoch: 6| Step: 8
Training loss: 1.3746715784072876
Validation loss: 1.8443663068996963

Epoch: 6| Step: 9
Training loss: 2.37652850151062
Validation loss: 1.898660186798342

Epoch: 6| Step: 10
Training loss: 1.7690738439559937
Validation loss: 1.8738039949888825

Epoch: 6| Step: 11
Training loss: 1.5131840705871582
Validation loss: 1.8384989179590696

Epoch: 6| Step: 12
Training loss: 1.9374802112579346
Validation loss: 1.8748677712614819

Epoch: 6| Step: 13
Training loss: 0.9344667792320251
Validation loss: 1.8680005714457522

Epoch: 226| Step: 0
Training loss: 1.8883414268493652
Validation loss: 1.8672558915230535

Epoch: 6| Step: 1
Training loss: 1.6784758567810059
Validation loss: 1.8612426827030797

Epoch: 6| Step: 2
Training loss: 2.3745439052581787
Validation loss: 1.8778865824463546

Epoch: 6| Step: 3
Training loss: 1.977346658706665
Validation loss: 1.8521227964790918

Epoch: 6| Step: 4
Training loss: 1.7222871780395508
Validation loss: 1.8862352512216056

Epoch: 6| Step: 5
Training loss: 1.776607871055603
Validation loss: 1.9180615358455206

Epoch: 6| Step: 6
Training loss: 1.4108901023864746
Validation loss: 1.9188194608175626

Epoch: 6| Step: 7
Training loss: 1.8378764390945435
Validation loss: 1.895198272120568

Epoch: 6| Step: 8
Training loss: 1.638009786605835
Validation loss: 1.9149510219532957

Epoch: 6| Step: 9
Training loss: 1.8687233924865723
Validation loss: 1.9049521518009964

Epoch: 6| Step: 10
Training loss: 1.6088446378707886
Validation loss: 1.9304046682132188

Epoch: 6| Step: 11
Training loss: 1.9573078155517578
Validation loss: 1.9313079387910905

Epoch: 6| Step: 12
Training loss: 1.2481215000152588
Validation loss: 1.902981860663301

Epoch: 6| Step: 13
Training loss: 1.4060096740722656
Validation loss: 1.916005180728051

Epoch: 227| Step: 0
Training loss: 1.8998445272445679
Validation loss: 1.885266368107129

Epoch: 6| Step: 1
Training loss: 1.581709384918213
Validation loss: 1.9075252586795437

Epoch: 6| Step: 2
Training loss: 1.4103996753692627
Validation loss: 1.8436986169507426

Epoch: 6| Step: 3
Training loss: 2.5759825706481934
Validation loss: 1.8572704997113956

Epoch: 6| Step: 4
Training loss: 1.5268748998641968
Validation loss: 1.872401229796871

Epoch: 6| Step: 5
Training loss: 1.0679280757904053
Validation loss: 1.8357300091815252

Epoch: 6| Step: 6
Training loss: 1.6024285554885864
Validation loss: 1.857227941995026

Epoch: 6| Step: 7
Training loss: 2.1239986419677734
Validation loss: 1.8489114533188522

Epoch: 6| Step: 8
Training loss: 2.1617531776428223
Validation loss: 1.8415322637045255

Epoch: 6| Step: 9
Training loss: 1.5897928476333618
Validation loss: 1.8648133508620723

Epoch: 6| Step: 10
Training loss: 1.8940956592559814
Validation loss: 1.8517593312007126

Epoch: 6| Step: 11
Training loss: 1.7308568954467773
Validation loss: 1.8473319135686403

Epoch: 6| Step: 12
Training loss: 2.055953025817871
Validation loss: 1.839740345554967

Epoch: 6| Step: 13
Training loss: 1.249224305152893
Validation loss: 1.873474838913128

Epoch: 228| Step: 0
Training loss: 1.3927558660507202
Validation loss: 1.8753157008078791

Epoch: 6| Step: 1
Training loss: 1.6154060363769531
Validation loss: 1.8595514271848945

Epoch: 6| Step: 2
Training loss: 2.024977207183838
Validation loss: 1.851084711731121

Epoch: 6| Step: 3
Training loss: 1.9668736457824707
Validation loss: 1.847170037607993

Epoch: 6| Step: 4
Training loss: 0.9372726678848267
Validation loss: 1.8630236130888744

Epoch: 6| Step: 5
Training loss: 1.434761881828308
Validation loss: 1.8807629539120583

Epoch: 6| Step: 6
Training loss: 1.168310284614563
Validation loss: 1.8751084176442956

Epoch: 6| Step: 7
Training loss: 1.6881970167160034
Validation loss: 1.8389974486443303

Epoch: 6| Step: 8
Training loss: 1.8427832126617432
Validation loss: 1.8741455590853127

Epoch: 6| Step: 9
Training loss: 2.739474296569824
Validation loss: 1.879056957460219

Epoch: 6| Step: 10
Training loss: 1.9405213594436646
Validation loss: 1.8670102421955397

Epoch: 6| Step: 11
Training loss: 1.7549548149108887
Validation loss: 1.8726973636175996

Epoch: 6| Step: 12
Training loss: 2.6002745628356934
Validation loss: 1.8488226936709495

Epoch: 6| Step: 13
Training loss: 1.3098130226135254
Validation loss: 1.8763818894663165

Epoch: 229| Step: 0
Training loss: 1.5500574111938477
Validation loss: 1.8984224539931103

Epoch: 6| Step: 1
Training loss: 1.66609525680542
Validation loss: 1.884890692208403

Epoch: 6| Step: 2
Training loss: 1.9897284507751465
Validation loss: 1.8956379967351114

Epoch: 6| Step: 3
Training loss: 1.7247145175933838
Validation loss: 1.8560003516494588

Epoch: 6| Step: 4
Training loss: 1.3361485004425049
Validation loss: 1.8683912895059074

Epoch: 6| Step: 5
Training loss: 2.7010693550109863
Validation loss: 1.8843567973823958

Epoch: 6| Step: 6
Training loss: 1.2364634275436401
Validation loss: 1.8880735251211351

Epoch: 6| Step: 7
Training loss: 2.0277414321899414
Validation loss: 1.8749179199177732

Epoch: 6| Step: 8
Training loss: 2.2201905250549316
Validation loss: 1.8863042067455988

Epoch: 6| Step: 9
Training loss: 2.2220664024353027
Validation loss: 1.8780849313223233

Epoch: 6| Step: 10
Training loss: 2.0642666816711426
Validation loss: 1.8499520363346222

Epoch: 6| Step: 11
Training loss: 1.0647273063659668
Validation loss: 1.8560207672016595

Epoch: 6| Step: 12
Training loss: 1.0854833126068115
Validation loss: 1.8707514270659416

Epoch: 6| Step: 13
Training loss: 1.5531842708587646
Validation loss: 1.8661751542040097

Epoch: 230| Step: 0
Training loss: 1.815686821937561
Validation loss: 1.8416345048976202

Epoch: 6| Step: 1
Training loss: 2.160080909729004
Validation loss: 1.84600951081963

Epoch: 6| Step: 2
Training loss: 2.462414503097534
Validation loss: 1.8648799850094704

Epoch: 6| Step: 3
Training loss: 1.530137062072754
Validation loss: 1.8632794310969691

Epoch: 6| Step: 4
Training loss: 1.6826450824737549
Validation loss: 1.8607030812130179

Epoch: 6| Step: 5
Training loss: 2.223813533782959
Validation loss: 1.8877914541511125

Epoch: 6| Step: 6
Training loss: 1.2201755046844482
Validation loss: 1.8654472148546608

Epoch: 6| Step: 7
Training loss: 1.54849112033844
Validation loss: 1.8825119695355814

Epoch: 6| Step: 8
Training loss: 1.8147889375686646
Validation loss: 1.878375768661499

Epoch: 6| Step: 9
Training loss: 1.7588865756988525
Validation loss: 1.8632047291724914

Epoch: 6| Step: 10
Training loss: 1.8087929487228394
Validation loss: 1.8719834358461442

Epoch: 6| Step: 11
Training loss: 1.187108039855957
Validation loss: 1.8529848219245992

Epoch: 6| Step: 12
Training loss: 1.7593920230865479
Validation loss: 1.8271084754697737

Epoch: 6| Step: 13
Training loss: 1.2705473899841309
Validation loss: 1.8555869671606249

Epoch: 231| Step: 0
Training loss: 0.6292511224746704
Validation loss: 1.8832876490008446

Epoch: 6| Step: 1
Training loss: 1.6692554950714111
Validation loss: 1.859131710503691

Epoch: 6| Step: 2
Training loss: 1.7735506296157837
Validation loss: 1.8991063499963412

Epoch: 6| Step: 3
Training loss: 1.2785673141479492
Validation loss: 1.890054533558507

Epoch: 6| Step: 4
Training loss: 1.5078744888305664
Validation loss: 1.8078034334285285

Epoch: 6| Step: 5
Training loss: 2.5830836296081543
Validation loss: 1.863152579594684

Epoch: 6| Step: 6
Training loss: 1.6339302062988281
Validation loss: 1.8663094197550127

Epoch: 6| Step: 7
Training loss: 2.8415229320526123
Validation loss: 1.8555882771809895

Epoch: 6| Step: 8
Training loss: 1.504662036895752
Validation loss: 1.849917645095497

Epoch: 6| Step: 9
Training loss: 1.50458562374115
Validation loss: 1.834801709780129

Epoch: 6| Step: 10
Training loss: 2.103170871734619
Validation loss: 1.8644618334308747

Epoch: 6| Step: 11
Training loss: 1.4187626838684082
Validation loss: 1.8418203656391432

Epoch: 6| Step: 12
Training loss: 1.839062213897705
Validation loss: 1.8616393432822278

Epoch: 6| Step: 13
Training loss: 2.461383581161499
Validation loss: 1.8579300859923005

Epoch: 232| Step: 0
Training loss: 1.4169847965240479
Validation loss: 1.8556039538434757

Epoch: 6| Step: 1
Training loss: 1.7018041610717773
Validation loss: 1.862990499824606

Epoch: 6| Step: 2
Training loss: 1.9105924367904663
Validation loss: 1.8340750971148092

Epoch: 6| Step: 3
Training loss: 1.728482723236084
Validation loss: 1.8565459892313967

Epoch: 6| Step: 4
Training loss: 1.981366515159607
Validation loss: 1.8455661189171575

Epoch: 6| Step: 5
Training loss: 1.5223076343536377
Validation loss: 1.9060531598265453

Epoch: 6| Step: 6
Training loss: 1.8942514657974243
Validation loss: 1.8732456507221344

Epoch: 6| Step: 7
Training loss: 1.6764979362487793
Validation loss: 1.877677813653023

Epoch: 6| Step: 8
Training loss: 1.6544805765151978
Validation loss: 1.8736754514837777

Epoch: 6| Step: 9
Training loss: 2.1032872200012207
Validation loss: 1.866761040943925

Epoch: 6| Step: 10
Training loss: 1.9371721744537354
Validation loss: 1.8959502276553903

Epoch: 6| Step: 11
Training loss: 1.5967196226119995
Validation loss: 1.8709788758267638

Epoch: 6| Step: 12
Training loss: 1.2449820041656494
Validation loss: 1.89915479383161

Epoch: 6| Step: 13
Training loss: 1.9963501691818237
Validation loss: 1.8728589345050115

Epoch: 233| Step: 0
Training loss: 1.7318164110183716
Validation loss: 1.8469547481947048

Epoch: 6| Step: 1
Training loss: 1.7023537158966064
Validation loss: 1.8301686151053316

Epoch: 6| Step: 2
Training loss: 1.7712591886520386
Validation loss: 1.8869273675385343

Epoch: 6| Step: 3
Training loss: 1.4619659185409546
Validation loss: 1.8310454763391966

Epoch: 6| Step: 4
Training loss: 2.052837371826172
Validation loss: 1.8327941843258437

Epoch: 6| Step: 5
Training loss: 1.6623847484588623
Validation loss: 1.841175135745797

Epoch: 6| Step: 6
Training loss: 1.6563611030578613
Validation loss: 1.8335235605957687

Epoch: 6| Step: 7
Training loss: 1.1641939878463745
Validation loss: 1.8437095124234435

Epoch: 6| Step: 8
Training loss: 2.1350455284118652
Validation loss: 1.851355375782136

Epoch: 6| Step: 9
Training loss: 1.9056036472320557
Validation loss: 1.8353930698928012

Epoch: 6| Step: 10
Training loss: 1.9993171691894531
Validation loss: 1.838663948479519

Epoch: 6| Step: 11
Training loss: 1.5650736093521118
Validation loss: 1.856197936560518

Epoch: 6| Step: 12
Training loss: 1.392343282699585
Validation loss: 1.8510837888204923

Epoch: 6| Step: 13
Training loss: 2.065809726715088
Validation loss: 1.8537710225710304

Epoch: 234| Step: 0
Training loss: 2.3952786922454834
Validation loss: 1.8567415475845337

Epoch: 6| Step: 1
Training loss: 1.5662215948104858
Validation loss: 1.8397513563914965

Epoch: 6| Step: 2
Training loss: 1.630932092666626
Validation loss: 1.882763442172799

Epoch: 6| Step: 3
Training loss: 2.0407567024230957
Validation loss: 1.8798315371236494

Epoch: 6| Step: 4
Training loss: 1.4685707092285156
Validation loss: 1.8276816734703638

Epoch: 6| Step: 5
Training loss: 1.673445224761963
Validation loss: 1.8161869805346254

Epoch: 6| Step: 6
Training loss: 1.8598003387451172
Validation loss: 1.8515721174978441

Epoch: 6| Step: 7
Training loss: 1.7490615844726562
Validation loss: 1.8419543620078795

Epoch: 6| Step: 8
Training loss: 1.4711885452270508
Validation loss: 1.8799223156385525

Epoch: 6| Step: 9
Training loss: 1.7116339206695557
Validation loss: 1.864194659776585

Epoch: 6| Step: 10
Training loss: 1.1608600616455078
Validation loss: 1.8597246062371038

Epoch: 6| Step: 11
Training loss: 1.7963645458221436
Validation loss: 1.8469094691738006

Epoch: 6| Step: 12
Training loss: 1.6395585536956787
Validation loss: 1.8576940528808101

Epoch: 6| Step: 13
Training loss: 2.122647285461426
Validation loss: 1.849566230209925

Epoch: 235| Step: 0
Training loss: 1.5583771467208862
Validation loss: 1.8639700412750244

Epoch: 6| Step: 1
Training loss: 1.8448303937911987
Validation loss: 1.8474074563672465

Epoch: 6| Step: 2
Training loss: 1.4637947082519531
Validation loss: 1.8506655282871698

Epoch: 6| Step: 3
Training loss: 1.8915460109710693
Validation loss: 1.8410078581943308

Epoch: 6| Step: 4
Training loss: 1.7511379718780518
Validation loss: 1.8745353529530187

Epoch: 6| Step: 5
Training loss: 1.440450668334961
Validation loss: 1.8697598647045832

Epoch: 6| Step: 6
Training loss: 1.9548702239990234
Validation loss: 1.86819685915465

Epoch: 6| Step: 7
Training loss: 2.1232900619506836
Validation loss: 1.8348072190438547

Epoch: 6| Step: 8
Training loss: 1.8221075534820557
Validation loss: 1.8854871091022287

Epoch: 6| Step: 9
Training loss: 2.031747817993164
Validation loss: 1.8399260197916338

Epoch: 6| Step: 10
Training loss: 1.9764043092727661
Validation loss: 1.8211797744997087

Epoch: 6| Step: 11
Training loss: 1.334913730621338
Validation loss: 1.8676060425337924

Epoch: 6| Step: 12
Training loss: 1.2635078430175781
Validation loss: 1.8530897940358808

Epoch: 6| Step: 13
Training loss: 1.3226721286773682
Validation loss: 1.8653127429305867

Epoch: 236| Step: 0
Training loss: 2.4102542400360107
Validation loss: 1.8543088397672098

Epoch: 6| Step: 1
Training loss: 1.7277576923370361
Validation loss: 1.855889448555567

Epoch: 6| Step: 2
Training loss: 1.8415453433990479
Validation loss: 1.825972790359169

Epoch: 6| Step: 3
Training loss: 1.5670363903045654
Validation loss: 1.8483253948150142

Epoch: 6| Step: 4
Training loss: 1.4591755867004395
Validation loss: 1.8388196024843442

Epoch: 6| Step: 5
Training loss: 2.2498397827148438
Validation loss: 1.8467659911801737

Epoch: 6| Step: 6
Training loss: 1.449967861175537
Validation loss: 1.8310667712201354

Epoch: 6| Step: 7
Training loss: 2.0199217796325684
Validation loss: 1.8679431241045716

Epoch: 6| Step: 8
Training loss: 1.69344961643219
Validation loss: 1.8731241290287306

Epoch: 6| Step: 9
Training loss: 2.6085171699523926
Validation loss: 1.8514024954970165

Epoch: 6| Step: 10
Training loss: 0.6676074266433716
Validation loss: 1.842604338481862

Epoch: 6| Step: 11
Training loss: 1.2917442321777344
Validation loss: 1.836978732898671

Epoch: 6| Step: 12
Training loss: 1.4146723747253418
Validation loss: 1.8561385241887902

Epoch: 6| Step: 13
Training loss: 1.0345779657363892
Validation loss: 1.8749177020083192

Epoch: 237| Step: 0
Training loss: 2.1742186546325684
Validation loss: 1.88224026977375

Epoch: 6| Step: 1
Training loss: 1.562813639640808
Validation loss: 1.8398675841669883

Epoch: 6| Step: 2
Training loss: 1.2361197471618652
Validation loss: 1.8534320067333918

Epoch: 6| Step: 3
Training loss: 1.3799219131469727
Validation loss: 1.842249249899259

Epoch: 6| Step: 4
Training loss: 1.9045932292938232
Validation loss: 1.8355998710919452

Epoch: 6| Step: 5
Training loss: 2.3539140224456787
Validation loss: 1.8289460264226443

Epoch: 6| Step: 6
Training loss: 2.411431312561035
Validation loss: 1.849920025435827

Epoch: 6| Step: 7
Training loss: 1.057450771331787
Validation loss: 1.8630432954398535

Epoch: 6| Step: 8
Training loss: 1.6405583620071411
Validation loss: 1.8609738247368925

Epoch: 6| Step: 9
Training loss: 1.592329740524292
Validation loss: 1.8366813082848825

Epoch: 6| Step: 10
Training loss: 1.841517686843872
Validation loss: 1.8519463846760411

Epoch: 6| Step: 11
Training loss: 1.5564441680908203
Validation loss: 1.8512318108671455

Epoch: 6| Step: 12
Training loss: 2.082386016845703
Validation loss: 1.8277888003215994

Epoch: 6| Step: 13
Training loss: 1.0872836112976074
Validation loss: 1.8586680517401746

Epoch: 238| Step: 0
Training loss: 1.4265803098678589
Validation loss: 1.853933927833393

Epoch: 6| Step: 1
Training loss: 1.4268018007278442
Validation loss: 1.8605809391185801

Epoch: 6| Step: 2
Training loss: 2.083773612976074
Validation loss: 1.8271810316270398

Epoch: 6| Step: 3
Training loss: 1.7532782554626465
Validation loss: 1.8142732933003416

Epoch: 6| Step: 4
Training loss: 2.1276984214782715
Validation loss: 1.8576052496510167

Epoch: 6| Step: 5
Training loss: 1.8900830745697021
Validation loss: 1.8611277021387571

Epoch: 6| Step: 6
Training loss: 1.5694801807403564
Validation loss: 1.863811154519358

Epoch: 6| Step: 7
Training loss: 1.6188504695892334
Validation loss: 1.8045577541474374

Epoch: 6| Step: 8
Training loss: 1.4478670358657837
Validation loss: 1.8480339127202188

Epoch: 6| Step: 9
Training loss: 1.8753899335861206
Validation loss: 1.8270722691730787

Epoch: 6| Step: 10
Training loss: 2.0754446983337402
Validation loss: 1.8465930902829735

Epoch: 6| Step: 11
Training loss: 1.9869768619537354
Validation loss: 1.8683169400820168

Epoch: 6| Step: 12
Training loss: 1.2576960325241089
Validation loss: 1.859100180287515

Epoch: 6| Step: 13
Training loss: 1.7709423303604126
Validation loss: 1.8329656111296786

Epoch: 239| Step: 0
Training loss: 1.3669085502624512
Validation loss: 1.875808649165656

Epoch: 6| Step: 1
Training loss: 1.5625566244125366
Validation loss: 1.8422494319177443

Epoch: 6| Step: 2
Training loss: 1.594156265258789
Validation loss: 1.8330838859722178

Epoch: 6| Step: 3
Training loss: 1.596872091293335
Validation loss: 1.855562844584065

Epoch: 6| Step: 4
Training loss: 1.836413860321045
Validation loss: 1.84225784578631

Epoch: 6| Step: 5
Training loss: 1.2930397987365723
Validation loss: 1.8587916025551416

Epoch: 6| Step: 6
Training loss: 2.3181138038635254
Validation loss: 1.841135307024884

Epoch: 6| Step: 7
Training loss: 1.2622411251068115
Validation loss: 1.8451202710469563

Epoch: 6| Step: 8
Training loss: 1.862628698348999
Validation loss: 1.8784594766555294

Epoch: 6| Step: 9
Training loss: 1.6105684041976929
Validation loss: 1.8678807122733003

Epoch: 6| Step: 10
Training loss: 1.7098655700683594
Validation loss: 1.8362051851005965

Epoch: 6| Step: 11
Training loss: 1.5011783838272095
Validation loss: 1.8640752530867053

Epoch: 6| Step: 12
Training loss: 2.4003968238830566
Validation loss: 1.8374517316459327

Epoch: 6| Step: 13
Training loss: 1.8632333278656006
Validation loss: 1.8592338344102264

Epoch: 240| Step: 0
Training loss: 0.9989585876464844
Validation loss: 1.8855838160361014

Epoch: 6| Step: 1
Training loss: 0.9500045776367188
Validation loss: 1.8824818557308567

Epoch: 6| Step: 2
Training loss: 1.9999916553497314
Validation loss: 1.830884761707757

Epoch: 6| Step: 3
Training loss: 1.7397011518478394
Validation loss: 1.860716559553659

Epoch: 6| Step: 4
Training loss: 1.9058547019958496
Validation loss: 1.8250643771181825

Epoch: 6| Step: 5
Training loss: 1.461097002029419
Validation loss: 1.8389857302429855

Epoch: 6| Step: 6
Training loss: 2.359768867492676
Validation loss: 1.8434807177512877

Epoch: 6| Step: 7
Training loss: 1.6388345956802368
Validation loss: 1.8564629144566034

Epoch: 6| Step: 8
Training loss: 0.813065767288208
Validation loss: 1.842430217291719

Epoch: 6| Step: 9
Training loss: 2.612215518951416
Validation loss: 1.8371827666477492

Epoch: 6| Step: 10
Training loss: 1.5032858848571777
Validation loss: 1.8371486202363045

Epoch: 6| Step: 11
Training loss: 2.3060691356658936
Validation loss: 1.8417728177962764

Epoch: 6| Step: 12
Training loss: 1.5343966484069824
Validation loss: 1.849384383488727

Epoch: 6| Step: 13
Training loss: 2.4667820930480957
Validation loss: 1.8138779081324095

Epoch: 241| Step: 0
Training loss: 1.579187035560608
Validation loss: 1.8154113792604016

Epoch: 6| Step: 1
Training loss: 2.0980069637298584
Validation loss: 1.8346960672768213

Epoch: 6| Step: 2
Training loss: 1.519586443901062
Validation loss: 1.8452312433591453

Epoch: 6| Step: 3
Training loss: 1.0202550888061523
Validation loss: 1.8596625328063965

Epoch: 6| Step: 4
Training loss: 1.9955224990844727
Validation loss: 1.844444772248627

Epoch: 6| Step: 5
Training loss: 1.8924487829208374
Validation loss: 1.8373935248262139

Epoch: 6| Step: 6
Training loss: 2.416398048400879
Validation loss: 1.8658169725889802

Epoch: 6| Step: 7
Training loss: 1.4245882034301758
Validation loss: 1.8607967412599953

Epoch: 6| Step: 8
Training loss: 1.7525603771209717
Validation loss: 1.8679828630980624

Epoch: 6| Step: 9
Training loss: 1.386653184890747
Validation loss: 1.838573489137875

Epoch: 6| Step: 10
Training loss: 1.7481769323349
Validation loss: 1.8434334570361721

Epoch: 6| Step: 11
Training loss: 1.2775834798812866
Validation loss: 1.8455409555024997

Epoch: 6| Step: 12
Training loss: 1.5938549041748047
Validation loss: 1.8517192794430641

Epoch: 6| Step: 13
Training loss: 2.166121482849121
Validation loss: 1.8127474592578026

Epoch: 242| Step: 0
Training loss: 1.841021180152893
Validation loss: 1.8551341154242074

Epoch: 6| Step: 1
Training loss: 1.523939847946167
Validation loss: 1.8313066805562666

Epoch: 6| Step: 2
Training loss: 2.182185411453247
Validation loss: 1.821152473008761

Epoch: 6| Step: 3
Training loss: 1.460275650024414
Validation loss: 1.863269135516177

Epoch: 6| Step: 4
Training loss: 1.4540518522262573
Validation loss: 1.8829196576149232

Epoch: 6| Step: 5
Training loss: 1.3460568189620972
Validation loss: 1.8622824991902998

Epoch: 6| Step: 6
Training loss: 1.1475107669830322
Validation loss: 1.8644167364284556

Epoch: 6| Step: 7
Training loss: 1.519435167312622
Validation loss: 1.8404435585903864

Epoch: 6| Step: 8
Training loss: 1.902886986732483
Validation loss: 1.831078379384933

Epoch: 6| Step: 9
Training loss: 1.782660722732544
Validation loss: 1.825879208503231

Epoch: 6| Step: 10
Training loss: 1.507720708847046
Validation loss: 1.829261560593882

Epoch: 6| Step: 11
Training loss: 1.738792896270752
Validation loss: 1.8551247888995754

Epoch: 6| Step: 12
Training loss: 2.3927433490753174
Validation loss: 1.8206975011415378

Epoch: 6| Step: 13
Training loss: 2.4301235675811768
Validation loss: 1.8406839191272695

Epoch: 243| Step: 0
Training loss: 1.9120821952819824
Validation loss: 1.841882191678529

Epoch: 6| Step: 1
Training loss: 2.104496955871582
Validation loss: 1.849679640544358

Epoch: 6| Step: 2
Training loss: 1.9831297397613525
Validation loss: 1.8263112088685394

Epoch: 6| Step: 3
Training loss: 0.9908562898635864
Validation loss: 1.8151616050351052

Epoch: 6| Step: 4
Training loss: 2.0080506801605225
Validation loss: 1.8441696205446798

Epoch: 6| Step: 5
Training loss: 1.9343299865722656
Validation loss: 1.8269940717245943

Epoch: 6| Step: 6
Training loss: 1.8403836488723755
Validation loss: 1.8413174460011144

Epoch: 6| Step: 7
Training loss: 1.5102765560150146
Validation loss: 1.8263087195734824

Epoch: 6| Step: 8
Training loss: 1.6391875743865967
Validation loss: 1.8627237863438104

Epoch: 6| Step: 9
Training loss: 1.3231480121612549
Validation loss: 1.7967020337299635

Epoch: 6| Step: 10
Training loss: 1.9396601915359497
Validation loss: 1.8348484167488672

Epoch: 6| Step: 11
Training loss: 1.9708257913589478
Validation loss: 1.8164058564811625

Epoch: 6| Step: 12
Training loss: 1.9173330068588257
Validation loss: 1.8027235974547684

Epoch: 6| Step: 13
Training loss: 0.5253750681877136
Validation loss: 1.8142562438082952

Epoch: 244| Step: 0
Training loss: 1.4388880729675293
Validation loss: 1.854601453709346

Epoch: 6| Step: 1
Training loss: 1.819472074508667
Validation loss: 1.8596511169146466

Epoch: 6| Step: 2
Training loss: 1.6087992191314697
Validation loss: 1.8413495440636911

Epoch: 6| Step: 3
Training loss: 2.4258434772491455
Validation loss: 1.8385727610639346

Epoch: 6| Step: 4
Training loss: 1.5821583271026611
Validation loss: 1.834595581536652

Epoch: 6| Step: 5
Training loss: 1.1311229467391968
Validation loss: 1.839833829992561

Epoch: 6| Step: 6
Training loss: 1.6768696308135986
Validation loss: 1.8713628194665397

Epoch: 6| Step: 7
Training loss: 1.9608668088912964
Validation loss: 1.8278640624015563

Epoch: 6| Step: 8
Training loss: 1.8859062194824219
Validation loss: 1.8741229875113374

Epoch: 6| Step: 9
Training loss: 1.7042367458343506
Validation loss: 1.84466052439905

Epoch: 6| Step: 10
Training loss: 1.7304444313049316
Validation loss: 1.8215866781050158

Epoch: 6| Step: 11
Training loss: 1.7641961574554443
Validation loss: 1.8494244954919303

Epoch: 6| Step: 12
Training loss: 1.3344707489013672
Validation loss: 1.8207003826736121

Epoch: 6| Step: 13
Training loss: 1.3436837196350098
Validation loss: 1.8470492619340138

Epoch: 245| Step: 0
Training loss: 1.9643259048461914
Validation loss: 1.8376493492434103

Epoch: 6| Step: 1
Training loss: 2.167386531829834
Validation loss: 1.8413957203588178

Epoch: 6| Step: 2
Training loss: 2.071725845336914
Validation loss: 1.8641031929241714

Epoch: 6| Step: 3
Training loss: 1.467477560043335
Validation loss: 1.8299188908710275

Epoch: 6| Step: 4
Training loss: 1.7671560049057007
Validation loss: 1.8248467560737365

Epoch: 6| Step: 5
Training loss: 1.2535450458526611
Validation loss: 1.8606367790570824

Epoch: 6| Step: 6
Training loss: 1.152420997619629
Validation loss: 1.873549578010395

Epoch: 6| Step: 7
Training loss: 1.5692731142044067
Validation loss: 1.8278128562435028

Epoch: 6| Step: 8
Training loss: 2.159329414367676
Validation loss: 1.827108601088165

Epoch: 6| Step: 9
Training loss: 1.6738539934158325
Validation loss: 1.8690336635035854

Epoch: 6| Step: 10
Training loss: 1.7775084972381592
Validation loss: 1.8153490738202167

Epoch: 6| Step: 11
Training loss: 1.034064531326294
Validation loss: 1.8576917673951836

Epoch: 6| Step: 12
Training loss: 1.6789298057556152
Validation loss: 1.8124564232364777

Epoch: 6| Step: 13
Training loss: 2.1777524948120117
Validation loss: 1.8390886655417822

Epoch: 246| Step: 0
Training loss: 1.4370100498199463
Validation loss: 1.8296084839810607

Epoch: 6| Step: 1
Training loss: 1.5350499153137207
Validation loss: 1.8151731555179884

Epoch: 6| Step: 2
Training loss: 2.3009700775146484
Validation loss: 1.8239501458342358

Epoch: 6| Step: 3
Training loss: 1.0553028583526611
Validation loss: 1.8787163175562376

Epoch: 6| Step: 4
Training loss: 1.54972505569458
Validation loss: 1.846898176336801

Epoch: 6| Step: 5
Training loss: 1.8358309268951416
Validation loss: 1.8580696531521377

Epoch: 6| Step: 6
Training loss: 1.6727545261383057
Validation loss: 1.8407953657129759

Epoch: 6| Step: 7
Training loss: 1.7927508354187012
Validation loss: 1.8162471658440047

Epoch: 6| Step: 8
Training loss: 1.6087840795516968
Validation loss: 1.8185271845068982

Epoch: 6| Step: 9
Training loss: 2.435370445251465
Validation loss: 1.831671073872556

Epoch: 6| Step: 10
Training loss: 1.914665937423706
Validation loss: 1.8645690538549935

Epoch: 6| Step: 11
Training loss: 1.3810309171676636
Validation loss: 1.8217808559376707

Epoch: 6| Step: 12
Training loss: 1.7550549507141113
Validation loss: 1.8141382926253862

Epoch: 6| Step: 13
Training loss: 1.674347996711731
Validation loss: 1.790899072923968

Epoch: 247| Step: 0
Training loss: 1.1311296224594116
Validation loss: 1.8113778009209582

Epoch: 6| Step: 1
Training loss: 2.5148444175720215
Validation loss: 1.8642093430283249

Epoch: 6| Step: 2
Training loss: 1.8824650049209595
Validation loss: 1.8697182991171395

Epoch: 6| Step: 3
Training loss: 1.8280915021896362
Validation loss: 1.8531763322891728

Epoch: 6| Step: 4
Training loss: 1.3505399227142334
Validation loss: 1.8545298486627557

Epoch: 6| Step: 5
Training loss: 1.8463482856750488
Validation loss: 1.8579579732751335

Epoch: 6| Step: 6
Training loss: 1.2042059898376465
Validation loss: 1.9021905429901615

Epoch: 6| Step: 7
Training loss: 1.1217067241668701
Validation loss: 1.8314432341565368

Epoch: 6| Step: 8
Training loss: 1.7702229022979736
Validation loss: 1.82118974449814

Epoch: 6| Step: 9
Training loss: 1.6275014877319336
Validation loss: 1.886809128586964

Epoch: 6| Step: 10
Training loss: 1.8367531299591064
Validation loss: 1.8740331934344383

Epoch: 6| Step: 11
Training loss: 2.1395344734191895
Validation loss: 1.8566459558343376

Epoch: 6| Step: 12
Training loss: 1.327004075050354
Validation loss: 1.8137287080928843

Epoch: 6| Step: 13
Training loss: 3.1608426570892334
Validation loss: 1.85283463744707

Epoch: 248| Step: 0
Training loss: 1.406355857849121
Validation loss: 1.8096668053698797

Epoch: 6| Step: 1
Training loss: 2.0040745735168457
Validation loss: 1.8534098799510668

Epoch: 6| Step: 2
Training loss: 1.2675094604492188
Validation loss: 1.837272371015241

Epoch: 6| Step: 3
Training loss: 1.736626148223877
Validation loss: 1.8670173204073341

Epoch: 6| Step: 4
Training loss: 1.4915162324905396
Validation loss: 1.8692829570462626

Epoch: 6| Step: 5
Training loss: 2.105976104736328
Validation loss: 1.850030956729766

Epoch: 6| Step: 6
Training loss: 1.455941081047058
Validation loss: 1.8335201945356143

Epoch: 6| Step: 7
Training loss: 1.8603949546813965
Validation loss: 1.8812793300997825

Epoch: 6| Step: 8
Training loss: 1.3394176959991455
Validation loss: 1.871619156611863

Epoch: 6| Step: 9
Training loss: 1.3172136545181274
Validation loss: 1.7986870235012424

Epoch: 6| Step: 10
Training loss: 2.3061087131500244
Validation loss: 1.8298964602972871

Epoch: 6| Step: 11
Training loss: 1.9496455192565918
Validation loss: 1.8263750986386371

Epoch: 6| Step: 12
Training loss: 1.3363832235336304
Validation loss: 1.85770631605579

Epoch: 6| Step: 13
Training loss: 2.3335204124450684
Validation loss: 1.8577385974186722

Epoch: 249| Step: 0
Training loss: 2.286242961883545
Validation loss: 1.8278827769781953

Epoch: 6| Step: 1
Training loss: 1.505929708480835
Validation loss: 1.8489083141408942

Epoch: 6| Step: 2
Training loss: 0.9983181953430176
Validation loss: 1.8439194874096942

Epoch: 6| Step: 3
Training loss: 1.9204561710357666
Validation loss: 1.8429018887140418

Epoch: 6| Step: 4
Training loss: 1.9904463291168213
Validation loss: 1.8542964945557296

Epoch: 6| Step: 5
Training loss: 1.5936061143875122
Validation loss: 1.8144010997587634

Epoch: 6| Step: 6
Training loss: 2.1320886611938477
Validation loss: 1.814614075486378

Epoch: 6| Step: 7
Training loss: 1.3382642269134521
Validation loss: 1.8352251219493088

Epoch: 6| Step: 8
Training loss: 2.244704246520996
Validation loss: 1.828813942529822

Epoch: 6| Step: 9
Training loss: 1.5899083614349365
Validation loss: 1.8017543400487592

Epoch: 6| Step: 10
Training loss: 1.5225787162780762
Validation loss: 1.8507854964143486

Epoch: 6| Step: 11
Training loss: 1.6431283950805664
Validation loss: 1.8585990423797278

Epoch: 6| Step: 12
Training loss: 1.2820358276367188
Validation loss: 1.8551814722758468

Epoch: 6| Step: 13
Training loss: 1.4869087934494019
Validation loss: 1.8288454394186697

Epoch: 250| Step: 0
Training loss: 1.2312891483306885
Validation loss: 1.8300641723858413

Epoch: 6| Step: 1
Training loss: 2.4003424644470215
Validation loss: 1.8361458381017048

Epoch: 6| Step: 2
Training loss: 1.934299111366272
Validation loss: 1.816141128540039

Epoch: 6| Step: 3
Training loss: 1.6197210550308228
Validation loss: 1.8532595685733262

Epoch: 6| Step: 4
Training loss: 1.9487842321395874
Validation loss: 1.8475600186214651

Epoch: 6| Step: 5
Training loss: 1.70269775390625
Validation loss: 1.8227791401647753

Epoch: 6| Step: 6
Training loss: 1.0934410095214844
Validation loss: 1.7922915797079764

Epoch: 6| Step: 7
Training loss: 1.7140815258026123
Validation loss: 1.839021792975805

Epoch: 6| Step: 8
Training loss: 2.120744228363037
Validation loss: 1.86410318779689

Epoch: 6| Step: 9
Training loss: 2.123791217803955
Validation loss: 1.8144656086480746

Epoch: 6| Step: 10
Training loss: 1.227509617805481
Validation loss: 1.8397063926983905

Epoch: 6| Step: 11
Training loss: 1.147845983505249
Validation loss: 1.8727463573537848

Epoch: 6| Step: 12
Training loss: 1.4021375179290771
Validation loss: 1.7941545722305134

Epoch: 6| Step: 13
Training loss: 1.5224412679672241
Validation loss: 1.8412883358616983

Epoch: 251| Step: 0
Training loss: 2.185115337371826
Validation loss: 1.8409926352962371

Epoch: 6| Step: 1
Training loss: 1.6611239910125732
Validation loss: 1.8244735297336374

Epoch: 6| Step: 2
Training loss: 1.6005196571350098
Validation loss: 1.8323468828714022

Epoch: 6| Step: 3
Training loss: 1.9568160772323608
Validation loss: 1.810813662826374

Epoch: 6| Step: 4
Training loss: 1.6910746097564697
Validation loss: 1.8521808142303138

Epoch: 6| Step: 5
Training loss: 1.6733875274658203
Validation loss: 1.8027915082952028

Epoch: 6| Step: 6
Training loss: 1.5167815685272217
Validation loss: 1.8414147323177708

Epoch: 6| Step: 7
Training loss: 1.3994829654693604
Validation loss: 1.822736677303109

Epoch: 6| Step: 8
Training loss: 2.0792555809020996
Validation loss: 1.8461213522059943

Epoch: 6| Step: 9
Training loss: 0.9645474553108215
Validation loss: 1.8545445498599802

Epoch: 6| Step: 10
Training loss: 1.5974071025848389
Validation loss: 1.794473212252381

Epoch: 6| Step: 11
Training loss: 1.3698360919952393
Validation loss: 1.8408481844009892

Epoch: 6| Step: 12
Training loss: 2.38716459274292
Validation loss: 1.843212022576281

Epoch: 6| Step: 13
Training loss: 1.3269917964935303
Validation loss: 1.828170863530969

Epoch: 252| Step: 0
Training loss: 2.1438770294189453
Validation loss: 1.8224369018308577

Epoch: 6| Step: 1
Training loss: 1.2385601997375488
Validation loss: 1.8368556281571746

Epoch: 6| Step: 2
Training loss: 2.326894760131836
Validation loss: 1.8414336455765592

Epoch: 6| Step: 3
Training loss: 1.7086031436920166
Validation loss: 1.8302191201076712

Epoch: 6| Step: 4
Training loss: 0.9349104762077332
Validation loss: 1.836827681910607

Epoch: 6| Step: 5
Training loss: 1.3038160800933838
Validation loss: 1.840174045614017

Epoch: 6| Step: 6
Training loss: 2.0087223052978516
Validation loss: 1.8496311967090895

Epoch: 6| Step: 7
Training loss: 1.8877151012420654
Validation loss: 1.8354488444584671

Epoch: 6| Step: 8
Training loss: 1.8607512712478638
Validation loss: 1.8478696038646083

Epoch: 6| Step: 9
Training loss: 1.08707594871521
Validation loss: 1.828076800992412

Epoch: 6| Step: 10
Training loss: 1.6550266742706299
Validation loss: 1.8168857994899954

Epoch: 6| Step: 11
Training loss: 2.051053524017334
Validation loss: 1.8335267215646722

Epoch: 6| Step: 12
Training loss: 1.735702633857727
Validation loss: 1.8316796428413802

Epoch: 6| Step: 13
Training loss: 1.7314213514328003
Validation loss: 1.8408810656557801

Epoch: 253| Step: 0
Training loss: 1.5001037120819092
Validation loss: 1.8258031773310837

Epoch: 6| Step: 1
Training loss: 1.6039161682128906
Validation loss: 1.827926185823256

Epoch: 6| Step: 2
Training loss: 1.4874813556671143
Validation loss: 1.8275177119880595

Epoch: 6| Step: 3
Training loss: 1.4172463417053223
Validation loss: 1.8428597424619941

Epoch: 6| Step: 4
Training loss: 1.5105202198028564
Validation loss: 1.8381167522040747

Epoch: 6| Step: 5
Training loss: 2.843846321105957
Validation loss: 1.8449100525148454

Epoch: 6| Step: 6
Training loss: 1.6319494247436523
Validation loss: 1.8558711313432263

Epoch: 6| Step: 7
Training loss: 1.418466567993164
Validation loss: 1.8305228602501653

Epoch: 6| Step: 8
Training loss: 1.1929428577423096
Validation loss: 1.8536289597070346

Epoch: 6| Step: 9
Training loss: 1.5583707094192505
Validation loss: 1.8608648841099074

Epoch: 6| Step: 10
Training loss: 2.2316341400146484
Validation loss: 1.8452886599366383

Epoch: 6| Step: 11
Training loss: 1.3595675230026245
Validation loss: 1.836302686763066

Epoch: 6| Step: 12
Training loss: 1.8944226503372192
Validation loss: 1.8429977150373562

Epoch: 6| Step: 13
Training loss: 1.9498683214187622
Validation loss: 1.8508652820382068

Epoch: 254| Step: 0
Training loss: 1.7997617721557617
Validation loss: 1.8346947636655582

Epoch: 6| Step: 1
Training loss: 1.9767718315124512
Validation loss: 1.8289523663059357

Epoch: 6| Step: 2
Training loss: 1.7900898456573486
Validation loss: 1.8455474133132606

Epoch: 6| Step: 3
Training loss: 2.0350310802459717
Validation loss: 1.8432764519927323

Epoch: 6| Step: 4
Training loss: 1.3507248163223267
Validation loss: 1.8567812506870558

Epoch: 6| Step: 5
Training loss: 1.1570724248886108
Validation loss: 1.8670476341760287

Epoch: 6| Step: 6
Training loss: 1.605613112449646
Validation loss: 1.8449620957015662

Epoch: 6| Step: 7
Training loss: 1.9431519508361816
Validation loss: 1.8244957513706659

Epoch: 6| Step: 8
Training loss: 2.5294792652130127
Validation loss: 1.8436905004644906

Epoch: 6| Step: 9
Training loss: 1.3923568725585938
Validation loss: 1.8150664914038874

Epoch: 6| Step: 10
Training loss: 0.9896053075790405
Validation loss: 1.798930573207076

Epoch: 6| Step: 11
Training loss: 1.8573272228240967
Validation loss: 1.8149994419467064

Epoch: 6| Step: 12
Training loss: 1.3202064037322998
Validation loss: 1.8026822408040364

Epoch: 6| Step: 13
Training loss: 1.6520284414291382
Validation loss: 1.7904735547240063

Epoch: 255| Step: 0
Training loss: 2.590650796890259
Validation loss: 1.7956329673849127

Epoch: 6| Step: 1
Training loss: 1.1977183818817139
Validation loss: 1.8203332142163349

Epoch: 6| Step: 2
Training loss: 1.2968535423278809
Validation loss: 1.8324304498651975

Epoch: 6| Step: 3
Training loss: 1.724416971206665
Validation loss: 1.8464242053288284

Epoch: 6| Step: 4
Training loss: 1.8752191066741943
Validation loss: 1.8110483051628194

Epoch: 6| Step: 5
Training loss: 2.1372334957122803
Validation loss: 1.808853454487298

Epoch: 6| Step: 6
Training loss: 1.3682470321655273
Validation loss: 1.839737469150174

Epoch: 6| Step: 7
Training loss: 1.412574052810669
Validation loss: 1.7838815937760055

Epoch: 6| Step: 8
Training loss: 1.5934569835662842
Validation loss: 1.843791668133069

Epoch: 6| Step: 9
Training loss: 1.4319891929626465
Validation loss: 1.7727267139701433

Epoch: 6| Step: 10
Training loss: 1.4781852960586548
Validation loss: 1.802783658427577

Epoch: 6| Step: 11
Training loss: 1.5388567447662354
Validation loss: 1.815121603268449

Epoch: 6| Step: 12
Training loss: 1.5119054317474365
Validation loss: 1.8400558207624702

Epoch: 6| Step: 13
Training loss: 2.6655359268188477
Validation loss: 1.823562196505967

Epoch: 256| Step: 0
Training loss: 1.8587605953216553
Validation loss: 1.8103889444822907

Epoch: 6| Step: 1
Training loss: 1.4268081188201904
Validation loss: 1.8139520947651198

Epoch: 6| Step: 2
Training loss: 1.1668078899383545
Validation loss: 1.8029134324801865

Epoch: 6| Step: 3
Training loss: 2.064209461212158
Validation loss: 1.8526183174502464

Epoch: 6| Step: 4
Training loss: 1.4239919185638428
Validation loss: 1.845094496204007

Epoch: 6| Step: 5
Training loss: 1.5812658071517944
Validation loss: 1.8579466791563137

Epoch: 6| Step: 6
Training loss: 1.6332414150238037
Validation loss: 1.8368915383533766

Epoch: 6| Step: 7
Training loss: 1.6074271202087402
Validation loss: 1.8633382012767177

Epoch: 6| Step: 8
Training loss: 1.859297513961792
Validation loss: 1.8656523894238215

Epoch: 6| Step: 9
Training loss: 1.5132198333740234
Validation loss: 1.862037597164031

Epoch: 6| Step: 10
Training loss: 1.6281275749206543
Validation loss: 1.8853398561477661

Epoch: 6| Step: 11
Training loss: 1.9925661087036133
Validation loss: 1.8810876479712866

Epoch: 6| Step: 12
Training loss: 1.6492114067077637
Validation loss: 1.8410844443946757

Epoch: 6| Step: 13
Training loss: 1.717637538909912
Validation loss: 1.8271500859209286

Epoch: 257| Step: 0
Training loss: 1.670719861984253
Validation loss: 1.7895084145248576

Epoch: 6| Step: 1
Training loss: 0.8267817497253418
Validation loss: 1.8041853930360527

Epoch: 6| Step: 2
Training loss: 1.8342410326004028
Validation loss: 1.7980352960607058

Epoch: 6| Step: 3
Training loss: 0.9479405879974365
Validation loss: 1.8233518703009493

Epoch: 6| Step: 4
Training loss: 2.0920815467834473
Validation loss: 1.7881406930185133

Epoch: 6| Step: 5
Training loss: 2.104856014251709
Validation loss: 1.7843789708229802

Epoch: 6| Step: 6
Training loss: 1.6432126760482788
Validation loss: 1.8336451579165716

Epoch: 6| Step: 7
Training loss: 1.6752294301986694
Validation loss: 1.8319999312841764

Epoch: 6| Step: 8
Training loss: 1.5788369178771973
Validation loss: 1.8167605297539824

Epoch: 6| Step: 9
Training loss: 1.7330234050750732
Validation loss: 1.799236261716453

Epoch: 6| Step: 10
Training loss: 1.6677155494689941
Validation loss: 1.8082697263327978

Epoch: 6| Step: 11
Training loss: 1.6543731689453125
Validation loss: 1.8339493325961533

Epoch: 6| Step: 12
Training loss: 2.3063838481903076
Validation loss: 1.848529290127498

Epoch: 6| Step: 13
Training loss: 1.5726075172424316
Validation loss: 1.796896562781385

Epoch: 258| Step: 0
Training loss: 1.6884241104125977
Validation loss: 1.8083940462399555

Epoch: 6| Step: 1
Training loss: 1.9189432859420776
Validation loss: 1.8000133947659565

Epoch: 6| Step: 2
Training loss: 2.1176657676696777
Validation loss: 1.8140778246746267

Epoch: 6| Step: 3
Training loss: 2.0049333572387695
Validation loss: 1.855864317186417

Epoch: 6| Step: 4
Training loss: 1.252039909362793
Validation loss: 1.875242220458164

Epoch: 6| Step: 5
Training loss: 1.6102294921875
Validation loss: 1.863519932634087

Epoch: 6| Step: 6
Training loss: 0.707197904586792
Validation loss: 1.8652661692711614

Epoch: 6| Step: 7
Training loss: 2.227158546447754
Validation loss: 1.888905458552863

Epoch: 6| Step: 8
Training loss: 1.6219708919525146
Validation loss: 1.8634405213017617

Epoch: 6| Step: 9
Training loss: 1.1846933364868164
Validation loss: 1.8239715765881281

Epoch: 6| Step: 10
Training loss: 1.1557459831237793
Validation loss: 1.8228348967849568

Epoch: 6| Step: 11
Training loss: 1.954308271408081
Validation loss: 1.8569844422801849

Epoch: 6| Step: 12
Training loss: 1.6918917894363403
Validation loss: 1.8294857419947141

Epoch: 6| Step: 13
Training loss: 2.1765120029449463
Validation loss: 1.8479458247461626

Epoch: 259| Step: 0
Training loss: 1.1765044927597046
Validation loss: 1.839448792960054

Epoch: 6| Step: 1
Training loss: 1.7180577516555786
Validation loss: 1.83577940540929

Epoch: 6| Step: 2
Training loss: 1.6901350021362305
Validation loss: 1.8498389503007293

Epoch: 6| Step: 3
Training loss: 1.7026984691619873
Validation loss: 1.807149120556411

Epoch: 6| Step: 4
Training loss: 1.4425592422485352
Validation loss: 1.8441312812989759

Epoch: 6| Step: 5
Training loss: 1.9756062030792236
Validation loss: 1.7963025557097567

Epoch: 6| Step: 6
Training loss: 2.135427951812744
Validation loss: 1.8276964208131194

Epoch: 6| Step: 7
Training loss: 2.0338873863220215
Validation loss: 1.795687501148511

Epoch: 6| Step: 8
Training loss: 1.4639737606048584
Validation loss: 1.837778247812743

Epoch: 6| Step: 9
Training loss: 1.9079999923706055
Validation loss: 1.810118773932098

Epoch: 6| Step: 10
Training loss: 1.5192854404449463
Validation loss: 1.8046775671743578

Epoch: 6| Step: 11
Training loss: 1.5539145469665527
Validation loss: 1.7811902620459115

Epoch: 6| Step: 12
Training loss: 1.2700525522232056
Validation loss: 1.7779664442103396

Epoch: 6| Step: 13
Training loss: 1.5811527967453003
Validation loss: 1.8014962596278037

Epoch: 260| Step: 0
Training loss: 2.15679931640625
Validation loss: 1.7822152337720316

Epoch: 6| Step: 1
Training loss: 1.6236497163772583
Validation loss: 1.8080190843151462

Epoch: 6| Step: 2
Training loss: 1.5109295845031738
Validation loss: 1.7764813964084913

Epoch: 6| Step: 3
Training loss: 1.0336356163024902
Validation loss: 1.835576444543818

Epoch: 6| Step: 4
Training loss: 1.3726117610931396
Validation loss: 1.8256768385569255

Epoch: 6| Step: 5
Training loss: 1.470351219177246
Validation loss: 1.8199325274395686

Epoch: 6| Step: 6
Training loss: 1.4867885112762451
Validation loss: 1.8369599401309926

Epoch: 6| Step: 7
Training loss: 0.87380051612854
Validation loss: 1.8186509545131395

Epoch: 6| Step: 8
Training loss: 2.0900399684906006
Validation loss: 1.8444357507972307

Epoch: 6| Step: 9
Training loss: 2.751260995864868
Validation loss: 1.8211408404893772

Epoch: 6| Step: 10
Training loss: 1.8632395267486572
Validation loss: 1.808742518066078

Epoch: 6| Step: 11
Training loss: 0.8740543127059937
Validation loss: 1.8393564762607697

Epoch: 6| Step: 12
Training loss: 2.4560599327087402
Validation loss: 1.8106638782767839

Epoch: 6| Step: 13
Training loss: 0.8728731870651245
Validation loss: 1.8634536830327844

Epoch: 261| Step: 0
Training loss: 1.3522326946258545
Validation loss: 1.8400171097888742

Epoch: 6| Step: 1
Training loss: 1.4795210361480713
Validation loss: 1.8104337505114976

Epoch: 6| Step: 2
Training loss: 1.5834486484527588
Validation loss: 1.8504060160729192

Epoch: 6| Step: 3
Training loss: 1.7619643211364746
Validation loss: 1.8803880829964914

Epoch: 6| Step: 4
Training loss: 2.3230466842651367
Validation loss: 1.8292153419986847

Epoch: 6| Step: 5
Training loss: 1.4935648441314697
Validation loss: 1.8562240395494687

Epoch: 6| Step: 6
Training loss: 1.625228762626648
Validation loss: 1.8740004493344216

Epoch: 6| Step: 7
Training loss: 1.8611326217651367
Validation loss: 1.8343062785363966

Epoch: 6| Step: 8
Training loss: 1.0435459613800049
Validation loss: 1.8442905051733858

Epoch: 6| Step: 9
Training loss: 1.4052095413208008
Validation loss: 1.8161255416049753

Epoch: 6| Step: 10
Training loss: 2.1548914909362793
Validation loss: 1.826270067563621

Epoch: 6| Step: 11
Training loss: 1.6676639318466187
Validation loss: 1.8515937174520185

Epoch: 6| Step: 12
Training loss: 1.2536609172821045
Validation loss: 1.8311346154059134

Epoch: 6| Step: 13
Training loss: 2.5585215091705322
Validation loss: 1.7988803437961045

Epoch: 262| Step: 0
Training loss: 1.5669573545455933
Validation loss: 1.8613057328808693

Epoch: 6| Step: 1
Training loss: 1.8131768703460693
Validation loss: 1.8097090118674821

Epoch: 6| Step: 2
Training loss: 1.5927088260650635
Validation loss: 1.8359043816084504

Epoch: 6| Step: 3
Training loss: 1.475907564163208
Validation loss: 1.8280925186731483

Epoch: 6| Step: 4
Training loss: 1.6331965923309326
Validation loss: 1.8565099546986241

Epoch: 6| Step: 5
Training loss: 1.7520482540130615
Validation loss: 1.8251130311719832

Epoch: 6| Step: 6
Training loss: 1.6553940773010254
Validation loss: 1.7909730454926849

Epoch: 6| Step: 7
Training loss: 1.7101513147354126
Validation loss: 1.8300813269871536

Epoch: 6| Step: 8
Training loss: 2.1616477966308594
Validation loss: 1.8497783496815672

Epoch: 6| Step: 9
Training loss: 0.6195734739303589
Validation loss: 1.8188314886503323

Epoch: 6| Step: 10
Training loss: 2.0564699172973633
Validation loss: 1.780690836650069

Epoch: 6| Step: 11
Training loss: 1.2825813293457031
Validation loss: 1.8507121686012513

Epoch: 6| Step: 12
Training loss: 2.2819297313690186
Validation loss: 1.8139177522351664

Epoch: 6| Step: 13
Training loss: 1.310701847076416
Validation loss: 1.8322848850680935

Epoch: 263| Step: 0
Training loss: 1.6311547756195068
Validation loss: 1.8133197920296782

Epoch: 6| Step: 1
Training loss: 2.165194511413574
Validation loss: 1.7945623141463085

Epoch: 6| Step: 2
Training loss: 1.7123095989227295
Validation loss: 1.846563744288619

Epoch: 6| Step: 3
Training loss: 2.17824649810791
Validation loss: 1.8178769785870788

Epoch: 6| Step: 4
Training loss: 1.0159759521484375
Validation loss: 1.8260105527857298

Epoch: 6| Step: 5
Training loss: 1.6906898021697998
Validation loss: 1.8472129068066996

Epoch: 6| Step: 6
Training loss: 1.899791955947876
Validation loss: 1.7885626913398824

Epoch: 6| Step: 7
Training loss: 1.4416027069091797
Validation loss: 1.8360376037577146

Epoch: 6| Step: 8
Training loss: 1.1750249862670898
Validation loss: 1.8140604611366027

Epoch: 6| Step: 9
Training loss: 2.068432331085205
Validation loss: 1.7796556488160165

Epoch: 6| Step: 10
Training loss: 1.8441587686538696
Validation loss: 1.8318883385709537

Epoch: 6| Step: 11
Training loss: 1.8368791341781616
Validation loss: 1.802235669987176

Epoch: 6| Step: 12
Training loss: 0.8119359016418457
Validation loss: 1.8171670359949912

Epoch: 6| Step: 13
Training loss: 1.3714377880096436
Validation loss: 1.8023344227062759

Epoch: 264| Step: 0
Training loss: 1.3807883262634277
Validation loss: 1.8399196004354825

Epoch: 6| Step: 1
Training loss: 1.7325479984283447
Validation loss: 1.8359421401895502

Epoch: 6| Step: 2
Training loss: 1.2267765998840332
Validation loss: 1.7897360747860325

Epoch: 6| Step: 3
Training loss: 1.8747230768203735
Validation loss: 1.783968880612363

Epoch: 6| Step: 4
Training loss: 1.7220585346221924
Validation loss: 1.8198849065329439

Epoch: 6| Step: 5
Training loss: 1.9987876415252686
Validation loss: 1.7778608029888523

Epoch: 6| Step: 6
Training loss: 1.4156444072723389
Validation loss: 1.8120310229639853

Epoch: 6| Step: 7
Training loss: 1.416007399559021
Validation loss: 1.8394092770032986

Epoch: 6| Step: 8
Training loss: 1.6102573871612549
Validation loss: 1.7577337398323962

Epoch: 6| Step: 9
Training loss: 2.3952033519744873
Validation loss: 1.808217199899817

Epoch: 6| Step: 10
Training loss: 1.3237911462783813
Validation loss: 1.8194206863321283

Epoch: 6| Step: 11
Training loss: 1.827371597290039
Validation loss: 1.810830573881826

Epoch: 6| Step: 12
Training loss: 1.4748682975769043
Validation loss: 1.8085510512833953

Epoch: 6| Step: 13
Training loss: 1.6577712297439575
Validation loss: 1.8420609786946287

Epoch: 265| Step: 0
Training loss: 1.9625968933105469
Validation loss: 1.8243324910440752

Epoch: 6| Step: 1
Training loss: 1.3243815898895264
Validation loss: 1.8457068268970778

Epoch: 6| Step: 2
Training loss: 1.7871196269989014
Validation loss: 1.837568053635218

Epoch: 6| Step: 3
Training loss: 1.9725896120071411
Validation loss: 1.8515296777089436

Epoch: 6| Step: 4
Training loss: 1.4854199886322021
Validation loss: 1.8378934283410349

Epoch: 6| Step: 5
Training loss: 1.1752537488937378
Validation loss: 1.84235559099464

Epoch: 6| Step: 6
Training loss: 2.097750663757324
Validation loss: 1.823299224658679

Epoch: 6| Step: 7
Training loss: 0.9096958637237549
Validation loss: 1.8465699482989568

Epoch: 6| Step: 8
Training loss: 1.4772765636444092
Validation loss: 1.848069961353015

Epoch: 6| Step: 9
Training loss: 1.974924087524414
Validation loss: 1.8659639230338476

Epoch: 6| Step: 10
Training loss: 1.7829773426055908
Validation loss: 1.8120639183187996

Epoch: 6| Step: 11
Training loss: 2.200374126434326
Validation loss: 1.8380012037933513

Epoch: 6| Step: 12
Training loss: 1.41286301612854
Validation loss: 1.8103616096640145

Epoch: 6| Step: 13
Training loss: 1.369669795036316
Validation loss: 1.809814659498071

Epoch: 266| Step: 0
Training loss: 1.707679033279419
Validation loss: 1.827671948299613

Epoch: 6| Step: 1
Training loss: 2.078711748123169
Validation loss: 1.8251066259158555

Epoch: 6| Step: 2
Training loss: 1.9295250177383423
Validation loss: 1.794718309115338

Epoch: 6| Step: 3
Training loss: 1.6528462171554565
Validation loss: 1.7906839437382196

Epoch: 6| Step: 4
Training loss: 1.686002254486084
Validation loss: 1.8253972274000927

Epoch: 6| Step: 5
Training loss: 2.2362401485443115
Validation loss: 1.790211776251434

Epoch: 6| Step: 6
Training loss: 1.4750686883926392
Validation loss: 1.824634854511548

Epoch: 6| Step: 7
Training loss: 1.4108152389526367
Validation loss: 1.822904908528892

Epoch: 6| Step: 8
Training loss: 1.2507915496826172
Validation loss: 1.7915673678921116

Epoch: 6| Step: 9
Training loss: 1.4594504833221436
Validation loss: 1.8098169475473382

Epoch: 6| Step: 10
Training loss: 1.2774043083190918
Validation loss: 1.8255707743347331

Epoch: 6| Step: 11
Training loss: 1.585533618927002
Validation loss: 1.8029032830269105

Epoch: 6| Step: 12
Training loss: 1.370522379875183
Validation loss: 1.818937309326664

Epoch: 6| Step: 13
Training loss: 2.053835868835449
Validation loss: 1.8204044001076811

Epoch: 267| Step: 0
Training loss: 2.0521240234375
Validation loss: 1.838904119306995

Epoch: 6| Step: 1
Training loss: 2.093104362487793
Validation loss: 1.8395668204112718

Epoch: 6| Step: 2
Training loss: 1.4004178047180176
Validation loss: 1.8322685995409567

Epoch: 6| Step: 3
Training loss: 2.065920352935791
Validation loss: 1.813722743782946

Epoch: 6| Step: 4
Training loss: 2.228952646255493
Validation loss: 1.8427200458383048

Epoch: 6| Step: 5
Training loss: 1.1687994003295898
Validation loss: 1.8370691332765805

Epoch: 6| Step: 6
Training loss: 1.8232276439666748
Validation loss: 1.9028423024762062

Epoch: 6| Step: 7
Training loss: 1.1802687644958496
Validation loss: 1.830398964625533

Epoch: 6| Step: 8
Training loss: 1.1906039714813232
Validation loss: 1.8618600086499286

Epoch: 6| Step: 9
Training loss: 1.018423318862915
Validation loss: 1.846496129548678

Epoch: 6| Step: 10
Training loss: 1.2686357498168945
Validation loss: 1.856661464578362

Epoch: 6| Step: 11
Training loss: 2.1083903312683105
Validation loss: 1.826336883729504

Epoch: 6| Step: 12
Training loss: 1.9902021884918213
Validation loss: 1.7982525928046114

Epoch: 6| Step: 13
Training loss: 1.5795480012893677
Validation loss: 1.7960574819195656

Epoch: 268| Step: 0
Training loss: 1.560846209526062
Validation loss: 1.8035929972125637

Epoch: 6| Step: 1
Training loss: 2.5683488845825195
Validation loss: 1.8068571936699651

Epoch: 6| Step: 2
Training loss: 1.1010360717773438
Validation loss: 1.8136375924592376

Epoch: 6| Step: 3
Training loss: 1.2509422302246094
Validation loss: 1.8247534946728778

Epoch: 6| Step: 4
Training loss: 1.6658821105957031
Validation loss: 1.7871409000888947

Epoch: 6| Step: 5
Training loss: 1.1155813932418823
Validation loss: 1.8019522595149216

Epoch: 6| Step: 6
Training loss: 1.9281431436538696
Validation loss: 1.7770545867181593

Epoch: 6| Step: 7
Training loss: 1.623467206954956
Validation loss: 1.8047514410429104

Epoch: 6| Step: 8
Training loss: 1.4490535259246826
Validation loss: 1.8015467351482761

Epoch: 6| Step: 9
Training loss: 1.5534274578094482
Validation loss: 1.8179708168070803

Epoch: 6| Step: 10
Training loss: 1.9799015522003174
Validation loss: 1.7798057845843736

Epoch: 6| Step: 11
Training loss: 1.1154390573501587
Validation loss: 1.812617084031464

Epoch: 6| Step: 12
Training loss: 2.0435829162597656
Validation loss: 1.8157823701058664

Epoch: 6| Step: 13
Training loss: 1.479524850845337
Validation loss: 1.7947998046875

Epoch: 269| Step: 0
Training loss: 1.7932075262069702
Validation loss: 1.8312845986376527

Epoch: 6| Step: 1
Training loss: 1.202613115310669
Validation loss: 1.8141561092868927

Epoch: 6| Step: 2
Training loss: 1.432802677154541
Validation loss: 1.840981537295926

Epoch: 6| Step: 3
Training loss: 1.2473304271697998
Validation loss: 1.8124042813495924

Epoch: 6| Step: 4
Training loss: 1.584857702255249
Validation loss: 1.8564183968369679

Epoch: 6| Step: 5
Training loss: 1.8145580291748047
Validation loss: 1.8513666942555418

Epoch: 6| Step: 6
Training loss: 1.5183359384536743
Validation loss: 1.8387023415616763

Epoch: 6| Step: 7
Training loss: 1.5909487009048462
Validation loss: 1.855344735166078

Epoch: 6| Step: 8
Training loss: 2.2083423137664795
Validation loss: 1.9035275469544113

Epoch: 6| Step: 9
Training loss: 1.2727441787719727
Validation loss: 1.8380437884279477

Epoch: 6| Step: 10
Training loss: 1.7233545780181885
Validation loss: 1.8704140237582627

Epoch: 6| Step: 11
Training loss: 1.7253038883209229
Validation loss: 1.8278493753043554

Epoch: 6| Step: 12
Training loss: 1.9400460720062256
Validation loss: 1.8491004577247045

Epoch: 6| Step: 13
Training loss: 1.937161922454834
Validation loss: 1.8302825843134234

Epoch: 270| Step: 0
Training loss: 1.8420754671096802
Validation loss: 1.8035648586929485

Epoch: 6| Step: 1
Training loss: 2.218724250793457
Validation loss: 1.804093926183639

Epoch: 6| Step: 2
Training loss: 1.3772287368774414
Validation loss: 1.8362996462852723

Epoch: 6| Step: 3
Training loss: 1.4173154830932617
Validation loss: 1.8168297839421097

Epoch: 6| Step: 4
Training loss: 1.9055474996566772
Validation loss: 1.7903055362803961

Epoch: 6| Step: 5
Training loss: 1.6344352960586548
Validation loss: 1.7759853383546234

Epoch: 6| Step: 6
Training loss: 1.6170220375061035
Validation loss: 1.80155389155111

Epoch: 6| Step: 7
Training loss: 1.8623346090316772
Validation loss: 1.8310792535863898

Epoch: 6| Step: 8
Training loss: 1.1269688606262207
Validation loss: 1.8069714320603238

Epoch: 6| Step: 9
Training loss: 1.6120563745498657
Validation loss: 1.7873387452094787

Epoch: 6| Step: 10
Training loss: 1.4088276624679565
Validation loss: 1.8203140151116155

Epoch: 6| Step: 11
Training loss: 2.20259165763855
Validation loss: 1.818665535219254

Epoch: 6| Step: 12
Training loss: 1.1196134090423584
Validation loss: 1.8189845213326075

Epoch: 6| Step: 13
Training loss: 0.882921040058136
Validation loss: 1.7988412431491319

Epoch: 271| Step: 0
Training loss: 0.8942935466766357
Validation loss: 1.8467722669724496

Epoch: 6| Step: 1
Training loss: 2.0042991638183594
Validation loss: 1.802295369486655

Epoch: 6| Step: 2
Training loss: 1.3419601917266846
Validation loss: 1.7695151298276839

Epoch: 6| Step: 3
Training loss: 1.315698266029358
Validation loss: 1.8204431405631445

Epoch: 6| Step: 4
Training loss: 2.1760737895965576
Validation loss: 1.7761673478670017

Epoch: 6| Step: 5
Training loss: 1.3614797592163086
Validation loss: 1.8030005680617465

Epoch: 6| Step: 6
Training loss: 1.6619923114776611
Validation loss: 1.7932301029082267

Epoch: 6| Step: 7
Training loss: 1.164847493171692
Validation loss: 1.8321614701260802

Epoch: 6| Step: 8
Training loss: 1.3222945928573608
Validation loss: 1.7974000707749398

Epoch: 6| Step: 9
Training loss: 1.936706781387329
Validation loss: 1.7911366916471911

Epoch: 6| Step: 10
Training loss: 2.235804557800293
Validation loss: 1.7706472078959148

Epoch: 6| Step: 11
Training loss: 1.632913589477539
Validation loss: 1.8179660689446233

Epoch: 6| Step: 12
Training loss: 2.186359405517578
Validation loss: 1.8112763384337067

Epoch: 6| Step: 13
Training loss: 1.362681269645691
Validation loss: 1.8412661936975294

Epoch: 272| Step: 0
Training loss: 1.4972662925720215
Validation loss: 1.8570520711201493

Epoch: 6| Step: 1
Training loss: 1.0822584629058838
Validation loss: 1.8323836172780683

Epoch: 6| Step: 2
Training loss: 1.5499439239501953
Validation loss: 1.8525059735903175

Epoch: 6| Step: 3
Training loss: 2.2095165252685547
Validation loss: 1.816537857055664

Epoch: 6| Step: 4
Training loss: 1.736950397491455
Validation loss: 1.8661813979507775

Epoch: 6| Step: 5
Training loss: 1.9201029539108276
Validation loss: 1.8398950651127806

Epoch: 6| Step: 6
Training loss: 1.800133228302002
Validation loss: 1.8543672074553788

Epoch: 6| Step: 7
Training loss: 1.2296570539474487
Validation loss: 1.8456830606665662

Epoch: 6| Step: 8
Training loss: 1.8312104940414429
Validation loss: 1.8815543869490265

Epoch: 6| Step: 9
Training loss: 1.792832374572754
Validation loss: 1.8380957380417855

Epoch: 6| Step: 10
Training loss: 2.0746097564697266
Validation loss: 1.8171647107729347

Epoch: 6| Step: 11
Training loss: 1.09975266456604
Validation loss: 1.8089914219353789

Epoch: 6| Step: 12
Training loss: 1.4119908809661865
Validation loss: 1.8442714803962297

Epoch: 6| Step: 13
Training loss: 1.084299087524414
Validation loss: 1.7819479396266322

Epoch: 273| Step: 0
Training loss: 1.2064082622528076
Validation loss: 1.7798526299897062

Epoch: 6| Step: 1
Training loss: 1.4638175964355469
Validation loss: 1.809638786059554

Epoch: 6| Step: 2
Training loss: 2.368849515914917
Validation loss: 1.824028955992832

Epoch: 6| Step: 3
Training loss: 1.972508430480957
Validation loss: 1.7901957470883605

Epoch: 6| Step: 4
Training loss: 1.0367381572723389
Validation loss: 1.7986983458201091

Epoch: 6| Step: 5
Training loss: 1.8682725429534912
Validation loss: 1.7870694847517117

Epoch: 6| Step: 6
Training loss: 1.315315842628479
Validation loss: 1.7982250170041156

Epoch: 6| Step: 7
Training loss: 1.5724711418151855
Validation loss: 1.7773112417549215

Epoch: 6| Step: 8
Training loss: 1.9669642448425293
Validation loss: 1.808794375388853

Epoch: 6| Step: 9
Training loss: 1.6235740184783936
Validation loss: 1.7852506355572773

Epoch: 6| Step: 10
Training loss: 1.7774829864501953
Validation loss: 1.7816502291669127

Epoch: 6| Step: 11
Training loss: 1.7514729499816895
Validation loss: 1.8042549458883141

Epoch: 6| Step: 12
Training loss: 1.4196746349334717
Validation loss: 1.81171868565262

Epoch: 6| Step: 13
Training loss: 1.3675047159194946
Validation loss: 1.8255553783908967

Epoch: 274| Step: 0
Training loss: 1.6451877355575562
Validation loss: 1.8222718033739316

Epoch: 6| Step: 1
Training loss: 1.6643037796020508
Validation loss: 1.8535042680719847

Epoch: 6| Step: 2
Training loss: 1.564117431640625
Validation loss: 1.8353735541784635

Epoch: 6| Step: 3
Training loss: 1.932882308959961
Validation loss: 1.851411125993216

Epoch: 6| Step: 4
Training loss: 1.5593488216400146
Validation loss: 1.84412044607183

Epoch: 6| Step: 5
Training loss: 1.7939270734786987
Validation loss: 1.8800439270593787

Epoch: 6| Step: 6
Training loss: 1.8216266632080078
Validation loss: 1.8396079732525734

Epoch: 6| Step: 7
Training loss: 1.0941660404205322
Validation loss: 1.8351110053318802

Epoch: 6| Step: 8
Training loss: 1.4746674299240112
Validation loss: 1.8702411254247029

Epoch: 6| Step: 9
Training loss: 1.4415303468704224
Validation loss: 1.8445940863701604

Epoch: 6| Step: 10
Training loss: 1.5279479026794434
Validation loss: 1.8604873893081502

Epoch: 6| Step: 11
Training loss: 1.5327935218811035
Validation loss: 1.856108150174541

Epoch: 6| Step: 12
Training loss: 1.9689853191375732
Validation loss: 1.8102502412693475

Epoch: 6| Step: 13
Training loss: 1.79490327835083
Validation loss: 1.8132166849669589

Epoch: 275| Step: 0
Training loss: 1.986090898513794
Validation loss: 1.7826817420221144

Epoch: 6| Step: 1
Training loss: 1.570439338684082
Validation loss: 1.8105618223067252

Epoch: 6| Step: 2
Training loss: 1.2617571353912354
Validation loss: 1.8176746009498514

Epoch: 6| Step: 3
Training loss: 1.7102127075195312
Validation loss: 1.7788923222531554

Epoch: 6| Step: 4
Training loss: 2.231084108352661
Validation loss: 1.7976727062656033

Epoch: 6| Step: 5
Training loss: 1.7882716655731201
Validation loss: 1.781833501272304

Epoch: 6| Step: 6
Training loss: 1.5564712285995483
Validation loss: 1.804895672746884

Epoch: 6| Step: 7
Training loss: 1.0951813459396362
Validation loss: 1.7597294097305627

Epoch: 6| Step: 8
Training loss: 1.9183156490325928
Validation loss: 1.7702721498345817

Epoch: 6| Step: 9
Training loss: 1.7142918109893799
Validation loss: 1.7843755137535833

Epoch: 6| Step: 10
Training loss: 1.5973930358886719
Validation loss: 1.7852620027398551

Epoch: 6| Step: 11
Training loss: 1.8451106548309326
Validation loss: 1.7780068689777004

Epoch: 6| Step: 12
Training loss: 1.255743384361267
Validation loss: 1.780424161623883

Epoch: 6| Step: 13
Training loss: 1.3482965230941772
Validation loss: 1.7891480089515768

Epoch: 276| Step: 0
Training loss: 1.5364978313446045
Validation loss: 1.8247870655469998

Epoch: 6| Step: 1
Training loss: 2.032952308654785
Validation loss: 1.7918966713772024

Epoch: 6| Step: 2
Training loss: 2.464874267578125
Validation loss: 1.7852325567635157

Epoch: 6| Step: 3
Training loss: 1.0897116661071777
Validation loss: 1.7805917775759132

Epoch: 6| Step: 4
Training loss: 1.5948538780212402
Validation loss: 1.8081804372931038

Epoch: 6| Step: 5
Training loss: 1.6181639432907104
Validation loss: 1.837777276192942

Epoch: 6| Step: 6
Training loss: 1.825068473815918
Validation loss: 1.847758707179818

Epoch: 6| Step: 7
Training loss: 1.3706903457641602
Validation loss: 1.809616268322032

Epoch: 6| Step: 8
Training loss: 1.487626552581787
Validation loss: 1.809259432618336

Epoch: 6| Step: 9
Training loss: 2.0416641235351562
Validation loss: 1.8440807865511986

Epoch: 6| Step: 10
Training loss: 1.5119075775146484
Validation loss: 1.8239041887303835

Epoch: 6| Step: 11
Training loss: 1.563309907913208
Validation loss: 1.8559795323238577

Epoch: 6| Step: 12
Training loss: 1.0360939502716064
Validation loss: 1.8371599720370384

Epoch: 6| Step: 13
Training loss: 1.3415734767913818
Validation loss: 1.8292320800083939

Epoch: 277| Step: 0
Training loss: 1.567883014678955
Validation loss: 1.8113406845318374

Epoch: 6| Step: 1
Training loss: 1.836195468902588
Validation loss: 1.8315646635588778

Epoch: 6| Step: 2
Training loss: 2.352553129196167
Validation loss: 1.8195628966054609

Epoch: 6| Step: 3
Training loss: 1.6005096435546875
Validation loss: 1.8241257385541034

Epoch: 6| Step: 4
Training loss: 1.1868374347686768
Validation loss: 1.8534660493173907

Epoch: 6| Step: 5
Training loss: 1.2029738426208496
Validation loss: 1.8152872913627214

Epoch: 6| Step: 6
Training loss: 1.2128314971923828
Validation loss: 1.801213086292308

Epoch: 6| Step: 7
Training loss: 1.3245728015899658
Validation loss: 1.868806921025758

Epoch: 6| Step: 8
Training loss: 2.212149143218994
Validation loss: 1.8011491478130381

Epoch: 6| Step: 9
Training loss: 1.257460594177246
Validation loss: 1.812332393020712

Epoch: 6| Step: 10
Training loss: 1.6936311721801758
Validation loss: 1.81628845584008

Epoch: 6| Step: 11
Training loss: 1.4756966829299927
Validation loss: 1.840873477279499

Epoch: 6| Step: 12
Training loss: 1.9149116277694702
Validation loss: 1.7952677613945418

Epoch: 6| Step: 13
Training loss: 1.7785077095031738
Validation loss: 1.7971841878788446

Epoch: 278| Step: 0
Training loss: 1.4858648777008057
Validation loss: 1.806715396142775

Epoch: 6| Step: 1
Training loss: 2.2036988735198975
Validation loss: 1.7952485263988536

Epoch: 6| Step: 2
Training loss: 1.6160355806350708
Validation loss: 1.76973795506262

Epoch: 6| Step: 3
Training loss: 1.7802873849868774
Validation loss: 1.8284809756022629

Epoch: 6| Step: 4
Training loss: 1.6306360960006714
Validation loss: 1.7993249636824413

Epoch: 6| Step: 5
Training loss: 1.2503403425216675
Validation loss: 1.8015376124330746

Epoch: 6| Step: 6
Training loss: 1.8498002290725708
Validation loss: 1.8065108304382653

Epoch: 6| Step: 7
Training loss: 1.3651612997055054
Validation loss: 1.8543143387763732

Epoch: 6| Step: 8
Training loss: 1.8762617111206055
Validation loss: 1.8552941981182303

Epoch: 6| Step: 9
Training loss: 1.5402631759643555
Validation loss: 1.769245461751056

Epoch: 6| Step: 10
Training loss: 1.5931646823883057
Validation loss: 1.7776815173446492

Epoch: 6| Step: 11
Training loss: 1.2120704650878906
Validation loss: 1.817604382832845

Epoch: 6| Step: 12
Training loss: 1.337107539176941
Validation loss: 1.790866659533593

Epoch: 6| Step: 13
Training loss: 1.6441800594329834
Validation loss: 1.8141633284989225

Epoch: 279| Step: 0
Training loss: 1.433368444442749
Validation loss: 1.801681339099843

Epoch: 6| Step: 1
Training loss: 1.5647475719451904
Validation loss: 1.8218888992904334

Epoch: 6| Step: 2
Training loss: 2.3709464073181152
Validation loss: 1.8045868437777284

Epoch: 6| Step: 3
Training loss: 1.5004216432571411
Validation loss: 1.8500414484290666

Epoch: 6| Step: 4
Training loss: 1.146594762802124
Validation loss: 1.803545714706503

Epoch: 6| Step: 5
Training loss: 1.3237634897232056
Validation loss: 1.8097461115929387

Epoch: 6| Step: 6
Training loss: 1.6726620197296143
Validation loss: 1.852454690523045

Epoch: 6| Step: 7
Training loss: 1.7048194408416748
Validation loss: 1.8627394245516868

Epoch: 6| Step: 8
Training loss: 1.2251477241516113
Validation loss: 1.7998722958308395

Epoch: 6| Step: 9
Training loss: 1.701953411102295
Validation loss: 1.8708179791768391

Epoch: 6| Step: 10
Training loss: 1.3991727828979492
Validation loss: 1.8576526077844764

Epoch: 6| Step: 11
Training loss: 2.4780995845794678
Validation loss: 1.8247633326438166

Epoch: 6| Step: 12
Training loss: 1.5248744487762451
Validation loss: 1.8494561038991457

Epoch: 6| Step: 13
Training loss: 0.9068949818611145
Validation loss: 1.81106896169724

Epoch: 280| Step: 0
Training loss: 1.4770983457565308
Validation loss: 1.810662059373753

Epoch: 6| Step: 1
Training loss: 1.2419497966766357
Validation loss: 1.824717919031779

Epoch: 6| Step: 2
Training loss: 1.5594406127929688
Validation loss: 1.7986859634358396

Epoch: 6| Step: 3
Training loss: 1.3355671167373657
Validation loss: 1.7909262821238527

Epoch: 6| Step: 4
Training loss: 1.8764808177947998
Validation loss: 1.787640574157879

Epoch: 6| Step: 5
Training loss: 1.3692268133163452
Validation loss: 1.8100433746973674

Epoch: 6| Step: 6
Training loss: 1.5816237926483154
Validation loss: 1.821915917499091

Epoch: 6| Step: 7
Training loss: 1.115448236465454
Validation loss: 1.7868818775300057

Epoch: 6| Step: 8
Training loss: 1.6700252294540405
Validation loss: 1.7780948505606702

Epoch: 6| Step: 9
Training loss: 2.172497272491455
Validation loss: 1.7912218621982041

Epoch: 6| Step: 10
Training loss: 1.8528454303741455
Validation loss: 1.7916602037286247

Epoch: 6| Step: 11
Training loss: 2.1838290691375732
Validation loss: 1.7761185720402708

Epoch: 6| Step: 12
Training loss: 1.659940242767334
Validation loss: 1.8151552100335397

Epoch: 6| Step: 13
Training loss: 1.2605196237564087
Validation loss: 1.7830433717337988

Epoch: 281| Step: 0
Training loss: 1.397549033164978
Validation loss: 1.804356796767122

Epoch: 6| Step: 1
Training loss: 2.120758056640625
Validation loss: 1.8235022406424246

Epoch: 6| Step: 2
Training loss: 0.8742056488990784
Validation loss: 1.8149570521487985

Epoch: 6| Step: 3
Training loss: 1.6280277967453003
Validation loss: 1.8023304964906426

Epoch: 6| Step: 4
Training loss: 2.1759653091430664
Validation loss: 1.8025867580085673

Epoch: 6| Step: 5
Training loss: 1.058445692062378
Validation loss: 1.8089201347802275

Epoch: 6| Step: 6
Training loss: 1.4337143898010254
Validation loss: 1.806632065003918

Epoch: 6| Step: 7
Training loss: 1.1736667156219482
Validation loss: 1.8472517126349992

Epoch: 6| Step: 8
Training loss: 1.9448896646499634
Validation loss: 1.8144999140052385

Epoch: 6| Step: 9
Training loss: 1.5989773273468018
Validation loss: 1.8266069748068368

Epoch: 6| Step: 10
Training loss: 2.6774673461914062
Validation loss: 1.7853303378628147

Epoch: 6| Step: 11
Training loss: 1.7192274332046509
Validation loss: 1.812337375456287

Epoch: 6| Step: 12
Training loss: 0.9182466268539429
Validation loss: 1.8257424126389206

Epoch: 6| Step: 13
Training loss: 1.5644887685775757
Validation loss: 1.8035953198709795

Epoch: 282| Step: 0
Training loss: 1.4919886589050293
Validation loss: 1.804658075814606

Epoch: 6| Step: 1
Training loss: 2.8143296241760254
Validation loss: 1.8027935822804768

Epoch: 6| Step: 2
Training loss: 1.04374361038208
Validation loss: 1.805571788100786

Epoch: 6| Step: 3
Training loss: 1.4051423072814941
Validation loss: 1.8003267870154431

Epoch: 6| Step: 4
Training loss: 1.7486143112182617
Validation loss: 1.8033000269243795

Epoch: 6| Step: 5
Training loss: 1.3630871772766113
Validation loss: 1.8049390892828665

Epoch: 6| Step: 6
Training loss: 1.656705617904663
Validation loss: 1.806959245794563

Epoch: 6| Step: 7
Training loss: 2.355161666870117
Validation loss: 1.8340293579204108

Epoch: 6| Step: 8
Training loss: 0.7226126194000244
Validation loss: 1.8365747351800241

Epoch: 6| Step: 9
Training loss: 1.530421257019043
Validation loss: 1.8162023303329304

Epoch: 6| Step: 10
Training loss: 1.6093332767486572
Validation loss: 1.8084718706787273

Epoch: 6| Step: 11
Training loss: 1.375917911529541
Validation loss: 1.8105807073654667

Epoch: 6| Step: 12
Training loss: 1.671684741973877
Validation loss: 1.7879121393285773

Epoch: 6| Step: 13
Training loss: 1.1531808376312256
Validation loss: 1.7844914313285583

Epoch: 283| Step: 0
Training loss: 1.4351708889007568
Validation loss: 1.8095531604623283

Epoch: 6| Step: 1
Training loss: 1.3087319135665894
Validation loss: 1.80875946885796

Epoch: 6| Step: 2
Training loss: 1.2866120338439941
Validation loss: 1.7610909477356942

Epoch: 6| Step: 3
Training loss: 1.1996352672576904
Validation loss: 1.7960230791440575

Epoch: 6| Step: 4
Training loss: 1.7474498748779297
Validation loss: 1.7476339711937854

Epoch: 6| Step: 5
Training loss: 1.0736905336380005
Validation loss: 1.7842477854862009

Epoch: 6| Step: 6
Training loss: 1.812450885772705
Validation loss: 1.7847012704418552

Epoch: 6| Step: 7
Training loss: 1.4742047786712646
Validation loss: 1.7937909121154456

Epoch: 6| Step: 8
Training loss: 2.502021312713623
Validation loss: 1.816813644542489

Epoch: 6| Step: 9
Training loss: 2.0389509201049805
Validation loss: 1.7687046194589267

Epoch: 6| Step: 10
Training loss: 1.6594452857971191
Validation loss: 1.802784978702504

Epoch: 6| Step: 11
Training loss: 1.4538031816482544
Validation loss: 1.8076101451791742

Epoch: 6| Step: 12
Training loss: 1.6626029014587402
Validation loss: 1.7733866860789638

Epoch: 6| Step: 13
Training loss: 1.7135050296783447
Validation loss: 1.787409613209386

Epoch: 284| Step: 0
Training loss: 1.725170612335205
Validation loss: 1.8509807394396873

Epoch: 6| Step: 1
Training loss: 2.612222671508789
Validation loss: 1.807944587481919

Epoch: 6| Step: 2
Training loss: 1.6847455501556396
Validation loss: 1.8184868674124441

Epoch: 6| Step: 3
Training loss: 1.1874442100524902
Validation loss: 1.8279018184190154

Epoch: 6| Step: 4
Training loss: 1.5152106285095215
Validation loss: 1.8466796336635467

Epoch: 6| Step: 5
Training loss: 1.046622395515442
Validation loss: 1.8623125912040792

Epoch: 6| Step: 6
Training loss: 1.7048366069793701
Validation loss: 1.8432763033015753

Epoch: 6| Step: 7
Training loss: 1.4433224201202393
Validation loss: 1.9167694981380174

Epoch: 6| Step: 8
Training loss: 1.3506736755371094
Validation loss: 1.869212583828998

Epoch: 6| Step: 9
Training loss: 1.8873732089996338
Validation loss: 1.8364445432539909

Epoch: 6| Step: 10
Training loss: 1.6129812002182007
Validation loss: 1.8324557927346998

Epoch: 6| Step: 11
Training loss: 1.591207504272461
Validation loss: 1.8242122127163796

Epoch: 6| Step: 12
Training loss: 1.2394733428955078
Validation loss: 1.8156797834621963

Epoch: 6| Step: 13
Training loss: 2.5330185890197754
Validation loss: 1.8250572014880437

Epoch: 285| Step: 0
Training loss: 2.2091336250305176
Validation loss: 1.7682513575400076

Epoch: 6| Step: 1
Training loss: 1.640660047531128
Validation loss: 1.8062022552695325

Epoch: 6| Step: 2
Training loss: 1.1332064867019653
Validation loss: 1.7790793154829292

Epoch: 6| Step: 3
Training loss: 1.4019421339035034
Validation loss: 1.8108324107303415

Epoch: 6| Step: 4
Training loss: 1.2571989297866821
Validation loss: 1.7613874430297523

Epoch: 6| Step: 5
Training loss: 2.435588836669922
Validation loss: 1.7775864806226505

Epoch: 6| Step: 6
Training loss: 1.8452064990997314
Validation loss: 1.7772243445919407

Epoch: 6| Step: 7
Training loss: 0.7900315523147583
Validation loss: 1.844489356522919

Epoch: 6| Step: 8
Training loss: 1.6171984672546387
Validation loss: 1.7506696767704462

Epoch: 6| Step: 9
Training loss: 1.399379014968872
Validation loss: 1.7933257331130326

Epoch: 6| Step: 10
Training loss: 2.008927583694458
Validation loss: 1.7917063082418134

Epoch: 6| Step: 11
Training loss: 1.2451715469360352
Validation loss: 1.8280960308608187

Epoch: 6| Step: 12
Training loss: 0.9906063675880432
Validation loss: 1.7729969921932425

Epoch: 6| Step: 13
Training loss: 2.303644895553589
Validation loss: 1.799437754897661

Epoch: 286| Step: 0
Training loss: 1.413506269454956
Validation loss: 1.7900516961210517

Epoch: 6| Step: 1
Training loss: 1.7223536968231201
Validation loss: 1.8015158407149776

Epoch: 6| Step: 2
Training loss: 1.5323139429092407
Validation loss: 1.8126499909226612

Epoch: 6| Step: 3
Training loss: 1.3140313625335693
Validation loss: 1.81310700344783

Epoch: 6| Step: 4
Training loss: 1.3397369384765625
Validation loss: 1.8275762706674554

Epoch: 6| Step: 5
Training loss: 1.8720452785491943
Validation loss: 1.7986400755502845

Epoch: 6| Step: 6
Training loss: 1.7705003023147583
Validation loss: 1.8314387721400107

Epoch: 6| Step: 7
Training loss: 1.3402175903320312
Validation loss: 1.804357954250869

Epoch: 6| Step: 8
Training loss: 1.6692917346954346
Validation loss: 1.8116958115690498

Epoch: 6| Step: 9
Training loss: 1.5215575695037842
Validation loss: 1.8262399922135055

Epoch: 6| Step: 10
Training loss: 1.1633388996124268
Validation loss: 1.8190701520571144

Epoch: 6| Step: 11
Training loss: 2.004955291748047
Validation loss: 1.8206252333938435

Epoch: 6| Step: 12
Training loss: 1.8317443132400513
Validation loss: 1.8094002264802174

Epoch: 6| Step: 13
Training loss: 2.0196893215179443
Validation loss: 1.8091176530366302

Epoch: 287| Step: 0
Training loss: 2.07069993019104
Validation loss: 1.8274085060242684

Epoch: 6| Step: 1
Training loss: 2.0728979110717773
Validation loss: 1.8248008579336188

Epoch: 6| Step: 2
Training loss: 1.0917035341262817
Validation loss: 1.835581547470503

Epoch: 6| Step: 3
Training loss: 1.872764229774475
Validation loss: 1.804799473413857

Epoch: 6| Step: 4
Training loss: 1.4939422607421875
Validation loss: 1.8027580220212218

Epoch: 6| Step: 5
Training loss: 1.6335783004760742
Validation loss: 1.812107091308922

Epoch: 6| Step: 6
Training loss: 1.6668517589569092
Validation loss: 1.8030805459586523

Epoch: 6| Step: 7
Training loss: 1.0669145584106445
Validation loss: 1.8196785065435594

Epoch: 6| Step: 8
Training loss: 1.0684541463851929
Validation loss: 1.788146993165375

Epoch: 6| Step: 9
Training loss: 1.833630919456482
Validation loss: 1.8202378852393037

Epoch: 6| Step: 10
Training loss: 1.3587706089019775
Validation loss: 1.771344704012717

Epoch: 6| Step: 11
Training loss: 1.6057653427124023
Validation loss: 1.8228866156711374

Epoch: 6| Step: 12
Training loss: 1.7513926029205322
Validation loss: 1.8232585742909422

Epoch: 6| Step: 13
Training loss: 1.5352718830108643
Validation loss: 1.7673236016304261

Epoch: 288| Step: 0
Training loss: 1.0883464813232422
Validation loss: 1.7658783274312173

Epoch: 6| Step: 1
Training loss: 1.0520873069763184
Validation loss: 1.7956730575971707

Epoch: 6| Step: 2
Training loss: 1.4736976623535156
Validation loss: 1.7962986371850456

Epoch: 6| Step: 3
Training loss: 1.8275082111358643
Validation loss: 1.7931690100700624

Epoch: 6| Step: 4
Training loss: 2.0728530883789062
Validation loss: 1.7545169271448606

Epoch: 6| Step: 5
Training loss: 1.912696361541748
Validation loss: 1.8345783013169483

Epoch: 6| Step: 6
Training loss: 0.9314485788345337
Validation loss: 1.77461834620404

Epoch: 6| Step: 7
Training loss: 1.6899430751800537
Validation loss: 1.8415306204108781

Epoch: 6| Step: 8
Training loss: 1.5450059175491333
Validation loss: 1.8208511926794564

Epoch: 6| Step: 9
Training loss: 1.8930126428604126
Validation loss: 1.7612870277897004

Epoch: 6| Step: 10
Training loss: 1.83274507522583
Validation loss: 1.8216351885949411

Epoch: 6| Step: 11
Training loss: 1.6578528881072998
Validation loss: 1.780297702358615

Epoch: 6| Step: 12
Training loss: 1.3359019756317139
Validation loss: 1.8181651792218607

Epoch: 6| Step: 13
Training loss: 1.6101633310317993
Validation loss: 1.8092579200703611

Epoch: 289| Step: 0
Training loss: 1.1194180250167847
Validation loss: 1.7968521220709688

Epoch: 6| Step: 1
Training loss: 1.4852466583251953
Validation loss: 1.7797349781118414

Epoch: 6| Step: 2
Training loss: 1.8593127727508545
Validation loss: 1.8137718490374986

Epoch: 6| Step: 3
Training loss: 1.8666900396347046
Validation loss: 1.7853647919111355

Epoch: 6| Step: 4
Training loss: 1.5582016706466675
Validation loss: 1.8041590336830384

Epoch: 6| Step: 5
Training loss: 2.0127596855163574
Validation loss: 1.8186913831259615

Epoch: 6| Step: 6
Training loss: 1.8608819246292114
Validation loss: 1.828993538374542

Epoch: 6| Step: 7
Training loss: 1.1995632648468018
Validation loss: 1.8406165992060015

Epoch: 6| Step: 8
Training loss: 2.122661590576172
Validation loss: 1.841720813064165

Epoch: 6| Step: 9
Training loss: 1.6891326904296875
Validation loss: 1.8501064969647316

Epoch: 6| Step: 10
Training loss: 1.5907338857650757
Validation loss: 1.8079656234351538

Epoch: 6| Step: 11
Training loss: 0.9559073448181152
Validation loss: 1.841363573587069

Epoch: 6| Step: 12
Training loss: 1.496242880821228
Validation loss: 1.817759584355098

Epoch: 6| Step: 13
Training loss: 0.8809347748756409
Validation loss: 1.8014463609264744

Epoch: 290| Step: 0
Training loss: 1.5317305326461792
Validation loss: 1.793081037459835

Epoch: 6| Step: 1
Training loss: 1.7838218212127686
Validation loss: 1.7972697532305153

Epoch: 6| Step: 2
Training loss: 1.070960521697998
Validation loss: 1.7693671962266326

Epoch: 6| Step: 3
Training loss: 1.5479243993759155
Validation loss: 1.8049324763718473

Epoch: 6| Step: 4
Training loss: 0.9864783883094788
Validation loss: 1.793667697137402

Epoch: 6| Step: 5
Training loss: 1.7896952629089355
Validation loss: 1.79010054116608

Epoch: 6| Step: 6
Training loss: 1.766575813293457
Validation loss: 1.8155984852903633

Epoch: 6| Step: 7
Training loss: 1.2109088897705078
Validation loss: 1.7844047930932814

Epoch: 6| Step: 8
Training loss: 1.8455173969268799
Validation loss: 1.7862941167687858

Epoch: 6| Step: 9
Training loss: 1.646902084350586
Validation loss: 1.8054684862013786

Epoch: 6| Step: 10
Training loss: 1.449126958847046
Validation loss: 1.7520206551398

Epoch: 6| Step: 11
Training loss: 1.6065444946289062
Validation loss: 1.8143819570541382

Epoch: 6| Step: 12
Training loss: 2.0366647243499756
Validation loss: 1.7831711499921736

Epoch: 6| Step: 13
Training loss: 1.9724432229995728
Validation loss: 1.816528389530797

Epoch: 291| Step: 0
Training loss: 2.1285111904144287
Validation loss: 1.8125320096169748

Epoch: 6| Step: 1
Training loss: 1.1321423053741455
Validation loss: 1.7793242803183935

Epoch: 6| Step: 2
Training loss: 1.334486722946167
Validation loss: 1.8074425753726755

Epoch: 6| Step: 3
Training loss: 1.5718111991882324
Validation loss: 1.7608194376832695

Epoch: 6| Step: 4
Training loss: 1.8116185665130615
Validation loss: 1.8262757735867654

Epoch: 6| Step: 5
Training loss: 1.2854745388031006
Validation loss: 1.7998941354854132

Epoch: 6| Step: 6
Training loss: 1.7981427907943726
Validation loss: 1.8066681418367612

Epoch: 6| Step: 7
Training loss: 1.3529517650604248
Validation loss: 1.7970187035940026

Epoch: 6| Step: 8
Training loss: 2.511935234069824
Validation loss: 1.8179075871744463

Epoch: 6| Step: 9
Training loss: 0.8912628889083862
Validation loss: 1.7965068586411015

Epoch: 6| Step: 10
Training loss: 2.3360800743103027
Validation loss: 1.7855922509265203

Epoch: 6| Step: 11
Training loss: 1.3002417087554932
Validation loss: 1.791089524504959

Epoch: 6| Step: 12
Training loss: 1.0962212085723877
Validation loss: 1.804755567222513

Epoch: 6| Step: 13
Training loss: 0.7341786623001099
Validation loss: 1.8422868149254912

Epoch: 292| Step: 0
Training loss: 2.0465939044952393
Validation loss: 1.8144299637886785

Epoch: 6| Step: 1
Training loss: 1.9435173273086548
Validation loss: 1.785187605888613

Epoch: 6| Step: 2
Training loss: 1.5428273677825928
Validation loss: 1.8294761180877686

Epoch: 6| Step: 3
Training loss: 1.3028693199157715
Validation loss: 1.8081598217769335

Epoch: 6| Step: 4
Training loss: 1.8126050233840942
Validation loss: 1.824724870343362

Epoch: 6| Step: 5
Training loss: 1.1042170524597168
Validation loss: 1.8353872376103555

Epoch: 6| Step: 6
Training loss: 1.0855417251586914
Validation loss: 1.8160791832913634

Epoch: 6| Step: 7
Training loss: 1.5837093591690063
Validation loss: 1.7862813447111396

Epoch: 6| Step: 8
Training loss: 1.7294306755065918
Validation loss: 1.8287092972827215

Epoch: 6| Step: 9
Training loss: 1.674107551574707
Validation loss: 1.8356831304488643

Epoch: 6| Step: 10
Training loss: 1.2517528533935547
Validation loss: 1.8066508116260651

Epoch: 6| Step: 11
Training loss: 1.609872579574585
Validation loss: 1.800097668042747

Epoch: 6| Step: 12
Training loss: 1.3433151245117188
Validation loss: 1.8292725675849504

Epoch: 6| Step: 13
Training loss: 1.9173916578292847
Validation loss: 1.8151556291887838

Epoch: 293| Step: 0
Training loss: 1.3534603118896484
Validation loss: 1.7968414957805345

Epoch: 6| Step: 1
Training loss: 1.5813713073730469
Validation loss: 1.7981651457407142

Epoch: 6| Step: 2
Training loss: 1.1044366359710693
Validation loss: 1.8234096727063578

Epoch: 6| Step: 3
Training loss: 1.2956149578094482
Validation loss: 1.8003903717123053

Epoch: 6| Step: 4
Training loss: 1.545853614807129
Validation loss: 1.802222587729013

Epoch: 6| Step: 5
Training loss: 1.4592907428741455
Validation loss: 1.7749505760849162

Epoch: 6| Step: 6
Training loss: 1.9205906391143799
Validation loss: 1.760575391912973

Epoch: 6| Step: 7
Training loss: 1.7619202136993408
Validation loss: 1.7980959735890871

Epoch: 6| Step: 8
Training loss: 1.364469289779663
Validation loss: 1.7951730451276224

Epoch: 6| Step: 9
Training loss: 2.3294572830200195
Validation loss: 1.7977156690371934

Epoch: 6| Step: 10
Training loss: 1.5733293294906616
Validation loss: 1.808012435513158

Epoch: 6| Step: 11
Training loss: 1.0769230127334595
Validation loss: 1.7785004415819723

Epoch: 6| Step: 12
Training loss: 1.753638744354248
Validation loss: 1.8107633270243162

Epoch: 6| Step: 13
Training loss: 1.809070348739624
Validation loss: 1.8262580735709077

Epoch: 294| Step: 0
Training loss: 1.8623337745666504
Validation loss: 1.7545688415086398

Epoch: 6| Step: 1
Training loss: 1.817453145980835
Validation loss: 1.8003655069617814

Epoch: 6| Step: 2
Training loss: 1.6336722373962402
Validation loss: 1.7901322111006706

Epoch: 6| Step: 3
Training loss: 1.9240710735321045
Validation loss: 1.7883632772712297

Epoch: 6| Step: 4
Training loss: 0.9298591613769531
Validation loss: 1.8166400694078015

Epoch: 6| Step: 5
Training loss: 1.7295284271240234
Validation loss: 1.8118518039744387

Epoch: 6| Step: 6
Training loss: 1.9057056903839111
Validation loss: 1.8075733607815159

Epoch: 6| Step: 7
Training loss: 1.2747232913970947
Validation loss: 1.8511877162482149

Epoch: 6| Step: 8
Training loss: 0.9573275446891785
Validation loss: 1.813901444917084

Epoch: 6| Step: 9
Training loss: 2.043765068054199
Validation loss: 1.797570163203824

Epoch: 6| Step: 10
Training loss: 1.5494754314422607
Validation loss: 1.8063595256497782

Epoch: 6| Step: 11
Training loss: 0.9428541660308838
Validation loss: 1.8171720479124336

Epoch: 6| Step: 12
Training loss: 1.286417007446289
Validation loss: 1.804337493834957

Epoch: 6| Step: 13
Training loss: 2.1836800575256348
Validation loss: 1.7981570600181498

Epoch: 295| Step: 0
Training loss: 2.168745994567871
Validation loss: 1.817477221130043

Epoch: 6| Step: 1
Training loss: 1.0290303230285645
Validation loss: 1.7741716254142024

Epoch: 6| Step: 2
Training loss: 1.4415364265441895
Validation loss: 1.8101137773964995

Epoch: 6| Step: 3
Training loss: 1.3384528160095215
Validation loss: 1.7852422050250474

Epoch: 6| Step: 4
Training loss: 2.064393997192383
Validation loss: 1.7593917987679923

Epoch: 6| Step: 5
Training loss: 1.5793726444244385
Validation loss: 1.773141453343053

Epoch: 6| Step: 6
Training loss: 1.2620608806610107
Validation loss: 1.7899234089800107

Epoch: 6| Step: 7
Training loss: 1.710734486579895
Validation loss: 1.7741199719008578

Epoch: 6| Step: 8
Training loss: 1.2263777256011963
Validation loss: 1.805356526887545

Epoch: 6| Step: 9
Training loss: 0.9863603115081787
Validation loss: 1.8050398916326544

Epoch: 6| Step: 10
Training loss: 1.4692517518997192
Validation loss: 1.7667580278970862

Epoch: 6| Step: 11
Training loss: 1.6573376655578613
Validation loss: 1.7932553791230725

Epoch: 6| Step: 12
Training loss: 2.0138120651245117
Validation loss: 1.8076238811656993

Epoch: 6| Step: 13
Training loss: 2.5937769412994385
Validation loss: 1.8057935827521867

Epoch: 296| Step: 0
Training loss: 1.6022264957427979
Validation loss: 1.8088052939343195

Epoch: 6| Step: 1
Training loss: 1.2420101165771484
Validation loss: 1.8490461867342713

Epoch: 6| Step: 2
Training loss: 2.044283866882324
Validation loss: 1.8038924765843216

Epoch: 6| Step: 3
Training loss: 1.8751952648162842
Validation loss: 1.820692293105587

Epoch: 6| Step: 4
Training loss: 1.008788824081421
Validation loss: 1.7822576786882134

Epoch: 6| Step: 5
Training loss: 1.7818976640701294
Validation loss: 1.8177346516680974

Epoch: 6| Step: 6
Training loss: 1.3823413848876953
Validation loss: 1.8149101247069657

Epoch: 6| Step: 7
Training loss: 1.4330649375915527
Validation loss: 1.8131326090904973

Epoch: 6| Step: 8
Training loss: 1.7450296878814697
Validation loss: 1.7870455057390275

Epoch: 6| Step: 9
Training loss: 1.5538361072540283
Validation loss: 1.817196141007126

Epoch: 6| Step: 10
Training loss: 1.2839716672897339
Validation loss: 1.824443035228278

Epoch: 6| Step: 11
Training loss: 1.3847010135650635
Validation loss: 1.8031655165456957

Epoch: 6| Step: 12
Training loss: 1.6253520250320435
Validation loss: 1.8313556255832795

Epoch: 6| Step: 13
Training loss: 1.4487290382385254
Validation loss: 1.828175405020355

Epoch: 297| Step: 0
Training loss: 1.6994400024414062
Validation loss: 1.8187808016295075

Epoch: 6| Step: 1
Training loss: 1.1589131355285645
Validation loss: 1.7790247932557137

Epoch: 6| Step: 2
Training loss: 1.017246127128601
Validation loss: 1.8292884980478594

Epoch: 6| Step: 3
Training loss: 2.0957107543945312
Validation loss: 1.7994395353460824

Epoch: 6| Step: 4
Training loss: 1.3425564765930176
Validation loss: 1.8033563257545553

Epoch: 6| Step: 5
Training loss: 1.7382428646087646
Validation loss: 1.7792117621309014

Epoch: 6| Step: 6
Training loss: 2.0145249366760254
Validation loss: 1.820982894589824

Epoch: 6| Step: 7
Training loss: 1.2812747955322266
Validation loss: 1.7956233280961231

Epoch: 6| Step: 8
Training loss: 1.4175548553466797
Validation loss: 1.811217192680605

Epoch: 6| Step: 9
Training loss: 1.358459711074829
Validation loss: 1.8219918025437223

Epoch: 6| Step: 10
Training loss: 1.5952775478363037
Validation loss: 1.8152543703715007

Epoch: 6| Step: 11
Training loss: 0.8800021409988403
Validation loss: 1.7657606345351025

Epoch: 6| Step: 12
Training loss: 1.9048161506652832
Validation loss: 1.8553097735169113

Epoch: 6| Step: 13
Training loss: 2.4083261489868164
Validation loss: 1.7907428497909217

Epoch: 298| Step: 0
Training loss: 1.6255712509155273
Validation loss: 1.7890591172761814

Epoch: 6| Step: 1
Training loss: 1.39702308177948
Validation loss: 1.8175261482115714

Epoch: 6| Step: 2
Training loss: 1.8510854244232178
Validation loss: 1.809642646902351

Epoch: 6| Step: 3
Training loss: 1.9279388189315796
Validation loss: 1.831107162660168

Epoch: 6| Step: 4
Training loss: 1.6535528898239136
Validation loss: 1.8208747435641546

Epoch: 6| Step: 5
Training loss: 1.505045771598816
Validation loss: 1.779464429424655

Epoch: 6| Step: 6
Training loss: 1.2935795783996582
Validation loss: 1.7868348424152662

Epoch: 6| Step: 7
Training loss: 1.178376317024231
Validation loss: 1.7961329055088822

Epoch: 6| Step: 8
Training loss: 0.8974318504333496
Validation loss: 1.7626709527866815

Epoch: 6| Step: 9
Training loss: 1.7374235391616821
Validation loss: 1.7881366706663562

Epoch: 6| Step: 10
Training loss: 1.1163121461868286
Validation loss: 1.800458388943826

Epoch: 6| Step: 11
Training loss: 1.4281890392303467
Validation loss: 1.8344918809911257

Epoch: 6| Step: 12
Training loss: 2.4644243717193604
Validation loss: 1.8018006509350193

Epoch: 6| Step: 13
Training loss: 1.6828649044036865
Validation loss: 1.78674151051429

Epoch: 299| Step: 0
Training loss: 1.3454583883285522
Validation loss: 1.7892227583034064

Epoch: 6| Step: 1
Training loss: 1.2393958568572998
Validation loss: 1.7526178462530977

Epoch: 6| Step: 2
Training loss: 1.998732566833496
Validation loss: 1.8230572003190235

Epoch: 6| Step: 3
Training loss: 1.4227343797683716
Validation loss: 1.7541767666416783

Epoch: 6| Step: 4
Training loss: 1.796898603439331
Validation loss: 1.7988168962540165

Epoch: 6| Step: 5
Training loss: 1.6367697715759277
Validation loss: 1.7702571499732234

Epoch: 6| Step: 6
Training loss: 1.190629482269287
Validation loss: 1.7958465327498734

Epoch: 6| Step: 7
Training loss: 1.7221226692199707
Validation loss: 1.8039819220060944

Epoch: 6| Step: 8
Training loss: 1.7165629863739014
Validation loss: 1.7803380373985536

Epoch: 6| Step: 9
Training loss: 1.2421443462371826
Validation loss: 1.7510144146539832

Epoch: 6| Step: 10
Training loss: 1.8140898942947388
Validation loss: 1.787420649682322

Epoch: 6| Step: 11
Training loss: 2.1157727241516113
Validation loss: 1.7700164433448546

Epoch: 6| Step: 12
Training loss: 1.2774556875228882
Validation loss: 1.7943462389771656

Epoch: 6| Step: 13
Training loss: 0.5601534843444824
Validation loss: 1.8058486394984747

Epoch: 300| Step: 0
Training loss: 1.9332062005996704
Validation loss: 1.7408070141269314

Epoch: 6| Step: 1
Training loss: 1.5050398111343384
Validation loss: 1.7975897994092715

Epoch: 6| Step: 2
Training loss: 1.957596778869629
Validation loss: 1.7994627260392713

Epoch: 6| Step: 3
Training loss: 1.240564227104187
Validation loss: 1.7801612910404

Epoch: 6| Step: 4
Training loss: 1.1250771284103394
Validation loss: 1.7969737360554356

Epoch: 6| Step: 5
Training loss: 1.3894309997558594
Validation loss: 1.799460700763169

Epoch: 6| Step: 6
Training loss: 1.9914896488189697
Validation loss: 1.7913550048746087

Epoch: 6| Step: 7
Training loss: 1.5843594074249268
Validation loss: 1.8065320138008363

Epoch: 6| Step: 8
Training loss: 1.6644045114517212
Validation loss: 1.7895564840685936

Epoch: 6| Step: 9
Training loss: 1.3428536653518677
Validation loss: 1.7619604449118338

Epoch: 6| Step: 10
Training loss: 1.1991195678710938
Validation loss: 1.773745729077247

Epoch: 6| Step: 11
Training loss: 1.9327480792999268
Validation loss: 1.8052438151451848

Epoch: 6| Step: 12
Training loss: 1.1897863149642944
Validation loss: 1.8059219237296813

Epoch: 6| Step: 13
Training loss: 1.5804708003997803
Validation loss: 1.8338841212693082

Epoch: 301| Step: 0
Training loss: 1.4159096479415894
Validation loss: 1.8424394079433974

Epoch: 6| Step: 1
Training loss: 1.4350587129592896
Validation loss: 1.82158584748545

Epoch: 6| Step: 2
Training loss: 1.938042163848877
Validation loss: 1.800592989049932

Epoch: 6| Step: 3
Training loss: 1.247638463973999
Validation loss: 1.7867386123185516

Epoch: 6| Step: 4
Training loss: 1.462232232093811
Validation loss: 1.7902218116227018

Epoch: 6| Step: 5
Training loss: 1.8198014497756958
Validation loss: 1.7984081545183737

Epoch: 6| Step: 6
Training loss: 1.9477770328521729
Validation loss: 1.7844568926800963

Epoch: 6| Step: 7
Training loss: 2.1051859855651855
Validation loss: 1.7965714931488037

Epoch: 6| Step: 8
Training loss: 1.4796223640441895
Validation loss: 1.8085118083543674

Epoch: 6| Step: 9
Training loss: 1.3658220767974854
Validation loss: 1.8123217705757386

Epoch: 6| Step: 10
Training loss: 1.5607317686080933
Validation loss: 1.797801148506903

Epoch: 6| Step: 11
Training loss: 1.3398679494857788
Validation loss: 1.7706986537543676

Epoch: 6| Step: 12
Training loss: 1.1060264110565186
Validation loss: 1.7931310181976647

Epoch: 6| Step: 13
Training loss: 1.1857903003692627
Validation loss: 1.779716102025842

Epoch: 302| Step: 0
Training loss: 0.8496143817901611
Validation loss: 1.7984029067459928

Epoch: 6| Step: 1
Training loss: 1.9180361032485962
Validation loss: 1.78613083593307

Epoch: 6| Step: 2
Training loss: 1.4637811183929443
Validation loss: 1.8077346060865669

Epoch: 6| Step: 3
Training loss: 1.4624159336090088
Validation loss: 1.8078137649002897

Epoch: 6| Step: 4
Training loss: 1.8653895854949951
Validation loss: 1.7320848229110881

Epoch: 6| Step: 5
Training loss: 1.3356592655181885
Validation loss: 1.7543075174413703

Epoch: 6| Step: 6
Training loss: 2.029723644256592
Validation loss: 1.8168323296372608

Epoch: 6| Step: 7
Training loss: 1.4528744220733643
Validation loss: 1.773526942858132

Epoch: 6| Step: 8
Training loss: 1.53883695602417
Validation loss: 1.7717133311815159

Epoch: 6| Step: 9
Training loss: 1.4439811706542969
Validation loss: 1.7895390269576863

Epoch: 6| Step: 10
Training loss: 2.033830165863037
Validation loss: 1.8162862459818523

Epoch: 6| Step: 11
Training loss: 1.1530470848083496
Validation loss: 1.7649046528723933

Epoch: 6| Step: 12
Training loss: 1.1597723960876465
Validation loss: 1.7572879714350547

Epoch: 6| Step: 13
Training loss: 2.0172815322875977
Validation loss: 1.7721137808215233

Epoch: 303| Step: 0
Training loss: 1.254197597503662
Validation loss: 1.7911910613377888

Epoch: 6| Step: 1
Training loss: 1.2723296880722046
Validation loss: 1.8263766765594482

Epoch: 6| Step: 2
Training loss: 1.972562313079834
Validation loss: 1.7631524890981696

Epoch: 6| Step: 3
Training loss: 1.8591147661209106
Validation loss: 1.7678322753598612

Epoch: 6| Step: 4
Training loss: 1.5606510639190674
Validation loss: 1.7919422400894987

Epoch: 6| Step: 5
Training loss: 1.4646549224853516
Validation loss: 1.7907707832192863

Epoch: 6| Step: 6
Training loss: 1.7181124687194824
Validation loss: 1.8277118923843547

Epoch: 6| Step: 7
Training loss: 1.1408908367156982
Validation loss: 1.8017170070320048

Epoch: 6| Step: 8
Training loss: 1.6536550521850586
Validation loss: 1.829154376060732

Epoch: 6| Step: 9
Training loss: 0.856201171875
Validation loss: 1.7705240826452933

Epoch: 6| Step: 10
Training loss: 1.8274869918823242
Validation loss: 1.7985790275758313

Epoch: 6| Step: 11
Training loss: 1.8267990350723267
Validation loss: 1.7769656283881075

Epoch: 6| Step: 12
Training loss: 1.2323694229125977
Validation loss: 1.7845197108484083

Epoch: 6| Step: 13
Training loss: 2.5862200260162354
Validation loss: 1.8039656749335669

Epoch: 304| Step: 0
Training loss: 2.137270450592041
Validation loss: 1.827085038667084

Epoch: 6| Step: 1
Training loss: 1.6166956424713135
Validation loss: 1.818465684049873

Epoch: 6| Step: 2
Training loss: 1.462531566619873
Validation loss: 1.7879350262303506

Epoch: 6| Step: 3
Training loss: 1.2726823091506958
Validation loss: 1.7901102137821976

Epoch: 6| Step: 4
Training loss: 1.9546676874160767
Validation loss: 1.7861203083428003

Epoch: 6| Step: 5
Training loss: 0.9172909259796143
Validation loss: 1.7970522219134915

Epoch: 6| Step: 6
Training loss: 1.4939329624176025
Validation loss: 1.816045504744335

Epoch: 6| Step: 7
Training loss: 1.9164069890975952
Validation loss: 1.814564044757556

Epoch: 6| Step: 8
Training loss: 1.3745453357696533
Validation loss: 1.8308000333847538

Epoch: 6| Step: 9
Training loss: 1.2975282669067383
Validation loss: 1.8318333010519705

Epoch: 6| Step: 10
Training loss: 1.429459810256958
Validation loss: 1.839832063644163

Epoch: 6| Step: 11
Training loss: 1.7859876155853271
Validation loss: 1.7847188365074895

Epoch: 6| Step: 12
Training loss: 1.0444962978363037
Validation loss: 1.804914145059483

Epoch: 6| Step: 13
Training loss: 1.569199800491333
Validation loss: 1.7780537361739783

Epoch: 305| Step: 0
Training loss: 1.5310490131378174
Validation loss: 1.8551502484147266

Epoch: 6| Step: 1
Training loss: 1.4337072372436523
Validation loss: 1.7899468816736692

Epoch: 6| Step: 2
Training loss: 2.2106873989105225
Validation loss: 1.7823761624674643

Epoch: 6| Step: 3
Training loss: 1.397721529006958
Validation loss: 1.7773279759191698

Epoch: 6| Step: 4
Training loss: 1.2493458986282349
Validation loss: 1.8239627807371077

Epoch: 6| Step: 5
Training loss: 1.3301920890808105
Validation loss: 1.817433290584113

Epoch: 6| Step: 6
Training loss: 1.9989190101623535
Validation loss: 1.8066382113323416

Epoch: 6| Step: 7
Training loss: 1.4898924827575684
Validation loss: 1.7912275316894695

Epoch: 6| Step: 8
Training loss: 1.1379587650299072
Validation loss: 1.8198569705409389

Epoch: 6| Step: 9
Training loss: 2.042466163635254
Validation loss: 1.770579179128011

Epoch: 6| Step: 10
Training loss: 1.6639535427093506
Validation loss: 1.8032391994230208

Epoch: 6| Step: 11
Training loss: 1.2932076454162598
Validation loss: 1.7964782868662188

Epoch: 6| Step: 12
Training loss: 1.01378333568573
Validation loss: 1.783839048877839

Epoch: 6| Step: 13
Training loss: 1.739922046661377
Validation loss: 1.7873368288881035

Epoch: 306| Step: 0
Training loss: 1.5620903968811035
Validation loss: 1.8267474507772794

Epoch: 6| Step: 1
Training loss: 1.040995717048645
Validation loss: 1.7696807307581748

Epoch: 6| Step: 2
Training loss: 1.4805996417999268
Validation loss: 1.8320334393491027

Epoch: 6| Step: 3
Training loss: 1.2721765041351318
Validation loss: 1.8136862939403904

Epoch: 6| Step: 4
Training loss: 1.3766436576843262
Validation loss: 1.772933586951225

Epoch: 6| Step: 5
Training loss: 2.4782907962799072
Validation loss: 1.7959907939357143

Epoch: 6| Step: 6
Training loss: 1.7960673570632935
Validation loss: 1.7581167336433166

Epoch: 6| Step: 7
Training loss: 0.895631730556488
Validation loss: 1.7717919170215566

Epoch: 6| Step: 8
Training loss: 1.542344331741333
Validation loss: 1.7785521220135432

Epoch: 6| Step: 9
Training loss: 1.420190691947937
Validation loss: 1.7816494728929253

Epoch: 6| Step: 10
Training loss: 1.9608699083328247
Validation loss: 1.782690889091902

Epoch: 6| Step: 11
Training loss: 1.791103482246399
Validation loss: 1.7693503466985558

Epoch: 6| Step: 12
Training loss: 1.2199937105178833
Validation loss: 1.83531363420589

Epoch: 6| Step: 13
Training loss: 1.86513352394104
Validation loss: 1.780665207934636

Epoch: 307| Step: 0
Training loss: 1.5768625736236572
Validation loss: 1.8038996560599214

Epoch: 6| Step: 1
Training loss: 0.8777539134025574
Validation loss: 1.808714480810268

Epoch: 6| Step: 2
Training loss: 1.4175488948822021
Validation loss: 1.808882967118294

Epoch: 6| Step: 3
Training loss: 2.1371917724609375
Validation loss: 1.794728445750411

Epoch: 6| Step: 4
Training loss: 1.5826048851013184
Validation loss: 1.8118842891467515

Epoch: 6| Step: 5
Training loss: 1.2881243228912354
Validation loss: 1.7826153411660144

Epoch: 6| Step: 6
Training loss: 0.9981577396392822
Validation loss: 1.7831480836355558

Epoch: 6| Step: 7
Training loss: 1.3755844831466675
Validation loss: 1.7498316329012635

Epoch: 6| Step: 8
Training loss: 0.9997866749763489
Validation loss: 1.7644302268182077

Epoch: 6| Step: 9
Training loss: 1.307283878326416
Validation loss: 1.7665238124068066

Epoch: 6| Step: 10
Training loss: 1.6672685146331787
Validation loss: 1.794408195762224

Epoch: 6| Step: 11
Training loss: 2.0319137573242188
Validation loss: 1.7865013896778066

Epoch: 6| Step: 12
Training loss: 1.7618412971496582
Validation loss: 1.7689527516723962

Epoch: 6| Step: 13
Training loss: 2.299027681350708
Validation loss: 1.8057052396958875

Epoch: 308| Step: 0
Training loss: 1.822007417678833
Validation loss: 1.7830236727191555

Epoch: 6| Step: 1
Training loss: 1.1881929636001587
Validation loss: 1.8323992413859214

Epoch: 6| Step: 2
Training loss: 1.8896901607513428
Validation loss: 1.787450180258802

Epoch: 6| Step: 3
Training loss: 1.1781516075134277
Validation loss: 1.775297741736135

Epoch: 6| Step: 4
Training loss: 1.7941341400146484
Validation loss: 1.8158926117804743

Epoch: 6| Step: 5
Training loss: 1.115452766418457
Validation loss: 1.779494595784013

Epoch: 6| Step: 6
Training loss: 1.3961925506591797
Validation loss: 1.7816935329027073

Epoch: 6| Step: 7
Training loss: 1.212273120880127
Validation loss: 1.7873090172326693

Epoch: 6| Step: 8
Training loss: 1.450836420059204
Validation loss: 1.760457815662507

Epoch: 6| Step: 9
Training loss: 1.4786617755889893
Validation loss: 1.761873907940362

Epoch: 6| Step: 10
Training loss: 1.796409010887146
Validation loss: 1.8098278225109141

Epoch: 6| Step: 11
Training loss: 1.63680899143219
Validation loss: 1.7979806610333022

Epoch: 6| Step: 12
Training loss: 1.3304510116577148
Validation loss: 1.7847084691447597

Epoch: 6| Step: 13
Training loss: 1.75700044631958
Validation loss: 1.7727362391769246

Epoch: 309| Step: 0
Training loss: 0.9644559621810913
Validation loss: 1.7873360674868348

Epoch: 6| Step: 1
Training loss: 2.1128578186035156
Validation loss: 1.825580939169853

Epoch: 6| Step: 2
Training loss: 1.266106367111206
Validation loss: 1.8188119049995177

Epoch: 6| Step: 3
Training loss: 1.2614140510559082
Validation loss: 1.7900167357537053

Epoch: 6| Step: 4
Training loss: 1.242153525352478
Validation loss: 1.8138386998125302

Epoch: 6| Step: 5
Training loss: 1.6104650497436523
Validation loss: 1.8472951996710993

Epoch: 6| Step: 6
Training loss: 1.416303277015686
Validation loss: 1.8036753349406744

Epoch: 6| Step: 7
Training loss: 1.1562914848327637
Validation loss: 1.806229224769018

Epoch: 6| Step: 8
Training loss: 1.7435266971588135
Validation loss: 1.8085274106712752

Epoch: 6| Step: 9
Training loss: 1.8469218015670776
Validation loss: 1.8293478514558525

Epoch: 6| Step: 10
Training loss: 2.006202459335327
Validation loss: 1.7958307368780977

Epoch: 6| Step: 11
Training loss: 1.721260905265808
Validation loss: 1.825083496750042

Epoch: 6| Step: 12
Training loss: 1.342670202255249
Validation loss: 1.796691922731297

Epoch: 6| Step: 13
Training loss: 0.9296472072601318
Validation loss: 1.790577797479527

Epoch: 310| Step: 0
Training loss: 1.6176133155822754
Validation loss: 1.8125789037314795

Epoch: 6| Step: 1
Training loss: 1.1583209037780762
Validation loss: 1.7836267255967664

Epoch: 6| Step: 2
Training loss: 1.3485833406448364
Validation loss: 1.8164730200203516

Epoch: 6| Step: 3
Training loss: 1.2513184547424316
Validation loss: 1.7589011987050374

Epoch: 6| Step: 4
Training loss: 1.2001123428344727
Validation loss: 1.7969018861811648

Epoch: 6| Step: 5
Training loss: 0.9720820188522339
Validation loss: 1.7950113691309446

Epoch: 6| Step: 6
Training loss: 1.9065321683883667
Validation loss: 1.7759289074969549

Epoch: 6| Step: 7
Training loss: 1.7120206356048584
Validation loss: 1.794434371814933

Epoch: 6| Step: 8
Training loss: 1.686873197555542
Validation loss: 1.7553367999292189

Epoch: 6| Step: 9
Training loss: 1.8333303928375244
Validation loss: 1.8067283707280313

Epoch: 6| Step: 10
Training loss: 1.375001311302185
Validation loss: 1.7807508117409163

Epoch: 6| Step: 11
Training loss: 1.9018750190734863
Validation loss: 1.770026042897214

Epoch: 6| Step: 12
Training loss: 1.6054129600524902
Validation loss: 1.8003842343566239

Epoch: 6| Step: 13
Training loss: 1.530220627784729
Validation loss: 1.7461956111333703

Epoch: 311| Step: 0
Training loss: 2.0876128673553467
Validation loss: 1.7688241389489943

Epoch: 6| Step: 1
Training loss: 1.3859705924987793
Validation loss: 1.7752062928292058

Epoch: 6| Step: 2
Training loss: 1.8835686445236206
Validation loss: 1.803885402217988

Epoch: 6| Step: 3
Training loss: 1.4832799434661865
Validation loss: 1.8033837618366364

Epoch: 6| Step: 4
Training loss: 1.2086795568466187
Validation loss: 1.8096700970844557

Epoch: 6| Step: 5
Training loss: 1.767404556274414
Validation loss: 1.7970664449917373

Epoch: 6| Step: 6
Training loss: 1.7750499248504639
Validation loss: 1.7699091370387743

Epoch: 6| Step: 7
Training loss: 1.5853562355041504
Validation loss: 1.76996216722714

Epoch: 6| Step: 8
Training loss: 1.2950748205184937
Validation loss: 1.7917228757694204

Epoch: 6| Step: 9
Training loss: 1.0391926765441895
Validation loss: 1.7897562083377634

Epoch: 6| Step: 10
Training loss: 1.6910350322723389
Validation loss: 1.7687963490845056

Epoch: 6| Step: 11
Training loss: 0.8507310748100281
Validation loss: 1.7741773679692259

Epoch: 6| Step: 12
Training loss: 1.2969794273376465
Validation loss: 1.7925597031911213

Epoch: 6| Step: 13
Training loss: 2.046473741531372
Validation loss: 1.7818131831384474

Epoch: 312| Step: 0
Training loss: 1.1186935901641846
Validation loss: 1.777461979978828

Epoch: 6| Step: 1
Training loss: 1.5798410177230835
Validation loss: 1.8104231178119619

Epoch: 6| Step: 2
Training loss: 2.099141836166382
Validation loss: 1.7815852831768733

Epoch: 6| Step: 3
Training loss: 1.5254261493682861
Validation loss: 1.7781426240039129

Epoch: 6| Step: 4
Training loss: 1.187186598777771
Validation loss: 1.8041518900984077

Epoch: 6| Step: 5
Training loss: 0.9556424617767334
Validation loss: 1.7556163046949653

Epoch: 6| Step: 6
Training loss: 1.5867931842803955
Validation loss: 1.7804797554528842

Epoch: 6| Step: 7
Training loss: 1.7570092678070068
Validation loss: 1.7934690880519089

Epoch: 6| Step: 8
Training loss: 1.9899964332580566
Validation loss: 1.7632305032463484

Epoch: 6| Step: 9
Training loss: 1.4005911350250244
Validation loss: 1.7625671291864047

Epoch: 6| Step: 10
Training loss: 1.7354214191436768
Validation loss: 1.784820149021764

Epoch: 6| Step: 11
Training loss: 1.0684627294540405
Validation loss: 1.798311924421659

Epoch: 6| Step: 12
Training loss: 1.7656793594360352
Validation loss: 1.8028855528882755

Epoch: 6| Step: 13
Training loss: 1.209403395652771
Validation loss: 1.7990048098307785

Epoch: 313| Step: 0
Training loss: 0.9000051021575928
Validation loss: 1.7696287952443606

Epoch: 6| Step: 1
Training loss: 2.1589581966400146
Validation loss: 1.7599478767764183

Epoch: 6| Step: 2
Training loss: 1.7725049257278442
Validation loss: 1.7421093781789143

Epoch: 6| Step: 3
Training loss: 1.6226117610931396
Validation loss: 1.8255830580188381

Epoch: 6| Step: 4
Training loss: 1.1431167125701904
Validation loss: 1.7650348960712392

Epoch: 6| Step: 5
Training loss: 2.019822835922241
Validation loss: 1.7530231232284217

Epoch: 6| Step: 6
Training loss: 1.9093424081802368
Validation loss: 1.7590943831269459

Epoch: 6| Step: 7
Training loss: 1.8349860906600952
Validation loss: 1.7701632579167683

Epoch: 6| Step: 8
Training loss: 1.3605493307113647
Validation loss: 1.8063261201304774

Epoch: 6| Step: 9
Training loss: 0.6403213739395142
Validation loss: 1.7677994940870552

Epoch: 6| Step: 10
Training loss: 1.4635871648788452
Validation loss: 1.7732942642704133

Epoch: 6| Step: 11
Training loss: 1.4416544437408447
Validation loss: 1.7666863074866674

Epoch: 6| Step: 12
Training loss: 1.425248146057129
Validation loss: 1.7758896299587783

Epoch: 6| Step: 13
Training loss: 1.1694214344024658
Validation loss: 1.7557670044642624

Epoch: 314| Step: 0
Training loss: 1.376598834991455
Validation loss: 1.7801367236721901

Epoch: 6| Step: 1
Training loss: 0.9785680770874023
Validation loss: 1.7878270854232132

Epoch: 6| Step: 2
Training loss: 1.2774806022644043
Validation loss: 1.7524544910718036

Epoch: 6| Step: 3
Training loss: 1.6097486019134521
Validation loss: 1.7958038545423938

Epoch: 6| Step: 4
Training loss: 1.7135368585586548
Validation loss: 1.7415047922442037

Epoch: 6| Step: 5
Training loss: 1.6378278732299805
Validation loss: 1.7770223848281368

Epoch: 6| Step: 6
Training loss: 1.6203054189682007
Validation loss: 1.7871144689539427

Epoch: 6| Step: 7
Training loss: 1.4545283317565918
Validation loss: 1.7598831666413175

Epoch: 6| Step: 8
Training loss: 2.0829577445983887
Validation loss: 1.7803796952770603

Epoch: 6| Step: 9
Training loss: 1.9551334381103516
Validation loss: 1.7749580234609625

Epoch: 6| Step: 10
Training loss: 0.9722031354904175
Validation loss: 1.7903727087923276

Epoch: 6| Step: 11
Training loss: 0.8889535069465637
Validation loss: 1.8110981756641018

Epoch: 6| Step: 12
Training loss: 2.060586929321289
Validation loss: 1.8176882984817668

Epoch: 6| Step: 13
Training loss: 1.3802485466003418
Validation loss: 1.8284539176571755

Epoch: 315| Step: 0
Training loss: 1.46213960647583
Validation loss: 1.8217858742642146

Epoch: 6| Step: 1
Training loss: 1.1736401319503784
Validation loss: 1.8203634728667557

Epoch: 6| Step: 2
Training loss: 0.9304720163345337
Validation loss: 1.8266347403167396

Epoch: 6| Step: 3
Training loss: 1.4171555042266846
Validation loss: 1.8115816552151915

Epoch: 6| Step: 4
Training loss: 1.1149966716766357
Validation loss: 1.7997180749011297

Epoch: 6| Step: 5
Training loss: 1.8456041812896729
Validation loss: 1.7776852141144455

Epoch: 6| Step: 6
Training loss: 2.013139486312866
Validation loss: 1.788035406861254

Epoch: 6| Step: 7
Training loss: 1.8011571168899536
Validation loss: 1.7741835296794932

Epoch: 6| Step: 8
Training loss: 1.3299264907836914
Validation loss: 1.7514449447713873

Epoch: 6| Step: 9
Training loss: 1.3684616088867188
Validation loss: 1.7891699690972604

Epoch: 6| Step: 10
Training loss: 1.0345404148101807
Validation loss: 1.7928698126987745

Epoch: 6| Step: 11
Training loss: 2.0587105751037598
Validation loss: 1.7636188204570482

Epoch: 6| Step: 12
Training loss: 0.9632759690284729
Validation loss: 1.7601967537274925

Epoch: 6| Step: 13
Training loss: 2.4987287521362305
Validation loss: 1.781271388453822

Epoch: 316| Step: 0
Training loss: 2.0206069946289062
Validation loss: 1.7851967747493456

Epoch: 6| Step: 1
Training loss: 0.8751097917556763
Validation loss: 1.7661332353468864

Epoch: 6| Step: 2
Training loss: 1.2219316959381104
Validation loss: 1.7270245731517833

Epoch: 6| Step: 3
Training loss: 1.707672119140625
Validation loss: 1.806184640494726

Epoch: 6| Step: 4
Training loss: 1.7134366035461426
Validation loss: 1.8261658248081003

Epoch: 6| Step: 5
Training loss: 1.6286594867706299
Validation loss: 1.8349220957807315

Epoch: 6| Step: 6
Training loss: 2.055480718612671
Validation loss: 1.8021279791350007

Epoch: 6| Step: 7
Training loss: 1.1975064277648926
Validation loss: 1.8545738881634128

Epoch: 6| Step: 8
Training loss: 1.811415433883667
Validation loss: 1.8444463629876413

Epoch: 6| Step: 9
Training loss: 0.9855109453201294
Validation loss: 1.847730957051759

Epoch: 6| Step: 10
Training loss: 0.7156550288200378
Validation loss: 1.8401192618954567

Epoch: 6| Step: 11
Training loss: 1.4120593070983887
Validation loss: 1.8393273661213536

Epoch: 6| Step: 12
Training loss: 1.4824533462524414
Validation loss: 1.782593834784723

Epoch: 6| Step: 13
Training loss: 2.611579418182373
Validation loss: 1.8374992160386936

Epoch: 317| Step: 0
Training loss: 1.700554609298706
Validation loss: 1.7828396469034173

Epoch: 6| Step: 1
Training loss: 1.3450968265533447
Validation loss: 1.8180488078824935

Epoch: 6| Step: 2
Training loss: 1.1707839965820312
Validation loss: 1.7789325252656014

Epoch: 6| Step: 3
Training loss: 1.5529214143753052
Validation loss: 1.7919964751889628

Epoch: 6| Step: 4
Training loss: 1.8303120136260986
Validation loss: 1.81430765762124

Epoch: 6| Step: 5
Training loss: 1.5497664213180542
Validation loss: 1.7750635788004885

Epoch: 6| Step: 6
Training loss: 1.6266944408416748
Validation loss: 1.7762195384630592

Epoch: 6| Step: 7
Training loss: 1.07289719581604
Validation loss: 1.7661575476328533

Epoch: 6| Step: 8
Training loss: 0.8108517527580261
Validation loss: 1.781379747134383

Epoch: 6| Step: 9
Training loss: 1.2059519290924072
Validation loss: 1.7684331914430023

Epoch: 6| Step: 10
Training loss: 1.280889630317688
Validation loss: 1.792378838344287

Epoch: 6| Step: 11
Training loss: 1.811410665512085
Validation loss: 1.746239375042659

Epoch: 6| Step: 12
Training loss: 1.6466022729873657
Validation loss: 1.776651213246007

Epoch: 6| Step: 13
Training loss: 2.655907154083252
Validation loss: 1.762238048738049

Epoch: 318| Step: 0
Training loss: 1.373542308807373
Validation loss: 1.774831420631819

Epoch: 6| Step: 1
Training loss: 1.1970406770706177
Validation loss: 1.7746912048709007

Epoch: 6| Step: 2
Training loss: 1.619924545288086
Validation loss: 1.7552150641718218

Epoch: 6| Step: 3
Training loss: 1.839249610900879
Validation loss: 1.7734164845558904

Epoch: 6| Step: 4
Training loss: 1.0508192777633667
Validation loss: 1.8024618638459073

Epoch: 6| Step: 5
Training loss: 1.2709907293319702
Validation loss: 1.7952757753351682

Epoch: 6| Step: 6
Training loss: 1.1666204929351807
Validation loss: 1.7921981273158905

Epoch: 6| Step: 7
Training loss: 1.4334616661071777
Validation loss: 1.8227816704780824

Epoch: 6| Step: 8
Training loss: 2.1263084411621094
Validation loss: 1.7874077391880814

Epoch: 6| Step: 9
Training loss: 1.503514051437378
Validation loss: 1.7787652348959317

Epoch: 6| Step: 10
Training loss: 1.4694452285766602
Validation loss: 1.7898758983099332

Epoch: 6| Step: 11
Training loss: 1.4389190673828125
Validation loss: 1.7651748464953514

Epoch: 6| Step: 12
Training loss: 1.662621259689331
Validation loss: 1.8059322462287

Epoch: 6| Step: 13
Training loss: 2.003006935119629
Validation loss: 1.7906502036638157

Epoch: 319| Step: 0
Training loss: 1.4006760120391846
Validation loss: 1.7533559017283942

Epoch: 6| Step: 1
Training loss: 1.1681617498397827
Validation loss: 1.7780211587106027

Epoch: 6| Step: 2
Training loss: 1.4631990194320679
Validation loss: 1.7870473746330506

Epoch: 6| Step: 3
Training loss: 1.1639156341552734
Validation loss: 1.7912534731690601

Epoch: 6| Step: 4
Training loss: 2.425889015197754
Validation loss: 1.7548429504517586

Epoch: 6| Step: 5
Training loss: 0.7631882429122925
Validation loss: 1.7856285418233564

Epoch: 6| Step: 6
Training loss: 0.8154416084289551
Validation loss: 1.7966417651022635

Epoch: 6| Step: 7
Training loss: 1.5021185874938965
Validation loss: 1.7699819226418771

Epoch: 6| Step: 8
Training loss: 1.6353607177734375
Validation loss: 1.8172004799689017

Epoch: 6| Step: 9
Training loss: 1.6788557767868042
Validation loss: 1.7741606761050481

Epoch: 6| Step: 10
Training loss: 1.3741530179977417
Validation loss: 1.7575140383935743

Epoch: 6| Step: 11
Training loss: 1.43791925907135
Validation loss: 1.7545863505332702

Epoch: 6| Step: 12
Training loss: 2.144214153289795
Validation loss: 1.803162169712846

Epoch: 6| Step: 13
Training loss: 1.529260516166687
Validation loss: 1.7600430147622221

Epoch: 320| Step: 0
Training loss: 1.6540906429290771
Validation loss: 1.7822106410098333

Epoch: 6| Step: 1
Training loss: 1.8289973735809326
Validation loss: 1.754290488458449

Epoch: 6| Step: 2
Training loss: 1.2699494361877441
Validation loss: 1.760330702668877

Epoch: 6| Step: 3
Training loss: 1.2300844192504883
Validation loss: 1.7844536048109814

Epoch: 6| Step: 4
Training loss: 1.1316742897033691
Validation loss: 1.8141417887903029

Epoch: 6| Step: 5
Training loss: 1.2761142253875732
Validation loss: 1.7917143888370965

Epoch: 6| Step: 6
Training loss: 1.398154616355896
Validation loss: 1.8024938926901868

Epoch: 6| Step: 7
Training loss: 1.4849028587341309
Validation loss: 1.778715661776963

Epoch: 6| Step: 8
Training loss: 1.6026924848556519
Validation loss: 1.7887645844490296

Epoch: 6| Step: 9
Training loss: 1.7518740892410278
Validation loss: 1.775188587045157

Epoch: 6| Step: 10
Training loss: 1.3939589262008667
Validation loss: 1.809722751699468

Epoch: 6| Step: 11
Training loss: 1.298013687133789
Validation loss: 1.7831829581209409

Epoch: 6| Step: 12
Training loss: 1.9364697933197021
Validation loss: 1.7947234902330624

Epoch: 6| Step: 13
Training loss: 1.6925292015075684
Validation loss: 1.7442214322346512

Epoch: 321| Step: 0
Training loss: 1.0427495241165161
Validation loss: 1.7703349077573387

Epoch: 6| Step: 1
Training loss: 1.4470704793930054
Validation loss: 1.7562769894958825

Epoch: 6| Step: 2
Training loss: 1.3405766487121582
Validation loss: 1.7752096037710867

Epoch: 6| Step: 3
Training loss: 0.6185386180877686
Validation loss: 1.794220365503783

Epoch: 6| Step: 4
Training loss: 1.2817952632904053
Validation loss: 1.7522394746862433

Epoch: 6| Step: 5
Training loss: 1.684362769126892
Validation loss: 1.7839424917774815

Epoch: 6| Step: 6
Training loss: 1.3952908515930176
Validation loss: 1.8127596301417197

Epoch: 6| Step: 7
Training loss: 1.4812872409820557
Validation loss: 1.7427769784004457

Epoch: 6| Step: 8
Training loss: 1.724191427230835
Validation loss: 1.7941864254654094

Epoch: 6| Step: 9
Training loss: 1.2199456691741943
Validation loss: 1.8057108976507699

Epoch: 6| Step: 10
Training loss: 1.6241511106491089
Validation loss: 1.783530512163716

Epoch: 6| Step: 11
Training loss: 2.1628942489624023
Validation loss: 1.7615917151974094

Epoch: 6| Step: 12
Training loss: 1.9292035102844238
Validation loss: 1.7624450601557249

Epoch: 6| Step: 13
Training loss: 2.2290117740631104
Validation loss: 1.7595597390205628

Epoch: 322| Step: 0
Training loss: 1.4416539669036865
Validation loss: 1.776559788693664

Epoch: 6| Step: 1
Training loss: 1.472991943359375
Validation loss: 1.7930588645319785

Epoch: 6| Step: 2
Training loss: 1.7744958400726318
Validation loss: 1.7834841051409323

Epoch: 6| Step: 3
Training loss: 1.8888839483261108
Validation loss: 1.8053282089130853

Epoch: 6| Step: 4
Training loss: 0.9202687740325928
Validation loss: 1.7641432567309308

Epoch: 6| Step: 5
Training loss: 1.550825834274292
Validation loss: 1.8132356430894585

Epoch: 6| Step: 6
Training loss: 1.9183459281921387
Validation loss: 1.776815378537742

Epoch: 6| Step: 7
Training loss: 1.6196963787078857
Validation loss: 1.7834013072393273

Epoch: 6| Step: 8
Training loss: 1.4854487180709839
Validation loss: 1.7838214494848763

Epoch: 6| Step: 9
Training loss: 1.4775604009628296
Validation loss: 1.7936425555136897

Epoch: 6| Step: 10
Training loss: 1.1386353969573975
Validation loss: 1.7577127641247166

Epoch: 6| Step: 11
Training loss: 1.4944038391113281
Validation loss: 1.7595180965239001

Epoch: 6| Step: 12
Training loss: 1.516757607460022
Validation loss: 1.7697564568570865

Epoch: 6| Step: 13
Training loss: 1.2095938920974731
Validation loss: 1.770988836083361

Epoch: 323| Step: 0
Training loss: 0.9180659651756287
Validation loss: 1.7880200801357147

Epoch: 6| Step: 1
Training loss: 1.5960302352905273
Validation loss: 1.7711752230121243

Epoch: 6| Step: 2
Training loss: 1.3267836570739746
Validation loss: 1.774653083534651

Epoch: 6| Step: 3
Training loss: 1.9027141332626343
Validation loss: 1.7666678685013966

Epoch: 6| Step: 4
Training loss: 1.9809095859527588
Validation loss: 1.7791064016280635

Epoch: 6| Step: 5
Training loss: 1.256941795349121
Validation loss: 1.8036701269047235

Epoch: 6| Step: 6
Training loss: 1.0824962854385376
Validation loss: 1.78521438055141

Epoch: 6| Step: 7
Training loss: 1.6248831748962402
Validation loss: 1.7813009228757632

Epoch: 6| Step: 8
Training loss: 1.6517786979675293
Validation loss: 1.7688104388534382

Epoch: 6| Step: 9
Training loss: 1.00105881690979
Validation loss: 1.782056736689742

Epoch: 6| Step: 10
Training loss: 1.9932990074157715
Validation loss: 1.795499394016881

Epoch: 6| Step: 11
Training loss: 1.5828371047973633
Validation loss: 1.7543804594265517

Epoch: 6| Step: 12
Training loss: 1.382711410522461
Validation loss: 1.7833402451648508

Epoch: 6| Step: 13
Training loss: 1.171114206314087
Validation loss: 1.8148675810906194

Epoch: 324| Step: 0
Training loss: 1.9031578302383423
Validation loss: 1.7559010572330926

Epoch: 6| Step: 1
Training loss: 2.1043243408203125
Validation loss: 1.7736163023979432

Epoch: 6| Step: 2
Training loss: 1.1277453899383545
Validation loss: 1.7733012296820199

Epoch: 6| Step: 3
Training loss: 1.6583073139190674
Validation loss: 1.77399048753964

Epoch: 6| Step: 4
Training loss: 0.6679549813270569
Validation loss: 1.7664841336588706

Epoch: 6| Step: 5
Training loss: 1.5197129249572754
Validation loss: 1.8033705206327542

Epoch: 6| Step: 6
Training loss: 1.4404138326644897
Validation loss: 1.7533899789215417

Epoch: 6| Step: 7
Training loss: 1.5283517837524414
Validation loss: 1.8140377049805017

Epoch: 6| Step: 8
Training loss: 1.0764925479888916
Validation loss: 1.795086068491782

Epoch: 6| Step: 9
Training loss: 1.2221851348876953
Validation loss: 1.8220414884628788

Epoch: 6| Step: 10
Training loss: 1.5727617740631104
Validation loss: 1.7750434080759685

Epoch: 6| Step: 11
Training loss: 1.5597972869873047
Validation loss: 1.782759388287862

Epoch: 6| Step: 12
Training loss: 1.2920408248901367
Validation loss: 1.7601514477883615

Epoch: 6| Step: 13
Training loss: 2.0789942741394043
Validation loss: 1.7944865560018888

Epoch: 325| Step: 0
Training loss: 1.006537914276123
Validation loss: 1.7971233629411267

Epoch: 6| Step: 1
Training loss: 1.5328936576843262
Validation loss: 1.769917861107857

Epoch: 6| Step: 2
Training loss: 2.323685646057129
Validation loss: 1.7688734351947744

Epoch: 6| Step: 3
Training loss: 1.3158676624298096
Validation loss: 1.7721064770093529

Epoch: 6| Step: 4
Training loss: 1.6415352821350098
Validation loss: 1.7889997241317586

Epoch: 6| Step: 5
Training loss: 1.5033751726150513
Validation loss: 1.7628059733298518

Epoch: 6| Step: 6
Training loss: 1.1387832164764404
Validation loss: 1.766846385053409

Epoch: 6| Step: 7
Training loss: 1.8769532442092896
Validation loss: 1.813502916725733

Epoch: 6| Step: 8
Training loss: 0.8925139904022217
Validation loss: 1.773829093543432

Epoch: 6| Step: 9
Training loss: 1.5157687664031982
Validation loss: 1.7520283447798861

Epoch: 6| Step: 10
Training loss: 1.9249112606048584
Validation loss: 1.795059545065767

Epoch: 6| Step: 11
Training loss: 1.145887851715088
Validation loss: 1.7713074709779473

Epoch: 6| Step: 12
Training loss: 1.2422667741775513
Validation loss: 1.7592358678899787

Epoch: 6| Step: 13
Training loss: 1.1384921073913574
Validation loss: 1.7773579884600896

Epoch: 326| Step: 0
Training loss: 1.182336688041687
Validation loss: 1.7921064656267884

Epoch: 6| Step: 1
Training loss: 1.5873496532440186
Validation loss: 1.7680374268562562

Epoch: 6| Step: 2
Training loss: 1.1780339479446411
Validation loss: 1.7482420154797134

Epoch: 6| Step: 3
Training loss: 1.2930339574813843
Validation loss: 1.7523157468406103

Epoch: 6| Step: 4
Training loss: 1.2484779357910156
Validation loss: 1.7548484007517497

Epoch: 6| Step: 5
Training loss: 1.2275179624557495
Validation loss: 1.7581268177237561

Epoch: 6| Step: 6
Training loss: 1.6494431495666504
Validation loss: 1.7389257723285305

Epoch: 6| Step: 7
Training loss: 1.9175173044204712
Validation loss: 1.7628178993860881

Epoch: 6| Step: 8
Training loss: 1.4347102642059326
Validation loss: 1.7653031695273615

Epoch: 6| Step: 9
Training loss: 1.9975569248199463
Validation loss: 1.7408621106096493

Epoch: 6| Step: 10
Training loss: 1.6248936653137207
Validation loss: 1.764445815035092

Epoch: 6| Step: 11
Training loss: 1.1314756870269775
Validation loss: 1.7789229744224138

Epoch: 6| Step: 12
Training loss: 2.0444631576538086
Validation loss: 1.761916237492715

Epoch: 6| Step: 13
Training loss: 1.3466851711273193
Validation loss: 1.7922407363050727

Epoch: 327| Step: 0
Training loss: 1.2145719528198242
Validation loss: 1.7699968686667822

Epoch: 6| Step: 1
Training loss: 1.1972339153289795
Validation loss: 1.8040055741545975

Epoch: 6| Step: 2
Training loss: 1.4324580430984497
Validation loss: 1.8200253030305267

Epoch: 6| Step: 3
Training loss: 1.869946837425232
Validation loss: 1.8162724459043114

Epoch: 6| Step: 4
Training loss: 1.9475953578948975
Validation loss: 1.8051176186530822

Epoch: 6| Step: 5
Training loss: 1.988698124885559
Validation loss: 1.814024817559027

Epoch: 6| Step: 6
Training loss: 1.0527644157409668
Validation loss: 1.8110571856139808

Epoch: 6| Step: 7
Training loss: 1.334366798400879
Validation loss: 1.7908610131150933

Epoch: 6| Step: 8
Training loss: 1.1697298288345337
Validation loss: 1.803125121260202

Epoch: 6| Step: 9
Training loss: 1.2309894561767578
Validation loss: 1.8108028134992045

Epoch: 6| Step: 10
Training loss: 1.1082146167755127
Validation loss: 1.8100012630544684

Epoch: 6| Step: 11
Training loss: 1.2673908472061157
Validation loss: 1.7742422793501167

Epoch: 6| Step: 12
Training loss: 1.53660249710083
Validation loss: 1.7728253231253674

Epoch: 6| Step: 13
Training loss: 3.2346293926239014
Validation loss: 1.7855153878529866

Epoch: 328| Step: 0
Training loss: 1.1958339214324951
Validation loss: 1.775326260956385

Epoch: 6| Step: 1
Training loss: 1.80015230178833
Validation loss: 1.7629892056988132

Epoch: 6| Step: 2
Training loss: 0.8430768251419067
Validation loss: 1.7309344583942043

Epoch: 6| Step: 3
Training loss: 0.8498017191886902
Validation loss: 1.7707026453428372

Epoch: 6| Step: 4
Training loss: 1.7620043754577637
Validation loss: 1.7577470271818099

Epoch: 6| Step: 5
Training loss: 2.3748936653137207
Validation loss: 1.7633202601504583

Epoch: 6| Step: 6
Training loss: 1.3003830909729004
Validation loss: 1.7734826123842629

Epoch: 6| Step: 7
Training loss: 1.060293436050415
Validation loss: 1.7442261903516707

Epoch: 6| Step: 8
Training loss: 1.1097187995910645
Validation loss: 1.7428869790928339

Epoch: 6| Step: 9
Training loss: 1.4049077033996582
Validation loss: 1.7579520299870481

Epoch: 6| Step: 10
Training loss: 1.4760595560073853
Validation loss: 1.7360049563069497

Epoch: 6| Step: 11
Training loss: 1.9107859134674072
Validation loss: 1.7839510927918136

Epoch: 6| Step: 12
Training loss: 1.3373303413391113
Validation loss: 1.764576014652047

Epoch: 6| Step: 13
Training loss: 2.1425065994262695
Validation loss: 1.7909820464349562

Epoch: 329| Step: 0
Training loss: 1.2419241666793823
Validation loss: 1.8037119488562308

Epoch: 6| Step: 1
Training loss: 0.9878206253051758
Validation loss: 1.8021431456330002

Epoch: 6| Step: 2
Training loss: 2.1375246047973633
Validation loss: 1.7620438478326286

Epoch: 6| Step: 3
Training loss: 0.8783297538757324
Validation loss: 1.7643958932609969

Epoch: 6| Step: 4
Training loss: 1.5667362213134766
Validation loss: 1.7339553602280156

Epoch: 6| Step: 5
Training loss: 1.502422571182251
Validation loss: 1.7800535232790056

Epoch: 6| Step: 6
Training loss: 1.5849168300628662
Validation loss: 1.7698968789910758

Epoch: 6| Step: 7
Training loss: 1.391405463218689
Validation loss: 1.7704684272889168

Epoch: 6| Step: 8
Training loss: 1.0325047969818115
Validation loss: 1.7517541390593334

Epoch: 6| Step: 9
Training loss: 1.439131259918213
Validation loss: 1.806757459076502

Epoch: 6| Step: 10
Training loss: 1.495992660522461
Validation loss: 1.75938493205655

Epoch: 6| Step: 11
Training loss: 1.9371495246887207
Validation loss: 1.7235515604736984

Epoch: 6| Step: 12
Training loss: 1.5754334926605225
Validation loss: 1.7511949411002539

Epoch: 6| Step: 13
Training loss: 1.6029607057571411
Validation loss: 1.7461727998589958

Epoch: 330| Step: 0
Training loss: 1.3710421323776245
Validation loss: 1.7560894720015987

Epoch: 6| Step: 1
Training loss: 1.4404606819152832
Validation loss: 1.7640539907640027

Epoch: 6| Step: 2
Training loss: 1.5145424604415894
Validation loss: 1.7214022041648946

Epoch: 6| Step: 3
Training loss: 1.3998184204101562
Validation loss: 1.7643573989150345

Epoch: 6| Step: 4
Training loss: 1.3638689517974854
Validation loss: 1.8030272094152306

Epoch: 6| Step: 5
Training loss: 1.4842332601547241
Validation loss: 1.7653562484248992

Epoch: 6| Step: 6
Training loss: 1.0822969675064087
Validation loss: 1.7529255510658346

Epoch: 6| Step: 7
Training loss: 1.838884949684143
Validation loss: 1.7459388599600842

Epoch: 6| Step: 8
Training loss: 1.317832112312317
Validation loss: 1.774210012087258

Epoch: 6| Step: 9
Training loss: 0.8540661334991455
Validation loss: 1.8071388070301344

Epoch: 6| Step: 10
Training loss: 1.624082326889038
Validation loss: 1.7530751305241739

Epoch: 6| Step: 11
Training loss: 1.5127232074737549
Validation loss: 1.781296000685743

Epoch: 6| Step: 12
Training loss: 2.215087413787842
Validation loss: 1.7698447460769324

Epoch: 6| Step: 13
Training loss: 1.8038030862808228
Validation loss: 1.7482823171923239

Epoch: 331| Step: 0
Training loss: 1.5279273986816406
Validation loss: 1.7473976765909502

Epoch: 6| Step: 1
Training loss: 1.2460051774978638
Validation loss: 1.787754153692594

Epoch: 6| Step: 2
Training loss: 1.6128618717193604
Validation loss: 1.7772609136437858

Epoch: 6| Step: 3
Training loss: 1.5087225437164307
Validation loss: 1.7752369501257454

Epoch: 6| Step: 4
Training loss: 1.2990615367889404
Validation loss: 1.790005769780887

Epoch: 6| Step: 5
Training loss: 1.4326062202453613
Validation loss: 1.7764025349770822

Epoch: 6| Step: 6
Training loss: 1.313591480255127
Validation loss: 1.76551450708861

Epoch: 6| Step: 7
Training loss: 1.452409029006958
Validation loss: 1.8056385363301923

Epoch: 6| Step: 8
Training loss: 1.4190168380737305
Validation loss: 1.7796834156077395

Epoch: 6| Step: 9
Training loss: 1.1560659408569336
Validation loss: 1.77977490937838

Epoch: 6| Step: 10
Training loss: 1.9404956102371216
Validation loss: 1.7268974011944187

Epoch: 6| Step: 11
Training loss: 1.6601264476776123
Validation loss: 1.7824252625947357

Epoch: 6| Step: 12
Training loss: 1.161839246749878
Validation loss: 1.7556183209983252

Epoch: 6| Step: 13
Training loss: 1.8335003852844238
Validation loss: 1.7345343430836995

Epoch: 332| Step: 0
Training loss: 1.3929692506790161
Validation loss: 1.7774503166957567

Epoch: 6| Step: 1
Training loss: 1.230165958404541
Validation loss: 1.7716674009958904

Epoch: 6| Step: 2
Training loss: 1.3999018669128418
Validation loss: 1.7808003220506894

Epoch: 6| Step: 3
Training loss: 1.0844898223876953
Validation loss: 1.7583536742835917

Epoch: 6| Step: 4
Training loss: 1.6650145053863525
Validation loss: 1.7830755351692118

Epoch: 6| Step: 5
Training loss: 1.7654025554656982
Validation loss: 1.758549367227862

Epoch: 6| Step: 6
Training loss: 1.4309136867523193
Validation loss: 1.7661512987588042

Epoch: 6| Step: 7
Training loss: 1.0796865224838257
Validation loss: 1.746192293782388

Epoch: 6| Step: 8
Training loss: 1.4834074974060059
Validation loss: 1.7547430633216776

Epoch: 6| Step: 9
Training loss: 1.3623371124267578
Validation loss: 1.7689190308252971

Epoch: 6| Step: 10
Training loss: 1.2035789489746094
Validation loss: 1.7389621350073046

Epoch: 6| Step: 11
Training loss: 2.3953537940979004
Validation loss: 1.7487075559554561

Epoch: 6| Step: 12
Training loss: 1.5829015970230103
Validation loss: 1.7518356307860343

Epoch: 6| Step: 13
Training loss: 1.1331400871276855
Validation loss: 1.7691856109967796

Epoch: 333| Step: 0
Training loss: 1.506547451019287
Validation loss: 1.7863962432389617

Epoch: 6| Step: 1
Training loss: 1.5184285640716553
Validation loss: 1.7509566468577231

Epoch: 6| Step: 2
Training loss: 1.364757776260376
Validation loss: 1.7662932718953779

Epoch: 6| Step: 3
Training loss: 1.216750979423523
Validation loss: 1.7932202316099597

Epoch: 6| Step: 4
Training loss: 1.556300401687622
Validation loss: 1.7978822428693053

Epoch: 6| Step: 5
Training loss: 1.1484293937683105
Validation loss: 1.800125350234329

Epoch: 6| Step: 6
Training loss: 1.2139716148376465
Validation loss: 1.7801864762460031

Epoch: 6| Step: 7
Training loss: 1.3294093608856201
Validation loss: 1.7506046051620154

Epoch: 6| Step: 8
Training loss: 0.9720984697341919
Validation loss: 1.7426700758677658

Epoch: 6| Step: 9
Training loss: 1.5579450130462646
Validation loss: 1.7779132012398011

Epoch: 6| Step: 10
Training loss: 1.6175661087036133
Validation loss: 1.773001645200996

Epoch: 6| Step: 11
Training loss: 1.3723559379577637
Validation loss: 1.794537462213988

Epoch: 6| Step: 12
Training loss: 1.6448743343353271
Validation loss: 1.8063078657273324

Epoch: 6| Step: 13
Training loss: 2.661823034286499
Validation loss: 1.7617639444207633

Epoch: 334| Step: 0
Training loss: 1.2072856426239014
Validation loss: 1.7669589160591044

Epoch: 6| Step: 1
Training loss: 0.7897842526435852
Validation loss: 1.7447990448244157

Epoch: 6| Step: 2
Training loss: 1.6481165885925293
Validation loss: 1.7739028469208749

Epoch: 6| Step: 3
Training loss: 1.2242733240127563
Validation loss: 1.7590422527764433

Epoch: 6| Step: 4
Training loss: 1.47841215133667
Validation loss: 1.764915552190555

Epoch: 6| Step: 5
Training loss: 1.854779601097107
Validation loss: 1.7690571136372064

Epoch: 6| Step: 6
Training loss: 1.9427118301391602
Validation loss: 1.7535635502107683

Epoch: 6| Step: 7
Training loss: 1.615837812423706
Validation loss: 1.7185866320005028

Epoch: 6| Step: 8
Training loss: 0.8465216755867004
Validation loss: 1.7538069294344993

Epoch: 6| Step: 9
Training loss: 1.3214473724365234
Validation loss: 1.7580511082885086

Epoch: 6| Step: 10
Training loss: 1.3448405265808105
Validation loss: 1.7932298234713975

Epoch: 6| Step: 11
Training loss: 2.0181093215942383
Validation loss: 1.7999147433106617

Epoch: 6| Step: 12
Training loss: 2.0272698402404785
Validation loss: 1.821214327248194

Epoch: 6| Step: 13
Training loss: 0.3019411265850067
Validation loss: 1.7636409690303188

Epoch: 335| Step: 0
Training loss: 1.4723320007324219
Validation loss: 1.7976481709429013

Epoch: 6| Step: 1
Training loss: 1.4168907403945923
Validation loss: 1.8080543984649002

Epoch: 6| Step: 2
Training loss: 0.7838485240936279
Validation loss: 1.8189486867638045

Epoch: 6| Step: 3
Training loss: 1.4585891962051392
Validation loss: 1.7923220255041634

Epoch: 6| Step: 4
Training loss: 1.5555329322814941
Validation loss: 1.8231095447335193

Epoch: 6| Step: 5
Training loss: 1.4690968990325928
Validation loss: 1.800671794081247

Epoch: 6| Step: 6
Training loss: 2.1083478927612305
Validation loss: 1.7820594144123856

Epoch: 6| Step: 7
Training loss: 1.084661841392517
Validation loss: 1.78321337187162

Epoch: 6| Step: 8
Training loss: 1.6335090398788452
Validation loss: 1.796390382192468

Epoch: 6| Step: 9
Training loss: 1.5924177169799805
Validation loss: 1.77839796773849

Epoch: 6| Step: 10
Training loss: 1.409438967704773
Validation loss: 1.7763423073676325

Epoch: 6| Step: 11
Training loss: 1.4486844539642334
Validation loss: 1.8087133053810365

Epoch: 6| Step: 12
Training loss: 1.2557258605957031
Validation loss: 1.7672720301535823

Epoch: 6| Step: 13
Training loss: 1.9754939079284668
Validation loss: 1.7351937960552912

Epoch: 336| Step: 0
Training loss: 1.3532359600067139
Validation loss: 1.7754552415622178

Epoch: 6| Step: 1
Training loss: 1.582290530204773
Validation loss: 1.7808705632404616

Epoch: 6| Step: 2
Training loss: 1.2854901552200317
Validation loss: 1.7820060868417062

Epoch: 6| Step: 3
Training loss: 1.6155006885528564
Validation loss: 1.7716379524559103

Epoch: 6| Step: 4
Training loss: 1.646329402923584
Validation loss: 1.75841325072832

Epoch: 6| Step: 5
Training loss: 2.063478946685791
Validation loss: 1.7723707511860838

Epoch: 6| Step: 6
Training loss: 0.7875758409500122
Validation loss: 1.6899642072698122

Epoch: 6| Step: 7
Training loss: 1.137434482574463
Validation loss: 1.7273551488435397

Epoch: 6| Step: 8
Training loss: 1.3353362083435059
Validation loss: 1.7862528190817883

Epoch: 6| Step: 9
Training loss: 1.7089629173278809
Validation loss: 1.74459211544324

Epoch: 6| Step: 10
Training loss: 1.7710702419281006
Validation loss: 1.7362492046048563

Epoch: 6| Step: 11
Training loss: 0.987076997756958
Validation loss: 1.7385645297265822

Epoch: 6| Step: 12
Training loss: 1.361924409866333
Validation loss: 1.7298025508080759

Epoch: 6| Step: 13
Training loss: 2.0030713081359863
Validation loss: 1.8062769789849558

Epoch: 337| Step: 0
Training loss: 1.8943946361541748
Validation loss: 1.7439759418528566

Epoch: 6| Step: 1
Training loss: 1.2713737487792969
Validation loss: 1.7539010483731505

Epoch: 6| Step: 2
Training loss: 1.0848212242126465
Validation loss: 1.7639761727343324

Epoch: 6| Step: 3
Training loss: 1.1983156204223633
Validation loss: 1.7291498684114026

Epoch: 6| Step: 4
Training loss: 1.012521505355835
Validation loss: 1.780573627000214

Epoch: 6| Step: 5
Training loss: 1.8938825130462646
Validation loss: 1.7845305883756248

Epoch: 6| Step: 6
Training loss: 1.7811015844345093
Validation loss: 1.7099234801466747

Epoch: 6| Step: 7
Training loss: 1.1745593547821045
Validation loss: 1.7701071923778904

Epoch: 6| Step: 8
Training loss: 1.0549654960632324
Validation loss: 1.742123866593966

Epoch: 6| Step: 9
Training loss: 0.9124463200569153
Validation loss: 1.738404381659723

Epoch: 6| Step: 10
Training loss: 2.066702365875244
Validation loss: 1.7521071318657166

Epoch: 6| Step: 11
Training loss: 1.4822837114334106
Validation loss: 1.7616910652447773

Epoch: 6| Step: 12
Training loss: 1.5117522478103638
Validation loss: 1.7522743581443705

Epoch: 6| Step: 13
Training loss: 2.1997122764587402
Validation loss: 1.7742321119513562

Epoch: 338| Step: 0
Training loss: 1.2654389142990112
Validation loss: 1.763083730974505

Epoch: 6| Step: 1
Training loss: 1.4602940082550049
Validation loss: 1.8223596516475882

Epoch: 6| Step: 2
Training loss: 1.130181074142456
Validation loss: 1.7702397325987458

Epoch: 6| Step: 3
Training loss: 1.9065260887145996
Validation loss: 1.778530272104407

Epoch: 6| Step: 4
Training loss: 1.1586902141571045
Validation loss: 1.7597770152553436

Epoch: 6| Step: 5
Training loss: 1.2933893203735352
Validation loss: 1.794846991057037

Epoch: 6| Step: 6
Training loss: 1.8385838270187378
Validation loss: 1.719982406144501

Epoch: 6| Step: 7
Training loss: 1.6048177480697632
Validation loss: 1.7618996071559128

Epoch: 6| Step: 8
Training loss: 1.2484312057495117
Validation loss: 1.7764995380114483

Epoch: 6| Step: 9
Training loss: 0.9842831492424011
Validation loss: 1.7776550028913765

Epoch: 6| Step: 10
Training loss: 1.1336952447891235
Validation loss: 1.773445242194719

Epoch: 6| Step: 11
Training loss: 1.944340467453003
Validation loss: 1.702976885662284

Epoch: 6| Step: 12
Training loss: 1.1621379852294922
Validation loss: 1.765008459809006

Epoch: 6| Step: 13
Training loss: 1.5558217763900757
Validation loss: 1.7565457513255458

Epoch: 339| Step: 0
Training loss: 1.5349726676940918
Validation loss: 1.732179860914907

Epoch: 6| Step: 1
Training loss: 2.0820319652557373
Validation loss: 1.7594505061385453

Epoch: 6| Step: 2
Training loss: 1.2414093017578125
Validation loss: 1.725661834081014

Epoch: 6| Step: 3
Training loss: 0.9650782346725464
Validation loss: 1.7672723300995365

Epoch: 6| Step: 4
Training loss: 1.5902974605560303
Validation loss: 1.800745746140839

Epoch: 6| Step: 5
Training loss: 1.4963253736495972
Validation loss: 1.7775747263303368

Epoch: 6| Step: 6
Training loss: 1.8673627376556396
Validation loss: 1.7776073742938299

Epoch: 6| Step: 7
Training loss: 1.2985436916351318
Validation loss: 1.7606996035063138

Epoch: 6| Step: 8
Training loss: 1.3871300220489502
Validation loss: 1.7589378690206876

Epoch: 6| Step: 9
Training loss: 1.3715620040893555
Validation loss: 1.7603307206143615

Epoch: 6| Step: 10
Training loss: 1.0839663743972778
Validation loss: 1.7675985892613728

Epoch: 6| Step: 11
Training loss: 1.059962272644043
Validation loss: 1.7875537603132186

Epoch: 6| Step: 12
Training loss: 1.4325873851776123
Validation loss: 1.774870426424088

Epoch: 6| Step: 13
Training loss: 1.8351904153823853
Validation loss: 1.7241484759956278

Epoch: 340| Step: 0
Training loss: 1.0236456394195557
Validation loss: 1.7627939947189823

Epoch: 6| Step: 1
Training loss: 1.5060094594955444
Validation loss: 1.7249173797586912

Epoch: 6| Step: 2
Training loss: 1.180932641029358
Validation loss: 1.7612366586603143

Epoch: 6| Step: 3
Training loss: 1.5009559392929077
Validation loss: 1.7379948759591708

Epoch: 6| Step: 4
Training loss: 1.3663452863693237
Validation loss: 1.7275889124921573

Epoch: 6| Step: 5
Training loss: 1.4269558191299438
Validation loss: 1.7413526517088695

Epoch: 6| Step: 6
Training loss: 2.2638745307922363
Validation loss: 1.7646900723057408

Epoch: 6| Step: 7
Training loss: 1.2483025789260864
Validation loss: 1.7333421361061834

Epoch: 6| Step: 8
Training loss: 0.9468567967414856
Validation loss: 1.7478657640436643

Epoch: 6| Step: 9
Training loss: 1.4712218046188354
Validation loss: 1.7343135956794984

Epoch: 6| Step: 10
Training loss: 1.5904719829559326
Validation loss: 1.7894701086064821

Epoch: 6| Step: 11
Training loss: 1.6634910106658936
Validation loss: 1.808005848238545

Epoch: 6| Step: 12
Training loss: 1.0480692386627197
Validation loss: 1.7874020940514022

Epoch: 6| Step: 13
Training loss: 2.076712131500244
Validation loss: 1.7717277132054812

Epoch: 341| Step: 0
Training loss: 1.4359514713287354
Validation loss: 1.7615930784133174

Epoch: 6| Step: 1
Training loss: 1.31406831741333
Validation loss: 1.7722874508109143

Epoch: 6| Step: 2
Training loss: 1.3489670753479004
Validation loss: 1.7804533845634871

Epoch: 6| Step: 3
Training loss: 1.4891691207885742
Validation loss: 1.7911943594614665

Epoch: 6| Step: 4
Training loss: 1.4062776565551758
Validation loss: 1.7204957982545257

Epoch: 6| Step: 5
Training loss: 0.6618844270706177
Validation loss: 1.7725487191190001

Epoch: 6| Step: 6
Training loss: 1.5473687648773193
Validation loss: 1.7475251036305581

Epoch: 6| Step: 7
Training loss: 1.5597035884857178
Validation loss: 1.7606240857032038

Epoch: 6| Step: 8
Training loss: 1.3884072303771973
Validation loss: 1.7378572405025523

Epoch: 6| Step: 9
Training loss: 1.766355037689209
Validation loss: 1.8064482711976575

Epoch: 6| Step: 10
Training loss: 1.606397032737732
Validation loss: 1.7461653089010587

Epoch: 6| Step: 11
Training loss: 1.455917477607727
Validation loss: 1.782194588773994

Epoch: 6| Step: 12
Training loss: 1.7954133749008179
Validation loss: 1.7502128949729345

Epoch: 6| Step: 13
Training loss: 1.0539898872375488
Validation loss: 1.730665264591094

Epoch: 342| Step: 0
Training loss: 2.0501556396484375
Validation loss: 1.7105365748046546

Epoch: 6| Step: 1
Training loss: 1.0595612525939941
Validation loss: 1.731846039013196

Epoch: 6| Step: 2
Training loss: 1.476158618927002
Validation loss: 1.7668589238197572

Epoch: 6| Step: 3
Training loss: 1.4548516273498535
Validation loss: 1.8307589702708746

Epoch: 6| Step: 4
Training loss: 1.6299736499786377
Validation loss: 1.7747226004959435

Epoch: 6| Step: 5
Training loss: 1.1076951026916504
Validation loss: 1.7690071469994002

Epoch: 6| Step: 6
Training loss: 1.13826584815979
Validation loss: 1.7999157546668925

Epoch: 6| Step: 7
Training loss: 1.2543082237243652
Validation loss: 1.8211902136443763

Epoch: 6| Step: 8
Training loss: 1.2091128826141357
Validation loss: 1.8271047396044577

Epoch: 6| Step: 9
Training loss: 1.052203893661499
Validation loss: 1.754832879189522

Epoch: 6| Step: 10
Training loss: 1.6206978559494019
Validation loss: 1.8041492726213189

Epoch: 6| Step: 11
Training loss: 1.8512141704559326
Validation loss: 1.7708646148763678

Epoch: 6| Step: 12
Training loss: 1.6883922815322876
Validation loss: 1.7750769725409887

Epoch: 6| Step: 13
Training loss: 1.1670432090759277
Validation loss: 1.781803947623058

Epoch: 343| Step: 0
Training loss: 1.8262765407562256
Validation loss: 1.7684596507780013

Epoch: 6| Step: 1
Training loss: 1.411095380783081
Validation loss: 1.7144505772539365

Epoch: 6| Step: 2
Training loss: 1.3845350742340088
Validation loss: 1.7525194191163587

Epoch: 6| Step: 3
Training loss: 1.4417076110839844
Validation loss: 1.769109187587615

Epoch: 6| Step: 4
Training loss: 1.0566357374191284
Validation loss: 1.7865615813962874

Epoch: 6| Step: 5
Training loss: 1.0577317476272583
Validation loss: 1.7651052756976056

Epoch: 6| Step: 6
Training loss: 1.3714540004730225
Validation loss: 1.7083693588933637

Epoch: 6| Step: 7
Training loss: 1.4751176834106445
Validation loss: 1.7750498299957604

Epoch: 6| Step: 8
Training loss: 2.1648964881896973
Validation loss: 1.7448589071150749

Epoch: 6| Step: 9
Training loss: 1.470860481262207
Validation loss: 1.7658181600673224

Epoch: 6| Step: 10
Training loss: 1.4553163051605225
Validation loss: 1.7517316943855696

Epoch: 6| Step: 11
Training loss: 1.4461102485656738
Validation loss: 1.7567840340316936

Epoch: 6| Step: 12
Training loss: 1.256908655166626
Validation loss: 1.7620803181843092

Epoch: 6| Step: 13
Training loss: 1.5814584493637085
Validation loss: 1.7514625428825297

Epoch: 344| Step: 0
Training loss: 1.506312608718872
Validation loss: 1.7597186219307683

Epoch: 6| Step: 1
Training loss: 1.368466854095459
Validation loss: 1.7677361888270224

Epoch: 6| Step: 2
Training loss: 1.3270721435546875
Validation loss: 1.8148072201718566

Epoch: 6| Step: 3
Training loss: 1.631316900253296
Validation loss: 1.7842244717382616

Epoch: 6| Step: 4
Training loss: 1.7895294427871704
Validation loss: 1.854889069193153

Epoch: 6| Step: 5
Training loss: 1.4153079986572266
Validation loss: 1.817737179417764

Epoch: 6| Step: 6
Training loss: 1.0843502283096313
Validation loss: 1.809588001620385

Epoch: 6| Step: 7
Training loss: 1.5817697048187256
Validation loss: 1.7980482450095556

Epoch: 6| Step: 8
Training loss: 1.177549958229065
Validation loss: 1.8133314553127493

Epoch: 6| Step: 9
Training loss: 1.7097368240356445
Validation loss: 1.7983700690730926

Epoch: 6| Step: 10
Training loss: 1.583662748336792
Validation loss: 1.7864119416923934

Epoch: 6| Step: 11
Training loss: 1.20757257938385
Validation loss: 1.7659022141528387

Epoch: 6| Step: 12
Training loss: 1.5228263139724731
Validation loss: 1.7706932842090566

Epoch: 6| Step: 13
Training loss: 1.1225361824035645
Validation loss: 1.7566971689142206

Epoch: 345| Step: 0
Training loss: 1.4242489337921143
Validation loss: 1.7625887752861105

Epoch: 6| Step: 1
Training loss: 1.6129010915756226
Validation loss: 1.7630894696840675

Epoch: 6| Step: 2
Training loss: 1.4518277645111084
Validation loss: 1.750044233055525

Epoch: 6| Step: 3
Training loss: 1.027702808380127
Validation loss: 1.7661713015648626

Epoch: 6| Step: 4
Training loss: 1.2636486291885376
Validation loss: 1.7223784795371435

Epoch: 6| Step: 5
Training loss: 1.6094192266464233
Validation loss: 1.7594792330136864

Epoch: 6| Step: 6
Training loss: 1.376621961593628
Validation loss: 1.7627562861288748

Epoch: 6| Step: 7
Training loss: 1.2913472652435303
Validation loss: 1.7667134115772862

Epoch: 6| Step: 8
Training loss: 1.1887654066085815
Validation loss: 1.7429143177565707

Epoch: 6| Step: 9
Training loss: 1.1261727809906006
Validation loss: 1.773789337886277

Epoch: 6| Step: 10
Training loss: 1.8763279914855957
Validation loss: 1.7254272378900999

Epoch: 6| Step: 11
Training loss: 1.4204179048538208
Validation loss: 1.7630431164977372

Epoch: 6| Step: 12
Training loss: 1.4581403732299805
Validation loss: 1.7608164266873432

Epoch: 6| Step: 13
Training loss: 1.9227771759033203
Validation loss: 1.778982816203948

Epoch: 346| Step: 0
Training loss: 1.187880277633667
Validation loss: 1.7631174569488854

Epoch: 6| Step: 1
Training loss: 1.486061453819275
Validation loss: 1.7650986179228751

Epoch: 6| Step: 2
Training loss: 1.629676342010498
Validation loss: 1.7737584511439006

Epoch: 6| Step: 3
Training loss: 1.1342825889587402
Validation loss: 1.7734848068606468

Epoch: 6| Step: 4
Training loss: 0.997069239616394
Validation loss: 1.793234650806714

Epoch: 6| Step: 5
Training loss: 1.9281113147735596
Validation loss: 1.764265339861634

Epoch: 6| Step: 6
Training loss: 1.0403854846954346
Validation loss: 1.809123690410327

Epoch: 6| Step: 7
Training loss: 1.0316241979599
Validation loss: 1.7529549880694317

Epoch: 6| Step: 8
Training loss: 1.5975971221923828
Validation loss: 1.7559293790530133

Epoch: 6| Step: 9
Training loss: 1.4376953840255737
Validation loss: 1.7601844905525126

Epoch: 6| Step: 10
Training loss: 1.4828006029129028
Validation loss: 1.7995827210846769

Epoch: 6| Step: 11
Training loss: 1.4315780401229858
Validation loss: 1.7268846906641477

Epoch: 6| Step: 12
Training loss: 1.38240647315979
Validation loss: 1.7735270223309916

Epoch: 6| Step: 13
Training loss: 2.2464287281036377
Validation loss: 1.7344949950454056

Epoch: 347| Step: 0
Training loss: 1.5252046585083008
Validation loss: 1.7797832066012966

Epoch: 6| Step: 1
Training loss: 2.504777193069458
Validation loss: 1.7602017041175597

Epoch: 6| Step: 2
Training loss: 1.4666757583618164
Validation loss: 1.7330096511430637

Epoch: 6| Step: 3
Training loss: 1.7261254787445068
Validation loss: 1.7697864258161156

Epoch: 6| Step: 4
Training loss: 1.218168020248413
Validation loss: 1.7516353566159484

Epoch: 6| Step: 5
Training loss: 1.8316826820373535
Validation loss: 1.7872217470599758

Epoch: 6| Step: 6
Training loss: 1.2857911586761475
Validation loss: 1.7782502879378617

Epoch: 6| Step: 7
Training loss: 1.0872728824615479
Validation loss: 1.782628692606444

Epoch: 6| Step: 8
Training loss: 0.6908154487609863
Validation loss: 1.7672264537503641

Epoch: 6| Step: 9
Training loss: 1.2462421655654907
Validation loss: 1.777723910988018

Epoch: 6| Step: 10
Training loss: 1.2523829936981201
Validation loss: 1.799869183571108

Epoch: 6| Step: 11
Training loss: 1.504495620727539
Validation loss: 1.783581728576332

Epoch: 6| Step: 12
Training loss: 0.6825865507125854
Validation loss: 1.7939368563313638

Epoch: 6| Step: 13
Training loss: 1.6839778423309326
Validation loss: 1.781414358846603

Epoch: 348| Step: 0
Training loss: 1.0342280864715576
Validation loss: 1.7323975357958066

Epoch: 6| Step: 1
Training loss: 1.5815622806549072
Validation loss: 1.775038069294345

Epoch: 6| Step: 2
Training loss: 1.313462495803833
Validation loss: 1.7283506278068788

Epoch: 6| Step: 3
Training loss: 1.4999350309371948
Validation loss: 1.7517300498101018

Epoch: 6| Step: 4
Training loss: 1.2423090934753418
Validation loss: 1.7330691429876512

Epoch: 6| Step: 5
Training loss: 1.4860098361968994
Validation loss: 1.74777235779711

Epoch: 6| Step: 6
Training loss: 1.497185230255127
Validation loss: 1.7451108360803256

Epoch: 6| Step: 7
Training loss: 1.5580710172653198
Validation loss: 1.7493277916344263

Epoch: 6| Step: 8
Training loss: 1.260192632675171
Validation loss: 1.7817924432857062

Epoch: 6| Step: 9
Training loss: 1.687464714050293
Validation loss: 1.750132183874807

Epoch: 6| Step: 10
Training loss: 1.6817126274108887
Validation loss: 1.7531096883999404

Epoch: 6| Step: 11
Training loss: 1.405017375946045
Validation loss: 1.7781075034090268

Epoch: 6| Step: 12
Training loss: 1.3122867345809937
Validation loss: 1.8237152727701331

Epoch: 6| Step: 13
Training loss: 1.271147608757019
Validation loss: 1.8160354309184576

Epoch: 349| Step: 0
Training loss: 1.3185707330703735
Validation loss: 1.808928458921371

Epoch: 6| Step: 1
Training loss: 1.7772986888885498
Validation loss: 1.7981083341824111

Epoch: 6| Step: 2
Training loss: 1.2954663038253784
Validation loss: 1.8179407837570354

Epoch: 6| Step: 3
Training loss: 0.9295456409454346
Validation loss: 1.7702307393473964

Epoch: 6| Step: 4
Training loss: 1.307352066040039
Validation loss: 1.7874526695538593

Epoch: 6| Step: 5
Training loss: 1.7659883499145508
Validation loss: 1.8298030578961937

Epoch: 6| Step: 6
Training loss: 1.3685587644577026
Validation loss: 1.783787158227736

Epoch: 6| Step: 7
Training loss: 1.2017189264297485
Validation loss: 1.7718839324930662

Epoch: 6| Step: 8
Training loss: 1.0898561477661133
Validation loss: 1.7893560663346322

Epoch: 6| Step: 9
Training loss: 1.5406608581542969
Validation loss: 1.7636078596115112

Epoch: 6| Step: 10
Training loss: 1.5359983444213867
Validation loss: 1.769565075956365

Epoch: 6| Step: 11
Training loss: 1.8567206859588623
Validation loss: 1.764516217734224

Epoch: 6| Step: 12
Training loss: 1.5178029537200928
Validation loss: 1.7828720833665581

Epoch: 6| Step: 13
Training loss: 1.0922425985336304
Validation loss: 1.7543291609774354

Epoch: 350| Step: 0
Training loss: 1.477054476737976
Validation loss: 1.7481217820157287

Epoch: 6| Step: 1
Training loss: 1.764229416847229
Validation loss: 1.7900770607814993

Epoch: 6| Step: 2
Training loss: 0.9247227907180786
Validation loss: 1.7401327061396774

Epoch: 6| Step: 3
Training loss: 0.8993098735809326
Validation loss: 1.7178340381191624

Epoch: 6| Step: 4
Training loss: 1.2737529277801514
Validation loss: 1.7144597961056618

Epoch: 6| Step: 5
Training loss: 1.5581176280975342
Validation loss: 1.7445073717383928

Epoch: 6| Step: 6
Training loss: 1.2139102220535278
Validation loss: 1.730729902944257

Epoch: 6| Step: 7
Training loss: 1.3968796730041504
Validation loss: 1.7642178125278924

Epoch: 6| Step: 8
Training loss: 1.7209407091140747
Validation loss: 1.7441811459038847

Epoch: 6| Step: 9
Training loss: 1.5737473964691162
Validation loss: 1.7552860590719408

Epoch: 6| Step: 10
Training loss: 1.3827308416366577
Validation loss: 1.7784621113090104

Epoch: 6| Step: 11
Training loss: 1.3169876337051392
Validation loss: 1.7742225880263953

Epoch: 6| Step: 12
Training loss: 1.807356595993042
Validation loss: 1.8056297840610627

Epoch: 6| Step: 13
Training loss: 2.1019182205200195
Validation loss: 1.7971508900324504

Epoch: 351| Step: 0
Training loss: 1.0809822082519531
Validation loss: 1.7738393993787869

Epoch: 6| Step: 1
Training loss: 1.4507379531860352
Validation loss: 1.8238735852702972

Epoch: 6| Step: 2
Training loss: 0.9961885809898376
Validation loss: 1.8299998262877106

Epoch: 6| Step: 3
Training loss: 1.857049822807312
Validation loss: 1.8067312061145742

Epoch: 6| Step: 4
Training loss: 1.2142770290374756
Validation loss: 1.7977450586134387

Epoch: 6| Step: 5
Training loss: 1.4976478815078735
Validation loss: 1.7355150279178415

Epoch: 6| Step: 6
Training loss: 1.443159580230713
Validation loss: 1.7738971428204608

Epoch: 6| Step: 7
Training loss: 1.4426889419555664
Validation loss: 1.7986952617604246

Epoch: 6| Step: 8
Training loss: 1.696190595626831
Validation loss: 1.7705534171032649

Epoch: 6| Step: 9
Training loss: 1.1374322175979614
Validation loss: 1.807859859158916

Epoch: 6| Step: 10
Training loss: 1.3135716915130615
Validation loss: 1.7692441325033865

Epoch: 6| Step: 11
Training loss: 1.341801404953003
Validation loss: 1.7612118926099551

Epoch: 6| Step: 12
Training loss: 1.980014681816101
Validation loss: 1.7740085176242295

Epoch: 6| Step: 13
Training loss: 1.1786043643951416
Validation loss: 1.738240791905311

Epoch: 352| Step: 0
Training loss: 1.8009846210479736
Validation loss: 1.759771680319181

Epoch: 6| Step: 1
Training loss: 1.1215934753417969
Validation loss: 1.762691532411883

Epoch: 6| Step: 2
Training loss: 1.5117847919464111
Validation loss: 1.7123643031684301

Epoch: 6| Step: 3
Training loss: 1.3804795742034912
Validation loss: 1.722487570137106

Epoch: 6| Step: 4
Training loss: 0.9046863317489624
Validation loss: 1.702568281081415

Epoch: 6| Step: 5
Training loss: 1.0356885194778442
Validation loss: 1.755925807901608

Epoch: 6| Step: 6
Training loss: 2.6416866779327393
Validation loss: 1.778388439968068

Epoch: 6| Step: 7
Training loss: 1.5036561489105225
Validation loss: 1.7579130139402164

Epoch: 6| Step: 8
Training loss: 1.388681173324585
Validation loss: 1.7586211158383278

Epoch: 6| Step: 9
Training loss: 1.704169511795044
Validation loss: 1.7795190964975665

Epoch: 6| Step: 10
Training loss: 1.4965848922729492
Validation loss: 1.782454054842713

Epoch: 6| Step: 11
Training loss: 1.0797879695892334
Validation loss: 1.780408599043405

Epoch: 6| Step: 12
Training loss: 0.7393004298210144
Validation loss: 1.7688249580321773

Epoch: 6| Step: 13
Training loss: 1.0351250171661377
Validation loss: 1.7506186013580651

Epoch: 353| Step: 0
Training loss: 1.551798939704895
Validation loss: 1.7617610039249543

Epoch: 6| Step: 1
Training loss: 1.6002306938171387
Validation loss: 1.7298861959929108

Epoch: 6| Step: 2
Training loss: 1.1962910890579224
Validation loss: 1.737743975013815

Epoch: 6| Step: 3
Training loss: 1.3909776210784912
Validation loss: 1.7401663103411276

Epoch: 6| Step: 4
Training loss: 2.295358657836914
Validation loss: 1.740279398938661

Epoch: 6| Step: 5
Training loss: 1.188195824623108
Validation loss: 1.7764753949257635

Epoch: 6| Step: 6
Training loss: 0.9491750597953796
Validation loss: 1.7725798301799323

Epoch: 6| Step: 7
Training loss: 1.4087461233139038
Validation loss: 1.7424048710894842

Epoch: 6| Step: 8
Training loss: 1.6333352327346802
Validation loss: 1.738019202345161

Epoch: 6| Step: 9
Training loss: 1.7117435932159424
Validation loss: 1.7447034799924461

Epoch: 6| Step: 10
Training loss: 1.4495488405227661
Validation loss: 1.7553244713814027

Epoch: 6| Step: 11
Training loss: 1.1866501569747925
Validation loss: 1.7711533679757068

Epoch: 6| Step: 12
Training loss: 0.81346195936203
Validation loss: 1.798772540143741

Epoch: 6| Step: 13
Training loss: 1.1561270952224731
Validation loss: 1.7448334898999942

Epoch: 354| Step: 0
Training loss: 1.3808058500289917
Validation loss: 1.7854896835101548

Epoch: 6| Step: 1
Training loss: 0.9905000925064087
Validation loss: 1.7163719515646658

Epoch: 6| Step: 2
Training loss: 1.4343032836914062
Validation loss: 1.7403024601679977

Epoch: 6| Step: 3
Training loss: 1.3945581912994385
Validation loss: 1.7334585459001604

Epoch: 6| Step: 4
Training loss: 1.2676900625228882
Validation loss: 1.74479829624135

Epoch: 6| Step: 5
Training loss: 1.8711824417114258
Validation loss: 1.771505102034538

Epoch: 6| Step: 6
Training loss: 1.517199993133545
Validation loss: 1.731862719340991

Epoch: 6| Step: 7
Training loss: 1.8694086074829102
Validation loss: 1.7786667116226689

Epoch: 6| Step: 8
Training loss: 1.8569996356964111
Validation loss: 1.7690839972547305

Epoch: 6| Step: 9
Training loss: 1.5923422574996948
Validation loss: 1.7466506188915623

Epoch: 6| Step: 10
Training loss: 0.7759131193161011
Validation loss: 1.7837965155160556

Epoch: 6| Step: 11
Training loss: 1.482388973236084
Validation loss: 1.7455146927987375

Epoch: 6| Step: 12
Training loss: 1.2248247861862183
Validation loss: 1.785798043333074

Epoch: 6| Step: 13
Training loss: 0.4335883855819702
Validation loss: 1.7622143760804208

Epoch: 355| Step: 0
Training loss: 2.2559540271759033
Validation loss: 1.7322375248837214

Epoch: 6| Step: 1
Training loss: 1.4435410499572754
Validation loss: 1.7587166704157347

Epoch: 6| Step: 2
Training loss: 0.8490920662879944
Validation loss: 1.7484020827918925

Epoch: 6| Step: 3
Training loss: 1.9150936603546143
Validation loss: 1.7681432847053773

Epoch: 6| Step: 4
Training loss: 1.3668687343597412
Validation loss: 1.7299513457923807

Epoch: 6| Step: 5
Training loss: 1.2734025716781616
Validation loss: 1.6994209417732813

Epoch: 6| Step: 6
Training loss: 1.2358002662658691
Validation loss: 1.7340028285980225

Epoch: 6| Step: 7
Training loss: 1.6274234056472778
Validation loss: 1.7648019662467382

Epoch: 6| Step: 8
Training loss: 1.3455766439437866
Validation loss: 1.7531185227055703

Epoch: 6| Step: 9
Training loss: 1.5464427471160889
Validation loss: 1.7493974483141335

Epoch: 6| Step: 10
Training loss: 1.293859601020813
Validation loss: 1.808036788817375

Epoch: 6| Step: 11
Training loss: 0.6576648950576782
Validation loss: 1.7634750758447955

Epoch: 6| Step: 12
Training loss: 1.4732954502105713
Validation loss: 1.743127207602224

Epoch: 6| Step: 13
Training loss: 1.3913347721099854
Validation loss: 1.7506329692820066

Epoch: 356| Step: 0
Training loss: 1.6042640209197998
Validation loss: 1.7571008025958974

Epoch: 6| Step: 1
Training loss: 1.5339436531066895
Validation loss: 1.7876703034165085

Epoch: 6| Step: 2
Training loss: 1.685829758644104
Validation loss: 1.8146220099541448

Epoch: 6| Step: 3
Training loss: 1.771022915840149
Validation loss: 1.8206718070532686

Epoch: 6| Step: 4
Training loss: 0.9789637327194214
Validation loss: 1.7798273665930635

Epoch: 6| Step: 5
Training loss: 1.455798864364624
Validation loss: 1.7690633830203806

Epoch: 6| Step: 6
Training loss: 1.5581960678100586
Validation loss: 1.7669212241326608

Epoch: 6| Step: 7
Training loss: 1.5919787883758545
Validation loss: 1.7265784637902373

Epoch: 6| Step: 8
Training loss: 0.8464783430099487
Validation loss: 1.7191847139789211

Epoch: 6| Step: 9
Training loss: 0.8312469720840454
Validation loss: 1.7467833936855357

Epoch: 6| Step: 10
Training loss: 1.4102234840393066
Validation loss: 1.7168817225322928

Epoch: 6| Step: 11
Training loss: 1.2660410404205322
Validation loss: 1.7453892807806692

Epoch: 6| Step: 12
Training loss: 1.055075764656067
Validation loss: 1.7411512610732869

Epoch: 6| Step: 13
Training loss: 1.9218565225601196
Validation loss: 1.7342545383719987

Epoch: 357| Step: 0
Training loss: 1.740849256515503
Validation loss: 1.743464005890713

Epoch: 6| Step: 1
Training loss: 1.7185794115066528
Validation loss: 1.7845003284433836

Epoch: 6| Step: 2
Training loss: 1.3638266324996948
Validation loss: 1.7883592344099475

Epoch: 6| Step: 3
Training loss: 0.986373782157898
Validation loss: 1.7392587008014802

Epoch: 6| Step: 4
Training loss: 1.0920181274414062
Validation loss: 1.76378212564735

Epoch: 6| Step: 5
Training loss: 1.1625237464904785
Validation loss: 1.7611472734840967

Epoch: 6| Step: 6
Training loss: 1.244602918624878
Validation loss: 1.7462015818524104

Epoch: 6| Step: 7
Training loss: 1.945509672164917
Validation loss: 1.8043149850701774

Epoch: 6| Step: 8
Training loss: 1.6168144941329956
Validation loss: 1.779413575767189

Epoch: 6| Step: 9
Training loss: 1.8183295726776123
Validation loss: 1.7908326695042271

Epoch: 6| Step: 10
Training loss: 0.8933302164077759
Validation loss: 1.7784592041405298

Epoch: 6| Step: 11
Training loss: 1.0111678838729858
Validation loss: 1.818875487132739

Epoch: 6| Step: 12
Training loss: 1.338338851928711
Validation loss: 1.7512761892810944

Epoch: 6| Step: 13
Training loss: 1.88536536693573
Validation loss: 1.7453845700910013

Epoch: 358| Step: 0
Training loss: 1.5634572505950928
Validation loss: 1.7838114538500387

Epoch: 6| Step: 1
Training loss: 1.304645299911499
Validation loss: 1.7433266716618692

Epoch: 6| Step: 2
Training loss: 1.6253328323364258
Validation loss: 1.787404401327974

Epoch: 6| Step: 3
Training loss: 1.7142517566680908
Validation loss: 1.7050789992014568

Epoch: 6| Step: 4
Training loss: 1.2128032445907593
Validation loss: 1.7915117638085478

Epoch: 6| Step: 5
Training loss: 1.4332985877990723
Validation loss: 1.7741138665906844

Epoch: 6| Step: 6
Training loss: 1.1132407188415527
Validation loss: 1.7429907937203684

Epoch: 6| Step: 7
Training loss: 1.8869311809539795
Validation loss: 1.7527665117735505

Epoch: 6| Step: 8
Training loss: 1.4925117492675781
Validation loss: 1.750236052338795

Epoch: 6| Step: 9
Training loss: 1.5721666812896729
Validation loss: 1.758387734813075

Epoch: 6| Step: 10
Training loss: 0.8284857273101807
Validation loss: 1.7725042399539743

Epoch: 6| Step: 11
Training loss: 1.0569806098937988
Validation loss: 1.7522565318692116

Epoch: 6| Step: 12
Training loss: 1.4114081859588623
Validation loss: 1.7321798750149306

Epoch: 6| Step: 13
Training loss: 0.9521758556365967
Validation loss: 1.7468380415311424

Epoch: 359| Step: 0
Training loss: 1.828165888786316
Validation loss: 1.771710411194832

Epoch: 6| Step: 1
Training loss: 0.9490020275115967
Validation loss: 1.78706104781038

Epoch: 6| Step: 2
Training loss: 1.7693824768066406
Validation loss: 1.7425726767509215

Epoch: 6| Step: 3
Training loss: 1.5613234043121338
Validation loss: 1.725555068703108

Epoch: 6| Step: 4
Training loss: 1.40060293674469
Validation loss: 1.7675844354014243

Epoch: 6| Step: 5
Training loss: 1.3106331825256348
Validation loss: 1.7500262004072948

Epoch: 6| Step: 6
Training loss: 1.2464519739151
Validation loss: 1.77414958964112

Epoch: 6| Step: 7
Training loss: 1.0789941549301147
Validation loss: 1.7293077322744554

Epoch: 6| Step: 8
Training loss: 1.3760757446289062
Validation loss: 1.7270929223747664

Epoch: 6| Step: 9
Training loss: 0.7973847389221191
Validation loss: 1.7486446467779015

Epoch: 6| Step: 10
Training loss: 1.2231757640838623
Validation loss: 1.756822169467967

Epoch: 6| Step: 11
Training loss: 1.898296594619751
Validation loss: 1.7242000295269875

Epoch: 6| Step: 12
Training loss: 1.2189161777496338
Validation loss: 1.7607195249167822

Epoch: 6| Step: 13
Training loss: 1.4663591384887695
Validation loss: 1.7954391356437438

Epoch: 360| Step: 0
Training loss: 1.3876879215240479
Validation loss: 1.7595729879153672

Epoch: 6| Step: 1
Training loss: 0.9398786425590515
Validation loss: 1.7342303119679934

Epoch: 6| Step: 2
Training loss: 0.9858760833740234
Validation loss: 1.6806802570178945

Epoch: 6| Step: 3
Training loss: 1.6009985208511353
Validation loss: 1.726034793802487

Epoch: 6| Step: 4
Training loss: 1.3008403778076172
Validation loss: 1.7313516716803274

Epoch: 6| Step: 5
Training loss: 1.1501580476760864
Validation loss: 1.790565711195751

Epoch: 6| Step: 6
Training loss: 1.1537935733795166
Validation loss: 1.760559102540375

Epoch: 6| Step: 7
Training loss: 1.417802333831787
Validation loss: 1.7643765121377923

Epoch: 6| Step: 8
Training loss: 0.8924311399459839
Validation loss: 1.767961496947914

Epoch: 6| Step: 9
Training loss: 1.7938131093978882
Validation loss: 1.8079048125974593

Epoch: 6| Step: 10
Training loss: 1.4826633930206299
Validation loss: 1.78982174781061

Epoch: 6| Step: 11
Training loss: 1.7688459157943726
Validation loss: 1.7533328007626277

Epoch: 6| Step: 12
Training loss: 1.19514799118042
Validation loss: 1.7556906284824494

Epoch: 6| Step: 13
Training loss: 2.2815656661987305
Validation loss: 1.7168928859054402

Epoch: 361| Step: 0
Training loss: 1.5547168254852295
Validation loss: 1.7840617754126107

Epoch: 6| Step: 1
Training loss: 0.9597192406654358
Validation loss: 1.7552589216539938

Epoch: 6| Step: 2
Training loss: 0.9825876951217651
Validation loss: 1.7473977355546848

Epoch: 6| Step: 3
Training loss: 1.346299171447754
Validation loss: 1.7772359335294334

Epoch: 6| Step: 4
Training loss: 1.4047622680664062
Validation loss: 1.6860709792824202

Epoch: 6| Step: 5
Training loss: 1.8192436695098877
Validation loss: 1.7762519800534813

Epoch: 6| Step: 6
Training loss: 2.1154801845550537
Validation loss: 1.7602314320943688

Epoch: 6| Step: 7
Training loss: 0.9096580743789673
Validation loss: 1.7451278599359656

Epoch: 6| Step: 8
Training loss: 1.7891486883163452
Validation loss: 1.7278197144949308

Epoch: 6| Step: 9
Training loss: 1.1363879442214966
Validation loss: 1.7574998755608835

Epoch: 6| Step: 10
Training loss: 1.3926331996917725
Validation loss: 1.7668789432894798

Epoch: 6| Step: 11
Training loss: 1.1582154035568237
Validation loss: 1.7311179073907996

Epoch: 6| Step: 12
Training loss: 1.037684679031372
Validation loss: 1.7849204694071124

Epoch: 6| Step: 13
Training loss: 2.0951974391937256
Validation loss: 1.7868924448567052

Epoch: 362| Step: 0
Training loss: 1.1157958507537842
Validation loss: 1.7327791196043774

Epoch: 6| Step: 1
Training loss: 1.6551992893218994
Validation loss: 1.729413233777528

Epoch: 6| Step: 2
Training loss: 1.8866841793060303
Validation loss: 1.7297870125821841

Epoch: 6| Step: 3
Training loss: 1.54770827293396
Validation loss: 1.7192834897707867

Epoch: 6| Step: 4
Training loss: 1.2003071308135986
Validation loss: 1.7377122941837515

Epoch: 6| Step: 5
Training loss: 1.3330919742584229
Validation loss: 1.731067131924373

Epoch: 6| Step: 6
Training loss: 1.7893128395080566
Validation loss: 1.7615594581891132

Epoch: 6| Step: 7
Training loss: 1.947331190109253
Validation loss: 1.7840991148384668

Epoch: 6| Step: 8
Training loss: 1.309908390045166
Validation loss: 1.7658677870227444

Epoch: 6| Step: 9
Training loss: 0.795498788356781
Validation loss: 1.777579830538842

Epoch: 6| Step: 10
Training loss: 1.6264439821243286
Validation loss: 1.7860670935723089

Epoch: 6| Step: 11
Training loss: 1.2458562850952148
Validation loss: 1.7617868274770758

Epoch: 6| Step: 12
Training loss: 0.8137607574462891
Validation loss: 1.722077158189589

Epoch: 6| Step: 13
Training loss: 1.0878750085830688
Validation loss: 1.7821178679825158

Epoch: 363| Step: 0
Training loss: 1.2750924825668335
Validation loss: 1.753784095087359

Epoch: 6| Step: 1
Training loss: 1.5913759469985962
Validation loss: 1.743332193743798

Epoch: 6| Step: 2
Training loss: 1.303197979927063
Validation loss: 1.7556282140875374

Epoch: 6| Step: 3
Training loss: 1.3828024864196777
Validation loss: 1.7300202833708895

Epoch: 6| Step: 4
Training loss: 1.3275842666625977
Validation loss: 1.7257151590880526

Epoch: 6| Step: 5
Training loss: 1.8287981748580933
Validation loss: 1.7062706716599003

Epoch: 6| Step: 6
Training loss: 1.2178014516830444
Validation loss: 1.7454194138126988

Epoch: 6| Step: 7
Training loss: 1.5409377813339233
Validation loss: 1.7371190222360755

Epoch: 6| Step: 8
Training loss: 1.4296150207519531
Validation loss: 1.730452004299369

Epoch: 6| Step: 9
Training loss: 1.0633609294891357
Validation loss: 1.7435546190507951

Epoch: 6| Step: 10
Training loss: 0.9569191932678223
Validation loss: 1.7535235510077527

Epoch: 6| Step: 11
Training loss: 1.4114786386489868
Validation loss: 1.7287024797931794

Epoch: 6| Step: 12
Training loss: 1.515683650970459
Validation loss: 1.7623348082265546

Epoch: 6| Step: 13
Training loss: 1.2110074758529663
Validation loss: 1.7636848508670766

Epoch: 364| Step: 0
Training loss: 1.4464013576507568
Validation loss: 1.7829786897987447

Epoch: 6| Step: 1
Training loss: 1.6525341272354126
Validation loss: 1.7857898230193763

Epoch: 6| Step: 2
Training loss: 1.6231343746185303
Validation loss: 1.7864810010438323

Epoch: 6| Step: 3
Training loss: 1.1392426490783691
Validation loss: 1.8063886678347023

Epoch: 6| Step: 4
Training loss: 1.126770257949829
Validation loss: 1.8380858795617216

Epoch: 6| Step: 5
Training loss: 0.9434497356414795
Validation loss: 1.797522125705596

Epoch: 6| Step: 6
Training loss: 1.2105257511138916
Validation loss: 1.7841538870206444

Epoch: 6| Step: 7
Training loss: 1.539800763130188
Validation loss: 1.774488995152135

Epoch: 6| Step: 8
Training loss: 1.819674015045166
Validation loss: 1.7736159114427463

Epoch: 6| Step: 9
Training loss: 1.143470048904419
Validation loss: 1.7595382121301466

Epoch: 6| Step: 10
Training loss: 1.1965501308441162
Validation loss: 1.7794528725326701

Epoch: 6| Step: 11
Training loss: 1.469975471496582
Validation loss: 1.7783509198055472

Epoch: 6| Step: 12
Training loss: 1.4906070232391357
Validation loss: 1.740409610091999

Epoch: 6| Step: 13
Training loss: 1.5938210487365723
Validation loss: 1.7339939173831735

Epoch: 365| Step: 0
Training loss: 1.0375349521636963
Validation loss: 1.7373147395349318

Epoch: 6| Step: 1
Training loss: 1.6804600954055786
Validation loss: 1.7366132813115274

Epoch: 6| Step: 2
Training loss: 1.4633349180221558
Validation loss: 1.762235951680009

Epoch: 6| Step: 3
Training loss: 1.0987136363983154
Validation loss: 1.7393443558805732

Epoch: 6| Step: 4
Training loss: 1.2028684616088867
Validation loss: 1.7338392619163758

Epoch: 6| Step: 5
Training loss: 1.0427597761154175
Validation loss: 1.717580315887287

Epoch: 6| Step: 6
Training loss: 1.5609512329101562
Validation loss: 1.7562147058466429

Epoch: 6| Step: 7
Training loss: 1.855825424194336
Validation loss: 1.75179414338963

Epoch: 6| Step: 8
Training loss: 1.293233871459961
Validation loss: 1.7475717990629134

Epoch: 6| Step: 9
Training loss: 1.492645025253296
Validation loss: 1.7669742325300812

Epoch: 6| Step: 10
Training loss: 1.4936671257019043
Validation loss: 1.7656617305612052

Epoch: 6| Step: 11
Training loss: 1.3959884643554688
Validation loss: 1.7355856331445838

Epoch: 6| Step: 12
Training loss: 1.2071954011917114
Validation loss: 1.8112486523966635

Epoch: 6| Step: 13
Training loss: 1.53977632522583
Validation loss: 1.7322969257190663

Epoch: 366| Step: 0
Training loss: 1.715333104133606
Validation loss: 1.7735986953140588

Epoch: 6| Step: 1
Training loss: 1.3475843667984009
Validation loss: 1.766447428734072

Epoch: 6| Step: 2
Training loss: 1.5512018203735352
Validation loss: 1.7319483526291386

Epoch: 6| Step: 3
Training loss: 1.0671491622924805
Validation loss: 1.77603232091473

Epoch: 6| Step: 4
Training loss: 1.1536993980407715
Validation loss: 1.7960277193336076

Epoch: 6| Step: 5
Training loss: 1.0397439002990723
Validation loss: 1.776200279112785

Epoch: 6| Step: 6
Training loss: 0.9691161513328552
Validation loss: 1.7706807505699895

Epoch: 6| Step: 7
Training loss: 1.9244621992111206
Validation loss: 1.7448371225787747

Epoch: 6| Step: 8
Training loss: 1.307682752609253
Validation loss: 1.7883454817597584

Epoch: 6| Step: 9
Training loss: 1.6816163063049316
Validation loss: 1.7747090285824192

Epoch: 6| Step: 10
Training loss: 1.4648587703704834
Validation loss: 1.744460609651381

Epoch: 6| Step: 11
Training loss: 1.3185338973999023
Validation loss: 1.7857065892988635

Epoch: 6| Step: 12
Training loss: 1.3816694021224976
Validation loss: 1.7132995904132884

Epoch: 6| Step: 13
Training loss: 1.0864087343215942
Validation loss: 1.7017128403468798

Epoch: 367| Step: 0
Training loss: 1.0231807231903076
Validation loss: 1.765894901367926

Epoch: 6| Step: 1
Training loss: 1.2750523090362549
Validation loss: 1.7388692068797287

Epoch: 6| Step: 2
Training loss: 1.3171062469482422
Validation loss: 1.7643935693207609

Epoch: 6| Step: 3
Training loss: 1.5933972597122192
Validation loss: 1.724059998348195

Epoch: 6| Step: 4
Training loss: 1.4525880813598633
Validation loss: 1.7756444408047585

Epoch: 6| Step: 5
Training loss: 1.6072115898132324
Validation loss: 1.756276346022083

Epoch: 6| Step: 6
Training loss: 1.365173101425171
Validation loss: 1.7090086219131306

Epoch: 6| Step: 7
Training loss: 1.537009358406067
Validation loss: 1.731050052950459

Epoch: 6| Step: 8
Training loss: 1.1751675605773926
Validation loss: 1.7578059780982234

Epoch: 6| Step: 9
Training loss: 1.5407789945602417
Validation loss: 1.7912866274515789

Epoch: 6| Step: 10
Training loss: 1.1024144887924194
Validation loss: 1.7498187326615857

Epoch: 6| Step: 11
Training loss: 1.1621404886245728
Validation loss: 1.7218201544977003

Epoch: 6| Step: 12
Training loss: 1.1378419399261475
Validation loss: 1.788001650123186

Epoch: 6| Step: 13
Training loss: 1.7123650312423706
Validation loss: 1.7324290365301154

Epoch: 368| Step: 0
Training loss: 1.1339187622070312
Validation loss: 1.7375590416692919

Epoch: 6| Step: 1
Training loss: 1.0997103452682495
Validation loss: 1.7849689222151233

Epoch: 6| Step: 2
Training loss: 1.3031831979751587
Validation loss: 1.8000057961351128

Epoch: 6| Step: 3
Training loss: 1.5422769784927368
Validation loss: 1.7536077191752772

Epoch: 6| Step: 4
Training loss: 1.947052240371704
Validation loss: 1.7978816519501388

Epoch: 6| Step: 5
Training loss: 1.8233458995819092
Validation loss: 1.7370116685026435

Epoch: 6| Step: 6
Training loss: 0.7415845394134521
Validation loss: 1.7356589135303293

Epoch: 6| Step: 7
Training loss: 1.4179409742355347
Validation loss: 1.7650330617863645

Epoch: 6| Step: 8
Training loss: 0.9534153938293457
Validation loss: 1.7591414579781153

Epoch: 6| Step: 9
Training loss: 1.2766529321670532
Validation loss: 1.7865322507837766

Epoch: 6| Step: 10
Training loss: 1.3328944444656372
Validation loss: 1.7423483389680103

Epoch: 6| Step: 11
Training loss: 1.7181432247161865
Validation loss: 1.7850511766249133

Epoch: 6| Step: 12
Training loss: 1.6169017553329468
Validation loss: 1.7454993801732217

Epoch: 6| Step: 13
Training loss: 1.2381501197814941
Validation loss: 1.774202831329838

Epoch: 369| Step: 0
Training loss: 1.658219337463379
Validation loss: 1.7339851164048719

Epoch: 6| Step: 1
Training loss: 1.4500987529754639
Validation loss: 1.8034876136369602

Epoch: 6| Step: 2
Training loss: 0.7168845534324646
Validation loss: 1.7311187610831311

Epoch: 6| Step: 3
Training loss: 1.4435992240905762
Validation loss: 1.7688063857375935

Epoch: 6| Step: 4
Training loss: 0.7306227087974548
Validation loss: 1.744605464320029

Epoch: 6| Step: 5
Training loss: 1.5915350914001465
Validation loss: 1.7358010045943721

Epoch: 6| Step: 6
Training loss: 1.5040032863616943
Validation loss: 1.7298310764374272

Epoch: 6| Step: 7
Training loss: 1.508581280708313
Validation loss: 1.7391398709307435

Epoch: 6| Step: 8
Training loss: 1.20467209815979
Validation loss: 1.743058878888366

Epoch: 6| Step: 9
Training loss: 1.4845869541168213
Validation loss: 1.7119945326159078

Epoch: 6| Step: 10
Training loss: 1.664374828338623
Validation loss: 1.7515419375511907

Epoch: 6| Step: 11
Training loss: 1.237704873085022
Validation loss: 1.7297384508194462

Epoch: 6| Step: 12
Training loss: 1.4519119262695312
Validation loss: 1.7631493838884498

Epoch: 6| Step: 13
Training loss: 0.7817996740341187
Validation loss: 1.78200731226193

Epoch: 370| Step: 0
Training loss: 1.5983291864395142
Validation loss: 1.7258743419442126

Epoch: 6| Step: 1
Training loss: 1.2528667449951172
Validation loss: 1.7745334525262155

Epoch: 6| Step: 2
Training loss: 1.3646790981292725
Validation loss: 1.7208541183061496

Epoch: 6| Step: 3
Training loss: 1.1804215908050537
Validation loss: 1.750156262869476

Epoch: 6| Step: 4
Training loss: 1.6789923906326294
Validation loss: 1.7639744384314424

Epoch: 6| Step: 5
Training loss: 1.3165863752365112
Validation loss: 1.7467512661410916

Epoch: 6| Step: 6
Training loss: 1.1361465454101562
Validation loss: 1.726375050442193

Epoch: 6| Step: 7
Training loss: 1.804225206375122
Validation loss: 1.744157036145528

Epoch: 6| Step: 8
Training loss: 1.2029792070388794
Validation loss: 1.724142204048813

Epoch: 6| Step: 9
Training loss: 1.7073519229888916
Validation loss: 1.739231933829605

Epoch: 6| Step: 10
Training loss: 0.9603757262229919
Validation loss: 1.7163652091897943

Epoch: 6| Step: 11
Training loss: 1.1929413080215454
Validation loss: 1.7783129048603836

Epoch: 6| Step: 12
Training loss: 1.3100720643997192
Validation loss: 1.708915304112178

Epoch: 6| Step: 13
Training loss: 1.2232208251953125
Validation loss: 1.7594062487284343

Epoch: 371| Step: 0
Training loss: 2.3332247734069824
Validation loss: 1.7361303708886588

Epoch: 6| Step: 1
Training loss: 1.7120347023010254
Validation loss: 1.7531876576844083

Epoch: 6| Step: 2
Training loss: 0.9930156469345093
Validation loss: 1.7914529410741662

Epoch: 6| Step: 3
Training loss: 0.9156026840209961
Validation loss: 1.731981873512268

Epoch: 6| Step: 4
Training loss: 1.2774447202682495
Validation loss: 1.7268787673724595

Epoch: 6| Step: 5
Training loss: 1.4320281744003296
Validation loss: 1.747115841475866

Epoch: 6| Step: 6
Training loss: 1.2502572536468506
Validation loss: 1.7351632348952755

Epoch: 6| Step: 7
Training loss: 1.043701410293579
Validation loss: 1.7619975574554936

Epoch: 6| Step: 8
Training loss: 1.6614396572113037
Validation loss: 1.729743657573577

Epoch: 6| Step: 9
Training loss: 1.6449942588806152
Validation loss: 1.737518205437609

Epoch: 6| Step: 10
Training loss: 0.7264087796211243
Validation loss: 1.694939403123753

Epoch: 6| Step: 11
Training loss: 1.644492268562317
Validation loss: 1.7486046565476285

Epoch: 6| Step: 12
Training loss: 1.1643927097320557
Validation loss: 1.7180212159310617

Epoch: 6| Step: 13
Training loss: 1.0049976110458374
Validation loss: 1.7089279095331829

Epoch: 372| Step: 0
Training loss: 1.0112686157226562
Validation loss: 1.7543734517148746

Epoch: 6| Step: 1
Training loss: 0.7804937362670898
Validation loss: 1.7844452345243065

Epoch: 6| Step: 2
Training loss: 1.0841515064239502
Validation loss: 1.7532266134856849

Epoch: 6| Step: 3
Training loss: 1.5789304971694946
Validation loss: 1.7744902205723587

Epoch: 6| Step: 4
Training loss: 0.8217872381210327
Validation loss: 1.7519653433112687

Epoch: 6| Step: 5
Training loss: 1.951595425605774
Validation loss: 1.8137187188671482

Epoch: 6| Step: 6
Training loss: 1.7103112936019897
Validation loss: 1.7989563724046111

Epoch: 6| Step: 7
Training loss: 1.893578290939331
Validation loss: 1.8175169639689948

Epoch: 6| Step: 8
Training loss: 1.4145057201385498
Validation loss: 1.8445450157247565

Epoch: 6| Step: 9
Training loss: 1.1125495433807373
Validation loss: 1.80117069777622

Epoch: 6| Step: 10
Training loss: 1.5205905437469482
Validation loss: 1.8087138386182888

Epoch: 6| Step: 11
Training loss: 1.7912590503692627
Validation loss: 1.7764072648940548

Epoch: 6| Step: 12
Training loss: 1.3646183013916016
Validation loss: 1.7795602685661727

Epoch: 6| Step: 13
Training loss: 0.8594518303871155
Validation loss: 1.7769368002491612

Epoch: 373| Step: 0
Training loss: 1.8971514701843262
Validation loss: 1.710157626418657

Epoch: 6| Step: 1
Training loss: 1.2760064601898193
Validation loss: 1.7929035976368894

Epoch: 6| Step: 2
Training loss: 1.1250149011611938
Validation loss: 1.7541789662453435

Epoch: 6| Step: 3
Training loss: 0.8035642504692078
Validation loss: 1.7198897459173714

Epoch: 6| Step: 4
Training loss: 1.342736005783081
Validation loss: 1.7399570044650827

Epoch: 6| Step: 5
Training loss: 1.7451223134994507
Validation loss: 1.7228508226333126

Epoch: 6| Step: 6
Training loss: 1.3367618322372437
Validation loss: 1.693091461735387

Epoch: 6| Step: 7
Training loss: 1.4890389442443848
Validation loss: 1.7336605774459017

Epoch: 6| Step: 8
Training loss: 1.3560144901275635
Validation loss: 1.7210518544720066

Epoch: 6| Step: 9
Training loss: 1.2331066131591797
Validation loss: 1.7266584365598616

Epoch: 6| Step: 10
Training loss: 2.036007881164551
Validation loss: 1.7696637312571208

Epoch: 6| Step: 11
Training loss: 0.9565900564193726
Validation loss: 1.7034815434486634

Epoch: 6| Step: 12
Training loss: 1.0867297649383545
Validation loss: 1.6991435827747468

Epoch: 6| Step: 13
Training loss: 1.3414185047149658
Validation loss: 1.6771769318529355

Epoch: 374| Step: 0
Training loss: 1.4395674467086792
Validation loss: 1.737482084381965

Epoch: 6| Step: 1
Training loss: 1.5260632038116455
Validation loss: 1.7228478821375037

Epoch: 6| Step: 2
Training loss: 1.778550148010254
Validation loss: 1.7614086187014015

Epoch: 6| Step: 3
Training loss: 0.7375650405883789
Validation loss: 1.7146406737706994

Epoch: 6| Step: 4
Training loss: 1.0687953233718872
Validation loss: 1.727427868432896

Epoch: 6| Step: 5
Training loss: 1.0685644149780273
Validation loss: 1.7344215723776049

Epoch: 6| Step: 6
Training loss: 0.9062370657920837
Validation loss: 1.7204682288631317

Epoch: 6| Step: 7
Training loss: 1.5533440113067627
Validation loss: 1.6713637011025542

Epoch: 6| Step: 8
Training loss: 1.5334010124206543
Validation loss: 1.7753241087800713

Epoch: 6| Step: 9
Training loss: 0.972612738609314
Validation loss: 1.7581239092734553

Epoch: 6| Step: 10
Training loss: 1.8642709255218506
Validation loss: 1.7150383251969532

Epoch: 6| Step: 11
Training loss: 1.4905894994735718
Validation loss: 1.766824831244766

Epoch: 6| Step: 12
Training loss: 1.2787516117095947
Validation loss: 1.7766346341820174

Epoch: 6| Step: 13
Training loss: 1.7995022535324097
Validation loss: 1.7588155384986632

Epoch: 375| Step: 0
Training loss: 0.9291709661483765
Validation loss: 1.7866907401751446

Epoch: 6| Step: 1
Training loss: 0.8386034965515137
Validation loss: 1.7662494400496125

Epoch: 6| Step: 2
Training loss: 1.4368878602981567
Validation loss: 1.749737572926347

Epoch: 6| Step: 3
Training loss: 1.507720708847046
Validation loss: 1.75772443638053

Epoch: 6| Step: 4
Training loss: 1.6557137966156006
Validation loss: 1.7570903455057452

Epoch: 6| Step: 5
Training loss: 1.7288460731506348
Validation loss: 1.7344547471692484

Epoch: 6| Step: 6
Training loss: 0.8724783062934875
Validation loss: 1.771609616535966

Epoch: 6| Step: 7
Training loss: 1.2977254390716553
Validation loss: 1.736412630286268

Epoch: 6| Step: 8
Training loss: 1.2709459066390991
Validation loss: 1.7255091769720918

Epoch: 6| Step: 9
Training loss: 1.5043468475341797
Validation loss: 1.7351034149046867

Epoch: 6| Step: 10
Training loss: 1.6634584665298462
Validation loss: 1.7833081368477113

Epoch: 6| Step: 11
Training loss: 1.4528260231018066
Validation loss: 1.7287195510761713

Epoch: 6| Step: 12
Training loss: 1.0944876670837402
Validation loss: 1.7103068097945182

Epoch: 6| Step: 13
Training loss: 1.627729892730713
Validation loss: 1.7555391634664228

Epoch: 376| Step: 0
Training loss: 1.2087931632995605
Validation loss: 1.7514014628625685

Epoch: 6| Step: 1
Training loss: 1.145376205444336
Validation loss: 1.7494552468740812

Epoch: 6| Step: 2
Training loss: 1.1927589178085327
Validation loss: 1.7351944959291847

Epoch: 6| Step: 3
Training loss: 1.2308961153030396
Validation loss: 1.7780731147335422

Epoch: 6| Step: 4
Training loss: 1.784409761428833
Validation loss: 1.7672073443730671

Epoch: 6| Step: 5
Training loss: 1.9448368549346924
Validation loss: 1.7826531805017942

Epoch: 6| Step: 6
Training loss: 1.2909672260284424
Validation loss: 1.823019726302034

Epoch: 6| Step: 7
Training loss: 1.3403456211090088
Validation loss: 1.818371226710658

Epoch: 6| Step: 8
Training loss: 1.3075251579284668
Validation loss: 1.8128767077640822

Epoch: 6| Step: 9
Training loss: 1.1687028408050537
Validation loss: 1.7753135773443407

Epoch: 6| Step: 10
Training loss: 1.4085683822631836
Validation loss: 1.7964264692798737

Epoch: 6| Step: 11
Training loss: 0.8321781754493713
Validation loss: 1.7261564782870713

Epoch: 6| Step: 12
Training loss: 1.653533697128296
Validation loss: 1.7513832123048845

Epoch: 6| Step: 13
Training loss: 1.555979609489441
Validation loss: 1.7782571520856632

Epoch: 377| Step: 0
Training loss: 1.001222848892212
Validation loss: 1.7396820283705188

Epoch: 6| Step: 1
Training loss: 1.6083742380142212
Validation loss: 1.7667688272332633

Epoch: 6| Step: 2
Training loss: 1.726165771484375
Validation loss: 1.7284577226126066

Epoch: 6| Step: 3
Training loss: 0.9608253836631775
Validation loss: 1.759057580783803

Epoch: 6| Step: 4
Training loss: 1.7387609481811523
Validation loss: 1.7243540530563684

Epoch: 6| Step: 5
Training loss: 1.2480356693267822
Validation loss: 1.7253702430314914

Epoch: 6| Step: 6
Training loss: 0.875756025314331
Validation loss: 1.713160046967127

Epoch: 6| Step: 7
Training loss: 1.7501965761184692
Validation loss: 1.6966754621075046

Epoch: 6| Step: 8
Training loss: 1.1958283185958862
Validation loss: 1.6941066416361

Epoch: 6| Step: 9
Training loss: 1.8293826580047607
Validation loss: 1.7941543684210828

Epoch: 6| Step: 10
Training loss: 1.1227046251296997
Validation loss: 1.7465471413827711

Epoch: 6| Step: 11
Training loss: 1.3181626796722412
Validation loss: 1.7740341207032562

Epoch: 6| Step: 12
Training loss: 1.4181253910064697
Validation loss: 1.7290965100770355

Epoch: 6| Step: 13
Training loss: 0.8941632509231567
Validation loss: 1.7354825940183414

Epoch: 378| Step: 0
Training loss: 1.0734622478485107
Validation loss: 1.7058437293575657

Epoch: 6| Step: 1
Training loss: 1.0606324672698975
Validation loss: 1.7320182964365969

Epoch: 6| Step: 2
Training loss: 1.3879064321517944
Validation loss: 1.7585852146148682

Epoch: 6| Step: 3
Training loss: 1.7375017404556274
Validation loss: 1.7707684988616614

Epoch: 6| Step: 4
Training loss: 1.2171412706375122
Validation loss: 1.8211320587383804

Epoch: 6| Step: 5
Training loss: 1.7251670360565186
Validation loss: 1.8098918776358328

Epoch: 6| Step: 6
Training loss: 1.543575406074524
Validation loss: 1.8270055863165087

Epoch: 6| Step: 7
Training loss: 1.5181083679199219
Validation loss: 1.8168186487690094

Epoch: 6| Step: 8
Training loss: 1.0795499086380005
Validation loss: 1.8191022924197617

Epoch: 6| Step: 9
Training loss: 1.4132790565490723
Validation loss: 1.7821233170006865

Epoch: 6| Step: 10
Training loss: 1.2175942659378052
Validation loss: 1.7879276506362423

Epoch: 6| Step: 11
Training loss: 1.4898968935012817
Validation loss: 1.7652232416214482

Epoch: 6| Step: 12
Training loss: 0.8161394596099854
Validation loss: 1.7644285104608024

Epoch: 6| Step: 13
Training loss: 1.579765796661377
Validation loss: 1.7005906669042443

Epoch: 379| Step: 0
Training loss: 1.1741228103637695
Validation loss: 1.7121233363305368

Epoch: 6| Step: 1
Training loss: 0.900833010673523
Validation loss: 1.7537363049804524

Epoch: 6| Step: 2
Training loss: 1.7937153577804565
Validation loss: 1.7430468707956293

Epoch: 6| Step: 3
Training loss: 1.7313458919525146
Validation loss: 1.7271442990149222

Epoch: 6| Step: 4
Training loss: 1.2632031440734863
Validation loss: 1.7147261711858934

Epoch: 6| Step: 5
Training loss: 1.002721905708313
Validation loss: 1.7620453232078142

Epoch: 6| Step: 6
Training loss: 1.3425238132476807
Validation loss: 1.7370346425681986

Epoch: 6| Step: 7
Training loss: 1.5037164688110352
Validation loss: 1.7243153151645456

Epoch: 6| Step: 8
Training loss: 0.8699455857276917
Validation loss: 1.733805989706388

Epoch: 6| Step: 9
Training loss: 1.157362699508667
Validation loss: 1.7574559732150006

Epoch: 6| Step: 10
Training loss: 1.3118467330932617
Validation loss: 1.7642980108978927

Epoch: 6| Step: 11
Training loss: 1.7345921993255615
Validation loss: 1.7581921713326567

Epoch: 6| Step: 12
Training loss: 1.5235095024108887
Validation loss: 1.7592404465521536

Epoch: 6| Step: 13
Training loss: 1.05361807346344
Validation loss: 1.7241462789556032

Epoch: 380| Step: 0
Training loss: 0.7256824374198914
Validation loss: 1.7505985588155768

Epoch: 6| Step: 1
Training loss: 1.3610506057739258
Validation loss: 1.7854690795303674

Epoch: 6| Step: 2
Training loss: 0.93184494972229
Validation loss: 1.744911318184227

Epoch: 6| Step: 3
Training loss: 1.4164671897888184
Validation loss: 1.73436640795841

Epoch: 6| Step: 4
Training loss: 1.560669183731079
Validation loss: 1.6983980786415838

Epoch: 6| Step: 5
Training loss: 1.0357539653778076
Validation loss: 1.7285342395946544

Epoch: 6| Step: 6
Training loss: 1.4194717407226562
Validation loss: 1.7696387434518466

Epoch: 6| Step: 7
Training loss: 1.6596965789794922
Validation loss: 1.7735011346878544

Epoch: 6| Step: 8
Training loss: 0.8828339576721191
Validation loss: 1.7385257187710013

Epoch: 6| Step: 9
Training loss: 1.3400416374206543
Validation loss: 1.7814981027316021

Epoch: 6| Step: 10
Training loss: 1.6538927555084229
Validation loss: 1.7880944846778788

Epoch: 6| Step: 11
Training loss: 1.5133986473083496
Validation loss: 1.788912175804056

Epoch: 6| Step: 12
Training loss: 1.373372197151184
Validation loss: 1.7450770434512888

Epoch: 6| Step: 13
Training loss: 1.5052410364151
Validation loss: 1.7629409759275374

Epoch: 381| Step: 0
Training loss: 1.4374563694000244
Validation loss: 1.7725715893571095

Epoch: 6| Step: 1
Training loss: 1.2202839851379395
Validation loss: 1.7610368292818788

Epoch: 6| Step: 2
Training loss: 1.4505647420883179
Validation loss: 1.7433376850620392

Epoch: 6| Step: 3
Training loss: 0.801552414894104
Validation loss: 1.7634890182043916

Epoch: 6| Step: 4
Training loss: 1.6379475593566895
Validation loss: 1.760091458597491

Epoch: 6| Step: 5
Training loss: 1.394413709640503
Validation loss: 1.7798136921339138

Epoch: 6| Step: 6
Training loss: 1.543705701828003
Validation loss: 1.769668174046342

Epoch: 6| Step: 7
Training loss: 1.6105561256408691
Validation loss: 1.7634580891619447

Epoch: 6| Step: 8
Training loss: 1.3821609020233154
Validation loss: 1.7546218992561422

Epoch: 6| Step: 9
Training loss: 0.9040825366973877
Validation loss: 1.7772420080759193

Epoch: 6| Step: 10
Training loss: 1.0853396654129028
Validation loss: 1.7343065892496417

Epoch: 6| Step: 11
Training loss: 1.5221344232559204
Validation loss: 1.7487430495600547

Epoch: 6| Step: 12
Training loss: 1.1887891292572021
Validation loss: 1.7418067686019405

Epoch: 6| Step: 13
Training loss: 1.6670970916748047
Validation loss: 1.7330058749004076

Epoch: 382| Step: 0
Training loss: 1.6131941080093384
Validation loss: 1.7308344097547634

Epoch: 6| Step: 1
Training loss: 1.5169072151184082
Validation loss: 1.7772396379901516

Epoch: 6| Step: 2
Training loss: 1.1801996231079102
Validation loss: 1.7380866850576093

Epoch: 6| Step: 3
Training loss: 1.5405954122543335
Validation loss: 1.717631951455147

Epoch: 6| Step: 4
Training loss: 1.4523831605911255
Validation loss: 1.7459247291729014

Epoch: 6| Step: 5
Training loss: 0.9835553765296936
Validation loss: 1.70183600020665

Epoch: 6| Step: 6
Training loss: 1.3947770595550537
Validation loss: 1.7175913523602229

Epoch: 6| Step: 7
Training loss: 1.2983992099761963
Validation loss: 1.755543916456161

Epoch: 6| Step: 8
Training loss: 1.1820638179779053
Validation loss: 1.7610356858981553

Epoch: 6| Step: 9
Training loss: 1.2069495916366577
Validation loss: 1.7508606218522595

Epoch: 6| Step: 10
Training loss: 1.1083099842071533
Validation loss: 1.7425710360209148

Epoch: 6| Step: 11
Training loss: 1.244854211807251
Validation loss: 1.730226388541601

Epoch: 6| Step: 12
Training loss: 1.449777364730835
Validation loss: 1.7338561422081404

Epoch: 6| Step: 13
Training loss: 1.4057116508483887
Validation loss: 1.7333127029480473

Epoch: 383| Step: 0
Training loss: 1.2005852460861206
Validation loss: 1.7064979294294953

Epoch: 6| Step: 1
Training loss: 1.872969388961792
Validation loss: 1.7650597954309115

Epoch: 6| Step: 2
Training loss: 0.4390319287776947
Validation loss: 1.7436529372328071

Epoch: 6| Step: 3
Training loss: 0.6719263195991516
Validation loss: 1.7790407429459274

Epoch: 6| Step: 4
Training loss: 1.1357440948486328
Validation loss: 1.7405203055309992

Epoch: 6| Step: 5
Training loss: 1.1214576959609985
Validation loss: 1.7661432617454118

Epoch: 6| Step: 6
Training loss: 1.4885038137435913
Validation loss: 1.7477421042739705

Epoch: 6| Step: 7
Training loss: 1.3971790075302124
Validation loss: 1.7338371853674612

Epoch: 6| Step: 8
Training loss: 2.0518722534179688
Validation loss: 1.7921376330878145

Epoch: 6| Step: 9
Training loss: 1.540818214416504
Validation loss: 1.7091622250054472

Epoch: 6| Step: 10
Training loss: 1.2976312637329102
Validation loss: 1.7304712444223382

Epoch: 6| Step: 11
Training loss: 1.5365431308746338
Validation loss: 1.7612142332138554

Epoch: 6| Step: 12
Training loss: 1.2555946111679077
Validation loss: 1.7449302122157107

Epoch: 6| Step: 13
Training loss: 1.2934691905975342
Validation loss: 1.7386890431886077

Epoch: 384| Step: 0
Training loss: 1.2015233039855957
Validation loss: 1.7719969223904353

Epoch: 6| Step: 1
Training loss: 1.0035507678985596
Validation loss: 1.7216711146857149

Epoch: 6| Step: 2
Training loss: 1.3256354331970215
Validation loss: 1.7339457517029138

Epoch: 6| Step: 3
Training loss: 1.239034652709961
Validation loss: 1.7265862021394955

Epoch: 6| Step: 4
Training loss: 1.5183086395263672
Validation loss: 1.6822664404428134

Epoch: 6| Step: 5
Training loss: 1.4612247943878174
Validation loss: 1.7125064890871766

Epoch: 6| Step: 6
Training loss: 1.1732875108718872
Validation loss: 1.7108725886191092

Epoch: 6| Step: 7
Training loss: 1.7505238056182861
Validation loss: 1.7137557255324496

Epoch: 6| Step: 8
Training loss: 1.3345093727111816
Validation loss: 1.7531833071862497

Epoch: 6| Step: 9
Training loss: 1.6023828983306885
Validation loss: 1.7294111726104573

Epoch: 6| Step: 10
Training loss: 1.0339871644973755
Validation loss: 1.7206781871857182

Epoch: 6| Step: 11
Training loss: 1.3953801393508911
Validation loss: 1.7580080109257852

Epoch: 6| Step: 12
Training loss: 0.8488951921463013
Validation loss: 1.739772165975263

Epoch: 6| Step: 13
Training loss: 1.7953321933746338
Validation loss: 1.771553793261128

Epoch: 385| Step: 0
Training loss: 1.9119514226913452
Validation loss: 1.7869960210656608

Epoch: 6| Step: 1
Training loss: 1.2268092632293701
Validation loss: 1.7587783144366356

Epoch: 6| Step: 2
Training loss: 1.690210223197937
Validation loss: 1.7390374906601445

Epoch: 6| Step: 3
Training loss: 1.0710980892181396
Validation loss: 1.7570110828645769

Epoch: 6| Step: 4
Training loss: 1.3796870708465576
Validation loss: 1.7573780513578845

Epoch: 6| Step: 5
Training loss: 0.9541841745376587
Validation loss: 1.7511101820135628

Epoch: 6| Step: 6
Training loss: 1.952204942703247
Validation loss: 1.7047362776212795

Epoch: 6| Step: 7
Training loss: 1.178858995437622
Validation loss: 1.7058179686146397

Epoch: 6| Step: 8
Training loss: 1.4656448364257812
Validation loss: 1.7039531046344387

Epoch: 6| Step: 9
Training loss: 1.285257339477539
Validation loss: 1.7421441193549865

Epoch: 6| Step: 10
Training loss: 0.8970974683761597
Validation loss: 1.7224621042128532

Epoch: 6| Step: 11
Training loss: 1.1743290424346924
Validation loss: 1.749867759725099

Epoch: 6| Step: 12
Training loss: 0.9207292795181274
Validation loss: 1.6909516267879035

Epoch: 6| Step: 13
Training loss: 1.2294749021530151
Validation loss: 1.7138587826041765

Epoch: 386| Step: 0
Training loss: 1.143754243850708
Validation loss: 1.7281727662650488

Epoch: 6| Step: 1
Training loss: 1.618972897529602
Validation loss: 1.731221011889878

Epoch: 6| Step: 2
Training loss: 1.2219014167785645
Validation loss: 1.7067161478022093

Epoch: 6| Step: 3
Training loss: 1.057953953742981
Validation loss: 1.7424663202736967

Epoch: 6| Step: 4
Training loss: 1.5507445335388184
Validation loss: 1.7158608039220173

Epoch: 6| Step: 5
Training loss: 1.3222168684005737
Validation loss: 1.7736964892315608

Epoch: 6| Step: 6
Training loss: 1.8687794208526611
Validation loss: 1.7624888855923888

Epoch: 6| Step: 7
Training loss: 1.4741077423095703
Validation loss: 1.72430750759699

Epoch: 6| Step: 8
Training loss: 1.049717664718628
Validation loss: 1.764087361674155

Epoch: 6| Step: 9
Training loss: 1.053632140159607
Validation loss: 1.7505891220543974

Epoch: 6| Step: 10
Training loss: 1.3182322978973389
Validation loss: 1.7604731667426325

Epoch: 6| Step: 11
Training loss: 0.9427134394645691
Validation loss: 1.7344119510342997

Epoch: 6| Step: 12
Training loss: 0.7570462226867676
Validation loss: 1.7272775314187492

Epoch: 6| Step: 13
Training loss: 1.3852187395095825
Validation loss: 1.7184065375276791

Epoch: 387| Step: 0
Training loss: 1.3975129127502441
Validation loss: 1.732077601135418

Epoch: 6| Step: 1
Training loss: 1.4562077522277832
Validation loss: 1.7584090848122873

Epoch: 6| Step: 2
Training loss: 0.9835454225540161
Validation loss: 1.72604880409856

Epoch: 6| Step: 3
Training loss: 1.3180654048919678
Validation loss: 1.758776730106723

Epoch: 6| Step: 4
Training loss: 1.489837408065796
Validation loss: 1.708876673893262

Epoch: 6| Step: 5
Training loss: 1.2737904787063599
Validation loss: 1.7710631226980558

Epoch: 6| Step: 6
Training loss: 1.857880711555481
Validation loss: 1.6743518537090671

Epoch: 6| Step: 7
Training loss: 1.7141715288162231
Validation loss: 1.7567913032347156

Epoch: 6| Step: 8
Training loss: 0.7926177978515625
Validation loss: 1.7262743185925227

Epoch: 6| Step: 9
Training loss: 1.3714563846588135
Validation loss: 1.7136128679398568

Epoch: 6| Step: 10
Training loss: 0.8109411001205444
Validation loss: 1.7316360435178202

Epoch: 6| Step: 11
Training loss: 1.5056941509246826
Validation loss: 1.732532822957603

Epoch: 6| Step: 12
Training loss: 0.6758250594139099
Validation loss: 1.7704176979680215

Epoch: 6| Step: 13
Training loss: 1.0545531511306763
Validation loss: 1.7159184960908787

Epoch: 388| Step: 0
Training loss: 1.241971492767334
Validation loss: 1.7269067597645584

Epoch: 6| Step: 1
Training loss: 1.2564125061035156
Validation loss: 1.7483511496615667

Epoch: 6| Step: 2
Training loss: 1.1487627029418945
Validation loss: 1.746113125995923

Epoch: 6| Step: 3
Training loss: 1.0623582601547241
Validation loss: 1.7274940885523313

Epoch: 6| Step: 4
Training loss: 0.6725850701332092
Validation loss: 1.7441117199518348

Epoch: 6| Step: 5
Training loss: 1.4544713497161865
Validation loss: 1.747352236060686

Epoch: 6| Step: 6
Training loss: 1.0371474027633667
Validation loss: 1.7223493450431413

Epoch: 6| Step: 7
Training loss: 0.6864199638366699
Validation loss: 1.777508569020097

Epoch: 6| Step: 8
Training loss: 1.7344233989715576
Validation loss: 1.7240195569171701

Epoch: 6| Step: 9
Training loss: 1.4436206817626953
Validation loss: 1.7291634454522082

Epoch: 6| Step: 10
Training loss: 1.8449525833129883
Validation loss: 1.725079563356215

Epoch: 6| Step: 11
Training loss: 0.8282449245452881
Validation loss: 1.7418346212756248

Epoch: 6| Step: 12
Training loss: 2.148756504058838
Validation loss: 1.7346520000888455

Epoch: 6| Step: 13
Training loss: 0.9329344630241394
Validation loss: 1.7455288274313814

Epoch: 389| Step: 0
Training loss: 1.2323894500732422
Validation loss: 1.7423485184228549

Epoch: 6| Step: 1
Training loss: 0.7860283255577087
Validation loss: 1.773621287397159

Epoch: 6| Step: 2
Training loss: 1.1757746934890747
Validation loss: 1.7149900518437868

Epoch: 6| Step: 3
Training loss: 1.2882270812988281
Validation loss: 1.7284155827696606

Epoch: 6| Step: 4
Training loss: 1.158357858657837
Validation loss: 1.7650098864750197

Epoch: 6| Step: 5
Training loss: 1.1276185512542725
Validation loss: 1.7125758060844996

Epoch: 6| Step: 6
Training loss: 1.2763919830322266
Validation loss: 1.7391242275955856

Epoch: 6| Step: 7
Training loss: 1.3561547994613647
Validation loss: 1.758473688556302

Epoch: 6| Step: 8
Training loss: 1.5893728733062744
Validation loss: 1.7791174893738122

Epoch: 6| Step: 9
Training loss: 1.2573199272155762
Validation loss: 1.7485247940145514

Epoch: 6| Step: 10
Training loss: 1.7746646404266357
Validation loss: 1.6965316623769782

Epoch: 6| Step: 11
Training loss: 1.490898847579956
Validation loss: 1.721364600684053

Epoch: 6| Step: 12
Training loss: 1.8263734579086304
Validation loss: 1.7278044672422512

Epoch: 6| Step: 13
Training loss: 0.8089607357978821
Validation loss: 1.7944098993014264

Epoch: 390| Step: 0
Training loss: 1.3440179824829102
Validation loss: 1.7468027837814823

Epoch: 6| Step: 1
Training loss: 0.7163683176040649
Validation loss: 1.7324534244434808

Epoch: 6| Step: 2
Training loss: 1.0909385681152344
Validation loss: 1.7382234937401229

Epoch: 6| Step: 3
Training loss: 1.3989717960357666
Validation loss: 1.7631536273546116

Epoch: 6| Step: 4
Training loss: 1.3450722694396973
Validation loss: 1.791335754497077

Epoch: 6| Step: 5
Training loss: 0.9031084179878235
Validation loss: 1.7794653984808153

Epoch: 6| Step: 6
Training loss: 1.064660906791687
Validation loss: 1.8177201260802567

Epoch: 6| Step: 7
Training loss: 1.395297884941101
Validation loss: 1.8530465979729929

Epoch: 6| Step: 8
Training loss: 1.4844913482666016
Validation loss: 1.7780663954314364

Epoch: 6| Step: 9
Training loss: 1.6272387504577637
Validation loss: 1.780535113426947

Epoch: 6| Step: 10
Training loss: 2.2686147689819336
Validation loss: 1.8129416870814499

Epoch: 6| Step: 11
Training loss: 1.4447307586669922
Validation loss: 1.7835035939370432

Epoch: 6| Step: 12
Training loss: 0.9769637584686279
Validation loss: 1.7723225239784486

Epoch: 6| Step: 13
Training loss: 1.588212013244629
Validation loss: 1.747833349371469

Epoch: 391| Step: 0
Training loss: 1.2864850759506226
Validation loss: 1.7316027354168635

Epoch: 6| Step: 1
Training loss: 1.477407455444336
Validation loss: 1.7598532092186712

Epoch: 6| Step: 2
Training loss: 1.0560351610183716
Validation loss: 1.7236762790269748

Epoch: 6| Step: 3
Training loss: 1.2920387983322144
Validation loss: 1.7363648119793142

Epoch: 6| Step: 4
Training loss: 0.7740895748138428
Validation loss: 1.7248995586108136

Epoch: 6| Step: 5
Training loss: 1.0819666385650635
Validation loss: 1.7027584416891939

Epoch: 6| Step: 6
Training loss: 1.306872010231018
Validation loss: 1.7615284330101424

Epoch: 6| Step: 7
Training loss: 1.052717924118042
Validation loss: 1.741699996814933

Epoch: 6| Step: 8
Training loss: 1.6738026142120361
Validation loss: 1.7270842508603168

Epoch: 6| Step: 9
Training loss: 1.5054513216018677
Validation loss: 1.7158649185652375

Epoch: 6| Step: 10
Training loss: 1.4829459190368652
Validation loss: 1.727396729171917

Epoch: 6| Step: 11
Training loss: 1.321465015411377
Validation loss: 1.700675666973155

Epoch: 6| Step: 12
Training loss: 0.7181062698364258
Validation loss: 1.7353637064656904

Epoch: 6| Step: 13
Training loss: 2.509918689727783
Validation loss: 1.730311006628057

Epoch: 392| Step: 0
Training loss: 1.3164918422698975
Validation loss: 1.7110386471594534

Epoch: 6| Step: 1
Training loss: 1.4295923709869385
Validation loss: 1.7614159481499785

Epoch: 6| Step: 2
Training loss: 1.0209076404571533
Validation loss: 1.7544639879657375

Epoch: 6| Step: 3
Training loss: 1.897400140762329
Validation loss: 1.7763723583631619

Epoch: 6| Step: 4
Training loss: 0.7739812135696411
Validation loss: 1.6984530546331917

Epoch: 6| Step: 5
Training loss: 0.9806348085403442
Validation loss: 1.7693241565458235

Epoch: 6| Step: 6
Training loss: 1.3237228393554688
Validation loss: 1.8004303234879688

Epoch: 6| Step: 7
Training loss: 1.022079586982727
Validation loss: 1.7774108635481967

Epoch: 6| Step: 8
Training loss: 1.4806835651397705
Validation loss: 1.7686087623719247

Epoch: 6| Step: 9
Training loss: 1.7549257278442383
Validation loss: 1.755574413525161

Epoch: 6| Step: 10
Training loss: 1.0717724561691284
Validation loss: 1.8055612476923133

Epoch: 6| Step: 11
Training loss: 1.4016611576080322
Validation loss: 1.7510788581704582

Epoch: 6| Step: 12
Training loss: 1.2442041635513306
Validation loss: 1.7140886014507664

Epoch: 6| Step: 13
Training loss: 1.150097131729126
Validation loss: 1.704847974161948

Epoch: 393| Step: 0
Training loss: 1.063240647315979
Validation loss: 1.743036603414884

Epoch: 6| Step: 1
Training loss: 1.4329242706298828
Validation loss: 1.7037389188684442

Epoch: 6| Step: 2
Training loss: 1.0565338134765625
Validation loss: 1.740608082022718

Epoch: 6| Step: 3
Training loss: 1.0683534145355225
Validation loss: 1.7532043867213751

Epoch: 6| Step: 4
Training loss: 1.3531086444854736
Validation loss: 1.7344202123662478

Epoch: 6| Step: 5
Training loss: 1.3293743133544922
Validation loss: 1.7453290006165862

Epoch: 6| Step: 6
Training loss: 0.5914794206619263
Validation loss: 1.7007525697831185

Epoch: 6| Step: 7
Training loss: 0.9693876504898071
Validation loss: 1.74264185531165

Epoch: 6| Step: 8
Training loss: 1.4511263370513916
Validation loss: 1.7111817047160158

Epoch: 6| Step: 9
Training loss: 1.5571961402893066
Validation loss: 1.712792254263355

Epoch: 6| Step: 10
Training loss: 0.9852263927459717
Validation loss: 1.7358176938949093

Epoch: 6| Step: 11
Training loss: 1.8922924995422363
Validation loss: 1.7843499106745566

Epoch: 6| Step: 12
Training loss: 1.3790879249572754
Validation loss: 1.7449476424083914

Epoch: 6| Step: 13
Training loss: 2.0630781650543213
Validation loss: 1.744901644286289

Epoch: 394| Step: 0
Training loss: 1.5377798080444336
Validation loss: 1.7136474668338735

Epoch: 6| Step: 1
Training loss: 1.3659756183624268
Validation loss: 1.764190455918671

Epoch: 6| Step: 2
Training loss: 2.0748190879821777
Validation loss: 1.725850607759209

Epoch: 6| Step: 3
Training loss: 1.818397045135498
Validation loss: 1.7266366827872492

Epoch: 6| Step: 4
Training loss: 0.9558478593826294
Validation loss: 1.724953902665005

Epoch: 6| Step: 5
Training loss: 1.1727418899536133
Validation loss: 1.7037242997077204

Epoch: 6| Step: 6
Training loss: 1.0359687805175781
Validation loss: 1.7408881821940023

Epoch: 6| Step: 7
Training loss: 0.8484261631965637
Validation loss: 1.7235054123786189

Epoch: 6| Step: 8
Training loss: 0.9657258987426758
Validation loss: 1.7387229511814732

Epoch: 6| Step: 9
Training loss: 1.237475872039795
Validation loss: 1.7003927769199494

Epoch: 6| Step: 10
Training loss: 1.9813364744186401
Validation loss: 1.755225331552567

Epoch: 6| Step: 11
Training loss: 0.9318915605545044
Validation loss: 1.7686510752606135

Epoch: 6| Step: 12
Training loss: 1.2691729068756104
Validation loss: 1.7595661519676127

Epoch: 6| Step: 13
Training loss: 0.785122275352478
Validation loss: 1.7407324634572512

Epoch: 395| Step: 0
Training loss: 1.3237314224243164
Validation loss: 1.6973058831307195

Epoch: 6| Step: 1
Training loss: 0.99608314037323
Validation loss: 1.7466116323265979

Epoch: 6| Step: 2
Training loss: 1.2186691761016846
Validation loss: 1.7295641117198493

Epoch: 6| Step: 3
Training loss: 1.352602243423462
Validation loss: 1.7467134229598507

Epoch: 6| Step: 4
Training loss: 1.5229904651641846
Validation loss: 1.7489362019364552

Epoch: 6| Step: 5
Training loss: 1.4055135250091553
Validation loss: 1.7173312043630948

Epoch: 6| Step: 6
Training loss: 1.9373838901519775
Validation loss: 1.7508937812620593

Epoch: 6| Step: 7
Training loss: 1.4351001977920532
Validation loss: 1.7167721563769924

Epoch: 6| Step: 8
Training loss: 1.2571138143539429
Validation loss: 1.7052372681197299

Epoch: 6| Step: 9
Training loss: 0.9175503253936768
Validation loss: 1.7374038132288123

Epoch: 6| Step: 10
Training loss: 1.134592890739441
Validation loss: 1.668900393670605

Epoch: 6| Step: 11
Training loss: 0.9743995070457458
Validation loss: 1.7215669770394602

Epoch: 6| Step: 12
Training loss: 1.070176362991333
Validation loss: 1.6960593769627232

Epoch: 6| Step: 13
Training loss: 1.1439483165740967
Validation loss: 1.7577628435627106

Epoch: 396| Step: 0
Training loss: 0.7852863073348999
Validation loss: 1.7409347718761814

Epoch: 6| Step: 1
Training loss: 1.2321845293045044
Validation loss: 1.7029653338975803

Epoch: 6| Step: 2
Training loss: 0.9838829040527344
Validation loss: 1.797026829052997

Epoch: 6| Step: 3
Training loss: 1.3833365440368652
Validation loss: 1.7933144851397442

Epoch: 6| Step: 4
Training loss: 1.0618823766708374
Validation loss: 1.7809006731997254

Epoch: 6| Step: 5
Training loss: 1.200246810913086
Validation loss: 1.8157377345587618

Epoch: 6| Step: 6
Training loss: 1.3505927324295044
Validation loss: 1.8081036178014611

Epoch: 6| Step: 7
Training loss: 1.0571237802505493
Validation loss: 1.8173289119556386

Epoch: 6| Step: 8
Training loss: 1.4689133167266846
Validation loss: 1.7663213270966724

Epoch: 6| Step: 9
Training loss: 1.693360447883606
Validation loss: 1.7191140433793426

Epoch: 6| Step: 10
Training loss: 1.125628113746643
Validation loss: 1.769155688183282

Epoch: 6| Step: 11
Training loss: 1.7000775337219238
Validation loss: 1.7858144134603522

Epoch: 6| Step: 12
Training loss: 1.413043737411499
Validation loss: 1.7266514057754188

Epoch: 6| Step: 13
Training loss: 1.3246800899505615
Validation loss: 1.7697103959257885

Epoch: 397| Step: 0
Training loss: 1.0325889587402344
Validation loss: 1.755969742292999

Epoch: 6| Step: 1
Training loss: 1.5194437503814697
Validation loss: 1.785048859093779

Epoch: 6| Step: 2
Training loss: 0.9028337597846985
Validation loss: 1.7683598738844677

Epoch: 6| Step: 3
Training loss: 0.9117224216461182
Validation loss: 1.707441581192837

Epoch: 6| Step: 4
Training loss: 1.6528956890106201
Validation loss: 1.73041166797761

Epoch: 6| Step: 5
Training loss: 1.308732509613037
Validation loss: 1.725824482979313

Epoch: 6| Step: 6
Training loss: 1.454266905784607
Validation loss: 1.7735987670959965

Epoch: 6| Step: 7
Training loss: 1.6108925342559814
Validation loss: 1.78193566747891

Epoch: 6| Step: 8
Training loss: 1.5486745834350586
Validation loss: 1.7415175066199353

Epoch: 6| Step: 9
Training loss: 1.5173442363739014
Validation loss: 1.731218646931392

Epoch: 6| Step: 10
Training loss: 1.1671980619430542
Validation loss: 1.7312998605030838

Epoch: 6| Step: 11
Training loss: 1.0176805257797241
Validation loss: 1.7782584595423874

Epoch: 6| Step: 12
Training loss: 1.224388599395752
Validation loss: 1.713478301161079

Epoch: 6| Step: 13
Training loss: 1.7103759050369263
Validation loss: 1.7745440108801729

Epoch: 398| Step: 0
Training loss: 1.043291449546814
Validation loss: 1.7360718160547235

Epoch: 6| Step: 1
Training loss: 1.2593374252319336
Validation loss: 1.7281611029819777

Epoch: 6| Step: 2
Training loss: 1.4694374799728394
Validation loss: 1.7474158540848763

Epoch: 6| Step: 3
Training loss: 1.1188178062438965
Validation loss: 1.7569466906209146

Epoch: 6| Step: 4
Training loss: 1.143036961555481
Validation loss: 1.773786651190891

Epoch: 6| Step: 5
Training loss: 0.7193669676780701
Validation loss: 1.7902903659369356

Epoch: 6| Step: 6
Training loss: 1.394448161125183
Validation loss: 1.7542122589644564

Epoch: 6| Step: 7
Training loss: 0.8696656823158264
Validation loss: 1.7554494104077738

Epoch: 6| Step: 8
Training loss: 1.118453860282898
Validation loss: 1.7729531565020162

Epoch: 6| Step: 9
Training loss: 1.2540478706359863
Validation loss: 1.7799089800926946

Epoch: 6| Step: 10
Training loss: 1.5502393245697021
Validation loss: 1.730403906555586

Epoch: 6| Step: 11
Training loss: 1.6263532638549805
Validation loss: 1.7065838844545427

Epoch: 6| Step: 12
Training loss: 1.5517637729644775
Validation loss: 1.7156615923809748

Epoch: 6| Step: 13
Training loss: 1.328705072402954
Validation loss: 1.7245804314972253

Epoch: 399| Step: 0
Training loss: 0.9244438409805298
Validation loss: 1.686960199827789

Epoch: 6| Step: 1
Training loss: 1.7590712308883667
Validation loss: 1.7268469846376808

Epoch: 6| Step: 2
Training loss: 1.2629311084747314
Validation loss: 1.7455381347287087

Epoch: 6| Step: 3
Training loss: 0.5434778928756714
Validation loss: 1.7437541382287138

Epoch: 6| Step: 4
Training loss: 0.6213822364807129
Validation loss: 1.6941178832002866

Epoch: 6| Step: 5
Training loss: 1.232362151145935
Validation loss: 1.7425215898021575

Epoch: 6| Step: 6
Training loss: 1.4067349433898926
Validation loss: 1.7637763113103888

Epoch: 6| Step: 7
Training loss: 1.279852271080017
Validation loss: 1.7506595811536234

Epoch: 6| Step: 8
Training loss: 0.8807637691497803
Validation loss: 1.7196919571968816

Epoch: 6| Step: 9
Training loss: 1.841336727142334
Validation loss: 1.7175490817716044

Epoch: 6| Step: 10
Training loss: 0.9207819700241089
Validation loss: 1.6975326999541251

Epoch: 6| Step: 11
Training loss: 1.343708872795105
Validation loss: 1.7778042170309252

Epoch: 6| Step: 12
Training loss: 1.6389374732971191
Validation loss: 1.7323468398022395

Epoch: 6| Step: 13
Training loss: 2.013742446899414
Validation loss: 1.7382328433375205

Epoch: 400| Step: 0
Training loss: 1.5829384326934814
Validation loss: 1.745850355394425

Epoch: 6| Step: 1
Training loss: 1.2378969192504883
Validation loss: 1.7435839599178684

Epoch: 6| Step: 2
Training loss: 1.0441123247146606
Validation loss: 1.7656779417427637

Epoch: 6| Step: 3
Training loss: 0.3995429277420044
Validation loss: 1.817992700043545

Epoch: 6| Step: 4
Training loss: 1.4933693408966064
Validation loss: 1.7740844757326188

Epoch: 6| Step: 5
Training loss: 1.4265506267547607
Validation loss: 1.731932552911902

Epoch: 6| Step: 6
Training loss: 0.9918549060821533
Validation loss: 1.7821033898220267

Epoch: 6| Step: 7
Training loss: 1.3744909763336182
Validation loss: 1.7481179634730022

Epoch: 6| Step: 8
Training loss: 0.5553348064422607
Validation loss: 1.759288227686318

Epoch: 6| Step: 9
Training loss: 1.436173677444458
Validation loss: 1.7226186157554708

Epoch: 6| Step: 10
Training loss: 1.3549318313598633
Validation loss: 1.7493691700761036

Epoch: 6| Step: 11
Training loss: 1.4733448028564453
Validation loss: 1.6987089175049976

Epoch: 6| Step: 12
Training loss: 1.4734129905700684
Validation loss: 1.7678836366181732

Epoch: 6| Step: 13
Training loss: 1.6513909101486206
Validation loss: 1.737777207487373

Epoch: 401| Step: 0
Training loss: 1.3846309185028076
Validation loss: 1.7354513752845027

Epoch: 6| Step: 1
Training loss: 1.304419994354248
Validation loss: 1.700409512366018

Epoch: 6| Step: 2
Training loss: 0.5863422155380249
Validation loss: 1.7122789916171823

Epoch: 6| Step: 3
Training loss: 1.2357218265533447
Validation loss: 1.7361146442351802

Epoch: 6| Step: 4
Training loss: 1.293138027191162
Validation loss: 1.7129877395527338

Epoch: 6| Step: 5
Training loss: 1.6742403507232666
Validation loss: 1.7334295536882134

Epoch: 6| Step: 6
Training loss: 1.3846392631530762
Validation loss: 1.7517739393377816

Epoch: 6| Step: 7
Training loss: 1.1835963726043701
Validation loss: 1.6959702250778035

Epoch: 6| Step: 8
Training loss: 0.7191472053527832
Validation loss: 1.7340986062121648

Epoch: 6| Step: 9
Training loss: 1.695176362991333
Validation loss: 1.6872004283371793

Epoch: 6| Step: 10
Training loss: 2.2391061782836914
Validation loss: 1.7031889807793401

Epoch: 6| Step: 11
Training loss: 1.279274582862854
Validation loss: 1.666999191366216

Epoch: 6| Step: 12
Training loss: 1.32880437374115
Validation loss: 1.7213218519764562

Epoch: 6| Step: 13
Training loss: 0.6059675216674805
Validation loss: 1.7120748091769475

Epoch: 402| Step: 0
Training loss: 0.9663092494010925
Validation loss: 1.7769655232788415

Epoch: 6| Step: 1
Training loss: 0.5350830554962158
Validation loss: 1.755557821642968

Epoch: 6| Step: 2
Training loss: 1.029170036315918
Validation loss: 1.7834040080347369

Epoch: 6| Step: 3
Training loss: 1.2113304138183594
Validation loss: 1.7405943562907558

Epoch: 6| Step: 4
Training loss: 1.1757322549819946
Validation loss: 1.7222100163018832

Epoch: 6| Step: 5
Training loss: 2.0057010650634766
Validation loss: 1.712147226897619

Epoch: 6| Step: 6
Training loss: 1.2418127059936523
Validation loss: 1.7718953406938942

Epoch: 6| Step: 7
Training loss: 1.0973094701766968
Validation loss: 1.6836095561263382

Epoch: 6| Step: 8
Training loss: 1.1684951782226562
Validation loss: 1.7844772774686095

Epoch: 6| Step: 9
Training loss: 1.3326282501220703
Validation loss: 1.7719473825987948

Epoch: 6| Step: 10
Training loss: 1.2768681049346924
Validation loss: 1.7342133547670098

Epoch: 6| Step: 11
Training loss: 1.3668135404586792
Validation loss: 1.6808669644017373

Epoch: 6| Step: 12
Training loss: 1.3440840244293213
Validation loss: 1.7315947650581278

Epoch: 6| Step: 13
Training loss: 1.7402594089508057
Validation loss: 1.7366628928851056

Epoch: 403| Step: 0
Training loss: 1.0438549518585205
Validation loss: 1.6975791454315186

Epoch: 6| Step: 1
Training loss: 1.435892105102539
Validation loss: 1.7060220613274524

Epoch: 6| Step: 2
Training loss: 2.149512767791748
Validation loss: 1.7044858765858475

Epoch: 6| Step: 3
Training loss: 1.214324712753296
Validation loss: 1.7061952134614349

Epoch: 6| Step: 4
Training loss: 1.2348159551620483
Validation loss: 1.7740773680389568

Epoch: 6| Step: 5
Training loss: 1.2648093700408936
Validation loss: 1.749235483907884

Epoch: 6| Step: 6
Training loss: 1.359015703201294
Validation loss: 1.733780477636604

Epoch: 6| Step: 7
Training loss: 2.030365467071533
Validation loss: 1.7926448263147825

Epoch: 6| Step: 8
Training loss: 1.1683156490325928
Validation loss: 1.750796865391475

Epoch: 6| Step: 9
Training loss: 1.4503145217895508
Validation loss: 1.7054833417297692

Epoch: 6| Step: 10
Training loss: 0.8787700533866882
Validation loss: 1.7326440426611132

Epoch: 6| Step: 11
Training loss: 0.6784665584564209
Validation loss: 1.7581720467536681

Epoch: 6| Step: 12
Training loss: 1.1408385038375854
Validation loss: 1.7272021232112762

Epoch: 6| Step: 13
Training loss: 0.8858540654182434
Validation loss: 1.7493440604978991

Epoch: 404| Step: 0
Training loss: 1.2539315223693848
Validation loss: 1.8014312867195375

Epoch: 6| Step: 1
Training loss: 0.9194509387016296
Validation loss: 1.75622046250169

Epoch: 6| Step: 2
Training loss: 1.2754788398742676
Validation loss: 1.8048852746204664

Epoch: 6| Step: 3
Training loss: 1.7250595092773438
Validation loss: 1.7972447590161396

Epoch: 6| Step: 4
Training loss: 0.9537461400032043
Validation loss: 1.788228093936879

Epoch: 6| Step: 5
Training loss: 0.9714423418045044
Validation loss: 1.7533557440644951

Epoch: 6| Step: 6
Training loss: 1.4705414772033691
Validation loss: 1.7938213835480392

Epoch: 6| Step: 7
Training loss: 1.5162978172302246
Validation loss: 1.7453340638068415

Epoch: 6| Step: 8
Training loss: 1.1716423034667969
Validation loss: 1.7827269287519558

Epoch: 6| Step: 9
Training loss: 0.956844687461853
Validation loss: 1.735217264903489

Epoch: 6| Step: 10
Training loss: 1.6511175632476807
Validation loss: 1.7727691281226374

Epoch: 6| Step: 11
Training loss: 2.0047996044158936
Validation loss: 1.7353206706303421

Epoch: 6| Step: 12
Training loss: 1.0852761268615723
Validation loss: 1.722404150552647

Epoch: 6| Step: 13
Training loss: 0.6570712327957153
Validation loss: 1.7128540982482254

Epoch: 405| Step: 0
Training loss: 2.136765480041504
Validation loss: 1.7157771369462371

Epoch: 6| Step: 1
Training loss: 1.6089789867401123
Validation loss: 1.7258454766324771

Epoch: 6| Step: 2
Training loss: 1.3792108297348022
Validation loss: 1.6926766095622894

Epoch: 6| Step: 3
Training loss: 1.2460887432098389
Validation loss: 1.7147957919746317

Epoch: 6| Step: 4
Training loss: 1.258961796760559
Validation loss: 1.7032550060620872

Epoch: 6| Step: 5
Training loss: 0.8490935564041138
Validation loss: 1.724687736521485

Epoch: 6| Step: 6
Training loss: 1.4296419620513916
Validation loss: 1.759773003157749

Epoch: 6| Step: 7
Training loss: 1.0990959405899048
Validation loss: 1.75970007142713

Epoch: 6| Step: 8
Training loss: 1.3192312717437744
Validation loss: 1.7632389632604455

Epoch: 6| Step: 9
Training loss: 0.7640583515167236
Validation loss: 1.7057691684333227

Epoch: 6| Step: 10
Training loss: 0.9217609763145447
Validation loss: 1.6988877173393004

Epoch: 6| Step: 11
Training loss: 1.3711105585098267
Validation loss: 1.7571106367213751

Epoch: 6| Step: 12
Training loss: 0.5413061380386353
Validation loss: 1.7640685086609216

Epoch: 6| Step: 13
Training loss: 1.504560947418213
Validation loss: 1.7294896917958413

Epoch: 406| Step: 0
Training loss: 0.6585519909858704
Validation loss: 1.6999794283220846

Epoch: 6| Step: 1
Training loss: 0.9026575088500977
Validation loss: 1.7060052425630632

Epoch: 6| Step: 2
Training loss: 1.3770833015441895
Validation loss: 1.7374491204497635

Epoch: 6| Step: 3
Training loss: 0.7762706279754639
Validation loss: 1.7645442870355421

Epoch: 6| Step: 4
Training loss: 1.4217318296432495
Validation loss: 1.7213694844194638

Epoch: 6| Step: 5
Training loss: 1.2667179107666016
Validation loss: 1.7543369698268112

Epoch: 6| Step: 6
Training loss: 1.0335887670516968
Validation loss: 1.7371377560400194

Epoch: 6| Step: 7
Training loss: 1.9316518306732178
Validation loss: 1.7656672077794229

Epoch: 6| Step: 8
Training loss: 1.9317549467086792
Validation loss: 1.7302246260386642

Epoch: 6| Step: 9
Training loss: 1.513887643814087
Validation loss: 1.7493598070195926

Epoch: 6| Step: 10
Training loss: 1.7521235942840576
Validation loss: 1.7781243901098929

Epoch: 6| Step: 11
Training loss: 1.0064764022827148
Validation loss: 1.7460723871825843

Epoch: 6| Step: 12
Training loss: 0.7971447706222534
Validation loss: 1.7570187660955614

Epoch: 6| Step: 13
Training loss: 1.079189658164978
Validation loss: 1.7132064437353483

Epoch: 407| Step: 0
Training loss: 1.5179301500320435
Validation loss: 1.7160687549139864

Epoch: 6| Step: 1
Training loss: 1.0453815460205078
Validation loss: 1.718602285590223

Epoch: 6| Step: 2
Training loss: 0.9356975555419922
Validation loss: 1.7384974443784325

Epoch: 6| Step: 3
Training loss: 1.9667258262634277
Validation loss: 1.735169817042607

Epoch: 6| Step: 4
Training loss: 2.028196096420288
Validation loss: 1.7499067398809618

Epoch: 6| Step: 5
Training loss: 1.2677232027053833
Validation loss: 1.707248959490048

Epoch: 6| Step: 6
Training loss: 1.2723395824432373
Validation loss: 1.7433259230788036

Epoch: 6| Step: 7
Training loss: 0.7940378189086914
Validation loss: 1.734609846145876

Epoch: 6| Step: 8
Training loss: 0.6291855573654175
Validation loss: 1.7575882070808

Epoch: 6| Step: 9
Training loss: 0.718600869178772
Validation loss: 1.7052419647093742

Epoch: 6| Step: 10
Training loss: 1.4307334423065186
Validation loss: 1.6997179241590603

Epoch: 6| Step: 11
Training loss: 0.8676199913024902
Validation loss: 1.7367177547947052

Epoch: 6| Step: 12
Training loss: 1.1886963844299316
Validation loss: 1.7511900573648431

Epoch: 6| Step: 13
Training loss: 1.7235450744628906
Validation loss: 1.7135101185050061

Epoch: 408| Step: 0
Training loss: 0.6354914307594299
Validation loss: 1.6992152147395636

Epoch: 6| Step: 1
Training loss: 1.6283998489379883
Validation loss: 1.7190919614607287

Epoch: 6| Step: 2
Training loss: 0.9787185192108154
Validation loss: 1.7248079828036729

Epoch: 6| Step: 3
Training loss: 1.11521577835083
Validation loss: 1.6865938786537416

Epoch: 6| Step: 4
Training loss: 1.1555054187774658
Validation loss: 1.7161065032405238

Epoch: 6| Step: 5
Training loss: 1.0267162322998047
Validation loss: 1.7437929927661855

Epoch: 6| Step: 6
Training loss: 1.005852460861206
Validation loss: 1.6964662549316243

Epoch: 6| Step: 7
Training loss: 1.4173928499221802
Validation loss: 1.703181723112701

Epoch: 6| Step: 8
Training loss: 1.8602828979492188
Validation loss: 1.688643765705888

Epoch: 6| Step: 9
Training loss: 1.5547645092010498
Validation loss: 1.7170148613632366

Epoch: 6| Step: 10
Training loss: 0.939745306968689
Validation loss: 1.6815164460930774

Epoch: 6| Step: 11
Training loss: 0.8411016464233398
Validation loss: 1.751372257868449

Epoch: 6| Step: 12
Training loss: 2.1215391159057617
Validation loss: 1.7583995788328108

Epoch: 6| Step: 13
Training loss: 1.1402175426483154
Validation loss: 1.7466864278239589

Epoch: 409| Step: 0
Training loss: 1.212916612625122
Validation loss: 1.753674361013597

Epoch: 6| Step: 1
Training loss: 0.8150849938392639
Validation loss: 1.7395099593747048

Epoch: 6| Step: 2
Training loss: 1.2514619827270508
Validation loss: 1.7040853128638318

Epoch: 6| Step: 3
Training loss: 1.289245843887329
Validation loss: 1.7227293009399085

Epoch: 6| Step: 4
Training loss: 1.779107689857483
Validation loss: 1.7322594042747252

Epoch: 6| Step: 5
Training loss: 1.1562693119049072
Validation loss: 1.7591391609561058

Epoch: 6| Step: 6
Training loss: 1.0922696590423584
Validation loss: 1.740215992414823

Epoch: 6| Step: 7
Training loss: 1.2188866138458252
Validation loss: 1.7267582429352628

Epoch: 6| Step: 8
Training loss: 0.860759973526001
Validation loss: 1.710301012121221

Epoch: 6| Step: 9
Training loss: 1.7972619533538818
Validation loss: 1.7348021589299685

Epoch: 6| Step: 10
Training loss: 1.3549507856369019
Validation loss: 1.7360629202217184

Epoch: 6| Step: 11
Training loss: 0.9688901901245117
Validation loss: 1.7390470017669022

Epoch: 6| Step: 12
Training loss: 1.0920984745025635
Validation loss: 1.780425658790014

Epoch: 6| Step: 13
Training loss: 1.5193898677825928
Validation loss: 1.757510922288382

Epoch: 410| Step: 0
Training loss: 1.0692665576934814
Validation loss: 1.726910444997972

Epoch: 6| Step: 1
Training loss: 1.1935136318206787
Validation loss: 1.658180408580329

Epoch: 6| Step: 2
Training loss: 1.5641262531280518
Validation loss: 1.7229783304276005

Epoch: 6| Step: 3
Training loss: 1.1261653900146484
Validation loss: 1.7166087306955808

Epoch: 6| Step: 4
Training loss: 1.168226957321167
Validation loss: 1.7358589390272736

Epoch: 6| Step: 5
Training loss: 0.7847039699554443
Validation loss: 1.7211907755944036

Epoch: 6| Step: 6
Training loss: 1.4433009624481201
Validation loss: 1.7188634436617616

Epoch: 6| Step: 7
Training loss: 0.8662793040275574
Validation loss: 1.6900388310032506

Epoch: 6| Step: 8
Training loss: 1.345921277999878
Validation loss: 1.7332382663603751

Epoch: 6| Step: 9
Training loss: 2.093681812286377
Validation loss: 1.6737450297160814

Epoch: 6| Step: 10
Training loss: 0.9582430124282837
Validation loss: 1.7511930965608167

Epoch: 6| Step: 11
Training loss: 1.2766051292419434
Validation loss: 1.724819480731923

Epoch: 6| Step: 12
Training loss: 0.8865129351615906
Validation loss: 1.7416983817213325

Epoch: 6| Step: 13
Training loss: 1.5773001909255981
Validation loss: 1.7387998245095695

Epoch: 411| Step: 0
Training loss: 0.7002522945404053
Validation loss: 1.733281509850615

Epoch: 6| Step: 1
Training loss: 1.327897071838379
Validation loss: 1.7367689583891182

Epoch: 6| Step: 2
Training loss: 1.6363565921783447
Validation loss: 1.718514923126467

Epoch: 6| Step: 3
Training loss: 1.1294362545013428
Validation loss: 1.736441832716747

Epoch: 6| Step: 4
Training loss: 1.3565375804901123
Validation loss: 1.7300022109862296

Epoch: 6| Step: 5
Training loss: 1.05320405960083
Validation loss: 1.6256334615010086

Epoch: 6| Step: 6
Training loss: 1.1461751461029053
Validation loss: 1.73684371671369

Epoch: 6| Step: 7
Training loss: 1.8110156059265137
Validation loss: 1.7347007438700686

Epoch: 6| Step: 8
Training loss: 0.9358888864517212
Validation loss: 1.6899764467311162

Epoch: 6| Step: 9
Training loss: 0.930202841758728
Validation loss: 1.7400738987871396

Epoch: 6| Step: 10
Training loss: 1.1262407302856445
Validation loss: 1.7053581360847718

Epoch: 6| Step: 11
Training loss: 1.3298163414001465
Validation loss: 1.6765849308301044

Epoch: 6| Step: 12
Training loss: 1.2340755462646484
Validation loss: 1.698409620151725

Epoch: 6| Step: 13
Training loss: 0.650669515132904
Validation loss: 1.6869361887695968

Epoch: 412| Step: 0
Training loss: 1.4056236743927002
Validation loss: 1.7222669586058585

Epoch: 6| Step: 1
Training loss: 0.8780090808868408
Validation loss: 1.7265939661251601

Epoch: 6| Step: 2
Training loss: 1.461638331413269
Validation loss: 1.6987714408546366

Epoch: 6| Step: 3
Training loss: 1.0184862613677979
Validation loss: 1.692526936531067

Epoch: 6| Step: 4
Training loss: 1.124014139175415
Validation loss: 1.7192256835199171

Epoch: 6| Step: 5
Training loss: 1.2360801696777344
Validation loss: 1.6998947589628157

Epoch: 6| Step: 6
Training loss: 1.525868535041809
Validation loss: 1.6715661761581257

Epoch: 6| Step: 7
Training loss: 1.6939923763275146
Validation loss: 1.7330397636659685

Epoch: 6| Step: 8
Training loss: 1.1636593341827393
Validation loss: 1.7281580419950588

Epoch: 6| Step: 9
Training loss: 0.9536218643188477
Validation loss: 1.7688862687797957

Epoch: 6| Step: 10
Training loss: 1.3229689598083496
Validation loss: 1.762833200475221

Epoch: 6| Step: 11
Training loss: 0.9186227321624756
Validation loss: 1.7470749103894798

Epoch: 6| Step: 12
Training loss: 1.280043601989746
Validation loss: 1.7868749903094383

Epoch: 6| Step: 13
Training loss: 1.7761402130126953
Validation loss: 1.7783474999089395

Epoch: 413| Step: 0
Training loss: 1.1154217720031738
Validation loss: 1.7527266663889731

Epoch: 6| Step: 1
Training loss: 1.6235355138778687
Validation loss: 1.798972004203386

Epoch: 6| Step: 2
Training loss: 0.9997501969337463
Validation loss: 1.731757567774865

Epoch: 6| Step: 3
Training loss: 1.4108926057815552
Validation loss: 1.75600682022751

Epoch: 6| Step: 4
Training loss: 0.8769018054008484
Validation loss: 1.7067937158769177

Epoch: 6| Step: 5
Training loss: 1.5594581365585327
Validation loss: 1.711760490171371

Epoch: 6| Step: 6
Training loss: 0.7568309307098389
Validation loss: 1.7384048315786547

Epoch: 6| Step: 7
Training loss: 0.8759093284606934
Validation loss: 1.7386393008693573

Epoch: 6| Step: 8
Training loss: 0.9003831148147583
Validation loss: 1.7340756039465628

Epoch: 6| Step: 9
Training loss: 1.8231130838394165
Validation loss: 1.729436925662461

Epoch: 6| Step: 10
Training loss: 1.7703511714935303
Validation loss: 1.7079812865103445

Epoch: 6| Step: 11
Training loss: 0.675249457359314
Validation loss: 1.6879266987564743

Epoch: 6| Step: 12
Training loss: 1.1223315000534058
Validation loss: 1.6705701953621321

Epoch: 6| Step: 13
Training loss: 1.173561930656433
Validation loss: 1.71395952727205

Epoch: 414| Step: 0
Training loss: 1.1146289110183716
Validation loss: 1.701141652240548

Epoch: 6| Step: 1
Training loss: 1.045069694519043
Validation loss: 1.7212144636338758

Epoch: 6| Step: 2
Training loss: 1.3425530195236206
Validation loss: 1.6625619716541742

Epoch: 6| Step: 3
Training loss: 1.171560287475586
Validation loss: 1.6898096607577415

Epoch: 6| Step: 4
Training loss: 1.1498193740844727
Validation loss: 1.713609286533889

Epoch: 6| Step: 5
Training loss: 1.047625184059143
Validation loss: 1.7406413760236514

Epoch: 6| Step: 6
Training loss: 0.9243265390396118
Validation loss: 1.715325483711817

Epoch: 6| Step: 7
Training loss: 1.3951969146728516
Validation loss: 1.736693577099872

Epoch: 6| Step: 8
Training loss: 1.0162501335144043
Validation loss: 1.6725040969028269

Epoch: 6| Step: 9
Training loss: 1.1471519470214844
Validation loss: 1.7030902242147794

Epoch: 6| Step: 10
Training loss: 1.0184062719345093
Validation loss: 1.735685089583038

Epoch: 6| Step: 11
Training loss: 1.1826171875
Validation loss: 1.7287506967462518

Epoch: 6| Step: 12
Training loss: 1.4270126819610596
Validation loss: 1.7373617579860072

Epoch: 6| Step: 13
Training loss: 2.3250653743743896
Validation loss: 1.7261085382071875

Epoch: 415| Step: 0
Training loss: 1.5826467275619507
Validation loss: 1.7598867236926992

Epoch: 6| Step: 1
Training loss: 0.7891659736633301
Validation loss: 1.8103282425993232

Epoch: 6| Step: 2
Training loss: 1.46321439743042
Validation loss: 1.8025600602549892

Epoch: 6| Step: 3
Training loss: 1.7785329818725586
Validation loss: 1.7624164255716468

Epoch: 6| Step: 4
Training loss: 1.1698012351989746
Validation loss: 1.804476309848088

Epoch: 6| Step: 5
Training loss: 1.0936907529830933
Validation loss: 1.7538745480199014

Epoch: 6| Step: 6
Training loss: 0.8330552577972412
Validation loss: 1.7876724889201503

Epoch: 6| Step: 7
Training loss: 0.9275937080383301
Validation loss: 1.7477821380861345

Epoch: 6| Step: 8
Training loss: 0.9510661959648132
Validation loss: 1.7439155347885624

Epoch: 6| Step: 9
Training loss: 1.2842681407928467
Validation loss: 1.7448411910764632

Epoch: 6| Step: 10
Training loss: 1.4031422138214111
Validation loss: 1.7106152196084299

Epoch: 6| Step: 11
Training loss: 1.7358362674713135
Validation loss: 1.7405001104518931

Epoch: 6| Step: 12
Training loss: 0.8351186513900757
Validation loss: 1.7378914343413485

Epoch: 6| Step: 13
Training loss: 0.8890836238861084
Validation loss: 1.671244917377349

Epoch: 416| Step: 0
Training loss: 0.9705528616905212
Validation loss: 1.6794798002448132

Epoch: 6| Step: 1
Training loss: 1.8115670680999756
Validation loss: 1.7094768170387513

Epoch: 6| Step: 2
Training loss: 1.4937307834625244
Validation loss: 1.729246481772392

Epoch: 6| Step: 3
Training loss: 1.1771113872528076
Validation loss: 1.7178216070257208

Epoch: 6| Step: 4
Training loss: 0.7280905246734619
Validation loss: 1.7207663777053996

Epoch: 6| Step: 5
Training loss: 0.966825008392334
Validation loss: 1.707630777871737

Epoch: 6| Step: 6
Training loss: 0.9225805997848511
Validation loss: 1.7322530003004177

Epoch: 6| Step: 7
Training loss: 0.5725602507591248
Validation loss: 1.7174156519674486

Epoch: 6| Step: 8
Training loss: 1.0493799448013306
Validation loss: 1.7360687460950626

Epoch: 6| Step: 9
Training loss: 1.390406608581543
Validation loss: 1.712891976038615

Epoch: 6| Step: 10
Training loss: 1.6637301445007324
Validation loss: 1.7413764897213186

Epoch: 6| Step: 11
Training loss: 2.0955581665039062
Validation loss: 1.7234331689855105

Epoch: 6| Step: 12
Training loss: 1.0184550285339355
Validation loss: 1.757612794958135

Epoch: 6| Step: 13
Training loss: 1.0387195348739624
Validation loss: 1.715712878011888

Epoch: 417| Step: 0
Training loss: 1.789311408996582
Validation loss: 1.7481685594845844

Epoch: 6| Step: 1
Training loss: 1.2323769330978394
Validation loss: 1.719628732691529

Epoch: 6| Step: 2
Training loss: 1.347271203994751
Validation loss: 1.787535980183591

Epoch: 6| Step: 3
Training loss: 1.4490270614624023
Validation loss: 1.7051800515062066

Epoch: 6| Step: 4
Training loss: 1.153641939163208
Validation loss: 1.7196452310008388

Epoch: 6| Step: 5
Training loss: 0.987576425075531
Validation loss: 1.715082327524821

Epoch: 6| Step: 6
Training loss: 0.9933573007583618
Validation loss: 1.6846490226766115

Epoch: 6| Step: 7
Training loss: 1.9339548349380493
Validation loss: 1.673592572571129

Epoch: 6| Step: 8
Training loss: 0.7808017730712891
Validation loss: 1.7246609157131565

Epoch: 6| Step: 9
Training loss: 0.6211769580841064
Validation loss: 1.6819870061771844

Epoch: 6| Step: 10
Training loss: 1.7056841850280762
Validation loss: 1.708806460903537

Epoch: 6| Step: 11
Training loss: 0.8567671775817871
Validation loss: 1.7236639056154477

Epoch: 6| Step: 12
Training loss: 1.0395842790603638
Validation loss: 1.72600438902455

Epoch: 6| Step: 13
Training loss: 0.9147027134895325
Validation loss: 1.7823197534007411

Epoch: 418| Step: 0
Training loss: 1.5864866971969604
Validation loss: 1.7167772682764197

Epoch: 6| Step: 1
Training loss: 1.5744343996047974
Validation loss: 1.7237276780989863

Epoch: 6| Step: 2
Training loss: 0.8776381611824036
Validation loss: 1.729742355244134

Epoch: 6| Step: 3
Training loss: 1.4953887462615967
Validation loss: 1.7605504887078398

Epoch: 6| Step: 4
Training loss: 0.5165603756904602
Validation loss: 1.8167034554225143

Epoch: 6| Step: 5
Training loss: 1.268420696258545
Validation loss: 1.7587851503843903

Epoch: 6| Step: 6
Training loss: 0.8818709254264832
Validation loss: 1.7645221987078268

Epoch: 6| Step: 7
Training loss: 1.3413820266723633
Validation loss: 1.8607007252272738

Epoch: 6| Step: 8
Training loss: 1.1845883131027222
Validation loss: 1.743303333559344

Epoch: 6| Step: 9
Training loss: 1.074859619140625
Validation loss: 1.771269807251551

Epoch: 6| Step: 10
Training loss: 1.4669160842895508
Validation loss: 1.7621720824190366

Epoch: 6| Step: 11
Training loss: 1.681775689125061
Validation loss: 1.7067854199358212

Epoch: 6| Step: 12
Training loss: 1.3240983486175537
Validation loss: 1.747414101836502

Epoch: 6| Step: 13
Training loss: 0.8762630820274353
Validation loss: 1.735301677898694

Epoch: 419| Step: 0
Training loss: 0.7892197370529175
Validation loss: 1.699298982979149

Epoch: 6| Step: 1
Training loss: 1.271820068359375
Validation loss: 1.678444940556762

Epoch: 6| Step: 2
Training loss: 0.746228039264679
Validation loss: 1.7118329848012617

Epoch: 6| Step: 3
Training loss: 1.2128269672393799
Validation loss: 1.7141853301755843

Epoch: 6| Step: 4
Training loss: 1.0798677206039429
Validation loss: 1.7356168967421337

Epoch: 6| Step: 5
Training loss: 1.1878893375396729
Validation loss: 1.715205797585108

Epoch: 6| Step: 6
Training loss: 0.7172174453735352
Validation loss: 1.7033871822459723

Epoch: 6| Step: 7
Training loss: 1.0932912826538086
Validation loss: 1.6766930267375002

Epoch: 6| Step: 8
Training loss: 1.337836503982544
Validation loss: 1.716190339416586

Epoch: 6| Step: 9
Training loss: 1.3274941444396973
Validation loss: 1.7248412498863794

Epoch: 6| Step: 10
Training loss: 2.1684327125549316
Validation loss: 1.694565059036337

Epoch: 6| Step: 11
Training loss: 1.16097092628479
Validation loss: 1.731701147171759

Epoch: 6| Step: 12
Training loss: 1.256643295288086
Validation loss: 1.7595624013613629

Epoch: 6| Step: 13
Training loss: 1.7415586709976196
Validation loss: 1.7551612315639373

Epoch: 420| Step: 0
Training loss: 1.7678699493408203
Validation loss: 1.691468386239903

Epoch: 6| Step: 1
Training loss: 1.082792043685913
Validation loss: 1.7411647996594828

Epoch: 6| Step: 2
Training loss: 0.834505558013916
Validation loss: 1.741364425228488

Epoch: 6| Step: 3
Training loss: 1.488578200340271
Validation loss: 1.722908773729878

Epoch: 6| Step: 4
Training loss: 1.290151596069336
Validation loss: 1.6899174567191833

Epoch: 6| Step: 5
Training loss: 0.7943899631500244
Validation loss: 1.7282716971571728

Epoch: 6| Step: 6
Training loss: 1.2179536819458008
Validation loss: 1.7038511640282088

Epoch: 6| Step: 7
Training loss: 1.4861876964569092
Validation loss: 1.7122067879605036

Epoch: 6| Step: 8
Training loss: 1.1208524703979492
Validation loss: 1.730048519308849

Epoch: 6| Step: 9
Training loss: 0.9705424308776855
Validation loss: 1.7151954148405342

Epoch: 6| Step: 10
Training loss: 1.1396740674972534
Validation loss: 1.6780848003202868

Epoch: 6| Step: 11
Training loss: 1.4003678560256958
Validation loss: 1.7300789202413251

Epoch: 6| Step: 12
Training loss: 1.0719878673553467
Validation loss: 1.7218250125967047

Epoch: 6| Step: 13
Training loss: 1.1378737688064575
Validation loss: 1.6885996364778089

Epoch: 421| Step: 0
Training loss: 1.1895829439163208
Validation loss: 1.651369620394963

Epoch: 6| Step: 1
Training loss: 0.9270622134208679
Validation loss: 1.71441569764127

Epoch: 6| Step: 2
Training loss: 1.3245916366577148
Validation loss: 1.720461840270668

Epoch: 6| Step: 3
Training loss: 0.8020817041397095
Validation loss: 1.7474258304924093

Epoch: 6| Step: 4
Training loss: 0.6329569220542908
Validation loss: 1.670960203293831

Epoch: 6| Step: 5
Training loss: 0.8763913512229919
Validation loss: 1.6829806425238167

Epoch: 6| Step: 6
Training loss: 1.1980229616165161
Validation loss: 1.680604652691913

Epoch: 6| Step: 7
Training loss: 1.7173384428024292
Validation loss: 1.6748791740786644

Epoch: 6| Step: 8
Training loss: 1.6802990436553955
Validation loss: 1.7219515551802933

Epoch: 6| Step: 9
Training loss: 1.3301693201065063
Validation loss: 1.7339050756987704

Epoch: 6| Step: 10
Training loss: 0.9476755261421204
Validation loss: 1.7152104390564786

Epoch: 6| Step: 11
Training loss: 1.6051063537597656
Validation loss: 1.687717604380782

Epoch: 6| Step: 12
Training loss: 0.8096528053283691
Validation loss: 1.7495954998077885

Epoch: 6| Step: 13
Training loss: 1.6119812726974487
Validation loss: 1.7411869661782378

Epoch: 422| Step: 0
Training loss: 1.2980835437774658
Validation loss: 1.749636932085919

Epoch: 6| Step: 1
Training loss: 1.1331095695495605
Validation loss: 1.7473595450001378

Epoch: 6| Step: 2
Training loss: 1.2345913648605347
Validation loss: 1.7697090718054003

Epoch: 6| Step: 3
Training loss: 0.9142962098121643
Validation loss: 1.7447030262280536

Epoch: 6| Step: 4
Training loss: 0.932948887348175
Validation loss: 1.7090557185552453

Epoch: 6| Step: 5
Training loss: 1.3022061586380005
Validation loss: 1.7237666089047667

Epoch: 6| Step: 6
Training loss: 0.9875355362892151
Validation loss: 1.7022227497511013

Epoch: 6| Step: 7
Training loss: 1.1583948135375977
Validation loss: 1.7400382052185714

Epoch: 6| Step: 8
Training loss: 1.0340337753295898
Validation loss: 1.7342591990706742

Epoch: 6| Step: 9
Training loss: 1.2911558151245117
Validation loss: 1.7408882905078191

Epoch: 6| Step: 10
Training loss: 0.9475740790367126
Validation loss: 1.718692846195672

Epoch: 6| Step: 11
Training loss: 1.4151265621185303
Validation loss: 1.6824115348118607

Epoch: 6| Step: 12
Training loss: 1.2317745685577393
Validation loss: 1.6896584585148802

Epoch: 6| Step: 13
Training loss: 1.6643431186676025
Validation loss: 1.7217604767891668

Epoch: 423| Step: 0
Training loss: 1.2312562465667725
Validation loss: 1.7270800810988232

Epoch: 6| Step: 1
Training loss: 1.4571245908737183
Validation loss: 1.7120757820785686

Epoch: 6| Step: 2
Training loss: 1.9004111289978027
Validation loss: 1.7254017412021596

Epoch: 6| Step: 3
Training loss: 1.1990313529968262
Validation loss: 1.720483446633944

Epoch: 6| Step: 4
Training loss: 1.084059476852417
Validation loss: 1.7118313889349661

Epoch: 6| Step: 5
Training loss: 1.4709833860397339
Validation loss: 1.7394508828399002

Epoch: 6| Step: 6
Training loss: 1.0857832431793213
Validation loss: 1.704603211854094

Epoch: 6| Step: 7
Training loss: 1.497800588607788
Validation loss: 1.7123190408111901

Epoch: 6| Step: 8
Training loss: 1.4408355951309204
Validation loss: 1.6862707714880667

Epoch: 6| Step: 9
Training loss: 0.8233556151390076
Validation loss: 1.7297415951246857

Epoch: 6| Step: 10
Training loss: 0.7740846872329712
Validation loss: 1.6955991829595258

Epoch: 6| Step: 11
Training loss: 0.9636870622634888
Validation loss: 1.7488238298764793

Epoch: 6| Step: 12
Training loss: 1.114586353302002
Validation loss: 1.7546117562119679

Epoch: 6| Step: 13
Training loss: 0.6623765230178833
Validation loss: 1.7446286844950851

Epoch: 424| Step: 0
Training loss: 1.6519359350204468
Validation loss: 1.7460314849371552

Epoch: 6| Step: 1
Training loss: 0.8035566806793213
Validation loss: 1.7338738569649317

Epoch: 6| Step: 2
Training loss: 1.2833821773529053
Validation loss: 1.7418983187726749

Epoch: 6| Step: 3
Training loss: 1.3470168113708496
Validation loss: 1.7111736151479906

Epoch: 6| Step: 4
Training loss: 1.2371413707733154
Validation loss: 1.7756811495750182

Epoch: 6| Step: 5
Training loss: 0.9933049082756042
Validation loss: 1.6911682698034471

Epoch: 6| Step: 6
Training loss: 1.1835992336273193
Validation loss: 1.6891629260073426

Epoch: 6| Step: 7
Training loss: 0.9395965337753296
Validation loss: 1.7049245475440897

Epoch: 6| Step: 8
Training loss: 0.8847965002059937
Validation loss: 1.7209069805760537

Epoch: 6| Step: 9
Training loss: 1.1210107803344727
Validation loss: 1.6663548395197878

Epoch: 6| Step: 10
Training loss: 1.2127968072891235
Validation loss: 1.708088767143988

Epoch: 6| Step: 11
Training loss: 1.9158105850219727
Validation loss: 1.7095266029398928

Epoch: 6| Step: 12
Training loss: 0.8119663596153259
Validation loss: 1.7386005309320265

Epoch: 6| Step: 13
Training loss: 1.0478274822235107
Validation loss: 1.7184246265760033

Epoch: 425| Step: 0
Training loss: 0.9660760164260864
Validation loss: 1.7056762479966687

Epoch: 6| Step: 1
Training loss: 1.000598430633545
Validation loss: 1.6913620066899124

Epoch: 6| Step: 2
Training loss: 1.2756061553955078
Validation loss: 1.699124869479928

Epoch: 6| Step: 3
Training loss: 1.910160779953003
Validation loss: 1.6729037607869794

Epoch: 6| Step: 4
Training loss: 1.077591896057129
Validation loss: 1.7409213294265091

Epoch: 6| Step: 5
Training loss: 1.0102381706237793
Validation loss: 1.6871451716269217

Epoch: 6| Step: 6
Training loss: 1.047568917274475
Validation loss: 1.7029293288466751

Epoch: 6| Step: 7
Training loss: 1.3020992279052734
Validation loss: 1.7469733517657045

Epoch: 6| Step: 8
Training loss: 1.1684390306472778
Validation loss: 1.7392981565126808

Epoch: 6| Step: 9
Training loss: 1.469796061515808
Validation loss: 1.7588034060693556

Epoch: 6| Step: 10
Training loss: 1.0794373750686646
Validation loss: 1.7938471507000666

Epoch: 6| Step: 11
Training loss: 1.0306497812271118
Validation loss: 1.7473868913547967

Epoch: 6| Step: 12
Training loss: 1.0467147827148438
Validation loss: 1.7563253397582679

Epoch: 6| Step: 13
Training loss: 1.0263721942901611
Validation loss: 1.7478367077407015

Epoch: 426| Step: 0
Training loss: 1.2993193864822388
Validation loss: 1.7197860351172827

Epoch: 6| Step: 1
Training loss: 1.3247501850128174
Validation loss: 1.731528059128792

Epoch: 6| Step: 2
Training loss: 1.5355640649795532
Validation loss: 1.7373420423077

Epoch: 6| Step: 3
Training loss: 0.5330461859703064
Validation loss: 1.7360685506174642

Epoch: 6| Step: 4
Training loss: 0.9219502806663513
Validation loss: 1.7215750691711262

Epoch: 6| Step: 5
Training loss: 1.5778076648712158
Validation loss: 1.7678965573669763

Epoch: 6| Step: 6
Training loss: 1.0571587085723877
Validation loss: 1.694162840484291

Epoch: 6| Step: 7
Training loss: 0.875586748123169
Validation loss: 1.7280889941800026

Epoch: 6| Step: 8
Training loss: 1.158555507659912
Validation loss: 1.7221720782659387

Epoch: 6| Step: 9
Training loss: 1.2544939517974854
Validation loss: 1.702456658886325

Epoch: 6| Step: 10
Training loss: 1.3342041969299316
Validation loss: 1.7361192344337382

Epoch: 6| Step: 11
Training loss: 1.018060326576233
Validation loss: 1.6986858428165477

Epoch: 6| Step: 12
Training loss: 1.1350164413452148
Validation loss: 1.7523045962856663

Epoch: 6| Step: 13
Training loss: 1.5003653764724731
Validation loss: 1.6818361218257616

Epoch: 427| Step: 0
Training loss: 0.9711242914199829
Validation loss: 1.7084951919894065

Epoch: 6| Step: 1
Training loss: 1.0419831275939941
Validation loss: 1.72436386282726

Epoch: 6| Step: 2
Training loss: 0.5024718642234802
Validation loss: 1.686855012370694

Epoch: 6| Step: 3
Training loss: 1.1622204780578613
Validation loss: 1.7129402763100081

Epoch: 6| Step: 4
Training loss: 0.9354345202445984
Validation loss: 1.7017584218773791

Epoch: 6| Step: 5
Training loss: 1.2997808456420898
Validation loss: 1.7350108687595656

Epoch: 6| Step: 6
Training loss: 1.3840333223342896
Validation loss: 1.7441842402181318

Epoch: 6| Step: 7
Training loss: 1.2384942770004272
Validation loss: 1.6972298096585017

Epoch: 6| Step: 8
Training loss: 1.0740480422973633
Validation loss: 1.6869862669257707

Epoch: 6| Step: 9
Training loss: 1.2577582597732544
Validation loss: 1.7576304866421608

Epoch: 6| Step: 10
Training loss: 1.8573213815689087
Validation loss: 1.779552089270725

Epoch: 6| Step: 11
Training loss: 1.5740251541137695
Validation loss: 1.736727117210306

Epoch: 6| Step: 12
Training loss: 1.0108318328857422
Validation loss: 1.7138752988589707

Epoch: 6| Step: 13
Training loss: 0.8734903335571289
Validation loss: 1.7406919361442648

Epoch: 428| Step: 0
Training loss: 0.9620065689086914
Validation loss: 1.7690791007011168

Epoch: 6| Step: 1
Training loss: 1.0809205770492554
Validation loss: 1.7668228944142659

Epoch: 6| Step: 2
Training loss: 1.3731019496917725
Validation loss: 1.7620675230538974

Epoch: 6| Step: 3
Training loss: 1.166947603225708
Validation loss: 1.7484330284980036

Epoch: 6| Step: 4
Training loss: 1.3236244916915894
Validation loss: 1.758186996624034

Epoch: 6| Step: 5
Training loss: 1.5658936500549316
Validation loss: 1.781503087730818

Epoch: 6| Step: 6
Training loss: 1.3492318391799927
Validation loss: 1.7876673257479103

Epoch: 6| Step: 7
Training loss: 1.0980615615844727
Validation loss: 1.7545719903002504

Epoch: 6| Step: 8
Training loss: 1.5241477489471436
Validation loss: 1.7536360871407293

Epoch: 6| Step: 9
Training loss: 1.194809913635254
Validation loss: 1.736689087524209

Epoch: 6| Step: 10
Training loss: 1.2075632810592651
Validation loss: 1.750784489416307

Epoch: 6| Step: 11
Training loss: 1.1170060634613037
Validation loss: 1.7282086008338517

Epoch: 6| Step: 12
Training loss: 0.8333420753479004
Validation loss: 1.688875425246454

Epoch: 6| Step: 13
Training loss: 0.5818389654159546
Validation loss: 1.7151883943106538

Epoch: 429| Step: 0
Training loss: 1.2796778678894043
Validation loss: 1.6836684070607668

Epoch: 6| Step: 1
Training loss: 1.4532181024551392
Validation loss: 1.7500372766166605

Epoch: 6| Step: 2
Training loss: 1.6023619174957275
Validation loss: 1.7222781783791

Epoch: 6| Step: 3
Training loss: 1.3107998371124268
Validation loss: 1.7061427498376498

Epoch: 6| Step: 4
Training loss: 1.5016133785247803
Validation loss: 1.6867547753036662

Epoch: 6| Step: 5
Training loss: 1.280389666557312
Validation loss: 1.6941017412370252

Epoch: 6| Step: 6
Training loss: 1.17543625831604
Validation loss: 1.6726655678082538

Epoch: 6| Step: 7
Training loss: 1.0261733531951904
Validation loss: 1.6919511402806928

Epoch: 6| Step: 8
Training loss: 1.011036992073059
Validation loss: 1.7105210827242943

Epoch: 6| Step: 9
Training loss: 1.0262387990951538
Validation loss: 1.7511799168843094

Epoch: 6| Step: 10
Training loss: 0.928922712802887
Validation loss: 1.669527038451164

Epoch: 6| Step: 11
Training loss: 0.6664018034934998
Validation loss: 1.7007363047651065

Epoch: 6| Step: 12
Training loss: 1.2728660106658936
Validation loss: 1.7351122248557307

Epoch: 6| Step: 13
Training loss: 0.96186763048172
Validation loss: 1.7262095956392185

Epoch: 430| Step: 0
Training loss: 1.4267935752868652
Validation loss: 1.6906901290339809

Epoch: 6| Step: 1
Training loss: 0.8153969049453735
Validation loss: 1.7288398370947888

Epoch: 6| Step: 2
Training loss: 0.7832059860229492
Validation loss: 1.7012492174743323

Epoch: 6| Step: 3
Training loss: 0.9489260911941528
Validation loss: 1.6990598106897006

Epoch: 6| Step: 4
Training loss: 1.5215458869934082
Validation loss: 1.6862168427436584

Epoch: 6| Step: 5
Training loss: 1.3904134035110474
Validation loss: 1.6946226243049867

Epoch: 6| Step: 6
Training loss: 1.0553771257400513
Validation loss: 1.713628356174756

Epoch: 6| Step: 7
Training loss: 1.04220712184906
Validation loss: 1.736058242859379

Epoch: 6| Step: 8
Training loss: 1.5547723770141602
Validation loss: 1.7228397400148454

Epoch: 6| Step: 9
Training loss: 0.9805456399917603
Validation loss: 1.6760875204558014

Epoch: 6| Step: 10
Training loss: 1.3896034955978394
Validation loss: 1.7619311040447605

Epoch: 6| Step: 11
Training loss: 1.0424343347549438
Validation loss: 1.7193764089256205

Epoch: 6| Step: 12
Training loss: 1.422947883605957
Validation loss: 1.7463208642057193

Epoch: 6| Step: 13
Training loss: 1.2855199575424194
Validation loss: 1.6853436628977458

Epoch: 431| Step: 0
Training loss: 1.3066728115081787
Validation loss: 1.750047904188915

Epoch: 6| Step: 1
Training loss: 0.7939175367355347
Validation loss: 1.7524858226058304

Epoch: 6| Step: 2
Training loss: 0.9202839136123657
Validation loss: 1.7324002571003412

Epoch: 6| Step: 3
Training loss: 0.9596838355064392
Validation loss: 1.7076174046403618

Epoch: 6| Step: 4
Training loss: 1.4555552005767822
Validation loss: 1.7004746390927223

Epoch: 6| Step: 5
Training loss: 1.2059812545776367
Validation loss: 1.7107012951245872

Epoch: 6| Step: 6
Training loss: 1.8315415382385254
Validation loss: 1.7176450093587239

Epoch: 6| Step: 7
Training loss: 1.0908663272857666
Validation loss: 1.6930957891607796

Epoch: 6| Step: 8
Training loss: 1.1179523468017578
Validation loss: 1.7346934464669996

Epoch: 6| Step: 9
Training loss: 1.024271011352539
Validation loss: 1.7026638048951344

Epoch: 6| Step: 10
Training loss: 1.1731557846069336
Validation loss: 1.7534037636172386

Epoch: 6| Step: 11
Training loss: 1.1545398235321045
Validation loss: 1.7372910104772097

Epoch: 6| Step: 12
Training loss: 1.0330054759979248
Validation loss: 1.7098637447562268

Epoch: 6| Step: 13
Training loss: 1.4214261770248413
Validation loss: 1.7467074086589198

Epoch: 432| Step: 0
Training loss: 0.5413632392883301
Validation loss: 1.7055244817528674

Epoch: 6| Step: 1
Training loss: 1.550169587135315
Validation loss: 1.7022087317641064

Epoch: 6| Step: 2
Training loss: 1.3750327825546265
Validation loss: 1.6572475023167108

Epoch: 6| Step: 3
Training loss: 0.5951599478721619
Validation loss: 1.667202796987308

Epoch: 6| Step: 4
Training loss: 0.8240097165107727
Validation loss: 1.7285426983269312

Epoch: 6| Step: 5
Training loss: 1.446553111076355
Validation loss: 1.7487340614359865

Epoch: 6| Step: 6
Training loss: 0.7474665641784668
Validation loss: 1.6846306439368957

Epoch: 6| Step: 7
Training loss: 1.1914288997650146
Validation loss: 1.673902242414413

Epoch: 6| Step: 8
Training loss: 1.0331872701644897
Validation loss: 1.6813759009043376

Epoch: 6| Step: 9
Training loss: 1.5967214107513428
Validation loss: 1.687268336613973

Epoch: 6| Step: 10
Training loss: 1.726458191871643
Validation loss: 1.733790966772264

Epoch: 6| Step: 11
Training loss: 1.0682265758514404
Validation loss: 1.6916956504185994

Epoch: 6| Step: 12
Training loss: 1.8441880941390991
Validation loss: 1.7198098244205597

Epoch: 6| Step: 13
Training loss: 0.8514806032180786
Validation loss: 1.7404738754354498

Epoch: 433| Step: 0
Training loss: 0.9571307301521301
Validation loss: 1.7436215454532253

Epoch: 6| Step: 1
Training loss: 1.3381271362304688
Validation loss: 1.7209702730178833

Epoch: 6| Step: 2
Training loss: 1.015447735786438
Validation loss: 1.7525630086980841

Epoch: 6| Step: 3
Training loss: 1.22674560546875
Validation loss: 1.7556275052409018

Epoch: 6| Step: 4
Training loss: 0.8094026446342468
Validation loss: 1.7322534335556852

Epoch: 6| Step: 5
Training loss: 1.1327121257781982
Validation loss: 1.7336590187523955

Epoch: 6| Step: 6
Training loss: 1.1327223777770996
Validation loss: 1.7050364100804893

Epoch: 6| Step: 7
Training loss: 1.5110243558883667
Validation loss: 1.7167520779435352

Epoch: 6| Step: 8
Training loss: 1.0463242530822754
Validation loss: 1.717092453792531

Epoch: 6| Step: 9
Training loss: 0.8620693683624268
Validation loss: 1.7311091205125213

Epoch: 6| Step: 10
Training loss: 1.1682850122451782
Validation loss: 1.7045196358875563

Epoch: 6| Step: 11
Training loss: 1.172760248184204
Validation loss: 1.7068374438952374

Epoch: 6| Step: 12
Training loss: 1.7548129558563232
Validation loss: 1.7013675461533249

Epoch: 6| Step: 13
Training loss: 0.9770695567131042
Validation loss: 1.7238409019285632

Epoch: 434| Step: 0
Training loss: 0.8619388937950134
Validation loss: 1.695852074571835

Epoch: 6| Step: 1
Training loss: 1.572861671447754
Validation loss: 1.6902691907780145

Epoch: 6| Step: 2
Training loss: 0.9706436395645142
Validation loss: 1.769420358442491

Epoch: 6| Step: 3
Training loss: 1.003067970275879
Validation loss: 1.733016690900249

Epoch: 6| Step: 4
Training loss: 0.9547621011734009
Validation loss: 1.7794932934545702

Epoch: 6| Step: 5
Training loss: 1.408461570739746
Validation loss: 1.733589687655049

Epoch: 6| Step: 6
Training loss: 1.1057621240615845
Validation loss: 1.736774480471047

Epoch: 6| Step: 7
Training loss: 0.8718135356903076
Validation loss: 1.7903120107548212

Epoch: 6| Step: 8
Training loss: 1.5929784774780273
Validation loss: 1.766635807611609

Epoch: 6| Step: 9
Training loss: 0.428646445274353
Validation loss: 1.7483265335841844

Epoch: 6| Step: 10
Training loss: 1.3483641147613525
Validation loss: 1.728845900104892

Epoch: 6| Step: 11
Training loss: 1.5301079750061035
Validation loss: 1.7142818025363389

Epoch: 6| Step: 12
Training loss: 1.6803040504455566
Validation loss: 1.7484248338207122

Epoch: 6| Step: 13
Training loss: 0.7521383762359619
Validation loss: 1.7273991569395988

Epoch: 435| Step: 0
Training loss: 1.0313923358917236
Validation loss: 1.6862527247398131

Epoch: 6| Step: 1
Training loss: 0.7704386115074158
Validation loss: 1.7277860500479256

Epoch: 6| Step: 2
Training loss: 1.6785937547683716
Validation loss: 1.7475698840233587

Epoch: 6| Step: 3
Training loss: 1.5595955848693848
Validation loss: 1.708103205568047

Epoch: 6| Step: 4
Training loss: 1.394244909286499
Validation loss: 1.771682886667149

Epoch: 6| Step: 5
Training loss: 0.6890992522239685
Validation loss: 1.7319243082436182

Epoch: 6| Step: 6
Training loss: 0.9934718608856201
Validation loss: 1.7404379537028651

Epoch: 6| Step: 7
Training loss: 1.0480639934539795
Validation loss: 1.7284688488129647

Epoch: 6| Step: 8
Training loss: 1.3911898136138916
Validation loss: 1.6965152973769813

Epoch: 6| Step: 9
Training loss: 1.1454927921295166
Validation loss: 1.7219070170515327

Epoch: 6| Step: 10
Training loss: 0.7920855283737183
Validation loss: 1.697323424841768

Epoch: 6| Step: 11
Training loss: 0.6689972877502441
Validation loss: 1.7118044681446527

Epoch: 6| Step: 12
Training loss: 1.6610493659973145
Validation loss: 1.7394373673264698

Epoch: 6| Step: 13
Training loss: 1.0864366292953491
Validation loss: 1.7186558682431456

Epoch: 436| Step: 0
Training loss: 1.605872392654419
Validation loss: 1.696022125982469

Epoch: 6| Step: 1
Training loss: 0.8319675922393799
Validation loss: 1.7018116417751517

Epoch: 6| Step: 2
Training loss: 1.2152574062347412
Validation loss: 1.711121836016255

Epoch: 6| Step: 3
Training loss: 1.656202793121338
Validation loss: 1.697428701385375

Epoch: 6| Step: 4
Training loss: 0.7688955068588257
Validation loss: 1.7141672526636431

Epoch: 6| Step: 5
Training loss: 1.091253399848938
Validation loss: 1.7171938278341805

Epoch: 6| Step: 6
Training loss: 1.299087643623352
Validation loss: 1.7086530878979673

Epoch: 6| Step: 7
Training loss: 0.8701406121253967
Validation loss: 1.7103143379252443

Epoch: 6| Step: 8
Training loss: 1.2153027057647705
Validation loss: 1.7518671853567964

Epoch: 6| Step: 9
Training loss: 1.3045557737350464
Validation loss: 1.7626332185601676

Epoch: 6| Step: 10
Training loss: 1.4985806941986084
Validation loss: 1.7703442663274787

Epoch: 6| Step: 11
Training loss: 0.9430629014968872
Validation loss: 1.7666074896371493

Epoch: 6| Step: 12
Training loss: 1.1331028938293457
Validation loss: 1.759982823043741

Epoch: 6| Step: 13
Training loss: 1.06877601146698
Validation loss: 1.7909956875667776

Epoch: 437| Step: 0
Training loss: 1.0561929941177368
Validation loss: 1.789937824331304

Epoch: 6| Step: 1
Training loss: 1.1157505512237549
Validation loss: 1.703960196946257

Epoch: 6| Step: 2
Training loss: 1.0117794275283813
Validation loss: 1.7352109621929865

Epoch: 6| Step: 3
Training loss: 1.4633491039276123
Validation loss: 1.7065992329710273

Epoch: 6| Step: 4
Training loss: 1.2798373699188232
Validation loss: 1.732845393560266

Epoch: 6| Step: 5
Training loss: 1.2794173955917358
Validation loss: 1.688739998366243

Epoch: 6| Step: 6
Training loss: 0.7057613134384155
Validation loss: 1.6937267447030673

Epoch: 6| Step: 7
Training loss: 1.2286542654037476
Validation loss: 1.6820429499431322

Epoch: 6| Step: 8
Training loss: 1.4140167236328125
Validation loss: 1.7108916223690074

Epoch: 6| Step: 9
Training loss: 0.8057423830032349
Validation loss: 1.740903813351867

Epoch: 6| Step: 10
Training loss: 1.477852463722229
Validation loss: 1.7110645053207234

Epoch: 6| Step: 11
Training loss: 0.8500884771347046
Validation loss: 1.7220647181234052

Epoch: 6| Step: 12
Training loss: 1.2188491821289062
Validation loss: 1.7272901406852148

Epoch: 6| Step: 13
Training loss: 1.4540302753448486
Validation loss: 1.7108183804378714

Epoch: 438| Step: 0
Training loss: 0.7343722581863403
Validation loss: 1.7234197765268304

Epoch: 6| Step: 1
Training loss: 1.094444990158081
Validation loss: 1.6922666295882194

Epoch: 6| Step: 2
Training loss: 1.3387765884399414
Validation loss: 1.7320800801759124

Epoch: 6| Step: 3
Training loss: 1.054971694946289
Validation loss: 1.6972172221829813

Epoch: 6| Step: 4
Training loss: 1.776450753211975
Validation loss: 1.6923832060188375

Epoch: 6| Step: 5
Training loss: 1.057753086090088
Validation loss: 1.7218015629758117

Epoch: 6| Step: 6
Training loss: 1.1359851360321045
Validation loss: 1.7630914911147086

Epoch: 6| Step: 7
Training loss: 1.049626111984253
Validation loss: 1.733869106538834

Epoch: 6| Step: 8
Training loss: 1.4184471368789673
Validation loss: 1.712494469458057

Epoch: 6| Step: 9
Training loss: 1.2764041423797607
Validation loss: 1.7016860156930902

Epoch: 6| Step: 10
Training loss: 0.9511505961418152
Validation loss: 1.7249032156441801

Epoch: 6| Step: 11
Training loss: 0.4854649305343628
Validation loss: 1.7177134585636917

Epoch: 6| Step: 12
Training loss: 1.5611038208007812
Validation loss: 1.702328940873505

Epoch: 6| Step: 13
Training loss: 1.2908052206039429
Validation loss: 1.681000494187878

Epoch: 439| Step: 0
Training loss: 1.3097798824310303
Validation loss: 1.7234011273230276

Epoch: 6| Step: 1
Training loss: 1.2834982872009277
Validation loss: 1.7563983060980355

Epoch: 6| Step: 2
Training loss: 1.1029514074325562
Validation loss: 1.7201339429424656

Epoch: 6| Step: 3
Training loss: 1.4778578281402588
Validation loss: 1.689090282686295

Epoch: 6| Step: 4
Training loss: 1.7504172325134277
Validation loss: 1.7061919512287262

Epoch: 6| Step: 5
Training loss: 1.2775275707244873
Validation loss: 1.7283687745371172

Epoch: 6| Step: 6
Training loss: 1.0281927585601807
Validation loss: 1.6649478827753375

Epoch: 6| Step: 7
Training loss: 0.7120222449302673
Validation loss: 1.7077845552916169

Epoch: 6| Step: 8
Training loss: 0.8680189847946167
Validation loss: 1.7143987173675208

Epoch: 6| Step: 9
Training loss: 0.9899071455001831
Validation loss: 1.726264298603099

Epoch: 6| Step: 10
Training loss: 1.2034904956817627
Validation loss: 1.7485333258105862

Epoch: 6| Step: 11
Training loss: 0.909517765045166
Validation loss: 1.7342999225021691

Epoch: 6| Step: 12
Training loss: 0.9010767936706543
Validation loss: 1.706968867650596

Epoch: 6| Step: 13
Training loss: 1.4357601404190063
Validation loss: 1.6960515437587615

Epoch: 440| Step: 0
Training loss: 1.0496915578842163
Validation loss: 1.7311549411025098

Epoch: 6| Step: 1
Training loss: 1.2532157897949219
Validation loss: 1.691996435965261

Epoch: 6| Step: 2
Training loss: 1.1066628694534302
Validation loss: 1.7122990956870459

Epoch: 6| Step: 3
Training loss: 0.6692767143249512
Validation loss: 1.7012136136331866

Epoch: 6| Step: 4
Training loss: 1.3859055042266846
Validation loss: 1.7166687750047254

Epoch: 6| Step: 5
Training loss: 1.6581127643585205
Validation loss: 1.6729587572877125

Epoch: 6| Step: 6
Training loss: 1.1144706010818481
Validation loss: 1.7534361449621056

Epoch: 6| Step: 7
Training loss: 1.3262419700622559
Validation loss: 1.7422607547493392

Epoch: 6| Step: 8
Training loss: 0.8450411558151245
Validation loss: 1.785025324872745

Epoch: 6| Step: 9
Training loss: 1.683997392654419
Validation loss: 1.7460209810605614

Epoch: 6| Step: 10
Training loss: 0.644512951374054
Validation loss: 1.7418315666978077

Epoch: 6| Step: 11
Training loss: 1.789304256439209
Validation loss: 1.7456685343096334

Epoch: 6| Step: 12
Training loss: 0.4624190032482147
Validation loss: 1.752423676111365

Epoch: 6| Step: 13
Training loss: 1.143725872039795
Validation loss: 1.6985792395889119

Epoch: 441| Step: 0
Training loss: 0.6025407314300537
Validation loss: 1.77114733060201

Epoch: 6| Step: 1
Training loss: 0.9238772392272949
Validation loss: 1.717277922937947

Epoch: 6| Step: 2
Training loss: 1.6897305250167847
Validation loss: 1.7118368033439881

Epoch: 6| Step: 3
Training loss: 1.5070085525512695
Validation loss: 1.6953250118481216

Epoch: 6| Step: 4
Training loss: 0.7239994406700134
Validation loss: 1.724977744522915

Epoch: 6| Step: 5
Training loss: 1.1945064067840576
Validation loss: 1.7216452949790544

Epoch: 6| Step: 6
Training loss: 0.9834384918212891
Validation loss: 1.7130693427978023

Epoch: 6| Step: 7
Training loss: 1.0410947799682617
Validation loss: 1.6964213194385651

Epoch: 6| Step: 8
Training loss: 1.0209929943084717
Validation loss: 1.6847668142728909

Epoch: 6| Step: 9
Training loss: 1.3533010482788086
Validation loss: 1.7384265379239154

Epoch: 6| Step: 10
Training loss: 1.431895136833191
Validation loss: 1.6930545094192668

Epoch: 6| Step: 11
Training loss: 1.1588317155838013
Validation loss: 1.7252063571765859

Epoch: 6| Step: 12
Training loss: 0.8262292146682739
Validation loss: 1.7252470434352916

Epoch: 6| Step: 13
Training loss: 1.8309561014175415
Validation loss: 1.6874729933277253

Epoch: 442| Step: 0
Training loss: 1.2033123970031738
Validation loss: 1.7723103236126643

Epoch: 6| Step: 1
Training loss: 0.8541511297225952
Validation loss: 1.7077924897593837

Epoch: 6| Step: 2
Training loss: 1.2800205945968628
Validation loss: 1.7794693977602067

Epoch: 6| Step: 3
Training loss: 1.0755136013031006
Validation loss: 1.7531780542865876

Epoch: 6| Step: 4
Training loss: 1.4183474779129028
Validation loss: 1.7979596378982707

Epoch: 6| Step: 5
Training loss: 1.8305513858795166
Validation loss: 1.7711073993354716

Epoch: 6| Step: 6
Training loss: 1.200157880783081
Validation loss: 1.718068108763746

Epoch: 6| Step: 7
Training loss: 1.1706669330596924
Validation loss: 1.7134738506809357

Epoch: 6| Step: 8
Training loss: 0.8776962757110596
Validation loss: 1.7417010594439764

Epoch: 6| Step: 9
Training loss: 1.131068468093872
Validation loss: 1.7037210900296447

Epoch: 6| Step: 10
Training loss: 1.0742204189300537
Validation loss: 1.7063020493394585

Epoch: 6| Step: 11
Training loss: 0.7238273024559021
Validation loss: 1.717780590057373

Epoch: 6| Step: 12
Training loss: 0.9782271981239319
Validation loss: 1.7453191344456007

Epoch: 6| Step: 13
Training loss: 0.9356906414031982
Validation loss: 1.7122208405566472

Epoch: 443| Step: 0
Training loss: 1.1936347484588623
Validation loss: 1.7410220407670545

Epoch: 6| Step: 1
Training loss: 1.643592357635498
Validation loss: 1.7459752328934208

Epoch: 6| Step: 2
Training loss: 1.1176297664642334
Validation loss: 1.7002661766544465

Epoch: 6| Step: 3
Training loss: 1.0450153350830078
Validation loss: 1.723140521716046

Epoch: 6| Step: 4
Training loss: 0.7939508557319641
Validation loss: 1.7322493035306212

Epoch: 6| Step: 5
Training loss: 0.9352720379829407
Validation loss: 1.7100610361304334

Epoch: 6| Step: 6
Training loss: 1.8503146171569824
Validation loss: 1.6957604385191394

Epoch: 6| Step: 7
Training loss: 0.41219693422317505
Validation loss: 1.699802069253819

Epoch: 6| Step: 8
Training loss: 1.1171813011169434
Validation loss: 1.7178038653507028

Epoch: 6| Step: 9
Training loss: 1.132715106010437
Validation loss: 1.7146505091779976

Epoch: 6| Step: 10
Training loss: 1.0123283863067627
Validation loss: 1.7291965933256253

Epoch: 6| Step: 11
Training loss: 0.8850431442260742
Validation loss: 1.722348218323082

Epoch: 6| Step: 12
Training loss: 1.2115066051483154
Validation loss: 1.7582875669643443

Epoch: 6| Step: 13
Training loss: 0.929144024848938
Validation loss: 1.7084228351552

Epoch: 444| Step: 0
Training loss: 0.8703044056892395
Validation loss: 1.7800726980291388

Epoch: 6| Step: 1
Training loss: 0.6238918304443359
Validation loss: 1.6990747336418397

Epoch: 6| Step: 2
Training loss: 1.1806498765945435
Validation loss: 1.7025710741678874

Epoch: 6| Step: 3
Training loss: 0.6413013935089111
Validation loss: 1.687524595568257

Epoch: 6| Step: 4
Training loss: 0.932835042476654
Validation loss: 1.6969916705162293

Epoch: 6| Step: 5
Training loss: 0.8367582559585571
Validation loss: 1.742927687142485

Epoch: 6| Step: 6
Training loss: 1.055355429649353
Validation loss: 1.7329210747954666

Epoch: 6| Step: 7
Training loss: 0.9540718197822571
Validation loss: 1.678972880686483

Epoch: 6| Step: 8
Training loss: 1.4451911449432373
Validation loss: 1.7311196737391974

Epoch: 6| Step: 9
Training loss: 1.5078816413879395
Validation loss: 1.7012222787385345

Epoch: 6| Step: 10
Training loss: 1.724782109260559
Validation loss: 1.6700043139919158

Epoch: 6| Step: 11
Training loss: 1.2862210273742676
Validation loss: 1.7016039048471758

Epoch: 6| Step: 12
Training loss: 1.647104024887085
Validation loss: 1.7132776667994838

Epoch: 6| Step: 13
Training loss: 1.1964125633239746
Validation loss: 1.7481226075080134

Epoch: 445| Step: 0
Training loss: 1.3149669170379639
Validation loss: 1.7522852946353216

Epoch: 6| Step: 1
Training loss: 1.1888022422790527
Validation loss: 1.7418405458491335

Epoch: 6| Step: 2
Training loss: 0.9415687918663025
Validation loss: 1.8085436205710135

Epoch: 6| Step: 3
Training loss: 1.0120302438735962
Validation loss: 1.7437661232486847

Epoch: 6| Step: 4
Training loss: 0.9324022531509399
Validation loss: 1.7235704455324399

Epoch: 6| Step: 5
Training loss: 1.5282210111618042
Validation loss: 1.7606572002492926

Epoch: 6| Step: 6
Training loss: 1.1253314018249512
Validation loss: 1.7390273283886653

Epoch: 6| Step: 7
Training loss: 1.0740669965744019
Validation loss: 1.759207215360416

Epoch: 6| Step: 8
Training loss: 1.1870213747024536
Validation loss: 1.7299684645027242

Epoch: 6| Step: 9
Training loss: 1.2109923362731934
Validation loss: 1.7118964425979122

Epoch: 6| Step: 10
Training loss: 0.6826130151748657
Validation loss: 1.7277913990841116

Epoch: 6| Step: 11
Training loss: 1.0200996398925781
Validation loss: 1.7038408671655962

Epoch: 6| Step: 12
Training loss: 1.630838394165039
Validation loss: 1.6931555501876339

Epoch: 6| Step: 13
Training loss: 1.1092209815979004
Validation loss: 1.7263738493765555

Epoch: 446| Step: 0
Training loss: 1.059769630432129
Validation loss: 1.713423611015402

Epoch: 6| Step: 1
Training loss: 0.9128972291946411
Validation loss: 1.6863153910124173

Epoch: 6| Step: 2
Training loss: 0.7251245975494385
Validation loss: 1.671487267299365

Epoch: 6| Step: 3
Training loss: 1.7135556936264038
Validation loss: 1.691360512087422

Epoch: 6| Step: 4
Training loss: 1.0790228843688965
Validation loss: 1.7159428904133458

Epoch: 6| Step: 5
Training loss: 0.6185093522071838
Validation loss: 1.658384015483241

Epoch: 6| Step: 6
Training loss: 0.8827850818634033
Validation loss: 1.6898419575024677

Epoch: 6| Step: 7
Training loss: 1.2775862216949463
Validation loss: 1.7084391437551028

Epoch: 6| Step: 8
Training loss: 0.8507919311523438
Validation loss: 1.6934707741583548

Epoch: 6| Step: 9
Training loss: 1.350712537765503
Validation loss: 1.6833509783590994

Epoch: 6| Step: 10
Training loss: 1.5010356903076172
Validation loss: 1.6809240720605338

Epoch: 6| Step: 11
Training loss: 1.3029261827468872
Validation loss: 1.7295496412502822

Epoch: 6| Step: 12
Training loss: 1.118207573890686
Validation loss: 1.695798231709388

Epoch: 6| Step: 13
Training loss: 1.2978218793869019
Validation loss: 1.7317659726706884

Epoch: 447| Step: 0
Training loss: 1.1938103437423706
Validation loss: 1.7201604497048162

Epoch: 6| Step: 1
Training loss: 1.6666977405548096
Validation loss: 1.7320962041936896

Epoch: 6| Step: 2
Training loss: 1.694066047668457
Validation loss: 1.7270943426316785

Epoch: 6| Step: 3
Training loss: 1.2170119285583496
Validation loss: 1.7017082283573766

Epoch: 6| Step: 4
Training loss: 0.6020011901855469
Validation loss: 1.70680453572222

Epoch: 6| Step: 5
Training loss: 0.8450562953948975
Validation loss: 1.7238854990210584

Epoch: 6| Step: 6
Training loss: 1.0687663555145264
Validation loss: 1.7187615081828127

Epoch: 6| Step: 7
Training loss: 1.3000767230987549
Validation loss: 1.7632969194842922

Epoch: 6| Step: 8
Training loss: 1.3152830600738525
Validation loss: 1.6908457176659697

Epoch: 6| Step: 9
Training loss: 0.6769858002662659
Validation loss: 1.7096708705348354

Epoch: 6| Step: 10
Training loss: 1.148519515991211
Validation loss: 1.725682698270326

Epoch: 6| Step: 11
Training loss: 0.6104008555412292
Validation loss: 1.7389536339749572

Epoch: 6| Step: 12
Training loss: 1.1559748649597168
Validation loss: 1.696481280429389

Epoch: 6| Step: 13
Training loss: 1.565179705619812
Validation loss: 1.758246519232309

Epoch: 448| Step: 0
Training loss: 0.9366222620010376
Validation loss: 1.7386336095871464

Epoch: 6| Step: 1
Training loss: 0.9230564832687378
Validation loss: 1.6914100993064143

Epoch: 6| Step: 2
Training loss: 1.8778204917907715
Validation loss: 1.6726430090524818

Epoch: 6| Step: 3
Training loss: 1.3743122816085815
Validation loss: 1.6474574458214544

Epoch: 6| Step: 4
Training loss: 1.246077299118042
Validation loss: 1.693182526096221

Epoch: 6| Step: 5
Training loss: 0.9247066974639893
Validation loss: 1.7190632627856346

Epoch: 6| Step: 6
Training loss: 1.3991634845733643
Validation loss: 1.6937395590607838

Epoch: 6| Step: 7
Training loss: 0.7759785652160645
Validation loss: 1.73063793746374

Epoch: 6| Step: 8
Training loss: 0.6337652206420898
Validation loss: 1.6988113464847687

Epoch: 6| Step: 9
Training loss: 1.1849027872085571
Validation loss: 1.7114234150096934

Epoch: 6| Step: 10
Training loss: 1.6284021139144897
Validation loss: 1.7340557985408331

Epoch: 6| Step: 11
Training loss: 0.6637105345726013
Validation loss: 1.7220950716285295

Epoch: 6| Step: 12
Training loss: 0.8273143172264099
Validation loss: 1.6809169938487392

Epoch: 6| Step: 13
Training loss: 1.1135538816452026
Validation loss: 1.7792377984651955

Epoch: 449| Step: 0
Training loss: 1.0234676599502563
Validation loss: 1.7281868637249034

Epoch: 6| Step: 1
Training loss: 0.4436051845550537
Validation loss: 1.6823808441879928

Epoch: 6| Step: 2
Training loss: 1.4653607606887817
Validation loss: 1.7466185144198838

Epoch: 6| Step: 3
Training loss: 1.134861946105957
Validation loss: 1.7577528748460995

Epoch: 6| Step: 4
Training loss: 0.4757688045501709
Validation loss: 1.7296715346715783

Epoch: 6| Step: 5
Training loss: 1.3452813625335693
Validation loss: 1.7331076181063088

Epoch: 6| Step: 6
Training loss: 0.9288247227668762
Validation loss: 1.659322738647461

Epoch: 6| Step: 7
Training loss: 1.0404469966888428
Validation loss: 1.7071474803391324

Epoch: 6| Step: 8
Training loss: 1.190842628479004
Validation loss: 1.7152116657585226

Epoch: 6| Step: 9
Training loss: 1.675681233406067
Validation loss: 1.7261345796687628

Epoch: 6| Step: 10
Training loss: 0.8336946964263916
Validation loss: 1.6865709725246634

Epoch: 6| Step: 11
Training loss: 1.4248301982879639
Validation loss: 1.7266731877480783

Epoch: 6| Step: 12
Training loss: 1.6766130924224854
Validation loss: 1.7630443419179609

Epoch: 6| Step: 13
Training loss: 0.8437163233757019
Validation loss: 1.6949113838134273

Epoch: 450| Step: 0
Training loss: 0.9464912414550781
Validation loss: 1.7142217902727024

Epoch: 6| Step: 1
Training loss: 0.965591549873352
Validation loss: 1.7329714221339072

Epoch: 6| Step: 2
Training loss: 1.3241090774536133
Validation loss: 1.704332677266931

Epoch: 6| Step: 3
Training loss: 1.2891520261764526
Validation loss: 1.7154525377417122

Epoch: 6| Step: 4
Training loss: 0.844971776008606
Validation loss: 1.6944545802249704

Epoch: 6| Step: 5
Training loss: 1.3806512355804443
Validation loss: 1.7321776126020698

Epoch: 6| Step: 6
Training loss: 0.82002192735672
Validation loss: 1.726901618383264

Epoch: 6| Step: 7
Training loss: 0.8239501714706421
Validation loss: 1.7228772204409364

Epoch: 6| Step: 8
Training loss: 1.4150922298431396
Validation loss: 1.7269035603410454

Epoch: 6| Step: 9
Training loss: 1.562699556350708
Validation loss: 1.7540967310628583

Epoch: 6| Step: 10
Training loss: 1.106576681137085
Validation loss: 1.734472777253838

Epoch: 6| Step: 11
Training loss: 1.2840452194213867
Validation loss: 1.7433312913422943

Epoch: 6| Step: 12
Training loss: 0.8923077583312988
Validation loss: 1.714512284084033

Epoch: 6| Step: 13
Training loss: 0.876825749874115
Validation loss: 1.713936754452285

Epoch: 451| Step: 0
Training loss: 1.6387660503387451
Validation loss: 1.7068311770757039

Epoch: 6| Step: 1
Training loss: 0.8674311637878418
Validation loss: 1.705772683184634

Epoch: 6| Step: 2
Training loss: 1.2024075984954834
Validation loss: 1.7864234268024404

Epoch: 6| Step: 3
Training loss: 1.4551068544387817
Validation loss: 1.7024309045525008

Epoch: 6| Step: 4
Training loss: 1.0438255071640015
Validation loss: 1.6751650661550543

Epoch: 6| Step: 5
Training loss: 1.2892942428588867
Validation loss: 1.6624796070078367

Epoch: 6| Step: 6
Training loss: 0.7914562225341797
Validation loss: 1.7319456505519089

Epoch: 6| Step: 7
Training loss: 0.9872704744338989
Validation loss: 1.7584033807118733

Epoch: 6| Step: 8
Training loss: 0.7993960976600647
Validation loss: 1.6989659288878083

Epoch: 6| Step: 9
Training loss: 1.158191204071045
Validation loss: 1.70182656088183

Epoch: 6| Step: 10
Training loss: 0.6221032738685608
Validation loss: 1.7189048900399158

Epoch: 6| Step: 11
Training loss: 1.95304536819458
Validation loss: 1.7565173872055546

Epoch: 6| Step: 12
Training loss: 1.1006770133972168
Validation loss: 1.699296602638819

Epoch: 6| Step: 13
Training loss: 0.7440099120140076
Validation loss: 1.7896345853805542

Epoch: 452| Step: 0
Training loss: 0.9323290586471558
Validation loss: 1.792072480724704

Epoch: 6| Step: 1
Training loss: 1.0882514715194702
Validation loss: 1.827901791500789

Epoch: 6| Step: 2
Training loss: 1.061571478843689
Validation loss: 1.790531994194113

Epoch: 6| Step: 3
Training loss: 1.4901140928268433
Validation loss: 1.82597993522562

Epoch: 6| Step: 4
Training loss: 1.4211158752441406
Validation loss: 1.7807694635083597

Epoch: 6| Step: 5
Training loss: 1.2829501628875732
Validation loss: 1.754545328437641

Epoch: 6| Step: 6
Training loss: 0.8983802795410156
Validation loss: 1.7690944684449064

Epoch: 6| Step: 7
Training loss: 1.012528657913208
Validation loss: 1.7150863344951341

Epoch: 6| Step: 8
Training loss: 0.6696065664291382
Validation loss: 1.7164682726706229

Epoch: 6| Step: 9
Training loss: 1.0916467905044556
Validation loss: 1.7268342792346913

Epoch: 6| Step: 10
Training loss: 1.1277854442596436
Validation loss: 1.691708472467238

Epoch: 6| Step: 11
Training loss: 0.8536175489425659
Validation loss: 1.7000088999348302

Epoch: 6| Step: 12
Training loss: 1.4344289302825928
Validation loss: 1.704807996749878

Epoch: 6| Step: 13
Training loss: 1.2587331533432007
Validation loss: 1.7128972430383005

Epoch: 453| Step: 0
Training loss: 1.233252763748169
Validation loss: 1.6994082107338855

Epoch: 6| Step: 1
Training loss: 0.6601143479347229
Validation loss: 1.7090624673392183

Epoch: 6| Step: 2
Training loss: 0.8609464168548584
Validation loss: 1.7067754960829211

Epoch: 6| Step: 3
Training loss: 0.802874743938446
Validation loss: 1.709342489960373

Epoch: 6| Step: 4
Training loss: 1.0466492176055908
Validation loss: 1.75612638842675

Epoch: 6| Step: 5
Training loss: 0.7657195925712585
Validation loss: 1.69053017580381

Epoch: 6| Step: 6
Training loss: 1.6433237791061401
Validation loss: 1.6982300742979972

Epoch: 6| Step: 7
Training loss: 1.187293529510498
Validation loss: 1.7102242772297194

Epoch: 6| Step: 8
Training loss: 1.014836311340332
Validation loss: 1.7454539056747191

Epoch: 6| Step: 9
Training loss: 1.4597886800765991
Validation loss: 1.723581757596744

Epoch: 6| Step: 10
Training loss: 1.1328026056289673
Validation loss: 1.7465065512605893

Epoch: 6| Step: 11
Training loss: 1.1736578941345215
Validation loss: 1.7581103553054154

Epoch: 6| Step: 12
Training loss: 0.9025137424468994
Validation loss: 1.7057248366776334

Epoch: 6| Step: 13
Training loss: 1.5718979835510254
Validation loss: 1.7700931026089577

Epoch: 454| Step: 0
Training loss: 1.1529285907745361
Validation loss: 1.760844676725326

Epoch: 6| Step: 1
Training loss: 1.265383243560791
Validation loss: 1.7083861084394558

Epoch: 6| Step: 2
Training loss: 0.9557994604110718
Validation loss: 1.7669644240410096

Epoch: 6| Step: 3
Training loss: 1.1317592859268188
Validation loss: 1.7119858303377706

Epoch: 6| Step: 4
Training loss: 1.7037986516952515
Validation loss: 1.731111588016633

Epoch: 6| Step: 5
Training loss: 1.010704755783081
Validation loss: 1.6839672455223658

Epoch: 6| Step: 6
Training loss: 0.9668831825256348
Validation loss: 1.6981844056037165

Epoch: 6| Step: 7
Training loss: 1.326349139213562
Validation loss: 1.7526369543485745

Epoch: 6| Step: 8
Training loss: 1.302896499633789
Validation loss: 1.697403319420353

Epoch: 6| Step: 9
Training loss: 0.9793333411216736
Validation loss: 1.7016041586475987

Epoch: 6| Step: 10
Training loss: 1.1122761964797974
Validation loss: 1.7480856769828386

Epoch: 6| Step: 11
Training loss: 0.8519597053527832
Validation loss: 1.7098260412934005

Epoch: 6| Step: 12
Training loss: 0.7603403925895691
Validation loss: 1.730576810016427

Epoch: 6| Step: 13
Training loss: 0.9532109498977661
Validation loss: 1.7306817654640443

Epoch: 455| Step: 0
Training loss: 0.8360772132873535
Validation loss: 1.7208793086390342

Epoch: 6| Step: 1
Training loss: 1.2314019203186035
Validation loss: 1.748199624399985

Epoch: 6| Step: 2
Training loss: 1.4305046796798706
Validation loss: 1.6783095931494108

Epoch: 6| Step: 3
Training loss: 1.5450899600982666
Validation loss: 1.6921353135057675

Epoch: 6| Step: 4
Training loss: 0.9409934282302856
Validation loss: 1.778365973503359

Epoch: 6| Step: 5
Training loss: 1.3764055967330933
Validation loss: 1.7083695357845676

Epoch: 6| Step: 6
Training loss: 0.7556368112564087
Validation loss: 1.7354640268510388

Epoch: 6| Step: 7
Training loss: 0.9991095662117004
Validation loss: 1.6969100326620123

Epoch: 6| Step: 8
Training loss: 1.080934762954712
Validation loss: 1.7380652722492014

Epoch: 6| Step: 9
Training loss: 0.7160394191741943
Validation loss: 1.7528942451682141

Epoch: 6| Step: 10
Training loss: 1.1997418403625488
Validation loss: 1.7185608853576004

Epoch: 6| Step: 11
Training loss: 1.1475238800048828
Validation loss: 1.689692005034416

Epoch: 6| Step: 12
Training loss: 1.1341062784194946
Validation loss: 1.719950658018871

Epoch: 6| Step: 13
Training loss: 0.98973149061203
Validation loss: 1.7019019485801778

Epoch: 456| Step: 0
Training loss: 0.9651144742965698
Validation loss: 1.705014786412639

Epoch: 6| Step: 1
Training loss: 0.8635138273239136
Validation loss: 1.6823077227479668

Epoch: 6| Step: 2
Training loss: 0.7115767002105713
Validation loss: 1.7145242947404102

Epoch: 6| Step: 3
Training loss: 0.8358308672904968
Validation loss: 1.6862377005238687

Epoch: 6| Step: 4
Training loss: 1.3819234371185303
Validation loss: 1.7081676849754908

Epoch: 6| Step: 5
Training loss: 1.5236176252365112
Validation loss: 1.7279600481833182

Epoch: 6| Step: 6
Training loss: 1.5810467004776
Validation loss: 1.6632122173104236

Epoch: 6| Step: 7
Training loss: 1.38958740234375
Validation loss: 1.6892388943702943

Epoch: 6| Step: 8
Training loss: 1.4635781049728394
Validation loss: 1.6611905213325255

Epoch: 6| Step: 9
Training loss: 0.8391835689544678
Validation loss: 1.729626126186822

Epoch: 6| Step: 10
Training loss: 0.7890586256980896
Validation loss: 1.7294679111050022

Epoch: 6| Step: 11
Training loss: 1.1487171649932861
Validation loss: 1.7261993500494188

Epoch: 6| Step: 12
Training loss: 0.9621800780296326
Validation loss: 1.74752761215292

Epoch: 6| Step: 13
Training loss: 1.1371511220932007
Validation loss: 1.7567816972732544

Epoch: 457| Step: 0
Training loss: 0.7659937143325806
Validation loss: 1.7504556345683273

Epoch: 6| Step: 1
Training loss: 1.1435747146606445
Validation loss: 1.7616043911185315

Epoch: 6| Step: 2
Training loss: 0.9509073495864868
Validation loss: 1.7455648670914352

Epoch: 6| Step: 3
Training loss: 0.7546008825302124
Validation loss: 1.7531398509138374

Epoch: 6| Step: 4
Training loss: 2.0080578327178955
Validation loss: 1.7140495687402704

Epoch: 6| Step: 5
Training loss: 1.0016754865646362
Validation loss: 1.7190497447085638

Epoch: 6| Step: 6
Training loss: 1.998814582824707
Validation loss: 1.7426023726822228

Epoch: 6| Step: 7
Training loss: 0.6542262434959412
Validation loss: 1.7124255062431417

Epoch: 6| Step: 8
Training loss: 0.881496787071228
Validation loss: 1.7361647114958814

Epoch: 6| Step: 9
Training loss: 0.757612943649292
Validation loss: 1.7065477832671134

Epoch: 6| Step: 10
Training loss: 1.0190455913543701
Validation loss: 1.709265999896552

Epoch: 6| Step: 11
Training loss: 1.2929795980453491
Validation loss: 1.6883584542941021

Epoch: 6| Step: 12
Training loss: 1.4014763832092285
Validation loss: 1.689804728313159

Epoch: 6| Step: 13
Training loss: 0.4766906499862671
Validation loss: 1.7097252209981282

Epoch: 458| Step: 0
Training loss: 1.1993658542633057
Validation loss: 1.7204126843842127

Epoch: 6| Step: 1
Training loss: 1.058829665184021
Validation loss: 1.7156895399093628

Epoch: 6| Step: 2
Training loss: 1.4631396532058716
Validation loss: 1.7316886891600907

Epoch: 6| Step: 3
Training loss: 0.8305890560150146
Validation loss: 1.7210275011677896

Epoch: 6| Step: 4
Training loss: 1.4459153413772583
Validation loss: 1.7052522449083225

Epoch: 6| Step: 5
Training loss: 1.180955171585083
Validation loss: 1.7073388407307286

Epoch: 6| Step: 6
Training loss: 1.2130049467086792
Validation loss: 1.725295130924512

Epoch: 6| Step: 7
Training loss: 0.6222601532936096
Validation loss: 1.7203810214996338

Epoch: 6| Step: 8
Training loss: 0.6877440810203552
Validation loss: 1.7465986487685994

Epoch: 6| Step: 9
Training loss: 1.0477616786956787
Validation loss: 1.7112708309645295

Epoch: 6| Step: 10
Training loss: 1.2313671112060547
Validation loss: 1.7129358540299118

Epoch: 6| Step: 11
Training loss: 1.019054651260376
Validation loss: 1.7632057000232

Epoch: 6| Step: 12
Training loss: 1.4531102180480957
Validation loss: 1.7471012556424705

Epoch: 6| Step: 13
Training loss: 0.35668954253196716
Validation loss: 1.6877908373391757

Epoch: 459| Step: 0
Training loss: 1.3120596408843994
Validation loss: 1.7067956027164255

Epoch: 6| Step: 1
Training loss: 1.218585729598999
Validation loss: 1.725894610087077

Epoch: 6| Step: 2
Training loss: 0.8924481272697449
Validation loss: 1.7749736475688156

Epoch: 6| Step: 3
Training loss: 1.055035948753357
Validation loss: 1.6988942738502257

Epoch: 6| Step: 4
Training loss: 1.009611964225769
Validation loss: 1.6899613693196287

Epoch: 6| Step: 5
Training loss: 0.9891771674156189
Validation loss: 1.656534214173594

Epoch: 6| Step: 6
Training loss: 0.7252825498580933
Validation loss: 1.6978445373555666

Epoch: 6| Step: 7
Training loss: 1.0562784671783447
Validation loss: 1.7079575305343957

Epoch: 6| Step: 8
Training loss: 1.0658304691314697
Validation loss: 1.725471668345954

Epoch: 6| Step: 9
Training loss: 1.5565437078475952
Validation loss: 1.7301226200595978

Epoch: 6| Step: 10
Training loss: 1.3332312107086182
Validation loss: 1.734523223292443

Epoch: 6| Step: 11
Training loss: 0.9706964492797852
Validation loss: 1.7694495134456183

Epoch: 6| Step: 12
Training loss: 0.7948125600814819
Validation loss: 1.6893507242202759

Epoch: 6| Step: 13
Training loss: 1.0562771558761597
Validation loss: 1.7730416431221911

Epoch: 460| Step: 0
Training loss: 0.9824960231781006
Validation loss: 1.7640140774429485

Epoch: 6| Step: 1
Training loss: 1.387768268585205
Validation loss: 1.7181359401313208

Epoch: 6| Step: 2
Training loss: 0.7051374912261963
Validation loss: 1.721384176643946

Epoch: 6| Step: 3
Training loss: 0.8441226482391357
Validation loss: 1.7235328638425438

Epoch: 6| Step: 4
Training loss: 1.7112783193588257
Validation loss: 1.6626329293815039

Epoch: 6| Step: 5
Training loss: 1.2913923263549805
Validation loss: 1.7111527048131472

Epoch: 6| Step: 6
Training loss: 0.9921326637268066
Validation loss: 1.7421060146824006

Epoch: 6| Step: 7
Training loss: 0.5378624200820923
Validation loss: 1.7480145680007113

Epoch: 6| Step: 8
Training loss: 1.2478476762771606
Validation loss: 1.7513707190431573

Epoch: 6| Step: 9
Training loss: 1.513611078262329
Validation loss: 1.6900613333589287

Epoch: 6| Step: 10
Training loss: 1.3168916702270508
Validation loss: 1.7062528799938899

Epoch: 6| Step: 11
Training loss: 0.7083813548088074
Validation loss: 1.7343978856199531

Epoch: 6| Step: 12
Training loss: 1.1363770961761475
Validation loss: 1.7308843648561867

Epoch: 6| Step: 13
Training loss: 1.2958016395568848
Validation loss: 1.7271415405375983

Epoch: 461| Step: 0
Training loss: 1.089745044708252
Validation loss: 1.7458420632987894

Epoch: 6| Step: 1
Training loss: 0.7831651568412781
Validation loss: 1.6750725315463157

Epoch: 6| Step: 2
Training loss: 0.7270060181617737
Validation loss: 1.733885044692665

Epoch: 6| Step: 3
Training loss: 0.747559666633606
Validation loss: 1.7277296602085073

Epoch: 6| Step: 4
Training loss: 1.875826120376587
Validation loss: 1.68296476077008

Epoch: 6| Step: 5
Training loss: 0.8750623464584351
Validation loss: 1.7294118840207335

Epoch: 6| Step: 6
Training loss: 1.410841464996338
Validation loss: 1.7015974201181883

Epoch: 6| Step: 7
Training loss: 1.0239388942718506
Validation loss: 1.7125500684143395

Epoch: 6| Step: 8
Training loss: 1.641746997833252
Validation loss: 1.7362205584843953

Epoch: 6| Step: 9
Training loss: 0.7516763806343079
Validation loss: 1.69828631929172

Epoch: 6| Step: 10
Training loss: 1.3144081830978394
Validation loss: 1.7386380190490394

Epoch: 6| Step: 11
Training loss: 0.9062780737876892
Validation loss: 1.7058590663376676

Epoch: 6| Step: 12
Training loss: 1.4809004068374634
Validation loss: 1.7265480526031987

Epoch: 6| Step: 13
Training loss: 0.6179254651069641
Validation loss: 1.7633769960813626

Epoch: 462| Step: 0
Training loss: 0.9447771310806274
Validation loss: 1.7075225922369188

Epoch: 6| Step: 1
Training loss: 1.2376987934112549
Validation loss: 1.7338677375547347

Epoch: 6| Step: 2
Training loss: 1.220107078552246
Validation loss: 1.7002625811484553

Epoch: 6| Step: 3
Training loss: 0.7081589102745056
Validation loss: 1.7668124091240667

Epoch: 6| Step: 4
Training loss: 1.069724440574646
Validation loss: 1.7145213311718357

Epoch: 6| Step: 5
Training loss: 1.1284432411193848
Validation loss: 1.68129224418312

Epoch: 6| Step: 6
Training loss: 1.0587677955627441
Validation loss: 1.7542549102537093

Epoch: 6| Step: 7
Training loss: 1.326782464981079
Validation loss: 1.6755131880442302

Epoch: 6| Step: 8
Training loss: 1.0423858165740967
Validation loss: 1.714673303788708

Epoch: 6| Step: 9
Training loss: 1.1119158267974854
Validation loss: 1.7189411424821424

Epoch: 6| Step: 10
Training loss: 1.0573674440383911
Validation loss: 1.6903411188433248

Epoch: 6| Step: 11
Training loss: 1.078075885772705
Validation loss: 1.6952715881409184

Epoch: 6| Step: 12
Training loss: 1.0593974590301514
Validation loss: 1.7337062051219325

Epoch: 6| Step: 13
Training loss: 1.7013386487960815
Validation loss: 1.7308332766256025

Epoch: 463| Step: 0
Training loss: 1.2078278064727783
Validation loss: 1.676654774655578

Epoch: 6| Step: 1
Training loss: 0.7481127977371216
Validation loss: 1.6885202533455306

Epoch: 6| Step: 2
Training loss: 1.1957005262374878
Validation loss: 1.7187478106508973

Epoch: 6| Step: 3
Training loss: 0.9299633502960205
Validation loss: 1.6978175101741668

Epoch: 6| Step: 4
Training loss: 1.403730034828186
Validation loss: 1.6991987766758088

Epoch: 6| Step: 5
Training loss: 0.8993524312973022
Validation loss: 1.749444802602132

Epoch: 6| Step: 6
Training loss: 1.2366912364959717
Validation loss: 1.7081491665173603

Epoch: 6| Step: 7
Training loss: 1.1671245098114014
Validation loss: 1.7032976304331133

Epoch: 6| Step: 8
Training loss: 0.6547409296035767
Validation loss: 1.7261532865544802

Epoch: 6| Step: 9
Training loss: 1.1218980550765991
Validation loss: 1.713728686814667

Epoch: 6| Step: 10
Training loss: 1.2101988792419434
Validation loss: 1.700850103491096

Epoch: 6| Step: 11
Training loss: 0.8944917321205139
Validation loss: 1.6850053392430788

Epoch: 6| Step: 12
Training loss: 1.3702255487442017
Validation loss: 1.713850696881612

Epoch: 6| Step: 13
Training loss: 1.059755802154541
Validation loss: 1.6973067906595045

Epoch: 464| Step: 0
Training loss: 1.1899566650390625
Validation loss: 1.7074687275835263

Epoch: 6| Step: 1
Training loss: 0.722478985786438
Validation loss: 1.6908209349519463

Epoch: 6| Step: 2
Training loss: 1.2259479761123657
Validation loss: 1.7200680009780391

Epoch: 6| Step: 3
Training loss: 1.4723007678985596
Validation loss: 1.680488947899111

Epoch: 6| Step: 4
Training loss: 0.4156514108181
Validation loss: 1.7343268638016076

Epoch: 6| Step: 5
Training loss: 1.4121675491333008
Validation loss: 1.6864781200244863

Epoch: 6| Step: 6
Training loss: 0.927178144454956
Validation loss: 1.6572731143684798

Epoch: 6| Step: 7
Training loss: 1.023007869720459
Validation loss: 1.669980920771117

Epoch: 6| Step: 8
Training loss: 1.2597599029541016
Validation loss: 1.6753174630544518

Epoch: 6| Step: 9
Training loss: 1.1965420246124268
Validation loss: 1.6714260321791454

Epoch: 6| Step: 10
Training loss: 1.3140015602111816
Validation loss: 1.7550988428054317

Epoch: 6| Step: 11
Training loss: 0.6992170810699463
Validation loss: 1.6893172584554201

Epoch: 6| Step: 12
Training loss: 1.1463024616241455
Validation loss: 1.6990567932846725

Epoch: 6| Step: 13
Training loss: 0.7152562737464905
Validation loss: 1.7377371441933416

Epoch: 465| Step: 0
Training loss: 1.1659209728240967
Validation loss: 1.697585117432379

Epoch: 6| Step: 1
Training loss: 0.8402043581008911
Validation loss: 1.801334188830468

Epoch: 6| Step: 2
Training loss: 1.1629393100738525
Validation loss: 1.7714161167862594

Epoch: 6| Step: 3
Training loss: 1.0884521007537842
Validation loss: 1.7517819942966584

Epoch: 6| Step: 4
Training loss: 0.5367611050605774
Validation loss: 1.7291066595303115

Epoch: 6| Step: 5
Training loss: 1.026053786277771
Validation loss: 1.7509684370410057

Epoch: 6| Step: 6
Training loss: 1.3208458423614502
Validation loss: 1.7461167612383444

Epoch: 6| Step: 7
Training loss: 1.3776112794876099
Validation loss: 1.7011783135834562

Epoch: 6| Step: 8
Training loss: 1.0139291286468506
Validation loss: 1.6911323057707919

Epoch: 6| Step: 9
Training loss: 1.030907154083252
Validation loss: 1.7367574758427118

Epoch: 6| Step: 10
Training loss: 0.7831248044967651
Validation loss: 1.7238755354317286

Epoch: 6| Step: 11
Training loss: 1.3819139003753662
Validation loss: 1.7057607699466009

Epoch: 6| Step: 12
Training loss: 1.0033930540084839
Validation loss: 1.70144441563596

Epoch: 6| Step: 13
Training loss: 1.4747728109359741
Validation loss: 1.691504850182482

Epoch: 466| Step: 0
Training loss: 1.4209668636322021
Validation loss: 1.701724588230092

Epoch: 6| Step: 1
Training loss: 0.9639443159103394
Validation loss: 1.687370325929375

Epoch: 6| Step: 2
Training loss: 1.5657840967178345
Validation loss: 1.7123228311538696

Epoch: 6| Step: 3
Training loss: 0.8133642077445984
Validation loss: 1.6887365605241509

Epoch: 6| Step: 4
Training loss: 0.7126956582069397
Validation loss: 1.671821363510624

Epoch: 6| Step: 5
Training loss: 0.4855707287788391
Validation loss: 1.701212085703368

Epoch: 6| Step: 6
Training loss: 1.4831602573394775
Validation loss: 1.7096432383342455

Epoch: 6| Step: 7
Training loss: 1.1203553676605225
Validation loss: 1.6848276392106087

Epoch: 6| Step: 8
Training loss: 1.63051176071167
Validation loss: 1.6570617870617939

Epoch: 6| Step: 9
Training loss: 1.005971908569336
Validation loss: 1.6954056255279049

Epoch: 6| Step: 10
Training loss: 1.161032795906067
Validation loss: 1.6936609950116885

Epoch: 6| Step: 11
Training loss: 0.36053940653800964
Validation loss: 1.696405412048422

Epoch: 6| Step: 12
Training loss: 0.8747448325157166
Validation loss: 1.706379311059111

Epoch: 6| Step: 13
Training loss: 1.526928186416626
Validation loss: 1.7745475640860937

Epoch: 467| Step: 0
Training loss: 0.712215006351471
Validation loss: 1.708895811470606

Epoch: 6| Step: 1
Training loss: 0.7795292139053345
Validation loss: 1.7060589380161737

Epoch: 6| Step: 2
Training loss: 0.67571622133255
Validation loss: 1.7253959191742765

Epoch: 6| Step: 3
Training loss: 1.27406644821167
Validation loss: 1.7398911009552658

Epoch: 6| Step: 4
Training loss: 1.253914475440979
Validation loss: 1.682404165626854

Epoch: 6| Step: 5
Training loss: 1.0418250560760498
Validation loss: 1.7048696112889115

Epoch: 6| Step: 6
Training loss: 1.0239553451538086
Validation loss: 1.7355541272829937

Epoch: 6| Step: 7
Training loss: 1.5661141872406006
Validation loss: 1.7117502099724227

Epoch: 6| Step: 8
Training loss: 1.4360493421554565
Validation loss: 1.7181525768772248

Epoch: 6| Step: 9
Training loss: 0.8318215608596802
Validation loss: 1.7322769959767659

Epoch: 6| Step: 10
Training loss: 0.7355918288230896
Validation loss: 1.737749654759643

Epoch: 6| Step: 11
Training loss: 1.4046258926391602
Validation loss: 1.7174884580796765

Epoch: 6| Step: 12
Training loss: 1.4444835186004639
Validation loss: 1.7134648048749535

Epoch: 6| Step: 13
Training loss: 0.5378124713897705
Validation loss: 1.7613954620976602

Epoch: 468| Step: 0
Training loss: 1.7741687297821045
Validation loss: 1.7537648139461395

Epoch: 6| Step: 1
Training loss: 1.6095993518829346
Validation loss: 1.7333846579315841

Epoch: 6| Step: 2
Training loss: 1.1139363050460815
Validation loss: 1.7559769743232316

Epoch: 6| Step: 3
Training loss: 0.8581279516220093
Validation loss: 1.7786926274658532

Epoch: 6| Step: 4
Training loss: 0.5896111726760864
Validation loss: 1.7553809663300872

Epoch: 6| Step: 5
Training loss: 1.034923791885376
Validation loss: 1.715141793733002

Epoch: 6| Step: 6
Training loss: 0.5519205927848816
Validation loss: 1.7363839675021429

Epoch: 6| Step: 7
Training loss: 1.2532340288162231
Validation loss: 1.7032310488403484

Epoch: 6| Step: 8
Training loss: 1.5830366611480713
Validation loss: 1.687257013013286

Epoch: 6| Step: 9
Training loss: 0.9253243207931519
Validation loss: 1.7900125775285947

Epoch: 6| Step: 10
Training loss: 1.488105297088623
Validation loss: 1.7070130545605895

Epoch: 6| Step: 11
Training loss: 0.9904579520225525
Validation loss: 1.6748797457705262

Epoch: 6| Step: 12
Training loss: 0.589148998260498
Validation loss: 1.744865047034397

Epoch: 6| Step: 13
Training loss: 1.1865438222885132
Validation loss: 1.7506469475325717

Epoch: 469| Step: 0
Training loss: 1.5189895629882812
Validation loss: 1.7459620173259447

Epoch: 6| Step: 1
Training loss: 1.0894789695739746
Validation loss: 1.654307790981826

Epoch: 6| Step: 2
Training loss: 1.0165696144104004
Validation loss: 1.6845622190865137

Epoch: 6| Step: 3
Training loss: 1.4709057807922363
Validation loss: 1.6451335799309514

Epoch: 6| Step: 4
Training loss: 0.988457202911377
Validation loss: 1.6658347806622904

Epoch: 6| Step: 5
Training loss: 1.0935518741607666
Validation loss: 1.7476824945019138

Epoch: 6| Step: 6
Training loss: 0.6051415205001831
Validation loss: 1.7062405770824802

Epoch: 6| Step: 7
Training loss: 1.0520232915878296
Validation loss: 1.6862646020868772

Epoch: 6| Step: 8
Training loss: 0.9709361791610718
Validation loss: 1.6907171831336072

Epoch: 6| Step: 9
Training loss: 1.5995025634765625
Validation loss: 1.7303930046737834

Epoch: 6| Step: 10
Training loss: 0.947040319442749
Validation loss: 1.6841693411591232

Epoch: 6| Step: 11
Training loss: 1.1373100280761719
Validation loss: 1.7226019174821916

Epoch: 6| Step: 12
Training loss: 0.9471038579940796
Validation loss: 1.7780554230495165

Epoch: 6| Step: 13
Training loss: 0.3929253816604614
Validation loss: 1.7436790722672657

Epoch: 470| Step: 0
Training loss: 1.0415012836456299
Validation loss: 1.7101246900455926

Epoch: 6| Step: 1
Training loss: 0.49350404739379883
Validation loss: 1.689339073755408

Epoch: 6| Step: 2
Training loss: 0.7491571307182312
Validation loss: 1.742863288489721

Epoch: 6| Step: 3
Training loss: 0.804067850112915
Validation loss: 1.7543175335853332

Epoch: 6| Step: 4
Training loss: 1.365523099899292
Validation loss: 1.716303902287637

Epoch: 6| Step: 5
Training loss: 1.043278455734253
Validation loss: 1.7265709907777849

Epoch: 6| Step: 6
Training loss: 1.4851067066192627
Validation loss: 1.7656106654033865

Epoch: 6| Step: 7
Training loss: 0.844326376914978
Validation loss: 1.7139374761171238

Epoch: 6| Step: 8
Training loss: 0.8107500076293945
Validation loss: 1.7227627615774832

Epoch: 6| Step: 9
Training loss: 0.6716359257698059
Validation loss: 1.7074943088716077

Epoch: 6| Step: 10
Training loss: 0.8784522414207458
Validation loss: 1.7349656038386847

Epoch: 6| Step: 11
Training loss: 1.5482105016708374
Validation loss: 1.6505628824234009

Epoch: 6| Step: 12
Training loss: 2.2509641647338867
Validation loss: 1.7030827358204832

Epoch: 6| Step: 13
Training loss: 0.7498113512992859
Validation loss: 1.6578736292418612

Epoch: 471| Step: 0
Training loss: 1.2837975025177002
Validation loss: 1.6772545037731048

Epoch: 6| Step: 1
Training loss: 1.0369338989257812
Validation loss: 1.6847303721212572

Epoch: 6| Step: 2
Training loss: 1.1409720182418823
Validation loss: 1.6680304875937841

Epoch: 6| Step: 3
Training loss: 0.8616365194320679
Validation loss: 1.7040484797570012

Epoch: 6| Step: 4
Training loss: 1.047111988067627
Validation loss: 1.6992586505028509

Epoch: 6| Step: 5
Training loss: 0.9378340244293213
Validation loss: 1.7680271889573784

Epoch: 6| Step: 6
Training loss: 1.2399128675460815
Validation loss: 1.726490464261783

Epoch: 6| Step: 7
Training loss: 0.8733042478561401
Validation loss: 1.7065130933638541

Epoch: 6| Step: 8
Training loss: 1.2789685726165771
Validation loss: 1.7091229910491614

Epoch: 6| Step: 9
Training loss: 0.6186767816543579
Validation loss: 1.7210990523779264

Epoch: 6| Step: 10
Training loss: 0.7607004642486572
Validation loss: 1.7011080147117696

Epoch: 6| Step: 11
Training loss: 1.5144598484039307
Validation loss: 1.7083363033110095

Epoch: 6| Step: 12
Training loss: 1.0707952976226807
Validation loss: 1.7053773723622805

Epoch: 6| Step: 13
Training loss: 1.4959466457366943
Validation loss: 1.6757919019268406

Epoch: 472| Step: 0
Training loss: 1.260742425918579
Validation loss: 1.6550393527553928

Epoch: 6| Step: 1
Training loss: 1.1409306526184082
Validation loss: 1.716314504223485

Epoch: 6| Step: 2
Training loss: 0.9840970039367676
Validation loss: 1.681581510010586

Epoch: 6| Step: 3
Training loss: 0.9946708679199219
Validation loss: 1.7299550156439505

Epoch: 6| Step: 4
Training loss: 1.0661401748657227
Validation loss: 1.7091981493016726

Epoch: 6| Step: 5
Training loss: 0.7728044986724854
Validation loss: 1.6889007270977061

Epoch: 6| Step: 6
Training loss: 1.2108166217803955
Validation loss: 1.7106190881421488

Epoch: 6| Step: 7
Training loss: 1.4158002138137817
Validation loss: 1.7259523535287509

Epoch: 6| Step: 8
Training loss: 0.7215248346328735
Validation loss: 1.7125632570635887

Epoch: 6| Step: 9
Training loss: 1.2205770015716553
Validation loss: 1.7675220120337702

Epoch: 6| Step: 10
Training loss: 1.4174060821533203
Validation loss: 1.6677255271583475

Epoch: 6| Step: 11
Training loss: 0.6130342483520508
Validation loss: 1.7186265145578692

Epoch: 6| Step: 12
Training loss: 1.1730302572250366
Validation loss: 1.7272939630734023

Epoch: 6| Step: 13
Training loss: 0.6771576404571533
Validation loss: 1.7255430542012697

Epoch: 473| Step: 0
Training loss: 0.9826304912567139
Validation loss: 1.6658881992422125

Epoch: 6| Step: 1
Training loss: 1.6652811765670776
Validation loss: 1.6909992130853797

Epoch: 6| Step: 2
Training loss: 1.2081003189086914
Validation loss: 1.7040033084090038

Epoch: 6| Step: 3
Training loss: 0.5818291902542114
Validation loss: 1.7080238788358626

Epoch: 6| Step: 4
Training loss: 1.0642539262771606
Validation loss: 1.7507330653487996

Epoch: 6| Step: 5
Training loss: 1.0144596099853516
Validation loss: 1.6932986359442435

Epoch: 6| Step: 6
Training loss: 0.9412144422531128
Validation loss: 1.7137085109628656

Epoch: 6| Step: 7
Training loss: 1.1955127716064453
Validation loss: 1.7295556299148067

Epoch: 6| Step: 8
Training loss: 1.5400644540786743
Validation loss: 1.716389427902878

Epoch: 6| Step: 9
Training loss: 1.1737334728240967
Validation loss: 1.7467584949667736

Epoch: 6| Step: 10
Training loss: 0.6056567430496216
Validation loss: 1.7153054116874613

Epoch: 6| Step: 11
Training loss: 0.5674992799758911
Validation loss: 1.732602293773364

Epoch: 6| Step: 12
Training loss: 1.113004446029663
Validation loss: 1.7216131815346338

Epoch: 6| Step: 13
Training loss: 0.971064567565918
Validation loss: 1.6889001528422039

Epoch: 474| Step: 0
Training loss: 1.2273714542388916
Validation loss: 1.7370567514050392

Epoch: 6| Step: 1
Training loss: 1.0459911823272705
Validation loss: 1.7139156582534953

Epoch: 6| Step: 2
Training loss: 0.6142433285713196
Validation loss: 1.7062548552789996

Epoch: 6| Step: 3
Training loss: 1.6097437143325806
Validation loss: 1.7263785895480905

Epoch: 6| Step: 4
Training loss: 0.6478575468063354
Validation loss: 1.6757828509935768

Epoch: 6| Step: 5
Training loss: 1.2796318531036377
Validation loss: 1.6740012373975528

Epoch: 6| Step: 6
Training loss: 1.1869049072265625
Validation loss: 1.7376379838553808

Epoch: 6| Step: 7
Training loss: 0.957873523235321
Validation loss: 1.7281493999624764

Epoch: 6| Step: 8
Training loss: 1.2750872373580933
Validation loss: 1.6656460928660568

Epoch: 6| Step: 9
Training loss: 0.8798263072967529
Validation loss: 1.7414267563050794

Epoch: 6| Step: 10
Training loss: 0.9039610624313354
Validation loss: 1.6902609358551681

Epoch: 6| Step: 11
Training loss: 0.8903342485427856
Validation loss: 1.675924757475494

Epoch: 6| Step: 12
Training loss: 1.4614038467407227
Validation loss: 1.70216457305416

Epoch: 6| Step: 13
Training loss: 0.6771166920661926
Validation loss: 1.7007852190284318

Epoch: 475| Step: 0
Training loss: 1.361074447631836
Validation loss: 1.7012584029987294

Epoch: 6| Step: 1
Training loss: 1.5326485633850098
Validation loss: 1.7259417554383636

Epoch: 6| Step: 2
Training loss: 1.0753908157348633
Validation loss: 1.7216917725019558

Epoch: 6| Step: 3
Training loss: 1.2836003303527832
Validation loss: 1.7121556433298255

Epoch: 6| Step: 4
Training loss: 0.9575212001800537
Validation loss: 1.739188955676171

Epoch: 6| Step: 5
Training loss: 0.7952396273612976
Validation loss: 1.682946361521239

Epoch: 6| Step: 6
Training loss: 0.5643879175186157
Validation loss: 1.7002430423613517

Epoch: 6| Step: 7
Training loss: 0.9132713079452515
Validation loss: 1.716297807232026

Epoch: 6| Step: 8
Training loss: 0.7281825542449951
Validation loss: 1.7001624978998655

Epoch: 6| Step: 9
Training loss: 0.7780148983001709
Validation loss: 1.76023228322306

Epoch: 6| Step: 10
Training loss: 0.5469427108764648
Validation loss: 1.7148881548194475

Epoch: 6| Step: 11
Training loss: 1.8784805536270142
Validation loss: 1.752107072901982

Epoch: 6| Step: 12
Training loss: 0.8749610781669617
Validation loss: 1.7529724503076205

Epoch: 6| Step: 13
Training loss: 2.038005828857422
Validation loss: 1.7176047268734183

Epoch: 476| Step: 0
Training loss: 1.2894747257232666
Validation loss: 1.729754174909284

Epoch: 6| Step: 1
Training loss: 1.1299564838409424
Validation loss: 1.7180509451896913

Epoch: 6| Step: 2
Training loss: 1.1684904098510742
Validation loss: 1.727897096705693

Epoch: 6| Step: 3
Training loss: 1.0361839532852173
Validation loss: 1.7199926145615116

Epoch: 6| Step: 4
Training loss: 0.9698109030723572
Validation loss: 1.725157892832192

Epoch: 6| Step: 5
Training loss: 1.0799076557159424
Validation loss: 1.7497061221830306

Epoch: 6| Step: 6
Training loss: 0.8230509757995605
Validation loss: 1.7178112896539832

Epoch: 6| Step: 7
Training loss: 1.1019203662872314
Validation loss: 1.7318183760489188

Epoch: 6| Step: 8
Training loss: 1.3935147523880005
Validation loss: 1.7206854102432088

Epoch: 6| Step: 9
Training loss: 1.2889777421951294
Validation loss: 1.7245990448100592

Epoch: 6| Step: 10
Training loss: 0.9347609281539917
Validation loss: 1.7507729607243692

Epoch: 6| Step: 11
Training loss: 0.8527296781539917
Validation loss: 1.663922772612623

Epoch: 6| Step: 12
Training loss: 0.9052532911300659
Validation loss: 1.7176880631395566

Epoch: 6| Step: 13
Training loss: 0.9052557349205017
Validation loss: 1.7153042772764802

Epoch: 477| Step: 0
Training loss: 0.9876341223716736
Validation loss: 1.6749981987860896

Epoch: 6| Step: 1
Training loss: 1.237526774406433
Validation loss: 1.7427940907016877

Epoch: 6| Step: 2
Training loss: 1.1698030233383179
Validation loss: 1.6906180920139435

Epoch: 6| Step: 3
Training loss: 1.2559938430786133
Validation loss: 1.7178459346935313

Epoch: 6| Step: 4
Training loss: 0.7540437579154968
Validation loss: 1.6825617372348745

Epoch: 6| Step: 5
Training loss: 1.0063954591751099
Validation loss: 1.7144882845622238

Epoch: 6| Step: 6
Training loss: 0.9900481700897217
Validation loss: 1.7149499641951693

Epoch: 6| Step: 7
Training loss: 0.9393709301948547
Validation loss: 1.7084588517424881

Epoch: 6| Step: 8
Training loss: 0.9754630923271179
Validation loss: 1.7364901675972888

Epoch: 6| Step: 9
Training loss: 1.0266282558441162
Validation loss: 1.707296363769039

Epoch: 6| Step: 10
Training loss: 0.6575654745101929
Validation loss: 1.7384544008521623

Epoch: 6| Step: 11
Training loss: 1.3761485815048218
Validation loss: 1.7748420879405031

Epoch: 6| Step: 12
Training loss: 1.020991563796997
Validation loss: 1.6826377209796701

Epoch: 6| Step: 13
Training loss: 1.2583935260772705
Validation loss: 1.6974752077492334

Epoch: 478| Step: 0
Training loss: 0.6354434490203857
Validation loss: 1.6923481892513972

Epoch: 6| Step: 1
Training loss: 1.2494248151779175
Validation loss: 1.6542878048394316

Epoch: 6| Step: 2
Training loss: 1.4638397693634033
Validation loss: 1.7035250535575293

Epoch: 6| Step: 3
Training loss: 0.8731139898300171
Validation loss: 1.6429103587263374

Epoch: 6| Step: 4
Training loss: 0.8610789775848389
Validation loss: 1.6454271975383963

Epoch: 6| Step: 5
Training loss: 0.8282705545425415
Validation loss: 1.6819791684868515

Epoch: 6| Step: 6
Training loss: 0.9777920842170715
Validation loss: 1.7031650004848358

Epoch: 6| Step: 7
Training loss: 0.649396538734436
Validation loss: 1.6820958083675754

Epoch: 6| Step: 8
Training loss: 0.9113933444023132
Validation loss: 1.6841377096791421

Epoch: 6| Step: 9
Training loss: 0.7035357356071472
Validation loss: 1.7244259272852251

Epoch: 6| Step: 10
Training loss: 1.4916038513183594
Validation loss: 1.7265483807492

Epoch: 6| Step: 11
Training loss: 1.6565037965774536
Validation loss: 1.6708436999269711

Epoch: 6| Step: 12
Training loss: 1.342221736907959
Validation loss: 1.7040167995678481

Epoch: 6| Step: 13
Training loss: 0.4108092188835144
Validation loss: 1.7022987309322561

Epoch: 479| Step: 0
Training loss: 0.9906965494155884
Validation loss: 1.7048714417283253

Epoch: 6| Step: 1
Training loss: 1.092820167541504
Validation loss: 1.7543273446380452

Epoch: 6| Step: 2
Training loss: 0.9734755754470825
Validation loss: 1.7374485205578547

Epoch: 6| Step: 3
Training loss: 1.3714083433151245
Validation loss: 1.705523992097506

Epoch: 6| Step: 4
Training loss: 0.9306764602661133
Validation loss: 1.65443322607266

Epoch: 6| Step: 5
Training loss: 0.7051594853401184
Validation loss: 1.7164877153212024

Epoch: 6| Step: 6
Training loss: 0.6161002516746521
Validation loss: 1.7240861205644504

Epoch: 6| Step: 7
Training loss: 1.3127565383911133
Validation loss: 1.7030771060656476

Epoch: 6| Step: 8
Training loss: 0.9489102363586426
Validation loss: 1.7298348770346692

Epoch: 6| Step: 9
Training loss: 1.2573611736297607
Validation loss: 1.6820972657972766

Epoch: 6| Step: 10
Training loss: 0.7386388778686523
Validation loss: 1.6789364737849082

Epoch: 6| Step: 11
Training loss: 1.2397509813308716
Validation loss: 1.709522613915064

Epoch: 6| Step: 12
Training loss: 0.9712121486663818
Validation loss: 1.7267282932035384

Epoch: 6| Step: 13
Training loss: 0.5787345170974731
Validation loss: 1.7387392982359855

Epoch: 480| Step: 0
Training loss: 1.3326280117034912
Validation loss: 1.7093409979215233

Epoch: 6| Step: 1
Training loss: 0.5998358726501465
Validation loss: 1.676065521855508

Epoch: 6| Step: 2
Training loss: 0.7248377203941345
Validation loss: 1.7062021583639166

Epoch: 6| Step: 3
Training loss: 0.8066255450248718
Validation loss: 1.6999959407314178

Epoch: 6| Step: 4
Training loss: 0.6477781534194946
Validation loss: 1.6856462083837038

Epoch: 6| Step: 5
Training loss: 0.9225689172744751
Validation loss: 1.712274323227585

Epoch: 6| Step: 6
Training loss: 1.3068909645080566
Validation loss: 1.6797025767705773

Epoch: 6| Step: 7
Training loss: 1.046383261680603
Validation loss: 1.686747076690838

Epoch: 6| Step: 8
Training loss: 1.2701252698898315
Validation loss: 1.6861553538230158

Epoch: 6| Step: 9
Training loss: 1.3970661163330078
Validation loss: 1.710977751721618

Epoch: 6| Step: 10
Training loss: 1.175652027130127
Validation loss: 1.6904359966196039

Epoch: 6| Step: 11
Training loss: 1.4606653451919556
Validation loss: 1.8028752214165145

Epoch: 6| Step: 12
Training loss: 0.6378723978996277
Validation loss: 1.7515231447835122

Epoch: 6| Step: 13
Training loss: 1.0452264547348022
Validation loss: 1.6908024049574328

Epoch: 481| Step: 0
Training loss: 0.7342708706855774
Validation loss: 1.738223188666887

Epoch: 6| Step: 1
Training loss: 1.6132110357284546
Validation loss: 1.7144036805757912

Epoch: 6| Step: 2
Training loss: 1.337411642074585
Validation loss: 1.714632631630026

Epoch: 6| Step: 3
Training loss: 1.5782639980316162
Validation loss: 1.7177900729640838

Epoch: 6| Step: 4
Training loss: 0.9846225380897522
Validation loss: 1.735916196659047

Epoch: 6| Step: 5
Training loss: 0.9605036973953247
Validation loss: 1.6695755822684175

Epoch: 6| Step: 6
Training loss: 0.6866793036460876
Validation loss: 1.6947187864652244

Epoch: 6| Step: 7
Training loss: 0.8289098143577576
Validation loss: 1.7313552902590843

Epoch: 6| Step: 8
Training loss: 0.8332981467247009
Validation loss: 1.6974986650610482

Epoch: 6| Step: 9
Training loss: 1.1350810527801514
Validation loss: 1.6857728919675272

Epoch: 6| Step: 10
Training loss: 0.7681711316108704
Validation loss: 1.6563845981833756

Epoch: 6| Step: 11
Training loss: 0.7470390796661377
Validation loss: 1.715654298823367

Epoch: 6| Step: 12
Training loss: 1.3439910411834717
Validation loss: 1.7240825609494281

Epoch: 6| Step: 13
Training loss: 0.5266027450561523
Validation loss: 1.70749649629798

Epoch: 482| Step: 0
Training loss: 1.306313395500183
Validation loss: 1.698516668811921

Epoch: 6| Step: 1
Training loss: 0.9336910247802734
Validation loss: 1.695293507268352

Epoch: 6| Step: 2
Training loss: 1.24661386013031
Validation loss: 1.7106967459442795

Epoch: 6| Step: 3
Training loss: 1.155623197555542
Validation loss: 1.7098395747523154

Epoch: 6| Step: 4
Training loss: 1.0685408115386963
Validation loss: 1.7656112793953187

Epoch: 6| Step: 5
Training loss: 1.7779524326324463
Validation loss: 1.7323415779298352

Epoch: 6| Step: 6
Training loss: 0.8683081865310669
Validation loss: 1.743643004407165

Epoch: 6| Step: 7
Training loss: 1.1232877969741821
Validation loss: 1.8158062170910578

Epoch: 6| Step: 8
Training loss: 1.2665934562683105
Validation loss: 1.7742586161500664

Epoch: 6| Step: 9
Training loss: 0.9758464694023132
Validation loss: 1.7530953807215537

Epoch: 6| Step: 10
Training loss: 0.5672512650489807
Validation loss: 1.7873779599384596

Epoch: 6| Step: 11
Training loss: 0.5810067653656006
Validation loss: 1.69841339254892

Epoch: 6| Step: 12
Training loss: 0.8890396356582642
Validation loss: 1.712057739175776

Epoch: 6| Step: 13
Training loss: 0.8887303471565247
Validation loss: 1.7075303933953727

Epoch: 483| Step: 0
Training loss: 0.7213159203529358
Validation loss: 1.7335195900291525

Epoch: 6| Step: 1
Training loss: 0.7657313346862793
Validation loss: 1.7272610574640253

Epoch: 6| Step: 2
Training loss: 1.5221199989318848
Validation loss: 1.6784465139912021

Epoch: 6| Step: 3
Training loss: 1.2781202793121338
Validation loss: 1.7603468151502712

Epoch: 6| Step: 4
Training loss: 1.0947904586791992
Validation loss: 1.695776875301074

Epoch: 6| Step: 5
Training loss: 1.0620338916778564
Validation loss: 1.660243716291202

Epoch: 6| Step: 6
Training loss: 0.6942651867866516
Validation loss: 1.7306556304295857

Epoch: 6| Step: 7
Training loss: 1.5236687660217285
Validation loss: 1.6810315014213644

Epoch: 6| Step: 8
Training loss: 0.937445342540741
Validation loss: 1.7483929171357104

Epoch: 6| Step: 9
Training loss: 0.9983897805213928
Validation loss: 1.7321618590303647

Epoch: 6| Step: 10
Training loss: 0.8821315765380859
Validation loss: 1.7274944166983328

Epoch: 6| Step: 11
Training loss: 1.0051658153533936
Validation loss: 1.6887761944083757

Epoch: 6| Step: 12
Training loss: 0.8978555202484131
Validation loss: 1.6907950524360902

Epoch: 6| Step: 13
Training loss: 1.5761040449142456
Validation loss: 1.729486806418306

Epoch: 484| Step: 0
Training loss: 1.0593528747558594
Validation loss: 1.7352970351455033

Epoch: 6| Step: 1
Training loss: 0.6659224033355713
Validation loss: 1.7185765774019304

Epoch: 6| Step: 2
Training loss: 1.199163794517517
Validation loss: 1.7092505552435433

Epoch: 6| Step: 3
Training loss: 0.8682814240455627
Validation loss: 1.75097821604821

Epoch: 6| Step: 4
Training loss: 1.107714056968689
Validation loss: 1.767764009455199

Epoch: 6| Step: 5
Training loss: 0.7998138070106506
Validation loss: 1.7243833080414803

Epoch: 6| Step: 6
Training loss: 1.6051734685897827
Validation loss: 1.7155052359386156

Epoch: 6| Step: 7
Training loss: 1.4097875356674194
Validation loss: 1.7272456243473997

Epoch: 6| Step: 8
Training loss: 1.091939926147461
Validation loss: 1.6987658892908404

Epoch: 6| Step: 9
Training loss: 0.8557881116867065
Validation loss: 1.7158391770496164

Epoch: 6| Step: 10
Training loss: 0.8527919054031372
Validation loss: 1.7382639941348825

Epoch: 6| Step: 11
Training loss: 0.9217424392700195
Validation loss: 1.6686546225701608

Epoch: 6| Step: 12
Training loss: 1.6553702354431152
Validation loss: 1.7532634901744064

Epoch: 6| Step: 13
Training loss: 0.8595904111862183
Validation loss: 1.680958927318614

Epoch: 485| Step: 0
Training loss: 1.2165929079055786
Validation loss: 1.7349326969474874

Epoch: 6| Step: 1
Training loss: 0.7303457260131836
Validation loss: 1.7035806435410694

Epoch: 6| Step: 2
Training loss: 0.9582460522651672
Validation loss: 1.7141848020656134

Epoch: 6| Step: 3
Training loss: 0.8001930713653564
Validation loss: 1.7408087740662277

Epoch: 6| Step: 4
Training loss: 1.357215404510498
Validation loss: 1.648403884262167

Epoch: 6| Step: 5
Training loss: 1.0521082878112793
Validation loss: 1.7281129526835617

Epoch: 6| Step: 6
Training loss: 0.977150559425354
Validation loss: 1.7405864718139812

Epoch: 6| Step: 7
Training loss: 1.0031957626342773
Validation loss: 1.7179591719822218

Epoch: 6| Step: 8
Training loss: 1.03701651096344
Validation loss: 1.773196840798983

Epoch: 6| Step: 9
Training loss: 1.776436686515808
Validation loss: 1.771909087575892

Epoch: 6| Step: 10
Training loss: 1.1120761632919312
Validation loss: 1.7215141891151347

Epoch: 6| Step: 11
Training loss: 0.6290891170501709
Validation loss: 1.6784156830080095

Epoch: 6| Step: 12
Training loss: 0.6871410608291626
Validation loss: 1.7349676765421385

Epoch: 6| Step: 13
Training loss: 1.2111254930496216
Validation loss: 1.6759836699372979

Epoch: 486| Step: 0
Training loss: 1.3269414901733398
Validation loss: 1.7199810038330734

Epoch: 6| Step: 1
Training loss: 0.7398921251296997
Validation loss: 1.6982761249747327

Epoch: 6| Step: 2
Training loss: 0.7041505575180054
Validation loss: 1.692070109869844

Epoch: 6| Step: 3
Training loss: 0.9755144119262695
Validation loss: 1.6971838935728996

Epoch: 6| Step: 4
Training loss: 1.6176221370697021
Validation loss: 1.726607386783887

Epoch: 6| Step: 5
Training loss: 0.872157096862793
Validation loss: 1.7697369167881627

Epoch: 6| Step: 6
Training loss: 0.791225254535675
Validation loss: 1.6364838436085691

Epoch: 6| Step: 7
Training loss: 1.2784430980682373
Validation loss: 1.7112050492276427

Epoch: 6| Step: 8
Training loss: 1.0099858045578003
Validation loss: 1.644417473064956

Epoch: 6| Step: 9
Training loss: 1.128646731376648
Validation loss: 1.728640100007416

Epoch: 6| Step: 10
Training loss: 0.8512424826622009
Validation loss: 1.7069630315226894

Epoch: 6| Step: 11
Training loss: 0.778265118598938
Validation loss: 1.691184946285781

Epoch: 6| Step: 12
Training loss: 1.3166563510894775
Validation loss: 1.6995067750253985

Epoch: 6| Step: 13
Training loss: 0.9934322834014893
Validation loss: 1.713216338106381

Epoch: 487| Step: 0
Training loss: 1.237555742263794
Validation loss: 1.7291729257952781

Epoch: 6| Step: 1
Training loss: 0.6824069023132324
Validation loss: 1.7669228917808943

Epoch: 6| Step: 2
Training loss: 1.2686994075775146
Validation loss: 1.7626742086102885

Epoch: 6| Step: 3
Training loss: 1.0223045349121094
Validation loss: 1.77321373134531

Epoch: 6| Step: 4
Training loss: 1.3208134174346924
Validation loss: 1.7445776552282355

Epoch: 6| Step: 5
Training loss: 0.797997236251831
Validation loss: 1.6998895445177633

Epoch: 6| Step: 6
Training loss: 1.0897111892700195
Validation loss: 1.7385528113252373

Epoch: 6| Step: 7
Training loss: 0.7681459784507751
Validation loss: 1.7309138133961668

Epoch: 6| Step: 8
Training loss: 0.8706344366073608
Validation loss: 1.7558412923607776

Epoch: 6| Step: 9
Training loss: 1.0946120023727417
Validation loss: 1.6781001488367717

Epoch: 6| Step: 10
Training loss: 1.1144776344299316
Validation loss: 1.674255468512094

Epoch: 6| Step: 11
Training loss: 0.7479302287101746
Validation loss: 1.6825450876707673

Epoch: 6| Step: 12
Training loss: 0.9699267148971558
Validation loss: 1.6795254394572268

Epoch: 6| Step: 13
Training loss: 1.3625156879425049
Validation loss: 1.662438811794404

Epoch: 488| Step: 0
Training loss: 1.013047695159912
Validation loss: 1.7026859265501781

Epoch: 6| Step: 1
Training loss: 1.3043327331542969
Validation loss: 1.6879215804479455

Epoch: 6| Step: 2
Training loss: 0.870326578617096
Validation loss: 1.667152504767141

Epoch: 6| Step: 3
Training loss: 0.965059220790863
Validation loss: 1.7046104169660998

Epoch: 6| Step: 4
Training loss: 1.5825741291046143
Validation loss: 1.6409672972976521

Epoch: 6| Step: 5
Training loss: 0.9852311611175537
Validation loss: 1.6896891465751074

Epoch: 6| Step: 6
Training loss: 0.718795895576477
Validation loss: 1.6881218789726176

Epoch: 6| Step: 7
Training loss: 0.7485976815223694
Validation loss: 1.7300977617181756

Epoch: 6| Step: 8
Training loss: 1.0292046070098877
Validation loss: 1.7635505096886748

Epoch: 6| Step: 9
Training loss: 1.3723294734954834
Validation loss: 1.7287559278549687

Epoch: 6| Step: 10
Training loss: 0.9730365872383118
Validation loss: 1.7392122412240634

Epoch: 6| Step: 11
Training loss: 0.6058007478713989
Validation loss: 1.7600408010585333

Epoch: 6| Step: 12
Training loss: 1.0513646602630615
Validation loss: 1.7391012176390617

Epoch: 6| Step: 13
Training loss: 1.036821722984314
Validation loss: 1.7448817658168014

Epoch: 489| Step: 0
Training loss: 0.9847310185432434
Validation loss: 1.739722559528966

Epoch: 6| Step: 1
Training loss: 0.7856717109680176
Validation loss: 1.6667094999744045

Epoch: 6| Step: 2
Training loss: 0.9584763050079346
Validation loss: 1.7823003492047709

Epoch: 6| Step: 3
Training loss: 0.8717126846313477
Validation loss: 1.670980905973783

Epoch: 6| Step: 4
Training loss: 1.0185741186141968
Validation loss: 1.6878002600003315

Epoch: 6| Step: 5
Training loss: 1.278518557548523
Validation loss: 1.7288704956731489

Epoch: 6| Step: 6
Training loss: 0.8413209915161133
Validation loss: 1.7357569843210199

Epoch: 6| Step: 7
Training loss: 1.2019551992416382
Validation loss: 1.678008533293201

Epoch: 6| Step: 8
Training loss: 1.2379307746887207
Validation loss: 1.7189999267619143

Epoch: 6| Step: 9
Training loss: 1.083799958229065
Validation loss: 1.6809968409999725

Epoch: 6| Step: 10
Training loss: 1.4456045627593994
Validation loss: 1.7062270833599953

Epoch: 6| Step: 11
Training loss: 0.80577552318573
Validation loss: 1.653880819197624

Epoch: 6| Step: 12
Training loss: 0.9614611864089966
Validation loss: 1.6850836623099543

Epoch: 6| Step: 13
Training loss: 0.7867529988288879
Validation loss: 1.7138756782777849

Epoch: 490| Step: 0
Training loss: 1.1252427101135254
Validation loss: 1.7869011125256937

Epoch: 6| Step: 1
Training loss: 1.1052130460739136
Validation loss: 1.7385312690529773

Epoch: 6| Step: 2
Training loss: 1.1038315296173096
Validation loss: 1.7360240797842703

Epoch: 6| Step: 3
Training loss: 1.0630018711090088
Validation loss: 1.7304212867572744

Epoch: 6| Step: 4
Training loss: 0.8637943863868713
Validation loss: 1.6976176628502466

Epoch: 6| Step: 5
Training loss: 0.7396700978279114
Validation loss: 1.7488680244773946

Epoch: 6| Step: 6
Training loss: 0.8725646734237671
Validation loss: 1.714491218648931

Epoch: 6| Step: 7
Training loss: 0.5374755859375
Validation loss: 1.7338398323264173

Epoch: 6| Step: 8
Training loss: 1.387037754058838
Validation loss: 1.6890275157907957

Epoch: 6| Step: 9
Training loss: 1.352330207824707
Validation loss: 1.6849990826781078

Epoch: 6| Step: 10
Training loss: 1.214469313621521
Validation loss: 1.7111933961991341

Epoch: 6| Step: 11
Training loss: 1.2524745464324951
Validation loss: 1.652783037513815

Epoch: 6| Step: 12
Training loss: 0.3745567500591278
Validation loss: 1.7363609165273688

Epoch: 6| Step: 13
Training loss: 1.51200270652771
Validation loss: 1.6831979161949568

Epoch: 491| Step: 0
Training loss: 0.6391737461090088
Validation loss: 1.6499517425414054

Epoch: 6| Step: 1
Training loss: 0.9707313179969788
Validation loss: 1.7122241495757975

Epoch: 6| Step: 2
Training loss: 1.4512596130371094
Validation loss: 1.6710165649332025

Epoch: 6| Step: 3
Training loss: 1.022676706314087
Validation loss: 1.6981664678101898

Epoch: 6| Step: 4
Training loss: 0.9370852708816528
Validation loss: 1.7305168990165956

Epoch: 6| Step: 5
Training loss: 1.2863123416900635
Validation loss: 1.703587007778947

Epoch: 6| Step: 6
Training loss: 0.9714105129241943
Validation loss: 1.7424089767599618

Epoch: 6| Step: 7
Training loss: 0.7633995413780212
Validation loss: 1.6625686204561623

Epoch: 6| Step: 8
Training loss: 0.6125689744949341
Validation loss: 1.6866542446997859

Epoch: 6| Step: 9
Training loss: 0.9096738696098328
Validation loss: 1.696213992693091

Epoch: 6| Step: 10
Training loss: 1.3050587177276611
Validation loss: 1.7194894193321146

Epoch: 6| Step: 11
Training loss: 1.3826651573181152
Validation loss: 1.7213874145220684

Epoch: 6| Step: 12
Training loss: 1.4208106994628906
Validation loss: 1.6679363302005235

Epoch: 6| Step: 13
Training loss: 0.4752606153488159
Validation loss: 1.696609761125298

Epoch: 492| Step: 0
Training loss: 0.9524152874946594
Validation loss: 1.700055274912106

Epoch: 6| Step: 1
Training loss: 0.522243857383728
Validation loss: 1.7204565296890915

Epoch: 6| Step: 2
Training loss: 1.1217743158340454
Validation loss: 1.7720790998910063

Epoch: 6| Step: 3
Training loss: 1.2103279829025269
Validation loss: 1.7340747707633561

Epoch: 6| Step: 4
Training loss: 1.2136452198028564
Validation loss: 1.685262405744163

Epoch: 6| Step: 5
Training loss: 0.8247998356819153
Validation loss: 1.7192261885571223

Epoch: 6| Step: 6
Training loss: 0.7228447794914246
Validation loss: 1.6864782187246508

Epoch: 6| Step: 7
Training loss: 1.479910135269165
Validation loss: 1.7287248655032086

Epoch: 6| Step: 8
Training loss: 1.0147676467895508
Validation loss: 1.7218906084696453

Epoch: 6| Step: 9
Training loss: 1.347583532333374
Validation loss: 1.7319216112936697

Epoch: 6| Step: 10
Training loss: 0.8174300193786621
Validation loss: 1.7391846769599504

Epoch: 6| Step: 11
Training loss: 0.7712587714195251
Validation loss: 1.7264599556564002

Epoch: 6| Step: 12
Training loss: 1.1733596324920654
Validation loss: 1.8144890531416862

Epoch: 6| Step: 13
Training loss: 1.259176254272461
Validation loss: 1.731530236941512

Epoch: 493| Step: 0
Training loss: 1.1609208583831787
Validation loss: 1.7029090568583498

Epoch: 6| Step: 1
Training loss: 0.6295839548110962
Validation loss: 1.7371887750523065

Epoch: 6| Step: 2
Training loss: 1.054769515991211
Validation loss: 1.7038936743172266

Epoch: 6| Step: 3
Training loss: 0.7422584295272827
Validation loss: 1.7239365552061348

Epoch: 6| Step: 4
Training loss: 0.8971173167228699
Validation loss: 1.6779721757417083

Epoch: 6| Step: 5
Training loss: 0.9281623363494873
Validation loss: 1.7094005013024935

Epoch: 6| Step: 6
Training loss: 1.0557341575622559
Validation loss: 1.6892918207312142

Epoch: 6| Step: 7
Training loss: 1.2491618394851685
Validation loss: 1.7163871270354076

Epoch: 6| Step: 8
Training loss: 1.3741415739059448
Validation loss: 1.670977847550505

Epoch: 6| Step: 9
Training loss: 0.8639358282089233
Validation loss: 1.6836312740079817

Epoch: 6| Step: 10
Training loss: 0.8905125856399536
Validation loss: 1.6781385316643664

Epoch: 6| Step: 11
Training loss: 1.3751579523086548
Validation loss: 1.7423171766342656

Epoch: 6| Step: 12
Training loss: 1.4246913194656372
Validation loss: 1.6405606603109708

Epoch: 6| Step: 13
Training loss: 0.4057822823524475
Validation loss: 1.7400841482224003

Epoch: 494| Step: 0
Training loss: 1.017836093902588
Validation loss: 1.725808071833785

Epoch: 6| Step: 1
Training loss: 0.6721667051315308
Validation loss: 1.6865153517774356

Epoch: 6| Step: 2
Training loss: 1.426640272140503
Validation loss: 1.7737367999169134

Epoch: 6| Step: 3
Training loss: 1.0945978164672852
Validation loss: 1.7599211444136917

Epoch: 6| Step: 4
Training loss: 1.6457196474075317
Validation loss: 1.7700392405192058

Epoch: 6| Step: 5
Training loss: 1.1545772552490234
Validation loss: 1.7452247411974016

Epoch: 6| Step: 6
Training loss: 0.4583342671394348
Validation loss: 1.725705357008083

Epoch: 6| Step: 7
Training loss: 1.4932560920715332
Validation loss: 1.7323901255925496

Epoch: 6| Step: 8
Training loss: 0.8369810581207275
Validation loss: 1.7005853345317226

Epoch: 6| Step: 9
Training loss: 0.8209577798843384
Validation loss: 1.6727577088981547

Epoch: 6| Step: 10
Training loss: 1.1649020910263062
Validation loss: 1.6852237729616062

Epoch: 6| Step: 11
Training loss: 0.6166431903839111
Validation loss: 1.6738007683907785

Epoch: 6| Step: 12
Training loss: 0.9818325042724609
Validation loss: 1.6895654509144444

Epoch: 6| Step: 13
Training loss: 1.1794840097427368
Validation loss: 1.7330962432328092

Epoch: 495| Step: 0
Training loss: 0.9431912302970886
Validation loss: 1.6442275752303421

Epoch: 6| Step: 1
Training loss: 0.8641562461853027
Validation loss: 1.6717344125111897

Epoch: 6| Step: 2
Training loss: 0.9900926947593689
Validation loss: 1.7288926570646224

Epoch: 6| Step: 3
Training loss: 0.8699424266815186
Validation loss: 1.69186415467211

Epoch: 6| Step: 4
Training loss: 0.9282160997390747
Validation loss: 1.7007305186281922

Epoch: 6| Step: 5
Training loss: 1.3117656707763672
Validation loss: 1.717670234300757

Epoch: 6| Step: 6
Training loss: 1.6386504173278809
Validation loss: 1.7186383124320739

Epoch: 6| Step: 7
Training loss: 0.8741961717605591
Validation loss: 1.7043078791710637

Epoch: 6| Step: 8
Training loss: 0.7609918713569641
Validation loss: 1.6920361595769082

Epoch: 6| Step: 9
Training loss: 1.3688457012176514
Validation loss: 1.7397941927756033

Epoch: 6| Step: 10
Training loss: 0.9583896994590759
Validation loss: 1.7396231825633715

Epoch: 6| Step: 11
Training loss: 0.7574008107185364
Validation loss: 1.7567590590446227

Epoch: 6| Step: 12
Training loss: 0.8061596751213074
Validation loss: 1.6869837314851823

Epoch: 6| Step: 13
Training loss: 0.9563576579093933
Validation loss: 1.6819838118809525

Epoch: 496| Step: 0
Training loss: 1.0338244438171387
Validation loss: 1.6830794426702684

Epoch: 6| Step: 1
Training loss: 0.9752078056335449
Validation loss: 1.6858570908987394

Epoch: 6| Step: 2
Training loss: 1.0992121696472168
Validation loss: 1.7030651595002861

Epoch: 6| Step: 3
Training loss: 1.5231826305389404
Validation loss: 1.7674461526255454

Epoch: 6| Step: 4
Training loss: 0.7903586626052856
Validation loss: 1.6556895855934388

Epoch: 6| Step: 5
Training loss: 0.6199133992195129
Validation loss: 1.6987317621067006

Epoch: 6| Step: 6
Training loss: 1.282181739807129
Validation loss: 1.7143480931558917

Epoch: 6| Step: 7
Training loss: 0.9236471652984619
Validation loss: 1.6885562660873576

Epoch: 6| Step: 8
Training loss: 1.104065179824829
Validation loss: 1.6978199058963406

Epoch: 6| Step: 9
Training loss: 1.3639451265335083
Validation loss: 1.6958976048295216

Epoch: 6| Step: 10
Training loss: 0.732694149017334
Validation loss: 1.6696824732647146

Epoch: 6| Step: 11
Training loss: 1.0787527561187744
Validation loss: 1.689857804647056

Epoch: 6| Step: 12
Training loss: 0.5867413282394409
Validation loss: 1.7012779110221452

Epoch: 6| Step: 13
Training loss: 0.9110506772994995
Validation loss: 1.7368622646536878

Epoch: 497| Step: 0
Training loss: 0.8273422718048096
Validation loss: 1.673751240135521

Epoch: 6| Step: 1
Training loss: 0.8681401610374451
Validation loss: 1.7500854820333502

Epoch: 6| Step: 2
Training loss: 1.0366145372390747
Validation loss: 1.7212527874977357

Epoch: 6| Step: 3
Training loss: 1.8990237712860107
Validation loss: 1.7114892505830335

Epoch: 6| Step: 4
Training loss: 0.9841898083686829
Validation loss: 1.743497670337718

Epoch: 6| Step: 5
Training loss: 1.4800384044647217
Validation loss: 1.7126766943162488

Epoch: 6| Step: 6
Training loss: 1.0297058820724487
Validation loss: 1.714213005958065

Epoch: 6| Step: 7
Training loss: 0.5677182674407959
Validation loss: 1.6653371498148928

Epoch: 6| Step: 8
Training loss: 0.8675876259803772
Validation loss: 1.7299251223123202

Epoch: 6| Step: 9
Training loss: 0.9778444766998291
Validation loss: 1.7105889672874122

Epoch: 6| Step: 10
Training loss: 0.7792422771453857
Validation loss: 1.7333671803115516

Epoch: 6| Step: 11
Training loss: 0.9174247980117798
Validation loss: 1.719569670256748

Epoch: 6| Step: 12
Training loss: 0.8195812702178955
Validation loss: 1.6983231139439408

Epoch: 6| Step: 13
Training loss: 0.8652222752571106
Validation loss: 1.6777911109309043

Epoch: 498| Step: 0
Training loss: 1.0057799816131592
Validation loss: 1.6557683239700973

Epoch: 6| Step: 1
Training loss: 0.594080924987793
Validation loss: 1.6904243141092279

Epoch: 6| Step: 2
Training loss: 0.7265785932540894
Validation loss: 1.7112264966451993

Epoch: 6| Step: 3
Training loss: 0.9868640899658203
Validation loss: 1.6879748259821246

Epoch: 6| Step: 4
Training loss: 0.7595546245574951
Validation loss: 1.7149852796267437

Epoch: 6| Step: 5
Training loss: 1.2673377990722656
Validation loss: 1.7155382812664073

Epoch: 6| Step: 6
Training loss: 0.785740852355957
Validation loss: 1.7659196481909802

Epoch: 6| Step: 7
Training loss: 1.5510691404342651
Validation loss: 1.7717913517387964

Epoch: 6| Step: 8
Training loss: 0.634190022945404
Validation loss: 1.6925882113877164

Epoch: 6| Step: 9
Training loss: 1.0663259029388428
Validation loss: 1.746572120215303

Epoch: 6| Step: 10
Training loss: 0.8719184398651123
Validation loss: 1.7102484190335838

Epoch: 6| Step: 11
Training loss: 1.408206820487976
Validation loss: 1.7028348381801317

Epoch: 6| Step: 12
Training loss: 1.0820027589797974
Validation loss: 1.6915887030222083

Epoch: 6| Step: 13
Training loss: 1.36283540725708
Validation loss: 1.6836175059759488

Epoch: 499| Step: 0
Training loss: 1.5148122310638428
Validation loss: 1.695238886340972

Epoch: 6| Step: 1
Training loss: 0.9486997127532959
Validation loss: 1.676105495422117

Epoch: 6| Step: 2
Training loss: 0.891310453414917
Validation loss: 1.7090675151476296

Epoch: 6| Step: 3
Training loss: 0.6331095695495605
Validation loss: 1.6815354990702804

Epoch: 6| Step: 4
Training loss: 1.1692519187927246
Validation loss: 1.7013030898186468

Epoch: 6| Step: 5
Training loss: 1.2793066501617432
Validation loss: 1.652203389393386

Epoch: 6| Step: 6
Training loss: 0.8351418375968933
Validation loss: 1.722189159803493

Epoch: 6| Step: 7
Training loss: 0.8940417766571045
Validation loss: 1.735715058542067

Epoch: 6| Step: 8
Training loss: 0.9190236926078796
Validation loss: 1.714147626712758

Epoch: 6| Step: 9
Training loss: 0.8738086223602295
Validation loss: 1.7845855348853654

Epoch: 6| Step: 10
Training loss: 1.0888409614562988
Validation loss: 1.719819454736607

Epoch: 6| Step: 11
Training loss: 1.4971349239349365
Validation loss: 1.6880457465366652

Epoch: 6| Step: 12
Training loss: 0.8829880952835083
Validation loss: 1.6746706296038885

Epoch: 6| Step: 13
Training loss: 0.7179279327392578
Validation loss: 1.776243035511304

Epoch: 500| Step: 0
Training loss: 0.84025639295578
Validation loss: 1.7402960331209245

Epoch: 6| Step: 1
Training loss: 0.9827593564987183
Validation loss: 1.7273758265279955

Epoch: 6| Step: 2
Training loss: 1.25700044631958
Validation loss: 1.7362536941805193

Epoch: 6| Step: 3
Training loss: 0.8885678052902222
Validation loss: 1.6585725885565563

Epoch: 6| Step: 4
Training loss: 1.0504133701324463
Validation loss: 1.6876876661854405

Epoch: 6| Step: 5
Training loss: 1.123980164527893
Validation loss: 1.7087878975816952

Epoch: 6| Step: 6
Training loss: 0.679263710975647
Validation loss: 1.6810436261597501

Epoch: 6| Step: 7
Training loss: 0.9366321563720703
Validation loss: 1.6787921613262546

Epoch: 6| Step: 8
Training loss: 0.7618486881256104
Validation loss: 1.6931789613539172

Epoch: 6| Step: 9
Training loss: 0.657524824142456
Validation loss: 1.7022136347268217

Epoch: 6| Step: 10
Training loss: 1.0438055992126465
Validation loss: 1.7205311739316551

Epoch: 6| Step: 11
Training loss: 0.9647383093833923
Validation loss: 1.725849687412221

Epoch: 6| Step: 12
Training loss: 1.7267158031463623
Validation loss: 1.7258641950545772

Epoch: 6| Step: 13
Training loss: 1.2159909009933472
Validation loss: 1.6961372949743783

Epoch: 501| Step: 0
Training loss: 1.011393427848816
Validation loss: 1.7065640957124772

Epoch: 6| Step: 1
Training loss: 1.3426326513290405
Validation loss: 1.7027933905201573

Epoch: 6| Step: 2
Training loss: 0.9469257593154907
Validation loss: 1.736264903058288

Epoch: 6| Step: 3
Training loss: 1.1498548984527588
Validation loss: 1.7269781994563278

Epoch: 6| Step: 4
Training loss: 0.8248357772827148
Validation loss: 1.7152279948675504

Epoch: 6| Step: 5
Training loss: 1.0872728824615479
Validation loss: 1.7160075197937668

Epoch: 6| Step: 6
Training loss: 1.1451064348220825
Validation loss: 1.6941683023206648

Epoch: 6| Step: 7
Training loss: 1.1830463409423828
Validation loss: 1.6904354736369143

Epoch: 6| Step: 8
Training loss: 1.0895963907241821
Validation loss: 1.6854683006963422

Epoch: 6| Step: 9
Training loss: 0.822218656539917
Validation loss: 1.7313875177855134

Epoch: 6| Step: 10
Training loss: 1.3300260305404663
Validation loss: 1.7442958970223703

Epoch: 6| Step: 11
Training loss: 0.6263768672943115
Validation loss: 1.6766986218831872

Epoch: 6| Step: 12
Training loss: 0.5323007106781006
Validation loss: 1.7198903676002257

Epoch: 6| Step: 13
Training loss: 0.9331527352333069
Validation loss: 1.705887984204036

Epoch: 502| Step: 0
Training loss: 1.1703839302062988
Validation loss: 1.7438643029941026

Epoch: 6| Step: 1
Training loss: 0.9419866800308228
Validation loss: 1.7330185905579598

Epoch: 6| Step: 2
Training loss: 0.8714007139205933
Validation loss: 1.6852185790256788

Epoch: 6| Step: 3
Training loss: 0.7632874250411987
Validation loss: 1.699723885905358

Epoch: 6| Step: 4
Training loss: 1.288151502609253
Validation loss: 1.7598948055698025

Epoch: 6| Step: 5
Training loss: 0.5365687012672424
Validation loss: 1.754213306211656

Epoch: 6| Step: 6
Training loss: 0.9594800472259521
Validation loss: 1.6807230698165072

Epoch: 6| Step: 7
Training loss: 1.0772240161895752
Validation loss: 1.7210283856238089

Epoch: 6| Step: 8
Training loss: 1.1328028440475464
Validation loss: 1.749846358453074

Epoch: 6| Step: 9
Training loss: 1.041160225868225
Validation loss: 1.7051086733418126

Epoch: 6| Step: 10
Training loss: 1.097493290901184
Validation loss: 1.745197187187851

Epoch: 6| Step: 11
Training loss: 0.9322401285171509
Validation loss: 1.745528672331123

Epoch: 6| Step: 12
Training loss: 1.065558910369873
Validation loss: 1.6744872421346686

Epoch: 6| Step: 13
Training loss: 0.9042423963546753
Validation loss: 1.7036634516972367

Epoch: 503| Step: 0
Training loss: 1.1100130081176758
Validation loss: 1.7147714373885945

Epoch: 6| Step: 1
Training loss: 1.0429184436798096
Validation loss: 1.6942674113858132

Epoch: 6| Step: 2
Training loss: 1.7915328741073608
Validation loss: 1.6986997717170305

Epoch: 6| Step: 3
Training loss: 1.2745387554168701
Validation loss: 1.6995125560350315

Epoch: 6| Step: 4
Training loss: 0.8090449571609497
Validation loss: 1.645133383812443

Epoch: 6| Step: 5
Training loss: 0.704025387763977
Validation loss: 1.689520473121315

Epoch: 6| Step: 6
Training loss: 0.7518301010131836
Validation loss: 1.652338045899586

Epoch: 6| Step: 7
Training loss: 0.7519403696060181
Validation loss: 1.7617830409798572

Epoch: 6| Step: 8
Training loss: 0.7542763948440552
Validation loss: 1.6843229480969009

Epoch: 6| Step: 9
Training loss: 0.9708147644996643
Validation loss: 1.719774297488633

Epoch: 6| Step: 10
Training loss: 0.8207439184188843
Validation loss: 1.7120159518334173

Epoch: 6| Step: 11
Training loss: 0.756891667842865
Validation loss: 1.7131581332093926

Epoch: 6| Step: 12
Training loss: 1.101191759109497
Validation loss: 1.7401775044779624

Epoch: 6| Step: 13
Training loss: 1.1960322856903076
Validation loss: 1.7787309410751506

Epoch: 504| Step: 0
Training loss: 0.753285825252533
Validation loss: 1.7209662519475466

Epoch: 6| Step: 1
Training loss: 1.015042781829834
Validation loss: 1.702903829595094

Epoch: 6| Step: 2
Training loss: 1.1360875368118286
Validation loss: 1.7085025618153233

Epoch: 6| Step: 3
Training loss: 1.1231194734573364
Validation loss: 1.6951773064110869

Epoch: 6| Step: 4
Training loss: 0.8778196573257446
Validation loss: 1.6972702600622689

Epoch: 6| Step: 5
Training loss: 0.49969589710235596
Validation loss: 1.7072713490455382

Epoch: 6| Step: 6
Training loss: 1.0365238189697266
Validation loss: 1.6745093637897122

Epoch: 6| Step: 7
Training loss: 1.1071044206619263
Validation loss: 1.6532231992290867

Epoch: 6| Step: 8
Training loss: 1.2413362264633179
Validation loss: 1.7484959274209955

Epoch: 6| Step: 9
Training loss: 0.46907612681388855
Validation loss: 1.7131242264983475

Epoch: 6| Step: 10
Training loss: 0.6444795727729797
Validation loss: 1.6771511134280954

Epoch: 6| Step: 11
Training loss: 1.5312862396240234
Validation loss: 1.7193597593615133

Epoch: 6| Step: 12
Training loss: 1.2752268314361572
Validation loss: 1.7521046835889098

Epoch: 6| Step: 13
Training loss: 1.097694993019104
Validation loss: 1.687930900563476

Epoch: 505| Step: 0
Training loss: 0.8483831882476807
Validation loss: 1.6944262609686902

Epoch: 6| Step: 1
Training loss: 0.7181676626205444
Validation loss: 1.6708191235860188

Epoch: 6| Step: 2
Training loss: 1.3267033100128174
Validation loss: 1.7408907234027822

Epoch: 6| Step: 3
Training loss: 1.0012903213500977
Validation loss: 1.660677267659095

Epoch: 6| Step: 4
Training loss: 1.5348780155181885
Validation loss: 1.7108138453575872

Epoch: 6| Step: 5
Training loss: 1.0816583633422852
Validation loss: 1.7086964832839144

Epoch: 6| Step: 6
Training loss: 0.695228636264801
Validation loss: 1.6764982105583273

Epoch: 6| Step: 7
Training loss: 0.7435179948806763
Validation loss: 1.6404353598112702

Epoch: 6| Step: 8
Training loss: 0.6741501092910767
Validation loss: 1.7223249507206742

Epoch: 6| Step: 9
Training loss: 0.6350361108779907
Validation loss: 1.7182713772660942

Epoch: 6| Step: 10
Training loss: 1.3316006660461426
Validation loss: 1.7399631213116389

Epoch: 6| Step: 11
Training loss: 0.7380188703536987
Validation loss: 1.7679439078095138

Epoch: 6| Step: 12
Training loss: 1.3884623050689697
Validation loss: 1.7202661268172725

Epoch: 6| Step: 13
Training loss: 0.8618020415306091
Validation loss: 1.7118154033537833

Epoch: 506| Step: 0
Training loss: 1.004892349243164
Validation loss: 1.6934335295872023

Epoch: 6| Step: 1
Training loss: 1.2226229906082153
Validation loss: 1.688678970900915

Epoch: 6| Step: 2
Training loss: 1.1162970066070557
Validation loss: 1.7646038352802236

Epoch: 6| Step: 3
Training loss: 0.9599815607070923
Validation loss: 1.7028997098245928

Epoch: 6| Step: 4
Training loss: 0.9819130897521973
Validation loss: 1.7056332890705397

Epoch: 6| Step: 5
Training loss: 1.3874433040618896
Validation loss: 1.7060560282840525

Epoch: 6| Step: 6
Training loss: 0.75499427318573
Validation loss: 1.7413405128704604

Epoch: 6| Step: 7
Training loss: 1.4073235988616943
Validation loss: 1.7329419402665989

Epoch: 6| Step: 8
Training loss: 0.8066720962524414
Validation loss: 1.7218038317977742

Epoch: 6| Step: 9
Training loss: 0.5936474800109863
Validation loss: 1.7116294509621077

Epoch: 6| Step: 10
Training loss: 0.7438389658927917
Validation loss: 1.7023621015651251

Epoch: 6| Step: 11
Training loss: 0.4720788598060608
Validation loss: 1.6827384848748483

Epoch: 6| Step: 12
Training loss: 1.1426584720611572
Validation loss: 1.7156616641629128

Epoch: 6| Step: 13
Training loss: 1.4886521100997925
Validation loss: 1.7204219384859967

Epoch: 507| Step: 0
Training loss: 0.6403142213821411
Validation loss: 1.708930249496173

Epoch: 6| Step: 1
Training loss: 1.4058281183242798
Validation loss: 1.7035658820982902

Epoch: 6| Step: 2
Training loss: 1.198514461517334
Validation loss: 1.730537708087634

Epoch: 6| Step: 3
Training loss: 0.6518394947052002
Validation loss: 1.6704065056257351

Epoch: 6| Step: 4
Training loss: 1.1925339698791504
Validation loss: 1.6462327241897583

Epoch: 6| Step: 5
Training loss: 1.0197768211364746
Validation loss: 1.725173181103122

Epoch: 6| Step: 6
Training loss: 1.6225945949554443
Validation loss: 1.7096494154263568

Epoch: 6| Step: 7
Training loss: 0.6838964223861694
Validation loss: 1.713397079898465

Epoch: 6| Step: 8
Training loss: 1.2149062156677246
Validation loss: 1.7266646610793246

Epoch: 6| Step: 9
Training loss: 0.6443597078323364
Validation loss: 1.6990077880121046

Epoch: 6| Step: 10
Training loss: 0.8197061419487
Validation loss: 1.6955040090827531

Epoch: 6| Step: 11
Training loss: 0.9142647385597229
Validation loss: 1.6913185311901955

Epoch: 6| Step: 12
Training loss: 1.0050708055496216
Validation loss: 1.6686337135171379

Epoch: 6| Step: 13
Training loss: 0.5237522125244141
Validation loss: 1.7156123076715777

Epoch: 508| Step: 0
Training loss: 0.8265355229377747
Validation loss: 1.7045352458953857

Epoch: 6| Step: 1
Training loss: 1.2873096466064453
Validation loss: 1.7510400843876663

Epoch: 6| Step: 2
Training loss: 0.6347301602363586
Validation loss: 1.6802656368542743

Epoch: 6| Step: 3
Training loss: 0.9310407638549805
Validation loss: 1.7119903897726407

Epoch: 6| Step: 4
Training loss: 0.8417431712150574
Validation loss: 1.6668600331070602

Epoch: 6| Step: 5
Training loss: 0.7522913217544556
Validation loss: 1.7060592738530969

Epoch: 6| Step: 6
Training loss: 0.8876739740371704
Validation loss: 1.695764107088889

Epoch: 6| Step: 7
Training loss: 0.626921534538269
Validation loss: 1.7016656591046242

Epoch: 6| Step: 8
Training loss: 1.9883321523666382
Validation loss: 1.68819688212487

Epoch: 6| Step: 9
Training loss: 0.7467501163482666
Validation loss: 1.722094754378001

Epoch: 6| Step: 10
Training loss: 0.9652100801467896
Validation loss: 1.7210479615837015

Epoch: 6| Step: 11
Training loss: 0.9015862345695496
Validation loss: 1.7008955811941495

Epoch: 6| Step: 12
Training loss: 1.197882056236267
Validation loss: 1.7092763980229695

Epoch: 6| Step: 13
Training loss: 1.176405429840088
Validation loss: 1.7256214375137

Epoch: 509| Step: 0
Training loss: 1.2401797771453857
Validation loss: 1.702607540674107

Epoch: 6| Step: 1
Training loss: 1.30234694480896
Validation loss: 1.6773078031437372

Epoch: 6| Step: 2
Training loss: 1.198962926864624
Validation loss: 1.6977096232034827

Epoch: 6| Step: 3
Training loss: 0.6252199411392212
Validation loss: 1.7451764050350393

Epoch: 6| Step: 4
Training loss: 1.0749386548995972
Validation loss: 1.7241525406478553

Epoch: 6| Step: 5
Training loss: 0.8557581305503845
Validation loss: 1.7397150403709822

Epoch: 6| Step: 6
Training loss: 0.6777818202972412
Validation loss: 1.6813943328395966

Epoch: 6| Step: 7
Training loss: 0.741753339767456
Validation loss: 1.7801051152649747

Epoch: 6| Step: 8
Training loss: 0.9805825352668762
Validation loss: 1.6804046592404764

Epoch: 6| Step: 9
Training loss: 1.488023281097412
Validation loss: 1.7566270097609489

Epoch: 6| Step: 10
Training loss: 0.9347278475761414
Validation loss: 1.7498306433359783

Epoch: 6| Step: 11
Training loss: 0.9828431606292725
Validation loss: 1.738883364585138

Epoch: 6| Step: 12
Training loss: 0.6902682781219482
Validation loss: 1.7420292733817972

Epoch: 6| Step: 13
Training loss: 0.6392717957496643
Validation loss: 1.718707876820718

Epoch: 510| Step: 0
Training loss: 1.2173211574554443
Validation loss: 1.7394033606334398

Epoch: 6| Step: 1
Training loss: 0.7481247186660767
Validation loss: 1.7382606511474938

Epoch: 6| Step: 2
Training loss: 0.8682675361633301
Validation loss: 1.6325728713825185

Epoch: 6| Step: 3
Training loss: 1.2219760417938232
Validation loss: 1.654122075726909

Epoch: 6| Step: 4
Training loss: 0.777581512928009
Validation loss: 1.7261405657696467

Epoch: 6| Step: 5
Training loss: 0.5454357862472534
Validation loss: 1.7273226784121605

Epoch: 6| Step: 6
Training loss: 1.0282871723175049
Validation loss: 1.7212133458865586

Epoch: 6| Step: 7
Training loss: 0.8984150886535645
Validation loss: 1.6779082487988215

Epoch: 6| Step: 8
Training loss: 0.8654993772506714
Validation loss: 1.6569229402849752

Epoch: 6| Step: 9
Training loss: 0.829291820526123
Validation loss: 1.7030185909681423

Epoch: 6| Step: 10
Training loss: 1.1917080879211426
Validation loss: 1.6793055047271073

Epoch: 6| Step: 11
Training loss: 0.9758774042129517
Validation loss: 1.7565535422294372

Epoch: 6| Step: 12
Training loss: 0.7358004450798035
Validation loss: 1.7215419264249905

Epoch: 6| Step: 13
Training loss: 1.7122845649719238
Validation loss: 1.6710268220593851

Epoch: 511| Step: 0
Training loss: 1.0331084728240967
Validation loss: 1.7328550969400713

Epoch: 6| Step: 1
Training loss: 1.0967525243759155
Validation loss: 1.71147322141996

Epoch: 6| Step: 2
Training loss: 1.1536741256713867
Validation loss: 1.7007048053126181

Epoch: 6| Step: 3
Training loss: 0.7692443132400513
Validation loss: 1.760295029609434

Epoch: 6| Step: 4
Training loss: 0.8107644319534302
Validation loss: 1.7097265489639775

Epoch: 6| Step: 5
Training loss: 0.8089914321899414
Validation loss: 1.7109149386805873

Epoch: 6| Step: 6
Training loss: 1.3877980709075928
Validation loss: 1.706829724773284

Epoch: 6| Step: 7
Training loss: 1.1479580402374268
Validation loss: 1.7166791423674552

Epoch: 6| Step: 8
Training loss: 1.0166659355163574
Validation loss: 1.6895556257617088

Epoch: 6| Step: 9
Training loss: 1.0648887157440186
Validation loss: 1.7109558838669972

Epoch: 6| Step: 10
Training loss: 0.7870444655418396
Validation loss: 1.645743045755612

Epoch: 6| Step: 11
Training loss: 0.8913822174072266
Validation loss: 1.7219035984367452

Epoch: 6| Step: 12
Training loss: 0.7203450202941895
Validation loss: 1.7136997586937361

Epoch: 6| Step: 13
Training loss: 0.3538382053375244
Validation loss: 1.7117874263435282

Epoch: 512| Step: 0
Training loss: 1.0714466571807861
Validation loss: 1.695261170787196

Epoch: 6| Step: 1
Training loss: 0.5426540374755859
Validation loss: 1.6984866613982825

Epoch: 6| Step: 2
Training loss: 1.3079216480255127
Validation loss: 1.6943885792968094

Epoch: 6| Step: 3
Training loss: 0.7580703496932983
Validation loss: 1.6624682693071262

Epoch: 6| Step: 4
Training loss: 1.1508785486221313
Validation loss: 1.71778323957997

Epoch: 6| Step: 5
Training loss: 1.0168198347091675
Validation loss: 1.7422160525475778

Epoch: 6| Step: 6
Training loss: 0.5865747332572937
Validation loss: 1.691600868778844

Epoch: 6| Step: 7
Training loss: 0.9890150427818298
Validation loss: 1.6980263674131004

Epoch: 6| Step: 8
Training loss: 0.9809902310371399
Validation loss: 1.6893150601335751

Epoch: 6| Step: 9
Training loss: 1.0167938470840454
Validation loss: 1.7230423381251674

Epoch: 6| Step: 10
Training loss: 0.5861902236938477
Validation loss: 1.7013224606872888

Epoch: 6| Step: 11
Training loss: 0.8378770351409912
Validation loss: 1.7237365502183155

Epoch: 6| Step: 12
Training loss: 1.2203221321105957
Validation loss: 1.6806773037038825

Epoch: 6| Step: 13
Training loss: 1.5850751399993896
Validation loss: 1.6856237778099634

Epoch: 513| Step: 0
Training loss: 0.9085089564323425
Validation loss: 1.6990000829901746

Epoch: 6| Step: 1
Training loss: 1.1877789497375488
Validation loss: 1.733529894582687

Epoch: 6| Step: 2
Training loss: 0.7695153951644897
Validation loss: 1.6928533930932321

Epoch: 6| Step: 3
Training loss: 1.114698886871338
Validation loss: 1.6778649130175192

Epoch: 6| Step: 4
Training loss: 0.8160253763198853
Validation loss: 1.7049186537342687

Epoch: 6| Step: 5
Training loss: 1.0873260498046875
Validation loss: 1.699611392072452

Epoch: 6| Step: 6
Training loss: 1.4359889030456543
Validation loss: 1.7004657073687481

Epoch: 6| Step: 7
Training loss: 1.0299046039581299
Validation loss: 1.7197602269470051

Epoch: 6| Step: 8
Training loss: 0.8853580951690674
Validation loss: 1.7147070387358307

Epoch: 6| Step: 9
Training loss: 0.7752794027328491
Validation loss: 1.6749947891440442

Epoch: 6| Step: 10
Training loss: 0.5789889097213745
Validation loss: 1.669302281513009

Epoch: 6| Step: 11
Training loss: 0.9222692251205444
Validation loss: 1.6909540596828665

Epoch: 6| Step: 12
Training loss: 1.1474840641021729
Validation loss: 1.716758433849581

Epoch: 6| Step: 13
Training loss: 0.5177416205406189
Validation loss: 1.6904997851258965

Epoch: 514| Step: 0
Training loss: 0.6561520099639893
Validation loss: 1.7225138820627683

Epoch: 6| Step: 1
Training loss: 1.436532735824585
Validation loss: 1.731954377184632

Epoch: 6| Step: 2
Training loss: 0.9143282175064087
Validation loss: 1.7278622247839486

Epoch: 6| Step: 3
Training loss: 0.9432060718536377
Validation loss: 1.6600214050662132

Epoch: 6| Step: 4
Training loss: 0.9700204133987427
Validation loss: 1.6865259165404944

Epoch: 6| Step: 5
Training loss: 0.6190433502197266
Validation loss: 1.679235351982937

Epoch: 6| Step: 6
Training loss: 0.8044983148574829
Validation loss: 1.6807597362866966

Epoch: 6| Step: 7
Training loss: 0.9028026461601257
Validation loss: 1.7347063710612636

Epoch: 6| Step: 8
Training loss: 1.068017840385437
Validation loss: 1.705611313543012

Epoch: 6| Step: 9
Training loss: 1.3749938011169434
Validation loss: 1.7231197728905627

Epoch: 6| Step: 10
Training loss: 0.6555421352386475
Validation loss: 1.75848904989099

Epoch: 6| Step: 11
Training loss: 1.0901566743850708
Validation loss: 1.7415827423013666

Epoch: 6| Step: 12
Training loss: 1.1290249824523926
Validation loss: 1.713702069815769

Epoch: 6| Step: 13
Training loss: 0.4197506308555603
Validation loss: 1.6654354180059125

Epoch: 515| Step: 0
Training loss: 1.1102728843688965
Validation loss: 1.7177630880827546

Epoch: 6| Step: 1
Training loss: 1.210320234298706
Validation loss: 1.694406327380929

Epoch: 6| Step: 2
Training loss: 0.7986772060394287
Validation loss: 1.7085018939869379

Epoch: 6| Step: 3
Training loss: 0.44419461488723755
Validation loss: 1.70439116672803

Epoch: 6| Step: 4
Training loss: 0.6844065189361572
Validation loss: 1.7005032852131834

Epoch: 6| Step: 5
Training loss: 1.3200342655181885
Validation loss: 1.6176992283072522

Epoch: 6| Step: 6
Training loss: 1.0908539295196533
Validation loss: 1.6742226526301394

Epoch: 6| Step: 7
Training loss: 0.9181894063949585
Validation loss: 1.717649131692866

Epoch: 6| Step: 8
Training loss: 0.8960353136062622
Validation loss: 1.662992432553281

Epoch: 6| Step: 9
Training loss: 1.078537940979004
Validation loss: 1.6578820354195052

Epoch: 6| Step: 10
Training loss: 1.2017810344696045
Validation loss: 1.7502764322424447

Epoch: 6| Step: 11
Training loss: 0.7381778359413147
Validation loss: 1.688394409354015

Epoch: 6| Step: 12
Training loss: 0.8535009622573853
Validation loss: 1.7111556299271122

Epoch: 6| Step: 13
Training loss: 0.9085656404495239
Validation loss: 1.6751070971130042

Epoch: 516| Step: 0
Training loss: 1.0630112886428833
Validation loss: 1.656015828091611

Epoch: 6| Step: 1
Training loss: 1.114952564239502
Validation loss: 1.7356568831269459

Epoch: 6| Step: 2
Training loss: 0.8483043909072876
Validation loss: 1.7082817772383332

Epoch: 6| Step: 3
Training loss: 1.2370290756225586
Validation loss: 1.6782976747840963

Epoch: 6| Step: 4
Training loss: 0.9502174854278564
Validation loss: 1.7577063498958465

Epoch: 6| Step: 5
Training loss: 0.6957612037658691
Validation loss: 1.7645723845369072

Epoch: 6| Step: 6
Training loss: 0.9932994246482849
Validation loss: 1.758303096217494

Epoch: 6| Step: 7
Training loss: 0.6825899481773376
Validation loss: 1.7339762564628356

Epoch: 6| Step: 8
Training loss: 0.925642728805542
Validation loss: 1.7635643225844189

Epoch: 6| Step: 9
Training loss: 0.9025458693504333
Validation loss: 1.7194899756421325

Epoch: 6| Step: 10
Training loss: 1.0382939577102661
Validation loss: 1.706132270956552

Epoch: 6| Step: 11
Training loss: 0.7936633825302124
Validation loss: 1.7169604801362561

Epoch: 6| Step: 12
Training loss: 1.3742783069610596
Validation loss: 1.7090099242425734

Epoch: 6| Step: 13
Training loss: 0.8161032795906067
Validation loss: 1.6715073739328692

Epoch: 517| Step: 0
Training loss: 0.8374883532524109
Validation loss: 1.7150854692664197

Epoch: 6| Step: 1
Training loss: 0.8166365027427673
Validation loss: 1.685530867627872

Epoch: 6| Step: 2
Training loss: 0.8591334819793701
Validation loss: 1.689529034399217

Epoch: 6| Step: 3
Training loss: 1.5462586879730225
Validation loss: 1.6569138239788752

Epoch: 6| Step: 4
Training loss: 0.915202260017395
Validation loss: 1.7170424897183654

Epoch: 6| Step: 5
Training loss: 0.4489849805831909
Validation loss: 1.6538180446112027

Epoch: 6| Step: 6
Training loss: 0.9292468428611755
Validation loss: 1.7009168722296273

Epoch: 6| Step: 7
Training loss: 1.1232147216796875
Validation loss: 1.7133784396674043

Epoch: 6| Step: 8
Training loss: 0.9984056949615479
Validation loss: 1.6927519177877774

Epoch: 6| Step: 9
Training loss: 1.1876217126846313
Validation loss: 1.703510134450851

Epoch: 6| Step: 10
Training loss: 1.0133366584777832
Validation loss: 1.6760200838888846

Epoch: 6| Step: 11
Training loss: 0.754584789276123
Validation loss: 1.6856054746976463

Epoch: 6| Step: 12
Training loss: 0.9110291600227356
Validation loss: 1.722386961342186

Epoch: 6| Step: 13
Training loss: 0.8040733933448792
Validation loss: 1.7046114706224011

Epoch: 518| Step: 0
Training loss: 1.11766517162323
Validation loss: 1.7151240084760933

Epoch: 6| Step: 1
Training loss: 1.128476858139038
Validation loss: 1.7568084578360281

Epoch: 6| Step: 2
Training loss: 1.0743403434753418
Validation loss: 1.6872963200333297

Epoch: 6| Step: 3
Training loss: 0.6125988960266113
Validation loss: 1.7783121165408884

Epoch: 6| Step: 4
Training loss: 0.9755408763885498
Validation loss: 1.7252989097308087

Epoch: 6| Step: 5
Training loss: 1.2761125564575195
Validation loss: 1.6840778627703268

Epoch: 6| Step: 6
Training loss: 0.9002072811126709
Validation loss: 1.7213454195248183

Epoch: 6| Step: 7
Training loss: 1.237710952758789
Validation loss: 1.7003201374443628

Epoch: 6| Step: 8
Training loss: 0.6632043123245239
Validation loss: 1.703850616690933

Epoch: 6| Step: 9
Training loss: 0.8306816816329956
Validation loss: 1.7186789345997635

Epoch: 6| Step: 10
Training loss: 1.075082540512085
Validation loss: 1.7197185254866076

Epoch: 6| Step: 11
Training loss: 0.9027425050735474
Validation loss: 1.6690983374913533

Epoch: 6| Step: 12
Training loss: 1.0192428827285767
Validation loss: 1.6698978331781202

Epoch: 6| Step: 13
Training loss: 0.9908748269081116
Validation loss: 1.7252168911759571

Epoch: 519| Step: 0
Training loss: 1.6040360927581787
Validation loss: 1.6842753502630419

Epoch: 6| Step: 1
Training loss: 0.6744235754013062
Validation loss: 1.711507519086202

Epoch: 6| Step: 2
Training loss: 0.9400283098220825
Validation loss: 1.676942197225427

Epoch: 6| Step: 3
Training loss: 0.8448566794395447
Validation loss: 1.6712170288126955

Epoch: 6| Step: 4
Training loss: 1.2642742395401
Validation loss: 1.6832730693201865

Epoch: 6| Step: 5
Training loss: 0.815290093421936
Validation loss: 1.6969821273639638

Epoch: 6| Step: 6
Training loss: 1.183544397354126
Validation loss: 1.7180401958445066

Epoch: 6| Step: 7
Training loss: 1.2954826354980469
Validation loss: 1.7725792546426096

Epoch: 6| Step: 8
Training loss: 0.5865169167518616
Validation loss: 1.697429233981717

Epoch: 6| Step: 9
Training loss: 0.8722890615463257
Validation loss: 1.7054803935430383

Epoch: 6| Step: 10
Training loss: 0.7906957864761353
Validation loss: 1.777939313201494

Epoch: 6| Step: 11
Training loss: 0.8477455377578735
Validation loss: 1.6937285213060276

Epoch: 6| Step: 12
Training loss: 0.8529477119445801
Validation loss: 1.7020740483396797

Epoch: 6| Step: 13
Training loss: 0.9552870988845825
Validation loss: 1.7352501820492487

Epoch: 520| Step: 0
Training loss: 0.6728566884994507
Validation loss: 1.6579704797396095

Epoch: 6| Step: 1
Training loss: 0.9756947755813599
Validation loss: 1.6658322516308035

Epoch: 6| Step: 2
Training loss: 0.6781474351882935
Validation loss: 1.722298514458441

Epoch: 6| Step: 3
Training loss: 0.9825481176376343
Validation loss: 1.6892167291333597

Epoch: 6| Step: 4
Training loss: 1.310908317565918
Validation loss: 1.7456304296370475

Epoch: 6| Step: 5
Training loss: 0.7992438673973083
Validation loss: 1.7412239402853034

Epoch: 6| Step: 6
Training loss: 0.6993173956871033
Validation loss: 1.6956423828678746

Epoch: 6| Step: 7
Training loss: 1.3891927003860474
Validation loss: 1.7521072369749828

Epoch: 6| Step: 8
Training loss: 0.8844377994537354
Validation loss: 1.7617875299146097

Epoch: 6| Step: 9
Training loss: 0.9739707112312317
Validation loss: 1.711946351553804

Epoch: 6| Step: 10
Training loss: 0.7834029197692871
Validation loss: 1.722950819999941

Epoch: 6| Step: 11
Training loss: 0.722103476524353
Validation loss: 1.733878513818146

Epoch: 6| Step: 12
Training loss: 1.1605510711669922
Validation loss: 1.6704285567806614

Epoch: 6| Step: 13
Training loss: 1.5125298500061035
Validation loss: 1.7023332990625852

Epoch: 521| Step: 0
Training loss: 0.9768026471138
Validation loss: 1.7379452759219753

Epoch: 6| Step: 1
Training loss: 0.5472137928009033
Validation loss: 1.6937688973642164

Epoch: 6| Step: 2
Training loss: 0.9742134213447571
Validation loss: 1.6555396382526686

Epoch: 6| Step: 3
Training loss: 0.7898839712142944
Validation loss: 1.6581912514983967

Epoch: 6| Step: 4
Training loss: 0.7257912158966064
Validation loss: 1.7329265084317935

Epoch: 6| Step: 5
Training loss: 1.356440544128418
Validation loss: 1.6589217711520452

Epoch: 6| Step: 6
Training loss: 1.1305198669433594
Validation loss: 1.696630717605673

Epoch: 6| Step: 7
Training loss: 0.7481555342674255
Validation loss: 1.7078558873104792

Epoch: 6| Step: 8
Training loss: 1.3880891799926758
Validation loss: 1.6911714243632492

Epoch: 6| Step: 9
Training loss: 0.404053270816803
Validation loss: 1.687411214715691

Epoch: 6| Step: 10
Training loss: 0.8338569402694702
Validation loss: 1.7020634399947299

Epoch: 6| Step: 11
Training loss: 0.8308582305908203
Validation loss: 1.733440908052588

Epoch: 6| Step: 12
Training loss: 1.1699223518371582
Validation loss: 1.7529398023441274

Epoch: 6| Step: 13
Training loss: 1.0781816244125366
Validation loss: 1.7151432832082112

Epoch: 522| Step: 0
Training loss: 0.742703914642334
Validation loss: 1.7285698793267692

Epoch: 6| Step: 1
Training loss: 1.0810699462890625
Validation loss: 1.7191326246466687

Epoch: 6| Step: 2
Training loss: 1.0032902956008911
Validation loss: 1.6780898635105421

Epoch: 6| Step: 3
Training loss: 0.8555691242218018
Validation loss: 1.6444139019135506

Epoch: 6| Step: 4
Training loss: 0.5475196242332458
Validation loss: 1.6603412628173828

Epoch: 6| Step: 5
Training loss: 1.1996994018554688
Validation loss: 1.656909469635256

Epoch: 6| Step: 6
Training loss: 0.952967643737793
Validation loss: 1.6729254209867088

Epoch: 6| Step: 7
Training loss: 1.102433443069458
Validation loss: 1.7076293794057702

Epoch: 6| Step: 8
Training loss: 0.37842923402786255
Validation loss: 1.6383043681421587

Epoch: 6| Step: 9
Training loss: 0.8922914266586304
Validation loss: 1.6755671321704824

Epoch: 6| Step: 10
Training loss: 1.3218939304351807
Validation loss: 1.6861336808050833

Epoch: 6| Step: 11
Training loss: 0.7956209182739258
Validation loss: 1.7127548071645922

Epoch: 6| Step: 12
Training loss: 0.9453140497207642
Validation loss: 1.7313887329511746

Epoch: 6| Step: 13
Training loss: 1.3218896389007568
Validation loss: 1.6371298938669183

Epoch: 523| Step: 0
Training loss: 1.05929434299469
Validation loss: 1.6990307018321047

Epoch: 6| Step: 1
Training loss: 1.357452392578125
Validation loss: 1.745037651831104

Epoch: 6| Step: 2
Training loss: 0.7454089522361755
Validation loss: 1.7228267180022372

Epoch: 6| Step: 3
Training loss: 1.7253228425979614
Validation loss: 1.7329084745017431

Epoch: 6| Step: 4
Training loss: 0.8405002355575562
Validation loss: 1.7343902395617576

Epoch: 6| Step: 5
Training loss: 0.7122805118560791
Validation loss: 1.7497956945050148

Epoch: 6| Step: 6
Training loss: 0.7970277070999146
Validation loss: 1.7300162161550214

Epoch: 6| Step: 7
Training loss: 0.8487812876701355
Validation loss: 1.7076411734345138

Epoch: 6| Step: 8
Training loss: 0.7047748565673828
Validation loss: 1.7029990265446324

Epoch: 6| Step: 9
Training loss: 1.0722037553787231
Validation loss: 1.6949652548759215

Epoch: 6| Step: 10
Training loss: 0.530860185623169
Validation loss: 1.706112906497012

Epoch: 6| Step: 11
Training loss: 1.5967216491699219
Validation loss: 1.6988868046832342

Epoch: 6| Step: 12
Training loss: 0.5307539701461792
Validation loss: 1.759836232790383

Epoch: 6| Step: 13
Training loss: 0.4394044876098633
Validation loss: 1.6668134222748459

Epoch: 524| Step: 0
Training loss: 0.48179152607917786
Validation loss: 1.720892511388307

Epoch: 6| Step: 1
Training loss: 0.9984138607978821
Validation loss: 1.6856498948989376

Epoch: 6| Step: 2
Training loss: 0.816016674041748
Validation loss: 1.7230483434533561

Epoch: 6| Step: 3
Training loss: 1.1374504566192627
Validation loss: 1.680669291045076

Epoch: 6| Step: 4
Training loss: 0.5391330718994141
Validation loss: 1.714884029921665

Epoch: 6| Step: 5
Training loss: 0.6846522688865662
Validation loss: 1.7222110584218016

Epoch: 6| Step: 6
Training loss: 0.7642649412155151
Validation loss: 1.7298880546323714

Epoch: 6| Step: 7
Training loss: 0.8707082271575928
Validation loss: 1.7421779613341055

Epoch: 6| Step: 8
Training loss: 1.6953176259994507
Validation loss: 1.658119777197479

Epoch: 6| Step: 9
Training loss: 1.3293166160583496
Validation loss: 1.7294135209052794

Epoch: 6| Step: 10
Training loss: 1.3101414442062378
Validation loss: 1.6978552149188133

Epoch: 6| Step: 11
Training loss: 0.8243131637573242
Validation loss: 1.739883017796342

Epoch: 6| Step: 12
Training loss: 0.6363658308982849
Validation loss: 1.7068119113163283

Epoch: 6| Step: 13
Training loss: 0.45093923807144165
Validation loss: 1.7201270646946405

Epoch: 525| Step: 0
Training loss: 1.126296877861023
Validation loss: 1.6988155175280828

Epoch: 6| Step: 1
Training loss: 1.3033214807510376
Validation loss: 1.7433462706945275

Epoch: 6| Step: 2
Training loss: 1.4932936429977417
Validation loss: 1.7371083715910554

Epoch: 6| Step: 3
Training loss: 0.8648898005485535
Validation loss: 1.6848356377693914

Epoch: 6| Step: 4
Training loss: 0.9212359189987183
Validation loss: 1.7084614820377801

Epoch: 6| Step: 5
Training loss: 0.790285050868988
Validation loss: 1.7417854596209783

Epoch: 6| Step: 6
Training loss: 0.3358750343322754
Validation loss: 1.7148284348108436

Epoch: 6| Step: 7
Training loss: 0.604753851890564
Validation loss: 1.7145084488776423

Epoch: 6| Step: 8
Training loss: 1.2696094512939453
Validation loss: 1.766434738712926

Epoch: 6| Step: 9
Training loss: 0.7216917276382446
Validation loss: 1.6813347057629657

Epoch: 6| Step: 10
Training loss: 1.047318696975708
Validation loss: 1.6802907092596895

Epoch: 6| Step: 11
Training loss: 0.6644676327705383
Validation loss: 1.703494301406286

Epoch: 6| Step: 12
Training loss: 1.1367881298065186
Validation loss: 1.723316002917546

Epoch: 6| Step: 13
Training loss: 0.7993572950363159
Validation loss: 1.687502820004699

Epoch: 526| Step: 0
Training loss: 0.9190374612808228
Validation loss: 1.6929726908283849

Epoch: 6| Step: 1
Training loss: 0.6499022245407104
Validation loss: 1.6688636925912672

Epoch: 6| Step: 2
Training loss: 0.5875982642173767
Validation loss: 1.6735912625507643

Epoch: 6| Step: 3
Training loss: 1.1066573858261108
Validation loss: 1.692311688136029

Epoch: 6| Step: 4
Training loss: 0.7183183431625366
Validation loss: 1.6878852510965

Epoch: 6| Step: 5
Training loss: 1.1544276475906372
Validation loss: 1.6960247050049484

Epoch: 6| Step: 6
Training loss: 0.7279407978057861
Validation loss: 1.7168995513710925

Epoch: 6| Step: 7
Training loss: 0.8195347189903259
Validation loss: 1.7126898278472245

Epoch: 6| Step: 8
Training loss: 0.8862097263336182
Validation loss: 1.7458116918481805

Epoch: 6| Step: 9
Training loss: 1.4891629219055176
Validation loss: 1.7277317316301408

Epoch: 6| Step: 10
Training loss: 0.9603734612464905
Validation loss: 1.7412085302414433

Epoch: 6| Step: 11
Training loss: 1.1961495876312256
Validation loss: 1.7095905734646706

Epoch: 6| Step: 12
Training loss: 0.7407722473144531
Validation loss: 1.7576971233531993

Epoch: 6| Step: 13
Training loss: 1.0966953039169312
Validation loss: 1.7154512969396447

Epoch: 527| Step: 0
Training loss: 1.094662070274353
Validation loss: 1.6900186974515197

Epoch: 6| Step: 1
Training loss: 1.1694655418395996
Validation loss: 1.7202958778668476

Epoch: 6| Step: 2
Training loss: 0.9445594549179077
Validation loss: 1.6444392947740452

Epoch: 6| Step: 3
Training loss: 0.949140191078186
Validation loss: 1.6823633460588352

Epoch: 6| Step: 4
Training loss: 1.2193734645843506
Validation loss: 1.63914369767712

Epoch: 6| Step: 5
Training loss: 0.7831190824508667
Validation loss: 1.699885586256622

Epoch: 6| Step: 6
Training loss: 0.8040410280227661
Validation loss: 1.65311558400431

Epoch: 6| Step: 7
Training loss: 0.5029247999191284
Validation loss: 1.7172853408321258

Epoch: 6| Step: 8
Training loss: 0.9248661994934082
Validation loss: 1.644520580127675

Epoch: 6| Step: 9
Training loss: 0.8295609951019287
Validation loss: 1.688160063118063

Epoch: 6| Step: 10
Training loss: 0.7393447160720825
Validation loss: 1.7138017890273884

Epoch: 6| Step: 11
Training loss: 0.6684522032737732
Validation loss: 1.719155094956839

Epoch: 6| Step: 12
Training loss: 1.1568527221679688
Validation loss: 1.7032545945977653

Epoch: 6| Step: 13
Training loss: 1.3682396411895752
Validation loss: 1.7043222432495446

Epoch: 528| Step: 0
Training loss: 0.6213308572769165
Validation loss: 1.6572552778387581

Epoch: 6| Step: 1
Training loss: 0.6525580883026123
Validation loss: 1.7216224849865

Epoch: 6| Step: 2
Training loss: 0.8691490888595581
Validation loss: 1.7259747738479285

Epoch: 6| Step: 3
Training loss: 0.8863362669944763
Validation loss: 1.727344887230986

Epoch: 6| Step: 4
Training loss: 1.067347764968872
Validation loss: 1.6916338615520026

Epoch: 6| Step: 5
Training loss: 0.8977451324462891
Validation loss: 1.6791828909227926

Epoch: 6| Step: 6
Training loss: 1.0251089334487915
Validation loss: 1.7133538838355773

Epoch: 6| Step: 7
Training loss: 0.8190151453018188
Validation loss: 1.6944228500448248

Epoch: 6| Step: 8
Training loss: 0.8915537595748901
Validation loss: 1.658899486705821

Epoch: 6| Step: 9
Training loss: 0.5562505722045898
Validation loss: 1.671068697847346

Epoch: 6| Step: 10
Training loss: 1.647284746170044
Validation loss: 1.7064275010939567

Epoch: 6| Step: 11
Training loss: 1.2780208587646484
Validation loss: 1.6644162593349334

Epoch: 6| Step: 12
Training loss: 0.9413772821426392
Validation loss: 1.6824512904690159

Epoch: 6| Step: 13
Training loss: 1.1918667554855347
Validation loss: 1.6699318167983845

Epoch: 529| Step: 0
Training loss: 1.4807839393615723
Validation loss: 1.7410164046031174

Epoch: 6| Step: 1
Training loss: 0.693041980266571
Validation loss: 1.7124558046299925

Epoch: 6| Step: 2
Training loss: 0.7496146559715271
Validation loss: 1.7225681094713108

Epoch: 6| Step: 3
Training loss: 1.1004798412322998
Validation loss: 1.7020228447452668

Epoch: 6| Step: 4
Training loss: 0.919158399105072
Validation loss: 1.6466778811588083

Epoch: 6| Step: 5
Training loss: 1.2237329483032227
Validation loss: 1.6527948866608322

Epoch: 6| Step: 6
Training loss: 0.8495516777038574
Validation loss: 1.708658738802838

Epoch: 6| Step: 7
Training loss: 0.5638524889945984
Validation loss: 1.6814769339817826

Epoch: 6| Step: 8
Training loss: 0.9499955177307129
Validation loss: 1.672446193233613

Epoch: 6| Step: 9
Training loss: 0.8710671663284302
Validation loss: 1.7179030397886872

Epoch: 6| Step: 10
Training loss: 0.8972713351249695
Validation loss: 1.6815412121434365

Epoch: 6| Step: 11
Training loss: 0.7125725150108337
Validation loss: 1.6795008028707197

Epoch: 6| Step: 12
Training loss: 1.0599428415298462
Validation loss: 1.7373976143457557

Epoch: 6| Step: 13
Training loss: 0.8258650302886963
Validation loss: 1.7001868460768013

Epoch: 530| Step: 0
Training loss: 0.7156828045845032
Validation loss: 1.6725639694480485

Epoch: 6| Step: 1
Training loss: 0.6779282689094543
Validation loss: 1.7046726442152453

Epoch: 6| Step: 2
Training loss: 1.1055065393447876
Validation loss: 1.732410204026007

Epoch: 6| Step: 3
Training loss: 1.131673812866211
Validation loss: 1.7255158885832755

Epoch: 6| Step: 4
Training loss: 1.2911176681518555
Validation loss: 1.738697108402047

Epoch: 6| Step: 5
Training loss: 0.8440420031547546
Validation loss: 1.7301219663312357

Epoch: 6| Step: 6
Training loss: 0.6470077633857727
Validation loss: 1.7015799988982498

Epoch: 6| Step: 7
Training loss: 0.8852752447128296
Validation loss: 1.7171519110279698

Epoch: 6| Step: 8
Training loss: 0.6847118735313416
Validation loss: 1.7250808003128215

Epoch: 6| Step: 9
Training loss: 1.056072473526001
Validation loss: 1.7015763175102971

Epoch: 6| Step: 10
Training loss: 0.9212467670440674
Validation loss: 1.7439720246099657

Epoch: 6| Step: 11
Training loss: 1.4746817350387573
Validation loss: 1.6998932553875832

Epoch: 6| Step: 12
Training loss: 0.9414053559303284
Validation loss: 1.6740582655834895

Epoch: 6| Step: 13
Training loss: 0.45613929629325867
Validation loss: 1.699943987272119

Epoch: 531| Step: 0
Training loss: 1.0911977291107178
Validation loss: 1.6673912489286034

Epoch: 6| Step: 1
Training loss: 0.758399248123169
Validation loss: 1.6911160061436314

Epoch: 6| Step: 2
Training loss: 0.970101535320282
Validation loss: 1.726632559171287

Epoch: 6| Step: 3
Training loss: 1.0081868171691895
Validation loss: 1.673388837486185

Epoch: 6| Step: 4
Training loss: 0.6237046718597412
Validation loss: 1.7204480286567443

Epoch: 6| Step: 5
Training loss: 1.3022785186767578
Validation loss: 1.7071081284553773

Epoch: 6| Step: 6
Training loss: 1.556235909461975
Validation loss: 1.7032393716996717

Epoch: 6| Step: 7
Training loss: 0.930009663105011
Validation loss: 1.7114247378482614

Epoch: 6| Step: 8
Training loss: 0.6989446878433228
Validation loss: 1.6580343695097073

Epoch: 6| Step: 9
Training loss: 0.7982455492019653
Validation loss: 1.6981367552152244

Epoch: 6| Step: 10
Training loss: 0.9657300710678101
Validation loss: 1.6615033739356584

Epoch: 6| Step: 11
Training loss: 0.6508602499961853
Validation loss: 1.6684596717998545

Epoch: 6| Step: 12
Training loss: 0.801724910736084
Validation loss: 1.6920937415092223

Epoch: 6| Step: 13
Training loss: 0.9214227199554443
Validation loss: 1.7395678309984104

Epoch: 532| Step: 0
Training loss: 0.8580422401428223
Validation loss: 1.7191857971170896

Epoch: 6| Step: 1
Training loss: 0.8018614053726196
Validation loss: 1.7396366083493797

Epoch: 6| Step: 2
Training loss: 0.9127458333969116
Validation loss: 1.726328037118399

Epoch: 6| Step: 3
Training loss: 1.5990664958953857
Validation loss: 1.7450814811132287

Epoch: 6| Step: 4
Training loss: 0.5521762371063232
Validation loss: 1.690027508684384

Epoch: 6| Step: 5
Training loss: 0.7804983854293823
Validation loss: 1.7114788550202564

Epoch: 6| Step: 6
Training loss: 1.0500128269195557
Validation loss: 1.6997787798604658

Epoch: 6| Step: 7
Training loss: 0.7611392736434937
Validation loss: 1.7147762185783797

Epoch: 6| Step: 8
Training loss: 0.8004831075668335
Validation loss: 1.655821446449526

Epoch: 6| Step: 9
Training loss: 0.9040315747261047
Validation loss: 1.6787612502292921

Epoch: 6| Step: 10
Training loss: 0.726463794708252
Validation loss: 1.700304486418283

Epoch: 6| Step: 11
Training loss: 0.885528564453125
Validation loss: 1.6542286616499706

Epoch: 6| Step: 12
Training loss: 0.8480594158172607
Validation loss: 1.6671530995317685

Epoch: 6| Step: 13
Training loss: 1.1420395374298096
Validation loss: 1.7256459830909647

Epoch: 533| Step: 0
Training loss: 0.7267012596130371
Validation loss: 1.7673152967165875

Epoch: 6| Step: 1
Training loss: 0.9271018505096436
Validation loss: 1.7244511060817267

Epoch: 6| Step: 2
Training loss: 1.3726580142974854
Validation loss: 1.750524995147541

Epoch: 6| Step: 3
Training loss: 0.9136694073677063
Validation loss: 1.7535156178218063

Epoch: 6| Step: 4
Training loss: 0.8492547273635864
Validation loss: 1.7665735726715417

Epoch: 6| Step: 5
Training loss: 0.7992887496948242
Validation loss: 1.7998590597542383

Epoch: 6| Step: 6
Training loss: 1.5241873264312744
Validation loss: 1.7882655153992355

Epoch: 6| Step: 7
Training loss: 0.8127168416976929
Validation loss: 1.801676348973346

Epoch: 6| Step: 8
Training loss: 0.8914830684661865
Validation loss: 1.803947305166593

Epoch: 6| Step: 9
Training loss: 0.8957885503768921
Validation loss: 1.7447907283741941

Epoch: 6| Step: 10
Training loss: 0.4877679944038391
Validation loss: 1.7493347096186813

Epoch: 6| Step: 11
Training loss: 1.2694814205169678
Validation loss: 1.6839492474832842

Epoch: 6| Step: 12
Training loss: 0.9158111810684204
Validation loss: 1.668273946290375

Epoch: 6| Step: 13
Training loss: 0.7039189338684082
Validation loss: 1.6854413619605444

Epoch: 534| Step: 0
Training loss: 0.8191636204719543
Validation loss: 1.707336752645431

Epoch: 6| Step: 1
Training loss: 1.6217151880264282
Validation loss: 1.7097749940810665

Epoch: 6| Step: 2
Training loss: 1.0574020147323608
Validation loss: 1.6878780447026736

Epoch: 6| Step: 3
Training loss: 1.016994833946228
Validation loss: 1.681035457118865

Epoch: 6| Step: 4
Training loss: 0.6750322580337524
Validation loss: 1.6421237632792482

Epoch: 6| Step: 5
Training loss: 0.4483144283294678
Validation loss: 1.7104794492003739

Epoch: 6| Step: 6
Training loss: 0.7557322978973389
Validation loss: 1.625651035257565

Epoch: 6| Step: 7
Training loss: 0.7681801915168762
Validation loss: 1.6809867082103607

Epoch: 6| Step: 8
Training loss: 1.0350672006607056
Validation loss: 1.7191101825365456

Epoch: 6| Step: 9
Training loss: 1.1111160516738892
Validation loss: 1.677747062457505

Epoch: 6| Step: 10
Training loss: 0.5843686461448669
Validation loss: 1.6743161934678272

Epoch: 6| Step: 11
Training loss: 1.5610074996948242
Validation loss: 1.6994988802940614

Epoch: 6| Step: 12
Training loss: 0.5863887071609497
Validation loss: 1.6979489903296194

Epoch: 6| Step: 13
Training loss: 0.8139287829399109
Validation loss: 1.6963568477220432

Epoch: 535| Step: 0
Training loss: 1.0112707614898682
Validation loss: 1.6895486565046414

Epoch: 6| Step: 1
Training loss: 0.7181206345558167
Validation loss: 1.712749986238377

Epoch: 6| Step: 2
Training loss: 1.428116798400879
Validation loss: 1.7235587168765325

Epoch: 6| Step: 3
Training loss: 0.567628800868988
Validation loss: 1.6953709240882628

Epoch: 6| Step: 4
Training loss: 1.0149545669555664
Validation loss: 1.6982022190606723

Epoch: 6| Step: 5
Training loss: 1.1869349479675293
Validation loss: 1.6889230769167665

Epoch: 6| Step: 6
Training loss: 0.9678780436515808
Validation loss: 1.6459738234037995

Epoch: 6| Step: 7
Training loss: 0.7656458616256714
Validation loss: 1.7483694002192507

Epoch: 6| Step: 8
Training loss: 0.5660260915756226
Validation loss: 1.7299618439007831

Epoch: 6| Step: 9
Training loss: 1.1061477661132812
Validation loss: 1.7029026964659333

Epoch: 6| Step: 10
Training loss: 0.9589498043060303
Validation loss: 1.6955154980382612

Epoch: 6| Step: 11
Training loss: 0.9911619424819946
Validation loss: 1.6745162240920528

Epoch: 6| Step: 12
Training loss: 0.6580038666725159
Validation loss: 1.7116082470904115

Epoch: 6| Step: 13
Training loss: 0.7045371532440186
Validation loss: 1.6800990489221388

Epoch: 536| Step: 0
Training loss: 0.8264349699020386
Validation loss: 1.7509014093747703

Epoch: 6| Step: 1
Training loss: 1.1467176675796509
Validation loss: 1.7222697516923309

Epoch: 6| Step: 2
Training loss: 0.9542053937911987
Validation loss: 1.7070625187248312

Epoch: 6| Step: 3
Training loss: 0.8185459971427917
Validation loss: 1.6875717870650753

Epoch: 6| Step: 4
Training loss: 1.085446834564209
Validation loss: 1.7177648723766368

Epoch: 6| Step: 5
Training loss: 1.0881859064102173
Validation loss: 1.7573526931065384

Epoch: 6| Step: 6
Training loss: 0.7553215026855469
Validation loss: 1.7331217655571558

Epoch: 6| Step: 7
Training loss: 0.6412999629974365
Validation loss: 1.7140692510912496

Epoch: 6| Step: 8
Training loss: 0.7773527503013611
Validation loss: 1.7159024566732428

Epoch: 6| Step: 9
Training loss: 1.0582541227340698
Validation loss: 1.7961943572567356

Epoch: 6| Step: 10
Training loss: 0.8976880311965942
Validation loss: 1.7026685617303337

Epoch: 6| Step: 11
Training loss: 0.8378782272338867
Validation loss: 1.6795686162928098

Epoch: 6| Step: 12
Training loss: 0.7789230346679688
Validation loss: 1.7581614755815076

Epoch: 6| Step: 13
Training loss: 0.9569952487945557
Validation loss: 1.7176004391844555

Epoch: 537| Step: 0
Training loss: 0.7672574520111084
Validation loss: 1.6517375887081187

Epoch: 6| Step: 1
Training loss: 0.5761812925338745
Validation loss: 1.7030986919197986

Epoch: 6| Step: 2
Training loss: 0.8230843544006348
Validation loss: 1.6962074746367752

Epoch: 6| Step: 3
Training loss: 0.7761456966400146
Validation loss: 1.6903731810149325

Epoch: 6| Step: 4
Training loss: 1.1933763027191162
Validation loss: 1.649678832741194

Epoch: 6| Step: 5
Training loss: 0.7049779295921326
Validation loss: 1.7080335155610116

Epoch: 6| Step: 6
Training loss: 1.3463735580444336
Validation loss: 1.6879908314315222

Epoch: 6| Step: 7
Training loss: 0.8489475250244141
Validation loss: 1.7081087866137106

Epoch: 6| Step: 8
Training loss: 1.363800287246704
Validation loss: 1.6867080670531078

Epoch: 6| Step: 9
Training loss: 0.7427904605865479
Validation loss: 1.6513938544898905

Epoch: 6| Step: 10
Training loss: 1.3466051816940308
Validation loss: 1.6916590647030902

Epoch: 6| Step: 11
Training loss: 0.669242799282074
Validation loss: 1.6706879382492394

Epoch: 6| Step: 12
Training loss: 0.6965224742889404
Validation loss: 1.7017445641179239

Epoch: 6| Step: 13
Training loss: 1.37056565284729
Validation loss: 1.713009839416832

Epoch: 538| Step: 0
Training loss: 0.9502941966056824
Validation loss: 1.7315186467221988

Epoch: 6| Step: 1
Training loss: 1.072877287864685
Validation loss: 1.725538360175266

Epoch: 6| Step: 2
Training loss: 1.079443335533142
Validation loss: 1.7083954721368768

Epoch: 6| Step: 3
Training loss: 0.9396142959594727
Validation loss: 1.6836099073451052

Epoch: 6| Step: 4
Training loss: 0.6661360263824463
Validation loss: 1.704781231059823

Epoch: 6| Step: 5
Training loss: 0.5381309986114502
Validation loss: 1.700927153710396

Epoch: 6| Step: 6
Training loss: 0.715499758720398
Validation loss: 1.6353769058822303

Epoch: 6| Step: 7
Training loss: 0.9317744970321655
Validation loss: 1.6771331551254436

Epoch: 6| Step: 8
Training loss: 0.7635551691055298
Validation loss: 1.6810552407336492

Epoch: 6| Step: 9
Training loss: 1.1301945447921753
Validation loss: 1.6826711867445259

Epoch: 6| Step: 10
Training loss: 0.5946792364120483
Validation loss: 1.6983631028923938

Epoch: 6| Step: 11
Training loss: 1.3279625177383423
Validation loss: 1.6981119071283648

Epoch: 6| Step: 12
Training loss: 0.9853121042251587
Validation loss: 1.713909120969875

Epoch: 6| Step: 13
Training loss: 1.2083420753479004
Validation loss: 1.7410707345572851

Epoch: 539| Step: 0
Training loss: 0.4762662649154663
Validation loss: 1.7597033323780182

Epoch: 6| Step: 1
Training loss: 1.0718302726745605
Validation loss: 1.7382208403720651

Epoch: 6| Step: 2
Training loss: 1.0507994890213013
Validation loss: 1.7110230371516237

Epoch: 6| Step: 3
Training loss: 0.7031753659248352
Validation loss: 1.7531196353256062

Epoch: 6| Step: 4
Training loss: 1.0755330324172974
Validation loss: 1.7536999141016314

Epoch: 6| Step: 5
Training loss: 1.1475849151611328
Validation loss: 1.670000059630281

Epoch: 6| Step: 6
Training loss: 1.2381329536437988
Validation loss: 1.7194695831626974

Epoch: 6| Step: 7
Training loss: 1.6284918785095215
Validation loss: 1.6804759092228387

Epoch: 6| Step: 8
Training loss: 0.9962425231933594
Validation loss: 1.7259038763661538

Epoch: 6| Step: 9
Training loss: 0.7424436211585999
Validation loss: 1.685871349867954

Epoch: 6| Step: 10
Training loss: 0.7842537760734558
Validation loss: 1.6596294885040612

Epoch: 6| Step: 11
Training loss: 0.626542866230011
Validation loss: 1.7322170490859656

Epoch: 6| Step: 12
Training loss: 0.8780895471572876
Validation loss: 1.6817456086476643

Epoch: 6| Step: 13
Training loss: 0.5600950121879578
Validation loss: 1.6669145668706586

Epoch: 540| Step: 0
Training loss: 0.6036041975021362
Validation loss: 1.7170560936773978

Epoch: 6| Step: 1
Training loss: 1.6505870819091797
Validation loss: 1.685662442638028

Epoch: 6| Step: 2
Training loss: 0.7024292349815369
Validation loss: 1.7109209068359867

Epoch: 6| Step: 3
Training loss: 0.6826231479644775
Validation loss: 1.720268549457673

Epoch: 6| Step: 4
Training loss: 0.6051782369613647
Validation loss: 1.7110712630774385

Epoch: 6| Step: 5
Training loss: 0.9503629207611084
Validation loss: 1.7223742264573292

Epoch: 6| Step: 6
Training loss: 0.8984320163726807
Validation loss: 1.733291805431407

Epoch: 6| Step: 7
Training loss: 1.2502195835113525
Validation loss: 1.7638099962665188

Epoch: 6| Step: 8
Training loss: 1.1047234535217285
Validation loss: 1.6861424599924395

Epoch: 6| Step: 9
Training loss: 0.8592653274536133
Validation loss: 1.6932282627269786

Epoch: 6| Step: 10
Training loss: 1.1454951763153076
Validation loss: 1.7092210644034929

Epoch: 6| Step: 11
Training loss: 0.49316439032554626
Validation loss: 1.6994394025494974

Epoch: 6| Step: 12
Training loss: 1.0200845003128052
Validation loss: 1.734735865746775

Epoch: 6| Step: 13
Training loss: 1.12242591381073
Validation loss: 1.7224739046506985

Epoch: 541| Step: 0
Training loss: 0.5133739709854126
Validation loss: 1.7469282868087932

Epoch: 6| Step: 1
Training loss: 1.176542043685913
Validation loss: 1.6555274276323215

Epoch: 6| Step: 2
Training loss: 0.8289701342582703
Validation loss: 1.691976233195233

Epoch: 6| Step: 3
Training loss: 0.8341344594955444
Validation loss: 1.7338109131782287

Epoch: 6| Step: 4
Training loss: 0.8067938089370728
Validation loss: 1.6770358816269906

Epoch: 6| Step: 5
Training loss: 1.3305854797363281
Validation loss: 1.6673231073605117

Epoch: 6| Step: 6
Training loss: 0.943374514579773
Validation loss: 1.7192450518249183

Epoch: 6| Step: 7
Training loss: 0.7957625985145569
Validation loss: 1.7218819536188597

Epoch: 6| Step: 8
Training loss: 0.7360014915466309
Validation loss: 1.7318714549464564

Epoch: 6| Step: 9
Training loss: 0.8693920373916626
Validation loss: 1.712102020940473

Epoch: 6| Step: 10
Training loss: 0.8741512298583984
Validation loss: 1.7273806474542106

Epoch: 6| Step: 11
Training loss: 0.9283413887023926
Validation loss: 1.727029219750435

Epoch: 6| Step: 12
Training loss: 1.091800570487976
Validation loss: 1.7372100712150655

Epoch: 6| Step: 13
Training loss: 0.5786387324333191
Validation loss: 1.7304830807511524

Epoch: 542| Step: 0
Training loss: 1.0374798774719238
Validation loss: 1.7137334487771476

Epoch: 6| Step: 1
Training loss: 0.6841397285461426
Validation loss: 1.767169007691004

Epoch: 6| Step: 2
Training loss: 1.180381178855896
Validation loss: 1.722545841688751

Epoch: 6| Step: 3
Training loss: 0.957553505897522
Validation loss: 1.682776484438168

Epoch: 6| Step: 4
Training loss: 0.7643256187438965
Validation loss: 1.6504381561792025

Epoch: 6| Step: 5
Training loss: 1.786473035812378
Validation loss: 1.6952674228657958

Epoch: 6| Step: 6
Training loss: 0.8402221202850342
Validation loss: 1.6796710080997919

Epoch: 6| Step: 7
Training loss: 0.8103877305984497
Validation loss: 1.6438847869955084

Epoch: 6| Step: 8
Training loss: 0.5031640529632568
Validation loss: 1.696154208593471

Epoch: 6| Step: 9
Training loss: 0.8013280630111694
Validation loss: 1.680569387251331

Epoch: 6| Step: 10
Training loss: 0.752131462097168
Validation loss: 1.6968856870487172

Epoch: 6| Step: 11
Training loss: 0.7515469789505005
Validation loss: 1.7425063258858138

Epoch: 6| Step: 12
Training loss: 0.6423717141151428
Validation loss: 1.671106578201376

Epoch: 6| Step: 13
Training loss: 1.2044446468353271
Validation loss: 1.692217146837583

Epoch: 543| Step: 0
Training loss: 0.6441888213157654
Validation loss: 1.6928029252636818

Epoch: 6| Step: 1
Training loss: 0.7566933631896973
Validation loss: 1.6803914987912743

Epoch: 6| Step: 2
Training loss: 1.2922381162643433
Validation loss: 1.674504941509616

Epoch: 6| Step: 3
Training loss: 0.6601535081863403
Validation loss: 1.6959862837227442

Epoch: 6| Step: 4
Training loss: 0.5451252460479736
Validation loss: 1.67094450612222

Epoch: 6| Step: 5
Training loss: 0.6220957040786743
Validation loss: 1.7008380082345778

Epoch: 6| Step: 6
Training loss: 0.7099704146385193
Validation loss: 1.7317759542055027

Epoch: 6| Step: 7
Training loss: 1.0935546159744263
Validation loss: 1.6730732007693219

Epoch: 6| Step: 8
Training loss: 0.823185920715332
Validation loss: 1.65357207739225

Epoch: 6| Step: 9
Training loss: 1.2710394859313965
Validation loss: 1.713959595208527

Epoch: 6| Step: 10
Training loss: 1.4524292945861816
Validation loss: 1.7241340901262017

Epoch: 6| Step: 11
Training loss: 1.1467421054840088
Validation loss: 1.684406985518753

Epoch: 6| Step: 12
Training loss: 0.8078671097755432
Validation loss: 1.7325017118966708

Epoch: 6| Step: 13
Training loss: 1.0575029850006104
Validation loss: 1.6708887584747807

Epoch: 544| Step: 0
Training loss: 0.6976903676986694
Validation loss: 1.7458744523345784

Epoch: 6| Step: 1
Training loss: 1.2200721502304077
Validation loss: 1.8073356407944874

Epoch: 6| Step: 2
Training loss: 0.7867973446846008
Validation loss: 1.791448672612508

Epoch: 6| Step: 3
Training loss: 0.8109384775161743
Validation loss: 1.7538831560842452

Epoch: 6| Step: 4
Training loss: 0.5570684671401978
Validation loss: 1.7113384046862203

Epoch: 6| Step: 5
Training loss: 0.8669124841690063
Validation loss: 1.7501242455615793

Epoch: 6| Step: 6
Training loss: 1.3765995502471924
Validation loss: 1.724772394344371

Epoch: 6| Step: 7
Training loss: 1.1505488157272339
Validation loss: 1.6816109072777532

Epoch: 6| Step: 8
Training loss: 0.906843900680542
Validation loss: 1.7238893162819646

Epoch: 6| Step: 9
Training loss: 0.6567050814628601
Validation loss: 1.702681197915026

Epoch: 6| Step: 10
Training loss: 0.6915849447250366
Validation loss: 1.6724537226461595

Epoch: 6| Step: 11
Training loss: 0.822100043296814
Validation loss: 1.6963903442505868

Epoch: 6| Step: 12
Training loss: 0.6065616607666016
Validation loss: 1.6986088393836893

Epoch: 6| Step: 13
Training loss: 2.017242431640625
Validation loss: 1.6705707708994548

Epoch: 545| Step: 0
Training loss: 0.6201845407485962
Validation loss: 1.6416389531986688

Epoch: 6| Step: 1
Training loss: 0.9521378874778748
Validation loss: 1.7242446740468342

Epoch: 6| Step: 2
Training loss: 1.1152715682983398
Validation loss: 1.7290179601279638

Epoch: 6| Step: 3
Training loss: 0.8006253242492676
Validation loss: 1.692235133981192

Epoch: 6| Step: 4
Training loss: 0.8738329410552979
Validation loss: 1.669182441567862

Epoch: 6| Step: 5
Training loss: 0.9796267747879028
Validation loss: 1.6690122517206336

Epoch: 6| Step: 6
Training loss: 0.8859585523605347
Validation loss: 1.6791838022970385

Epoch: 6| Step: 7
Training loss: 1.2114521265029907
Validation loss: 1.7086062713335919

Epoch: 6| Step: 8
Training loss: 1.4586939811706543
Validation loss: 1.66575026512146

Epoch: 6| Step: 9
Training loss: 0.5746933817863464
Validation loss: 1.712222565886795

Epoch: 6| Step: 10
Training loss: 0.9338725805282593
Validation loss: 1.7582015247755154

Epoch: 6| Step: 11
Training loss: 0.5859625339508057
Validation loss: 1.7321710907002932

Epoch: 6| Step: 12
Training loss: 1.0381739139556885
Validation loss: 1.6658093570381083

Epoch: 6| Step: 13
Training loss: 1.0405573844909668
Validation loss: 1.6985832081046155

Epoch: 546| Step: 0
Training loss: 1.0065882205963135
Validation loss: 1.6899416972232122

Epoch: 6| Step: 1
Training loss: 0.44095319509506226
Validation loss: 1.6436406809796569

Epoch: 6| Step: 2
Training loss: 0.6701668500900269
Validation loss: 1.6969097019523702

Epoch: 6| Step: 3
Training loss: 0.8901210427284241
Validation loss: 1.7062563319360056

Epoch: 6| Step: 4
Training loss: 1.1005730628967285
Validation loss: 1.697293552019263

Epoch: 6| Step: 5
Training loss: 0.7226765155792236
Validation loss: 1.7196650594793341

Epoch: 6| Step: 6
Training loss: 0.8966665267944336
Validation loss: 1.735579744462044

Epoch: 6| Step: 7
Training loss: 1.826280951499939
Validation loss: 1.702894700470791

Epoch: 6| Step: 8
Training loss: 0.8145686984062195
Validation loss: 1.6961044534560172

Epoch: 6| Step: 9
Training loss: 0.7296326756477356
Validation loss: 1.6913823825056835

Epoch: 6| Step: 10
Training loss: 1.1513762474060059
Validation loss: 1.7310139184357018

Epoch: 6| Step: 11
Training loss: 0.4117034375667572
Validation loss: 1.7312888868393437

Epoch: 6| Step: 12
Training loss: 0.9323503971099854
Validation loss: 1.700764371502784

Epoch: 6| Step: 13
Training loss: 0.9595462083816528
Validation loss: 1.7278867280611427

Epoch: 547| Step: 0
Training loss: 0.3967214822769165
Validation loss: 1.697053704210507

Epoch: 6| Step: 1
Training loss: 1.3769166469573975
Validation loss: 1.6880630177836264

Epoch: 6| Step: 2
Training loss: 0.9943581819534302
Validation loss: 1.7145904994780017

Epoch: 6| Step: 3
Training loss: 0.7779655456542969
Validation loss: 1.7191389914481872

Epoch: 6| Step: 4
Training loss: 0.9511474370956421
Validation loss: 1.691279076760815

Epoch: 6| Step: 5
Training loss: 0.7335735559463501
Validation loss: 1.7012088785889328

Epoch: 6| Step: 6
Training loss: 0.9596884846687317
Validation loss: 1.6845323065275788

Epoch: 6| Step: 7
Training loss: 0.36294519901275635
Validation loss: 1.6960465010776316

Epoch: 6| Step: 8
Training loss: 1.3375182151794434
Validation loss: 1.7271248332915767

Epoch: 6| Step: 9
Training loss: 0.5828223824501038
Validation loss: 1.6738963191227247

Epoch: 6| Step: 10
Training loss: 1.2123397588729858
Validation loss: 1.699226708822353

Epoch: 6| Step: 11
Training loss: 1.2381428480148315
Validation loss: 1.6380647766974665

Epoch: 6| Step: 12
Training loss: 0.5309147834777832
Validation loss: 1.6567588365206154

Epoch: 6| Step: 13
Training loss: 0.9785284399986267
Validation loss: 1.677923237123797

Epoch: 548| Step: 0
Training loss: 0.8198891282081604
Validation loss: 1.68504044061066

Epoch: 6| Step: 1
Training loss: 1.2024388313293457
Validation loss: 1.683668524988236

Epoch: 6| Step: 2
Training loss: 1.1511414051055908
Validation loss: 1.626150583708158

Epoch: 6| Step: 3
Training loss: 0.6747173070907593
Validation loss: 1.6723781580566077

Epoch: 6| Step: 4
Training loss: 0.6885051727294922
Validation loss: 1.7101782867985387

Epoch: 6| Step: 5
Training loss: 0.8501152992248535
Validation loss: 1.69510857905111

Epoch: 6| Step: 6
Training loss: 0.41361546516418457
Validation loss: 1.7239051198446622

Epoch: 6| Step: 7
Training loss: 0.8791121244430542
Validation loss: 1.659980547043585

Epoch: 6| Step: 8
Training loss: 0.7824252843856812
Validation loss: 1.6621861637279551

Epoch: 6| Step: 9
Training loss: 1.0765764713287354
Validation loss: 1.6196401388414445

Epoch: 6| Step: 10
Training loss: 1.2045683860778809
Validation loss: 1.6777946769550283

Epoch: 6| Step: 11
Training loss: 0.7286081910133362
Validation loss: 1.7549270750373922

Epoch: 6| Step: 12
Training loss: 1.3211956024169922
Validation loss: 1.6609876002034833

Epoch: 6| Step: 13
Training loss: 0.6116580963134766
Validation loss: 1.704044102340616

Epoch: 549| Step: 0
Training loss: 0.48971986770629883
Validation loss: 1.66220607039749

Epoch: 6| Step: 1
Training loss: 1.132194995880127
Validation loss: 1.642232915406586

Epoch: 6| Step: 2
Training loss: 0.31551846861839294
Validation loss: 1.680856862375813

Epoch: 6| Step: 3
Training loss: 1.0954053401947021
Validation loss: 1.6801236470540364

Epoch: 6| Step: 4
Training loss: 1.5746400356292725
Validation loss: 1.6963347106851556

Epoch: 6| Step: 5
Training loss: 0.6723803281784058
Validation loss: 1.6975847931318386

Epoch: 6| Step: 6
Training loss: 0.94068443775177
Validation loss: 1.707609022817304

Epoch: 6| Step: 7
Training loss: 0.6969512701034546
Validation loss: 1.67711038871478

Epoch: 6| Step: 8
Training loss: 1.020359754562378
Validation loss: 1.6895019149267545

Epoch: 6| Step: 9
Training loss: 0.539348304271698
Validation loss: 1.6734221007234307

Epoch: 6| Step: 10
Training loss: 0.7814879417419434
Validation loss: 1.690133261424239

Epoch: 6| Step: 11
Training loss: 0.6677625179290771
Validation loss: 1.7397213597451486

Epoch: 6| Step: 12
Training loss: 1.1982091665267944
Validation loss: 1.731125106093704

Epoch: 6| Step: 13
Training loss: 0.9309298396110535
Validation loss: 1.6723121289283998

Epoch: 550| Step: 0
Training loss: 1.059083342552185
Validation loss: 1.6994058944845711

Epoch: 6| Step: 1
Training loss: 0.7464035749435425
Validation loss: 1.7541836423258628

Epoch: 6| Step: 2
Training loss: 1.0805754661560059
Validation loss: 1.7307126009336082

Epoch: 6| Step: 3
Training loss: 0.4529273509979248
Validation loss: 1.725406612119367

Epoch: 6| Step: 4
Training loss: 0.6777244806289673
Validation loss: 1.7316045209925661

Epoch: 6| Step: 5
Training loss: 1.4697226285934448
Validation loss: 1.6885758241017659

Epoch: 6| Step: 6
Training loss: 1.448049783706665
Validation loss: 1.6827364429350822

Epoch: 6| Step: 7
Training loss: 0.5587247610092163
Validation loss: 1.718469064722779

Epoch: 6| Step: 8
Training loss: 0.5703297853469849
Validation loss: 1.6758587001472391

Epoch: 6| Step: 9
Training loss: 0.5607041716575623
Validation loss: 1.6863848547781668

Epoch: 6| Step: 10
Training loss: 1.150169849395752
Validation loss: 1.7219881178230367

Epoch: 6| Step: 11
Training loss: 1.0720677375793457
Validation loss: 1.690361185740399

Epoch: 6| Step: 12
Training loss: 0.46549755334854126
Validation loss: 1.7056515357827629

Epoch: 6| Step: 13
Training loss: 0.9165121912956238
Validation loss: 1.6531944685084845

Epoch: 551| Step: 0
Training loss: 1.3223216533660889
Validation loss: 1.7040562591245096

Epoch: 6| Step: 1
Training loss: 1.0287470817565918
Validation loss: 1.7045589172711937

Epoch: 6| Step: 2
Training loss: 0.7952972650527954
Validation loss: 1.6898052038684968

Epoch: 6| Step: 3
Training loss: 1.0757997035980225
Validation loss: 1.689169805536988

Epoch: 6| Step: 4
Training loss: 0.7721605896949768
Validation loss: 1.726076078671281

Epoch: 6| Step: 5
Training loss: 0.9722263813018799
Validation loss: 1.6871944217271702

Epoch: 6| Step: 6
Training loss: 0.9816391468048096
Validation loss: 1.6559039187687699

Epoch: 6| Step: 7
Training loss: 0.9128761887550354
Validation loss: 1.6662770894265944

Epoch: 6| Step: 8
Training loss: 0.830704391002655
Validation loss: 1.6768657648435203

Epoch: 6| Step: 9
Training loss: 0.38963782787323
Validation loss: 1.7360804644964074

Epoch: 6| Step: 10
Training loss: 0.6660963296890259
Validation loss: 1.719254950041412

Epoch: 6| Step: 11
Training loss: 1.3365607261657715
Validation loss: 1.6916755937760877

Epoch: 6| Step: 12
Training loss: 0.582139790058136
Validation loss: 1.7268740284827448

Epoch: 6| Step: 13
Training loss: 1.3551744222640991
Validation loss: 1.7127191353869695

Epoch: 552| Step: 0
Training loss: 0.6867965459823608
Validation loss: 1.7143497274767967

Epoch: 6| Step: 1
Training loss: 0.5933564305305481
Validation loss: 1.7311570605924052

Epoch: 6| Step: 2
Training loss: 1.1050963401794434
Validation loss: 1.7203713745199225

Epoch: 6| Step: 3
Training loss: 1.1141314506530762
Validation loss: 1.715308771338514

Epoch: 6| Step: 4
Training loss: 0.5635966062545776
Validation loss: 1.6965909696394397

Epoch: 6| Step: 5
Training loss: 0.39490851759910583
Validation loss: 1.6758693546377204

Epoch: 6| Step: 6
Training loss: 1.637633204460144
Validation loss: 1.7169754428248252

Epoch: 6| Step: 7
Training loss: 0.6637226343154907
Validation loss: 1.6829675679565759

Epoch: 6| Step: 8
Training loss: 1.2378435134887695
Validation loss: 1.69309102976194

Epoch: 6| Step: 9
Training loss: 0.8952493071556091
Validation loss: 1.6538129160481114

Epoch: 6| Step: 10
Training loss: 1.0088229179382324
Validation loss: 1.6918380234831123

Epoch: 6| Step: 11
Training loss: 0.7011927962303162
Validation loss: 1.6853689262943883

Epoch: 6| Step: 12
Training loss: 0.8853203654289246
Validation loss: 1.683275112541773

Epoch: 6| Step: 13
Training loss: 0.5902858972549438
Validation loss: 1.749831848247077

Epoch: 553| Step: 0
Training loss: 1.1860342025756836
Validation loss: 1.6877021135822419

Epoch: 6| Step: 1
Training loss: 0.6835814714431763
Validation loss: 1.6569268626551474

Epoch: 6| Step: 2
Training loss: 0.6248128414154053
Validation loss: 1.6785383993579495

Epoch: 6| Step: 3
Training loss: 0.4079015851020813
Validation loss: 1.7236442835100236

Epoch: 6| Step: 4
Training loss: 1.076590657234192
Validation loss: 1.6935371070779779

Epoch: 6| Step: 5
Training loss: 1.1032642126083374
Validation loss: 1.7019570194264895

Epoch: 6| Step: 6
Training loss: 0.5906738638877869
Validation loss: 1.7742457992287093

Epoch: 6| Step: 7
Training loss: 0.9690804481506348
Validation loss: 1.6565960068856516

Epoch: 6| Step: 8
Training loss: 1.1024802923202515
Validation loss: 1.6819593111673992

Epoch: 6| Step: 9
Training loss: 1.1400742530822754
Validation loss: 1.7117343794914983

Epoch: 6| Step: 10
Training loss: 0.6792897582054138
Validation loss: 1.6801944496811076

Epoch: 6| Step: 11
Training loss: 0.6424480080604553
Validation loss: 1.7196198573676489

Epoch: 6| Step: 12
Training loss: 1.5482897758483887
Validation loss: 1.6877325901421167

Epoch: 6| Step: 13
Training loss: 0.5256824493408203
Validation loss: 1.664815459200131

Epoch: 554| Step: 0
Training loss: 1.0434434413909912
Validation loss: 1.6875225997740222

Epoch: 6| Step: 1
Training loss: 1.2048230171203613
Validation loss: 1.6636528840629004

Epoch: 6| Step: 2
Training loss: 0.7137216925621033
Validation loss: 1.6818898672698646

Epoch: 6| Step: 3
Training loss: 1.3322423696517944
Validation loss: 1.6733219546656455

Epoch: 6| Step: 4
Training loss: 0.6485586166381836
Validation loss: 1.6822706319952523

Epoch: 6| Step: 5
Training loss: 0.5840504169464111
Validation loss: 1.7385406289049374

Epoch: 6| Step: 6
Training loss: 1.2664573192596436
Validation loss: 1.6857424551440823

Epoch: 6| Step: 7
Training loss: 0.9006609916687012
Validation loss: 1.6663031065335838

Epoch: 6| Step: 8
Training loss: 0.7646241784095764
Validation loss: 1.6763997565033615

Epoch: 6| Step: 9
Training loss: 0.8638705015182495
Validation loss: 1.7111253020583943

Epoch: 6| Step: 10
Training loss: 0.6241815090179443
Validation loss: 1.6975658119365733

Epoch: 6| Step: 11
Training loss: 0.7571037411689758
Validation loss: 1.7302234800913001

Epoch: 6| Step: 12
Training loss: 0.6181508898735046
Validation loss: 1.7174208266760713

Epoch: 6| Step: 13
Training loss: 1.1879873275756836
Validation loss: 1.7066464475406113

Epoch: 555| Step: 0
Training loss: 1.0058952569961548
Validation loss: 1.7276248149974371

Epoch: 6| Step: 1
Training loss: 0.7209475040435791
Validation loss: 1.6570301043089999

Epoch: 6| Step: 2
Training loss: 1.1583280563354492
Validation loss: 1.697475533331594

Epoch: 6| Step: 3
Training loss: 0.9390574097633362
Validation loss: 1.6966038006608204

Epoch: 6| Step: 4
Training loss: 0.8265532851219177
Validation loss: 1.7147243010100497

Epoch: 6| Step: 5
Training loss: 0.9908583164215088
Validation loss: 1.6579517382447437

Epoch: 6| Step: 6
Training loss: 1.3581374883651733
Validation loss: 1.7198238129256873

Epoch: 6| Step: 7
Training loss: 0.9743828773498535
Validation loss: 1.6973918432830482

Epoch: 6| Step: 8
Training loss: 0.9208968877792358
Validation loss: 1.704550850775934

Epoch: 6| Step: 9
Training loss: 0.739559531211853
Validation loss: 1.719322871136409

Epoch: 6| Step: 10
Training loss: 0.43417325615882874
Validation loss: 1.6678578058878581

Epoch: 6| Step: 11
Training loss: 0.6538225412368774
Validation loss: 1.680689202841892

Epoch: 6| Step: 12
Training loss: 0.6007798314094543
Validation loss: 1.6806280459127119

Epoch: 6| Step: 13
Training loss: 0.7510677576065063
Validation loss: 1.7141674616003548

Epoch: 556| Step: 0
Training loss: 0.9276130199432373
Validation loss: 1.6563761247101652

Epoch: 6| Step: 1
Training loss: 1.0224709510803223
Validation loss: 1.7461607994571808

Epoch: 6| Step: 2
Training loss: 1.3428490161895752
Validation loss: 1.6762596266244048

Epoch: 6| Step: 3
Training loss: 0.8664605617523193
Validation loss: 1.7312016897304083

Epoch: 6| Step: 4
Training loss: 1.0294667482376099
Validation loss: 1.6861718162413566

Epoch: 6| Step: 5
Training loss: 0.7768440842628479
Validation loss: 1.7055118878682454

Epoch: 6| Step: 6
Training loss: 0.3277038335800171
Validation loss: 1.7223781475456812

Epoch: 6| Step: 7
Training loss: 0.9387167692184448
Validation loss: 1.7050976022597282

Epoch: 6| Step: 8
Training loss: 0.7273776531219482
Validation loss: 1.7054810652168848

Epoch: 6| Step: 9
Training loss: 0.6701204776763916
Validation loss: 1.6528789535645516

Epoch: 6| Step: 10
Training loss: 0.9389998316764832
Validation loss: 1.6931624258718183

Epoch: 6| Step: 11
Training loss: 0.662600040435791
Validation loss: 1.6617852308416878

Epoch: 6| Step: 12
Training loss: 1.0019277334213257
Validation loss: 1.66036404332807

Epoch: 6| Step: 13
Training loss: 0.8827041387557983
Validation loss: 1.7081003394178165

Epoch: 557| Step: 0
Training loss: 0.9100947380065918
Validation loss: 1.6665846404208933

Epoch: 6| Step: 1
Training loss: 0.6513628363609314
Validation loss: 1.6558867590401762

Epoch: 6| Step: 2
Training loss: 0.8704742193222046
Validation loss: 1.708916700014504

Epoch: 6| Step: 3
Training loss: 0.9525661468505859
Validation loss: 1.6823036183593094

Epoch: 6| Step: 4
Training loss: 1.3846107721328735
Validation loss: 1.6789863853044407

Epoch: 6| Step: 5
Training loss: 0.7445085048675537
Validation loss: 1.726439191449073

Epoch: 6| Step: 6
Training loss: 0.923115074634552
Validation loss: 1.7144751356494041

Epoch: 6| Step: 7
Training loss: 1.3977468013763428
Validation loss: 1.6677621859376148

Epoch: 6| Step: 8
Training loss: 0.5241405367851257
Validation loss: 1.7163165743632982

Epoch: 6| Step: 9
Training loss: 1.0279227495193481
Validation loss: 1.682860469305387

Epoch: 6| Step: 10
Training loss: 1.0167219638824463
Validation loss: 1.7018212785003006

Epoch: 6| Step: 11
Training loss: 0.3534650206565857
Validation loss: 1.6909014050678541

Epoch: 6| Step: 12
Training loss: 0.4934421181678772
Validation loss: 1.6498085356527759

Epoch: 6| Step: 13
Training loss: 0.30642402172088623
Validation loss: 1.7130124440757177

Epoch: 558| Step: 0
Training loss: 0.7898259162902832
Validation loss: 1.669781482347878

Epoch: 6| Step: 1
Training loss: 0.8764382004737854
Validation loss: 1.6752413883004138

Epoch: 6| Step: 2
Training loss: 1.2639644145965576
Validation loss: 1.6799723576473933

Epoch: 6| Step: 3
Training loss: 0.8052913546562195
Validation loss: 1.6904459102179414

Epoch: 6| Step: 4
Training loss: 0.5557135343551636
Validation loss: 1.693751742762904

Epoch: 6| Step: 5
Training loss: 0.6316120624542236
Validation loss: 1.6832196584311865

Epoch: 6| Step: 6
Training loss: 1.4260330200195312
Validation loss: 1.7106362952980945

Epoch: 6| Step: 7
Training loss: 0.5975300073623657
Validation loss: 1.7168658523149387

Epoch: 6| Step: 8
Training loss: 0.9524975419044495
Validation loss: 1.7102502802366852

Epoch: 6| Step: 9
Training loss: 0.3468617796897888
Validation loss: 1.6951877353011922

Epoch: 6| Step: 10
Training loss: 1.0958796739578247
Validation loss: 1.7572713154618458

Epoch: 6| Step: 11
Training loss: 0.8622881174087524
Validation loss: 1.6967239136336951

Epoch: 6| Step: 12
Training loss: 0.9002576470375061
Validation loss: 1.751019512453387

Epoch: 6| Step: 13
Training loss: 0.9560133814811707
Validation loss: 1.6931517899677317

Epoch: 559| Step: 0
Training loss: 1.1415199041366577
Validation loss: 1.680524472267397

Epoch: 6| Step: 1
Training loss: 0.8131165504455566
Validation loss: 1.729154711128563

Epoch: 6| Step: 2
Training loss: 1.0721445083618164
Validation loss: 1.7412455786940872

Epoch: 6| Step: 3
Training loss: 0.8821911811828613
Validation loss: 1.6758189380809825

Epoch: 6| Step: 4
Training loss: 0.9341564178466797
Validation loss: 1.6980583155027

Epoch: 6| Step: 5
Training loss: 0.838921308517456
Validation loss: 1.6912326646107498

Epoch: 6| Step: 6
Training loss: 1.0579248666763306
Validation loss: 1.720999590812191

Epoch: 6| Step: 7
Training loss: 0.629703938961029
Validation loss: 1.7057664317469443

Epoch: 6| Step: 8
Training loss: 1.1527197360992432
Validation loss: 1.6574580733494093

Epoch: 6| Step: 9
Training loss: 0.8827404975891113
Validation loss: 1.6667594127757575

Epoch: 6| Step: 10
Training loss: 0.6604042053222656
Validation loss: 1.6480311129682808

Epoch: 6| Step: 11
Training loss: 0.6365177631378174
Validation loss: 1.6832439527716687

Epoch: 6| Step: 12
Training loss: 0.6545323133468628
Validation loss: 1.6647032563404371

Epoch: 6| Step: 13
Training loss: 1.0997540950775146
Validation loss: 1.682154752874887

Epoch: 560| Step: 0
Training loss: 0.897346019744873
Validation loss: 1.6970138421622656

Epoch: 6| Step: 1
Training loss: 0.8625349998474121
Validation loss: 1.7607956881164222

Epoch: 6| Step: 2
Training loss: 0.8473865985870361
Validation loss: 1.7377685552002282

Epoch: 6| Step: 3
Training loss: 0.7666962742805481
Validation loss: 1.6406784249890236

Epoch: 6| Step: 4
Training loss: 0.7586838006973267
Validation loss: 1.7042037235793246

Epoch: 6| Step: 5
Training loss: 0.9394519925117493
Validation loss: 1.619628055121309

Epoch: 6| Step: 6
Training loss: 0.7768716812133789
Validation loss: 1.6525977798687514

Epoch: 6| Step: 7
Training loss: 0.8476685881614685
Validation loss: 1.7086240950451101

Epoch: 6| Step: 8
Training loss: 1.339203119277954
Validation loss: 1.6664952257628083

Epoch: 6| Step: 9
Training loss: 0.8554539680480957
Validation loss: 1.6976201021543114

Epoch: 6| Step: 10
Training loss: 0.9013807773590088
Validation loss: 1.719139624667424

Epoch: 6| Step: 11
Training loss: 0.5044143199920654
Validation loss: 1.680196899239735

Epoch: 6| Step: 12
Training loss: 0.8924822807312012
Validation loss: 1.679097552453318

Epoch: 6| Step: 13
Training loss: 1.0399366617202759
Validation loss: 1.6602761309633973

Epoch: 561| Step: 0
Training loss: 0.8732151985168457
Validation loss: 1.7245462632948352

Epoch: 6| Step: 1
Training loss: 1.0746700763702393
Validation loss: 1.6754848777606923

Epoch: 6| Step: 2
Training loss: 0.5992351174354553
Validation loss: 1.691165284443927

Epoch: 6| Step: 3
Training loss: 1.139051914215088
Validation loss: 1.7117670351459133

Epoch: 6| Step: 4
Training loss: 0.9615308046340942
Validation loss: 1.686969490461452

Epoch: 6| Step: 5
Training loss: 0.6820127964019775
Validation loss: 1.67488601387188

Epoch: 6| Step: 6
Training loss: 0.8861421942710876
Validation loss: 1.7252355339706584

Epoch: 6| Step: 7
Training loss: 1.517789602279663
Validation loss: 1.6408286927848734

Epoch: 6| Step: 8
Training loss: 0.6064057946205139
Validation loss: 1.7212161133366246

Epoch: 6| Step: 9
Training loss: 0.5830278396606445
Validation loss: 1.6682142685818415

Epoch: 6| Step: 10
Training loss: 0.589858889579773
Validation loss: 1.7248758372440134

Epoch: 6| Step: 11
Training loss: 0.8322892785072327
Validation loss: 1.6926956381849063

Epoch: 6| Step: 12
Training loss: 0.6726765036582947
Validation loss: 1.656987472247052

Epoch: 6| Step: 13
Training loss: 0.9558137059211731
Validation loss: 1.6683494211525045

Epoch: 562| Step: 0
Training loss: 1.0017573833465576
Validation loss: 1.690059115809779

Epoch: 6| Step: 1
Training loss: 1.1349124908447266
Validation loss: 1.6681937017748434

Epoch: 6| Step: 2
Training loss: 1.3261055946350098
Validation loss: 1.6553506505104802

Epoch: 6| Step: 3
Training loss: 0.63019198179245
Validation loss: 1.682576048758722

Epoch: 6| Step: 4
Training loss: 0.6028625965118408
Validation loss: 1.6840540721852293

Epoch: 6| Step: 5
Training loss: 0.9296705722808838
Validation loss: 1.6561117633696525

Epoch: 6| Step: 6
Training loss: 0.6544945240020752
Validation loss: 1.6441517453039847

Epoch: 6| Step: 7
Training loss: 1.024085283279419
Validation loss: 1.649914747925215

Epoch: 6| Step: 8
Training loss: 0.7383641004562378
Validation loss: 1.703098993147573

Epoch: 6| Step: 9
Training loss: 0.8283519148826599
Validation loss: 1.692140862505923

Epoch: 6| Step: 10
Training loss: 1.1623060703277588
Validation loss: 1.6714807582157913

Epoch: 6| Step: 11
Training loss: 0.7275051474571228
Validation loss: 1.6278660605030675

Epoch: 6| Step: 12
Training loss: 0.6525984406471252
Validation loss: 1.6954372723897297

Epoch: 6| Step: 13
Training loss: 0.7484323978424072
Validation loss: 1.7010421945202736

Epoch: 563| Step: 0
Training loss: 0.8729349970817566
Validation loss: 1.7191809031271166

Epoch: 6| Step: 1
Training loss: 0.8153184652328491
Validation loss: 1.7320550898069977

Epoch: 6| Step: 2
Training loss: 0.7753251791000366
Validation loss: 1.704460346570579

Epoch: 6| Step: 3
Training loss: 0.39153051376342773
Validation loss: 1.685839763251684

Epoch: 6| Step: 4
Training loss: 0.3778780698776245
Validation loss: 1.699319927923141

Epoch: 6| Step: 5
Training loss: 1.006878137588501
Validation loss: 1.655932314934269

Epoch: 6| Step: 6
Training loss: 1.2095229625701904
Validation loss: 1.6734005994694208

Epoch: 6| Step: 7
Training loss: 1.1330281496047974
Validation loss: 1.6961517577530236

Epoch: 6| Step: 8
Training loss: 0.6977497935295105
Validation loss: 1.7172122540012482

Epoch: 6| Step: 9
Training loss: 0.6936635375022888
Validation loss: 1.6786108991151214

Epoch: 6| Step: 10
Training loss: 0.6653713583946228
Validation loss: 1.655332229470694

Epoch: 6| Step: 11
Training loss: 1.194137454032898
Validation loss: 1.675544220914123

Epoch: 6| Step: 12
Training loss: 1.228349208831787
Validation loss: 1.652489709597762

Epoch: 6| Step: 13
Training loss: 1.0071076154708862
Validation loss: 1.6786778075720674

Epoch: 564| Step: 0
Training loss: 1.1082133054733276
Validation loss: 1.6985293408875823

Epoch: 6| Step: 1
Training loss: 0.7831107974052429
Validation loss: 1.6245791771078621

Epoch: 6| Step: 2
Training loss: 0.5469775795936584
Validation loss: 1.647729258383474

Epoch: 6| Step: 3
Training loss: 0.851496160030365
Validation loss: 1.654243133401358

Epoch: 6| Step: 4
Training loss: 1.2835763692855835
Validation loss: 1.6261071171811832

Epoch: 6| Step: 5
Training loss: 0.4642307758331299
Validation loss: 1.677863791424741

Epoch: 6| Step: 6
Training loss: 0.4952623248100281
Validation loss: 1.680286701007556

Epoch: 6| Step: 7
Training loss: 0.98140949010849
Validation loss: 1.6965463302468742

Epoch: 6| Step: 8
Training loss: 1.0065655708312988
Validation loss: 1.6782562066149969

Epoch: 6| Step: 9
Training loss: 1.06783127784729
Validation loss: 1.6649839442263368

Epoch: 6| Step: 10
Training loss: 0.9255303740501404
Validation loss: 1.661291527491744

Epoch: 6| Step: 11
Training loss: 0.9614519476890564
Validation loss: 1.7119131126711447

Epoch: 6| Step: 12
Training loss: 0.7065359950065613
Validation loss: 1.742385882203297

Epoch: 6| Step: 13
Training loss: 0.40437400341033936
Validation loss: 1.7274833379253265

Epoch: 565| Step: 0
Training loss: 0.5857157707214355
Validation loss: 1.7306162272730181

Epoch: 6| Step: 1
Training loss: 0.4382946789264679
Validation loss: 1.7134383609217982

Epoch: 6| Step: 2
Training loss: 0.49829554557800293
Validation loss: 1.7159350802821498

Epoch: 6| Step: 3
Training loss: 0.9438784122467041
Validation loss: 1.731506141283179

Epoch: 6| Step: 4
Training loss: 1.0423697233200073
Validation loss: 1.7050242001010525

Epoch: 6| Step: 5
Training loss: 0.7436048984527588
Validation loss: 1.6326638037158596

Epoch: 6| Step: 6
Training loss: 0.8543715476989746
Validation loss: 1.6984140924228135

Epoch: 6| Step: 7
Training loss: 0.7938954830169678
Validation loss: 1.6606174169048187

Epoch: 6| Step: 8
Training loss: 1.3169281482696533
Validation loss: 1.722191108170376

Epoch: 6| Step: 9
Training loss: 1.0744439363479614
Validation loss: 1.6632810010704944

Epoch: 6| Step: 10
Training loss: 1.353882074356079
Validation loss: 1.6663597963189567

Epoch: 6| Step: 11
Training loss: 0.9750601053237915
Validation loss: 1.661228588832322

Epoch: 6| Step: 12
Training loss: 0.5206847786903381
Validation loss: 1.6936818938101492

Epoch: 6| Step: 13
Training loss: 0.4836990535259247
Validation loss: 1.6592678818651425

Epoch: 566| Step: 0
Training loss: 0.9137078523635864
Validation loss: 1.6937622344622048

Epoch: 6| Step: 1
Training loss: 0.8268586993217468
Validation loss: 1.7351771926367154

Epoch: 6| Step: 2
Training loss: 0.9546149969100952
Validation loss: 1.6841959658489432

Epoch: 6| Step: 3
Training loss: 0.7261629104614258
Validation loss: 1.7074470340564687

Epoch: 6| Step: 4
Training loss: 0.8933401703834534
Validation loss: 1.7021462571236394

Epoch: 6| Step: 5
Training loss: 0.41811954975128174
Validation loss: 1.6605610539836269

Epoch: 6| Step: 6
Training loss: 0.8376216888427734
Validation loss: 1.7005897875755065

Epoch: 6| Step: 7
Training loss: 0.31834420561790466
Validation loss: 1.744073829343242

Epoch: 6| Step: 8
Training loss: 0.7983870506286621
Validation loss: 1.6937971884204495

Epoch: 6| Step: 9
Training loss: 1.1604281663894653
Validation loss: 1.7035937219537713

Epoch: 6| Step: 10
Training loss: 1.3787143230438232
Validation loss: 1.763246665718735

Epoch: 6| Step: 11
Training loss: 0.650327742099762
Validation loss: 1.734015800619638

Epoch: 6| Step: 12
Training loss: 0.9323053359985352
Validation loss: 1.6814054712172477

Epoch: 6| Step: 13
Training loss: 0.8444802761077881
Validation loss: 1.702006252863074

Epoch: 567| Step: 0
Training loss: 0.5982850790023804
Validation loss: 1.7063126935753772

Epoch: 6| Step: 1
Training loss: 1.0779454708099365
Validation loss: 1.6961177113235637

Epoch: 6| Step: 2
Training loss: 1.325472116470337
Validation loss: 1.7121602553193287

Epoch: 6| Step: 3
Training loss: 0.5401360988616943
Validation loss: 1.6324310738553283

Epoch: 6| Step: 4
Training loss: 0.8544713854789734
Validation loss: 1.6401654315251175

Epoch: 6| Step: 5
Training loss: 0.6668475866317749
Validation loss: 1.6713636126569522

Epoch: 6| Step: 6
Training loss: 0.8140178918838501
Validation loss: 1.702178116767637

Epoch: 6| Step: 7
Training loss: 1.2444607019424438
Validation loss: 1.6478702201638171

Epoch: 6| Step: 8
Training loss: 0.5731289386749268
Validation loss: 1.688332051359197

Epoch: 6| Step: 9
Training loss: 0.9576686024665833
Validation loss: 1.6300304653824016

Epoch: 6| Step: 10
Training loss: 0.7254254817962646
Validation loss: 1.6689894968463528

Epoch: 6| Step: 11
Training loss: 1.1295671463012695
Validation loss: 1.676859696706136

Epoch: 6| Step: 12
Training loss: 1.2065212726593018
Validation loss: 1.689612155319542

Epoch: 6| Step: 13
Training loss: 0.2848908603191376
Validation loss: 1.6465426542425667

Epoch: 568| Step: 0
Training loss: 1.0518025159835815
Validation loss: 1.7127259738983647

Epoch: 6| Step: 1
Training loss: 0.5605146288871765
Validation loss: 1.6593289516305412

Epoch: 6| Step: 2
Training loss: 1.0125510692596436
Validation loss: 1.7122480837247704

Epoch: 6| Step: 3
Training loss: 0.6790775060653687
Validation loss: 1.7232886668174499

Epoch: 6| Step: 4
Training loss: 0.496060311794281
Validation loss: 1.7191418870802848

Epoch: 6| Step: 5
Training loss: 0.7453170418739319
Validation loss: 1.715021555141736

Epoch: 6| Step: 6
Training loss: 0.9135396480560303
Validation loss: 1.707432380286596

Epoch: 6| Step: 7
Training loss: 0.6792910099029541
Validation loss: 1.7197116523660638

Epoch: 6| Step: 8
Training loss: 0.6121994853019714
Validation loss: 1.7510912636274933

Epoch: 6| Step: 9
Training loss: 1.1870388984680176
Validation loss: 1.737567884947664

Epoch: 6| Step: 10
Training loss: 1.2857344150543213
Validation loss: 1.7150990886072959

Epoch: 6| Step: 11
Training loss: 0.631189227104187
Validation loss: 1.7162291055084558

Epoch: 6| Step: 12
Training loss: 0.9562813639640808
Validation loss: 1.7239825315372919

Epoch: 6| Step: 13
Training loss: 1.7614549398422241
Validation loss: 1.6495739689437292

Epoch: 569| Step: 0
Training loss: 0.7621544003486633
Validation loss: 1.7000418427169963

Epoch: 6| Step: 1
Training loss: 0.5887171030044556
Validation loss: 1.6639158571920087

Epoch: 6| Step: 2
Training loss: 1.0673542022705078
Validation loss: 1.6654983669198968

Epoch: 6| Step: 3
Training loss: 0.8316134214401245
Validation loss: 1.6787840884218934

Epoch: 6| Step: 4
Training loss: 0.7784628868103027
Validation loss: 1.686677453338459

Epoch: 6| Step: 5
Training loss: 0.7234327793121338
Validation loss: 1.695914832494592

Epoch: 6| Step: 6
Training loss: 0.6245865225791931
Validation loss: 1.7043462402077132

Epoch: 6| Step: 7
Training loss: 0.8259297013282776
Validation loss: 1.7217085976754465

Epoch: 6| Step: 8
Training loss: 0.7209385633468628
Validation loss: 1.6824579302982619

Epoch: 6| Step: 9
Training loss: 1.0814911127090454
Validation loss: 1.7077582715660014

Epoch: 6| Step: 10
Training loss: 0.9048206806182861
Validation loss: 1.6835028458667058

Epoch: 6| Step: 11
Training loss: 0.6414430737495422
Validation loss: 1.7007254964561873

Epoch: 6| Step: 12
Training loss: 0.7557424306869507
Validation loss: 1.7064214252656507

Epoch: 6| Step: 13
Training loss: 1.0594850778579712
Validation loss: 1.6893224831550353

Epoch: 570| Step: 0
Training loss: 0.6830893158912659
Validation loss: 1.7388613890576106

Epoch: 6| Step: 1
Training loss: 0.7252110242843628
Validation loss: 1.7158268138926516

Epoch: 6| Step: 2
Training loss: 0.5726462602615356
Validation loss: 1.714480791040646

Epoch: 6| Step: 3
Training loss: 1.3923850059509277
Validation loss: 1.6989925753685735

Epoch: 6| Step: 4
Training loss: 0.7621678113937378
Validation loss: 1.7396584813312819

Epoch: 6| Step: 5
Training loss: 0.7013822793960571
Validation loss: 1.6930705385823404

Epoch: 6| Step: 6
Training loss: 0.917248010635376
Validation loss: 1.6622811030316096

Epoch: 6| Step: 7
Training loss: 0.9429240822792053
Validation loss: 1.7175468347405876

Epoch: 6| Step: 8
Training loss: 0.8582622408866882
Validation loss: 1.6781498245013657

Epoch: 6| Step: 9
Training loss: 0.760200560092926
Validation loss: 1.7067621946334839

Epoch: 6| Step: 10
Training loss: 0.8877004384994507
Validation loss: 1.7161274058844453

Epoch: 6| Step: 11
Training loss: 0.8016420006752014
Validation loss: 1.6983687006017214

Epoch: 6| Step: 12
Training loss: 1.0894310474395752
Validation loss: 1.6739357081792687

Epoch: 6| Step: 13
Training loss: 0.8301879167556763
Validation loss: 1.6819801458748438

Epoch: 571| Step: 0
Training loss: 1.0282175540924072
Validation loss: 1.6572344995314074

Epoch: 6| Step: 1
Training loss: 0.8890657424926758
Validation loss: 1.6914639037142518

Epoch: 6| Step: 2
Training loss: 1.213935375213623
Validation loss: 1.65059325515583

Epoch: 6| Step: 3
Training loss: 1.0560039281845093
Validation loss: 1.7279991513939315

Epoch: 6| Step: 4
Training loss: 0.980992317199707
Validation loss: 1.6955092299369074

Epoch: 6| Step: 5
Training loss: 0.9549815654754639
Validation loss: 1.6772131086677633

Epoch: 6| Step: 6
Training loss: 0.7428174018859863
Validation loss: 1.6813905213468818

Epoch: 6| Step: 7
Training loss: 0.6166061162948608
Validation loss: 1.683845712292579

Epoch: 6| Step: 8
Training loss: 0.47686928510665894
Validation loss: 1.68483857698338

Epoch: 6| Step: 9
Training loss: 0.4797673523426056
Validation loss: 1.7310639350645003

Epoch: 6| Step: 10
Training loss: 0.6663320660591125
Validation loss: 1.741315596847124

Epoch: 6| Step: 11
Training loss: 1.1642073392868042
Validation loss: 1.6594864873475925

Epoch: 6| Step: 12
Training loss: 0.8898253440856934
Validation loss: 1.6968066000169324

Epoch: 6| Step: 13
Training loss: 1.409298300743103
Validation loss: 1.7175008302093835

Epoch: 572| Step: 0
Training loss: 0.8484984040260315
Validation loss: 1.629487483732162

Epoch: 6| Step: 1
Training loss: 0.9073364734649658
Validation loss: 1.6907970290030203

Epoch: 6| Step: 2
Training loss: 0.543183445930481
Validation loss: 1.6882035411814207

Epoch: 6| Step: 3
Training loss: 1.0473084449768066
Validation loss: 1.7111698241644009

Epoch: 6| Step: 4
Training loss: 1.253920078277588
Validation loss: 1.701301699043602

Epoch: 6| Step: 5
Training loss: 0.915316104888916
Validation loss: 1.6610443694617159

Epoch: 6| Step: 6
Training loss: 0.7721896171569824
Validation loss: 1.652955016782207

Epoch: 6| Step: 7
Training loss: 0.989692211151123
Validation loss: 1.6626213109621437

Epoch: 6| Step: 8
Training loss: 0.4991847276687622
Validation loss: 1.714666981850901

Epoch: 6| Step: 9
Training loss: 0.6144787073135376
Validation loss: 1.665085106767634

Epoch: 6| Step: 10
Training loss: 1.2276455163955688
Validation loss: 1.687984102515764

Epoch: 6| Step: 11
Training loss: 0.6328383684158325
Validation loss: 1.6837969313385666

Epoch: 6| Step: 12
Training loss: 0.9748736619949341
Validation loss: 1.7476267224998885

Epoch: 6| Step: 13
Training loss: 0.8002005815505981
Validation loss: 1.7004839784355574

Epoch: 573| Step: 0
Training loss: 0.7269618511199951
Validation loss: 1.6573949090896114

Epoch: 6| Step: 1
Training loss: 0.3253709673881531
Validation loss: 1.6940887769063313

Epoch: 6| Step: 2
Training loss: 0.7223300933837891
Validation loss: 1.7037275222039991

Epoch: 6| Step: 3
Training loss: 0.5351492166519165
Validation loss: 1.6945647026902886

Epoch: 6| Step: 4
Training loss: 0.9345765113830566
Validation loss: 1.6964300370985461

Epoch: 6| Step: 5
Training loss: 1.3646724224090576
Validation loss: 1.7205369126412176

Epoch: 6| Step: 6
Training loss: 0.6249390840530396
Validation loss: 1.710882693208674

Epoch: 6| Step: 7
Training loss: 1.3206017017364502
Validation loss: 1.7446463338790401

Epoch: 6| Step: 8
Training loss: 0.5922240018844604
Validation loss: 1.6618940099593131

Epoch: 6| Step: 9
Training loss: 0.7252987623214722
Validation loss: 1.6552592105762933

Epoch: 6| Step: 10
Training loss: 0.6955806016921997
Validation loss: 1.6897030825256019

Epoch: 6| Step: 11
Training loss: 0.7897249460220337
Validation loss: 1.6859201385128884

Epoch: 6| Step: 12
Training loss: 1.4475011825561523
Validation loss: 1.7116426191022318

Epoch: 6| Step: 13
Training loss: 0.7710472345352173
Validation loss: 1.6770034028637795

Epoch: 574| Step: 0
Training loss: 0.4815511107444763
Validation loss: 1.7028916856294036

Epoch: 6| Step: 1
Training loss: 1.413535714149475
Validation loss: 1.7010364904198596

Epoch: 6| Step: 2
Training loss: 0.9685065746307373
Validation loss: 1.7117309429312264

Epoch: 6| Step: 3
Training loss: 1.1997250318527222
Validation loss: 1.6738614805283085

Epoch: 6| Step: 4
Training loss: 0.9603959321975708
Validation loss: 1.734338000256528

Epoch: 6| Step: 5
Training loss: 0.8113364577293396
Validation loss: 1.6578540186728201

Epoch: 6| Step: 6
Training loss: 0.5448311567306519
Validation loss: 1.676245968828919

Epoch: 6| Step: 7
Training loss: 0.6772617101669312
Validation loss: 1.6527885506230016

Epoch: 6| Step: 8
Training loss: 0.8180686831474304
Validation loss: 1.6624343446505967

Epoch: 6| Step: 9
Training loss: 0.40634334087371826
Validation loss: 1.6273636779477518

Epoch: 6| Step: 10
Training loss: 1.0615589618682861
Validation loss: 1.6641312459463715

Epoch: 6| Step: 11
Training loss: 0.6924622058868408
Validation loss: 1.7024999023765646

Epoch: 6| Step: 12
Training loss: 1.027003288269043
Validation loss: 1.68901817388432

Epoch: 6| Step: 13
Training loss: 0.6732255220413208
Validation loss: 1.727277014845161

Epoch: 575| Step: 0
Training loss: 0.8692309260368347
Validation loss: 1.7213866223571122

Epoch: 6| Step: 1
Training loss: 0.7867087125778198
Validation loss: 1.6894428108328132

Epoch: 6| Step: 2
Training loss: 0.4104284644126892
Validation loss: 1.7183717643060992

Epoch: 6| Step: 3
Training loss: 0.8676425218582153
Validation loss: 1.7055861296192292

Epoch: 6| Step: 4
Training loss: 0.6575855016708374
Validation loss: 1.7239152077705628

Epoch: 6| Step: 5
Training loss: 0.6152846217155457
Validation loss: 1.697471584043195

Epoch: 6| Step: 6
Training loss: 0.680507481098175
Validation loss: 1.6829527103772728

Epoch: 6| Step: 7
Training loss: 0.9620832800865173
Validation loss: 1.7388831069392543

Epoch: 6| Step: 8
Training loss: 1.4765472412109375
Validation loss: 1.7578164851793678

Epoch: 6| Step: 9
Training loss: 0.600766658782959
Validation loss: 1.7196742783310592

Epoch: 6| Step: 10
Training loss: 1.0156865119934082
Validation loss: 1.7093783386291996

Epoch: 6| Step: 11
Training loss: 0.8634355068206787
Validation loss: 1.6725367666572653

Epoch: 6| Step: 12
Training loss: 1.1030075550079346
Validation loss: 1.7434452272230578

Epoch: 6| Step: 13
Training loss: 1.1478488445281982
Validation loss: 1.674468755722046

Epoch: 576| Step: 0
Training loss: 0.9775867462158203
Validation loss: 1.747561122781487

Epoch: 6| Step: 1
Training loss: 0.825838565826416
Validation loss: 1.721105191015428

Epoch: 6| Step: 2
Training loss: 0.2923416495323181
Validation loss: 1.6853777208635885

Epoch: 6| Step: 3
Training loss: 0.9389089345932007
Validation loss: 1.7297137347600793

Epoch: 6| Step: 4
Training loss: 1.2182351350784302
Validation loss: 1.6736915380724016

Epoch: 6| Step: 5
Training loss: 0.5351898670196533
Validation loss: 1.6728446522066671

Epoch: 6| Step: 6
Training loss: 1.2754852771759033
Validation loss: 1.6650550365447998

Epoch: 6| Step: 7
Training loss: 0.7589998245239258
Validation loss: 1.6744960854130406

Epoch: 6| Step: 8
Training loss: 0.8595974445343018
Validation loss: 1.7005357357763475

Epoch: 6| Step: 9
Training loss: 0.658828616142273
Validation loss: 1.6565711472624092

Epoch: 6| Step: 10
Training loss: 0.9264638423919678
Validation loss: 1.6717846201312156

Epoch: 6| Step: 11
Training loss: 0.6662669777870178
Validation loss: 1.6541721769558486

Epoch: 6| Step: 12
Training loss: 0.9001202583312988
Validation loss: 1.712205861204414

Epoch: 6| Step: 13
Training loss: 0.7010722160339355
Validation loss: 1.68776782097355

Epoch: 577| Step: 0
Training loss: 0.893602728843689
Validation loss: 1.717833133154018

Epoch: 6| Step: 1
Training loss: 0.6844249963760376
Validation loss: 1.7210887414152904

Epoch: 6| Step: 2
Training loss: 0.8477641344070435
Validation loss: 1.7063263641890658

Epoch: 6| Step: 3
Training loss: 0.8889248967170715
Validation loss: 1.7709905575680476

Epoch: 6| Step: 4
Training loss: 0.5752246379852295
Validation loss: 1.7215132803045294

Epoch: 6| Step: 5
Training loss: 0.5879819393157959
Validation loss: 1.6651853745983494

Epoch: 6| Step: 6
Training loss: 1.4237122535705566
Validation loss: 1.7020168471080002

Epoch: 6| Step: 7
Training loss: 1.0302448272705078
Validation loss: 1.6825928816231348

Epoch: 6| Step: 8
Training loss: 0.7719523906707764
Validation loss: 1.656537248242286

Epoch: 6| Step: 9
Training loss: 0.7410672903060913
Validation loss: 1.6994275098205895

Epoch: 6| Step: 10
Training loss: 0.6974253058433533
Validation loss: 1.6136483441116989

Epoch: 6| Step: 11
Training loss: 0.648686408996582
Validation loss: 1.6742904378521828

Epoch: 6| Step: 12
Training loss: 0.8775426149368286
Validation loss: 1.658581373512104

Epoch: 6| Step: 13
Training loss: 1.1934053897857666
Validation loss: 1.7038582999219176

Epoch: 578| Step: 0
Training loss: 0.662703275680542
Validation loss: 1.6767127718976749

Epoch: 6| Step: 1
Training loss: 0.8313009142875671
Validation loss: 1.7178911214233727

Epoch: 6| Step: 2
Training loss: 1.2526636123657227
Validation loss: 1.6900961873351887

Epoch: 6| Step: 3
Training loss: 0.39105069637298584
Validation loss: 1.6643896154178086

Epoch: 6| Step: 4
Training loss: 0.8901692628860474
Validation loss: 1.7083536348035258

Epoch: 6| Step: 5
Training loss: 0.4752626121044159
Validation loss: 1.728653794975691

Epoch: 6| Step: 6
Training loss: 0.7945263385772705
Validation loss: 1.7266168030359412

Epoch: 6| Step: 7
Training loss: 1.0506339073181152
Validation loss: 1.7513389869402813

Epoch: 6| Step: 8
Training loss: 0.7067720293998718
Validation loss: 1.7795059142574188

Epoch: 6| Step: 9
Training loss: 0.7802269458770752
Validation loss: 1.727913241232595

Epoch: 6| Step: 10
Training loss: 0.8320424556732178
Validation loss: 1.7339489690719112

Epoch: 6| Step: 11
Training loss: 1.4120538234710693
Validation loss: 1.7411285523445375

Epoch: 6| Step: 12
Training loss: 0.7528167366981506
Validation loss: 1.7009839985960273

Epoch: 6| Step: 13
Training loss: 1.0485126972198486
Validation loss: 1.7040588048196608

Epoch: 579| Step: 0
Training loss: 0.37402766942977905
Validation loss: 1.7114618978192728

Epoch: 6| Step: 1
Training loss: 0.6347559690475464
Validation loss: 1.7545943170465448

Epoch: 6| Step: 2
Training loss: 1.2613779306411743
Validation loss: 1.7274588282390306

Epoch: 6| Step: 3
Training loss: 1.1941230297088623
Validation loss: 1.6777879743165867

Epoch: 6| Step: 4
Training loss: 0.8979555368423462
Validation loss: 1.6612056839850642

Epoch: 6| Step: 5
Training loss: 0.8126139640808105
Validation loss: 1.7220033189301849

Epoch: 6| Step: 6
Training loss: 0.7077641487121582
Validation loss: 1.6756614908095329

Epoch: 6| Step: 7
Training loss: 0.9666502475738525
Validation loss: 1.702191738672154

Epoch: 6| Step: 8
Training loss: 0.9282472133636475
Validation loss: 1.6815512539238058

Epoch: 6| Step: 9
Training loss: 0.8318613171577454
Validation loss: 1.6640504393526303

Epoch: 6| Step: 10
Training loss: 0.6134641170501709
Validation loss: 1.6812655297658776

Epoch: 6| Step: 11
Training loss: 0.7378544807434082
Validation loss: 1.6700940747414865

Epoch: 6| Step: 12
Training loss: 0.7024905681610107
Validation loss: 1.6770755860113329

Epoch: 6| Step: 13
Training loss: 0.44558075070381165
Validation loss: 1.6658798404919204

Epoch: 580| Step: 0
Training loss: 0.9560118913650513
Validation loss: 1.6929042185506513

Epoch: 6| Step: 1
Training loss: 1.1156702041625977
Validation loss: 1.6807682693645518

Epoch: 6| Step: 2
Training loss: 1.2843666076660156
Validation loss: 1.6951973874081847

Epoch: 6| Step: 3
Training loss: 0.7806930541992188
Validation loss: 1.6905949167025986

Epoch: 6| Step: 4
Training loss: 0.37913596630096436
Validation loss: 1.683325900826403

Epoch: 6| Step: 5
Training loss: 0.8248081207275391
Validation loss: 1.6887940027380501

Epoch: 6| Step: 6
Training loss: 0.6716340184211731
Validation loss: 1.6486234434189335

Epoch: 6| Step: 7
Training loss: 0.49055173993110657
Validation loss: 1.620401539469278

Epoch: 6| Step: 8
Training loss: 0.9605934619903564
Validation loss: 1.6653457662110687

Epoch: 6| Step: 9
Training loss: 1.420823097229004
Validation loss: 1.7376467104881042

Epoch: 6| Step: 10
Training loss: 0.5850456357002258
Validation loss: 1.7057863717438073

Epoch: 6| Step: 11
Training loss: 0.6383853554725647
Validation loss: 1.6672128669677242

Epoch: 6| Step: 12
Training loss: 0.4533692002296448
Validation loss: 1.6418496998407508

Epoch: 6| Step: 13
Training loss: 0.8669052124023438
Validation loss: 1.7077204130029167

Epoch: 581| Step: 0
Training loss: 0.9578498601913452
Validation loss: 1.700338106001577

Epoch: 6| Step: 1
Training loss: 0.4819355010986328
Validation loss: 1.690989314868886

Epoch: 6| Step: 2
Training loss: 0.6834784746170044
Validation loss: 1.7561321296999532

Epoch: 6| Step: 3
Training loss: 0.42097821831703186
Validation loss: 1.7468961438825052

Epoch: 6| Step: 4
Training loss: 0.5738992691040039
Validation loss: 1.740888839126915

Epoch: 6| Step: 5
Training loss: 0.7254724502563477
Validation loss: 1.756693781063121

Epoch: 6| Step: 6
Training loss: 0.641055166721344
Validation loss: 1.7414245784923594

Epoch: 6| Step: 7
Training loss: 1.6279289722442627
Validation loss: 1.739852528418264

Epoch: 6| Step: 8
Training loss: 0.9526225924491882
Validation loss: 1.6839446739483905

Epoch: 6| Step: 9
Training loss: 1.0083116292953491
Validation loss: 1.6548332975756737

Epoch: 6| Step: 10
Training loss: 1.1070693731307983
Validation loss: 1.7136583776884182

Epoch: 6| Step: 11
Training loss: 0.8311419486999512
Validation loss: 1.681270859574759

Epoch: 6| Step: 12
Training loss: 0.6505355834960938
Validation loss: 1.696218075290803

Epoch: 6| Step: 13
Training loss: 0.6141353845596313
Validation loss: 1.6961839519521242

Epoch: 582| Step: 0
Training loss: 0.9532049894332886
Validation loss: 1.6700024758615801

Epoch: 6| Step: 1
Training loss: 0.9276814460754395
Validation loss: 1.6376706938589773

Epoch: 6| Step: 2
Training loss: 0.6286797523498535
Validation loss: 1.6374115431180565

Epoch: 6| Step: 3
Training loss: 0.6580359935760498
Validation loss: 1.6503134786441762

Epoch: 6| Step: 4
Training loss: 0.7397604584693909
Validation loss: 1.639563468194777

Epoch: 6| Step: 5
Training loss: 0.8066884279251099
Validation loss: 1.6944420645313878

Epoch: 6| Step: 6
Training loss: 0.893897294998169
Validation loss: 1.7023866227878037

Epoch: 6| Step: 7
Training loss: 0.588634192943573
Validation loss: 1.7369123671644477

Epoch: 6| Step: 8
Training loss: 0.8120669722557068
Validation loss: 1.67294567631137

Epoch: 6| Step: 9
Training loss: 1.028357744216919
Validation loss: 1.6975441940369145

Epoch: 6| Step: 10
Training loss: 1.0475777387619019
Validation loss: 1.7162172537977978

Epoch: 6| Step: 11
Training loss: 0.8565806746482849
Validation loss: 1.6744309138226252

Epoch: 6| Step: 12
Training loss: 0.45673495531082153
Validation loss: 1.6671000513979184

Epoch: 6| Step: 13
Training loss: 1.299489140510559
Validation loss: 1.6481379988372966

Epoch: 583| Step: 0
Training loss: 0.3839997947216034
Validation loss: 1.679751109051448

Epoch: 6| Step: 1
Training loss: 1.03721022605896
Validation loss: 1.6591592963023851

Epoch: 6| Step: 2
Training loss: 0.7006452083587646
Validation loss: 1.660566117173882

Epoch: 6| Step: 3
Training loss: 0.4270502030849457
Validation loss: 1.688897914783929

Epoch: 6| Step: 4
Training loss: 1.121793508529663
Validation loss: 1.7029034168489519

Epoch: 6| Step: 5
Training loss: 0.8822005987167358
Validation loss: 1.6574759021882088

Epoch: 6| Step: 6
Training loss: 0.46140122413635254
Validation loss: 1.6485083013452508

Epoch: 6| Step: 7
Training loss: 0.9107980728149414
Validation loss: 1.6865927685973465

Epoch: 6| Step: 8
Training loss: 0.8157123327255249
Validation loss: 1.6758566979439027

Epoch: 6| Step: 9
Training loss: 0.8926881551742554
Validation loss: 1.6500037652190014

Epoch: 6| Step: 10
Training loss: 1.3254015445709229
Validation loss: 1.6513080981469923

Epoch: 6| Step: 11
Training loss: 0.844959020614624
Validation loss: 1.6526912822518298

Epoch: 6| Step: 12
Training loss: 1.09357750415802
Validation loss: 1.68336909432565

Epoch: 6| Step: 13
Training loss: 0.32943904399871826
Validation loss: 1.6606423265190535

Epoch: 584| Step: 0
Training loss: 0.3798675537109375
Validation loss: 1.6951925370001024

Epoch: 6| Step: 1
Training loss: 0.7907456159591675
Validation loss: 1.7550506822524532

Epoch: 6| Step: 2
Training loss: 1.0566086769104004
Validation loss: 1.6624715533307803

Epoch: 6| Step: 3
Training loss: 0.6428999900817871
Validation loss: 1.7056137361834127

Epoch: 6| Step: 4
Training loss: 0.5018367171287537
Validation loss: 1.7112031495699318

Epoch: 6| Step: 5
Training loss: 0.6977193355560303
Validation loss: 1.7531788092787548

Epoch: 6| Step: 6
Training loss: 1.0989068746566772
Validation loss: 1.7146613405596824

Epoch: 6| Step: 7
Training loss: 0.6045879125595093
Validation loss: 1.6404934788262973

Epoch: 6| Step: 8
Training loss: 0.904083251953125
Validation loss: 1.74104473539578

Epoch: 6| Step: 9
Training loss: 1.0660145282745361
Validation loss: 1.6361394518165178

Epoch: 6| Step: 10
Training loss: 0.7718533873558044
Validation loss: 1.7184770632815618

Epoch: 6| Step: 11
Training loss: 1.1049392223358154
Validation loss: 1.6877195514658445

Epoch: 6| Step: 12
Training loss: 0.7323187589645386
Validation loss: 1.715681584932471

Epoch: 6| Step: 13
Training loss: 1.0453566312789917
Validation loss: 1.6742973302000312

Epoch: 585| Step: 0
Training loss: 1.2277915477752686
Validation loss: 1.7053614213902464

Epoch: 6| Step: 1
Training loss: 0.8191788792610168
Validation loss: 1.6835079026478592

Epoch: 6| Step: 2
Training loss: 1.1228643655776978
Validation loss: 1.7391221049011394

Epoch: 6| Step: 3
Training loss: 0.6408818364143372
Validation loss: 1.6685735294895787

Epoch: 6| Step: 4
Training loss: 0.8567575812339783
Validation loss: 1.6081346939968806

Epoch: 6| Step: 5
Training loss: 0.5490490794181824
Validation loss: 1.7185362949166247

Epoch: 6| Step: 6
Training loss: 0.5134389400482178
Validation loss: 1.7391394927937498

Epoch: 6| Step: 7
Training loss: 0.7313178777694702
Validation loss: 1.656980787554095

Epoch: 6| Step: 8
Training loss: 1.0506150722503662
Validation loss: 1.7118395451576478

Epoch: 6| Step: 9
Training loss: 1.073421597480774
Validation loss: 1.7160912329150784

Epoch: 6| Step: 10
Training loss: 0.7172626256942749
Validation loss: 1.6636168854210966

Epoch: 6| Step: 11
Training loss: 0.5340445041656494
Validation loss: 1.6695136511197655

Epoch: 6| Step: 12
Training loss: 0.3467353582382202
Validation loss: 1.632013299131906

Epoch: 6| Step: 13
Training loss: 1.014782428741455
Validation loss: 1.6393286528125885

Epoch: 586| Step: 0
Training loss: 0.9738495349884033
Validation loss: 1.6999001868309513

Epoch: 6| Step: 1
Training loss: 0.627147376537323
Validation loss: 1.7498362371998448

Epoch: 6| Step: 2
Training loss: 0.7375809550285339
Validation loss: 1.6715997508777085

Epoch: 6| Step: 3
Training loss: 0.44791072607040405
Validation loss: 1.68078451900072

Epoch: 6| Step: 4
Training loss: 0.3957221210002899
Validation loss: 1.6731987794240315

Epoch: 6| Step: 5
Training loss: 0.8106594085693359
Validation loss: 1.6677542207061604

Epoch: 6| Step: 6
Training loss: 0.9671724438667297
Validation loss: 1.7089374731945735

Epoch: 6| Step: 7
Training loss: 0.89258873462677
Validation loss: 1.6839152702721216

Epoch: 6| Step: 8
Training loss: 0.4655247926712036
Validation loss: 1.7048392090746152

Epoch: 6| Step: 9
Training loss: 1.0000706911087036
Validation loss: 1.7010754680120816

Epoch: 6| Step: 10
Training loss: 1.122066617012024
Validation loss: 1.7231064996411722

Epoch: 6| Step: 11
Training loss: 0.6697870492935181
Validation loss: 1.6919222544598322

Epoch: 6| Step: 12
Training loss: 0.8992093205451965
Validation loss: 1.661999257661963

Epoch: 6| Step: 13
Training loss: 1.463202953338623
Validation loss: 1.7169531160785305

Epoch: 587| Step: 0
Training loss: 0.7457197904586792
Validation loss: 1.645552586483699

Epoch: 6| Step: 1
Training loss: 0.7430830001831055
Validation loss: 1.6180535388249222

Epoch: 6| Step: 2
Training loss: 0.8663069605827332
Validation loss: 1.6544054759446012

Epoch: 6| Step: 3
Training loss: 0.7115192413330078
Validation loss: 1.711912929370839

Epoch: 6| Step: 4
Training loss: 1.0887181758880615
Validation loss: 1.6463841469057146

Epoch: 6| Step: 5
Training loss: 0.6695246696472168
Validation loss: 1.6838788024840816

Epoch: 6| Step: 6
Training loss: 0.38458484411239624
Validation loss: 1.7073323816381476

Epoch: 6| Step: 7
Training loss: 0.9241548776626587
Validation loss: 1.692947503059141

Epoch: 6| Step: 8
Training loss: 0.7047091722488403
Validation loss: 1.6501592615599274

Epoch: 6| Step: 9
Training loss: 1.013081431388855
Validation loss: 1.712076961353261

Epoch: 6| Step: 10
Training loss: 1.4061108827590942
Validation loss: 1.726828109833502

Epoch: 6| Step: 11
Training loss: 0.9068900942802429
Validation loss: 1.7726287611069218

Epoch: 6| Step: 12
Training loss: 0.49733126163482666
Validation loss: 1.7475951051199308

Epoch: 6| Step: 13
Training loss: 0.4794178009033203
Validation loss: 1.7514095370487501

Epoch: 588| Step: 0
Training loss: 1.0502309799194336
Validation loss: 1.7444664662884128

Epoch: 6| Step: 1
Training loss: 0.4646685719490051
Validation loss: 1.7342878528820571

Epoch: 6| Step: 2
Training loss: 1.242469072341919
Validation loss: 1.7226986500524706

Epoch: 6| Step: 3
Training loss: 0.7360219359397888
Validation loss: 1.7135805827315136

Epoch: 6| Step: 4
Training loss: 0.474550724029541
Validation loss: 1.702376639971169

Epoch: 6| Step: 5
Training loss: 0.6783467531204224
Validation loss: 1.71204706545799

Epoch: 6| Step: 6
Training loss: 0.9857145547866821
Validation loss: 1.6533532129820956

Epoch: 6| Step: 7
Training loss: 0.6061782240867615
Validation loss: 1.6965509819728073

Epoch: 6| Step: 8
Training loss: 0.4961422383785248
Validation loss: 1.6900996636318903

Epoch: 6| Step: 9
Training loss: 0.8130253553390503
Validation loss: 1.662999055718863

Epoch: 6| Step: 10
Training loss: 0.999672532081604
Validation loss: 1.673049275593091

Epoch: 6| Step: 11
Training loss: 0.6882701516151428
Validation loss: 1.6731324900862992

Epoch: 6| Step: 12
Training loss: 1.4550319910049438
Validation loss: 1.7001305664739301

Epoch: 6| Step: 13
Training loss: 0.33375561237335205
Validation loss: 1.6690020650945685

Epoch: 589| Step: 0
Training loss: 1.0653047561645508
Validation loss: 1.70501648482456

Epoch: 6| Step: 1
Training loss: 1.0132453441619873
Validation loss: 1.6837917450935609

Epoch: 6| Step: 2
Training loss: 0.42268553376197815
Validation loss: 1.67415819116818

Epoch: 6| Step: 3
Training loss: 0.46101152896881104
Validation loss: 1.6697264986653482

Epoch: 6| Step: 4
Training loss: 0.5891063213348389
Validation loss: 1.674743413925171

Epoch: 6| Step: 5
Training loss: 0.35078561305999756
Validation loss: 1.7060255183968493

Epoch: 6| Step: 6
Training loss: 0.5839171409606934
Validation loss: 1.603496859150548

Epoch: 6| Step: 7
Training loss: 0.6771121025085449
Validation loss: 1.65694256495404

Epoch: 6| Step: 8
Training loss: 1.1351367235183716
Validation loss: 1.6487278848566034

Epoch: 6| Step: 9
Training loss: 1.026149034500122
Validation loss: 1.6871718898896249

Epoch: 6| Step: 10
Training loss: 0.7038239240646362
Validation loss: 1.6432290615574006

Epoch: 6| Step: 11
Training loss: 1.120543122291565
Validation loss: 1.6601354114470943

Epoch: 6| Step: 12
Training loss: 1.0780653953552246
Validation loss: 1.6958461487165062

Epoch: 6| Step: 13
Training loss: 1.2083771228790283
Validation loss: 1.6710649369865336

Epoch: 590| Step: 0
Training loss: 1.3301767110824585
Validation loss: 1.6919805683115476

Epoch: 6| Step: 1
Training loss: 0.6061214804649353
Validation loss: 1.6493406616231447

Epoch: 6| Step: 2
Training loss: 1.0080691576004028
Validation loss: 1.665671016580315

Epoch: 6| Step: 3
Training loss: 0.4504643678665161
Validation loss: 1.6695888901269564

Epoch: 6| Step: 4
Training loss: 1.455381155014038
Validation loss: 1.709331290696257

Epoch: 6| Step: 5
Training loss: 0.4977383017539978
Validation loss: 1.686159069820117

Epoch: 6| Step: 6
Training loss: 0.8213749527931213
Validation loss: 1.6657190874058714

Epoch: 6| Step: 7
Training loss: 0.6294081807136536
Validation loss: 1.6849237718889791

Epoch: 6| Step: 8
Training loss: 0.4493718147277832
Validation loss: 1.692956457855881

Epoch: 6| Step: 9
Training loss: 0.5900506973266602
Validation loss: 1.6787947185577885

Epoch: 6| Step: 10
Training loss: 0.895810604095459
Validation loss: 1.665158482008083

Epoch: 6| Step: 11
Training loss: 0.5071660280227661
Validation loss: 1.6919918393576017

Epoch: 6| Step: 12
Training loss: 0.8793546557426453
Validation loss: 1.7242843104946999

Epoch: 6| Step: 13
Training loss: 0.877315878868103
Validation loss: 1.7087849404222222

Epoch: 591| Step: 0
Training loss: 0.5373213291168213
Validation loss: 1.693080331689568

Epoch: 6| Step: 1
Training loss: 0.5535169839859009
Validation loss: 1.6927940345579577

Epoch: 6| Step: 2
Training loss: 1.5090211629867554
Validation loss: 1.6560591241364837

Epoch: 6| Step: 3
Training loss: 0.36845046281814575
Validation loss: 1.6906579617531068

Epoch: 6| Step: 4
Training loss: 0.523579478263855
Validation loss: 1.6579874138678274

Epoch: 6| Step: 5
Training loss: 0.6275882720947266
Validation loss: 1.6214744890889814

Epoch: 6| Step: 6
Training loss: 0.622430682182312
Validation loss: 1.7008015968466317

Epoch: 6| Step: 7
Training loss: 0.728812038898468
Validation loss: 1.6412275773222729

Epoch: 6| Step: 8
Training loss: 1.0960640907287598
Validation loss: 1.7649544797917849

Epoch: 6| Step: 9
Training loss: 0.7411375045776367
Validation loss: 1.693664385426429

Epoch: 6| Step: 10
Training loss: 0.6515708565711975
Validation loss: 1.6775316589622087

Epoch: 6| Step: 11
Training loss: 0.8114148378372192
Validation loss: 1.6663198624887774

Epoch: 6| Step: 12
Training loss: 1.2323856353759766
Validation loss: 1.639206164626665

Epoch: 6| Step: 13
Training loss: 0.7810279726982117
Validation loss: 1.6929382636982908

Epoch: 592| Step: 0
Training loss: 0.6404770612716675
Validation loss: 1.7336334887371267

Epoch: 6| Step: 1
Training loss: 0.7363309860229492
Validation loss: 1.737973226014004

Epoch: 6| Step: 2
Training loss: 0.7071247100830078
Validation loss: 1.7279288986677765

Epoch: 6| Step: 3
Training loss: 0.5937010049819946
Validation loss: 1.6669543904642905

Epoch: 6| Step: 4
Training loss: 1.0516217947006226
Validation loss: 1.6696348831217775

Epoch: 6| Step: 5
Training loss: 0.6679612398147583
Validation loss: 1.6522539366957962

Epoch: 6| Step: 6
Training loss: 1.2745695114135742
Validation loss: 1.6567335321057228

Epoch: 6| Step: 7
Training loss: 1.072953462600708
Validation loss: 1.710982052228784

Epoch: 6| Step: 8
Training loss: 0.613978922367096
Validation loss: 1.6893820031996696

Epoch: 6| Step: 9
Training loss: 0.9874376058578491
Validation loss: 1.6515635021271244

Epoch: 6| Step: 10
Training loss: 0.6419487595558167
Validation loss: 1.6548508085230345

Epoch: 6| Step: 11
Training loss: 0.7541028261184692
Validation loss: 1.6401388952808995

Epoch: 6| Step: 12
Training loss: 0.729595422744751
Validation loss: 1.6973710636938772

Epoch: 6| Step: 13
Training loss: 1.4580045938491821
Validation loss: 1.6972426586253668

Epoch: 593| Step: 0
Training loss: 0.8633319139480591
Validation loss: 1.6867657053855158

Epoch: 6| Step: 1
Training loss: 0.33895760774612427
Validation loss: 1.7104259229475451

Epoch: 6| Step: 2
Training loss: 0.8738055229187012
Validation loss: 1.6796403469577912

Epoch: 6| Step: 3
Training loss: 0.687007486820221
Validation loss: 1.7312828174201391

Epoch: 6| Step: 4
Training loss: 0.9976739287376404
Validation loss: 1.7044552769712222

Epoch: 6| Step: 5
Training loss: 0.6044808030128479
Validation loss: 1.6789498970072756

Epoch: 6| Step: 6
Training loss: 1.3277640342712402
Validation loss: 1.6549494625419698

Epoch: 6| Step: 7
Training loss: 0.7111361026763916
Validation loss: 1.7087047253885577

Epoch: 6| Step: 8
Training loss: 0.6087976694107056
Validation loss: 1.6567143419737458

Epoch: 6| Step: 9
Training loss: 0.7448248863220215
Validation loss: 1.690290012667256

Epoch: 6| Step: 10
Training loss: 0.44152843952178955
Validation loss: 1.7173975924009919

Epoch: 6| Step: 11
Training loss: 0.983884334564209
Validation loss: 1.689835225382159

Epoch: 6| Step: 12
Training loss: 0.9657498598098755
Validation loss: 1.6695626628014348

Epoch: 6| Step: 13
Training loss: 0.47557470202445984
Validation loss: 1.7449509136138424

Epoch: 594| Step: 0
Training loss: 0.8878452181816101
Validation loss: 1.685016563502691

Epoch: 6| Step: 1
Training loss: 0.33764979243278503
Validation loss: 1.7245337745194793

Epoch: 6| Step: 2
Training loss: 0.9387857913970947
Validation loss: 1.6823786843207575

Epoch: 6| Step: 3
Training loss: 0.594029426574707
Validation loss: 1.7044453262000956

Epoch: 6| Step: 4
Training loss: 0.9038515686988831
Validation loss: 1.64899561097545

Epoch: 6| Step: 5
Training loss: 0.5930707454681396
Validation loss: 1.6388476151292042

Epoch: 6| Step: 6
Training loss: 1.7309930324554443
Validation loss: 1.679859918932761

Epoch: 6| Step: 7
Training loss: 0.49028995633125305
Validation loss: 1.681006912262209

Epoch: 6| Step: 8
Training loss: 0.5927755832672119
Validation loss: 1.7110660768324328

Epoch: 6| Step: 9
Training loss: 0.6456925868988037
Validation loss: 1.6329178963938067

Epoch: 6| Step: 10
Training loss: 1.3994886875152588
Validation loss: 1.6514254564880042

Epoch: 6| Step: 11
Training loss: 0.5230941772460938
Validation loss: 1.6366634638078752

Epoch: 6| Step: 12
Training loss: 0.6142467260360718
Validation loss: 1.7534896263512232

Epoch: 6| Step: 13
Training loss: 0.6042089462280273
Validation loss: 1.65246565880314

Epoch: 595| Step: 0
Training loss: 0.6111354231834412
Validation loss: 1.698496357087166

Epoch: 6| Step: 1
Training loss: 1.0463491678237915
Validation loss: 1.6742673509864396

Epoch: 6| Step: 2
Training loss: 0.7716764211654663
Validation loss: 1.7407124286056848

Epoch: 6| Step: 3
Training loss: 0.6420660018920898
Validation loss: 1.6785961991997176

Epoch: 6| Step: 4
Training loss: 0.7843300104141235
Validation loss: 1.686005852555716

Epoch: 6| Step: 5
Training loss: 0.6267107725143433
Validation loss: 1.7145067991748932

Epoch: 6| Step: 6
Training loss: 0.593040406703949
Validation loss: 1.7226819530610116

Epoch: 6| Step: 7
Training loss: 0.6018204092979431
Validation loss: 1.7271545599865656

Epoch: 6| Step: 8
Training loss: 0.65622878074646
Validation loss: 1.6319540085331086

Epoch: 6| Step: 9
Training loss: 0.9934607744216919
Validation loss: 1.7189210480259312

Epoch: 6| Step: 10
Training loss: 0.931552529335022
Validation loss: 1.6863400487489597

Epoch: 6| Step: 11
Training loss: 1.491004467010498
Validation loss: 1.6707030111743557

Epoch: 6| Step: 12
Training loss: 0.5387321710586548
Validation loss: 1.6959239436734108

Epoch: 6| Step: 13
Training loss: 0.6095278263092041
Validation loss: 1.7354024815303024

Epoch: 596| Step: 0
Training loss: 1.0681627988815308
Validation loss: 1.666841649240063

Epoch: 6| Step: 1
Training loss: 0.5524576306343079
Validation loss: 1.690872319283024

Epoch: 6| Step: 2
Training loss: 0.4820645749568939
Validation loss: 1.681774802105401

Epoch: 6| Step: 3
Training loss: 0.42901483178138733
Validation loss: 1.7180041420844294

Epoch: 6| Step: 4
Training loss: 1.2139389514923096
Validation loss: 1.706612669011598

Epoch: 6| Step: 5
Training loss: 1.727711796760559
Validation loss: 1.7647923308034097

Epoch: 6| Step: 6
Training loss: 0.5326855778694153
Validation loss: 1.7589057722399313

Epoch: 6| Step: 7
Training loss: 0.5352618098258972
Validation loss: 1.7236199186694237

Epoch: 6| Step: 8
Training loss: 1.0047729015350342
Validation loss: 1.7079480348094818

Epoch: 6| Step: 9
Training loss: 0.7956960797309875
Validation loss: 1.6765790216384395

Epoch: 6| Step: 10
Training loss: 0.5532239675521851
Validation loss: 1.6519420710943078

Epoch: 6| Step: 11
Training loss: 0.3567308485507965
Validation loss: 1.6954985241736136

Epoch: 6| Step: 12
Training loss: 0.8809614181518555
Validation loss: 1.7025649278394637

Epoch: 6| Step: 13
Training loss: 0.539921224117279
Validation loss: 1.6828357917006298

Epoch: 597| Step: 0
Training loss: 0.7308070659637451
Validation loss: 1.6969854876559267

Epoch: 6| Step: 1
Training loss: 0.6860413551330566
Validation loss: 1.705768003258654

Epoch: 6| Step: 2
Training loss: 0.7292658090591431
Validation loss: 1.6784855896426785

Epoch: 6| Step: 3
Training loss: 0.4973756670951843
Validation loss: 1.7073913030726935

Epoch: 6| Step: 4
Training loss: 0.6222668886184692
Validation loss: 1.7034022141528387

Epoch: 6| Step: 5
Training loss: 0.9161133170127869
Validation loss: 1.6802392153329746

Epoch: 6| Step: 6
Training loss: 0.9163886308670044
Validation loss: 1.7376901398422897

Epoch: 6| Step: 7
Training loss: 0.992013692855835
Validation loss: 1.7565779673155917

Epoch: 6| Step: 8
Training loss: 1.1654720306396484
Validation loss: 1.668380779604758

Epoch: 6| Step: 9
Training loss: 0.6992391347885132
Validation loss: 1.7073177983683925

Epoch: 6| Step: 10
Training loss: 0.5407186150550842
Validation loss: 1.6635735752762004

Epoch: 6| Step: 11
Training loss: 1.1577693223953247
Validation loss: 1.6867970933196366

Epoch: 6| Step: 12
Training loss: 0.6899641752243042
Validation loss: 1.6602707870544926

Epoch: 6| Step: 13
Training loss: 0.6317880153656006
Validation loss: 1.6696959516053558

Epoch: 598| Step: 0
Training loss: 0.6757184863090515
Validation loss: 1.6775675922311761

Epoch: 6| Step: 1
Training loss: 1.1836588382720947
Validation loss: 1.7851991589351366

Epoch: 6| Step: 2
Training loss: 1.0290924310684204
Validation loss: 1.724146960884012

Epoch: 6| Step: 3
Training loss: 0.5122758150100708
Validation loss: 1.6469139668249315

Epoch: 6| Step: 4
Training loss: 0.7242505550384521
Validation loss: 1.67713753766911

Epoch: 6| Step: 5
Training loss: 0.5761433839797974
Validation loss: 1.6398670301642468

Epoch: 6| Step: 6
Training loss: 1.0604480504989624
Validation loss: 1.6980027806374334

Epoch: 6| Step: 7
Training loss: 0.8206611275672913
Validation loss: 1.6701427262316468

Epoch: 6| Step: 8
Training loss: 0.9288070201873779
Validation loss: 1.6593194341146817

Epoch: 6| Step: 9
Training loss: 0.739311695098877
Validation loss: 1.6946858718831053

Epoch: 6| Step: 10
Training loss: 0.31422677636146545
Validation loss: 1.6635191978946808

Epoch: 6| Step: 11
Training loss: 0.7106020450592041
Validation loss: 1.7483488244395102

Epoch: 6| Step: 12
Training loss: 0.9886730909347534
Validation loss: 1.6714653135627828

Epoch: 6| Step: 13
Training loss: 1.1107234954833984
Validation loss: 1.6529827169192735

Epoch: 599| Step: 0
Training loss: 0.5538173913955688
Validation loss: 1.6651417683529597

Epoch: 6| Step: 1
Training loss: 0.9386638402938843
Validation loss: 1.6674484809239705

Epoch: 6| Step: 2
Training loss: 1.1564968824386597
Validation loss: 1.6764892583252282

Epoch: 6| Step: 3
Training loss: 1.2177765369415283
Validation loss: 1.6494922291847967

Epoch: 6| Step: 4
Training loss: 0.7943763136863708
Validation loss: 1.7180694085295483

Epoch: 6| Step: 5
Training loss: 1.0088834762573242
Validation loss: 1.718430156348854

Epoch: 6| Step: 6
Training loss: 0.5142348408699036
Validation loss: 1.7555532096534647

Epoch: 6| Step: 7
Training loss: 0.8023842573165894
Validation loss: 1.6829310770957702

Epoch: 6| Step: 8
Training loss: 0.6812614798545837
Validation loss: 1.7635756769487936

Epoch: 6| Step: 9
Training loss: 1.1088420152664185
Validation loss: 1.7364054610652309

Epoch: 6| Step: 10
Training loss: 0.7554251551628113
Validation loss: 1.6896343769565705

Epoch: 6| Step: 11
Training loss: 0.5576711297035217
Validation loss: 1.7012211686821395

Epoch: 6| Step: 12
Training loss: 0.5808109045028687
Validation loss: 1.7599262627222205

Epoch: 6| Step: 13
Training loss: 0.36467987298965454
Validation loss: 1.700533418245213

Epoch: 600| Step: 0
Training loss: 0.7271971106529236
Validation loss: 1.6440295545003747

Epoch: 6| Step: 1
Training loss: 1.6712350845336914
Validation loss: 1.6597884598598684

Epoch: 6| Step: 2
Training loss: 0.6340519189834595
Validation loss: 1.6822486821041311

Epoch: 6| Step: 3
Training loss: 0.6809898614883423
Validation loss: 1.691365921369163

Epoch: 6| Step: 4
Training loss: 0.6201461553573608
Validation loss: 1.6572807129993234

Epoch: 6| Step: 5
Training loss: 0.5997815132141113
Validation loss: 1.6494526145278767

Epoch: 6| Step: 6
Training loss: 0.8359386920928955
Validation loss: 1.6850916865051433

Epoch: 6| Step: 7
Training loss: 0.6317815780639648
Validation loss: 1.6300700415847122

Epoch: 6| Step: 8
Training loss: 1.006676197052002
Validation loss: 1.7016019231529647

Epoch: 6| Step: 9
Training loss: 0.7172532677650452
Validation loss: 1.6862673221095916

Epoch: 6| Step: 10
Training loss: 0.7637795805931091
Validation loss: 1.7150827774437525

Epoch: 6| Step: 11
Training loss: 0.6606137752532959
Validation loss: 1.7465562089796989

Epoch: 6| Step: 12
Training loss: 0.50983726978302
Validation loss: 1.6501865233144453

Epoch: 6| Step: 13
Training loss: 0.9574471712112427
Validation loss: 1.7080925831230738

Testing loss: 2.3383508258395724
