Epoch: 1| Step: 0
Training loss: 4.11529541015625
Validation loss: 5.46739883320306

Epoch: 6| Step: 1
Training loss: 4.347476005554199
Validation loss: 5.459268610964539

Epoch: 6| Step: 2
Training loss: 3.370332717895508
Validation loss: 5.453579574502925

Epoch: 6| Step: 3
Training loss: 5.234402656555176
Validation loss: 5.446911140154767

Epoch: 6| Step: 4
Training loss: 6.101752281188965
Validation loss: 5.440076012765208

Epoch: 6| Step: 5
Training loss: 4.887124538421631
Validation loss: 5.4318794383797595

Epoch: 6| Step: 6
Training loss: 6.237788677215576
Validation loss: 5.42471142225368

Epoch: 6| Step: 7
Training loss: 7.378807544708252
Validation loss: 5.420102283518801

Epoch: 6| Step: 8
Training loss: 5.724451065063477
Validation loss: 5.409954050535797

Epoch: 6| Step: 9
Training loss: 4.685131072998047
Validation loss: 5.403016382648099

Epoch: 6| Step: 10
Training loss: 5.588294982910156
Validation loss: 5.395442655009608

Epoch: 6| Step: 11
Training loss: 5.667340278625488
Validation loss: 5.390170348587857

Epoch: 6| Step: 12
Training loss: 4.519574165344238
Validation loss: 5.3808479001445155

Epoch: 6| Step: 13
Training loss: 5.207132339477539
Validation loss: 5.374463378742177

Epoch: 2| Step: 0
Training loss: 5.6119890213012695
Validation loss: 5.368831993431173

Epoch: 6| Step: 1
Training loss: 4.992128372192383
Validation loss: 5.36246903224658

Epoch: 6| Step: 2
Training loss: 6.213651180267334
Validation loss: 5.353725617931735

Epoch: 6| Step: 3
Training loss: 4.92774772644043
Validation loss: 5.349915396782659

Epoch: 6| Step: 4
Training loss: 5.900012493133545
Validation loss: 5.340178653758059

Epoch: 6| Step: 5
Training loss: 5.16448974609375
Validation loss: 5.330800912713491

Epoch: 6| Step: 6
Training loss: 5.045022964477539
Validation loss: 5.32669581649124

Epoch: 6| Step: 7
Training loss: 3.8948240280151367
Validation loss: 5.3160234676894325

Epoch: 6| Step: 8
Training loss: 5.236976623535156
Validation loss: 5.309367713107858

Epoch: 6| Step: 9
Training loss: 5.213240623474121
Validation loss: 5.304449686440089

Epoch: 6| Step: 10
Training loss: 4.622693061828613
Validation loss: 5.294927212499803

Epoch: 6| Step: 11
Training loss: 5.084864616394043
Validation loss: 5.286836906145978

Epoch: 6| Step: 12
Training loss: 5.010531902313232
Validation loss: 5.279160991791756

Epoch: 6| Step: 13
Training loss: 4.389490127563477
Validation loss: 5.269692867032943

Epoch: 3| Step: 0
Training loss: 4.6378021240234375
Validation loss: 5.263232661831763

Epoch: 6| Step: 1
Training loss: 4.283248424530029
Validation loss: 5.254333855003439

Epoch: 6| Step: 2
Training loss: 4.514193534851074
Validation loss: 5.250853830768216

Epoch: 6| Step: 3
Training loss: 5.241084098815918
Validation loss: 5.2385328405646865

Epoch: 6| Step: 4
Training loss: 5.872867584228516
Validation loss: 5.2326203469307195

Epoch: 6| Step: 5
Training loss: 5.638616561889648
Validation loss: 5.220993970030097

Epoch: 6| Step: 6
Training loss: 5.493717193603516
Validation loss: 5.211569401525682

Epoch: 6| Step: 7
Training loss: 6.068825721740723
Validation loss: 5.201654300894789

Epoch: 6| Step: 8
Training loss: 4.358913421630859
Validation loss: 5.195511407749628

Epoch: 6| Step: 9
Training loss: 4.987250328063965
Validation loss: 5.185928072980655

Epoch: 6| Step: 10
Training loss: 4.155942440032959
Validation loss: 5.178693643180273

Epoch: 6| Step: 11
Training loss: 4.38946533203125
Validation loss: 5.166889949511456

Epoch: 6| Step: 12
Training loss: 4.577051162719727
Validation loss: 5.162324700304257

Epoch: 6| Step: 13
Training loss: 6.417487144470215
Validation loss: 5.150666180477347

Epoch: 4| Step: 0
Training loss: 5.031732559204102
Validation loss: 5.142372187747751

Epoch: 6| Step: 1
Training loss: 5.888836860656738
Validation loss: 5.131516261767316

Epoch: 6| Step: 2
Training loss: 5.0019659996032715
Validation loss: 5.125551685210197

Epoch: 6| Step: 3
Training loss: 3.773991584777832
Validation loss: 5.114687714525449

Epoch: 6| Step: 4
Training loss: 5.492036819458008
Validation loss: 5.1044277734653924

Epoch: 6| Step: 5
Training loss: 5.258742332458496
Validation loss: 5.096557304423342

Epoch: 6| Step: 6
Training loss: 4.30335807800293
Validation loss: 5.087121512300225

Epoch: 6| Step: 7
Training loss: 3.7866222858428955
Validation loss: 5.074597215139738

Epoch: 6| Step: 8
Training loss: 3.9338274002075195
Validation loss: 5.069624772635839

Epoch: 6| Step: 9
Training loss: 5.43271541595459
Validation loss: 5.05974970581711

Epoch: 6| Step: 10
Training loss: 6.255061149597168
Validation loss: 5.047415733337402

Epoch: 6| Step: 11
Training loss: 3.753160238265991
Validation loss: 5.0379286068742

Epoch: 6| Step: 12
Training loss: 4.973379135131836
Validation loss: 5.025865908591978

Epoch: 6| Step: 13
Training loss: 5.693267822265625
Validation loss: 5.0188314119974775

Epoch: 5| Step: 0
Training loss: 5.067392349243164
Validation loss: 5.010886997304937

Epoch: 6| Step: 1
Training loss: 5.182864665985107
Validation loss: 4.999209106609386

Epoch: 6| Step: 2
Training loss: 6.3497819900512695
Validation loss: 4.989573401789511

Epoch: 6| Step: 3
Training loss: 3.80643367767334
Validation loss: 4.977688625294675

Epoch: 6| Step: 4
Training loss: 5.8696370124816895
Validation loss: 4.968824745506368

Epoch: 6| Step: 5
Training loss: 4.907625198364258
Validation loss: 4.9606945078860045

Epoch: 6| Step: 6
Training loss: 5.706128120422363
Validation loss: 4.947376951094596

Epoch: 6| Step: 7
Training loss: 4.296920299530029
Validation loss: 4.941131822524532

Epoch: 6| Step: 8
Training loss: 4.874104022979736
Validation loss: 4.933111462541806

Epoch: 6| Step: 9
Training loss: 3.8129324913024902
Validation loss: 4.91859035594489

Epoch: 6| Step: 10
Training loss: 4.419099807739258
Validation loss: 4.910684344589069

Epoch: 6| Step: 11
Training loss: 3.9549450874328613
Validation loss: 4.898768137860042

Epoch: 6| Step: 12
Training loss: 3.824082612991333
Validation loss: 4.887240866179107

Epoch: 6| Step: 13
Training loss: 3.7484054565429688
Validation loss: 4.873679099544402

Epoch: 6| Step: 0
Training loss: 5.07615852355957
Validation loss: 4.863191102140693

Epoch: 6| Step: 1
Training loss: 6.0600810050964355
Validation loss: 4.855387913283481

Epoch: 6| Step: 2
Training loss: 5.636055946350098
Validation loss: 4.843064026166034

Epoch: 6| Step: 3
Training loss: 3.969622850418091
Validation loss: 4.833444400500226

Epoch: 6| Step: 4
Training loss: 3.719411849975586
Validation loss: 4.819767213636829

Epoch: 6| Step: 5
Training loss: 5.810898780822754
Validation loss: 4.8092546257921445

Epoch: 6| Step: 6
Training loss: 4.276573657989502
Validation loss: 4.797930553395261

Epoch: 6| Step: 7
Training loss: 3.5202372074127197
Validation loss: 4.785335858662923

Epoch: 6| Step: 8
Training loss: 5.57930850982666
Validation loss: 4.774851481119792

Epoch: 6| Step: 9
Training loss: 4.3077592849731445
Validation loss: 4.7622610984310025

Epoch: 6| Step: 10
Training loss: 3.2262625694274902
Validation loss: 4.748435666484218

Epoch: 6| Step: 11
Training loss: 5.521867752075195
Validation loss: 4.7386889714066704

Epoch: 6| Step: 12
Training loss: 3.1680116653442383
Validation loss: 4.725692041458622

Epoch: 6| Step: 13
Training loss: 3.882319450378418
Validation loss: 4.7124936247384674

Epoch: 7| Step: 0
Training loss: 4.37239408493042
Validation loss: 4.700472785580542

Epoch: 6| Step: 1
Training loss: 4.928672790527344
Validation loss: 4.688731757543421

Epoch: 6| Step: 2
Training loss: 3.695950984954834
Validation loss: 4.671525524508569

Epoch: 6| Step: 3
Training loss: 4.8441290855407715
Validation loss: 4.663112096889044

Epoch: 6| Step: 4
Training loss: 5.705929279327393
Validation loss: 4.648717998176493

Epoch: 6| Step: 5
Training loss: 4.370154857635498
Validation loss: 4.633596589488368

Epoch: 6| Step: 6
Training loss: 4.813091278076172
Validation loss: 4.624602610065091

Epoch: 6| Step: 7
Training loss: 4.061046600341797
Validation loss: 4.606743566451534

Epoch: 6| Step: 8
Training loss: 3.9153647422790527
Validation loss: 4.596168384757093

Epoch: 6| Step: 9
Training loss: 5.7605814933776855
Validation loss: 4.581606459873979

Epoch: 6| Step: 10
Training loss: 3.589970111846924
Validation loss: 4.566714276549637

Epoch: 6| Step: 11
Training loss: 4.590693473815918
Validation loss: 4.553480604643463

Epoch: 6| Step: 12
Training loss: 4.114569664001465
Validation loss: 4.537803280738093

Epoch: 6| Step: 13
Training loss: 1.511733055114746
Validation loss: 4.526922651516494

Epoch: 8| Step: 0
Training loss: 4.765128135681152
Validation loss: 4.51033624269629

Epoch: 6| Step: 1
Training loss: 5.190598487854004
Validation loss: 4.494006064630324

Epoch: 6| Step: 2
Training loss: 3.2716948986053467
Validation loss: 4.479932677361273

Epoch: 6| Step: 3
Training loss: 3.8499321937561035
Validation loss: 4.468914252455517

Epoch: 6| Step: 4
Training loss: 3.7368955612182617
Validation loss: 4.447061651496477

Epoch: 6| Step: 5
Training loss: 4.452267169952393
Validation loss: 4.437967364506055

Epoch: 6| Step: 6
Training loss: 3.1792867183685303
Validation loss: 4.4207841862914385

Epoch: 6| Step: 7
Training loss: 3.7107882499694824
Validation loss: 4.403074413217524

Epoch: 6| Step: 8
Training loss: 5.682048797607422
Validation loss: 4.391648200250441

Epoch: 6| Step: 9
Training loss: 4.549655914306641
Validation loss: 4.373181507151614

Epoch: 6| Step: 10
Training loss: 3.3602588176727295
Validation loss: 4.358705489866195

Epoch: 6| Step: 11
Training loss: 3.507934093475342
Validation loss: 4.343368479000625

Epoch: 6| Step: 12
Training loss: 5.382833480834961
Validation loss: 4.325859182624407

Epoch: 6| Step: 13
Training loss: 3.9980947971343994
Validation loss: 4.314715493109919

Epoch: 9| Step: 0
Training loss: 4.275112152099609
Validation loss: 4.298284381948491

Epoch: 6| Step: 1
Training loss: 5.224886417388916
Validation loss: 4.281755452514977

Epoch: 6| Step: 2
Training loss: 4.181525230407715
Validation loss: 4.26337831763811

Epoch: 6| Step: 3
Training loss: 4.694774627685547
Validation loss: 4.2490310412581245

Epoch: 6| Step: 4
Training loss: 4.237048625946045
Validation loss: 4.232331111866941

Epoch: 6| Step: 5
Training loss: 4.145733833312988
Validation loss: 4.212779070741387

Epoch: 6| Step: 6
Training loss: 3.0494399070739746
Validation loss: 4.200078441250708

Epoch: 6| Step: 7
Training loss: 3.3737802505493164
Validation loss: 4.181849300220448

Epoch: 6| Step: 8
Training loss: 3.9189023971557617
Validation loss: 4.16709009293587

Epoch: 6| Step: 9
Training loss: 4.722155570983887
Validation loss: 4.148130096415038

Epoch: 6| Step: 10
Training loss: 3.9194893836975098
Validation loss: 4.129113294745005

Epoch: 6| Step: 11
Training loss: 3.081002712249756
Validation loss: 4.106071174785655

Epoch: 6| Step: 12
Training loss: 3.741506338119507
Validation loss: 4.093494612683532

Epoch: 6| Step: 13
Training loss: 2.8316426277160645
Validation loss: 4.082178592681885

Epoch: 10| Step: 0
Training loss: 2.8724300861358643
Validation loss: 4.063673360373384

Epoch: 6| Step: 1
Training loss: 4.401765823364258
Validation loss: 4.045707712891281

Epoch: 6| Step: 2
Training loss: 4.582027435302734
Validation loss: 4.03005443080779

Epoch: 6| Step: 3
Training loss: 2.423858642578125
Validation loss: 4.012069868785079

Epoch: 6| Step: 4
Training loss: 4.451810836791992
Validation loss: 3.992822421494351

Epoch: 6| Step: 5
Training loss: 3.071657180786133
Validation loss: 3.9777691825743644

Epoch: 6| Step: 6
Training loss: 4.268274307250977
Validation loss: 3.9603720736759964

Epoch: 6| Step: 7
Training loss: 3.5708279609680176
Validation loss: 3.9391491848935365

Epoch: 6| Step: 8
Training loss: 4.05094575881958
Validation loss: 3.9278653616546304

Epoch: 6| Step: 9
Training loss: 5.203259468078613
Validation loss: 3.911022657989174

Epoch: 6| Step: 10
Training loss: 3.9835164546966553
Validation loss: 3.8912243894351426

Epoch: 6| Step: 11
Training loss: 4.127995491027832
Validation loss: 3.8696697040270736

Epoch: 6| Step: 12
Training loss: 3.512826919555664
Validation loss: 3.8525491196622133

Epoch: 6| Step: 13
Training loss: 1.5576967000961304
Validation loss: 3.839492772215156

Epoch: 11| Step: 0
Training loss: 3.2384514808654785
Validation loss: 3.818485293337094

Epoch: 6| Step: 1
Training loss: 3.230543851852417
Validation loss: 3.807743531401439

Epoch: 6| Step: 2
Training loss: 3.587239980697632
Validation loss: 3.7935860669741066

Epoch: 6| Step: 3
Training loss: 4.101844787597656
Validation loss: 3.775701076753678

Epoch: 6| Step: 4
Training loss: 3.944150924682617
Validation loss: 3.761000843458278

Epoch: 6| Step: 5
Training loss: 3.8791985511779785
Validation loss: 3.7419117548132457

Epoch: 6| Step: 6
Training loss: 3.35432767868042
Validation loss: 3.7294530278892926

Epoch: 6| Step: 7
Training loss: 3.5747222900390625
Validation loss: 3.7127035510155464

Epoch: 6| Step: 8
Training loss: 3.3116161823272705
Validation loss: 3.6968944200905423

Epoch: 6| Step: 9
Training loss: 4.062189102172852
Validation loss: 3.679823306299025

Epoch: 6| Step: 10
Training loss: 3.1528711318969727
Validation loss: 3.6574809038510887

Epoch: 6| Step: 11
Training loss: 3.714367389678955
Validation loss: 3.643171236079226

Epoch: 6| Step: 12
Training loss: 3.694079875946045
Validation loss: 3.6227705478668213

Epoch: 6| Step: 13
Training loss: 3.0795469284057617
Validation loss: 3.609200441709129

Epoch: 12| Step: 0
Training loss: 3.6998777389526367
Validation loss: 3.584417514903571

Epoch: 6| Step: 1
Training loss: 3.2568469047546387
Validation loss: 3.5667770652360815

Epoch: 6| Step: 2
Training loss: 3.3827667236328125
Validation loss: 3.552286794108729

Epoch: 6| Step: 3
Training loss: 3.1855220794677734
Validation loss: 3.535582214273432

Epoch: 6| Step: 4
Training loss: 3.746401309967041
Validation loss: 3.511983363859115

Epoch: 6| Step: 5
Training loss: 3.5191149711608887
Validation loss: 3.4881176948547363

Epoch: 6| Step: 6
Training loss: 2.2754435539245605
Validation loss: 3.471251518495621

Epoch: 6| Step: 7
Training loss: 4.329041481018066
Validation loss: 3.4531130534346386

Epoch: 6| Step: 8
Training loss: 2.385477304458618
Validation loss: 3.4428281117511053

Epoch: 6| Step: 9
Training loss: 3.7011899948120117
Validation loss: 3.415369305559384

Epoch: 6| Step: 10
Training loss: 3.2534213066101074
Validation loss: 3.3992394554999565

Epoch: 6| Step: 11
Training loss: 3.723360300064087
Validation loss: 3.384998772733955

Epoch: 6| Step: 12
Training loss: 4.145264625549316
Validation loss: 3.3682729633905555

Epoch: 6| Step: 13
Training loss: 1.986664891242981
Validation loss: 3.352643177073489

Epoch: 13| Step: 0
Training loss: 2.5313639640808105
Validation loss: 3.3291329363340973

Epoch: 6| Step: 1
Training loss: 2.0176029205322266
Validation loss: 3.305285430723621

Epoch: 6| Step: 2
Training loss: 2.9733057022094727
Validation loss: 3.288653753137076

Epoch: 6| Step: 3
Training loss: 3.5667057037353516
Validation loss: 3.268258810043335

Epoch: 6| Step: 4
Training loss: 3.289825439453125
Validation loss: 3.2537519726701962

Epoch: 6| Step: 5
Training loss: 3.1146836280822754
Validation loss: 3.2343796401895504

Epoch: 6| Step: 6
Training loss: 3.4674110412597656
Validation loss: 3.2209222316741943

Epoch: 6| Step: 7
Training loss: 3.829819679260254
Validation loss: 3.190756813172371

Epoch: 6| Step: 8
Training loss: 3.699998617172241
Validation loss: 3.1852654846765662

Epoch: 6| Step: 9
Training loss: 2.233006000518799
Validation loss: 3.1591259510286394

Epoch: 6| Step: 10
Training loss: 3.9614357948303223
Validation loss: 3.1451490002293743

Epoch: 6| Step: 11
Training loss: 2.1368401050567627
Validation loss: 3.1306852986735683

Epoch: 6| Step: 12
Training loss: 3.6628613471984863
Validation loss: 3.108387106208391

Epoch: 6| Step: 13
Training loss: 3.9894917011260986
Validation loss: 3.097609463558402

Epoch: 14| Step: 0
Training loss: 3.019179582595825
Validation loss: 3.0801282185380177

Epoch: 6| Step: 1
Training loss: 3.265235424041748
Validation loss: 3.05903108145601

Epoch: 6| Step: 2
Training loss: 3.585369110107422
Validation loss: 3.0280028338073404

Epoch: 6| Step: 3
Training loss: 3.586751699447632
Validation loss: 3.0166040928133073

Epoch: 6| Step: 4
Training loss: 3.9796528816223145
Validation loss: 3.00069188046199

Epoch: 6| Step: 5
Training loss: 2.243523359298706
Validation loss: 2.9791047291089128

Epoch: 6| Step: 6
Training loss: 2.766958236694336
Validation loss: 2.953107746698523

Epoch: 6| Step: 7
Training loss: 2.3905344009399414
Validation loss: 2.93280198753521

Epoch: 6| Step: 8
Training loss: 2.9036664962768555
Validation loss: 2.9127673897691952

Epoch: 6| Step: 9
Training loss: 2.406501293182373
Validation loss: 2.893382974850234

Epoch: 6| Step: 10
Training loss: 3.0100455284118652
Validation loss: 2.8729125043397308

Epoch: 6| Step: 11
Training loss: 2.5467612743377686
Validation loss: 2.8636737613267798

Epoch: 6| Step: 12
Training loss: 3.9152307510375977
Validation loss: 2.8450796886156966

Epoch: 6| Step: 13
Training loss: 1.8654425144195557
Validation loss: 2.8265026205329487

Epoch: 15| Step: 0
Training loss: 2.814350128173828
Validation loss: 2.813128045810166

Epoch: 6| Step: 1
Training loss: 2.61851167678833
Validation loss: 2.791344150420158

Epoch: 6| Step: 2
Training loss: 2.7569680213928223
Validation loss: 2.7751392779811734

Epoch: 6| Step: 3
Training loss: 3.2835488319396973
Validation loss: 2.775155267407817

Epoch: 6| Step: 4
Training loss: 2.898449420928955
Validation loss: 2.7569600664159304

Epoch: 6| Step: 5
Training loss: 3.214806079864502
Validation loss: 2.739642050958449

Epoch: 6| Step: 6
Training loss: 2.9257140159606934
Validation loss: 2.736193287757135

Epoch: 6| Step: 7
Training loss: 2.8016457557678223
Validation loss: 2.7103005173385784

Epoch: 6| Step: 8
Training loss: 2.2532544136047363
Validation loss: 2.6944644117868073

Epoch: 6| Step: 9
Training loss: 2.379798650741577
Validation loss: 2.680717058079217

Epoch: 6| Step: 10
Training loss: 2.7708663940429688
Validation loss: 2.6781133785042712

Epoch: 6| Step: 11
Training loss: 3.21248722076416
Validation loss: 2.6581185017862627

Epoch: 6| Step: 12
Training loss: 2.582242965698242
Validation loss: 2.638824055271764

Epoch: 6| Step: 13
Training loss: 3.4235737323760986
Validation loss: 2.6274307902141283

Epoch: 16| Step: 0
Training loss: 2.502504587173462
Validation loss: 2.6014161879016506

Epoch: 6| Step: 1
Training loss: 2.9980859756469727
Validation loss: 2.580263107053695

Epoch: 6| Step: 2
Training loss: 2.3311285972595215
Validation loss: 2.5656500862490748

Epoch: 6| Step: 3
Training loss: 2.4766154289245605
Validation loss: 2.5502735132812173

Epoch: 6| Step: 4
Training loss: 2.2062320709228516
Validation loss: 2.5326485095485562

Epoch: 6| Step: 5
Training loss: 3.0099194049835205
Validation loss: 2.5273136913135485

Epoch: 6| Step: 6
Training loss: 2.582686424255371
Validation loss: 2.5312891749925512

Epoch: 6| Step: 7
Training loss: 2.6198501586914062
Validation loss: 2.5154502827634095

Epoch: 6| Step: 8
Training loss: 2.9475574493408203
Validation loss: 2.494371303948023

Epoch: 6| Step: 9
Training loss: 3.085927963256836
Validation loss: 2.4828274557667394

Epoch: 6| Step: 10
Training loss: 2.6395740509033203
Validation loss: 2.4710391054871264

Epoch: 6| Step: 11
Training loss: 2.3216607570648193
Validation loss: 2.450607060104288

Epoch: 6| Step: 12
Training loss: 2.800199031829834
Validation loss: 2.4334321765489477

Epoch: 6| Step: 13
Training loss: 3.52248477935791
Validation loss: 2.4271953157199326

Epoch: 17| Step: 0
Training loss: 2.2003345489501953
Validation loss: 2.4041330340088054

Epoch: 6| Step: 1
Training loss: 1.9978736639022827
Validation loss: 2.4030290111418693

Epoch: 6| Step: 2
Training loss: 2.799787759780884
Validation loss: 2.3895137053664013

Epoch: 6| Step: 3
Training loss: 2.171776056289673
Validation loss: 2.38302638453822

Epoch: 6| Step: 4
Training loss: 2.770301342010498
Validation loss: 2.36512243106801

Epoch: 6| Step: 5
Training loss: 2.7307417392730713
Validation loss: 2.363978483343637

Epoch: 6| Step: 6
Training loss: 2.0322952270507812
Validation loss: 2.3680228161555466

Epoch: 6| Step: 7
Training loss: 2.7625033855438232
Validation loss: 2.3431584450506393

Epoch: 6| Step: 8
Training loss: 2.5833680629730225
Validation loss: 2.3548080639172624

Epoch: 6| Step: 9
Training loss: 2.528132438659668
Validation loss: 2.3493905169989473

Epoch: 6| Step: 10
Training loss: 3.049759864807129
Validation loss: 2.3279445581538702

Epoch: 6| Step: 11
Training loss: 3.1547274589538574
Validation loss: 2.327736541789065

Epoch: 6| Step: 12
Training loss: 2.341355323791504
Validation loss: 2.315597698252688

Epoch: 6| Step: 13
Training loss: 3.2466654777526855
Validation loss: 2.304666893456572

Epoch: 18| Step: 0
Training loss: 2.2599411010742188
Validation loss: 2.2945015891905753

Epoch: 6| Step: 1
Training loss: 2.540846347808838
Validation loss: 2.3003964847134006

Epoch: 6| Step: 2
Training loss: 3.148087501525879
Validation loss: 2.275172620691279

Epoch: 6| Step: 3
Training loss: 1.8180387020111084
Validation loss: 2.2737811175725793

Epoch: 6| Step: 4
Training loss: 2.9070982933044434
Validation loss: 2.258525977852524

Epoch: 6| Step: 5
Training loss: 1.6935288906097412
Validation loss: 2.265661678006572

Epoch: 6| Step: 6
Training loss: 2.1591506004333496
Validation loss: 2.2574570255894817

Epoch: 6| Step: 7
Training loss: 3.1935348510742188
Validation loss: 2.259490074649934

Epoch: 6| Step: 8
Training loss: 2.569333076477051
Validation loss: 2.2511352441644155

Epoch: 6| Step: 9
Training loss: 3.320605516433716
Validation loss: 2.229480316562037

Epoch: 6| Step: 10
Training loss: 2.7596559524536133
Validation loss: 2.228470289579002

Epoch: 6| Step: 11
Training loss: 1.910621166229248
Validation loss: 2.2169526725687008

Epoch: 6| Step: 12
Training loss: 2.155237913131714
Validation loss: 2.2222793268901047

Epoch: 6| Step: 13
Training loss: 3.4401509761810303
Validation loss: 2.214279897751347

Epoch: 19| Step: 0
Training loss: 1.702262282371521
Validation loss: 2.202395354547808

Epoch: 6| Step: 1
Training loss: 1.9674339294433594
Validation loss: 2.205846148152505

Epoch: 6| Step: 2
Training loss: 2.758822441101074
Validation loss: 2.194588963703443

Epoch: 6| Step: 3
Training loss: 3.131450891494751
Validation loss: 2.1944025972838044

Epoch: 6| Step: 4
Training loss: 2.057459592819214
Validation loss: 2.1992593631949475

Epoch: 6| Step: 5
Training loss: 1.8526171445846558
Validation loss: 2.2041256197037233

Epoch: 6| Step: 6
Training loss: 3.03413462638855
Validation loss: 2.1885785992427538

Epoch: 6| Step: 7
Training loss: 2.616670608520508
Validation loss: 2.202244266386955

Epoch: 6| Step: 8
Training loss: 2.409604072570801
Validation loss: 2.169286761232602

Epoch: 6| Step: 9
Training loss: 2.270089864730835
Validation loss: 2.2054810395804783

Epoch: 6| Step: 10
Training loss: 2.702526330947876
Validation loss: 2.186298644670876

Epoch: 6| Step: 11
Training loss: 2.8962771892547607
Validation loss: 2.187752672421035

Epoch: 6| Step: 12
Training loss: 2.8406805992126465
Validation loss: 2.1630484365647837

Epoch: 6| Step: 13
Training loss: 2.903278112411499
Validation loss: 2.1721685445436867

Epoch: 20| Step: 0
Training loss: 3.166896104812622
Validation loss: 2.1796099062888854

Epoch: 6| Step: 1
Training loss: 2.281186819076538
Validation loss: 2.1726317021154586

Epoch: 6| Step: 2
Training loss: 2.8201675415039062
Validation loss: 2.167205923347063

Epoch: 6| Step: 3
Training loss: 2.1952104568481445
Validation loss: 2.1694906937178744

Epoch: 6| Step: 4
Training loss: 1.81277334690094
Validation loss: 2.1713398489900815

Epoch: 6| Step: 5
Training loss: 2.0356667041778564
Validation loss: 2.173066798076835

Epoch: 6| Step: 6
Training loss: 2.1189699172973633
Validation loss: 2.1469550017387635

Epoch: 6| Step: 7
Training loss: 2.572288990020752
Validation loss: 2.168847555755287

Epoch: 6| Step: 8
Training loss: 2.613405227661133
Validation loss: 2.1616314457308863

Epoch: 6| Step: 9
Training loss: 2.182487964630127
Validation loss: 2.164227110083385

Epoch: 6| Step: 10
Training loss: 2.6545209884643555
Validation loss: 2.1671367691409205

Epoch: 6| Step: 11
Training loss: 2.7869937419891357
Validation loss: 2.1683182703551425

Epoch: 6| Step: 12
Training loss: 2.499767780303955
Validation loss: 2.174106905537267

Epoch: 6| Step: 13
Training loss: 3.99065899848938
Validation loss: 2.1640584238113894

Epoch: 21| Step: 0
Training loss: 3.063141345977783
Validation loss: 2.174226176354193

Epoch: 6| Step: 1
Training loss: 2.7074766159057617
Validation loss: 2.1642996880315963

Epoch: 6| Step: 2
Training loss: 2.490180730819702
Validation loss: 2.152910383798743

Epoch: 6| Step: 3
Training loss: 2.0929055213928223
Validation loss: 2.160619879281649

Epoch: 6| Step: 4
Training loss: 3.158984661102295
Validation loss: 2.1811874451175814

Epoch: 6| Step: 5
Training loss: 1.917283296585083
Validation loss: 2.153246147658235

Epoch: 6| Step: 6
Training loss: 1.922034740447998
Validation loss: 2.159506097916634

Epoch: 6| Step: 7
Training loss: 2.1503472328186035
Validation loss: 2.1709965198270735

Epoch: 6| Step: 8
Training loss: 3.158947467803955
Validation loss: 2.1789229044350247

Epoch: 6| Step: 9
Training loss: 2.5782923698425293
Validation loss: 2.1541298217670892

Epoch: 6| Step: 10
Training loss: 2.0100018978118896
Validation loss: 2.1608950553401822

Epoch: 6| Step: 11
Training loss: 1.9499266147613525
Validation loss: 2.171376238587082

Epoch: 6| Step: 12
Training loss: 2.7877349853515625
Validation loss: 2.1730778832589426

Epoch: 6| Step: 13
Training loss: 3.2567596435546875
Validation loss: 2.149904207516742

Epoch: 22| Step: 0
Training loss: 2.141373634338379
Validation loss: 2.174551240859493

Epoch: 6| Step: 1
Training loss: 2.875446319580078
Validation loss: 2.1425844405287053

Epoch: 6| Step: 2
Training loss: 2.4735774993896484
Validation loss: 2.1573207955206595

Epoch: 6| Step: 3
Training loss: 2.4653983116149902
Validation loss: 2.1694216984574513

Epoch: 6| Step: 4
Training loss: 1.975437045097351
Validation loss: 2.170562631340437

Epoch: 6| Step: 5
Training loss: 2.018479347229004
Validation loss: 2.17919933924111

Epoch: 6| Step: 6
Training loss: 2.2530431747436523
Validation loss: 2.1870507553059566

Epoch: 6| Step: 7
Training loss: 3.0385446548461914
Validation loss: 2.170964971665413

Epoch: 6| Step: 8
Training loss: 2.3542895317077637
Validation loss: 2.16978532268155

Epoch: 6| Step: 9
Training loss: 2.428189754486084
Validation loss: 2.1657236955499135

Epoch: 6| Step: 10
Training loss: 2.458252429962158
Validation loss: 2.1629371002156246

Epoch: 6| Step: 11
Training loss: 2.405702590942383
Validation loss: 2.166598290525457

Epoch: 6| Step: 12
Training loss: 2.8490586280822754
Validation loss: 2.169107162824241

Epoch: 6| Step: 13
Training loss: 3.713106393814087
Validation loss: 2.152568756893117

Epoch: 23| Step: 0
Training loss: 2.2978157997131348
Validation loss: 2.1651752738542456

Epoch: 6| Step: 1
Training loss: 2.252427101135254
Validation loss: 2.1749431625489266

Epoch: 6| Step: 2
Training loss: 3.1674270629882812
Validation loss: 2.1691936190410326

Epoch: 6| Step: 3
Training loss: 2.2209577560424805
Validation loss: 2.1672472107794976

Epoch: 6| Step: 4
Training loss: 2.700012683868408
Validation loss: 2.1467625658999205

Epoch: 6| Step: 5
Training loss: 2.314237117767334
Validation loss: 2.158214467827992

Epoch: 6| Step: 6
Training loss: 2.9740219116210938
Validation loss: 2.165809328838061

Epoch: 6| Step: 7
Training loss: 2.359485626220703
Validation loss: 2.1317850415424635

Epoch: 6| Step: 8
Training loss: 1.951430320739746
Validation loss: 2.14747215086414

Epoch: 6| Step: 9
Training loss: 3.1106183528900146
Validation loss: 2.1419838474642847

Epoch: 6| Step: 10
Training loss: 1.9496259689331055
Validation loss: 2.1329031426419496

Epoch: 6| Step: 11
Training loss: 2.839057683944702
Validation loss: 2.1389557366730063

Epoch: 6| Step: 12
Training loss: 2.394641876220703
Validation loss: 2.147999737852363

Epoch: 6| Step: 13
Training loss: 1.960816740989685
Validation loss: 2.1359133438397477

Epoch: 24| Step: 0
Training loss: 2.514341354370117
Validation loss: 2.1412567553981656

Epoch: 6| Step: 1
Training loss: 1.9254696369171143
Validation loss: 2.15020433292594

Epoch: 6| Step: 2
Training loss: 2.4345271587371826
Validation loss: 2.1529054052086285

Epoch: 6| Step: 3
Training loss: 2.755261182785034
Validation loss: 2.144586842547181

Epoch: 6| Step: 4
Training loss: 2.526904821395874
Validation loss: 2.1498491969159854

Epoch: 6| Step: 5
Training loss: 1.7394905090332031
Validation loss: 2.130181645834318

Epoch: 6| Step: 6
Training loss: 2.5590224266052246
Validation loss: 2.134501528996293

Epoch: 6| Step: 7
Training loss: 2.239753007888794
Validation loss: 2.1355881306432907

Epoch: 6| Step: 8
Training loss: 2.8093667030334473
Validation loss: 2.1423045345531997

Epoch: 6| Step: 9
Training loss: 3.4104013442993164
Validation loss: 2.1542871562383508

Epoch: 6| Step: 10
Training loss: 2.528599262237549
Validation loss: 2.1416036749398835

Epoch: 6| Step: 11
Training loss: 2.6138458251953125
Validation loss: 2.1243292567550496

Epoch: 6| Step: 12
Training loss: 1.795933723449707
Validation loss: 2.1470190632727837

Epoch: 6| Step: 13
Training loss: 2.950327157974243
Validation loss: 2.137426196887929

Epoch: 25| Step: 0
Training loss: 2.667494297027588
Validation loss: 2.1521728372061126

Epoch: 6| Step: 1
Training loss: 2.1362152099609375
Validation loss: 2.1393632863157537

Epoch: 6| Step: 2
Training loss: 2.344148874282837
Validation loss: 2.1434026456648305

Epoch: 6| Step: 3
Training loss: 2.335146903991699
Validation loss: 2.1319450075908373

Epoch: 6| Step: 4
Training loss: 2.470066547393799
Validation loss: 2.140153534950749

Epoch: 6| Step: 5
Training loss: 2.631786823272705
Validation loss: 2.132438294349178

Epoch: 6| Step: 6
Training loss: 2.0582938194274902
Validation loss: 2.1460017158139135

Epoch: 6| Step: 7
Training loss: 3.1174044609069824
Validation loss: 2.1478002917382026

Epoch: 6| Step: 8
Training loss: 2.5351016521453857
Validation loss: 2.1346815504053587

Epoch: 6| Step: 9
Training loss: 2.6200690269470215
Validation loss: 2.1533977498290358

Epoch: 6| Step: 10
Training loss: 2.2975635528564453
Validation loss: 2.140703466630751

Epoch: 6| Step: 11
Training loss: 1.9356000423431396
Validation loss: 2.12275791680941

Epoch: 6| Step: 12
Training loss: 2.8363823890686035
Validation loss: 2.1434695143853464

Epoch: 6| Step: 13
Training loss: 2.592142105102539
Validation loss: 2.147534970314272

Epoch: 26| Step: 0
Training loss: 2.323988199234009
Validation loss: 2.147907882608393

Epoch: 6| Step: 1
Training loss: 2.080291509628296
Validation loss: 2.1329250592057423

Epoch: 6| Step: 2
Training loss: 3.0307798385620117
Validation loss: 2.1384733735874133

Epoch: 6| Step: 3
Training loss: 2.7142233848571777
Validation loss: 2.1443144788024244

Epoch: 6| Step: 4
Training loss: 2.312633514404297
Validation loss: 2.152233409625228

Epoch: 6| Step: 5
Training loss: 2.464803695678711
Validation loss: 2.1522381113421534

Epoch: 6| Step: 6
Training loss: 2.7893972396850586
Validation loss: 2.140839389575425

Epoch: 6| Step: 7
Training loss: 2.77592396736145
Validation loss: 2.1399682350056146

Epoch: 6| Step: 8
Training loss: 2.777757167816162
Validation loss: 2.1647292260200746

Epoch: 6| Step: 9
Training loss: 2.0711724758148193
Validation loss: 2.154115541006929

Epoch: 6| Step: 10
Training loss: 1.9125574827194214
Validation loss: 2.152989346493957

Epoch: 6| Step: 11
Training loss: 2.5616114139556885
Validation loss: 2.1546431433769966

Epoch: 6| Step: 12
Training loss: 2.1473469734191895
Validation loss: 2.147865287719234

Epoch: 6| Step: 13
Training loss: 2.2281723022460938
Validation loss: 2.165807698362617

Epoch: 27| Step: 0
Training loss: 1.7395354509353638
Validation loss: 2.1561714833782566

Epoch: 6| Step: 1
Training loss: 2.3339216709136963
Validation loss: 2.14339029917153

Epoch: 6| Step: 2
Training loss: 2.262516975402832
Validation loss: 2.1488104379305275

Epoch: 6| Step: 3
Training loss: 2.779715061187744
Validation loss: 2.1586777728091002

Epoch: 6| Step: 4
Training loss: 2.309645652770996
Validation loss: 2.1389454385285736

Epoch: 6| Step: 5
Training loss: 2.7037172317504883
Validation loss: 2.144290595926264

Epoch: 6| Step: 6
Training loss: 2.5921742916107178
Validation loss: 2.1557552429937545

Epoch: 6| Step: 7
Training loss: 1.5890851020812988
Validation loss: 2.1381558602856052

Epoch: 6| Step: 8
Training loss: 3.036794662475586
Validation loss: 2.1378728164139615

Epoch: 6| Step: 9
Training loss: 2.547762155532837
Validation loss: 2.160401016153315

Epoch: 6| Step: 10
Training loss: 2.6328177452087402
Validation loss: 2.1267645948676654

Epoch: 6| Step: 11
Training loss: 2.0669636726379395
Validation loss: 2.1401863713418283

Epoch: 6| Step: 12
Training loss: 3.2700443267822266
Validation loss: 2.124150283875004

Epoch: 6| Step: 13
Training loss: 2.353172540664673
Validation loss: 2.1468262467333066

Epoch: 28| Step: 0
Training loss: 3.131009340286255
Validation loss: 2.1420574290778047

Epoch: 6| Step: 1
Training loss: 1.943735122680664
Validation loss: 2.135042982716714

Epoch: 6| Step: 2
Training loss: 2.213007688522339
Validation loss: 2.142084401140931

Epoch: 6| Step: 3
Training loss: 2.2767629623413086
Validation loss: 2.121508559873027

Epoch: 6| Step: 4
Training loss: 2.540802478790283
Validation loss: 2.1357435282840522

Epoch: 6| Step: 5
Training loss: 2.336580276489258
Validation loss: 2.1317181459037204

Epoch: 6| Step: 6
Training loss: 1.5704858303070068
Validation loss: 2.1242042305648967

Epoch: 6| Step: 7
Training loss: 2.5340991020202637
Validation loss: 2.133359352747599

Epoch: 6| Step: 8
Training loss: 2.517587661743164
Validation loss: 2.1266985593303556

Epoch: 6| Step: 9
Training loss: 2.4645938873291016
Validation loss: 2.1199658711751304

Epoch: 6| Step: 10
Training loss: 2.5268938541412354
Validation loss: 2.132552812176366

Epoch: 6| Step: 11
Training loss: 2.4615416526794434
Validation loss: 2.1188043317487164

Epoch: 6| Step: 12
Training loss: 3.051203489303589
Validation loss: 2.1369725094046643

Epoch: 6| Step: 13
Training loss: 2.828427314758301
Validation loss: 2.130381384203511

Epoch: 29| Step: 0
Training loss: 2.0589075088500977
Validation loss: 2.1351272521480436

Epoch: 6| Step: 1
Training loss: 2.503537178039551
Validation loss: 2.1195225895092054

Epoch: 6| Step: 2
Training loss: 2.727245807647705
Validation loss: 2.1372457191508305

Epoch: 6| Step: 3
Training loss: 3.0967507362365723
Validation loss: 2.1340579294389292

Epoch: 6| Step: 4
Training loss: 2.7443974018096924
Validation loss: 2.1375062375940304

Epoch: 6| Step: 5
Training loss: 2.659507989883423
Validation loss: 2.138792581455682

Epoch: 6| Step: 6
Training loss: 1.954697847366333
Validation loss: 2.132165462740006

Epoch: 6| Step: 7
Training loss: 2.737119436264038
Validation loss: 2.139183823780347

Epoch: 6| Step: 8
Training loss: 2.046309471130371
Validation loss: 2.1375337390489477

Epoch: 6| Step: 9
Training loss: 1.9608697891235352
Validation loss: 2.1335065134109987

Epoch: 6| Step: 10
Training loss: 2.3498594760894775
Validation loss: 2.136522346927274

Epoch: 6| Step: 11
Training loss: 2.4148874282836914
Validation loss: 2.132354005690544

Epoch: 6| Step: 12
Training loss: 2.424314498901367
Validation loss: 2.1500380475033998

Epoch: 6| Step: 13
Training loss: 2.6796023845672607
Validation loss: 2.153130744093208

Epoch: 30| Step: 0
Training loss: 2.061354637145996
Validation loss: 2.1364419434660222

Epoch: 6| Step: 1
Training loss: 1.42567777633667
Validation loss: 2.1464581361380954

Epoch: 6| Step: 2
Training loss: 2.907287120819092
Validation loss: 2.148155848185221

Epoch: 6| Step: 3
Training loss: 2.794713020324707
Validation loss: 2.1416551400256414

Epoch: 6| Step: 4
Training loss: 2.9087424278259277
Validation loss: 2.149745488679537

Epoch: 6| Step: 5
Training loss: 1.7396092414855957
Validation loss: 2.1425148517854753

Epoch: 6| Step: 6
Training loss: 3.182687759399414
Validation loss: 2.1373495209601616

Epoch: 6| Step: 7
Training loss: 2.3618268966674805
Validation loss: 2.1325744082850795

Epoch: 6| Step: 8
Training loss: 1.8395979404449463
Validation loss: 2.1292989510361866

Epoch: 6| Step: 9
Training loss: 2.2500226497650146
Validation loss: 2.13881274448928

Epoch: 6| Step: 10
Training loss: 2.644016742706299
Validation loss: 2.1278634096986506

Epoch: 6| Step: 11
Training loss: 2.5566601753234863
Validation loss: 2.1234798277578046

Epoch: 6| Step: 12
Training loss: 2.60581636428833
Validation loss: 2.134683080898818

Epoch: 6| Step: 13
Training loss: 2.9668617248535156
Validation loss: 2.1279694931481474

Epoch: 31| Step: 0
Training loss: 2.5485153198242188
Validation loss: 2.127163892151207

Epoch: 6| Step: 1
Training loss: 2.939739942550659
Validation loss: 2.1366656800752044

Epoch: 6| Step: 2
Training loss: 1.6777749061584473
Validation loss: 2.1145149610375844

Epoch: 6| Step: 3
Training loss: 2.146800994873047
Validation loss: 2.1250151664979997

Epoch: 6| Step: 4
Training loss: 2.245739459991455
Validation loss: 2.1394222423594487

Epoch: 6| Step: 5
Training loss: 1.6191949844360352
Validation loss: 2.1273126089444725

Epoch: 6| Step: 6
Training loss: 2.1614179611206055
Validation loss: 2.121504863103231

Epoch: 6| Step: 7
Training loss: 2.488114833831787
Validation loss: 2.115934648821431

Epoch: 6| Step: 8
Training loss: 2.496891975402832
Validation loss: 2.1314748384619273

Epoch: 6| Step: 9
Training loss: 2.9933784008026123
Validation loss: 2.1311456464952037

Epoch: 6| Step: 10
Training loss: 2.597550868988037
Validation loss: 2.1245792681171047

Epoch: 6| Step: 11
Training loss: 2.559512138366699
Validation loss: 2.1236889849426928

Epoch: 6| Step: 12
Training loss: 2.9929354190826416
Validation loss: 2.125997704844321

Epoch: 6| Step: 13
Training loss: 2.230226993560791
Validation loss: 2.1236670030060636

Epoch: 32| Step: 0
Training loss: 2.7254111766815186
Validation loss: 2.1419270218059583

Epoch: 6| Step: 1
Training loss: 2.3117542266845703
Validation loss: 2.121135719360844

Epoch: 6| Step: 2
Training loss: 2.475914239883423
Validation loss: 2.1408329663738126

Epoch: 6| Step: 3
Training loss: 2.236064910888672
Validation loss: 2.1441216340629

Epoch: 6| Step: 4
Training loss: 2.0525028705596924
Validation loss: 2.1410723373454106

Epoch: 6| Step: 5
Training loss: 3.433323383331299
Validation loss: 2.1292733223207536

Epoch: 6| Step: 6
Training loss: 2.4997806549072266
Validation loss: 2.119711632369667

Epoch: 6| Step: 7
Training loss: 2.059262275695801
Validation loss: 2.1547933804091586

Epoch: 6| Step: 8
Training loss: 2.0959062576293945
Validation loss: 2.1448023114153134

Epoch: 6| Step: 9
Training loss: 2.0503616333007812
Validation loss: 2.127952294964944

Epoch: 6| Step: 10
Training loss: 2.837191104888916
Validation loss: 2.1331964590216197

Epoch: 6| Step: 11
Training loss: 2.982994318008423
Validation loss: 2.1287711794658373

Epoch: 6| Step: 12
Training loss: 1.7433587312698364
Validation loss: 2.130195659975852

Epoch: 6| Step: 13
Training loss: 2.1876461505889893
Validation loss: 2.1362251056137906

Epoch: 33| Step: 0
Training loss: 2.1628851890563965
Validation loss: 2.119345559868761

Epoch: 6| Step: 1
Training loss: 2.8621747493743896
Validation loss: 2.1426080811408257

Epoch: 6| Step: 2
Training loss: 2.3510122299194336
Validation loss: 2.132429479270853

Epoch: 6| Step: 3
Training loss: 2.321876049041748
Validation loss: 2.1386280136723674

Epoch: 6| Step: 4
Training loss: 3.280802011489868
Validation loss: 2.1499965178069247

Epoch: 6| Step: 5
Training loss: 2.854841709136963
Validation loss: 2.125108172816615

Epoch: 6| Step: 6
Training loss: 2.389160394668579
Validation loss: 2.142873300019131

Epoch: 6| Step: 7
Training loss: 1.9839504957199097
Validation loss: 2.131800607968402

Epoch: 6| Step: 8
Training loss: 2.5015506744384766
Validation loss: 2.1138250481697822

Epoch: 6| Step: 9
Training loss: 2.0468335151672363
Validation loss: 2.11910500577701

Epoch: 6| Step: 10
Training loss: 2.0546884536743164
Validation loss: 2.127792754480916

Epoch: 6| Step: 11
Training loss: 2.4428229331970215
Validation loss: 2.127415978780357

Epoch: 6| Step: 12
Training loss: 2.137603282928467
Validation loss: 2.1141058885922996

Epoch: 6| Step: 13
Training loss: 2.0410423278808594
Validation loss: 2.115829049900014

Epoch: 34| Step: 0
Training loss: 2.4710752964019775
Validation loss: 2.133786436050169

Epoch: 6| Step: 1
Training loss: 2.694645404815674
Validation loss: 2.1321842670440674

Epoch: 6| Step: 2
Training loss: 2.4950592517852783
Validation loss: 2.1180155277252197

Epoch: 6| Step: 3
Training loss: 2.0325632095336914
Validation loss: 2.1115565094896542

Epoch: 6| Step: 4
Training loss: 2.345917224884033
Validation loss: 2.107324751474524

Epoch: 6| Step: 5
Training loss: 2.5277061462402344
Validation loss: 2.117907661263661

Epoch: 6| Step: 6
Training loss: 2.8837838172912598
Validation loss: 2.1116793668398293

Epoch: 6| Step: 7
Training loss: 2.206453561782837
Validation loss: 2.093841906516783

Epoch: 6| Step: 8
Training loss: 2.2017173767089844
Validation loss: 2.0919174507100093

Epoch: 6| Step: 9
Training loss: 1.9875094890594482
Validation loss: 2.099573414812806

Epoch: 6| Step: 10
Training loss: 2.197117328643799
Validation loss: 2.075645908232658

Epoch: 6| Step: 11
Training loss: 2.6666419506073
Validation loss: 2.074836893748212

Epoch: 6| Step: 12
Training loss: 2.6399190425872803
Validation loss: 2.1090932840942056

Epoch: 6| Step: 13
Training loss: 2.503434181213379
Validation loss: 2.096860859983711

Epoch: 35| Step: 0
Training loss: 2.5638267993927
Validation loss: 2.103526320508731

Epoch: 6| Step: 1
Training loss: 2.1818530559539795
Validation loss: 2.103788500191063

Epoch: 6| Step: 2
Training loss: 2.4043495655059814
Validation loss: 2.0935454701864593

Epoch: 6| Step: 3
Training loss: 2.742840528488159
Validation loss: 2.0848385467324206

Epoch: 6| Step: 4
Training loss: 2.2967031002044678
Validation loss: 2.0968472393610145

Epoch: 6| Step: 5
Training loss: 2.257129192352295
Validation loss: 2.091205290568772

Epoch: 6| Step: 6
Training loss: 3.0279321670532227
Validation loss: 2.1052720392903974

Epoch: 6| Step: 7
Training loss: 2.19160795211792
Validation loss: 2.1120495270657282

Epoch: 6| Step: 8
Training loss: 1.8244445323944092
Validation loss: 2.1221907228551884

Epoch: 6| Step: 9
Training loss: 1.9689072370529175
Validation loss: 2.098778822088754

Epoch: 6| Step: 10
Training loss: 1.8917698860168457
Validation loss: 2.109639972768804

Epoch: 6| Step: 11
Training loss: 2.6798248291015625
Validation loss: 2.1145461323440715

Epoch: 6| Step: 12
Training loss: 2.938718795776367
Validation loss: 2.109792714477867

Epoch: 6| Step: 13
Training loss: 2.5723912715911865
Validation loss: 2.1092680269672024

Epoch: 36| Step: 0
Training loss: 2.240172863006592
Validation loss: 2.119429631899762

Epoch: 6| Step: 1
Training loss: 2.6324145793914795
Validation loss: 2.117792075680148

Epoch: 6| Step: 2
Training loss: 2.9865307807922363
Validation loss: 2.1054242528894895

Epoch: 6| Step: 3
Training loss: 3.1316475868225098
Validation loss: 2.1032701153909006

Epoch: 6| Step: 4
Training loss: 1.5622386932373047
Validation loss: 2.109154308995893

Epoch: 6| Step: 5
Training loss: 1.8365085124969482
Validation loss: 2.1184034603898243

Epoch: 6| Step: 6
Training loss: 1.9124332666397095
Validation loss: 2.1067214729965373

Epoch: 6| Step: 7
Training loss: 2.441683292388916
Validation loss: 2.1137177252000376

Epoch: 6| Step: 8
Training loss: 2.590334415435791
Validation loss: 2.1183173066826275

Epoch: 6| Step: 9
Training loss: 2.6486988067626953
Validation loss: 2.1134598062884424

Epoch: 6| Step: 10
Training loss: 2.2271728515625
Validation loss: 2.1365162146988737

Epoch: 6| Step: 11
Training loss: 2.4286861419677734
Validation loss: 2.127115995653214

Epoch: 6| Step: 12
Training loss: 2.5936403274536133
Validation loss: 2.1342081818529355

Epoch: 6| Step: 13
Training loss: 1.9783971309661865
Validation loss: 2.126895191848919

Epoch: 37| Step: 0
Training loss: 1.7859052419662476
Validation loss: 2.106134542854883

Epoch: 6| Step: 1
Training loss: 3.195838451385498
Validation loss: 2.1280181971929406

Epoch: 6| Step: 2
Training loss: 2.4136464595794678
Validation loss: 2.116541606123729

Epoch: 6| Step: 3
Training loss: 2.5609023571014404
Validation loss: 2.108871611215735

Epoch: 6| Step: 4
Training loss: 2.4085335731506348
Validation loss: 2.107752280850564

Epoch: 6| Step: 5
Training loss: 2.0455493927001953
Validation loss: 2.1217361419431624

Epoch: 6| Step: 6
Training loss: 2.4827351570129395
Validation loss: 2.1301300128300986

Epoch: 6| Step: 7
Training loss: 2.3339059352874756
Validation loss: 2.1376677046539965

Epoch: 6| Step: 8
Training loss: 2.493126630783081
Validation loss: 2.1369711096568773

Epoch: 6| Step: 9
Training loss: 1.7213999032974243
Validation loss: 2.108209515130648

Epoch: 6| Step: 10
Training loss: 2.0254573822021484
Validation loss: 2.1307222996988604

Epoch: 6| Step: 11
Training loss: 2.7575485706329346
Validation loss: 2.1548571099517164

Epoch: 6| Step: 12
Training loss: 2.456483840942383
Validation loss: 2.1019610064004057

Epoch: 6| Step: 13
Training loss: 2.9229819774627686
Validation loss: 2.1019834882469586

Epoch: 38| Step: 0
Training loss: 2.6228294372558594
Validation loss: 2.132199413032942

Epoch: 6| Step: 1
Training loss: 1.9489223957061768
Validation loss: 2.1148140686814503

Epoch: 6| Step: 2
Training loss: 2.3557300567626953
Validation loss: 2.113699789970152

Epoch: 6| Step: 3
Training loss: 2.9610326290130615
Validation loss: 2.1104590956882765

Epoch: 6| Step: 4
Training loss: 2.7953100204467773
Validation loss: 2.124684915747694

Epoch: 6| Step: 5
Training loss: 2.1852662563323975
Validation loss: 2.0920948084964546

Epoch: 6| Step: 6
Training loss: 2.0597500801086426
Validation loss: 2.118725476726409

Epoch: 6| Step: 7
Training loss: 1.971163034439087
Validation loss: 2.0991664189164356

Epoch: 6| Step: 8
Training loss: 2.2802560329437256
Validation loss: 2.10599870322853

Epoch: 6| Step: 9
Training loss: 2.455660343170166
Validation loss: 2.1181460452336136

Epoch: 6| Step: 10
Training loss: 3.09273099899292
Validation loss: 2.116621025146977

Epoch: 6| Step: 11
Training loss: 1.7577930688858032
Validation loss: 2.1059881999928463

Epoch: 6| Step: 12
Training loss: 2.2606916427612305
Validation loss: 2.0953726845402874

Epoch: 6| Step: 13
Training loss: 2.638546943664551
Validation loss: 2.100231762855284

Epoch: 39| Step: 0
Training loss: 2.5309231281280518
Validation loss: 2.1069722137143536

Epoch: 6| Step: 1
Training loss: 1.919867992401123
Validation loss: 2.1122438151349305

Epoch: 6| Step: 2
Training loss: 1.8277312517166138
Validation loss: 2.095211704572042

Epoch: 6| Step: 3
Training loss: 2.444589138031006
Validation loss: 2.0937455443925757

Epoch: 6| Step: 4
Training loss: 2.410917282104492
Validation loss: 2.1135230769393263

Epoch: 6| Step: 5
Training loss: 3.3880860805511475
Validation loss: 2.101801895326184

Epoch: 6| Step: 6
Training loss: 2.164583921432495
Validation loss: 2.118416400365932

Epoch: 6| Step: 7
Training loss: 2.4418821334838867
Validation loss: 2.091111303657614

Epoch: 6| Step: 8
Training loss: 2.3258914947509766
Validation loss: 2.1168751819159395

Epoch: 6| Step: 9
Training loss: 2.21044659614563
Validation loss: 2.0961258103770595

Epoch: 6| Step: 10
Training loss: 2.4055557250976562
Validation loss: 2.0987762687026814

Epoch: 6| Step: 11
Training loss: 2.3796191215515137
Validation loss: 2.091114985045566

Epoch: 6| Step: 12
Training loss: 2.2543599605560303
Validation loss: 2.110157682049659

Epoch: 6| Step: 13
Training loss: 2.662907838821411
Validation loss: 2.0906058331971527

Epoch: 40| Step: 0
Training loss: 2.1717453002929688
Validation loss: 2.0837437619445143

Epoch: 6| Step: 1
Training loss: 2.414314031600952
Validation loss: 2.108499014249412

Epoch: 6| Step: 2
Training loss: 2.296506881713867
Validation loss: 2.12154988063279

Epoch: 6| Step: 3
Training loss: 3.487412214279175
Validation loss: 2.0890587504192064

Epoch: 6| Step: 4
Training loss: 2.3494155406951904
Validation loss: 2.091565342359645

Epoch: 6| Step: 5
Training loss: 2.007483959197998
Validation loss: 2.08406630510925

Epoch: 6| Step: 6
Training loss: 1.5644352436065674
Validation loss: 2.101877894452823

Epoch: 6| Step: 7
Training loss: 1.7700883150100708
Validation loss: 2.100568499616397

Epoch: 6| Step: 8
Training loss: 2.294382333755493
Validation loss: 2.1162543373723186

Epoch: 6| Step: 9
Training loss: 2.6926321983337402
Validation loss: 2.0800880847438687

Epoch: 6| Step: 10
Training loss: 2.8589844703674316
Validation loss: 2.0827468595197125

Epoch: 6| Step: 11
Training loss: 3.02101469039917
Validation loss: 2.0855069545007523

Epoch: 6| Step: 12
Training loss: 1.7251362800598145
Validation loss: 2.094056596038162

Epoch: 6| Step: 13
Training loss: 2.6002557277679443
Validation loss: 2.086688332660224

Epoch: 41| Step: 0
Training loss: 2.9782941341400146
Validation loss: 2.08781038689357

Epoch: 6| Step: 1
Training loss: 1.730006217956543
Validation loss: 2.06958157016385

Epoch: 6| Step: 2
Training loss: 1.9652013778686523
Validation loss: 2.1005337379312

Epoch: 6| Step: 3
Training loss: 2.3585519790649414
Validation loss: 2.0847418231348835

Epoch: 6| Step: 4
Training loss: 2.044837236404419
Validation loss: 2.0883786550132175

Epoch: 6| Step: 5
Training loss: 2.6032071113586426
Validation loss: 2.0861304549760717

Epoch: 6| Step: 6
Training loss: 2.026651620864868
Validation loss: 2.0780989341838385

Epoch: 6| Step: 7
Training loss: 2.201322078704834
Validation loss: 2.072089223451512

Epoch: 6| Step: 8
Training loss: 2.9630889892578125
Validation loss: 2.0823560863412838

Epoch: 6| Step: 9
Training loss: 2.008023738861084
Validation loss: 2.0814885759866364

Epoch: 6| Step: 10
Training loss: 2.3603835105895996
Validation loss: 2.085737536030431

Epoch: 6| Step: 11
Training loss: 2.9051194190979004
Validation loss: 2.068528690645772

Epoch: 6| Step: 12
Training loss: 2.1812548637390137
Validation loss: 2.0694648834966842

Epoch: 6| Step: 13
Training loss: 3.117647171020508
Validation loss: 2.0760309324469617

Epoch: 42| Step: 0
Training loss: 2.4026031494140625
Validation loss: 2.077299976861605

Epoch: 6| Step: 1
Training loss: 1.5827789306640625
Validation loss: 2.0754741930192515

Epoch: 6| Step: 2
Training loss: 1.860619068145752
Validation loss: 2.07615339884194

Epoch: 6| Step: 3
Training loss: 1.9642643928527832
Validation loss: 2.0892072826303463

Epoch: 6| Step: 4
Training loss: 3.10070538520813
Validation loss: 2.0637258406608336

Epoch: 6| Step: 5
Training loss: 2.0819754600524902
Validation loss: 2.0854437915227746

Epoch: 6| Step: 6
Training loss: 2.965062141418457
Validation loss: 2.075781919622934

Epoch: 6| Step: 7
Training loss: 3.065939426422119
Validation loss: 2.086640086225284

Epoch: 6| Step: 8
Training loss: 2.087125301361084
Validation loss: 2.085771596559914

Epoch: 6| Step: 9
Training loss: 2.6920254230499268
Validation loss: 2.093613209262971

Epoch: 6| Step: 10
Training loss: 2.0393922328948975
Validation loss: 2.067524392117736

Epoch: 6| Step: 11
Training loss: 2.687584400177002
Validation loss: 2.087973278055909

Epoch: 6| Step: 12
Training loss: 2.3149075508117676
Validation loss: 2.0715767901430846

Epoch: 6| Step: 13
Training loss: 2.0142436027526855
Validation loss: 2.0570820326446206

Epoch: 43| Step: 0
Training loss: 1.947134256362915
Validation loss: 2.068436926411044

Epoch: 6| Step: 1
Training loss: 1.936009168624878
Validation loss: 2.0710645183440177

Epoch: 6| Step: 2
Training loss: 2.562344551086426
Validation loss: 2.0732028817617767

Epoch: 6| Step: 3
Training loss: 2.366307020187378
Validation loss: 2.0834495508542625

Epoch: 6| Step: 4
Training loss: 2.282538890838623
Validation loss: 2.072818563830468

Epoch: 6| Step: 5
Training loss: 2.732539176940918
Validation loss: 2.075163955329567

Epoch: 6| Step: 6
Training loss: 2.80609130859375
Validation loss: 2.0811536440285305

Epoch: 6| Step: 7
Training loss: 3.102287769317627
Validation loss: 2.0865994653394146

Epoch: 6| Step: 8
Training loss: 1.8675868511199951
Validation loss: 2.0607251044242614

Epoch: 6| Step: 9
Training loss: 2.452727794647217
Validation loss: 2.075518182528916

Epoch: 6| Step: 10
Training loss: 2.438163995742798
Validation loss: 2.0661178096648185

Epoch: 6| Step: 11
Training loss: 2.1229188442230225
Validation loss: 2.082757052554879

Epoch: 6| Step: 12
Training loss: 1.9705476760864258
Validation loss: 2.0801392319381877

Epoch: 6| Step: 13
Training loss: 2.496098279953003
Validation loss: 2.0648077790455153

Epoch: 44| Step: 0
Training loss: 2.2153987884521484
Validation loss: 2.0686729313224874

Epoch: 6| Step: 1
Training loss: 2.5410494804382324
Validation loss: 2.0760250450462423

Epoch: 6| Step: 2
Training loss: 2.44319486618042
Validation loss: 2.0620000413669053

Epoch: 6| Step: 3
Training loss: 2.8140902519226074
Validation loss: 2.077109662435388

Epoch: 6| Step: 4
Training loss: 2.6141414642333984
Validation loss: 2.0641908696902695

Epoch: 6| Step: 5
Training loss: 2.0125532150268555
Validation loss: 2.0636570992008334

Epoch: 6| Step: 6
Training loss: 1.6450687646865845
Validation loss: 2.065596140841002

Epoch: 6| Step: 7
Training loss: 1.9152828454971313
Validation loss: 2.0646918294250325

Epoch: 6| Step: 8
Training loss: 2.0754404067993164
Validation loss: 2.069466430653808

Epoch: 6| Step: 9
Training loss: 2.519252300262451
Validation loss: 2.077992175215034

Epoch: 6| Step: 10
Training loss: 2.7513206005096436
Validation loss: 2.0655709299989926

Epoch: 6| Step: 11
Training loss: 2.0637989044189453
Validation loss: 2.067116291292252

Epoch: 6| Step: 12
Training loss: 2.6696386337280273
Validation loss: 2.0738212344467

Epoch: 6| Step: 13
Training loss: 2.84995436668396
Validation loss: 2.0536532017492477

Epoch: 45| Step: 0
Training loss: 2.071953535079956
Validation loss: 2.0695761480639057

Epoch: 6| Step: 1
Training loss: 2.7428507804870605
Validation loss: 2.0404882251575427

Epoch: 6| Step: 2
Training loss: 2.8224105834960938
Validation loss: 2.05240245403782

Epoch: 6| Step: 3
Training loss: 1.8804088830947876
Validation loss: 2.051010253608868

Epoch: 6| Step: 4
Training loss: 1.9255938529968262
Validation loss: 2.0594374774604716

Epoch: 6| Step: 5
Training loss: 1.82492196559906
Validation loss: 2.067216073313067

Epoch: 6| Step: 6
Training loss: 2.167872428894043
Validation loss: 2.0665893541869296

Epoch: 6| Step: 7
Training loss: 2.8100976943969727
Validation loss: 2.079569010324376

Epoch: 6| Step: 8
Training loss: 2.1466383934020996
Validation loss: 2.088782407904184

Epoch: 6| Step: 9
Training loss: 2.597595691680908
Validation loss: 2.068888541190855

Epoch: 6| Step: 10
Training loss: 1.4564299583435059
Validation loss: 2.07217312371859

Epoch: 6| Step: 11
Training loss: 2.908710241317749
Validation loss: 2.0879661152439732

Epoch: 6| Step: 12
Training loss: 2.7749972343444824
Validation loss: 2.0781603936226136

Epoch: 6| Step: 13
Training loss: 2.6238856315612793
Validation loss: 2.076608178436115

Epoch: 46| Step: 0
Training loss: 2.2206127643585205
Validation loss: 2.075019854371266

Epoch: 6| Step: 1
Training loss: 2.4548873901367188
Validation loss: 2.066021265522126

Epoch: 6| Step: 2
Training loss: 2.947981357574463
Validation loss: 2.0839685752827632

Epoch: 6| Step: 3
Training loss: 2.615861177444458
Validation loss: 2.057516057004211

Epoch: 6| Step: 4
Training loss: 2.984441041946411
Validation loss: 2.0618465305656515

Epoch: 6| Step: 5
Training loss: 2.187622547149658
Validation loss: 2.05972873010943

Epoch: 6| Step: 6
Training loss: 2.209110975265503
Validation loss: 2.0434818114003828

Epoch: 6| Step: 7
Training loss: 1.875535488128662
Validation loss: 2.0561125009290633

Epoch: 6| Step: 8
Training loss: 2.619565010070801
Validation loss: 2.055667063241364

Epoch: 6| Step: 9
Training loss: 1.9711806774139404
Validation loss: 2.0336395181635374

Epoch: 6| Step: 10
Training loss: 2.1025257110595703
Validation loss: 2.0418326803433

Epoch: 6| Step: 11
Training loss: 2.2727179527282715
Validation loss: 2.0570078588301137

Epoch: 6| Step: 12
Training loss: 1.8554797172546387
Validation loss: 2.0400622275567826

Epoch: 6| Step: 13
Training loss: 2.7791857719421387
Validation loss: 2.0487775533430037

Epoch: 47| Step: 0
Training loss: 1.912016749382019
Validation loss: 2.0698184608131327

Epoch: 6| Step: 1
Training loss: 1.8278489112854004
Validation loss: 2.0525300079776394

Epoch: 6| Step: 2
Training loss: 2.4777729511260986
Validation loss: 2.055424513355378

Epoch: 6| Step: 3
Training loss: 2.0548064708709717
Validation loss: 2.0516236828219507

Epoch: 6| Step: 4
Training loss: 2.967536211013794
Validation loss: 2.055583938475578

Epoch: 6| Step: 5
Training loss: 1.7741036415100098
Validation loss: 2.0507587796898297

Epoch: 6| Step: 6
Training loss: 2.330563545227051
Validation loss: 2.027597560677477

Epoch: 6| Step: 7
Training loss: 2.4732673168182373
Validation loss: 2.0552149126606603

Epoch: 6| Step: 8
Training loss: 2.5033481121063232
Validation loss: 2.0552299727675734

Epoch: 6| Step: 9
Training loss: 2.548492193222046
Validation loss: 2.062532719745431

Epoch: 6| Step: 10
Training loss: 2.7613391876220703
Validation loss: 2.0628338706108833

Epoch: 6| Step: 11
Training loss: 2.315376043319702
Validation loss: 2.0486245360425723

Epoch: 6| Step: 12
Training loss: 1.9368518590927124
Validation loss: 2.062582513337494

Epoch: 6| Step: 13
Training loss: 3.0317459106445312
Validation loss: 2.051085202924667

Epoch: 48| Step: 0
Training loss: 2.046699047088623
Validation loss: 2.055462973092192

Epoch: 6| Step: 1
Training loss: 2.4426114559173584
Validation loss: 2.0592696846172376

Epoch: 6| Step: 2
Training loss: 2.442000389099121
Validation loss: 2.0355497534557054

Epoch: 6| Step: 3
Training loss: 2.6817026138305664
Validation loss: 2.0725658093729327

Epoch: 6| Step: 4
Training loss: 2.051358699798584
Validation loss: 2.04441447283632

Epoch: 6| Step: 5
Training loss: 1.400637149810791
Validation loss: 2.045084781544183

Epoch: 6| Step: 6
Training loss: 2.2321691513061523
Validation loss: 2.0550878368398195

Epoch: 6| Step: 7
Training loss: 2.6415228843688965
Validation loss: 2.0446783047850414

Epoch: 6| Step: 8
Training loss: 2.3722119331359863
Validation loss: 2.0364965841334355

Epoch: 6| Step: 9
Training loss: 2.479684829711914
Validation loss: 2.041694574458625

Epoch: 6| Step: 10
Training loss: 2.5604147911071777
Validation loss: 2.0418785413106284

Epoch: 6| Step: 11
Training loss: 2.0169174671173096
Validation loss: 2.0476891584293817

Epoch: 6| Step: 12
Training loss: 2.3151469230651855
Validation loss: 2.044488483859647

Epoch: 6| Step: 13
Training loss: 3.427138566970825
Validation loss: 2.0463993549346924

Epoch: 49| Step: 0
Training loss: 3.234795570373535
Validation loss: 2.054367032102359

Epoch: 6| Step: 1
Training loss: 1.7772022485733032
Validation loss: 2.0576618948290424

Epoch: 6| Step: 2
Training loss: 2.216526985168457
Validation loss: 2.044228558899254

Epoch: 6| Step: 3
Training loss: 2.332850933074951
Validation loss: 2.035481906706287

Epoch: 6| Step: 4
Training loss: 1.9492456912994385
Validation loss: 2.0480812262463313

Epoch: 6| Step: 5
Training loss: 1.985367774963379
Validation loss: 2.0314203039292367

Epoch: 6| Step: 6
Training loss: 2.389514923095703
Validation loss: 2.05480618117958

Epoch: 6| Step: 7
Training loss: 1.4737287759780884
Validation loss: 2.0159723451060634

Epoch: 6| Step: 8
Training loss: 2.9609248638153076
Validation loss: 2.034336587434174

Epoch: 6| Step: 9
Training loss: 2.9697799682617188
Validation loss: 2.0311000629137923

Epoch: 6| Step: 10
Training loss: 2.284996271133423
Validation loss: 2.025870510326919

Epoch: 6| Step: 11
Training loss: 2.2370479106903076
Validation loss: 2.0378839713270946

Epoch: 6| Step: 12
Training loss: 2.481987237930298
Validation loss: 2.033781087526711

Epoch: 6| Step: 13
Training loss: 2.07742977142334
Validation loss: 2.064048524825804

Epoch: 50| Step: 0
Training loss: 2.6596286296844482
Validation loss: 2.045408620629259

Epoch: 6| Step: 1
Training loss: 1.6432650089263916
Validation loss: 2.040674509540681

Epoch: 6| Step: 2
Training loss: 2.764132261276245
Validation loss: 2.0359520194351033

Epoch: 6| Step: 3
Training loss: 2.2566494941711426
Validation loss: 2.03699133985786

Epoch: 6| Step: 4
Training loss: 2.742880344390869
Validation loss: 2.041570621152078

Epoch: 6| Step: 5
Training loss: 2.2204365730285645
Validation loss: 2.046184639776907

Epoch: 6| Step: 6
Training loss: 2.0400452613830566
Validation loss: 2.041640954632913

Epoch: 6| Step: 7
Training loss: 2.3681397438049316
Validation loss: 2.040027581235414

Epoch: 6| Step: 8
Training loss: 2.0647525787353516
Validation loss: 2.048092870302098

Epoch: 6| Step: 9
Training loss: 1.8332936763763428
Validation loss: 2.0582753817240396

Epoch: 6| Step: 10
Training loss: 2.2589292526245117
Validation loss: 2.0352257361976047

Epoch: 6| Step: 11
Training loss: 2.2693493366241455
Validation loss: 2.0319706650190454

Epoch: 6| Step: 12
Training loss: 2.754974365234375
Validation loss: 2.0420902544452297

Epoch: 6| Step: 13
Training loss: 2.5172581672668457
Validation loss: 2.0372300994011665

Epoch: 51| Step: 0
Training loss: 2.3109986782073975
Validation loss: 2.0574308364622054

Epoch: 6| Step: 1
Training loss: 2.132507085800171
Validation loss: 2.0504013389669438

Epoch: 6| Step: 2
Training loss: 2.022057056427002
Validation loss: 2.022388901761783

Epoch: 6| Step: 3
Training loss: 2.5914535522460938
Validation loss: 2.0122463010972544

Epoch: 6| Step: 4
Training loss: 2.1257243156433105
Validation loss: 2.0388793432584373

Epoch: 6| Step: 5
Training loss: 2.358698844909668
Validation loss: 2.038544708682645

Epoch: 6| Step: 6
Training loss: 2.2482571601867676
Validation loss: 2.046126514352778

Epoch: 6| Step: 7
Training loss: 2.4203848838806152
Validation loss: 2.047844748343191

Epoch: 6| Step: 8
Training loss: 2.8827574253082275
Validation loss: 2.0369296932733185

Epoch: 6| Step: 9
Training loss: 2.1715707778930664
Validation loss: 2.0311790986727645

Epoch: 6| Step: 10
Training loss: 1.8492040634155273
Validation loss: 2.0523271945215042

Epoch: 6| Step: 11
Training loss: 2.118145704269409
Validation loss: 2.023953330132269

Epoch: 6| Step: 12
Training loss: 2.8086767196655273
Validation loss: 2.0298292700962355

Epoch: 6| Step: 13
Training loss: 2.157045602798462
Validation loss: 2.0472823689060826

Epoch: 52| Step: 0
Training loss: 1.7009673118591309
Validation loss: 2.020306101409338

Epoch: 6| Step: 1
Training loss: 2.27005672454834
Validation loss: 2.019857104106616

Epoch: 6| Step: 2
Training loss: 2.512885570526123
Validation loss: 2.0448365852396977

Epoch: 6| Step: 3
Training loss: 2.380927562713623
Validation loss: 2.0280735364524265

Epoch: 6| Step: 4
Training loss: 2.1408095359802246
Validation loss: 2.02829937524693

Epoch: 6| Step: 5
Training loss: 2.1056392192840576
Validation loss: 2.027667135320684

Epoch: 6| Step: 6
Training loss: 2.770163059234619
Validation loss: 2.0271732448249735

Epoch: 6| Step: 7
Training loss: 1.6445344686508179
Validation loss: 2.027754836185004

Epoch: 6| Step: 8
Training loss: 2.8882720470428467
Validation loss: 2.0340862940716486

Epoch: 6| Step: 9
Training loss: 2.584538459777832
Validation loss: 2.0450147121183333

Epoch: 6| Step: 10
Training loss: 1.8114922046661377
Validation loss: 2.05144004924323

Epoch: 6| Step: 11
Training loss: 2.6163394451141357
Validation loss: 2.035745847609735

Epoch: 6| Step: 12
Training loss: 2.6551380157470703
Validation loss: 2.0542723773628153

Epoch: 6| Step: 13
Training loss: 2.2185065746307373
Validation loss: 2.0520874889948035

Epoch: 53| Step: 0
Training loss: 2.8324191570281982
Validation loss: 2.0515299586839575

Epoch: 6| Step: 1
Training loss: 2.4446945190429688
Validation loss: 2.0373413024410123

Epoch: 6| Step: 2
Training loss: 2.032684803009033
Validation loss: 2.056847503108363

Epoch: 6| Step: 3
Training loss: 2.3021962642669678
Validation loss: 2.050680119504211

Epoch: 6| Step: 4
Training loss: 2.700282573699951
Validation loss: 2.0568092343627766

Epoch: 6| Step: 5
Training loss: 2.603523015975952
Validation loss: 2.0584287310159333

Epoch: 6| Step: 6
Training loss: 2.8089442253112793
Validation loss: 2.0556440071393083

Epoch: 6| Step: 7
Training loss: 2.4792635440826416
Validation loss: 2.040159631800908

Epoch: 6| Step: 8
Training loss: 1.8554860353469849
Validation loss: 2.0539135420194237

Epoch: 6| Step: 9
Training loss: 1.8852415084838867
Validation loss: 2.0218671521832867

Epoch: 6| Step: 10
Training loss: 2.106919288635254
Validation loss: 2.0313618260045208

Epoch: 6| Step: 11
Training loss: 1.7546452283859253
Validation loss: 2.0436536278775943

Epoch: 6| Step: 12
Training loss: 2.296135425567627
Validation loss: 2.042599783148817

Epoch: 6| Step: 13
Training loss: 2.101346254348755
Validation loss: 2.043490345760058

Epoch: 54| Step: 0
Training loss: 2.1036031246185303
Validation loss: 2.033280147019253

Epoch: 6| Step: 1
Training loss: 2.22503924369812
Validation loss: 2.0346513922496507

Epoch: 6| Step: 2
Training loss: 2.4113330841064453
Validation loss: 2.040811638678274

Epoch: 6| Step: 3
Training loss: 2.2285261154174805
Validation loss: 2.035398998568135

Epoch: 6| Step: 4
Training loss: 2.554438591003418
Validation loss: 2.0366501295438377

Epoch: 6| Step: 5
Training loss: 2.1061463356018066
Validation loss: 2.027365579400011

Epoch: 6| Step: 6
Training loss: 2.702678918838501
Validation loss: 2.0437356938597975

Epoch: 6| Step: 7
Training loss: 2.210164785385132
Validation loss: 2.0173400973760955

Epoch: 6| Step: 8
Training loss: 2.9474503993988037
Validation loss: 2.0214386293965

Epoch: 6| Step: 9
Training loss: 1.9054319858551025
Validation loss: 2.0094564217393116

Epoch: 6| Step: 10
Training loss: 2.515080451965332
Validation loss: 2.0313341527856807

Epoch: 6| Step: 11
Training loss: 2.2429885864257812
Validation loss: 2.02412812940536

Epoch: 6| Step: 12
Training loss: 2.1049294471740723
Validation loss: 2.0303038602234214

Epoch: 6| Step: 13
Training loss: 1.62289559841156
Validation loss: 2.0232317524571575

Epoch: 55| Step: 0
Training loss: 2.403879165649414
Validation loss: 2.0289665114495063

Epoch: 6| Step: 1
Training loss: 2.2642269134521484
Validation loss: 2.0399406622814875

Epoch: 6| Step: 2
Training loss: 2.161703586578369
Validation loss: 2.0208430854223107

Epoch: 6| Step: 3
Training loss: 1.508221983909607
Validation loss: 2.0360290363270748

Epoch: 6| Step: 4
Training loss: 2.0574917793273926
Validation loss: 2.0332243109262116

Epoch: 6| Step: 5
Training loss: 2.5019702911376953
Validation loss: 2.031310648046514

Epoch: 6| Step: 6
Training loss: 2.535550594329834
Validation loss: 2.0493210720759567

Epoch: 6| Step: 7
Training loss: 2.283686637878418
Validation loss: 2.029175011060571

Epoch: 6| Step: 8
Training loss: 2.2830750942230225
Validation loss: 2.028197447458903

Epoch: 6| Step: 9
Training loss: 2.615741014480591
Validation loss: 2.032124993621662

Epoch: 6| Step: 10
Training loss: 2.811131238937378
Validation loss: 2.0226941595795336

Epoch: 6| Step: 11
Training loss: 2.6399898529052734
Validation loss: 2.03318380155871

Epoch: 6| Step: 12
Training loss: 2.178823947906494
Validation loss: 2.0453617495875203

Epoch: 6| Step: 13
Training loss: 1.265320897102356
Validation loss: 2.015843996437647

Epoch: 56| Step: 0
Training loss: 2.906201124191284
Validation loss: 2.0203777974651707

Epoch: 6| Step: 1
Training loss: 2.236802101135254
Validation loss: 2.0437136362957697

Epoch: 6| Step: 2
Training loss: 1.6325409412384033
Validation loss: 2.031632049109346

Epoch: 6| Step: 3
Training loss: 2.3837223052978516
Validation loss: 2.03611336728578

Epoch: 6| Step: 4
Training loss: 2.8986990451812744
Validation loss: 2.0438976800569923

Epoch: 6| Step: 5
Training loss: 1.957405686378479
Validation loss: 2.0535916090011597

Epoch: 6| Step: 6
Training loss: 2.8803725242614746
Validation loss: 2.0677751366810133

Epoch: 6| Step: 7
Training loss: 2.0494537353515625
Validation loss: 2.032068278199883

Epoch: 6| Step: 8
Training loss: 1.8850054740905762
Validation loss: 2.033121642246041

Epoch: 6| Step: 9
Training loss: 2.525381088256836
Validation loss: 2.045339907369306

Epoch: 6| Step: 10
Training loss: 2.195472478866577
Validation loss: 2.0555587327608498

Epoch: 6| Step: 11
Training loss: 1.8193808794021606
Validation loss: 2.052600340176654

Epoch: 6| Step: 12
Training loss: 1.9466160535812378
Validation loss: 2.0613749386161886

Epoch: 6| Step: 13
Training loss: 2.8604001998901367
Validation loss: 2.0622057389187556

Epoch: 57| Step: 0
Training loss: 2.132175922393799
Validation loss: 2.0383179341593096

Epoch: 6| Step: 1
Training loss: 2.731334686279297
Validation loss: 2.047926874570949

Epoch: 6| Step: 2
Training loss: 2.35054349899292
Validation loss: 2.0515543491609636

Epoch: 6| Step: 3
Training loss: 2.799466848373413
Validation loss: 2.0501201204074326

Epoch: 6| Step: 4
Training loss: 2.7840659618377686
Validation loss: 2.045113727610598

Epoch: 6| Step: 5
Training loss: 1.6140239238739014
Validation loss: 2.0351680350560013

Epoch: 6| Step: 6
Training loss: 1.9768481254577637
Validation loss: 2.0430356533296647

Epoch: 6| Step: 7
Training loss: 1.9959110021591187
Validation loss: 2.054059265762247

Epoch: 6| Step: 8
Training loss: 1.6883490085601807
Validation loss: 2.037629529994021

Epoch: 6| Step: 9
Training loss: 1.8207025527954102
Validation loss: 2.048819036893947

Epoch: 6| Step: 10
Training loss: 2.529417037963867
Validation loss: 2.0472312717027563

Epoch: 6| Step: 11
Training loss: 3.0029714107513428
Validation loss: 2.0559301658343245

Epoch: 6| Step: 12
Training loss: 2.075226306915283
Validation loss: 2.0373718405282624

Epoch: 6| Step: 13
Training loss: 2.383310317993164
Validation loss: 2.0457584383667156

Epoch: 58| Step: 0
Training loss: 2.418200969696045
Validation loss: 2.035821032780473

Epoch: 6| Step: 1
Training loss: 2.3786983489990234
Validation loss: 2.0499768757051036

Epoch: 6| Step: 2
Training loss: 2.1470510959625244
Validation loss: 2.0269666179533927

Epoch: 6| Step: 3
Training loss: 2.1280627250671387
Validation loss: 2.0313372073634977

Epoch: 6| Step: 4
Training loss: 2.8595714569091797
Validation loss: 2.02214575582935

Epoch: 6| Step: 5
Training loss: 2.352653980255127
Validation loss: 2.0171613244600195

Epoch: 6| Step: 6
Training loss: 2.0081000328063965
Validation loss: 2.02750761278214

Epoch: 6| Step: 7
Training loss: 2.0400736331939697
Validation loss: 2.0377274585026566

Epoch: 6| Step: 8
Training loss: 1.849560022354126
Validation loss: 2.033227523167928

Epoch: 6| Step: 9
Training loss: 1.8488857746124268
Validation loss: 2.0271607547677974

Epoch: 6| Step: 10
Training loss: 2.486205577850342
Validation loss: 2.04636186938132

Epoch: 6| Step: 11
Training loss: 2.1598336696624756
Validation loss: 2.0276263170344855

Epoch: 6| Step: 12
Training loss: 2.7287988662719727
Validation loss: 2.030559742322532

Epoch: 6| Step: 13
Training loss: 2.5407748222351074
Validation loss: 2.0252273159642376

Epoch: 59| Step: 0
Training loss: 1.8245749473571777
Validation loss: 2.0236385714623237

Epoch: 6| Step: 1
Training loss: 2.071173667907715
Validation loss: 2.030481574355915

Epoch: 6| Step: 2
Training loss: 2.397277355194092
Validation loss: 2.0383342824956423

Epoch: 6| Step: 3
Training loss: 2.579179048538208
Validation loss: 2.019803088198426

Epoch: 6| Step: 4
Training loss: 2.2995247840881348
Validation loss: 2.027898503888038

Epoch: 6| Step: 5
Training loss: 2.372140407562256
Validation loss: 2.0056146344830914

Epoch: 6| Step: 6
Training loss: 2.1407203674316406
Validation loss: 2.03139986530427

Epoch: 6| Step: 7
Training loss: 2.0733237266540527
Validation loss: 2.0086518910623368

Epoch: 6| Step: 8
Training loss: 2.220587968826294
Validation loss: 2.0208115782789005

Epoch: 6| Step: 9
Training loss: 2.3674697875976562
Validation loss: 2.022403624749953

Epoch: 6| Step: 10
Training loss: 2.083517551422119
Validation loss: 2.0198715566306986

Epoch: 6| Step: 11
Training loss: 2.6240108013153076
Validation loss: 2.02222635797275

Epoch: 6| Step: 12
Training loss: 2.5109455585479736
Validation loss: 2.0163472083307084

Epoch: 6| Step: 13
Training loss: 2.1758999824523926
Validation loss: 2.0168254747185657

Epoch: 60| Step: 0
Training loss: 2.274216651916504
Validation loss: 2.021328592813143

Epoch: 6| Step: 1
Training loss: 2.086489677429199
Validation loss: 1.9946225509848645

Epoch: 6| Step: 2
Training loss: 1.7926806211471558
Validation loss: 2.0285365478966826

Epoch: 6| Step: 3
Training loss: 2.602332353591919
Validation loss: 2.010355225173376

Epoch: 6| Step: 4
Training loss: 2.244077682495117
Validation loss: 2.030673216747981

Epoch: 6| Step: 5
Training loss: 2.5287036895751953
Validation loss: 2.037998048208093

Epoch: 6| Step: 6
Training loss: 2.850008964538574
Validation loss: 2.017873628165132

Epoch: 6| Step: 7
Training loss: 2.419039011001587
Validation loss: 2.0333374008055656

Epoch: 6| Step: 8
Training loss: 1.7600888013839722
Validation loss: 2.0251771237260554

Epoch: 6| Step: 9
Training loss: 2.3998637199401855
Validation loss: 2.0281466540469917

Epoch: 6| Step: 10
Training loss: 2.049208402633667
Validation loss: 1.9989583864006946

Epoch: 6| Step: 11
Training loss: 2.2817723751068115
Validation loss: 2.0250317332565144

Epoch: 6| Step: 12
Training loss: 2.3857221603393555
Validation loss: 2.0415749562683927

Epoch: 6| Step: 13
Training loss: 1.8631566762924194
Validation loss: 2.016173837005451

Epoch: 61| Step: 0
Training loss: 1.9536702632904053
Validation loss: 2.0142450230095976

Epoch: 6| Step: 1
Training loss: 2.2878031730651855
Validation loss: 2.0370288100293887

Epoch: 6| Step: 2
Training loss: 2.0509228706359863
Validation loss: 2.024517196480946

Epoch: 6| Step: 3
Training loss: 2.7222700119018555
Validation loss: 2.022418796375234

Epoch: 6| Step: 4
Training loss: 2.6641712188720703
Validation loss: 2.0322322332730858

Epoch: 6| Step: 5
Training loss: 2.343492031097412
Validation loss: 2.0338362442549838

Epoch: 6| Step: 6
Training loss: 2.7382118701934814
Validation loss: 2.0322006851114254

Epoch: 6| Step: 7
Training loss: 2.0947842597961426
Validation loss: 2.0308194545007523

Epoch: 6| Step: 8
Training loss: 1.931762456893921
Validation loss: 2.057408418706668

Epoch: 6| Step: 9
Training loss: 2.1338491439819336
Validation loss: 2.0419938948846634

Epoch: 6| Step: 10
Training loss: 2.352717399597168
Validation loss: 2.048554515325895

Epoch: 6| Step: 11
Training loss: 2.447373867034912
Validation loss: 2.0430560329908967

Epoch: 6| Step: 12
Training loss: 2.1605770587921143
Validation loss: 2.045631426636891

Epoch: 6| Step: 13
Training loss: 1.6934541463851929
Validation loss: 2.0430781200367916

Epoch: 62| Step: 0
Training loss: 2.347984552383423
Validation loss: 2.0287844673279793

Epoch: 6| Step: 1
Training loss: 1.5636121034622192
Validation loss: 2.0316221009018602

Epoch: 6| Step: 2
Training loss: 2.8133013248443604
Validation loss: 2.0237582114435013

Epoch: 6| Step: 3
Training loss: 2.0934457778930664
Validation loss: 2.03614229284307

Epoch: 6| Step: 4
Training loss: 2.0913171768188477
Validation loss: 2.0366615774810954

Epoch: 6| Step: 5
Training loss: 2.3458592891693115
Validation loss: 2.018637631529121

Epoch: 6| Step: 6
Training loss: 1.8117806911468506
Validation loss: 2.016843277920959

Epoch: 6| Step: 7
Training loss: 2.6555280685424805
Validation loss: 2.0105522986381286

Epoch: 6| Step: 8
Training loss: 2.0879602432250977
Validation loss: 2.009540814225392

Epoch: 6| Step: 9
Training loss: 2.3752992153167725
Validation loss: 2.0020203539120254

Epoch: 6| Step: 10
Training loss: 2.5409936904907227
Validation loss: 1.9868772593877648

Epoch: 6| Step: 11
Training loss: 2.3894262313842773
Validation loss: 2.0128234048043527

Epoch: 6| Step: 12
Training loss: 1.493753433227539
Validation loss: 2.0183392391409924

Epoch: 6| Step: 13
Training loss: 3.8348312377929688
Validation loss: 2.014822256180548

Epoch: 63| Step: 0
Training loss: 2.169114112854004
Validation loss: 2.016796713234276

Epoch: 6| Step: 1
Training loss: 2.623873710632324
Validation loss: 1.9990371350319154

Epoch: 6| Step: 2
Training loss: 2.0245437622070312
Validation loss: 2.0033105829710602

Epoch: 6| Step: 3
Training loss: 1.9516339302062988
Validation loss: 2.016620424485976

Epoch: 6| Step: 4
Training loss: 2.730614185333252
Validation loss: 2.00546645989982

Epoch: 6| Step: 5
Training loss: 2.0898730754852295
Validation loss: 1.9949860521542129

Epoch: 6| Step: 6
Training loss: 1.7378034591674805
Validation loss: 1.9951102541339012

Epoch: 6| Step: 7
Training loss: 2.5629982948303223
Validation loss: 2.0179333968829085

Epoch: 6| Step: 8
Training loss: 2.964871406555176
Validation loss: 2.0153157121391705

Epoch: 6| Step: 9
Training loss: 2.6205267906188965
Validation loss: 2.0078928598793606

Epoch: 6| Step: 10
Training loss: 1.931764841079712
Validation loss: 1.9794864449449765

Epoch: 6| Step: 11
Training loss: 1.9848458766937256
Validation loss: 1.9999796408478931

Epoch: 6| Step: 12
Training loss: 2.071704626083374
Validation loss: 2.0053580422555246

Epoch: 6| Step: 13
Training loss: 2.3852550983428955
Validation loss: 2.001846900550268

Epoch: 64| Step: 0
Training loss: 2.3997087478637695
Validation loss: 2.0040344948409707

Epoch: 6| Step: 1
Training loss: 1.832866907119751
Validation loss: 2.0039676107386106

Epoch: 6| Step: 2
Training loss: 1.9595755338668823
Validation loss: 2.0153112232044177

Epoch: 6| Step: 3
Training loss: 1.9393665790557861
Validation loss: 2.01367808670126

Epoch: 6| Step: 4
Training loss: 1.7415289878845215
Validation loss: 1.9910339809233142

Epoch: 6| Step: 5
Training loss: 2.5422301292419434
Validation loss: 2.0010127508512108

Epoch: 6| Step: 6
Training loss: 2.709458827972412
Validation loss: 2.007217400817461

Epoch: 6| Step: 7
Training loss: 2.508108139038086
Validation loss: 2.0003609118923062

Epoch: 6| Step: 8
Training loss: 1.169511079788208
Validation loss: 2.0110599481931297

Epoch: 6| Step: 9
Training loss: 2.474642276763916
Validation loss: 2.0135967680203017

Epoch: 6| Step: 10
Training loss: 1.7685267925262451
Validation loss: 2.0149028737057924

Epoch: 6| Step: 11
Training loss: 3.2809953689575195
Validation loss: 1.9909488539541922

Epoch: 6| Step: 12
Training loss: 2.555307149887085
Validation loss: 2.0274507973783757

Epoch: 6| Step: 13
Training loss: 2.8095059394836426
Validation loss: 2.0163276682617846

Epoch: 65| Step: 0
Training loss: 2.3897900581359863
Validation loss: 2.0278846935559343

Epoch: 6| Step: 1
Training loss: 2.260186195373535
Validation loss: 2.0230008453451176

Epoch: 6| Step: 2
Training loss: 1.9654871225357056
Validation loss: 2.023598514577394

Epoch: 6| Step: 3
Training loss: 2.360410690307617
Validation loss: 2.042867281103647

Epoch: 6| Step: 4
Training loss: 2.1760571002960205
Validation loss: 2.0216270287831626

Epoch: 6| Step: 5
Training loss: 2.214357376098633
Validation loss: 2.023393177217053

Epoch: 6| Step: 6
Training loss: 2.2096779346466064
Validation loss: 2.0551188504824074

Epoch: 6| Step: 7
Training loss: 2.4671525955200195
Validation loss: 2.0161597318546747

Epoch: 6| Step: 8
Training loss: 2.263970375061035
Validation loss: 2.027099411974671

Epoch: 6| Step: 9
Training loss: 1.3839807510375977
Validation loss: 2.027245899682404

Epoch: 6| Step: 10
Training loss: 2.625580310821533
Validation loss: 2.0330139795939126

Epoch: 6| Step: 11
Training loss: 2.176812171936035
Validation loss: 2.013186193281604

Epoch: 6| Step: 12
Training loss: 2.004908561706543
Validation loss: 2.0264613295114167

Epoch: 6| Step: 13
Training loss: 3.590094566345215
Validation loss: 2.0189180925328243

Epoch: 66| Step: 0
Training loss: 2.112020492553711
Validation loss: 2.031103939138433

Epoch: 6| Step: 1
Training loss: 1.6466606855392456
Validation loss: 2.047308411649478

Epoch: 6| Step: 2
Training loss: 2.1904587745666504
Validation loss: 2.036514166862734

Epoch: 6| Step: 3
Training loss: 2.7783737182617188
Validation loss: 1.9978997181820612

Epoch: 6| Step: 4
Training loss: 2.1834325790405273
Validation loss: 2.0255643949713757

Epoch: 6| Step: 5
Training loss: 2.474562168121338
Validation loss: 2.0369798150113834

Epoch: 6| Step: 6
Training loss: 2.4616780281066895
Validation loss: 2.025598254255069

Epoch: 6| Step: 7
Training loss: 2.714961290359497
Validation loss: 2.01747110197621

Epoch: 6| Step: 8
Training loss: 2.385303497314453
Validation loss: 2.040181882919804

Epoch: 6| Step: 9
Training loss: 1.8172762393951416
Validation loss: 2.0443153535166094

Epoch: 6| Step: 10
Training loss: 2.5077157020568848
Validation loss: 2.0342143671486967

Epoch: 6| Step: 11
Training loss: 2.1256346702575684
Validation loss: 2.0376444452552387

Epoch: 6| Step: 12
Training loss: 1.845069408416748
Validation loss: 2.0488435170983754

Epoch: 6| Step: 13
Training loss: 2.1061534881591797
Validation loss: 2.0393597028588735

Epoch: 67| Step: 0
Training loss: 2.2336347103118896
Validation loss: 2.0224575906671505

Epoch: 6| Step: 1
Training loss: 2.5284264087677
Validation loss: 2.0432734002349195

Epoch: 6| Step: 2
Training loss: 2.267390251159668
Validation loss: 2.023303254958122

Epoch: 6| Step: 3
Training loss: 1.967724323272705
Validation loss: 2.0314350794720393

Epoch: 6| Step: 4
Training loss: 2.064122200012207
Validation loss: 2.020376305426321

Epoch: 6| Step: 5
Training loss: 2.0095021724700928
Validation loss: 2.0248104180059125

Epoch: 6| Step: 6
Training loss: 2.576338291168213
Validation loss: 2.0338951156985376

Epoch: 6| Step: 7
Training loss: 2.6924610137939453
Validation loss: 2.0232849787640315

Epoch: 6| Step: 8
Training loss: 2.75872540473938
Validation loss: 2.0311496462873233

Epoch: 6| Step: 9
Training loss: 1.8501741886138916
Validation loss: 2.0284302106467624

Epoch: 6| Step: 10
Training loss: 1.863593339920044
Validation loss: 2.031260662181403

Epoch: 6| Step: 11
Training loss: 1.9044368267059326
Validation loss: 2.032613500472038

Epoch: 6| Step: 12
Training loss: 2.2227680683135986
Validation loss: 2.024843415906352

Epoch: 6| Step: 13
Training loss: 2.64375638961792
Validation loss: 2.0314691964016167

Epoch: 68| Step: 0
Training loss: 2.3813633918762207
Validation loss: 2.0364879023644233

Epoch: 6| Step: 1
Training loss: 2.958493947982788
Validation loss: 2.0279816760811755

Epoch: 6| Step: 2
Training loss: 2.1276345252990723
Validation loss: 1.988263371170208

Epoch: 6| Step: 3
Training loss: 1.9579654932022095
Validation loss: 2.0213744858259797

Epoch: 6| Step: 4
Training loss: 2.224855899810791
Validation loss: 2.000713832916752

Epoch: 6| Step: 5
Training loss: 2.4532418251037598
Validation loss: 2.0232382333406838

Epoch: 6| Step: 6
Training loss: 2.680443525314331
Validation loss: 2.022190083739578

Epoch: 6| Step: 7
Training loss: 1.8275856971740723
Validation loss: 2.0088828891836186

Epoch: 6| Step: 8
Training loss: 0.978603720664978
Validation loss: 2.0101373875012962

Epoch: 6| Step: 9
Training loss: 2.43698787689209
Validation loss: 2.0068905045909267

Epoch: 6| Step: 10
Training loss: 2.3946590423583984
Validation loss: 2.002263927972445

Epoch: 6| Step: 11
Training loss: 2.5372471809387207
Validation loss: 2.010589120208576

Epoch: 6| Step: 12
Training loss: 2.6605162620544434
Validation loss: 2.009452958260813

Epoch: 6| Step: 13
Training loss: 1.4657063484191895
Validation loss: 2.0029994954345045

Epoch: 69| Step: 0
Training loss: 2.541752815246582
Validation loss: 2.0024344318656513

Epoch: 6| Step: 1
Training loss: 1.9804167747497559
Validation loss: 2.0058130705228416

Epoch: 6| Step: 2
Training loss: 2.105041742324829
Validation loss: 1.9986860341923212

Epoch: 6| Step: 3
Training loss: 1.447191596031189
Validation loss: 2.0243714663290207

Epoch: 6| Step: 4
Training loss: 2.4236998558044434
Validation loss: 2.012204735509811

Epoch: 6| Step: 5
Training loss: 2.4301371574401855
Validation loss: 2.0060329591074297

Epoch: 6| Step: 6
Training loss: 2.2667057514190674
Validation loss: 2.017777935151131

Epoch: 6| Step: 7
Training loss: 2.9368557929992676
Validation loss: 2.029168960868671

Epoch: 6| Step: 8
Training loss: 2.3418755531311035
Validation loss: 2.0240860062260784

Epoch: 6| Step: 9
Training loss: 1.398983120918274
Validation loss: 2.032174256540114

Epoch: 6| Step: 10
Training loss: 1.6022450923919678
Validation loss: 2.027683675930064

Epoch: 6| Step: 11
Training loss: 2.4428553581237793
Validation loss: 2.020175185254825

Epoch: 6| Step: 12
Training loss: 3.0025744438171387
Validation loss: 2.032731360004794

Epoch: 6| Step: 13
Training loss: 2.819871664047241
Validation loss: 2.03920986319101

Epoch: 70| Step: 0
Training loss: 2.465891122817993
Validation loss: 2.0178112829885175

Epoch: 6| Step: 1
Training loss: 2.1455211639404297
Validation loss: 2.011182890143446

Epoch: 6| Step: 2
Training loss: 2.302607297897339
Validation loss: 2.0389854343988563

Epoch: 6| Step: 3
Training loss: 2.7209458351135254
Validation loss: 2.04106996392691

Epoch: 6| Step: 4
Training loss: 1.519242525100708
Validation loss: 2.027603659578549

Epoch: 6| Step: 5
Training loss: 1.4753755331039429
Validation loss: 2.0170578572057907

Epoch: 6| Step: 6
Training loss: 2.282318592071533
Validation loss: 2.0316767961748186

Epoch: 6| Step: 7
Training loss: 1.5287950038909912
Validation loss: 2.051842725405129

Epoch: 6| Step: 8
Training loss: 2.4219751358032227
Validation loss: 2.017405092075307

Epoch: 6| Step: 9
Training loss: 2.217512845993042
Validation loss: 2.0432378784302743

Epoch: 6| Step: 10
Training loss: 2.290285587310791
Validation loss: 2.0087858015491116

Epoch: 6| Step: 11
Training loss: 2.475374698638916
Validation loss: 2.0135179899072133

Epoch: 6| Step: 12
Training loss: 2.8503451347351074
Validation loss: 2.0274607725040887

Epoch: 6| Step: 13
Training loss: 2.617678642272949
Validation loss: 2.0120970895213466

Epoch: 71| Step: 0
Training loss: 2.6954803466796875
Validation loss: 2.02500940651022

Epoch: 6| Step: 1
Training loss: 2.9388890266418457
Validation loss: 2.014189527880761

Epoch: 6| Step: 2
Training loss: 1.9668383598327637
Validation loss: 2.032364253074892

Epoch: 6| Step: 3
Training loss: 2.465646266937256
Validation loss: 2.0209698061789236

Epoch: 6| Step: 4
Training loss: 1.3806374073028564
Validation loss: 2.0221831683189637

Epoch: 6| Step: 5
Training loss: 2.2340025901794434
Validation loss: 2.0120175435978878

Epoch: 6| Step: 6
Training loss: 2.5546703338623047
Validation loss: 2.0126521356644167

Epoch: 6| Step: 7
Training loss: 1.999355435371399
Validation loss: 1.9822407486618205

Epoch: 6| Step: 8
Training loss: 1.9453494548797607
Validation loss: 2.0258585073614634

Epoch: 6| Step: 9
Training loss: 2.4501938819885254
Validation loss: 2.0122887037133657

Epoch: 6| Step: 10
Training loss: 2.4561474323272705
Validation loss: 2.002967724236109

Epoch: 6| Step: 11
Training loss: 2.553555488586426
Validation loss: 2.0163816995518182

Epoch: 6| Step: 12
Training loss: 1.7129319906234741
Validation loss: 2.0066706570245887

Epoch: 6| Step: 13
Training loss: 1.698171615600586
Validation loss: 2.0252811818994503

Epoch: 72| Step: 0
Training loss: 2.418175458908081
Validation loss: 2.0153487625942437

Epoch: 6| Step: 1
Training loss: 2.7891407012939453
Validation loss: 1.9816245391804685

Epoch: 6| Step: 2
Training loss: 1.872596263885498
Validation loss: 2.016136993644058

Epoch: 6| Step: 3
Training loss: 1.9361670017242432
Validation loss: 2.015569847117188

Epoch: 6| Step: 4
Training loss: 1.7827479839324951
Validation loss: 2.0167482783717494

Epoch: 6| Step: 5
Training loss: 3.160634994506836
Validation loss: 2.0134015275586035

Epoch: 6| Step: 6
Training loss: 1.9953488111495972
Validation loss: 2.025003984410276

Epoch: 6| Step: 7
Training loss: 2.889225959777832
Validation loss: 2.0321811655516266

Epoch: 6| Step: 8
Training loss: 1.905831217765808
Validation loss: 2.026928955508817

Epoch: 6| Step: 9
Training loss: 1.949812412261963
Validation loss: 2.0153624780716433

Epoch: 6| Step: 10
Training loss: 2.02567195892334
Validation loss: 2.033234001487814

Epoch: 6| Step: 11
Training loss: 2.3069076538085938
Validation loss: 2.026150188138408

Epoch: 6| Step: 12
Training loss: 2.2374110221862793
Validation loss: 2.029280747136762

Epoch: 6| Step: 13
Training loss: 1.8537428379058838
Validation loss: 2.0387108172139814

Epoch: 73| Step: 0
Training loss: 2.1981658935546875
Validation loss: 2.035324274852712

Epoch: 6| Step: 1
Training loss: 1.801931381225586
Validation loss: 2.0183272207936933

Epoch: 6| Step: 2
Training loss: 1.8554607629776
Validation loss: 2.025144459098898

Epoch: 6| Step: 3
Training loss: 2.037550926208496
Validation loss: 2.036335672101667

Epoch: 6| Step: 4
Training loss: 2.2382326126098633
Validation loss: 2.022450344536894

Epoch: 6| Step: 5
Training loss: 2.759979486465454
Validation loss: 2.049014114564465

Epoch: 6| Step: 6
Training loss: 2.5131959915161133
Validation loss: 2.0296314044665267

Epoch: 6| Step: 7
Training loss: 2.3982675075531006
Validation loss: 2.012197991853119

Epoch: 6| Step: 8
Training loss: 2.2451233863830566
Validation loss: 2.022378175489364

Epoch: 6| Step: 9
Training loss: 2.5782318115234375
Validation loss: 2.04024508178875

Epoch: 6| Step: 10
Training loss: 2.4454121589660645
Validation loss: 2.0309449549644225

Epoch: 6| Step: 11
Training loss: 1.3644237518310547
Validation loss: 2.019289392296986

Epoch: 6| Step: 12
Training loss: 2.174546480178833
Validation loss: 2.020701657059372

Epoch: 6| Step: 13
Training loss: 2.7461071014404297
Validation loss: 2.036053499867839

Epoch: 74| Step: 0
Training loss: 2.6658647060394287
Validation loss: 2.0366004128609934

Epoch: 6| Step: 1
Training loss: 1.6413161754608154
Validation loss: 2.0271012501050065

Epoch: 6| Step: 2
Training loss: 1.6055991649627686
Validation loss: 2.024990520169658

Epoch: 6| Step: 3
Training loss: 1.8443326950073242
Validation loss: 2.040618896484375

Epoch: 6| Step: 4
Training loss: 2.225893974304199
Validation loss: 2.0136413266581874

Epoch: 6| Step: 5
Training loss: 1.8761699199676514
Validation loss: 2.0041475449838946

Epoch: 6| Step: 6
Training loss: 2.004608631134033
Validation loss: 2.0043548384020404

Epoch: 6| Step: 7
Training loss: 2.059614896774292
Validation loss: 2.004436517274508

Epoch: 6| Step: 8
Training loss: 2.7075119018554688
Validation loss: 2.002617146379204

Epoch: 6| Step: 9
Training loss: 2.7193965911865234
Validation loss: 1.9977121609513477

Epoch: 6| Step: 10
Training loss: 2.615407943725586
Validation loss: 2.0221574409033662

Epoch: 6| Step: 11
Training loss: 2.0220417976379395
Validation loss: 2.0204964542901642

Epoch: 6| Step: 12
Training loss: 2.5217952728271484
Validation loss: 2.007221791052049

Epoch: 6| Step: 13
Training loss: 3.157348871231079
Validation loss: 1.9946248633887178

Epoch: 75| Step: 0
Training loss: 2.3867459297180176
Validation loss: 2.0173374670808033

Epoch: 6| Step: 1
Training loss: 1.7333353757858276
Validation loss: 2.0238479286111812

Epoch: 6| Step: 2
Training loss: 2.0346016883850098
Validation loss: 2.0341656336220364

Epoch: 6| Step: 3
Training loss: 1.6283408403396606
Validation loss: 2.001659757347517

Epoch: 6| Step: 4
Training loss: 2.343221664428711
Validation loss: 2.027520018239175

Epoch: 6| Step: 5
Training loss: 1.8894391059875488
Validation loss: 2.0222901657063472

Epoch: 6| Step: 6
Training loss: 2.6310482025146484
Validation loss: 2.032606465842134

Epoch: 6| Step: 7
Training loss: 2.321688175201416
Validation loss: 2.041770629985358

Epoch: 6| Step: 8
Training loss: 3.029355049133301
Validation loss: 2.027374744415283

Epoch: 6| Step: 9
Training loss: 1.583844542503357
Validation loss: 2.0327818342434463

Epoch: 6| Step: 10
Training loss: 1.8530240058898926
Validation loss: 2.034436580955341

Epoch: 6| Step: 11
Training loss: 2.715264320373535
Validation loss: 2.0243136844327374

Epoch: 6| Step: 12
Training loss: 2.96164608001709
Validation loss: 2.030548757122409

Epoch: 6| Step: 13
Training loss: 1.9400643110275269
Validation loss: 2.037026330988894

Epoch: 76| Step: 0
Training loss: 1.6437664031982422
Validation loss: 2.0234483621453725

Epoch: 6| Step: 1
Training loss: 2.6424362659454346
Validation loss: 2.0369695053305676

Epoch: 6| Step: 2
Training loss: 2.378488540649414
Validation loss: 2.008056661134125

Epoch: 6| Step: 3
Training loss: 1.6519443988800049
Validation loss: 2.0303652414711575

Epoch: 6| Step: 4
Training loss: 2.32940673828125
Validation loss: 2.028512180492442

Epoch: 6| Step: 5
Training loss: 1.5578734874725342
Validation loss: 2.026315681395992

Epoch: 6| Step: 6
Training loss: 2.4926395416259766
Validation loss: 2.0365301819257837

Epoch: 6| Step: 7
Training loss: 2.453336715698242
Validation loss: 2.0277605787400277

Epoch: 6| Step: 8
Training loss: 2.4413161277770996
Validation loss: 2.0424189465020293

Epoch: 6| Step: 9
Training loss: 2.642514705657959
Validation loss: 2.012992052621739

Epoch: 6| Step: 10
Training loss: 1.8180311918258667
Validation loss: 2.0152146303525535

Epoch: 6| Step: 11
Training loss: 2.0090315341949463
Validation loss: 2.008544261737536

Epoch: 6| Step: 12
Training loss: 2.3099136352539062
Validation loss: 2.0142028306120183

Epoch: 6| Step: 13
Training loss: 2.93839693069458
Validation loss: 2.0229316578116467

Epoch: 77| Step: 0
Training loss: 1.848296046257019
Validation loss: 2.017725210036001

Epoch: 6| Step: 1
Training loss: 2.118511438369751
Validation loss: 2.0033995682193386

Epoch: 6| Step: 2
Training loss: 2.0754804611206055
Validation loss: 2.017065860891855

Epoch: 6| Step: 3
Training loss: 2.844351291656494
Validation loss: 2.0186525185902915

Epoch: 6| Step: 4
Training loss: 2.4675698280334473
Validation loss: 2.005476010743008

Epoch: 6| Step: 5
Training loss: 2.3257808685302734
Validation loss: 2.02144060468161

Epoch: 6| Step: 6
Training loss: 1.6569430828094482
Validation loss: 2.013764371154129

Epoch: 6| Step: 7
Training loss: 1.831563115119934
Validation loss: 2.0214601075777443

Epoch: 6| Step: 8
Training loss: 2.803889513015747
Validation loss: 2.010287515578731

Epoch: 6| Step: 9
Training loss: 2.0882253646850586
Validation loss: 2.012220882600354

Epoch: 6| Step: 10
Training loss: 2.714303493499756
Validation loss: 2.031864691806096

Epoch: 6| Step: 11
Training loss: 2.628255844116211
Validation loss: 1.9903136581502936

Epoch: 6| Step: 12
Training loss: 1.733277440071106
Validation loss: 2.0061270447187525

Epoch: 6| Step: 13
Training loss: 1.6860076189041138
Validation loss: 2.0045206059691725

Epoch: 78| Step: 0
Training loss: 2.22932505607605
Validation loss: 2.0283560599050214

Epoch: 6| Step: 1
Training loss: 2.584472179412842
Validation loss: 2.0161496708470006

Epoch: 6| Step: 2
Training loss: 2.4995129108428955
Validation loss: 2.00513715897837

Epoch: 6| Step: 3
Training loss: 1.9477672576904297
Validation loss: 2.011721513604605

Epoch: 6| Step: 4
Training loss: 1.9747843742370605
Validation loss: 2.0135409806364324

Epoch: 6| Step: 5
Training loss: 2.5642876625061035
Validation loss: 2.025623571488165

Epoch: 6| Step: 6
Training loss: 2.49241042137146
Validation loss: 2.0443723265842726

Epoch: 6| Step: 7
Training loss: 2.873181104660034
Validation loss: 2.024588733591059

Epoch: 6| Step: 8
Training loss: 2.01705002784729
Validation loss: 2.003513587418423

Epoch: 6| Step: 9
Training loss: 1.50400710105896
Validation loss: 2.0163657024342525

Epoch: 6| Step: 10
Training loss: 2.0230095386505127
Validation loss: 2.0211389577516945

Epoch: 6| Step: 11
Training loss: 2.375439167022705
Validation loss: 2.0402152666481594

Epoch: 6| Step: 12
Training loss: 1.826093316078186
Validation loss: 2.0357887180902625

Epoch: 6| Step: 13
Training loss: 1.969329833984375
Validation loss: 2.0229373670393422

Epoch: 79| Step: 0
Training loss: 1.99200439453125
Validation loss: 2.0337935904020905

Epoch: 6| Step: 1
Training loss: 1.886207103729248
Validation loss: 2.0396267188492643

Epoch: 6| Step: 2
Training loss: 3.1986398696899414
Validation loss: 2.0355446313017156

Epoch: 6| Step: 3
Training loss: 1.943363904953003
Validation loss: 2.033151998314806

Epoch: 6| Step: 4
Training loss: 1.882292628288269
Validation loss: 2.0495598764829737

Epoch: 6| Step: 5
Training loss: 2.544739246368408
Validation loss: 2.0238003525682675

Epoch: 6| Step: 6
Training loss: 1.8234093189239502
Validation loss: 2.0419614834170186

Epoch: 6| Step: 7
Training loss: 2.872218132019043
Validation loss: 2.044149209094304

Epoch: 6| Step: 8
Training loss: 1.7852177619934082
Validation loss: 2.0192658516668502

Epoch: 6| Step: 9
Training loss: 2.176128387451172
Validation loss: 2.054415933547481

Epoch: 6| Step: 10
Training loss: 1.8696544170379639
Validation loss: 2.0532845476622223

Epoch: 6| Step: 11
Training loss: 2.493119955062866
Validation loss: 2.0432753511654433

Epoch: 6| Step: 12
Training loss: 2.529400110244751
Validation loss: 2.0466051050411758

Epoch: 6| Step: 13
Training loss: 1.8509407043457031
Validation loss: 2.03088374804425

Epoch: 80| Step: 0
Training loss: 2.4638938903808594
Validation loss: 2.0279769410369215

Epoch: 6| Step: 1
Training loss: 2.8260860443115234
Validation loss: 2.0354675836460565

Epoch: 6| Step: 2
Training loss: 2.3729004859924316
Validation loss: 2.0365227294224564

Epoch: 6| Step: 3
Training loss: 2.3480677604675293
Validation loss: 2.0493908582195157

Epoch: 6| Step: 4
Training loss: 1.9755096435546875
Validation loss: 2.0483188500968357

Epoch: 6| Step: 5
Training loss: 2.718027353286743
Validation loss: 2.0272281477528233

Epoch: 6| Step: 6
Training loss: 2.229210376739502
Validation loss: 2.0095246812348724

Epoch: 6| Step: 7
Training loss: 1.74876070022583
Validation loss: 2.0347114198951313

Epoch: 6| Step: 8
Training loss: 1.7620477676391602
Validation loss: 2.047277157024671

Epoch: 6| Step: 9
Training loss: 2.270404100418091
Validation loss: 2.0309529278867986

Epoch: 6| Step: 10
Training loss: 1.5224180221557617
Validation loss: 2.023177675021592

Epoch: 6| Step: 11
Training loss: 2.3087053298950195
Validation loss: 1.997708917945944

Epoch: 6| Step: 12
Training loss: 2.5466198921203613
Validation loss: 2.015030309718142

Epoch: 6| Step: 13
Training loss: 1.4533272981643677
Validation loss: 2.0072414464848016

Epoch: 81| Step: 0
Training loss: 2.8922483921051025
Validation loss: 2.023009507886825

Epoch: 6| Step: 1
Training loss: 2.0039589405059814
Validation loss: 2.046831061763148

Epoch: 6| Step: 2
Training loss: 2.656242609024048
Validation loss: 2.0431652453637894

Epoch: 6| Step: 3
Training loss: 2.287476062774658
Validation loss: 2.0228592170182096

Epoch: 6| Step: 4
Training loss: 2.133909225463867
Validation loss: 2.0016375023831605

Epoch: 6| Step: 5
Training loss: 2.2187836170196533
Validation loss: 2.0316914935265817

Epoch: 6| Step: 6
Training loss: 1.810807466506958
Validation loss: 2.0273427117255425

Epoch: 6| Step: 7
Training loss: 2.0524909496307373
Validation loss: 2.0349749647161013

Epoch: 6| Step: 8
Training loss: 2.010103940963745
Validation loss: 2.0212747884053055

Epoch: 6| Step: 9
Training loss: 2.0842268466949463
Validation loss: 2.053752130077731

Epoch: 6| Step: 10
Training loss: 1.8995715379714966
Validation loss: 2.036837418874105

Epoch: 6| Step: 11
Training loss: 2.5872511863708496
Validation loss: 2.052655237977223

Epoch: 6| Step: 12
Training loss: 2.251366376876831
Validation loss: 2.0370468247321343

Epoch: 6| Step: 13
Training loss: 1.834490418434143
Validation loss: 2.04805911484585

Epoch: 82| Step: 0
Training loss: 1.697587251663208
Validation loss: 2.0276619952212096

Epoch: 6| Step: 1
Training loss: 2.3963747024536133
Validation loss: 2.0258795779238463

Epoch: 6| Step: 2
Training loss: 2.338456153869629
Validation loss: 2.0123049725768385

Epoch: 6| Step: 3
Training loss: 2.1612119674682617
Validation loss: 2.020832218149657

Epoch: 6| Step: 4
Training loss: 1.9871107339859009
Validation loss: 2.0014302307559597

Epoch: 6| Step: 5
Training loss: 2.0424106121063232
Validation loss: 2.0140573311877508

Epoch: 6| Step: 6
Training loss: 2.945253849029541
Validation loss: 1.9996611405444402

Epoch: 6| Step: 7
Training loss: 2.196165084838867
Validation loss: 1.9987615295635757

Epoch: 6| Step: 8
Training loss: 1.5367473363876343
Validation loss: 2.0082996045389483

Epoch: 6| Step: 9
Training loss: 2.5255179405212402
Validation loss: 2.0126343029801563

Epoch: 6| Step: 10
Training loss: 1.4804065227508545
Validation loss: 1.9846796374167166

Epoch: 6| Step: 11
Training loss: 2.2013745307922363
Validation loss: 1.9873564961136028

Epoch: 6| Step: 12
Training loss: 3.055070400238037
Validation loss: 2.005860238946894

Epoch: 6| Step: 13
Training loss: 2.36326003074646
Validation loss: 1.9941575834828038

Epoch: 83| Step: 0
Training loss: 1.8875184059143066
Validation loss: 2.00292767119664

Epoch: 6| Step: 1
Training loss: 2.3179678916931152
Validation loss: 1.9867430502368557

Epoch: 6| Step: 2
Training loss: 2.9996907711029053
Validation loss: 2.004709553974931

Epoch: 6| Step: 3
Training loss: 1.8148677349090576
Validation loss: 1.9959560773705924

Epoch: 6| Step: 4
Training loss: 2.0348401069641113
Validation loss: 2.01264831583987

Epoch: 6| Step: 5
Training loss: 2.2977163791656494
Validation loss: 2.0199596292229107

Epoch: 6| Step: 6
Training loss: 2.411824941635132
Validation loss: 1.9941968661482616

Epoch: 6| Step: 7
Training loss: 1.958457589149475
Validation loss: 2.007185228409306

Epoch: 6| Step: 8
Training loss: 1.7114195823669434
Validation loss: 2.014384787569764

Epoch: 6| Step: 9
Training loss: 2.391144037246704
Validation loss: 2.004861856019625

Epoch: 6| Step: 10
Training loss: 1.7893186807632446
Validation loss: 2.007827228115451

Epoch: 6| Step: 11
Training loss: 2.390005111694336
Validation loss: 2.016684534729168

Epoch: 6| Step: 12
Training loss: 2.8492603302001953
Validation loss: 2.019284273988457

Epoch: 6| Step: 13
Training loss: 1.8654215335845947
Validation loss: 2.015085816383362

Epoch: 84| Step: 0
Training loss: 2.3376450538635254
Validation loss: 2.0150035953009002

Epoch: 6| Step: 1
Training loss: 0.998067319393158
Validation loss: 1.9991760202633437

Epoch: 6| Step: 2
Training loss: 2.0997955799102783
Validation loss: 2.024694276112382

Epoch: 6| Step: 3
Training loss: 2.563577175140381
Validation loss: 2.0212724798469135

Epoch: 6| Step: 4
Training loss: 2.207779884338379
Validation loss: 2.050309096613238

Epoch: 6| Step: 5
Training loss: 2.0001535415649414
Validation loss: 2.0242641510501986

Epoch: 6| Step: 6
Training loss: 2.2528345584869385
Validation loss: 2.026155928129791

Epoch: 6| Step: 7
Training loss: 1.9633681774139404
Validation loss: 2.011681136264596

Epoch: 6| Step: 8
Training loss: 2.149412155151367
Validation loss: 2.0072054978339904

Epoch: 6| Step: 9
Training loss: 2.2913148403167725
Validation loss: 2.025793621616979

Epoch: 6| Step: 10
Training loss: 2.4033188819885254
Validation loss: 2.0181933731161137

Epoch: 6| Step: 11
Training loss: 2.4662740230560303
Validation loss: 2.0115809876431703

Epoch: 6| Step: 12
Training loss: 2.679983139038086
Validation loss: 2.0344478007285827

Epoch: 6| Step: 13
Training loss: 2.1610729694366455
Validation loss: 2.0148148254681657

Epoch: 85| Step: 0
Training loss: 3.0070157051086426
Validation loss: 2.0169692770127328

Epoch: 6| Step: 1
Training loss: 2.444650650024414
Validation loss: 2.0136126420831166

Epoch: 6| Step: 2
Training loss: 1.770113229751587
Validation loss: 2.011047431217727

Epoch: 6| Step: 3
Training loss: 2.5734176635742188
Validation loss: 2.0038215370588404

Epoch: 6| Step: 4
Training loss: 2.3260812759399414
Validation loss: 2.01250369574434

Epoch: 6| Step: 5
Training loss: 2.5432841777801514
Validation loss: 2.0165987373680196

Epoch: 6| Step: 6
Training loss: 1.6948301792144775
Validation loss: 1.9857523505405714

Epoch: 6| Step: 7
Training loss: 1.96392822265625
Validation loss: 1.9931228519767843

Epoch: 6| Step: 8
Training loss: 1.643257737159729
Validation loss: 1.9862014542343795

Epoch: 6| Step: 9
Training loss: 1.400436282157898
Validation loss: 1.9797541877274871

Epoch: 6| Step: 10
Training loss: 3.0195703506469727
Validation loss: 2.0067069197213776

Epoch: 6| Step: 11
Training loss: 2.0022623538970947
Validation loss: 1.9965017046979678

Epoch: 6| Step: 12
Training loss: 1.868099331855774
Validation loss: 1.980829397837321

Epoch: 6| Step: 13
Training loss: 2.5414133071899414
Validation loss: 2.0072242649652625

Epoch: 86| Step: 0
Training loss: 1.5742878913879395
Validation loss: 2.0095685835807555

Epoch: 6| Step: 1
Training loss: 2.6081061363220215
Validation loss: 1.999589225297333

Epoch: 6| Step: 2
Training loss: 1.9436249732971191
Validation loss: 2.0127569142208306

Epoch: 6| Step: 3
Training loss: 2.0899317264556885
Validation loss: 1.9938354030732186

Epoch: 6| Step: 4
Training loss: 1.6933791637420654
Validation loss: 2.0143881741390435

Epoch: 6| Step: 5
Training loss: 1.9204416275024414
Validation loss: 2.01841139793396

Epoch: 6| Step: 6
Training loss: 2.5628108978271484
Validation loss: 2.023232577949442

Epoch: 6| Step: 7
Training loss: 2.984994411468506
Validation loss: 2.0113566754966654

Epoch: 6| Step: 8
Training loss: 2.6141977310180664
Validation loss: 2.0291064682827202

Epoch: 6| Step: 9
Training loss: 1.87784743309021
Validation loss: 2.0104024551248036

Epoch: 6| Step: 10
Training loss: 3.0088653564453125
Validation loss: 2.051810631188013

Epoch: 6| Step: 11
Training loss: 1.5872228145599365
Validation loss: 2.03364816019612

Epoch: 6| Step: 12
Training loss: 2.3340306282043457
Validation loss: 2.0302074134990735

Epoch: 6| Step: 13
Training loss: 1.5861554145812988
Validation loss: 2.039444261981595

Epoch: 87| Step: 0
Training loss: 2.5049831867218018
Validation loss: 2.044316368718301

Epoch: 6| Step: 1
Training loss: 2.1166107654571533
Validation loss: 2.0488648491521038

Epoch: 6| Step: 2
Training loss: 2.0650320053100586
Validation loss: 2.0375000225600375

Epoch: 6| Step: 3
Training loss: 1.9713493585586548
Validation loss: 2.048447903766427

Epoch: 6| Step: 4
Training loss: 1.343397617340088
Validation loss: 2.0348759697329615

Epoch: 6| Step: 5
Training loss: 2.3355660438537598
Validation loss: 2.0452072979301534

Epoch: 6| Step: 6
Training loss: 2.4564270973205566
Validation loss: 2.049552945680516

Epoch: 6| Step: 7
Training loss: 2.3382558822631836
Validation loss: 2.059841284187891

Epoch: 6| Step: 8
Training loss: 1.369231939315796
Validation loss: 2.045283199638449

Epoch: 6| Step: 9
Training loss: 3.052727222442627
Validation loss: 2.050028924019106

Epoch: 6| Step: 10
Training loss: 1.9290515184402466
Validation loss: 2.035546810396256

Epoch: 6| Step: 11
Training loss: 2.2560367584228516
Validation loss: 2.0442588765134095

Epoch: 6| Step: 12
Training loss: 2.7213497161865234
Validation loss: 2.0047296170265443

Epoch: 6| Step: 13
Training loss: 2.352457046508789
Validation loss: 2.038323612623317

Epoch: 88| Step: 0
Training loss: 2.198822498321533
Validation loss: 2.025344325650123

Epoch: 6| Step: 1
Training loss: 3.119868755340576
Validation loss: 2.021037497828084

Epoch: 6| Step: 2
Training loss: 1.8701391220092773
Validation loss: 2.0075730354555192

Epoch: 6| Step: 3
Training loss: 2.22296142578125
Validation loss: 2.038278551511867

Epoch: 6| Step: 4
Training loss: 1.7492636442184448
Validation loss: 2.0118937005278883

Epoch: 6| Step: 5
Training loss: 1.9748964309692383
Validation loss: 1.9845023052666777

Epoch: 6| Step: 6
Training loss: 3.2322399616241455
Validation loss: 1.9910418564273464

Epoch: 6| Step: 7
Training loss: 1.727227807044983
Validation loss: 1.97954422684126

Epoch: 6| Step: 8
Training loss: 1.7810380458831787
Validation loss: 1.986451316905278

Epoch: 6| Step: 9
Training loss: 2.1130709648132324
Validation loss: 1.9901901829627253

Epoch: 6| Step: 10
Training loss: 1.8086657524108887
Validation loss: 1.9790139775122366

Epoch: 6| Step: 11
Training loss: 3.0167527198791504
Validation loss: 1.992392175941057

Epoch: 6| Step: 12
Training loss: 1.91640305519104
Validation loss: 2.0055955379239974

Epoch: 6| Step: 13
Training loss: 1.7992804050445557
Validation loss: 1.9886215399670344

Epoch: 89| Step: 0
Training loss: 2.1253437995910645
Validation loss: 2.002852701371716

Epoch: 6| Step: 1
Training loss: 2.5911924839019775
Validation loss: 1.9854709922626455

Epoch: 6| Step: 2
Training loss: 2.1101632118225098
Validation loss: 1.9822284790777391

Epoch: 6| Step: 3
Training loss: 1.4061545133590698
Validation loss: 1.9947825836878952

Epoch: 6| Step: 4
Training loss: 2.5978307723999023
Validation loss: 1.9959124416433356

Epoch: 6| Step: 5
Training loss: 2.454047441482544
Validation loss: 2.0081178744633994

Epoch: 6| Step: 6
Training loss: 1.9185274839401245
Validation loss: 1.9818139717143068

Epoch: 6| Step: 7
Training loss: 2.535360097885132
Validation loss: 1.9768186153904084

Epoch: 6| Step: 8
Training loss: 2.4486746788024902
Validation loss: 1.9983468440271193

Epoch: 6| Step: 9
Training loss: 1.914046287536621
Validation loss: 1.9785908986163396

Epoch: 6| Step: 10
Training loss: 2.437040328979492
Validation loss: 1.9968767601956603

Epoch: 6| Step: 11
Training loss: 2.152926445007324
Validation loss: 1.9991609306745632

Epoch: 6| Step: 12
Training loss: 1.9157010316848755
Validation loss: 2.010255302152326

Epoch: 6| Step: 13
Training loss: 1.604705810546875
Validation loss: 2.0004964720818306

Epoch: 90| Step: 0
Training loss: 2.6556825637817383
Validation loss: 2.0067964702524166

Epoch: 6| Step: 1
Training loss: 1.963989019393921
Validation loss: 1.9890881430718206

Epoch: 6| Step: 2
Training loss: 1.343654751777649
Validation loss: 2.0040658109931537

Epoch: 6| Step: 3
Training loss: 2.6169614791870117
Validation loss: 2.0059762103583223

Epoch: 6| Step: 4
Training loss: 1.6901661157608032
Validation loss: 1.9969321156060824

Epoch: 6| Step: 5
Training loss: 2.165846824645996
Validation loss: 2.0073115697471042

Epoch: 6| Step: 6
Training loss: 2.0848922729492188
Validation loss: 2.001893119145465

Epoch: 6| Step: 7
Training loss: 2.6908018589019775
Validation loss: 1.9868968558567826

Epoch: 6| Step: 8
Training loss: 2.4362165927886963
Validation loss: 2.007101115360055

Epoch: 6| Step: 9
Training loss: 2.208858013153076
Validation loss: 1.9934974742192093

Epoch: 6| Step: 10
Training loss: 1.9550161361694336
Validation loss: 2.0048549047080417

Epoch: 6| Step: 11
Training loss: 1.6279343366622925
Validation loss: 2.0258723061571837

Epoch: 6| Step: 12
Training loss: 2.734880208969116
Validation loss: 2.0097834217932915

Epoch: 6| Step: 13
Training loss: 2.0665242671966553
Validation loss: 2.0088667472203574

Epoch: 91| Step: 0
Training loss: 1.1810332536697388
Validation loss: 2.0280681835707797

Epoch: 6| Step: 1
Training loss: 2.328570604324341
Validation loss: 2.022712366555327

Epoch: 6| Step: 2
Training loss: 2.552654266357422
Validation loss: 2.019659471768205

Epoch: 6| Step: 3
Training loss: 2.0778331756591797
Validation loss: 2.0283921200742006

Epoch: 6| Step: 4
Training loss: 2.0702388286590576
Validation loss: 2.0442028353291173

Epoch: 6| Step: 5
Training loss: 1.7936190366744995
Validation loss: 2.0364582974423646

Epoch: 6| Step: 6
Training loss: 1.7844525575637817
Validation loss: 2.04176672556067

Epoch: 6| Step: 7
Training loss: 2.2598681449890137
Validation loss: 2.042712985828359

Epoch: 6| Step: 8
Training loss: 3.0647201538085938
Validation loss: 2.0411101054119807

Epoch: 6| Step: 9
Training loss: 2.891392946243286
Validation loss: 2.046429593075988

Epoch: 6| Step: 10
Training loss: 2.38749623298645
Validation loss: 2.0414344828615905

Epoch: 6| Step: 11
Training loss: 1.7307316064834595
Validation loss: 2.038421151458576

Epoch: 6| Step: 12
Training loss: 2.200896978378296
Validation loss: 2.0347446959505797

Epoch: 6| Step: 13
Training loss: 2.058627128601074
Validation loss: 2.0424424755957817

Epoch: 92| Step: 0
Training loss: 1.739495038986206
Validation loss: 2.0398832418585338

Epoch: 6| Step: 1
Training loss: 2.008385181427002
Validation loss: 2.030387370817123

Epoch: 6| Step: 2
Training loss: 2.1591696739196777
Validation loss: 2.052346532062818

Epoch: 6| Step: 3
Training loss: 2.1650514602661133
Validation loss: 2.0172579442301104

Epoch: 6| Step: 4
Training loss: 2.129807233810425
Validation loss: 2.023518493098597

Epoch: 6| Step: 5
Training loss: 2.589691162109375
Validation loss: 2.052844580783639

Epoch: 6| Step: 6
Training loss: 2.010108232498169
Validation loss: 2.0403470403404644

Epoch: 6| Step: 7
Training loss: 2.2415051460266113
Validation loss: 2.0182861102524625

Epoch: 6| Step: 8
Training loss: 1.9026641845703125
Validation loss: 2.0195217465841644

Epoch: 6| Step: 9
Training loss: 2.284167766571045
Validation loss: 2.0243542425094114

Epoch: 6| Step: 10
Training loss: 2.6204442977905273
Validation loss: 2.0111569461002143

Epoch: 6| Step: 11
Training loss: 2.3325538635253906
Validation loss: 2.0283877208668697

Epoch: 6| Step: 12
Training loss: 2.6039278507232666
Validation loss: 2.0189319631104827

Epoch: 6| Step: 13
Training loss: 1.299716591835022
Validation loss: 2.0251481930414834

Epoch: 93| Step: 0
Training loss: 2.2920076847076416
Validation loss: 2.0324815857794976

Epoch: 6| Step: 1
Training loss: 2.5523128509521484
Validation loss: 2.0362423440461517

Epoch: 6| Step: 2
Training loss: 2.158294916152954
Validation loss: 2.040009443477918

Epoch: 6| Step: 3
Training loss: 1.425166368484497
Validation loss: 2.001436097647554

Epoch: 6| Step: 4
Training loss: 3.056328535079956
Validation loss: 2.018970897120814

Epoch: 6| Step: 5
Training loss: 2.089763641357422
Validation loss: 2.041273616975354

Epoch: 6| Step: 6
Training loss: 2.3322877883911133
Validation loss: 2.058199700488839

Epoch: 6| Step: 7
Training loss: 2.371009349822998
Validation loss: 2.021365319528887

Epoch: 6| Step: 8
Training loss: 2.192566394805908
Validation loss: 2.0344510680885723

Epoch: 6| Step: 9
Training loss: 1.9054971933364868
Validation loss: 2.050342930260525

Epoch: 6| Step: 10
Training loss: 1.8190056085586548
Validation loss: 2.0309069387374388

Epoch: 6| Step: 11
Training loss: 2.0418190956115723
Validation loss: 2.0238529354013424

Epoch: 6| Step: 12
Training loss: 1.8104649782180786
Validation loss: 2.0087465701564664

Epoch: 6| Step: 13
Training loss: 2.5240304470062256
Validation loss: 2.0402132106083695

Epoch: 94| Step: 0
Training loss: 2.723165988922119
Validation loss: 2.0004759988477154

Epoch: 6| Step: 1
Training loss: 1.9988558292388916
Validation loss: 2.0124046200065204

Epoch: 6| Step: 2
Training loss: 2.0827505588531494
Validation loss: 2.0043484651914207

Epoch: 6| Step: 3
Training loss: 2.1654229164123535
Validation loss: 2.028884982550016

Epoch: 6| Step: 4
Training loss: 2.510237693786621
Validation loss: 2.0264822898372525

Epoch: 6| Step: 5
Training loss: 2.6994223594665527
Validation loss: 2.022802132432179

Epoch: 6| Step: 6
Training loss: 1.7610912322998047
Validation loss: 2.020959231161302

Epoch: 6| Step: 7
Training loss: 1.7358016967773438
Validation loss: 2.0191004314730243

Epoch: 6| Step: 8
Training loss: 1.9519264698028564
Validation loss: 2.025845228984792

Epoch: 6| Step: 9
Training loss: 1.863451600074768
Validation loss: 2.020504872004191

Epoch: 6| Step: 10
Training loss: 2.279536008834839
Validation loss: 2.0171426701289352

Epoch: 6| Step: 11
Training loss: 2.0635902881622314
Validation loss: 2.0208093594479304

Epoch: 6| Step: 12
Training loss: 2.3079209327697754
Validation loss: 2.037077598674323

Epoch: 6| Step: 13
Training loss: 2.0499508380889893
Validation loss: 2.011528540683049

Epoch: 95| Step: 0
Training loss: 1.0036206245422363
Validation loss: 2.0212994724191646

Epoch: 6| Step: 1
Training loss: 2.8600361347198486
Validation loss: 1.9944273912778465

Epoch: 6| Step: 2
Training loss: 1.9865307807922363
Validation loss: 2.0299665530522666

Epoch: 6| Step: 3
Training loss: 1.9995975494384766
Validation loss: 1.9864751536359069

Epoch: 6| Step: 4
Training loss: 2.2868576049804688
Validation loss: 1.9955085426248529

Epoch: 6| Step: 5
Training loss: 2.351243495941162
Validation loss: 2.007704416910807

Epoch: 6| Step: 6
Training loss: 2.2716472148895264
Validation loss: 1.9829103241684616

Epoch: 6| Step: 7
Training loss: 1.8378899097442627
Validation loss: 2.008560014027421

Epoch: 6| Step: 8
Training loss: 2.7241804599761963
Validation loss: 2.0005869352689354

Epoch: 6| Step: 9
Training loss: 2.5763497352600098
Validation loss: 1.9926655497602237

Epoch: 6| Step: 10
Training loss: 2.1551437377929688
Validation loss: 1.9920132788278724

Epoch: 6| Step: 11
Training loss: 1.9678776264190674
Validation loss: 2.0199701593768213

Epoch: 6| Step: 12
Training loss: 2.226055145263672
Validation loss: 2.010315397734283

Epoch: 6| Step: 13
Training loss: 2.277615547180176
Validation loss: 1.9914624511554677

Epoch: 96| Step: 0
Training loss: 2.1182639598846436
Validation loss: 1.9799671942187893

Epoch: 6| Step: 1
Training loss: 2.3966622352600098
Validation loss: 2.0023048846952376

Epoch: 6| Step: 2
Training loss: 2.514284133911133
Validation loss: 1.9996846375926849

Epoch: 6| Step: 3
Training loss: 1.8960239887237549
Validation loss: 1.9995399546879593

Epoch: 6| Step: 4
Training loss: 2.4362831115722656
Validation loss: 2.016017662581577

Epoch: 6| Step: 5
Training loss: 1.7519692182540894
Validation loss: 2.0095888953055105

Epoch: 6| Step: 6
Training loss: 2.0242221355438232
Validation loss: 2.0069352567836805

Epoch: 6| Step: 7
Training loss: 2.4463086128234863
Validation loss: 2.0301208367911716

Epoch: 6| Step: 8
Training loss: 1.682516098022461
Validation loss: 2.027711165848599

Epoch: 6| Step: 9
Training loss: 2.6254420280456543
Validation loss: 2.009908181364818

Epoch: 6| Step: 10
Training loss: 1.8464038372039795
Validation loss: 2.0223748248110534

Epoch: 6| Step: 11
Training loss: 1.8934998512268066
Validation loss: 2.0266238668913483

Epoch: 6| Step: 12
Training loss: 2.7195167541503906
Validation loss: 1.9994677741040465

Epoch: 6| Step: 13
Training loss: 1.7331079244613647
Validation loss: 2.0146646884179886

Epoch: 97| Step: 0
Training loss: 1.4614994525909424
Validation loss: 1.9957886613825315

Epoch: 6| Step: 1
Training loss: 2.563892364501953
Validation loss: 2.0066804988409883

Epoch: 6| Step: 2
Training loss: 1.105639100074768
Validation loss: 2.008800423273476

Epoch: 6| Step: 3
Training loss: 1.8265893459320068
Validation loss: 1.9979464700145106

Epoch: 6| Step: 4
Training loss: 2.0713047981262207
Validation loss: 1.9933858148513302

Epoch: 6| Step: 5
Training loss: 1.9743201732635498
Validation loss: 2.0229161452221613

Epoch: 6| Step: 6
Training loss: 2.6450860500335693
Validation loss: 2.0054159215701524

Epoch: 6| Step: 7
Training loss: 2.393202781677246
Validation loss: 1.999042167458483

Epoch: 6| Step: 8
Training loss: 1.668532371520996
Validation loss: 2.0230868426702355

Epoch: 6| Step: 9
Training loss: 2.9354913234710693
Validation loss: 1.985794553192713

Epoch: 6| Step: 10
Training loss: 2.299867630004883
Validation loss: 2.0011285069168254

Epoch: 6| Step: 11
Training loss: 2.715080976486206
Validation loss: 2.0179061428193124

Epoch: 6| Step: 12
Training loss: 2.0623888969421387
Validation loss: 1.9981227984992407

Epoch: 6| Step: 13
Training loss: 2.8401637077331543
Validation loss: 1.9968636458919895

Epoch: 98| Step: 0
Training loss: 1.7787340879440308
Validation loss: 1.9864020475777246

Epoch: 6| Step: 1
Training loss: 1.8738515377044678
Validation loss: 1.983648943644698

Epoch: 6| Step: 2
Training loss: 2.515002727508545
Validation loss: 1.9830753418707079

Epoch: 6| Step: 3
Training loss: 2.365009307861328
Validation loss: 2.0015135170311056

Epoch: 6| Step: 4
Training loss: 1.8281229734420776
Validation loss: 1.9970233414762764

Epoch: 6| Step: 5
Training loss: 2.4805960655212402
Validation loss: 1.9907707040027907

Epoch: 6| Step: 6
Training loss: 1.5383243560791016
Validation loss: 2.0161410659872074

Epoch: 6| Step: 7
Training loss: 2.23154878616333
Validation loss: 1.990296733635728

Epoch: 6| Step: 8
Training loss: 2.974893093109131
Validation loss: 2.0065288005336637

Epoch: 6| Step: 9
Training loss: 2.032768726348877
Validation loss: 2.007736475236954

Epoch: 6| Step: 10
Training loss: 2.5472159385681152
Validation loss: 1.9950449351341493

Epoch: 6| Step: 11
Training loss: 2.0563580989837646
Validation loss: 1.9789438721954182

Epoch: 6| Step: 12
Training loss: 2.223353862762451
Validation loss: 1.9846685945346791

Epoch: 6| Step: 13
Training loss: 1.7438818216323853
Validation loss: 1.9752865837466331

Epoch: 99| Step: 0
Training loss: 3.2342264652252197
Validation loss: 1.9989206124377508

Epoch: 6| Step: 1
Training loss: 2.067321300506592
Validation loss: 1.9978161293973205

Epoch: 6| Step: 2
Training loss: 2.663930892944336
Validation loss: 2.00416362285614

Epoch: 6| Step: 3
Training loss: 2.352025032043457
Validation loss: 2.005697158075148

Epoch: 6| Step: 4
Training loss: 1.784906029701233
Validation loss: 2.008921118192775

Epoch: 6| Step: 5
Training loss: 1.996277093887329
Validation loss: 2.027753842774258

Epoch: 6| Step: 6
Training loss: 2.504648447036743
Validation loss: 1.9868411479457733

Epoch: 6| Step: 7
Training loss: 1.6053712368011475
Validation loss: 2.0198273325479157

Epoch: 6| Step: 8
Training loss: 2.0740349292755127
Validation loss: 2.0126013371252243

Epoch: 6| Step: 9
Training loss: 1.3304070234298706
Validation loss: 2.01979846595436

Epoch: 6| Step: 10
Training loss: 2.293440818786621
Validation loss: 2.0028535114821566

Epoch: 6| Step: 11
Training loss: 1.5466433763504028
Validation loss: 2.023125026815681

Epoch: 6| Step: 12
Training loss: 2.227644681930542
Validation loss: 2.0240614850033998

Epoch: 6| Step: 13
Training loss: 2.5243847370147705
Validation loss: 2.0069293898920857

Epoch: 100| Step: 0
Training loss: 1.848029375076294
Validation loss: 2.0280192769983763

Epoch: 6| Step: 1
Training loss: 2.5730581283569336
Validation loss: 2.027566338098177

Epoch: 6| Step: 2
Training loss: 1.982170581817627
Validation loss: 1.9935814642137097

Epoch: 6| Step: 3
Training loss: 2.449570894241333
Validation loss: 2.0111472375931276

Epoch: 6| Step: 4
Training loss: 1.969408392906189
Validation loss: 1.9913824681312806

Epoch: 6| Step: 5
Training loss: 2.698897361755371
Validation loss: 2.015673404098839

Epoch: 6| Step: 6
Training loss: 2.6186141967773438
Validation loss: 2.0073738264781174

Epoch: 6| Step: 7
Training loss: 1.8948804140090942
Validation loss: 2.01223430069544

Epoch: 6| Step: 8
Training loss: 1.7948203086853027
Validation loss: 1.9984230815723378

Epoch: 6| Step: 9
Training loss: 2.1954879760742188
Validation loss: 2.0104966368726505

Epoch: 6| Step: 10
Training loss: 1.862842321395874
Validation loss: 1.9894438584645588

Epoch: 6| Step: 11
Training loss: 2.1988697052001953
Validation loss: 2.0091497282828055

Epoch: 6| Step: 12
Training loss: 2.29164719581604
Validation loss: 1.9980365332736765

Epoch: 6| Step: 13
Training loss: 1.4973628520965576
Validation loss: 2.0092514099613314

Epoch: 101| Step: 0
Training loss: 2.6152803897857666
Validation loss: 2.0105254688570575

Epoch: 6| Step: 1
Training loss: 2.1900064945220947
Validation loss: 1.998362107943463

Epoch: 6| Step: 2
Training loss: 2.161837577819824
Validation loss: 2.0139837098378006

Epoch: 6| Step: 3
Training loss: 1.621708631515503
Validation loss: 1.9994214106631536

Epoch: 6| Step: 4
Training loss: 2.9731693267822266
Validation loss: 2.0019509933328115

Epoch: 6| Step: 5
Training loss: 2.328212022781372
Validation loss: 2.009990958757298

Epoch: 6| Step: 6
Training loss: 1.863680124282837
Validation loss: 1.9997699158166045

Epoch: 6| Step: 7
Training loss: 2.117476224899292
Validation loss: 2.0188830129561888

Epoch: 6| Step: 8
Training loss: 2.3031723499298096
Validation loss: 2.0346640976526404

Epoch: 6| Step: 9
Training loss: 1.0580953359603882
Validation loss: 2.0066574722208004

Epoch: 6| Step: 10
Training loss: 2.0395660400390625
Validation loss: 2.0159466984451457

Epoch: 6| Step: 11
Training loss: 2.8765015602111816
Validation loss: 2.0130139371400237

Epoch: 6| Step: 12
Training loss: 1.9696778059005737
Validation loss: 2.0123209261125132

Epoch: 6| Step: 13
Training loss: 1.9914801120758057
Validation loss: 2.0142627416118497

Epoch: 102| Step: 0
Training loss: 2.5128064155578613
Validation loss: 2.0197338083738923

Epoch: 6| Step: 1
Training loss: 1.7172069549560547
Validation loss: 2.0301073494777886

Epoch: 6| Step: 2
Training loss: 1.8676968812942505
Validation loss: 2.010825977530531

Epoch: 6| Step: 3
Training loss: 2.743626594543457
Validation loss: 2.0069676471012894

Epoch: 6| Step: 4
Training loss: 2.2358434200286865
Validation loss: 2.0300250386679046

Epoch: 6| Step: 5
Training loss: 1.8197014331817627
Validation loss: 2.024752655336934

Epoch: 6| Step: 6
Training loss: 2.595606803894043
Validation loss: 2.029003704747846

Epoch: 6| Step: 7
Training loss: 2.1382217407226562
Validation loss: 2.0248676012921076

Epoch: 6| Step: 8
Training loss: 1.6773985624313354
Validation loss: 2.023599433642562

Epoch: 6| Step: 9
Training loss: 1.8061811923980713
Validation loss: 2.032201793886

Epoch: 6| Step: 10
Training loss: 2.3881444931030273
Validation loss: 2.0381307217382614

Epoch: 6| Step: 11
Training loss: 2.424008846282959
Validation loss: 2.0096160288779967

Epoch: 6| Step: 12
Training loss: 1.7295305728912354
Validation loss: 2.0248569391107045

Epoch: 6| Step: 13
Training loss: 2.5240564346313477
Validation loss: 2.024400862314368

Epoch: 103| Step: 0
Training loss: 1.4344321489334106
Validation loss: 2.0287025487551125

Epoch: 6| Step: 1
Training loss: 2.2145328521728516
Validation loss: 2.020317400655439

Epoch: 6| Step: 2
Training loss: 2.096804141998291
Validation loss: 2.023072704192131

Epoch: 6| Step: 3
Training loss: 2.026803970336914
Validation loss: 2.038534406692751

Epoch: 6| Step: 4
Training loss: 1.8606524467468262
Validation loss: 2.043172936285696

Epoch: 6| Step: 5
Training loss: 2.12510085105896
Validation loss: 2.0258270284181

Epoch: 6| Step: 6
Training loss: 2.4383811950683594
Validation loss: 2.058900289638068

Epoch: 6| Step: 7
Training loss: 1.8788509368896484
Validation loss: 2.0542304285110964

Epoch: 6| Step: 8
Training loss: 1.9469718933105469
Validation loss: 2.036079681047829

Epoch: 6| Step: 9
Training loss: 2.604238510131836
Validation loss: 2.0174557880688737

Epoch: 6| Step: 10
Training loss: 1.9149419069290161
Validation loss: 2.0232065531515304

Epoch: 6| Step: 11
Training loss: 1.995192289352417
Validation loss: 2.0308205927571943

Epoch: 6| Step: 12
Training loss: 2.7118544578552246
Validation loss: 2.0219102392914476

Epoch: 6| Step: 13
Training loss: 3.053044557571411
Validation loss: 2.019056623981845

Epoch: 104| Step: 0
Training loss: 2.193655014038086
Validation loss: 2.0363365527122252

Epoch: 6| Step: 1
Training loss: 1.9721124172210693
Validation loss: 2.0075631577481508

Epoch: 6| Step: 2
Training loss: 1.9799187183380127
Validation loss: 2.016816953177093

Epoch: 6| Step: 3
Training loss: 2.9883933067321777
Validation loss: 2.009062477337417

Epoch: 6| Step: 4
Training loss: 2.8243377208709717
Validation loss: 2.012811633848375

Epoch: 6| Step: 5
Training loss: 1.9737132787704468
Validation loss: 2.0059987165594615

Epoch: 6| Step: 6
Training loss: 2.189751625061035
Validation loss: 2.0016781745418424

Epoch: 6| Step: 7
Training loss: 1.3627815246582031
Validation loss: 1.9672827695005684

Epoch: 6| Step: 8
Training loss: 2.332263708114624
Validation loss: 1.9975494748802596

Epoch: 6| Step: 9
Training loss: 1.9329171180725098
Validation loss: 1.9823199933575046

Epoch: 6| Step: 10
Training loss: 2.023939371109009
Validation loss: 2.0090016959815897

Epoch: 6| Step: 11
Training loss: 2.061577558517456
Validation loss: 1.9946230842221169

Epoch: 6| Step: 12
Training loss: 2.223459243774414
Validation loss: 1.9829607548252228

Epoch: 6| Step: 13
Training loss: 1.8164106607437134
Validation loss: 1.9821138728049494

Epoch: 105| Step: 0
Training loss: 2.0480542182922363
Validation loss: 1.9817906118208362

Epoch: 6| Step: 1
Training loss: 2.4323267936706543
Validation loss: 1.9771805219752814

Epoch: 6| Step: 2
Training loss: 1.4651684761047363
Validation loss: 1.9848719130280197

Epoch: 6| Step: 3
Training loss: 2.445016860961914
Validation loss: 1.9892836257975588

Epoch: 6| Step: 4
Training loss: 1.9218310117721558
Validation loss: 1.9896309311671923

Epoch: 6| Step: 5
Training loss: 2.5103940963745117
Validation loss: 1.9853396043982556

Epoch: 6| Step: 6
Training loss: 2.4845399856567383
Validation loss: 2.0049614060309624

Epoch: 6| Step: 7
Training loss: 1.6100780963897705
Validation loss: 1.997548222541809

Epoch: 6| Step: 8
Training loss: 1.9175262451171875
Validation loss: 2.011574863105692

Epoch: 6| Step: 9
Training loss: 2.583418846130371
Validation loss: 2.0020755926767984

Epoch: 6| Step: 10
Training loss: 1.9535319805145264
Validation loss: 2.012113150729928

Epoch: 6| Step: 11
Training loss: 2.5296530723571777
Validation loss: 2.002010331358961

Epoch: 6| Step: 12
Training loss: 1.6914348602294922
Validation loss: 2.0066236321644118

Epoch: 6| Step: 13
Training loss: 2.484403371810913
Validation loss: 2.010550461789613

Epoch: 106| Step: 0
Training loss: 2.327040195465088
Validation loss: 2.0259098417015484

Epoch: 6| Step: 1
Training loss: 2.2920844554901123
Validation loss: 2.012283379031766

Epoch: 6| Step: 2
Training loss: 1.5005512237548828
Validation loss: 2.019432426780783

Epoch: 6| Step: 3
Training loss: 1.7866178750991821
Validation loss: 1.9886792936632711

Epoch: 6| Step: 4
Training loss: 2.1239495277404785
Validation loss: 2.000929529948901

Epoch: 6| Step: 5
Training loss: 2.130852699279785
Validation loss: 2.0115108566899456

Epoch: 6| Step: 6
Training loss: 2.1524739265441895
Validation loss: 1.9934306670260686

Epoch: 6| Step: 7
Training loss: 1.576366662979126
Validation loss: 1.9859098272938882

Epoch: 6| Step: 8
Training loss: 2.6544384956359863
Validation loss: 1.9926035481114541

Epoch: 6| Step: 9
Training loss: 2.971567153930664
Validation loss: 1.9928611837407595

Epoch: 6| Step: 10
Training loss: 1.8992730379104614
Validation loss: 1.98315353034645

Epoch: 6| Step: 11
Training loss: 2.2134265899658203
Validation loss: 1.987788841288577

Epoch: 6| Step: 12
Training loss: 2.158945083618164
Validation loss: 1.999155185555899

Epoch: 6| Step: 13
Training loss: 2.065291404724121
Validation loss: 1.9973875963559715

Epoch: 107| Step: 0
Training loss: 1.3797118663787842
Validation loss: 1.9973271380188644

Epoch: 6| Step: 1
Training loss: 2.211005449295044
Validation loss: 1.9840298032247892

Epoch: 6| Step: 2
Training loss: 2.2736973762512207
Validation loss: 1.9969727095737253

Epoch: 6| Step: 3
Training loss: 1.81744384765625
Validation loss: 2.0006507673571186

Epoch: 6| Step: 4
Training loss: 2.071641445159912
Validation loss: 1.9924136797587078

Epoch: 6| Step: 5
Training loss: 2.484375476837158
Validation loss: 1.9882061148202548

Epoch: 6| Step: 6
Training loss: 2.2472586631774902
Validation loss: 1.9826419135575652

Epoch: 6| Step: 7
Training loss: 2.3492226600646973
Validation loss: 2.0003795008505545

Epoch: 6| Step: 8
Training loss: 1.5531893968582153
Validation loss: 1.9747702716499247

Epoch: 6| Step: 9
Training loss: 1.8391342163085938
Validation loss: 1.9790333086444485

Epoch: 6| Step: 10
Training loss: 2.376358985900879
Validation loss: 1.9945499063819967

Epoch: 6| Step: 11
Training loss: 2.532991409301758
Validation loss: 2.007534655191565

Epoch: 6| Step: 12
Training loss: 2.487185478210449
Validation loss: 1.9950301698459092

Epoch: 6| Step: 13
Training loss: 2.3186392784118652
Validation loss: 1.9818919474078762

Epoch: 108| Step: 0
Training loss: 1.6655693054199219
Validation loss: 1.9941190647822555

Epoch: 6| Step: 1
Training loss: 1.9467397928237915
Validation loss: 2.000448029528382

Epoch: 6| Step: 2
Training loss: 1.6960654258728027
Validation loss: 1.9945700450610089

Epoch: 6| Step: 3
Training loss: 2.2077908515930176
Validation loss: 1.992254896830487

Epoch: 6| Step: 4
Training loss: 1.98173987865448
Validation loss: 1.9914995957446355

Epoch: 6| Step: 5
Training loss: 1.9186196327209473
Validation loss: 1.9919744306995022

Epoch: 6| Step: 6
Training loss: 1.8978326320648193
Validation loss: 2.015624605199342

Epoch: 6| Step: 7
Training loss: 1.7868704795837402
Validation loss: 2.0102077197003108

Epoch: 6| Step: 8
Training loss: 1.8059245347976685
Validation loss: 2.001227068644698

Epoch: 6| Step: 9
Training loss: 2.389587879180908
Validation loss: 1.9935364184841033

Epoch: 6| Step: 10
Training loss: 2.7400131225585938
Validation loss: 2.012936165255885

Epoch: 6| Step: 11
Training loss: 3.279470443725586
Validation loss: 1.9944157408129783

Epoch: 6| Step: 12
Training loss: 2.2545676231384277
Validation loss: 2.0072836029914116

Epoch: 6| Step: 13
Training loss: 2.069729804992676
Validation loss: 2.014365864056413

Epoch: 109| Step: 0
Training loss: 2.424520254135132
Validation loss: 2.0023952197003108

Epoch: 6| Step: 1
Training loss: 1.9641923904418945
Validation loss: 2.0020740519287767

Epoch: 6| Step: 2
Training loss: 2.3626368045806885
Validation loss: 2.012239045994256

Epoch: 6| Step: 3
Training loss: 3.1792821884155273
Validation loss: 1.996947926859702

Epoch: 6| Step: 4
Training loss: 1.7867454290390015
Validation loss: 1.98210512181764

Epoch: 6| Step: 5
Training loss: 2.310012102127075
Validation loss: 2.0174623138161114

Epoch: 6| Step: 6
Training loss: 1.0555901527404785
Validation loss: 1.9932980383596113

Epoch: 6| Step: 7
Training loss: 1.8536663055419922
Validation loss: 2.01200101196125

Epoch: 6| Step: 8
Training loss: 1.8491623401641846
Validation loss: 1.9991961320241292

Epoch: 6| Step: 9
Training loss: 2.2396597862243652
Validation loss: 1.9860974409246956

Epoch: 6| Step: 10
Training loss: 2.099790573120117
Validation loss: 2.008790668620858

Epoch: 6| Step: 11
Training loss: 2.2938389778137207
Validation loss: 2.0080694511372554

Epoch: 6| Step: 12
Training loss: 1.772452473640442
Validation loss: 1.9971907010642431

Epoch: 6| Step: 13
Training loss: 2.7382969856262207
Validation loss: 2.0096051718599055

Epoch: 110| Step: 0
Training loss: 2.4156837463378906
Validation loss: 2.0080043167196293

Epoch: 6| Step: 1
Training loss: 2.130505084991455
Validation loss: 2.023619400557651

Epoch: 6| Step: 2
Training loss: 2.015763759613037
Validation loss: 2.0179225706285044

Epoch: 6| Step: 3
Training loss: 1.8328471183776855
Validation loss: 2.0128834709044425

Epoch: 6| Step: 4
Training loss: 2.3711655139923096
Validation loss: 2.0082246565049693

Epoch: 6| Step: 5
Training loss: 1.6131117343902588
Validation loss: 2.012427488962809

Epoch: 6| Step: 6
Training loss: 1.8568413257598877
Validation loss: 2.0087158372325282

Epoch: 6| Step: 7
Training loss: 1.9178271293640137
Validation loss: 2.0110849308711227

Epoch: 6| Step: 8
Training loss: 1.7005364894866943
Validation loss: 2.0118922853982575

Epoch: 6| Step: 9
Training loss: 2.603116273880005
Validation loss: 2.0359713159581667

Epoch: 6| Step: 10
Training loss: 1.8576853275299072
Validation loss: 2.0429487510394027

Epoch: 6| Step: 11
Training loss: 2.251619577407837
Validation loss: 2.0062055741586993

Epoch: 6| Step: 12
Training loss: 2.3021926879882812
Validation loss: 2.0162240151436097

Epoch: 6| Step: 13
Training loss: 3.4360032081604004
Validation loss: 2.00648933072244

Epoch: 111| Step: 0
Training loss: 2.5300967693328857
Validation loss: 2.023034405964677

Epoch: 6| Step: 1
Training loss: 2.7022714614868164
Validation loss: 2.0238617671433317

Epoch: 6| Step: 2
Training loss: 2.1085171699523926
Validation loss: 2.0232976508396927

Epoch: 6| Step: 3
Training loss: 1.8944706916809082
Validation loss: 2.021448427631009

Epoch: 6| Step: 4
Training loss: 2.0066399574279785
Validation loss: 2.0184905247021745

Epoch: 6| Step: 5
Training loss: 2.321183919906616
Validation loss: 2.0143887368581628

Epoch: 6| Step: 6
Training loss: 1.6066882610321045
Validation loss: 2.02889129166962

Epoch: 6| Step: 7
Training loss: 2.092444658279419
Validation loss: 2.0178662756437897

Epoch: 6| Step: 8
Training loss: 2.3258960247039795
Validation loss: 2.013823213115815

Epoch: 6| Step: 9
Training loss: 1.6653697490692139
Validation loss: 2.035000305021963

Epoch: 6| Step: 10
Training loss: 1.9752411842346191
Validation loss: 1.9935691202840498

Epoch: 6| Step: 11
Training loss: 2.0086050033569336
Validation loss: 2.0157870349063667

Epoch: 6| Step: 12
Training loss: 2.3588812351226807
Validation loss: 2.0182548979277253

Epoch: 6| Step: 13
Training loss: 1.9823671579360962
Validation loss: 2.004576039570634

Epoch: 112| Step: 0
Training loss: 1.3865913152694702
Validation loss: 1.997461659933931

Epoch: 6| Step: 1
Training loss: 1.5183632373809814
Validation loss: 1.9974682971995363

Epoch: 6| Step: 2
Training loss: 2.0294880867004395
Validation loss: 1.9906177982207267

Epoch: 6| Step: 3
Training loss: 2.5323028564453125
Validation loss: 2.000395522322706

Epoch: 6| Step: 4
Training loss: 2.036320447921753
Validation loss: 2.0031390651579826

Epoch: 6| Step: 5
Training loss: 1.8319928646087646
Validation loss: 1.991079645772134

Epoch: 6| Step: 6
Training loss: 1.6162524223327637
Validation loss: 1.9850824686788744

Epoch: 6| Step: 7
Training loss: 1.9051837921142578
Validation loss: 1.9739991029103596

Epoch: 6| Step: 8
Training loss: 2.540639877319336
Validation loss: 1.9912268577083465

Epoch: 6| Step: 9
Training loss: 2.694587230682373
Validation loss: 1.9863861837694723

Epoch: 6| Step: 10
Training loss: 2.777592182159424
Validation loss: 1.9658038205997919

Epoch: 6| Step: 11
Training loss: 2.5596492290496826
Validation loss: 1.9925217807933848

Epoch: 6| Step: 12
Training loss: 1.837289571762085
Validation loss: 1.981441738784954

Epoch: 6| Step: 13
Training loss: 2.7883715629577637
Validation loss: 1.9703808817812192

Epoch: 113| Step: 0
Training loss: 1.3120956420898438
Validation loss: 2.0110568051697104

Epoch: 6| Step: 1
Training loss: 2.0543105602264404
Validation loss: 2.009112940039686

Epoch: 6| Step: 2
Training loss: 2.1916415691375732
Validation loss: 2.0031607151031494

Epoch: 6| Step: 3
Training loss: 2.1663894653320312
Validation loss: 1.9819959953267088

Epoch: 6| Step: 4
Training loss: 2.5097339153289795
Validation loss: 1.9889589919838855

Epoch: 6| Step: 5
Training loss: 1.9478285312652588
Validation loss: 1.9894877864468483

Epoch: 6| Step: 6
Training loss: 2.25262713432312
Validation loss: 1.9972470498854114

Epoch: 6| Step: 7
Training loss: 2.2283143997192383
Validation loss: 2.0089038520730953

Epoch: 6| Step: 8
Training loss: 1.7916314601898193
Validation loss: 2.0181121005806872

Epoch: 6| Step: 9
Training loss: 1.5740982294082642
Validation loss: 2.0059314415019047

Epoch: 6| Step: 10
Training loss: 2.336073160171509
Validation loss: 1.995655982725082

Epoch: 6| Step: 11
Training loss: 2.4595208168029785
Validation loss: 2.003745778914421

Epoch: 6| Step: 12
Training loss: 2.936683416366577
Validation loss: 2.019282656331216

Epoch: 6| Step: 13
Training loss: 1.3858733177185059
Validation loss: 1.9968554422419558

Epoch: 114| Step: 0
Training loss: 2.5787689685821533
Validation loss: 2.000641420323362

Epoch: 6| Step: 1
Training loss: 2.4845685958862305
Validation loss: 2.0235775311787925

Epoch: 6| Step: 2
Training loss: 1.5705697536468506
Validation loss: 2.0170902603416034

Epoch: 6| Step: 3
Training loss: 2.319831371307373
Validation loss: 2.0270048033806587

Epoch: 6| Step: 4
Training loss: 2.46748685836792
Validation loss: 2.021209127159529

Epoch: 6| Step: 5
Training loss: 1.765916109085083
Validation loss: 2.021339472904

Epoch: 6| Step: 6
Training loss: 1.8353466987609863
Validation loss: 2.024547082121654

Epoch: 6| Step: 7
Training loss: 2.3118677139282227
Validation loss: 2.0181334377616964

Epoch: 6| Step: 8
Training loss: 1.8667361736297607
Validation loss: 2.0329950291623353

Epoch: 6| Step: 9
Training loss: 1.4052377939224243
Validation loss: 2.021118199953469

Epoch: 6| Step: 10
Training loss: 2.4949703216552734
Validation loss: 2.011852510513798

Epoch: 6| Step: 11
Training loss: 2.784700870513916
Validation loss: 2.0080794954812653

Epoch: 6| Step: 12
Training loss: 1.9956644773483276
Validation loss: 2.0126161254862303

Epoch: 6| Step: 13
Training loss: 1.7623674869537354
Validation loss: 2.005965986559468

Epoch: 115| Step: 0
Training loss: 2.0119264125823975
Validation loss: 2.000220725613256

Epoch: 6| Step: 1
Training loss: 2.929011821746826
Validation loss: 1.9975958434484338

Epoch: 6| Step: 2
Training loss: 1.6015278100967407
Validation loss: 2.01796732923036

Epoch: 6| Step: 3
Training loss: 2.5084309577941895
Validation loss: 2.0107908171992146

Epoch: 6| Step: 4
Training loss: 1.9986820220947266
Validation loss: 2.0125221988206268

Epoch: 6| Step: 5
Training loss: 1.783109426498413
Validation loss: 2.011240768176253

Epoch: 6| Step: 6
Training loss: 1.9649994373321533
Validation loss: 2.0333277640804166

Epoch: 6| Step: 7
Training loss: 2.291949510574341
Validation loss: 2.025177458281158

Epoch: 6| Step: 8
Training loss: 2.3583877086639404
Validation loss: 2.0119335087396766

Epoch: 6| Step: 9
Training loss: 2.650270700454712
Validation loss: 2.0326734486446587

Epoch: 6| Step: 10
Training loss: 2.0899276733398438
Validation loss: 2.0376993763831353

Epoch: 6| Step: 11
Training loss: 1.8127321004867554
Validation loss: 2.0178336686985467

Epoch: 6| Step: 12
Training loss: 1.6193174123764038
Validation loss: 2.0167109735550417

Epoch: 6| Step: 13
Training loss: 1.8244116306304932
Validation loss: 2.0139904816945395

Epoch: 116| Step: 0
Training loss: 2.428464889526367
Validation loss: 2.0147983720225673

Epoch: 6| Step: 1
Training loss: 2.2532925605773926
Validation loss: 2.0110390391401065

Epoch: 6| Step: 2
Training loss: 2.1213860511779785
Validation loss: 2.0105316985038018

Epoch: 6| Step: 3
Training loss: 1.7687935829162598
Validation loss: 1.9991917148713143

Epoch: 6| Step: 4
Training loss: 1.8792011737823486
Validation loss: 2.027960346591088

Epoch: 6| Step: 5
Training loss: 1.936495304107666
Validation loss: 2.003626158160548

Epoch: 6| Step: 6
Training loss: 2.394399404525757
Validation loss: 2.029668874638055

Epoch: 6| Step: 7
Training loss: 2.1394331455230713
Validation loss: 2.0391195640769055

Epoch: 6| Step: 8
Training loss: 2.6190664768218994
Validation loss: 2.0066046919873965

Epoch: 6| Step: 9
Training loss: 2.1329855918884277
Validation loss: 2.0177911455913256

Epoch: 6| Step: 10
Training loss: 1.8893353939056396
Validation loss: 2.024767965398809

Epoch: 6| Step: 11
Training loss: 1.8407671451568604
Validation loss: 1.9997472327242616

Epoch: 6| Step: 12
Training loss: 2.0295653343200684
Validation loss: 2.0031288618682535

Epoch: 6| Step: 13
Training loss: 1.6689109802246094
Validation loss: 2.0200515383033344

Epoch: 117| Step: 0
Training loss: 1.9651418924331665
Validation loss: 2.0045081364211215

Epoch: 6| Step: 1
Training loss: 2.261875629425049
Validation loss: 2.003232879023398

Epoch: 6| Step: 2
Training loss: 1.600059151649475
Validation loss: 1.9888315816079416

Epoch: 6| Step: 3
Training loss: 2.380519151687622
Validation loss: 1.9941232153164443

Epoch: 6| Step: 4
Training loss: 2.0274548530578613
Validation loss: 2.0056312904563

Epoch: 6| Step: 5
Training loss: 1.9436774253845215
Validation loss: 2.007320970617315

Epoch: 6| Step: 6
Training loss: 1.8298354148864746
Validation loss: 2.0223972367983993

Epoch: 6| Step: 7
Training loss: 3.1279070377349854
Validation loss: 1.9980763619945896

Epoch: 6| Step: 8
Training loss: 1.3636000156402588
Validation loss: 2.021362018841569

Epoch: 6| Step: 9
Training loss: 1.7389634847640991
Validation loss: 1.9987674784916702

Epoch: 6| Step: 10
Training loss: 2.1248619556427
Validation loss: 2.0077130948343584

Epoch: 6| Step: 11
Training loss: 2.5307180881500244
Validation loss: 1.9938009067248272

Epoch: 6| Step: 12
Training loss: 2.021392345428467
Validation loss: 2.010248395704454

Epoch: 6| Step: 13
Training loss: 2.612497568130493
Validation loss: 2.0188625807403238

Epoch: 118| Step: 0
Training loss: 1.8950499296188354
Validation loss: 1.996280106165076

Epoch: 6| Step: 1
Training loss: 1.3937482833862305
Validation loss: 1.9977782541705715

Epoch: 6| Step: 2
Training loss: 1.9027900695800781
Validation loss: 1.9843164118387366

Epoch: 6| Step: 3
Training loss: 1.828385829925537
Validation loss: 1.9898431493389992

Epoch: 6| Step: 4
Training loss: 1.698720932006836
Validation loss: 1.9715387154650945

Epoch: 6| Step: 5
Training loss: 2.1752192974090576
Validation loss: 1.9730300134228123

Epoch: 6| Step: 6
Training loss: 2.556257724761963
Validation loss: 1.982383733154625

Epoch: 6| Step: 7
Training loss: 2.6691479682922363
Validation loss: 1.9750147378572853

Epoch: 6| Step: 8
Training loss: 1.7189242839813232
Validation loss: 1.9906628093411844

Epoch: 6| Step: 9
Training loss: 2.6412405967712402
Validation loss: 1.9710023672349992

Epoch: 6| Step: 10
Training loss: 1.7614078521728516
Validation loss: 1.976927350926143

Epoch: 6| Step: 11
Training loss: 1.6690726280212402
Validation loss: 1.9773326432833107

Epoch: 6| Step: 12
Training loss: 3.168315887451172
Validation loss: 1.9648316547434816

Epoch: 6| Step: 13
Training loss: 2.6060218811035156
Validation loss: 1.9950162979864305

Epoch: 119| Step: 0
Training loss: 2.2705464363098145
Validation loss: 1.961904764175415

Epoch: 6| Step: 1
Training loss: 2.6006486415863037
Validation loss: 1.986312186846169

Epoch: 6| Step: 2
Training loss: 1.4353033304214478
Validation loss: 1.9906662023195656

Epoch: 6| Step: 3
Training loss: 1.7540130615234375
Validation loss: 1.975157025039837

Epoch: 6| Step: 4
Training loss: 2.458547353744507
Validation loss: 1.9774773992517942

Epoch: 6| Step: 5
Training loss: 1.6241424083709717
Validation loss: 1.9775277196720082

Epoch: 6| Step: 6
Training loss: 1.5907325744628906
Validation loss: 2.001923503414277

Epoch: 6| Step: 7
Training loss: 2.185237169265747
Validation loss: 1.9978586396863383

Epoch: 6| Step: 8
Training loss: 1.9812787771224976
Validation loss: 1.975133308800318

Epoch: 6| Step: 9
Training loss: 2.42349910736084
Validation loss: 2.0064829882755073

Epoch: 6| Step: 10
Training loss: 1.91529381275177
Validation loss: 1.9989944914335847

Epoch: 6| Step: 11
Training loss: 2.5762643814086914
Validation loss: 1.9793725116278535

Epoch: 6| Step: 12
Training loss: 2.012456178665161
Validation loss: 2.0061978191457768

Epoch: 6| Step: 13
Training loss: 2.7540183067321777
Validation loss: 1.9997165062094246

Epoch: 120| Step: 0
Training loss: 1.9081406593322754
Validation loss: 2.0062061355959986

Epoch: 6| Step: 1
Training loss: 2.480316162109375
Validation loss: 2.0137810271273375

Epoch: 6| Step: 2
Training loss: 2.4206230640411377
Validation loss: 2.013248779440439

Epoch: 6| Step: 3
Training loss: 1.3532953262329102
Validation loss: 1.9844837547630392

Epoch: 6| Step: 4
Training loss: 1.880846381187439
Validation loss: 1.99207353848283

Epoch: 6| Step: 5
Training loss: 1.8851726055145264
Validation loss: 1.9710768243317962

Epoch: 6| Step: 6
Training loss: 1.6303133964538574
Validation loss: 1.9852410106248752

Epoch: 6| Step: 7
Training loss: 2.1164286136627197
Validation loss: 2.0034116096394037

Epoch: 6| Step: 8
Training loss: 2.0069079399108887
Validation loss: 1.9834287666505384

Epoch: 6| Step: 9
Training loss: 2.4665112495422363
Validation loss: 1.991026759147644

Epoch: 6| Step: 10
Training loss: 2.072634220123291
Validation loss: 1.9986277203406058

Epoch: 6| Step: 11
Training loss: 2.732057571411133
Validation loss: 1.9894423882166545

Epoch: 6| Step: 12
Training loss: 2.29758882522583
Validation loss: 2.0035958392645723

Epoch: 6| Step: 13
Training loss: 2.1996748447418213
Validation loss: 1.9786464033588287

Epoch: 121| Step: 0
Training loss: 2.721442222595215
Validation loss: 1.9869216488253685

Epoch: 6| Step: 1
Training loss: 1.82071053981781
Validation loss: 1.9847417544293147

Epoch: 6| Step: 2
Training loss: 2.0661892890930176
Validation loss: 1.9785380927465295

Epoch: 6| Step: 3
Training loss: 2.111231803894043
Validation loss: 1.9799570319473103

Epoch: 6| Step: 4
Training loss: 2.2096331119537354
Validation loss: 1.9888878560835315

Epoch: 6| Step: 5
Training loss: 1.9552627801895142
Validation loss: 2.0060076559743574

Epoch: 6| Step: 6
Training loss: 1.8650600910186768
Validation loss: 1.9939639722147295

Epoch: 6| Step: 7
Training loss: 2.285285234451294
Validation loss: 1.9855477861178819

Epoch: 6| Step: 8
Training loss: 1.4046870470046997
Validation loss: 2.000086925363028

Epoch: 6| Step: 9
Training loss: 1.7746374607086182
Validation loss: 1.9796011037723993

Epoch: 6| Step: 10
Training loss: 2.491443157196045
Validation loss: 1.9821809030348254

Epoch: 6| Step: 11
Training loss: 1.8196008205413818
Validation loss: 1.9763994652737853

Epoch: 6| Step: 12
Training loss: 1.899141550064087
Validation loss: 1.9890856537767636

Epoch: 6| Step: 13
Training loss: 3.0347633361816406
Validation loss: 1.9956987288690382

Epoch: 122| Step: 0
Training loss: 1.6454721689224243
Validation loss: 2.011242276878767

Epoch: 6| Step: 1
Training loss: 1.5397303104400635
Validation loss: 1.9872935715542044

Epoch: 6| Step: 2
Training loss: 1.7713459730148315
Validation loss: 1.997574157612298

Epoch: 6| Step: 3
Training loss: 2.075284004211426
Validation loss: 1.9893443738260577

Epoch: 6| Step: 4
Training loss: 1.6881160736083984
Validation loss: 2.0043441480205906

Epoch: 6| Step: 5
Training loss: 1.7199126482009888
Validation loss: 1.9767241375420683

Epoch: 6| Step: 6
Training loss: 2.5091819763183594
Validation loss: 1.9929562076445548

Epoch: 6| Step: 7
Training loss: 1.755128264427185
Validation loss: 1.9860495931358748

Epoch: 6| Step: 8
Training loss: 2.2866709232330322
Validation loss: 1.98523546290654

Epoch: 6| Step: 9
Training loss: 2.3069801330566406
Validation loss: 1.9592105368132233

Epoch: 6| Step: 10
Training loss: 2.270627498626709
Validation loss: 1.96669307831795

Epoch: 6| Step: 11
Training loss: 2.461994171142578
Validation loss: 1.9687158753795009

Epoch: 6| Step: 12
Training loss: 2.9410645961761475
Validation loss: 1.983202595864573

Epoch: 6| Step: 13
Training loss: 2.1928577423095703
Validation loss: 1.9719172036775978

Epoch: 123| Step: 0
Training loss: 1.5908540487289429
Validation loss: 1.9879744475887668

Epoch: 6| Step: 1
Training loss: 1.929924488067627
Validation loss: 1.9844470754746468

Epoch: 6| Step: 2
Training loss: 2.4486782550811768
Validation loss: 1.9694442287568124

Epoch: 6| Step: 3
Training loss: 1.8808314800262451
Validation loss: 1.9920756381045106

Epoch: 6| Step: 4
Training loss: 2.023078441619873
Validation loss: 1.989605039678594

Epoch: 6| Step: 5
Training loss: 2.3360185623168945
Validation loss: 1.9860052216437556

Epoch: 6| Step: 6
Training loss: 1.968053936958313
Validation loss: 1.9914349650823941

Epoch: 6| Step: 7
Training loss: 2.5204379558563232
Validation loss: 1.9736720041562152

Epoch: 6| Step: 8
Training loss: 2.0226221084594727
Validation loss: 1.970390796661377

Epoch: 6| Step: 9
Training loss: 2.195181369781494
Validation loss: 1.9708005125804613

Epoch: 6| Step: 10
Training loss: 2.320176601409912
Validation loss: 1.9999864191137335

Epoch: 6| Step: 11
Training loss: 1.8941861391067505
Validation loss: 2.0034091754626204

Epoch: 6| Step: 12
Training loss: 2.3273253440856934
Validation loss: 1.9848605163635746

Epoch: 6| Step: 13
Training loss: 1.2541550397872925
Validation loss: 2.0038509625260548

Epoch: 124| Step: 0
Training loss: 2.5061397552490234
Validation loss: 1.9965686900641328

Epoch: 6| Step: 1
Training loss: 2.4680423736572266
Validation loss: 2.0151268769336004

Epoch: 6| Step: 2
Training loss: 1.785327434539795
Validation loss: 1.9898282609960085

Epoch: 6| Step: 3
Training loss: 1.7288131713867188
Validation loss: 2.0114527466476604

Epoch: 6| Step: 4
Training loss: 1.6703660488128662
Validation loss: 1.9814390443986463

Epoch: 6| Step: 5
Training loss: 1.9326090812683105
Validation loss: 2.0045706277252524

Epoch: 6| Step: 6
Training loss: 2.179271936416626
Validation loss: 1.9837387479761595

Epoch: 6| Step: 7
Training loss: 1.9079033136367798
Validation loss: 1.9968685001455329

Epoch: 6| Step: 8
Training loss: 2.5860044956207275
Validation loss: 1.9851677443391533

Epoch: 6| Step: 9
Training loss: 1.8710616827011108
Validation loss: 1.9766045180700158

Epoch: 6| Step: 10
Training loss: 1.3375906944274902
Validation loss: 1.9757115097456082

Epoch: 6| Step: 11
Training loss: 2.2689292430877686
Validation loss: 1.9828310474272697

Epoch: 6| Step: 12
Training loss: 2.4443812370300293
Validation loss: 1.9839076816394765

Epoch: 6| Step: 13
Training loss: 2.60188627243042
Validation loss: 1.953277193089967

Epoch: 125| Step: 0
Training loss: 2.3463826179504395
Validation loss: 2.006629131173575

Epoch: 6| Step: 1
Training loss: 2.315131187438965
Validation loss: 1.9627578732787923

Epoch: 6| Step: 2
Training loss: 1.6327694654464722
Validation loss: 1.9711761243881718

Epoch: 6| Step: 3
Training loss: 1.6375794410705566
Validation loss: 1.9886681008082565

Epoch: 6| Step: 4
Training loss: 2.6845178604125977
Validation loss: 1.9810115983409267

Epoch: 6| Step: 5
Training loss: 1.71917724609375
Validation loss: 1.978510308009322

Epoch: 6| Step: 6
Training loss: 1.7195470333099365
Validation loss: 1.967762395899783

Epoch: 6| Step: 7
Training loss: 2.163257360458374
Validation loss: 1.9722081256169144

Epoch: 6| Step: 8
Training loss: 1.8185416460037231
Validation loss: 1.9576453829324374

Epoch: 6| Step: 9
Training loss: 2.1999425888061523
Validation loss: 1.979263533828079

Epoch: 6| Step: 10
Training loss: 2.1236703395843506
Validation loss: 1.964275320370992

Epoch: 6| Step: 11
Training loss: 2.7505733966827393
Validation loss: 1.9651975862441524

Epoch: 6| Step: 12
Training loss: 2.064859390258789
Validation loss: 1.967845542456514

Epoch: 6| Step: 13
Training loss: 1.9060834646224976
Validation loss: 1.9689659559598534

Epoch: 126| Step: 0
Training loss: 1.8563079833984375
Validation loss: 1.988956300161218

Epoch: 6| Step: 1
Training loss: 1.4241456985473633
Validation loss: 1.9751019247116581

Epoch: 6| Step: 2
Training loss: 2.3536524772644043
Validation loss: 1.9754315294245237

Epoch: 6| Step: 3
Training loss: 1.9044657945632935
Validation loss: 2.006301203081685

Epoch: 6| Step: 4
Training loss: 2.183999538421631
Validation loss: 1.9931938596951064

Epoch: 6| Step: 5
Training loss: 1.0415853261947632
Validation loss: 1.975165956763811

Epoch: 6| Step: 6
Training loss: 2.249007225036621
Validation loss: 1.9963082421210505

Epoch: 6| Step: 7
Training loss: 2.593921661376953
Validation loss: 1.9876960797976422

Epoch: 6| Step: 8
Training loss: 1.4609806537628174
Validation loss: 2.0101537755740586

Epoch: 6| Step: 9
Training loss: 2.9158380031585693
Validation loss: 1.9960112866534983

Epoch: 6| Step: 10
Training loss: 2.310387134552002
Validation loss: 1.9981666277813654

Epoch: 6| Step: 11
Training loss: 1.3792641162872314
Validation loss: 2.011211654191376

Epoch: 6| Step: 12
Training loss: 3.3477680683135986
Validation loss: 2.0156367542923137

Epoch: 6| Step: 13
Training loss: 2.503048896789551
Validation loss: 1.996130749743472

Epoch: 127| Step: 0
Training loss: 2.3812336921691895
Validation loss: 2.043353537077545

Epoch: 6| Step: 1
Training loss: 3.035303831100464
Validation loss: 2.000985796733569

Epoch: 6| Step: 2
Training loss: 2.495494842529297
Validation loss: 2.017543054396106

Epoch: 6| Step: 3
Training loss: 1.35272216796875
Validation loss: 1.9991765150459864

Epoch: 6| Step: 4
Training loss: 1.9873590469360352
Validation loss: 1.9931854381356189

Epoch: 6| Step: 5
Training loss: 1.8741345405578613
Validation loss: 1.9940639823995612

Epoch: 6| Step: 6
Training loss: 1.8658497333526611
Validation loss: 1.9810577720724127

Epoch: 6| Step: 7
Training loss: 2.020969867706299
Validation loss: 1.9920691290209371

Epoch: 6| Step: 8
Training loss: 1.7877110242843628
Validation loss: 1.9785937506665465

Epoch: 6| Step: 9
Training loss: 1.7946220636367798
Validation loss: 1.993999315846351

Epoch: 6| Step: 10
Training loss: 2.315892219543457
Validation loss: 1.993706549367597

Epoch: 6| Step: 11
Training loss: 1.8299589157104492
Validation loss: 1.9926040352031749

Epoch: 6| Step: 12
Training loss: 1.7840287685394287
Validation loss: 1.9769977831071424

Epoch: 6| Step: 13
Training loss: 2.8376035690307617
Validation loss: 1.9823277381158644

Epoch: 128| Step: 0
Training loss: 2.257845640182495
Validation loss: 1.989100420346824

Epoch: 6| Step: 1
Training loss: 1.8551992177963257
Validation loss: 1.9894740632785264

Epoch: 6| Step: 2
Training loss: 1.5591685771942139
Validation loss: 1.9439044331991544

Epoch: 6| Step: 3
Training loss: 1.9146379232406616
Validation loss: 1.9998375638838737

Epoch: 6| Step: 4
Training loss: 1.7343343496322632
Validation loss: 1.9722672880336802

Epoch: 6| Step: 5
Training loss: 2.016763210296631
Validation loss: 1.9765418806383688

Epoch: 6| Step: 6
Training loss: 1.8341012001037598
Validation loss: 1.9706654561463224

Epoch: 6| Step: 7
Training loss: 1.996412754058838
Validation loss: 1.986136903044998

Epoch: 6| Step: 8
Training loss: 2.4268674850463867
Validation loss: 1.9740832339050949

Epoch: 6| Step: 9
Training loss: 1.6883761882781982
Validation loss: 1.9453129447916502

Epoch: 6| Step: 10
Training loss: 1.940046787261963
Validation loss: 1.9830283298287341

Epoch: 6| Step: 11
Training loss: 2.7986769676208496
Validation loss: 1.987202246983846

Epoch: 6| Step: 12
Training loss: 2.451113224029541
Validation loss: 1.9532867400876937

Epoch: 6| Step: 13
Training loss: 2.8441243171691895
Validation loss: 1.9619631049453572

Epoch: 129| Step: 0
Training loss: 2.316291332244873
Validation loss: 1.9757864834159933

Epoch: 6| Step: 1
Training loss: 2.0784337520599365
Validation loss: 1.9690663365907566

Epoch: 6| Step: 2
Training loss: 1.8494253158569336
Validation loss: 1.9742256300423735

Epoch: 6| Step: 3
Training loss: 2.02962327003479
Validation loss: 1.9561628539075133

Epoch: 6| Step: 4
Training loss: 1.5803697109222412
Validation loss: 1.9620195742576354

Epoch: 6| Step: 5
Training loss: 1.8751804828643799
Validation loss: 1.968104766261193

Epoch: 6| Step: 6
Training loss: 2.0172791481018066
Validation loss: 1.9796908017127746

Epoch: 6| Step: 7
Training loss: 1.8962221145629883
Validation loss: 1.989639204035523

Epoch: 6| Step: 8
Training loss: 2.486783027648926
Validation loss: 1.9705134553294028

Epoch: 6| Step: 9
Training loss: 2.6546177864074707
Validation loss: 1.986888285606138

Epoch: 6| Step: 10
Training loss: 2.218301296234131
Validation loss: 1.986932853216766

Epoch: 6| Step: 11
Training loss: 1.8994641304016113
Validation loss: 1.9932404423272738

Epoch: 6| Step: 12
Training loss: 2.052356004714966
Validation loss: 1.992894454668927

Epoch: 6| Step: 13
Training loss: 1.9405484199523926
Validation loss: 1.9624821550102645

Epoch: 130| Step: 0
Training loss: 1.8627374172210693
Validation loss: 1.980694527267128

Epoch: 6| Step: 1
Training loss: 1.6958580017089844
Validation loss: 2.001802980258901

Epoch: 6| Step: 2
Training loss: 1.9872792959213257
Validation loss: 1.9618157289361442

Epoch: 6| Step: 3
Training loss: 2.177464246749878
Validation loss: 1.9821656378366614

Epoch: 6| Step: 4
Training loss: 2.164759874343872
Validation loss: 1.9767040052721578

Epoch: 6| Step: 5
Training loss: 2.381990909576416
Validation loss: 1.956628796874836

Epoch: 6| Step: 6
Training loss: 2.1168341636657715
Validation loss: 1.9773343365679505

Epoch: 6| Step: 7
Training loss: 1.6653763055801392
Validation loss: 1.9587703263887795

Epoch: 6| Step: 8
Training loss: 2.2235913276672363
Validation loss: 1.9559510061817784

Epoch: 6| Step: 9
Training loss: 2.544107675552368
Validation loss: 1.984181386168285

Epoch: 6| Step: 10
Training loss: 1.9388387203216553
Validation loss: 1.956099005155666

Epoch: 6| Step: 11
Training loss: 2.569120407104492
Validation loss: 1.9562155482589558

Epoch: 6| Step: 12
Training loss: 1.8685109615325928
Validation loss: 1.9712295186135076

Epoch: 6| Step: 13
Training loss: 1.6779990196228027
Validation loss: 1.9829344723814277

Epoch: 131| Step: 0
Training loss: 2.679356336593628
Validation loss: 1.9888347810314548

Epoch: 6| Step: 1
Training loss: 2.2171521186828613
Validation loss: 1.9547929148520193

Epoch: 6| Step: 2
Training loss: 2.0614075660705566
Validation loss: 1.9705211834240985

Epoch: 6| Step: 3
Training loss: 1.716226577758789
Validation loss: 1.9859205945845573

Epoch: 6| Step: 4
Training loss: 1.5650436878204346
Validation loss: 1.9918529525879891

Epoch: 6| Step: 5
Training loss: 2.4355762004852295
Validation loss: 1.9670862920822636

Epoch: 6| Step: 6
Training loss: 1.6754704713821411
Validation loss: 1.9677261793485252

Epoch: 6| Step: 7
Training loss: 1.7201913595199585
Validation loss: 1.970522165298462

Epoch: 6| Step: 8
Training loss: 1.294276475906372
Validation loss: 1.9837766398665726

Epoch: 6| Step: 9
Training loss: 2.686901092529297
Validation loss: 1.9867072131044121

Epoch: 6| Step: 10
Training loss: 1.925032138824463
Validation loss: 1.9807726734427995

Epoch: 6| Step: 11
Training loss: 2.67449688911438
Validation loss: 1.9766740286222069

Epoch: 6| Step: 12
Training loss: 2.130934238433838
Validation loss: 1.9889441997774187

Epoch: 6| Step: 13
Training loss: 2.0877411365509033
Validation loss: 1.9775633504313808

Epoch: 132| Step: 0
Training loss: 1.787179946899414
Validation loss: 1.9916351149159093

Epoch: 6| Step: 1
Training loss: 2.4931716918945312
Validation loss: 1.9894066741389613

Epoch: 6| Step: 2
Training loss: 1.6567776203155518
Validation loss: 1.9866302897853236

Epoch: 6| Step: 3
Training loss: 2.401961326599121
Validation loss: 1.9943662061486194

Epoch: 6| Step: 4
Training loss: 1.3539334535598755
Validation loss: 1.983814839393862

Epoch: 6| Step: 5
Training loss: 2.155275583267212
Validation loss: 1.9882200046252179

Epoch: 6| Step: 6
Training loss: 2.2928829193115234
Validation loss: 1.9872767643261982

Epoch: 6| Step: 7
Training loss: 2.0112037658691406
Validation loss: 2.0067434144276444

Epoch: 6| Step: 8
Training loss: 2.424023151397705
Validation loss: 2.0207126986595894

Epoch: 6| Step: 9
Training loss: 2.352125406265259
Validation loss: 1.988181665379514

Epoch: 6| Step: 10
Training loss: 1.6759287118911743
Validation loss: 2.016106782420989

Epoch: 6| Step: 11
Training loss: 2.268909215927124
Validation loss: 1.9984925152153097

Epoch: 6| Step: 12
Training loss: 1.9460070133209229
Validation loss: 1.998735886748119

Epoch: 6| Step: 13
Training loss: 1.9662988185882568
Validation loss: 1.9944750852482294

Epoch: 133| Step: 0
Training loss: 2.062323570251465
Validation loss: 2.0160962663671023

Epoch: 6| Step: 1
Training loss: 2.3910841941833496
Validation loss: 1.9887936717720442

Epoch: 6| Step: 2
Training loss: 1.5081584453582764
Validation loss: 2.002763412332022

Epoch: 6| Step: 3
Training loss: 3.0361135005950928
Validation loss: 1.9858713419206682

Epoch: 6| Step: 4
Training loss: 2.2403922080993652
Validation loss: 1.965870008673719

Epoch: 6| Step: 5
Training loss: 1.9645171165466309
Validation loss: 1.9787977946701871

Epoch: 6| Step: 6
Training loss: 2.170876979827881
Validation loss: 1.9805485048601705

Epoch: 6| Step: 7
Training loss: 2.152764320373535
Validation loss: 1.9795570565808205

Epoch: 6| Step: 8
Training loss: 1.2687110900878906
Validation loss: 1.9742703155804706

Epoch: 6| Step: 9
Training loss: 1.5892260074615479
Validation loss: 1.9611831121547247

Epoch: 6| Step: 10
Training loss: 2.7819297313690186
Validation loss: 1.997473741090426

Epoch: 6| Step: 11
Training loss: 1.6977148056030273
Validation loss: 1.9849539238919494

Epoch: 6| Step: 12
Training loss: 2.0597338676452637
Validation loss: 1.9684511756384244

Epoch: 6| Step: 13
Training loss: 2.1246044635772705
Validation loss: 1.9492471487291398

Epoch: 134| Step: 0
Training loss: 1.6757957935333252
Validation loss: 1.967145235307755

Epoch: 6| Step: 1
Training loss: 2.180556058883667
Validation loss: 1.9482548595756612

Epoch: 6| Step: 2
Training loss: 1.9538214206695557
Validation loss: 1.9664709850024151

Epoch: 6| Step: 3
Training loss: 1.5726230144500732
Validation loss: 1.9802497868896813

Epoch: 6| Step: 4
Training loss: 1.6078829765319824
Validation loss: 1.9443225642686248

Epoch: 6| Step: 5
Training loss: 2.689976692199707
Validation loss: 1.945961650981698

Epoch: 6| Step: 6
Training loss: 1.631540060043335
Validation loss: 1.9673916819275066

Epoch: 6| Step: 7
Training loss: 2.015033483505249
Validation loss: 1.9765964528565765

Epoch: 6| Step: 8
Training loss: 3.6108670234680176
Validation loss: 1.9547062919985863

Epoch: 6| Step: 9
Training loss: 2.412269115447998
Validation loss: 1.9633291882853354

Epoch: 6| Step: 10
Training loss: 1.9208251237869263
Validation loss: 1.9705343759188088

Epoch: 6| Step: 11
Training loss: 2.543226480484009
Validation loss: 1.9510287777070077

Epoch: 6| Step: 12
Training loss: 1.7022993564605713
Validation loss: 1.971800919502012

Epoch: 6| Step: 13
Training loss: 1.1176763772964478
Validation loss: 1.961088098505492

Epoch: 135| Step: 0
Training loss: 2.3496720790863037
Validation loss: 1.969215645585009

Epoch: 6| Step: 1
Training loss: 2.285763740539551
Validation loss: 1.9746739415712253

Epoch: 6| Step: 2
Training loss: 2.0239715576171875
Validation loss: 1.9542755285898845

Epoch: 6| Step: 3
Training loss: 2.1644515991210938
Validation loss: 1.962144451756631

Epoch: 6| Step: 4
Training loss: 2.1907005310058594
Validation loss: 1.9878739490303943

Epoch: 6| Step: 5
Training loss: 2.184072971343994
Validation loss: 1.9842946144842333

Epoch: 6| Step: 6
Training loss: 1.900587558746338
Validation loss: 2.0093161470146588

Epoch: 6| Step: 7
Training loss: 0.93419349193573
Validation loss: 2.0035889943440757

Epoch: 6| Step: 8
Training loss: 2.381324529647827
Validation loss: 1.99572923362896

Epoch: 6| Step: 9
Training loss: 1.918144941329956
Validation loss: 2.0225311120351157

Epoch: 6| Step: 10
Training loss: 2.6337015628814697
Validation loss: 1.998513622950482

Epoch: 6| Step: 11
Training loss: 2.476731300354004
Validation loss: 2.0151981769069547

Epoch: 6| Step: 12
Training loss: 1.7600489854812622
Validation loss: 2.032658753856536

Epoch: 6| Step: 13
Training loss: 1.3305453062057495
Validation loss: 1.9816141474631526

Epoch: 136| Step: 0
Training loss: 2.5241260528564453
Validation loss: 1.9969894347652313

Epoch: 6| Step: 1
Training loss: 1.9845067262649536
Validation loss: 2.0059984422499135

Epoch: 6| Step: 2
Training loss: 2.0132837295532227
Validation loss: 2.006659646188059

Epoch: 6| Step: 3
Training loss: 2.162968158721924
Validation loss: 1.979469983808456

Epoch: 6| Step: 4
Training loss: 1.8828763961791992
Validation loss: 2.0018677275667907

Epoch: 6| Step: 5
Training loss: 1.8208736181259155
Validation loss: 1.979192400491366

Epoch: 6| Step: 6
Training loss: 2.5908541679382324
Validation loss: 1.979232608631093

Epoch: 6| Step: 7
Training loss: 1.3389272689819336
Validation loss: 1.9548938505111202

Epoch: 6| Step: 8
Training loss: 1.7497705221176147
Validation loss: 1.9747894963910502

Epoch: 6| Step: 9
Training loss: 2.3415989875793457
Validation loss: 1.9704029406270673

Epoch: 6| Step: 10
Training loss: 2.0830278396606445
Validation loss: 1.960683773922664

Epoch: 6| Step: 11
Training loss: 2.07659912109375
Validation loss: 1.9793141888033958

Epoch: 6| Step: 12
Training loss: 2.1765296459198
Validation loss: 1.9760881790550806

Epoch: 6| Step: 13
Training loss: 1.8478628396987915
Validation loss: 1.9626798168305428

Epoch: 137| Step: 0
Training loss: 1.5872743129730225
Validation loss: 1.970884564102337

Epoch: 6| Step: 1
Training loss: 3.0921103954315186
Validation loss: 1.9701709619132421

Epoch: 6| Step: 2
Training loss: 1.79691481590271
Validation loss: 1.963676634655204

Epoch: 6| Step: 3
Training loss: 1.7613298892974854
Validation loss: 1.9683598215861986

Epoch: 6| Step: 4
Training loss: 1.2215311527252197
Validation loss: 1.9724501332929056

Epoch: 6| Step: 5
Training loss: 2.235748529434204
Validation loss: 1.9919498120584795

Epoch: 6| Step: 6
Training loss: 2.172545909881592
Validation loss: 1.9676176976132136

Epoch: 6| Step: 7
Training loss: 2.23297119140625
Validation loss: 1.983562570746227

Epoch: 6| Step: 8
Training loss: 1.5790259838104248
Validation loss: 1.965260318530503

Epoch: 6| Step: 9
Training loss: 2.857741117477417
Validation loss: 1.9701291181707894

Epoch: 6| Step: 10
Training loss: 2.1187477111816406
Validation loss: 1.959218450771865

Epoch: 6| Step: 11
Training loss: 1.7063782215118408
Validation loss: 1.9702221667894753

Epoch: 6| Step: 12
Training loss: 1.8625942468643188
Validation loss: 1.9827363862786243

Epoch: 6| Step: 13
Training loss: 2.8058056831359863
Validation loss: 1.9822859853826544

Epoch: 138| Step: 0
Training loss: 1.7747018337249756
Validation loss: 1.9846687983441096

Epoch: 6| Step: 1
Training loss: 2.2947888374328613
Validation loss: 1.9639965129154984

Epoch: 6| Step: 2
Training loss: 2.4913108348846436
Validation loss: 1.987113207899114

Epoch: 6| Step: 3
Training loss: 2.098350763320923
Validation loss: 1.96923452936193

Epoch: 6| Step: 4
Training loss: 2.0826995372772217
Validation loss: 1.9975952230474001

Epoch: 6| Step: 5
Training loss: 2.121674060821533
Validation loss: 1.9803157647450764

Epoch: 6| Step: 6
Training loss: 1.8619332313537598
Validation loss: 1.9829550225247619

Epoch: 6| Step: 7
Training loss: 2.2089669704437256
Validation loss: 1.9953392269790813

Epoch: 6| Step: 8
Training loss: 1.9314751625061035
Validation loss: 1.9885284387937157

Epoch: 6| Step: 9
Training loss: 2.2629799842834473
Validation loss: 1.9833920463438957

Epoch: 6| Step: 10
Training loss: 1.9139454364776611
Validation loss: 1.9924954611768004

Epoch: 6| Step: 11
Training loss: 1.9287877082824707
Validation loss: 1.9825870683116298

Epoch: 6| Step: 12
Training loss: 1.68186354637146
Validation loss: 1.994291736233619

Epoch: 6| Step: 13
Training loss: 1.9959182739257812
Validation loss: 1.9783010534060899

Epoch: 139| Step: 0
Training loss: 2.2848591804504395
Validation loss: 1.98712412388094

Epoch: 6| Step: 1
Training loss: 1.9880610704421997
Validation loss: 1.9655017468237108

Epoch: 6| Step: 2
Training loss: 2.3494200706481934
Validation loss: 1.9788628393603909

Epoch: 6| Step: 3
Training loss: 2.498709201812744
Validation loss: 1.9635076138281053

Epoch: 6| Step: 4
Training loss: 1.306185007095337
Validation loss: 1.9767967475357877

Epoch: 6| Step: 5
Training loss: 2.332474708557129
Validation loss: 1.9543418858640937

Epoch: 6| Step: 6
Training loss: 2.303576946258545
Validation loss: 1.9749428559375066

Epoch: 6| Step: 7
Training loss: 2.7443737983703613
Validation loss: 1.9648802690608527

Epoch: 6| Step: 8
Training loss: 1.9610410928726196
Validation loss: 1.981120349258505

Epoch: 6| Step: 9
Training loss: 1.4834353923797607
Validation loss: 1.9737736114891626

Epoch: 6| Step: 10
Training loss: 1.9272032976150513
Validation loss: 1.9604524233007943

Epoch: 6| Step: 11
Training loss: 1.8999180793762207
Validation loss: 1.9583457541722122

Epoch: 6| Step: 12
Training loss: 1.5853993892669678
Validation loss: 1.943356385795019

Epoch: 6| Step: 13
Training loss: 1.7932692766189575
Validation loss: 1.9593645449607604

Epoch: 140| Step: 0
Training loss: 2.4652509689331055
Validation loss: 1.952923108172673

Epoch: 6| Step: 1
Training loss: 2.225020408630371
Validation loss: 1.9642367926977014

Epoch: 6| Step: 2
Training loss: 2.673243522644043
Validation loss: 1.9688745801166823

Epoch: 6| Step: 3
Training loss: 1.9300105571746826
Validation loss: 1.9694703753276537

Epoch: 6| Step: 4
Training loss: 2.3332479000091553
Validation loss: 1.9565094235122844

Epoch: 6| Step: 5
Training loss: 1.8014469146728516
Validation loss: 1.9589462523819299

Epoch: 6| Step: 6
Training loss: 2.0974855422973633
Validation loss: 1.9707289126611525

Epoch: 6| Step: 7
Training loss: 1.7584670782089233
Validation loss: 1.952373735366329

Epoch: 6| Step: 8
Training loss: 1.9983570575714111
Validation loss: 1.9642978893813265

Epoch: 6| Step: 9
Training loss: 1.7843793630599976
Validation loss: 1.9733431249536493

Epoch: 6| Step: 10
Training loss: 2.2841029167175293
Validation loss: 1.9710948415981826

Epoch: 6| Step: 11
Training loss: 1.7343926429748535
Validation loss: 1.9753196854745187

Epoch: 6| Step: 12
Training loss: 1.6791973114013672
Validation loss: 1.9640646878109183

Epoch: 6| Step: 13
Training loss: 1.656456470489502
Validation loss: 1.9712936724385908

Epoch: 141| Step: 0
Training loss: 2.078450918197632
Validation loss: 1.9718506438757784

Epoch: 6| Step: 1
Training loss: 2.288181781768799
Validation loss: 1.977946921061444

Epoch: 6| Step: 2
Training loss: 1.6900149583816528
Validation loss: 2.00378220312057

Epoch: 6| Step: 3
Training loss: 2.386967182159424
Validation loss: 1.9829481801679056

Epoch: 6| Step: 4
Training loss: 2.2719202041625977
Validation loss: 1.9681231616645731

Epoch: 6| Step: 5
Training loss: 2.085442543029785
Validation loss: 1.9727402092308126

Epoch: 6| Step: 6
Training loss: 1.695253849029541
Validation loss: 1.95666427253395

Epoch: 6| Step: 7
Training loss: 2.75166654586792
Validation loss: 1.9489496536152338

Epoch: 6| Step: 8
Training loss: 1.8537062406539917
Validation loss: 1.9817707897514425

Epoch: 6| Step: 9
Training loss: 2.268298625946045
Validation loss: 1.9834654459389307

Epoch: 6| Step: 10
Training loss: 2.4353365898132324
Validation loss: 1.9681022397933468

Epoch: 6| Step: 11
Training loss: 1.6806316375732422
Validation loss: 1.9888065271480109

Epoch: 6| Step: 12
Training loss: 1.1379375457763672
Validation loss: 1.941533738566983

Epoch: 6| Step: 13
Training loss: 1.596993327140808
Validation loss: 1.9935540204407067

Epoch: 142| Step: 0
Training loss: 2.3075716495513916
Validation loss: 1.9531963371461438

Epoch: 6| Step: 1
Training loss: 2.3643531799316406
Validation loss: 1.9655179913325975

Epoch: 6| Step: 2
Training loss: 1.7601804733276367
Validation loss: 1.9790715709809334

Epoch: 6| Step: 3
Training loss: 1.2481050491333008
Validation loss: 1.9845689394140755

Epoch: 6| Step: 4
Training loss: 1.5028371810913086
Validation loss: 1.9890887788546983

Epoch: 6| Step: 5
Training loss: 2.5209686756134033
Validation loss: 1.970342509208187

Epoch: 6| Step: 6
Training loss: 3.2767796516418457
Validation loss: 1.9736861516070623

Epoch: 6| Step: 7
Training loss: 1.417534589767456
Validation loss: 1.9593791448941795

Epoch: 6| Step: 8
Training loss: 2.0634818077087402
Validation loss: 1.9445238421040196

Epoch: 6| Step: 9
Training loss: 1.8425120115280151
Validation loss: 1.9607932516323623

Epoch: 6| Step: 10
Training loss: 2.253122329711914
Validation loss: 1.970497303111579

Epoch: 6| Step: 11
Training loss: 1.7561287879943848
Validation loss: 1.9698933350142611

Epoch: 6| Step: 12
Training loss: 1.7617378234863281
Validation loss: 1.9821059011643933

Epoch: 6| Step: 13
Training loss: 2.671375036239624
Validation loss: 2.0004638600093063

Epoch: 143| Step: 0
Training loss: 2.5860471725463867
Validation loss: 1.9738326021420058

Epoch: 6| Step: 1
Training loss: 2.386711597442627
Validation loss: 1.9692182707530197

Epoch: 6| Step: 2
Training loss: 1.3724433183670044
Validation loss: 1.9632607698440552

Epoch: 6| Step: 3
Training loss: 2.547447919845581
Validation loss: 1.9662357530286234

Epoch: 6| Step: 4
Training loss: 1.1293609142303467
Validation loss: 1.9869916823602491

Epoch: 6| Step: 5
Training loss: 2.0022552013397217
Validation loss: 1.9761412976890482

Epoch: 6| Step: 6
Training loss: 1.7493395805358887
Validation loss: 1.9714384668616838

Epoch: 6| Step: 7
Training loss: 2.369818925857544
Validation loss: 1.9824131868218864

Epoch: 6| Step: 8
Training loss: 2.264617919921875
Validation loss: 2.002026765577255

Epoch: 6| Step: 9
Training loss: 1.3692984580993652
Validation loss: 1.9774658615871141

Epoch: 6| Step: 10
Training loss: 2.5036063194274902
Validation loss: 1.9956691367651826

Epoch: 6| Step: 11
Training loss: 1.9247584342956543
Validation loss: 1.9556638476669148

Epoch: 6| Step: 12
Training loss: 2.276564121246338
Validation loss: 1.977127686623604

Epoch: 6| Step: 13
Training loss: 1.4902576208114624
Validation loss: 1.9881504351092922

Epoch: 144| Step: 0
Training loss: 2.421285629272461
Validation loss: 1.9814991694624706

Epoch: 6| Step: 1
Training loss: 1.1043660640716553
Validation loss: 1.9500481441456785

Epoch: 6| Step: 2
Training loss: 2.600330352783203
Validation loss: 1.9661645735463789

Epoch: 6| Step: 3
Training loss: 1.100649356842041
Validation loss: 1.9592117199333765

Epoch: 6| Step: 4
Training loss: 2.720583915710449
Validation loss: 1.9366226657744376

Epoch: 6| Step: 5
Training loss: 1.8378713130950928
Validation loss: 1.971614004463278

Epoch: 6| Step: 6
Training loss: 2.43173885345459
Validation loss: 1.9605972292602702

Epoch: 6| Step: 7
Training loss: 2.2423863410949707
Validation loss: 1.9565540859776158

Epoch: 6| Step: 8
Training loss: 2.1953272819519043
Validation loss: 1.9629370884228778

Epoch: 6| Step: 9
Training loss: 1.981182336807251
Validation loss: 1.965685079174657

Epoch: 6| Step: 10
Training loss: 1.6065870523452759
Validation loss: 1.9691041182446223

Epoch: 6| Step: 11
Training loss: 1.7600611448287964
Validation loss: 1.9649236432967647

Epoch: 6| Step: 12
Training loss: 2.3477938175201416
Validation loss: 1.9687517868575228

Epoch: 6| Step: 13
Training loss: 2.0472116470336914
Validation loss: 1.955025424239456

Epoch: 145| Step: 0
Training loss: 1.8039432764053345
Validation loss: 1.9630061247015511

Epoch: 6| Step: 1
Training loss: 2.0633678436279297
Validation loss: 1.9699145504223403

Epoch: 6| Step: 2
Training loss: 1.7449438571929932
Validation loss: 1.9604149198019376

Epoch: 6| Step: 3
Training loss: 1.6441869735717773
Validation loss: 1.9487087624047392

Epoch: 6| Step: 4
Training loss: 2.020336151123047
Validation loss: 1.9519393303061043

Epoch: 6| Step: 5
Training loss: 2.1753485202789307
Validation loss: 1.939538748033585

Epoch: 6| Step: 6
Training loss: 1.9193004369735718
Validation loss: 1.9601197934919787

Epoch: 6| Step: 7
Training loss: 2.7547788619995117
Validation loss: 1.9707107261944843

Epoch: 6| Step: 8
Training loss: 2.029249668121338
Validation loss: 1.971902706289804

Epoch: 6| Step: 9
Training loss: 1.943114995956421
Validation loss: 1.9676124024134811

Epoch: 6| Step: 10
Training loss: 2.2044036388397217
Validation loss: 1.952544004686417

Epoch: 6| Step: 11
Training loss: 2.5082685947418213
Validation loss: 1.933477400451578

Epoch: 6| Step: 12
Training loss: 1.7101629972457886
Validation loss: 1.975340151017712

Epoch: 6| Step: 13
Training loss: 1.8069177865982056
Validation loss: 1.972977049889103

Epoch: 146| Step: 0
Training loss: 1.9317642450332642
Validation loss: 1.962027354906964

Epoch: 6| Step: 1
Training loss: 1.7959216833114624
Validation loss: 1.980549035533782

Epoch: 6| Step: 2
Training loss: 2.2593963146209717
Validation loss: 1.9773363246712634

Epoch: 6| Step: 3
Training loss: 1.687134861946106
Validation loss: 1.9734977381203764

Epoch: 6| Step: 4
Training loss: 1.727631688117981
Validation loss: 1.9642888576753679

Epoch: 6| Step: 5
Training loss: 1.648478627204895
Validation loss: 1.9692967809656614

Epoch: 6| Step: 6
Training loss: 1.944361925125122
Validation loss: 1.9701649450486707

Epoch: 6| Step: 7
Training loss: 2.514843463897705
Validation loss: 1.955909921276954

Epoch: 6| Step: 8
Training loss: 1.7694164514541626
Validation loss: 1.9487615887836744

Epoch: 6| Step: 9
Training loss: 2.596224784851074
Validation loss: 1.9650160574143933

Epoch: 6| Step: 10
Training loss: 2.2962937355041504
Validation loss: 1.9569322742441648

Epoch: 6| Step: 11
Training loss: 1.8883187770843506
Validation loss: 1.966968810686501

Epoch: 6| Step: 12
Training loss: 1.857795238494873
Validation loss: 1.9608736794481996

Epoch: 6| Step: 13
Training loss: 2.279991865158081
Validation loss: 1.9572501720920685

Epoch: 147| Step: 0
Training loss: 2.0967230796813965
Validation loss: 1.9744358639563284

Epoch: 6| Step: 1
Training loss: 1.9623761177062988
Validation loss: 1.969733989366921

Epoch: 6| Step: 2
Training loss: 2.421855926513672
Validation loss: 1.97423203017122

Epoch: 6| Step: 3
Training loss: 1.8974432945251465
Validation loss: 1.952370318033362

Epoch: 6| Step: 4
Training loss: 1.879218578338623
Validation loss: 1.9917200560210853

Epoch: 6| Step: 5
Training loss: 2.39457106590271
Validation loss: 1.9836355383678148

Epoch: 6| Step: 6
Training loss: 2.5912909507751465
Validation loss: 1.9698782582436838

Epoch: 6| Step: 7
Training loss: 1.598545789718628
Validation loss: 1.9606429633273874

Epoch: 6| Step: 8
Training loss: 2.2944531440734863
Validation loss: 1.9737136030709872

Epoch: 6| Step: 9
Training loss: 1.5967782735824585
Validation loss: 1.9656044411402878

Epoch: 6| Step: 10
Training loss: 1.832996129989624
Validation loss: 1.9749405396881925

Epoch: 6| Step: 11
Training loss: 1.6740121841430664
Validation loss: 1.9867678047508321

Epoch: 6| Step: 12
Training loss: 1.8151352405548096
Validation loss: 1.955703734069742

Epoch: 6| Step: 13
Training loss: 1.8799413442611694
Validation loss: 1.9514849314125635

Epoch: 148| Step: 0
Training loss: 1.7187952995300293
Validation loss: 1.9517871743889266

Epoch: 6| Step: 1
Training loss: 1.822110652923584
Validation loss: 1.9615025751052364

Epoch: 6| Step: 2
Training loss: 1.9324686527252197
Validation loss: 1.9585952604970625

Epoch: 6| Step: 3
Training loss: 2.160257577896118
Validation loss: 1.9649387764674362

Epoch: 6| Step: 4
Training loss: 1.9462705850601196
Validation loss: 1.9674254463564964

Epoch: 6| Step: 5
Training loss: 1.8124207258224487
Validation loss: 1.9623124035455848

Epoch: 6| Step: 6
Training loss: 1.686810851097107
Validation loss: 1.9743460429612028

Epoch: 6| Step: 7
Training loss: 1.9747073650360107
Validation loss: 1.9573479967732583

Epoch: 6| Step: 8
Training loss: 2.818091869354248
Validation loss: 1.9730783995761667

Epoch: 6| Step: 9
Training loss: 2.714682102203369
Validation loss: 1.9805448593631867

Epoch: 6| Step: 10
Training loss: 1.9555532932281494
Validation loss: 1.9604222505323348

Epoch: 6| Step: 11
Training loss: 1.7242326736450195
Validation loss: 1.9767874158838743

Epoch: 6| Step: 12
Training loss: 1.6638628244400024
Validation loss: 1.9858730493053314

Epoch: 6| Step: 13
Training loss: 2.5697097778320312
Validation loss: 1.9655225264128817

Epoch: 149| Step: 0
Training loss: 1.7483515739440918
Validation loss: 1.9558649127201369

Epoch: 6| Step: 1
Training loss: 1.9509365558624268
Validation loss: 1.955486148916265

Epoch: 6| Step: 2
Training loss: 2.157222270965576
Validation loss: 1.9774054840046873

Epoch: 6| Step: 3
Training loss: 1.6606497764587402
Validation loss: 1.9695574570727605

Epoch: 6| Step: 4
Training loss: 2.43447208404541
Validation loss: 1.9583164312506234

Epoch: 6| Step: 5
Training loss: 1.757120966911316
Validation loss: 1.975453810025287

Epoch: 6| Step: 6
Training loss: 2.381544589996338
Validation loss: 1.9849248470798615

Epoch: 6| Step: 7
Training loss: 2.056741714477539
Validation loss: 1.9747807928310928

Epoch: 6| Step: 8
Training loss: 2.4032554626464844
Validation loss: 1.9875439084986204

Epoch: 6| Step: 9
Training loss: 1.9618538618087769
Validation loss: 1.9843682576251287

Epoch: 6| Step: 10
Training loss: 2.1863059997558594
Validation loss: 1.9823694895672541

Epoch: 6| Step: 11
Training loss: 2.386996269226074
Validation loss: 1.9557064476833548

Epoch: 6| Step: 12
Training loss: 1.131580114364624
Validation loss: 1.965036033302225

Epoch: 6| Step: 13
Training loss: 1.7530437707901
Validation loss: 1.9521709513920609

Epoch: 150| Step: 0
Training loss: 1.4194400310516357
Validation loss: 1.9708202397951515

Epoch: 6| Step: 1
Training loss: 2.2916665077209473
Validation loss: 1.9714284942996116

Epoch: 6| Step: 2
Training loss: 2.5929222106933594
Validation loss: 1.9507298392634238

Epoch: 6| Step: 3
Training loss: 2.1180496215820312
Validation loss: 1.964345903806789

Epoch: 6| Step: 4
Training loss: 1.5802552700042725
Validation loss: 1.9619774074964627

Epoch: 6| Step: 5
Training loss: 2.3780081272125244
Validation loss: 1.9951363148227814

Epoch: 6| Step: 6
Training loss: 1.7456564903259277
Validation loss: 1.9746629653438446

Epoch: 6| Step: 7
Training loss: 2.6129138469696045
Validation loss: 1.9869200055317213

Epoch: 6| Step: 8
Training loss: 1.9316766262054443
Validation loss: 1.9816808187833397

Epoch: 6| Step: 9
Training loss: 2.503946304321289
Validation loss: 1.9721694902707172

Epoch: 6| Step: 10
Training loss: 1.3914680480957031
Validation loss: 1.9393198772143292

Epoch: 6| Step: 11
Training loss: 2.057187557220459
Validation loss: 1.9625318742567492

Epoch: 6| Step: 12
Training loss: 1.3796985149383545
Validation loss: 1.9818039401885001

Epoch: 6| Step: 13
Training loss: 2.3231582641601562
Validation loss: 1.9479162231568368

Epoch: 151| Step: 0
Training loss: 2.101998805999756
Validation loss: 1.9717972304231377

Epoch: 6| Step: 1
Training loss: 1.8518140316009521
Validation loss: 1.9606202481895365

Epoch: 6| Step: 2
Training loss: 1.6903454065322876
Validation loss: 1.9882469356700938

Epoch: 6| Step: 3
Training loss: 2.5604653358459473
Validation loss: 1.990551717819706

Epoch: 6| Step: 4
Training loss: 1.5272983312606812
Validation loss: 1.9538883534810876

Epoch: 6| Step: 5
Training loss: 2.093601703643799
Validation loss: 1.952636097067146

Epoch: 6| Step: 6
Training loss: 1.6843712329864502
Validation loss: 1.9580975835041334

Epoch: 6| Step: 7
Training loss: 1.356062412261963
Validation loss: 1.9770760715648692

Epoch: 6| Step: 8
Training loss: 2.3798744678497314
Validation loss: 1.986847928775254

Epoch: 6| Step: 9
Training loss: 1.5474023818969727
Validation loss: 1.9610503053152433

Epoch: 6| Step: 10
Training loss: 1.8588107824325562
Validation loss: 1.9756563709628197

Epoch: 6| Step: 11
Training loss: 2.762265205383301
Validation loss: 1.9607469266460789

Epoch: 6| Step: 12
Training loss: 2.6163222789764404
Validation loss: 1.9791686752791047

Epoch: 6| Step: 13
Training loss: 1.9655070304870605
Validation loss: 1.9741218102875577

Epoch: 152| Step: 0
Training loss: 2.12321138381958
Validation loss: 1.9596783794382566

Epoch: 6| Step: 1
Training loss: 2.373873710632324
Validation loss: 1.9748992663557812

Epoch: 6| Step: 2
Training loss: 2.020294189453125
Validation loss: 1.9528302325997302

Epoch: 6| Step: 3
Training loss: 1.8536262512207031
Validation loss: 1.942184873806533

Epoch: 6| Step: 4
Training loss: 1.931506872177124
Validation loss: 1.9489802340025544

Epoch: 6| Step: 5
Training loss: 2.3539867401123047
Validation loss: 1.9643367259733138

Epoch: 6| Step: 6
Training loss: 2.7551960945129395
Validation loss: 1.9569967331424836

Epoch: 6| Step: 7
Training loss: 1.4490761756896973
Validation loss: 1.9479114124851842

Epoch: 6| Step: 8
Training loss: 1.4238418340682983
Validation loss: 1.9606988199295536

Epoch: 6| Step: 9
Training loss: 1.9092297554016113
Validation loss: 1.9544732211738505

Epoch: 6| Step: 10
Training loss: 1.6129322052001953
Validation loss: 1.951611436823363

Epoch: 6| Step: 11
Training loss: 2.370849609375
Validation loss: 1.9412354346244567

Epoch: 6| Step: 12
Training loss: 2.254929542541504
Validation loss: 1.9691582084983907

Epoch: 6| Step: 13
Training loss: 0.9596790671348572
Validation loss: 1.9560929549637662

Epoch: 153| Step: 0
Training loss: 1.5427110195159912
Validation loss: 1.957181199904411

Epoch: 6| Step: 1
Training loss: 1.868304967880249
Validation loss: 1.9496592219157884

Epoch: 6| Step: 2
Training loss: 1.7535250186920166
Validation loss: 1.9699803501047113

Epoch: 6| Step: 3
Training loss: 1.8643758296966553
Validation loss: 1.9650708167783675

Epoch: 6| Step: 4
Training loss: 2.0554895401000977
Validation loss: 1.9410375036219114

Epoch: 6| Step: 5
Training loss: 2.0148396492004395
Validation loss: 1.9432327132071219

Epoch: 6| Step: 6
Training loss: 2.2836978435516357
Validation loss: 1.9472464694771716

Epoch: 6| Step: 7
Training loss: 1.484845519065857
Validation loss: 1.9504388583603727

Epoch: 6| Step: 8
Training loss: 2.7923812866210938
Validation loss: 1.9640342830329813

Epoch: 6| Step: 9
Training loss: 1.87101149559021
Validation loss: 1.9886270697398851

Epoch: 6| Step: 10
Training loss: 2.2057909965515137
Validation loss: 1.9802051821062643

Epoch: 6| Step: 11
Training loss: 2.1132073402404785
Validation loss: 1.9720414505209973

Epoch: 6| Step: 12
Training loss: 2.256330966949463
Validation loss: 1.942625407249697

Epoch: 6| Step: 13
Training loss: 2.11452054977417
Validation loss: 1.964458643749196

Epoch: 154| Step: 0
Training loss: 2.0033693313598633
Validation loss: 1.9579290702778807

Epoch: 6| Step: 1
Training loss: 2.467548370361328
Validation loss: 1.9661233168776318

Epoch: 6| Step: 2
Training loss: 1.63735032081604
Validation loss: 1.9952643891816497

Epoch: 6| Step: 3
Training loss: 1.58251953125
Validation loss: 1.9743900645163752

Epoch: 6| Step: 4
Training loss: 2.8882339000701904
Validation loss: 1.961928249687277

Epoch: 6| Step: 5
Training loss: 2.0588173866271973
Validation loss: 1.9646886958870837

Epoch: 6| Step: 6
Training loss: 2.0567734241485596
Validation loss: 1.9811471175122004

Epoch: 6| Step: 7
Training loss: 1.9041494131088257
Validation loss: 1.9528017300431446

Epoch: 6| Step: 8
Training loss: 2.263197183609009
Validation loss: 1.940175549958342

Epoch: 6| Step: 9
Training loss: 2.214787244796753
Validation loss: 1.9521817661100818

Epoch: 6| Step: 10
Training loss: 1.6422975063323975
Validation loss: 1.9565486074775778

Epoch: 6| Step: 11
Training loss: 1.3824293613433838
Validation loss: 1.9747244593917683

Epoch: 6| Step: 12
Training loss: 1.7526872158050537
Validation loss: 1.945899349386974

Epoch: 6| Step: 13
Training loss: 2.5726239681243896
Validation loss: 1.955471138800344

Epoch: 155| Step: 0
Training loss: 2.2300257682800293
Validation loss: 1.9488684733708699

Epoch: 6| Step: 1
Training loss: 2.022108554840088
Validation loss: 1.9406126570957962

Epoch: 6| Step: 2
Training loss: 2.0145082473754883
Validation loss: 1.9251039463986632

Epoch: 6| Step: 3
Training loss: 1.6645216941833496
Validation loss: 1.9279519550261959

Epoch: 6| Step: 4
Training loss: 2.156033515930176
Validation loss: 1.9449954302080217

Epoch: 6| Step: 5
Training loss: 1.5121228694915771
Validation loss: 1.9630551594559864

Epoch: 6| Step: 6
Training loss: 1.5576534271240234
Validation loss: 1.9505333362087127

Epoch: 6| Step: 7
Training loss: 2.6871466636657715
Validation loss: 1.9315440193299325

Epoch: 6| Step: 8
Training loss: 1.963619589805603
Validation loss: 1.9603733067871423

Epoch: 6| Step: 9
Training loss: 2.228933811187744
Validation loss: 1.9409829339673441

Epoch: 6| Step: 10
Training loss: 1.57304048538208
Validation loss: 1.9463073950941845

Epoch: 6| Step: 11
Training loss: 2.490189552307129
Validation loss: 1.942118585750621

Epoch: 6| Step: 12
Training loss: 1.7553980350494385
Validation loss: 1.9597839706687517

Epoch: 6| Step: 13
Training loss: 1.8874189853668213
Validation loss: 1.9274149082040275

Epoch: 156| Step: 0
Training loss: 1.823732614517212
Validation loss: 1.9616293573892245

Epoch: 6| Step: 1
Training loss: 2.007601737976074
Validation loss: 1.9512366799898044

Epoch: 6| Step: 2
Training loss: 1.644669532775879
Validation loss: 1.957176508442048

Epoch: 6| Step: 3
Training loss: 1.7994680404663086
Validation loss: 1.9360906680425007

Epoch: 6| Step: 4
Training loss: 1.7950003147125244
Validation loss: 1.9369983955096173

Epoch: 6| Step: 5
Training loss: 2.260690212249756
Validation loss: 1.963788705487405

Epoch: 6| Step: 6
Training loss: 1.765555739402771
Validation loss: 1.940268789568255

Epoch: 6| Step: 7
Training loss: 2.187941551208496
Validation loss: 1.9494126599322084

Epoch: 6| Step: 8
Training loss: 2.3493430614471436
Validation loss: 1.9432342975370345

Epoch: 6| Step: 9
Training loss: 2.371276378631592
Validation loss: 1.9411091009775798

Epoch: 6| Step: 10
Training loss: 2.0206069946289062
Validation loss: 1.9484184685573782

Epoch: 6| Step: 11
Training loss: 2.073490619659424
Validation loss: 1.9561238263242988

Epoch: 6| Step: 12
Training loss: 1.840899109840393
Validation loss: 1.9299067246016635

Epoch: 6| Step: 13
Training loss: 1.8685929775238037
Validation loss: 1.944312059751121

Epoch: 157| Step: 0
Training loss: 2.0657167434692383
Validation loss: 1.945182567001671

Epoch: 6| Step: 1
Training loss: 1.7429943084716797
Validation loss: 1.9565551447611984

Epoch: 6| Step: 2
Training loss: 1.4714300632476807
Validation loss: 1.972646713256836

Epoch: 6| Step: 3
Training loss: 2.9380688667297363
Validation loss: 1.9539989348380797

Epoch: 6| Step: 4
Training loss: 1.3593411445617676
Validation loss: 1.9461851850632699

Epoch: 6| Step: 5
Training loss: 1.6995960474014282
Validation loss: 1.9511405703842

Epoch: 6| Step: 6
Training loss: 1.6553398370742798
Validation loss: 1.951446315293671

Epoch: 6| Step: 7
Training loss: 2.442032814025879
Validation loss: 1.9500687904255365

Epoch: 6| Step: 8
Training loss: 1.7626785039901733
Validation loss: 1.9492310157386206

Epoch: 6| Step: 9
Training loss: 1.693371295928955
Validation loss: 1.97227111939461

Epoch: 6| Step: 10
Training loss: 2.670121669769287
Validation loss: 1.946689905658845

Epoch: 6| Step: 11
Training loss: 2.087252140045166
Validation loss: 1.9369226694107056

Epoch: 6| Step: 12
Training loss: 2.203038215637207
Validation loss: 1.9595827543607323

Epoch: 6| Step: 13
Training loss: 1.9535967111587524
Validation loss: 1.9566610244012648

Epoch: 158| Step: 0
Training loss: 1.75409734249115
Validation loss: 1.9407092935295516

Epoch: 6| Step: 1
Training loss: 1.931329607963562
Validation loss: 1.966788827732045

Epoch: 6| Step: 2
Training loss: 2.036673069000244
Validation loss: 1.9660680499128116

Epoch: 6| Step: 3
Training loss: 1.8491065502166748
Validation loss: 1.985143102625365

Epoch: 6| Step: 4
Training loss: 1.7101997137069702
Validation loss: 1.9497923645921933

Epoch: 6| Step: 5
Training loss: 2.0788912773132324
Validation loss: 1.973994178156699

Epoch: 6| Step: 6
Training loss: 1.514486312866211
Validation loss: 1.9546339217052664

Epoch: 6| Step: 7
Training loss: 1.4913445711135864
Validation loss: 1.95816296146762

Epoch: 6| Step: 8
Training loss: 2.582791805267334
Validation loss: 1.9550498480437903

Epoch: 6| Step: 9
Training loss: 1.8043994903564453
Validation loss: 1.9475468153594642

Epoch: 6| Step: 10
Training loss: 3.122270345687866
Validation loss: 1.940234168883293

Epoch: 6| Step: 11
Training loss: 1.8550509214401245
Validation loss: 1.9359120066447923

Epoch: 6| Step: 12
Training loss: 2.2595529556274414
Validation loss: 1.9548994148931196

Epoch: 6| Step: 13
Training loss: 1.3429932594299316
Validation loss: 1.9452072856246785

Epoch: 159| Step: 0
Training loss: 2.171379327774048
Validation loss: 1.9467107852300007

Epoch: 6| Step: 1
Training loss: 1.9130268096923828
Validation loss: 1.9524344410947574

Epoch: 6| Step: 2
Training loss: 1.869699239730835
Validation loss: 1.9688620951867872

Epoch: 6| Step: 3
Training loss: 1.986403465270996
Validation loss: 1.956523556863108

Epoch: 6| Step: 4
Training loss: 2.1617543697357178
Validation loss: 1.9717895471921532

Epoch: 6| Step: 5
Training loss: 2.0480380058288574
Validation loss: 1.9554732871311966

Epoch: 6| Step: 6
Training loss: 1.88893723487854
Validation loss: 1.9917231977626841

Epoch: 6| Step: 7
Training loss: 2.166059732437134
Validation loss: 1.9872656329985587

Epoch: 6| Step: 8
Training loss: 2.1025705337524414
Validation loss: 1.9629320483053885

Epoch: 6| Step: 9
Training loss: 1.624171257019043
Validation loss: 1.9765799737745715

Epoch: 6| Step: 10
Training loss: 2.3727657794952393
Validation loss: 1.9534292926070511

Epoch: 6| Step: 11
Training loss: 1.2919304370880127
Validation loss: 1.9701726731433664

Epoch: 6| Step: 12
Training loss: 2.0615878105163574
Validation loss: 1.9672698154244372

Epoch: 6| Step: 13
Training loss: 2.50972843170166
Validation loss: 1.9528343254520046

Epoch: 160| Step: 0
Training loss: 1.677112340927124
Validation loss: 1.9491769600940008

Epoch: 6| Step: 1
Training loss: 1.9901912212371826
Validation loss: 1.958317659234488

Epoch: 6| Step: 2
Training loss: 2.060112953186035
Validation loss: 1.9890556155994374

Epoch: 6| Step: 3
Training loss: 2.119952917098999
Validation loss: 1.9750749359848678

Epoch: 6| Step: 4
Training loss: 2.4203381538391113
Validation loss: 1.9501514562996485

Epoch: 6| Step: 5
Training loss: 2.1276473999023438
Validation loss: 1.9477922019138132

Epoch: 6| Step: 6
Training loss: 1.6645621061325073
Validation loss: 1.9690760668887888

Epoch: 6| Step: 7
Training loss: 1.7814388275146484
Validation loss: 1.9545216432181738

Epoch: 6| Step: 8
Training loss: 2.550081729888916
Validation loss: 1.9432187298292756

Epoch: 6| Step: 9
Training loss: 2.2558722496032715
Validation loss: 1.9597209140818606

Epoch: 6| Step: 10
Training loss: 1.5869050025939941
Validation loss: 1.9468430716504332

Epoch: 6| Step: 11
Training loss: 1.7903425693511963
Validation loss: 1.9429603084441154

Epoch: 6| Step: 12
Training loss: 1.5467541217803955
Validation loss: 1.9458725067877

Epoch: 6| Step: 13
Training loss: 2.088364601135254
Validation loss: 1.955244638586557

Epoch: 161| Step: 0
Training loss: 2.051286458969116
Validation loss: 1.9495162707503124

Epoch: 6| Step: 1
Training loss: 1.730299949645996
Validation loss: 1.9382046089377454

Epoch: 6| Step: 2
Training loss: 2.16180419921875
Validation loss: 1.9657922521714242

Epoch: 6| Step: 3
Training loss: 2.072700262069702
Validation loss: 1.9375253505604242

Epoch: 6| Step: 4
Training loss: 2.367069721221924
Validation loss: 1.9565066022257651

Epoch: 6| Step: 5
Training loss: 1.0751665830612183
Validation loss: 1.9440565955254339

Epoch: 6| Step: 6
Training loss: 2.3924028873443604
Validation loss: 1.9412579959438694

Epoch: 6| Step: 7
Training loss: 1.724452018737793
Validation loss: 1.922391729970132

Epoch: 6| Step: 8
Training loss: 2.062927722930908
Validation loss: 1.9489745709203905

Epoch: 6| Step: 9
Training loss: 2.606752634048462
Validation loss: 1.9168812382605769

Epoch: 6| Step: 10
Training loss: 1.8940755128860474
Validation loss: 1.9301621837000693

Epoch: 6| Step: 11
Training loss: 1.66957688331604
Validation loss: 1.931523787078037

Epoch: 6| Step: 12
Training loss: 1.5861656665802002
Validation loss: 1.9227131130874797

Epoch: 6| Step: 13
Training loss: 2.5272939205169678
Validation loss: 1.939847400111537

Epoch: 162| Step: 0
Training loss: 1.5701417922973633
Validation loss: 1.9297599843753281

Epoch: 6| Step: 1
Training loss: 1.8886430263519287
Validation loss: 1.9382014941143733

Epoch: 6| Step: 2
Training loss: 2.307424306869507
Validation loss: 1.9595144871742494

Epoch: 6| Step: 3
Training loss: 1.7446775436401367
Validation loss: 1.924045708871657

Epoch: 6| Step: 4
Training loss: 1.5088787078857422
Validation loss: 1.9550660207707395

Epoch: 6| Step: 5
Training loss: 2.142529010772705
Validation loss: 1.9539369947166854

Epoch: 6| Step: 6
Training loss: 2.0462846755981445
Validation loss: 1.9676164991112166

Epoch: 6| Step: 7
Training loss: 2.5681614875793457
Validation loss: 1.949042804779545

Epoch: 6| Step: 8
Training loss: 2.4859938621520996
Validation loss: 1.9509997880587013

Epoch: 6| Step: 9
Training loss: 2.0155773162841797
Validation loss: 1.9694514864234514

Epoch: 6| Step: 10
Training loss: 1.6287615299224854
Validation loss: 1.9872227163725003

Epoch: 6| Step: 11
Training loss: 2.2621424198150635
Validation loss: 1.9770798029438141

Epoch: 6| Step: 12
Training loss: 1.9507825374603271
Validation loss: 1.9563225264190345

Epoch: 6| Step: 13
Training loss: 1.2158613204956055
Validation loss: 1.9569956051406039

Epoch: 163| Step: 0
Training loss: 1.5868520736694336
Validation loss: 1.9802645175687728

Epoch: 6| Step: 1
Training loss: 2.1222429275512695
Validation loss: 1.9674069868621005

Epoch: 6| Step: 2
Training loss: 2.4755492210388184
Validation loss: 1.9619536784387404

Epoch: 6| Step: 3
Training loss: 1.7355118989944458
Validation loss: 1.9590564620110296

Epoch: 6| Step: 4
Training loss: 2.399305820465088
Validation loss: 1.9660439811727053

Epoch: 6| Step: 5
Training loss: 2.062375545501709
Validation loss: 1.9469152471070648

Epoch: 6| Step: 6
Training loss: 1.204450011253357
Validation loss: 1.9484645371795983

Epoch: 6| Step: 7
Training loss: 1.7568151950836182
Validation loss: 1.9679555136670348

Epoch: 6| Step: 8
Training loss: 1.9849436283111572
Validation loss: 1.966953513442829

Epoch: 6| Step: 9
Training loss: 2.511162757873535
Validation loss: 1.9494396960863503

Epoch: 6| Step: 10
Training loss: 2.4041571617126465
Validation loss: 1.953368394605575

Epoch: 6| Step: 11
Training loss: 1.3775997161865234
Validation loss: 1.9616008984145297

Epoch: 6| Step: 12
Training loss: 2.202040433883667
Validation loss: 1.9392319071677424

Epoch: 6| Step: 13
Training loss: 1.4751476049423218
Validation loss: 1.9313688739653556

Epoch: 164| Step: 0
Training loss: 1.581748604774475
Validation loss: 1.9502591779155116

Epoch: 6| Step: 1
Training loss: 1.1191378831863403
Validation loss: 1.9278462010045205

Epoch: 6| Step: 2
Training loss: 1.5918984413146973
Validation loss: 1.926032256054622

Epoch: 6| Step: 3
Training loss: 1.4555740356445312
Validation loss: 1.9590416223772111

Epoch: 6| Step: 4
Training loss: 1.8072986602783203
Validation loss: 1.9524069063125118

Epoch: 6| Step: 5
Training loss: 2.3660926818847656
Validation loss: 1.936835124928464

Epoch: 6| Step: 6
Training loss: 1.740100622177124
Validation loss: 1.9166185522592196

Epoch: 6| Step: 7
Training loss: 2.143968105316162
Validation loss: 1.9399547243631015

Epoch: 6| Step: 8
Training loss: 2.377926826477051
Validation loss: 1.9257686176607687

Epoch: 6| Step: 9
Training loss: 2.588301181793213
Validation loss: 1.934945132142754

Epoch: 6| Step: 10
Training loss: 2.3474998474121094
Validation loss: 1.9226604533451859

Epoch: 6| Step: 11
Training loss: 2.227374792098999
Validation loss: 1.9411660419997347

Epoch: 6| Step: 12
Training loss: 1.6555674076080322
Validation loss: 1.9405070427925355

Epoch: 6| Step: 13
Training loss: 2.7926225662231445
Validation loss: 1.9277084322385891

Epoch: 165| Step: 0
Training loss: 2.0783252716064453
Validation loss: 1.919825469293902

Epoch: 6| Step: 1
Training loss: 1.579965353012085
Validation loss: 1.9166478867171912

Epoch: 6| Step: 2
Training loss: 1.7325156927108765
Validation loss: 1.9178374044356807

Epoch: 6| Step: 3
Training loss: 2.109713554382324
Validation loss: 1.9485819852480324

Epoch: 6| Step: 4
Training loss: 2.273963212966919
Validation loss: 1.9401478998122677

Epoch: 6| Step: 5
Training loss: 2.1210014820098877
Validation loss: 1.945092919052288

Epoch: 6| Step: 6
Training loss: 2.1062726974487305
Validation loss: 1.9157683874971123

Epoch: 6| Step: 7
Training loss: 2.8626809120178223
Validation loss: 1.936529605619369

Epoch: 6| Step: 8
Training loss: 2.0980091094970703
Validation loss: 1.952948002405064

Epoch: 6| Step: 9
Training loss: 1.7144325971603394
Validation loss: 1.9642767290915213

Epoch: 6| Step: 10
Training loss: 1.749355435371399
Validation loss: 1.9194999484605686

Epoch: 6| Step: 11
Training loss: 1.279276967048645
Validation loss: 1.9485294690696142

Epoch: 6| Step: 12
Training loss: 1.8852429389953613
Validation loss: 1.9412351154511975

Epoch: 6| Step: 13
Training loss: 2.0868287086486816
Validation loss: 1.9112823804219563

Epoch: 166| Step: 0
Training loss: 2.574402332305908
Validation loss: 1.9373984772671935

Epoch: 6| Step: 1
Training loss: 1.9267299175262451
Validation loss: 1.948056686309076

Epoch: 6| Step: 2
Training loss: 1.714747667312622
Validation loss: 1.9528058908318962

Epoch: 6| Step: 3
Training loss: 2.0347349643707275
Validation loss: 1.9421461564238354

Epoch: 6| Step: 4
Training loss: 0.9483778476715088
Validation loss: 1.9383920200409428

Epoch: 6| Step: 5
Training loss: 1.9089059829711914
Validation loss: 1.9494210789280553

Epoch: 6| Step: 6
Training loss: 2.13472580909729
Validation loss: 1.9758933949214157

Epoch: 6| Step: 7
Training loss: 1.8788046836853027
Validation loss: 1.9552619944336593

Epoch: 6| Step: 8
Training loss: 2.399374008178711
Validation loss: 1.9390945434570312

Epoch: 6| Step: 9
Training loss: 2.1868324279785156
Validation loss: 1.9615444931932675

Epoch: 6| Step: 10
Training loss: 2.451542615890503
Validation loss: 1.955056405836536

Epoch: 6| Step: 11
Training loss: 2.180415153503418
Validation loss: 1.9487353704308952

Epoch: 6| Step: 12
Training loss: 1.6146814823150635
Validation loss: 1.9329126137559132

Epoch: 6| Step: 13
Training loss: 0.9180954694747925
Validation loss: 1.9162021888199674

Epoch: 167| Step: 0
Training loss: 1.5102826356887817
Validation loss: 1.9303567678697648

Epoch: 6| Step: 1
Training loss: 2.584200382232666
Validation loss: 1.9301315674217798

Epoch: 6| Step: 2
Training loss: 2.0791397094726562
Validation loss: 1.9585363095806492

Epoch: 6| Step: 3
Training loss: 1.5027883052825928
Validation loss: 1.9523610632906678

Epoch: 6| Step: 4
Training loss: 1.5523358583450317
Validation loss: 1.9215046949284051

Epoch: 6| Step: 5
Training loss: 1.9058185815811157
Validation loss: 1.971164317541225

Epoch: 6| Step: 6
Training loss: 1.1824523210525513
Validation loss: 1.9499601984536776

Epoch: 6| Step: 7
Training loss: 1.9022645950317383
Validation loss: 1.9606211236728135

Epoch: 6| Step: 8
Training loss: 1.8720020055770874
Validation loss: 1.9291078300886257

Epoch: 6| Step: 9
Training loss: 2.469322681427002
Validation loss: 1.9411898133575276

Epoch: 6| Step: 10
Training loss: 2.9434237480163574
Validation loss: 1.9612766376105688

Epoch: 6| Step: 11
Training loss: 1.8510940074920654
Validation loss: 1.95399901687458

Epoch: 6| Step: 12
Training loss: 2.0436878204345703
Validation loss: 1.9572525434596564

Epoch: 6| Step: 13
Training loss: 1.9394654035568237
Validation loss: 1.9743053746479813

Epoch: 168| Step: 0
Training loss: 1.9560627937316895
Validation loss: 1.965967709018338

Epoch: 6| Step: 1
Training loss: 2.350058078765869
Validation loss: 1.9532039050132997

Epoch: 6| Step: 2
Training loss: 1.6640205383300781
Validation loss: 1.9388138991530224

Epoch: 6| Step: 3
Training loss: 1.9758265018463135
Validation loss: 1.9478967907608196

Epoch: 6| Step: 4
Training loss: 2.2275137901306152
Validation loss: 1.9188555607231714

Epoch: 6| Step: 5
Training loss: 1.2196223735809326
Validation loss: 1.9204062646435154

Epoch: 6| Step: 6
Training loss: 1.9882643222808838
Validation loss: 1.9369803731159498

Epoch: 6| Step: 7
Training loss: 2.2396419048309326
Validation loss: 1.9229835899927283

Epoch: 6| Step: 8
Training loss: 1.9557855129241943
Validation loss: 1.9384997801114154

Epoch: 6| Step: 9
Training loss: 2.333620071411133
Validation loss: 1.9289702356502574

Epoch: 6| Step: 10
Training loss: 2.09426212310791
Validation loss: 1.9324333975392003

Epoch: 6| Step: 11
Training loss: 1.9230852127075195
Validation loss: 1.9400374338191042

Epoch: 6| Step: 12
Training loss: 1.5368661880493164
Validation loss: 1.955553461146611

Epoch: 6| Step: 13
Training loss: 1.89018714427948
Validation loss: 1.950018294395939

Epoch: 169| Step: 0
Training loss: 2.2953431606292725
Validation loss: 1.9266434100366407

Epoch: 6| Step: 1
Training loss: 1.557511568069458
Validation loss: 1.936869869949997

Epoch: 6| Step: 2
Training loss: 1.291736125946045
Validation loss: 1.938704458616113

Epoch: 6| Step: 3
Training loss: 2.5066189765930176
Validation loss: 1.924797724652034

Epoch: 6| Step: 4
Training loss: 1.8777557611465454
Validation loss: 1.9227602366478211

Epoch: 6| Step: 5
Training loss: 1.609276533126831
Validation loss: 1.9274523527391496

Epoch: 6| Step: 6
Training loss: 2.4493000507354736
Validation loss: 1.9313786952726302

Epoch: 6| Step: 7
Training loss: 1.4871485233306885
Validation loss: 1.9530795658788374

Epoch: 6| Step: 8
Training loss: 1.823012113571167
Validation loss: 1.935474854643627

Epoch: 6| Step: 9
Training loss: 1.6330327987670898
Validation loss: 1.9294733206431072

Epoch: 6| Step: 10
Training loss: 1.7013144493103027
Validation loss: 1.9325377107948385

Epoch: 6| Step: 11
Training loss: 1.9103147983551025
Validation loss: 1.9471108682693974

Epoch: 6| Step: 12
Training loss: 2.666273355484009
Validation loss: 1.9343414845005158

Epoch: 6| Step: 13
Training loss: 3.1434876918792725
Validation loss: 1.9309084235980947

Epoch: 170| Step: 0
Training loss: 1.5888173580169678
Validation loss: 1.941397479785386

Epoch: 6| Step: 1
Training loss: 1.978381872177124
Validation loss: 1.9519975877577258

Epoch: 6| Step: 2
Training loss: 1.8509938716888428
Validation loss: 1.9379398258783485

Epoch: 6| Step: 3
Training loss: 2.315514326095581
Validation loss: 1.9356974388963433

Epoch: 6| Step: 4
Training loss: 1.377789855003357
Validation loss: 1.9821362572331582

Epoch: 6| Step: 5
Training loss: 1.4864174127578735
Validation loss: 1.9502286590555662

Epoch: 6| Step: 6
Training loss: 2.4361400604248047
Validation loss: 1.9391067386955343

Epoch: 6| Step: 7
Training loss: 1.9665858745574951
Validation loss: 1.9608969585869902

Epoch: 6| Step: 8
Training loss: 2.041064739227295
Validation loss: 1.9673394580041208

Epoch: 6| Step: 9
Training loss: 2.833171844482422
Validation loss: 1.957870957671955

Epoch: 6| Step: 10
Training loss: 1.5359656810760498
Validation loss: 1.9551361235239173

Epoch: 6| Step: 11
Training loss: 1.787625789642334
Validation loss: 1.9761776411405174

Epoch: 6| Step: 12
Training loss: 2.1187477111816406
Validation loss: 1.964409698722183

Epoch: 6| Step: 13
Training loss: 1.938272476196289
Validation loss: 1.9453021352009108

Epoch: 171| Step: 0
Training loss: 2.1273224353790283
Validation loss: 1.9404639454298123

Epoch: 6| Step: 1
Training loss: 1.8437590599060059
Validation loss: 1.9409082038428194

Epoch: 6| Step: 2
Training loss: 1.9113487005233765
Validation loss: 1.9613953110992268

Epoch: 6| Step: 3
Training loss: 2.290894031524658
Validation loss: 1.9405199276503695

Epoch: 6| Step: 4
Training loss: 1.403080940246582
Validation loss: 1.9484341606017082

Epoch: 6| Step: 5
Training loss: 1.6125378608703613
Validation loss: 1.926567151982297

Epoch: 6| Step: 6
Training loss: 1.8454248905181885
Validation loss: 1.939682093999719

Epoch: 6| Step: 7
Training loss: 2.875072479248047
Validation loss: 1.9270741093543269

Epoch: 6| Step: 8
Training loss: 1.8989113569259644
Validation loss: 1.948856762660447

Epoch: 6| Step: 9
Training loss: 1.1765360832214355
Validation loss: 1.9423518462847638

Epoch: 6| Step: 10
Training loss: 2.2478747367858887
Validation loss: 1.9297320868379326

Epoch: 6| Step: 11
Training loss: 1.641298770904541
Validation loss: 1.9260658243651032

Epoch: 6| Step: 12
Training loss: 2.085904836654663
Validation loss: 1.9165513925654913

Epoch: 6| Step: 13
Training loss: 2.388380289077759
Validation loss: 1.916389311513593

Epoch: 172| Step: 0
Training loss: 2.1032228469848633
Validation loss: 1.9183249665844826

Epoch: 6| Step: 1
Training loss: 1.6388328075408936
Validation loss: 1.9422307027283536

Epoch: 6| Step: 2
Training loss: 2.6104860305786133
Validation loss: 1.9365218095881964

Epoch: 6| Step: 3
Training loss: 1.8687611818313599
Validation loss: 1.9365023092557025

Epoch: 6| Step: 4
Training loss: 2.627629041671753
Validation loss: 1.9236540025280369

Epoch: 6| Step: 5
Training loss: 1.7286797761917114
Validation loss: 1.9286164545243787

Epoch: 6| Step: 6
Training loss: 1.3503432273864746
Validation loss: 1.92193990753543

Epoch: 6| Step: 7
Training loss: 2.001741886138916
Validation loss: 1.9295352453826575

Epoch: 6| Step: 8
Training loss: 1.455826997756958
Validation loss: 1.9479656347664454

Epoch: 6| Step: 9
Training loss: 2.1645193099975586
Validation loss: 1.9260214567184448

Epoch: 6| Step: 10
Training loss: 2.0158724784851074
Validation loss: 1.9378683836229387

Epoch: 6| Step: 11
Training loss: 1.8361097574234009
Validation loss: 1.933687271610383

Epoch: 6| Step: 12
Training loss: 2.212191104888916
Validation loss: 1.9364848957266858

Epoch: 6| Step: 13
Training loss: 1.4525290727615356
Validation loss: 1.9539994911480976

Epoch: 173| Step: 0
Training loss: 2.0295510292053223
Validation loss: 1.933041855853091

Epoch: 6| Step: 1
Training loss: 1.5978871583938599
Validation loss: 1.9389667690441172

Epoch: 6| Step: 2
Training loss: 1.9103237390518188
Validation loss: 1.9498457280538415

Epoch: 6| Step: 3
Training loss: 2.106112003326416
Validation loss: 1.9366673423397927

Epoch: 6| Step: 4
Training loss: 2.0066120624542236
Validation loss: 1.932429264950496

Epoch: 6| Step: 5
Training loss: 1.9090118408203125
Validation loss: 1.94598251517101

Epoch: 6| Step: 6
Training loss: 2.4032328128814697
Validation loss: 1.9170290193250101

Epoch: 6| Step: 7
Training loss: 2.4413347244262695
Validation loss: 1.9335091280680832

Epoch: 6| Step: 8
Training loss: 1.7073237895965576
Validation loss: 1.9582667760951544

Epoch: 6| Step: 9
Training loss: 1.9380249977111816
Validation loss: 1.9324217086197228

Epoch: 6| Step: 10
Training loss: 1.2277836799621582
Validation loss: 1.9281454663122854

Epoch: 6| Step: 11
Training loss: 1.8451257944107056
Validation loss: 1.931954894014584

Epoch: 6| Step: 12
Training loss: 1.9748293161392212
Validation loss: 1.9455116371954642

Epoch: 6| Step: 13
Training loss: 2.333995819091797
Validation loss: 1.936768639472223

Epoch: 174| Step: 0
Training loss: 2.511786460876465
Validation loss: 1.9155112030685588

Epoch: 6| Step: 1
Training loss: 1.609466791152954
Validation loss: 1.921924655155469

Epoch: 6| Step: 2
Training loss: 2.33402156829834
Validation loss: 1.9453915665226598

Epoch: 6| Step: 3
Training loss: 1.0302143096923828
Validation loss: 1.9340894504259991

Epoch: 6| Step: 4
Training loss: 1.744415283203125
Validation loss: 1.9508820259442894

Epoch: 6| Step: 5
Training loss: 2.303682804107666
Validation loss: 1.9208679147945937

Epoch: 6| Step: 6
Training loss: 1.6511950492858887
Validation loss: 1.9435344921645297

Epoch: 6| Step: 7
Training loss: 2.1760852336883545
Validation loss: 1.9299362385144798

Epoch: 6| Step: 8
Training loss: 1.905319094657898
Validation loss: 1.9518089332888204

Epoch: 6| Step: 9
Training loss: 2.394819736480713
Validation loss: 1.9446846913265925

Epoch: 6| Step: 10
Training loss: 1.9397428035736084
Validation loss: 1.9383808182131859

Epoch: 6| Step: 11
Training loss: 1.5402929782867432
Validation loss: 1.9195020262913038

Epoch: 6| Step: 12
Training loss: 1.7328922748565674
Validation loss: 1.9516411340364845

Epoch: 6| Step: 13
Training loss: 2.4002790451049805
Validation loss: 1.9534856247645553

Epoch: 175| Step: 0
Training loss: 2.029292345046997
Validation loss: 1.9295462485282653

Epoch: 6| Step: 1
Training loss: 2.361506223678589
Validation loss: 1.9219057700967277

Epoch: 6| Step: 2
Training loss: 2.3421950340270996
Validation loss: 1.91643234222166

Epoch: 6| Step: 3
Training loss: 1.223010778427124
Validation loss: 1.9479719041496195

Epoch: 6| Step: 4
Training loss: 1.4333266019821167
Validation loss: 1.927726996842251

Epoch: 6| Step: 5
Training loss: 1.7060714960098267
Validation loss: 1.918421463299823

Epoch: 6| Step: 6
Training loss: 2.066019296646118
Validation loss: 1.9265044376414309

Epoch: 6| Step: 7
Training loss: 1.7289528846740723
Validation loss: 1.9174570537382556

Epoch: 6| Step: 8
Training loss: 1.33847975730896
Validation loss: 1.9168072823555238

Epoch: 6| Step: 9
Training loss: 2.272383451461792
Validation loss: 1.928730950560621

Epoch: 6| Step: 10
Training loss: 2.551677703857422
Validation loss: 1.928096120075513

Epoch: 6| Step: 11
Training loss: 2.2277731895446777
Validation loss: 1.9329933415177047

Epoch: 6| Step: 12
Training loss: 1.9938538074493408
Validation loss: 1.8972723586584932

Epoch: 6| Step: 13
Training loss: 1.1599867343902588
Validation loss: 1.9232066331371185

Epoch: 176| Step: 0
Training loss: 2.0056071281433105
Validation loss: 1.8935034377600557

Epoch: 6| Step: 1
Training loss: 1.4740567207336426
Validation loss: 1.918007489173643

Epoch: 6| Step: 2
Training loss: 1.9867885112762451
Validation loss: 1.9203424223007695

Epoch: 6| Step: 3
Training loss: 1.9064127206802368
Validation loss: 1.9182086862543577

Epoch: 6| Step: 4
Training loss: 2.2023305892944336
Validation loss: 1.9177547218979045

Epoch: 6| Step: 5
Training loss: 1.6114509105682373
Validation loss: 1.9211812660258303

Epoch: 6| Step: 6
Training loss: 1.6968059539794922
Validation loss: 1.9126053587082894

Epoch: 6| Step: 7
Training loss: 2.02895450592041
Validation loss: 1.8876153845940866

Epoch: 6| Step: 8
Training loss: 2.029865026473999
Validation loss: 1.9181254217701573

Epoch: 6| Step: 9
Training loss: 1.819110631942749
Validation loss: 1.9091916289380801

Epoch: 6| Step: 10
Training loss: 1.3749849796295166
Validation loss: 1.9463397982299968

Epoch: 6| Step: 11
Training loss: 2.1816565990448
Validation loss: 1.9537807254381077

Epoch: 6| Step: 12
Training loss: 2.5353927612304688
Validation loss: 1.931885464217073

Epoch: 6| Step: 13
Training loss: 1.9555176496505737
Validation loss: 1.9406528742082658

Epoch: 177| Step: 0
Training loss: 2.4132142066955566
Validation loss: 1.92943311250338

Epoch: 6| Step: 1
Training loss: 2.240450382232666
Validation loss: 1.9402201803781653

Epoch: 6| Step: 2
Training loss: 1.4648230075836182
Validation loss: 1.955138853801194

Epoch: 6| Step: 3
Training loss: 1.8601574897766113
Validation loss: 1.9762569883818268

Epoch: 6| Step: 4
Training loss: 2.204652786254883
Validation loss: 1.9215869147290465

Epoch: 6| Step: 5
Training loss: 2.7399420738220215
Validation loss: 1.9545465746233541

Epoch: 6| Step: 6
Training loss: 1.7373378276824951
Validation loss: 1.9808332714983212

Epoch: 6| Step: 7
Training loss: 1.9521061182022095
Validation loss: 1.9531463256446264

Epoch: 6| Step: 8
Training loss: 1.6265149116516113
Validation loss: 1.9569173038646739

Epoch: 6| Step: 9
Training loss: 1.904679775238037
Validation loss: 1.9616923742396857

Epoch: 6| Step: 10
Training loss: 1.9114727973937988
Validation loss: 1.965079899757139

Epoch: 6| Step: 11
Training loss: 1.7792565822601318
Validation loss: 1.9261025677445114

Epoch: 6| Step: 12
Training loss: 1.5772099494934082
Validation loss: 1.957083268832135

Epoch: 6| Step: 13
Training loss: 1.2298979759216309
Validation loss: 1.979751202367967

Epoch: 178| Step: 0
Training loss: 1.4906790256500244
Validation loss: 1.9386643696856756

Epoch: 6| Step: 1
Training loss: 1.8512234687805176
Validation loss: 1.9407825892971409

Epoch: 6| Step: 2
Training loss: 1.9549142122268677
Validation loss: 1.9272809259353145

Epoch: 6| Step: 3
Training loss: 1.8465499877929688
Validation loss: 1.9252802710379324

Epoch: 6| Step: 4
Training loss: 1.7763807773590088
Validation loss: 1.9330025039693361

Epoch: 6| Step: 5
Training loss: 2.0002007484436035
Validation loss: 1.9153922527067122

Epoch: 6| Step: 6
Training loss: 2.071777820587158
Validation loss: 1.952673255756337

Epoch: 6| Step: 7
Training loss: 1.5176587104797363
Validation loss: 1.9390640310061875

Epoch: 6| Step: 8
Training loss: 1.7520111799240112
Validation loss: 1.8813234272823538

Epoch: 6| Step: 9
Training loss: 1.7833172082901
Validation loss: 1.9058627133728356

Epoch: 6| Step: 10
Training loss: 1.8584702014923096
Validation loss: 1.900750244817426

Epoch: 6| Step: 11
Training loss: 2.2363646030426025
Validation loss: 1.9157710049742012

Epoch: 6| Step: 12
Training loss: 2.6360912322998047
Validation loss: 1.89836032928959

Epoch: 6| Step: 13
Training loss: 2.161778450012207
Validation loss: 1.913581266198107

Epoch: 179| Step: 0
Training loss: 1.8722469806671143
Validation loss: 1.905144274875682

Epoch: 6| Step: 1
Training loss: 1.662534236907959
Validation loss: 1.9270247310720465

Epoch: 6| Step: 2
Training loss: 1.5892772674560547
Validation loss: 1.9019989326436033

Epoch: 6| Step: 3
Training loss: 2.036106824874878
Validation loss: 1.935041622448993

Epoch: 6| Step: 4
Training loss: 1.5747010707855225
Validation loss: 1.9053358390767088

Epoch: 6| Step: 5
Training loss: 1.6706318855285645
Validation loss: 1.9379844434799687

Epoch: 6| Step: 6
Training loss: 2.10925030708313
Validation loss: 1.890952770427991

Epoch: 6| Step: 7
Training loss: 1.6831920146942139
Validation loss: 1.925762455950501

Epoch: 6| Step: 8
Training loss: 1.636756420135498
Validation loss: 1.912755356040052

Epoch: 6| Step: 9
Training loss: 2.3623459339141846
Validation loss: 1.9198110090788973

Epoch: 6| Step: 10
Training loss: 2.2744545936584473
Validation loss: 1.925977567190765

Epoch: 6| Step: 11
Training loss: 2.163461446762085
Validation loss: 1.9451798392880348

Epoch: 6| Step: 12
Training loss: 2.079688787460327
Validation loss: 1.9334702716078809

Epoch: 6| Step: 13
Training loss: 2.1861588954925537
Validation loss: 1.9574540994500602

Epoch: 180| Step: 0
Training loss: 2.069995403289795
Validation loss: 1.929728518250168

Epoch: 6| Step: 1
Training loss: 2.4454522132873535
Validation loss: 1.9449183710159794

Epoch: 6| Step: 2
Training loss: 1.8903427124023438
Validation loss: 1.9473911741728425

Epoch: 6| Step: 3
Training loss: 1.6728594303131104
Validation loss: 1.9591781041955436

Epoch: 6| Step: 4
Training loss: 1.429129958152771
Validation loss: 1.9565260410308838

Epoch: 6| Step: 5
Training loss: 2.4888973236083984
Validation loss: 1.9446960649182718

Epoch: 6| Step: 6
Training loss: 1.4772131443023682
Validation loss: 1.9187253649516771

Epoch: 6| Step: 7
Training loss: 1.125014066696167
Validation loss: 1.9501786244812833

Epoch: 6| Step: 8
Training loss: 2.5075392723083496
Validation loss: 1.934640448580506

Epoch: 6| Step: 9
Training loss: 2.1395058631896973
Validation loss: 1.9234307581378567

Epoch: 6| Step: 10
Training loss: 2.208789825439453
Validation loss: 1.9339951238324564

Epoch: 6| Step: 11
Training loss: 1.521918535232544
Validation loss: 1.9448241162043747

Epoch: 6| Step: 12
Training loss: 1.5415174961090088
Validation loss: 1.9139401861416396

Epoch: 6| Step: 13
Training loss: 2.431654930114746
Validation loss: 1.9345628189784225

Epoch: 181| Step: 0
Training loss: 1.773359775543213
Validation loss: 1.9327139572430683

Epoch: 6| Step: 1
Training loss: 1.3249537944793701
Validation loss: 1.943840572910924

Epoch: 6| Step: 2
Training loss: 1.2646007537841797
Validation loss: 1.937554778591279

Epoch: 6| Step: 3
Training loss: 2.5773863792419434
Validation loss: 1.9458369196102183

Epoch: 6| Step: 4
Training loss: 1.3831706047058105
Validation loss: 1.9579534838276524

Epoch: 6| Step: 5
Training loss: 2.036170244216919
Validation loss: 1.9722770555045015

Epoch: 6| Step: 6
Training loss: 2.0177881717681885
Validation loss: 1.9333717733301141

Epoch: 6| Step: 7
Training loss: 1.8614875078201294
Validation loss: 1.9570729719695223

Epoch: 6| Step: 8
Training loss: 2.135831356048584
Validation loss: 1.9453530593584942

Epoch: 6| Step: 9
Training loss: 2.348785161972046
Validation loss: 1.9179579288728776

Epoch: 6| Step: 10
Training loss: 1.599219799041748
Validation loss: 1.94594693440263

Epoch: 6| Step: 11
Training loss: 2.1988070011138916
Validation loss: 1.9509702959368307

Epoch: 6| Step: 12
Training loss: 2.3676998615264893
Validation loss: 1.9473287533688288

Epoch: 6| Step: 13
Training loss: 1.8804640769958496
Validation loss: 1.9450672390640422

Epoch: 182| Step: 0
Training loss: 2.2996673583984375
Validation loss: 1.9325414755011117

Epoch: 6| Step: 1
Training loss: 1.647336721420288
Validation loss: 1.9300042711278445

Epoch: 6| Step: 2
Training loss: 2.3448314666748047
Validation loss: 1.9095714976710658

Epoch: 6| Step: 3
Training loss: 1.7318222522735596
Validation loss: 1.919934162529566

Epoch: 6| Step: 4
Training loss: 1.883306622505188
Validation loss: 1.9155956224728656

Epoch: 6| Step: 5
Training loss: 2.03488826751709
Validation loss: 1.9340615285340177

Epoch: 6| Step: 6
Training loss: 1.8203420639038086
Validation loss: 1.9090990263928649

Epoch: 6| Step: 7
Training loss: 2.119915008544922
Validation loss: 1.909600857765444

Epoch: 6| Step: 8
Training loss: 1.3882617950439453
Validation loss: 1.9054970920726817

Epoch: 6| Step: 9
Training loss: 2.4860520362854004
Validation loss: 1.9067391246877692

Epoch: 6| Step: 10
Training loss: 1.4799699783325195
Validation loss: 1.9196444711377543

Epoch: 6| Step: 11
Training loss: 1.4886467456817627
Validation loss: 1.915290008309067

Epoch: 6| Step: 12
Training loss: 1.985066294670105
Validation loss: 1.9489291598719936

Epoch: 6| Step: 13
Training loss: 1.8650531768798828
Validation loss: 1.9229721792282597

Epoch: 183| Step: 0
Training loss: 1.7968863248825073
Validation loss: 1.912350582820113

Epoch: 6| Step: 1
Training loss: 2.2617273330688477
Validation loss: 1.919564252258629

Epoch: 6| Step: 2
Training loss: 1.6100594997406006
Validation loss: 1.914653790894375

Epoch: 6| Step: 3
Training loss: 1.6781790256500244
Validation loss: 1.916185627701462

Epoch: 6| Step: 4
Training loss: 1.4418116807937622
Validation loss: 1.931143900399567

Epoch: 6| Step: 5
Training loss: 1.4916437864303589
Validation loss: 1.9195774883352301

Epoch: 6| Step: 6
Training loss: 1.7177393436431885
Validation loss: 1.932662510102795

Epoch: 6| Step: 7
Training loss: 1.8692481517791748
Validation loss: 1.9188896609890846

Epoch: 6| Step: 8
Training loss: 2.7194557189941406
Validation loss: 1.9309088260896745

Epoch: 6| Step: 9
Training loss: 1.7882033586502075
Validation loss: 1.8939639637547154

Epoch: 6| Step: 10
Training loss: 2.356485605239868
Validation loss: 1.9194739813445716

Epoch: 6| Step: 11
Training loss: 2.432321071624756
Validation loss: 1.907605589077037

Epoch: 6| Step: 12
Training loss: 1.2690327167510986
Validation loss: 1.9066565767411263

Epoch: 6| Step: 13
Training loss: 2.6186282634735107
Validation loss: 1.897571789321079

Epoch: 184| Step: 0
Training loss: 2.2999157905578613
Validation loss: 1.9186825700985488

Epoch: 6| Step: 1
Training loss: 1.9806675910949707
Validation loss: 1.8991012368150937

Epoch: 6| Step: 2
Training loss: 2.317039966583252
Validation loss: 1.9097207233469973

Epoch: 6| Step: 3
Training loss: 1.8919082880020142
Validation loss: 1.9417972564697266

Epoch: 6| Step: 4
Training loss: 2.156656265258789
Validation loss: 1.9400553703308105

Epoch: 6| Step: 5
Training loss: 2.637613534927368
Validation loss: 1.9070809682210286

Epoch: 6| Step: 6
Training loss: 1.6667224168777466
Validation loss: 1.9536290271307832

Epoch: 6| Step: 7
Training loss: 1.5866450071334839
Validation loss: 1.9634985513584589

Epoch: 6| Step: 8
Training loss: 1.9430439472198486
Validation loss: 1.9567837868967364

Epoch: 6| Step: 9
Training loss: 1.4264131784439087
Validation loss: 1.9422325639314548

Epoch: 6| Step: 10
Training loss: 1.8149958848953247
Validation loss: 1.9348158233909196

Epoch: 6| Step: 11
Training loss: 1.7112326622009277
Validation loss: 1.9263095394257577

Epoch: 6| Step: 12
Training loss: 1.6405093669891357
Validation loss: 1.9317175265281432

Epoch: 6| Step: 13
Training loss: 1.4904024600982666
Validation loss: 1.9195816824513097

Epoch: 185| Step: 0
Training loss: 1.604909896850586
Validation loss: 1.917692801003815

Epoch: 6| Step: 1
Training loss: 2.1207046508789062
Validation loss: 1.925575412729735

Epoch: 6| Step: 2
Training loss: 1.7871747016906738
Validation loss: 1.9302838912574194

Epoch: 6| Step: 3
Training loss: 1.7953320741653442
Validation loss: 1.925442849436114

Epoch: 6| Step: 4
Training loss: 2.0334274768829346
Validation loss: 1.896096185971332

Epoch: 6| Step: 5
Training loss: 1.8588590621948242
Validation loss: 1.9262948830922444

Epoch: 6| Step: 6
Training loss: 2.3995561599731445
Validation loss: 1.9053734746030582

Epoch: 6| Step: 7
Training loss: 1.0607643127441406
Validation loss: 1.9276414468724241

Epoch: 6| Step: 8
Training loss: 2.416588306427002
Validation loss: 1.888039150545674

Epoch: 6| Step: 9
Training loss: 1.9394161701202393
Validation loss: 1.895422891903949

Epoch: 6| Step: 10
Training loss: 2.4410901069641113
Validation loss: 1.9143714263874998

Epoch: 6| Step: 11
Training loss: 1.2619071006774902
Validation loss: 1.918896326454737

Epoch: 6| Step: 12
Training loss: 2.118662118911743
Validation loss: 1.9407193532554052

Epoch: 6| Step: 13
Training loss: 1.5785813331604004
Validation loss: 1.9394667994591497

Epoch: 186| Step: 0
Training loss: 1.7307795286178589
Validation loss: 1.9348953129142843

Epoch: 6| Step: 1
Training loss: 1.5910756587982178
Validation loss: 1.924092064621628

Epoch: 6| Step: 2
Training loss: 1.958497405052185
Validation loss: 1.927814620797352

Epoch: 6| Step: 3
Training loss: 2.492368459701538
Validation loss: 1.9165444194629628

Epoch: 6| Step: 4
Training loss: 1.658928632736206
Validation loss: 1.8921727544517928

Epoch: 6| Step: 5
Training loss: 1.5519540309906006
Validation loss: 1.9029957338046002

Epoch: 6| Step: 6
Training loss: 2.0544896125793457
Validation loss: 1.9104166376975276

Epoch: 6| Step: 7
Training loss: 1.853356957435608
Validation loss: 1.9211408912494619

Epoch: 6| Step: 8
Training loss: 2.6757421493530273
Validation loss: 1.8684754781825568

Epoch: 6| Step: 9
Training loss: 1.490725040435791
Validation loss: 1.8943629905741701

Epoch: 6| Step: 10
Training loss: 1.7239673137664795
Validation loss: 1.897479062439293

Epoch: 6| Step: 11
Training loss: 1.917059302330017
Validation loss: 1.8860753249096613

Epoch: 6| Step: 12
Training loss: 1.5948847532272339
Validation loss: 1.9353420490859656

Epoch: 6| Step: 13
Training loss: 2.5619149208068848
Validation loss: 1.8901819964890838

Epoch: 187| Step: 0
Training loss: 1.6302714347839355
Validation loss: 1.8905035577794558

Epoch: 6| Step: 1
Training loss: 1.4164633750915527
Validation loss: 1.9137592033673358

Epoch: 6| Step: 2
Training loss: 2.113893985748291
Validation loss: 1.895126138964007

Epoch: 6| Step: 3
Training loss: 1.646489143371582
Validation loss: 1.8944776750379992

Epoch: 6| Step: 4
Training loss: 1.4819929599761963
Validation loss: 1.9062351552389

Epoch: 6| Step: 5
Training loss: 2.2598025798797607
Validation loss: 1.9300834081506217

Epoch: 6| Step: 6
Training loss: 1.9096019268035889
Validation loss: 1.931069302302535

Epoch: 6| Step: 7
Training loss: 1.9630498886108398
Validation loss: 1.9286693808852986

Epoch: 6| Step: 8
Training loss: 1.8211015462875366
Validation loss: 1.9169241933412449

Epoch: 6| Step: 9
Training loss: 2.61898136138916
Validation loss: 1.9021963547634821

Epoch: 6| Step: 10
Training loss: 1.8016481399536133
Validation loss: 1.8917821325281614

Epoch: 6| Step: 11
Training loss: 1.9919700622558594
Validation loss: 1.8969303805341002

Epoch: 6| Step: 12
Training loss: 1.752028465270996
Validation loss: 1.919596516957847

Epoch: 6| Step: 13
Training loss: 1.8877122402191162
Validation loss: 1.9155406798085859

Epoch: 188| Step: 0
Training loss: 1.2445952892303467
Validation loss: 1.9069663734846218

Epoch: 6| Step: 1
Training loss: 1.8807201385498047
Validation loss: 1.919363050050633

Epoch: 6| Step: 2
Training loss: 1.8660005331039429
Validation loss: 1.9225400775991461

Epoch: 6| Step: 3
Training loss: 1.5674241781234741
Validation loss: 1.9318048774555165

Epoch: 6| Step: 4
Training loss: 1.7215608358383179
Validation loss: 1.9144706469710155

Epoch: 6| Step: 5
Training loss: 1.7541577816009521
Validation loss: 1.9116768631883847

Epoch: 6| Step: 6
Training loss: 2.4664039611816406
Validation loss: 1.9171652024792087

Epoch: 6| Step: 7
Training loss: 1.7820043563842773
Validation loss: 1.9291935992497269

Epoch: 6| Step: 8
Training loss: 1.725623607635498
Validation loss: 1.9177448672633017

Epoch: 6| Step: 9
Training loss: 1.9068806171417236
Validation loss: 1.9272069418302147

Epoch: 6| Step: 10
Training loss: 2.7130696773529053
Validation loss: 1.9287515019857755

Epoch: 6| Step: 11
Training loss: 1.8316409587860107
Validation loss: 1.9107172642984698

Epoch: 6| Step: 12
Training loss: 1.8131085634231567
Validation loss: 1.9026150818794005

Epoch: 6| Step: 13
Training loss: 2.3743736743927
Validation loss: 1.8902000586191814

Epoch: 189| Step: 0
Training loss: 1.939949870109558
Validation loss: 1.9175336694204679

Epoch: 6| Step: 1
Training loss: 1.9381407499313354
Validation loss: 1.9010035837850263

Epoch: 6| Step: 2
Training loss: 2.7787835597991943
Validation loss: 1.9174714037167129

Epoch: 6| Step: 3
Training loss: 1.5200388431549072
Validation loss: 1.9167213234850156

Epoch: 6| Step: 4
Training loss: 1.8164600133895874
Validation loss: 1.9267647984207317

Epoch: 6| Step: 5
Training loss: 1.5886292457580566
Validation loss: 1.9207213642776653

Epoch: 6| Step: 6
Training loss: 1.6412146091461182
Validation loss: 1.9349581426189792

Epoch: 6| Step: 7
Training loss: 1.9340862035751343
Validation loss: 1.9202654361724854

Epoch: 6| Step: 8
Training loss: 1.6785924434661865
Validation loss: 1.903694042595484

Epoch: 6| Step: 9
Training loss: 1.616762638092041
Validation loss: 1.9239302681338402

Epoch: 6| Step: 10
Training loss: 1.9955095052719116
Validation loss: 1.9050212137160762

Epoch: 6| Step: 11
Training loss: 2.014857530593872
Validation loss: 1.89314135941126

Epoch: 6| Step: 12
Training loss: 1.5546181201934814
Validation loss: 1.9096531534707675

Epoch: 6| Step: 13
Training loss: 2.9005918502807617
Validation loss: 1.8910439027253019

Epoch: 190| Step: 0
Training loss: 2.2545955181121826
Validation loss: 1.9059245458213232

Epoch: 6| Step: 1
Training loss: 1.5358161926269531
Validation loss: 1.9165105819702148

Epoch: 6| Step: 2
Training loss: 1.6565849781036377
Validation loss: 1.9251030183607531

Epoch: 6| Step: 3
Training loss: 2.2565865516662598
Validation loss: 1.903596180741505

Epoch: 6| Step: 4
Training loss: 1.7732336521148682
Validation loss: 1.9100348821250341

Epoch: 6| Step: 5
Training loss: 1.5301570892333984
Validation loss: 1.9206730691335534

Epoch: 6| Step: 6
Training loss: 1.703000545501709
Validation loss: 1.9099583753975489

Epoch: 6| Step: 7
Training loss: 1.3388521671295166
Validation loss: 1.8875342081951838

Epoch: 6| Step: 8
Training loss: 2.1118688583374023
Validation loss: 1.921889196160019

Epoch: 6| Step: 9
Training loss: 1.8696916103363037
Validation loss: 1.893874745215139

Epoch: 6| Step: 10
Training loss: 1.7913891077041626
Validation loss: 1.9147888639921784

Epoch: 6| Step: 11
Training loss: 2.075007438659668
Validation loss: 1.8934534544585853

Epoch: 6| Step: 12
Training loss: 2.168417453765869
Validation loss: 1.8974663544726629

Epoch: 6| Step: 13
Training loss: 2.187177896499634
Validation loss: 1.9151078013963596

Epoch: 191| Step: 0
Training loss: 1.5069611072540283
Validation loss: 1.914587818166261

Epoch: 6| Step: 1
Training loss: 1.897687315940857
Validation loss: 1.8954037773993708

Epoch: 6| Step: 2
Training loss: 2.1859254837036133
Validation loss: 1.87330335955466

Epoch: 6| Step: 3
Training loss: 2.0143635272979736
Validation loss: 1.937164714259486

Epoch: 6| Step: 4
Training loss: 1.920040249824524
Validation loss: 1.9081820288012106

Epoch: 6| Step: 5
Training loss: 2.4518978595733643
Validation loss: 1.908895432308156

Epoch: 6| Step: 6
Training loss: 1.8543647527694702
Validation loss: 1.9013946505003079

Epoch: 6| Step: 7
Training loss: 1.8260749578475952
Validation loss: 1.9066825976935766

Epoch: 6| Step: 8
Training loss: 2.2682526111602783
Validation loss: 1.9136031622527747

Epoch: 6| Step: 9
Training loss: 1.846667766571045
Validation loss: 1.9127080088020654

Epoch: 6| Step: 10
Training loss: 2.5577712059020996
Validation loss: 1.9005048685176398

Epoch: 6| Step: 11
Training loss: 1.0982730388641357
Validation loss: 1.9412918449730001

Epoch: 6| Step: 12
Training loss: 1.1193947792053223
Validation loss: 1.9124959361168645

Epoch: 6| Step: 13
Training loss: 1.6952393054962158
Validation loss: 1.8955745491930234

Epoch: 192| Step: 0
Training loss: 1.7690212726593018
Validation loss: 1.9171843618474982

Epoch: 6| Step: 1
Training loss: 1.9865436553955078
Validation loss: 1.9254420162529073

Epoch: 6| Step: 2
Training loss: 2.193147897720337
Validation loss: 1.9202918673074374

Epoch: 6| Step: 3
Training loss: 2.385575532913208
Validation loss: 1.9164277763776882

Epoch: 6| Step: 4
Training loss: 2.1915431022644043
Validation loss: 1.9098555144443308

Epoch: 6| Step: 5
Training loss: 1.5975786447525024
Validation loss: 1.9045724099682224

Epoch: 6| Step: 6
Training loss: 1.674716830253601
Validation loss: 1.923943249128198

Epoch: 6| Step: 7
Training loss: 2.2252278327941895
Validation loss: 1.9154075755867908

Epoch: 6| Step: 8
Training loss: 2.102992534637451
Validation loss: 1.9017154324439265

Epoch: 6| Step: 9
Training loss: 1.8727941513061523
Validation loss: 1.9009143460181452

Epoch: 6| Step: 10
Training loss: 1.7572391033172607
Validation loss: 1.9079044557386828

Epoch: 6| Step: 11
Training loss: 1.3989217281341553
Validation loss: 1.9228217473594091

Epoch: 6| Step: 12
Training loss: 1.6534333229064941
Validation loss: 1.8969374856641215

Epoch: 6| Step: 13
Training loss: 0.9804378151893616
Validation loss: 1.9022779695449337

Epoch: 193| Step: 0
Training loss: 1.5920462608337402
Validation loss: 1.9037470304837791

Epoch: 6| Step: 1
Training loss: 1.9255638122558594
Validation loss: 1.8990089239612702

Epoch: 6| Step: 2
Training loss: 2.143362522125244
Validation loss: 1.9291486791385117

Epoch: 6| Step: 3
Training loss: 1.6800320148468018
Validation loss: 1.9475790595495572

Epoch: 6| Step: 4
Training loss: 1.5285859107971191
Validation loss: 1.9323097839150378

Epoch: 6| Step: 5
Training loss: 2.084920644760132
Validation loss: 1.9287986345188592

Epoch: 6| Step: 6
Training loss: 2.2339999675750732
Validation loss: 1.935861292705741

Epoch: 6| Step: 7
Training loss: 1.2074148654937744
Validation loss: 1.9249482180482598

Epoch: 6| Step: 8
Training loss: 1.4532029628753662
Validation loss: 1.9418393745217273

Epoch: 6| Step: 9
Training loss: 2.2735190391540527
Validation loss: 1.9283354897652902

Epoch: 6| Step: 10
Training loss: 1.3567675352096558
Validation loss: 1.9343215598854968

Epoch: 6| Step: 11
Training loss: 2.0074892044067383
Validation loss: 1.9111558801384383

Epoch: 6| Step: 12
Training loss: 2.4103407859802246
Validation loss: 1.9399501854373562

Epoch: 6| Step: 13
Training loss: 2.56514573097229
Validation loss: 1.9345612692576584

Epoch: 194| Step: 0
Training loss: 1.343522548675537
Validation loss: 1.921356770300096

Epoch: 6| Step: 1
Training loss: 1.7387497425079346
Validation loss: 1.9208340234653924

Epoch: 6| Step: 2
Training loss: 2.7264657020568848
Validation loss: 1.9182684242084462

Epoch: 6| Step: 3
Training loss: 2.1910228729248047
Validation loss: 1.8898869035064534

Epoch: 6| Step: 4
Training loss: 1.7004082202911377
Validation loss: 1.8634961420489895

Epoch: 6| Step: 5
Training loss: 2.0187714099884033
Validation loss: 1.8759342521749518

Epoch: 6| Step: 6
Training loss: 2.016481637954712
Validation loss: 1.906648209018092

Epoch: 6| Step: 7
Training loss: 1.5679473876953125
Validation loss: 1.9042873600477814

Epoch: 6| Step: 8
Training loss: 2.291477680206299
Validation loss: 1.9174738135389102

Epoch: 6| Step: 9
Training loss: 1.836158037185669
Validation loss: 1.8895739393849527

Epoch: 6| Step: 10
Training loss: 1.2107601165771484
Validation loss: 1.8868440017905286

Epoch: 6| Step: 11
Training loss: 1.0978695154190063
Validation loss: 1.8840908927302207

Epoch: 6| Step: 12
Training loss: 2.3054966926574707
Validation loss: 1.8839910645638742

Epoch: 6| Step: 13
Training loss: 2.2573366165161133
Validation loss: 1.9028904027836298

Epoch: 195| Step: 0
Training loss: 1.9017815589904785
Validation loss: 1.9012721430870794

Epoch: 6| Step: 1
Training loss: 1.8898541927337646
Validation loss: 1.88806821966684

Epoch: 6| Step: 2
Training loss: 1.945772409439087
Validation loss: 1.8713485425518406

Epoch: 6| Step: 3
Training loss: 2.407148838043213
Validation loss: 1.8997050882667623

Epoch: 6| Step: 4
Training loss: 1.8774311542510986
Validation loss: 1.889435068253548

Epoch: 6| Step: 5
Training loss: 1.8413119316101074
Validation loss: 1.9076995503517888

Epoch: 6| Step: 6
Training loss: 1.5542608499526978
Validation loss: 1.9050312760055705

Epoch: 6| Step: 7
Training loss: 2.0436785221099854
Validation loss: 1.8826738147325413

Epoch: 6| Step: 8
Training loss: 1.648254156112671
Validation loss: 1.9061373587577575

Epoch: 6| Step: 9
Training loss: 0.7095773220062256
Validation loss: 1.8969692081533454

Epoch: 6| Step: 10
Training loss: 2.325525999069214
Validation loss: 1.8990345693403674

Epoch: 6| Step: 11
Training loss: 1.8016867637634277
Validation loss: 1.8936115849402644

Epoch: 6| Step: 12
Training loss: 2.2355213165283203
Validation loss: 1.8965565427657096

Epoch: 6| Step: 13
Training loss: 1.447068214416504
Validation loss: 1.9096478300709878

Epoch: 196| Step: 0
Training loss: 2.0187010765075684
Validation loss: 1.8872203352630779

Epoch: 6| Step: 1
Training loss: 1.4443501234054565
Validation loss: 1.9171337953177832

Epoch: 6| Step: 2
Training loss: 1.9585292339324951
Validation loss: 1.9120921434894684

Epoch: 6| Step: 3
Training loss: 2.318479537963867
Validation loss: 1.9318174316037087

Epoch: 6| Step: 4
Training loss: 1.9981553554534912
Validation loss: 1.8602606468303229

Epoch: 6| Step: 5
Training loss: 2.5085794925689697
Validation loss: 1.9049469758105535

Epoch: 6| Step: 6
Training loss: 1.9663524627685547
Validation loss: 1.9253030387304162

Epoch: 6| Step: 7
Training loss: 1.7008423805236816
Validation loss: 1.9288942942055323

Epoch: 6| Step: 8
Training loss: 1.4277639389038086
Validation loss: 1.9125837254267868

Epoch: 6| Step: 9
Training loss: 1.1219651699066162
Validation loss: 1.884227450175952

Epoch: 6| Step: 10
Training loss: 2.0209858417510986
Validation loss: 1.91960891344214

Epoch: 6| Step: 11
Training loss: 1.6726356744766235
Validation loss: 1.9069521324608916

Epoch: 6| Step: 12
Training loss: 1.8070518970489502
Validation loss: 1.9094196852817331

Epoch: 6| Step: 13
Training loss: 2.411221742630005
Validation loss: 1.8907796605940788

Epoch: 197| Step: 0
Training loss: 1.2081656455993652
Validation loss: 1.88774356021676

Epoch: 6| Step: 1
Training loss: 1.1066688299179077
Validation loss: 1.895401826468847

Epoch: 6| Step: 2
Training loss: 1.8234288692474365
Validation loss: 1.8958335384245841

Epoch: 6| Step: 3
Training loss: 2.0846803188323975
Validation loss: 1.9503021317143594

Epoch: 6| Step: 4
Training loss: 2.125688314437866
Validation loss: 1.915328041199715

Epoch: 6| Step: 5
Training loss: 1.2983460426330566
Validation loss: 1.909023800203877

Epoch: 6| Step: 6
Training loss: 1.8082576990127563
Validation loss: 1.9292195894384896

Epoch: 6| Step: 7
Training loss: 2.007707118988037
Validation loss: 1.9326004674357753

Epoch: 6| Step: 8
Training loss: 1.9492881298065186
Validation loss: 1.8957586801180275

Epoch: 6| Step: 9
Training loss: 2.682502269744873
Validation loss: 1.8888950732446486

Epoch: 6| Step: 10
Training loss: 2.2612509727478027
Validation loss: 1.8900353562447332

Epoch: 6| Step: 11
Training loss: 1.541285753250122
Validation loss: 1.925517468042271

Epoch: 6| Step: 12
Training loss: 1.855699896812439
Validation loss: 1.8943999672448764

Epoch: 6| Step: 13
Training loss: 2.180420160293579
Validation loss: 1.9013261154133787

Epoch: 198| Step: 0
Training loss: 1.8669999837875366
Validation loss: 1.8840069155539236

Epoch: 6| Step: 1
Training loss: 1.014671802520752
Validation loss: 1.8805148293895106

Epoch: 6| Step: 2
Training loss: 1.7726645469665527
Validation loss: 1.9003609482960035

Epoch: 6| Step: 3
Training loss: 1.5184801816940308
Validation loss: 1.8898426666054675

Epoch: 6| Step: 4
Training loss: 1.3979249000549316
Validation loss: 1.8884531503082604

Epoch: 6| Step: 5
Training loss: 1.1764225959777832
Validation loss: 1.8860189017429148

Epoch: 6| Step: 6
Training loss: 2.3121795654296875
Validation loss: 1.9036633301806707

Epoch: 6| Step: 7
Training loss: 1.6805673837661743
Validation loss: 1.9002197480970813

Epoch: 6| Step: 8
Training loss: 2.292098045349121
Validation loss: 1.8850515568128197

Epoch: 6| Step: 9
Training loss: 2.6601450443267822
Validation loss: 1.896032174428304

Epoch: 6| Step: 10
Training loss: 2.2291483879089355
Validation loss: 1.8876666202340076

Epoch: 6| Step: 11
Training loss: 2.4418692588806152
Validation loss: 1.88211525511998

Epoch: 6| Step: 12
Training loss: 1.7375866174697876
Validation loss: 1.8761891985452304

Epoch: 6| Step: 13
Training loss: 1.4347461462020874
Validation loss: 1.8988774002239268

Epoch: 199| Step: 0
Training loss: 2.235776424407959
Validation loss: 1.89799169699351

Epoch: 6| Step: 1
Training loss: 1.1049195528030396
Validation loss: 1.888430885089341

Epoch: 6| Step: 2
Training loss: 2.221611976623535
Validation loss: 1.8947539150073964

Epoch: 6| Step: 3
Training loss: 1.6933361291885376
Validation loss: 1.911774290505276

Epoch: 6| Step: 4
Training loss: 1.865336298942566
Validation loss: 1.889099346694126

Epoch: 6| Step: 5
Training loss: 2.376676321029663
Validation loss: 1.8836872295666767

Epoch: 6| Step: 6
Training loss: 1.50132417678833
Validation loss: 1.887060788369948

Epoch: 6| Step: 7
Training loss: 1.66907799243927
Validation loss: 1.8828445711443502

Epoch: 6| Step: 8
Training loss: 1.6818876266479492
Validation loss: 1.908929919683805

Epoch: 6| Step: 9
Training loss: 2.565309524536133
Validation loss: 1.8935258375701083

Epoch: 6| Step: 10
Training loss: 1.5146000385284424
Validation loss: 1.8781591153913928

Epoch: 6| Step: 11
Training loss: 1.7232590913772583
Validation loss: 1.881068870585452

Epoch: 6| Step: 12
Training loss: 1.8819464445114136
Validation loss: 1.9017705584085116

Epoch: 6| Step: 13
Training loss: 1.8137410879135132
Validation loss: 1.911022081170031

Epoch: 200| Step: 0
Training loss: 2.0510053634643555
Validation loss: 1.9012381005030807

Epoch: 6| Step: 1
Training loss: 1.6967027187347412
Validation loss: 1.8890486378823557

Epoch: 6| Step: 2
Training loss: 1.395758032798767
Validation loss: 1.8981501287029636

Epoch: 6| Step: 3
Training loss: 1.4577980041503906
Validation loss: 1.8968258596235705

Epoch: 6| Step: 4
Training loss: 2.250563144683838
Validation loss: 1.915377346418237

Epoch: 6| Step: 5
Training loss: 2.1271815299987793
Validation loss: 1.8711689646526048

Epoch: 6| Step: 6
Training loss: 1.0235601663589478
Validation loss: 1.9059156935702088

Epoch: 6| Step: 7
Training loss: 1.5658612251281738
Validation loss: 1.906182178886988

Epoch: 6| Step: 8
Training loss: 2.0645015239715576
Validation loss: 1.9148308051529752

Epoch: 6| Step: 9
Training loss: 1.9915778636932373
Validation loss: 1.9028610657620173

Epoch: 6| Step: 10
Training loss: 2.1806483268737793
Validation loss: 1.9243427258665844

Epoch: 6| Step: 11
Training loss: 2.4965009689331055
Validation loss: 1.8799009912757463

Epoch: 6| Step: 12
Training loss: 1.690997838973999
Validation loss: 1.8745238960430186

Epoch: 6| Step: 13
Training loss: 1.572858214378357
Validation loss: 1.9142087569800756

Testing loss: 2.1491106934017603
