Epoch: 1| Step: 0
Training loss: 6.928879737854004
Validation loss: 8.324362390784808

Epoch: 6| Step: 1
Training loss: 8.241594314575195
Validation loss: 8.317643606534569

Epoch: 6| Step: 2
Training loss: 6.684531211853027
Validation loss: 8.310348644051501

Epoch: 6| Step: 3
Training loss: 8.816259384155273
Validation loss: 8.301784371816984

Epoch: 6| Step: 4
Training loss: 8.92116928100586
Validation loss: 8.294183659297163

Epoch: 6| Step: 5
Training loss: 8.129546165466309
Validation loss: 8.284725260990923

Epoch: 6| Step: 6
Training loss: 8.045548439025879
Validation loss: 8.279989222044586

Epoch: 6| Step: 7
Training loss: 8.315537452697754
Validation loss: 8.273654763416577

Epoch: 6| Step: 8
Training loss: 9.484984397888184
Validation loss: 8.263592976395802

Epoch: 6| Step: 9
Training loss: 7.160824298858643
Validation loss: 8.2581576583206

Epoch: 6| Step: 10
Training loss: 7.554598331451416
Validation loss: 8.249805194075389

Epoch: 6| Step: 11
Training loss: 7.8368635177612305
Validation loss: 8.243456091932071

Epoch: 6| Step: 12
Training loss: 8.497228622436523
Validation loss: 8.236045263146842

Epoch: 6| Step: 13
Training loss: 8.631832122802734
Validation loss: 8.228852733489006

Epoch: 2| Step: 0
Training loss: 8.647857666015625
Validation loss: 8.221420154776624

Epoch: 6| Step: 1
Training loss: 8.25400161743164
Validation loss: 8.214556611994261

Epoch: 6| Step: 2
Training loss: 7.310504913330078
Validation loss: 8.206026682289698

Epoch: 6| Step: 3
Training loss: 6.11674690246582
Validation loss: 8.197663748136131

Epoch: 6| Step: 4
Training loss: 7.078327655792236
Validation loss: 8.192634633792345

Epoch: 6| Step: 5
Training loss: 9.009913444519043
Validation loss: 8.184960380677254

Epoch: 6| Step: 6
Training loss: 8.817719459533691
Validation loss: 8.17832637089555

Epoch: 6| Step: 7
Training loss: 8.4940824508667
Validation loss: 8.169385499851678

Epoch: 6| Step: 8
Training loss: 8.44948673248291
Validation loss: 8.164843964320356

Epoch: 6| Step: 9
Training loss: 7.833446025848389
Validation loss: 8.156543649652953

Epoch: 6| Step: 10
Training loss: 8.052169799804688
Validation loss: 8.149323955658943

Epoch: 6| Step: 11
Training loss: 7.544215202331543
Validation loss: 8.141630106074835

Epoch: 6| Step: 12
Training loss: 6.5846710205078125
Validation loss: 8.136540197557018

Epoch: 6| Step: 13
Training loss: 10.377158164978027
Validation loss: 8.12662826045867

Epoch: 3| Step: 0
Training loss: 7.277300834655762
Validation loss: 8.123101070363035

Epoch: 6| Step: 1
Training loss: 7.639068603515625
Validation loss: 8.114238292940202

Epoch: 6| Step: 2
Training loss: 7.4095540046691895
Validation loss: 8.107808082334456

Epoch: 6| Step: 3
Training loss: 7.6206464767456055
Validation loss: 8.09843361249534

Epoch: 6| Step: 4
Training loss: 7.98931360244751
Validation loss: 8.093534684950306

Epoch: 6| Step: 5
Training loss: 8.590293884277344
Validation loss: 8.085335003432407

Epoch: 6| Step: 6
Training loss: 7.520614147186279
Validation loss: 8.080391099376063

Epoch: 6| Step: 7
Training loss: 8.039240837097168
Validation loss: 8.069525636652465

Epoch: 6| Step: 8
Training loss: 8.194952964782715
Validation loss: 8.064167504669518

Epoch: 6| Step: 9
Training loss: 7.957300186157227
Validation loss: 8.057128639631374

Epoch: 6| Step: 10
Training loss: 7.1370344161987305
Validation loss: 8.047553093202653

Epoch: 6| Step: 11
Training loss: 8.800600051879883
Validation loss: 8.043119040868616

Epoch: 6| Step: 12
Training loss: 7.710145950317383
Validation loss: 8.035548938217984

Epoch: 6| Step: 13
Training loss: 8.517057418823242
Validation loss: 8.029486374188496

Epoch: 4| Step: 0
Training loss: 8.148174285888672
Validation loss: 8.018285853888399

Epoch: 6| Step: 1
Training loss: 7.296957015991211
Validation loss: 8.01576759994671

Epoch: 6| Step: 2
Training loss: 8.141205787658691
Validation loss: 8.005777276972289

Epoch: 6| Step: 3
Training loss: 9.848567962646484
Validation loss: 7.996504178611181

Epoch: 6| Step: 4
Training loss: 6.7777509689331055
Validation loss: 7.990413501698484

Epoch: 6| Step: 5
Training loss: 6.96387243270874
Validation loss: 7.983337315179968

Epoch: 6| Step: 6
Training loss: 7.266278266906738
Validation loss: 7.977178604372086

Epoch: 6| Step: 7
Training loss: 7.8725409507751465
Validation loss: 7.968309638320759

Epoch: 6| Step: 8
Training loss: 8.037628173828125
Validation loss: 7.962804512311053

Epoch: 6| Step: 9
Training loss: 7.464803218841553
Validation loss: 7.953288437217794

Epoch: 6| Step: 10
Training loss: 7.312237739562988
Validation loss: 7.945159101998934

Epoch: 6| Step: 11
Training loss: 8.742728233337402
Validation loss: 7.938746677931919

Epoch: 6| Step: 12
Training loss: 7.170340538024902
Validation loss: 7.930452423710977

Epoch: 6| Step: 13
Training loss: 7.473201274871826
Validation loss: 7.922135876071069

Epoch: 5| Step: 0
Training loss: 7.303426265716553
Validation loss: 7.916959378027147

Epoch: 6| Step: 1
Training loss: 7.823010444641113
Validation loss: 7.908820080500777

Epoch: 6| Step: 2
Training loss: 8.171231269836426
Validation loss: 7.89951737209033

Epoch: 6| Step: 3
Training loss: 7.550789833068848
Validation loss: 7.8886255295045915

Epoch: 6| Step: 4
Training loss: 7.622566223144531
Validation loss: 7.88165158097462

Epoch: 6| Step: 5
Training loss: 7.320320129394531
Validation loss: 7.873071788459696

Epoch: 6| Step: 6
Training loss: 7.58031702041626
Validation loss: 7.866719004928425

Epoch: 6| Step: 7
Training loss: 7.002362251281738
Validation loss: 7.858541539920274

Epoch: 6| Step: 8
Training loss: 6.8992509841918945
Validation loss: 7.8490710719939205

Epoch: 6| Step: 9
Training loss: 6.8680524826049805
Validation loss: 7.84120524314142

Epoch: 6| Step: 10
Training loss: 8.386075019836426
Validation loss: 7.834937049496558

Epoch: 6| Step: 11
Training loss: 8.397333145141602
Validation loss: 7.821108515544604

Epoch: 6| Step: 12
Training loss: 8.283130645751953
Validation loss: 7.814753409354918

Epoch: 6| Step: 13
Training loss: 7.969106674194336
Validation loss: 7.807678986621159

Epoch: 6| Step: 0
Training loss: 5.998028755187988
Validation loss: 7.798956583904964

Epoch: 6| Step: 1
Training loss: 7.51411247253418
Validation loss: 7.789375469248782

Epoch: 6| Step: 2
Training loss: 7.289281845092773
Validation loss: 7.777132629066386

Epoch: 6| Step: 3
Training loss: 8.102473258972168
Validation loss: 7.769883160950036

Epoch: 6| Step: 4
Training loss: 6.570265769958496
Validation loss: 7.7595172287315455

Epoch: 6| Step: 5
Training loss: 8.25323486328125
Validation loss: 7.7512502465196835

Epoch: 6| Step: 6
Training loss: 7.824496269226074
Validation loss: 7.74266731098134

Epoch: 6| Step: 7
Training loss: 7.683948040008545
Validation loss: 7.731657674235683

Epoch: 6| Step: 8
Training loss: 7.487403869628906
Validation loss: 7.723511818916567

Epoch: 6| Step: 9
Training loss: 8.297062873840332
Validation loss: 7.714164190394904

Epoch: 6| Step: 10
Training loss: 5.746655464172363
Validation loss: 7.700770634476856

Epoch: 6| Step: 11
Training loss: 7.672345161437988
Validation loss: 7.691257322988203

Epoch: 6| Step: 12
Training loss: 8.877472877502441
Validation loss: 7.683975881145846

Epoch: 6| Step: 13
Training loss: 8.264824867248535
Validation loss: 7.669502073718656

Epoch: 7| Step: 0
Training loss: 7.673298358917236
Validation loss: 7.660633446067892

Epoch: 6| Step: 1
Training loss: 7.739690780639648
Validation loss: 7.653956028722948

Epoch: 6| Step: 2
Training loss: 6.869405746459961
Validation loss: 7.6427878205494215

Epoch: 6| Step: 3
Training loss: 8.332857131958008
Validation loss: 7.63189172744751

Epoch: 6| Step: 4
Training loss: 7.454848289489746
Validation loss: 7.620073677391134

Epoch: 6| Step: 5
Training loss: 7.492168426513672
Validation loss: 7.6098262776610675

Epoch: 6| Step: 6
Training loss: 7.874788284301758
Validation loss: 7.602093440230175

Epoch: 6| Step: 7
Training loss: 7.526340007781982
Validation loss: 7.588745229987688

Epoch: 6| Step: 8
Training loss: 7.2999348640441895
Validation loss: 7.578759747166788

Epoch: 6| Step: 9
Training loss: 6.852960586547852
Validation loss: 7.566000282123524

Epoch: 6| Step: 10
Training loss: 6.365297317504883
Validation loss: 7.556951558718118

Epoch: 6| Step: 11
Training loss: 6.490499973297119
Validation loss: 7.54766022774481

Epoch: 6| Step: 12
Training loss: 7.741230487823486
Validation loss: 7.5323343584614415

Epoch: 6| Step: 13
Training loss: 7.641571044921875
Validation loss: 7.523681225315217

Epoch: 8| Step: 0
Training loss: 6.189245223999023
Validation loss: 7.513511647460281

Epoch: 6| Step: 1
Training loss: 6.333353042602539
Validation loss: 7.499506109504289

Epoch: 6| Step: 2
Training loss: 5.392012119293213
Validation loss: 7.488502553714219

Epoch: 6| Step: 3
Training loss: 6.861734867095947
Validation loss: 7.481892842118458

Epoch: 6| Step: 4
Training loss: 7.882082939147949
Validation loss: 7.472409115042738

Epoch: 6| Step: 5
Training loss: 7.27316951751709
Validation loss: 7.456906851901803

Epoch: 6| Step: 6
Training loss: 6.700321197509766
Validation loss: 7.446526860678068

Epoch: 6| Step: 7
Training loss: 8.865821838378906
Validation loss: 7.433016120746571

Epoch: 6| Step: 8
Training loss: 7.165631294250488
Validation loss: 7.418082201352683

Epoch: 6| Step: 9
Training loss: 8.970548629760742
Validation loss: 7.408538623522687

Epoch: 6| Step: 10
Training loss: 7.463517189025879
Validation loss: 7.390007280534314

Epoch: 6| Step: 11
Training loss: 8.155328750610352
Validation loss: 7.38173460191296

Epoch: 6| Step: 12
Training loss: 6.709632873535156
Validation loss: 7.366738191214941

Epoch: 6| Step: 13
Training loss: 6.7750244140625
Validation loss: 7.356654582485076

Epoch: 9| Step: 0
Training loss: 7.071840286254883
Validation loss: 7.343208553970501

Epoch: 6| Step: 1
Training loss: 7.610491752624512
Validation loss: 7.329010768603253

Epoch: 6| Step: 2
Training loss: 7.938748359680176
Validation loss: 7.318051558668896

Epoch: 6| Step: 3
Training loss: 7.989989280700684
Validation loss: 7.305648137164372

Epoch: 6| Step: 4
Training loss: 7.785010814666748
Validation loss: 7.28994405910533

Epoch: 6| Step: 5
Training loss: 6.703825950622559
Validation loss: 7.277922425218808

Epoch: 6| Step: 6
Training loss: 6.654062747955322
Validation loss: 7.261950318531324

Epoch: 6| Step: 7
Training loss: 6.244701862335205
Validation loss: 7.245810816364903

Epoch: 6| Step: 8
Training loss: 7.813937664031982
Validation loss: 7.237479568809591

Epoch: 6| Step: 9
Training loss: 7.402493953704834
Validation loss: 7.22034671742429

Epoch: 6| Step: 10
Training loss: 7.357607364654541
Validation loss: 7.202880228719404

Epoch: 6| Step: 11
Training loss: 5.8363871574401855
Validation loss: 7.192235362145208

Epoch: 6| Step: 12
Training loss: 5.750603199005127
Validation loss: 7.17843767391738

Epoch: 6| Step: 13
Training loss: 5.463951587677002
Validation loss: 7.1636878546848095

Epoch: 10| Step: 0
Training loss: 6.072568893432617
Validation loss: 7.145632836126512

Epoch: 6| Step: 1
Training loss: 6.803500175476074
Validation loss: 7.131566324541645

Epoch: 6| Step: 2
Training loss: 6.009990692138672
Validation loss: 7.114584712571995

Epoch: 6| Step: 3
Training loss: 7.637433052062988
Validation loss: 7.1020884411309355

Epoch: 6| Step: 4
Training loss: 7.331010818481445
Validation loss: 7.087833789087111

Epoch: 6| Step: 5
Training loss: 7.534502983093262
Validation loss: 7.069678634725591

Epoch: 6| Step: 6
Training loss: 7.870256423950195
Validation loss: 7.0556328783753095

Epoch: 6| Step: 7
Training loss: 6.635687828063965
Validation loss: 7.036226734038322

Epoch: 6| Step: 8
Training loss: 7.074934482574463
Validation loss: 7.026788460311069

Epoch: 6| Step: 9
Training loss: 6.216444969177246
Validation loss: 7.0033715360908095

Epoch: 6| Step: 10
Training loss: 6.232532024383545
Validation loss: 6.989605801079863

Epoch: 6| Step: 11
Training loss: 6.999179840087891
Validation loss: 6.9676500853671826

Epoch: 6| Step: 12
Training loss: 6.524707794189453
Validation loss: 6.955572425678212

Epoch: 6| Step: 13
Training loss: 6.035971164703369
Validation loss: 6.93402281115132

Epoch: 11| Step: 0
Training loss: 6.550714492797852
Validation loss: 6.9143595490404355

Epoch: 6| Step: 1
Training loss: 6.443221569061279
Validation loss: 6.897579141842422

Epoch: 6| Step: 2
Training loss: 7.864358901977539
Validation loss: 6.882705785894907

Epoch: 6| Step: 3
Training loss: 7.201046943664551
Validation loss: 6.866649581540015

Epoch: 6| Step: 4
Training loss: 5.516539573669434
Validation loss: 6.846371937823552

Epoch: 6| Step: 5
Training loss: 6.719799041748047
Validation loss: 6.822971072248233

Epoch: 6| Step: 6
Training loss: 5.548951148986816
Validation loss: 6.809153408132573

Epoch: 6| Step: 7
Training loss: 6.405919551849365
Validation loss: 6.786611582643243

Epoch: 6| Step: 8
Training loss: 7.042321681976318
Validation loss: 6.768110393196024

Epoch: 6| Step: 9
Training loss: 7.548809051513672
Validation loss: 6.747883878728395

Epoch: 6| Step: 10
Training loss: 6.674046516418457
Validation loss: 6.731680413728119

Epoch: 6| Step: 11
Training loss: 6.033940315246582
Validation loss: 6.709397362124536

Epoch: 6| Step: 12
Training loss: 6.335004806518555
Validation loss: 6.689659682653284

Epoch: 6| Step: 13
Training loss: 5.335427284240723
Validation loss: 6.667827124236732

Epoch: 12| Step: 0
Training loss: 5.981837749481201
Validation loss: 6.6536120906952885

Epoch: 6| Step: 1
Training loss: 5.70560359954834
Validation loss: 6.630098250604445

Epoch: 6| Step: 2
Training loss: 6.00626277923584
Validation loss: 6.612063254079511

Epoch: 6| Step: 3
Training loss: 6.422812461853027
Validation loss: 6.588759694048154

Epoch: 6| Step: 4
Training loss: 8.364912033081055
Validation loss: 6.564371734537104

Epoch: 6| Step: 5
Training loss: 6.8795928955078125
Validation loss: 6.552243581382177

Epoch: 6| Step: 6
Training loss: 6.539371013641357
Validation loss: 6.526095928684358

Epoch: 6| Step: 7
Training loss: 5.892955780029297
Validation loss: 6.496183728659025

Epoch: 6| Step: 8
Training loss: 6.114103317260742
Validation loss: 6.481410282914356

Epoch: 6| Step: 9
Training loss: 5.310080051422119
Validation loss: 6.459103999599334

Epoch: 6| Step: 10
Training loss: 5.573739051818848
Validation loss: 6.435579535781696

Epoch: 6| Step: 11
Training loss: 5.29763126373291
Validation loss: 6.412582664079563

Epoch: 6| Step: 12
Training loss: 6.822031021118164
Validation loss: 6.389916584055911

Epoch: 6| Step: 13
Training loss: 7.0441718101501465
Validation loss: 6.363302035998273

Epoch: 13| Step: 0
Training loss: 6.106610298156738
Validation loss: 6.335333157611149

Epoch: 6| Step: 1
Training loss: 5.16011905670166
Validation loss: 6.320459570935977

Epoch: 6| Step: 2
Training loss: 6.625714302062988
Validation loss: 6.297209560230214

Epoch: 6| Step: 3
Training loss: 5.674227714538574
Validation loss: 6.268523575157247

Epoch: 6| Step: 4
Training loss: 6.184871673583984
Validation loss: 6.241735453246742

Epoch: 6| Step: 5
Training loss: 7.081214904785156
Validation loss: 6.219674336012973

Epoch: 6| Step: 6
Training loss: 6.489387512207031
Validation loss: 6.191394093216107

Epoch: 6| Step: 7
Training loss: 4.752993106842041
Validation loss: 6.164771264599215

Epoch: 6| Step: 8
Training loss: 5.7073469161987305
Validation loss: 6.141126566035773

Epoch: 6| Step: 9
Training loss: 5.115783214569092
Validation loss: 6.1177574998588975

Epoch: 6| Step: 10
Training loss: 6.5943779945373535
Validation loss: 6.088833562789425

Epoch: 6| Step: 11
Training loss: 5.656942844390869
Validation loss: 6.061081491490846

Epoch: 6| Step: 12
Training loss: 5.392487049102783
Validation loss: 6.028179266119516

Epoch: 6| Step: 13
Training loss: 6.518617630004883
Validation loss: 6.006477919957971

Epoch: 14| Step: 0
Training loss: 6.148252010345459
Validation loss: 5.97268174284248

Epoch: 6| Step: 1
Training loss: 6.360185623168945
Validation loss: 5.957259465289372

Epoch: 6| Step: 2
Training loss: 3.9506099224090576
Validation loss: 5.9120709050086235

Epoch: 6| Step: 3
Training loss: 5.322721481323242
Validation loss: 5.892794926961263

Epoch: 6| Step: 4
Training loss: 5.742361545562744
Validation loss: 5.862277261672482

Epoch: 6| Step: 5
Training loss: 4.747618675231934
Validation loss: 5.83150589337913

Epoch: 6| Step: 6
Training loss: 5.070812225341797
Validation loss: 5.798098471856886

Epoch: 6| Step: 7
Training loss: 5.451902389526367
Validation loss: 5.777941385904948

Epoch: 6| Step: 8
Training loss: 6.757941246032715
Validation loss: 5.7348699005701205

Epoch: 6| Step: 9
Training loss: 5.944816589355469
Validation loss: 5.708393655797487

Epoch: 6| Step: 10
Training loss: 4.867834091186523
Validation loss: 5.682482709166824

Epoch: 6| Step: 11
Training loss: 5.380091190338135
Validation loss: 5.646543492553055

Epoch: 6| Step: 12
Training loss: 5.8392157554626465
Validation loss: 5.618637269543063

Epoch: 6| Step: 13
Training loss: 5.667862415313721
Validation loss: 5.583642790394444

Epoch: 15| Step: 0
Training loss: 5.204322814941406
Validation loss: 5.558001682322512

Epoch: 6| Step: 1
Training loss: 4.798880577087402
Validation loss: 5.5274166958306425

Epoch: 6| Step: 2
Training loss: 5.318545341491699
Validation loss: 5.489641717685166

Epoch: 6| Step: 3
Training loss: 4.810912132263184
Validation loss: 5.452864364911151

Epoch: 6| Step: 4
Training loss: 5.660306930541992
Validation loss: 5.428092900142874

Epoch: 6| Step: 5
Training loss: 5.581239223480225
Validation loss: 5.378039565137637

Epoch: 6| Step: 6
Training loss: 5.330413341522217
Validation loss: 5.353209223798526

Epoch: 6| Step: 7
Training loss: 3.416201591491699
Validation loss: 5.300492373845911

Epoch: 6| Step: 8
Training loss: 4.786248207092285
Validation loss: 5.273700806402391

Epoch: 6| Step: 9
Training loss: 3.986056327819824
Validation loss: 5.237482757978542

Epoch: 6| Step: 10
Training loss: 5.438717842102051
Validation loss: 5.196759080374113

Epoch: 6| Step: 11
Training loss: 5.111767292022705
Validation loss: 5.1527428524468535

Epoch: 6| Step: 12
Training loss: 5.707963943481445
Validation loss: 5.12469490625525

Epoch: 6| Step: 13
Training loss: 5.966878414154053
Validation loss: 5.0835372555640435

Epoch: 16| Step: 0
Training loss: 5.297748565673828
Validation loss: 5.055231473779165

Epoch: 6| Step: 1
Training loss: 3.8908777236938477
Validation loss: 5.006580711692892

Epoch: 6| Step: 2
Training loss: 5.164874076843262
Validation loss: 4.978110426215715

Epoch: 6| Step: 3
Training loss: 4.279993057250977
Validation loss: 4.946857231919483

Epoch: 6| Step: 4
Training loss: 5.11916446685791
Validation loss: 4.89063221921203

Epoch: 6| Step: 5
Training loss: 4.157100677490234
Validation loss: 4.873082381422802

Epoch: 6| Step: 6
Training loss: 5.006772994995117
Validation loss: 4.824953453515166

Epoch: 6| Step: 7
Training loss: 3.5600242614746094
Validation loss: 4.770362413057717

Epoch: 6| Step: 8
Training loss: 3.8569726943969727
Validation loss: 4.744721720295567

Epoch: 6| Step: 9
Training loss: 4.02506160736084
Validation loss: 4.710883463582685

Epoch: 6| Step: 10
Training loss: 5.7340474128723145
Validation loss: 4.651877526314028

Epoch: 6| Step: 11
Training loss: 4.841119766235352
Validation loss: 4.626790082582864

Epoch: 6| Step: 12
Training loss: 4.087211608886719
Validation loss: 4.592810897416966

Epoch: 6| Step: 13
Training loss: 4.707579135894775
Validation loss: 4.551928356129636

Epoch: 17| Step: 0
Training loss: 3.9112837314605713
Validation loss: 4.508965492248535

Epoch: 6| Step: 1
Training loss: 3.9751336574554443
Validation loss: 4.479758816380655

Epoch: 6| Step: 2
Training loss: 5.169351100921631
Validation loss: 4.430215004951723

Epoch: 6| Step: 3
Training loss: 3.502781391143799
Validation loss: 4.404903176010296

Epoch: 6| Step: 4
Training loss: 3.828275203704834
Validation loss: 4.386795797655659

Epoch: 6| Step: 5
Training loss: 5.474733352661133
Validation loss: 4.340069278593986

Epoch: 6| Step: 6
Training loss: 3.049530506134033
Validation loss: 4.296454911590905

Epoch: 6| Step: 7
Training loss: 4.549548149108887
Validation loss: 4.254069958963702

Epoch: 6| Step: 8
Training loss: 4.082064151763916
Validation loss: 4.202899394496795

Epoch: 6| Step: 9
Training loss: 4.251864433288574
Validation loss: 4.158823623452135

Epoch: 6| Step: 10
Training loss: 4.032357215881348
Validation loss: 4.122475108792705

Epoch: 6| Step: 11
Training loss: 3.531987190246582
Validation loss: 4.093954383686024

Epoch: 6| Step: 12
Training loss: 3.022333860397339
Validation loss: 4.043247535664548

Epoch: 6| Step: 13
Training loss: 3.447850227355957
Validation loss: 4.005902182671331

Epoch: 18| Step: 0
Training loss: 4.302180290222168
Validation loss: 3.962809439628355

Epoch: 6| Step: 1
Training loss: 3.9229888916015625
Validation loss: 3.934413433074951

Epoch: 6| Step: 2
Training loss: 3.3340041637420654
Validation loss: 3.870738962645172

Epoch: 6| Step: 3
Training loss: 3.073812961578369
Validation loss: 3.861077836764756

Epoch: 6| Step: 4
Training loss: 3.6259450912475586
Validation loss: 3.7923527943190707

Epoch: 6| Step: 5
Training loss: 2.9537172317504883
Validation loss: 3.7676989032376196

Epoch: 6| Step: 6
Training loss: 2.8024380207061768
Validation loss: 3.710665656674293

Epoch: 6| Step: 7
Training loss: 4.303124904632568
Validation loss: 3.7014773840545327

Epoch: 6| Step: 8
Training loss: 3.12416410446167
Validation loss: 3.648550469388244

Epoch: 6| Step: 9
Training loss: 3.1866414546966553
Validation loss: 3.6320042276895173

Epoch: 6| Step: 10
Training loss: 3.3714771270751953
Validation loss: 3.5820400176509732

Epoch: 6| Step: 11
Training loss: 3.0142288208007812
Validation loss: 3.5692364605524207

Epoch: 6| Step: 12
Training loss: 4.774044990539551
Validation loss: 3.5303055470989597

Epoch: 6| Step: 13
Training loss: 2.6222105026245117
Validation loss: 3.4727651919088056

Epoch: 19| Step: 0
Training loss: 3.465601921081543
Validation loss: 3.4598761168859338

Epoch: 6| Step: 1
Training loss: 2.850377321243286
Validation loss: 3.435085222285281

Epoch: 6| Step: 2
Training loss: 3.2797951698303223
Validation loss: 3.4166804205986763

Epoch: 6| Step: 3
Training loss: 3.2486724853515625
Validation loss: 3.3469864219747563

Epoch: 6| Step: 4
Training loss: 3.3474748134613037
Validation loss: 3.3278802569194506

Epoch: 6| Step: 5
Training loss: 3.186652660369873
Validation loss: 3.299527314401442

Epoch: 6| Step: 6
Training loss: 3.6724867820739746
Validation loss: 3.2580145225729993

Epoch: 6| Step: 7
Training loss: 3.2644824981689453
Validation loss: 3.24276686996542

Epoch: 6| Step: 8
Training loss: 3.171781539916992
Validation loss: 3.215807489169541

Epoch: 6| Step: 9
Training loss: 2.467881917953491
Validation loss: 3.1713266193225818

Epoch: 6| Step: 10
Training loss: 2.7809104919433594
Validation loss: 3.1525032340839343

Epoch: 6| Step: 11
Training loss: 3.09433650970459
Validation loss: 3.1360184325966785

Epoch: 6| Step: 12
Training loss: 2.9384889602661133
Validation loss: 3.1016499483457176

Epoch: 6| Step: 13
Training loss: 4.225912570953369
Validation loss: 3.089708064192085

Epoch: 20| Step: 0
Training loss: 3.1014962196350098
Validation loss: 3.0454914441672702

Epoch: 6| Step: 1
Training loss: 3.671326160430908
Validation loss: 3.0343856478250153

Epoch: 6| Step: 2
Training loss: 3.5245325565338135
Validation loss: 2.9890688850033666

Epoch: 6| Step: 3
Training loss: 2.4935784339904785
Validation loss: 2.9840041232365433

Epoch: 6| Step: 4
Training loss: 3.5471010208129883
Validation loss: 2.950199673252721

Epoch: 6| Step: 5
Training loss: 3.584357738494873
Validation loss: 2.927776105942265

Epoch: 6| Step: 6
Training loss: 2.9162039756774902
Validation loss: 2.926620942290111

Epoch: 6| Step: 7
Training loss: 1.863312840461731
Validation loss: 2.855668862660726

Epoch: 6| Step: 8
Training loss: 3.0772910118103027
Validation loss: 2.8409923917503765

Epoch: 6| Step: 9
Training loss: 2.2079174518585205
Validation loss: 2.822405466469385

Epoch: 6| Step: 10
Training loss: 1.9804375171661377
Validation loss: 2.820337741605697

Epoch: 6| Step: 11
Training loss: 2.393263816833496
Validation loss: 2.8052396338473082

Epoch: 6| Step: 12
Training loss: 3.669034957885742
Validation loss: 2.8002044000933246

Epoch: 6| Step: 13
Training loss: 3.29097056388855
Validation loss: 2.770900159753779

Epoch: 21| Step: 0
Training loss: 3.2910733222961426
Validation loss: 2.7483185542527067

Epoch: 6| Step: 1
Training loss: 2.7441816329956055
Validation loss: 2.7428729713604016

Epoch: 6| Step: 2
Training loss: 3.141843318939209
Validation loss: 2.7508671309358332

Epoch: 6| Step: 3
Training loss: 2.081786632537842
Validation loss: 2.7184757468520955

Epoch: 6| Step: 4
Training loss: 2.17343807220459
Validation loss: 2.694054559994769

Epoch: 6| Step: 5
Training loss: 3.286466598510742
Validation loss: 2.68082364912956

Epoch: 6| Step: 6
Training loss: 2.7336485385894775
Validation loss: 2.6887932490277033

Epoch: 6| Step: 7
Training loss: 1.7759572267532349
Validation loss: 2.6792953527101906

Epoch: 6| Step: 8
Training loss: 2.6393582820892334
Validation loss: 2.659521040096078

Epoch: 6| Step: 9
Training loss: 3.4578351974487305
Validation loss: 2.650890682333259

Epoch: 6| Step: 10
Training loss: 2.6861112117767334
Validation loss: 2.6293769369843187

Epoch: 6| Step: 11
Training loss: 2.682337760925293
Validation loss: 2.62110823200595

Epoch: 6| Step: 12
Training loss: 3.18051815032959
Validation loss: 2.6075665899502334

Epoch: 6| Step: 13
Training loss: 2.5048019886016846
Validation loss: 2.607622397843228

Epoch: 22| Step: 0
Training loss: 2.3415627479553223
Validation loss: 2.594529962026945

Epoch: 6| Step: 1
Training loss: 2.372750759124756
Validation loss: 2.5812674850545902

Epoch: 6| Step: 2
Training loss: 2.08681583404541
Validation loss: 2.582946341524842

Epoch: 6| Step: 3
Training loss: 2.582838296890259
Validation loss: 2.5779744322581957

Epoch: 6| Step: 4
Training loss: 2.3034675121307373
Validation loss: 2.549474844368555

Epoch: 6| Step: 5
Training loss: 3.551286458969116
Validation loss: 2.5414571403175272

Epoch: 6| Step: 6
Training loss: 3.0022366046905518
Validation loss: 2.5557290328446256

Epoch: 6| Step: 7
Training loss: 2.225651502609253
Validation loss: 2.5779206137503348

Epoch: 6| Step: 8
Training loss: 2.615138053894043
Validation loss: 2.538144011651316

Epoch: 6| Step: 9
Training loss: 2.897280216217041
Validation loss: 2.525141008438603

Epoch: 6| Step: 10
Training loss: 2.352341651916504
Validation loss: 2.526415358307541

Epoch: 6| Step: 11
Training loss: 2.452609062194824
Validation loss: 2.5346667279479322

Epoch: 6| Step: 12
Training loss: 3.5723836421966553
Validation loss: 2.5086408533075804

Epoch: 6| Step: 13
Training loss: 3.1506001949310303
Validation loss: 2.5120735296639065

Epoch: 23| Step: 0
Training loss: 2.271038055419922
Validation loss: 2.5028557854314006

Epoch: 6| Step: 1
Training loss: 2.734006881713867
Validation loss: 2.495155167836015

Epoch: 6| Step: 2
Training loss: 2.257754325866699
Validation loss: 2.4960679341388006

Epoch: 6| Step: 3
Training loss: 3.028721570968628
Validation loss: 2.5113934265669955

Epoch: 6| Step: 4
Training loss: 2.6266965866088867
Validation loss: 2.5189825565584245

Epoch: 6| Step: 5
Training loss: 2.942734479904175
Validation loss: 2.492830514907837

Epoch: 6| Step: 6
Training loss: 3.040309429168701
Validation loss: 2.507706570368941

Epoch: 6| Step: 7
Training loss: 3.2689547538757324
Validation loss: 2.4953778507888957

Epoch: 6| Step: 8
Training loss: 2.763767719268799
Validation loss: 2.484173487591487

Epoch: 6| Step: 9
Training loss: 2.195554733276367
Validation loss: 2.483041860724008

Epoch: 6| Step: 10
Training loss: 2.060073137283325
Validation loss: 2.490612341511634

Epoch: 6| Step: 11
Training loss: 2.169203519821167
Validation loss: 2.496062973494171

Epoch: 6| Step: 12
Training loss: 3.1262331008911133
Validation loss: 2.4804600182399956

Epoch: 6| Step: 13
Training loss: 2.729381561279297
Validation loss: 2.4947331438782396

Epoch: 24| Step: 0
Training loss: 2.799030303955078
Validation loss: 2.4830522050139723

Epoch: 6| Step: 1
Training loss: 3.2510199546813965
Validation loss: 2.493726158654818

Epoch: 6| Step: 2
Training loss: 2.8433749675750732
Validation loss: 2.471470291896533

Epoch: 6| Step: 3
Training loss: 2.7772634029388428
Validation loss: 2.478912345824703

Epoch: 6| Step: 4
Training loss: 2.6205432415008545
Validation loss: 2.466236563139064

Epoch: 6| Step: 5
Training loss: 2.7024574279785156
Validation loss: 2.4836489513356197

Epoch: 6| Step: 6
Training loss: 2.151667594909668
Validation loss: 2.4736203455155894

Epoch: 6| Step: 7
Training loss: 3.5248498916625977
Validation loss: 2.4714781238186743

Epoch: 6| Step: 8
Training loss: 2.139280319213867
Validation loss: 2.479212725034324

Epoch: 6| Step: 9
Training loss: 1.6109695434570312
Validation loss: 2.4661252075626003

Epoch: 6| Step: 10
Training loss: 2.6589627265930176
Validation loss: 2.4919495967126664

Epoch: 6| Step: 11
Training loss: 2.3146204948425293
Validation loss: 2.478839202593732

Epoch: 6| Step: 12
Training loss: 3.0967254638671875
Validation loss: 2.4561530364457

Epoch: 6| Step: 13
Training loss: 2.068782329559326
Validation loss: 2.4772664603366645

Epoch: 25| Step: 0
Training loss: 2.719074249267578
Validation loss: 2.4614082510753343

Epoch: 6| Step: 1
Training loss: 3.0025925636291504
Validation loss: 2.505753891442412

Epoch: 6| Step: 2
Training loss: 2.8308255672454834
Validation loss: 2.4756022294362388

Epoch: 6| Step: 3
Training loss: 2.1784162521362305
Validation loss: 2.502385511193224

Epoch: 6| Step: 4
Training loss: 3.2646777629852295
Validation loss: 2.499183690676125

Epoch: 6| Step: 5
Training loss: 1.6227173805236816
Validation loss: 2.476168268470354

Epoch: 6| Step: 6
Training loss: 2.4246819019317627
Validation loss: 2.471842881171934

Epoch: 6| Step: 7
Training loss: 2.1367506980895996
Validation loss: 2.500391719161823

Epoch: 6| Step: 8
Training loss: 2.7815372943878174
Validation loss: 2.451478568456506

Epoch: 6| Step: 9
Training loss: 3.060413360595703
Validation loss: 2.464135544274443

Epoch: 6| Step: 10
Training loss: 2.6227619647979736
Validation loss: 2.4562617527541293

Epoch: 6| Step: 11
Training loss: 2.7908809185028076
Validation loss: 2.4865354773818806

Epoch: 6| Step: 12
Training loss: 2.8200631141662598
Validation loss: 2.4736923812538065

Epoch: 6| Step: 13
Training loss: 2.3666086196899414
Validation loss: 2.490910327562722

Epoch: 26| Step: 0
Training loss: 2.592392921447754
Validation loss: 2.4898059419406358

Epoch: 6| Step: 1
Training loss: 3.2248306274414062
Validation loss: 2.4734086503264723

Epoch: 6| Step: 2
Training loss: 2.6941275596618652
Validation loss: 2.472396191730294

Epoch: 6| Step: 3
Training loss: 3.1570956707000732
Validation loss: 2.4674590582488687

Epoch: 6| Step: 4
Training loss: 2.548788547515869
Validation loss: 2.4719763237942933

Epoch: 6| Step: 5
Training loss: 2.462475538253784
Validation loss: 2.4702042969324256

Epoch: 6| Step: 6
Training loss: 2.8476104736328125
Validation loss: 2.456069110542215

Epoch: 6| Step: 7
Training loss: 2.551945209503174
Validation loss: 2.480914802961452

Epoch: 6| Step: 8
Training loss: 1.7372413873672485
Validation loss: 2.4785914831264044

Epoch: 6| Step: 9
Training loss: 2.1189634799957275
Validation loss: 2.461924506771949

Epoch: 6| Step: 10
Training loss: 3.2613396644592285
Validation loss: 2.4859869223768993

Epoch: 6| Step: 11
Training loss: 1.3734290599822998
Validation loss: 2.488621298984815

Epoch: 6| Step: 12
Training loss: 3.327035665512085
Validation loss: 2.4848941679923766

Epoch: 6| Step: 13
Training loss: 3.0169224739074707
Validation loss: 2.458057039527483

Epoch: 27| Step: 0
Training loss: 2.5825507640838623
Validation loss: 2.4738186995188394

Epoch: 6| Step: 1
Training loss: 2.3625831604003906
Validation loss: 2.4674606477060625

Epoch: 6| Step: 2
Training loss: 2.424513101577759
Validation loss: 2.4540619388703377

Epoch: 6| Step: 3
Training loss: 2.9716532230377197
Validation loss: 2.4713059625317975

Epoch: 6| Step: 4
Training loss: 2.889338493347168
Validation loss: 2.4577690145020843

Epoch: 6| Step: 5
Training loss: 2.0989155769348145
Validation loss: 2.457914726708525

Epoch: 6| Step: 6
Training loss: 2.8832006454467773
Validation loss: 2.442558729520408

Epoch: 6| Step: 7
Training loss: 2.1388063430786133
Validation loss: 2.4619073278160504

Epoch: 6| Step: 8
Training loss: 2.7548160552978516
Validation loss: 2.4575283424828642

Epoch: 6| Step: 9
Training loss: 3.189899444580078
Validation loss: 2.4778597072888444

Epoch: 6| Step: 10
Training loss: 2.441307306289673
Validation loss: 2.4610877908686155

Epoch: 6| Step: 11
Training loss: 2.25046968460083
Validation loss: 2.4464847682624735

Epoch: 6| Step: 12
Training loss: 2.5684306621551514
Validation loss: 2.4681263828790314

Epoch: 6| Step: 13
Training loss: 2.9702165126800537
Validation loss: 2.4844560033531597

Epoch: 28| Step: 0
Training loss: 2.9875786304473877
Validation loss: 2.464731098503195

Epoch: 6| Step: 1
Training loss: 2.5711660385131836
Validation loss: 2.4654332284004457

Epoch: 6| Step: 2
Training loss: 2.2345614433288574
Validation loss: 2.459781026327482

Epoch: 6| Step: 3
Training loss: 2.3024463653564453
Validation loss: 2.444653844320646

Epoch: 6| Step: 4
Training loss: 3.2763266563415527
Validation loss: 2.4309562278050247

Epoch: 6| Step: 5
Training loss: 2.546455144882202
Validation loss: 2.448021255513673

Epoch: 6| Step: 6
Training loss: 2.624587059020996
Validation loss: 2.4352464932267384

Epoch: 6| Step: 7
Training loss: 1.8442661762237549
Validation loss: 2.4214337538647395

Epoch: 6| Step: 8
Training loss: 3.330839157104492
Validation loss: 2.4244249841218353

Epoch: 6| Step: 9
Training loss: 2.19459867477417
Validation loss: 2.426935621487197

Epoch: 6| Step: 10
Training loss: 1.8759140968322754
Validation loss: 2.4327048088914607

Epoch: 6| Step: 11
Training loss: 2.910101890563965
Validation loss: 2.435373362674508

Epoch: 6| Step: 12
Training loss: 2.9394140243530273
Validation loss: 2.46031197937586

Epoch: 6| Step: 13
Training loss: 3.0122878551483154
Validation loss: 2.44222677651272

Epoch: 29| Step: 0
Training loss: 2.5461935997009277
Validation loss: 2.4613646153480775

Epoch: 6| Step: 1
Training loss: 3.327479362487793
Validation loss: 2.453591041667487

Epoch: 6| Step: 2
Training loss: 1.9892139434814453
Validation loss: 2.457948161709693

Epoch: 6| Step: 3
Training loss: 2.6480326652526855
Validation loss: 2.436358844080279

Epoch: 6| Step: 4
Training loss: 2.569108009338379
Validation loss: 2.4535542457334456

Epoch: 6| Step: 5
Training loss: 2.835021495819092
Validation loss: 2.4551711146549513

Epoch: 6| Step: 6
Training loss: 2.606804847717285
Validation loss: 2.4522173891785326

Epoch: 6| Step: 7
Training loss: 2.3898751735687256
Validation loss: 2.4485668008045485

Epoch: 6| Step: 8
Training loss: 2.539590835571289
Validation loss: 2.417564671526673

Epoch: 6| Step: 9
Training loss: 2.665956497192383
Validation loss: 2.4204164551150416

Epoch: 6| Step: 10
Training loss: 2.9566292762756348
Validation loss: 2.4442354914962605

Epoch: 6| Step: 11
Training loss: 2.512012004852295
Validation loss: 2.4107046896411526

Epoch: 6| Step: 12
Training loss: 2.3509950637817383
Validation loss: 2.405913814421623

Epoch: 6| Step: 13
Training loss: 1.885591983795166
Validation loss: 2.439970326680009

Epoch: 30| Step: 0
Training loss: 2.37506103515625
Validation loss: 2.4456281687623713

Epoch: 6| Step: 1
Training loss: 2.8144116401672363
Validation loss: 2.4186311844856507

Epoch: 6| Step: 2
Training loss: 2.1968817710876465
Validation loss: 2.4591218399745163

Epoch: 6| Step: 3
Training loss: 2.802089214324951
Validation loss: 2.446678615385486

Epoch: 6| Step: 4
Training loss: 2.2570583820343018
Validation loss: 2.438811720058482

Epoch: 6| Step: 5
Training loss: 3.656481981277466
Validation loss: 2.435065702725482

Epoch: 6| Step: 6
Training loss: 2.974132537841797
Validation loss: 2.426925047751396

Epoch: 6| Step: 7
Training loss: 2.534860610961914
Validation loss: 2.448897951392717

Epoch: 6| Step: 8
Training loss: 2.4464058876037598
Validation loss: 2.436093612383771

Epoch: 6| Step: 9
Training loss: 3.083832263946533
Validation loss: 2.431171686418595

Epoch: 6| Step: 10
Training loss: 2.0058865547180176
Validation loss: 2.4635238006550777

Epoch: 6| Step: 11
Training loss: 2.6003475189208984
Validation loss: 2.4576467339710524

Epoch: 6| Step: 12
Training loss: 2.448657512664795
Validation loss: 2.4436579852975826

Epoch: 6| Step: 13
Training loss: 1.6537299156188965
Validation loss: 2.431091723903533

Epoch: 31| Step: 0
Training loss: 2.440049648284912
Validation loss: 2.414905032803935

Epoch: 6| Step: 1
Training loss: 2.276109218597412
Validation loss: 2.445554651239867

Epoch: 6| Step: 2
Training loss: 2.2807531356811523
Validation loss: 2.423317350367064

Epoch: 6| Step: 3
Training loss: 2.416912078857422
Validation loss: 2.4368646990868355

Epoch: 6| Step: 4
Training loss: 2.3376598358154297
Validation loss: 2.453327945483628

Epoch: 6| Step: 5
Training loss: 2.083077907562256
Validation loss: 2.4156831361914195

Epoch: 6| Step: 6
Training loss: 3.5006747245788574
Validation loss: 2.432536745584139

Epoch: 6| Step: 7
Training loss: 2.863466739654541
Validation loss: 2.4123137689405874

Epoch: 6| Step: 8
Training loss: 2.407421588897705
Validation loss: 2.4194110439669703

Epoch: 6| Step: 9
Training loss: 2.6195013523101807
Validation loss: 2.427390939445906

Epoch: 6| Step: 10
Training loss: 3.138291835784912
Validation loss: 2.4361212253570557

Epoch: 6| Step: 11
Training loss: 2.508392810821533
Validation loss: 2.426281299642337

Epoch: 6| Step: 12
Training loss: 2.660126209259033
Validation loss: 2.4096633849605436

Epoch: 6| Step: 13
Training loss: 2.664065361022949
Validation loss: 2.4110958576202393

Epoch: 32| Step: 0
Training loss: 2.4622011184692383
Validation loss: 2.4018860401645785

Epoch: 6| Step: 1
Training loss: 2.454740047454834
Validation loss: 2.4036466485710553

Epoch: 6| Step: 2
Training loss: 3.484970808029175
Validation loss: 2.4057043085816088

Epoch: 6| Step: 3
Training loss: 2.1832075119018555
Validation loss: 2.4149009053425123

Epoch: 6| Step: 4
Training loss: 2.991565704345703
Validation loss: 2.416812437836842

Epoch: 6| Step: 5
Training loss: 2.0341339111328125
Validation loss: 2.414735806885586

Epoch: 6| Step: 6
Training loss: 2.307210683822632
Validation loss: 2.414759205233666

Epoch: 6| Step: 7
Training loss: 2.1260998249053955
Validation loss: 2.381189061749366

Epoch: 6| Step: 8
Training loss: 2.2317261695861816
Validation loss: 2.433531589405511

Epoch: 6| Step: 9
Training loss: 3.2915005683898926
Validation loss: 2.404871209975212

Epoch: 6| Step: 10
Training loss: 2.8365557193756104
Validation loss: 2.38772556858678

Epoch: 6| Step: 11
Training loss: 2.7316770553588867
Validation loss: 2.386938178411094

Epoch: 6| Step: 12
Training loss: 2.6656241416931152
Validation loss: 2.377225399017334

Epoch: 6| Step: 13
Training loss: 1.5064804553985596
Validation loss: 2.3962825934092202

Epoch: 33| Step: 0
Training loss: 2.6639533042907715
Validation loss: 2.386250562565301

Epoch: 6| Step: 1
Training loss: 1.9341871738433838
Validation loss: 2.407174233467348

Epoch: 6| Step: 2
Training loss: 2.7962684631347656
Validation loss: 2.37411468772478

Epoch: 6| Step: 3
Training loss: 1.7895901203155518
Validation loss: 2.425291317765431

Epoch: 6| Step: 4
Training loss: 1.9837713241577148
Validation loss: 2.40034758147373

Epoch: 6| Step: 5
Training loss: 2.6719183921813965
Validation loss: 2.3989496282351914

Epoch: 6| Step: 6
Training loss: 2.4563181400299072
Validation loss: 2.379742906939599

Epoch: 6| Step: 7
Training loss: 2.8205907344818115
Validation loss: 2.4165218517344487

Epoch: 6| Step: 8
Training loss: 2.169552803039551
Validation loss: 2.3889678473113687

Epoch: 6| Step: 9
Training loss: 2.5338199138641357
Validation loss: 2.37828924322641

Epoch: 6| Step: 10
Training loss: 2.8440046310424805
Validation loss: 2.404501256122384

Epoch: 6| Step: 11
Training loss: 3.2095234394073486
Validation loss: 2.397073484236194

Epoch: 6| Step: 12
Training loss: 3.1609585285186768
Validation loss: 2.379791257201984

Epoch: 6| Step: 13
Training loss: 2.756650686264038
Validation loss: 2.3659120016200568

Epoch: 34| Step: 0
Training loss: 2.729107141494751
Validation loss: 2.366586644162414

Epoch: 6| Step: 1
Training loss: 3.175159215927124
Validation loss: 2.3930845414438555

Epoch: 6| Step: 2
Training loss: 2.551344394683838
Validation loss: 2.4012012891871954

Epoch: 6| Step: 3
Training loss: 2.53306245803833
Validation loss: 2.3772225559398694

Epoch: 6| Step: 4
Training loss: 1.9356229305267334
Validation loss: 2.4200738809442006

Epoch: 6| Step: 5
Training loss: 1.9459123611450195
Validation loss: 2.3990413552971295

Epoch: 6| Step: 6
Training loss: 2.3975653648376465
Validation loss: 2.3850714852732997

Epoch: 6| Step: 7
Training loss: 2.0943455696105957
Validation loss: 2.3835475624248548

Epoch: 6| Step: 8
Training loss: 2.589944839477539
Validation loss: 2.4080352988294376

Epoch: 6| Step: 9
Training loss: 2.408883571624756
Validation loss: 2.363804324980705

Epoch: 6| Step: 10
Training loss: 3.063081979751587
Validation loss: 2.3852168744610203

Epoch: 6| Step: 11
Training loss: 2.4589834213256836
Validation loss: 2.3882033901829876

Epoch: 6| Step: 12
Training loss: 2.9024314880371094
Validation loss: 2.3909644619111092

Epoch: 6| Step: 13
Training loss: 2.8254785537719727
Validation loss: 2.3933330146215295

Epoch: 35| Step: 0
Training loss: 2.0458998680114746
Validation loss: 2.36517321935264

Epoch: 6| Step: 1
Training loss: 3.2305703163146973
Validation loss: 2.3756992945107083

Epoch: 6| Step: 2
Training loss: 2.4468281269073486
Validation loss: 2.3670641581217446

Epoch: 6| Step: 3
Training loss: 2.1696252822875977
Validation loss: 2.3873317985124487

Epoch: 6| Step: 4
Training loss: 2.453209638595581
Validation loss: 2.379286463542651

Epoch: 6| Step: 5
Training loss: 2.9118776321411133
Validation loss: 2.3864864200674076

Epoch: 6| Step: 6
Training loss: 2.584127426147461
Validation loss: 2.3809892003254225

Epoch: 6| Step: 7
Training loss: 2.322239875793457
Validation loss: 2.3612984354778

Epoch: 6| Step: 8
Training loss: 2.7272372245788574
Validation loss: 2.353685414919289

Epoch: 6| Step: 9
Training loss: 1.4023346900939941
Validation loss: 2.344166972303903

Epoch: 6| Step: 10
Training loss: 3.166745901107788
Validation loss: 2.3449613176366335

Epoch: 6| Step: 11
Training loss: 1.7817978858947754
Validation loss: 2.3745606176314817

Epoch: 6| Step: 12
Training loss: 2.9242398738861084
Validation loss: 2.367696767212242

Epoch: 6| Step: 13
Training loss: 3.691561698913574
Validation loss: 2.340464484307074

Epoch: 36| Step: 0
Training loss: 3.1939291954040527
Validation loss: 2.3579388844069613

Epoch: 6| Step: 1
Training loss: 2.675474166870117
Validation loss: 2.3728710938525457

Epoch: 6| Step: 2
Training loss: 1.8648953437805176
Validation loss: 2.390533918975502

Epoch: 6| Step: 3
Training loss: 2.4012413024902344
Validation loss: 2.3650173089837514

Epoch: 6| Step: 4
Training loss: 2.1919708251953125
Validation loss: 2.362941283051686

Epoch: 6| Step: 5
Training loss: 2.2335805892944336
Validation loss: 2.3745361912635063

Epoch: 6| Step: 6
Training loss: 2.57275390625
Validation loss: 2.3719458067288963

Epoch: 6| Step: 7
Training loss: 2.679151773452759
Validation loss: 2.374997615814209

Epoch: 6| Step: 8
Training loss: 2.2006382942199707
Validation loss: 2.382405370794317

Epoch: 6| Step: 9
Training loss: 2.3854780197143555
Validation loss: 2.3627663863602506

Epoch: 6| Step: 10
Training loss: 2.7450718879699707
Validation loss: 2.37932058816315

Epoch: 6| Step: 11
Training loss: 2.738450050354004
Validation loss: 2.341827560496587

Epoch: 6| Step: 12
Training loss: 2.7297327518463135
Validation loss: 2.368842714576311

Epoch: 6| Step: 13
Training loss: 2.7593584060668945
Validation loss: 2.3706552597784225

Epoch: 37| Step: 0
Training loss: 2.172542095184326
Validation loss: 2.3603616965714322

Epoch: 6| Step: 1
Training loss: 2.761077404022217
Validation loss: 2.3914667534571823

Epoch: 6| Step: 2
Training loss: 2.4368414878845215
Validation loss: 2.3627602695136942

Epoch: 6| Step: 3
Training loss: 2.3155622482299805
Validation loss: 2.3519935877092424

Epoch: 6| Step: 4
Training loss: 2.12235164642334
Validation loss: 2.346946441999046

Epoch: 6| Step: 5
Training loss: 2.4041872024536133
Validation loss: 2.3304602612731276

Epoch: 6| Step: 6
Training loss: 2.875509262084961
Validation loss: 2.364482072091872

Epoch: 6| Step: 7
Training loss: 2.300112724304199
Validation loss: 2.332851376584781

Epoch: 6| Step: 8
Training loss: 3.1330976486206055
Validation loss: 2.367504714637674

Epoch: 6| Step: 9
Training loss: 2.3273608684539795
Validation loss: 2.3600221077601113

Epoch: 6| Step: 10
Training loss: 2.3131604194641113
Validation loss: 2.3275926574583976

Epoch: 6| Step: 11
Training loss: 2.7417855262756348
Validation loss: 2.3480260577253116

Epoch: 6| Step: 12
Training loss: 2.546154022216797
Validation loss: 2.3381173379959597

Epoch: 6| Step: 13
Training loss: 2.490051507949829
Validation loss: 2.336122710217712

Epoch: 38| Step: 0
Training loss: 2.39683198928833
Validation loss: 2.347988966972597

Epoch: 6| Step: 1
Training loss: 2.5110316276550293
Validation loss: 2.347952781185027

Epoch: 6| Step: 2
Training loss: 2.387159585952759
Validation loss: 2.350049718733757

Epoch: 6| Step: 3
Training loss: 3.2369351387023926
Validation loss: 2.3360511077347623

Epoch: 6| Step: 4
Training loss: 2.3653411865234375
Validation loss: 2.328509812713951

Epoch: 6| Step: 5
Training loss: 2.328169345855713
Validation loss: 2.316203127625168

Epoch: 6| Step: 6
Training loss: 2.471806049346924
Validation loss: 2.343259798583164

Epoch: 6| Step: 7
Training loss: 1.6961658000946045
Validation loss: 2.3565545902457288

Epoch: 6| Step: 8
Training loss: 2.9545164108276367
Validation loss: 2.3502376797378703

Epoch: 6| Step: 9
Training loss: 2.3424673080444336
Validation loss: 2.342195354482179

Epoch: 6| Step: 10
Training loss: 3.0835978984832764
Validation loss: 2.373029544789304

Epoch: 6| Step: 11
Training loss: 2.8131792545318604
Validation loss: 2.3282069262637886

Epoch: 6| Step: 12
Training loss: 2.280651330947876
Validation loss: 2.357966282034433

Epoch: 6| Step: 13
Training loss: 1.7983390092849731
Validation loss: 2.3475798637636247

Epoch: 39| Step: 0
Training loss: 2.3311760425567627
Validation loss: 2.338078598822317

Epoch: 6| Step: 1
Training loss: 2.7374472618103027
Validation loss: 2.332544454964258

Epoch: 6| Step: 2
Training loss: 3.414341449737549
Validation loss: 2.364090311911798

Epoch: 6| Step: 3
Training loss: 1.5712952613830566
Validation loss: 2.336596401788855

Epoch: 6| Step: 4
Training loss: 2.5706000328063965
Validation loss: 2.3199837720522316

Epoch: 6| Step: 5
Training loss: 3.0154361724853516
Validation loss: 2.331254715560585

Epoch: 6| Step: 6
Training loss: 2.2900919914245605
Validation loss: 2.3646947619735554

Epoch: 6| Step: 7
Training loss: 2.1052191257476807
Validation loss: 2.3216213692900953

Epoch: 6| Step: 8
Training loss: 2.8234591484069824
Validation loss: 2.3132154275012273

Epoch: 6| Step: 9
Training loss: 1.5430927276611328
Validation loss: 2.3170293402928177

Epoch: 6| Step: 10
Training loss: 2.644257068634033
Validation loss: 2.338471669022755

Epoch: 6| Step: 11
Training loss: 2.615283489227295
Validation loss: 2.331269012984409

Epoch: 6| Step: 12
Training loss: 2.5213747024536133
Validation loss: 2.307012656683563

Epoch: 6| Step: 13
Training loss: 2.456329345703125
Validation loss: 2.3283689611701557

Epoch: 40| Step: 0
Training loss: 1.4455249309539795
Validation loss: 2.319582716111214

Epoch: 6| Step: 1
Training loss: 2.650261878967285
Validation loss: 2.3442439443321637

Epoch: 6| Step: 2
Training loss: 2.01350736618042
Validation loss: 2.3150822411301317

Epoch: 6| Step: 3
Training loss: 1.7005176544189453
Validation loss: 2.3265536421088764

Epoch: 6| Step: 4
Training loss: 3.0097084045410156
Validation loss: 2.3323248509437806

Epoch: 6| Step: 5
Training loss: 2.6352171897888184
Validation loss: 2.322103197856616

Epoch: 6| Step: 6
Training loss: 2.9104087352752686
Validation loss: 2.329304387492518

Epoch: 6| Step: 7
Training loss: 2.9356493949890137
Validation loss: 2.3760616356326687

Epoch: 6| Step: 8
Training loss: 2.9953904151916504
Validation loss: 2.352139357597597

Epoch: 6| Step: 9
Training loss: 1.7605345249176025
Validation loss: 2.3231531625152915

Epoch: 6| Step: 10
Training loss: 2.8735387325286865
Validation loss: 2.326329267153176

Epoch: 6| Step: 11
Training loss: 3.2044155597686768
Validation loss: 2.3667740642383532

Epoch: 6| Step: 12
Training loss: 2.4713988304138184
Validation loss: 2.3580541867081837

Epoch: 6| Step: 13
Training loss: 2.2138662338256836
Validation loss: 2.315823280683128

Epoch: 41| Step: 0
Training loss: 2.6152544021606445
Validation loss: 2.32490494302524

Epoch: 6| Step: 1
Training loss: 2.347691297531128
Validation loss: 2.330187782164543

Epoch: 6| Step: 2
Training loss: 3.285000801086426
Validation loss: 2.339643819357759

Epoch: 6| Step: 3
Training loss: 2.394096851348877
Validation loss: 2.319056039215416

Epoch: 6| Step: 4
Training loss: 2.4309194087982178
Validation loss: 2.329129201109691

Epoch: 6| Step: 5
Training loss: 2.332498073577881
Validation loss: 2.3254284217793453

Epoch: 6| Step: 6
Training loss: 2.811033010482788
Validation loss: 2.304370782708609

Epoch: 6| Step: 7
Training loss: 2.202688694000244
Validation loss: 2.331581428486814

Epoch: 6| Step: 8
Training loss: 2.0216336250305176
Validation loss: 2.334018830330141

Epoch: 6| Step: 9
Training loss: 2.233295202255249
Validation loss: 2.3297644430591213

Epoch: 6| Step: 10
Training loss: 2.2356326580047607
Validation loss: 2.3119160000995924

Epoch: 6| Step: 11
Training loss: 2.639528274536133
Validation loss: 2.3391830844263874

Epoch: 6| Step: 12
Training loss: 2.6289114952087402
Validation loss: 2.309752882167857

Epoch: 6| Step: 13
Training loss: 2.01438045501709
Validation loss: 2.313143612236105

Epoch: 42| Step: 0
Training loss: 2.5908381938934326
Validation loss: 2.3235929037934993

Epoch: 6| Step: 1
Training loss: 1.9974110126495361
Validation loss: 2.300656710901568

Epoch: 6| Step: 2
Training loss: 2.111116409301758
Validation loss: 2.304480375782136

Epoch: 6| Step: 3
Training loss: 1.5182794332504272
Validation loss: 2.273579353927284

Epoch: 6| Step: 4
Training loss: 1.8440700769424438
Validation loss: 2.3488160897326726

Epoch: 6| Step: 5
Training loss: 2.2588088512420654
Validation loss: 2.304562907065115

Epoch: 6| Step: 6
Training loss: 3.3480634689331055
Validation loss: 2.3337247628037647

Epoch: 6| Step: 7
Training loss: 2.5710978507995605
Validation loss: 2.2999497023961877

Epoch: 6| Step: 8
Training loss: 2.5468759536743164
Validation loss: 2.335311387174873

Epoch: 6| Step: 9
Training loss: 2.380181312561035
Validation loss: 2.3057186808637393

Epoch: 6| Step: 10
Training loss: 2.8771960735321045
Validation loss: 2.330504063637026

Epoch: 6| Step: 11
Training loss: 3.3455586433410645
Validation loss: 2.307262724445712

Epoch: 6| Step: 12
Training loss: 2.9062328338623047
Validation loss: 2.260497934074812

Epoch: 6| Step: 13
Training loss: 1.0443063974380493
Validation loss: 2.321661883784879

Epoch: 43| Step: 0
Training loss: 2.3156867027282715
Validation loss: 2.3139569259458974

Epoch: 6| Step: 1
Training loss: 3.3734426498413086
Validation loss: 2.2802180884986796

Epoch: 6| Step: 2
Training loss: 2.036081314086914
Validation loss: 2.2896371900394397

Epoch: 6| Step: 3
Training loss: 2.8045530319213867
Validation loss: 2.3053074664967035

Epoch: 6| Step: 4
Training loss: 2.491011619567871
Validation loss: 2.303771790637765

Epoch: 6| Step: 5
Training loss: 2.2145802974700928
Validation loss: 2.32422379268113

Epoch: 6| Step: 6
Training loss: 2.6590092182159424
Validation loss: 2.2757105827331543

Epoch: 6| Step: 7
Training loss: 2.571293354034424
Validation loss: 2.319566698484523

Epoch: 6| Step: 8
Training loss: 2.496943473815918
Validation loss: 2.292725673285864

Epoch: 6| Step: 9
Training loss: 2.231907844543457
Validation loss: 2.295381035856021

Epoch: 6| Step: 10
Training loss: 1.961195945739746
Validation loss: 2.2900004976539203

Epoch: 6| Step: 11
Training loss: 2.6816139221191406
Validation loss: 2.2995653203738633

Epoch: 6| Step: 12
Training loss: 2.5600104331970215
Validation loss: 2.268987791512602

Epoch: 6| Step: 13
Training loss: 1.5128893852233887
Validation loss: 2.2681106675055718

Epoch: 44| Step: 0
Training loss: 2.4192302227020264
Validation loss: 2.286553375182613

Epoch: 6| Step: 1
Training loss: 2.0569729804992676
Validation loss: 2.3033920872596

Epoch: 6| Step: 2
Training loss: 3.145907163619995
Validation loss: 2.2673717160378732

Epoch: 6| Step: 3
Training loss: 2.111104965209961
Validation loss: 2.2913206905447026

Epoch: 6| Step: 4
Training loss: 2.5874574184417725
Validation loss: 2.28697677581541

Epoch: 6| Step: 5
Training loss: 2.274099349975586
Validation loss: 2.292242947445121

Epoch: 6| Step: 6
Training loss: 2.8260691165924072
Validation loss: 2.305057453852828

Epoch: 6| Step: 7
Training loss: 2.748027801513672
Validation loss: 2.2864902506592455

Epoch: 6| Step: 8
Training loss: 2.4078450202941895
Validation loss: 2.2977740251889793

Epoch: 6| Step: 9
Training loss: 2.932919502258301
Validation loss: 2.318164115310997

Epoch: 6| Step: 10
Training loss: 1.5278222560882568
Validation loss: 2.2750785478981594

Epoch: 6| Step: 11
Training loss: 2.0886478424072266
Validation loss: 2.318902915523898

Epoch: 6| Step: 12
Training loss: 2.636401653289795
Validation loss: 2.3179642385052097

Epoch: 6| Step: 13
Training loss: 2.3468329906463623
Validation loss: 2.286218279151506

Epoch: 45| Step: 0
Training loss: 2.431065320968628
Validation loss: 2.2803134200393513

Epoch: 6| Step: 1
Training loss: 2.218891143798828
Validation loss: 2.243002294212259

Epoch: 6| Step: 2
Training loss: 2.748936653137207
Validation loss: 2.27716580770349

Epoch: 6| Step: 3
Training loss: 2.319146156311035
Validation loss: 2.26945896046136

Epoch: 6| Step: 4
Training loss: 2.6025819778442383
Validation loss: 2.307356165301415

Epoch: 6| Step: 5
Training loss: 3.0518555641174316
Validation loss: 2.321456532324514

Epoch: 6| Step: 6
Training loss: 1.9806301593780518
Validation loss: 2.2811799792833227

Epoch: 6| Step: 7
Training loss: 2.9775443077087402
Validation loss: 2.2909783240287536

Epoch: 6| Step: 8
Training loss: 1.7575069665908813
Validation loss: 2.293401220793365

Epoch: 6| Step: 9
Training loss: 1.9882957935333252
Validation loss: 2.301361039120664

Epoch: 6| Step: 10
Training loss: 1.9324796199798584
Validation loss: 2.2768361799178587

Epoch: 6| Step: 11
Training loss: 2.702324867248535
Validation loss: 2.3040672092027563

Epoch: 6| Step: 12
Training loss: 1.983924150466919
Validation loss: 2.2912900909300773

Epoch: 6| Step: 13
Training loss: 3.443824291229248
Validation loss: 2.297812097816057

Epoch: 46| Step: 0
Training loss: 2.354635238647461
Validation loss: 2.2497587280888713

Epoch: 6| Step: 1
Training loss: 2.1319591999053955
Validation loss: 2.271224940976789

Epoch: 6| Step: 2
Training loss: 2.549363851547241
Validation loss: 2.251156550581737

Epoch: 6| Step: 3
Training loss: 2.548663377761841
Validation loss: 2.289729659275342

Epoch: 6| Step: 4
Training loss: 2.146790027618408
Validation loss: 2.2538897504088697

Epoch: 6| Step: 5
Training loss: 2.496817111968994
Validation loss: 2.2796836591536

Epoch: 6| Step: 6
Training loss: 2.1316261291503906
Validation loss: 2.2714405905815864

Epoch: 6| Step: 7
Training loss: 1.8290977478027344
Validation loss: 2.254806964628158

Epoch: 6| Step: 8
Training loss: 1.9189494848251343
Validation loss: 2.2476593294451312

Epoch: 6| Step: 9
Training loss: 2.32783842086792
Validation loss: 2.2469267793880996

Epoch: 6| Step: 10
Training loss: 2.3378076553344727
Validation loss: 2.291171973751437

Epoch: 6| Step: 11
Training loss: 3.437396287918091
Validation loss: 2.2723486115855556

Epoch: 6| Step: 12
Training loss: 2.6789283752441406
Validation loss: 2.2652953106869935

Epoch: 6| Step: 13
Training loss: 2.812643051147461
Validation loss: 2.2374174723061184

Epoch: 47| Step: 0
Training loss: 2.795656204223633
Validation loss: 2.2439500952279694

Epoch: 6| Step: 1
Training loss: 2.2833380699157715
Validation loss: 2.26334289837909

Epoch: 6| Step: 2
Training loss: 2.0691604614257812
Validation loss: 2.2486867109934487

Epoch: 6| Step: 3
Training loss: 2.251478433609009
Validation loss: 2.245751106610862

Epoch: 6| Step: 4
Training loss: 1.9752366542816162
Validation loss: 2.2263865650341077

Epoch: 6| Step: 5
Training loss: 2.3619651794433594
Validation loss: 2.2114499922721618

Epoch: 6| Step: 6
Training loss: 3.069117546081543
Validation loss: 2.2567657757830877

Epoch: 6| Step: 7
Training loss: 1.9574918746948242
Validation loss: 2.2593272988514235

Epoch: 6| Step: 8
Training loss: 2.4488649368286133
Validation loss: 2.2335606723703365

Epoch: 6| Step: 9
Training loss: 2.023343563079834
Validation loss: 2.2607136131614767

Epoch: 6| Step: 10
Training loss: 2.964649200439453
Validation loss: 2.228599968776908

Epoch: 6| Step: 11
Training loss: 3.078305721282959
Validation loss: 2.254133370614821

Epoch: 6| Step: 12
Training loss: 2.358011484146118
Validation loss: 2.2595844743072346

Epoch: 6| Step: 13
Training loss: 2.02820086479187
Validation loss: 2.2346533075455697

Epoch: 48| Step: 0
Training loss: 1.3541184663772583
Validation loss: 2.2429043862127487

Epoch: 6| Step: 1
Training loss: 2.618107557296753
Validation loss: 2.24496784646024

Epoch: 6| Step: 2
Training loss: 2.538139820098877
Validation loss: 2.2388970672443347

Epoch: 6| Step: 3
Training loss: 2.861266613006592
Validation loss: 2.257583495109312

Epoch: 6| Step: 4
Training loss: 2.876784563064575
Validation loss: 2.2765980177028204

Epoch: 6| Step: 5
Training loss: 2.084671974182129
Validation loss: 2.2291428414724206

Epoch: 6| Step: 6
Training loss: 2.45578932762146
Validation loss: 2.2648819056890344

Epoch: 6| Step: 7
Training loss: 1.7777329683303833
Validation loss: 2.290550452406688

Epoch: 6| Step: 8
Training loss: 2.768584966659546
Validation loss: 2.2295586139925065

Epoch: 6| Step: 9
Training loss: 3.2339963912963867
Validation loss: 2.256994814001104

Epoch: 6| Step: 10
Training loss: 2.5609617233276367
Validation loss: 2.2837404897136073

Epoch: 6| Step: 11
Training loss: 2.779305934906006
Validation loss: 2.2452663888213453

Epoch: 6| Step: 12
Training loss: 2.155045747756958
Validation loss: 2.2956070925599787

Epoch: 6| Step: 13
Training loss: 1.6321454048156738
Validation loss: 2.2643350234595676

Epoch: 49| Step: 0
Training loss: 2.4792020320892334
Validation loss: 2.2517600508146387

Epoch: 6| Step: 1
Training loss: 2.6099748611450195
Validation loss: 2.246872276388189

Epoch: 6| Step: 2
Training loss: 2.2783703804016113
Validation loss: 2.275090326545059

Epoch: 6| Step: 3
Training loss: 2.8848798274993896
Validation loss: 2.2664986477103284

Epoch: 6| Step: 4
Training loss: 3.0716211795806885
Validation loss: 2.231327749067737

Epoch: 6| Step: 5
Training loss: 2.108660936355591
Validation loss: 2.2818659351718042

Epoch: 6| Step: 6
Training loss: 1.5671765804290771
Validation loss: 2.2655862031444425

Epoch: 6| Step: 7
Training loss: 2.5404152870178223
Validation loss: 2.249944670225984

Epoch: 6| Step: 8
Training loss: 1.578596591949463
Validation loss: 2.265018334952734

Epoch: 6| Step: 9
Training loss: 1.8056888580322266
Validation loss: 2.2396094978496595

Epoch: 6| Step: 10
Training loss: 2.5955495834350586
Validation loss: 2.1761801832465717

Epoch: 6| Step: 11
Training loss: 2.4499897956848145
Validation loss: 2.255545111112697

Epoch: 6| Step: 12
Training loss: 2.46138858795166
Validation loss: 2.2582072083668043

Epoch: 6| Step: 13
Training loss: 2.5750224590301514
Validation loss: 2.2751915993229037

Epoch: 50| Step: 0
Training loss: 2.200622797012329
Validation loss: 2.2620596501135055

Epoch: 6| Step: 1
Training loss: 2.0460245609283447
Validation loss: 2.228059632803804

Epoch: 6| Step: 2
Training loss: 2.3405089378356934
Validation loss: 2.226990984332177

Epoch: 6| Step: 3
Training loss: 2.1034083366394043
Validation loss: 2.2706258784058275

Epoch: 6| Step: 4
Training loss: 2.6578309535980225
Validation loss: 2.268167213727069

Epoch: 6| Step: 5
Training loss: 1.9140596389770508
Validation loss: 2.242032886833273

Epoch: 6| Step: 6
Training loss: 2.330352783203125
Validation loss: 2.2249850009077337

Epoch: 6| Step: 7
Training loss: 2.2105467319488525
Validation loss: 2.2476858503075055

Epoch: 6| Step: 8
Training loss: 2.9759864807128906
Validation loss: 2.2161867464742353

Epoch: 6| Step: 9
Training loss: 1.8162667751312256
Validation loss: 2.2337591148191884

Epoch: 6| Step: 10
Training loss: 2.9662318229675293
Validation loss: 2.209480421517485

Epoch: 6| Step: 11
Training loss: 2.5769972801208496
Validation loss: 2.252217128712644

Epoch: 6| Step: 12
Training loss: 2.5036427974700928
Validation loss: 2.2173236441868607

Epoch: 6| Step: 13
Training loss: 2.3472912311553955
Validation loss: 2.2165454331264702

Epoch: 51| Step: 0
Training loss: 2.405841827392578
Validation loss: 2.2266771178091727

Epoch: 6| Step: 1
Training loss: 2.2740631103515625
Validation loss: 2.227117730725196

Epoch: 6| Step: 2
Training loss: 2.29532527923584
Validation loss: 2.256166329947851

Epoch: 6| Step: 3
Training loss: 1.5756897926330566
Validation loss: 2.2372266900154854

Epoch: 6| Step: 4
Training loss: 3.4899983406066895
Validation loss: 2.25700875764252

Epoch: 6| Step: 5
Training loss: 2.1816234588623047
Validation loss: 2.21024662961242

Epoch: 6| Step: 6
Training loss: 2.3789734840393066
Validation loss: 2.272229879133163

Epoch: 6| Step: 7
Training loss: 1.7860286235809326
Validation loss: 2.22330625595585

Epoch: 6| Step: 8
Training loss: 2.6033971309661865
Validation loss: 2.234276262662744

Epoch: 6| Step: 9
Training loss: 2.5915653705596924
Validation loss: 2.23600273747598

Epoch: 6| Step: 10
Training loss: 2.684666872024536
Validation loss: 2.2287675180742816

Epoch: 6| Step: 11
Training loss: 2.0632472038269043
Validation loss: 2.2321270717087613

Epoch: 6| Step: 12
Training loss: 3.0409865379333496
Validation loss: 2.2268939351522796

Epoch: 6| Step: 13
Training loss: 1.1769912242889404
Validation loss: 2.2315005487011326

Epoch: 52| Step: 0
Training loss: 2.254626750946045
Validation loss: 2.231195065283006

Epoch: 6| Step: 1
Training loss: 2.554842472076416
Validation loss: 2.182956039264638

Epoch: 6| Step: 2
Training loss: 2.1136226654052734
Validation loss: 2.204847933143698

Epoch: 6| Step: 3
Training loss: 1.8932759761810303
Validation loss: 2.2238327623695455

Epoch: 6| Step: 4
Training loss: 2.1366655826568604
Validation loss: 2.2439841096119215

Epoch: 6| Step: 5
Training loss: 1.924644947052002
Validation loss: 2.2215801259522796

Epoch: 6| Step: 6
Training loss: 3.0185728073120117
Validation loss: 2.245525610062384

Epoch: 6| Step: 7
Training loss: 2.624509334564209
Validation loss: 2.2239866359259493

Epoch: 6| Step: 8
Training loss: 2.3935348987579346
Validation loss: 2.2574411028174945

Epoch: 6| Step: 9
Training loss: 1.7160003185272217
Validation loss: 2.2269720954279744

Epoch: 6| Step: 10
Training loss: 2.8702006340026855
Validation loss: 2.259185314178467

Epoch: 6| Step: 11
Training loss: 2.2407422065734863
Validation loss: 2.2210549052043627

Epoch: 6| Step: 12
Training loss: 2.9274494647979736
Validation loss: 2.246572973907635

Epoch: 6| Step: 13
Training loss: 1.8683533668518066
Validation loss: 2.2310524960999847

Epoch: 53| Step: 0
Training loss: 2.570354700088501
Validation loss: 2.261017314849361

Epoch: 6| Step: 1
Training loss: 2.241696834564209
Validation loss: 2.246442405126428

Epoch: 6| Step: 2
Training loss: 2.242048501968384
Validation loss: 2.204850822366694

Epoch: 6| Step: 3
Training loss: 1.9510912895202637
Validation loss: 2.2735883805059616

Epoch: 6| Step: 4
Training loss: 2.517141819000244
Validation loss: 2.208279437916253

Epoch: 6| Step: 5
Training loss: 2.6478934288024902
Validation loss: 2.2152489641661286

Epoch: 6| Step: 6
Training loss: 2.313106060028076
Validation loss: 2.2412058281642135

Epoch: 6| Step: 7
Training loss: 1.728986382484436
Validation loss: 2.2395265743296635

Epoch: 6| Step: 8
Training loss: 2.313180446624756
Validation loss: 2.243671609509376

Epoch: 6| Step: 9
Training loss: 2.0642385482788086
Validation loss: 2.2118409641327395

Epoch: 6| Step: 10
Training loss: 3.111144542694092
Validation loss: 2.2295513973441174

Epoch: 6| Step: 11
Training loss: 2.111809253692627
Validation loss: 2.2458663038028184

Epoch: 6| Step: 12
Training loss: 2.5942978858947754
Validation loss: 2.245537024672313

Epoch: 6| Step: 13
Training loss: 2.1406614780426025
Validation loss: 2.251281679317515

Epoch: 54| Step: 0
Training loss: 3.1257641315460205
Validation loss: 2.2598332102580736

Epoch: 6| Step: 1
Training loss: 2.8541946411132812
Validation loss: 2.2603801988786265

Epoch: 6| Step: 2
Training loss: 2.4874074459075928
Validation loss: 2.2783809913102018

Epoch: 6| Step: 3
Training loss: 2.040304183959961
Validation loss: 2.2760948904099

Epoch: 6| Step: 4
Training loss: 1.7110174894332886
Validation loss: 2.2536803419871996

Epoch: 6| Step: 5
Training loss: 2.9348764419555664
Validation loss: 2.249077618763011

Epoch: 6| Step: 6
Training loss: 1.458822250366211
Validation loss: 2.234437496431412

Epoch: 6| Step: 7
Training loss: 2.775055408477783
Validation loss: 2.234208929923273

Epoch: 6| Step: 8
Training loss: 2.2768635749816895
Validation loss: 2.236792218300604

Epoch: 6| Step: 9
Training loss: 2.0745067596435547
Validation loss: 2.2252838739784817

Epoch: 6| Step: 10
Training loss: 2.8323850631713867
Validation loss: 2.2399964486399004

Epoch: 6| Step: 11
Training loss: 1.6604063510894775
Validation loss: 2.2447705832860803

Epoch: 6| Step: 12
Training loss: 1.9823920726776123
Validation loss: 2.282900179586103

Epoch: 6| Step: 13
Training loss: 2.3597848415374756
Validation loss: 2.2468342422157206

Epoch: 55| Step: 0
Training loss: 2.7563092708587646
Validation loss: 2.2384376269514843

Epoch: 6| Step: 1
Training loss: 1.9003523588180542
Validation loss: 2.2184371691878124

Epoch: 6| Step: 2
Training loss: 2.3607430458068848
Validation loss: 2.2408650562327397

Epoch: 6| Step: 3
Training loss: 2.2854485511779785
Validation loss: 2.234714167092436

Epoch: 6| Step: 4
Training loss: 2.2232866287231445
Validation loss: 2.2349664062582035

Epoch: 6| Step: 5
Training loss: 1.6358457803726196
Validation loss: 2.2131244777351298

Epoch: 6| Step: 6
Training loss: 2.2962613105773926
Validation loss: 2.2070389127218597

Epoch: 6| Step: 7
Training loss: 1.8650869131088257
Validation loss: 2.2051558071567166

Epoch: 6| Step: 8
Training loss: 2.2793030738830566
Validation loss: 2.247705016084897

Epoch: 6| Step: 9
Training loss: 2.07960844039917
Validation loss: 2.218899872995192

Epoch: 6| Step: 10
Training loss: 2.5661823749542236
Validation loss: 2.2645873895255466

Epoch: 6| Step: 11
Training loss: 2.9049429893493652
Validation loss: 2.218572978050478

Epoch: 6| Step: 12
Training loss: 2.5703206062316895
Validation loss: 2.1771765665341447

Epoch: 6| Step: 13
Training loss: 2.8362321853637695
Validation loss: 2.208063017937445

Epoch: 56| Step: 0
Training loss: 1.6997191905975342
Validation loss: 2.2400746499338458

Epoch: 6| Step: 1
Training loss: 2.3132705688476562
Validation loss: 2.2086411560735395

Epoch: 6| Step: 2
Training loss: 2.5796031951904297
Validation loss: 2.2365654027590187

Epoch: 6| Step: 3
Training loss: 1.815908670425415
Validation loss: 2.252950112024943

Epoch: 6| Step: 4
Training loss: 2.529543399810791
Validation loss: 2.2714925837773148

Epoch: 6| Step: 5
Training loss: 2.9509458541870117
Validation loss: 2.2742994318726244

Epoch: 6| Step: 6
Training loss: 1.8152177333831787
Validation loss: 2.282819108296466

Epoch: 6| Step: 7
Training loss: 2.4673960208892822
Validation loss: 2.2575793779024513

Epoch: 6| Step: 8
Training loss: 2.124169111251831
Validation loss: 2.245404356269426

Epoch: 6| Step: 9
Training loss: 2.3209776878356934
Validation loss: 2.2303921971269833

Epoch: 6| Step: 10
Training loss: 2.0804836750030518
Validation loss: 2.247162342071533

Epoch: 6| Step: 11
Training loss: 2.258758068084717
Validation loss: 2.2819674604682514

Epoch: 6| Step: 12
Training loss: 3.006197690963745
Validation loss: 2.2232769381615425

Epoch: 6| Step: 13
Training loss: 2.108091115951538
Validation loss: 2.20553562718053

Epoch: 57| Step: 0
Training loss: 1.9801898002624512
Validation loss: 2.206552949002994

Epoch: 6| Step: 1
Training loss: 2.072944164276123
Validation loss: 2.2484382557612594

Epoch: 6| Step: 2
Training loss: 1.9792112112045288
Validation loss: 2.219388541354928

Epoch: 6| Step: 3
Training loss: 2.778709888458252
Validation loss: 2.214754645542432

Epoch: 6| Step: 4
Training loss: 2.134451389312744
Validation loss: 2.232373858010897

Epoch: 6| Step: 5
Training loss: 1.952942132949829
Validation loss: 2.2556557655334473

Epoch: 6| Step: 6
Training loss: 1.923396348953247
Validation loss: 2.237163030973045

Epoch: 6| Step: 7
Training loss: 3.042808771133423
Validation loss: 2.1999967021326863

Epoch: 6| Step: 8
Training loss: 2.521921157836914
Validation loss: 2.2016596089127245

Epoch: 6| Step: 9
Training loss: 2.502380847930908
Validation loss: 2.2089883999157975

Epoch: 6| Step: 10
Training loss: 1.843314528465271
Validation loss: 2.2149703015563307

Epoch: 6| Step: 11
Training loss: 2.7675623893737793
Validation loss: 2.2235243833193215

Epoch: 6| Step: 12
Training loss: 2.510089635848999
Validation loss: 2.203479605336343

Epoch: 6| Step: 13
Training loss: 2.478334903717041
Validation loss: 2.2003972658547024

Epoch: 58| Step: 0
Training loss: 2.3021421432495117
Validation loss: 2.2189746877198577

Epoch: 6| Step: 1
Training loss: 2.563668727874756
Validation loss: 2.1844117051811627

Epoch: 6| Step: 2
Training loss: 2.4311025142669678
Validation loss: 2.271087484975015

Epoch: 6| Step: 3
Training loss: 2.1155223846435547
Validation loss: 2.230895621802217

Epoch: 6| Step: 4
Training loss: 1.337791919708252
Validation loss: 2.25295094777179

Epoch: 6| Step: 5
Training loss: 2.0364432334899902
Validation loss: 2.2401737218262046

Epoch: 6| Step: 6
Training loss: 2.175774574279785
Validation loss: 2.214806713083739

Epoch: 6| Step: 7
Training loss: 3.2697324752807617
Validation loss: 2.2177090157744703

Epoch: 6| Step: 8
Training loss: 1.8248417377471924
Validation loss: 2.252249006302126

Epoch: 6| Step: 9
Training loss: 2.324333667755127
Validation loss: 2.256716997392716

Epoch: 6| Step: 10
Training loss: 2.121403455734253
Validation loss: 2.2545653030436528

Epoch: 6| Step: 11
Training loss: 2.836202383041382
Validation loss: 2.271614800217331

Epoch: 6| Step: 12
Training loss: 2.508871078491211
Validation loss: 2.259465884136897

Epoch: 6| Step: 13
Training loss: 1.9768842458724976
Validation loss: 2.251731739249281

Epoch: 59| Step: 0
Training loss: 2.605288028717041
Validation loss: 2.2488511736674974

Epoch: 6| Step: 1
Training loss: 1.3866426944732666
Validation loss: 2.235924588736667

Epoch: 6| Step: 2
Training loss: 1.9766515493392944
Validation loss: 2.2442790590306765

Epoch: 6| Step: 3
Training loss: 1.7808693647384644
Validation loss: 2.2384508476462415

Epoch: 6| Step: 4
Training loss: 3.0756280422210693
Validation loss: 2.2735988196506294

Epoch: 6| Step: 5
Training loss: 2.9776501655578613
Validation loss: 2.2343083991799304

Epoch: 6| Step: 6
Training loss: 2.9803287982940674
Validation loss: 2.200935886752221

Epoch: 6| Step: 7
Training loss: 2.0384702682495117
Validation loss: 2.244525545386858

Epoch: 6| Step: 8
Training loss: 2.046132802963257
Validation loss: 2.2400879180559548

Epoch: 6| Step: 9
Training loss: 2.4252398014068604
Validation loss: 2.2665812815389326

Epoch: 6| Step: 10
Training loss: 3.3853139877319336
Validation loss: 2.2339766435725714

Epoch: 6| Step: 11
Training loss: 1.6391704082489014
Validation loss: 2.2795154304914576

Epoch: 6| Step: 12
Training loss: 1.8166106939315796
Validation loss: 2.2656720581875054

Epoch: 6| Step: 13
Training loss: 1.760197639465332
Validation loss: 2.24759566655723

Epoch: 60| Step: 0
Training loss: 2.51934814453125
Validation loss: 2.228576252537389

Epoch: 6| Step: 1
Training loss: 2.0044045448303223
Validation loss: 2.30791453648639

Epoch: 6| Step: 2
Training loss: 2.882169246673584
Validation loss: 2.260695698440716

Epoch: 6| Step: 3
Training loss: 2.4142165184020996
Validation loss: 2.283622331516717

Epoch: 6| Step: 4
Training loss: 2.768751621246338
Validation loss: 2.284885980749643

Epoch: 6| Step: 5
Training loss: 1.8217504024505615
Validation loss: 2.3309476196124987

Epoch: 6| Step: 6
Training loss: 1.9555139541625977
Validation loss: 2.26227060697412

Epoch: 6| Step: 7
Training loss: 2.207029104232788
Validation loss: 2.258976436430408

Epoch: 6| Step: 8
Training loss: 1.3572368621826172
Validation loss: 2.2769443501708326

Epoch: 6| Step: 9
Training loss: 1.400831699371338
Validation loss: 2.279320739930676

Epoch: 6| Step: 10
Training loss: 3.5345468521118164
Validation loss: 2.289234544641228

Epoch: 6| Step: 11
Training loss: 2.6466786861419678
Validation loss: 2.2712718645731607

Epoch: 6| Step: 12
Training loss: 2.407957077026367
Validation loss: 2.2407173700230096

Epoch: 6| Step: 13
Training loss: 1.9566906690597534
Validation loss: 2.2273086988797752

Epoch: 61| Step: 0
Training loss: 2.120558738708496
Validation loss: 2.2692623907519924

Epoch: 6| Step: 1
Training loss: 2.0355191230773926
Validation loss: 2.30950580873797

Epoch: 6| Step: 2
Training loss: 3.150994062423706
Validation loss: 2.259003180329518

Epoch: 6| Step: 3
Training loss: 2.310548782348633
Validation loss: 2.2317832951904624

Epoch: 6| Step: 4
Training loss: 2.683967113494873
Validation loss: 2.290740518159764

Epoch: 6| Step: 5
Training loss: 2.4041857719421387
Validation loss: 2.2531694007176224

Epoch: 6| Step: 6
Training loss: 1.6730417013168335
Validation loss: 2.222271664168245

Epoch: 6| Step: 7
Training loss: 1.6567069292068481
Validation loss: 2.247320700717229

Epoch: 6| Step: 8
Training loss: 1.861104965209961
Validation loss: 2.250204442649759

Epoch: 6| Step: 9
Training loss: 2.3861141204833984
Validation loss: 2.2457181305013676

Epoch: 6| Step: 10
Training loss: 3.0129971504211426
Validation loss: 2.216101950214755

Epoch: 6| Step: 11
Training loss: 1.9724278450012207
Validation loss: 2.22311354965292

Epoch: 6| Step: 12
Training loss: 2.1208574771881104
Validation loss: 2.2337483231739332

Epoch: 6| Step: 13
Training loss: 2.8858163356781006
Validation loss: 2.235112351755942

Epoch: 62| Step: 0
Training loss: 1.9015215635299683
Validation loss: 2.232312428053989

Epoch: 6| Step: 1
Training loss: 2.370135545730591
Validation loss: 2.1947152255683817

Epoch: 6| Step: 2
Training loss: 2.133739948272705
Validation loss: 2.2324361493510585

Epoch: 6| Step: 3
Training loss: 2.2553272247314453
Validation loss: 2.2234972741014216

Epoch: 6| Step: 4
Training loss: 2.9723033905029297
Validation loss: 2.2123262395140944

Epoch: 6| Step: 5
Training loss: 2.9576759338378906
Validation loss: 2.1828602129413235

Epoch: 6| Step: 6
Training loss: 1.9266180992126465
Validation loss: 2.2214809566415767

Epoch: 6| Step: 7
Training loss: 2.0564002990722656
Validation loss: 2.2319844204892396

Epoch: 6| Step: 8
Training loss: 2.339629650115967
Validation loss: 2.2806331944722

Epoch: 6| Step: 9
Training loss: 1.370584487915039
Validation loss: 2.2320216971059

Epoch: 6| Step: 10
Training loss: 1.9175604581832886
Validation loss: 2.260440875125188

Epoch: 6| Step: 11
Training loss: 2.951647996902466
Validation loss: 2.2331203709366503

Epoch: 6| Step: 12
Training loss: 2.319814682006836
Validation loss: 2.254317186212027

Epoch: 6| Step: 13
Training loss: 2.507944345474243
Validation loss: 2.23205897115892

Epoch: 63| Step: 0
Training loss: 2.277292490005493
Validation loss: 2.2645026894025904

Epoch: 6| Step: 1
Training loss: 1.79752516746521
Validation loss: 2.2405281323258595

Epoch: 6| Step: 2
Training loss: 2.1125447750091553
Validation loss: 2.1978723643928446

Epoch: 6| Step: 3
Training loss: 2.0131473541259766
Validation loss: 2.301221925725219

Epoch: 6| Step: 4
Training loss: 2.3596415519714355
Validation loss: 2.221790531630157

Epoch: 6| Step: 5
Training loss: 2.543503761291504
Validation loss: 2.2130668496572845

Epoch: 6| Step: 6
Training loss: 2.4993247985839844
Validation loss: 2.238628113141624

Epoch: 6| Step: 7
Training loss: 2.0585570335388184
Validation loss: 2.257952264560166

Epoch: 6| Step: 8
Training loss: 2.7973079681396484
Validation loss: 2.284542037594703

Epoch: 6| Step: 9
Training loss: 3.054523468017578
Validation loss: 2.276427138236261

Epoch: 6| Step: 10
Training loss: 2.375946044921875
Validation loss: 2.238814494943106

Epoch: 6| Step: 11
Training loss: 2.1488239765167236
Validation loss: 2.2575570332106722

Epoch: 6| Step: 12
Training loss: 2.2309024333953857
Validation loss: 2.194950819015503

Epoch: 6| Step: 13
Training loss: 0.8764569759368896
Validation loss: 2.2317951033192296

Epoch: 64| Step: 0
Training loss: 2.8014819622039795
Validation loss: 2.2344454565355854

Epoch: 6| Step: 1
Training loss: 2.1333541870117188
Validation loss: 2.2895888410588747

Epoch: 6| Step: 2
Training loss: 2.2498345375061035
Validation loss: 2.208532428228727

Epoch: 6| Step: 3
Training loss: 1.7995511293411255
Validation loss: 2.228762972739435

Epoch: 6| Step: 4
Training loss: 1.9355109930038452
Validation loss: 2.241586551871351

Epoch: 6| Step: 5
Training loss: 2.7044146060943604
Validation loss: 2.2114284256453156

Epoch: 6| Step: 6
Training loss: 2.6005492210388184
Validation loss: 2.204041539981801

Epoch: 6| Step: 7
Training loss: 2.173468828201294
Validation loss: 2.203788088214013

Epoch: 6| Step: 8
Training loss: 2.1378979682922363
Validation loss: 2.255192241361064

Epoch: 6| Step: 9
Training loss: 2.632719039916992
Validation loss: 2.1743532034658615

Epoch: 6| Step: 10
Training loss: 1.9031282663345337
Validation loss: 2.2657960461032007

Epoch: 6| Step: 11
Training loss: 2.478646755218506
Validation loss: 2.214473194973443

Epoch: 6| Step: 12
Training loss: 2.1388983726501465
Validation loss: 2.189158090981104

Epoch: 6| Step: 13
Training loss: 1.7196650505065918
Validation loss: 2.2576212088267007

Epoch: 65| Step: 0
Training loss: 3.181659460067749
Validation loss: 2.2668133333165157

Epoch: 6| Step: 1
Training loss: 2.247709274291992
Validation loss: 2.2666381584700717

Epoch: 6| Step: 2
Training loss: 2.189608573913574
Validation loss: 2.259997275567824

Epoch: 6| Step: 3
Training loss: 2.4558749198913574
Validation loss: 2.2543883785124748

Epoch: 6| Step: 4
Training loss: 1.9394910335540771
Validation loss: 2.199786468218732

Epoch: 6| Step: 5
Training loss: 1.8769159317016602
Validation loss: 2.2251020554573304

Epoch: 6| Step: 6
Training loss: 2.0056066513061523
Validation loss: 2.2892523760436685

Epoch: 6| Step: 7
Training loss: 2.23970365524292
Validation loss: 2.221836123415219

Epoch: 6| Step: 8
Training loss: 2.1608147621154785
Validation loss: 2.246324590457383

Epoch: 6| Step: 9
Training loss: 2.0132389068603516
Validation loss: 2.2573212603087067

Epoch: 6| Step: 10
Training loss: 2.384392738342285
Validation loss: 2.2673130458401096

Epoch: 6| Step: 11
Training loss: 2.226388692855835
Validation loss: 2.257778177979172

Epoch: 6| Step: 12
Training loss: 2.841371774673462
Validation loss: 2.2433628420675955

Epoch: 6| Step: 13
Training loss: 2.010051727294922
Validation loss: 2.2514256918302147

Epoch: 66| Step: 0
Training loss: 2.258408784866333
Validation loss: 2.260270359695599

Epoch: 6| Step: 1
Training loss: 2.273411750793457
Validation loss: 2.2392707229942403

Epoch: 6| Step: 2
Training loss: 2.181924819946289
Validation loss: 2.250567484927434

Epoch: 6| Step: 3
Training loss: 2.775235176086426
Validation loss: 2.2705868239043863

Epoch: 6| Step: 4
Training loss: 2.531435251235962
Validation loss: 2.2475706095336587

Epoch: 6| Step: 5
Training loss: 1.828012466430664
Validation loss: 2.2523873839327084

Epoch: 6| Step: 6
Training loss: 2.267573595046997
Validation loss: 2.2295705118486957

Epoch: 6| Step: 7
Training loss: 2.197535514831543
Validation loss: 2.271205868772281

Epoch: 6| Step: 8
Training loss: 2.1075215339660645
Validation loss: 2.2349933219212357

Epoch: 6| Step: 9
Training loss: 1.8336033821105957
Validation loss: 2.267439575605495

Epoch: 6| Step: 10
Training loss: 2.8973309993743896
Validation loss: 2.2699047365496234

Epoch: 6| Step: 11
Training loss: 1.6747660636901855
Validation loss: 2.2341464334918606

Epoch: 6| Step: 12
Training loss: 2.050351142883301
Validation loss: 2.1854021318497194

Epoch: 6| Step: 13
Training loss: 3.5665957927703857
Validation loss: 2.199177990677536

Epoch: 67| Step: 0
Training loss: 2.8518590927124023
Validation loss: 2.2031320166844193

Epoch: 6| Step: 1
Training loss: 2.059511184692383
Validation loss: 2.2306689908427577

Epoch: 6| Step: 2
Training loss: 2.530592441558838
Validation loss: 2.268170238823019

Epoch: 6| Step: 3
Training loss: 1.8935184478759766
Validation loss: 2.224974925800036

Epoch: 6| Step: 4
Training loss: 2.095858097076416
Validation loss: 2.203659439599642

Epoch: 6| Step: 5
Training loss: 3.041923999786377
Validation loss: 2.22751590641596

Epoch: 6| Step: 6
Training loss: 1.7013475894927979
Validation loss: 2.225323023334626

Epoch: 6| Step: 7
Training loss: 2.8253884315490723
Validation loss: 2.210393977421586

Epoch: 6| Step: 8
Training loss: 1.8214190006256104
Validation loss: 2.2029642648594354

Epoch: 6| Step: 9
Training loss: 2.201958656311035
Validation loss: 2.2250290750175394

Epoch: 6| Step: 10
Training loss: 2.0334224700927734
Validation loss: 2.1734668080524733

Epoch: 6| Step: 11
Training loss: 2.7224295139312744
Validation loss: 2.177037154474566

Epoch: 6| Step: 12
Training loss: 2.3972582817077637
Validation loss: 2.2217585399586666

Epoch: 6| Step: 13
Training loss: 1.463113784790039
Validation loss: 2.223636370833202

Epoch: 68| Step: 0
Training loss: 2.6665596961975098
Validation loss: 2.243024854249852

Epoch: 6| Step: 1
Training loss: 3.024554967880249
Validation loss: 2.279342564203406

Epoch: 6| Step: 2
Training loss: 1.4328546524047852
Validation loss: 2.268227682318739

Epoch: 6| Step: 3
Training loss: 2.157393455505371
Validation loss: 2.2564687754518244

Epoch: 6| Step: 4
Training loss: 2.7647547721862793
Validation loss: 2.2519159932290354

Epoch: 6| Step: 5
Training loss: 2.1024129390716553
Validation loss: 2.2864840030670166

Epoch: 6| Step: 6
Training loss: 1.9974849224090576
Validation loss: 2.2604377244108464

Epoch: 6| Step: 7
Training loss: 2.165951728820801
Validation loss: 2.2440842992515972

Epoch: 6| Step: 8
Training loss: 2.338974714279175
Validation loss: 2.244523973875148

Epoch: 6| Step: 9
Training loss: 2.728935956954956
Validation loss: 2.2684513048459123

Epoch: 6| Step: 10
Training loss: 2.7251126766204834
Validation loss: 2.263441096069992

Epoch: 6| Step: 11
Training loss: 1.8902628421783447
Validation loss: 2.21774544126244

Epoch: 6| Step: 12
Training loss: 2.0399129390716553
Validation loss: 2.283706652220859

Epoch: 6| Step: 13
Training loss: 1.5023112297058105
Validation loss: 2.2990381922773135

Epoch: 69| Step: 0
Training loss: 2.0369834899902344
Validation loss: 2.2721904887947986

Epoch: 6| Step: 1
Training loss: 2.6531200408935547
Validation loss: 2.2815565806563183

Epoch: 6| Step: 2
Training loss: 1.7738409042358398
Validation loss: 2.277211058524347

Epoch: 6| Step: 3
Training loss: 2.1804563999176025
Validation loss: 2.249857214189345

Epoch: 6| Step: 4
Training loss: 2.501990556716919
Validation loss: 2.270375197933566

Epoch: 6| Step: 5
Training loss: 2.220916509628296
Validation loss: 2.2142307860876924

Epoch: 6| Step: 6
Training loss: 2.3070430755615234
Validation loss: 2.282672292442732

Epoch: 6| Step: 7
Training loss: 2.1250622272491455
Validation loss: 2.2257224590547624

Epoch: 6| Step: 8
Training loss: 2.0607266426086426
Validation loss: 2.2708865583583875

Epoch: 6| Step: 9
Training loss: 2.217088222503662
Validation loss: 2.2824966305045673

Epoch: 6| Step: 10
Training loss: 2.976668119430542
Validation loss: 2.244218941657774

Epoch: 6| Step: 11
Training loss: 2.2735886573791504
Validation loss: 2.24114978185264

Epoch: 6| Step: 12
Training loss: 2.154078960418701
Validation loss: 2.204719202492827

Epoch: 6| Step: 13
Training loss: 1.5906281471252441
Validation loss: 2.2714838135627007

Epoch: 70| Step: 0
Training loss: 1.599816083908081
Validation loss: 2.22836273459978

Epoch: 6| Step: 1
Training loss: 2.523913860321045
Validation loss: 2.206493693013345

Epoch: 6| Step: 2
Training loss: 2.022040605545044
Validation loss: 2.189876643560266

Epoch: 6| Step: 3
Training loss: 1.8083786964416504
Validation loss: 2.260645358793197

Epoch: 6| Step: 4
Training loss: 2.6749582290649414
Validation loss: 2.2403127506215084

Epoch: 6| Step: 5
Training loss: 2.410597801208496
Validation loss: 2.2370129759593675

Epoch: 6| Step: 6
Training loss: 1.9431178569793701
Validation loss: 2.2427298240764166

Epoch: 6| Step: 7
Training loss: 2.709987163543701
Validation loss: 2.2494725796484176

Epoch: 6| Step: 8
Training loss: 1.8175368309020996
Validation loss: 2.257189748107746

Epoch: 6| Step: 9
Training loss: 2.395235061645508
Validation loss: 2.2629227740790254

Epoch: 6| Step: 10
Training loss: 2.7178244590759277
Validation loss: 2.261125672248102

Epoch: 6| Step: 11
Training loss: 2.2078161239624023
Validation loss: 2.2231772292044854

Epoch: 6| Step: 12
Training loss: 1.8136826753616333
Validation loss: 2.2726775471882155

Epoch: 6| Step: 13
Training loss: 2.4154696464538574
Validation loss: 2.260851119154243

Epoch: 71| Step: 0
Training loss: 2.5556092262268066
Validation loss: 2.300480840026691

Epoch: 6| Step: 1
Training loss: 1.842950701713562
Validation loss: 2.284350774621451

Epoch: 6| Step: 2
Training loss: 2.111133575439453
Validation loss: 2.259484541031622

Epoch: 6| Step: 3
Training loss: 2.4005959033966064
Validation loss: 2.279420288660193

Epoch: 6| Step: 4
Training loss: 1.7906599044799805
Validation loss: 2.3003761383794967

Epoch: 6| Step: 5
Training loss: 2.426344871520996
Validation loss: 2.313257976244855

Epoch: 6| Step: 6
Training loss: 2.533273458480835
Validation loss: 2.2735540636124147

Epoch: 6| Step: 7
Training loss: 3.3359220027923584
Validation loss: 2.285454862861223

Epoch: 6| Step: 8
Training loss: 2.1638057231903076
Validation loss: 2.245608557936966

Epoch: 6| Step: 9
Training loss: 2.2398219108581543
Validation loss: 2.283358931541443

Epoch: 6| Step: 10
Training loss: 2.0421464443206787
Validation loss: 2.2937115469286518

Epoch: 6| Step: 11
Training loss: 2.043024778366089
Validation loss: 2.2609794421862532

Epoch: 6| Step: 12
Training loss: 2.2289717197418213
Validation loss: 2.271586133587745

Epoch: 6| Step: 13
Training loss: 1.5186223983764648
Validation loss: 2.255551420232301

Epoch: 72| Step: 0
Training loss: 2.6862123012542725
Validation loss: 2.2830214218426774

Epoch: 6| Step: 1
Training loss: 2.7365622520446777
Validation loss: 2.251737940695978

Epoch: 6| Step: 2
Training loss: 2.3865203857421875
Validation loss: 2.277045234557121

Epoch: 6| Step: 3
Training loss: 1.653304100036621
Validation loss: 2.271358184916999

Epoch: 6| Step: 4
Training loss: 2.3989038467407227
Validation loss: 2.277432193038284

Epoch: 6| Step: 5
Training loss: 1.8077802658081055
Validation loss: 2.2730075287562546

Epoch: 6| Step: 6
Training loss: 1.8729275465011597
Validation loss: 2.2438105152499292

Epoch: 6| Step: 7
Training loss: 2.450106382369995
Validation loss: 2.2061702692380516

Epoch: 6| Step: 8
Training loss: 2.3415091037750244
Validation loss: 2.244945569704938

Epoch: 6| Step: 9
Training loss: 1.8267710208892822
Validation loss: 2.2286009186057636

Epoch: 6| Step: 10
Training loss: 2.831183910369873
Validation loss: 2.250216591742731

Epoch: 6| Step: 11
Training loss: 1.950359582901001
Validation loss: 2.157597585390973

Epoch: 6| Step: 12
Training loss: 2.1124463081359863
Validation loss: 2.2766639417217625

Epoch: 6| Step: 13
Training loss: 3.0917468070983887
Validation loss: 2.270028588592365

Epoch: 73| Step: 0
Training loss: 1.616300106048584
Validation loss: 2.2294301102238316

Epoch: 6| Step: 1
Training loss: 2.2556447982788086
Validation loss: 2.2608999218992007

Epoch: 6| Step: 2
Training loss: 2.944286346435547
Validation loss: 2.2155970014551634

Epoch: 6| Step: 3
Training loss: 2.161146640777588
Validation loss: 2.2578722943541822

Epoch: 6| Step: 4
Training loss: 2.7113990783691406
Validation loss: 2.2313048275568153

Epoch: 6| Step: 5
Training loss: 2.233707904815674
Validation loss: 2.24247383814986

Epoch: 6| Step: 6
Training loss: 1.7675302028656006
Validation loss: 2.2614543412321355

Epoch: 6| Step: 7
Training loss: 2.557025909423828
Validation loss: 2.2732882115148727

Epoch: 6| Step: 8
Training loss: 1.6568334102630615
Validation loss: 2.24549896999072

Epoch: 6| Step: 9
Training loss: 2.328530788421631
Validation loss: 2.277406597650179

Epoch: 6| Step: 10
Training loss: 2.615921974182129
Validation loss: 2.2717847567732616

Epoch: 6| Step: 11
Training loss: 2.28371524810791
Validation loss: 2.203251923284223

Epoch: 6| Step: 12
Training loss: 2.085890769958496
Validation loss: 2.257731217210011

Epoch: 6| Step: 13
Training loss: 1.0961897373199463
Validation loss: 2.2816449672945085

Epoch: 74| Step: 0
Training loss: 1.6302459239959717
Validation loss: 2.264259325560703

Epoch: 6| Step: 1
Training loss: 2.542628288269043
Validation loss: 2.2524834807201097

Epoch: 6| Step: 2
Training loss: 2.4109034538269043
Validation loss: 2.249007522418935

Epoch: 6| Step: 3
Training loss: 2.1919686794281006
Validation loss: 2.246891672893237

Epoch: 6| Step: 4
Training loss: 1.7234349250793457
Validation loss: 2.2495145003000894

Epoch: 6| Step: 5
Training loss: 2.021202564239502
Validation loss: 2.269042215039653

Epoch: 6| Step: 6
Training loss: 1.980576753616333
Validation loss: 2.2176773830126693

Epoch: 6| Step: 7
Training loss: 2.854893922805786
Validation loss: 2.2333501436377086

Epoch: 6| Step: 8
Training loss: 1.8944780826568604
Validation loss: 2.209600064062303

Epoch: 6| Step: 9
Training loss: 2.3426222801208496
Validation loss: 2.2722098570997997

Epoch: 6| Step: 10
Training loss: 1.9249261617660522
Validation loss: 2.2371765387955533

Epoch: 6| Step: 11
Training loss: 1.5353622436523438
Validation loss: 2.2275235140195457

Epoch: 6| Step: 12
Training loss: 2.8862595558166504
Validation loss: 2.254268325785155

Epoch: 6| Step: 13
Training loss: 2.748549461364746
Validation loss: 2.2687722739352973

Epoch: 75| Step: 0
Training loss: 2.5134167671203613
Validation loss: 2.217660879576078

Epoch: 6| Step: 1
Training loss: 2.143177032470703
Validation loss: 2.1965196619751635

Epoch: 6| Step: 2
Training loss: 1.3053568601608276
Validation loss: 2.228432996298677

Epoch: 6| Step: 3
Training loss: 2.1383347511291504
Validation loss: 2.2138306299845376

Epoch: 6| Step: 4
Training loss: 2.22756290435791
Validation loss: 2.2507783110423754

Epoch: 6| Step: 5
Training loss: 1.2084413766860962
Validation loss: 2.2536759273980254

Epoch: 6| Step: 6
Training loss: 2.1291439533233643
Validation loss: 2.2333079153491604

Epoch: 6| Step: 7
Training loss: 2.3005142211914062
Validation loss: 2.1968953506920927

Epoch: 6| Step: 8
Training loss: 2.3419101238250732
Validation loss: 2.2309298425592403

Epoch: 6| Step: 9
Training loss: 2.7178072929382324
Validation loss: 2.2464285127578245

Epoch: 6| Step: 10
Training loss: 2.2846078872680664
Validation loss: 2.2623596140133437

Epoch: 6| Step: 11
Training loss: 2.3354573249816895
Validation loss: 2.2122169681774673

Epoch: 6| Step: 12
Training loss: 2.129589557647705
Validation loss: 2.257820736977362

Epoch: 6| Step: 13
Training loss: 3.7457075119018555
Validation loss: 2.2344226273157264

Testing loss: 2.273112159305149
